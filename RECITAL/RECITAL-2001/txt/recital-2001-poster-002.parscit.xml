<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Amati</author>
<author>F Crestani</author>
<author>F Ubaldini</author>
</authors>
<title>A Learning System for Selective Dissemination of Information”,</title>
<date>1997</date>
<booktitle>Proc. Of the 15”’ International Joint Conf On Artificial Intelligence (IJCAI— 97),</booktitle>
<pages>764--769</pages>
<location>Nagoya,</location>
<contexts>
<context position="5561" citStr="Amati et al. (1997)" startWordPosition="768" endWordPosition="771">IWBC AgentWeb &gt;&gt; (http://www.csee.umbc.edu/agents) ou &lt;&lt; Web Information Retrieval &amp; Information Extraction» (http://www.mri.mq.edu.au/~einat/web_ir). Nous souhaitons focaliser sur les différents aspects de la personnalisation et les approches dont l’objectif est de rendre le logiciel adaptable aux besoins de chaque utilisateur et un aspect de la personnalisation est le filtrage de l’information. Michel (2000) propose un systeme permettant le filtrage de données en prenant en compte les caractéristiques personnelles des utilisateurs qui choisissent parmi huit processus de filtrage différents. Amati et al. (1997) présentent le systeme ProFile qui acquiert et met a jour un modele des intéréts des utilisateurs au moyen d’une interaction avec 1 Afin de simplifier la discussion, nous utilisons le terme document pour faire reference a n’importe quel groupement des donne&apos;es du Web qui est vu nomialement comme une unite’. Par exemple, cela peut étre une page Web, un document textuel, une image, un fichier audio, etc. Outils d ’assistance a la construction de Webs personnels ceux-ci et de l’utilisation d’un algorithme d’apprentissage. Pour le ﬁltrage d’inforrnations et la collaboration entre agents et utilisa</context>
</contexts>
<marker>Amati, Crestani, Ubaldini, 1997</marker>
<rawString>Amati G., Crestani, F., Ubaldini, F. (1997), “A Learning System for Selective Dissemination of Information”, Proc. Of the 15”’ International Joint Conf On Artificial Intelligence (IJCAI— 97), Nagoya, Japan, 23-29 aoﬁt 1997, 764-769.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Yassine El Amrani Barker K</author>
<author>S Delisle</author>
<author>S Szpakowicz</author>
</authors>
<title>Test-Driving TANKA: Evaluating a Semi-automatic System of Text Analysis for Knowledge Acquisition”,</title>
<date>1998</date>
<booktitle>I2th Biennal Conference of the Canadian Society for Computational Studies of Intelligence (CAI &apos;98), Vancouver (B.C.), Canada, juin</booktitle>
<pages>18--20</pages>
<publisher>Springer.</publisher>
<marker>K, Delisle, Szpakowicz, 1998</marker>
<rawString>Mohamed Yassine El Amrani Barker K., Delisle, S., Szpakowicz, S. (1998). “Test-Driving TANKA: Evaluating a Semi-automatic System of Text Analysis for Knowledge Acquisition”, I2th Biennal Conference of the Canadian Society for Computational Studies of Intelligence (CAI &apos;98), Vancouver (B.C.), Canada, juin 18-20 1998, 60--71. Published in Lectures Notes in Artiﬁcial Intelligence #1418, Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Biskri</author>
<author>S Delisle</author>
</authors>
<title>Un modele hybride pour le textual data mining : un mariage de raison entre le numérique et le linguistique”,</title>
<date>1999</date>
<booktitle>6eme Conférence Annuelle sur le Traitement Automatique des Langues (TALN-99), Cargese,</booktitle>
<pages>55--64</pages>
<location>Corse,</location>
<contexts>
<context position="6737" citStr="Biskri &amp; Delisle (1999)" startWordPosition="952" endWordPosition="955">ons et la collaboration entre agents et utilisateurs, nous référons le lecteur aux travaux de Cohen &amp; Kudenko (1997) et de Good et al. (1999). Le systeme proposé par Craven et al. (1998) utilise une ontologie de classes et de relations ainsi que des pages Web sélectionnées par l’utilisateur qui servent d’exemples d’entrainements a ces classes et relations pour apprendre les procédures permettant l’extraction de nouvelles instances a partir du Web. Jouis et al. (1998) présentent le projet COGNIWEB qui est un modele hybride combinant des outils numériques et linguistiques du TLN (Voir également Biskri &amp; Delisle (1999)). C’est un outil de ﬁltrage de documents issus du Web. Un classiﬁcateur identiﬁe les pages Web partageant un certain nombre de termes puis une analyse sémantique est effectuée a l’aide du sous-systeme SEEK. L’utilisateur identifie ensuite les relations sémantiques entre les termes. 3 Le systeme d’aide 51 la construction de Webs personnels Nous décrivons maintenant les principaux éléments de notre outil d’aide a la construction de Webs personnels. Bien que le projet soit en cours de développement, nous avons déja concu, développé et implémenté en Visual C++ plusieurs de ses composantes. Ce pro</context>
<context position="9439" citStr="Biskri &amp; Delisle, 1999" startWordPosition="1360" endWordPosition="1363">e devrait englober l’information que l’utilisateur espere trouver sur le Web. Par la suite, l’utilisateur aura l’opportunité de reconsidérer sa requéte a la lumiere des résultats de recherche obtenus grace a cette requéte initiale (Figure 1). Dans le cadre de ce projet, nous considérons que chaque site Web représente un segment textuel. Ainsi, un ensemble de sites Web forme un ensemble de segments textuels composant ainsi un corpus ou chaque segment conserve son identité et sa source. Nous soumettons alors ce corpus a un classiﬁcateur numérique (l\/Ieunier et al., 1997 ; Rialle et al., 1998 ; Biskri &amp; Delisle, 1999) permettant l’identiﬁcation des segments partageant des régularités lexicales. Toutefois, nous demeurons ouvert a l’utilisation de classificateurs autres que ceux cités — sur les classiﬁcateurs textuels, Voir Turenne (2000). Les classes produites par le classiﬁcateur Vont tendre a contenir des segments de sujets similaires et Vont identiﬁer les unités lexicales qui ont tendance a étre associées a ces sujets. Les résultats du classiﬁcateur numérique Vont fournir une liste de termes candidats en relation avec ceux de la requéte initiale. Cela permet de foumir une assistance dans la formulation d</context>
</contexts>
<marker>Biskri, Delisle, 1999</marker>
<rawString>Biskri I., Delisle, S. (1999), “Un modele hybride pour le textual data mining : un mariage de raison entre le numérique et le linguistique”, 6eme Conférence Annuelle sur le Traitement Automatique des Langues (TALN-99), Cargese, Corse, 12-17 juillet 1999, 55-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Biskri</author>
<author>S Delisle</author>
</authors>
<title>User-Relevant Access to Textual Information Through Flexible Identification of Terms: A Semi-Automatic Method and Software Based on a Combination of N-Grams and Surface Linguistic Filters”,</title>
<date>2000</date>
<booktitle>Actes de la 6e‘me Conférence RIAO-2000 ( Content-Based Multimedia Information Access),</booktitle>
<location>Paris</location>
<marker>Biskri, Delisle, 2000</marker>
<rawString>Biskri I., Delisle, S. (2000), “User-Relevant Access to Textual Information Through Flexible Identification of Terms: A Semi-Automatic Method and Software Based on a Combination of N-Grams and Surface Linguistic Filters”, Actes de la 6e‘me Conférence RIAO-2000 ( Content-Based Multimedia Information Access), Paris (France), 12-14 avril 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W W Cohen</author>
<author>K Kudenko</author>
</authors>
<title>Transferring and Retraining Learned Information Filters”,</title>
<date>1997</date>
<booktitle>Proc. of the 14th National Conf on Artiﬁcial Intelligence (AAAI—97),</booktitle>
<pages>583--590</pages>
<location>Providence (Rhode Island), USA,</location>
<contexts>
<context position="6230" citStr="Cohen &amp; Kudenko (1997)" startWordPosition="873" endWordPosition="876">met a jour un modele des intéréts des utilisateurs au moyen d’une interaction avec 1 Afin de simplifier la discussion, nous utilisons le terme document pour faire reference a n’importe quel groupement des donne&apos;es du Web qui est vu nomialement comme une unite’. Par exemple, cela peut étre une page Web, un document textuel, une image, un fichier audio, etc. Outils d ’assistance a la construction de Webs personnels ceux-ci et de l’utilisation d’un algorithme d’apprentissage. Pour le ﬁltrage d’inforrnations et la collaboration entre agents et utilisateurs, nous référons le lecteur aux travaux de Cohen &amp; Kudenko (1997) et de Good et al. (1999). Le systeme proposé par Craven et al. (1998) utilise une ontologie de classes et de relations ainsi que des pages Web sélectionnées par l’utilisateur qui servent d’exemples d’entrainements a ces classes et relations pour apprendre les procédures permettant l’extraction de nouvelles instances a partir du Web. Jouis et al. (1998) présentent le projet COGNIWEB qui est un modele hybride combinant des outils numériques et linguistiques du TLN (Voir également Biskri &amp; Delisle (1999)). C’est un outil de ﬁltrage de documents issus du Web. Un classiﬁcateur identiﬁe les pages W</context>
</contexts>
<marker>Cohen, Kudenko, 1997</marker>
<rawString>Cohen, W.W., Kudenko, K. (1997), “Transferring and Retraining Learned Information Filters”, Proc. of the 14th National Conf on Artiﬁcial Intelligence (AAAI—97), Providence (Rhode Island), USA, 27-31 juillet 1997, 583-590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Craven</author>
<author>D DiPasquo</author>
<author>D Freitag</author>
<author>A McCallum</author>
<author>T Mitchell</author>
<author>K Nigam</author>
<author>S Slattery</author>
</authors>
<date>1998</date>
<booktitle>Learning to Extract Symbolic Knowledge from the World Wide Web”, Proc. of the 15th National Conf on Artificial Intelligence (AAAI-98),</booktitle>
<pages>509--516</pages>
<location>Madison, Wisconsin, USA,</location>
<contexts>
<context position="6300" citStr="Craven et al. (1998)" startWordPosition="887" endWordPosition="890">ction avec 1 Afin de simplifier la discussion, nous utilisons le terme document pour faire reference a n’importe quel groupement des donne&apos;es du Web qui est vu nomialement comme une unite’. Par exemple, cela peut étre une page Web, un document textuel, une image, un fichier audio, etc. Outils d ’assistance a la construction de Webs personnels ceux-ci et de l’utilisation d’un algorithme d’apprentissage. Pour le ﬁltrage d’inforrnations et la collaboration entre agents et utilisateurs, nous référons le lecteur aux travaux de Cohen &amp; Kudenko (1997) et de Good et al. (1999). Le systeme proposé par Craven et al. (1998) utilise une ontologie de classes et de relations ainsi que des pages Web sélectionnées par l’utilisateur qui servent d’exemples d’entrainements a ces classes et relations pour apprendre les procédures permettant l’extraction de nouvelles instances a partir du Web. Jouis et al. (1998) présentent le projet COGNIWEB qui est un modele hybride combinant des outils numériques et linguistiques du TLN (Voir également Biskri &amp; Delisle (1999)). C’est un outil de ﬁltrage de documents issus du Web. Un classiﬁcateur identiﬁe les pages Web partageant un certain nombre de termes puis une analyse sémantique </context>
</contexts>
<marker>Craven, DiPasquo, Freitag, McCallum, Mitchell, Nigam, Slattery, 1998</marker>
<rawString>Craven, M., DiPasquo, D., Freitag, D., McCallum, A., Mitchell, T., Nigam, K., Slattery, S. (1998), “Learning to Extract Symbolic Knowledge from the World Wide Web”, Proc. of the 15th National Conf on Artificial Intelligence (AAAI-98), Madison, Wisconsin, USA, 26-30 juillet 1998, 509-516.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Good</author>
<author>B Schafer</author>
<author>J Konstan</author>
<author>A Borchers</author>
<author>B Sarwar</author>
<author>J Herlocker</author>
<author>J Riedl</author>
</authors>
<title>Combining Collaborative Filtering With Personal Agents for Better Recommendations”,</title>
<date>1999</date>
<booktitle>In Proceedings of the AAAI- ’99 conference,</booktitle>
<pages>439--446</pages>
<contexts>
<context position="6255" citStr="Good et al. (1999)" startWordPosition="879" endWordPosition="882">réts des utilisateurs au moyen d’une interaction avec 1 Afin de simplifier la discussion, nous utilisons le terme document pour faire reference a n’importe quel groupement des donne&apos;es du Web qui est vu nomialement comme une unite’. Par exemple, cela peut étre une page Web, un document textuel, une image, un fichier audio, etc. Outils d ’assistance a la construction de Webs personnels ceux-ci et de l’utilisation d’un algorithme d’apprentissage. Pour le ﬁltrage d’inforrnations et la collaboration entre agents et utilisateurs, nous référons le lecteur aux travaux de Cohen &amp; Kudenko (1997) et de Good et al. (1999). Le systeme proposé par Craven et al. (1998) utilise une ontologie de classes et de relations ainsi que des pages Web sélectionnées par l’utilisateur qui servent d’exemples d’entrainements a ces classes et relations pour apprendre les procédures permettant l’extraction de nouvelles instances a partir du Web. Jouis et al. (1998) présentent le projet COGNIWEB qui est un modele hybride combinant des outils numériques et linguistiques du TLN (Voir également Biskri &amp; Delisle (1999)). C’est un outil de ﬁltrage de documents issus du Web. Un classiﬁcateur identiﬁe les pages Web partageant un certain </context>
</contexts>
<marker>Good, Schafer, Konstan, Borchers, Sarwar, Herlocker, Riedl, 1999</marker>
<rawString>Good, N., Schafer, B., Konstan, J., Borchers, A., Sarwar, B., Herlocker, J., &amp; Riedl, J. (1999). “Combining Collaborative Filtering With Personal Agents for Better Recommendations”, In Proceedings of the AAAI- ’99 conference, 439-446.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jouis</author>
<author>Mustafa el-Hadi</author>
<author>W Rialle</author>
<author>V</author>
</authors>
<title>COGNIWEB, Modélisation hybride linguistique et numérique pour un outil de filtrage d’informations sur les réseaux”,</title>
<date>1998</date>
<booktitle>Actes de la Rencontre Internationale sur l ’Extraction, le F iltrage et le Résumé Automatique (RIFRA-98), Sfax, Tunisie,</booktitle>
<pages>11--14</pages>
<contexts>
<context position="6585" citStr="Jouis et al. (1998)" startWordPosition="929" endWordPosition="932"> Outils d ’assistance a la construction de Webs personnels ceux-ci et de l’utilisation d’un algorithme d’apprentissage. Pour le ﬁltrage d’inforrnations et la collaboration entre agents et utilisateurs, nous référons le lecteur aux travaux de Cohen &amp; Kudenko (1997) et de Good et al. (1999). Le systeme proposé par Craven et al. (1998) utilise une ontologie de classes et de relations ainsi que des pages Web sélectionnées par l’utilisateur qui servent d’exemples d’entrainements a ces classes et relations pour apprendre les procédures permettant l’extraction de nouvelles instances a partir du Web. Jouis et al. (1998) présentent le projet COGNIWEB qui est un modele hybride combinant des outils numériques et linguistiques du TLN (Voir également Biskri &amp; Delisle (1999)). C’est un outil de ﬁltrage de documents issus du Web. Un classiﬁcateur identiﬁe les pages Web partageant un certain nombre de termes puis une analyse sémantique est effectuée a l’aide du sous-systeme SEEK. L’utilisateur identifie ensuite les relations sémantiques entre les termes. 3 Le systeme d’aide 51 la construction de Webs personnels Nous décrivons maintenant les principaux éléments de notre outil d’aide a la construction de Webs personne</context>
</contexts>
<marker>Jouis, el-Hadi, Rialle, V, 1998</marker>
<rawString>Jouis C., Mustafa el-Hadi, W. Rialle, V. (1998), “COGNIWEB, Modélisation hybride linguistique et numérique pour un outil de filtrage d’informations sur les réseaux”, Actes de la Rencontre Internationale sur l ’Extraction, le F iltrage et le Résumé Automatique (RIFRA-98), Sfax, Tunisie, 11-14 novembre 1998, 191-203.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G Meunier</author>
<author>I Biskri</author>
<author>G Nault</author>
<author>M Nyongwa</author>
</authors>
<title>ALADIN et le traitement connexionniste de l’analyse terminologique”,</title>
<date>1997</date>
<booktitle>Actes de la Conf sur la Recherche d ’Informations Assistée par Ordinateur (RIAO-97),</booktitle>
<pages>661--664</pages>
<location>Montréal (Québec),</location>
<marker>Meunier, Biskri, Nault, Nyongwa, 1997</marker>
<rawString>Meunier, J.G., I. Biskri, G. Nault &amp; M. Nyongwa (1997), “ALADIN et le traitement connexionniste de l’analyse terminologique”, Actes de la Conf sur la Recherche d ’Informations Assistée par Ordinateur (RIAO-97), Montréal (Québec), Canada, 25-27 juillet 1997, 661-664.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Michel</author>
</authors>
<title>Diagnostic Evaluation of a Personalized Filtering Information Retrieval System: Methodology and Experimental Results”,</title>
<date>2000</date>
<booktitle>Actes de la Conf sur la Recherche d ’Informations Assistée par Ordinateur (RIAO-2000),</booktitle>
<pages>1578--1588</pages>
<location>Paris,</location>
<contexts>
<context position="5355" citStr="Michel (2000)" startWordPosition="741" endWordPosition="742">aborerons pas sur les travaux traitant des agents Web. Le lecteur intéressé pourra consulter les sites &lt;&lt; Agent—based Information Retrieval Resources» (http://www.cs.umbc.edu/~ian/agent—ir.htm1), &lt;&lt; UIWBC AgentWeb &gt;&gt; (http://www.csee.umbc.edu/agents) ou &lt;&lt; Web Information Retrieval &amp; Information Extraction» (http://www.mri.mq.edu.au/~einat/web_ir). Nous souhaitons focaliser sur les différents aspects de la personnalisation et les approches dont l’objectif est de rendre le logiciel adaptable aux besoins de chaque utilisateur et un aspect de la personnalisation est le filtrage de l’information. Michel (2000) propose un systeme permettant le filtrage de données en prenant en compte les caractéristiques personnelles des utilisateurs qui choisissent parmi huit processus de filtrage différents. Amati et al. (1997) présentent le systeme ProFile qui acquiert et met a jour un modele des intéréts des utilisateurs au moyen d’une interaction avec 1 Afin de simplifier la discussion, nous utilisons le terme document pour faire reference a n’importe quel groupement des donne&apos;es du Web qui est vu nomialement comme une unite’. Par exemple, cela peut étre une page Web, un document textuel, une image, un fichier </context>
</contexts>
<marker>Michel, 2000</marker>
<rawString>Michel, C. (2000), “Diagnostic Evaluation of a Personalized Filtering Information Retrieval System: Methodology and Experimental Results”, Actes de la Conf sur la Recherche d ’Informations Assistée par Ordinateur (RIAO-2000), Paris, France, 12-14 avril 2000, 1578-1588.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
</authors>
<title>Automatic Text Processing .&apos; Ihe Transformation, Analysis and Retrieval of Information by Computer,</title>
<date>1989</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="4555" citStr="Salton (1989)" startWordPosition="644" endWordPosition="645">s (TLN). Ces outils permettent d’identifier les intersections entre les concepts de l’utilisateur et ceux présents sur le Web. L’évaluation et l’interprétation des documents étant tres personnelle, l’utilisateur doit prendre une part active dans ce processus. Notre travail peut étre associé aux recherches liées a la personnalisation du Web ainsi qu’aux travaux utilisant les traitements des langues naturelles (TLN). Nous résumons quelques travaux similaires dans la section suivante. 2 Travaux similaires Cette section ne traitera pas des travaux classiques sur la recherche documentaire tels que Salton (1989), ni des produits commerciaux déja disponibles sur le marché (pour des exemples de logiciels de recherche documentaire, voir http: //www.dwinfocenter.org/docum.html). Egalement, nous n’élaborerons pas sur les travaux traitant des agents Web. Le lecteur intéressé pourra consulter les sites &lt;&lt; Agent—based Information Retrieval Resources» (http://www.cs.umbc.edu/~ian/agent—ir.htm1), &lt;&lt; UIWBC AgentWeb &gt;&gt; (http://www.csee.umbc.edu/agents) ou &lt;&lt; Web Information Retrieval &amp; Information Extraction» (http://www.mri.mq.edu.au/~einat/web_ir). Nous souhaitons focaliser sur les différents aspects de la per</context>
</contexts>
<marker>Salton, 1989</marker>
<rawString>Salton, G. (1989), Automatic Text Processing .&apos; Ihe Transformation, Analysis and Retrieval of Information by Computer, Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Turenne</author>
</authors>
<title>Apprentissage statistique pour l ’extraction de concepts a partir de textes (Application au ﬁltrage d’informations textuelles), these de doctorat en inforrnatique, Université Louis-Pasteur,</title>
<date>2000</date>
<location>Strasbourg, France.</location>
<contexts>
<context position="9662" citStr="Turenne (2000)" startWordPosition="1390" endWordPosition="1391">Figure 1). Dans le cadre de ce projet, nous considérons que chaque site Web représente un segment textuel. Ainsi, un ensemble de sites Web forme un ensemble de segments textuels composant ainsi un corpus ou chaque segment conserve son identité et sa source. Nous soumettons alors ce corpus a un classiﬁcateur numérique (l\/Ieunier et al., 1997 ; Rialle et al., 1998 ; Biskri &amp; Delisle, 1999) permettant l’identiﬁcation des segments partageant des régularités lexicales. Toutefois, nous demeurons ouvert a l’utilisation de classificateurs autres que ceux cités — sur les classiﬁcateurs textuels, Voir Turenne (2000). Les classes produites par le classiﬁcateur Vont tendre a contenir des segments de sujets similaires et Vont identiﬁer les unités lexicales qui ont tendance a étre associées a ces sujets. Les résultats du classiﬁcateur numérique Vont fournir une liste de termes candidats en relation avec ceux de la requéte initiale. Cela permet de foumir une assistance dans la formulation d’une nouvelle requéte plus précise. Mohamed Yassine El Amrani ‘ Prefi1sde1’usager ||Le‘WWW :4 IL Requete initiale ‘V Liste GWUPB [13 m&apos;3&apos;t&apos;3U-1&apos;5 513 dfaclresses de _ recherche du Web F pages web Classiﬁcateur U i mméﬂque i</context>
</contexts>
<marker>Turenne, 2000</marker>
<rawString>Turenne, N. (2000), Apprentissage statistique pour l ’extraction de concepts a partir de textes (Application au ﬁltrage d’informations textuelles), these de doctorat en inforrnatique, Université Louis-Pasteur, Strasbourg, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rialle</author>
<author>J G Meunier</author>
<author>S Oussedik</author>
<author>I Biskri</author>
<author>G Nault</author>
</authors>
<title>Application de l’algorithmique génétique a l’analyse terminologique”,</title>
<date>1998</date>
<booktitle>Acte du Colloque international JADT98,</booktitle>
<location>Nice, France</location>
<contexts>
<context position="9413" citStr="Rialle et al., 1998" startWordPosition="1355" endWordPosition="1358">sta, etc. Cette requéte devrait englober l’information que l’utilisateur espere trouver sur le Web. Par la suite, l’utilisateur aura l’opportunité de reconsidérer sa requéte a la lumiere des résultats de recherche obtenus grace a cette requéte initiale (Figure 1). Dans le cadre de ce projet, nous considérons que chaque site Web représente un segment textuel. Ainsi, un ensemble de sites Web forme un ensemble de segments textuels composant ainsi un corpus ou chaque segment conserve son identité et sa source. Nous soumettons alors ce corpus a un classiﬁcateur numérique (l\/Ieunier et al., 1997 ; Rialle et al., 1998 ; Biskri &amp; Delisle, 1999) permettant l’identiﬁcation des segments partageant des régularités lexicales. Toutefois, nous demeurons ouvert a l’utilisation de classificateurs autres que ceux cités — sur les classiﬁcateurs textuels, Voir Turenne (2000). Les classes produites par le classiﬁcateur Vont tendre a contenir des segments de sujets similaires et Vont identiﬁer les unités lexicales qui ont tendance a étre associées a ces sujets. Les résultats du classiﬁcateur numérique Vont fournir une liste de termes candidats en relation avec ceux de la requéte initiale. Cela permet de foumir une assist</context>
</contexts>
<marker>Rialle, Meunier, Oussedik, Biskri, Nault, 1998</marker>
<rawString>Rialle V., Meunier, J.G., Oussedik, S., Biskri, I., Nault, G. (1998), “Application de l’algorithmique génétique a l’analyse terminologique”, Acte du Colloque international JADT98, Nice, France</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>