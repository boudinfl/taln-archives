<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique : pr&#233;sentation et premiers r&#233;sultats sur les cooccurrences</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#201;CITAL 2002, Nancy, 24-27 juin 2002 
</p>
<p>Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique : 
pr&#233;sentation et premiers r&#233;sultats sur les cooccurrences 
</p>
<p>Laurent AUDIBERT 
</p>
<p>Jeune &#233;quipe DELIC &#8211; Universit&#233; de Provence 
29 Avenue Robert SCHUMAN 
</p>
<p>13621 Aix-en-Provence Cedex 1 
laurent.audibert@up.univ-aix.fr  
</p>
<p>Mots-clefs &#8211; Keywords 
</p>
<p>D&#233;sambigu&#239;sation s&#233;mantique, corpus s&#233;mantiquement &#233;tiquet&#233;, cooccurrences. 
</p>
<p>Word sense disambiguation, sense tagged corpora, cooccurrences. 
</p>
<p>R&#233;sum&#233; &#8211; Abstract 
</p>
<p>Nous pr&#233;sentons dans cet article les d&#233;buts d&#8217;un travail visant &#224; rechercher et &#224; &#233;tudier 
syst&#233;matiquement les crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique. Cette &#233;tude 
utilise un corpus fran&#231;ais &#233;tiquet&#233; s&#233;mantiquement dans le cadre du projet SyntSem. Le 
crit&#232;re ici &#233;tudi&#233; est celui des cooccurrences. Nous pr&#233;sentons une s&#233;rie de r&#233;sultats sur le 
pouvoir d&#233;sambigu&#239;sateur des cooccurrences en fonction de leur cat&#233;gorie grammaticale et de 
leur &#233;loignement du mot &#224; d&#233;sambigu&#239;ser. 
</p>
<p>This paper describes the beginning of a study which aims at researching and systematically 
analysing criteria for automatic word sense disambiguation. This study uses a French sense 
tagged corpus developed in the SyntSem project. We analyse here the cooccurrence criterion 
and report a series of results on the disambiguative power of cooccurrences with respect to 
their grammatical category and distance from the word to be disambiguated.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L. AUDIBERT 
</p>
<p>1 Introduction 
</p>
<p>La d&#233;sambigu&#239;sation automatique est un enjeu important dans la plupart des applications de 
traitement automatique des langues (T.A.L.). On peut citer comme exemple les applications 
de recherche d&#8217;information, de traduction, de reconnaissance de la parole, de reconnaissance 
des caract&#232;res, de restauration de l&#8217;accentuation, etc. (cf. Ide &amp; V&#233;ronis, 1998) 
</p>
<p>Bien que la d&#233;sambigu&#239;sation du sens des mots soit un th&#232;me de recherche important depuis 
l'origine du T.A.L., les ressources n&#233;cessaires pour aborder correctement le probl&#232;me 
commencent &#224; peine &#224; &#234;tre disponibles. Ceci est particuli&#232;rement vrai pour le fran&#231;ais, langue 
pour laquelle on commence &#224; disposer d'outils informatiques efficaces d&#8217;annotation 
(lemmatisation1, &#233;tiquetage morpho-syntaxique, dictionnaire de synonymes2, relation 
syntaxique simple entre les mots, etc.). Il existe &#233;galement des applications puissantes et 
&#233;volutives qui permettent d'&#233;crire des requ&#234;tes complexes sur des corpus &#233;tiquet&#233;s (Intex voir 
[Silberztein, 2000], (Win/Dos)LoX3, IMS Corpus Workbench, etc.). Enfin un corpus fran&#231;ais 
d&#233;sambigu&#239;s&#233;, de taille exploitable, est en cours de constitution (Projet SyntSem4). 
</p>
<p>2 Mat&#233;riaux de l&#8217;&#233;tude 
</p>
<p>La premi&#232;re phase de notre travail fut l'&#233;tiquetage de notre corpus avec le logiciel Cordial 
Analyseur5, qui offre une lemmatisation et un &#233;tiquetage morpho-syntaxique d&#8217;une exactitude 
satisfaisante (Valli, V&#233;ronis, 1999). D&#8217;autres informations (hyperonymes, relations 
syntaxiques, classes d&#8217;objets &#8230;) seront ult&#233;rieurement apport&#233;es en fonction des besoins du 
crit&#232;re de d&#233;sambigu&#239;sation &#233;tudi&#233;. 
</p>
<p>L&#8217;une des difficult&#233;s majeures de l&#8217;&#233;tiquetage s&#233;mantique automatique r&#233;side dans 
l&#8217;inad&#233;quation des dictionnaires traditionnels (V&#233;ronis, 2001) ou d&#233;di&#233;s (Palmer, 1998) pour 
cette t&#226;che. Une autre difficult&#233; (Gale, Church, Yarowsky, 1993) provient du manque de 
corpus s&#233;mantiquement &#233;tiquet&#233;s sur lesquels des m&#233;thodes d'apprentissage pourraient &#234;tre 
entra&#238;n&#233;es. Ce manque se transforme m&#234;me en absence totale pour une langue comme le 
fran&#231;ais : si quelques corpus s&#233;mantiquement &#233;tiquet&#233;s commencent &#224; appara&#238;tre pour 
                                                 
1  Selon Y. Choueka, S. Lusignan. (1985), Disambiguation by short contexts, Actes de Computer and the 
</p>
<p>Humanities, pp.147-158., il n&#8217;existait, en 1985, aucun outil efficace de lemmatisation automatique. 
</p>
<p>2  Nous travaillons en collaboration avec J.L. Manguin du CRISCO (CNRS Caen) qui nous fournit un 
dictionnaire de synonymes, voir J. Francois, B. Victorri, J.-L. Manguin. (1999), Polys&#233;mie adjectivale et 
synonymie, Actes de Colloque POLYSEMIE, . 
</p>
<p>3  D&#233;velopp&#233;s au sein de l&#8217;&#233;quipe DELIC &#224; l&#8217;Universit&#233; de Provence, WinLoX et DosLoX sont disponibles sur 
le site http://laurent.audibert.free.fr/lox.htm, voir &#233;galement l&#8217;article L. Audibert. (2001), LoX  : outil 
polyvalent pour l'exploration de corpus annot&#233;s, Actes de RECITAL (TALN) 2001, pp.411-419.. 
</p>
<p>4  Le projet SyntSem, financ&#233; par l&#8217;ELRA/ELDA, vise &#224; produire un corpus &#233;tiquet&#233; au niveau morpho-
syntaxique avec en plus un marquage syntaxique peu profond et un marquage s&#233;mantique de mots 
s&#233;lectionn&#233;s. 
</p>
<p>5  Cordial 7 Analyseur est d&#233;velopp&#233; par la soci&#233;t&#233; Synapse D&#233;veloppement (http://www.synapse-fr.com/). </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique 
</p>
<p>l'anglais, notamment dans le cadre de l'action d'&#233;valuation Senseval, cf. (Kilgarriff, 1998), ils 
sont pour l'instant inexistants pour le fran&#231;ais. 
</p>
<p>Pour ces multiples raisons, Delphine Reymond, avec qui nous travaillons en collaboration, a 
entrepris la construction d&#8217;un dictionnaire distributionnel en se basant sur un ensemble de 
crit&#232;res diff&#233;rentiels stricts (Reymond, 2002). Ce dictionnaire comporte pour l'instant la 
description d&#233;taill&#233;e de 20 noms communs, 20 verbes et 20 adjectifs. Il lui a permis 
d&#8217;&#233;tiqueter manuellement chacune des 53000 occurrences de ces 60 vocables dans le corpus 
du projet SyntSem (Corpus d&#8217;environ 5.5 millions de mots, compos&#233; de textes de genres 
vari&#233;s). Ce corpus est une ressource de d&#233;part pour une &#233;tude approfondie des crit&#232;res de 
d&#233;sambigu&#239;sation s&#233;mantique automatique puisqu&#8217;il permet l'entra&#238;nement et l'&#233;valuation des 
algorithmes. 
</p>
<p>La derni&#232;re pi&#232;ce manquante &#233;tait un outil permettant de mod&#233;liser les crit&#232;res que l&#8217;on d&#233;sire 
&#233;tudier. Nous avons donc d&#233;velopp&#233; un tel outil, qui permet d&#8217;appliquer des requ&#234;tes 
complexes et vari&#233;es sur des corpus dont le format peut &#233;voluer (Audibert, 2001). Polyvalent, 
il a servi dans la phase d&#8217;&#233;tiquetage manuel des corpus. Il est &#233;galement utilis&#233; par de 
nombreux &#233;tudiants en TAL pour leurs travaux de recherche. Le grand pouvoir expressif de 
son langage de requ&#234;te permet d&#8217;exprimer les crit&#232;res dont on d&#233;sire conna&#238;tre le potentiel 
discriminant. Son m&#233;canisme d&#8217;abstraction de l&#8217;objet corpus nous permettra de le faire 
&#233;voluer facilement pour qu&#8217;il suive l&#8217;enrichissement de notre corpus ou l&#8217;adjonction d&#8217;autres 
sources d&#8217;information (dictionnaires par exemple). 
</p>
<p>20
 n
</p>
<p>om
s 
</p>
<p>barrage, chef, communication, 
compagnie, concentration, constitution, 
degr&#233;, d&#233;tention, &#233;conomie, 
formation, lancement, observation, 
organe, passage, pied, restauration, 
solution, station, suspension, vol. 
</p>
<p>20
 a
</p>
<p>dj
ec
</p>
<p>tif
s biologique, clair, correct, courant, 
</p>
<p>exceptionnel, frais, haut, historique, 
plein, populaire, r&#233;gulier, sain, 
secondaire, sensible, simple, strict, s&#251;r, 
traditionnel, utile, vaste. 
</p>
<p>20
 v
</p>
<p>er
be
</p>
<p>s arr&#234;ter, comprendre, conclure, conduire, 
conna&#238;tre, couvrir, entrer, exercer, 
importer, mettre, ouvrir, parvenir, 
passer, porter, poursuivre, pr&#233;senter, 
rendre, r&#233;pondre, tirer, venir. 
Tableau 1 : les 60 vocables de  
</p>
<p>l&#8217;&#233;tude compl&#232;te 
</p>
<p>Nom Sens D&#233;finition Nb. 
Co1 Association de personnes. 327 Compagnie
Co2 Pr&#233;sence de quelqu&#8217;un. 85 
De1 Incarc&#233;ration, enfermement. 81 D&#233;tention 
De2 Possession. 31 
Fo1 Instruction 1227
Fo2 Formation de qqch. 227 Formation 
Fo3 Groupement de personnes. 65 
Ob1 Surveillance, &#233;tude. 492 
Ob2 Remarques, r&#233;flexions. 66 Observation
Ob3 Conformation &#224;. 14 
Or1 Porte-parole d&#8217;un groupe. 182 
Or2 Partie d&#8217;un corps. 140 Organe 
Or3 Partie d&#8217;une machine. 44 
So1 D&#233;nouement, r&#233;ponse. 821 Solution 
So2 M&#233;lange liquide. 36 
Vo1 Abr&#233;viation de volume. 52 
Vo2 D&#233;lit. 65 Vol 
Vo3 D&#233;placement dans l&#8217;air. 146 
</p>
<p>Tableau 2 : les 7 vocables de l&#8217;&#233;tude pr&#233;liminaire 
</p>
<p>L&#8217;&#233;tude compl&#232;te portera sur l&#8217;ensemble des 60 vocables, &#233;num&#233;r&#233;s dans le Tableau 1. Ces 
vocables ont &#233;t&#233; s&#233;lectionn&#233;s pour l&#8217;importance de leur fr&#233;quence et pour leur caract&#232;re 
particuli&#232;rement polys&#233;mique. L&#8217;&#233;tude pr&#233;liminaire pr&#233;sent&#233;e dans cet article porte seulement 
sur 7 noms (en gras dans le Tableau 1), qui repr&#233;sentent 4101 occurrences au total dans le 
corpus SyntSem. Le Tableau 2 pr&#233;sente le nombre d&#8217;occurrences dans le corpus pour chacun 
des sens de ces 7 vocables. A ce stade de notre &#233;tude nous travaillons avec un niveau de sens </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L. AUDIBERT 
</p>
<p>grossier (2 &#224; 3 sens par vocable) que nous affinerons par la suite. Le nombre d&#8217;occurrences de 
certains sens peut parfois para&#238;tre faible, mais (Gale, et al., 1993) ont montr&#233; que tr&#232;s peu 
d&#8217;exemples (de l&#8217;ordre de 5) permettent d&#8217;obtenir de tr&#232;s bons r&#233;sultats, et qu&#8217;il &#233;tait rarement 
utile de d&#233;passer la cinquantaine d&#8217;exemples. Il semblerait que ce ne soit pas tant le nombre 
d&#8217;exemples que leur diversit&#233; qui compte. 
</p>
<p>3 Crit&#232;res 
</p>
<p>Il existe de nombreuses sources d&#8217;information pour lever l&#8217;ambigu&#239;t&#233; du sens des mots. 
Comme l&#8217;ont montr&#233; (McRoy, 1992), (Wilks, Stevenson, 1998) ou encore (Ng, Lee, 1996) 
toutes ces sources peuvent &#234;tre utilis&#233;es simultan&#233;ment pour aboutir &#224; une meilleure 
d&#233;sambigu&#239;sation. Dans cette section nous dressons une liste (non restrictive) des crit&#232;res de 
d&#233;sambigu&#239;sation s&#233;mantique automatique que nous projetons d&#8217;&#233;tudier. 
</p>
<p>De nombreuses &#233;tudes montrent que les cooccurrences6 constituent un bon crit&#232;re pour 
identifier le sens d&#8217;un mot. Mais que doit-on regarder : la forme fl&#233;chie du mot ou son 
lemme ; faut-il ne consid&#233;rer que les mots pleins ou bien consid&#233;rer aussi les mots 
grammaticaux ? O&#249; doit-on regarder : jusqu'&#224; quelle distance les cooccurrences apportent-
elles de l&#8217;information ; est-il pertinent de sortir du contexte de la phrase ; doit-on diff&#233;rencier 
le contexte droit du contexte gauche ? 
</p>
<p>Des cooccurrences cibl&#233;es par des relations syntaxiques telles que les relations sujet-verbe, 
verbe-objet, adjectif-nom, nom-adjectif, nom-nom peuvent &#234;tre plus pertinentes que des 
cooccurrences prises au hasard. Aussi est-il certainement important d'accorder une attention 
particuli&#232;re &#224; ces cooccurrences, comme l&#8217;a fait (Yarowsky, 1993). 
</p>
<p>Les &#233;tiquettes morpho-syntaxiques des mots qui entourent le mot dont on cherche &#224; identifier 
le sens sont souvent un bon crit&#232;re de d&#233;sambigu&#239;sation. Il faudrait donc en tenir compte. 
Mais une question se pose : quelle est la meilleure granularit&#233; des &#233;tiquettes morpho-
syntaxiques ? Serait-il judicieux de travailler simultan&#233;ment sur plusieurs niveaux de 
granularit&#233; ? 
</p>
<p>Selon (Gross, Clas, 1997) les traits syntactico-s&#233;mantiques permettent une subdivision des 
noms en 8 sous-ensembles : humain, animal, v&#233;g&#233;tal, inanim&#233; concret, inanim&#233; abstrait, 
locatif, temps, &#233;v&#233;nement. Toujours selon (Gross, Clas, 1997), les classes d&#8217;objets permettent 
une sous-cat&#233;gorisation des traits. Par exemple, le terme autobus se voit attribuer le trait 
inanim&#233; concret et la &#171; classe d&#8217;objets &#187; moyens de transports routiers en commun. Conna&#238;tre 
le trait ou la classe d&#8217;objets des mots environnant le mot &#224; d&#233;sambigu&#239;ser permet d&#8217;am&#233;liorer 
l&#8217;apprentissage sur des petits nombres d&#8217;exemples. Il serait int&#233;ressant de conna&#238;tre l&#8217;impact 
de tels regroupements sur la d&#233;sambigu&#239;sation. 
</p>
<p>D&#8217;autres crit&#232;res seront &#233;galement explor&#233;s. On peut citer, par exemple, les synonymes des 
mots en cooccurrence, les n-grammes (qui peuvent &#234;tre constitu&#233;s de mots, de lemmes, ou 
encore d&#8217;&#233;tiquettes morpho-syntaxiques), les informations sur le domaine (le th&#232;me) du texte 
dans lequel on cherche &#224; d&#233;sambigu&#239;ser un mot donn&#233;, etc. 
                                                 
6  Nous emploierons, dans cet article, le mot &#171; cooccurrence &#187; dans son acception la plus large, d&#233;nu&#233;e des 
</p>
<p>notions de fr&#233;quence, de figement, de lien syntaxique ou encore de proximit&#233;. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique 
</p>
<p>4 Mise en &#339;uvre de crit&#232;res sur les cooccurrences 
</p>
<p>4.1 D&#233;finition d&#8217;un crit&#232;re 
</p>
<p>Tout d&#8217;abord, il faut trouver, puis &#233;noncer clairement un crit&#232;re susceptible d&#8217;&#234;tre pertinent 
pour la lev&#233;e de l&#8217;ambigu&#239;t&#233; s&#233;mantique. Ce crit&#232;re doit pouvoir &#234;tre mis en &#339;uvre dans la 
perspective d&#8217;un &#233;tiquetage automatique. Les crit&#232;res les plus appropri&#233;s pour l&#8217;&#233;tiquetage 
automatique ne peuvent pas &#234;tre directement calqu&#233;s sur les crit&#232;res diff&#233;rentiels pr&#233;sent&#233;s 
dans (Reymond, 2002) destin&#233;s &#224; un &#233;tiquetage s&#233;mantique manuel. En effet, les crit&#232;res 
diff&#233;rentiels sont souvent difficiles &#224; mettre en &#339;uvre car ils font intervenir le jugement du 
linguiste. De plus, les crit&#232;res qui font intervenir des classes d&#8217;objets, ou des informations 
syntaxiques, imposent de disposer de ces informations. Or, si la lemmatisation ou l&#8217;&#233;tiquetage 
morpho-syntaxique sont des techniques qui commencent &#224; arriver &#224; maturit&#233;, l&#8217;appartenance &#224; 
une classe d&#8217;objets et l&#8217;&#233;tiquetage syntaxique sont encore du domaine de la recherche. A 
l&#8217;inverse, la puissance de calcul des ordinateurs permet d&#8217;utiliser des crit&#232;res qui seraient 
difficiles &#224; mettre en &#339;uvre manuellement.  
</p>
<p>Voici un exemple de crit&#232;re :  
</p>
<p>lemme des trois noms, adjectifs, verbes ou adverbes qui suivent le mot d&#233;tention 
sans sortir de la phrase. 
</p>
<p>Il faut ensuite &#233;crire une r&#232;gle qui mod&#233;lise notre crit&#232;re. Une r&#232;gle est compos&#233;e d&#8217;une 
requ&#234;te, par exemple 
</p>
<p>[lemme=&quot;d&#233;tention&quot;] []{0,2} coo:[ems~&quot;(^NC|^ADV|^V|^ADJ)&quot;] 
stop(ems=&quot;PCTFORTE&quot;), 
</p>
<p>qui permet de formaliser le crit&#232;re, et d&#8217;un masque, par exemple : 
</p>
<p>[P:coo.lemme], 
qui permet de sp&#233;cifier comment seront format&#233;s les r&#233;sultats de la 
requ&#234;te. Ces requ&#234;tes sont bas&#233;es sur des m&#233;ta-expressions 
r&#233;guli&#232;res (i.e. qui se situent au niveau des mots) et permettent de 
d&#233;crire de mani&#232;re formelle des classes de suites de mots, donc des 
portions de texte. La syntaxe des requ&#234;tes et des masques, a &#233;t&#233; 
pr&#233;sent&#233;e dans (Audibert, 2001). 
</p>
<p>indices De1 De2
arme 0 19
</p>
<p>contr&#244;le 0 11
provisoire 10 0 
acquisition 0 9 
condition 8 1 
pr&#233;ventif 9 0 
</p>
<p>faire 6 0 
munition 0 5 
</p>
<p>camp 5 0 
dur&#233;e 5 0 
</p>
<p>politique 5 0 
prisonnier 5 0 
</p>
<p>torture 5 0 
r&#233;gime 0 4 
abusif 4 0 
</p>
<p>maintenir 4 0 
mettre 4 0 
</p>
<p>placement 4 0 
Tableau 3 
</p>
<p>4.2 Application du crit&#232;re 
</p>
<p>Les logiciels WinLoX et DosLoX permettent d&#8217;appliquer chaque 
r&#232;gle au corpus et de d&#233;nombrer les cha&#238;nes (nous appellerons ces 
cha&#238;nes des indices) g&#233;n&#233;r&#233;es par le masque de la r&#232;gle en fonction 
du sens du mot cible. On peut ainsi se faire une premi&#232;re id&#233;e de la 
pertinence du crit&#232;re. Dans le Tableau 3 sont d&#233;nombr&#233;s des indices 
g&#233;n&#233;r&#233;s par l&#8217;application du crit&#232;re &#171; lemme des trois mots pleins 
(noms, adjectifs, verbes ou adverbes) qui suivent ou qui pr&#233;c&#232;dent le 
mot cible sans sortir de la phrase &#187; en fonction du sens &#171; De1 &#187; 
(incarc&#233;ration, enfermement) ou &#171; De2 &#187; (possession) de d&#233;tention. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L. AUDIBERT 
</p>
<p>4.3 &#201;valuation du crit&#232;re indices De1 De2
arme 0 18
</p>
<p>munition 0 4 
condition 8 0 
proc&#233;dure 2 0 
</p>
<p>&#234;tre 11 8 
Tableau 4 
</p>
<p>Nous &#233;valuons le crit&#232;re en utilisant une m&#233;thode d&#8217;&#233;valuation 
crois&#233;e (de type &#171; leave-one-out &#187;). Pour chacune des occurrences 
du mot &#233;tudi&#233; on r&#233;alise un apprentissage (une application du 
crit&#232;re) sur toutes les autres occurrences. Puis on &#233;tiquette 
l&#8217;occurrence en question et on v&#233;rifie la pertinence de l&#8217;&#233;tiquetage 
sur cette occurrence. 
</p>
<p>L&#8217;application de la r&#232;gle &#224; l&#8217;occurrence que l&#8217;on d&#233;sire &#233;tiqueter g&#233;n&#232;re une liste d&#8217;indices. 
Nous cherchons ceux qui se trouvent dans le tableau d&#8217;apprentissage pour g&#233;n&#233;rer un sous-
tableau similaire au Tableau 4. On recherche ensuite, dans ce tableau, l&#8217;indice dont la 
dispersion est la plus faible et on &#233;tiquette selon le sens le plus probable pour cet indice. Si 
aucun indice ne se trouve dans ce sous-tableau, on &#233;tiquette avec le sens le plus fr&#233;quent. 
</p>
<p>La mesure de dispersion utilise une fonction de la variance comprise entre 0 et 1 qui traduit la 
dispersion des donn&#233;es7. Plus la mesure dispersion est proche de 0, plus la dispersion des 
donn&#233;es est grande. Notre strat&#233;gie d&#8217;&#233;tiquetage ne combine pas les indices mais se focalise 
sur le plus fiable, d&#233;sign&#233; par le plus faible indice de dispersion. Cette strat&#233;gie, bas&#233;e sur une 
liste de d&#233;cision, est fort simple &#224; mettre en &#339;uvre et permet de s&#8217;affranchir de la condition 
d&#8217;ind&#233;pendance des indices. Nous comptons cependant &#233;valuer d&#8217;autres strat&#233;gies comme, par 
exemple, la quantit&#233; d&#8217;information pond&#233;r&#233;e ou les arbres de classification s&#233;mantique 
pr&#233;sent&#233;s dans (Loupy, El-B&#232;ze, Marteau, 1998). 
</p>
<p>5 Premiers r&#233;sultats sur les cooccurrences 
</p>
<p>Nous appellerons pr&#233;cision le rapport entre le nombre d&#8217;&#233;tiquetages corrects et le nombre 
d&#8217;&#233;tiquetages effectu&#233;s : 
</p>
<p>Pr&#233;cision = (Nombre d&#8217;&#233;tiquetages corrects) / (Nombre d&#8217;&#233;tiquetages effectu&#233;s). 
</p>
<p>Nous appellerons pr&#233;cision de l&#8217;&#233;tiquetage na&#239;f (&#171; base line &#187; en anglais) la pr&#233;cision 
obtenue en &#233;tiquetant toutes les occurrences avec l&#8217;&#233;tiquette la plus fr&#233;quente dans le corpus. 
</p>
<p>Nous appellerons gain l&#8217;am&#233;lioration de la pr&#233;cision obtenue par rapport &#224; la pr&#233;cision d&#8217;un 
&#233;tiquetage na&#239;f : 
</p>
<p>Gain = ( Pr&#233;cision(&#233;tiq.) - Pr&#233;cision(&#233;tiq. na&#239;f) ) / ( 1 - Pr&#233;cision(&#233;tiq. na&#239;f) ). 
</p>
<p>Le rappel sera :  
Rappel = (Nombre d&#8217;&#233;tiquetages corrects) / (Nombre d&#8217;occurrences &#224; &#233;tiqueter). 
</p>
<p>                                                 
</p>
<p>7  Mesure de dispersion : 
1
</p>
<p> variationde coef.
&#8722;&#8722; N1 . </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique 
</p>
<p>5.1 Que faut-il regarder ? 
</p>
<p>Pour &#233;tudier quelles sont les cat&#233;gories grammaticales les plus utiles, nous avons observ&#233; le 
r&#233;sultat du crit&#232;re suivant : forme fl&#233;chie des n mots qui suivent ou qui pr&#233;c&#232;dent le mot cible. 
Nous avons fait varier la taille n du contexte et nous avons observ&#233; la cat&#233;gorie grammaticale 
du mot ayant servi &#224; la lev&#233;e de l&#8217;ambigu&#239;t&#233; (c'est-&#224;-dire le mot dont l&#8217;indice de dispersion 
&#233;tait le plus faible) pour nos 7 vocables. Les figures 1 et 2 montrent l&#8217;importance relative des 
cat&#233;gories grammaticales pour la d&#233;sambigu&#239;sation en fonction de la taille n de la fen&#234;tre. La 
Figure 1 montre la pr&#233;dominance que prennent les noms sur toutes les autres cat&#233;gories 
grammaticales quand la taille du contexte cro&#238;t : au-del&#224; d&#8217;un contexte de &#177;400 mots ils ont 
&#233;t&#233; s&#233;lectionn&#233;s pour la lev&#233;e de l&#8217;ambigu&#239;t&#233; dans plus de 80% des cas. On peut aussi 
remarquer que l&#8217;importance des adjectifs est &#224; peu pr&#232;s constante : ce sont eux qui ont permis 
la lev&#233;e de l&#8217;ambigu&#239;t&#233; dans 10 &#224; 20% des cas. Pour de petites fen&#234;tres (&#177;1 mot &#224; &#177;2 mots), la 
Figure 2 montre l&#8217;importance des mots grammaticaux, notamment des d&#233;terminants. 
</p>
<p> 
Figure 1 
</p>
<p> 
Figure 2 
</p>
<p>Faut-il regarder le lemme plut&#244;t que la forme fl&#233;chie ? Nos exp&#233;riences sur les 7 mots 
montrent que la lemmatisation n&#8217;apporte rien en terme de pr&#233;cision, mais permet une 
augmentation du rappel de l&#8217;ordre de 10% dans une fen&#234;tre de &#177;8 mots. La lemmatisation 
permet, en effet, de regrouper toutes les formes fl&#233;chies d&#8217;un mot, ce qui a pour effet de 
diminuer la dispersion des indices et d&#8217;am&#233;liorer l&#8217;apprentissage sur de petits effectifs, d&#8217;o&#249; 
une augmentation du rappel. Cette augmentation est cependant r&#233;duite &#224; n&#233;ant pour des 
fen&#234;tres de plus de &#177;30 mots. Pour de tels contextes, le nombre d&#8217;indices est suffisamment 
grand pour que l&#8217;apprentissage se fasse sur toutes les formes fl&#233;chies. D&#8217;autant plus que, 
comme nous venons de le voir, les grands contextes privil&#233;gient les noms qui ne poss&#232;dent 
que deux formes fl&#233;chies (singulier et pluriel). 
</p>
<p>5.2 O&#249; doit-on regarder ? 
</p>
<p>Faut-il accepter de sortir de la phrase ? Nous avons formul&#233; les deux crit&#232;res suivants : 
- lemme des n mots pleins qui suivent ou qui pr&#233;c&#232;dent le mot cible ; 
- lemme des n mots pleins qui suivent ou qui pr&#233;c&#232;dent le mot cible sans sortir de la phrase. 
</p>
<p>Dans le corpus Syntsem, les phrases ont en moyenne 12,2 mots pleins par phrase. Nous avons 
donc observ&#233; un contexte allant de &#177;1 mot plein &#224; &#177;10 mots pleins. La Figure 3 montre le gain 
et le rappel obtenu pour ces deux crit&#232;res en fonction de la taille de la fen&#234;tre n compt&#233; en </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L. AUDIBERT 
</p>
<p>nombre de mots pleins. La diff&#233;rence entre les 
deux crit&#232;res est sensible. En acceptant les 
cooccurrences en dehors de la phrase, on 
augmente le rappel d&#8217;environ 5%, mais on 
diminue la pr&#233;cision de 2% et le gain de plus de 
6%. 
</p>
<p>Ainsi, si l&#8217;on privil&#233;gie le rappel, il faut sortir de 
la phrase. Mais jusqu&#8217;&#224; quelle distance du mot &#224; 
d&#233;sambigu&#239;ser trouve-t-on de l&#8217;information ? 
Nous avons tent&#233; de d&#233;sambigu&#239;ser chacun de 
nos 7 vocables en regardant une fen&#234;tre de 5 
mots pleins situ&#233;e &#224; une distance de &#177;x mots de 
la cible. La courbe de la Figure 4 repr&#233;sente le 
gain obtenu en fonction de cette distance de x mots. Bien que nous ne travaillions ni sur la 
m&#234;me langue ni sur les m&#234;me corpus que (Gale, et al., 1993), nous obtenons un r&#233;sultat 
analogue : pour d&#233;sambigu&#239;ser un mot, on trouve de l&#8217;information dans un contexte s&#8217;&#233;tendant 
jusqu'&#224; &#177;10000 mots. 
</p>
<p>Figure 3 
</p>
<p>Figure 4 
</p>
<p>En r&#233;sum&#233;, pour l&#8217;ensemble de nos 7 vocables, la meilleure pr&#233;cision moyenne obtenue 
atteint 95% pour une taille de fen&#234;tre tr&#232;s petite, &#177;1 mot plein, sans sortir de la phrase. Mais 
en contre-partie, le rappel est assez faible, de l&#8217;ordre de 40%. Pour une taille de fen&#234;tre de 
&#177;30 mots pleins, en acceptant de sortir de la phrase, le rappel atteint 89% et toutes les 
occurrences ont &#233;t&#233; &#233;tiquet&#233;es, la pr&#233;cision est donc &#233;galement de 89%. 
</p>
<p>6 Perspectives et conclusion 
</p>
<p>Le travail pr&#233;sent&#233; dans cet article sera approfondi et &#233;tendu &#224; 60 mots r&#233;partis de mani&#232;re 
&#233;gale dans trois classes grammaticales : les noms communs, les verbes et les adjectifs. Il sera 
ensuite compl&#233;t&#233; par l&#8217;&#233;tude d&#8217;autres crit&#232;res de d&#233;sambigu&#239;sation. A l&#8217;issue de cette &#233;tude, 
les crit&#232;res retenus seront utilis&#233;s conjointement pour aboutir &#224; une d&#233;sambigu&#239;sation 
automatique plus efficace et plus robuste. Notre m&#233;thode d&#8217;&#233;tiquetage conviendrait &#233;galement 
&#224; un &#233;tiquetage incr&#233;mental de gros corpus dans une perspective d&#8217;&#233;tiquetage semi-
automatique. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique 
</p>
<p>On peut remarquer que, parmi les travaux similaires d&#233;j&#224; r&#233;alis&#233;s, tr&#232;s peu l&#8217;ont &#233;t&#233; sur des 
corpus manuellement &#233;tiquet&#233;s en raison de leur raret&#233;. Pour pallier ce probl&#232;me, les 
chercheurs ont souvent us&#233; de subterfuges pour &#233;valuer leurs algorithmes. Certains fusionnent 
deux mots quelconques en un seul en gardant l&#8217;information du mot d&#8217;origine. Un raffinement 
de cette technique consiste &#224; ne pas choisir les deux mots au hasard mais &#224; en prendre deux 
qui sont homographes dans une autre langue ou encore qui ne se distinguent que par une seule 
lettre, cf. (Yarowsky, 1993) par exemple. Ces techniques permettent de r&#233;aliser des 
apprentissages supervis&#233;s sur des corpus de grande taille sans avoir &#224; les &#233;tiqueter 
manuellement. Cependant, il est clair que les contextes de tels mots sont tr&#232;s distincts, ce qui 
facilite leur d&#233;sambigu&#239;sation et biaise les r&#233;sultats. Notre &#233;tude porte sur de &#171; vrais &#187; mots et 
s&#8217;appuie sur un corpus de taille suffisante manuellement &#233;tiquet&#233;. 
</p>
<p>On peut &#233;galement remarquer que l&#8217;une des difficult&#233;s de l&#8217;&#233;tiquetage s&#233;mantique 
automatique r&#233;side dans l&#8217;inad&#233;quation des dictionnaires traditionnels. Pour cette raison, notre 
corpus a &#233;t&#233; &#233;tiquet&#233; en utilisant les d&#233;finitions d&#8217;un dictionnaire distributionnel &#233;tabli sur un 
ensemble de crit&#232;res diff&#233;rentiels stricts. 
</p>
<p>Cette &#233;tude pr&#233;liminaire a port&#233; sur les 7 noms communs suivants : compagnie, d&#233;tention, 
formation, observation, organe, solution, vol. Le nombre de sens est de 2.6 en moyenne pour 
ces 7 mots. Les premiers r&#233;sultats obtenus sont encourageants. La pr&#233;cision moyenne obtenue 
atteint 95% pour une taille de fen&#234;tre tr&#232;s petite au d&#233;triment d&#8217;un rappel assez faible. En 
&#233;tiquetant tous les mots la pr&#233;cision moyenne atteint 89% pour une taille de fen&#234;tre de 30 
mots. Ces r&#233;sultats sont comparables &#224; ceux obtenus par d&#8217;autres &#233;quipes sur des corpus en 
langue anglaise. 
</p>
<p>7 R&#233;f&#233;rences 
</p>
<p>L. Audibert. (2001), LoX  : outil polyvalent pour l'exploration de corpus annot&#233;s, Actes de 
RECITAL (TALN) 2001, pp.411-419. 
</p>
<p>Y. Choueka, S. Lusignan. (1985), Disambiguation by short contexts, Actes de Computer and 
the Humanities, pp.147-158. 
</p>
<p>J. Francois, B. Victorri, J.-L. Manguin. (1999), Polys&#233;mie adjectivale et synonymie, Actes de 
Colloque POLYSEMIE. 
</p>
<p>W. A. Gale, K. W. Church, D. Yarowsky. (1993), A method for disambiguating word senses 
in a large corpus, Actes de Computers and the Humanities, pp.415-439. 
</p>
<p>G. Gross, A. Clas. (1997), Synonymie, Polys&#233;mie et Classes D'objets, Meta, Presses de 
l'Universit&#233; de Montr&#233;al, pp.147-155. 
</p>
<p>N. Ide, J. V&#233;ronis. (1998), Word sense disambiguation : the state of the art, Special Issue on 
Word Sense Disambiguation, Presses de l'Universit&#233; de Montr&#233;al, pp.1-40. 
</p>
<p>A. Kilgarriff. (1998), SENSEVAL : an exercise in evaluating word sense disambiguation 
programs, Actes de EURALEX-98, pp.176-174. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L. AUDIBERT 
</p>
<p>C. d. Loupy, M. El-B&#232;ze, P.-F. Marteau. (1998), WSD Based on Three Short Context 
Methods, Actes de SENSEVAL Workshop. 
</p>
<p>S. McRoy. (1992), Using multiple knowledge sources for word sense discrimination, Actes de 
Computational Linguistics, pp.1-30. 
</p>
<p>H. T. Ng, H. B. Lee. (1996), Integrating multiple knowledge sources to disambiguate word 
sense : an exemplar-based approach, Actes de 34th Annual Meeting of the Society for 
Computational Linguistics, pp.40-47. 
</p>
<p>M. Palmer. (1998), Are WordNet sense distinctions appropriate for computational lexicons ?, 
Actes de SIGLEX-98, SENSEVAL. 
</p>
<p>D. Reymond. (2002), M&#233;thodologie pour la cr&#233;ation d'un dictionnaire distributionnel dans une 
perspective d'&#233;tiquetage lexical semi-automatique, Actes de RECITAL (TALN) 2002. 
</p>
<p>M. Silberztein. (2000), INTEX, Association pour le traitement informatique des langues 
(ASSTRIL), http://ladl.univ-mlv.fr/INTEX/information.html. 
</p>
<p>A. Valli, J. V&#233;ronis. (1999), Etiquetage grammatical de corpus oraux : probl&#232;mes et 
perpectives, Revue Fran&#231;aise de Linguistique Appliqu&#233;e, Association pour le traitement 
informatique des langues (ASSTRIL), pp.113-133. 
</p>
<p>J. V&#233;ronis. (2001), Sense tagging : does it makes sense ?, Actes de Corpus Linguistics'2001, 
pp.in press. 
</p>
<p>Y. Wilks, M. Stevenson. (1998), Word sense disembiguation using optimised combinations of 
knowledge sources, Actes de COLING-ACL98. 
</p>
<p>D. Yarowsky. (1993), One sense per collocation, Actes de ARPA Human Language 
Technology Workshop, pp.266-271. </p>

</div></div>
</body></html>