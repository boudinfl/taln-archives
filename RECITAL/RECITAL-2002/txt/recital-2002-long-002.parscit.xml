<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Audibert</author>
</authors>
<title>LoX : outil polyvalent pour l&apos;exploration de corpus annotés, Actes de RECITAL (TALN)</title>
<date>2001</date>
<pages>411--419</pages>
<contexts>
<context position="5798" citStr="Audibert, 2001" startWordPosition="794" endWordPosition="795">ellement chacune des 53000 occurrences de ces 60 vocables dans le corpus du projet SyntSem (Corpus d’environ 5.5 millions de mots, composé de textes de genres variés). Ce corpus est une ressource de départ pour une étude approfondie des critères de désambiguïsation sémantique automatique puisqu’il permet l&apos;entraînement et l&apos;évaluation des algorithmes. La dernière pièce manquante était un outil permettant de modéliser les critères que l’on désire étudier. Nous avons donc développé un tel outil, qui permet d’appliquer des requêtes complexes et variées sur des corpus dont le format peut évoluer (Audibert, 2001). Polyvalent, il a servi dans la phase d’étiquetage manuel des corpus. Il est également utilisé par de nombreux étudiants en TAL pour leurs travaux de recherche. Le grand pouvoir expressif de son langage de requête permet d’exprimer les critères dont on désire connaître le potentiel discriminant. Son mécanisme d’abstraction de l’objet corpus nous permettra de le faire évoluer facilement pour qu’il suive l’enrichissement de notre corpus ou l’adjonction d’autres sources d’information (dictionnaires par exemple). barrage, chef, communication, Nom Sens Définition Nb. compagnie, concentration, cons</context>
<context position="13449" citStr="Audibert, 2001" startWordPosition="1916" endWordPosition="1917">composée d’une requête, par exemple [lemme=&amp;quot;détention&amp;quot;] []{0,2} coo:[ems~&amp;quot;(^NC|^ADV|^V|^ADJ)&amp;quot;] stop(ems=&amp;quot;PCTFORTE&amp;quot;), qui permet de formaliser le critère, et d’un masque, par exemple : [P:coo.lemme], qui permet de spécifier comment seront formatés les résultats de la requête. Ces requêtes sont basées sur des méta-expressions indices De1 De2 régulières (i.e. qui se situent au niveau des mots) et permettent de arme 0 19 décrire de manière formelle des classes de suites de mots, donc des contrôle 0 11 portions de texte. La syntaxe des requêtes et des masques, a été provisoire 10 0 présentée dans (Audibert, 2001). acquisition 0 9 condition 8 1 préventif 9 0 4.2 Application du critère faire 6 0 munition 0 5 Les logiciels WinLoX et DosLoX permettent d’appliquer chaque camp 5 0 règle au corpus et de dénombrer les chaînes (nous appellerons ces durée 5 0 chaînes des indices) générées par le masque de la règle en fonction politique 5 0 du sens du mot cible. On peut ainsi se faire une première idée de la prisonnier 5 0 pertinence du critère. Dans le Tableau 3 sont dénombrés des indices torture 5 0 générés par l’application du critère « lemme des trois mots pleins régime 0 4 (noms, adjectifs, verbes ou adverb</context>
</contexts>
<marker>Audibert, 2001</marker>
<rawString>L. Audibert. (2001), LoX : outil polyvalent pour l&apos;exploration de corpus annotés, Actes de RECITAL (TALN) 2001, pp.411-419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choueka</author>
<author>S Lusignan</author>
</authors>
<title>Disambiguation by short contexts,</title>
<date>1985</date>
<booktitle>Actes de Computer and the Humanities,</booktitle>
<pages>147--158</pages>
<marker>Choueka, Lusignan, 1985</marker>
<rawString>Y. Choueka, S. Lusignan. (1985), Disambiguation by short contexts, Actes de Computer and the Humanities, pp.147-158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Francois</author>
<author>B Victorri</author>
<author>J-L Manguin</author>
</authors>
<title>Polysémie adjectivale et synonymie, Actes de Colloque POLYSEMIE.</title>
<date>1999</date>
<marker>Francois, Victorri, Manguin, 1999</marker>
<rawString>J. Francois, B. Victorri, J.-L. Manguin. (1999), Polysémie adjectivale et synonymie, Actes de Colloque POLYSEMIE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Gale</author>
<author>K W Church</author>
<author>D Yarowsky</author>
</authors>
<title>A method for disambiguating word senses in a large corpus,</title>
<date>1993</date>
<booktitle>Actes de Computers and the Humanities,</booktitle>
<pages>415--439</pages>
<contexts>
<context position="8323" citStr="Gale, et al., 1993" startWordPosition="1156" endWordPosition="1159">ce de leur fréquence et pour leur caractère particulièrement polysémique. L’étude préliminaire présentée dans cet article porte seulement sur 7 noms (en gras dans le Tableau 1), qui représentent 4101 occurrences au total dans le corpus SyntSem. Le Tableau 2 présente le nombre d’occurrences dans le corpus pour chacun des sens de ces 7 vocables. A ce stade de notre étude nous travaillons avec un niveau de sens 20 verbes 20 adjectifs 20 noms L. AUDIBERT grossier (2 à 3 sens par vocable) que nous affinerons par la suite. Le nombre d’occurrences de certains sens peut parfois paraître faible, mais (Gale, et al., 1993) ont montré que très peu d’exemples (de l’ordre de 5) permettent d’obtenir de très bons résultats, et qu’il était rarement utile de dépasser la cinquantaine d’exemples. Il semblerait que ce ne soit pas tant le nombre d’exemples que leur diversité qui compte. 3 Critères Il existe de nombreuses sources d’information pour lever l’ambiguïté du sens des mots. Comme l’ont montré (McRoy, 1992), (Wilks, Stevenson, 1998) ou encore (Ng, Lee, 1996) toutes ces sources peuvent être utilisées simultanément pour aboutir à une meilleure désambiguïsation. Dans cette section nous dressons une liste (non restric</context>
<context position="20039" citStr="Gale, et al., 1993" startWordPosition="3034" endWordPosition="3037">s en dehors de la phrase, on augmente le rappel d’environ 5%, mais on diminue la précision de 2% et le gain de plus de 6%. Ainsi, si l’on privilégie le rappel, il faut sortir de la phrase. Mais jusqu’à quelle distance du mot à désambiguïser trouve-t-on de l’information ? Nous avons tenté de désambiguïser chacun de nos 7 vocables en regardant une fenêtre de 5 mots pleins située à une distance de ±x mots de Figure 3 la cible. La courbe de la Figure 4 représente le gain obtenu en fonction de cette distance de x mots. Bien que nous ne travaillions ni sur la même langue ni sur les même corpus que (Gale, et al., 1993), nous obtenons un résultat analogue : pour désambiguïser un mot, on trouve de l’information dans un contexte s’étendant jusqu&apos;à ±10000 mots. Figure 4 En résumé, pour l’ensemble de nos 7 vocables, la meilleure précision moyenne obtenue atteint 95% pour une taille de fenêtre très petite, ±1 mot plein, sans sortir de la phrase. Mais en contre-partie, le rappel est assez faible, de l’ordre de 40%. Pour une taille de fenêtre de ±30 mots pleins, en acceptant de sortir de la phrase, le rappel atteint 89% et toutes les occurrences ont été étiquetées, la précision est donc également de 89%. 6 Perspect</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1993</marker>
<rawString>W. A. Gale, K. W. Church, D. Yarowsky. (1993), A method for disambiguating word senses in a large corpus, Actes de Computers and the Humanities, pp.415-439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gross</author>
<author>A Clas</author>
</authors>
<date>1997</date>
<booktitle>Synonymie, Polysémie et Classes D&apos;objets, Meta, Presses de l&apos;Université de Montréal,</booktitle>
<pages>147--155</pages>
<marker>Gross, Clas, 1997</marker>
<rawString>G. Gross, A. Clas. (1997), Synonymie, Polysémie et Classes D&apos;objets, Meta, Presses de l&apos;Université de Montréal, pp.147-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>J Véronis</author>
</authors>
<title>Word sense disambiguation : the state of the art,</title>
<date>1998</date>
<booktitle>Special Issue on Word Sense Disambiguation, Presses de l&apos;Université de Montréal,</booktitle>
<pages>1--40</pages>
<contexts>
<context position="1798" citStr="Ide &amp; Véronis, 1998" startWordPosition="243" endWordPosition="246">ped in the SyntSem project. We analyse here the cooccurrence criterion and report a series of results on the disambiguative power of cooccurrences with respect to their grammatical category and distance from the word to be disambiguated. L. AUDIBERT 1 Introduction La désambiguïsation automatique est un enjeu important dans la plupart des applications de traitement automatique des langues (T.A.L.). On peut citer comme exemple les applications de recherche d’information, de traduction, de reconnaissance de la parole, de reconnaissance des caractères, de restauration de l’accentuation, etc. (cf. Ide &amp; Véronis, 1998) Bien que la désambiguïsation du sens des mots soit un thème de recherche important depuis l&apos;origine du T.A.L., les ressources nécessaires pour aborder correctement le problème commencent à peine à être disponibles. Ceci est particulièrement vrai pour le français, langue pour laquelle on commence à disposer d&apos;outils informatiques efficaces d’annotation (lemmatisation1, étiquetage morpho-syntaxique, dictionnaire de synonymes2, relation syntaxique simple entre les mots, etc.). Il existe également des applications puissantes et évolutives qui permettent d&apos;écrire des requêtes complexes sur des cor</context>
</contexts>
<marker>Ide, Véronis, 1998</marker>
<rawString>N. Ide, J. Véronis. (1998), Word sense disambiguation : the state of the art, Special Issue on Word Sense Disambiguation, Presses de l&apos;Université de Montréal, pp.1-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
</authors>
<title>SENSEVAL : an exercise in evaluating word sense disambiguation programs,</title>
<date>1998</date>
<booktitle>Actes de EURALEX-98,</booktitle>
<pages>176--174</pages>
<contexts>
<context position="4751" citStr="Kilgarriff, 1998" startWordPosition="641" endWordPosition="642">.htm, voir également l’article L. Audibert. (2001), LoX : outil polyvalent pour l&apos;exploration de corpus annotés, Actes de RECITAL (TALN) 2001, pp.411-419.. 4 Le projet SyntSem, financé par l’ELRA/ELDA, vise à produire un corpus étiqueté au niveau morphosyntaxique avec en plus un marquage syntaxique peu profond et un marquage sémantique de mots sélectionnés. 5 Cordial 7 Analyseur est développé par la société Synapse Développement (http://www.synapse-fr.com/). Etude des critères de désambiguïsation sémantique automatique l&apos;anglais, notamment dans le cadre de l&apos;action d&apos;évaluation Senseval, cf. (Kilgarriff, 1998), ils sont pour l&apos;instant inexistants pour le français. Pour ces multiples raisons, Delphine Reymond, avec qui nous travaillons en collaboration, a entrepris la construction d’un dictionnaire distributionnel en se basant sur un ensemble de critères différentiels stricts (Reymond, 2002). Ce dictionnaire comporte pour l&apos;instant la description détaillée de 20 noms communs, 20 verbes et 20 adjectifs. Il lui a permis d’étiqueter manuellement chacune des 53000 occurrences de ces 60 vocables dans le corpus du projet SyntSem (Corpus d’environ 5.5 millions de mots, composé de textes de genres variés). </context>
</contexts>
<marker>Kilgarriff, 1998</marker>
<rawString>A. Kilgarriff. (1998), SENSEVAL : an exercise in evaluating word sense disambiguation programs, Actes de EURALEX-98, pp.176-174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L AUDIBERT C d Loupy</author>
<author>M El-Bèze</author>
<author>P-F Marteau</author>
</authors>
<date>1998</date>
<journal>WSD Based on Three Short Context Methods, Actes de SENSEVAL Workshop.</journal>
<marker>Loupy, El-Bèze, Marteau, 1998</marker>
<rawString>L. AUDIBERT C. d. Loupy, M. El-Bèze, P.-F. Marteau. (1998), WSD Based on Three Short Context Methods, Actes de SENSEVAL Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S McRoy</author>
</authors>
<title>Using multiple knowledge sources for word sense discrimination,</title>
<date>1992</date>
<booktitle>Actes de Computational Linguistics,</booktitle>
<pages>1--30</pages>
<contexts>
<context position="8712" citStr="McRoy, 1992" startWordPosition="1220" endWordPosition="1221"> niveau de sens 20 verbes 20 adjectifs 20 noms L. AUDIBERT grossier (2 à 3 sens par vocable) que nous affinerons par la suite. Le nombre d’occurrences de certains sens peut parfois paraître faible, mais (Gale, et al., 1993) ont montré que très peu d’exemples (de l’ordre de 5) permettent d’obtenir de très bons résultats, et qu’il était rarement utile de dépasser la cinquantaine d’exemples. Il semblerait que ce ne soit pas tant le nombre d’exemples que leur diversité qui compte. 3 Critères Il existe de nombreuses sources d’information pour lever l’ambiguïté du sens des mots. Comme l’ont montré (McRoy, 1992), (Wilks, Stevenson, 1998) ou encore (Ng, Lee, 1996) toutes ces sources peuvent être utilisées simultanément pour aboutir à une meilleure désambiguïsation. Dans cette section nous dressons une liste (non restrictive) des critères de désambiguïsation sémantique automatique que nous projetons d’étudier. De nombreuses études montrent que les cooccurrences6 constituent un bon critère pour identifier le sens d’un mot. Mais que doit-on regarder : la forme fléchie du mot ou son lemme ; faut-il ne considérer que les mots pleins ou bien considérer aussi les mots grammaticaux ? Où doit-on regarder : jus</context>
</contexts>
<marker>McRoy, 1992</marker>
<rawString>S. McRoy. (1992), Using multiple knowledge sources for word sense discrimination, Actes de Computational Linguistics, pp.1-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H T Ng</author>
<author>H B Lee</author>
</authors>
<title>Integrating multiple knowledge sources to disambiguate word sense : an exemplar-based approach,</title>
<date>1996</date>
<booktitle>Actes de 34th Annual Meeting of the Society for Computational Linguistics,</booktitle>
<pages>40--47</pages>
<marker>Ng, Lee, 1996</marker>
<rawString>H. T. Ng, H. B. Lee. (1996), Integrating multiple knowledge sources to disambiguate word sense : an exemplar-based approach, Actes de 34th Annual Meeting of the Society for Computational Linguistics, pp.40-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
</authors>
<title>Are WordNet sense distinctions appropriate for computational lexicons ?,</title>
<date>1998</date>
<booktitle>Actes de SIGLEX-98, SENSEVAL.</booktitle>
<contexts>
<context position="3190" citStr="Palmer, 1998" startWordPosition="424" endWordPosition="425">on (Projet SyntSem4). 2 Matériaux de l’étude La première phase de notre travail fut l&apos;étiquetage de notre corpus avec le logiciel Cordial Analyseur5, qui offre une lemmatisation et un étiquetage morpho-syntaxique d’une exactitude satisfaisante (Valli, Véronis, 1999). D’autres informations (hyperonymes, relations syntaxiques, classes d’objets ...) seront ultérieurement apportées en fonction des besoins du critère de désambiguïsation étudié. L’une des difficultés majeures de l’étiquetage sémantique automatique réside dans l’inadéquation des dictionnaires traditionnels (Véronis, 2001) ou dédiés (Palmer, 1998) pour cette tâche. Une autre difficulté (Gale, Church, Yarowsky, 1993) provient du manque de corpus sémantiquement étiquetés sur lesquels des méthodes d&apos;apprentissage pourraient être entraînées. Ce manque se transforme même en absence totale pour une langue comme le français : si quelques corpus sémantiquement étiquetés commencent à apparaître pour 1 Selon Y. Choueka, S. Lusignan. (1985), Disambiguation by short contexts, Actes de Computer and the Humanities, pp.147-158., il n’existait, en 1985, aucun outil efficace de lemmatisation automatique. 2 Nous travaillons en collaboration avec J.L. Ma</context>
</contexts>
<marker>Palmer, 1998</marker>
<rawString>M. Palmer. (1998), Are WordNet sense distinctions appropriate for computational lexicons ?, Actes de SIGLEX-98, SENSEVAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Reymond</author>
</authors>
<title>Méthodologie pour la création d&apos;un dictionnaire distributionnel dans une perspective d&apos;étiquetage lexical semi-automatique, Actes de RECITAL (TALN)</title>
<date>2002</date>
<contexts>
<context position="5037" citStr="Reymond, 2002" startWordPosition="680" endWordPosition="681">syntaxique peu profond et un marquage sémantique de mots sélectionnés. 5 Cordial 7 Analyseur est développé par la société Synapse Développement (http://www.synapse-fr.com/). Etude des critères de désambiguïsation sémantique automatique l&apos;anglais, notamment dans le cadre de l&apos;action d&apos;évaluation Senseval, cf. (Kilgarriff, 1998), ils sont pour l&apos;instant inexistants pour le français. Pour ces multiples raisons, Delphine Reymond, avec qui nous travaillons en collaboration, a entrepris la construction d’un dictionnaire distributionnel en se basant sur un ensemble de critères différentiels stricts (Reymond, 2002). Ce dictionnaire comporte pour l&apos;instant la description détaillée de 20 noms communs, 20 verbes et 20 adjectifs. Il lui a permis d’étiqueter manuellement chacune des 53000 occurrences de ces 60 vocables dans le corpus du projet SyntSem (Corpus d’environ 5.5 millions de mots, composé de textes de genres variés). Ce corpus est une ressource de départ pour une étude approfondie des critères de désambiguïsation sémantique automatique puisqu’il permet l&apos;entraînement et l&apos;évaluation des algorithmes. La dernière pièce manquante était un outil permettant de modéliser les critères que l’on désire étud</context>
<context position="11951" citStr="Reymond, 2002" startWordPosition="1689" endWordPosition="1690"> des notions de fréquence, de figement, de lien syntaxique ou encore de proximité. Etude des critères de désambiguïsation sémantique automatique 4 Mise en œuvre de critères sur les cooccurrences 4.1 Définition d’un critère Tout d’abord, il faut trouver, puis énoncer clairement un critère susceptible d’être pertinent pour la levée de l’ambiguïté sémantique. Ce critère doit pouvoir être mis en œuvre dans la perspective d’un étiquetage automatique. Les critères les plus appropriés pour l’étiquetage automatique ne peuvent pas être directement calqués sur les critères différentiels présentés dans (Reymond, 2002) destinés à un étiquetage sémantique manuel. En effet, les critères différentiels sont souvent difficiles à mettre en œuvre car ils font intervenir le jugement du linguiste. De plus, les critères qui font intervenir des classes d’objets, ou des informations syntaxiques, imposent de disposer de ces informations. Or, si la lemmatisation ou l’étiquetage morpho-syntaxique sont des techniques qui commencent à arriver à maturité, l’appartenance à une classe d’objets et l’étiquetage syntaxique sont encore du domaine de la recherche. A l’inverse, la puissance de calcul des ordinateurs permet d’utilise</context>
</contexts>
<marker>Reymond, 2002</marker>
<rawString>D. Reymond. (2002), Méthodologie pour la création d&apos;un dictionnaire distributionnel dans une perspective d&apos;étiquetage lexical semi-automatique, Actes de RECITAL (TALN) 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Silberztein</author>
</authors>
<title>INTEX, Association pour le traitement informatique des langues (ASSTRIL),</title>
<date>2000</date>
<location>http://ladl.univ-mlv.fr/INTEX/information.html.</location>
<contexts>
<context position="2442" citStr="Silberztein, 2000" startWordPosition="330" endWordPosition="331">on du sens des mots soit un thème de recherche important depuis l&apos;origine du T.A.L., les ressources nécessaires pour aborder correctement le problème commencent à peine à être disponibles. Ceci est particulièrement vrai pour le français, langue pour laquelle on commence à disposer d&apos;outils informatiques efficaces d’annotation (lemmatisation1, étiquetage morpho-syntaxique, dictionnaire de synonymes2, relation syntaxique simple entre les mots, etc.). Il existe également des applications puissantes et évolutives qui permettent d&apos;écrire des requêtes complexes sur des corpus étiquetés (Intex voir [Silberztein, 2000], (Win/Dos)LoX3, IMS Corpus Workbench, etc.). Enfin un corpus français désambiguïsé, de taille exploitable, est en cours de constitution (Projet SyntSem4). 2 Matériaux de l’étude La première phase de notre travail fut l&apos;étiquetage de notre corpus avec le logiciel Cordial Analyseur5, qui offre une lemmatisation et un étiquetage morpho-syntaxique d’une exactitude satisfaisante (Valli, Véronis, 1999). D’autres informations (hyperonymes, relations syntaxiques, classes d’objets ...) seront ultérieurement apportées en fonction des besoins du critère de désambiguïsation étudié. L’une des difficultés</context>
</contexts>
<marker>Silberztein, 2000</marker>
<rawString>M. Silberztein. (2000), INTEX, Association pour le traitement informatique des langues (ASSTRIL), http://ladl.univ-mlv.fr/INTEX/information.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Valli</author>
<author>J Véronis</author>
</authors>
<title>Etiquetage grammatical de corpus oraux : problèmes et perpectives, Revue Française de Linguistique Appliquée, Association pour le traitement informatique des langues (ASSTRIL),</title>
<date>1999</date>
<pages>113--133</pages>
<marker>Valli, Véronis, 1999</marker>
<rawString>A. Valli, J. Véronis. (1999), Etiquetage grammatical de corpus oraux : problèmes et perpectives, Revue Française de Linguistique Appliquée, Association pour le traitement informatique des langues (ASSTRIL), pp.113-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Véronis</author>
</authors>
<title>Sense tagging : does it makes sense ?, Actes de Corpus Linguistics&apos;2001, pp.in press.</title>
<date>2001</date>
<contexts>
<context position="3165" citStr="Véronis, 2001" startWordPosition="420" endWordPosition="421">est en cours de constitution (Projet SyntSem4). 2 Matériaux de l’étude La première phase de notre travail fut l&apos;étiquetage de notre corpus avec le logiciel Cordial Analyseur5, qui offre une lemmatisation et un étiquetage morpho-syntaxique d’une exactitude satisfaisante (Valli, Véronis, 1999). D’autres informations (hyperonymes, relations syntaxiques, classes d’objets ...) seront ultérieurement apportées en fonction des besoins du critère de désambiguïsation étudié. L’une des difficultés majeures de l’étiquetage sémantique automatique réside dans l’inadéquation des dictionnaires traditionnels (Véronis, 2001) ou dédiés (Palmer, 1998) pour cette tâche. Une autre difficulté (Gale, Church, Yarowsky, 1993) provient du manque de corpus sémantiquement étiquetés sur lesquels des méthodes d&apos;apprentissage pourraient être entraînées. Ce manque se transforme même en absence totale pour une langue comme le français : si quelques corpus sémantiquement étiquetés commencent à apparaître pour 1 Selon Y. Choueka, S. Lusignan. (1985), Disambiguation by short contexts, Actes de Computer and the Humanities, pp.147-158., il n’existait, en 1985, aucun outil efficace de lemmatisation automatique. 2 Nous travaillons en c</context>
</contexts>
<marker>Véronis, 2001</marker>
<rawString>J. Véronis. (2001), Sense tagging : does it makes sense ?, Actes de Corpus Linguistics&apos;2001, pp.in press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
<author>M Stevenson</author>
</authors>
<title>Word sense disembiguation using optimised combinations of knowledge sources, Actes de COLING-ACL98.</title>
<date>1998</date>
<marker>Wilks, Stevenson, 1998</marker>
<rawString>Y. Wilks, M. Stevenson. (1998), Word sense disembiguation using optimised combinations of knowledge sources, Actes de COLING-ACL98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>One sense per collocation,</title>
<date>1993</date>
<journal>Actes de ARPA Human Language Technology Workshop,</journal>
<pages>266--271</pages>
<contexts>
<context position="3260" citStr="Yarowsky, 1993" startWordPosition="434" endWordPosition="435">tre travail fut l&apos;étiquetage de notre corpus avec le logiciel Cordial Analyseur5, qui offre une lemmatisation et un étiquetage morpho-syntaxique d’une exactitude satisfaisante (Valli, Véronis, 1999). D’autres informations (hyperonymes, relations syntaxiques, classes d’objets ...) seront ultérieurement apportées en fonction des besoins du critère de désambiguïsation étudié. L’une des difficultés majeures de l’étiquetage sémantique automatique réside dans l’inadéquation des dictionnaires traditionnels (Véronis, 2001) ou dédiés (Palmer, 1998) pour cette tâche. Une autre difficulté (Gale, Church, Yarowsky, 1993) provient du manque de corpus sémantiquement étiquetés sur lesquels des méthodes d&apos;apprentissage pourraient être entraînées. Ce manque se transforme même en absence totale pour une langue comme le français : si quelques corpus sémantiquement étiquetés commencent à apparaître pour 1 Selon Y. Choueka, S. Lusignan. (1985), Disambiguation by short contexts, Actes de Computer and the Humanities, pp.147-158., il n’existait, en 1985, aucun outil efficace de lemmatisation automatique. 2 Nous travaillons en collaboration avec J.L. Manguin du CRISCO (CNRS Caen) qui nous fournit un dictionnaire de synony</context>
<context position="9838" citStr="Yarowsky, 1993" startWordPosition="1381" endWordPosition="1382">es mots pleins ou bien considérer aussi les mots grammaticaux ? Où doit-on regarder : jusqu&apos;à quelle distance les cooccurrences apportentelles de l’information ; est-il pertinent de sortir du contexte de la phrase ; doit-on différencier le contexte droit du contexte gauche ? Des cooccurrences ciblées par des relations syntaxiques telles que les relations sujet-verbe, verbe-objet, adjectif-nom, nom-adjectif, nom-nom peuvent être plus pertinentes que des cooccurrences prises au hasard. Aussi est-il certainement important d&apos;accorder une attention particulière à ces cooccurrences, comme l’a fait (Yarowsky, 1993). Les étiquettes morpho-syntaxiques des mots qui entourent le mot dont on cherche à identifier le sens sont souvent un bon critère de désambiguïsation. Il faudrait donc en tenir compte. Mais une question se pose : quelle est la meilleure granularité des étiquettes morphosyntaxiques ? Serait-il judicieux de travailler simultanément sur plusieurs niveaux de granularité ? Selon (Gross, Clas, 1997) les traits syntactico-sémantiques permettent une subdivision des noms en 8 sous-ensembles : humain, animal, végétal, inanimé concret, inanimé abstrait, locatif, temps, événement. Toujours selon (Gross, </context>
<context position="21855" citStr="Yarowsky, 1993" startWordPosition="3320" endWordPosition="3321">ambiguïsation sémantique automatique On peut remarquer que, parmi les travaux similaires déjà réalisés, très peu l’ont été sur des corpus manuellement étiquetés en raison de leur rareté. Pour pallier ce problème, les chercheurs ont souvent usé de subterfuges pour évaluer leurs algorithmes. Certains fusionnent deux mots quelconques en un seul en gardant l’information du mot d’origine. Un raffinement de cette technique consiste à ne pas choisir les deux mots au hasard mais à en prendre deux qui sont homographes dans une autre langue ou encore qui ne se distinguent que par une seule lettre, cf. (Yarowsky, 1993) par exemple. Ces techniques permettent de réaliser des apprentissages supervisés sur des corpus de grande taille sans avoir à les étiqueter manuellement. Cependant, il est clair que les contextes de tels mots sont très distincts, ce qui facilite leur désambiguïsation et biaise les résultats. Notre étude porte sur de « vrais » mots et s’appuie sur un corpus de taille suffisante manuellement étiqueté. On peut également remarquer que l’une des difficultés de l’étiquetage sémantique automatique réside dans l’inadéquation des dictionnaires traditionnels. Pour cette raison, notre corpus a été étiqu</context>
</contexts>
<marker>Yarowsky, 1993</marker>
<rawString>D. Yarowsky. (1993), One sense per collocation, Actes de ARPA Human Language Technology Workshop, pp.266-271.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>