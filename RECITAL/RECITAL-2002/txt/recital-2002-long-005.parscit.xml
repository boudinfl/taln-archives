<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Braffort</author>
</authors>
<title>Reconnaissance et compréhension de gestes, application a la langue des signes, these, Université Paris XI -</title>
<date>1996</date>
<location>Orsay.</location>
<contexts>
<context position="12314" citStr="Braffort, 1996" startWordPosition="1991" endWordPosition="1992">ssance de la parole o1‘1l’on cherche a reconnaitre des phonemes et non pas directement des mots. Nous allons tacher de préserver cette approche dans l’architecture que nous allons proposer dans la partie 4. 111 n’y a théoriquement pas de limite possible (mis a part les contraintes articulatoires) quand au nombre de Variantes pour chaque parametre. Cela est particulierement Valable pour les spéciﬁcateurs de forme et de taille dont les parametres sont lies :21 Ce qu’ils décrivent. Pour les signes standards on recense l’utilisation d’enViron 140 conﬁguration, 300 orientations et 50 emplacements (Braffort, 1996). JJKIDDCLLDI 1J1 blllkl 3.2 Relations entre les deux mains On a vu précédemment (partie 2.2) que l’on peut rencontrer trois types d’interaction entre les deux mains. Soit les deux mains produisent ensemble un signe, soit une main effectue un signe et l’autre est au repos, soit les deux mains effectuent séparément deux signes de maniere plus ou moins indépendante. Le probleme Va donc étre de savoir distinguer ces différents cas pour ne pas reconnaitre un signe a deux mains alors qu’il s’agissait de deux signes distincts effectués au meme moment (ou vice-versa). Pour distinguer ces deux cas, on</context>
</contexts>
<marker>Braffort, 1996</marker>
<rawString>Braffort A. (1996), Reconnaissance et compréhension de gestes, application a la langue des signes, these, Université Paris XI - Orsay.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Braffort</author>
</authors>
<title>Traitement automatique des langues des signes : interprétation des informations spatiales, dans Revue d’Ir1teraction Homme-Machine,</title>
<date>1998</date>
<volume>1</volume>
<pages>65--87</pages>
<contexts>
<context position="15122" citStr="Braffort, 1998" startWordPosition="2440" endWordPosition="2441"> Va donc y avoir pendant un certain laps de temps une disposition particuliere des mains pour exprimer la relation spatiale “dans” (quatrieme image, ﬁgure 7). 11 Va donc falloir étre capable de détecter cet instant pour interpreter cette relation. Aucune solution n’a été proposée a ce jour pour résoudre ce probleme. 3.3 Interprétation des signes non standards Un troisieme probleme encore plus difﬁcile a résoudre concerne l’interprétation des signes non standards. A ce jour, seule une catégorie de ces signes (les verbes directionnels) a été abordée dans le cadre d’un systeme de reconnaissance (Braffort, 1998; Sagawa et Takeuchi, 1999). Parmis les categories qui n’ont pas été abordées en reconnaissance de la LS, on trouve les classiﬁcateurs et les spéciﬁcateurs. On a vu dans la partie 2.3 que ces demiers n’ont pas de sens propre, c’est la phrase et son contexte qui permettent de le déterminer. 1 1\}l}1\/111\/D PUDVD Hal 1“ 1\/\/\}l1l1(LlDD(l.ll\/\/ \al\/ s\/DL\/D \/ll J..4(l.llsbl\/ \al\/D xllsllk/D Les classiﬁcateurs se rapportent souVent a un signe standard qui a été signé précédemment mais ce n’est pas toujours le cas. On peut cependant déterminer pour chaque signe la liste des classiﬁ- cateurs</context>
</contexts>
<marker>Braffort, 1998</marker>
<rawString>Braffort A., (1998), Traitement automatique des langues des signes : interprétation des informations spatiales, dans Revue d’Ir1teraction Homme-Machine, Vol. 1, Num. 1, 65-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cuxac</author>
</authors>
<title>La langue des Signes Francaise (LSF), les voies de l ’iconicité, Faits de Langues 15-16, Editions OPHRYS.</title>
<date>2000</date>
<contexts>
<context position="3567" citStr="Cuxac, 2000" startWordPosition="551" endWordPosition="552">rents problemes d’interprétation induits par ces signes et le probleme de la synchronisation des mains y sera plus particulierement developpé. Enﬁn la troisieme partie expose l’architecture proposée pour traiter ces problemes de synchronisation. 2 Quelques caractéristiques de la Langue des Signes La Langue des Signes est le moyen d’expression utilisé par les communautés de sourds ou malentendants pour communiquer entre eux. La Langue des Signes est une véritable langue a part entiere (avec un lexique, une syntaxe...) et constitue de ce fait la forme la plus évoluée en communication gestuelle (Cuxac, 2000; McNeil, 1992). L’ expression de phrases en LS ne se réduit pas aux gestes produits par les deux mains, c’est le corps tout entier qui peut étre mis a contribution pour exprimer une phrase. On peut distinger trois principales parties qui interviennent : les mains, la téte (mimique et regard) et le buste. Dans cette étude on se restreint uniquement aux mains, c’est pourquoi les autres parties du corps ne seront pas abordées par la suite. Chaque phrase est constituée d’une suite de gestes des mains que l’on appelle signes et qui sont agencés suivant une syntaxe régie par une logique spatiale et</context>
<context position="4828" citStr="Cuxac, 2000" startWordPosition="751" endWordPosition="752">n des signes et des relations qui s’établissent entre eux qui nous intéressent, et qui vont étre décrits avec précision dans les parties qui suivent. 2.1 Composition d’un signe Chaque geste d’une main peut étre décomposé en quatre parametres qui sont indépendants et peuvent étre aussi bien dynamiques qu’invariants durant l’émission du signe. 1 1\}l}1\/111\/D PUDVD Hal 1“ 1\/\/\}l1l1(LlDD(l.ll\/\/ \al\/ s\/DL\/D \/ll J..4(l.llsbl\/ \al\/D 0151190 0 La conﬁguration correspond a la forme de la main déﬁnie par les doigts et la paume (exemples ﬁgure 1). Les signes ont souvent des aspect iconiques (Cuxac, 2000). En particulier la conﬁguration est souvent en rapport avec la forme de ce que le signe décrit. o L’ orientation de la main est déﬁnie par deux axes de la main indiqués dans la ﬁgure 1. 0 Le mouvement correspond a la trajectoire décrite par la main (ligne, arc de cercle...)(voir ﬁgure 1). ﬁlm-I I: |:|II1I‘Il r:&amp;quot;&apos;Il hm. I__,&amp;quot;_ h_ V ..r .. Figure 1: Exemples de conﬁgurations, d’orientation et de mouvement. o L’emplacement est la position de la main par rapport au corps. Selon les besoins, il va avoir une granularité plus ou moins ﬁne. Dans la ﬁgure 2, l’emplacement du premier signe [GARCON] est</context>
<context position="6340" citStr="Cuxac, 2000" startWordPosition="1012" endWordPosition="1013">se “Un garcon a droite” constituée des signes [GARCON] et [ICI] Chacun de ces parametres est porteur d’information et contribue au sens d’un signe. 2.2 Interaction entre les deux mains Un signe peut aussi bien faire intervenir une main que deux mains et les deux mains ont différentes facons d’interagir. Lorsque les deux mains sont impliquées dans un signe, deux cas se présentent. Dans le premier cas on voit apparaitre un role pour chaque main. Une main est dite dominante eta pour role de décrire “l’action”, tandis que l’autre main qui est appelée main dominée sert de reference a cette action (Cuxac, 2000). Par exemple, avec le signe [TOMBER DE] (ﬁgure 3), on peut voir la main dominante (main droite dans la ﬁgure) qui mime l’action de tomber d’un support (référence donnée par la main dominée). En général la main dominante se déplace au cours du geste tandis que la main dominée reste statique. Dans le deuxieme cas, les deux mains sont completement synchronisées : leurs parametres sont JJKIDDCLLDI 1J1 blllkl identiques ou symétriques. Par exemple, avec le signe [TABLE] (ﬁgure 3), les deux mains ont une conﬁguration et une orientation identiques et des mouvements de meme traj ectoire mais de sens </context>
<context position="8570" citStr="Cuxac, 2000" startWordPosition="1382" endWordPosition="1383">udiés en reconnaissance de gestes et il existe des systemes permettant d’effectuer la reconnaissance de maniere ﬁable sur des vocabulaires de taille limitée. Par exemple dans (Hienz et Bauer, 2000) le taux de reconnaisssance atteint un peu plus de 90% pour un vocabulaire d’une centaine de signes. I1 existe deux autres classes de signes qui eux ne permettent aucune correspondance directe avec des mots du langage oral. Il s’agit des spéciﬁcateurs deforme et de taille, et des classiﬁcateurs. Ces signes ont des aspects fortement iconiques et font partie de ce que l’on appelle la grande iconicité (Cuxac, 2000). Les spéciﬁcateurs permettent de décrire un objet, un animal, une scene. C’est a l’aide de la forme des mains, de leur orientation et de leur mouvement que le signeur décrit une forme et les dimensions d’un objet. Les classiﬁcateurs sont siIr1ilaires aux spéciﬁ- cateurs dans le sens o1‘1 ils représentent également un objet (ou personne, animal...) et donc la forme de la main est en rapport avec celle de l’objet ou de sa fonction. Mais ils ont un tout autre role car ils servent en quelque sorte de pronom. Lorsqu’un objet a été cité dans une phrase a l’aide d’un signe du vocabulaire standard (o</context>
</contexts>
<marker>Cuxac, 2000</marker>
<rawString>Cuxac C. (2000), La langue des Signes Francaise (LSF), les voies de l ’iconicité, Faits de Langues 15-16, Editions OPHRYS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cuxac</author>
<author>I Fusellier-Souza</author>
<author>M A Sallandre</author>
</authors>
<date>1998</date>
<booktitle>Iconicite’ des Langues des Signes et Catégorisation, dans SEMIOTIQUES, Num.</booktitle>
<volume>16</volume>
<pages>181</pages>
<contexts>
<context position="16285" citStr="Cuxac et al., 1998" startWordPosition="2620" endWordPosition="2623">terminer pour chaque signe la liste des classiﬁ- cateurs potentiels. Les spéciﬁcateurs posent un probleme beaucoup plus complexe du fait qu’ils sont propres a la description et peuvent Varier énormément. Contrairement aux langues orales qui possedent un Vocabulaire délimité, en LS on peut tres bien “inventer” un signe de toutes pieces. Par déﬁnition, les parametres d’un spéciﬁcateur sont associés a ce qu’ils décrivent et donc a chaque nouvelle description peut correspondre de nouveaux signes. De plus, la maniere de faire une description peut dépendre du contexte social et culturel du signeur (Cuxac et al., 1998) Il Va falloir chercher le sens de ces signes dans le contexte de la phrase et en analysant les formes qu’ils décrivent. Ceci est un probleme tres complexe et il n’y a actuellement aucune solution qui y remédie. Il faut a notre niveau que l’architecture proposée permette une interaction bidirectionnelle entre le processus de reconnaissance de forme et le processus d’interprétation prenant en compte les aspect syntaxiques et sémantiques. Pour pouvoir traiter des phrases de la LS les plus riches possibles il faut donc que le systeme de reconnaissance prenne en compte les différents problemes sou</context>
</contexts>
<marker>Cuxac, Fusellier-Souza, Sallandre, 1998</marker>
<rawString>Cuxac C., Fusellier-Souza I., Sallandre M.A., (1998), Iconicite’ des Langues des Signes et Catégorisation, dans SEMIOTIQUES, Num. 16, 181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hienz</author>
<author>B Bauer</author>
</authors>
<title>Video-Based Continuous Sign Language Recognition Using Statistical Methods,</title>
<date>2000</date>
<booktitle>Actes de IEEE International Conference on Automatic Face and Gesture Recognition,</booktitle>
<pages>440--445</pages>
<marker>Hienz, Bauer, 2000</marker>
<rawString>Hienz H., Bauer B. (2000), Video-Based Continuous Sign Language Recognition Using Statistical Methods, Actes de IEEE International Conference on Automatic Face and Gesture Recognition, 440-445.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Lejeune</author>
<author>A Braffort</author>
<author>J P Desclés</author>
</authors>
<date>2002</date>
<booktitle>Study on Semantic Representations of French Sign Language Sentences, Actes de Gesture Workshop ’0I , Springer, LNAI 2298 (a paraitre),</booktitle>
<pages>440--445</pages>
<contexts>
<context position="14234" citStr="Lejeune et al., 2002" startWordPosition="2296" endWordPosition="2299">cées spatialement de maniere a véhiculer une certaine information. Par exemple dans la phrase “Le chat est dans la voiture” (ﬁgure 5), le signe [VOITURE] est d’abord ennoncé (premiere image) puis remplacé par le classiﬁcateur “C” qui représente la voiture en tant que “contenant” et la positionne dans la scene (deuxieme image). Ensuite on voit la main gauche qui énonce le signe [CHAT] (troisieme image), le remplace par le classiﬁcateur “X” (représentant les pattes du chat) et positionne ce demier relativement au classiﬁcateur représentant la voiture (derniere image)(description effectuée dans (Lejeune et al., 2002)). Figure 5: “Le chat est dans la voiture” On remarque dans les trois dernieres images que la main dominante “maintient” le classiﬁcateur “C” alors que la main dominée effectue trois signes successifs. On peut donc penser que les deux mains sont indépendantes. Cependant, il Va donc y avoir pendant un certain laps de temps une disposition particuliere des mains pour exprimer la relation spatiale “dans” (quatrieme image, ﬁgure 7). 11 Va donc falloir étre capable de détecter cet instant pour interpreter cette relation. Aucune solution n’a été proposée a ce jour pour résoudre ce probleme. 3.3 Inte</context>
</contexts>
<marker>Lejeune, Braffort, Desclés, 2002</marker>
<rawString>Lejeune F., Braffort A., Desclés J .P. (2002), Study on Semantic Representations of French Sign Language Sentences, Actes de Gesture Workshop ’0I , Springer, LNAI 2298 (a paraitre), 440-445.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Liang</author>
<author>Ming</author>
</authors>
<title>A Sign Language Recognition System Using Hidden Markov Model and Context Sensitive Search,</title>
<date>1996</date>
<booktitle>Actes de ACM Symposium on Wrtual Reality Software and Technology’96,</booktitle>
<pages>59--66</pages>
<marker>Liang, Ming, 1996</marker>
<rawString>Liang R.H., Ming 0., (1996), A Sign Language Recognition System Using Hidden Markov Model and Context Sensitive Search, Actes de ACM Symposium on Wrtual Reality Software and Technology’96, 59-66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McNeil</author>
</authors>
<title>Hand and Mind : What gestures reveal about thought,</title>
<date>1992</date>
<publisher>Press.</publisher>
<institution>University of Chicago</institution>
<contexts>
<context position="3582" citStr="McNeil, 1992" startWordPosition="553" endWordPosition="554">es d’interprétation induits par ces signes et le probleme de la synchronisation des mains y sera plus particulierement developpé. Enﬁn la troisieme partie expose l’architecture proposée pour traiter ces problemes de synchronisation. 2 Quelques caractéristiques de la Langue des Signes La Langue des Signes est le moyen d’expression utilisé par les communautés de sourds ou malentendants pour communiquer entre eux. La Langue des Signes est une véritable langue a part entiere (avec un lexique, une syntaxe...) et constitue de ce fait la forme la plus évoluée en communication gestuelle (Cuxac, 2000; McNeil, 1992). L’ expression de phrases en LS ne se réduit pas aux gestes produits par les deux mains, c’est le corps tout entier qui peut étre mis a contribution pour exprimer une phrase. On peut distinger trois principales parties qui interviennent : les mains, la téte (mimique et regard) et le buste. Dans cette étude on se restreint uniquement aux mains, c’est pourquoi les autres parties du corps ne seront pas abordées par la suite. Chaque phrase est constituée d’une suite de gestes des mains que l’on appelle signes et qui sont agencés suivant une syntaxe régie par une logique spatiale et temporelle. C’</context>
</contexts>
<marker>McNeil, 1992</marker>
<rawString>McNeil D. (1992), Hand and Mind : What gestures reveal about thought, University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Rubine</author>
</authors>
<title>The Automatic Recognition of Gestures,</title>
<date>1991</date>
<tech>Ph-D thesis, Carnegie-Mellon.</tech>
<contexts>
<context position="19491" citStr="Rubine, 1991" startWordPosition="3125" endWordPosition="3126">ié a l’élément retourné par le module, la durée de cet élément est foumie (a quel instant il a commencé et a quel instant il a ﬁni). JJKIDDCLLDI 1J1 blllkl Module recc . _ Configuration :: Module reco . Or:.entat:.on on P1“: In Module reeo . &apos; nmplacemnnt 1 olnlln-U&apos;Hnuu’ 50!-&amp;quot;RD!-“OOIIIF it Module reco . &apos; Mmxvemenc Figure 6: Module de reconnaissance des gestes d’une main La composition méme des modules de reconnaissance des parametres peut-étre Variable suivant la complexité du vocabulaire que l’on Veut reconnaitre. On peut aussi bien utiliser un simple systeme de classiﬁcation statistique (Rubine, 1991), que des modeles stochastiques tel que les chaines de Markov cachées (Vogler et Metaxas, 1999). 0 Proposition 2 : reconnaissance a la fois synchrone et asynchrone Si l’on considere la problématique liée a l’utilisation d’une ou deux mains, on peut identiﬁer trois types de signes possibles : ceux effectués avec les deux mains, ceux effectués par la main droite et ceux effectués par la main gauche. Pour interpréter correctement un signe il Va donc falloir déterminer a laquelle de ces trois catégories il est associé. Pour cela, la solution proposée est la suivante : pour chaque geste émis, trois</context>
<context position="24452" citStr="Rubine, 1991" startWordPosition="3947" endWordPosition="3948">ne ou deux mains, synchronisation Variable, classiﬁcateurs Aﬁn de faciliter la phase de capture des gestes, l’acquisition de ces phrases se fait a partir de gants numériques et de capteurs de position 3D. Les données sont récupérées de maniere synchrone a partir des quatre périphériques, cela aﬁn que les modules de reconnaissance puissent travailler correctement. La réalisation de 1’ architecture est actuellement en cours. A ce jour l’implémentation des propositions 1 et 2 est achevée. Pour l’instant les modules de reconnaissance sont basés sur un systeme de classiﬁcation de type statistique (Rubine, 1991) pour pouVoir tester la comparaison des sorties des trois modules. Mais l’objectif a moyen terme est de tester une approche stochastique qui est beaucoup plus adaptée aux phrases gestuelles car elle permet de modéliser la coarticulation entre deux gestes enchainés. L’ objectif a court terme est de tester différentes méthodes de comparaison aVant de progresser plus en aVant dans la réalisation de l’architecture. 5 Conclusion Le fait que les mains sont deux moyens de communications indépendants permet en LS d’exprimer diverses relations entre les signes. On ne peut ignorer l’information que ces </context>
</contexts>
<marker>Rubine, 1991</marker>
<rawString>Rubine D. (1991), The Automatic Recognition of Gestures, Ph-D thesis, Carnegie-Mellon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sagawa</author>
<author>M Takeuchi</author>
</authors>
<title>A Method for Analyzing Spatial Relationships Between Words</title>
<date>1999</date>
<booktitle>in Sign Language Recognition, Actes de Gesture Workshop’99, Springer, LNAI 1739,</booktitle>
<pages>197--210</pages>
<marker>Sagawa, Takeuchi, 1999</marker>
<rawString>Sagawa H., Takeuchi M. (1999), A Method for Analyzing Spatial Relationships Between Words in Sign Language Recognition, Actes de Gesture Workshop’99, Springer, LNAI 1739, 197-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Vogler</author>
<author>D N Metaxas</author>
</authors>
<title>Toward Scalability in ASL Recognition: Breaking Down Signs into Phonemes, Actes de GEsture Workshop’99, Springer,</title>
<date>1999</date>
<journal>LNAI</journal>
<volume>1739</volume>
<pages>211--224</pages>
<marker>Vogler, Metaxas, 1999</marker>
<rawString>Vogler C., Metaxas D.N. (1999), Toward Scalability in ASL Recognition: Breaking Down Signs into Phonemes, Actes de GEsture Workshop’99, Springer, LNAI 1739, 211-224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Vogler</author>
<author>D N Metaxas</author>
</authors>
<title>Parallel Hiden Markov Models for American Sign Language Recognition,</title>
<date>1999</date>
<booktitle>Actes de IEEE International Conference on Computer Wsion,</booktitle>
<pages>116--122</pages>
<marker>Vogler, Metaxas, 1999</marker>
<rawString>Vogler C., Metaxas D.N. (1999), Parallel Hiden Markov Models for American Sign Language Recognition, Actes de IEEE International Conference on Computer Wsion, 116-122.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>