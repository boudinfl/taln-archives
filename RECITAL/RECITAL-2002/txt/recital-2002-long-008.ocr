RECITAL 2002, Nancy, 24-27 juin 2002

Normalisation de documents par analyse du contenu a l’aide
d’un modéle sémantique et d’un générateur

Aurélien Max
Groupe d’Etude pour la Traduction Automatique (GETA CLIPS-I1\/IAG)
Xerox Research Centre Europe (XRCE)
Grenoble, France
aurelien.max @ imag.fr
date de soutenance prévue : Novembre 2003

Mots-clefs — Keywords

analyse de contenu, génération, création assistée de documents, normalisation de document
content analysis, generation, document authoring, document normalization

Résumé - Abstract

La problématique de la normalisation de documents est introduite et illustrée par des exemples
issus de notices pharmaceutiques. Un paradigme pour l’analyse du contenu des documents est
proposé. Ce paradigme se base sur la spéciﬁcation formelle de la sémantique des documents et
utilise une notion de similarité ﬂoue entre les prédictions textuelles d’un générateur de texte et
le texte du document a analyser. Une implémentation initiale du paradigme est présentée.

This paper discusses document normalization and gives examples based on a class of pharma-
ceutical documents. The discussion is based on a paradigm for document content analysis. This
paradigm focusses on a formal speciﬁcation of document semantics and uses a fuzzy matching
measure between the textual predictions of a natural language generator and the input document.
An initial implementation is presented.

Aurélien Max

1 Introduction

Nous introduisons la problématique de la normalisation de documents, et nous l’illustrons sur
des exemples issus de notices pharmaceutiques. La normalisation d’un document est déﬁnie
comme la reconnaissance des buts communicatifs pre’de’ﬁnis exprimé dans celui-ci, puis leur
reformulation par un processus de génération controlée. Dans cet article, nous déﬁnissons des
besoins sur la speciﬁcation du contenu des documents pour leur normalisation, puis nous mon-
trons comment des modeles existants développés pour la création assistée de documents multi-
lingues peuvent étre utilisés. Nous proposons ensuite un paradigme pour l’analyse du contenu
qui utilise de tels modeles en conjonction avec la notion de ge’ne’ration inverse’e ﬂoue, et nous
montrons comment le contenu d’un document source peut etre retrouvé heuristiquement par le
biais d’une procédure de recherche admissible. Dans un demier temps, nous présentons une
implémentation initiale d’un systeme de normalisation de documents existants.

2 Normalisation de documents

2.1 Etude de cas: les notices pharmaceutiques

Aﬁn de motiver la tache de normalisation de documents, nous avons étudié un corpus contenant
50 notices pharmaceutiques en anglais pour des médicaments analgésiques.1 Les notices, issues
de différentes pharmacies en ligne en Grande-Bretagne et aux Etats-Unis, constituent une col-
lection hétérogene de documents comparables pour des médicaments similaires ayant l’aspirine
comme principal principe actif. Notre étude de corpus a révélé différents types de variation,
que nous allons illustrer sur deux exemples de notices (voir ﬁgure 1), ANA (pour ANADIN) et
ALK (pour ALKA-SELTZER)?

Tout d’abord, les structures des deux notices sont différentes, ce qui se traduit par exemple
dans la facon dont les informations relatives aux avertissements (warnings) sont organisées.
ANA distingue une section d’avertissements assez générale (Warnings), une section sur les
effets indésirables possibles (Side eﬁects), alors que ALK a une section sur les intéractions
médicamenteuses possibles (Drug interaction precautions), une section d’avertissements (Wam-
ings), et une section sur les avertissements propres a la consommation d’alcool (Alcohol warn-
ing). ANA donne les informations relatives aux intéractions médicamenteuses possibles dans
sa section sur les avertissements (Wamings: You should ask your doctor before taking aspirin
if you are taking medicines for...). A l’inverse, les effets indésirables possibles, qui apparaissent
dans la section générale sur les avertissements dans ALK (If ringing in the ears or a loss of
hearing occurs...), ont une section propre dans ANA.

Certains types de contenu peuvent étre exprimés ou non, ce qui reﬂete des décisions prises
par l’organisme responsable de la diffusion de la notice. Ainsi, ALK a une section speciﬁque
sur les avertissements lies a la consommation d’alcool (Alcohol warning); l’effet indésirable
possible correspondant (hémorragie digestive haute, stomach bleeding) est également exprimé
dans ANA dans sa section sur les effets indésirables possibles (Side eﬁects), mais sans référence

1Le choix de la langue du corpus a principalement été motivé par la disponibilité de documents électroniques de
différentes origines en anglais. L’ approche que nous présentons dans cet article s’applique également au frangais.

2Ces deux médicaments contiennent également d’autres principes actifs, ce qui a bien entendu des
repercussions sur le contenu de leur notice respective.

Normalisation de documents par analyse du contenu a l’aide d’un modele
sémantique et d’un générateur

ANADIN (source: wvvw.pharmacy2u.co.uk)

Indications For the symptomatic relief of inﬂuenza and common colds. Also indicated for the treatment of mild to moderate pain, including
headache, migraine, neuralgia, dental pain, period pain and muscular aches and pains.

Directions 

Ingredients Capsule containing: Aspirin (acetylsalicylic acid) 500 mg 

Warnings Do not take aspirin if you are allergic to aspirin or to any other ingredients, have a stomach ulcer or have haemophilia. Avoid in
asthmatics and pregnancy particularly the ﬁnal trimester. Aspirin has also been associated with increased risk of Reye’s Syndrome when given
to children with a fever. For this reason the use of aspirin is not recommended in children under 12 years of age. You should ask your doctor
before taking aspirin if you are taking medicines for blood clots (thrombosis) such as warfarin or gout such as probenecid. 

Side effects In people sensitive to aspirin, reactions such as asthma attacks and skin rashes may occur occasionally. Aspirin may induce gastric
irritation, nausea, dyspepsia and stomach bleeding. Consult your doctor or pharmacist if you have any side effects after taking this product. 

ALKA-SELTZER (source: wvwv.drugstore.com)

Indications For fast relief of heartburn, acid indigestion, sour stomach with headache or body aches and pains.  Effective for pain relief
alone; headache or body and muscular aches and pains.

Directions 

Ingredients Active ingredient: per tablet: Aspirin (325mg) 

Drug interaction precautions Do not take this product if you are taking a prescription drug for anticoagulation (thinning the blood), diabetes,
gout, or arthristis unless directed by a doctor.  Ifyou are presently taking a prescription drug, do not take this product without checking with
your doctor or other health professionel.

Warnings Children and teenagers should not use this medicine for chicken pox or ﬂu symptoms before a doctor is consulted about Reye
Syndrome, a rare but serious illness reported to be associated with aspirin. As with any drug, if you are pregnant or nursing a baby, seek the
advice of a health professional before using this product. It is especially important not to use aspirin during the last three months of pregnancy
unless speciﬁcally directed to do so by a doctor because it may cause problems in the unborn child or complications during delivery.  Do not
take this product if you are allergic to aspirin or if you have asthma, bleeding problems or on a sodium restricted diet. If ringing in the ears or
a loss of hearing occurs, consult a doctor before taking any more of this product. If pain persists or gets worse, if new symptoms occur, or if
redness or swelling is present, consult a doctor because these could be signs of a serious condition. 

Alcohol warning If you consume 3 or more alcoholic drinks every day, ask your doctor whether you should take aspirin or other pain relievers
/ fever reducers. Aspirin may cause stomach bleeding.

Figure 1: Extraits de notices pour les médicaments ANADIN et ALKA-SELTZER

a sa relation possible avec la consommation d’alcool.

Malgré ces premieres différences, les notices dans le corpus que nous avons étudié expriment
généralement le meme type de contenu communicatif. Autrement dit, les buts communica-
tives exprimés par les auteurs de ces notices sont similaires. Toutefois, ce contenu peut etre
exprimé de nombreuses facons. Une analyse de la variation stylistique dans un corpus de 342
notices pharmaceutiques (Paiva, 2000) montre que deux facteurs importants opposent d’une
part l ’abstraction (ex. utilisation de passifs sans agents) a l ’engagement (ex. utilisation de
pronoms de la lere et 2eme personne et de l’impératif), et d’autre part la re’fe’rence complete a
la re’fe’rence pronominale. Au dela de cette variation dans l’expression linguistique de surface,
nous avons également constaté que des buts communicatifs similaires peuvent étre exprimés
avec des différences sémantiques plus ou moins importantes. Par exemple, il est admis en
médecine qu’on ne doit pas donner d’aspirine a des enfants ou in des adolescents ayant de la
ﬁevre ou d’autres symptomes d’une infection virale (particulierement la grippe et la varicelle)
sans avis médical, car cela peut causer une maladie grave appelée Syndrome de Reye. Les
avertissements en rapport dans nos deux exemples sont formulés ainsi:

ANA: Aspirin has also been associated with increased risk of Reye ’s Syndrome when given to
children with a fever For this reason the use of aspirin is not recommended in children under
12 years of age.

ALK: Children and teenagers should not use this medicine for chicken pox or ﬂu symptoms
before a doctor is consulted about Reye Syndrome, a rare but serious illness reported to be
associated with aspirin.

Ces deux fragments de texte véhiculent tres clairement des différences sémantiques: ALK men-

Aurélien Max

tionne par exemple qu’un docteur devrait étre consulté (a doctor should be consulted), alors
que ANA indique que l’aspirine n’est pas recommandée pour les enfants age de moins de 12
ans (aspirin is not recommended in children under 12). De méme, ALK fait référence aux en-
fants et aux adolescents ayant des symptomes de varicelle ou de grippe (children and teenagers
with chickenpox or ﬂu symptoms), et ANA fait référence aux enfants en état de ﬁevre (children
with a fever). Ces distinctions sémantiques révelent des choix différents faits par les auteurs
de ces notices. Toutefois, il existe bel et bien un but communicatif commun, qui pourrait étre
formulé comme suit: l ’aspirine ne doit étre administre’e que sous supervision me’dicale aux
enfants et adolescents pre’sentant des symptomes d ’une infection virale. Pour des documents
de l’importance des notices pharmaceutiques, on peut soutenir le fait que la cohérence dans
l’expression des buts communicatifs ainsi que dans la structure du contenu peut aider a une
compréhension claire et non-ambigiie. Ceci se retrouve dans des compilations de notices de
médicaments ayant été normalisées, comme Le Vidal de la FaInille (Vidal, 1998).

Les observations que nous avons faites nous permettent de donner une déﬁnition possible pour
la normalisation de documents. La normalisation d’un document dans un domaine de discours
particulier implique son analyse sous forme de représentation du contenu sémantiquement pos-
sible, et la production d’une version normalisée du document a partir de cette représentation.
Cette version normalisée exprime un contenu communicatifpre’de’ﬁni, présent sous quelque
forme dans le document source, avec une structure et une expression linguistique controlées.
Le contenu prédéﬁni révele des buts communicatifs, lesquels devraient idéalement étre décrits
par un expert du domaine de discours. Un tel but communicatif pour des notices pour des
médicaments contenant de l’aspirine mettrait en garde contre le Syndrome de Reye. Produire le
texte du document normalisé a partir d’une représentation du contenu permet de générer un mes-
sage pouvant étre considéré comme l ’e’talon or pour l’expression de ce concept (c’est-a-dire une
expression claire et largement acceptée adaptée au lecteur). Cela permet également d’obtenir
des structures de documents cohérentes ainsi que d’imposer des contraintes terminologiques et
stylistiques sur les textes produits.

2.2 Spéciﬁcation du contenu des documents

Le niveau de spéciﬁcation du contenu des documents que nous souhaitons utiliser pour la nor-
malisation de documents est donc celui des buts communicatifs (par opposition a un niveau
de sémantique exprimable en termes de formes logiques par exemple). Dans le cas de notre
exemple précédant concemant le Syndrome de Reye, nous ne souhaiterions n’avoir a spéciﬁer
que la présence du but communicatif riskOfReyeSyndrome dans la partie appropriée de la
représentation du contenu du document, et donc déléguer la production du texte pour exprimer
ce concept a un processus de génération propre.

La représentation du contenu d’un document doit étre complete et bien formée. Elle doit étre
complete par rapport a des attentes propres a la classe de documents (l’ensemble des documents
comparables dans un meme domaine de discours). Elle doit étre bienforme’e dans le sens ou sa
structure sémantique doit étre possible dans le domaine de discours considéré, et ou elle doit re-
specter les contraintes sémantiques pouvant exister entre ses sous-structures. Par exemple, une
telle contrainte pourrait exprimer que le type d’ administration pour un médicament dans la sous-
structure concemant les modes d’administration doit étre compatible avec la forme pharmaceu-
tique du médicament telle que spéciﬁée dans la sous-structure de description du médicament (de
sorte que l’on ne puisse spéciﬁer qu’un médicament sous forme de poudre doive étre croqué).

Normalisation de documents par analyse du contenu a l’aide d’un modele
sémantique et d’un générateur

Une telle modélisation de la sémantique des documents ne semble possible que pour des do-
maines de discours limités mettant en jeu des types de contenu prédéﬁnis, comme cela semble
etre le cas pour le corpus que nous avons étudié. Sous ces conditions, spéciﬁer le contenu d’un
document peut etre vu comme la deﬁnition d’un point dans l’espace sémantique du domaine de
discours considéré qui identiﬁe de facon unique le document.

2.3 Systémes de création de documents

On constate un intéret récent pour la recherche dans le domaine des systemes de création de
documents (Power et Scott, 1998; Brun et al 2000; Hallgren et Ranta, 2000; Coch et Chevreau,
2001). Cette recherche s’est principalement concentrée sur l’obtention des représentations du
contenu des documents par interaction avec l’utilisateur du systeme (Z ’auteur), et la production
de versions multilingues du document correspondant a ces representations spéciﬁées par les
choix de l’auteur. Typiquement, l’auteur doit faire des choix sémantiquement valides dans des
zones actives qui apparaissent dans le texte en évolution du document, lequel est généré au fur
et a mesure de la création du document dans la langue de l’auteur. Les selections ainsi faites
rafﬁnent itérativement la representation du contenu du document jusqu’a ce que celle-ci soit
complete.

Dans le systeme MDA (Multilingual Document Authoring) (Dymetman et al, 2000) (voir ﬁg-
ure 2), la speciﬁcation de representations du contenu des documents bien formées est décrite
récursivement dans un formalisme grammatical qui est une variante des Deﬁnite Clause Gram-
mars (Pereira et Warren, 1980). Un extrait de graInInaire tres simple pour une notice phar-
maceutique dans le formalisme MDA est donné en ﬁgure 3.3 La premiere regle se lit ainsi:
la structure sémantique |eaf|et(T,P,D,W,...)4 est de type patientLeaf|et; ce type est constitué
d’une structure title, d’une structure presentation, d’une structure directions, d’une structure
warnings, et d’une liste de structures n’apparaissant pas dans notre exemple. Les contraintes
sémantiques sont établies a l’aide de parametres de type partagés: par exemple, PersonCat-
egory contraint les structures presentation et warnings (ceci permettant d’eXprimer le type
de contrainte mentionné plus tot). La seconde regle indique que riskOfReyeSyndrome et de
type warnings(chi|dren).5 Cette regle illustre également la possibilité d’avoir des chaines de
caracteres dans les parties droites des regles, ce qui permet d’associer des réalisations textuelles
a des representations du contenu des documents.6

3 Un paradigme pour l’analyse de contenu automatique ap-

pliquée a la normalisation de documents

Comme nous l’ avons vu dans la section précédante, un systeme comme MDA permet de représenter
le contenu de documents bien formés ainsi que de produire des réalisations textuelles a par-

3MDA a deja été utilise pour la modélisation de notices phannaceutiques plus complexes (Brun et al 2000).

4Les points indiquent des Variables qui ne sont pas montrées.

511 s’ agit ici d’une simpliﬁcation pour l’exposition, puisque une telle structure contient habituellement plusieurs
avertissements, et qu’elle peut dépendre d’autre parametres.

5Le texte d’un document est obtenu en parcourant sa structure semantique et en concaténant les chaines de
caracteres de fagon ascendante, apres avoir eventuellement applique des contraintes de niveau morphologique qui
n’apparaissent pas dans notre exemple (Brun etDymet1nan, 2002)

Aurélien Max

'I- run In-|--.. II-urn.
_ I-an-..I I-l.u.-
»- .  . , .
1
I mu rr-:n".
in
-.|'I-1
1
Hr-
rh--in--uy
upuu-n.

Figure 2: Exemple de création de notice pharmaceutique a l’aide du systeme MDA

leaflet(T,P,D,W,...)::patientLeaflet ———>
T::title,
P:zpresentation(PharmaceuticalForm, Personcategory),
D::directions(PharmaceuticalForm),
W:zwarnings(Personcategory),

riskOfReyeSyndrome::warnings(children) ——>
[’Aspirin should not be given to children and teenagers with a fever or other symptoms of
a virus infection, especially flu or chickenpox, unless prescribed by a doctor, because
it may cause a serious illness called Reye’s Syndrome.’]

Figure 3: Extrait de grammaire MDA pour une notice pharmaceutique.

tir de ces représentations. Ainsi, un tel systeme peut étre utilisé pour faire l’énumération de
l’ensemble des documents possibles pour la classe de documents modélisée. En rendant la
grammaire de génération non-déterministe, on peut obtenir un nombre important de réalisations
textuelles associées avec des représentations du contenu des documents, rendant compte en par-
tie de la diversité rencontrée dans les corpus.

I1 existe de fortes motivations pour vouloir réutiliser des modeles sémantiques précédemment
développés pour de tels systemes de création de documents pour normaliser des documents
existants. La représentation du contenu d’un document a analyser peut étre obtenue par la re-
création des choix sémantiques, déﬁnis dans un modele sémantique donné, qui sont exprimés
dans ce document. Lorsqu’une représentation complete et bien formée est obtenue, le texte de
la version normalisée du document peut étre produit par la grammaire générative du systeme
de création de documents (éventuellement en plusieurs langues en utilisant des grammaires
paralleles).

3.1 Génération inversée ﬂoue

L’ analyse du contenu des documents est souvent abordée comme un probleme d’analyse syn-
taxique ou des représentations sémantiques sont composées a partir de structures syntaxiques
(Allen, 1995). Il est toutefois tres difﬁcile en pratique de développer des grammaires d’analyse

Normalisation de documents par analyse du contenu a l’aide d’un modele
sémantique et d’un générateur

syntaxique a couverture large qui soient robustes a la variabilité linguistique que l’on peut trou-
ver dans les textes. De plus, faire la correspondance entre une representation sémantique dérivée
d’une structure syntaxique et un but communicatif (notre niveau cible) n’est en general pas triv-
ial. Nous proposons donc un paradigme pour l’analyse du contenu en domaine limite’ et bien
déﬁni qui inverse cette vue en se concentrant sur la notion de génération inversée ﬂoue a partir
de structures sémantiques produites par un modele (Max et Dymetman, 2002).

Un modele MDA peut etre utilise pour faire l’énumération de l’ensemble des representations
du contenu de documents bien formées pour sa classe de documents, et associer des réalisations
textuelles a ces representations par un processus de generation. Nous appellerons ces réalisations
les documents virtuels du modele sémantique, parce que ces documents n’existent pas avant
d’avoir été effectivement produits par le modele. Conceptuellement, pour normaliser un docu-
ment nous souhaiterions trouver le document virtuel le plus proche du document a analyser en
termes des buts communicatifs qu’il exprime. Nous pourrions alors considérer sa representation
du contenu associée comme une approximation de celle du document a analyser. La génération
inversée intervient a ce niveau, puisque les predictions faites par la grammaire de generation a
partir de representations bien formées peuvent etre utilisées pour mesurer une certaine forme
de similarité entre deux documents. Mais puisque la grammaire de generation sous-génere rel-
ativement a l’ensemble des textes qui expriment le meme contenu communicatif, nous utilisons
un méchanisme de correspondance ﬂoue pour faire l’estimation d’une mesure de similarité qui
essaie de rendre compte de la quantité de contenu communicatif partagée par deux textes.

3.2 Similarité de contenu entre deux textes

Nous avons déﬁni notre notion de similarité de contenu a partir du fait, généralement accepté
dans le domaine de la recherche d’information, que plus deux textes partagent de termes et de
termes lies (ex. grossesse et enceinte), et plus ils sont succeptibles d’etre a propos du meme
sujet. Le contenu d’un texte peut etre grossierement approximé par un vecteur contenant les
formes lemmatisées des termes et leur nombre d’occurrences. Nous appelons un tel vecteur le
proﬁl lexical d’un texte. Aﬁn de rendre compte de la variation lexico-sémantique, les elements
d’un proﬁl lexical sont en fait des ensembles de synonymes au sens de WordNet (synsets), ce
qui permet a la fois d’avoir une representation lexicalement désambiguisée et d’identiﬁer les
termes equivalents (Gonzalo et al, 2000).

La mesure de similarité que nous cherchons a évaluer doit rendre compte de la quantité de
contenu communicatif commun a deux textes (dans un premier temps, nous ne considérons pas
la masse communicative qui est propre a chaque texte7). Une telle mesure de similarité peut
donc etre obtenue par une mesure d’intersection entre les proﬁls lexicaux des deux textes. De
plus, les elements presents dans les proﬁls lexicaux ne participent pas de la meme facon a la
caractérisation de leur contenu communicationnel, c’est pourquoi la mesure d’intersection est
pondérée par une valeur d’ informativité. Dans notre implementation initiale, nous donnons une
informativité nulle aux mots fonctionnels, et une informativité dérivée de leur fréquence inverse
dans un corpus aux ensembles de synonymes (ainsi, un terme (ainsi que ses synonymes) appa-
raissant peu souvent, comme ﬁévre, partipera davantage a l’intersection qu’un terme apparais-
sant plus souvent, comme médicament). La formule suivante donne cette mesure de similarité.
0ccsL1(sg/nset) est le nombre d’occurrences de synset dans le proﬁl lexical L1, et in f (synset)

\

7Sous cette hypothése, le processus de normalisation peut etre compare a un processus d’extraction
d’ information, ou encore de résumé automatique en domaine contraint.

Aurélien Max

— creer une liste vide de representations du contenu (OPEN)
— creer une liste vide de candidats (CAND) (representations du contenu completes)
— mettre le type ’document’ (representation partielle initiale d’un document) dans OPEN
— repeter jusqu’é ce que N candidats aient ete trouves
— enlever le premier element de OPEN
— si cet element est une representation du contenu complete l’ajouter 3 CAND
— sinon pour chacun de ses successeurs, calculer leur similarite avec le texte
source et les inserer dans OPEN par similarite decroissante

Figure 4: Algorithme de recherche des structures candidates

son informativité.

sim(L1, L2) = Z mz'n(occ3L1(3;4/nset), 0ccsL2(3yn3et)) >s< z'nf(synset)
synset€L1,L2

3.3 Recherche admissible des structures candidates

En pratique, nous ne souhaitons pas comparer l’ensemble des documents virtuels au docu-
ment a analyser. Nous proposons donc une recherche heuristique qui garantie, grace a son
caractere admissible (Nilsson, 1998), que les N premiers documents trouvés sont les N plus
similaires avec le texte a analyser. L’hypothese qui est faite ici est que la mesure de similarité
et la valeur de N choisies permettent de garantir que le meilleur candidat pour la normalisa-
tion du document a analyser se trouve dans la liste retournée. La procédure est similaire a une
analyse syntaxique descendante ou des représentations partielles du contenu des documents
sont itérativement construites en tenant compte d’une mesure de similarité avec le texte a anal-
yser. La recherche est admissible si elle suit une stratégie en meilleur d ’ab0rd, et si la fonction
d’évaluation utilisée est optimiste, c’est-a-dire qu’elle sur-estime la valeur réelle de la simi-
larité entre le document source et quelque document virtuel pouvant étre produit £1 partir d ’une
representation partielle du contenu d ’un document d0nne’e. De plus, la fonction d’évaluation
doit décroitre au fur eta mesure de la progression de la recherche. Un noeud dans l’espace de
recherche est une représentation partielle du contenu d’un document, et ses successeurs peuvent
étre obtenus en appliquant un pas de dérivation dans la grammaire (une variable non-instanciée
dans une représentation partielle d’un document recoit une valeur compatible avec son type),
puis en éliminant les représentations obtenues qui ne respectent pas les contraintes sémantiques
imposées par le modele. L’algorithme donné en ﬁgure 4 est une implementation d’une telle
recherche qui examine a chaque itération le noeud avec la meilleure évaluation et retourne la
liste des N meilleures structures candidates.

3.4 Similarité de contenu entre une représentation partielle et un texte

La fonction d’évaluation que nous utilisons est l’intersection pondérée entre deux proﬁls lexi-
caux: l’un est celui du document a analyser, l’autre est celui d’une représentation du contenu
partielle. Nous pouvons déﬁnir la notion de proﬁl lexical pour les types de la grammaire en
propageant les proﬁls lexicaux obtenables pour les terminaux (chaines de caracteres) de la
grammaire. Un type donné peut avoir plusieurs réalisations, qui correspondent toutes a une
collection de textes virtuels. Le proﬁl lexical d’un type doit donner une mesure du nombre

Normalisation de documents par analyse du contenu a l’aide d’un modele
sémantique et d’un générateur

— construire le profil lexical d’un type T
— pour chacune de ses réalisations REA
— pour chaque element dans REA construire son profil lexical s’il n’a pas déja
été construit
— calculer le profil lexical pour REA en sommant les nombres d’occurrences de
chaque element
— calculer le profil lexical pour T en prenant le maximum d’occurrences pour chaque
element dans chacune de ses réalisations
— indiquer le profil lexical de ce type T comme ayant été construit

Figure 5: Précompilation des proﬁls lexicaux des types de la grammaire

maximum d’occurrences des membres d’un ensemble de synonymes pouvant etre obtenu en
dérivant ce type de toutes les facons possibles. Le proﬁl lexical pour la réalisation d’un type
(la partie droite d’une regle) peut étre obtenu en prenant une union des proﬁls lexicaux de
l’ensemble de ses éléments qui somme le nombre d’occurrences pour chaque élément.

Le proﬁl lexical d’un type peut etre alors obtenu en prenant pour chaque élément son nom-
bre maximum d’occurrences dans chacune des réalisations pour ce type. Cela reﬂete le fait
que quelle que soit la dérivation qui est faite a partir d’un type, un élément donné ne peut ap-
paraitre dans un texte produit a partir de cette dérivation plus d’un certain nombre de fois. Un
processus de précompilation récursif de la grammaire permet de construire les proﬁls lexicaux
pour l’ensemble des types de la grammaires (voir ﬁgure 5).8 Finalement, le proﬁl lexical d’une
représentation partielle est l’union (sommant les nombres d’occurrences) des proﬁls lexicaux
pour les types de toutes ses variables non-instanciées (les parties non-spéciﬁées) et de ses frag-
ments de texte (les parties connues). On peut facilement montrer que la mesure de similarité
par intersection donnée plus tot ne peut que décroitre ou rester constante au fur et a mesure que
des représentations partielles sont rafﬁnées, satisfaisant ainsi les contraintes d’admissibilité.

3.5 Implémentation initiale et critéres d’évaluation

Nous avons développé un prototype initial utilisant une grammaire hors-contexte qui est une
simpliﬁcation d’une grammaire MDA pour des notices pharmaceutiques, qui utilise le lemma-
tizer de notre laboratoire (XRCE, Finite-state linguistic components). Un nouveau prototype
supportant le formalisme MDA est en cours de développement dans le cadre de notre travail.
Le processus de normalisation peut etre inspecté en lisant et comparant les textes retournés
avec le texte source. Nous souhaitons mettre en place une procédure d’évaluation automatique
qui comparera les représentations du contenu de documents issus d’un corpus de test ayant été
‘manuellement’ analyses in l’aide de l’interface de MDA avec celles obtenues pour le document
source.

8La Version de l’algorithme donnée est pour une grammaire non—récursiVe, mais elle peut étre adaptée au cas
d’une grammaire récursive si l’on autorise une Valeur inﬁnie (en pratique, une borne supérieure) pour le nombre
d’ occurrences d’un mot.

Aurélien Max

4 Conclusions et perspectives

Nous avons introduit la problématique de la normalisation de documents, et nous avons pro-
pose un paradigme et une implementation possibles pour l’analyse du contenu de documents
utilisant un modele sémantique et la génération inversée ﬂoue. L’ approche que nous avons pro-
posée est plus simple a implémenter qu’une grammaire d’analyse syntaxique, mais elle permet
néanmoins d’obtenir une certaine robustesse a la variabilité linguistique présente dans les doc-
uments analyses. 11 nous reste encore a évaluer les limites des techniques simples que nous
utilisons pour la mesure du contenu communicatif commun entre textes. I1 faut toutefois re-
marquer que malgré le caractere simple de la mesure de similarité utilisée, beaucoup de fausses
analyses ne seront jamais considérées: en effet, seules les representations du contenu pouvant
étre produites par le modele entrent en competition, ce qui joue déja pour une part importante
dans la discrimination des candidats.

Nous considérons néanmoins l’approche proposée comme une premiere passe pour la normal-
isation de documents: une fois qu’un nombre ﬁni de documents virtuels a été isolé, des tech-
niques plus complexes de traitement des langues peuvent étre appliquées sur ces documents.
Celles-ci peuvent aller par exemple de la simple mesure de proximité entre mots jusqu’a la
mise en correspondance de dépendances telles que retoumées par un analyseur syntaxique ro-
buste, tout en gardant en compte que l’on cherche avant tout a déterminer la présence de buts
communicatifs communs. Finalement, un expert de la classe de documents pourrait intervenir
dans une phase de désambiguisation interactive.

Références

James Allen (1995), Natural Language Understanding, 2eme édition, Benjamin/Cummings.

Avi Arampatzis, Th. P. van der Weide, P. van Bommel, C.H.A. Koster (2000), Linguistically Motivated Information Retrieval, Encyclopedia of
Library and Information Science, Marcel Dekker, Vol. 69, 2000.

Dominique Dupagne, Pauline Groleau, Colette Pecquet, Marie-Catherine Bonjean (1998), Le Vidal de la Famille, OVP Editions du Vidal,
Hachette, Paris.

Caroline Brun, Marc Dymetman, Veronika Lux (2000), Document Structure and Multilingual Authoring, Actes de INLG 2000, Mitzpe Ramon,
Isra'e'l.

Caroline Brun, Marc Dymetman (2002), Rédaction Multilingue Assistée dans le Modele MDA, Dans Multilinguisme et Traitement de
l’Information, Frédérique Segond éditeur, Hermes.

José Coch, Karine Chevreau (2001), Interactive Multilingual Generation, Actes de CICLING 2001, Mexico, Mexique.

Marc Dymetman, Veronika Lux, Aarne Ranta (2000), XML and Multilingual Document Authoring: Convergent Trends, Actes de COLING
2000, Saarbrucken, Allemagne.

Julio Gonzalo, Felisa Verdejo, Irina Chugur, Juan Cigarran (1998), Indexing with WordNet Synsets Can Improve Text Retrieval, Actes du
COLING/ACL-98 Workshop on the Usage of WordNet in Natural Language Processing Systems, Montréal, Canada.

T. Hallgren et A. Ranta (2000), An Extensible Proof Text Editor, M. Parigot et A. Voronkov éditeurs, Logic for Programming and Automated
Reasoning, LPAR’2000, Springer Verlag, Heidelberg.

Aurélien Max et Marc Dymetman (2002), Document Content Analysis through Inverted Generation, AAAI Spring Symposium on Using (and
Acquiring) Linguistic (and World) Knowledge for Information Access, Stanford University, Etats-Unis.

Nils J. Nilsson (1998), Artiﬁcial Intelligence: a New Synthesis, Morgan Kaufmann.

Daniel S. Paiva (2000), Investigating Style in a Corpus of Pharmaceutical Leaﬂets: Results of a Factor Analysis, Actes du ACL 2000 Student
Research Workshop, Hong Kong.

Fernando Pereira, David Warren (1980), Deﬁnite Clauses for Language Analysis, Artiﬁcal Intelligence, Vol. 13, 1980.
Richard Power, Donia Scott (1998), Multilingual Authoring using Feedback Texts, Actes de COL.ING/ACL-98, Montréal, Canada.

Xerox Research Centre Europe, Finite-state linguistic components,
http://wvvw.xrce.xerox.com/research/mltt/fsnlp.

