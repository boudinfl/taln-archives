RÉCITAL 2002, Nancy, 24–27 juin 2002
Un Modèle Distribué d’Interprétation de Requêtes fondé sur
la notion d’Observateur
Guillaume Pitel
LIMSI-CNRS F-91403 Orsay CEDEX
pitel@limsi.fr
date de soutenance prévue : fin 2003
Résumé - Abstract
Nous proposons un modèle de conception d’agent conversationnel pour l’assistance d’interface.
Notre but est d’obtenir un système d’interprétation de requêtes en contexte, générique pour l’in-
dépendance vis-à-vis de la tâche, extensible pour sa capacité à intégrer des connaissances sur
un nouveau domaine sans remettre en cause les connaissances antérieures et unifié dans le sens
où tous les aspects du traitement de la langue naturelle, syntaxe, sémantique, ou pragmatique
doivent s’exprimer dans un même formalisme. L’originalité de notre système est de permettre de
représenter des connaissances d’interprétation de niveaux de granularité divers sous une même
forme, réduisant la problématique de communication entre sources de connaissances qui existe
dans les systèmes modulaires. Nous adoptons l’approche des micro-systèmes suivant laquelle
l’interprétation de la langue se fait selon un processus non stratifié, et où absolument tous les
niveaux peuvent interagir entre eux. Pour cela, nous introduisons et définissons un type d’entité
que nous avons nommé observateur.
This paper describes a conversationnal agent design model for interface assistance. The model
is meant to be generic, i.e. task independant extensible for the ability of integrating know-
ledge about a new task without revising previous knowledge, and unified because every level
of Natural Language, from syntax, semantics, pragmatics and dialogue to production should be
described within the same formalism. The main originality of the proposed system is its abi-
lity to represent in the same way various granularity levels of interpretation knowledge sources.
This avoids communication problems between heterogeneous knowledge sources, as they occur
in modular systems. Thus we adopt a micro-systemics approach, stating that the Natural Lan-
guage Interpretation, rather than being made of multi-layered processes, a process where all the
components levels can interact with each others. This is achieved by introducing the notion of
observer.
Mots-clefs – Keywords
Agents Conversationnels, Analyse Distribuée, Micro-Systèmes, Sémantique Procédurale
Conversationnal Agents, Distributed Analysis, Micro-Systems, Procedural Semantics
1 Cadre et problématique
Le projet InterViews (Sansonnet, 1999) se donne pour objectif de concevoir un système de dia-
logue en langue naturelle pour supporter l’exécution d’agents assistants d’interface. Nous nous
situons dans le cadre des applications interactives disponibles sur la toile. Le projet regroupe
des travaux sur le raisonnement sur le fonctionnement des composants (Sabouret & Sansonnet,
2001), l’analyse de textes par motifs et proximité sémantique (Gérard & Sansonnet, 2000), et
sur un modèle d’interprétation des questions sur la structure des composants. A long terme,
l’objectif de ce projet est de pouvoir proposer un environnement de conception d’interfaces en
langue naturelle, à partir du système de dialogue proposé et des différentes recherches citées
précédemment. Concernant la langue naturelle, nous devrons vérifier par l’expérimentation les
problématiques d’analyse et d’interprétation qui seront ainsi supportées. Notre travail en étant
au stade préliminaire, nous n’avons cependant pas encore abordé le cas pratique de l’utilisateur
final, primordial dans le domaine de l’interface homme-machine.
1.1 Problème de la généricité dans l’interaction en langue naturelle
La maîtrise de l’Interaction en Langue Naturelle (ILN) entre un utilisateur et une interface d’ap-
plication grand public a pour but de permettre à une personne non initiée d’accéder rapidement
aux fonctionnalités d’un logiciel. Il existe des réalisations permettant de commander certains
types d’applications (Goddeau et al., 1994; Allen et al., 1996; Bennacef et al., 1996; Lamel
et al., 1998) par la voie de la langue naturelle, mais il n’y a pas actuellement de modèle de des-
cription générique permettant de définir pour n’importe quelle tâche son interface en langue
naturelle. D’une part, les systèmes existants sont en grande partie conçus de manière ad hoc,
et d’autre part, on ne sait toujours pas dire pour une application donnée si on est capable de
produire son interface de langue naturelle. C’est pourquoi des chercheurs comme (Allen et al.,
2001a) ont posé clairement la problématique de produire des outils génériques pour l’ILN :
(après avoir posé l’hypothèse de l’indépendance vis-à-vis du domaine dans le
cadre des dialogues pratiques) « Si cette hypothèse est vraie, il est rentable de s’in-
vestir massivement dans la conception d’un système de dialogue générique, qui
sera alors assez facilement adaptable à chaque nouvelle tâche. »1
1.2 Vers un système d’ILN générique, extensible et unifié
Les premières tentatives pour produire des systèmes d’ILN ont suivi des approches monoli-
thiques, fortement dépendantes de la tâche de dialogue spécifique à laquelle on les destinait.
Depuis, des modèles issus des systèmes multi-agents (Carvalho et al., 1998; Stefanini & De-
mazeau, 1995), et s’appuyant sur la communication entre modules de traitement indépendants
ont fait l’objet de recherches approfondies (Sabah, 1990; Boitet & Seligman, 1994; Stefanini &
Demazeau, 1995), et certains produisent déjà des résultats encourageants (Allen et al., 2001b).
L’adaptation de ces systèmes à une nouvelle tâche est plus aisée que dans les systèmes monoli-
thiques, puisque seuls quelques modules doivent être modifiés. Cependant il reste pour l’instant
1« If this hypothesis is true, it is worthwhile to spend a considerable effort building a generic dialogue system
that can then be adapted to each new task relatively easily ».
Un Modèle d’Interprétation de Requêtes G. Pitel
impossible de concevoir un système de dialogue permettant de décrire simplement n’importe
quelle tâche.
Ces limitations nous ont conduit à proposer trois axes majeurs autour desquels les systèmes de
dialogue modernes devraient être conçus : la généricité, l’extensibilité, et l’unité de la descrip-
tion. La généricité pour l’indépendance vis-à-vis de la tâche, l’extensibilité pour sa capacité à
intégrer des connaissances sur un nouveau domaine sans remettre en cause les connaissances
antérieures, et l’unité dans le sens où tous les aspects du traitement de la langue naturelle,
syntaxe, sémantique, pragmatique, dialogue ou réponse par production linguistique ou action,
doivent s’exprimer dans un même formalisme, et donc tous communiquer entre eux de la même
manière, ce qui facilite l’ajout de nouvelles sources de connaissances.
Notre vision d’un système d’ILN adopte une approche fortement distribuée et à granularité va-
riable de l’interprétation. Notre système de dialogue possède trois caractéristiques principales :
Environnement L’interprétation est idéalement appliquée à tout l’environnement, c’est-à-dire
que l’analyse ne porte pas seulement sur la phrase que vient de prononcer l’utilisateur,
mais sur l’ensemble du dialogue passé ainsi que les informations concernant l’application
ou les applications auxquelles le système sert d’interface.
Médiateur Le système d’ILN suit l’approche médiateur, qui implique que l’analyse doit non
pas amener à un formalisme de représentation centralisé (langage pivot) pour être ensuite
interprété de manière ad hoc, mais aller de l’observation à l’action grâce a un système
unifié.
Observateurs L’interprétation est représentée par des observateurs, entités remplaçant les règles
de réécriture d’un système d’analyse classique. Ils sont capables de donner un point de
vue sur l’environnement (ou la partie de l’environnement) qu’ils observent, ce point de
vue pouvant se traduire par une action.
2 Orientations théoriques
2.1 Théorie des Affordances
La théorie des affordances (de to afford : fournir en anglais) de l’environnement sur les individus
telle qu’elle est définie par (Gibson, 1977; Gibson, 1979), propose que la perception ne consiste
pas à capter les dimensions et les propriétés absolues des objets de l’environnement, mais à cap-
ter les caractéristiques que ces objets fournissent, exposent aux observateurs. (Norman, 1988;
Norman, 1990) en fait l’interprétation suivante : « la référence aux objets et concepts se fait tels
qu’ils sont vus (perçus, catégorisés) par l’observateur », c’est-à-dire en fonction du phénomène
de ces objets et concepts, et non pas en fonction de leurs caractéristiques implémentatoires.
Nous appellons phénomène d’un objet son expression à travers le point de vue d’un observa-
teur donné, ce qu’il donne à voir de lui à celui-ci. En cela, le phénomène n’a pas de réalité en
l’absence d’un observateur, et pour chaque observateur, il existe un phénomène différent.
A partir de cette théorie, nous avons choisi de concevoir notre système de dialogue comme un
médiateur, c’est-à-dire un système capable de faire le lien entre deux visions différentes du
monde : celle de l’utilisateur et celle de l’application. Notre système sera articulé autour de
l’idée sous-jacente de changement de point de vue, afin d’amener le point de vue de l’utilisa-
teur vers le point de vue de l’application par traitements successifs.
2.2 Sémantique Procédurale
La théorie de la sémantique procédurale introduite par (Wittgenstein, 1953) et reformulée par
(Johnson-Laird, 1977; Woods, 1981) pour les applications informatiques, a posé les bases d’une
vision fonctionnelle de la signification. En effet, ses initiateurs proposent de considérer le sens
d’un symbole (puis par extension, de toute observation) comme sa réalisation ou encore son
application dans le monde réel par l’action de l’observateur. La sémantique n’a donc pas d’exis-
tence autre que celle de son expression dans un environnement, ce qui implique qu’il ne peut
être remplacé que par un processus réalisant son interprétation. (Woods, 1981) exprime cette
idée de la façon suivante :
« [. . .] la signification d’un symbole réside dans une procédure abstraite, pas
nécessairement exécutable, qui fait le lien entre l’expression symbolique et le monde
réel par l’intermédiaire des opérations (de calcul, d’inférence) d’un interprète
physique agissant à la fois sur des représentations internes et sur ses connexions
sensori-motrices avec le monde. »2
L’un des travaux appliquant cette théorie est le classique SHRDLU de (Winograd, 1973). La
difficulté d’étendre son application hors du micro-monde où elle était cantonnée a bloqué le
développement de son idée pourtant très prometteuse. C’est donc très probablement dans cette
extension qu’il faut travailler pour proposer des systèmes de dialogue ayant des caractéristiques
de généricité améliorées.
2.3 Analyse guidée
Le Word Expert Parsing (Small, 1980; Adriaens & Devos, 1994) est une théorie de la com-
préhension du langage naturel, fondée sur l’hypothèse que les objets du langage (les mots et
leur morphologie) sont individuellement autant porteurs d’information sur leur propre analyse
que d’information sémantique. Un système de compréhension du langage naturel devrait donc,
selon cette idée, diriger son analyse en fonction de la connaissance (pragmatique, sémantique,
lexicale, morphologique) apportée par chaque mot.
Cette représentation décentralisée du processus d’analyse conduit le système à se reposer sur
les actes de communication entre experts pour l’échange d’informations et les choix à faire
concernant la signification globale vers laquelle le système doit se diriger. Pour contrôler cette
population d’experts, chacun d’entre eux doit être décrit de manière à se mettre en pause lors-
qu’il a besoin d’information provenant d’un autre expert, et à reprendre son activité lorsque
cette information arrive.
2« [. . .] the meaning of a symbol resides in an abstract procedure, not necessarily executable, linking the sym-
bolic expression to the physical world through the (computational / inferential) operations of a physical interpreter
operating on a combination of internal representations and sensory/motor connections to the world. »
Un Modèle d’Interprétation de Requêtes G. Pitel
3 Proposition d’un modèle d’ILN
3.1 Notion de granularité
Dans l’ILN, le problème de la granularité de l’interprétation se pose à deux niveaux :
– au niveau abstrait, la granularité de l’objet de l’interprétation. Ce sur quoi porte l’inter-
prétation (le mot, la phrase, le dialogue, ou la morphologie, la syntaxe, la sémantique, la
pragmatique, etc.).
– au niveau concret, la granularité de l’objet d’interprétation. Ce avec quoi on conduit celle-ci
(la forme prise par le logiciel d’analyse).
Dans les systèmes de dialogue comme (Sabah, 1990; Allen et al., 2001b), l’interprétation porte
sur la syntaxe, la sémantique, la pragmatique, la planification de tâche et d’autres niveaux, et
chaque niveau est implémenté par un module. L’objet de l’interprétation et l’objet d’interpréta-
tion ont donc la même granularité moyenne3.
Dans les systèmes comme (Small, 1980), l’interprétation est conduite à partir de et par les mots,
l’objet de l’interprétation a donc une granularité très grosse (restreinte au mot). En revanche,
comme chaque mot doit être interprété, la granularité de l’objet d’interprétation est fine.
Notre objectif en proposant ce modèle est d’offrir dans les deux cas une granularité variable à
champ large (couvrant un maximum de niveaux), répondant aux besoins de l’interprétation des
différents niveaux de la langue, y compris en autorisant des interprétations nécessitant la prise
en compte simultanée de plusieurs niveaux.
3.2 Notation de l’environnement
L’application et le dialogue avec l’utilisateur sont décrits en texte et annotés avec des balises
dans un formalisme proche de XML, mais se différenciant de ce dernier par plusieurs aspects.
En effet, il nous faut, grâce à ces balises, marquer des zones éventuellement discontinues, en
leur donnant un contenu et une identification unique. Pour cela, nous avons choisi le formalisme
de balisage suivant :
<T id = ’%IDUN%’ attribut1 = ’valeur1’ ... attributN = ’valeurN’>...</T id =
’%IDUN%’>...<T id = ’%IDUN%’>...</T id = ’%IDUN%’>
Où T est le type utilisé pour la reconnaissance, %IDUN% est une clef unique dans l’environ-
nement permettant d’identifier la zone, attribut et valeur sont des informations utilisables par
les observateurs, qui correspondent au type T donné dans la balise. Les portions de l’environne-
ment délimitées par une balise de type <T id=’xxx’ v1=’...’ v2=’...’>...</T id=’xxx’> sont ainsi
marquées comme pouvant être interprétées comme des entités T avec les attributs v1 et v2 ayant
leurs valeurs données. On aura donc par exemple (incomplet) :
<effacer id=’1’>Efface-moi</effacer id=’1’> <liste-mels id=’4’ contenu=’mel1,
mel23, ..., mel54’><liste-mels id=’2’ contenu=’mel1, mel2, ..., melN’>tous les
méls</liste-mels id=’2’> <date-restr id=’3’ condition = ’annees( aujourdhui() -
date(*) ) > 4’>de plus de quatre ans</date-restr id=’3’></liste-mels id=’4’>
3Entre 10 et 50 modules environ, chacun travaillant sur un niveau de la langue naturelle.
De plus, nous cherchons à vérifier la cohérence entre deux balises, c’est-à-dire le fait que les
deux interprétations données par deux balises ne soit pas contradictoires. En effet, si un obser-
vateur reconnait une certaine combinaison de balises, et que celles-ci sont présentes dans l’envi-
ronnement, mais en provenance d’observations contradictoires (se recouvrant l’une l’autre, par
exemple), il ne faut pas que son point de vue soit pris en compte. Afin de savoir si une balise est
cohérente avec une autre, chaque balise créée devra ainsi conserver les identifiants des balises
qu’elle a reconnu faire partie du motif de sa règle d’activation.
3.3 Représentation du processus d’interprétation
La théorie de la sémantique procédurale implique que, quelque soit le niveau de granularité
de l’observation auquel on se place (le mot, la phrase ou un échange verbal complet) l’entité
observée peut être considérée comme le déclencheur d’une fonction dont le résultat va être
la réaction de l’observateur. Or si nous partons du postulat que cette théorie est applicable à
tous les niveaux, cela signifie que la fonction totale est le produit de l’interaction de fonctions
d’observation à des niveaux inférieurs.
Selon la théorie de la sémantique procédurale, quelque soit le niveau de granularité de l’objet
de l’interprétation auquel on se situe, il existe une procédure interprétant la signification des
symboles observés. Nous choisissons pour cette raison de représenter le processus d’interpréta-
tion avec de nombreux processus spécifiques plutôt qu’avec quelques modules génériques, ceci
afin d’obtenir justement la généricité de l’interprétation.
3.4 Mise en œuvre
3.4.1 Observateurs
Conceptuellement, un observateur exprime un point de vue sur ce qu’il « voit ». Son champ
d’observation est principalement tourné autour du langage, mais il inclut aussi les perceptions
auxquelles il a accès, c’est-à-dire la représentation de l’application et l’historique du dialogue.
Un observateur va donc « voir » certaines balises à certaines positions les unes par rapport
aux autres, et écrire une interprétation de cette vision à partir de sa connaissance propre (sa
procédure de réécriture).
Formellement, un observateur est composé de trois éléments : une règle d’activation  , un
mode d’activation  , et un procédure de réécriture  où  est le type de la balise produite par
 
la procédure.
– La règle d’activation est implémentée par une fonction d’appariement appliquée sur l’en-
vironnement. Elle va déterminer s’il existe des éléments dans l’environnement susceptibles
d’être interprétés par la procédure de réécriture  .
 
– Le mode d’activation  permet de déterminer le comportement de l’observateur pour le
mécanisme de prédiction expliqué plus loin. Le concepteur de l’observateur fait le choix du
mode d’activation (par défaut, on considère qu’un observateur est réactif et proactif à la fois) :
réactif s’il réagit à la présence de certaines balises dans l’environnement.
proactif s’il réagit au fait que d’autres observateurs attendent la balise qu’il sait produire.
– La procédure de réécriture  peut avoir trois actions différentes, au choix du concepteur :
 
Un Modèle d’Interprétation de Requêtes G. Pitel
– si l’observateur produit seulement une information pour d’autres observateurs,  modifie
 
l’environnement en rajoutant des balises , par exemple (<adjectif ><nom>bleu</adjectif >-
</nom> deviendra <couleur rvb=#0000FF><adjectif ><nom>bleu</adjectif ></couleur>-
</nom>)
– si l’observateur doit agir sur l’environnement,  effectue une opération sur l’application,
 
en appelant une fonction, ou en modifiant des données
– si l’observateur doit agir sur l’utilisateur,  produit un message pour celui-ci.
 
3.4.2 Mécanisme de prédiction
Pour diminuer la complexité du traitement, mais aussi pour assurer la convergence de notre
système, la théorie du Word Expert Parsing, et plus généralement les travaux sur les méthodes
d’analyse guidées par prédiction nous ont conduit à intégrer dans notre processus d’interpréta-
tion le fait qu’un observateur va avoir besoin pour être déclenché de la présence de certaines
balises dans l’environnement sur lequel il est appliqué. Par exemple, considérons un observa-
teur qui reconnait ce motif :
<ordre><transferer>...</transferer><designation_message>...
</designation_message><designation_destinataire>...</designation_destinataire>
</ordre>
Cet observateur aura besoin des balises ordre, transferer, designation_message, designation_desti-
nataire. Si les balises ordre et transferer ont déjà été produites par l’exécution de procédures
d’autres observateurs, il y a une chance importante que la suite de la phrase corresponde au
motif reconnu par cet observateur.
Le fait qu’un observateur ait presque tous les objets dont il a besoin va ainsi être interprété
comme le fait qu’il attend certains objets encore absents. Le déclenchement de l’action d’un
observateur va donc être dirigée aussi bien par la présence ou non de certaines balises dans
l’environnement que par le fait que la balise qu’il produit soit attendue ou non par d’autres
observateurs.
Nous mettons ce mécanisme en œuvre en calculant le graphe de connexion implicite4 de la
population d’observateurs (cf. fig 1).
3.4.3 Algorithme d’interprétation
L’algorithme d’interprétation de l’environnement est une boucle qui s’exécute sans fin, et à
chaque tour, on suit le cheminement suivant :
4La règle d’activation des observateurs est une fonction d’appariement portant sur les balises dont les types
sont ceux des procédures de réécriture. Nous considérons que le type de balise produit par un observateur est
connu à l’avance par le mécanisme d’interprétation. De fait, il se forme donc un graphe statique de propagation
de l’analyse dans la population des observateurs, les noeuds du graphe étant les observateurs, les entrées du noeud
sont les concepts attendus dans la règle d’activation, la sortie est le type de la procédure de réécriture.
L’existence de ce graphe va nous permettre de guider l’analyse par une recherche accélérée des chemins pos-
sibles pour la satisfaction des prédictions. Il permettra non seulement de réduire le nombre de règles essayées pour
trouver les observateurs à déclencher, mais aussi de trouver les chemins les plus probables pour arriver à obtenir
un certain type de balise dans une certaine zone.
ENVIRONNEMENT
<dialogue> <application>
<transmettre−message><ordre> <liste−dest nom="amis"><ami>
transmet ce message à Jean−Paul <nom>hermier</nom><prénom>.....
</ordre></transmettre−message> ....</liste−dest><mels><mel−grp nom=
.... "LIMSI">...</mel−grp><mel−grp
.... nom="copains"><mel><auteur nom=
"\nico"><sujet>Je suis là</sujet>
Requête <phrase>Est−ce que j’ai reçu des <contenu>...</contenu>
méls de mes amis récemment ?
....
</phrase> </application>
</dialogue>
Utilisateur OBSERVATEURS
O1:={R=(<ordre><transmettre−mes−
−sage>....<message>M...<destina−
−taire>D</destinataire></ordre>)
M=(réactif)
Réponse Paction = (forward_mail(M,D))}
...
O8:={R = (<mel num=pluriel>...</mel><de>
...<de><liste−envoyeurs>...</liste−
envoyeurs>)
M = (proactif) Graphe implicite
Pliste−mels = (mels=select * from mels etc.) de connexions
...
FIG. 1 – Fonctionnement général du système d’analyse d’InterViews. Exemple de traitement
sur des objets de haut niveau, ici des listes de méls.
1. l’algorithme étudie les concepts nouvellement entrés dans l’environnement d’observation,
– soit par l’action des observateurs,
– soit par l’action de l’utilisateur (lorsqu’il produit une phrase),
– soit par l’action de l’application.
2. En priorité, on tente de satisfaire les demandes des observateurs en attente de balises,
grâce à un algorithme de planification, permettant de trouver les chemins possibles dans
le graphe de connexion des observateurs. Cette première étape permet de classer les obser-
vateurs à activer plus tard, et surtout à autoriser l’activation des observateurs uniquement
proactifs.
3. Ensuite, à partir des balises nouvellement arrivées, on va chercher dans le graphe de
connexion des observateurs réactifs et des observateurs proactifs rendus activables à
l’étape 2, ceux qui ont une de ces balises dans leur règle d’activation.
4. En exécutant la règle d’activation, on vérifie si les observateurs ainsi recensés deviennent
ou non activables.
5. Si leur règle d’activation n’est que partiellement reconnue, alors l’algorithme met en mé-
moire les balises qui manquent pour vérifier la règle, et elles sont recherchées en priorité
à la prochaine itération.
6. Si la règle est totalement vérifiée, la procédure de réécriture est déclenchée, provoquant
éventuellement l’arrivée de nouvelles balises dans l’environnement.
L’algorithme converge vers des interprétations locales, mais ne termine jamais, des interpréta-
tions faites par les observateurs pouvant toujours être utilisées par la suite.
Un Modèle d’Interprétation de Requêtes G. Pitel
4 Conclusion
Afin de permettre une plus grande généricité dans la conception des systèmes d’ILN, comme
proposé par (Allen et al., 2001a), nous avons construit un modèle d’interprétation à partir des
théories cognitives des Affordances et de la sémantique procédurale. Ce modèle, mis en œuvre
par la construction d’un grand nombre d’entités que nous appelons observateurs, permet selon
nous de prendre en compte de larges aspects de la langue naturelle, grâce à sa conception qui lui
permet d’avoir une granularité variable. Nous pouvons dans le même formalisme exprimer des
règles syntaxiques que des règles du discours. Plusieurs raisons nous font penser que ce modèle
est capable d’atteindre les trois objectifs que nous nous étions fixés :
– Généricité, car sa granularité variable fait que plusieurs niveaux de la langue peuvent être
traités en même temps, et que de plus sa définition ne restreint pas son utilisation au langage,
puisque tout phénomène observable peut éventuellement être pris en compte ;
– Extensibilité, car sa conception fortement modulaire permet de rajouter des observateurs pour
traiter tout nouveau cas particulier. Des hétérogénéités peuvent toutefois apparaître lorsque
des observateurs de haut niveau d’abstraction devront être modifiés ;
– Unité, car tous les observateurs sont décrits dans un même formalisme, supprimant le pro-
blème de la communication entre modules qui apparaît avec les systèmes hétérogènes.
L’implémentation de ce modèle en Objective-Caml et Mathematica est en cours, et sera intégrée
à InterViews. Cela nous permettra de valider son potentiel, de l’améliorer, ou de le rejetter le
cas échéant. De nombreux travaux vont découler de sa mise en pratique effective, car si cette
approche s’avère valide, il restera à exprimer dans ce formalisme un grand nombre d’aspects de
l’ILN.
Références
ADRIAENS G. & DEVOS M. (1994). The Parallel Expert Parser. In G. ADRIAENS & U. HAHN, Eds.,
Natural Language Processing, p. 350–375. Norwood, New Jersey : Ablex Publishing Corporation.
ALLEN J., BYRON D., DZIKOVSKA M., FERGUSON G., GALESCU L. & STENT A. (2001a). Towards
conversational human-computer interaction. AI Magazine.
ALLEN J., FERGUSON G. & STENT A. (2001b). An architecture for more realistic conversational
systems. In Proceedings of Intelligent User Interfaces 2001 (IUI-01), p. 1–8, Santa Fe, NM.
ALLEN J., MILLER B., RINGGER E. & SIKORSKI T. (1996). A Robust System for Natural Spoken
Dialogue. In Proc. 34th Meeting of the Assoc. for Computational Linguistics.
BENNACEF S. K., DEVILLERS L., ROSSET S. & LAMEL L. (1996). Dialog in the RAILTEL
Telephone-Based System. In Proceedings of the International Conference on Speech and Language
Processing, p. 550–553, Philadelphia.
BOITET C. & SELIGMAN M. (1994). The “whiteboard” Architecture : A Way to Integrate Heteroge-
neous Components of NLP Systems. In Proceedings of COLING’94, volume 1.
CARVALHO A., D.S. P., SICHMAN J., SILVA J., WAZLAWICK R. & STRUBE DE LIMA V. (1998).
Multi-Agent Systems for Natural Language Processing. In Proceedings of the Second Iberoamerican
Workshop on Distributed Artificial Intelligence and Multi-agent Systems, Toledo, Spain.
GIBSON J. J. (1977). The theory of affordances. In R. SHAW & J. BRANSFORD, Eds., Perceiving,
Acting and Knowing, p. 67–82. New York : Wiley.
GIBSON J. J. (1979). The Ecological Approach to Visual Perception. Boston : Houghton Mifflin.
GODDEAU D., BRILL E., GLASS J., PAO C., PHILLIPS M., POLIFRONI J., SENEFF S. & ZUE V.
(1994). GALAXY : A Human-Language Interface to On-Line Travel Information. In Proceedings
of the International Conference on Spoken Language Processing, p. 707–710, Yokohama, Japan : The
Acoustical Society of Japan.
GÉRARD S. & SANSONNET J.-P. (2000). A Spatio-Temporal Model for the Representation of Situa-
tions Described in Narrative Texts. In Proc. NLP2000, Patras.
JOHNSON-LAIRD P. (1977). Procedural Semantics. Cognition, (5), 189–214.
LAMEL L., ROSSET S., GAUVIN J., BENNACEF S. & PROUTS G. (1998). The LIMSI ARISE sys-
tem. In Proceedings of IEEE 4th Workshop on Interactive Voice Technology for Telecommunications
Applications, p. 209–214, Torino, Italy.
NORMAN D. A. (1988). The psychology of everyday things. New York : Basic Books.
NORMAN D. A. (1990). The design of everyday things. New York : Doubleday.
SABAH G. (1990). CARAMEL : A Computational Model of Natural Language Understanding Using a
Parallel Implementation. In Proceedings of the Ninth ECAI, p. 563–565, Stockholm.
SABOURET N. & SANSONNET J.-P. (2001). Automated Answers to Questions about a Running Process.
In Proc. CommonSense 2001, p. 217–227.
SANSONNET J.-P. (1999). Présentation de VDL 0.1. Rapport interne 99-10, LIMSI-CNRS.
SMALL S. (1980). Word Expert Parsing : a Theory of Distributed Word-based Natural Language Un-
derstanding. PhD thesis, University of Maryland.
STEFANINI M.-H. & DEMAZEAU Y. (1995). TALISMAN : A Multi-Agent System for Natural Lan-
guage Processing. In J. WAINER & A. CARVALHO, Eds., Lecture Notes in Artificial Intelligence 991,
Springer-Verlag.
WINOGRAD T. (1973). A procedural model of language understanding. In R. SCHANK & K. COLBY,
Eds., Computer Models of Thought and Language, p. 152–186. W. H. Freeman.
WITTGENSTEIN L. (1953). The Philosophical Investigations. New York : Macmillan.
WOODS W. (1981). Procedural Semantics as a theory of meaning. In A. JOSHI, B. WEBBER & I. SAG,
Eds., Elements of Discourse Understanding. Cambridge, MA : MIT Press.
