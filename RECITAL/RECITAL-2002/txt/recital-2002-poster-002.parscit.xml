<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I I Bejar</author>
<author>E P Stabler</author>
<author>R Camp</author>
</authors>
<title>Syntactic complexity and psychometric difficulty: A preliminary investigation,</title>
<date>1987</date>
<journal>ETS Research</journal>
<tech>Report, No. RR-87-25,</tech>
<institution>Educational Testing Service.</institution>
<location>Princeton, NJ,</location>
<marker>Bejar, Stabler, Camp, 1987</marker>
<rawString>Bejar, I. I., Stabler, E. P., &amp; Camp, R. (1987), Syntactic complexity and psychometric difficulty: A preliminary investigation, ETS Research Report, No. RR-87-25, Princeton, NJ, Educational Testing Service.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Burstein</author>
<author>M Chodorow</author>
</authors>
<title>Automated Essay Scoring for Nonnative English Speakers,</title>
<date>1999</date>
<booktitle>Joint Symposium of the Association of Computational Linguistics and the International Association of Language Learning Technologies, Workshop on Computer-Mediated Language Assessment and Evaluation of Natural Language Processing.</booktitle>
<marker>Burstein, Chodorow, 1999</marker>
<rawString>Burstein J., Chodorow M. (1999), Automated Essay Scoring for Nonnative English Speakers, Joint Symposium of the Association of Computational Linguistics and the International Association of Language Learning Technologies, Workshop on Computer-Mediated Language Assessment and Evaluation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G E DeMauro</author>
<author>A Merritt</author>
<author>R Adams</author>
</authors>
<title>Delimiting the verbal domain,</title>
<date>1994</date>
<journal>ETS Research Report,</journal>
<volume>No.</volume>
<pages>94--34</pages>
<institution>Educational Testing Service.</institution>
<location>Princeton, NJ,</location>
<marker>DeMauro, Merritt, Adams, 1994</marker>
<rawString>DeMauro, G. E., Merritt, A., &amp; Adams, R. (1994), Delimiting the verbal domain, ETS Research Report, No. RR-94-34, Princeton, NJ, Educational Testing Service.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fairon</author>
</authors>
<title>ed., Analyse lexicale et syntaxique:</title>
<date>1999</date>
<booktitle>Le système INTEX, Lingvisticae Investigationes, Tome XXII (volume spécial),</booktitle>
<location>Amsterdam/Philaldelphia, John Benjamins.</location>
<contexts>
<context position="9239" citStr="Fairon, 1999" startWordPosition="1412" endWordPosition="1413">veaux textes, 5 ETS a développé une échelle de difficulté des items allant de -3.0 à +3.0. Par exemple, une erreur de majuscule dans une phrase est considérée comme très facile à détecter et est catégorisée -3.13 sur l’échelle de difficulté, tandis qu’une erreur de ponctuation (virgule) a une difficulté de -1.41. Ces estimations statistiques sont obtenues par l’analyse des résultats des étudiants dans les archives de plusieurs années de tests. Murielle Marchand nous avons connecté notre système d’extraction à un système qui récupère continuellement de nouveaux textes sur internet (GlossaNet - Fairon, 1999). 2 Conception d’un outil d’extraction et de classification automatique de phrases L’outil sur lequel porte le présent papier a pour but d’automatiser la sélection de phrasesitems qui approvisionnent le PPST. Il est conçu à partir du système INTEX6 pour localiser dans des bases de données en ligne (principalement des journaux) des phrases répondant à certains critères linguistiques et donc susceptibles de contenir certains types d’erreurs spécifiques. Le système extrait et classifie ces phrases d’après ces critères linguistiques pour ensuite les proposer comme phrases-candidates à un développe</context>
<context position="10460" citStr="Fairon 1999" startWordPosition="1592" endWordPosition="1593"> qui y introduira manuellement l’erreur désirée (un projet ultérieur envisagera la génération automatique d’erreurs calibrées). Une fois terminée la récupération de corpus par GlossaNet commence le processus d’extraction et de classification automatique des phrases. Celui-ci se déroule en 3 temps, comme illustré ci-dessous (étapes 2 à 4) : Figure 2 : Extraction et de classification de phrases à partir de corpus de données en ligne : méthodologie L’analyse comprend : 6 INTEX est un analyseur de corpus dévéloppé par Max Silberztein. Pour une présentation des différentes applications INTEX, voir Fairon 1999 et Silberztein 2000. Extraction et classification automatique de matériaux textuels pour la création de tests de langue - une phase d’analyse de ce corpus de données textuelles (c’est-à-dire la normalisation du texte par le système INTEX et l’application de dictionnaires électroniques à large couverture) ; - une phase d’extraction et de filtrage des phrases-candidates ; - une phase de classification et d’affichage de ces phrases par catégories. 2.1 Récupération de matériel textuel en ligne La méthodologie utilisée lors de la récupération de matériel textuel à partir de bases de données en lig</context>
</contexts>
<marker>Fairon, 1999</marker>
<rawString>Fairon C. (1999) ed., Analyse lexicale et syntaxique: Le système INTEX, Lingvisticae Investigationes, Tome XXII (volume spécial), Amsterdam/Philaldelphia, John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fairon</author>
</authors>
<title>Parsing a Web site as a corpus,</title>
<date>1999</date>
<booktitle>Analyse lexicale et syntaxique: Le système INTEX, Lingvisticae Investigationes Tome XXII (volume spécial),</booktitle>
<editor>in C. Fairon (ed.)</editor>
<location>Amsterdam/Philaldelphia, John Benjamins.</location>
<contexts>
<context position="9239" citStr="Fairon, 1999" startWordPosition="1412" endWordPosition="1413">veaux textes, 5 ETS a développé une échelle de difficulté des items allant de -3.0 à +3.0. Par exemple, une erreur de majuscule dans une phrase est considérée comme très facile à détecter et est catégorisée -3.13 sur l’échelle de difficulté, tandis qu’une erreur de ponctuation (virgule) a une difficulté de -1.41. Ces estimations statistiques sont obtenues par l’analyse des résultats des étudiants dans les archives de plusieurs années de tests. Murielle Marchand nous avons connecté notre système d’extraction à un système qui récupère continuellement de nouveaux textes sur internet (GlossaNet - Fairon, 1999). 2 Conception d’un outil d’extraction et de classification automatique de phrases L’outil sur lequel porte le présent papier a pour but d’automatiser la sélection de phrasesitems qui approvisionnent le PPST. Il est conçu à partir du système INTEX6 pour localiser dans des bases de données en ligne (principalement des journaux) des phrases répondant à certains critères linguistiques et donc susceptibles de contenir certains types d’erreurs spécifiques. Le système extrait et classifie ces phrases d’après ces critères linguistiques pour ensuite les proposer comme phrases-candidates à un développe</context>
<context position="10460" citStr="Fairon 1999" startWordPosition="1592" endWordPosition="1593"> qui y introduira manuellement l’erreur désirée (un projet ultérieur envisagera la génération automatique d’erreurs calibrées). Une fois terminée la récupération de corpus par GlossaNet commence le processus d’extraction et de classification automatique des phrases. Celui-ci se déroule en 3 temps, comme illustré ci-dessous (étapes 2 à 4) : Figure 2 : Extraction et de classification de phrases à partir de corpus de données en ligne : méthodologie L’analyse comprend : 6 INTEX est un analyseur de corpus dévéloppé par Max Silberztein. Pour une présentation des différentes applications INTEX, voir Fairon 1999 et Silberztein 2000. Extraction et classification automatique de matériaux textuels pour la création de tests de langue - une phase d’analyse de ce corpus de données textuelles (c’est-à-dire la normalisation du texte par le système INTEX et l’application de dictionnaires électroniques à large couverture) ; - une phase d’extraction et de filtrage des phrases-candidates ; - une phase de classification et d’affichage de ces phrases par catégories. 2.1 Récupération de matériel textuel en ligne La méthodologie utilisée lors de la récupération de matériel textuel à partir de bases de données en lig</context>
</contexts>
<marker>Fairon, 1999</marker>
<rawString>Fairon, C. (1999), Parsing a Web site as a corpus, in C. Fairon (ed.) Analyse lexicale et syntaxique: Le système INTEX, Lingvisticae Investigationes Tome XXII (volume spécial), Amsterdam/Philaldelphia, John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gross</author>
</authors>
<title>The Construction of local grammars, in E. Roche et Y. Schabes (eds), Finite State Language Processing,</title>
<date>1997</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge MA.</location>
<contexts>
<context position="12187" citStr="Gross, 1997" startWordPosition="1846" endWordPosition="1847">egmente le texte en unités, les phrases, et applique ensuite sur le texte des dictionnaires de mots simples et de mots composés ainsi que des transducteurs lexicaux. 2.3 L’extraction de phrases avec le système INTEX La phase d’extraction des phrases-candidates consiste en l’application d’automates à états finis (cf. Figure 3 ci-dessous) qui localisent et extraient du corpus normalisé des phrases répondant à certaines propriétés linguistiques. 2.3.1 Création et application de graphes : Toutes les caractéristiques linguistiques recherchées sont décrites dans des graphes ou ‘grammaires locales’ (Gross, 1997). Par exemple, dans la phrase-item présentée plus haut (figure1), l’erreur introduite visait à évaluer la capacité de l’examiné à utiliser correctement la construction « between A and B ». Afin de rechercher dans une base de données textuelles d’autres phrases capables de supporter ce même genre d’erreur (between A to B), nous avons décrit ce phénomène linguistique dans le graphe présenté à la Figure 3. L’application de ce graphe sur le fichier-texte qui constitue notre corpus nous donne toutes les séquences de mots correspondant à « between A and B » sous forme de concordance (voir Figure 4).</context>
</contexts>
<marker>Gross, 1997</marker>
<rawString>Gross M. (1997), The Construction of local grammars, in E. Roche et Y. Schabes (eds), Finite State Language Processing, The MIT Press, Cambridge MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Powers</author>
<author>J C Burstein</author>
<author>M E Fowles</author>
<author>K Kukich</author>
</authors>
<title>Comparing the validity of automated and human essay scoring,</title>
<date>2000</date>
<journal>GRE,</journal>
<volume>Vol.</volume>
<pages>98--08</pages>
<marker>Powers, Burstein, Fowles, Kukich, 2000</marker>
<rawString>Powers D.E., Burstein J.C., Fowles M.E., Kukich K. (2000), Comparing the validity of automated and human essay scoring, GRE, Vol. 98-08a.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Renouf</author>
</authors>
<title>Corpus Development,</title>
<date>1988</date>
<booktitle>Looking up. An account of the COBUILD Project in lexical computing, Londres-Glasgow, Collins ELT.</booktitle>
<editor>in J.M. Sinclair (ed.),</editor>
<marker>Renouf, 1988</marker>
<rawString>Renouf A. (1988), Corpus Development, in J.M. Sinclair (ed.), Looking up. An account of the COBUILD Project in lexical computing, Londres-Glasgow, Collins ELT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Silberztein</author>
</authors>
<title>Dictionnaires électroniques et analyse automatique de textes. Le système INTEX,</title>
<date>1993</date>
<location>Paris, Masson.</location>
<marker>Silberztein, 1993</marker>
<rawString>Silberztein M. (1993), Dictionnaires électroniques et analyse automatique de textes. Le système INTEX, Paris, Masson.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Silberztein</author>
</authors>
<title>Transducteurs pour le traitement automatique de textes,</title>
<date>1998</date>
<booktitle>Le Lexique-grammaire, Travaux de Linguistique 37, Bruxelles, Duculot,</booktitle>
<pages>127--142</pages>
<editor>in B. Lamiroy (ed.),</editor>
<marker>Silberztein, 1998</marker>
<rawString>Silberztein M. (1998), Transducteurs pour le traitement automatique de textes, in B. Lamiroy (ed.), Le Lexique-grammaire, Travaux de Linguistique 37, Bruxelles, Duculot, pp. 127-142.</rawString>
</citation>
<citation valid="false">
<authors>
<author>http users bestweb netintexdownloadsManuel pdf Sheehan</author>
<author>K M</author>
<author>R J Mislevy</author>
</authors>
<title>An inquiry into the nature of the sentence-completion task: Implications for item generation,</title>
<journal>ETS Research Report,</journal>
<volume>No.</volume>
<pages>01--13</pages>
<institution>Educational Testing Service.</institution>
<location>Princeton, NJ,</location>
<marker>Sheehan, M, Mislevy, </marker>
<rawString>Silberztein M. (2000), Manuel INTEX. http://users.bestweb.net/~intex/downloads/Manuel.pdf Sheehan, K. M. &amp; Mislevy, R. J.(2001), An inquiry into the nature of the sentence-completion task: Implications for item generation, ETS Research Report, No. RR-01-13. Princeton, NJ, Educational Testing Service.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>