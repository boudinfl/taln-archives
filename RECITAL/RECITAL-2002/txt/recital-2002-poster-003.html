<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>MemLabor, un environnement de cr&#233;ation, de gestion et de manipulation de corpus de textes</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#201;CITAL 2002, Nancy, 24-27 juin 2002 
</p>
<p>MemLabor, un environnement de cr&#233;ation, de gestion 
et de manipulation de corpus de textes 
</p>
<p>Vincent Perlerin 
</p>
<p>GREYC &#8211; CRNS UMR 6072 &#8211; Universit&#233; de Caen 
Campus II &#8211; BP 5186 &#8211; F14032 Caen Cedex 
</p>
<p>perlerin@info.unicaen.fr 
</p>
<p>R&#233;sum&#233; &#8211; Abstract  
</p>
<p>Nous pr&#233;sentons dans cet article un logiciel d&#8217;&#233;tude permettant la cr&#233;ation, la gestion et la 
manipulation de corpus de textes. Ce logiciel appel&#233; MemLabor se veut un outil ouvert et 
open-source adaptable &#224; toutes les op&#233;rations possibles que l&#8217;on peut effectuer sur ce type de 
mat&#233;riau. Dans une premi&#232;re partie, nous pr&#233;senterons les principes g&#233;n&#233;raux de l&#8217;outil. Dans 
une seconde, nous en proposerons une utilisation dans le cadre d&#8217;une acquisition supervis&#233;e 
de classes s&#233;mantiques. 
</p>
<p>In this article, we present a study software that allows creation, management and handling of 
corpora. This software called MemLabor is an open-source program, adaptable to all 
operations that we can carry out on this type of material. In the first part of this article, we 
will present the main principles of this tool. In the second part, we will suggest one of it use 
within the framework of a semantic classes supervised acquisition. 
</p>
<p>Keywords &#8211; Mots Cl&#233;s  
</p>
<p>analyse de corpus, acquisition supervis&#233;e de terminologie, s&#233;mantique lexicale 
corpus analysis, supervised terminology acquisition, lexical semantics 
</p>
<p>1 Introduction 
</p>
<p>L'analyse automatique ou semi-automatique de corpus de textes a d&#233;j&#224; montr&#233; son int&#233;r&#234;t pour 
l'&#233;tude de ph&#233;nom&#232;nes linguistiques ou l&#8217;acquisition terminologique. Des avanc&#233;s notables 
ont eu lieux dans ce domaine tant du point de vue logiciel (Intex (Silbertein 1993), Hyperbase 
d&#8217;Etienne Brunet, Lexico d&#8217;Andr&#233; Salem&#8230;) que du point de vue des standards de 
repr&#233;sentation des corpus utilis&#233;s (le CES &#8211; Corpus Standard Encoding - cr&#233;e &#224; partir des 
recommandations de la TEI, les propositions du projet MATE pour la repr&#233;sentation des 
corpus de dialogues, le projet GENELEX&#8230;). Si ces standards sont d&#8217;une utilit&#233; certaine, leur 
complexit&#233; est souvent un frein &#224; leur int&#233;gration aux logiciels d&#8217;&#233;tude pour l&#8217;analyse. Leur </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Vincent Perlerin 
</p>
<p>vocation d&#8217;&#233;change et de partage des r&#233;sultats d&#8217;op&#233;rations effectu&#233;es sur les ensembles de 
documents en est consid&#233;rablement affect&#233;e.  
</p>
<p>Dans cet article, nous pr&#233;sentons un environnement logiciel (MemLabor) permettant la 
cr&#233;ation, la gestion et la manipulation de corpus de textes bas&#233;s sur l&#8217;utilisation d&#8217;un format 
de conservation simple et l&#233;ger (une DTD XML) pouvant int&#233;grer &#224; volont&#233; d&#8217;autres 
propositions de standardisation par le biais d&#8217;URI1 ou de chemins explicites sur des supports 
de stockage. Le logiciel assure la normalisation des documents : la possibilit&#233; est donc donn&#233;e 
d&#8217;int&#233;grer &#224; un corpus des documents directement issus de l&#8217;Internet (dans la version actuelle, 
aux formats HTML, XML et TXT). MemLabor se veut adaptable &#224; tout type de travaux sur 
corpus de textes (annotations, recherche de patterns..) de par son caract&#232;re open-source2 et sa 
vocation a conserver les documents dans leur &#233;tat initial. Son utilisation dans le cadre de nos 
travaux vise la constitution supervis&#233;e de bases terminologiques structur&#233;es selon un mod&#232;le 
de s&#233;mantique diff&#233;rentielle et componentielle (Beust, 1998). Un des atouts majeurs du 
logiciel est de proposer un standard permettant de regrouper dans un m&#234;me fichier XML, le 
corpus, les travaux effectu&#233;s dessus et les relations entre ces entit&#233;s. Ce standard est 
suffisamment ouvert pour permettre l&#8217;introduction de tout type de manipulations attendu que 
le chemin d&#8217;acc&#232;s aux r&#233;sultats et les caract&#233;ristiques de ces manipulations doivent &#234;tre 
explicit&#233;s au sein du fichier centralisant les documents du corpus.  
</p>
<p>2  Description du logiciel 
</p>
<p>Le logiciel propos&#233; permet de g&#233;rer des corpus sous forme d&#8217;une description XML de fichiers 
de textes ou de fichiers de ressources linguistiques (mots grammaticaux d&#8217;une langue, lexies 
d&#8217;un domaine, &#233;tiquettes syntaxiques&#8230;) et des programmes qui prennent ces corpus en entr&#233;e 
et produisent des r&#233;sultats (comptages, graphiques&#8230;) conserv&#233;s avec le corpus. On peut y 
ajouter des programmes (classes, m&#233;thodes ou ex&#233;cutables) tout en conservant les techniques 
de manipulation bas&#233;es sur l&#8217;utilisation de la DTD XML propos&#233;e. Les fichiers peuvent &#234;tre 
partag&#233;s entre plusieurs corpus puisqu&#8217;ils ne sont pas modifi&#233;s par les traitements et qu&#8217;ils 
peuvent &#234;tre r&#233;f&#233;renc&#233;s par une URI ou tout autre chemin d&#8217;emplacement sur un support de 
stockage. 
</p>
<p>2.1 Cr&#233;ation d&#8217;un corpus 
</p>
<p>Un corpus utilisable par le logiciel MemLabor doit &#234;tre repr&#233;sent&#233; par un fichier XML soumis 
&#224; une DTD permettant un stockage d&#8217;information du type de la Figure 1. Cette DTD d&#233;finit 
un document de type CORPUS d&#233;termin&#233; par un nom, une suite de commentaires et une date 
de cr&#233;ation (ligne 1). Chaque CORPUS est compos&#233; d&#8217;&#233;l&#233;ments de type TRAVAIL_CORPUS et 
FICHIER_CORPUS.Les &#233;l&#233;ments TRAVAIL_CORPUS correspondent &#224; des travaux effectu&#233;s sur 
l&#8217;ensemble des fichiers du corpus. Ils sont d&#233;finis par un nom (le type de travail effectu&#233; sur 
le corpus), un fichier o&#249; sont stock&#233;s les r&#233;sultats de ce travail (URI ou emplacement sur un 
support de stockage) et une date (celle &#224; laquelle le travail a &#233;t&#233; effectu&#233; sur le corpus) (ligne 
                                                 
1 Universal Resource Identifier &#8211; www.w3c.org/Addressing 
</p>
<p>2 www.info.unicaen.fr/~perlerin </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>MemLabor, un outil de cr&#233;ation, de gestion et de manipulation de corpus de textes 
</p>
<p>2). Les &#233;l&#233;ments de type FICHIER_CORPUS correspondent aux documents constituant le corpus : 
ils sont d&#233;finis par un nom (URI ou emplacement sur un support de stockage) (ligne 3). 
Chaque document du corpus (de type FICHIER_CORPUS) peut &#234;tre soumis &#224; un travail particulier 
dont la trace sera sauvegard&#233;e dans le fichier XML du corpus selon le format d&#233;fini pour les 
&#233;l&#233;ments de type TRAVAIL_FICHIER (ligne 4) o&#249; les attributs Nom, Result et Date 
correspondent respectivement au nom du travail correspondant, au fichier o&#249; sont stock&#233;s les 
r&#233;sultats de ce travail et &#224; la date de r&#233;alisation de ce travail.  
</p>
<p>1 &lt;CORPUS Nom=&quot;Microsoft-Lib&#233;&quot; Commentaires=&quot;Proc&#232;s Microsoft 2001-2002&quot;
Date=&quot;12/02/2002&quot;&gt;
2 &lt;TRAVAIL_CORPUS Nom=&quot;Zipf&quot; Result=&quot;E:\Corpus\Zipf\Microsoft-Lib&#233;.zipf.xml&quot;
Date=&quot;12/02/2002&quot;/&gt;
3 &lt;FICHIER_CORPUS Nom=&quot;E:\Corpus\ Reprise des hostilit&#233;s contre Microsoft.htm&quot;&gt;
4 &lt;TRAVAIL_FICHIER Nom=&quot;HTMLToTXT&quot; Result=&quot;E:\Corpus\HTMLToTXT\ Reprise des
hostilit&#233;s contre Microsoft.txt&quot; Date=&quot;13/02/2002&quot; /&gt;
5 &lt;/FICHIER_CORPUS&gt;
6 &lt;/CORPUS&gt; 
</p>
<p>Figure 1 : Exemple de document de type Corpus pour MemLabor. 
</p>
<p>La Figure 2 est une copie d&#8217;&#233;cran du logiciel MemLabor. Il s&#8217;agit de la premi&#232;re fen&#234;tre 
d&#8217;interaction permettant de cr&#233;er automatiquement un corpus (le fichier XML correspondant) 
en fonction d&#8217;un ensemble de fichiers choisis par l&#8217;utilisateur sur des supports de stockage. Le 
principe est identique pour des corpus constitu&#233;s d&#8217;URLs externes, bien que l&#8217;utilisation 
d&#8217;URLs non personnelles puisse s&#8217;av&#233;rer probl&#233;matique &#233;tant donn&#233;e la forte volatilit&#233; des 
documents du Web. Dans la partie gauche sont pr&#233;sent&#233;s les fichiers du r&#233;pertoire s&#233;lectionn&#233;, 
dans celle de droite, les fichiers candidats au corpus en cours de cr&#233;ation. 
</p>
<p> 
</p>
<p>Figure 2 : Copie d&#8217;&#233;cran de MemLabor &#8211; cr&#233;ation d&#8217;un corpus. 
</p>
<p>2.2 Travaux  
</p>
<p>Dans sa version actuelle, MemLabor propose cinq types de travaux sur corpus (ou sur des 
sous-ensembles du corpus) : la normalisation des documents d&#8217;un corpus au format TXT 
(depuis XML ou HTML), un segmenteur param&#233;trable (tokeniseur), un calcul de type Zipf 
(c.f. 2.2.1), une segmentation en paragraphe et une recherche de cooccurrences d&#8217;ensembles 
de lexies (c.f. 2.2.2). </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Vincent Perlerin 
</p>
<p>2.2.1 Calcul de type Zipf  
</p>
<p>Zipf a observ&#233; (Zipf, 1949) que la fr&#233;quence d'utilisation des mots d&#233;cro&#238;t de mani&#232;re quasi-
lin&#233;aire et que le produit f.R , soit la fr&#233;quence d'un mot multipli&#233;e par le rang de ce mot est &#224; 
peu pr&#232;s constant (cette constante d&#233;pend du texte ou de l&#8217;ensemble de textes consid&#233;r&#233;). 
MemLabor permet d&#8217;effectuer un calcul de type Zipf sur l&#8217;ensemble des documents d&#8217;un 
corpus o&#249; sur un sous-ensemble de documents d&#8217;un corpus. Ce calcul donne lieu &#224; la 
modification du fichier XML du corpus en fonction des travaux demand&#233;s et &#224; la cr&#233;ation 
d&#8217;un fichier de r&#233;sultat rassemblant les lexies d&#233;couvertes class&#233;es par ordre d&#233;croissant de 
leur nombre d&#8217;occurrences au sein des textes. Ce calcul est effectu&#233; &#224; l&#8217;aide d&#8217;un segmenteur 
param&#233;trable permettant par exemple de prendre en compte ou non les mots compos&#233;s 
contenant des tirets ou les groupes nominaux ou verbaux. Ce segmenteur utilise un moteur &#224; 
base de r&#232;gles d&#233;claratives modifiable par les utilisateurs.   
</p>
<p> 
</p>
<p>Figure 3 : Copie d&#8217;&#233;cran de MemLabor &#8211; calcul de type Zipf sur un corpus. 
</p>
<p>Lors d&#8217;un calcul de type Zipf, en plus de la liste des lexies (ou des motifs d&#233;finies dans la 
base de r&#232;gles du segmenteur) rep&#233;r&#233;es avec leur nombre d&#8217;occurrences au sein de l&#8217;ensemble 
du corpus (fen&#234;tre de gauche dans la Figure 3) sont propos&#233;es &#224; l&#8217;utilisateur les 
repr&#233;sentations graphiques en histogrammes et en log/log des r&#233;sultats (respectivement les 
fen&#234;tres du centre et de droite dans la Figure 3). Ces graphiques permettent outre de v&#233;rifier la 
validit&#233; de la loi de Zipf sur le corpus consid&#233;r&#233;, de rep&#233;rer d&#8217;&#233;ventuelles irr&#233;gularit&#233;s 
inh&#233;rentes &#224; des corpus h&#233;t&#233;rog&#232;nes (c&#8217;est-&#224;-dire rassemblant des textes utilisant des 
vocabulaires tr&#232;s diff&#233;rents). Dans ce cas, la repr&#233;sentation en histogramme n&#8217;est pas d&#8217;allure 
logarithmique et la droite de r&#233;gression &#8211; en rouge sur le graphique &#8211; de la repr&#233;sentation en 
log/log ne peut &#234;tre significative &#233;tant donn&#233;e la dispersion des points du graphique.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>MemLabor, un outil de cr&#233;ation, de gestion et de manipulation de corpus de textes 
</p>
<p>2.2.2 Cooccurrences de lexies 
</p>
<p>L&#8217;utilisateur de MemLabor peut cr&#233;er &#224; l&#8217;aide du logiciel des fichiers de lexies (au format 
XML) correspondant &#224; une DTD pr&#233;-d&#233;finie fournie avec le logiciel. L&#8217;utilisation d&#8217;autres 
standards de bases terminologiques (TBX selon la norme ISO 122003, ISO DIS 16642 : TMF 
&#8211; Terminilogical Markup Framework, voir TC37/SC4) pouvant &#234;tre pr&#233;vue par l&#8217;utilisateur 
moyennant la programmation de modules ad&#233;quats. 
</p>
<p>Un ensemble de lexies (FIC_LEXIE) et leurs flexions peut &#234;tre alors constitu&#233; selon le 
mod&#232;le suivant (Figure 4) :  
</p>
<p>1 &lt;FIC_LEXIE Nom=&quot;Lexies en rapport avec Microsoft&quot; &gt;
2 &lt;LEXIE Nom=&quot;Microsoft&quot; Categorie=&quot;N&quot;&gt;
3 &lt;FLEXION&gt;MS&lt;/FLEXION&gt;
4 &lt;/LEXIE&gt;
5 &lt;LEXIE Nom=&quot;logiciel&quot; Categorie=&quot;N&quot;&gt;
6 &lt;FLEXION&gt;logiciels&lt;/FLEXION&gt;
7 &lt;FLEXION&gt;software&lt;/FLEXION&gt;
8 &lt;FLEXION&gt;softwares&lt;/FLEXION&gt;
9 &lt;/LEXIE&gt;
10 &lt;/FIC_LEXIE&gt;
</p>
<p>Figure 4 : Exemple de fichier d&#8217;ensemble de lexies. 
</p>
<p>Selon la DTD fournie avec le logiciel, une lexie doit &#234;tre d&#233;crite par un nom et une cat&#233;gorie. 
Les cat&#233;gories propos&#233;es doivent &#234;tre cod&#233;es selon la norme Bdlex4 (A pour les adverbes, C 
pour les conjonctions, N pour les noms&#8230;) car celle-ci peut ensuite &#234;tre utilis&#233;e pour g&#233;n&#233;rer 
automatiquement les flexions de la lexie consid&#233;r&#233;e &#224; partir des donn&#233;es d&#8217;une base Bdlex. 
Les flexions seront cod&#233;es dans le fichier XML selon le mod&#232;le de la ligne 6 de la Figure 4. 
L&#8217;utilisation de fichiers XML pour stocker ces donn&#233;es permet &#233;galement, comme &#224; la ligne 3 
de la Figure 4, d&#8217;introduire des repr&#233;sentations textuelles s&#233;mantiquement identiques &#224; la 
lexie (ici MS pour Microsoft) ne relevant pas des flexions courantes du mot ou des 
&#233;quivalents dans d&#8217;autres langues pouvant appara&#238;tre dans certains types de documents (lignes 
7 et 8 de la Figure 4). L&#8217;utilisation &#233;tendue du terme &#171; flexion &#187; pourra alors &#234;tre per&#231;ue 
comme erron&#233;e mais la repr&#233;sentation propos&#233;e pourra &#234;tre utilis&#233;e pour des travaux sur 
corpus multilingues. Les fichiers de lexies ainsi constitu&#233;s peuvent donner lieu &#224; un calcul de 
cooccurrences au sein des documents d&#8217;un corpus choisi (Figure 5). 
</p>
<p>Pr&#233;alablement aux calculs des cooccurrences des lexies, les documents du corpus peuvent 
faire l&#8217;objet d&#8217;une segmentation en paragraphes (rep&#233;rage des indices typographiques dans les 
fichiers). Cette segmentation permet alors de limiter la prise en compte des cooccurrences &#224; 
cette entit&#233; textuelle. 
</p>
<p>                                                 
3 www.lisa.org 
</p>
<p>4 http://www.irit.fr/ACTIVITES/EQ_IHMPT/ress_ling/accueil01.php </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Vincent Perlerin 
</p>
<p> 
Figure 5 : Copie d&#8217;&#233;cran de MemLabor &#8211; r&#233;sultats du calcul de cooccurrences en pourcentage 
</p>
<p>du nombre de fichiers du corpus pour un fichier contenant 10 lexies (ex : le mot microsoft 
appara&#238;t dans 83,93% des fichiers o&#249; le mot bill appara&#238;t dans l&#8217;ensemble des fichiers du 
</p>
<p>corpus &#8211; le mot souris t&#233;moin dans l&#8217;exp&#233;rience n&#8217;appara&#238;t pas au sein du corpus). 
</p>
<p>3 Acquisition terminologique supervis&#233;e 
</p>
<p>3.1 Cadre de recherche - Probl&#233;matique 
</p>
<p>Nos recherches en s&#233;mantique pour le TAL r&#233;pondent aux exigences suivantes : nous d&#233;sirons 
&#233;laborer des mod&#232;les et construire des outils permettant des traitements syntagmatiques 
rapides et des repr&#233;sentations paradigmatiques non exhaustives a priori, c'est-&#224;-dire aboutir &#224; 
une s&#233;mantique l&#233;g&#232;re. Nous nous pla&#231;ons dans une approche anthropocentr&#233;e o&#249; la machine 
se construit autour des besoins de l'utilisateur (Thlivitis, 1998), et nous revendiquons une 
approche prax&#233;ologique de l'activit&#233; langagi&#232;re (s&#233;mantique tourn&#233;e vers la pratique de la 
langue par un individu ou un groupe restreint d'individus). De plus, nous d&#233;sirons constuire 
une s&#233;mantique lexicale intra-linguistique textuellement situ&#233;e (&#224; l&#8217;oppos&#233; d&#8217;une s&#233;mantique 
purement r&#233;f&#233;rentielle qui &#233;tudierait les rapports des expressions au monde - selon la 
diff&#233;rence soulign&#233;e par (Auroux, 1999 p.38). Le logiciel d&#233;crit dans cet article et l'exemple 
d'application s'inscrivent donc pleinement dans ce cadre. 
</p>
<p>La r&#233;alisation de MemLabor est cons&#233;cutive &#224; une &#233;tude semi-manuelle d&#233;but&#233;e en 2000 dans 
le cadre d&#8217;un projet visant &#224; proposer des outils de filtrage et de r&#233;ordonnancement de 
r&#233;sultats de syst&#232;mes documentaires classiques (moteurs de recherche du Web) en fonction de 
ressources s&#233;mantiques fournies par l&#8217;utilisateur (Perlerin, 2001). Cette &#233;tude semi-manuelle 
de 1783 d&#233;p&#234;ches journalistiques (Corpus Reuter) avait montr&#233; que les pourcentages de 
cooccurrences en nombre de fichiers &#224; l&#8217;int&#233;rieur d&#8217;un corpus homog&#232;ne (Figure 5) pouvaient 
&#234;tre un indice valable pour le choix de lexies appartenant &#224; des th&#232;mes proches en vue de 
construire des syst&#232;mes de classes de cat&#233;gorisation selon le mod&#232;le Anadia (Coursil, 
2000)(Beust, 1998). Cette observation peut &#234;tre partiellement expliqu&#233;e par la notion 
d&#8217;isotopie (r&#233;currence syntagmatique d&#8217;un m&#234;me trait s&#233;mantique) support crucial du sens 
dans les textes. Les lexies candidates &#224; une m&#234;me classe de cat&#233;gorisation partagent en effet 
un certain nombre de traits g&#233;n&#233;riques (Rastier, 1994) dont la redondance au sein des entit&#233;s 
textuelles conditionne le sens. C&#8217;est la d&#233;termination du global sur le local. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>MemLabor, un outil de cr&#233;ation, de gestion et de manipulation de corpus de textes 
</p>
<p>3.2 Aide pour la constitution de classes de cat&#233;gorisation s&#233;mantique 
</p>
<p>Nos recherches concernent la dimension th&#233;matique de la coh&#233;sion textuelle. A partir d&#8217;un 
corpus homog&#232;ne, il s&#8217;agit ici de constituer des classes de cat&#233;gorisation s&#233;mantiques au sens 
des tax&#232;mes de la s&#233;mantique interpr&#233;tative (Rastier, 1994) : &#171; structure paradigmatique 
constitu&#233;e par des unit&#233;s lexicales se partageant une zone commune de signification et se 
trouvant en opposition imm&#233;diate les unes avec les autres &#187;. En d&#8217;autres termes et dans un 
cadre diff&#233;rentiel, il s&#8217;agit de structurer des ensembles de mots appartenant &#224; un m&#234;me th&#232;me 
en formant des sous-ensembles au sein desquels on peut marquer leur diff&#233;rence - voir le 
mod&#232;le Anadia (Nicolle et al., 2002). Notre but est de fournir aux utilisateurs une aide &#224; la 
constitution de telles ressources. 
</p>
<p>Deux t&#226;ches sont &#224; r&#233;aliser : l&#8217;extraction des candidats termes et le classement de ces 
candidats aux seins de sous-ensembles. Dans la litt&#233;rature, on trouve de nombreuses 
techniques d&#8217;acquisition de terminologie : en fonction de crit&#232;res principalement morpho-
syntaxique (TERMINO [David et Plante, 1990], et LEXTER [Bourigault, 1994], &#8230;), en 
fonction de crit&#232;res principalement statistiques (ANA [Enguehard, 1993], [Riloff et Shreperd, 
1997],&#8230;), ou encore en fonction de marqueurs a priori (SEEK de Christophe Jouis, COATIS 
de Daniela Garcia). D&#233;sirant restreindre au maximum la quantit&#233; de ressources n&#233;cessaires au 
traitement et placer l&#8217;utilisateur au c&#339;ur du syst&#232;me, nous avons opt&#233; pour l&#8217;extractions des 
mots du domaine pour une technique statistique simple. Nous nous basons sur un calcul de 
type Zipf filtr&#233; &#224; l&#8217;aide d&#8217;une liste de mots s&#233;mantiquement limit&#233;s. En effet, lors du rep&#233;rage 
des lexies mises en jeu dans les documents d&#8217;un corpus homog&#232;ne, les graphiques en 
histogrammes obtenus pr&#233;sentent trois groupes cons&#233;cutifs (num&#233;rot&#233;s 1, 2 et 3 dans la Figure 
6). Le premier rassemble les lexies fortement redondantes dans la langue et n&#8217;ayant pas un 
potentiel s&#233;mantique important (d&#233;terminants, pronoms, articles&#8230;). Le second regroupe 
principalement les mots sp&#233;cifiques au domaine du corpus. Le troisi&#232;me ne pr&#233;sente pas de 
particularit&#233;s remarquables. 
</p>
<p> 
</p>
<p>Figure 6 : Repr&#233;sentation graphique d&#8217;un calcul de type Zipf sur un corpus homog&#232;ne.  
</p>
<p>MemLabor est actuellement disponible avec une liste de mots ayant un potentiel s&#233;mantique 
faible ou stoplist en fran&#231;ais contenant 744 entr&#233;es. Cette liste repr&#233;sente 6Ko de m&#233;moire et 
contient essentiellement les d&#233;terminants, pronoms, chiffres, auxiliaires et adverbes courants. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Vincent Perlerin 
</p>
<p>Des stoplists d&#8217;autres langues sont disponibles sur le web (ex : http://download-
west.oracle.com/otndoc/oracle9i/901_doc/text.901/a90121/astopsup.htm#1234). 
</p>
<p>En ne tenant pas compte des mots pr&#233;sents dans la stoplist lors d&#8217;un calcul de type Zipf, la 
liste des lexies obtenue rassemble majoritairement des mots sp&#233;cifiques au domaine du corpus 
(fen&#234;tre de gauche dans la Figure 3). Parmi cette liste, l&#8217;utilisateur peut regrouper les mots qui 
selon sa pratique de la langue rel&#232;vent de la m&#234;me th&#233;matique. Pour l&#8217;aider dans la 
constitution des classes de cat&#233;gorisation, le calcul des cooccurrences des lexies s&#233;lectionn&#233;es 
pour un th&#232;me avec les autres lexies de la liste (comme dans la Figure 5) permet au logiciel de 
lui proposer la liste des lexies fortement cooccurrentes avec celles d&#233;j&#224; pr&#233;sentes dans la 
classe qu&#8217;il est en train de constituer. Sur un corpus homog&#232;ne et pour un domaine th&#233;matique 
donn&#233;, la prise en compte du document dans son entier comme surface d&#8217;exploration des 
cooccurrences peut s&#8217;av&#233;rer suffisante pour aider l&#8217;utilisateur dans son choix des ensembles 
de cat&#233;gorisation.  
</p>
<p> 
</p>
<p>Figure 7 : Copie d&#8217;&#233;cran de MemLabor - r&#233;sultats partiels du calcul des cooccurrences de 35 
lexies en pourcentage du nombre de fichiers d&#8217;un corpus de 150 articles du journal Lib&#233;ration 
</p>
<p>sur le proc&#232;s Microsoft en 2001 (la lexie souris est absente du corpus). 
</p>
<p>Figure 7
</p>
<p>Soit Li, la lexie i et P(Li,Lj) le pourcentage en nombre de fichiers au sein du corpus contenant 
Li o&#249; Lj appara&#238;t5. Si les lexies L1, L2, L3 &#8230;ont &#233;t&#233; s&#233;lectionn&#233;es comme candidates &#224; une 
m&#234;me classe s&#233;mantique, le logiciel proposera en fonction d&#8217;une table de r&#233;sultats identique &#224; 
celle pr&#233;sent&#233;e dans la Figure 7, une liste de lexies Li class&#233;es en fonction du produit  
P(L1, Li)xP(L2,Li)&#8230; le facteur multiplicateur permettant de rendre compte des proportions de 
cooccurrence. 
</p>
<p>Une premi&#232;re exp&#233;rience (d&#233;crite dans (Nicolle et al., 2002)) sur le corpus Reuter a montr&#233; 
que les r&#233;sultats ainsi obtenus pla&#231;aient les mots initialement choisis pour &#234;tre candidats &#224; une 
m&#234;me classe s&#233;mantique parmi approximativement les 15 premi&#232;res places de la liste. Dans le 
cas du corpus utilis&#233; pour cet article (corpus Lib&#233;ration &#8211; cf. Figure 7), la Figure 8 pr&#233;sente la 
liste obtenue pour les lexies d&#233;j&#224; candidates &#224; une m&#234;me classe : entreprise et firme (le 
tableau de cooccurrences ayant &#233;t&#233; calcul&#233; pour les 60 premi&#232;res lexies de la liste obtenue 
suite au calcul de type Zipf6). 
</p>
<p>                                                 
5 dans la , P(microsoft,linux) = 19,64 % et P(linux,microsoft) = 100%. 
</p>
<p>6 l&#8217;ensemble des donn&#233;es de l&#8217;&#233;tude sont disponibles sur www.info.unicaen.fr/~perlerin </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>MemLabor, un outil de cr&#233;ation, de gestion et de manipulation de corpus de textes 
</p>
<p> firme entreprise Produit   firme entreprise Produit 
</p>
<p>logiciel 68 74 5032 gates 60,87 65,22 3969,9414
internet 100 50 5000 verdict 57,89 68,42 3960,8338
industrie 65,85 75,61 4978,9185 bill 61,7 63,83 3938,311
gouverment 73,53 61,76 4541,2128 juge 68,18 56,82 3873,9876
justice 71,43 63,49 4535,0907 appel 71,43 53,57 3826,5051
soci&#233;t&#233; 64,71 67,65 4377,6315 microsoft 60 61,82 3709,2
produit 70,59 61,76 4359,6384 proc&#232;s 65,85 56,1 3694,185
actionnaire 61,11 69,44 4243,4784 pc 57,14 64,29 3673,5306
informatique 66,67 63,33 4222,2111 antitrust 60,71 58,93 3577,6403
logiciel 59,38 70,31 4175,0078 monopole 58,06 56,45 3277,487
concurrent 66,67 61,9 4126,873 communication 59,26 53,7 3182,262
Figure 8 : Extrait de la liste des lexies propos&#233;es pour les lexies firme et entreprise. (La liste 
compl&#232;te contient 60 lexies). 
</p>
<p>Comme on peut le constater dans la Figure 8, les mots raisonnablement candidats &#224; une m&#234;me 
classe s&#233;mantique que firme et entreprise (en gras dans la liste), ne sont pas class&#233;s aux 
premi&#232;res places mais apparaissent &#224; des positions coh&#233;rentes, plus rapidemment atteignables 
par l&#8217;utilisateur que dans la liste Zipf globale. L&#8217;exp&#233;rience a &#233;t&#233; men&#233;e sur un corpus non 
segment&#233;7 et ne saurait &#234;tre valid&#233;e que dans des conditions r&#233;elles. Une exp&#233;rience sera 
m&#233;n&#233;e lors de l&#8217;atelier-formation organis&#233; par l&#8217;ARCO8 et le CNRS en juillet de cette ann&#233;e9. 
D&#8217;une mani&#232;re g&#233;n&#233;rale, nous pensons que ce type de calculs supervis&#233;s par un utilisateur &#224; 
m&#234;me d&#8217;investir une partie de son temps &#224; la constitution de telles ressources pourrait, 
coupl&#233;s avec d&#8217;autres traitements l&#233;gers (comme la reconnaissance des noms au sein des 
documents), repr&#233;sente une aide importante. Notre objectif est de proposer des outils 
s&#233;mantiques ne n&#233;cessitant pas de ressources paradigmatiques importantes ; ni de traitements 
pr&#233;alables importants du corpus. L&#8217;analyse distributionnelle de documents bas&#233;e sur une 
observation de caract&#233;ristiques linguistiques (redondances des termes, principe d&#8217;isotopie, &#8230;) 
est une piste int&#233;ressante de recherche pour aider &#224; la constition de telles ressources.  
</p>
<p>4 Conclusion 
</p>
<p>Dans cette article, nous avons propos&#233; une plateforme de gestion de corpus pour le TAL. Le 
logiciel MemLabor s&#8217;inscrit dans une approche coop&#233;rative de la recherche en TAL en 
permettant l&#8217;&#233;change de corpus ou de r&#233;sultats obtenus sur ces corpus par l&#8217;interm&#233;diaire 
d&#8217;une DTD XML. Le caract&#232;re open-source du programme en assure aussi sa possible 
d&#8217;&#233;volution.  
</p>
<p>Cette ressource logicielle exploite et rend compte de la dimension intertextuelle des 
documents. Des &#233;tudes linguistiques r&#233;centes (Rastier, 2001) montrent l&#8217;importance dans le 
processus d&#8217;interpr&#233;tation de la place d&#8217;un document dans un ensemble saisi par le lecteur 
</p>
<p>                                                 
7 des r&#233;sultats sur des documents segment&#233;s (pourcentages de cooccurrences dans les segments de documents) 
</p>
<p>sont disponibles sur www.info.unicaen.fr/~perlerin 
</p>
<p>8 Association pour la recherche cognitive 
</p>
<p>9 http://users.info.unicaen.fr/~anne/HTML/atelier.htm </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Vincent Perlerin 
</p>
<p>(ici, le corpus constitu&#233; par l&#8217;utilisateur) . MemLabor a pour objectif de participer &#224; ce genre 
d&#8217;&#233;tude, (re)pla&#231;ant le document au sein d&#8217;entit&#233;s plus grandes influen&#231;ant son interpr&#233;tation 
et permettant des exp&#233;rimentations sur cette dimension textuelle. 
</p>
<p>R&#233;f&#233;rences  
</p>
<p>Auroux S. (1999), Le langage, la raison et les normes, Paris, PUF. 
</p>
<p>Beust P. (1998) Contribution &#224; un mod&#232;le interactionniste du sens, Th&#232;se de Doctorat en 
Informatique de l&#8217;Universit&#233; de Caen. 
</p>
<p>Bourigault  D. (1994), Lexter, un logiciel d'extraction de terminologie. Application &#224; 
l'acquisition des connaissances &#224; partir de textes. Th&#232;se en informatique linguistique, Ecole 
des hautes Etudes en Sciences Sociales, Paris. 
</p>
<p>Coursil J. (2000), La fonction muette du langage - Essai de linguistique g&#233;n&#233;rale 
contemporaine, Editions Ibis Rouge. 
</p>
<p>David  S, Plante P. (1990). De la n&#233;cessit&#233; d'une approche morpho-syntaxique dans l'analyse 
de textes, ICO, 2(3):140-154. 
</p>
<p>Enguehard, C (1993). Acquisition de terminologie &#224; partir de gros corpus, Informatique &amp; 
Langue Naturelle, ILN'93, Nantes,. 373-384. 
</p>
<p>Nicolle A, Beust P, Perlerin V. (2002), Un analogue de la m&#233;moire pour un agent logiciel 
interactif, In Cognito  N&#176;21, 37-66. 
</p>
<p>Perlerin V (2001), La recherche documentaire : une activit&#233; langagi&#232;re, Actes de TALN-
RECITAL 2001, 469-479. 
</p>
<p>Rastier F. (2001), El&#233;ments de th&#233;orie des genres, texte diffus&#233; sur la liste ferm&#233;e S&#233;mantique 
des textes, 2001. http://www.atala.org/je/010428/Rastier/Rastier280401.html 
</p>
<p>Riloff E., Shepherd J. (1997). A corpus-based approach for building semantic lexicons. In 
Cardie, C. et Weischedel, R., editors, Proceedings of the Second Conference on Empirical 
Methods in Natural Language Processing, 117-124. ACL, Somerset, New Jersey. 
</p>
<p>Silberstein M. (1993), Le syst&#232;me INTEX, Dictionnaires &#233;lectroniques et analyse automatique 
de textes, Paris, Masson. 
</p>
<p>Thlivitis T. (1998), S&#233;mantique interpr&#233;tative Intertextuelle : assitance informatique 
anthropocentr&#233;e &#224; la compr&#233;hension des textes, Th&#232;se de l'Universit&#233; de Rennes 1. 
</p>
<p>Zipf G. K. (1949), Human Behavior and the Principle of Least Effort, Addison-Wesley. </p>

</div></div>
</body></html>