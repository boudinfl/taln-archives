RECITAL 2002, Nancy, 24-2 7 juin 2002

MemLabor, un cnvironncmcnt dc creation, dc gestion
ct dc manipulation dc corpus dc textes

Vincent Perlerin

GREYC — CRNS UI\/[R 6072 — Universite de Caen
Campus II — BP 5186 — F14032 Caen Cedex
perlerin@info.unicaen.fr

Résumé — Abstract

Nous presentons dans cet article un logiciel d’etude perrnettant la creation, la gestion et la
manipulation de corpus de textes. Ce logiciel appele MemLab0r se Veut un outil ouvert et
open-source adaptable a toutes les operations possibles que l’on peut effectuer sur ce type de
materiau. Dans une premiere partie, nous presenterons les principes generaux de l’outil. Dans
une seconde, nous en proposerons une utilisation dans le cadre d’une acquisition supervisee
de classes semantiques.

In this article, we present a study software that allows creation, management and handling of
corpora. This software called MemLab0r is an open-source program, adaptable to all
operations that we can carry out on this type of material. In the first part of this article, we
will present the main principles of this tool. In the second part, we will suggest one of it use
within the framework of a semantic classes supervised acquisition.

Keywords — Mots Clés

analyse de corpus, acquisition supervisee de terrninologie, semantique lexicale
corpus analysis, supervised terminology acquisition, lexical semantics

1 Introduction

L'analyse automatique ou semi-automatique de corpus de textes a deja montre son interét pour
l'etude de phenomenes linguistiques ou l’acquisition terminologique. Des avances notables
ont eu lieux dans ce domaine tant du point de Vue logiciel (Intex (Silbertein 1993), Hyperbase
d’Etienne Brunet, Lexico d’Andre Salem...) que du point de Vue des standards de
representation des corpus utilises (le CES — Corpus Standard Encoding - cree a partir des
recommandations de la TEI, les propositions du projet MATE pour la representation des
corpus de dialogues, le projet GENELEX. . .). Si ces standards sont d’une utilite certaine, leur
complexite est souvent un frein a leur integration aux logiciels d’etude pour l’analyse. Leur

Vincent Perlerin

vocation d’échange et de partage des résultats d’opérations effectuées sur les ensembles de
documents en est considérablement affectée.

Dans cet article, nous présentons un environnement logiciel (MemLab0r) permettant la
création, la gestion et la manipulation de corpus de textes basés sur l’utilisation d’un format
de conservation simple et léger (une DTD XML) pouvant intégrer a volonté d’autres
propositions de standardisation par le biais d’URI1 ou de chemins explicites sur des supports
de stockage. Le logiciel assure la normalisation des documents : la possibilité est donc donnée
d’intégrer a un corpus des documents directement issus de l’Intemet (dans la version actuelle,
aux formats HTML, XML et TXT). MemLab0r se veut adaptable a tout type de travaux sur
corpus de textes (annotations, recherche de patterns..) de par son caractere open-sourcez et sa
vocation a conserver les documents dans leur état initial. Son utilisation dans le cadre de nos
travaux vise la constitution supervisée de bases terrninologiques structurées selon un modele
de sémantique différentielle et componentielle (Beust, 1998). Un des atouts majeurs du
logiciel est de proposer un standard permettant de regrouper dans un méme fichier XML, le
corpus, les travaux effectués dessus et les relations entre ces entités. Ce standard est
suffisamment ouvert pour permettre l’introduction de tout type de manipulations attendu que
le chemin d’acces aux résultats et les caractéristiques de ces manipulations doivent étre
explicités au sein du fichier centralisant les documents du corpus.

2 Description du logiciel

Le logiciel proposé permet de gérer des corpus sous forme d’une description XML de fichiers
de textes ou de fichiers de ressources linguistiques (mots grammaticaux d’une langue, lexies
d’un domaine, étiquettes syntaxiques. . .) et des programmes qui prennent ces corpus en entrée
et produisent des résultats (comptages, graphiques...) conservés avec le corpus. On peut y
aj outer des programmes (classes, méthodes ou exécutables) tout en conservant les techniques
de manipulation basées sur l’utilisation de la DTD XML proposée. Les fichiers peuvent étre
partagés entre plusieurs corpus puisqu’ils ne sont pas modifiés par les traitements et qu’ils
peuvent étre référencés par une URI ou tout autre chemin d’emplacement sur un support de
stockage.

2.1 Création d’un corpus

Un corpus utilisable par le logiciel MemLab0r doit étre représenté par un fichier XML soumis
a une DTD permettant un stockage d’information du type de la Figure 1. Cette DTD définit
un document de type CORPUS déterminé par un nom, une suite de commentaires et une date
de création (ligne 1). Chaque CORPUS est composé d’éléments de type TRAVAIL_CORPUS et
FICHIER_CORPUS .Les éléments TRAVAIL_CORPUS correspondent a des travaux effectués sur
l’ensemble des fichiers du corpus. Ils sont définis par un nom (le type de travail effectué sur
le corpus), un fichier ou sont stockés les résultats de ce travail (URI ou emplacement sur un
support de stockage) et une date (celle a laquelle le travail a été effectué sur le corpus) (ligne

1 Universal Resource Identifier — www.w3c.org/Addressing

2 www.info.unicaen.fr/~perlerin

MemLabor, un outil de création, de gestion et de manipulation de corpus de textes

2). Les elements de type FICHIER_CORPUS correspondent aux documents constituant le corpus :
ils sont definis par un nom (URI ou emplacement sur un support de stockage) (ligne 3).
Chaque document du corpus (de type FICHIER_CORPUS) peut etre soumis a un travail particulier
dont la trace sera sauvegardee dans le fichier XML du corpus selon le format defini pour les
elements de type TRAVAIL_FICHIER (ligne 4) ou les attributs Nom, Result et Date
correspondent respectivement au nom du travail correspondant, au fichier ou sont stockés les
résultats de ce travail et a la date de realisation de ce travail.

1 <CORPUS Nom="Microsoft—Libé" Commentaires="Procés Microsoft 2001-2002"
Date="l2/02/2002">

2 <TRAVAIL_CORPUS Nom="Zipf" Resu1t="E:\Corpus\Zipf\Microsoft—Libé.zipf.xml"
Date="l2/02/2002"/>

3 <FICHIER_CORPUS Nom="E:\Corpus\ Reprise des hostilités contre Microsoft.htm">
4 <TRAVAIL_FICHIER Nom="HTMLToTXT" Resu1t="E:\Corpus\HTMLToTXT\ Reprise des
hostilités contre Microsoft.txt" Date="l3/02/2002" />

5 </FICHIER_CORPUS>

6 </6ORPUS>

Figure 1 : Exemple de document de type Corpus pour MemLab0r.

La Figure 2 est une copie d’écran du logiciel MemLab0r. Il s’agit de la premiere fenetre
d’interaction perrnettant de créer automatiquement un corpus (le fichier XML correspondant)
en fonction d’un ensemble de fichiers choisis par l’utilisateur sur des supports de stockage. Le
principe est identique pour des corpus constitués d’URLs externes, bien que l’utilisation
d’URLs non personnelles puisse s’averer problématique étant donnée la forte volatilité des
documents du Web. Dans la partie gauche sont présentés les fichiers du repertoire selectionne,
dans celle de droite, les fichiers candidats au corpus en cours de creation.

Creation tie corpus HE

Emplacement
Repertoire |E:1PROGR:'-‘du1MES1CorpusInformatique1h.I1icrosoﬂ(58)  I
Fichiers ciu repertoire fichiers ciu corpus _
Reprise des hostilites contre Microsoﬂhtmﬁl Liberation - Reprise des hostilites centre 4:
_>

Microsoﬁ un proces obsoletehtm
Microsoft Elill Gates un empire menace.htm
Les cteboires de la nouvelle economie_htm
Le terrain perciu cie microsoﬂ_htm

-
._*l MI >

Liberation — Microsoft un proces obsolete L
Liberation — Microsoft Elill Gates un empir
I Liberation — Les cieboires de la nouvelle E
Ajoutertous les ﬁchiers au corpus emu .33 micrgsgﬂ v~

 

  

Sauvegarcierle corpus I

Figure 2 : Copie d’écran de MemLab0r — creation d’un corpus.

2.2 Travaux

Dans sa version actuelle, MemLab0r propose cinq types de travaux sur corpus (ou sur des
sous-ensembles du corpus) : la normalisation des documents d’un corpus au format TXT
(depuis XML ou HTML), un segmenteur parametrable (tokeniseur), un calcul de type Zipf
(c.f. 2.2.1), une segmentation en paragraphe et une recherche de cooccurrences d’ensembles
de lexies (c.f. 2.2.2).

Vincent Perlerin

2.2.1 Calcul de type Zipf

Zipf a observé (Zipf, 1949) que la fréquence d'utilisation des mots décroit de maniere quasi-
linéaire et que le produit f.R, soit la fréquence d'un mot multipliée par le rang de ce mot est a
peu pres constant (cette constante dépend du texte ou de l’ensemble de textes considéré).
MemLab0r permet d’effectuer un calcul de type Zipf sur l’ensemble des documents d’un
corpus ou sur un sous-ensemble de documents d’un corpus. Ce calcul donne lieu a la
modiﬁcation du ﬁchier XML du corpus en fonction des travaux demandés et a la création
d’un ﬁchier de résultat rassemblant les lexies découvertes classées par ordre décroissant de
leur nombre d’occurrences au sein des textes. Ce calcul est effectué a l’aide d’un segmenteur
paramétrable permettant par exemple de prendre en compte ou non les mots composés
contenant des tirets ou les groupes nominaux ou Verbaux. Ce segmenteur utilise un moteur a
base de regles déclaratives modiﬁable par les utilisateurs.

E:DoIpus Chalgé : Petit Miclosolt
Elcmer Qorous Iravauxsurcorpus Travauxsurﬁmhxerts) ﬂmdow

Zlpfsurcorp lllpfsurcorp Zlplsurcorp
l 

Zipf sur corpus: Petit Microsoft E El Zillf SUI CUHIIIS I Pelil Miltfﬂsﬂfl E El‘:
mmmggn 53 ii Nnre d‘o:c Nbre d'occ.

gates 26 as
process 22
juge1Q 53'
hI|l1B
gouvernemenﬂs 5|}
jackson 1?
interne114 43.
InformalIque13
compagnie11 3D_
|ogIcIe111 ‘
w1ndows11

momopo1e11

noun-'e|1e11

|ibera11on1U

monde1EI

|ogicie151U

Er1I|lrLlSl1|]

washinglone

economle E

explorers

pom-'oirB

1998 S

netscape 8

lol 7

marche 7 v

 

    

20'

1|]

 

1 1E! 1UU 311
Lexies Hana

 

4|

Figure 3 : Copie d’écran de MemLab0r — calcul de type Zipf sur un corpus.

Lors d’un calcul de type Zipf, en plus de la liste des lexies (ou des motifs définies dans la
base de regles du segmenteur) repérées avec leur nombre d’occurrences au sein de l’ensemble
du corpus (fenétre de gauche dans la Figure 3) sont proposées a l’utilisateur les
representations graphiques en histogrammes et en log/log des résultats (respectivement les
fenétres du centre et de droite dans la Figure 3). Ces graphiques permettent outre de vérifier la
Validité de la loi de Zipf sur le corpus considéré, de repérer d’éVentuelles irrégularités
inhérentes a des corpus hétérogenes (c’est-a-dire rassemblant des textes utilisant des
Vocabulaires tres différents). Dans ce cas, la représentation en histogramme n’est pas d’allure
logarithmique et la droite de régression — en rouge sur le graphique — de la représentation en
log/log ne peut étre signiﬁcative étant donnée la dispersion des points du graphique.

MemLabor, un outil de création, de gestion et de manipulation de corpus de textes

2.2.2 Cooccurrences de lexies

L’utilisateur de MemLab0r peut creer a l’aide du logiciel des ﬁchiers de lexies (au format
XML) correspondant a une DTD pre-deﬁnie fournie avec le logiciel. L’utilisation d’autres
standards de bases terminologiques (TBX selon la norme ISO 122003, ISO DIS 16642 : TMF
— Terminilogical Markup Framework, Voir TC37/SC4) pouvant étre prevue par l’utilisateur
moyennant la programmation de modules adequats.

Un ensemble de lexies (FIC_LEXIE) et leurs ﬂexions peut étre alors constitue selon le
modele suivant (Figure 4) :

1 <FIC_LEXIE Nom="Lexies en rapport avec Microsoft" >
2 <LEXIE Nom="Microsoft" Categorie="N">

3 <FLEXION>MS</FLEXION>

4 </LEXIE>

5 <LEXIE Nom="logiciel" Categorie="N">

6 <FLEXION>logiCiels</FLEXION>

7 <FLEXION>software</FLEXION>

8 <FLEXION>softwares</FLEXION>

9 </LEXIE>

10 </FIC_LEXIE>

Figure 4 : Exemple de ﬁchier d’ensemble de lexies.

Selon la DTD foumie avec le logiciel, une lexie doit étre decrite par un nom et une categorie.
Les categories proposees doivent étre codees selon la norme Bdlex4 (A pour les adverbes, C
pour les conjonctions, N pour les noms. . .) car celle-ci peut ensuite étre utilisee pour generer
automatiquement les ﬂexions de la lexie consideree a partir des donnees d’une base Bdlex.
Les ﬂexions seront codees dans le ﬁchier XML selon le modele de la ligne 6 de la Figure 4.
L’utilisation de ﬁchiers XML pour stocker ces donnees permet egalement, comme a la ligne 3
de la Figure 4, d’introduire des representations textuelles semantiquement identiques a la
lexie (ici MS pour Microsoft) ne relevant pas des ﬂexions courantes du mot ou des
equivalents dans d’autres langues pouvant apparaitre dans certains types de documents (lignes
7 et 8 de la Figure 4). L’utilisation etendue du terme << ﬂexion >> pourra alors étre percue
comme erronee mais la representation proposee pourra étre utilisee pour des travaux sur
corpus multilingues. Les fichiers de lexies ainsi constitues peuvent donner lieu a un calcul de
cooccurrences au sein des documents d’un corpus choisi (Figure 5).

Prealablement aux calculs des cooccurrences des lexies, les documents du corpus peuvent
faire l’objet d’une segmentation en paragraphes (reperage des indices typographiques dans les
fichiers). Cette segmentation permet alors de limiter la prise en compte des cooccurrences a
cette entite textuelle.

3 www.lisa.org

4 http://www.irit.fr/ACTIVITES/EQ_IHl\/IPT/ress_ling/accueil01.php

Vincent Perlerin

 

Résultats : Microsoft - Liberation .I' Essai

Travaux sur corpus entieu
— microsoﬂ bill gates juge windows prunes Iogiciels ordinateur 53uri5 clavier

microsofl - 33,33 32,14 33,35 23,21 23,21 52,14 42,35 3 1,23

3111 133 - 32,32 33,35 24,42 25,5 51,2 43,34 3 2,13
gates 133 133 - 33,43 25,33 25,33 53,34 53 3 2,12
juge 133 34,44 32,22 - 25,55 23,33 52,23 42,22 3 2,22
windows 133 35,32 35,32 32,33 - 23,23 23,23 53,55 3 2,44
procés 133 32,3 35,32 33,43 23,23 - 53,55 43,23 3 2,44
|3gici3|3 133 33,52 53,52 31,25 33,52 53,25 - 55,25 3 3,12
ordinateur 133 35,33 35,33 23,12 31,52 33,33 25 - 3 4,12
SDUHS incalculable incalculable incalculable incalculable incalculable incalculable incalculable incalculable - incalculable
clavier 133 |133 133 133 |133 133 133 |133 3 -

Figure 5 : Copie d’ecran de MemLab0r — resultats du calcul de cooccurrences en pourcentage
du nombre de ﬁchiers du corpus pour un ﬁchier contenant 10 lexies (ex : le mot microsoft
apparait dans 83,93% des ﬁchiers ou le mot bill apparait dans l’ensemble des ﬁchiers du
corpus — le mot souris temoin dans l’experience n’apparait pas au sein du corpus).

3 Acquisition terminologique supervisée

3.1 Cadre de recherche - Problématique

Nos recherches en semantique pour le TAL repondent aux exigences suivantes : nous desirons
elaborer des modeles et construire des outils permettant des traitements syntagmatiques
rapides et des representations paradigmatiques non exhaustives a priori, c'est-a-dire aboutir a
une semantique légére. Nous nous placons dans une approche anthropocentree ou la machine
se construit autour des besoins de l'utilisateur (Thlivitis, 1998), et nous revendiquons une
approche praxeologique de l'actiVite langagiere (semantique tournee Vers la pratique de la
langue par un individu ou un groupe restreint d'indiVidus). De plus, nous desirons constuire
une semantique lexicale intra-linguistique textuellement situee (a l’oppose d’une semantique
purement referentielle qui etudierait les rapports des expressions au monde - selon la
difference soulignee par (Auroux, 1999 p.38). Le logiciel decrit dans cet article et l'exemple
d'application s'inscriVent donc pleinement dans ce cadre.

La realisation de MemLab0r est consecutive a une etude semi-manuelle debutee en 2000 dans
le cadre d’un projet Visant a proposer des outils de ﬁltrage et de reordonnancement de
resultats de systemes documentaires classiques (moteurs de recherche du Web) en fonction de
ressources semantiques fournies par l’utilisateur (Perlerin, 2001). Cette etude semi-manuelle
de 1783 depéches journalistiques (Corpus Reuter) avait montre que les pourcentages de
cooccurrences en nombre de ﬁchiers a l’interieur d’un corpus homogene (Figure 5) pouvaient
étre un indice Valable pour le choix de lexies appartenant a des themes proches en Vue de
construire des systemes de classes de categorisation selon le modele Anadia (Coursil,
2000)(Beust, 1998). Cette observation peut étre partiellement expliquee par la notion
d’isotopie (recurrence syntagmatique d’un meme trait semantique) support crucial du sens
dans les textes. Les lexies candidates a une meme classe de categorisation partagent en effet
un certain nombre de traits generiques (Rastier, 1994) dont la redondance au sein des entites
textuelles conditionne le sens. C’est la determination du global sur le local.

MemLabor, un outil de creation, de gestion et de manipulation de corpus de textes

3.2 Aide pour la constitution de classes de catégorisation sémantique

Nos recherches concernent la dimension thématique de la cohésion textuelle. A partir d’un
corpus homogéne, il s’agit ici de constituer des classes de catégorisation sémantiques au sens
des taxe‘mes de la sémantique interprétative (Rastier, 1994): «structure paradigmatique
constituée par des unités lexicales se partageant une zone commune de signiﬁcation et se
trouvant en opposition immediate les unes avec les autres >>. En d’autres termes et dans un
cadre différentiel, il s’agit de structurer des ensembles de mots appartenant a un méme theme
en formant des sous-ensembles au sein desquels on peut marquer leur différence - voir le
modéle Anadia (Nicolle et al., 2002). Notre but est de foumir aux utilisateurs une aide a la
constitution de telles ressources.

Deux taches sont a réaliser: l’extraction des candidats termes et le classement de ces
candidats aux seins de sous-ensembles. Dans la littérature, on trouve de nombreuses
techniques d’acquisition de terminologie: en fonction de critéres principalement morpho-
syntaxique (TERMINO [David et Plante, 1990], et LEXTER [Bourigault, 1994], ...), en
fonction de critéres principalement statistiques (ANA [Enguehard, 1993], [Riloff et Shreperd,
1997],...), ou encore en fonction de marqueurs a priori (SEEK de Christophe Jouis, COATIS
de Daniela Garcia). Désirant restreindre au maximum la quantité de ressources nécessaires au
traitement et placer l’utilisateur au coeur du systéme, nous avons opté pour l’extractions des
mots du domaine pour une technique statistique simple. Nous nous basons sur un calcul de
type Zipf ﬁltré a l’aide d’une liste de mots sémantiquement limités. En effet, lors du repérage
des lexies mises en jeu dans les documents d’un corpus homogéne, les graphiques en
histogrammes obtenus présentent trois groupes consécutifs (numérotés 1, 2 et 3 dans la Figure
6). Le premier rassemble les lexies fortement redondantes dans la langue et n’ayant pas un
potentiel sémantique important (déterminants, pronoms, articles. . .). Le second regroupe
principalement les mots spéciﬁques au domaine du corpus. Le troisiéme ne présente pas de
particularités remarquables.

Rmbre d'occurrence

CD

@

\ <5)

lexies

Figure 6 : Représentation graphique d’un calcul de type Zipf sur un corpus homogéne.

MemLab0r est actuellement disponible avec une liste de mots ayant un potentiel sémantique
faible ou stoplist en francais contenant 744 entrées. Cette liste représente 6K0 de mémoire et
contient essentiellement les déterminants, pronoms, chiffres, auxiliaires et adverbes courants.

Vincent Perlerin

Des stoplists d’autres langues sont disponibles sur le web (ex: http://download-
west.oracle.com/otndoc/oracle9i/901_doc/text.901/a90121/astopsup.htm#1234).

En ne tenant pas compte des mots présents dans la stoplist lors d’un calcul de type Zipf, la
liste des lexies obtenue rassemble majoritairement des mots spécifiques au domaine du corpus
(fenétre de gauche dans la Figure 3). Parmi cette liste, l’utilisateur peut regrouper les mots qui
selon sa pratique de la langue relevent de la méme thématique. Pour l’aider dans la
constitution des classes de catégorisation, le calcul des cooccurrences des lexies sélectionnées
pour un theme avec les autres lexies de la liste (comme dans la Figure 5) perrnet au logiciel de
lui proposer la liste des lexies fortement cooccurrentes avec celles déja présentes dans la
classe qu’il est en train de constituer. Sur un corpus homogene et pour un domaine thématique
donné, la prise en compte du document dans son entier comme surface d’exploration des
cooccurrences peut s’aVérer sufﬁsante pour aider l’utilisateur dans son choix des ensembles
de catégorisation.

 

Résultats : Microsoft — Libération .I' Essai
Travaux sur corpus cutie.

    
  
 
  
  
 
  
 
  

industrie clavier
51
58
31
Y 92
35
91
U9
3
4?

microsoﬂ windows
3

   
     

microsoﬂ
windows

  
  
  
  
  
  

   
  
 

ordinateur
linux
ﬁrme

  
   
 
 

industrie
DU

 
 

Figure 7 : Copie d’écran de MemLab0r - résultats partiels du calcul des cooccurrences de 35
lexies en pourcentage du nombre de ﬁchiers d’un corpus de 150 articles du journal Libération
sur le proces Microsoft en 2001 (la lexie souris est absente du corpus).

Soit Li, la lexie i et P(Li,Lj) le pourcentage en nombre de fichiers au sein du corpus contenant
Li ou Li apparaits. Si les lexies L1, L2, L3 ...ont été sélectionnées comme candidates a une
méme classe sémantique, le logiciel proposera en fonction d’une table de résultats identique a
celle présentée dans la Figure 7, une liste de lexies Li classées en fonction du produit
P(Li, Li)xP(L2,Li)___ le facteur multiplicateur permettant de rendre compte des proportions de
cooccurrence.

Une premiere expérience (décrite dans (Nicolle et al., 2002)) sur le corpus Reuter a montré
que les résultats ainsi obtenus placaient les mots initialement choisis pour étre candidats a une
méme classe sémantique parrni approximativement les 15 premieres places de la liste. Dans le
cas du corpus utilisé pour cet article (corpus Libération — cf. Figure 7), la Figure 8 présente la
liste obtenue pour les lexies déja candidates a une méme classe: entreprise et ﬁrme (le
tableau de cooccurrences ayant été calculé pour les 60 premieres lexies de la liste obtenue
suite au calcul de type Zipf6).

5 dans la Figure 7, P(n1icrosoft,linux) = 19,64 % et P(linux,n1icrosoft) = 100%.

6 l’ensemb1e des donne'es de l’e'tude sont disponibles sur www.info.ur1icaen.fr/~perlerin

MemLabor, un outil de création, de gestion et de manipulation de corpus de textes

ﬁrme entreprise Produit ﬁrme entreprise Produit
logiciel 68 74 5032 gates 60,87 65,22 3969,9414
intemet 100 50 5000 verdict 57,89 68,42 3960,8338
industrie 65,85 75,61 4978,9185 bill 61,7 63,83 3938,311
gouvennent 73,53 61,76 4541,2128 juge 68,18 56,82 3873,9876
justice 71,43 63,49 4535,0907 appel 71,43 53,57 3826,5051
société 64,71 67,65 4377,6315 Inicrosoﬁ 60 61,82 3709,2
produit 70,59 61,76 4359,6384 proces 65,85 56,1 3694,185
actionnaire 61,11 69,44 4243,4784 pc 57,14 64,29 3673,5306
informatique 66,67 63,33 4222,2111 antitrust 60,71 58,93 3577,6403
logiciel 59,38 70,31 4175,0078 monopole 58,06 56,45 3277,487
concunent 66,67 61,9 4126,873 communication 59,26 53,7 3182,262

Figure 8 : Extrait de la liste des lexies proposees pour les lexies ﬁrme et entreprise. (La liste
complete contient 60 lexies).

Comme on peut le constater dans la Figure 8, les mots raisonnablement candidats a une meme
classe semantique que ﬁrme et entreprise (en gras dans la liste), ne sont pas classes aux
premieres places mais apparaissent a des positions coherentes, plus rapidemment atteignables
par l’utilisateur que dans la liste Zipf globale. L’experience a ete menee sur un corpus non
segmente7 et ne saurait étre validee que dans des conditions reelles. Une experience sera
menee lors de l’atelier-formation organise par l’ARCO8 et le CNRS en juillet de cette annee9.
D’une maniere generale, nous pensons que ce type de calculs supervises par un utilisateur a
meme d’investir une partie de son temps a la constitution de telles ressources pourrait,
couples avec d’autres traitements legers (comme la reconnaissance des noms au sein des
documents), represente une aide importante. Notre objectif est de proposer des outils
semantiques ne necessitant pas de ressources paradigmatiques importantes ; ni de traitements
prealables importants du corpus. L’analyse distributionnelle de documents basee sur une
observation de caracteristiques linguistiques (redondances des termes, principe d’isotopie, ...)
est une piste interessante de recherche pour aider a la constition de telles ressources.

4 Conclusion

Dans cette article, nous avons propose une plateforme de gestion de corpus pour le TAL. Le
logiciel MemLab0r s’inscrit dans une approche cooperative de la recherche en TAL en
permettant l’echange de corpus ou de resultats obtenus sur ces corpus par l’intermediaire
d’une DTD XML. Le caractere open-source du programme en assure aussi sa possible
d’ evolution.

Cette ressource logicielle exploite et rend compte de la dimension intertextuelle des
documents. Des etudes linguistiques recentes (Rastier, 2001) montrent l’importance dans le
processus d’interpretation de la place d’un document dans un ensemble saisi par le lecteur

7 des resultats sur des documents segmentes (pourcentages de cooccurrences dans les segments de documents)
sont disponibles sur www.info.unicaen.fr/~perlerin

8 Association pour la recherche cognitive

9 http://users.info.unicaen.fr/~arme/HTML/atelier.htm

Vincent Perlerin

(ici, le corpus constitué par l’utilisateur) . MemLabor a pour obj ectif de participer a ce genre
d’étude, (re)placant le document au sein d’entités plus grandes inﬂuencant son interprétation
et permettant des expérimentations sur cette dimension textuelle.

Références
Auroux S. (1999), Le langage, la raison et les normes, Paris, PUF.

Beust P. (1998) Contribution a un modele interactionniste du sens, These de Doctorat en
Inforrnatique de l’UniVersité de Caen.

Bourigault D. (1994), Lexter, un logiciel d'extraction de terminologie. Application a
l 'acquisition des connaissances a partir de textes. These en inforrnatique linguistique, Ecole
des hautes Etudes en Sciences Sociales, Paris.

Coursil J. (2000), La fonction muette du langage - Essai de linguistique générale
contemporaine, Editions Ibis Rouge.

David S, Plante P. (1990). De la nécessité d 'une approche morpho-syntaxique dans l 'anab/se
de textes, ICO, 2(3): 140-154.

Enguehard, C (1993). Acquisition de terminologie a partir de gros corpus, Informatique &
Langue Naturelle, ILN'93, Nantes,. 373-3 84.

Nicolle A, Beust P, Perlerin V. (2002), Un analogue de la mémoire pour un agent logiciel
interactif, In Cognito N°21, 37-66.

Perlerin V (2001), La recherche documentaire : une activité langagiere, Actes de TALN-
RECITAL 2001, 469-479.

Rastier F. (2001), Elements de théorie des genres, texte diffusé sur la liste fermée Sémantique
des textes, 2001. http://www.atala.org/je/010428/Rastier/Rastier280401.html

Riloff E., Shepherd J. (1997). A corpus-based approach for building semantic lexicons. In
Cardie, C. et Weischedel, R., editors, Proceedings of the Second Conference on Empirical
Methods in Natural Language Processing, 1 17-124. ACL, Somerset, New Jersey.

Silberstein M. (1993), Le systeme IN TEX, Dictionnaires électroniques et analyse automatique
de textes, Paris, Masson.

Thlivitis T. (1998), Sémantique interpretative Intertextuelle .' assitance informatique
anthropocentrée a la comprehension des textes, These de l'UniVersité de Rennes 1.

Zipf G. K. (1949), Human Behavior and the Principle of Least Eﬂort, Addison-Wesley.

