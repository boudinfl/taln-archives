<?xml version="1.0" encoding="UTF-8"?>
<!-- Fichiers problématiques OCRisés : recital-2003-poster-006 -->
<conference>
	<edition>
		<acronyme>RECITAL'2003</acronyme>
		<titre>5e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues</titre>
		<ville>Batz-sur-Mer</ville>
		<pays>France</pays>
		<dateDebut>2003-06-11</dateDebut>
		<dateFin>2003-06-14</dateFin>
		<presidents>
			<nom>Emmanuel Morin</nom>
		</presidents>
		<typeArticles>
			<type id="long">Papiers longs</type>
			<type id="poster">Posters</type>
		</typeArticles>
		<statistiques>
			<acceptations id="long" soumissions="21">8</acceptations>
			<acceptations id="poster" soumissions="21">8</acceptations>
		</statistiques>
		<siteWeb></siteWeb>
		<meilleurArticle>
<!-- 			<articleId></articleId> -->
		</meilleurArticle>
	</edition>
	<articles>

		<article id="recital-2003-long-001" session="">
			<auteurs>
				<auteur>
					<nom>Chafik Aloulou</nom>
					<email>chafik.aloulou@fsegs.rnu.tn</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Faculté des Sciences Economiques et de Gestion de Sfax Laboratoire de recherche LARIS, B.P. 1088 3018 - Sfax  TUNISIE</affiliation>
			</affiliations>
			<titre>Analyse syntaxique de l'Arabe: Le système MASPAR</titre>
			<type>long</type>
			<pages>419-428</pages>
			<resume>De nombreux systèmes de Traitement Automatique des Langues (TAL) utilisent une architecture séquentielle basée sur la transmission, à la fin de chaque phase danalyse, des résultats trouvés à la phase danalyse suivante. Ces types de systèmes séquentiels posent plusieurs problèmes (i.e. explosion combinatoire des solutions, lourdeur danalyse, etc.). Pour remédier à ces problèmes, plusieurs solutions de remplacement ont vu le jour, nous pouvons citer par exemple, lutilisation des approches multi-agent que nous avons adopté pour faire lanalyse syntaxique de textes Arabes, et que nous présentons dans cet article.</resume>
			<mots_cles>Analyse syntaxique, Robustesse danalyse, HPSG, système multi-agent, AgentBuilder</mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords>Syntactic Analysis, Robust analysis, HPSG, multi-agent system, AgentBuilder</keywords>
		</article>
		<article id="recital-2003-long-002" session="">
			<auteurs>
				<auteur>
					<nom>Francis Brunet-Manquat</nom>
					<email>Francis.Brunet-Manquat@imag.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">GETA-CLIPS-IMAG (UJF &amp; CNRS) BP 53 – 38041 Grenoble Cedex 9, France</affiliation>
			</affiliations>
			<titre>Fusionner pour mieux analyser: quelques idées et une première expérience</titre>
			<type>long</type>
			<pages>429-438</pages>
			<resume>L’objectif de cet article est de présenter nos travaux sur l’analyse d’un énoncé vers une structure de dépendance. Cette structure décrit les relations entre mots, des relations syntaxiques mais également des relations sémantiques de surface de l’énoncé de départ dans un certain contexte. L’idée est de créer une plateforme d’analyse capable d’intégrer des analyseurs linguistiques existants (syntaxiques ou de dépendance) et de fusionner leurs résultats dans le but d’obtenir une analyse de dépendance pour des énoncés quelconques.</resume>
			<mots_cles>Analyse de dépendance, analyse syntaxique, intégration, fusion</mots_cles>
			<title></title>
			<abstract>The article’s goal is to present our work about the parsing of a sentence to a dependency structure. This structure describes the relations between words, syntactic relations but also surface semantic relations of a sentence in a certain context. The idea is to create an analysis’ platform capable of integrating existing linguistic parsers (syntactic parsers or dependency parsers) and to fusion their results to obtain a dependency parsing from a sentence.</abstract>
			<keywords>Dependency parsing, syntactic parsing, integration, fusion</keywords>
		</article>
		<article id="recital-2003-long-003" session="">
			<auteurs>
				<auteur>
					<nom>Sana-Leila Chaar</nom>
					<email>sana.chaar@cea.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Université de Marne la vallée CEA – LIST 18, rue du Panorama BP 6 92265 Fontenay-aux-Roses Cedex</affiliation>
			</affiliations>
			<titre>Extraction de segments thématiques pour la construction de résumé multi-document orienté par un profil utilisateur</titre>
			<type>long</type>
			<pages>439-448</pages>
			<resume>Dans cet article, nous présentons une méthode qui vise à donner à un utilisateur la possibilité de parcourir rapidement un ensemble de documents par le biais d’un profil utilisateur. Un profil est un ensemble de termes structuré en sous-ensembles thématiquement homogènes. L’analyse des documents se fonde pour sa part sur l’extraction des passages les plus étroitement en relation avec ce profil. Cette analyse permet en particulier d’étendre le vocabulaire définissant un profil en fonction du document traité en sélectionnant les termes de ce dernier les plus étroitement liés aux termes du profil. Cette capacité ouvre ainsi la voie à une plus grande finesse du filtrage en permettant la sélection d’extraits de documents ayant un lien plus ténu avec les profils mais davantage susceptibles d’apporter des informations nouvelles et donc intéressantes. La production du résumé résulte de l’appariement entre les segments délimités lors de l’analyse des documents et les thèmes du profil.</resume>
			<mots_cles>Extraction d’information, profil utilisateur, résumé multi-document</mots_cles>
			<title></title>
			<abstract>In this article, we present an information extraction method that selects from a set of documents their most significant excerpts in relation to an user profile. This method relies on both structured profiles and a topical analysis of documents. The topical analysis is notably used for expanding a profile in relation to a particular document by selecting the terms of the document that are closely linked to those of the profile. This expansion is a way for selecting in a more reliable way excerpts that are not strongly linked to profiles but that may bring new and interessant information about their topics.</abstract>
			<keywords>Information extraction, user profile, multi-document summarization</keywords>
		</article>
		<article id="recital-2003-long-004" session="">
			<auteurs>
				<auteur>
					<nom>Laurence Delort</nom>
					<email>laurence.delort@linguist.jussieu.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LaTTICe-TALaNa, Université Paris 7 UFR de Linguistique, case 7003 2, place Jussieu 75251 Paris Cedex 05</affiliation>
			</affiliations>
			<titre>Structure communicative du discours : étude pour la génération automatique de textes</titre>
			<type>long</type>
			<pages>449-458</pages>
			<resume>Dans cet article, nous montrons que la cohérence d’un discours dépend de la relation entre la structure communicative des phrases et la structure du discours. Du point de vue de la synthèse, la visée communicative contrôle la structure du discours, et la structure du discours contraint le choix des structures communicatives phrastiques : nous proposons de reproduire ce processus dans un système de génération de textes. Nous montrons de quelle manière la structure communicative intervient lors de la phase de structuration de document pour permettre la génération de discours cohérents et répondant à des visées communicatives particulières.</resume>
			<mots_cles>Structure communicative (ou structure informationnelle), progression thématique, structure du discours (relations de discours), structuration de document, génération automatique de textes</mots_cles>
			<title></title>
			<abstract>In this paper, we show that discourse coherence depends on the relationship between communicative structure of sentences and discourse structure. From the synthesis point of view, communicative goal controls discourse structure, and discourse structure constrains choice of communicative structures of sentences : we propose to reproduce this process in a natural language generation system. We show how communicative structure can be used during document structuring task so as to produce discourses which are coherent and corresponding to particular communicative goals.</abstract>
			<keywords>Communicative structure (or information structure), thematic progression, discourse structure (discourse relations), document structuring, natural language generation</keywords>
		</article>
		<article id="recital-2003-long-005" session="">
			<auteurs>
				<auteur>
					<nom>Cécile Frérot</nom>
					<email>frerot@univ-tlse2.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">ERSS  Université Toulouse-Le Mirail Maison de la Recherche 5 allées A. Machado 31058 Toulouse Cedex</affiliation>
			</affiliations>
			<titre>Procédures dapprentissage endogène doublées de ressources exogènes : résolution en corpus dune ambiguïté sur de </titre>
			<type>long</type>
			<pages>459-468</pages>
			<resume>Dans cette étude, nous nous intéressons à lapport de ressources exogènes dans un analyseur syntaxique de corpus basé sur des procédures dapprentissage endogène. Nous menons une expérience en corpus sur un cas dambiguïté catégorielle du français (forme de en position postverbale, article ou préposition). Après avoir présenté et évalué la stratégie endogène, nous en analysons les limites. Nous discutons ensuite la perspective dune approche mixte combinant des informations acquises de manière endogène à des informations exogènes (données de sous-catégorisation verbale sur la préposition de). Nous montrons alors comment un apport maximal de ressources exogènes améliore les performances de lanalyseur (+8%, +15% sur les deux corpus évalués). Nous présentons les premiers résultats dune approche mixte avant de conclure sur les orientations futures du travail.</resume>
			<mots_cles>analyse syntaxique automatique, approche endogène, ressource exogène, approche mixte, ambiguïté catégorielle</mots_cles>
			<title></title>
			<abstract>This paper addresses the issue of the contribution of exogenous resources within the framework of a parser, based on endogenous techniques. We discuss how exogenous resources could combine with endogenous techniques in the context of a POS French ambiguity (the word de, determiner or preposition). We present and evaluate our endogenous strategy on cases where verbs are adjacent to de. We highlight the limits of such a strategy and show how exogenous resources improve the parser output (+8%, +15% on the corpus evaluated). Finally, we present the first results of the combined strategy and conclude on future work.</abstract>
			<keywords>automatic parsing, endogenous strategy, exogenous resources, hybrid approach, POS ambiguity</keywords>
		</article>
		<article id="recital-2003-long-006" session="">
			<auteurs>
				<auteur>
					<nom>Guillaume Jacquet</nom>
					<email>guillaume.jacquet@ens.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LaTTICe - CNRS UMR 8094 Langues, Textes, Traitements Informatiques et Cognition Ecole Normale Supérieure 1 rue Maurice Arnoux F-92120 Montrouge</affiliation>
			</affiliations>
			<titre>Polysémie verbale et construction syntaxique : étude sur le verbe jouer</titre>
			<type>long</type>
			<pages>469-478</pages>
			<resume>Dans lanalyse sémantique de textes, un des obstacles au TAL est la polysémie des unités linguistiques. Par exemple, le sens du verbe jouer peut varier en fonction du contexte : Il joue de la trompette (pratiquer) ; Il joue avec son fils (samuser). Une des approches pour traiter ces ambiguïtés de sens, est le modèle de la construction dynamique du sens proposé par B. Victorri et C. Fuchs (1996). Dans ce modèle, on associe à chaque unité polysémique un espace sémantique, et le sens de lunité dans un énoncé donné est le résultat dune interaction dynamique avec les autres unités présentes dans lénoncé. Nous voulons montrer ici que les constructions verbales sont des éléments du co-texte qui contribuent, au même titre que le co-texte lexical, au processus dynamique de construction du sens du verbe. Lobjectif est alors de montrer que les constructions verbales sont porteuses de sens intrinsèque (Goldberg, 1995) et quelles permettent dans notre modèle de contraindre automatiquement le sens d’un verbe.</resume>
			<mots_cles>polysémie, calcul du sens, construction syntaxique, espace sémantique, préposition</mots_cles>
			<title></title>
			<abstract>Polysemy is an important issue in Natural Language Processing. For instance, in French, the meaning of the verb jouer (to play) change with the context : Il joue de la trompette (to practice) ; Il joue avec son fils (to enjoy oneself). The model of "Dynamical construction of meaning" (Victorri, Fuchs, 1996) is an interesting approach for dealing with this problem. In this model, each polysemic unit is assigned a semantic space. The meaning of unit in a particular sentence is the result of a dynamical interaction with all other units of the sentence. In this paper, we consider the syntactic constructions as units contributing to the global meaning like the other linguistics units. We want to show that verbal constructions have an intrinsic meaning (Goldberg, 1995), and that we can use automatically this meaning to held selecting the right meaning of a verb.</abstract>
			<keywords>polysemy, meaning calculation, syntactic structure, semantic space, preposition</keywords>
		</article>
		<article id="recital-2003-long-007" session="">
			<auteurs>
				<auteur>
					<nom>Guillaume Pitel</nom>
					<email>Guillaume.Pitel@limsi.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LIMSI  CNRS Bât. 508 BP 133 F-91403 Orsay CEDEX</affiliation>
			</affiliations>
			<titre>Vers une Approche Fonctionnelle de la Résolution de la Référence dans le Dialogue Finalisé</titre>
			<type>long</type>
			<pages>479-488</pages>
			<resume>Dans cet article, nous montrons linsuffisance du pouvoir dexpression des approches par prédicats pour la résolution de la référence en extension dans un cadre générique de dialogue homme-machine. Cette insuffisance oblige pour linstant les concepteurs de tels systèmes de dialogue à concevoir des heuristiques ad hoc impossibles à intégrer dans un cadre de description unifié. Nous montrons que la résolution des expressions référentielles nécessite la prise en compte du contexte même pour les termes portant sur des caractéristiques intrinsèques aux éléments. Nous proposons alors un formalisme pour représenter la sémantique des extracteurs référentiels intrinsèques. Ce formalisme repose sur trois fonctions, la première permet de calculer le rapport de similarité de deux éléments en fonction dune certaine dimension et dans un certain contexte, les deux autres permettent de partitionner un domaine de référence trié par lutilisation de la première fonction.</resume>
			<mots_cles>Résolution de la Référence Intrinsèque, Approche Fonctionnelle, Dialogue Homme Machine</mots_cles>
			<title></title>
			<abstract>In this paper, we show the lack of expressiveness of predicative approaches for extensional reference resolution. This drawback forces dialogue systems designers to develop specific heuristics for solving some reference cases they cant integrate in a unified representation framework. As we focus on extensional reference resolution in a generic framework for human computer dialogue system, we point the fact that the process of resolving referential expressions needs to take context into account even for expressions involving intrinsic characteristics of elements. Thus we propose a representation model for the semantic of intrinsic referential extractors. This model is built on three functions, the first one serves to calculate the similarity ratio between two elements, the two others serve to partition a reference domain which is previously sorted by the first function.</abstract>
			<keywords>Reference Resolution, Intrinsic Reference, Functional Approach, Human Computer Dialogue</keywords>
		</article>
		<article id="recital-2003-long-008" session="">
			<auteurs>
				<auteur>
					<nom>Didier Schwab</nom>
					<email>schwab@lirmm.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LIRMM Laboratoire d’informatique, de Robotique et de Microélectronique de Montpellier MONTPELLIER - FRANCE</affiliation>
			</affiliations>
			<titre>Société d’agents apprenants et sémantique lexicale : comment construire des vecteurs conceptuels à l’aide de la double boucle</titre>
			<type>long</type>
			<pages>489-499</pages>
			<resume>Dans le cadre de la représentation du sens en TALN, nous développons actuellement un système d’analyse des aspects thématiques des textes et de désambiguïsation lexicale basée sur les vecteurs conceptuels. Ces vecteurs visent à représenter un ensemble d’idées associées à tout segment textuel. À partir de ce modèle, nous avons posé des hypothèses sur la construction des vecteurs. Dans cet article, nous montrons comment ces hypothèses, ainsi que des considérations techniques comme la possibilité de distribuer les tâches à effectuer ou la modularité, nous ont amenées à adopter une architecture multi-agents. Chaque agent possède un certain nombre de compétences, une mémoire qui lui est propre et peut interragir avec son environnement (les autres agents). Pour finir, nous présentons les agents déjà implémentés et un exemple de leur collaboration.</resume>
			<mots_cles>sociétés d’agents, vecteurs conceptuels, sémantique lexicale, apprentissage</mots_cles>
			<title></title>
			<abstract>In the framework of research in meaning representations in NLP, we focus our attention on thematic aspects and lexical disambiguation based on conceptual vectors. These vectors are supposed to encode “ideas” associated to words or expressions. Starting from this model, we have built a number of hypothesis on the construction of vectors. In this article, we show how we adopted a multi-agents architecture using these hypothesis together with some technical considerations such as modularity and tasks distribution. Each agent has some abilities, a memory, and can interact with its environment (the other agents). To conclude, we present implemented agents and an example of their collaboration.</abstract>
			<keywords>agents society, conceptual vectors, lexical semantic, learning</keywords>
		</article>
		<article id="recital-2003-poster-001" session="">
			<auteurs>
				<auteur>
					<nom>Christophe Benzitoun</nom>
					<email>christophebenzitoun@yahoo.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Equipe Delic  Université de Provence 29, Av. Robert Schuman, 13100 Aix-en-Provence</affiliation>
			</affiliations>
			<titre>Un "langage pivot" pour articuler description et formalisation : l’exemple des verbes introducteurs de "que-phrases"</titre>
			<type>poster</type>
			<pages>501-506</pages>
			<resume>Nous présentons dans cet article une réflexion en vue de la modélisation d’une partie du patrimoine descriptif du français finalement peu utilisé en TALN. Pour ce faire, nous utilisons le concept de langage "pivot" qui permet d’articuler la description et la présentation formalisée.</resume>
			<mots_cles>Langage "pivot", que-phrase, description, formalisation</mots_cles>
			<title></title>
			<abstract>This paper presents insights to rewrite in a "one level" formal language a part of French descriptive patrimony finally not much employed in NLP. We make use the concept of "pivot" language that allows to combine the description of a language and his formalized presentation.</abstract>
			<keywords>"pivot" language, Wh-sentence, description, formalization</keywords>
		</article>
		<article id="recital-2003-poster-002" session="">
			<auteurs>
				<auteur>
					<nom>Gaëlle Birocheau</nom>
					<email>gaelle.birocheau@univ-fcomte.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Centre de recherches Lucien TESNIERE  Université de Franche-Comté rue Mégevand 25000 BESANCON FRANCE</affiliation>
			</affiliations>
			<titre>Un étiquetage morphologique pour une résolution des ambiguïtés morphologiques en anglais</titre>
			<type>poster</type>
			<pages>507-514</pages>
			<resume>Cet article expose la recherche effectuée dans le cadre de mon doctorat visant à élaborer un étiquetage morphologique de langlais et à désambiguïser automatiquement les ambiguïtés dues à la morphologie dans le cadre du projet LABELGRAM [9]. Nous montrons quil est très pertinent et efficace de travailler conjointement sur létiquetage et la désambiguïsation. Nous décrivons de manière précise notre contribution au système qui a consisté à mettre en place la partie anglaise. Pour ce faire, nous avons établi un dictionnaire en intention, nous avons évalué quantitativement le phénomène dambiguïté morphologique et établi la validité de la méthode de désambiguïsation par règles contextuelles pour langlais.</resume>
			<mots_cles>Anglais, TAL, étiquetage morphologique, ambiguïtés dues à la morphologie, grammaires locales, contexte</mots_cles>
			<title></title>
			<abstract>The issue of this paper is to present a morphological tagging of English dedicated to resolve morphological ambiguities within the LABELGRAM project. We show it is useful to work on both fields of NLP at the same time since they make their mutual contribution to each other. To establish the base of the English part of the LABELGRAM software, we completely built up an intention dictionary of the English language, we quantitatively brought the ambiguity to the fore, and we precisely described ambiguous contexts of simple words and proved the context based disambiguation valid for English. Finally we give a tool, useful for many NLP fields, even semantic processing.</abstract>
			<keywords>English, NLP, morphological tagging, morphological ambiguities, local grammars, context</keywords>
		</article>
		<article id="recital-2003-poster-003" session="">
			<auteurs>
				<auteur>
					<nom>Marie Calberg</nom>
					<email>marie.calberg@wanadoo.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">OSTERLITS</affiliation>
			</affiliations>
			<titre>Traitement de la morphologie du finnois par transducteurs à nombre fini d’états</titre>
			<type>poster</type>
			<pages>515-520</pages>
			<resume>Cette étude présente un modèle pour le traitement de la morphologie du finnois. Ce modèle est fondé sur des transducteurs à nombre fini d’états. L’approche utilise une façon originale d’organiser les données et de générer dynamiquement une structure sémantique à partir d’une analyse morphologique. L’approche est linguistiquement validée par une étude des suffixes de dérivation verbale en finnois.</resume>
			<mots_cles>Dérivation, suffixe, finnois, tranducteurs à nombre fini d’états</mots_cles>
			<title></title>
			<abstract>This study presents a model for Finnish morphology processing. This model is based on finite-state machines. The approach uses an original way to structure the data and dynamically generates semantic information from the morphology analysis. The approach is linguistically validated by a study of Finnish verbal suffixes.</abstract>
			<keywords>Derivation, suffix, finnish, finite state tranducers</keywords>
		</article>
		<article id="recital-2003-poster-004" session="">
			<auteurs>
				<auteur>
					<nom>Marie-Laure Guénot</nom>
					<email>mlg@lpl.univ-aix.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<nom>Tristan VanRullen</nom>
					<email>tristan@lpl.univ-aix.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Laboratoire Parole et Langage – CNRS – Université de Provence 29 avenue Robert Schuman, 13621 Aix-en-Provence cedex 1</affiliation>
			</affiliations>
			<titre>Un outil de représentation et de développement des Grammaires de Propriétés</titre>
			<type>poster</type>
			<pages>521-526</pages>
			<resume>Nous présentons dans cet article un outil graphique de développement de grammaire, basé sur le formalisme des Grammaires de Propriétés. Nous y exprimons les raisons pour lesquelles l’association d’une représentation complète et ergonomique, et d’un modèle formel flexible et homogène fournit un avantage considérable pour l’intégration des informations issues de la linguistique descriptive.</resume>
			<mots_cles>Linguistique descriptive, Linguistique formelle, Grammaires de Propriétés (GP), Traitement Automatique des Langues Naturelles (TALN), Syntaxe</mots_cles>
			<title></title>
			<abstract>We present in this paper a graphical tool for grammar development, based upon the Property Grammars formalism. We explain the reasons why the association of a complete and ergonomic representation and a neutral and homogeneous model, provides the considerable advantage of integrating information coming from descriptive linguistics.</abstract>
			<keywords>Descriptive linguistics, Formal linguistics, Property Grammars (PG), Natural Language Processing (NLP), Syntax</keywords>
		</article>
		<article id="recital-2003-poster-005" session="">
			<auteurs>
				<auteur>
					<nom>Fabien Jalabert</nom>
					<email>jalabert@lirmm.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LIRMM (CNRS - Université Montpellier 2) Laboratoire d’Informatique, de Robotique et de Microélectronique de Montpellier 161, rue Ada - F - 34392 Montpellier Cedex 5</affiliation>
			</affiliations>
			<titre>Annotation sémantique hors-source à l’aide de vecteurs conceptuels</titre>
			<type>poster</type>
			<pages>527-532</pages>
			<resume>Dans le cadre de la recherche en sémantique lexicale, nous utilisons le modèle des vecteurs conceptuels pour représenter les sens de termes. La base vectorielle est construite à partir de définitions provenant de diverses sources lexicales, ce qui permet statistiquement de tempérer les diverses incohérences locales. Pour désigner le sens obtenu après un regroupement des définitions, nous utilisons un identificateur qui entraîne certaines contraintes. En particulier, un “cluster” de définition est désigné par une référence vers différentes définitions de la multisource. D’autre part, le contrôle de la qualité d’une classification ou désambiguisation de sens impose de faire référence en permanence au lexique source. Nous proposons donc de nommer un sens à l’aide d’un autre terme du lexique. L’annotation est un outil léger et efficace qui est essentiellement une association d’idées que l’on peut extraire de toute base de connaissance linguistique. Les annotations obtenues peuvent finalement constituer une nouvelle source d’apprentissage pour la base de vecteurs conceptuels.</resume>
			<mots_cles>annotation sémantique, désambiguisation sémantique lexicale</mots_cles>
			<title></title>
			<abstract>In the framework of research in meaning representation in NLP, we focus our attention on thematic aspects and conceptual vectors. This vectorial base is built by a morphosyntaxic analysis of several lexical resources to reduce isolated problems. Also a meaning is a cluster of definitions that are pointed by an Id number. To check the results of an automatic clustering or WSD, we must refer continously to the source dictionnary. We describe in this article a method for naming a word sens by a term of vocabulary. This kind of annotation is a light and efficient method the uses meanings associations someone or something can extract from any lexical knowledge base. Finally, the annotations should become a new lexical learning resource to improve the vectorial base.</abstract>
			<keywords>WSD, word sense disambiguation, word sense tagging, annotation</keywords>
		</article>
		<article id="recital-2003-poster-006" session="">
			<auteurs>
				<auteur>
					<nom>Yiping Li</nom>
					<email>li@zoe.cea.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LIC2M CEA Fontenay-aux-Roses - Université de Marne la Vallée 18 rue du Panorama BP 6, 92265 Fontenay aux Roses Cedex</affiliation>
			</affiliations>
			<titre>Un système de segmentation du chinois basé sur des triplets</titre>
			<type>poster</type>
			<pages>533-538</pages>
			<resume>Un des problèmes rencontrés lors de l’analyse de textes en chinois est qu’il n’existe pas de séparateur entré lés mots dans cette langue. Le mot étant une unité linguistique fondamentale en traitement automatique dé la langue, il est nécessaire d'identifier les mots dans un texte chinois afin que des analysés de plus haut niveau puissent être réalisées. Le but de cet article est dé présenter un système d’idéntification dés mots basé sur un algorithme utilisant des triplets dé catégories grammaticales ét dés fréquences de mots. Cé système comprend deux dictionnaires : l’un dédié aux mots ét à léurs fréquences, l’autré aux triplets dés catégories correspondantes. Les tests qui ont été effectués révèlent que 98,5% dés phrases sont découpées correctement. Certaines erreurs sont dués à la taillé limitée du dictionnaire utilisé. Une réflexion sur la création de nouvelles catégories ét dés études proposant des règles grammaticales sont en cours de réalisation afin d’aug1nénter la performance du système.</resume>
			<mots_cles>Tokenisation, segmentation du chinois, ngrammes, approche statistique, maximum matching</mots_cles>
			<title></title>
			<abstract>One of the problems encountered by Chinese texts analysis is that there is no separator between the words in this language. As a fundamental linguistic unit in automatic treatment of the language, word is necessary to be identified in a Chinese text so that higher-level analyses can be carried out. The goal of this work is to develop a system, identifying words, based on an algorithm of triplets of grammatical categories and words frequencies. This system contains two dictionaries. One is dedicated to the words and their frequencies, the other, to the triplets of the corresponding categories. The tests carried out reveal that this system works very well, 98.5% of the sentences are segmented correctly. Thus, a reflection about the creation of new categories and the study proposing the grammatical rules are carrying out to improve the performance of the triplets.</abstract>
			<keywords>Chinese segmentation, ngrams, statistical approach, maximum matching</keywords>
		</article>
		<article id="recital-2003-poster-007" session="">
			<auteurs>
				<auteur>
					<nom>Hoá Nguyen</nom>
					<email>Ngoc-Hoa.Nguyen@imag.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Laboratoire CLIPS - IMAG – Université Joseph Fourier 385, rue de la Bibliothèque - B.P. 53 - 38041 Grenoble Cedex 9</affiliation>
			</affiliations>
			<titre>Vers une architecture générique de système de dialogue oral homme-machine</titre>
			<type>poster</type>
			<pages>539-546</pages>
			<resume>Cet article présente une architecture générique de système de dialogue oral homme-machine. Premièrement, nous abordons quelques problèmes soulevés par la généricité des systèmes de dialogue homme-machine. Nous décrivons ensuite dans ce cadre quelques systèmes récents et typiques. Nous présentons finalement une architecture générique pour concevoir/construire des systèmes de dialogue oral homme-machine.</resume>
			<mots_cles>Dialogue homme-machine, gestion du dialogue, gestion de la tâche, compréhension, interprétation</mots_cles>
			<title></title>
			<abstract>In this paper, we present a general architecture for the dialog person-machine system that enables human interacts with a machine via speech’s modality. First, we approach some notions of dialog system, the role of the speech in application, their interests and their limitations. Then, we present some recent, critical dialog person-machine systems and finally, we describe our architecture proposed for designing and constructing the general dialog systems.</abstract>
			<keywords>Human-machine dialogue system, dialogue management, task management, comprehension, interpretation</keywords>
		</article>
		<article id="recital-2003-poster-008" session="">
			<auteurs>
				<auteur>
					<nom>Omar Nouali</nom>
					<email>onouali@mail.cerist.dz</email>
					<affiliationId>1</affiliationId>
					<affiliationId>2</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Laboratoire des Logiciels de base, CE.R.I.S.T, Rue des 3 frères Aïssiou, Ben Aknoun, Alger, Algérie</affiliation>
				<affiliation affiliationId="2">LPL- Université de Provence 29, Av. Robert Schuman, F-13621 Aix-en-Provence, France</affiliation>
			</affiliations>
			<titre>Sélection de critères pour le filtrage automatique de messages</titre>
			<type>poster</type>
			<pages>547-552</pages>
			<resume>La plupart des systèmes de filtrage du courrier électronique existants enregistrent des lacunes ou faiblesses sur lefficacité du filtrage. Certains systèmes sont basés seulement sur le traitement de la partie structurée (un ensemble de règles sur lentête du message), et dautres sont basés sur un balayage superficiel de la partie texte du message (occurrence dun ensemble de mots clés décrivant les intérêts de lutilisateur). Cet article propose une double amélioration de ces systèmes. Dune part, nous proposons un ensemble de critères automatisables et susceptibles dinfluer sur le processus de filtrage. Ces critères sont des indices qui portent généralement sur la structure et le contenu des messages. Dautre part, nous utilisons une méthode dapprentissage automatique permettant au système dapprendre à partir de données et de sadapter à la nature des mails dans le temps. Dans cet article, nous nous intéressons à un type de messages bien particulier, qui continue à polluer nos boîtes emails de façon croissante : les messages indésirables, appelés spam. Nous présentons à la fin les résultats dune expérience dévaluation.</resume>
			<mots_cles>Filtrage dinformation, e-mail, réseaux de neurones, apprentissage, spam</mots_cles>
			<title></title>
			<abstract>Most of existing filtering messages systems exhibit weaknesses in term of efficiency. In fact, there are systems that use only message header information and others use a superficial processing of message body. In this paper, we try to improve the filtering processes efficiency. First, we introduce a set of criteria which are cues related to the message structure and content. Second, we use a machine learning method allowing the system to learn from data and to adapt to the email nature. We are interested in a special type of messages that continuously poluate our email boxes: spam email. At the end, to measure the approach performances, we illustrate and discuss the results obtained by experimental evaluations.</abstract>
			<keywords>Information filtering, e-mail, neural network, learning, e-mail filtering, spam</keywords>
		</article>
	</articles>
</conference>