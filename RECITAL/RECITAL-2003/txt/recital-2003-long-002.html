<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Fusionner pour mieux analyser: quelques id&#233;es et une premi&#232;re exp&#233;rience</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#201;CITAL 2003, Batz-sur-Mer, 11-14 juin 2003
</p>
<p>Fusionner pour mieux analyser!:
quelques id&#233;es et une premi&#232;re exp&#233;rience
</p>
<p>Francis Brunet-Manquat
</p>
<p>GETA-CLIPS-IMAG (UJF &amp; CNRS)
BP 53 &#8211; 38041 Grenoble Cedex 9, France
</p>
<p>Francis.Brunet- Manquat@imag.fr
</p>
<p>Mots-clefs &#8211; Keywords
Analyse de d&#233;pendance, analyse syntaxique, int&#233;gration, fusion.
</p>
<p>Dependency parsing, syntactic parsing, integration, fusion.
</p>
<p>R&#233;sum&#233; &#8211; Abstract
L&#8217;objectif de cet article est de pr&#233;senter nos travaux sur l&#8217;analyse d&#8217;un &#233;nonc&#233; vers une
structure de d&#233;pendance. Cette structure d&#233;crit les relations entre mots, des relations
syntaxiques mais &#233;galement des relations s&#233;mantiques de surface de l&#8217;&#233;nonc&#233; de d&#233;part dans
un certain contexte. L&#8217;id&#233;e est de cr&#233;er une plateforme d&#8217;analyse capable d&#8217;int&#233;grer des
analyseurs linguistiques existants (syntaxiques ou de d&#233;pendance) et de fusionner leurs
r&#233;sultats dans le but d&#8217;obtenir une analyse de d&#233;pendance pour des &#233;nonc&#233;s quelconques.
</p>
<p>The article&#8217;s goal is to present our work about the parsing of a sentence to a dependency
structure. This structure describes the relations between words, syntactic relations but also
surface semantic relations of a sentence in a certain context. The idea is to create an analysis&#8217;
platform capable of integrating existing linguistic parsers (syntactic parsers or dependency
parsers) and to fusion their results to obtain a dependency parsing from a sentence.
</p>
<p>1 Introduction
Notre laboratoire est impliqu&#233; dans deux projets internationaux importants!: CSTAR, avec le
projet europ&#233;en associ&#233; NESPOLE! (http://nespole.itc.it) pour la traduction de parole et UNL,
Universal Networking Language (http://www.unl.ias.unu.edu), pour la traduction de l&#8217;&#233;crit.
Ces deux projets se caract&#233;risent notamment par la pr&#233;sence d&#8217;une repr&#233;sentation pivot des
&#233;nonc&#233;s et par le fait que l&#8217;&#233;nonc&#233; &#224; traduire est susceptible d&#8217;&#234;tre &#8220;!bruit&#233;!&#8221;, c&#8217;est-&#224;-dire pas
forc&#233;ment conforme &#224; la grammaire acad&#233;mique de la langue fran&#231;aise.
</p>
<p>L&#8217;objectif de cet article est de pr&#233;senter nos travaux sur l&#8217;&#233;tude et la r&#233;alisation d&#8217;un outil
robuste pour l&#8217;analyse de d&#233;pendance. Cet outil doit &#234;tre capable d&#8217;int&#233;grer des analyseurs
linguistiques existants (syntaxique ou de d&#233;pendance) et de fusionner leurs r&#233;sultats dans le
but d&#8217;obtenir une analyse de d&#233;pendance pour des &#233;nonc&#233;s quelconques. L&#8217;outil doit &#234;tre</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Francis Brunet-Manquat
</p>
<p>robuste!: capable de fournir une analyse, m&#234;me partielle, d&#8217;une entr&#233;e mal form&#233;e (erreur de
syntaxe, mots erron&#233;s). La structure de d&#233;pendance ainsi obtenue d&#233;crit les relations entre
mots, des relations syntaxiques mais &#233;galement des relations s&#233;mantiques de surface de
l&#8217;&#233;nonc&#233; de d&#233;part dans un certain contexte. L&#8217;outil cr&#233;&#233; doit pouvoir &#234;tre utilis&#233; et param&#233;tr&#233;
par un utilisateur non sp&#233;cialiste de l&#8217;informatique, mais ayant une bonne connaissance
linguistique de la langue &#224; traiter.
</p>
<p>L&#8217;id&#233;e principale est de mettre en place une plateforme d&#8217;analyse capable d&#8217;extraire des
informations linguistiques provenant d&#8217;un ensemble d&#8217;analyseurs et de traiter ces diff&#233;rentes
informations pour obtenir un ensemble de relations probables entre les mots d&#8217;un &#233;nonc&#233;.
Pour ce faire, nous devons dans un premier temps &#233;tudier les r&#233;sultats obtenus &#224; partir de
diff&#233;rents analyseurs pour d&#233;terminer si les informations de chaque r&#233;sultat peuvent &#234;tre
extraites et fusionn&#233;es. &#192; partir d&#8217;une telle id&#233;e, nous pourrons construire un analyseur de
d&#233;pendance plus robuste et plus adaptable en combinant diff&#233;rentes sources d&#8217;analyse.
</p>
<p>&#192; long terme, nous comptons valider l&#8217;&#233;tude et la r&#233;alisation de notre outil d&#8217;analyse de
d&#233;pendance, en concevant une extension permettant de g&#233;n&#233;rer des hypergraphes UNL
(Universal Networking Language). Un hypergraphe d&#233;crit le sens de l&#8217;&#233;nonc&#233; dans un
contexte donn&#233;. Il est compos&#233; d&#8217;arcs repr&#233;sentant des relations s&#233;mantiques (tels qu&#8217;agent,
objet, but,etc.) et de n&#339;uds repr&#233;sentant les UW (&#171;!Universal Word!&#187;, ou acceptions
interlingues) auxquelles sont associ&#233;s des attributs s&#233;mantiques (S&#233;rasset et Boitet 2000).
Pour g&#233;n&#233;rer ce type de graphe, la structure de d&#233;pendance fournie par notre outil d&#8217;analyse
nous semble particuli&#232;rement ad&#233;quate, vu qu&#8217;elle repr&#233;sente &#233;galement un ensemble de
relations entre mots. Une telle structure associ&#233;e &#224; un dictionnaire sp&#233;cifique nous permettra
dans un premier temps de g&#233;n&#233;rer des hypergraphes simples, compos&#233;s d&#8217;informations
s&#233;mantiques de surface.
</p>
<p>Dans cet article, nous allons pr&#233;senter l&#8217;&#233;tude r&#233;alis&#233;e sur diff&#233;rents analyseurs d&#233;j&#224; existants.
Puis nous d&#233;crirons l&#8217;organisation de notre outil d&#8217;analyse de d&#233;pendance. Finalement, nous
pr&#233;senterons une premi&#232;re exp&#233;rimentation.
</p>
<p>2 &#201;tude
Pour r&#233;aliser une plateforme d&#8217;analyse regroupant plusieurs analyseurs, il faut, dans un
premier temps, conna&#238;tre les particularit&#233;s de ces analyseurs et surtout les caract&#233;ristiques des
r&#233;sultats fournis par ceux-ci. Une telle connaissance de chaque analyseur nous permet de
d&#233;terminer la compl&#233;mentarit&#233; de certains analyseurs, la performance de chaque analyseur
selon le type d&#8217;&#233;nonc&#233; (bruit&#233; ou non), la pertinence selon la typologie, le traitement de
certains ph&#233;nom&#232;nes linguistique, etc. Cette &#233;tude a &#233;t&#233; r&#233;alis&#233;e dans un premier temps sur
des analyseurs du fran&#231;ais, nous compl&#233;terons progressivement cette &#233;valuation avec d&#8217;autres
analyseurs du fran&#231;ais puis nous &#233;tudierons les analyseurs d&#8217;autres langues, notre outil se
devant d&#8217;&#234;tre adaptable au plus grand nombre de langues possibles.
</p>
<p>2.1 Analyseurs
</p>
<p>Nous pouvons distinguer deux types d&#8217;analyseurs!: les analyseurs linguistiques, fond&#233;s sur
des formalismes grammaticaux, et les analyseurs probabilistes, fond&#233;s sur l&#8217;apprentissage &#224;
partir de corpus. Pour notre &#233;tude et la r&#233;alisation de notre outil, nous avons choisi d&#8217;utiliser
dans un premier temps des analyseurs linguistiques. La plupart de ces analyseurs se</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#201;CITAL 2003, Batz-sur-Mer, 11-14 juin 2003
</p>
<p>r&#233;partissent en trois cat&#233;gories en fonction des r&#233;sultats qu&#8217;ils fournissent (Monceaux et
Robba 2002)!!:
</p>
<p>&#8226; Les analyseurs fond&#233;s sur les constituants qui retournent une segmentation en groupes.
&#8226; Les analyseurs fond&#233;s sur les d&#233;pendances qui retournent les d&#233;pendances entre mots
</p>
<p>d&#8217;une phrase.
&#8226; Les analyseurs fond&#233;s sur les constituants et les d&#233;pendances qui retournent une
</p>
<p>segmentation en groupes et des relations de d&#233;pendance entre ces groupes et entre les
mots.
</p>
<p>Dans la suite, nous pr&#233;sentons les quatre analyseurs &#224; notre disposition!: l&#8217;analyseur
syntaxique de la plateforme Xelda d&#233;velopp&#233; par Rank Xerox, l&#8217;analyseur du GREYC
d&#233;velopp&#233; par Jacques Vergne, l&#8217;analyseur syntaxique du projet Lidia d&#233;velopp&#233; au GETA.
Ces trois analyseurs sont fond&#233;s sur les constituants et les d&#233;pendances.
</p>
<p>2.1.1 Analyseur syntaxique de la plateforme Xelda
</p>
<p>L'outil d&#8217;analyse IFSP (Incremental Finite-State Parser) (Ait-Mokhtar et Chanod 1997) de la
plateforme Xelda (http://www.xrce.xerox.com/ats/xelda/) est un analyseur syntaxique partiel
qui construit les groupes syntagmatiques noyaux des phrases en entr&#233;e, puis utilise la structure
ainsi construite pour extraire des relations syntaxiques entre les mots (sujet, sujet passif, objet
direct, etc.). Les phrases sont pr&#233;alablement segment&#233;es et &#233;tiquet&#233;es avec un &#233;tiqueteur
morpho-syntaxique, afin de r&#233;duire les &#233;ventuelles ambigu&#239;t&#233;s d'analyse. Les phrases ainsi
&#233;tiquet&#233;es sont alors segment&#233;es en groupes noyaux (chunks) dont les mod&#232;les sont d&#233;crits
par des suites d'&#233;tiquettes morpho-syntaxiques. Lorsque les groupes noyaux sont d&#233;limit&#233;s,
l'analyseur assigne &#224; la phrase des &#233;tiquettes de fonction syntaxique principale (sujet, objet,
etc.) et en fonction des r&#232;gles d'extraction sp&#233;cifi&#233;es sur la structure des groupes noyaux,
extrait des relations de d&#233;pendances syntaxiques explicites entre les mots.
</p>
<p>SUBJ(Pierre,travaille)
VMODOBJ(travaille,dans,bureau)
</p>
<p>0:  (ROOT)
   1: SC(TAG &lt;0 1&gt;)
      2: NP(TAG &lt;0 0&gt;)
         3: Pierre PROPRN
         3: SUBJ(FUNC)
      2:  :v(HEAD)
      2: travaille VERB
   1: PP(TAG &lt;2 4&gt;)
      2: dans PREP
      2: son DET
      2: bureau NOUN
   1: .^.+SENT+SENT+SENT[5](WORD)
</p>
<p>Exemple 1 : R&#233;sultat Xelda  filtr&#233; de la phrase &quot;Pierre travaille dans son bureau.&quot;
</p>
<p>2.1.2 Analyseur du GREYC (Jacques Vergne)
</p>
<p>L'analyseur syntaxique de GREYC combine des techniques d'&#233;tiquetage grammatical
(Tagging) pour construire des segments non-r&#233;cursifs (SNR) et un algorithme de calcul de
d&#233;pendances pour calculer la structure fonctionnelle (Vergne 1998). Ce syst&#232;me est</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Francis Brunet-Manquat
</p>
<p>d&#233;terministe et a une complexit&#233; lin&#233;aire (http://users.infocaen.fr/~jvergne/). L&#8217;analyseur a &#233;t&#233;
test&#233; sur diff&#233;rents types de corpus (extraits d'articles du journal Le Monde) et a &#233;t&#233; &#233;valu&#233;
dans le cadre de l&#8217;action Grace (Adda et al 1999).
</p>
<p>SNR nominal : Pierre
SNR verbal : travaille
SNR nominal : dans son bureau [bureau gouverneur]
</p>
<p>Relations de d&#233;pendance :
</p>
<p>Exemple 2 : R&#233;sultat filtr&#233; de la phrase &quot;Pierre travaille dans son bureau.&quot;
</p>
<p>2.1.3 Lidia
</p>
<p>Cet outil d&#8217;analyse a &#233;t&#233; d&#233;velopp&#233; pour le projet LIDIA (Large Internationalisation des
Documents par Interaction avec l&#8217;Auteur) (Boitet et Blanchon 1995) &#224;  partir du g&#233;n&#233;rateur de
syst&#232;me de TAO ARIANE-G5 (Boitet 1990). Cet analyseur fournit un arbre de constituant
comme r&#233;sultat d&#8217;analyse. Le mod&#232;le linguistique utilis&#233; repose sur une structure arborescente
&#171;!multi-niveau!&#187;. La structure produite est dite multi-niveau car les n&#339;uds portent, entre
autres, des d&#233;corations complexes qui repr&#233;sentent trois niveaux d&#8217;interpr&#233;tation!: le niveau
des classes syntaxiques et des classes syntagmatiques, le niveau des fonctions syntaxiques, et
enfin le niveau des relations logiques et s&#233;mantiques.
</p>
<p>Etiquette 4 : ENONCP(DECL),K(PHVB),etc.
Etiquette 5 : FS(SUJ),K(GN),RL(ARG0),etc.
Etiquette 6 : UL('GOV'),FS(SUJ),K(GN),etc.
Etiquette 7 : UL('*PIERRE_MS'),CAT(N),GNR(MAS),NBR(SING),SENS(1),etc.
Etiquette 9 : UL('TRAVAILLER_V'),AUX(AVOIR),SENS(1),etc.
Etiquette 10 : FS(CIRC),K(GN),etc.
Etiquette 12 : UL('DANS'),CAT(S),SEM1(CONCRET,LIEU),SENS(2),etc.
Etiquette 13 : FS(DES),CAT(D),etc.
Etiquette 14 : UL('GOV'),FS(CIRC),K(GN),etc.
Etiquette 15 : UL('BUREAU_NM'),CAT(N),SENS(1),etc.
</p>
<p>Exemple 3 : R&#233;sultat LIDIA filtr&#233; de la phrase &quot;Pierre travaille dans son bureau.&quot;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#201;CITAL 2003, Batz-sur-Mer, 11-14 juin 2003
</p>
<p>2.2 &#201;tude qualitative
</p>
<p>Cette &#233;tude nous a permis de r&#233;pertorier les diff&#233;rentes informations produites par les
analyseurs (relations entre mots, groupements de mots, etc.) et de comparer les diff&#233;rentes
particularit&#233;s de chaque analyseur afin de v&#233;rifier la pr&#233;sence d&#8217;informations utiles pour
r&#233;aliser une analyse de d&#233;pendance. Cette &#233;tude nous permet surtout d&#8217;&#233;valuer la
compl&#233;mentarit&#233; des analyseurs et de d&#233;finir certains des crit&#232;res &#224; utiliser lors de la fusion
des r&#233;sultats des diff&#233;rents analyseurs. Nous avons class&#233; toutes ces informations linguistiques
en 6 cat&#233;gories!:
</p>
<p>&#8226; Syntagmes!: groupe nominal, groupe verbal, groupe adjectival, groupe adverbial,
groupe pr&#233;positionnel, proposition relative, proposition subordonn&#233;e, etc.
</p>
<p>&#8226; Relations syntaxiques!: sujet, objet, gouverneur, compl&#233;ment d&#8217;agent, compl&#233;ment
circonstanciel, coordination, apposition, inclusion, etc.
</p>
<p>&#8226; Relations logiques (relations pr&#233;dicatives)!: num&#233;rotation des arguments, etc.
&#8226; Relations s&#233;mantiques!: contexte, but, cause, cons&#233;quence, instrument, b&#233;n&#233;ficiaire,
</p>
<p>cons&#233;quence, mani&#232;re, mati&#232;re, lieu, qualification, etc.
&#8226; Cat&#233;gories morpho-syntaxiques!: nom, verbe, adjectif, adverbe, subordonnant,
</p>
<p>coordonnant, ponctuation, mot inconnu, pronom, pr&#233;position, d&#233;terminant, participe,
etc.
</p>
<p>&#8226; Variables grammaticales!: genre, nombre, temps, mode, personne, etc.
</p>
<p>Figure 1 : Extrait d&#8217;un tableau de classement</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Francis Brunet-Manquat
</p>
<p>Nous avons cherch&#233; &#224; d&#233;tailler chacune de ces six cat&#233;gories puis de faire correspondre, si
possible, &#224; chaque information d&#233;taill&#233;e les informations fournies par les analyseurs (voir
Figure 1 : Extrait d&#8217;un tableau de classement). Ceci nous permet de voir plus clairement
quelles informations sont disponibles, quelles informations pourront &#234;tre contradictoires et
surtout quelles informations seront compl&#233;mentaires.
</p>
<p>3 Outil d&#8217;analyse de d&#233;pendance
L&#8217;outil d&#8217;analyse de d&#233;pendance ne doit pas int&#233;grer les analyseurs, mais il doit &#234;tre capable
d&#8217;extraire les informations linguistiques de leurs r&#233;sultats, de les interpr&#233;ter et de les
fusionner. Notre outil se compose de quatre modules!:
</p>
<p>&#8226; Module de chargement!: Ce module extrait les informations linguistiques des r&#233;sultats
obtenus par un analyseur linguistique.
</p>
<p>&#8226; Module de normalisation!: Ce module traite l&#8217;information extraite pour la faire
correspondre &#224; notre norme/standard. &#192; chaque information est associ&#233;e un indice de
confiance calcul&#233; en fonction de l&#8217;information et des particularit&#233;s de l&#8217;analyseur.
</p>
<p>&#8226; Module de fusion!: Ce module fusionne les informations normalis&#233;es.
&#8226; Module de g&#233;n&#233;ration!: Ce module g&#233;n&#232;re une structure de d&#233;pendance en fonction des
</p>
<p>informations fusionn&#233;es, des indices de confiance associ&#233;s et de nos r&#232;gles de
g&#233;n&#233;ration.
</p>
<p>Figure 2 : Architecture fonctionnelle de l&#8217;outil d&#8217;analyse
</p>
<p>3.1 Chargement!: r&#233;cup&#233;ration de l&#8217;information
</p>
<p>Le module de chargement est un module capable de charger n&#8217;importe quels types de
r&#233;sultats. Nous prendrons l&#8217;hypoth&#232;se que les analyseurs linguistiques se r&#233;partissent la
plupart du temps en trois cat&#233;gories en fonction des r&#233;sultats qu&#8217;ils produisent (voir 2.1
Analyseurs)!:
</p>
<p>&#8226; Les analyseurs fond&#233;s sur les constituants.
&#8226; Les analyseurs fond&#233;s sur les d&#233;pendances.
&#8226; Les analyseurs fond&#233;s sur les constituants et les d&#233;pendances.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#201;CITAL 2003, Batz-sur-Mer, 11-14 juin 2003
</p>
<p>Dans un premier temps, il faut &#234;tre capable de d&#233;crire le format de repr&#233;sentation des r&#233;sultats
de l&#8217;analyseur, dans notre cas nous d&#233;crivons ce format sous la forme d&#8217;une grammaire
JAVACC (un g&#233;n&#233;rateur d&#8217;analyseurs syntaxiques pour JAVA). Puis &#224; l&#8217;int&#233;rieur de cette
grammaire, nous introduisons des m&#233;thodes de chargement en fonction de la cat&#233;gorie du
r&#233;sultat!: !
</p>
<p>&#8226; Soit une m&#233;thode permettant de charger des relations de d&#233;pendance!:
&#8226; AjoutRelation(TypeRelation, Mot1, Mot2).
</p>
<p>&#8226; Soit une m&#233;thodes permettant de charger des constituants!:
&#8226; AjoutSyntagme(TypeSyntagme, Ensemble de mots ou de syntagmes).
</p>
<p>Nous devrons &#233;galement avoir une m&#233;thode de chargement de l'information associ&#233;e &#224; un
mot!:
</p>
<p>&#8226; AjoutCat&#233;gorie(Mot, Information).
&#8226; AjoutCat&#233;gorie (Mot, Information, Valeur).
</p>
<p>3.2 Normalisation de l&#8217;information
</p>
<p>Apr&#232;s avoir extrait toutes les informations des r&#233;sultats d&#8217;un analyseur, il nous faut encore
traiter toutes ces donn&#233;es pour les faire correspondre &#224; notre repr&#233;sentation. Nous utilisons
une repr&#233;sentation matricielle qui nous semble plus ad&#233;quate pour repr&#233;senter un ensemble de
relations. Ce type de repr&#233;sentation permet de manipuler et fusionner facilement des donn&#233;es.
</p>
<p>Pour normaliser toutes ces informations extraites de chaque analyseur, nous nous aidons du
tableau de classement (voir 2.2 &#201;tude). Ce tableau fait correspondre &#224; chaque donn&#233;e extraite
son information normalis&#233;e. Par exemple, pour le r&#233;sultat fourni par Xelda, la relation SUBJ
sera normalis&#233;e pour correspondre &#224; la relation SUJET et ainsi de suite pour toutes les
relations et les cat&#233;gories simples &#224; normaliser. Mais ce tableau devra &#233;galement contenir,
pour certaines informations, des renseignements suppl&#233;mentaires concernant la normalisation
de celle-ci. Par exemple, la relation SUBINV (sujet invers&#233;) extraite de l&#8217;analyse de Xelda
pourra &#234;tre transform&#233;e en une relation sujet gr&#226;ce &#224; la r&#232;gle normalisation!:
</p>
<p>SUBINV($var11, $var2) ::= SUJET::xelda($var1, $var2)
</p>
<p>D&#8217;autres relations posent des probl&#232;mes plus difficiles par exemple la relation VMODOBJ
extraite de l&#8217;analyse de Xelda pourrait avoir plusieurs significations syntaxiques!:
compl&#233;ment circonstanciel (voir Exemple 1 : R&#233;sultat Xelda  filtr&#233; de la phrase &quot;Pierre
travaille dans son bureau.&quot;), compl&#233;ment d&#8217;objet direct, etc. L&#8217;id&#233;e est d&#8217;associer &#224; chaque
information linguistique pouvant &#234;tre extraite un indice de confiance2!:
</p>
<p>VMODOBJ($var1, $prep, $var2) ::= COMPLEMENT_CIRCONSTANCIEL($var1, $var2)
                                indice_de_confiance = 0,8
</p>
<p>VMODOBJ($var1, $prep, $var2) ::= COMPLEMENT_OBJET_DIRECT($var1, $var2)
                                indice_de_confiance = 0,2
</p>
<p>                                                 
1 La variable $var repr&#233;sente soit un mot soit un syntagme, . la variable $prep repr&#233;sente un mot.
</p>
<p>2 L&#8217;indice varie de 0 &#224; 1, 1 &#233;tant l&#8217;indice de confiance maximum.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Francis Brunet-Manquat
</p>
<p>Cet indice sera d&#233;termin&#233; &#224; l&#8217;aide d&#8217;un apprentissage r&#233;alis&#233; &#224; partir d&#8217;un corpus de
r&#233;f&#233;rence3. Cet indice exprime la confiance relative &#224; l&#8217;information en fonction de l&#8217;analyseur
et de la typologie de l&#8217;&#233;nonc&#233;. Cet indice sera recalcul&#233; lors de la fusion en fonction des autres
indices associ&#233;s &#224; la m&#234;me information linguistique fournis par les autres analyseurs et du
nombre d&#8217;analyseurs pouvant fournir ce type d&#8217;information (voir 3.3 Fusion des informations
linguistiques). L&#8217;indice ainsi recalcul&#233; permettra lors de la g&#233;n&#233;ration de d&#233;terminer si
l&#8217;information correspondante doit &#234;tre conserv&#233;e ou supprim&#233;e (voir 3.4 G&#233;n&#233;ration des
structures de d&#233;pendance).
</p>
<p>La m&#233;thode explicit&#233;e ci-dessus est bas&#233;e sur la m&#233;thode dite de &#171;!vote &#224; la majorit&#233;!&#187; (plus
une information sera commune aux diff&#233;rents analyseurs, plus son indice de confiance
augmentera). Chaque indice pourra &#234;tre vu comme le vote pond&#233;r&#233; de l&#8217;analyseur pour
l&#8217;information, ce vote &#233;tant adapt&#233; aux diff&#233;rentes possibilit&#233;s de l&#8217;analyseur en fonction de
l&#8217;&#233;nonc&#233; (par exemple, entr&#233;e bruit&#233;e ou non) lors de l&#8217;apprentissage.
</p>
<p>3.3  Fusion des informations linguistiques
</p>
<p>&#192; ce moment de l&#8217;analyse, &#224; chaque r&#233;sultat fourni par un analyseur est associ&#233;e une
repr&#233;sentation matricielle comprenant toutes les informations linguistiques normalis&#233;es
extraites. Dans ce module, nous fusionnons toutes ces repr&#233;sentations pour obtenir une
repr&#233;sentation matricielle finale contenant toutes les informations extraites de chaque
analyseur. Certaines informations linguistiques seront compl&#233;mentaires, d&#8217;autres
contradictoires. Il ne s&#8217;agit pas simplement de regrouper toutes les informations, il faut
&#233;galement calculer de nouveaux indices de confiance pour chaque information en fonction des
indices de confiance fournis par le module de normalisation.
</p>
<p>D&#233;finition du calcul du nouvel indice associ&#233; &#224; l&#8217;information i !:
</p>
<p>Par exemple, calculons le nouvel indice de confiance &#224; associer &#224; l&#8217;information!: relation
SUJET entre les mots x et y, fournie &#224; la fois par l&#8217;analyseur de Xelda et par l&#8217;analyseur de
Vergne. L&#8217;indice de fusion associ&#233; &#224; SUJET(x,y) est &#233;gal &#224; la somme des deux indices de
confiance indice(SUJET::xelda)=0,5 et indice(SUJET::vergne)=0,7 divis&#233; par le nombre
d&#8217;analyseurs pouvant fournir ce type d&#8217;information (ici trois), (0,5+0,7+0)/3 = 0,4. Si le
troisi&#232;me analyseur fournit &#233;galement une information de type SUJET entre les mots x et z, et
que l&#8217;indice de confiance relatif &#224; cette information est de 0,8. L&#8217;indice de fusion associ&#233; &#224;
SUJET(x,z) est &#233;gal &#224; (0+0+0,8)/3 = 0,26.
On peut constater que notre calcul favorise les informations fournies par le plus grand nombre
d&#8217;analyseurs et ayant des indices &#233;lev&#233;s. Les nouveaux indices ainsi calcul&#233;s serviront lors de
la phase de g&#233;n&#233;ration.
</p>
<p>                                                 
3 Le module d&#8217;apprentissage est en cours de r&#233;alisation et sera bas&#233; sur une m&#233;thode de r&#233;tro-propagation des
</p>
<p>indices. Pour le moment, les indices de confiance sont fix&#233;s manuellement.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#201;CITAL 2003, Batz-sur-Mer, 11-14 juin 2003
</p>
<p>3.4 G&#233;n&#233;ration des structures de d&#233;pendance
</p>
<p>Le dernier module permet d&#8217;obtenir une ou plusieurs structures de d&#233;pendance gr&#226;ce &#224; toutes
les informations recueillies. Les structures de d&#233;pendance sont g&#233;n&#233;r&#233;es &#224; partir des
informations ayant un indice de confiance &#233;lev&#233; et de contraintes linguistiques impos&#233;es par
l&#8217;utilisateur pour &#233;viter les informations contradictoires. Nous pouvons voir ce module
comme un module de satisfaction de contraintes comportant 3 r&#232;gles!: une et une seule
relation entre deux mots, les informations seront conserv&#233;es si leur indice de confiance est au-
dessus d&#8217;un certain seuil et le respect des contraintes linguistiques impos&#233;es par l&#8217;utilisateur.
Notre outil g&#233;n&#233;rera donc plusieurs structures r&#233;sultats pour un &#233;nonc&#233;, &#224; chaque structure
r&#233;sultat sera associ&#233; un indice de pertinence, moyenne pond&#233;r&#233;e des indices de confiance
pr&#233;sents dans la structure.
</p>
<p>4 Premi&#232;re r&#233;alisation
Nous avons r&#233;alis&#233; une premi&#232;re maquette de notre outil ne comportant que les deux premiers
modules!: chargement et normalisation en utilisant une repr&#233;sentation classique en arbre pour
repr&#233;senter nos donn&#233;es. Cette maquette ne charge que deux analyseurs!: l&#8217;analyseur de la
plateforme Xelda et l&#8217;analyseur d&#233;velopp&#233; par Jacques Vergne. Cette premi&#232;re r&#233;alisation
avait pour but de v&#233;rifier nos hypoth&#232;ses de d&#233;part, c&#8217;est-&#224;-dire!: la possibilit&#233; d&#8217;extraire
facilement de l&#8217;information et de la normaliser, ainsi que la possibilit&#233; d&#8217;int&#233;grer facilement
de nouveaux analyseurs &#224; une plateforme d&#8217;analyse. Cette exp&#233;rimentation nous a &#233;galement
permis de distinguer les futurs probl&#232;mes.
</p>
<p>Le corpus de phrases utilis&#233; provient d&#8217;un corpus UNL, Universal Networking Language,
contenant une phrase et son hypergraphe UNL associ&#233;. Ce corpus &#233;tait constitu&#233; de quarante
phrases courtes, neuf mots par phrase en moyenne (minimum 3 mots, maximum 56 mots),
d&#233;crivant de nombreux ph&#233;nom&#232;nes linguistiques!: coordination, n&#233;gation, relative, etc. Par
exemple!:
</p>
<p>&#8226; Une tulipe est plus belle qu'une rose.
&#8226; Il sait que tu ne viendras pas et il ne le regrette pas.
</p>
<p>Dans un premier temps, nous avons donc trait&#233; ces quarante phrases avec l&#8217;analyseur de
Xelda et avec l&#8217;analyseur d&#233;velopp&#233; par J. Vergne. Ce premier traitement, appliqu&#233; &#224; toutes
les phrases du corpus, nous a permis de d&#233;terminer quelques r&#232;gles de normalisation &#224;
associer aux informations fournies par les analyseurs. Pour cette exp&#233;rimentation, nous avons
15 r&#232;gles de normalisation associ&#233;es &#224; chaque analyseur concernant essentiellement les
relations syntaxiques.
</p>
<p>Pour int&#233;grer les deux analyseurs &#224; notre outil, nous avons donc r&#233;alis&#233; leurs grammaires de
r&#233;cup&#233;ration &#224; associer au module de chargement et leurs modules de normalisation ont &#233;t&#233;
g&#233;n&#233;r&#233;s automatiquement en fonction des r&#232;gles de normalisation associ&#233;es &#224; chaque
analyseur. Notre outil a extrait toutes les informations linguistiques fournies par les r&#233;sultats
d&#8217;analyse. Avec seulement 15 r&#232;gles de normalisation, notre outil a d&#233;termin&#233; 78% des
liaisons entre mots (relations non &#233;tiquet&#233;es) et 67% de ces relations ont pu &#234;tre &#233;tiquet&#233;. Les
premiers r&#233;sultats normalis&#233;s fournis pour notre outil sont encourageants, m&#234;me s&#8217;ils restent
limit&#233;s &#224; quelques phrases et quelques r&#232;gles de normalisation, mais surtout les hypoth&#232;ses de
d&#233;part ont pu &#234;tre v&#233;rifi&#233;es.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Francis Brunet-Manquat
</p>
<p>Mais plusieurs probl&#232;mes se sont pr&#233;sent&#233;s, tout d&#8217;abord, la lourdeur de la repr&#233;sentation
arborescente utilis&#233;e. En effet, nous nous sommes vite rendu compte de l&#8217;utilit&#233; de changer de
repr&#233;sentation pour les deux premiers modules mais surtout pour le futur module de fusion et
d&#8217;adopter une repr&#233;sentation de type matricielle, plus maniable et plus adapt&#233;e &#224; nos besoins
(voir 3.2 Normalisation de l&#8217;information). Le second probl&#232;me concerne le besoin
d&#8217;informations linguistiques suppl&#233;mentaires dans le cas des analyseurs fond&#233;s sur les
constituants. Comment trouver les relations entre mots &#224; partir des syntagmes si aucune
information n&#8217;est pas fournie concernant le gouverneur du syntagme. Dans le cas de
l&#8217;analyseur d&#233;velopp&#233; par J. Vergne, l&#8217;information concernant le gouverneur  du syntagme est
fournie mais pas dans le cas de l&#8217;analyseur de Xelda. Nous avons donc besoin d&#8217;une base de
connaissances linguistiques simple permettant de r&#233;soudre ce genre de probl&#232;mes.
</p>
<p>5 Bilan et perspectives
Cette premi&#232;re exp&#233;rience nous a permis de v&#233;rifier la possibilit&#233; de charger des informations
linguistiques extraites de r&#233;sultats d&#8217;analyse fond&#233; sur les constituants et les d&#233;pendances,
mais &#233;galement la possibilit&#233; de normaliser ces informations. Une seconde maquette est en
cours de r&#233;alisation et sera test&#233;e sur 5 analyseurs!: l&#8217;analyseur de la plateforme Xelda,
l&#8217;analyseur Xip d&#233;velopp&#233; par Rank Xerox, l&#8217;analyseur developp&#233; par J. Vergne, l&#8217;analyseur
du projet Lidia, l&#8217;analyseur developp&#233; par J. Chauch&#233;. Nous utilisons le corpus amaryllis
compos&#233; de 140000 fichiers compos&#233; chacun d&#8217;une douzaine de phrases longues (environ une
trentaine de mots). Les phrases sont bien form&#233;es et abordent de nombreuses th&#233;matiques. Ce
corpus a d&#233;j&#224; &#233;t&#233; trait&#233; par l&#8217;analyseur de la plateforme Xelda et est en cours de traitement par
l&#8217;analyseur d&#233;velopp&#233; par J. Vergne. Cette nouvelle maquette int&#233;grera tous les modules et
fournira en r&#233;sultat une ou plusieurs structures de d&#233;pendance.
</p>
<p>Remerciements
Je tiens &#224; remercier Rank Xerox et Jacques Vergne pour m&#8217;avoir permis d&#8217;utiliser leurs
analyseurs.
</p>
<p>R&#233;f&#233;rences
Adda G., Mariani J., Paroubek P., Rajman M., et Lecomte, J. (1999), L'action GRACE
d'&#233;valuation de l'assignation des parties du discours pour le Fran&#231;ais, in revue Langues, Vol.
2(2)!: pp 119-129.
Ait-Mokhtar S., Chanod JP. (1997), Incremental finite-state parsing, in Applied Natural
Language Processing 1997, April 1997, Washington.
Boitet C. (1990), La TAO &#224; Grenoble en 1990. in &#201;cole d&#8217;&#233;t&#233; de Lannion sur le Traitement
Automatique des Langues Naturelles. CENT, juillet 1990, 65 p.
Boitet C., Blanchon H. (1995), Multilingual Dialogue-Based MT for monolingual authors: the
LIDIA project and a first mockup. in Machine Translation. vol. 9(2) : pp!99-132.
Monceaux L., Isabelle Robba I. (2002), Les analyseurs syntaxiques!: atouts pour une analyse
des questions dans un syst&#232;me de question-r&#233;ponse!?, Actes de TALN&#8217;2003, pp.195-204.
S&#233;rasset G., Boitet Ch. (2000), On UNL as the future &quot;html of the linguistic content&quot; &amp; the
reuse of existing NLP components in UNL-related applications with the example of a UNL-
French deconverter, in COLING 2000, Saarebruecken, Germany.
Vergne J., Giguet E. (1998), Regards th&#233;orique sur le &#171;!Tagging!&#187;, Actes de TALN&#8217;1998,
pp 24-33</p>

</div></div>
</body></html>