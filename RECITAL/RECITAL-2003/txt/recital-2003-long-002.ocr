RECITAL 2003, Batz~sur—Mer, I I -14 juin 2003

Fusionner pour mieux analyser :
quelques idées et une premiere expérience

Francis Brunet—Manquat

GETA—CLIPS—IMAG (UJF & CNRS)
BP 53 — 38041 Grenoble Cedex 9, France
Francis.Brunet— Manquat@imag.fr

Mots-clefs — Keywords
Analyse de dépendance, analyse syntaxique, intégration, fusion.

Dependency parsing, syntactic parsing, integration, fusion.
Résumé — Abstract

L’objectif de cet article est de présenter nos travaux sur l’analyse d’un énoncé Vers une
structure de dépendance. Cette structure décrit les relations entre mots, des relations
syntaxiques mais également des relations sémantiques de surface de l’énoncé de départ dans
un certain contexte. L’idée est de créer une plateforme d’analyse capable d’intégrer des
analyseurs linguistiques existants (syntaxiques ou de dépendance) et de fusionner leurs
résultats dans le but d’obtenir une analyse de dépendance pour des énoncés quelconques.

The article’s goal is to present our work about the parsing of a sentence to a dependency
structure. This structure describes the relations between words, syntactic relations but also
surface semantic relations of a sentence in a certain context. The idea is to create an analysis’
platform capable of integrating existing linguistic parsers (syntactic parsers or dependency
parsers) and to fusion their results to obtain a dependency parsing from a sentence.

1 Introduction

Notre laboratoire est impliqué dans deux projets internationaux importants : CSTAR, avec le
projet européen associé NESPOLE! (http://nespole.itc.it) pour la traduction de parole et UNL,
Universal Networking Language (http://www.unl.ias.unu.edu), pour la traduction de l’écrit.
Ces deux projets se caractérisent notamment par la présence d’une représentation pivot des
énoncés et par le fait que l’énoncé a traduire est susceptible d’étre “ bruité ”, c’est—a—dire pas
forcément conforme a la grammaire académique de la langue francaise.

L’objectif de cet article est de présenter nos travaux sur l’étude et la realisation d’un outil
robuste pour l’analyse de dépendance. Cet outil doit étre capable d’intégrer des analyseurs
linguistiques existants (syntaxique ou de dépendance) et de fusionner leurs résultats dans le
but d’obtenir une analyse de dépendance pour des énoncés quelconques. L’outil doit étre

Francis Brunet—Manquat

robuste : capable de fournir une analyse, meme partielle, d’une entree mal formee (erreur de
syntaxe, mots errones). La structure de dependance ainsi obtenue decrit les relations entre
mots, des relations syntaxiques mais egalement des relations semantiques de surface de
l’enonce de depart dans un certain contexte. L’outil cree doit pouvoir etre utilise et parametre
par un utilisateur non specialiste de l’informatique, mais ayant une bonne connaissance
linguistique de la langue a traiter.

L’idee principale est de mettre en place une plateforme d’analyse capable d’eXtraire des
informations linguistiques provenant d’un ensemble d’analyseurs et de traiter ces differentes
informations pour obtenir un ensemble de relations probables entre les mots d’un enonce.
Pour ce faire, nous devons dans un premier temps etudier les resultats obtenus a partir de
differents analyseurs pour determiner si les informations de chaque resultat peuvent etre

extraites et fusionnees. A partir d’une telle idee, nous pourrons construire un analyseur de
dependance plus robuste et plus adaptable en combinant differentes sources d’analyse.

A long terme, nous comptons valider l’etude et la realisation de notre outil d’analyse de
dependance, en concevant une extension permettant de generer des hypergraphes UNL
(Universal Networking Language). Un hypergraphe decrit le sens de l’enonce dans un
contexte donne. Il est compose d’arcs representant des relations semantiques (tels qu’agent,
objet, but,etc.) et de noeuds representant les UW (<< Universal Word >>, ou acceptions
interlingues) auxquelles sont associes des attributs semantiques (Serasset et Boitet 2000).
Pour generer ce type de graphe, la structure de dependance fournie par notre outil d’analyse
nous semble particulierement adequate, vu qu’elle represente egalement un ensemble de
relations entre mots. Une telle structure associee a un dictionnaire specifique nous permettra
dans un premier temps de generer des hypergraphes simples, composes d’informations
semantiques de surface.

Dans cet article, nous allons presenter l’etude realisee sur differents analyseurs deja existants.
Puis nous decrirons l’organisation de notre outil d’analyse de dependance. Finalement, nous
presenterons une premiere experimentation.

2 Etude

Pour realiser une plateforme d’analyse regroupant plusieurs analyseurs, il faut, dans un
premier temps, connaitre les particularites de ces analyseurs et surtout les caracteristiques des
resultats fournis par ceuX—ci. Une telle connaissance de chaque analyseur nous permet de
determiner la complementarite de certains analyseurs, la performance de chaque analyseur
selon le type d’enonce (bruite ou non), la pertinence selon la typologie, le traitement de
certains phenomenes linguistique, etc. Cette etude a ete realisee dans un premier temps sur
des analyseurs du francais, nous completerons progressivement cette evaluation avec d’autres
analyseurs du francais puis nous etudierons les analyseurs d’autres langues, notre outil se
devant d’etre adaptable au plus grand nombre de langues possibles.

2.1 Analyseurs

Nous pouvons distinguer deux types d’analyseurs : les analyseurs linguistiques, fondes sur
des formalismes grammaticaux, et les analyseurs probabilistes, fondes sur l’apprentissage a
partir de corpus. Pour notre etude et la realisation de notre outil, nous avons choisi d’utiliser
dans un premier temps des analyseurs linguistiques. La plupart de ces analyseurs se

RECITAL 2003, Batz~sur—Mer, I I -14 juin 2003

répartissent en trois catégories en fonction des résultats qu’ils fournissent (Monceaux et
Robba 2002) :

Les analyseurs f0nde's sur les constituants qui retournent une segmentation en groupes.

Les analyseurs f0nde's sur les dependances qui retournent les dépendances entre mots
d’une phrase.

Les analyseurs f0nde's sur les constituants et les dependances qui retournent une
segmentation en groupes et des relations de dépendance entre ces groupes et entre les
mots.

Dans la suite, nous présentons les quatre analyseurs a notre disposition: l’analyseur
syntaxique de la plateforme Xelda développé par Rank Xerox, l’analyseur du GREYC
développé par Jacques Vergne, l’analyseur syntaxique du projet Lidia développé au GETA.
Ces trois analyseurs sont fondés sur les constituants et les dépendances.

2.1.1 Analyseur syntaxique de la plateforme Xelda

L'outil d’analyse IFSP (Incremental Finite—State Parser) (Ait—Mokhtar et Chanod 1997) de la
plateforme Xelda (http://www.Xrce.XeroX.com/ats/Xelda/) est un analyseur syntaxique partiel
qui construit les groupes syntagmatiques noyaux des phrases en entree, puis utilise la structure
ainsi construite pour extraire des relations syntaxiques entre les mots (sujet, sujet passif, objet
direct, etc.). Les phrases sont préalablement segmentées et étiquetées avec un étiqueteur
morpho—syntaXique, afin de réduire les éventuelles ambigu'1'tés d'analyse. Les phrases ainsi
étiquetées sont alors segmentées en groupes noyaux (chunks) dont les modeles sont décrits
par des suites d'étiquettes morpho—syntaXiques. Lorsque les groupes noyaux sont délimités,
l'analyseur assigne a la phrase des étiquettes de fonction syntaxique principale (sujet, objet,
etc.) et en fonction des regles d'extraction spécifiées sur la structure des groupes noyaux,
extrait des relations de dépendances syntaxiques explicites entre les mots.

SUBJ(Pierre,travaille)
VMDDOBJ(travaille,dans,bureau)

O: (ROOT)

1: SC(TAG <0 l>)

2: NP(TAG <0 O>)

3: Pierre PROPRN
3: SUBJ(FUNC)
2: :v(HEAD)
2: travaille VERB
1: PP(TAG <2 4>)

2: dans PREP

2: son DET

2: bureau NOUN
1: .".+SENT+SENT+SENT[5] (WORD)

Exemple 1 : Résultat Xelda filtré de la phrase "Pierre travaille dans son bureau."
2.1.2 Analyseur du GREYC (Jacques Vergne)

L'analyseur syntaxique de GREYC combine des techniques d'étiquetage grammatical
(Tagging) pour construire des segments non—récursifs (SNR) et un algorithme de calcul de
dépendances pour calculer la structure fonctionnelle (Vergne 1998). Ce systeme est

Francis Brunet—Manquat

déterministe eta une complexité linéaire (http://users.infocaen.fr/~jVergne/). L’analyseur a été
testé sur différents types de corpus (extraits d'articles du journal Le Monde) et a été évalué
dans le cadre de l’action Grace (Adda et al 1999).

SNR nominal : Pierre
SNR verbal : travaille
SNR nominal : dans son bureau [bureau gouverneur]

Relations de dépendance

[Pierre] [Travaille] [dans son bureau]

Exemple 2 : Résultat filtré de la phrase "Pierre travaille dans son bureau."
2.1.3 Lidia

Cet outil d’analyse a été développé pour le projet LIDIA (Large Internationalisation des
Documents par Interaction avec l’Auteur) (Boitet et Blanchon 1995) a partir du générateur de
systeme de TAO ARIANE—G5 (Boitet 1990). Cet analyseur fournit un arbre de constituant
comme résultat d’analyse. Le modele linguistique utilise repose sur une structure arborescente
« multi—niVeau >>. La structure produite est dite multi—niVeau car les noeuds portent, entre
autres, des decorations complexes qui représentent trois niveaux d’interprétation : le niveau
des classes syntaxiques et des classes syntagmatiques, le niveau des fonctions syntaxiques, et
enfin le niveau des relations logiques et sémantiques.

4:PHVB
5:GN 8:UavmHe 10:GN 19g
6:FNene 9:Uavame 11:dans 13Tson 14:bureau
sensﬂ)

7:F%ene 12:dans 15:bureau 16:bureau 17:bureau 18:bureau

sens(1) sens(2) sens(1) sens(2) sens(3) sens(3)
Etiquette 4 ENONCP(DECL),K(PHVB),etc.
Etiquette 5 FS(SUJ),K(GN),RL(ARGO),etc.
Etiquette 6 UL('GOV'),FS(SUJ),K(GN),etc.
Etiquette 7 UL('*PIERRE_MS'),CAT(N),GNR(MAS),NBR(SING),SENS(l),etc.

Etiquette 9 : UL('TRAVAILLER_V'),AUX AVOIR),SENS(1),etC.
Etiquette 10 : FS(CIRC),K(GN),etc.

Etiquette 12 : UL 'DANS'),CAT(S),SEM1(CONCRET,LIEU),SENS(2),etC.
Etiquette 13 : FS DES),CAT(D),etc.

Etiquette 14 : UL 'GOV'),FS(CIRC),K(GN),etC.

Etiquette 15 : UL 'BUREAU_NM'),CAT(N),SENS(1),etC.

».,~,~,\

Exemple 3 : Résultat LIDIA filtré de la phrase "Pierre travaille dans son bureau."

RECITAL 2003, Batz~sur—Mer, I I -14 juin 2003

2.2 Etude qualitative

Cette étude nous a permis de répertorier les différentes informations produites par les
analyseurs (relations entre mots, groupements de mots, etc.) et de comparer les différentes
particularités de chaque analyseur afin de Vérifier la présence d’informations utiles pour
réaliser une analyse de dépendance. Cette étude nous permet surtout d’éValuer la
complémentarité des analyseurs et de définir certains des criteres a utiliser lors de la fusion
des résultats des différents analyseurs. Nous avons classé toutes ces informations linguistiques
en 6 catégories :

Syntagmes : groupe nominal, groupe Verbal, groupe adjectival, groupe adverbial,
groupe prépositionnel, proposition relative, proposition subordonnée, etc.

Relations syntaxiques: sujet, objet, gouverneur, complément d’agent, complément
circonstanciel, coordination, apposition, inclusion, etc.

Relations logiques (relations pre'dicatives) : numérotation des arguments, etc.

Relations se'mantiques : contexte, but, cause, conséquence, instrument, bénéficiaire,
conséquence, maniere, matiere, lieu, qualification, etc.

Categories morpho—syntaxiques : nom, Verbe, adjectif, adverbe, subordonnant,
coordonnant, ponctuation, mot inconnu, pronom, préposition, déterminant, participe,
etc.

Variables grammaticales : genre, nombre, temps, mode, personne, etc.

ggo \8b ~ 8%
4“ -\3’ \>
« & 0‘
0 Q, Q)
99’ 9 4°
« \* «s
‘E (<0 K‘
v‘‘ ‘r V
Syntagmes
Groupe nominal x x x
Groupe verbal x x x
Groupe prépositionnel x x x
Groupe adjectival x x
Groupe adverbial x
Proposition relative x x
Proposition infinitive x
Proposition participate x x x
Proposition subordonnée x x
Relations syntaxiques
Suiet x x x
Obiet x x X
Complément d'ac1ent x
Complément circonstanciel x
Coordin_ation x x

Figure 1 : Extrait d’un tableau de classement

Francis Brunet—Manquat

Nous avons cherché a détailler chacune de ces six categories puis de faire correspondre, si
possible, a chaque information détaillée les informations fournies par les analyseurs (Voir
Figure 1 : Extrait d’un tableau de classement). Ceci nous permet de Voir plus clairement
quelles informations sont disponibles, quelles informations pourront étre contradictoires et
surtout quelles informations seront complémentaires.

3 Outil d’analyse de dépendance

L’outil d’analyse de dépendance ne doit pas intégrer les analyseurs, mais il doit étre capable
d’extraire les informations linguistiques de leurs résultats, de les interpreter et de les
fusionner. Notre outil se compose de quatre modules :

Module de chargement : Ce module extrait les informations linguistiques des résultats
obtenus par un analyseur linguistique.

Module de normalisation: Ce module traite l’information extraite pour la faire

correspondre a notre norme/standard. A chaque information est associée un indice de
confiance calculé en fonction de l’information et des particularités de l’analyseur.

Module de fusion : Ce module fusionne les informations normalisées.

Module de generation : Ce module génere une structure de dépendance en fonction des
informations fusionnées, des indices de confiance associés et de nos regles de

 
     

génération.

Flésultats Ensemble d'informations Matrice de dépendances
d'analyse extraites des résultats normalisées

Resunats Informations _ Matrice de dépendances
analyseur A1 extraites MD1

Matrice de dépendances
fusionnée
go‘; 600

Résunats ‘ge(° Informations o\\9_> Matrice de dépendances Génération

analyseur A2 “'5 extraites ‘ MD2
0 90 i
Structure de dépendance
finale

Résultats _ Informations _ Matrice de dépendances

analyseur A3 7 extraites ' MD3

Figure 2 : Architecture fonctionnelle de l’outil d’analyse

3.1 Chargement : récupération de l’information

Le module de chargement est un module capable de charger n’importe quels types de
résultats. Nous prendrons l’hypothese que les analyseurs linguistiques se répartissent la
plupart du temps en trois categories en fonction des résultats qu’ils produisent (Voir 2.1
Analyseurs) :

Les analyseurs fondés sur les constituants.
Les analyseurs fondés sur les dépendances.
Les analyseurs fondés sur les constituants et les dépendances.

RECITAL 2003, Batz~sur—Mer, I I -14 juin 2003

Dans un premier temps, il faut étre capable de décrire le format de représentation des résultats
de l’analyseur, dans notre cas nous décrivons ce format sous la forme d’une grammaire
JAVACC (un générateur d’analyseurs syntaxiques pour JAVA). Puis a l’intérieur de cette
grammaire, nous introduisons des méthodes de chargement en fonction de la catégorie du
résultat:

Soit une méthode permettant de charger des relations de dépendance :
AjoutRelation(TypeRelation, Motl , Mot2).

Soit une méthodes permettant de charger des constituants :
AjoutSyntagme(TypeSyntagme, Ensemble de mots ou de syntagmes).

Nous devrons également avoir une méthode de chargement de l'information associée a un
mot:
A_joutCatégorie(Mot, Information).
A_joutCatégorie (Mot, Information, Valeur).

3.2 Normalisation de l’information

Apres avoir extrait toutes les informations des résultats d’un analyseur, il nous faut encore
traiter toutes ces données pour les faire correspondre a notre représentation. Nous utilisons
une représentation matricielle qui nous semble plus adequate pour représenter un ensemble de
relations. Ce type de représentation permet de manipuler et fusionner facilement des données.

Pour normaliser toutes ces informations extraites de chaque analyseur, nous nous aidons du
tableau de classement (Voir 2.2 Etude). Ce tableau fait correspondre a chaque donnée extraite
son information normalisée. Par exemple, pour le résultat fourni par Xelda, la relation SUBJ
sera normalisée pour correspondre a la relation SUJET et ainsi de suite pour toutes les
relations et les categories simples a normaliser. Mais ce tableau devra également contenir,
pour certaines informations, des renseignements supplémentaires concernant la normalisation
de celle—ci. Par exemple, la relation SUBINV (sujet inversé) extraite de l’analyse de Xelda
pourra étre transformée en une relation sujet grace a la regle normalisation :

| SUBINV($varll, $var2) ::= SUJET::xelda($varl, $var2) |

D’autres relations posent des problemes plus difficiles par exemple la relation VMODOBJ
extraite de l’analyse de Xelda pourrait avoir plusieurs significations syntaxiques :
complément circonstanciel (Voir Exemple 1 : Résultat Xelda filtré de la phrase "Pierre
travaille dans son bureau."), complement d’objet direct, etc. L’idée est d’associer a chaque
information linguistique pouvant étre extraite un indice de confiance2 :

VMODOBJ($varl, $prep, $var2) ::= COMPLEMENT_CIRCONSTANCIEL($varl, $var2)
indice_de_confiance = 0,8

VMODOBJ($varl, $prep, $var2) ::= COMPLEMENT_OBJET_DIRECT($varl, $var2)
indice_de_confiance = 0,2

1 La variable $var représente soit un mot soit un syntagme, . la variable $prep représente un mot.

2 L’indice varie de 0 a 1, 1 étant l’indice de confiance maximum.

Francis Brunet—Manquat

Cet indice sera determine a l’aide d’un apprentissage realise a partir d’un corpus de
reference3. Cet indice exprime la confiance relative a l’information en fonction de l’analyseur
et de la typologie de l’enonce. Cet indice sera recalcule lors de la fusion en fonction des autres
indices associes a la meme information linguistique fournis par les autres analyseurs et du
nombre d’analyseurs pouvant fournir ce type d’information (Voir 3.3 Fusion des informations
linguistiques). L’indice ainsi recalcule permettra lors de la generation de determiner si
l’information correspondante doit etre conservee ou supprimee (Voir 3.4 Generation des
structures de dependance).

La methode explicitee ci—dessus est basee sur la methode dite de << Vote a la majorite >> (plus
une information sera commune aux differents analyseurs, plus son indice de confiance
augmentera). Chaque indice pourra etre Vu comme le vote p0nde're' de l’analyseur pour
l’information, ce Vote etant adapté aux differentes possibilites de l’analyseur en fonction de
l’enonce (par exemple, entree bruitee ou non) lors de l’apprentissage.

3.3 Fusion des informations linguistiques

\

A ce moment de l’analyse, a chaque resultat fourni par un analyseur est associee une
representation matricielle comprenant toutes les informations linguistiques normalisees
extraites. Dans ce module, nous fusionnons toutes ces representations pour obtenir une
representation matricielle finale contenant toutes les informations extraites de chaque
analyseur. Certaines informations linguistiques seront complementaires, d’autres
contradictoires. ll ne s’agit pas simplement de regrouper toutes les informations, il faut
egalement calculer de nouveaux indices de confiance pour chaque information en fonction des
indices de confiance fournis par le module de normalisation.

Definition du calcul du nouvel indice associe a l’information i :

indice(i) = Z indice“)
Fusion

Nombre d'ana|yseurs
pouvant fournir |'information i

Par exemple, calculons le nouvel indice de confiance a associer a l’information : relation
SUJET entre les mots x et y, fournie a la fois par l’analyseur de Xelda et par l’analyseur de
Vergne. L’indice de fusion associe a SUJET(x,y) est egal a la somme des deux indices de
confiance indice(SUJET::xelda)=0,5 et indice(SUJET::Vergne)=0,7 divise par le nombre
d’analyseurs pouvant fournir ce type d’information (ici trois), (0,5+0,7+0)/3 = 0,4. Si le
troisieme analyseur foumit egalement une information de type SUJ ET entre les mots x et Z, et
que l’indice de confiance relatif a cette information est de 0,8. L’indice de fusion associe a
SUJET(x,z) est egal a (0+0+0,8)/3 = 0,26.

On peut constater que notre calcul favorise les informations fournies par le plus grand nombre
d’analyseurs et ayant des indices eleves. Les nouveaux indices ainsi calcules serviront lors de
la phase de generation.

3 Le module d’apprentissage est en cours de realisation et sera base sur une methode de retro-propagation des

indices. Po11r le moment, les indices de confiance sont ﬁxes manuellement.

RECITAL 2003, Batz~sur—Mer, I I -14 juin 2003

3.4 Generation des structures de dépendance

Le demier module permet d’obtenir une ou plusieurs structures de dépendance grace a toutes
les informations recueillies. Les structures de dépendance sont générées a partir des
informations ayant un indice de confiance élevé et de contraintes linguistiques imposées par
l’utilisateur pour éviter les informations contradictoires. Nous pouvons Voir ce module
comme un module de satisfaction de contraintes comportant 3 regles : une et une seule
relation entre deux mots, les informations seront conservées si leur indice de confiance est au-
dessus d’un certain seuil et le respect des contraintes linguistiques imposées par l’utilisateur.
Notre outil générera donc plusieurs structures résultats pour un énoncé, a chaque structure
résultat sera associé un indice de pertinence, moyenne pondérée des indices de confiance

présents dans la structure.

4 Premiere réalisation

Nous avons réalisé une premiere maquette de notre outil ne comportant que les deux premiers
modules : chargement et normalisation en utilisant une représentation classique en arbre pour
représenter nos données. Cette maquette ne charge que deux analyseurs : l’analyseur de la
plateforme Xelda et l’analyseur développé par Jacques Vergne. Cette premiere réalisation
avait pour but de Vérifier nos hypotheses de départ, c’est—a—dire : la possibilité d’eXtraire
facilement de l’information et de la normaliser, ainsi que la possibilité d’intégrer facilement
de nouveaux analyseurs a une plateforme d’analyse. Cette expérimentation nous a également
permis de distinguer les futurs problemes.

Le corpus de phrases utilisé provient d’un corpus UNL, Universal Networking Language,
contenant une phrase et son hypergraphe UNL associé. Ce corpus était constitué de quarante
phrases courtes, neuf mots par phrase en moyenne (minimum 3 mots, maximum 56 mots),
décrivant de nombreux phénomenes linguistiques : coordination, négation, relative, etc. Par
exemple :

Une tulipe est plus belle qu'une rose.

11 sait que tu ne Viendras pas et il ne le regrette pas.

Dans un premier temps, nous avons donc traité ces quarante phrases avec l’analyseur de
Xelda et avec l’analyseur développé par J. Vergne. Ce premier traitement, appliqué a toutes
les phrases du corpus, nous a permis de déterminer quelques regles de normalisation a
associer aux informations fournies par les analyseurs. Pour cette expérimentation, nous avons

15 regles de normalisation associées a chaque analyseur concernant essentiellement les
relations syntaxiques.

Pour intégrer les deux analyseurs a notre outil, nous avons donc réalisé leurs grammaires de
récupération a associer au module de chargement et leurs modules de normalisation ont été
générés automatiquement en fonction des regles de normalisation associées a chaque
analyseur. Notre outil a extrait toutes les informations linguistiques fournies par les résultats
d’analyse. Avec seulement 15 regles de normalisation, notre outil a déterminé 78% des
liaisons entre mots (relations non étiquetées) et 67% de ces relations ont pu étre étiqueté. Les
premiers résultats normalisés fournis pour notre outil sont encourageants, meme s’ils restent
limités a quelques phrases et quelques regles de normalisation, mais surtout les hypotheses de
départ ont pu étre Vérifiées.

Francis Brunet—Manquat

Mais plusieurs problemes se sont présentés, tout d’abord, la lourdeur de la representation
arborescente utilisée. En effet, nous nous sommes Vite rendu compte de l’utilité de changer de
representation pour les deux premiers modules mais surtout pour le futur module de fusion et
d’adopter une representation de type matricielle, plus maniable et plus adaptée a nos besoins
(Voir 3.2 Normalisation de l’information). Le second probleme concerne le besoin
d’informations linguistiques supplémentaires dans le cas des analyseurs fondés sur les
constituants. Comment trouver les relations entre mots a partir des syntagmes si aucune
information n’est pas fournie concernant le gouverneur du syntagme. Dans le cas de
l’analyseur développé par J . Vergne, l’information concernant le gouvemeur du syntagme est
fournie mais pas dans le cas de l’analyseur de Xelda. Nous avons donc besoin d’une base de
connaissances linguistiques simple permettant de résoudre ce genre de problemes.

5 Bilan et perspectives

Cette premiere experience nous a permis de Verifier la possibilité de charger des informations
linguistiques extraites de résultats d’analyse fondé sur les constituants et les dépendances,
mais également la possibilité de normaliser ces informations. Une seconde maquette est en
cours de realisation et sera testée sur 5 analyseurs : l’analyseur de la plateforme Xelda,
l’analyseur Xip développé par Rank Xerox, l’analyseur developpé par J . Vergne, l’analyseur
du projet Lidia, l’analyseur developpé par J . Chauché. Nous utilisons le corpus amaryllis
composé de 140000 fichiers composé chacun d’une douzaine de phrases longues (environ une
trentaine de mots). Les phrases sont bien forrnées et abordent de nombreuses thématiques. Ce
corpus a déja été traité par l’analyseur de la plateforme Xelda et est en cours de traitement par
l’analyseur développé par J. Vergne. Cette nouvelle maquette intégrera tous les modules et
foumira en résultat une ou plusieurs structures de dépendance.

Remerciements
Je tiens a remercier Rank Xerox et Jacques Vergne pour m’aVoir permis d’utiliser leurs
analyseurs.

Références

Adda G., Mariani J., Paroubek P., Rajman M., et Lecomte, J. (1999), L'action GRACE
d'éValuation de l'assignation des parties du discours pour le Frangais, in revue Langues, Vol.
2(2) : pp 119-129.

Ait—Mokhtar S., Chanod JP. (1997), Incremental finite—state parsing, in Applied Natural
Language Processing 1997, April 1997, Washington.

Boitet C. (1990), La TAO a Grenoble en 1990. in Ecole d’e'te' de Lannion sur le Traitement
Automatique des Langues Naturelles. CENT, juillet 1990, 65 p.

Boitet C., Blanchon H. (1995), Multilingual Dialogue—Based MT for monolingual authors: the
LIDIA project and a first mockup. in Machine Translation. Vol. 9(2) : pp 99-132.

Monceaux L., Isabelle Robba I. (2002), Les analyseurs syntaxiques : atouts pour une analyse
des questions dans un systeme de question—réponse ?, Actes de TALN’2003, pp. 195-204.

Sérasset G., Boitet Ch. (2000), On UNL as the future "html of the linguistic content" & the
reuse of existing NLP components in UNL—related applications with the example of a UNL-
French deconverter, in COLING 2000, Saarebruecken, Germany.

Vergne J., Giguet E. (1998), Regards théorique sur le << Tagging >>, Actes de TALN’1998,
pp 24-33

