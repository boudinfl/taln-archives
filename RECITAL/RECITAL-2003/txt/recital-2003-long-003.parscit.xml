<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>Mc Keown</author>
<author>R Kathleen</author>
<author>M Elhadad</author>
</authors>
<title>Information fusion in the context of multi-document summarizationqPH$QQXDO0HHWLQJRIWKH$&amp;/.</title>
<date>1999</date>
<contexts>
<context position="4075" citStr="Barzilay et al., 1999" startWordPosition="586" endWordPosition="589">ocument) (Goldstein et al., 2000), qui définit une métrique d’intérêt des passages de texte, du système développé par TNO-TPD (Kraaij et al., 2001) qui attribue un score à des segments textuels en combinant un modèle de langage uni-gramme et un modèle bayésien, ou encore le systèmes décrit dans (Boros et al., 2001) qui fait appel à des méthodes de classification. L’exploitation de critères plus linguistiques constitue une deuxième grande approche parmi les systèmes de résumé multidocument. Elle est représentée par des travaux tels que ceux de Radev et McKeown (Raved et al. 1998), de Barzilay (Barzilay et al., 1999) ou encore de McKeown (McKeown et al., 2001). Les systèmes concernés font appel à des traitements linguistiques plus ou moins élaborés (extraction de termes, reconnaissance d’entités nommées, analyse syntaxique, …). Dans cette même perspective, des travaux tels que (Mani, 1999) ou (White et al., 2001) utilisent des méthodes d’extraction d’information pour produire des résumés multi-documents en fonction d’une requête ou d’un profil utilisateur. Enfin, la problématique du résumé multi-document rejoint et peut se combiner à celle de la visualisation et du parcours d’un ensemble de documents ains</context>
</contexts>
<marker>Barzilay, Keown, Kathleen, Elhadad, 1999</marker>
<rawString>Barzilay R., Mc Keown, Kathleen R., Elhadad, M. (1999) Information fusion in the context of multi-document summarizationqPH$QQXDO0HHWLQJRIWKH$&amp;/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Endre Boros</author>
<author>Paul B Kandor</author>
<author>David J Neu</author>
</authors>
<title>A clustering based approach to creating multi-document summaries,</title>
<date>2001</date>
<pages>0--6</pages>
<contexts>
<context position="3769" citStr="Boros et al., 2001" startWordPosition="538" endWordPosition="541">lement par extraction de passages ou de phrases. Différentes approches ont été développées au sein de ce paradigme. L’une des plus répandues consiste à exploiter des critères essentiellement statistiques ou probabilistes. C’est le cas notamment de la méthode MMR-MD (Maximal Marginal Relevance – Multi-Document) (Goldstein et al., 2000), qui définit une métrique d’intérêt des passages de texte, du système développé par TNO-TPD (Kraaij et al., 2001) qui attribue un score à des segments textuels en combinant un modèle de langage uni-gramme et un modèle bayésien, ou encore le systèmes décrit dans (Boros et al., 2001) qui fait appel à des méthodes de classification. L’exploitation de critères plus linguistiques constitue une deuxième grande approche parmi les systèmes de résumé multidocument. Elle est représentée par des travaux tels que ceux de Radev et McKeown (Raved et al. 1998), de Barzilay (Barzilay et al., 1999) ou encore de McKeown (McKeown et al., 2001). Les systèmes concernés font appel à des traitements linguistiques plus ou moins élaborés (extraction de termes, reconnaissance d’entités nommées, analyse syntaxique, …). Dans cette même perspective, des travaux tels que (Mani, 1999) ou (White et al</context>
</contexts>
<marker>Boros, Kandor, Neu, 2001</marker>
<rawString>Boros, Endre, Kandor, Paul B., Neu, David J. (2001) A clustering based approach to creating multi-document summaries, $&amp;06,*,5¶:RUNVKRSRQ7H[W6XPPDUL]DWLRQ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fluhr</author>
</authors>
<title>SPIRIT : un système d&apos;exploration de données textuelles,</title>
<date>1994</date>
<booktitle>H 7UDLWHPHQW ,QIRUPDWLTXHGHV&amp;RUSXV7H[WXHOV, INALF.</booktitle>
<contexts>
<context position="6130" citStr="Fluhr, 1994" startWordPosition="897" endWordPosition="898">ôle de mettre en évidence dans les documents à résumer : le vocabulaire susceptible d’être comparé au profil et les structures thématiques pouvant être mises en correspondance avec les thèmes constituant ce profil. 2.1 Normalisation des documents La première étape de l’analyse des document vise à normaliser le vocabulaire des documents. Cette normalisation consiste à associer à chaque mot d’un document son lemme. ([WUDFWLRQGHVHJPHQWVWKpPDWLTXHVSRXUOHUpVXPpPXOWLGRFXPHQW  Pour cela nous utilisons les modules d’analyse morphologique et d’étiquetage morphosyntaxique du logiciel 63,5,7(Fluhr, 1994). A la fin du processus d’analyse et d’étiquetage, seuls les mots non grammaticaux susceptibles d’apparaître dans les profils sont sélectionnés, c’est-à-dire les noms, les verbes et les adjectifs. Ce prétraitement linguistique vise donc à normaliser le vocabulaire et à faciliter ainsi la comparaison avec un profil. Malgré la présence dans les profils de termes complexes, nous ne faisons volontairement appel ni à un extracteur terminologique généraliste, ni à un outil de reconnaissance de variantes terminologiques. En dépit de l’intérêt de ces outils pour la mise en évidence des termes complexe</context>
</contexts>
<marker>Fluhr, 1994</marker>
<rawString>Fluhr C. (1994) SPIRIT : un système d&apos;exploration de données textuelles, /H 7UDLWHPHQW ,QIRUPDWLTXHGHV&amp;RUSXV7H[WXHOV, INALF.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goldstein</author>
<author>V Mittal</author>
<author>M Kantrowitz</author>
<author>J Carbonell</author>
</authors>
<title>Multi-Document Summarization By Sentence Extraction,$1/31$$&amp;/:RUNVKRSRQ$XWRPDWLF6XPPDUL]DWLRQ.</title>
<date>2000</date>
<contexts>
<context position="3486" citStr="Goldstein et al., 2000" startWordPosition="491" endWordPosition="494">r dans le cadre de l’évaluation DUC (Document Understanding Conference) (Over, 2001). Le travail que nous présentons dans cet article rejoint donc la problématique du résumé multi-document. Actuellement les systèmes de résumé, qu’ils soient mono ou multi-document, fonctionnent essentiellement par extraction de passages ou de phrases. Différentes approches ont été développées au sein de ce paradigme. L’une des plus répandues consiste à exploiter des critères essentiellement statistiques ou probabilistes. C’est le cas notamment de la méthode MMR-MD (Maximal Marginal Relevance – Multi-Document) (Goldstein et al., 2000), qui définit une métrique d’intérêt des passages de texte, du système développé par TNO-TPD (Kraaij et al., 2001) qui attribue un score à des segments textuels en combinant un modèle de langage uni-gramme et un modèle bayésien, ou encore le systèmes décrit dans (Boros et al., 2001) qui fait appel à des méthodes de classification. L’exploitation de critères plus linguistiques constitue une deuxième grande approche parmi les systèmes de résumé multidocument. Elle est représentée par des travaux tels que ceux de Radev et McKeown (Raved et al. 1998), de Barzilay (Barzilay et al., 1999) ou encore </context>
</contexts>
<marker>Goldstein, Mittal, Kantrowitz, Carbonell, 2000</marker>
<rawString>Goldstein J., Mittal V., Kantrowitz M., Carbonell J. (2000) Multi-Document Summarization By Sentence Extraction,$1/31$$&amp;/:RUNVKRSRQ$XWRPDWLF6XPPDUL]DWLRQ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hearst</author>
</authors>
<title>TextTiling: Segmenting Text into Multi-paragraph Subtopic Passages,</title>
<date>1997</date>
<journal>RPSXWDWLRQDO/LQJXLVWLFV,</journal>
<volume>23</volume>
<pages>33--64</pages>
<contexts>
<context position="7418" citStr="Hearst, 1997" startWordPosition="1088" endWordPosition="1089">cate dans un contexte, comme celui du filtrage, où chaque occurrence d’un terme peut être importante. Nous détaillerons à la section 4.2 la méthode que nous utilisons pour identifier dans les documents les termes complexes d’un profil. 2.2 Analyse thématique L’analyse thématique des documents a dans le cas présent pour rôle de segmenter les documents en unités thématiquement homogènes, tâche que l’on nomme segmentation thématique. Les segments ainsi délimités constituent les unités textuelles de base qui sont comparées aux profils. Nous avons choisi d’utiliser le système 7H[W7LOLQJ de Hearst (Hearst, 1997) en l’adaptant afin de prendre en entrée le résultat du prétraitement des textes décrit à la section précédente et d’aligner les bornes de segment sur des frontières de phrase. Le choix de 7H[W7LOLQJ s’appuie sur le bon rapport complexité / efficacité de son algorithme : une fenêtre glissante est déplacée sur le texte à segmenter. Pour chaque position du texte ainsi parcourue, on compare les deux parties de la fenêtre situées de part et d’autre de cette position à l’aide d’une mesure de similarité s’appuyant sur les mots présents dans la fenêtre. Les valeurs de cette mesure pour l’ensemble du </context>
</contexts>
<marker>Hearst, 1997</marker>
<rawString>Hearst M. (1997) TextTiling: Segmenting Text into Multi-paragraph Subtopic Passages, &amp;RPSXWDWLRQDO/LQJXLVWLFV, Vol. 23, n° 1, p. 33-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wessel Kraaij</author>
<author>Spitters</author>
</authors>
<title>Combining a mixture language model and Naive Bayes for multi-document summarisation,</title>
<date>2001</date>
<pages>0--6</pages>
<marker>Kraaij, Spitters, 2001</marker>
<rawString>Kraaij, Wessel, Spitters, , et al. (2001) Combining a mixture language model and Naive Bayes for multi-document summarisation, $&amp;06,*,5¶:RUNVKRSRQ7H[W6XPPDUL]DWLRQ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
<author>E Bloedorn</author>
</authors>
<title>Summarizing similarities and differences among documents,</title>
<date>1999</date>
<booktitle>QIRUPDWLRQ5HWULHYDO,</booktitle>
<volume>1</volume>
<pages>1--23</pages>
<marker>Mani, Bloedorn, 1999</marker>
<rawString>Mani I., Bloedorn E. (1999) Summarizing similarities and differences among documents, ,QIRUPDWLRQ5HWULHYDO, Vol. 1, n° 1, p. 1-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
<author>Barzilay</author>
</authors>
<title>Columbia Multi-document Summarization : Approach and Evalution ,</title>
<date>2001</date>
<pages>0--6</pages>
<location>Regina, Evans David, Hatzivassiloglou, Vasileios, Kan, Min-Yen, Schiffman, Barry, Teufel, Simone</location>
<marker>McKeown, Barzilay, 2001</marker>
<rawString>McKeown, Kathleen R., Barzilay, Regina, Evans David, Hatzivassiloglou, Vasileios, Kan, Min-Yen, Schiffman, Barry, Teufel, Simone (2001) Columbia Multi-document Summarization : Approach and Evalution , $&amp;06,*,5¶:RUNVKRSRQ7H[W6XPPDUL]DWLRQ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Over</author>
</authors>
<title>Introduction to DUC-2001: an Intrinsic Evaluaton of Generic News Text Summarization Systems,$&amp;06,*,5¶:RUNVKRSRQ7H[W6XPPDUL]DWLRQ.</title>
<date>2001</date>
<contexts>
<context position="2947" citStr="Over, 2001" startWordPosition="419" endWordPosition="420">t pas du temps nécessaire pour compiler toutes les sources qui pourraient leur permettre de prendre les meilleures décisions. L’exploitation des documents récupérés pour réaliser une synthèse ou un résumé automatique est devenue un thème qui occupe de plus en plus les chercheurs. On s’est d’abord intéressé au résumé d’un document unique puis, pour les besoins de la veille, l’un des thèmes de recherche principal est devenu le résumé multidocument. Cette nouvelle problématique fait l’objet de nombreux travaux, en particulier dans le cadre de l’évaluation DUC (Document Understanding Conference) (Over, 2001). Le travail que nous présentons dans cet article rejoint donc la problématique du résumé multi-document. Actuellement les systèmes de résumé, qu’ils soient mono ou multi-document, fonctionnent essentiellement par extraction de passages ou de phrases. Différentes approches ont été développées au sein de ce paradigme. L’une des plus répandues consiste à exploiter des critères essentiellement statistiques ou probabilistes. C’est le cas notamment de la méthode MMR-MD (Maximal Marginal Relevance – Multi-Document) (Goldstein et al., 2000), qui définit une métrique d’intérêt des passages de texte, d</context>
</contexts>
<marker>Over, 2001</marker>
<rawString>Over P. (2001) Introduction to DUC-2001: an Intrinsic Evaluaton of Generic News Text Summarization Systems,$&amp;06,*,5¶:RUNVKRSRQ7H[W6XPPDUL]DWLRQ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Generating natural language summaries from multiple on-line sources,</title>
<date>1998</date>
<journal>RPSXWDWLRQDO/LQJXLVWLFV,</journal>
<volume>24</volume>
<pages>469--500</pages>
<marker>Radev, McKeown, 1998</marker>
<rawString>Radev, Dragomir R., McKeown, Kathleen R. (1998) Generating natural language summaries from multiple on-line sources, &amp;RPSXWDWLRQDO/LQJXLVWLFV, Vol. 24, n° 3, p. 469-500.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael White</author>
</authors>
<title>Detecting Disrepancies and Improving Intelligibility : Two Preliminary Evaluations of RIPTIDES,</title>
<date>2001</date>
<pages>0--6</pages>
<marker>White, 2001</marker>
<rawString>White, Michael, et al., (2001) Detecting Disrepancies and Improving Intelligibility : Two Preliminary Evaluations of RIPTIDES, $&amp;06,*,5¶:RUNVKRSRQ7H[W6XPPDUL]DWLRQ.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>