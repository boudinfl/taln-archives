<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Annotation s&#233;mantique hors-source &#224; l&#8217;aide de vecteurs conceptuels</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>RECITAL 2003, Batz-sur-Mer, 11&#8211;14 juin 2003
</p>
<p>Annotation s&#233;mantique hors-source &#224; l&#8217;aide de vecteurs
conceptuels
</p>
<p>Fabien JALABERT
LIRMM (CNRS - Universit&#233; Montpellier 2)
Laboratoire d&#8217;Informatique, de Robotique
</p>
<p>et de Micro&#233;lectronique de Montpellier
161, rue Ada - F - 34392 Montpellier Cedex 5
</p>
<p>jalabert@lirmm.fr
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>annotation s&#233;mantique, d&#233;sambiguisation s&#233;mantique lexicale
WSD , word sens disambiguation, word sens tagging, annotation
</p>
<p>R&#233;sum&#233; - Abstract
</p>
<p>Dans le cadre de la recherche en s&#233;mantique lexicale, nous utilisons le mod&#232;le des vecteurs
conceptuels pour repr&#233;senter les sens de termes. La base vectorielle est construite &#224; partir de d&#233;f-
initions provenant de diverses sources lexicales, ce qui permet statistiquement de temp&#233;rer les di-
verses incoh&#233;rences locales. Pour d&#233;signer le sens obtenu apr&#232;s un regroupement des d&#233;finitions,
nous utilisons un identificateur qui entra&#238;ne certaines contraintes. En particulier, un &#8220;cluster&#8221; de
d&#233;finition est d&#233;sign&#233; par une r&#233;f&#233;rence vers diff&#233;rentes d&#233;finitions de la multisource. D&#8217;autre
part, le contr&#244;le de la qualit&#233; d&#8217;une classification ou d&#233;sambiguisation de sens impose de faire
r&#233;f&#233;rence en permanence au lexique source. Nous proposons donc de nommer un sens &#224; l&#8217;aide
d&#8217;un autre terme du lexique. L&#8217;annotation est un outil l&#233;ger et efficace qui est essentiellement
une association d&#8217;id&#233;es que l&#8217;on peut extraire de toute base de connaissance linguistique. Les
annotations obtenues peuvent finalement constituer une nouvelle source d&#8217;apprentissage pour la
base de vecteurs conceptuels.
</p>
<p>In the framework of research in meaning representation in NLP, we focus our attention on the-
matic aspects and conceptual vectors. This vectorial base is built by a morphosyntaxic analysis
of several lexical resources to reduce isolated problems. Also a meaning is a cluster of definitions
that are pointed by an Id number. To check the results of an automatic clustering or WSD, we
must refer continously to the source dictionnary. We describe in this article a method for naming
a word sens by a term of vocabulary. This kind of annotation is a light and efficient method the
uses meanings associations someone or something can extract from any lexical knowledge base.
Finally, the annotations should become a new lexical learning resource to improve the vectorial
base.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Fabien JALABERT
</p>
<p>Introduction
</p>
<p>Dans le cadre de la recherche en s&#233;mantique lexicale, l&#8217;&#233;quipe TAL du LIRMM d&#233;veloppe
actuellement un syst&#232;me d&#8217;analyse des aspects th&#233;matiques des textes et de d&#233;sambiguisation
lexicale bas&#233; sur les vecteurs conceptuels. Les vecteurs repr&#233;sentent les id&#233;es associ&#233;es &#224; tout
segment textuel (mots, expressions, textes, . . . ) via l&#8217;activation de concepts. Pour la construction
des vecteurs, nous avons pris deux hypoth&#232;ses principales : l&#8217;automatisation de la cr&#233;ation de la
base lexicale vectorielle par apprentissage &#224; partir d&#8217;informations extraites de diverses sources
(dictionnaires &#224; usage humain, liste de synonymes, . . . ), et un apprentissage multisource afin de
palier au bruit d&#233;finitoire (par exemple les probl&#232;mes d&#251;s au m&#233;talangage comme dans la d&#233;fi-
nition d&#8217; &#0; aboyer &#1; , crier en parlant du chien). Chaque dictionnnaire proposant un d&#233;coupage des
sens pour une entr&#233;e, nous avons mis en place une proc&#233;dure qui associe &#224; un sens un ensem-
ble d&#233;finitions. Ce groupe de d&#233;finitions est d&#233;sign&#233; par un identifiant num&#233;rique utilis&#233; lors
d&#8217;un processus de d&#233;sambigu&#239;sation. L&#8217;utilisateur, humain ou machine, doit donc conna&#238;tre le
codage pour pouvoir r&#233;associer &#224; un terme et un identifiant le sens correspondant. Chaque util-
isateur doit d&#232;s lors poss&#233;der les sources lexicales du ou des d&#233;sambigu&#239;seurs auxquels ils font
appel. Superviser une d&#233;sambigu&#239;sation manuellement demande syst&#233;matiquement de consulter
la source pour chaque terme polys&#233;mique. Nous proposons dans cet article de nommer un sens
par un terme de la langue. Tout agent poss&#233;dant une comp&#233;tence linguistique doit &#234;tre capable
de retrouver le sens uniquement &#224; partir du terme annot&#233; (couple (terme, annotation)). Une telle
proc&#233;dure offre l&#8217;avantage d&#8217;une bonne interop&#233;rabilit&#233;, diff&#233;rents d&#233;sambigu&#239;seur peuvent pro-
poser leurs r&#233;sultats &#224; diff&#233;rents clients (traducteur, indexeur, . . . ) et ces derniers peuvent faire
appel &#224; de multiples d&#233;sambigu&#239;seurs pour pallier aux lacunes de certains. Nous pr&#233;sentons, dans
un premier temps, une formalisation de l&#8217;annotation puis le mod&#232;le des vecteurs conceptuels.
Nous d&#233;taillerons ensuite la proc&#233;dure d&#8217;annotation que nous proposons et qui repose &#224; la fois
sur les vecteurs conceptuels et sur les sources lexicales.
</p>
<p>1 Annotation s&#233;mantique, nommage de sens : d&#233;finition
</p>
<p>Les syst&#232;mes actuels associent &#224; chaque mot polys&#233;mique une annotation num&#233;riques, par exem-
ple : &#8220;Le chat/I.2/ mange/1/ la souris/II.1/&#8221;. L&#8217;usage que nous proposons diff&#232;re des pr&#233;c&#233;dents,
nous souhaitons retrouver des associations d&#8217;id&#233;es dans la langue et les utiliser pour d&#233;signer un
sens. Nous associons &#224; chaque terme polys&#233;mique d&#8217;un texte un annoteur qui est lui m&#234;me terme
du lexique. Par exemple :
</p>
<p>Chauss&#233;/porter/ de ses bottes/chaussure/ il revenait/d&#233;placer/ vers la grange et apercevait/voir/
les bottes/amas/ de foin/paille/.
Le lexicographe qui poss&#232;de ainsi un annotateur et un terme sera alors capable d&#8217;identifier plus
facilement le sens d&#233;sign&#233;. Il ne s&#8217;agit plus de donner une d&#233;finition comme annotateur (Wilks,
Stevenson, 1997) mais d&#8217;extraire un repr&#233;sentant. Par exemple, nous proposons d&#8217;annoter le
terme &#0; botte &#1; par botte/paille/, botte/chaussure/, botte/escrime/ qui sont des formes plus intu-
itives et compr&#233;hensibles. On peut alors consid&#233;rer que cette annotation est hors-source, elle fait
sens sans source lexicale sp&#233;cifique. Si le destinataire a une comp&#233;tence linguistique, il lui sera
possible de r&#233;associer la botte et la chaussure, ou la botte et la r&#233;union de v&#233;g&#233;taux.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Nommage de sens et annotation autocontenue
</p>
<p>1.1 D&#233;finition formelle
L&#8217;annotation correspond &#224; une fonction bijective qui, &#224; un terme et un sens, associe un couple
(terme, annotation). Soit &#2; le dictionnaire, &#3; un terme du dictionnaire, &#4;&#6;&#5; un sens de &#3; tel que
&#4;&#7;&#5;&#9;&#8;&#10;&#3; et &#11;&#12;&#5; un ensemble d&#8217;annotateurs pour &#4;&#13;&#5; et soit &#14; la fonction d&#8217;annotation :
</p>
<p>&#14;&#16;&#15;&#18;&#17;&#19;&#3; &#20;
</p>
<p>&#2;&#22;&#21;
</p>
<p>&#17;&#19;&#4;&#7;&#5;&#23;&#20;&#24;&#3; &#4;&#7;&#5;&#23;&#25;&#9;&#26; &#11;ff&#5; &#11;&#12;&#5;flfi
</p>
<p>&#2;
</p>
<p>telle que : &#17;&#9;&#11;&#12;&#5;ffi&#8;&#10;&#14; &#31;!&#4;&#7;&#5;#&quot;
&#21;
</p>
<p>&#17;$&#11;&amp;%'&#8;&#10;&#14; &#31;!&#4;(%)&quot;
</p>
<p>&#21; *ff+
</p>
<p>&#8;-,
</p>
<p>&#21;
</p>
<p>&#11;ff&#5;/.0&#11;1%1&#8;32 4&#7;5 &#11;&#12;&#5;
</p>
<p>&#21;
</p>
<p>&#11;1%
</p>
<p>+
</p>
<p>&#8;62
</p>
<p>Quel que soit le terme &#3; &#20; &#2; , on partitionne le lexique pour obtenir pour chaque sens &#4;&#18;&#5;7&#20;8&#3;
un ensemble (non vide) d&#8217;annotateurs &#11;9&#5; . Cette fonction doit permettre de r&#233;associer &#224; tout
couple &#31;!:
</p>
<p>&#21;
</p>
<p>&#3;&#10;&quot; o&#249; : est un &#233;l&#233;ment de &#11;;&#5; le sens &#4;&#7;&#5; correspondant. Cette fonction admet donc
une bijection r&#233;ciproque &#14;=&lt;?&gt; :
</p>
<p>&#14;
</p>
<p>&lt;?&gt;
</p>
<p>&#15;&#18;&#17;&#19;&#3; &#20;
</p>
<p>&#2;&#22;&#21;
</p>
<p>&#17;&#9;&#11;&#12;&#5;flfi
</p>
<p>&#2;&#22;&#21;
</p>
<p>&#17;ffi:@&#20;&#16;&#11;&#12;&#5; &#31;!:
</p>
<p>&#21;
</p>
<p>&#3;&#10;&quot;1&#25;&#9;&#26; &#4;A&#5;
</p>
<p>On souhaite ainsi ins&#233;rer dans un texte des balises contenant un terme discr&#233;minant pour chaque
terme polys&#233;mique d&#233;sambigu&#239;s&#233;. La fonction d&#8217;annotation pr&#233;c&#233;dente propose pour un sens
donn&#233; d&#8217;un terme un ensemble de candidats. Il importe donc d&#8217;&#233;valuer les diff&#233;rents candidats
et de les classer par ordre d&#8217;int&#233;ret tout en accordant une souplesse suivant l&#8217;utilisation qui sera
faite de l&#8217;annotation (usage humain, interop&#233;rabilit&#233;, . . . ).
</p>
<p>1.2 Propri&#233;t&#233;s remarquables
1.2.1 Ind&#233;pendance aux dictionnaires
Dans le cas o&#249; on ne souhaite pas diffuser le dictionnaire source (droits d&#8217;auteur, volume trop
important,. . . ) une annotation par des termes de la langue peut permettre au client de retrouver
le bon sens sans la source. Si dans plusieurs dictionnaires un terme est associ&#233; &#224; un autre, il est
fortement probable de retrouver la m&#234;me relation &#224; l&#8217;aide d&#8217;autre sources. Diff&#233;rents annotateurs
n&#8217;offriront pas la m&#234;me ind&#233;pendance aux sources, il est donc important d&#8217;&#233;valuer cette propri&#233;t&#233;
et de classer les annotateurs en cons&#233;quence.
</p>
<p>1.2.2 Une interface homme-machine
L&#8217;annotation est un outil pr&#233;cieux pour le lexicographe qui supervise une d&#233;sambig&#239;sation. Elle
met en &#233;vidence de fa&#231;on simple le sens qu&#8217;il faut attribuer &#224; un terme, sans devoir constament
se r&#233;f&#233;rer &#224; un dictionnaire donn&#233; et en assimiler la d&#233;finition. Le co&#251;t cognitif est d&#233;fini comme
l&#8217;effort que doit faire l&#8217;agent humain pour transformer une perception, une information en une
connaissance exploitable (Prince, 1996). Dans le cas de l&#8217;annotation s&#233;mantique &#224; usage humain,
il est d&#233;terminant de minimiser ce co&#251;t et pour cela de prendre en compte d&#8217;autre crit&#232;res. On
favorisera ainsi des candidats qui ont un usage proche en utilisant des notions de fr&#233;quence, de
cooccurence terme/annotation, mais aussi des informations fournies par les dictionnaires comme
la morphologie ou l&#8217;usage (contexte ou domaine, sens figur&#233; ou soutenu, . . . ).
</p>
<p>2 Les vecteurs conceptuels
Le mod&#232;le vectoriel a &#233;t&#233; introduit par (Salton, 1968) en recherche d&#8217;information. C&#8217;est &#224; partir
de (Chauch&#233;, 1990) que l&#8217;on a une formalisation de la projection de la notion linguistique de
champs s&#233;mantiques dans un espace vectoriel. A partir d&#8217;un ensemble de notions &#233;l&#233;mentaires
dont nous faisons l&#8217;hypoth&#232;se, les concepts, il est possibles de construire des vecteurs (dits con-
ceptuels) et de les associer &#224; des items lexicaux. Dans notre exp&#233;rimentation sur le Fran&#231;ais
nous utilisons (Th&#233;saurus Larousse, 1992) dans lequel sont d&#233;finis 873 concepts. L&#8217;hypoth&#232;se
g&#233;n&#233;rale du th&#233;saurus, que nous adoptons ici, est que cet ensemble constitue un espace g&#233;n&#233;ra-
teur (non libre) pour les termes et leur sens. On d&#233;finit Une mesure de similarit&#233; B *!C &#31;#D &#21;FE &quot;1&#8;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Fabien JALABERT
</p>
<p>G&#7;HJI
</p>
<p>&#31;ffKD
</p>
<p>&#21;(E
</p>
<p>&quot;L&#8; MON P
</p>
<p>Q
</p>
<p>M
</p>
<p>QSR/Q
</p>
<p>P
</p>
<p>Q avec &#8220; T &#8221; d&#233;signant le produit scalaire et la distance angulaire U/V &#31;WD &#21;(E &quot;7&#8;
XZY[G)G&#7;HJI
</p>
<p>&#31;\B
</p>
<p>*\C
</p>
<p>&#31;WD
</p>
<p>&#21;(E
</p>
<p>&quot;[&quot; . Cette derni&#232;re mesure repr&#233;sente intuitivement une notion de distance th&#233;-
matique entre deux mots, elle respecte la sym&#233;trie, la r&#233;flexivit&#233; et l&#8217;in&#233;galit&#233; triangulaire. Voici
un exemple avec le terme amour o&#249; les termes les plus proches sont &#233;prendre (0.17), Cupidon
(0.25), Aphrodite (0.27), amiti&#233; (0.308), tendresse (0.3084). Les concepts les plus activ&#233;s sont
amour (11879), passion (4137), inimiti&#233; (3511), courtoisie (3348),. . . La construction de la base
vectorielle est automatis&#233;e &#224; partir de d&#233;finitions issues de dictionnaires &#224; usage humain (Schwab
&amp; al., 2002), (Lafourcade &amp; al., 2002).
</p>
<p>3 La proc&#233;dure d&#8217;annotation
Notre proc&#233;dure d&#8217;annotation repose sur une utilisation mixte des ressources lexicales et des
vecteurs conceptuels. Nous l&#8217;avons vu, nous souhaitons annoter avec un terme du lexique. Pour
des raisons pratiques (co&#251;t calculatoire &#233;lev&#233;), nous utilisons dans un premier temps les sources
lexicales pour extraire les candidats. Une proc&#233;dure de validation permet de retirer tous ceux qui
ne satisfont pas aux conditions de bijectivit&#233; (cf. 1.1). Enfin, pour obtenir une pertinence et un
co&#251;t cognitif optimaux, des &#233;valuateurs ordonnent le r&#233;sultat suivant divers crit&#232;res (fr&#233;quence,
cooccurence, morphologie, . . . ).
</p>
<p>3.1 Extraction de candidats
On distingue plusieurs types d&#8217;extracteurs qui sont caract&#233;ris&#233;s par leur source et la m&#233;thode
employ&#233;e. Les premiers s&#8217;appliquent &#224; un ensemble de dictionnaires traditionnels, analysant les
diff&#233;rentes d&#233;finitions et proposant tous les mots contenus comme candidats. Nous utilisons pour
cela SYGMART 1, un analyseur morphosyntaxique calcul&#233; &#224; partir d&#8217;une phrase donn&#233;e un arbre
morphosyntaxique donn&#233;e. On obtient alors des informations compl&#234;te sur la morphologies des
termes de la phrase ainsi que leur fonction. On filtre articles, pronoms, m&#233;talangage (famille de,
du latin,...) qui n&#8217;apportent pas d&#8217;information s&#233;mantique &#224; la d&#233;finition. D&#8217;autre extracteurs ont
une m&#233;thode identique mais s&#8217;appliquent &#224; des sources comme une liste de synonymes (Ploux,
Victorri, 1998) , concepts du th&#233;saurus, de dictionnaires de cooccurence,... Enfin, les derniers
extracteurs s&#8217;appliquent &#224; des dictionnaires dont on a pu retirer une information structur&#233;e gr&#226;ce
&#224; une analyse morphosyntaxique ou &#224; un format semi-structur&#233; comme XML. On peut alors
retrouver des relations comme synonymie, antonymie, hyperonymie, r&#232;gles d&#8217;usage, exemples
caract&#233;ristiques,... Dans le cas des noms propres, on d&#233;termine qu&#8217;il s&#8217;agit d&#8217;une ville, d&#8217;un
fleuve d&#8217;un pays pr&#233;cis, etc. Ces extracteurs travailleront ainsi sur tous les cas particuliers qu&#8217;on
peut extraire des d&#233;finitions et s&#8217;av&#232;rent particuli&#232;rement efficaces sur les noms propres.
</p>
<p>3.2 Validation d&#8217;un candidat
Apr&#232;s avoir extrait de nombreux candidats, il est n&#233;cessaire de les &#233;valuer. Cependant, avant de
classer des candidats, un filtre va valider ou non des candidats. Comme nous l&#8217;avons expliqu&#233;
pr&#233;c&#233;demment, nous souhaitons obtenir une fonction admettant une r&#233;ciproque pour associer &#224;
un couple &#31;!:J&#5;
</p>
<p>&#21;
</p>
<p>&#3;&#10;&quot; un sens &#4;A&#5;]&#20;^&#3; . L&#8217;objectif de la proc&#233;dure de validation est simplement
d&#8217;&#244;ter tout candidat qui ne satisfait pas cette condition. Elle se formalise de la fa&#231;on suivante :
un annotateur : est valide si et seulement si:
</p>
<p>&#17;&#19;&#4;_%
</p>
<p>+
</p>
<p>&#8;3&#4;&#7;&#5;
</p>
<p>&#21; &#2;
</p>
<p>V`&#31;!:
</p>
<p>&#21;
</p>
<p>&#4;&#7;&#5;#&quot;1a
</p>
<p>&#2;
</p>
<p>V`&#31;!:
</p>
<p>&#21;
</p>
<p>&#4;(%&#7;&quot;
</p>
<p>1d&#233;velopp&#233; par Jacques Chauch&#233; : http://www.lirmm.fr/ b chauche/Pr%E9sentationSygmart.html</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Nommage de sens et annotation autocontenue
</p>
<p>3.3 Evaluation d&#8217;un candidat
3.3.1 Une note d&#8217;extraction des candidats
</p>
<p>Durant la phase d&#8217;extraction des candidats, il est d&#233;j&#224; indispensable de les &#233;valuer suivant : (1)
la source lexicale (diff&#233;rents dictionnaires n&#8217;offrent pas la m&#234;me qualit&#233; de r&#233;sultat), (2) le type
d&#8217;extraction (les concepts les plus activ&#233;s ou les domaines et usages (qui ne sont pas le plus
souvant les meilleurs) et enfin (3) l&#8217;arbre morphosyntaxique fournit des informations comme la
position et la fonction du terme dans la phrase qui sont particuli&#232;rement pr&#233;cieuses. En effet, les
premiers termes d&#8217;une d&#233;finition contiennent tr&#232;s souvent un excellent annotateur du fait qu&#8217;elles
sont exprim&#233;es en genre et diff&#233;rence. SYGMART nous permet de tenir compte particuli&#232;rement
du sujet ou du compl&#233;ment d&#8217;objet dans la d&#233;finition et de r&#233;soudre les difficult&#233;s engendr&#233;es par
l&#8217;apposition de compl&#233;ments.
</p>
<p>3.3.2 La distance angulaire et l&#8217;annotation
Pour assurer la reciprocit&#233; de l&#8217;annotation, il est indispensable que le candidat soit le plus proche
possible du sens annot&#233; tout en maximisant sa distance avec tout autre sens. La notion de distance
angulaire permet d&#8217;&#233;valuer les candidats potentiels gr&#226;ce &#224; trois mesures :
</p>
<p>La marge de d&#233;sambigu&#239;sation absolue. Elle repr&#233;sente l&#8217;intervalle dans lequel la fonction r&#233;-
ciproque n&#8217;associe pas l&#8217;annotateur &#224; un mauvais sens. Plus cette marge est importante, plus les
probabilit&#233;s sont bonnes de ne pas r&#233;associer un mauvais sens dans une autre base lexicale. Soit
:
</p>
<p>&gt;
</p>
<p>l&#8217;annotateur de &#4;
&gt;
</p>
<p>et &#4;Ac
+
</p>
<p>&#8;6&#4;
</p>
<p>&gt;
</p>
<p>le second sens le plus proche de :
&gt;
</p>
<p>. Alors la marge absolue est :
&#3;3&#11;;d$egfhV7&#31;i:
</p>
<p>&gt;
</p>
<p>&#21;
</p>
<p>&#4;
</p>
<p>&gt;
</p>
<p>&quot;7&#8;kj
</p>
<p>&#2;
</p>
<p>V`&#31;!:
</p>
<p>&gt;
</p>
<p>&#21;
</p>
<p>&#4;Ac_&quot;`&#25;
</p>
<p>&#2;
</p>
<p>V`&#31;!:
</p>
<p>&gt;
</p>
<p>&#21;
</p>
<p>&#4;
</p>
<p>&gt;
</p>
<p>&quot;&#12;j
</p>
<p>La marge de d&#233;sambigu&#239;sation relative. Prenons comme exemple deux candidats :
&gt;
</p>
<p>et :lc qui
annotent un sens &#4;m&#20;n&#3; avec les valeurs suivantes :
</p>
<p>&#2;
</p>
<p>V`&#31;!:
</p>
<p>&gt;
</p>
<p>&#21;
</p>
<p>&#4;
</p>
<p>&gt;
</p>
<p>&quot;o&#8;qpsrutwv ,
</p>
<p>&#2;
</p>
<p>V`&#31;!:
</p>
<p>&gt;
</p>
<p>&#21;
</p>
<p>&#4;Ac_&quot;o&#8;qpsryxJx ,
&#2;
</p>
<p>V &#31;i:zc
</p>
<p>&#21;
</p>
<p>&#4;
</p>
<p>&gt;
</p>
<p>&quot;&#16;&#8; psr{xZp et
&#2;
</p>
<p>V`&#31;!:lc
</p>
<p>&#21;
</p>
<p>&#4;&#13;|(&quot;&#16;&#8; p/r}vZp . Leur marge de d&#233;sambiguisation respectives sont
: &#3;3&#11;9d$e~fhVL&#31;!:
</p>
<p>&gt;
</p>
<p>&#21;
</p>
<p>&#4;
</p>
<p>&gt;
</p>
<p>&quot;&#24;&#8; p/r&#127;t&#13;&#128; et &#3;3&#11;;d$egfhV7&#31;i:zc
&#21;
</p>
<p>&#4;&#6;&quot;&#24;&#8; psr}&#129;&#18;p . La marge absolue favorise ainsi
le deuxi&#232;me candidat. Pourtant, le premier est bien mieux associ&#233; au sens annot&#233;. La marge
relative prend en compte la distance entre le candidat est le sens nomm&#233; de la fa&#231;on suivante :
&#3;3&#11;9d$e~fff&#130; &#31;!:
</p>
<p>&gt;
</p>
<p>&#21;
</p>
<p>&#4;w&quot;7&#8;&#132;&#131;
</p>
<p>Vs&#130;s&#133;&#135;&#134;&#137;&#136;s&#321;}&#139;(&#140;&#142;&#141; &#143;\&#144;
</p>
<p>&#145;
</p>
<p>&#140;
</p>
<p>Le risque de non-sens : Cette derni&#232;re mesure poss&#232;de encore un dernier d&#233;faut : elle ne tient pas
compte de la distance entre les deux sens les plus ambigus. Prenons l&#8217;exemple de &#0; fr&#233;gate &#1; . Les
trois sens de ce mot sont (1) &#0; Oiseau de mer &#1; , (2) &#0; b&#226;timent de guerre &#224; trois m&#226;ts &#1; et (3) &#0; B&#226;timent
d&#8217;escorte anti-sous-marin &#1; . Soient les deux candidats &#0; voilier &#1; et &#0; guerre &#1; poss&#233;dant une marge de
d&#233;sambiguisation identique qui annotent (2). &#0; Voilier &#1; a pour sens le plus proche (1) tandis que
&#0; guerre &#1; l&#8217;est avec (3). Alors on doit tenir compte de la distance entre les sens ambigus. Ainsi
la distance entre (1) et (2) &#233;tant bien plus importante qu&#8217;entre (2) et (3), une erreur que ferait la
proc&#233;dure r&#233;ciproque serait bien plus importante si elle associait (1) &#224; (2) dans un texte que si
elle associait (3). Cependant, on peut souhaiter dans le contexte o&#249; les sens (2) et (3) seraient tr&#232;s
pr&#233;sents et le sens (1) absent utiliser l&#8217;annotation (1), l&#8217;objectif &#233;tant de discr&#233;miner au mieux les
sens (2) et (3).
</p>
<p>3.3.3 Autres &#233;valuateurs d&#8217;usage
Pour selectionner un terme r&#233;ellement associ&#233;, il est d&#233;terminant de tenir compte de l&#8217;usage de
l&#8217;annotateur et de l&#8217;annot&#233;. Pour cela, plusieurs &#233;valuateurs sont pr&#233;sents dans notre proc&#233;dure :
(1) La fr&#233;quence d&#8217;usage de l&#8217;annotateur : supposons que &#0; mouche &#1; re&#231;oive comme candidat
mouche/drosophyle/ (pour le sens de l&#8217;insecte). Un annotateur tr&#232;s rare risque de ne pas &#234;tre</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Fabien JALABERT
</p>
<p>connu du client, qu&#8217;il soit humain ou automatique, un annotateur trop fr&#233;quent risque de ne
pas faire sens (cuisine/faire/). De m&#234;me, suivant l&#8217;utilisation, on peut souhaiter dans l&#8217;ordre de
pr&#233;f&#233;rence un hyperonyme, un hyponyme ou un co-hyponyme. La fr&#233;quence est un indice : un
terme bien moins fr&#233;quent qu&#8217;un autre a plus de chance d&#8217;&#234;tre un hyponyme qu&#8217;un hyperonyme.
(2) La cat&#233;gorie grammaticale : le choix d&#8217;utiliser des termes de m&#234;me nature grammaticale
r&#233;duit le co&#251;t cognitif, technique qu&#8217;utilisent depuis longtemps les dictionnaires pour d&#233;finir un
terme ( &#0; d&#233;planter &#1; &#26; &#0; enlever &#1; ; &#0; rimer &#1; &#26; &#0; constituer une rime &#1; ; &#0; table &#1; &#26; &#0; meuble &#1; ... ).
(3) L&#8217;usage : deux utilisateurs diff&#233;rents n&#8217;auront pas les m&#234;mes associations d&#8217;id&#233;es entre dif-
f&#233;rents mots. Par exemple, le terme &#0; police &#1; peut signifier le contrat d&#8217;assurance ou l&#8217;autorit&#233;
judiciaire. Dans ce deuxi&#232;me sens, l&#8217;annotation &#0; agent &#1; ou &#0; poulet &#1; n&#8217;induira pas le m&#234;me com-
portement chez le lecteur. Celui-ci risque de ne pas retrouver une association pourtant &#233;vidente
chez un autre. La cooccurence permet de confirmer l&#8217;association d&#8217;id&#233;e entre deux termes. De
plus, un &#233;tude en contexte et en usage offrira de meilleurs r&#233;sultats. Un site personnel et un livre
ne s&#8217;adresseront pas aux m&#234;me lecteurs, tout comme un article de presse et un article scientifique.
</p>
<p>Conclusion et perspectives
L&#8217;annotation telle que nous venons de la pr&#233;senter est un outil important dans le cadre de nos
recherche. C&#8217;est une interface homme-machine permettant une &#233;valuation rapide et efficace pour
le superviseur d&#8217;un processus de d&#233;sambigu&#239;sation dans le cadre de la traduction, ou dans notre
cas, une aide de l&#8217;analyse de d&#233;finitions pour produire un vecteur conceptuel. Elle est, d&#8217;autre
part, un nouvelle forme d&#8217;interfa&#231;age entres de multiples syst&#232;mes. Les r&#233;sultats actuels sont en-
courrageants, mais de nombreuses voies restent &#224; explorer. Nous projetons ainsi dans un avenir
proche d&#8217;&#233;tudier pr&#233;cis&#233;ment les comportement de l&#8217;utilisateurs et d&#8217;exp&#233;rimenter l&#8217;interfa&#231;age
entre diff&#233;rents syst&#232;mes automatiques dans un cadre multilingue. Enfin, cette analyse des asso-
ciations d&#8217;id&#233;es va devenir une nouvelle source lexicale pour la base vectorielle. L&#8217;objectif est
par cela d&#8217;am&#233;liorer la base de connaissance, et de ce fait notre propre processus (ph&#233;nom&#232;ne de
la double boucle (Schwab, 2003).
Je remercie D. Schwab, M. Lafourcade et V. Prince pour l&#8217;aide pr&#233;cieuse qu&#8217;ils m&#8217;ont apport&#233;e
R&#233;f&#233;rences
Jacques Chauch&#233;, D&#233;termination s&#233;mantique en analyse structurelle : une exp&#233;rience bas&#233;e sur une d&#233;fi-
nition de distance. TAL Information, 31/1, pp 17-24, 1990.
Hachette. Dictionnaire Hachette Encyclop&#233;dique. Hachette, ISBN 2.01.280477.2, version en ligne:
http://www.encyclopedie-hachette.com
M. Lafourcade, V. Prince, D. Schwab Vecteurs conceptuels et structuration &#233;mergente de terminologies
Revue TAL Volume 43 - n 1/2002, pages 43 &#224; 72
Larousse. Th&#233;saurus Larousse - des id&#233;es aux mots, des mots aux id&#233;es. Larousse, 1992.
S. Ploux, B. Victorri Construction d&#8217;espaces s&#233;mantiques &#224; l&#8217;aide de dictionnaires de synonymes Revue
TAL Volume 39, 1998, Num&#233;ro 1.
V. Prince Vers une informatique cognitive dans les organisations - Le r&#244;le central du langage Ed. Masson
1996.
G. Salton Automatic Information Organisation and Retrieval McGraw-Hill, New York 1968.
D. Schwab, M. Lafourcade, V. Prince Vers l&#8217;apprentissage automatique, pour et par les vecteurs con-
ceptuels, de fonctions lexicales. - L&#8217;exemple de l&#8217;antonymie. TALN&#8217;2002 Nancy, Juin 2002.
D. Schwab Soci&#233;t&#233; d&#8217;agents apprenants et s&#233;mantique lexicale : comment construire des vecteurs con-
ceptuels &#224; l&#8217;aide de la double boucle. RECITAL 2003, Batz-sur-Mer, Juin 2003.
Y. Wilks, M. Stevenson Sense tagging : semantic tagging with a lexicon Proceedings of the SIGLEX
Workshop on Tagging Text with Lexical Semantics: Why, What and How?, Washington, D.C. (1997).</p>

</div></div>
</body></html>