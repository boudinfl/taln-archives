<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Tom Emerson</author>
</authors>
<date>2000</date>
<journal>Segmentation of Chinese Text, Multilingual Computing &amp; Technology,</journal>
<volume>12</volume>
<pages>38</pages>
<contexts>
<context position="4560" citStr="Emerson, 2000" startWordPosition="699" endWordPosition="700"> prises en compte. Par exemple au lieu de dire &amp;quot;regarder&amp;quot;, le chinois utilise tres souvent l’eXpression &amp;quot;regarder un regarder&amp;quot;, etc. Deux types d’ambigu&apos;1&apos;tés sont trés fréquentes : ambiguité de croisement intérieur (si une chaine de caractéres ABC peut étre découpée en A/BC ou AB/C, ABC est une chaine ambigué de croisement intérieur) et ambiguité de combinaison (si PQ est un mot et P et Q peuvent aussi étre des mots indépendants. PQ est une chaine ambigué de combinaison). 2 Les approches existantes Dans le domaine de la segmentation du chinois, i1 existe trois types principaux d’algorithmes (Emerson, 2000) : les approches statistiques, les approches fondées sur les dictionnaires et les approches mixtes. Les approches statistiques sont basées sur la probabilité que deux ou plusieurs caractéres apparaissent ensemble. Elles s’appuient généralement sur des modéles a base de HMM (modéles de Markov cachés). Ces approches présentent l’avantage d’étre peu sensibles a l&apos;effet des mots inconnus et des translittérations phonétiques. Toutefois, elles dépendent d’un modele linguistique qui est lui-méme contraint par la qualité et le volume des corpus d’apprentissage. Les approches basées sur les dictionnair</context>
<context position="6532" citStr="Emerson, 2000" startWordPosition="975" endWordPosition="976">ésoudre des ambiguités de croisement intérieur. Comme aucun dictionnaire ne peut étre Un systeme de découpage de chinois basé sur des triplets exhaustif, une désambiguisation a 1’aide de connaissances linguistiques peut étre utilisée en complément. Ces connaissances, par exemple de nature grammaticale, permettent d’effectuer certains regroupements préférentiels a partir d’une segmentation de base considérant chaque caractére comme un mot. C’est le cas dans (Hockenmaier, Brew, 1998). Les méthodes mixes combinent les deux types de méthodes présentés ci-dessus. Le Chinese Morphological Analyzer (Emerson, 2000) en est un exemple. Au vu des avantages et des inconvénients de chaque méthode, nous avons choisi le troisiéme type de méthodes, en combinant un dictionnaire, des connaissances linguistiques et des statistiques. L’a1gorithme de simple maximum matching implique toujours des ambiguités de croisement intérieur et des traitements supplémentaires sont nécessaires pour améliorer la qualité du découpage. Pour la désambiguisation, nous avons aussi besoin de connaissances gramrnaticales. Si des ambiguités persistent encore aprés ces traitements, l’utilisation de fréquences de mots constitue un trés bon</context>
</contexts>
<marker>Emerson, 2000</marker>
<rawString>Tom Emerson (2000), Segmentation of Chinese Text, Multilingual Computing &amp; Technology, Vol. 12 Issue 2, pp38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Hao Tsai</author>
</authors>
<title>A Word Identiﬁcation System for Mandarin Chinese Text Based on Two Variants of the Maximum Matching Algorithm.</title>
<date>1996</date>
<contexts>
<context position="5611" citStr="Tsai, 1996" startWordPosition="846" endWordPosition="847">s dépendent d’un modele linguistique qui est lui-méme contraint par la qualité et le volume des corpus d’apprentissage. Les approches basées sur les dictionnaires peuvent étre divisées en approches strictement basées sur les dictionnaires et approches combinant dictionnaire et connaissances linguistiques. L’idée générale consiste rassembler des caractéres en mot en fonction de ceux présents dans un dictionnaire. Les ambiguités sont levées en utilisant une heuristique générale sur la facon de guider Pappariement : heuristique concemant la taille des mots, comme pour le simple maximum matching (Tsai, 1996) et le complexe maximum matching (Chen, Liu, 1992); ou heuristique relative au sens dans lequel l’appan&apos;ement se fait, comme pour le forward maximum matching mis en oeuvre dans Chinese Segment (Peterson, 2000) et le backward maximum matching. Les deux derniéres sont parfois utilisées conjointement aﬁn de résoudre des ambiguités de croisement intérieur. Comme aucun dictionnaire ne peut étre Un systeme de découpage de chinois basé sur des triplets exhaustif, une désambiguisation a 1’aide de connaissances linguistiques peut étre utilisée en complément. Ces connaissances, par exemple de nature gra</context>
</contexts>
<marker>Tsai, 1996</marker>
<rawString>Chih-Hao Tsai (1996), A Word Identiﬁcation System for Mandarin Chinese Text Based on Two Variants of the Maximum Matching Algorithm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S H Liu</author>
</authors>
<title>Word identiﬁcation for Mandarin Chinese sentences.</title>
<date>1992</date>
<booktitle>Proceedings, Fifteenth International Conference on Computational Linguistics,</booktitle>
<location>Nantes:</location>
<contexts>
<context position="5661" citStr="Liu, 1992" startWordPosition="854" endWordPosition="855">me contraint par la qualité et le volume des corpus d’apprentissage. Les approches basées sur les dictionnaires peuvent étre divisées en approches strictement basées sur les dictionnaires et approches combinant dictionnaire et connaissances linguistiques. L’idée générale consiste rassembler des caractéres en mot en fonction de ceux présents dans un dictionnaire. Les ambiguités sont levées en utilisant une heuristique générale sur la facon de guider Pappariement : heuristique concemant la taille des mots, comme pour le simple maximum matching (Tsai, 1996) et le complexe maximum matching (Chen, Liu, 1992); ou heuristique relative au sens dans lequel l’appan&apos;ement se fait, comme pour le forward maximum matching mis en oeuvre dans Chinese Segment (Peterson, 2000) et le backward maximum matching. Les deux derniéres sont parfois utilisées conjointement aﬁn de résoudre des ambiguités de croisement intérieur. Comme aucun dictionnaire ne peut étre Un systeme de découpage de chinois basé sur des triplets exhaustif, une désambiguisation a 1’aide de connaissances linguistiques peut étre utilisée en complément. Ces connaissances, par exemple de nature grammaticale, permettent d’effectuer certains regroup</context>
</contexts>
<marker>Liu, 1992</marker>
<rawString>Chen K. J ., &amp; Liu S. H. (1992), Word identiﬁcation for Mandarin Chinese sentences. Proceedings, Fifteenth International Conference on Computational Linguistics, Nantes: COLING-92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L Hung</author>
<author>O J L Tzeng</author>
</authors>
<title>Orthographic variations and visual information processing,</title>
<date>1981</date>
<journal>Psychological Bulletin,</journal>
<volume>90</volume>
<pages>377--414</pages>
<marker>Hung, Tzeng, 1981</marker>
<rawString>Hung D. L, &amp; Tzeng O. J. L (1981), Orthographic variations and visual information processing, Psychological Bulletin, Vol.90, pp377-414.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Palmer</author>
</authors>
<title>A Trainable Rule-Based Algorithm for Word Segmentation</title>
<date>1997</date>
<booktitle>Proceedings, Acte de the 35th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Madrid.</location>
<contexts>
<context position="14021" citStr="Palmer, 1997" startWordPosition="2122" endWordPosition="2123">rmi 9489 mots dans le texte découpé par notre algorithme. 11 y a 9599 mots dans le résultat standard. Les valeurs du rappel, de la précision et de la F-mesure de notre algorithme sont respectivement de 97,2%, 98,9% et 97,7%. Par rapport aux performances d’autres algorithmes existants, notre algorithme donne des résultats assez satisfaisants. Le rappel, la précision et la F-mesure de l’algorithme de MMSEG de Chih-Hao Tsai sur 1013 mots sont de 95,4%, 95,5% et 95.4% pour le simple maximum matching, et 98,1%, 98,4% et 98,3% pour le complex maximum matching. Le résultat de l’algorithme de Palmer (Palmer, 1997) sur le corpus XinHua a une F-mesure de 89,6%. Les Fmesures de l’algorithme Error Driven Learning (Hockenmaier, Brew, 1998) sont de 87,9%, 87,4% et 87,1%. 5 Discussion Aﬁn de mieux évaluer les performances de notre algorithme, nous l&apos;avons comparé a deux systémes actuellement disponibles (Peterson, Wu). Un découpage au moyen de ces deux algorithmes et du notre est réalisé sur le méme corpus . Texte 2‘: découper : iZ7&apos;%&apos; E|2li%%ElITl?%‘:*’Iﬁﬁ3&lt;ﬂ” “F |l&gt;|’%EﬁEl‘J%%lﬁ3e?&lt;i3F?li Segmentation correct : ii-7%“ EIZIS-ééﬂ-ﬂiii;-ﬁgﬁij-X3‘-EF E&gt;|-4‘?Eﬁ°l5I&amp;quot;J&apos;§%“° ﬁ3$&apos;i¥Zl’z Traduction: C’est l’évaluatio</context>
</contexts>
<marker>Palmer, 1997</marker>
<rawString>David Palmer (1997), A Trainable Rule-Based Algorithm for Word Segmentation Proceedings, Acte de the 35th Annual Meeting of the Association for Computational Linguistics, Madrid.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
</authors>
<title>The part-of-speech tagging guidelines for the Penn Chinese T reebank (3.0),</title>
<date>2000</date>
<pages>4--5</pages>
<location>Philadelphia,</location>
<contexts>
<context position="3923" citStr="Xia, 2000" startWordPosition="598" endWordPosition="599"> les caracteres peuvent constituer un mot en soi. lls peuvent également se joindre a d’autres caractéres pour former des mots. Deuxiémement, le chinois modeme utilise essentiellement des mots composés. Il est difﬁcile de détenniner si un mot composé rare est un mot ou une expression. Troisiémement, les mémes caractéres sont généralement employés pour la construction des noms communs et des noms propres. La distinction e11tre les deux se révéle des lors difﬁcile. Quatriémement, quelques structures morphologiques spéciales, comme la duplication et les constructions A_non_A, AA, A_un_A, et ABAB (Xia, 2000) doivent également étre prises en compte. Par exemple au lieu de dire &amp;quot;regarder&amp;quot;, le chinois utilise tres souvent l’eXpression &amp;quot;regarder un regarder&amp;quot;, etc. Deux types d’ambigu&apos;1&apos;tés sont trés fréquentes : ambiguité de croisement intérieur (si une chaine de caractéres ABC peut étre découpée en A/BC ou AB/C, ABC est une chaine ambigué de croisement intérieur) et ambiguité de combinaison (si PQ est un mot et P et Q peuvent aussi étre des mots indépendants. PQ est une chaine ambigué de combinaison). 2 Les approches existantes Dans le domaine de la segmentation du chinois, i1 existe trois types pri</context>
</contexts>
<marker>Xia, 2000</marker>
<rawString>Fei Xia (2000), The part-of-speech tagging guidelines for the Penn Chinese T reebank (3.0), Philadelphia, ppl4-l 5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fuchun Peng</author>
<author>Xiangji Huang</author>
<author>Dale Schuurmans</author>
<author>Nick Cercone</author>
</authors>
<title>Investigating the relationship between word segmentation performance and retrieval performance</title>
<date>2002</date>
<booktitle>in Chinese IR, Acte de COLING 2002 the 19th International Conference on Computational Linguistics,</booktitle>
<pages>793--799</pages>
<marker>Peng, Huang, Schuurmans, Cercone, 2002</marker>
<rawString>Fuchun Peng, Xiangji Huang, Dale Schuurmans, Nick Cercone (2002), Investigating the relationship between word segmentation performance and retrieval performance in Chinese IR, Acte de COLING 2002 the 19th International Conference on Computational Linguistics, 793-799.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Chris Brew</author>
</authors>
<title>Error-driven segmentation of Chinese,</title>
<date>1998</date>
<booktitle>Acte de 12th Paciﬁc Conference on Language and Information,</booktitle>
<pages>218--229</pages>
<marker>Hockenmaier, Brew, 1998</marker>
<rawString>Julia Hockenmaier, Chris Brew, (1998), Error-driven segmentation of Chinese, Acte de 12th Paciﬁc Conference on Language and Information, 218-229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Peterson</author>
</authors>
<title>http://wvvw.mandarintools.com Zhibiao Wu,</title>
<date>2000</date>
<note>http://www.ldc.upenn.edu/Projects/Chinese/segmenter/ma11segment.perl http://www.ldc.upenn.edu/Projects/Chinese/segmenter/Mandarin.fre</note>
<contexts>
<context position="5820" citStr="Peterson, 2000" startWordPosition="878" endWordPosition="879">ment basées sur les dictionnaires et approches combinant dictionnaire et connaissances linguistiques. L’idée générale consiste rassembler des caractéres en mot en fonction de ceux présents dans un dictionnaire. Les ambiguités sont levées en utilisant une heuristique générale sur la facon de guider Pappariement : heuristique concemant la taille des mots, comme pour le simple maximum matching (Tsai, 1996) et le complexe maximum matching (Chen, Liu, 1992); ou heuristique relative au sens dans lequel l’appan&apos;ement se fait, comme pour le forward maximum matching mis en oeuvre dans Chinese Segment (Peterson, 2000) et le backward maximum matching. Les deux derniéres sont parfois utilisées conjointement aﬁn de résoudre des ambiguités de croisement intérieur. Comme aucun dictionnaire ne peut étre Un systeme de découpage de chinois basé sur des triplets exhaustif, une désambiguisation a 1’aide de connaissances linguistiques peut étre utilisée en complément. Ces connaissances, par exemple de nature grammaticale, permettent d’effectuer certains regroupements préférentiels a partir d’une segmentation de base considérant chaque caractére comme un mot. C’est le cas dans (Hockenmaier, Brew, 1998). Les méthodes m</context>
</contexts>
<marker>Peterson, 2000</marker>
<rawString>Erik Peterson, (2000), http://wvvw.mandarintools.com Zhibiao Wu, (1999), http://www.ldc.upenn.edu/Projects/Chinese/segmenter/ma11segment.perl http://www.ldc.upenn.edu/Projects/Chinese/segmenter/Mandarin.fre</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>