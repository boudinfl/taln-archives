@proceedings{RECITAL:2004,
  editor    = {Béchet, Frédéric and Vanrullen, Tristan},
  title     = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004}
}

@inproceedings{ligozat:2004:RECITAL,
  author    = {Ligozat, Anne-Laure},
  title     = {Système de Question Réponse : apport de l’analyse syntaxique lors de l’extraction de la réponse},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-long-001},
  language  = {french},
  resume    = {Dans cet article, nous présentons le système de Question Réponse QALC, et nous nous intéressons tout particulièrement à l’extraction de la réponse. Un appariement question-réponse fondé sur les relations syntaxiques a été développé, afin d’améliorer les performances du système. Un projet de génération de réponses à partir de plusieurs documents est également discuté.},
  abstract  = {In this paper, we present the question answering system QALC, and we particularly focus on the answer extraction. A question and answer matching based on syntactic relations has been developed, in order to improve the results of our system. A project aiming at fusing answers from several documents is also discussed.},
  motscles  = {Système de Question Réponse, analyse syntaxique, fusion de documents},
  keywords  = {Question answering system, syntactic analysis, document fusion},
}

@inproceedings{millon:2004:RECITAL,
  author    = {Millon, Chrystel},
  title     = {Acquisition de relations lexicales désambiguïsées à partir du Web},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-long-002},
  language  = {french},
  resume    = {Nous montrons dans cet article qu’un pré-étiquetage des usages des mots par un algorithme de désambiguïsation tel qu’HyperLex (Véronis, 2003, 2004) permet d’obtenir des relations lexicales (du type NOM-ADJECTIF, NOM de NOM, NOM-VERBE) beaucoup plus exploitables, parce qu’elles-mêmes catégorisées en fonction des usages. De plus, cette technique permet d’obtenir des relations pour des usages très peu fréquents, alors qu’une extraction indifférenciée « noie » ces relations au milieu de celles correspondant aux usages les plus fréquents. Nous avons conduit une évaluation sur un corpus de plusieurs milliers de pages Web comportant l’un des 10 mots-cibles très polysémiques choisis pour cette expérience, et nous montrons que la précision obtenue est très bonne, avec un rappel honorable, suffisant en tout cas pour de nombreuses applications. L’analyse des erreurs ouvre des perspectives d’améliorations pour la suite de notre travail de thèse.},
  abstract  = {This study shows that a pre-labeling of word uses by means of a disambiguation algorithm such as HyperLex (Véronis, 2003, 2004) allows a better extraction of lexical relations (NOUNADJECTIVE, NOUN “de” NOUN, NOUN-VERB, etc.), since these relations are categorised with respect to word use. In addition, this technique enables us to retrieve relations for very infrequent word uses, which otherwise would be buried in the residual noise corresponding to the most frequent uses. We performed an evaluation on several thousand web pages containing a target word among a set of 10 highly polysemic ones. We show that the precision obtained is very good, with a quite honourable recall, sufficient in any case for many applications. The analysis of errors opens avenues of research for the rest of our PhD work.},
  motscles  = {Corpus, relations lexicales, acquisition automatique, désambiguïsation lexicale},
  keywords  = {Corpus, lexical relations, automatic acquisition, word sense disambiguation},
}

@inproceedings{neveol:2004:RECITAL,
  author    = {Névéol, Aurélie},
  title     = {Indexation automatique de ressources de santé à l’aide d’un vocabulaire contrôlé},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-long-003},
  language  = {french},
  resume    = {Nous présentons ici le système d’indexation automatique actuellement en cours de développement dans l’équipe CISMeF afin d’aider les documentalistes lors de l’indexation de ressources de santé. Nous détaillons l’architecture du système pour l’extraction de mots clés MeSH, et présentons les résultats d’une première évaluation. La stratégie d’indexation choisie atteint une précision comparable à celle des systèmes existants. De plus, elle permet d’extraire des paires mot clé/qualificatif, et non des termes isolés, ce qui constitue une indexation beaucoup plus fine. Les travaux en cours s’attachent à étendre la couverture des dictionnaires, et des tests à plus grande échelle sont envisagés afin de valider le système et d’évaluer sa valeur ajoutée dans le travail quotidien des documentalistes.},
  abstract  = {This paper presents the automatic indexing system currently developed in the CISMeF team to assist human indexers. The system architecture, using the INTEX platform for MeSH term extraction is detailed. The results of a preliminary experiment indicate that the automatic indexing strategy is relevant, as it achieves a precision comparable to that of other existing operational systems. Moreover, the system presented in this paper retrieves keyword/qualifier pairs as opposed to single terms, therefore providing a significantly more precise indexing. Further development and tests will be carried out in order to improve the coverage, and validate the efficiency of the system in the librarians’ everyday work.},
  motscles  = {Indexation Automatique, Terminologie Médicale, Vocabulaire Contrôlé},
  keywords  = {Automatic Indexing, Medical terminology, Controlled Vocabulary},
}

@inproceedings{ozdowska:2004:RECITAL,
  author    = {Ozdowska, Sylwia},
  title     = {Appariement bilingue de mots par propagation syntaxique à partir de corpus français/anglais alignés},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-long-004},
  language  = {french},
  resume    = {Nous présentons une méthode d’appariement de mots, à partir de corpus français/anglais alignés, qui s’appuie sur l’analyse syntaxique en dépendance des phrases. Tout d’abord, les mots sont appariés à un niveau global grâce au calcul des fréquences de cooccurrence dans des phrases alignées. Ces mots constituent les couples amorces qui servent de point de départ à la propagation des liens d’appariement à l’aide des différentes relations de dépendance identifiées par un analyseur syntaxique dans chacune des deux langues. Pour le moment, cette méthode dite d’appariement local traite majoritairement des cas de parallélisme, c’est-à-dire des cas où les relations syntaxiques sont identiques dans les deux langues et les mots appariés de même catégorie. Elle offre un taux de réussite de 95,4% toutes relations confondues.},
  abstract  = {We present a word alignment procedure based on a syntactic dependency analysis of French/English parallel corpora. First, words are associated at a global level by comparing their co-occurrences in aligned sentences with respect to their overall occurrences in order to derive a set of anchor words. The anchor words are the starting point of the propagation process of alignment links using the different syntactic relations identified by a parser for each language. This process is called the local alignment. For the moment, it is performed basically when the syntactic relations are identical in both languages and the words aligned have the same part of speech. This method achieves a precision rate of 95,4% all syntactic relations taken into account.},
  motscles  = {appariement syntaxique de mots, corpus parallèle, traitement automatique des langues naturelles},
  keywords  = {syntactic word alignment, parallel corpora, natural language processing},
}

@inproceedings{guenot-bellengier:2004:RECITAL,
  author    = {Guénot, Marie-Laure and Bellengier, Emmanuel},
  title     = {Quelques principes pour une grammaire multimodale non-modulaire du français},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-long-005},
  language  = {french},
  resume    = {Dans cet article, nous introduisons une approche de la représentation et de l’analyse des discours multimodaux, basée sur un traitement unimodulaire par contraintes. Le but de cet article est de présenter (i) un système de représentation des données et (ii) une méthode d’analyse, permettant une interaction simplifiée entre les différentes modalités de communication. L’avantage de cette méthode est qu’elle permet la prise en compte rigoureuse d’informations communicatives de natures diverses en un traitement unique, grâce à une représentation homogène des objets, de leurs relations, et de leur méthode d’analyse, selon le modèle des Grammaires de Propriétés.},
  abstract  = {In this paper, we introduce an approach to multimodal discourse representation and analysis, based on a unimodular constraint-based treatment. The aim of this paper is to present (i) a data representation system, and (ii) an analysis method, which allow a simple interaction between the various modalities of communication. The advantage of this method is that it allows to rigorously take into account multi-character information within a single treatment, thanks to a homogeneous representation of the objects, of their relations, and of their analysis method, according to the Property Grammars formalism.},
  motscles  = {Analyse multimodale, Linguistique formelle, Développement de grammaire, Grammaires de Propriétés},
  keywords  = {Multimodal analysis, Formal linguistics, Grammar development, Property Grammars},
}

@inproceedings{benzitoun:2004:RECITAL,
  author    = {Benzitoun, Christophe},
  title     = {L'annotation syntaxique de corpus oraux constitue-t-elle un problème spécifique ?},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-long-006},
  language  = {french},
  resume    = {Dans cet article, nous présentons une typologie des phénomènes qui posent problème pour l'annotation syntaxique de corpus oraux. Nous montrons également que ces phénomènes, même s'ils y sont d'une fréquence moindre, sont loin d'être absents à l'écrit (ils peuvent même être tout à fait significatifs dans certains corpus : e-mails, chats, SMS…), et que leur prise en compte peut améliorer l'annotation et fournir un cadre intégré pour l'oral et l'écrit.},
  abstract  = {In this paper, we present a typology of the phenomena that create problems for the syntactic tagging of spoken corpora. We also show that these phenomena, although less frequent, are far from being absent in written language (they can even be quite significant in some corpora: e-mails, chats, SMS…). Taken them into account can improve the annotation and provide a unified analysis framework for both spoken and written data.},
  motscles  = {Annotation syntaxique, corpus oraux, NFCE, annotation de référence},
  keywords  = {Syntactic annotation, spoken corpora, reference annotation},
}

@inproceedings{blanc-dister:2004:RECITAL,
  author    = {Blanc, Olivier and Dister, Anne},
  title     = {Automates lexicaux avec structure de traits},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-long-007},
  language  = {french},
  resume    = {Nous présentons les automates lexicaux avec structure de traits, une extension du modèle des automates finis sur le mots dans lesquels les transitions sont étiquetées par des motifs qui sélectionnent un sous-ensemble des mots étiquetés en fonction de leurs traits positionnés. Nous montrons l’adéquation de ce modèle avec les ressources linguistiques dont nous disposons et nous exposons les grandes lignes de nos méthodes pour effectuer des opérations telles que la déterminisation, l’intersection ou la complémentation sur ces objets. Nous terminons en présentant une application concrète de ces méthodes pour la levée d’ambiguïtés lexicales par intersection d’automates à l’aide de contraintes locales.},
  abstract  = {We present an extension to finite automata on words in which transitions are labeled with lexical masks describing a subset of their alphabet. We first show the connection between this model and our linguitic data and we present our implementation of classical automata operations on these objects. Then we show a concrete application of our methods to lexical disambiguation making use of grammatical constraints described in local grammars.},
  motscles  = {automates finis, grammaire locale, dictionnaire électronique, levée d’ambiguïtés, lexique-grammaire},
  keywords  = {finite state automata, local grammar, electronic dictionnary, disambiguation, lexicon-grammar},
}

@inproceedings{venant:2004:RECITAL,
  author    = {Venant, Fabienne},
  title     = {Géométriser le sens},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-long-008},
  language  = {french},
  resume    = {Les recherches en sémantique lexicale s’appuient de plus en plus sur des ressources électroniques de grande taille (dictionnaires informatisés, corpus, ontologies) à partir desquelles on peut obtenir diverses relations sémantiques entre unités lexicales. Ces relations sont naturellement modélisées par des graphes. Bien qu'ils décrivent des phénomènes lexicaux très différents, ces graphes ont en commun des caractéristiques bien particulières. On dit qu’ils sont de type petit monde. Nous voulons mener une étude théorique mathématique et informatique de la structure de ces graphes pour le lexique. Il s’agit de les géométriser afin de faire apparaître l'organisation du lexique, qui est implicitement encodée dans leur structure. Les outils mis en place sont testés sur le graphe du dictionnaire électronique des synonymes (www.crisco.unicaen.fr). Ils constituent une extension du logiciel Visusyn développé par Ploux et Victorri (1998).},
  abstract  = {Research in lexical semantics tends to rely on large-scale electronic language resources (machine-readable dictionaries, corpora, ontologies), from which one can get varied semantic relationships between lexical units. Such relationships are naturally modelled by graphs. Although they describe different lexical phenomena, these graphs share some very specific characteristics. They are called "small worlds". We want to carry out a theoretical mathematical and informatic study of these graphs. The point is to geometrise them in order to reveal the organisation of the lexicon that is encoded in their structure. The tools we developed are tested on the graph of the electronic dictionary of synonyms (www.crisco.unicaen.fr). They represent an extension of Visusyn, the software developed by Ploux and Victorri (1998).},
  motscles  = {Lexique, espace sémantique, synonymie, graphes petit monde},
  keywords  = {Lexicon, Semantic space, synonymy, graph, small world},
}

@inproceedings{anoun:2004:RECITAL,
  author    = {Anoun, Houda},
  title     = {ICHARATE : Un Atelier Logique pour les Grammaires Multimodales},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-001},
  language  = {french},
  resume    = {Cet article présente le projet de l’atelier logique ICHARATE dédié à l’étude des grammaires catégorielles multimodales. Cet atelier se présente sous la forme de bibliothèques pour l’assistant de preuves Coq.},
  abstract  = {},
  motscles  = {analyse syntaxique, grammaires catégorielles, théorie des types, assistant de preuves},
  keywords  = {},
}

@inproceedings{barque:2004:RECITAL,
  author    = {Barque, Lucie},
  title     = {De la lexie au vocable : la représentation formelle des liens de polysémie},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-002},
  language  = {french},
  resume    = {Cet article s’intéresse aux définitions formalisées de la base de données BDéf et montre en quoi la structure formelle de ces définitions est à même d’offrir une représentation originale de la polysémie lexicale.},
  abstract  = {This article deals with formal structure of BDéf’s definitions and shows in what way this structure is appropriate to offer an original representation of the lexical polysemy phenomenon.},
  motscles  = {LEC, dictionnaire électronique formalisé, structure définitionnelle, TAL},
  keywords  = {ECL, formalised electronical dictionnary, structure of the definition, NLP},
}

@inproceedings{bouhafs:2004:RECITAL,
  author    = {Bouhafs, Asma},
  title     = {Système d'extraction d'information dédié à la veille Qui est qui? Qui fait quoi? Où? Quand? Comment?},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-003},
  language  = {french},
  resume    = {Dans cet article nous présentons un outil d’extraction d’information dédié à la veille qui répond à un certain nombre de requêtes formulées par l'utilisateur, en combinant la puissance des outils et les ressources informatiques à une analyse linguistique. Cette analyse linguistique permet le repérage des entités nommées (acteurs, lieux, temps,…) ainsi que la mise en relation des acteurs avec leur environnement dans l'espace et le temps au moyen d'indices déclencheurs, d’indices complémentaires et de règles qui les combinent, c'est le principe de l'Exploration Contextuelle. Les résultats capitalisés dans des fichiers XML, sont proposés par le biais d’une interface, soit sous forme de graphes soit sous forme de base d'informations.},
  abstract  = {In this article we present an information extraction tool which answers a certain number of requests formulated by the user, by combining data-processing with a linguistic analysis. This linguistic analysis allows the location of the named entities (actors, places, time...) thus the relations between actors and their environments in space and time by means of indices, indicators and rules which combine them, it is the principle of Contextual Exploration. The results capitalized in XML files are presented in an interface, either in the form of graphs or in the form of databases.},
  motscles  = {Classes sémantiques, Extraction d’information, Exploration Contextuelle, Ressources, Réseau sémantique},
  keywords  = {Semantic classes, Information Extraction, Contextual Exploration, Resources, Semantic network},
}

@inproceedings{farzindar:2004:RECITAL,
  author    = {Farzindar, Atefeh},
  title     = {Développement d’un système de Résumé automatique de Textes Juridiques},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-004},
  language  = {french},
  resume    = {Nous décrivons notre méthode de production automatique du résumé de textes juridiques. C’est une nouvelle application du résumé qui permet aux juristes de consulter rapidement les idées clés d’une décision juridique pour trouver les jurisprudences pertinentes à leurs besoins. Notre approche est basée sur l’exploitation de l’architecture des documents et les structures thématiques, afin de constituer automatiquement des fiches de résumé qui augmentent la cohérence et la lisibilité du résumé. Dans cet article nous détaillons les conceptions des différentes composantes du système, appelé LetSum et le résultat d’évaluation.},
  abstract  = {We describe our method for dealing with automatic summarization techniques in the legal domain. This new application of summary helps a legal expert determine the key ideas of a judgement. Our approach is based on the exploration of the document’s architecture and its thematic structures, in order to build a table style summary, which improves coherency and readability in the summary. We present the components of a system, called LetSum, built with this approach and some preliminary results of the evaluation.},
  motscles  = {Résumé automatique, fiches de résumé, segmentation thématique, textes juridiques},
  keywords  = {Automatic text summarization, summary table, topic segmentation, legals texts},
}

@inproceedings{grivolla:2004:RECITAL,
  author    = {Grivolla, Jens},
  title     = {Méthodes statistiques et apprentissage automatique pour l’évaluation de requêtes en recherche documentaire},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-005},
  language  = {french},
  resume    = {Pour la recherche documentaire il est souvent intéressant d’avoir une bonne mesure de confiance dans les réponses trouvées par le moteur de recherche. Une bonne estimation de pertinence peut permettre de faire un choix entre plusieurs réponses (venant éventuellement de différents systèmes), d’appliquer des méthodes d’enrichissement additionnelles selon les besoins, ou encore de permettre à l’utilisateur de prendre des décisions (comme d’approfondir la recherche à travers un dialogue). Nous proposons une méthode permettant de faire une telle estimation, utilisant des connaissances extraites d’un ensemble de requˆetes connues pour en déduire des prédictions sur d’autres requˆetes posées au système de recherche documentaire.},
  abstract  = {In document retrieval applications it is often interesting to have a measure of confidence in the answers found by the retrieval system. A good relevance estimation can allow us to make a choice between different answers (possibly provided by different sources), apply additional expansion techniques according to the specific needs, or enable the user to make decisions (such as to refine the search interactively). We propose a method that allows us to make such estimations, using knowledge extracted from a known query corpus to deduce predictions on new queries presented to the document retrieval system.},
  motscles  = {apprentissage/décision automatique, recherche documentaire, expansion de requêtes, évaluation de difficulté},
  keywords  = {automatic learning/decision, document retrieval, query expansion, difficulty evaluation},
}

@inproceedings{houben:2004:RECITAL,
  author    = {Houben, Frédérick},
  title     = {Mot vide, mot plein ? Comment trancher localement},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-006},
  language  = {french},
  resume    = {Nous présentons une méthode multilingue de catégorisation en mot vide / mot plein à partir de corpus brut. Cette méthode fait appel à des propriétés très générales des langues ainsi qu’à des techniques issues de la communauté de la fouille de données.},
  abstract  = {We are presenting a NLP multilingual method for function word / content word categorization using no other resource than the raw text itself. This method uses very general linguistic properties and also engineering from data mining community.},
  motscles  = {Traitements multilingues, découverte de mots vides, alternative à une stop-list, extraction de règles et de motifs fréquents},
  keywords  = {Multilingual NLP, function words discovery, stop-list alternation, rules and frequent pattern mining},
}

@inproceedings{iheddadene:2004:RECITAL,
  author    = {Iheddadene, Mehand},
  title     = {Génération sémantico-syntaxique pour la traduction automatique basée sur une architecture interlingue},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-007},
  language  = {french},
  resume    = {Dans cet article, nous présentons un processus de génération sémantico-syntaxique conçu et mis en oeuvre dans la réalisation d’un prototype de traduction automatique basée sur le modèle à structure intermédiaire (ou structure pivot). Dans une première partie de l’article, nous présentons l’organisation des ressources lexicales et sémantiques multilingues, ainsi que les mécanismes permettant d’exploiter ces ressources pour produire une représentation conceptuelle du sens de la phrase source. Dans une seconde partie, nous présentons la première phase de génération à partir d’une structure pivot (génération Sémantico-Syntaxique) permettant la construction d’une structure syntaxique profonde de la phrase cible à produire. Les autres phases de génération ne seront pas abordées dans cet article.},
  abstract  = {This paper aims to present a method for the semantic-syntactic generation that has been proposed to build a machine translation prototype based on the interlingua translation model. The first part of the paper introduces the multilingual lexical and semantical resources, and the way they are used to build conceptual representations of the meaning of source sentences. The following part of the paper presents the first step in generating the target text from the conceptual representation (semantic-syntactic generation) which results on a deep syntactic structure of the targeted text. The other steps of the generation process will not be discussed in this paper.},
  motscles  = {Traduction Automatique, Architecture interlingue, sémantique lexicale, Génération sémanticosyntaxique, structure syntaxique profonde},
  keywords  = {Machine Translation, Interlingual architecture, lexical semantics, semantic-syntactic generation, deep syntactic structure},
}

@inproceedings{jamborovalemay:2004:RECITAL,
  author    = {Jamborova-Lemay, Diana},
  title     = {Reconnaissance automatique des adjectifs durs et des adverbes réguliers lors de l’analyse morphologique automatique du slovaque},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-008},
  language  = {french},
  resume    = {L’analyse morphologique automatique du slovaque constitue la première étape d’un système d’analyse automatique du contenu des textes scientifiques et techniques slovaques. Un tel système pourrait être utilisé par des applications telles que l’indexation automatique des textes, la recherche automatique de la terminologie ou par un système de traduction. Une description des régularités de la langue par un ensemble de règles ainsi que l’utilisation de tous les éléments au niveau de la forme du mot qui rendent possible son interprétation permettent de réduire d’une manière considérable le Volume des dictionnaires. Notamment s’il s’agît d’une langue à flexion très riche, comme le slovaque. La reconnaissance automatique des adjectifs durs et des adverbes réguliers constitue la partie la plus importante de nos travaux. Les résultats que nous obtenons lors de l’analyse morphologique confirment la faisabilité et la grande fiabilité d’une analyse morphologique basée sur la reconnaissance des formes et ceci pour toutes les catégories lexicales.},
  abstract  = {Automatic morphological analysis of Slovak language is the first level of an automatic analyser for Slovak scientific and technical texts. Such a system could be used for different applications: automatic text indexation, automatic research of terminology or translation systems. Rule-based descriptions of language regularities as Well as the use of all the formal level elements of Words allow reducing considerably the volume of dictionaries. Notably in case of inflectionally rich languages such as Slovak. The most important part of our research is the automatic recognition of adjectives and regular adverbs. The results obtained by our morphological analyser justify such an approach and confirm the high reliability of morphological analysis based on form-recognition for all lexical categories.},
  motscles  = {Traitement automatique du slovaque, Analyse morphologique, Morphologie flexionnelle, Morphologie dérivationnelle},
  keywords  = {Natural Language Processing of Slovak, Morphological Analysis, Inflectional Morphology, Derivational Morphology},
}

@inproceedings{lunagarcia:2004:RECITAL,
  author    = {Luna Garcia, Francisca},
  title     = {Traitement informatique de l’inflexion dans le Lunaf, dictionnaire électronique du luxembourgeois},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-009},
  language  = {french},
  resume    = {Afin de générer les formes fléchies des noms luxembourgeois dans le dictionnaire luxembourgeois, nous utilisons un code flexionnel. Ce code s’étant révélé trop contraignant pour traiter l’inflexion (alternance vocalique/Umlaut), nous présentons ici un moyen efficace pour coder ce phénomène. La pertinence de ce type de code est double. D’une part, il correspond mieux aux besoins du linguiste qui aimerait établir des classes flexionnelles naturelles sans trop de contraintes informatiques. D’autre part, il permet de réduire significativement le nombre de classes flexionnelles. Le dictionnaire électronique luxembourgeois dispose ainsi de deux codes qui peuvent se combiner entre eux pour mieux traiter les particularités morphologiques des mots luxembourgeois.},
  abstract  = {In order to generate the inflected forms of the Luxemburgish nouns in the Luxemburgish dictionary, we use a flexional. This code having proved to be too constraining to treat the inflection (vocalic alternation/Umlaut), we present here an effective means to encode this phenomenon. The relevance of this code is two-fold. On the one hand, it corresponds better to the needs of the linguist who would like to establish natural flexional classes without too many data-processing constraints. In addition, it reduces the number of flexional classes significantly. The Luxemburgish dictionary has thus two codes which can be combined for a better processing of the morphological characteristics of the Luxemburgish words.},
  motscles  = {inflexion vocalique, codage, génération automatique, luxembourgeois},
  keywords  = {vowel inflection, encoding, automatic generation, Luxemburgish},
}

@inproceedings{nguyen:2004:RECITAL,
  author    = {Nguyen, Tuan-Dang},
  title     = {Nouvelle méthode syntagmatique de vectorisation appliquée au self-organizing map des textes vietnamiens},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-010},
  language  = {french},
  resume    = {Par ses caractéristiques éminentes dans la présentation des données, Self-Organizing Map (SOM) est particulièrement convenable à l’organisation des cartes. SOM se comporte d’un ensemble des vecteurs prototypes pour représenter les données d’entrée, et fait une projection, en conservant la topologie, à partir des vecteurs prototypes de n-dimensions sur une carte de 2-dimensions. Cette carte deviendra une vision qui reflète la structure des classes des données. Nous notons un problème crucial pour SOM, c’est la méthode de vectorisation des données. Dans nos études, les données se présentent sous forme des textes. Bien que le modèle général du SOM soit déjà créé, il nous faut de nouvelles recherches pour traiter des langues spécifiques, comme le vietnamien, qui sont de nature assez différente de l’anglais. Donc, nous avons appliqué la conception du syntagme pour établir un algorithme qui est capable de résoudre ce problème.},
  abstract  = {},
  motscles  = {Self-Organizing Map, text mining, classification, vectorisation du texte, syntagme, évaluation visuelle},
  keywords  = {},
}

@inproceedings{raynal:2004:RECITAL,
  author    = {Raynal, Céline},
  title     = {Représentation compositionnelle de la sémantique de aussi},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-011},
  language  = {french},
  resume    = {L’objectif de notre travail est de dégager une représentation formelle compositionnelle de la contribution sémantique de aussi lorsqu’il a une valeur additive. Plusieurs problèmes de compositionnalité, liés surtout à la diversité des arguments concernés par l’adverbe, vont se poser. Nous proposons une alternative compositionnelle à la représentation proposée initialement en l-DRT.},
  abstract  = {The aim is to find a compositional formal representation to the French adverb aussi when it has an additive meaning. The variety of arguments of the adverb entails several problems of compositionality. Given the l-DRT representation is problematic, we try to propose an other one, compositional too.},
  motscles  = {Sémantique, l-DRT, présupposition, compositionnalité},
  keywords  = {Semantics, l-DRT, presupposition, compositionality},
}

@inproceedings{saidane-zrigui-benahmed:2004:RECITAL,
  author    = {Saidane, Tahar and Zrigui, Mounir and Ben Ahmed, Mohamed},
  title     = {La Transcription Orthographique-Phonetique De La Langue Arabe},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-012},
  language  = {french},
  resume    = {Notre article présente les composants nécessaires à la synthèse de la parole arabe. Nous nous attarderons sur la transcription graphème phonème, étape primordiale pour l’élaboration d’un système de synthèse d’une qualité acceptable. Nous présenterons ensuite quelques-unes des règles utilisées pour la réalisation de notre système de traitement phonétique. Ces règles sont, pour notre système, stockées dans une base de données et sont parcourues plusieurs fois lors de la transcription.},
  abstract  = {Our paper presents the components which are necessary for the arabic speech synthesis. We will dwell on the transcription graphème phoneme, a primordial stage for the development of a synthesis system with an acceptable quality. Then, we will present some of the rules used for the realization of our phonetic treatment system. These rules are, for our system, stocked in a data base and are browsed several times during the transcription.},
  motscles  = {Transcription graphème-phonème, langue arabe, règles de transcription},
  keywords  = {Grapheme-phoneme transcription, Arabic language, transcription rules},
}

@inproceedings{sonnenhauser:2004:RECITAL,
  author    = {Sonnenhauser, Barbara},
  title     = {},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-013},
  language  = {french},
  note      = {Towards a rule-guided derivation of aspectual readings in Russian},
  resume    = {Les significations des expressions dans les langues naturelles sont souvent indéterminées (sous-spécifiées) et nécessitent d’être enrichies avant de devenir des propositions complètes. La sémantique générale des expressions linguistiques doit être complétée par les inférences pragmatiques, identifiées et captées d’une manière régulière et permettant ainsi un traitement opérationnel et même informatique. Cet article étudie l’indétermination de l’aspect imperfectif en russe et propose un cadre sémantique et pragmatique pour l’identification de ses différentes valeurs sémantiques à la base de règles.},
  abstract  = {Natural language expressions are underspecified and require enrichment to develop into full fledged propositions. Their sense-general semantics must be complemented with pragmatic inferences that have to be systematically figured out and pinned down in a principled way, so as to make them suitable inputs for NLP algorithms. This paper deals with the underspecified ipf1 aspect in Russian and introduces a semantic and pragmatic framework that might serve as the basis for a rule-guided derivation of its different readings.},
  motscles  = {Indétermination, aspect, interprétation, sémantique, pragmatique},
  keywords  = {Underspecification, aspect, interpretation, semantics, pragmatics},
}

@inproceedings{teeraparbseree:2004:RECITAL,
  author    = {Teeraparbseree, Aree},
  title     = {Un système adaptable pour l’initialisation automatique d’une base lexicale interlingue par acceptions},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-014},
  language  = {french},
  resume    = {Cet article présente une stratégie de construction semi-automatique d’une base lexicale interlingue par acception, à partir de ressources existantes, qui utilise en synergie des techniques existantes de désambiguïsation. Les apports et limitations de chaque technique sont présentés. Notre proposition est de pouvoir composer arbitrairement des techniques, en fonction des ressources disponibles, afin d’obtenir une base interlingue de la qualité souhaitée. Jeminie, un système adaptable qui met en oeuvre cette stratégie, est introduit dans cet article.},
  abstract  = {This article presents a strategy for the semi-automatic building of an interlingual lexical database, based on existing resources, and using existing disambiguisation techniques in synergy. The pros and cons of each technique are given. Our proposal is to be able to compose techniques arbitrarily, according to the available resources, in order to produce an interlingual database of the desired quality. Jeminie, an adaptable system that implements this strategy, is introduced in this article.},
  motscles  = {base lexicale multilingue, construction automatique de lexies et axies, acception interlingue},
  keywords  = {multilingual lexical database, automatic building of lexies and axies, interlingual acception},
}

@inproceedings{vanrullen:2004:RECITAL,
  author    = {VanRullen, Tristan},
  title     = {Analyse syntaxique et granularité variable},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-015},
  language  = {french},
  resume    = {Il est souhaitable qu’une analyse syntaxique -en traitement automatique des langues naturellessoit réalisée avec plus ou moins de précision en fonction du contexte, c’est-à-dire que sa granularité soit réglable. Afin d’atteindre cet objectif, nous présentons ici des études préliminaires permettant d’appréhender les contextes technique et scientifique qui soulèvent ce problème. Nous établissons un cadre pour les développements à réaliser. Plusieurs types de granularité sont définis. Puis nous décrivons une technique basée sur la densité de satisfaction, développée dans ce cadre avec des algorithmes basés sur un formalisme de satisfaction de contraintes (celui des Grammaires de Propriétés) ayant l’avantage de permettre l’utilisation des mêmes ressources linguistiques avec un degré de précision réglable. Enfin, nous envisageons les développements ultérieurs pour une analyse syntaxique à granularité variable.},
  abstract  = {It is gainful for a syntactic analysis - in Natural Language Processing- to be carried out with more or less accuracy depending on the context, i.e. its granularity should be adjustable. In order to reach this objective, we present here preliminary studies allowing, first of all, to understand the technical and scientific contexts which raise this problem. We establish a framework within which developments can be carried out. Several kinds of variable granularity are defined. We then describe a technic developed within this framework using satisfaction density, on algorithms based on a constraints satisfaction formalism (Property Grammars) and allowing the use of the same linguistic resources with an adjustable degree of accuracy. Lastly, we further consider developments towards a syntactic analysis with variable granularity.},
  motscles  = {Analyse syntaxique, granularité variable, grammaire de propriétés, shallow parsing, deep parsing, densité de satisfaction},
  keywords  = {Parsing, variable granularity, property grammars, shallow parsing, deep parsing, satisfaction density},
}

@inproceedings{votrung:2004:RECITAL,
  author    = {Vo Trung, Hung},
  title     = {Réutilisation de traducteurs gratuits pour développer des systèmes multilingues},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-016},
  language  = {french},
  resume    = {Nous présentons ici une méthode de réutilisation de systèmes de traduction automatique gratuits en ligne pour développer des applications multilingues et évaluer ces mêmes systèmes. Nous avons développé un outil de traitement et de traduction de documents hétérogènes (multilingues et multicodage). Cet outil permet d'identifier la langue et le codage du texte, de segmenter un texte hétérogène en zones homogènes, d'appeler un traducteur correspondant avec une paire de langue source et cible, et de récupérer les résultats traduits dans la langue souhaitée. Cet outil est utilisable dans plusieurs applications différentes comme la recherche multilingue, la traduction des courriers électroniques, la construction de sites web multilingues, etc.},
  abstract  = {We present here a method of the reuse of the free on line automatic translation systems to develop multilingual applications and to evaluate translators. We developed a tool for treatment and translation of the heterogeneous documents (multilingual and multicoding). This tool makes it possible to identify the language and the coding of the text, to segment a heterogeneous text in homogeneous zones, to call a translator corresponding with a fair of languages and to recover the results translated into desired language. We can use this tool in several different applications as multilingual research, the translation of the e-mail, the construction of the multilingual Web, etc.},
  motscles  = {Traduction Automatique, Traducteur Multilingue, Multilinguisme, Document Multilingue},
  keywords  = {Machine Translation, Multilingual Translator, Multilingualism, Multilingual Document},
}

@inproceedings{weissenbacher:2004:RECITAL,
  author    = {Weissenbacher, Davy},
  title     = {La relation de synonymie en génomique},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-017},
  language  = {french},
  resume    = {L’accès au contenu des textes de génomique est aujourd’hui un enjeu important. Cela suppose au départ d’identifier les noms d’entités biologiques comme les gènes ou les protéines. Se pose alors la question de la variation de ces noms. Cette question revêt une importance particulière en génomique où les noms de gènes sont soumis à de nombreuses variations, notamment la synonymie. A partir d’une étude de corpus montrant que la synonymie est une relation stable et linguistiquement marquée, cet article propose une modélisation de la synonymie et une méthode d’extraction spécifiquement adaptée à cette relation. Au vu de nos premières expériences, cette méthode semble plus prometteuse que les approches génériques utilisées pour l’extraction de cette relation.},
  abstract  = {The access to textual content in genomics is now recognized as an important issue. One of the first steps is the recognition of biological entity names such as gene or protein names. It has often been observed that entity names may vary in texts but this phenomenon is especially common in genomics. Besides a gene canonical name, one can find various abbreviation forms, typographic variants and synonyms. Stemming in a corpus analysis, this paper argues that synonymy in genomic texts is a stable and linguistically marked relation. This paper presents a method for extracting couples of synonymous gene or protein names. From a preliminary experiment, this method seems more promising than generic approaches that are exploited to extract synonymy relations.},
  motscles  = {Extraction d’information, synonymie, entités nommées, génomique},
  keywords  = {Information extraction, synonymy, named entities, genomics},
}

@inproceedings{widlocher:2004:RECITAL,
  author    = {Widlöcher, Antoine},
  title     = {Analyse macro-sémantique: vers une analyse rhétorique du discours},
  booktitle = {Actes des 6e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
  month     = {April},
  year      = {2004},
  address   = {Fès, Maroc},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/RECITAL/RECITAL-2004/recital-2004-poster-018},
  language  = {french},
  resume    = {S’inscrivant dans les domaines du TAL, de la linguistique sur corpus et de l’informatique documentaire, l’étude présentée ici opère plus précisément dans la perspective d’une analyse macrosémantique de la structuration discursive. Plus spécifiquement, nous proposons une analyse sémantique des structures rhétoriques du discours. Après avoir envisagé certaines voies ouvertes en la matière, nous définissons notre approche, et présentons les expérimentations conduites, dans le cadre du projet GeoSem, sur les structures énumératives dans le domaine géographique.},
  abstract  = {Within the frameworks of automatic NLP, corpus linguistics, and automatic document processing, this study aims more precisely at a macro-semantic examination of the discursive structuring. Specifically, a semantic study of the rhetorical structures of discourse is here suggested. After considering existing approaches, we present our own methodology, and relate experimentations, as part of the GeoSem project, on enumerative structures in geographical corpus.},
  motscles  = {Macro-sémantique, analyse rhétorique, structure du discours, extraction d’information},
  keywords  = {Macro-semantics, rhetorical analysis, discourse structuring, information retrieval},
}