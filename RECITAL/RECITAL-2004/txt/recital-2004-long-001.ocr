RECITAL 2004, Fés, 21 av11'1 2004

Systeme de Question Réponse :
apport de l’analyse syntaxique lors de l’extraction de la
réponse

Anne-Laure Ligozat
LIMSI-CNRS - Université Paris Sud Orsay
BP 133, 91403 Orsay
annlor@limsi.fr
date de soutenance prévue : 2006

Résumé - Abstract

Dans cet article, nous présentons le systeme de Question Réponse QALC, et nous nous interes-
sons tout particulierement a l’extraction de la réponse. Un appariement question-réponse fondé
sur les relations syntaxiques a été développé, aﬁn d’améliorer les performances du systeme. Un
proj et de génération de réponses a partir de plusieurs documents est également discuté.

In this paper, we present the question answering system QALC, and we particularly focus on
the answer extraction. A question and answer matching based on syntactic relations has been
developed, in order to improve the results of our system. A project aiming at fusing answers
from several documents is also discussed.

Mots-clefs — Keywords

Systeme de Question Réponse, analyse syntaxique, fusion de documents
Question answering system, syntactic analysis, document fusion

Anne-Laure Li gozat

1 Fonctionnement d’un systeme de Question Réponse

Développés pour répondre aux besoins croissants de recherche d’information dans des corpus
toujours plus foumis tels que le Web, les systemes de Question Réponse correspondent a une
double problématique : permettre a l’utilisateur recherchant une information précise de poser
sa question en langage naturel, et extraire la réponse a cette question d’un grand nombre de
documents également en langage naturel.

La majorité des systemes de question-réponse fonctionnent de la facon suivante :

o la question en langage naturel est analysée, aﬁn d’en extraire les mots-clefs qui vont per-
mettre de soumettre une requéte a un moteur de recherche traditionnel, ainsi que d’autres
informations qui seront utiles par la suite ;

o la requéte retourne un certain nombre de documents, dont les phrases, appelées candi-
dates, sont susceptibles de contenir la réponse a la question posée. Ces phrases sont
ensuite classées en fonction de criteres d’adéquation a la question ;

o enﬁn, a partir des informations de la question, les réponses possibles sont extraites des
phrases candidates et celle qui présente la plus forte pertinence est retoumée ;

Le groupe LIR (Langues, Information, Representations) a développé un systeme de Question
Réponse en anglais, appelé QALC1, qui a participé aux campagnes d’évaluation intemationales
TREC2 ces demieres années, arrivant 9eme sur 34 en 2002 ; sa version francaise participera a
l’évaluation du programme EVALDA-Equer3 en 2004.

Le fonctionnement de QALC, a l’image des autres systemes, peut étre décomposé en plusieurs
étapes : analyse de la question, sélection de documents pertinents et reconnaissance des entités
nommées4, et enﬁn extraction de la réponse (Ferret et al., 2003). L’architecture globale du
systeme QALC est présentée dans la ﬁgure 1.

La stratégie d’extraction de la réponse, qui nous intéresse plus particulierement ici, dépend du
type de la question :

o si la question attend une entité nommée d’un certain type, la réponse sera l’entité nommée
du type attendu la plus proche des mots de la question ;

o sinon, des patrons linguistiques, sémantiques ou syntaxiques, seront appliqués aux phrases
candidates.
Si l’on a pu déterminer des contraintes sémantiques sur la réponse, des patrons séman-
tiques seront utilisés (Dalmas, 2002). Par exemple pour la question “Name a stimulant.”,
la réponse doit étre un hyponyme5 de “stimulant”. On Va donc rechercher une réponse
qui vériﬁe cette contrainte, et qui de plus soit liée par exemple par “such as” a “stimu-
lant”, ce qui permettra de valider une réponse comme “Stimulants such as Ritalin”. Les
contraintes sémantiques sont vériﬁées dans la base de données WordNet6 ;

1Question Answering program of the Language and Cognition group at LIMSI-CNRS
2Text REtrieVal Conference, http://trec.nist.goV/. Pour une presentation de TREC 2002, Voir (Voorhees, 2002)
3Evaluation lancée par le Ministere de la Recherche, dans le cadre de l’Action Technolangue,
http://www.recherche.gouv.fr/appel/2002/technolangue.ht1n
4Expression qui, dans un contexte particulier, identiﬁe de fagon unique une entité telle qu’une personne, un
lieu, une organisation, une date; les noms propres correspondent a une sous—classe importante d’entités nommées.
5La réponse doit avoir une relation de type “est un” avec “stimulant”
Ghttp://www.cogsci.princeton.edu/ wn/. Voir aussi (Fellbaum, 1998)

Systéme de Question Réponse :
apportde1’ana1yse syntaxique lors de 1’eXtraction de la réponse

Quesﬁon\ CVOTPUS
Traitement des 'M0tem. de
questions recherche

Catégories des

. Termes Documents
questions, Focus, candidats retoumes
Type de la réponse * $

Traitement des documents:

Ré—indexation et selection
des documents (Fastr)

Documents classes

Reconnaissance
des entités nommées

Phrases étiquetées

V 1

Recherche de la réponse: — reconnaissance du focus
— appariement question/phrase
— extraction de la réponse

Sequences ordonnées de 50 caracteres

Figure 1: Architecture du systeme QALC

o si aucune contrainte sémantique n’a été déterminée, des patrons syntaxiques permettront
d’apparier les phrases réponses et la question. Ces patrons sont fondés sur l’idée intuitive
que les phrases réponses correspondent a des structures syntaxiques précises, la plus sim-
ple étant la reformulation a l’afﬁrmative de la question. Une étude manuelle de corpus a
permis de dégager des structures syntaxiques typiques pour chaque catégorie de question,
qui ont été formalisées sous forme de patrons.

La ﬁgure 2 présente des exemples de chaque stratégie. Les performances du systeme QALC
dépendent bien entendu du type de la question, et donc de la stratégie Inise en oeuvre. Le
pourcentage de bonnes réponses retournées par QALC est ainsi de 29% lorsque la question
attend une entité nommée, et de 20% pour les autres questions. Mais ces résultats dépendent
également des phrases réponses disponibles dans le corpus. En effet, selon la forme de la phrase
réponse, les stratégies de QALC seront plus ou moins adaptées.

Nous détaillerons dans la suite de cet article des problemes qui peuvent se poser lors de l’extrac-
tion de la réponse, et montrerons qu’une analyse syntaxique des phrases candidates peut en
résoudre certains. Puis nous donnerons les principes du module que nous avons développé, qui
procede a un appariement syntaxique question-réponse, et commenterons ses possibilités et ses
limites. Enﬁn, nous présenterons une perspective un peu plus large d’utilisation de l’analyse
syntaxique des phrases, qui est la construction de réponses a partir de plusieurs documents.

Anne-Laure Li gozat

Entite nommee: What Ear was Alaska purchased ? (10.1398)
type EN = date
by 1867, when Secretary of State William H. Seward negociated

the purchase of Alaska from the Russians, 

Patron semantique: Which political party is Lionel J ospin a member of ‘.7 (10.1408)
type semantique
the ﬁrst secretary of the French Socialist Party Lionel J ospin

Patron syntaxique: What does Knight Ridder publish ‘.7 (9.671)
What do GN VB

Knight Ridder published 30 daily newspapers 
GNfocus VB GNreponse

Figure 2: Exemples de chacune des strategies
2 Analyse syntaxique des phrases candidates

Dans certains cas, la structure des phrases candidates peut entrainer l’eXtraction d’une mauvaise
reponse par QALC. Pour la question “Who killed Lee Harvey Oswald ?”, une phrase candidate
contenant la reponse est “Jack Ruby, who killed J .F. Kennedy assassin Lee Harvey Oswald”
(Hovy et al., 2001). La selection de l’entite nommee la plus proche de l’objet de la question
“Lee Harvey Oswald” retourne comme reponse “J .F. Kennedy” au lieu de “Jack Ruby”.

L’ analyse de la question nous donne des indices sur la fonction syntaxique de la reponse at-
tendue, qui peuvent étre utilises pour retoumer la bonne reponse : d’apres la question, l’entite
nommee attendue doit étre agent du verbe “kill”; l’analyse de la phrase reponse montrerait que
cet agent est bien “Jack Ruby” (Monceaux et al., 2002). Des connaissances syntaxiques sur la
fonction attendue de la reponse peuvent ainsi ameliorer l’eXtraction de la reponse dans QALC,
et nous nous sommes donc interesses aux possibilites d’utilisation de ce type de connaissances.

2.1 Amélioration de la sélection des entités nommées

Dans le cas d’une question attendant une entite nommee, l’entite nommee la plus proche des
mots de la question ne correspond pas toujours a la reponse, comme le montre l’exemple prece-
dent (“Who killed Lee Harvey Oswald ?”). Des connaissances semantiques ne pourront pas
non plus permettre de rejeter la mauvaise reponse, car d’une part les noms propres sont peu
presents dans les bases de donnees semantiques, et d’autre part lorsqu’ils le sont, ils ont sou-
vent les memes caracteristiques semantiques (a l’exception de leurs deﬁnitions (gloses) mais
cette information est difﬁcile a traiter). Seule une analyse syntaxique des relations de la phrase
permettra donc de montrer que “Jack Ruby” est la bonne reponse, puisqu’il est sujet du verbe
“kill”.

2.2 Un outil plus puissant que les patrons linguistiques

Les patrons linguistiques presentent egalement des failles car ils ne tiennent compte que de
l’objet de la question et de connecteurs sans tenir compte de leur environnement, ce qui peut
induire en erreur. Une expression telle que “a person has a seizure disorder or epilepsy if...”

Systeme de Question Réponse :
apportde1’ana1yse syntaxique lors de 1’eXtraction de la réponse

répond bien a la question “What is epilepsy ?”, car elle correspond au patron “GN or epilepsy”,
qui permet de repérer une déﬁnition de l’épilepsie. Mais ce méme patron ne permettra pas
de rejeter la phrase “Delirium tremens or epilepsy imply serious behavioral disorders” comme
une réponse possible. Un patron sémantique ne po11rra probablement pas non plus discrim-
imer les deux possibilités de réponse “seizure disorder” et “delirium tremens” car aucune des
deux n’est directement reliée a “epilepsy” dans WordNet. Une analyse syntaxique ﬁne pourrait
en revanche, en tenant compte du pluriel du verbe “imply”, montrer que le patron syntaxique
ne peut s’appliquer dans le second cas, et que seule la premiere réponse doit étre retoumée.
D’autres inconvénients rendent par ailleurs délicate l’utilisation de patrons linguistiques : ceux-
ci sont doivent en effet connsidérer le plus de constructions possibles, ce qui rend leur nombre
important, leur construction fastidieuse et leur couverture nécessairement incomplete.

2.3 Quels outils pour l’analyse syntaxique des phrases candidates ?

QALC effectue une analyse ﬁne des questions grace a un analyseur syntaxique, qui fournit en
particulier le type de la question, son objet (au sens du “focus” déﬁni par (Lehnert, 1978)),
le type attendu de la réponse, entité nommée ou type sémantique général, et les relations de
dépendance de la question. Cette analyse est rendue possible notamment par la forme syntax-
ique relativement ﬁgée des questions. En revanche, les phrases candidates sont analysées par
un étiqueteur morpho-syntaxique, qui ne retourne qu’une analyse partielle de ces phrases. Aﬁn
d’améliorer nos connaissances sur ces phrases, un analyseur syntaxique po11rra également étre
utilisé, qui nous fournira, en plus de l’étiquetage morphologique des phrases, les fonctions syn-
taxiques de leurs éléments. Nous avons choisi d’utiliser pour le systeme QALC, l’analyseur
syntaxique pour le francais XIP7 de Xerox, dont une description détaillée po11rra étre trouvée
dans (A'1't-Mokthar et al., 2002).

2.4 Evaluation préliminaire des apports de l’analyse syntaxique

Les quelques exemples ci-dessus prouvent que l’analyse syntaxique résoudrait certaines difﬁ-
cultés du systeme actuel, mais il convient de se demander si ces exemples sont marginaux ou
non. Nous avons donc mené une étude manuelle sur les réponses de QALC a 106 questions
de l’évaluation TREC-11, choisies aléatoirement, pour tester si une analyse syntaxique sup-
posée exacte pourrait améliorer le score de QALC. Et ce de deux facons : soit en conﬁrmant les
bonnes réponses, soit en rejetant les mauvaises. Les résultats de notre travail sont résumés dans
la table 1.

Nombre de questions Bonnes réponses conﬁrrnées Mauvaises réponses rejetées Réponses justes rejetées

106 45% 12,5% 5%

Table 1: Résultats de l’utilisation d’une analyse syntaxique sans erreur

Les différentes colonnes doivent étre interprétées ainsi : l’étude a été menée sur 106 questions
du corpus TREC-11 et sur la phrase candidate retournée comme réponse par QALC ; une anal-
yse syntaxique aurait conﬁrmé 45% des réponses justes que QALC avait retourné et rejeté 5%

7Xerox Incremental Parsing

Anne-Laure Li gozat

de ces réponses. Pour les 50% restant, la possibilité de conﬁrmer la bonne réponse dépend de la
ﬁnesse de l’analyseur syntaxique, et des reformulations prises en compte. Parmi les questions
pour lesquelles QALC avait donné une mauvaise réponse, plus de 12% auraient été rejetées par
une analyse syntaxique. En conclusion, on remarque qu’un pourcentage important des réponses
fausses aurait été rejetées avec une analyse syntaxique, et que pres de la moitié des bonnes
réponses auraient été conﬁrmées, ce qui est un point tres positif pour la ﬁabilité du systeme.
Intégrer une analyse syntaxique représente donc un avantage important.

Il est a noter que les informations utilisées pour cette évaluation sont celles que donne un analy-
seur syntaxique, en supposant qu’il ne fait aucune erreur. Meme s’il n’est donc pas irréaliste de
s’attendre a ces résultats, les informations foumies par un analyseur réel comprennent souvent
des erreurs, et on peut donc s’attendre a des performances moins élevées que celles prévues par
cette étude.

Cette évaluation nous a également permis de dégager les relations qui perrnettent, le plus sou-
vent, de rejeter une mauvaise réponse ou de conﬁrmer une bonne. Il conviendra donc de
s’intéresser d’une part aux relations sur l’objet de la question, et d’autre part sur la fonction
syntaxique de la réponse. Partant de ces conclusions, nous avons développé un prototype
d’ appariement question-réponse.

2.5 Appariement syntaxique question-réponse

L’ appariement que nous avons construit consiste a déterminer les relations de dépendance de
la question, en particulier celles qui concernent l’objet de la question et le mot interrogatif,
puis a rechercher les mémes relations dans les phrases candidates (phrase I) ou des relations
équivalentes (phrases 2 et 3).

Le schéma suivant expose un exemple d’appariement :

. V
Questiom Who is the evil H. R. Director in Dilbert ?

Lnjt

sujet attribut

— 3 """"""""""""""" '1
Phrase 1 Catbert is the evil H. R. Director in Dilbert.

Llljl

_ sujet attribut
Réponses posslblesz Phrase 2 The evil H. R. Director is Catbert.

sujet attribut

Phrase 3 Catbert, the evil H. R. Director in Dilbert...

apposition

Figure 3: Principe de l’appariement syntaxique

Sera donc privilégié comme réponse, le groupe nominal possédant la fonction syntaxique voulue,
dans une phrase ou l’objet de la question a, autant que possible, les attributs attendus. Cette ap-
proche reprend en partie la stratégie des patrons syntaxiques, mais d’une part, elle peut facile-
ment améliorer les autres traitements (la recherche d’entités nommées et l’utilisation de patrons

Systéme de Question Réponse :
apportde1’ana1yse syntaxique lors de 1’eXtraction de la réponse

sémantiques), et d’autre part, elle est plus ﬁne que des patrons.

Un module effectuant cet appariement a été développé et sera testé sur un corpus francais des
que notre systeme aura été adapté a cette langue, sur un corpus de test construit par le groupe
LIR du LIMSI. Néanmoins, on peut s’attendre a ce que ce module fasse preuve d’une précision
relativement forte, mais d’un rappel faible. En effet, lorsque les relations syntaxiques de la
phrase candidate sont trop éloignées de celles qui sont attendues, le module ne renvoie pas de
réponse. Du fait des nombreuses variations contenues dans les phrases candidates, ce cas de
ﬁgure devrait se produire fréquemment.

2.6 Améliorations possibles

Aﬁn de pallier les difﬁcultés relevées précédemment, il est tout d’abord nécessaire de pouvoir
recourir aux stratégies actuelles si ce module échoue a foumir une réponse. Aﬁn d’améliorer les
performances de notre module, on po11rra également tenter de prendre en compte les variations
sémantiques. Plusieurs pistes peuvent étre envisagées, selon le degré de variation entre les
formulations de la question et des phrases réponses.

La variation peut se situer au niveau du mot, comme dans l’exemple “- What was the name of
the dog in the Thin Man movies ? - in The Thin Man, Asta, the wire haired terrier...”. Dans
ce cas, il peut étre intéressant d’utiliser un dictionnaire des synonymes, qui po11rra nous foumir
une relation entre “wire haired terrier” et “dog”, ou une base de données comme WordNet ou
EuroWordNet8, qui nous donnera une relation d’hyponyInie entre ces deux termes.

Si la variation met en jeu une reformulation de la phrase, des patrons de reformulation pourront
étre utilisés dans certains cas, permettant par exemple de passer d’une question du type “Who
invented...” a une phrase contenant “the inventor of...”. Un outil comme Fastr9, déja utilisé
lors de la construction de la requéte pour le moteur de recherche, pourrait engendrer ces refor-
mulations. Dans d’autres cas cependant, il est difﬁcile de trouver le lien sémantique entre les
formulations de la question et de la réponse (“- What school did Emmitt Smith go to ? - Emmitt
Smith, then a freshman at Escambia High School”) et de plus, la relation entre l’objet de la
question et la réponse n’est pas toujours explicite (“- What is the chemical formula for sulphur
dioxide? - Sulphur dioxyde (SO2)”).

Enﬁn, l’ extraction de la réponse peut nécessiter la Ir1ise en oeuvre de raisonnements complemen-
taires, par exemple dans les taches “List” ou “Context” de TREC, pour lesquelles la réponse
attendue est une liste (“Name 7 brand names of Belgian chocolates.”) ou les questions posées
simulent un dialogue (“- How many species of spiders are there ? How many are poisonous to
humans ? What percentage of spider bites in the US are fatal ?”). Si les scores des meilleurs sys-
temes a TREC sont tres élevés (83% de bonnes réponses pour LCC a TREC 2002), les questions
posées contiennent en grande majorité des questions factuelles : la distribution des questions
TREC entre 1999 et 2001 est présentée dans la table 2 (Moldovan et al., 2003).

Plus de 95% des questions TREC sont donc des questions factuelles ou nécessitant un raison-
nement simple, ce qui est loin d’étre représentatif des besoins réels en recherche d’information.
De nombreuses problématiques demeurent. Certaines font l’objet de nouvelles taches aux con-
férences TREC ; d’autres pourront étre abordées par d’autres évaluations comme EVALDA-

shttp://www.illc.uva.nl/EuroWordNet/
9Analyseur transformationnel de surface qui reconnait les occurrences et les variantes des termes en entree
(Jacquemin et al., 1997)

Anne-Laure Li gozat

Type Nombre(%)

Factuel 985 (67.5%)

Raisonnement simple 408 (27.9%)
Liste 25 (1.7%)
Contextuel 42 (2.9%)
Speculatif 0 (0.0%)

Table 2: Distribution des questions TREC

Equer.

3 Vers des inferences en contexte large

3.1 Des réponses réparties dans plusieurs documents

Bien qu’une reponse courte issue d’un document unique soit exigee dans les conferences TREC,
une reponse plus adequate pourrait souvent etre donnee par regroupement d’informations dis-
persees dans plusieurs passages d’un texte. En effet, pour certaines questions, les elements de
reponse apparaissent a plusieurs endroits du texte, avec des references contextuelles differentes
mais compatibles. Ainsi, pour la question “Quel coureur espagnol a gagne une etape du Tour de
France en 2002 ?”, les informations sur les resultats de l’epreuve et celles sur les nationalites des
coureurs peuvent appartenir a des passages differents du corpus. I1 faudra donc pouvoir relier
ces informations qui partageront un meme contexte thematique (le Tour de France) et temporel
(en 2002). Les questions de deﬁnition (“What is epilepsy ?”) pourraient egalement beneﬁcier
d’un procede perrnettant de regrouper differents elements de reponse.

Cette possibilite de trouver la reponse a partir de textes differents pourrait egalement etre mise
a proﬁt pour ameliorer la ﬁabilite des reponses. Ainsi, pour la question “Quel compositeur a
donne un concert devant la tour Eiffel le 14 Juillet 1995 ?”, dont une phrase reponse est “Le
serveur du ministere de la culture vient d’ouvrir, sur Internet, un site consacre au concert donne
par J ean-Michel J arre devant la tour Eiffel, le 14 juillet.”, certains elements de la question ne
sont pas presents dans la phrase reponse, puisqu’il n’y est par exemple pas precise que Jean-
Michel J arre est compositeur. L’ information manquante pourrait etre cherchee dans une autre
partie du corpus, ou dans un autre corpus comme le Web, aﬁn de pouvoir accorder un score de

conﬁance plus important a cette reponse“).

3.2 La fusion d’informations : au caeur des problématiques de Question
Réponse

L’ obj ectif est donc d’ arriver a constituer des elements de connaissance coherents a partir d’infor-
mations dispersees dans plusieurs passages. Cette problematique est l’un des principaux deﬁs
pour le domaine de Question Reponse dans les prochaines annees, selon le roadmap des con-

1°Cette information pourrait eventuellement étre recherchee dans une base de donnees de noms propres, mais
ne pourra étre trouvee dans WordNet, qui ne recense qu’un nombre limite de noms propres.

Systeme de Question Réponse :
apportde1’ana1yse syntaxique lors de 1’eXtraction de la réponse

férences TREC (Burger et al., 2001). La classiﬁcation des systemes de Question Réponse selon
leurs capacités (Moldovan et al., 2003), utilisée précédemment, révele également l’importance
de pouvoir traiter ce type de probleme. Cette taxonomie se présente les cinq classes de sys-
temes suivantes : systemes capables de traiter des questions factuelles, systemes mettant en oeu-
vre des mécanismes de raisonnement simple, permettant par exemple de répondre a la question
“How did Socrates die ?” par la phrase réponse “drinking poisoned wine”, systemes capables
d’extraire la réponse a partir de plusieurs documents, les questions pouvant attendre par ex-
emple une liste comme réponse (“Name 20 countries that produce coffee.”) ou bien une suite
d’instructions (“How do I assemble a bicycle ?”), systemes interactifs, pouvant répondre a des
questions qui se suivent (“How long was the Varyag ?”; “How wide ?”), systemes a capacité
spéculative (“Is the US out of recession ?”).

La fusion d’informations provenant de plusieurs documents serait a ranger dans la classe 3, bien
que le point de vue adopté ici soit un peu différent. En effet, le recours a plusieurs documents
n’est considéré par (Moldovan et al., 2003) que pour construire une réponse complexe, alors
que nous l’envisageons également pour déterminer ou justiﬁer la réponse.

3.3 Les différents niveaux de raisonnement nécessaires

La Inise en oeuvre de la fusion d’informations peut se révéler complexe, car si dans certains cas
elle nécessite peu de raisonnements, il faudra dans d’autres cas utiliser des processus inférentiels
complexes pour mettre en relation les différentes connaissances utiles.

Ainsi, dans les exemples cités plus haut (“Quel coureur espagnol a gagné une étape du Tour de
France en 2002 ?” et “Quel compositeur a donné un concert devant la tour Eiffel le 14 Juillet
1995 ?”), les éléments de réponse sont directement présents dans le corpus. On peut en re-
vanche envisager que la construction de la réponse fasse appel a des connaissances sémantiques
plus poussées : pour la question “How many casualties were reported last week in Fredonia?”
associée aux phrases réponses “Last Monday two people were killed on the streets of Beau-
tiville, Fredonia, after a bomb exploded” et “The terrorists murdered a family with a small child
in Fredonia last Friday, near its border with Evilonia.” (Burger et al., 2001), i1 faudra deter-
miner que “casualties” regroupe les événements évoqués par les termes “kill” et “murder”. Les
mécanismes nécessaires peuvent également faire appel a un raisonnement de type causal : la
réponse a la question “Why there were hacker attacks on the computers at University of Cali-
fornia, Santa Barbara?” nécessite de relier les informations présentes dans les phrases réponses
“U.S. Colleges have powerful computing facilities” et “Computer hackers need speedy proces-
sors to break security passwords” et donc d’effectuer un raisonnement causal. Les ressources
a mettre en oeuvre peuvent donc étre de natures tres diverses, selon les informations apportées
par le corpus.

Nous nous proposons d’étudier les cas ou des connaissances sémantiques devraient permettre
de répondre aux questions. L’objectif est de déduire de la question les relations a rechercher
dans le corpus, et de trouver ensuite des textes les contenant, avant de relier ces connaissances.
La reconnaissance de contextes thématiques ou temporels permettra de relier les connaissances
partageant un méme contexte. Nous parlerons dans ces conditions de chaine d’inférences valide.

La construction de telles chaines se fera a partir d’ontologies générales et de relations issues du
texte, aﬁn de ne pas dépendre d’une base de connaissances, forcément incomplete.

Anne-Laure Li gozat

4 Conclusion

Aﬁn de répondre aux failles de notre systeme de Question Réponse, nous avons développé un
module d’appariement question-réponse s’appuyant sur les relations syntaxiques données par
un analyseur. Ce module sera intégré a QALC, aﬁn de valider notre modele d’appariement et
d’étudier son impact sur les performances de notre systeme. La representation syntaxique des
phrases élaborée dans ce cadre servira ensuite de base pour fusionner des informations lorsque
plusieurs textes sont nécessaires a l’extraction de la réponse.

Références

A'1’t-Mokthar S., Chanod J ., Roux C. (2002), Robustness beyond shallowness 2 incremental deep parsing,
Journal of Natural Language Engineering, Vol. 8, No. 3-2.

Burger J ., Cardie C., Chaudhri V., Gaizauskas R., Harabagiu S., Israel D., Jacquemin C., Lin C.-Y.,
Maiorano S., Miller G., Moldovan D., Ogden B., Prager J., Riloff E., Singhal A., Shrihari R., Strza-
lkowski T., Voorhees E., Weishedel R. (2001), Issues, Tasks and Program Structures to Roadmap Re-
search in Question & Answering (Q&A), National Institute of Standards and Technology, http://www-
n1pir.nist.gov/projects/duc/papers/qa.Roadmap-paper_v2.doc

Dalmas T. (2002), Selection et validation de la réponse dans les systemes de question-réponse, un sys-
teme a base de contraintes sémantiques, Rapport de DESS, LIMSI-CNRS.

Fellbaum C. (1998), WordNet : An Electronic Lexical Database, Cambridge, Massachussetts, The MIT
Press.

Ferret 0., Grau B., Hurault-Plantet M., Illouz G., Jacquemin C., Monceaux L., Robba I., Vilnat A.
(2003), How a NLP approach beneﬁts question answering, Knowledge Organization joumal, A Special
Issue on Evaluation of HLT, Guest Editor 2 Widad Mustafa E1 Hadi, Vol. 29, 3-4.

Hovy E., Hermjakob U., Lin C.-Y. (2001), The Use of External Knowledge in Factoid QA, TREC 10
Notebook.

Jacquemin C., Klavans J . L., Tzoukermarm E. (1997), Expansion of multi-word terms for indexing and
retrieval using morphology and syntax, Actes de ACL-EACL’97, 24-31.

Lehnert W. (1978), The process of question answering, Hillsdale, N.J., Lawrence Erlbaum Associates.

Moldovan D., Pasca M., Harabagiu S., Surdeanu M. (2003), Performance Issues and Error Analysis in
an Open-Domain Question Answering System, ACM Transactions on Information Systems, Vol. 21, No.
2, 133-154.

Monceaux L., Robba I. (2002), Les analyseurs syntaxiques 2 atouts pour une analyse des questions dans
un systéme de question-réponse ?, Actes de TALN2002, 195-204.

Voorhees E. (2002), Overview of the TREC 2002 Question Answering Task, TREC 2002.

