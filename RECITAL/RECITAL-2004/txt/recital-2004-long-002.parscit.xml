<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Abeillé</author>
<author>L Clément</author>
<author>F Toussenel</author>
</authors>
<title>Building a treebank for French, Abeillé A. Treebanks. Building and unising parsed corpora,</title>
<date>2003</date>
<pages>165--187</pages>
<contexts>
<context position="24848" citStr="Abeillé et al., 2003" startWordPosition="3835" endWordPosition="3838">NOM2, où les variantes syntaxiques peuvent être facilement appréhendées (l’adjectif épithète par exemple ne peut être séparé du nom qu’il modifie que par des adverbes ou d’autres adjectifs), les relations NOM – VERBE (sujet, objet) sont plus délicates à extraire puisque le nom-cible peut être séparé du verbe par des constituants syntaxiques hétérogènes (compléments circonstantielles, relatives par exemple) pouvant être de taille conséquente. De nombreuses relations Barrage (sujet) – VERBE extraites sont incorrectes. Les récents travaux sur l’analyse syntaxique partielle (shallow parsing) (cf. Abeillé et al., 2003), laissent penser que des progrès significatifs pourraient être fait sur l’extraction de ce type de relations. 6 Conclusion Nous avons essayé de montrer dans cet article qu’un pré-étiquetage des usages des mots par un algorithme tel qu’HyperLex (Véronis, 2003, 2004) permettait d’obtenir des relations lexicales (du type NOM-ADJECTIF, NOM de NOM, NOM-VERBE) beaucoup plus exploitables, parce qu’elles-mêmes catégorisées en fonction des usages. De plus, cette technique permet d’obtenir des relations pour des usages très peu fréquents, alors qu’une extraction indifférenciée « noierait » ces relation</context>
</contexts>
<marker>Abeillé, Clément, Toussenel, 2003</marker>
<rawString>Abeillé A., Clément L., Toussenel F. (2003), Building a treebank for French, Abeillé A. Treebanks. Building and unising parsed corpora, pp. 165-187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Benson</author>
</authors>
<title>Collocations and general-purpose dictionaries,</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>1</issue>
<pages>23--35</pages>
<contexts>
<context position="4368" citStr="Benson, 1990" startWordPosition="662" endWordPosition="663">d’en extraire par des moyens automatiques ou semi-automatiques au moins les relations lexicales les plus importantes et récurrentes. Cette recherche de relations lexicales a des points communs avec la recherche de termes complexes, pour lesquels il existe des méthodes et logiciels d’extraction tels que, pour le français, Acabit (Daille, 1994) et Lexter (Bourigault, 1994). Bien que les relations recherchées ici soient plus générales (toutes ne constituent pas des « termes ») et relèvent des « préférences » lexicales (Wilks, 1975), restrictions de sélection (Katz &amp; Fodor, 1964) ou collocations (Benson, 1990 ; Smadja, 1993 ; Cruse, 1986) générales de la langue, on peut toutefois s’inspirer des mêmes techniques, basées sur la recherche de patrons syntaxiques, comme nous le verrons ci-après. La littérature témoignant d’une terminologie disparate et de concepts souvent flous et contradictoires, nous employons ici le terme relation lexicale, plus neutre, défini comme une cooccurrence lexicale entre deux lexèmes liés syntaxiquement. Nous centrons le présent travail sur l’importance d’une catégorisation lexicale automatique des relations lexicales, le tri des relations lexicales extraites sera effectué</context>
</contexts>
<marker>Benson, 1990</marker>
<rawString>Benson M. (1990), Collocations and general-purpose dictionaries, International Journal of Lexicography, vol. 3(1), pp. 23-35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bourigault</author>
</authors>
<title>LEXTER, un Logiciel d&apos;EXtraction de TERminologie. Application a l&apos;acquisition des connaissances à partir de textes,</title>
<date>1994</date>
<booktitle>Ph.D. Thesis, Ecole des Hautes Etudes en Sciences Sociales,</booktitle>
<location>Paris.</location>
<contexts>
<context position="4129" citStr="Bourigault, 1994" startWordPosition="625" endWordPosition="626">e Explicatif et Combinatoire de (Mel’cuk et al.,1984, etc.), qui ne liste qu’une petite partie de ces relations, en est un bon exemple. Or, il semble que si l’on disposait d’une grande quantité de textes informatisés, il pourrait être possible d’en extraire par des moyens automatiques ou semi-automatiques au moins les relations lexicales les plus importantes et récurrentes. Cette recherche de relations lexicales a des points communs avec la recherche de termes complexes, pour lesquels il existe des méthodes et logiciels d’extraction tels que, pour le français, Acabit (Daille, 1994) et Lexter (Bourigault, 1994). Bien que les relations recherchées ici soient plus générales (toutes ne constituent pas des « termes ») et relèvent des « préférences » lexicales (Wilks, 1975), restrictions de sélection (Katz &amp; Fodor, 1964) ou collocations (Benson, 1990 ; Smadja, 1993 ; Cruse, 1986) générales de la langue, on peut toutefois s’inspirer des mêmes techniques, basées sur la recherche de patrons syntaxiques, comme nous le verrons ci-après. La littérature témoignant d’une terminologie disparate et de concepts souvent flous et contradictoires, nous employons ici le terme relation lexicale, plus neutre, défini comm</context>
</contexts>
<marker>Bourigault, 1994</marker>
<rawString>Bourigault D. (1994), LEXTER, un Logiciel d&apos;EXtraction de TERminologie. Application a l&apos;acquisition des connaissances à partir de textes, Ph.D. Thesis, Ecole des Hautes Etudes en Sciences Sociales, Paris.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D Bourigault</author>
<author>N Aussenac-Gilles</author>
<author>J Charlet</author>
</authors>
<title>(à paraître), Construction de ressources terminologiques ou ontologiques à partir de textes : un cadre unificateur pour trois études de cas,</title>
<date>1989</date>
<journal>Computational Linguistics,</journal>
<booktitle>Revue d’Intelligence Artificielle [En ligne : http://www.univlse2.fr/erss/membres/bourigault/]</booktitle>
<volume>16</volume>
<issue>1</issue>
<pages>76--83</pages>
<marker>Bourigault, Aussenac-Gilles, Charlet, 1989</marker>
<rawString>Bourigault D., Aussenac-Gilles N., Charlet J. (à paraître), Construction de ressources terminologiques ou ontologiques à partir de textes : un cadre unificateur pour trois études de cas, Revue d’Intelligence Artificielle [En ligne : http://www.univlse2.fr/erss/membres/bourigault/] Church K., Hanks P. (1989), Word association norms, mutual information, and lexicography, Computational Linguistics, Vol. 16(1), pp. 76-83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Cruse</author>
</authors>
<title>Lexical Semantics, Cambridge,</title>
<date>1986</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="4398" citStr="Cruse, 1986" startWordPosition="668" endWordPosition="669">utomatiques ou semi-automatiques au moins les relations lexicales les plus importantes et récurrentes. Cette recherche de relations lexicales a des points communs avec la recherche de termes complexes, pour lesquels il existe des méthodes et logiciels d’extraction tels que, pour le français, Acabit (Daille, 1994) et Lexter (Bourigault, 1994). Bien que les relations recherchées ici soient plus générales (toutes ne constituent pas des « termes ») et relèvent des « préférences » lexicales (Wilks, 1975), restrictions de sélection (Katz &amp; Fodor, 1964) ou collocations (Benson, 1990 ; Smadja, 1993 ; Cruse, 1986) générales de la langue, on peut toutefois s’inspirer des mêmes techniques, basées sur la recherche de patrons syntaxiques, comme nous le verrons ci-après. La littérature témoignant d’une terminologie disparate et de concepts souvent flous et contradictoires, nous employons ici le terme relation lexicale, plus neutre, défini comme une cooccurrence lexicale entre deux lexèmes liés syntaxiquement. Nous centrons le présent travail sur l’importance d’une catégorisation lexicale automatique des relations lexicales, le tri des relations lexicales extraites sera effectué plus tard. Une difficulté, lo</context>
</contexts>
<marker>Cruse, 1986</marker>
<rawString>Cruse D. A. (1986), Lexical Semantics, Cambridge, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Daille</author>
</authors>
<title>Approche mixte pour l&apos;extraction de terminologie: statistique lexicale et filtres linguistiques, Paris : Université de Paris VII.</title>
<date>1994</date>
<contexts>
<context position="4100" citStr="Daille, 1994" startWordPosition="621" endWordPosition="622">nstitution du Dictionnaire Explicatif et Combinatoire de (Mel’cuk et al.,1984, etc.), qui ne liste qu’une petite partie de ces relations, en est un bon exemple. Or, il semble que si l’on disposait d’une grande quantité de textes informatisés, il pourrait être possible d’en extraire par des moyens automatiques ou semi-automatiques au moins les relations lexicales les plus importantes et récurrentes. Cette recherche de relations lexicales a des points communs avec la recherche de termes complexes, pour lesquels il existe des méthodes et logiciels d’extraction tels que, pour le français, Acabit (Daille, 1994) et Lexter (Bourigault, 1994). Bien que les relations recherchées ici soient plus générales (toutes ne constituent pas des « termes ») et relèvent des « préférences » lexicales (Wilks, 1975), restrictions de sélection (Katz &amp; Fodor, 1964) ou collocations (Benson, 1990 ; Smadja, 1993 ; Cruse, 1986) générales de la langue, on peut toutefois s’inspirer des mêmes techniques, basées sur la recherche de patrons syntaxiques, comme nous le verrons ci-après. La littérature témoignant d’une terminologie disparate et de concepts souvent flous et contradictoires, nous employons ici le terme relation lexic</context>
</contexts>
<marker>Daille, 1994</marker>
<rawString>Daille B. (1994), Approche mixte pour l&apos;extraction de terminologie: statistique lexicale et filtres linguistiques, Paris : Université de Paris VII.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Katz</author>
<author>J A Fodor</author>
</authors>
<title>The structure of a semantic theory, In</title>
<date>1964</date>
<booktitle>The Structure of Language, chapter 19,</booktitle>
<pages>479--518</pages>
<editor>J. A. Fodor and J. J. Katz, editors,</editor>
<contexts>
<context position="4338" citStr="Katz &amp; Fodor, 1964" startWordPosition="656" endWordPosition="659">ormatisés, il pourrait être possible d’en extraire par des moyens automatiques ou semi-automatiques au moins les relations lexicales les plus importantes et récurrentes. Cette recherche de relations lexicales a des points communs avec la recherche de termes complexes, pour lesquels il existe des méthodes et logiciels d’extraction tels que, pour le français, Acabit (Daille, 1994) et Lexter (Bourigault, 1994). Bien que les relations recherchées ici soient plus générales (toutes ne constituent pas des « termes ») et relèvent des « préférences » lexicales (Wilks, 1975), restrictions de sélection (Katz &amp; Fodor, 1964) ou collocations (Benson, 1990 ; Smadja, 1993 ; Cruse, 1986) générales de la langue, on peut toutefois s’inspirer des mêmes techniques, basées sur la recherche de patrons syntaxiques, comme nous le verrons ci-après. La littérature témoignant d’une terminologie disparate et de concepts souvent flous et contradictoires, nous employons ici le terme relation lexicale, plus neutre, défini comme une cooccurrence lexicale entre deux lexèmes liés syntaxiquement. Nous centrons le présent travail sur l’importance d’une catégorisation lexicale automatique des relations lexicales, le tri des relations lex</context>
</contexts>
<marker>Katz, Fodor, 1964</marker>
<rawString>Katz J. J, Fodor J. A. (1964), The structure of a semantic theory, In J. A. Fodor and J. J. Katz, editors, The Structure of Language, chapter 19, pp. 479-518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A</author>
</authors>
<title>Dictionnaire explicatif et combinatoire du français contemporain: Recherches lexicosémantiques I, Montréal, Presses de l&apos;Université de Montréal.</title>
<date>1984</date>
<marker>A, 1984</marker>
<rawString>Mel’cuk I. A., Arbatchewsky-Jumarie, N., Elnitsky, L., Iordanskaja, L., Lessard. A. (1984), Dictionnaire explicatif et combinatoire du français contemporain: Recherches lexicosémantiques I, Montréal, Presses de l&apos;Université de Montréal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Véronis</author>
</authors>
<title>Hyperlex : cartographie lexicale pour la recherche d’informations,</title>
<date>2003</date>
<booktitle>Actes de TALN’2003,</booktitle>
<pages>265--274</pages>
<location>Batz-sur-mer (France): ATALA.</location>
<contexts>
<context position="1313" citStr="Véronis, 2003" startWordPosition="192" endWordPosition="193">oie » ces relations au milieu de celles correspondant aux usages les plus fréquents. Nous avons conduit une évaluation sur un corpus de plusieurs milliers de pages Web comportant l’un des 10 mots-cibles très polysémiques choisis pour cette expérience, et nous montrons que la précision obtenue est très bonne, avec un rappel honorable, suffisant en tout cas pour de nombreuses applications. L’analyse des erreurs ouvre des perspectives d’améliorations pour la suite de notre travail de thèse. This study shows that a pre-labeling of word uses by means of a disambiguation algorithm such as HyperLex (Véronis, 2003, 2004) allows a better extraction of lexical relations (NOUNADJECTIVE, NOUN “de” NOUN, NOUN-VERB, etc.), since these relations are categorised with respect to word use. In addition, this technique enables us to retrieve relations for very infrequent word uses, which otherwise would be buried in the residual noise corresponding to the most frequent uses. We performed an evaluation on several thousand web pages containing a target word among a set of 10 highly polysemic ones. We show that the precision obtained is very good, with a quite honourable recall, sufficient in any case for many applic</context>
<context position="7147" citStr="Véronis, 2003" startWordPosition="1059" endWordPosition="1060">ectrique hydraulique 71 routier routier 68 faux routier 31 mobile hydraulique 27 agricole hydraulique 26 haut hydraulique 23 hydro-électrique hydraulique 22 ancien hydraulique 21 Tableau 1 : Les 10 adjectifs les plus fréquents en cooccurrence avec barrage Nous explorons dans cette communication la possibilité d’exploiter une catégorisation automatique préalable des usages de mots. Toutefois, si une telle catégorisation devait faire intervenir des ressources lexicales importantes (incluant celles que nous cherchons à extraire), nous serions face à une circularité manifeste. (Schütze, 1998) et (Véronis, 2003) ont heureusement montré qu’on pouvait effectuer une catégorisation automatique par l’examen des similarités entre contextes directement à partir de grands corpus sans ressources lexicales (sémantiques) préexistantes. Nous allons plus précisément considérer ici l’aide qu’offre la pré- catégorisation opérée par l’algorithme HyperLex (Véronis, 2003, 2004)1 pour l’extraction des relations de type NOM – ADJECTIF, NOM1 DE NOM2, NOM – VERBE. Cet algorithme permet d’extraire les différents usages d’un mot. L’avantage d’HyperLex, contrairement aux méthodes précédemment proposées (vecteurs de mots, cf.</context>
<context position="25107" citStr="Véronis, 2003" startWordPosition="3876" endWordPosition="3877">que le nom-cible peut être séparé du verbe par des constituants syntaxiques hétérogènes (compléments circonstantielles, relatives par exemple) pouvant être de taille conséquente. De nombreuses relations Barrage (sujet) – VERBE extraites sont incorrectes. Les récents travaux sur l’analyse syntaxique partielle (shallow parsing) (cf. Abeillé et al., 2003), laissent penser que des progrès significatifs pourraient être fait sur l’extraction de ce type de relations. 6 Conclusion Nous avons essayé de montrer dans cet article qu’un pré-étiquetage des usages des mots par un algorithme tel qu’HyperLex (Véronis, 2003, 2004) permettait d’obtenir des relations lexicales (du type NOM-ADJECTIF, NOM de NOM, NOM-VERBE) beaucoup plus exploitables, parce qu’elles-mêmes catégorisées en fonction des usages. De plus, cette technique permet d’obtenir des relations pour des usages très peu fréquents, alors qu’une extraction indifférenciée « noierait » ces relations au milieu de celles correspondant aux usages les plus fréquents. Nous avons conduit une évaluation sur un corpus de plusieurs milliers de pages Web comportant l’un des 10 mots-cibles très polysémiques choisis pour cette expérience, et nous avons montré que </context>
</contexts>
<marker>Véronis, 2003</marker>
<rawString>Véronis J. (2003), Hyperlex : cartographie lexicale pour la recherche d’informations, Actes de TALN’2003, pp. 265-274, Batz-sur-mer (France): ATALA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Véronis</author>
</authors>
<title>HyperLex : cartographie lexicale pour la recherche d’informations.</title>
<date>2004</date>
<contexts>
<context position="8963" citStr="Véronis, 2004" startWordPosition="1315" endWordPosition="1316">i apparaissent en cooccurrence avec le mot-cible servent à créer un graphe pondéré par la force d’association entre cooccurrents. Les mots constituent les nœuds du graphe. Les arêtes du graphe représentent les interconnexions entre les mots qui se retrouvent au sein du même contexte. Ainsi les noms production et électricité dans l’exemple ci-dessous sont reliés (figure 1). Outre la production d’électricité, le BARRAGE permettra de réguler le cours du fleuve… 1 Démonstration en ligne : http://www.up.univ-aix.fr/veronis Chrystel MILLON Figure 1 : Graphe des cooccurrences du mot barrage (d’après Véronis, 2004) Les inter-connexions entre les mots font émerger des composantes fortement connexes (figure 1), qui correspondent aux différents usages du mot-cible du corpus analysé. L’algorithme HyperLex a été évalué sur 10 mots-cibles très polysémiques (barrage, détention, formation, lancement, organe, passage, restauration, solution, station et vol) à partir d’un corpus de plusieurs milliers de pages Web constitué pour chacun des mots-cibles à l’aide d’un méta-moteur de recherche (Copernic Agent). Seul un petit nombre d’usages a été omis par l’algorithme : la quasi-totalité des usages de fréquence supéri</context>
</contexts>
<marker>Véronis, 2004</marker>
<rawString>Véronis J. (2004), HyperLex : cartographie lexicale pour la recherche d’informations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rapport Interne Equipe DELIC</author>
<author>Université de Provence</author>
</authors>
<title>[En ligne : http://www.up.univmrs.fr/veronis/pdf/2004-hyperlex-rapport.pdf] Thorndike</title>
<date>1938</date>
<publisher>University Press.</publisher>
<location>New York, Columbia</location>
<marker>DELIC, de Provence, 1938</marker>
<rawString>Rapport Interne Equipe DELIC, Université de Provence. [En ligne : http://www.up.univmrs.fr/veronis/pdf/2004-hyperlex-rapport.pdf] Thorndike E. L., Lorge I. (1938), Semantic counts of English Words, New York, Columbia University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schütze</author>
</authors>
<title>Automatic word sense discrimination,</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<pages>97--124</pages>
<contexts>
<context position="7128" citStr="Schütze, 1998" startWordPosition="1056" endWordPosition="1057">raulique 85 hydroélectrique hydraulique 71 routier routier 68 faux routier 31 mobile hydraulique 27 agricole hydraulique 26 haut hydraulique 23 hydro-électrique hydraulique 22 ancien hydraulique 21 Tableau 1 : Les 10 adjectifs les plus fréquents en cooccurrence avec barrage Nous explorons dans cette communication la possibilité d’exploiter une catégorisation automatique préalable des usages de mots. Toutefois, si une telle catégorisation devait faire intervenir des ressources lexicales importantes (incluant celles que nous cherchons à extraire), nous serions face à une circularité manifeste. (Schütze, 1998) et (Véronis, 2003) ont heureusement montré qu’on pouvait effectuer une catégorisation automatique par l’examen des similarités entre contextes directement à partir de grands corpus sans ressources lexicales (sémantiques) préexistantes. Nous allons plus précisément considérer ici l’aide qu’offre la pré- catégorisation opérée par l’algorithme HyperLex (Véronis, 2003, 2004)1 pour l’extraction des relations de type NOM – ADJECTIF, NOM1 DE NOM2, NOM – VERBE. Cet algorithme permet d’extraire les différents usages d’un mot. L’avantage d’HyperLex, contrairement aux méthodes précédemment proposées (ve</context>
</contexts>
<marker>Schütze, 1998</marker>
<rawString>Schütze H. (1998), Automatic word sense discrimination, Computational Linguistics, Vol. 24 (1), pp. 97-124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Smadja</author>
</authors>
<title>Retrieving collocations from text :</title>
<date>1993</date>
<journal>Xtract, Computational Linguistics,</journal>
<volume>19</volume>
<pages>143--177</pages>
<contexts>
<context position="4383" citStr="Smadja, 1993" startWordPosition="665" endWordPosition="666">ar des moyens automatiques ou semi-automatiques au moins les relations lexicales les plus importantes et récurrentes. Cette recherche de relations lexicales a des points communs avec la recherche de termes complexes, pour lesquels il existe des méthodes et logiciels d’extraction tels que, pour le français, Acabit (Daille, 1994) et Lexter (Bourigault, 1994). Bien que les relations recherchées ici soient plus générales (toutes ne constituent pas des « termes ») et relèvent des « préférences » lexicales (Wilks, 1975), restrictions de sélection (Katz &amp; Fodor, 1964) ou collocations (Benson, 1990 ; Smadja, 1993 ; Cruse, 1986) générales de la langue, on peut toutefois s’inspirer des mêmes techniques, basées sur la recherche de patrons syntaxiques, comme nous le verrons ci-après. La littérature témoignant d’une terminologie disparate et de concepts souvent flous et contradictoires, nous employons ici le terme relation lexicale, plus neutre, défini comme une cooccurrence lexicale entre deux lexèmes liés syntaxiquement. Nous centrons le présent travail sur l’importance d’une catégorisation lexicale automatique des relations lexicales, le tri des relations lexicales extraites sera effectué plus tard. Une</context>
<context position="6366" citStr="Smadja, 1993" startWordPosition="952" endWordPosition="953">ue les mots associés aux usages les moins fréquents (par exemple fatal, décisif associés à barrage en tant que rencontre sportive, qui représente moins de 5% des occurrences) sont totalement noyés dans les relations lexicales concernant le ou les usages majoritaires (ici, « barrage hydraulique »). Les méthodes existantes d’extraction automatique de collocations ne tiennent pas compte des usages des mots. Ainsi, que les auteurs adoptent une approche essentiellement statistique Acquisition de relations lexicales désambiguïsées à partir du Web (Church, Hanks, 1989) ou bien syntaxico-statistique (Smadja, 1993), de nombreuses collocations relatives aux usages peu fréquents des mots sont a fortiori omises. ADJECTIF Usage Freq grand hydraulique 304 petit hydraulique 85 hydroélectrique hydraulique 71 routier routier 68 faux routier 31 mobile hydraulique 27 agricole hydraulique 26 haut hydraulique 23 hydro-électrique hydraulique 22 ancien hydraulique 21 Tableau 1 : Les 10 adjectifs les plus fréquents en cooccurrence avec barrage Nous explorons dans cette communication la possibilité d’exploiter une catégorisation automatique préalable des usages de mots. Toutefois, si une telle catégorisation devait fai</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Smadja F. (1993), Retrieving collocations from text : Xtract, Computational Linguistics, Vol. 19, pp. 143-177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y A Wilks</author>
</authors>
<title>Preference Semantics,</title>
<date>1975</date>
<pages>329--348</pages>
<publisher>Cambridge University Press,</publisher>
<location>In:</location>
<contexts>
<context position="4290" citStr="Wilks, 1975" startWordPosition="651" endWordPosition="652">osait d’une grande quantité de textes informatisés, il pourrait être possible d’en extraire par des moyens automatiques ou semi-automatiques au moins les relations lexicales les plus importantes et récurrentes. Cette recherche de relations lexicales a des points communs avec la recherche de termes complexes, pour lesquels il existe des méthodes et logiciels d’extraction tels que, pour le français, Acabit (Daille, 1994) et Lexter (Bourigault, 1994). Bien que les relations recherchées ici soient plus générales (toutes ne constituent pas des « termes ») et relèvent des « préférences » lexicales (Wilks, 1975), restrictions de sélection (Katz &amp; Fodor, 1964) ou collocations (Benson, 1990 ; Smadja, 1993 ; Cruse, 1986) générales de la langue, on peut toutefois s’inspirer des mêmes techniques, basées sur la recherche de patrons syntaxiques, comme nous le verrons ci-après. La littérature témoignant d’une terminologie disparate et de concepts souvent flous et contradictoires, nous employons ici le terme relation lexicale, plus neutre, défini comme une cooccurrence lexicale entre deux lexèmes liés syntaxiquement. Nous centrons le présent travail sur l’importance d’une catégorisation lexicale automatique d</context>
</contexts>
<marker>Wilks, 1975</marker>
<rawString>Wilks Y. A. (1975), Preference Semantics, In: Keenan, E. (ed), The Formal Semantics of Natural Language, Cambridge University Press, pp. 329-348.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>