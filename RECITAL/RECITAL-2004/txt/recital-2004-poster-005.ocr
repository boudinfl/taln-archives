RECITAL 2004, Fés, 21 avril 2004

Méthodes statistiques et apprentissage automatique pour
l’évaluation de requétes en recherche documentaire

Jens GRIVOLLA"‘l
encadre’ par Pierre Jourlin et Renato de Mori
Laboratoire Informatique d’Avignon (LIA)

Résumé - Abstract

Pour la recherche documentaire il est souvent intéressant d’avoir une bonne mesure de conﬁance
dans les réponses trouvées par le moteur de recherche.

Une bonne estimation de pertinence peut permettre de faire un choix entre plusieurs réponses
(venant éventuellement de différents systemes), d’appliquer des méthodes d’enrichissement ad-
ditionnelles selon les besoins, ou encore de permettre a l’utilisateur de prendre des décisions
(comme d’approfondir la recherche a travers un dialogue).

Nous proposons une méthode permettant de faire une telle estimation, utilisant des connais-
sances extraites d’un ensemble de requétes connues pour en déduire des prédictions sur d’autres
requétes posées au systeme de recherche documentaire.

In document retrieval applications it is often interesting to have a measure of conﬁdence in the
answers found by the retrieval system.

A good relevance estimation can allow us to make a choice between different answers (possibly
provided by different sources), apply additional expansion techniques according to the speciﬁc
needs, or enable the user to make decisions (such as to reﬁne the search interactively).

We propose a method that allows us to make such estimations, using knowledge extracted from
a known query corpus to deduce predictions on new queries presented to the document retrieval
system.

Mots-clefs — Keywords

apprentissage/décision automatique, recherche documentaire, expansion de requétes, évaluation
de difﬁculté
automatic learning/decision, document retrieval, query expansion, difﬁculty evaluation

ﬁens.grivolla@lia.univ—avignon.fr
avec le soutien de Digitech S.A. et de la Region PACA

Jens Grivolla

1 Introduction

Un systeme de recherche documentaire doit trouver dans une base de documents (typiquement
une collection de textes) les documents répondants a une requéte posée (en langage naturel) par
un utilisateur.

En général, un systeme de recherche documentaire répondra a une requéte posée par une liste
ordonnée de documents. Le but dans la conception d’un systeme de recherche est de maximiser
le nombre de documents pertinents dans la liste, surtout en téte de liste, et de minimiser le
nombre de documents non-pertinents.

Dans la plupart des applications, la performance d’un systeme sera jugé selon la précision, c’est-
a-dire le pourcentage de documents pertinents parmi les documents trouvés par le systeme de
recherche. Une autre mesure importante est le rappel, le pourcentage des documents pertinents
contenus dans la collection qui ont été retournés par le systeme.

Nous avons utilisé la precision moyenne, qui tient compte aussi bien du rappel que de la
précision, ainsi que du classement relatif des documents dans la liste.

Beaucoup de travail est fait par un grand nombre de chercheurs pour améliorer les perfor-
mances, en particulier par des méthodes d’enrichissement de requétes, c.a.d. des modiﬁcations
des requétes p. ex. en rajoutant des termes additionnels (voir section 3) aﬁn de trouver des
documents pertinent supplémentaires.

Malheureusement, ces méthodes ne sont efﬁcaces que pour une partie des requétes et peuvent
meme dégrader les résultats pour d’autres. Pour certaines requétes aucun systeme n’atﬁve a
foumir de réponses satisfaisantes.

De ceci se dégagent deux problématiques :

— déterminer le traitement optimal pour chaque requéte

— identiﬁer les requétes pour lesquelles la recherche échoue aﬁn de p. ex. poursuivre une ap-
proche interactive

2 L’environnement d’application

Toutes les expérimentations présentées dans cet article ont été effectuées sur la base du corpus
de documents et des requétes issues des campagnes TREC (Text REtrieval Conference). Pour la
discipline appelée adhoc, la recherche non-interactive automatique a partir de requétes écrites
en langage naturel, ces campagnes foumissent chaque année un corpus de documents (environ
500 000) et 50 requétes, ainsi que les moyens pour évaluer automatiquement les performances
d’un systeme de recherche documentaire sur ces données.

Les requétes sont disponibles sous différentes formes, pouvant étre composées d’un titre
(quelques mots clés), d’un descriptif (une ou deux phrases) et d’un narratzf (explication
détaillée de la thématique recherchée).

Nos méthodes ont été appliquées sur la base d’un systeme de recherche documentaire utilisant
le modele probabiliste. Le systeme implémenté par Pierre Jourlin est relativement classique,
proche du systeme OKAPI, et avait préalablement servi dans le contexte du «spoken document
retrieval» (SDR) (Jones et al., 2001).

Méthodes statistiques et apprentissage automatique pour 1’éVa1uation de requétes
en recherche documentaire

3 L’enrichissement des requétes

Une méthode pour enrichir des requétes sans interaction avec 1’uti1isateur est le blind relevance
feedback (BRF )(Wa1ker & de Vere, 1990).

Partant de 1’hypothese que les premiers documents dans la liste retournée par le systeme de
recherche ont une forte probabilité d’étre pertinents, un nombre t de termes caractérisant les d
premiers documents est ajouté a la requéte initiale. La requéte ainsi enrichie peut permettre de
retrouver des documents pertinents qui ne contiennent pas les termes employés dans la requéte
d’origine, et ainsi augmenter le rappel. Diverses études sur le BRF ont montré que la précision
est (en moyenne) également meilleure en utilisant des requétes enrichie de cette maniere.

Nous avons constaté que (quel que soit le paramétrage ou le type de requéte) 1’app1ication
de BRF dégrade les résultats obtenus pour au minimum environ 30% des requétes, malgré une
amélioration globale des performances. Pour les requétes courtes consistant uniquement du titre
ou du descriptif, le taux d’échec peut dépasser les 50%. Il est donc intéressant d’éviter cet effet
négatif pour les requétes concernées.

3.1 La difﬁculté des requétes et l’effet de l’enrichissement

Nos travaux portant sur les deux aspects de la difﬁculté des requétes posées et de 1’effet qu’ont
des techniques d’enrichissement selon la requéte, nous avons également analysé le lien entre la
précision moyenne obtenue (sans BRF) et le gain apporté par 1’enrichissement de la requéte.

+
+
u2- + +
m5 J“ + -
+
u.1 + -
+
++ ,__
u. ____ _
E u.u5-+ .- N‘: + +
5  +*--.1‘: ____ __ +
5 a + ++ -1+ """ -- \ ......... .- -
.==_ +H- + + + +
g -a.u5- + +++++ + -
-u.¢ -
+
41.15
02-
+
£5 . . . . . . . .
u 0.1 0.2 as 0.4 0.5 0.6 0.7 as 0.9

avg. mac. Me an:

FIG. 1 — précision moyenne et gain par BRF : TREC 8 ad-hoc

On constate dans la ﬁgure 1 que 1’eXpansion de requéte fonctionne surtout sur des requétes pour
lesquelles on obtient des performances moyennes sans BRF, alors que pour les requétes qui
donnaient des résultats tres bon ou tres mauvais 1’enrichissement a plutot tendance a dégrader
le résultat.

On peut supposer que ceci s’exp1ique principalement par le fait que 1’enrichissement utilise des
mots extraits des premiers documents dans la liste. Si ceux-ci ne sont pas pertinents, il n’est pas
possible de trouver des termes représentatif de la thématique recherchée, 1’eXpansion de requéte
ne peut donc pas améliorer les performances. Dans le cas contraire, les documents trouvés étant
bons, une nouvelle recherche avec un classement différent des documents risque de déclasser
les documents pertinents initialement trouvés et ainsi de détériorer le résultat.

Jens Grivolla

4 Notre approche

L’ approche poursuivie consiste a déterminer un ensemble d’attributs calculables sur la base de
la requéte meme et (selon les informations disponibles) des réponses ainsi que du processus
ayant conduit a la réponse (scores intemes du systeme de recherche documentaire, documents
dont la réponse est extraite dans les applications QA, etc.)

Chaque requéte ou chaque couple requéte-réponse sera ainsi représenté par un vecteur d’at-
tributs d’une dimension variant selon l’ensemble d’attributs choisi. En utilisant un corpus de
requétes pour lesquelles la performance du systeme est connue, on peut ensuite appliquer des
méthodes de classiﬁcation automatique aﬁn d’aboutir a des prédictions par rapport au critere de
classiﬁcation (p. ex. la difﬁculté de la requéte en termes de précision moyenne obtenue) pour
des nouvelles requétes non comprises dans ce corpus d’apprentissage.

Nous avons développé une liste d’attributs plus ou moins fortement corrélés avec la difﬁculté
de la requéte (en terme de précision obtenue par le moteur de recherche). Sur la représentation
vectorielle de la requéte, nous avons appliqué différentes méthodes de classiﬁcation et décision
automatique (arbres de décision, SVM, etc.) aﬁn d’obtenir des prédictions.

Les attributs choisis peuvent se diviser en deux types :

— des attributs basés purement sur la requéte meme

— des attributs utilisant les résultats d’une premiere phase de recherche

La premiere catégorie comprend p. ex. la longueur de la requéte, des mesures de spéciﬁcité
des termes de la requéte (hyponymie, IDF, ...) ou encore des mesures d’ambigu'1'té (le nombre
de sens des termes de la requéte, ...) ainsi que des scores divers calculés sur la base de telles
propriétés.

Parmi les attributs du deuxieme type ce trouvent en particulier des mesures de similarité ou dis-
tance entre les documents trouvés, les scores des documents d’apres la formule Okapi-BM251
(Robertson et al., 1996) et des scores dérivés.

Nous avons utilisé différents classiﬁeurs génériques sur différentes représentations vectorielles
des informations disponibles : arbres de décision, CAL5, Dipol, SVM, NaiveBayes, réseaux
de neurones, etc. Le systeme WEKA (Witten & Frank, 1999) permet l’utilisation d’un grand
nombre de classiﬁeurs différents, mais nous avons également évalué d’autres implémentations.

Les algorithmes a base d’arbres de décisions présentent l’avantage de construire des regles de
classiﬁcation qui peuvent étre lues et interprétées. Ceci peut livrer des informations intéressantes
et exploitables sur le processus de classiﬁcation. Par contre, sur le nombre limité de données dis-
ponible d’autres classiﬁeurs (en particulier les SVM) permettent d’obtenir de meilleurs résultats
de classiﬁcation.

Nous avons également utilisé un classiﬁeur spécial pour la catégorisation de textes, les «Seman-
tic Classiﬁcation Trees» (SCT) (Kuhn & De Mori, 1995), qui construit a partir d’un ensemble
de textes (dans notre cas des requétes) un arbre basé sur des expressions régulieres (extraites
automatiquement) qui servent a diviser le corpus sur les différentes branches de l’arbre.

_ <K+1)><tf ,
1ZtCwt,d — Ztqtft  1Og Ni,

Méthodes statistiques et apprentissage automatique pour 1’éVa1uation de requétes
en recherche documentaire

5 Résultats

5.1 Estimation de difﬁculté

Sur l’estimation de difﬁculté des requétes nous avons séparé les requétes en deux classes :
<<faciles>> et <<difﬁciles>>, selon la précision moyenne obtenue par rapport a un seuil ﬁxé.

Nous avons ensuite utilisé la méthode «leave one out» aﬁn de découper le corpus de requétes
disponibles en entrainemem,‘ et test. Pour chaque requéte, un classiﬁeur a ainsi été construit
sur la base du reste du corpus et appliqué sur la requéte restante pour évaluer la qualité des
prédiction. La précision de classiﬁcation devait ensuite étre comparée au taux obtenable par
la connaissance de la distribution des classes (en faisant systématiquement la prédiction de la
classe plus grande).

Le seuil devait étre ﬁxé de maniere relativement arbitraire (il dépendrait d’une application pra-
tique éventuelle), nous avons choisi de prendre pour l’instant la valeur médiane ainsi que la
moyenne pour évaluer notre systeme.

Actuellement, en utilisant un classiﬁeur a base de SVM et un jeu d’environ 20 caractéristiques
(plus un grand nombre de variations) nous anivons a un taux de classiﬁcation correcte de 70%
avec la valeur médiane comme seuil (par rapport a 50% basé sur la distribution des classes).
Avec le seuil ﬁxé a la valeur moyenne nous obtenons une précision de 73% (contre 62%).

Ces valeurs ont été obtenues sur les requétes de TREC 8 et semblent étre signiﬁcativement
au-dessus des taux de référence. I1 reste a vériﬁer si ces performances sont généralisables a
d’autres corpus, mais cela semble probable, aucune <<optimisation>> n’ayant été faite sur le
corpus donné. I1 reste également a étudier quel taux de classiﬁcation peut étre obtenu avec des
seuils ﬁxés différemment.

Utilisant un corpus tres limité pour l’apprentissage du classiﬁeur, les SVMs se sont avérés les
plus performants. Dans un contexte avec un plus grand nombre d’exemples disponibles, il est
pensable que d’autres méthodes obtiennent de meilleurs résultats, cela n’a pas encore pu étre
vériﬁé.

Nous avons fait quelques tests avec des classiﬁeurs capables de prédire des valeurs continues
aﬁn d’avoir une estimation directe de la précision (du moteur de recherche) attendue, mais nous
n’avons pas obtenu de résultats satisfaisants, probablement dﬁ a la faible quantité de données
dont nous disposons.

5.2 Décision sur l’enrichissement des requétes

Au-dela de l’estimation de la qualité attendue du résultat, il est possible d’utiliser la classiﬁca-
tion aﬁn de décider de l’utilisation de méthodes d’expansion des requétes (ou d’autres traite-
ments spéciﬁques).

Une premiere étude a permis de déterminer le potentiel de notre approche en supposant qu’on
soit capable d’une décision parfaite sur l’application d’enrichissement pour chaque requéte.

En particulier, sur les requétes de taille moyenne (titre et descriptif) de TREC 8, notre systeme
arrive a une moyenne (sur toutes les requétes) des <<précisions moyennes>> de 24% sans ex-
pansion et 27% avec le meilleur paramétrage choisi globalement pour toutes les requétes. Par

Jens Grivolla

contre, en choisissant les meilleurs parametres pour chaque requéte on arrive a 33%, avec un
simple choix binaire d’application de BRF sans variation des parametres 29% sont possibles.

Il est donc possible (en principe) d’obtenir des performances considérablement supérieures aux
meilleures performances n’utilisant pas de décision pour chaque requéte individuelle.

La décision sur le paramétrage précis de l’expansion a appliquer demande l’utilisation de clas-
siﬁeurs permettant une prédiction numérique des parametres et suppose que l’estimation des
différents parametres est indépendante (qu’on peut donc estimer les valeurs optimales de d et t
séparément).

Nous nous sommes pour l’instant contentés d’une décision binaire d’application ou non de
l’expansion (avec un paramétrage ﬁxé) selon les probabilités d’une amélioration ou dégradation
des performances. Un grand choix de méthodes de classiﬁcation peut étre utilisé pour cela.

En appliquant les prédictions issues d’un classiﬁeur dans la pratique nous n’obtenons actuelle-
ment pas de performances signiﬁcativement meilleures que sans décision. De plus, nous avons
constaté que les résultats varient fortement selon le corpus de requétes traité.

6 Conclusions et perspectives

Les résultats actuels pour l’estimation de difﬁculté sont prometteurs. L’ effet de l’enrichissement
étant lié a la précision obtenue, il semble probable qu’on puisse arriver a des prédiction exploi-
tables, ce qui se traduirait directement en une meilleure performance du systeme utilisant ces
informations.

Le domaine <<questions/réponses>> semble se préter particulierement a notre approche, car au-
dela des attributs que nous avons utilisés pour la tache <<adhoc>>, une grande quantité d’infor-
mations linguistiques pourraient étre exploitées.

A plus long terme, il semble intéressant d’exploiter les informations extraites pour diriger un
dialogue avec l’utilisateur pour les requétes qui ne peuvent pas étre traitées correctement de
maniere automatique.

Références

JONES K. S., J OURLIN P., JOHNSON S. & WOODLAND P. (2001). The Cambridge multimedia docu-
ment retrieval (mdr) project 2 Summary of experiments.

KUHN R. & DE MORI R. (1995). The Application of Semantic Classiﬁcation Trees to Natural Language
Understanding, volume 17, chapter 5, p. 449-460. IEEE Transactions on Pattern Analysis and Machine
Intelligence.

ROBERTSON S., WALKER S., JONES S., HANCOCK-BEAULIEU M. & GATFORD M. (1996). Okapi at
TREC-3. In Overview of the Third Text REtrieval Conference (TREC-3).

WALKER S. & DE VERE R. (1990). Improving subject retrieval in online catalogues 2 2. relevance
feedback and query expansion. British Library Research Paper 72.

WITTEN I. H. & FRANK E. (1999). Data Mining : Practical machine learning tools with Java imple-
mentations. San Francisco 2 Morgan Kaufmarm.

