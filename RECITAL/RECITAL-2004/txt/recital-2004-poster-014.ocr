RECITAL 2004, Fés, 21 avril 2004

Un systéme adaptable pour l’initialisation automatique d’une
base lexicale interlingue par acceptions

Aree Teeraparbseree
GETA, CLIPS, IMAG (UJF & CNRS)
385, rue de la Bibliotheque
B.P. 53 - 38041 Grenoble Cedex 9, France
aree.teeraparbseree@imag.fr

Mots-clefs — Keywords

base lexicale multilingue, construction automatique de lexies et axies, acception interlingue
multilingual lexical database, automatic building of lexies and axies, interlingual acception

Résumé - Abstract

Cet article présente une stratégie de construction semi-automatique d’une base lexicale inter-
lingue par acception, a partir de ressources existantes, qui utilise en synergie des techniques
existantes de désambiguisation. Les apports et limitations de chaque technique sont présen-
tés. Notre proposition est de pouvoir composer arbitrairement des techniques, en fonction des
ressources disponibles, aﬁn d’obtenir une base interlingue de la qualité souhaitée. Jeminie, un
systeme adaptable qui met en oeuvre cette stratégie, est introduit dans cet article.

This article presents a strategy for the semi-automatic building of an interlingual lexical data-
base, based on existing resources, and using existing disambiguisation techniques in synergy.
The pros and cons of each technique are given. Our proposal is to be able to compose techniques
arbitrarily, according to the available resources, in order to produce an interlingual database of
the desired quality. J eminie, an adaptable system that implements this strategy, is introduced in
this article.

Introduction

Le travail présenté ici se place dans le cadre du projet Papillon (Mangeot-Lerebours et al. ,
2003). Ce projet vise a la construction collaborative d’une grande base lexicale multilingue. La
motivation initiale du proj et est le manque de dictionnaires, a la fois pour humains et machines,
entre le francais et de nombreuses langues asiatiques. La construction d’une base lexicale multi-
lingue nécessite de réunir des linguistes spécialistes de toutes les langues concernées par la base,

Aree Teeraparbseree

ce qui peut étre difﬁcile voire impossible. Des logiciels d’aide automatique a la construction de
bases lexicales s’averent donc nécessaires.

Nous proposons dans cet article un systeme logiciel d’aide a la construction d’une base lexicale
interlingue par acceptions, et plus précisément a la production d’un “premier jet” d’une organi-
sation des vocables en lexies (sens de mot) et a la transformation des liens traductionnels entre
vocables en liens interlingues (axies) entre lexies. Cette premiere version de la base est ensuite
corrigée et améliorée par les linguistes.

Cet article présente d’abord la structure de la base lexicale du projet Papillon, puis une stratégie
générale et des techniques automatiques utilisables pour la construction d’une base lexicale
interlingue, et enﬁn J eminie, un systeme adaptable pour la construction de telles bases.

1 Papillon : base lexicale interlingue par acceptions

Le projet Papillonl a pour but de créer une base lexicale multilingue comprenant l’allemand,
l’anglais, le francais, le japonais, le lao, le malais, le tha'1', le vietnaInien et, tres récemment,
le chinois. Papillon utilise l’approche interlingue, o1‘1 un langage intermédiaire artiﬁciel (dit
aussi langage pivot) est utilisé pour établir des liens entre les langues. Une telle approche a
été utilisée dans d’autres projets, par exemple, le projet KBMT-89 (Goodman & Nirenburg,
1991) et le projet ULTRA (Farwell et al., 1992). La macrostructure de Papillon repose sur une
structure pivot déﬁnie dans (Sérasset, 1994). Une “base Papillon” est composée d’un ensemble
d’acceptions monolingues (lexies) pour chaque langue et d’un ensemble de liens interlingues
qui relient les lexies. Ces liens interlingues peuvent aussi étre reliés a une liste d’éléments de
chaque systeme extérieur qui sont plus ou moins équivalents ou voisins (synsets de WordNet,
universal words d’UNL, ...). Cette structure a déja été expérimentée dans PARAX (Blanc, 1999).
La microstructure (structure lexicale des entrées de chaque dictionnaire) est tirée des travaux de
Polguere sur le format lexicographique DiCo, qui est une simpliﬁcation de celui du Dictionnaire
Explicatif et Combinatoire associé a la théorie sens-texte (Mel’cuk et al., 1995).

La construction du contenu se fera en deux phases (Mangeot-Lerebours et al., 2003). (1) La
phase d ’am0rgage a pour but d’obtenir, a partir de dictionnaires existants, une premiere base
lexicale contenant de nombreuses entrées associées a des informations minimales. Puis dans (2)
la phase de contribution, des internautes bénévoles cooperent a travers Internet pour apporter
des modiﬁcations (ajout, correction ou suppression) a la base lexicale du serveur Papillon. Cette
phase ne peut commencer que lorsqu’il existe un ensemble minimal d’informations lexicales
sur la base du serveur Papillon. Le travail présente ici conceme la phase d’amorcage, et plus
particulierement son automatisation partielle ou complete.

2 Construction d’acceptions interlingues

Pour mener a bien ce travail, nous disposons de plusieurs dictionnaires monolingues (4000 en-
trées francaises DiCo de l’Université de Montreal, 10 000 entrées tha'1' de l’Université Kasetsart),
de dictionnaires bilingues (70 000 entrées japonais-anglais et 10 000 entrées japonais-francais

1La base est accessible principalement sur le site http ://Www.papillon—dictionary.orgﬂ Ce site contient aussi un
collection de dictionnaires “classiques”, accessibles par une interface uniﬁée.

Un systéme adaptable pour1’initia1isation automatique d ’une base lexicale interlingue
par acceptions

de J MDICT en format XML de J . Breen, 8000 entrées japonais-tha'1' de SAIKAM) et de diction-
naires multicibles (50 000 entrées anglais-francais-malais de FeM).

Nous proposons d’initialiser la “base Papillon” en deux étapes : (1) pour chaque dictionnaire
monolingue on extrait l’information des vocables, par exemple les lemmes (simples ou com-
posés), les parties du discours et les déﬁnitions, et on cre’e des lexies; (2) a partir des lexies de
plusieurs langues et des ressources bilingues et multilingues, on cre’e des axies qui relient ces
lexies et on fait évoluer si nécessaire l’ensemble des lexies de chaque langue. Si les bases mo-
nolingues sont volumineuses, le temps nécessaire pour relier a la main ces bases monolingues
en liens interlingues sera tres élevé. De plus, le travail de création des axies est tres coﬁteux. Il
nécessite des personnes connaissant de nombreuses langues. Notre objectif est de développer
un logiciel pour aider a la construction de ces liens aﬁn de réduire le coﬁt de construction. Plus
précisément, dans l’étape (1) le logiciel automatisera la construction des lexies, mais il faudra
quand méme ﬁltrer les lexies a la main pour vériﬁer leur qualité ; dans l’étape (2) le logiciel sera
semi-automatique car la construction est automatique mais l’utilisateur devra tout de méme pa-
ramétrer l’outil en fonction des ressources et de la qualité désirée, et du coﬁt des traitements. Le
probleme principal est de relier automatiquement des lexies qui ont la méme signiﬁcation. Cette
section décrit donc quelques techniques existantes de désambiguisation que nous considérons
pour la construction automatique des axies, et les problemes lies a chaque technique.

La technique de traduction bilingue (TR_BILING) utilise un ou plusieurs dictionnaires bi-
lingues pour créer des axies qui relient toutes les lexies de deux langues dont les mots sont la
traduction l’un de l’autre. Les axies obtenues devraient étre ﬁltrées ultérieurement en utilisant
d’autres techniques pour éventuellement dégrouper une axie en plusieurs axies ou enlever des
mauvaises lexies dans les axies. La technique de traduction bilingue multiple (TR_MBILING)
est une technique de traduction bilingue qui se base sur plusieurs dictionnaires bilingues, p.ex.
japonais-anglais et anglais-francais et leurs dictionnaires inverses, pour compléter ou pallier
l’absence de dictionnaires bilingues entre deux langues, p.ex. entre le japonais et le francais
(Tanaka & Umemura, 1994). Cependant, ces deux techniques produisent une base lexicale au
niveau des mots et pas du sens des mots. La technique de comparaison de deux vecteurs
conceptuels (CMP_VECTOR) associe a chaque lexie un vecteur de concepts, appellé vec-
teur conceptuel, dont chaque dimension correspond a un concept feuille d’un thésaurus. M.
Lafourcade (Lafourcade, 2002; Mangeot-Lerebours et al., 2003) expérimente pour le francais
et l’anglais, en se basant sur les 873 concepts feuilles du thésaurus Larousse. La distance angu-
laire entre vecteurs mesure la proximité thématique entre lexies. La difﬁculté est de trouver des
thésaurus pour ces langues et de faire correspondre les concepts feuilles de ces thésaurus. Par
contre, le résultat est directement de niveau lexie et cette technique est relativement efﬁcace.
La technique de ﬁltrage de synonymes (FILT_SYN) regroupe dans une méme axie des lexies
de la méme langue qui ont le méme sens d’apres un dictionnaire de synonymes. Le manque de
dictionnaires de synonymes des langues considérées est un probleme pour cette technique.

Une seule technique n’est pas sufﬁsante pour initialiser une base lexicale interlingue de la
qualité qu’on souhaite. En revanche, ces techniques sont complémentaires : pour atteindre la
meilleure qualité possible, nous proposons de composer plusieurs techniques ensemble. Nous
présentons ci-apres deux exemples de composition de techniques pour illustrer et motiver la
nécessité de composer des techniques. Les ressources disponibles sont : (1) des dictionnaires bi-
lingues : FAl (francais-anglais), FA2 (francais-anglais), AT (anglais-tha'1'), AJ (anglais-japonais),
(2) des bases lexicales monolingues francais, anglais, japonais, tha'1', (3) l’information sur la
partie du discours pour chaque lexie, (4) un vecteur conceptuel associé a chaque lexie, (5) un
dictionnaire de synonymes francais SF. La liste des techniques disponibles est celle de la section

Aree Teeraparbseree

2. On peut alors deﬁnir la composition de techniques suivante, ou les techniques sont appliquees
les unes apres les autres :

TR_BILING (FAl); TR_BILING (FA2); FILT_SYN(SF); CMP_VECTOR; TR_BILING (AJ);
TR_MBILING (AJ); TR_BILING (AT); TR_MBILING(AT)

L’ execution de chaque technique modiﬁe la base en fonction des parametres passes, p.eX., le
nom d’un ﬁchier dictionnaire bilingue pour TR_BILING. L’ ordre d’execution peut avoir un
impact important sur le temps de calcul. Par exemple, si une base lexicale monolingue francais
a beaucoup de mots synonymes, il faudra probablement utiliser la technique de ﬁltrage par
dictionnaire de synonymes pour diminuer le nombre d’axies avant d’uti1iser d’autres ﬁltrages,
pour diminuer le temps de calcul de la suite d’eXecution. Si les dictionnaires FA2 et AJ, et le
dictionnaire monolingue japonais ne sont pas disponibles, l’ensemble des techniques utilisables
est plus restreint. On peut par exemple deﬁnir la composition de techniques suivante :

TR_BILING (FAl) ; CMP_VECTOR; TR_BILING (AT) ; TR_MBILING (AT)

A cause du manque de ressources disponibles, cette deuxieme composition produit probable-
ment une base lexicale interlingue de qualite inferieure, avec une plus grande proportion d’axies
incorrectes, necessitant plus de corrections ulterieures par les linguistes.

Ces exemples montrent qu’il est necessaire de pouvoir utiliser des compositions des techniques
differentes, car le choix d’une composition est un compromis entre la qualite souhaitee de la
base produite, le coﬁt de la Inise en oeuvre des techniques (ressources techniques necessaires), et
les ressources lexicales necessaires. Une propriete essentielle d’un systeme logiciel de construc-
tion d’axies est donc de pouvoir supporter la Inise en oeuvre de compositions arbitraires de
techniques de construction d’axies. Le systeme J eminie, presente dans la section suivante, a ete
concu dans cet objectif.

3 Systéme J eminie

J eminie est un canevas logiciel (framework) que nous avons concu pour automatiser la construc-
tion de bases lexicales interlingues par acceptions. J eminie met en oeuvre les deux etapes de-
ﬁnies dans la section 2 : normalisation des donnees avec production d’un premier ensemble de
lexies, puis production d’axies et amelioration de l’ensemble des lexies.

Dans l’etape de normalisation des donnees, on ne manipule que des lexies, en convertissant vers
le modele de donnees (modele d’objets) de Jeminie les donnees qui proviennent de ressources
monolingues differentes a partir de ﬁchiers au format XML Papillon, mais le systeme peut
etre etendu pour importer des dictionnaires dans d’autres modeles de donnees. On enrichit ces
lexies initiales de chaque langue par des informations tirees des ressources monolingues, par
exemple, des informations sur la partie du discours, une deﬁnition, etc. C’est dans cette phase
qu’ on controle la difference entre les informations qui proviennent de ressources differentes. Par
exemple, on transforme l’information de partie du discours de chaque lexie en une des valeurs
communes, par exemple, on convertit l’information “nom masculin” en “nom”.

Dans l’etape de production d’axies et d’evolution des lexies, dans Jeminie, nous considerons
une technique de creation ou de ﬁltrage des axies comme un module logiciel. Jeminie per-
met de composer arbitrairement des modules pour creer une base lexicale interlingue de la
meilleure qualite possible. Nous appelons processus de production de base multilingue une se-
quence d’executions de modules. Un seul processus n’est pas applicable dans tous les cas. I1

Un systéme adaptable pour1’initia1isation automatique d ’une base lexicale interlingue
par acceptions

peut étre différent en fonction des ressources et outils disponibles, des propriétés des langues,
des objectifs linguistiques, etc. Le systeme a deux types d’acteurs différents, dont le point de
vue, les préoccupations et les taches sont indépendantes : (1) un informaticien qui programme
des modules, (2) un linguiste qui compose des techniques par la description d’un processus.

J eminie a une architecture en couches. L’ interpréteur de processus interprete les processus spe-
ciﬁés par les linguistes, et déclenche l’exécution des modules. L’interpréteur et les modules sont
développés en utilisant le noyau de J eIr1inie, qui est une bibliotheque de programmation Java de
base qui implante aussi la normalisation et l’importation de dictionnaires. La syntaxe que nous
avons déﬁnie pour spéciﬁer des processus est illustrée dans les exemples de “composition” de
la section 2. Cette syntaxe est simple, car destinée aux linguistes non informaticiens. Jeminie
peut étre étendu en développant de nouveaux modules. Les données sont représentées ici par
des objets Java, p.ex. un objet de type Axie est lié a un ensemble d’objets Lexie, accessibles
via des objets de type Inter1ingualDatabase représentant des bases multilingues. Les objets sont
sauvegardés dans une base de données relationnelle via un intergiciel de persistance d’objets
Java, Hibernatez, sur lequel s’appuie le noyau.

Considérons par exemple deux dictionnaires monolingues francais et anglais. Pour chaque dic-
tionnaire, une étape de normalisation crée un objet LexieDatabase, qui contient un objet Lexie
pour chaque acception avec pour chacun un objet ConceptualVector, etc. Ensuite, un objet In-
terlingualDatabase “vide” est créé. Lors de l’exécution d’un processus, l’objet Interlingual-
Database et les objets LexieDatabase sont passés en parametre a chaque module exécuté. Un
module peut avoir des parametres supplémentaires spéciﬁques, comme un nom de ﬁchier de
dictionnaire bilingue pour le module TR_BILING. Un module exécuté crée ou supprime des
objets Axie dans l’objet InterlingualDatabase. Par exemple, considérons un processus qui exe-
cute successivement les modules TR_BILING et FILT_SYN. Le module TR_BILING crée un
obj et Axie pour chaque paire d’obj ets Lexie pour les acceptions des mots “affection” en francais
et “affection” et “disease” en anglais, mots qui sont traductions l’un de l’autre selon le diction-
naire bilingue passé en parametre, et ainsi de suite pour toutes les Lexies francaises. Ensuite, le
module FILT_SYN fusionne en un méme nouvel objet Axie tous les objets Axie qui sont liés
aux objets Lexie qui sont les acceptions des mots francais “affection” et “maladie”, car ils sont
synonymes selon le dictionnaire de synonymes passé en parametre, et ainsi de suite pour toutes
les Axies. Les objets sont automatiquement persistants et conservés dans la base de données.
Cette approche a objets permet de développer facilement des modules.

Nous avons implanté des fonctions de normalisation des données capables d’extraire des in-
formations liées aux lexies telles que les lemmes, les parties du discours, les déﬁnitions. Nous
avons validé la partie de normalisation des données avec une base lexicale monolingue pour
le francais qui regroupe des informations de plusieurs dictionnaires monolingues. Nous avons
aussi normalisé des lexies en anglais extraites de Wordnet3. Le résultat obtenu est une base de
lexies avec pour chaque lexie son lemme, sa partie du discours, sa déﬁnition, et son vecteur
conceptuel stockée dans une base de données PostgreSQL. Nous avons pour l’instant normalisé
21400 mots / 45500 lexies du francais a partir de la resource Semantic CV Service, et 52900
mots / 94660 lexies de l’anglais a partir de WordNet. Trois modules / techniques de construction
d’axies sont en cours d’implantation : traduction bilingue, comparaison de partie du discours et
comparaison de deux vecteurs conceptuels.

Zhttp ://hibernate.sf.net/
3http ://www.cogsci.princeton.edu/~wn/index.shtm1

Aree Teeraparbseree

4 Conclusion et perspectives

Cet article présente une stratégie de construction seIni-automatique d’une base lexicale inter-
lingue a partir de ressources existantes et introduit un systeme logiciel adaptable qui supporte
cette stratégie. L’idée principale est de permettre a des utilisateurs linguistes de choisir et com-
poser des techniques disponibles pour construire une base de lexies reliées par des axies. Le
systeme est ouvert pour implanter des nouvelles techniques de construction ou de ﬁltrage des
axies. Le systeme devra permettre d’évaluer automatiquement un processus en cours d’exécu-
tion en mesurant sa consommation de ressources (temps de calcul, etc.) et la qualité des axies
obtenues. Nous sommes en train d’identiﬁer des criteres possibles pour évaluer la qualité des
axies. Ces criteres seront utiles pour comparer des processus de construction pour pouvoir pro-
duire des axies de la meilleure qualité possible.

Références

BLANC E. (1999). PARAX-UNL : A large scale hypertextual multilingual lexical database.
In Proceedings of 5th Natural Language Processing Paciﬁc Rim Symposium, pp. 507-510,
Beijing : T singhua University Press.

FARWELL D., GUTHRIE L. & WILKS Y. (1992). The automatic creation of lexical entries for
a multilingual MT system. In Proceedings of COLING’92, pp. 532-538, Nantes.

GOODMAN K. & NIRENBURG S. (1991). The KBMT Project .' A Case Study in Knowledge-
Based Machine Translation. San Mateo, California : Morgan Kaufmann.

LAFOURCADE M. (2002). Automatically populating acception lexical databases through bi-
lingual dictionaries and conceptual vectors. In Proceedings of Se’minaire Papillon 2002, Tokyo.

MANGEOT-LEREBOURS M., SERASSET G. & LAFOURCADE M. (2003). Construction col-

laborative d’une base lexicale multilingue - le projet Papillon. In Proceedings of TAL’2003,
number 2, pp. 151-176.

MEL’CUK I., CLAS A. & POLGUERE A. (1995). Introduction a la lexicologie explicative et
combinatoire. Louvain-la-Neuve : Duculot.

SERASSET G. (1994). Interlingual lexical organisation for multilingual lexical databases in
NADIA. In Proceedings of COLING’94, pp. 278-282, Kyoto.

TANAKA K. & UMEMURA K. (1994). Construction of a bilingual dictionary intermediated
by a third language. In Proceedings of COLING’94, pp. 297-303, Kyoto, Japan.

