<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Synchronisation syntaxe s&#233;mantique, des grammaires minimalistes cat&#233;gorielles (GMC) aux Constraint Languages for Lambda Structures (CLLS)</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>RECITAL 2005, Dourdan, 6&#8211;10 juin 2005
</p>
<p>Synchronisation syntaxe-s&#233;mantique,
des grammaires minimalistes cat&#233;gorielles (GMC) aux
Constraint Languages for Lambda Structures (CLLS)
</p>
<p>Amblard Maxime (1)
(1) LaBRI - Universit&#233; de Bordeaux 1
</p>
<p>351 cours de la lib&#233;ration
33405 Talence cedex amblard@labri.fr
</p>
<p>date de soutenance pr&#233;vue : novembre 2006
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>logique, grammaires minimalistes cat&#233;gorielles, &#955;-calcul, port&#233;e des quantificateurs, Constraint
Language for Lambda Structures
logic, minimalist grammars, &#955;-calculus, quantifiers scope, Constraint Language for Lambda
Structures
</p>
<p>R&#233;sum&#233; - Abstract
</p>
<p>Ces travaux se basent sur l&#8217;approche computationelle et logique de Ed Stabler (?), qui donne
une formalisation sous forme de grammaire du programme minimaliste de Noam Chomsky (?).
La question que je veux aborder est comment, &#224; partir d&#8217;une analyse syntaxique retrouver la
forme pr&#233;dicative de l&#8217;&#233;nonc&#233;. Pour cela, il faut mettre en place une interface entre syntaxe
et s&#233;mantique. C&#8217;est ce que je propose en utilisant les Grammaires Minimalistes Cat&#233;gorielles
(GMC) extension des GM vers le calcul de Lambeck. Ce nouveau formalisme permet une
synchronisation simple avec le &#955;-calcul.
</p>
<p>Parmi les questions fr&#233;quemment rencontr&#233;es dans le traitement des langues naturelles, j&#8217;interroge
la performance de cette interface pour la r&#233;solution des probl&#232;mes de port&#233;e des quantificateurs.
Je montre pourquoi et comment il faut utiliser un &#955;-calcul plus &#233;labor&#233; pour obtenir les dif-
f&#233;rentes lectures, en utilisant Constraint Languages for Lambda Structures -CLLS.
</p>
<p>This work is based on the computational and logical approach of Ed Stabler (?), which gives a
formalization of the minimalist program of Noam Chomsky (?). The question I want to solve
is, starting from a syntactic analysis, how to find the predicative forms of a sentence.
</p>
<p>I propose an interface between syntax and semantic by using Categorical Minimalists Gram-
mars (CMG) extension of the MG towards the Lambeck calculus and Constraint Language for
Lambda Structures (CLLS). This interface is powerful for the resolution of quantifier scope
ambiguities.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Amblard Maxime
</p>
<p>Introduction
Dans un premier temps, le formalisme des GMC, extension des grammaires minimalistes vers
le calcul de Lambeck, (?) et (?), sera pr&#233;sent&#233;. Puis une interface entre syntaxe et s&#233;mantique -
calcul des formes pr&#233;dicatives en logique d&#8217;ordre sup&#233;rieur - sera expos&#233;e. Mais cette interface
ne suffit pas pour conserver tous les calculs possibles avec les grammaires de Lambeck. Dans
une seconde partie, j&#8217;&#233;tudie une solution qui consiste &#224; utiliser des &#955;-termes structur&#233;s avec
contexte, via CLLS (?).
</p>
<p>1 Grammaires Minimalistes Cat&#233;gorielles - GMC
</p>
<p>1.1 Syntaxe
Ce formalisme, pr&#233;sent&#233; dans (?), est l&#8217;extension de la formalisation des grammaires minimal-
istes de Stabler (?). Tout comme ces derni&#232;res, les GMC sont lexicalis&#233;es et les expressions
sont des arbres finis, ordonn&#233;es avec projection. La projection est la relation entre les &#233;l&#233;ments
permettant de retrouver la t&#234;te du constituant.
</p>
<p>Les fonctions g&#233;n&#233;ratrices dans les grammaires minimalistes sont de deux types. La premi&#232;re
est la fusion qui permet d&#8217;agglom&#233;rer deux structures. La seconde est motiv&#233;e par Chomsky
comme la n&#233;cessit&#233; de v&#233;rifier certains traits, mettant en relation deux &#233;l&#233;ments de l&#8217;analyse,
permettant de faire monter dans la d&#233;rivation une feuille en position basse : le d&#233;placement.
</p>
<p>Fusion : &#233;limination de / ou \ - structurellement la concat&#233;nation droite ou gauche. Ce qui se
traduit sous forme de s&#233;quents par les formules suivantes :
</p>
<p>&#915;&#8594; x : A/B &#8710;&#8594; y : B
[e/]
</p>
<p>&#915;,&#8710;&#8594; xy : A
&#8710;&#8594; y : B &#915;&#8594; x : B\A
</p>
<p>[e\]
&#915;,&#8710;&#8594; xy : A
</p>
<p>Graphiquement, on ajoute une branche binaire &#224; notre arbre entre une nouvelle feuille et la
structure actuelle. Le nouveau sommet contiendra la r&#233;duction des types.
</p>
<p>D&#233;placement : cette op&#233;ration se base sur la notion de lien entre deux positions d&#8217;une d&#233;ri-
vation. Elle se d&#233;roule en deux temps. Dans la d&#233;rivation principale, on introduit certaines
hypoth&#232;ses. Dans une seconde d&#233;rivation, on construit un &#233;l&#233;ment de type &#215;. Si le type des
&#233;l&#233;ments autours du &#215; est le m&#234;me que celui des hypoth&#232;ses dans la d&#233;rivation principale, on
peut substituer dans cette derni&#232;re les &#233;l&#233;ments de la seconde.
</p>
<p>&#915;&#8594; w : A&#215;B &#8710;, x : A, y : B,&#8710;&#8242; &#8594; z : C
[e&#215;]
</p>
<p>&#8710;,&#915;,&#8710;&#8242; &#8594; let(x, y) = (pi1(w), pi2(w)) in z : C
O&#249; pi1 est la projection de la premi&#232;re composante et pi2 de la deuxi&#232;me.
</p>
<p>Selon l&#8217;hypoth&#232;se de Chomsky, les formes phonologiques et logiques fonctionnent s&#233;par&#233;ment.
Le d&#233;placement met en relation deux positions dans l&#8217;analyse et ces formes peuvent se substituer
soit en position basse, soit en position haute ce qui motive cette op&#233;ration.
</p>
<p>Graphiquement, on ajoute une branche unaire &#224; l&#8217;arbre pour marquer que la substitution a eu
lieu. Pour une meilleure visibilit&#233;, on marquera les projections reliant les deux d&#233;rivations.
</p>
<p>La section suivante pr&#233;sente un calcul s&#233;mantique parall&#232;le &#224; l&#8217;analyse syntaxique, dont un
exemple est expos&#233;.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Synchronisation syntaxe s&#233;mantique, GMC et CLLS
</p>
<p>1.2 Interface syntaxe - s&#233;mantique
</p>
<p>La s&#233;mantique utilis&#233;e est la forme pr&#233;dicative des constituants formant l&#8217;&#233;nonc&#233;. Pour l&#8217;obtenir,
le &#955;-calcul est la voie la plus naturelle. Cependant un &#955;-calcul classique ne permet pas d&#8217;aboutir
au r&#233;sultat escompt&#233; car les hypoth&#232;ses utilis&#233;es pour le d&#233;placement excluent une construction
it&#233;rative.
</p>
<p>L&#8217;analyse syntaxique est suppos&#233;e normalis&#233;e pour rencontrer l&#8217;objet puis le sujet, ce qui donne
l&#8217;ordre des variables dans le &#955;-terme du verbe.
</p>
<p>Les r&#232;gles de l&#8217;interface &#955;-termes contextu&#233;s. A chaque r&#232;gle syntaxique correspond une
r&#232;gle s&#233;mantique : la fusion est une application dans la contre-partie s&#233;mantique. On aura donc
[\E] ou [/E] devenant [&#8594; E].
L&#8217;&#233;quivalence du d&#233;placement est un peu plus complexe. Il faut distinguer deux situations. On
peut introduire soit une variable de type simple et dans ce cas, il faut faire une application stan-
dard, soit une variable de type sup&#233;rieur, ayant subi un type-raising, donc inverser l&#8217;application.
Ce qui se traduit par les deux r&#232;gles suivantes :
</p>
<p>&#8710; ` z : T &#8594; U &#8594; V &#915; &#8746; [x : T ] ` y : U
[RAISE/]
</p>
<p>&#8710; &#8746; &#915; ` z(&#955;x.y) : V
</p>
<p>&#8710; ` z : T &#8594; U &#8594; V &#915; &#8746; [x : T ] ` y : U
[NORAISE/]
</p>
<p>&#8710; &#8746; &#915; ` (&#955;x.y)(z) : V
Pour les hypoth&#232;ses, nous introduisons des variables neutres. Mais, avant qu&#8217;un d&#233;placement
n&#8217;intervienne, une &#955;-abstraction sur cette variable est n&#233;cessaire. Pour &#233;viter de perdre la posi-
tion relative &#224; cette variable lors d&#8217;applications pr&#233;c&#233;dentes, on utilise un contexte. Les variables
neutres ont une redondance dans le contexte et lors de leur extraction de ce dernier, on abstrait
sur la bonne variable. Les contextes se conservent par application et sont marqu&#233;s par le sym-
bole `.
</p>
<p>Interface syntaxe-s&#233;mantique SY N est le calcul syntaxique (&#215;, / et \) et SEM le calcul
s&#233;mantique (&#8594;, [RAISE] et [NORAISE]).
Chaque &#233;tape dans un calcul trouve sa contrepartie dans l&#8217;autre. Deux preuves, l&#8217;une dans SY N
et l&#8217;autre dans SEM sont dites synchronis&#233;es si : chaque feuille dans SEM est en bijection
avec une feuille de SY N et chaque &#233;tape et sa contrepartie sont r&#233;alis&#233;es en m&#234;me temps. Pour
synchroniser ces deux calculs, on construit pour la s&#233;mantique un arbre binaire en utilisant le
&#955;-terme associ&#233; dans la partie syntaxique.
</p>
<p>Exemple d&#8217;analyse s&#233;mantique synchronis&#233;e &#224; l&#8217;analyse syntaxique : Les enfants prendront une
pizza.
</p>
<p>items lexicaux &#955;-terme s&#233;mantique types syntaxique
prendre ` &#955;u&#955;v. prendre(v, u) (d\k\v)/d
les ` &#955;P&#955;Q&#8704;x. P (x)&#8594; Q(x) k &#215; d/n
une ` &#955;P&#955;Q&#8707;x.P (x) &#8743;Q(x) k &#215; d/n
pizza ` &#955;x.pizza(x) n
enfants ` &#955;x.enfant(x) n
infl ` &#955;P.Pres(P ) (k\v)/v</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Amblard Maxime
</p>
<p>prendre
</p>
<p>k\vk
</p>
<p>d
</p>
<p>k k\v
</p>
<p>(k\v)/v v
</p>
<p>v
</p>
<p>d\(k\v)
dd\(k/v)/d
</p>
<p>v
</p>
<p>v
</p>
<p>(kxd)/n n
</p>
<p>kxd
</p>
<p>n
</p>
<p>kxd
</p>
<p>(kxd)/n
enfantsLes
</p>
<p>une pizza
</p>
<p>` &#8704; z . enf(z)&#8658; Pres(&#8707; x. pizza (x) &#8743; prendre (v,x))
</p>
<p>x ` x
</p>
<p>x ` &#955;v. prendre (v, x)y ` y
</p>
<p>y ` &#955; u. prendre (y, u)` &#955; Q &#8707; x. pizza (x) &#8743; Q(x)
</p>
<p>y ` &#8707; x. pizza (x) &#8743; prendre (y,x)
</p>
<p>y ` &#8707; x. Pres(pizza (x) &#8743; prendre (y,x))
` &#955; Q &#8704; z. enf (z)&#8658; Q(x)
</p>
<p>` &#955;u&#955;v. prendre (v, u)
</p>
<p>x, y ` prendre (y, x)
</p>
<p>` &#955; P. Pres (P)
</p>
<p>` &#955; v&#8707; x. Pres(pizza (x) &#8743; prendre (v,x))
</p>
<p>SY N SEM
</p>
<p>La premi&#232;re partie de l&#8217;analyse syntaxique sature les positions du verbe avec des hypoth&#232;ses
dans les deux calculs. On obtient dans SEM : x, y ` prendre(y, x) o&#249; deux variables neutres
ont satur&#233; les positions dans le verbe et sont &#233;galement pr&#233;sente dans le contexte.
</p>
<p>Puis le d&#233;placement relatif &#224; l&#8217;objet est d&#233;clench&#233; dans SY N , marqu&#233; par une branche unaire.
Dans SEM , une &#955;-abstraction s&#8217;op&#232;re par extraction d&#8217;un &#233;l&#233;ment du contexte. Le d&#233;placement
permet l&#8217;arriv&#233;e effective de la forme logique, ici : ` &#955;Q&#8707;x.pizza(x) &#8743;Q(x). Une application
est donc possible et suit imm&#233;diatement cette arriv&#233;e dans la d&#233;rivation.
</p>
<p>La d&#233;rivation se poursuit avec l&#8217;inflexion qui apporte dans la d&#233;rivation la n&#233;cessit&#233; d&#8217;une hy-
poth&#232;se de type cas. Celle-ci correspond &#224; la v&#233;rification que le constituant introduit via sa
position aura le bon cas, en l&#8217;occurrence le nominatif pour le sujet. Elle d&#233;clenche le second d&#233;-
placement, avec projection des formes logiques et phonologiques. La contre-partie dans SEM
est une &#955;-abstraction puis une application.
</p>
<p>L&#8217;analyse syntaxique est termin&#233;e et acceptante. Dans le m&#234;me temps la formule s&#233;mantique
voulue a &#233;t&#233; construite : ` &#8704;z.enf(z)&#8658; Pres(&#8707;x.pizza(x) &#8743; prendre(v, x)).
Cependant, &#224; chaque analyse syntaxique ne correspond qu&#8217;une forme s&#233;mantique. Or, lorsqu&#8217;un
&#233;nonc&#233; contient des quantificateurs, plusieurs lectures sont possibles. La section suivante pr&#233;sente
une extension de l&#8217;interface pour calculer les diff&#233;rentes formules.
</p>
<p>2 Utilisation de &#955;-structures
</p>
<p>CLLS (Constraint Language for Lambda Structures) est un formalisme &#233;labor&#233; par Markus Egg
et al en Allemagne. L&#8217;id&#233;e est de repr&#233;senter les &#955;-termes par des arbres binaires et de relier ces
arbres entre eux par deux types de relations pour permettre la sous-sp&#233;cification.
</p>
<p>Il existe donc trois types de liens possibles entre les divers &#233;l&#233;ments de la structure.
</p>
<p>1. une arr&#234;te d&#8217;un arbre qui est une application d&#8217;un terme &#224; un autre, not&#233;e @.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Synchronisation syntaxe s&#233;mantique, GMC et CLLS
</p>
<p>2. une relation de substitution qui lie une variable &#224; une autre suite &#224; une application entre
deux arbres. Graphiquement ce lien sera une fl&#232;che en gras.
</p>
<p>3. une relation de dominance entre deux arbres, reliant une feuille d&#8217;un arbre au sommet
d&#8217;un autre, graphiquement celui-ci sera en pointill&#233;s. Elle intervient lorsque deux ar-
bres entrent en relation par application. La racine d&#8217;un arbre peut &#234;tre sujet de plusieurs
relations de dominance.
</p>
<p>Gr&#226;ce &#224; ces d&#233;finitions, la construction de repr&#233;sentations sous-sp&#233;cifi&#233;es entre les diff&#233;rents
constituants est permise. En effet, les relations de type 2 permettent de conserver l&#8217;ordre dans
lequel les variables sont substitu&#233;es et la relation de dominance (type 3) permet de modifier la
port&#233;e des quantificateurs.
</p>
<p>Exemple de CLLS et de r&#233;ductions : les enfants prendront une pizza
</p>
<p>prendre
</p>
<p>@
</p>
<p>@
</p>
<p>var x
</p>
<p>var y
</p>
<p>les enfants
</p>
<p>@
</p>
<p>pizzaune
</p>
<p>@
</p>
<p>@
! &quot;
</p>
<p>@
</p>
<p>&#8658; prendre
@
</p>
<p>@
</p>
<p>var x
</p>
<p>var y
</p>
<p>pizzaune
</p>
<p>@
</p>
<p>@
les enfants
</p>
<p>@
</p>
<p>@
!
</p>
<p>&quot;
</p>
<p>prendre
</p>
<p>@
</p>
<p>@
</p>
<p>var x
</p>
<p>var y
</p>
<p>pizzaune
</p>
<p>@
</p>
<p>@
</p>
<p>les enfants
</p>
<p>@
</p>
<p>@
!
</p>
<p>&quot;
</p>
<p>lecture lecture
nombre enfants = nombre pizzas une unique pizza&#955;-structures contextu&#233;s
</p>
<p>Pour synchroniser les GMC et CLLS, il faut conserver la notion de contexte dont on a vu la
n&#233;cessit&#233; dans la partie pr&#233;c&#233;dente.
</p>
<p>Pour cela, on ajoute sur la racine de la CLLS une liste repr&#233;sentant le contexte, not&#233;e entre
crochet : [ ]. On admettra la propri&#233;t&#233; selon laquelle les contextes sont s&#233;dentaires. Ce qui
signifie que lorsque la structure est li&#233;e par une application &#224; une autre structure, on maintient
le contexte sur la racine de la sous-structure.
</p>
<p>D&#233;tails du calcul dans la partie s&#233;mantique pour le d&#233;placement :
</p>
<p>(1) (2) (3)
</p>
<p>prendre
</p>
<p>@
</p>
<p>@
</p>
<p>var x
</p>
<p>var y
</p>
<p>pizzaune
</p>
<p>@
</p>
<p>@
!
</p>
<p>[x,y]
</p>
<p>prendre
</p>
<p>@
</p>
<p>@
</p>
<p>var x
</p>
<p>var y
</p>
<p>pizzaune
</p>
<p>@
</p>
<p>@
!
</p>
<p>[y]
</p>
<p>prendre
</p>
<p>@
</p>
<p>@
</p>
<p>var x
</p>
<p>var y
</p>
<p>pizzaune
</p>
<p>@
</p>
<p>@
!
</p>
<p>[y]
</p>
<p>(1) verbe charg&#233; de ses deux hypoth&#232;ses avec redondance dans le contexte</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Amblard Maxime
</p>
<p>(2) premi&#232;re phase du d&#233;placement, lambda-abstraction, une variable est lib&#233;r&#233;e en fonction
du contexte. Ici, celle correspondant &#224; l&#8217;objet est &#224; nouveau libre.
</p>
<p>(3) application avec l&#8217;arbre correspondant &#224; l&#8217;objet. Les deux arbres sont maintenant li&#233;s et on
peut r&#233;aliser une r&#233;duction de la relation de dominance. La variable esseul&#233;e dispara&#238;t.
</p>
<p>Cette repr&#233;sentation est n&#233;cessaire car, par d&#233;finition, l&#8217;apport logique d&#8217;un constituant dans les
grammaires minimalistes se fait toujours en position haute.
</p>
<p>Le d&#233;faut de ce mod&#232;le est qu&#8217;il est finalement trop souple. En effet, pour une phrase avec deux
quantificateurs, toutes les lectures (2! = 2) sont possibles. Par contre pour une phrase &#224; trois
quantificateurs, il n&#8217;y a pas 6 (3! = 6) lectures mais seulement 5. Une des solutions &#224; l&#8217;&#233;tude
est d&#8217;ajouter un ordre sur les relations de dominance. Pour cela il faut diff&#233;rencier ces relations
selon leur genre. Une classification sur ces derni&#232;res est en cours d&#8217;&#233;tude.
</p>
<p>Conclusion
A partir d&#8217;une id&#233;e calculatoire simple qui sous-tend la th&#233;orie de Stabler et qui encode le
programme minimaliste, on obtient un syst&#232;me formel pour l&#8217;analyse syntaxique, les GMCs.
A partir de cette analyse, j&#8217;ai propos&#233; une interface pour le calcul de la s&#233;mantique o&#249; chaque
utilisation de r&#232;gle dans la partie syntaxique trouve sa contre-partie dans celle s&#233;mantique, par
l&#8217;utilisation de &#955;-termes structur&#233;s avec contexte. L&#8217;utilisation du &#955;-calcul est naturelle pour le
calcul de la forme pr&#233;dicative d&#8217;un &#233;nonc&#233;, cependant, il ne suffit pas dans sa forme standard.
CLLS avec contexte est une solution viable qui permet de reprojeter la structure obtenue vers
plusieurs formules et d&#8217;obtenir les diff&#233;rentes lectures.
</p>
<p>Le concept de synchronisation entre analyse syntaxique et s&#233;mantique montre qu&#8217;il est difficile
de mettre en place un syst&#232;me formel r&#233;pondant &#224; toutes les caract&#233;ristiques de la langue, car il
se heurte &#224; de nombreuses questions. Celle de la port&#233;e des quantificateurs reste ouverte. Une
impl&#233;mentation &#224; partir de celui des GM devient envisageable.
</p>
<p>R&#233;f&#233;rences
</p>
<p>Amblard M., Lecomte A. et Retor&#233; C. (2004), Synchronization Syntax Semantic for a minimalism theory
Journ&#233;e S&#233;mantique et Mod&#233;lisation 2004,
</p>
<p>Chomsky Noam (1995), The Minimalist Program, Cambridge, MIT Press.
</p>
<p>Egg M., Koller A. et Niehren J. (2001) The Constraint Language for Lambda Structures, Journal of
Logic, Language, and Information, To appear.
</p>
<p>Heim I. et Kratzer A. (1998), Semantics en Generative Grammar, Oxford, Blackwell.
</p>
<p>Koller A., Burchardt A. et Walter S. (2004), Computational semantics, Actes de ESSLLI 2004.
</p>
<p>Lecomte A. et Retor&#233; C. (2001), Extending Lambeck Grammars, Actes de Algebraic Mahods in Lanuage
Processing 2003, 354-361
</p>
<p>Stabler Ed. (1997), Derivational Minimalism, Actes de Logical Aspect of Computational Linguistics
1996, vol 1328, Springer-Verlag.
</p>
<p>Stabler Ed. (1999), Remnant movement and structural complexity, Actes de Constraints and Resources
in Natural Language Syntax and Semantics 1999, 299-326.</p>

</div></div>
</body></html>