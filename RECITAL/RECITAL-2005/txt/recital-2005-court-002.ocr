RECITAL 2005, Dourdan, 6-10 juin 2005

Recherche d’information en langue arabe : inﬂuence des
parametres linguistiques et de pondération de LSA

Siham Boulaknadel (1,2), Fadoua Ataa-Allah (2)

(l)LINA FRE CNRS 2729 — Université de Nantes
2 rue la Houssiniere BP 92208 44322 Nantes cedex 03, France
siharn.boulaknadel@univ-nantes.fr
(2) GSCM — Université Mohammed V
BP 1014 Agdal Rabat-Maroc
fadoua_O 1 @yahoo .fr

Mots-clefs — Keywords

Recherche d’information, Analyse de la sémantique latente, Langue arabe, Racinisation

Information retrieval, Latent semantic analyses, Arabic language, Stemming

Résumé — Abstract

Nous nous intéressons a la recherche d’information en langue arabe en utilisant le modele de
l’analyse sémantique latente (LSA). Nous proposons dans cet article de montrer que le
traitement linguistique et la pondération des unités lexicales inﬂuent sur la performance de la
LSA pour quatre cas d’études: le premier avec un simple prétraitement des corpus; le
deuxieme en utilisant un anti-dictionnaire; le troisieme avec un racineur de l’arabe; le
quatrieme ou nous avons combiné l’anti-dictionnaire et le racineur. Globalement les résultats
de nos expérimentations montrent que les traitements linguistiques ainsi que la pondération
des unités lexicales utilisés améliorent la performance de LSA.

We are interested in information retrieval in Arabic language by using latent semantic
analysis method (LSA). We propose in this article to show that the linguistic treatment and
weighting of lexemes inﬂuence the performance of LSA. Four cases are studied: the first with
a simple pretreatment of the corpora; the second by using a stopword list; the third with arabic
stemmer; the fourth where we combined stopword list and arabic stemmer. Broadly the results
of our experiments show that the linguistic treatments as well as weighting of lexemes used
improve the performance of LSA.

Siham Boulaknadel, F adoua Ataa-Allah

1 Introduction

En recherche d’inforrnation, le probleme d’acces au texte est essentiellement dﬁ a l’ecart entre
les termes utilises dans les requétes et les documents. L’appariement entre requéte et
document se fait donc par l’intermediaire de leur representation respective. Le modele de
recherche le plus souvent utilise est le modele Vectoriel (Salton, 1983). Un des problemes de
ce modele reside dans l’hypothese d’independance faite sur les termes d’indexation : chaque
terrne d’indexation constitue une dimension de l’espace Vectoriel, sans consideration
d’eVentuelles relations entre termes.

En l’absence d’une connaissance approfondie de la collection de documents, la requéte peut
étre forrnule en des termes proches mais non identiques a ceux employes dans un document.
Un certain nombre de chercheurs se sont interesses a ce probleme, soit par l’utilisation de
reseaux semantiques qui consiste a recourir a une base de connaissances linguistiques
regroupant les mots semantiquement proches et structure selon des relations hyperonymiques
et/ou synonymiques (Grefenstette, 1994), soit par l’extension de requétes, operation par
laquelle un certain nombre de termes issus de documents de la collection sont ajoutes a une
requéte.

La troisieme possibilite que nous avons choisie, consiste a se servir des relations semantiques
implicites induites par les cooccurrences entre termes dans les documents. Ainsi le modele de
l’analyse semantique latente (LSA) (Deerwester et al., 1990) consiste a reduire le nombre de
dimensions de l’espace Vectoriel en s’appuyant sur le fait que les documents traitant des
memes sujets ont des Vocabulaires proches et sont donc proches dans l’espace Vectoriel.

Dans notre travail, nous avons selectionne les schemas de ponderation qui ameliorent la
performance de la methode LSA pour le calcul de similarite, dans le cas de cinq corpus de
petites tailles en langue arabe, tout en evaluant l’importance de differents parametres
linguistiques utilises.

2 Presentation de LSA

L’analyse semantique latente (LSA) consiste a reduire le nombre de dimensions de l’espace
Vectoriel par le biais d’une decomposition en Valeurs singulieres (SVD), de la matrice A en un
produit de trois autres matrices : A = U S VT

on U est une matrice orthogonale de taille (m x n) de description d’unite lexicale, V est une
matrice orthogonale de taille (n x n) de description d’unite textuelle et S une matrice
diagonale de taille (n x n).

A partir d’un certain nombre k<n, nous nous apercevons de l’existence de Valeurs singulieres
tres faibles et qui peuvent étre negligees dans la matrice.

De ce fait, il est demontre qu’il y a une meilleure approximation Ak de A qui est donnee par :
Ak = Uk Sk VkT

Cette reduction Va permettre de ne garder que les unites lexicales les plus significatives. A
noter que k est determine de facon empirique en fonction du corpus utilise et du degre de
performance Voulu.

Pour evaluer la performance de la LSA on utilise les deux mesures traditionnelles de precision
et de taux de rappel (Salton, 1989).

Recherche d ’inf0rmati0n en langue arabe .' inﬂuence des parametres linguistiques et de
ponderation en LSA

3 Parametres de pondération

La ponderation des unites lexicales consiste a transformer l’occurrence d’une unite lexicale
dans l’unite textuelle par une combinaison de ponderations locales L(i,j), indiquant
l’importance de l’unite lexicale i dans l’unite textuelle j et ponderations globales G(i),
indiquant l’importance de l’unite lexicale i dans l’ensemble des unites textuelles de la
collection.

Avec fij la frequence de l’unite lexicale i dans l’unite textuelle j, dfi le nombre d’unites
textuelles auxquelles l’unite lexicale i appartient, gfi le nombre total de fois ou l’unite lexicale

i apparait dans la collection, N est le nombre d’unites textuelles, M le nombre des termes dans
le corpus et pij est le rapport de fij par gfi.

Ponderation globale

N0r,n du Formule Interét
schema
Elle tient compte de la distribution des unites lexicales dans les
_ N plj log plj unites textuelles et perrnet d’attribuer un poids minimum aux _
Entropie — e termes qui sont distnbues de la meme facon dans toutes les unites
J 1°g(N) textuelles et un poids maximum aux termes qui sont concentres
dans quelques unites textuelles
1 Elle a pour effet de donner un poids eleve aux termes peu
Normal N 2 frequents et elle ne depend que de la somme des frequences au
§fiJ' carre et pas de la distribution de ces frequences.
gfi Elles ponderent tous deux les termes par le nombre des unites
Gﬂdf  textuelles differentes dans lesquelles ils apparaissent. La
’ difference entre les deux c’est que Gfldf augmente le poids des
mots frequents.
N
Idf 1°82 
das-

Figure 1 : Parametres de ponderation utilises

4 Traitements linguistiques

L’arabe est une langue semitique s’ecriVant de droite a gauche elle comporte 28 consonnes et
6 Voyelles standard (3 longues :1‘; 55 et 3 courtes : ‘/ _/ '/). Le traitement automatique de l’arabe
est difficile vu ses Variations orthographiques et sa structure morphologique complexe.

Siham Boulaknadel, F adoua Ataa-Allah

Deux approches sont utilisées dans l’analyse morphologique de l’arabe, la premiere que nous
avons choisie (Darwish, 2002) est une analyse morphologique assouplie ou racinisation qui
consiste a essayer de déceler si des suffixes ou preﬁxes ont été ajoutés a l’unité lexicale : par
exemple pour le duel (oi) dans (claim, deux professeurs), le pluriel des noms masculins (cu , ca)
dans (Q;-J», des professeurs) et féminins (sh!) dans (shbdm, musulmanes) ; la forme possessive
(U, as, ea) dans (944135, ses livres) et les preﬁxes dans les articles définis (dl, db, db, dis, dlé).

La deuxieme est une lemmatisation qui consiste a réduire les formes déclinées a une
représentation canonique.

5 Expérimentations

Notre obj ectif est de sélectionner les schémas de pondération qui améliorent la performance
de la méthode LSA pour le calcul de similarité, dans le cas des corpus de petite taille, tout en
évaluant l’importance de l’utilisation d’un anti-dictionnaire et d’un racineur.

5.1 Données

Afin de bien évaluer nos résultats sur les corpus de petite taille, nous avons choisi sur Internet
une Version arabe des contes partiellement voyellés de 1800 mots : << Le paysan énergique »1,
de H.Darwish << Fleurs du miel »2 , <<Musique de la nature >> 3 et << Sous les branches >> 4 de
K.Abid et «Les chaussures en bois>> 5 de J.alhamad. Nous avons appliqué la transcription de
Buckwalter qui consiste a transcrire l’alphabet arabe en alphabet latin (Buckwalter, 2002).
Nous avons décidé de construire un anti-dictionnaire général qui contient l’ensemble des
unités lexicales grammaticales extraites du dictionnaire arabe6 ensuite nous avons choisi de
formuler les requétes avec aussi peu de variations que possible par rapport a la formulation
d’origine. L’ensemble des requétes que nous avons établi est de l’ordre de 71 requétes.

5.2 Calculs des courbes

Nous avons segmenté par la suite chacun de ces contes en paragraphes, ce qui nous a permis
de construire cinq corpus dont le nombre d’unités textuelles (paragraphes) Varie entre 8 et 24.
Apres avoir transformer ces contes et requétes textuelles en mode Vectoriel, nous avons
calculé la précision moyenne sur l’ensemble des requétes de chaque corpus, en faisant Varier
k de 2 a r (le rang de la matrice correspondant a chaque corpus). Les paragraphes retournés
étaient ceux dont le Vecteur faisait un angle de cosinus supérieur a un seuil de 0.9 avec les
Vecteurs requétes.

5.3 Résultats

Nous avons effectué des tests pour Vingt trois schémas de pondération, plus un autre test ou
nous avons utilisé la méthode LSA sans appliquer aucune pondération a la matrice originale.
Effectivement, d’apres les tests appliqués sur le corpus << Musique de la nature >>, nous avons
remarqué que la performance de la LSA sans pondéré la matrice originale est relativement

http://www.awu-dam.org/book/99/child99/5 -a-d/book99-ch008.htm
http://www.awu-dam.org/book/99/child99/1 1-h-a/book99-ch001.htm
http://www.awu-dam.org/book/99/child99/1 1-h-a/book99-ch003 .htm
http://www.awu-dam.org/book/99/child99/1 1-h-a/book99-ch012.htm
http://www.comp.leeds.ac.uk/latifa/research.htm
http://www.almeshkat.net/books/archive/books/muajm arabia.zip

ONLII-PbJI\it—

Recherche d ’inf0rmati0n en langue arabe .' inﬂuence des parametres linguistiques et de
pondération en LSA

inférieure de 6% par rapport a celle ou nous appliquons le schéma de pondération
‘Pondération Local Logarithmique * Entropie de Dumais’ ; et les schémas ‘Pondération Local
Logarithmique*Entropie Globale’ et ‘Pondération Local Logarithmique*GFIDF’.

:,um.-.- -mm

=,1m.5- -mm

 

Figure 2 : L’inﬂuence des schémas de pondération sur la performance de la LSA

Pour évaluer l’importance de l’utilisation d’un anti-dictionnaire et d’un racineur, nous avons
extrait la précision maximale de l’ensemble des précisions moyennes résultantes des tests
réalisés. Nous avons présenté l’éVolution de la précision moyenne de la méthode LSA, en
appliquant les deux schémas de pondération << Tf x IDF >> et << LTC », pour le corpus << Sous
les branches >> sur la ﬁgure 3-(a) et sur la ﬁgure 3-(b) pour le corpus << Musique de la nature >>.

(a)

(b)

 

Figure 3 : Evolution de la précision en fonction du nombre de dimensions de l’espace pour
un seuil de 0.9

Siham Boulaknadel, F adoua Ataa-Allah

Globalement les courbes calculées montrent que la performance de LSA s’améliore en
utilisant soit un anti-dictionnaire soit un racineur, soit les deux. Néanmoins pour certaines
requétes les traitements linguistiques n’améliorent pas la performance de la LSA. Ceci est dﬁ
au racineur qui échoue a traiter certains pluriels et verbes. Par exemple pour les pluriels
irréguliers des noms comme << déla, enfant >> << dlélai, enfants >> qui ne sont pas une combinaison
des formes singulieres. Pour les verbes irréguliers comportant des consonnes particulieres
dites faibles (3, 1, sf) qui sont soit conservée, soit remplacée ou éliminée lors de leur
déclinaison, exemple «J15, il a dit >> «U335, il dit >> . Vu aussi la petite taille de nos corpus, par
consequent on peut dire que la LSA reste sensible dans le cas ou on a peu de données a traiter.

6 Conclusion

Nous avons proposé une approche pour améliorer la méthode de l’analyse sémantique latente
(LSA) en intégrant les parametres linguistiques et de pondération. L’évaluation a montré
l’intérét d’appliquer conjointement le traitement linguistique et la pondération des unités
lexicales pour pouvoir améliorer la performance de la LSA. Dans la suite de nos travaux, nous
envisageons d’étendre cette étude a l’utilisation de la lemmatisation.

Références

Buckwalter T.(2002), Buckwalter Arabic Morphological Analyzer Version 1.0
http://www.ldc.upenn.edu/Catalog/CatologEntry.jsp?catologId=LDC2002L49.

7

Darwish K. (2002), Building a Shallow Arabic Morphological Analyzer in One Day,
Proceedings of the workshop on Computational Approaches to Semitic Languages in the 40th
Annual Meeting of the Association for Computational Linguistics (ACL-02) , pp. 47-54.

Deerwester S, Dumais S.T., Furnas G.W., Landauer T.K., Hrashman R. (1990), Indexing by
latent semantic analysis, Journal of the american society for information science, Vol.41, pp.
391-407.

Grefenstette G. (1994), Explorations in automatic thesaurus discovery, New York, Kluwer
Academic Publishers.

Salton G. (1989), Automatic text processing the transformation analysis and retrieval of
information by computer, New York, Addison-Wesley.

Salton G. (1983), An Introduction to Modern Information Retrieval, New York, McGraw-
Hill.

