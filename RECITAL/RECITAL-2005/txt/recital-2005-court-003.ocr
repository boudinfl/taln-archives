RECITAL 2005, Dourdan, 6-10 juin 2005

Etiquetage morpho-syntaxique des textes arabes par modéle
de Markov caché

Abdelhamid EL J IHAD (1), Abdellah YOUSFI (2)
(1),(2) Institut d’ études et de recherches pour l’arabisation
Université Mohamed V, Rabat, Maroc
(1) eljihad@ifrance.com
date de soutenance prévue : 2007
(2) yousﬁ240ma@yahoo.fr
date de soutenance : 19 juin 2001

Mots-clefs — Keywords

Corpus, jeu d’étiquettes, Etiquetage morpho-syntaxique, texte arabe, modele de Markov caché
Corpus, the set of tags, the morpho-syntactic tagging, arabic text, Hidden Markov Model

Résumé - Abstract

L’ étiquetage des textes est un outil tres important pour le traitement automatique de langage, il
est utilisé dans plusieurs applications par exemple l’analyse morphologique et syntaxique des
textes, l’indexation, la recherche documentaire, la voyellation pour la langue arabe, les modeles
de langage probabilistes (modeles n-classes), etc.

Dans cet article nous avons élaboré un systeme d’étiquetage morpho-syntaxique de la langue
arabe en utilisant les modeles de Markov cachés, et ceci pour construire un corpus de référence
étiqueté et représentant les principales difﬁcultés grammaticales rencontrées en langue arabe
générale.

Pour l’estimation des parametres de ce modele, nous avons utilisé un corpus d’apprentissage éti-
queté manuellement en utilisant un jeu de 52 étiquettes de nature morpho-syntaxique. Ensuite
on procede a une amélioration du systeme grace a la procédure de réestimation des parametres
de ce modele.

The tagging of texts is a very important tool for various applications of natural language pro-
cessing : morphological and syntactic analysis of texts, indexation and information retrieval,
vowelling of arabic texts, probabilistic language model (n-class model).

In this paper we have used the Hidden Markov Model (HMM) to tag the arabic texts. This
system of tagging is used to build a large labelled arabic corpus. The experiments are carried in
the set of the labelled texts and the 52 tags of morpho-syntactic nature, in order to estimate the
parameters of the HMM.

1 Introduction

Le developpement des corpus electroniques a beneﬁcie ces demieres annees d’un appui vigour-
eux et un soutien ﬁnancier important, de la communaute du traitement automatique des langues
naturelles, qui voit la une etape indispensable pour la mise au point de systemes de TAL ro-
bustes. Aujourd’hui de vaste corpus de textes electroniques etiquetes sont disponibles et sont
majoritairement de langue anglaise. Ceci a permis l’essor considerable des traitements automa-
tiques concernant cette langue; des outils d’interrogation de ces corpus ainsi que des outils
d’annotations proprement dits (etiqueteurs, analyseurs syntaxique, etc.) se repandent. Leurs
equivalents en frangais commence a apparaitre egalement [Habert et al 1997].

Pour la langue arabe, il n’existe pas a ce jour de corpus etiquete aisement disponible. Par
consequent les recherches linguistiques qui ont recours a des corpus etiquetes sont donc encore
rares. Motive par ce manque, l’Institut d’Etudes et de Recherches pour l’Arabisation (IERA)
a entrepris un projet de recherche dont l’objectif est la constitution d’un corpus de reference
etiquete et representant les principales difﬁcultes grammaticales rencontrees en langue arabe
generale. La disponibilite de ce corpus a l’institut, va donner le coup d’envoi aux divers travaux
de recherches linguistiques qui utilisent les corpus etiquetes. Un corpus etiquete est un corpus
dans lequel on associe a des segments de textes (le plus souvent des mots) d’autres informations
de quelque nature qu’elle soit morphologique, syntaxique, semantique, prosodique, critique, etc
[Veronis 2000] [Vergne et al 1998].

En particulier, dans la communaute du traitement automatique des langues naturelles, quand
on parle de corpus etiquete on fait reference le plus souvent a un document 011 chaque mot pos-
sede une etiquette morpho-syntaxique et une seule.

L’ etiquetage morpho-syntaxique automatique est un processus qui s’effectue generalement en
trois etapes [Minh et al 2003][Rajman et al 2000]: la segmentation du texte en unites lexicales,
l’etiquetage a priori, la desambiguisation qui permet d’attribuer, pour chacun des unites lexi-
cales et en fonction de son contexte, l’etiquette morpho-syntaxique pertinente.

La taille du jeu d’etiquettes, la taille du corpus d’apprentissage sont autant de facteur importants
pour une bonne performance du systeme d’etiquetage [Chanod 1995][Claud 1995].

En general, il existe deux methodes pour l’etiquetage morpho-syntaxique :

- Methode a base de regles [Claud 1995][Bril 1992].

- Methode probabiliste.

Dans cet article nous avons utilise la deuxieme approche.

2 Méthode probabiliste

Le choix de l’etiquette la plus probable en un point donne se fait au regard de l’historique des
dernieres etiquettes qui viennent d’etre attribuees. En general cet historique se limite a une ou
deux etiquettes precedentes. Cette methode suppose qu’on dispose d’un corpus d’apprentissage
qui doit etre d’une taille sufﬁsante pour permettre une estimation ﬁable des probabilites [Habert
et al 1997].

Soit Ph = w1...wT une phrase constituee des mots wl, ..., 1127-, E = {(2751, ..., etN} un jeu
d’ etiquettes.

L’ etiquetage morpho-syntaxique de la phrase Ph par des etiquettes appartenant a E et s’appuyant

Etiquetage morpho-syntaxique des textes arabes par modele de Markov caché

sur l’approche probabiliste , consiste a trouver l’ensemble d’étiquettes et*1...et*T associés a la
phrase Ph tel que :

et*1...et*T = arg max Pr(w1...wT,et1...etT) (1)
6t1...6tT

Pour faciliter la résolution de ce probleme on utilise les modeles de Markov cachés d’ordre 1.

3 Etiquetage morpho-syntaxique par modéle de Markov caché
d’ordre 1

Un modele de Markov caché d’ordre 1 est un double processus (Xt, Y;),;Z1 avec :

o X,; est une chaine de Markov d’ordre 1 a valeur dans un ensemble d’états ﬁni Q = {q1, ..., q N},
X,; vériﬁe :

P7‘(Xt+1 = Qj/X1 = Q1, ---,Xt = Q2‘) = P7‘(Xt+1 = Qj/X2: = G2‘) = aij-

Pr(X1 = q,-) = 7r,-, 2' = 1, ...,N.

a,-j est la probabilité de transition entre les états qi et qj.

7r,- est la probabilité que l’états qi est un état initial.

0 Yt est un processus observable a valeurs dans un ensemble mesurable Y, Y; vériﬁe :

P7‘(Yt = yt/X1 = Q1, ---, X2: = Q1‘, Y1 = :91, ---, 34-1 = yt_1) = P7‘(Yt = yt/Xt = G2‘) =
bi(yt) = bit-

bit est la probabilité d’émission de l’observation y,, a partir de l’état q,-.

Dans la suite on supposera que le double processus :

X,; = et,-t représentant les étiquettes appartenant a l’ensemble E,

Y; = wt représentant les mots de notre vocabulaire V = {w1, ..., wL},

est un modele de Markov caché d’ordre 1.

Remarque :

Ce modele est déﬁni entierement par un vecteur de parametres note A = (H, A, B).

o H = {7r1, ..., 7rN} l’ensemble des probabilités initiales.

o A = (aij)1Si,jSN la matrice des probabilités de transition entre les étiquettes.

o B = (b,-,;)15,-SN et 1 g t 3 L : la matrice des probabilités d’émission des mots a partir des
étiquettes.

4 Procédure d’apprentissage (Estimation des paramétres)

L’ apprentissage est une opération nécessaire pour un systeme de reconnaissance de formes
(en particulier le systeme d’étiquetage), il permet d’estimer les parametres du modele A =
(H, A, B). Un apprentissage incorrect ou insufﬁsant diminue la performance du systeme d’ étiqu-
etage. Pour préparer le corpus d’apprentissage, on procede par approximations successives. Un
premier corpus d’apprentissage, relativement court, permet d’étiqueter un corpus beaucoup plus
important. Celui-ci est corrigé, ce qui permet de réestimer les probabilités, il sert donc a un sec-
ond apprentissage, et ainsi de suite.

En général il existe trois méthodes d’estimation de ces parametresl :

o L’estimation par maximum de vraisemblance (Maximum Likelihood Estimation), elle est real-
isée par l’algorithme de Baum-Welch [Baum 1972] ou l’algorithme de Viterbi [Celeux 92].

1Pour plus de détaille sur ces fonnule voir [Yousﬁ 2001]

o L’estimation par maximum a posteriori [John Arice].

o L’estimation par maximum d’information mutuel [Bahl et al 86,87][Kapadia 93].

Dans notre cas nous avons utilisé l’estimation par maximum de vraisemblance car c’est la plus
utilisée et la plus facile a calculer.

Alors si on prend un ensemble d’apprentissage R = {Ph1, ..., PhK}, constitué des phrases
Phl, ..., PhK étiquetées manuellement, les formules d’estimation des parametres du modele
A = (H, A, B) sont données par :

25:1 le nombre de fois ou la transition eti etj est dans la phrase Phn

aij 2 25:1 le nombre de fois o1‘1 l’état eti est atteint le long de la phrase Phn

25:1 6[l’étiquette eti est un état initial dans la phrase Phn]
7T1‘ =
K
: 2:116 nombre de fois ou le mot wt a l’étiquette et,- le long de la phrase Phn

b.
it 25:1 le nombre de fois o1‘1 l’état eti est atteint le long de la phrase Phn
avec :
6[ ] _ 1 si l’événement x est vrai
1; _ 0 sinon

5 Etiquetage automatique par algorithme de Viterbi

Pour un calcul plus rapide du chemin optimalz dans la formule (1) nous avons utilisé 1’ algorithme
de Viterbi [For 73].
On note par :
6,;(etj) = etrriaggit Pr(w1...w,;, et,-1...et,-t)

avec et,-t = etj.
Cette formule devient [Yousﬁ 2001]:

6t(€tj) =  6,;_1(et,-).a,-j.bj (wt)

On calcule cette formule pour toutes les valeurs t = 1, ..., T et j = 1, ..., N.
Enﬁn le chemin optimal est obtenu a l’aide d’un calcul récursif sur cette formule.

6 Expérimentation

6.1 Données d’apprentissage

Le travail expérimental a été réalisé en trois grandes étapes :

1) étape de deﬁnition du jeu d’étiquettes et de construction de corpus d’apprentissage.

La deﬁnition de notre propre jeu d’étiquettes morpho-syntaxique a été particulierement délicate,
cette phase a été réalisée en collaboration avec des linguistes pour satisfaire au besoin des pro-
jets en cours de réalisation a IERA. Ce jeu d’étiquettes est constitué de 52 étiquettes de nature

2Nous cherchons ce chemin dans un réseau d’étiquettes. Ce réseau est construit de tel fagon 51 Ce que pour
une phrase donnée, chaque chemin de ce réseau correspond a la probabilité que cette phrase ales étiquettes de ce
chemin (Pr(w1 ...wt, et,-1 ...et1-t  Le chemin associé a la probabilité maximale est nomme chemin optimal.

Etiquetage morpho-syntaxique des textes arabes par modele de Markov caché

morpho-syntaxique (comme par exemple ism-faail, ism-mafaoul, harf nasb,...).

Le corpus d’apprentissage est constitué d’un ensemble de phrases représentant les principales
regles morphologiques et syntaxiques utilisées en langue arabe générale. Ce corpus a été éti-
queté manuellement par un linguiste.

2) étape d’estimation des parametres du modele de Markov cache.

3) étape d’étiquetage automatique et réestimation des parametres du modele de Markov caché.
Pour réaliser ces deux demieres étapes, nous avons développé une application en langage C,
comportant deux modules, module d’apprentissage et module d’étiquetage automatique qui
permet d’étiqueter automatiquement un corpus brut, ce dernier est corrigé manuellement pour
servir a une réestimation des parametres du modele de Markov caché.

Les programmes sont évalués sur deux versions de textes voyellé et non voyellé.

6.2 Résultats

Le taux d’erreur est mesuré sur deux ensembles :

Ensemblel constitué des memes phrases que l’ensemble d’apprentissage mais sans étiquettes,
Ensemble2 constitué de phrases (sans étiquettes) différentes de celles de l’ensemble d’apprenti-
ssage.

H | Ensemblel | Ensemble2 

Textes voyellés 1,76% 2%
Textes non voyellés 2,5% 3%

Table 1: Les taux d’erreur d’étiquetage automatique.

On remarque que dans le cas des textes non voyellés le taux d’erreur augmente par rapport
aux textes voyellés, a cause de l’augmentation de l’ambigu'1'té (un mot peut prendre plusieurs
étiquettes). Pour le reste des erreurs, elles sont dues au manque de données d’apprentissage (il
existe des mots et des transitions entre des étiquettes qui ne sont pas représentées dans le corpus
d’apprentissage).

7 Conclusions et perspectives

En analysant les résultats trouvés, nous avons remarqué que la majorité d’erreurs d’étiquetage
provient essentiellement du probleme de manque ou d’insufﬁsance de données d’apprentissage.
Dans notre cas il existe deux type de problemes de manque de données :

0 un ou plusieurs mots, appartenant a la phrase a étiqueter par ce systeme, n’existent pas dans
le lexique, c’est a dire nous n’avons pas une estimation des probabilités d’observation de ces
mots dans tous les états.

o une ou plusieurs étiquettes n’ont pas de prédécesseurs dans la phrase a étiqueter automatique-
ment, c’ est a dire nous n’ avons pas une estimation des probabilités de transition de ces étiquettes
vers tous les autres étiquettes du systeme.

Dans la suite de notre travail, nous allons proceder a deux solutions pour remedier a ces deux
problemes :

la premiere est d’introduire une sorte d’analyse morphologique qui s’appuit sur les formes mor-
phologiques des mots pour pouvoir identiﬁer les étiquettes des mots inconnus.

La deuxieme est d’introduire une base de regles syntaxiques qui déﬁnie les transitions possibles
entre les différents étiquettes.

Références

L.R. Bahl, P.F. Brown, P.V. de Souza & R.L. Mercer 2 "Maximum mutual information estimation in
hidden Markov model parameters for speech recognition ", Proc. ICASSP, pp. 49-52, Tokyo, 1986.

L. R. Bahl, P. F. Brown, P.V De Souza and R. L. Mercer 2 "Estimating HMM parameters so as to

maximise speech recognition accuracy ", Research Report RC-13121, IBM TJ Watson Research Center,
9/10/1987.

L. Baum 2 "An inequality and association maximization technique in statistical estimation for proba-
bilistic functions of Markov processes ", Inequality, vol. 3, 1972.

G. Celux, J. Clairambault 2"Estimation de chaines de Markov cache’es: méthodes et problemes ,
J ournées thématiques CNRS sur les approches markoviennes en signal et images, Septembre 1992.

J ean-Pierre Chanod and Pasi Tapanainen 2 "Tagging French - comparing a statistical and a constraint-
based method", Proceeding of the seventh Conference of the European Chapter of the Association for
Computatinal

Linguistics (EACL.95), Dublin, Ireland. pp.149-156, 1995.
Claude De Loupy 2 "La me’thode de’tiquetage d ’Eric Brill". Revue T.A.L, 1995, Vol.36, nf 1-2, pp.37-46

Eric Brill 2 "A simple rule-based part of speech tagger". Proceedings of the third Conference on Applied
Natural Language Processing, Trento, Italy. pp.152-155. Avril 1992.

Fornay D. R. 2 "The Viterbi Algorithm ", Proc. IEEE, vol. 61, n 3, mai 1973.

Benoit Habert, Adeline Nazarenko, André Salem 2 "Les linguistiques de corpus" , Armand colin /
Masson.Paris, 1997.

John Rice 2 "Mathematical Statistics and data
analysis ", page 511-540.

S. Kapadia, V. Valtchev & S.J. Young 2 "MMI training for continuous phoneme recognition on the TIMIT
database ", Proc. ICASSP, pp. H.491-494, Minneapolis, 1993.

Thi Minh Huyen Nguyen, Laurent Romary, Xuan Luong Vu 2 "Une e’tude de cas pour l ’e’tiquetage
morpho-syntaxique de textes vietnamiens" , 5e conférence sur le traitement Automatique du Langage
Naturel (TALN2003), Batz-sur-Mer, 11-14 juin, 2003.

Patrick Paroubek et Martin Rajman 2 "Etiquetage morpho-syntaxique. " , Ingénierie des langues. pp.131-
150, Paris, HERMES Sciences Europe.

Jacques Vergne, Emmanuel Giguet2 "Regards the’oriques sur le ”Tagging” " , 5e conférence sur le
traitement Automatique du Langage Naturel (TALN98), Paris, France, 10-12 juin, 1998.

Jean Veronis 2 "Annotation automatique de corpus : panorama et état de la technique" , Ingénierie des
langues. pp.111-128. Paris, HERMES Sciences Europe.

A. Yousﬁ 2 "Introduction de la Wtesse d ’élocution dans un modele de reconnaissance automatique de la
parole " , These de doctorat, 19 juin 2001.

