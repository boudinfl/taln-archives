RECITAL 2005, Dourdan, 6-1 0ju1'n 2005

Etiquetage morpho-syntaxique des textes arabes par modéle
de Markov cache

Abdelhamid EL J IHAD (1), Abdellah YOUSFI (2)
(l),(2) Institut d’etudes et de recherches pour l’arabisation
Universite Mohamed V, Rabat, Maroc
(1) eljihad@ifrance.com
date de soutenance prevue : 2007
(2) yousﬁ240ma@yahoo.fr
date de soutenance : 19 juin 2001

Mots-clefs — Keywords

Corpus, jeu d’etiquettes, Etiquetage morpho—syntaxique, texte arabe, modele de Markov cache
Corpus, the set of tags, the morpho—syntactic tagging, arabic text, Hidden Markov Model

Resume - Abstract

L’ etiquetage des textes est un outil tres important pour le traitement automatique de langage, il
est utilise dans plusieurs applications par exemple l’analyse morphologique et syntaxique des
textes, l’indexation, la recherche documentaire, la voyellation pour la langue arabe, les modeles
de langage probabilistes (modeles n—classes), etc.

Dans cet article nous avons elabore un systeme d’etiquetage morpho—syntaxique de la langue
arabe en utilisant les modeles de Markov caches, et ceci pour construire un corpus de reference
etiquete et representant les principales difﬁcultes grammaticales rencontrees en langue arabe
generale.

Pour l’estimation des parametres de ce modele, nous avons utilise un corpus d’apprentissage eti-
quete manuellement en utilisant un jeu de 52 etiquettes de nature morpho—syntaxique. Ensuite
on procede a une amelioration du systeme grace a la procedure de reestimation des parametres
de ce modele.

The tagging of texts is a very important tool for various applications of natural language pro-
cessing : morphological and syntactic analysis of texts, indexation and information retrieval,
vowelling of arabic texts, probabilistic language model (n—class model).

In this paper we have used the Hidden Markov Model (HMM) to tag the arabic texts. This
system of tagging is used to build a large labelled arabic corpus. The experiments are carried in
the set of the labelled texts and the 52 tags of morpho—syntactic nature, in order to estimate the
parameters of the HMM.

649

650

1 Introduction

Le developpement des corpus electroniques a beneﬁcie ces demieres annees d’un appui vigour-
eux et un soutien ﬁnancier important, de la communaute du traitement automatique des langues
naturelles, qui voit la une etape indispensable pour la mise au point de systemes de TAL ro-
bustes. Aujourd’hui de vaste corpus de textes electroniques etiquetes sont disponibles et sont
maj oritairement de langue anglaise. Ceci a permis l’essor considerable des traitements automa-
tiques concernant cette langue; des outils d’interrogation de ces corpus ainsi que des outils
d’annotations proprement dits (etiqueteurs, analyseurs syntaxique, etc.) se repandent. Leurs
equivalents en frangais commence a apparaitre egalement [Habert et al 1997].

Pour la langue arabe, il n’existe pas a ce jour de corpus etiquete aisement disponible. Par
consequent les recherches linguistiques qui ont recours a des corpus etiquetes sont donc encore
rares. Motive par ce manque, l’Institut d’Etudes et de Recherches pour l’Arabisation (IERA)
a entrepris un projet de recherche dont l’objectif est la constitution d’un corpus de reference
etiquete et representant les principales difﬁcultes grammaticales rencontrees en langue arabe
generale. La disponibilite de ce corpus a l’institut, Va donner le coup d’envoi aux divers travaux
de recherches linguistiques qui utilisent les corpus etiquetes. Un corpus etiquete est un corpus
dans lequel on associe a des segments de textes (le plus souvent des mots) d’autres informations
de quelque nature qu’elle soit morphologique, syntaxique, semantique, prosodique, critique, etc
[Veronis 2000] [Vergne et al 1998].

En particulier, dans la communaute du traitement automatique des langues naturelles, quand
on parle de corpus etiquete on fait reference le plus souvent a un document on chaque mot pos-
sede une etiquette morpho—syntaxique et une seule.

L’ etiquetage morpho—syntaxique automatique est un processus qui s’effectue generalement en
trois etapes [Minh et al 2003][Rajman et al 2000]: la segmentation du texte en unites lexicales,
l’etiquetage a priori, la desambiguisation qui permet d’attribuer, pour chacun des unites lexi-
cales et en fonction de son contexte, l’étiquette morpho—syntaxique pertinente.

La taille du jeu d’etiquettes, la taille du corpus d’apprentissage sont autant de facteur importants
pour une bonne performance du systeme d’etiquetage [Chanod 1995][Claud 1995].

En general, il existe deux méthodes pour l’etiquetage morpho—syntaxique :

— Méthode a base de regles [Claud 1995][Bril 1992].

— Méthode probabiliste.

Dans cet article nous avons utilise la deuxieme approche.

2 Méthode probabiliste

Le choix de l’etiquette la plus probable en un point donne se fait au regard de l’historique des
demieres étiquettes qui viennent d’étre attribuees. En general cet historique se limite a une ou
deux etiquettes precédentes. Cette methode suppose qu’on dispose d’un corpus d’apprentis sage
qui doit étre d’une taille sufﬁsante pour permettre une estimation ﬁable des probabilites [Habert
et al 1997].

Soit Ph : w1...wT une phrase constituee des mots w1,...,wT, E : {e261, ..., etN} un jeu
d’etiquettes.

L’ etiquetage morpho—syntaxique de la phrase Ph par des etiquettes appartenant a E et s’ appuyant

Etiquetage morpho—syntaxique des textes arabes par modele de Markov cache

sur l’approche probabiliste , consiste a trouver l’ensemble d’etiquettes et*1...et*T associes a la
phrase Ph tel que :

et*1...et*T : arg trnax P7“(w1...wT,et1...etT) (l)
6 1...6 T

Pour faciliter la resolution de ce probleme on utilise les modeles de Markov caches d’ordre 1.

3 Etiquetage morpho-syntaxique par modéle de Markov caché
d’0rdre 1

Un modele de Markov cache d’ordre 1 est un double processus (Xt, Y,;)t21 avec :

o Xt est une chaine de Markov d’ordre 1 a valeur dans un ensemble d’etats ﬁni Q : {(11, ..., qN},
Xt veriﬁe :

P7“(Xt+1 : €13‘/X1 : Q1,---7X2: : Q1‘) : P7“(Xt+1 : €13‘/Xt : €11‘): aij-

P7“(X1 : qi) : 7r,~, 2' : 1, ..., N.

a,-j est la probabilité de transition entre les états q,- et qj.

7r,- est la probabilite que l’etats q,- est un etat initial.

0 Yt est un processus observable a valeurs dans un ensemble mesurable Y, Yt veriﬁe :

P7"(Yt : yt/X1 : Q1,---7X2: : C1133/1 : 91, ---7 Yt—1 : yt—1) : P7"(Yt : yt/Xt : Q1‘) :
bi(?Jt) : bit-

bit est la probabilite d’emission de l’observation gt a partir de l’etat q,-.

Dans la suite on supposera que le double processus :

X ,5 : et,-t representant les étiquettes appartenant a l’ensemble E,

Yt : wt représentant les mots de notre vocabulaire V : {w1, ..., wL},

est un modele de Markov cache d’ordre 1.

Remarque :

Ce modele est deﬁni entierement par un vecteur de parametres note A : (H, A, B

o H : {7r1, ..., 7rN} l’ensemble des probabilites initiales.

o A : (aij)1gi,jg N 1a matrice des probabilites de transition entre les étiquettes.

o B : (b,-t)1S,-SN et 1 3 t 3 L : la matrice des probabilites d’emission des mots a partir des
étiquettes.

4 Procedure d’apprentissage (Estimation des paramétres)

L’ apprentissage est une operation necessaire pour un systeme de reconnaissance de formes

(en particulier le systeme d’étiquetage), il permet d’estimer les parametres du modele A :

(H, A, B). Un apprentissage incorrect ou insufﬁsant diminue la performance du systeme d’etiqu—
etage. Pour preparer le corpus d’apprentissage, on procede par approximations successives. Un

premier corpus d’apprentis sage, relativement court, permet d’etiqueter un corpus beaucoup plus

important. Celui—ci est corrige, ce qui permet de reestimer les probabilites, il sert donc a un sec-

ond apprentissage, et ainsi de suite.

En general il existe trois methodes d’estimation de ces parametresl :

0 L’estimation par maximum de vraisemblance (Maximum Likelihood Estimation), elle est real-

isée par l’algorithme de Baum—Welch [Baum 1972] ou l’algorithme de Viterbi [Celeux 92].

1Pour plus de détaille sur ces formule voir [Yousﬁ 2001]
651

652

o L’estimation par maximum a posteriori [John Arice].

0 L’estimation par maximum d’information mutuel [Bahl et al 86,87] [Kapadia 93].

Dans notre cas nous avons utilise l’estimation par maximum de Vraisemblance car c’est la plus
utilisee et la plus facile a calculer.

Alors si on prend un ensemble d’apprentissage R : {Ph1, ..., PhK}, constitue des phrases
Ph1,...,PhK etiquetees manuellement, les formules d’estimation des parametres du modele
A : (H, A, B) sont donnees par:

2f:1le nombre de fois ou la transition eti etj est dans la phrase Phn

aij : 2f:1le nombre de fois ou l’etat eti est atteint le long de la phrase Phn

2 25:1 6 [l’etiquette eti est un etat initial dans la phrase Phn]
7 K
: 2f:1le nombre de fois ou le mot wt a l’etiquette et,- le long de la phrase Phn

771'

bit

25:1 le nombre de fois ou l’etat eti est atteint le long de la phrase Phn

avec :
1 s1 l’eVenement x est Vrai

(Sm : { 0 sinon

5 Etiquetage automatique par algorithme de Viterbi

Pour un calcul plus rapide du chemin optimal2 dans la formule (1) nous avons utilise l’ algorithme
de Viterbi [For 73].
On note par :

6t(€tj) : 6 mag; P7"(w1...wt, et,-1...et,-1)
1... .1

avec et,-1 : etj.
Cette formule devient [Yousﬁ 2001]:

6t(€tj) :  6t_1.a,-j.bj(wt)

On calcule cette formule pour toutes les Valeurs t : l, ..., T et j : l, ..., N.
Enﬁn le chemin optimal est obtenu a l’aide d’un calcul recursif sur cette formule.

6 Experimentation

6.1 Donnees d’apprentissage

Le travail experimental a ete realise en trois grandes etapes :

1) etape de deﬁnition du jeu d’etiquettes et de construction de corpus d’apprentissage.

La deﬁnition de notre propre jeu d’etiquettes morpho—syntaxique a ete particulierement delicate,
cette phase a ete realisee en collaboration avec des linguistes pour satisfaire au besoin des pro-
jets en cours de realisation a IERA. Ce jeu d’etiquettes est constitue de 52 etiquettes de nature

2Nous cherchons ce chemin dans un reseau d’etiquettes. Ce reseau est construit de tel fagon a ce que pour
une phrase donnee, chaque chemin de ce reseau correspond a la probabilite que cette phrase a les etiquettes de ce
chemin (Pr(w1...wt, et,-1...et,-t)). Le chemin associe 51 la probabilite maximale est nomme chemin optimal.

Etiquetage morpho—syntaxique des textes arabes par modele de Markov cache

morpho—syntaxique (comme par exemple ism—faail, ism—mafaoul, harf nasb,...).

Le corpus d’apprentissage est constitue d’un ensemble de phrases representant les principales
regles morphologiques et syntaxiques utilisees en langue arabe generale. Ce corpus a ete eti-
quete manuellement par un linguiste.

2) etape d’estimation des parametres du modele de Markov cache.

3) etape d’etiquetage automatique et reestimation des parametres du modele de Markov cache.

Pour realiser ces deux demieres etapes, nous avons developpe une application en langage C,
comportant deux modules, module d’apprentissage et module d’etiquetage automatique qui
permet d’etiqueter automatiquement un corpus brut, ce dernier est corrige manuellement pour
servir a une reestimation des parametres du modele de Markov cache.

Les programmes sont evalues sur deux versions de textes voyelle et non voyelle.

6.2 Résultats

Le taux d’erreur est mesure sur deux ensembles :

Ensemblel constitue des memes phrases que l’ensemble d’apprentissage mais sans etiquettes,
Ensemble2 constitue de phrases (sans etiquettes) differentes de celles de l’ensemble d’apprenti—
ssage.

H | Ensemblel | Ensemble2 

1,76% 2%
2,5 % 3%

Textes voyelles
Textes non voyelles

Table 1: Les taux d’erreur d’etiquetage automatique.

On remarque que dans le cas des textes non voyelles le taux d’erreur augmente par rapport
aux textes voyelles, a cause de l’augmentation de l’ambiguite (un mot peut prendre plusieurs
etiquettes). Pour le reste des erreurs, elles sont dues au manque de donnees d’apprentissage (il
existe des mots et des transitions entre des etiquettes qui ne sont pas representees dans le corpus
d’ apprentissage).

7 Conclusions et perspectives

En analysant les resultats trouves, nous avons remarque que la majorite d’erreurs d’etiquetage
provient essentiellement du probleme de manque ou d’insufﬁsance de donnees d’apprentissage.
Dans notre cas il existe deux type de problemes de manque de donnees :

0 un ou plusieurs mots, appartenant a la phrase a etiqueter par ce systeme, n’existent pas dans
le lexique, c’est a dire nous n’avons pas une estimation des probabilites d’observation de ces
mots dans tous les etats.

0 une ou plusieurs etiquettes n’ont pas de predecesseurs dans la phrase a etiqueter automatique-
ment, c’est a dire nous n’ avons pas une estimation des probabilites de transition de ces etiquettes
vers tous les autres etiquettes du systeme.

Dans la suite de notre travail, nous allons proceder a deux solutions pour remedier a ces deux
problemes :

653

654

la premiere est d’introduire une sorte d’analyse morphologique qui s’appuit sur les formes mor-
phologiques des mots pour pouvoir identiﬁer les etiquettes des mots inconnus.

La deuxieme est d’introduire une base de regles syntaxiques qui deﬁnie les transitions possibles
entre les differents etiquettes.

References

L.R. Bahl, PF. Brown, PV. de Souza & R.L. Mercer : "Maximum mutual information estimation in
hidden Markov model parameters for speech recognition ", Proc. ICASSP, pp. 49-52, Tokyo, 1986.

L. R. Bahl, P. F. Brown, PV De Souza and R. L. Mercer : "Estimating HMM parameters so as to
maximise speech recognition accuracy ", Research Report RC-13121, IBM TJ Watson Research Center,
9/10/1987.

L. Baum : "An inequality and association maximization technique in statistical estimation for proba-
bilistic functions of Markov processes ", Inequality, vol. 3, 1972.

G. Celux, J. Clairambault :"Estimation de chaines de Markov cache’es.' me’thodes et problemes ",
J ournees thematiques CNRS sur les approches markoviennes en signal et images, Septembre 1992.

J ean-Pierre Chanod and Pasi Tapanainen : "Tagging French — comparing a statistical and a constraint-
based method", Proceeding of the seventh Conference of the European Chapter of the Association for
Computatinal

Linguistics (EACL.95), Dublin, Ireland. pp.149-156, 1995.
Claude De Loupy : "La methode detiquetage d ’Eric Brill". Revue T.A.L, 1995, Vol.36, nf 1-2, pp.37-46

Eric Brill : "A simple rule—based part of speech tagger". Proceedings of the third Conference on Applied
Natural Language Processing, Trento, Italy. pp.152-155. Avril 1992.

Fornay D. R. : "The Viterbi Algorithm ", Proc. IEEE, vol. 61, n 3, mai 1973.

Benoit Habert, Adeline Nazarenko, Andre Salem : "Les linguistiques de corpus" , Armand colin /
Masson.Paris, 1997.

John Rice : "Mathematical Statistics and data
analysis ", page 511-540.

S. Kapadia, V. Valtchev & S.J. Young : "MMI training for continuous phoneme recognition on the T IMIT
database ", Proc. ICASSP, pp. II.491-494, Minneapolis, 1993.

Thi Minh Huyen Nguyen, Laurent Romary, Xuan Luong Vu : "Une etude de cas pour l ’etiquetage
morpho—syntaxique de textes vietnamiens" , 5e conference sur le traitement Automatique du Langage
Naturel (TALN2003), Batz-sur-Mer, 11-14 juin, 2003.

Patrick Paroubek et Martin Rajman : "Etiquetage morpho—syntaxique. " , Ingenierie des langues. pp. 13 1-
150, Paris, HERMES Sciences Europe.

Jacques Vergne, Emmanuel Giguet: "Regards the’oriques sur le ”Tagging” " , 5e conference sur le
traitement Automatique du Langage Naturel (TALN98), Paris, France, 10-12 juin, 1998.

Jean Veronis : "Annotation automatique de corpus .' panorama et etat de la technique" , Ingenierie des
langues. pp. 1 1 1-128. Paris, HERMES Sciences Europe.

A. Yousﬁ : "Introduction de la Vitesse d’elocution dans un modele de reconnaissance automatique de la
parole " , These de doctorat, 19 juin 2001.

