RECITAL 2005, Dourdan, 6-10 juin 2005

Une méthode pour la classiﬁcation de signal de parole
sur la caractéristique de nasalisation

Luquet Pierre-Sylvain
GREYC - CNRS UMR 6072 - Université de Caen
Bd Maréchal Juin - F14032 Caen Cedex
psluquet@info.unicaen.fr
Date de soutenance prévue : décembre 2005

Mots-clefs — Keywords

Phonologie, phonétique, classiﬁeur, réseaux de neurones
Phonology, phonetic, classiﬁer, neural nets

Résumé - Abstract

Nous exposons ici une méthode permettant d’étudier la nature d’un signal de parole dans le
temps. Plus précisément, nous nous intéressons a la caractéristique de nasalisation du signal.
Ainsi nous cherchons a savoir si a un instant 2,‘ le signal est nasalisé ou oralisé. Nous procédons
par classiﬁcation a l’aide d’un réseau de neurones type perceptron multi-couches, apres une
phase d’apprentissage supervisée. La classiﬁcation, apres segmentation du signal en fenétres,
nous permet d’associer a chaque fenétre de signal une étiquette renseignant sur la nature du
signal.

In this paper we expose a method that allows the study of the phonetic features of a speech
signal through time. More speciﬁcally, we focus on the nasal features of the signal. We try to
consider the signal as [+nasal] or [-nasal] at any given time. We proceed with a classiﬁer system
based on a multilayer perceptron neural net. The classiﬁer is trained on a hand tagged corpus.
The signal is tokenized into 30ms hamming windows. The classiﬁcation process lets us tag each
window with information concerning the properties of its content.

Luquet Pierre-Sylvain

1 Appuis théoriques

La reconnaissance de la parole a, grace aux techniques Markoviennes, fait un bond qualitatif
énorme ces demieres années. Les décodeurs acoustiques, tels que ceux développés au LIlVISI
(Lamel & Gauvain, 1993), atteignent des taux de reconnaissance proches des 75%. Cependant,
les limitations restent nombreuses et la critique la plus largement formulée vis-a-vis de ce type
de systeme est la quasi absence de connaissances sur le langage dans les modeles sous-jacents
(Plaut & Kello, 1999). Les travaux actuels s’articulent autour de deux axes. Le premier s’in-
téresse a l’amélioration des techniques de description du signal (Chetouani et al., 2002). Le
second est orienté vers la production : acquisition de connaissances concernant les gestes arti-
culatoires des locuteurs (Vaxelaire et al., 2002), leurs inﬂuences sur le signal (Montagu, 2004),
et les processus cognitifs Inis en jeu (Hawkins, 2003). Ces connaissances font l’objet de diffé-
rentes études visant a leur integration dans les systemes de reconnaissance automatique de la
parole (Wrench & Richmond, 2000).

Nous décrivons dans ces lignes une approche sensiblement différente. Nous cherchons a ap-
puyer une technique de décodage acoustico-phonétique sur la notion de diﬁérence. Saussure
afﬁrme que « dans la langue, il n’y a que des diﬁérences [. . .] sans termes positifs » (Saus-
sure, 1986). Coursil reprend a son compte cette notion dans (Coursil, 1992)1 et afﬁrme a son
tour « Pour tout phonéme X, il existe un phonéme y tel que y = X 61 une et une seule diﬁférence
catégorique prés ». C’est a partir de cette derniere afﬁrmation qu’il construit la topique des
phonémes dufrangais contemporainz. Le but de la classiﬁcation est de mettre en evidence cette
difference dans le signal. Notons enﬁn que la classiﬁcation automatique d’un signal de parole
suivant un trait phonétique donné suppose que le phoneme est une substance, hypothese validée
par la « Dispersion-Focalisation Theory » publiée dans (Schwartz et al., 1997).

Le trait de nasalité. On distingue dans le francais contemporain les phonemes nasaux des
phonemes oraux, le tableau 1 en présente la partition3. Du point de vue de la mécanique arti-
culatoire, la nasalité est décrite comme une connexion du conduit vocal avec le conduit nasal
par le biais de l’abaissement du vélum. Les repercussions acoustiques de ce phénomene, sont
décrites par J akobson dans (J akobson, 1980) en s’appuyant sur Fant et Delattre. Pour Fant, les
consonnes nasales sont « caractérisées par un spectre ou F2 est faible ou bien absent »4 ; Delattre
afﬁne la description en précisant que pour les voyelles nasales, comparées aux orales, F1 perd
une bonne part de son intensité au proﬁt de F2. Plus récemment, Feng et Kotenkoff (Feng &
Kotenkoff, 2004) ont mené a l’ICP5 des observations basées sur une technique d’enregistrement
du locuteur en différenciant les prises de son en provenance du conduit vocal et du conduit na-
sal. Ils ont constaté que l’abaissement du vélum a deux effets distincts : pour le conduit vocal
le rétrécissement engendre le rapprochement des formants F3 et F4, et pour le conduit nasal
sa connexion entraine un rayonnement au niveau des narines caractérisé par une concentration
dans les basses fréquences et aux alentours de 3000 Hz.

1Les travaux sur la phonologie de Coursil s’inscriVent dans un proj et global dénommé ANADIA. On lira dans
(Mauger, 1999) l’une des extensions de ce projet.

2Le format dans lequel cet article est accepté ne me permet pas d’expliquer plus avant cette notion de topique.
Néanmoins, je mets a disposition de tout lecteur en faisant la demande une Version étendue décrivant plus ﬁnement
celle—ci.

3La notation employee ici pour designer les phonemes est le codage SAMPA (Speech As-
sessment Methods Phonetic Alphabet). Pour plus d’informations se reporter au site de l’UCL
http://www.phon.ucl.ac.uk/home/sampa/home.htm

4F1 et F2 désignent respectivement le premier et le second formants. Les formants sont des fréquences de
resonance maximum de l’enVeloppe spectrale du signal de la parole a un instant donné.

5Institut de la Communication Parlée - Grenoble

Une méthode pour la classiﬁcation de signal de parole

nasal oral
voyelles /e~, o~, 9~, a~/ /u, y, i, E, e, O, o, 9, 2, @, a, Al
consonnes /m, n, J/ /p, f, V, b, d, t, k, g, z, s, S, Z, R, l, w, H, j/

TAB. 1 — Nasal vs. oral

2 Corpus

2.1 Constitution

Nous faisons ici l’hypothese que le corpus présentant le moins de difﬁcultés pour réaliser la
partition oralisé vs. nasalisé est constitué de paires minimales oral vs. nasal. De plus, nous nous
sommes concentrés sur les phonemes dont la production pouvait etre maintenue. Nous avons
retenu dans notre corpus les quatre paires oppositives suivantes : /o~/ - /o/, /e~/ - /E/, /9~/ - /9/
et /a~/ - /A/. Ces phonemes sont associés aux mots prototypiques du tableau 2.

Phonemes /o~/ /o/ /e~/ /E/ /9~/ /9/ /a~/ /A/
Prototype tronc trot bain baie un neuf pente pate

TAB. 2 — Phonemes et mots prototypes

Nous disposons aujourd’hui des résultats sur 3 corpus6 de test monolocuteur (voir le tableau 3).
Le premier corpus, C1 est constitué d’une seule paire minimale (/o~/ & /o/), dont la seule
variation est le trait de nasalisation (N). Les corpus C2 et 03 sont plus complexes : sur les 7
caractéristiques Inises en jeu 5 varient. Pour les orales (/o/ & /a/) les variations portent sur la
laxité (L), la compacité (C) et la bémolisation (B); la hauteur (H) intervient en plus pour les
nasales (/o~/ & /a~/)7.

Phonemes Nb. Phonemes Nb. fenetres Maintenus Variations
C 1 /o~/-/o/ 22 2250 oui N
02 /o~, a~/-/o, al 20 2000 oui N, L, C, B, H
03 low, a~/-/o, a/ 24 470 non N, L, C, B, H
TAB. 3 — Corpus

2.2 Parametres

L’ outil principalement utilise dans cette experience est le logiciel d’analyse acoustique PRAAT8.
Corpus. Nous travaillons en utilisant la technique classique de fenetrage du signal. Chaque si-
gnal de parole a analyser est segmenté en tranches de 30ms avec un décalage de 10ms. A chaque

5Pour chacun de ces phonemes, il a ete demandé au locuteur de le prononcer dans un mot prototypique, puis
de le répeter de fagon isolée. Cette fagon de proceder pennet a l’utilisateur de << calibrer » le phoneme qu’il doit
ensuite prononcer isolément. Nous demandons au locuteur de repéter une dizaine de fois ce processus par couple
prototype/phoneme.

7Les quantités du tableau 3 (nombre de phonemes et nombre de fenetres) données ici correspondent pour
chaque corpus aux Versions detest. Les Versions d’apprentissage sont du meme ordre de grandeur.

8Pour plus d’infonnations Voir la page web http : / /www . fon . hum . uva . nl /praat /

Luquet Pierre-Sylvain

fenétre est appliquée une fonction de Hamming. Chaque tranche de signal fenétré constitue un
vecteur dont le nombre d’éléments est dépendant de la fréquence d’échantillonnage du signal
(662 échantillons par tranche pour du signal échantillonné a 22kHz). Chaque vecteur est la-
bellisé par sa caractéristique acoustique ("nasal" ou "oral"). Ces vecteurs sont concaténés en
matrices, qui selon le corpus servira soit a l’apprentissage, soit a la phase de test9.

Classiﬁeur. Nous utilisons des réseaux de neurones type perceptron a une couche cachée. L’ en-
trée du réseau comporte autant de cellules que nous avons de valeurs par vecteur de signal, soit
662 cellules. La sortie est composée de deux cellules correspondant aux classes activables. La
couche cachée est composée de 331 cellules. Lors des phases d’apprentissage l’évaluation de
l’erreur est calculée suivant la méthode minimum squared error.

3 Résultats

3.1 Variation restreinte

Les résultats du tableau 3 concernent le corpus 01 et ont été obtenus au terme d’un apprentis-
sage de 400 cycles. Les phonemes sont maintenus et la seule variation phonologique Inise en
jeu est la nasalisation. Nous voyons ici que sur une quantité restreinte de corpus il est possible
de classiﬁer le signal avec de bons résultats. En effet nous obtenons un taux d’erreurs faible
(2, 8%), mais nous voyons surtout que le nombre de fenétres continues incorrectement classi-
ﬁées est tres faible (8) en regard du nombre de fenétres par phoneme (102). Le risque de mal
classiﬁer un phoneme est donc Ininime.

fenétres 2252 fenétres par phoneme 102
erreurs 63 groupes d’erreur 17
taux 2,8 % erreurs par groupe 3, 71
erreurs consécutives maximum 8

TAB. 4 — Résultats 01

3.2 Augmentation de la dissemblance

Les résultats donnés ici concernent le corpus C2. Le tableau 5 donne les résultats obtenus pour
400 cycles d’apprentissage, tandis que le tableau 6 nous donne les résultats au bout de 600
cycles. Comme précédemment les phonemes sont maintenus mais plusieurs variations phono-
logiques sont ici mises en jeu (voire 2.1). La focalisation du classiﬁeur sur la caractéristique de
nasalisation est donc rendue plus complexe en raison du bruit apporté par les autres variations.

Cependant, les résultats obtenus montrent qu’une classiﬁcation est toujours possible. Avec 400
cycles (tableau 5), nous obtenons un taux d’erreurs qui reste faible (5, 3%). Le nombre de fe-
nétres contigues incorrectement classiﬁées l’est aussi (12 fenétres mal classiﬁées). Néanmoins,
si nous augmentons d’un tiers le nombre de cycles (tableau 6), le taux d’erreurs retombe a 2, 3%.

9Dans les deux cas, les valeurs des échantillons sont décalées et mises a l’échelle pour étre dans le domaine
de déﬁnition de notre classiﬁeur. Les valeurs d’origine Varient dans l’interva1le [-1, 1]. Nous les réduisons d’un
facteur 1/2 puis les décalons de 1 pour qu’elles soient comprises dans l’interValle d’entrée du classiﬁeur : [0, 1].

Une méthode pour la classiﬁcation de signal de parole

fenétres 1996 fenétres par phoneme 100
erreurs 106 groupes d’erreur 47
taux 5,3% erreurs par groupe 2, 3
erreurs consécutives maximum 12

TAB. 5 — Résultats C2 - Apprentissage : 400 cycles

fenétres 1996 fenétres par phoneme 100
erreurs 47 groupes d’erreur 16
taux 2,3% erreurs par groupe 2, 9
erreurs consécutives maximum 9

TAB. 6 — Résultats C2 - Apprentissage : 600 cycles

3.3 Phonémes non maintenus

L’ expérience menée sur le corpus 03 est similaire a l’expérience précédente, mais conceme des
phonemes non maintenus. Les résultats obtenus (tableau 7 et 8) sont nettement en retrait, mais
restent néanmoins tres intéressants. Au terme d’un apprentissage de 300 cycles, nous observons
un taux d’erreur de 20% que nous pouvons réduire a 15, 8% au terme de 600 cycles d’apprentis-
sage (soit une réduction de ce taux de 21, 5%). En revanche, le doublement du nombre de cycles
d’apprentissage n’apporte rien ici en terme de réduction du nombre d’erreurs contigues (7 fe-
nétres mal classiﬁées1°). Néanmoins ce nombre reste acceptable, dans le cas d’une stratégie de
classiﬁcation winner-takes-all dans la mesure ou un phoneme compte en moyenne 20 fenétres.
Notons que la taille de notre corpus d’apprentissage (412 fenétres) pose ici un probleme; le
nombre de patrons étiquetés limite la capacité de classiﬁcation. Enﬁn, un dernier cycle long
d’apprentissage (2000 cycles) ne nous a pas permis d’améliorer sensiblement le taux d’erreurs
et a également conﬁrmé qu’au dela de 600 cycles, la réduction de l’erreur est faible pour un coﬁt
tres élevé; dans notre cas le nombre de cycles a été plus que triplé pour un gain de 2 erreurs
seulement sur le corpus detest.

fenétres 469 fenétres par phoneme 20
erreurs 94 groupes d’erreur 37
taux 20,0% erreurs par groupe 2, 5
erreurs consécutives maximum 7

TAB. 7 — Résultats C3 - Apprentissage : 300 cycles

4 Perspectives et conclusion

Les résultats présentés dans cet article sont prometteurs, cependant certains aspects sont a ap-
profondir. D’autre types de descripteurs sont envisagés : techniques d’extraction de type MFCC
(Mel Frequency Cepstral Coefﬁcients), LPC (Linear Predictive Coding) ou plus encore PLP
(Perceptual Linear Predictive coding). Par ailleurs, la limite en terme de fréquence d’échan-
tillonnage en deca de laquelle l’apprentissage n’est plus réalisable n’est pas connue. Qu’en

1°Le nombre donné ici correspond au nombre maximal de fenétres contigués mal classiﬁées dans un phoneme.

Luquet Pierre-Sylvain

fenétres 469 fenétres par phoneme 20
erreurs 74 groupes d’erreur 30
taux 15,8% erreurs par groupe 2, 5
erreurs consécutives maximum 7

TAB. 8 — Résultats C3 - Apprentissage 2 600 cycles

est-il d’un signal de qualité téléphonique échantillonné a 8kHz ?

Nous envisageons également d’augmenter la complexité du corpus 2 nombre de locuteurs et
nombre de phonemes présents. L’augmentation du nombre de locuteurs a pour but de tester
l’indépendance de l’apprentissage du classiﬁeur. Pour valider notre méthode sur du signal de
parole continue, une nouvelle série d’eXpériences est envisagée. L’ augmentation du nombre de
phonemes doit permettre de multiplier les caractéristiques prises en considération.

En outre, nous faisons l’hypothese que le croisement de résultats issus de plusieurs classiﬁeurs
(avec un apprentissage sur des catégories phonétiques différentes) permettra de situer le signal
dans l’espace topique et de déterminer ainsi la classe phonétique a laquelle il appartient.

Références

CHETOUANI M., GAS B. & ZARADER J. (2002). Coopération entre codeurs neuro-prédictifs pour
l’extraction de caractéristiques en reconnaissance de phonemes. In Reconnaissances desformes et intel-
ligence artiﬁcielle.

COURSIL J. (1992). Essai d’intelligence artiﬁcielle et de linguistique générale. PhD thesis, Université
de Caen.

FENG & KOTENKOFF (2004). Vers un nouveau modéle acoustique des nasales basé sur l’enregistrement
bouche - nez séparé. In Journe’es d ’Etude sur la Parole.

HAWKINS S. (2003). Roles and representations of systematic ﬁne phonetic detail in speech understan-
ding. Journal of Phonetics.

JAKOBSON R. (1980). La charpente phonique du langage. Paris 2 Editions de Minuit.

LAMEL L. & GAUVAIN J . (1993). High performance speaker-independent phone recognition using
cdhmm. In European Conference on Speech Communication and Technology.

MAUGER S. (1999). L’Interpre’tation des Messages Enigmatiques. Essai de Sémantique et de Traitement
Automatique des Langues. PhD thesis, Université de Caen.

MONTAGU J . (2004). Les sons sous-jacents aux Voyelles nasales en francais parisien 2 indices perceptifs
des changements. In Journe’es d ’E'tude sur la Parole, p. 385-388.

PLAUT D. C. & KELLO C. T. (1999). The Emergence of Language, chapter The Emergence of Phono-
logy from the Interplay of Speech Comprehension and Production 2 A Distributed Connectionist. Law-
rence Erlbaum Assoc 2 Mahwah.

SAUSSURE F. (1986). Cours de linguistique ge’ne’rale. Paris 2 Mauro Payot.

SCHWARTZ J .-L., BOE L.-J., VALLEE N. & ABRY C. (1997). The dispersion-focalization theory of
Vowel systems. Journal of Phonetics.

VAXELAIRE B ., FERBACH-HECKER V. & SOCK R. (2002). La perception auditive de gestes Vocaliques
anticipatoires. In Joumées d ’Etude sur la Parole.

WRENCH A. A. & RICHMOND K. (2000). Continuous speech recognition using articulatory data. In
International Conference on Spoken Language Processing.

