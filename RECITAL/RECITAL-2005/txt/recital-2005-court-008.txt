RECITAL 2005, Dourdan, 6-1 0ju1'n 2005

Une méthode pour la classiﬁcation de signal de parole
sur la caractéristique de nasalisation

Luquet Pierre—Sy1Vain
GREYC — CNRS UMR 6072 — Université de Caen
Bd Maréchal Juin — F14032 Caen Cedex
ps1uquet@info.unicaen.fr
Date de soutenance prévue : décembre 2005

Mots-clefs — Keywords

Phonologie, phonétique, classiﬁeur, réseaux de neurones
Phonology, phonetic, classiﬁer, neural nets

Résumé - Abstract

Nous exposons ici une méthode permettant d’étudier la nature d’un signal de parole dans le
temps. Plus précisément, nous nous intéressons a la caractéristique de nasalisation du signal.
Ainsi nous cherchons a savoir si 5. un instant I le signal est nasalisé ou oralisé. Nous procédons
par classiﬁcation a l’aide d’un réseau de neurones type perceptron multi—couches, apres une
phase d’apprentissage supervisée. La classiﬁcation, apres segmentation du signal en fenétres,
nous permet d’ associer a chaque fenétre de signal une etiquette renseignant sur la nature du
signal.

In this paper we expose a method that allows the study of the phonetic features of a speech
signal through time. More speciﬁcally, we focus on the nasal features of the signal. We try to
consider the signal as [+nasal] or [—nasal] at any given time. We proceed with a classiﬁer system
based on a multilayer perceptron neural net. The classiﬁer is trained on a hand tagged corpus.
The signal is tokenized into 30ms hamming windows. The classiﬁcation process lets us tag each
window with information concerning the properties of its content.

679

680

Luquet Pierre—Sylvain

1 Appuis théoriques

La reconnaissance de la parole a, grace aux techniques Markoviennes, fait un bond qualitatif
enorme ces dernieres annees. Les decodeurs acoustiques, tels que ceux developpes au LIMSI
(Lamel & Gauvain, 1993), atteignent des taux de reconnaissance proches des 75%. Cependant,
les limitations restent nombreuses et la critique la plus largement formulee vis—a—vis de ce type
de systeme est la quasi absence de connaissances sur le langage dans les modeles sous—jacents
(Plaut & Kello, 1999). Les travaux actuels s’articulent autour de deux axes. Le premier s’in—
teresse a l’amélioration des techniques de description du signal (Chetouani er al., 2002). Le
second est oriente vers la production : acquisition de connaissances concernant les gestes arti-
culatoires des locuteurs (Vaxelaire er al., 2002), leurs inﬂuences sur le signal (Montagu, 2004),
et les processus cognitifs rnis en jeu (Hawkins, 2003). Ces connaissances font l’objet de diffe-
rentes etudes visant a leur integration dans les systemes de reconnaissance automatique de la
parole (Wrench & Richmond, 2000).

Nous decrivons dans ces lignes une approche sensiblement differente. Nous cherchons a ap-
puyer une technique de decodage acoustico—phonetique sur la notion de dyﬁférence. Saussure
afﬁrme que << dans la langue, il n’y a que des dyjférences [. . .] sans termes positifs » (Saus-
sure, 1986). Coursil reprend a son compte cette notion dans (Coursil, 1992)1 et afﬁrme a son
tour << Pour tout phonéme x, il existe Lm phonéme y tel que y = x a une et une seule dyﬁférence
catégorique prés >>. C’est a partir de cette derniere afﬁrmation qu’il construit la topique des
phonémes dufrcmgais contemporainz. Le but de la classiﬁcation est de mettre en evidence cette
difference dans le signal. Notons enﬁn que la classiﬁcation automatique d’un signal de parole
suivant un trait phonetique donne suppose que le phoneme est une substance, hypothese validee
par la « Dispersion—Focalisation Theory » publiee dans (Schwartz et al., 1997).

Le trait de nasalité. On distingue dans le francais contemporain les phonemes nasaux des
phonemes oraux, le tableau 1 en presente la partition3. Du point de vue de la mecanique arti-
culatoire, la nasalite est décrite comme une connexion du conduit vocal avec le conduit nasal
par le biais de l’abaissement du velum. Les repercussions acoustiques de ce phenomene, sont
decrites par J akobson dans (J akobson, 1980) en s’appuyant sur Fant et Delattre. Pour Fant, les
consonnes nasales sont << caracterisees par un spectre ou F2 est faible ou bien absent »4 ; Delattre
afﬁne la description en precisant que pour les voyelles nasales, comparees aux orales, F1 perd
une bonne part de son intensite au proﬁt de F2. Plus recemment, Feng et Kotenkoff (Feng &
Kotenkoff, 2004) ont mene a l’ICP5 des observations basees sur une technique d’enregistrement
du locuteur en differenciant les prises de son en provenance du conduit vocal et du conduit na-
sal. Ils ont constate que l’abaissement du velum a deux effets distincts : pour le conduit vocal
le retrecissement engendre le rapprochement des formants F3 et F4, et pour le conduit nasal
sa connexion entraine un rayonnement au niveau des narines caracterise par une concentration
dans les basses frequences et aux alentours de 3000 Hz.

1Les travaux sur la phonologie de Coursil s’inscrivent dans un projet global denomme ANADIA. On lira dans
(Mauger, 1999) l’une des extensions de ce projet.

2Le format dans lequel cet article est accepte ne me permet pas d’expliquer plus avant cette notion de topique.
Neanmoins, je mets a disposition de tout lecteur en faisant la demande une version etendue decrivant plus ﬁnement
celle—ci.

3La notation employee ici pour designer les phonemes est le codage SAMPA (Speech As-
sessment Methods Phonetic Alphabet). Pour plus d’ informations se reporter au site de l’UCL
http://www.phon.ucl.ac.uk/home/sampa/home.htm

4F1 et F2 designent respectivement le premier et le second formants. Les formants sont des frequences de
resonance maximum de l’enveloppe spectrale du signal de la parole a un instant donne.

5Institut de la Communication Parlee — Grenoble

Une methode pour la classiﬁcation de signal de parole

nasal oral
Voyelles /e~, o~, 9~, a~/ /u, y, i, E, e, O, 0, 9, 2, @, a, A/
consonnes /m, n, J/ /p, f, V, b, d, t, k, g, z, s, S, Z, R, l, w, H, j/
TAB. 1 — Nasal VS. oral
2 Corpus

2.1 Constitution

Nous faisons ici l’hypothese que le corpus presentant le moins de difﬁcultes pour realiser la
partition oralise vs. nasalise est constitue de paires minimales oral vs. nasal. De plus, nous nous
sommes concentres sur les phonemes dont la production pouvait etre maintenue. Nous avons
retenu dans notre corpus les quatre paires oppositives suivantes : /o~/ — /o/, /e~/ — /E/, /9~/ — /9/
et /a~/ — /A/. Ces phonemes sont associes aux mots prototypiques du tableau 2.

Phonemes /o~/ /o/ /e~/ /E/ /9~/ /9/ /a~/ /A/
Prototype tronc trot bain baie un neuf pente pate

TAB. 2 — Phonemes et mots prototypes

Nous disposons aujourd’hui des resultats sur 3 corpus6 de test monolocuteur (Voir le tableau 3).
Le premier corpus, 01 est constitue d’une seule paire minimale (/o~/ & /o/), dont la seule
Variation est le trait de nasalisation (N). Les corpus 02 et 03 sont plus complexes : sur les 7
caracteristiques mises en jeu 5 Varient. Pour les orales (/o/ & /a/) les Variations portent sur la
laxite (L), la compacite (C) et la bemolisation (B) ; la hauteur (H) intervient en plus pour les
nasales (/o~/ & /a~/)7.

Phonemes Nb. Phonemes Nb. fenetres Maintenus Variations
C’ l /o~/—/o/ 22 2250 oui N
02 /o~, a~/—/o, a/ 20 2000 oui N, L, C, B, H
03 /o~, a~/—/o, a/ 24 470 non N, L, C, B, H

TAB. 3 — Corpus

2.2 Parametres

L’ outil principalement utilise dans cette experience est le lo giciel d’analyse acoustique PRAAT8.
Corpus. Nous travaillons en utilisant la technique classique de fenetrage du signal. Chaque si-
gnal de parole a analyser est segmente en tranches de 30m3 avec un decalage de l0m3. A chaque

6Pour chacun de ces phonemes, il a ete demande au locuteur de le prononcer dans un mot prototypique, puis
de le repeter de fagon isolee. Cette fagon de proceder permet a l’utilisateur de « calibrer » le phoneme qu’il doit
ensuite prononcer isolement. Nous demandons au locuteur de repeter une dizaine de fois ce processus par couple
prototype/phoneme.

7Les quantites du tableau 3 (nombre de phonemes et nombre de fenetres) donnees ici correspondent pour
chaque corpus aux Versions detest. Les Versions d’apprentissage sont du meme ordre de grandeur.

8Pour plus d’informations Voir la page web http : / /www . fon . hum . uva . nl/praat/

681

682

Luquet Pierre—SylVain

fenetre est appliquee une fonction de H ammmg. Chaque tranche de signal fenetre constitue un
vecteur dont le nombre d’elements est dependant de la frequence d’echantillonnage du signal
(662 echantillons par tranche pour du signal echantillonne a 22k;Hz). Chaque Vecteur est la-
bellise par sa caracteristique acoustique ("nasal" ou "oral"). Ces Vecteurs sont concatenes en
matrices, qui selon le corpus servira soit a l’apprentissage, soit a la phase de test9.

Classiﬁeur. Nous utilisons des reseaux de neurones type perceptron a une couche cachee. L’en—
tree du reseau comporte autant de cellules que nous avons de Valeurs par Vecteur de signal, soit
662 cellules. La sortie est composee de deux cellules correspondant aux classes activables. La
couche cachee est composee de 331 cellules. Lors des phases d’apprentissage l’eValuation de
l’erreur est calculee suivant la methode minimum squared error.

3 Résultats

3.1 Variation restreinte

Les resultats du tableau 3 concernent le corpus 01 et ont ete obtenus au terme d’un apprentis—
sage de 400 cycles. Les phonemes sont maintenus et la seule Variation phonologique mise en
jeu est la nasalisation. Nous Voyons ici que sur une quantite restreinte de corpus il est possible
de classiﬁer le signal avec de bons resultats. En effet nous obtenons un taux d’erreurs faible
(2, 8%), mais nous Voyons surtout que le nombre de fenetres continues incorrectement classi-
ﬁees est tres faible (8) en regard du nombre de fenetres par phoneme (102). Le risque de mal
classiﬁer un phoneme est donc minime.

fenetres 2252 fenetres par phoneme 102
erreurs 63 groupes d’erreur 17
taux 2,8% erreurs par groupe 3, 71
erreurs consecutives maximum 8

TAB. 4 — Résultats 01

3.2 Augmentation de la dissemblance

Les resultats donnes ici concernent le corpus 02. Le tableau 5 donne les resultats obtenus pour
400 cycles d’apprentissage, tandis que le tableau 6 nous donne les resultats au bout de 600
cycles. Comme precedemment les phonemes sont maintenus mais plusieurs Variations phono-
logiques sont ici mises en jeu (Voire 2.1). La focalisation du classiﬁeur sur la caracteristique de
nasalisation est donc rendue plus complexe en raison du bruit apporte par les autres Variations.
Cependant, les resultats obtenus montrent qu’une classiﬁcation est toujours possible. Avec 400
cycles (tableau 5), nous obtenons un taux d’erreurs qui reste faible (5, 3%). Le nombre de fe-
netres contigues incorrectement classiﬁees l’est aussi (12 fenetres mal classiﬁees). Neanmoins,
si nous augmentons d’un tiers le nombre de cycles (tableau 6), le taux d’erreurs retombe a 2, 3%.

9Dans les deux cas, les Valeurs des echantillons sont decalees et mises a 1’eche11e pour etre dans le domaine
de deﬁnition de notre classiﬁeur. Les Valeurs d’origine Varient dans 1’interVa11e [-1, 1]. Nous les reduisons d’un
facteur 1/2 puis les decalons de 1 pour qu’e11es soient comprises dans 1’interVa11e d’entree du classiﬁeur : [0, 1].

Une methode pour la classiﬁcation de signal de parole

fenétres 1996 fenétres par phoneme 100
erreurs 106 groupes d’erreur 47
taux 5,3% erreurs par groupe 2, 3
erreurs consecutives maximum 12

TAB. 5 — Resultats O2 — Apprentissage : 400 cycles

fenétres 1996 fenétres par phoneme 100
erreurs 47 groupes d’erreur 16
taux 2,3% erreurs par groupe 2, 9
erreurs consecutives maximum 9

TAB. 6 — Resultats C2 — Apprentissage : 600 cycles

3.3 Phonemes non maintenus

L’ experience menee sur le corpus 03 est similaire a l’experience precedente, mais concerne des
phonemes non maintenus. Les resultats obtenus (tableau 7 et 8) sont nettement en retrait, mais
restent neanmoins tres interessants. Au terme d’un apprentissage de 300 cycles, nous observons
un taux d’erreur de 20% que nous pouvons reduire a 15, 8% au terme de 600 cycles d’apprentis—
sage (soit une reduction de ce taux de 21, 5%). En revanche, le doublement du nombre de cycles
d’apprentissage n’apporte rien ici en terme de reduction du nombre d’erreurs contigues (7 fe-
nétres mal classiﬁe’es1°). Neanmoins ce nombre reste acceptable, dans le cas d’une strategie de
classiﬁcation wirmer—takes—all dans la mesure ou un phoneme compte en moyenne 20 fenétres.
Notons que la taille de notre corpus d’apprentissage (412 fenétres) pose ici un probleme; le
nombre de patrons etiquetes limite la capacite de classiﬁcation. Enﬁn, un dernier cycle long
d’apprentissage (2000 cycles) ne nous a pas permis d’ ameliorer sensiblement le taux d’erreurs
et a egalement conﬁrme qu’ au dela de 600 cycles, la reduction de l’erreur est faible pour un coﬁt
tres eleve; dans notre cas le nombre de cycles a ete plus que triple pour un gain de 2 erreurs
seulement sur le corpus detest.

fenétres 469 fenétres par phoneme 20
erreurs 94 groupes d’erreur 37
taux 20,0% erreurs par groupe 2, 5
erreurs consecutives maximum 7

TAB. 7 — Resultats O3 — Apprentissage : 300 cycles

4 Perspectives et conclusion

Les resultats presentes dans cet article sont prometteurs, cependant certains aspects sont a ap-
profondir. D’autre types de descripteurs sont envisages : techniques d’extraction de type MFCC
(Mel Frequency Cepstral Coefﬁcients), LPC (Linear Predictive Coding) ou plus encore PLP
(Perceptual Linear Predictive coding). Par ailleurs, la limite en terme de frequence d’echan—
tillonnage en deca de laquelle l’apprentissage n’est plus realisable n’est pas connue. Qu’en

1°Le nombre donne ici correspond au nombre maximal de fenetres contigues ma] classiﬁees dans un phoneme.

683

684

Luquet Pierre—SylVain

fenétres 469 fenétres par phoneme 20
erreurs 74 groupes d’erreur 30
taux 15,8% erreurs par groupe 2, 5
erreurs consecutives maximum 7

TAB. 8 — Resultats C3 — Apprentissage : 600 cycles

est—il d’un signal de qualite telephonique echantillonne a 8k/‘Hz ?

Nous envisageons egalement d’augmenter la complexite du corpus : nombre de locuteurs et
nombre de phonemes presents. L’augmentation du nombre de locuteurs a pour but de tester
l’independance de l’apprentissage du classiﬁeur. Pour Valider notre methode sur du signal de
parole continue, une nouvelle serie d’experiences est envisagee. L’ augmentation du nombre de
phonemes doit permettre de multiplier les caracteristiques prises en consideration.

En outre, nous faisons l’hypothese que le croisement de resultats issus de plusieurs classiﬁeurs
(avec un apprentissage sur des categories phonetiques differentes) permettra de situer le signal
dans l’espace topique et de determiner ainsi la classe phonetique a laquelle il appartient.

Références

CHETOUANI M., GAS B. & ZARADER J. (2002). Cooperation e11tre codeurs neuro—prédictifs pour
1’extraction de caractéristiques en reconnaissance de phonemes. In Reconnaissances desformes et intel-
ligence artiﬁcielle.

COURSIL J. (1992). Essai d’intelligence artiﬁcielle et de linguistique générale. PhD thesis, Université
de Caen.

FEN G & KOTENKOFF (2004). Vers un nouveau modele acoustique des nasales base sur1’enregistrement
bouche — nez séparé. In Journe’es d’Etude sur la Parole.

HAWKINS S. (2003). Roles and representations of systematic ﬁne phonetic detail in speech understan-
ding. Journal of Phonetics.

JAKOB SON R. (1980). La charpente phonique du langage. Paris : Editions de Minuit.

LAMEL L. & GAUVAIN J . (1993). High performance speaker—independent phone recognition using
cdhmm. In European Conference on Speech Communication and Technology.

MAUGER S. (1999). L’Interpre’tation des Messages Enigmatiques. Essai de Sémantique et de T raitement
Automatique des Langues. PhD thesis, Université de Caen.

MONTAGU J . (2004). Les sons sous—jacents aux voyelles nasales en francais parisien : indices perceptifs
des changements. In Journe’es d’Etude sur la Parole, p. 385-388.

PLAUT D. C. & KELLO C. T. (1999). The Emergence of Language, chapter The Emergence of Phono-
logy from the Interplay of Speech Comprehension and Production : A Distributed Connectionist. Law-
rence Erlbaum Assoc : Mahwah.

SAUSSURE F. (1986). Cours de linguistique générale. Paris : Mauro Payot.

SCHWARTZ J .—L., BOE L.—J., VALLEE N. & ABRY C. (1997). The dispersion—foca1ization theory of
vowel systems. Journal of Phonetics.

VAXELAIRE B ., FERBACH—HECKER V. & SOCK R. (2002). La perception auditive de gestes vocaliques
anticipatoires. In Journe’es d ’Etude sur la Parole.

WRENCH A. A. & RICHMOND K. (2000). Continuous speech recognition using articulatory data. In
International Conference on Spoken Language Processing.

