<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Un &#233;tiqueteur s&#233;mantique des &#233;nonc&#233;s en langue arabe</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#201;CITAL 2005, Dourdan, 6-10 juin 2005 
</p>
<p>Un &#233;tiqueteur s&#233;mantique des &#233;nonc&#233;s en langue arabe  
</p>
<p>Anis Zouaghi (1), Mounir Zrigui (2) et Mohamed Ben Ahmed (3)  
 
</p>
<p>(1) et (2) Laboratoire RIADI (unit&#233; de Monastir) - Universit&#233; du centre  
Facult&#233; des Sciences de Monastir - Tunisie  
</p>
<p>(1) Anis.Zouaghi@riadi.rnu.tn 
 (2) Mounir.Zrigui@fsm.rnu.tn 
</p>
<p>(3) Laboratoire RIADI - Universit&#233; de la Mannouba 
Ecole Nationale Sup&#233;rieure d&#8217;Informatique de la Mannouba - Tunisie 
</p>
<p>Mohamed.BenAhmed@riadi.rnu.tn 
</p>
<p>Mots-clefs &#8211; Keywords  
</p>
<p>Mod&#232;les statistiques de langage &#8211; Mod&#232;les n-classes &#8211; D&#233;codage s&#233;mantique &#8211; Approche 
componentielle et s&#233;lective.  
</p>
<p>Statistical models of language &#8211; Models N-classes &#8211; Semantic analyze &#8211; Componential and 
selective approach.   
</p>
<p>R&#233;sum&#233; &#8211; Abstract  
</p>
<p>Notre article s&#8217;int&#232;gre dans le cadre du projet intitul&#233; Or&#233;odule: un syst&#232;me de 
reconnaissance, de traduction et de synth&#232;se de la parole spontan&#233;e. L&#8217;objectif de cet article 
est de pr&#233;senter un mod&#232;le d&#8217;&#233;tiquetage probabiliste, selon une approche componentielle et 
s&#233;lective. Cette approche ne consid&#232;re que les &#233;l&#233;ments de l&#8217;&#233;nonc&#233; porteurs de sens. La 
signification de chaque mot est  repr&#233;sent&#233;e par un ensemble de traits s&#233;mantiques Ts. Ce 
mod&#232;le participe au choix des Ts candidats lors du d&#233;codage s&#233;mantique d&#8217;un &#233;nonc&#233;. 
</p>
<p>The work reported here is part of a larger research project, Or&#233;odule, aiming at developing 
tools for automatic speech recognition, translation, and synthesis for the Arabic language. 
This article focuses on a probabilistic labelling model, according to a componential and 
selective approach. This approach considers only the elements of the statement carrying 
direction. The significance of each word is represented by a whole of semantic features Ts. 
This model takes part in the choice of the Ts candidates at the time of the semantic decoding 
of a statement. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed 
</p>
<p>1 Introduction 
Depuis quelques ann&#233;es, La tendance est vers l&#8217;utilisation des mod&#232;les de langages 
statistiques  dans le domaine de la compr&#233;hension automatique de la parole spontan&#233;e 
(Bousquet, 2002), (Lef&#232;vre, 2002), etc. Pour la langue arabe, l&#8217;utilisation de tels mod&#232;les &#224; 
notre connaissance constitue une nouveaut&#233;. L&#8217;avantage principal de ces mod&#232;les statistiques 
par rapport aux mod&#232;les &#224; syntaxe fixe (Bennacef et al., 1994) est qu&#8217;ils sont plus portables 
vers d&#8217;autres domaines (Minker, 1999), et n&#233;cessite moins de recours &#224; un expert humain. 
Dans cet article, nous proposons un &#233;tiqueteur s&#233;mantique bas&#233; sur un mod&#232;le de langage 
probabiliste hybride [Zouaghi et al., 2005] pour l&#8217;interpr&#233;tation d&#8217;une s&#233;quence de mots 
reconnue par le module de reconnaissance de la parole. Ce mod&#232;le participe au choix des  
ensembles de traits s&#233;mantiques Ts candidats, en tenant compte des donn&#233;es suivantes: le type 
d&#8217;acte illocutoire accompli par l&#8217;&#233;nonc&#233; (demande, refus, excuse, etc.), le type de l&#8217;&#233;nonc&#233; 
(demande de r&#233;servation, de tarifs, etc.), des mots d&#233;j&#224; interpr&#233;t&#233;s (les traits s&#233;mantiques 
utilis&#233;s), et de la probabilit&#233; d&#8217;interpr&#233;tation d&#8217;un mot par un Ts candidat. 
</p>
<p>2 Mod&#232;le probabiliste 
</p>
<p>2.1 Corpus d&#8217;apprentissage  
</p>
<p>Le corpus d&#8217;apprentissage consid&#233;r&#233; d&#233;crit des demandes de renseignements ferroviaires, en 
langue arabe classique. Chaque mot significatif dans ce corpus se voit attribuer un ensemble 
de traits (Ts), tel que d&#233;fini dans (Zouaghi et al., 2004). Le mot  &#1575;&#1576;&#1607;&#1575;&#1584;&#1604;  (qui va) par exemple se 
voit attribuer Ts = (Transport_Ferroviaire, Mouvement, Destination). Les mots synonymiques 
ou poss&#233;dant un m&#234;me r&#244;le s&#233;mantique sont interpr&#233;t&#233;s via un m&#234;me Ts. Pareil, pour les mots 
d&#233;riv&#233;s &#224; partir d&#8217;une m&#234;me racine morphologique et poss&#233;dant un m&#234;me sens (tels que &#1576;&#1607;&#1575;&#1584;&#1604;&#1575; 
(qui va) et &#1576;&#1607;&#1584;&#1610; (va) qui sont d&#233;riv&#233;s &#224; partir de la racine &#1576;&#1607;&#1584; (dhahaba)). Nous avons utilis&#233; 
une quarantaine de Ts diff&#233;rents pour l&#8217;&#233;tiquetage du corpus. En plus chaque &#233;nonc&#233; de ce 
corpus se voit attribuer une &#233;tiquette permettant de pr&#233;ciser le type de l&#8217;&#233;nonc&#233;. En tout, nous 
avons utilis&#233; sept &#233;tiquettes.  
</p>
<p>Domaine Taille (Mo) Nombre 
d&#8217;&#233;nonc&#233;s 
</p>
<p>Nombre de 
mots 
</p>
<p>Nombre de 
locuteurs 
</p>
<p>Renseignements ferroviaires 3,4 10000 85900 1000 
</p>
<p> Figure 1 : Caract&#233;ristiques du corpus de point de vue de son volume. 
</p>
<p>Figure 2 : Caract&#233;ristiques du corpus de point de vue de son contenu. 
</p>
<p>Nature de la t&#226;che Renseignements sur les: R&#233;servations autres 
</p>
<p>horaires trajets tarifs dur&#233;es Taux de sa 
repr&#233;sentation  
</p>
<p>28,7 % 9,37 % 16,66 % 3,12 % 
</p>
<p>10,41 % 
</p>
<p> 
</p>
<p>40,64% </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Un Etiqueteur s&#233;mantique des &#233;nonc&#233;s en langue arabe 
</p>
<p>Ce corpus a &#233;t&#233; collect&#233; en demandant &#224; cent personnes de formuler des &#233;nonc&#233;s relatifs aux 
renseignements ferroviaires. Donc c&#8217;est un corpus simul&#233; et non pas r&#233;el. L&#8217;inconv&#233;nient de 
ce type de corpus est qu&#8217;il ne permet pas de d&#233;crire parfaitement l&#8217;application. 
</p>
<p>2.2 Principe du d&#233;codage s&#233;mantique 
</p>
<p>Nous entendons par d&#233;codage s&#233;mantique d&#8217;un &#233;nonc&#233;, l&#8217;&#233;tiquetage de chacun de ses mots 
significatifs via un Ts (Zouaghi et al., 2004). Seulement les mots porteurs de sens parmi ceux 
qui sont reconnus sont interpr&#233;t&#233;s.   
</p>
<p> 
</p>
<p> 
</p>
<p>Figure 3 : Principe du d&#233;codage s&#233;mantique. 
</p>
<p>Soit la s&#233;quence de mots significatifs S = M1 M2 M3 M4 obtenus apr&#232;s la phase de 
pr&#233;traitement (figure 3). Soit Ts1, Ts2 et Ts3 les traits affect&#233;s respectivement aux mots M1, 
M2 et M3. A partir de ces donn&#233;es, nous voulons d&#233;terminer le Ts correspondant &#224; M4. Pour 
atteindre cet objectif, nous utilisons un mod&#232;le de langage probabiliste hybride, permettant de 
tenir compte du type et de la nature de l&#8217;&#233;nonc&#233;, ainsi que des mots d&#233;j&#224; interpr&#233;t&#233;s (figure 4).  
</p>
<p> 
</p>
<p> 
</p>
<p>Figure 4 : Int&#233;gration des donn&#233;es s&#233;mantiques et du type de l&#8217;&#233;nonc&#233; dans l&#8217;interpr&#233;tation. 
</p>
<p>2.3 Description du mod&#232;le 
</p>
<p>Les syst&#232;mes &#224; base de mod&#232;les de langage probabilistes tentent de d&#233;terminer le score 
d&#8217;une s&#233;quence de mots S = m1, m2, ..., mi, dont la formule g&#233;n&#233;rale est la suivante:  
P (S) = P (m1).P (m2/m1) ... P (mi/m1, m2, ..., mi-1)                                                                   (1) 
Dans le cas de l&#8217;&#233;tiquetage I d&#8217;une s&#233;quence de mots significatifs M1&#8230;Mn, par Ts1&#8230;Tsn, le 
mod&#232;le tente de d&#233;terminer le score d&#8217;interpr&#233;tation de chacun de ces mots, par chacun de ces 
traits. Soit I=Ts1&#198;M1&#8230;Tsn&#198;Mn, la vraisemblance de I est alors d&#233;finie comme suit:   P (I) = 
P (Ts1...Tsn|M1&#8230; Mn)= P (Ts1/M1&#8230;Mk). P (Ts2/Ts1, M1&#8230;Mk)... P (Tsn /Ts1&#8230; Tsn-1, M1&#8230; Mn) = 
P (Ts1/M1) . P (Ts2/ Ts1, M2)... .P (Tsn / Ts1&#8230; Tsn-1, Mn)                                       (2) 
Nous signalons que le passage de la deuxi&#232;me &#224; la troisi&#232;me ligne correspond &#224; une 
approximation du mod&#232;le, qui consid&#232;re que la probabilit&#233; d'un Tsi ne d&#233;pend, 
conditionnellement &#224; la s&#233;quence compl&#232;te des traits, qu'au mot courant Mi. En fixant &#224; 
l&#8217;avance le domaine de l&#8217;application, chaque mot significatif Mi peut &#234;tre interpr&#233;t&#233; via Tsi = 
(Ci, TMi), o&#249; Ci indique la classe &#224; laquelle appartient le mot Mi, et TMi le trait micro 
s&#233;mantique qui lui correspond. L&#8217;&#233;quation (2) devient: 
P(I)=P((C1,TM1)/M1).P((C2,TM2)/(C1,TM1),M2)..P((Cn,TMn)/(C1,TM1)&#8230;(Cn-1,TMn-1),Mn)    (3) 
</p>
<p>Etiquetage s&#233;mantique Mots reconnus  
</p>
<p>&#224; l&#8217;instant t 
</p>
<p>Interpr&#233;tation de la s&#233;quence 
de mots 
</p>
<p>Mod&#232;le de langage 
probabiliste
</p>
<p>Pr&#233;traitements Mots porteurs de sens 
</p>
<p>Tsk
</p>
<p>Ts2
</p>
<p>Ts1
</p>
<p>M4
</p>
<p>?
</p>
<p>?
</p>
<p>?
</p>
<p>M2
</p>
<p>TS2 TS3
</p>
<p>M3
</p>
<p>Type de l&#8217;&#233;nonc&#233;
</p>
<p>TS1
</p>
<p>M1
</p>
<p>Mot &#224;  
interpr&#233;ter 
</p>
<p>Mots d&#233;j&#224; 
interpr&#233;t&#233;s </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed 
</p>
<p>Nous avons int&#233;gr&#233; dans l&#8217;&#233;quation (4) d&#8217;autres sources d&#8217;informations afin d&#8217;am&#233;liorer la 
qualit&#233; du d&#233;codeur s&#233;mantique. Ceci, en tenant compte du type de l&#8217;&#233;nonc&#233; not&#233; par NTj 
(avec P (NTj/M1&#8230;Mn) est la probabilit&#233; conditionnelle d&#8217;avoir un &#233;nonc&#233; de type NTj). 
P (I) = P (Ts1...Tsn|NTj, M1&#8230; Mn)  = P (NTj/M1&#8230; Mn). P ((C1, TM1) / NTj,, M1) . P ((C2, TM2) 
/ NTj;(C1, TM1),M2) ... P ((Cn, TMn) / NTj, (C1, TM1)&#8230; (Cn-1, TMn-1), Mn)                               (4) 
</p>
<p>2.4 Lissage du mod&#232;le 
</p>
<p>La premi&#232;re approximation appliqu&#233;e &#224; ce mod&#232;le consiste &#224; ne consid&#233;rer pour la 
d&#233;termination du type de l&#8217;&#233;nonc&#233;, que certains mots appel&#233;s mots de r&#233;f&#233;rence not&#233;s Mrk. 
Les mots de r&#233;f&#233;rence sont des mots dont leurs occurrences dans un &#233;nonc&#233; permettent de 
d&#233;terminer son type. Ces mots sont en fait des uni-grammes, ou des bi-grammes, et dans 
certains cas des tri-grammes, dont la probabilit&#233; est &#233;gale &#224; un. Par exemple le bi-gramme 
&#1585;&#1575;&#1591;&#1602;&#1604;&#1575; (le train) &#1583;&#1610;&#1585;&#1571; (je veux) constitue un mot de r&#233;f&#233;rence, permettant d&#8217;identifier les &#233;nonc&#233;s 
de type r&#233;servation. Ce bi-gramme ne peut &#234;tre rencontr&#233; que dans les &#233;nonc&#233;s du corpus 
d&#8217;apprentissage qui sont &#233;tiquet&#233;s par l&#8217;&#233;tiquette &lt;R&#233;servation&gt; (on a: P (&#1585;&#1575;&#1591;&#1602;&#1604;&#1575; (le train)/&#1583;&#1610;&#1585;&#1571; 
(je veux))=1). On obtient ainsi la substitution suivante:  
P (NTj / M1 &#8230; Mn) = P (NTj  / Mrk)                                                                                           (5) 
La deuxi&#232;me hypoth&#232;se de mod&#233;lisation porte sur les relations d&#8217;ind&#233;pendance conditionnelle 
dans le mod&#232;le et concerne la probabilit&#233; jointe P((Ci,TMi)/NTj,(C1,TM1)...(Ci-1,TMi-1), Mi). 
P((Ci,TMi)/NTj,(C1,TM1)...(Ci-1,TMi-1),Mi)=  
P (Ci / NTj, (C1, TM1)&#8230; (Ci-1, TMi-1), Mi). P (TMi  / Ci, NTj, (C1,TM1)&#8230;(Ci-1, TMi-1), Mi)       (6) 
Afin de simplifier ce mod&#232;le, nous avons consid&#233;r&#233; seulement les Ts jug&#233;s pertinents TsP 
(CP, TMP) &#224; la pr&#233;diction du Ts correspondant au mot Mi not&#233; par Ts (Mi). Un Ts n&#8217;est 
consid&#233;r&#233; pertinent, que lorsqu&#8217;il est suivi par un nombre k minime de Ts (k tend vers 1). 
Nous avons fix&#233; k = 3, car nous pensons que pour k= 1, la grammaire devient tr&#232;s rigide et &#231;a 
revient &#224; consid&#233;rer dans l&#8217;historique du mot Mi que les mots jouant le r&#244;le de marqueurs 
(Fillmore, 1968). Par exemple, l&#8217;ensemble de traits Ts = ( &#1585;&#1588;&#1572;&#1605;_&#1577;&#1570;&#1585;&#1581;  
(Indice_mouvement), &#1585;&#1588;&#1572;&#1605;_ &#1577;&#1607;&#1580;&#1608;  (Indice_destination)) est un Ts pertinent car cet ensemble  
est toujours succ&#233;d&#233; dans le corpus d&#8217;apprentissage par Ts = (&#1577;&#1606;&#1610;&#1583;&#1605; (ville), &#1577;&#1607;&#1580;&#1608; (destination)). 
k correspondant &#224; Ts=(Indice_mouvement, Indice_destination) est ainsi &#233;gal &#224; 1. La deuxi&#232;me 
approximation consid&#233;r&#233;e est que Ci &#224; un instant t, ne d&#233;pend que des classes pertinentes 
pr&#233;c&#233;dentes CP et du type de l&#8217;&#233;nonc&#233;, on a ainsi:  
P (Ci / NTj, (C1, TM1)&#8230; (Ci-1, TMi-1), Mi) = P (Ci/NTj, CPi-1,&#8230;, CPi-l)                                     (7) 
Une autre approximation consid&#233;r&#233;e, est que TMi du Ts(Mi), &#224; un instant t, ne d&#233;pend que de 
la classe Ci affect&#233;e &#224; Mi et du trait pertinent pr&#233;c&#233;dent TsPi-1(CPi-1, TMPi-1). Ainsi on a:  
P (TMi  / Ci, NTj, (C1, TM1)&#8230; (Ci-1, TMi-1), Mi) = P (TMi  / Ci, CPi-1, TMPi-1)                         (8) 
A partir de ces deux approximations (7) et (8), on d&#233;duit de l&#8217;&#233;quation (6) que: 
P((Ci,TMi)/NTj,(C1,TM1).. (Ci-1,TMi-1),Mi)=P(Ci/NTj,CPi-1.. CPi-l).P(TMi /Ci,CPi-1,TMPi-1)   (9)  
Et enfin &#224; partir des &#233;quations (5) et (9), on d&#233;duit &#224; partir de l&#8217;&#233;quation (4) que: 
P((Ci,TMi)&#198;Mi/NTj)=P((Ci,TMi)/Mi,NTj)  
= P (Nj  / Mrk). P (Ci/NTj, CPi-1,&#8230;, CPi-l) . P (TMi  / Ci, CPi-1, TMPi-1)                                  (10) 
</p>
<p>2.5 Applicabilit&#233; du mod&#232;le &#224; la langue arabe 
</p>
<p>Comme signal&#233; ci-dessus, nous avons consid&#233;r&#233; une approche s&#233;lective (voir paragraphe 2.2).  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Un Etiqueteur s&#233;mantique des &#233;nonc&#233;s en langue arabe 
</p>
<p>D&#251; aux sp&#233;cificit&#233;s de la langue arabe, on peut s&#8217;interroger sur l&#8217;ad&#233;quation de cette approche 
au traitement de cette langue. L&#8217;absence de la voyellation est l&#8217;une des sources d&#8217;ambigu&#239;t&#233;s 
majeure de la compr&#233;hension de cette langue. Pour mieux comprendre, le mot non voyell&#233; 
&#1576;&#1607;&#1584; (thalhab) par exemple peut avoir deux significations diff&#233;rentes selon la mani&#232;re de sa 
voyellation. Il a le sens du verbe partir en le pronon&#231;ant (thahaba), et de l&#8217;or lorsqu&#8217;il est 
prononc&#233; (thahabon). Ce mot peut &#234;tre ainsi interpr&#233;t&#233; par Ts= (&#1577;&#1570;&#1585;&#1581; (Mouvement), &#1577;&#1607;&#1580;&#1608; 
(destination)), ou par Ts=((m&#233;tal)  &#1606;&#1583;&#1593;&#1605; , &#1606;&#1610;&#1605;&#1579; (cher)). Or la d&#233;termination de la voyellation 
correspondante &#224; un mot (et par cons&#233;quent son sens), n&#233;cessite plusieurs niveaux de 
connaissances: morphologiques, syntaxiques, ... (Debili et al., 2002). Cette n&#233;cessit&#233; est 
surmont&#233;e dans notre cas par la nature du domaine restreint de l&#8217;application. Nous 
prospectons d&#8217;am&#233;liorer la performance de l&#8217;&#233;tiqueteur, en lui int&#233;grant des donn&#233;es 
syntaxiques.  
</p>
<p>3 Application du mod&#232;le  
Nous avons utilis&#233; une centaine d&#8217;&#233;nonc&#233;s (diff&#233;rents du ceux du corpus d&#8217;apprentissage), 
portant tous sur des demandes d&#8217;horaires pour le test. Le corpus d&#8217;apprentissage a &#233;t&#233; &#233;tiquet&#233; 
avec 37 Ts. Pour juger de la qualit&#233; de notre &#233;tiqueteur, nous avons calcul&#233; le pourcentage 
d&#8217;&#233;tiquettes s&#233;mantiques qui sont incorrectement attribu&#233;es, &#224; partir de la formule suivante: 
Taux_erreur=Ninc/N&#215;100. O&#249;, Ninc est le nombre de Ts incorrectement attribu&#233;s, et N est le 
nombre total des Ts attribu&#233;s par un expert au corpus de test. N est &#233;gal &#224; 500 dans ce test. La 
table ci-dessous montre les Taux_erreur des &#233;tiqueteurs s&#233;mantiques obtenus en consid&#233;rant 
des mod&#232;les bi-classes et tri-classes ainsi que le mod&#232;le hybride d&#233;fini. La longueur de 
l&#8217;historique est fix&#233;e &#224; 3 pour la d&#233;termination des Ci et &#224; 2 pour TMi. 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p>Figure 5 : Taux d&#8217;erreur des &#233;tiqueteurs s&#233;mantiques consid&#233;r&#233;s. 
</p>
<p>4 Interpr&#233;tation des r&#233;sultats 
D&#8217;apr&#232;s la table ci-dessus, chaque fois que l&#8217;on int&#232;gre des donn&#233;es lexicales dans un mod&#232;le, 
le r&#233;sultat s&#8217;am&#233;liore. Nous avons utilis&#233; l&#8217;approche de (Katz, 1987) pour l'estimation des 
donn&#233;es manquantes. L&#8217;am&#233;lioration est encore meilleure, en consid&#233;rant en m&#234;me temps le 
type de l&#8217;&#233;nonc&#233; et les Ts pertinents, pour la pr&#233;diction du Ts suivant.  Nous remarquons que 
malgr&#233; l&#8217;am&#233;lioration de la qualit&#233; de l&#8217;&#233;tiqueteur s&#233;mantique, le taux d&#8217;erreur (qui atteint 
37%) reste comme m&#234;me un peu &#233;lev&#233;. Ceci est d&#251; au fait, que certains &#233;nonc&#233;s du corpus de 
test ont une structure syntaxique tr&#232;s complexe. Afin de rem&#233;dier ce probl&#232;me, certains 
</p>
<p>                                               Etiqueteurs s&#233;mantiques consid&#233;r&#233;s                                                           Taux_erreur 
</p>
<p>bi-classes:                             (1) P ((Ci, TMi) / Mi) = P (Ci / Ci-1)) x P (TMi  / Ci, Tsi-1)                                              57% 
avec consid&#233;ration lexicale: (2) P ((Ci, TMi) / Mi) = P (Ci /  Mi-1, Ci-1)) x P (TMi  / Mi,, Ci, Tsi-1)                              45%  
</p>
<p>tri-classes:                            (1) P ((Ci, TMi) / Mi) = P (Ci / Ci-1, Ci-2)) x P (TMi  / Ci, Tsi-1)                                    48,6%  
                                        (2) P ((Ci, TMi) / Mi) = P (Ci / Mi-1, Ci-1, Ci-2)) x P (TMi  / Mi, Ci, Tsi-1)                      41,2%
 
hybride k=2: (1) P ((Ci, TMi)/Mi, NTj) = P (NTj) x P(Ci/NTj, CPi-1, CPi-2)) x P (TMi / Ci, TsPi-1,)                          50%  
                        (2) P ((Ci, TMi)/Mi, NTj) = P (NTj) x P (Ci /NTj, Mi-1,CPi-1,CPi-2)) x P (TMi / Mi, Ci, TsPi-1)             39,4
</p>
<p>hybride k=3: (1) P ((Ci, TMi) / Mi, NTj) = P (NTj) x P (Ci / NTj, CPi-1, CPi-2)) x P (TMi / Ci,TsPi-1)                       46,8  
                        (2) P ((Ci, TMi)/ Mi, NTj) =P (NTj) x P(Ci / NTj, Mi-1, CPi-1, CPi-2))  x P (TMi /Mi,Ci, TsPi-1)            37%  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed 
</p>
<p>syst&#232;mes combinent une analyse syntaxique profonde avec une analyse s&#233;lective tel que le 
syst&#232;me TINA de (Seneff, 1992). D&#8217;autres syst&#232;mes utilisent les strat&#233;gies d&#8217;analyses du TAL 
robuste (Antoine et al., 2003). Ces syst&#232;mes sont performants dans des applications ouvertes.     
</p>
<p>5 Conclusion 
Nous avons pr&#233;sent&#233; dans cet article un &#233;tiqueteur s&#233;mantique bas&#233; sur un mod&#232;le de langage 
hybride. Ce mod&#232;le permet d&#8217;int&#233;grer des donn&#233;es contextuelles lexicales, s&#233;mantiques ainsi 
qu&#8217;illocutoire en m&#234;me temps. Il permet en plus de ne tenir compte que des traits s&#233;mantiques 
pertinents dans l&#8217;historique du mot &#224; interpr&#233;ter. Afin de montrer l&#8217;avantage de ce mod&#232;le, 
nous l&#8217;avons &#233;valu&#233; et compar&#233; par rapport aux mod&#232;les n-classes classiques, qui ne tiennent 
pas compte de la nature et du type de l&#8217;&#233;nonc&#233; dans le calcul de la probabilit&#233; d&#8217;interpr&#233;tation 
d&#8217;un mot par un Ts donn&#233;.  
</p>
<p>R&#233;f&#233;rences  
</p>
<p>Antoine J-Y., Goulian J., Villaneau J. (2003), Quand le TAL robuste s&#8217;attaque au langage 
parl&#233;: analyse incr&#233;mentale pour la compr&#233;hension de la parole spontan&#233;e, Actes de TALN. 
</p>
<p>Bennacef S., Bonneau-Maynard H., Gauvain J-L., Lamel L., Minker W. (1994), A spoken 
language for information retrieval, Actes de ICSLP, 1271-1274.    
</p>
<p>Bousquet-Vernhettes C. (2002), Compr&#233;hension robuste de la parole spontan&#233;e dans le 
dialogue oral homme-machine &#8211; D&#233;codage conceptuel stochastique, Th&#232;se de l&#8217;universit&#233; de 
Toulouse III, 84-85. 
</p>
<p>D&#233;bili F., Achour H., Souici E. (2002), La langue arabe et l'ordinateur: de l'&#233;tiquetage 
grammatical &#224; la voyellation automatique, Correspondances de l'IRMC, N&#176; 71, 10-28. 
 
Fillmore C. J. (1968), The case for case, Hollt and Rinehart and Winston Inc.   
</p>
<p>Katz S.M. (Katz, 1987), Estimation of probabilities from sparse data for the language model 
component of a speech recognizer, IEEE Transactions on Acoustics, Speech and Signal 
Processing, 400-401. 
 
Lef&#232;vre F. (2000), Estimation de probabilit&#233; non param&#233;trique pour la reconnaissance 
markovienne de la parole, Th&#232;se de l'Universit&#233; Pierre et Marie Curie. 
</p>
<p>Minker W. (1999), Compr&#233;hension automatique de la parole spontan&#233;e, Paris, L&#8217;Harmattan.  
</p>
<p>Seneff S. (1992), Robust parsing for spoken language systems, Actes de ICASSP, 189-192.  
</p>
<p>Zouaghi A., Zrigui M., Ben Ahmed M. (2004), Une structure s&#233;mantique pour l&#8217;interpr&#233;tation 
des &#233;nonc&#233;s en langue arabe, Actes de JEP-TALN-ARABIC. 
</p>
<p>Zouaghi A., Zrigui M., Ben Ahmed M. (2005), A statistical model for semantic decoding of 
Arabic language statements, Actes de NODALIDA. </p>

</div></div>
</body></html>