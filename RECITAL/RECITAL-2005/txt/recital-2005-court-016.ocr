RECITAL 2005, Dourdan, 6-10 juin 2005

Un étiqueteur sémantique des énoncés en langue arabe

Anis Zouaghi (1 ), Mounir Zrigui (2) et Mohamed Ben Ahmed (3)

(1) et (2) Laboratoire RIADI (unite de Monastir) - Université du centre
Faculte des Sciences de Monastir - Tunisie
(l) Anis.Zouaghi@riadi.mu.tn
(2) Mounir.Zrigui@fsm.rnu.tn
(3) Laboratoire RIADI - Université de la Mannouba
Ecole Nationale Supérieure d’Informatique de la Mannouba - Tunisie
Mohamed.BenAhmed@riadi.mu.tn

Mots-clefs — Keywords

Modeles statistiques de langage — Modeles n-classes — Décodage sémantique — Approche
componentielle et sélective.

Statistical models of language — Models N-classes — Semantic analyze — Componential and
selective approach.

Résumé — Abstract

Notre article s’integre dans le cadre du projet intitulé Oréodule: un systeme de
reconnaissance, de traduction et de synthese de la parole spontanée. L’objectif de cet article
est de présenter un modele d’étiquetage probabiliste, selon une approche componentielle et
sélective. Cette approche ne considere que les éléments de l’énoncé porteurs de sens. La
signiﬁcation de chaque mot est représentée par un ensemble de traits sémantiques Ts. Ce
modele participe au choix des Ts candidats lors du décodage sémantique d’un énoncé.

The work reported here is part of a larger research project, Oréodule, aiming at developing
tools for automatic speech recognition, translation, and synthesis for the Arabic language.
This article focuses on a probabilistic labelling model, according to a componential and
selective approach. This approach considers only the elements of the statement carrying
direction. The significance of each word is represented by a whole of semantic features Ts.
This model takes part in the choice of the Ts candidates at the time of the semantic decoding
of a statement.

Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed

1 Introduction

Depuis quelques annees, La tendance est Vers l’utilisation des modeles de langages
statistiques dans le domaine de la comprehension automatique de la parole spontanee
(Bousquet, 2002), (Lefevre, 2002), etc. Pour la langue arabe, l’utilisation de tels modeles a
notre connaissance constitue une nouveaute. L’aVantage principal de ces modeles statistiques
par rapport aux modeles a syntaxe ﬁxe (Bennacef et al., 1994) est qu’ils sont plus portables
Vers d’autres domaines (Minker, 1999), et necessite moins de recours a un expert humain.
Dans cet article, nous proposons un etiqueteur semantique base sur un modele de langage
probabiliste hybride [Zouaghi et al., 2005] pour l’interprétation d’une sequence de mots
reconnue par le module de reconnaissance de la parole. Ce modele participe au choix des
ensembles de traits semantiques Ts candidats, en tenant compte des données suivantes: le type
d’acte illocutoire accompli par l’enonce (demande, refus, excuse, etc.), le type de l’enonce
(demande de reservation, de tarifs, etc.), des mots deja interpretes (les traits semantiques
utilises), et de la probabilite d’interprétation d’un mot par un Ts candidat.

2 Modélc probabiliste

2.1 Corpus d’apprentissage

Le corpus d’apprentissage considere decrit des demandes de renseignements ferroviaires, en
langue arabe classique. Chaque mot signiﬁcatif dans ce corpus se Voit attribuer un ensemble
de traits (Ts), tel que deﬁni dans (Zouaghi et al., 2004). Le mot %‘5l5Sl (qui Va) par exemple se
Voit attribuer Ts = (Transport_FerroViaire, Mouvement, Destination). Les mots synonymiques
ou possedant un meme r6le semantique sont interpretes Via un meme Ts. Pareil, pour les mots
derives a partir d’une meme racine morphologique et possedant un meme sens (tels que *.—‘5l3il
(qui Va) et @553 (Va) qui sont derives a partir de la racine «.453 (dhahaba)). Nous avons utilise
une quarantaine de Ts differents pour l’etiquetage du corpus. En plus chaque enonce de ce
corpus se Voit attribuer une etiquette permettant de preciser le type de l’enonce. En tout, nous
avons utilise sept etiquettes.

Domaine Taille (Mo) Nombre Nombre de Nombre de
d’enonces mots locuteurs
Renseignements ferroviaires 3,4 10000 85900 1000

Figure 1 : Caracteristiques du corpus de point de Vue de son Volume.

Nature de la tache Renseignements sur les: Reservations autres
Taux de sa horaires trajets tarifs durees 10,41 % 40, 64%
representation
28,7% 9,37% I6,66% 3,12 %

Figure 2 : Caracteristiques du corpus de point de Vue de son contenu.

Un Etiqueteur semantique des enonces en langue arabe

Ce corpus a été collecte en demandant a cent personnes de formuler des enonces relatifs aux
renseignements ferroviaires. Donc c’est un corpus simule et non pas reel. L’inconVenient de
ce type de corpus est qu’i1 ne perrnet pas de decrire parfaitement1’app1ication.

2.2 Principe du décodage sémantique
Nous entendons par decodage semantique d’un enonce, 1’etiquetage de chacun de ses mots

signiﬁcatifs Via un Ts (Zouaghi et a1., 2004). Seulement les mots porteurs de sens parrni ceux
qui sont reconnus sont interpretes.

Mots reconnus Mots porteurs Eti r <
r < quetage semantlque
__> Pretraitements de sens

mb Interpretation de la sequence
de mots

a l’instant t

Modele de langage
probabiliste

 

Figure 3 : Principe du decodage semantique.

Soit la sequence de mots signiﬁcatifs S = M1 M2 M3 M4 obtenus apres la phase de
pretraitement (ﬁgure 3). Soit Tsl, Ts2 et Ts3 les traits affectes respectivement aux mots M1,
M2 et M3. A partir de ces donnees, nous Voulons determiner 1e Ts correspondant a M4. Pour
atteindre cet objectif, nous utilisons un modele de langage probabiliste hybride, perrnettant de
tenir compte du type et de la nature de1’enonce, ainsi que des mots deja interpretes (ﬁgure 4).

Mots deja

4 TS, ........ .59
mterpretes , 9 
5  ,, Mot a
Type de l’enonce

interpreter
Figure 4 : Integration des donnees semantiques et du type de1’enonce dans 1’interpretation.

  

 

2.3 Description du modele

Les systemes a base de modeles de langage probabilistes tentent de determiner 1e score
d’une sequence de mots S = mi, m2, ..., mi, dont la formule generale est la suivante:
P (S) : P (m1).P (mg/mi)  P (mi-/mi, mg,  m,-_;) (I)
Dans le cas de 1’etiquetage I d’une sequence de mots signiﬁcatifs Mi...Mii, par Tsi...Tsii, 1e
modele tente de determiner 1e score d’interpretation de chacun de ces mots, par chacun de ces
traits. Soit I=Tsi9Mi. ..Tsii9Mii, la Vraisemblance de 1 est alors deﬁnie comme suit: P (I) :
P (TS1...TSn\M1... Mn): P (TS1m41...M]J. P (TS;/TS],  P (Tsn /TS]... TS,,_1,  :
P(TS1m41) . P (TS;/TS],  .P (TS,,/ TS]... TSn_1,  (2)
Nous signalons que le passage de la deuxieme a la troisieme ligne correspond a une
approximation du modele, qui considere que la probabilite d'un Tsi ne depend,
conditionnellement a la sequence complete des traits, qu'au mot courant Mi. En ﬁxant a
1’aVance le domaine de 1’app1ication, chaque mot signiﬁcatif Mi peut étre interprete via Tsi =
(Ci, TMi), ou Ci indique la classe a laquelle appartient 1e mot Mi, et TMi 1e trait micro
semantique qui lui correspond. L’ equation (2) deVient:
P(I):P((C1,ﬂW1)M1).P((C2,H42)/(C1,ﬂ\41),M2)..P((C,,,ﬂ\4,,)/(C1, 71%;)... (C -1, ﬂ\4,,_1),M,,) (3)

Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed

Nous avons intégré dans l’équation (4) d’autres sources d’informations afin d’améliorer la
qualité du décodeur sémantique. Ceci, en tenant compte du type de l’énoncé noté par NTJ»
(avec P (NTi/Mi...Mii) est la probabilité conditionnelle d’aVoir un énoncé de type NTi).
P (I) : P (TS1...TSniNY}-, M1... Mn) : P  Mn). P ((C1, W1)  M1) . P ((C2, W2)
/NT,-,-(C1, 2M1),M2)  P ((Cn: M) /NY;-. (C1, mu... (Cn-I; m,-1),Mn) (4)

2.4 Lissage du modéle

La premiere approximation appliquée a ce modele consiste a ne considérer pour la
détermination du type de l’énoncé, que certains mots appelés mots de reférence notés Mrk.
Les mots de référence sont des mots dont leurs occurrences dans un énoncé permettent de
déterminer son type. Ces mots sont en fait des uni-grammes, ou des bi-grammes, et dans
certains cas des tri-grammes, dont la probabilité est égale a un. Par exemple le bi-gramme
J1-L-35‘ (le train) Jul (je veux) constitue un mot de référence, permettant d’identiﬁer les énoncés
de type réservation. Ce bi-gramme ne peut étre rencontré que dans les énoncés du corpus
d’apprentissage qui sont étiquetés par l’étiquette <Réservation> (on a: P (J1-L35‘ (le train)/Jul
(je Veux))=l). On obtient ainsi la substitution suivante:
PW];/Mi ...M,) :P /Mrk) (5)
La deuxieme hypothese de modélisation porte sur les relations d’indépendance conditionnelle
dans le modele et concerne la probabilité jointe P((Ci,TMi)/NTi,(Ci,TMi)...(Ci-i,TMi-i), Mi).
P((C,-, Yllli)/NY}, (C1, Yl\41)...(C,--1, Il\4-_1),1\4,):

1’ (C:/NY}. (C1, YMI)-~ (C,--1, YM-z).M:}- P (TM /C13 N7}: (Cz,YMz)---(Cu, YM-z).Mz} (6)
Aﬁn de simpliﬁer ce modele, nous avons considéré seulement les Ts jugés pertinents TsP
(CP, TMP) a la prédiction du Ts correspondant au mot Mi noté par Ts (A4,). Un Ts n’est
considéré pertinent, que lorsqu’il est suivi par un nombre k minime de Ts (k tend Vers 1).
Nous avons fixé k = 3, car nous pensons que pour k= 1, la grammaire devient tres rigide et ca
revient a considérer dans l’historique du mot Mi que les mots jouant le role de marqueurs
(Fillmore, 1968). Par exemple, l’ensemble de traits Ts = (3SJ=_J-53»
(Indice_mouVement), 3«A.3_J-534 (Indice_destination)) est un Ts pertinent car cet ensemble
est touj ours succédé dans le corpus d’apprentissage par Ts = (3-'94-° (Ville), 34+; (destination)).
k correspondant a Ts=(Indice_mouVement, Indice_destination) est ainsi égal a 1. La deuxieme
approximation considérée est que Ci a un instant t, ne dépend que des classes pertinentes
précédentes CP et du type de l’énoncé, on a ainsi:
P (C,-/NY}, (C1, 71%;)... (C,-_;, HM-_1),1\4,) :P (C,-/NY}, CP,-_1,..., CP,-4) (7)
Une autre approximation considérée, est que TMi du Ts(M), a un instant t, ne dépend que de
la classe Ci affectée a Mi et du trait pertinent précédent TsPi-i(CPi-i, TMPi.i). Ainsi on a:
P (77% /C1':N7i': (C1, NW1)-~ (CH, NW"-I).1Wz) :1) (NW: /Ci, CPH, 77WPi—I) (8)
A partir de ces deux approximations (7) et (8), on déduit de l’équation (6) que:
P((C,-, M4,)/IVY}, (C1, H41)” (C--1, Ylll-_1),1\4,):P(C,-/IVY}-,CP,-_1.. CP,-_i).P(Yl\4,-/Ci,CP,--1,Yl\4Pi_1) (9)
Et enfin a partir des equations (5) et (9), on déduit a partir de l’équation (4) que:
1’( ( Ci: TM) 9M/IVY}? :1’ ( ( Ci; TM)/MJV T1)

: P  /Mrk). P (C,-/NY}, CP,-_1,..., CP,-4) . P (71%; /Ci, CP,--1, NW’,--1) (10)

2.5 Applicabilité du modéle in la langue arabe

Comme signalé ci-dessus, nous avons considéré une approche sélective (Voir paragraphe 2.2).

Un Etiqueteur sémantique des énoncés en langue arabe

Dﬁ aux spéciﬁcités de la langue arabe, on peut s’interroger sur1’adéquation de cette approche
au traitement de cette langue. L’absence de la Voyellation est 1’une des sources d’ambigu'1'tés
majeure de la compréhension de cette langue. Pour mieux comprendre, 1e mot non Voyellé
«.453 (thalhab) par exemple peut avoir deux signiﬁcations différentes selon la maniere de sa
Voyellation. 11 a le sens du Verbe partir en 1e prononcant (thahaba), et de 1’or 1orsqu’i1 est
prononcé (thahabon). Ce mot peut étre ainsi interprété par Ts= (35): (Mouvement), 34+;
(destination)), ou par Ts=((méta1) om , 0+5 (cher)). Or la détermination de la Voyellation
correspondante £1 un mot (et par conséquent son sens), nécessite plusieurs niveaux de
connaissances: morphologiques, syntaxiques,  (Debili et a1., 2002). Cette nécessité est
surmontée dans notre cas par la nature du domaine restreint de 1’app1ication. Nous
prospectons d’amé1iorer la performance de 1’étiqueteur, en lui intégrant des données
syntaxiques.

3 Application du modéle

Nous avons utilisé une centaine d’énoncés (différents du ceux du corpus d’apprentissage),
portant tous sur des demandes d’horaires pour le test. Le corpus d’apprentissage a été étiqueté
avec 37 Ts. Pour juger de la qualité de notre étiqueteur, nous avons calculé 1e pourcentage
d’étiquettes sémantiques qui sont incorrectement attribuées, £1 partir de la formule suivante:
Taux_erreur:N,-,,C/Nx100. ou, Nine est le nombre de Ts incorrectement attribués, et N est le
nombre total des Ts attribués par un expert au corpus de test. N est égal 51 500 dans ce test. La
table ci-dessous montre les Taux_erreur des étiqueteurs sémantiques obtenus en considérant
des modeles bi-classes et tri-classes ainsi que le modele hybride déﬁni. La longueur de
1’historique est ﬁxée £1 3 pour la détermination des Ci et 51 2 pour TMi.

Etiqueteurs sémantiques considérés Taux_m,,r
bi'C1aSSeS:  P ((Ci,   = P  Ci_1» X P  /  TSi_1) 
avec consideration lexicalez (2) P ((Ci, TMi) / Mi) = P (Ci/ MH, Ci_1)) x P (TMi / Mi", Ci, Tsi_1) 45%
tri'C1aSSeS:  P ((Ci,   = P  Ci_1, Ci_2» X P  /  TSi_1) 

(2) P ((Ci, TMi) /Mi) = P (Ci/Mi-1, Ci—l, Ci-2)) X P (TMi /Mi, Ci, TSi—1) 413%

   P ((Ci, TMi)/Mi,  = P  X  CPi_1, CPi_2» X P   TSPi_1,) 
(2) P ((Ci, TMi)/Mi, NTj) = P (NTj) X P (Ci/NTj, Mi—1,CPi-1,CPi-2)) X P (TMi/ Mi, Ci, TSPi—1) 39,4

 k:3:  P ((Ci,  /Mi,  = P  X P   CPi_1, CPi_2)) X P  Ci,TSPi_1) 
(2) P ((Ci, TMi)/ Mi, NTj) =P (NTj) X P(Ci/ NTj, Mi—1, CPi-1, CPi-2)) X P (TMi/Mi,Ci, TSPi-1) 37%

Figure 5 : Taux d’erreur des étiqueteurs sémantiques considérés.

4 Interprétation des résultats

D’apres la table ci-dessus, chaque fois que l’on integre des données lexicales dans un modele,
le résultat s’amé1iore. Nous avons utilisé 1’approche de (Katz, 1987) pour 1'estimation des
données manquantes. L’amé1ioration est encore meilleure, en considérant en méme temps 1e
type de 1’énoncé et les Ts pertinents, pour la prédiction du Ts suivant. Nous remarquons que
malgré 1’amé1ioration de la qualité de 1’étiqueteur sémantique, 1e taux d’erreur (qui atteint
37%) reste comme méme un peu élevé. Ceci est dﬁ au fait, que certains énoncés du corpus de
test ont une structure syntaxique tres complexe. Aﬁn de remédier ce probleme, certains

Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed

systemes combinent une analyse syntaxique profonde avec une analyse sélective tel que le
systeme TINA de (Seneff, 1992). D’autres systemes utilisent les stratégies d’analyses du TAL
robuste (Antoine et al., 2003). Ces systemes sont performants dans des applications ouvertes.

5 Conclusion

Nous avons présenté dans cet article un étiqueteur sémantique basé sur un modele de langage
hybride. Ce modele permet d’intégrer des données contextuelles lexicales, sémantiques ainsi
qu’illocutoire en méme temps. Il permet en plus de ne tenir compte que des traits sémantiques
pertinents dans l’historique du mot a interpréter. Aﬁn de montrer l’aVantage de ce modele,
nous l’aVons évalué et comparé par rapport aux modeles n-classes classiques, qui ne tiennent
pas compte de la nature et du type de l’énoncé dans le calcul de la probabilité d’interprétation
d’un mot par un Ts donné.

Références

Antoine J-Y., Goulian J., Villaneau J. (2003), Quand le TAL robuste s’attaque au langage
parlé: analyse incrémentale pour la compréhension de la parole spontanée, Actes de TALN.

Bennacef S., Bonneau-Maynard H., Gauvain J-L., Lamel L., Minker W. (1994), A spoken
language for information retrieval, Actes de ICSLP, 1271-1274.

Bousquet-Vemhettes C. (2002), Comprehension robuste de la parole spontanée dans le
dialogue oral homme-machine — Décodage conceptuel stochastique, These de l’uniVersité de
Toulouse III, 84-85.

Débili F., Achour H., Souici E. (2002), La langue arabe et l'ordinateur: de l'étiquetage
grammatical a la Voyellation automatique, Correspondances de l ’IRMC, N° 71, 10-28.

Fillmore C. J. (1968), The case for case, Hollt and Rinehart and Winston Inc.

Katz S.M. (Katz, 1987), Estimation of probabilities from sparse data for the language model
component of a speech recognizer, IEEE Transactions on Acoustics, Speech and Signal
Processing, 400-401.

Lefevre F. (2000), Estimation de probabilité non paramétrique pour la reconnaissance
markovienne de la parole, These de l'UniVersité Pierre et Marie Curie.

Minker W. (1999), Comprehension automatique de la parole spontanée, Paris, L’Harmattan.
Seneff S. (1992), Robust parsing for spoken language systems, Actes de ICASSP, 189-192.

Zouaghi A., Zrigui M., Ben Ahmed M. (2004), Une structure sémantique pour l’interprétation
des énoncés en langue arabe, Actes de JEP-TALN-ARABIC.

Zouaghi A., Zrigui M., Ben Ahmed M. (2005), A statistical model for semantic decoding of
Arabic language statements, Actes de NODALIDA.

