<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J-Y Antoine</author>
<author>J Goulian</author>
<author>J Villaneau</author>
</authors>
<title>Quand le TAL robuste s’attaque au langage parlé: analyse incrémentale pour la compréhension de la parole spontanée, Actes de TALN.</title>
<date>2003</date>
<contexts>
<context position="14274" citStr="Antoine et al., 2003" startWordPosition="2283" endWordPosition="2286">e l’énoncé et les Ts pertinents, pour la prédiction du Ts suivant. Nous remarquons que malgré l’amélioration de la qualité de l’étiqueteur sémantique, le taux d’erreur (qui atteint 37%) reste comme même un peu élevé. Ceci est dû au fait, que certains énoncés du corpus de test ont une structure syntaxique très complexe. Afin de remédier ce problème, certains Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed systèmes combinent une analyse syntaxique profonde avec une analyse sélective tel que le système TINA de (Seneff, 1992). D’autres systèmes utilisent les stratégies d’analyses du TAL robuste (Antoine et al., 2003). Ces systèmes sont performants dans des applications ouvertes. 5 Conclusion Nous avons présenté dans cet article un étiqueteur sémantique basé sur un modèle de langage hybride. Ce modèle permet d’intégrer des données contextuelles lexicales, sémantiques ainsi qu’illocutoire en même temps. Il permet en plus de ne tenir compte que des traits sémantiques pertinents dans l’historique du mot à interpréter. Afin de montrer l’avantage de ce modèle, nous l’avons évalué et comparé par rapport aux modèles n-classes classiques, qui ne tiennent pas compte de la nature et du type de l’énoncé dans le calcu</context>
</contexts>
<marker>Antoine, Goulian, Villaneau, 2003</marker>
<rawString>Antoine J-Y., Goulian J., Villaneau J. (2003), Quand le TAL robuste s’attaque au langage parlé: analyse incrémentale pour la compréhension de la parole spontanée, Actes de TALN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bennacef</author>
<author>H Bonneau-Maynard</author>
<author>J-L Gauvain</author>
<author>L Lamel</author>
<author>W Minker</author>
</authors>
<title>A spoken language for information retrieval,</title>
<date>1994</date>
<booktitle>Actes de ICSLP,</booktitle>
<pages>1271--1274</pages>
<contexts>
<context position="2307" citStr="Bennacef et al., 1994" startWordPosition="336" endWordPosition="339"> whole of semantic features Ts. This model takes part in the choice of the Ts candidates at the time of the semantic decoding of a statement. Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed 1 Introduction Depuis quelques années, La tendance est vers l’utilisation des modèles de langages statistiques dans le domaine de la compréhension automatique de la parole spontanée (Bousquet, 2002), (Lefèvre, 2002), etc. Pour la langue arabe, l’utilisation de tels modèles à notre connaissance constitue une nouveauté. L’avantage principal de ces modèles statistiques par rapport aux modèles à syntaxe fixe (Bennacef et al., 1994) est qu’ils sont plus portables vers d’autres domaines (Minker, 1999), et nécessite moins de recours à un expert humain. Dans cet article, nous proposons un étiqueteur sémantique basé sur un modèle de langage probabiliste hybride [Zouaghi et al., 2005] pour l’interprétation d’une séquence de mots reconnue par le module de reconnaissance de la parole. Ce modèle participe au choix des ensembles de traits sémantiques Ts candidats, en tenant compte des données suivantes: le type d’acte illocutoire accompli par l’énoncé (demande, refus, excuse, etc.), le type de l’énoncé (demande de réservation, de</context>
</contexts>
<marker>Bennacef, Bonneau-Maynard, Gauvain, Lamel, Minker, 1994</marker>
<rawString>Bennacef S., Bonneau-Maynard H., Gauvain J-L., Lamel L., Minker W. (1994), A spoken language for information retrieval, Actes de ICSLP, 1271-1274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Bousquet-Vernhettes</author>
</authors>
<title>Compréhension robuste de la parole spontanée dans le dialogue oral homme-machine – Décodage conceptuel stochastique, Thèse de l’université de Toulouse III,</title>
<date>2002</date>
<pages>84--85</pages>
<marker>Bousquet-Vernhettes, 2002</marker>
<rawString>Bousquet-Vernhettes C. (2002), Compréhension robuste de la parole spontanée dans le dialogue oral homme-machine – Décodage conceptuel stochastique, Thèse de l’université de Toulouse III, 84-85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Débili</author>
<author>H Achour</author>
<author>E Souici</author>
</authors>
<title>La langue arabe et l&apos;ordinateur: de l&apos;étiquetage grammatical à la voyellation automatique, Correspondances de l&apos;IRMC,</title>
<date>2002</date>
<journal>N°</journal>
<volume>71</volume>
<pages>10--28</pages>
<marker>Débili, Achour, Souici, 2002</marker>
<rawString>Débili F., Achour H., Souici E. (2002), La langue arabe et l&apos;ordinateur: de l&apos;étiquetage grammatical à la voyellation automatique, Correspondances de l&apos;IRMC, N° 71, 10-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Fillmore</author>
</authors>
<title>The case for case, Hollt and Rinehart and</title>
<date>1968</date>
<publisher>Winston Inc.</publisher>
<contexts>
<context position="9227" citStr="Fillmore, 1968" startWordPosition="1455" endWordPosition="1456">, Mi). P((Ci,TMi)/NTj,(C1,TM1)...(Ci-1,TMi-1),Mi)= P (Ci / NTj, (C1, TM1)... (Ci-1, TMi-1), Mi). P (TMi / Ci, NTj, (C1,TM1)...(Ci-1, TMi-1), Mi) (6) Afin de simplifier ce modèle, nous avons considéré seulement les Ts jugés pertinents TsP (CP, TMP) à la prédiction du Ts correspondant au mot Mi noté par Ts (Mi). Un Ts n’est considéré pertinent, que lorsqu’il est suivi par un nombre k minime de Ts (k tend vers 1). Nous avons fixé k = 3, car nous pensons que pour k= 1, la grammaire devient très rigide et ça revient à considérer dans l’historique du mot Mi que les mots jouant le rôle de marqueurs (Fillmore, 1968). Par exemple, l’ensemble de traits Ts = (ةآرح_رشؤم (Indice_mouvement), ةهجو_رشؤم (Indice_destination)) est un Ts pertinent car cet ensemble est toujours succédé dans le corpus d’apprentissage par Ts = (ةنيدم (ville), ةهجو (destination)). k correspondant à Ts=(Indice_mouvement, Indice_destination) est ainsi égal à 1. La deuxième approximation considérée est que Ci à un instant t, ne dépend que des classes pertinentes précédentes CP et du type de l’énoncé, on a ainsi: P (Ci / NTj, (C1, TM1)... (Ci-1, TMi-1), Mi) = P (Ci/NTj, CPi-1,..., CPi-l) (7) Une autre approximation considérée, est que TMi </context>
</contexts>
<marker>Fillmore, 1968</marker>
<rawString>Fillmore C. J. (1968), The case for case, Hollt and Rinehart and Winston Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Katz</author>
</authors>
<title>Estimation of probabilities from sparse data for the language model component of a speech recognizer,</title>
<date>1987</date>
<journal>IEEE Transactions on Acoustics, Speech and Signal Processing,</journal>
<pages>400--401</pages>
<contexts>
<context position="13535" citStr="Katz, 1987" startWordPosition="2171" endWordPosition="2172">i-1, CPi-2)) x P (TMi / Ci, TsPi-1,) 50% (2) P ((Ci, TMi)/Mi, NTj) = P (NTj) x P (Ci /NTj, Mi-1,CPi-1,CPi-2)) x P (TMi / Mi, Ci, TsPi-1) 39,4 hybride k=3: (1) P ((Ci, TMi) / Mi, NTj) = P (NTj) x P (Ci / NTj, CPi-1, CPi-2)) x P (TMi / Ci,TsPi-1) 46,8 (2) P ((Ci, TMi)/ Mi, NTj) =P (NTj) x P(Ci / N Tj, Mi-1, CPi-1, CPi-2)) x P (TMi /Mi,Ci, TsPi-1) 37% Figure 5 : Taux d’erreur des étiqueteurs sémantiques considérés. 4 Interprétation des résultats D’après la table ci-dessus, chaque fois que l’on intègre des données lexicales dans un modèle, le résultat s’améliore. Nous avons utilisé l’approche de (Katz, 1987) pour l&apos;estimation des données manquantes. L’amélioration est encore meilleure, en considérant en même temps le type de l’énoncé et les Ts pertinents, pour la prédiction du Ts suivant. Nous remarquons que malgré l’amélioration de la qualité de l’étiqueteur sémantique, le taux d’erreur (qui atteint 37%) reste comme même un peu élevé. Ceci est dû au fait, que certains énoncés du corpus de test ont une structure syntaxique très complexe. Afin de remédier ce problème, certains Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed systèmes combinent une analyse syntaxique profonde avec une analyse sélec</context>
</contexts>
<marker>Katz, 1987</marker>
<rawString>Katz S.M. (Katz, 1987), Estimation of probabilities from sparse data for the language model component of a speech recognizer, IEEE Transactions on Acoustics, Speech and Signal Processing, 400-401.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Lefèvre</author>
</authors>
<title>Estimation de probabilité non paramétrique pour la reconnaissance markovienne de la parole, Thèse de l&apos;Université Pierre et Marie Curie.</title>
<date>2000</date>
<marker>Lefèvre, 2000</marker>
<rawString>Lefèvre F. (2000), Estimation de probabilité non paramétrique pour la reconnaissance markovienne de la parole, Thèse de l&apos;Université Pierre et Marie Curie.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Minker</author>
</authors>
<title>Compréhension automatique de la parole spontanée,</title>
<date>1999</date>
<location>Paris, L’Harmattan.</location>
<contexts>
<context position="2376" citStr="Minker, 1999" startWordPosition="348" endWordPosition="349">candidates at the time of the semantic decoding of a statement. Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed 1 Introduction Depuis quelques années, La tendance est vers l’utilisation des modèles de langages statistiques dans le domaine de la compréhension automatique de la parole spontanée (Bousquet, 2002), (Lefèvre, 2002), etc. Pour la langue arabe, l’utilisation de tels modèles à notre connaissance constitue une nouveauté. L’avantage principal de ces modèles statistiques par rapport aux modèles à syntaxe fixe (Bennacef et al., 1994) est qu’ils sont plus portables vers d’autres domaines (Minker, 1999), et nécessite moins de recours à un expert humain. Dans cet article, nous proposons un étiqueteur sémantique basé sur un modèle de langage probabiliste hybride [Zouaghi et al., 2005] pour l’interprétation d’une séquence de mots reconnue par le module de reconnaissance de la parole. Ce modèle participe au choix des ensembles de traits sémantiques Ts candidats, en tenant compte des données suivantes: le type d’acte illocutoire accompli par l’énoncé (demande, refus, excuse, etc.), le type de l’énoncé (demande de réservation, de tarifs, etc.), des mots déjà interprétés (les traits sémantiques uti</context>
</contexts>
<marker>Minker, 1999</marker>
<rawString>Minker W. (1999), Compréhension automatique de la parole spontanée, Paris, L’Harmattan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Seneff</author>
</authors>
<title>Robust parsing for spoken language systems,</title>
<date>1992</date>
<booktitle>Actes de ICASSP,</booktitle>
<pages>189--192</pages>
<contexts>
<context position="14181" citStr="Seneff, 1992" startWordPosition="2272" endWordPosition="2273">nquantes. L’amélioration est encore meilleure, en considérant en même temps le type de l’énoncé et les Ts pertinents, pour la prédiction du Ts suivant. Nous remarquons que malgré l’amélioration de la qualité de l’étiqueteur sémantique, le taux d’erreur (qui atteint 37%) reste comme même un peu élevé. Ceci est dû au fait, que certains énoncés du corpus de test ont une structure syntaxique très complexe. Afin de remédier ce problème, certains Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed systèmes combinent une analyse syntaxique profonde avec une analyse sélective tel que le système TINA de (Seneff, 1992). D’autres systèmes utilisent les stratégies d’analyses du TAL robuste (Antoine et al., 2003). Ces systèmes sont performants dans des applications ouvertes. 5 Conclusion Nous avons présenté dans cet article un étiqueteur sémantique basé sur un modèle de langage hybride. Ce modèle permet d’intégrer des données contextuelles lexicales, sémantiques ainsi qu’illocutoire en même temps. Il permet en plus de ne tenir compte que des traits sémantiques pertinents dans l’historique du mot à interpréter. Afin de montrer l’avantage de ce modèle, nous l’avons évalué et comparé par rapport aux modèles n-cla</context>
</contexts>
<marker>Seneff, 1992</marker>
<rawString>Seneff S. (1992), Robust parsing for spoken language systems, Actes de ICASSP, 189-192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Zouaghi</author>
<author>M Zrigui</author>
<author>Ben Ahmed M</author>
</authors>
<title>Une structure sémantique pour l’interprétation des énoncés en langue arabe, Actes de JEP-TALN-ARABIC.</title>
<date>2004</date>
<contexts>
<context position="3342" citStr="Zouaghi et al., 2004" startWordPosition="490" endWordPosition="493">ues Ts candidats, en tenant compte des données suivantes: le type d’acte illocutoire accompli par l’énoncé (demande, refus, excuse, etc.), le type de l’énoncé (demande de réservation, de tarifs, etc.), des mots déjà interprétés (les traits sémantiques utilisés), et de la probabilité d’interprétation d’un mot par un Ts candidat. 2 Modèle probabiliste 2.1 Corpus d’apprentissage Le corpus d’apprentissage considéré décrit des demandes de renseignements ferroviaires, en langue arabe classique. Chaque mot significatif dans ce corpus se voit attribuer un ensemble de traits (Ts), tel que défini dans (Zouaghi et al., 2004). Le mot بهاذلا (qui va) par exemple se voit attribuer Ts = (Transport_Ferroviaire, Mouvement, Destination). Les mots synonymiques ou possédant un même rôle sémantique sont interprétés via un même Ts. Pareil, pour les mots dérivés à partir d’une même racine morphologique et possédant un même sens (tels que بهاذلا (qui va) et بهذي (va) qui sont dérivés à partir de la racine بهذ (dhahaba)). Nous avons utilisé une quarantaine de Ts différents pour l’étiquetage du corpus. En plus chaque énoncé de ce corpus se voit attribuer une étiquette permettant de préciser le type de l’énoncé. En tout, nous av</context>
<context position="4882" citStr="Zouaghi et al., 2004" startWordPosition="739" endWordPosition="742">rées 10,41 % 40,64% représentation 28,7 % 9,37 % 16,66 % 3,12 % Figure 2 : Caractéristiques du corpus de point de vue de son contenu. Un Etiqueteur sémantique des énoncés en langue arabe Ce corpus a été collecté en demandant à cent personnes de formuler des énoncés relatifs aux renseignements ferroviaires. Donc c’est un corpus simulé et non pas réel. L’inconvénient de ce type de corpus est qu’il ne permet pas de décrire parfaitement l’application. 2.2 Principe du décodage sémantique Nous entendons par décodage sémantique d’un énoncé, l’étiquetage de chacun de ses mots significatifs via un Ts (Zouaghi et al., 2004). Seulement les mots porteurs de sens parmi ceux qui sont reconnus sont interprétés. Mots reconnus Prétraitements Mots porteurs Etiquetage sémantique de sens Interprétation de la séquence de mots à l’instant t Modèle de langage probabiliste Figure 3 : Principe du décodage sémantique. Soit la séquence de mots significatifs S = M1 M2 M3 M4 obtenus après la phase de prétraitement (figure 3). Soit Ts1, Ts2 et Ts3 les traits affectés respectivement aux mots M1, M2 et M3. A partir de ces données, nous voulons déterminer le Ts correspondant à M4. Pour atteindre cet objectif, nous utilisons un modèle </context>
</contexts>
<marker>Zouaghi, Zrigui, M, 2004</marker>
<rawString>Zouaghi A., Zrigui M., Ben Ahmed M. (2004), Une structure sémantique pour l’interprétation des énoncés en langue arabe, Actes de JEP-TALN-ARABIC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Zouaghi</author>
<author>M Zrigui</author>
<author>Ben Ahmed M</author>
</authors>
<title>A statistical model for semantic decoding of Arabic language statements, Actes de NODALIDA.</title>
<date>2005</date>
<contexts>
<context position="2558" citStr="Zouaghi et al., 2005" startWordPosition="375" endWordPosition="378">utilisation des modèles de langages statistiques dans le domaine de la compréhension automatique de la parole spontanée (Bousquet, 2002), (Lefèvre, 2002), etc. Pour la langue arabe, l’utilisation de tels modèles à notre connaissance constitue une nouveauté. L’avantage principal de ces modèles statistiques par rapport aux modèles à syntaxe fixe (Bennacef et al., 1994) est qu’ils sont plus portables vers d’autres domaines (Minker, 1999), et nécessite moins de recours à un expert humain. Dans cet article, nous proposons un étiqueteur sémantique basé sur un modèle de langage probabiliste hybride [Zouaghi et al., 2005] pour l’interprétation d’une séquence de mots reconnue par le module de reconnaissance de la parole. Ce modèle participe au choix des ensembles de traits sémantiques Ts candidats, en tenant compte des données suivantes: le type d’acte illocutoire accompli par l’énoncé (demande, refus, excuse, etc.), le type de l’énoncé (demande de réservation, de tarifs, etc.), des mots déjà interprétés (les traits sémantiques utilisés), et de la probabilité d’interprétation d’un mot par un Ts candidat. 2 Modèle probabiliste 2.1 Corpus d’apprentissage Le corpus d’apprentissage considéré décrit des demandes de</context>
</contexts>
<marker>Zouaghi, Zrigui, M, 2005</marker>
<rawString>Zouaghi A., Zrigui M., Ben Ahmed M. (2005), A statistical model for semantic decoding of Arabic language statements, Actes de NODALIDA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>