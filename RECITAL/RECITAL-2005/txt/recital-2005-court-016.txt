RECITAL 2005, Dourdan, 6-I0juin 2005

Un étiqueteur sémantique des énoncés en langue arabe

Anis Zouaghi (I), Mounir Zrigui (2) et Mohamed Ben Ahmed (3)

(1) et (2) Laboratoire RIADI (unite de Monastir) - Université du centre
Faculté des Sciences de Monastir - Tunisie
(1) Anis.Zouaghi@riadi.rnu.tn
(2) Mounir.Zrigui@fsm.rnu.tr1
(3) Laboratoire RIADI - Université de la Mannouba
Ecole Nationale Supérieure d’Informatique de la Mannouba - Tunisie
Mohamed.BenAhmed@riadi.rnu.tr1

Mots-clefs — Keywords

Modéles statistiques de langage — Modéles n-classes — Décodage sémantique — Approche
componentielle et sélective.

Statistical models of language — Models N-classes — Semantic analyze — Componential and
selective approach.

Résumé — Abstract

Notre article s’intégre dans le cadre du projet intitulé Oréodule: un systéme de
reconnaissance, de traduction et de synthése de la parole spontanée. L’objectif de cet article
est de présenter un modéle d’étiquetage probabiliste, selon une approche componentielle et
sélective. Cette approche ne considére que les éléments de l’énoncé porteurs de sens. La
signiﬁcation de chaque mot est représentée par un ensemble de traits sémantiques Ts. Ce
modéle participe au choix des Ts candidats lors du décodage sémantique d’un énoncé.

The work reported here is part of a larger research project, Oréodule, aiming at developing
tools for automatic speech recognition, translation, and synthesis for the Arabic language.
This article focuses on a probabilistic labelling model, according to a componential and
selective approach. This approach considers only the elements of the statement carrying
direction. The signiﬁcance of each word is represented by a whole of semantic features Ts.
This model takes part in the choice of the Ts candidates at the time of the semantic decoding
of a statement.

727

728

Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed

1 Introduction

Depuis quelques annees, La tendance est vers l’utilisation des modeles de langages
statistiques dans le domaine de la comprehension automatique de la parole spontanee
(Bousquet, 2002), (Lefevre, 2002), etc. Pour la langue arabe, l’utilisation de tels modeles a
notre connaissance constitue une nouveaute. L’avantage principal de ces modeles statistiques
par rapport aux modeles a syntaxe ﬁxe (Bennacef et al., 1994) est qu’ils sont plus portables
vers d’autres domaines (Minker, 1999), et necessite moins de recours a un expert humain.
Dans cet article, nous proposons un etiqueteur semantique base sur un modele de langage
probabiliste hybride [Zouaghi et al., 2005] pour l’interpretation d’une sequence de mots
reconnue par le module de reconnaissance de la parole. Ce modele participe au choix des
ensembles de traits semantiques Ts candidats, en tenant compte des donnees suivantes: le type
d’acte illocutoire accompli par l’enonce (demande, reﬁ1s, excuse, etc.), le type de l’enonce
(demande de reservation, de tarifs, etc.), des mots deja interpretes (les traits semantiques
utilises), et de la probabilite d’interpretation d’un mot par un Ts candidat.

2 Modéle probabiliste

2.1 Corpus d’apprentissage

Le corpus d’apprentissage considere decrit des demandes de renseignements ferroviaires, en
langue arabe classique. Chaque mot signiﬁcatif dans ce corpus se voit attribuer un ensemble
de traits (Ts), tel que deﬁni dans (Zouaghi et al., 2004). Le mot £95133‘ (qui va) par exemple se
voit attribuer Ts = (Transport_Ferroviaire, Mouvement, Destination). Les mots synonymiques
ou possedant un meme rele semantique sont interpretes via un meme Ts. Pareil, pour les mots
derives a partir d’une meme racine morphologique et possedant un meme sens (tels que 6.45133‘
(qui va) et «.4532 (va) qui sont derives a partir de la racine «.453 (dhahaba)). Nous avons utilise
une quarantaine de Ts differents pour l’etiquetage du corpus. En plus chaque enonce de ce
corpus se voit attribuer une etiquette permettant de preciser le type de l’enonce. En tout, nous
avons utilise sept etiquettes.

Domaine Taille (Mo) Nombre Nombre de Nombre de
d’enonces mots locuteurs
Renseignements ferroviaires 3, 4 I 0000 85900 I 000

Figure 1 : Caracteristiques du corpus de point de vue de son volume.

Nature de la tache Renseignements sur les: Reservations autres
Taux de sa horaires trajets tarifs durees 10,41 % 40, 64%
representation
28,7% 9,37 % 16,66 % 3,12 %

Figure 2 : Caracteristiques du corpus de point de vue de son contenu.

Un Etiqueteur sémantique des enonces en langue arabe

Ce corpus a ete collecte en demandant a cent personnes de formuler des enonces relatifs aux
renseignements ferroviaires. Donc c’est un corpus simulé et non pas reel. L’inconvenient de
ce type de corpus est qu’i1 ne permet pas de decrire parfaitement 1’app1ication.

2.2 Principe du décodage sémantique

Nous entendons par décodage sémantique d’un enonce, 1’etiquetage de chacun de ses mots
signiﬁcatifs via un Ts (Zouaghi et a1., 2004). Seulement les mots porteurs de sens parmi ceux
qui sont reconnus sont interpretes.

Mots reconnus , Mots porteurs
__> Pretraitements de sens

a l’instant t

Etiquetage sémantique mb Interpretation de la sequence
de mots

Modele de langage
probabiliste

 

Figure 3 : Principe du décodage sémantique.

Soit la sequence de mots signiﬁcatifs S = M1 M2 M3 M4 obtenus apres la phase de
pretraitement (ﬁgure 3). Soit Tsl, Ts2 et Ts3 les traits affectes respectivement aux mots M1,
M2 et M3. A partir de ces donnees, nous voulons determiner 1e Ts correspondant a M4. Pour
atteindre cet objectif, nous utilisons un modele de langage probabiliste hybride, perrnettant de
tenir compte du type et de la nature de 1’enonce, ainsi que des mots deja interpretes (ﬁgure 4).

Mots deja
interpretes

  

 

Type de l’enonce

Figure 4 : Integration des donnees semantiques et du type de 1’enonce dans 1’interpretation.

2.3 Description du modéle

Les systemes a base de modeles de langage probabilistes tentent de determiner 1e score
d’une sequence de mots S = mi, II12, ..., mi, dont la formule generale est la suivante:
P (S) = P (m1).P (mg/mi)  P (mi/mi, mg, ..., mi_1) (I)
Dans le cas de 1’etiquetage I d’une sequence de mots signiﬁcatifs Mi...Mii, par Tsi...Tsii, 1e
modele tente de determiner 1e score d’interpretation de chacun de ces mots, par chacun de ces
traits. Soit I=Tsi9Mi...Tsii9Mii, la vraisemblance de I est alors deﬁnie comme suit: P (I) =
P (TS1...TSn|M1... Mn): P (TS1/M1...M]i}r). P (TS)/TS],  P (Ts,, /TS]... TS,,_1, M1... Mn) =
P (Tsi/M1) . P (Ts2/ Tsi, M2)... .P (Ts,,/ Tsi... Ts,,_i, Mn) (2)
Nous signalons que le passage de la deuxieme a la troisieme ligne correspond a une
approximation du modele, qui considere que la probabilite d'un Tsi ne depend,
conditionnellement a la sequence complete des traits, qu'au mot courant Mi. En ﬁxant a
1’avance le domaine de 1’app1ication, chaque mot signiﬁcatif Mi peut etre interprete via Tsi =
(Ci, TMi), ou Ci indique la classe a laquelle appartient 1e mot Mi, et TMi 1e trait micro
sémantique qui lui correspond. L’equation (2) devient:
P(I)=P((C1,TM1)/M1).P((C2,TM2)/(C1,TM1),M2)..P((Cn,TM")/(C,TM1)...(Cn-I,TMn—I)»Mn) 

729

730

Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed

Nous avons integre dans l’equation (4) d’autres sources d’informations aﬁn d’ameliorer la
qualite du decodeur semantique. Ceci, en tenant compte du type de l’enonce note par NT]-
(avec P (NT,-/Mi...Mii) est la probabilite conditionnelle d’avoir un enonce de type NT]-).
P (I) = P (Tsi...Ts,,|NZ}, Mi... M,,) = P (N7)/Mi... M,,). P ((Ci, TMi) /NZ}, Mi) . P ((C2, TM2)
/N]},.(Ci, TMi),M2)  P ((C,,, TM") /NZ}, (Ci, TMi)... (C,,_i, TM,,_i), Mn) (4)

2.4 Lissage du modéle

La premiere approximation appliquee a ce modele consiste a ne considerer pour la
determination du type de l’enonce, que certains mots appeles mots de référence notes Mrk.
Les mots de reference sont des mots dont leurs occurrences dans un enonce permettent de
determiner son type. Ces mots sont en fait des uni-grammes, ou des bi-grammes, et dans
certains cas des tri-grammes, dont la probabilite est egale a un. Par exemple le bi-gramme
ﬂail‘ (le train) :3)‘ Ge veux) constitue un mot de reference, permettant d’identiﬁer les enonces
de type reservation. Ce bi-gramme ne peut etre rencontre que dans les enonces du corpus
d’apprentissage qui sont etiquetes par l’etiquette <Reservation> (on a: P (31-3311 (le train)/Jul
(je veux))=1). On obtient ainsi la substitution suivante:
P(N1}/Mi...M,,) =P(N7}/Mrk) (5)
La deuxieme hypothese de modelisation porte sur les relations d’independance conditionnelle
dans le modele et concerne la probabilite jointe P((Ci,TMi)/NT]-,(Ci,TMi)...(Ci_i,TMi_i), Mi).
P((C,~,TM)/NY},(Ci,TM1)...(Ci.1,T1W—1),Mi)=

P (Ci/N7}? (C1, TM1)--- (Ci-I; TIWPI)» Mz9- P(T1Wz°/Ci» N7} (C1,TMI)---(Cz—1, TIWPI), Mi) (6)
Aﬁn de simpliﬁer ce modele, nous avons considere seulement les Ts juges pertinents TsP
(CP, TMP) a la prediction du Ts correspondant au mot Mi note par Ts ﬂlli). Un Ts n’est
considere pertinent, que lorsqu’il est suivi par un nombre k minime de Ts (k tend vers 1).
Nous avons ﬁxe k = 3, car nous pensons que pour k= 1, la grammaire devient tres rigide et ca
revient a considerer dans l’historique du mot Mi que les mots jouant le role de marqueurs
(Fillmore, 1968). Par exemple, l’ensemble de traits Ts = (3SJ=_J-3:3»
(Indice_mouvement), 1e+;_J-5'=3~ (Indice_destination)) est un Ts pertinent car cet ensemble
est toujours succede dans le corpus d’apprentissage par Ts = (3-3244 (ville), 14+; (destination)).
k correspondant a Ts=(Indice_mouvement, Indice_destination) est ainsi egal a 1. La deuxieme
approximation consideree est que Ci a un instant t, ne depend que des classes pertinentes
precedentes CP et du type de l’enonce, on a ainsi:
P (Ci/NZ}, (Ci, TMi)... (Ci_i, TMi_i), Mi) =P (C,~ﬂ\/'1}, CPi_i,..., CPi_;) (7)
Une autre approximation consideree, est que TMi du Ts(M,), a un instant t, ne depend que de
la classe Ci affectee a Mi et du trait pertinent precedent TsPi_i(CPi_i, TMPi_i). Ainsi on a:
P (TMi /Ci, N1}, (Ci, TMi)... (C,~_i, TMi_i), M) = P (TM /Ci, CPi_i, TMP,~_i) (8)
A partir de ces deux approximations (7) et (8), on deduit de l’equation (6) que:
P((Ci,TMQ/A/7},(Ci,TM1).. (Ci_i,T]m_i),MQ=P(Ci/]\/'1},CPi_i.. CPi_;).P(TMi/Ci,CPi_i,TMPi_i) (9)
Et enﬁn a partir des equations (5) et (9), on deduit a partir de l’equation (4) que:
P((C,~, TM 9 9M,/NTJ) =P((Ci, TM Q/Mi,NT,~)

= P (N, /Mrk). P (Ci/Jvrj, CP,~_,,  CP,~_;) . P (TMi / Ci, CPi_i, TMP,~_i) (10)

2.5 Applicabilité du modéle :71 la langue arabe

Comme signale ci-dessus, nous avons considere une approche selective (voir paragraphe 2.2).

Un Etiqueteur sémantique des énoncés en langue arabe

Dﬁ aux spéciﬁcités de la langue arabe, on peut s’interroger sur1’adéquation de cette approche
au traitement de cette langue. L’absence de la voyellation est 1’une des sources d’ambigu'ités
majeure de la comprehension de cette langue. Pour mieux comprendre, 1e mot non voyellé
‘.453 (thalhab) par exemple peut avoir deux signiﬁcations différentes selon la maniere de sa
voyellation. II a le sens du verbe partir en 1e prononcant (thahaba), et de 1’or 1orsqu’i1 est
prononcé (thahabon). Ce mot peut étre ainsi interprété par Ts= (35): (Mouvement), 14+;
(destination)), ou par Ts=((méta1) 04:-A , as-«3 (cher)). Or la determination de la voyellation
correspondante a un mot (et par consequent son sens), nécessite plusieurs niveaux de
connaissances: morphologiques, syntaxiques,  (Debili et a1., 2002). Cette nécessité est
surmontée dans notre cas par la nature du domaine restreint de 1’app1ication. Nous
prospectons d’amé1iorer la performance de 1’étiqueteur, en lui intégrant des données
syntaxiques.

3 Application du modéle

Nous avons utilise une centaine d’énoncés (différents du ceux du corpus d’apprentissage),
portant tous sur des demandes d’horaires pour le test. Le corpus d’apprentissage a été étiqueté
avec 37 Ts. Pour juger de la qualité de notre étiqueteur, nous avons calculé 1e pourcentage
d’étiquettes sémantiques qui sont incorrectement attribuées, a partir de la formule suivante:
Taux_erreur=N,~,,c/]\/'xI00. on, N,-nc est le nombre de Ts incorrectement attribués, et N est le
nombre total des Ts attribués par un expert au corpus de test. N est égal a 500 dans ce test. La
table ci-dessous montre les Taux_erreur des étiqueteurs sémantiques obtenus en considérant
des modeles bi-classes et tri-classes ainsi que le modele hybride déﬁni. La longueur de
1’historique est ﬁxée a 3 pour la determination des Ci et a 2 pour TMi.

Etiqueteurs sémantiques considérés Tm_mu,
bi-Classes:  P ((Ci,   = P  C14» X P  /  TSi_1) 
avec considération lexicale: (2) P ((Ci, TMi) / Mi) = P (Ci/ MM, Ci_1)) x P (TM; / Mi’, Ci, Ts“) 45%
tri-classes: (1) P ((Ci, TMi) / Mi) = P (Ci/ CH, Ci_2)) x P (TM; / Ci, Ts“) 48,6%

(2) P «Ci, TM0 / Mi) = P (Ci / Mi-1, Cm, Ci-2)) X P (TMi / Mi, Ci, TSi.1) 419%

 k=2:  P ((Ci, TMO/Mi,  = P  X  CPL], CPi_2» X P   TSPi_1,) 
(2) P «Ci, TMi)/Mi, NTj) = P (NTj) X P (Ci/NTj, Mi-1,CPi-l,CPi-2)) X P (TMi/ Mi, Ci, TSPi-1) 39,4

 k=3I  P «Ci,  /Mi,  = P  X P  CPL], CPi_2)) X P  Ci,TSPi_1) 
(2) P «Ci, TM,)/ Mi, NT,~) =P (NT,~) x Pm / NT,~, Mi-1,CPi-1, cP,.,» x P (TM, /M,,Ci, Ts1=..,) 37%

Figure 5 : Taux d’erreur des étiqueteurs sémantiques considérés.

4 Interprétation des résultats

D’apres la table ci-dessus, chaque fois que l’on integre des données lexicales dans un modele,
1e résultat s’amé1iore. Nous avons utilise 1’approche de (Katz, 1987) pour 1'estimation des
données manquantes. L’amé1ioration est encore meilleure, en considérant en meme temps 1e
type de 1’énoncé et les Ts pertinents, pour la prediction du Ts suivant. Nous remarquons que
malgré 1’amé1ioration de la qualité de 1’étiqueteur sémantique, 1e taux d’erreur (qui atteint
37%) reste comme meme un peu élevé. Ceci est dﬁ au fait, que certains énoncés du corpus de
test ont une structure syntaxique tres complexe. Afm de remédier ce probleme, certains

731

732

Anis Zouaghi, Mounir Zrigui et Mohamed Ben Ahmed

systemes combinent une analyse syntaxique profonde avec une analyse selective tel que le
systeme TINA de (Seneff, 1992). D’autres systemes utilisent les strategies d’analyses du TAL
robuste (Antoine et al., 2003). Ces systemes sont performants dans des applications ouvertes.

5 Conclusion

Nous avons presente dans cet article un etiqueteur semantique base sur un modele de langage
hybride. Ce modele permet d’integrer des donnees contextuelles lexicales, semantiques ainsi
qu’illocutoire en meme temps. Il permet en plus de ne tenir compte que des traits semantiques
pertinents dans l’historique du mot a interpreter. Aﬁn de montrer l’avantage de ce modele,
nous l’avons evalue et compare par rapport aux modeles n-classes classiques, qui ne tiennent
pas compte de la nature et du type de l’enonce dans le calcul de la probabilite d’interpretation
d’un mot par un Ts donne.

References

Antoine J-Y., Goulian J ., Villaneau J. (2003), Quand le TAL robuste s’attaque au langage
parle: analyse incrementale pour la comprehension de la parole spontanee, Actes de TALN.

Bennacef S., Bonneau-Maynard H., Gauvain J -L., Lamel L., Minker W. (1994), A spoken
language for information retrieval, Actes de ICSLP, 1271-1274.

Bousquet-Vernhettes C. (2002), Comprehension robuste de la parole spontanee dans le
dialogue oral homme-machine — Decodage conceptuel stochastique, These de l’uniVersite de
Toulouse III, 84-85.

Debili F., Achour H., Souici E. (2002), La langue arabe et l'ordinateur: de l'etiquetage
grammatical a la voyellation automatique, Correspondances de l’IRMC, N° 71, 10-28.

Fillmore C. J. (1968), The case for case, Hollt and Rinehart and Winston Inc.

Katz S.M. (Katz, 1987), Estimation of probabilities from sparse data for the language model
component of a speech recognizer, IEEE Transactions on Acoustics, Speech and Signal
Processing, 400-401.

Lefevre F. (2000), Estimation de probabilite non parametrique pour la reconnaissance
markovienne de la parole, These de l'Universite Pierre et Marie Curie.

Minker W. (1999), Comprehension automatique de la parole spontanee, Paris, L’Harmattan.
Seneff S. (1992), Robust parsing for spoken language systems, Actes de ICASSP, 189-192.

Zouaghi A., Zrigui M., Ben Ahmed M. (2004), Une structure semantique pour l’interpretation
des enonces en langue arabe, Actes de JEP-TALN-ARABIC.

Zouaghi A., Zrigui M., Ben Ahmed M. (2005), A statistical model for semantic decoding of
Arabic language statements, Actes de NODALIDA.

