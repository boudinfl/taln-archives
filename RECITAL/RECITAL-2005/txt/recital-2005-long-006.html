<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>A la d&#233;couverte de la polys&#233;mie des sp&#233;cificit&#233;s du fran&#231;ais technique</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#201;CITAL 2005, Dourdan, 6-10 juin 2005 
</p>
<p>A la d&#233;couverte de la polys&#233;mie des sp&#233;cificit&#233;s                              
du fran&#231;ais technique 
</p>
<p>Ann Bertels 
</p>
<p>ILT &#8211; K.U.Leuven 
Dekenstraat 6 &#8211; B-3000 LEUVEN (Belgique) 
</p>
<p>ann.bertels@ilt.kuleuven.ac.be 
</p>
<p>Mots-clefs &#8211; Keywords 
</p>
<p>s&#233;mantique lexicale, langue sp&#233;cialis&#233;e, sp&#233;cificit&#233;s, polys&#233;mie, cooccurrences 
</p>
<p>lexical semantics, language for specific purposes (LSP), keywords, polysemy, co-occurrences 
</p>
<p>R&#233;sum&#233; &#8211; Abstract 
</p>
<p>Cet article d&#233;crit l&#8217;analyse s&#233;mantique des sp&#233;cificit&#233;s dans le domaine technique des 
machines-outils pour l&#8217;usinage des m&#233;taux. Le but de cette &#233;tude est de v&#233;rifier si et dans 
quelle mesure les sp&#233;cificit&#233;s dans ce domaine sont monos&#233;miques ou polys&#233;miques. Les 
sp&#233;cificit&#233;s (situ&#233;es dans un continuum de sp&#233;cificit&#233;) seront identifi&#233;es avec la KeyWords 
Method en comparant le corpus d&#8217;analyse &#224; un corpus de r&#233;f&#233;rence. Elles feront ensuite 
l&#8217;objet d&#8217;une analyse s&#233;mantique automatis&#233;e &#224; partir du recouvrement des cooccurrences des 
cooccurrences, afin d&#8217;&#233;tablir le continuum de monos&#233;mie. Les travaux de recherche &#233;tant en 
cours, nous pr&#233;senterons des r&#233;sultats pr&#233;liminaires de cette double analyse.  
</p>
<p>This article discusses a semantic analysis of pivotal terms (keywords) in the domain of 
machining terminology in French. Building on corpus data, the investigation attempts to find 
out whether, and to what extent, the keywords are polysemous. In order to identify the most 
typical words of the typicality continuum, the KeyWords Method will be used to compare the 
technical corpus with a reference corpus. The monosemy continuum will be implemented in 
terms of degree of overlap between the co-occurrents of the co-occurrents of the keywords. 
We present some preliminary results of work in progress. 
</p>
<p>1 Introduction et question de recherche 
</p>
<p>Cet article s&#8217;inscrit dans le cadre d&#8217;une th&#232;se de doctorat sur la s&#233;mantique du vocabulaire 
sp&#233;cifique d&#8217;un corpus de fran&#231;ais technique. Comme le corpus d&#8217;analyse rel&#232;ve du domaine </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ann Bertels 
</p>
<p>technique des machines-outils pour l&#8217;usinage des m&#233;taux, l&#8217;analyse s&#233;mantique porte sur les 
sp&#233;cificit&#233;s1 d&#8217;une langue sp&#233;cialis&#233;e. 
</p>
<p>Dans la langue sp&#233;cialis&#233;e, les besoins communicatifs requi&#232;rent plus de pr&#233;cision, ce que la 
terminologie traditionnelle d&#233;finit comme l&#8217;univocit&#233;, la monor&#233;f&#233;rentialit&#233; et la monos&#233;mie 
des unit&#233;s terminologiques de la langue sp&#233;cialis&#233;e. La terminologie traditionnelle 
prescriptive et normative adopte une approche onomasiologique par domaine. R&#233;cemment, la 
monos&#233;mie et l&#8217;univocit&#233; de la langue sp&#233;cialis&#233;e ont &#233;t&#233; remises en question par la Th&#233;orie 
Communicative de la Terminologie (Cabr&#233;, 1998, 2000), par la socioterminologie (Gaudin, 
1993) et par la terminologie socio-cognitive (Temmerman, 1997). Les termes font partie 
int&#233;grante de la langue naturelle, mais v&#233;hiculent des connaissances sp&#233;cialis&#233;es (Lerat, 
1995). Les partisans de la terminologie descriptive rejettent la dichotomie entre la langue 
g&#233;n&#233;rale et la langue sp&#233;cialis&#233;e et adoptent une approche s&#233;masiologique et linguistique, 
bas&#233;e sur l&#8217;&#233;tude de corpus de textes sp&#233;cialis&#233;s (Condamines &amp; Rebeyrolles, 1997). 
</p>
<p>Pour quantifier la th&#232;se monos&#233;miste de la terminologie traditionnelle, nous nous proposons 
de la reformuler en une question de recherche op&#233;rationnelle et mesurable : &#171; Y a-t-il une 
corr&#233;lation entre, d&#8217;une part, le continuum de sp&#233;cificit&#233; et, d&#8217;autre part, le continuum de 
monos&#233;mie (continuum de sens) ? &#187; L&#8217;hypoth&#232;se de recherche avanc&#233;e pose que, 
contrairement &#224; la th&#232;se traditionnelle, les mots (les plus) sp&#233;cifiques du corpus technique ne 
sont pas n&#233;cessairement (les plus) monos&#233;miques. L&#8217;analyse se propose donc de v&#233;rifier la 
polys&#233;mie des mots du corpus technique d&#8217;analyse, p.ex. le mot broche (1) &#171; partie tournante 
d&#8217;une machine-outil qui porte un outil ou une pi&#232;ce &#224; usiner &#187; et (2) &#171; outil servant &#224; usiner 
des pi&#232;ces m&#233;talliques &#187;. A cet effet, ces mots sont ordonn&#233;s en fonction de leur sp&#233;cificit&#233; et 
situ&#233;s sur une &#233;chelle de sp&#233;cificit&#233; allant des mots les plus sp&#233;cifiques aux mots les moins 
sp&#233;cifiques, mais comprenant toujours des sp&#233;cificit&#233;s statistiquement significatives du 
corpus technique. Un deuxi&#232;me classement situe les m&#234;mes mots sur une &#233;chelle de 
monos&#233;mie, &#224; partir d&#8217;une analyse des cooccurrences de deuxi&#232;me ordre, c&#8217;est-&#224;-dire les 
cooccurrences des cooccurrences. La question de recherche principale (corr&#233;lation entre le 
degr&#233; de sp&#233;cificit&#233; et le degr&#233; de monos&#233;mie) sera compl&#233;t&#233;e par des questions de recherche 
secondaires faisant intervenir les facteurs influant sur le degr&#233; de monos&#233;mie, notamment la 
fr&#233;quence et la classe lexicale. Une analyse de r&#233;gression multiple permettra de v&#233;rifier 
l&#8217;impact des variables ind&#233;pendantes (sp&#233;cificit&#233;, fr&#233;quence, classe lexicale, etc.) sur le degr&#233; 
de monos&#233;mie. 
</p>
<p>2 Corpus technique d&#8217;analyse et corpus de r&#233;f&#233;rence 
</p>
<p>Le corpus technique d&#8217;analyse est constitu&#233; de textes techniques du domaine des machines-
outils pour l&#8217;usinage des m&#233;taux et comprend environ 1.760.000 mots. Le corpus a &#233;t&#233; 
&#233;tiquet&#233; et lemmatis&#233; par Cordial 7 Analyseur et consiste en 4 sous-corpus, datant de 1998 &#224; 
2001 : revues techniques &#233;lectroniques (800.000) et fiches techniques (300.000) trouv&#233;es sur 
Internet, normes ISO et directives (300.000) et quatre manuels num&#233;ris&#233;s (360.000). Les 
textes se situent &#224; diff&#233;rents niveaux de normalisation et de vulgarisation, s&#8217;adressant tant &#224; 
des professionnels (revues et fiches) qu&#8217;&#224; des &#233;tudiants (manuels). Afin de pouvoir d&#233;terminer 
                                                 
1  Nous adoptons le terme &#171; sp&#233;cificit&#233;s &#187; pour d&#233;signer les mots les plus sp&#233;cifiques et caract&#233;ristiques du 
</p>
<p>corpus d&#8217;analyse, ind&#233;pendamment de la m&#233;thode utilis&#233;e (calcul des sp&#233;cificit&#233;s vs. KeyWords Method). </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>A la d&#233;couverte de la polys&#233;mie des sp&#233;cificit&#233;s du fran&#231;ais technique 
</p>
<p>les sp&#233;cificit&#233;s du corpus technique, il est compl&#233;t&#233; par un corpus de r&#233;f&#233;rence de langue 
g&#233;n&#233;rale. Celui-ci est constitu&#233; d&#8217;articles journalistiques du journal Le Monde (janvier &#8211; 
septembre 1998). Il a &#233;galement &#233;t&#233; lemmatis&#233; et comprend environ 15.300.000 mots. 
</p>
<p>Les fichiers g&#233;n&#233;r&#233;s par Cordial se composent de trois colonnes, avec un mot par ligne: (1) la 
forme fl&#233;chie ou forme graphique, (2) le lemme ou forme canonique et (3) le code Cordial, 
comparable &#224; un POS-tag (Part-Of-Speech) indiquant la classe lexicale. Dans les fichiers 
texte, nous avons corrig&#233; quelques fautes de frappe. Les fichiers lemmatis&#233;s ont &#233;galement 
fait l&#8217;objet d&#8217;un nettoyage, &#224; savoir quelques regroupements (p.ex. lemmes avec et sans point  
Fig./Fig et lemmes avec et sans trait d&#8217;union) et la correction des erreurs de lemmatisation 
(p.ex. machines-outils sous le lemme machine-outil). Ces op&#233;rations de nettoyage ont &#233;t&#233; 
effectu&#233;es, tant pour le corpus d&#8217;analyse technique que pour le corpus de r&#233;f&#233;rence.  
</p>
<p>3 Approche m&#233;thodologique : sp&#233;cificit&#233;s et polys&#233;mie 
</p>
<p>Comme la recherche porte sur la question de savoir s&#8217;il y a une corr&#233;lation entre le continuum 
de sp&#233;cificit&#233; et le continuum de monos&#233;mie, la r&#233;ponse et l&#8217;analyse linguistique qui en 
d&#233;coule requi&#232;rent une approche m&#233;thodologique double. Il faut d&#8217;une part le calcul des 
sp&#233;cificit&#233;s et d&#8217;autre part une mesure pour d&#233;terminer le degr&#233; de monos&#233;mie. Ces 
sp&#233;cificit&#233;s se situent, non seulement au niveau des unit&#233;s simples, p.ex. fraisage, commande, 
mais &#233;galement au niveau des unit&#233;s polylexicales, p.ex. commande num&#233;rique.  
</p>
<p>3.1 Sp&#233;cificit&#233;s 
</p>
<p>La recherche en langue sp&#233;cialis&#233;e prend g&#233;n&#233;ralement comme point de d&#233;part l&#8217;identification 
des sp&#233;cificit&#233;s, c&#8217;est-&#224;-dire des mots sp&#233;cifiques qui caract&#233;risent le corpus sp&#233;cialis&#233; et qui 
le diff&#233;rencient d&#8217;un corpus de langue g&#233;n&#233;rale. Les sp&#233;cificit&#233;s ne sont pas les mots les plus 
fr&#233;quents de ce corpus, mais les mots les plus repr&#233;sentatifs. Du point de vue relatif, ces mots 
figurent de fa&#231;on significative plus fr&#233;quemment dans le corpus de langue sp&#233;cialis&#233;e que 
dans un corpus de langue g&#233;n&#233;rale. Afin de d&#233;terminer les sp&#233;cificit&#233;s, les fr&#233;quences dans le 
corpus sp&#233;cialis&#233; sont compar&#233;es aux fr&#233;quences dans un corpus de r&#233;f&#233;rence, compte tenu de 
la taille des deux corpus, ce qui revient &#224; comparer la fr&#233;quence observ&#233;e (corpus d&#8217;analyse) &#224; 
la fr&#233;quence attendue (corpus de r&#233;f&#233;rence). S&#8217;il y a une diff&#233;rence entre la fr&#233;quence 
observ&#233;e et la fr&#233;quence attendue, il faut v&#233;rifier si elle est statistiquement significative. A cet 
effet, deux m&#233;thodologies sont d&#233;sormais disponibles : le calcul des sp&#233;cificit&#233;s (Lafon, 1984) 
impl&#233;ment&#233; dans le logiciel Lexico32, outils de statistique textuelle, et la KeyWords Method 
des logiciels WordSmith Tools3 et Abundantia Verborum4 (Speelman, 1997). Les deux 
m&#233;thodologies aboutissent grosso modo &#224; des r&#233;sultats similaires, &#224; savoir une liste de mots 
sp&#233;cifiques pourvus d&#8217;une mesure statistique indiquant le degr&#233; de sp&#233;cificit&#233;. Les diff&#233;rences 
les plus importantes r&#233;sident dans la m&#233;thodologie et la statistique sous-jacentes.  
</p>
<p>                                                 
2  Lexico3 : SYLED &#8211; CLA2T, Paris3 : http://www.cavi.univ-paris3.fr/ilpga/ilpga/tal/lexicoWWW/ 
</p>
<p>3  WordSmith Tools version 3 : http://www.lexically.net/wordsmith/ et http://www.oup.com 
</p>
<p>4  Abundantia Verborum : http://wwwling.arts.kuleuven.ac.be/genling/abundant/obtain/ </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ann Bertels 
</p>
<p>Premi&#232;rement, le calcul des sp&#233;cificit&#233;s (Lafon, 1984 et Labb&#233; &amp; Labb&#233;, 1991) compare une 
section d&#8217;un corpus au corpus entier afin d&#8217;identifier le vocabulaire sp&#233;cifique de cette 
section. La comparaison partie-tout permet de d&#233;cider si la fr&#233;quence relative d&#8217;un mot dans 
la section est sup&#233;rieure &#224; ce qui serait attendu, en fonction de la fr&#233;quence relative dans le 
corpus entier. L&#8217;analyse statistique sous-jacente au calcul des sp&#233;cificit&#233;s utilise le test de 
Fisher Exact, bas&#233; sur les probabilit&#233;s exactes de la distribution hyperg&#233;om&#233;trique. Fisher 
Exact est g&#233;n&#233;ralement utilis&#233; pour un ensemble de donn&#233;es de taille modeste (n &#8804; 20). En 
outre, les factorielles de la formule pour le calcul de la probabilit&#233; de la fr&#233;quence observ&#233;e 
(Lafon, 1984) m&#232;neraient &#224; des nombres astronomiques, si la formule &#233;tait appliqu&#233;e &#224; un 
corpus de quelques milliers, voire des millions de mots. Pour rem&#233;dier &#224; ce probl&#232;me, Lafon 
propose d&#8217;utiliser des logarithmes. D&#232;s lors, le r&#233;sultat du calcul x est &#224; interpr&#233;ter comme 
l&#8217;exposant de la base 10, d&#8217;o&#249; r&#233;sulte la probabilit&#233; 10x. Dans Lexico3, ce sont les exposants 
(r&#233;sultats de la formule du calcul hyperg&#233;om&#233;trique) qui figurent dans la colonne du 
coefficient de sp&#233;cificit&#233;. Les sp&#233;cificit&#233;s positives indiquent un suremploi dans la section 
analys&#233;e, tandis que les sp&#233;cificit&#233;s n&#233;gatives signalent un sous-emploi. Le calcul des 
sp&#233;cificit&#233;s est surtout utilis&#233; par la communaut&#233; francophone (Cf. Zimina, 2004 et Drouin, 
2004).  
</p>
<p>La deuxi&#232;me m&#233;thodologie permettant d&#8217;identifier les mots les plus sp&#233;cifiques est surtout 
utilis&#233;e par des utilisateurs du logiciel WordSmith&#8211;KeyWords (Berber-Sardinha, 1999). Elle 
est couramment appel&#233;e KeyWords Method ou m&#233;thode des mots-clefs. Les fr&#233;quences dans 
le corpus sp&#233;cialis&#233; sont compar&#233;es aux fr&#233;quences dans un corpus de r&#233;f&#233;rence de langue 
g&#233;n&#233;rale, compte tenu de la taille des deux corpus, ce qui permet d&#8217;identifier les mots 
significativement plus fr&#233;quents dans le corpus sp&#233;cialis&#233;. Il s&#8217;agit donc de la comparaison de 
deux corpus diff&#233;rents, et non d&#8217;une comparaison partie-tout. La deuxi&#232;me diff&#233;rence entre 
les deux m&#233;thodologies r&#233;side dans la statistique sous-jacente. La KeyWords Method se sert 
du ratio du log de vraisemblance (log likelihood ratio) (Dunning,1993). Cette statistique de 
test n&#8217;est pas bas&#233;e sur des probabilit&#233;s exactes et par cons&#233;quent, elle s&#8217;applique facilement &#224; 
des corpus plut&#244;t volumineux. Le ratio du log de vraisemblance sera d&#8217;autant plus &#233;lev&#233; que 
le mot est plus fr&#233;quent dans le corpus sp&#233;cialis&#233; par rapport au corpus de r&#233;f&#233;rence, indiquant 
d&#232;s lors son degr&#233; de sp&#233;cificit&#233;. La valeur p correspondante permet de supprimer les 
sp&#233;cificit&#233;s statistiquement non significatives (p&#8804;0.05). En plus, le tri des sp&#233;cificit&#233;s en 
fonction de la statistique de test (ratio du log de vraisemblance) permet de les classer par 
ordre de sp&#233;cificit&#233; d&#233;croissante et par cons&#233;quent, de les situer dans un continuum de 
sp&#233;cificit&#233;. 
</p>
<p>3.2 Polys&#233;mie 
</p>
<p>Les sp&#233;cificit&#233;s relev&#233;es dans le corpus technique d&#8217;analyse, font ensuite l&#8217;objet d&#8217;une 
analyse s&#233;mantique. Pour chaque sp&#233;cificit&#233;, on d&#233;terminera le degr&#233; de monos&#233;mie, dans le 
but de v&#233;rifier si les mots les plus sp&#233;cifiques sont en effet (les plus) monos&#233;miques et si les 
mots moins sp&#233;cifiques ont plus tendance &#224; &#234;tre polys&#233;miques. Il s&#8217;agira donc d&#8217;objectiver et 
de quantifier l&#8217;analyse s&#233;mantique, en ayant recours aux cooccurrences. Selon Sch&#252;tze 
(1998), V&#233;ronis (2003) et d&#8217;autres, les cooccurrences permettent de distinguer les diff&#233;rents 
usages et sens des mots. Audibert (2003) recourt m&#234;me aux cooccurrences comme crit&#232;res de 
d&#233;sambigu&#239;sation s&#233;mantique automatique. Dans V&#233;ronis (2003), les cooccurrences d&#8217;un mot, 
&#224; partir d&#8217;un grand corpus, sont regroup&#233;es suivant leur similarit&#233; ou dissimilarit&#233; (en fonction 
de leur co-fr&#233;quence) pour identifier les diff&#233;rents sens du mot. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>A la d&#233;couverte de la polys&#233;mie des sp&#233;cificit&#233;s du fran&#231;ais technique 
</p>
<p>Afin de d&#233;terminer le degr&#233; de monos&#233;mie des sp&#233;cificit&#233;s, nous proposons d&#8217;aller plus loin et 
d&#8217;&#233;tudier les cooccurrences de deuxi&#232;me ordre. Les cooccurrences des cooccurrences 
permettent de trouver des synonymes d&#8217;un mot, selon Martinez (2000). Pour le mot mesures, 
il trouve les cooccurrents nouvelles, prises, etc. qui cooccurrent &#224; leur tour avec d&#233;cisions. 
D&#8217;apr&#232;s Denhi&#232;re &amp; Lemaire (2003), les cooccurrences de deuxi&#232;me ordre et m&#234;me d&#8217;ordre 
sup&#233;rieur d&#233;terminent le degr&#233; d&#8217;association de deux mots M1 et M2, m&#234;me si ces deux mots 
ne figurent jamais ensemble. Si les cooccurrences M1-M3 et M2-M3 sont suffisamment 
fortes, on consid&#232;re que M1 et M2 sont associ&#233;s et des cooccurrents d&#8217;ordre 2. Il est 
&#233;galement possible d&#8217;extraire automatiquement les sens des mots &#224; partir d&#8217;un r&#233;seau de 
cooccurrences lexicales de deuxi&#232;me ordre, comme l&#8217;explique Ferret (2004). La connectivit&#233; 
des cooccurrents formant un sens est plus importante que leur connectivit&#233; avec les autres 
cooccurrents d&#233;finissant les autres sens de ce mot, la mesure de coh&#233;sion &#233;tant l&#8217;information 
mutuelle normalis&#233;e (Ferret, 2004). 
</p>
<p>Les cooccurrents de deuxi&#232;me ordre &#233;tant des crit&#232;res d&#233;sambigu&#239;sateurs puissants, ils seront 
tr&#232;s pr&#233;cieux lors de l&#8217;analyse s&#233;mantique des sp&#233;cificit&#233;s. En effet, le degr&#233; de recouvrement 
des cooccurrences de deuxi&#232;me ordre sera un indice important du degr&#233; de monos&#233;mie du mot 
de base. Pour &#233;tudier le caract&#232;re monos&#233;mique ou polys&#233;mique d&#8217;une unit&#233; linguistique, on 
v&#233;rifie si les contextes peuvent &#234;tre consid&#233;r&#233;s comme s&#233;mantiquement homog&#232;nes ou non 
(Condamines &amp; Rebeyrolles, 1997). L&#8217;acc&#232;s &#224; la s&#233;mantique des cooccurrences pourra se 
faire (automatiquement) par le biais des cooccurrences de deuxi&#232;me ordre. Le degr&#233; de 
recouvrement de ces cooccurrences de deuxi&#232;me ordre indiquera &#224; quel point les 
cooccurrences de premier ordre (contextes du mot de base) sont s&#233;mantiquement homog&#232;nes.  
</p>
<p>&#8226; Si les cooccurrents des cooccurrents (&#171; cc &#187; ou cooccurrents de deuxi&#232;me ordre) sont 
formellement tr&#232;s diff&#233;rents et se recouvrent tr&#232;s peu, les diff&#233;rents cooccurrents 
(&#171; c &#187; ou cooccurrents de premier ordre) seront s&#233;mantiquement plus diversifi&#233;s, une 
structure formelle de cooccurrence diff&#233;rente indiquant un sens diff&#233;rent. Les 
cooccurrents s&#233;mantiquement diversifi&#233;s appartenant &#224; plusieurs champs 
s&#233;mantiques, la sp&#233;cificit&#233; aura moins de chances d&#8217;&#234;tre monos&#233;mique.  
</p>
<p>&#8226; Et inversement, plus les cooccurrences des cooccurrences se recouvrent, plus les 
cooccurrents sont s&#233;mantiquement homog&#232;nes. Le degr&#233; de ressemblance ou 
similarit&#233; lexicale des cooccurrents d&#8217;un mot &#233;tant proportionnel au degr&#233; de 
monos&#233;mie de ce mot, un fort recouvrement des cooccurrents de deuxi&#232;me ordre 
signale un degr&#233; de monos&#233;mie plus important. 
</p>
<p>4 Premiers r&#233;sultats de la recherche : sp&#233;cificit&#233;s et polys&#233;mie 
</p>
<p>4.1 Sp&#233;cificit&#233;s 
</p>
<p>La liste des sp&#233;cificit&#233;s du corpus technique d&#8217;analyse (1,7 million de mots) est g&#233;n&#233;r&#233;e avec 
les logiciels Abundantia Verborum et AV Frequency List Tool. Une exp&#233;rimentation sur un 
&#233;chantillon restreint du corpus technique sur les trois logiciels disponibles pour le calcul des 
sp&#233;cificit&#233;s montre des r&#233;sultats comparables en termes de sp&#233;cificit&#233;s relev&#233;es. Pour garantir 
la comparaison des r&#233;sultats, le corpus technique a &#233;t&#233; incorpor&#233; dans le corpus de r&#233;f&#233;rence 
dans le logiciel Lexico3, proc&#233;dant par comparaison partie-tout. Force est de constater que la </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ann Bertels 
</p>
<p>m&#234;me proc&#233;dure d&#8217;incorporation pour le corpus entier (corpus technique de 1,7 million et 
corpus de r&#233;f&#233;rence de 15,3 millions) n&#8217;aboutit pas aux r&#233;sultats escompt&#233;s. M&#234;me si la liste 
de fr&#233;quence du grand corpus entier s&#8217;affiche, l&#8217;&#233;tape suivante du calcul des sp&#233;cificit&#233;s 
&#233;choue en raison de la taille trop importante du corpus. 
</p>
<p>Appliqu&#233;e au corpus technique lemmatis&#233;, la KeyWords Method produit une liste d&#8217;environ 
13.000 sp&#233;cificit&#233;s pour le corpus technique (p&#8804;0.05). A l&#8217;aide des codes Cordial, une liste de 
mots grammaticaux (450) et une liste de noms propres (7200) sont g&#233;n&#233;r&#233;es, permettant de les 
supprimer. Les op&#233;rations de filtrage et de nettoyage g&#233;n&#232;rent une liste de sp&#233;cificit&#233;s 
techniques d&#233;finitive de 7240 mots (lemmes), Cf. Figure 1, pour un aper&#231;u des 25 mots les 
plus sp&#233;cifiques. Ces 7240 mots feront l&#8217;objet de l&#8217;analyse s&#233;mantique automatis&#233;e pour 
&#233;tablir le degr&#233; de monos&#233;mie. La premi&#232;re colonne (Cf. Figure 1) contient les lemmes 
sp&#233;cifiques, les deuxi&#232;me et troisi&#232;me colonnes donnent la fr&#233;quence absolue dans le corpus 
technique (FREQ_ABS1) et dans le corpus de r&#233;f&#233;rence (FREQ_ABS 2). Dans la colonne 4, 
on voit la statistique de test LLR indiquant le degr&#233; de sp&#233;cificit&#233; et dans la colonne 5, le 
compl&#233;ment de la valeur p correspondante (1-p). Les colonnes 6 et 7 affichent les fr&#233;quences 
relatives (multipli&#233;es par 10000) pour les deux corpus et la derni&#232;re colonne informe sur le 
type de sp&#233;cificit&#233; (1 pour une sp&#233;cificit&#233; positive et &#8211;1 pour une sp&#233;cificit&#233; n&#233;gative). Il est &#224; 
remarquer que cette liste de sp&#233;cificit&#233;s contient aussi des mots de la langue g&#233;n&#233;rale (p.ex. 
type, permettre), sp&#233;cifiques de ce corpus technique. Ce ne sont pas des termes, mais ils sont 
maintenus car nous nous proposons de comparer leur degr&#233; de monos&#233;mie &#224; celui des termes 
(dans le corpus technique) et &#224; leur degr&#233; de monos&#233;mie dans un corpus de langue g&#233;n&#233;rale.   
</p>
<p>LEMME FREQ ABS1 FREQ ABS2 LLR 1-P FREQ REL1 FREQ REL2 SPEC POS 
machine 12671 1052 50521,91 1 74,51 0,71 1 
outil 8306 918 32037,72 1 48,84 0,62 1 
usinage 6720 8 30468,41 1 39,52 0,01 1 
pi&#232;ce 7556 2219 24407,46 1 44,43 1,50 1 
mm 5490 191 23357,57 1 32,28 0,13 1 
vitesse 5283 900 19108,78 1 31,07 0,61 1 
coupe 6730 4153 17063,37 1 39,58 2,80 1 
broche 2893 12 13010,42 1 17,01 0,01 1 
Fig 2680 0 12194,00 1 15,76 0,00 1 
axe 3206 420 12079,16 1 18,85 0,28 1 
copeau 2557 0 11634,18 1 15,04 0,00 1 
plaquette 2407 35 10592,46 1 14,15 0,02 1 
diam&#232;tre 2415 95 10200,09 1 14,20 0,06 1 
commande 2751 850 8765,71 1 16,18 0,57 1 
acier 2252 277 8558,49 1 13,24 0,19 1 
fraisage 1873 0 8521,34 1 11,01 0,00 1 
ar&#234;te 1870 29 8213,91 1 11,00 0,02 1 
pr&#233;cision 2263 541 7663,01 1 13,31 0,36 1 
usiner 1577 11 7045,52 1 9,27 0,01 1 
surface 2258 758 7037,02 1 13,28 0,51 1 
type 2820 1830 6994,07 1 16,58 1,23 1 
syst&#232;me 4052 5165 6915,85 1 23,83 3,48 1 
fraise 1571 45 6745,88 1 9,24 0,03 1 
gamme 1860 545 6006,35 1 10,94 0,37 1 
permettre 4883 9504 5848,03 1 28,71 6,41 1 
</p>
<p>Figure 1 : Les 25 mots les plus sp&#233;cifiques du corpus technique d&#8217;analyse </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>A la d&#233;couverte de la polys&#233;mie des sp&#233;cificit&#233;s du fran&#231;ais technique 
</p>
<p>4.2 Polys&#233;mie 
</p>
<p>Le degr&#233; de monos&#233;mie (ou inversement de polys&#233;mie) d&#233;pend du degr&#233; de recouvrement des 
cooccurrents des cooccurrents. Afin d&#8217;&#233;tablir les listes des cooccurrences pertinentes &#224; deux 
niveaux et de g&#233;n&#233;rer une base de donn&#233;es qui sera interrog&#233;e pour le calcul automatique du 
degr&#233; de recouvrement, nous avons recours &#224; un algorithme de scripts Python5.  
</p>
<p>Pour d&#233;terminer le degr&#233; de monos&#233;mie, nous proposons une formule (Cf. Figure 2), bas&#233;e 
sur le recouvrement des cooccurrents des cooccurrents (cc), en tenant compte (1) de la 
fr&#233;quence d&#8217;un cc dans la liste des cc (= nombre de cooccurrents (c) apparaissant avec ce cc), 
(2) du nombre total de c et (3) du nombre total de cc. La mesure d&#8217;association utilis&#233;e pour 
d&#233;terminer les cooccurrences pertinentes est la statistique LLR (log de vraisemblance). Nous 
ne prenons en consid&#233;ration que les cooccurrences statistiquement significatives (p&#8804;0.05). 
</p>
<p>&#8721; &#8901;cc   total#    total#
 fq
</p>
<p>ccc
cc
</p>
<p> 
</p>
<p>Figure 2 : Formule de recouvrement des cooccurrents des cooccurrents 
</p>
<p>Dans un premier temps, nous dressons une liste des cooccurrences pertinentes &#224; partir des 
fichiers lemmatis&#233;s du corpus technique, contenant le collocatif, la base6 et leur co-fr&#233;quence. 
Deux autres fichiers sont d&#233;riv&#233;s de ces informations et contiennent respectivement les bases 
et les collocatifs et leurs fr&#233;quences. Toutes ces informations permettront de g&#233;n&#233;rer une base 
de donn&#233;es avec des informations statistiques, &#224; savoir la statistique de test LLR et la valeur 
p. En fait, deux listes de cooccurrences avec leur base de donn&#233;es correspondante sont ainsi 
dress&#233;es : une premi&#232;re liste avec les sp&#233;cificit&#233;s comme base et leurs cooccurrents comme 
collocatif et une deuxi&#232;me liste de cooccurrences avec les cooccurrents de la premi&#232;re liste 
comme base et leurs cooccurrents (d&#8217;ordre 2) comme collocatif.  
</p>
<p>Les param&#232;tres modifiables sont le type de cooccurrent &#224; relever (lemme ou forme fl&#233;chie) et 
la fen&#234;tre d&#8217;observation. Nous optons pour une fen&#234;tre de [-5,+5], 5 mots &#224; gauche et 5 mots &#224; 
droite, parce qu&#8217;elle apporte assez d&#8217;information s&#233;mantique, sans qu&#8217;il y ait trop de bruit et 
qu&#8217;elle permet un traitement informatique efficace. Au premier niveau d&#8217;analyse de la 
sp&#233;cificit&#233; comme base, la base de la cooccurrence est n&#233;cessairement relev&#233;e sous forme 
lemmatis&#233;e, afin de pouvoir rattacher les informations s&#233;mantiques (degr&#233; de monos&#233;mie) aux 
informations de sp&#233;cificit&#233; (liste de sp&#233;cificit&#233;s). Pour le collocatif, la forme fl&#233;chie s&#8217;impose, 
en raison des informations s&#233;mantiques plus riches qu&#8217;elle v&#233;hicule (Cf. diff&#233;rence entre pi&#232;ce 
&#224; usiner et pi&#232;ce usin&#233;e). Comme ce collocatif est la base du deuxi&#232;me niveau d&#8217;analyse, la 
forme fl&#233;chie s&#8217;impose &#224; ce deuxi&#232;me niveau tant pour la base que pour le collocatif. 
</p>
<p>Ces deux bases de donn&#233;es sont fusionn&#233;es en une grande base de donn&#233;es, interrog&#233;e pour 
l&#8217;analyse du recouvrement des cooccurrents de deuxi&#232;me ordre. A cet effet, la fonction 
Python de l&#8217;algorithme pr&#233;voit les param&#232;tres suivants : la base (sp&#233;cificit&#233; &#224; analyser), le 
</p>
<p>                                                 
5  http://www.python.org/ 
</p>
<p>6  la base (anglais : node) &#233;tant le mot &#233;tudi&#233; et le collocatif (anglais : collocate) &#233;tant un de ses cooccurrents </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ann Bertels 
</p>
<p>seuil de signification pour les cooccurrents de premier niveau (p.ex. 0.95 pour p&#8804;0.05), le 
seuil pour les cooccurrents de deuxi&#232;me niveau et la base de donn&#233;es. Il y a plus de 
recouvrement, si plus de cooccurrents (c) partagent le m&#234;me cc, ce qui signifie un poids plus 
lourd pour ce cc (score pr&#232;s de 1). Un cc moins/pas partag&#233; indique donc peu/pas de 
recouvrement (score pr&#232;s de 0).  
</p>
<p>La figure 3 ci-dessous montre les premiers r&#233;sultats pour le corpus technique (1.7 million) et 
pour un seuil de signification des c et cc de p&#8804;0.0001. Parmi les 25 mots les plus sp&#233;cifiques 
du corpus technique entier, les 2 mots les plus sp&#233;cifiques se caract&#233;risent par le degr&#233; de 
monos&#233;mie le moins &#233;lev&#233; (rangs 25 et 24), indiquant peu de recouvrement des cooccurrents 
d&#8217;ordre 2. Les mots en gras sont les moins monos&#233;miques de cet &#233;chantillon, ce qui semble 
contredire la th&#232;se de la corr&#233;lation7 entre le degr&#233; de sp&#233;cificit&#233; et le degr&#233; de monos&#233;mie.  
</p>
<p>LEMME FREQ_ABS1 FREQ_ABS2 LLR DEGRE DE 
MONOSEMIE 
</p>
<p>RANG DE 
MONOSEMIE 
</p>
<p>machine 12671 1052 50521,91 0,0231 25 
outil 8306 918 32037,72 0,0240 24 
usinage 6720 8 30468,41 0,0349 12 
pi&#232;ce 7556 2219 24407,46 0,0310 18 
mm 5490 191 23357,57 0,0534 1 
vitesse 5283 900 19108,78 0,0402 6 
coupe 6730 4153 17063,37 0,0370 10 
broche 2893 12 13010,42 0,0394 7 
Fig 2680 0 12194,00 0,0483 3 
axe 3206 420 12079,16 0,0340 13 
copeau 2557 0 11634,18 0,0299 20 
plaquette 2407 35 10592,46 0,0282 22 
diam&#232;tre 2415 95 10200,09 0,0444 4 
commande 2751 850 8765,71 0,0317 17 
acier 2252 277 8558,49 0,0282 21 
fraisage 1873 0 8521,34 0,0350 11 
ar&#234;te 1870 29 8213,91 0,0386 8 
pr&#233;cision 2263 541 7663,01 0,0491 2 
usiner 1577 11 7045,52 0,0406 5 
surface 2258 758 7037,02 0,0321 15 
type 2820 1830 6994,07 0,0372 9 
syst&#232;me 4052 5165 6915,85 0,0280 23 
fraise 1571 45 6745,88 0,0319 16 
gamme 1860 545 6006,35 0,0324 14 
permettre 4883 9504 5848,03 0,0303 19 
</p>
<p>Figure 3 : Degr&#233; et rang de monos&#233;mie des 25 mots les plus sp&#233;cifiques (p &#8804; 0.0001) 
</p>
<p>Pour les 100 mots les plus sp&#233;cifiques, une premi&#232;re analyse de r&#233;gression simple fait 
intervenir le degr&#233; de monos&#233;mie comme variable d&#233;pendante et le degr&#233; de sp&#233;cificit&#233; 
comme variable ind&#233;pendante ou pr&#233;dictive. Elle montre qu&#8217;il y a une tr&#232;s faible corr&#233;lation 
n&#233;gative (p=0.03) et que le degr&#233; de sp&#233;cificit&#233; n&#8217;explique que 3.5% de la variation du degr&#233; 
</p>
<p>                                                 
7  Nous ne recourons pas &#224; une simple mesure de corr&#233;lation, en raison de l&#8217;effet d&#8217;interf&#233;rence attendu des 
</p>
<p>autres facteurs (fr&#233;quence, classe lexicale, etc.). </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>A la d&#233;couverte de la polys&#233;mie des sp&#233;cificit&#233;s du fran&#231;ais technique 
</p>
<p>de monos&#233;mie. Une analyse de r&#233;gression multiple, mesurant l&#8217;impact de plusieurs variables 
ind&#233;pendantes (sp&#233;cificit&#233;, fr&#233;quence, classe lexicale, nombre de classes lexicales et 
longueur), indique comme facteurs significatifs le nombre de classes lexicales (p=0.008), la 
classe lexicale (p=0.03) et la fr&#233;quence (p=0.03) pour une variation totale expliqu&#233;e de 12% 
(p=0.004). Parmi les 100 mots les plus sp&#233;cifiques du corpus technique, les mots les plus 
polys&#233;miques, affichant le degr&#233; de monos&#233;mie le plus bas, se caract&#233;risent par une fr&#233;quence 
absolue &#233;lev&#233;e et par leur appartenance &#224; deux ou plusieurs classes lexicales, principalement 
les classes &#8216;nom&#8217; et &#8216;adjectif&#8217;.  
</p>
<p>5 Conclusion et perspectives 
</p>
<p>Pour &#233;tudier la s&#233;mantique des sp&#233;cificit&#233;s dans le domaine technique des machines-outils 
pour l&#8217;usinage des m&#233;taux, nous avons eu recours &#224; une double analyse. D&#8217;une part, la 
KeyWords Method a permis de dresser la liste des sp&#233;cificit&#233;s du corpus d&#8217;analyse, ordonn&#233;es 
par ordre de sp&#233;cificit&#233; d&#233;croissante. D&#8217;autre part, la formule pour le recouvrement des 
cooccurrences des cooccurrences a permis d&#8217;acc&#233;der &#224; la s&#233;mantique des sp&#233;cificit&#233;s, en 
&#233;valuant le degr&#233; de monos&#233;mie. L&#8217;analyse d&#233;taill&#233;e des r&#233;sultats de recherche nous 
apprendra pour un nombre important de mots techniques, s&#8217;il y a une corr&#233;lation entre leur 
degr&#233; de sp&#233;cificit&#233; et leur degr&#233; de monos&#233;mie, en fonction d&#8217;une s&#233;rie de facteurs, 
notamment la classe lexicale et la fr&#233;quence. 
</p>
<p>La formule pour le recouvrement des cooccurrents de deuxi&#232;me ordre et pour le degr&#233; de 
monos&#233;mie sera soumise &#224; plusieurs exp&#233;rimentations en fonction de plusieurs param&#232;tres, 
afin de mettre au point le calcul du degr&#233; de monos&#233;mie. Une fois recueillies pour le corpus 
technique entier, les donn&#233;es sur le degr&#233; de monos&#233;mie permettront de situer les sp&#233;cificit&#233;s 
dans un continuum de monos&#233;mie (continuum de sens). Des analyses statistiques dans R8 
permettront ensuite de v&#233;rifier la corr&#233;lation entre le continuum de sp&#233;cificit&#233; et le continuum 
de monos&#233;mie et de proc&#233;der &#224; une analyse linguistique d&#233;taill&#233;e en fonction des variables 
(linguistiques) ind&#233;pendantes.  
</p>
<p>Nous envisageons cette double analyse du degr&#233; de sp&#233;cificit&#233; et du degr&#233; de monos&#233;mie pour 
les collocations sp&#233;cifiques &#233;galement, &#233;tant donn&#233; que les termes se situent souvent au 
niveau des unit&#233;s polylexicales. Nous nous proposons aussi de proc&#233;der &#224; une validation 
manuelle de la formule d&#233;terminant le degr&#233; de monos&#233;mie &#224; l&#8217;aide de l&#8217;analyse des 
collocations et cooccurrences relev&#233;es. 
</p>
<p>R&#233;f&#233;rences 
</p>
<p>Audibert L. (2003), Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique : r&#233;sultats 
sur les cooccurrences, Actes de TALN 2003, 35-44. 
</p>
<p>Berber Sardinha A. (1999), Word sets, keywords and text contents : An investigation of text 
topic on the computer, DELTA, 15-1, 141-149. 
</p>
<p>                                                 
8  http://www.r-project.org/ </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ann Bertels 
</p>
<p>Cabr&#233; M.T. (1998), La terminologie. Th&#233;orie, m&#233;thode et applications, Ottawa, Les Presses 
de l&#8217;Universit&#233;. 
</p>
<p>Cabr&#233; M.T. (2000), Terminologie et linguistique : la th&#233;orie des portes, Terminologies 
nouvelles, 21, 10-15. 
</p>
<p>Condamines A., Rebeyrolle J. (1997), Point de vue en langue sp&#233;cialis&#233;e, Meta, XLII-1, 174-
184. 
</p>
<p>Drouin P. (2004), Sp&#233;cificit&#233;s lexicales et acquisition de la terminologie, Actes de JADT 
2004, 345-352. 
</p>
<p>Denhi&#232;re G., Lemaire B. (2003), Mod&#233;lisation des effets contextuels par l'analyse de la 
s&#233;mantique latente. Actes de EPIQUE 2003, http://www.upmf-grenoble.fr/sciedu/blemaire/ 
epique03.pdf 
</p>
<p>Dunning T. (1993), Accurate methods for the statistics of surprise and coincidence, 
Computational Linguistics, 19-1, 61-74.  
</p>
<p>Ferret O. (2004), D&#233;couvrir des sens de mots &#224; partir d&#8217;un r&#233;seau de cooccurrences lexicales, 
Actes de TALN 2004, http://www.lpl.univ-aix.fr/jep-taln04/proceed/actes/taln2004-
Fez/Ferret.pdf 
</p>
<p>Gaudin F. (1993), Pour une socioterminologie. Des probl&#232;mes s&#233;mantiques aux pratiques 
institutionnelles, Rouen, Publications de l&#8217;Universit&#233; de Rouen. 
</p>
<p>Labb&#233; C., Labb&#233; D. (2001), Que mesure la sp&#233;cificit&#233; du vocabulaire?, Lexicometrica, 3, 
http://www.cavi.univ-paris3.fr/lexicometrica/article/numero3/specificite2001.PDF 
</p>
<p>Lafon P. (1984), D&#233;pouillements et statistiques en lexicom&#233;trie, Gen&#232;ve-Paris, Slatkine-
Champion. 
</p>
<p>Lerat P. (1995), Les langues sp&#233;cialis&#233;es, Paris, PUF. 
</p>
<p>Martinez W. (2000), Mise en &#233;vidence de rapports synonymiques par la m&#233;thode des 
cooccurrences, Actes de JADT 2000, 78-84.  
</p>
<p>Sch&#252;tze H. (1998), Automatic Word Sense Discrimination, Computational Linguistics, 24-1, 
97-123. 
</p>
<p>Speelman D. (1997), Abundantia verborum : a computer tool for carrying out corpus-based 
linguistic case studies, PhD Thesis, K.U.Leuven. 
</p>
<p>Temmerman R. (1997), Questioning the univocity ideal. The difference between socio-
cognitive Terminology and traditional Terminology, Hermes, 18, 51-90. 
</p>
<p>V&#233;ronis J. (2003), Cartographie lexicale pour la recherche d&#8217;informations, Actes de TALN 
2003, 265-274. </p>

</div></div>
</body></html>