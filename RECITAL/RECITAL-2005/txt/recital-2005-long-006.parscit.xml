<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Audibert</author>
</authors>
<title>Etude des critères de désambiguïsation sémantique automatique : résultats sur les cooccurrences, Actes de TALN</title>
<date>2003</date>
<pages>35--44</pages>
<contexts>
<context position="12625" citStr="Audibert (2003)" startWordPosition="1837" endWordPosition="1838">cificité. 3.2 Polysémie Les spécificités relevées dans le corpus technique d’analyse, font ensuite l’objet d’une analyse sémantique. Pour chaque spécificité, on déterminera le degré de monosémie, dans le but de vérifier si les mots les plus spécifiques sont en effet (les plus) monosémiques et si les mots moins spécifiques ont plus tendance à être polysémiques. Il s’agira donc d’objectiver et de quantifier l’analyse sémantique, en ayant recours aux cooccurrences. Selon Schütze (1998), Véronis (2003) et d’autres, les cooccurrences permettent de distinguer les différents usages et sens des mots. Audibert (2003) recourt même aux cooccurrences comme critères de désambiguïsation sémantique automatique. Dans Véronis (2003), les cooccurrences d’un mot, à partir d’un grand corpus, sont regroupées suivant leur similarité ou dissimilarité (en fonction de leur co-fréquence) pour identifier les différents sens du mot. A la découverte de la polysémie des spécificités du français technique Afin de déterminer le degré de monosémie des spécificités, nous proposons d’aller plus loin et d’étudier les cooccurrences de deuxième ordre. Les cooccurrences des cooccurrences permettent de trouver des synonymes d’un mot, s</context>
</contexts>
<marker>Audibert, 2003</marker>
<rawString>Audibert L. (2003), Etude des critères de désambiguïsation sémantique automatique : résultats sur les cooccurrences, Actes de TALN 2003, 35-44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Berber Sardinha A</author>
</authors>
<title>Word sets, keywords and text contents : An investigation of text topic on the computer,</title>
<date>1999</date>
<booktitle>8 http://www.r-project.org/ Ann Bertels Cabré M.T.</booktitle>
<pages>15--1</pages>
<location>DELTA,</location>
<marker>A, 1999</marker>
<rawString>Berber Sardinha A. (1999), Word sets, keywords and text contents : An investigation of text topic on the computer, DELTA, 15-1, 141-149. 8 http://www.r-project.org/ Ann Bertels Cabré M.T. (1998), La terminologie. Théorie, méthode et applications, Ottawa, Les Presses de l’Université.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M T Cabré</author>
</authors>
<date>2000</date>
<booktitle>Terminologie et linguistique : la théorie des portes, Terminologies nouvelles,</booktitle>
<volume>21</volume>
<pages>10--15</pages>
<marker>Cabré, 2000</marker>
<rawString>Cabré M.T. (2000), Terminologie et linguistique : la théorie des portes, Terminologies nouvelles, 21, 10-15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Condamines</author>
<author>J Rebeyrolle</author>
</authors>
<title>Point de vue en langue spécialisée,</title>
<date>1997</date>
<pages>174--184</pages>
<location>Meta, XLII-1,</location>
<marker>Condamines, Rebeyrolle, 1997</marker>
<rawString>Condamines A., Rebeyrolle J. (1997), Point de vue en langue spécialisée, Meta, XLII-1, 174-184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Drouin</author>
</authors>
<title>Spécificités lexicales et acquisition de la terminologie, Actes de JADT</title>
<date>2004</date>
<pages>345--352</pages>
<contexts>
<context position="10541" citStr="Drouin, 2004" startWordPosition="1530" endWordPosition="1531">re des millions de mots. Pour remédier à ce problème, Lafon propose d’utiliser des logarithmes. Dès lors, le résultat du calcul x est à interpréter comme l’exposant de la base 10, d’où résulte la probabilité 10x. Dans Lexico3, ce sont les exposants (résultats de la formule du calcul hypergéométrique) qui figurent dans la colonne du coefficient de spécificité. Les spécificités positives indiquent un suremploi dans la section analysée, tandis que les spécificités négatives signalent un sous-emploi. Le calcul des spécificités est surtout utilisé par la communauté francophone (Cf. Zimina, 2004 et Drouin, 2004). La deuxième méthodologie permettant d’identifier les mots les plus spécifiques est surtout utilisée par des utilisateurs du logiciel WordSmith–KeyWords (Berber-Sardinha, 1999). Elle est couramment appelée KeyWords Method ou méthode des mots-clefs. Les fréquences dans le corpus spécialisé sont comparées aux fréquences dans un corpus de référence de langue générale, compte tenu de la taille des deux corpus, ce qui permet d’identifier les mots significativement plus fréquents dans le corpus spécialisé. Il s’agit donc de la comparaison de deux corpus différents, et non d’une comparaison partie-t</context>
</contexts>
<marker>Drouin, 2004</marker>
<rawString>Drouin P. (2004), Spécificités lexicales et acquisition de la terminologie, Actes de JADT 2004, 345-352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Denhière</author>
<author>B Lemaire</author>
</authors>
<title>Modélisation des effets contextuels par l&apos;analyse de la sémantique latente.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<booktitle>Actes de EPIQUE 2003, http://www.upmf-grenoble.fr/sciedu/blemaire/ epique03.pdf Dunning T.</booktitle>
<volume>19</volume>
<pages>61--74</pages>
<contexts>
<context position="13396" citStr="Denhière &amp; Lemaire (2003)" startWordPosition="1945" endWordPosition="1948">ir d’un grand corpus, sont regroupées suivant leur similarité ou dissimilarité (en fonction de leur co-fréquence) pour identifier les différents sens du mot. A la découverte de la polysémie des spécificités du français technique Afin de déterminer le degré de monosémie des spécificités, nous proposons d’aller plus loin et d’étudier les cooccurrences de deuxième ordre. Les cooccurrences des cooccurrences permettent de trouver des synonymes d’un mot, selon Martinez (2000). Pour le mot mesures, il trouve les cooccurrents nouvelles, prises, etc. qui cooccurrent à leur tour avec décisions. D’après Denhière &amp; Lemaire (2003), les cooccurrences de deuxième ordre et même d’ordre supérieur déterminent le degré d’association de deux mots M1 et M2, même si ces deux mots ne figurent jamais ensemble. Si les cooccurrences M1-M3 et M2-M3 sont suffisamment fortes, on considère que M1 et M2 sont associés et des cooccurrents d’ordre 2. Il est également possible d’extraire automatiquement les sens des mots à partir d’un réseau de cooccurrences lexicales de deuxième ordre, comme l’explique Ferret (2004). La connectivité des cooccurrents formant un sens est plus importante que leur connectivité avec les autres cooccurrents défi</context>
</contexts>
<marker>Denhière, Lemaire, 2003</marker>
<rawString>Denhière G., Lemaire B. (2003), Modélisation des effets contextuels par l&apos;analyse de la sémantique latente. Actes de EPIQUE 2003, http://www.upmf-grenoble.fr/sciedu/blemaire/ epique03.pdf Dunning T. (1993), Accurate methods for the statistics of surprise and coincidence, Computational Linguistics, 19-1, 61-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Ferret</author>
</authors>
<title>Découvrir des sens de mots à partir d’un réseau de cooccurrences lexicales, Actes de TALN 2004, http://www.lpl.univ-aix.fr/jep-taln04/proceed/actes/taln2004-Fez/Ferret.pdf Gaudin F.</title>
<date>2004</date>
<contexts>
<context position="13870" citStr="Ferret (2004)" startWordPosition="2021" endWordPosition="2022">t mesures, il trouve les cooccurrents nouvelles, prises, etc. qui cooccurrent à leur tour avec décisions. D’après Denhière &amp; Lemaire (2003), les cooccurrences de deuxième ordre et même d’ordre supérieur déterminent le degré d’association de deux mots M1 et M2, même si ces deux mots ne figurent jamais ensemble. Si les cooccurrences M1-M3 et M2-M3 sont suffisamment fortes, on considère que M1 et M2 sont associés et des cooccurrents d’ordre 2. Il est également possible d’extraire automatiquement les sens des mots à partir d’un réseau de cooccurrences lexicales de deuxième ordre, comme l’explique Ferret (2004). La connectivité des cooccurrents formant un sens est plus importante que leur connectivité avec les autres cooccurrents définissant les autres sens de ce mot, la mesure de cohésion étant l’information mutuelle normalisée (Ferret, 2004). Les cooccurrents de deuxième ordre étant des critères désambiguïsateurs puissants, ils seront très précieux lors de l’analyse sémantique des spécificités. En effet, le degré de recouvrement des cooccurrences de deuxième ordre sera un indice important du degré de monosémie du mot de base. Pour étudier le caractère monosémique ou polysémique d’une unité linguis</context>
</contexts>
<marker>Ferret, 2004</marker>
<rawString>Ferret O. (2004), Découvrir des sens de mots à partir d’un réseau de cooccurrences lexicales, Actes de TALN 2004, http://www.lpl.univ-aix.fr/jep-taln04/proceed/actes/taln2004-Fez/Ferret.pdf Gaudin F. (1993), Pour une socioterminologie. Des problèmes sémantiques aux pratiques institutionnelles, Rouen, Publications de l’Université de Rouen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Labbé</author>
<author>D Labbé</author>
</authors>
<title>Que mesure la spécificité du vocabulaire?,</title>
<date>2001</date>
<journal>Lexicometrica,</journal>
<volume>3</volume>
<location>Genève-Paris, SlatkineChampion.</location>
<marker>Labbé, Labbé, 2001</marker>
<rawString>Labbé C., Labbé D. (2001), Que mesure la spécificité du vocabulaire?, Lexicometrica, 3, http://www.cavi.univ-paris3.fr/lexicometrica/article/numero3/specificite2001.PDF Lafon P. (1984), Dépouillements et statistiques en lexicométrie, Genève-Paris, SlatkineChampion.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Lerat</author>
</authors>
<title>Les langues spécialisées,</title>
<date>1995</date>
<location>Paris, PUF.</location>
<contexts>
<context position="2817" citStr="Lerat, 1995" startWordPosition="392" endWordPosition="393">itionnelle définit comme l’univocité, la monoréférentialité et la monosémie des unités terminologiques de la langue spécialisée. La terminologie traditionnelle prescriptive et normative adopte une approche onomasiologique par domaine. Récemment, la monosémie et l’univocité de la langue spécialisée ont été remises en question par la Théorie Communicative de la Terminologie (Cabré, 1998, 2000), par la socioterminologie (Gaudin, 1993) et par la terminologie socio-cognitive (Temmerman, 1997). Les termes font partie intégrante de la langue naturelle, mais véhiculent des connaissances spécialisées (Lerat, 1995). Les partisans de la terminologie descriptive rejettent la dichotomie entre la langue générale et la langue spécialisée et adoptent une approche sémasiologique et linguistique, basée sur l’étude de corpus de textes spécialisés (Condamines &amp; Rebeyrolles, 1997). Pour quantifier la thèse monosémiste de la terminologie traditionnelle, nous nous proposons de la reformuler en une question de recherche opérationnelle et mesurable : « Y a-t-il une corrélation entre, d’une part, le continuum de spécificité et, d’autre part, le continuum de monosémie (continuum de sens) ? » L’hypothèse de recherche ava</context>
</contexts>
<marker>Lerat, 1995</marker>
<rawString>Lerat P. (1995), Les langues spécialisées, Paris, PUF.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Martinez</author>
</authors>
<title>Mise en évidence de rapports synonymiques par la méthode des cooccurrences, Actes de JADT</title>
<date>2000</date>
<pages>78--84</pages>
<contexts>
<context position="13245" citStr="Martinez (2000)" startWordPosition="1924" endWordPosition="1925">urt même aux cooccurrences comme critères de désambiguïsation sémantique automatique. Dans Véronis (2003), les cooccurrences d’un mot, à partir d’un grand corpus, sont regroupées suivant leur similarité ou dissimilarité (en fonction de leur co-fréquence) pour identifier les différents sens du mot. A la découverte de la polysémie des spécificités du français technique Afin de déterminer le degré de monosémie des spécificités, nous proposons d’aller plus loin et d’étudier les cooccurrences de deuxième ordre. Les cooccurrences des cooccurrences permettent de trouver des synonymes d’un mot, selon Martinez (2000). Pour le mot mesures, il trouve les cooccurrents nouvelles, prises, etc. qui cooccurrent à leur tour avec décisions. D’après Denhière &amp; Lemaire (2003), les cooccurrences de deuxième ordre et même d’ordre supérieur déterminent le degré d’association de deux mots M1 et M2, même si ces deux mots ne figurent jamais ensemble. Si les cooccurrences M1-M3 et M2-M3 sont suffisamment fortes, on considère que M1 et M2 sont associés et des cooccurrents d’ordre 2. Il est également possible d’extraire automatiquement les sens des mots à partir d’un réseau de cooccurrences lexicales de deuxième ordre, comme</context>
</contexts>
<marker>Martinez, 2000</marker>
<rawString>Martinez W. (2000), Mise en évidence de rapports synonymiques par la méthode des cooccurrences, Actes de JADT 2000, 78-84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schütze</author>
</authors>
<title>Automatic Word Sense Discrimination,</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--1</pages>
<contexts>
<context position="12497" citStr="Schütze (1998)" startWordPosition="1819" endWordPosition="1820">emblance) permet de les classer par ordre de spécificité décroissante et par conséquent, de les situer dans un continuum de spécificité. 3.2 Polysémie Les spécificités relevées dans le corpus technique d’analyse, font ensuite l’objet d’une analyse sémantique. Pour chaque spécificité, on déterminera le degré de monosémie, dans le but de vérifier si les mots les plus spécifiques sont en effet (les plus) monosémiques et si les mots moins spécifiques ont plus tendance à être polysémiques. Il s’agira donc d’objectiver et de quantifier l’analyse sémantique, en ayant recours aux cooccurrences. Selon Schütze (1998), Véronis (2003) et d’autres, les cooccurrences permettent de distinguer les différents usages et sens des mots. Audibert (2003) recourt même aux cooccurrences comme critères de désambiguïsation sémantique automatique. Dans Véronis (2003), les cooccurrences d’un mot, à partir d’un grand corpus, sont regroupées suivant leur similarité ou dissimilarité (en fonction de leur co-fréquence) pour identifier les différents sens du mot. A la découverte de la polysémie des spécificités du français technique Afin de déterminer le degré de monosémie des spécificités, nous proposons d’aller plus loin et d’</context>
</contexts>
<marker>Schütze, 1998</marker>
<rawString>Schütze H. (1998), Automatic Word Sense Discrimination, Computational Linguistics, 24-1, 97-123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Speelman</author>
</authors>
<title>Abundantia verborum : a computer tool for carrying out corpus-based linguistic case studies,</title>
<date>1997</date>
<tech>PhD Thesis, K.U.Leuven.</tech>
<contexts>
<context position="8502" citStr="Speelman, 1997" startWordPosition="1240" endWordPosition="1241"> comparées aux fréquences dans un corpus de référence, compte tenu de la taille des deux corpus, ce qui revient à comparer la fréquence observée (corpus d’analyse) à la fréquence attendue (corpus de référence). S’il y a une différence entre la fréquence observée et la fréquence attendue, il faut vérifier si elle est statistiquement significative. A cet effet, deux méthodologies sont désormais disponibles : le calcul des spécificités (Lafon, 1984) implémenté dans le logiciel Lexico32, outils de statistique textuelle, et la KeyWords Method des logiciels WordSmith Tools3 et Abundantia Verborum4 (Speelman, 1997). Les deux méthodologies aboutissent grosso modo à des résultats similaires, à savoir une liste de mots spécifiques pourvus d’une mesure statistique indiquant le degré de spécificité. Les différences les plus importantes résident dans la méthodologie et la statistique sous-jacentes. 2 Lexico3 : SYLED – CLA2T, Paris3 : http://www.cavi.univ-paris3.fr/ilpga/ilpga/tal/lexicoWWW/ 3 WordSmith Tools version 3 : http://www.lexically.net/wordsmith/ et http://www.oup.com 4 Abundantia Verborum : http://wwwling.arts.kuleuven.ac.be/genling/abundant/obtain/ Ann Bertels Premièrement, le calcul des spécificit</context>
</contexts>
<marker>Speelman, 1997</marker>
<rawString>Speelman D. (1997), Abundantia verborum : a computer tool for carrying out corpus-based linguistic case studies, PhD Thesis, K.U.Leuven.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Temmerman</author>
</authors>
<title>Questioning the univocity ideal. The difference between sociocognitive Terminology and traditional</title>
<date>1997</date>
<journal>Terminology, Hermes,</journal>
<volume>18</volume>
<pages>51--90</pages>
<contexts>
<context position="2697" citStr="Temmerman, 1997" startWordPosition="376" endWordPosition="377">spécialisée. Dans la langue spécialisée, les besoins communicatifs requièrent plus de précision, ce que la terminologie traditionnelle définit comme l’univocité, la monoréférentialité et la monosémie des unités terminologiques de la langue spécialisée. La terminologie traditionnelle prescriptive et normative adopte une approche onomasiologique par domaine. Récemment, la monosémie et l’univocité de la langue spécialisée ont été remises en question par la Théorie Communicative de la Terminologie (Cabré, 1998, 2000), par la socioterminologie (Gaudin, 1993) et par la terminologie socio-cognitive (Temmerman, 1997). Les termes font partie intégrante de la langue naturelle, mais véhiculent des connaissances spécialisées (Lerat, 1995). Les partisans de la terminologie descriptive rejettent la dichotomie entre la langue générale et la langue spécialisée et adoptent une approche sémasiologique et linguistique, basée sur l’étude de corpus de textes spécialisés (Condamines &amp; Rebeyrolles, 1997). Pour quantifier la thèse monosémiste de la terminologie traditionnelle, nous nous proposons de la reformuler en une question de recherche opérationnelle et mesurable : « Y a-t-il une corrélation entre, d’une part, le c</context>
</contexts>
<marker>Temmerman, 1997</marker>
<rawString>Temmerman R. (1997), Questioning the univocity ideal. The difference between sociocognitive Terminology and traditional Terminology, Hermes, 18, 51-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Véronis</author>
</authors>
<title>Cartographie lexicale pour la recherche d’informations, Actes de TALN</title>
<date>2003</date>
<pages>265--274</pages>
<contexts>
<context position="12513" citStr="Véronis (2003)" startWordPosition="1821" endWordPosition="1822"> de les classer par ordre de spécificité décroissante et par conséquent, de les situer dans un continuum de spécificité. 3.2 Polysémie Les spécificités relevées dans le corpus technique d’analyse, font ensuite l’objet d’une analyse sémantique. Pour chaque spécificité, on déterminera le degré de monosémie, dans le but de vérifier si les mots les plus spécifiques sont en effet (les plus) monosémiques et si les mots moins spécifiques ont plus tendance à être polysémiques. Il s’agira donc d’objectiver et de quantifier l’analyse sémantique, en ayant recours aux cooccurrences. Selon Schütze (1998), Véronis (2003) et d’autres, les cooccurrences permettent de distinguer les différents usages et sens des mots. Audibert (2003) recourt même aux cooccurrences comme critères de désambiguïsation sémantique automatique. Dans Véronis (2003), les cooccurrences d’un mot, à partir d’un grand corpus, sont regroupées suivant leur similarité ou dissimilarité (en fonction de leur co-fréquence) pour identifier les différents sens du mot. A la découverte de la polysémie des spécificités du français technique Afin de déterminer le degré de monosémie des spécificités, nous proposons d’aller plus loin et d’étudier les cooc</context>
</contexts>
<marker>Véronis, 2003</marker>
<rawString>Véronis J. (2003), Cartographie lexicale pour la recherche d’informations, Actes de TALN 2003, 265-274.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>