<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Benson</author>
</authors>
<title>Collocations and general-purpose dictionaries,</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>1</issue>
<pages>23--35</pages>
<contexts>
<context position="5742" citStr="Benson, 1990" startWordPosition="833" endWordPosition="834"> de données linguistique. (Cao &amp; Li, 2002) proposent une méthode automatique de génération et de sélection de traductions pour les syntagmes nominaux de l’anglais vers le chinois à partir du Web. Les résultats montrent que le Web peut être utile tant pour l’acquisition de données que pour une aide à la validation. 1 http://www.systransoft.com/ 2 Concernant la combinatoire lexicale, la littérature présente une terminologie disparate et souvent floue. Certains parlent de « préférences lexicales » (Wilks, 1975), de « restrictions de sélection » (Katz &amp; Fodor, 1964) ou encore de « collocations » (Benson, 1990 ; Smadja, 1993 ; Cruse, 1986). Afin de désigner ce phénomène, nous employons ici le terme « relation lexicale », plus neutre, défini comme une cooccurrence lexicale entre deux lexèmes liés syntaxiquement. 3 Ensemble de textes alignés avec leur traduction au niveau du paragraphe, de la phrase, des expressions ou des mots. 4 Corpus de langues différentes traitant du même domaine mais non parallèles. Acquisition semi-automatique de relations lexicales bilingues à partir du Web L’objectif de notre article est de proposer une méthodologie de validation semi-automatique de traductions anglaises via</context>
</contexts>
<marker>Benson, 1990</marker>
<rawString>Benson M. (1990), Collocations and general-purpose dictionaries, International Journal of Lexicography, vol. 3(1), pp. 23-35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Cao</author>
<author>H Li</author>
</authors>
<title>Base noun phrase translation using web data and the EM algorithm.</title>
<date>2002</date>
<booktitle>In Proceedings of CoLing.</booktitle>
<contexts>
<context position="5172" citStr="Cao &amp; Li, 2002" startWordPosition="743" endWordPosition="746">er grâce à des moteurs de recherche tels que Google ou Altavista. En se basant sur les travaux de (Kilgarriff &amp; Grefenstette, 2003), on peut estimer à environ 100 milliards le nombre de mots indexés par Google pour la seule langue anglaise. Même si les données du Web sont moins contrôlées, et donc plus « bruitées », elles permettent d’envisager un changement radical d’échelle pour les méthodes basées sur les données, à condition de développer des méthodes et des techniques adaptées. Depuis quelques années, divers domaines du TAL utilisent le Web en tant que ressource de données linguistique. (Cao &amp; Li, 2002) proposent une méthode automatique de génération et de sélection de traductions pour les syntagmes nominaux de l’anglais vers le chinois à partir du Web. Les résultats montrent que le Web peut être utile tant pour l’acquisition de données que pour une aide à la validation. 1 http://www.systransoft.com/ 2 Concernant la combinatoire lexicale, la littérature présente une terminologie disparate et souvent floue. Certains parlent de « préférences lexicales » (Wilks, 1975), de « restrictions de sélection » (Katz &amp; Fodor, 1964) ou encore de « collocations » (Benson, 1990 ; Smadja, 1993 ; Cruse, 1986)</context>
</contexts>
<marker>Cao, Li, 2002</marker>
<rawString>Cao Y., Li H. (2002), Base noun phrase translation using web data and the EM algorithm. In Proceedings of CoLing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Chuquet</author>
<author>M Paillard</author>
</authors>
<title>Approche linguistique des problèmes de traduction: anglaisfrançais,</title>
<date>1987</date>
<location>Gap, Ophrys.</location>
<contexts>
<context position="14099" citStr="Chuquet &amp; Paillard, 1987" startWordPosition="2076" endWordPosition="2079"> d’articles dans les requêtes du patron syntaxique NOM ADJECTIF permet également de réduire le problème de l’ambiguïté catégorielle. Par exemple, complete peut être un adjectif (entier, complet, intégral, total) ou un verbe (parfaire, compléter). La relation lexicale complete restoration est ambiguë. L’ajout de l’article permet d’éliminer les cas où complete est un verbe. Le patron syntaxique NOM1 DE NOM2 pouvant être traduit par différentes structures en anglais selon la relation sémantique considérée entre les deux objets, nous traitons séparément deux types de structures dans les requêtes (Chuquet &amp; Paillard, 1987) : d’une part, le patron N2 N1 marque une relation étroite entre les deux noms et d’autre part, la structure N1 of N2 accorde la priorité à l’élément repéré (N2)4. 1 http://www.google.com/apis/ 2 Des différences ont été remarquées entre le nombre de résultats renvoyés par l’API et par l’interface web. Ce problème a été mentionné dans divers forums, mais aucune explication n’a pu être fournie. 3 Précisons que si les fréquences de Google sont peu fiables dans le cadre de certaines configurations de requêtes dans « tout le Web » (http://aixtal.blogspot.com/2005/02/web-le-mystre-des-pages-manquant</context>
</contexts>
<marker>Chuquet, Paillard, 1987</marker>
<rawString>Chuquet H., Paillard M. (1987), Approche linguistique des problèmes de traduction: anglaisfrançais, Gap, Ophrys.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Cruse</author>
</authors>
<title>Lexical Semantics, Cambridge,</title>
<date>1986</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="5772" citStr="Cruse, 1986" startWordPosition="839" endWordPosition="840"> &amp; Li, 2002) proposent une méthode automatique de génération et de sélection de traductions pour les syntagmes nominaux de l’anglais vers le chinois à partir du Web. Les résultats montrent que le Web peut être utile tant pour l’acquisition de données que pour une aide à la validation. 1 http://www.systransoft.com/ 2 Concernant la combinatoire lexicale, la littérature présente une terminologie disparate et souvent floue. Certains parlent de « préférences lexicales » (Wilks, 1975), de « restrictions de sélection » (Katz &amp; Fodor, 1964) ou encore de « collocations » (Benson, 1990 ; Smadja, 1993 ; Cruse, 1986). Afin de désigner ce phénomène, nous employons ici le terme « relation lexicale », plus neutre, défini comme une cooccurrence lexicale entre deux lexèmes liés syntaxiquement. 3 Ensemble de textes alignés avec leur traduction au niveau du paragraphe, de la phrase, des expressions ou des mots. 4 Corpus de langues différentes traitant du même domaine mais non parallèles. Acquisition semi-automatique de relations lexicales bilingues à partir du Web L’objectif de notre article est de proposer une méthodologie de validation semi-automatique de traductions anglaises via le Web, à partir de relations</context>
</contexts>
<marker>Cruse, 1986</marker>
<rawString>Cruse D. A. (1986), Lexical Semantics, Cambridge, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Katz</author>
<author>J A Fodor</author>
</authors>
<title>The structure of a semantic theory, In</title>
<date>1964</date>
<booktitle>The Structure of Language, chapter 19,</booktitle>
<pages>479--518</pages>
<editor>J. A. Fodor and J. J. Katz, editors,</editor>
<contexts>
<context position="5698" citStr="Katz &amp; Fodor, 1964" startWordPosition="823" endWordPosition="826">aines du TAL utilisent le Web en tant que ressource de données linguistique. (Cao &amp; Li, 2002) proposent une méthode automatique de génération et de sélection de traductions pour les syntagmes nominaux de l’anglais vers le chinois à partir du Web. Les résultats montrent que le Web peut être utile tant pour l’acquisition de données que pour une aide à la validation. 1 http://www.systransoft.com/ 2 Concernant la combinatoire lexicale, la littérature présente une terminologie disparate et souvent floue. Certains parlent de « préférences lexicales » (Wilks, 1975), de « restrictions de sélection » (Katz &amp; Fodor, 1964) ou encore de « collocations » (Benson, 1990 ; Smadja, 1993 ; Cruse, 1986). Afin de désigner ce phénomène, nous employons ici le terme « relation lexicale », plus neutre, défini comme une cooccurrence lexicale entre deux lexèmes liés syntaxiquement. 3 Ensemble de textes alignés avec leur traduction au niveau du paragraphe, de la phrase, des expressions ou des mots. 4 Corpus de langues différentes traitant du même domaine mais non parallèles. Acquisition semi-automatique de relations lexicales bilingues à partir du Web L’objectif de notre article est de proposer une méthodologie de validation s</context>
</contexts>
<marker>Katz, Fodor, 1964</marker>
<rawString>Katz J. J, Fodor J. A. (1964), The structure of a semantic theory, In J. A. Fodor and J. J. Katz, editors, The Structure of Language, chapter 19, pp. 479-518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
<author>G Grefenstette</author>
</authors>
<title>Introduction to the Special Issue on the Web as Corpus.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>3</issue>
<pages>333--348</pages>
<contexts>
<context position="4688" citStr="Kilgarriff &amp; Grefenstette, 2003" startWordPosition="664" endWordPosition="667">arallèles ou alignés3 (Véronis, 2000). Toutefois, ces méthodes présentent diverses limites : de telles ressources sont peu nombreuses et concernent des domaines restreints. Le paysage est un peu plus souriant avec des corpus comparables4 (Morin, DufourKowalski et Daille, 2004), mais les contraintes restent fortes. Le Web, qui génère des besoins considérables de traduction, offre en même temps un réservoir gigantesque de données qui peuvent être exploitées par des moyens automatiques, en particulier grâce à des moteurs de recherche tels que Google ou Altavista. En se basant sur les travaux de (Kilgarriff &amp; Grefenstette, 2003), on peut estimer à environ 100 milliards le nombre de mots indexés par Google pour la seule langue anglaise. Même si les données du Web sont moins contrôlées, et donc plus « bruitées », elles permettent d’envisager un changement radical d’échelle pour les méthodes basées sur les données, à condition de développer des méthodes et des techniques adaptées. Depuis quelques années, divers domaines du TAL utilisent le Web en tant que ressource de données linguistique. (Cao &amp; Li, 2002) proposent une méthode automatique de génération et de sélection de traductions pour les syntagmes nominaux de l’ang</context>
</contexts>
<marker>Kilgarriff, Grefenstette, 2003</marker>
<rawString>Kilgarriff A., Grefenstette G. (2003), Introduction to the Special Issue on the Web as Corpus. Computational Linguistics, 29(3): 333-348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I D Melamed</author>
</authors>
<title>Empirical methods for exploiting parallel texts,</title>
<date>2001</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="21504" citStr="Melamed, 2001" startWordPosition="3243" endWordPosition="3244"> formation des mots composés en anglais, avec ou sans espace ou tiret, est évidemment un cas extrêmement difficile, mais on peut envisager de générer des requêtes du type N-N ou NN (sans espace). 4.1.2 Erreurs sémantiques Un type d’erreurs d’ordre sémantique concerne l’acquisition de relations lexicales anglaises valides, mais non correspondantes à la relation lexicale source, comme dans l’exemple : cours de formation --&gt; group rate (59900 occurrences) Ici, group rate signifie tarif de groupe. De plus, la traduction d’une relation lexicale n’est pas toujours obtenue de façon compositionnelle (Melamed, 2001, cité par Morin et al., 2004). Par exemple, en anglais, il n’existe pas une traduction littérale de forcer un barrage : la traduction va dépendre du contexte situationnel (to drive through a roadblock, to run through a roadblock, etc.). Une autre limite est due à l’absence de certains usages dans le dictionnaire. C’est le cas par exemple de l’acception sportive du nom barrage (playoff). Ainsi, la relation lexicale match de barrage est traduite par weir game et barrage game au lieu de la traduction correcte playoff game. 4.1.3 Erreurs techniques Google ne prend pas en compte des phénomènes tel</context>
</contexts>
<marker>Melamed, 2001</marker>
<rawString>Melamed I. D. (2001), Empirical methods for exploiting parallel texts, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Millon</author>
</authors>
<title>Acquisition de relations lexicales désambiguïsées à partir du Web, Rencontre des Etudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (RECITAL</title>
<date>2004</date>
<location>Fès, (Maroc).</location>
<contexts>
<context position="8438" citStr="Millon, 2004" startWordPosition="1236" endWordPosition="1237">ion, station et vol). Ces mots ont été jugés comme les plus polysémiques parmi 200 noms de fréquence équivalente, lors du projet Senseval (Véronis, 1998) et constituent donc un banc de test difficile, qui a été utilisé par la suite dans divers travaux. Nous exploitons la version lemmatisée et étiquetée morpho-syntaxiquement du corpus de pages Web francophones élaboré par Jean Véronis (Véronis, 2003) autour de ces 10 noms. L’acquisition automatique des relations lexicales françaises de type NOM ADJECTIF, NOM1 DE NOM21 et VERBE NOM(objet) utilise une version améliorée du programme employé dans (Millon, 2004), dans lequel des filtres linguistiques d’extraction sont utilisés (représentation de patrons syntaxiques, filtres de candidats indésirables). Les relations lexicales sont ensuite soumises à un seuil limite de fréquence fixé à au moins 10 occurrences, afin d’obtenir des relations lexicales représentatives de besoins en lexicographie. En effet, un nombre important de relations moins fréquentes sont « accidentelles » (comme par exemple barrage violet), et non pertinentes pour notre étude. L’objectif est d’extraire une majorité de relations lexicales « propres » du côté français. A l’inverse, des</context>
</contexts>
<marker>Millon, 2004</marker>
<rawString>Millon C. (2004), Acquisition de relations lexicales désambiguïsées à partir du Web, Rencontre des Etudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (RECITAL 2004), Fès, (Maroc).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Morin</author>
<author>S Dufour-Kowalski</author>
<author>B Daille</author>
</authors>
<title>Extraction de terminologies bilingues à partir de corpus , Actes de TALN’2004, Fès (Maroc).</title>
<date>2004</date>
<contexts>
<context position="21534" citStr="Morin et al., 2004" startWordPosition="3247" endWordPosition="3250">osés en anglais, avec ou sans espace ou tiret, est évidemment un cas extrêmement difficile, mais on peut envisager de générer des requêtes du type N-N ou NN (sans espace). 4.1.2 Erreurs sémantiques Un type d’erreurs d’ordre sémantique concerne l’acquisition de relations lexicales anglaises valides, mais non correspondantes à la relation lexicale source, comme dans l’exemple : cours de formation --&gt; group rate (59900 occurrences) Ici, group rate signifie tarif de groupe. De plus, la traduction d’une relation lexicale n’est pas toujours obtenue de façon compositionnelle (Melamed, 2001, cité par Morin et al., 2004). Par exemple, en anglais, il n’existe pas une traduction littérale de forcer un barrage : la traduction va dépendre du contexte situationnel (to drive through a roadblock, to run through a roadblock, etc.). Une autre limite est due à l’absence de certains usages dans le dictionnaire. C’est le cas par exemple de l’acception sportive du nom barrage (playoff). Ainsi, la relation lexicale match de barrage est traduite par weir game et barrage game au lieu de la traduction correcte playoff game. 4.1.3 Erreurs techniques Google ne prend pas en compte des phénomènes tels que la ponctuation, les maju</context>
</contexts>
<marker>Morin, Dufour-Kowalski, Daille, 2004</marker>
<rawString>Morin E., Dufour-Kowalski S., Daille B. (2004), Extraction de terminologies bilingues à partir de corpus , Actes de TALN’2004, Fès (Maroc).</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Smadja</author>
</authors>
<title>Retrieving collocations from text :</title>
<date>1993</date>
<journal>Xtract, Computational Linguistics,</journal>
<volume>19</volume>
<pages>143--177</pages>
<contexts>
<context position="5757" citStr="Smadja, 1993" startWordPosition="836" endWordPosition="837">guistique. (Cao &amp; Li, 2002) proposent une méthode automatique de génération et de sélection de traductions pour les syntagmes nominaux de l’anglais vers le chinois à partir du Web. Les résultats montrent que le Web peut être utile tant pour l’acquisition de données que pour une aide à la validation. 1 http://www.systransoft.com/ 2 Concernant la combinatoire lexicale, la littérature présente une terminologie disparate et souvent floue. Certains parlent de « préférences lexicales » (Wilks, 1975), de « restrictions de sélection » (Katz &amp; Fodor, 1964) ou encore de « collocations » (Benson, 1990 ; Smadja, 1993 ; Cruse, 1986). Afin de désigner ce phénomène, nous employons ici le terme « relation lexicale », plus neutre, défini comme une cooccurrence lexicale entre deux lexèmes liés syntaxiquement. 3 Ensemble de textes alignés avec leur traduction au niveau du paragraphe, de la phrase, des expressions ou des mots. 4 Corpus de langues différentes traitant du même domaine mais non parallèles. Acquisition semi-automatique de relations lexicales bilingues à partir du Web L’objectif de notre article est de proposer une méthodologie de validation semi-automatique de traductions anglaises via le Web, à part</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Smadja F. (1993), Retrieving collocations from text : Xtract, Computational Linguistics, Vol. 19, pp. 143-177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Véronis</author>
</authors>
<title>A study of polysemy judgements and inter-annotator agreement,</title>
<date>1998</date>
<booktitle>Programme and advanced papers of the Senseval workshop,</booktitle>
<pages>2--4</pages>
<location>Herstmonceux Castle (England).</location>
<contexts>
<context position="7978" citStr="Véronis, 1998" startWordPosition="1167" endWordPosition="1168">Nous générons ensuite de façon automatique leurs traductions potentielles à partir d’un dictionnaire électronique. Nous interrogeons enfin le moteur de recherche Google afin de valider ces dernières de façon semi-automatique. 2.1 Extraction automatique des relations lexicales françaises Notre méthode a été testée sur la combinatoire lexicale de 10 noms français très polysémiques (barrage, détention, formation, lancement, organe, passage, restauration, solution, station et vol). Ces mots ont été jugés comme les plus polysémiques parmi 200 noms de fréquence équivalente, lors du projet Senseval (Véronis, 1998) et constituent donc un banc de test difficile, qui a été utilisé par la suite dans divers travaux. Nous exploitons la version lemmatisée et étiquetée morpho-syntaxiquement du corpus de pages Web francophones élaboré par Jean Véronis (Véronis, 2003) autour de ces 10 noms. L’acquisition automatique des relations lexicales françaises de type NOM ADJECTIF, NOM1 DE NOM21 et VERBE NOM(objet) utilise une version améliorée du programme employé dans (Millon, 2004), dans lequel des filtres linguistiques d’extraction sont utilisés (représentation de patrons syntaxiques, filtres de candidats indésirables</context>
</contexts>
<marker>Véronis, 1998</marker>
<rawString>Véronis J. (1998), A study of polysemy judgements and inter-annotator agreement, Programme and advanced papers of the Senseval workshop, pp. 2-4, Herstmonceux Castle (England).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Véronis</author>
</authors>
<title>Parallel Text Processing: Alignment and use of translation corpora,</title>
<date>2000</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="4093" citStr="Véronis, 2000" startWordPosition="576" endWordPosition="577">énérer des traductions correctes. La combinatoire est toutefois beaucoup plus ouverte qu’avec les expressions composées mentionnées plus haut et la constitution manuelle d’une base de données de combinaisons lexicales à grande échelle est une tâche à peu près impossible. Les dictionnaires bilingues se contentent d’ailleurs de rares indications ponctuelles, se fiant au jugement du lecteur et à sa connaissance du monde, que l’on ne peut guère espérer d’une machine. Afin de constituer de telles bases de données bilingues, de nombreux travaux se sont appuyés sur des corpus parallèles ou alignés3 (Véronis, 2000). Toutefois, ces méthodes présentent diverses limites : de telles ressources sont peu nombreuses et concernent des domaines restreints. Le paysage est un peu plus souriant avec des corpus comparables4 (Morin, DufourKowalski et Daille, 2004), mais les contraintes restent fortes. Le Web, qui génère des besoins considérables de traduction, offre en même temps un réservoir gigantesque de données qui peuvent être exploitées par des moyens automatiques, en particulier grâce à des moteurs de recherche tels que Google ou Altavista. En se basant sur les travaux de (Kilgarriff &amp; Grefenstette, 2003), on </context>
</contexts>
<marker>Véronis, 2000</marker>
<rawString>Véronis J. (Ed.) (2000). Parallel Text Processing: Alignment and use of translation corpora, Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Véronis</author>
</authors>
<title>Hyperlex : cartographie lexicale pour la recherche d’informations,</title>
<date>2003</date>
<booktitle>Actes de TALN’2003,</booktitle>
<pages>265--274</pages>
<location>Batz-sur-mer (France): ATALA.</location>
<contexts>
<context position="8227" citStr="Véronis, 2003" startWordPosition="1205" endWordPosition="1206">que des relations lexicales françaises Notre méthode a été testée sur la combinatoire lexicale de 10 noms français très polysémiques (barrage, détention, formation, lancement, organe, passage, restauration, solution, station et vol). Ces mots ont été jugés comme les plus polysémiques parmi 200 noms de fréquence équivalente, lors du projet Senseval (Véronis, 1998) et constituent donc un banc de test difficile, qui a été utilisé par la suite dans divers travaux. Nous exploitons la version lemmatisée et étiquetée morpho-syntaxiquement du corpus de pages Web francophones élaboré par Jean Véronis (Véronis, 2003) autour de ces 10 noms. L’acquisition automatique des relations lexicales françaises de type NOM ADJECTIF, NOM1 DE NOM21 et VERBE NOM(objet) utilise une version améliorée du programme employé dans (Millon, 2004), dans lequel des filtres linguistiques d’extraction sont utilisés (représentation de patrons syntaxiques, filtres de candidats indésirables). Les relations lexicales sont ensuite soumises à un seuil limite de fréquence fixé à au moins 10 occurrences, afin d’obtenir des relations lexicales représentatives de besoins en lexicographie. En effet, un nombre important de relations moins fréq</context>
<context position="23374" citStr="Véronis, 2003" startWordPosition="3530" endWordPosition="3531">nées. Néanmoins, ces problèmes concernent également des traductions correctes, et « bruitent » quelque peu les fréquences de l’API Google1. 4.2 Perspectives d&apos;amélioration du protocole 4.2.1 Changement de seuil de filtrage des relations lexicales françaises Les relations lexicales françaises qui comptent moins de 10 occurrences au sein du corpus sont éliminées. Or, un certain nombre de relations lexicales correctes ont des fréquences inférieures à ce seuil. C’est le cas, par exemple pour l’usage sportif de barrage (match de barrage, barrage aller, barrage retour, etc.). L’algorithme HyperLex (Véronis, 2003, 2004) nous permettrait d’identifier les usages peu fréquents des mots (jusqu’à environ 1% des occurrences). Une amélioration consisterait à ajuster le seuil des relations lexicales françaises selon la fréquence de l’usage du nom concerné. 4.2.2 Description des patrons syntaxiques de l’anglais Contrairement à notre méthode d’extraction des relations lexicales françaises, ne sont pris en compte que les patrons de « base » de l’anglais sans autres variations que celles de l’article dans le cadre de notre acquisition des traductions. Ces patrons « de base » ont donné un premier éventail de résul</context>
</contexts>
<marker>Véronis, 2003</marker>
<rawString>Véronis J. (2003), Hyperlex : cartographie lexicale pour la recherche d’informations, Actes de TALN’2003, pp. 265-274, Batz-sur-mer (France): ATALA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Véronis</author>
</authors>
<title>HyperLex : cartographie lexicale pour la recherche d’informations.Rapport Interne Equipe DELIC, Université de Provence. [En ligne : http://www.up.univmrs.fr/veronis/pdf/2004-hyperlex-rapport.pdf] Wilks</title>
<date>2004</date>
<pages>329--348</pages>
<publisher>Cambridge University Press,</publisher>
<location>In:</location>
<marker>Véronis, 2004</marker>
<rawString>Véronis J. (2004), HyperLex : cartographie lexicale pour la recherche d’informations.Rapport Interne Equipe DELIC, Université de Provence. [En ligne : http://www.up.univmrs.fr/veronis/pdf/2004-hyperlex-rapport.pdf] Wilks Y. A. (1975), Preference Semantics, In: Keenan, E. (ed), The Formal Semantics of Natural Language, Cambridge University Press, pp. 329-348.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>