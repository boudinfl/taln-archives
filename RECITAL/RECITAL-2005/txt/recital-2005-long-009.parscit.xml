<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Knight</author>
<author>G Gorrell</author>
<author>M Rayner</author>
<author>D Milward</author>
<author>R Koeling</author>
<author>I Levin</author>
</authors>
<title>Comparing grammar-based and robust approaches to speech understanding: a case study,</title>
<date>2001</date>
<booktitle>In Proceedings of Eurospeech</booktitle>
<pages>1779--1782</pages>
<location>Aalborg, Denmark,</location>
<contexts>
<context position="3459" citStr="Knight et al., 2001" startWordPosition="476" endWordPosition="479">istical methods have been commonly used in speech systems. This even to the point that it may have given the impression that rule-based methods are no longer relevant. The general success of statistical methods over rule-based methods is based principally on the general robustness of the statistical systems and on the overall easiness of system development. However in some special fields, like for example in the medical domain, the reliability of the system is more important than the general robustness of the system. This suggests that in these domains rule-based methods can be better suited (Knight et al., 2001). MedSLT is an Open Source project which is developing a generic platform for building this kind of rulebased system where reliability is a crucial issue (See Rayner, Bouillon, 2002, Rayner et al., 2004). To compare rule-based to statistical methods there exist two versions of the system, on based on grammar-based language modelling (GLM) and one on statistical language modelling (SLM). These versions are trained on the same corpus, and evaluated on a test corpus collected using both versions of the system. The experiments show that in terms of number of sentences translated, the GLM and SLM s</context>
</contexts>
<marker>Knight, Gorrell, Rayner, Milward, Koeling, Levin, 2001</marker>
<rawString>Knight S., Gorrell G., Rayner M., Milward D., Koeling R., Levin I. (2001), Comparing grammar-based and robust approaches to speech understanding: a case study, In Proceedings of Eurospeech 2001, Aalborg, Denmark, 1779–1782.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>Two-level Morphology: A General Computational Model for WordForm Recognition and Production,</title>
<date>1993</date>
<institution>University of Helsinki, Department of General Linguistics.</institution>
<marker>Koskenniemi, 1993</marker>
<rawString>Koskenniemi K. (1993), Two-level Morphology: A General Computational Model for WordForm Recognition and Production, University of Helsinki, Department of General Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MedSLT</author>
</authors>
<title>https://sourceforge.net/projects/medslt/.</title>
<date>2005</date>
<journal>As of</journal>
<volume>31</volume>
<contexts>
<context position="6498" citStr="MedSLT, 2005" startWordPosition="934" endWordPosition="935">re multilingual MedSLT system architecture including the MedSLT interlingua representation from a new perspective. Linguistic representation of Finnish in the medical domain spoken language translation system The paper is organised as follows. Section 2 describes the Open Source speech translation system MedSLT. Section 3 presents the Finnish module (sub-domain corpora, Finnish generation grammar and lexicon, and interlingua to Finnish mapping rules). Section 4 presents the evaluation of the MedSLT English to Finnish translation performance and Section 5 concludes. 2 The MedSLT system MedSLT (MedSLT, 2005, Rayner et al., 2003) is a medical domain spoken language translation (SLT) system, which is developed to translate doctor-patient examination dialogue. Translation is one-way; the system translates the diagnosis questions asked by the doctor. The questions are formulated so that the patient can answer them non-verbally by nodding or shaking the head, by pointing at a body part or similar. The system coverage is organised into medical sub-domains by symptom classes. The current system sub-domains include the emergency relevant sub-domains of headaches, chest pains and abdominal pains, each su</context>
</contexts>
<marker>MedSLT, 2005</marker>
<rawString>MedSLT (2005), https://sourceforge.net/projects/medslt/. As of 31 January 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuance</author>
</authors>
<title>http://www.nuance.com.</title>
<date>2005</date>
<journal>As of</journal>
<volume>15</volume>
<contexts>
<context position="8182" citStr="Nuance, 2005" startWordPosition="1173" endWordPosition="1174">r, 2000, Rayner et al., 2000). At runtime the system behaves like a phrasal translator, which translates beforehand defined patterns. In contrast, the compile time architecture is based on general linguistic resources. The grammars used in the MedSLT system are written in unification grammar formalism in a SICStus Prolog based feature-value notation. The unification grammars are compiled into grammar-based language models using the Open Source Regulus toolkit (Regulus, 2005) (figure 1: Regulus compile time component). Language models are in GSL form, suitable for use with the Nuance platform (Nuance, 2005). The translation is based on the interlingua approach of MT. MedSLT Runtime System Java Client Library (regclient) Regulus Runtime Speech Platform Interface Process Time System (regserver) Translation Server Nuance Voice Platform (recognition, playback) Regulus Application Unification Compile Specific Data Grammar Database Time Component Figure 1 : MedSLT system architecture The MedSLT runtime system is accessed through a GUI (illustrated in figure 1), which allows the simple utilisation of the system for the diagnosing doctor. The flow of information in the Marianne Santaholma MedSLT system </context>
</contexts>
<marker>Nuance, 2005</marker>
<rawString>Nuance (2005), http://www.nuance.com. As of 15 January 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Petitpierre</author>
<author>G Russell</author>
</authors>
<title>MMORPH-The Multext Morphology Program, Version 2.3:</title>
<date>1995</date>
<marker>Petitpierre, Russell, 1995</marker>
<rawString>Petitpierre D., Russell G. (1995), MMORPH-The Multext Morphology Program, Version 2.3: October 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phraselator</author>
</authors>
<title>http://www.phraselator.com.</title>
<date>2005</date>
<journal>As of</journal>
<volume>15</volume>
<contexts>
<context position="7522" citStr="Phraselator, 2005" startWordPosition="1078" endWordPosition="1079">overage is organised into medical sub-domains by symptom classes. The current system sub-domains include the emergency relevant sub-domains of headaches, chest pains and abdominal pains, each supporting a vocabulary of between 300 and 500 words. The current system prototype translates from English into such structurally different languages as French, Japanese and Finnish. The system includes also initial versions of French-English, Japanese-English, Spanish-English and English-Spanish. The basic architecture adopted in the MedSLT-system is a compromise between the fixedphrase translation (e.g Phraselator, 2005) and the rule-based linguistic methods (Wahlster, 2000, Rayner et al., 2000). At runtime the system behaves like a phrasal translator, which translates beforehand defined patterns. In contrast, the compile time architecture is based on general linguistic resources. The grammars used in the MedSLT system are written in unification grammar formalism in a SICStus Prolog based feature-value notation. The unification grammars are compiled into grammar-based language models using the Open Source Regulus toolkit (Regulus, 2005) (figure 1: Regulus compile time component). Language models are in GSL fo</context>
</contexts>
<marker>Phraselator, 2005</marker>
<rawString>Phraselator (2005), http://www.phraselator.com. As of 15 January 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>D Carter</author>
<author>P Bouillon</author>
<author>V Digalakis</author>
<author>M Wirén</author>
</authors>
<title>The Spoken Language Translator, Cambridge,</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="4940" citStr="Rayner et al, 2000" startWordPosition="705" endWordPosition="708">d of the target language (TL) and a set of translation rules, for example transfer rules or interlingua mapping rules. Since in general the development of linguistic resources used in translation systems is laborious and time consuming, in order to reduce the development effort needed for multilingual rule-based systems, we focus on developing general unification grammars that can be used for speech recognition, analysis, and generation. The main feature is that the general grammars will be automatically specialised for these different tasks with a corpus and an example-based learning method (Rayner et al, 2000). The grammar specialisation is necessary in order to compile the grammar into CFG form, to reduce the ambiguity of the grammar and to build the generation grammar. This paper presents the development of linguistic resources for Finnish for the MedSLT system. The development includes the collection of the medical sub-domain corpora, the creation of the Finnish generation grammar and lexicon, and the definition of interlingua to Finnish mapping rules, used by the multilingual translation module. The interest of working on the Finnish language is that despite different natural language processin</context>
<context position="7598" citStr="Rayner et al., 2000" startWordPosition="1087" endWordPosition="1090">ent system sub-domains include the emergency relevant sub-domains of headaches, chest pains and abdominal pains, each supporting a vocabulary of between 300 and 500 words. The current system prototype translates from English into such structurally different languages as French, Japanese and Finnish. The system includes also initial versions of French-English, Japanese-English, Spanish-English and English-Spanish. The basic architecture adopted in the MedSLT-system is a compromise between the fixedphrase translation (e.g Phraselator, 2005) and the rule-based linguistic methods (Wahlster, 2000, Rayner et al., 2000). At runtime the system behaves like a phrasal translator, which translates beforehand defined patterns. In contrast, the compile time architecture is based on general linguistic resources. The grammars used in the MedSLT system are written in unification grammar formalism in a SICStus Prolog based feature-value notation. The unification grammars are compiled into grammar-based language models using the Open Source Regulus toolkit (Regulus, 2005) (figure 1: Regulus compile time component). Language models are in GSL form, suitable for use with the Nuance platform (Nuance, 2005). The translatio</context>
</contexts>
<marker>Rayner, Carter, Bouillon, Digalakis, Wirén, 2000</marker>
<rawString>Rayner M., Carter D., Bouillon P., Digalakis V., Wirén M. (2000), The Spoken Language Translator, Cambridge, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>P Bouillon</author>
</authors>
<title>A flexible Speech to Speech Phrasebook Translator,</title>
<date>2002</date>
<booktitle>In Proceedings of ACL-02 Workshop on Speech-to-Speech Translation: Algorithms and Systems,</booktitle>
<pages>69--76</pages>
<location>Philadelphia,</location>
<marker>Rayner, Bouillon, 2002</marker>
<rawString>Rayner M., Bouillon P. (2002), A flexible Speech to Speech Phrasebook Translator, In Proceedings of ACL-02 Workshop on Speech-to-Speech Translation: Algorithms and Systems, Philadelphia, 69-76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>P Bouillon</author>
<author>Dalsem Van V</author>
<author>B A Hockey</author>
<author>H Isahara</author>
<author>K Kanzaki</author>
</authors>
<title>A limited-domain English to Japanese medical speech translator build using REGULUS 2,</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (demo track),</booktitle>
<pages>137--140</pages>
<location>Sapporo, Japan,</location>
<marker>Rayner, Bouillon, Van V, Hockey, Isahara, Kanzaki, 2003</marker>
<rawString>Rayner M., Bouillon P., Dalsem Van V., Hockey B.A., Isahara H., Kanzaki K. (2003), A limited-domain English to Japanese medical speech translator build using REGULUS 2, In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (demo track), Sapporo, Japan, 137-140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>P Bouillon</author>
<author>B A Hockey</author>
<author>N Chatzichrisafis</author>
<author>M Starlander</author>
</authors>
<title>Comparing Rule-Based and Statistical Approaches to Speech Understanding in a Limited Domain Speech Translation System,</title>
<date>2004</date>
<booktitle>In Proceedings of TMI 2004,</booktitle>
<pages>21--29</pages>
<location>Baltimore, MD USA,</location>
<contexts>
<context position="3662" citStr="Rayner et al., 2004" startWordPosition="510" endWordPosition="513">methods over rule-based methods is based principally on the general robustness of the statistical systems and on the overall easiness of system development. However in some special fields, like for example in the medical domain, the reliability of the system is more important than the general robustness of the system. This suggests that in these domains rule-based methods can be better suited (Knight et al., 2001). MedSLT is an Open Source project which is developing a generic platform for building this kind of rulebased system where reliability is a crucial issue (See Rayner, Bouillon, 2002, Rayner et al., 2004). To compare rule-based to statistical methods there exist two versions of the system, on based on grammar-based language modelling (GLM) and one on statistical language modelling (SLM). These versions are trained on the same corpus, and evaluated on a test corpus collected using both versions of the system. The experiments show that in terms of number of sentences translated, the GLM and SLM scored equally well. However, (Rayner et al., 2004) concluded that the GLM was preferable in terms of presenting a more predictable interface. A rule-based spoken translation system implies several differ</context>
<context position="23495" citStr="Rayner et al, 2004" startWordPosition="3337" endWordPosition="3340">olma 4 Evaluation of the translation The translation performance of the MedSLT English-Finnish language pair was evaluated on unseen data and the obtained results were compared with the corresponding results of the English-French language pair. The (speech) data used for the evaluation was collected during November 2004 in twelve data collection sessions on the headache sub-domain. A total of 870 spoken utterances were collected. For the recognition of English input were used both GLM and SLM based versions of the English recogniser (Recognition results are analysed and described in detail in Rayner et al, 2004, Rayner et al, 2005). The correctly recognised English sentences (judged by English native speakers) were translated into Finnish and the acceptability of these translations were judged by 3 Finnish native speakers with grades of ‘good’ (semantically and grammatically correct sentence), ‘acceptable’ (semantically correct translation) and ‘bad’ (semantically and grammatically incorrect sentence). The translation performance into Finnish was somewhat weaker than into French but comparable if taking into consideration the non-translated sentences (figure 4). Out of the correctly recognised utter</context>
</contexts>
<marker>Rayner, Bouillon, Hockey, Chatzichrisafis, Starlander, 2004</marker>
<rawString>Rayner M., Bouillon P., Hockey B. A., Chatzichrisafis N., Starlander M. (2004), Comparing Rule-Based and Statistical Approaches to Speech Understanding in a Limited Domain Speech Translation System, In Proceedings of TMI 2004, Baltimore, MD USA, 21-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>P Bouillon</author>
</authors>
<title>Using Regulus,</title>
<date>2005</date>
<location>http://cvs.sourceforge.net/viewcvs.py/regulus/Regulus/doc/RegulusDoc.htm.</location>
<contexts>
<context position="23516" citStr="Rayner et al, 2005" startWordPosition="3341" endWordPosition="3344"> the translation The translation performance of the MedSLT English-Finnish language pair was evaluated on unseen data and the obtained results were compared with the corresponding results of the English-French language pair. The (speech) data used for the evaluation was collected during November 2004 in twelve data collection sessions on the headache sub-domain. A total of 870 spoken utterances were collected. For the recognition of English input were used both GLM and SLM based versions of the English recogniser (Recognition results are analysed and described in detail in Rayner et al, 2004, Rayner et al, 2005). The correctly recognised English sentences (judged by English native speakers) were translated into Finnish and the acceptability of these translations were judged by 3 Finnish native speakers with grades of ‘good’ (semantically and grammatically correct sentence), ‘acceptable’ (semantically correct translation) and ‘bad’ (semantically and grammatically incorrect sentence). The translation performance into Finnish was somewhat weaker than into French but comparable if taking into consideration the non-translated sentences (figure 4). Out of the correctly recognised utterances (395 utterance;</context>
</contexts>
<marker>Rayner, Hockey, Bouillon, 2005</marker>
<rawString>Rayner M., Hockey B A., Bouillon P. (2005), Using Regulus, http://cvs.sourceforge.net/viewcvs.py/regulus/Regulus/doc/RegulusDoc.htm.</rawString>
</citation>
<citation valid="true">
<date>2005</date>
<journal>As of</journal>
<volume>31</volume>
<marker>2005</marker>
<rawString>As of 31 January 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bouillon</author>
<author>M Rayner</author>
<author>N Chatzichrisafis</author>
<author>B A Hockey</author>
<author>M Santaholma</author>
<author>M Starlander</author>
<author>Y Nakao</author>
<author>K Kanzaki</author>
<author>H Isahara</author>
</authors>
<title>A Generic Multi-Lingual Open Source Platform for Limited-Domain Medical Speech Translation,</title>
<date>2005</date>
<booktitle>In Proceedings of EAMT 2004,</booktitle>
<location>Budapest, Hungary. Forthcoming.</location>
<marker>Bouillon, Rayner, Chatzichrisafis, Hockey, Santaholma, Starlander, Nakao, Kanzaki, Isahara, 2005</marker>
<rawString>Bouillon P., Rayner M., Chatzichrisafis N., Hockey B. A., Santaholma M., Starlander M., Nakao Y., Kanzaki K., Isahara H. (2005) A Generic Multi-Lingual Open Source Platform for Limited-Domain Medical Speech Translation, In Proceedings of EAMT 2004, Budapest, Hungary. Forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Santaholma</author>
</authors>
<title>Linguistic representation of Finnish language in speech-to-speech translation system, Masters thesis.</title>
<date>2005</date>
<institution>Geneva University, Department</institution>
<contexts>
<context position="10809" citStr="Santaholma, 2005" startWordPosition="1565" endWordPosition="1566"> to find the equivalent Finnish questions for the original English diagnosis questions. Since in the current MedSLT system Finnish is used only as output language it was not regarded necessary, at this point, to take into consideration the other possible questions a Finnish doctor might want to include in the system coverage, or the different variations of the same question. Therefore it was justified to translate the original English corpora into Finnish instead of collecting authentic Finnish data. The translated Finnish diagnosis questions were, however, revised by Finnish medical doctors (Santaholma, 2005). Two essential issues were taken into consideration when translating the diagnosis questions into Finnish: the particular character of spoken language and the special situation in which the utterances were intended to be used. The spoken language style differs markedly from the written style. Generally the spoken language is more informal and commonly contains the use of ill-formed language, such as incomplete sentences, wrong word cases, and unusual word order. This special character of spoken language influenced the content of the Finnish corpora and consequently the structure and lexical r</context>
<context position="14756" citStr="Santaholma, 2005" startWordPosition="2161" endWordPosition="2162">innish generation grammar is more limited than the standard Finnish grammar regarding the variety of constructions the grammar includes. However the grammar does not contain particular structure rules that would be considered being merely specific constructions of a medical domain sublanguage. The syntax reduction in the range of constructions does rather reflect the specific text type and discourse of the domain than the domain specific language itself. Furthermore, we believe that a specialised grammar is not solely domain specific but is also constructed after a particular discourse type. (Santaholma, 2005) vp:[sem=concat(Vbar, concat(Advp, Np)), vform=Vform, subcat=A, inv=Inv, agr=Agr, subj_n_case=Case, np_n_type=nonsubj, subj_sem_n_type=SubjType, gapsin=null, gapsout=null] --&gt; vbar:[sem=Vbar, vform=Vform, inv=Inv, subcat=(trans\/personal), subcat=A, agr=Agr, np_n_type=nonsubj, subj_n_case=Case, subj_sem_n_type=SubjType, obj_sem_n_type=ObjType, obj_case=B, takes_adv_type=AdvpType], ?advp:[sem=Advp, sem_adv_type=AdvpType], np:[sem=Np, wh=n, agr=Agr, sem_n_type=ObjType, n_type=nonsubj, case=(ptv\/nom), case=B, gapsin=GIn, gapsout=GOut]. Figure 2 : Finnish transitive verb phrase rule The natural l</context>
</contexts>
<marker>Santaholma, 2005</marker>
<rawString>Santaholma M. (2005), Linguistic representation of Finnish language in speech-to-speech translation system, Masters thesis. Geneva University, Department of translation and interpretation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlster</author>
</authors>
<title>Verbmobil: Foundations of Speech-to-speech Translation,</title>
<date>2000</date>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg, New York,</location>
<contexts>
<context position="7576" citStr="Wahlster, 2000" startWordPosition="1085" endWordPosition="1086">lasses. The current system sub-domains include the emergency relevant sub-domains of headaches, chest pains and abdominal pains, each supporting a vocabulary of between 300 and 500 words. The current system prototype translates from English into such structurally different languages as French, Japanese and Finnish. The system includes also initial versions of French-English, Japanese-English, Spanish-English and English-Spanish. The basic architecture adopted in the MedSLT-system is a compromise between the fixedphrase translation (e.g Phraselator, 2005) and the rule-based linguistic methods (Wahlster, 2000, Rayner et al., 2000). At runtime the system behaves like a phrasal translator, which translates beforehand defined patterns. In contrast, the compile time architecture is based on general linguistic resources. The grammars used in the MedSLT system are written in unification grammar formalism in a SICStus Prolog based feature-value notation. The unification grammars are compiled into grammar-based language models using the Open Source Regulus toolkit (Regulus, 2005) (figure 1: Regulus compile time component). Language models are in GSL form, suitable for use with the Nuance platform (Nuance,</context>
</contexts>
<marker>Wahlster, 2000</marker>
<rawString>Wahlster W. (Ed.) (2000), Verbmobil: Foundations of Speech-to-speech Translation, Berlin, Heidelberg, New York, Springer-Verlag.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>