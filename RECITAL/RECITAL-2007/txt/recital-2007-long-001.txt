RECITAL 2007, Toulouse, 5-8 juin 2007

Utilisation des ontologies pour la modélisation logique
d’une commande en langue nature]

Laurent MAZUEL
LIP6, 104 avenue du President Kennedy, 75016 Paris
laurent.mazuel@lip6.fr

Résumé. Dans cet article, nous nous intéressons a l’interprétation de commandes en
langue naturelle pour un agent artiﬁciel. Notre architecture repose sur une modélisation lo-
gique de la commande pour l’interprétation sémantique, qui permet de capturer la « structure
fonctionnelle » de la phrase, c’est-a-dire les r6les des terrnes les uns par rapport aux autres.
Cet article décrit une méthode d’ analyse structurelle de surface qui s’appuie sur l’ontologie de
l’agent pour construire cette modélisation logique. Nous déﬁnissons tout d’ abord un algoritlrme
d’ancrage des termes de la commande dans l’ontologie de l’agent puis nous montrons com-
ment s’ en servir pour l’analyse de surface. Enﬁn, nous expliquons brievement comment rrotre
modélisation peut étre utilisée au moment de l’interprétation sémantique des commandes.

Abstract. In this paper, we focus on natural language interaction for artiﬁcial agents. Our
architecture relies on a command logical model to enhance the semantic interpretation. It allows
us to catch the « functional structure » of the user sentence, i.e. each terms compared to each
others. This paper describes a partial structural approach which relies on the agent ontology to
build a logical form of the sentence. We ﬁrst deﬁne an algorithm to anchor a word from the
command in the ontology and we use it to make our partial analysis. Lastly, we explain brieﬂy
how to use our model for the semantic interpretation of the user command.

Mots-clés 2 commande en langue naturelle, analyse structurelle de surface, modélisation
logique, ontologies.

Keywords: natural language command, partial structural analysis, logical form, onto-
logies.

1 Introduction

Dans les applications de commandes en langue naturelle, l’utilisation d’un analyseur syntaxique
basé sur des regles grarnrnaticale fortes de la langue pose des problemes d’efﬁcacité (Milward,
2000; Sabouret & Mazuel, 2005). En effet, les utilisateurs emploient plus régulierement des
mots clés plut6t que des phrases bien structurées (e. g. « drop object low » ou « take blue »). De
plus, dans le cadre d’ applications réelles, la complexité, la difﬁculté d’ écriture de regles non-
spéciﬁques et de maintenances rendent ces types d’ approches complexes at mettre en oeuvre et
lourdes a utiliser (Sabah, 2006). D’un autre coté, l’utilisation d’un modele « sac de mots » est
insufﬁsante, générant des problemes de modélisation impossible at interpreter par la suite (par
exemple, « go from London to Boston » et « go from Boston to London » sont représentées
par le meme sac de mots). C’est pourquoi la majorité des travaux actuels (Hobbs et al., 1997;

427

Laurent MAZUEL

Eliasson, 2007) cherchent a effectuer une analyse partielle (ou de surface), aﬁn de réduire le coﬁt
de développement, augmenter la portée utilitaire et éviter les écueils des deux modélisations
extrémes précédemment décrites.

Les méthodes actuelles d’ analyse de surface s’orientent ainsi vers une modélisation basée sur la
logique du premier ou second ordre (Shapiro, 2000; Milward, 2000). Cette modélisation permet
a la fois de s’affranchir d’une analyse symtaxique lourde et de conserver sufﬁsarmnent d’in-
formation pour étre applicable facilement au moment de l’analyse sémantique. Néanmoins, le
défaut de ces systemes réside dans la déﬁnition de ces prédicats, qui doit souvent se faire dans
un langage contraint dépendant d’un ensemble d’ axiomes logiques spéciﬁques (Shapiro, 2000;
Sadek et al., 1997). Au contraire, l’utilisation d’ ontologies dans les systémes de dialogue a
pour objectif de rendre les systemes plus indépendants de l’application. Elles sont utilisées par
exemple pour l’inte1prétation sémantique d’une commande pour le systéme (Milward & Beve-
ridge, 2003; Flycht-Eriksson, 2003) et avant cette interprétation pour désambigu'1'serleste1mes
d’une commande (Porzel et al., 2003; Resnik, 1995). Nous pensons qu’il est aussi possible
d’exploiter le contenu de l’ontologie pour construire la représentation structurelle logique de la
commande, ce qui permet de s’affranchir de la déﬁnition de regles dans un langage spéciﬁque.

Dans cet article, nous proposons de déﬁnir une méthode d’ analyse structurelle de surface pour
construire une modélisation logique de la commande basée sur l’étude des concepts et des re-
lations déﬁnis dans l’ontologie de l’agent. Notre analyse s’appuie sur un ancrage des termes
de la commande dans l’ontologie (nous nous placons dans le cadre de l’hypothése de connec-
tivité sémantique de Sadek (Sadek et al., 1997), qui suppose que tous les concepts de toutes
commandes apparaissent dans l’ontologie). En fonction des roles des termes dans l’ontologie
(relation ou classe), nous construisons une représentation de la commande sous forme de prédi-
cats (correspondant aux relations) et d’ arguments (instances de classes).

La section suivante présente brievement notre systeme d’inte1prétation de commandes en langue
naturel. Nous décrivons l’architecture principale et 1’ articulation entre les différents compo-
sants. La section 3 décrit plus précisément l’ancrage des termes utilisateurs a l’ontologie, l’al-
gorithme de construction logique de la commande et l’inte1prétation sémantique.

2 Architecture du systéme de commande en langue nature]

Notre architecture est basée sur le modele classique des « modules réseaux communicants »
(Allen et al., 2000; Seneff, 2002). Cette structure permet le backtrack entre les différents com-
posants ainsi que les réponses anticipées en fonction de l’état du dialogue (ﬁgure 1). Nous
donnons dans cette section les grandes lignes des modules de 1’ architecture, en gardant les dé-
tails de l’analyse logique et l’inte1prétation sémantique (comme illustration de l’uti1isation de
notre analyse) pour la section 3.1

1L‘ architecture est déﬁnie plus en détails dans (Mazuel & Sabouret, 2006). Elle est utilisée pour la déﬁnition
d‘agents conversationnels sur le web : http: //www—poleia . lip 6 . fr/~sabouret /demos.

428

Ontologies & modelisation logique d’une commande en langue naturel

     

E Etiqueteur _ l Analyse
':? Chunker l fonctionnelle
: emmatiseur H__/f l
E L.._,\ I//"M I t It t_ introspection
e o : Bactgtraék ........ .. I1 efpfe _a I0” ,d,u,,Q9I1t,e,xte,,,,.u
\/ I & Anticipation Sémanmlue 
' \.. J
E  Intmspection 
: \-V des Actions ;
(:51 Gggﬁralgsur _ Gestionnaire Generation
1 basé Sgr XML ‘ de Dialogue de Commandes

FIG. 1 — Architecture generale

2.1 Analyse morphologique et lexical

Notre module morphologique et lexical est base sur la bibliotheque d’ outils OpenNLP2. Nous
utilisons les modules Maximum-Entropy Tokenizer et Chunker, 1’etiqueteur et le lennnatiseur
base sur WordNet. L’ etiqueteur, le tokenizer et le chunker sont entraines sur des donnees an-
glaises du Wall Street Journal et du corpus Brovm. Le demier modele propose est annonce a
96% d’etiquetage correct sur des donnees hors base d’apprentissage. Une etude comparative
avec le TreeTagger3 sur quelques exemples tires de notre application n’a pas montre de pertes
tres signiﬁcatives. Le lennnatiseur base sur WordNetpermet1a decouverte des mots composes
de la commande, dans la mesure ou le tenne existe en tant qu’un des mots d’un synset (e.g.
« dark red », « extra large »). Nous n’avons pas utilise le module de resolution d’anaphore de
OpenNLP, car elles n’ apparaissent que tres rarement dans une commande (a la difference de
textes longs ou de dialogues).4

2.2 Principe de la generation de commandes formelles

Notre systeme de comprehension des commandes en langue naturelle repose sur une approche
ascendante (i.e. bottom-up) comme il est possible d’en voir dans (Paraiso & Barthes, 2004).
Cette approche utilise une liste préétablie de competences (formelles) et essaye de relier la
commande en LN a (au moins) une competence. Cependant, elles presentent des problemes
d’efﬁcacite en pratique (e.g. ecriture des competences, difﬁculte d’evolution, etc.) qui font que
nous utilisons actuellement une version ascendante générative basee sur une analyse du code
de notre agent (Mazuel & Sabouret, 2006). Notre modele agent, appele VDL, permet en effet un
acces £1 l’exécution a 1’ensemb1e du code et de son etatcourar1t(Sabouret& Sansonnet, 2001).
L’ algorithme de generation des commandes formelles est inspire des travaux sur la validation
de logiciel par 1’ analyse des preconditions d’ activation d’une action.

Le principe general de l’approche ascendante generative est d’ apparier les tennes de la com-
mande utilisateur avec les commandes formelles (i. e. notees événements en VDL) generees, qui
correspondent aux commandes que 1’agent est capable de traiter. Cet appariement est le resultat

Zhttp: //opennlp . sourceforge . net/

3http: //www . ims . uni— stuttgart . de/pro jekte/corplex/TreeTagger

4En fait, elles apparaissent uniquement lors des dialogues avec l‘uti]isateur (exemple : « prend le carre vert »,
« ok », « pose l_e en haut »). C‘est alors le gestionnaire de dialogue qui est responsable de leur resolution (cf.
section 2.3).

429

Laurent MAZUEL

de l’inte1prétation sémantique, dont nous parlerons brievement en section 3.4. A l’issue de cette
interprétation sémantique, chaque évenement est associé a un score d’appariement évaluant la
proximité de l’événement avec la commande de l’utilisateur. L’ objectif de cet article 11’ est pas
de présenter l’algorithme de calcul de ce score (le lecteur intéressé le trouvera dans (Mazuel &
Sabouret, 2006)), mais de présenter l’analyse structurelle de surface qui le rend possible.

2.3 Le gestionnaire de dialogue

A l’issue de l’inte1prétation sémantique le gestionnaire de dialogue utilise le score d’apparie-
ment pour déterminer la stratégie de dialogue. Nous utilisons pour cela un systeme de seuil
inspiré de celui proposé par Patty Maes (Maes, 1994) qui pennet de faire la différence entre
les commandes parfaitement comprises, les commandes incertaines et les commandes non-
comprises. Nous avons en plus pris en compte le cas des commandes possibles ou impossibles
dans l’état courant de l’agent (Mazuel & Sabouret, 2006).

Pour répondre a l’utilisateur, le gestionnaire de dialogue utilise un générateur d’anglais qui
transfonne une réponse formalisée en VDL en une phrase anglaise. L’algorithme actuel est trés
simple et ne produit pas des réponses grarmnaticalement correctes, mais donne sufﬁsarmnent
d’info1mations (i.e. de mots clefs) pour aider l’utilisateur a reformuler sa commande. Notre
obj ectif a long terme est d’utiliser un générateur perfonnant basé sur XML et les ontologies.

Par exemple, dans le cas d’une ambigu'1'té, le gestionnaire de dialogue propose a l’utilisateur
l’ensemble des commandes possibles dans le contexte courant et utilise le générateur d’anglais
pour transformer les commandes formalisées 2

— I want to go to Boston today.

— Your command is imprecise. I can either :
— Go Boston with flight is AFl345 and departure time is 8h47
— Go Boston with flight is AA6543 and departure time is lOh34

3 Analyse fonctionnelle logique

Nous décrivons dans cette section comment nous construisons un modele de la commande de
l’utilisateur sous la forme d’un ensemble de prédicats. Nous décrirons d’ abord le modele d’ on-
tologie utilisé, l’algorithme d’ancrage d’un mot dans l’ontologie, puis enﬁn la construction
complete de la modélisation logique de la commande.

Dans la suite de l’article, nous noterons St I’ ensemble des chaines de caracteres et pour tout
ensemble E, nous noterons ’P(E) l’ ensemble des sous-ensembles de l’ensemble E.

3.1 Modele de l’ontologie

Dans notre modele, l’ontologie d’un agent5 est un couple 0 = (C, R) dans lequel 2

— C est l’ensemble des concepts (ou classes). Un concept représente un ensemble d’obj ets réuni
par les mémes propriétés. Tout concept c E C est caractérisé par un label lc (nous nous

5Nous utilisons Jena et OWL pour l‘implémenta1:ion.
430

Ontologies & modélisation logique d’une commande en langue naturel

limiterons a un unique label pour simpliﬁer, mais il peut y en avoir plusieurs dans le cas de
swionymie, a la maniere des synsets de WordNet).

— ‘R, est un ensemble de relations binaires. Chaque relation 1" 6 ‘Rest caractérisée par un label
de relation l, et un ensemble de couples E, C C2.

Par soucis de simpliﬁcation, nous identiﬁerons l, et lc respectivement au concept c et a la relation
1", et nous noterons ainsi abusivement C et ‘R, les ensembles de labels de concepts et de relations.
Nous noterons E = C U R. Enﬁn, nous noterons (c1,r,c2) E O lorsque les concepts c1 et 02
sont reliés par la relation 1".

Soulignons que l’ontologie de domaine d’un agent contiendra non seulement les relations usuelles
d’hyperonymie (isa) et de meronymie (parto f ), mais aussi des relations plus spéciﬁque du do-
maine comme isLargerThan ou le ftO f .

3.2 Ancrage d’un mot dans l’0ntologie

Soit W l’ensemble ordonné w1,...,wn des mots utilisés dans la commande. L’ancrage dans
l’ontologie consiste a trouver le label lc ou l, « le plus proche » pour chaque mot wi. Notre
algorithme se décompose en trois étapes 2

1. La simpliﬁcation morphologique.
2. La recherche des « approximations sémantiques ».
3. L’ ancrage proprement dit.

La simpliﬁcation morphologique consiste a uniﬁer l’écriture des mots ou des groupes de mots
(accents, minuscule/majuscule, remplacement des espaces par « _ », etc). Par exemple, le terme
bigger de la commande peut correspondre aux labels bigger-than, is-bigger encore biggerfhan
selon la notation adoptée dans l’ontologie. Nous ne détaillerons pas le calcul de cette fonction
que nous noterons appm :St —> ’P(£). Elle prend en entrée un terme de la commande et ren-
voie la liste de candidats morphologiquement proche parmi les labels présent dans l’ontologie.

La recherche des « approximations sémantiques ».consiste a trouver l’ ensemble des tennes de
l’ontologie les plus proches sémantiquement d’un mot de la commande, en utilisant des mesures
de similarité sémantique comme décrites dans (Budanitsky & Hirst, 2006). Nous ne faisons
pas ici d’inte1prétation sémantique de la commande dans le contexte de l’application (nous
ne sommes pour l’instant que dans l’analyse structurelle), mais nous cherchons les concepts
représentant le n1ieux les mots utilisés par l’utilisateur. Cette démarche est équivalente aux
travaux visant a désambigu'1'serl’ensemble des concepts reconnus pour un mot d’une commande
pour ne choisir que le plus représentatif du contexte de la phrase“ (Porzel et al., 2003; Resnik,
1995). Par un exemple, dans la commande « buy a place for the Pink Floyd show at the cheapest
price », le terme « cheapest » est proche du label de relation lowerfhan et 1e 1e terme « show »
du label de concept concert7.

6]] n‘est pas forcément évident que les phrases employées au sein de notre application correspondent exacte-
ment aux sens enregistrés dans WordNet, surtout lorsqu‘il s‘agit d’un domaine technique (Resnik, 1995). Néan-
moins, nous ne nous servons pas de WordNet pour Pinterprétation sémantique mais pour aider a retrouver les
mots de l‘uti]isateur dans l‘ontologie. Ainsi, si le domaine est technique, l‘ontologie le sera aussi et la plupart des
termes utilisateurs seront retrouvés directement (ou par simpliﬁcation morphologique). Nous n‘avons d‘ai]leurs
pas constaté en pratique de faux-sens a ce niveau.

7Ces exemples sous-entendent que « cheapest » et « show » ne sont pas déﬁnie dans l‘ontologie et n‘ont pas
d‘équivalent morphologique.

431

Laurent MAZUEL

Pour cette recherche, nous avons choisi d’utiliser la formule de Jiang & Conrath (Jiang &
Conrath, 1997) appliquée aux calculs de probabilités déﬁnies par N. Seco (Seco et al., 2004).
Cette formule calcule sur WordNet un score de similarité sémantique compris entre [0, 1]. Nous
ne détaillerons pas cette formule ici car ce n’est pas l’objectif de cet article. Elle a été plu-
sieurs fois évalué et présente les meilleurs résultats actuels en la matiere (Budanitsky & Hirst,
2006). Nous noterons sz'mJg(w1, wg) le score de similarité sémantique entre les mots wl E St
et U12 6 St.

Nous noterons apps 2 St —> ’P(£) la fonction calculant l’ensemble des labels les plus proches
du terme de l’utilisateur. Nous la déﬁnissons de la facon suivante 2

app.s(w) =

111

(0 si maxfggm < to
{l E E tq simJo(l, w) = maxsim} sinon

avec to E [0, 1] le seuil d’acceptabilite’ et la similarité maximum maxfggm =  .simJg(l, 

Le seuil d’acceptabilité to permet de décider si l’appariement est acceptable ou nons. La si-
milarité maxfim est le score maximal obtenu pour le mot w lors du calcul de similarité sur
l’ontologie. Autrement dit, apps  donne l’ ensemble des concepts de l’ontologie de similarité
maximale avec w.

Ainsi, nous pouvons déﬁnir l’ancrage A C St X E des mots wl, ..., w,, dans l’ontologie O 2

A =
U (w: l) Si appm(w) 79 0

U leappm(w)
wew U (111, l) Sinon
leamdw)

Soulignons qu’un méme terme peut étre ancré a plusieurs labels de l’ontologie, donc a plusieurs
concepts et/ou relations.

Soulignons aussi que l’inte1prétation sémantique (cf. section 3.4) utilise les scores calculés a
cet étape par simm pour déterminer l’imprécision globale de la commande. Cette imprécision
est ensuite utilisée par le gestionnaire de dialogue pour déterminer la meilleure stratégie de
dialogue.

3.3 Construction des prédicats

Notre objectif est de déﬁnir une modélisation logique qui capture la structure fonctionnelle de
la phrase, c’est-a-dire de construire un ensemble de prédicats représentant les relations entre les
concepts (au sens de l’ontologie O) tels qu’ils sont exprimées dans la commande. Par exemple,
dans « the big object next to the book », l’utilisateur exprime une relation « next-to » entre « big
object » et « book ».

Pour cela, chaque terme est considéré du point de we de son ancrage dans l’ontologie 2 si c’ est
une relation, nous la modéliserons sous la forme d’un prédicat et nous devons rechercher ses
arguments dans la commande parmi les autres termes/concepts. En adoptant une représentation

8Actue]lement et empiriquement, la valeur du seuil d‘acceptabi]ité to est de 0.7.
432

Ontologies & modelisation logique d’une commande en langue naturel

    
   
 

E '°west @

   

FIG. 2 — Modelisation de « drop on the lowest line, left of the largest red cube »

arborescente des predicats, les noeuds des arbres sont les termes de la commande. Les tennes
qui sont des labels de concepts sont representes par des feuilles. Les termes qui sont des labels
de relations sont representes par des noeuds dont les ﬁls sont les arguments de la relation dans
la commande de l’utilisateur. Par exemple, dans la phrase « drop on the lowest line, left of the
largest cube », « drop », « line », « red » et « cube » sont des feuilles, « lowest » aura comme
ﬁls « line ». Nous obtenons alors le resultat presente dans sur ﬁgure 2.

Toute la difﬁculte de cette construction reside dans la capacite a determiner quel terme est un
argument de quelle relation. Idealement, nous devrions nous appuyer sur 1’ analyse semantique
de la phrase et sur les deﬁnitions des relations dans l’ontologie pour identiﬁer les instances
correspondant a des arguments de 1’ agent, en utilisant du backtrack pour rechercher toutes les
permutations possibles.

Mais dans un premier temps, par soucis d’efﬁcacite, nous utiliserons l’heuristique suivante, tiree
de nos observations sur les relations dans la langue anglaise 2

Les arguments d’une relation sont soit l’ensemble des termes restant dans le syn-
tagme nominal de la relation, soit dans l’ensemble des termes du symtagme imme-
diatement suivant.

La force de cette heuristique est qu’elle prend aussi en compte le traitement des comparatifs et
des superlatifs 2

1. Si un superlatif appara’1‘t, il l’est alors a titre d’ adjectif descriptif de l’objet. Les termes de
la commande relies appartiennent donc au meme syntagme (e. g. « the biggest square »,
« the darkest big object », etc.).

2. Si un comparatif appara’1‘t, l’objet de la comparaison est separe par l’utilisation d’une
conjonction (« than », etc.) et donc dans le symtagme suivant (e.g. « higher than the
cube », « left to the current position », etc.).

Fonnellement, soit S l’ensemble ordonne’ {c1,c2, ...,c,L} compose de 71 chunks tel que W E
[1, n], q = {sigh 51,2, ..., 3%} oil les 311,- sont les termes de la commande utilisateur, regroupes
en chunksg. La fonction 7' 2 S »—> S,, construit l’ensemble d’arbres S,, a partir de la modelisa-
tion de la commande chunkee S. Les elements de Sa seront representes en utilisant une notation
predicat/Valeurs (chaque predicat representant un noeud, et ses valeurs les ﬁls du noeud).

La fonction 7' est deﬁnie recursivement par 2 7(5) =

9La commande de l‘u1:i]isateur est Pensemble ordonné SW" = {.s1,1, 31,2...“ 31¢“, 32,1, ..., 3%,, ..., 3,1,1, ..., smk" }.

433

Laurent MAZUEL

{am (-({{s1,2, ...s1,a}}))} U T({o2,  c,L}) Si (kl > 1) /\ (Elc e R. (31,,-,c) e A)

{$111  U T({C3, ...,  Sl (k1 = 1) /\ (30 E  (Sid, C) E 

{51,1}U 7'({{s1,2, ...s1,k1}, C2, ..., cn}) sinon
avec 7'(@) = 7'({@}) = (0. Autrement dit, l’arbre Sa est obtenu en transformant chaque relation
de la commande en noeud dont les ﬁls sont les termes restant du chunk (lorsque kl > 1) ou les
éléments du chunk immédiatement suivant lorsque la relation est le dernier élément du chunk
(k1 = 1). Les concepts sont systématiquement transformés en feuilles. Pour mieux comprendre
cette opération, considérons l’exemple suivant 2 « drop on the lowest line, left of the largest red
cube » est chunkée en 2

[VP Drop 2VB ] [PP on :IN ] [NP the :DT lowest 2JJS line :NN ] [?? , 2, ] [NP
left :NN ] [PP of :IN ] [NP the :DT largest 2JJS red 2JJ cube :NN ]

Apres ﬁltrage des termes non- signiﬁcatifs, nous obtenons l’ensemble d’ ensembles 2

S = {{drop}, {lowest, line}, {leftof}, {largest red, cube}}

Nous obtenons alors 7(5) = {drop, lowest(line), le fto f (largest(red, cube))}, représenté sous
forme d’arbre sur la ﬁgure 2.

3.4 Interprétation sémantique

L’ analyse fonctionnelle décrite précédemment (cf ﬁgure 3) permet 2

1. La construction d’un ensemble d’arbres représentant la commande;
2. L’ ancrage de cet arbre, par l’ancrage de chacun de ses termes, sur l’ontologie.

Ces deux propriétés sont a la base de notre modele d’ analyse sémantique. En effet, de maniere
similaire, nous ancrons serni-automatiquement le code de l’agent VDL sur l’ontologie au mo-
ment de l’écriture de l’agent. Ainsi, les évenements formels construits par notre algorithme
ascendant génératif, utilisant des termes issus du code VDL, sont déja ancrées dans l’ontolo-
gie (chaque commande générée ayant un ancrage different). Nous nous retrouvons alors dans
une situation proche d’un probleme d’appariement d’ontologies selon une ontologie de réfé-
rence (e.g. (Aleksovski et al., 2006)). L’ objectif est alors d’évaluer comparativement ses deux
ancrages, aﬁn de pouvoir décider quelles sont les commandes générées les plus proches de la
commande en langue naturelle de l’utilisateur.

C’est l’ancrage des termes de la commande dans l’ontologie qui permet de se ramener a un
probleme (non trivial) d’alignement d’ontologies. En effet, il nous est alors possible de cal-
c11ler l’alignement demandant le moins « d’ effort » d’approximation entre les deux ensembles
de termes ancrés et donc d’en déduire quel couple (évenement/structure de commande) est le
meilleur candidat comme résultat a cette inteiprétation sémantique.

La modélisation logique structurée de la commande utilisateur est ensuite utilisée au moment de
l’inte1prétation sémantique pour calculer la fermeture transitive de la relation dans le contexte
courant de l’agent. Par exemple, si l’utilisateuI parle d’un objet « £1 céte’ du livre », notre in-
teiprétation sémantique donne l’ ensemble des positions correspondant a « £1 céte’ du livre » en
fonction de la position du livre dans l’état courant.

434

Ontologies & modelisation logique d’une commande en langue naturel

Ontologie

Evénement
formel VDL

     

Structure Iogique
—-—de.la.,cg mande

FIG. 3 — l-’3tat apres la modelisation logique avec un evenement formel et un seul arbre de la
comnrande.

4 Conclusion

Dans cet article, nous proposons un algorithme de modelisation d’une comnrande sous la forme
d’un ensemble de propositions logiques qui s’ appuie sur l’utilisation de l’ontologie de 1’ agent.
Les symboles de predicats utilises sont directement extrait a partir des terrnes de la commande
en fonction de leur proxinrite avec les concepts de l’ontologie. Les r6les de predicats ou argu-
ments pour chaque tenne sont choisis a partir de leur deﬁnition dans l’ontologie. Ce mecarrisme
ne necessite donc pas l’utilisation d’un forrnalisme particulier pour deﬁnir les regles d’ analyse
syurtaxique. La modelisation obtenue est simple a interpreter et a utiliser, en particulier pour l’in-
terpretation semantique de la comrrrande. La plupart des systemes de dialogues actuelles etant
bases sur l’utilisation d’ ontologies pour l’interpretation semantique, l’approche est applicable a
large echelle sur des systemes d’implementation diverses.

La methode d’ ancrage des terrnes de la comnrande dans l’ontologie (c’est-a-dire la recherche
du concept de l’ontologie le plus proche semantiquement d’un tenne donne) que nous avons
presente repose sur un algorithme de sirrrilarite semantique base sur WordNet. L’eva1uation
prelirninaire de notre systeme actuellement en court presente des resultats encourageants. Ce-
pendant, nous voudrions la valider sur d’autres agents et ontologies que celles que nous avons
utilisees jusqu’a present, aﬁn de montrer la genericite de notre approche.

Références

ALEKSOVSKI Z., TEN KATE W. & VAN HARMELEN F. (2006). Exploiting the structure of
background knowledge used in ontology matching. In Proc. Workshop on Ontology Matching
in ISWC2006 : CEUR Workshop Proceedings.

ALLEN J., BYRON D., DZIKOVSKA M., FERGUSON G., GALESCU L. & STENT A. (2000).
An architecture for a generic dialogue shell. NLENG .' Natural Language Engineering, 6.
BUDANITSKY A. & HIRST G. (2006). Evaluating wordnet-based measures of semantic dis-
tance. Computational Linguistics, 32(1), 13-47.

ELIASSON K. (2007). Case-Based Techniques Used for Dialogue Understanding and Plarming
in a Human-Robot Dialogue System. In Proc. of IJCAI07, p. 1600-1605.
FLYCHT-ERIKSSON A. (2003). Design of Ontologies for Dialogue Interaction and Informa-
tion Extraction. In Proc. Workshop on Knowledge and reasoning in practical dialogue systems
(IJCAI’03).

435

Laurent MAZUEL

HOBBS J., APPELT D., BEAR J., ISRAEL D., KAMEYAMA M., STICKEL M. & TYSON
M. (1997). FASTUS 2 A Cascaded Finite-State Transducer for Extracting Information from
Natural-Language Text. Finite-State Language Processing, p. 383-406.

J IANG J. & CONRATH D. (1997). Semantic similarity based on corpus statistics and lexical
taxonomy. In Proc. on International Conference on Research in Computational Linguistics, p.
19-33, Taiwan.

MAES P. (1994). Agents that reduce workload and information overload. Communications of
the ACM, 37(7), 30-40.

MAZUEL L. & SABOURET N. (2006). Generic command interpretation algorithms for conver-
sational agents. In Proc. Intelligent Agent Technology (IAT’06), p. 146-153 2 IEEE Computer
Society.

MILWARD D. (2000). Distributing representation for robust interpretation of dialogue utte-
rances. In ACL, p. 133-141.

MILWARD D. & BEVERIDGE M. (2003). Ontology-based dialogue systems. In Proc. 3rd
Workshop on Knowledge and reasoning in practical dialogue systems (IJCAI03), p. 9-18.
PARAISO E. & BARTHES J. (2004). Architecture d’une interface conversationnelle pour les
agents assistants personnels. In P. PAROUBECK & J .-P. SANSONNET, Eds., Actes de la Jour-
ne’e d ’Etude ATALA Agental « Agents et Iangue », p. 83-90, Paris, France 2 ATALA ATALA.
PORZEL R., GUREVYCH I. & MULLER C. (2003). Ontology-based contextual coherence
scoring. In Proc. of the Fourth SIGdial Workshop on Discourse and Dialogue, Sapporo, Japan.
RESNIK P. (1995). Using information content to evaluate semantic similarity in a taxonomy.
In IJCAI, p. 448-453.

SABAH G. (2006). Compre’hension des langues et interaction. Cognition et Traitement de
l’Information. Herrnes-Lavoisier.

SAB OURET N. & MAZUEL L. (2005). Commande en langage naturel d’ agents VDL. In Proc.
I st Workshop sur les Agents Conversationnels Anime’s (WACA), p. 53-62.

SAB OURET N. & SANSONNET J. (2001). Automated Answers to Questions about a Running
Process. In Proc. CommonSense 2001, p. 217-227.

SADEK D., BRETIER P. & PANAGET E. (1997). Ar1'.imis 2 Natural dialogue meets rational
agency. In IJCAI (2), p. 1030-1035.

SECO N., VEALE T. & HAYES J. (2004). An Intrinsic Information Content Metric for Seman-
tic Similarity in WordNet. In Proc. ECAI’2004, the I 6th European Conference on Artificial
Intelligence, p. 1089-1090.

SENEFF S. (2002). Response planning and generation in the MERCURY ﬂight reservation
system. In Computer Speech and language, volume 16, p. 283-312.

SHAPIRO S. (2000). Sneps 2 a logic for natural language understanding and commonsense rea-

soning. Natural language processing and knowledge representation : language for knowledge
and knowledge for language, p. 175-195.

436

Alexia BLANCHARD

nous avons ajoute ces re'gularisations et ﬂexions erronees au modele. (e.g. la re'gularisation
erronee —eaux en —als en plus de la re'g.1larisation existante —aux en —als).

Apres la modiﬁcation du modele, nous obtenons 88 modeles de ﬂexions, contre 61 a
l’origine, et 83 regles de regularisations contre 63. Quant au dictionnaire, nous avons modiﬁe
de facon semi-automatique les 70 000 entre'es aﬁn d’associer les modeles de ﬂexions a
chaque base.

Nous trouvions judicieux, en plus des informations « classiques» generees par l’analyse
morphologique, de creer une typologie des erreurs de morphologie ﬂexionnelle, en nous
appuyant sur le corpus FRIDA et sur le modele (i.e. mauvaise manipulation des regles de
regmlarisations). Cette typologie permet de proposer une premiere interpretation,
eventuellement utilisable pour la future generation du feed-back. Par exemple, nationals est
type comme un oubli d’une regularisation de forme (i.e. -aux en -als) Via le code
Fl_REGF_O genere lors de son analyse. Quant ajourneaux, son analyse produit le code
F2_REGF, qui correspond a une utilisation d’une reg.1larisation de forme inexistante en
francais (i.e. —eaux en —als).

Le module a ete realise en Prolog ll+7, pour sa capacite a separer donnees et algorithmes
(grammaire declarative) et pour son principe de bactracking (qui permet une analyse
combinatoire et multiple).Voici la sortie propose'e par notre analyseur pour les deux formes
Vues pre'ce'demment :

[----l

quelle Fnrlne uou1ez—uous analyser? (pour quitter, taper 1)

national;

<'?xIn1 uersiun="1.ﬂ" en:oding="ISlJ—B859—1"'?>

('.7xIn1—sty1Bsheet ty[IE="tBXt/DES" I'll‘EF="Sty1E.[2ES" ?)

<nesu1tats>\

<FnrIne_ana1ysee>nationa1s</ForIne_ana1ysee>

(I2ategurie)Rdjet:tiF(/[2ateguria)
<Lemne>natinna1</Lemme)
(Interpretatiun_I1e5_F1Bxiun5)[maa,plu](IInterpretatiun_|1es_F1exiur
(Type_erreur>F1_REGF_lJ</Type_erreur>

quella FDFIIIE unulrr-z—uuus analyser? (puur quitter, taper 1)

jnurneaux

<FurIne_ana1ysee)juurneaux</FurIne_ana1y§ee)

<categurie>NoIn</Gategurie>
(Lemme>juurna1</Lemma)
<1nterpretatinnidesiﬂexinn5>[mas,p1u]<lInterpretationidesiﬂexior
(Type_erreur>F2_REI3F(lType_Brreur)

( 3

Figmre 1 : Sorties de l’analyseur pour les formes nationals etjourneaux.

Lors de l’analyse de nationals, l’algorithme decoupe la forme en national- et —s. 11 Veriﬁe
ensuite la pre'sence de la base dans le dictionnaire. Grace a cela, il recupere le modele associe'
au lemme et compare les ﬂexions et les re'gularisations effectuees lors du de'coupage par
rapport aux ﬂexions et re'gularisations autorisees (et obligatoires) du modele. Il observe une
incoherence sur une regularisation qui n’a pas ete effectuee par l’apprenant pour former le
masculin pluriel de national. Il genere un diagnostic en consequence, puis tente un nouveau
de'coupage (nationa + ls, etc.), sans succes.

Pourjourneaux, aucun decoupage ne permet d’extraire une base appartenant au dictionnaire.
ll effectue donc une regularisation de forme (-eaux en —als), puis decoupe la forme en

journal- et —s. Les donnees associees au lemme ne correspondent pas aux donnees du

7

htm://www.prologia.fr/

444

L’analyse morphologique des re'ponses d’apprenants

decoupage, au niveau de la regmlarisation qui est en fait une regularisation erronee. ll de'tecte
ainsi une erreur et ge'nere la retroaction, comme montre ci-dessus (ﬁgure 1).

4 Conclusion et perspectives

Nous avons deVeloppe' un module permettant la detection et l’analyse d’erreurs
morphologiques en situation hors-contexte. ll donne des re'sultats tout a fait prometteurs quant
a l’analyse des erreurs issues du corpus FRIDA (toutes les erreurs sont correctement
analyse'es). 11 est evident qu’il est ne'cessaire de tester ce module sur un corpus plus important
que ce demier, afin de Valider notre demarche, et de completer notre modelisation linguistique
des erreurs morphologiques existantes.

ll serait inte'ressant d’integrer ce module dans un systeme existant d’ALAO, aﬁn de deﬁnir sa
plus-Value et la robustesse qu’il peut apporter a celui-ci. La prochaine e'tape de ce travail Va
ainsi consister a implementer cette analyse au sein de la plateforme MIRTO (Antoniadis et
al., 2005a) qui a l’heure actuelle se fonde sur une analyse a 4 niveaux (Kraif, 2005). Cette
demiere n’est pas capable de ge'nerer des re'troactions sur des erreurs morphologiques. En
effet, son analyse considere chevals comme une erreur d’orthographe, en trouvant une
ressemblance graphique entre chevals et cheval, et ne peut extraire aucune information
expliquant l’erreur de l’apprenant.

Ce module constitue une premiere pierre dans la re'alisation d’un dispositif complet capable
de detecter et interpre'ter les reponses d’apprenants. ll convient a present d’e'largir le type des
erreurs a analyser. C’est dans cette optique que s’inscriVent mes travaux de these. Une
premiere e'tape consistera a de'ﬁnir les types d’actiVites qui seront susceptibles d’étre e'Valuees
par des outils issus du TAL. Puis, nous e'tablirons un corpus de productions d’apprenants Via
les activites retenues. Ces donnees perrnettront ensuite d’e'tablir une typologie attestee des
erreurs rencontrees. A partir de ces recherches, la conception d’un systeme TAL d’e'valuation
des productions et de generation de re'troactions pourra alors étre mene'e.

Références

AGREN M. (2005). La morphologie du nombre dans le systeme Verbal en francais L2 e'crit-
L’accord de la 35”” personne du pluriel. Acquisition et production de la morphologie
ﬂexionnelle. Actes du Festival de la morphologie. Jonas Granfeldt et Suzanne Schylter Eds,
Lund (Suede).

ANTONIADIS G., ECHINARD S., KRAIF 0., LEBARBE T., PONTON C. (2005a). Modelisation de
l’inte'gration des ressources TAL pour l’apprentissage des langues : la plateforme MIRTO.
Revue ALSIC, 8.

ANTONIADIS G., FAIRON C., GRANGER S., MEDORI J., ZAMPA V. (2006). Quelles machines
pour enseigner la langue. T ALN 2006, Leuven.

ANTONIADIS G., PONTON C., ECHINARD S. (200513). Le TAL au servie de l’eValuation
automatique des fautes d’apprenants. Du Vrai / faux a l’eValuation pedagogique. Actes du
colloque UNTELE.

ASTOLFI J.P. (1997). L’erreur, un outilpour enseigner. Paris : Editions ESF.

445

Alexia BLANCHARD

BERRENDONNER A. (1990). Grammaire pour un analyseur. Aspects morphologiques. France :
Les Cahiers du CRISS.

BOUILLON P., VANDOOVEREN F., DA SYLVA L., JACQMIN L., LEHMANN S., RUssEL G., VIEGAS
E. (1998). T raitement automatique des langues naturelles. Paris : Duculot.

CORDIER-GAUTHIER C., DION C. (2003). Correction et revision de l’ecrit en francais langue
seconde : mediation humaine, mediation inforrnatique. Revue ALSIC, 24,29-43.

FAYOL M. (2001). Compte-rendu de la conference donnee par M. Fayol a l’IUFM de Poitou-
Charentes, site des Deux-Sevres a Niort, dans le cadre des Conference de L’Ais :Apprendre a
utiliser l ’orthographe.

FUCHS C., DANLOS L., LACHERET-DUJOUR A., LUZATTI D., VICTORRI B. (1993). Linguistique
et T raitementAutomatique des Langues. France : Hachette.

GRANGER S., VANDEVENTER A., HAMEL M.J. (2001). Analyse de corpus d’apprenants pour
l ’ELAO base sur le TAL. Paris : Hermes.

KRAIF O. (2005). Evaluation automatique de productions lexicales : une analyse a 4 niveaux.
Actes du colloque UNTELE.

LALLICH-BOIDIN G., HENNERON G., PALERMATI R. (1990). Analyse dufrangais. Achevement
et implantation de l ’analyseur morpho-syntaxique. France : Les Cahiers du CRISS (Centre de
Recherche en Informatique appliquee au Sciences Sociales.

LANCIEN T. (1997). Le Multimedia (pp. 90-97). Cle International.

L’HAIRE S., VANDEVENTER A. (2003). Diagnostic d’erreurs dans le projet FreeText. Revue
ALSIC, Vol. 6, n°2, 21-37.

NIELSEN J. (1993). Usability engyneering. New York: Academic Press.

REZEAU J. (2004). Mediatisation et mediation pédagogique dans un environnement
multimedia. Le cas de l ’apprentissage de l ’anglais en Histoire de l ’Art. These de doctorat de
l’uniVersite Bordeaux 2 (pp. 356-367).

SILBERZTEIN M. (1993). Dictiormaires electroniques et analyse automatique de textes .' le
systeme INT EX. Paris : Masson.

WYATT D.H. (1988). Applying pedagogical principles to CALL courseware development, in

Modern Media in Foreign Langnlage Education : Theory and implementation. Illinois:
National Textbook.

446

