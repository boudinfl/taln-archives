<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Extraction de paraphrases d&#233;sambigu&#239;s&#233;es &#224; partir d&#8217;un corpus d&#8217;articles encyclop&#233;diques align&#233;s automatiquement</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#201;CITAL 2007, Toulouse, 5&#8211;8 juin 2007 
</p>
<p>Extraction de paraphrases d&#233;sambigu&#239;s&#233;es &#224; partir d&#8217;un corpus 
d&#8217;articles encyclop&#233;diques align&#233;s automatiquement 
</p>
<p>Fran&#231;ois-R&#233;gis CHAUMARTIN
Lattice/Talana &#8211; Universit&#233; Paris 7 
</p>
<p>30 rue du ch&#226;teau des rentiers, 75013 Paris 
fchaumartin@linguist.jussieu.fr, frc@proxem.com 
</p>
<p>R&#233;sum&#233;. Nous d&#233;crivons ici comment enrichir automatiquement WordNet en y important 
des articles encyclop&#233;diques. Ce processus permet de cr&#233;er des nouvelles entr&#233;es, en les 
rattachant au bon hyperonyme. Par ailleurs, les entr&#233;es pr&#233;existantes de WordNet peuvent &#234;tre 
enrichies de descriptions compl&#233;mentaires. La r&#233;p&#233;tition de ce processus sur plusieurs 
encyclop&#233;dies permet de constituer un corpus d&#8217;articles comparables. On peut ensuite extraire 
automatiquement des paraphrases &#224; partir des couples d&#8217;articles ainsi cr&#233;&#233;s. Gr&#226;ce &#224; 
l&#8217;application d&#8217;une mesure de similarit&#233;, utilisant la hi&#233;rarchie de verbes de WordNet, les 
constituants de ces paraphrases peuvent &#234;tre d&#233;sambigu&#239;s&#233;s. 
</p>
<p>Abstract. We describe here how to automatically import encyclopedic articles into 
WordNet. This process makes it possible to create new entries, attached to their appropriate 
hypernym. In addition, the preexisting entries of WordNet can get enriched with 
complementary descriptions. Reiterating this process on several encyclopedias makes it 
possible to constitute a corpus of comparable articles; we can then automatically extract 
paraphrases from the couples of articles that have been created. The paraphrases components 
can finally be disambiguated, by means of a similarity measure (using the verbs WordNet 
hierarchy).
</p>
<p>Mots-cl&#233;s :   extraction de paraphrases, fusion d&#8217;articles, mesure de similarit&#233;, distance 
s&#233;mantique, identification d&#8217;hyperonyme, WordNet, Wikipedia, entit&#233;s nomm&#233;es, analyse 
syntaxique, d&#233;sambigu&#239;sation lexicale, cadres de sous-cat&#233;gorisation, apprentissage.
</p>
<p>Keywords: paraphrases extraction, articles merging, similarity measure, semantic 
distance, hypernym identification, WordNet, Wikipedia, named entities, syntactic analysis, 
word sense disambiguation, syntactic frames, unsupervised learning.
</p>
<p>1 Introduction
</p>
<p>1.1 Architecture d&#8217;ensemble 
</p>
<p>Nous souhaitons disposer d&#8217;une correspondance directe entre les articles d&#8217;une encyclop&#233;die 
et les entr&#233;es d&#8217;un lexique s&#233;mantique de r&#233;f&#233;rence. Deux cas de figure se rencontrent alors ; 
</p>
<p>457</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Fran&#231;ois-R&#233;gis CHAUMARTIN
</p>
<p>quand une entr&#233;e de lexique correspond d&#233;j&#224; &#224; un article, nous &#233;tablissons la correspondance 
entre les deux ; sinon, nous enrichissons le lexique, en cr&#233;ant une nouvelle entr&#233;e et en la 
rattachant (via une relation d&#8217;hyperonymie/hyponymie) au meilleur &#171; anc&#234;tre &#187; existant. 
</p>
<p>En r&#233;it&#233;rant ce processus sur plusieurs encyclop&#233;dies, nous obtenons un corpus monolingue 
de paires d&#8217;articles traitant d&#8217;un m&#234;me sujet, propice &#224; la d&#233;couverte de paraphrases. Nous 
pouvons alors d&#233;terminer, par exemple, que &#171; la rivi&#232;re Alabama serpente jusqu&#8217;&#224; Selma &#187; 
est une paraphrase de &#171; la rivi&#232;re Alabama coule vers Selma &#187;. Nous repr&#233;sentons les 
paraphrases sous forme de triplets (sujet, verbe, compl&#233;ment). La d&#233;sambigu&#239;sation des 
entit&#233;s nomm&#233;es permet d&#8217;&#233;tablir que &#171; RIVI&#200;RE#1 serpente (pr&#233;position) VILLE#1 &#187; est une 
paraphrase de &#171; RIVI&#200;RE#1 coule (pr&#233;position) VILLE#1 &#187;. (L&#8217;indice #i indique le sens du mot 
dans le lexique.) L&#8217;utilisation d&#8217;une mesure de similarit&#233; entre les deux verbes permet enfin 
de d&#233;terminer les sens de &#171; serpenter &#187; et &#171; couler &#187; dans le contexte. Nous obtenons, au final, 
l&#8217;&#233;quivalence entre deux cadres de sous-cat&#233;gorisation, dont les &#233;l&#233;ments sont d&#233;sambigu&#239;s&#233;s 
par rapport au lexique : SERPENTER#1 (RIVI&#200;RE#1, VILLE#1) ~ COULER#2 (RIVI&#200;RE#1, VILLE#1).
</p>
<p>Ces op&#233;rations constituent les deux premi&#232;res &#233;tapes du projet ISIDORE1, qui vise &#224; extraire 
des connaissances d&#8217;une encyclop&#233;die en langue anglaise. Pour faciliter la lecture, les 
exemples cit&#233;s ici ont &#233;t&#233; traduits en fran&#231;ais. 
</p>
<p>Figure 1 : architecture d&#8217;ensemble du projet ISIDORE 
</p>
<p>1.2 Lexique de r&#233;f&#233;rence 
</p>
<p>Notre lexique de r&#233;f&#233;rence est WordNet (Miller, 1995) version 2.1. Ce projet, men&#233; depuis 
1985 &#224; Princeton, offre un r&#233;seau s&#233;mantique tr&#232;s complet de la langue anglaise. S&#8217;il n&#8217;est pas 
exempt de critiques (granularit&#233; tr&#232;s fine, absence de relations paradigmatiques&#8230;), WordNet 
n&#8217;en reste pas moins l&#8217;une des ressources de TAL2 les plus populaires. 
</p>
<p>Les n&#339;uds sont constitu&#233;s par des ensembles de synonymes (ou synsets), correspondant au 
sens d&#8217;un ou plusieurs lemmes. Un synset est d&#233;fini d&#8217;une fa&#231;on diff&#233;rentielle par les relations 
qu'il entretient avec les sens voisins. Par exemple, des relations d&#8217;hyperonymie et 
d&#8217;hyponymie relient les &#171; anc&#234;tres &#187; des noms et des verbes avec leurs &#171; sp&#233;cialisations &#187;. La 
version 2.1 a de plus introduit la notion d&#8217; &#171; instance hyponyme &#187;, qui d&#233;signe une instance 
</p>
<p>1 St-Isidore (560-636), patron des informaticiens, fut l&#8217;auteur des Etymologies, une encyclop&#233;die en 20 livres. 
</p>
<p>2 WordNet est t&#233;l&#233;chargeable sur http://wordnet.princeton.edu. 
</p>
<p>458</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Extraction de paraphrases d&#233;sambigu&#239;s&#233;es &#224; partir d&#8217;un corpus d&#8217;articles encyclop&#233;diques 
</p>
<p>(typiquement une entit&#233; nomm&#233;e) d&#8217;un synset, et non une sous-classe. Ainsi, le nom TOUR#1 a 
SILO#1, MINARET#1, PHARE#1&#8230; pour hyponymes, et TOUR EIFFEL #1 comme instance hyponyme. 
</p>
<p>2 Importation d&#8217;articles encyclop&#233;diques dans WordNet 
L&#8217;encyclop&#233;die en ligne Wikipedia poss&#232;de une vingtaine d&#8217;articles dont le titre contient (au 
moins partiellement) &#171; Abraham Lincoln &#187; :
</p>
<p>1. &#171; Abraham Lincoln &#187; : l&#8217;homme politique, 16&#232;me Pr&#233;sident des Etats-Unis. 
2. &#171; Abraham Lincoln assassination &#187; : l&#8217;assassinat de l&#8217;homme politique. 
3. &#171; Abraham Lincoln (Pullman car) &#187; : le plus ancien wagon de passagers des Etats-Unis. 
4. Sans oublier deux films biographiques, trois lieux g&#233;ographiques, plusieurs &#233;coles, deux 
</p>
<p>vaisseaux militaires&#8230; &#233;galement nomm&#233;s en m&#233;moire de l&#8217;homme politique. 
</p>
<p>Nous constatons donc qu&#8217;une similarit&#233; entre le titre d&#8217;un article et un lemme (ou groupe de 
mots) d&#233;signant un synset de WordNet ne suffit pas &#224; d&#233;duire qu&#8217;ils traitent du m&#234;me sujet. 
</p>
<p>Nous cherchons &#224; identifier le (ou les) synset de WordNet auquel un article se rattache. Pour 
ce faire, nous commen&#231;ons par extraire de WordNet les &#171; synsets candidats &#187; pouvant 
correspondre au titre de l&#8217;article. Cette &#233;tape ne pose pas de difficult&#233; particuli&#232;re. Pour les 
personnes, par exemple, chaque article poss&#232;de un ou plusieurs titres normalis&#233;s (de la forme 
&#171; Pr&#233;nom Nom &#187; ou &#171; Nom, Pr&#233;nom &#187;). Il suffit de rechercher les synsets correspondants 
dans WordNet. Pour un nom commun, il est n&#233;cessaire de tenir compte d&#8217;&#233;ventuelles 
variantes morphologiques et de retrouver la forme de base du mot. Nous appliquons alors un 
ensemble d&#8217;heuristiques3 pour retenir le meilleur candidat. S&#8217;il n&#8217;en existe pas, nous 
commen&#231;ons par chercher le synset correspondant le mieux au th&#232;me de l&#8217;article (d&#233;crit-il une 
rivi&#232;re, un pr&#233;sident&#8230; ?) Ensuite, nous cr&#233;ons un nouveau synset, rattach&#233; (en tant 
qu&#8217;hyponyme ou instance hyponyme) au synset du th&#232;me de l&#8217;article. 
</p>
<p>Dans l&#8217;univers du traitement automatis&#233; des encyclop&#233;dies, la Wikipedia pose un probl&#232;me 
particulier. Pouvant &#234;tre modifi&#233;e par tout internaute, elle voit depuis plusieurs ann&#233;es une 
progression exponentielle de son nombre d&#8217;entr&#233;es4 : certain articles ne sont que des 
biographies auto-promotionnelles, d&#8217;autres des comptes-rendus de films ou de jeux vid&#233;o&#8230; 
Notre choix est de ne retenir que les entr&#233;es correspondant &#224; un consensus en termes de 
connaissances encyclop&#233;diques. Nous travaillons donc sur un sous-ensemble des articles de la 
Wikipedia recoupant (sur la base du titre) ceux d&#8217;une autre encyclop&#233;die de r&#233;f&#233;rence. 
</p>
<p>3 (Carr&#233;, Degremont, Gross, Pierrel, Sabah, 1991) d&#233;finit (p. 48) une heuristique comme &#171; une r&#232;gle qu&#8217;on a 
int&#233;r&#234;t &#224; utiliser en g&#233;n&#233;ral, parce qu&#8217;on sait qu&#8217;elle conduit souvent &#224; la solution, bien qu&#8217;on n&#8217;ait aucune 
certitude sur sa validit&#233; dans tous les cas &#187;. 
</p>
<p>4 1 539 908 fin 2006 ; 874 359 fin 2005 ; 414 023 fin 2004 ; 188 538 fin 2003 ; 95 735 fin 2002. 
</p>
<p>459</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Fran&#231;ois-R&#233;gis CHAUMARTIN
</p>
<p>2.1 Autre projet similaire 
(Ruiz-Casado, Alfonseca, Castells, 2005) pr&#233;sentent l&#8217;impl&#233;mentation d&#8217;un algorithme rapide 
permettant de r&#233;aliser la correspondance entre un article de la Simple Wikipedia5 et le synset 
correspondant de WordNet6. Si aucun synset n&#8217;a de lemme en commun avec le titre de 
l&#8217;article, ce dernier est ignor&#233;. Si un seul synset de WordNet a un lemme &#233;gal au titre, l&#8217;article 
y est li&#233; sans autre analyse. En cas d&#8217;ambigu&#239;t&#233;, l&#8217;article fait l&#8217;objet d&#8217;un &#233;tiquetage 
morphosyntaxique (apr&#232;s un filtrage des marqueurs syntaxiques sp&#233;cifiques &#224; la Wikipedia),
pour ne conserver que les noms, verbes et adjectifs. Le syst&#232;me analyse les d&#233;finitions de 
WordNet, et construit pour chacune d&#8217;entre elles un vecteur bool&#233;en (contenant &#171; 1 &#187; pour 
chaque terme en commun avec l&#8217;article et &#171; 0 &#187; pour chaque mot en disjonction). 
L&#8217;algorithme calcule alors une mesure de type cosinus entre les vecteurs, et retient le meilleur 
article, au sens de cette mesure de similarit&#233;. 
</p>
<p>2.2 Heuristiques utilis&#233;es dans notre approche 
Notre approche am&#233;liore celle pr&#233;sent&#233;e ci-dessus, avec deux diff&#233;rences. D&#8217;une part, nous 
avons ajout&#233; plusieurs heuristiques, afin d&#8217;augmenter la pr&#233;cision. D&#8217;autre part, nous 
appliquons ces heuristiques m&#234;me dans le cas o&#249; un seul synset de WordNet a un lemme &#233;gal 
au titre de l&#8217;article. Comme nous l&#8217;avons vu, la Wikipedia ne contient pas moins de vingt 
articles sur &#171; Abraham Lincoln &#187; ; cette d&#233;cision permet d&#8217;&#233;viter des appariements erron&#233;s. 
</p>
<p>Les heuristiques utilis&#233;es sont ind&#233;pendantes les unes des autres ; elles peuvent donc &#234;tre 
appliqu&#233;es dans n&#8217;importe quel ordre. Au d&#233;part, tous les synsets candidats partent avec un 
m&#234;me indice de confiance, qui est modifi&#233; durant l&#8217;application des heuristiques. Apr&#232;s cette 
&#233;tape, les synsets candidats qui disposent d&#8217;un poids manifestement trop faible pour 
correspondre &#224; l&#8217;article sont supprim&#233;s de la liste. Dans notre cas, nous avons d&#233;termin&#233; 
exp&#233;rimentalement un poids minimal de 0,6. Ensuite, on conserve les synsets dont l&#8217;indice de 
confiance vaut au moins 40% de celui du synset le mieux class&#233;. Ceci permet de supprimer 
les synsets non significatifs. 
</p>
<p>2.2.1 Distance vectorielle sur les mots 
Cette heuristique est identique &#224; celle d&#233;crite dans (Ruiz-Casado, Alfonseca, Castells, 2005). 
</p>
<p>2.2.2 Comparaisons des contextes (domaines implicites et noms propres) 
Nous extrayons du texte les domaines (&#171; biologie&#187;, &#171; sport &#187;&#8230;) &#233;ventuellement associ&#233;s &#224; 
chaque mot7, ainsi que les noms propres. Nous comparons la liste d&#8217;&#233;l&#233;ments extraits de 
l&#8217;article avec celle de chaque synset candidat, &#233;galement &#224; l&#8217;aide d&#8217;une mesure vectorielle. 
</p>
<p>5 Une version en anglais simplifi&#233; de la Wikipedia (http://simple.wikipedia.org). 
</p>
<p>6 Les auteurs revendiquent une pr&#233;cision de 91,11% (83.89% sur les mots polys&#233;miques). 
</p>
<p>7 WordNet associe parfois explicitement un domaine (baseball, g&#233;ologie, math&#233;matiques&#8230;) &#224; un synset. Dans 
cette &#233;tape, nous comptons les domaines associ&#233;s &#224; chaque sens possible d&#8217;un mot du contenu de l&#8217;article. 
</p>
<p>460</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Extraction de paraphrases d&#233;sambigu&#239;s&#233;es &#224; partir d&#8217;un corpus d&#8217;articles encyclop&#233;diques 
</p>
<p>2.2.3 Comparaison des domaines cit&#233;s explicitement dans le texte 
Cette heuristique recherche, dans une d&#233;finition, des patrons de la forme &#171; en
math&#233;matiques &#187;, &#171; utilis&#233; en g&#233;ologie &#187;&#8230; &#224; l&#8217;aide d&#8217;expressions r&#233;guli&#232;res. Si un patron de 
ce type est rep&#233;r&#233;, son domaine d&#8217;application est extrait (&#171; math&#233;matiques &#187; ou &#171; g&#233;ologie &#187; 
par exemple). Si le synset candidat (ou l&#8217;un de ses hyperonymes) appartient &#224; ce domaine, son 
indice de confiance est augment&#233;. 
</p>
<p>2.3 Comparaison des hyperonymes 
Cette heuristique a pour but de d&#233;terminer l&#8217;hyperonyme du sujet de l&#8217;article, en &#233;tudiant sa 
d&#233;finition. En voici quelques exemples, o&#249; les hyperonymes sont soulign&#233;s :  
</p>
<p>x Abraham Lincoln : 16&#232;me Pr&#233;sident des Etats-Unis.
</p>
<p>x Australie : un pays et le continent le plus petit.
</p>
<p>x chat : mammif&#232;re f&#233;lin ayant une &#233;paisse fourrure douce et incapable de rugir.
</p>
<p>Le ou les hyperonymes du sujet de l&#8217;article sont compar&#233;s aux hyperonymes des synsets 
candidats. S&#8217;ils sont suffisamment proches (au sens d&#8217;une mesure de similarit&#233;), l&#8217;indice de 
confiance est fortement augment&#233;. Cette heuristique est essentielle en termes d&#8217;am&#233;lioration 
de la pr&#233;cision de l&#8217;appariement ; c&#8217;est pourquoi elle est d&#233;taill&#233;e ici. 
</p>
<p>2.3.1 Analyse syntaxique de la d&#233;finition 
Notre but est d&#8217;extraire l&#8217;hyperonyme d&#8217;une d&#233;finition. Prenons l&#8217;exemple pr&#233;c&#233;dent du 
&#171; chat &#187; ; notre but est d&#8217;extraire &#171; mammif&#232;re &#187; (ou &#233;ventuellement &#171; mammif&#232;re f&#233;lin &#187;, si 
ce terme existe dans le lexique de r&#233;f&#233;rence)8.
</p>
<p>Nous effectuons pour cela une analyse syntaxique en profondeur de la d&#233;finition, en utilisant 
le Stanford Parser9 (Manning, Klein, 2002). Cet analyseur statistique fournit une sortie sous 
forme de d&#233;pendances syntaxiques.  
</p>
<p>Nous supposons que l&#8217;hyperonyme se situe dans la 1&#232;re phrase de l&#8217;article, qui tient le plus 
souvent lieu de d&#233;finition ; nous ne traitons donc que celle-ci. Comme une d&#233;finition se 
r&#233;sume souvent &#224; un groupe nominal, il convient de la modifier pour la rendre 
&#171; grammaticalement correcte &#187;. Notre exp&#233;rience montre que c&#8217;est indispensable dans le cas 
d&#8217;un analyseur bas&#233; sur des r&#232;gles comme le Link Grammar Parser (Sleator, Temperley, 
1991) et souhaitable dans le cas d&#8217;un analyseur statistique tel que le Stanford Parser. La 
premi&#232;re passe consiste donc en un &#233;tiquetage morphosyntaxique de la d&#233;finition ; ensuite, en 
fonction de la partie du discours (adjectif, nom, verbe, etc.) du premier mot, l&#8217;algorithme 
pr&#233;fixe &#233;ventuellement la d&#233;finition par &#171; c&#8217;est &#187; ou &#171; c&#8217;est un &#187;. 
</p>
<p>8 Si l&#8217;hyperonyme est qualifi&#233; par un adjectif ou un compl&#233;ment de nom, l&#8217;algorithme teste l&#8217;existence d&#8217;un 
synset constitu&#233; par l&#8217;expression compl&#232;te, de fa&#231;on &#224; &#234;tre le plus pr&#233;cis possible. 
</p>
<p>9 Composant Java t&#233;l&#233;chargeable sur http://nlp.stanford.edu/downloads/lex-parser.shtml. 
</p>
<p>461</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Fran&#231;ois-R&#233;gis CHAUMARTIN
</p>
<p>Figure 2 : Analyse syntaxique de la d&#233;finition (en anglais) du nom &#171; chat &#187; 
</p>
<p>2.3.2 Recherche de l&#8217;hyperonyme 
L&#8217;analyse syntaxique de la d&#233;finition est alors disponible sous forme d&#8217;un graphe de 
d&#233;pendances. Nous le transformons en clauses Prolog, &#224; partir desquelles nous pouvons 
identifier des sch&#233;mas (Chaumartin, 2006). 
</p>
<p>Le processus tient compte des conjonctions de coordination, afin d&#8217;extraire correctement les 
hyperonymes multiples comme dans &#171; l&#8217;Australie est un pays et le continent le plus petit &#187;. 
Dans une construction comme &#171; une esp&#232;ce de&#8230; &#187; ou &#171; un membre du groupe de&#8230; &#187;, nous 
remontons d&#8217;une fa&#231;on r&#233;cursive le long des constituants de l&#8217;amas nominal, en passant au 
constituant imbriqu&#233; suivant. 
</p>
<p>2.3.3 Cr&#233;ation de nouveaux synsets 
Si aucun synset de WordNet ne correspond &#224; l&#8217;article consid&#233;r&#233;, on en cr&#233;e un nouveau, dont 
la d&#233;finition sera la premi&#232;re phrase de l&#8217;article. Ensuite on le relie au synset repr&#233;sentant 
l&#8217;hyperonyme de l&#8217;article &#233;tudi&#233;. On est confront&#233; ici &#224; une probl&#233;matique de 
d&#233;sambigu&#239;sation lexicale, pour identifier le sens correct. Par exemple, si l&#8217;hyperonyme est 
&#171; empereur &#187;, il faut choisir entre les sens &#171; dirigeant m&#226;le d&#8217;un empire &#187;,  &#171; raisin rouge de 
Californie &#187; ou &#171; grand papillon richement color&#233; &#187;.
</p>
<p>Les hyponymes du meilleur anc&#234;tre se situent au m&#234;me niveau que le sujet de l&#8217;article dans la 
hi&#233;rarchie de WordNet. Nous cherchons donc des points communs entre l&#8217;article et ses 
&#171; cousins &#187; potentiels. Nous commen&#231;ons par relever les similarit&#233;s au niveau du vocabulaire 
employ&#233; entre l&#8217;article et chacun des hyponymes de ses anc&#234;tres possibles ; en effet, des 
articles ayant le m&#234;me hyperonyme ont une forte probabilit&#233; de traiter de sujets voisins, et 
donc de partager un champ lexical. 
</p>
<p>Pour finir, nous appliquons deux heuristiques suppl&#233;mentaires. Tout hyperonyme candidat 
d&#8217;une entit&#233; nomm&#233;e (personne, lieu, etc.) voit son indice de confiance augment&#233; si :  
</p>
<p>x Il en d&#233;coule des relations de type &#171; instance hyponyme &#187;. 
</p>
<p>x Il h&#233;rite d&#8217;un groupe social (&#171; entreprise &#187;, &#171; organisation &#187;, &#171; mouvement &#187;&#8230;). 
</p>
<p>2.4 R&#233;sultats obtenus pour l&#8217;appariement d&#8217;articles 
</p>
<p>La version de mars 2006 de la Wikipedia en anglais (1 005 682 articles) a &#233;t&#233; filtr&#233;e pour 
retenir 15 847 articles, dont le titre &#233;tait &#233;galement pr&#233;sent dans une autre encyclop&#233;die de 
</p>
<p>462</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Extraction de paraphrases d&#233;sambigu&#239;s&#233;es &#224; partir d&#8217;un corpus d&#8217;articles encyclop&#233;diques 
</p>
<p>r&#233;f&#233;rence. Ces articles ont &#233;t&#233; appari&#233;s automatiquement sur WordNet. Pour &#233;valuer la 
pr&#233;cision de l&#8217;appariement, nous avons examin&#233; manuellement le r&#233;sultat sur 800 articles : 
</p>
<p>x 505 ont &#233;t&#233; associ&#233;s &#224; un synset existant d&#233;j&#224; dans WordNet ; l&#8217;appariement a &#233;t&#233; 
fait correctement dans 465 cas (soit une pr&#233;cision de 92%). 
</p>
<p>x 295 nouveaux synset ont &#233;t&#233; cr&#233;es ; l&#8217;hyperonyme a &#233;t&#233; correctement identifi&#233; dans 
251 cas (soit une pr&#233;cision de 85%). 
</p>
<p>2.5 Bilan : constitution d&#8217;un corpus monolingue d&#8217;articles comparables 
</p>
<p>En r&#233;p&#233;tant le processus pr&#233;c&#233;dent sur plusieurs sources encyclop&#233;diques, nous pouvons 
rattacher plusieurs articles &#224; un m&#234;me synset, et obtenir un corpus d&#8217;articles comparables. 
</p>
<p>Figure 3 : Trois articles en anglais portant sur la rivi&#232;re Alabama ; les entit&#233;s nomm&#233;es sont 
surlign&#233;es dans une m&#234;me couleur (un module de r&#233;solution d&#8217;anaphores a &#233;t&#233; appliqu&#233;) 
</p>
<p>3 Extraction de paraphrases d&#233;sambigu&#239;s&#233;es 
</p>
<p>3.1 Objectif
L&#8217;apprentissage automatique de paraphrases peut se faire sur la base de textes align&#233;s ou 
comparables. (Ibrahim, Katz, Lin, 2003) d&#233;crivent ainsi l&#8217;utilisation de plusieurs traductions 
diff&#233;rentes, en anglais, d&#8217;&#339;uvres litt&#233;raires (par exemple 20 000 lieues sous les mers), et 
am&#233;liore l&#8217;approche de (Lin, Pantel, 2001) traitant de corpus comparables. L&#8217;algorithme mis 
en &#339;uvre consiste &#224; effectuer une analyse syntaxique de deux textes, et &#224; identifier le plus 
court chemin, dans chaque graphe de d&#233;pendance, entre deux ancres (des entit&#233;s nomm&#233;es). 
</p>
<p>Nous appliquons une technique voisine sur des paires d&#8217;articles portant sur le m&#234;me sujet. 
Notre objectif est de constituer un catalogue de paraphrases dont les &#233;l&#233;ments sont totalement 
d&#233;sambigu&#239;s&#233;s par rapport &#224; WordNet. 
</p>
<p>463</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Fran&#231;ois-R&#233;gis CHAUMARTIN
</p>
<p>3.2 Traitement unitaire d&#8217;un article 
Notre algorithme commence par traiter chaque article s&#233;par&#233;ment, avec les &#233;tapes 
suivantes10 : 
</p>
<p>x Analyse syntaxique profonde du texte. Nous obtenons un ensemble de d&#233;pendances o&#249; 
les constructions de syntaxe de surface (sujet invers&#233;&#8230;) sont gomm&#233;es. 
</p>
<p>x R&#233;solution des anaphores pronominales (notre exp&#233;rience montre que dans le cas de 
textes encyclop&#233;diques, elles concernent g&#233;n&#233;ralement le sujet de l&#8217;article). 
</p>
<p>x Identification des entit&#233;s nomm&#233;es, autres que le sujet de l&#8217;article, et cit&#233;es une seule 
fois (donc sans reprise anaphorique). Pour chacune de ces entit&#233;s nomm&#233;es : 
</p>
<p>o D&#233;sambigu&#239;sation lexicale (par rapport &#224; WordNet). 
o Recherche du (ou des) chemin(s) la reliant au sujet de l&#8217;article, dans le graphe 
</p>
<p>de syntaxe profonde. 
</p>
<p>En partant de l&#8217;article de la Wikipedia sur la rivi&#232;re Alabama, nous obtenons ainsi des triplets 
de la forme (sujet, verbe, compl&#233;ment), o&#249; le sujet et le compl&#233;ment sont d&#233;j&#224; d&#233;sambigu&#239;s&#233;s : 
(RIVI&#200;RE COOSA, former, RIVI&#200;RE ALABAMA), (RIVI&#200;RE TALLAPOOSA, former, RIVI&#200;RE 
ALABAMA), (RIVI&#200;RE ALABAMA, couler, VILLE SELMA), (RIVI&#200;RE ALABAMA, unir, RIVI&#200;RE 
TOMBIGBEE), (RIVI&#200;RE ALABAMA, former, RIVI&#200;RE MOBILE)&#8230;
</p>
<p>De m&#234;me, un article d&#8217;une autre encyclop&#233;die, traitant &#233;galement de la rivi&#232;re Alabama, 
fournit : (RIVI&#200;RE TALLAPOOSA, former, RIVI&#200;RE ALABAMA), (RIVI&#200;RE COOSA, former, RIVI&#200;RE 
ALABAMA), (RIVI&#200;RE ALABAMA, serpenter, VILLE SELMA), (RIVI&#200;RE TOMBIGBEE, rejoindre,
RIVI&#200;RE ALABAMA), (RIVI&#200;RE ALABAMA, former, RIVI&#200;RE MOBILE)&#8230;
</p>
<p>3.3 Rapprochement des informations entre paires d&#8217;articles 
Nous pouvons rapprocher ces informations. Sans les triplets identiques, il reste (RIVI&#200;RE 
ALABAMA, couler, VILLE SELMA) ~ (RIVI&#200;RE ALABAMA, serpenter, VILLE SELMA) et (RIVI&#200;RE 
ALABAMA, unir, RIVI&#200;RE TOMBIGBEE) ~ (RIVI&#200;RE TOMBIGBEE, rejoindre, RIVI&#200;RE ALABAMA).
Les entit&#233;s nomm&#233;es sont d&#233;j&#224; d&#233;sambigu&#239;s&#233;es ; connaissant leurs hyperonymes, nous 
pouvons donc r&#233;&#233;crire ces paraphrases au niveau des classes plut&#244;t que des instances : 
</p>
<p>x (RIVI&#200;RE#1 riv1, couler, VILLE#1 v1) ~ (RIVI&#200;RE#1 riv1, serpenter, VILLE#1 v1) 
x (RIVI&#200;RE#1 riv1, unir, RIVI&#200;RE#1 riv2) ~ (RIVI&#200;RE#1 riv2, rejoindre, RIVI&#200;RE#1 riv1). 
</p>
<p>3.4 D&#233;finition d&#8217;une mesure de similarit&#233; sur les verbes 
Il nous reste &#224; d&#233;terminer le sens de chacun des deux verbes dans la paire de triplets. Nous 
utilisons pour cela une mesure de similarit&#233;, qui exploite la hi&#233;rarchie de verbes de WordNet. 
Partant de l&#8217;hypoth&#232;se que les deux verbes doivent avoir un sens proche l&#8217;un de l&#8217;autre, nous 
</p>
<p>10 La cha&#238;ne de traitement utilis&#233;e est Antelope (t&#233;l&#233;chargeable sur http://www.proxem.com). 
</p>
<p>464</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Extraction de paraphrases d&#233;sambigu&#239;s&#233;es &#224; partir d&#8217;un corpus d&#8217;articles encyclop&#233;diques 
</p>
<p>cherchons la combinaison de sens qui minimise leur distance, au sens d&#8217;une telle mesure. De 
nombreux auteurs ont propos&#233; des d&#233;finitions de mesures de similarit&#233;, et plusieurs 
impl&#233;mentations bas&#233;es sur WordNet sont disponibles11. Par exemple, (Lin, 1998) d&#233;finit 
comme mesure de similarit&#233; entre deux synsets s1 et s2 :
</p>
<p>sim(s1, s2) = (2 . log P(s)) / (log P(s1) + log P(s2))  
</p>
<p>o&#249; s est le synset le plus sp&#233;cifique subsumant les synset s1 et s2 dans la hi&#233;rarchie de 
WordNet, et o&#249; P(s) repr&#233;sente la fr&#233;quence du synset s obtenue &#224; partir d&#8217;un corpus de 
r&#233;f&#233;rence (le SemCor en l&#8217;occurrence). 
</p>
<p>Nous avons impl&#233;ment&#233; une mesure de ce type, en introduisant deux niveaux suppl&#233;mentaires 
en plus de la hi&#233;rarchie de WordNet. En effet, la qualit&#233; de la mesure de similarit&#233; est 
fonction de la finesse de la hi&#233;rarchie. De fa&#231;on &#224; rendre tous les verbes comparables, nous 
avons cr&#233;&#233; un pseudo-synset qui sert de racine commune &#224; tous les verbes. Nous avons 
&#233;galement intercal&#233;, entre cette racine et les verbes, des pseudo-synsets regroupant les 
cat&#233;gories lexicales (verbes de mouvement, verbes d&#8217;&#233;tat, verbes de changement&#8230;). 
</p>
<p>3.5 Application de cette mesure de similarit&#233; aux verbes des paraphrases 
Nous appliquons cette mesure de similarit&#233; &#224; toutes les combinaisons de sens de &#171; couler &#187; et 
&#171; serpenter &#187;, d&#8217;une part, et d&#8217; &#171; unir &#187; et &#171; rejoindre &#187;, d&#8217;autre part. Nous obtenons alors, 
comme combinaison minimisant la distance entre les paires de verbes : 
</p>
<p>x (RIVI&#200;RE#1 riv1, COULER#2, VILLE#1 v1) ~ (RIVI&#200;RE#1 riv1, SERPENTER#1, VILLE#1 v1) 
x (RIVI&#200;RE#1 riv1, UNIR#4, RIVI&#200;RE#1 riv2) ~ (RIVI&#200;RE#1 riv2, REJOINDRE#5, RIVI&#200;RE#1 riv1). 
</p>
<p>3.6 Bilan
Ce processus permet d&#8217;obtenir automatiquement des paires de cadres de sous-cat&#233;gorisation, 
dont les &#233;l&#233;ments sont totalement d&#233;sambigu&#239;s&#233;s par rapport &#224; WordNet. Nos premi&#232;res 
&#233;valuations pr&#233;liminaires (effectu&#233;es sur une dizaine d&#8217;articles) montrent une pr&#233;cision de 
l&#8217;ordre de 70% dans la d&#233;tection de paraphrases pertinentes.
</p>
<p>Une premi&#232;re passe, sur l&#8217;ensemble des articles de l&#8217;encyclop&#233;die portant sur une m&#234;me 
cat&#233;gorie, permet de compter la fr&#233;quence de chaque construction particuli&#232;re. 
</p>
<p>Il est alors possible de fixer un seuil minimal en dessous-duquel la construction n&#8217;est pas 
retenue ; ce m&#233;canisme est important pour compenser les erreurs ayant pu subvenir lors de 
l&#8217;application de la cha&#238;ne de traitement (durant les phases d&#8217;analyse syntaxique, de 
d&#233;sambigu&#239;sation lexicale des entit&#233;s nomm&#233;es ou de r&#233;solution d&#8217;anaphores). Si une m&#234;me 
construction se retrouve un grand nombre de fois, elle est probablement correcte. 
</p>
<p>Ces cadres de sous-cat&#233;gorisations fournissent par la suite, lors d&#8217;une seconde passe de 
traitement, de puissants indices de d&#233;sambigu&#239;sation lexicale et syntaxique. 
</p>
<p>11 Par exemple, WordNet::Similarity (t&#233;l&#233;chargeable sur http://www.d.umn.edu/~tpederse/similarity.html). 
</p>
<p>465</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Fran&#231;ois-R&#233;gis CHAUMARTIN
</p>
<p>4 Conclusion
Cet article montre qu&#8217;il est possible d&#8217;enrichir automatiquement WordNet &#224; partir d&#8217;une ou 
plusieurs encyclop&#233;dies. Nous projetons d&#8217;utiliser le m&#234;me m&#233;canisme pour importer des 
dictionnaires sp&#233;cialis&#233;s (en informatique, en droit et en m&#233;decine). Le fait de disposer de 
plusieurs textes, portant sur un m&#234;me sujet, permet d&#8217;extraire automatiquement des 
paraphrases ; leurs constituants sont compl&#232;tement identifi&#233;s, ce qui permet, dans une seconde 
passe, d&#8217;am&#233;liorer la d&#233;sambigu&#239;sation lexicale des textes. Dans le cadre du projet en cours 
ISIDORE, il reste &#224; mettre en &#339;uvre ces m&#233;canismes sur un volume significatif d&#8217;articles, 
pour affiner notre jugement sur la validit&#233; de cette approche. 
</p>
<p>Remerciements
Je remercie Sylvain Kahane (Paris 10) pour ses conseils, et Benjamin Surma et Ricardo 
Minhoto pour leur participation au projet dans le cadre de leur m&#233;moire d&#8217;ing&#233;nieur ENSIIE. 
</p>
<p>R&#233;f&#233;rences
CARR&#201; R., D&#201;GREMONT J.F., GROSS M., PIERREL J.M., SABAH G. (1991), Langage humain et 
machine. Presses du CNRS. 
CHAUMARTIN F. (2006) Construction automatique d&#8217;interface syntaxe-s&#233;mantique utilisant 
des ressources de large couverture en langue anglaise. Actes de TALN 2006, 729-735. 
IBRAHIM A., KATZ B., LIN J. (2003) Extracting Structural Paraphrases from Aligned 
Monolingual Corpora. Actes de Second International Workshop on Paraphrasing.
LIN D. (1998). An information-theoretic definition of similarity. Actes de 15th International 
Conf. on Machine Learning, 296&#8211;304. 
LIN D., PANTEL D. (2001) DIRT - Discovery of Inference Rules from Text. Actes de ACM
SIGKDD Conference on Knowledge Discovery and Data Mining.
MANNING C., KLEIN D. (2002). Fast Exact Inference with a Factored Model for Natural 
Language Parsing. Advances in Neural Information Processing Systems 15 (NIPS 2002). 
MILLER G. (1995) WordNet: A lexical database. Actes de ACM 38, 39-41. 
RESNIK P. (1995) Using Information Content to evaluate semantic similarity in a taxonomy. 
Actes de IJCAI-95, 448&#8211;453. 
RUIZ-CASADO M., ALFONSECA E., CASTELLS P. (2005) Automatic assignment of 
Wikipedia encyclopedic entries to WordNet synsets. Actes de AWIC, 380-386. 
SLEATOR D., TEMPERLEY D. (1991) Parsing English with a Link Grammar. Actes de Third
International Workshop on Parsing Technologies.
</p>
<p>466</p>

</div></div>
</body></html>