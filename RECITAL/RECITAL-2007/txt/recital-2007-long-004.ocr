RECITAL 2007, Toulouse, 5—8juin 2007

Extraction de paraphrases désambiguisées it partir d’un corpus
d’articles encyclopédiques alignés automatiquement

Francois-Régis CHAUMARTIN
Lattice/Talana — Université Paris 7

30 rue du chateau des rentiers, 75013 Paris
fchaumartin@linguist.jussieu.fr, frc@proxem.com

Résumé. Nous decrivons ici comment enrichir automatiquement WordNet en y important
des articles encyclopédiques. Ce processus permet de creer des nouvelles entrees, en les
rattachant au bon hyperonyme. Par ailleurs, les entre'es pre'existantes de WordNet peuvent étre
enrichies de descriptions comple'mentaires. La repetition de ce processus sur plusieurs
encyclopedies permet de constituer un corpus d’articles comparables. On peut ensuite extraire
automatiquement des paraphrases a partir des couples d’articles ainsi crees. Grace a
l’application d’une mesure de similarite, utilisant la hierarchie de Verbes de WordNet, les
constituants de ces paraphrases peuvent étre desambiguises.

Abstract. We describe here how to automatically import encyclopedic articles into
WordNet. This process makes it possible to create new entries, attached to their appropriate
hypernym. In addition, the preexisting entries of WordNet can get enriched with
complementary descriptions. Reiterating this process on several encyclopedias makes it
possible to constitute a corpus of comparable articles; we can then automatically extract
paraphrases from the couples of articles that have been created. The paraphrases components
can ﬁnally be disambiguated, by means of a similarity measure (using the Verbs WordNet
hierarchy).

Mots-clés I extraction de paraphrases, fusion d’articles, mesure de similarite, distance
semantique, identiﬁcation d’hyperonyme, WordNet, Wikipedia, entites nommees, analyse
syntaxique, de'sambigu‘1‘sation lexicale, cadres de sous-categorisation, apprentissage.
Keywords: paraphrases extraction, articles merging, similarity measure, semantic

distance, hypernym identiﬁcation, WordNet, Wikipedia, named entities, syntactic analysis,
word sense disambiguation, syntactic frames, unsupervised learning.

1 Introduction
1.1 Architecture d’ensemble

Nous souhaitons disposer d’une correspondance directe entre les articles d’une encyclopedie
et les entrees d’un lexique se'mantique de reference. Deux cas de ﬁgure se rencontrent alors ;

457

Francois-Regis CHAUMARTIN

quand une entree de lexique correspond de'ja a un article, nous e'tablissons la correspondance
entre les deux; sinon, nous enrichissons le lexique, en cre'ant une nouvelle entree et en la
rattachant (Via une relation d’hyperonymie/hyponymie) au meilleur « ancétre » existant.

En re'ite'rant ce processus sur plusieurs encyclopedies, nous obtenons un corpus monolingme
de paires d’articles traitant d’un meme sujet, propice a la de'couVerte de paraphrases. Nous
pouvons alors determiner, par exemple, que « la riviére Alabama serpentejusqz/a Selma »
est une paraphrase de « la riviére Alabama coule vers Selma ». Nous repre'sentons les
paraphrases sous forme de triplets (sujet, Verbe, complement). La desambigiisation des
entites nommees permet d’etablir que « RIVIERE#1 serpente (preposition) VILLE#1» est une
paraphrase de « RIVIERE#1 coule (preposition) VILLE#1 ». (L’indice #,- indique le sens du mot
dans le lexique.) L’utilisation d’une mesure de similarite entre les deux Verbes permet enﬁn
de de'terminer les sens de « serpenter » et « couler » dans le contexte. Nous obtenons, au ﬁnal,
l’e'quiValence entre deux cadres de sous-categorisation, dont les elements sont desambiguises
par rapport au lexique : SERPENTER#1 (RIVIERE#1, VILLE#1) ~ COULER#2 (RIVIl3RE#1, VILLE#1).

Ces operations constituent les deux premieres e'tapes du projet ISIDORE1, qui Vise a extraire

des connaissances d’une encyclopedie en langue anglaise. Pour faciliter la lecture, les
exemples cite's ici ont e'te traduits en francais.

0 .
Encylclnpédii 1 \\ Ensemble de connaissances

Encyclapédie 2 ,\,
“ 9
= %

;

E

 

at
Figure 1 : architecture d’ensemble du projet ISIDORE

1.2 Lexique de référence

Notre lexique de reference est WordNet (Miller, 1995) Version 2.1. Ce projet, mene' depuis
1985 a Princeton, offre un reseau semantique tres complet de la langme anglaise. S’il n’est pas
exempt de critiques (granularite tres ﬁne, absence de relations paradigmatiques. . .), WordNet
n’en reste pas moins l’une des ressources de TAL2 les plus populaires.

Les noeuds sont constitue's par des ensembles de synonymes (ou synsets), correspondant au
sens d’un ou plusieurs lemmes. Un synset est de'ﬁni d’une facon differentielle par les relations
qu'il entretient avec les sens Voisins. Par exemple, des relations d’hyperonymie et
d’hyponymie relient les « ancetres » des noms et des Verbes avec leurs « specialisations ». La
Version 2.1 a de plus introduit la notion d’ « instance hyponyme », qui designe une instance

1 St-Isidore (560-636), patron des informaticiens, fut l’auteur des Etymologies, une encyclopédje en 20 livres.

2 WordNet est téléchargeable sur http://wordnetprinceton.edu.

458

Extraction de paraphrases desambiguisees a partir d’un corpus d’articles encyclopediques

(typiquement une entite nommee) d’un synset, et non une sous-classe. Ainsi, le nom TOUR#1 a
SILO#1, MINARET#1, PHARE#1, .. pour hyponymes, et TOUR EIFFEL #1 comme instance hyponyme.

2 Importation d’articles encyclopédiques dans WordNet

L’encyclopedie en ligne Wikipeclia possede une Vingtaine d’articles dont le titre contient (au
moins partiellement) «Abraham Lincoln » :

. «Abraham Lincoln » .' l’homme politique, l6éme President des Etats-Unis.
. «Abraham Lincoln assassination » : l’assassinat de l’homme politique.
. «Abraham Lincoln (Pullman car) » : le plus ancien wagon de passagers des Etats-Unis.

-l>UJI\)>—‘

. Sans oublier deux ﬁlms biographiques, trois lieux geographiques, plusieurs ecoles, deux
Vaisseaux militaires, .. egalement nommes en memoire de l’homme politique.

Nous constatons donc qu’une similarite entre le titre d’un article et un lemme (ou groupe de
mots) designant un synset de WordNet ne sufﬁt pas a deduire qu’ils traitent du meme sujet.

Nous cherchons a identiﬁer le (ou les) synset de WordNet auquel un article se rattache. Pour
ce faire, nous commencons par extraire de WordNet les « synsets candidats » pouvant
correspondre au titre de l’article. Cette etape ne pose pas de difﬁculte particuliere. Pour les
personnes, par exemple, chaque article possede un ou plusieurs titres normalises (de la forme
« Prenom Nom» ou « Nom, Prenom»). ll sufﬁt de rechercher les synsets correspondants
dans WordNet. Pour un nom commun, il est necessaire de tenir compte d’eVentuelles
Variantes morphologiques et de retrouver la forme de base du mot. Nous appliquons alors un
ensemble d’heuristiques3 pour retenir le meilleur candidat. S’il n’en existe pas, nous
commencons par chercher le synset correspondant le mieux au theme de l’article (decrit-il une
riviere, un president... ?) Ensuite, nous creons un nouveau synset, rattache (en tant
qu’hyponyme ou instance hyponyme) au synset du theme de l’article.

Dans l’uniVers du traitement automatise des encyclopedies, la Wikipedia pose un probleme
particulier. Pouvant etre modiﬁee par tout intemaute, elle Voit depuis plusieurs annees une
progression exponentielle de son nombre d’entrees4 : certain articles ne sont que des
biographies auto-promotionnelles, d’autres des comptes-rendus de ﬁlms ou de jeux Video...
Notre choix est de ne retenir que les entrees correspondant a un consensus en termes de
connaissances encyclopediques. Nous travaillons donc sur un sous-ensemble des articles de la
Wikipedia recoupant (sur la base du titre) ceux d’une autre encyclopedie de reference.

3 (Carre, Degremont, Gross, Pierre], Sabah, 1991) deﬁnit (p. 48) une heuristique comme « une régle qu’on a
interet £1 utiliser en general, parce qu’on sait qu’elle conduit souvent 21 la solution, bien qu’on n’ait aucune
certitude sur sa validite dans tous les cas ».

41539 908 ﬁn 2006; 874 359 ﬁn 2005 ;414 023 ﬁn 2004; 188 538 ﬁn 2003 ; 95 735 ﬁn 2002.

459

Francois-Regis CHAUMARTIN

2.1 Autre projet similaire

(Ruiz-Casado, Alfonseca, Castells, 2005) presentent l’implementation d’un algorithme rapide
perrnettant de realiser la correspondance entre un article de la Simple Wikipedia5 et le synset
correspondant de WordNet6. Si aucun synset n’a de lemme en commun avec le titre de
l’article, ce dernier est ignore. Si un seul synset de WordNet a un lemme egal au titre, l’article
y est lie sans autre analyse. En cas d’ambigu‘1‘te, l’article fait l’objet d’un etiquetage
morphosyntaxique (apres un ﬁltrage des marqueurs syntaxiques speciﬁques a la Wikipedia),
pour ne conserver que les noms, Verbes et adjectifs. Le systeme analyse les deﬁnitions de
WordNet, et construit pour chacune d’entre elles un Vecteur booleen (contenant « 1 » pour
chaque terme en commun avec l’article et « 0 » pour chaque mot en disjonction).
L’algorithme calcule alors une mesure de type cosinus entre les Vecteurs, et retient le meilleur
article, au sens de cette mesure de similarite.

2.2 Heuristiques utilisées dans notre approche

Notre approche ameliore celle presentee ci-dessus, avec deux differences. D’une part, nous
avons ajoute plusieurs heuristiques, aﬁn d’augmenter la precision. D’autre part, nous
appliquons ces heuristiques meme dans le cas ou un seul synset de WordNet a un lemme egal
au titre de l’article. Comme nous l’aVons Vu, la Wikipedia ne contient pas moins de Vingt
articles sur «Abraham Lincoln » ; cette decision permet d’eViter des appariements errones.

Les heuristiques utilisees sont independantes les unes des autres; elles peuvent donc étre
appliquees dans n’importe quel ordre. Au depart, tous les synsets candidats partent avec un
meme indice de conﬁance, qui est modiﬁe durant l’application des heuristiques. Apres cette
etape, les synsets candidats qui disposent d’un poids manifestement trop faible pour
correspondre a l’article sont supprimes de la liste. Dans notre cas, nous avons determine
experimentalement un poids minimal de 0,6. Ensuite, on conserve les synsets dont l’indice de
conﬁance Vaut au moins 40% de celui du synset le mieux classe. Ceci permet de supprimer
les synsets non signiﬁcatifs.

2.2.1 Distance vectorielle sur les mots

Cette heuristique est identique a celle decrite dans (Ruiz-Casado, Alfonseca, Castells, 2005).

2.2.2 Comparaisons des contextes (domaines implicites et noms propres)

Nous extrayons du texte les domaines (« biologie», « sport »...) eventuellement associes a
chaque mot7, ainsi que les noms propres. Nous comparons la liste d’elements extraits de
l’article avec celle de chaque synset candidat, egalement a l’aide d’une mesure Vectorielle.

5 Une version en anglais simpliﬁe de la Wikipedia (http://simple.wikipedia.org).
5 Les auteurs revendiquent une precision de 91,1l% (83.89% sur les mots polysemiques).

7 WordNet associe parfois explicitement un domaine (baseball, geologie, mathematiques...) £1 un synset. Dans
cette etape, nous comptons les domaines associes £1 chaque sens possible d’un mot du contenu de l’article.

460

Extraction de paraphrases de'sambigu‘1‘sees a partir d’un corpus d’artic1es encyclopediques

2.2.3 Comparaison des domaines cités explicitement dans le tercte

Cette heuristique recherche, dans une deﬁnition, des patrons de la forme « en
mathématiques », « utilise en géologie >>... a 1’aide d’expressions re'gu1ieres. Si un patron de
ce type est repere, son domaine d’application est extrait (« mathematiques » ou « geologie »
par exemple). Si le synset candidat (ou 1’un de ses hyperonymes) appartient a ce domaine, son
indice de conﬁance est augmente'.

2.3 Comparaison des hyperonymes

Cette heuristique a pour but de determiner 1’hyperonyme du sujet de 1’artic1e, en etudiant sa
deﬁnition. En Voici quelques exemples, ou les hyperonymes sont soulignes :

0 Abraham Lincoln : 16”“ President des Etats- Unis.
0 Australie : un gays et le continent le plus petit.
0 chat : mammifere [elin ayant une epaissefourrure douce et incapable de rugir.

Le ou les hyperonymes du sujet de 1’artic1e sont compares aux hyperonymes des synsets
candidats. S’i1s sont sufﬁsamment proches (au sens d’une mesure de simi1arite'), 1’indice de
conﬁance est fortement augmente. Cette heuristique est essentielle en termes d’ame'1ioration
de la precision de l’appariement ; c’est pourquoi elle est detaillee ici.

2.3.1 Analyse syntaxique de la définition

Notre but est d’extraire 1’hyperonyme d’une deﬁnition. Prenons 1’exemp1e precedent du
« chat» ; notre but est d’extraire « mammifere » (ou eventuellement « mammiferefélin », si
ce terme existe dans le lexique de re'fe'rence)8.

Nous effectuons pour cela une analyse syntaxique en profondeur de la deﬁnition, en utilisant
le Stanford Parser9 (Manning, Klein, 2002). Cet analyseur statistique fournit une sortie sous
forme de de'pendances syntaxiques.

Nous supposons que 1’hyperonyme se situe dans la la" phrase de 1’artic1e, qui tient le plus
souvent lieu de de'ﬁnition; nous ne traitons donc que celle-ci. Comme une deﬁnition se
resume souvent a un groupe nominal, il convient de la modiﬁer pour la rendre
« grammaticalement correcte ». Notre expe'rience montre que c’est indispensable dans le cas
d’un analyseur base sur des regles comme 1e Link Grammar Parser (Sleator, Temperley,
1991) et souhaitable dans le cas d’un analyseur statistique tel que le Stanford Parser. La
premiere passe consiste donc en un e'tiquetage morphosyntaxique de la deﬁnition ; ensuite, en
fonction de la partie du discours (adjectif, nom, Verbe, etc.) du premier mot, 1’a1gorithme
preﬁxe eventuellement la deﬁnition par « c ’est » ou « c ’est un ».

3 Si l’hyperonyme est qualiﬁe par un adjectif ou un complement de nom, l’algorithme teste l’existence d’un
synset constitue par l’expression complete, de facon £1 etre le plus precis possible.

9 Composant Java telechargeable sur http://nlp.stanford.edu/downloads/lex-parser.shtml.

461

Francois-Regis CHAUMARTIN

    

  
     
 

 

4amod <adumod

[M E

<det h]rtmod>

<nSUh]

conj>

Figure 2 : Analyse syntaxique de la deﬁnition (en anglais) du nom « chat »

2.3.2 Recherche de I ’hyper0nyme

L’analyse syntaxique de la deﬁnition est alors disponible sous forme d’un graphe de
de'pendances. Nous le transformons en clauses Prolog, a partir desquelles nous pouvons
identiﬁer des sche'mas (Chaumartin, 2006).

Le processus tient compte des conjonctions de coordination, aﬁn d’extraire correctement les
hyperonymes multiples comme dans « l’Australie est un ﬂhs et le continent le plus petit ».
Dans une construction comme « une espece de... » ou « un membre du groupe de... », nous
remontons d’une facon recursive le long des constituants de l’amas nominal, en passant au
constituant imbrique suiVant.

2.3.3 Creation de nouveaux synsets

Si aucun synset de WordNet ne correspond a l’article considéré, on en cree un nouveau, dont
la deﬁnition sera la premiere phrase de l’article. Ensuite on le relie au synset representant
l’hyperonyme de l’article e'tudie. On est confronte' ici a une problématique de
desambigmisation lexicale, pour identiﬁer le sens correct. Par exemple, si l’hyperonyme est
« empereur », il faut choisir entre les sens « dirigeant male d’un empire », « raisin rouge de
Californie » ou « grandpapillon richement coloré ».

Les hyponymes du meilleur ancétre se situent au meme niveau que le sujet de l’article dans la
hie'rarchie de WordNet. Nous cherchons donc des points communs entre l’article et ses
« cousins » potentiels. Nous commencons par releVer les similarites au niveau du Vocabulaire
employe' entre l’article et chacun des hyponymes de ses ancétres possibles; en effet, des
articles ayant le meme hyperonyme ont une forte probabilité de traiter de sujets Voisins, et
donc de partager un champ lexical.

Pour ﬁnir, nous appliquons deux heuristiques supplementaires. Tout hyperonyme candidat
d’une entite nommée (personne, lieu, etc.) Voit son indice de conﬁance augmente si :

0 11 en découle des relations de type « instance hyponyme ».

0 ll herite d’un groupe social (« entreprise », « organisation », « mouvement », . .).
2.4 Résultats obtenus pour Pappariement d’articles
La Version de mars 2006 de la Wikipedia en anglais (1 005 682 articles) a ete ﬁltree pour

retenir 15 847 articles, dont le titre e'tait également present dans une autre encyclopedie de

462

Extraction de paraphrases desambiguisees a partir d’un corpus d’articles encyclopediques
reference. Ces articles ont e'te apparies automatiquement sur WordNet. Pour evaluer la
precision de l’appariement, nous avons examine manuellement le resultat sur 800 articles :

0 505 ont ete associes a un synset existant deja dans WordNet ; l’appariement a ete
fait correctement dans 465 cas (soit une precision de 92%).

0 295 nouveaux synset ont ete crees ; l’hyperonyme a e'te correctement identiﬁe dans
251 cas (soit une precision de 85%).
2.5 Bilan : constitution d’un corpus monolingue d’articles comparables

En re'pe'tant le processus precedent sur plusieurs sources encyclopediques, nous pouvons
rattacher plusieurs articles a un meme synset, et obtenir un corpus d’articles comparables.

Encyclopédie 3

is The is a
and river, 315 mi long, formed in
rivers northeast central Alaska by the

confluence of the 2

rivers north

Wikipedia Encyclopédie 2

    
 
   
 
 

and 2 rivers, which
unite six miles above The winds _
. The ‘ westward to and of
flows west as far as then flows south for a length Flowing southwest to
, then southwest until, of 318 mi.
about 45 miles from Mobile. The — is joined joins the
' above Mobile by the ' form the
to form Tvisnnloig  to form the

   
      
   
  
 

  
   

Tensaw and ,
rivers, which discharge into which flow into the Gulf of
Mobile Bay. Mexico.

F iglre 3 : Trois articles en anglais portant sur la riviere Alabama ; les entites nommees sont
surlignees dans une meme couleur (un module de resolution d’anaphores a e'te applique)

3 Extraction de paraphrases désambiguisées

3.1 Objectif

L’apprentissage automatique de paraphrases peut se faire sur la base de textes alignes ou
comparables. (Ibrahim, Katz, Lin, 2003) decrivent ainsi l’utilisation de plusieurs traductions
differentes, en anglais, d’oeuVres litteraires (par exemple 20 000 lieues sous les mers), et
ameliore l’approche de (Lin, Pantel, 2001) traitant de corpus comparables. L’algorithme mis
en oeuvre consiste a effectuer une analyse syntaxique de deux textes, et a identiﬁer le plus
court chemin, dans chaque graphe de de'pendance, entre deux ancres (des entites nommees).

Nous appliquons une technique Voisine sur des paires d’articles portant sur le meme sujet.

Notre objectif est de constituer un catalogue de paraphrases dont les elements sont totalement
desambigiises par rapport a WordNet.

463

Francois-Regis CHAUMARTIN

3.2 Traitement unitaire d’un article

Notre algorithme commence par traiter chaque article separement, avec les etapes
suivanteslo :

0 Analyse syntaxique profonde du texte. Nous obtenons un ensemble de dependances ou
les constructions de syntaxe de surface (sujet inverse...) sont gommees.

0 Resolution des anaphores pronominales (notre experience montre que dans le cas de
textes encyclopediques, elles concernent ge'ne'ralement le sujet de l’article).

0 Identiﬁcation des entites nomme'es, autres que le sujet de l’article, et citees une seule
fois (donc sans reprise anaphorique). Pour chacune de ces entites nommees :

o De'sambigu‘1‘sation lexicale (par rapport a WordNet).

o Recherche du (ou des) chemin(s) la reliant au sujet de l’article, dans le graphe
de syntaxe profonde.

En partant de l’article de la Wikipedia sur la riviere Alabama, nous obtenons ainsi des triplets
de la forme (sujet, Verbe, complement), ou le sujet et le comple'ment sont deja de'sambigu‘1‘ses :
(RIVIERE COOSA, former, RIVIERE ALABAMA), (RIVIERE TALLAPOOSA, former, RIVIERE
ALABAMA), (RIVIERE ALABAMA, couler, VILLE SELMA), (RIVIERE ALABAMA, unir, RIVIERE
TOMBIGBEE), (RIVIERE ALABAMA, former, RIVIERE MOBILE)...

De meme, un article d’une autre encyclopedie, traitant egalement de la riviere Alabama,
fournit : (RIVIERE TALLAPOOSA, former, RIVIERE ALABAMA), (RIVIERE COOSA, former, RIVIERE
ALABAMA), (RIVIERE ALABAMA, serpenter, VILLE SELMA), (RIVIERE TOMBIGBEE, rejoindre,
RIVIERE ALABAMA), (RIVIERE ALABAMA, former, RIVIERE MOBILE). . .

3.3 Rapprochement des informations entre paires d’articles

Nous pouvons rapprocher ces informations. Sans les triplets identiques, il reste (RIVIERE
ALABAMA, couler, VILLE SELMA) ~ (RIVIERE ALABAMA, serpenter, VILLE SELMA) et (RIVIERE
ALABAMA, unir, RIVIERE TOMBIGBEE) ~ (RIVIERE TOMBIGBEE, rejoindre, RIVIERE ALABAMA).
Les entites nommees sont deja de'sambig.1‘1‘sees ; connaissant leurs hyperonymes, nous
pouvons donc re'ecrire ces paraphrases au niveau des classes plutot que des instances :
- (RIVIl3RE#1 rivl, couler, VILLE#1 v1) ~ (RIVIl3RE#1 riV1, SC1'p€I1t€I‘,VlLLE#1Vl)

- (RIVIl3RE#1 rivl, unir, RIVIl3RE#1 riV2) ~ (RIVIl3RE#1 riV2, rejoindre, RIVIl3RE#1 rivl).
3.4 Définition d’une mesure de similarité sur les verbes
ll nous reste a determiner le sens de chacun des deux verbes dans la paire de triplets. Nous

utilisons pour cela une mesure de similarité, qui exploite la hierarchie de verbes de WordNet.
Partant de l’hypothese que les deux verbes doivent avoir un sens proche l’un de l’autre, nous

10 La chaine de traitement utilisee est Antelope (telechargeable sur http://www.proxem.com).

464

Extraction de paraphrases de'sambigu‘1‘sees a partir d’un corpus d’articles encyclopediques

cherchons la combinaison de sens qui minimise leur distance, au sens d’une telle mesure. De
nombreux auteurs ont propose des deﬁnitions de mesures de similarité, et plusieurs
implementations basees sur WordNet sont disponiblesll. Par exemple, (Lin, 1998) deﬁnit
comme mesure de similarite entre deux synsets s] et s2 :

sim(s1, s2) = (2 . log P(s)) / (log P(s1) + log P(s2))

ou s est le synset le plus spe'ciﬁque subsumant les synset s] et s2 dans la hie'rarchie de
WordNet, et ou P(s) repre'sente la fre'quence du synset s obtenue a partir d’un corpus de
reference (le SemC0r en l’occurrence).

Nous avons imple'mente une mesure de ce type, en introduisant deux niveaux supple'mentaires
en plus de la hierarchie de WordNet. En effet, la qualite de la mesure de similarité est
fonction de la ﬁnesse de la hie'rarchie. De facon a rendre tous les Verbes comparables, nous
avons cree' un pseudo-synset qui sert de racine commune a tous les Verbes. Nous avons
e'galement intercale, entre cette racine et les Verbes, des pseudo-synsets regroupant les
categories lexicales (Verbes de mouvement, Verbes d’e'tat, Verbes de changement. . .).

3.5 Application de cette mesure de similarité aux Verbes des paraphrases

Nous appliquons cette mesure de similarite a toutes les combinaisons de sens de « couler » et
« serpenter », d’une part, et d’ « unir» et « rejoindre », d’autre part. Nous obtenons alors,
comme combinaison minimisant la distance entre les paires de Verbes :

- (RIVIl3RE#1 riV1, COULER#2, VILLE#1 v1) ~ (RIVIl3RE#1 rivl, SERPENTER#1, VILLE#1 v1)

- (RIVIl3RE#1 rivl, UNIR#4, RIVIl3RE#1 riV2) ~ (RIVIERE#1 riV2, REJOINDRE#5, RIVIl3RE#1 rivl).

3.6 Bilan

Ce processus permet d’obtenir automatiquement des paires de cadres de sous-categorisation,
dont les elements sont totalement de'sambigu‘1‘se's par rapport a WordNet. Nos premieres
evaluations preliminaires (effectuees sur une dizaine d’articles) montrent une precision de
l’ordre de 70% dans la detection de paraphrases pertinentes.

Une premiere passe, sur l’ensemble des articles de l’encyclope'die portant sur une meme
cate'gorie, permet de compter la frequence de chaque construction particuliere.

Il est alors possible de ﬁxer un seuil minimal en dessous-duquel la construction n’est pas
retenue; ce me'canisme est important pour compenser les erreurs ayant pu subvenir lors de
l’application de la chaine de traitement (durant les phases d’analyse syntaxique, de
de'sambign.1‘1‘sation lexicale des entites nommees ou de resolution d’anaphores). Si une meme
construction se retrouve un grand nombre de fois, elle est probablement correcte.

Ces cadres de sous-categorisations foumissent par la suite, lors d’une seconde passe de
traitement, de puissants indices de de'sambig.1‘1‘sation lexicale et syntaxique.

11 Par exemple, WordNet::Similarity (téléchargeable sur http://www.d.umn.edu/~tpederse/similarity.html).

465

Francois-Regis CHAUMARTIN

4 Conclusion

Cet article montre qu’il est possible d’enrichir automatiquement WordNet a partir d’une ou
plusieurs encyclopedies. Nous projetons d’utiliser le meme mecanisme pour importer des
dictionnaires specialises (en informatique, en droit et en medecine). Le fait de disposer de
plusieurs textes, portant sur un meme sujet, permet d’extraire automatiquement des
paraphrases ; leurs constituants sont completement identiﬁes, ce qui permet, dans une seconde
passe, d’ameliorer la desambigiisation lexicale des textes. Dans le cadre du projet en cours
ISIDORE, il reste a mettre en oeuvre ces mecanismes sur un volume signiﬁcatif d’articles,
pour affiner notre jugement sur la validite de cette approche.

Remerciements

Je remercie Sylvain Kahane (Paris 10) pour ses conseils, et Benjamin Surma et Ricardo
Minhoto pour leur participation au projet dans le cadre de leur memoire d’ingenieur ENSIIE.

Références
CARRE R., DEGREMONT J.F., GROSS M., PIERREL J.M., SABAH G. (1991), Langage humain et
machine. Presses du CNRS.

CHAUMARTIN F. (2006) Constmction automatique d’interface syntaxe-semantique utilisant
des ressources de large couverture en langme anglaise. Actes de T ALN 2006, 729-735.

IBRAHIM A., KATZ B., LIN J. (2003) Extracting Stmctural Paraphrases from Aligned
Monolingmal Corpora. Actes de Second International Workshop on Paraphrasing.

LIN D. (1998). An information-theoretic definition of similarity. Actes de I 5th International
Con)’. on Machine Learning, 296—304.

LIN D., PANTEL D. (2001) DIRT - Discovery of Inference Rules from Text. Actes de ACM
SIGKDD Conference on Knowledge Discovery and Data Mining.

MANNING C., KLEIN D. (2002). Fast Exact Inference with a Factored Model for Natural
Language Parsing. Advances in Neural Information Processing Systems I 5 (NIPS 2002).

MILLER G. (1995) WordNet: A lexical database. Actes de ACM 38, 39-41.

RESNIK P. (1995) Using Information Content to evaluate semantic similarity in a taxonomy.
Actes de IJCAI-95, 448453.

RUIZ-CASADO M., ALFONSECA E., CASTELLS P. (2005) Automatic assignment of
Wikipedia encyclopedic entries to WordNet synsets. Actes de A WIC, 380-386.

SLEATOR D., TEMPERLEY D. (1991) Parsing English with a Link Grammar. Actes de Third
International Workshop on Parsing Technologies.

466

