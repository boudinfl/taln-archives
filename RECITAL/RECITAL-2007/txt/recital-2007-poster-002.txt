RECITAL 2007, Toulouse, 5-8 juin 2007

Vers une ressource prédicative
pour l’extraction d’information

Aurélien BOSSARD
LIPN — Université Paris 13, 93200 Villetaneuse
aurelien . bossard@lipn . univ—parisl3 . fr

Résumé. Cet article présente une méthode pour construire, a partir d’une ressource lexi-
cale prédicative existante, une ressource enrichie pouvant servir a une tache d’ extraction. Nous
montrons les points forts et les lacunes de deux ressources existantes pour le Francais 2 les
Tables du LADL et Volem. Apres avoir montré pourquoi nous avons sélectionné Volem, nous
listons les données nécessaires a la téiche d’ extraction d’information. Nous présentons le proces-
sus d’ enrichissement de la ressource initiale et une evaluation, a travers une tache d’ extraction
d’information concemant des textes de rachats d’ entreprise.

Abstract. In this article, we present a method aiming at building a resource for an infor-
mation extraction task, from an already existing French predicative lexical resource. We point
out the weaknesses and strengtlmesses of two predicative resources we worked with 2 Les tables
du LADL and Volem. We present why we select Volem as the most interesting resource for the
task. Thereafter, we make a list of the needs an information extraction task implies, and how we
include missing information in the resource we selected. We evaluate the resource completed
by those missing informations, using it in an information extraction task.

Mots-clés 2 ressource prédicative, extraction d’information, patrons lexico-switaxiques.

Keywords: predicative resource, information extraction, lexico-switactic patterns.

1 Introduction

Cet article vise a montrer la facon dont nous avons procédé pour contribuer a une ressource lexi-
cale pour le francais, utile a des ﬁns d’ extraction d’information, en nous servant de ressources
déja existantes. La création d’une ressource pour le francais assez complete pour couvrir de
larges champs d’application en TAL apparait aujourd’hui comme un enjeu majeur. En effet,
en raison du manque de ressources, seules deux approches sont aujourd’hui possibles aﬁn de
réaliser des applications du type extraction d’information 2 1’ apprentissage automatique et/ou la
création de regles a la main.

L’ approche que nous défendons ici est fondée sur la notion de schéma prédicatif. Les éléments
pertinents pour l’extraction sont ceux qui se situent autour d’une relation sémantique, portée par
un nom prédicatif ou, plus souvent, par un verbe. L’ étude des schémas prédicatifs permet d’ at-
tribuer un role a chacun des arguments du prédicat; l’étude de la syntaxe de la phrase permet
en outre une mise en relation des arguments d’un prédicat avec leur role thématique. Nous tes-
tons notre approche dans le cadre d’une application d’ extraction d’information portant sur des

347

Aurélien B OSSARD

rachats d’ entreprise. La tache consiste par exemple a donner une représentation (sémantique)
identique pour les trois phrases suivantes 2

— CPI rachete Fulmar.
— CPI a racheté Fulmar a son PDG pour 50 millions d’ euros.
— CPI a indiqué avoir racheté Fulmar.

Dans chacune de ces trois phrases, nous pouvons identiﬁer un acheteur 2 CPI, une entreprise
acheté 2 Fulmar, auxquelles peuvent s’ajouter des données sur le montant de la transaction, le
vendeur, la date de la transaction... Ce type d’ applications a déja été développé, y compris pour
le frangais (Poibeau, 2003). Notre but est ici de l’envisager avec un nouveau regard, en nous
focalisant sur des ressources sémantiquement riches. Plutot que de développer des ressources
de maniere ad hoc, nous cherchons a caractériser l’intérét des données déja existantes pour le
frangais.

Les questions que nous nous sommes posé sont les suivantes 2
— Quelles sont les infonnations qu’une ressource lexicale syntaxique doit encoder pour que
l’on puisse arriver a un tel résultat ?
— Est-il possible, avec les ressources existantes, de créer une telle ressource ?
— Quel réel intérét aurait une telle ressource (précision de l’extraction, rappel, automatisa-
tion...) ?
Dans un premier temps, nous présentons un état de l’art traitant des ressources lexicales syn-
taxique existantes. Dans une seconde partie, nous caractérisons plus en détail notre suj et d’ étude
avant d’ aborder, dans une troisieme partie, les experiences réalisées. Nous présentons ensuite
les résultats et leur analyse avant de poser, dans une demiere partie, les conclusions de notre
recherche.

2 Choix d’une ressource

L’anglais dispose aujourd’hui de trois ressources a large couverture encodant d’une maniere
ou d’une autre la notion de schéma prédicatif 2 VerbNet, PropBank et FrameNet. Ces trois
ressources sont fondées sur des approches différentes 2 approche symtaxique pour VerbNet et
PropBank, et approche sémantique pour FrameNet (Pitel, 2006). De nombreuses applications
ont été développées autour de FrameNet, comme la désambiguisation sémantique (Fillmore &
Baker, 2001), (Lowe et al., 1997), mais aussi l’extraction d’infonnation. Des recherches ont été
menées pour utiliser conj ointement ces trois ressources aﬁn d’ améliorer l’ étiquetage sémantique
(Giuglea & Moschitti, 2004).

Il existe beaucoup moins de richesse pour le frangais. Le Dictionnaire Explicatif et Combina-
toire (DEC, http : / /www . olst .umontreal . ca/decfr . html) d’I. Melc’1'1k a été ex-
clu car il n’offrait pas une couverture sufﬁsante pour la tache. DicoValence

(http : / /bach. arts . kuleuven .be/dicovalence/) n’était quant a lui pas dispo-
nible au moment de l’étude mais mériterait sinon d’ étre pris en considération. Nous nous
sommes alors focalisés sur deux ressources pour le francais 2 Volem et les tables du LADL.
Il s’ agit dans cette partie d’ expliquer le choix que nous avons fait concemant la ressource que
nous avons utilisée.

348

Vers une ressource prédicative pour l’ extraction d’ information

2.1 Les Tables du LADL

Les Tables du LADL, aussi connues sous le nom de lexique-grarmnaire, ont été établies sous
la direction de Maurice Gross. Elles regroupent 6000 verbes répartis dans des tables construites
d’apres des similitudes de comportement syntaxique. Chaque table du Lexique-Grarmnaire
contient un certain nombre de propriétés, qui sont validées ou invalidées pour chacun des verbes
qui y ﬁgure (matrice de + et de —). Les propriétés encodent des informations sur (Gross, 1975) 2
— Les réalisations possibles des arguments (restrictions de selection 2 arguments a trait « hu-
main » ou « non-hurnain », argument de type abstrait, obj et...) ;
— Les propriétés syntaxiques du verbe ou de ses arguments (pronominalisation des verbes, in-
troduction d’ un argument par une préposition...)

— Les sous-catégorisations alternatives;

— Les possibilités de redistributions (passif long, passif court...).

Les infonnations contenues dans les tables du LADL sont riches sur le plan swrtaxique mais
relativement pauvres sur le plan sémantique. Les arguments ne sont typés que par des restric-
tions de sélection (humain, non—humain, ob j et concret, abst rait...). Le format en
colonnes des tables et le fait que l’information soit répartie sur plusieurs colonnes rend les trai-
tements difﬁciles. Le fait que, selon les tables, les propriétés codées dans les colonnes ne sont
pas toujours les memes complique encore le traitement. Il est nécessaire d’effectuer un travail
important de transformation pour rendre ces tables exploitables directement par des applications
de TAL (Gardent et al., 2005).

2.2 Volem

Volem (Saint-Dizier et al., 2002) est une ressource multilingue (francais-espagnol-catalan). Les
entrées sont des verbes 2 la ressource décrit leur comportement syntaxique et sémantique a
travers la description des arguments et des schémas de sous-catégorisation. Cette ressource
décrit a l’heure actuelle 1700 verbes.

Description du verbe : acheter

GRILLE THEMATIQUE :
[[inic(agent),dest],[th],[src]]
LCS :

ALTERNANCES :

caus_2np_pp , anti_pr_np , anti_pr_np_pp , pas_etre_part_np_2pp , pas_etre_part_np_pp
, caus_2np , caus_reﬂ_pr_2np , caus_np_pp , caus_support_np

WN :

[l3,2,3], [13,11] , [13,18]
EXEMPLE :

Ila acheté ce livre 3 un brocanteur

FIG. 1 — L’entrée lexicale du verbe « acheter » dans Volem

Cette ressource est fondée sur une liste de roles thématiques génériques, mais assez précis. Les
différents roles thématiques peuvent étre combinés aﬁn de décrire aux mieux les arguments
d’un verbe (cf Figure 1).

Les principaux inconvénients de cette ressource sont 2

349

Aurélien B OSSARD

— L’ absence de gestion de la polysémie (les concepteurs de la ressource ont fait le choix de ne
coder qu’un sens par verbe, correspondant a l’emploi le plus fréquent) ;

— La faible couverture de la ressource (1700 verbes) ;

— L’absence de description précise des schémas syntaxiques que représentent les différentes
altemances utilisées dans Volem.

Volem a une couverture moindre que celle des tables du LADL. L’absence de gestion des roles

thématiques dans les tables du LADL constitue cependant un inconvénient de taille pour une

tache d’ extraction d’info1mation, qui demande plus poussée sur la nature des arguments. Nous

avons donc choisi de concentrer notre étude sur la ressource lexicale Volem, qui para’1‘t avoir un

potentiel de description plus fort que les Tables du LADL pour notre application d’extraction.

3 Méthode d’enrichissement de la ressource

Les informations contenues dans Volem n’étaient pas sufﬁsantes pour réaliser une tache d’ex-
traction d’info1mation. Le format de Volem au format XML n’était pas non plus directement
exploitable. Nous avons donc retravaillé la ressource sur les points suivants aﬁn de pouvoir
l’utiliser dans le cadre d’une tache d’ extraction d’information :

1. Codage de la ressource sous la forme d’une table de contraintes
2. Ajout des informations manquantes

3. Codage d’automates patrons

3.1 Codage de la ressource sous la forme d’une table de contraintes

Nous voulons, a partir de Volem, créer des automates d’extraction (format unitex : http : / /
www— igm . univ—mlv . fr / ~unit ex/ ). Pour cela, nous avons besoin d’une ressource codée
a l’aide d’un tableau. Nous avons donc créé un convertisseur pour passer du format de Volem
a I1otre format. Nous utilisons une colonne par altemance de Volem, et validons l’altemance
pour un verbe en mettant un « + » dans la case correspondante, et un « - » sinon. Pour encoder
les informations sur les roles thématiques, nous écrivons une colonne par argument du verbe (3
colonnes) et nous remplissons chacune d’ elle avec la description enregistrée au sein de Volem du
role thématique de l’argument. Ainsi, la ressource est directement exploitable par des graphes
unitex, qui exploitent les tables de contraintes.

3.2 Ajout des informations manquantes

Cependant, la ressource en l’état n’encode toujours pas assez d’info1mations pour réaliser une
extraction d’info1mation précise. En effet, il lui manque encore 2

1. les auxiliaires des verbes
2. les différentes prépositions introduisant éventuellement un argument
3. les non1s associés aux verbes (e.g. rachat pour racheter)

4. les adjonctions essentielles a une relation a extraire.

350

Vers une ressource prédicative pour l’ extraction d’ information

3.2.1 Les auxiliaires

Deux possibilités se sont offertes a nous pour ajouter les auxiliaires d’un verbe a la table de
données que nous avions construite. Soit récupérer les auxiliaires depuis un dictionnaire, soit
identiﬁer l’auxiliaire d’un verbe grace aux occurrences de celui-ci en corpus. Nous avons opté
pour la deuxieme solution. A partir de la table de données que nous avons créée, un automate est
créé qui reconna’1‘tles différents verbes ainsi que les auxiliaires qui les accompagnent. Si l’auxi-
liaire « avoir » appara’1‘t au moins une fois dans le texte pour un verbe donné, un « + » est ajouté
a l’intersection de la ligne correspondant a ce verbe et de la colonne correspondant a l’auxiliaire
« avoir ». L’inconvér1ient de cette méthode est qu’elle demande des textes correctement écrits.
Mais elle n’est pas dépendante d’une ressource comme l’aurait été la premiere 2 en effet, en
utilisant les tables du LADL comme référence, nous n’aurions pas pu aj outer automatiquement
certains verbes qui ne sont pas encodés dans la ressource. Nous avons procédé au repérage des
auxiliaires avec la version « brute » des corpus que nous avons utilisés pour extraire les relations
de rachat d’ entreprises (cf §4.1).

3.2.2 L’ajout des prépositions

Nous avons déja mentionné qu’une seule préposition est codée par argument au sein de Volem,
alors que plusieurs prépositions peuvent appara1"tre pour certains verbes (acheter £1 ou auprés
de). Nous avons donc réalisé un outil permettant d’ aj outer a la table de données les prépositions
qui introduisent les arguments d’un verbe. Cet outil nécessite une validation des résultats par
l’utilisateur.

Le systeme est fondé sur une série d’auton1ates « a trou » : chaque « trou » correspond a une
préposition possible introduisant un argument. Le systeme renvoie quelques erreurs (soit des
groupes de mots qui ne sont pas des prépositions, soit des prépositions rallongées de certains
mots qui les suivaient dans le texte). Apres validation des rés11ltats par l’utilisateur, les prépo-
sitions validées sont ajoutées a la table de données. Cet outil nécessite un corpus annoté par
entités nommées. Nous avons travaillé sur les corpus utilisés pour l’extraction de relations de
rachats d’ entreprise (cf §4.1).

3.2.3 Les adjonctions

Volem ne gere que les arguments clé d’un verbe. Cependant, certains arguments qui ne sont
pas nécessaires d’un point de vue syntaxique jouent un role extrémement important dans des
relations a extraire. Par exemple, un achat selon Volem ne fait pas intervenir de montant : le
montant est quasiment toujours présent quand on se base sur 1’ analyse en corpus. C’est donc un
argument clé, sémantiquement parlant.

L’approche développée par les auteurs de FrameNet est du méme type (Fillmore & Baker,
2001). La description des schémas prédicatifs au sein de cette ressource se fonde sur l’étude
en corpus des réalisation du verbe. Si un complément intervient fréquemment pour un verbe
donné, alors celui-ci sera assimilé a un argument, méme s’il est considéré comme un ajout dans
la grammaire traditionnelle.

Nous avons alors tenté, en dénombrant ces adj onctions au sein des corpus étudiés, de déterminer
quelles adjonctions essentielles pouvaient tenir lieu d’ argument et dans quelle mesure celles-ci

351

Aurélien B OSSARD

pouvaient étre repérées par une analyse statistique. La méthode se fonde sur le repérage et le
regroupement des compléments circonstanciels (temps, lieu, montant...) pour chaque verbe au
sein du corpus.

Apres dénombrement des adj onctions, nous ne retenons que celles au-dessus d’un seuil de 10 %
(déﬁni manuellement). Cela signiﬁe que nous ne sélectionnons que celles qui sont apparues
dans au moins 10 % des phrases contenant un verbe donné. Cette méthode nous a perrnis de
compléter nos informations concemant les données a extraire avec les adjonctions adéquates
pour 80 % des verbes sélectionnés (pour les 20 % restant, 1’adjonction « montant » était apparue
dans moins de 10 % des phrases a extraire, contre 15 % pour 1’ adj onction « date »). Les rés11ltats
doivent toutefois étre validés par un expert avant d’ aj outer les adj onctions au schéma argurnental
des verbes concemés.

3.3 Les automates patrons

La derniere étape de 1’enr'ichissement de la ressource a consisté en la création d’automates
patrons pour chacune des altemances listée dans Volem. Un automate patron est un automate
lexicalement vide, encodant une famille d’a1temances ; il est instancié par 1’ensemble des verbes
correspondant a la famille d’a1temances visée. Pour cela, il a fallu dans un premier temps iden-
tiﬁer les différentes formes de surface que présentent chacune des altemances de Volem, puis
réaliser pour chacune d’entre elles des graphes qui permettent de les reconna1"tre.

La ﬁgure 2 (cf demiere page de 1’artic1e) présente un extrait d’un graphe qui permet de recon-
na1"tre 1’a1temance caus_2np de Volem.

Ces automates patrons prennent en entrée la ressource que nous avons créée, et produisent en
sortie autant d’automates que d’a1temances a reconna1"tre pour chaque verbe. Les automates
ainsi créés annotent un texte avec les informations que l’on veut extraire. En 1’occurrence, pour
notre extraction sur les rachats d’ entreprise, ils reconnaissent les fragments de textes correspon-
dant a 1’acheteur, au vendeur, a1’é1ément vendu, au montant et a la date.

4 Expériences

4.1 Données d’évaluati0n

Nous avons choisi de travailler sur une tﬁche d’ extraction précise 2 1e rachat d’entrepr'ises. Les
expériences ont été menées sur plusieurs corpus 2

— Un corpus tiré d’un autre site spécialisé 2 FUSACQ (300ko, 25000 mots) (http : / /www.

f usacq . com)

— Un corpus tiré de différents joumaux généralistes (400ko)

— Un corpus d’ entra’1‘nement pour repérer les entités nommées (200ko).

L’uti1isation de plusieurs corpus permet d’ évaluer les performances en tenant compte (dans la
mesure du possible) du genre textuel. On ne trouve pas les memes constructions ni les memes
expressions suivant que l’on a affaire a un corpus joumalistique ou a un site web. Nous ver-
rons dans la discussion que cette hypothese se vériﬁe lors de 1’étude des performances sur les
différents corpus.

352

Vers une ressource prédicative pour l’ extraction d’ information

4.2 Résultats

Nous avons mis en place deux protocoles d’évaluation, aﬁn d’isoler les éventuels problemes;
dans l’un, nous passons les regles d’ extraction sur un corpus dans lequel les entités nommées
ont été annotées grace a un outil pour armoter développé au LIPN (TagEN,

http : / /www—lipn . univ—paris13 . fr/~poibeau/tagen . html). Dans l’autre,
nous utilisons un corpus dans lequel nous avons annoté toutes les entités nommées a la main.
Nous pouvons ainsi procéder d’un cote a une évaluation « en conditions réelles », et de l’autre,
de nous focaliser sur l’évaluation des schémas prédicatifs, indépendanunent des erreurs dues a
la mauvaise reconnaissance des entités.

Dans le tableau 1, nous entendons « relations » comme des structures grammaticales comportant
un verbe et ses arguments participant a un rachat d’entreprise.

Protocole 1 Protocole 2 Nombre total
de relations

Nombre de relations 101 184 285
repérées
% de relations 35 64 100

TAB. 1 — Tableau des résultats de l’extraction sur le corpus FUSACQ

Un peu plus seulement de la moitié des entités nommées correspondant a un acheteur potentiel
ou a un vendeur potentiel ont été armotées. L’ annotation des entités nommées n’a pas été menée
plus avant, étant donnée qu’elle n’ est pas au centre de notre étude. Notre outil perrnet de repérer
dans un texte dans lequel l’annotation des entités nommées est correcte, 65 % des relations
d’achat.

35 % des relations restent tout de meme non repérées. Ceci provient du fait que nous n’avons

pas géré certains schémas syntaxiques 2

— les subordonnées relatives

— les verbes introducteurs précédés d’un verbe marquant soit le passé, soit le futur (ambigu'1'té
sémantique possible. Ex. : « Bull vient d’armoncer le rachat de CP8 a Schlumberger »)

— les structures complexes (ex. :« COMPAN Y1 s’était diversiﬁé a travers l’acquisition de COM-
PANY2 »

— L’ altemance passive sans groupe prépositionnel (non encodé dans Volem pour les verbes qui
nous intéressent. Ex. : « COMPANY a été racheté »)

— Les structures faisant intervenir un pronom (pas de résolution d’ anaphores).

L’ outil de repérage des prépositions renvoie des résultats bruités a hauteur de 8 %.

Les adj onctions nécessaires a une tache d’ extraction sont la date et le montant de la transaction.
Les corpus sur lesquels nous avons fait nos expériences ont montré ce point, meme s’ils sont de
taille trop faible pour donner des chiffres signiﬁcatifs statistiquement.

4.3 Discussion

Nous avons vu que Volem est incomplet du fait qu’il ne gere pas la polysémie et que toutes les
altemances n’y sont pas codées.

Est-il possible de rajouter aux entrées de Volem les altemances que cette ressource n’encode

353

Aurélien B OSSARD

de 1’ altemance

caus_
caus_2np_pp

caus_2np
caus_

caus_
caus_2np_pp

caus_ _pp
caus_2np

aucune occurrence

1
caus_ _pp
1 0

pas_etre_part_np_pp
caus_ 12 8

 

TAB. 2 — Répartition des altemances selon les verbes dans les phrases extraites des corpus
(FUSACQ annoté et extrait du corpus general)

pas ? L’ ajout des altemances constitue un reel probleme. En effet, il est possible, par des me-
thodes statistiques, de sélectionner des schémas de sous-categorisation acceptables pour un
verbe (Salmon-Alt & Chesley, 2005),(B1iscoe & Carroll, 1997). Mais la selection d’altemances
acceptables constitue un tout autre probleme; il faut en effet pouvoir distinguer une phrase du
type : « COMPANYI a acheté une usine a LIEU. » d’une phrase du type : « COMPANY 1 a
acheté des terrains a LIEU{la ville de LIEU}. Ce probleme mériterait une etude approfondie.

Un point intéressant est la variation dans l’usage du verbe suivant le corpus. On s’apercoit,
meme sur des corpus de taille modeste, des variations d’usage, une altemance étant plutet em-
ployée dans un corpus, une autre dans un autre corpus (cf tableau2). Nous faisons l’hypothese
qu’il s’agit de variations dans le style d’éc1iture propre aux différents genres textuels. Ainsi,
l’altemance « caus_2np » du verbe « détenir » constitue 78 % des variations symtaxiques pour le
verbe « détenir » dans le corpus Firstlnvest, et 80 % dans FUSACQ, mais n’appara’1‘t pas dans le
corpus tire de joumaux non specialises.

Les résultats obtenus sont satisfaisants. En effet, l’ajout des structures syntaxiques manquantes
(cf §4.2) permettrait d’obtenir environ 65 % de rappel sur une tache d’ extraction des rachats
d’entrep1ise, soit 15 % de moins que le rappel obtenu par 'Ihierry Poibeau, sur la meme tache
et le meme type de corpus (Poibeau, 2003), mais en utilisant une méthode a base de ressources
qui se distingue des autres travaux par une certaine généricité.

5 Conclusion et Perspectives

Les ressources pour le francais sont beaucoup moins completes que celles pour l’anglais. La
ressource pour le francais qui nous a semblé la plus adaptée a l’ extraction d’information (Vo-
lem), présente des manques (non gestion de la polysémie, couverture faible, altemances non
encodées...) qu’il est cependant possible de combler par des méthodes semi-automatiques.

354

Vers une ressource prédicative pour l’ extraction d’ inforrrration

Les résultats obtenus pour une tache d’extraction pour l’anglais (Giuglea & Moschitti, 2004)
montre que 1’ extraction a base de ressources a large couverture pennet d’ obtenir de bons ré-
sultats et évite de redévelopper de maniere ad hoc des connaissances pour chaque nouvelle
application.

Il reste certes un travail a réaliser dépendant de l’application (ajout d’adjonctions, preposi-
tions), cependant la mise en place d’une méthode utilisant des ressources extérieures perrnet
une réutilisabilité a contrario des méthodes purement ad hoc tout en garantissant malgré tout
une couverture et une certaine généricité.

Cet article a cherché a montrer comment compléter Volem, notannnent avec les prépositions et
le ﬁltrage des altemances non per1;inentes pour un sens donné. Il reste a déﬁnir une méthode
serni-automatique pour l’ajout des altemances non référencées par Volem.

Références

BRISCOE T. & CARROLL J. (1997). Automatic extraction of subcategorization from corpora.

FILLMORE C. & BAKER C. (2001). Frame semantics for text understanding. In WordNet and
Other Lexical Resources Workshop, NAACL, Pittsburgh.

GARDENT C., GUILLAUME B., FALK I. & PERRIER G. (2005). Le lexique-grarmnaire de m.
gross et le traitement automatique des langues.

GIUGLEA A.-M. & MOSCHITTI A. (2004). Knowledge discovering using framenet, verbnet

and propbank. In International Workshop on Mining for and from the Semantic Web, Seattle,
USA.

GROSS M. (1975). Me’thodes en syntaxe. Paris 2 Hermarm.
LOWE J., BAKER C. & FILLMORE C. (1997). A frame-semantic approach to semantic anno-
tation.

PITEL G. (2006). Framenet, théorie, produit, processus, multilingualité et connexions. In
Autour de FrameNet et de la Sémantique Lexicale Multilingue : projets en cours et points de
contacts entre les diﬁérentes approches. date de la conference 2 28 Février 2006.

POIBEAU T. (2003). Extraction automatique d ’information, du texte bmt au web se’mantique.
Paris 2 Hermes.

SAINT-DIZIER P., FERNANDEZ A., VAZQUEZ G., KAMEL M. & BENAMARA F. (2002).
The Volem Project 2 a Framework for the Construction of Advanced Multilingual Lexicons .
In Language Technology 2002 , Hyderabad, , p. 123-142 2 Springer Verlag, Lecture Notes.
Dates de conference 2 décembre 2002.

SALMON-ALT S. & CHESLEY P. (2005). Le ﬁltrage probabiliste dans l’extraction automa-
tique de cadres de sous-categorisation. In Joume’e ATTAIA du I 2/03/2005.

355

Aurélien B OSSARD

Acmnmmv©..I_.<mzmmu

FIG. 2 — Exemple d’un automate patron

356

