<?xml version="1.0" encoding="UTF-8"?>
<!-- Corrections fichier corrompu recital-2008-long-010 -->
<conference>
	<edition>
		<acronyme>RECITAL'2008</acronyme>
		<titre>10e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues</titre>
		<ville>Avignon</ville>
		<pays>France</pays>
		<dateDebut>2008-06-09</dateDebut>
		<dateFin>2008-06-13</dateFin>
		<presidents>
			<president>
				<prenom>Patrice</prenom>
				<nom>Bellot</nom>
			</president>
			<president>
				<prenom>Marie-Laure</prenom>
				<nom>Guénot</nom>
			</president>
		</presidents>
		<typeArticles>
			<type id="long">Papiers longs</type>
		</typeArticles>
		<siteWeb>http://www.lia.univ-avignon.fr/jep-taln08/</siteWeb>
	</edition>
	<articles>
		<article id="recital-2008-long-001" session="Session Orale">
			<auteurs>
				<auteur>
					<prenom>Guillaume</prenom>
					<nom>Bernard</nom>
					<email>gbernard@limsi.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LIMSI - CNRS, B.P. 133, 91403 ORSAY, France</affiliation>
			</affiliations>
			<titre>Méthode de réordonnancement de réponses par transformation d’arbres : présentation et analyse des résultats</titre>
			<type>long</type>
			<pages></pages>
			<resume>Dans cet article nous présentons une évaluation et une analyse des résultats d’une méthode de réordonnancement de réponses pour un système de questions-réponses. Cette méthode propose une sélection des réponses candidates à une question en calculant un coût par transformation d’arbres. Nous présentons une analyse des résultats obtenus sur le corpus Clef 2004-2005 et nos conclusions sur les voies d’amélioration possibles pour notre système.</resume>
			<mots_cles>Recherche d’information, Traitement Automatique des Langues, systèmes de questions-réponses</mots_cles>
			<title></title>
			<abstract>This paper describes an evaluation and an analysis of the results of an answers reranking method for a question-answering system. Candidate answers to a question are reordered by computing a tree transform cost. We discuss the results of our evaluation on the Clef 2004-2005 corpus and describe possible improvements to the system.</abstract>
			<keywords>Information Retrieval, Natural Language Processing, Question-Answering systems</keywords>
		</article>
		<article id="recital-2008-long-002" session="Session Orale">
			<auteurs>
				<auteur>
					<prenom>André</prenom>
					<nom>Bittar</nom>
					<email>andre.bittar@linguist.jussieu.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Université Paris 7 Diderot - ALPAGE</affiliation>
			</affiliations>
			<titre>Annotation des informations temporelles dans des textes en français</titre>
			<type>long</type>
			<pages></pages>
			<resume>Le traitement des informations temporelles est crucial pour la compréhension de textes en langue naturelle. Le langage de spécification TimeML a été conçu afin de permettre le repérage et la normalisation des expressions temporelles et des événements dans des textes écrits en anglais. L’objectif des divers projets TimeML a été de formuler un schéma d’annotation pouvant s’appliquer à du texte libre, comme ce que l’on trouve sur le Web, par exemple. Des efforts ont été faits pour l’application de TimeML à d’autres langues que l’anglais, notamment le chinois, le coréen, l’italien, l’espagnol et l’allemand. Pour le français, il y a eu des efforts allant dans ce sens, mais ils sont encore un peu éparpillés. Dans cet article, nous détaillons nos travaux actuels qui visent à élaborer des ressources complètes pour l’annotation de textes en français selon TimeML - notamment un guide d’annotation, un corpus de référence (Gold Standard) et des modules d’annotation automatique.</resume>
			<mots_cles>Annotation temporelle, repérage des événements, TimeML</mots_cles>
			<title></title>
			<abstract>The processing of temporal information is crucial for the understanding of natural language texts. The specification language TimeML was developed to facilitate the identification and normalization of temporal expressions and events in texts written in English. The aim of the various TimeML projects was to formulate an annotation scheme able to be applied to free text, such as that which is found on the Web, for example. Recently, efforts have been made to apply TimeML to languages other than English, namely Chinese, Korean, Italian, Spanish and German. Some efforts have been made in this direction with respect to French, but they remain somewhat scattered. In this paper, we detail our ongoing work, which aims to establish comprehensive resources for the annotation of French texts according to TimeML - an annotation guide, a Gold Standard corpus and modules for automatic annotation.</abstract>
			<keywords>Temporal annotation, event recognition, TimeML</keywords>
		</article>
		<article id="recital-2008-long-003" session="Session Orale">
			<auteurs>
				<auteur>
					<prenom>Anne</prenom>
					<nom>Garcia-Fernandez</nom>
					<email>annegf@limsi.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Carole</prenom>
					<nom>Lailler</nom>
					<email>carole.lailler@lium.univ-lemans.fr</email>
					<affiliationId>2</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LIMSI-CNRS – Université Paris Sud, BP 133 - 91403 Orsay Cedex</affiliation>
				<affiliation affiliationId="2">LIUM – Université du Maine, 72085 Le Mans Cedex 9</affiliation>
				<affiliation affiliationId="3"></affiliation>
			</affiliations>
			<titre>Morphosyntaxe de l'interrogation pour le système de question-réponse RITEL</titre>
			<type>long</type>
			<pages></pages>
			<resume>Nous proposons d'étudier le cas de l'interrogation en Dialogue Homme-Machine au sein d'un système de Question-Réponse à travers le prisme de la Grammaire Interactive. Celle-ci établit un rapport direct entre question et réponse et présuppose que la morphosyntaxe d'une interrogation dépend d'une « réponse escomptée »; l'interlocuteur humain ou machine ayant la possibilité de produire une réponse effective divergente. Nous proposons d’observer la présence des différentes formes de questions dans un corpus issu de l’utilisation du système RITEL. Et nous présentons une expérience menée sur des locuteurs natifs qui nous a permis de mettre en valeur la différence entre réponses effectives produites par nos sujets et réponses présupposées par le contenu intentionnel des questions. Les formalismes ainsi dégagés ont pour but de donner aux systèmes de DHM des fonctionnalités nouvelles comme la capacité à interpréter et à générer de la variabilité dans les énoncés produits.</resume>
			<mots_cles>Grammaire Interactive, modèles dynamiques, dialogue homme-machine, système de question-réponse, morphosyntaxe, expérimentation utilisateur, formulation de réponse</mots_cles>
			<title></title>
			<abstract>In this paper we study the interrogation in Human-Computer Dialogue in order to integrate interpretative and dynamic functionnalities in a Question-Answering system using Interactive Grammar. It constitues a direct link between question and answer and assumes that the morphosyntax of interrogation depends on an anticipated answer. We propose an observation of question-answering corpora coming from the RITEL system showing the distribution of different morphosyntatic kinds of questions. Then we present an experimentation based on this observation in which French native speakers answer to those different kinds of questions. Our objective is to observe the difference between the anticipated answer and the effective one.</abstract>
			<keywords>Interactive Grammar, dynamic models, human-computer dialogue, question-answering system, morphosyntax, user experimentation, answer formulation</keywords>
		</article>
		<article id="recital-2008-long-004" session="Session Orale">
			<auteurs>
				<auteur>
					<prenom>Elzbieta</prenom>
					<nom>Gryglicka</nom>
					<email>elzbieta.gryglicka@thalesgroup.com</email>
					<affiliationId>1</affiliationId>
					<affiliationId>2</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Laboratoire Mathématiques et Aide à la Décision – Thales R&amp;T, RD 128 Palaiseau</affiliation>
				<affiliation affiliationId="2">ALPAGE –Paris 7, 30 rue Château des Rentiers, 75 013 Paris</affiliation>
			</affiliations>
			<titre>Un système d'annotation des entités nommées du type personne pour la résolution de la référence</titre>
			<type>long</type>
			<pages></pages>
			<resume>Dans cet article nous présentons notre démarche pour l’annotation des expressions référentielles désignant les personnes et son utilisation pour la résolution partielle de la référence. Les choix effectués dans notre implémentation s'inspirent des travaux récents dans le domaine de l'extraction d'information et plus particulièrement de la reconnaissance des entités nommées. Nous utilisons les grammaires locales dans le but d'annoter les entités nommées du type Personne et pour construire, à partir des annotations produites, une base de connaissances extra-linguistiques. Les informations acquises par ce procédé sont ensuite utilisées pour implémenter une méthode de la résolution de la référence pour les syntagmes nominaux coréférentiels.</resume>
			<mots_cles>entités nommées, annotation, grammaires locales, Nooj, base de connaissances</mots_cles>
			<title></title>
			<abstract>The aim of this paper is to describe our approach for annotating of the referential mentions that refer to the entities which are the instances of Person. Our method is inspired by the recent work in information extraction and particularly the named entities recognition and classification task. Local grammars are used to identify this category of named entities and to generate an extra-linguistic knowledge base which is further used for the process of reference resolution.</abstract>
			<keywords>named entities, entity recongnition, local grammars, Nooj, knowledge base</keywords>
		</article>
		<article id="recital-2008-long-005" session="Session Orale">
			<auteurs>
				<auteur>
					<prenom>Alexis</prenom>
					<nom>Kauffmann</nom>
					<email>alexis.kauffmann@lettres.unige.ch</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LATL (Laboratoire d'Analyse et de Technologie du Langage) – Université de Genève, 2, rue de Candolle, 1211 Genève, Suisse</affiliation>
			</affiliations>
			<titre>Description de la structure de la phrase japonaise en vue d'une analyse syntaxique</titre>
			<type>long</type>
			<pages></pages>
			<resume>Nous décrivons la façon dont est formée la phrase japonaise, avec son contenu minimal, la structure des composants d'une phrase simple et l'ordre des mots dans ses composants, les différentes phrases complexes et les possibilités de changements modaux. Le but de cette description est de permettre l'analyse de la phrase japonaise selon des principes universels tout en restant fidèles aux particularités de la langue. L'analyseur syntaxique multilingue FIPS est en cours d'adaptation pour le japonais selon les règles de grammaire qui ont été définies. Bien qu'il fonctionnait alors uniquement pour des langues occidentales, les premiers résultats sont très positifs pour l'analyse des phrases simples, ce qui montre la capacité de Fips à s'adapter à des langues très différentes.</resume>
			<mots_cles>Analyse Syntaxique, Japonais, Grammaire</mots_cles>
			<title></title>
			<abstract>We describe here the way the Japanese sentence is structured, with its minimal content, the structure of its components, the different kinds of complex sentences and the possible modal effects. The aim of this description is to analyse the Japanese sentence in a universal way while respecting the language properties. The syntactic parser FIPS is now being developed to analyse Japanese sentences following grammar rules coming from this syntactic description. Even though the parser used to be used for Western languages only, the first results of simple Japanese sentence analysis are very positive. This shows how FIPS can adapt easily to very different languages.</abstract>
			<keywords>Syntactic Parser, Japanese language, Grammar</keywords>
		</article>
		<article id="recital-2008-long-006" session="Session Orale">
			<auteurs>
				<auteur>
					<prenom>Marc</prenom>
					<nom>Le Tallec</nom>
					<email>marc.letallec@etu.univ-tours.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Laboratoire d’Informatique – Université François-Rabelais de Tours, Campus Universitaire de Blois, 3 place Jean Jaurès, F-41000 Blois</affiliation>
			</affiliations>
			<titre>Adaptation d’un système de compréhension pour un robot compagnon</titre>
			<type>long</type>
			<pages></pages>
			<resume>Le projet EmotiRob, financé par l’ANR, a pour but de réaliser un robot compagnon pour des enfants fragilisés. Le projet se décompose en deux sous parties que sont le module de compréhension pour comprendre ce que dit l’enfant et un module d’interaction émotionnelle pour apporter une réponse en simulant des émotions par les mouvements du corps, les traits du visage et par l'émission de petits sons simples. Le module de compréhension dont il est question ici réutilise les travaux du système Logus. La principale difficulté est de faire évoluer le système existant d’un dialogue homme-machine finalisé vers un domaine plus large et de détecter l’état émotionnel de l’enfant. Dans un premier temps, nous présentons le projet EmotiRob et ses spécificités. Ensuite, le système de compréhension de la parole Logus, sur lequel se base ce travail, est présenté en détail. Enfin, nous présentons les adaptations du système à la nouvelle tâche EmotiRob.</resume>
			<mots_cles>Compréhension du langage, langue parlée spontanée</mots_cles>
			<title></title>
			<abstract>The EmotiRob project, financed by ANR, aims at realizing a robot companion for weakened children. The project decomposes into two under parts that which are the module of understanding to include what says the child and a module of emotional interaction to bring an answer by feigning feelings by the movements of the body, lines of the face and by emission of small simple sounds. The module of understanding reuses the works of the system Logus. The main difficulty is to develop the existing system of a human-machine dialogue finalized towards a wider domain and to detect the emotional state of the child. At first, we present the EmotiRob project and its specificities. Then, the system of understanding Logus, on which bases itself this work is presented. Finally, we present the adaptations of the system to his new task EmotiRob.</abstract>
			<keywords>spoken language understanding, spontaneous language</keywords>
		</article>
		<article id="recital-2008-long-007" session="Session Orale">
			<auteurs>
				<auteur>
					<prenom>Aiala</prenom>
					<nom>Rosá</nom>
					<email>aialar@fing.edu.uy</email>
					<affiliationId>1</affiliationId>
					<affiliationId>2</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Facultad de Ingeniería - Universidad de la República, J. Herrera y Reissig 565, Montevideo, Uruguay</affiliation>
				<affiliation affiliationId="2">MoDyCo, UMR7114, CNRS - Université Paris X, 200, avenue de la République, Nanterre, France </affiliation>
			</affiliations>
			<titre>Identification automatique de marques d'opinion dans des textes</titre>
			<type>long</type>
			<pages></pages>
			<resume>Nous présentons un modèle conceptuel pour la représentation d'opinions, en analysant les éléments qui les composent et quelques propriétés. Ce modèle conceptuel est implémenté et nous en décrivons le jeu d’annotations. Le processus automatique d’annotation de textes en espagnol est effectué par application de règles contextuelles. Un premier sous-ensemble de règles a été écrit pour l'identification de quelques éléments du modèle. Nous analysons les premiers résultats de leur application.</resume>
			<mots_cles>Identification d'opinions, Fouille de textes, Traitement automatique du langage naturel</mots_cles>
			<title></title>
			<abstract>We  present a model for the representation of opinions, by analyzing the elements which compose them and some properties. The model has an operating counterpart, implemented in the form of a set of tags. For the automatic application of these tags on Spanish texts, we work on the writing of contextual rules. A primary subset of rules was written for the identification of some elements of the model. We analyze the first results of their application.</abstract>
			<keywords>Opinions Identification, Text Mining, Natural Language Processing</keywords>
		</article>
		<article id="recital-2008-long-008" session="Session Orale">
			<auteurs>
				<auteur>
					<prenom>Yves</prenom>
					<nom>Scherrer</nom>
					<email>yves.scherrer@lettres.unige.ch</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LATL, Université de Genève, Rue de Candolle 5, 1211 Genève 4, Suisse</affiliation>
			</affiliations>
			<titre>Transducteurs à fenêtre glissante pour l’induction lexicale</titre>
			<type>long</type>
			<pages></pages>
			<resume>Nous appliquons différents modèles de similarité graphique à la tâche de l’induction de lexiques bilingues entre un dialecte de Suisse allemande et l’allemand standard. Nous comparons des transducteurs stochastiques utilisant des fenêtres glissantes de 1 à 3 caractères, entraînés à l’aide de l’algorithme de maximisation de l’espérance avec des corpus d’entraînement de tailles différentes. Si les transducteurs à unigrammes donnent des résultats satisfaisants avec des corpus très petits, nous montrons que les transducteurs à bigrammes les dépassent à partir de 750 paires de mots d’entraînement. En général, les modèles entraînés nous ont permis d’améliorer la F-mesure de 7% à 15% par rapport à la distance de Levenshtein.</resume>
			<mots_cles>Induction lexicale, transducteurs stochastiques, langues apparentées</mots_cles>
			<title></title>
			<abstract>We apply different models of graphemic similarity to the task of bilingual lexicon induction between a Swiss German dialect and Standard German. We compare stochastic transducers using sliding windows from 1 to 3 letters, trained with the Expectation-Maximisation algorithm on training corpora of different sizes. While the unigram transducers provide good results with very small corpora, we show that bigram transducers outperform them with corpora of 750 word pairs or more. Overall, the trained models show between 7% and 15% F-measure improvement over Levenshtein distance.</abstract>
			<keywords>Lexicon induction, stochastic transducers, cognate languages</keywords>
		</article>
		<article id="recital-2008-long-009" session="Poster">
			<auteurs>
				<auteur>
					<prenom>Pierre</prenom>
					<nom>Hankach</nom>
					<email>pierre.hankach@orange-ftgroup.com</email>
					<affiliationId>1</affiliationId>
					<affiliationId>2</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Orange Labs, 2 avenue Pierre Marzin, 22300 Lannion</affiliation>
				<affiliation affiliationId="2">Université Paris 7, 5 rue Thomas Mann, 75013 PARIS</affiliation>
			</affiliations>
			<titre>Génération intégrée localisée pour la production de documents</titre>
			<type>long</type>
			<pages></pages>
			<resume>Dans cet article, nous proposons une approche intégrée localisée pour la génération. Dans cette approche, le traitement intégré des décisions linguistiques est limité à la production des propositions dont les décisions qui concernent leurs générations sont dépendantes. La génération se fait par groupes de propositions de tailles limitées avec traitement intégré des décisions linguistiques qui concernent la production des propositions qui appartiennent au même groupe. Notre approche apporte une solution pour le problème de complexité computationnelle de la génération intégrée classique. Elle fournit ainsi une alternative à la génération séparée (séquentielle ou interactive) qui présente plusieurs défauts mais qui est implémentée de manière répandue dans les systèmes de générations existants.</resume>
			<mots_cles>génération intégrée localisée, architectures de génération, SDRT, segmentation du discours</mots_cles>
			<title></title>
			<abstract>In this paper, we propose a localized integrated approach for generation. In this approach, the integrated handling of linguistic decisions is limited to the production of propositions whose decisions concerning their generation are dependant. The generation is performed by groups of propositions of limited size with an integrated handling of linguistic decisions that concern the production of the propositions that belong to the same group. Our approach provides a solution for the computational complexity problem of classical integrated generation. Therefore, it provides an alternative to separated generation (sequential and interactive) that has many drawbacks but is widely implemented in today’s generation systems.</abstract>
			<keywords>localized integrated generation, generation architectures, SDRT, discourse segmentation</keywords>
		</article>
		<article id="recital-2008-long-010" session="Poster">
			<auteurs>
				<auteur>
					<prenom>Mohamed</prenom>
					<nom>Bouallegue</nom>
					<email>mohamed.bouallegue@u-grenoble3.fr</email>
					<affiliationId>2</affiliationId>
				</auteur>
				<auteur>
					<prenom>Mohsen</prenom>
					<nom>Maraoui</nom>
					<email>Mohsen.maroui@u-grenoble3.fr</email>
					<affiliationId>2</affiliationId>
				</auteur>
				<auteur>
					<prenom>Mourad</prenom>
					<nom>Mars</nom>
					<email>Mourad.mars@u-grenoble3.fr</email>
					<affiliationId>1</affiliationId>
					<affiliationId>2</affiliationId>
				</auteur>
				<auteur>
					<prenom>Mounir</prenom>
					<nom>Zrigui</nom>
					<email>Mounir.Zrigui@fsm.rnu.tn</email>
					<affiliationId>2</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Labo (UTIC : Equipe de Monastir) – Université de Monastir Faculté des Sciences de Monastir</affiliation>
				<affiliation affiliationId="2">Labo LIDILEM, Université STENDHAL, Grenoble, France</affiliation>
			</affiliations>
			<titre>Un système de génération et étiquetage automatique de dictionnaires linguistiques de l'arabe</titre>
			<type>long</type>
			<pages></pages>
			<resume>L'objectif de cet article est la présentation d'un système de génération automatique de dictionnaires électroniques de la langue arabe classique, développé au sein de laboratoire UTIC (unité de Monastir). Dans cet article, nous présenterons, les différentes étapes de réalisation, et notamment la génération automatique de ces dictionnaires se basant sur une théorie originale : les Conditions de Structures Morphomatiques (CSM), et les matrices lexicales. Ce système rentre dans le cadre des deux projets MIRTO et OREILLODULE réalisés dans les deux laboratoires LIDILEM de Grenoble et UTIC Monastir de Tunisie</resume>
			<mots_cles>génération automatique, dictionnaire, conditions de structure morphématique</mots_cles>
			<title></title>
			<abstract>The objective of this article is the presentation of an automatic system of generation of dictionaries electronics of Arabic basing itself on the conditions of morphemic structure and the matrices lexical. This work returns within the framework of two projects MIRTO and OREILLODULE under development to laboratories LIDILEM of Grenoble and UTIC of Tunisia.</abstract>
			<keywords>automatic system of generation, conditions of morphemic structure, matrices lexical</keywords>
		</article>
		<article id="recital-2008-long-011" session="Poster">
			<auteurs>
				<auteur>
					<prenom>Fabien</prenom>
					<nom>Poulard</nom>
					<email>Fabien.Poulard@univ-nantes.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Université de Nantes, LINA CNRS UMR 6241, 44322 Nantes Cedex 3</affiliation>
			</affiliations>
			<titre>Analyse quantitative et qualitative de citations extraites d’un corpus journalistique</titre>
			<type>long</type>
			<pages></pages>
			<resume>Dans le contexte de la détection de plagiats, le repérage de citations et de ses constituants est primordial puisqu’il peut aider à évaluer le caractère licite ou illicite d’une reprise (source citée ou non). Nous proposons ici une étude quantitative et qualitative des citations extraites d’un corpus que nous avons auparavant construit. Cette étude a pour but de tracer des axes de recherche vers une méthode de repérage automatique des citations.</resume>
			<mots_cles>citations, contruction et étude de corpus, genre journalistique</mots_cles>
			<title></title>
			<abstract>In the plagiarism detection context, finding citations and their components is essential as it may help estimating legal value of a copy (with or without original source specified). We propose here a quantitative and qualitative study of citations we extracted from a corpus we previously built. This study aims at orienting our research towards an efficient automatic citations extraction method.</abstract>
			<keywords>citations, corpus creation and analysis, journalistic genre</keywords>
		</article>
		<article id="recital-2008-long-012" session="Poster">
			<auteurs>
				<auteur>
					<prenom>Kévin</prenom>
					<nom>Séjourné</nom>
					<email>kevin.sejourne@limsi.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Université de Paris Sud XI, Limsi-CNRS, BP 133, 91403 Orsay Cedex, Bâtiment 508</affiliation>
			</affiliations>
			<titre>Une structure pour les questions enchainées</titre>
			<type>long</type>
			<pages></pages>
			<resume>Nous présentons des travaux réalisés dans le domaine des systèmes de questions réponses (SQR) utilisant des questions enchainées. La recherche des documents dans un SQR est perturbée par l’absence d’informations sur la valeur à accorder aux éléments de texte éventuellement utiles à la recherche d’informations qui figurent dans les questions liées. Les récentes campagnes d’évaluation montrent que ce problème est sous-estimé, et n’a pas fait l’oeuvre de technique dédiée. Afin d’améliorer la recherche des documents dans un SQR nous étudions une nouvelle méthode pour organiser les informations liées aux interactions entre questions. Celle-ci se base sur l’exploitation d’une structure de données adaptée à la transmission des informations des questions liées jusqu’au moteur d’interrogation.</resume>
			<mots_cles>Question réponse enchainée</mots_cles>
			<title></title>
			<abstract>We present works realized in the field of questions answering systems(SQR) using chained questions. The search for documents in a SQR is disrupted by the absence of information on the value to be granted to the possibly useful elements of text in search of information which appear in bound questions. The recent campaigns of evaluation show that this problem is under estimated, and did not make the work of dedicated technique. To improve the search for documents in a SQR we study a new method to organize the information bound to the interactions between questions. This one is based on the operation of a structure of data adapted to the transmission of the information of bound questions up to the search engine.</abstract>
			<keywords>chained question answering</keywords>
		</article>
		<article id="recital-2008-long-013" session="Poster">
			<auteurs>
				<auteur>
					<prenom>Agnès</prenom>
					<nom>Souque</nom>
					<email>asouque@gmail.com</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Laboratoire LIDILEM - Université Stendhal - Grenoble 3, 1491 rue des Résidences, 38040 Grenoble Cedex 09</affiliation>
			</affiliations>
			<titre>Vers une nouvelle approche de la correction grammaticale automatique</titre>
			<type>long</type>
			<pages></pages>
			<resume>La correction grammaticale automatique du français est une fonctionnalité qui fait cruellement défaut à la communauté des utilisateurs de logiciels libres. Dans le but de combler cette lacune, nous avons travaillé à l’adaptation au français d’un outil initialement développé pour une langue étrangère. Ce travail nous a permis de montrer que les approches classiques du traitement automatique des langues utilisées dans le domaine ne sont pas appropriées. Pour y remédier, nous proposons de faire évoluer les formalismes des correcteurs en intégrant les principes linguistiques de la segmentation en chunks et de l’unification. Bien qu’efficace, cette évolution n’est pas suffisante pour obtenir un bon correcteur grammatical du français. Nous envisageons alors une nouvelle approche de la problématique.</resume>
			<mots_cles>correction grammaticale, syntagme, unification</mots_cles>
			<title></title>
			<abstract>Free software users community is sorely lacking French grammar checking. With the aim of filling this gap, we have worked on the adaptation to French of a tool originally developped for a foreign language. Thanks to this work, we could show that classic natural language processing approaches used in grammar checking are not suitable. To remedy it, we suggest an evolution of grammar checkers that includes linguistic principles such as chunking and unification. Despite its efficiency, this evolution is not sufficient to get a good French grammr checker. We are then thinking of a new approach of the problem.</abstract>
			<keywords>grammar checking, chunk, unification</keywords>
		</article>
		<article id="recital-2008-long-014" session="Poster">
			<auteurs>
				<auteur>
					<prenom>Stéphanie</prenom>
					<nom>Weiser</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">MoDyCo, UMR7114, CNRS – Université Paris X, 200 av. de la République, 92001 Nanterre</affiliation>
			</affiliations>
			<titre>Informations spatio-temporelles et objets touristiques dans des pages Web : repérage et annotation</titre>
			<type>long</type>
			<pages></pages>
			<resume>Cet article présente un projet de repérage, d'extraction et d'annotation d'informations temporelles, d'informations spatiales et d'objets touristiques dans des pages Web afin d'alimenter la base de connaissance d'un portail touristique. Nous portons une attention particulière aux différences qui distinguent le repérage d'information dans des pages Web du repérage d’informations dans des documents structurés. Après avoir introduit et classifié les différentes informations à extraire, nous nous intéressons à la façon de lier ces informations entre elles (par exemple apparier une information d’ouverture et un restaurant) et de les annoter. Nous présentons également le logiciel que nous avons réalisé afin d'effectuer cette opération d'annotation ainsi que les premiers résultats obtenus. Enfin, nous nous intéressons aux autres types de marques que l'on trouve dans les pages Web, les marques sémiotiques en particulier, dont l'analyse peut être utile à l’interprétation des pages.</resume>
			<mots_cles>extraction d'information, annotation, informations spatio-temporelles, tourisme, pages Web</mots_cles>
			<title></title>
			<abstract>This paper presents a project for the detection, extraction and annotation of temporal and spatial information and of tourism objects in order to fill the knowledge base of a tourism Web portal. We focus on the differences that exist between extraction from structured documents and extraction from Web pages. First, the different types of information to extract are presented. We then discuss methods for linking these pieces of information together – for example relating the name of a restaurant to its opening hours – and how to annotate the extracted data. The program we have developed to perform the extraction and annotation, as well as an evaluation of this program, are presented here. Finally, we focus on the semiotic marks which appear on the Web and show they also prove useful in interpreting Web pages.</abstract>
			<keywords>information extraction, annotation, spatial &amp; temporal information, tourism, Web pages</keywords>
		</article>
	</articles>
</conference>
