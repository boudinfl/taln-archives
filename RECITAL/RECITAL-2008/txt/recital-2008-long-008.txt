RECITAL 2008, Avignon, 9-13 juin 2008

Transducteurs a fenétre glissante pour l’induction lexicale

Yves Scherrer
LATL, Université de Geneve
Rue de Candolle 5
1211 Geneve 4, Suisse

yVes.scherrer@lettres.unige.ch

Résumé. Nous appliquons différents modeles de similarité graphique a la tache de l’in-
duction de lexiques bilingues entre un dialecte de Suisse allemande et l’allemand standard. Nous
comparons des transducteurs stochastiques utilisant des fenétres glissantes de 1 a 3 caracteres,
entrainés a l’aide de l’algorithme de maximisation de l’espérance avec des corpus d’entraine-
ment de tailles différentes. Si les transducteurs a unigrammes donnent des résultats satisfaisants
avec des corpus tres petits, nous montrons que les transducteurs a bigrammes les dépassent a
partir de 750 paires de mots d’entrainement. En général, les modeles entrainés nous ont permis
d’améliorer la F-mesure de 7% a 15% par rapport a la distance de Levenshtein.

Abstract. We apply different models of graphemic similarity to the task of bilingual
lexicon induction between a Swiss German dialect and Standard German. We compare sto-
chastic transducers using sliding windows from 1 to 3 letters, trained with the Expectation-
Maximisation algorithm on training corpora of different sizes. While the unigram transducers
provide good results with very small corpora, we show that bigram transducers outperform them
with corpora of 750 word pairs or more. Overall, the trained models show between 7% and 15%
F-measure improvement over Levenshtein distance.

M0tS-CléS 2 Induction lexicale, transducteurs stochastiques, langues apparentées.

Keywords: Lexicon induction, stochastic transducers, cognate languages.

1 Introduction

Les ressources lexicales constituent une partie essentielle de tout systeme de traitement auto-
matique des langues. Comme la construction manuelle de telles ressources est fastidieuse et
gourmande en temps, l’induction automatique de ressources lexicales est une alternative parti-
culierement attractive. Dans cet article, nous discuterons différentes approches pour l’induction
d’un dictionnaire bilingue entre un dialecte suisse allemand et la variété standard de l’allemand.

Le choix particulier de cette paire de langues a des consequences importantes sur la methodo-
logie. En Suisse allemande, les dialectes et la variété standard forment une diglossie médiale :
les dialectes sont utilisés a l’oral, tandis que l’allemand standard est surtout utilisé a l’éc1it. A
cause de cette distribution complémentaire, il est difﬁcile de trouver des corpus paralleles, et
généralement des textes écrits en dialecte. Pourtant, l’attitude positive de la population envers
le dialecte et son utilisation généralisée en font un candidat attractif pour le traitement automa-

Yves Scherrer

tique. Ces contraintes relatives a la disponibilité des données placent notre recherche dans le
contexte du traitement de langues peu dotées.

En meme temps, les dialectes alémaniques sont étroitement apparentés a l’allemand standard.
Cette parenté réduit la complexité des relations lexicales a induire. Nos travaux s’inserent donc
dans le courant de recherche du traitement de langues apparentées. Nous soutenons que l’avan-
tage de la parenté étroite est a meme de lever quelques restrictions imposées par la rareté des
ressources. Plus précisément, nous faisons l’hypothese que dans le cas de deux langues appa-
rentées, l’utilisation de techniques d’apprentissage automatique est possible méme si peu de
ressources existent pour l’une d’entre elles.

Nous concevons un dictionnaire bilingue essentiellement comme une liste de paires de mots.1
L’induction de paires de mots se fonde sur un critere de similarité. Théoriquement, cette si-
milarité est d’ordre sémantique : deux mots sont associés dans un dictionnaire s’ils renvoient
au méme concept. Or, il est difﬁcile d’extraire directement les signiﬁcations des mots a partir
de données textuelles brutes. En general, on recourt a des criteres de similarité plus simples
et plus opérationnels, mais néanmoins corrélés avec la similarité sémantique. L’ approche clas-
sique se base sur l’alignement de mots dans un corpus parallele (Brown et al. , 1993) : deux mots
sont considérés similaires s’ils ont une probabilité d’alignement sufﬁsante. Une autre approche
(Rapp, 1999) s’affranchit de corpus paralleles; selon celle-ci, deux mots sont similaires s’ils
apparaissent dans des contextes lexicaux similaires.

Les propriétés particulieres de notre paire de langues nous ont amené a considérer un autre type
de similarité : la similarité graphique. Pour des langues étroitement apparentées, une grande
partie du lexique général est constitué de paires lexicales apparentées (cognate word pairs) : les

mots qui ont la méme signiﬁcation ont également une forme phonétique et graphique similairez.

La similarité graphique a l’avantage de foumir de bons résultats avec peu de ressources. S’il est
possible de l’utiliser sans données d’entrainement, nous montrerons que l’apprentissage auto-
matique avec un corpus de taille modeste améliore nettement les résultats. Nous nous appuyons
sur des recherches récentes dans le domaine de la traduction entre phonemes et graphemes aﬁn
de tenir compte du contexte des lettres lors du calcul de la similarité. Nous nous focalisons sur
les correspondances de mots simples a mots simples.

Apres une discussion des travaux récents dans ce domaine, nous présenterons notre architecture
d’induction lexicale ainsi que les différents modeles implémentés (section 3). Ensuite, nous
décrirons les données utilisées pour l’entrainement et l’évaluation (section 4), suivi par la pre-
sentation et la discussion des résultats obtenus (section 5).

2 Travaux connexes

Les mesures de similarité phonétique et graphique sont utilisées extensivement dans le cadre
du traitement de la parole, aﬁn de transformer des séquences de phonemes en séquences de

1Etant donné la parenté de nos langues, des infonnations morphologiques et syntaxiques, disponibles pour le
cote allemand standard, pourront etre proj etées sur le cote dialecte sans modiﬁcations maj eures.

2Evidemment, l’existence de conventions orthographiques pour les langues en question et la nature de ces der-
nieres peuvent inﬂuencer les résultats de cette méthode. Bien qu’il n’existe pas de conventions orthographiques
obligatoires pour les dialectes suisse allemands, des questions pratiques nous ont amené a utiliser des données
écrites (c’est—a—dire non transcites phonétiquement). Cependant, l’orthographe utilisée est tres proche de la pro-
nonciation.

Transducteurs a fenétre glissante pour l’induction lexicale

lettres et inversement. Dans ce cadre, (Ristad & Yianilos, 1998) introduisent des méthodes d’ap-
prentissage automatique : ils entrainent un transducteur stochastique sans mémoire (a un état)
en utilisant l’algorithme de maximisation de l’espérance (EM). Cet algorithme itératif permet
d’estimer les probabilités des transitions du transducteur stochastique a partir d’un corpus d’en-
trainement contenant des paires de mots corrects.

Le modele de Ristad & Yianilos a été repris pour l’induction de dictionnaires bilingues entre
langues apparentées (Mann & Yarowsky, 2001). L’idée de Mann & Yarowsky est d’étendre un
lexique bilingue existant a une langue apparentée. Par exemple, un lexique anglais-espagnol
peut servir de base pour un lexique anglais-portugais, l’espagnol jouant le role de pivot. Les
mesures de similarité graphique (appelés cognate models) sont utilisées pour apparier les mots
espagnols et les mots portugais. Les auteurs de cette étude font la distinction entre des mesures
statiques, qui sont assez génériques pour étre appliquées a toute paire de langues sans entraine-
ment préalable, et des mesures adaptives, qui sont adaptées a une paire de langues précise. En
particulier, un transducteur stochastique entrainé a l’aide de EM comme mesure adaptive ainsi
que la distance de Levenshtein comme mesure statique. La distance de Levenshtein entre deux
chaines de caracteres est déﬁnie comme le nombre minimal d’opérations d’édition (insertion,
effacement ou substitution d’un caractere) nécessaires pour transformer une chaine dans l’autre.

La distance de Levenshtein et les méthodes basées sur les transducteurs sans mémoire ne
prennent pas en compte le contexte : un seul symbole de l’entrée est comparé avec un seul sym-
bole de la sortie a la fois. Cette approche s’est avérée insufﬁsante dans le cadre de la conversion
entre phonemes et lettres : ph doit étre converti en [t], tandis que X doit étre converti en [ks].
Une solution au premier probleme est l’utilisation d’une fenétre glissante (Jansche, 2001) :
on regarde plusieurs caracteres dans l’entrée pour en générer un seul a la sortie. Une autre
technique, plus sophistiquée, consiste a adapter l’algorithme d’apprentissage pour entrainer des
correspondances plusieurs-a-plusieurs (Jiampojamarn et al., 2007). Cette technique nécessite
un prétraitement du mot source; il faut le couper en morceaux d’une a plusieurs lettres aﬁn de
déterminer les types de correspondances a utiliser. Nous avons montré dans (Scherrer, 2007)
qu’un transducteur basé sur des regles dépendantes du contexte, implémentées manuellement,
obtient de meilleures performances que le transducteur sans mémoire entrainé avec EM.

Les méthodes d’induction lexicale proposées ici s’appliquent aux conﬁgurations linguistiques
dans lesquelles la majorité des paires lexicales se ressemblent graphiquement. Si cette condition
est vériﬁée pour le lexique general de langues apparentées, elle l’est aussi pour des domaines
lexicaux spéciﬁques, indépendamment du degré de parenté des langues. Dans cette optique,
(Claveau & Zweigenbaum, 2005) entrainent un transducteur (non stochastique) pour inférer des
traductions francaises de termes biomédicaux anglais. (Claveau, 2007) étend cette technique a
d’autres paires de langues (par exemple, anglais-russe) et introduit un modele de la langue cible
pour ﬁltrer les candidats lexicaux proposés.

3 Modéles d’induction lexicale

3.1 Les deux étapes de l’induction lexicale

En traduction automatique statistique, il est usuel de partager la problématique en deux taches
distinctes. La traduction d’une phrase doit en effet satisfaire deux conditions principales. Pre-
mierement, son contenu doit rester ﬁdele a la phrase source, et deuxiemement, sa forme doit étre

Yves Scherrer

conforme a la grammaire de la langue cible. La premiere condition est garantie par le modéle
de traduction, la deuxieme par le modéle de langue.

Nous reprenons cette architecture pour l’induction du lexique. Dans une premiere étape, nous
proposons des chaines de caracteres qui restent similaires au mot source. C’est ici que les dif-
férentes mesures de similarité graphique interviennent : elles génerent une suite de chaines de
caracteres, ordonnées par leur taux de similarité graphique par rapport au mot source. Dans
une seconde étape, nous devons garantir que les chaines de caracteres ainsi générées soient
conformes a la langue cible. Pour cela, nous utilisons une liste de mots de l’allemand standard
comme ﬁltre : seules les chaines de caracteres qui sont des mots allemands sont retenues. On
peut donc considérer ce ﬁltre lexical comme un modele de langue binaire. La ﬁgure 1 illustre
cette architecture a l’aide d’un exemple.

3.2 Distance de Levenshtein

La distance de Levenshtein entre deux chaines de caracteres est déﬁnie comme le nombre mi-
nimal d’opérations d’édition nécessaires pour transformer une chaine dans l’autre.3 11 y a trois
types d’opérations d’édition : l’insertion d’un caractere, la substitution d’un caractere par un
autre, et l’effacement d’un caractere. La distance de Levenshtein opere sur des caracteres isolés
sans prendre en compte les caracteres précédents et suivants. Ainsi, elle peut étre implémentée
dans un transducteur sans mémoire (a un état). Par ailleurs, cette mesure de distance est sta-
tique; elle est identique pour toutes les paires de langues. Nous l’utiliserons comme modele de
référence pour nos experiences.

3.3 Transducteurs stochastiques entrainés avec EM

Un transducteur implémentant la distance de Levenshtein possede deux classes de transitions :
les transitions d’édition avec un coﬁt unitaire, et les transitions d’identité (le meme caractere en
entrée et en sortie) avec un coﬁt de 0. Pour des applications linguistiques, cette classiﬁcation
binaire est souvent insufﬁsante. Par exemple, lorsqu’on traduit des mots suisse allemands en
allemand standard, l’insertion de 11 ou de e est beaucoup plus fréquente que celle de m ou de i.
De méme, un a reste plus souvent identique qu’un i1’. Aﬁn de pouvoir prédire de tels phénomenes
spéciﬁques, il nous faut primo un type de transducteur plus souple, permettant d’associer des
poids différents a chaque transition, et secundo un mécanisme d’apprentissage automatique
pour déterminer ces poids. Suivant (Ristad & Yianilos, 1998), nous utilisons un transducteur
stochastique pour satisfaire la premiere exigence, et 1’ algorithme EM pour satisfaire la seconde.4

Dans un transducteur stochastique, toutes les transitions représentent des probabilités. La pro-
babilité de transduction d’une paire de mots donnée est la somme des probabilités de tous les
chemins qui la génerent. L’ algorithme EM sert a trouver les probabilités de transition de sorte a

3Dans cet article, nous utilisons parfois le terme similarite’, parfois le terme distance. Comme les Valeurs de
similarité ou de distance servent seulement a ordonner les candidats générés, le rapport exact entre ces deux notions
ne nous semble pas important : dans ce travail, il nous sufﬁt de pouvoir comparer des listes ordonnées par similarité
décroissante avec des listes ordonnées par distance croissante.

4Pour notre paire de langues, le nombre de transpositions de caracteres est relativement restreint; on peut donc
envisager de créer un transducteur a la main, sans utiliser un algorithme d’apprentissage. (Scherrer, 2007) présente
une telle approche.

Transducteurs a fenétre glissante pour l’induction lexicale

Mot d’entrée Premiére étape Deuxiéme étape
Génération de candidats Filtrage des candidats
vermuetet vermuetet 29.87 vermutet 32. 19
vermutet 32. 19 vermutete 36.08
vermuett 32. 19 vermute 36.65
vrmuetet 32. 19 vermuten 37.69
vermaetet 32.68 vermutetet 39.23
vermuetit 33.41 vermottet 39.41
vermuitet 33.41 vermuteten 39.72
virmuetet 33.41 vermutest 40.57
vermuetent 3 3 .5 1
vermunetet 3 3 .5 1
vnermuetet 3 3 .5 1
vermuetetn 3 3 .5 1
nvermuetet 3 3 .5 1
(10000 candidats)

FIG. 1 — Sortie du modele d’induction lexicale pour le mot dialectal Vennuetet ‘supposé’. Ce
mot doit étre associé au mot allemand standard vermutet (en gras). La colonne du milieu montre
les chaines de caracteres générées a l’aide du modele de similarité graphique. Les chiffres cor-
respondent a des logarithmes négatifs de probabilités, et proviennent du transducteur stochas-
tique a unigrammes (cf. section 3.3). La colonne de droite montre les candidats ayant passé la
deuxieme étape, c’est-a-dire ceux qui sont effectivement des mots allemands.

ce qu’elles maximisent la vraisemblance de générer les paires de mots vues pendant l’entraine-
ment. Cet obj ectif peut étre atteint itérativement en utilisant une liste de paires de mots corrects.
Le transducteur est initialisé avec des probabilités uniformes. En traduisant les paires de mots
de la liste d’entrainement, il compte toutes les transitions utilisées dans ce processus. Ensuite,
les probabilités des transitions sont réestimées selon la fréquence d’utilisation des transitions
comptées auparavant. Ces nouvelles probabilités sont ensuite utilisées dans l’itération suivante.

3.4 Transducteurs £1 fenétre glissante

Le transducteur stochastique présenté ci-dessus ne tient pas compte du contexte graphique des
caracteres. La ﬁgure 1 illustre bien cette propriété : le modele a appris que l’élimination de e est
peu coﬁteuse, mais cette élimination obtient la méme probabilité dans toutes les positions. On
génere ainsi beaucoup de candidats inutiles, car éliminés dans la seconde étape. (J ansche, 2001)
a présenté une solution a ce probleme. Au lieu de fournir au transducteur un caractere a la fois,
il lui fournit également le caractere précédent et le caractere suivant. A partir d’un trigramme
d’entrée, le transducteur doit prédire un seul caractere, celui du milieu. Ce transducteur possede
donc une fenétre glissante de longueur 3. La ﬁgure 2 illustre son fonctionnement.5

Aﬁn de pouvoir conserver l’algorithme d’entrainement simple du transducteur sans mémoire,
nous considérons chaque trigramme comme un symbole primitif. Néanmoins, ce choix aug-
mente considérablement le nombre de transitions a entrainer : avec un alphabet de 11 caracteres,

5Les symboles spéciaux @ et $ sont insérés au début et a la ﬁn du mot aﬁn d’obtenir un nombre sufﬁsant de
trigrammes.

Yves Scherrer

@ve ver erm rmu mue uet ete tet et$

l l l l l l l l l

v e r m u 8 t e t

FIG. 2 — Le meilleur alignement pour le mot vennuetet avec le modele a fenétre glissante de
trigrammes. L’ eliIr1ination du e est conditionnee par le contexte u_t.

@g gu ue et t$ @h hu uu us s$
l l l l l l l l l l
g u 8 t 8 8 h a u s

FIG. 3 — A gauche, le meilleur alignement pour la paire guet — gut ‘bon’ avec un transduc-
teur a bigrammes regressif. Ce type est particulierement bien adapte aux diphtongues dont le
deuxieme element est modiﬁe, comme ue —> u8. A droite, le meilleur alignement pour la paire
huus — Haus ‘maison’ avec un transducteur a bigrammes progressif. Ce type est bien adapte
aux diphtongues dont le premier element est modiﬁe, comme uu —> au.

nous obtenons n2 transitions pour le transducteur traditionnel (a unigrammes), mais n4 transi-
tions pour le transducteur a trigrammes. I-/3tant donne les limitations de nos donnees d’entraine-
ment, nous avons developpe une solution intermediaire, utilisant des fenetres glissante de lon-
gueur 2 (bigrammes). Techniquement, il existe deux variantes de transducteurs a bigrammes :
une variante regressive, generant un caractere en fonction des caracteres courant et precedent,
et une variante progressive, generant un caractere en fonction des caracteres courant et suivant.
La ﬁgure 3 en donne des exemples. Nous avons choisi de combiner les deux variantes pour nos
experiences. Deux transducteurs sont entraines a l’aide du meme corpus, mais avec un biais ini-
tial favorisant soit les transitions de type AB —> B pour la variante regressive, soit les transitions
de type AB —> A pour la variante progressive. Dans la phase d’evaluation, nous utilisons l’union
des resultats des deux transducteurs.6

4 Données et entrainement

Comme evoque dans l’introduction, il est difﬁcile d’obtenir des donnees ecrites en dialecte
suisse allemand. Aﬁn d’eviter les difﬁcultes posees par le manque de regles orthographiques
et par le style tres familier de la plupart des textes, nous avons choisi un livre de litterature en
dialecte bernois.

Les differences linguistiques entre l’allemand standard et le dialecte bernois concernent en
grande partie les voyelles. Selon le contexte, des monophtongues allemands peuvent corres-
pondre a des diphtongues bernois, ou l’inverse. Certains 1' allemands peuvent devenir i1‘ en
bernois, et les e ﬁnaux sont soit elides, soit transformes en 1'. Au niveau des consonnes, les
phenomenes les plus frequents sont l’effacement du 11 ﬁnal en bernois et la vocalisation du 1
preconsonantique devenant u. Nous esperons egalement capter certains phenomenes morpho-
logiques simples comme l’alternance du sufﬁxe diIr1inutif (-chen en allemand standard, -11' en
dialecte bernois).

5L’union a donne des meilleurs résultats que l’intersection, aussi bien au niveau de la precision que du rappel.

Transducteurs a fenétre glissante pour l’induction lexicale

De notre livre bernois, nous en avons extrait les mots sous forme d’une liste. Nous n’avons
pas fait d’analyse morphologique de ces mots; plusieurs formes ﬂéchies du meme lexeme
peuvent donc apparaitre dans la liste. Seules les variantes morpho-phonologiques (phénomenes
de sandhi) ont été éliminées. En plus, le corpus contenait quelques citations en langues étran-
geres et en allemand standard. Ces mots ont également été exclus. Les 4731 mots restants ont
été traduits en allemand standard par l’auteur. Le contexte du mot dans le texte original aidait
a résoudre les ambigu'1'tés de traduction éventuelles. La moitié de cette liste de paires de mots a
été réservée pour l’entrainement des modeles, l’autre moitié pour l’évaluation.7

Dans la partie réservée a l’entrainement, nous avons sélectionné uniquement des paires dont
la distance de Levenshtein était inférieure a 3, aﬁn d’éviter le bruit causé par des paires non
apparentées. Par exemple, nos modeles ne permettent pas de trouver la correspondance entre le
mot bernois himugiiegeli ‘coccinelle’ et le mot allemand standard Man'enkéiferc11en.8 Lorsque
le corpus d’entrainement est relativement petit, il est crucial qu’il ne contienne aussi peu de
bruit que possible. Cet élagage a réduit la taille du corpus d’entrainement de 2365 paires a 1500
paires. De plus, nous avons effectué nos expériences avec des sous-ensembles de ce corpus
contenant 300 et 750 paires de mots. Les modeles ont été entrainés avec EM en 50 iterations.

Le lexique allemand standard, utilisé dans la seconde étape, comporte 202 000 formes. Les
informations morphologiques et syntaxiques présentes dans le lexique n’ont pas été utilisées.

Le corpus de test contient 2366 paires de mots, dont 407 (17,2%) sont identiques en dialecte
et en allemand standard. 565 mots du corpus (23,9%) ne se retrouvent pas dans le lexique
allemand. Meme si ces mots sont correctement induits par le modele de similarité, ils sont
éliminés en seconde étape. Il s’agit avant tout de noms composés, dont certains ont été formés
ad hoc dans le texte littéraire. En plus, quelques mots du dialecte bernois correspondent a deux
mots en allemand standard (par exemple ir — in der ‘dans1a’). Pour des raisons de complexité
computationnelle, nos modeles ne trouvent pas de telles correspondances.

5 Résultats et discussion

Ci-dessus, nous avons présenté notre architecture d’induction lexicale a deux étapes. La pre-
miere étape prend le mot source et génere 10 000 candidats.9 La seconde étape valide les can-
didats qui se trouvent dans le lexique de la langue cible. En général, entre 0 et 20 candidats
sont ainsi validés par mot source. Les coﬁts ou probabilités associés aux candidats lors de la
premiere étape permettent de les ordonner (cf. ﬁgure 1).

Dans un premier temps, nous nous intéressons aux candidats situés en téte de liste. La partie
gauche du tableau 1 montre combien de fois le mot allemand correct se trouve en téte de la liste
des candidats. Le rappel est calculé comme suit :

nombre de paires correctes en premiére position

ra el = _ , _
pp nombre de pazres dans le corpus d ’evaluatz0n

7Les dictionnaires bilingues suisse allemand — allemand standard disponibles sur Internet se limitent en general
aux paires de mots non apparentées. Ils constituent donc un complement intéressant a notre approche, mais ne
peuvent pas servir de point de depart pour l’entrainement de nos modeles.

8Le seuil de 3 est arbitraire; nous l’aVons repris de (Mann & Yarowsky, 2001).

9Cette Valeur est arbitraire. Dans (Scherrer, 2007), nous avons généré seulement 500 candidats. 11 se trouvait
alors que pour beaucoup de mots longs, aucun de ces candidats n’étaitVa1idé dans la seconde étape. Les résultats
rapportés ici ne sont donc pas directement comparables.

Yves Scherrer

Téte de liste Toutes positions
N Précision Rappel F-mesure N Rappel
Levenshtein 725 22,8 30,6 26,1 932 39,4

UnigramInes 300 840 45,8 35,5 40,0 1384 58,5
UnigraInmes 750 859 44,8 36,3 40,1 1441 60,9
Unigrammes 1500 864 45,3 36,5 40,5 1446 61,1
Bigrammes 300 805 32,4 34,0 33,2 1088 46,0
Bigrammes 750 890 39,8 37,6 38,7 1239 52,4
Bigrammes 1500 930 44,4 39,3 41,7 1309 55,3
Trigrammes 1500 394 22,3 16,7 19,0 492 20,8

TAB. 1 — Paires lexicales correctement induites apres la seconde étape. La partie gauche du
tableau montre les résultats pour les paires correctes induites en téte de liste. La partie droite
montre les résultats pour les paires correctes induites toutes positions de liste confondues. Les
chiffres dans la premiere colonne se referent a la taille du corpus d’entrainement. I-/3tant donné
les résultats du modele Trigrammes 1500, nous avons renoncé a indiquer les chiffres des deux
autres modeles a trigrammes. N se refere au nombre absolu de paires induites, les autres chiffres
représentent des pourcentages.

Dans certains cas (surtout avec la distance de Levenshtein), plusieurs candidats se trouvent ex
aequo en premiere position. 11 est donc utile de calculer également la précision :

nombre de paires correctes en premiére position

précision = _ _‘ _ _
nombre de pazres en premzere posztzon

La F-mesure est calculée de maniere standard :

F _ 2 -précision - rappel
_ précision + rappel

La partie gauche du tableau 1 montre que les modeles adaptifs a unigrammes et a bigrammes
donnent de meilleurs résultats que la distance de Levenshtein. En revanche, le modele des tri-
grammes fournit des résultats décevants : la taille du corpus d’entrainement ne sufﬁt visible-
ment pas pour entrainer correctement le nombre élevé de transitions de ce modele. Si la taille
du corpus d’entrainement semble avoir un impact tres léger sur le modele a unigrammes (aug-
mentation de la F-mesure de 0, 4% entre le corpus a 300 paires et celui a 1500 paires), l’impact
est plus prononcé pour le modele a bigrammes (augmentation de la F-mesure de 8,5%). Ce
résultat suggere qu’un corpus plus grand pourrait encore améliorer les performances du modele
a bigrammes, permettant d’obtenir des résultats bien meilleurs que les modeles a unigrammes.

Au lieu d’évaluer seulement les candidats apparaissant en premiere position de la liste, il peut
également étre intéressant de considérer la liste entiere. Par exemple, une architecture étendue
pourrait utiliser des heuristiques (fréquence des mots, contexte syntaxique des mots, ...) pour
réordonner les candidats. Dans ce cas, l’ordre des candidats proposé par le modele de similarité
graphique aurait peu d’importance. On s’intéresserait donc avant tout a ce que le mot correct
se trouve dans la liste, peu importe sa position. La partie droite du tableau 1 montre le nombre
absolu des mots corrects apparaissant dans la liste, ainsi que le rappel.1° Ces chiffres conﬁrment
les caractéristiques globales des modeles. En revanche, le modele des bigrammes ne parvient

1°11 ne nous semble pas pertinent de calculer la précision pour ce cas de ﬁgure.

Transducteurs a fenétre glissante pour l’induction lexicale

pas a égaliser les résultats du modele a unigrammes. La progression des chiffres selon la taille
du corpus d’entrainement suggere cependant que les limites du modele des bigrammes ne sont
pas encore atteintes.

Les performances générales de l’induction lexicale par similarité graphique paraissent assez
faibles. Sur un corpus de 2366 paires, moins de 900 paires peuvent étre induites de maniere
ﬁable sans heuristiques supplémentaires. Mais comme nous l’avons déja évoqué, il est impos-
sible d’obtenir 100% de réussite avec l’architecture choisie. D’une part, 565 paires ne peuvent
pas étre induites parce qu’elles ne sont pas présentes dans le lexique cible. D’autre part, cer-
taines paires de mots sont completement différentes dans les deux variétés linguistiques, et il
est illusoire de les induire avec des mesures de similarité graphique. Si on admet, avec (Mann
& Yarowsky, 2001), que les paires avec une distance de Levenshtein inférieure a 3 sont faciles
a induire, on obtient une borne de 1256 paires de mots présents dans le lexique cible et faciles
a induire. Selon les chiffres se référant a toutes les positions de liste, les modeles a bigrammes
atteignent cette borne, et les modeles a unigrammes la dépassent meme. De plus, on constate
que jusqu’a 70% des paires faciles a induire sont correctement induites en premiere position.

Nous avons expliqué (Scherrer, 2007) que les études précédentes (Mann & Yarowsky, 2001)
obtiennent de bien meilleurs résultats grace a une méthode d’évaluation moins sévere. Cette
méthode consiste a trouver les paires étant donné une liste de 100 mots de la langue source et la
liste (en désordre) des 100 mots correspondants de la langue cible. Ils obtiennent autour de 67%
de réussite sur le vocabulaire espagnol-portugais complet. Avec la meme méthode d’évaluation,
nos modeles atteignent des chiffres entre 85% et 89% avec les unigrammes, et entre 71% et 81%
avec les bigrammes. Sur le vocabulaire des mots apparentés (distance de Levenshtein inférieure
a 3), Mann & Yarowsky obtiennent des chiffres de 92%. Dans cette tache, les performances de
nos modeles a unigrammes eta bigrammes se situent entre 91% et 98%.

6 Conclusion

Nos expériences ont montré que les mesures de similarité graphique peuvent faciliter l’induction
lexicale lorsque les deux langues sont étroitement apparentées. En plus, nous avons montré que
l’utilisation de méthodes d’apprentissage automatique permet d’améliorer nettement les perfor-
mances par rapport a des modeles génériques comme la distance de Levenshtein. Le modele
a unigrammes fournit de bons résultats avec des corpus d’entrainement tres petits. Le modele
utilisant une fenétre glissante de bigrammes permet de faire des prédictions plus ciblées, aug-
mentant ainsi le rappel. Cependant, ce modele nécessite des corpus d’entrainement plus grands
a cause du nombre plus élevé de transitions a entrainer. Nos expériences suggerent que des cor-
pus de plus de 1500 paires de mots pourraient améliorer davantage les performances du modele
a bigrammes. Des recherches futures devraient montrer si tel est le cas. En revanche, le corpus
de 1500 paires s’ est révélé clairement insufﬁsant pour entrainer un modele a trigrammes. I1 reste
a voir si un corpus plus grand permettrait a ce modele de dépasser les performances du modele
a bigrammes.

Nous avons constaté que le lexique de la langue cible, que nous utilisons comme modele de
langue simple, est insufﬁsant, car une grande partie des mots composés ne s’y trouve pas. Pour
remédier a cette lacune, il pourrait étre avantageux de ne pas utiliser ce lexique directement,
mais plutot de maniere indirecte pour créer un modele de langue a n-grammes de lettres, a
l’instar de (Claveau, 2007).

Yves Scherrer

Les résultats suggerent également qu’il peut étre intéressant d’inclure d’autres heuristiques aﬁn
de sélectionner la bonne traduction dans la liste des candidats. En particulier, l’architecture
présentée ici ne tient compte ni de l’information contextuelle riche encodée dans les textes,
ni des informations morphologiques et syntaxiques contenues dans le lexique allemand utilisé
dans la deuxieme étape. L’intégration de ces informations nous parait prometteuse, d’autant
plus que celles-ci sont facilement disponibles pour notre paire de langues. Les méthodes basées
sur la similarité graphique peuvent donc étre utilisées avec proﬁt dans la tache d’induction
lexicale pour des langues apparentées sans pour autant exiger de grandes quantités de données
d’ entrainement.

Remerciements

Nous remercions Paola Merlo pour son soutien et ses commentaires précieux au cours de cette
recherche. Nous aimerions aussi remercier Eric Wehrli pour sa permission d’utiliser le lexique
allemand du projet Fips.

Références

BROWN P. F., PIETRA V. J. D., PIETRA S. A. D. & MERCER R. L. (1993). The mathematics
of statistical machine translation : parameter estimation. Computational Linguistics, 19(2),
263-31 1.

CLAVEAU V. (2007). Inférence de regles de réécriture pour la traduction de termes biomédi-
caux. In Actes de TALN 2007, p. 111-120, Toulouse, France.

CLAVEAU V. & ZWEIGENBAUM P. (2005). Traduction de termes biomédicaux par inférence
de transducteurs. In Actes de TALN 2005, p. 253-262, Dourdan, France.

JANSCHE M. (2001). Re-engineering letter-to-sound rules. In Proceedings of NAACL’01,
Pittsburgh, PA, USA.

J IAMPOJAMARN S., KONDRAK G. & SHERIF T. (2007). Applying many-to—many alignments
and hidden markov models to letter-to-phoneme conversion. In Proceedings of NAACL’07, p.
372-379, Rochester, NY, USA.

MANN G. S. & YAROWSKY D. (2001). Multipath translation lexicon induction via bridge
languages. In Proceedings of NAACL’0I , Pittsburgh, PA, USA.

RAPP R. (1999). Automatic identiﬁcation of word translations from unrelated English and
German corpora. In Proceedings of ACL’99, p. 519-526, Maryland, USA.

RISTAD E. S. & YIANILOS P. N. (1998). Learning string-edit distance. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 20(5), 522-532.

SCHERRER Y. (2007). Adaptive string distance measures for bilingual dialect lexicon induc-
tion. In Proceedings of ACL’07, Student Research Workshop, Prague, République Tcheque.

