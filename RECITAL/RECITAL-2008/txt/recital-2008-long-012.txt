RECITAL 2008, Avignon, 9-13 juin 2008

Une structure pour les questions enchainées

Kévin Séjourné
Université de Paris Sud XI, Limsi-CNRS, BP 133, 91403 Orsay Cedex
Batiment 508
keVin.sejourne@1imsi.fr

Résumé. Nous présentons des travaux réalisés dans le domaine des systemes de questions
réponses (SQR) utilisant des questions enchainées. La recherche des documents dans un SQR
est perturbée par l’absence d’informations sur la valeur a accorder aux éléments de texte even-
tuellement utiles a la recherche d’informations qui ﬁgurent dans les questions liées. Les récentes
campagnes d’évaluation montrent que ce probleme est sous-estimé, et n’a pas fait l’oeuvre de
technique dédiée. Aﬁn d’amé1iorer la recherche des documents dans un SQR nous étudions une
nouvelle méthode pour organiser les informations liées aux interactions entre questions. Celle-ci
se base sur l’exploitation d’une structure de données adaptée a la transmission des informations
des questions liées jusqu’au moteur d’interrogation.

Abstract. We present works realized in the ﬁeld of questions answering systems(SQR)
using chained questions. The search for documents in a SQR is disrupted by the absence of
information on the value to be granted to the possibly useful elements of text in search of
information which appear in bound questions. The recent campaigns of evaluation show that
this problem is under estimated, and did not make the work of dedicated technique. To improve
the search for documents in a SQR we study a new method to organize the information bound
to the interactions between questions. This one is based on the operation of a structure of data
adapted to the transmission of the information of bound questions up to the search engine.

M0tS-CléS 2 Question réponse enchainée.

Keywords: chained question answering.

1 Introduction aux questions enchainées

Les questions enchainées sont des questions destinées a des systemes de questions réponses
classiques, mais qui présentent une difﬁculté supplémentaire. Chaque question doit étre in-

1 011 se trouve la cathédrale Sainte-Sophie en Russie ?

2 Qui était son archiprétre en 1995 ?

3 Quel Ecossais a construit la cathédrale ?

4 Quelle impératrice russe l’a accrédité pour la construire ?

TAB. 1 — Exemple d’un groupe de questions enchainées tirées du corpus utilisées pour la cam-
pagne d’évaluation CLEF 2007.

Kévin Séjourné

_ _ _ _ _;

Collection
(111) ad;
Analyse de la question Traltement des documen
Type ' Ré—' de ti ttri . .
(I) F de 1a [spouse Mom" Sé1e1c]:i0:a on e 2 hstes tnées
Questions 0°“ U , _ (11) de de réponses _ R9P0115°5
Terrnes rehes Selﬂalltlqucl . * — Marquage des EN Fllslo en anglais
ell francais : Relations symtaxiques : I recherche (3)

  ¥erbe pﬁncipal : : Extraction de la réponse
. I errnes , . _
! 5 , . Pondération des phrases
E  Questions : : T°TmeS_ Extraction de la réponse
 {99.%2$1%_i§ Traduction <- — -' :°“*‘"g1‘‘‘S 0’)
I

-_.._.._.._.._.> en anglais

FIG. 1 — Architecture du systeme Musclef en mode inter-lingue

terprétée en connaissance de l’historique des questions et des réponses précédentes. 11 y a eu
récemment plusieurs campagnes d’évaluation de systemes de questions réponses (SQR) ou des
questions enchainées étaient proposées. Selon les corpus, les questions enchainées peuvent faire
référence a un contexte global (ou sujet global) préalablement introduit comme ce fut le cas dans
la campagne d’évaluation TREC (Zhou et al., 2006). Elles peuvent aussi faire référence aux ré-
ponses précédentes ou avoir de multiples références vers d’autres questions. Les questions en-
chainées peuvent présenter toutes ces difﬁcultés sans les annoncer explicitement, comme dans
la campagne d’évaluation des SQR Clef07 (Penas et al. , 2007) ; la premiere question peut meme
parfois avoir le r6le d’un introducteur de contexte. Le tableau 1 montre un exemple de groupe
de questions enchainées. Parfois les SQR sont inter-lingue, cela signiﬁe que la langue des do-
cuments est différente de la langue des questions, comme c’était le cas pour une des pistes de
la campagne Clef07. C’est le corpus de cette campagne que nous utilisons par la suite.

Le systeme Musclef (ﬁgure 1) développé au Limsi a globalement une architecture semblable
aux SQR classiques. Le probleme que nous nous posons est alors de savoir comment organi-
ser les informations des questions précédentes pour que celles-ci puissent étre utilisées pour
améliorer la recherche de la réponse ?

Dans la suite de notre article, nous proposons les déﬁnitions suivantes 2

Terme 2 Un terme est un mot ou un groupe de mots considéré lors de l’interprétation de la question et
donc jugé pertinent par rapport a des ressources dont nous disposons (documents, dictionnaires, questions
précédentes ...). Ainsi les termes de la premiere question du tableau 1 sont «la cathédrale Sainte-Sophie»
et «en Russie».

Elément utile 51 la recherche d’inf0I'mati0n (RI) 2 Un élément utile 51 la RI peut étre de plusieurs
natures 2 cela peut étre un groupe de termes d’une question, de réponse ou des résultats intermédiaires
de calcul d’un SQR. Par exemple, la catégorie de la réponse est un élément. Les éléments de la premiere
question sont les termes «la cathédrale Sainte-Sophie», «en Russie», la catégorie de la question «lieu»,
et la réponse «Novgorod».

Dépendance d’un couple question/réponse vers un autre 2 Une dépendance d’un couple QR
vers un autre est un lien hiérarchique lexicall syntaxiquel sémantiquel pragmatique nécessaire a la bonne
résolution d’une question. Les dépendances Vont d’une paire question/réponse vers une autre paire ques-
tion/réponse. La question 2 du tableau 1 dépend de la 1 2 Cette dépendance a pour origine le mot «son»,
qui renvoie a un attribut d’un objet précédemment évoqué. Comme il n’y en a pas dans la question 2, il
s’agit de la question 1 ; la question 3 dépend de la 1 ; la question 4 dépend de la 3 mais pas directement
de la 1, un élément est manquant pour cette résolution. Par contre, les dépendances sont transitives 2 4
hérite de la dépendance de 3 vers 1.

Une structure pour les questions enchainees

Contexte (d’une question d’un groupe) : Un contexte est un groupe d’elements relies Via des
dépendances. C’est l’ensemble de tous les elements utiles a la RI pour la resolution d’une question en
tenant compte des questions auxquelles elle est liee. Pour considérer un contexte possible d’une question
il faut les elements de chaque couple question/réponse obtenu en suivant les dépendances de tous les
couples question/réponse qui la precedent dans le groupe.

Notre probleme peut alors se reformuler ainsi : Si nous considerons que les donnees issues
des dependances peuvent ameliorer la recherche de la reponse, comment structurer le contexte
pour que cette recherche soit plus efﬁcace ? Chiori et Al. (Chiori et al., 2003 4) rencontrent
ce probleme dans leur systeme de question reponse interactif ecrit/oral, mais lui apportent une
solution basee sur une interrogation de l’utilisateur. 1

Dans la litterature on trouve essentiellement trois approches possibles :

1) Ajouter les elements de la question liee au texte de la nouvelle question et mettre en entree
d’un SQR classique.

Cela revient a modiﬁer les questions au niveau du point I de la ﬁgure 1. I1 faut alors disposer
d’un systeme capable d’assurer que la jointure sera realisee correctement. I1 faut aussi pouvoir
gerer les differentes formulations et interpretations, et dans tous les cas disposer d’un module de
plus pour ne pas oublier le type attendu de la reponse ou d’autres elements pertinents. Souvent
l’ensemble est mal formule et donc mal analyse. La question «Quelle imperatrice russe l’a
accredite pour la construire ?» peut se re-ecrire de nombreuses manieres.2

— Ajout a la ﬁn avec separation du contexte par un ’ ;’ : Quelle impératrice russe l ’a accrédité pour

la construire ; [im] écossais, Vladimir [oﬂde] Novgorod, cathédrale Sainte-Sophie Russie ?
— Uniﬁcations syntaxiques des éléments : Quelle impératrice russe a accrédité [[im] écossaisl Vladimir
[oﬂde] Novgorod] pour construire la cathédrale [Sainte-Sophie [en Russie]] ?

Cette approche est limitee an ce que l’on peut re-structurer dans une phrase sans trop perturber le
systeme d’analyse de la question. Pour les systemes de QR inter-lingues il faudrait aussi prevoir
de traduire la reponse.

2) Ajouter les elements de la question liee directement dans la structure des termes destines au
moteur de recherche.

C’ est a dire au niveau du point II de la ﬁgure 1. Les termes composant les elements de la question
liee sont alors meles a ceux de la nouvelle question (Buscaldi et al., 2007). La structure envoyee
au moteur de recherche est une structure qui contient notamment le resultat de la resolution
des anaphores. Cependant, cet ajout ne permet pas de faire de distinction entre ce qui vient
de la question courante ou de la precedente. Dans le groupe du tableau 1, apres la resolution
d’anaphores, il n’est plus possible de savoir que l’element de texte «cathedrale Sainte-Sophie
Russie» provient de la premiere question. 11 est possible d’avoir simultanement deux documents
dans lesquels on trouve qu’un ecossais a construit quelque chose et un autre dans lequel on
trouve qu’une personne a construit une cathedrale en Russie. Mais il est possible que l’on ne
dispose pas de documents parlant simultanement d’ecossais, de cathedrale et de Russie.

Quel poids accorder a ces differents elements quand on ne sait pas d’o1‘1ils viennent ?

1La solution examine un score d’ambigiiite structurelle d’une question pour determiner de nouvelles questions
de desambigiiisation. Puis l’utilisateur est cense y repondre correctement pour apporter des infonnations dont les
dépendances inter question—reponse peuvent etre correctement resolues.

2«Vladimir of Novgorod» est la réponse de Musclef a la question 3 du tableau 1.

Kévin Séjourné

Par exemple : dans le contexte de la cathédrale de Novgorod, dans l’ensemble des documents
de clef 2007, i1 était possible de trouver le nom d’un personne ayant construit la cathédrale3.
Mais rien ne conﬁrme ou n’inﬁrme que cette personne soit de nationalité écossaise4.

Ce n’est donc pas satisfaisant, si en plus les groupes de questions forment des séquences ou les
éléments de texte sont repris implicitement ou avec une variation/oubli partielle, cette approche
conduit a une perte de performance proportionnelle a la longueur des séquences de questions.

3) Réaliser une premiere recherche sur la premiere question.

Cette premiere question déﬁnit le contexte du groupe. Puis réaliser les recherches suivantes uni-
quement sur l’ensemble de documents trouvés lors de cette premiere recherche (Zhou et al.,
2006; Hickl et al., 2006). On réduit a chaque question la collection utilisée au niveau du point
III de la ﬁgure 1. On peut remarquer qu’avec cette stratégie, une question dépendant de 11 autres
dispose alors d’un ensemble de recherche réduit n fois. Il n’y a aucun moyen de re-ouvrir l’es-
pace de recherche. Pour des séquences de questions avec des dépendances, cette stratégie n’est
pas généralisable. Par exemple, imaginons que dans le groupe présenté en exemple nous ayons
déja analysé les dépendances entre questions et que l’on puisse restreindre l’étude a la séquence
de questions 1 3 4. La résolution de la question 4 se fera sur les seuls documents qui parlent de
«cathédrale Sainte-Sophie en Russie» et d’«Ecossais>>. Si la réponse est dans un document lié
au nom de l’Ecossais seul sans sa nationalité, alors la réponse ne sera pas trouvée.

Dans les SQR, les documents sont généralement découpés en paragraphes de taille équivalente
avant leur indexation. L’ impact de la taille des paragraphes est évidemment tres important. Trop
gros ils ne restreignent pas sufﬁsamment la recherche, et la seconde question est traitée presque
’hors contexte’. Trop petits ils la restreignent trop, et il n’y plus assez d’information autour
de la réponse. Pour trouver une taille de paragraphe adaptée aux questions enchainées, il fau-
drait aussi que les questions réferent toujours a des informations proches dans les paragraphes
des documents réponses des premieres questions. Il faut aussi que cette proximité puisse étre
quantiﬁée aﬁn de déﬁnir la taille adaptée des paragraphes.

Dans les 3 approches présentées ci-dessus, les éléments ont la méme importance, ce qui pose de
probleme et ne permet pas une recherche efﬁcace. Aucune de ces stratégies n’est satisfaisante.
Plus généralement, la quantité d’éléments pour une recherche unique augmente linéairement
avec la profondeur des dépendances entre questions. Le probleme se pose pour le choix des ele-
ments : ne prendre que ceux de la question ? ou prendre tous ceux de toutes les questions liées ?
C’est un probleme de controle du bruit par rapport au silence dans le nombre de documents
retoumés par le moteur de recherche.

Dans un groupe de questions enchainées, les contraintes sur la recherche d’informations sont les
dépendances entre questions ainsi que la structuration des ensembles de termes en éléments et
contextes. Ainsi, nous voulons proposer une nouvelle structure permettant de lier les contraintes
classiques de recherche d’informations (les termes), a des contraintes concemant l’ordre dans
lequel ces termes peuvent étre relaxés en cas de silence trop important. Nous pouvons donc obte-
nir des contraintes sur la maniere de relaxer d’autres contraintes. L’ utilisation de cette structure
suppose de concevoir une stratégie de relaxation qui soit adaptée au domaine d’application du
SQR. Toute relaxation de contraintes sera alors réalisée en tenant compte des performances de
la recherche. Une recherche plus performante po11rra étre mise en place et une justiﬁcation des

3Vladi1nir of Novgorod, cf Article wikipedia anglais <<Saint_Sophia_Cathedra1_in_Novgorod» et
«Church_of_Scotland» de la cathédrale sainte—sophie de Novgorod

4Une analyse pragmatique approfondie avec un moteur d’inférence aurait peut—étre trouvé la nationalité de cette
personne.

Une structure pour les questions enchainées

(Du se trouve la <§.thedra1dSainte—Sophie en Russie ‘.7

    

Quel ecossaisvl
u.i_ eta.i_t son ar_chi retre_en _1_995 ‘.7
1_koa.1 L’vov1ch se1-p1tsk11

construjt la cathedrale ‘.7
‘rnjr of Novgorod

   
 
   

Quelle irnperatrice a accredite pour la construire ‘.7
Nil

FIG. 2 — L’ arbre correspondant au groupe du tableau 1

termes choisis foumie a l’utilisateur. Dans le cas idéal, nous sommes aussi convaincus que les
SQR capables de résoudre des questions enchainées de cette maniere sont une étape vers des
systemes de dialogue homme-machine en domaine ouvert.

Nous voulons donc créer une structure qui permet de représenter les dépendances d’un groupe
aﬁn d’améliorer la recherche dans les documents. Nous nous intéressons plus particulierement
a la partie structure et organisation du probleme. C’est ce que nous allons présenter maintenant.

2 Construction de la structure du contexte

Nous avons voulu construire une structure pour représenter plus ﬁnement les dépendances. Nous
allons maintenant préciser cette structure et expliquer une méthode de construction. Nous ana-
lyserons alors sa performance a trouver ces dépendances. En s’inspirant des travaux sur les
structures de dialogue (Vilnat, 2005), de la nature séquentielle des groupes de questions et du
partage des terInes des questions déja résolues du groupe, nous choisissons d’organiser la struc-
ture du contexte d’un groupe de questions en un arbre (ﬁgure 2).

2.1 L’organisation

La structure du contexte est un arbre, a sa racine on trouve le contexte commun a toutes les ques-
tions. Chaque branche est constituée d’un arbre de paires question/réponse. A chaque noeud
sont indiqués la question et son contexte. Ce sont les dépendances qui encodent la structure de
l’arbre. Le contexte est composé d’une liste d’éléments faisant éventuellement reference a un
noeud réponse.

La structure d’arbre nous permet de représenter efﬁcacement les groupes ou les questions ne re-
prennent que le contexte issu de la premiere question. L’ ajout des éléments d’informations utiles
a la recherche d’information a chaque noeud permet une représentation homogene des groupes
ou les questions réutilisent des contextes liés les uns aux autres. Les questions ne réutilisant pas
le contexte des précédentes sont rattachées au noeud groupe. Ce noeud groupe peut également
recevoir des éléments aﬁn de contraindre l’espace de recherche a la maniere des évaluations de
T rec 2006 5 (Hickl et al., 2006).

5Un contexte était donné explicitement pour chaque groupe de questions.

2.2 La construction Kevin Sejourne

2.2 La construction

Nous appelons dependance unitaire un chemin de longueur 1 dans l’arbre de dependance. Pour
detecter des dependances, nous combinons un ensemble de criteres linguistiques concemant
une dependance unitaire. La combinaison de criteres donne un score de ﬁabilite d’existence
(cf 2.2.2) de cette dependance. Il est possible d’ajouter autant de criteres que l’on veut aﬁn
d’ameliorer la detection. La formalisation en dependances unitaires nous permet donc d’obtenir
une resolution multi-critere qui n’est pas dependante d’un concept linguistique sous-jacent.
Chaque critere retourne un unique score pour un couple de questions. C’est la valeur de ce
score qui permet de determiner l’existence d’une dependance entre 2 questions.

2.2.1 Criteres utilisés pour construire les vecteurs de scores

L’ algorithme generique de creation d’arbre de dependances tient compte d’un nombre quel-
conque de criteres linguistiques. Nous avons utilise les 4 criteres suivants pour illustrer sa Inise
en oeuvre et realiser des tests.

1) Les categories6 des questions detectees par Musclef. Si deux questions ont des catego-
ries(Ligozat, 2006) identiques il a beaucoup de chance qu’il n’y ait pas de dependances de
l’une vers l’autre :

Citer le nom d ’urt alimertt corttenu darts le regime alimerttaire de base d ’Asie du sud—est.

Citer le nom d ’urt alimertt contenu darts le regime alimerttaire de base d ’Europe.

Les categories sont identiques, et n’ont donc pas de lien.

2) La presence d’anaphores inter-questions. Un systeme de resolutions developpe au labora-
toire7, permet d’associer des elements d’une question a l’autre. Celui-ci utilise essentiellement
un dictionnaire pour determiner le genre et le nombre des elements et referents pour les com-
parer. Les referents sont calcules via des criteres morpho-syntaxiques inclus dans une mini-
grammaire. Une anaphore inter-questions indique une dependance entre 2 questions.

3) La longueur relative d’une question par rapport a une autre. Une question avec moins de
caracteres reintroduit probablement moins d’elements et vraisemblablement reutilise plus les
elements deja introduits. Comme c’est une mesure de l’entropie relative entre 2 questions, seules
les differences importantes sont signiﬁcatives, comme dans l’exemple suivant :

Quel e’tait le nom de la barge qui a coule’ a Porto Rico le 7 jartvier I994 ?

Qu’a heurte’ la barge ? Les mots, a cause de leur plus faible nombre relativement aux caracteres et
a cause de leur capacite d’agregation de sens ne forment pas un bon candidat pour construire un
critere de score de dependance.

4) Les entites nommees identiques d’une question sur l’autre. Ce critere a tendance a montrer
que les 2 questions ne sont pas liees, au contraire la repetition partielle d’une EN8 dans une
question indique plut6t une dependance vers la question dans laquelle elle est complete.

De quel instrument Swarm jouait-il dans le duo ’Flartders et Swarm’ ?

Dans quel pays Swarm est—il rte’ ?

Dans quelle ville Swarm est-il mort ?

Nous allons maintenant voir comment ces criteres sont utilises.

5Dans Musclef chaque question a une categorie. Celle—ci permet de connaitre le type de la reponse attendue.
7inspire des travaux de (Hernandez, 2004)
sentite nommee

Une structure pour les questions enchainees 2.2 La construction

Num quest 1 2 3 1 2 3
2 [1,1,0,0] X X [7,8,0,0]—> 15 X X
3 [1,1,0,0] [1,0,0,0] X [7,8,0,0]—> 15 [7,0,0,0]—> 7 X
4 [1,1,0,0] [1,0,0,0] [0,2,0,0] [7,8,0,0]—> 15 [7,0,0,0]—> 7 [0,16,0,0]—> 16

TAB. 2 — Les criteres sont [cate’g0rie, lien anaphorique, taille,entite’ nommée]. Premiere partie :
Les vecteurs de scores pour le groupe en exemple. Seconde partie : Les vecteurs de scores apres
ponderation et projection.

2.2.2 Un algorithme £1 6 étapes

A chaque combinaison de deux questions d’un groupe est associe un vecteur de scores. Dans
l’etape 1 nos vecteurs sont ceux du tableau 2(premiere partie) pour le groupe en exemple du
tableau 1. Le vecteur de la case (1,2)=[1,1,0,0] indique que seules une difference de categorie
et une anaphore ont ete trouvees, entre les questions 1 et 2.

La seconde etape consiste a projeter chaque vecteur sur une valeur unique apres harmonisation
de leurs composantes. La projection se fait selon une somme ponderee par l’efﬁcacite a priori
de chaque critere linguistique. La normalisation corrige les resultats pour tenir compte des taux
d’erreurs differents. La projection est alors une somme ponderee de chaque composante. L’ har-
monisation utilisee dans notre implementation est [0.5,0.4,1,1] ; elle est calculee par rapport a la
valeur maximum d’un critere. Par exemple, la valeur maximum que donne le critere des catego-
ries9 est 2. L’ harmonisation pour ce critere est donc de «1/2». La ponderation utilisee dans notre
implementation est [14,20,5,-5], elle est choisie par rapport a la conﬁance a priori en chaque
critere. On obtient alors les donnees du tableau 2(seconde partie). Le vecteur de la case (1,2)
devient donc [0.5x14x1, 0.4x20x1, 1x5x0, 1x-5x0] soit une somme de 15.

A la troisieme etape chaque valeur est convertie en une probabilite d’existence d’une depen-
dance unitaire. Le programme utilise la valeur du score maximum possible du systeme pour la
totalite de ces criteres aﬁn de calculer la conﬁance dans les associations. On en deduit la pro-
babilite d’existence d’une dependance unitaire. Les valeurs harmonisees-ponderees-extremums
sont donnees par le vecteur [7,24,5,-5]. La valeur maximum pour les calculs de probabilite
d’existence est donc 7x1 + 24x1 + 5x1 + -5x0 = 36.10

A la quatrieme etape on utilise une valeur limite choisie a l’avance a l’aide d’un apprentissage
supervise. Cette valeur permet d’eliminer les combinaisons a scores trop faibles (dans notre
exemple il s’agit des scores qui lui sont inferieurs). Cette valeur limite est calculee a partir des
resultats de l’etape 3 et des dependances encodees sous la forme ’I .' existe ’ et ’0 .' existe pas’
prealablement annotee. Les combinaisons ’2-3’ et ’2-4’ sont oubliees dans l’exemple. Dans
notre implementation, les 122 questions situees en rang 2 et plus d’un groupe ont recu un score
qui a ete compare aux 92 dependances annotees (cf 2.2.3). Nous avons alors cree une table qui
indique pour chaque score l’existence ou non d’une dependance. Le systeme weka (Frank et al. ,
2005) nous a permis de deployer facilement un outil de classiﬁcation statistique nous permettant
alors d’evaluer une valeur limite.

La cinquieme etape consiste a comparer les combinaisons restantes. Si deux combinaisons ont
la meme question pour origine, celle de plus faible score est eliminee. Ceci garantit qu’une
question ne reutilise le contexte que d’une seule autre question qui eventuellement aura construit

9Les categories sont comparees sur deux niveaux de similarites : «deﬁnition-personne» <<deﬁnition—autre»
1°Les projections dont la valeur est negative sont supprimees, il n’y a donc pas de probabilite’ négative.

2.2 La construction Kévin Séjourné

son contexte sur celui d’une précédente. Cette étape est réalisée en utilisant le maximum de
chaque ligne. On obtient donc ’I-2’, ’1-3’ et ’3-4’.

La sixieme étape construit l’arbre apres un tri topologique des dépendances unitaires. Le tri
topologique donne 2 ordres valides (et donc deux arbres).

—l—.—. —l—.————.
2 3-. 3-. 2
4 4

Le premier est toujours choisi, car il respecte l’ordre d’introduction des questions. Pour un
groupe de questions donné, la structure arborée n’est pas forcément unique. Si une question
’1’ introduit les elements A et B. Si une question ’2’ réutilise uniquement l’élément A et que
la question ’3’ réutilise les elements A et B. Alors, il est possible de rattacher la question ’3’
soit a la question ’1’ (Stratégie de la premiere introduction d’un élément), soit a la question
’2’ (Stratégie de la déﬁnition la plus récente d’un élément). Si on ne dispose pas de criteres
sémantiques/pragmatiques, l’élément peut étre décrit par les memes mots, mais correspondre a
des sens différents. Etant donné le type des questions posées il peut étre intéressant de privilégier
la stratégie de la premiere introduction, alors que sur un systeme de dialogue on préferera peut-
étre la demiere aﬁn d’avoir une représentation plus concise ne demandant pas de mémorisation
des évenements anciens.

On peut alors décorer l’arbre avec les éléments, contextes, réponses et vecteur de scores. Les
éléments de texte utiles sont repérés via un mécanisme basé sur la morpho-syntaxe. Ils sont
constitués des noms, adjectifs, nombres et déterminants les entourant. L’ analyse des questions
de Musclef permet de s’assurer que les constituants formant le focus (Ferret et al., 2001)“ de
la question sont présents dans les éléments reconstruits. De méme, les entités nommées sont
arbitrairement ajoutées dans la liste des éléments. Chaque élément produit est un sous ensemble
contigu de la question et tous les sous éléments contigus sont fusionnés. Une fois l’arbre de
dépendances construit, chaque élément de texte d’une question est traité exactement de la meme
maniere que dans un SQR normal. On utilise juste une numérotation des termes des éléments
aﬁn de les suivre dans les étapes de sélection de mots, traduction... Les termes des éléments sont
récupérés juste avant leur utilisation dans le moteur de recherche. Le vecteur de scores est aj outé
aﬁn de caractériser le type de dépendance entre les questions. Les réponses aux questions sont
ajoutées ainsi que leur type (type de la réponse attendue de la question précédente).La ﬁgure 3
montre cette structure pour le groupe de 4 questions de l’exemple en tableau 1.

\

A l’aide de cette organisation, on peut concevoir une nouvelle interrogation des documents
tenant compte de l’origine des éléments.

2.2.3 Résultats

Le corpus de questions de la campagne Clef2007 a été annoté a la main. Nous avons annoté
un total de 92 dépendances unitaires 12. Nous avons évalué notre approche sur ce corpus en
comparant les dépendances unitaires annotées a celles trouvées automatiquement.

“Le focus d’une question : une phrase nominale qui a des chances d’etre présente dans la réponse : Qui est le
mjnistre ? «Le ministre» est 

12Nous pouvons remarquer ici une difference avec l’étude réalisée par Dominique Laurent et Al.(Laurent et al.,
2007) qui comptent 76 questions disposant d’un lien anaphorique. Comme mentionné plus haut nous ne nous
arretons pas aux anaphores coréférentes.

Une structure pour les questions enchainees 2.2 La construction

Groupe 97-100 (Corpus clef O7 FR—EN)

I

I contexte

I

‘——. Numéro : 97
Question : on se trouve la cathédrale Sainte—Sophie en Russie ?
Réponse : Novgorod
#é1éments réutilisables : 0

I
I
I
I contexte
I
\

—. Numéro : 98
I I Question : Qui était son archipretre en 1995 ?
I I Réponse : Nikoai L’vovich Tserpitskii
I I #é1éments réutilisables : 1
I I contexte : «la cathédrale Sainte—Sophie en Russie»
I I scores : [7,8,0,0]
I
‘—. Numéro : 99
I Question : Quel écossais a construit la cathédrale ?
I Réponse : Vladimir of Novgorod
I #é1éments réutilisables : 1
I contexte : «sainte—Sophie en Russie»
I scores : [7,8,0,0]
I
‘—. Numéro : 100
I Question : Que11e impératrice 1’a accrédité pour la construire ?
I Réponse : ni1
I #é1éments réutilisables : 2
I contexte : «écossais» «Réponse(99)»
I «la cathédrale sainte—Sophie en Russie»
I scores : [O,16,0,0]

FIG. 3 — La structure d’arbre pour un groupe de questions enchainees.

cat.. cat.. Les

F-Mesure

 

TAB. 3 — Les performances de decouverte automatique de dependances unitaires.

Les 4 criteres utilises simultanement permettent une detection des dependances unitaires dont
les performances sont recapitulees dans le tableau 3, pour la detection des 92 dependances du
corpus. Des etudes individuelles de chaque critere montrent qu’ils ameliorent tous les resultats.
Les deux plus efﬁcaces sont la detection des anaphores et les differences de categories. Cepen-
dant, les 2 autres criteres peuvent etre afﬁnes et d’autres pourraient etre envisages, incluant des
elements syntaxiques et/ou semantiques.

En premiere approche pour l’utilisation des informations calculees precedemment, nous avons
ajoute les termes du contexte a la liste des termes des questions ayant des dependances, sans
controler un seul des problemes qui motive la construction de la structure. Nous avons pu ob-
server que dans 48 cas nous obtenons des phrases candidates la o1‘1 sans la methode de selection
nous n’en obtenons aucune. Nous pouvons aussi observer que le deploiement de la methode
proposee est robuste a la traduction des termes dans les systemes inter-lingue. Ceci nous incite
a penser que nos resultats de selection des dependances sont tres corrects.

Kevin Sejourne

3 Conclusion

Notre travail permet d’etablir des dependances entre questions. Dans le cas general, ces depen-
dances sont problematiques. Nous obtenons donc ainsi des resultats encourageants qui montrent
des progres dans l’OrganisatiOn des dependances liant les elements pour l’interrOgatiOn. La pro-
chaine etape de ce travail consiste a modiﬁer l’interrOgatiOn des documents aﬁn d’uti1iser au
Inieux cette structure d’arbre, dans le but d’ameliOrer les resultats du SQR sur des questions
enchainees.

Des evolutions sont possibles : On pourrait prOlOnger cette structure jusque dans le systeme de
selection des reponses du SQR. I1 serait alors interessant d’etudier comment la selection des
reponses (et l’analyse des questions) pourrait s’appuyer sur cette structure, et comment fournir
des elements visant a faciliter la recherche de la reponse de la question suivante grace a cela.

Références

BUSCALDI D., ANND PAOLO ROSSO Y. B. & SANCHIS E. (2007). The upv at qa@clef 2007.
Universidad Politcnica de Valencia.

CHIORI H., TAKAAKI H., HIDEAKI 1., EISAKU M. & ANDFURUI SADAOKI K. S. (2003—4).

Study On spoken interactive open domain question answering. Spontaneous Speech Processing
and Recognition (SSPR), p. 111-114.

FERRET 0., GRAU B., HURAULT—PLANTET M., MONCEAUX L., ROBBA I. & VILNAT A.
(2001). Finding an answer based On the recognition Of the question focus. Text retrieval
conference, TREC I0.

FRANK E., HALL M. A., HOLMES G., KIRKBY R., PFAHRINGER B., WITTEN I. H. &
TRIGG L. (2005). Weka - a machine learning workbench for data mining. In 0. MAIMON
& L. ROKACH, Eds., The Data Mining and Knowledge Discovery Handbook, p. 1305-1314.
Springer.

HERNANDEZ N. (2004). Description et de’tection automatique de structures de
texte. PhD thesis, University de Paris-Sud XI LIMSI/CNRS. http :// www.limsi.fr
/Individu/hemandz/researchﬂ-Iernandez-these.tar.gz.

HICKL A., WILLIAMS J ., BENSLEY J ., ROBERTS K., SHI Y. & RINK B. (2006). Question
answering with lcc’s chaucer at trec 2006. 15th Text REtrieval Conference, Gaithersburg, p.1.

LAURENT D., SEGUELA P. & NEGRE S. (2007). Cross lingual question answering using
qristal for clef 2007. Synapse De’veloppement.

LIGOZAT A.-L. (2006). Exploitation et fusion de connaissances locales pour la recherche
d ’informations pre’cises. PhD thesis, Universite de Paris-Sud XI LI1VISI/CNRS. .

PENAS A., FORNER P. & GIAMPICCOLO D. (2007). Guidelines for participants in qa at clef
2007. CELCT Trento(IT) and UNED, Madrid, p.1.

VILNAT A. (2005). Habilitation a diriger les recherches .' Dialogue et analyse de
phrases. PhD thesis, University de Paris-Sud XI LI1VISI/CNRS. http :// www.limsi.fr [In-
dividu/anne/I-IDR/MemOireHDR.pdf.

ZHOU Y., YUAN X., CAO J ., HUANG X. & WU L. (2006). Fduqa On trec2006 qa track. 15th
Text REtrieval Conference, Gaithersburg, p. 1026-1033.

