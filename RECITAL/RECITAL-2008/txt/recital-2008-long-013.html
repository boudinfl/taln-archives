<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Vers une nouvelle approche de la correction grammaticale automatique</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>RECITAL 2008, Avignon, 9&#8211;13 juin 2008
</p>
<p>Vers une nouvelle approche
de la correction grammaticale automatique
</p>
<p>Agn&#232;s Souque
Laboratoire LIDILEM - Universit&#233; Stendhal - Grenoble 3
</p>
<p>1491 rue des R&#233;sidences
38040 Grenoble Cedex 09
</p>
<p>asouque@gmail.com
</p>
<p>R&#233;sum&#233;. La correction grammaticale automatique du fran&#231;ais est une fonctionnalit&#233; qui
fait cruellement d&#233;faut &#224; la communaut&#233; des utilisateurs de logiciels libres. Dans le but de
combler cette lacune, nous avons travaill&#233; &#224; l&#8217;adaptation au fran&#231;ais d&#8217;un outil initialement
d&#233;velopp&#233; pour une langue &#233;trang&#232;re. Ce travail nous a permis de montrer que les approches
classiques du traitement automatique des langues utilis&#233;es dans le domaine ne sont pas ap-
propri&#233;es. Pour y rem&#233;dier, nous proposons de faire &#233;voluer les formalismes des correcteurs
en int&#233;grant les principes linguistiques de la segmentation en chunks et de l&#8217;unification. Bien
qu&#8217;efficace, cette &#233;volution n&#8217;est pas suffisante pour obtenir un bon correcteur grammatical du
fran&#231;ais. Nous envisageons alors une nouvelle approche de la probl&#233;matique.
</p>
<p>Abstract. Free software users community is sorely lacking French grammar checking.
With the aim of filling this gap, we have worked on the adaptation to French of a tool ori-
ginally developped for a foreign language. Thanks to this work, we could show that classic
natural language processing approaches used in grammar checking are not suitable. To remedy
it, we suggest an evolution of grammar checkers that includes linguistic principles such as chun-
king and unification. Despite its efficiency, this evolution is not sufficient to get a good French
grammr checker. We are then thinking of a new approach of the problem.
</p>
<p>Mots-cl&#233;s : correction grammaticale, syntagme, unification.
</p>
<p>Keywords: grammar checking, chunk, unification.
</p>
<p>1 Introduction
</p>
<p>Dans le domaine de la correction grammaticale automatique, les outils existants sont g&#233;n&#233;rale-
ment des logiciels propri&#233;taires aux co&#251;ts d&#8217;int&#233;gration &#233;lev&#233;s, qui sont peu ou pas d&#233;crits dans
la litt&#233;rature, et ferm&#233;s &#224; toute am&#233;lioration externe. Nos travaux de recherche visent donc &#224;
d&#233;velopper un outil de correction grammaticale libre pour le fran&#231;ais, dont les ressources lan-
gagi&#232;res seront accessibles et modifiables, et dont le formalisme g&#233;n&#233;rique le rendra facilement
adaptable &#224; d&#8217;autres langues.
</p>
<p>Dans (Souque, 2007), nous avons &#233;tudi&#233; plusieurs correcteurs libres existant dans des langues
&#233;trang&#232;res. L&#8217;adaptation au fran&#231;ais de l&#8217;un d&#8217;entre eux nous a permis de mettre &#224; la disposi-
tion de la communaut&#233; scientifique, mais aussi de la communaut&#233; des utilisateurs de logiciels</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Agn&#232;s Souque
</p>
<p>libres (OpenOffice.org, WEB), un formalisme, un outil informatique et une base cons&#233;quente
de r&#232;gles de correction grammaticale. Cependant, nous avons mis en &#233;vidence l&#8217;inad&#233;quation
des approches classiques du traitement automatique des langues &#224; la probl&#233;matique.
</p>
<p>Dans la section 1 de cet article, nous commen&#231;ons par expliquer dans quelle mesure le principe
de fonctionnement des correcteurs libres que nous avons &#233;tudi&#233;s nuit &#224; leur efficacit&#233;. Nous
exposons plus particuli&#232;rement le probl&#232;me de la d&#233;tection des erreurs qui se fonde sur des
r&#232;gles sans abstraction et sur un syst&#232;me de pattern-matching rigide, dont une des cons&#233;quences
est la n&#233;cessit&#233; d&#8217;&#233;num&#233;rer dans des r&#232;gles toutes les fautes possibles.
Pour simplifier la d&#233;tection des erreurs, nous proposons dans la section 2 une &#233;volution des
formalismes des correcteurs grammaticaux, qui combine deux approches syntaxiques issues
d&#8217;&#233;coles oppos&#233;es : la segmentation en chunks et l&#8217;unification de structures de traits.
La section 3 est consacr&#233;e &#224; la validation de l&#8217;&#233;volution pr&#233;sent&#233;e dans la section pr&#233;c&#233;dente et
aux b&#233;n&#233;fices qu&#8217;elle peut apporter. Nous avons pour cela d&#233;velopp&#233; un prototype de calculateur
d&#8217;unification auquel nous avons soumis des phrases contenant des erreurs de grammaire.
</p>
<p>2 Une correction grammaticale limit&#233;e
</p>
<p>Il ne nous a pas &#233;t&#233; possible d&#8217;analyser le fonctionnement des correcteurs grammaticaux pro-
pri&#233;taires, ces derniers n&#8217;&#233;tant pas document&#233;s. Les outils que nous avons &#233;tudi&#233;s sont donc
exclusivement des outils libres, tel que An Gramad&#243;ir (AnGramad&#243;ir, WEB) de Kevin Scan-
nell, ou (LanguageTool, WEB) d&#233;velopp&#233; par Daniel Naber (Naber, 2003).
</p>
<p>Ces syst&#232;mes de correction grammaticale ont une structure en couche qui effectue le traite-
ment du texte en plusieurs &#233;tapes successives. Dans un premier temps, le texte est segment&#233; en
phrases, puis en tokens 1. L&#8217;&#233;tape suivante consiste &#224; &#233;tiqueter morpho-syntaxiquement chacun
de ces tokens. Lors de cette &#233;tape, les mots peuvent recevoir plusieurs &#233;tiquettes s&#8217;ils sont ambi-
gus. Un traitement suppl&#233;mentaire est alors n&#233;cessaire pour les d&#233;sambigu&#239;ser, c&#8217;est-&#224;-dire pour
r&#233;duire le nombre d&#8217;&#233;tiquettes qu&#8217;ils poss&#232;dent, selon une m&#233;thode statistique ou fond&#233;e sur
des r&#232;gles. La derni&#232;re &#233;tape consiste enfin &#224; d&#233;tecter les erreurs de grammaire. Cette d&#233;tection
utilise le principe du pattern-matching &#224; partir d&#8217;une base de r&#232;gles de correction. Ce principe
rigide consiste &#224; comparer des s&#233;quences de tokens du texte avec des patrons de s&#233;quences de
tokens d&#233;crits dans les r&#232;gles. Une erreur est d&#233;tect&#233;e lorsqu&#8217;il y a correspondance exacte entre
les deux. Le correcteur LanguageTool que nous avons adapt&#233; au fran&#231;ais dans (Souque, 2007),
fonctionne selon ce principe.
</p>
<p>Dans cette section, nous pr&#233;sentons les principales cons&#233;quences de l&#8217;utilisation du pattern-
matching rigide dans les correcteurs grammaticaux que nous avons &#233;tudi&#233;s. Ces outils n&#233;ces-
sitent un tr&#232;s grand nombre de r&#232;gles de correction, ils se retrouvent pris au pi&#232;ge d&#8217;un cercle
vicieux et se r&#233;v&#232;lent incapables de d&#233;tecter des erreurs, pourtant fr&#233;quentes, impliquant des
mots distants.
</p>
<p>1Un token est g&#233;n&#233;ralement un signe de ponctuation ou un mot, au sens forme graphique. En effet, le mot en
linguistique peut d&#233;signer une unit&#233; s&#233;mantique constitu&#233;e de plusieurs formes graphiques. Par exemple, &quot;pomme
de terre&quot; est une unit&#233; compos&#233;e de 3 formes graphiques, qui correspondent &#224; 3 tokens.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Vers une nouvelle approche de la correction grammaticale automatique
</p>
<p>2.1 L&#8217;explosion combinatoire des r&#232;gles
</p>
<p>Pour qu&#8217;une erreur grammaticale soit d&#233;tect&#233;e, elle doit donc &#234;tre d&#233;crite dans une r&#232;gle. Ceci
implique que pour avoir une efficacit&#233; maximale, le correcteur doit poss&#233;der une r&#232;gle de cor-
rection pour chaque erreur possible.
</p>
<p>Si nous prenons l&#8217;exemple simple des syntagmes nominaux. Ils sont principalement constitu&#233;s
de d&#233;terminants, de noms et d&#8217;adjectifs, en quantit&#233; variable, chacun se d&#233;clinant en plusieurs
genres et nombres. Les correcteurs An Gramad&#243;ir ou LanguageTool utilisent par exemple un
lexique dans lequel les d&#233;terminants, les noms et les adjectifs peuvent &#234;tre de genre masculin,
f&#233;minin ou &#233;pic&#232;ne, et de nombre singulier, pluriel ou invariable.
</p>
<p>Si nous voulons &#233;crire une r&#232;gle pour chaque erreur d&#8217;accord possible dans un syntagme no-
minal, la non abstraction des motifs dans les r&#232;gles nous oblige d&#8217;une part &#224; &#233;num&#233;rer toutes
les positions que peut prendre chaque mot au sein du syntagme en fonction de sa cat&#233;gorie, et
d&#8217;autre part &#224; tenir compte pour chacun de toutes les combinaisons genre-nombre qu&#8217;il peut
avoir. Nous sommes confront&#233;s ainsi rapidement &#224; une explosion combinatoire du nombre de
r&#232;gles, telle que le montre la figure 1.
</p>
<p>FIG. 1 &#8211; Explosion combinatoire du nombre de r&#232;gles pour un syntagme nominal
</p>
<p>Nous retrouvons le m&#234;me probl&#232;me pour tous les types d&#8217;erreurs. Le fait de devoir d&#233;crire tous
les contextes de fautes implique qu&#8217;il faut imaginer toutes les combinaisons erron&#233;es de mots,
ce qui est impossible.
Il s&#8217;ensuit de nombreux probl&#232;mes de silence ou de bruit dans la d&#233;tection des fautes : du
silence lorsqu&#8217;une erreur n&#8217;a pas &#233;t&#233; pr&#233;vue et n&#8217;est pas d&#233;crite dans une r&#232;gle ; du bruit lorsque
plusieurs r&#232;gles, parmi les tr&#232;s nombreuses existantes, d&#233;tectent une m&#234;me erreur.
Par exemple, dans un &#233;nonc&#233; tel que *&quot;La petit aiguille indique l&#8217;heure&quot;
l&#8217;erreur de genre de &quot;petit&quot; est d&#233;tect&#233;e &#224; deux reprises par le correcteur LanguageTool :
&#8211; une premi&#232;re r&#232;gle s&#8217;applique car un d&#233;terminant f&#233;minin est suivi d&#8217;un adjectif masculin ;
&#8211; une seconde r&#232;gle s&#8217;applique car un adjectif masculin est suivi d&#8217;un nom f&#233;minin.
</p>
<p>Il est g&#233;n&#233;ralement pr&#233;f&#233;rable pour l&#8217;utilisateur que le silence soit privil&#233;gi&#233; au bruit. Les fausses
d&#233;tections sont en effet tr&#232;s g&#234;nantes, et lorsqu&#8217;elles sont trop fr&#233;quentes, elles conduisent sou-
vent l&#8217;utilisateur &#224; ne plus utiliser le correcteur.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Agn&#232;s Souque
</p>
<p>2.2 Le cercle vicieux
</p>
<p>Le nombre de r&#232;gles n&#8217;est pas l&#8217;unique responsable du bruit et du silence. En effet, pour que les
r&#232;gles de correction puissent s&#8217;appliquer et que la d&#233;tection des erreurs se fasse correctement,
selon le principe du pattern-matching, il faut que la s&#233;quence de tokens contenant l&#8217;erreur et le
patron d&#233;crit dans une r&#232;gle correspondent parfaitement. Cependant, les erreurs de grammaire
ou d&#8217;orthographe dans le texte peuvent conduire &#224; des erreurs d&#8217;&#233;tiquetage, qui &#224; leur tour
nuisent &#224; l&#8217;application des r&#232;gles, car la correspondance entre le texte et les motifs des r&#232;gles ne
peut plus se faire.
</p>
<p>Par exemple, la r&#232;gle suivante d&#233;crit un motif permettant de d&#233;tecter l&#8217;oubli de la particule
&quot;ne&quot; de la n&#233;gation : pronom sujet + verbe + &quot;pas&quot;
En pr&#233;sence d&#8217;un &#233;nonc&#233; tel que : *&quot;Il travail pas assez.&quot; la r&#232;gle ne peut pas
&#234;tre appliqu&#233;e. En effet, tel qu&#8217;il est orthographi&#233;, le mot &quot;travail&quot; porte l&#8217;&#233;tiquette nom.
La s&#233;quence ne correspond donc pas au motif d&#233;crit dans la r&#232;gle et l&#8217;erreur concernant l&#8217;oubli
de &quot;ne&quot; ne peut pas &#234;tre d&#233;tect&#233;e.
</p>
<p>Nous nous heurtons ainsi au probl&#232;me du cercle vicieux en correction grammaticale : la bonne
d&#233;tection des erreurs d&#233;pend d&#8217;un bon &#233;tiquetage, qui lui-m&#234;me d&#233;pend d&#8217;un texte sans erreurs...
</p>
<p>FIG. 2 &#8211; Cercle vicieux
</p>
<p>2.3 La limitation au contexte imm&#233;diat
</p>
<p>Le principe du pattern-matching a &#233;galement pour cons&#233;quence de rendre la d&#233;tection des er-
reurs portant sur des relations distantes tr&#232;s difficile, voire impossible. Prenons par exemple
l&#8217;&#233;nonc&#233; ci-dessous :
</p>
<p>*&quot;Les personnes en situation de test s&#8217;autosurveille
&#233;norm&#233;ment.&quot;
</p>
<p>Le verbe &quot;autosurveille&quot; n&#8217;est pas accord&#233; correctement avec le syntagme nominal sujet
&quot;Les personnes&quot;. Pour d&#233;tecter cette erreur d&#8217;accord sur le verbe, il faut une r&#232;gle d&#233;cri-
vant un motif du type : Det f&#233;m plur + Nom f&#233;m plur + 5 mots + Verbe 3e pers sing
Une telle r&#232;gle convient dans notre exemple pr&#233;cis, mais ne fonctionne plus si les mots qui
doivent s&#8217;accorder sont s&#233;par&#233;s d&#8217;un nombre de tokens diff&#233;rent de 5. Il faudrait donc cr&#233;er une
r&#232;gle pour chaque quantit&#233; de mots, quantit&#233; qu&#8217;il est impossible de pr&#233;voir.
D&#8217;autre part, nous pouvons &#233;voquer &#224; nouveau, avec cet exemple, le probl&#232;me de l&#8217;explosion
combinatoire des r&#232;gles. En dehors du nombre de &quot;mots s&#233;parateurs&quot; &#224; pr&#233;voir, il faut &#233;galement
cr&#233;er une r&#232;gle pour chaque possibilit&#233; de sujet du verbe, c&#8217;est-&#224;-dire avec chaque combinaison
de mots pouvant constituer un syntagme nominal sujet.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Vers une nouvelle approche de la correction grammaticale automatique
</p>
<p>2.4 Conclusion
</p>
<p>Le principe du pattern-matching rigide, avec la non abstraction des motifs d&#233;crits dans les
r&#232;gles, oblige &#224; pr&#233;voir toutes les erreurs possibles et rend ainsi tr&#232;s co&#251;teux le travail de consti-
tution du nombre d&#233;mesur&#233; de r&#232;gles n&#233;cessaires, travail qui doit par ailleurs &#234;tre r&#233;p&#233;t&#233; pour
chaque langue.
Nous pensons qu&#8217;il est possible de simplifier ce travail en utilisant des principes linguistiques
mieux adapt&#233;s, permettant d&#8217;int&#233;grer un niveau d&#8217;abstraction dans les r&#232;gles et de remplacer
ainsi les nombreuses r&#232;gles sp&#233;cifiques par quelques r&#232;gles g&#233;n&#233;riques simples.
</p>
<p>3 Une am&#233;lioration possible des correcteurs
</p>
<p>La simplification des r&#232;gles est indispensable &#224; une correction plus efficace et moins co&#251;teuse.
Pour y parvenir, nous avons combin&#233;, de mani&#232;re atypique, les deux concepts de la segmentation
en chunks et de l&#8217;unification de structures de traits (Miller &amp; Toris, 1990).
Dans cette partie, nous pr&#233;sentons donc ces deux concepts et l&#8217;int&#233;r&#234;t de les combiner pour
simplifier la d&#233;tection des fautes.
</p>
<p>3.1 La segmentation en chunks
</p>
<p>(Abney, 1991) d&#233;finit les chunks de la mani&#232;re suivante :
</p>
<p>&#171; The typical chunk consists of a single content word surrounded by a constellation
of function words, matching a fixed template &#187;
</p>
<p>Un chunk est donc un groupe de mots contigus, r&#233;unis autour d&#8217;une t&#234;te lexicale dont ils d&#233;-
pendent. Ces relations de d&#233;pendance font de la structure interne des chunks une structure re-
lativement fig&#233;e, dans laquelle les contraintes d&#8217;accord sont assez fortes, ce qui nous int&#233;resse
particuli&#232;rement pour la correction grammaticale.
</p>
<p>Les chunks sont principalement de type nominal ou verbal, et plus rarement adjectival ou adver-
bial. Ils sont d&#233;limit&#233;s gr&#226;ce aux mots grammaticaux, &#224; la ponctuation ou aux marques morpho-
logiques, et sont donc relativement faciles &#224; d&#233;finir. En g&#233;n&#233;ral, un chunk commence par un mot
grammatical ou juste apr&#232;s une ponctuation, et se termine juste avant une ponctuation ou le mot
grammatical suivant, qui marquent alors le d&#233;but d&#8217;un nouveau chunk. Ainsi, la d&#233;finition d&#8217;un
chunk ne se fait pas en fonction de son contenu, mais en fonction de ses marqueurs de d&#233;but et
de fin.
</p>
<p>Les chunks sont &#233;galement appel&#233;s syntagmes, mais ils font partie des grammaires robustes
du TAL dans lesquelles la notion de syntagme diff&#232;re de celle des grammaires chomskyennes,
d&#8217;o&#249; est issu le principe d&#8217;unification. Dans (Chomsky, 1979), les syntagmes sont r&#233;cursifs par
exemple, ce qui signifie qu&#8217;ils peuvent contenir d&#8217;autres syntagmes du m&#234;me type. Ainsi &quot;un
code &#233;labor&#233; et un code restreint&quot; est consid&#233;r&#233; comme un syntagme nomi-
nal constitu&#233; de deux autres syntagmes nominaux.
Pour les grammaires robustes au contraire, l&#8217;exemple ci-dessus consiste en trois syntagmes dis-
tincts, ou chunks : &quot;[un code &#233;labor&#233;] [et] [un code restreint]&quot;. Ces
syntagmes ne sont pas r&#233;cursifs, mais constituent au contraire un niveau hi&#233;rarchique entre les
mots et la phrase. Ainsi, chaque chunk est constitu&#233; d&#8217;&#233;l&#233;ments du niveau hi&#233;rarchique inf&#233;-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Agn&#232;s Souque
</p>
<p>rieur (les mots) et constitue &#224; son tour un &#233;l&#233;ment du niveau hi&#233;rarchique sup&#233;rieur (la phrase)
(Vergne &amp; Giguet, 1998).
Lorsque nous employons le mot syntagme dans la suite de cet article, nous faisons r&#233;f&#233;rence
aux syntagmes non r&#233;cursifs, c&#8217;est-&#224;-dire aux chunks.
</p>
<p>L&#8217;exemple que nous donnons en 2.3 est segment&#233; en chunks de la mani&#232;re suivante :
</p>
<p>[*Les personnes] [en situation] [de test] [s&#8217;autosurveille
&#233;norm&#233;ment].
</p>
<p>Au sein d&#8217;une phrase, les chunks entretiennent &#233;galement des relations de d&#233;pendance. Un syn-
tagme d&#233;pend g&#233;n&#233;ralement de son pr&#233;d&#233;cesseur, sauf dans le cas d&#8217;un chunk verbal. Ce dernier
d&#233;pend du chunk sujet, qui correspond en principe au premier syntagme nominal &#224; gauche.
Ces propri&#233;t&#233;s de d&#233;pendance vont s&#8217;av&#233;rer tr&#232;s utiles pour v&#233;rifier les accords entre diff&#233;rents
syntagmes.
</p>
<p>3.2 L&#8217;unification de structures de traits
</p>
<p>Les &#233;tiquettes morpho-syntaxiques attribu&#233;es &#224; chaque mot lors de l&#8217;&#233;tiquetage du texte consti-
tuent des structures de traits. Elles d&#233;crivent chaque &#233;l&#233;ment des phrases en &#233;num&#233;rant ses
caract&#233;ristiques linguistiques, sous la forme de liste de couples attribut-valeur.
</p>
<p>L&#8217;unification est d&#233;finie de mani&#232;re g&#233;n&#233;rale dans (Abeill&#233;, 1993) :
</p>
<p>&#171; L&#8217;unification de deux structures de traits A et B (not&#233;e A &#8746; B) est la structure
minimale qui est &#224; la fois une extension de A et de B. Si une telle extension n&#8217;existe
pas, l&#8217;unification &#171;&#233;choue&#187; (ce qui est not&#233; &#8869;) &#187;.
</p>
<p>Plus pr&#233;cis&#233;ment, dans le cadre de notre travail, nous dirons que l&#8217;unification consiste &#224; combi-
ner les traits de deux &#233;tiquettes et &#224; v&#233;rifier leur compatibilit&#233;. Deux structures de traits peuvent
s&#8217;unifier si elles ont les m&#234;mes valeurs pour des attributs identiques.
Par exemple, dans la figure 3, l&#8217;unification &#233;choue entre l&#8217;&#233;tiquette du nom &quot;genoux&quot; et celle
du d&#233;terminant &quot;le&quot;, car la valeur de l&#8217;attribut nombre n&#8217;est pas identique.
</p>
<p>FIG. 3 &#8211; &#201;chec de l&#8217;unification
</p>
<p>3.3 La combinaison des chunks et de l&#8217;unification
</p>
<p>Le fait de combiner le d&#233;coupage en chunks et l&#8217;unification de structures de traits va permettre
de faciliter la v&#233;rification grammaticale, en particulier pour les ph&#233;nom&#232;nes d&#8217;accord.
Les chunks d&#233;limitent des zones de calcul en fonction de leurs fronti&#232;res, et non plus en fonction
de leur contenu, comme c&#8217;est le cas avec les patrons de s&#233;quences de tokens dans les r&#232;gles. Il
n&#8217;est alors plus n&#233;cessaire de lister exhaustivement toutes les combinaisons de mots.
&#192; l&#8217;int&#233;rieur de ces zones de calcul, tous les &#233;l&#233;ments doivent s&#8217;accorder, ce qui signifie que
tous leurs traits doivent s&#8217;unifier, ind&#233;pendamment de leur cat&#233;gorie grammaticale. Il est ainsi</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Vers une nouvelle approche de la correction grammaticale automatique
</p>
<p>possible de d&#233;tecter les erreurs d&#8217;accord, m&#234;me si un mot est ambigu ou mal &#233;tiquet&#233;.
De plus, en attribuant aux chunks les traits de leur t&#234;te lexicale, ils peuvent alors s&#8217;unifier entre
eux, et des erreurs entre groupes de mots peuvent ainsi &#234;tre d&#233;tect&#233;es, comme par exemple l&#8217;ac-
cord entre le syntagme nominal sujet et le syntagme verbal.
L&#8217;utilisation combin&#233;e de ces deux principes linguistiques permet donc d&#8217;introduire une abs-
traction dans les motifs des r&#232;gles, dont le nombre peut &#234;tre ainsi consid&#233;rablement r&#233;duit.
</p>
<p>4 Un prototype de calculateur d&#8217;unification
</p>
<p>Pour valider notre hypoth&#232;se selon laquelle la combinaison des chunks et de l&#8217;unification peut
permettre de d&#233;tecter des fautes &#224; l&#8217;aide de quelques r&#232;gles simplifi&#233;es, nous avons con&#231;u un
calculateur d&#8217;unification. L&#8217;outil prend en entr&#233;e des phrases pr&#233;alablement &#233;tiquet&#233;es et seg-
ment&#233;es en chunks, il recherche des erreurs d&#8217;accord en calculant l&#8217;unification &#224; l&#8217;aide d&#8217;ex-
pressions r&#233;guli&#232;res, puis cr&#233;e un fichier de sortie contenant des informations sur les erreurs
d&#233;tect&#233;es.
</p>
<p>4.1 L&#8217;&#233;tiquetage de phrases test
</p>
<p>Pour pouvoir tester notre outil, nous avions besoin de phrases &#233;tiquet&#233;es et segment&#233;es. Nous
avons choisi le formalisme XML pour repr&#233;senter ces phrases. Bien que plus lourd &#224; traiter
par le programme, ce formalisme a plusieurs avantages. Il est facilement lisible et modifiable
par des linguistes, qui ne sont pas n&#233;cessairement informaticiens, c&#8217;est un formalisme ouvert
qui permet l&#8217;implantation de nombreuses fonctionnalit&#233;s, et les balises qui le constituent sont
faciles &#224; identifier par un outil tel que le n&#244;tre qui utilise des expressions r&#233;guli&#232;res. Il s&#8217;agit
d&#8217;autre part du formalisme d&#8217;&#233;tiquetage utilis&#233; dans le correcteur LanguageTool sur lequel nous
avons travaill&#233;.
</p>
<p>Ne disposant pas d&#8217;&#233;tiqueteur en XML ni de segmenteur en chunks compatibles avec ce que
nous voulions obtenir, nous avons r&#233;alis&#233; le travail manuellement sur quelques phrases, extraites
d&#8217;un corpus de variations orthographiques (COVAREC, 1994) (Lucci &amp; Millet, 1994). Nous
avons obtenu des phrases &#233;tiquet&#233;es de la mani&#232;re suivante :
</p>
<p>*&quot;Les personnes en situation de test s&#8217;autosurveille &#233;norm&#233;ment&quot;
&lt;SN genre=&quot;f&quot; nombre=&quot;p&quot;&gt;
</p>
<p>&lt;D nombre=&quot;p&quot;&gt;Les&lt;/D&gt;
&lt;N genre=&quot;f&quot; nombre=&quot;p&quot;&gt;personnes&lt;/N&gt;
</p>
<p>&lt;/SN&gt;
&lt;SP&gt;
</p>
<p>&lt;P&gt;en&lt;/P&gt;
&lt;N genre=&quot;f&quot; nombre=&quot;s&quot;&gt;situation&lt;/N&gt;
</p>
<p>&lt;/SP&gt;
&lt;SP&gt;
</p>
<p>&lt;P&gt;de&lt;/P&gt;
&lt;N genre=&quot;m&quot; nombre=&quot;s&quot;&gt;test&lt;/N&gt;
</p>
<p>&lt;/SP&gt;
&lt;SV type=&quot;ppal&quot;&gt;
</p>
<p>&lt;R type=&quot;refl&quot; pers=&quot;3&quot; &gt;s&#8217;&lt;/R&gt;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Agn&#232;s Souque
</p>
<p>&lt;V mode=&quot;ind&quot; temps=&quot;pres&quot; pers=&quot;3&quot; nombre=&quot;s&quot;&gt;
autosurveille&lt;/V&gt;
&lt;A&gt;&#233;norm&#233;ment&lt;/A&gt;
</p>
<p>&lt;/SV&gt;
</p>
<p>Les balises SN, SV et SP d&#233;limitent respectivement les chunks nominaux, verbaux et pr&#233;posi-
tionnels. Chacune contient &#224; son tour un ou plusieurs &#233;lements : dans notre exemple, nous avons
les balises D (d&#233;terminant), N (nom), P (pr&#233;position), V (verbe), R (pronom) et A (adverbe), &#192;
l&#8217;int&#233;rieur des balises, divers attributs d&#233;finissent les traits morpho-syntaxiques (genre, nombre,
temps, etc.) de chaque mot.
</p>
<p>4.2 Le fonctionnement du prototype
</p>
<p>Notre prototype fonctionne &#224; l&#8217;aide d&#8217;expressions r&#233;guli&#232;res, qui permettent de trouver faci-
lement des motifs dans les cha&#238;nes de caract&#232;res. Comme tout l&#8217;&#233;tiquetage se fonde sur des
balises, il est facile de d&#233;finir des motifs pour rep&#233;rer les diff&#233;rents niveaux : phrases, chunks,
&#233;l&#233;ments et attributs.
</p>
<p>L&#8217;outil commence par parcourir le fichier XML afin d&#8217;isoler et de stocker dans un tableau
chaque niveau dans une phrase. Ainsi, pour l&#8217;exemple en 4.1, l&#8217;outil va commencer par iso-
ler et stocker le chunk SN, ses attributs et les 2 &#233;l&#233;ments D et N avec leurs attributs, puis il va
continuer avec les chunks suivants jusqu&#8217;&#224; la fin de la phrase.
</p>
<p>Viennent ensuite les calculs d&#8217;unification. Ils sont d&#8217;abord effectu&#233;s au sein des chunks, &#224; partir
des donn&#233;es stock&#233;es pr&#233;c&#233;demment. Le programme compare la valeur de chaque attribut d&#8217;un
&#233;l&#233;ment avec la valeur du m&#234;me attribut dans tous les autres &#233;l&#233;ments du chunk trait&#233;. Si deux
m&#234;mes attributs compar&#233;s n&#8217;ont pas une valeur identique, l&#8217;unification &#233;choue et renvoie &quot;faux&quot;,
ce qui signifie qu&#8217;il y a une erreur d&#8217;accord. Dans ce cas, le programme indique dans le fichier
de sortie (en HTML) le chunk concern&#233;, la phrase dans laquelle il se situe, un commentaire sur
le type d&#8217;erreur d&#233;tect&#233;e et une suggestion de correction.
</p>
<p>Une fois toutes les v&#233;rifications intra-chunks effectu&#233;es, le programme proc&#232;de alors aux cal-
culs d&#8217;unification entre les chunks. Il s&#8217;agit dans ce cas g&#233;n&#233;ralement de d&#233;tection d&#8217;erreurs
d&#8217;accord entre le sujet et le verbe. Ainsi, le verbe du chunk verbal principal doit avoir un attri-
but nombre de m&#234;me valeur que l&#8217;attribut nombre du premier chunk nominal &#224; gauche, celui-ci
&#233;tant g&#233;n&#233;ralement sujet. De m&#234;me, il doit y avoir unification entre les attributs genre et nombre
du chunk nominal sujet et ceux d&#8217;un &#233;ventuel participe pass&#233; dans le chunk verbal. Lorsque le
sujet est un pronom personnel, celui-ci &#233;tant inclus au chunk verbal, une erreur d&#8217;accord sera
d&#233;tect&#233;e lors des calculs d&#8217;unification intra-chunks.
En cas d&#8217;&#233;chec de l&#8217;unification, le m&#234;me type d&#8217;indications que lors de la v&#233;rifications intra-
chunk est retourn&#233; dans le fichier de sortie.
</p>
<p>4.3 Les r&#233;sultats des tests
</p>
<p>Nous avons test&#233; notre prototype sur les phrases que nous avons pr&#233;alablement &#233;tiquet&#233;es ma-
nuellement et nous avons obtenus des r&#233;sultats plut&#244;t encourageants.
Les erreurs d&#8217;accord dans les syntagmes nominaux ont toutes &#233;t&#233; d&#233;tect&#233;es, sans qu&#8217;il soit fait
usage d&#8217;une base d&#233;mesur&#233;e de r&#232;gles de correction. Le correcteur libre An Gramad&#243;ir (AnGra-
mad&#243;ir, WEB) par exemple poss&#232;de une base d&#8217;environ 450 r&#232;gles, utilisant des expressions</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Vers une nouvelle approche de la correction grammaticale automatique
</p>
<p>r&#233;guli&#232;res et des macros complexes, pour la d&#233;tection des erreurs d&#8217;accord dans les syntagmes
nominaux. En utilisant les propri&#233;t&#233;s des chunks et l&#8217;unification, ces r&#232;gles ne sont plus n&#233;ces-
saires. Pour d&#233;tecter ce type d&#8217;erreurs, il suffit de calculer l&#8217;unification entre tous les constituants
d&#8217;un chunk.
Les fautes d&#8217;accord entre les syntagmes nominaux sujet et leur verbe ou participe pass&#233; ont
&#233;galement &#233;t&#233; d&#233;tect&#233;es correctement. Par exemple, si nous reprenons notre &#233;nonc&#233; :
&quot;Les personnes en situation de test s&#8217;autosurveille &#233;norm&#233;ment&quot;
l&#8217;erreur de personne sur le verbe a &#233;t&#233; signal&#233;e. De telles erreurs sont g&#233;n&#233;ralement difficile-
ment d&#233;tectables par la plupart des correcteurs, car elles sont souvent associ&#233;es &#224; des relations
de d&#233;pendance distantes. Avec les propri&#233;t&#233;s de d&#233;pendance que les chunks entretiennent entre
eux, ce type d&#8217;erreur peut non seulement &#234;tre d&#233;tect&#233;, mais en plus d&#233;tect&#233; avec un nombre tr&#232;s
r&#233;duit de r&#232;gles simples.
</p>
<p>Notre prototype ne d&#233;tecte pour le moment que quelques types d&#8217;erreurs que nous venons de
mentionner (accords dans les SN, accords sujet-verbe, accords sujet-participe pass&#233;). Il permet
n&#233;anmoins de montrer que la combinaison chunks-unification est efficace pour d&#233;tecter les er-
reurs d&#8217;accord. La d&#233;tection se fait correctement et &#224; moindre co&#251;t car elle ne n&#233;cessite plus la
r&#233;daction de tr&#232;s nombreuses r&#232;gles.
</p>
<p>5 Conclusion et perspectives
</p>
<p>Les correcteurs grammaticaux libres que nous connaissons ont tous &#224; peu pr&#232;s la m&#234;me struc-
ture et se fondent sur un syst&#232;me de pattern-matching, que l&#8217;absence d&#8217;abstraction des patrons
d&#233;crits dans les r&#232;gles rend tr&#232;s rigide. Comme nous l&#8217;avons vu dans cet article, ceci limite
de mani&#232;re importante les performances des correcteurs. Ces derniers doivent disposer d&#8217;un
nombre d&#233;mesur&#233; de r&#232;gles (notamment pour les fautes d&#8217;accord), qui ne permettent cependant
pas de d&#233;tecter toutes les erreurs et sont &#233;galement souvent source de fausses d&#233;tections.
Les approches TAL mises en oeuvres n&#8217;&#233;tant pas adapt&#233;es &#224; la probl&#233;matique, nous nous sommes
donc tourn&#233;e vers d&#8217;autres approches : la segmentation en chunks et l&#8217;unification. Le fait de
les combiner permet d&#8217;int&#233;grer une abstraction et ainsi de simplifier les r&#232;gles et d&#8217;en r&#233;duire
consid&#233;rablement le nombre. Les chunks constituent en effet des zones de calcul &#224; l&#8217;int&#233;rieur
desquelles les traits de tous les &#233;l&#233;ments doivent s&#8217;unifier.
</p>
<p>Pour v&#233;rifier la faisabilit&#233; d&#8217;une telle combinaison chunk-unification, nous avons d&#233;velopp&#233; un
prototype de calcul d&#8217;unification. En pr&#233;sence de phrases pr&#233;alablement &#233;tiquet&#233;es en XML et
segment&#233;es en chunks, l&#8217;outil s&#8217;est r&#233;v&#233;l&#233; parfaitement capable de d&#233;tecter les erreurs d&#8217;accord,
aussi bien dans qu&#8217;entre les chunks. Cet outil nous a montr&#233; qu&#8217;il est donc possible, avec un
nombre tr&#232;s r&#233;duit de r&#232;gles simples, de d&#233;tecter les erreurs d&#8217;accord quelle que soit la dis-
tance qui s&#233;pare les mots concern&#233;s, alors que ces d&#233;tections ne sont actuellement pas toujours
possibles et n&#233;cessitent &#233;norm&#233;ment de r&#232;gles, parfois tr&#232;s complexes.
</p>
<p>Les b&#233;n&#233;fices que nous avons mentionn&#233;s sont importants mais selon nous pas suffisants pour
obtenir un outil capable de corriger efficacement le fran&#231;ais. Il nous semble n&#233;cessaire de sortir
d&#8217;une part de l&#8217;approche &#233;num&#233;rative des r&#232;gles, d&#8217;autre part de l&#8217;approche en couches tra-
ditionnelle, o&#249; le traitement du texte est d&#233;compos&#233; en plusieurs &#233;tapes successives et o&#249; la
d&#233;tection des fautes est prisonni&#232;re d&#8217;un cercle vicieux (figure 2).
</p>
<p>Nous envisageons donc une approche innovante de la correction grammaticale, que nous pour-
rions nommer &quot;gauche-droite&quot;. Le principe est de construire simultan&#233;ment l&#8217;analyse morpho-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Agn&#232;s Souque
</p>
<p>syntaxique et la correction au fur et &#224; mesure de la r&#233;daction / lecture de la phrase, et de recher-
cher des incoh&#233;rences grammaticales plut&#244;t que d&#8217;&#233;num&#233;rer exhaustivement toutes les erreurs
possibles. Plus pr&#233;cis&#233;ment, en se fondant sur le principe des latences (Tesni&#232;re, 1959) ou d&#8217;at-
tentes r&#233;ciproques (Lebarb&#233;, 2002), construire la structure syntaxique dans l&#8217;ordre de lecture des
tokens, valider les attentes r&#233;ciproques (un d&#233;terminant attend un nom), construire les chunks et
tester l&#8217;unification : l&#8217;&#233;chec de l&#8217;un des trois constitue une d&#233;tection d&#8217;erreur de grammaire et
donne son explication.
</p>
<p>L&#8217;analyse de *&quot;Les premiers linguistes on donc d&#8217;abord &#233;cout&#233;&quot;
g&#233;n&#233;rerait une erreur sur le mot &quot;on&quot;, le syntagme nominal qui le pr&#233;c&#232;de ayant une latence
droite pour un verbe ou une pr&#233;position.
</p>
<p>&quot;Les premiers linguistes on donc d&#8217;abord &#233;cout&#233;&quot;
[SN----------------------] erreur
</p>
<p>Un message du type &quot;un verbe est attendu&quot; serait alors g&#233;n&#233;r&#233; pour indiquer l&#8217;erreur &#224; l&#8217;utilisa-
teur.
Cette approche, sur laquelle nous travaillons dans le cadre de notre th&#232;se, implique une recon-
sid&#233;ration compl&#232;te des formalismes existants (d&#233;claration non plus des fautes, mais de ce qui
est attendu) et du traitement.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ABEILL&#201; A. (1993). Les nouvelles syntaxes. Grammaires d&#8217;unification et analyse du fran&#231;ais.
Armand Colin.
ABNEY S. (1991). Parsing by chunks. In Principle-based parsing : Computation and Psycho-
linguistics, p. 257&#8211;278. Kluwer Academic Publishers.
ANGRAMAD&#211;IR (WEB). http ://borel.slu.edu/gramadoir.
CHOMSKY N. (1979). Structures syntaxiques. &#201;ditions Seuil.
COVAREC (1994). Corpus de variations orthographiques. Laboratoire LIDILEM, Universit&#233;
Stendhal-Grenoble 3.
LANGUAGETOOL (WEB). http ://www.languagetool.org/.
LEBARB&#201; T. (2002). Hi&#233;rarchie inclusive des unit&#233;s linguistiques en analyse syntaxique co-
op&#233;rative ; le segment, unit&#233; interm&#233;diaire entre chunk et phrase dans le traitement linguistique
par syst&#232;me multi-agents. PhD thesis, Universit&#233; de Caen.
LUCCI V. &amp; MILLET A. (1994). L&#8217;orthographe de tous les jours, enqu&#234;te sur les pratiques
orthographiques des fran&#231;ais. &#201;ditions Champion.
MILLER P. &amp; TORIS T. (1990). Formalisme pour le TALN. Herm&#232;s.
NABER D. (2003). A rule-based and grammar checker. PhD thesis, Technische Fakult&#228;t,
Universit&#228;t Beilefeld.
OPENOFFICE.ORG (WEB). http ://fr.openoffice.org/.
SOUQUE A. (2007). Conception et d&#233;veloppement d&#8217;un formalisme de correction gramma-
ticale automatique - Application au fran&#231;ais. M&#233;moire de master 2 recherche sciences de
langage, Universit&#233; Stendhal - Grenoble 3.
TESNI&#200;RE L. (1959). &#201;l&#233;ments de syntaxe structurale. Klincksieck.
VERGNE J. &amp; GIGUET E. (1998). Regards th&#233;oriques sur le &quot;tagging&quot;. Actes de la cinqui&#232;me
conf&#233;rence Le Traitement Automatique des Langues Naturelles.</p>

</div></div>
</body></html>