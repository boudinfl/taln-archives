<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>M&#233;ta-moteur de traduction automatique : proposition d&#8217;une m&#233;trique pour le classement de traductions</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>RECITAL 2009, Senlis, 24&#8211;26 juin 2009
</p>
<p>M&#233;ta-moteur de traduction automatique : proposition d&#8217;une
m&#233;trique pour le classement de traductions
</p>
<p>Marion Potet
Laboratoire d&#8217;informatique de Grenoble, &#233;quipe GETALP
</p>
<p>UJF - BP 53, 38041 Grenoble Cedex 9
Marion.Potet@imag.fr
</p>
<p>R&#233;sum&#233;. Compte tenu de l&#8217;essor du Web et du d&#233;veloppement des documents multi-
lingues, le besoin de traductions &quot;&#224; la vol&#233;e&quot; est devenu une &#233;vidence. Cet article pr&#233;sente un
syst&#232;me qui propose, pour une phrase donn&#233;e, non pas une unique traduction, mais une liste de
N hypoth&#232;ses de traductions en faisant appel &#224; plusieurs moteurs de traduction pr&#233;-existants.
Neufs moteurs de traduction automatique gratuits et disponibles sur le Web ont &#233;t&#233; s&#233;lectionn&#233;s
pour soumettre un texte &#224; traduire et r&#233;ceptionner sa traduction. Les traductions obtenues sont
class&#233;es selon une m&#233;trique reposant sur l&#8217;utilisation d&#8217;un mod&#232;le de langage. Les exp&#233;riences
conduites ont montr&#233; que ce m&#233;ta-moteur de traduction se r&#233;v&#232;le plus pertinent que l&#8217;utilisation
d&#8217;un seul syst&#232;me de traduction.
</p>
<p>Abstract. Considering the Web and multilingual documents development expansion, the
need of fast translation has become an evidence. This paper presents a system that proposes,
for a given sentence, a list of N translation hypotheses instead of a single translation, using
several machine translation systems already existing. Nine free and available (on the Internet)
automatic translation engines have been chosen to submit a text to be translated and to receive its
translation. The translations obtained are evaluated individually with a language model adapted
and a metric elaborated by us, and in this way classified by relevance order. The experiment
have pointed out that this meta-translation engine is more useful than the use of one system for
translation.
</p>
<p>Mots-cl traduction automatique, web, mod&#232;le de langage, m&#233;ta-moteur de traduction.
Keywords: automatic translation, web, language model, meta-translator.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Marion Potet
</p>
<p>1 Introduction
</p>
<p>Le premi&#232;re approche utilis&#233;e pour traduire des textes &#233;tait bas&#233;e sur des r&#232;gles linguistiques
qui visent &#224; formaliser toutes les connaissances n&#233;cessaires &#224; la traduction. Celle-ci n&#233;cessite
beaucoup de travail de la part des linguistes pour d&#233;finir le vocabulaire et la grammaire. Cette
m&#233;thode a donn&#233; naissance, par exemple, au c&#233;l&#232;bre syst&#232;me de traduction Systran. D&#8217;autres
m&#233;thodes existent, comme les m&#233;thodes empiriques et parmi elles, l&#8217;approche statistique, dont
les bases th&#233;oriques ont &#233;t&#233; pos&#233;es par (Brown et al., 1993) puis (Koehn et al., 2003), qui fait
en sorte que toute la connaissance translingue soit acquise de mani&#232;re automatique &#224; partir de
corpus.
</p>
<p>Plusieurs travaux se sont int&#233;ress&#233;s &#224; la comparaison des performances des syst&#232;mes issus des
diff&#233;rentes approches. Il en ressort que, pour des performances &#233;quivalentes, les approches ex-
pertes &#224; base de r&#232;gle et les approches empiriques font des erreurs diff&#233;rentes lors de la tra-
duction. Dans (Dugast et al., 2008), par exemple, on remarque que les oublis de mots et la g&#233;-
n&#233;ration de mots inconnus sont des types d&#8217;erreurs sp&#233;cifiques aux syst&#232;mes statistiques alors
que les erreurs dans l&#8217;ordre des mots, tout comme les erreurs de vocabulaire, sont sp&#233;cifiques
aux syst&#232;mes &#224; base de r&#232;gles. D&#8217;autre part, (Rayner &amp; Bouillon, 1995) pr&#233;cisent que les r&#232;gles
semblent encoder les informations grammaticales alors que les statistiques encodent les infor-
mations li&#233;es au domaine. Par ailleurs, la combinaison d&#8217;un syst&#232;me bas&#233; sur les r&#232;gles et d&#8217;un
module statistique, par exemple au moyen de la post-&#233;dition comme dans (Simard et al., 2007)
et (Koehn et al., 2007), montre une am&#233;lioration significative de la qualit&#233; de traduction.
Cet article propose de combiner les r&#233;sultats de plusieurs moteurs de traduction automatique
issus de syst&#232;mes de natures diff&#233;rentes. Son originalit&#233; est qu&#8217;il fait appel &#224; diff&#233;rents moteurs
de traduction automatique du Web afin d&#8217;obtenir plusieurs traductions qui sont ensuite class&#233;es
par ordre de pertinence &#224; l&#8217;aide d&#8217;une m&#233;trique bas&#233;e sur la fluidit&#233; de la traduction. L&#8217;id&#233;e est de
tirer parti de cette variabilit&#233; inter-syst&#232;mes en regroupant, pour une m&#234;me phrase, les r&#233;sultats
obtenus des diff&#233;rents moteurs afin de les mettre en concurrence. Le syst&#232;me utilise plusieurs
moteurs de traduction simultan&#233;ment ; par d&#233;finition ; nous pouvons lui attribuer l&#8217;appellation
de m&#233;ta-moteur de traduction.
</p>
<p>Dans un premier temps, des interfaces de traduction sont r&#233;f&#233;renc&#233;es, s&#233;lectionn&#233;es puis test&#233;es.
Il en r&#233;sulte une liste de N moteurs de traduction qui sont ensuite interrog&#233;s par programme afin
d&#8217;obtenir N traductions d&#8217;une phrase source initiale.
</p>
<p>Une fois les r&#233;sultats des diff&#233;rents moteurs de traduction obtenus, il s&#8217;agit de scorer chaque
traduction, en vue de les classer. Pour une phrase source, il en r&#233;sulte une liste ordonn&#233;e d&#8217;hy-
poth&#232;ses de traduction. La section 3, d&#233;crit la m&#233;trique utilis&#233;e pour classer ces traductions. La
d&#233;marche est valid&#233;e par une &#233;valuation automatique (score BLEU) et par une &#233;valuation sub-
jective dont les r&#233;sultats sont d&#233;crits dans la section suivante. Enfin, le syst&#232;me a &#233;t&#233; impl&#233;ment&#233;
&#224; travers une interface graphique, accessible sur le Web, pr&#233;sent&#233;e dans la section 5.
</p>
<p>2 R&#233;cup&#233;ration de traductions
</p>
<p>Le cadre applicatif est restreint au domaine des informations journalistiques ou d&#233;p&#234;ches, plus
commun&#233;ment appel&#233; &quot;news&quot;, en vue de valoriser ce travail par des d&#8217;applications directes
comme la traduction automatique d&#8217;articles journalistiques de la langue anglaise vers la langue</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M&#233;ta-moteur de traduction automatique
</p>
<p>fran&#231;aise.
</p>
<p>Une s&#233;lection manuelle des moteurs de traduction a &#233;t&#233; r&#233;alis&#233;e sur la base des caract&#233;ristiques
suivantes : disponible sur le net ; gratuit ; permettre la traduction de phrases ou de textes ; traiter
la traduction de la langue anglaise vers la langue fran&#231;aise ; ne pas pratiquer de &quot;blacklistage&quot;1.
Peuvent &#233;galement &#234;tre prises en compte la performance des r&#233;sultats, la rapidit&#233; de r&#233;ponse et
une bonne utilisabilit&#233;. Selon ces crit&#232;res, 22 interfaces ont ainsi &#233;t&#233; r&#233;pertori&#233;es.
</p>
<p>Lors de l&#8217;analyse et des tests des syst&#232;mes de traduction pr&#233;sents sur le web, plusieurs inter-
faces diff&#233;rentes pr&#233;sentaient syst&#233;matiquement, pour une m&#234;me phrase &#224; traduire, des r&#233;sultats
identiques. Ces interfaces ont &#233;t&#233; regroup&#233;es et neuf moteurs de traduction distincts ont &#233;t&#233;
identifi&#233;s. Comme plusieurs interfaces utilisent le m&#234;me outil traductif, le choix se porte sur
celles qui pr&#233;sentent un temps de r&#233;ponse court et une bonne utilisabilit&#233; (pas d&#8217;identification
aupr&#232;s du serveur, m&#233;thode d&#8217;envoi du formulaire, etc). Par soucis d&#8217;anonymat, dans la suite
de l&#8217;article, les neuf interfaces finalement retenues seront d&#233;sign&#233;es par : MTG, MTS , MTR,
MTA, MTE , MTF , MTL, MTP , MTW .
</p>
<p>3 Classement des traductions
</p>
<p>3.1 Description des corpus
</p>
<p>Etant donn&#233; le cadre applicatif, les corpus doivent n&#233;cessairement comporter des donn&#233;es jour-
nalistiques de type &quot;news&quot; et ils doivent atteindre une taille suffisante pour permettre des trai-
tements statistiques fiables. Etant donn&#233; le peu de ressources disponibles, dans le domaine sp&#233;-
cifique des donn&#233;es journalistiques, nous avons, pour le besoin, constitu&#233; nos propres corpus &#224;
partir de textes &#233;crits collect&#233;s sur le World Wide Web. Nous avons constitu&#233;, d&#8217;une part, un
corpus monolingue en fran&#231;ais pour le mod&#232;le de langage sur lequel d&#8217;appuie la m&#233;trique ainsi
qu&#8217;un corpus bilingue fran&#231;ais/anglais pour tester le syst&#232;me.
</p>
<p>L&#8217;apprentissage du mod&#232;le de langage, utilis&#233; pour classer les traductions de chaque moteurs,
n&#233;cessite un ou des corpus repr&#233;sentatifs des conditions d&#8217;utilisation et de l&#8217;application envisa-
g&#233;e : des corpus monolingues fran&#231;ais de donn&#233;es contemporaines et journalistiques et de taille
suffisante pour une estimation fiable des probabilit&#233;s.
</p>
<p>Trois mod&#232;les de langage ont &#233;t&#233; entra&#238;n&#233;s &#224; partir des corpus d&#8217;apprentissage ( d&#233;crits dans le
tableau 1). Ils sont ensuite combin&#233;s par interpolation lin&#233;aire. Le corpus de d&#233;veloppement n&#233;-
cessaire &#224; l&#8217;estimation des pond&#233;rations de chaque mod&#232;le de langage, est compos&#233; de donn&#233;es
journalistiques du site France242 du 1er au 14 mai 2008.
Par ailleurs, l&#8217;&#233;valuation des syst&#232;mes n&#233;cessite un corpus de test, bilingue et align&#233;, de phrases
issues du domaine journalistique qui vont servir de r&#233;f&#233;rence pour mesurer la qualit&#233; des traduc-
teurs. Pour cela, nous avons donc constitu&#233; un corpus bilingue &#224; partir des versions anglaises
et fran&#231;aises du site Web de France24. Les phrases align&#233;es ont ensuite &#233;t&#233; s&#233;lectionn&#233;es et
extraites manuellement, directement d&#8217;apr&#232;s la mise en correspondance automatique des do-
</p>
<p>1Le nombre de requ&#234;tes permises pour une m&#234;me machine sur un moteur de traduction est suceptible d&#8217;&#234;tre
limit&#233; ou contr&#244;l&#233; par le serveur de certains moteurs de traduction
</p>
<p>2http ://www.france24.com
5Association Europ&#233;enne pour les ressources linguistiques.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Marion Potet
</p>
<p>Source Description Nombre de mots P&#233;riode
France24 www.France24.com 4 M f&#233;vrier/avril 2008
</p>
<p>Web donn&#233;es du web 72 M juin 2003/avril 2008
Le Monde CDRom de ELRA5 23 M janvier/d&#233;cembre 2003
</p>
<p>TAB. 1 &#8211; Description des corpus d&#8217;apprentissage du mod&#232;le de langage
</p>
<p>cuments. Il est &#224; noter que les textes relataient le m&#234;me &#233;v&#233;nement sans &#234;tre pour autant la
traduction l&#8217;un de l&#8217;autre. Les phrases traduites pr&#233;lev&#233;es ont donc d&#251; &#234;tre v&#233;rifi&#233;es et, au be-
soin, corrig&#233;es une par une. Le r&#233;sultat est un corpus de 300 phrases, bilingue et align&#233; de
donn&#233;es journalistiques r&#233;centes.
</p>
<p>3.2 Description du mod&#232;le de langage
</p>
<p>Avant tout traitement, les corpus d&#8217;apprentissage ont &#233;t&#233; normalis&#233;s avec la bo&#238;te &#224; outils CLIPS-
Text-Toolkit-2.5 (Bigi &amp; Le, 2008). Les mod&#232;les de langage ont &#233;t&#233; entra&#238;n&#233;s &#224; partir des corpus
&#224; l&#8217;aide de l&#8217;outil SRILM (Stolcke, 2002). Les mod&#232;les utilisent des trigrammes de mots, ils
ont &#233;t&#233;s liss&#233;s avec la m&#233;thode de repli de Kneser-Ney modifi&#233;e et un pruning &#224; 10&#8722;9 leur &#233;t&#233;
appliqu&#233;.
</p>
<p>Nous avons donc cr&#233;&#233; trois mod&#232;les de langage que nous nommerons, en rappel &#224; leur corpus
d&#8217;apprentissage respectif (vus dans la table 1), LeMonde, Web et France24. Le mod&#232;le de lan-
gage final est le r&#233;sultat de l&#8217;interpolation lin&#233;aire du mod&#232;le France24 avec un coefficient de
0,41, du mod&#232;le Web avec un coefficient de 0,42 et du mod&#232;le LeMonde avec un coefficient de
0,17. Son vocabulaire est de 60 147 mots et le taux de mots inconnus est de 1,36 % dans le
corpus de test.
</p>
<p>Nous avons choisi un apprentissage &#224; vocabulaire ferm&#233;, un vocabulaire ouvert &#233;tant, &#224; notre
avis, inadapt&#233; dans le cas de donn&#233;es journalistiques fortement d&#233;pendante de l&#8217;actualit&#233; car le
nombre de mots inconnus est tr&#232;s important et la distribution des probabilit&#233;s en est fortement
affect&#233;e.
</p>
<p>3.3 D&#233;finition d&#8217;une m&#233;trique pour classer les traductions
</p>
<p>Un mod&#232;le de langage analyse une phrase et lui applique plusieurs m&#233;triques. Celles qui nous
interressent sont : le nombre de mots de la phrase, le nombre de mots de la phrase ne figurant pas
dans le mod&#232;le de langage ou mots inconnus (not&#233;s OOV s3) et le logarithme de la probabilit&#233;
de la phrase WK = w1w2 &#183; &#183; &#183;wK , avec wk les K mots de la phrase. Cette derni&#232;re not&#233;e logprob
s&#8217;estime comme suit :
</p>
<p>logprob(WK) =
K&#8721;
</p>
<p>k=2
</p>
<p>log P (wk|wk&#8722;1, wk&#8722;2)
</p>
<p>avec P (wk|wk&#8722;1, wk&#8722;2) la probabilit&#233; du trigramme wk&#8722;2, wk&#8722;1, wk.
</p>
<p>3OOV= Out Of Vocabulary.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M&#233;ta-moteur de traduction automatique
</p>
<p>En pratique, l&#8217;outil SRILM poss&#232;de une commande ngram qui, &#224; partir d&#8217;un mod&#232;le de lan-
gage, applique &#224; toute phrase les m&#233;triques pr&#233;c&#233;demment cit&#233;es. Cette commande appliqu&#233;e &#224;
la phrase &quot;je fais un essai&quot; donnera le r&#233;sultat suivant :
</p>
<p>&lt;s&gt; je fais un essai &lt;/s&gt;
1 sentence, 4 words, 0 00Vs, logprob= -10.1085
</p>
<p>Dans notre application, la m&#233;trique recherch&#233;e sera utilis&#233;e pour comparer les hypoth&#232;ses de
traduction issues des diff&#233;rents moteurs en ligne.
</p>
<p>Pour l&#8217;attribution d&#8217;un score aux diff&#233;rentes traductions, il est inutile d&#8217;introduire un param&#232;tre
destin&#233; &#224; normaliser la longueur des phrases car les phrases, &#233;tant la traduction d&#8217;une seule
et m&#234;me phrase source, ont n&#233;cessairement approximativement le m&#234;me nombre de mots. Le
crit&#232;re logprob, bien que fortement d&#233;pendant du nombre de mots dans la phrase, semble donc
en parti appropri&#233; &#224; notre application. Le probl&#232;me est, qu&#8217;avec le mod&#232;le de langage utilis&#233;, ce
crit&#232;re sur-&#233;value les phrases comportant un ou plusieurs mots inconnus.
</p>
<p>Dans le cas des donn&#233;es d&#8217;actualit&#233;, le vocabulaire du corpus d&#8217;apprentissage est tr&#232;s large et
le mod&#232;le de langage associe une probabilit&#233; trop importante aux mots hors vocabulaire. Ainsi,
certaines suites de mots comme &quot;Je fais un MOTINC&quot; peuvent se voir attribuer une probabilit&#233;
d&#8217;apparition beaucoup plus forte que la phrase &quot;Je fais un essai&quot;. Pour traiter ce probl&#232;me, une
technique consiste &#224; assigner une probabilit&#233; que l&#8217;on d&#233;finira aux mots n&#8217;apparaissant pas dans
le corpus d&#8217;apprentissage. Notre m&#233;trique de classement doit donc tenir compte du nombre de
mots inconnus dans la phrase, en leur attribuant une pond&#233;ration ad&#233;quate. Il est alors n&#233;cessaire
d&#8217;introduire une p&#233;nalit&#233; &#491; appliqu&#233;e &#224; chacun des mots hors vocabulaire rencontr&#233;s dans les
phrases. Pour cela nous avons d&#233;termin&#233; empiriquement une valeur ad&#233;quate en v&#233;rifiant qu&#8217;elle
soit inf&#233;rieure au plus petit des logarithmes de probabilit&#233; attribu&#233; &#224; un mot connu. Celle-ci a
&#233;t&#233; fix&#233;e &#224; &#491; = &#8722;8. Finalement, le score LPOOV attribu&#233; &#224; une phrase traduite WK s&#8217;&#233;crit :
</p>
<p>LPOOV (W
K) =
</p>
<p>K&#8721;
</p>
<p>k=2
</p>
<p>logP (wk | wk&#8722;1wk&#8722;2) + OOV s&#215; &#491; (1)
</p>
<p>o&#249; OOV s est le nombre de mots hors vocabulaire de la phrase.
</p>
<p>Par la suite, nous classerons les phrases par maximisation du score LPOOV de l&#8217;&#233;quation 1.
</p>
<p>4 Exp&#233;rimentations et r&#233;sultats
</p>
<p>Le m&#233;ta-moteur a l&#8217;int&#233;ret de pr&#233;senter, pour une seule et m&#234;me phrase &#224; traduire, plusieurs tra-
ductions provenant de diff&#233;rents syst&#232;mes de traduction, d&#8217;une part, et de les pr&#233;senter class&#233;es
selon un crit&#232;re de qualit&#233;, d&#8217;autre part. C&#8217;est ce classement qui va &#234;tre jug&#233; lors des &#233;valua-
tions. Le syst&#232;me de classement est donc &#233;valu&#233;, avec les m&#233;thodes usuelles, en consid&#233;rant
uniquement la traduction qu&#8217;il classe premi&#232;re (1stBest). Il pr&#233;sente, en effet, un int&#233;r&#234;t parti-
culier s&#8217;il apporte plus d&#8217;information que l&#8217;utilisation d&#8217;un seul des moteurs de traduction, pris
s&#233;par&#233;ment, en l&#8217;occurrence le meilleur. On pr&#233;voit donc que les performances de notre syst&#232;me
soient meilleures que celles du meilleur moteur de traduction utilis&#233;. Pour v&#233;rifier cette hypo-
th&#232;se, nous proc&#233;derons &#224; une &#233;valuation automatique que l&#8217;on confirmera par une &#233;valuation
subjective.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Marion Potet
</p>
<p>4.1 Evaluation automatique
</p>
<p>La qualit&#233; des traductions est estim&#233;e automatiquement par la m&#233;trique existante la plus utilis&#233;e
dans le domaine, le score BLEU (Papineni et al., 2002), compl&#233;t&#233; avec le score NIST (Dod-
dington, 2002) et le score METEOR (Lavie &amp; Agarwal., 2005). La m&#233;trique BLEU repose sur
la comparaison de la sortie du traducteur avec les traductions dites de r&#233;f&#233;rence. Cette m&#233;trique
mesure le recouvrement lexical de la phrase traduite avec une ou plusieurs phrases donn&#233;es
comme r&#233;f&#233;rences de la traduction. Le score BLEU varie de 0 &#224; 1 et, &#233;tant un score de pr&#233;-
cision, il est d&#8217;autant meilleur qu&#8217;il est grand. N&#233;anmoins difficile &#224; interpr&#233;ter dans l&#8217;absolu,
nous comparerons le score BLEU de notre syst&#232;me au score Bleu des moteurs de traduction en
ligne utilis&#233;s. Les scores NIST et METEOR, quant &#224; eux, reprennent le principe du score BLEU
et l&#8217;adaptent l&#233;g&#232;rement.
</p>
<p>Le tableau 2 montre les r&#233;sultats de l&#8217;&#233;valuation des neufs moteurs de traduction utilis&#233;s. Ils sont
class&#233;s par ordre de performance, sur notre corpus de test align&#233; de 300 phrases. Le traducteur
MTG est en t&#234;te avec un score BLEU de 0,311. On constate &#233;galement que les scores NIST et
METEOR sont corr&#233;l&#233;s avec l&#8217;&#233;valuation BLEU.
</p>
<p>METEOR NIST BLEU
MTG 0,165 6,68 0,311
MTR 0,145 6,20 0,258
MTS 0,141 6,07 0,252
MTP 0,142 6,06 0,251
MTA 0,135 5,89 0,234
MTE 0,122 5,83 0,216
MTW 0,130 5,78 0,230
MTF 0,122 5,78 0,216
MTL 0,120 5,51 0,206
</p>
<p>TAB. 2 &#8211; Scores BLEU, NIST et METEOR des 9 moteurs de traduction sur notre corpus jour-
nalistique de 300 phrases
</p>
<p>Le tableau 3 pr&#233;sente les r&#233;sultats de l&#8217;&#233;valuation du classement propos&#233; par la m&#233;trique de
l&#8217;&#233;quation 1. L&#8217;ensemble des traductions class&#233;es premi&#232;res par notre syst&#232;me, que l&#8217;on nom-
mera par la suite 1stBest, obtient un score BLEU de 0,317. De la m&#234;me fa&#231;on, on appelle
respectivement 2ndBest et 3rdBest l&#8217;ensemble des traductions class&#233;es par le syst&#232;me en
deuxi&#232;me et troisi&#232;me position.
</p>
<p>METEOR NIST BLEU
1stBest 0,170 6,82 0,317
2ndBest 0,154 6,48 0,285
3rdBest 0,144 6,21 0,261
</p>
<p>TAB. 3 &#8211; Scores BLEU, NIST et METEOR des trois premiers r&#233;sultats de notre m&#233;ta-traducteur
</p>
<p>Le tableau 4 d&#233;taille la proportion des diff&#233;rents moteurs de traduction pr&#233;sents dans les trois
premiers r&#233;sultats. Bien que MTG soit pr&#233;sent &#224; 80,7 % dans les trois premi&#232;res r&#233;ponses don-
n&#233;es par le syst&#232;me, les autres traducteurs apparaissent &#233;galement en t&#234;te des r&#233;sultats du clas-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M&#233;ta-moteur de traduction automatique
</p>
<p>sement. Les neufs moteurs de traduction s&#233;lectionn&#233;s apportent donc tous leur contribution aux
performances des trois meilleurs s&#233;lectionn&#233;s.
</p>
<p>% MTG MTR MTP MTA MTS MTE MTL MTF MTW total
1stBest 54,88 21,44 5,4 5,7 2,8 4,3 3,4 2,0 0 100
2ndBest 15,3 46,4 13,0 6,0 5,8 6,0 4,3 4,3 0,9 100
3rdBest 46,8 8,5 8,8 8,0 9,0 6,3 4,8 4,5 3,0 100
Total 39,0 25,4 9,0 5,5 5,9 5,5 4,1 3,6 1,3 100
</p>
<p>TAB. 4 &#8211; Proportions des moteurs dans les trois premiers r&#233;sultats du m&#233;ta-traducteur
</p>
<p>En s&#233;lectionnant automatiquement la meilleure phrase, au sens de la m&#233;trique, propos&#233;e par
les neuf moteurs de traduction, notre syst&#232;me pr&#233;sente un score BLEU de 0,317 alors que le
meilleur des moteurs de traduction utilis&#233; (MTG) obtient un score de 0,311. Les scores NIST
et METEOR sont eux aussi nettement am&#233;lior&#233;s. N&#233;anmoins, il est difficile de savoir si ce gain
est r&#233;ellement significatif. De ce fait, il para&#238;t utile d&#8217;avoir recours &#224; une &#233;valuation humaine
subjective pour v&#233;rifier le r&#233;sultat obtenu de fa&#231;on automatique.
</p>
<p>4.2 Evaluation subjective
Le but de cette &#233;valuation subjective est de faire appel &#224; des annotateurs pour confirmer les
r&#233;sultats obtenus avec l&#8217;&#233;valuation automatique. V&#233;rifier le classement complet des traductions
par le syst&#232;me serait tr&#232;s complexe &#224; mettre en &#339;uvre, on pr&#233;f&#232;rera &#233;valuer le premier choix
&#233;tabli par notre syst&#232;me comparativement au meilleur des moteurs de traduction utilis&#233;, en
l&#8217;occurrence MTG.
</p>
<p>On &#233;value donc la meilleure traduction s&#233;lectionn&#233;e par notre syst&#232;me comparativement &#224; la
traduction que donne MTG. La consigne donn&#233;e aux participants est de choisir, parmi les deux
phrases, celle qui leur semble la meilleure, ou de n&#8217;effectuer aucun choix s&#8217;ils jugent celles-
ci &#233;quivalentes. Il y a donc trois r&#233;ponses possibles : la phrase donn&#233;e par notre syst&#232;me est
meilleure, la phrase donn&#233;e par MTG est meilleure, aucune n&#8217;est meilleure que l&#8217;autre. Il est &#224;
noter que nous ne pr&#233;cisons &#233;videmment pas la provenance des phrases.
</p>
<p>Seize volontaires ont particip&#233; &#224; l&#8217;exp&#233;rimentation et chaque phrase a &#233;t&#233; &#233;valu&#233;e par six annota-
teurs diff&#233;rents. Nous avons v&#233;rifi&#233; la coh&#233;rence des r&#233;ponses &#224; l&#8217;aide de l&#8217;indice de Bayes. Plus
l&#8217;erreur de Bayes est petite, plus les annotateurs sont coh&#233;rents dans leurs r&#233;ponses. Nous avons
donc &#233;limin&#233; les phrases pour lesquelles les annotateurs &#233;taient trop partag&#233;s, pour obtenir 78
phrases de test restantes (indice de Bayes &lt; 0,9).
Sur ces phrases, on peut donc dire que les participants pr&#233;f&#232;rent dans 55 % des cas les r&#233;ponses
renvoy&#233;es par notre syst&#232;me contre 33 % pour MTG.
</p>
<p>L&#8217;&#233;valuation subjective confirme l&#8217;&#233;valuation automatique : il est pr&#233;f&#233;rable d&#8217;utiliser une tra-
duction choisie parmi plusieurs, provenant de moteurs diff&#233;rents, que de n&#8217;utiliser syst&#233;mati-
quement que celui qui obtient le meilleur score moyen. On peut en d&#233;duire que ce concept de
m&#233;ta-traducteur est une solution pour am&#233;liorer la qualit&#233; des traductions et que le classement
propos&#233; par notre syst&#232;me est pertinent.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Marion Potet
</p>
<p>5 Cr&#233;ation d&#8217;une interface graphique en ligne
</p>
<p>Pour mettre ce service de m&#233;ta-traducteur &#224; disposition d&#8217;utilisateurs potentiels, nous avons cr&#233;&#233;
une interface graphique qui permet d&#8217;interagir avec le syst&#232;me &#224; partir du Web.
</p>
<p>L&#8217;interface permet &#224; l&#8217;utilisateur d&#8217;entrer un texte &#224; traduire et de choisir les moteurs de traduc-
tion &#224; utiliser parmi les 9 disponibles ( figure 1). Une fois le texte traduit entr&#233; et les moteurs
de traduction &#224; utiliser s&#233;lectionn&#233;s, l&#8217;utilisateur a le choix de l&#8217;affichage des r&#233;sultats. Ceux-ci
peuvent appara&#238;tre class&#233;s par ordre de pertinence ou non. L&#8217;option d&#8217;affichage class&#233; enverra la
requ&#234;te aux moteurs de traduction s&#233;lectionn&#233;s et, apr&#232;s r&#233;ception des r&#233;ponses, les &#233;valuera &#224;
l&#8217;aide du mod&#232;le de langage et les affichera class&#233;es (figure 2). L&#8217;option d&#8217;affichage non class&#233;
d&#233;roule le processus jusqu&#8217;&#224; r&#233;ception des requ&#234;tes et affiche les traductions selon leur ordre
d&#8217;arriv&#233;e sur le serveur. L&#8217;interface est accessible, &#224; partir de l&#8217;URL suivante :
http : //www&#8722; clips.imag.fr/geod/User/marion.potet/GUI/metatranslator.php.
</p>
<p>FIG. 1 &#8211; Interface graphique : page d&#8217;accueil
</p>
<p>6 Conclusion
</p>
<p>Au terme de ce travail, il ressort que, une solution possible pour am&#233;liorer la qualit&#233; de la
traduction automatique, est de tirer parti de la variabilit&#233; des r&#233;sultats de plusieurs syst&#232;mes
de traduction. C&#8217;est l&#8217;int&#233;ret et l&#8217;originalit&#233; de l&#8217;outil traductif propos&#233; dans cet article. Notre</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M&#233;ta-moteur de traduction automatique
</p>
<p>FIG. 2 &#8211; Interface graphique : r&#233;sultat d&#8217;une traduction
</p>
<p>m&#233;ta-traducteur utilise, en effet, plusieurs moteurs de traduction existants et met &#224; profit, pour
chaque situation, ceux qui semblent r&#233;pondre le mieux. La validation des solutions propos&#233;es a
&#233;t&#233; r&#233;alis&#233;e dans la cadre d&#8217;une traduction de phrases anglaises vers la langue fran&#231;aise de don-
n&#233;es de type journalistique. Pour chaque phrase donn&#233;e &#224; traduire, les traductions obtenues sont
class&#233;es selon un crit&#232;re qualitatif &#233;valu&#233; par une m&#233;trique reposant sur un mod&#232;le de langage.
Dans l&#8217;&#233;chantillon de phrases test&#233;, il s&#8217;est r&#233;v&#233;l&#233; &#234;tre plus pertinent de proposer la meilleure
traduction, s&#233;lectionn&#233;e automatiquement par notre syst&#232;me parmi les neufs hypoth&#232;ses de tra-
duction, que de proposer syst&#233;matiquement un seul des moteurs de traduction utilis&#233;. Ceci a &#233;t&#233;
confirm&#233; aussi bien lors de l&#8217;&#233;valuation automatique que lors de tests subjectifs aupr&#232;s d&#8217;utili-
sateurs potentiels. Au vu de ces r&#233;sultats, l&#8217;outil a &#233;t&#233; mis &#224; disposition sur le web &#224; travers une
interface graphique. Il est ainsi possible de soumettre un texte &#224; traduire, de s&#233;lectionner des
traducteurs automatiques &#224; interroger et de visualiser la liste des traductions propos&#233;es class&#233;es
par ordre de pertinence.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BIGI B. &amp; LE V. B. (2008). Normalisation et alignement de corpus fran&#231;ais et vietnamiens :
Format et logiciels. In 9es journ&#233;es internationales d&#8217;analyse statistique des donn&#233;es tex-
tuelles, France, Lyon.
</p>
<p>BROWN P. E., PIETRA V. J. D., PIETRA S. A. D. &amp; MERCER R. L. (1993). The mathematics
of machine translation : Parameter estimation. Computational linguistics, 19, 263&#8211;311.
</p>
<p>DODDINGTON G. (2002). Automatic evaluation of machine translation quality using n-gram
co-occurrence statistics. Human Language Technology Conference archive Proceedings of</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Marion Potet
</p>
<p>the second international conference on Human Language Technology Research, San Diego,
California, p. 138&#8211;145.
DUGAST L., SENELLART J. &amp; KOEHN P. (2008). Can we relearn an rbmt system ? In The
Third Workshop on statistical Machine Translation, Columbus, Ohio, USA, volume 3, p. 175&#8211;
179.
KOEHN P., DUGAST L. &amp; SEMELLARD J. (2007). Statistical post-editing on systran&#8217;s rule
based translation system. In The Second Workshop on Statistical Machine Translation, Prague,
Czech Republic, volume 23, p. 220&#8211;223.
KOEHN P., OCH F. J. &amp; MARCU D. (2003). Statistical phrase-based translation. In Confe-
rence of the North American Chapter of the Association for Computational Linguistics on
Human Language Technology, Edmonton, Canada, volume 1, p. 48&#8211;54.
LAVIE &amp; AGARWAL. (2005). Meteor : An automatic metric for mt evaluation with improved
correlation with human judgments. In Workshop on Statistical Machine Translation, Michigan,
USA, p. 65&#8211;72.
PAPINENI K., ROUKOS S., WARD T. &amp; ZHU W.-J. (2002). Bleu : A method for automatic
evaluation of machine translation. In the 40th Annual Meeting on Association for Computatio-
nal Linguistics SESSION : Machine translation and evaluation, Philadelphia, Pennsylvania,
p. 311&#8211;318.
RAYNER M. &amp; BOUILLON P. (1995). Hybrid transfer in an english-french spoken language
translator. In Journ&#233;es internationales : Language engineering, Montpellier, FRANCE, vo-
lume 15, p. 153&#8211;162.
SIMARD M., GOUTTE C. &amp; ISABELLE P. (2007). statistical phrase-based post-editing. In The
Conference of the North American Chapter of the Association for Computational Linguistics,
pages , Rochester, USA, p. 508&#8211;515.
STOLCKE A. (2002). Srilm, an extensible language modeling toolkit. In The International
Conference on Spoken Language Processing, Denver, Colorado, volume 3, p. 901&#8211;904.</p>

</div></div>
</body></html>