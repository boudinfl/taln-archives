<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Mod&#232;les statistiques pour l&#8217;estimation automatique de la difficult&#233; de textes de FLE</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>RECITAL 2009, Senlis, 24&#8211;26 juin 2009
</p>
<p>Mod&#232;les statistiques pour l&#8217;estimation automatique de la
difficult&#233; de textes de FLE
</p>
<p>Thomas Fran&#231;ois
Aspirant FNRS
</p>
<p>Centre de Traitement Automatique du Langage
Universit&#233; Catholique de Louvain
</p>
<p>thomas.francois@uclouvain.be
</p>
<p>R&#233;sum&#233;. La lecture constitue l&#8217;une des t&#226;ches essentielles dans l&#8217;apprentissage d&#8217;une
langue &#233;trang&#232;re. Toutefois, la d&#233;couverte d&#8217;un texte portant sur un sujet pr&#233;cis et qui soit adapt&#233;
au niveau de chaque apprenant est consommatrice de temps et pourrait &#234;tre automatis&#233;e. Des ex-
p&#233;riences montrent que, pour l&#8217;anglais, l&#8217;utilisation de classifieurs statistiques permet d&#8217;estimer
automatiquement la difficult&#233; d&#8217;un texte. Dans cet article, nous proposons une m&#233;thodologie
originale comparant, pour le fran&#231;ais langue &#233;trang&#232;re (FLE), diverses techniques de classifi-
cation (la r&#233;gression logistique, le bagging et le boosting) sur deux corpus d&#8217;entra&#238;nement. Il
ressort de cette analyse comparative une l&#233;g&#232;re sup&#233;riorit&#233; de la r&#233;gression logistique multino-
miale.
</p>
<p>Abstract. Reading is known to be an essential task in language learning, but finding the
appropriate text for every learner is far from easy. In this context, automatic procedures can sup-
port the teacher&#8217;s work. Some works on English reveal that it is possible to assess the readability
of texts using statistical classifiers. In this paper, we present an original approach comparing va-
rious classification techniques, namely logistic regression, bagging and boosting on two training
corpora. The results show a slight superiority for multinomial logistic regression over bagging
or boosting.
</p>
<p>Mots-cl&#233;s : lisibilit&#233;, r&#233;gression logistique, bagging, boosting, mod&#232;le de langue.
Keywords: readability, logistic regression, bagging, boosting, language model.
</p>
<p>1 Introduction
</p>
<p>Aujourd&#8217;hui, sous l&#8217;effet de l&#8217;&#233;largissement europ&#233;en et d&#8217;un accroissement de la mobilit&#233;, le
secteur de l&#8217;enseignement des langues se trouve en pleine croissance et l&#8217;offre peine &#224; suivre la
demande. Le d&#233;veloppement de l&#8217;ALAO (Apprentissage des Langues Assist&#233; par Ordinateur)
vise &#224; r&#233;pondre &#224; ces nouveaux besoins, notamment en automatisant certaines t&#226;ches r&#233;p&#233;titives
inh&#233;rentes &#224; l&#8217;enseignement des langues. Parmi celles-ci, la recherche de documents authen-
tiques portant sur un sujet pr&#233;cis et adapt&#233; au niveau des apprenants constitue une t&#226;che co&#251;-
teuse en temps. C&#8217;est pourquoi nous proposons dans cet article un mod&#232;le de lisibilit&#233; apte &#224;
estimer rapidement la difficult&#233; d&#8217;un texte sur la base d&#8217;algorithmes de classification. Il a pour
objectif de faciliter aussi bien le travail des concepteurs de supports p&#233;dagogiques que celui des
professeurs de FLE amen&#233;s &#224; utiliser l&#8217;Internet pour la pr&#233;paration de leur cours.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Thomas Fran&#231;ois
</p>
<p>Nous discutons des recherches ant&#233;rieures en lisibilit&#233; dans la section 2, avant de pr&#233;senter la
m&#233;thodologie propre &#224; notre approche. Celle-ci se base sur un corpus et une &#233;chelle de difficult&#233;,
pr&#233;sent&#233;s dans la section 3. De chacun des textes de ce corpus est ensuite extrait une s&#233;rie de
variables linguistiques d&#233;crites &#224; la section 4 et qui sont ensuite utilis&#233;es au sein de mod&#232;les
statistiques pr&#233;dictifs dont les d&#233;tails techniques sont r&#233;sum&#233;s &#224; la section 5. La section 6 d&#233;taille
quelques remarques propres &#224; notre impl&#233;mentation et la section 7 discute les r&#233;sultats obtenus.
Enfin, nous concluons avec la section 8 en avan&#231;ant diverses pistes de recherche.
</p>
<p>2 Recherches en lisibilit&#233;
</p>
<p>La premi&#232;re m&#233;thode visant &#224; &#233;valuer la difficult&#233; d&#8217;un texte pour un lectorat d&#233;termin&#233; fut le
jugement d&#8217;expert, qui recoure &#224; des crit&#232;res non explicites. Toutefois, dans les ann&#233;es 20, les
premi&#232;res m&#233;thodes reproductibles apparurent avec les travaux de Lively and Pressey (1923), &#224;
l&#8217;origine de la premi&#232;re formule de lisibilit&#233;. Par la suite, le domaine s&#8217;est d&#233;velopp&#233; et a produit,
pour l&#8217;anglais, une s&#233;rie de formules bas&#233;es sur des indices lexicaux et syntaxiques (Flesch,
1948; Chall &amp; Dale, 1995). Par contre, il faut attendre 1956 et l&#8217;ouvrage d&#8217;Andr&#233; Conquet, La
lisibilit&#233; (1971) pour que le monde francophone d&#233;couvre ce champ de recherche. Les premi&#232;res
formules pour le fran&#231;ais sont dues &#224; Kandel et Moles (1958) et de de Landsheere (1963), mais
elles ne constituent encore qu&#8217;une adaptation de la formule de Flesch, sans que soit pris en
compte l&#8217;ensemble des sp&#233;cificit&#233;s de la langue fran&#231;aise.
</p>
<p>La premi&#232;re formule sp&#233;cifique au fran&#231;ais est due &#224; Henry (1975). Ce chercheur exp&#233;rimente
un grand nombre de variables linguistiques dont il tire trois formules, de loin les plus utilis&#233;es
et plus les abouties pour le fran&#231;ais. &#201;trangement, bien peu de travaux suivent ces premi&#232;res
perc&#233;es. On ne compte que Richaudeau (1979), qui pr&#233;f&#232;re substituer aux formules de lisibi-
lit&#233; un crit&#232;re d&#8217;efficacit&#233; linguistique d&#233;velopp&#233; &#224; partir d&#8217;exp&#233;riences sur la m&#233;moire &#224; court
terme, et Mesnager (1989), qui con&#231;oit la formule la plus r&#233;cente pour le fran&#231;ais avec comme
population cible, les enfants. Pour Boss&#233;-Andrieu (1993), ce manque d&#8217;int&#233;r&#234;t s&#8217;explique par
des raisons culturelles : l&#8217;id&#233;e de mesurer un texte par des moyens objectifs constituerait une
approche trop pragmatique pour l&#8217;esprit fran&#231;ais.
</p>
<p>Quoi qu&#8217;il en soit, il faut noter que si peu de travaux en lisibilit&#233; ont port&#233; sur le fran&#231;ais
langue premi&#232;re (L1), on en compte encore moins qui se sont attach&#233;s aux particularit&#233;s du
FLE. Cornaire (1988) a test&#233; la validit&#233; de la formule de Henry pour le FLE et, plus r&#233;cemment,
Uitdenbogerd (2005) s&#8217;est int&#233;ress&#233;e, au travers des cognates, &#224; la prise en compte de la proxi-
mit&#233; lexicale entre deux langues et a d&#233;velopp&#233; une formule de FLE destin&#233;e &#224; des apprenants
anglophones.
</p>
<p>Confront&#233;s &#224; ce relatif oubli du domaine, nous nous sommes tourn&#233;s vers le monde anglo-saxon
o&#249; la lisibilit&#233; a connu un renouveau r&#233;cent sous l&#8217;impulsion du TAL et de techniques d&#8217;appren-
tissage automatique. Il est d&#233;sormais possible de tester la capacit&#233; pr&#233;dictive de variables plus
complexes. Ainsi, Collins-Thompson et al. (2005) ont propos&#233; un classifieur bay&#233;sien na&#239;f qui
correspond &#224; un mod&#232;le unigramme liss&#233;, montrant par l&#224; qu&#8217;il &#233;tait possible de remplacer les
listes de mots les plus communs par des mod&#232;les de langue. De leur c&#244;t&#233;, Schwarm et Os-
tendorf (2005) ont utilis&#233; des support vector machines (SVM) afin de combiner certaines des
variables classiques en lisibilit&#233; avec, d&#8217;une part, une s&#233;rie de mod&#232;les de langue trigrammes (un
mod&#232;le par niveau de difficult&#233;) et, d&#8217;autre part, des caract&#233;ristiques syntaxiques bas&#233;es sur des
arbres de d&#233;rivation. Heilman et al. (2007) ont enrichi le mod&#232;le unigramme de en lui ajoutant</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mod&#232;les statistiques pour l&#8217;estimation automatique de la difficult&#233; de textes de FLE
</p>
<p>la reconnaissance de structures syntaxiques, en vue d&#8217;estimer la difficult&#233; de textes en anglais
comme langue &#233;trang&#232;re. Par la suite, ils ont am&#233;lior&#233; la capacit&#233; pr&#233;dictive de leurs diverses
variables en utilisant des m&#233;thodes de r&#233;gression (Heilman et al., 2008). C&#8217;est sur la base de ces
diff&#233;rents travaux que nous avons &#233;tudi&#233; les possibilit&#233;s d&#8217;adaptation de diverses techniques &#224;
la lisibilit&#233; du FLE.
</p>
<p>3 Description du corpus
</p>
<p>La premi&#232;re &#233;tape dans le d&#233;veloppement d&#8217;une nouvelle formule de lisibilit&#233; consiste &#224; col-
lecter un corpus de textes qui soient d&#233;j&#224; cat&#233;goris&#233;s selon une &#233;chelle de difficult&#233;. Dans un
contexte europ&#233;en, il nous est apparu logique d&#8217;opter pour l&#8217;&#233;chelle qui sert de r&#233;f&#233;rence pour
l&#8217;ensemble des programmes d&#8217;&#233;ducation en langue &#233;trang&#232;re, &#224; savoir le Cadre europ&#233;en com-
mun de r&#233;f&#233;rence pour les langues (CECR) (Conseil de l&#8217;Europe, 2001) . Le CECR a d&#233;fini six
niveaux : A1 (le plus bas), A2, B1, B2, C1 et C2 (le plus &#233;lev&#233;)
Pour rassembler en nombre suffisant des textes &#233;tiquet&#233;s selon la m&#234;me &#233;chelle, nous avons
utilis&#233; des manuels de FLE qui, depuis la cr&#233;ation du CECR, ont connu une certaine standar-
disation en termes de difficult&#233;. Il est d&#232;s lors possible de constituer un corpus de documents
&#233;tiquet&#233;s par des experts en FLE. Cependant, seuls certains manuels sont adapt&#233;s aux objectifs
de notre recherche et tout leur contenu n&#8217;est pas utilisable. C&#8217;est pourquoi nous avons d&#233;fini des
crit&#232;res de s&#233;lection suivants :
&#8211; Les manuels doivent &#234;tre post&#233;rieurs &#224; 2001, date de la publication du CECR. Cette restriction
</p>
<p>permet &#233;galement de s&#8217;assurer que le langage contenu dans les textes soit proche du fran&#231;ais
actuel.
</p>
<p>&#8211; Seuls des manuels destin&#233;s &#224; des adultes ou des jeunes gens sont retenus puisqu&#8217;il s&#8217;agit de
la population de lecteurs vis&#233;e par notre formule.
</p>
<p>&#8211; Parmi les textes, n&#8217;ont &#233;t&#233; conserv&#233;s que ceux qui sont constitu&#233;s de phrases compl&#232;tes et qui
d&#233;pendent d&#8217;une t&#226;che de compr&#233;hension &#224; la lecture.
</p>
<p>En respectant ces crit&#232;res, nous avons rassembl&#233; pr&#232;s de 2 000 textes, repr&#233;sentant plus de
500 000 mots, et qui couvrent des sujets divers : extraits de litt&#233;rature, articles de journaux,
dialogues, recettes de cuisine... L&#8217;objectif est de permettre &#224; la formule obtenue une capacit&#233; de
g&#233;n&#233;ralisation optimale tout en rep&#233;rant les types de textes pour lesquels elle ne s&#8217;applique pas.
</p>
<p>4 Variables lexicales et syntaxiques
</p>
<p>Les travaux en lisibilit&#233; ont toujours vis&#233; &#224; param&#233;trer les textes sous la forme de variables
qui constituent de bons indices de la difficult&#233; (c.-&#224;-d. qui soient fortement corr&#233;l&#233;es avec cette
difficult&#233;). Les approches classiques, qui n&#8217;ont recouru qu&#8217;&#224; des variables de types lexical et
syntaxique, furent largement critiqu&#233;es par des cognitivistes tels que Kintsch and Vipond (1979)
et Kemper (1983). Ces auteurs soulign&#232;rent l&#8217;importance de prendre en compte les aspects
conceptuels des textes, tels que les relations entre phrases ou la charge inf&#233;rentielle. Bien que
th&#233;oriquement fond&#233;es, ces approches ne men&#232;rent pas &#224; des mod&#232;les ais&#233;ment reproductibles
et automatisables, ce qui explique le retour &#224; des variables lexicales et syntaxiques, en profitant
toutefois des avanc&#233;es du TAL. Notre recherche &#233;tant encore loin de son terme, nous n&#8217;avons
encore exp&#233;riment&#233; que quelques variables, d&#233;crites ci-dessous.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Thomas Fran&#231;ois
</p>
<p>4.1 Les variables classiques
</p>
<p>Parmi les pr&#233;dicteurs couramment utilis&#233;s, nous avons test&#233; le rapport type-token, le nombre
moyen de lettres par mot et la longueur moyenne des phrases. Nous n&#8217;avons conserv&#233; que les
deux derniers, qui pr&#233;sentaient une corr&#233;lation &#233;lev&#233;e avec la difficult&#233;. De plus, nous avons
repris chez Henry (1975, p. 85) cinq variables de dialogue : le rapport des pronoms person-
nels de dialogue (1re et 2e personnes) aux pronoms (PPD), la proportion d&#8217;interjections (PI), le
pourcentage de points d&#8217;exclamation et de points d&#8217;interrogation par rapport au nombre total de
signes de ponctuation (PPEI) et la pr&#233;sence de guillemets (BINGUI).
</p>
<p>4.2 La fr&#233;quence lexicale mesur&#233;e &#224; l&#8217;aide d&#8217;un mod&#232;le de langue
</p>
<p>La fr&#233;quence des mots d&#8217;un texte est consid&#233;r&#233;e depuis longtemps comme un excellent indice
de la complexit&#233; lexicale (Howes &amp; Solomon, 1951). Or, comme l&#8217;ont montr&#233; les travaux de
Collins-Thompson et al. (2005), les mod&#232;les de langue peuvent remplacer avantageusement les
listes de vocabulaire comme mode de param&#233;trisation. C&#8217;est pourquoi nous avons consid&#233;r&#233; la
probabilit&#233; d&#8217;un texte T (avec N mots wi) comme un indice de la complexit&#233; lexicale, calcul&#233;
sur base de l&#8217;&#233;quation 1 :
</p>
<p>P (T ) = P (w1)P (w2 | w1) &#183; &#183; &#183;P (wn | w1, w2, . . . , wn&#8722;1) (1)
</p>
<p>Cette &#233;quation soul&#232;ve deux probl&#232;mes :
1. La difficult&#233;, bien connue, d&#8217;estimer correctement l&#8217;ensemble de ces probabilit&#233;s condi-
</p>
<p>tionnelles. Nous avons opt&#233; pour un mod&#232;le par unigramme liss&#233; puisque, d&#8217;apr&#232;s Collins-
Thompson et al. (2005), il semble donner de bons r&#233;sultats. La probabilit&#233; d&#8217;un texte est
donc r&#233;duite &#224; l&#8217;&#233;quation suivante :
</p>
<p>P (T ) = exp(
n&#8721;
</p>
<p>i=1
</p>
<p>log[p(wi)]) (2)
</p>
<p>Le r&#233;sultat doit ensuite &#234;tre normalis&#233; en divisant par le nombre N de mots, afin de le
rendre ind&#233;pendant de la longueur du texte. Davantage de d&#233;tails concernant l&#8217;origine et
le lissage des probabilit&#233;s sont d&#233;crits dans la section 6.
</p>
<p>2. L&#8217;unit&#233; linguistique &#224; prendre en compte. Celle traditionnellement utilis&#233;e en lisibilit&#233; est
la forme fl&#233;chie, mais la nature flexionnelle du fran&#231;ais laisse supposer que le lemme
pourrait constituer une meilleure alternative. Par ailleurs, d&#8217;un point de vue th&#233;orique,
l&#8217;emploi des formes fl&#233;chies sous-entend que le lecteur n&#8217;est pas capable d&#8217;inf&#233;rer le sens
d&#8217;une forme inconnue m&#234;me s&#8217;il conna&#238;t une autre forme de ce m&#234;me mot, une position
qui para&#238;t critiquable pour la majorit&#233; des formes r&#233;guli&#232;res.
Dans le but d&#8217;&#233;claircir cette question &#224; l&#8217;aide de r&#233;sultats concrets, nous avons entra&#238;n&#233;
trois mod&#232;les de langue : un premier bas&#233; sur des lemmes1 (LM1), un second consid&#233;rant
les formes fl&#233;chies d&#233;sambigu&#239;s&#233;es en fonction de leur cat&#233;gorie(LM2) et un dernier re-
courant simplement aux formes fl&#233;chies (LM3)1. Cependant, l&#8217;exp&#233;rience n&#8217;a pas &#233;t&#233; tr&#232;s
informative, puisque ces trois variables sont corr&#233;l&#233;es de mani&#232;re assez similaire avec la
difficult&#233; dans nos diff&#233;rents sous-corpus de test. C&#8217;est pourquoi nous avons conserv&#233; les
trois variables lors de cette premi&#232;re &#233;tape.
</p>
<p>1Pour ces trois mod&#232;les, les textes ont &#233;t&#233; analys&#233;s &#224; l&#8217;aide du TreeTagger (Schmid, 1994).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mod&#232;les statistiques pour l&#8217;estimation automatique de la difficult&#233; de textes de FLE
</p>
<p>4.3 Mesure de la complexit&#233; verbale
</p>
<p>Une caract&#233;ristique int&#233;ressante de l&#8217;enseignement des langues &#233;trang&#232;res est la s&#233;quentialit&#233; de
l&#8217;apprentissage, c&#8217;est-&#224;-dire qu&#8217;on apprend certaines formes linguistiques avant d&#8217;autres. C&#8217;est
d&#8217;autant plus vrai pour la conjugaison o&#249; certains temps ou modes sont syst&#233;matiquement &#233;tu-
di&#233;s avant d&#8217;autres. Par cons&#233;quent, il est possible d&#8217;utiliser cette information comme pr&#233;dicteur
de la difficult&#233; de textes de FLE, &#233;tant donn&#233; qu&#8217;un apprenant d&#233;butant est peu susceptible de
conna&#238;tre le temps, le mode et l&#8217;aspect d&#8217;une forme verbale au pass&#233; simple et risque donc de
mal en saisir le sens.
</p>
<p>Nous avons ainsi d&#233;fini 11 variables binaires comme indices de cette complexit&#233; verbale : le
conditionnel, le futur, l&#8217;imp&#233;ratif, l&#8217;indicatif imparfait, l&#8217;infinitif, le participe pass&#233;, le participe
pr&#233;sent, le pass&#233; simple, l&#8217;indicatif pr&#233;sent, le subjonctif pr&#233;sent et le subjonctif imparfait.
</p>
<p>5 Pr&#233;sentation des mod&#232;les statistiques
</p>
<p>&#192; l&#8217;issue de cette &#233;tape de param&#233;trisation, nous avons obtenu, pour chacun des textes du cor-
pus, 20 pr&#233;dicteurs associ&#233;s &#224; une classe qui repr&#233;sente la difficult&#233;. Les raisons qui justifient de
consid&#233;rer la difficult&#233; comme une variable cat&#233;gorielle sont discut&#233;es dans Fran&#231;ois (2009) et
se r&#233;sument &#224; un manque d&#8217;ad&#233;quation aux donn&#233;es des mod&#232;les bas&#233;s sur une variable d&#233;-
pendante continue ou ordinale. En effet, nous avons montr&#233; que la r&#233;gression logistique mul-
tinomiale se r&#233;v&#233;lait sup&#233;rieure &#224; des classifieurs bas&#233;s sur la r&#233;gression lin&#233;aire, la r&#233;gression
logistique ordinale ou les arbres de d&#233;cision (Fran&#231;ois, 2009).
Par cons&#233;quent, nous avons voulu comparer la r&#233;gression logistique multinomiale &#224; deux autres
techniques de classification, consid&#233;r&#233;es comme parmi les plus efficaces : le bagging et le boos-
ting. Dans la suite de cette section, nous pr&#233;sentons bri&#232;vement ces trois techniques statistiques.
</p>
<p>5.1 La r&#233;gression logistique multinomiale
</p>
<p>La r&#233;gression logistique a d&#8217;abord &#233;t&#233; d&#233;velopp&#233;e pour des donn&#233;es binaires et, comme toutes
les techniques de r&#233;gression, elle vise &#224; mod&#233;liser l&#8217;esp&#233;rance conditionnelle E(Y | X), c.-&#224;-d.
la valeur moyenne attendue pour Y &#233;tant donn&#233; une valeur de X. &#192; la diff&#233;rence de la r&#233;gression
lin&#233;aire, qui mod&#233;lise cette esp&#233;rance &#224; l&#8217;aide d&#8217;une droite, la r&#233;gression logistique recourt &#224; une
courbe en S (sigmo&#239;de), &#233;vitant ainsi d&#8217;attribuer &#224; Y des valeurs sortant de l&#8217;intervalle [0, 1].
La r&#233;gression multinomiale (RLM) constitue une g&#233;n&#233;ralisation de cette technique pour un
probl&#232;me &#224; K classes et se r&#233;alise &#224; l&#8217;aide d&#8217;un mod&#232;le constitu&#233; de K&#8722; 1 sigmo&#239;des. Chacune
d&#8217;elles compare la classe k &#224; une cat&#233;gorie de r&#233;f&#233;rence (souvent la premi&#232;re), afin de retomber
sur le cas binaire. Ainsi, pour chacune de ces paires de classes (Yj, Y1), il existe une fonction
d&#233;crite sous forme matricielle par l&#8217;&#233;quation suivante (Agresti, 2002, p. 268) :
</p>
<p>log
P (Y = k | X = x)
</p>
<p>P (Y = 1 | X = x)
= &#945;k + &#946;
</p>
<p>T
k x k = 2, &#183; &#183; &#183; , K (3)
</p>
<p>o&#249; x est un vecteur observation, &#945;k et &#946;Tk repr&#233;sentent les param&#232;tres du mod&#232;le pour la classe
k. Sur la base de ces K &#8722; 1 &#233;quations, il est possible de calculer la probabilit&#233; qu&#8217;un texte</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Thomas Fran&#231;ois
</p>
<p>appartienne au niveau de difficult&#233; k pour un vecteur x donn&#233;. Cette probabilit&#233; est donn&#233;e par
l&#8217;&#233;quation suivante2 (Agresti, 2002, p. 271) :
</p>
<p>P (Y = k | X = x) =
exp(&#945;k + &#946;
</p>
<p>T
k x)
</p>
<p>1 +
&#8721;K
</p>
<p>k=2 exp(&#945;k + &#946;
T
k x)
</p>
<p>(4)
</p>
<p>L&#8217;estimation des param&#232;tres d&#8217;un tel mod&#232;le s&#8217;effectue par maximum de vraisemblance &#224; l&#8217;aide
d&#8217;une proc&#233;dure d&#233;crite dans Agresti (2002, p. 192).
</p>
<p>5.2 Le bagging et le boosting
</p>
<p>Le bagging et le boosting partagent le m&#234;me postulat th&#233;orique : mieux vaut un ensemble de
classifieurs qu&#8217;un seul. La difficult&#233; de cette approche provient de la n&#233;cessit&#233; de disposer d&#8217;un
corpus diff&#233;rent pour entra&#238;ner chacun des classifieurs. C&#8217;est dans leur mani&#232;re de r&#233;pondre &#224;
cette probl&#233;matique que les deux approches se distinguent.
</p>
<p>Le bagging, une technique d&#233;velopp&#233;e par Breiman (1996), va g&#233;n&#233;rer al&#233;atoirement N &#233;chan-
tillons par r&#233;&#233;chantillonnage, qui permettront d&#8217;entra&#238;ner N classifieurs. Par la suite, le niveau
d&#8217;un texte peut &#234;tre d&#233;fini comme la cat&#233;gorie majoritaire lors du vote de ces N classifieurs.
Le bagging pr&#233;sente l&#8217;avantage de r&#233;duire la variance d&#8217;un mod&#232;le et s&#8217;applique donc particu-
li&#232;rement bien &#224; des classifieurs instables, c.-&#224;-d. qui peuvent fortement varier en fonction des
donn&#233;es d&#8217;entra&#238;nement, tels que les arbres de d&#233;cision.
</p>
<p>Le boosting, mis au point par Freund and Schapire (1997), pr&#233;sente la particularit&#233; d&#8217;&#234;tre adap-
tatif, car il se concentre sur les donn&#233;es difficiles &#224; mod&#233;liser. C&#8217;est pourquoi l&#8217;algorithme le
plus connu s&#8217;appelle AdaBoost (Adaptative Boosting) et fonctionne de la mani&#232;re suivante :
&#8211; Un poids wi = 1N est attribu&#233; &#224; chacune des N observations du corpus d&#8217;entra&#238;nement. Sur
</p>
<p>la base de ce corpus, un classifieur ht(x) est entra&#238;n&#233; et une estimation de son taux d&#8217;erreur
&#491;t est obtenue (pour le d&#233;tail des formules, se reporter &#224; Meir and Ratsch (2003)).
</p>
<p>&#8211; Sur la base de cette estimation de l&#8217;erreur, on peut calculer le poids &#945;t du classifieur, avant de
r&#233;&#233;valuer le poids wi de chacune des observations, donnant plus d&#8217;importance aux donn&#233;es
mal class&#233;es et moins &#224; celles qui ont &#233;t&#233; correctement cat&#233;goris&#233;es.
</p>
<p>&#8211; Ces deux &#233;tapes sont it&#233;r&#233;es T fois, apr&#232;s quoi on obtient un ensemble de T classifieurs qui
attribuent &#224; un texte un niveau de difficult&#233; par un vote pond&#233;r&#233;, ce qui revient &#224; l&#8217;&#233;quation
suivante (Meir &amp; Ratsch, 2003, p. 118):
</p>
<p>fEns(x) =
T&#8721;
</p>
<p>t=1
</p>
<p>&#945;tht(x) (5)
</p>
<p>Le boosting ne convient normalement qu&#8217;&#224; une variable d&#233;pendante de type binaire. Nous avons
adapt&#233; cette technique pour un probl&#232;me &#224; K classes en recourant &#224; la strat&#233;gie du un contre
tous. Celle-ci d&#233;veloppe K ensembles, en opposant chaque classe k au reste des donn&#233;es. On
obtient donc K pr&#233;dicteurs qui, pour un texte donn&#233;, vont chacun estimer la probabilit&#233; que ce
texte appartienne &#224; la classe k. Reste alors &#224; attribuer &#224; ce texte la classe pour laquelle fEns,k(x)
est la plus &#233;lev&#233;e.
</p>
<p>2Notons que pour la cat&#233;gorie de r&#233;f&#233;rence (k = 1), &#945;1 et &#946;T1 = 0. Aussi, lors du calcul de la probabilit&#233; qu&#8217;un
texte appartienne &#224; cette cat&#233;gorie de r&#233;f&#233;rence, le num&#233;rateur vaut exp(0) = 1.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mod&#232;les statistiques pour l&#8217;estimation automatique de la difficult&#233; de textes de FLE
</p>
<p>6 Impl&#233;mentations
</p>
<p>Apr&#232;s avoir d&#233;crit les aspects th&#233;oriques de notre mod&#232;le, nous pr&#233;sentons quelques d&#233;tails de
son impl&#233;mentation, envisageant d&#8217;abord le mod&#232;le de langue, avant de s&#8217;arr&#234;ter sur la s&#233;lection
des variables linguistiques.
</p>
<p>Notre mod&#232;le de langue a n&#233;cessit&#233; de disposer d&#8217;une liste des lemmes et formes fl&#233;chies du
fran&#231;ais auxquels est associ&#233;e leur fr&#233;quence d&#8217;apparition dans la langue. Nous avons utilis&#233;
Lexique3, un lexique d&#233;velopp&#233; par New et al. (2001) qui contient plus de 50 000 lemmes dont
les fr&#233;quences ont &#233;t&#233; estim&#233;es sur un corpus de sous-titres de films rassemblant plus de 50
millions de mots. &#192; partir de ces fr&#233;quences, nous avons estim&#233; des probabilit&#233;s par maximum
de vraisemblance avant de les lisser &#224; l&#8217;aide de l&#8217;algorithme Simple Good-Turing d&#233;crit par Gale
et Sampson (1995). Cette &#233;tape est n&#233;cessaire pour &#234;tre capable d&#8217;attribuer une probabilit&#233; aux
mots n&#8217;ayant pas &#233;t&#233; observ&#233;s dans le corpus d&#8217;apprentissage.
</p>
<p>En ce qui concerne la s&#233;lection des variables, il convenait de d&#233;terminer, parmi les 20 pr&#233;dic-
teurs obtenus &#224; l&#8217;issue de la phase de param&#233;trisation, lesquels repr&#233;sentent les meilleurs pr&#233;-
dicteurs de la complexit&#233; d&#8217;un texte. Pour le bagging et le boosting, qui sont bas&#233;s sur des arbres
de d&#233;cision, la s&#233;lection de variables s&#8217;op&#232;re automatiquement &#224; chaque noeud de chaque arbre
gr&#226;ce au crit&#232;re de Gini. Par contre, pour la r&#233;gression logistique multinomiale, il est n&#233;cessaire
d&#8217;obtenir le mod&#232;le le plus parcimonieux possible, &#233;tant donn&#233; le nombre &#233;lev&#233; de param&#232;tres3.
Pour ce faire, nous avons utilis&#233; un algorithme de s&#233;lection pas &#224; pas des variables, qui compare
les diff&#233;rents mod&#232;les possibles et s&#233;lectionne celui qui est &#224; la fois efficace et parcimonieux.
Ce mod&#232;le est celui qui obtient la valeur AIC (Akaike&#8217;s Information Criterion) la plus &#233;lev&#233;e,
celle-ci &#233;tant d&#233;finie comme &#233;quivalent &#224; &#8722;2 &#8727; log-vraisemblance + 2p, o&#249; p correspond au
nombre de param&#232;tres du mod&#232;le et la log-vraisemblance s&#8217;obtient &#224; l&#8217;aide d&#8217;un calcul d&#233;taill&#233;
dans Hosmer and Lemeshow (1989).
</p>
<p>7 R&#233;sultats
</p>
<p>Une fois cette m&#233;thodologie mise en place, deux sous-corpus, obtenus par un r&#233;&#233;chantillonnage
du corpus global, ont &#233;t&#233; constitu&#233;s. Le premier d&#8217;entre eux comprend 288 textes r&#233;partis selon
les 6 niveaux du CECR, alors que le second rassemble 437 textes &#233;tal&#233;s sur les 9 niveaux de
difficult&#233;4 suivants : A1, A1+, A2, A2+, B1, B1+, B2, C1 et C2. Chaque niveau comprenait
50 textes, formant nos deux corpus desquels ont &#233;t&#233; exclus respectivement 12 et 13 donn&#233;es
aberrantes, d&#233;finis comme des donn&#233;es situ&#233;es au-del&#224; de 3 &#233;carts-types de leur moyenne (ce
qui correspond &#224; un &#945; de 0,0026).
Ensuite, pour chacun des deux corpus, trois classifieurs ont &#233;t&#233; entra&#238;n&#233;s, respectivement par
RLM, bagging et boosting. Les mod&#232;les obtenus ont &#233;t&#233; &#233;valu&#233;s &#224; l&#8217;aide des trois mesures
suivantes : la corr&#233;lation (r de Pearson) entre les niveaux r&#233;els des textes et les pr&#233;dictions,
l&#8217;exactitude des pr&#233;dictions (d&#233;finie comme le rapport du nombre de textes correctement class&#233;s
sur le nombre total de textes) et l&#8217;exactitude contigu&#235;5.
</p>
<p>3Ce nombre d&#233;pend du nombre K de classes et du nombre X de variables ind&#233;pendantes selon la relation
suivante : nombre de param&#232;tres = (K &#8722; 1)(X + 1).
</p>
<p>4L&#8217;objectif de cette seconde &#233;chelle est de mod&#233;liser plus finement les premi&#232;res &#233;tapes de l&#8217;apprentissage o&#249;
les diff&#233;rences se font davantage sentir au sein d&#8217;un m&#234;me niveau.
</p>
<p>5Cette mesure est d&#233;finie par Heilman et al. (2008) comme la proportion de pr&#233;dictions qui s&#8217;&#233;loigne au plus</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Thomas Fran&#231;ois
</p>
<p>Mesure RLM bagging boosting Mesure RLM bagging boosting
R&#233;sultats sur les &#233;chantillons d&#8217;apprentissage
</p>
<p>Sous-corpus &#224; 6 niveaux de difficult&#233; Sous-corpus &#224; 9 niveaux de difficult&#233;
Corr&#233;lation 0, 70 1 0, 97 Corr&#233;lation 0, 74 1 0, 99
Exactitude 50% 100% 97% Exactitude 41% 100% 97%
</p>
<p>Exac. contigu&#235; 76% 100% 98% Exac. contigu&#235; 66% 100% 98%
R&#233;sultats sur les &#233;chantillons de test
</p>
<p>Sous-corpus &#224; 6 niveaux de difficult&#233; Sous-corpus &#224; 9 niveaux de difficult&#233;
Corr&#233;lation 0, 62 0, 60 0, 64 Corr&#233;lation 0, 72 0, 69 0, 68
Exactitude 41% 37% 40% Exactitude 32% 29% 29%
</p>
<p>Exac. contigu&#235; 71% 70% 70% Exac. contigu&#235; 63% 65% 64%
</p>
<p>TAB. 1 &#8211; Estimation, par une proc&#233;dure de validation crois&#233;e, du coefficient de Pearson&#8217;s, de
l&#8217;exactitude et de l&#8217;exactitude contigu&#235; pour les diff&#233;rents classifieurs.
</p>
<p>Pour chacun des classifieurs, nous avons effectu&#233; une proc&#233;dure de validation crois&#233;e &#224; dix
&#233;chantillons afin d&#8217;estimer plus pr&#233;cis&#233;ment les trois mesures d&#8217;&#233;valuation. La Table 1 pr&#233;sente
les r&#233;sultats obtenus sur nos deux sous-corpus. Notons que, sur les deux corpus et pour les
diff&#233;rentes mesures d&#8217;&#233;valuation, les trois classifieurs pr&#233;sentent des r&#233;sultats qui ne sont pas
significativement diff&#233;rents. Il est donc impossible de conclure &#224; la sup&#233;riorit&#233; de l&#8217;un des mo-
d&#232;les statistiques, m&#234;me si la m&#233;thode qui semble se comporter le mieux est la RLM. Sachant de
plus que le temps n&#233;cessaire &#224; l&#8217;entra&#238;nement d&#8217;un tel mod&#232;le est consid&#233;rablement plus r&#233;duit
que celui pour le bagging et surtout le boosting, il nous semble que la RLM constitue le meilleur
choix aussi bien au niveau de l&#8217;optimisation du temps de calcul qu&#8217;au niveau de l&#8217;efficacit&#233; du
mod&#232;le. Cette conclusion concorde avec nos r&#233;sultats pr&#233;c&#233;dents (Fran&#231;ois, 2009).
En termes d&#8217;efficacit&#233;, l&#8217;exactitude obtenue (respectivement 41% et 32% pour la RLM) para&#238;t
peu satisfaisante. L&#8217;exactitude contigu&#235; r&#233;v&#232;le cependant que les pr&#233;dictions se concentrent as-
sez bien autour de la diagonale de la matrice de confusion, ce qui signifie que les textes sont
plus ou moins bien class&#233;s &#224; un niveau pr&#232;s. D&#8217;ailleurs, si nous comparons ces r&#233;sultats &#224; la
seule approche similaire pour le fran&#231;ais, r&#233;alis&#233;e par Collins-Thompson et Callan (2005) (qui
obtiennent une corr&#233;lation de 0,64 entre leur variable d&#233;pendante &#224; 5 classes et leurs pr&#233;dic-
teurs), nous nous situons dans le m&#234;me ordre de grandeur, avec un r de 0,62 pour 6 classes et
de 0,72 pour 9 classes.
</p>
<p>Cette similarit&#233; dans les r&#233;sultats confirme que pr&#233;dire automatiquement la difficult&#233; d&#8217;un texte
constitue une t&#226;che ardue. Les meilleurs taux pour l&#8217;anglais, o&#249; la recherche dans ce domaine est
plus avanc&#233;e, ne d&#233;passent d&#8217;ailleurs pas 52% d&#8217;exactitude contigu&#235; pour 12 classes (Heilman
et al., 2008). Le probl&#232;me s&#8217;explique aussi par le fait que les psychologues n&#8217;aient pas encore
r&#233;ussi &#224; s&#8217;accorder sur une description explicite des facteurs qui font la complexit&#233; d&#8217;un texte.
D&#232;s lors, les chercheurs en lisibilit&#233; en sont r&#233;duits &#224; v&#233;rifier exp&#233;rimentalement l&#8217;importance
des diff&#233;rentes variables.
</p>
<p>d&#8217;un niveau par rapport &#224; celui qui a &#233;t&#233; attribu&#233; au texte par un humain. Son emploi se justifie par la difficult&#233;
qu&#8217;ont divers experts humains &#224; accorder leur jugement sur un ensemble de textes. Il ne faut toutefois pas oublier
qu&#8217;elle fournit des valeurs exag&#233;r&#233;ment optimistes lorsqu&#8217;il y a peu de cat&#233;gories.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mod&#232;les statistiques pour l&#8217;estimation automatique de la difficult&#233; de textes de FLE
</p>
<p>8 Perspectives de recherche
</p>
<p>En vue d&#8217;une am&#233;lioration des performances, les deux axes suivants seront poursuivis. D&#8217;une
part, il s&#8217;agira d&#8217;exp&#233;rimenter un plus grand nombre d&#8217;indices de difficult&#233;. Nous pensons ainsi
recourir &#224; un mod&#232;le lexical par n-grammes, distinguer entre mots concrets et abstraits ou en-
core utiliser diverses informations obtenues sur la base d&#8217;un analyseur syntaxique, telles que le
nombre moyen de n&#339;uds par phrase, le nombre moyen de propositions par phrase ou encore la
profondeur lexicale moyenne (Bormuth, 1966).
D&#8217;autre part, une grande part de la perte de performance s&#8217;explique par le bruit contenu dans
le corpus. En effet, les mat&#233;riaux r&#233;colt&#233;s au sein de manuels de FLE ont le d&#233;faut de pr&#233;senter
une grande variabilit&#233; au sein d&#8217;un m&#234;me niveau. Il convient donc de d&#233;velopper un moyen de
r&#233;duire ce bruit. Pour l&#8217;instant, nous envisageons d&#8217;entra&#238;ner les mod&#232;les en plusieurs passes au
cours desquelles les textes trop mal pr&#233;dits seraient exclus du corpus d&#8217;apprentissage.
</p>
<p>Par ailleurs, comme nos exp&#233;rimentations montrent que l&#8217;emploi de diverses m&#233;thodes de clas-
sification ne d&#233;bouche pas sur une am&#233;lioration sensible des r&#233;sultats, nous envisageons de
limiter les investigations dans ce sens &#224; une seule autre m&#233;thode de classification bien connue,
les SVM. Ces diff&#233;rentes exp&#233;riences permettront d&#8217;obtenir une estimation pr&#233;cise de l&#8217;impor-
tance de chacun de ces trois facteurs que sont le corpus d&#8217;apprentissage, les pr&#233;dicteurs et les
techniques de classification dans la construction de nouvelles formules de lisibilit&#233; bas&#233;es sur
des techniques de TAL.
</p>
<p>R&#233;f&#233;rences
AGRESTI A. (2002). Categorical Data Analysis. 2nd edition. New York: Wiley-Interscience.
BORMUTH J. (1966). Readability: A new approach. Reading research quarterly, p. 79&#8211;132.
BOSS&#201;-ANDRIEU J. (1993). La question de la lisibilit&#233; dans les pays anglophones et les pays
francophones. Technostyle, Association canadienne des professeurs de r&#233;daction technique et
scientifique, 11(2), 73&#8211;85.
BREIMAN L. (1996). Bagging predictors. Machine learning, 24(2), 123&#8211;140.
CHALL J. &amp; DALE E. (1995). Readability Revisited: The New Dale-Chall Readability For-
mula. Cambridge: Brookline Books.
COLLINS-THOMPSON K. &amp; CALLAN J. (2005). Predicting reading difficulty with statistical
language models. Journal of the American Society for Information Science and Technology,
56(13), 1448&#8211;1462.
CONQUET A. (1971). La lisibilit&#233;. Paris: Assembl&#233;e Permanente des CCI de Paris.
CONSEIL DE L&#8217;EUROPE . (2001). Cadre europ&#233;en commun de r&#233;f&#233;rence pour les langues.
CORNAIRE C. (1988). La lisibilit&#233; : essai d&#8217;application de la formule courte d&#8217;Henry au
fran&#231;ais langue &#233;trang&#232;re. Canadian Modern Language Review, 44(2), 261&#8211;273.
DE LANDSHEERE G. (1963). Pour une application des tests de lisibilit&#233; de Flesch &#224; la langue
fran&#231;aise. Le Travail Humain, 26, 141&#8211;154.
FLESCH R. (1948). A new readability yardstick. Journal of Applied Psychology, 32(3), 221&#8211;
233.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Thomas Fran&#231;ois
</p>
<p>FRAN&#199;OIS T. (2009). Combining a Statistical Language Model with Logistic Regression to
Predict the Lexical and Syntactic Difficulty of Texts for FFL. In Proceedings of the EACL
2009 Student Research Workshop, p. 19&#8211;27, Athens, Greece.
GALE W. &amp; SAMPSON G. (1995). Good-Turing frequency estimation without tears. Journal
of Quantitative Linguistics, 2(3), 217&#8211;237.
HEILMAN M., COLLINS-THOMPSON K., CALLAN J. &amp; ESKENAZI M. (2007). Combining
lexical and grammatical features to improve readability measures for first and second language
texts. In Proceedings of NAACL HLT, p. 460&#8211;467.
HEILMAN M., COLLINS-THOMPSON K. &amp; ESKENAZI M. (2008). An analysis of statistical
models and features for reading difficulty prediction. Association for Computational Linguis-
tics, The 3rd Workshop on Innovative Use of NLP for Building Educational Applications,
1&#8211;8.
HENRY G. (1975). Comment mesurer la lisibilit&#233;. Labor.
HOSMER D. &amp; LEMESHOW S. (1989). Applied Logistic Regression. New York: Wiley.
HOWES D. &amp; SOLOMON R. (1951). Visual duration threshold as a function of word probabi-
lity. Journal of Experimental Psychology, 41(40), 1&#8211;4.
KANDEL L. &amp; MOLES A. (1958). Application de l&#8217;indice de Flesch &#224; la langue fran&#231;aise.
Cahiers &#201;tudes de Radio-T&#233;l&#233;vision, 19, 253&#8211;274.
KEMPER S. (1983). Measuring the inference load of a text. Journal of Educational Psycho-
logy, 75(3), 391&#8211;401.
KINTSCH W. &amp; VIPOND D. (1979). Reading comprehension and readability in educational
practice and psychological theory. Perspectives on Memory Research, p. 329&#8211;366.
LIVELY B. &amp; PRESSEY S. (1923). A method for measuring the &quot;vocabulary burden&quot; of
textbooks. Educational Administration and Supervision, 9, 389&#8211;398.
MEIR R. &amp; RATSCH G. (2003). An introduction to boosting and leveraging. Lecture Notes in
Computer Science, 2600, 118&#8211;183.
MESNAGER J. (1989). Lisibilit&#233; des textes pour enfants: un nouvel outil ? Communication et
Langages, 79, 18&#8211;38.
NEW B., PALLIER C., FERRAND L. &amp; MATOS R. (2001). Une base de donn&#233;es lexicales du
fran&#231;ais contemporain sur internet: LEXIQUE. L&#8217;Ann&#233;e Psychologique, 101, 447&#8211;462.
RICHAUDEAU F. (1979). Une nouvelle formule de lisibilit&#233;. Communication et Langages, 44,
5&#8211;26.
SCHAPIRE R. &amp; FREUND Y. (1997). A decision theoretic generalization of on-line learning
and an application to boosting. Journal Computer and System Sciences, 55, 119&#8211;139.
SCHMID H. (1994). Probabilistic part-of-speech tagging using decision trees. In Proceedings
of International Conference on New Methods in Language Processing, volume 12: Manches-
ter, UK.
SCHWARM S. &amp; OSTENDORF M. (2005). Reading level assessment using support vector
machines and statistical language models. Proceedings of the 43rd Annual Meeting on Asso-
ciation for Computational Linguistics, p. 523&#8211;530.
UITDENBOGERD S. (2005). Readability of French as a foreign language and its uses. In
Proceedings of the Australian Document Computing Symposium, p. 19&#8211;25.</p>

</div></div>
</body></html>