RECITAL 2009, Senlis, 24-26 juin 2009

Modéles statistiques pour l’estimation automatique de la
difﬁculté de textes de FLE

Thomas Francois
Aspirant FNRS
Centre de Traitement Automatique du Langage
Université Catholique de Louvain
thomas.francois @ uclouvain.be

Résumé. La lecture constitue l’une des taches essentielles dans l’apprentissage d’une
langue étrangere. Toutefois, la découverte d’un texte portant sur un suj et précis et qui soit adapté
au niveau de chaque apprenant est consommatrice de temps et pourrait étre automatisée. Des ex-
périences montrent que, pour l’anglais, l’utilisation de classiﬁeurs statistiques permet d’estimer
automatiquement la difﬁculté d’un texte. Dans cet article, nous proposons une méthodologie
originale comparant, pour le francais langue étrangere (FLE), diverses techniques de classiﬁ-
cation (la régression logistique, le bagging et le boosting) sur deux corpus d’entrainement. Il
ressort de cette analyse comparative une légere supériorité de la régression logistique multino-
miale.

Abstract. Reading is known to be an essential task in language learning, but ﬁnding the
appropriate text for every learner is far from easy. In this context, automatic procedures can sup-
port the teacher’s work. Some works on English reveal that it is possible to assess the readability
of texts using statistical classiﬁers. In this paper, we present an original approach comparing va-
rious classiﬁcation techniques, namely logistic regression, bagging and boosting on two training
corpora. The results show a slight superiority for multinomial logistic regression over bagging
or boosting.

M0tS-CléS I lisibilité, régression logistique, bagging, boosting, modele de langue.

Keywords: readability, logistic regression, bagging, boosting, language model.

1 Introduction

Aujourd’hui, sous l’effet de l’élargissement européen et d’un accroissement de la mobilité, le
secteur de l’enseignement des langues se trouve en pleine croissance et l’offre peine a suivre la
demande. Le développement de l’ALAO (Apprentissage des Langues Assisté par Ordinateur)
vise a répondre a ces nouveaux besoins, notamment en automatisant certaines taches répétitives
inhérentes a l’enseignement des langues. Parmi celles-ci, la recherche de documents authen-
tiques portant sur un sujet précis et adapté au niveau des apprenants constitue une tache cou-
teuse en temps. C’est pourquoi nous proposons dans cet article un modele de lisibilité apte a
estimer rapidement la difﬁculté d’un texte sur la base d’algorithmes de classiﬁcation. Il a pour
objectif de faciliter aussi bien le travail des concepteurs de supports pédagogiques que celui des
professeurs de FLE amenés a utiliser l’Internet pour la préparation de leur cours.

Thomas Francois

Nous discutons des recherches antérieures en lisibilité dans la section 2, avant de présenter la
méthodologie propre a notre approche. Celle-ci se base sur un corpus et une échelle de difﬁculté,
présentés dans la section 3. De chacun des textes de ce corpus est ensuite extrait une série de
variables linguistiques décrites a la section 4 et qui sont ensuite utilisées au sein de modeles
statistiques prédictifs dont les détails techniques sont résumés a la section 5. La section 6 détaille
quelques remarques propres a notre implémentation et la section 7 discute les résultats obtenus.
Enﬁn, nous concluons avec la section 8 en avancant diverses pistes de recherche.

2 Recherches en lisibilité

La premiere méthode visant a évaluer la difﬁculté d’un texte pour un lectorat déterminé fut le
jugement d’expert, qui recoure a des criteres non explicites. Toutefois, dans les années 20, les
premieres méthodes reproductibles apparurent avec les travaux de Lively and Pressey (1923), a
l’origine de la premiere formule de lisibilité. Par la suite, le domaine s’ est développé et a produit,
pour l’anglais, une série de formules basées sur des indices lexicaux et syntaxiques (Flesch,
1948; Chall & Dale, 1995). Par contre, il faut attendre 1956 et l’ouvrage d’André Conquet, La
lisibilité (1971) pour que le monde francophone découvre ce champ de recherche. Les premieres
formules pour le francais sont dues a Kandel et Moles (1958) et de de Landsheere (1963), mais
elles ne constituent encore qu’une adaptation de la formule de Flesch, sans que soit pris en
compte l’ensemble des spéciﬁcités de la langue francaise.

La premiere formule spéciﬁque au francais est due a Henry (1975). Ce chercheur expérimente
un grand nombre de variables linguistiques dont il tire trois formules, de loin les plus utilisées
et plus les abouties pour le francais. Etrangement, bien peu de travaux suivent ces premieres
percées. On ne compte que Richaudeau (1979), qui préfere substituer aux formules de lisibi-
lité un critere d’efﬁcacité linguistique développé a partir d’expériences sur la mémoire a court
terme, et Mesnager (1989), qui concoit la formule la plus récente pour le francais avec comme
population cible, les enfants. Pour Bossé-Andrieu (1993), ce manque d’intérét s’explique par
des raisons culturelles : l’idée de mesurer un texte par des moyens objectifs constituerait une
approche trop pragmatique pour l’esprit francais.

Quoi qu’il en soit, il faut noter que si peu de travaux en lisibilité ont porté sur le francais
langue premiere (L1), on en compte encore moins qui se sont attachés aux particularités du
FLE. Cornaire (1988) a testé la validité de la formule de Henry pour le FLE et, plus récemment,
Uitdenbogerd (2005) s’est intéressée, au travers des cognates, a la prise en compte de la proxi-
Inité lexicale entre deux langues et a développé une formule de FLE destinée a des apprenants
anglophones.

Confrontés a ce relatif oubli du domaine, nous nous sommes toumés vers le monde anglo-saxon
ou la lisibilité a connu un renouveau récent sous l’impulsion du TAL et de techniques d’appren-
tissage automatique. Il est désormais possible de tester la capacité prédictive de variables plus
complexes. Ainsi, Collins-Thompson et al. (2005) ont proposé un classiﬁeur bayésien na'1'f qui
correspond a un modele unigramme lissé, montrant par la qu’il était possible de remplacer les
listes de mots les plus communs par des modeles de langue. De leur cote, Schwarm et Os-
tendorf (2005) ont utilisé des support vector machines (SVM) aﬁn de combiner certaines des
variables classiques en lisibilité avec, d’une part, une série de modeles de langue trigrammes (un
modele par niveau de difﬁculté) et, d’autre part, des caractéristiques syntaxiques basées sur des
arbres de dérivation. Heilman et al. (2007) ont enrichi le modele unigramme de en lui ajoutant

Modeles statistiques pour l’estimation automatique de la difﬁculté de textes de FLE

la reconnaissance de structures syntaxiques, en vue d’estimer la difﬁculté de textes en anglais
comme langue étrangere. Par la suite, ils ont amélioré la capacité prédictive de leurs diverses
variables en utilisant des méthodes de régression (Heilman et al. , 2008). C’est sur la base de ces
différents travaux que nous avons étudié les possibilités d’adaptation de diverses techniques a
la lisibilité du FLE.

3 Description du corpus

La premiere étape dans le développement d’une nouvelle formule de lisibilité consiste a col-
lecter un corpus de textes qui soient déja catégorisés selon une échelle de difﬁculté. Dans un
contexte européen, il nous est apparu logique d’opter pour l’échelle qui sert de référence pour
l’ensemble des programmes d’éducation en langue étrangere, a savoir le Cadre européen com-
mun de référence pour les langues (CECR) (Conseil de l’Europe, 2001) . Le CECR a déﬁni six
niveaux : A1 (le plus bas), A2, B1, B2, C1 et C2 (le plus élevé)

Pour rassembler en nombre sufﬁsant des textes étiquetés selon la meme échelle, nous avons
utilisé des manuels de FLE qui, depuis la création du CECR, ont connu une certaine standar-
disation en termes de difﬁculté. Il est des lors possible de constituer un corpus de documents
étiquetés par des experts en FLE. Cependant, seuls certains manuels sont adaptés aux objectifs
de notre recherche et tout leur contenu n’est pas utilisable. C’est pourquoi nous avons déﬁni des
criteres de sélection suivants :

— Les manuels doivent étre postérieurs a 2001, date de la publication du CECR. Cette restriction
permet également de s’assurer que le langage contenu dans les textes soit proche du francais
actuel.

— Seuls des manuels destinés a des adultes ou des jeunes gens sont retenus puisqu’il s’agit de
la population de lecteurs visée par notre formule.

— Parmi les textes, n’ont été conservés que ceux qui sont constitués de phrases completes et qui
dépendent d’une tache de compréhension a la lecture.

En respectant ces criteres, nous avons rassemblé pres de 2 000 textes, représentant plus de
500 000 mots, et qui couvrent des sujets divers : extraits de littérature, articles de journaux,
dialogues, recettes de cuisine... L’ objectif est de permettre a la formule obtenue une capacité de
généralisation optimale tout en repérant les types de textes pour lesquels elle ne s’applique pas.

4 Variables lexicales et syntaxiques

Les travaux en lisibilité ont toujours visé a paramétrer les textes sous la forme de variables
qui constituent de bons indices de la difﬁculté (c.-a-d. qui soient fortement corrélées avec cette
difﬁculté). Les approches classiques, qui n’ont recouru qu’a des variables de types lexical et
syntaxique, furent largement critiquées par des cognitivistes tels que Kintsch and Vipond (1979)
et Kemper (1983). Ces auteurs soulignerent l’importance de prendre en compte les aspects
conceptuels des textes, tels que les relations entre phrases ou la charge inférentielle. Bien que
théoriquement fondées, ces approches ne menerent pas a des modeles aisément reproductibles
et automatisables, ce qui explique le retour a des variables lexicales et syntaxiques, en proﬁtant
toutefois des avancées du TAL. Notre recherche étant encore loin de son terme, nous n’avons
encore expérimenté que quelques variables, décrites ci-dessous.

Thomas Francois

4.1 Les variables classiques

Parmi les prédicteurs couramment utilisés, nous avons testé le rapport type-token, le nombre
moyen de lettres par mot et la longueur moyenne des phrases. Nous n’avons conservé que les
deux derniers, qui présentaient une corrélation élevée avec la difﬁculté. De plus, nous avons
repris chez Henry (1975, p. 85) cinq variables de dialogue : le rapport des pronoms person-
nels de dialogue (1‘° et 2° personnes) aux pronoms (PPD), la proportion d’interjections (PI), le
pourcentage de points d’exclamation et de points d’interrogation par rapport au nombre total de
signes de ponctuation (PPEI) et la présence de guillemets (BINGUI).

4.2 La fréquence lexicale mesurée 2‘1l’aide d’un modéle de langue

La fréquence des mots d’un texte est considérée depuis longtemps comme un excellent indice
de la complexité lexicale (Howes & Solomon, 1951). Or, comme l’ont montré les travaux de
Collins-Thompson et al. (2005), les modeles de langue peuvent remplacer avantageusement les
listes de vocabulaire comme mode de paramétrisation. C’est pourquoi nous avons considéré la
probabilité d’un texte T (avec N mots 11),) come un indice de la complexité lexicale, calculé
sur base de l’équation 1 :

P(T) = P(w1)P(w2 | wl) - - -P(wn | 1111,1112, . . .,wn_1) (1)

Cette équation souleve deux problemes :

1. La difﬁculté, bien connue, d’estimer correctement l’ensemble de ces probabilités condi-
tionnelles. Nous avons opté pour un modele par unigramme lissé puisque, d’ apres Collins-
Thompson et al. (2005), i1 semble donner de bons résultats. La probabilité d’un texte est
donc réduite a l’équation suivante :

Pm = ea.-p<_i1og[p<w.->1) <2)

Le résultat doit ensuite étre normalisé en divisant par le nombre N de mots, aﬁn de le
rendre indépendant de la longueur du texte. Davantage de détails concernant l’origine et
le lissage des probabilités sont décrits dans la section 6.

2. L’ unité linguistique a prendre en compte. Celle traditionnellement utilisée en lisibilité est

la forme ﬂéchie, mais la nature ﬂexionnelle du francais laisse supposer que le lemme
pourrait constituer une meilleure alternative. Par ailleurs, d’un point de vue théorique,
l’emploi des formes ﬂéchies sous-entend que le lecteur n’est pas capable d’inférer le sens
d’une forme inconnue méme s’il connait une autre forme de ce méme mot, une position
qui parait critiquable pour la maj orité des formes régulieres.
Dans le but d’éclaircir cette question a l’aide de résultats concrets, nous avons entrainé
trois modeles de langue : un premier basé sur des lemmesl (LM1), un second considérant
les formes ﬂéchies désambiguisées en fonction de leur catégorie(LM2) et un demier re-
courant simplement aux formes ﬂéchies (LM3)1. Cependant, l’expérience n’a pas été tres
informative, puisque ces trois variables sont corrélées de maniere assez similaire avec la
difﬁculté dans nos différents sous-corpus detest. C’est pourquoi nous avons conservé les
trois variables lors de cette premiere étape.

1Pour ces trois modéles, les textes ont été analysés a l’aide du TreeTagger (Sch1nid, 1994).

Modeles statistiques pour l’estimation automatique de la difﬁculte de textes de FLE

4.3 Mesure de la complexité verbale

Une caracteristique interessante de l’enseignement des langues etrangeres est la sequentialite de
l’apprentissage, c’est-a-dire qu’on apprend certaines formes linguistiques avant d’autres. C’est
d’autant plus vrai pour la conjugaison ou certains temps ou modes sont systematiquement etu-
dies avant d’autres. Par consequent, il est possible d’utiliser cette information comme predicteur
de la difﬁculte de textes de FLE, etant donne qu’un apprenant debutant est peu susceptible de
connaitre le temps, le mode et l’aspect d’une forme verbale au passe simple et risque donc de
mal en saisir le sens.

Nous avons ainsi deﬁni 11 variables binaires comme indices de cette complexite verbale : le
conditionnel, le futur, l’imperatif, l’indicatif imparfait, l’inﬁnitif, le participe passe, le participe
present, le passe simple, l’indicatif present, le subjonctif present et le subjonctif imparfait.

5 Presentation des modéles statistiques

A l’issue de cette etape de parametrisation, nous avons obtenu, pour chacun des textes du cor-
pus, 20 predicteurs associes a une classe qui represente la difﬁculte. Les raisons qui justiﬁent de
considerer la difﬁculte comme une variable categorielle sont discutees dans Francois (2009) et
se resument a un manque d’adequation aux donnees des modeles bases sur une variable de-
pendante continue ou ordinale. En effet, nous avons montre que la regression logistique mul-
tinomiale se revelait superieure a des classiﬁeurs bases sur la regression lineaire, la regression
logistique ordinale ou les arbres de decision (Francois, 2009).

Par consequent, nous avons voulu comparer la regression logistique multinomiale a deux autres
techniques de classiﬁcation, considerees comme parmi les plus efﬁcaces : le bagging et le boos-
ting. Dans la suite de cette section, nous presentons brievement ces trois techniques statistiques.

5.1 La régression logistique multinomiale

La regression logistique a d’abord ete developpee pour des donnees binaires et, comme toutes
les techniques de regression, elle vise a modeliser l’esperance conditionnelle E (Y | X), c.-a-d.
la valeur moyenne attendue pour Y etant donne une valeur de X. A la difference de la regression
lineaire, qui modelise cette esperance a l’aide d’une droite, la regression logistique recourt a une
courbe en S (sigmo'1'de), evitant ainsi d’attribuer a Y des valeurs sortant de l’intervalle [0, 1].

La regression multinomiale (RLM) constitue une generalisation de cette technique pour un
probleme a K classes et se realise a l’aide d’un modele constitue de K — 1 sigmo'1'des. Chacune
d’elles compare la classe is a une categorie de reference (souvent la premiere), aﬁn de retomber
sur le cas binaire. Ainsi, pour chacune de ces paires de classes (Yj, Y1), il existe une fonction
decrite sous forme matricielle par l’equation suivante (Agresti, 2002, p. 268) :

P(Y=k|X=x)

 =°‘k+"5" ’“=2""vK (3)

log

ou x est un vecteur observation, 04;, et ,6; representent les parametres du modele pour la classe
k. Sur la base de ces K — 1 equations, il est possible de calculer la probabilite qu’un texte

Thomas Francois
appartienne au niveau de difﬁculté k pour un vecteur x donné. Cette probabilité est donnée par
l’équation suivantez (Agresti, 2002, p. 271) :

exp(oz:. + ﬁfx)
1 + 2;; exp(oa. + ﬁfx)

P(Y=k|X=x)= (4)

L’estimation des parametres d’un tel modele s’effectue par maximum de vraisemblance a l’aide
d’une procédure décrite dans Agresti (2002, p. 192).

5.2 Le bagging et le boosting

Le bagging et le boosting partagent le meme postulat théorique : mieux Vaut un ensemble de
classiﬁeurs qu’un seul. La difﬁculté de cette approche provient de la nécessité de disposer d’un
corpus different pour entrainer chacun des classiﬁeurs. C’est dans leur maniere de répondre a
cette problématique que les deux approches se distinguent.

Le bagging, une technique développée par Breiman (1996), Va générer aléatoirement N échan-
tillons par rééchantillonnage, qui permettront d’entrainer N classiﬁeurs. Par la suite, le niveau
d’un texte peut étre déﬁni comme la catégorie majoritaire lors du vote de ces N classiﬁeurs.
Le bagging présente l’avantage de réduire la variance d’un modele et s’applique donc particu-
lierement bien a des classiﬁeurs instables, c.-a-d. qui peuvent fortement varier en fonction des
données d’entrainement, tels que les arbres de décision.

Le boosting, Inis au point par Freund and Schapire (1997), présente la particularité d’étre adap-
tatif, car il se concentre sur les données difﬁciles a modéliser. C’est pourquoi l’algorithme le
plus connu s’appelle AdaBoost (Adaptative Boosting) et fonctionne de la maniere suivante :

— Un poids w,- = % est attribué a chacune des N observations du corpus d’entrainement. Sur
la base de ce corpus, un classiﬁeur h,;(x) est entrainé et une estimation de son taux d’erreur
6,; est obtenue (pour le détail des formules, se reporter a Meir and Ratsch (2003)).

— Sur la base de cette estimation de l’erreur, on peut calculer le poids at du classiﬁeur, avant de
réévaluer le poids 111,- de chacune des observations, donnant plus d’importance aux données
mal classées et moins a celles qui ont été correctement catégorisées.

— Ces deux étapes sont itérées T fois, apres quoi on obtient un ensemble de T classiﬁeurs qui
attribuent a un texte un niveau de difﬁculté par un vote pondéré, ce qui revient a l’équation
suivante (Meir & Ratsch, 2003, p. 118):

T
fEns(X) = Z 05tht(X) (5)

Le boosting ne convient normalement qu’ a une variable dépendante de type binaire. Nous avons
adapté cette technique pour un probleme a K classes en recourant a la stratégie du un contre
tous. Celle-ci développe K ensembles, en opposant chaque classe is au reste des données. On
obtient donc K prédicteurs qui, pour un texte donné, vont chacun estimer la probabilité que ce
texte appartienne a la classe k. Reste alors a attribuer a ce texte la classe pour laquelle f Ens, ,,(x)
est la plus élevée.

2Notons que pour la catégorie de référence (k = 1), 041 et ,6? = 0. Aussi, lors du calcul de la probabilité qu’un
texte appartienne a cette catégorie de référence, le numérateur Vaut exp(0) = 1.

Modeles statistiques pour l’estimation automatique de la difﬁculte de textes de FLE

6 Implémentations

Apres avoir decrit les aspects theoriques de notre modele, nous presentons quelques details de
son implementation, envisageant d’abord le modele de langue, avant de s’arreter sur la selection
des variables linguistiques.

Notre modele de langue a necessite de disposer d’une liste des lemmes et formes ﬂechies du
francais auxquels est associee leur frequence d’apparition dans la langue. Nous avons utilise
Lexiquej’, un lexique developpe par New et al. (2001) qui contient plus de 50 000 lemmes dont
les frequences ont ete estimees sur un corpus de sous-titres de ﬁlms rassemblant plus de 50
millions de mots. A partir de ces frequences, nous avons estime des probabilites par maximum
de vraisemblance avant de les lisser a l’aide de l’algorithme Simple G00d- Turing decrit par Gale
et Sampson (1995). Cette etape est necessaire pour étre capable d’attribuer une probabilite aux
mots n’ayant pas ete observes dans le corpus d’apprentissage.

En ce qui conceme la selection des variables, il convenait de determiner, parmi les 20 predic-
teurs obtenus a l’issue de la phase de parametrisation, lesquels representent les meilleurs pre-
dicteurs de la complexite d’un texte. Pour le bagging et le boosting, qui sont bases sur des arbres
de decision, la selection de variables s’opere automatiquement a chaque noeud de chaque arbre
grace au critere de Gini. Par contre, pour la regression logistique multinomiale, il est necessaire
d’obtenir le modele le plus parcimonieux possible, etant donne le nombre eleve de parametres3.
Pour ce faire, nous avons utilise un algorithme de selection pas a pas des variables, qui compare
les differents modeles possibles et selectionne celui qui est a la fois efﬁcace et parcimonieux.
Ce modele est celui qui obtient la valeur AIC (Akaike’s Information Criterion) la plus elevee,
celle-ci etant deﬁnie comme equivalent a —2 * log-vraisemblance + 2p, ou p correspond au
nombre de parametres du modele et la log-vraisemblance s’obtient a l’aide d’un calcul detaille
dans Hosmer and Lemeshow (1989).

7 Résultats

Une fois cette methodologie Inise en place, deux sous-corpus, obtenus par un reechantillonnage
du corpus global, ont ete constitues. Le premier d’entre eux comprend 288 textes repartis selon
les 6 niveaux du CECR, alors que le second rassemble 437 textes etales sur les 9 niveaux de
difﬁculte4 suivants : A1, A1+, A2, A2+, B1, B1+, B2, C1 et C2. Chaque niveau comprenait
50 textes, formant nos deux corpus desquels ont ete exclus respectivement 12 et 13 donnees
aberrantes, deﬁnis comme des donnees situees au-dela de 3 ecarts-types de leur moyenne (ce
qui correspond a un 04 de 0,0026).

Ensuite, pour chacun des deux corpus, trois classiﬁeurs ont ete entraines, respectivement par
RLM, bagging et boosting. Les modeles obtenus ont ete evalues a l’aide des trois mesures
suivantes : la correlation (r de Pearson) entre les niveaux reels des textes et les predictions,
l’exactitude des predictions (deﬁnie comme le rapport du nombre de textes correctement classes
sur le nombre total de textes) et l’eXactitude contigue5.

3Ce nombre depend du nombre K de classes et du nombre X de Variables independantes selon la relation
suivante : nombre de parametres = (K — 1)(X + 1).

4L’ obj ectif de cette seconde echelle est de modeliser plus ﬁnement les premieres etapes de 1’apprentissage ou
les differences se font davantage sentir au sein d’un meme niveau.

5Cette mesure est déﬁnie par Heilman et al. (2008) comme la proportion de predictions qui s’e1oigne au plus

Thomas Francois

Mesure | RLM | bagging | boosting | Mesure | RLM | bagging | boosting
Résultats sur les échantillons d’apprentissage

Sous-corpus £1 6 niveaux de difﬁculté Sous-corpus £1 9 niveaux de difﬁculté
Correlation 0, 70 1 0, 97 Correlation 0, 74 1 0, 99
Exactitude 50% 100% 97% Exactitude 41% 100% 97%

Exac. contigue 76% 100% 98% Exac. contigue 66% 100% 98%
Résultats sur les échantillons de test

Sous-corpus £1 6 niveaux de difﬁculté Sous-corpus £1 9 niveaux de difﬁculté
Correlation 0, 62 0, 60 0, 64 Correlation 0, 72 0, 69 0, 68
Exactitude 41% 37% 40% Exactitude 32% 29% 29%

Exac. contigue 71% 70% 70% Exac. contigue 63% 65% 64%

TAB. 1 — Estimation, par une procédure de validation croisée, du coefﬁcient de Pearson’s, de
l’exactitude et de l’eXactitude contigue pour les différents classiﬁeurs.

Pour chacun des classiﬁeurs, nous avons effectué une procédure de validation croisée a dix
échantillons aﬁn d’estimer plus précisément les trois mesures d’évaluation. La Table 1 présente
les résultats obtenus sur nos deux sous-corpus. Notons que, sur les deux corpus et pour les
différentes mesures d’évaluation, les trois classiﬁeurs présentent des résultats qui ne sont pas
signiﬁcativement différents. Il est donc impossible de conclure a la supériorité de l’un des mo-
deles statistiques, meme si la méthode qui semble se comporter le mieux est la RLM. Sachant de
plus que le temps nécessaire a l’entrainement d’un tel modele est considérablement plus réduit
que celui pour le bagging et surtout le boosting, il nous semble que la RLM constitue le meilleur
choix aussi bien au niveau de l’optimisation du temps de calcul qu’au niveau de l’efﬁcacité du
modele. Cette conclusion concorde avec nos résultats précédents (Francois, 2009).

En termes d’efﬁcacité, l’eXactitude obtenue (respectivement 41% et 32% pour la RLM) parait
peu satisfaisante. L’ exactitude contigue révele cependant que les prédictions se concentrent as-
sez bien autour de la diagonale de la matrice de confusion, ce qui signiﬁe que les textes sont
plus ou moins bien classes a un niveau pres. D’ailleurs, si nous comparons ces résultats a la
seule approche similaire pour le francais, réalisée par Collins-Thompson et Callan (2005) (qui
obtiennent une corrélation de 0,64 entre leur variable dépendante a 5 classes et leurs predic-
teurs), nous nous situons dans le meme ordre de grandeur, avec un r de 0,62 pour 6 classes et
de 0,72 pour 9 classes.

Cette similarité dans les résultats conﬁrme que prédire automatiquement la difﬁculté d’un texte
constitue une tache ardue. Les meilleurs taux pour l’anglais, ou la recherche dans ce domaine est
plus avancée, ne dépassent d’ailleurs pas 52% d’exactitude contigue pour 12 classes (Heilman
et al., 2008). Le probleme s’explique aussi par le fait que les psychologues n’aient pas encore
réussi a s’accorder sur une description explicite des facteurs qui font la complexité d’un texte.
Des lors, les chercheurs en lisibilité en sont réduits a veriﬁer expérimentalement l’importance
des différentes variables.

d’un niveau par rapport a celui qui a été attribué au texte par un humain. Son emploi se justiﬁe par la difﬁculté
qu’ont divers experts humains a accorder leur jugement sur un ensemble de textes. Il ne faut toutefois pas oublier
qu’elle foumit des Valeurs exagérément optimistes lorsqu’il y a peu de categories.

Modeles statistiques pour l’estimation automatique de la difﬁculté de textes de FLE

8 Perspectives de recherche

En vue d’une amélioration des performances, les deux axes suivants seront poursuivis. D’une
part, il s’agira d’expérimenter un plus grand nombre d’indices de difﬁculté. Nous pensons ainsi
recourir a un modele lexical par n-grammes, distinguer entre mots concrets et abstraits ou en-
core utiliser diverses informations obtenues sur la base d’un analyseur syntaxique, telles que le
nombre moyen de noeuds par phrase, le nombre moyen de propositions par phrase ou encore la
profondeur lexicale moyenne (Bormuth, 1966).

D’autre part, une grande part de la perte de performance s’explique par le bruit contenu dans
le corpus. En effet, les matériaux récoltés au sein de manuels de FLE ont le défaut de présenter
une grande variabilité au sein d’un meme niveau. Il convient donc de développer un moyen de
réduire ce bruit. Pour l’instant, nous envisageons d’entrainer les modeles en plusieurs passes au
cours desquelles les textes trop mal prédits seraient exclus du corpus d’apprentissage.

Par ailleurs, comme nos expérimentations montrent que l’emploi de diverses méthodes de clas-
siﬁcation ne débouche pas sur une amélioration sensible des résultats, nous envisageons de
limiter les investigations dans ce sens a une seule autre méthode de classiﬁcation bien connue,
les SVM. Ces différentes experiences permettront d’obtenir une estimation précise de l’impor-
tance de chacun de ces trois facteurs que sont le corpus d’apprentissage, les prédicteurs et les
techniques de classiﬁcation dans la construction de nouvelles formules de lisibilité basées sur
des techniques de TAL.

Références

AGRESTI A. (2002). Categorical Data Analysis. 2nd edition. New York: Wiley-Interscience.
BORMUTH J. (1966). Readability: A new approach. Reading research quarterly, p. 79-132.

BOSSE-ANDRIEU J. (1993). La question de la lisibilité dans les pays anglophones et les pays
francophones. Technostyle, Association canadienne des professeurs de rédaction technique et
scientiﬁque, 11(2), 73-85.

BREIMAN L. (1996). Bagging predictors. Machine learning, 24(2), 123-140.

CHALL J. & DALE E. (1995). Readability Revisited.‘ The New Dale-Chall Readability For-
mula. Cambridge: Brookline Books.

COLLINS-THOMPSON K. & CALLAN J. (2005). Predicting reading difﬁculty with statistical

language models. Journal of the American Society for Information Science and Technology,
56(13), 1448-1462.

CONQUET A. (1971). La lisibilite’. Paris: Assemblée Permanente des CCI de Paris.
CONSEIL DE L’EUROPE . (2001). Cadre européen commun de re’fe’rence pour les langues.

CORNAIRE C. (1988). La lisibilité : essai d’application de la formule courte d’Henry au
frangais langue étrangere. Canadian Modern Language Review, 44(2), 261-273.

DE LANDSHEERE G. (1963). Pour une application des tests de lisibilité de Flesch a la langue
frangaise. Le Travail Humain, 26, 141-154.

FLESCH R. (1948). A new readability yardstick. Journal of Applied Psychology, 32(3), 221-
233.

Thomas Francois

FRANCOIS T. (2009). Combining a Statistical Language Model with Logistic Regression to
Predict the Lexical and Syntactic Difﬁculty of Texts for FFL. In Proceedings of the EACL
2009 Student Research Workshop, p. 19-27, Athens, Greece.

GALE W. & SAMPSON G. (1995). Good-Turing frequency estimation without tears. Journal
of Quantitative Linguistics, 2(3), 217-237.
HEILMAN M., COLLINS-THOMPSON K., CALLAN J. & ESKENAZI M. (2007). Combining

lexical and grammatical features to improve readability measures for ﬁrst and second language
texts. In Proceedings of NAACL HLT, p. 460-467.

HEILMAN M., COLLINS-THOMPSON K. & ESKENAZI M. (2008). An analysis of statistical
models and features for reading difﬁculty prediction. Association for Computational Linguis-
tics, The 3rd Workshop on Innovative Use of N LP for Building Educational Applications,
1-8.

HENRY G. (1975). Comment mesurer la lisibilité. Labor.
HOSMER D. & LEMESHOW S. (1989). Applied Logistic Regression. New York: Wiley.

HOWES D. & SOLOMON R. (1951). Visual duration threshold as a function of word probabi-
lity. Journal of Experimental Psychology, 41(40), 1-4.

KANDEL L. & MOLES A. (1958). Application de l’indice de Flesch a la langue francaise.
Cahiers Etudes de Radio-Te’le’vision, 19, 253-274.

KEMPER S. (1983). Measuring the inference load of a text. Journal of Educational Psycho-
logy, 75(3), 391-401.

KINTSCH W. & VIPOND D. (1979). Reading comprehension and readability in educational
practice and psychological theory. Perspectives on Memory Research, p. 329-366.

LIVELY B. & PRESSEY S. (1923). A method for measuring the "vocabulary burden" of
textbooks. Educational Administration and Supervision, 9, 389-398.

MEIR R. & RATSCH G. (2003). An introduction to boosting and leveraging. Lecture Notes in
Computer Science, 2600, 118-183.

MESNAGER J. (1989). Lisibilité des textes pour enfants: un nouvel outil ? Communication et
Langages, 79, 18-38.

NEW B., PALLIER C., FERRAND L. & MATOS R. (2001). Une base de données lexicales du
francais contemporain sur internet: LEXIQUE. L’Anne’e Psychologique, 101, 447-462.

RICHAUDEAU F. (1979). Une nouvelle formule de lisibilité. Communication et Langages, 44,
5-26.

SCHAPIRE R. & FREUND Y. (1997). A decision theoretic generalization of on-line learning
and an application to boosting. Journal Computer and System Sciences, 55, 119-139.

SCHMID H. (1994). Probabilistic part-of-speech tagging using decision trees. In Proceedings
of International Conference on New Methods in Language Processing, volume 12: Manches-
ter, UK.

SCHWARM S. & OSTENDORF M. (2005). Reading level assessment using support vector
machines and statistical language models. Proceedings of the 43rd Annual Meeting on Asso-
ciation for Computational Linguistics, p. 523-530.

UITDENBOGERD S. (2005). Readability of French as a foreign language and its uses. In
Proceedings of the Australian Document Computing Symposium, p. 19-25.

