<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Attribution d&#8217;auteur au moyen de mod&#232;les de langue et de mod&#232;les stylom&#233;triques</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>RECITAL 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>Attribution d&#8217;auteur au moyen de mod&#232;les de langue et de mod&#232;les
stylom&#233;triques
</p>
<p>Audrey Laroche
OLST, D&#233;p. de linguistique et de traduction, Universit&#233; de Montr&#233;al
</p>
<p>audrey.laroche@umontreal.ca
</p>
<p>R&#233;sum&#233;. Dans une t&#226;che consistant &#224; trouver l&#8217;auteur (parmi 53) de chacun de 114 textes, nous
analysons la performance de mod&#232;les de langue et de mod&#232;les stylom&#233;triques sous les angles du rappel
et du nombre de param&#232;tres. Le mod&#232;le de mots bigramme &#224; lissage de Kneser-Ney modifi&#233; interpol&#233; est
le plus performant (75 % de bonnes r&#233;ponses au premier rang). Parmi les mod&#232;les stylom&#233;triques, une
combinaison de 7 param&#232;tres li&#233;s aux parties du discours produit les meilleurs r&#233;sultats (rappel de 25 % au
premier rang). Dans les deux cat&#233;gories de mod&#232;les, le rappel maximal n&#8217;est pas atteint lorsque le nombre
de param&#232;tres est le plus &#233;lev&#233;.
</p>
<p>Abstract. In a task consisting of attributing the proper author (among 53) of each of 114 texts, we
analyze the performance of language models and stylometric models from the point of view of recall and
the number of parameters. The best performance is obtained with a bigram word model using interpolated
modified Kneser-Ney smoothing (first-rank recall of 75 %). The best of the stylometric models, which
combines 7 parameters characterizing the proportion of the different parts of speech in a text, has a first-
rank recall of 25 % only. In both types of models, the maximal recall is not reached when the number of
parameters is highest.
</p>
<p>Mots-cl&#233;s : Attribution d&#8217;auteur, mod&#232;le de langue, stylom&#233;trie, n-grammes, vecteurs de traits.
</p>
<p>Keywords: Authorship attribution, language model, stylometry, n-grams, feature vectors.
</p>
<p>1 Introduction
</p>
<p>L&#8217;attribution d&#8217;auteur est une t&#226;che qui int&#233;resse les chercheurs depuis le XIXe si&#232;cle (Holmes, 1994). Elle
a permis d&#8217;identifier l&#8217;auteur d&#8217;&#339;uvres de provenance contest&#233;e, comme les Federalist Papers (McEnery
&amp; Oakes, 2000) ; elle a aujourd&#8217;hui des applications dans des domaines comme la d&#233;tection de plagiat dans
les travaux scolaires et la linguistique l&#233;gale. La plupart des techniques d&#8217;identification d&#8217;auteur ont trait
&#224; la stylom&#233;trie, c&#8217;est-&#224;-dire la mesure quantitative d&#8217;indices textuels de natures diverses qui caract&#233;risent
le style d&#8217;un auteur. Les indices stylistiques et leur quantit&#233; varient d&#8217;une &#233;tude &#224; l&#8217;autre. Par exemple,
Schaalje et al. (1997) tentent de d&#233;terminer quels types d&#8217;indices donnent de meilleurs r&#233;sultats ; selon eux,
ce sont les mots fonctionnels qui permettent de distinguer les auteurs, et non la richesse du vocabulaire (ex.
ratio types/tokens). Stamatatos et al. (1999) forment des vecteurs de 22 indices stylistiques (ex. nombre
de syntagmes nominaux par rapport au nombre total de syntagmes) qu&#8217;ils comparent statistiquement &#224; un
article de journal pour en trouver l&#8217;auteur. Pour attribuer un auteur &#224; des courriels, Koppel &amp; Schler (2003)
combinent trois classes de traits : lexicaux (fr&#233;quence des mots fonctionnels), collocationels (fr&#233;quence</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>AUDREY LAROCHE
</p>
<p>des bigrammes de parties du discours) et idiosyncratiques (ex. &#233;pellation, formatage). Les param&#232;tres
sont beaucoup plus nombreux dans Van Halteren (2004), dont la technique est bas&#233;e sur des milliers
de traits lexicaux et syntaxiques (mots-formes, parties du discours, bigrammes, trigrammes). D&#8217;autres
&#233;tudes portent sur la performance de r&#233;seaux de neurones et d&#8217;algorithmes g&#233;n&#233;tiques (McEnery &amp; Oakes,
2000). Un autre type d&#8217;approche ne fait appel qu&#8217;&#224; des mod&#232;les de langue : entre autres, Keselj et al.
(2003) construisent des ensembles optimaux de n-grammes de lettres pour former des profils d&#8217;auteur. Les
performances de toutes ces techniques sont variables (les meilleures rapport&#233;es allant de 50 % &#224; 98 %) et
d&#233;pendent fortement de la t&#226;che effectu&#233;e, du nombre d&#8217;auteurs candidats (Luyckx &amp; Daelemans, 2008)
et de la taille des corpus d&#8217;entra&#238;nement, en plus des indices stylistiques ou des n-grammes s&#233;lectionn&#233;s.
</p>
<p>L&#8217;objectif de la pr&#233;sente &#233;tude est de comparer la performance de diff&#233;rentes m&#233;thodes d&#8217;identification
automatique de l&#8217;auteur d&#8217;un texte : certaines sont bas&#233;es sur des mod&#232;les de langue et d&#8217;autres sur des
mod&#232;les stylom&#233;triques. Pour d&#233;terminer l&#8217;auteur d&#8217;un texte, les mod&#232;les construits selon ces deux ap-
proches lui sont compar&#233;s tour &#224; tour ; il s&#8217;agit en fait d&#8217;un probl&#232;me de cat&#233;gorisation. Les meilleurs
mod&#232;les doivent combiner un rappel &#233;lev&#233; et un petit nombre de param&#232;tres.
</p>
<p>Le plan de l&#8217;article est le suivant. Notre corpus est d&#233;crit &#224; la section 2. La section 3 pr&#233;sente les deux
types d&#8217;approches test&#233;s dans la t&#226;che d&#8217;attribution d&#8217;auteur. Nous discutons dans la section 4 des r&#233;sultats
obtenus lors des exp&#233;riences. La section 5 conclut l&#8217;article en sugg&#233;rant des pistes d&#8217;am&#233;lioration.
</p>
<p>2 Corpus
</p>
<p>Le corpus utilis&#233; dans les exp&#233;riences est constitu&#233; de 167 textes de 53 auteurs diff&#233;rents (minimum de
2 textes par auteur ; moyenne de 3,2). Ces textes, &#233;crits en fran&#231;ais (pas de traductions), proviennent de
diverses r&#233;gions de la francophonie (France, Qu&#233;bec, etc.) et sont ant&#233;rieurs &#224; la seconde moiti&#233; du XXe
</p>
<p>si&#232;cle. Ils s&#8217;inscrivent dans des genres litt&#233;raires h&#233;t&#233;rog&#232;nes : romans (73 textes), essais (21), po&#232;mes (14),
pi&#232;ces de th&#233;&#226;tre (14), m&#233;moires (12), nouvelles (9), biographies (8), lettres (6), journaux (6) et dialogues
(4). De plus, les textes de 21 des auteurs ne sont pas du m&#234;me genre. Les textes sont g&#233;n&#233;ralement assez
longs : le plus court fait 2100 mots, le plus long 261 700 mots, et un texte compte en moyenne 53 200
mots.
</p>
<p>Cent six textes de 31 auteurs sont extraits de la Biblioth&#232;que Universelle (ABU)1 ; les 61 textes des 22
auteurs restants sont tir&#233;s du Projet Gutenberg (PG)2. Pour les exp&#233;riences, l&#8217;ensemble du corpus est divis&#233;
arbitrairement en sous-corpus d&#8217;entra&#238;nement et de test. Le corpus d&#8217;entra&#238;nement, qui sert &#224; mod&#233;liser
chaque auteur, est form&#233; d&#8217;un texte par auteur. Le corpus de test est donc constitu&#233; de 114 textes dont
l&#8217;auteur est inconnu, mais fait partie des 53 auteurs mod&#233;lis&#233;s.
</p>
<p>&#192; notre connaissance, aucun corpus fran&#231;ais ayant servi dans les &#233;tudes ant&#233;rieures sur l&#8217;attribution d&#8217;au-
teur n&#8217;est disponible. Les corpus grec de Stamatatos et al. (1999) et chinois de Fuchun et al. (2003)
ont bien &#233;t&#233; repris dans Keselj et al. (2003), mais ces derniers ont &#233;t&#233; contraints, comme nous, d&#8217;as-
sembler pour l&#8217;anglais un corpus constitu&#233; de textes classiques (ex. Shakespeare, Dickens) libres de
droits. &#192; des fins de reproductibilit&#233; et de comparaison, l&#8217;ensemble du corpus que nous avons constitu&#233;
(sous ses formes originale et pr&#233;trait&#233;e) est disponible &#224; l&#8217;adresse http://olst.ling.umontreal.
ca/~audrey/recital2010/.
</p>
<p>1http://abu.cnam.fr/BIB/auteurs/
2http://www.gutenberg.org/browse/languages/fr</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ATTRIBUTION D&#8217;AUTEUR AU MOYEN DE MOD&#200;LES DE LANGUE ET DE MOD&#200;LES STYLOM&#201;TRIQUES
</p>
<p>2.1 Pr&#233;traitement
</p>
<p>Les textes des corpus d&#8217;entra&#238;nement et de test passent par une s&#233;rie de transformations avant d&#8217;&#234;tre mo-
d&#233;lis&#233;s. D&#8217;abord, au moyen de scripts, les licences d&#8217;ABU et du PG sont enlev&#233;es, de m&#234;me que, pour
anonymiser les &#339;uvres, les 10 premi&#232;res lignes des textes d&#8217;ABU et les 20 premi&#232;res des textes du PG. Les
textes sont segment&#233;s finement en mots &#224; l&#8217;aide d&#8217;un script &#233;crit par Tanguy &amp; Hathout (2003). Ce script
de segmentation est adapt&#233; au fran&#231;ais : une liste d&#8217;exceptions permet de ne pas s&#233;parer les constituants
des mots complexes (au fur et &#224; mesure) et des mots comprenant un signe de ponctuation (R.-de-ch.). Par
la suite, une &#233;tiquette morphosyntaxique et un lemme sont attribu&#233;s &#224; chaque mot &#224; l&#8217;aide de TreeTagger3.
La lemmatisation de TreeTagger est d&#233;sambigu&#239;s&#233;e &#224; l&#8217;aide d&#8217;un autre script de Tanguy &amp; Hathout (2003)
qui s&#233;lectionne le lemme le plus fr&#233;quent (selon un corpus de r&#233;f&#233;rence) dans les cas o&#249; TreeTagger pro-
pose plusieurs lemmatisations pour un mot. Enfin, pour certaines des exp&#233;riences, les textes segment&#233;s
sont &#233;galement d&#233;coup&#233;s en syntagmes avec le chunker de TreeTagger.
</p>
<p>3 Approches
</p>
<p>Le principe g&#233;n&#233;ral de la t&#226;che d&#8217;attribution d&#8217;auteur consiste tout d&#8217;abord &#224; mod&#233;liser les 53 auteurs du
corpus d&#8217;entra&#238;nement selon une technique donn&#233;e (section 3.1). Ensuite, les mod&#232;les sont compar&#233;s un
&#224; un au texte de test dont nous cherchons &#224; d&#233;terminer l&#8217;auteur (section 3.2). Cette t&#226;che est r&#233;p&#233;t&#233;e pour
chacun des 114 textes du corpus de test, et la performance des diff&#233;rents mod&#232;les, qui fait l&#8217;objet de notre
&#233;tude, est &#233;valu&#233;e &#224; l&#8217;aide des m&#233;triques pr&#233;sent&#233;es &#224; la section 3.3.
</p>
<p>3.1 Phase d&#8217;entra&#238;nement
</p>
<p>Nous avons impl&#233;ment&#233; deux cat&#233;gories de m&#233;thodes pour mod&#233;liser des auteurs &#224; partir d&#8217;un de leurs
textes. La premi&#232;re est constitu&#233;e de mod&#232;les de langue d&#8217;ordres, de lissages et d&#8217;unit&#233;s distincts. La
seconde cat&#233;gorie regroupe des mod&#232;les stylom&#233;triques simples et complexes.
</p>
<p>3.1.1 Acquisition des mod&#232;les de langue
</p>
<p>Un mod&#232;le de langue d&#8217;ordre n, ou mod&#232;le n-gramme, dans son acception la plus courante, est un mod&#232;le
statistique qui calcule la probabilit&#233; d&#8217;un mot &#233;tant donn&#233;s les n-1 mots qui le pr&#233;c&#232;dent (Goodman, 2001).
Un tel mod&#232;le est habituellement liss&#233; afin d&#8217;accorder une probabilit&#233; non nulle &#224; des s&#233;quences non
observ&#233;es dans le corpus d&#8217;entra&#238;nement. L&#8217;utilisation de mod&#232;les de langue dans l&#8217;attribution d&#8217;auteur
est assez r&#233;pandue ; elle est souvent conjugu&#233;e &#224; des indices stylistiques, comme dans Koppel &amp; Schler
(2003) et Van Halteren (2004). Keselj et al. (2003) en font une &#233;tude plus d&#233;taill&#233;e en tentant de construire
de petits mod&#232;les de caract&#232;res d&#8217;ordres diff&#233;rents. Nous voulons v&#233;rifier si les mod&#232;les les plus petits
sont effectivement meilleurs et &#233;tudier l&#8217;influence des propri&#233;t&#233;s d&#8217;un mod&#232;le de langue, soit son type de
lissage, son ordre et son unit&#233; de base. Dans notre premi&#232;re s&#233;rie d&#8217;exp&#233;riences, 16 mod&#232;les de langue sont
construits pour chacun des 53 auteurs &#224; l&#8217;aide de la bo&#238;te &#224; outils SRILM (Stolcke, 2002). Le lissage de
ces mod&#232;les est soit celui de Kneser-Ney modifi&#233; interpol&#233; (KN), soit celui de repli de Witten-Bell (WB).
</p>
<p>3http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>AUDREY LAROCHE
</p>
<p>Pour chaque type de lissage, des mod&#232;les d&#8217;ordre 2, 3, 4 et 5 sont cr&#233;&#233;s. Les mod&#232;les &#224; lissage KN sont
des mod&#232;les de mots. Pour les mod&#232;les &#224; lissage WB, trois unit&#233;s correspondant &#224; des niveaux d&#8217;analyse
plus ou moins abstraits sont utilis&#233;es : mod&#232;les de mots, de lemmes et de parties du discours (les deux
derniers sont cr&#233;&#233;s &#224; partir du corpus &#233;tiquet&#233; par TreeTagger). Le vocabulaire des mod&#232;les de lemmes et
de parties du discours dans le corpus &#233;tant restreint, le lissage KN (bien qu&#8217;il soit g&#233;n&#233;ralement le meilleur
selon Chen &amp; Goodman (1998)) n&#8217;est pas appropri&#233; pour construire des mod&#232;les de langue bas&#233;s sur ces
unit&#233;s4 ; Stolcke et al. (2010) recommandent plut&#244;t d&#8217;utiliser le lissage WB dans ces cas.
</p>
<p>3.1.2 Acquisition des mod&#232;les stylom&#233;triques
</p>
<p>L&#8217;approche employ&#233;e dans la deuxi&#232;me s&#233;rie d&#8217;exp&#233;riences consiste &#224; acqu&#233;rir des mod&#232;les stylom&#233;triques
pour repr&#233;senter les auteurs. Les indices stylistiques &#233;tudi&#233;s formant ce type de mod&#232;le sont pour la plupart
tir&#233;s de l&#8217;&#233;tat de l&#8217;art de Holmes (1994) et ont trait aux proportions de parties du discours. Les mod&#232;les
stylom&#233;triques sont construits &#224; partir des textes analys&#233;s par TreeTagger. Chaque auteur est d&#8217;abord mo-
d&#233;lis&#233; neuf fois &#224; partir d&#8217;un trait stylistique unique parmi les suivants : 1) nombre de noms par rapport au
nombre de verbes, 2) nombre de noms par rapport au nombre total de mots dans le texte (N), 3) nombre
de verbes par rapport &#224; N, 4) nombre d&#8217;adverbes par rapport &#224; N, 5) nombre de mots fonctionnels5 par
rapport &#224; N, 6) nombre de signes de ponctuation par rapport &#224; N, 7) nombre d&#8217;adjectifs par rapport au
nombre de noms, 8) nombre d&#8217;adjectifs par rapport &#224; N, et 9) longueur moyenne des syntagmes nominaux
(SN). Des mod&#232;les stylom&#233;triques complexes sont ensuite construits de fa&#231;on vorace : selon leur perfor-
mance respective dans la t&#226;che d&#8217;attribution d&#8217;auteur, les indices stylistiques simples sont combin&#233;s de
fa&#231;on incr&#233;mentale en un vecteur de deux &#224; neuf traits pour former des mod&#232;les d&#8217;auteur complexes. No-
tons que les indices stylistiques que nous &#233;tudions sont beaucoup moins nombreux que ceux dans Koppel
&amp; Schler (2003), Van Halteren (2004), Luyckx &amp; Daelemans (2008), etc. Ceux-ci utilisent des techniques
d&#8217;apprentissage machine pour pond&#233;rer les indices. Comme nous avons pour objectif d&#8217;utiliser le moins
de param&#232;tres possibles, nous n&#8217;avons pas encore explor&#233; cette voie qui donne de bons r&#233;sultats dans la
litt&#233;rature, bien qu&#8217;elle n&#233;cessite beaucoup de ressources.
</p>
<p>3.2 Phase de test
</p>
<p>Dans la phase de test, notre syst&#232;me doit identifier l&#8217;auteur d&#8217;un texte du corpus de test parmi les auteurs
mod&#233;lis&#233;s &#224; l&#8217;aide des deux m&#233;thodes d&#8217;acquisition pr&#233;sent&#233;es &#224; la section 3.1. Pour ce faire, il attribue un
score &#224; chaque mod&#232;le d&#8217;auteur pour indiquer &#224; quel point celui-ci ressemble au texte d&#8217;auteur inconnu.
Les mod&#232;les sont ordonn&#233;s selon leur score ; le mod&#232;le en t&#234;te de liste correspond &#224; l&#8217;auteur attribu&#233; au
texte par le syst&#232;me. La fa&#231;on de calculer ce score d&#233;pend du type de mod&#232;le employ&#233;.
</p>
<p>3.2.1 Attribution &#224; l&#8217;aide de mod&#232;les de langue
</p>
<p>Le score indiquant &#224; quel point un mod&#232;le de langue mod&#233;lise bien le texte d&#8217;auteur inconnu est donn&#233; par
la perplexit&#233;. La perplexit&#233; d&#8217;un mod&#232;le de langue est la moyenne g&#233;om&#233;trique de la probabilit&#233; inverse
</p>
<p>4En effet, SRILM ne parvient pas &#224; calculer ces mod&#232;les.
5Les mots consid&#233;r&#233;s comme fonctionnels sont les d&#233;terminants, les conjonctions, les pronoms et les pr&#233;positions.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ATTRIBUTION D&#8217;AUTEUR AU MOYEN DE MOD&#200;LES DE LANGUE ET DE MOD&#200;LES STYLOM&#201;TRIQUES
</p>
<p>des mots du corpus de test (Goodman, 2001, p. 4) :
</p>
<p>scoreperplexite&#769;(x1...xn) = n
</p>
<p>&#8730;&#8730;&#8730;&#8730; n&#8719;
i=1
</p>
<p>1
P (xi|x1...i&#8722;1)
</p>
<p>La perplexit&#233; des mod&#232;les de langue par rapport au texte de test est calcul&#233;e &#224; l&#8217;aide de la bo&#238;te &#224; outils
SRILM. Plus la perplexit&#233; est basse, plus le mod&#232;le de langue r&#233;ussit bien &#224; pr&#233;dire le texte. L&#8217;auteur
pr&#233;sum&#233; d&#8217;un texte est par cons&#233;quent celui qui obtient la plus petite perplexit&#233; parmi tous les auteurs
mod&#233;lis&#233;s.
</p>
<p>3.2.2 Attribution &#224; l&#8217;aide de mod&#232;les stylom&#233;triques
</p>
<p>Tel que d&#233;crit &#224; la section 3.1.2, chaque auteur est repr&#233;sent&#233; &#224; l&#8217;aide de mod&#232;les stylom&#233;triques simples
et complexes. Les mod&#232;les stylom&#233;triques simples sont constitu&#233;s d&#8217;un param&#232;tre unique. Pour attribuer
l&#8217;auteur d&#8217;un texte de test, ce dernier doit &#234;tre repr&#233;sent&#233; par le m&#234;me param&#232;tre que le type de mod&#232;le
stylom&#233;trique &#224; l&#8217;&#233;tude. Le score indiquant &#224; quel point un mod&#232;le d&#8217;auteur repr&#233;sente bien le texte d&#8217;au-
teur inconnu est &#233;gal &#224; la diff&#233;rence, en valeur absolue, entre la valeur du param&#232;tre pour le mod&#232;le (m) et
celle du m&#234;me param&#232;tre pour le texte (t) :
</p>
<p>scoreMS simple(m, t) = |m&#8722; t|
</p>
<p>Le score est calcul&#233; pour tous les auteurs mod&#233;lis&#233;s ; le plus petit des scores obtenus indique lequel des
mod&#232;les d&#8217;auteur correspond le mieux au texte.
</p>
<p>Pour comparer des mod&#232;les stylom&#233;triques complexes, constitu&#233;s d&#8217;un vecteur d&#8217;indices stylistiques, &#224; un
texte d&#8217;auteur inconnu, ce texte est d&#8217;abord caract&#233;ris&#233; par un vecteur form&#233; des m&#234;mes param&#232;tres que
les mod&#232;les. Le vecteur de chaque mod&#232;le d&#8217;auteur (~m) est ensuite compar&#233; au vecteur du texte (~t) &#224; l&#8217;aide
de la mesure du cosinus :
</p>
<p>scorecosinus(~m,~t) =
&#8721;n
</p>
<p>i=1 mi &#215; ti&#8730;&#8721;n
i=1 m
</p>
<p>2
i
</p>
<p>&#8730;&#8721;n
i=1 t
</p>
<p>2
i
</p>
<p>Plus le cosinus entre deux vecteurs est &#233;lev&#233;, plus ces vecteurs sont similaires. L&#8217;auteur attribu&#233; au texte
est donc celui qui donne la plus grande valeur de cosinus.
</p>
<p>3.3 M&#233;triques d&#8217;&#233;valuation
</p>
<p>Dans la phase de test, les mod&#232;les d&#8217;auteur sont ordonn&#233;s selon un score indiquant leur degr&#233; de ressem-
blance au texte dont nous cherchons &#224; d&#233;terminer l&#8217;auteur. Pendant les exp&#233;riences, cette proc&#233;dure est
r&#233;p&#233;t&#233;e pour chaque type de mod&#232;le de langue et de mod&#232;le stylom&#233;trique parmi ceux d&#233;crits &#224; la section
3.1. La comparaison des performances des diff&#233;rentes approches est bas&#233;e sur deux crit&#232;res : le rappel et
le nombre de param&#232;tres que renferme le mod&#232;le. Le rappel au rang n est donn&#233; par :
</p>
<p>rappeln =
nombre de bonnes re&#769;ponses au rang n
</p>
<p>nombre de textes de test
&#215; 100
</p>
<p>Ainsi, le rappel d&#8217;un mod&#232;le au rang 1 correspond au pourcentage des 114 textes de test pour lesquels le
syst&#232;me trouve le bon auteur en premi&#232;re position. Plus le rappel est &#233;lev&#233;, meilleure est la performance
du mod&#232;le. Quant au nombre de param&#232;tres, il &#233;quivaut &#224; la quantit&#233; de n-grammes distincts caract&#233;risant</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>AUDREY LAROCHE
</p>
<p>les mod&#232;les de langue ou &#224; la taille des vecteurs d&#8217;indices stylistiques dans les mod&#232;les stylom&#233;triques
simples et complexes. &#201;tant donn&#233; qu&#8217;une quantit&#233; r&#233;duite de param&#232;tres requiert moins de ressources
(temps de calcul, m&#233;moire), la performance d&#8217;un mod&#232;le du point de vue du nombre de param&#232;tres est
meilleure si ce mod&#232;le implique moins de param&#232;tres.
</p>
<p>4 R&#233;sultats et discussion
</p>
<p>Les deux types d&#8217;approches &#8212; mod&#232;les de langue et mod&#232;les stylom&#233;triques &#8212; ont fait l&#8217;objet d&#8217;exp&#233;-
riences dans lesquelles un auteur parmi les 53 mod&#233;lis&#233;s doit &#234;tre attribu&#233; &#224; chacun des 114 textes d&#8217;auteur
inconnu. De fa&#231;on g&#233;n&#233;rale, les meilleurs r&#233;sultats en termes de rappel sont obtenus avec des mod&#232;les
de langue. Dans les deux approches, un nombre de param&#232;tres plus &#233;lev&#233; n&#8217;est pas directement li&#233; &#224; un
rappel sup&#233;rieur. Les paragraphes qui suivent pr&#233;sentent les r&#233;sultats obtenus lors des exp&#233;riences d&#8217;attri-
bution d&#8217;auteur dans lesquelles le type de mod&#233;lisation varie (sections 4.1 et 4.2) ; la section 4.3 montre les
r&#233;sultats d&#8217;exp&#233;riences sur l&#8217;influence de la taille des corpus d&#8217;entra&#238;nement et de test sur la performance.
</p>
<p>4.1 Performance des mod&#232;les de langue
</p>
<p>Dans une premi&#232;re s&#233;rie d&#8217;exp&#233;riences, les auteurs sont mod&#233;lis&#233;s avec des mod&#232;les de langue dont le
lissage, l&#8217;ordre et l&#8217;unit&#233; varient. Le tableau 1 permet de comparer les diff&#233;rents types de mod&#232;les de
</p>
<p>TAB. 1 &#8211; Rappel au rang 1 des mod&#232;les de langue
Mots Lemmes Parties du discours
</p>
<p>KN WB WB WB
2-gramme 74,56 0,00 5,26 54,39
3-gramme 71,93 0,00 7,02 50,00
4-gramme 72,81 0,00 9,65 47,37
5-gramme 72,81 0,00 10,53 49,12
</p>
<p>langue. Il montre que le choix de la m&#233;thode de lissage est tr&#232;s important : le rappel au rang 1 pour les
mod&#232;les de mots &#224; lissage de Kneser-Ney modifi&#233; interpol&#233; est sup&#233;rieur &#224; 70 %, tandis que les mod&#232;les
de mots &#224; lissage de Witten-Bell ne donnent jamais la bonne r&#233;ponse au rang 1. L&#8217;ordre des mod&#232;les de
langue a lui aussi une influence (irr&#233;guli&#232;re) sur la performance. L&#8217;ordre 2 donne le meilleure rappel dans
le cas des mod&#232;les de mots KN (74,56 %) et des mod&#232;les de parties du discours WB (54,39 %), mais
c&#8217;est l&#8217;ordre le plus &#233;lev&#233; (5) qui produit le meilleur rappel parmi les mod&#232;les de lemmes WB (10,53 %) ;
l&#8217;ordre n&#8217;influence pas le rappel au rang 1 des mod&#232;les de mots WB, qui demeure nul. Par ailleurs, plus le
niveau d&#8217;analyse du texte est abstrait (du plus concret au plus abstrait : mot, lemme, partie du discours),
plus le rappel des mod&#232;les WB augmente. Par exemple, le rappel au rang 1 des mod&#232;les WB bigrammes
est d&#233;cupl&#233; lorsque l&#8217;unit&#233; passe du lemme (5,26 %) &#224; la partie du discours (54,39 %). La figure 1(a) (page
suivante) montre l&#8217;importante am&#233;lioration du rappel aux rangs 1 &#224; 10 selon l&#8217;unit&#233; du mod&#232;le de langue
WB. Tout se passe comme si la variation au niveau des suites de mots entre les textes d&#8217;un m&#234;me auteur est
plus marqu&#233;e que celle au niveau des suites de parties du discours. En construisant des mod&#232;les d&#8217;auteur
encore plus abstraits, des mod&#232;les syntaxiques, Baayen et al. (1996) ont en effet not&#233; que les structures
syntaxiques constituent de meilleurs indices stylistiques que les indices portant sur le lexique. Les mod&#232;les
KN sont impossibles &#224; construire lorsque la taille de vocabulaire est r&#233;duite (Stolcke et al., 2010), comme</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ATTRIBUTION D&#8217;AUTEUR AU MOYEN DE MOD&#200;LES DE LANGUE ET DE MOD&#200;LES STYLOM&#201;TRIQUES
</p>
<p>(a) Mod&#232;les de langue Witten-Bell bi-
grammes
</p>
<p>(b) Mod&#232;les stylom&#233;triques complexes
</p>
<p>FIG. 1 &#8211; Rappel en fonction du rang
</p>
<p>c&#8217;est le cas des mod&#232;les de lemmes et des mod&#232;les de parties du discours. S&#8217;il existait un type de lissage
plus performant que WB (comme KN) et adapt&#233; aux vocabulaires restreints, la performance dans la t&#226;che
d&#8217;attribution d&#8217;auteur serait probablement am&#233;lior&#233;e.
</p>
<p>Le nombre de param&#232;tres, notre autre crit&#232;re de performance, ne varie pas en fonction du type de lissage
(seul le poids des n-grammes varie), mais selon l&#8217;ordre et l&#8217;unit&#233; des mod&#232;les de langue. Plus l&#8217;ordre du
mod&#232;le est &#233;lev&#233;, plus le nombre de param&#232;tres (nombre de n-grammes distincts dans le texte mod&#233;lis&#233;)
est &#233;lev&#233;. Par exemple, pour un texte de 48 500 mots (taille m&#233;diane des textes du corpus d&#8217;entra&#238;nement),
le mod&#232;le bigramme contient 41 400 param&#232;tres, celui d&#8217;ordre 3, 45 900 param&#232;tres, d&#8217;ordre 4, 47 600
param&#232;tres et d&#8217;ordre 5, 48 200 param&#232;tres. L&#8217;abstraction des niveaux d&#8217;analyse textuelle est inversement
proportionnelle &#224; la quantit&#233; de param&#232;tres. &#192; titre d&#8217;exemple, dans le texte de 48 500 mots, un mod&#232;le
de mots bigramme contient 41 400 param&#232;tres, un mod&#232;le de lemmes 24 700 param&#232;tres et un mod&#232;le de
parties du discours, 300.
</p>
<p>Comme le montre le tableau 1 ci-dessus, un nombre de param&#232;tres plus &#233;lev&#233; n&#8217;est pas une condition
n&#233;cessaire pour obtenir un meilleur rappel. Au contraire, parmi tous les mod&#232;les WB, c&#8217;est celui qui
compte le moins de param&#232;tres (bigramme, parties du discours) qui donne le meilleur rappel au rang 1
(54,39 %). Parmi les mod&#232;les KN, c&#8217;est &#233;galement celui qui contient le moins de param&#232;tres, le mod&#232;le
bigramme, qui donne le meilleur rappel (74,56 %). Les mod&#232;les d&#8217;ordre plus &#233;lev&#233; souffrent donc d&#8217;un
probl&#232;me de surapprentissage.
</p>
<p>4.2 Performance des mod&#232;les stylom&#233;triques
</p>
<p>L&#8217;attribution d&#8217;auteur &#224; l&#8217;aide de mod&#232;les stylom&#233;triques simples donne des rappels au rang 1 (tableau
2, page suivante) de beaucoup inf&#233;rieurs &#224; ceux obtenus avec les mod&#232;les de mots &#224; lissage KN et de
parties du discours &#224; lissage WB. Les mod&#232;les stylom&#233;triques simples, qui comptent un seul param&#232;tre,
ont cependant un meilleur rappel au rang 1 que les mod&#232;les WB de mots et de lemmes, qui contiennent
des milliers de param&#232;tres.
</p>
<p>Il est int&#233;ressant de constater que les meilleurs indices stylistiques sont ceux qui sont li&#233;s aux proportions</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>AUDREY LAROCHE
</p>
<p>TAB. 2 &#8211; Rappel des mod&#232;les stylom&#233;triques simples aux rangs 1 et 10
Id Trait R1 R10 Id Trait R1 R10
</p>
<p>1 &#8214;Noms&#8214;/&#8214;Verbes&#8214; 9,65 42,98 6 &#8214;Ponctuations&#8214;/&#8214;Mots&#8214; 6,14 41,23
2 &#8214;Noms&#8214;/&#8214;Mots&#8214; 9,65 40,35 7 &#8214;Adjectifs&#8214;/&#8214;Noms&#8214; 5,26 36,84
3 &#8214;Verbes&#8214;/&#8214;Mots&#8214; 7,02 43,86 8 &#8214;Adjectifs&#8214;/&#8214;Mots&#8214; 3,51 40,35
4 &#8214;Adverbes&#8214;/&#8214;Mots&#8214; 7,02 40,35 9 Longueur moyenne SN 2,63 26,32
5 &#8214;Mots fonctionnels&#8214;/&#8214;Mots&#8214; 6,14 47,37
</p>
<p>des mots lexicaux (traits 1 &#224; 4). En effet, plusieurs &#233;tudes stylom&#233;triques utilisent des indices li&#233;s aux mots
fonctionnels et &#224; la ponctuation (McEnery &amp; Oakes, 2000), mais nos r&#233;sultats montrent que ces indices
sont moins performants que ceux li&#233;s aux noms, aux verbes et aux adverbes. Notons toutefois qu&#8217;au rang
10, le meilleur rappel est celui donn&#233; par la proportion de mots fonctionnels dans les textes (47,37 %). Les
indices li&#233;s aux proportions d&#8217;adjectifs et &#224; la longueur moyenne des syntagmes nominaux (indices 7 &#224; 9)
ont une performance m&#233;diocre.
</p>
<p>Pour former les mod&#232;les stylom&#233;triques complexes, nous utilisons une approche vorace : les indices
simples sont graduellement combin&#233;s en des vecteurs de traits par ordre de leur rappel au rang 1 tel
que not&#233; dans le tableau 2. La figure 1(b) montre le rappel aux rangs 1 &#224; 10 de ces mod&#232;les de vecteurs de
traits stylom&#233;triques.
</p>
<p>Comme dans le cas des mod&#232;les de langue, les mod&#232;les stylom&#233;triques complexes ayant le plus grand
nombre de param&#232;tres (&#233;quivalant &#224; la taille du vecteur) ne sont pas ceux qui ont le meilleur rappel. En
effet, le meilleur ensemble de param&#232;tres combine les indices stylistiques 1 &#224; 7 et a un rappel de 24,56 %
au rang 1 ; le plus gros des mod&#232;les stylom&#233;triques (9 param&#232;tres) a un rappel de 19,30 % au premier rang.
La figure 1(b) montre que l&#8217;introduction des traits 4, 6 et 7 a une plus grande influence sur le rappel au
rang 1 que celle des traits 5, 8 et 9 (ces deux derniers diminuant m&#234;me le rappel). Notre &#233;tude, dans son
&#233;tat actuel, &#233;tant donn&#233; qu&#8217;elle ne fait intervenir que 9 indices, ne permet pas de conclure qu&#8217;un nombre
inf&#233;rieur de param&#232;tres stylistiques donne n&#233;cessairement de meilleurs r&#233;sultats. Il pourrait au contraire
&#234;tre profitable de s&#233;lectionner une grande quantit&#233; d&#8217;indices comme le font Luyckx &amp; Daelemans (2008)
puis de les pond&#233;rer automatiquement.
</p>
<p>4.3 L&#8217;influence de la taille du corpus
</p>
<p>Les textes d&#8217;entra&#238;nement et de test utilis&#233;s dans les exp&#233;riences d&#233;crites ci-dessus sont longs (53 200 mots
en moyenne) et leur taille varie beaucoup : cela peut influencer les r&#233;sultats. Nous avons v&#233;rifi&#233; la perfor-
mance du meilleur mod&#232;le de chaque approche &#8212; mod&#232;le de mots bigramme KN et mod&#232;le stylom&#233;trique
complexe &#224; 7 param&#232;tres &#8212; sur des textes d&#8217;entra&#238;nement de tailles &#233;gales (2000, 2500 et 3000 mots), puis
sur des textes de test de 500, 750 et 1000 mots6. Lorsque la taille des textes d&#8217;entra&#238;nement est r&#233;duite par
rapport aux textes originaux, les textes de test conservent leur taille originale, et inversement.
</p>
<p>Comme l&#8217;indique le tableau 3, plus la taille des textes d&#8217;entra&#238;nement est importante, meilleur est le rappel
au rang 1 (ce qui est conforme aux r&#233;sultats de Luyckx &amp; Daelemans (2008)). Il n&#8217;en est pas ainsi pour
les textes de test (ceux dont on cherche &#224; d&#233;terminer l&#8217;auteur) : le rappel maximal est atteint avec la
</p>
<p>6Ces tailles sont d&#233;termin&#233;es en fonction de la taille des plus petits textes d&#8217;entra&#238;nement (6000 mots) et de test (2000 mots).
La t&#226;che a &#233;t&#233; effectu&#233;e deux ou trois fois pour chaque taille ; les r&#233;sultats rapport&#233;s correspondent &#224; la moyenne des rappels
obtenus.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ATTRIBUTION D&#8217;AUTEUR AU MOYEN DE MOD&#200;LES DE LANGUE ET DE MOD&#200;LES STYLOM&#201;TRIQUES
</p>
<p>TAB. 3 &#8211; Rappel au rang 1 des meilleurs mod&#232;les en fonction de la taille des corpus
Mod&#232;le Taille du corpus d&#8217;entra&#238;nement Taille du corpus de test
</p>
<p>2000 mots 2500 mots 3000 mots 500 mots 750 mots 1000 mots
Mod&#232;le de langue 38,89 42,11 44,30 46,49 48,25 47,81
Mod&#232;le stylom&#233;trique 6,14 9,21 10,53 5,85 6,14 5,26
</p>
<p>taille m&#233;diane. Ces constats sont valides pour les deux approches de mod&#233;lisation. Dans tous les cas,
cependant, le rappel dans cette s&#233;rie d&#8217;exp&#233;riences (dans laquelle les textes sont coup&#233;s) est inf&#233;rieur &#224;
celui obtenu lorsque tous les textes ont leur taille originale. Cette diff&#233;rence est plus marqu&#233;e lorsque
les textes d&#8217;entra&#238;nement sont raccourcis dans le cas des mod&#232;les de langue et, dans le cas des mod&#232;les
stylom&#233;triques, lorsque c&#8217;est la taille des textes de test qui est r&#233;duite.
</p>
<p>5 Conclusion
</p>
<p>Nous avons pr&#233;sent&#233; une t&#226;che d&#8217;attribution d&#8217;auteur dans laquelle un texte doit &#234;tre cat&#233;goris&#233; en &#233;tant
compar&#233; &#224; des mod&#232;les d&#8217;auteurs. Plusieurs approches de mod&#233;lisation sont possibles ; nous avons test&#233;
la performance de mod&#232;les de langue et de mod&#232;les stylom&#233;triques, ces derniers &#233;tant tr&#232;s r&#233;pandus dans
la litt&#233;rature. Nos r&#233;sultats montrent que les mod&#232;les de langue atteignent de meilleurs rappels que les
mod&#232;les stylom&#233;triques, bien que des disparit&#233;s de performance importantes existent entre les diff&#233;rents
types de mod&#232;les dans chaque approche. Le rappel maximal obtenu est de 75 % (avec un mod&#232;le de mots
bigramme &#224; lissage de Kneser-Ney modifi&#233; interpol&#233;) ; ce r&#233;sultat est difficilement comparable &#224; ceux
mentionn&#233;s dans les travaux ant&#233;rieurs, ceux-ci traitant en g&#233;n&#233;ral moins d&#8217;auteurs (entre 2 et 10) et leurs
corpus &#233;tant vari&#233;s. Soulignons que Luyckx &amp; Daelemans (2008), qui se sont pench&#233;s sur l&#8217;influence
du nombre d&#8217;auteurs, obtiennent un rappel semblable au n&#244;tre (76 %) pour 20 auteurs (avec une approche
bas&#233;e sur l&#8217;apprentissage machine), alors que notre &#233;tude porte sur 53 auteurs. Nous constatons par ailleurs
qu&#8217;un grand nombre de param&#232;tres dans les mod&#232;les n&#8217;est pas gage de meilleurs r&#233;sultats ; dans le cas des
mod&#232;les stylom&#233;triques, ces r&#233;sultats sugg&#232;rent qu&#8217;il serait int&#233;ressant de pond&#233;rer les indices stylistiques,
comme le font plusieurs auteurs. Des exp&#233;riences futures porteront aussi sur des mod&#232;les de langue bas&#233;s
sur les caract&#232;res et sur les structures syntaxiques.
</p>
<p>Il serait int&#233;ressant de tester les approches sur des corpus diff&#233;rents (le n&#244;tre &#233;tant relativement long et
compos&#233; de genres h&#233;t&#233;rog&#232;nes) afin de mesurer leur capacit&#233; &#224; accomplir des t&#226;ches plus pr&#232;s d&#8217;applica-
tions r&#233;elles. La matrice de confusion obtenue &#224; partir du meilleur mod&#232;le montre qu&#8217;en moyenne, 28 %
des textes d&#8217;un auteur sont attribu&#233;s &#224; un autre ; 38 % de cette moyenne est d&#251; &#224; 5 des 53 auteurs. Si le
texte d&#8217;entra&#238;nement est d&#8217;un genre diff&#233;rent de celui des textes de test (par ex. un po&#232;me et des romans), la
cat&#233;gorisation effectu&#233;e par notre syst&#232;me est plus mauvaise : 52 % des auteurs ayant mal &#233;t&#233; attribu&#233;s au
moins une fois sont repr&#233;sent&#233;s par des genres diff&#233;rents au sein de notre corpus. Par ailleurs, si les textes
d&#8217;entra&#238;nement et de test portent sur le m&#234;me th&#232;me (par ex. La femme du mort, Tome I et La femme du
mort, Tome II), ce qui est le cas pour 9 des 53 auteurs (15 textes de test), le meilleur mod&#232;le de langue a un
rappel de 100 %. Il semble donc que l&#8217;homog&#233;n&#233;it&#233; du genre et du th&#232;me soit un facteur non n&#233;gligeable
pour l&#8217;attribution d&#8217;auteur ; de plus amples exp&#233;riences pourraient le confirmer.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>AUDREY LAROCHE
</p>
<p>Remerciements
</p>
<p>Nous remercions Philippe Langlais pour ses nombreuses et pr&#233;cieuses suggestions de m&#234;me que pour la
constitution d&#8217;une partie du corpus. Nous remercions aussi Patrick Drouin et les relecteurs anonymes pour
leurs commentaires.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BAAYEN H., VAN HALTEREN H. &amp; TWEEDIE F. (1996). Outside the cave of shadows : using syntactic
annotation to enhance authorship attribution. Literary and Linguistic Computing, 11, 121&#8211;132.
CHEN S. F. &amp; GOODMAN J. (1998). An Empirical Study of Smoothing Techniques for Language Mode-
ling. Rapport interne.
FUCHUN P., SCHUURMANS D., KESELJ V. &amp; WANG S. (2003). Automated authorship attribution with
character level language models. In Proceedings of the tenth conference of the European Chapter of the
Association for Computational Linguistics, p. 12&#8211;17, Budapest, Hongrie.
GOODMAN J. (2001). A Bit of Progress in Language Modeling. Rapport interne, Redmond, WA.
HOLMES D. I. (1994). Authorship attribution. Computers and the Humanities, 28(2), 87&#8211;106.
KESELJ V., FUCHUN P., CERCONE N. &amp; THOMAS C. (2003). N-gram-based author profiles for author-
ship attribution. In Proceedings of the Conference Pacific Association for Computational Linguistics,
PACLING&#8217;03, p. 255&#8211;264, Halifax, Canada : Pacific Association for Computational Linguistics.
KOPPEL M. &amp; SCHLER J. (2003). Exploiting stylistic idiosyncrasies for authorship attribution. In
Proceedings of IJCAI&#8217;03 Workshop on Computational Approaches to Style Analysis and Synthesis, p.
69&#8211;72.
LUYCKX K. &amp; DAELEMANS W. (2008). Authorship attribution and verification with many authors
and limited data. In Proceedings of the 22nd International Conference on Computational Linguistics
(COLING 2008), p. 513&#8211;520, Manchester.
MCENERY T. &amp; OAKES M. (2000). Authorship identification and computational stylometry, In R.
DALE, H. MOISL &amp; H. SOMERS, Eds., Handbook of Natural Language Processing, p. 545&#8211;562. Marcel
Dekker : New York.
SCHAALJE G. B., HILTON J. L. &amp; ARCHER J. B. (1997). Comparative power of three author-attribution
techniques for differentiating authors. Journal of Book of Mormon Studies, 6(1), 47&#8211;63.
STAMATATOS E., FAKOTAKIS N. &amp; KOKKINAKIS G. (1999). Automatic authorship attribution. In
Proceedings of the ninth conference of the European Chapter of the Association for Computational Lin-
guistics, p. 158&#8211;164, Morristown, NJ : Association for Computational Linguistics.
STOLCKE A. (2002). SRILM &#8211; an extensible language modeling toolkit. In Proceedings of the Interna-
tional Conference on Spoken Language Processing, p. 901&#8211;904, Menlo Park, CA : SRI International.
STOLCKE A., YURET D. &amp; MADNANI N. (2010). SRILM-FAQ. http://www.speech.sri.
com/projects/srilm/manpages/srilm-faq.7.html.
TANGUY L. &amp; HATHOUT N. (2003). Perl pour les linguistes. Paris : Lavoisier.
VAN HALTEREN H. (2004). Linguistic profiling for author recognition and verification. In Proceedings
of the 42nd Annual Meeting of the Association for Computational Linguistics, p. 199&#8211;206, Morristown,
NJ : Association for Computational Linguistics.</p>

</div></div>
</body></html>