RECITAL 2010, Montréal, 19-23 juillet 2010

Densidées : calcul automatique dc la densité des idées dans un corpus oral

Hyeran Leel, Philippe Gambettez, Elsa Maillé 3, Constance Thuillier3

(1) Praxiling - Université Montpellier 3 / CNRS, 17 rue Abbé de l'Epée 34090
Montpellier France
(2) LIRMM - Université Montpellier 2/ CNRS, 34095 Montpellier Cedex 5
(3) ISTR - Université Claude Bernard Lyon 1, 69622 Villeurbanne Cedex
hleel @univ-montp3 .fr

Résumé La densité des idées, qui correspond au ratio entre le nombre de propositions sémantiques et le
nombre de mots dans un texte reﬂete la qualité informative des propositions langagieres d’un texte.
L'apparition de la maladie d'Alzheimer a été reliée a une dégradation de la densité des idées, ce qui explique
l'intérét pour un calcul automatique de cette mesure. Nous proposons une méthode basée sur un étiquetage
morphosyntaxique et des regles d'ajustement, inspirée du logiciel CPIDR. Cette méthode a été validée sur un
corpus de quarante entretiens oraux transcrits et obtient de meilleurs résultats pour le frangais que CPIDR
pour l’anglais. Elle est implémentée dans le logiciel libre Densidées disponible sur
http://code.goog1e.com/p/densidees.

Abstract Idea density, which is the ratio of semantic propositions divided by the number of words in a
text, reﬂects the informative quality of the sentences of a text. A decreasing idea density has been identified
as one of the symptoms of Alzheimer’s disease, which explains the interest in an automatic calculation of
idea density. We propose a method based on part-of-speech tagging followed by adjustment rules inspired
from the CPIDR software. This method was validated on a corpus of 40 transcribed conversations in French
and obtains better results in French than CPIDR in English. It is implemented in the free software Densidées
available at http://code.goog1e.coIn/p/densidees.

Mots-clés 2 densité des idées, analyse prédicative, étiquetage sémantique, psycholinguistique
Keywords: idea density, propositional analysis, semantic tagging, psycholinguistics

HYERAN LEE, PHILIPPE GAMBETTE, ELSA MAILLE, CONSTANCE THUILLIER

1 Introduction

La degradation de la capacite linguistique est un element caracteristique de la maladie d’Alzheimer
(Moreaud et al., 2001). be deficit linguistique dans cette pathologie est dﬁ a l’alteration de la mémoire
semantique. Ainsi, pour evaluer la performance langagiere des patients atteints de la maladie d’Alzheimer,
une mesure fine au niveau semantique du langage est necessaire. La densite des idees (DI), ratio pour dix
mots du nombre de propositions semantiques dans un texte, est aujourd’hui reconnue comme un
indicateur pertinent des fonctions intellectuelles de sujets. Cette methode a ete validée par de nombreuses
études psycholinguistiques appliquées : la comprehension du texte (Kintsch et al., 1973 ; Kintsch, 1978),
la mémoire (Thorson et al., 1984), la maladie d'Alzheimer (Snowdon et al., 1996 ; Lee et al., 2009), la
qualité de prise de note des étudiants (Takao et al., 2002), le vieillissement (Kemper et al., 2001), la
schizophrenic (Covington et al., 2007), le genre du discours (Covington, 2009). Cependant, son analyse
longue, fastidieuse, et parfois subjective fait souvent obstacle a son utilisation pratique. Par consequent, il
serait intéressant et innovant de développer un outil automatique permettant de donner un résultat rapide
et ﬁable de la DI. Nous proposerons une methode de calcul automatique de la DI, basee sur un etiquetage
morphosyntaxique et des regles d'ajustement, inspiree du logiciel CPIDR (Brown et al., 2008). Enfin nous
testerons la validite de cette methode sur un corpus de quarante entretiens oraux transcrits.

1.1 Analyse prédicative et densité des idées

Pour etudier les mecanismes qui sous—tendent la pensee humaine, la psychologie cognitive n'ayant acces
qu'aux productions du sujet, considere qu'elles possedent en leur sein les marques des mecanismes qui les
ont engendrees. En ce sens, les productions discursives sont privilegiees car le langage est a la fois le
support et le produit de la pensee. Autrement dit, les structures langagieres peuvent refleter les structures
cognitives. Ainsi, une certaine forme d'analyse du discours revient a modeliser des phenomenes cognitifs.

La fonction primitive du langage est la fonction referentielle (Jakobson, 1963), c'est—a—dire qu'il sert a
transmettre a autrui des informations du monde reel par la symbolisation. Cette fonction est accomplie en
vehiculant du sens. L'activite semantique consiste done a produire du sens dans l'intellect du recepteur,
c'est—a—dire la formation de representation mentale chez l'interlocuteur par l'intermediaire du langage.
Depuis la logique aristotelicienne ainsi que dans la logique classique de Frege (1967, 1971), en passant par
la theorie psychologique des reseaux semantiques propositionnels d'Anderson (1976), les chercheurs se
sont interesses au traitement semantique de l'information et ont tente de definir la structure cognitive. Ils
ont fait l'hypothese que l'information dans la memoire est organisee sous forme propositionnelle. En effet,
un mot isole seul ne suffit pas a creer une idee, c'est l'ensemble de proprietes et de relations s'y rapportant
qui permet d'apprehender et de produire la signification psychologique. A partir de ces theories logiques et
psychologiques, Kintsch (1974) a developpe une methode d'analyse linguistique qui permet de modeliser
la maniere dont l'humain encode les informations, appelee analyse predicative. 11 part du postulat que la
forme dominante de la representation cognitive du langage est de nature propositionnelle. Ainsi, « si l'on
considere que la predication qui s'exprime dans un message linguistique est une activite cognitive
essentielle de l'homme et que, sous-jacent a la realisation de surface, c'est-a-dire au mot, se trouve un
concept, on peut estimer que l'analyse predicative, outil de description semantique des textes, est pour le
psychologue la transcription d'une activite cognitive >> (Ghiglione et al., 1995 : 49).

L'analyse predicative permet d'extraire les propositions semantiques dans le discours par la concatenation
des unites elementaires du sens : predicat et argument(s). Par exemple, dans la phrase « Le chien
poursuivait un chat dans le jardin », exemple emprunte a Le Ny (1989), les concepts generiques qui font
reference a des objets (« chien », « chat », « jardin »), a des evenements (« poursuivre »), et a des relations

DENSIDEES : CALCUL AUTOMATIQUE DE LA DENSHE DES IDEES DANS UN CORPUS ORAL

dans l’eSpace (« dans ») peuvent etre extraits. On parle des arguments qui sont des entités référentielles
pouvant correspondre £1 des etres ou des objets, et des prédicats qui sont des unites requérant des
arguments. Ainsi les prédicats assignent des propriétés aux arguments ou définissent la relation entre les
arguments (Coirier et al., 1996). L’analySe prédicative de cette phrase peut etre notée selon la fonne
classique ci—dessous :

Pl. POURSUIVRE (al, a2) a1: chien, a2= chat

P2. DANS (Pl, a3) a3=jardin

L’enSemble constitué d’un prédicat et de son ou ses arguments fonne une idée ou proposition sémantique.

Si 1'ana1yse prédicative reﬂete l'activité cognitive, la densité des idées, quant a elle, permet de la
quantifier. En ramenant le nombre de propositions sémantiques au nombre de mots produits dans le
discours (multiplié par 10 pour obtenir une DI pour 10 mots), on peut mesurer la densité des idées d'un
discours. La DI permet donc de mesurer la quantité informative dans le discours. Une DI élevée peut
reﬂéter l'aptitude d'un locuteur a exprimer efﬁcacement ses idées ainsi que leur interrelation complexe.
Par contre, une faible DI dans le discours peut révéler un discours peu efﬁcient, du fait de l'utilisation d'un
plus grand nombre de mots pour exprimer les idées essentielles. Le score de DI de la phrase « Le chien
poursuivait un chat dans le jardin » précédemment évoquée est donc de 2.5 (2/8*10 = 2.5 : 2 propositions
sémantiques divisées par 8 mots, multiplié par 10).

D1 =  x 10
nombre total de mots

1.2 Calcul automatique de la densité des idées : Densidées

Les études portant sur l’analyse prédicative en langue francaise ont été développées principalement par Le
Ny (1979), Ghiglione (1982), Denhiere (1983). Cependant, il n’y a pas de méthode clairement établie pour
l’analyse prédicative du francais et de texte oral. Aussi, selon les auteurs, quelques divergences peuvent
étre observées selon l’évolution de la théorie linguistique, par exemple la proposition de Le Ny (1987)
d’intégrer les acquis de la grammaire des cas de Fillmore (1968) dans l’analyse prédicative. Nous avons
ainsi établi des régles d’analyse prédicative, basées sur les études précédentes (Kintsch, 1974 ; Turner et
al., 1977 ; Le Ny, 1979 ; Ghiglione et al., 1995 ; Kemper et al., 2001 ; Chand et al., 2010). L’exemple ci-
dessous montre notre méthode d’analyse prédicative :
le plus beau jour de ma vie bon bah réﬂéchissons c'est le jour de mon mariage voila il y a 52 ans bientét donc voila

bien que ca a été un mariage tout a fait Simple parce que je ne je n'avaiS plus mes parents donc quand on S'eSt mariés
on était 12 personnes donc vous voyez

P1

. BEAU (a1) a1=jour
P2.
P3.
P4.
P5.
P6.
P7.
P8.
P9.

LE PLUS (P1)

DE (P1, a2) a2: vie
MON (a2)

COPULE (P3, a=1)

DE (P5, a3) a3: mariage
MON (a3)

IL Y A (a4) a4: ans

52 (a4)

P10. BIENTOT (P8)

P11. COPULE (P7, a3)
P12. SIMPLE (a3)

P13. TOUT A FAIT (P12)
P14. BIEN QUE (P6, P11)

P15. POSSEDER (a5, a6) a5: je,
a6= parents

P16. MON (a6)
P17. NE PLUS (P15)

23/57*10= 4.04

P18. PARCE QUE (P12, P17)
P19. SE MARIER (a7) a7: on

P20. COPULE (a8, a9) a8: on, a9=
personnes

P21. 12 (a9)
P22. QUAND (P19, P20)
P23. DONC (P17, P22)

HYERAN LEE, PHILIPPE GAMBETTE, ELSA MAILLE, CONSTANCE THUILLIER

Les predicats peuvent etre classes en trois grandes categories : predicateur, modificateur, et connecteur.
Les predicateurs expriment 1’action ou l’état (e.g. Verbes « se marier », « etre » dans notre corpus) ; les
modiﬁcateurs spéciﬁent la qualité ou la quantité de l’argument (e.g. adjectif « 52 », adverbe « bientot ») ;
les connecteurs relient les differentes idees (e.g. preposition « de », conjonction « donc », causalite « parce
que », concession « bien que >>). Les arguments renvoient aux objets et/ou personnes (e.g. « je », « on »,
« mariage »), et relevent d'une categorie lexicale qui a pour fonction principale la designation d'objets, en
l'occurrence les substantifs. Ainsi, une proposition peut étre l’argument d’une autre proposition. Si les
prédicats et les arguments peuvent étre relevés facilement, il est difﬁcile d’étab1ir leurs relations,
1’uti1isation des anaphores, l’ambigu"1"té semantique créée par l’emploi du pronom << on » (« on » de a7 dans
P19 a comme referent Vise « nous >>: locutrice + son mari alors que « on » de a8 dans P20 a comme
referent « les gens » incluant a7) requierent une attention soutenue au sens Vehicule.

Plusieurs problematiques de traitement automatique des langues naturelles (e.g. traduction automatique,
extraction d'informations, etc.) ont fait appel a l'analyse predicative, avec l'objectif de representer un texte
en langue naturelle par une formule logique, en langage des predicats du premier ordre. Divers
formalismes sont par exemple presentes par Francois (1991). Toutefois, cette approche s'est heurtee aux
limites du formalisme de representation, et de telles analyses predicatives d'etiquetage semantique sont
actuellement utilisees en pratique uniquement sur des taches tres specifiques et des corpus cibles, comme
dans le systeme presente par Meurs et al. (1998). Sur des corpus plus generaux, la couverture des bases de
donnees semantiques (comme FrameNet) est trop faible, et l'analyse semantique conduit a des taux
d'erreurs importants. Ces erreurs sont amplifiees sur les corpus oraux du type de ceux qui nous interessent
dans le contexte du calcul de la DI, du fait des contraintes qu'ils induisent. En effet, de nombreuses
utilisations de 1’anaphore, les phenomenes oraux particuliers tels que les mots fragmentes, les enonces
inacheves, les ratages, les reformulations, les repetitions, les interjections, les habitudes du langage
(gimmicks), les pauses remplies, etc. rendent l’analyse de l’oral complexe.

Cependant, le calcul de la DI ne necessite en fait pas de calculer l'ensemble des predicats et de leurs
arguments, mais seulement de compter les predicats. Nous avons donc choisi d'eviter d'utiliser une
approche semantique, et d'utiliser plutot les travaux de Brown et al. (2008) sur la langue anglaise. Ceci
dans le but de concevoir une approche du comptage des predicats par un ensemble de regles appliquees
apres un etiquetage morphosyntaxique du texte. Pour calculer la densite des idees, Brown et al. proposent
le logiciel CPIDR qui etiquette chaque mot du texte comme predicat, ou bien comme non-predicat. L'idee
principale de l'etiquetage est qu'un predicat correspond typiquement a un verbe (predicateur), a un adjectif,
a un adverbe (modificateurs), a une preposition, ou a une conjonction (connecteurs). Ainsi, 1'etiquetage
morphosyntaxique est a la base du calcul approximatif de la densite des idees. Cette etape d'etiquetage
morphosyntaxique, traitee dans le cas de CPIDR par le logiciel MontyLingua (Liu, 2004), est suivie d'un
post-traitement a base de regles destinees a corriger les erreurs d'etiquetage morphosyntaxique qui ont une
inﬂuence sur le nombre de predicats, a traiter le cas speciﬁque des corpus oraux (avec une gestion basique
de certaines repetitions ou auto-corrections), et enfin a ajuster le calcul du nombre de predicats. Cette
methode est efficace en anglais, puisque CPIDR obtient generalement un meilleur accord avec un
ensemble d'etiqueteurs humains que les etiqueteurs humains entre eux. Nous avons donc choisi de suivre
les memes principes, en apportant une attention particuliere au caractere oral de notre corpus, important a
la fois pour nos objectifs d'uti1isation de la densite des idees, meme si 1'outil que nous proposons est aussi
destine a l'ecrit. L'implementation de ces principes pour le frangais nous a fait recourir a TreeTagger
(Schmid, 1994) pour 1'etiquetage morphosyntaxique du texte. C'est ensuite un ensemble de 35 regles
d'ajustement que nous proposons pour determiner si un mot est un predicat ou non. Des exemples de
regles sont fournis en ﬁgure 1, elles sont integralement decrites dans le manuel d'uti1isation de Densidees.
Dans la mesure du possible, les numeros de regles utilises dans CPIDR ont ete conserves dans Densidees.
En outre, le logiciel Densidees est ecrit en Python de fagon commentee et tres lisible. I1 fonctionne en

DENSIDEES : CALCUL AUTOMATIQUE DE LA DENSHE DES IDEES DANS UN CORPUS ORAL
ligne de commande mais peut également étre appelé depuis Windows par 1’interrnédiaire d’une interface
graphique montrée en figure 2.

Regle 208 — Comparatif : "que" n'est pas proposition apres "autant", "moins", "pire", "plus"

Regle 301 — Verbes de liaison ("apparaitre", "étre", "Sembler", "devenir", "paraitre",
"rester", "demeurer") non propositions si suivis d'un adiectif ou d'un adverbe

Figure 1 : Exemples de regles de Densidées

 

Ce pvrugramme calcule la dleensité des lidées d'un texte en frangaiis éti-queté "*P'°l_“"'" _ V
par-|—meTag_ger IQ. *1: vas4mi.2--zwmmlu
' : PhiItp_pe  H?yeHanll.ee .

ss;==,fE] Duwir Ie texte '7 “"°d5 °'a' $ Ealculerl | ‘ Mmmmsnwedechslpﬂdcplnﬂ

Ie |DET:AP.'T le A 201 DIETEART W la A
plus ADV plus ZDU AIW W P zpllus

beau ADJ beau 2'31“ IIFDWJ '1 P ll?‘-33"-'

   : 235 :2: 1 P 32”’

1 — 1 ,

“"3 PRP. . “'3 zoo D|Elf:Pl]S w P ma =
ma !DET.F“0.S mun B0,: mm N We

we MOM vie um] Pu” I:

1 PU“ ‘ zoo mu in how

huin ADJ bun mm PU" J‘

1 FUN 1 um: um lbalh

halh INT bah [mg pun (

( PU“ C ZDIU V|EH:pres ‘N réflléclhuissons

réfléchiissurns Vfﬂzpres réflé-chir UBO FUN )1

} PUN } DEII2 PRl]:D>EM W e‘

c‘ PRQDEM ca 2130 \|'|EH:\pres W P est

est VEF.‘:|:urr.-sétre Em WETZMW W “F

Ie uET:Am Ia ggé Egg n P ‘Jiwur

' I 1 ' . ‘ 3

1:?" Egg ﬁg" 333 ﬁﬂwus a P molr:|_

mun [I-ET:‘P‘0:5 mun mm PU" mar "age

mariage MOM mariage mm MW ,"

C PU” C ' nun PIJN

Adresse de Python:   ﬂ

|C:\F'_I,Ithon2B\python.e:-ce 2m] ‘.f|Eﬂ;pre3 1] ,

 

Figure 2. L’interface graphique de Densidées sous Windows

2 Méthode

2.1 Corpus

Pour examiner la validité de notre méthode, nous avons analysé 40 textes oraux. Ce corpus est issu d’une
étude sur la description ﬁne de la degradation linguistique dans la maladie d’A1zheimer. Pour le recueillir,
nous avons mené un entretien individuel semi-dirigé aupres de 40 sujets volontaires. Ces sujets sont agés
de 65 a 85 ans, ne présentant pas d’une pathologie cognitive, et sont locuteurs francais natifs. Cet entretien
dure environ 35 minutes dont 5 a 15 minutes pour 1'enregistrement du discours oral. Une narration libre de
l'évocation d'un souvenir personnel a été demandée pour la production du discours spontané, et une
description d'image « voleur du biscuit », tirée de Boston Diagnostic Aphasia Examination (Goodglass et
al., 1983), pour un discours descriptif. Tous les entretiens ont été enregistrés numériquement. Ces discours
oraux ont été transcrits individuellement avec une transcription orthographique standard de type GARS
(Blanche-Benveniste, 1998), c'est-a-dire sans renormalisation de la parole (e.g. sans introduire de
1’é1ément absent << ne » dans « il y a pas >>), aligner la parole et le texte.

HYERAN LEE, PHILIPPE GAMBETTE, ELSA MAILLE, CONSTANCE THUILLIER
Ce corpus a été tronqué de maniere a garder environ 300 mots par transcription pour que les corpus soient
comparables statistiquement. Kemper et al. (2001) recommande que 1’échanti11on du discours ne soit pas
trop bref pour avoir un résultat ﬁable, et que 1’ana1yse porte sur un minimum de 10 énoncés, ce qui bien
est le cas ici.

2.2 Procédure

Nous avons choisi de proposer un prétraitement manuel du corpus pour marquer certaines caractéristiques
spécifiques a l'oral qui ne semblent difficilement traitables de facon automatique. Nous avons utilisé les
crochets [ ] pour marquer les mots fragmentés, les répétitions successives qui ne doivent pas étre comptées
ni comme prédicats ni comme mots. Les parentheses ( ) servent a entourer les mots qui doivent étre
intégrés dans le compte du nombre total de mots mais ne doivent pas étre marqués comme prédicats.
Entrent dans ce cas les énoncés inachevés, les énoncés et/ou mots inaudibles, les marqueurs discursifs
(e. g. « vous Voyez »), les interjections (e. g. « bon ») qui ne doivent pas étre traitées comme des adjectifs
(donc des prédicats) mais qui sont considérées comme des mots contrairement aux pauses remplies non-
lexicales (e.g. « bah », « hein », etc.), et les noms propres pour éviter les problémes d’étiquetage
morphosyntaxique. Par exemple, voici le prétraitement de la phrase analysée plus haut :

le plus beau jour de ma vie (bon) bah (réﬂéchissons) c'est le jour de mon mariage (voila) il y a 52 ans
bientot (donc voila) bien que ca a été un mariage tout a fait simple parce que [je ne] je n'avais plus
mes parents donc quand on s'est mariés on était 12 personnes (donc vous Voyez)

Ce corpus prétraité manuellement a été soumis au calcul automatique de la DI avec la version 1.2 de
Densidées. Deux experts ont travaillé individuellement chaque texte en notant prédicat et argument de
chaque mot sur Excel, un troisieme examinateur a vérifié leur analyse. Le résultat obtenu par Densidées
est donc vérifié par ces trois experts, pour mesurer le coefﬁcient de corrélation de 1’ana1yse manuelle et
automatique.

3 Résultats

La figure 3 montre les résultats obtenus. On peut noter, entre la densité des idées calculée manuellement et
automatiquement, pour les 40 textes, un coefficient de corrélation de 0.972, la ou CPIDR obtenait 0.942.

demsaité des idées 5‘
salon Densidées I
4.3
4.63
4.4 i
.2 _-5
4
3.3: .
:35 I
3.4 I

'32 densitédes idées Se-.|o~n
3,2 3.4 3.5 3.3. 4 42 4.4 4.6 4.3 5 I|'ét«:iqueta»ge Innanuel

Figure 3. Representation de la densité des idées calculée automatiquement en fonction de la densité des
idées calculée manuellement pour chacun des 40 textes du corpus

DENSIDEES : CALCUL AUTOMATIQUE DE LA DENSHE DES IDEES DANS UN CORPUS ORAL

Pour une evaluation plus fine du logiciel, nous avons choisi de determiner le taux de faux negatifs
(predicats non etiquetes comme tels) et de faux positifs (non-predicats etiquetes comme predicats) :
respectivement 2.7% et 3.1%. Comme la formule de densite des idees fait intervenir le nombre total de
predicats, ces deux types d'erreurs se compensent, pour arriver a un taux d'erreur moyen de 0.5% sur le
nombre de predicats. Le corpus a alors ete separe en une base de test (correspondant a 10 sujets pour
assurer une variete dans les scores de DI) de 3728 mots et 1548 predicats et une base de validation de
10211 mots et 4199 predicats. La base de test a ete utilisee pour evaluer la pertinence de chaque regle, en
testant l'effet de sa suppression. Pour evaluer la qualite d'un etiquetage automatique, on calcule la F-
mesure, qui se base sur la precision (i.e. proportion de predicats corrects parmi les predicats trouves
automatiquement) et le rappel (i.e. proportion des predicats corrects trouves par Densidées sur l'ensemble
des predicats corrects). En n'utilisant que la regle 200, qui etiquette les conjonctions, numeraux,
determinants, prepositions, adjectifs, adverbes et verbes comme predicats, on obtient 29 faux negatifs et
1003 faux positifs, ce qui correspond a une F-mesure de 0.747 sur la base de test. Si l'on prend en compte
l'ensemble des 35 regles de la version 1.2, on arrive a une F-mesure de 0,975.

1|E|1

EL%|E|

E|.9'I"

E135
ELEG
H.914
E19-'5
EL92
E|,E1|Z|
E321
Ilﬂﬁl
1

Figure 4. F-mesure obtenue apres suppression de chaque regle de la version 1.2 de Densidées

D

D

D

E

D

D

D

2!! 24 "1112 2111 ECE 235 2118 211 213 M1 -IUZI2 505 51Ii| EDD E02 "M2
23 54- 2|2|2 2!]-I 2C|':' 21|2 212 214 M2 -I-C5 SE19 512 E-IZI1 "M1 7'93

La figure 4 illustre la degradation de la F-mesure induite par la suppression de chaque regle. Ainsi, on
constate par exemple qu'en retirant la regle 201 dediee a l'etiquetage des determinants "un", "une", "le",
"la", etc. (qui ne sont pas des predicats), la F-mesure decroit a 0.900. Inversement, la suppression de
certaines regles (24, 203, 208, 214, 601, 602, 703) n'a aucun effet, voire ameliore legerement la F-mesure
en supprimant un faux positif pour la regle 500.

Meme si la suppression de ces regles semble n'avoir aucun effet sur le corpus detest, elle pourrait en avoir
sur d'autres textes, ce qui explique que nous les laissons dans Densidées. En effet, certaines de ces regles
sont plus adaptees pour des discours ecrits (comme la 214 qui considere « si  alors » comme un seul
predicat). D'autres, a l'inverse, sont prevues pour le discours oral, mais ciblees sur des marqueurs
discursifs particuliers que les locuteurs n'utilisent pas necessairement : la regle 602 considere par exemple
que « donc » n'est pas un predicat apres le verbe « dire ».

HYERAN LEE, PHILIPPE GAMBETTE, ELSA MAILLE, CONSTANCE THUILLIER

Munis de ce score de qualité qu'est la F-mesure, nous proposons la méthodologie suivante pour l'ajout de
nouvelles regles ou la modiﬁcation de regles existantes dans Densidées. Nous utilisons la base de test a
titre d'exploration pour évaluer l'évolution de la F-mesure suite a des modiﬁcations du programme, la base
de validation sert quant a elle a valider la pertinence des modifications, en vériﬁant que les modiﬁcations
proposées a partir du corpus de test ne sont pas biaisées par les spéciﬁcités linguistiques de ce corpus. Par
exemple, par rapport a la version 1.2, parmi toutes les modifications de regles testées, une seule
(modiﬁcation de la regle 301), raisonnable du point de vue linguistique, a permis d'améliorer la F-mesure
en atteignant 0.978 sur le corpus de test. Sur la base de validation, cette modification a permis de passer
d'une F-mesure de 0.969 a 0.972. Ainsi, elle sera intégrée dans la version 1.3 de Densidées.

4 Discussion

Un entretien oral de 300 mots nécessite environ 25 minutes de transcription, 10 minutes de parenthésage
et 35 minutes d’étiquetage manuel des idées. Ainsi, Densidées permet de diviser par deux le temps total
nécessaire a l'évaluation manuelle de la densité des idées. I1 permet surtout de normaliser l'étiquetage en
évitant les spécificités d’étiquetage des experts humains sur certains mots difficiles a étiqueter. Précisons
que le temps de parenthésage est principalement dﬁ a la relecture attentive du texte nécessaire a la
détection des passages vides de sens ou correspondant a des idées répétées. Rappelons que notre corpus
n’était pas créé pour l’étude du calcul automatique de la densité des idées. Si l’objectif est bien déterminé
au départ (e.g. application médicale) et que les entretiens sont réalisés dans l'optique exclusive de calculer
la densité des idées, la transcription obéit a des contraintes ciblées, et peut se faire plus rapidement en
conjonction avec l'étiquetage (e.g. les passages incompréhensibles placés entre crochets ne sont alors
simplement pas transcrits).

I1 faut aussi noter, a propos des bonnes performances obtenues par Densidées, que les régles d’étiquetage
de mots en prédicats ou non-prédicats présentent une certaine robustesse par rapport a d’éventuelles
erreurs au cours de l’étiquetage morphosyntaxique. En effet, une erreur d’étiquetage d’un verbe pris pour
un adj ectif n’aura souvent aucune conséquence sur l’étiquetage réalisé par Densidées, puisque verbes et
adjectifs sont généralement tous deux considérés comme des prédicats (par la regle 200).

Si la densité des idées est une méthode efﬁcace pour mesurer la quantité d’informations dans un discours,
de nombreuses applications de l’analyse qualitative ﬁne qu’offre l’analyse prédicative sont délaissées, du
fait que les arguments ne sont pas pris en compte dans cette méthode. Par exemple, le calcul du décalage
(i.e. produit par le partage du meme argument par différentes propositions, marquant la cohésion du
discours et sa complexité sémantique) (Duong et al., 2000). Aussi, le calcul du prédicat de premier rang
(i.e. qui n’implique que des arguments objets) et du prédicat de rang supérieur (i.e. implique également
ou exclusivement des arguments propositionnels). Etant donné que le prédicat de rang supérieur a un coﬁt
cognitif plus important, ce type de calcul serait utile pour l’étude psycholinguistique. Pour contourner ces
limites, une méthode probabilistique peut étre envisagée, en mesurant par exemple le nombre et le type
d’arguments que peut avoir un prédicat (e.g. verbe transitif << vendre >> comporte 3 places d’argument:
agent, objet, récepteur). Densidées version 1.2 fait ses premiers pas vers une interprétation qualitative du
résultat de la DI, en offrant les résultats détaillés des regles utilisées pour le calcul (e.g. le taux important
de l’utilisation de la regle 211 reﬁéterait un discours construit principalement autour de la négation, etc.).

5 Conclusion

Le logiciel Densidées foumit actuellement une approximation tout a fait satisfaisante de la densité des
idées d’un discours oral transcrit selon la méthodologie que nous proposons ici. Cette méthodologie fait
intervenir une détection humaine des idées répétées, et il pourrait étre envisagé d'aborder ce probleme de

DENSIDEES : CALCUL AUTOMATIQUE DE LA DENSHE DES IDEES DANS UN CORPUS ORAL
facon automatique. Toutefois, nous pensons que l'effort d'étiquetage humain des idées répétées pendant la
transcription constitue un effort Ininime, et envisageons plutot pour de prochaines versions du logiciel
d'améliorer l'étiquetage morphosyntaxique sur lequel se basent les regles de Densidées, en faisant appel au
logiciel Cordial au lieu de TreeTagger.

On peut également noter que l'étiquetage automatique des prédicats dépend fortement des habitudes
langagieres récurrentes des locuteurs (ajout de « quoi » en fin de phrase par exemple). Ainsi, compléter
cette approche par regles avec une partie statistique (par exemple pour détecter des mots fréquents
inattendus) pourrait aider a repérer ces habitudes langagieres, et proposer automatiquement de nouvelles
regles adaptées.

Enfin, la densité des idées a d'autres applications citées plus haut, dont la mesure du niveau de te chnicité
d'articles scientifiques en langue anglaise. Il serait intéressant de calculer la densité des idées de corpus
écrits en francais pour tenter d'identifier certains genres de textes associés a une densité des idées tres
élevée ou au contraire tres basse. La densité des idées pourrait aussi S’aj outer aux paramétres pertinents
pour choisir des textes en fonction de leur niveau de technicité en enseignement du francais langue
étrangere (Thomas, 2009).

Références

ANDERSON J. (1976). Language, memory and thought. Hillsdale, NJ: Erlbaum Associates.
BLANCHE-BENVENISTE C. (1998). Approches de la langue parlée en francais. Paris : Ophrys.

BROWN C., SNODGRASS T., KEMPER S., HERMAN R., COVINGTON M. (2008). Automatic measurement of
propositional idea density from part-of-speech tagging. Behavior Research Methods, 40(2), 540-545.

CHAND V., BAYNES K., BONNICI L., TOMASZEWSKI FARIAS S. (2010). Analysis of idea density (AID) : A
manual. University of California at Davis.

COIRIER P., GAONAC'H D., PASSERAULT J .-M. (1996). Psycholinguistique textuelle : approche cognitive de
la compréhension et de la production des textes. Paris: Armand Colin.

COVINGTON M. (2009). Idea Density: A potentially informative characteristic of retrieved documents.
Proceedings, IEEE SoutheastCon.

COVINGTON M., RIEDEL W., BROWN C., HE C., MORRIS E., WEINSTEIN S., et al. (2007). Does ketamine
mimic aspects of schizophrenic speech? Journal of Psychopharmacology, 21, 338-346.

DENHIERE G. (1984). Il était une fois... Compréhension et souvenir de récits. Lille: Presses Universitaires
de Lille.

DUONG A., SKA B., POISSANT A., J OANETTE Y. (2000). Effet du vieillissement de la scolarité et du stimulus
sur la production de narrations. In I/e vieillissement cognitif normal. Vers un modéle explicatif du
vieillissement, 137-154. Bruxelles : Edition de De Boeck Université.

FILLMORE C. (1968). The case for case. In Universals in linguistic theory, 1-88. New York: Holt, Rinehart,
and Winston.

FRANCOIS J . (1991). Pertinence linguistique des représentations propositionnelles de la sémantique
cognitive. Sérniotiques, 1(1), 69-80.

FRANCOIS T. (2009). Modeles statistiques pour l'estimation automatique de la difficulté de textes de FLE.
Actes de RECITAL 2009.

FREGE G. (1967). The basic laws of arithmetic. Berkeley: University of California.

HYERAN LEE, PHILIPPE GAMBETTE, ELSA MAILLE, CONSTANCE THUILLIER
FREGE G. (1971). Ecrits logiques et philosophiques. Paris : Presses Universitaires de France.

GHIGLIONE R. (1982). Analyse propositionnelle et modeles argumentatifs. Connexions, 38, 89-106.

GHIGLIONE R., KEKENBOSCH C., LANDRE A. (1995). L'analyse cognitivo-discursive. Grenoble: Presses
Universitaires de Grenoble.

GOODGLASS H., KAPLAN E. (1983) The assessment of aphasia and related disorders. Philadelphia : Lea
and Febiger.

JAKOBSON R. (1963). Essais de linguistique générale. Paris : Editions de Minuit.

KEMPER S., GREINER L., MARQUIS J ., PRENEVOST K., MITZNER T. (2001). Language decline across life
span: ﬁndings from the Nun study. Psychology and Aging, 16(2), 227-239.

KINTSCH W. (1974). The representation of meaning in memory. Hillsdale, NJ : Erlbeaum.

KINTSCH W., KEENAN J . (1973). Reading rate and retention as a function of the number of propositions in
the base structure of sentences. Cognitive Psychology, 5(3), 257-274.

KINTSCH W., KEENAN J . (1978). Toward a model of text comprehension and production. Psychological
Review, 85, 363-394.

LE NY J .-F. (1979). La sémantique psychologique. Paris : Presses Universitaires de France.

LE NY J .-F. (1987). Sémantique psychologique. In Problemes de psycholinguistique, 13-42. Bruxelles :
Pierre Mardaga.

LE NY J .-F. (1989). Science cognitive et compréhension du langage. Paris : Presses Universitaires de
France.

LEE H., BARKAT-DEFRADAS M. (2009). La densité des idées : un modele d'analyse du discours pertinent
pour le diagnostic précoce de la maladie d'Alzheimer ? Actes des 8éme Rencontres J eunes Chercheurs en
Parole.

LIU H. (2004). MontyLingua : An end-to-end natural language processor with common sense. Available at:
web.media.Init.edu/~hugo/montylingua

MEURS M., DUVERT F., BECHET F., LEFEVRE F., DE MORI R. (2008). Annotation en Frames Sémantiques
du corpus de dialogue MEDIA. Actes de TALN 2008.

MOREAUD 0., DAVID D., CHARNALLET A., PELLAT J . (2001). Are semantic errors actually semantic ?
Evidence from Alzheimer’s disease. Brain and language, 77, 176-186.

SCHIVIID H. (1994). Probabilistic Part-of-Speech tagging using decision trees. In New Methods in Language
Processing, 154-164. London : UCL Press.

SNOWDON D., KEMPER S., MORTIIVIER J ., GREINER L., WEKSTEIN D., MAYKESBERY W. (1996). Linguistic
ability in early life and cognitive function and Alzheimer's disease in late life: ﬁndings from the Nun
Study, J AMA, 275, 528-532.

T AKAO A., PROTI-IERO W., KELLY G. (2002). Applying argumentation analysis to assess the quality of
university oceanography students’ scientiﬁc writing. Journal of Geoscience Education, 50, 40-48.

THORSON E., SNYDER R. (1984). Viewer recall of television commercials: structure of commercial scripts.
Psychological Review, 85, 363-394.

TURNER A., GREENE E. (1977). The construction and use of a propositional text base. Technical report, 63.
Boulder: Institute for the study of intellectual behavior, University of Colorado.

