<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Acquisition de grammaires locales pour l&#8217;extraction de relations entre entit&#233;s nomm&#233;es</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>Acquisition de grammaires locales pour l&#8217;extraction de relations
entre entit&#233;s nomm&#233;es
</p>
<p>Mani EZZAT1, 2
</p>
<p>(1) Er-Tim, Inalco, 75343 Paris
(2) Arisem, Thales, 91300 Massy
</p>
<p>mani.ezzat@arisem.com
</p>
<p>R&#233;sum&#233;. La constitution de ressources linguistiques est une t&#226;che cruciale pour les syst&#232;mes d&#8217;ex-
traction d&#8217;information fond&#233;s sur une approche symbolique. Ces syst&#232;mes reposent en effet sur des gram-
maires utilisant des informations issues de dictionnaires &#233;lectroniques ou de r&#233;seaux s&#233;mantiques afin
de d&#233;crire un ph&#233;nom&#232;ne linguistique pr&#233;cis &#224; rechercher dans les textes. La cr&#233;ation et la r&#233;vision ma-
nuelle de telles ressources sont des t&#226;ches longues et co&#251;teuses en milieu industriel. Nous pr&#233;sentons ici
un nouvel algorithme produisant une grammaire d&#8217;extraction de relations entre entit&#233;s nomm&#233;es, de ma-
ni&#232;re semi-automatique &#224; partir d&#8217;un petit ensemble de phrases repr&#233;sentatives. Dans un premier temps, le
linguiste rep&#232;re un jeu de phrases pertinentes &#224; partir d&#8217;une analyse des cooccurrences d&#8217;entit&#233;s rep&#233;r&#233;es
automatiquement. Cet &#233;chantillon n&#8217;a pas forc&#233;ment une taille importante. Puis, un algorithme permet de
produire une grammaire en g&#233;n&#233;ralisant progressivement les &#233;l&#233;ments lexicaux exprimant la relation entre
entit&#233;s. L&#8217;originalit&#233; de l&#8217;approche repose sur trois aspects : une repr&#233;sentation riche du document initial
permettant des g&#233;n&#233;ralisations pertinentes, la collaboration &#233;troite entre les aspects automatiques et l&#8217;ap-
port du linguiste et sur la volont&#233; de contr&#244;ler le processus en ayant toujours affaire &#224; des donn&#233;es lisibles
par un humain.
</p>
<p>Abstract. Building linguistics resources is a vital task for information extraction systems based on
a symbolic approach : cascaded patterns use information from digital dictionaries or semantic networks to
describe a precise linguistic phenomenon in texts. The manual elaboration and revision of such patterns
is a long and costly process in an industrial environment. This work presents a semi-automatic method
for creating patterns that detect relations between named entities in corpora. The process is made of two
different phases. The result of the first phase is a collection of sentences containing the relevant relation.
This collection isn&#8217;t necessairly big. During the second phase, an algorithm automatically produces the
recognition grammar by generalizing the actual content of the different relevant sentences. This method
is original from three different points of view : it uses a rich description of the linguistic content to allow
accurate generalizations, it is based on a close collaboration between an automatic process and a linguist
and, lastly, the output of the acquisition process is always readable and modifiable by the end user.
</p>
<p>Mots-cl&#233;s : relation, entit&#233; nomm&#233;e, grammaire.
</p>
<p>Keywords: relation, named entity, pattern.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mani EZZAT
</p>
<p>1 Introduction
</p>
<p>Les grammaires locales (Silberztein, 1993) sont des ressources indispensables aux syst&#232;mes de recherche
d&#8217;information fond&#233;s sur une approche symbolique. Elles permettent de formaliser un ph&#233;nom&#232;ne linguis-
tique et de le d&#233;tecter dans les textes. Leur principal avantage est la possibilit&#233; de r&#233;vision : elles sont
lisibles et manipulables par un linguiste, ce qui n&#8217;est pas le cas pour les syst&#232;mes &#224; base d&#8217;apprentissage
statistique. L&#8217;am&#233;lioration incr&#233;mentale des r&#233;sultats est une contrainte importante dans un contexte indus-
triel. La plupart des travaux similaires (section 3) produisent une liste importante de patrons, g&#233;n&#233;ralement
lexico-syntaxiques, dans laquelle il est difficile de naviguer.
</p>
<p>Afin de r&#233;pondre &#224; ces contraintes, nous proposons une m&#233;thode semi-automatique d&#8217;acquisition de gram-
maires pour l&#8217;extraction de relations en deux phases. La premi&#232;re consiste en la r&#233;colte de quelques seg-
ments de textes attestant la relation recherch&#233;e. Puis &#224; partir de cette collection de segments, un algorithme
g&#233;n&#232;re une grammaire pr&#233;sent&#233;e sous la forme d&#8217;un unique transducteur &#224; nombre fini d&#8217;&#233;tats, facilitant
alors sa maintenance par le linguiste. Enfin, nous pr&#233;sentons les r&#233;sultats de l&#8217;exp&#233;rience sur un corpus
&#224; travers un cas concret : la relation de contact. L&#8217;originalit&#233; de l&#8217;approche repose sur trois aspects : une
repr&#233;sentation riche du document initial permettant des g&#233;n&#233;ralisations pertinentes, la collaboration &#233;troite
entre les aspects automatiques et l&#8217;apport du linguiste et sur la volont&#233; de contr&#244;ler le processus en ayant
toujours affaire &#224; des donn&#233;es lisibles par un humain.
</p>
<p>Dans la suite de cet article nous pr&#233;sentons en premier lieu ce que nous entendons par le terme relation
(section 2), puis nous pr&#233;senterons les travaux similaires, notamment ceux qui alimentent les syst&#232;mes
fond&#233;s sur une approche symbolique (section 3). Apr&#232;s une description de notre m&#233;thodologie (section 4),
nous pr&#233;sentons nos r&#233;sultats d&#8217;exp&#233;rience (section 5). Enfin, nous concluons par une discussion sur les
r&#233;sultats et les perspectives de recherche (section 6).
</p>
<p>2 D&#233;finition
</p>
<p>L&#8217;extraction de relations entre entit&#233;s nomm&#233;es n&#8217;est pas un probl&#232;me nouveau et a &#233;t&#233; formalis&#233;e officiel-
lement pour la premi&#232;re fois en tant que t&#226;che ind&#233;pendante et r&#233;utilisable lors de la conf&#233;rence Message
Understandig Conference de 1998 (MUC, 1998). Le but est de d&#233;tecter des relations entre entit&#233;s nom-
m&#233;es et de structurer les r&#233;sultats afin d&#8217;alimenter une base de donn&#233;es. Plus tard, les travaux motiv&#233;s par
la campagne Automatic Content Extraction (ACE, 2004) ont fait &#233;merger une d&#233;finition dont nous nous
inspirons ici. Nous appelons relation, un lien significatif entre entit&#233;s nomm&#233;es explicit&#233; dans un texte.
Nous distinguons deux types de relations :
</p>
<p>1. Les relations statiques ou faits repr&#233;sentent essentiellement des &#233;tats. Ce qu&#8217;on appelle &#233;tat se ca-
ract&#233;rise par l&#8217;absence de changement. Un &#233;tat qui est vrai pour un intervalle donn&#233; est vrai pour
tout point de cet intervalle. C&#8217;est donc un lien stable et av&#233;r&#233; entre deux entit&#233;s nomm&#233;es.
exemple : Arisem est une filiale du Groupe Thales. (1)
</p>
<p>2. Les &#233;v&#232;nements peuvent &#234;tre assimil&#233;s &#224; une phrase d&#8217;action et mettent en cause plusieurs enti-
t&#233;s (l&#8217;acteur, la cible et l&#8217;&#233;v&#232;nement particulier qui est d&#233;fini par le pr&#233;dicat et ses arguments par
exemple), qui apportent une information nouvelle sur les participants et qui peuvent avoir une loca-
lisation spatio-temporelle implicite ou non.
exemple : Le groupe Thales a rachet&#233; Arisem en Mars 2004. (2)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Acquision de grammaire locale pour l&#8217;extraction de relations entre entit&#233;s nomm&#233;es
</p>
<p>Les relations entre entit&#233;s nomm&#233;es sont g&#233;n&#233;ralement n-aires et nous distinguons deux types de consti-
tuants : les arguments et les circonstants. Les arguments sont les entit&#233;s nomm&#233;es n&#233;cessaires &#224; l&#8217;existence
de chaque instance. Les circonstants, quant &#224; eux, sont des &#233;l&#233;ments optionnels qui ne sont pas indispen-
sables &#224; la compr&#233;hension et &#224; la compl&#233;tude de l&#8217;&#233;nonc&#233; et repr&#233;sentent g&#233;n&#233;ralement une localisation,
une date ou encore une expression num&#233;rique. Par exemple dans (2), les entit&#233;s nomm&#233;es groupe Thales
et Arisem sont ici les arguments de l&#8217;&#233;v&#232;nement sans lesquels la relation n&#8217;existerait pas, tandis que Mars
2004 est un circonstant, qui n&#8217;est pas obligatoire pour l&#8217;instanciation de la relation.
</p>
<p>3 Travaux similaires
</p>
<p>Depuis MUC 1998, la plupart des travaux se sont concentr&#233;s autour des approches statistiques, car elles ne
n&#233;cessitent pas de d&#233;veloppement manuel de ressources et obtiennent de bons r&#233;sultats. Diff&#233;rents mod&#232;les
sont utilis&#233;s, des SVM (Support Vector Machine) (Zelenko et al., 2003) (Zhao &amp; Grishman, 2005) aux
CRF (Conditional Random Field) (Zhang et al., 2008). Cependant, toutes ces approches reposent sur la
disponibilit&#233; de corpus annot&#233;s et elles apparaissent comme de v&#233;ritables &#8220;bo&#238;tes noires&#8221; : l&#8217;intervention
du linguiste dans l&#8217;analyse reste difficile et ce sont essentiellement certains param&#232;tres qui peuvent &#234;tre
manipul&#233;s afin d&#8217;am&#233;liorer les r&#233;sultats du syst&#232;me.
</p>
<p>Parall&#232;lement, du milieu des ann&#233;es 90 &#224; aujourd&#8217;hui, des &#233;tudes traitent de la g&#233;n&#233;ration de grammaires
pour l&#8217;extraction de relations. Certains travaux utilisent un algorithme de g&#233;n&#233;ralisation ascendante (So-
derland et al., 1995), (Califf &amp; Mooney, 2003). Il s&#8217;agit de rel&#226;cher les contraintes des grammaires qui
d&#233;crivent principalement des &#233;l&#233;ments lexicaux dans un premier temps. On g&#233;n&#233;ralise ensuite cette des-
cription &#224; diff&#233;rents niveaux (morpho-syntaxiques, s&#233;mantiques) en unifiant les patrons. Une nouvelle
r&#232;gle est cr&#233;&#233;e en fusionnant deux r&#232;gles existantes.
</p>
<p>A l&#8217;inverse, d&#8217;autres travaux utilisent des algorithmes descendants pour sp&#233;cifier les patrons. Le syst&#232;me
AutoSlog (Riloff, 1996) pr&#233;cise des sch&#233;mas syntaxiques simples comme &#8220;sujet - verbe &#224; la voix passive&#8221;
et les instancie avec des &#233;l&#233;ments du domaine apr&#232;s analyse. Par exemple, ce sch&#233;ma, dans un corpus sur
le terrorisme, pourra devenir &#8220;&lt;victim&gt; was murdered&#8221;. Les patrons fournis ne d&#233;crivent g&#233;n&#233;ralement
pas de longues d&#233;pendances, comme c&#8217;est souvent le cas pour les relations entre entit&#233;s nomm&#233;es. D&#8217;une
mani&#232;re similaire, le composant LIEP (Huffman, 1996) extrait des patrons lexicaux &#224; partir de sch&#233;mas
simples dont le coeur est une liste de mots cl&#233;s, puis analyse le contexte afin de trouver les &#233;l&#233;ments en
relation syntaxique.
</p>
<p>Enfin, le syst&#232;me Sem+1 (Goujon, 2008) utilise un algorithme issu de la terminologie (Hearst, 1992). Il
s&#8217;agit d&#8217;un processus it&#233;ratif auquel on donne des couples d&#8217;entit&#233;s nomm&#233;es que l&#8217;ont sait en relation,
afin d&#8217;extraire des phrases o&#249; cette relation appara&#238;t. Apr&#232;s avoir inf&#233;r&#233; des patrons lexicaux &#224; partir de ces
phrases, le syst&#232;me les applique au corpus afin de trouver de nouveaux candidats qui servent de donn&#233;es
d&#8217;entr&#233;e &#224; une nouvelle it&#233;ration. Le syst&#232;me produit un patron par phrase, contraint sur le lexique qui la
compose. Il en r&#233;sulte un nombre important de patrons difficiles &#224; maintenir et dont le rappel peut chuter
sur un autre corpus.
</p>
<p>La plupart de ces travaux n&#233;cessitent que l&#8217;utilisateur fournisse en amont une liste de patrons. De plus, ces
syst&#232;mes produisent des grammaires pr&#233;sent&#233;es sous la forme de liste importante de patrons qui restent
tr&#232;s difficiles &#224; maintenir.
</p>
<p>1Sem+ est un outil de Thal&#232;s Research and Technology avec qui Arisem collabore</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mani EZZAT
</p>
<p>4 M&#233;thodologie
</p>
<p>Notre m&#233;thode g&#233;n&#232;re une grammaire &#224; partir de segments de textes extraits d&#8217;un corpus et attestant la
relation recherch&#233;e. Elle se divise en deux phases distinctes. La premi&#232;re consiste en la s&#233;lection de seg-
ments repr&#233;sentatifs de la relation recherch&#233;e. Cette &#233;tape n&#8217;est pas enti&#232;rement automatique et requiert
l&#8217;assistance du linguiste. Il s&#8217;agit de compter les cooccurrences entre entit&#233;s nomm&#233;es puis de pr&#233;senter
les r&#233;sultats de mani&#232;re lisible, afin que le linguiste puisse rapidement s&#233;lectionner une relation qui l&#8217;in-
t&#233;resse et les segments de texte qui en attestent. Cette collection de segments vient ensuite alimenter un
algorithme, bas&#233; sur un principe de curseur. Cette technique consiste &#224; lire les phrases de gauche &#224; droite et
&#224; g&#233;n&#233;raliser au fil de l&#8217;eau l&#8217;information contenue dans les phrases. Le processus produit un unique trans-
ducteur &#224; nombre fini d&#8217;&#233;tats, au fur et &#224; mesure des r&#233;sultats renvoy&#233;s par l&#8217;analyse de chaque segment.
</p>
<p>FIG. 1 &#8211; Sch&#233;ma g&#233;n&#233;ral de la m&#233;thode
</p>
<p>4.1 S&#233;lection des segments de textes
</p>
<p>La premi&#232;re &#233;tape a pour but la s&#233;lection de segments de texte qui rel&#232;vent d&#8217;un &#233;v&#232;nement particulier.
Apr&#232;s avoir d&#233;tect&#233; les entit&#233;s nomm&#233;es avec l&#8217;analyseur d&#8217;Arisem, nous comptons le nombre de phrases
dans lesquelles le m&#234;me groupe d&#8217;entit&#233;s nomm&#233;es appara&#238;t. Ce processus ne se restreint pas &#224; 2, mais &#224; n
entit&#233;s pr&#233;sentes dans la m&#234;me phrase.
</p>
<p>Personne Personne Lieu Date Nb Liens
Gnassingb&#233; Eyad&#233;ma Gbagbo Lom&#233; Jeudi 11 Lien1, Lien2...
Olusegun Obasanjo Guillaume Soro Paris 30 Avril 11 Lien1, Lien2...
Carlo Azeglio Ciampi Laurent Gbagbo Vatican mercredi 11 Lien1, Lien2...
Chirac Kofi Annan 10 Lien1, Lien2...
</p>
<p>TAB. 1 &#8211; Echantillon de la sortie apr&#232;s calcul des cooccurrences
</p>
<p>Le r&#233;sultat (tableau 1) est pr&#233;sent&#233; sous la forme d&#8217;un tableau listant les ensembles d&#8217;entit&#233;s nomm&#233;es
cooccurrentes, class&#233;s par leur nombre, avec des liens pointant sur les phrases o&#249; elles apparaissent. Le</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Acquision de grammaire locale pour l&#8217;extraction de relations entre entit&#233;s nomm&#233;es
</p>
<p>linguiste peut alors explorer ce r&#233;sultat afin de choisir rapidement une relation int&#233;ressante par rapport au
corpus et s&#233;lectionner les segments de textes qui en attestent. Pour cette exp&#233;rience, nous avons retenu la
relation de contact, d&#233;finie comme la rencontre explicite entre deux personnes dans un texte.
</p>
<p>Parmi les segments s&#233;lectionn&#233;s, nous avons gard&#233; uniquement ceux bas&#233;s sur un pr&#233;dicat verbal. L&#8217;algo-
rithme qui g&#233;n&#232;re le transducteur ob&#233;it &#224; des r&#232;gles &#233;tablies en fonction du type de construction syntaxique.
Dans le cadre de cet article, nous nous sommes restreint aux pr&#233;dicats verbaux car ils composent la majo-
rit&#233; des segments de textes repr&#233;sentant une relation. Le nombre de segments s&#233;lectionn&#233;s ne doit pas &#234;tre
n&#233;cessairement important.
</p>
<p>4.2 Description de l&#8217;algorithme de g&#233;n&#233;ration de la grammaire
</p>
<p>L&#8217;algorithme de g&#233;n&#233;ration de la grammaire &#224; partir des exemples proc&#232;de en deux &#233;tapes. Les phrases sont
tout d&#8217;abord &#8220;d&#233;cor&#233;es&#8221; avec diff&#233;rentes annotations linguistiques (li&#233;s &#224; la morphosyntaxe, &#224; la syntaxe
de surface et &#224; la s&#233;mantique) gr&#226;ce &#224; un analyseur d&#233;velopp&#233; chez Arisem. Une g&#233;n&#233;ralisation est ensuite
op&#233;r&#233;e &#224; partir des annotations pour produire une grammaire &#224; partir d&#8217;un algorithme de type shift-reduce
(Aho &amp; Ullman, 1972).
</p>
<p>4.2.1 Description des annotation fournies par l&#8217;analyseur Arisem
</p>
<p>Nous utilisons l&#8217;analyseur d&#8217;Arisem, fond&#233; sur une approche symbolique, afin de g&#233;n&#233;raliser le niveau de la
description de la grammaire g&#233;n&#233;r&#233;e &#224; partir des segments de texte issus de la premi&#232;re &#233;tape. L&#8217;analyseur
d&#233;core le texte avec diff&#233;rents niveaux d&#8217;&#233;tiquettes, morphologiques, syntaxiques et s&#233;mantiques sur les
mots et les syntagmes pertinents.
</p>
<p>En compl&#233;ment des &#233;tiquettes morpho-syntaxiques apport&#233;es par les dictionnaires, nous avons utilis&#233; des
grammaires pour la d&#233;tection des entit&#233;s nomm&#233;es. Nous avons &#233;galement ajout&#233; une grammaire de d&#233;tec-
tions de groupes nominaux (d&#233;terminants exclus) ainsi qu&#8217;une grammaire de reconnaissance de locutions
verbales (&#8220;aller voir&#8221; par exemple) et de verbes munis d&#8217;un auxiliaire. Cette analyse syntaxique de surface
nous permet de reconna&#238;tre de longues s&#233;quences de mots, avec des contraintes suffisantes pour ne pas
g&#233;n&#233;rer de bruit.
</p>
<p>4.2.2 Description de l&#8217;algorithme de production de la grammaire
</p>
<p>On peut assimiler l&#8217;algorithme de production de la grammaire &#224; un algorithme de type shift reduce (Aho
&amp; Ullman, 1972; Soricut &amp; Marcu, 2003) : les phrases sont examin&#233;es une &#224; une, de gauche &#224; droite.
Les mots sont lus les uns apr&#232;s les autres (shift) et r&#233;duits &#224; une &#233;tiquette donn&#233;e quand une r&#232;gle de
g&#233;n&#233;ralisation peut &#234;tre appliqu&#233;e (reduce). Un graphe (la grammaire r&#233;sultat) est g&#233;n&#233;r&#233; en parall&#232;le &#224;
partir des g&#233;n&#233;ralisations ; cette g&#233;n&#233;ration repose sur deux op&#233;rations essentielles : unification du noeud
en cours d&#8217;examen avec un noeud compatible d&#233;j&#224; existant dans la grammaire g&#233;n&#233;r&#233;e, ou cr&#233;ation d&#8217;un
nouveau noeud si aucune unification n&#8217;est possible.
</p>
<p>Exemples :
</p>
<p>1. Soit la phrase &#8220;Sarkozy a rencontr&#233; Chirac&#8221;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mani EZZAT
</p>
<p>L&#8217;analyseur fournit (parmi d&#8217;autres) les &#233;tiquettes suivantes :
&#8211; Sarkozy&#8594; Personne
&#8211; Chirac&#8594; Personne
&#8211; a rencontr&#233;&#8594; Groupe Verbal
S&#8217;il s&#8217;agit de la premi&#232;re phrase analys&#233;e, la grammaire g&#233;n&#233;r&#233;e est vide. A partir de cette phrase,
l&#8217;algorithme va produire la grammaire suivante sous la forme d&#8217;un graphe :
</p>
<p>2. Si l&#8217;analyseur re&#231;oit &#224; pr&#233;sent la phrase &#8220;Sarkozy a rencontr&#233; hier Chirac&#8221;
La m&#234;me analyse se met en place ; Sarkozy peut s&#8217;unifier avec le premier noeud de la grammaire
&lt;Personne&gt; ; idem pour le verbe. En revanche, hier ne peut s&#8217;unifier avec &lt;Personne&gt;. L&#8217;algo-
rithme cr&#233;e donc une nouvelle ramification avec un nouveau noeud portant l&#8217;&#233;tiquette &lt;ADV&gt; entre
&lt;Groupe Verbal&gt; et &lt;Personne&gt;.
</p>
<p>R&#232;gles de g&#233;n&#233;ralisation
</p>
<p>Voici, de fa&#231;on plus syst&#233;matique, l&#8217;ensemble des g&#233;n&#233;ralisations op&#233;r&#233;es &#224; partir des informations four-
nies par l&#8217;analyseur d&#8217;Arisem.
</p>
<p>&#8211; Les entit&#233;s nomm&#233;es sont typ&#233;es avec leur &#233;tiquette correspondante :&#8220;Chirac&quot;&#8594; &lt;Personne&gt;,
&#8220;Microsoft&quot;&#8594; &lt;Organisation&gt; etc...
</p>
<p>&#8211; Les groupes nominaux qui ne sont pas des entit&#233;s nomm&#233;es sont g&#233;n&#233;ralis&#233;s en tant que &lt;GN&gt; :
&#8220;les rebelles ivoiriens&quot;&#8594; &lt;GN&gt;.
</p>
<p>&#8211; Les groupes verbaux ont un statut particulier. La s&#233;mantique de la relation &#233;tant port&#233;e par celui-ci, nous
les g&#233;n&#233;ralisons en construisant un nouveau graphe en cascade, avec des noeuds repr&#233;sentant un retour
au lemme de tous les &#233;l&#233;ments qui composent le segment original (figure 2). Ainsi le segment ira voir
d&#233;tect&#233; en tant que groupe verbal, produira le sous-graphe [&lt;aller&gt;] &#8594; [&lt;voir&gt;].
</p>
<p>&#8211; Enfin, tous les mots restants ne rentrant pas dans ces cat&#233;gories sont g&#233;n&#233;ralis&#233;s par leur &#233;tiquette
morpho-syntaxique : &quot;et&quot; &#8594; &lt;CONJC&gt; (conjonction de coordination),&#8220;pour&quot; &#8594; &lt;PREP&gt; (pr&#233;posi-
tion),&#8216;le&quot;&#8594;&gt; &lt;DET&gt; (d&#233;terminant) etc...
</p>
<p>4.3 R&#233;sultat et formalisation
</p>
<p>Le r&#233;sultat est assimilable &#224; un graphe conceptuel (Sowa, 1984), o&#249; le pr&#233;dicat est le centre et les princi-
paux arguments sont li&#233;s par des relations typ&#233;es. Les r&#232;gles de g&#233;n&#233;ralisation op&#232;rent sur des &#233;l&#233;ments
de natures diverses sur la base de la compatibilit&#233; de type (on peut g&#233;n&#233;raliser &#8220;Chirac&#8221; en &lt;Personne&gt;
puis en &lt;Entit&#233;&gt; parce que ces diff&#233;rents &#233;l&#233;ments sont des g&#233;n&#233;ralisations compatibles, autrement dit</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Acquision de grammaire locale pour l&#8217;extraction de relations entre entit&#233;s nomm&#233;es
</p>
<p>FIG. 2 &#8211; Exemple de transducteur en cascade pour les groupes verbaux
</p>
<p>parce qu&#8217;on a affaire &#224; une relation d&#8217;hyponymie/hyperonymie entre ces diff&#233;rents &#233;l&#233;ments, modulo le
fait que Chirac est une instance et non un type).
</p>
<p>De m&#234;me, la g&#233;n&#233;ration de la grammaire est comparable &#224; la jointure dans les graphes conceptuels (Sowa,
1984), o&#249; les noeuds compatibles sont fusionn&#233;s, et o&#249; les autres cr&#233;ent de nouvelles ramifications dans le
graphe r&#233;sultat. La diff&#233;rence essentielle r&#233;side dans l&#8217;analyse sous-jacente au moyen d&#8217;un algorithme de
type shift reduce qui se fonde sur l&#8217;ordre lin&#233;aire de la phrase. Mais m&#234;me dans les premi&#232;res impl&#233;menta-
tions des graphes conceptuels (Fargues et al., 1986), de tels m&#233;canismes avaient d&#251; &#234;tre mis en place pour
limiter le pouvoir expressif de la jointure souvent trop puissante pour des applications en langue naturelles
(intuitivement, on souhaite tenir compte de l&#8217;ordre des &#233;l&#233;ments tout simplement parce que la syntaxe est
d&#233;terminante pour la compr&#233;hension). Certaines jointures sont guid&#233;es ici de fa&#231;on &#224; ce que le graphe res-
pecte la construction des phrases analys&#233;es, repr&#233;sent&#233;e ici par un verbe pr&#233;sent entre les deux arguments
de la relation.
</p>
<p>Nous autorisons les retours-arri&#232;re dans le graphe. Ils op&#232;rent seulement dans une fen&#234;tre pr&#233;cise, d&#233;limi-
t&#233;e par les deux arguments et le verbe. Il y a donc 4 fen&#234;tres d&#233;finies (avant, apr&#232;s et entre les arguments
et le verbe). Nous unifions les noeuds compatibles par un retour-arri&#232;re, si et seulement s&#8217;ils apparaissent
dans la m&#234;me fen&#234;tre. Autrement dit, si deux d&#233;terminants sont pr&#233;sents dans la m&#234;me fen&#234;tre, ils seront
unifi&#233;s par le m&#234;me noeud.
Ces retours-arri&#232;re guid&#233;s rendent le graphe plus lisible car ils limitent le nombre de cr&#233;ation de noeuds.
Cependant, ils augmentent la combinatoire des chemins possibles dans le graphe et peuvent engendrer du
bruit.
</p>
<p>Nous partons donc d&#8217;une base d&#8217;analyse assez traditionnelle. Notre objectif principal est de l&#8217;op&#233;ration-
naliser dans un cadre industriel avec les contraintes que nous avons mentionn&#233;es dans l&#8217;introduction :
n&#233;cessit&#233; de garder un processus lisible, modifiable par un linguiste et facilement adaptable &#224; un nouveau
domaine.
</p>
<p>5 Protocole d&#8217;exp&#233;rimentation et r&#233;sultats
</p>
<p>Nous avons utilis&#233; deux corpus pour l&#8217;exp&#233;rimentation, un corpus d&#8217;acquisition et un corpus de test. Le
corpus d&#8217;acquisition nous a servi pour inf&#233;rer la grammaire, le second pour l&#8217;&#233;valuation pr&#233;sent&#233;e dans
cette section.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mani EZZAT
</p>
<p>5.1 &#201;laboration de la grammaire &#224; partir du corpus d&#8217;entra&#238;nement
</p>
<p>Le corpus d&#8217;acquisition est compos&#233; d&#8217;environ 7 millions de mots r&#233;partis sur 13 500 d&#233;p&#234;ches AFP
portant sur la crise en C&#244;te d&#8217;Ivoire. Une d&#233;p&#234;che ne d&#233;passe g&#233;n&#233;ralement pas les 8 phrases et le genre
textuel est journalistique. Comme expliqu&#233; supra, il faut d&#8217;abord s&#233;lectionner un ensemble de phrases
pertinentes par rapport &#224; la relation pour pouvoir ensuite lancer le processus de g&#233;n&#233;ration de la grammaire
de reconnaissance.
</p>
<p>Lors de la s&#233;lection de segments de textes, nous remarquons que les nombres de cooccurrences les plus
importantes (jusqu&#8217;&#224; 200 phrases contenant le m&#234;me ensemble d&#8217;entit&#233;s nomm&#233;es) rel&#232;vent de relations
statiques. Les cooccurrences avec un nombre moyen, situ&#233; entre 5 et 15, sont compos&#233;es g&#233;n&#233;ralement
d&#8217;&#233;v&#232;nements. Au dessous de 5, le nombre d&#8217;ensembles d&#8217;entit&#233;s cooccurrentes tr&#232;s important rend dif-
ficile l&#8217;exploration. Nous avons observ&#233; que la relation de contact &#233;tait la plus pr&#233;sente dans les scores
moyens et nous avons s&#233;lectionn&#233; un ensemble de 98 segments qui en attestent. Parmi ces 98 segments,
nous n&#8217;avons gard&#233; que les 54 qui sont pr&#233;sent&#233;s sous la forme d&#8217;une construction autour d&#8217;un pr&#233;dicat
verbal.
</p>
<p>L&#8217;algorithme de g&#233;n&#233;ration est produit automatiquement &#224; partir de ces 54 phrases pertinentes. On re-
marquera la tr&#232;s faible taille de l&#8217;&#233;chantillon d&#8217;apprentissage, caract&#233;ristique de ce type d&#8217;applications en
milieu industriel. De fait, les techniques d&#8217;apprentissage demandant de grosses masses de donn&#233;es pour
l&#8217;apprentissage ne sont pas utilisables dans ce contexte.
</p>
<p>5.2 Evaluation de la grammaire
</p>
<p>Nous utilisons le second corpus pour &#233;valuer la grammaire produite : il s&#8217;agit d&#8217;un &#233;chantillon de l&#8217;ann&#233;e
2007 du journal Le Monde compos&#233; d&#8217;environ 639 500 mots. 227 segments attestant la relation de contact
ont &#233;t&#233; annot&#233;s manuellement ; nous avons volontairement utilis&#233; un corpus d&#8217;un genre textuel proche du
corpus d&#8217;acquisition pour l&#8217;&#233;valuation (corpus de type journalistique) mais nous avons tenu &#224; modifier la
source afin de ne pas &#234;tre trop proche du corpus original. Le reste de la section pr&#233;sente uniquement les
r&#233;sultats obtenus &#224; partir du corpus de test.
</p>
<p>Pour l&#8217;&#233;tape de s&#233;lection des segments de textes, nous n&#8217;utilisons pas de m&#233;triques car la s&#233;lection des
segments de textes est effectu&#233;e manuellement (&#224; partir de l&#8217;analyse automatique des cooccurrences tou-
tefois). Pour le transducteur g&#233;n&#233;r&#233;, nous utilisons les mesures de pr&#233;cision et rappel, calcul&#233; &#224; partir des
segments annot&#233;s dans le corpus d&#8217;&#233;valuation.
</p>
<p>Nous appliquons la grammaire g&#233;n&#233;r&#233;e sur le corpus de test et nous calculons le rappel (tableau 2) selon
trois cas distincts.
</p>
<p>1. En prenant en compte tous les segments annot&#233;s dans le corpus.
</p>
<p>2. En ne gardant que les segments annot&#233;s construits autour d&#8217;un pr&#233;dicat verbal.
</p>
<p>3. En ne gardant qu&#8217;un sous-ensemble des segments annot&#233;s construits autour d&#8217;un pr&#233;dicat verbal
sans anaphores ou cor&#233;f&#233;rences des entit&#233;s nomm&#233;es du type personne.
</p>
<p>La pr&#233;cision ne varie pas car la grammaire reconna&#238;t soit des segments qui correspondent au crit&#232;re 3 (le
plus petit des ensembles), soit des segments qui ne correspondent &#224; aucun des trois crit&#232;res. Si une petite
partie du bruit g&#233;n&#233;r&#233; provient des grammaires utilis&#233;es dans l&#8217;analyseur (mauvaise d&#233;tection d&#8217;entit&#233;s</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Acquision de grammaire locale pour l&#8217;extraction de relations entre entit&#233;s nomm&#233;es
</p>
<p>Segments consid&#233;r&#233;s Rappel Pr&#233;cision
Tous segments confondus 36.5% 84.6%
</p>
<p>Pr&#233;dicats verbaux 55.3% 84.6%
Pr&#233;dicats verbaux sans cor&#233;f&#233;rences 83.8% 84.6%
</p>
<p>TAB. 2 &#8211; Estimation du rappel et de la pr&#233;cision
</p>
<p>nomm&#233;es, de groupes nominaux et verbaux), la majeure partie est due aux retours arri&#232;re du transducteur,
notamment sur le noeud repr&#233;sentant un groupe nominal. En effet, celui-ci ne fait l&#8217;objet d&#8217;aucune r&#232;gle
de jointure, engendrant alors une forte augmentation de la combinatoire des s&#233;quences reconnues.
</p>
<p>Le silence est en partie d&#251; aux diff&#233;rences textuelles des corpus. Le corpus d&#8217;&#233;valuation contient des
phrases et des textes g&#233;n&#233;ralement plus longs qui peuvent contenir des incises. D&#8217;autre part, on observe
&#233;galement que la longueur des textes du corpus d&#8217;&#233;valuation force l&#8217;emploi d&#8217;anaphores et de cor&#233;f&#233;rences,
qui composent pr&#232;s d&#8217;un tiers des segments annot&#233;s manuellement. Leur r&#233;solution peut am&#233;liorer de
mani&#232;re importante le rappel (environ 30%).
</p>
<p>On remarque &#233;galement que le rappel est relativement correct si on consid&#232;re la petite taille de l&#8217;&#233;chan-
tillon de segments de textes (au nombre de 54) &#224; partir duquel est produite la grammaire. Les r&#232;gles de
g&#233;n&#233;ralisation et de jointure rel&#226;chent suffisamment les contraintes sans pour autant augmenter le bruit
d&#8217;une mani&#232;re importante.
</p>
<p>6 Discussion et conclusion
</p>
<p>Nous avons pr&#233;sent&#233; une m&#233;thode semi-automatique pour la cr&#233;ation de grammaires de d&#233;tection de re-
lations entre entit&#233;s nomm&#233;es. Si les performances sont honorables en terme de pr&#233;cision et rappel, il
est en revanche difficile d&#8217;objectiver le r&#233;el gain apport&#233;. En effet, notre m&#233;thode a un double objectif.
D&#8217;une part, elle doit faciliter l&#8217;&#233;dition de la grammaire par un linguiste en la rendant plus lisible &#224; travers
un unique transducteur &#224; nombre fini d&#8217;&#233;tats, et d&#8217;autre part, elle doit &#233;galement permettre un gain de
temps important par rapport &#224; la constitution manuelle d&#8217;une telle ressource. Ces deux crit&#232;res, r&#233;currents
dans les syst&#232;mes d&#8217;extraction d&#8217;informations fond&#233;s sur une approche symbolique, sont particuli&#232;rement
difficiles &#224; &#233;valuer. Par ailleurs, la mani&#232;re de fusionner les noeuds du graphe est guid&#233;e par le type de
construction syntaxique des phrases analys&#233;es. Ce qui implique un changement de r&#232;gles selon ce type.
Nous avons seulement exp&#233;riment&#233; l&#8217;algorithme dans le cas de relations entre entit&#233;s nomm&#233;es bas&#233;es sur
un pr&#233;dicat verbal. Mais il faut d&#233;finir autant de r&#232;gles qu&#8217;il existe de constructions syntaxiques exprimant
une relation entre entit&#233;s nomm&#233;es. Celles-ci sont potentiellement nombreuses.
</p>
<p>Remerciements
</p>
<p>Je remercie mon directeur de recherche, Thierry Poibeau, pour son suivi et ses conseils avis&#233;s. Je remercie
&#233;galement Nicolas Dessaigne, directeur technique de l&#8217;entreprise qui m&#8217;emploie, ainsi que mon coll&#232;gue
Ga&#235;l Patin pour son aide apport&#233;e. Ces recherches ont &#233;t&#233; en partie effectu&#233;es dans le cadre du projet
CAHORS financ&#233; par l&#8217;ANR (appel &#224; projet CSOSG 2008).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mani EZZAT
</p>
<p>R&#233;f&#233;rences
</p>
<p>ACE (2004). Automatic Content Extraction, English Annotation Guidelines for Relations. ACE Consor-
tium, Linguistic Data.
</p>
<p>AHO A. &amp; ULLMAN J. (1972). The Theory of Parsing, Translation and Compiling. Prentice Hall.
</p>
<p>CALIFF M.-E. &amp; MOONEY R. J. (2003). Relational learning of pattern matching rules for information
extraction. In The Journal of Machine Learning Research.
</p>
<p>FARGUES J., DUGOURD M.-C. L. A. &amp; CATACH L. (1986). Conceptual graphs for semantics and
knowledge processing. IBM Journal of Research and Development archive, 30(1), 70&#8211;79.
GOUJON B. (2008). Relation extraction in an intelligence context. In LangTech 2008.
</p>
<p>HEARST M. (1992). Automatic acquisition of hyponyms from large text corpora. Conference On Com-
putational Linguistics (COLING), p. 539&#8211;545.
</p>
<p>HUFFMAN S. B. (1996). Learning information extraction patterns from examples. In Connectionist,
Statistical and Symbolic Approaches to Learning for Natural Language Processing.
</p>
<p>MUC (1998). Proceedings of the Seventh Message Understanding Conference. MUC-7.
</p>
<p>RILOFF E. (1996). Automatically generating extraction patterns from untagged text. In Thirteenth
National Conference on Artificial Intelligence (AAAI-96).
</p>
<p>SILBERZTEIN M. (1993). Dictionnaires &#233;lectroniques et analyse automatique de textes - Le syst&#232;me
Intex. Masson.
</p>
<p>SODERLAND S., FISHER D., ASELTINE J. &amp; LEHNERT W. (1995). Crystal : Inducing a conceptual
dictionary. In Fourteenth International Joint Conference on Artificial Intelligence.
</p>
<p>SORICUT R. &amp; MARCU D. (2003). Sentence level discourse parsing using syntactic and lexical in-
formation. Proceedings of the 2003 Conference of the North American Chapter of the Association for
Computational Linguistics on Human Language Technology.
</p>
<p>SOWA J. F. (1984). Conceptual Structures : Information Processing in Mind and Machine. Addison-
Wesley.
</p>
<p>ZELENKO D., AONE C. &amp; RICHARDELLA A. (2003). Kernel method for relation extraction. In Journal
of Machine Learning Research.
</p>
<p>ZHANG S., ZHANG S. &amp; GAO G. (2008). Automatic entity relation extraction based on conditional
random fields. Fuzzy Systems and Knowledge Discovery, 2008. FSKD &#8217;08.
</p>
<p>ZHAO S. &amp; GRISHMAN R. (2005). Extracting relations with integrated information using kernel me-
thods. In ACL 2005, Dourdan.</p>

</div></div>
</body></html>