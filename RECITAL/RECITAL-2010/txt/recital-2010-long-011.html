<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Repr&#233;sentation vectorielle de textes courts d&#8217;opinions, Analyse de traitements s&#233;mantiques pour la fouille d&#8217;opinions par clustering</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>RECITAL 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>Repr&#233;sentation vectorielle de textes courts d&#8217;opinions
Analyse de traitements s&#233;mantiques pour la fouille d&#8217;opinions par clustering
</p>
<p>Beno&#238;t Trouvilliez1, 2
</p>
<p>(1) Centre de Recherche en Informatique de Lens, Universit&#233; d&#8217;Artois, Rue Jean
Souvraz, 62300 Lens, France
</p>
<p>(2) Onyme SARL, 165 Avenue de Bretagne, 59000 Lille, France
btrouvilliez@onyme.com, benoit.trouvilliez@gmail.com
</p>
<p>R&#233;sum&#233;. Avec le d&#233;veloppement d&#8217;internet et des sites d&#8217;&#233;changes (forums, blogs, sondages en
ligne, ...), l&#8217;exploitation de nouvelles sources d&#8217;informations dans le but d&#8217;en extraire des opinions sur
des sujets pr&#233;cis (film, commerce,...) devient possible. Dans ce papier, nous pr&#233;sentons une approche de
fouille d&#8217;opinions &#224; partir de textes courts. Nous expliquons notamment en quoi notre choix d&#8217;utilisation
de regroupements autour des id&#233;es exprim&#233;es nous a conduit &#224; opter pour une repr&#233;sentation implicite telle
que la repr&#233;sentation vectorielle. Nous voyons &#233;galement les diff&#233;rents traitements s&#233;mantiques int&#233;gr&#233;s &#224;
notre cha&#238;ne de traitement (traitement de la n&#233;gation, lemmatisation, stemmatisation, synonymie ou m&#234;me
polys&#233;mie des mots) et discutons leur impact sur la qualit&#233; des regroupements obtenus.
</p>
<p>Abstract. With the internet and sharing web sites developement (forums, blogs, online surveys,
...), new data source exploitation in order to extract opinions about various subjects (film, business, ...)
becomes possible. In this paper, we show an opinion mining approach from short texts. We explain how
our choice of using opinions clustering have conducted us to use an implicit representation like vectorial
representation. We present different semantic process that we have incorporated into our process chain
(negation process, lemmatisation, stemmatisation, synonymy or polysemy) and we discut their impact on
the cluster quality.
</p>
<p>Mots-cl&#233;s : repr&#233;sentation des textes, repr&#233;sentation vectorielle, traitement de textes courts, regrou-
pements d&#8217;opinions.
</p>
<p>Keywords: text representation, vectorial representation, short text processing, opinion clustering.
</p>
<p>ONYME SARL 1</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>RECITAL 2010, Montr&#233;al, 19-23 juillet 2010 Beno&#238;t Trouvilliez
</p>
<p>Introduction
</p>
<p>Avec le d&#233;veloppement d&#8217;internet, on observe la croissance de nouvelles sources d&#8217;informations refl&#233;tant
des opinions sur des sujets vari&#233;s : un film, une actualit&#233;, les valeurs d&#8217;une entreprise, les prestations
d&#8217;un commer&#231;ant, un site internet, ... Ces sources prennent des formes diverses telles que des sites com-
munautaires (forums, blogs) ou des sites de sondages en ligne. Les textes sont assez courts et d&#233;passent
rarement 4 phrases. Dans ce contexte, plusieurs strat&#233;gies d&#8217;extractions d&#8217;opinions (&#171;fouilles d&#8217;opinions&#187;
ou &#171;Opinion Mining&#187;) ont vu le jour. Alors que certains travaux visent &#224; une analyse de sentiments afin de
d&#233;terminer si les auteurs sont plut&#244;t favorables ou d&#233;favorables au sujet en question (Poirier et al., 2008),
nous nous int&#233;ressons &#224; la probl&#233;matique du regroupement afin d&#8217;extraire les principales id&#233;es d&#233;velop-
p&#233;es. Nous faisons appel &#224; deux techniques diff&#233;rentes : des m&#233;thodes d&#8217;analyse s&#233;mantique qui extraient
l&#8217;information des textes dans un mod&#232;le (&#171;repr&#233;sentation de textes&#187;) et des m&#233;thodes de regroupements
non supervis&#233;s (&#171;clusterings&#187;) qui transforment cette information en groupes d&#8217;opinions (Fig. 1).
</p>
<p>1 Repr&#233;sentation et traitements s&#233;mantiques
</p>
<p>1.1 G&#233;n&#233;ralit&#233;s et constats
</p>
<p>Les textes que nous avons &#224; traiter ont une taille moyenne de deux phrases exc&#232;dant rarement 5 mots
chacune. Ils refl&#232;tent des opinions d&#8217;auteurs diff&#233;rents, n&#8217;utilisant pas le m&#234;me niveau de registre de langue
et n&#8217;&#233;crivant pas non plus dans un langage fortement rigoureux. Deux constats peuvent &#234;tre faits. D&#8217;une
part, la taille des repr&#233;sentations est petite. Chaque texte n&#8217;exprime que peu d&#8217;id&#233;es / opinions, rarement
r&#233;p&#233;t&#233;es dans un m&#234;me texte. D&#8217;autre part, il n&#8217;est pas rare de trouver des fautes d&#8217;orthographe ou des
abr&#233;viations. Si celles-ci portent sur l&#8217;opinion du message, il est peu probable que l&#8217;on puisse r&#233;cup&#233;rer
l&#8217;information compl&#232;te a posteriori d&#8217;apr&#232;s le premier constat.
</p>
<p>1.2 Les repr&#233;sentations
</p>
<p>Deux grands types de repr&#233;sentations de la s&#233;mantique d&#8217;un texte existent. Les &#171;repr&#233;sentations expli-
cites&#187;, dont les graphes s&#233;mantiques sont un exemple (Rastier, 1989) (Sowa, 1984), prennent en compte
les liens s&#233;mantiques existants entre les mots du texte(&#171;s&#233;mantique des mots&#187;). Elles permettent d&#8217;obtenir
une pr&#233;cision importante mais ne sont pas ais&#233;es &#224; construire. Les &#171;repr&#233;sentations implicites&#187; repr&#233;sentent
la s&#233;mantique en utilisant un ensemble de variables bool&#233;ennes. Elles ne permettent pas de repr&#233;senter la
s&#233;mantique des mots mais offrent une m&#233;trique simple de comparaison entre les repr&#233;sentations (&#171;distance
s&#233;mantique&#187;) par comparaisons bool&#233;ennes. Cette distance peut ensuite &#234;tre utilis&#233;e par les algorithmes
de regroupements pour rapprocher les donn&#233;es. La repr&#233;sentation vectorielle standard est un exemple de
repr&#233;sentation implicite : elle utilise comme variables bool&#233;ennes, la pr&#233;sence ou l&#8217;absence des mots des
textes (&#171;vecteurs de mots&#187; (Salton et al., 1975)). Cette repr&#233;sentation a fait l&#8217;objet de nombreuses &#233;tudes
et est souvent utilis&#233;e en corr&#233;lation avec des m&#233;thodes statistiques tels que Hyperspace Analogue to
Language (HAL) (Lund et al., 1995) ou Latent Semantic Analysis (LSA) (Deerwester et al., 1990) pour
permettre la repr&#233;sentation de la s&#233;mantique des mots. Il est &#233;galement courant d&#8217;utiliser des m&#233;thodes de
pond&#233;ration afin de mesurer la quantit&#233; d&#8217;information apport&#233;e au texte par chaque mot (&#171;pertinence des
mots&#187;). Cette information va nous servir &#224; identifier les mots les plus propices aux rapprochements.
</p>
<p>CRIL 2</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>REPR&#201;SENTATION VECTORIELLE DE TEXTES COURTS D&#8217;OPINIONS
</p>
<p>L&#8217;utilisation de tous les mots des textes engendre une taille de repr&#233;sentation consid&#233;rable, difficile &#224; trai-
ter. Il est courant d&#8217;effectuer des traitements s&#233;mantiques visant &#224; la simplifier en regroupant ou supprimant
certaines composantes des vecteurs. Cette simplification des descripteurs a un impact sur la qualit&#233; finale
du traitement : si les textes ne sont pas correctement repr&#233;sent&#233;s, il est peu vraisemblable que le r&#233;sultat
obtenu soit probant car la repr&#233;sentation ne refl&#233;tera pas le sens du texte. Certains chercheurs pr&#233;conisent
de ne pas syst&#233;matiquement employer ces m&#233;thodes de simplification mais au contraire de r&#233;fl&#233;chir &#224; leur
pertinence et au fait que des mots supprim&#233;s traditionnellement des repr&#233;sentations peuvent &#234;tre primor-
diaux pour des traitements proches de la s&#233;mantique (Riloff, 1995).
</p>
<p>1.3 Pond&#233;ration et distance s&#233;mantique des mots
</p>
<p>La pond&#233;ration vise &#224; accorder plus d&#8217;importance &#224; certaines variables bool&#233;ennes, &#224; en p&#233;naliser d&#8217;autres
en allant jusqu&#8217;&#224; les retirer (&#233;quivalent &#224; une pond&#233;ration nulle) et s&#8217;oppose &#224; l&#8217;&#233;qui-importance qui consi-
d&#232;re que tous les mots apportent la m&#234;me quantit&#233; d&#8217;information. Utiliser une pond&#233;ration est particuli&#232;re-
ment int&#233;ressant en clustering pour distinguer les mots v&#233;hiculant beaucoup d&#8217;informations, de ceux n&#8217;en
apportant que peu. Deux types d&#8217;approches existent. Les premi&#232;res, m&#233;thodes statistiques, se basent sur
les occurrences des mots dans le corpus pour d&#233;terminer l&#8217;importance des mots en contexte. La formule
&#8220;term frequency, inverse document frequency&#8221; (TF.IDF) (Sparck Jones, 1972) en est un exemple. Dans le
cadre de regroupements, un mot qui appara&#238;t dans la majorit&#233; des textes n&#8217;est pas assez discriminant et
conduit &#224; rapprocher trop de textes. Un mot apparaissant tr&#232;s rarement conduit &#224; en rapprocher trop peu
sur des id&#233;es peu repr&#233;sentatives. Les deuxi&#232;mes, m&#233;thodes linguistiques, consistent &#224; &#233;tablir une liste
des mots &#224; &#233;liminer, consid&#233;r&#233;e comme peu &#233;volutive et de taille raisonnable (Salton et al., 1975) (Salem,
1987). Le contenu et la longueur de cette liste (&#171;black list&#187;, &#171;stop list&#187; ou &#171;liste noire&#187;) sont diff&#233;rents
en fonction de la nature du traitement. Quelle que soit l&#8217;approche retenue, la suppression &#224; ce stade d&#8217;un
descripteur important pour le corpus est d&#233;finitive et provoque une d&#233;gradation sensible des r&#233;sultats.
</p>
<p>Dans notre contexte, les opinions &#233;tant rarement r&#233;p&#233;t&#233;es, il est important de faire attention &#224; ne pas
supprimer de mots utiles pour &#233;viter les pertes d&#8217;informations. Utiliser une liste noire pour supprimer les
mots inutiles permet le contr&#244;le des mots retir&#233;s sous r&#233;serve de ne pas y inclure de mots qui pourraient &#234;tre
informatifs. Consid&#233;rer les autres mots comme &#233;qui-importants ne semble pas &#234;tre une solution efficace car
ceux qui v&#233;hiculent le plus par leur pr&#233;sence le sens global des textes sont plus importants que les autres.
Utiliser une technique statistique de pond&#233;ration semble donc judicieux. La formule du TF.IDF n&#8217;est pas
appropri&#233;e car sa pertinence repose sur l&#8217;hypoth&#232;se de r&#233;p&#233;tition des sens importants dans un texte, peu
v&#233;rifi&#233;e si les textes sont tr&#232;s courts. De m&#234;me, l&#8217;IDF seul privil&#233;gie les mots tr&#232;s rares. Utile dans un cadre
de recherche de termes discriminants, cela a pour effet dans notre cas de provoquer des rapprochements
sur des mots issus du niveau de langage du r&#233;pondant plus que sur les id&#233;es exprim&#233;es. On peut par contre
&#233;mettre l&#8217;hypoth&#232;se que l&#8217;importance des mots pour les textes est &#233;quivalente &#224; l&#8217;importance des mots
pour l&#8217;ensemble des textes. Nous proposons d&#8217;utiliser l&#8217;entropie de Shannon appliqu&#233;e sur l&#8217;ensemble des
</p>
<p>Analyse s&#233;mantique
par des m&#233;thodes linguistiques et statistiques
</p>
<p>Clustering ou Regroupements
</p>
<p>Textes courts
d&#8217;opinions
</p>
<p>Repr&#233;sentations 
vectorielles des textes
</p>
<p>Groupes ou 
clusters d&#8217;opinions
</p>
<p>FIG. 1 &#8211; Notre processus de traitement
</p>
<p>ONYME SARL 3</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>RECITAL 2010, Montr&#233;al, 19-23 juillet 2010 Beno&#238;t Trouvilliez
</p>
<p>documents (formule 1) pour que les mots ayant une probabilit&#233; d&#8217;apparition moyenne dans l&#8217;ensemble du
corpus soient privil&#233;gi&#233;s.
</p>
<p>Imot = &#8722;(Pmot &#8727; log(Pmot)) , avec Pmot = Occmot
Nbmots
</p>
<p>(1)
</p>
<p>Dans (1), Imot, Pmot etOccmot repr&#233;sentent l&#8217;importance, la probabilit&#233; d&#8217;apparition et l&#8217;occurrence du mot
dans le corpus, et Nbmots, le nombre de mots au total dans le corpus. Deux mots s&#233;mantiquement proches
devraient obtenir des notes qui refl&#232;tent leurs liens. Pour cela, il est courant d&#8217;associer &#224; la repr&#233;senta-
tion vectorielle des m&#233;thodes permettant d&#8217;identifier les liens s&#233;mantiques entre les mots du corpus. Une
fois encore, les m&#233;thodes sont soit statistiques (HAL, LSA) soit linguistiques (utilisation de ressources tels
qu&#8217;un th&#233;saurus ou une ontologie). Nous proposons d&#8217;utiliser une m&#233;thode linguistique bas&#233;e sur une onto-
logie. La plus connue est le Wordnet de Princeton (Miller, 1995), cr&#233;&#233; pour la langue anglaise et fondateur
des &#171;Wordnets&#187; : ressources aux caract&#233;ristiques similaires, d&#233;velopp&#233;es pour plus de 70 langues et list&#233;es
par la &#171;Global Wordnet Association&#187;1. Chaque unit&#233; de sens de la langue est repr&#233;sent&#233;e par un groupe de
mots porteur de ce sens appel&#233; synset. Des liens s&#233;mantiques tels que l&#8217;antonymie, l&#8217;hyp&#233;ronymie ou l&#8217;hy-
ponymie sont d&#233;finis entre les synsets. Pour le fran&#231;ais, on trouve le Wordnet Libre du Fran&#231;ais (WOLF)
(Sagot &amp; Fi&#353;er, 2008), utilis&#233; pour nos tests, et le projet francophone EuroWordnet (Vossen, 1998). Le
probl&#232;me majeur est alors la polys&#233;mie des mots car si l&#8217;ontologie fournit l&#8217;ensemble des sens du mot et
les liens existants pour chacun d&#8217;eux, il est difficile de d&#233;terminer lequel est employ&#233;. Dans le cadre de
textes longs, la r&#233;p&#233;tition du sens employ&#233; dans le texte peut aider &#224; l&#8217;identifier, fait non v&#233;rifi&#233; dans des
textes courts. Nous avons donc opt&#233; pour une m&#233;thode qui calcule la probabilit&#233; d&#8217;apparition d&#8217;un mot t
comme la somme des probabilit&#233;s d&#8217;apparition des mots i partageant un de leurs sens en commun avec le
mot t (formule 2).
</p>
<p>Imot/sens = &#8722;(Pmot/sens &#8727; log(Pmot/sens)) , avec Pmot/sens =
&#8721;
</p>
<p>i&#8712;Synmot
Pi , et Synmot =
</p>
<p>&#8899;
mot&#8712;s
</p>
<p>s (2)
</p>
<p>Dans (2), Imot/sens et Pmot/sens repr&#233;sentent l&#8217;importance et la probabilit&#233; d&#8217;apparition d&#8217;un mot selon
la repr&#233;sentativit&#233; de ses sens dans le corpus, i, un mot de l&#8217;ontologie, s, un synset de l&#8217;ontologie et Pi,
la probabilit&#233; d&#8217;apparition du mot i calcul&#233;e selon la sous-formule Pmot de la formule (1). La formule
2 a pour propri&#233;t&#233;s essentielles de provoquer la maximisation des probabilit&#233;s d&#8217;apparition des mots en
consid&#233;rant chaque mot potentiellement porteur du sens comme porteur et de ne pas requ&#233;rir de d&#233;sambi-
guisation au pr&#233;alable des sens des mots. Cette strat&#233;gie, peu justifi&#233;e dans un contexte pluri th&#233;matique,
l&#8217;est dans notre cas car la probabilit&#233; d&#8217;emploi polys&#233;mique d&#8217;un terme au sein des textes du corpus se
trouve consid&#233;rablement r&#233;duite en l&#8217;absence de th&#232;mes multiples.
</p>
<p>Le tableau 1 montre les mots identifi&#233;s comme les plus importants dans deux corpus de textes diff&#233;rents
selon cette m&#233;thode, mots propices aux regroupements d&#8217;opinions (ouverture de magasins, progression du
chiffre d&#8217;affaire, formation &#224; l&#8217;anglais, favoriser la mobilit&#233;, d&#233;velopper les connaissances culturelles, ...).
Les mots &#171;am&#233;liorer&#187; et &#171;promouvoir&#187; ont re&#231;u une note identique gr&#226;ce &#224; la d&#233;tection d&#8217;une proximit&#233;
s&#233;mantique dans leurs sens. Nous expliciterons ensuite les effets sur le clustering de ces pond&#233;rations.
</p>
<p>L&#8217;ontologie permet &#233;galement de tenir compte de la distance s&#233;mantique entre les mots lors des regrou-
pements. En l&#8217;absence de th&#232;mes multiples, nous consid&#233;rons que deux mots sont s&#233;mantiquement li&#233;s si
l&#8217;ontologie conna&#238;t un sens &#224; ces mots partageant un lien. Dans le cas, o&#249; plusieurs liens pourraient &#234;tre
trouv&#233;s, le lien le plus fort est retenu. A savoir, par ordre d&#233;croissant d&#8217;importance, la synonymie forte,
</p>
<p>1r&#233;f&#233;rence : http ://www.globalwordnet.org
</p>
<p>CRIL 4</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>REPR&#201;SENTATION VECTORIELLE DE TEXTES COURTS D&#8217;OPINIONS
</p>
<p>la synonymie faible, l&#8217;hyp&#233;ronymie et la fratrie par hyp&#233;ronymie commune (formule 3). Ce raisonnement
poss&#232;de les m&#234;mes propri&#233;t&#233;s que celles &#233;voqu&#233;es pour la pond&#233;ration : maximisation de la probabilit&#233;
d&#8217;identification d&#8217;un lien s&#233;mantique et non d&#233;sambiguisation du contexte.
</p>
<p>D(i, j) = min
i&#8712;s,j&#8712;s&#8242;
</p>
<p>(d(s, s&#8242;)) (3)
</p>
<p>Dans (3), i et j repr&#233;sentent deux mots du corpus, D(i, j), la distance s&#233;mantique entre i et j, s et s&#8242;, deux
synsets de l&#8217;ontologie distincts ou non et d(s, s&#8242;), la distance entre s et s&#8242; selon l&#8217;ontologie.
</p>
<p>1.4 Repr&#233;sentation de la n&#233;gation
</p>
<p>La repr&#233;sentation de la n&#233;gation est un probl&#232;me &#224; cause notamment des formes multiples qu&#8217;elle peut
prendre, simples (ne...pas, ne...plus, ... ) ou complexes (double n&#233;gation souvent par antonymie), et de sa
&#171;port&#233;e&#187; dans le texte (sur une ou plusieurs phrases ou parties de phrases). Cette liste n&#8217;est pas exhaustive
mais illustre bien les probl&#232;mes rencontr&#233;s. Alors que les chercheurs travaillant sur l&#8217;identification de
la th&#233;matique des textes n&#8217;effectuent aucun traitement particulier et se contentent de traiter les mots de
la n&#233;gation comme des mots ordinaires voire de les inclure &#224; la liste noire, d&#8217;autres, travaillant sur la
s&#233;mantique pr&#233;conisent une diff&#233;renciation entre les phrases selon que l&#8217;id&#233;e exprim&#233;e est ni&#233;e ou non
(Poirier et al., 2008). Traiter la n&#233;gation en particulier, n&#233;cessite de se confronter au probl&#232;me de sa
port&#233;e. Comme les textes sont tr&#232;s courts, nous pouvons poser l&#8217;hypoth&#232;se que la n&#233;gation, si elle existe,
peut &#234;tre appliqu&#233;e sur l&#8217;ensemble du texte sans en d&#233;grader le sens (Poirier et al., 2008). Cela n&#8217;est bien
s&#251;r pas v&#233;rifi&#233; dans des textes complexes (phrases avec conjonctions, ...).
</p>
<p>Afin de valider ces consid&#233;rations, des tests ont &#233;t&#233; r&#233;alis&#233;s sur un jeu d&#8217;essai comportant deux sortes de
messages : des messages affirmant aimer les chats et des messages niant aimer les chats. Ils ont consist&#233; &#224;
effectuer des regroupements en consid&#233;rant successivement les marques de la n&#233;gation comme appartenant
&#224; la liste noire, comme des mots ordinaires pour lesquels aucun traitement n&#8217;est &#224; faire et enfin comme
des mots discriminants permettant de marquer les messages avec une valeur affirm&#233;e ou ni&#233;e. Dans ce
</p>
<p>R&#233;sultat sur le jeu &#171;r&#233;ussite de l&#8217;enseigne TrucMuche&#187;
mot Isens mot Isens mot Isens mot Isens
</p>
<p>magasin/s 0.1535 international/e 0.1357 chiffre d affaire 0.1315 expansion 0.1248
ouverture/s 0.1519 pr&#233;f&#233;r&#233;e 0.1357 progresse 0.1315 com 0.1248
france/&#231;ais 0.1415 TrucMuche 0.1357 formation/s 0.1315 vendus/ues 0.1224
client/s/e/es 0.1396 augmentation/s 0.1336 d&#233;veloppement/s 0.1294
</p>
<p>enseigne 0.1377 nombre/s 0.1315 volume/s 0.1271
R&#233;sultat sur le jeu des &#171;choix strat&#233;giques&#187;
</p>
<p>mot Isens mot Isens mot Isens mot Isens
</p>
<p>formation/s 0.1668 international/ale/ales/aux 0.1489 communication/s 0.1296 inter 0.1186
anglais/se 0.1591 &#233;change/s 0.1441 connaissance/s 0.1254
mobilit&#233;/s 0.1591 langue/s 0.1372 diff&#233;rents/tes/ces 0.1254
favoriser 0.1563 sites 0.1372 personnel/s 0.1232
</p>
<p>d&#233;velopper/ement 0.1519 &#233;tranger/ers/&#232;res 0.1354 am&#233;liorer 0.1186
culture/es/el/elle/els/elles 0.1316 promouvoir 0.1186
</p>
<p>TAB. 1 &#8211; Extraits de l&#8217;importance des mots avec l&#8217;entropie de Shannon appliqu&#233;e sur les sens
</p>
<p>ONYME SARL 5</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>RECITAL 2010, Montr&#233;al, 19-23 juillet 2010 Beno&#238;t Trouvilliez
</p>
<p>dernier cas, les marques de la n&#233;gation et antonymes sont retir&#233;s. Puis, les messages sont marqu&#233;s comme
affirm&#233;s, s&#8217;ils contenaient un nombre pair d&#8217;expressions de n&#233;gation et antonymes, et comme ni&#233;s sinon.
Dans le cas o&#249; la n&#233;gation est dans la liste noire, aucune distinction n&#8217;est faite entre les messages affirm&#233;s
et ni&#233;s. Dans le cas du non traitement de la n&#233;gation, la distinction est faite uniquement sur la pr&#233;sence
ou l&#8217;absence des mots n&#233;gatifs. Cela engendre le regroupement &#224; tort des messages contenant une double
n&#233;gation avec ceux n&#8217;en contenant qu&#8217;une simple : &#171;Rien ne me fera aimer les chats&#187; et &#171;Rien ne me fera
d&#233;tester les chats&#187;. Dans le cas du marquage, la distinction se fait sur la polarit&#233; induite aux messages
par la n&#233;gation. Cette derni&#232;re distinction est la meilleure dans notre cas puiqu&#8217;elle permet d&#8217;obtenir deux
clusters d&#8217;opinions oppos&#233;es : &#171;ceux qui aiment les chats&#187; et &#171;ceux qui n&#8217;aiment pas les chats&#187;.
</p>
<p>1.5 Lemmatisation / stemmatisation
</p>
<p>Ces m&#233;thodes identifient les mots diff&#233;rents &#224; cause des r&#232;gles syntaxiques et grammaticales mais ayant
une s&#233;mantique identique. La lemmatisation identifie la fonction grammaticale et le lemme du mot, soit &#224;
l&#8217;aide du contexte au moyen d&#8217;une d&#233;sambigu&#239;sation, solution &#233;tudi&#233;e dans cet article, soit en &#233;tablissant
une liste des diff&#233;rents lemmes possibles du mot (&#171;lemmatisation en ou hors contexte&#187;). La stemmatisation
ne r&#233;sout jamais le contexte mais identifie selon la forme et la langue utilis&#233;e, la fonction grammaticale du
mot et en d&#233;duit son radical. La lemmatisation simplifie les repr&#233;sentations de mots dont le radical varie
mais pas celles de ceux occupant une fonction grammaticale diff&#233;rente. La stemmatisation, au contraire,
est capable d&#8217;effectuer des rapprochements entre les mots occupant une fonction grammaticale diff&#233;rente
mais pas entre ceux dont le radical varie et provoque de plus un rapprochement non d&#233;sir&#233; entre les mots
s&#233;mantiquement diff&#233;rents mais ayant une racine commune.
</p>
<p>Nos choix se sont port&#233;s sur TreeTagger (Schmid, 1994), &#233;tiqueteur multilingue r&#233;alis&#233; par le laboratoire
de l&#8217;Universit&#233; de Stuttgart, pour la lemmatisation et sur Snowball, sous projet de Apache Luc&#232;ne2, pour la
stemmatisation. Ils ont &#233;t&#233; test&#233;s sur diff&#233;rents jeux de tests. Ils ne commettent pratiquement aucune erreur
en contexte orthographique correct. TreeTagger semble m&#234;me parvenir &#224; d&#233;sambigu&#239;ser correctement dans
des phrases comportant des homonymes comme le verbe &#171;porter&#187; et le nom &#171;porte&#187;. Sur un corpus mal
orthographi&#233;, les r&#233;sultats de lemmatisation s&#8217;effondrent. Aucun lemme correct n&#8217;a &#233;t&#233; identifi&#233; sur les
termes inconnus et peu de fonctions grammaticales l&#8217;ont &#233;t&#233;. Du c&#244;t&#233; de la stemmatisation, les r&#233;sultats
sur un corpus mal orthographi&#233; sont mitig&#233;s. Les mots sur lesquels la faute porte sur la partie consid&#233;r&#233;e
comme le radical n&#8217;ont pas &#233;t&#233; corrig&#233;s. De m&#234;me, certaines fautes portant sur le suffixe ont modifi&#233; le
radical retourn&#233; par Snowball (exemple : &#171;jouet&#187; donne le radical &#171;jouet&#187; alors que &#171;jouer&#187; donne le
radical &#171;jou&#187;).
</p>
<p>Ces tests sur la lemmatisation et la stemmatisation montrent que la lemmatisation est peu efficace dans un
contexte orthographique difficile. Cela est surtout un handicap si le terme affect&#233; est un terme d&#233;cisif pour
les regroupements. La stemmatisation se r&#233;v&#232;le &#234;tre une solution si la faute ne modifie pas le radical du
mot. Ces constats nous ont conduits &#224; supposer que la combinaison des deux m&#233;thodes permettrait de tirer
parti des avantages de chacune des deux strat&#233;gies : la lemmatisation permet de regrouper dans un premier
temps les mots dont le radical &#233;volue et la stemmatisation, de regrouper ensuite les diff&#233;rentes formes
grammaticales d&#8217;un m&#234;me concept tout en corrigeant &#233;ventuellement quelques fautes d&#8217;orthographe. Les
r&#233;sultats interm&#233;diaires obtenus apr&#232;s la lemmatisation sont conserv&#233;s et utilis&#233;s lors des rapprochements
s&#233;mantiques &#224; l&#8217;aide de l&#8217;ontologie. Il serait &#233;galement possible d&#8217;utiliser les statistiques ainsi obtenues
</p>
<p>2http ://lucene.apache.org/
</p>
<p>CRIL 6</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>REPR&#201;SENTATION VECTORIELLE DE TEXTES COURTS D&#8217;OPINIONS
</p>
<p>Traitements s&#233;mantiques
N&#233;gation Lemmatisation Stemmatisation Pond&#233;ration Distance s&#233;mantique des mots
</p>
<p>Ne rien faire Ne rien faire Ne rien faire Equi-pond&#233;ration simple Similitude de formes
Black List TreeTagger SnowBall Black List + Equi-pond&#233;ration Similitude de sens
</p>
<p>Tags des textes Black List + TF.IDF
Black List + Shannon avec sens
</p>
<p>Black List + Shannon
</p>
<p>TAB. 2 &#8211; Les diff&#233;rentes strat&#233;gies de traitements s&#233;mantiques
</p>
<p>pour d&#233;terminer si deux mots proches apr&#232;s stemmatisation le sont &#224; cause de leur s&#233;mantique.
</p>
<p>Dans le tableau 1, &#171;formation&#187;/&#171;formations&#187;, &#171;culturel&#187;/&#171;culturelle&#187; ont la m&#234;me importance gr&#226;ce &#224; la
lemmatisation, et &#171;culture&#187;/&#171;culturelles&#187;, &#171;expatriation&#187;/&#171;expatri&#233;s&#187; gr&#226;ce &#224; la stemmatisation.
</p>
<p>2 R&#233;sultats exp&#233;rimentaux sur les regroupements
</p>
<p>Le tableau 2 reprend les 120 combinaisons de traitements s&#233;mantiques &#233;voqu&#233;es. Parmi elles, celle sou-
lign&#233;e dans le tableau s&#8217;est d&#233;marqu&#233;e dans nos r&#233;flexions et tests par son ad&#233;quation avec nos attentes.
Une analyse des regroupements obtenus au moyen d&#8217;une m&#233;thode hi&#233;rarchique dans cette configuration
est pr&#233;sent&#233;e dans le tableau 3. Les tests, conduits sur m&#233;thode par partitions (KMeans), ont montr&#233; des
probl&#232;mes s&#233;mantiques similaires &#224; ceux &#233;voqu&#233;s ci apr&#232;s pour la m&#233;thode hi&#233;rarchique.
</p>
<p>Dans le premier extrait, les id&#233;es de &#171;r&#233;union r&#233;guli&#232;re&#187;, &#171;proximit&#233;, convivialit&#233;&#187;, &#171;f&#234;ter les succ&#232;s&#187; ont
&#233;t&#233; d&#233;tect&#233;es. L&#8217;expression &#171;mise en place&#187; a &#233;t&#233; consid&#233;r&#233;e comme une opinion au lieu des compl&#233;ments
de cette expression. Dans le deuxi&#232;me extrait, les id&#233;es &#171;d&#8217;&#233;couter et de voir&#187; aussi bien les clients que
d&#8217;autres m&#233;tiers et de &#171;voyage&#187; ont &#233;t&#233; trouv&#233;es. Cet exemple montre l&#8217;int&#233;r&#234;t d&#8217;employer des techniques
tels que la lemmatisation ou la stemmatisation : le rapprochement s&#233;mantique a ainsi pu &#234;tre fait entre
le nom &#171;voyage&#187; et le verbe &#171;voyager&#187;. Dans le troisi&#232;me extrait, &#171;projets internationaux&#187; et &#171;projets
mondiaux&#187; ont &#233;t&#233; rapproch&#233;s par la d&#233;tection de liens s&#233;mantiques entre les termes &#171;internationaux&#187;
et &#171;mondiaux&#187;. Par ailleurs, cet extrait porte sur l&#8217;un des deux jeux utilis&#233;s pour tester la pond&#233;ration.
On retrouve bien les id&#233;es faisant l&#8217;objet de la plus forte pond&#233;ration : formation &#224; l&#8217;anglais, favoriser la
mobilit&#233; et d&#233;veloppement des connaissances culturelles. Dans le dernier extrait, notre traitement de la
n&#233;gation en particulier a permis de rapprocher le message &#171;je n&#8217;ai pas eu de probl&#232;mes avec les produits&#187;
du groupe &#171;satisfaction produit&#187;. En revanche, sur des textes plus complexes, notre technique engendre
comme pr&#233;vu, des erreurs de compr&#233;hension : le message &#171;je n ai rien a dire je suis tres heureuse de ma
commande&#187; a &#233;t&#233; rapproch&#233; du groupe &#171;insatisfait commande&#187; &#224; cause de la n&#233;gation qu&#8217;il comprend
(&#171;n&#187;). &#171;mercie a vous touts&#187; a &#233;t&#233; bien class&#233;, malgr&#233; l&#8217;orthographe, en combinant la lemmatisation et la
stemmatisation, mais &#171;je crois savoir ma la respnsable du pont relais...&#187; ne l&#8217;a pas &#233;t&#233;.
</p>
<p>Une analyse statistique a &#233;t&#233; men&#233;e sur le clustering produit par cette m&#233;thode hi&#233;rarchique sur un jeu de
test cr&#233;&#233; &#224; partir de plusieurs corpus. Cette qualit&#233; a &#233;t&#233; &#233;valu&#233;e, sur l&#8217;ecart entre le nombre de groupes
attendu et produit, et sur l&#8217;homog&#233;n&#233;it&#233; de ces derniers. Chaque message est codifi&#233; manuellement se-
lon l&#8217;id&#233;e principale qu&#8217;il exprime. L&#8217;homog&#233;n&#233;it&#233; d&#8217;un cluster correspond au pourcentage de messages
codifi&#233;s avec l&#8217;id&#233;e majoritaire du cluster. Si aucune id&#233;e n&#8217;est majoritaire, le cluster est d&#233;clar&#233; comme
totalement h&#233;t&#233;rog&#232;ne. L&#8217;homog&#233;n&#233;it&#233; globale est ensuite calcul&#233;e comme la moyenne des homog&#233;n&#233;it&#233;s
</p>
<p>ONYME SARL 7</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>RECITAL 2010, Montr&#233;al, 19-23 juillet 2010 Beno&#238;t Trouvilliez
</p>
<p>Premier extrait : jeu &#171;entreprise&#187;
Titre du cluster Messages
</p>
<p>Proximit&#233;, convivialit&#233; D&#233;velopper (la proximit&#233;/la convivialit&#233;) (dans l&#8217;entreprise/avec et entre les collaborateurs)
Conventions Convention semestrielle ou annuelle / Convention : r&#233;union de tous les collaborateurs
Groupes de projets (Travailler en/Cr&#233;er des groupes de) projets transversaux / Favoriser les groupes de projets
Mettre en place Mettre en place (des groupes de travail transversaux/des objectifs) / Solliciter des volontaires pour
</p>
<p>mettre en place des groupes de travail transversaux suivis et reconnus par le manager / Mise en place
(d&#8217;outils de mesure pr&#233;cise de r&#233;alisation des objectifs/de r&#233;unions r&#233;guli&#232;res d&#8217;information)
</p>
<p>F&#234;ter les succ&#232;s Savoir f&#234;ter les succ&#232;s / Cr&#233;er des &#233;v&#233;nements r&#233;guliers et varies f&#234;ter les succ&#232;s
Deuxi&#232;me extrait : jeu &#171;relationnel&#187;
</p>
<p>Titre du cluster Messages
Ecouter, observer Je regarde et j&#8217;&#233;coute mes clients / (Ecouter/Etre &#224; l&#8217;&#233;coute/Faire parler/R&#234;ver pour) les clients, les
</p>
<p>fournisseurs / Rester connect&#233; avec le client et la r&#233;alit&#233; du terrain / Ecouter son instinct / Je vais voir
autre chose dans d&#8217;autres m&#233;tiers
</p>
<p>Moins d&#8217;op&#233;rationnel (Pouvoir se d&#233;gager/Je me d&#233;gage) de l&#8217;op&#233;rationnel / Susciter un contre pouvoir non op&#233;rationnel
Veille Se tenir inform&#233; du march&#233; (visite clients, veille) / Je visite mes clients / S&#8217;informer, reste en veille
Voyager Je voyage / Voyager, s&#8217;ouvrir au monde / Voyages en interne, &#233;changes avec ses &#233;quipes
</p>
<p>Troisi&#232;me extrait : jeu &#171;choix strat&#233;giques&#187;
Titre du cluster Messages
</p>
<p>Projets internationaux Faire des projets internationaux / D&#233;velopper une culture mondiale &#224; l&#8217;occasion de projet
Diff&#233;rences culturelles (Sensibilisation/Sensibiliser le personnel) aux diff&#233;rences culturelles
Connaissance culturelle D&#233;velopper la connaissance des (cultures de nos clients/diff&#233;rentes &#8220;cultures business&#8221;/cultures lo-
</p>
<p>cales/des cultures des autres pays/diff&#233;rents sites) / Se former &#224; la culture
Ouverture international (D&#233;velopper les/Promouvoir l&#8217;exercice des) langues &#233;trang&#232;res / D&#233;velopper la ma&#238;trise de la langue
</p>
<p>anglaise / Apprendre l&#8217;anglais / Favoriser l&#8217;internationalisation des recrutements
Mobilit&#233; D&#233;velopper (la mobilit&#233;/la mobilit&#233; internationale (dans les 2 sens))
</p>
<p>Quatri&#232;me extrait : jeu &#171;commande internet&#187;
Titre du cluster Messages
</p>
<p>Satisfait produits comme d&#8217;habitude je n&#8217;ai pas eu de probl&#232;me avec les produits / J&#8217;ai &#233;t&#233; ravie par ma commande et
surtout la rapidit&#233; et le s&#233;rieux de l&#8217;envoi. / je suis contente de vos colis / Rien &#224; dire tout est parfait ! !
/ Frais de livraison un peu &#233;lev&#233;s je trouve. Les produits sont conformes et de bonne qualit&#233; pour le
prix. / Je suis tr&#232;s contente / mercie a vous touts
</p>
<p>Insatisfait commande commande soit disant livr&#233;e en 48 heures mais livraison seulement apr&#232;s relance le 24/12 &#231;a fait un
peu long heureusement qu&#8217;il n&#8217;y avair pas d&#8217;&#233;change &#224; faire / J&#8217;ai pass&#233; commande le 12/12 et je
n&#8217;ai pu r&#233;cup&#233;rer ma commande au relais que le 21/12 au lieu de 48h apr&#232;s car il &#233;tait livr&#233; mais pas
enregistr&#233;. / Annonce par mail commande livr&#233;e au point relai et quand je suis all&#233;e la chercher elle
n&#8217;&#233;tait pas l&#224;. / &#224; ce jour je n&#8217;ai toujours pas ma commande. / aucun suivi de cette commande. / je n ai
rien a dire je suis tres heureuse de ma commande
</p>
<p>Non class&#233; je crois savoir ma la respnsable du pont relais queles livraisons ne sont effectu&#233;es que 2 fois par
semaine ce qui repousse le d&#233;lai de 48h pr&#233;vu. Que popuvez-vous faire pour rem&#233;dier &#224; ce soucis ? ?
</p>
<p>TAB. 3 &#8211; Extraits de regroupements sur quatre jeux de tests
</p>
<p>de chaque cluster pond&#233;r&#233;e selon le nombre de messages qu&#8217;il contient. Les deux crit&#232;res &#233;tant compl&#233;-
mentaires, on consid&#233;rera un r&#233;sultat meilleur qu&#8217;un autre s&#8217;il l&#8217;est sur l&#8217;un des crit&#232;res et est au moins
aussi bon sur l&#8217;autre. On admettra par ailleurs de mani&#232;re non formelle qu&#8217;un r&#233;sultat n&#8217;est plus vraiment
acceptable en dessous d&#8217;une homog&#233;n&#233;it&#233; moyenne de 30% et au del&#224; d&#8217;un &#233;cart total de 20 rangs ainsi
que le fait qu&#8217;un gain de 3 rangs sur le crit&#232;re d&#8217;&#233;cart permet de compenser une perte moyenne de 10% sur
</p>
<p>CRIL 8</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>REPR&#201;SENTATION VECTORIELLE DE TEXTES COURTS D&#8217;OPINIONS
</p>
<p>le crit&#232;re d&#8217;homog&#233;n&#233;it&#233;. Nous avons pris comme r&#233;f&#233;rence la combinaison mise en &#233;vidence pr&#233;c&#233;dem-
ment (&#171;solution avec tous les traitements&#187;), puis nous l&#8217;avons compar&#233;e avec quelques autres proches en
terme de traitements (Fig. 2).
</p>
<p>La solution de r&#233;f&#233;rence obtient un bon r&#233;sultat mais les autres traitements de la n&#233;gation (en liste noire
et sans traitement) semblent meilleurs, le traitement en liste noire l&#8217;&#233;tant davantage que la solution sans
traitement. Parmi les messages comportant une n&#233;gation dans ce jeu, seul 44% r&#233;pondent aux crit&#232;res de
complexit&#233; &#233;voqu&#233;s. Cela illustre la faible pertinence de cette solution en pr&#233;sence de messages complexes.
Il est &#233;galement int&#233;ressant de souligner que toutes les solutions ont produit un nombre de clusters plus
&#233;lev&#233; que celui attendu. Nos solutions n&#8217;arriveraient donc pas &#224; regrouper les id&#233;es autant qu&#8217;un expert.
Ce test met &#233;galement en &#233;vidence la tr&#232;s forte pertinence de la liste noire et de la distance s&#233;mantique des
mots calcul&#233;e selon les sens. Tous les tests r&#233;alis&#233;s contradictoirement obtiennent des r&#233;sultats nettement
inf&#233;rieurs. La pond&#233;ration des sens semble meilleure que la pond&#233;ration des mots car elle permet de pro-
duire moins de groupes m&#234;me s&#8217;ils semblent l&#233;g&#232;rement moins homog&#232;nes. L&#8217;emploi de la lemmatisation
ou de la stemmatisation semble indispensable sous peine de produire un nombre de clusters trop &#233;lev&#233;. La
lemmatisation se r&#233;v&#232;le toutefois plus efficace que la stemmatisation et de qualit&#233; presque &#233;gale voire l&#233;-
g&#233;rement sup&#233;rieure &#224; la combinaison des deux m&#233;thodes. Ce constat tend &#224; prouver que la stemmatisation
peut d&#233;grader les r&#233;sultats par rapprochements de mots ayant seulement une racine commune.
</p>
<p>20
25
30
35
40
45
50
55
60
</p>
<p>0 5 10 15 20H
om
</p>
<p>og
&#233;n
</p>
<p>&#233;i
t&#233;
</p>
<p>de
s
</p>
<p>cl
us
</p>
<p>te
rs
</p>
<p>en
po
</p>
<p>ur
ce
</p>
<p>nt
ag
</p>
<p>e
</p>
<p>Ecart par rapport au nombre de clusters attendu
</p>
<p>Tous les traitements
</p>
<p>&#8869;
</p>
<p>&#8869;
Sans lemmatisation
</p>
<p>+
</p>
<p>+
Sans stemmatisation &#8704;&#8704;Ni lemmatisation, ni stemmatisation &#215;&#215;Sans traitement de la n&#233;gation
</p>
<p>4
</p>
<p>4
N&#233;gation en black list
</p>
<p>?
</p>
<p>?
Pond&#233;ration des mots
</p>
<p>&gt;
</p>
<p>&gt;
Sans black list
</p>
<p>&#8734;
</p>
<p>&#8734;
Pond&#233;ration des mots sans black list
</p>
<p>]
</p>
<p>]
Similitude de forme des mots
</p>
<p>b
</p>
<p>b
</p>
<p>FIG. 2 &#8211; R&#233;sultats statistiques de diff&#233;rentes m&#233;thodes
</p>
<p>Symbole Ecart Homog&#233;n&#233;it&#233;
] 2 20,12
&#8734; 4 19,94
&#8869; 15 45,62
? 15 55,15
4 16 53,94
&#8704; 17 50,91
+ 18 46,83
&gt; 18 49,1
&#215; 19 48,92
b 20 47,83
</p>
<p>3 Conclusion
</p>
<p>Nous avons &#233;tudi&#233; le regroupement de textes courts d&#8217;opinions. Dans ce cadre, La repr&#233;sentation vecto-
rielle se r&#233;v&#233;le pertinente car elle fournit une distance s&#233;mantique simple &#224; calculer et la possibilit&#233; d&#8217;y
adjoindre un syst&#232;me de pond&#233;ration favorisant les dimensions les plus int&#233;ressantes pour les rapproche-
ments. L&#8217;entropie de Shannon donne de bons r&#233;sultats pour le calcul de ces poids surtout apr&#232;s la prise en
compte de la s&#233;mantique des mots &#224; l&#8217;aide d&#8217;une ontologie et sans avoir recours &#224; une d&#233;sambiguisation
du corpus. La recherche de marques de n&#233;gation en vue d&#8217;un marquage des messages dans leur int&#233;gralit&#233;
comme ni&#233;es ou affirm&#233;es nous permet d&#8217;obtenir g&#233;n&#233;ralement de meilleurs r&#233;sultats sur les regroupe-
ments que les autres solutions envisag&#233;es dans le cadre de textes tr&#232;s courts. A l&#8217;inverse, cette m&#233;thode
</p>
<p>ONYME SARL 9</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>RECITAL 2010, Montr&#233;al, 19-23 juillet 2010 Beno&#238;t Trouvilliez
</p>
<p>se r&#233;v&#232;le &#234;tre m&#233;diocre dans un cadre contraire. Enfin, la lemmatisation se r&#233;v&#233;le tr&#232;s peu efficace dans
un contexte orthographique difficile. Ce constat n&#8217;est p&#233;nalisant dans notre application que si les fautes
portent sur l&#8217;opinion &#233;voqu&#233;e. La stemmatisation des formes lemmatis&#233;es permet de les corriger dans le
cas o&#249; le radical n&#8217;est pas affect&#233;. Les axes de travaux futurs concernent la mise en place d&#8217;une correction
orthographique automatique du corpus avant le traitement et une r&#233;flexion plus approfondie sur la gestion
des messages complexes comportant plusieurs id&#233;es.
</p>
<p>Remerciements
</p>
<p>Je remercie messieurs Pierre Marquis et Vincent Dubois, directeur et co-encadrant de th&#232;se, et messieurs
Antoine Serniclay et Thibaud Vibes, responsables d&#8217;Onyme, pour leurs conseils dans mes recherches.
</p>
<p>R&#233;f&#233;rences
</p>
<p>DEERWESTER S., DUMAIS S., FURNAS G., LANDAUER T. &amp; HARSHMAN R. (1990). Indexing by
latent semantic analysis. Journal of the American society for information science, 41(6), 391&#8211;407.
LUND K., BURGESS C. &amp; ATCHLEY R. (1995). Semantic and associative priming in high-dimensional
semantic space. In Proceedings of the 17th annual conference of the Cognitive Science Society, vo-
lume 17, p. 660&#8211;665.
</p>
<p>MILLER G. (1995). Wordnet : a lexical database for english. Communications of the ACM, 38(11), 41.
POIRIER D., BOTHOREL C., GUIMIER DE NEEF E. &amp; BOULL&#201; M. (2008). Automating opinion ana-
lysis in film reviews : the case of statistic versus linguistic approach. In Proceedings of the LREC 2008
Workshop on Sentiment Analysis : Emotion, Metaphor, Ontology and Terminology, p. 94&#8211;101.
</p>
<p>RASTIER F. (1989). Sens et textualit&#233;. Paris, Hachette.
</p>
<p>RILOFF E. (1995). Little words can make a big difference for text classification. In Proceedings of the
18th annual international ACM SIGIR conference on Research and development in information retrieval,
p. 130&#8211;136 : ACM New York, NY, USA.
</p>
<p>SAGOT B. &amp; FI&#352;ER D. (2008). Construction d&#8217;un wordnet libre du fran&#231;ais &#224; partir de ressources
multilingues. In Proceedings of TALN 2008.
</p>
<p>SALEM A. (1987). Pratique des segments r&#233;p&#233;t&#233;s : essai de statistique textuelle. Klincksieck.
</p>
<p>SALTON G., WONG A. &amp; YANG C. (1975). A vector space model for automatic indexing. Communi-
cations of the ACM, 18(11), 620.
SCHMID H. (1994). Probabilistic part-of-speech tagging using decision trees. In Proceedings of Inter-
national Conference on New Methods in Language Processing, volume 12 : Manchester, UK.
</p>
<p>SOWA J. (1984). Conceptual structures. Addison-Wesley Reading, MA.
</p>
<p>SPARCK JONES K. (1972). A statistical interpretation of term specificity and its application in retrieval.
Journal of Documentation, 28(1), 11&#8211;20.
VOSSEN P. (1998). Eurowordnet a multilingual database with lexical semantic networks. Computational
Linguistics, 25(4).
</p>
<p>CRIL 10</p>

</div></div>
</body></html>