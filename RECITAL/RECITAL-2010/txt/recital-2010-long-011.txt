RECITAL 2010, Montreal, 19-23 ju1'11et 201 0

Representation vectorielle de textes courts d’opinions
Analyse de traitements sémantiques pour la fouille d’opinions par clustering

Benoit TrouVilliez1*2
(1) Centre de Recherche en Informatique de Lens, Université d’Artois, Rue Jean
Souvraz, 62300 Lens, France
(2) Onyme SARL, 165 Avenue de Bretagne, 59000 Lille, France
btrouvilliez @ onyme.com, benoit.trouVilliez @ gmail.com

Résllmé. Avec le developpement d’internet et des sites d’echanges (forums, blogs, sondages en
ligne, ...), l’exploitation de nouvelles sources d’informations dans le but d’en extraire des opinions sur
des sujets precis (ﬁlm, commerce,...) devient possible. Dans ce papier, nous presentons une approche de
fouille d’opinions a partir de textes courts. Nous expliquons notamment en quoi notre choix d’utilisation
de regroupements autour des idees exprimees nous a conduit 51 opter pour une representation implicite telle
que la representation vectorielle. Nous voyons egalement les differents traitements semantiques integres a
notre chaine de traitement (traitement de la negation, lemmatisation, stemmatisation, synonymie ou meme
polysemie des mots) et discutons leur impact sur la qualite des regroupements obtenus.

Abstract. With the internet and sharing web sites developement (forums, blogs, online surveys,
...), new data source exploitation in order to extract opinions about various subjects (ﬁlm, business, ...)
becomes possible. In this paper, we show an opinion mining approach from short texts. We explain how
our choice of using opinions clustering have conducted us to use an implicit representation like vectorial
representation. We present different semantic process that we have incorporated into our process chain
(negation process, lemmatisation, stemmatisation, synonymy or polysemy) and we discut their impact on
the cluster quality.

M0tS-CléS I representation des textes, representation vectorielle, traitement de textes courts, regrou-
pements d’opinions.

Keywords: text representation, vectorial representation, short text processing, opinion clustering.

ONYME SARL 1

RECITAL 2010, Montreal, 19-23 juillet 2010 Benoit Trouvilliez

Introduction

Avec le developpement d’internet, on observe la croissance de nouvelles sources d’informations reﬂetant
des opinions sur des sujets varies : un ﬁlm, une actualite, les valeurs d’une entreprise, les prestations
d’un commergant, un site internet,  Ces sources prennent des formes diverses telles que des sites com-
munautaires (forums, blogs) ou des sites de sondages en ligne. Les textes sont assez courts et depassent
rarement 4 phrases. Dans ce contexte, plusieurs strategies d’extractions d’opinions («fouilles d’opinions»
ou «Opinion Mining») ont vu le jour. Alors que certains travaux visent a une analyse de sentiments aﬁn de
determiner si les auteurs sont plutot favorables ou defavorables au sujet en question (Poirier et al., 2008),
nous nous interessons a la problematique du regroupement aﬁn d’extraire les principales idees develop-
pees. Nous faisons appel a deux techniques differentes : des methodes d’analyse semantique qui extraient
l’information des textes dans un modele («representation de textes») et des methodes de regroupements
non supervises («clusterings») qui transforment cette information en groupes d’opinions (Fig. 1).

1 Representation et traitements sémantiques

1.1 Généralités et constats

Les textes que nous avons a traiter ont une taille moyenne de deux phrases excedant rarement 5 mots
chacune. Ils reﬂetent des opinions d’auteurs differents, n’utilisant pas le meme niveau de registre de langue
et n’ecrivant pas non plus dans un langage fortement rigoureux. Deux constats peuvent etre faits. D’une
part, la taille des representations est petite. Chaque texte n’exprime que peu d’idees / opinions, rarement
repetees dans un meme texte. D’autre part, il n’est pas rare de trouver des fautes d’orthographe ou des
abreviations. Si celles-ci portent sur l’opinion du message, il est peu probable que l’on puisse recuperer
l’information complete a posteriori d’apres le premier constat.

1.2 Les representations

Deux grands types de representations de la semantique d’un texte existent. Les «representations expli-
cites», dont les graphes semantiques sont un exemple (Rastier, 1989) (Sowa, 1984), prennent en compte
les liens semantiques existants entre les mots du texte(«semantique des mots»). Elles perInettent d’obtenir
une precision importante mais ne sont pas aisees a construire. Les «representations implicites» representent
la semantique en utilisant un ensemble de variables booleennes. Elles ne permettent pas de representer la
semantique des mots mais offrent une metrique simple de comparaison entre les representations («distance
semantique») par comparaisons booleennes. Cette distance peut ensuite étre utilisee par les algorithmes
de regroupements pour rapprocher les donnees. La representation vectorielle standard est un exemple de
representation implicite : elle utilise comme variables booleennes, la presence ou l’absence des mots des
textes («vecteurs de mots» (Salton et al., 1975)). Cette representation a fait l’objet de nombreuses etudes
et est souvent utilisee en correlation avec des methodes statistiques tels que Hyperspace Analogue to
Language (HAL) (Lund et al., 1995) ou Latent Semantic Analysis (LSA) (Deerwester et al., 1990) pour
permettre la representation de la semantique des mots. Il est egalement courant d’utiliser des methodes de
ponderation aﬁn de mesurer la quantite d’information apportee au texte par chaque mot («pertinence des
mots»). Cette information va nous servir a identiﬁer les mots les plus propices aux rapprochements.

CRIL 2

REPRESENTATION VECTORIELLE DE TEXTES COURTS D’OPINIONS

L’utilisation de tous les mots des textes engendre une taille de representation considerable, difﬁcile a trai-
ter. Il est courant d’effectuer des traitements semantiques visant a la simpliﬁer en regroupant ou supprimant
certaines composantes des vecteurs. Cette simpliﬁcation des descripteurs a un impact sur la qualite ﬁnale
du traitement : si les textes ne sont pas correctement representes, il est peu vraisemblable que le resultat
obtenu soit probant car la representation ne reﬂetera pas le sens du texte. Certains chercheurs preconisent
de ne pas systematiquement employer ces methodes de simpliﬁcation mais au contraire de reﬂechir a leur
pertinence et au fait que des mots supprimes traditionnellement des representations peuvent etre primor-
diaux pour des traitements proches de la semantique (Riloff, 1995).

1.3 Pondération et distance sémantique des mots

La ponderation vise a accorder plus d’importance a certaines variables booleennes, a en penaliser d’autres
en allant jusqu’a les retirer (equivalent a une ponderation nulle) et s’oppose a l’equi-importance qui consi-
dere que tous les mots apportent la meme quantite d’information. Utiliser une ponderation est particuliere-
ment interessant en clustering pour distinguer les mots vehiculant beaucoup d’informations, de ceux n’en
apportant que peu. Deux types d’approches existent. Les premieres, methodes statistiques, se basent sur
les occurrences des mots dans le corpus pour determiner l’importance des mots en contexte. La formule
“term frequency, inverse document frequency” (TF.IDF) (Sparck Jones, 1972) en est un exemple. Dans le
cadre de regroupements, un mot qui apparait dans la majorite des textes n’est pas assez discriminant et
conduit a rapprocher trop de textes. Un mot apparaissant tres rarement conduit a en rapprocher trop peu
sur des idees peu representatives. Les deuxiemes, methodes linguistiques, consistent a etablir une liste
des mots a eliminer, consideree comme peu evolutive et de taille raisonnable (Salton et al., 1975) (Salem,
1987). Le contenu et la longueur de cette liste («black list», «stop list» ou «liste noire») sont differents
en fonction de la nature du traitement. Quelle que soit l’approche retenue, la suppression a ce stade d’un
descripteur important pour le corpus est deﬁnitive et provoque une degradation sensible des resultats.

Dans notre contexte, les opinions etant rarement repetees, il est important de faire attention a ne pas
supprimer de mots utiles pour eviter les pertes d’informations. Utiliser une liste noire pour supprimer les
mots inutiles permet le controle des mots retires sous reserve de ne pas y inclure de mots qui pourraient etre
informatifs. Considerer les autres mots comme equi-importants ne semble pas etre une solution efﬁcace car
ceux qui vehiculent le plus par leur presence le sens global des textes sont plus importants que les autres.
Utiliser une technique statistique de ponderation semble donc judicieux. La formule du TF.IDF n’est pas
appropriee car sa pertinence repose sur l’hypothese de repetition des sens importants dans un texte, peu
veriﬁee si les textes sont tres courts. De meme, l’IDF seul privilegie les mots tres rares. Utile dans un cadre
de recherche de termes discriminants, cela a pour effet dans notre cas de provoquer des rapprochements
sur des mots issus du niveau de langage du repondant plus que sur les idees exprimees. On peut par contre
emettre l’hypothese que l’importance des mots pour les textes est equivalente a l’importance des mots
pour l’ensemble des textes. Nous proposons d’utiliser l’entropie de Shannon appliquee sur l’ensemble des

Textes courts I Analyse sémantique . RePFéSentati°nS
d’opinions par des méthodes linquistiques et statistiques Vectorielles des textes
Groupes ou

Clustering ou Regroupements l

clusters d’opinions

FIG. 1 — Notre processus de traitement

ONYME SARL 3

RECITAL 2010, Montreal, 19-23 juillet 2010 Benoit Trouvilliez

documents (formule 1) pour que les mots ayant une probabilité d’apparition moyenne dans l’ensemble du
corpus soient privilégiés.

O Ccmot
Nbmots

[mot : _(Pmot * l0g(Pmot» 9 avec Pmot : 
Dans (1), Imot, Pm, et Occmot représentent l’importance, la probabilité d’apparition et l’occurrence du mot
dans le corpus, et N bmots, le nombre de mots au total dans le corpus. Deux mots sémantiquement proches
devraient obtenir des notes qui reﬂetent leurs liens. Pour cela, il est courant d’associer a la representa-
tion vectorielle des méthodes permettant d’identiﬁer les liens sémantiques entre les mots du corpus. Une
fois encore, les méthodes sont soit statistiques (HAL, LSA) soit linguistiques (utilisation de ressources tels
qu’un thésaurus ou une ontologie). Nous proposons d’utiliser une méthode linguistique basée sur une onto-
logie. La plus connue est le Wordnet de Princeton (Miller, 1995), créé pour la langue anglaise et fondateur
des «Wordnets» : ressources aux caractéristiques similaires, développées pour plus de 70 langues et listées
par la «Global Wordnet Association»1. Chaque unité de sens de la langue est représentée par un groupe de
mots porteur de ce sens appelé synset. Des liens sémantiques tels que l’antonyInie, l’hypéronymie ou l’hy-
ponymie sont déﬁnis entre les synsets. Pour le francais, on trouve le Wordnet Libre du Francais (WOLF)
(Sagot & Fiser, 2008), utilisé pour nos tests, et le projet francophone EuroWordnet (Vossen, 1998). Le
probleme majeur est alors la polysémie des mots car si l’ontologie fournit l’ensemble des sens du mot et
les liens existants pour chacun d’eux, il est difﬁcile de déterminer lequel est employé. Dans le cadre de
textes longs, la répétition du sens employé dans le texte peut aider a l’identiﬁer, fait non vériﬁé dans des
textes courts. Nous avons donc opté pour une méthode qui calcule la probabilité d’apparition d’un mot t
comme la somme des probabilités d’apparition des mots i partageant un de leurs sens en commun avec le
mot t (formule 2).

[mot/sens : _(Pmot/sens * l0g(Pmot/sens» 9 avec Pmot/sens : Z  9 et Synmot : U 3 

iESynm,,t motes

Dans (2), Imot/sens et Pmot/sens représentent l’importance et la probabilité d’apparition d’un mot selon
la représentativité de ses sens dans le corpus, 1', un mot de l’ontologie, 3, un synset de l’ontologie et P,-,
la probabilité d’apparition du mot i calculée selon la sous-formule Pmot de la formule (1). La formule
2 a pour propriétés essentielles de provoquer la maximisation des probabilités d’apparition des mots en
considérant chaque mot potentiellement porteur du sens comme porteur et de ne pas requérir de désambi-
guisation au préalable des sens des mots. Cette stratégie, peu justiﬁée dans un contexte pluri thématique,
l’est dans notre cas car la probabilité d’emploi polysémique d’un terme au sein des textes du corpus se
trouve considérablement réduite en l’absence de themes multiples.

Le tableau 1 montre les mots identiﬁés comme les plus importants dans deux corpus de textes différents
selon cette méthode, mots propices aux regroupements d’opinions (ouverture de magasins, progression du
chiffre d’affaire, formation a l’anglais, favoriser la mobilité, développer les connaissances culturelles, ...).
Les mots «améliorer» et «promouvoir» ont recu une note identique grace a la détection d’une proximité
sémantique dans leurs sens. Nous expliciterons ensuite les effets sur le clustering de ces pondérations.

L’ ontologie permet également de tenir compte de la distance sémantique entre les mots lors des regrou-
pements. En l’absence de themes multiples, nous considérons que deux mots sont sémantiquement liés si
l’ontologie connait un sens a ces mots partageant un lien. Dans le cas, ou plusieurs liens pourraient étre
trouvés, le lien le plus fort est retenu. A savoir, par ordre décroissant d’importance, la synonymie forte,

lréférence : http ://www.globa1wordnet.org

CRIL 4

REPRESENTATION VECTORIELLE DE TEXTES COURTS D’OPINIONS

la synonymie faible, l’hypéronyInie et la fratrie par hypéronymie commune (formule 3). Ce raisonnement
possede les mémes propriétés que celles évoquées pour la pondération : maximisation de la probabilité
d’identiﬁcation d’un lien sémantique et non désambiguisation du contexte.

19(2) J’) = .mi.n ,(d(s, s’)) (3)

163,3 Es

Dans (3), 1' et j représentent deux mots du corpus, D(z', j), la distance sémantique entre 1' et j, 3 et 3’, deux
synsets de l’ontologie distincts ou non et d (3, 3’ ), la distance entre 3 et 3’ selon l’ontologie.

1.4 Représentation de la négation

La représentation de la négation est un probleme a cause notaInment des formes multiples qu’elle peut
prendre, simples (ne...pas, ne...plus,  ) ou complexes (double négation souvent par antonymie), et de sa
«portée» dans le texte (sur une ou plusieurs phrases ou parties de phrases). Cette liste n’est pas exhaustive
mais illustre bien les problemes rencontrés. Alors que les chercheurs travaillant sur l’identiﬁcation de
la thématique des textes n’effectuent aucun traitement particulier et se contentent de traiter les mots de
la négation comme des mots ordinaires voire de les inclure a la liste noire, d’autres, travaillant sur la
sémantique préconisent une différenciation entre les phrases selon que l’idée exprimée est niée ou non
(Poirier et al., 2008). Traiter la négation en particulier, nécessite de se confronter au probleme de sa
portée. Comme les textes sont tres courts, nous pouvons poser l’hypothese que la négation, si elle existe,
peut étre appliquée sur l’ensemble du texte sans en dégrader le sens (Poirier et al., 2008). Cela n’est bien
sﬁr pas vériﬁé dans des textes complexes (phrases avec conjonctions, ...).

Aﬁn de valider ces considérations, des tests ont été réalisés sur un jeu d’essai comportant deux sortes de
messages : des messages afﬁrmant aimer les chats et des messages niant aimer les chats. Ils ont consisté a
effectuer des regroupements en considérant successivement les marques de la négation comme appartenant
a la liste noire, comme des mots ordinaires pour lesquels aucun traitement n’est a faire et enﬁn comme
des mots discriminants permettant de marquer les messages avec une valeur afﬁrmée ou niée. Dans ce

Résultat sur le jeu «réussite de l’enseigne TrucMuche»

mot Isms mot Isms mot Isms mot Isms

magasin/s 0.1535 intemational/e 0.1357 chiffre d affaire 0.1315 expansion 0.1248

ouverture/s 0.1519 préférée 0.1357 progresse 0.1315 com 0.1248

france/gais 0.1415 TrucMuche 0.1357 formation/s 0.1315 Vendus/ues 0.1224
client/s/e/es 0. 1396 augmentation/s 0. 1336 développement/s 0. 1294
enseigne 0.1377 nombre/s 0.1315 Volumel s 0.1271

Résultat sur le jeu des «choix stratégiques»
mot Isms mot Isms mot Isms mot Isms

formation/s 0. 1668 international/ale/ales/aux 0. 1489 communication/s 0. 1296 inter 0. 1 186
anglais/se 0.1591 échange/s 0.1441 connaissance/s 0.1254
mobilitél s 0.1591 langue/s 0.1372 djfférents/tes/ces 0.1254
favoriser 0.1563 sites 0.1372 personnel/s 0.1232
développer/ement 0. 1519 étranger/ers/éres 0. 1354 améliorer 0. 1 186

culture/es/el/elle/els/elles 0. 13 16 promouvoir 0. 1 186

TAB. 1 — Extraits de l’importance des mots avec l’entropie de Shannon appliquée sur les sens

ONYME SARL 5

RECITAL 2010, Montreal, 19-23 juillet 2010 Benoit Trouvilliez

dernier cas, les marques de la negation et antonymes sont retires. Puis, les messages sont marques comme
afﬁrmes, s’ils contenaient un nombre pair d’expressions de negation et antonymes, et comme nies sinon.
Dans le cas ou la negation est dans la liste noire, aucune distinction n’est faite entre les messages afﬁrmes
et nies. Dans le cas du non traitement de la negation, la distinction est faite uniquement sur la presence
ou l’absence des mots negatifs. Cela engendre le regroupement a tort des messages contenant une double
negation avec ceux n’en contenant qu’une simple : «Rien ne me fera aimer les chats» et «Rien ne me fera
detester les chats». Dans le cas du marquage, la distinction se fait sur la polarite induite aux messages
par la negation. Cette demiere distinction est la meilleure dans notre cas puiqu’elle permet d’obtenir deux
clusters d’opinions opposees : «ceux qui aiment les chats» et «ceux qui n’aiment pas les chats».

1.5 Lemmatisation / stemmatisation

Ces methodes identiﬁent les mots differents a cause des regles syntaxiques et grammaticales mais ayant
une semantique identique. La lemmatisation identiﬁe la fonction grammaticale et le lemme du mot, soit a
l’aide du contexte au moyen d’une desambigu'1'sation, solution etudiee dans cet article, soit en etablissant
une liste des differents lemmes possibles du mot («lemmatisation en ou hors contexte»). La stemmatisation
ne resout jamais le contexte mais identiﬁe selon la forme et la langue utilisee, la fonction grammaticale du
mot et en deduit son radical. La lemmatisation simpliﬁe les representations de mots dont le radical varie
mais pas celles de ceux occupant une fonction grammaticale differente. La stemmatisation, au contraire,
est capable d’effectuer des rapprochements entre les mots occupant une fonction grammaticale differente
mais pas entre ceux dont le radical varie et provoque de plus un rapprochement non desire entre les mots
semantiquement differents mais ayant une racine commune.

Nos choix se sont portes sur TreeTagger (Schmid, 1994), etiqueteur multilingue realise par le laboratoire
de l’Universite de Stuttgart, pour la lemmatisation et sur Snowball, sous projet de Apache Lucenez, pour la
stemmatisation. Ils ont ete testes sur differents jeux de tests. Ils ne commettent pratiquement aucune erreur
en contexte orthographique correct. TreeTagger semble meme parvenir a desambigu'1'ser correctement dans
des phrases comportant des homonymes comme le verbe «porter» et le nom «porte». Sur un corpus mal
orthographie, les resultats de lemmatisation s’effondrent. Aucun lemme correct n’a ete identiﬁe sur les
termes inconnus et peu de fonctions grammaticales l’ont ete. Du cote de la stemmatisation, les resultats
sur un corpus mal orthographie sont mitiges. Les mots sur lesquels la faute porte sur la partie consideree
comme le radical n’ont pas ete corriges. De meme, certaines fautes portant sur le sufﬁxe ont modiﬁe le
radical retoume par Snowball (exemple : «jouet» donne le radical «jouet» alors que «jouer» donne le
radical «jou»).

Ces tests sur la lemmatisation et la stemmatisation montrent que la lemmatisation est peu efﬁcace dans un
contexte orthographique difﬁcile. Cela est surtout un handicap si le terme affecte est un terme decisif pour
les regroupements. La stemmatisation se revele etre une solution si la faute ne modiﬁe pas le radical du
mot. Ces constats nous ont conduits a supposer que la combinaison des deux methodes permettrait de tirer
parti des avantages de chacune des deux strategies : la lemmatisation permet de regrouper dans un premier
temps les mots dont le radical evolue et la stemmatisation, de regrouper ensuite les differentes formes
grammaticales d’un meme concept tout en corrigeant eventuellement quelques fautes d’orthographe. Les
resultats intermediaires obtenus apres la lemmatisation sont conserves et utilises lors des rapprochements
semantiques a l’aide de l’ontologie. I1 serait egalement possible d’utiliser les statistiques ainsi obtenues

zhttp ://1ucene.apache.org/

CRIL 6

REPRESENTATION VECTORIELLE DE TEXTES COURTS D’OPINIONS

Traitements sémantiques
Négation Lemmatisation Stemmatisation Pondération Distance sémantique des mots
Ne rien faire Ne rien faire Ne rien faire Equi—ponderation simple Similitude de formes
Black List TreeTagger SnowBall Black List + Equi—ponderation Similitude de sens
Tags des textes Black List + TF.1DF
Black List + Shannon avec sens
Black List + Shannon

TAB. 2 — Les differentes strategies de traitements semantiques

pour determiner si deux mots proches apres stemmatisation le sont a cause de leur semantique.

Dans le tableau 1, «formation»/«formations», «culturel»/«culturelle» ont la meme importance grace a la
lemmatisation, et «culture»/«culturelles», «expatriation»/«expatries>> grace a la stemmatisation.

2 Résultats expérimentaux sur les regroupements

Le tableau 2 reprend les 120 combinaisons de traitements semantiques evoquees. Parmi elles, celle sou-
lignee dans le tableau s’est demarquee dans nos reﬂexions et tests par son adequation avec nos attentes.
Une analyse des regroupements obtenus au moyen d’une methode hierarchique dans cette conﬁguration
est presentee dans le tableau 3. Les tests, conduits sur methode par partitions (KMeans), ont montre des
problemes semantiques similaires a ceux evoques ci apres pour la methode hierarchique.

Dans le premier extrait, les idees de «reunion reguliere», «proximite, convivialite», «feter les succes» ont
ete detectees. L’ expression «mise en place» a ete consideree comme une opinion au lieu des complements
de cette expression. Dans le deuxieme extrait, les idees «d’ecouter et de voir» aussi bien les clients que
d’autres metiers et de «voyage» ont ete trouvees. Cet exemple montre l’interét d’employer des techniques
tels que la lemmatisation ou la stemmatisation : le rapprochement semantique a ainsi pu etre fait entre
le nom «voyage» et le verbe «voyager». Dans le troisieme extrait, «projets internationaux» et «projets
mondiaux» ont ete rapproches par la detection de liens semantiques entre les termes «intemationaux»
et «mondiaux». Par ailleurs, cet extrait porte sur l’un des deux jeux utilises pour tester la ponderation.
On retrouve bien les idees faisant l’objet de la plus forte ponderation : formation a l’anglais, favoriser la
mobilite et developpement des connaissances culturelles. Dans le demier extrait, notre traitement de la
negation en particulier a permis de rapprocher le message «je n’ai pas eu de problemes avec les produits»
du groupe «satisfaction produit». En revanche, sur des textes plus complexes, notre technique engendre
comme prevu, des erreurs de comprehension : le message «je n ai rien a dire je suis tres heureuse de ma
commande» a ete rapproche du groupe «insatisfait commande» a cause de la negation qu’il comprend
(«n»). «mercie a vous touts» a ete bien classe, malgre l’orthographe, en combinant la lemmatisation et la
stemmatisation, mais «je crois savoir ma la respnsable du pont relais...» ne l’a pas ete.

Une analyse statistique a ete menee sur le clustering produit par cette methode hierarchique sur un jeu de
test cree a partir de plusieurs corpus. Cette qualite a ete evaluee, sur l’ecart entre le nombre de groupes
attendu et produit, et sur l’homogeneite de ces demiers. Chaque message est codiﬁe manuellement se-
lon l’idee principale qu’il exprime. L’homogeneite d’un cluster correspond au pourcentage de messages
codiﬁes avec l’idee majoritaire du cluster. Si aucune idee n’est majoritaire, le cluster est declare comme
totalement heterogene. L’ homogeneite globale est ensuite calculee comme la moyenne des homogeneites

ONYME SARL 7

RECITAL 2010, Montreal, 19-23 juillet 2010

Benoit Trouvilliez

Premier extrait : jeu «entreprise»

Titre du cluster

Messages

Proximité, convivialité
Conventions

Groupes de proj ets
Mettre en place

Feter les succes

Développer (la proximité/la convivialité) (dans l’entreprise/avec et er1tre les collaborateurs)
Convention semestrielle ou annuellel Convention : reunion de tous les collaborateurs
(Travailler en/Créer des groupes de) proj ets transversaux / Favoriser les groupes de projets

Mettre en place (des groupes de travail transversaux/des objectifs) / Solliciter des volontaires pour
mettre en place des groupes de travail transversaux suivis et reconnus par le manager / Mise en place
(d’outils de mesure precise de realisation des objectifs/de reunions régulieres d’information)

Savoir feter les succes / Créer des événements réguliers et varies feter les succes

Deuxieme extrait : jeu «relationnel»

Titre du cluster

Messages

Ecouter, observer

Moins d’opérationnel
Veille
Voyager

Je regarde et j’écoute mes clients / (Ecouter/Etre a l’écoute/Faire parler/Rever pour) les clients, les
fournisseurs / Rester connecté avec le client et la réalité du terrain / Ecouter son instinct / Je vais voir
autre chose dans d’autres métiers

(Pouvoir se dégager/J e me dégage) de l’opérationnel / Susciter un contre pouvoir non opérationnel
Se tenir informé du marché (visite clients, veille) / J e visite mes clients / S’informer, reste en veille
Je voyage / Voyager, s’ouvrir au monde / Voyages en inteme, échanges avec ses équipes

Troisieme extrait : jeu «choix stratégiques»

Titre du cluster

Messages

Proj ets intemationaux
Differences culturelles
Connaissance culturelle

Ouverture international

Mobilité

Faire des proj ets intemationaux / Développer une culture mondiale a l’occasion de proj et
(Sensibilisation/Sensibiliser le personnel) aux differences culturelles

Développer la connaissance des (cultures de nos clients/djfférentes “cultures business”/cultures lo-
cales/des cultures des autres pays/djfférents sites) / Se former a la culture

(Développer les/Promouvoir l’exercice des) langues étrangeres / Développer la maitrise de la langue
anglaise / Apprendre l’anglais / Favoriserl’intemationa1isation des recrutements

Développer (la mobilité/la mobilité intemationale (dans les 2 sens))

Quatrieme extrait : jeu «commande intemet»

Titre du cluster

Messages

Satisfait produits

Insatisfait commande

Non classé

comme d’habitude je n’ai pas eu de probleme avec les produits / J ’ai été ravie par ma commande et
surtout la rapidité et le sérieux de l’envoi. / je suis contente de vos colis / Rien a dire tout est parfait ! !
/ Frais de livraison un peu élevés je trouve. Les produits sont conformes et de bonne qualité pour le
prix. / J e suis tres contente / mercie a vous touts

commande soit disant livrée en 48 heures mais livraison seulement apres relance le 24/12 ca fait un
peu long heureusement qu’il n’y avair pas d’échange a faire / J ’ai passe commande le 12/12 et je
n’ai pu récupérer ma commande au relais que le 21/12 au lieu de 48h apres car il était livré mais pas
enregistré. / Annonce par mail commande livrée au point relai et quand je suis allée la chercher elle
n’était pas la. / a ce jour je n’ai toujours pas ma commande. / aucun suivi de cette commande. / je n ai
rien a dire je suis tres heureuse de ma commande

je crois savoir ma la respnsable du pont relais queles livraisons ne sont effectuées que 2 fois par
semaine ce qui repousse le délai de 48h prévu. Que popuvez—vous faire pour remédier a ce soucis ‘.7 ‘.7

TAB. 3 — Extraits de regroupements sur quatre jeux de tests

de chaque cluster pondérée selon 1e nombre de messages qu’i1 contient. Les deux criteres étant comple-
mentaires, on considérera un résultat meilleur qu’un autre s’i1 1’est sur 1’un des criteres et est au moins
aussi bon sur 1’autre. On admettra par ailleurs de maniere non formelle qu’un résultat n’est plus vraiment
acceptable en dessous d’une homogénéité moyenne de 30% et au dela d’un écart total de 20 rangs ainsi
que le fait qu’un gain de 3 rangs sur le critere d’écart permet de compenser une perte moyenne de 10% sur

CRIL 8

REPRESENTATION VECTORIELLE DE TEXTES COURTS D’OPINIONS

le critere d’homogénéité. Nous avons pris comme référence la combinaison Inise en évidence précédem-
ment («solution avec tous les traitements»), puis nous l’avons comparée avec quelques autres proches en
terme de traitements (Fig. 2).

La solution de référence obtient un bon résultat mais les autres traitements de la négation (en liste noire
et sans traitement) semblent meilleurs, le traitement en liste noire l’étant davantage que la solution sans
traitement. Parmi les messages comportant une négation dans ce jeu, seul 44% répondent aux criteres de
complexité évoqués. Cela illustre la faible pertinence de cette solution en présence de messages complexes.
Il est également intéressant de souligner que toutes les solutions ont produit un nombre de clusters plus
élevé que celui attendu. Nos solutions n’arriveraient donc pas a regrouper les idées autant qu’un expert.
Ce test met également en évidence la tres forte pertinence de la liste noire et de la distance sémantique des
mots calculée selon les sens. Tous les tests réalisés contradictoirement obtiennent des résultats nettement
inférieurs. La pondération des sens semble meilleure que la pondération des mots car elle permet de pro-
duire moins de groupes méme s’ils semblent légerement moins homogenes. L’ emploi de la lemmatisation
ou de la stemmatisation semble indispensable sous peine de produire un nombre de clusters trop élevé. La
lemmatisation se révele toutefois plus efﬁcace que la stemmatisation et de qualité presque égale voire le-
gérement supérieure a la combinaison des deux méthodes. Ce constat tend a prouver que la stemmatisation
peut dégrader les résultats par rapprochements de mots ayant seulement une racine commune.

E3“ 60 . . .

5 Tous les traitements J_

8 55 ‘ Sans lemmatisation + * A ‘ , ,, ,

g _ _ _ Sans stemmatisation V V Symbole Ecart Homogeneite

m 50 —N1lemmat1sation, n1 stemmatisation x —|— X — 2 20 12

5 45 Sa“W§%;‘g::IL3ee1.aI:I:%I:“I$sI: 3 1 + ’ 1 ’

E Pondérgtion tdles inﬁts 07;) O0 4 19,94

m _ ans ac s _

§ 40 Pondérationdes mots sans black list g J‘ 15 45’62

3 35 _ Snmlitude dc forme des mots _ ~k 15 55,15

‘'0

\ A 16 53 94

:3 30 - - ’

“" V 17 50 91

C‘: 9

‘§ 25 ’ ’ + 18 46 83

E 20 — ll 00 I I I - ,

0 T 18 49,1

E 0 5 10 15 20 19 48 92
Ecart par rapport au nombre de clusters attendu >1: 20 47’83

FIG. 2 — Résultats statistiques de différentes méthodes

3 Conclusion

Nous avons étudié le regroupement de textes courts d’opinions. Dans ce cadre, La représentation vecto-
rielle se révéle pertinente car elle fournit une distance sémantique simple a calculer et la possibilité d’y
adjoindre un systeme de pondération favorisant les dimensions les plus intéressantes pour les rapproche-
ments. L’ entropie de Shannon donne de bons résultats pour le calcul de ces poids surtout apres la prise en
compte de la sémantique des mots a l’aide d’une ontologie et sans avoir recours a une désambiguisation
du corpus. La recherche de marques de négation en vue d’un marquage des messages dans leur intégralité
comme niées ou afﬁrmées nous permet d’obtenir généralement de meilleurs résultats sur les regroupe-
ments que les autres solutions envisagées dans le cadre de textes tres courts. A l’inverse, cette méthode

ONYME SARL 9

RECITAL 2010, Montreal, 19-23 juillet 2010 Benoit Trouvilliez

se révele étre médiocre dans un cadre contraire. Enﬁn, la lemmatisation se révéle tres peu efﬁcace dans
un contexte orthographique difﬁcile. Ce constat n’est pénalisant dans notre application que si les fautes
portent sur l’opinion évoquée. La stemmatisation des formes lemmatisées permet de les corriger dans le
cas ou le radical n’est pas affecté. Les axes de travaux futurs concement la mise en place d’une correction
orthographique automatique du corpus avant le traitement et une réﬂexion plus approfondie sur la gestion
des messages complexes comportant plusieurs idées.

Remerciements

J e remercie messieurs Pierre Marquis et Vincent Dubois, directeur et co-encadrant de these, et messieurs
Antoine Serniclay et Thibaud Vibes, responsables d’Onyme, pour leurs conseils dans mes recherches.

Références

DEERWESTER S., DUMAIS S., FURNAS G., LANDAUER T. & HARSHMAN R. (1990). Indexing by
latent semantic analysis. Journal of the American society for information science, 41(6), 391-407.

LUND K., BURGESS C. & ATCHLEY R. (1995). Semantic and associative priming in high-dimensional

semantic space. In Proceedings of the 17th annual conference of the Cognitive Science Society, vo-
lume 17, p. 660-665.

MILLER G. (1995). Wordnet : a lexical database for english. Communications of the ACM, 38(11), 41.

POIRIER D., BOTHOREL C., GUIMIER DE NEEF E. & BoULLE M. (2008). Automating opinion ana-
lysis in ﬁlm reviews : the case of statistic versus linguistic approach. In Proceedings of the LREC 2008
Workshop on Sentiment Analysis .' Emotion, Metaphor, Ontology and Terminology, p. 94-101.

RASTIER F. (1989). Sens et textualité. Paris, Hachette.

RILOFF E. (1995). Little words can make a big difference for text classiﬁcation. In Proceedings of the
18th annual international ACM SIGIR conference on Research and development in information retrieval,

p. 130-136 : ACM New York, NY, USA.

SAGOT B. & FISER D. (2008). Construction d’un wordnet libre du francais a partir de ressources
multilingues. In Proceedings of TALN 2008.

SALEM A. (1987). Pratique des segments répétés .' essai de statistique textuelle. Klincksieck.

SALTON G., WONG A. & YANG C. (1975). A vector space model for automatic indexing. Communi-
cations of the ACM, 18(11), 620.

SCHMID H. (1994). Probabilistic part-of-speech tagging using decision trees. In Proceedings of Inter-
national Conference on New Methods in Language Processing, volume 12 : Manchester, UK.

SOWA J. (1984). Conceptual structures. Addison-Wesley Reading, MA.

SPARCK JONES K. (1972). A statistical interpretation of term speciﬁcity and its application in retrieval.
Journal of Documentation, 28(1), 11-20.

VOSSEN P. (1998). Eurowordnet a multilingual database with lexical semantic networks. Computational
Linguistics, 25(4).

CRIL 10

