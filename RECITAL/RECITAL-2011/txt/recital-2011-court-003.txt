RECITAL 2011, Montpellier, 27 juin — 1 er juillet 2011

Repérer les phrases évaluatives dans les articles de presse a partir
d’indices et de stéréotypes d’écriture

Mathias Lambert

Université Paris IV—Sorbonne, Laboratoire STIH (LaLIC) — 28 rue Serpente, 75006 Paris
Mathias.Lambert@paris—sorbonne.fr

Résumé. Ce papier présente une méthode de recherche des phrases évaluatives dans les articles
de presse économique et ﬁnanciere a partir de marques et d’indices stéréotypés, propres au style
journalistique, apparaissant de maniere concomitante a l’expression d’évaluation(s) dans les
phrases. Ces marques et indices ont été dégagés par le biais d’une armotation manuelle. lls ont
ensuite été implémentés, en vue d’une phase—test d’armotation automatique, sous forme de
grammaires DCG/GULP permettant, par filtrage, de matcher les phrases les contenant. Les
résultats de notre premiere tentative d’armotation automatique sont présentés dans cet article.
Enﬁn les perspectives offertes par cette méthode relativement peu coﬁteuse en ressources (a base
d’indices non intrinsequement évaluatifs) font l’obj et d’une discussion.

Abstract. This paper presents a method to locate evaluative sentences in financial and economic
newspapers, relying on marks and stereotyped signs. Peculiar to journalese, these are present
concomitantly with the expression of evaluation(s) in sentences. These marks or signs have been
found by means of a manual armotation. Then, in preparation for an automatic armotation phase,
they have been implemented in the form of DCG/GULP grammars which, by ﬁltering, allows to
locate the sentences containing them. The results of our first automatic armotation attempt are
shown in this article. Furthermore, the prospects offered by this method, which relies on non-
intrinsically evaluative marks and therefore does not require long lists of lexical resources, are
discussed.

Mots-clés: Opinion, évaluation, repérage de phrases évaluatives, presse économique et
financiere, style joumalistique, indices/marques/stéréotypes d’écriture.

Keywords: Opinion, appraisal, detection of evaluative sentences, ﬁnancial and economic
newspapers, journalese, writing signs/marks/stereotypes.

MATI-HAS LAMBERT

1 Le reperage automatique d’évaluation : un theme de recherche stratégique d’actualité

Au cours des dix demieres annees, le nombre de travaux, aussi bien a visees academiques qu’a visees
industrielles, ayant pour theme la recherche informatisee des opinions, des evaluations, des attitudes, des
sentiments ou des emotions exprimees dans les documents textuels a augmente de maniere signiﬁcative.
L’interet croissant que suscite ce theme atteste d’un reel besoin, notamment dans le domaine de la veille
economique. Avec intemet, la quantite de donnees disponibles (notamment dans le domaine de la presse) a
traiter est auj ourd’hui trop Volumineuse pour un analyste humain seul. La demande d’outils informatiques de
reperage ou d’aide au reperage des segments porteurs d’evaluation est donc tres forte, car au coeur d’enjeux
strategiques et economiques importants.

La plupart des travaux actuels se limitent souvent a la simple determination de polarites (positive, negative
ou neutre) et n'arrivent a capter que partiellement les phenomenes Vises qui recouvrent pourtant des
signiﬁcations riches, diversiﬁees et souvent complexes. Le but de notre recherche, qui s’inscrit plus
largement au sein du projet ANR OntOpiTex1, est d’avancer dans le domaine en cherchant a identifier, a
agreger eta caracteriser ﬁnement des segments textuels porteurs d'opinions, en fonction de plusieurs criteres
(valeur semantique, source, intensite et force, type d'objet evalue...). Le present article decrit une etude
exploratoire visant a decouvrir et a mettre en oeuvre de nouvelles methodes pour detecter les evaluations
dans les textes. Nous avons cherche, a partir d’une armotation manuelle sur un corpus d’articles de la presse
economique tires du web, a mettre au jour des indices textuels et lexicaux recurrents voire stereotypes
apparaissant de maniere concomitante a l’expression (ou au relais) d’evaluation(s). Ces indices ont ensuite
ete regroupes dans une dizaine de categories, en fonction de criteres syntaxiques et semantiques. Une
premiere implementation, a l’aide de la plateforme SemioLabs2, sous forme de grammaires locales
d’uniﬁcation a alors permis de tester, sur un nouveau corpus d’articles issus de la presse economique, la
ﬁabilite des indices, et par la meme la pertinence de notre methode. Le principal interet de notre approche
est que, contrairement aux autres travaux dans le domaine, elle est relativement peu coﬁteuse en ressources
lexicales. Nous n’avons en effet pas eu a constituer de longues listes de ressources lexicales evaluatives
(adjectifs, adverbes et/ou verbes).

1.1 Concept et domaine

Opinion, subjectivite, evaluation, attitude, jugement, appreciation, sentiment, emotion, affect, ..., la
proliferation des termes pour r1ommer le concept semble, d’une part, revelatrice de la difﬁculte qu’ont les
auteurs a l’apprehender et a le manipuler, et d’autre part, fortement liee a la diversite des travaux dans le
domaine. De maniere generale, les travaux en TAL relatifs au phenomene de l'evaluation sont en majorite
ceux traitant de la fouille d'opinion et de l'analyse de sentiments. Ils s'inscrivent dans trois grandes
categories : (i) la constitution de ressources lexicales pour la fouille d'opinion ; (ii) la classiﬁcation de textes
et/ou de phrases (objectif vs subjectif et/ou positif vs negatif) ; (iii) l’analyse d'opinion dans les textes. Pour
un etat de l’art complet et detaille de la question en TAL, voir (Pang et Lee, 2008).

Le travail presente ici s’inscrit dans la deuxieme categorie: la classification de phrases (objectives vs
subjectives). Pour etre plus precis, il s’agit de reperage de phrases subjectives dans les textes. Pour faire
reference a ces phrases, nous parlerons de phrases évaluatives. Cette appellation nous evitera de fait d’avoir
a aborder la question delicate de la delimitation des segments evaluatifs. Quant a la problematique
concemant ce qu’il faut considerer comme etant evaluatif ou non, nous la discuterons plus bas, dans la
partie ayant trait a l’a1motation.

1.2 Méthode

La methode la plus triviale pour reperer des phrases evaluatives consiste a constituer manuellement (avec
possibilite d’enrichissement semi—automatique) une liste de lexique evaluatif (principalement a base
d’adjectifs et d’adverbes) et de projeter ce lexique sur les textes. [Bloom et al, 2007a] et [Bloom et al,

1 Projet soutenu par l’ANR (2009 CORD 016) ; site : https://ontopitex.greyc.fr/

Developpee par la societe Noopsis : www.noopsis.fr/

REPERER LES PI-IRASES EVALUATIVES DANS LES ARTICLES DE PRESSE A PARTIR D’INDICES ET DE STEREOTYPES
D’ECRITURE

2007b] procedent de cette maniere3 pour extraire les phrases porteuses d’opinion, et les présentent dans un
navigateur (Appraisal Navigator) qui offre a l’utilisateur la possibilité d’attribuer une etiquette aux phrases
en fonction de categories propres a la théorie de l’Appraisal de (Martin et White, 2005).

Certains auteurs, comme (Wiebe et al., 2002) et (Wiebe et al., 2005), en s’appuyant sur une liste d’éléments
subj ectifs (SE) récoltés a la suite d’une armotation manuelle, proposent de rechercher automatiquement dans
les phrases des éléments potentiellement subjectifs ou PSE (hapax, collocations, adjectifs et verbes ayant
des similarités distributionnelles avec des SE) et de decider ensuite si leur potentiel subjectif s’actualise ou
pas en fonction de la densité de SE presents dans le cotexte. Ces travaux sont relativement proches de ceux
de (Riloff et Wiebe 2003) qui utilisent une méthode de bootstrapping, ou des phrases étiquetées évaluatives
sont utilisées comme données d'apprentissage, pour produire automatiquement des modalités représentant
des expressions subjectives et ainsi différencier les phrases objectives des phrases subjectives.

D’autres, comme (Yu et Hatzivassiloglou, 2003) qui s’intéresse a la classification de phrases et de
propositions pour distinguer les opinions des faits dans un systeme de Question/Réponse, s’appuient
essentiellement sur des techniques statistiques (approche par similarité, classiﬁeur bayésien na'i'f, classifieur
bayésien naif multiple).

Notre méthode se distingue des précédentes dans la mesure ou nous n’avons pas constitué de listes de
ressources lexico—gra1mnaticales évaluatives ni utilise de procédés statistiques pour détecter les phrases
porteuses d’évaluation(s). Notre idée est nee d’une constatation suite at l’armotation manuelle. Etant donné
que l’écriture journalistique se trouve soumise a de fortes contraintes (souci d’objectivisation, concision,
clarté, ...), le joumaliste a tendance a recourir a des tours spéciﬁques (formes morphosyntaxiques et/ou
syntaxiques, marques rhétoriques ou emphatiques) récurrents lorsqu’il cherche a atténuer/dissimiler une
evaluation. Ces formes, qui trahissent une certaine subjectivité, peuvent alors etre considérées comme des
indices ou des symptomes attestant de la presence d’évaluations.

2 Annotation, observations et hypothése, expérience

2.1 Annotation

Cette tache a été réalisée manuellement sur un corpus de 36 articles de presse économique collectés a partir
de la base documentaire Factiva. Ces articles, répartis par groupes de 6, concemaient 6 entreprises/domaines
(Apple, EDF—ENR, Goldman Sachs, Google, Total, les laboratoires pharmaceutiques). Pour distinguer ce
qui est de l’ordre de l’évaluation de ce qui est du contenu factuel, nous nous sommes donné un critere
simple : << si nous étions un investisseur, un analyste économique, ou tout autre type de partie prenante (au

sens de ‘stakeholder’), quels elements seraient susceptibles de nous intéresser ? (<< Is this relevant for my
goals/needs? » (Bednarek, 2009, p.l58)) ». Ci-dessous quelques exemples de phrases relevées :

0 C'est un trophée que Christophe de Margerie peut se réj ouir de perdre. (0ltotal)

0 «Les gens sont excédés par cette attente», explique Patrice Leclaire, délégué syndical Force
ouvriere. (04total)

0 Mais ce rendez—vous incontoumable des fans de la pomme, s'illustre, pour sa 25e edition, par
l'absence d'Apple... (08apple)

0 Le dieu de la ﬁnance semble s'etre transformé en diable. (15 glodmansachs)
0 Pas facile de concilier morale et commerce, surtout en Chine... (21google)
0 Certaines questions auraient dﬁ etre posées. (27labopharma)

0 Gare aux désillusions en bourse ! (32EDFENR)

En s’appuyant sur la théorie Appraisal de (Martin et White, 2005) pour constr11ire le lexique

MATI-HAS LAMBERT

2.2 Observations et hypothése

A partir des phrases evaluatives relevees (plus de 300), les marques/indices ont ete regroupes en 11
groupes/types se voulant syntaxiquement et/ou semantiquement homogenes et coherents :

1. Citation—Mise en relief (exemples d’indices : << », " ", d’apres, selon) ;

2. Conjecture (exemples d’indices : verbes au conditionnel, verbes au futur simple, peut-etre, sans
doute, Reste (adv)*4 a voir/savoir/attendre). En effet d’apres (Wiebe et Wilson, 2002, p.112) :
<< Subjectivity in natural language refers to aspects of language used to express emotion,
evaluation and speculation » ;

3. Constat (exemples d’indices : force est de, somme toute, en definitive, bref, finalement) ;
4. Opposition-Concession (exemples d’indices : mais, pourtant, neanmoins, toutefois, en revanche) ;
5. Construction attributive (exemples d’indices: verbes attributifs et assimiles). De fait, d’apres

(Wagner et Pinchon, 1962, p.147) : << l’attribut fait partie d’une phrase ou l’on pose un jugement
predicatif. Il evoque une qualite qu’on reconnait appartenir a une personne, a une chose, qu’on
leur attribue. »

6. Phrase averbale (exemples d’indices : absence de Verbe conjugue) ;

7. Qualite :(exemples d’indices : principal/premier/deuxieme/second atout/avantage/point positif, ne
manque (adv)?5 pas de) ;

8. Rang (exemples d’indices : le geant/champion/leader (adj)* (de)?) ;

9. Subjectivite journalistique afﬂeurante (exemples d’indices: !, ‘.7, utilisation de ‘on’ hors de
citations). En effet, d’apres (Wiebe et Wilson, 2002, p.113) : << some expressions such as! are
subjective in all contexts. ». Cette categorie, un peu plus generale que les autres, a permis de
regrouper certains phenomenes ;

10. Tournure emphatique (exemples d’indices : ce qui frappe le plus c’est, c’est... qui) ;
11. Volonte/Strategie (exemples d’indices : Verbes vouloir/souhaiter/preferer).

Sur ces 11 groupes, 8 (Citation, Conjecture, Constat, Opposition-Concession, Phrase attributive, Phrase
averbale, Subjectivite journalistique afﬂeurante, et Tournure emphatique) sont directement lies au style
d’ecriture. L’hypothese qui decoule de cette observation est donc la suivante: dans un corpus d’articles
joumalistiques, des marques/indices non intrinsequement evaluatifs et propres au style d’ecriture
journalistique (i.e., des stereotypess) peuvent aider, par leur presence recurrente et concomitante aux
evaluations, a reperer des phrases evaluatives.

2.3 Experience

Pour tester cette hypothese, une implementation, sous forme de grammaires locales, des 8 categories citees
plus haut a ete realisee a l’aide de la plateforme SemioLabs. Cette demiere est une plateforme generique
pour le developpement d’applications TAL developpee par la societe Noopsis pour son usage inteme.
Noopsis a mis cet outil a notre disposition dans le cadre du projet Ontopitex. L’interet de la plateforme
SemioLabs est qu’elle fonctionne de maniere modulaire par articulation de composants de traitement plus
ou moins independants parmi lesquels un tokeniseur et un tagger integres. Notre travail d’i1nplementation a
donc pu etre reduit a l’ecriture de grammaires locales (DCG/GULP) permettant, par ﬁltrage, de reperer les

4 Notations issues des expressions rationnelles : (X)* = zero, une, deux ou plusieurs fois X
5 Notations issues des expressions rationnelles : (X)? = zero ou une seule fois X

6 Le sens premier de ce terme peut etre eclairant a ce sujet: methode en imprimerie, au XIXeme siecle,
permettant la reproductibilite en masse d’un modele fixe.

REPERER LES PI-IRASES EVALUATIVES DANS LES ARTICLES DE PRESSE A PARTIR D’INDICES ET DE STEREOTYPES
D’ECRITURE

phrases contenant les marques/indices spéciﬁques dont nous avons parlé plus haut. Un total d’environ 200
regles (pour l’ensemble (les 8 grannnaires) a vu le jour. Comme SemioLabs offre la possibilité d’associer
chaque grannnaire a un module spécifique d’annotation pouvant fonctionner individuellement, nous avons
ensuite pu observer le résultat de l’armotation pour chaque grannnaire, i.e. pour chacune des categories
d’indices. Cette annotation automatique a été menée sur un nouveau corpus de 20 articles de presse
économique recoltés a partir de Factiva et concernant Airbus—Boeing (10 textes) et les Cleantechs (10
textes). En parallele, les 20 articles ont également été armotés manuellement par nos soins pour fournir une
premiere base de comparaison.

3 Résultats et conclusion

La pertinence de chaque type de marques (i.e. dans quelle mesure chacun de ces types de marques apparait
de maniere concomitante a l’expression d’évaluation(s) ?) a été évaluée. On peut parler d’un calcul de la
precision P,- de chacun des types de marques i, selon la formule suivante :

P : nombre de phrases e’valuatives contenant au moins une marque de type i correctement repe’re’es par le systeme
' nombre total de phrases contenant au moins une marque de type i repe’re’es par le systeme

Le calcul du rappel (i.e. le nombre de phrases evaluatives contenant au moins une marque de type i
correctement repérées par le systeme / le nombre total de phrases évaluatives contenant au moins une
marque de type i présentes dans le corpus) a fait apparaitre des taux entre 0,9 et 1. Deux interpretations
coexistent: le silence est inﬁme car i) les grannnaires ont une excellente couverture et/ou ii) parce que
l’évaluation n’est pas totalement objective (cf §2 du 3.2).

3.1 Détail des résultats pour la précision P,~

Pour chaque type de marques des tableaux7 récapitulatifs détaillés (un pour chacun des 20 articles du
corpus) ont été constitues. Ci—dessus un tableau récapitulant la precision obtenue pour chacun des types
d’indices/marques sur l’ensemble des 20 textes :

Type i de marques Pi

Citation-Mise en relief 0,698

Coniecture 0,807

Constat 0,912

Opposition—Concession 0,95 1

Construction attributive #1 (verbe ‘etre’ pris en compte) 0,592
Construction attributive #2 (verbe ‘étre non pris en compte) 0,879
Phrase averbale 0,950

Subiectivité ioumalistique afﬂeurante 0,972

Toumure emphatique 0,967

Tableau l : Résultats du calcul de la précision pour chaque type de marques

A l’exception des marques de type Citation-Mise en relief et celles de type Construction attributive #1, on
constate que, dans l’ensemble, le bruit est tres faible, donc que les marques sont plutot de bons, voire de tres
bons, jalons pour repérer les evaluations.

Concemant la catégorie Citation-Mise en relief, des phrases comme ‘En plus de l’espace « Recherche et
ﬁnancement », Pollutec organise la convention d ’aﬁ‘aires internationale B2Fair. ‘ (02CleanTech), contenant
entre guillemets des specifications de noms concourent a faire baisser la precision. Quant au résultat moyen
concernant la catégorie Construction attributive #1, l’analyse des indices de type Construction attributive #2
montre que la copule ‘etre’ est une source importante de bruit. Une phrase come ‘on e_st ici dans la région
de Seattle .’ (0lAirbusBoeing) a été relevée alors que, d’une part, il ne s’agit pas d’une phrase attributive et

7 Que par manque de place nous ne pouvons faire figurer dans cet article.

MATI-HAS LAMBERT

que, d’autre part, elle ne porte aucune evaluation. De meme les phrases passives (‘I80 A320 ont été
commande’s par IndiGo, 60 autres par Virgin Atlantic.’ (06AirbusBoeing)) ou avec des verbes dont les
temps composes se forment avec l’auxiliaire ‘etre’ (‘L’e’ve’nement annuel Materials Day’ s’est tenu fin avril
a l’Institut de Thermotechnique (sciences applique’es) de la K ULeuven.’ (06CleanTech)) ont occasionné du
bruit.

3.2 Conclusion et perspectives

Loin d’etre une evaluation dont on puisse tirer des resultats catégoriques, cette petite experience de repérage
automatique nous a permis i) d’effectuer quelques petits reglages au niveau des grammaires locales pour
éviter des erreurs grossieres, et ii) d’obtenir un premier retour, plutot encourageant, quant a la pertinence de
notre hypothese. Globalement, s’appuyer sur des marques non—intrinsequement evaluatives, récurrentes dans
le discours joumalistique, et apparaissant concomitamment a des evaluations semble une méthode
prometteuse. Peu coﬁteuse en ressources et relativement simple a mettre en oeuvre, cette méthode
permettrait d’offrir une solution concrete :2 une problématique completement d’actualite car en prise avec
des enj eux sensibles et strategiques.

La prochaine étape dans notre recherche devrait consister a nous procurer un corpus armoté par un analyste
(ou tout autre partie prenante) aﬁn de pouvoir mener une evaluation complete (precision et rappel) et
pleinement objective (car basée sur des données d’armotation independantes).

Nous envisageons egalement par la suite de foumir, de maniere automatique, pour chaque phrase repérée
par le systeme, un indice de ﬁabilite base sur la densite d’indices/marques presents dans la phrase. Cette
idee repose sur l’hypothese que plus une phrase contient d’indices/marques récurrentes dans le discours
joumalistique et apparaissant concomitamment a des evaluations, plus la probabilité qu’on ait a faire a une
phrase evaluative est forte. La validité d’une telle hypothese devra etre demontree par une etude concrete.

Références

BEDNAREK M. (2009). Dimensions of evaluation: cognitive and linguistic perspectives. Pragmatics &
Cognition 17/1: 146-175.

BLOOM K., GARG N., ARGAMON S. (2007 a). Extracting Appraisal Expressions, HLT/NAACL 2007.

BLOOM K., STEIN N., ARGAMON S. (2007 b). Appraisal Extraction for News Opinion Analysis, NT CIR6
2007.

MARTIN J. R., WHITE P. R. R. (2005). The Language of Evaluation : Appraisal in English, New York and
London : Palgrave McMillan.

PANG B., LEE L. (2008). Opinion Mining and Sentiment Analysis. In Fondations and Trends in Information
Retrieval, Vol 2, pp 1-135.

RIDOFF E., WIEBE J. (2003). Learning Extraction Patterns for Subjective Expressions in Proceedings of the
2003 Conference on Empirical Methods in Natural language Processing (EMNLP—2003), pp 105-112,
Sapporo, Japan. ACL.

WAGNER R.L., PINCHON J. (1962). Grammaire du francais classique et moderne, Paris : Hachette
Université.

WIEBE J ., WILSON T., CARDIE C. (2005). Annotating Expressions of Opinions and Emotions in Language.
language Resources and Evaluation, vol. 39, issue 2-3, pp 165-210.

WIEBE J ., WILSON T. (2002). Learning to disambiguate potentially subjective expressions. In Proceedings of
CoNLL—2002, Taipei, Taiwan.

YU H., HATZIVASSIDOGLOU V. (2003). Towards Answering Opinion Questions: Separating Facts from
Opinions and Identifying the Polarity of Opinion Sentences. In Proceedings of the 2003 Conference on
Empirical Methods in Natural language Processing (EMNLP 2003 ), Sapporo, Japan. pp 129-136. ACL.

