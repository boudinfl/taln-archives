TALN 2011, Montpellier, 27 juin Ğ 1er juillet 2011
La complexite« linguistique
Me«thode dÕanalyse
Adrien Barbaresi
ICAR, ENS LYON
Re«sume«. La complexite« linguistique regroupe diffe«rents phe«nome`nes dont il sÕagit de mode«liser le rapport.
Le travail en cours que je de«cris ici propose une re«flexion sur les approches linguistiques et techniques de cette
notion et la mise en application dÕun balayage des textes qui sÕefforce de contribuer a` leur enrichissement. Ce
traitement en surface effectue« suivant une liste de crite`res qui repre«sentent parfois des approximations de logiques
plus e«labore«es tente de fournir une image  raisonnable  de la complexite«.
Abstract. Linguistic complexity includes various linguistic phenomena which interaction is to be modeled.
The ongoing work described here tackles linguistic and technical approaches of this idea as well as an implemen-
tation of a parsing method which is part of text enrichment techniques. This chunk parsing is performed according
to a list of criteria that may consist in logical approximations of more sophisticated processes in order to provide
a  reasonable  image of complexity..
Mots-cle«s : Complexite«, lisibilite«, allemand, analyse de surface.
Keywords: Complexity, lisibility, German, chunk parsing.
1 Enjeux
LÕanalyse de la complexite« se situe dans le cadre de lÕassistance a` la compre«hension. Il sÕagit ici de de«terminer
la lisibilite« dÕun texte pour des humains ou pour des machines, cÕest-a`-dire dÕune part le niveau de maõötrise et de
pratique de la langue requis et dÕautre part le mode`le formel et les instruments a` utiliser.
Ce the`me tre`s riche invite a` penser les langues avant de les analyser a` diffe«rentes e«chelles et selon diffe«rents modes
ope«ratoires. Du point de vue disciplinaire, on peut le situer a` la croise«e de la linguistique, des e«tudes sur la lisibilite«,
des sciences cognitives et de la the«orie de lÕinformation. Le traitement envisage« aborde des notions dÕinformatique
et lÕinte«gration dÕun marquage des textes e«tudie«s, approches qui sont en prise directe avec la re«flexion actuelle chez
les chercheurs et les entrepreneurs sur les donne«es, leur statut, leur forme et leur traitement.
Cette de«marche sÕinscrit en ce sens entre la re«flexion en sciences humaines et lÕexploitation technique. Elle est
e«galement en rapport avec la transmission dÕune langue et son  outillage  (Auroux, 1994). En effet, au-dela`
dÕune tentative consistant a` mode«liser les processus a` lÕÏuvre lors du de«chiffrage dÕun texte, il sÕagit dÕe«quiper
une langue, de lÕenrichir dÕune description utile.
De fait, pour (Gibson, 1998), e«tudier la complexite« linguistique, cÕest expliquer les e«tapes de lÕapprentissage de sa
langue maternelle par un enfant, donner des e«le«ments pour aborder les proble`mes syntaxiques chez les aphasiques,
et fournir des applications dans lesquelles la compre«hensibilite« de la langue est importante, comme les correcteurs
grammaticaux ou la ge«ne«ration automatique de textes.
LÕinte«reöt premier porte sur la complexite« de phrases, de paragraphes ou de textes e«crits en allemand. LÕattention
portera spe«cifiquement sur un standard de cette langue, conside«re« comme une koine`, une langue commune qui
de«passe des disparite«s re«gionales.
Il ne sÕagit donc pas dÕun travail de comparaison entre diffe«rentes langues. En revanche, la pertinence de la notion
de sous-langage pourra eötre examine«e. De meöme, dans un deuxie`me temps, une adaptation de la de«marche et des
outils a` lÕanglais et au francüais apportera peut-eötre quelques e«le«ments qui viendront enrichir la compre«hension du
sujet en infirmant ou confirmant des hypothe`ses.
ADRIEN BARBARESI
2 Me«thode
2.1 Diviser pour mieux appre«hender
Du point de vue linguistique, la complexite« est avant tout un phe«nome`ne difficile a` de«finir (Kusters & Muysken,
2001).
Dans la ligne«e du concept dÕ architecture  de la complexite« (Simon, 1962), il sÕagit de diviser pour mieux
comprendre. Tout syste`me complexe est quasiment de«composable ( nearly-decomposable ) en sous-e«le«ments,
qui peuvent eux-meömes eötre complexes. Meöme si cette approche ne tient pas compte des interactions entre les
diffe«rents sous-syste`mes, elle propose ne«anmoins de chercher des strates e«le«mentaires en bas de la hie«rarchie dÕun
syste`me, postulant que celles-ci peuvent eötre comprises et mode«lise«es efficacement.
Or, dans le cas qui nous inte«resse, ces unite«s pourraient eötre les mots, qui permettent dÕaborder la complexite« mor-
phologique ainsi que par extension les bouts de phrases (chunks), afin de saisir la complexite« morpho-syntaxique et
e«ventuellement de sÕinte«resser a` la de«composition syntaxique dÕun groupe ou dÕune phrase. Les phe«nome`nes inter-
phrastiques repre«sentent un niveau supe«rieur et bien plus de«licat a` analyser automatiquement, celui du discours et
de la linguistique textuelle.
La division du texte en unite«s linguistiques pertinentes comme par exemple les groupes nominaux pre«sente
e«galement lÕinte«reöt de sÕapprocher des e«tudes psycho-linguistiques qui prennent en compte la notion de couöt de
rattachement des composants les uns aux autres. En effet, la tradition cognitiviste voit la complexite« linguistique
comme un couöt supple«mentaire de traitement pour un e«ventuel re«cepteur. La dimension syntaxique joue un grand
roöle a` travers notamment les principes dÕinte«gration et de distance entre constituants. Le couöt de rattachement des
unite«s linguistiques est mode«lise« en termes dÕunite«s dÕe«nergie et dÕunite«s de me«moire a` tre`s court terme (Gibson,
1998), dans la ligne«e des premiers travaux dans cette discipline (Miller, 1956).
Le cadre de pense«e de la grammaire ge«ne«rative a incontestablement contribue« a` faire e«voluer lÕide«e de complexite«.
Le fait quÕil sÕagisse avant tout dÕun mode`le syntaxique du langage a aussi joue« un roöle dans lÕabord de cette notion
en confe«rant une certaine importance a` la syntaxe qui joue aujourdÕhui encore un roöle. Cela dit, cette notion est
loin de se limiter a` cette dimension. La complexite« dÕun point de vue linguistique regroupe diffe«rents phe«nome`nes
dont il sÕagit de mode«liser le rapport, de meöme que diffe«rentes approches a` croiser.
2.2 Croiser les approches et enrichir les pratiques
(Corbin, 1980) opposait  deux facüons pour un linguiste de constituer les donne«es sur lesquelles il travaille :
lÕintrospection, le corpus , et deux me«thodes, la  linguistique de bureau  et la  linguistique de terrain .
Cette distinction a e«galement investi le traitement automatique des langues, ou` elle semble toujours dÕactualite«
selon (Cori, 2008), qui oppose  TAL the«orique  et  TAL robuste . Elle concerne aussi bien la de«marche
(processus longs et diversifie«s dÕune part, traitement plus pre`s de la surface dÕautre part) que les objectifs (en lien
avec la constitution dÕun syste`me linguistique dÕun coöte« et avec des contraintes pratiques comme lÕhe«te«roge«ne«ite«
des textes de lÕautre).
On pourrait ajouter a` la distinction e«tablie la  linguistique a` lÕinstrument  de«finie par (Habert, 2005), une
discipline qui exploite des corpus tout en menant une re«flexion sur les instruments quÕelle utilise. Re«flexion que
(Latour, 1985) appelait de«ja` de ses vÏux :
 Nous oublions toujours lÕimportance des inscriptions, de leurs strates successives et leur Ómise
en instrumentÓ alors que nous parlons pourtant dÕeötres qui ne sont visibles quÕainsi. 
Dans un contexte informatique qui a vu augmenter la vitesse de calcul a` un rythme soutenu, on a vu sÕope«rer
un de«placement en TAL des mode`les de la compe«tence, fonde«s sur des bases the«oriques fortes qui pre«ce`dent le
traitement automatique, vers ceux de la performance, qui ont une vision plus statistique du langage et donnent
plus dÕimportance a` lÕapprentissage par des techniques dÕintelligence artificielle, si bien que ces derniers ont
aujourdÕhui souvent la pre«fe«rence dans la communaute« scientifique.
Ce changement a bel et bien contribue« a` ame«liorer lÕefficacite« des me«thodes sur des crite`res quantitatifs. Toutefois,
cette re«ussite ne doit pas faire oublier quÕil sÕagit de  croiser les approches  et dÕaller dans le sens dÕune
LA COMPLEXITE« LINGUISTIQUE, ME«THODE DÕANALYSE
e«valuation qualitative qui sÕattache a`
 munir les donne«es atteste«es dÕannotations fines, multiples, permettant de progresser vers les
re«gularite«s sous-jacentes  (Habert & Zweigenbaum, 2002)
Cette de«marche se veut attentive a` la pertinence des textes e«tudie«s, en rapport avec le but de recherche poursuivi, a`
lÕexistence de nombreux crite`res dÕannotation qui doivent pouvoir coexister, se confronter, interagir a` travers leur
marquage et enfin a` un apport proprement linguistique concernant la compre«hension dÕun phe«nome`ne langagier
re«sultant de cette analyse.
3 Travail sur corpus
Ce travail est a` situer dans un contexte ou` il nÕy a plus de se«paration herme«tique entre les approches fonde«es sur
un corpus (corpus-based) et celles partant dÕun mode`le the«orique (theory-driven), mais bien une approche hybride
fonde«e sur la connaissance pour e«valuer, tester, ge«ne«rer des hypothe`ses (Wallis & Nelson, 2001).
Le corpus est constitue« de textes e«crits en allemand standard, et devra permettre une analyse diffe«rencie«e de
la complexite«. Pour ce faire, on peut imaginer de traiter des textes divers, dont un e«chantillon aura e«te« releve«
manuellement voire soumis a` un panel test pour permettre dÕe«tudier la corre«lation des re«sultats obtenus a` grande
e«chelle avec les re«sultats obtenus sur lÕe«chantillon.
LÕe«tude sera comparative, et ce a` deux niveaux diffe«rents : comparaison des re«sultats obtenus avec ceux dÕun
corpus e«talonne« dÕune part, comparaison de corpus connus pour eötre deux versions dÕun meöme texte dÕautre part
(litte«rature simplifie«e pour les enfants ou les apprenants par exemple, articles de journaux sur le meöme the`me,
articles scientifiques et leur vulgarisation).
Par ailleurs, on peut imaginer dÕeffectuer dÕautres comparaisons apportant un autre e«clairage sur la notion de
complexite«, comme les re«gularite«s dans lÕutilisation dÕune langue apprise (ou seconde). On peut de«terminer si
dÕapre`s les mesures les textes e«crits par des locuteurs natifs se caracte«risent par la pre«sence dÕun plus grand
nombre dÕindicateurs de la complexite«.
Concernant les textes pris en compte, lÕapport des textes du domaine public est essentiel dans une optique de
transmissibilite« des corpus et des re«sultats. En effet, la question des droits dÕauteurs est encadre«e beaucoup plus
strictement en Allemagne quÕen France.
Aussi lÕe«tude dÕarticles de journaux, par exemple une comparaison sur les articles traitant des meömes sujets dans
un quotidien a` tre`s grand tirage (la Bild-Zeitung) et dans un hebdomadaire (Die Zeit) est soumise a` caution. SÕil
est possible dÕobtenir les articles en te«le«chargeant et nettoyant des pages web, sÕil est possible de les analyser
librement, il nÕest pas permis de rendre disponible le texte enrichi et e«tiquete« sans recourir a` des techniques dites
de  masque  (Rehm et al., 2007), par exemple en remplacüant les mots e«tiquete«s par des autres choisis au hasard
dans la cate«gorie correpondante, ou en me«langeant les phrases du corpus au hasard. Ces techniques oötent toute
notion de cohe«rence et de cohe«sion au texte obtenu, limitant fortement lÕinte«reöt dÕun tel corpus.
Les articles de journaux ne sont donc utilise«s jusquÕici que pour un e«chantillonnage et une analyse  a` vue .
LÕe«tude sur corpus a jusquÕa` pre«sent porte« essentiellement sur des romans classiques, des textes philosophiques,
des romans pour enfants et des romans de gare. Le genre narratif est sur-repre«sente«, refle«tant la nature des Ïuvres
rassemble«es par le Projet Gutenberg.
Ne«anmoins, les articles scientifiques constituent une piste inte«ressante a` double titre : dÕune part du point de vue
technique, parce quÕil est souvent aise« dÕen extraire le texte, voire de remonter automatiquement dÕun article a`
un autre et parce quÕils peuvent dans la plupart des cas eötre republie«s, dÕautre part du point de vue linguistique,
puisquÕils ne sont pas toujours e«crits par des germanophones et quÕune e«tude compare«e pourrait souligner lÕexis-
tence ou non de re«gularite«s chez les uns et les autres.
Enfin, le corpus est susceptible dÕeötre e«largi a` des textes en anglais et en francüais, afin de valider ou dÕinfirmer les
re«sultats obtenus et dÕen tirer dÕautres conclusions par une e«tude comparative.
ADRIEN BARBARESI
4 Traitement
4.1 Hypothe`se de recherche
En prenant connaissance dÕun texte, on se demande souvent sÕil est difficile a` comprendre. Un rapide survol permet
dÕen savoir un peu plus sur le temps, les connaissances et les ressources ne«cessaires a` une lecture satisfaisante.
Il est possible de concevoir un programme capable dÕeffectuer une ope«ration de  survol  qui de«termine le degre«
de complexite« de donne«es textuelles destine«es a` eötre traite«es automatiquement. Cet indice peut prendre en compte
plusieurs dimensions de ce phe«nome`ne et plusieurs e«chelles, de la phrase au texte, de la morphologie a` lÕanalyse
du discours en passant par la syntaxe.
Il est possible dÕisoler les parties qui ne poseront aucun proble`me et celles qui ont besoin dÕune analyse en pro-
fondeur. Plutoöt que dÕappliquer une me«thode qui privile«gierait la rapidite« a` la justesse (ou vice-versa) on peut
alors ponde«rer ces deux parame`tres en appliquant un traitement diffe«rencie«, voire meöme adapte« aux difficulte«s
rencontre«es.
Il sÕagit ici de traiter cette question avec les moyens de la linguistique informatique et de lÕinte«grer au sein de la
chaõöne dÕope«rations qui va du texte brut au texte enrichi syntaxiquement et se«mantiquement. Mesurer la complexite«
peut amener a` mobiliser des ressources et des traitements complexes (comme lÕanalyse grammaticale automatique
par exemple).
Il importe de`s lors dÕexpe«rimenter lÕapport effectif dans un indicateur de complexite« des informations construites
a` lÕaide de ces ressources et traitements. Cela peut conduire a` adopter des approximations de certains de ces
traitements, a` partir du moment ou` il sÕave`re que de tels traitements moins complexes fournissent une image
 raisonnable  de la complexite«.
4.2 Architecture de traitement
La principale contrainte du point de vue du fonctionnement est donc de maintenir un niveau de complexite« algo-
rithmique relativement faible et de rester au plus pre`s dÕune approche line«aire, balayant les mots au fil du texte.
La chaõöne de traitement va du texte brut au texte enrichi selon le sche«ma suivant :
Texte brut
Nettoyage
Scripts
E«tiquetage
TreeTagger
Chunk parsing
Automate fini
Base de donne«es
SQLite
La chaõöne de traitement est guide«e par un script bash. Le nettoyage emploie notamment le logiciel sed, il comprend
un de«coupage en tokens qui comme le reste des scripts est imple«mente« en Perl, en raison de la polyvalence et de
lÕade«quation de ce langage a` la manipulation de texte. LÕe«tiqueteur utilise« est le TreeTagger de lÕIMS Stuttgart
(Schmid, 1994), en raison de sa pre«cision dans le cas de lÕallemand.
Les mesures de complexite« sont ensuite effectue«es et exporte«es au choix sous deux formes diffe«rentes :
Texte enrichi
Mesures
Scripts Perl
Base de donne«es
Export XML
La de«composition du texte et la mesure se font par des cascades a` e«tats finis (Abney, 1996). On tente par la` meöme
dÕe«viter dans la mesure du possible une  dilution des heuristiques  (Trouilleux, 2009), qui pourrait re«sulter
de lÕutilisation de techniques dÕintelligence artificielle ne«cessitant un apprentissage cible« comme les machines a`
vecteurs de support (Support Vector Machines, SVM) ou les re«seaux de neurones artificiels qui conduisent souvent
a` ce que lÕon appelle des  boõötes noires .
LA COMPLEXITE« LINGUISTIQUE, ME«THODE DÕANALYSE
LÕe«laboration du programme de traitement se situe a` un stade de recherche selon la classification de (Ve«ronis,
2000) : les travaux re«alise«s sont de nature prospective mais ne donnent pas encore lieu a` des imple«mentations
utilisables en situation dÕannotation re«elle.
4.3 Crite`res
Cette liste nÕa pas vocation a` eötre exhaustive, elle concerne des phe«nome`nes dont le repe«rage est envisageable,
voire parfois de«ja` mis en pratique.
1. MOTS
longueur par exemple en fixant un seuil a` 17 caracte`res, ce qui repre«sente en ge«ne«ral un peu moins de 5 %
des mots rencontre«s dans la langue ;
fre«quence relative au sein du document et par rapport a` une liste de mots fre«quents e«tablie a` partir dÕun
grand corpus (par exemple la liste des 10000 mots les plus fre«quents du Corpus Leipzig 1) ;
lemme savoir si le lemme est reconnu par lÕe«tiqueteur morpho-syntaxique (le TreeTagger propose cette
option) revient a` approximer un ensemble de mots connus ;
2. GROUPES
taille elle peut donner une ide«e des difficulte«s de rattachement des composants, par exemple dans un groupe
nominal long ;
composition des groupes nominaux atypiques, repe«rables par une suite dÕe«tiquettes, peuvent signaler une
structure plus complexe (de meöme quÕune erreur de lÕe«tiqueteur, ce qui repre«sente e«galement une
forme de complexite«) ;
nombre une phrase comportant de nombreux groupes posera sans doute des proble`mes de rattachement,
par exemple si cinq groupes nominaux sont trouve«s ;
3. PHRASES
longueur parmi les crite`res les plus souvent retenus dans les e«tudes de lisibilite«, la longueur en caracte`res
figure en bonne place (a` lÕusage, les seuils aux alentours de 130 et de 190 caracte`res semblent indiquer
que la phrase se complexifie) ;
virgules en allemand, les propositions sont obligatoirement suivies de virgules, cÕest la` un moyen efficace
pour repe«rer dÕe«ventuelles subordonne«es, a` condition dÕe«viter les e«nume«rations. (Les seuils retenus
jusque la` sont de 0 comme indice de simplification et 3 comme complexification) ;
subordonne«es de«terminer leur type de meöme que leur nombre par phrase par une observation des pronoms
relatifs corre«le«e au crite`re pre«cedent peut sÕave«rer pertinente ;
verbes la forme et la rection des verbes peuvent corroborer lÕexamen des groupes nominaux ;
attaque dÕe«nonce« ce champ est flexible en allemand, il de«note parfois des phe«nome`nes de line«arisation, par
exemple une volonte« de mettre en avant une partie de la phrase pour la rendre plus compre«hensible.
Parmi les sources e«ventuelles de complexite« pour lesquelles les crite`res manquent citons les ellipses et la densite«
conceptuelle en ge«ne«ral, les ambiguõ¬te«s syntaxiques et se«mantiques et a` plus large e«chelle les phe«nome`nes de
cohe«rence et de cohe«sion textuelle.
5 Notion de complexite«
On peut dire quÕau sein dÕune tradition philosophique puis philologique les de«bats autour de la notion de com-
plexite« du langage sont anciens, notamment a` travers la question qui consiste a` savoir si certaines pense«es ou ide«es
sont en elles-meömes complexes, si elles prennent une tournure complexe lors de leur expression ou sÕil existe un
lien entre les deux. Cette question se pose de manie`re particulie`re depuis le courant rationaliste, qui postule le
primat de lÕide«e pure sur la mate«rialite« de lÕexpression. Avec le concept de structure profonde, la complexite« est
1. http ://wortschatz.uni-leipzig.de/
ADRIEN BARBARESI
meöme en quelque sorte inhe«rente a` la relecture dÕune certaine  linguistique carte«sienne  (Chomsky, 1966), cÕest
donc tout naturellement que lÕattrait pour cette notion a connu une nette recrudescence lors du de«veloppement de
la grammaire ge«ne«rative.
Plus tard, le mouvement de la  nouvelle lisibilite«  dans les anne«es 80, en butte a` une conception machinale du
cerveau vu comme un me«canisme de traitement de lÕinformation, se re«approprie lÕide«e et lÕapplique au champ de la
psycho-linguistique tourne« vers des facteurs organisationnels comme la densite« des ide«es et des concepts (Kemper,
1983) ou la structure et la pre«sentation dÕun document (Britton et al., 1982). Ce changement de paradigme dans
les sciences cognitives a partie lie«e avec lÕe«mergence de la linguistique textuelle.
Plus re«cemment, le langage vu comme syste`me complexe adaptatif (Beckner et al., 2009) est une the`se qui se«duit
de plus de chercheurs qui souhaitent fournir une the«orie de lÕinterde«pendance des sous-syste`mes que sont par
exemple les traits phone«tiques, morphologiques ou la syntaxe.
Toutes ces approches de la complexite« sont autant de raisons de sÕatteler a` la mise en valeur de la proximite« des
 traces recombine«es  (Latour, 1985).
Re«fe«rences
ABNEY S. (1996). Partial parsing via finite-state cascades. Natural Language Engineering, 2(4), 337Ğ344.
AUROUX S. (1994). La re«volution technologique de la grammatisation. Lie`ge : Mardaga.
BECKNER C., ELLIS N., BLYTHE R., HOLLAND J., BYBEE J., KE J., CHRISTIANSEN M., LARSEN-
FREEMAN D., CROFT W. & SCHOENEMANN T. (2009). Language Is a Complex Adaptive System : Position
Paper. Language As a Complex Adaptive System, 59(1), 1Ğ26.
BRITTON B., GLYNN S., MEYER B. & PENLAND M. (1982). Effects of text structure on use of cognitive
capacity during reading. Journal of Educational Psychology, 74(1), 51Ğ61.
CHOMSKY N. (1966). Cartesian linguistics : A chapter in the history of rationalist thought. Harper & Row.
CORBIN P. (1980). De la production des donne«es en linguistique introspective. In The«ories linguistiques et
traditions grammaticales, p. 121Ğ179. Villeneuve-dÕAscq : Presses Universitaires de Lille.
CORI M. (2008). Des me«thodes de traitement automatique aux linguistiques fonde«es sur les corpus. Langages,
171.
GIBSON E. (1998). Linguistic complexity : Locality of syntactic dependencies. Cognition, 68(1), 1Ğ76.
HABERT B. (2005). Portrait de linguiste(s) a` lÕinstrument. Texto !, 10(4).
HABERT B. & ZWEIGENBAUM P. (2002). Re«gler les re`gles. TAL, 43(3), 83Ğ105.
KEMPER S. (1983). Measuring the inference load of a text. Journal of educational psychology, 75(3), 391Ğ401.
KUSTERS W. & MUYSKEN P. (2001). The complexities of arguing about complexity. Linguistic Typology,
5(2/3), 182Ğ185.
LATOUR B. (1985). Les  vues  de lÕesprit. Culture technique, 14, 4Ğ29.
MILLER G. A. (1956). The magical number seven, plus or minus two : Some limits on our capacity for process-
ing information. The Psychological Review, 63, 81Ğ97.
REHM G., WITT A., ZINSMEISTER H. & DELLERT J. (2007). Corpus masking : Legally bypassing licensing
restrictions for the free distribution of text collections. Digital Humanities, p. 166Ğ170.
SCHMID H. (1994). Probabilistic Part-Of-Speech Tagging Using Decision Trees. In Proceedings of the Interna-
tional Conference on New Methods in Language Processing, volume 12 : Manchester.
SIMON H. A. (1962). The Architecture of Complexity. Proceedings of the American Philosophical Society,
106(6), 467Ğ482.
TROUILLEUX F. (2009). Un analyseur de surface non de«terministe pour le francüais. In 16e`me Confe«rence sur le
Traitement Automatique des Langues Naturelles, Senlis.
VE«RONIS J. (2000). Annotation automatique de corpus : panorama et e«tat de la technique. In J.-M. PIERREL,
Ed., Inge«nierie des langues, Informatique et syste`mes dÕinformation, p. 111Ğ129. Paris : Herme`s Science.
WALLIS S. & NELSON G. (2001). Knowledge discovery in grammatically analysed corpora. Data Mining and
Knowledge Discovery, 5(4), 305Ğ335.
