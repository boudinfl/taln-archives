<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Application d&#8217;un algorithme de traduction statistique &#224; la normalisation de textos</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 3: RECITAL, pages 71&#8211;79,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Application d&#8217;un algorithme de traduction statistique &#224; la
normalisation de textos
</p>
<p>Gabriel Bernier-Colborne1
(1) Observatoire de linguistique Sens-Texte
</p>
<p>Universit&#233; de Montr&#233;al
gabriel.bernier-colborne@umontreal.ca
</p>
<p>R&#201;SUM&#201;
Ce travail porte sur l&#8217;application d&#8217;une technique de traduction statistique au probl&#232;me de
la normalisation de textos. La m&#233;thode est bas&#233;e sur l&#8217;algorithme de recherche vorace d&#233;crit
dans (Langlais et al., 2007). Une premi&#232;re normalisation est g&#233;n&#233;r&#233;e, puis nous appliquons
it&#233;rativement une fonction qui g&#233;n&#232;re des nouvelles hypoth&#232;ses &#224; partir de la normalisation
courante, et maximisons une fonction de score. Cette m&#233;thode fournit une r&#233;duction du taux
d&#8217;erreurs moyen par phrase de 33 % sur le corpus de test, et une augmentation du score BLEU de
plus de 30 %. Nous mettons l&#8217;accent sur les fonctions qui g&#233;n&#232;rent la normalisation initiale et sur
les op&#233;rations permettant de g&#233;n&#233;rer des nouvelles hypoth&#232;ses.
</p>
<p>ABSTRACT
Applying a Statistical Machine Translation Algorithm to SMS Text Message Normalization
</p>
<p>We report on the application of a statistical machine translation algorithm to the problem of SMS
text message normalization. The technique is based on a greedy search algorithm described in
(Langlais et al., 2007). A first normalization is generated, then a function that generates new
hypotheses is applied iteratively to a current best guess, while maximizing a scoring function.
This method leads to a drop in word error rate of 33% on a held-out test set, and a BLEU score
gain of over 30%. We focus on the methods of generating the initial normalization and the
operations that allow us to generate new hypotheses.
</p>
<p>MOTS-CL&#201;S : Traduction statistique, normalisation de textos, algorithme de recherche vorace,
mod&#232;le de langue.
</p>
<p>KEYWORDS: Machine translation, SMS, text message, normalization, greedy search algorithm,
language model.
</p>
<p>71</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1 Introduction
</p>
<p>Les messages textes (SMS ou textos) contiennent fr&#233;quemment des formes qui ne sont pas
conformes &#224; l&#8217;orthographe ordinaire, ce qui rend leur traitement par des syst&#232;mes de traitement
automatique de la langue probl&#233;matique. La normalisation des textos consiste &#224; &#171; r&#233;&#233;crire les
textos au moyen d&#8217;une orthographe plus classique afin de les rendre plus facilement lisibles par
un humain ou un ordinateur &#187; (Yvon, 2008, p. 5) 1. Par exemple, si on rencontre la forme &#171; stai
comment le ... &#187;, l&#8217;objectif est de produire une normalisation telle que &#171; comment &#233;tait le ... &#187;.
</p>
<p>&#201;tant donn&#233; la popularit&#233; &#233;norme des messages textes et des formes de communication ap-
parent&#233;es, l&#8217;int&#233;r&#234;t que pose la normalisation de ces messages a augment&#233;, ainsi le probl&#232;me
a-t-il inspir&#233; de nombreux travaux depuis quelques ann&#233;es. Les diff&#233;rentes approches propos&#233;es
font appel aux techniques de la correction orthographique, de la traduction statistique et de la
reconnaissance automatique de la parole (Yvon, 2008). Par exemple, (Aw et al., 2006) traitent le
probl&#232;me comme une t&#226;che de traduction, o&#249; on vise &#224; traduire l&#8217;anglais des textos en anglais
standard. (Yvon, 2008) traite le probl&#232;me comme une t&#226;che de reconnaissance automatique
de la parole (RAP), mais utilise &#233;galement des techniques de correction orthographique ; une
repr&#233;sentation phon&#233;tique des textos joue le r&#244;le du mod&#232;le acoustique, et un mod&#232;le de langue
est utilis&#233; pour convertir les s&#233;quences de phones en s&#233;quences de mots. (Beaufort et al., 2010)
proposent pour leur part un syst&#232;me qui combine des techniques de correction automatique et
de traduction statistique.
</p>
<p>Ce travail porte sur l&#8217;application d&#8217;une technique de traduction statistique au probl&#232;me de la
normalisation de textos. Le probl&#232;me consiste donc &#224; &#171; traduire &#187; un texto en fran&#231;ais standard.
Ainsi, l&#8217;objectif de ce travail est de maximiser p( f |e), o&#249; e d&#233;signe un texto et f , sa normalisation.
On peut reformuler le probl&#232;me ainsi en appliquant la loi de Bayes : p( f |e) = p( f ) &#183; p(e| f ), ces
deux termes &#233;tant d&#233;termin&#233;s par des mod&#232;les de langue et de traduction respectivement.
</p>
<p>Une remarque concernant l&#8217;&#233;valuation des techniques de normalisation de textos s&#8217;impose. Deux
m&#233;triques sont souvent utilis&#233;es pour cette &#233;valuation : certains auteurs utilisent le score BLEU
(Papineni et al., 2001), d&#8217;autres utilisent le taux d&#8217;erreur moyen par phrase (word error rate
ou WER). Les deux m&#233;triques sont utilis&#233;es dans nos &#233;valuations (ainsi que le taux de phrases
erron&#233;es ou SER), et nous proposons qu&#8217;il est plus pertinent d&#8217;observer la r&#233;duction du WER,
plut&#244;t que le WER final, &#233;tant donn&#233; que les corpus de textos contiennent diff&#233;rentes quantit&#233;s
de formes &#224; normaliser.
</p>
<p>Les r&#233;sultats pr&#233;sent&#233;s dans la litt&#233;rature divergent beaucoup, et il est tr&#232;s d&#233;licat d&#8217;&#233;tablir des
comparaisons, notamment en raison des diff&#233;rences quant &#224; la langue et la taille des corpus
utilis&#233;s (en plus de l&#8217;utilisation de diff&#233;rentes m&#233;triques). (Aw et al., 2006), qui travaillent sur
la langue anglaise, obtiennent un score BLEU de 0, 81. (Beaufort et al., 2010) affirment que les
syst&#232;mes &#224; l&#8217;&#233;tat de l&#8217;art obtiennent un WER de 11 %, et le syst&#232;me qu&#8217;ils proposent, qui exploite
le corpus SMS pour la science, obtient un WER de 9, 3 % et un score BLEU de 0, 83. (Yvon, 2008)
obtient un WER de 17, 8 %, un r&#233;sultat semblable &#224; ce qu&#8217;on obtiendrait en utilisant un syst&#232;me
g&#233;n&#233;rique de traduction statistique pour traiter ce probl&#232;me. (Kobus et al., 2008) obtiennent un
WER de 16, 5 % avec un syst&#232;me bas&#233; sur la m&#233;taphore de la RAP, de 12, 3 % avec un syst&#232;me de
traduction statistique, et d&#8217;environ 10, 8% en combinant les deux syst&#232;mes.
</p>
<p>1. Nous traduisons.
</p>
<p>72</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Le reste de cet article sera organis&#233; de la fa&#231;on suivante. Dans la section 2, nous d&#233;crirons
les ressources utilis&#233;es dans le cadre de ce travail. La section 3 portera sur l&#8217;algorithme de
recherche vorace que nous avons impl&#233;ment&#233; ; l&#8217;accent sera plac&#233; sur la fonction qui g&#233;n&#232;re la
normalisation initiale et la fonction qui g&#233;n&#232;re de nouvelles hypoth&#232;ses. Enfin, dans la section 4,
nous analyserons les r&#233;sultats obtenus.
</p>
<p>2 Ressources
</p>
<p>Trois ressources sont utilis&#233;es pour mettre en application l&#8217;algorithme vorace de recherche :
un mod&#232;le de langue, un mod&#232;le de traduction et un corpus de textos annot&#233;s. Ce corpus
est constitu&#233; de textos en fran&#231;ais recueillis et annot&#233;s dans le cadre du projet Texto4Science
(Langlais et al., 2012). Chaque texto est accompagn&#233; d&#8217;une normalisation produite par un
annotateur humain. Nous utilisons un corpus d&#8217;entra&#238;nement totalisant 11 000 textos align&#233;s
avec leur normalisation, un corpus de d&#233;veloppement de 1135 paires et un corpus de test de 1000
textos non vus &#224; l&#8217;entra&#238;nement, utilis&#233; pour l&#8217;&#233;valuation finale. Ce test est effectu&#233; seulement
une fois, sur la meilleure version de notre syst&#232;me. Les autres r&#233;sultats pr&#233;sent&#233;s proviennent
tous d&#8217;&#233;valuations sur le corpus de d&#233;veloppement.
</p>
<p>Le mod&#232;le de langue est un mod&#232;le trigramme avec lissage Kneser-Ney entra&#238;n&#233; sur un corpus de
fran&#231;ais totalisant 673 000 phrases et 8, 6 millions de mots, qui comprend les textos normalis&#233;s
du corpus d&#8217;entra&#238;nement.
</p>
<p>Quant au mod&#232;le de traduction, nous utilisons un mod&#232;le probabiliste appris sur le corpus
d&#8217;entra&#238;nement, de la forme p( f |e) o&#249; e sont des mots de la langue des textos et f des mots
du fran&#231;ais normalis&#233;. Le mod&#232;le est bas&#233; sur un alignement mot-&#224;-mot entre f et e. Dans
l&#8217;algorithme de recherche vorace d&#233;crit ci-dessous, la fonction qui g&#233;n&#232;re de nouvelles hypoth&#232;ses
comprend une op&#233;ration d&#8217;insertion de mots qui vise &#224; combler les lacunes de ce mod&#232;le mot-&#224;-
mot. La simplicit&#233; de ce mod&#232;le, et de la fonction de score utilis&#233;e (voir section 3), est coh&#233;rente
avec une approche par recherche vorace.
</p>
<p>3 Algorithme
</p>
<p>La technique mise en application ici est bas&#233;e sur l&#8217;algorithme vorace de recherche d&#233;crit dans
(Langlais et al., 2007). Cet algorithme fait appel &#224; trois fonctions : la premi&#232;re (Seed) g&#233;n&#232;re
une traduction initiale, la deuxi&#232;me (Score) attribue aux traductions un score que l&#8217;on tente de
maximiser, et la troisi&#232;me (Neighborhood) g&#233;n&#232;re, au moyen de diff&#233;rentes transformations, un
ensemble d&#8217;hypoth&#232;ses &#224; tester &#224; la prochaine it&#233;ration, jusqu&#8217;&#224; ce que le score plafonne. Dans
(Langlais et al., 2007), la fonction Seed choisit simplement la traduction la plus probable selon
un mod&#232;le de traduction &#224; segments ; la fonction Score est une combinaison log-lin&#233;aire de
</p>
<p>73</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>mod&#232;les :
</p>
<p>Score(e, f ) =&#955;lmlog plm( f ) +&#8721;
i
</p>
<p>&#955;itmlog p
i
tm( f |e) &#8722;
</p>
<p>&#955;w | f | &#8722;
&#955;dpd(e, f )
</p>
<p>o&#249; les &#955; sont des coefficients, plm est un mod&#232;le de langue, p
i
tm sont les diff&#233;rents mod&#232;les de
</p>
<p>traduction, | f | est la longueur de la traduction et pd(e, f ) est un mod&#232;le de distorsion.
L&#8217;algorithme vorace applique it&#233;rativement la fonction Neighborhood &#224; une traduction courante
et maximise le score jusqu&#8217;&#224; ce qu&#8217;il plafonne.
</p>
<p>Nous appliquons ici l&#8217;algorithme vorace au probl&#232;me de la normalisation de textos. L&#8217;approche
consiste globalement &#224; :
&#8211; G&#233;n&#233;rer une premi&#232;re normalisation plausible (Seed)
&#8211; Attribuer un score &#224; cette normalisation (Score)
&#8211; G&#233;n&#233;rer des nouvelles hypoth&#232;ses au moyen de transformations (Neighborhood)
&#8211; Boucler les deux &#233;tapes pr&#233;c&#233;dentes jusqu&#8217;&#224; ce que le score plafonne
</p>
<p>3.1 Fonction Seed
</p>
<p>Pour g&#233;n&#233;rer la normalisation initiale, deux m&#233;thodes sont compar&#233;es : recherche locale de la
normalisation la plus probable pour chaque mot ; et identification de la meilleure normalisation
par d&#233;codage de type Viterbi.
</p>
<p>En ce qui concerne le d&#233;codage de type Viterbi, il est effectu&#233; &#224; l&#8217;aide de la commande Disambig
de SRILM (Stolcke, 2002), que nous utilisons pour produire la normalisation la plus probable
&#233;tant donn&#233; une phrase source et un mod&#232;le de traduction. On peut &#233;galement fournir &#224; ce
programme un mod&#232;le de langue afin qu&#8217;il maximise p(e| f ) &#183; p( f ) plut&#244;t que seulement p(e| f ).
</p>
<p>3.2 Fonction Score
</p>
<p>Nous simplifions la fonction de score de la fa&#231;on suivante :
</p>
<p>Score(e, f ) = &#955;lmlog plm( f ) +&#955;tmlog ptm(e| f )
Le score utilis&#233; maximise donc p(e| f ) &#183; p( f ), ces deux probabilit&#233;s &#233;tant d&#233;termin&#233;es au moyen
des mod&#232;les de traduction et de langue. En ce qui concerne ptm(e| f ), ce terme est calcul&#233; suivant
la m&#233;thode IBM1 :
</p>
<p>p(eJ1 | f I1 ) =
J&#8719;
j=1
</p>
<p> 
1
</p>
<p>I
</p>
<p>I&#8721;
i=0
</p>
<p>p(e j | fi)
!
</p>
<p>74</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Quant &#224; plm( f ), nous calculons le produit des probabilit&#233;s des trigrammes d&#8217;une phrase 2 (des
tokens de d&#233;but et de fin de phrase sont ajout&#233;s). Ces probabilit&#233;s sont tir&#233;es du mod&#232;le de
langue.
</p>
<p>3.3 Fonction Neighborhood
</p>
<p>(Langlais et al., 2007) d&#233;crivent six op&#233;rations mises en application dans la fonction Neighbo-
rhood, dont quelques-unes sont propres aux mod&#232;les &#224; segments utilis&#233;s dans ce travail, alors
que l&#8217;approche utilis&#233;e ici traduit (normalise) mot &#224; mot. En revanche, les op&#233;rations Swap, qui
intervertit deux mots adjacents, et Replace, qui remplace un segment dans la traduction par
d&#8217;autres segments pr&#233;sents dans les mod&#232;les de traduction, s&#8217;appliquent tr&#232;s bien au mod&#232;le
de traduction mot-&#224;-mot. Nous appliquons aussi une op&#233;ration que les auteurs ont sugg&#233;r&#233;e,
c&#8217;est-&#224;-dire l&#8217;insertion de mots.
</p>
<p>Celle-ci consiste &#224; ins&#233;rer des mots &#224; n&#8217;importe quelle position dans une phrase, le vocabulaire
des mots &#224; ins&#233;rer pouvant &#234;tre d&#233;termin&#233; de diff&#233;rentes fa&#231;ons. Nous mettons &#224; l&#8217;&#233;preuve deux
variantes. L&#8217;op&#233;ration Insert_sp ins&#232;re seulement des mots que (Brown et al., 1993) qualifient
de spurious, c&#8217;est-&#224;-dire des mots de la phrase cible qui ne sont align&#233;s avec aucun mot dans la
phrase source. Ceux-ci sont identifi&#233;s automatiquement &#224; partir du mod&#232;le de traduction, en
rep&#233;rant tous les mots qui sont associ&#233;s au mot vide. La deuxi&#232;me op&#233;ration, que nous appelons
Insert_tr, ins&#232;re d&#8217;autres traductions pr&#233;sentes dans le mod&#232;le de traduction pour les mots de
la phrase source, l&#8217;objectif &#233;tant de combler les lacunes du mod&#232;le mot-&#224;-mot, qui risque de
proposer une traduction incorrecte dans les cas o&#249; un mot source doit &#234;tre traduit par plus d&#8217;un
mot cible.
</p>
<p>En somme, la fonction Neighborhood fait appel &#224; quatre op&#233;rations :
&#8211; Swap : intervertir deux mots adjacents
&#8211; Replace : remplacer un mot cible par d&#8217;autres &#233;quivalents potentiels
&#8211; Insert_tr : ins&#233;rer d&#8217;autres &#233;quivalents potentiels d&#8217;un mot source
&#8211; Insert_sp : ins&#233;rer des mots spurious
Les op&#233;rations Insert_sp et Swap seront utilis&#233;es dans toutes les versions &#233;valu&#233;es ici sauf
indication contraire, tandis que Replace et Insert_tr feront l&#8217;objet d&#8217;&#233;valuation distinctes.
</p>
<p>4 Analyse des r&#233;sultats
</p>
<p>4.1 Seed et Neighborhood
</p>
<p>L&#8217;objectif principal de cette &#233;valuation est de mettre &#224; l&#8217;&#233;preuve diff&#233;rentes fa&#231;ons d&#8217;obtenir la
normalisation initiale (fonction Seed) et de g&#233;n&#233;rer des nouvelles hypoth&#232;ses (Neighborhood).
Avant de proc&#233;der &#224; ces tests, nous avons d&#8217;abord enrichi manuellement la liste de mots spurious
exploit&#233;e par l&#8217;op&#233;ration Insert_sp. Une analyse rapide des mots extraits du mod&#232;le de traduction
a montr&#233; que plus de la moiti&#233; &#233;taient des mots de classes ferm&#233;es. Nous avons compl&#233;t&#233; les
</p>
<p>2. Notre programme exploite un wrapper pour Python qui permet d&#8217;interroger SRILM (Madnani, 2009). Voir
http://www.desilinguist.org.
</p>
<p>75</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>listes d&#8217;articles, de d&#233;terminants d&#233;monstratifs et possessifs et de pronoms, ajoutant 32 mots &#224; la
liste. Une l&#233;g&#232;re diminution du WER a &#233;t&#233; observ&#233;e, &#224; tr&#232;s faible co&#251;t.
</p>
<p>Seed IT WER (%) SER (%) BLEU
Baseline 21,01 62, 29 0, 5683
</p>
<p>Topword
Non 31,87 75,42 0,4202
Oui 29,37 74, 63 0, 4382
</p>
<p>Dis
Non 31,45 74, 98 0, 4237
Oui 28,92 74, 36 0, 4456
</p>
<p>Dis2
Non 14,05 53, 92 0, 7169
Oui 12,22 48, 63 0, 7468
</p>
<p>Dis3
Non 12,78 49, 96 0, 7394
Oui 11,05 43,88 0,7674
</p>
<p>TABLE 1 &#8211; Influence de Seed et de Insert_tr
</p>
<p>Les scores qu&#8217;offrent diff&#233;rentes variantes de la fonction Seed sont pr&#233;sent&#233;es dans la table 1.
Pour chacune des techniques, deux variantes de la fonction Neighborhood sont &#233;valu&#233;es. Chacune
comprend les op&#233;rations Swap et Insert_sp, mais nous activons et d&#233;sactivons l&#8217;op&#233;ration Insert_tr
(indiqu&#233; dans la colonne IT). En ce qui concerne les variantes de Seed, Topword choisit simplement
le mot cible le plus probable pour chaque mot source. Dis utilise le d&#233;codage Viterbi au moyen
de Disambig, mais n&#8217;exploite aucun mod&#232;le de langue, seulement un mod&#232;le de traduction. Dis2
exploite un mod&#232;le de langue bigramme et Dis3, un mod&#232;le trigramme. Enfin, pour d&#233;terminer
le baseline, nous conservons simplement le texto de d&#233;part.
</p>
<p>Les r&#233;sultats montrent que les techniques na&#239;ves de g&#233;n&#233;ration de la normalisation initiale
offrent des scores tr&#232;s pauvres, Topword et Dis obtenant des r&#233;sultats &#224; peu pr&#232;s &#233;quivalents. Or,
lorsqu&#8217;on fournit un mod&#232;le de langue &#224; Disambig, les scores deviennent nettement meilleurs.
Cela sugg&#232;re que cette impl&#233;mentation de l&#8217;algorithme n&#233;cessite une normalisation initiale d&#8217;une
certaine qualit&#233;.
</p>
<p>Nous avons &#233;galement &#233;valu&#233; la fonction Replace, qui parcourt les mots de la source, extrait tous
les &#233;quivalents du mod&#232;le de traduction, cherche la traduction du mot source dans la traduction
courante, et la remplace par chacun des &#233;quivalents. Nous l&#8217;avons impl&#233;ment&#233;e dans la version du
programme qui obtient les meilleurs r&#233;sultats, c&#8217;est-&#224;-dire Dis3 avec Insert_tr, et le taux d&#8217;erreurs
moyen par phrase ne diminue pas ; au contraire, il augmente d&#8217;environ 4 %, et le score BLEU
diminue de 2 %. Il semble donc que l&#8217;op&#233;ration Replace n&#8217;est pas b&#233;n&#233;fique, du moins lorsque les
normalisations initiales sont de bonne qualit&#233;. Nous montrerons dans la section suivante que le
contraire est vrai lorsque celles-ci sont moins bonnes.
</p>
<p>4.2 Am&#233;lioration des normalisations g&#233;n&#233;r&#233;es na&#239;vement
</p>
<p>Ayant identifi&#233; une combinaison de fonctions qui produit des r&#233;sultats satisfaisants, nous cher-
chons &#224; v&#233;rifier dans quelle mesure l&#8217;algorithme vorace de recherche am&#233;liore la qualit&#233; des
normalisations fournies par la fonction Seed la plus na&#239;ve, c&#8217;est-&#224;-dire Topword.
</p>
<p>76</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La table 2 pr&#233;sente les r&#233;sultats de cette &#233;valuation. Dis3 indique les r&#233;sultats qu&#8217;on obtient
simplement en laissant &#224; Disambig le soin de choisir la meilleure normalisation &#233;tant donn&#233; un
mod&#232;le de traduction et un mod&#232;le de langue trigramme. Greedy_search d&#233;signe l&#8217;impl&#233;mentation
de l&#8217;algorithme qui obtient les meilleurs r&#233;sultats : Dis3 est utilis&#233; pour la traduction initiale, et
la fonction Neighborhood comprend les op&#233;rations Swap, Insert_sp et Insert_tr. TW indique les
r&#233;sultats qu&#8217;on obtient par la m&#233;thode Topword, sans application de l&#8217;algorithme vorace. Par la
suite, on montre comment la performance de l&#8217;algorithme vorace varie &#224; mesure qu&#8217;on ajoute
des op&#233;rations &#224; la fonction Neighborhood : on d&#233;signe Swap par SW, Insert_sp par IS, Insert_tr
par IT et Replace par RE.
</p>
<p>Les r&#233;sultats montrent que l&#8217;algorithme vorace n&#8217;am&#233;liore pas &#233;norm&#233;ment la qualit&#233; des norma-
lisations produites par Dis3, qui sont d&#233;j&#224; beaucoup plus proches des normalisations de r&#233;f&#233;rence.
Or, nous arrivons tout de m&#234;me &#224; r&#233;duire le taux d&#8217;erreurs moyen par phrase (WER) de presque
moiti&#233; et &#224; augmenter le score BLEU d&#8217;environ 35 % par rapport au baseline.
</p>
<p>Si l&#8217;apport de l&#8217;algorithme vorace n&#8217;est pas &#233;norme lorsque les normalisations initiales sont bonnes,
il devient consid&#233;rable lorsque celles-ci sont g&#233;n&#233;r&#233;es grossi&#232;rement. Les normalisations g&#233;n&#233;r&#233;es
par Topword s&#8217;&#233;loignent nettement des normalisations de r&#233;f&#233;rence, et Swap et Insert_sp ne les
am&#233;liorent pas. Par contre, Replace (et dans une moindre mesure Insert_tr) est tr&#232;s b&#233;n&#233;fique,
offrant une r&#233;duction du taux d&#8217;erreurs moyen de l&#8217;ordre de 40 % et une augmentation du score
BLEU d&#8217;environ 47 %. Ces gains sont attribuables, du moins en partie, au r&#244;le que joue le mod&#232;le
de langue, qui permet par ailleurs d&#8217;am&#233;liorer les normalisations g&#233;n&#233;r&#233;es par Dis, comme nous
l&#8217;avons vu. Malgr&#233; ces gains, nous obtenons des meilleurs r&#233;sultats lorsque les normalisations de
d&#233;part sont d&#233;j&#224; de bonne qualit&#233;, int&#233;grant un mod&#232;le de langue. Rappelons aussi que, lorsque
les normalisation initiales sont bonnes, Replace n&#8217;a pas un effet favorable. Il nous semble que ces
observations correspondent aux intuitions qu&#8217;on peut avoir par rapport &#224; cette approche de la
traduction (ou normalisation).
</p>
<p>4.3 &#201;valuation sur le corpus de test
</p>
<p>Les r&#233;sultats de l&#8217;&#233;valuation finale, effectu&#233;e sur le corpus de test, sont pr&#233;sent&#233;s dans la table 3.
Nous &#233;valuons le syst&#232;me qui fournit les meilleurs r&#233;sultats sur le corpus de d&#233;veloppement : la
normalisation de d&#233;part est g&#233;n&#233;r&#233;e par Dis3, et la fonction Neighborhood utilise les op&#233;rations
Swap, Insert_sp et Insert_tr pour g&#233;n&#233;rer des nouvelles hypoth&#232;ses. Tout d&#8217;abord, on observe que
les textos contiennent une proportion nettement plus &#233;lev&#233;e de formes non standard que ceux
</p>
<p>M&#233;thode WER (%) SER (%) BLEU
Baseline 21, 01 62, 29 0, 5683
</p>
<p>Dis3 13, 01 51, 98 0, 7230
Greedy_search 11, 05 43, 88 0, 7674
</p>
<p>TW 30, 42 75, 51 0, 4051
TW+SW+IS 31, 87 75, 42 0, 4202
</p>
<p>TW+SW+IS+IT 29, 37 74, 63 0, 4382
TW+SW+IS+IT+RE 17, 78 51, 81 0, 5947
</p>
<p>TABLE 2 &#8211; Impact de l&#8217;algorithme vorace de recherche
</p>
<p>77</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>WER SER BLEU
Baseline 28,90 68,60 0,4677
</p>
<p>Greedy_search 19,32 57,70 0,6189
</p>
<p>TABLE 3 &#8211; &#201;valuation sur le corpus de test
</p>
<p>du corpus de d&#233;veloppement, le WER &#233;tant 37, 6 % plus &#233;lev&#233;. Ainsi, le WER des normalisations
produites passe de 11, 05 % (sur le corpus de d&#233;veloppement) &#224; 19, 32 %. De plus, la diminution
du WER observ&#233;e en test, de 33 %, est inf&#233;rieure &#224; la diminution observ&#233;e pendant la phase
de d&#233;veloppement (47 %). Or, si toute diff&#233;rence de WER de 30 % est consid&#233;r&#233;e significative
(Yvon, 2008), il m&#233;rite d&#8217;&#234;tre soulign&#233; que nos r&#233;sultats d&#233;passent ce seuil. En ce qui concerne le
score BLEU, le score des normalisations produites est beaucoup plus faible lorsqu&#8217;on &#233;value sur
le corpus de test, mais l&#8217;augmentation du score BLEU (32 %) est coh&#233;rente avec celle que nous
avons observ&#233;e pendant le d&#233;veloppement (35 %).
</p>
<p>5 Conclusion
</p>
<p>Dans ce travail, nous avons mis en application un algorithme de recherche vorace utilis&#233; en
traduction statistique dans le but de normaliser des textos. L&#8217;accent a &#233;t&#233; plac&#233; sur les fonctions
qui g&#233;n&#232;rent la normalisation initiale et aux op&#233;rations permettant de g&#233;n&#233;rer des nouvelles
hypoth&#232;ses.
</p>
<p>L&#8217;approche qui obtient les meilleurs r&#233;sultats consiste &#224; g&#233;n&#233;rer la normalisation initiale par
d&#233;codage de type Viterbi &#224; partir des mod&#232;les de traduction et de langue ; &#224; utiliser les op&#233;rations
d&#8217;alternance et d&#8217;insertion de mots afin de g&#233;n&#233;rer des nouvelles hypoth&#232;ses ; et &#224; maximiser la
fonction de score. Cette m&#233;thode engendre une diminution du taux d&#8217;erreurs moyen par phrase
de 33 % lors de l&#8217;&#233;valuation finale, et une augmentation du score BLEU de plus de 30 %.
</p>
<p>L&#8217;op&#233;ration Replace, qui consiste &#224; remplacer des mots dans la normalisation courante par d&#8217;autres
&#233;quivalents tir&#233;s du mod&#232;le de traduction, n&#8217;a pas un effet b&#233;n&#233;fique lorsque les normalisations
initiales sont de bonne qualit&#233;. Or, lorsque celles-ci sont g&#233;n&#233;r&#233;es par une simple recherche locale
du mot cible le plus probable pour chaque mot source, l&#8217;op&#233;ration Replace permet d&#8217;am&#233;liorer la
qualit&#233; des normalisations, notamment gr&#226;ce &#224; l&#8217;apport du mod&#232;le de langue.
</p>
<p>Ces techniques simples fournissent des r&#233;sultats qui nous semblent int&#233;ressants. Il nous pa-
ra&#238;t donc profitable de traiter la normalisation des textos comme un probl&#232;me de traduction
intralinguistique.
</p>
<p>Remerciements
</p>
<p>Nous d&#233;sirons remercier Philippe Langlais, ainsi que les relecteurs, pour leurs commentaires
et leurs suggestions sur ce travail. Nous remercions M. Langlais ainsi que Fabrizio Gotti pour
les ressources mises &#224; notre disposition. Nous remercions &#233;galement le Fonds de recherche du
Qu&#233;bec &#8211; Soci&#233;t&#233; et culture pour son soutien financier.
</p>
<p>78</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;f&#233;rences
</p>
<p>AW, A., ZHANG, M., XIAO, J. et SU, J. (2006). A Phrase-Based Statistical Model for SMS Text
Normalization. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages
33&#8211;40, Sydney (Australie). Association for Computational Linguistics.
</p>
<p>BEAUFORT, R., ROEKHAUT, S., COUGNON, L.-A. et FAIRON, C. (2010). A Hybrid Rule/Model-Based
Finite-State Framework for Normalizing SMS Messages. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguistics, pages 770&#8211;779, Uppsala (Su&#232;de).
Association for Computational Linguistics.
</p>
<p>BROWN, P. F., DELLA PIETRA, V. J., DELLA PIETRA, S. A. et MERCER, R. L. (1993). The Mathematics
of Statistical Machine Translation : Parameter Estimation. Computational Linguistics, 19(2):263&#8211;
311.
</p>
<p>KOBUS, C., YVON, F. et DAMNATI, G. (2008). Normalizing SMS : are Two Metaphors Better than
One ? In Proceedings of the 22nd International Conference on Computational Linguistics (Coling
2008), pages 441&#8211;448, Manchester (Angleterre). Coling 2008 Organizing Committee.
</p>
<p>LANGLAIS, P., DROUIN, P., PAULUS, A., BRODEUR, E. R. et COTTIN, F. (&#224; para&#238;tre, 2012).
Texto4science : a Quebec French Database of Annotated Short Text Messages. In Proceedings of
Language Resources and Evaluation Conference (LREC) 2012, Istanbul (Turquie). ELRA.
</p>
<p>LANGLAIS, P., PATRY, A. et GOTTI, F. (2007). A Greedy Decoder for Phrase-Based Statistical
Machine Translation. In Proceedings of the 11th International Conference on Theoretical and
Methodological Issues in Machine Translation, pages 104&#8211;113, Sk&#246;vde (Su&#232;de).
</p>
<p>MADNANI, N. (2009). Querying and Serving N-gram Language Models with Python. The Python
Papers, 4(2).
</p>
<p>PAPINENI, K., ROUKOS, S., WARD, T. et ZHU, W.-J. (2001). Bleu : A Method for Automatic
Evaluation of Machine Translation. Rapport technique RC22176 (W0109-022), IBM Research
Division, Thomas J. Watson Research Center.
</p>
<p>STOLCKE, A. (2002). SRILM &#8211; An Extensible Language Modeling Toolkit. In Proceedings of ICSLP,
Denver (&#201;tats-Unis).
</p>
<p>YVON, F. (2008). Reorthography of SMS Messages. Rapport technique 2008-18, LIMSI-CNRS.
</p>
<p>79</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div>
</div></div>
</body></html>