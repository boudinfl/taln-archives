Application d’un algorithme de traduction statistique a la
normalisation de textos

Gabriel Bernier-Colbornel
(1) Observatoire de linguistique Sens—Texte
Université de Montréal
gabriel .bernier—colbornetﬁumontreal . ca

RESUME
Ce travail porte sur l’application d’une technique de traduction statistique au probleme de
la normalisation de textos. La méthode est basée sur l’algorithme de recherche vorace décrit
dans (Langlais et al., 2007). Une premiere normalisation est générée, puis nous appliquons
itérativement une fonction qui génere des nouvelles hypotheses ‘a partir de la normalisation
courante, et maximisons une fonction de score. Cette méthode foumit une reduction du taux
d’erreurs moyen par phrase de 33 % sur le corpus de test, et une augmentation du score BLEU de
plus de 30 %. Nous mettons l’accent sur les fonctions qui générent la normalisation initiale et sur
les opérations permettant de générer des nouvelles hypotheses.

AB STRACT
Applying a Statistical Machine Translation Algorithm to SMS Text Message Normalization

We report on the application of a statistical machine translation algorithm to the problem of SMS
text message normalization. The technique is based on a greedy search algorithm described in
(Langlais et al., 2007). A first normalization is generated, then a function that generates new
hypotheses is applied iteratively to a current best guess, while maximizing a scoring function.
This method leads to a drop in word error rate of 33% on a held-out test set, and a BLEU score
gain of over 30%. We focus on the methods of generating the initial normalization and the
operations that allow us to generate new hypotheses.

MOTS-CLES : Traduction statistique, normalisation de textos, algorithme de recherche vorace,
modéle de langue.

KEYWORDS: Machine translation, SMS, text message, normalization, greedy search algorithm,
language model.

Actes de la con_fe'rence conjointe JEP-TALN-RECITAL 2012, volume 3: RECITAL, pages 71-79,
Grenoble, 4 an 8 juin 2012. ©2012 ATAI.A 8: AFCP

71

1 Introduction

Les messages textes (SMS ou textos) contiennent fréquemment des formes qui ne sont pas
conformes a l’orthographe ordinaire, ce qui rend leur traitement par des systémes de traitement
automatique de la langue problématique. La normalisation des textos consiste ‘a << réécrire les
textos au moyen d’une orthographe plus classique aﬁn de les rendre plus facilement lisibles par
un humain ou un ordinateur » (Yvon, 2008, p. 5) 1. Par exemple, si on rencontre la forme « stai
comment le  », l’objectif est de produire une normalisation telle que « comment était le  ».

Etant donné la popularité énorrne des messages textes et des formes de communication ap-
parentées, l’intérét que pose la normalisation de ces messages a augmenté, ainsi le probleme
a-t-il inspiré de nombreux travaux depuis quelques années. Les différentes approches proposées
font appel aux techniques de la correction orthographique, de la traduction statistique et de la
reconnaissance automatique de la parole (Yvon, 2008). Par exemple, (Aw et aL, 2006) traitent le
probleme comme une tache de traduction, oil on vise ‘a traduire l’anglais des textos en anglais
standard. (Yvon, 2008) traite le probleme comme une tache de reconnaissance automatique
de la parole (RAP), mais utilise également des techniques de correction orthographique; une
représentation phonétique des textos joue le réle du modéle acoustique, et un modéle de langue
est utilisé pour convertir les séquences de phones en séquences de mots. (Beaufort et al., 2010)
proposent pour leur part un systeme qui combine des techniques de correction automatique et
de traduction statistique.

Ce travail porte sur l’application d’une technique de traduction statistique au probleme de la
normalisation de textos. Le probleme consiste donc a « traduire » un texto en francais standard.
Ainsi, l’objectif de ce travail est de maximiser p(f Ie), o1‘1 e désigne un texto et f, sa normalisation.
On peut reformuler le probleme ainsi en appliquant la loi de Bayes : p( f Ie) = p( f ) - p(e If), ces
deux termes étant déterminés par des modéles de langue et de traduction respectivement.

Une remarque concernant l’évaluation des techniques de normalisation de textos s’impose. Deux
métriques sont souvent utilisées pour cette évaluation : certains auteurs utilisent le score BLEU
(Papineni et al., 2001), d’autres utilisent le taux d’erreur moyen par phrase (word error rate
ou WER). les deux métriques sont utilisées dans nos évaluations (ainsi que le taux de phrases
erronées ou SER), et nous proposons qu’il est plus pertinent d’observer la réduction du WER,
plutot que le WER ﬁnal, étant donné que les corpus de textos contiennent différentes quantités
de formes a normaliser.

Les résultats présentés dans la littérature divergent beaucoup, et il est tres délicat d’établir des
comparaisons, notamment en raison des différences quant a la langue et la taille des corpus
utilisés (en plus de l’utilisation de différentes métriques). (Aw et al., 2006), qui travaillent sur
la langue anglaise, obtiennent un score BLEU de 0, 81. (Beaufort et al., 2010) afﬁrment que les
systémes a l’état de l’art obtiennent un WER de 11 %, et le systéme qu’i1s proposent, qui exploite
le corpus SMS pour la science, obtient un WER de 9, 3 % et un score BLEU de 0, 83. (Yvon, 2008)
obtient un WER de 17, 8 %, un résultat semblable a ce qu’on obtiendrait en utilisant un systeme
générique de traduction statistique pour traiter ce probléme. (Kobus et al., 2008) obtiennent un
WER de 16, 5 % avec un systéme basé sur la métaphore de la RAP, de 12, 3 % avec un systéme de
traduction statistique, et d’environ 10, 8% en combinant les deux systémes.

1. Nous traduisons.

72

Le reste de cet article sera organisé de la facon suivante. Dans la section 2, nous décrirons
les ressources utilisées dans le cadre de ce travail. La section 3 portera sur l’algorithme de
recherche vorace que nous avons implémenté; l’accent sera placé sur la fonction qui génere la
normalisation initiale et la fonction qui génere de nouvelles hypotheses. Enﬁn, dans la section 4,
nous analyserons les résultats obtenus.

2 Ressources

Trois ressources sont utilisées pour mettre en application l’algorithme vorace de recherche :
un modele de langue, un modele de traduction et un corpus de textos annotés. Ce corpus
est constitué de textos en francais recueillis et annotés dans le cadre du projet Texto4Science
(Langlais et al., 2012). Chaque texto est accompagné d’une normalisation produite par un
annotateur humain. Nous utilisons un corpus d’entrainement totalisant 11 000 textos alignés
avec leur normalisation, un corpus de développement de 1135 paires et un corpus de test de 1000
textos non vus ‘a l’entrainement, utilisé pour l’évaluation ﬁnale. Ce test est effectué seulement
une fois, sur la meilleure version de notre systeme. Les autres résultats présentés proviennent
tous d’évaluations sur le corpus de développement.

Le modele de langue est un modele trigrarnme avec lissage Kneser-Ney entrainé sur un corpus de
francais totalisant 673 000 phrases et 8, 6 millions de mots, qui comprend les textos normalisés
du corpus d’entrainement.

Quant au modele de traduction, nous utilisons un modele probabiliste appris sur le corpus
d’entrainement, de la forme p( f Ie) o1‘1 e sont des mots de la langue des textos et f des mots
du francais normalisé. Le modele est basé sur un alignement mot-a-mot entre f et e. Dans
l’algorithme de recherche vorace décrit ci-dessous, la fonction qui génere de nouvelles hypotheses
comprend une opération d’insertion de mots qui vise a combler les lacunes de ce modele mot-a-
mot. La simplicité de ce modele, et de la fonction de score utilisée (voir section 3), est cohérente
avec une approche par recherche vorace.

3 Algorithme

La technique mise en application ici est basée sur l’algorithme vorace de recherche décrit dans
(Langlais et al., 2007). Get algorithme fait appel ‘a trois fonctions : la premiere (Seed) génere
une traduction initiale, la deuxieme (Score) attribue aux traductions un score que l’on tente de
maximiser, et la troisieme (Neighborhood) génere, au moyen de différentes transformations, un
ensemble d’hypotheses ‘a tester ‘a la prochaine itération, jusqu"a ce que le score plafonne. Dans
(Langlais et al., 2007), la fonction Seed choisit simplement la traduction la plus probable selon
un modele de traduction ‘a segments; la fonction Score est une combinaison log-linéaire de

73

modéles :

Score(e,f) =?Lz...10g Plm(f) +
Zaimlogpwle) —

 _
A’dPd(e:f)

o1‘1les A sont des coefficients, pl," est un modele de langue, pi," sont les différents modeles de
traduction, I fl est la longueur de la traduction et pd(e, f ) est un modéle de distorsion.

L’algorithme vorace applique itérativement la fonction Neighborhood a une traduction courante
et maximise le score jusqu’a ce qu’il plafonne.

Nous appliquons ici l’algorithme vorace au probleme de la normalisation de textos. L’approche
consiste globalement a :

— Générer une premiere normalisation plausible (Seed)

— Attribuer un score a cette normalisation (Score)

— Générer des nouvelles hypotheses au moyen de transformations (Neighborhood)

— Boucler les deux étapes précédentes jusqu’a ce que le score plafonne

3.1 Fonction Seed

Pour générer la normalisation initiale, deux méthodes sont comparées : recherche locale de la
normalisation la plus probable pour chaque mot; et identiﬁcation de la meilleure normalisation
par décodage de type Viterbi.

En ce qui concerne le décodage de type Viterbi, il est effectué a l’aide de la commande Disambig
de SRILM (Stolcke, 2002), que nous utilisons pour produire la normalisation la plus probable
étant donné une phrase source et un modele de traduction. On peut également fournir a ce

programme un modéle de langue aﬁn qu’il maximise p(e I f ) - p(f ) plutot que seulement p(e I f ).

3.2 Fonction Score

Nous simpliﬁons la fonction de score de la fagon suivante :

Score(e,f) = lzmlog Plm(f) + lmlog Pm(e|f)

Le score utilisé maximise donc p(e If) - p(f ), ces deux probabilités étant déterminées au moyen
des modéles de traduction et de langue. En ce qui concerne pt,,,(e I f ), ce terme est calculé suivant

la méthode IBM1 : J I
1
p(e{|f{) = 1'] (7 Zpte,-In-J)
j=1 i=0

74

Quant ‘a pl,,,( f ), nous calculons le produit des probabilités des trigrammes d’une phrase 2 (des
tokens de début et de ﬁn de phrase sont ajoutés). Ces probabilités sont tirées du modele de
langue.

3.3 Fonction Neighborhood

(Langlais et aL, 2007) décrivent six opérations mises en application dans la fonction Neighbo-
rhood, dont quelques-unes sont propres aux modeles ‘a segments utilisés dans ce travail, alors
que l’approche utilisée ici traduit (normalise) mot a mot. En revanche, les opérations Swap, qui
intervertit deux mots adjacents, et Replace, qui remplace un segment dans la traduction par
d’autres segments présents dans les modeles de traduction, s’appliquent tres bien au modele
de traduction mot-a-mot. Nous appliquons aussi une opération que les auteurs ont suggérée,
c’est-‘a-dire l’insertion de mots.

Celle-ci consiste ‘a insérer des mots a n’importe quelle position dans une phrase, le vocabulaire
des mots a insérer pouvant étre déterminé de différentes fagons. Nous mettons a l’épreuve deux
variantes. I.’opération Insert_sp insere seulement des mots que (Brown et al., 1993) qualiﬁent
de spurious, c’est-a-dire des mots de la phrase cible qui ne sont alignés avec aucun mot dans la
phrase source. Ceux-ci sont identiﬁes automatiquement ‘a partir du modele de traduction, en
repérant tous les mots qui sont associés au mot vide. La deuxiéme opération, que nous appelons
Insert_tr, insere d’autres traductions présentes dans le modele de traduction pour les mots de
la phrase source, l’objectif étant de combler les lacunes du modele mot-a-mot, qui risque de
proposer une traduction incorrecte dans les cas ou un mot source doit étre 1Iaduit par plus d’un
mot cible.

En somme, la fonction Neighborhood fait appel a quatre opérations :

— Swap : intervenir deux mots adjacents

— Replace : remplacer un mot cible par d’autres équivalents potentiels

— Insert_tr : insérer d’autres équivalents potentiels d’un mot source

— Insert_sp : insérer des mots murious

Les opérations Insert_sp et Swap seront utilisées dans toutes les versions évaluées ici sauf
indication contraire, tandis que Replace et Insert_tr feront l’objet d’évaluation distinctes.

4 Analyse des résultats

4.1 Seed et Neighborhood

L’objectif principal de cette évaluation est de mettre ‘a l’épreuve différentes facons d’obtenir la
normalisation initiale (fonction Seed) et de générer des nouvelles hypotheses (Neighborhood).
Avant de procéder a ces tests, nous avons d’abord enrichi manuellement la liste de mots spurious
exploitée par l’opération Insert_sp. Une analyse rapide des mots extraits du modéle de traduction
a montré que plus de la moitié étaient des mots de classes fermées. Nous avons complété les

2. Notre programme exploite un wrapper pour Python qui permet d’interroger SRILM (Madnani, 2009). Voir
h1:1:p://wwmdesilinguist.org.

75

listes d’artic1es, de déterminants démonstratifs et possessifs et de pronoms, ajoutant 32 mots a la
liste. Une légére diminution du WER a été observée, a trés faible co1"1t.

Seed I'I' WER (%) SER (%) BLEU
Baseline 2 1, 01 62, 29 0, 5683
Topword Non 3 1,87 75,42 0,4202
Oui 29, 37 74, 63 0, 4382
Dis Non 3 1, 45 74, 98 0, 4237
Our 28, 92 74, 36 0, 4456
Disz Non 14, 05 53, 92 0, 7169
Oui 12, 22 48, 63 0, 7468
Dis3 Non 12, 78 49, 96 0, 7394
0111 1 1,05 43,88 0, 7674

TABLE 1 — Inﬂuence de Seed et de Insert_tr

Les scores qu’offrent différentes variantes de la fonction Seed sont présentées dans la table 1.
Pour chacune des techniques, deux variantes de la fonction Neighborhood sont évaluées. Chacune
comprend les opérations Swap et Insert_sp, mais nous activons et désactivons l’opération Insert_tr
(indiqué dans la colonne IT). En ce qui concerne les variantes de Seed, Topword choisit simplement
le mot cible le plus probable pour chaque mot source. Dis utilise le décodage Viterbi au moyen
de Disambig, mais n’exploite aucun modéle de langue, seulement un modéle de traduction. Dis2
exploite un modéle de langue bigramme et Dis3, un modéle trigramme. Enﬁn, pour déterminer
le baseline, nous conservons simplement le texto de départ.

Les résultats montrent que les techniques na’ives de génération de la normalisation initiale
offrent des scores trés pauvres, Topword et Dis obtenant des résultats a peu pres équivalents. Or,
lorsqu’on fournit un modele de langue ‘a Disambig, les scores deviennent nettement meilleurs.
Cela suggére que cette implémentation de l’algorithme nécessite une normalisation initiale d’une
certaine qualité.

Nous avons également évalué la fonction Replace, qui parcourt les mots de la source, extrait tous
les équivalents du modéle de traduction, cherche la traduction du mot source dans la traduction
courante, et la remplace par chacun des équivalents. Nous l’avons implémentée dans la version du
programme qui obtient les meilleurs résultats, c’est-a-dire Dis3 avec Insert_tr, et le taux d’erreurs
moyen par phrase ne diminue pas; au contraire, il augmente d’environ 4 %, et le score BLEU
diminue de 2 %. Il semble donc que l’opération Replace n’est pas bénéﬁque, du moins lorsque les
normalisations initiales sont de bonne qualité. Nous montrerons dans la section suivante que le
contraire est vrai lorsque celles-ci sont moins bonnes.

4.2 Amélioration des normalisations générées naivement
Ayant identiﬁé une combinaison de fonctions qui produit des résultats satisfaisants, nous cher-

chons a vérifier dans quelle mesure l’algorithme vorace de recherche améliore la qualité des
normalisations fournies par la fonction Seed la plus naive, c’est-‘a-dire Topword.

76

La table 2 présente les résultats de cette évaluation. Dis3 indique les résultats qu’on obtient
simplement en laissant ‘a Disambig le soin de choisir la meilleure normalisation étant donné un
modéle de traduction et un modéle de langue trigramme. Greedy_search désigne l’implémentation
de l’algorithme qui obtient les meilleurs résultats : Dis3 est utilisé pour la traduction initiale, et
la fonction Neighborhood comprend les opérations Swap, Insert_sp et Insert_tr. TW indique les
résultats qu’on obtient par la méthode Topword, sans application de l’algorithme vorace. Par la
suite, on montre comment la performance de l’algorithme vorace varie ‘a mesure qu’on ajoute
des opérations a la fonction Neighborhood : on désigne Swap par SW, Insert_sp par IS, Insert_tr
par IT et Replace par RE.

Les résultats montrent que l’algorithme vorace n’amé1iore pas énormément la qualité des norma-
lisations produites par Dis3, qui sont déja beaucoup plus proches des normalisations de référence.
Or, nous arrivons tout de méme a réduire le taux d’erreurs moyen par phrase (WER) de presque
moitié et a augmenter le score BLEU d’environ 35 % par rapport au baseline.

Si l’apport de l’algorithme vorace n’est pas énorme lorsque les normalisations initiales sont bonnes,
il devient considérable lorsque celles-ci sont générées grossiérement. Les normalisations générées
par Topword s’éloignent nettement des normalisations de référence, et Swap et Insert_sp ne les
améliorent pas. Par contre, Replace (et dans une moindre mesure Insert_tr) est trés bénéﬁque,
offrant une réduction du taux d’erreurs moyen de l’ordre de 40 % et une augmentation du score
BLEU d’environ 47 %. Ces gains sont attribuables, du moins en partie, au r6le que joue le modéle
de langue, qui permet par ailleurs d’améliorer les normalisations générées par Dis, comme nous
1’avons vu. Malgré ces gains, nous obtenons des meilleurs résultats lorsque les normalisations de
départ sont déj‘a de bonne qualité, intégrant un modele de langue. Rappelons aussi que, lorsque
les normalisation initiales sont bonnes, Replace n’a pas un effet favorable. Il nous semble que ces
observations correspondent aux intuitions qu’on peut avoir par rapport ‘a cette approche de la
traduction (ou normalisation).

4.3 Evaluation sur le corpus de test

Les résultats de l’évaluation ﬁnale, effectuée sur le corpus de test, sont présentés dans la table 3.
Nous évaluons le systéme qui fournit les meilleurs résultats sur le corpus de développement : la
normalisation de départ est générée par Dis3, et la fonction Neighborhood utilise les opérations
Swap, Insert_sp et Insert_tr pour générer des nouvelles hypotheses. Tout d’abord, on observe que
les textos contiennent une proportion nettement plus élevée de formes non standard que ceux

Mét.hode WER (%) SER (%) BLEU
Baseline 2 1, 01 62, 29 0, 5683
Dis3 13,01 51,98 0, 7230
Greedy_search 1 1, 05 43, 88 0, 7674
TW 30,42 75,51 0,4051
TW+SW+IS 3 1, 87 75, 42 0, 4202
TW+SW+IS+IT 29, 37 74, 63 0, 4382
TW+SW+IS+IT+RE 17, 78 51, 81 0, 5947

TABLE 2 — Impact de l’algorithme vorace de recherche

77

WER SER BLEU
Baseline 28,90 68,60 0,4677
Greedy_search 19,32 57,70 0,6189

TABLE 3 — Evaluation sur le corpus de test

du corpus de développement, le WER étant 37, 6 % plus élevé. Ainsi, le WER des normalisations
produites passe de 11, 05 % (sur le corpus de développement) a 19,32 %. De plus, la diminution
du WER observée en test, de 33 %, est inférieure ‘a la diminution observée pendant la phase
de développement (47 %). Or, si toute différence de WER de 30 % est considérée signiﬁcative
(Yvon, 2008), il mérite d’étre souligné que nos résultats dépassent ce seuil. En ce qui concerne le
score BLEU, le score des normalisations produites est beaucoup plus faible lorsqu’on évalue sur
le corpus de test, mais l’augmentation du score BLEU (32 %) est cohérente avec celle que nous
avons observée pendant le développement (35 %).

5 Conclusion

Dans ce travail, nous avons mis en application un algorithme de recherche vorace utilisé en
traduction statisﬁque dans le but de normaliser des textos. L’accent a été placé sur les fonctions
qui génerent la normalisation initiale et aux opérations permettant de générer des nouvelles
hypotheses.

L’approche qui obtient les meilleurs résultats consiste ‘a générer la normalisation initiale par
décodage de type Viterbi a partir des modéles de traduction et de langue ; a utiliser les opérations
d’alternance et d’insertion de mots aﬁn de générer des nouvelles hypotheses; et 21 maximiser la
foncﬁon de score. Cette méthode engendre une diminution du taux d’erreurs moyen par phrase
de 33 % lors de l’évaluat1'on ﬁnale, et une augmentation du score BLEU de plus de 30 %.

L’opération Replace, qui consiste a remplacer des mots dans la normalisation courante par d’autres
équivalents tirés du modéle de traduction, n’a pas un effet bénéﬁque lorsque les normalisations
initiales sont de bonne qualité. Or, lorsque celles-ci sont générées par une simple recherche locale
du mot cible le plus probable pour chaque mot source, l’opération Replace permet d’améliorer la
qualité des normalisations, notamment grace a l’apport du modéle de langue.

Ces techniques simples fournissent des résultats qui nous semblent intéressants. Il nous pa-
rait donc proﬁtable de traiter la normalisation des textos comme un probleme de traduction
intralinguistique.

Remerciements

Nous désirons remercier Philippe Langlais, ainsi que les relecteurs, pour leurs commentaires
et leurs suggestions sur ce travail. Nous remercions M. Langlais ainsi que Fabrizio Gotti pour
les ressources mises ‘a notre disposition. Nous remercions également le Fonds de recherche du
Québec — Société et culture pour son soutien ﬁnancier.

78

Références

Aw, A., ZHANG, M., X1Ao, J. et SU, J. (2006). A Phrase-Based Statistical Model for SMS Text
Normalization. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages
33-40, Sydney (Australie). Association for Computational linguistics.

BEAUFORT, R., ROEKHAUT, S., COUGNON, L.-A. et FAIRON, C. (2010). A Hybrid Rule/Model-Based
Finite-State Framework for Normalizing SMS Messages. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguistics, pages 770-779, Uppsala (Suede).
Association for Computational Linguistics.

BROWN, P. F., DELLA PIETRA, V J., DELLA PIETRA, S. A. et MERCER, R. L. (1993). The Mathematics
of Statistical Machine Translation : Parameter Estimation. Computational Linguistics, 19(2) :263—
311.

KoBUs, C., YvoN, F. et DAMNATI, G. (2008). Normalizing SMS : are Two Metaphors Better than
One ? In Proceedings of the 22nd International Conference on Computational Linguistics (Coling
2008), pages 4414148, Manchester (Angleterre). Coling 2008 Organizing Committee.
LANGLAIS, R, DROUIN, R, PAULUs, A., BRODEUR, E. R. et COTTIN, F. (‘a paraitre, 2012).
Texto4science : a Quebec French Database of Annotated Short Text Messages. In Proceedings of
Language Resources and Evaluation Conference (LREC) 2012, Istanbul (Turquie). ELRA.

LANGLAIS, R, PATRY, A. et GOTTI, E (2007). A Greedy Decoder for Phrase-Based Statistical
Machine Translation. In Proceedings of the 1 1th International Conference on Theoretical and
Methodological Issues in Machine Translation, pages 104-113, Skovde (Suede).

MADNANI, N. (2009). Querying and Serving N-gram Language Models with Python. The Python
Papers, 4(2).

PAPINENI, K., RoUKos, S., WARD, T. et ZHU, W.-J. (2001). Bleu : A Method for Automatic
Evaluation of Machine Translation. Rapport technique RC22176 (W0109-022), IBM Research
Division, Thomas J. Watson Research Center.

SroLcKE, A. (2002). SRILM — An Extensible Language Modeling Tool.kit. In Proceedings of ICSLP,
Denver (Etats-Unis).

YvoN, F. (2008). Reorthography of SMS Messages. Rapport technique 2008-18, l.IMSI-CNRS.

79

