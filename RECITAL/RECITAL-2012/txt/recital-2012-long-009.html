<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Pr&#233;mices d&#8217;une analyse syntaxique par transition pour des structures de d&#233;pendance non-projectives</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 3: RECITAL, pages 81&#8211;94,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Pr&#233;mices d&#8217;une analyse syntaxique par transition pour des
structures de d&#233;pendance non-projectives
</p>
<p>Boris Karlov1, Oph&#233;lie Lacroix2
(1) Universit&#233; de Tver, 33, rue Zheliabov, 170000, Tver, Russie
</p>
<p>(2) LINA, 2, rue de la Houssini&#232;re 44322 Nantes Cedex 3
bnkarlov@gmail.com
</p>
<p>ophelie.lacroix@univ-nantes.fr
</p>
<p>R&#201;SUM&#201;
L&#8217;article pr&#233;sente une extension de l&#8217;analyseur traditionnel en d&#233;pendances par transitions adapt&#233;
aux d&#233;pendances discontinues et les premiers r&#233;sultats de son entra&#238;nement sur un corpus de
structures de d&#233;pendances de phrases en fran&#231;ais. Les r&#233;sultats des premi&#232;res exp&#233;rimentations
vont servir de base pour le choix des traits des configurations de calcul bien adapt&#233;s aux
d&#233;pendances discontinues pour am&#233;liorer l&#8217;apprentissage des d&#233;pendances t&#234;te.
</p>
<p>ABSTRACT
Beginnings of a Transition-Based Parsing for Non-Projectives Dependency Structures
</p>
<p>This paper presents an extension of the traditional transition-based dependency parser adapted
to discontinuous dependencies and the first results of its training on a dependency tree corpus
of French. The first experimental results will be useful for the choice of parsing configuration
features well adapted to discontinuous dependencies in order to ameliorate learning of head
dependencies.
</p>
<p>MOTS-CL&#201;S : analyse syntaxique par transitions, structure de d&#233;pendance non-projective,
grammaire cat&#233;gorielle de d&#233;pendance.
</p>
<p>KEYWORDS: transition-based parsing, non-projective dependency structure, dependency catego-
rial grammar.
</p>
<p>1 Introduction
</p>
<p>Il existe diff&#233;rentes m&#233;thodes d&#8217;analyses syntaxiques permettant de traiter les phrases du fran&#231;ais.
Ces analyses peuvent &#234;tre syntagmatiques (par constituants) (Kow et al., 2006; Vanrullen et al.,
2006) ou en d&#233;pendance (Nasr, 2004; Brunet-Manquat, 2005; Alfared et al., 2011). Elles peuvent
&#234;tre guid&#233;es par les r&#232;gles d&#8217;une grammaire (probabiliste ou non) ou &#234;tre entain&#233;es sur un corpus.
Depuis plusieurs ann&#233;es, les diff&#233;rentes m&#233;thodes d&#8217;analyses en d&#233;pendance (voir (K&#252;bler et al.,
2009)) gagnent en inter&#234;t dans le domaine de l&#8217;analyse syntaxique. Dans cet article nous nous
pla&#231;ons dans le cas d&#8217;une analyse syntaxique en d&#233;pendance, par transition, entra&#238;n&#233;e sur un
corpus correct par rapport &#224; une grammaire de d&#233;pendance (Alfared et al., 2011).
Les m&#233;thodes d&#8217;analyses en d&#233;pendance permettent de produire des repr&#233;sentations d&#8217;une phrase
plus expressives s&#233;mantiquement que celles par constituant. D&#8217;autres formalismes comme les
grammaires d&#8217;arbres adjoints sont parfois utilis&#233;s pour prendre en compte l&#8217;aspect s&#233;mantique
</p>
<p>81</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>des phrases, mais ne permettent pas, par exemple, de r&#233;v&#233;ler la relation de cor&#233;f&#233;rence (Candito
et Kahane, 1998). La repr&#233;sentation des phrases en structure de d&#233;pendance que nous avons
choisi de mettre en avant ici, nous permet d&#8217;exprimer certaines relations qui ne sont pas toutes
consid&#233;r&#233;es dans les m&#233;thodes classiques par constituants. La figure 1 pr&#233;sente, entre autres,
la relation distante existante entre les mots &quot;moins&quot; et &quot;que&quot; que l&#8217;on peut trouver lors d&#8217;une
comparaison.
</p>
<p>Il boit moins d' eau qu' avant .
REL
PUNCT
</p>
<p>CONJ
</p>
<p>#&#8600;REL
</p>
<p>OBJ
DETCOMPARPRED
</p>
<p>FIGURE 1 &#8211; Structure de d&#233;pendance de la phrase &quot;Il boit moins d&#8217;eau qu&#8217;avant.&quot;
</p>
<p>Il est donc possible de d&#233;finir des d&#233;pendances crois&#233;es. Cependant une telle repr&#233;sentation (dite
non-projective, voir la section 2.1) est peu utilis&#233;e dans le domaine de l&#8217;analyse en d&#233;pendance
pour les phrases en fran&#231;ais. Les analyses en d&#233;pendances courantes se basent principalement sur
le m&#234;me mod&#232;le que les analyses par constituants pour leur lien plus &#233;vident avec les grammaires
formelles. Certains travaux consistent d&#8217;ailleurs &#224; convertir des corpus annot&#233;s par constituants
en corpus de d&#233;pendance (Candito et al., 2009). Ce genre d&#8217;analyse produit donc des structures
de d&#233;pendances projectives (sans d&#233;pendances crois&#233;es), proches des arbres syntagmatiques. On
parle alors dans ce cas d&#8217;arbre de d&#233;pendance. N&#233;anmoins, tout le potentiel des structures de
d&#233;pendances n&#8217;est pas exploit&#233; lors d&#8217;une telle conversion. Comme le souligne (Rambow, 2010),
une perte d&#8217;information serait in&#233;vitablement constat&#233;e si on tentait de convertir une structure
de d&#233;pendance en structure par syntagme.
D&#8217;autre part, d&#8217;apr&#232;s (Nivre, 2011), les analyses du type analyse tabulaire (bas&#233;e sur les premiers
algorithmes tel que CKY ou Earley, voir (K&#252;bler et al., 2009)) ou analyse par satisfaction de
contraintes (Maruyama, 1990) ne sont pas bien adapt&#233;es aux structures de d&#233;pendance non-
projectives que nous souhaitons traiter. Le probl&#232;me devient d&#8217;une complexit&#233; trop grande ou
NP-complet. Les analyses par transition sur des structures de d&#233;pendance projectives pour des
phrases en anglais donnent de bons r&#233;sultats et l&#8217;adaptation aux structures de d&#233;pendance non-
projectives se fait en une complexit&#233; au pire quadratique. R&#233;cemment, (Choi et Palmer, 2011)
effectuent une analyse par transition sur des d&#233;pendances non-projectives pour des phrases
en anglais. (Alfared et al., 2011) travaillent sur un analyseur syntaxique semi-automatique
permettant de produire des structures de d&#233;pendances projectives et non-projectives sur des
phrases en fran&#231;ais. Nous nous appuierons ici sur la grammaire cat&#233;gorielle de d&#233;pendance
qu&#8217;ils utilisent, (Dikovsky, 2011), pour d&#233;finir les d&#233;pendances crois&#233;es existantes dans les
structures de d&#233;pendance non-projectives. Nous allons alors pr&#233;senter l&#8217;analyseur syntaxique par
transition, que nous avons d&#233;velopp&#233;, permettant de d&#233;finir des structures de d&#233;pendance non
n&#233;cessairement projectives pour des phrases en fran&#231;ais.
</p>
<p>82</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>2 Structures de d&#233;pendance
</p>
<p>Une structure de d&#233;pendance repr&#233;sente le r&#233;sultat d&#8217;une analyse en d&#233;pendance pour une phrase
donn&#233;e. Ces structures permettent de mettre en &#233;vidence les relations binaires entre les mots
d&#8217;une phrase telles que les relations sujet-verbe, verbe-objet, etc. Les structures de d&#233;pendance
sont &#224; diff&#233;rencier des structures syntagmatiques qui sont le r&#233;sultat d&#8217;une analyse par consti-
tuants. Mel&#8217;cuk met en &#233;vidence les diff&#233;rences, les avantages et les inconv&#233;nients de ces deux
m&#233;thodes d&#8217;analyses dans (Mel&#8217;cuk, 1988) et propose la th&#233;orie &quot;Sens-Texte&quot; qui r&#233;v&#232;le l&#8217;aspect
s&#233;mantique des d&#233;pendances entre les mots. Il met en avant, en outre, le fait que les structures
de d&#233;pendances profondes sont invariantes selon l&#8217;ordre des mots dans la phrase. Ces id&#233;es sont
aussi reprises plus r&#233;cemment par (Kahane, 2001). Ici nous travaillons sur l&#8217;analyse des struc-
tures de d&#233;pendance de surface qui ont la particularit&#233; de garantir l&#8217;ordre des mots dans la phrase.
</p>
<p>2.1 Projectivit&#233;, non-projectivit&#233;
</p>
<p>De mani&#232;re th&#233;orique, une structure de d&#233;pendance est un graphe orient&#233; dont les noeuds
sont les mots de la phrase &#224; analyser et les arcs repr&#233;sentent les d&#233;pendances reliant ces mots.
Dans une structure de d&#233;pendance, la relation de dominance est importante. Un mot domine de
mani&#232;re directe ses subordonn&#233;s, mais il domine aussi les subordonn&#233;s de ses subordonn&#233;s de
mani&#232;re transitive. Ainsi dans toute phrase la racine domine tous les mots. Un mot dominant est
appel&#233; un gouverneur.
Une structure de d&#233;pendance peut &#234;tre projective ou non. Une structure est projective si pour
chaque mot w tous les mots qui se trouvent entre w et ses subordonn&#233;s sont aussi domin&#233;s par
w, comme illustr&#233; par la figure 2. Par ailleurs, les figures 1 et 3 pr&#233;sentent des structures de
d&#233;pendances non-projectives. En effet, dans le cas de la figure 3, les mots &quot;attend&quot;, &quot;son&quot; et &quot;mari&quot;
sont compris entre le mot &quot;Elle&quot; et son subordonn&#233; &quot;press&#233;e&quot; mais ne sont pas des subordonn&#233;s de
&quot;Elle&quot;, la structure n&#8217;est donc pas projective.
</p>
<p>La nature fait bien les choses .
</p>
<p>PUNCT
OBJ
DETRESTRICTPREDDET
</p>
<p>FIGURE 2 &#8211; Structure de d&#233;pendance de la phrase &quot;La nature fait bien les choses.&quot;
</p>
<p>2.2 Repr&#233;sentation utilis&#233;e
</p>
<p>Les arcs repr&#233;sentant les d&#233;pendances sont de trois sortes diff&#233;rentes : projectifs, discontinus ou
ancres. Les d&#233;pendances projectives sont des d&#233;pendances locales (courtes) qui ne se croisent
pas les unes avec les autres. Les d&#233;pendances discontinues sont les d&#233;pendances non-projectives
distantes qui peuvent croiser les d&#233;pendances projectives. Et les ancres sont des d&#233;pendances lo-
cales permettant de lier localement une d&#233;pendance discontinue. Effectivement, les subordonn&#233;s
</p>
<p>83</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Elle attend son mari , press&#233;e de partir .
</p>
<p>MODIF PUNCT
</p>
<p>INFPRE-INF
</p>
<p>#&#8600;MODIF
</p>
<p>PUNCT
OBJ
DETPRED
</p>
<p>FIGURE 3 &#8211; Structure de d&#233;pendance de la phrase &quot;Elle attend son mari, press&#233;e de partir.&quot;
</p>
<p>des d&#233;pendances ancres sont aussi subordonn&#233;s via des d&#233;pendances discontinues. Ces ancres
sont importantes pour d&#233;finir la grammaire pr&#233;sent&#233;e ensuite. La figure 3 permet d&#8217;illustrer
chaque sorte d&#8217;arc &#233;nonc&#233; ci-dessus. Dans cette figure, la d&#233;pendance discontinue est de type
modificateur (le participe pass&#233; &quot;press&#233;e&quot; est bien rattach&#233; au pronom personnel &quot;Elle&quot;). Les
d&#233;pendances discontinues, comme MODI F 1 sont indiqu&#233;es au dessus de la phrase tandis que
les d&#233;pendances ancres li&#233;es aux d&#233;pendances discontinues, comme&#8601; MODI F , sont indiqu&#233;es
au dessous de la phrase. La n&#233;gation, la r&#233;fl&#233;xivit&#233;, l&#8217;apposition et l&#8217;aggr&#233;gation, parmi d&#8217;autres
types de d&#233;pendances, peuvent aussi engendrer des d&#233;pendances discontinues.
</p>
<p>2.3 Grammaire cat&#233;gorielle de d&#233;pendance (CDG)
</p>
<p>(Dekhtyar et Dikovsky, 2008) exposent une m&#233;thode pour repr&#233;senter les d&#233;pendances en
cat&#233;gories comme dans les grammaires cat&#233;gorielles classiques (Bar-Hillel et al., 1964). Cette
grammaire a permis &#224; (Alfared et al., 2011) de produire le corpus que nous utiliserons ensuite
pour notre analyse (voir section 4.1). L&#8217;id&#233;e est de repr&#233;senter les d&#233;pendances projectives et les
d&#233;pendances ancres par des cat&#233;gories qui sont les types de ces d&#233;pendances et les d&#233;pendances
non-projectives par des valences polaris&#233;es. Sur une phrase comme celle donn&#233;e en exemple dans
la figure 4, on aura pour chaque mot les cat&#233;gories suivantes : il 7&#8594; &#2;pred&#3;, y 7&#8594; [#&#8601; cl i t]&#8601;cl i t ,
est 7&#8594; &#2;#&#8601; cl i t\pred\S/punct/aux&#3;, all&#233; 7&#8594; [aux]&#8598;cl i t , . 7&#8594; &#2;punct&#3;.
</p>
<p>Il y est all&#233; .
CLIT PUNCT
</p>
<p>AUX
</p>
<p>#&#8601;CLIT
</p>
<p>PRED
</p>
<p>FIGURE 4 &#8211; Structure de d&#233;pendance de la phrase &quot;Il y est all&#233;.&quot;
</p>
<p>Ces cat&#233;gories sont ensuite utilis&#233;es dans une grammaire cat&#233;gorielle enrichie de r&#232;gles de
d&#233;rivations, expos&#233;es dans la table 1, permettant de traiter les valences polaris&#233;es. La r&#232;gle
</p>
<p>1. MODI F est le type attribu&#233; &#224; une d&#233;pendance entre un mot et son modificateur, qui peut &#234;tre un participe ou
un adjectif. Les types de d&#233;pendances utilis&#233;s dans ces structures sont ceux employ&#233;s par (Alfared et al., 2011) pour
construire leur corpus. Par ailleurs, les d&#233;pendances utilis&#233;es dans les figures de cet article sont &#233;tiquet&#233;es par les noms
des groupes de d&#233;pendances auxquelles elles appartiennent (voir section 3.4) pour une illustration plus simple.
</p>
<p>84</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L permet d&#8217;&#233;liminer les cat&#233;gories comme dans les grammaires cat&#233;gorielles classiques, et de
concat&#233;ner les valences polaris&#233;es en une cha&#238;ne que l&#8217;on appelle potentiel. Pour la r&#232;gle I, les
valences sont trait&#233;es de la m&#234;me mani&#232;re tandis que la d&#233;rivation s&#8217;effectue sur les cat&#233;gories
it&#233;rables. De m&#234;me, la r&#232;gle &#8486; permet d&#8217;&#233;liminer une cat&#233;gorie it&#233;rable en conservant le potentiel
tel qu&#8217;il &#233;tait. Puis l&#8217;&#233;limination des valences dans la d&#233;rivation (r&#232;gle D) se fait sur le principe FA
(First Available). Tout d&#8217;abord, des valences duales sont des valences de m&#234;me cat&#233;gorie dont
les polarit&#233;s sont&#8601; et&#8598;, ou&#8599; et&#8600;. Le principe FA indique que les valences duales les plus
proches dans un potentiel sont des paires. Alors dans un potentiel P1(&#8601; C)P(&#8598; C)P2, si (&#8601; C)
et (&#8598; C) (valences duales) n&#8217;apparaissent pas dans P, (&#8601; C) et (&#8598; C) satisfont le principe FA.
</p>
<p>L1 C P1
&#2;
</p>
<p>C\&#946;&#3;P2 ` &#2;&#946;&#3;P1 P2
I1 C P1
</p>
<p>&#2;
C&#8727;\&#946;&#3;P2 ` &#2;C&#8727;\&#946;&#3;P1 P2
</p>
<p>&#8486;1
&#2;
</p>
<p>C&#8727;\&#946;&#3;P ` &#2;&#946;&#3;P
D1 &#945;P1(&#8601;C)P(&#8598;C)P2 ` &#945;P1 PP2 , si (&#8601; C)(&#8598; C) satisfait le principe FA
</p>
<p>TABLE 1 &#8211; R&#232;gles de la grammaire cat&#233;gorielle de d&#233;pendance g&#233;n&#233;ralis&#233;e
</p>
<p>Un exemple d&#8217;arbre de d&#233;rivation, utilisant les valences polaris&#233;es pour les d&#233;pendances disconti-
nues, d&#233;riv&#233; de la phrase &quot;Il y est all&#233;.&quot; est pr&#233;sent&#233; par la figure 5.
</p>
<p>Il y est all&#233; .
PRED #&#8601;CLIT&#8601;CLIT #&#8601;CLIT\PRED\S/PUNCT/AUX PUNCT
</p>
<p>#&#8601;CLIT\PRED\S/PUNCT &#8601;CLIT
</p>
<p>PRED\S/PUNCT
S/PUNCT
</p>
<p>S
</p>
<p>AUX&#8601;CLIT
</p>
<p>FIGURE 5 &#8211; Arbre de d&#233;rivation utilisant la CDG sur la phrase &quot;Il y est all&#233;.&quot;
</p>
<p>3 Analyse par transition
</p>
<p>Comme expliqu&#233; par (Nivre, 2008), une structure de d&#233;pendance peut &#234;tre traduite en une
suite de transitions. Le but d&#8217;un analyseur syntaxique par transition est de trouver une suite de
transitions (op&#233;rations sur les configurations de calcul de l&#8217;analyseur) qui permette de construire
une structure de d&#233;pendance correcte pour une phrase donn&#233;e. Pour faire ce travail, l&#8217;analyseur
syntaxique doit s&#8217;appuyer sur un oracle qui lui indique quelle transition appliquer dans telle ou
telle configuration. Les configurations et transitions sont des &#233;l&#233;ments essentiels de l&#8217;analyse par
transition, qui peuvent varier selon l&#8217;utilisation que l&#8217;on veut en faire. K&#252;bler, Donald et Nivre
d&#233;finissent clairement leurs emplois dans (K&#252;bler et al., 2009). Ici nous pr&#233;sentons un analyseur
</p>
<p>85</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>par transition adapt&#233; aux d&#233;pendances discontinues, que nous avons d&#233;velopp&#233;. Le travail
consiste tout d&#8217;abord &#224; g&#233;n&#233;rer un oracle &#224; partir d&#8217;un corpus de r&#233;f&#233;rence. Chaque structure de
d&#233;pendance du corpus est traduite en un ensemble de couples configuration-transition qui sont
ajout&#233;es &#224; l&#8217;oracle selon le nombre d&#8217;occurences d&#8217;une transition pour une configuration 2 donn&#233;e.
L&#8217;oracle enregistre donc seulement la meilleure transition possible pour une configuration. Cet
oracle sera alors utilis&#233; pour d&#233;terminer une suite de transitions &#224; appliquer, pour chaque
phrase &#224; analyser, permettant de construire des structures de d&#233;pendance. L&#8217;analyseur est donc
d&#233;terministe car il s&#8217;appuie sur l&#8217;oracle pour choisir la transition &#224; appliquer &#224; chaque &#233;tape de
l&#8217;analyse.
</p>
<p>3.1 Configurations
</p>
<p>Une configuration, pour une phrase, est un &quot;&#233;tat&quot; dans lequel est l&#8217;analyseur syntaxique analysant
cette phrase. On peut y appliquer une transition qui permettra de passer dans la configuration
suivante.
Soit une phrase s = w1w2...wn. Une configuration pour une phrase est un quintuplet (&#963;,&#946; ,&#952; , i, E)
o&#249; &#963; est une pile de mots wi dans s, &#946; est un tampon de mots wi dans s, &#952; est un tampon de
valences (un potentiel), i est la position du mot courant, et E est un ensemble d&#8217;arcs (wi , r, t, w j)
o&#249; r est l&#8217;&#233;tiquette de l&#8217;arc (le type de la d&#233;pendance) et t est la sorte de l&#8217;arc (projectif, discontinu,
ancre). La configuration initiale c0 pour chaque phrase est :
</p>
<p>([] ,
&#2;
</p>
<p>w1, ..., wn
&#3;
</p>
<p>, [] , 1,;).
La configuration finale, pour n&#8217;importe quel &#963; et E, est :
</p>
<p>(&#963;, [] , [] , n+ 1, E).
</p>
<p>3.2 Transitions
</p>
<p>Les transitions sont des op&#233;rations s&#8217;appliquant aux configurations pour obtenir les configurations
suivantes. Celles-ci sont pr&#233;sent&#233;es dans la table 2. Ces transitions se basent sur les transitions
&#233;voqu&#233;es par (K&#252;bler et al., 2009). Nous y ajoutons des &#233;l&#233;ments permettant de traiter les
structures de d&#233;pendances projectives aussi bien que les structures non-projectives. En effet, la
transition PutPotential ajoute les valences polaris&#233;es dans le potentiel &#952; selon les r&#232;gles de la table
1 de la grammaire cat&#233;gorielle de d&#233;pendance vu &#224; la section 2.3. Puis les transitions DistLeft et
DistRight permettent de d&#233;finir les d&#233;pendances discontinues de la structure de d&#233;pendance en
&#233;liminant les valences duales du potentiel &#952; , suivant la r&#232;gle D. En outre, les transitions LocalLeft
et LocalRight servent &#224; d&#233;finir les d&#233;pendances projectives ainsi que les d&#233;pendances ancres. Les
ancres permettent de d&#233;tecter les subordonn&#233;s discontinus.
Pour convertir une structure de d&#233;pendance en une suite de transitions, on utilise un algorithme
qui applique les transitions dans un certain ordre. Pour cela, on consid&#232;re toujours le mot en haut
de la pile &#963; comme le mot courant de la configuration. L&#8217;algorithme essaie d&#8217;abord de trouver les
d&#233;pendances discontinues de la structure. Donc dans un premier temps, il tente d&#8217;ajouter une
valence dans le potentiel &#952; en appliquant la transition PutPotential si le mot courant est impliqu&#233;
</p>
<p>2. Une configuration est repr&#233;sent&#233;e par un vecteur de traits : image de taille r&#233;duite de la configuration, voir section
3.4
</p>
<p>86</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>dans une d&#233;pendance discontinue. Puis on applique les transitions DistLeft et DistRight, pour
d&#233;finir les d&#233;pendances distantes trouv&#233;es, jusqu&#8217;&#224; ce qu&#8217;il n&#8217;y ait plus de valences duales. Ensuite
l&#8217;algorithme traite les d&#233;pendances locales. Il commence donc par appliquer toutes les transitions
LocalLeft possible pour le mot courant, de son subordonn&#233; le plus proche au plus &#224; gauche. Puis
si ce mot a des d&#233;pendances &#224; droite, on le garde sur la pile et on applique la transition Put pour
empiler le mot suivant sur &#963;. N&#233;anmoins, si le mot courant n&#8217;a pas de subordonn&#233; droit et a
un gouverneur sur la gauche alors il est possible d&#8217;appliquer la transition LocalRight. Le dernier
cas possible est si le mot courant n&#8217;a plus aucun subordonn&#233; sur la droite et n&#8217;a pas non plus de
gouverneur. Alors il s&#8217;agit de la racine et le processus est termin&#233;.
</p>
<p>Transition Effet de son application sur une configuration
</p>
<p>PutPotential (&#963;, wk | &#946; ,&#952; , k, E)&#8658; (&#963;, wk | &#946; ,&#952; pk1...pkm, k+ 1, E)
(p1, ..., pm) o&#249; les p j sont des valences.
</p>
<p>Put (&#963;, wi | &#946; ,&#952; , k, E)&#8658; (&#963; | wi ,&#946; ,&#952; , nex t(k, i), E)
o&#249; nex t(k, l) =
</p>
<p>&#26;
k+ 1 si k = l
k sinon
</p>
<p>LocalLeft(d) (&#963; | wi , w j | &#946; ,&#952; , k, E)&#8658; (&#963;, w j | &#946; ,&#952; , k, E &#8746; {(wi , d, T Y PE(d), w j)})
LocalRight(d) (&#963; | wi , w j | &#946; ,&#952; , k, E)&#8658; (&#963;, wi | &#946; ,&#952; , nex t(k, j), E &#8746; {(wi , d, T Y PE(d), w j)})
DistLeft(v) (&#963;,&#946; ,&#952;1&#8601; v i&#952;2&#8598; v j&#952;3, k, E)&#8658; (&#963;,&#946; ,&#952; , k, E &#8746; {(w j , v, discontinuous, wi)})
</p>
<p>si&#8601; v i &#8598; v j est la paire la plus &#224; gauche satisfaisant la condition FA.
DistRight(v) (&#963;,&#946; ,&#952;1&#8599; v i&#952;2&#8600; v j&#952;3, k, E)&#8658; (&#963;,&#946; ,&#952; , k, E &#8746; {(wi , v, discontinuous, w j)})
</p>
<p>si&#8599; v i &#8600; v j est la paire la plus &#224; gauche satisfaisant la condition FA.
TABLE 2 &#8211; Les transitions utilis&#233;es par l&#8217;analyseur
</p>
<p>3.3 Exemple de conversion
</p>
<p>Pour illustrer la m&#233;thode de conversion d&#8217;une structure de d&#233;pendance en s&#233;quence de transitions
voici un exemple pour la phrase &quot;Cette victoire, elle l&#8217;a m&#233;rit&#233;e.&quot; dont la structure de d&#233;pendance
est pr&#233;sent&#233;e par la figure 6. Cette phrase comprend des d&#233;pendances discontinues de type
clitique et cor&#233;f&#233;rence. La suite de transitions appliqu&#233;es &#224; cette phrase et les &#233;l&#233;ments de chaque
configuration en d&#233;coulants sont illustr&#233;s dans la table 3.
</p>
<p>87</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Tr
an
</p>
<p>si
ti
</p>
<p>on
Pi
</p>
<p>le
&#963;
</p>
<p>Ta
m
</p>
<p>po
n
</p>
<p>&#946;
Po
</p>
<p>te
nt
</p>
<p>ie
l&#952;
</p>
<p>En
se
</p>
<p>m
bl
</p>
<p>e
d&#8217;
</p>
<p>ar
cs
</p>
<p>E
[]
</p>
<p>[C
et
</p>
<p>te
,v
</p>
<p>ic
to
</p>
<p>ir
e
</p>
<p>,e
lle
</p>
<p>l&#8217;
a
</p>
<p>m
&#233;r
</p>
<p>it
&#233;e
</p>
<p>.]
[]
</p>
<p>&#8709;
Pu
</p>
<p>t
[C
</p>
<p>et
te
</p>
<p>]
[v
</p>
<p>ic
to
</p>
<p>ir
e
</p>
<p>,e
lle
</p>
<p>l&#8217;
a
</p>
<p>m
&#233;r
</p>
<p>it
&#233;e
</p>
<p>.]
[]
</p>
<p>&#8709;
Pu
</p>
<p>tP
ot
</p>
<p>en
ti
</p>
<p>al
[C
</p>
<p>et
te
</p>
<p>]
[v
</p>
<p>ic
to
</p>
<p>ir
e
</p>
<p>,e
lle
</p>
<p>l&#8217;
a
</p>
<p>m
&#233;r
</p>
<p>it
&#233;e
</p>
<p>.]
[&#8601;
</p>
<p>co
re
</p>
<p>f]
&#8709;
</p>
<p>Lo
ca
</p>
<p>lL
ef
</p>
<p>t
[]
</p>
<p>[v
ic
</p>
<p>to
ir
</p>
<p>e
,e
</p>
<p>lle
l&#8217;
</p>
<p>a
m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
.]
</p>
<p>[&#8601;
co
</p>
<p>re
f]
</p>
<p>E
=
</p>
<p>(v
ic
</p>
<p>to
ir
</p>
<p>e,
pr
</p>
<p>oj
ec
</p>
<p>ti
ve
</p>
<p>,d
et
</p>
<p>,C
et
</p>
<p>te
)
</p>
<p>Pu
t
</p>
<p>[v
ic
</p>
<p>to
ir
</p>
<p>e]
[,
</p>
<p>el
le
</p>
<p>l&#8217;
a
</p>
<p>m
&#233;r
</p>
<p>it
&#233;e
</p>
<p>.]
[&#8601;
</p>
<p>co
re
</p>
<p>f]
E
</p>
<p>Lo
ca
</p>
<p>lR
ig
</p>
<p>ht
[]
</p>
<p>[v
ic
</p>
<p>to
ir
</p>
<p>e
el
</p>
<p>le
l&#8217;
</p>
<p>a
m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
.]
</p>
<p>[&#8601;
co
</p>
<p>re
f]
</p>
<p>E
=
</p>
<p>E
&#8746;(
</p>
<p>vi
ct
</p>
<p>oi
re
</p>
<p>,p
ro
</p>
<p>je
ct
</p>
<p>iv
e,
</p>
<p>pu
nc
</p>
<p>t,
,)
</p>
<p>Pu
t
</p>
<p>[v
ic
</p>
<p>to
ir
</p>
<p>e]
[e
</p>
<p>lle
l&#8217;
</p>
<p>a
m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
.]
</p>
<p>[&#8601;
co
</p>
<p>re
f]
</p>
<p>E
Pu
</p>
<p>t
[v
</p>
<p>ic
to
</p>
<p>ir
e
</p>
<p>el
le
</p>
<p>]
[l
</p>
<p>&#8217;a
m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
.]
</p>
<p>[&#8601;
co
</p>
<p>re
f]
</p>
<p>E
Pu
</p>
<p>tP
ot
</p>
<p>en
ti
</p>
<p>al
[v
</p>
<p>ic
to
</p>
<p>ir
e
</p>
<p>el
le
</p>
<p>]
[l
</p>
<p>&#8217;a
m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
.]
</p>
<p>[&#8601;
co
</p>
<p>re
f&#8598;
</p>
<p>co
re
</p>
<p>f]
E
</p>
<p>Pu
tP
</p>
<p>ot
en
</p>
<p>ti
al
</p>
<p>[v
ic
</p>
<p>to
ir
</p>
<p>e
el
</p>
<p>le
]
</p>
<p>[l
&#8217;a
</p>
<p>m
&#233;r
</p>
<p>it
&#233;e
</p>
<p>.]
[&#8601;
</p>
<p>co
re
</p>
<p>f&#8598;
co
</p>
<p>re
f&#8601;
</p>
<p>cl
it
</p>
<p>]
E
</p>
<p>D
is
</p>
<p>tL
ef
</p>
<p>t
[v
</p>
<p>ic
to
</p>
<p>ir
e
</p>
<p>el
le
</p>
<p>]
[l
</p>
<p>&#8217;a
m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
.]
</p>
<p>[&#8601;
cl
</p>
<p>it
]
</p>
<p>E
=
</p>
<p>E
&#8746;(
</p>
<p>l&#8217;,
di
</p>
<p>sc
on
</p>
<p>ti
nu
</p>
<p>ou
s,
</p>
<p>co
re
</p>
<p>f,
vi
</p>
<p>ct
oi
</p>
<p>re
)
</p>
<p>Pu
t
</p>
<p>[v
ic
</p>
<p>to
ir
</p>
<p>e
el
</p>
<p>le
l&#8217;]
</p>
<p>[a
m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
.]
</p>
<p>[&#8601;
cl
</p>
<p>it
]
</p>
<p>E
Lo
</p>
<p>ca
lL
</p>
<p>ef
t
</p>
<p>[v
ic
</p>
<p>to
ir
</p>
<p>e
el
</p>
<p>le
]
</p>
<p>[a
m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
.]
</p>
<p>[&#8601;
cl
</p>
<p>it
]
</p>
<p>E
=
</p>
<p>E
&#8746;(
</p>
<p>a,
an
</p>
<p>ch
or
</p>
<p>,c
lit
</p>
<p>,l
&#8217;)
</p>
<p>Lo
ca
</p>
<p>lL
ef
</p>
<p>t
[v
</p>
<p>ic
to
</p>
<p>ir
e]
</p>
<p>[a
m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
.]
</p>
<p>[&#8601;
cl
</p>
<p>it
]
</p>
<p>E
=
</p>
<p>E
&#8746;(
</p>
<p>a,
pr
</p>
<p>oj
ec
</p>
<p>ti
ve
</p>
<p>,p
re
</p>
<p>d,
el
</p>
<p>le
)
</p>
<p>Lo
ca
</p>
<p>lL
ef
</p>
<p>t
[]
</p>
<p>[a
m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
.]
</p>
<p>[&#8601;
cl
</p>
<p>it
]
</p>
<p>E
=
</p>
<p>E
&#8746;(
</p>
<p>a,
an
</p>
<p>ch
or
</p>
<p>,c
or
</p>
<p>ef
,v
</p>
<p>ic
to
</p>
<p>ir
e)
</p>
<p>Pu
t
</p>
<p>[a
]
</p>
<p>[m
&#233;r
</p>
<p>it
&#233;e
</p>
<p>.]
[&#8601;
</p>
<p>cl
it
</p>
<p>]
E
</p>
<p>Pu
tP
</p>
<p>ot
en
</p>
<p>ti
al
</p>
<p>[a
]
</p>
<p>[m
&#233;r
</p>
<p>it
&#233;e
</p>
<p>.]
[&#8601;
</p>
<p>cl
it
</p>
<p>&#8598;c
lit
</p>
<p>]
E
</p>
<p>D
is
</p>
<p>tL
ef
</p>
<p>t
[a
</p>
<p>]
[m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
.]
</p>
<p>[]
E
</p>
<p>=
E
</p>
<p>&#8746;(
m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
,d
</p>
<p>is
co
</p>
<p>nt
in
</p>
<p>uo
us
</p>
<p>,c
lit
</p>
<p>,l
&#8217;)
</p>
<p>Lo
ca
</p>
<p>lR
ig
</p>
<p>ht
[]
</p>
<p>[a
.]
</p>
<p>[]
E
</p>
<p>=
E
</p>
<p>&#8746;(
a,
</p>
<p>pr
oj
</p>
<p>ec
ti
</p>
<p>ve
,a
</p>
<p>ux
,m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
)
</p>
<p>Pu
t
</p>
<p>[a
]
</p>
<p>[.
]
</p>
<p>[]
E
</p>
<p>Lo
ca
</p>
<p>lR
ig
</p>
<p>ht
[]
</p>
<p>[a
]
</p>
<p>[]
E
</p>
<p>=
E
</p>
<p>&#8746;(
a,
</p>
<p>pr
oj
</p>
<p>ec
ti
</p>
<p>ve
,p
</p>
<p>un
ct
</p>
<p>,.
)
</p>
<p>TA
B
</p>
<p>LE
3
</p>
<p>&#8211;
C
</p>
<p>on
ve
</p>
<p>rs
io
</p>
<p>n
de
</p>
<p>la
st
</p>
<p>ru
ct
</p>
<p>ur
e
</p>
<p>de
d&#233;
</p>
<p>pe
nd
</p>
<p>an
ce
</p>
<p>de
la
</p>
<p>ph
ra
</p>
<p>se
&quot;C
</p>
<p>et
te
</p>
<p>vi
ct
</p>
<p>oi
re
</p>
<p>,e
lle
</p>
<p>l&#8217;a
m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
.&quot;
</p>
<p>en
un
</p>
<p>e
su
</p>
<p>it
e
</p>
<p>de
tr
</p>
<p>an
si
</p>
<p>ti
on
</p>
<p>s
</p>
<p>Ce
tte
</p>
<p>vic
toi
</p>
<p>re
,e
</p>
<p>lle
l'a
</p>
<p>m&#233;
rit
</p>
<p>&#233;e
.
</p>
<p>CL
IT
</p>
<p>CO
RE
</p>
<p>F
@P
</p>
<p>UN
CT
</p>
<p>AU
X
</p>
<p>#&#8601;
CL
</p>
<p>IT
</p>
<p>PR
ED
</p>
<p>@P
UN
</p>
<p>CT #&#8601;
CO
</p>
<p>RE
F
</p>
<p>DE
T
</p>
<p>FI
G
</p>
<p>U
R
</p>
<p>E
6
</p>
<p>&#8211;
St
</p>
<p>ru
ct
</p>
<p>ur
e
</p>
<p>de
d&#233;
</p>
<p>pe
nd
</p>
<p>an
ce
</p>
<p>de
la
</p>
<p>ph
ra
</p>
<p>se
&quot;C
</p>
<p>et
te
</p>
<p>vi
ct
</p>
<p>oi
re
</p>
<p>,e
lle
</p>
<p>l&#8217;a
m
</p>
<p>&#233;r
it
</p>
<p>&#233;e
.&quot;
</p>
<p>88</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>3.4 Oracles
</p>
<p>L&#8217;id&#233;e de l&#8217;analyse par transition est de repr&#233;senter partiellement les &#233;l&#233;ments des configurations
(dont la taille n&#8217;est pas limit&#233;e) par les valeurs de vecteurs de traits. Le probl&#232;me du choix des
traits se pose alors. Diff&#233;rents traits peuvent &#234;tre choisis pour entra&#238;ner un oracle &#224; partir d&#8217;un
corpus de structure de d&#233;pendance. Nous exp&#233;rimentons ici avec huit vecteurs de traits diff&#233;rents.
On peut donc choisir :
&#8211; l&#8217;utilisation ou non du nom complet de la classe grammaticale affect&#233;e au mot dans les
</p>
<p>structures de d&#233;pendance
&#8211; l&#8217;utilisation ou non des groupes de d&#233;pendances &#224; la place des noms exacts des d&#233;pendances
&#8211; la taille du vecteur de traits.
</p>
<p>Pour la classe grammaticale, on peut choisir d&#8217;utiliser le nom simple (court) de la classe ou
le nom enrichi d&#8217;un param&#232;tre (long). Par exemple pour le cas d&#8217;un mot de la classe adjectif
quantificateur, le nom court correspondra &#224; Adj et le nom long &#224; Adjquantifier. La classe courte
Adj rassemble les adjectifs modificateurs, quantifiants, restrictifs, comparatifs, etc... Un autre
exemple est celui de la classe des noms (N). Elles peut regrouper les classes de noms longs
Nproper (noms propres), Ncommon (noms communs), Ntime (noms &#224; r&#233;f&#233;rence temporelle),
etc...
</p>
<p>Par ailleurs, les d&#233;pendances avec des fonctions syntaxiques proches peuvent &#234;tre regroup&#233;es
dans des groupes de d&#233;pendances. Il est alors possible de s&#233;lectionner une option traitant les
d&#233;pendances selon le groupe de d&#233;pendances auxquelles elles appartiennent ou selon leurs types
de d&#233;pendances pr&#233;cis. Par exemple pour le cas d&#8217;un mot dont la d&#233;pendance est du type objet
accusatif, on utilisera par d&#233;faut le type de d&#233;pendance complet a-obj, mais on emploiera le type
OBJ pour une repr&#233;sentation des types par groupe. Dans ce cas l&#224;, le type OBJ pourra aussi &#234;tre
assign&#233; &#224; une d&#233;pendance de type g-obj (objet g&#233;nitif), l-obj (objet locatif) ou o-obj (objet oblique).
</p>
<p>Le vecteur de trait peut &#234;tre de taille 6 ou 8. Dans les deux cas, les vecteurs de traits, pour une
configuration donn&#233;e &#224; un moment de l&#8217;analyse, sont constitu&#233;s de :
&#8211; la classe grammaticale du mot au sommet de la pile &#963;
&#8211; la classe grammaticale du premier mot du tampon &#946; de mots
&#8211; le type de la d&#233;pendance la plus &#224; gauche (c&#8217;est-&#224;-dire, dont le subordonn&#233; est le plus &#224; gauche)
</p>
<p>du mot en haut de la pile &#963; suivi de la sorte de l&#8217;arc (discontinu, projectif, ancre)
&#8211; le type de la d&#233;pendance la plus &#224; droite du mot en haut de la pile &#963; suivi de la sorte de l&#8217;arc
&#8211; la derni&#232;re valence du potentiel et son orientation
&#8211; l&#8217;avant-derni&#232;re valence du potentiel et son orientation
</p>
<p>Si le vecteur est de taille 8, il poss&#232;de les deux traits suivants en plus :
&#8211; le type de la d&#233;pendance la plus &#224; gauche du premier mot du tampon &#946; suivi de la sorte de
</p>
<p>l&#8217;arc
&#8211; le type de la d&#233;pendance la plus &#224; droite du premier mot du tampon &#946; suivi de la sorte de l&#8217;arc
Ainsi nous g&#233;n&#233;rons huit oracles diff&#233;rents, expos&#233;s dans la table 4. L&#8217;oracle 1 est ainsi le plus
g&#233;n&#233;ral et l&#8217;oracle 8 est le plus pr&#233;cis.
</p>
<p>89</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Tail le du vecteur Classe grammaticale Groupe
6 8 cour te longue oui non
</p>
<p>Oracle 1
p p p
</p>
<p>Oracle 2
p p p
</p>
<p>Oracle 3
p p p
</p>
<p>Oracle 4
p p p
</p>
<p>Oracle 5
p p p
</p>
<p>Oracle 6
p p p
</p>
<p>Oracle 7
p p p
</p>
<p>Oracle 8
p p p
</p>
<p>TABLE 4 &#8211; Les param&#232;tres des diff&#233;rents oracles
</p>
<p>4 R&#233;sultats des analyses et discussion
</p>
<p>4.1 Corpus de d&#233;pendance
</p>
<p>Le corpus utilis&#233; pour cette analyse par transition est constitu&#233; d&#8217;un ensemble de corpus de
phrases de style grammatical diff&#233;rent. Il a &#233;t&#233; annot&#233; semi-automatiquement par des membres
de l&#8217;&#233;quipe TALN du Lina et leurs associ&#233;s, en utilisant le syst&#232;me CDG Lab (Alfared et al.,
2011) et une grammaire cat&#233;gorielle du fran&#231;ais (Dikovsky, 2011). Lors de chaque analyse
syntaxique 90% du corpus est employ&#233; comme corpus d&#8217;entra&#238;nement pour produire un oracle et
les 10% restants sont exploit&#233;s par l&#8217;analyse syntaxique par transition et traduits en structures
de d&#233;pendances. Le choix des phrases utilis&#233;es pour l&#8217;apprentissage et pour l&#8217;analyse se fait
al&#233;atoirement. Le corpus complet (apprentissage et analyse) comprend 2557 structures de
d&#233;pendances dont 33490 mots. 41% des structures de d&#233;pendances de ce corpus contiennent au
moins une d&#233;pendance discontinue mais les d&#233;pendances discontinues repr&#233;sentent seulement
4% du nombre de d&#233;pendances total du corpus.
</p>
<p>4.2 M&#233;thode d&#8217;exp&#233;rimentation
</p>
<p>Les fichiers de sortie de l&#8217;analyseur sont similaires aux fichiers d&#8217;entr&#233;e, de mani&#232;re &#224; ce que l&#8217;on
puisse retrouver pour chaque phrase, les d&#233;pendances correctements assign&#233;es ou non entre les
unit&#233;s lexicales. Pour estimer les r&#233;sultats, on calculera la f-mesure sur les t&#234;tes des d&#233;pendances.
C&#8217;est &#224; dire que l&#8217;on se contentera de v&#233;rifier si chaque mot de la phrase re&#231;oit bien la d&#233;pendance
du bon type. Toutefois, les d&#233;pendances discontinues ne sont pas comptabilis&#233;es, car les mots
recevant une telle d&#233;pendance re&#231;oivent aussi une d&#233;pendance ancre du m&#234;me type. Le choix de
calculer les r&#233;sultats uniquement sur les t&#234;tes des d&#233;pendances plut&#244;t que sur les d&#233;pendances
elles-m&#234;mes d&#233;pend de deux aspects importants :
&#8211; le volume du corpus n&#8217;est pas suffisant pour l&#8217;instant pour esp&#233;rer avoir les bons assignements
</p>
<p>des d&#233;pendances et de leurs types en m&#234;me temps
&#8211; ces types de r&#233;sultats s&#8217;accordent avec des travaux futurs qui consisteront &#224; d&#233;terminer les
</p>
<p>bonnes t&#234;tes des d&#233;pendances avant d&#8217;effectuer une analyse syntaxique en d&#233;pendance &#224; partir
de la CDG.
</p>
<p>90</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Le principe est donc de collecter, pour chaque type de d&#233;pendance appara&#238;ssant dans le corpus
d&#8217;entr&#233;e ou de sortie, le nombre de fois o&#249; celui-ci est assign&#233; dans le corpus d&#8217;entr&#233;e, le nombre
de fois o&#249; celui-ci est attribu&#233; &#224; un mot du corpus de sortie et le nombre de fois o&#249; celui-ci est
attribu&#233; au bon mot dans le corpus de sortie. La table 5 donne les r&#233;sultats de ces assignations sur
une analyse d&#8217;un corpus d&#8217;analyse possible (10% du corpus total, voir section 4.1) pour certains
types de d&#233;pendances. Par exemple, le type S (la t&#234;te de la phrase) a &#233;t&#233; assign&#233; sur 38 mots,
dont 37 fois correctement, parmi les 255 mots typ&#233;s S dans le corpus. Le type DET a toujours &#233;t&#233;
assign&#233; correctement sur les 117 fois o&#249; il a &#233;t&#233; trouv&#233; pour un mot.
</p>
<p>Type des Nb d&#8217;occurences Nb d&#8217;occurences Nb d&#8217;attributions
d&#233;pendance corpus d&#8217;entr&#233;e corpus de sortie correctes
S 38 255 37
PRED 169 314 168
DET 117 331 117
OBJ 69 218 64
COPUL 22 79 21
MODIF 26 113 24
CLIT 48 124 39
PUNCT 116 404 109
</p>
<p>TABLE 5 &#8211; Exemple de r&#233;sultats d&#8217;assignements des types (pour quelques types donn&#233;s) par
comparaison entre un corpus d&#8217;entr&#233;e et de sortie
</p>
<p>Pour chaque type de d&#233;pendance i de la table ainsi &#233;tablie, on calcule la pr&#233;sicion et le rappel de
la mani&#232;re suivante :
</p>
<p>pr&#233;cisioni =
Nb d&#8217;attributions correctes pour i
</p>
<p>Nb d&#8217;occurences corpus de sortie pour i
rappeli =
</p>
<p>Nb d&#8217;attributions correctes pour i
</p>
<p>Nb d&#8217;occurences corpus d&#8217;entr&#233;e pour i
</p>
<p>4.3 R&#233;sultats des exp&#233;rimentations
</p>
<p>Les valeurs de la f-mesure calcul&#233;es selon la m&#233;thode d&#233;crite &#224; la section 4.2 sont indiqu&#233;es dans
la table 6 en fonction de chaque oracle (voir la table 4 pour les caract&#233;ristiques des oracles).
Les r&#233;sultats sont une moyenne mesur&#233;e sur 20 it&#233;rations comprenant chacune la s&#233;paration du
corpus en un corpus d&#8217;entra&#238;nement et un corpus de test, l&#8217;entra&#238;nement de l&#8217;oracle, l&#8217;analyse
syntaxique par transition et le calcul de la f-mesure.
</p>
<p>L&#8217;analyse des r&#233;sultats montre que le choix du vecteur de traits pour l&#8217;oracle influe de mani&#232;re
significative sur l&#8217;attribution correcte ou non des types de d&#233;pendances sur les mots. Les meilleurs
r&#233;sultats se font avec les oracles dont les vecteurs de traits sont les plus informatifs. Le choix
d&#8217;une classe grammaticale longue et d&#8217;une taille de vecteur de 8 est pr&#233;f&#233;rable pour obtenir de
meilleurs r&#233;sultats. En outre, le choix d&#8217;utiliser les groupes &#224; la place des types exacts semble
d&#233;pendre de la longueur de la classe grammaticale. Ces deux param&#232;tres ont en effet un lien. Par
exemple, si un mot de classe grammaticale N 3 &#224; re&#231;u le type de d&#233;pendance a-obj, en utilisant
</p>
<p>3. voir section 3.4
</p>
<p>91</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Oracle 1 Oracle 2 Oracle 3 Oracle 4
Pr&#233;cision 0.373 0.282 0.567 0.615
Rappel 0.187 0.151 0.258 0.294
F-mesure 0.250 0.197 0.355 0.398
</p>
<p>Oracle 5 Oracle 6 Oracle 7 Oracle 8
Pr&#233;cision 0.463 0.393 0.635 0.697
Rappel 0.192 0.169 0.313 0.362
F-mesure 0.272 0.237 0.420 0.477
</p>
<p>TABLE 6 &#8211; R&#233;sultats des exp&#233;rimentations sur les sorties de l&#8217;analyse selon les diff&#233;rents oracles
</p>
<p>l&#8217;oracle 6, alors qu&#8217;il est de type a-obj-d, la d&#233;pendance sera consid&#233;r&#233;e comme mal attribu&#233;e.
Alors qu&#8217;avec l&#8217;oracle 5, la d&#233;pendance sera seulement OBJ dans les deux cas et sera donc
correcte pour ce mot. Inversement, le probl&#232;me se pose d&#8217;une autre mani&#232;re entre les oracles 7
et 8. Lors de l&#8217;entra&#238;nement des oracles, la transition choisie d&#233;pend de la fr&#233;quence d&#8217;apparition
d&#8217;une configuration dans le corpus. Un mot de classe grammaticale Ntime peut recevoir une
d&#233;pendance de type objet ou pr&#233;position par exemple. Il se pourrait alors qu&#8217;en utilisant les
groupes, l&#8217;ensemble des d&#233;pendances de type PREPOS soient plus nombreuses que l&#8217;ensemble
des d&#233;pendances de types OBJ alors que sans utiliser les groupes, les d&#233;pendances de type a-obj
soient plus nombreuses que chacune des d&#233;pendances de type prepos-x (o&#249; x=g|d|l|o|A|sel).
Donc dans un cas, l&#8217;oracle assignerait une d&#233;pendance de type pr&#233;position alors que dans l&#8217;autre,
il assignerait une d&#233;pendance de type objet.
</p>
<p>En outre, la taille du vecteur de trait est significative dans le sens o&#249; les options ajout&#233;es au
vecteur de taille 8 apportent une information importante lors de l&#8217;analyse. En effet, de cette
mani&#232;re on connait la d&#233;pendance la plus &#224; gauche et la d&#233;pendance la plus &#224; droite de chacun
des deux mots trait&#233;s (le mot en haut de la pile &#963; et le premier mot du tampon &#946;). On peut
savoir par exemple si un verbe, &#233;tant la t&#234;te de la phrase, a d&#233;j&#224; un sujet ou non. Alors qu&#8217;avec
un vecteur de trait de taille 6, cette information n&#8217;est pas conserv&#233;e et plusieurs sujets peuvent
&#234;tre attribu&#233;s dans une m&#234;me phrase lorsqu&#8217;il n&#8217;y a pas lieu de le faire.
</p>
<p>4.4 Perspectives et am&#233;liorations &#224; venir
</p>
<p>Le choix d&#8217;une transition lors de l&#8217;analyse se fait de mani&#232;re d&#233;terministe car, dans l&#8217;oracle, il n&#8217;y
a qu&#8217;une seule transition possible pour une configuration donn&#233;e. En outre, plus les options
choisies pour l&#8217;oracle sont g&#233;n&#233;ralistes, moins il y a de choix car des configurations diff&#233;rentes
se retrouvent confondues dans un m&#234;me vecteur de traits qui dirige l&#8217;analyse vers une seule
transition pour des cas tr&#232;s diff&#233;rents. Il sera donc n&#233;cessaire par la suite de m&#233;moriser dans
l&#8217;oracle, en plus de l&#8217;ensemble configuration-transition le meilleur, quelques autres possibilit&#233;es
de transition pour la configuration consid&#233;r&#233;e.
</p>
<p>De plus, l&#8217;analyse &#233;tant d&#233;terministe, celle-ci s&#8217;interrompt lorsqu&#8217;il n&#8217;y a pas de transition
applicable. Beaucoup de structures de d&#233;pendances r&#233;sultantes sont alors incompl&#232;tes ou parfois
compl&#233;tement vides. La proposition pr&#233;cedente, permettrait donc ensuite de pouvoir faire un
</p>
<p>92</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>retour en arri&#232;re dans la s&#233;quence de transitions. Le nombre de retour en arri&#232;re possible pour
une phrase devra &#234;tre limit&#233; et le choix d&#8217;une nouvelle transition pourra se baser sur la seconde
meilleure transition pour une certaine configuration. Ce probl&#232;me est aussi une cause du faible
score du rappel dans toutes les analyses. En effet, beaucoup de mots n&#8217;ont tout simplement pas
d&#8217;attribution de type alors que les mots ayant une d&#233;pendance sont plus souvent correctement
typ&#233;s, d&#8217;o&#249; une pr&#233;cision meilleure que le rappel (voir exemple table 5).
Le choix d&#8217;une premi&#232;re transition puis d&#8217;une potentielle seconde meilleure transition devra
se baser sur des donn&#233;es probabilistes. Ainsi, pour &#233;tablir ces donn&#233;es il sera n&#233;cessaire
d&#8217;exp&#233;rimenter diff&#233;rents lissages avant de m&#233;moriser les ensembles configuration-transitions
dans l&#8217;oracle.
</p>
<p>D&#8217;apr&#232;s les r&#233;sultats des exp&#233;rimentations, les oracles utilisant un vecteur de taille 8 sont plus
efficaces car ils m&#233;morisent les types des d&#233;pendances gauches et droites des deux mots trait&#233;s lors
de l&#8217;analyse. Cependant, ces informations ne sont pas pertinentes dans tous les cas. Notamment,
le fait de savoir qu&#8217;un mot a une d&#233;pendance de type modificateur n&#8217;est pas d&#233;terminant pour la
suite car rien n&#8217;emp&#234;che ce mot d&#8217;avoir d&#8217;autres modificateurs. Tous les types it&#233;rables, comme
les modificateurs, les circonstantiels, les coordinations verbales, assign&#233;s &#224; une d&#233;pendance ne
seront donc pas m&#233;moris&#233;s. Nous garderons uniquement des informations appropri&#233;es telles que
les types pr&#233;dicat, d&#233;terminant, objet, etc...
</p>
<p>5 Conclusion
</p>
<p>Les objectifs de cet article &#233;taient de proposer des r&#233;sultats d&#8217;exp&#233;rimentations avec un analyseur
syntaxique par transitions &#233;tendu aux d&#233;pendances discontinues et de pr&#233;parer la base d&#8217;une
comparaison de ces r&#233;sultats avec un oracle guidant l&#8217;analyse de la CDG du fran&#231;ais.
L&#8217;analyse par transition d&#233;crite dans cet article ne permet pas encore d&#8217;obtenir des r&#233;sultats
suffisants pour obtenir une bonne analyse en d&#233;pendance du fran&#231;ais. Cependant, le syst&#232;me
de transitions mis en place pour correspondre avec la grammaire CDG est tout &#224; fait adapt&#233;e
&#224; l&#8217;ajout des d&#233;pendances discontinues par valences polaris&#233;es. De plus, nous voulions mettre
en &#233;vidence les int&#233;r&#234;ts et les probl&#232;mes de ces premi&#232;res exp&#233;rimentations sur des phrases en
fran&#231;ais pour mettre en place un plan d&#8217;am&#233;liorations de l&#8217;analyse par transitions. Dans l&#8217;&#233;tat
actuel, l&#8217;algorithme &#233;tabli pour analyser les phrases en structures de d&#233;pendances est d&#233;terministe
et ne permet pas de faire des choix bien adapt&#233;s aux configurations trait&#233;es. L&#8217;aspect probabilistes
mis en place pour calculer la fr&#233;quence d&#8217;apparition des configurations dans l&#8217;analyse des phrases
du corpus devra &#234;tre exploit&#233; pour s&#233;lectionner les meilleures transitions possibles pour une
configuration et pas seulement la meilleure. En outre, les vecteurs de traits devront &#234;tre mieux
adapt&#233;s &#224; l&#8217;information dont l&#8217;analyseur a besoin pour faire les bons choix.
D&#232;s lors, les prochains r&#233;sultats permettront de comparer cette analyse avec l&#8217;oracle qui guide
l&#8217;analyse de la CDG du fran&#231;ais et ainsi d&#8217;&#233;tablir de nouvelles m&#233;thodes d&#8217;amor&#231;ages pour
attribuer les t&#234;tes des d&#233;pendances avant l&#8217;analyse de la CDG.
</p>
<p>93</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;f&#233;rences
</p>
<p>ALFARED, R., B&#201;CHET, D. et DIKOVSKY, A. (2011). &#8220;CDG Lab&#8221; : a toolbox for dependency
grammars and dependency treebanks development. In DEPLING 2011 (International Conference
on Dependency Linguistics), Barcelona.
</p>
<p>BAR-HILLEL, Y., GAIFMAN, C. et SHAMIR, E. (1964). On categorial and phrase structure grammars,
pages 99&#8211;115. Addison-Wesley.
</p>
<p>BRUNET-MANQUAT, F. (2005). Improving dependency analysis by syntactic parser combination.
In NLP-KE 2005 (Natural Language Processing and Knowledge Engineering), Wuhan.
</p>
<p>CANDITO, M., CRABB&#201;, B., DENIS, P. et GU&#201;RIN, F. (2009). Analyse syntaxique du fran&#231;ais : des
constituants aux d&#233;pendances. In TALN 2009 (Traitement automatique des langues naturelles),
Senlis.
</p>
<p>CANDITO, M.-H. et KAHANE, S. (1998). Une grammaire tag vue comme une grammaire sens-texte
pr&#233;compil&#233;e. In TALN 1998 (Traitement automatique des langues naturelles), Paris.
</p>
<p>CHOI, J. D. et PALMER, M. (2011). Getting the most out of transition-based dependency parsing.
In ACL 2011 (Association for Computational Linguistics), Portland.
</p>
<p>DEKHTYAR, M. et DIKOVSKY, A. (2008). Generalized Categorial Dependency Grammars, pages
230&#8211;255. LNCS 4800. Springer.
</p>
<p>DIKOVSKY, A. (2011). Categorial dependency grammars : from theory to large scale grammars.
In DEPLING 2011 (International Conference on Dependency Linguistics), Barcelona.
</p>
<p>KAHANE, S. (2001). Grammaires de d&#233;pendance formelles et th&#233;orie sens-texte. In TALN 2001
(Traitement automatique des langues naturelles), Tours.
</p>
<p>KOW, E., PARMENTIER, Y. et GARDENT, C. (2006). Semtag, the loria toolbox for tag-based parsing
and generation. In TAG+8 (The Eighth International Workshop on Tree Adjoining Grammar and
Related Formalisms), Sydney.
</p>
<p>K&#220;BLER, S., MCDONALD, R. et NIVRE, J. (2009). Dependency parsing. Morgan et Claypool.
</p>
<p>MARUYAMA, H. (1990). Structural disambiguation with constraint propagation. In ACL 1990
(Association for Computational Linguistics), Pittsburgh.
</p>
<p>MEL&#8217;CUK, I. (1988). Dependency syntax : Theory and Practice. State University of New York Press.
</p>
<p>NASR, A. (2004). Analyse syntaxique probabiliste pour grammaires de d&#233;pendances extraites
automatiquement. Habilitation &#224; diriger des recherches, Universit&#233; Paris 7, UFR d&#8217;informatique.
</p>
<p>NIVRE, J. (2008). Algorithms for Deterministic Incremental Dependency Parsing, pages 513&#8211;553.
Volume 34 (4). Massachusetts Institute of Technology.
</p>
<p>NIVRE, J. (2011). Bare-bones dependency parsing. In NODALIDA 2011 (Nordic Conference of
Computational Linguistics), Riga.
</p>
<p>RAMBOW, O. (2010). The simple truth about dependency and phrase structure representations.
In NAACL HTL 2010 (North American Chapter of the Association for Computational Linguistics -
Human Language Technologies), Los Angeles.
</p>
<p>VANRULLEN, T., BLACHE, P. et BALFOURIER, J.-M. (2006). Constraint-based parsing as an efficient
solution : Results from the parsing evaluation campaign easy. In LREC 2006 (Conference on
Language Resources and Evaluation), Genoa.
</p>
<p>94</p>

</div></div>
</body></html>