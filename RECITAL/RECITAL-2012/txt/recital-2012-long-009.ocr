Prémices d’une analyse syntaxique par transition pour des
structures de dépendance non-projectives

Boris Karlovl, Ophélie Lacroixz
(1) Université de 'I‘ver, 33, rue Zheliabov, 170000, 'I‘ver, Russie
(2) LINA, 2, rue de la Houssiniere 44322 Nantes Cedex 3
bnkarlovgmail . com
ophelie . lacroixQu.niv—na.ntes . fr

RESUME
L’artic1e présente une extension de l’analyseur traditionnel en dépendances par transitions adapté
aux dépendances discontinues et les premiers résultats de son entrainement sur un corpus de
structures de dépendances de phrases en frangais. Les résultats des premieres expérimentations
vont servir de base pour le choix des traits des conﬁgurations de calcul bien adaptés aux
dépendances discontinues pour améliorer l’apprentissage des dépendances téte.

AB STRACT
Beginnings of a 'I‘ransition-Based Parsing for Non-Projectives Dependency Structures

This paper presents an extension of the traditional transition-based dependency parser adapted
to discontinuous dependencies and the ﬁrst results of its training on a dependency tree corpus
of French. The first experimental results will be useful for the choice of parsing conﬁguration
features well adapted to discontinuous dependencies in order to ameliorate learning of head
dependencies.

MOTS-CLES : analyse syntaxique par transitions, structure de dépendance non-projective,
grammaire catégorielle de dépendance.

KEYWORDS: transition-based parsing, non-projective dependency structure, dependency catego-
rial grammar.

1 Introduction

Il existe différentes méthodes d’analyses syntaxiques permettant de traiter les phrases du francais.
Ces analyses peuvent étre syntagmatiques (par constituants) (Kow et aL, 2006; Vanrullen et al.,
2006) ou en dépendance (Nasr, 2004; Brunet-Manquat, 2005; Alfared et al., 2011). Elles peuvent
étre guidées par les régles d’une grammaire (probabiliste ou non) ou étre entainées sur un corpus.
Depuis plusieurs années, les différentes méthodes d’analyses en dépendance (voir (Kiibler et al.,
2009)) gagnent en interét dans le domaine de l’analyse syntaxique. Dans cet article nous nous
placons dans le cas d’une analyse syntaxique en dépendance, par transition, entrainée sur un
corpus correct par rapport 5 une grammaire de dépendance (Alfared et al., 2011).

Les méthodes d’analyses en dépendance permettent de produire des représentations d’une phrase
plus expressives sémantiquement que celles par constituant. D’autres forrnalismes comme les
grammaires d’arbres adjoints sont parfois utilisés pour prendre en compte l’aspect sémantique

Actes de la con_fe'rence conjointe JEP-TALN-RECITAL 2012, volume 3: RECITAL, pages 81-94,
Grenoble, 4 au 8 juin 2012. ©2012 ATAI.A 8: AFCP

81

des phrases, mais ne permettent pas, par exemple, de révéler la relation de coréférence (Candito
et Kahane, 1998). La représentation des phrases en structure de dépendance que nous avons
choisi de mettre en avant ici, nous permet d’exprimer certaines relations qui ne sont pas toutes
considérées dans les méthodes classiques par constituants. La ﬁgure 1 présente, entre autres,
la relation distante existante entre les mots "moins" et "que" que l’on peut trouver lors d’une
comparaison.

PUNCT

 

II boit moins d' eau qu' avant.

#\ EL

FIGURE 1 — Structure de dépendance de la phrase "11 boit moins d’eau qu’avant."

Il est donc possible de déﬁnir des dépendances croisées. Cependant une telle représentation (dite
non-projective, voir la section 2.1) est peu utilisée dans le domaine de l’analyse en dépendance
pour les phrases en frangais. Les analyses en dépendances courantes se basent principalement sur
le méme modéle que les analyses par constituants pour leur lien plus évident avec les grammaires
formelles. Certains travaux consistent d’ailleurs 5 convertir des corpus annotés par constituants
en corpus de dépendance (Candito et al., 2009). Ce genre d’analyse produit donc des structures
de dépendances projectives (sans dépendances croisées), proches des arbres syntagmatiques. On
parle alors dans ce cas d’arbre de dépendance. Néanmoins, tout le potentiel des structures de
dépendances n’est pas exploité lors d’une telle conversion. Comme le souligne (Rarnbow, 2010),
une perte d’information serait inévitablement constatée si on tentait de convertir une structure
de dépendance en structure par syntagme.

D’autre part, d’aprés (Nivre, 2011), les analyses du type analyse tabulaire (basée sur les premiers
algorithmes tel que CKY ou Earley, voir (Kiibler et al., 2009)) cu analyse par satisfaction de
contraintes (Maruyama, 1990) ne sont pas bien adaptées aux structures de dépendance non-
projectives que nous souhaitons traiter. Le probléme devient d’une complexité trop grande ou
NP-complet. Les analyses par transition sur des structures de dépendance projectives pour des
phrases en anglais donnent de bons résultats et l’adaptat1'on aux structures de dépendance non-
projectives se fait en une complexité au pire quadratique. Récernment, (Choi et Palmer, 2011)
effectuent une analyse par transition sur des dépendances non-projectives pour des phrases
en anglais. (Alfared et al., 2011) travaillent sur un analyseur syntaxique semi-automatique
permettant de produire des structures de dépendances projectives et non-projectives sur des
phrases en francais. Nous nous appuierons ici sur la grammaire catégorielle de dépendance
qu’ils utilisent, (Dikovsky, 2011), pour déﬁnir les dépendances croisées existantes dans les
structures de dépendance non-projectives. Nous allons alors présenter l’analyseur syntaxique par
transition, que nous avons développé, permettant de déﬁnir des structures de dépendance non
nécessairement projectives pour des phrases en francais.

82

2 Structures de dépendance

Une structure de dépendance représente le résultat d’une analyse en dépendance pour une phrase
donnée. Ces structures permettent de mettre en évidence les relations binaires entre les mots
d’une phrase telles que les relations sujet-verbe, verbe-objet, etc. Les stiuctures de dépendance
sont a différencier des structures syntagmatiques qui sont le résultat d’une analyse par consti-
tuants. Mel’cuk met en évidence les différences, les avantages et les inconvénients de ces deux
méthodes d’analyses dans (Mel’cuk, 1988) et propose la théorie "Sens-Texte" qui révéle l’aspect
sémantique des dépendances entre les mots. Il met en avant, en outre, le fait que les structures
de dépendances profondes sont invariantes selon l’ordre des mots dans la phrase. Ces idées sont
aussi reprises plus récemment par (Kahane, 2001). Ici nous travaillons sur l’analyse des struc-
tures de dépendance de surface qui ont la particularité de garantir l’ordre des mots dans la phrase.

2.1 Projectivité, non-projectivité

De maniére théorique, une structure de dépendance est un graphe orienté dont les noeuds
sont les mots de la phrase ‘a analyser et les arcs représentent les dépendances reliant ces mots.
Dans une structure de dépendance, la relation de dominance est importante. Un mot domine de
maniére directe ses subordonnés, mais il domine aussi les subordonnés de ses subordonnés de
maniére transitive. Ainsi dans toute phrase la racine domine tous les mots. Un mot dominant est
appelé un gouverneur.

Une structure de dépendance peut étre projective ou non. Une structure est projective si pour
chaque mot w tous les mots qui se trouvent entre w et ses subordonnés sont aussi dominés par
w, comme illustré par la ﬁgure 2. Par ailleurs, les ﬁgures 1 et 3 présentent des structures de
dépendances non-projectives. En effet, dans le cas de la ﬁgure 3, les mots “attend“, “son“ et “mari“
sont compris entre le mot “ElZe“ et son subordonné “presse’e“ mais ne sont pas des subordonnés de
"Elle", la structure n’est donc pas projective.

 

La nature fait bien les choses .

FIGURE 2 — Structure de dépendance de la phrase "Ia nature fait bien les choses."

2.2 Représentation utilisée

Les arcs représentant les dépendances sont de trois sortes différentes : projectifs, discontinus ou
ancres. Les dépendances projectives sont des dépendances locales (courtes) qui ne se croisent
pas les unes avec les autres. Les dépendances discontinues sont les dépendances non-projectives
distantes qui peuvent croiser les dépendances projectives. Et les ancres sont des dépendances lo-
cales permettant de lier localement une dépendance discontinue. Effectivement, les subordonnés

83

MODIF PUNCT

 

Elle attend son mari , pressée de partir .
#\-MODIF
FIGURE 3 — Structure de dépendance de la phrase "Elle attend son mari, pressée de partir."

des dépendances ancres sont aussi subordonnés via des dépendances discontinues. Ces ancres
sont importantes pour déﬁnir la grammaire présentée ensuite. La ﬁgure 3 permet d’illustrer
chaque sorte d’arc énoncé ci-dessus. Dans cette ﬁgure, la dépendance discontinue est de type
modificateur (le participe passé "pressée" est bien rattaché au pronom personnel "Elle"). Les
dépendances discontinues, comme M ODI F 1 sont indiquées au dessus de la phrase tandis que
les dépendances ancres liées aux dépendances discontinues, comme ,/ M ODI F, sont indiquées
au dessous de la phrase. La négation, la réfléxivité, l’apposition et l’agg're’gation, parmi d’autIes
types de dépendances, peuvent aussi engendrer des dépendances discontinues.

2.3 Grammaire catégorielle de dépendance (CDG)

(Dekhtyar et Dikovsky, 2008) exposent une méthode pour représenter les dépendances en
catégories comme dans les grammaires catégorielles classiques (Bar-Hillel et al., 1964). Cette
grammaire a permis a (Alfared et al., 2011) de produire le corpus que nous utiliserons ensuite
pour notre analyse (voir section 4.1). L’idée est de représenter les dépendances projectives et les
dépendances ancres par des catégories qui sont les types de ces dépendances et les dépendances
non-projectives par des valences polarisées. Sur une phrase comme celle donnée en exemple dans
la ﬁgure 4, on aura pour chaque mot les catégories suivantes : il -—> [pred] , y -—> [# ,/ clit]/‘lit
est -—> [# ,/ clit\pred\S/punct/aux], allé -—> [aux]\°”‘, . -—> [punct].

2
FRED CLIT PUNCT

II y est allé .

#-I LIT

FIGURE 4 — Structure de dépendance de la phrase ‘'11 y est allé."

Ces catégories sont ensuite utilisées dans une grammaire catégorielle enrichie de régles de
dérivations, exposées dans la table 1, permettant de traiter les valences polarisées. La régle

1. M ODI F est le type attribué a une dépendance entre un mot et son modiﬁcateur, qui peut étre un participe ou
un adjectif. Les types de dépendances utilisés dans ces structures sont ceux employés par (Alfared et al., 2011) pour
construire leur corpus. Par ailleurs, les dépendances utilisées dans les ﬁgures de cet anicle sont étiquetées par les noms
des groupes de dépendances auxquelles elles appartiennent (voir section 3.4) pour une illustration plus simple.

L permet d’éliminer les catégories comme dans les grammaires catégorielles classiques, et de
concaténer les valences polarisées en une chaine que l’on appelle potentiel. Pour la régle I, les
valences sont traitées de la méme maniére tandis que la dérivation s’effectue sur les catégories
itérables. De méme, la régle Q permet d’él1'miner une catégorie itérable en conservant le potentiel
tel qu’il était. Puis l’élimination des valences dans la dérivation (régle D) se fait sur le principe FA
(First Available). Tout d’abord, des valences duales sont des valences de méme catégorie dont
les polarités sont ,/ et \, ou /' et \. Le principe FA indique que les valences duales les plus
proches dans un potentiel sont des paires. Alors dans un potentiel P1(,/ C)P('\ C)P2, si (/ C)
et (\ C) (valences duales) n’apparaissent pas dans E (/ C) et (\ C) satisfont le principe FA.

L1 CP1  |_ D3:|P1P2

I1 CP1 [C*¥’3]P2 |_1LC*\’3]P1Pz

01 [c*\;3] F [/3]

D1 (XP1('/ 01’ (\C)P2 |- (XP1PP“, si (/ C)('\ C) satisfait le principe FA

TABLE 1 — Régles de la grammaire catégorielle de dépendance généralisée

Un exemple d’arbre de dérivation, utilisant les valences polarisées pour les dépendances disconti-
nues, dérivé de la phrase ‘'11 y est alle’." est présenté par la ﬁgure 5.

II y est allé .
PRED #.(CL|T“"3'-‘T #.(CL|T\PRED\S/PUNCT/AUX AUX"‘3'—'T PUNCT

 
 

#.(CL|T\PRED\S/PUNCT "CL"

PRED\S/PUNCT

X
S/PUNCT
\

FIGURE 5 — Arbre de dérivation utilisant la CDG sur la phrase "11 y est allé."

3 Analyse par transition

Comme expliqué par (Nivre, 2008), une structure de dépendance peut étre traduite en une
suite de transitions. Le but d’un analyseur syntaxique par transition est de trouver une suite de
transitions (opérations sur les conﬁgurations de calcul de l’analyseur) qui permette de construire
une structure de dépendance correcte pour une phrase donnée. Pour faire ce travail, l’analyseur
syntaxique doit s’appuyer sur un oracle qui lui indique quelle transition appliquer dans telle ou
telle conﬁguration. Les conﬁgurations et transitions sont des éléments essentiels de l’analyse par
transition, qui peuvent varier selon l’utilisation que l’on veut en faire. Kiibler, Donald et Nivre
déﬁnissent clairement leurs emplois dans (Kiibler et aL, 2009). Ici nous présentons un analyseur

85

par transition adapté aux dépendances discontinues, que nous avons développé. Le travail
consiste tout d’abord a générer un oracle a partir d’un corpus de référence. Chaque structure de
dépendance du corpus est traduite en un ensemble de couples conﬁguration-transition qui sont

ajoutées a l’oracle selon le nombre d’occurences d’une transition pour une conﬁguration 2 donnée.

L’oracle enregistre donc seulement la meilleure transition possible pour une conﬁguration. Cet
oracle sera alors utilisé pour déterminer une suite de transitions ‘a appliquer, pour chaque
phrase a analyser, permettant de construire des structures de dépendance. I.’analyseur est donc
déterministe car il s’appuie sur l’oracle pour choisir la transition a appliquer a chaque étape de
l’analyse.

3.1 Configurations

Une conﬁguration, pour une phrase, est un “état“ dans lequel est l’analyseur syntaxique analysant
cette phrase. On peut y appliquer une transition qui permettra de passer dans la conﬁguration
suivante.

Soit une phrase s = w1w2...w,,. Une conﬁguration pour une phrase est un quintuplet (0, [3, 9, i, E)
oil 0 est une pile de mots w,- dans s, /3 est un tampon de mots w,- dans s, 9 est un tampon de
valences (un potentiel), i est la position du mot courant, et E est un ensemble d’arcs (w,-, r, t, wj)
o1‘1 r est l’étiquette de l’arc (le type de la dépendance) et t est la sorte de l’arc (projectif, discontinu,
ancre). La conﬁguration initiale co pour chaque phrase est :

 1 [W12 "'1 Wu] J  1 11“)-

La conﬁguration ﬁnale, pour n’importe quel 0 et E, est :

(0,[],[],T1+1,E)-

3.2 Transitions

Les transitions sont des opérations s’appliquant aux conﬁgurations pour obtenir les conﬁgurations
suivantes. Celles-ci sont présentées dans la table 2. Ces transitions se basent sur les transitions
évoquées par (Kiibler et al., 2009). Nous y ajoutons des éléments permettant de traiter les
structures de dépendances projectives aussi bien que les structures non-projectives. En effet, la
transition PutPotentiaZ ajoute les valences polarisées dans le potentiel 9 selon les régles de la table
1 de la grammaire catégorielle de dépendance vu a la section 2.3. Puis les transitions DistLeft et
DistRight permettent de déﬁnir les dépendances discontinues de la structure de dépendance en
éliminant les valences duales du potentiel 9, suivant la régle D. En outre, les transitions LocaZLeft
et LocalRight servent a déﬁnir les dépendances projectives ainsi que les dépendances ancres. Les
ancres permettent de détecter les subordonnés discontinus.

Pour convertir une structure de dépendance en une suite de transitions, on utilise un algorithme
qui applique les transitions dans un certain ordre. Pour cela, on considére toujours le mot en haut
de la pile cr comme le mot courant de la conﬁguration. L’algorithme essaie d’abord de trouver les
dépendances discontinues de la structure. Donc dans un premier temps, il tente d’ajouter une
valence dans le potentiel 9 en appliquant la transition PutPotentiaZ si le mot courant est impliqué

2. Une conﬁguration est ieprésentée par un vecteur de traits : image de taﬂle réduite de la conﬁguration, voir section
3.4

86

dans une dépendance discontinue. Puis on applique les transitions DistLeft et DistRight, pour
déﬁnir les dépendances distantes trouvées, jusqu’a ce qu’il n’y ait plus de valences duales. Ensuite
l’algorithme traite les dépendances locales. Il commence donc par appliquer toutes les transitions
LocalLeft possible pour le mot courant, de son subordonné le plus proche au plus a gauche. Puis
si ce mot a des dépendances a droite, on le garde sur la pile et on applique la transition Put pour
empiler le mot suivant sur 0. Néanmoins, si le mot courant n’a pas de subordonné droit et a
un gouverneur sur la gauche alors il est possible d’appliquer la transition LocalRight. Le dernier
cas possible est si le mot courant n’a plus aucun subordonné sur la droite et n’a pas non plus de
gouverneur. Alors il s’agit de la racine et le processus est terrniné.

Transition Effet de son application sur une conﬁguration

PutPotential (cr,wk I /3, 9,k,E) 3 (cr,wk I /3, 9p’f...pI‘n,k + 1,E)

(pl, ..., pm) o1‘1 les pj sont des valences.
Put (alwi|Wi!ﬂ!9!next(k!i)!E)
o1‘1 next(k,l) ={ :4‘ 1 I

LocalLeft(d) (0 I wl-,wj I I3, 9,k,E) 3 (cr,w]- I /3, 9,k,E U {(wi, d, TYPE(d),w]-)})
I-'0ca1Right(d) (0 I Wiiwj I ﬁr ark:  => (0: wi I ﬂy 9: next(k:j):E U {(wi:d:  

DistLeft(v) (0, I3, _91 ,/ 1_/"92 '\ vj93,k,E) 3 (0, I3, 9, k,E U {(w]-,v,discontinuous,wi)})
si ,/ v‘ '\ v1 est la paire la plus a gauche satisfaisant la condition FA.

DistRight(v) (0, I3, _91 /' 1_/"92 \ vj93,k,E) 3 (0, I3, 9, k,E U {(wi,v,discontinuous,wj)})
si /' v‘ \ v1 est la paire la plus a gauche satisfaisant la condition FA.

TABLE 2 — Les transitions utilisées par l’analyseur

3.3 Exemple de conversion

Pour illustrer la méthode de conversion d’une structure de dépendance en séquence de transitions
voici un exemple pour la phrase "Cette victoire, elle l’a me’rite’e." dont la structure de dépendance
est présentée par la ﬁgure 6. Cette phrase comprend des dépendances discontinues de type
clitique et core’fe’rence. La suite de transitions appliquées a cette phrase et les éléments de chaque
conﬁguration en découlants sont illustrés dans la table 3.

87

__.uwu2.2w2.22 uh MEM .u22o2o2> MuuMU= ummﬁm mﬁ MU uonmunumwu MU u2:.2o3.22m I O mmawi

Lw¢OU\.%

._._._U\. 

. UWH_hWE N ._ U=U . w.._ouu_> UHHUU
{E

  
  

._.U2=n_@ ._._._U nun;

m22o.n2m22mb MU 3225. M625 ﬂM __.uwu2.2w2.22 ah MSM .u22o2o2> MuuMU= ummim mﬁ MU uoamuaumwu MU u2:.2o:.22m mﬁ MU 22o2m2u>22oU I M m2m<.H.

2. .655 .6>26662.2 .3 3 m n m 2 262 2 5622226662
m 2 E 262 5.2
266565 .526 .6>26662.2 .3 3 m n m 2 2 62 2 5622226662
2.2 .2226 62635566622. 6222652 3 m n m 2 2 6222652 262 62626222
m 2226/22262 2 6222652 62 2625626232
22 222262 2 665652 262 252
22666 2266 .6666 .3 3 m n 22 222262 2 66565 62 2 626226662
26226 .2.2.2 .6>266.22.2 .3 3 m n m 222262 2 622265 62 226622 62622682
2.2 .2226 .6656 .3 3 m n m 22262 2 622265 62 26226 26622 626226662
m 222262 2 622265 62 2.2 6226 2662.2 5.2
22666 228 62635566622. ..22 3 m u m 22262 2 622265 6 .2 26226 26622 6262662
m 2226\.2666/2266\.2 2 622265 6 .2 26226 26622 2625626232
m 2666/228\.2 2 622265 6 .2 26226 26622 2625626232
m 22662 2 622265 6 .2 26226 2662.2 5.2
m 22662 2 622265 6 .2 62262 226622 5.2
2. .655 .6>26662.2 .2665 3 m n m 22662 2 622265 6 .2 6226 2662.2 2 52222226662
m 22662 2 622265 6 .2 6226 .2 226622 5.2
22622 .62. .6>26662.2 .2665 n m 22662 2 2.622.225 6 .2 6226 . 2662.2 2 626226662
& 22662 2 622265 6 .2 6226 . 2662.2 2268 2625626232
& 2 2 622265 6 .2 6226 . 2662.2 2268 5.2

& 2 2 622265 6 .2 6226 . 2666 .268 2
m 8.226..» uEEum22m Q 2o2u22Bon2 Q 22356.2. .0 man 22o.n2m22m.2,2.

88

3.4 Oracles

L’idée de l’analyse par transition est de représenter partiellement les éléments des conﬁgurations
(dont la taille n’est pas limitée) par les valeurs de vecteurs de traits. Le probleme du choix des
traits se pose alors. Différents traits peuvent étre choisis pour entrainer un oracle ‘a partir d’un
corpus de structure de dépendance. Nous expérimentons ici avec huit vecteurs de traits différents.
On peut donc choisir :

— l’utilisat1'on ou non du nom complet de la classe grammaticale affectée au mot dans les

structures de dépendance

— l’utilisat1'on ou non des groupes de dépendances a la place des noms exacts des dépendances
— la taille du vecteur de traits.

Pour la classe grammaticale, on peut choisir d’utiliser le nom simple (court) de la classe ou
le nom enrichi d’un parametre (long). Par exemple pour le cas d’un mot de la classe adjectif
quantiﬁcateur, le nom court correspondra aAdj et le nom long aAdjquantifier. La classe courte
Adj rassemble les adjectifs modiﬁcateurs, quantiﬁants, restrictifs, comparatifs, etc... Un autre
exemple est celui de la classe des noms (N). Elles peut regrouper les classes de noms longs
Nproper (noms propres), Ncommon (noms communs), Ntime (noms ‘a référence temporelle),
etc...

Par ailleurs, les dépendances avec des fonctions syntaxiques proches peuvent étre regroupées
dans des groupes de dépendances. Il est alors possible de sélectionner une option traitant les
dépendances selon le groupe de dépendances auxquelles elles appartiennent ou selon leurs types
de dépendances précis. Par exemple pour le cas d’un mot dont la dépendance est du type objet
accusatif, on utilisera par défaut le type de dépendance complet a-obj, mais on emploiera le type
OBJ pour une représentation des types par groupe. Dans ce cas la, le type OB.I pourra aussi étre
assigné a une dépendance de type g-obj (objet génitif), Z-obj (objet locatif) ou o-obj (objet oblique).

Le vecteur de trait peut étre de taille 6 ou 8. Dans les deux cas, les vecteurs de traits, pour une
conﬁguration donnée a un moment de l’analyse, sont constitués de :

— la classe grammaticale du mot au sommet de la pile 0

— la classe grammaticale du premier mot du tampon /3 de mots

— le type de la dépendance la plus a gauche (c’est-a-dire, dont le subordonné est le plus a gauche)

du mot en haut de la pile cr suivi de la sorte de l’arc (discontinu, projectif, ancre)

— le type de la dépendance la plus a droite du mot en haut de la pile cr suivi de la sorte de l’arc
— la derniére valence du potentiel et son orientation

— l’avant-derniére valence du potentiel et son orientation

Si le vecteur est de taille 8, il posséde les deux traits suivants en plus :
— le type de la dépendance la plus ‘a gauche du premier mot du tampon /3 suivi de la sorte de
l’arc

— le type de la dépendance la plus a droite du premier mot du tampon /3 suivi de la sorte de l’arc
Ainsi nous générons huit oracles différents, exposés dans la table 4. L’oracle 1 est ainsi le plus
général et l’oracle 8 est le plus précis.

89

vecteur Casse ramma
8 courte

 

TABLE 4 — Les paramétres des différents oracles

4 Résultats des analyses et discussion

4.1 Corpus de dépendance

Le corpus utilisé pour cette analyse par transition est constitué d’un ensemble de corpus de
phrases de style grammatical différent. Ila été annoté semi-automaﬁquement par des membres
de l’équipe TALN du Lina et leurs associés, en utilisant le systéme CDG Lab (Alfared et al.,
2011) et une grammaire catégorielle du frangais (Di.kovsky, 2011). Lors de chaque analyse
syntaxique 90% du corpus est employé comme corpus d’entrainement pour produire un oracle et
les 10% restants sont exploités par l’analyse syntaxique par transition et traduits en structures
de dépendances. Le choix des phrases utilisées pour l’apprentissage et pour l’analyse se fait
aléatoirement. Le corpus complet (apprentissage et analyse) comprend 2557 structures de
dépendances dont 33490 mots. 41% des structures de dépendances de ce corpus contiennent au
moins une dépendance discontinue mais les dépendances discontinues représentent seulement
4% du nombre de dépendances total du corpus.

4.2 Méthode d’expérimentation

Les ﬁchiers de sortie de l’analyseur sont similaires aux ﬁchiers d’entrée, de maniére a ce que l’on

puisse retrouver pour chaque phrase, les dépendances correctements assignées on non entre les

unités lexicales. Pour estimer les résultats, on calculera la f-mesure sur les tétes des dépendances.

C’est a dire que l’on se contentera de vériﬁer si chaque mot de la phrase recoit bien la dépendance

du bon type. Toutefois, les dépendances discontinues ne sont pas comptabilisées, car les mots

recevant une telle dépendance recoivent aussi une dépendance ancre du méme type. Le choix de

calculer les résultats uniquement sur les tétes des dépendances plutot que sur les dépendances

elles-mémes dépend de deux aspects importants :

— le volume du corpus n’est pas sufﬁsant pour l’instant pour espérer avoir les bons assignements
des dépendances et de leurs types en méme temps

— ces types de résultats s’accordent avec des travaux futurs qui consisteront a déterminer les
bonnes tétes des dépendances avant d’effectuer une analyse syntaxique en dépendance a partir
de la CDG.

90

Le principe est donc de collecter, pour chaque type de dépendance apparaissant dans le corpus
d’entrée ou de sortie, le nombre de fois o1‘1 celui-ci est assigné dans le corpus d’entrée, le nombre
de fois o1‘1 celui-ci est attribué ‘a un mot du corpus de sortie et le nombre de fois o1‘1 celui-ci est
attribué au bon mot dans le corpus de sortie. La table 5 donne les résultats de ces assignations sur
une analyse d’un corpus d’analyse possible (10% du corpus total, voir section 4.1) pour certains
types de dépendances. Par exemple, le type 5 (la téte de la phrase) a été assigné sur 38 mots,
dont 37 fois correctement, parmi les 255 mots typés S dans le corpus. Le type DET a toujours été
assigné correctement sur les 117 fois o1‘1 il a été trouvé pour un mot.

Type des Nb d’occurences Nb d’occurences Nb d’attributions
dépendance corpus d’entrée corpus de sortie correctes

S 38 255 37

PRED 169 3 14 168

DET 1 1 7 331 1 17

OBJ 69 2 18 64
COPUL 22 79 21
MODIF 26 1 13 24

CLI'I' 48 124 39
PUNCT 1 16 404 109

TABLE 5 — Exemple de résultats d’assignements des types (pour quelques types donnés) par
comparaison entre un corpus d’entrée et de sortie

Pour chaque type de dépendance i de la table ainsi établie, on calcule la présicion et le rappel de
la maniére suivante :

Nb d’attributions correctes pour i Nb d’attributions correctes pour i

précisioni = rappeli =

Nb d’occurences corpus de sortie pour i Nb d’occurences corpus d’entrée pour i

4.3 Résultats des expérimentations

Les valeurs de la f-mesure calculées selon la méthode décrite a la section 4.2 sont indiquées dans
la table 6 en fonction de chaque oracle (voir la table 4 pour les caractéristiques des oracles).
Les résultats sont une moyenne mesurée sur 20 itérations comprenant chacune la séparation du
corpus en un corpus d’entrainement et un corpus de test, l’entrainement de l’oracle, l’analyse
syntaxique par transition et le calcul de la f-mesure.

L’analyse des résultats montre que le choix du vecteur de traits pour l’oracle inﬂue de maniere
signiﬁcative sur l’attribution correcte ou non des types de dépendances sur les mots. Les meilleurs
résultats se font avec les oracles dont les vecteurs de traits sont les plus informatifs. Le choix
d’une classe grammaticale longue et d’une taille de vecteur de 8 est préférable pour obtenir de
meilleurs résultats. En outre, le choix d’utiliser les groupes a la place des types exacts semble
dépendre de la longueur de la classe grammaticale. Ces deux paramétres ont en effet un lien. Par
exemple, si un mot de classe grammaticale N 3 ‘a recu le type de dépendance a-obj, en utilisant

3. voir section 3.4

91

Oracle 1 Oracle 2 Oracle 3 Oracle 4
Précision 0.373 0.282 0.567 0.615
Rappel 0.187 0.151 0.258 0.294
F-mesure 0.250 0.197 0.355 0.398
Oracle 5 Oracle 6 Oracle 7 Oracle 8
Précision 0.463 0.393 0.635 0.697
Rappel 0.192 0.169 0.313 0.362
F-mesure 0.272 0.237 0.420 0.477

TABLE 6 — Résultats des expérimentations sur les sorties de l’analyse selon les différents oracles

l’oracle 6, alors qu’il est de type a-obj-d, la dépendance sera considérée comme mal attribuée.

Alors qu’avec l’oracle 5, la dépendance sera seulement OBJ dans les deux cas et sera donc
correcte pour ce mot. Inversement, le probléme se pose d’une autre maniére entre les oracles 7
et 8. Lors de l’entrainement des oracles, la transition choisie dépend de la fréquence d’apparition
d’une conﬁguration dans le corpus. Un mot de classe grammaticale Ntime peut recevoir une
dépendance de type objet ou préposition par exemple. Il se pourrait alors qu’en utilisant les
groupes, l’ensemble des dépendances de type PREPOS soient plus nombreuses que l’ensemble
des dépendances de types OBJ alors que sans utiliser les groupes, les dépendances de type a-obj

soient plus nombreuses que chacune des dépendances de type prepos-x (o1‘1 x=g | d | l| o|A | sel).

Donc dans un cas, l’oracle assignerait une dépendance de type préposition alors que dans l’autre,
il assignerait une dépendance de type objet.

En outre, la taille du vecteur de trait est signiﬁcative dans le sens o1‘1 les options ajoutées au
vecteur de taille 8 apportent une information importante lors de l’analyse. En effet, de cette
maniére on connait la dépendance la plus a gauche et la dépendance la plus a droite de chacun
des deux mots traités (le mot en haut de la pile 0 et le premier mot du tampon /3). On peut
savoir par exemple si un verbe, étant la téte de la phrase, a déja un sujet ou non. Alors qu’avec
un vecteur de trait de taille 6, cette information n’est pas conservée et plusieurs sujets peuvent
étre attribués dans une méme phrase lorsqu’il n’y a pas lieu de le faire.

4.4 Perspectives et améliorations :31 venir

Le choix d’une transition lors de l’analyse se fait de maniére déterministe car, dansl’orac1e, il n’y
a qu’une seule transition possible pour une conﬁguration donnée. En outre, plus les options
choisies pour l’oracle sont généralistes, moins il y a de choix car des conﬁgurations différentes
se retrouvent confondues dans un méme vecteur de traits qui dirige l’analyse vers une seule
transition pour des cas trés différents. Il sera donc nécessaire par la suite de mémoriser dans
l’oracle, en plus de l’ensemble conﬁguration-transition le meilleur, quelques autres possibilitées
de transition pour la conﬁguration considérée.

De plus, l’analyse étant déterministe, celle-ci s’interrompt lorsqu’il n’y a pas de transition
applicable. Beaucoup de structures de dépendances résultantes sont alors incomplétes ou parfois
complétement vides. La proposition précedente, permettrait donc ensuite de pouvoir faire un

92

retour en arriere dans la séquence de transitions. Le nombre de retour en arriere possible pour
une phrase devra étre limité et le choix d’une nouvelle transition pourra se baser sur la seconde
meilleure transition pour une certaine conﬁguration. Ce probléme est aussi une cause du faible
score du rappel dans toutes les analyses. En effet, beaucoup de mots n’ont tout simplement pas
d’attribution de type alors que les mots ayant une dépendance sont plus souvent correctement
typés, d’o1‘1 une précision meilleure que le rappel (voir exemple table 5).

Le choix d’une premiere transition puis d’une potentielle seconde meilleure transition devra
se baser sur des données probabilistes. Ainsi, pour établir ces données il sera nécessaire
d’expérimenter différents lissages avant de mémoriser les ensembles conﬁguration-transitions
dans l’oracle.

D’apres les résultats des expérimentations, les oracles utilisant un vecteur de taille 8 sont plus
efﬁcaces car ils mémorisent les types des dépendances gauches et droites des deux mots traités lors
de l’analyse. Cependant, ces informations ne sont pas pertinentes dans tous les cas. Notamment,
le fait de savoir qu’un mot a une dépendance de type modiﬁcateur n’est pas déterminant pour la
suite car rien n’empéche ce mot d’avoir d’autres modiﬁcateurs. Tous les types itérables, comme
les modiﬁcateurs, les circonstantiels, les coordinations verbales, assignés ‘a une dépendance ne
seront donc pas mémorisés. Nous garderons uniquement des informations appropriées telles que
les types prédicat, déterminant, objet, etc...

5 Conclusion

Les objectifs de cet article étaient de proposer des résultats d’expérimentations avec un analyseur
syntaxique par transitions étendu aux dépendances discontinues et de préparer la base d’une
comparaison de ces résultats avec un oracle guidant l’analyse de la CDG du francais.

L’analyse par transition décrite dans cet article ne permet pas encore d’obtenir des résultats
sufﬁsants pour obtenir une bonne analyse en dépendance du francais. Cependant, le systeme
de transitions mis en place pour correspondre avec la grammaire CDG est tout ‘a fait adaptée
‘a l’ajout des dépendances discontinues par valences polarisées. De plus, nous voulions mettre
en évidence les intéréts et les problemes de ces premieres expérimentations sur des phrases en
francais pour mettre en place un plan d’améliorations de l’analyse par transitions. Dans l’état
actuel, l’a1gorithme établi pour analyser les phrases en structures de dépendances est déterministe
et ne permet pas de faire des choix bien adaptés aux conﬁgurations traitées. L’aspect probabilistes
mis en place pour calculer la fréquence d’apparition des conﬁgurations dans l’analyse des phrases
du corpus devra étre exploité pour sélectionner les meilleures transitions possibles pour une
conﬁguration et pas seulement la meilleure. En outre, les vecteurs de traits devront étre mieux
adaptés a l’information dont l’analyseur a besoin pour faire les bons choix.

Des lors, les prochains résultats permettront de comparer cette analyse avec l’oracle qui guide
l’analyse de la CDG du francais et ainsi d’établir de nouvelles méthodes d’amorc;ages pour
attribuer les tétes des dépendances avant l’analyse de la CDG.

93

Références

ALFARED, R., BECHET, D. et DIKOVSKY, A. (201 1). “CDG Lab” : a toolbox for dependency
grammars and dependency treebanks development. In DEPLING 2011 (International Conference
on Dependency Linguistics), Barcelona.

BAR-HILLEL, Y., GAIFMAN, C. et SHAMIR, E. (1964). On categorial and phrase structure grammars,
pages 99-115. Addison-Wesley.

BRUNET-MANQUAT, E (2005). Improving dependency analysis by syntactic parser combination.
In NLP-KE 2005 (Natural Language Processing and Knowledge Engineering), Wuhan.

CANDITO, M., CRABBE, B., DENIS, 1? et GUERIN, F. (2009). Analyse syntaxique du francais : des
constituants aux dépendances. In TALN 2009 (Traitement automatique des langues naturelles),
Senlis.

CANDITO, M.-H. et KAHANE, S. (1998). Une grammaire tag vue comme une grammaire sens-texte
précompilée. In TALN 1998 (T raitement automatique des langues naturelles), Paris.

C1-101, J. D. et PALMER, M. (2011). Getting the most out of transition-based dependency parsing.
In ACL 201 1 (Association for Computational Linguistics), Portland.

DEKHTYAR, M. et DIKOVSKY, A. (2008). Generalized Categorial Dependency Grammars, pages
230-255. LNCS 4800. Springer.

DIKOVSKY, A. (2011). Categorial dependency grammars : from theory to large scale grammars.
In DEPLING 201 1 (International Conference on Dependency Linguistics), Barcelona.

KAHANE, S. (2001). Grammaires de dépendance formelles et théorie sens-texte. In TALN 2001
(Traitement automatique des langues naturelles), Tours.

Kow, E., PARMENTIER, Y. et GARDENT, C. (2006). Semtag, the loria toolbox for tag-based parsing
and generation. In TAG+8 (The Eighth International Workshop on Tree Adjoining Grammar and
Related Forrnalisms), Sydney.

KUBLER, S., McDoNALD, R. et NIVRE, J. (2009). Dependency parsing. Morgan et Claypool.
MARUYAMA, H. (1990). Structural disambiguation with constraint propagation. In ACL 1990
(Association for Computational Linguistics), Pittsburgh.

MEL’cU1<, I. (1988). Dependency syntax : Theory and Practice. State University of New York Press.
NASR, A. (2004). Analyse syntaxique probabiliste pour grammaires de dépendances extraites
automatiquement. Habilitation a diriger des recherches, Université Paris 7, UFR d’informatique.
NIVRE, J. (2008). Algorithms for Deterministic Incremental Dependency Parsing, pages 513-553.
Volume 34 (4). Massachusetts Institute of Technology.

NIVRE, J. (2011). Bare-bones dependency parsing. In NODALIDA 201 1 (Nordic Conference of
Computational Linguistics), Riga.

RAMBOW, O. (2010). The simple truth about dependency and phrase structure representations.
In NAACL HTL 201 0 (North American Chapter of the Association for Computational Linguistics -
Human Language Technologies), Los Angeles.

VANRULLEN, 'I‘., BLACHE, P. et BALFOURIER, J.-M. (2006). Constraint-based parsing as an efﬁcient
solution : Results from the parsing evaluation campaign easy. In LREC 2006 (Conference on
Language Resources and Evaluation), Genoa.

94

