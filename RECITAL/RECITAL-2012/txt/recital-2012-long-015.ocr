Compression textuelle sur la base de regles issues
d'un corpus de sms

Arnaud Kirsch
UCL - CcnTAL - Placc Blaisc Pascal 1, Louvain-la-Ncuvc, 1348
arnaud.kirsch@student.uclouvain.be

RESUME

La présente recherche cherche a réduire la taille de messages textuels sur la base de
techniques de compression observées, pour la plupart, dans un corpus de sms. Ce papier
explique la méthodologie suiVie pour établir des regles de contraction. I1 présente
ensuite les 33 regles retenues, et illustre les quatre niveaux de compression proposes par
deux exemples concrets, produits automatiquement par un premier prototype. Le but de
cette recherche n'est donc pas de produire de "l'écIit-sms", mais d'élaborer un procede
de compression capable de produire des textes courts et compréhensibles a partir de
n'impoIte quelle source textuelle en frangais. Le terme "d'essentialisation" est propose
pour designer cette approche de reduction textuelle.

AB STRACT

Textual Compression Based on Rules Arising from a Corpus of Text
Messages

The present research seeks to reduce the size of text messages on the basis of
compression techniques observed mostly in a corpus of sms. This paper explains the
methodology followed to establish compression rules. It then presents the 33 considered
rules, and illustrates the four suggested levels of compression with two practical
examples, automatically generated by a ﬁrst prototype. This research’s main purpose is
not to produce "sms-language", but consists in designing a textual compression process
able to generate short and understandable texts from any textual source in French. The
term of "essentialization" is proposed to describe this approach of textual reduction.

MOTS-CLEFS : resume automatique, compression de texte, sms, lisibilité, essentialisation.

KEYWORDS : summarization, text compression, text messaging, readability,
essentialization.

Actes de la con_fe'rence conjointe JEP-TALN-RECITAL 2012, volume 3: RECITAL, pages 309-322,
Grenoble, 4 an 8 juin 2012. ©2012 ATAI.A 8: AFCP

309

1. Introduction

Les locuteurs, en pleine "convergence numerique", sont amenes simultanement a
echanger divers types de messages ecrits dans de memes environnements (c'est le cas de
Facebook ou la meme interface permet l'echange de mails, de messages instantanes et de
sms) et de memes types de messages ecrits dans des environnements divers (des emails
peuvent etre rediges depuis un ordinateur, une tablette ou un GSM). Un mode de
communication bref et informel traverse ainsi les genres et les media, mode mis en
evidence par la presente recherche, qui veut proposer une aide a la redaction de
messages courts.

En cela, nous nous sommes naturellement interesse au resume automatique et a la
compression de donnees, mais ces deux approches ne rencontrent pas totalement notre
objectif : nous avons donc choisi de deriver de nouvelles regles de contraction emanant
des pratiques des locuteurs. En effet, le resume automatique, apparu en linguistique
informatique avec Luhn a la ﬁn des annees 1950 (Luhn, 1958), a pour but la
simpliﬁcation d'un texte en ne retenant que les idees principales de celui-ci et en les
rassemblant dans un nouveau texte grammaticalement acceptable ((Minel, 2004),
(Yousfi-Monod, 2007)). La compression de donnees Vise elle a modifier la
representation binaire des donnees pour en reduire le poids numerique. Elle necessite
decompression du cete du recepteur.

A l'inverse, la proposition qui fait l'objet de cet article possede trois caracteristiques
essentielles. (1) Le processus de simpliﬁcation se situe au caractére pres : nous
cherchons a isoler les caracteres les plus essentiels a la transmission de la totalite de
l'information contenue dans le message initial, ce qui nous eloigne du resume
automatique stricto sensu (Minel, 2004). Nous nous distinguons egalement de la
compression textuelle (Yousﬁ-Monod, 2007) qui cherche a supprimer les segments non
porteurs de sens dans un texte. (2) Le processus de simpliﬁcation ne doit pas entraver la
compréhension : quel que soit le taux de compression recherche, nous devons
produire le texte le plus decodable possible, soit celui a partir duquel, malgre la
disparition d'un certain nombre de caracteres, un lecteur pourra le plus aisement
retrouver le texte initial. Cela signiﬁe qu'il y aura une borne minimale en deca de
laquelle il ne sera pas possible de descendre, au risque de rendre le texte de base
totalement inintelligible (puisque nous entendons transmettre le texte tel que comprime,
sans intention de decompression a l'arrivee). (3) Enﬁn, il s'agit d'un processus de
compression : seuls les mecanismes permettant de reduire la taille du message doivent
etre pris en compte. Pour respecter ces caracteristiques, nous nous sommes base sur le
corpus de sms de (Fairon et al., 2006a), et avons extrait une serie de regles de
compression. Malgre les caracteristiques du corpus d'entrainement, nous ne projetons
pas de reproduire de l'écrit-sms ((Cougnon et Francois, 2010) ; nous le noterons e-sms).
Notre intention n'est donc pas d'inverser les systemes de normalisation tels que ceux
developpes par (Yvon, 2008) et (Beaufort et al., 2010).

Notre recherche, meme si elle participe du resume automatique, s'en distancie donc. En
effet, selon la premiere caracteristique enoncee ci-dessus, nous ne cherchons pas a
extraire les idees principales d'un texte, ni a produire un message grammaticalement
acceptable : nous travaillons presque exclusivement au niveau des caracteres et tentons
de conserver toutes les informations du texte initial. Aussi nous avons prefere parler
"d'essentialisation" de texte, dont voici la deﬁnition : "sous-procede du resume
automatique focalise sur la reduction du nombre de caracteres". Le prototme de
programme d'essentialisation automatique, ou essentialiseur, a notamment pour objectif

310

la creation d'une application Tv»itter®‘. Nous envisageons, a l'instar de ce qui se fait déja
en anglais (140it, 2012), qu'un utilisateur encode un texte plus grand et le reduise
automatiquement a l'aide dudit programme.

Dans cet article nous aborderons tout d'abord la méthodologie que nous avons suivie
pour établir nos regles. Nous expliquerons ensuite le fonctionnement global d'un
premier protot§pe d'essentialiseur, en détaillant les regles retenues et les classements de
celles-ci. Nous terminerons par l'évocation des difﬁcultés et resistances rencontrées et
des perspectives de recherche que nous envisageons.

2. Méthodologie

Notre proposition d'essentialisation se base sur le corpus de (Fairon et al., 2006a). Ce
corpus a été constitué dans le cadre du projet sms4science : 30.000 messages ont été
transcrits et annotés en 2004. Ces messages sont des sms veritablement echanges er1tre
usagers et permettent donc d'observer les pratiques réelles de simpliﬁcation de la
population. Nous avons travaille sur trois sous-corpus : l'un contenant les messages
d'exactement 160 caracteres 2, un autre ceux de plus de 160 caracteres, et le dernier les
messages transcrits de plus de 160 caracteres3. Les messages de 160 caracteres ont
constitué notre corpus d'entrainement, et les deux autres ont servi a valider nos
observations.

Sur la base de ces sous-corpus, nous avons établi une liste de regles de contraction.
Celles-ci consistent en la formalisation de certains phénomenes en vue de respecter deux
enjeux majeurs : l'intercompréhension et la compression. Les phénomenes les plus
recurrents sont retenus parce qu'ils sont supposes étre les plus intelligibles. Parmi ceux-
ci, nous ne nous intéressons qu'a ceux permettant de diminuer la taille du texte. A ces
observations nous avons ajoute certaines regles qui ne sont pas issues de notre
observation du corpus, par exemple la formalisation des dates et des heures (norme ISO
8601, cf. (ISO, 2012)). Enﬁn, nous avons ordonné ses regles et avons établi différents
niveaux de contraction.

3. Le systéme

La deuxieme étape de ce travail a consisté a implémenter un premier prototwe
d'essentialiseur. A ce stade de nos travaux, certains tests statistiques et une evaluation

preliminaire sont rendus possibles, comme nous le montrons ensuite.

1 Site de microblogging, soit d'échange de courts messages ne pouvant dépasser 140 caractéres.

2 Ancienne limite technique, la limite de 160 caractéres est aujourd'hui une limite de facturation :
un sms de 161 caractéres sera facturé comme deux messages. Des études statistiques menées,
notamment, sur notre corpus, ont démontré qu'il y avait un pic de sms de 160 caractéres (Cougnon
et Francois, 2010).

3 Le premier corpus contenait 2223 sms, le deuxiéme 2298 et le troisiéme 8310.

311

3.1. Les régles

Nous avons établi 33 regles. Le TABLEAU 1 reprend chacune de ces regles, en donne une
explication succincte et l'illustre par un exemple concret. Les codes utilisés renvoient aux
classements présentés par la suite (cf. 3.3.).

Régle

[0101]

[0302]

[0203]

[0504]

[0705]

[0406]

[1107]

[1208]

[0809]

Description

Reduction des smileys

Remplacement des URL par une forme
plus courte

Reduction des repetitions inutiles de
caracteres

Réalisation des unites lexicales en
logogrammes

Remplacement par un synonyme

Norrnalisation des dates et des heures au
format ISO 8601

Suppression du pronom sujet quand les
formes verbales sont non ambigues
(notamment les il impersonnels)

Si deux verbes consécutifs utilisent le
meme pronom sujet, et que la premiere
occurrence du pronom sujet est
maintenue, la seconde peut-étre
supprimée

Ellipse des "et" qui retournent une
interrogation et des "ne" de la negation

312

Exemple

. :-) -) :)
. -1 9 _T_"

. http://
wvvw.uclouvain.be/
cental-
cahiers.html#langsms
-) http://tinyurl.com/
7lumcf7

Mdrrrrrrr -) mdr

Looooool -) lol

Vingt-quatre -) 24
. Et -) &

Travailler -) bosser

Le 14jui11et 1989 vers
12h3o -) 1989-07-14
vers 12:30

Nous allons arriver -)
allons arriver

Il faut partir -) Faut
partir

Je pense a toi. Je veux
te revoir. -) Je pense a
toi. Veux te revoir.

Je vais bien, et toi ? -)
Je vais bien, toi ?

- Je ne pense pas -) Je
pense pas

Régle

[1010]

[2411]

[3012]

[1513]

[1614]

[2115]

[2016]

[2317]

[2218]

[1319]

[1420]

[2721]

[2522]

[1723]

Description

Suppression des mots répétés (ne
concerne pas les pronoms personnels)

Reduction aux initiales des noms propres
composes et des noms communs
composes les plus courants
Simplification des repetitions de
pronoms personnels

"tu" et "Vous", suivis de voyelles,
VI WI

deviennent, respectivement, "t'" et 2

Reduction des "tu" et "je" a l’initiale

Fusion des mots composes, locutions,
etc. Reconnus par ailleurs

"bisou(s)" en ﬁn de texte > "x"

Les monosyllabiques courants sont
réduits a leur squelette

Certaines ﬁns de mots courantes sont
réduites a leur squelette

Certains mots tres courants du texte sont
réduits a leur squelette

Apocopes des mots les plus frequents

Suppression des consonnes finales
muettes, sauf les marques du pluriel

Si pas d’ambigu'ité, suppression des
marques muettes du pluriel

Suppression des schwas peu prononcés
et fusion avec le mot su1vant

313

Exemple
Hello hello -) Hello

Pierre-Yves -) P.Y.
Week-end -) w.e.

Nous nous reverrons
-) nous reverrons

Tu arrives -) t'arrives

Vous arrivez —)
z'arrivez

Tu vas -) tvas

Je pense -) jpense

Porte-monnaie —)
portemonnaie

A plus, bisous. -) a
plus,x

Temps -) tps

Internement -)
internemt

Beaucoup -) bcp
Anniversaire -) anniv

A travers -) a traver

J ournaux -) journau

Dernierement -)
dernierment

Je ne sais pas -> je
nsais pas

Régle

[3124]

[1825]

[2626]

[2827]

[2928]

[0629]

[1930]

[3231]

[0932]

[3333]

Description

Suppression de tous les schwas ; les
monosyllabiques fusionnent avec les
mots qu’ils precedent

Suppression des "h" muets
Simpliﬁcation des doubles consonnes

Les phonemes transcrits par plusieurs
caracteres sont remplacés par des
caracteres uniques

Phonétisation des syllabes par la lettre, le
signe ou le chiffre

Simpliﬁcation des abréviations

Suppression des points finaux, des
apostrophes, des traits d’union et
simpliﬁcation des points de suspension
(réduits a deux points successifs)

Suppression des doubles points et
points-virgules

Les espaces séparant deux systemes
graphiques différents sont supprimés

Suppression de tous les espaces
scriptura continua (sauf entre deux
caracteres numériques)

3.2. Remarques sur le tableau

Exemple

. Je me grouillerai —)
jmgrouillerai

Hérisson -) érisson

Notamment -)
notament

J e voulais que tu
viennes -) je voule ke
tu vienes

J'ai envie de toi -) G
envie 2 toi

P.-S. -) PS

J'imagine -) jimagine

Penses-tu -) pensestu

Je disais : comment
vas-tu ? -) je disais
comment vas-tu ?

J'ai passe 1 bonne
joumée -) j'ai
passe 1bonne journée

Je suis dégouté ! Et il
est la ! -) je suis
dégouté!Et il est la!

. Je ne crois pas -)
jenecroispas

Nous regroupons ici une série de remarques concemant le Tableau 1 :

- L'ordonnancement des regles n'est pas ﬁgé : en fonction des résultats d'une enquéte
qualitative, ou en cas d'ajout ou de suppression d'une regle, l'ordre global peut étre
repensé : il y a une grande variété de types de compression d'un meme texte, nous en

314

choisissons une, sans prétendre qu'elle soit la meilleure, aﬁn qu'elle serve de ligne de
conduite ;

Certaines regles, comme [0101] et [0203] proviennent typiquement de
caractéristiques propres au corpus sur lequel nous nous sommes base : le but de notre
systeme étant de pouvoir travailler sur n'importe quel type de texte, nous devons donc
y intégrer des regles plus spéciﬁques a certains textes qu'a d'autres ;

[0203] seule : il est clair que ces repetitions sont porteuses de sens également, et que
les supprimer rewient a enlever une partie du sens encode initialement. C'est
neanmoins un choix que nous posons de les réduire, aﬁn de gagner quelques
caracteres;

Un logogramme (mentionné en [0504]) est un "[d]essin représentatif d'une notion
(logogramme sémantique ou idéogramme) ou d'une suite phonique constituée par un
mot (logogramme phonétique ou phonogramme)." (TLFi, 2012) ;

Les smonymes, tels qu'évoqués par la regle [0705], soulevent un probleme evident : il
n'existe que tres peu de synonymes parfaits, et une substitution peut donc
fréquemment modiﬁer une partie du sens apporté. Pour cette approche préliminaire,
nous avons établi manuellement une courte liste de synonymes, dont les variations
sémantiques portent plutot sur le registre de langue ("bosser" pour "travailler", par
exemple). Ce choix est certes discutable, mais est en lien avec notre remarque
préliminaire : nous cherchons a cadrer avec un mode de communication bref et
informel;

De nombreuses regles, comme [1107], [1208], [0809], etc. se basent sur le constat que
le francais est parfois redondant (repetitions, reformulations, etc.). Nous cherchons a
déﬁnir ces redondances (et d'autres) pour les reduire au maximum et donc gagner de
l'espace ;

La regle [2115] prévoit la fusion des mots composes et autres locutions (puisque plus
facilement identiﬁables/compréhensibles par le lecteur). Si nous avions simplement
decide de fusionner les collocations4 se serait posee la question de l'évaluation du
degré de ﬁgement des syntagmes. Nous avons donc tout d'abord repris une liste ﬁnie
de mots composes que nous avons augmentée de locutions relevées automatiquement
dans notre coIpus5 ;

Les regles relatives aux squelettes consonantiques ([2317], [2218] et [1319]) sont
établies, elles aussi, sur la base de notre corpus : nous avons relevé de tres nombreux
squelettes et en avons dégage des constantes. La difﬁculte de ces trois regles est de
determiner quelles unites sont plus facilement compréhensibles lorsqu'elles sont
autant réduites. En ce qui concerne leurs fréquences d'apparition, nous nous sommes
base sur une evaluation statistique de notre corpus ;

Lors de la phonétisation des syllabes [2928], les lettres a lire pour leur valeur
phonétique seront encodées en majuscule. Aussi, avant l'application de cette regle,
toutes les majuscules orthographiques sont réduites, aﬁn d'éViter tout risque de

4 Au sens de << cooccurrences statistiquement prixilégiées >>.

5Pour ce faire, nous avons mesuré la fréquence d'apparition de chaque mot dans les transcriptions
des SITIS du corpus, ainsi que celle de leurs contextes gauche et droit. Nous avons donc pu établir
les fréquences d'apparition de tous les syntagmes du corpus et avons retenu les plus présents.
Nous avons utilisé les transcriptions afin d'é\iter les problémes d'instabilité orthographique.

315

confusion. La question se pose cependant de savoir quel s§steme suiwe lors de la
fusion des caracteres [3333] : maintenir la phonétisation ou concaténer les mots non
phonetises en utilisant des majuscules pour marquer l'emplacement des espaces
supprimes ? Cette question deVra étre tranchee apres enquéte qualitative ;

. Nous distinguons quatre systemes graphiques pour etablir la regle [0932] : les lettres,
les chiffres, les signes de ponctuation et les symboles. Cette distinction est établie par
nous-meme. La scriptura continua5 peut sembler excessive. Elle est cependant
présente dans quelques sms, et apparait a quelques reprises dans l'histoire de l'écriture
(par exemple durant l'Antiquité). Ainsi nous décidons de la maintenir.

3.3. Leur classement

Nous avons ordonné ces regles selon deux classements distincts. L'un dependant de
l'ordonnancement informatique, l'autre prenant en compte l'application du systeme.

Le premier classement répond a deux exigences : d'une part classer les regles selon leur
inﬂuence sur la lisibilité (ce classement est représente par les deux premiers chiffres du
code d'une regle) ; d'autre part selon l'ordre dans lequel elles doivent étre appliquees
pour ne pas se géner mutuellement : par exemple, il faut formaliser les dates avant de
phonetiser les noms des mois (les deux derniers chiffres du code illustrent ce second
ordre).

Le second classement, orienté vers l'application ﬁnale, enVisage deux types d'utilisation :
le premier, qualitatif, ou l'utilisateur doit choisir entre quatre niveaux d'essentialisation
predeﬁnis, et le second, quantitatif, ou le programme connait le seuil de caracteres sous
lequel ramener le texte initial et applique les regles jusqu'a y parvenir (ou non).

3.4. Les quatre niveaux

Revenons plus en detail sur les quatre niveaux d'essentialisation que nous proposons.
Chaque niveau permet de déﬁnir une sequence de regles a appliquer pour atteindre un
certain degre d'essentialisation. Nous enwisageons d'abord deux exemples produits par
notre protot§pe, puis nous les commentons et détaillons les choix theoriques sous-
jacents.

3.4.1.Déﬁniu'ons

Superﬁciel : ce niveau touche uniquement a ce que nous jugeons accessoire, aux
caracteres qui ne sont la que pour ﬂuidiﬁer la lecture, comme les repetitions émotives de
caracteres ("loooool"), les espaces précédant certains signes de ponctuation ("Non !"),
l'utilisation de logogrammes ("Vingt-quatre" > "24" ; "et" "&"), la suppression de certains
mots redondants, par ailleurs souvent absents du langage oral ("ne" de la negation), etc.
Ce niveau ne supprime donc que des caracteres que nous pourrions qualiﬁer de
sémantiquement moins pertinents.

Conventionnel : I1 s'agit d'appliquer une série de regles qui sont des pratiques
frequentes de l'ecrit (bien au-dela des seuls sms), ou des transcriptions de l'oral. Nous
pensons par exemple aux apocopes de mots frequents ("anniv"), a l'effacement des
schwas toujours silencieux ("effacement"), aux abréwiations courantes ("tps", "ds",

6 Le terme scriptio continua est également employé.

316

"qq"...), a l'élision de certains pronoms sujets, ou a leurs simpliﬁcations ("zavez vu",
"faut y aller"...). Nous commencons ici a atteindre plus conséquemment l'orthographe et
la syntaxe, mais selon des pratiques qui, par leur fréquence dans notre corpus et notre
propre perception, semblent rapidement déchiffrables.

Morpho-syntaxe du sms : Ce niveau se concentre sur des phenomenes couramment
trouvés dans des sms, notamment la phonétisation de certains phonemes transcrits par
plusieurs caracteres, la contraction en squelettes consonantiques de certaines ﬁns de
mots, ou de certaines unites lexicales fréquentes. Nous ne recensons ici que les
phénomenes les plus frequents aﬁn que nos messages restent les plus compréhensibles
possible : en effet nous partons du principe que les phénomenes les plus courants seront
les plus intelligibles.

Cryptage : On parle ici de l'application de toutes les regles observées dans notre corpus,
aﬁn de gagner un maximum de caracteres. Il ne s'agit plus de tenter de conserver un
minimum de décodabilité, le but est la compression : phonétisation de toutes les
syllabes, suppression d'un partie de la ponctuation, suppression des espaces, etc.

3.4.2.Application

Les quatre niveaux d'essentialisation que nous avons déﬁnis servent a dégager un
formalisme. Ils ont été poses arbitrairement, puisque seule la deﬁnition des niveaux est
importante. Le but est d'obtenir une description stricte des attentes et conditions de ces
niveaux, aﬁn de choisir les regles qui y correspondront le mieux. Quel que soit le nombre

Niveau Forme Taille

Hi tite puce,g pensé a tfer 1pti sign 2vi,tu m'mank

Corpus grav.pq pa svoir 2m1?alé pass ibonnuit 90

Hi petite puce, j'ai pensé a te faire un petit signe de vie,
Forme standard tu me manques grave. Pourquoi pas se voir demain ? 138
Allez passe une bonne nuit

Hi petite puce,j'ai pensé a te faire1petit signe de vie,tu
Superﬁciel me manquegrave.Pourquoi pas se voir demain?A1lez 124
passe1bonne nuit
Hi ptit puc,jai pensé a tfair1ptit signde vie,tu
Conventionnel mmanqugrav.Pourquoi pas svoir demain?Allez 105
passibonnnuit

Morpho-syntaxe hi ptit puc G penC a t9er1pttsign2vi tmmankgrav 80
du sms pourkoi pasvoir2m1alé pas1bOn n8

hiptitpucGpenCat9er1pttsign2vitmemankgravpourkoip

Cryptage asevoir2m1alépas1bOnn8

71

317

de niveaux deﬁnis, l'important reside dans la gradation continue entre ceux-ci, tant du
point de vue de l'intercompréhension que de la compression.

Deux exemples permettent d'illustrer les résultats de chaque niveau. Le premier
exemple7 est un texte illustrant l'immédiateté (cf. TABLEAU 2), le seconds exposant la
distance‘? (cﬁ TABLEAU 3).

Niveau Forme Taille

Je rappelle que les banques ont payé plus a l'Etat belge
que ce qu'on leur a donné. Les garanties sur Dexia ont
rapporté bien plus que le milliard qui a éte mis dans
Dexia. Tout a été payant.

Forme standard 191

Je rapelle que lebanques ont paye plus a l'Etat belge
que ce qu'on leur a doné.Les garanties sur Dexia ont
rapporté bien plus que le milliard qui a éte mis dans
Dexia.Tout a été payant.

Superﬁciel 185

J rapell qulebanqus ont paye plus a lEtat belgque cquon
leur a done Les garanties sur Dexia ont rapporté bien
plus que lmilliard qui a été mis ds Dexia.Tout a été
payant.

Conventionnel 169

jrapel klébanks on peye + a léta belj ke ce kon leur a
dOne lé garantisur dexia on rapOrT bi1 + ke lmiliar ki a 144
eT mi ds dexia tout a éT peyan

Morpho-syntaxe
du sms

jrapelkelébankonpeyé
Cryptage +alétabeljkecekoleuradoné.légarantisurdexiaonrapOrT 110
bi1+klmiliarkiaeTmidandexiatoutaéTpeyan

3.4.3.Ana1yse des résultats

Le niveau superﬁciel enregistre un taux de reduction de 14% pour le premier exemple,
et de seulement 3% pour le second. Le taux moyen de compression de ce niveau se situe
a hauteur de 9%. Les textes produits ne sont pas tres réduits, mais restent
compréhensibles : la forme des mots n'est pas atteinte. Il reste quelques erreurs
produites par notre prototype, notamment "lebanques", qui aurait dﬁ rester "les
banques", et la meme chose pour "maquegrave". Une assez grande difference que l'on

711 s'agit d'un sms issus du corpus.
8 (Libre Belgique, 2011 : 5)
9 L'opposition immédiat versus distance est proposée par (Koch et Csterreicher, 2001). La

distance communicative dénote le degré d'implication (immédiat) ou de détachement (distance)
des locuteurs dans le discours.

318

trouve entre les taux de compression des deux messages est probablement due au fait
que le premier message est du meme type que notre corpus d'entrainement.

Au niveau conventionnel, le sms obtient un taux de reduction de 24% et l'extrait de
journal 1o,5%. A nouveau, l'ecart est assez large entre les deux. Le taux moyen se situe a
18%. Par rapport au premier niveau, la progression est assez marquee du point de we de
la compression. En ce qui conceme la comprehension, le texte devient deja plus
hermetique, principalement lorsque des schwas ont ete supprimes, avec l'espace qui les
suivait. Cette agglutination de mots, si elle permet de gagner des caracteres, gene le
decodage du texte. Cependant, si nous regardons le troisieme niveau, l'ecart perceptif
entre celui-ci et le deuxieme qui nous occupe semble plus important qu'entre les deux
premiers niveaux. Notre impression est donc que la gradation n'est pas continue entre
les trois premiers niveaux.

Les taux de reduction des deux exemples du niveau morpho-syntaxe du sms sont
respectivement de 42% et 25%. Le taux moyen de ce troisieme niveau est de 34%. Les
deux textes reprennent certaines caracteristiques des sms et leur aspect est similaire a
l'ecIit sms. Nous pouvons d'ailleurs apprecier cette ressemblance en comparant le niveau
3 du premier exemple a la version originale de ce sms dans notre corpus. 11 y a des
differences, (rappelons que nous ne cherchons pas a produire de l'e-sms) mais nous
devons aussi garder a l'esprit que les possibilites de combinaison des regles sont tres
nombreuses, et que notre s§steme est deterministe : il produira toujours la meme sortie
pour un meme texte. A l'inverse, un locuteur n'emploiera pas forcement les memes
techniques d'un message a l'autre.

Les deux taux de reduction du niveau cryptage convergent assez fort, puisque le
premier texte atteint un taux de reduction de 49% et le second de 43%. Le taux moyen
est de 44%. La compression est excellente, puisque pres de la moitie du texte a ete
supprimee. La comprehension est par contre bien plus delicate. I1 semblerait qu'il
manque trop de caracteres pour que la lecture reste ﬂuide. En effet, l'absence d'espace
empeche le lecteur de delimiter les unites lexicales. Les deux textes produits ressemblent
a une suite continue de phonemes, a l'instar de ce qu'est le signal sonore.

3.5. Evaluation

Etant donne que nous sommes a une etape preliminaire de notre recherche, nous
n'avons pas encore pu realiser d'evaluation qualitative‘° de ce travail. Nous proposons
donc une evaluation en deux parties : une evaluation quantitative d'une part, et le releve
manuel des limites de notre systeme, d'autre part.

3.5.1.Evaluation quantitative

Pour etablir les taux moyens de compression, nous avons utilise un corpus de test
compose de cent textes courts ou extraits repartis comme suit : cinquante transcriptions
de sms tirees de notre corpus, quarante extraits de journaux et dix extraits litteraires“.
Nous avons mesure le taux moyen de compression produit par les quatre niveaux
mentionnes ci-dessus sur l'ensemble de notre corpus de test. 11 nous est impossible de
mesurer la divergence de nos resultats par rapport a une reference, celle-ci n'existant

1° Validation des choix théoriques par un échantillon de testeurs humains.

1‘ De dix auteurs différents.

319

pas. A l'inverse du resume automatique, nous ne pouvons essentialiser manuellement, ni
comparer les resultats d'un systeme equivalent.

Au mieux, dans le cas des 50 sms, aurions-nous pu comparer nos taux de compression a
ceux des locuteurs. Cependant, la variabilite de l'ecIit sms nous empecherait de savoir a
quel niveau d'essentialisation comparer le sms reel. Et un taux moyen ne serait pas plus
eclairant. Nous devons donc nous limiter a une observation des taux moyens de chaque
niveau. Le but est d'evaluer la gradation de la compression entre les quatre niveaux
proposes.

Les chiffres ainsi obtenus Viennent, d'une certaine facon appuyer notre premiere
impression : la progression n'est pas continue entre les quatre niveaux d'essentialisation
tels qu'ils sont deﬁnis actuellement. Nous passons en effet de 9% a 14% puis a 34% pour
atteindre 44% au dernier niveau. Le deuxieme niveau semble donc ne pas etre un bon
intermediaire entre le premier et le troisieme ; ou alors ceux-ci sont-ils respectivement
trop conservateur et trop destructeur. Nous dewons attendre d'avoir obtenu les resultats
d'une evaluation humaine pour le determiner et corriger ces premieres propositions.

Cependant, malgre certains soucis de gradation et quelques problemes
d'implementation, nous obtenons assez rapidement des taux de reduction interessant.
Le dernier niveau peut aller jusqu'a reduire de moitie la taille du texte initial, et le
deuxieme s'approche de 15% de reduction. Considerant que notre but est de transmettre
un texte maintenant toutes les nuances du texte d'oIigine et generant le moins
d'ambiguite possible, ces premiers resultats sont assez encourageants, meme s'ils ne
nous permettent pas encore d'evaluer objectivement l'evolution de la lisibilite des textes
produits.

3.5.2.Limites du systéme

Il convient d'etre assez critique au regard de nos premiers resultats. Nous rencontrons
en effet deux t§pes de problemes avec notre premier prototype d'essentialiseur : le
premier se situe au niveau de l'algorithme general d'application des regles, l'autre au
niveau de certaines regles elles-memes.

Tout d'abord, bien que nous en ayons conscience et ayons tente d'eViter ce type
d'inconvenients, certaines regles genent l'application des suivantes, voire annulent leurs
resultats. Par exemple, la regle [2031] supprime une serie de signes de ponctuation qui
pourraient se retrouver dans des adresses web prealablement reduites par la regle
[0302]. Ou encore, si la regle [0504], qui remplace, notamment, les nombres ecrits en
toutes lettres par leur equivalent en chiffres arabes ne s'applique pas correctement,
toutes les autres regles qui s'appuient sur des chiffres seront induites en erreur. Ensuite,
certaines regles qui semblent ewidentes pour l'esprit humain ne sont pas toujours les
plus simples a formaliser pour la machine. 11 en va ainsi de la regle [0504], que nous
avons deja citee : des trente-quatre, c'est elle qui fut la plus difﬁcile a implementer, et a
optimiser. I1 existe en effet une multitude de conﬁgurations possibles pour l'enonciation
de nombres, et nous n'avons considere que les plus frequentes, partant du double
constat que nous pourrons ameliorer cette regle lors des prochaines etapes de notre
reﬂexion et qu'il y aura probablement fort peu de cas ou les utilisateurs entreront des
nombres en toutes lettres.

Mais le principal probleme que nous rencontrons reste la variabilite de la langue :
comme nous l'avons deja precise ci-dessus, le francais, comme d'autres langues
naturelles, offre d'innombrables possibilites de variations que nous ne pourrons pas

320

toutes envisager, or certaines d'entre elles ameneront notre systeme a commettre des
erreurs et a manquer son objectif (par exemple les dates : nous tentons de les formaliser,
mais un utilisateur pour aussi bien entrer "le 2 juillet 1989" que "2 du 7 89" ou encore
"7-2-89"). Ce premier protot§pe doit donc encore étre améliore.

4. Conclusions

La premiere étape de cette recherche ouwe de tres nombreuses perspectives
d'optimisation. D'un point de vue technique, pour corriger les problemes mentionnés ci-
dessus, nous envisageons notamment de marquer certains caracteres, de sorte qu'ils ne
puissent plus étre modiﬁes. Nous continuons par ailleurs a réﬂéchir a un meilleur
algorithme de conversion de nombres. Au niveau du systeme lui-meme, d'autres regles
pourraient étre ajoutées, s'appuyant éventuellement sur d'autres types de corpus qu'un
corpus de sms, pour y observer d'autres mécanismes. Enﬁn les quatre niveaux que nous
avons présentés devront également étre afﬁnes, et de nouveaux pourraient étre ajoutes
au systeme.

Une evaluation qualitative effectuée par des locuteurs nous permettra d'ameliorer notre
estimation de la lisibilité des textes essentialisés, éventuellement de repenser
l'organisation des regles ou des niveaux du systeme actuel, mais également de valider
nos propositions quant a l'essentialisation en general. 11 reste donc de nombreuses pistes
de réﬂexion, et nous n'apportons ici que nos premieres propositions.

Si le champ de recherche ici présente peut sembler restreint ou limité a quelques
applications ludiques, nous afﬁrmons qu'il n'en est Iien. I1 ouwe d'une part la voie a une
approche originale de l'etude des phenomenes de contraction presents dans les sms en
ce qu'il postule leur application formelle. D'autre part, il propose une nouvelle methode
de compression textuelle, pertinente notamment dans le cadre de sites de microblogging
comme tv»itter® ou dans d'autres situations de communication textuelle soumises a une
forte contrainte d'espace (afﬁchage de messages d'alerte, de notiﬁcations). Mais il
reconnait surtout l'existence d'un nouveau mode de communication bref et informel, et
propose une aide a son utilisation.

Remerciements

Nous tenons a remercier Cédrick Fairon qui nous a soufﬂé l'idée de cette recherche.
Nous souhaitons que Louise-Amelie Cougnon soit également reconnue pour son
indéfectible soutien, sa disponibilite et son aide precieuse. Enﬁn merci a MM Beaufort,
Bouraoui et Watrin pour leurs conseils avises.

Références

140it, 2012-03-20 http://140it.com.
2011-11-05, La Libre Belgique, Bruxelles.

BEAUFORT Richard, COUGNON Louise-Amelie, FAIRON Cédrick et ROEKHAUT Sophie,
2010, "Une approche hybride traduction/correction pour la normalisation des sms", in
TALN, Montreal.

CO'I'I‘IN Florent, 2011, Le "pourrisseur de texte" du RALI, Université de Montreal.

321

COUGNON Louise-Amelie et FRANCOIS Thomas, 2010, Etudier l'écrit sms. Un objectif du
projet sms4science, Linguistik Online.

COUGNON Louise-Amelie et LEDEGEN Gudrun, 2008, "c'est écrire comme je parle. Une
etude comparatiste de varietes de frangais dans 1'écrit sms", Actes du Congres annuel de
l 'AFLS, Oxford.

FAIRON C., KLEIN J. et PAUMIER S., 2006a, sms pour la science. Corpus de 30.000 sms et
log iciel de consultation, Presses universitaires de Louvain, Louvain-la-Neuve.

FAIRON C., KLEIN J. et PAUMIER S., 2006b, Le langage sms, etude d'un corpus
informatisé a partir de l'enquéte "faites don de vos sms a la science", Cental (Cahier du
Cental), Louvain-la-Neuve.

GLOR HOWARD Paul, 1993, The Design and Analysis of Eﬂicient Lossless Data
Compression Systems, Brown University, Providence.

International Organisation for Standardization, 2012-03-20 vwwv.iso.org.

KOCH Peter et OSTERREICHER Wulf, 2001, << Gesprochene Sprache und geschriebene
Sprache », in Lexikon der romanistischen Linguistik, Giinter Holtus, Tiibingen, pp.
584-627.

LUHN H.P., 1958, "The Automatic Creation of Literature Abstracts", in IBM Journal of
Research and Development, pp. 159-165.

MINEL Jean-Luc HDR, 2004, Le résumé automatique de textes : solution et
perspectives, Sorbonne, Paris.

TLFi - Trésor de la Langue Frangaise informatisé, 2012-03-24, vWwv.cnrt1.fr/deﬁnition/ .

YOUSFI-MONOD Mehdi, 2007, Compression automatique ou semi-automatique de textes
par élagage des constituants eﬂacables : une approche interactive et indépendante des
corpus, These de doctorat a 1'Université de Montpellier II, Montpellier.

YVON Francois, 2008, Réorthographier des sms, LIMSI, Paris.

322

