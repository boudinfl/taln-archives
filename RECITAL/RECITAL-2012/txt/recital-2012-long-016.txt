Actes de la conférence conjointe JEP-TALN-RECITAL 2012, volume 3: RECITAL, pages 255–266,
Grenoble, 4 au 8 juin 2012. c©2012 ATALA & AFCP
Pour un étiquetage automatique des séquences verbales 
figées : état de l’art et approche transformationnelle 
Aurélie JOSEPH 
LDI, 99 avenue Jean-Baptiste Clément, 93 Villetaneuse 
ITESFOT, Parc d’Andron, Le Séquoia, 30470 Aimargues 
joseph.aurelie@gmail.com 
RESUME____________________________________________________________________________________________________________  
Cet article présente une approche permettant de reconnaitre automatiquement dans un 
texte des séquences verbales figées (casser sa pipe, briser la glace, prendre en compte) à 
partir d’une ressource. Cette ressource décrit chaque séquence en termes de possibilités 
et de restrictions transformationnelles. En effet, les séquences figées ne le sont pas 
complètement et nécessitent une description exhaustive afin de ne pas extraire seulement 
les formes canoniques. Dans un premier temps nous aborderons les approches 
traditionnelles permettant d’extraire des séquences phraséologiques. Par la suite, nous 
expliquerons comment est constituée notre ressource et comment celle-ci est utilisée 
pour un traitement automatique. 
ABSTRACT _________________________________________________________________________________________________________  
For an Automatic Fixed Verbal Sequence Tagging: State of the Art and 
Transformational Approach 
This article presents a resource-based method aiming at automatically recognizing fixed 
verbal sequences in French (i.e casser sa pipe, briser la glace, prendre en compte) inside a 
text. This resource describes each sequence from the view-point of transformational 
possibilities and restrictions. Fixed sequences are not totally fixed and an exhaustive 
description is necessary to not only extract canonical forms. We will first describe some 
transformational approaches that are able to extract phraseological sequences. The 
building of the resource will be then addressed followed by our approach to 
automatically recognize fixed sequences in corpora. 
 
MOTS-CLES : séquences verbales figées, reconnaissance automatique, étiquetage, 
transformations linguistiques, ressources électroniques. 
KEYWORDS: fixed verbal sequences, automatic recognition, tagging, linguistical 
transformations, electronic resources. 
255
1 Introduction 
Le découpage en mots est la première opération effectuée dans un traitement 
automatique de la langue. Mais le terme mot est linguistiquement inapproprié car il 
correspond en informatique à une entité, appelée token, délimitée par des séparateurs 
graphiques (blancs, retour à la ligne…). Il n’est pas nécessaire de rappeler ici que la 
notion de mot est beaucoup plus complexe. Et lorsque nous disons complexe nous 
pensons tout autant à la difficulté de les cerner qu’à leur potentielle polylexicalité. En 
effet, alors que les traitements informatiques se sont concentrés sur le mot simple, les 
chercheurs ont prouvé que les mots complexes sont tout aussi importants dans le 
traitement des langues (Gross, 1982 ; Gross, 1996 ; Mejri, 1997 ; Lamiroy, 2006…). Le 
traitement automatique de ces séquences devient un enjeu incontournable et se doit 
d’être traité correctement car la bonne identification et donc l’étiquetage correct de ces 
séquences dites figées est utile pour de nombreuses applications telles que la traduction, 
l’extraction d’information, la classification... Notre approche consiste à créer une 
ressource électronique décrivant les séquences verbales figées (SVF) en termes de 
possibilités transformationnelles. Nous pensons, que comme les termes simples, elles ont 
besoin d’être, dans un premier temps, reconnaissables sous toutes leurs formes. Comme 
un verbe peut être reconnu dans un texte même s’il est conjugué, les SVF doivent être 
également reconnues malgré leurs modifications. Inversement, pour les séquences avec 
un dédoublement de sens (Mejri, 2003), les contraintes liées à certaines transformations 
peuvent nous diriger sur une séquence littérale et non globale (prendre la veste verte sera 
reconnu comme non figé).  
2 Séquence figée et extraction automatique : état de l’art 
Notre objet d’étude concerne la séquence figée (SF) connue aussi sous le nom 
d’expression figée, locution, expression idiomatique... Une séquence figée est un groupe 
de mots non nécessairement contigus, possédant une unité sémantique (sens global), et 
un figement à la fois morphologique (blocage du nombre), lexical (blocage du paradigme 
commutationnel) et syntaxique (blocage de la passivation, de la relativation… pour des 
séquences verbales) (Lamiroy et al., 2008).  
A l’instar de Mejri (2011) nous distinguons les séquences figées de deux autres concepts :  
– les séquences totalement figées (au fur et à mesure) qui n’acceptent aucune 
modification. L’ensemble est un bloc immuable et dont le traitement nécessite un 
simple référencement dans un dictionnaire. 
– Les collocations : séquences répétées apparaissant fréquemment ensembles 
(Firth, 1957). Elles peuvent être propres à un domaine (collocation 
terminologique selon Smadja, 1993) ou typique d’une langue (comme les verbes 
supports ou les verbes appropriés) 
Nous étudions ici, plus précisément la séquence verbale figée (casser sa pipe, prendre le 
taureau par les cornes, faire faux bond…). La problématique des SF et de façon plus 
importante des SVF, vient du fait qu’elles ne sont pas totalement figées (Gross, 1982 ;  
Gross, 1996 ; Lamiroy, 2005 ; Abeillé, 1989). En effet, elles autorisent certaines 
modifications d’ordre syntagmatique et/ou paradigmatique créant ainsi des degrés de 
256
figement (Gross, 1996). Cependant, il n’est apparemment pas possible de définir a priori 
les transformations  réalisables d’une séquence. Villada-Moiròn (2005) remarque que 
“there is no uniform presence or absence of syntactic constraints in all fixed expressions since 
not all fixed expressions exhibit the same syntactic versatility”.1 (Villada Moiròn, 2005:46). 
Balibar-Mrabti (2005) va plus loin en postulant que des séquences de même structure 
syntaxique n’acceptent pas les mêmes libertés transformationnelles (bruler ses vaisseaux 
vs casser sa pipe). Comment peut-on alors extraire de telles séquences malgré des 
modifications évidentes ? Il existe plusieurs approches assez répandues.  
La première est purement syntaxique. Laporte et al. (2008) utilisent les patrons 
syntaxiques productifs en noms composés et vont les proposer à un transducteur (avec 
l’outil Unitex). En permettant certaines transformations (insertion, coordination…) ils  
récupèrent ainsi des séquences nominales correspondant syntaxiquement à des noms 
composés.  
La deuxième approche est purement statistique. Ces méthodes utilisent une mesure pour 
déterminer au mieux la cohésion entre les éléments. Dias (2003) propose ainsi le 
GenLocalMax qui permet de calculer le degré de figement d’une séquence plus grande 
que deux mots non obligatoirement contiguë. Cependant l’approche est largement 
dépendante du corpus et de sa taille. 
L’approche la plus utilisée conjugue à la fois syntaxe et statistique. Certains chercheurs  
(Manning & Schütze, 1999 ; Daille, 1996 ; Watrin, 2008…) commencent par un filtrage 
linguistique (sélection de lexèmes, patrons syntaxiques) pour ensuite prendre une 
décision basée sur un calcul probabiliste (logarithme de vraisemblance, information 
mutuelle…). D’autres à l’inverse, génèrent un premier filtrage par critères statistiques 
pour ensuite effectuer leur choix sur critères linguistiques (Smadja, 1993). Ces méthodes 
hybrides sont les plus prisées. Toutefois, elles permettent l’extraction de données 
terminologiques (souvent nominales) plus que l’extraction de séquences figées que nous 
pourrions appeler ‘langagières’, c'est-à-dire, qui peuvent se retrouver dans n’importe quel 
texte quel que soit le domaine. Les possibles modifications intégrées sont de l’ordre de 
l’expansion de séquence. Peu d’études (Al Haj et Wintner, 2010) testent les 
transformations morphologiques, lexicales ou même syntaxiques que peut subir une SF 
afin d’en calculer le degré de figement. 
Une autre approche, permettant d’extraire des unités phraséologiques, est basée sur des 
dictionnaires électroniques : les travaux du LDI (notamment ceux de Ben-Henia Ayat, 
2006, 2009 ; Buvet, 2008 ; Cartier, 2008) ou du Lexique-Grammaire (notamment Tolone, 
2011). Les dictionnaires électroniques du LDI décrivent les emplois des termes de 
manière syntactico-sémantique. Les éléments sont catégorisés en prédicat, argument, 
actualisateur et leur comportement syntaxique lié au sens est déterminé par ces mêmes 
notions : prendre(HUM,taureau,corne). Les séquences polylexicales sont également 
                                                   
1 « observationnel il n'y aucune uniformité dans la  présence ou dans l’absence de contraintes syntaxiques dans toutes 
les expressions figées puisque toutes les expressions figées ne présentent pas la même polyvalence syntaxique » (Villada 
Moiròn 2005:46). 
 
257
traitées de la sorte : prendre le taureau par les cornes(HUM). Cependant leur description 
est souvent liée à la syntaxe externe (les arguments qu’elles acceptent) et leur traitement 
interne n’est pas exhaustif. Une description des emplois en termes de prédicat et 
d’argument peut se révéler essentielle pour extraire, par exemple, des SF analytiquement 
fausses c'est-à-dire dont le rapprochement syntactico-sémantique n’est pas logiquement 
correct (avoir un chat dans la gorge : un humain ne peut pas avoir littéralement un chat 
dans la gorge) (Ben-Henia Ayat, 2009) ou pour les désambiguïser d’une séquence 
homonyme dont le sens est littéral (prendre une veste). Cependant, cette description 
s’avère coûteuse en description sous-jacente car le traitement d’un texte doit être très fin 
pour pouvoir être analysé.  
Abeillé et Schabes (1989) proposent, grâce aux grammaires d’arbres adjoints une 
méthode pouvant extraire les SF malgré leur discontinuité (insertion, modifieur) et leurs 
potentiels changements syntaxiques (passivation, clivage…). Cela implique toutefois que 
la description transformationnelle soit complète. 
Finalement, les approches hybrides sont assez rapides et nécessitent peu de ressources et 
de prétraitement. Toutefois elles incluent dans leur extraction toutes sortes d’unités 
phraséologiques (souvent des collocations terminologiques). De plus, elles ne prennent 
pas en compte toutes les possibilités transformationnelles d’une séquence en se limitant 
souvent à de simples expansions. Les dictionnaires électroniques, plus exhaustifs et précis 
sont néanmoins coûteux en réalisation et en prétraitement. De plus, même si les 
chercheurs décrivent la séquence figée comme ayant une double structuration, la 
description systématique de la structuration interne n’est pas détaillée. 
Nous voulons constituer une ressource électronique répertoriant chaque SVF associée à 
toutes les transformations qu’elle accepte. Cette ressource sera utilisée dans un outil et 
permettra de reconnaitre toutes les SVF malgré leurs variations possibles. 
3 Création de la ressource 
3.1 Les transformations 
Les transformations ‘bloquées’ des SVF ont été décrites dans la littérature (notamment 
Gross, 1982 ; Gross, 1996 ; Mejri, 1997 ; Lamiroy et al., 2006…). Nous l’avons dit 
précédemment, certaines de ces transformations peuvent être réalisées dans certaines 
SVF mais elles ne sont pas déterminables a priori. Nous reprenons donc chacune d’elles 
afin de transformer automatiquement chaque séquence2  (Cartier et Joseph, 2011).  Cette 
méthode s’apparente à l’utilisation de grammaire d’arbres adjoints (Abeillé, 1989) sans 
pour autant aspirer à des phrases toujours grammaticales. 
– Conjugaison : le verbe est mis à toutes les personnes au présent, imparfait et 
futur. 
– Flexion : chaque séquence est modifiée en changeant le nombre des noms et de 
leurs actualisateurs associés. Toutes les possibilités sont prises en compte. S’il y a 
                                                   
2  Les séquences étudiées ont été récupérées dans diverses ressources et correspondent à des séquences 
particulières (cf Cartier et Joseph 2011) 
258
deux noms dans la séquence nous aurons donc 4 possibilités (prendre le taureau 
par les cornes, prendre les taureaux par les cornes, prendre le taureau par la corne, 
prendre les taureaux par la corne). 
– Substitutions : les noms, les adjectifs, les verbes, les adverbes sont substitués par 
leurs synonymes et antonymes (pour les adjectifs et verbes) les plus récurrents. 
Les déterminants sont substitués par d’autres déterminants (indéfini, défini, 
possessif, démonstratif). 
– Modifieurs nominaux : seuls les compléments du nom et les relatives peuvent 
être modélisées pour être requêtés sur des données non étiquetées. (l’adjectif 
sera un simple mot joker). 
– Suppression d’éléments : les adjectifs (prêter main forte   prêter main), les 
adverbes, les déterminants, le verbe ‘introducteur’ sont tour à tour supprimés. 
Lorsqu’une séquence possède plusieurs syntagmes alors on supprime tour à tour 
les syntagmes (prendre le taureau par les cornes   prendre le taureau, prendre par 
les cornes). 
– Insertion : on teste la possibilité d’insérer un déterminant entre le verbe et le 
nom ou la préposition et le nom s’il n’existe pas (prendre peur  prendre la peur). 
– Négation / affirmation : les séquences affirmatives sont mises au négatif et 
inversement. 
– Inversion : les syntagmes d’une séquence sont inversés s’ils sont au moins deux 
(prendre le taureau par les cornes  prendre par les cornes le taureau) 
– Passivation : la séquence est modifiée en une phrase au passif (le taureau est pris 
par les cornes, le taureau par les cornes est pris) 
– Relativation : la séquence est modifiée en une relative (le taureau que je prends 
par les cornes). 
– Clivage : chaque syntagme est clivé (c’est le taureau que je prends par les cornes, 
c’est par les cornes que je prends le taureau). 
– Pronominalisation/Détachement : test non effectué actuellement 
automatiquement. 
– Les questions : test non effectué actuellement automatiquement. 
3.2 Aide à la création de la ressource 
Afin que la décision sur la possibilité transformationnelle ne soit pas uniquement liée à 
l’intuition du linguiste, un programme (Cartier et Joseph, 2011) va permettre de 
soumettre chaque séquence transformée en tant que requête à un moteur de recherche 
(Google, Google Books, Google News). Ce moteur de recherche va nous retourner le 
nombre de liens trouvés dans le web. Le linguiste pourra finalement valider les possibles 
transformations en s’appuyant à la fois sur les résultats et les attestations retournées par 
les moteurs de recherche en vérifiant que la transformation effectuée est bien relative au 
sens de la séquence figée. Le linguiste reste malgré tout le garant de la validité des 
transformations en ayant une aide sur l’usage réel de la séquence.  
Nous obtenons ainsi une ressource décrivant pour chaque SF les transformations qu’elle 
peut subir et par conséquent celles qui sont bloquées. Actuellement notre base se 
restreint à environ 500 séquences transformées et validées. Chaque séquence génère en 
moyenne 40 transformations. Le nombre de transformations réalisées dépend du nombre 
259
de constituants. Précisons également que les trois quart des SVF de notre base 
correspondent à la structure ‘verbe déterminant nom préposition déterminant nom’. Ce 
choix totalement arbitraire, avait pour but de trouver des règles transformationnelles 
potentielles malgré les postulats de départ. 
Le peu de données actuelles est essentiellement dû au fait que le programme de 
transformation a nécessité une attention toute particulière afin de garantir sa robustesse 
pour qu’il puisse traiter toutes sortes de structures syntaxiques.  
Voici comment se présentent les transformations d’une SVF, dans un premier temps 
celles qui affectent les constituants (Table 1), dans un deuxième temps celles qui 
affectent la séquence entière (Table 2). 
 
 
 
 
 
 
 
TABLE 1 – Transformations des constituants de la séquence prendre le taureau par les cornes 
TABLE 2 – Transformations possibles de la séquence prendre le taureau par les cornes 
Cette ressource nous permet de connaître sous formes de traits définitoires ce qui 
caractérise les séquences en termes de transformations possibles. De plus, il peut exister 
des liens entre les transformations. En effet, un déterminant peut se voir substituer si et 
seulement si le nom qu’il actualise est modifié. C’est le cas de le qui devient un si taureau 
est modifié par un adjectif placé avant lui (noté Adj0). Il est donc primordial de le 
répertorier. 
4 Outil de reconnaissance des SVF 
Nous proposons une méthode, qui devra être améliorée par la suite, permettant de 
reconnaitre automatiquement des SVF même si celles-ci ont été transformées et de les 
distinguer partiellement de séquences littérales homographes. Finalement nous pourrons 
les relier à leur forme canonique créant ainsi une lemmatisation de la SVF. 
4.1 Corpus 
Nous testons actuellement notre outil sur une base constituée des premières pages 
retournées par le moteur de recherche lors de nos requêtes sur les différentes 
transformations de prendre le taureau par les cornes. Dans l’état actuel des choses, la base 
260
n’est utile que pour tester visuellement notre outil. Un corpus servant de référence, 
permettant de tester nos résultats doit être réalisé au plus tôt. Notre corpus actuel, de 
plus de 32000 mots, est étiqueté morpho-syntaxiquement et lemmatisé par Treetagger à 
l’exception des noms. En effet, une séquence figée se caractérise très souvent par un 
blocage flexionnel des noms (singulier/pluriel). C’est pour cette raison que nous ne 
lemmatisons pas les noms. Toutefois, les séquences ayant des noms acceptant les 
versions singulier et pluriel seront indiquées dans la ressource et ne seront bien 
évidemment pas écartées de l’analyse. 
4.2 Étapes de reconnaissance 
Notre programme procède en plusieurs étapes. La première consiste à constituer un 
dictionnaire d’entrées des composants de la SVF (noms, verbes, adjectifs, adverbes), qui 
n’acceptent ni substitution ni suppression. Nous les appelons ‘invariants’. Ce terme utilisé 
de manière un peu abusive représente les termes obligatoirement présents dans la 
séquence mais peuvent toutefois varier en nombre. Ils peuvent s’apparenter à la « zone 
fixe » de Laporte (1988) correspondant à un ou plusieurs termes obligatoirement 
présents dans la séquence. Les ‘invariants’ se rapprochent de la définition de « tête » 
d’Abeillé (1989) qui correspond à un terme simple déclenchant la zone de recherche 
d’une potentielle SF. 
 
 
 
 
 
 
 
 
 
 
 
 
 
TABLE 3 – Échantillon de SVF associées à leurs invariants 
Les ‘invariants’ sont utilisés comme des déclencheurs d’une potentielle SVF. En effet, le 
texte étudié est découpé en tokens et chaque forme différente (nom, adjectif, adverbe) 
est recherchée comme un possible invariant. Les SVF associées à cet invariant sont donc 
récupérées et deviennent les séquences candidates à évaluer de manière plus 
approfondie.  Autour de cet invariant une fenêtre de recherche (que nous appellerons 
261
‘capture’) est récupérée. Elle correspond à 10 mots de part et d’autre de l’invariant. Ce 
nombre a été choisi arbitrairement. Il sera par la suite réévalué, pouvant même dépendre 
du nombre de constituants de la séquence. Il s’en suit à partir de cette capture, une 
succession de tests, susceptibles d’éliminer la capture et par la même occasion la 
potentielle SVF associée. Ces tests concernent dans un premier temps, les constituants de 
la séquence : 
– les autres ‘invariants’ : tous les éléments obligatoires dans la séquence doivent 
être retrouvés dans la capture. 
– les éléments ‘variants’ : substituables ou supprimables.  
Si l’élément est supprimable sa présence n’est pas requise. Un élément 
supprimable peut être également le fait d’un syntagme supprimable (avoir des 
fourmis dans les jambes, avoir des fourmis). 
Un élément de la séquence peut être substitué. Dans ce cas les substitutions 
possibles sont listées sous formes de lemmes ou de classes d’objets (avoir des 
fourmis dans <PARTIE DU CORPS>) 
– les modifieurs possibles ou impossibles : les compléments du nom, les adjectifs, 
les subordonnées relatives sont actuellement les trois modifieurs que nous 
recherchons dans la capture à partir d’un nom. Si ce nom ne doit pas être 
modifié et que des éléments représentants les modifieurs sont trouvés (de, une 
étiquette <adjectif>, un relatif) alors la séquence est éliminée. 
– les modifieurs possibles selon une contrainte particulière (substitution du 
déterminant : prendre une veste, prendre la veste de sa vie). 
Dans un deuxième temps, nous testons les transformations liées à la séquence entière 
(inversion, passivation, clivage, relativation). Pour ce faire, nous testons tout d’abord 
l’ordre dans lequel apparaissent les constituants. En effet, ces types de transformations 
impliquent un changement syntagmatique des éléments. Ainsi, en disant que prendre le 
taureau par les cornes possède 3 composants (prendre, taureau, cornes), ces composants 
constituent l’ordre suivant : 1 2 3. Le clivage de taureau modifie alors l’ordre en 2 1 3 
(c’est le taureau qu’il prend par les cornes). En procédant de cette manière nous validons 
l’ordre des éléments par rapport à la transformation associée. Cependant, ceci n’est pas 
suffisant pour savoir si nous traitons bien la transformation cible. Il nous faut ainsi des 
éléments définitoires de chaque transformation devant être présents dans la capture pour 
que la transformation soit validée. Ainsi le passif est défini par la présence d’un verbe au 
participe passé avec l’auxiliaire être, la relativation par un pronom relatif et le clivage 
par la présence de c’est et un pronom relatif (Riegel et al., 1994). 
Prenons un exemple : la ressource nous renseigne sur le fait qu’une passivation est 
acceptée (l’indice 1 indique que c’est une passivation de type : le taureau est pris par les 
cornes. Pour affirmer que nous avons ce passif, nous devons donc trouver l’ordre 2 1 3 
mais également avoir un participe passé avec l’auxiliaire être (ou sans l’auxiliaire selon 
certaines conditions).  
Précisons également que des interdépendances peuvent survenir et qu’il faut les prendre 
en compte. C’est le cas dans prendre le taureau par les cornes où lors d’une inversion le 
taureau doit être modifié par un complément du nom pour que l’inversion soit acceptée 
(prendre par les cornes le taureau de la fantaisie à la française dans actualites.leparisien.fr). 
262
4.3 Prenons le taureau par les cornes : exemple 
L’outil a été testé sur notre corpus constitué, comme nous l’avons dit précédemment, de 
différentes phrases incluant prendre le taureau par les cornes sous différentes formes (les 
différentes transformations). Les séquences libres et les séquences figées cohabitent donc 
dans ce corpus. La figure 1 illustre une partie des résultats retournés par l’outil. 
FIGURE 1 – Reconnaissance de prendre le taureau par les cornes 
Nous pouvons remarquer que les SVF même transformées ont été retrouvées (en vert). 
Les séquences ne correspondant pas aux possibilités transformationnelles décrites ne sont 
pas extraites (en bleu). Elles correspondent en effet à la version littérale de la séquence. 
Cependant, nous ne réglons pas – et nous l’avions prévu – les conflits entre séquence 
littérale et séquence figée ayant les mêmes transformations ou la forme canonique (en 
rouge). L’outil aura donc tendance à privilégier la séquence figée. Pour régler de tels 
conflits, nous ne pourrons pas nous dédouaner d’un traitement de la syntaxe externe par 
l’analyse des arguments ou encore par un traitement sémantique plus étendu. 
Nous présentons Table 4 les résultats de l’étiquetage de la séquence prendre le taureau par 
les cornes. La mesure prend en compte des séquences libres correctement ou 
incorrectement étiquetées. 
 
Prendre le taureau 
par les cornes 
Rappel 99.29% 
Précision 99.53% 
F-score 99.41% 
TABLE 4 – Reconnaissance de prendre le taureau par les cornes 
Les principaux faux négatifs sont dus a des problèmes d’étiquetage morpho-syntaxique. 
Précisons que ces données chiffrées sont à titre indicatives car elles ne représentent 
qu’une petite partie du problème, d’autant plus que même s’il peut avoir un sens littéral, 
263
le sens opaque pour prendre le taureau par les cornes est plus fréquent. Le nombre 
d’attestations de séquences libres en témoignent avec seulement 1% des occurrences 
dans notre corpus. Ces résultats doivent également être comparés à d’autres méthodes 
(probabilistes, hybrides…). Toutefois, nous pensons que le début est prometteur et sera 
compétitif avec d’autres méthodes, notamment par le fait que la reconnaissance est 
indépendante de la taille du document et que l’importance est donnée aux séquences 
transformées qui représentent plus de 10% des occurrences, dans notre corpus. 
5 Conclusion et Perspectives 
Nous venons de présenter une méthode permettant de reconnaitre automatiquement des 
séquences verbales semi-figées. Cette approche est basée sur  une ressource électronique 
constituée de SVF associées à leurs transformations possibles ou impossibles. Celle-ci 
répertorie à la fois les transformations liées aux composants de la séquence (modification 
flexionnelle, substitution, modifieurs…) mais également les changements liés à la 
séquence entière (passivation, relativation, inversion…) et les dépendances possibles 
entre les transformations (changement de déterminant en présence d’un modifieur). La 
ressource permet dans un premier temps, de trouver les mots du texte qui apparaissent 
comme des éléments obligatoirement présents dans la séquence, permettant de 
sélectionner des SVF potentielles qui seront testées sur une fenêtre autour de cet 
élément. Par la suite les composants sont vérifiés aussi bien par leur présence, leur 
substitution  ou leur possible modification. Enfin l’ordre des composants est analysé s’il 
ne correspond pas à l’ordre canonique. Si aucune transformation syntagmatique n’est 
réalisable alors la séquence est rejetée. A l’inverse, si l’ordre trouvé correspond à une 
transformation possible celle-ci doit être validée par rapport à ses éléments définitoires 
(participe passé pour le passif). C’est ainsi, par l’utilisation d’une ressource électronique 
et une méthode qui se veut être la plus rapide possible (pour une éventuelle utilisation 
industrielle), que nous arrivons à extraire des SVF et à désambiguïser certaines de leur 
double littéral, indépendamment de la taille du corpus. Néanmoins, le travail est loin 
d’être terminé. La ressource établissant les différentes possibilités transformationnelles 
doit être complétée. Les SVF peuvent être décomposées en plusieurs types non pas selon 
leur degré de figement mais selon leur littéralité, leur dédoublement de sens, leur 
opacité, ou selon le domaine dans lequel on se trouve. En effet, les étapes de 
reconnaissance peuvent être allégées selon certaines conditions. De plus, la notion 
d’invariant doit être revue et élargie peut-être même jusqu’à une prise en compte de 
classes d’objets. L’ajout de la syntaxe externe doit également compléter la description 
pour une désambiguïsation totale. Enfin, des tests de robustesse doivent être effectués 
sur un corpus de référence, et les résultats doivent être comparés aussi bien à d’autres 
mesures qu’à d’autres ressources. 
Références 
ABEILLE, A. et SCHABES, Y. (1989). Parsing idioms in lexicalized TAGs. In Proceedings of the 
the European Chapter of the Association for Computational Linguistics (EACL'89). 
Manchester, Angleterre. 
AL-HAJ, A. et WINTNER, S. (2010). Identifying Multi-words Expressions by Leveraging 
264
Morphological and Syntactic Idiosyncrasy. In Proceedings of COLING 2010 (Conference on 
Computational Linguistics), Beijing, Chine. 
BALIBAR-MRABTI, A. (2005). Semi-figement et limites de la phrase figée. In LINX (53), 
pages 35–54. 
BEN-HENIA AYAT, I. (2006). Degrés de figement et double structuration des séquences 
verbales figées. Thèse de doctorat, Université Paris 13, Paris. 
BEN-HENIA AYAT, I. (2009). Les séquences verbales figées métaphoriques. In Synergie (1), 
pages 159–171. 
BUVET, P.-A., (2008). Quelle description lexicographique du figement pour le TAL? Le cas 
des adjectifs prédicatifs à forme complexe. In (Blumenthal et Mejri 2008), pages 43–54. 
CARTIER, E. (2008). Repérage automatique des expressions figées : état des lieux, 
perspectives. In (Blumenthal et Mejri 2008), pages 55-70. 
CARTIER, E. et JOSEPH A. (2011). Repérage automatique des séquences figées pour la 
classification des documents. In LTT 2011 (Lexicologie, Terminologie, Traduction). 
DAILLE, B. (2001). Extraction de collocation à partir de textes. In TALN 2001 (Traitement 
automatique des langues naturelles). Tours.  
DAILLE, B. (1996). Study and Implementation of Combined Techniques for Automatic 
Extraction of Terminology. In (Klavans et Resnik 1996), pages 29–36. 
DIAS, G. (2003). Multiword Unit Hybrid Extraction. In Workshop on multiword expressions 
of ACL meeting (Association for Computational Linguistics). Sapporo, Japon. 
GROSS, G. (1996). Les expressions figées en français noms composés et autres locutions. 
Ophrys, Paris. 
GROSS, M. (1982). Une classification des « phrases figées » du français. In Revue 
québécoise de linguistique. 
LAMIROY, B. et al. (2010). Les expressions verbales figées de la francophonie Belgique, 
France, Québec et Suisse. Ophrys, Paris. 
LAMIROY, B. (2008). Les expressions figées : à la recherche d’une définition. In 
(Blumenthal et Mejri 2008), pages 85–88. 
LAMIROY, B. (2005). Le problème central du figement est le semi figement. In LINX (53), 
pages 135–153. 
LAPORTE, E. (1988). Reconnaissance des expressions figées lors de l’analyse automatique.  
In Langages 23(90), pages 117–126. 
LAPORTE, E., NAKAMURA, T. et VOYATZI, S. (2008). A French Corpus Annotated for 
Multiword Nouns. In LREC 2008 (International Conference on Language Resources and 
Evaluation). Maroc. 
LEPESANT, D. et MATHIEU-COLAS, M. (1998). Introduction aux classes d’objets. In Langages 
32(131), pages 6–33. 
MANNING, C. et SCHÜTZE, H. (1999). Collocation. In Draft, pages 141–177. 
265
MEJRI, S. (2011). Les Dictionnaires électroniques sémantico-syntaxiques. In (CARDOSO et 
al. 2011), pages 159–188. 
MEJRI, S. (2008). La place du figement dans la description des langues. In (Blumenthal et 
Mejri 2008), pages 117–129. 
MEJRI, S. (2003). Polysémie et polylexicalité. In Syntaxe et sémantique (5).  
RIEGEL, M., PELLAT, J.-C. et RIOUL, R. (1994). Grammaire méthodique du français. PUF, 
Paris. 
SMADJA, F. (1993). Retrieving Collocations from Text: Xtract. In Computational linguistics 
19(1), pages 144–177. 
TOLONE, E. (2011). Analyse syntaxique à l’aide des tables du Lexique-Grammaire du 
français. Thèse de doctorat, École des Ponts ParisTech, Paris. 
VILLADA MOIRON, M.B. (2005). Data-driven identification of fixed expressions and their 
modifiability. Thèse de doctorat. Université de Groningen, Pays-Bas. 
WATRIN, P. (2007). Collocations et traitement automatique des langues. In Lexis and 
Grammar, Bonifacio.  
266
