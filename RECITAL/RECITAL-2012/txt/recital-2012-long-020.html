<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>ResTS : Syst&#232;me de R&#233;sum&#233; Automatique des Textes d&#8217;Opinions bas&#233; sur Twitter et SentiWordNet</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 3: RECITAL, pages 233&#8211;246,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>ResTS : Syst&#232;me de R&#233;sum&#233; Automatique des Textes 
d&#8217;Opinions  bas&#233; sur Twitter et SentiWordNet 
</p>
<p>Jihene Jmal   
LARODEC, ISG, Universit&#233; de Tunis, 2000, Le Bardo, Tunisie 
</p>
<p>fer.jmal_jihene@hotmail.fr 
</p>
<p>RESUME ____________________________________________________________________________________________________________   
Comme le E-commerce est devenu de plus en plus populaire, le nombre de commentaires 
des internautes est en croissance constante. Les opinions sur le Web affectent nos choix 
et nos d&#233;cisions. Il s&#8217;av&#232;re alors indispensable de traiter une quantit&#233; importante de cri-
tiques des clients afin de pr&#233;senter &#224; l&#8217;utilisateur l&#8217;information dont il a besoin dans la 
forme la plus appropri&#233;e. Dans cet article, nous pr&#233;sentons ResTS, un nouveau syst&#232;me 
de r&#233;sum&#233; automatique de textes d&#8217;opinions bas&#233; sur les caract&#233;ristiques des produits. 
Notre approche vise &#224; transformer les critiques des utilisateurs en des scores qui mesu-
rent le degr&#233; de satisfaction des clients pour un produit donn&#233; et pour chacune de ses 
caract&#233;ristiques. Ces scores sont compris entre 0 et 1 et peuvent &#234;tre utilis&#233;s pour la prise 
de d&#233;cision. Nous avons &#233;tudi&#233; les opinions v&#233;hicul&#233;es par les noms, les adjectifs, les 
verbes et les adverbes, contrairement aux recherches pr&#233;c&#233;dentes qui utilisent essentiel-
lement les adjectifs. Les r&#233;sultats exp&#233;rimentaux pr&#233;liminaires montrent que notre m&#233;-
thode est comparable aux m&#233;thodes  classiques de r&#233;sum&#233; automatique  bas&#233;es sur les 
caract&#233;ristiques des produits. 
ABSTRACT _________________________________________________________________________________________________________  
System of Customer Review Summarization using Twitter and SentiWordNet  
As E-commerce is becoming more and more popular, the number of customer reviews 
raises rapidly. Opinions on the Web affect our choices and decisions. Thus, it is more 
efficient to automatically process a mixture of reviews and prepare to the customer the 
required information in an appropriate form. In this paper, we present ResTS, a new 
system of feature-based opinion summarization. Our approach aims to turn the customer 
reviews into scores that measure the customer satisfaction for a given product and its 
features. These scores are between 0 and 1 and can be used for decision making and then 
help users in their choices. We investigated opinions extracted from nouns, adjectives, 
verbs and adverbs contrary to previous research which use only adjectives. Experimental 
results show that our method performs comparably to classic feature-based summariza-
tion methods. 
MOTS-CLES : Fouille d&#8217;opinion, Classification, Intensit&#233; de l&#8217;Opinion, R&#233;sum&#233; de texte 
d&#8217;opinion, Popularit&#233;.  
KEYWORDS: Opinion mining, Sentiment Classification, Opinion Strength, Feature-based 
Opinion Summarization, Feature Buzz Summary. 
 
</p>
<p>1 Introduction 
Dans le Web 2.0 (Web social ou participatif), l&#8217;utilisateur est un acteur principal qui par-
</p>
<p>233</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>tage des documents, des informations, des avis. Il interagit, collabore avec autrui, 
s&#8217;exprime et donne son opinion. Il a des services &#224; sa disposition tels que les r&#233;seaux so-
ciaux (twitter, facebook, etc.), les blogs, les forums, les wikis, les sites de partages de vi-
d&#233;os, de photos, de musiques, etc. L&#8217;utilisation fr&#233;quente de ces services fournit un contenu 
g&#233;n&#233;r&#233; par l&#8217;utilisateur (UGC : User Generated Content) qui repr&#233;sente de nos jours une 
quantit&#233; de donn&#233;es qui se mesure en yotaoctets (1024). Ce contenu est compos&#233; g&#233;n&#233;ra-
lement de donn&#233;es textuelles qui sont porteuses d&#8217;opinions et de sentiments. L&#8217;acc&#232;s au 
contenu s&#233;mantique des ces donn&#233;es, pr&#233;alable &#224; la connaissance des opinions qu&#8217;elles 
v&#233;hiculent, repr&#233;sente un enjeu pour de nombreux acteurs. Par exemple : 
</p>
<p>&#8211; le consommateur, c&#8217;est-&#224;-dire chacun de nous, qui veut s&#8217;informer avant toute d&#233;-
cision qu&#8217;elle soit d&#8217;achat ou autre; 
</p>
<p>&#8211; les fournisseurs de biens et de services qui cherchent &#224; se positionner les uns par 
rapport aux autres dans un univers hautement comp&#233;titif et face &#224; une demande 
de plus en plus complexe &#224; identifier; 
</p>
<p>&#8211; les chercheurs : &#233;conomistes, sociologues,&#8230; ou simplement les responsables pu-
blics qui cherchent &#224; comprendre le comportement individuel ou collectif pour an-
ticiper, r&#233;guler ou ajuster les rapports entre les diff&#233;rents agents socio-
&#233;conomiques.  
</p>
<p>C&#8217;est dans ce contexte que s&#8217;introduit la fouille d&#8217;opinion (Opinion Mining, Sentiment Ana-
lysis ou Subjectivity Analysis) qui est un sous domaine de la fouille de texte. Son but &#233;tant  
de ressortir les marques d&#8217;opinions et de  sentiments des documents textuels. Une opinion 
peut &#234;tre d&#233;finie comme l&#8217;expression des sentiments d&#8217;une personne envers une entit&#233; (Liu, 
2010). En outre, l'e-commerce devient de plus en plus populaire. Les marchands et 
les fabricants de produits permettent aux clients de donner leurs avis et opinions sur 
les produits ou services qu'ils ont vendus (par exemple amazon.com, epinions.com). De 
plus, les opinions disponibles sur le Web influent sur nos choix et d&#233;cisions. En effet, 
d&#8217;apr&#232;s une &#233;tude men&#233;e en 2009 par le CR&#201;DOC (Centre de Recherche pour l&#8217;&#201;tude et 
l&#8217;Observation des Conditions de Vie), 57% des internautes fran&#231;ais ont cherch&#233; des avis des 
autres sur le Web et 66% d&#8217;entre eux font confiance en ces commentaires (Lehu&#233;d&#233;, 2009). 
La fouille d&#8217;opinion peut &#234;tre divis&#233;e en trois sous domaines qui sont la classification de la 
subjectivit&#233; (subjectif/objectif) (Riloff et al, 2003), la classification des sentiments (posi-
tif/n&#233;gatif ou positif/n&#233;gatif/neutre)(Pang et Lee, 2002), (Wilson et al, 2004) et (Blitzer et 
al, 2007) et le r&#233;sum&#233; d&#8217;opinions (Hu et Liu, 2004), (Popescu et Etzioni, 2005) et (Gamon 
et al, 2005). 
Nous proposons une nouvelle approche de r&#233;sum&#233; automatique des textes d&#8217;opinions bas&#233;e 
sur les commentaires des utilisateurs. Cette approche vise &#224; transformer ces commentaires 
en des scores qui mesurent l&#8217;intensit&#233; de l&#8217;opinion. Ces scores peuvent &#234;tre utilis&#233;s pour la 
prise de d&#233;cision et aident les utilisateurs dans leurs choix. Pour ce faire, nous avons com-
menc&#233; par extraire les caract&#233;ristiques des produits &#224; partir des critiques des utilisateurs 
(exemple batterie, &#233;cran, son, image, etc.). Ensuite, nous avons attribu&#233; &#224; chaque caract&#233;-
ristique un score calcul&#233; &#224; partir de sa fr&#233;quence d&#8217;apparition dans le corpus pond&#233;r&#233;e 
par sa popularit&#233; dans le Web 2.0, en particulier sur Twitter1 ; la plateforme de microblo-
gage la plus populaire. Nous avons par la suite identifi&#233; les phrases d'opinion et affect&#233; 
                                                   
1 www.twitter.com 
</p>
<p>234</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#224; chaque verbe et adjectif un score de SentiWordNet (Baccianella et al, 2010). Si la 
phrase contient un adverbe, ces scores sont pond&#233;r&#233;s par l'intensit&#233; de l&#8217;opinion v&#233;hicul&#233;e 
par cet adverbe en se r&#233;f&#233;rant &#224; la liste de modificateurs (en anglais intensifier 
et diminisher) que nous avons pr&#233;par&#233;. Nous avons enfin calcul&#233; le score de tout le pro-
duit qui mesure la satisfaction globale des clients. Voici un exemple de r&#233;sum&#233; g&#233;n&#233;r&#233; par 
notre syst&#232;me pour le produit iPod : 
Produit : iPod    
Satisfaction Client = 60% 
     Caract&#233;ristique 1 : Player : Popularit&#233; = 70% 
 Satisfaction Client = 83% 
     Caract&#233;ristique 2 : Ecran : Popularit&#233; = 54% 
 Satisfaction Client = 62% 
     &#8230;. 
Les caract&#233;ristiques des produits sont class&#233;es en fonction de leurs popularit&#233;s sur le web 
2.0. Dans notre conception, un produit n'est pas simplement consid&#233;r&#233; comme recomman-
d&#233; ou non recommand&#233;, au contraire, nous laissons l&#8217;utilisateur libre de faire son choix en 
se r&#233;f&#233;rant aux diff&#233;rents scores que nous mettons &#224; sa disposition traduisant la satisfaction 
des clients pour l'ensemble du produit et encore pour chacune de ses caract&#233;ristiques. Lors 
du calcul de ces scores, nous avons &#233;tudi&#233; l&#8217;opinion v&#233;hicul&#233;e par les noms, adjec-
tifs, verbes et adverbes, contrairement aux autres recherches qui utilisent principalement 
les adjectifs. 
</p>
<p>2 Etat de l&#8217;art 
Nous proposons dans cet article deux types de r&#233;sum&#233;s qui sont le r&#233;sum&#233; d&#8217;opinion bas&#233; 
sur les caract&#233;ristiques des produits (Feature-based Opinion summarization), et le r&#233;sum&#233; 
de leurs popularit&#233;s qui montre aux entreprises ce qu&#8217;int&#233;resse r&#233;ellement leurs 
clients  (Feature Buzz Summary). Nous avons &#233;galement fusionn&#233; deux axes de recherche &#224; 
savoir le r&#233;sum&#233; bas&#233; sur les caract&#233;ristiques (Hu et Liu, 2004) (Liu et Ding, 2008) (Zhang 
et Liu, 2011) et l&#8217;identification de l&#8217;intensit&#233; de l&#8217;opinion (Wilson et al, 2004). Nous nous 
sommes bas&#233;es essentiellement sur l&#8217;approche de Hu et Liu (Hu et Liu, 2004). Les deux 
auteurs utilisent les r&#232;gles d'association pour extraire les caract&#233;ristiques fr&#233;quentes des 
produits. Pour identifier les mots d'opinion (les adjectifs seulement), ils ont eu recours &#224; 
WordNet2 en conjonction avec une liste de mots cl&#233;s subjectifs (seed words) manuellement 
pr&#233;par&#233;e. Leur syst&#232;me extrait uniquement les caract&#233;ristiques explicites. Une ann&#233;e plus 
tard, ces auteurs ont mis en &#339;uvre Opinion Observer (Liu et al, 2005), un syst&#232;me offrant 
une comparaison visuelle entre produits en tenant compte des critiques des utilisateurs sur 
le Web. Ils identifient les caract&#233;ristiques des produits &#224; partir des rubriques Pros destin&#233;e 
aux avis positifs et Cons celle des avis n&#233;gatifs.  
Plusieurs recherches ont &#233;tudi&#233; le probl&#232;me de la d&#233;tection de mots d'opinion. Il y a des 
                                                   
2 http://wordnet.princeton.edu/ 
</p>
<p>235</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>approches fond&#233;es sur le corpus (Corpus-based Approach) (Hatzivassiloglou et McKeown, 
1997), (Wiebe, 2000), (Kanayama et Nasukawa, 2006) et (Qiu et al, 2009), d&#8217;autres bas&#233;es 
sur le dictionnaire (Dictionary-based Approach) (Hu et Liu, 2004), (Kim et Hovy, 2004), 
(Kamps et al, 2004), (Esuli et Sebastiani, 2005), (Takamura et al, 2005), (Andreevskaia et 
Bergler, 2006), (Dragut et al, 2010) et (Bouchlaghem et al, 2010). Hu et Liu utilisent seu-
lement les adjectifs pour la d&#233;tection des opinions. Ils construisent manuellement une liste 
d'adjectifs qu&#8217;ils utilisent pour pr&#233;dire l'orientation de la phrase et utilisent WordNet pour 
alimenter la liste par les synonymes et les antonymes des adjectifs dont on connait la pola-
rit&#233;. Ils assignent 1 &#224; chaque adjectif positif et 0 &#224; chaque adjectif n&#233;gatif. Toutefois, dans 
notre conception, les adjectifs, les verbes et les adverbes jouent un r&#244;le important dans 
l'analyse des sentiments. Ils sont tous utilis&#233;s pour exprimer une opinion ou une &#233;motion 
dans le texte, par exemple, le verbe appr&#233;cier dans &#171;J'appr&#233;cie ce produit&quot; inspire un sen-
timent positif, m&#234;me si la phrase ne contient ni adjectif, ni adverbe. Dans (Liu et al, 2005), 
les auteurs comptent le nombre d'occurrences de chaque entit&#233; dans la rubrique Pros ex-
primant un avis positif et Cons celle des avis n&#233;gatifs. Dans (Zhang et Liu, 2011), les au-
teurs ont montr&#233; que les syntagmes nominaux et le substantif peuvent aussi enfermer des 
opinions. Ils comptent le nombre de phrases positives et n&#233;gatives pour chaque fonctionna-
lit&#233; du produit en utilisant le lexique d&#8217;opinion pr&#233;par&#233; par (Ding et al, 2008). Leur ap-
proche permet d'atteindre une pr&#233;cision moyenne d'environ 0,44. Dans notre conception, 
nous rejoignons l&#8217;avis de ces auteurs. Nous consid&#233;rons &#233;galement que les noms peuvent 
exprimer une opinion. En outre, d&#233;celer la polarit&#233; de l'opinion n&#8217;est toujours pas suffi-
sant. La force (intensit&#233;) de l'opinion est &#233;galement n&#233;cessaire. En effet, la subjectivit&#233; est 
exprim&#233;e de diff&#233;rentes mani&#232;res ; &#171;good battery &#187; est diff&#233;rent de &#171;great battery &#187; et de &#171;ex-
cellent battery &#187;. (Wilson et al, 2004) et (Pang et Lee, 2005) mettent l'accent sur la d&#233;tection 
de la force de l&#8217;opinion. (Wilson et al, 2004) utilisent les techniques de boosting, rule lear-
ning et support vector regression. (Pang et Lee, 2002) et (Turney, 2002) classent les docu-
ments comme &#171; thumbs up &#187; ou &#171; thumbs down &#187;, selon l'opinion qu'ils v&#233;hicu-
lent. Cependant, (Pang et Lee, 2005) exploitent les techniques d'apprentissage automatique 
pour donner un score de 1 &#224; 5 aux passages d&#8217;opinions.  
</p>
<p>3 Approche propos&#233;e 
Notre approche est bas&#233;e sur les travaux de (Hu et Liu, 2004). La figure 1 pr&#233;sente le mo-
d&#232;le propos&#233;. Elle a &#233;t&#233; mise en &#339;uvre dans notre syst&#232;me ResTS.  Nous commen&#231;ons par 
recueillir les commentaires des internautes &#224; partir du Web et proc&#233;dons par l&#8217;op&#233;ration de 
pr&#233;traitement du corpus collect&#233;. Notons que notre syst&#232;me effectue toutes les &#233;tapes sui-
vantes d&#8217;une mani&#232;re automatis&#233;e et sans aucune intervention humaine. Rappelons que 
l'opinion est une expression des sentiments d'une personne envers une entit&#233; ou un aspect 
de l'entit&#233; (Liu, 2010). Une entit&#233; peut &#234;tre un produit, une personne, un &#233;v&#233;nement, une 
organisation ou un sujet.  Elle est repr&#233;sent&#233;e comme une hi&#233;rarchie de composants, de 
sous-composant et ainsi de suite o&#249; chaque n&#339;ud repr&#233;sente un composant et est associ&#233; &#224; 
un ensemble d'attributs (Liu, 2010). Par cons&#233;quent, l'entit&#233; elle-m&#234;me peut &#233;galement &#234;tre 
consid&#233;r&#233;e comme une caract&#233;ristique. Une critique de l'entit&#233; elle-m&#234;me est appel&#233;e une 
opinion g&#233;n&#233;rale comme dans &#171;I like this iPod &#187;. Une critique d&#8217;une de ses caract&#233;ristiques 
est appel&#233;e une opinion sp&#233;cifique comme dans &#171; the battery is really good&#187;. Comme Hu et 
Liu, notre t&#226;che est loin d'&#234;tre un r&#233;sum&#233; traditionnel de texte. A partir des critiques des 
utilisateurs, nous proposons un r&#233;sum&#233; structur&#233; qui donne une vue globale et concise des 
</p>
<p>236</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>opinions des clients. Hu et Liu ne pr&#233;sentent que le nombre de passages jug&#233;s positifs et 
ceux n&#233;gatifs pour chacune des caract&#233;ristique du produit. Notre syst&#232;me offre plus de 
d&#233;tails. Nous fournissons un score r&#233;v&#233;lant le degr&#233; de satisfaction des clients pour un pro-
duit donn&#233; et pour chacune de ses caract&#233;ristiques. Notre syst&#232;me n'est pas seulement bas&#233; 
sur le corpus puisque nous avons eu recours au Web 2.0 &#224; chaque &#233;tape. 
</p>
<p>3.1 Pr&#233;traitement  
Selon Liu, les commentaires des utilisateurs sont en trois formats (Liu, 2005):  
</p>
<p>&#8211; Format 1 - Pros et Cons : les consommateurs sont invit&#233;s &#224; d&#233;crire les avantages et 
les inconv&#233;nients s&#233;par&#233;ment dans les rubriques Pros et Cons. 
</p>
<p>&#8211; Format 2 - Pros, Cons et d&#233;tail : Les consommateurs  d&#233;crivent les avantages et les 
inconv&#233;nients s&#233;par&#233;ment dans les rubriques Pros et Cons et &#233;crivent de plus des 
commentaires d&#233;taill&#233;s.  
</p>
<p>&#8211; Format 3 - Format libre : Les consommateurs  &#233;crivent des avis en format libre, 
sans s&#233;paration entre les avantages et les inconv&#233;nients.  
</p>
<p>Dans ce papier nous utilisons les critiques du troisi&#232;me format.  Tous les exemples qui sui-
vent portent sur le produit iPod et toutes les critiques sont en anglais.  Le tableau 1, ci-
dessous, pr&#233;sente quelques exemples de commentaires des internautes.  
</p>
<p>FIGURE 1 &#8211; Mod&#232;le propos&#233;. 
## There isn't much features on the iPod at all, except games. 
</p>
<p>##The Click Wheel is a great design, something no one else came up with (however, the iRiver 
</p>
<p>has a touchpad). 
</p>
<p>TABLE 1 &#8211; Exemples de critiques utilisateurs 
Nous avons en entr&#233;e une base de donn&#233;es d&#8217;opinions recueillies &#224; partir de 2 sites mar-
chands (amazon.com et c|net.com) qui constitue notre corpus. &#201;tant donn&#233; un nom de 
</p>
<p>237</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>produit, notre syst&#232;me ResTS choisit les documents correspondants dans la base de don-
n&#233;es et proc&#232;de &#224; leur segmentation en phrases. Ensuite, il les convertit en minuscule 
et supprime les caract&#232;res non litt&#233;raux du d&#233;but et de la fin de chaque mot (par exemple 
&#171; ##ipod## &#187; devient &#171; ipod &#187;). Nous mettons &#233;galement  en relief la n&#233;gation pour 
l&#8217;utiliser plus tard dans la phase de classification (par exemple &#171; don&#8217;t &#187; ou &#171; dont &#187; devient 
&#171; do not &#187;). En outre, Hu et Liu (Hu et Liu, 2004) r&#233;v&#232;lent que les syntagmes nominaux et 
le substantif dans la phrase sont susceptibles d&#8217;&#234;tre la caract&#233;ristique du produit sur la-
quelle les clients commentent. Par ailleurs, les adjectifs v&#233;hiculent l&#8217;opinion et le jugement. 
Nous avons donc effectu&#233; l&#8217;&#233;tiquetage de l&#8217;ensemble du corpus en utilisant TreeTagger3 
pour identifier les classes grammaticales de chaque mot. 
</p>
<p>3.2 Extraction des caract&#233;ristiques des produits 
Nous avons extrait tous les syntagmes nominaux  (noms) &#224; partir des critiques des utilisa-
teurs. Ces noms seront consid&#233;r&#233;s comme des caract&#233;ristiques des produits. Notons qu&#8217;une 
caract&#233;ristique peut &#234;tre un nom simple ou un terme compos&#233; (exemple &#171; picture quality &#187;). 
</p>
<p>3.2.1 Construction des termes compos&#233;s 
Apr&#232;s avoir collect&#233; les diff&#233;rents noms &#224; partir des critiques des utilisateurs, nous avons 
proc&#233;d&#233; &#224; la construction des termes compos&#233;s qui sont form&#233;s de deux noms successifs. 
Prenons un exemple : &#171; The Click Wheel is a great design&#187;.  &#171; Click Weel &#187; est consid&#233;r&#233; 
comme un terme compos&#233;. Nous avons construit de la m&#234;me mani&#232;re tous les termes com-
pos&#233;s mais nous n&#8217;avons gard&#233; que ceux qui apparaissent au moins 3 fois dans le corpus. 
</p>
<p>3.2.2   Caract&#233;ristiques fr&#233;quentes 
Nous avons calcul&#233; la fr&#233;quence d&#8217;apparition des diff&#233;rents noms dans le corpus et 
nous n&#8217;avons gard&#233; que ceux dont la fr&#233;quence est sup&#233;rieure &#224; 0,01.  Le Tableau  2 pr&#233;-
sente quelques r&#233;sultats. 
</p>
<p>Caract&#233;ristiques Nombre d&#8217;occurrence Fr&#233;quence 
Click wheel 9 0.07853403 
</p>
<p>Battery 30 0.2617801 
</p>
<p>TABLE 2 &#8211; Exemples de caract&#233;ristiques fr&#233;quentes 
La colonne 1 pr&#233;sente les caract&#233;ristiques. La colonne 2 donne le nombre d'occur-
rences de la fonction et la colonne 3 est la fr&#233;quence des occurrences de cette caract&#233;ris-
tique dans le corpus. 
</p>
<p>3.2.3   Popularit&#233; dans Twitter 
Twitter est le service de microblogage le plus populaire. Les gens peuvent publier et lire de 
courts messages de 140 caract&#232;res maximum appel&#233;s tweets4. Les textes d&#8217;opinion suivent 
un style particulier (texte libre ou dialecte). On parle de nos jours de Discours Electronique 
M&#233;di&#233; (DEM) qui comporte des fautes d&#8217;orthographes, des &#233;motic&#244;nes (des smileys), des 
                                                   
3   http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/ 
4   Exemple de tweet : &#171; i neeed an ipod! i have a mill at my house but of course none of them work &#61516; &#187;. 
</p>
<p>238</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>acronymes (Exemple : lol), des &#233;tirements de mots, etc. Ce type d&#8217;&#233;criture est peu &#233;tudi&#233; 
par la litt&#233;rature. Twitter est devenu un domaine attractif pour le traitement automatique 
de la langue naturelle (NLP). Dans cet article, nous montrons comment les r&#233;seaux sociaux, 
en particulier Twitter, peuvent &#234;tre utilis&#233;s pour d&#233;tecter la popularit&#233; d'un produit donn&#233;. 
Pour ce faire, nous commen&#231;ons par l&#8217;op&#233;ration de crawling. Nous cherchons seulement les 
tweets populaires parlant d'un produit donn&#233;. Notre but &#233;tant de d&#233;celer les caract&#233;ris-
tiques populaires que les gens en montre le plus d&#8217;int&#233;r&#234;t pour un produit donn&#233; en comp-
tant le nombre de personnes qui s&#8217;y int&#233;ressent. Nous avons utilis&#233; twitter4j5, une librairie 
Java qui permet d&#8217;acc&#233;der au contenu de Twitter, pour recueillir pr&#232;s de 5000 tweets pour 
chaque produit post&#233; au cours des derniers jours. Nous avons ensuite  calcul&#233; le nombre de 
tweets &#233;voquant chacune des caract&#233;ristiques.  Le tableau 3 montre une comparaison entre 
le nombre d&#8217;occurrences de certaines caract&#233;ristiques dans le corpus et dans Twitter. Apr&#232;s 
avoir calcul&#233; le nombre d&#8217;occurrences de chaque caract&#233;ristique extraite dans Twitter, 
nous n&#8217;avons gard&#233; que celles dont le nombre d'occurrences est sup&#233;rieur &#224; 1 ; celles qui 
sont mentionn&#233;es par au moins un tweet. 
</p>
<p>Caract&#233;ristiques Occurrences corpus Occurrences Twitter 
Player 35 480 
</p>
<p>Reputation 3 0 
</p>
<p>Storage space 2 0 
</p>
<p>TABLE 3 &#8211; Nombre d&#8217;occurrences dans le corpus Vs nombre d&#8217;occurrences dans Twitter 
</p>
<p>3.3 Extraction des phrases d&#8217;opinion 
L'un des objectifs de notre syst&#232;me est de d&#233;tecter les passages subjectifs des commentaires 
des utilisateurs,  de d&#233;terminer leur polarit&#233; et de mesurer la force de l'opinion exprim&#233;e. 
En utilisant la liste des caract&#233;ristiques d&#233;j&#224; d&#233;tect&#233;es, notre syst&#232;me ResTS a extrait toutes 
les phrases qui contiennent au moins une caract&#233;ristique. Voici un exemple: &#171; iPod is bril-
liant, but service was awful. &#187;. Cette phrase pr&#233;sente deux caract&#233;ristiques qui sont 
&#171; iPod &#187; et &#171; service &#187;. Les mots d&#8217;opinion sont &#171; brillant &#187; et &#171; awful &#187;.  
</p>
<p>3.4 Calcul des scores 
Dans cette section, nous expliquons comment nous avons proc&#233;d&#233; pour mesurer l&#8217;intensit&#233; 
de l'opinion pour chaque caract&#233;ristique, puis pour l'ensemble du produit. Rappelons que 
nos scores sont compris entre 0 et 1. Le score n&#233;gatif appartient &#224; l'intervalle [0, 0.5] et 
le score positif appartient &#224; l'intervalle [0,5, 1]. Pour l'identification de l&#8217;intensit&#233; de 
l&#8217;opinion nous adoptons l&#8217;hypoth&#232;se suivante : plus le score est proche de 0, plus le mot est 
n&#233;gatif, et vice-versa.  
</p>
<p>3.4.1   Score d&#8217;une caract&#233;ristique 
Le score d'une caract&#233;ristique est sa fr&#233;quence d&#8217;apparition dans le corpus pond&#233;r&#233;e par sa 
popularit&#233; sur Twitter. Nous attribuons &#224; chaque caract&#233;ristique un score en utilisant la 
</p>
<p>                                                   
5 http://twitter4j.org/en/index.html 
</p>
<p>239</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>formule suivante6 : 
</p>
<p>                       
           
</p>
<p>          
 
</p>
<p>Avec :        est la fr&#233;quence d&#8217;apparition de la caract&#233;ristique dans le corpus,  
             est le nombre de tweets mentionnant &#224; la fois le produit et la caract&#233;ris-
tique,             est le nombre total de tweets collect&#233;s pour le produit. 
Ce poids mesure l'importance que les gens ont pour une caract&#233;ristique d&#8217;un produit don-
n&#233;. Il mesure &#233;galement sa popularit&#233;. Prenons l&#8217;exemple de la caract&#233;ristique &#171; battery &#187;, 
son score est &#233;gal &#224;  0.3442 (0.6x0.543+0.4x0.046 ). 
</p>
<p>3.4.2   Opinion sur  Twitter 
La contrainte de taille des tweets encourage l&#8217;utilisation des &#233;motic&#244;nes pour exprimer les 
opinions et les sentiments. Ces &#233;motic&#244;nes r&#233;sument souvent la polarit&#233; de toute la phrase. 
Nous avons construit notre propre liste d&#8217;&#233;motic&#244;nes (voir exemples dans le tableau 4) et 
avons divis&#233; les diff&#233;rents tweets collect&#233;s en des tweets positifs et d&#8217;autres n&#233;gatifs selon 
la polarit&#233; de l&#8217;&#233;motic&#244;ne qu&#8217;ils contiennent.  
</p>
<p>Polarit&#233; Emotic&#244;ne 
Positif :-)     :)     :o)   :]   :3    :c)     :^) 
</p>
<p>Extr&#234;mement Positif &lt;=3    &lt;=8    \o/ 
N&#233;gatif --!--    :-(     :(     :{ 
Extr&#234;mement N&#233;gatif :-9    q(;^;)p 
</p>
<p>TABLE 4 &#8211; Exemple d&#8217;&#233;motic&#244;nes avec polarit&#233; 
Nous avons compt&#233; par la suite le nombre de tweets positifs et n&#233;gatifs pour chaque carac-
t&#233;ristique. Notre hypoth&#232;se est qu&#8217;une caract&#233;ristique doit avoir un score &#233;lev&#233; si elle ap-
partient plus &#224; des tweets positifs.  Donc, si une caract&#233;ristique donn&#233;e apparait plus dans 
des tweets positifs, on doit augmenter son score, sinon on doit le diminuer. Comme nos 
scores sont entre 0 et 1, nous avons choisi la racine carr&#233;e et le carr&#233; pour augmenter et 
diminuer le score des caract&#233;ristiques des produits comme le montre l&#8217;algorithme suivant.  
Algorithm Feature_Score 
</p>
<p> 
Input: fscore , nbtweetpos, nbtweetneg //nombre de tweets positifs et n&#233;gatifs 
</p>
<p> 
Begin Feature_Score 
If ( fscore      then    
</p>
<p>If (nbtweetpos&gt;nbtweetneg) then 
</p>
<p> fft scorescore &#61501;  
</p>
<p>                                                   
6 Pour les exp&#233;rimentations&#61537; = 0.6 
</p>
<p>240</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Else 
</p>
<p>                              
fft
</p>
<p>scorescore
2
</p>
<p>&#61501;  
</p>
<p> EndIf 
ElseIf (nbtweetpos&lt;nbtweetneg) then 
</p>
<p> fft scorescore &#61501;  
</p>
<p>Else 
</p>
<p>                              
2
</p>
<p>fft scorescore &#61501;  
</p>
<p> EndIf 
End If 
End Feature_Score 
</p>
<p> 
Output: ftscore  
</p>
<p>Prenons l&#8217;exemple de la caract&#233;ristique &#171; battery &#187;, son score est &#233;gal &#224; 0.3442. Comme elle 
apparait plus dans des tweets n&#233;gatifs, on doit diminuer son score. Le score devient 0.118. 
</p>
<p>3.4.3 Score des verbes et des adjectifs 
Nous avons utilis&#233; SentiWordNet 3.0 (Baccianella et al, 2006), une ressource lexicale bas&#233;e 
sur WordNet 3.0, dans laquelle chaque mot w de WordNet  est associ&#233; &#224; trois scores num&#233;-
riques ObjScore(w), PosScore(w) et NegScore(w) d&#233;crivant &#224; quel point le mot w est objec-
tif, positif ou n&#233;gatif selon la formule suivante : 
</p>
<p>1)()()( &#61501;&#61483;&#61483; wNegScorewPosScorewObjScore  
</p>
<p>Par exemple, l&#8217;adjectif &#171; great &#187; a six synonymes (synset) et pour chacun un score positif et 
n&#233;gatif. Nous ne traitons pas les verbes ou adjectifs objectifs ; ceux dont le score objectif 
est plus &#233;lev&#233; que la somme de leurs scores positifs et n&#233;gatifs. &#201;tant donn&#233; un mot w, et n 
le nombre de ses synonymes, le score correspondant est calcul&#233; en utilisant la formule 
suivante: 
</p>
<p>         
         
</p>
<p> 
   
</p>
<p> 
 
</p>
<p>Avec : score wi est le score de SentiwordNet du mot w et donn&#233; par l&#8217;algorithme suivant. 
Algorithm Word_Score_Computing 
</p>
<p> 
Input: PosScore, NegScore   //les scores de SentiWordNet  
</p>
<p> 
Begin Word_Score_Computing 
ObjScore=1-(NegScore+PosScore) 
</p>
<p>241</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>If (Pos core + Neg core &#8805; Obj core) then   //non abjectif 
If ( NegScorePosScore&#61619; ) then 
 
</p>
<p>iw
score = PosScore 
ElseIf ( 5.0NegScore &#61603; ) then 
           
</p>
<p>iw
score = NegScore 
</p>
<p> Else 
              
</p>
<p>iw
score = 1-NegScore 
</p>
<p> EndIf 
End If 
End  Word_Score_Computing
Output: 
</p>
<p>iw
score         
</p>
<p>Prenons un exemple : &#171;The iPod has one of the worst batteries. &#187;. La phrase d&#8217;opinion est 
&#171;worst batteries&#187;. Le mot d&#8217;opinion est &#171; bad &#187;. Il a 14 synonymes dans SentiWordNet et son 
score calcul&#233; en utilisant l&#8217;algorithme &#233;nonc&#233; ci-dessus est &#233;gale &#224; 0.285. 
</p>
<p>3.4.4 Les adverbes 
Les phrases d&#8217;opinions peuvent contenir des modificateurs : intensifier comme &#171; Absurdly &#187;, 
&#171; Acutely &#187;, &#171; Alarmingly &#187; ou diminisher comme &#171; Moderately &#187;, &#171; Momentarily &#187;, &#171; Impro-
bably &#187; qui peut &#234;tre utilis&#233; de la m&#234;me mani&#232;re dans un contexte positif ou n&#233;ga-
tif comme &#171; Absolutely great &#187; ou &#171; Absolutely bad &#187;. Nous avons construit notre propre 
liste d&#8217;intensifier (192 termes) et diminisher (40 termes). Si une phrase contient un modifica-
teur qui pr&#233;c&#232;de le verbe ou l'adjectif, nous calculons leurs scores &#224; l'aide de l&#8217;algorithme 
suivant.  &#8217;il ya un intensifier pr&#233;c&#233;dant un verbe/adjectif positif (score&gt;=0.5), nous de-
vons augmenter son score. Cependant, s&#8217;il s&#8217;agit d&#8217;un diminisher, nous devons diminuer le 
score. Dans le cas d&#8217;un verbe/adjectif n&#233;gatif (score&lt;0,5), s&#8217;il est pr&#233;c&#233;d&#233; par un intensi-
fier, nous devons r&#233;duire son score, sinon, nous devons l'augmenter. Prenons un exemple : 
&#171;The battery is extremely bad. &#187;. Le score de &#171; bad &#187; est &#233;gal &#224; 0.285. Comme &#171; Extremely&#187; 
est un intensifier et bad est n&#233;gatif (score&lt;0.5), le score de &#171; extremely bad &#187; devient 
0.081(= 0.285x0.285). 
Algorithm Word_Score_Computing_Modifier 
</p>
<p> 
Input: wscore , IntensifierG, DiminisherG 
</p>
<p> 
Begin Word_Score_Computing_Modifier 
If ( wscore      then   // the word is positive 
</p>
<p>If (Modifier  IntensifierG) then 
</p>
<p> wscore = wscore  
ElseIf (Modifier  DiminisherG) then 
</p>
<p>242</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>                              wscore = wscore
 
</p>
<p> 
 EndIf 
ElseIf (Modifier  IntensifierG) then 
</p>
<p>             wscore = wscore
 
</p>
<p>  
ElseIf (Modifier  DiminisherG) then 
</p>
<p>            wscore = wscore  
 EndIf 
End If 
End Word_Score_Computing_Modifier 
</p>
<p> 
Output: wscore  
</p>
<p>3.4.5 Score des phrases d&#8217;opinions 
Le score des phrases d&#8217;opinions d&#233;pend en premier lieu des scores des verbes et des adjec-
tifs qu'elles contiennent. Il d&#233;pond &#233;galement du score de la caract&#233;ristique qu&#8217;elle con-
tient. Si une phrase contient n caract&#233;ristiques, son score est donn&#233; par la formule sui-
vante7 : 
</p>
<p>&#61480; &#61481;
</p>
<p>n
</p>
<p>scorescore
</p>
<p>score
ii w
</p>
<p>n
</p>
<p>i
</p>
<p>f
</p>
<p>s
</p>
<p>&#61620;&#61485;&#61483;&#61620;
</p>
<p>&#61501;
</p>
<p>&#61669;
&#61501;
</p>
<p>&#61537;&#61537; 1
1  
</p>
<p>Reprenons l&#8217;exemple pr&#233;c&#233;dent : &#171; The battery is extremely bad. &#187;. Le score de &#171; battery &#187; est 
&#233;gal &#224; 0.118. Le score de toute la phrase est : 0.3x0.118+0.7x0.081= 0.092. Prenons 
maintenant un autre exemple qui montre un score positif : &#171; The sound is pretty good. &#187;. Ici, 
la caract&#233;ristique est &#171; sound &#187;. Son score est 0.354. Elle apparait plus dans des tweets posi-
tifs, donc son score devient 0.595. La phrase d&#8217;opinion est &#171; pretty good &#187;. L&#8217;adjectif &#171; good &#187; 
a 21 synonymes. Son score est 0.595. Comme &#171; Pretty &#187; est un intensifier, le score devient 
0.771. Le score de la phrase devient 0.718 (= 0.3x0.595+0.7x0.771).  
</p>
<p>3.4.6 Score du produit 
Le score du produit est repr&#233;sent&#233; par le score de tout le corpus relatif &#224; ce produit. Il est 
donn&#233; par la formule suivante: 
</p>
<p>&#61669;
&#61501;
</p>
<p>&#61501;
n
</p>
<p>i
</p>
<p>r
</p>
<p>i
fs
</p>
<p>score
n
</p>
<p>score
1
</p>
<p>1
 
</p>
<p>Avec :         est le score d&#8217;une phrases d&#8217;opinions et n est le nombre de phrases 
                                                   
7 Pour les exp&#233;rimentations &#61537; = 0.3 
</p>
<p>243</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>d&#8217;opinions dans le corpus. 
</p>
<p>3.5 Exp&#233;rimentations 
L'approche propos&#233;e a &#233;t&#233; impl&#233;ment&#233;e en langage Java sous l&#8217;environnement Eclipse. 
Nous avons &#233;valu&#233; notre syst&#232;me en utilisant plusieurs corpus de critiques des utilisateurs 
sur les produits suivant : deux appareils photo num&#233;riques, un t&#233;l&#233;phone cellulaire et 
un iPod. Ces corpus ont &#233;t&#233; collect&#233;es &#224; partir de 2 sites marchands (Amazon.com et 
C|net.com) et annot&#233;es manuellement8 par (Hu et Liu, 2004). Le premier objectif de notre 
syst&#232;me est d'extraire les caract&#233;ristiques des produits les plus proches de celles de 
l&#8217;annotation manuelle. Le tableau 4 r&#233;sume la pr&#233;cision et le rappel de la phase de collecte 
des caract&#233;ristiques des produits. La colonne 1 pr&#233;sente la liste des produits utilis&#233;s pour 
l&#8217;&#233;valuation. La colonne 2 donne la pr&#233;cision et le rappel du syst&#232;me de Hu et Liu. La troi-
si&#232;me colonne indique la pr&#233;cision et le rappel de notre syst&#232;me. Nous constatons que nos 
r&#233;sultats sont tr&#232;s proches de ceux de Hu et Liu ; le F-score moyen du syst&#232;me de Hu et Liu 
est 0,657, il est de 0,651 pour cette recherche.  
</p>
<p>Produit Hu et Liu  Collecte Collecte (utilisant Twitter) 
</p>
<p>Pr&#233;cision Rappel Pr&#233;cision Rappel Pr&#233;cision Rappel 
iPod -- -- 0.702 0.697 0.754 0.518 
</p>
<p>A Photo1 0.634 0.658 0.617 0.679 0.743 0.55 
A Photo 2 0.679 0.594 0.69 0.58 0.727 0.508 
T&#233;l&#233;phone C 0.676 0.716 0.556 0.731 0.725 0.503 
Moyenne 0.663 0.656 0.641 0.671 0.737 0.519 
</p>
<p>TABLE 4 &#8211; Pr&#233;cision et rappel de la m&#233;thode propos&#233;e Vs Hu et Liu 
</p>
<p>           
    
</p>
<p>  
                                 
</p>
<p>    
</p>
<p>   
                                  
</p>
<p>                
</p>
<p>                
 
</p>
<p>Avec : NC : Nombre de caract&#233;ristiques collect&#233;es par le syst&#232;me, NCPR : Nombre de carac-
t&#233;ristiques pertinentes collect&#233;es par le syst&#232;me (qui correspondent &#224; ceux de l&#8217;annotation 
manuelle), NCP : Nombre de caract&#233;ristiques de l&#8217;annotation manuelle.  
L&#8217;utilisation de Twitter au cours de la phase de collecte des caract&#233;ristiques du produit a 
am&#233;lior&#233; la pr&#233;cision, mais a caus&#233; une baisse du rappel. Ce d&#233;clin est d&#251; &#224; la suppression 
d&#8217;un certain nombre de caract&#233;ristiques qui ne sont pas populaires, c'est &#224; dire qui 
n&#8217;int&#233;ressent pas la majorit&#233; des utilisateurs de Twitter.  
Le deuxi&#232;me objectif du syst&#232;me est de r&#233;sumer l'opinion des utilisateurs envers un produit 
donn&#233;. Pour ce faire, nous avons extrait les phrases d&#8217;opinions puis calcul&#233; leurs scores. 
Ces scores sont corr&#233;l&#233;s &#224; 82% avec ceux de l&#8217;annotation manuelle. 
</p>
<p>                                                   
8 Exemple d&#8217;une phrase annot&#233;e par Hu et Liu : &#8220;battery[-2]##This is really stupid to me. 18 months for a 
battery isn't good,&#8221; &#8220;Battery&#8221; est la caract&#233;ristique et &#8220;-2&#8221; est le score de la phrase.   
</p>
<p>244</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>3.6 Conclusion 
Cet article pr&#233;sente une nouvelle approche de r&#233;sum&#233; automatique des textes d&#8217;opinions 
des critiques des utilisateurs. Notre approche vise &#224; transformer les critiques des consom-
mateurs en un score qui mesure l&#8217;intensit&#233; de l&#8217;opinion. Ce score est compris entre 0 et 1 
et peut &#234;tre utilis&#233; pour la prise de d&#233;cision et aide les utilisateurs dans leurs choix. Dans 
notre conception, un produit n'est pas simplement consid&#233;r&#233; comme recommand&#233; ou non 
recommand&#233;, au contraire, nous laissons l&#8217;utilisateur libre de faire son choix en fonction 
de certains scores que nous mettons &#224; sa disposition traduisant la satisfaction des clients 
pour l'ensemble du produit et encore pour chacune de ses caract&#233;ristiques. Lors du calcul 
de ces scores, nous avons &#233;tudi&#233; l&#8217;opinion v&#233;hicul&#233;e par les noms, adjectifs, verbes et ad-
verbes, contrairement aux autres recherches qui utilisent principalement les adjectifs. Nous 
avons de plus montr&#233; que les r&#233;seaux sociaux tel que Twitter peuvent &#234;tre exploit&#233; pour 
mettre en &#233;vidence les caract&#233;ristiques les plus pertinentes pour l'utilisateur et de d&#233;tec-
ter leurs popularit&#233;s. Dans les travaux futurs, nous pr&#233;voyons am&#233;liorer nos r&#233;sultats 
(augmenter le rappel), &#233;ventuellement en exploitant les passages n&#233;gatifs et ironiques et 
d&#8217;exp&#233;rimenter notre m&#233;thode &#224; l&#8217;aide d&#8217;autres entit&#233;s, non seulement les produits. 
</p>
<p> &#233; &#233;rences 
ANDREEVSKAIA, A. AND BERGLER, S. (2006). Mining WordNet for fuzzy sentiment: Sentiment 
tag extraction from WordNet glosses. In Proceedings of EACL 2006. 
BLITZER, J., DREDZE, M.,  AND PEREIRA, F. (2007). Biographies, Bollywood, boom-boxes and 
blenders: Domain adaptation for sentiment classification. In Proceedings of ACL 2007. 
BACCIANELLA S., ESULI A., SEBASTIANI F. (2010). SentiWordNet 3.0 : An Enhanced Lexical 
Resource for Sentiment Analysis and Opinion Mining. In Proceedings of LREC&#8217;10.  
BOUCHLEGHEM R., ELKHLIFI A., AND FAIZ R. (2010). Automatic extraction and classification 
approach of opinions in texts. ISDA 2010, IEEE Press, 918-922. 
DING, X., LIU, B., AND YU, P.S. (2008). A Holistic Lexicon-Based Approach to Opinion Min-
ing. In Proceedings of WSDM, Stanford University, Stanford, California, USA. 
DRAGUT, E. C., YU, C., SISTLA, P., AND MENG, W. (2010). Construction of a sentimental word 
dictionary. In Proceedings of CIKM. 
ESULI A., AND SEBASTIANI, F. (2005). Determining the Semantic Orientation of Terms through 
Gloss Classification. In Proceedings of CIKM. 
GAMON, M., AUE, A., CORSTON-OLIVER, S., RINGGER, E. (2005). Pulse: Mining Customer Opin-
ions from Free Text. In Proc. 6th Int.  Symp. Advances in intelligent data analysis, 121&#8211;132. 
HU, M., LIU, B. (2004). Mining and Summarizing Customer Reviews. In Proc. 10th Int. Conf. 
Knowledge Discovery and Data Mining, Seattle, WA, 168&#8211;177. 
HARRIS, Z. S. (1998). Mathematical structures of language. Interscience tracts in pure and 
applied mathematics, no.21, New York:  Interscience Publishers. ix,230 p. 
HATZIVASSILOGLOU, V., AND MCKEOWN, K. (1997). Predicting the Semantic Orientation of 
Adjectives. In Proceedings of ACL 1997. 
</p>
<p>245</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>KANAYAMA, K., NASUKAWA, T. (2006). Fully Automatic Lexicon Expansion for Domain-
Oriented Sentiment Analysis. In Proceedings of EMNLP 2006. 
KAMPS, J., MARX, M., ROBERT J. M., AND RIJKE, M. (2004). Using WordNet to measure seman-
tic orientation of adjectives. In Proceedings of LREC 2004. 
KIM, S.M., AND HOVY, E. (2004). Determining the Sentiment of Opinions.  In Proceedings of 
COLING 2004. 
 LEHUEDE, F. (2009). L&#8217;internet participatif redonne confiance aux consommateurs. 
LIU, B., HU, M., AND CHENG, J. (2005). Opinion observer: Analyzing and comparing opinions 
on the web. In Proceedings of WWW 2005. 
LIU, B. (2007). Web Data Mining Exploring Hyperlinks, Contents, and Usage Data, Springer 
2007, New York. 
LIU, B. (2010). Invited Chapter for the Handbook of Natural Language Processing, Second 
Edition. March, 2010. 
MIHALCEA, R., CORLEY, C., AND STRAPPARAVA, C. (2006). Corpus-based and knowledgebased 
measures of text semantic similarity. In Proceedings of the 21st national conference on Artifi-
cial intelligence - Volume 1, pages 775&#8212;780, AAAI Press. 
PANG, B., LEE, L., VAITHYANATHAN, S. (2002). Thumbs up? Sentiment Classification Using 
Machine Learning Techniques. In Proc. Conf. Empirical Methods in Natural Language Pro-
cessing, 79-86. 
PEDERSEN, T., AND PATWARDHAN, S. AND MICHELIZZI, J. (2004). WordNet::Similarity: measur-
ing the relatedness of concepts. Association for Computational Linguistics, 2004. 
POPESCU, A. M., ETZIONI, O. (2005). Extracting Product Features and Opinions from Re-
views. In Proc. Conf. Human Language Technology and Empirical Methods in Natural Language 
Processing, Vancouver, British Columbia, 339&#8211;346. 
QIU, G., LIU, B., BU, J. AND CHEN, C. (2009). Expanding Domain Sentiment Lexicon through 
Double Propagation. In Proceedings of IJCAI 2009. 
RILOFF, E., JANYCE, W., THERESA, W. (2003). Learning Subjective Nouns Using Extraction 
Pattern Bootstrapping. In Proc. 7th Conf. Natural Language Learning, 25-32. 
TAKAMURA, H., INUI, T., AND OKUMURA, M. (2007). Extracting Semantic Orientations of 
Phrases from Dictionary. In Proceedings of HLT-NAACL. 
TURNEY, P. (2001). Mining the Web for Synonyms: PMI-IR versus L A on TOEFL&#8221;. Machine 
Learning: ECML 2001, pages 491&#8211;502. 
WIEBE,J. (2000). Learning Subjective Adjectives from Corpora. In Proceedings of AAAI 2000. 
WILSON, T.,  WIEBE, J., HWA, R. (2004). Just how mad are you? Finding strong and weak 
opinion clauses. In Proceedings of AAAI 2004. 
</p>
<p>246</p>

</div></div>
</body></html>