ResTS : Systérne de,RésuIné_Automatique des Textes
d’0p1n1ons base sur Tw1tter et Sent1WordNet

Jihene Jmal
LARODEC, ISG, Univetsité de Tunis, 2000, Le Bardo, Tunisie
fer . jmal_j ihene@hotmail . fr

RESUME

Comme le E-commerce est devenu de plus en plus populaire, le nombre de commentaires
des internautes est en croissance constante. Les opinions sur le Web affectent nos choix
et nos décisions. Il s’avere alors indispensable de traiter une quantité importante de cri-
tiques des clients aﬁn de présenter a l’utilisateur l’information dont il a besoin dans la
forme la plus appropriée. Dans cet article, nous présentons ResTS, un nouveau systeme
de résumé automatique de textes d’opinions basé sur les caractéristiques des produits.
Notre approche vise a transformer les critiques des utilisateurs en des scores qui mesu-
rent le degré de satisfaction des clients pour un produit donné et pour chacune de ses
caractéristiques. Ces scores sont compris entre O et 1 et peuvent étre utilisés pour la prise
de décision. Nous avons étudié les opinions véhiculées par les noms, les adjectifs, les
verbes et les adverbes, contrairement aux recherches précédentes qui utilisent essentiel-
lement les adjectifs. Les résultats expérimentaux préliminaires montrent que notre me-
thode est comparable aux méthodes classiques de résumé automatique basées sur les
caractéristiques des produits.

ABSTRACT

System of Customer Review Summarization using Twitter and SentiWordNet

As E-commerce is becoming more and more popular, the number of customer reviews
raises rapidly. Opinions on the Web affect our choices and decisions. Thus, it is more
efﬁcient to automatically process a mixture of reviews and prepare to the customer the
required information in an appropriate form. In this paper, we present ResTS, a new
system of feature-based opinion summarization. Our approach aims to turn the customer
reviews into scores that measure the customer satisfaction for a given product and its
features. These scores are between 0 and 1 and can be used for decision making and then
help users in their choices. We investigated opinions extracted from nouns, adjectives,
verbs and adverbs contrary to previous research which use only adjectives. Experimental
results show that our method performs comparably to classic feature-based summariza-
tion methods.

MOTS-CLES: Fouille d’opinion, Classiﬁcation, Intensité de l’Opinion, Résumé de texte
d’opinion, Popularité.

KEYWORDS: Opinion mining, Sentiment Classiﬁcation, Opinion Strength, Featu.re-based
Opinion Summarization, Featu.re Buzz Summary.

1 Introduction

Dans le Web 2.0 (Web social ou participatif), l’utilisateu1' est un acteu.r principal qui par-

Actes de la con_fe'rence conjointe JEP-TALN-RECITAL 2012, volume 3: RECITAL, pages 233-246,
Grenoble, 4 an 8 juin 2012. ©2012 ATAI.A 8: AFCP

233

tage des documents, des informations, des avis. Il interagit, collabore avec autru.i,
s’exprime et donne son opinion. Il a des services 5 sa disposition tels que les réseaux so-
ciaux (twitter, facebook, etc.), les blogs, les forums, les wikis, les sites de partages de vi-
déos, de photos, de musiques, etc. L’utilisation fréquente de ces services fou.rnit u.n contenu
généré par l’utilisateur (UGC: User Generated Content) qui représente de nos jours une
quantité de données qui se mesure en yotaoctets (1024). Ce contenu est composé généra-
lement de données textuelles qui sont porteuses d’opinions et de sentiments. L’acces au
contenu sémantique des ces données, préalable 5 la connaissance des opinions qu’elles
véh.icu.lent, représente u.n enjeu pour de nombreux acteu.rs. Par exemple :

— le consommateur, c’est-5-dire chacun de nous, qui veut s’informer avant toute dé-
cision qu’elle soit d’achat ou autre;

— les fou.rnisseu.rs de biens et de services qui cherchent 5 se positionner les u.ns par
rapport aux autres dans un univers hautement compétitif et face 5 une demande
de plus en plus complexe 5 identiﬁer;

— les chercheurs: économistes, sociologues,... ou simplement les responsables pu-
blics qui cherchent 5 comprendre le comportement individuel ou collectif pour an-
ticiper, réguler ou ajuster les rapports entre les différents agents socio-
économiques.

C’est dans ce contexte que s’introdu.it la fou.ille d’opinion (Opinion Mining, Sentiment Ana-
lysis ou Subjectivity Analysis) qui est un sous domaine de la fouille de texte. Son but étant
de ressortir les marques d’opinions et de sentiments des documents text11els. Une opinion
peut étre déﬂnie comme l’expression des sentiments d’une personne envers une entité (Liu,
2010). En outre, l'e-commerce devient de plus en plus populaire. Les marchands et
les fabricants de produits permettent aux clients de donner leu.rs avis et opinions sur
les produ.its ou services qu'ils ont vendus (par exemple amazon.com, epinions.com). De
plus, les opinions disponibles sur le Web inﬂuent sur nos choix et décisions. En effet,
d’apres une ét11de menée en 2009 par le CREDOC (Centre de Recherche pour l’f'.tude et
l’Observation des Conditions de Vie), 57% des intemautes francais ont cherché des avis des
autres sur le Web et 66% d’entre eux font conﬂance en ces commentaires (Lehuédé, 2009).
La fou.ille d’opinion peut étre divisée en trois sous domaines qui sont la classiﬁcation de la
subjectivité (subjectif/objectif) (Riloff et al, 2003), la classiﬁcation des sentiments (posi-
tif/négatif ou positif/négatif/neutre)(Pang et Lee, 2002), (Wilson et al, 2004) et (Blitzer et
al, 2007) et le résumé d’opinions (Hu et Liu, 2004), (Popescu et Etzioni, 2005) et (Gamon
et al, 2005).

Nous proposons une nouvelle approche de résumé automatique des textes d’opinions basée
sur les commentaires des utilisateurs. Cette approche vise 5 transformer ces commentaires
en des scores qui mesu.rent l’intensité de l’opinion. Ces scores peuvent étre utilisés pour la
prise de décision et aident les utilisateurs dans leu.rs choix. Pour ce faire, nous avons com-
mencé par extraire les caractéristiques des produits 5 parlir des critiques des utilisateurs
(exemple batterie, écran, son, image, etc.). Ensuite, nous avons atttibué 5 chaque caracté-
ristique u.n score calcu.lé 5 partir de sa fréquence d’apparition dans le corpus pondérée
par sa popularité dans le Web 2.0, en particulier sur Twitter‘ ; la plateforme de microblo-
gage la plus populaire. Nous avons par la suite identiﬁé les phrases d'opinion et affecté

1 www.twitter.com

234

scorew _ scorew

Endlf
Elself (Modiﬁer E IntensifierG) then

2
scorew : scorew

Elself (Modiﬁer E DiminisherG) then

scorew : / scorew

Endlf
End If
End Word_Score_Computing_Modifier

Output: SCOI'€w

3.4.5 Score des phrases d’opinions

Le score des phrases d’opinions dépend en premier lieu des scores des verbes et des adjec-
tifs qu‘elles contiennent. Il dépond également du score de la caractéristique qu’elle con-
tient Si une phrase contient n caractéristiques, son score est donné par la formule sui-
vante7:

n
a>< score + 1-0; >< score

f w

1 1
scores = ‘:1

n

Reprenons l’exemple précédent : << The battery is extremely bad. >>. Le score de << battery >> est
égal a 0.118. Le score de toute la phrase est : 0.3x0.118+0.7x0.081 = 0.092. Prenons
maintenant un autre exemple qui montre un score positif : << The sound is pretty good. >>. Ici,
la caractéristique est << sound >>. Son score est 0.354. Elle apparajt plus dans des tweets posi-
tifs, donc son score devient 0.595. La phrase d’opinion est << pretty good >>. L’adjectif << good >>
a 21 synonymes. Son score est 0.595. Comme << Pretty >> est un intensiﬁer, le score devient
0.771. Le score de la phrase devient 0.718 (= 0.3x0.595+0.7x0.771).

3.4.6 Score du produit

Le score du produit est représenté par le score de tout le corpus relatif a ce produit. Il est
donné par la forrnule suivante:

Avec: scorefs est le score d’une phrases d’opinions et n est le nombre de phrases

7 Pour les expérimentations a = 0.3

243

d’opinions dans le corpus.

3.5 Expérimentations

L'approche proposée a été implémentée en langage Java sous l’environnement Eclipse.
Nous avons évalué notre systéme en utilisant plusieurs corpus de critiques des utilisateurs
sur les produits s11.ivant : deux appareils photo numériques, un téléphone cellulaire et
un iPod. Ces corpus ont été collectées a partir de 2 sites marchands (Amazon.com et
C|net.com) et annotées manuellementa par (Hu et Liu, 2004). Le premier objectif de notre
systeme est d'extraire les caractéristiques des produits les plus proches de celles de
l’annotation manuelle. Le tableau 4 résume la précision et le rappel de la phase de collecte
des caractéristiques des produ.its. Ia colonne 1 présente la liste des produits utilisés pour
l’évaluation. Ia colonne 2 donne la précision et le rappel du systeme de Hu et Li11. La troi-
siéme colonne indique la précision et le rappel de notre systeme. Nous constatons que nos
résultats sont trés proches de ceux de Hu et Liu ; le F-score moyen du systeme de Hu et Liu
est 0,657, il est de 0,651 pour cette recherche.

Produit Hu et Liu Collecte Collecte (utilisant Twitter)
Précision Rappel Précision Rappel Précision Rappel

ipod -- -- 0.702 0.697 0.754 0.518

A Photo] 0.634 0.658 0.617 0.679 0.743 0.55

A Photo 2 0.679 0.594 0.69 0.58 0.727 0.508
Téléphone C 0.676 0.716 0.556 0.731 0.725 0.503
Moyenne 0.663 0.656 0.641 0.671 0.737 0.519

TABLE 4 — Précision et rappel de la méthode proposée Vs Hu et Liu

NCPR NCPR P ' ' R 1
Rappel = — F — score = 2 * ereclslonl am”

Precision = _ _
NC NCP P'rec1sLo11.+Rappel

Avec : NC : Nombre de caractéristiques collectées par le systéme, NCPR : Nombre de carac-
téristiques pertinentes collectées par le systeme (qui correspondent 5 ceux de l’annotation
manuelle), NCP : Nombre de caractéristiques de l’annotation manuelle.

L’utilisation de Twitter au cours de la phase de collecte des caractéristiques du produit a
amélioré la précision, mais a causé u.ne baisse du rappel. Ce déclin est dﬁ 5 la suppression

d’un certain nombre de caractéristiques qui ne sont pas populaires, c'est a dire qui
n’intéressent pas la majorité des utilisateurs de Twitter.

Le deuxiéme objectif du systeme est de résumer l'opinion des utilisateurs envers u.n produit
donné. Pou.r ce faire, nous avons extrait les phrases d’opinions pu.is calc11lé leurs scores.
Ces scores sont corrélés 5 82% avec ceux de l’annotation manuelle.

3 Exemple d’une phrase annotée par Hu et I..iu : “battery[-2]##Th.is is really stupid to me. 18 months for a
battery isn't good,” “Battery” est la caractéristique et “-2” st le score de la phrase.

244

3.6 Conclusion

Cet article présente une nouvelle approche de résumé automatique des textes d’opinions
des critiques des utilisateurs. Notre approche vise a transformer les critiques des consom-
mateurs en un score qui mesure l’intensité de l’opinion. Ce score est compris entre 0 et 1
et peut étre utilisé pour la prise de décision et aide les utilisateu.rs dans leu.rs choix. Dans
r1otre conception, u.n produit n'est pas simplement considéré comme recommandé ou non
recommandé, au contraire, nous laissons l’utilisateur libre de faire son choix en fonction
de certains scores que nous mettons a sa disposition traduisant la satisfaction des clients
pour l'ensemble du produit et encore pour chacu.ne de ses caractéristiques. Lors du calcul
de ces scores, nous avons ét11dié l’opinion véhiculée par les noms, adjectifs, verbes et ad-
verbes, contrairement aux autres recherches qui utilisent principalement les adjectifs. Nous
avons de plus montré que les réseaux sociaux tel que Twitter peuvent étre exploité pour
mettre en évidence les caractéristiques les plus pertinentes pour l'utilisateur et de détec-
ter leu.rs popularités. Dans les travaux futu.rs, nous prévoyons améliorer nos résultats
(augrnenter le rappel), éventuellement en exploitant les passages négatifs et ironiques et
d’expérimenter notre méthode 5 l’aide d’autres entités, r1on seulernent les produits.

Références
ANDREEVSKAIA, A. AND BERGLER, S. (2006). Mining WordNet for fuzzy sentiment: Sentiment

tag extraction from WordNet glosses. In Proceedings of EACL 2006.

BLITZER, J., DREDZE, M., AND PEREIRA, F. (2007). Biographies, Bollywood, boorn-boxes and
blenders: Domain adaptation for sentiment classification. In Proceedings of ACL 2007.

BACCIANELLA S., ESULI A., SEBASTIANI F. (2010). SentiWordNet 3.0 : An Enhanced Lexical
Resource for Sentiment Analysis and Opinion Mining. In Proceedings of LREC’10.

BOUCI-ILEGHEM R., ELI<H1.IFI A., AND FAIZ R. (2010). Automatic extraction and classification
approach of opinions in texts. ISDA 2010, IEEE Press, 918-922.

DING, X., LIU, B., AND YU, P.S. (2008). A Holistic Lexicon-Based Approach to Opinion Min-
ing. In Proceedings of WSDM, Stanford University, Stanford, California, USA.

DRAGUT, E. C., YU, C., SISTLA, P., AND MENG, W. (2010). Construction of a sentimental word
dictionary. In Proceedings of CIKM.

ESULI A., AND SEBASTIANI, F. (2005). Determining the Semantic Orientation of Terms through
Gloss Classiﬁcation. In Proceedings of CIKM.

GAMON, M., AUE, A., CORSTON-OI..IVER, S., RJNGGER, E. (2005). Pulse: Mining Customer Opin-
ions from Free Text. In Proc. 6th Int. S_yrnp. Advances in intelligent data analysis, 121-132.

HU, M., LIU, B. (2004). Mining and Summarizing Customer Reviews. In Proc. 10th Int. Cory‘.
Knowledge Discovery and Data Mining, Seattle, WA, 1 68-1 77.

HARRIS, Z. S. (1998). Mathematical structures of lang11age. Interscience tracts in pure and
applied mathematics, no.2], New York: Interscience Publishers. ix,230 p.

HATZIVASSILOGLOU, V., AND MCKEOWN, K. (1997). Predicting the Semantic Orientation of
Adjectives. In Proceedings of ACL 1997.

245

KANAYAMA, K., NASUKAWA, T. (2006). Fully Automatic Lexicon Expansion for Domain-
Oriented Sentiment Analysis. In Proceedings of EMNLP 2006.

KAMPS, J., MARX, M., ROBERT J. M., AND RIJKE, M. (2004). Using WordNet to measure seman-
tic orientation of adjectives. In Proceedings of LREC 2004.

KIM, S.M., AND HOVY, E. (2004). Determining the Sentiment of Opinions. In Proceedings of
COLING 2004.

LEHUEDE, F. (2009). L’intemet participatif redonne conﬁance aux consommateurs.
LIU, B., HU, M., AND CHENG, J. (2005). Opinion observer: Analyzing and comparing opinions
on the web. In Proceedings of WWW2005.

LIU, B. (2007). Web Data Mining Exploring Hyperlinks, Contents, and Usage Data, Springer
2007, New York.

LIU, B. (2010). Invited Chapter for the Hanzﬂrook of Natural Language Processing, Second
Edition. March, 2010.

MIHALCEA, R., CORLEY, C., AND SIRAPPARAVA, C. (2006). Corpus-based and knowledgebased
measures of text semantic similarity. In Proceedings of the 21st national conference on Artifi-
cial intelligence - Volume 1, pages 775—780, A] Press.

PANG, B., LEE, L, VAI'IHYANA'IHAN, S. (2002). Thumbs up? Sentiment Classiﬁcation Using
Machine Learning Techniques. In Proc. Cory‘. Empirical Methods in Natural Language Pro-
cessing, 79-86.

PEDERSEN, T., AND PATWARDHAN, S. AND MICI-IELIZZI, J. (2004). WordNet::Similarity: measur-
ing the relatedness of concepts. Association for Computational Linguistics, 2004.

POPESCU, A. M., E'IZIoNI, O. (2005). Extracting Product Features and Opinions from Re-
views. In Proc. Cory‘. Human Language Technology and Empirical Methods in Natural Language
Processing, Vancouver, British Columbia, 339-346.

QIU, G., LIU, B., BU, J. AND CHEN, C. (2009). Expanding Domain Sentiment Lexicon through
Double Propagation. In  of LICAI 2009.

RILOFF, E., JANYCE, W., THERESA, W. (2003). Iearning Subjective Nouns Using Extraction
Pattern Bootstrapping. In Proc. 7th Cory‘. Natural Language Learning, 25-32.

TAKAMURA, H., l.NUI, T., AND OKUMU'RA, M. (2007). Extracting Semantic OrieI1tations of
Phrases from Dictionary. In Proceedings of HLT—NAACL.

TURNEY, P. (2001). Mining the Web for Synonyms: PMI-IR versus LSA on TOEFL”. Machine
Learning: ECML 2001, pages 491-502.

WIEBE,J. (2000). Iearning Subjective Adjectives from Corpora. In Proceedings of AAAI 2000.

WILSON, T., WIEBE, J., HWA, R. (2004). Just how mad are you? Finding strong and weak
opinion clauses. In Proceedings of AAAI 2004.

246

a chaque verbe et adjectif u.n score de SentiWordNet (Baccianella et al, 2010). Si la
phrase contient u.n adverbe, ces scores sont pondérés par 1'intensité de 1’opinion véhicu.lée
par cet adverbe en se référant a la liste de modiﬂcateurs (en anglais intensifier
et diminisher) que nous avons préparé. Nous avons enﬁn calcu.lé le score de tout le pro-
duit qui mesure la satisfaction globale des clients. Voici u.n exemple de résumé généré par
notre systeme pour le produ.it iPod :

Produit: iPod
Satisfaction Client = 60%
Caractéristique 1 :Player: Popularité = 70%
Satisfaction Client = 83%
Caractéristique 2 :Ecran : Popularité = 54%
Satisfaction Client = 62%

Les caractéristiques des produits sont classées en fonction de leurs popularités sur le web
2.0. Dans notre conception, un produit n'est pas simplement considéré comme recomman-
dé ou non recommandé, au contraire, nous laissons 1’utilisateu.r libre de faire son choix en
se référant aux différents scores que nous mettons a sa disposition traduisant la satisfaction
des clients pour 1'ensemb1e du produ.it et encore pour chacu.ne de ses caractéristiques. Lors
du calcul de ces scores, nous avons ét11dié 1’opinion véhiculée par les noms, adjec-
tifs, verbes et adverbes, contrairement aux autres recherches qui utilisent principalement
les adjectifs.

2 Etat de l’art

Nous proposons dans cet article deux types de résumés qui sont le résumé d’opinion basé
sur les caractéristiques des produits (Feature-based Opinion summarization), et le résumé
de leurs popularités qui montre aux entreprises ce qu’intéresse réellement 1eu.rs
clients (Feature Buzz Summary). Nous avons également fusionné deux axes de recherche a
savoir le résumé basé sur les caractéristiques (Hu et Liu, 2004) (Liu et Ding, 2008) (Zhang
et Liu, 2011) et 1’identiﬁcation de 1’intensité de 1’opinion (Wilson et al, 2004). Nous nous
sommes basées essentiellement su.r 1’approche de Hu et Liu (Hu et Liu, 2004). Les deux
auteurs utilisent les régles d'association pour extraire les caractéristiques fréquentes des
produits. Pour identiﬁer les mots d'opinion (les adjectifs seulement), ils ont eu recours a
WordNet2 en conjonction avec une liste de mots clés subjectifs (seed words) manuellement
préparée. Leur systeme extrait uniquement les caractéristiques explicites. Une année plus
tard, ces auteurs ont mis en oeuvre Opinion Observer (Liu et al, 2005), un systeme offrant
une comparaison visuelle entre produits en tenant compte des critiques des utilisateurs sur
le Web. Ils identiﬂent les caractéristiques des produits a partir des rubriques Pros destinée
aux avis positifs et Cons celle des avis négatifs.

Plusieurs recherches ont étudié le probleme de la détection de mots d'opinion. I1 y a des

2 ht_tQ:g gwordnet.princeton.edug

235

approches fondées sur le corpus (Corpus-based Approach) (Hatzivassiloglou et McKeown,
1997), (Wiebe, 2000), (Kanayama et Nasu.kawa, 2006) et (Qiu et al, 2009), d’autres basées
sur le dictionnaire (Dictionary-based Approach) (Hu et Liu, 2004), (Kim et Hovy, 2004),
(Kamps et al, 2004), (Esuli et Sebastiani, 2005), (Takamu.ra et al, 2005), (Andreevskaia et
Bergler, 2006), (Dragut et al, 2010) et (Bouch.lagheIn et al, 2010). Hu et Liu utilisent seu-
lement les adjectifs pour la détection des opinions. Ils construisent manuellement une liste
d'adjectifs qu’ils utilisent pour prédire l'orientation de la phrase et utilisent WordNet pour
alimenter la liste par les synonymes et les antonymes des adjectifs dont on connait la pola-
rité. Ils assignent 1 a chaque adjectif positif et 0 a chaque adjectif négatif. Toutefois, dans
notre conception, les adjectifs, les verbes et les adverbes jouent un r6le important dans
l'analyse des sentiments. Ils sont tous utilisés pour exprimer une opinion ou une émotion
dans le texte, par exemple, le verbe apprécier dans <<J'apprécie ce produit" inspire un sen-
timent positif, méme si la phrase ne contient ni adjectif, ni adverbe. Dans (Liu et al, 2005),
les auteurs comptent le nombre d'occu.rrences de chaque entité dans la rubrique Pros ex-
primant un avis positif et Cons celle des avis négatifs. Dans (Zhang et Liu, 2011), les au-
teurs ont montré que les syntagmes nominaux et le substantif peuvent aussi enfermer des
opinions Ils comptent le nombre de phrases positives et négatives pour chaque fonctionna-
lité du produit en utilisant le lexique d’opinion préparé par (Ding et al, 2008). Leu.r ap-
proche permet d'atteindre une précision moyenne d'environ 0,44. Dans notre conception,
nous rejoignons l’avis de ces auteurs. Nous considérons également que les noms peuvent
exprimer une opinion. En outre, déceler la polarité de l'opinion n’est toujours pas suffi-
sant La force (intensité) de l'opinion est également nécessaire. En effet, la subjectivité est
exprimée de différentes maniéres ; «good battery» est différent de «great battery» et de «ex-
cellent battery». (Wilson et al, 2004) et (Pang et Lee, 2005) mettent l'accent sur la détection
de la force de l’opinion. (Wilson et al, 2004) utilisent les techniques de boosting, ru.le lear-
ning et support vector regression. (Pang et Lee, 2002) et (Tumey, 2002) classent les docu-
ments comme << thumbs up » ou << thumbs down », selon l'opinion qu'ils véhicu-
lent. Cependant, (Pang et Lee, 2005) exploitent les techniques d'apprentissage automatique
pou.r donner un score de 1 a 5 aux passages d’opinions.

3 Approche proposée

Notre approche est basée sur les travaux de (Hu et Liu, 2004). La ﬁgure 1 présente le mo-
déle proposé. Elle a été Inise en oeuvre dans notre systeme ResTS. Nous commencons par
recueillir les commentaires des intemautes a partir du Web et procédons par l’opération de
prétraitement du corpus collecté. Notons que notre systeme effectue toutes les étapes sui-
vantes d’une maniére automatisée et sans aucune intervention humaine. Rappelons que
l'opinion est une expression des sentiments d'une personne envers une entité ou un aspect
de l'entité (Liu, 2010). Une entité peut étre un produit, une personne, un événement, une
organisation ou un sujet Elle est représentée comme une hiérarchie de composants, de
sous-composant et ainsi de suite oil chaque noeud représente un composant et est associé a
un ensemble d'att1ibuts (Liu, 2010). Par conséquent, l'entité elle-méme peut également étre
considérée comme une caractéristique. Une critique de l'entité elle-méme est appelée une
opinion générale comme dans <<I like this iPod ». Une critique d’une de ses caractéristiques
est appelée une opinion spéciﬂque comme dans << the battery is really good». Comme Hu et
Liu, notre tache est loin d'étre un résumé traditionnel de texte. A parlir des critiques des
utilisateurs, nous proposons un résumé structuré qui donne une vue globale et concise des

236

opinions des clients. Hu et Liu ne présentent que le nombre de passages jugés positifs et
ceux négatifs pour chacune des caractéristique du produit. Notre systeme offre plus de
détails. Nous fou1nissons un score révélant le degré de satisfaction des clients pour un pro-
duit donné et pour chacune de ses caractéristiques. Notre systeme n'est pas seulement basé
sur le corpus puisque nous avons eu recours au Web 2.0 a chaque étape.

3.1 Prétraitement

Selon Liu, les commentaires des utilisateurs sont en trois formats (Liu, 2005):

— Format 1 - Pros et Cons : les consommateu.rs sont invités a décrire les avantages et
les inconvénients séparément dans les rubriques Pros et Cons.

— Format 2 - Pros, Cons et détail : Les consommateurs décrivent les avantages et les
inconvénients séparément dans les rubriques Pros et Cons et écrivent de plus des
commentaires détaillés.

— Format3 - Format libre : Les consommateu.rs écrivent des avis en format libre,
sans séparation entre les avantages et les inconvénients.

Dans ce papier nous utilisons les critiques du troisieme format. Tous les exemples qui sui-
vent portent sur le produit iPod et toutes les critiques sont en anglais. Le tableau 1, ci-
dessous, présente quelques exemples de commentaires des intemautes.

I) o(‘11111ent P1‘e1)1‘o(‘es S ing

/ 

   

Re\’ie\\' 1 Verb
Re\’ie\w'2
Cuslonler ' ' ' ' Adverb
Reviews Re"ie\‘~' H _ _
Ad] ectlv
No un .
/‘ Fen ture I) e(‘1(le1‘
(:)1)i11i4)11 S trengtli S 11111111.‘: ry /

/ \ .
Praductl : Prun lug
Custoxner Satisfaction : xv. ‘ Nouns

1=eoz-are 1 : Popularity : Pl"/n Noun
Custonler satisfaction : xl"/u Noun Phrases
Fecxtarez: Popularity : P2"/0 1, rases

C u 51 omer sat isfacvt i on : x2%

   
     

C)l)i11io1| Se11te11(‘e Extractioln

/  \
Re\'ie\\' 1

S (‘()1‘E‘ C o111l)11ti11g

      
 

RE\’ie\'V2
---- Opinion
Renew n Sentences

SentiVVord ‘
Net

    

FIGURE 1 — Modele proposé.

## There isn't rmich features on the iPod at all, except games.

##The Click Wheel is a great design, something no one else came up with (however, the iRiver
has a touchpad).

TABLE 1 — Exemples de critiques utilisateurs

Nous avons en entrée une base de données d’opinions recueillies a parlir de 2 sites mar-
chands (amazon.com et c|net.com) qui constit11e notre corpus. Etant donné un nom de

237

produit, notre systeme ResTS choisit les documents correspondants dans la base de don-
nées et procéde 5 leur segmentation en phrases. Ensuite, il les convertit en minuscule
et supprime les caracteres non littéraux du début et de la ﬁn de chaque mot (par exernple
<< ##ipod## >> devieI1t << ipod >>). Nous mettons égalernent en relief la négation pour
l’utiliser plus tard dans la phase de classiﬁcation (par exernple << don't » on << dont >> devient
<< do not >>). En outre, Hu et Liu (Hu et Liu, 2004) révelent que les syntagmes nominaux et
le substantif dans la phrase sont susceptibles d’étre la caractéristique du produit sur la-
quelle les clients commentent. Par ailleurs, les adjectifs véhiculent l’opinion et le jugement.
Nous avons donc effectué l’étiquetage de l’ensemble du corpus en utilisant TreeTagger3
pour identiﬁer les classes grammaticales de chaque mot.

3.2 Extraction des caractéristiques des produits

Nous avons extrait tous les syntagrnes nominaux (noms) 5 parlir des critiques des utilisa-
teurs. Ces noms seront considérés comme des caractéristiques des produits. Notons qu’une
caractéristique peut étre un nom simple ou un terrne composé (exemple << picture quality»).

3.2.1 Construction des ter-mes composés

Apres avoir collecté les différents noms 5 parlir des critiques des utilisateurs, nous avons
procédé 5 la construction des terrnes composés qui sont formés de deux noms successifs.
Prenons un exernple: << The Click M/heel is a great design». << Click Weel » est considéré
comme un terme composé. Nous avons construit de la meme maniere tous les terrnes corn-
posés mais nous n’avons gardé que ceux qui apparaissent au moins 3 fois dans le corpus.

3.2.2 Caractér-istiques fréquentes

Nous avons calculé la fréquence d’apparition des différents noms dans le corpus et
nous n’avons gardé que ceux dont la fréquence est supérieure 5 0,01. Le Tableau 2 pré-
sente quelques résultats.

Caractéristiques Nombre d’occurrence Fréquence
Click wheel 9 007853403
Battery 30 0.2617801

TABLE 2 — Exernples de caractéristiques fréquentes

Ia colonne 1 présente les caractéristiques. La colonne 2 donne le nombre d'occur-
rences de la fonction et la colonne 3 est la fréquence des occurrences de cette caractéris-
tique dans le corpus.

3.2.3 Popular-ité dans Twitter-

Twitter est le service de microblogage le plus populaire. Les gens peuvent publier et lire de
courts messages de 140 caracteres maximum appelés tweets‘. Les textes d’opinion suivent
un style particulier (texte libre ou dialecte). On parle de nos jours de Discours Electronique
Médié (DEM) qui comporte des fautes d’orthographes, des émoticones (des smileys), des

3 hI1]:_u://www.ims.uni-stuLtgart.de/projekte/cog;la(/TreeT§gger/
‘ Exemple de tweet: « i neeed an ipod! i have a mill at my house but of course none of them work ® ».

238

acronymes (Exemple : lol), des étirements de mots, etc. Ce type d’écriture est peu ét11dié
par la littérature. Twitter est devenu u.n domaine attractif pour le traitement automatique
de la langue naturelle (NLP). Dans cet article, nous montrons comment les réseaux sociaux,
en particulier Twitter, peuvent étre utilisés pour détecter la popularité d'un produit donné.
Pour ce faire, nous commencons par l’opération de crawling. Nous cherchons seulement les
tweets populaires parlant d'un produit donné. Notre but étant de déceler les caractéris-
tiques populaires que les gens en montre le plus d’intérét pour un produit donné en comp-
tant le nombre de personnes qui s’y intéressent. Nous avons utilisé twitter4j5, u.ne librairie
Java qui permet d’accéder au contenu de Twitter, pour recueillir pres de 5000 tweets pour
chaque produit posté au cours des derniers jours. Nous avons ensuite calculé le nombre de
tweets évoquant chacune des caractéristiques. Le tableau 3 montre u.ne comparaison entre
le nombre d’occurrences de certaines caractéristiques dans le corpus et dans Twitter. Apres
avoir calculé le nombre d’occurrences de chaque caractéristique extraite dans Twitter,
nous n’avons gardé que celles dont le nombre d'occurrences est supérieur 5 1 ; celles qui
sont mentionnées par au moins un tweet

Occurrences Occurrences Twitter
35 480

3 0
2 0

 

TABLE 3 — Nombre d’occurrences dans le corpus Vs nombre d’occurrences dans Twitter

3.3 Extraction des phrases d’opinion

L'un des objectifs de notre systeme est de détecter les passages subjectifs des commentaires
des utilisateurs, de déterminer leur polarité et de mesurer la force de l'opinion exprimée.
En utilisant la liste des caractéristiques déja détectées, notre systeme ResTS a extrait toutes
les phrases qui contiennent au moins u.ne caractéristique. Voici u.n exemple: << iPod is bril-
liant, but service was av|a‘uL >>. Cette phrase présente deux caractéristiques qui sont
<< iPod >> et << service >>. Les mots Cl’0piIl.lOI1 SOI1t << brillm1t >> et << awful >>.

3.4 Calcul des scores

Dans cette section, nous expliquons comment nous avons procédé pour mesurer l’intensité
de l'opinion pour chaque caractéristique, puis pour l'ensemble du produit Rappelons que
nos scores sont compris entre 0 et 1. Le score négatif appartient 5 l'intervalle [0, 0.5] et
le score positif apparlient 5 l'intervalle [0,5, 1]. Pour l'identiﬂcation de l’intensité de
l’opinion nous adoptons l’hypothese suivante : plus le score est proche de 0, plus le mot est
négatif, et vice-versa.

3.4.1 Score d’une caractéristique

Le score d’une caractéristique est sa fréquence d’apparition dans le corpus pondérée par sa
popularité sur Twitter. Nous attribuons 5 chaque caractéristique un score en utilisant la

5h : twitter4'.or en 1ndex.hunl

239

formule suivanteé :

nbre Twee tp f

scoref = (1 freqf + (1 — oz) nbrerweetp

Avec : freqf est la fréquence d’appariu'on de la caractérisﬁque dans le corpus,
nbreTweetp f est le nombre de tweets menﬁonnant a la fois le produit et la caractéris-
ﬁque, nbreTweetp est le nombre total de tweets collectés pour le produit

Ce poids mesure l'importance que les gens ont pour une caractérisﬁque d’un produit don-
né. I1 mesure également sa popularité. Prenons l’exeInple de la caractéristjque << battery»,
son score est égal a 0.3442 (0.6x0.543 +0.4x0.046 ).

3.4.2 Opinion sur Twitter

Ia contrainte de taille des tweets encourage l’ut1'lisau'on des émoﬁcones pour exprimer les
opinions et les sentiments. Ces émoﬁcones résument souvent la polarité de toute la phrase.
Nous avons construit notre propre liste d’éInotjc6nes (voir exemples dans le tableau 4) et
avons divisé les différents tweets collectés en des tweets posiﬁfs et d’autres négaﬁfs selon
la polarité de l’éInou'c6ne qu’ils conﬁennent.

Polarité Emoﬁcone
Posiﬁf 2-) :) :0) :] :3 :c) 2")

Extrémement Positjf <=3 <=8 \o/
Négaﬁf --!-- :-( :( :{
Extrémement Négatjf :-9 q(;";)p

TABLE 4 — Exemple d’éInou'c6nes avec polarité

Nous avons compté par la suite le nombre de tweets positjfs et négatjfs pour chaque Carac-
térisﬁque. Notre hypothese est qu’une caractéristjque doit avoir un score élevé si elle ap-
parﬁent plus a des tweets posiﬁfs. Donc, si me caractétisﬁque donnée apparait plus dans
des tweets positjfs, on doit augmenter son score, sinon on doit le diminuer. Comme nos
scores sont entre 0 et 1, nous avons choisi la racine carrée et le carré pour augmenter et
diminuer le score des caractérisﬁques des produits comme le montre l’algorithme suivant.

Algorithm Feature_Scone
Input: scoref , nbtweetpos, nbtweetneg //nombre de tweets positifs et négatifs

Begin Feature_Score
If( SCOI'6f 2 05) then
If (nbtweetpos > nbtweetneg) then

S0O1‘6ﬁ = 1’S0O1‘6f

6 Pour les aipérimentations a = 0.6

240

ELse

2
scoreﬁ = scoref

Endlf
ELseIf (nbtweetpos < nbtweetneg) than

S0O1‘6ﬁ = 1’S0O1‘6f

ELse

SCO1'Cﬁ = SCOI'Cf

Endlf
End If

End Feature_Score

Output: scorer,

Prenons1’exemp1e de la caractéristjque << battery », son score est égal 5 0.3442. Comme elle
apparait plus dans des tweets négaﬁfs, on doit diminuer son score. Le score devient 0.1 18.

3.4.3 Score des verbes et des adjectifs

Nous avons uﬁlisé Senu'WordNet 3.0 (Baccianella et a1, 2006), me ressource lexicale basée
su.r WordNet 3.0, dans laquelle chaque mot w de WordNet est associé 5 trois scores numé-
riques ObjScore(w), PosScore(w) et NegScore(w) décrivant 5 quel point le mot w est objec-
ﬁf, posiﬁf ou négatjf selon la formule suivante :

0bj&'0re(W) + P05.S'c0re(w) + Neg&'0re(W) = 1

Par exemple, 1’adjecu'f << great» a six synonymes (synset) et pour chacun u.n score posiﬁf et
négatjf. Nous ne traitons pas les verbes ou adjecﬁfs objecﬁfs; ceux dont le score objecﬁf
est plus élevé que la somme de leurs scores posiﬁfs et négaﬁfs. Etant donné u.n mot w, et 11
1e nombre de ses synonymes, le score correspondant est calculé en uﬁlisant la formule
sujvante:

2}; scoreSwi

scorewi = n

Avec : scoreswi est le score de Senu'wordNet du mot w et donné par Palgorithme sujvant

Algorithm Word_Score_Computing

Input: Posscore, Negscore //les scores de SentiWordNet

Begin Word_Score_Computing
Obj Score = 1 -(Negscore + Posscore)

241

If (PosScore + NegScore 2 ObjScore) then //non abjectif
If ( Posscorez Negscore) then
scorew‘ : PosScore
Elself ( Negscore S 0.5 ) then
SCOIBM : NegScore
Else
scorew‘ : 1-NegScore
Endlf
End If
End Word_Score_Computing

Output: scorew

Prenons un exemple : <<The iPod has one of the worst batteries. >>. La phrase d’opinion est
«worst batteries». Le mot d’opinion est << bad >>. Il a 14 synonymes dans SentiWordNet et son
score calculé en utilisant l’algorithme énoncé ci-dessus est égale a 0.285.

3.4.4 Les adverbes

Les phrases d’opinions peuvent contenir des modiﬁcateurs : intensifier comme << Absurdly >>,
<< Acutely >>, << Alaxmingly >> ou diminisher comme << Moderately >>, << Momentarily >>, << Impro-
bably >> qui peut étre utilisé de la meme maniere dans un contexte positif ou nega-
tif comme << Absolutely great >> ou << Absolutely bad >>. Nous avons construit notre propre
liste d’intensiﬁer (192 terrnes) et diminisher (40 terrnes). Si une phrase contient un modiﬁca-
teur qui precede le verbe ou l‘adjectif, nous calculons leurs scores a l‘aide de l’algorithme
suivant. S’il ya un intensiﬁer précédant un verbe/adjectif positif (score> =O.5), nous de-
vons augmenter son score. Cependant, s’il s’agit d’un diminisher, nous devons diminuer le
score. Dans le cas d’un verbe/adjectif négatif (score<O,5), s’il est précédé par un intensi-
fier, nous devons réduire son score, sinon, nous devons l‘augmenter. Prenons un exemple :
<<The battery is extremely bad. >>. Le score de << bad >> est égal a 0.285. Comme << Extremely»
est un intensiﬁer et bad est négatif (score<O.5), le score de << extremely bad >> devient
0.081( = 0.285X0.285).

Algorithm Word_Score_Computing_Modiﬁer
Input: scorew , IntensiﬁerG, DiminisherG

Begin Word_Score_Computing_Modiﬁer
If( SCOICW Z 05) then // the word is positive
If (Modiﬁer E IntensiﬁerG) then

scorew : / scorew

Elself (Modiﬁer E DiminisherG) then

242

