Adaptation d’un système de reconnaissance d’entités
nommeés pour le français à l’anglais à moindre coût

Mohamed Hatmi
LINA, UMR 6241,Université de Nantes
mohamed.hatmi@univ-nantes.fr

RÉSUMÉ
La portabilité entre les langues des systèmes de reconnaissance d’entités nommeés est coûteuse
en termes de temps et de connaissances linguistiques requises. L’adaptation des systèmes symbo-
liques souffrent du coût de développement de nouveaux lexiques et de la mise à jour des règles
contextuelles. D’un autre côté, l’adaptation des systèmes statistiques se heurtent au problème
du coût de préparation d’un nouveau corpus d’apprentissage. Cet article étudie l’intérêt et le
coût associé pour porter un système existant de reconnaissance d’entités nommeés pour du texte
bien formé vers une autre langue. Nous présentons une méthode peu coûteuse pour porter un
système symbolique dédié au français vers l’anglais. Pour ce faire, nous avons d’une part traduit
automatiquement l’ensemble des lexiques de mots déclencheurs au moyen d’un dictionnaire
bilingue. D’autre part, nous avons manuellement modifié quelques règles de manière à respecter
la syntaxe de la langue anglaise. Les résultats expérimentaux sont comparés à ceux obtenus avec
un système de référence développé pour l’anglais.
ABSTRACT
Adapting a French Named Entity Recognition System to English with Minimal Costs
Cross-language portability of Named Entity Recognition systems requires linguistic expertise and
needs human effort. Adapting symbolic systems suffers from the cost of developing new lexicons
and updating grammar rules. Porting statistical systems on the other hand faces the problem of
the high cost of annotation of new training corpus. This paper examines the cost of adapting a
rule-based Named Entity Recognition system designed for well-formed text to another language.
We present a low-cost method to adapt a French rule-based Named Entity Recognition system
to English. We first solve the problem of lexicon adaptation to English by simply translating the
French lexical resources. We then get to the task of grammar adaptation by slightly modifying
the grammar rules. Experimental results are compared to a state-of-the-art English system.
MOTS-CLÉS : Reconnaissance d’entités nommeés, approche symbolique, portabilité entre les
langues.
KEYWORDS: Named entity recognition, symbolic approache, cross-language portability.
151
1      Introduction

La reconnaissance des entités nommeés (REN) est une sous-tâche de l’extraction d’information
consistant à délimiter et à catégoriser certaines expressions linguistiques autonomes et
mono-référentielles (Ehrmann, 2008). Ces dernières correspondent traditionnellement à
l’ensemble des noms propres (noms de personnes, de lieu et d’organisation) ainsi que certaines
expressions numériques et temporelles (expressions de dates, de temps, de pourcentages, etc.).
La délimitation et la catégorisation des entités nommeés sont connues sous le nom d’annotation
qui consiste généralement à encadrer une entité nommeé par le biais d’une balise de début et de
fin mentionnant sa typologie.

Certaines langues ont suscité beaucoup d’intérêt, notamment via les campagnes d’éva-
luations telles que MUC (Grishman et Sundheim, 1996) pour l’anglais et le japonais, CONLL
(Tjong Kim Sang, 2002) pour l’espagnol et l’allemand et ESTER (Galliano et al., 2009) pour
le français. Plusieurs systèmes ont été développés pour ces différentes langues. La plupart
d’entre eux utilisent soit des méthodes symboliques soit des méthodes statistiques. Les systèmes
symboliques sont basés sur des lexiques (listes de prénom, de pays, etc.) et sur un ensemble
de règles de reé́criture (Maurel et al., 2011; Brun et Ehrmann, 2010; Stern et Sagot, 2010).
D’un autre côté, les systèmes statistiques sont basés sur un modèle appris à partir d’un corpus
préalablement annoté (Bikel et al., 1997; Raymond et Fayolle, 2010; Béchet et Charton, 2010).

La portabilité entre les langues des systèmes de REN est coûteuse en termes de temps
et de connaissances linguistiques requises. Par exemple, les systèmes symboliques nécessitent
un traitement lourd incluant, notamment, la modification des règles contextuelles et le
développement de nouvelles listes de mots déclencheurs et de noms propres. La rareté et
le coût de construction de ces ressources représentent un problème majeur pour certaines
langues (Poibeau, 2003; Gamon et al., 1997). D’un autre côté, les systèmes probabilistes se
heurtent au problème de disponibilité des corpus d’apprentissages. Ces derniers ne sont pas
faciles à constituer et ne sont pas disponibles pour toutes les langues. Plusieurs travaux visent
à automatiser le processus d’annotation en exploitant l’encyclopédie multilingue Wikipédia
(Nothman et al., 2009) et les corpus multilingues comparables (Klementiev et Roth, 2006).

Dans cet article, nous examinons l’intérêt et le coût associé pour porter un système
existant de REN pour du texte bien formé vers une autre langue. Nous nous sommes appuyés
pour cela sur le système symbolique français Nemesis (Fourour, 2002). Nous présentons une
méthode permettant de porter Nemesis vers l’anglais à moindre coût. Nous décrivons le système
Nemesis dans la section 2 et les corpus d’évaluation dans la section 3. Nous présentons ensuite le
détail du processus d’adaptation dans la section 4. La section 5 présente les résultats sur les
corpus ayant servi aux évaluations et les compare aux résultats obtenus par Stanford Named
Entity Recognizer 1 (Finkel et al., 2005), un système de REN développé pour l’anglais. Pour
terminer, dans la section 6, nous discutons les apports et les limites de cette approche.
1. Ce système est disponible gratuitement à : http ://nlp.stanford.edu/software/CRF-NER.shtml
152
2    Nemesis : un système symbolique de REN pour le français

Nemesis (Fourour, 2002) est un système qui permet la délimitation et la catégorisation des
entités nommeés développé pour le français et pour du texte bien formé (c’est-à-dire qui respecte
les règles du français écrit). Il se base essentiellement sur les indices internes et externes définis
par McDonald (1996). L’architecture de Nemesis se compose principalement de trois modules
qui s’exécutent séquentiellement : prétraitement lexical, projection des lexiques et application
des règles.

Prétraitement lexical : segmentation du texte en occurrences de formes et de phrases,
puis association des sigles à leur forme étendue.
Projection des lexiques : les lexiques ont été construits soit manuellement, soit automatique-
ment à partir du Web. Les éléments composant ces lexiques (79 476 éléments) sont répartis en
45 listes selon les catégories dans lesquelles ils sont utilisés : prénom connu, mot déclencheur
d’un nom d’organisation (l’élément fait partie de l’entité nommeé : « Fédération française de
handball »), contexte d’un nom de personne (l’élément appartient au contexte gauche immédiat
de l’entité nommeé, mais ne fait pas partie de celle-ci : « philosophe Emmanuel Kant »), fin d’un
nom d’organisation (l’élément est la dernière forme composant l’entité nommeé : « Conseil
régional », « Coupe du monde de football »), etc.
La projection des lexiques consiste à associer les étiquettes lieés aux lexiques aux différentes
formes du texte. Une forme peut avoir plusieurs étiquettes (Washington|prénom-connu|lieu-
connu).
Application des règles : les règles de reé́criture permettent l’annotation du texte par des
balises identifiant les entités nommeés (délimitation et catégorisation). Elles sont baseés sur des
étiquettes sémantiques référant à une forme capitaliseé ou à une forme appartenant à un lexique.
En tout, Nemesis utilise 93 règles qui s’exécutent dans un ordre prédéfini. Lorsque plusieurs
règles s’appliquent, Nemesis opte pour la règle ayant la priorité la plus éleveé. Voici un exemple
de règles de reé́criture :

$Clé-oronyme $Article-min [ $Forme-capitaliseé+ ]→ ORONYME

et le résultat de son application :

"montagne du <ORONYME> Mont-Blanc </ORONYME>"

L’évaluation de Nemesis a été réaliseé sur un corpus composé de textes issus du journal
Le Monde et du Web (31 000 mots). Les performances sur l’ensemble des entités nommeés
montrent un rappel de 79 % et une précision de 91 % (Fourour, 2003).
3    Description des corpus et mesure des performances

Trois corpus dont deux en langue française et un autre en langue anglaise ont été utilisés dans
nos expérimentations.
153
Le corpus de référence anglais, BBN Pronoun Coreference and Entity Type Corpus 2 , est
composé d’articles provenant de Wall Street Journal manuellement annoté en entités nommeés.
Le guide d’annotation comporte 12 catégories principales (Person, Facility, Organization, GPE,
Location, Nationality, Product, Event, Work of Art, Law, Language, Contact-Info) et plusieurs
sous-catégories. Seules les entités sont prises en compte dans l’étiquette. Les formes qui ne
font pas partie de l’entité elle-même sont exclues de l’annotation (Mr. <PERSON> Spoon
</PERSON>). Ce corpus a été divisé en deux parties, développement (3/4 du corpus) et test
(1/4 du corpus).

Le corpus de référence français (Stern et Sagot, 2010) 3 est constitué de dépêches pro-
venant de l’Agence France-Presse (AFP) et contient des annotations manuelles des entités
de type Personne, Lieu et Organisation (comprenant les noms d’entreprises). Les formes non
constitutives du nom de l’entité lui-même sont exclues de l’annotation (M. <PERSON> Spoon
</PERSON>). La taille de ce corpus est bien plus faible que celle du corpus anglais. Pour des
raisons de comparaison, nous avons également eu recours à un corpus non annoté constitué des
articles du journal Le Monde (2007).

Dans ce travail, seules les entités communes entre les deux corpus annotés ont été rete-
nues pour les expériences (Personne, Organisation, Lieu et Entreprise). La table 1 décrit les
différents corpus utilisés dans ce travail. Les performances sont mesureés en termes de rappel et

Corpus                          Langue       Nb de mots       Nb d’entités
Corpus BBN (développement)                anglais      938 330          46 478
Corpus BBN (test)                         anglais      235 274          11 930
Corpus AFP                                français     38 831           1 497
Corpus Le Monde                           français     1 010 000        -

TABLE 1: Description des corpus

de précision. Le rappel est défini par le nombre d’entités correctement étiqueteés au regard du
nombre d’entités étiqueteés dans la référence. La précision est le nombre d’entités correctement
étiqueteés au regard du nombre d’entités correctement et incorrectement étiqueteés. La F-mesure
combine ces deux mesures.

N ombr e d ent i tés cor r ec t ement é t iqueté es
Rappel =                                                                        (1)
N ombr e d ent i tés é t iqueté es dans la ré f é r ence
N ombr e d ent i tés cor r ec t ement é t iqueté es
P ré cision =                                                                 (2)
N ombr e d ent i tés é t iqueté es f our nis
2 ∗ r appel ∗ pré cision
F − mesur e =                                                    (3)
r appel + pré cision

2. Catalogue LDC n̊ LDC2005T33
3. Ce corpus est disponible librement dans le cadre de la distribution de SXPipe
154
4      Adaptation de Nemesis à l’anglais

La mesure des performances des systèmes de REN dépend directement de la cohérence entre les
annotations manuelles et les annotations automatiques. Nous avons donc commencé par ajuster
les règles de délimitation et de catégorisation de Nemesis aux normes d’annotation des corpus
d’évaluation.

Notre objectif est de porter Nemesis vers l’anglais d’une façon simple et peu coûteuse.
La méthode proposeé consiste à adapter séparément et séquentiellement les deux principaux
éléments constitutifs de Nemesis : les lexiques et les règles de reé́criture.
4.1     Adaptation des lexiques

Nous avons construit l’ensemble des lexiques pour l’anglais en traduisant tout simplement les
lexiques existants pour le français. La traduction est faite automatiquement en utilisant un
dictionnaire bilingue 4 sans aucune information contextuelle. Cela concerne principalement
l’ensemble des lexiques de mots déclencheurs. Les lexiques des noms de personne et d’entreprise
sont conservés. Cette tâche n’est pas coûteuse en termes de temps et ne demande pas une
expertise linguistique (des outils en ligne comme Google Translate peuvent être utilisés pour
les langues pour lesquelles les dictionnaires électroniques ne sont pas disponibles). Lorsque
le dictionnaire comporte plusieurs traductions pour un mot, l’ensemble des traductions sont
conserveés (nous ne traitons pas à ce niveau les problèmes de polysémie). Une fois la phase de
traduction termineé, nous avons utilisé une liste des mots outils en anglais pour écarter certaines
entreés pouvant produire de bruit, par exemple le mot even qui se présente comme un nom de
personne dans le lexique français. En définitive, l’ensemble des lexiques pour l’anglais compte 83
305 entreés.
4.2 Adaptation des règles

4.2.1 Classification des règles

Avant d’adapter les règles, nous avons commencé par mesurer la fréquence et la précision
relatives de chacune des règles utiliseés par Nemesis (93 règles). La fréquence représente le
nombre de fois où chaque règle est déclencheé pour reconnaître une entité nommeé. La figure
1 présente les résultats obtenus sur le corpus Le Monde pour le français (1a) et sur le corpus
de développement BBN pour l’anglais (après adaptation des lexiques) (1b). Les observations
montrent que la loi de Zipf est respecteé pour les deux langues : un nombre limité de règles est
à l’origine de la plupart des entités extraites, les autres règles sont rarement déclencheés. Par
exemple pour l’anglais, 11 règles couvrent 86% des entités extraites. On remarque aussi que de
nombreuses règles ne sont pas déclencheés (38 pour l’anglais contre 17 pour le français).

La précision mesure la quantité d’entités correctement reconnues parmi les réponses re-
tourneés. En effet, ce n’est pas parce qu’une règle est fréquente qu’elle est pour autant précise.

4. Catalogue ELRA-M0033 (http ://catalog.elra.info/product_info.phpproducts_id=666&language=fr)
155
Nous avons calculé la précision de chacune des règles déclencheés pour le français sur le corpus
AFP et pour l’anglais sur le corpus de développement BBN. La figure 2 présente les résultats
obtenus pour l’anglais. Plusieurs règles déclencheés obtiennent une précision relativement
faible (32 règles ont une précision inférieure à 50%, ce qui représente environ 60% des règles
déclencheés). En se basant sur les critères de fréquence et de précision, nous avons ensuite classé
(a) Français (corpus Le Monde)
(b) Anglais (corpus de développement BBN)

FIGURE 1: Nombre de déclenchements des règles pour le français et pour l’anglais
les règles en différentes catégories, par exemple : règles fréquentes 5 ayant une bonne précision 6
dans les deux langues (7 règles), règles fréquentes pour l’anglais avec une faible précision 7 (3
règles), règles déclencheés seulement pour le français (19 règles), règles non déclencheés dans
les deux langues (15 règles), etc. Ces différentes catégories vont nous permettre de déterminer
quelles sont les règles à modifier pour la langue anglaise.

5. Fréquence > 1 000
6. Précision > 70 %
7. Précision < 50 %
156
FIGURE 2: Précision des règles déclencheés pour l’anglais (corpus BBN)
4.2.2   Adaptation des règles
Pour adapter les règles, nous avons sélectionné celles n’appartenant pas aux catégories de bonne
précision pour l’anglais. Nous avons également éliminé certaines règles déclencheés seulement
pour le français car elles sont très spécifiques à cette langue, par exemple :

[ $Clé-organisation $Article-min $Item $Article-min
$Forme-capitaliseé+ ] → ORGANISATION

et un exemple d’application :

"<ORGANISATION> Centre de recherche de Solaize </ORGANISATION>"

Nous avons ensuite modifié les règles sélectionneés de manière à respecter la syntaxe
de la langue anglaise (29 règles), comme la règle suivante pour le français :

$Fonction $Adjectif-de-nationalité [ $Forme-capitaliseé+ ] → PERSON
et le résultat de son application :

"Le président français <PERSON> Jacques Chirac </PERSON>"

et la règle pour l’anglais après adaptation :

$Adjectif-de-nationalité $Fonction [ $Forme-capitaliseé+ ] → PERSON

et le résultat de son application :

"The French President <PERSON> Jacques Chirac </PERSON>"
157
5    Résultats

Pour des raisons de comparaison, nous avons dans un premier temps appliqué Nemesis au
corpus de test BBN et au corpus AFP. Aucune adaptation n’a été réaliseé. La table 2 présente les
performances réaliseés par catégorie. Nous pouvons remarquer que la reconnaissance des noms
de personne demeure satisfaisante (perte d’environ 5 points de F-mesure). Cela s’explique par
le fait que les lexiques de Nemesis contiennent des prénoms anglais et qu’il y a des règles de
reé́criture communes. La reconnaissance se voit fortement dégradeé pour les autres catégories.
Nous avons ensuite mesuré l’apport de l’adaptation des lexiques et des règles. La table 3 affiche
Nemesis Français             Nemesis Anglais
(sans aucune adaptation)
Corpus AFP              Corpus de test BBN
(français)                   (anglais)
F1 (P/R)                    F1 (P/R)
Personne         77,33 (85,83/71,03)      71,82 (66,65/77,85)
Lieu             88,82 (90,24/87,44)      37,46 (45,61/31,79)
Organisation     54,24 (65,04/46,51)      1,5 (1,1/2)
Entreprise       37,73 (54,05/30)         10 (36,83/5,84)

TABLE 2: Performances de Nemesis pour le français et l’anglais sans adaptation

les gains obtenus pour chaque adaptation. Ces résultats sont comparés à ceux obtenus avec un
système natif (Stanford NER).
Nemesis Anglais            Nemesis Anglais           Stanford NER
(adaptation lexiques)      (adaptation lexiques
et règles)
Corpus BBN                Corpus BBN              Corpus BBN
(anglais)                  (anglais)               (anglais)
F1 (P/R)                  F1 (P/R)                F1 (P/R)
Personne         77,3 (74,48/80,34)         79,51 (81,08/78,01)       90,9 (88,07/93,9)
Lieu             74,38 (72,5/76,35)         79,17 (78,59/79,76)       90,8 (87,6/94,2)
Organisation     21,02 (24,2/18,58)         38,15 (41,9/35,02)        84,6 (89,2/80,04)
Entreprise       27,52 (50,72/18,88)        30,15 (68,34/19,34)

TABLE 3: Performances de Nemesis pour le français et l’anglais

L’adaptation des lexiques a permis un apport significatif concernant la reconnaissance des
noms de lieu (environ 37 points de F-mesure). La reconnaissance des noms d’organisation et
d’entreprise se voit amélioreé mais elle reste toutefois faible. En effet, ce problème semble lié à
une couverture insuffisante des lexiques de Nemesis et à une ambiguité lieé à la catégorisation
des organisations et des entreprises (entreprise catégoriseé en tant qu’organisation et vice-versa).

L’adaptation des règles montre un gain relativement bon pour la catégorie organisation
158
(environ 17 points de F-mesure) et une légère amélioration concernant les autres catégories.
Les résultats globaux sont bien en dessous de ceux obtenus avec Stanford NER, surtout pour la
catégorie organisation. Stanford NER est un système à base d’apprentissage développé pour
l’anglais. Pour ce dernier, les noms d’entreprises sont catégorisés comme étant organisation.
6    Discussion

Cette approche peu coûteuse pour porter Nemesis vers l’anglais montre des résultats satisfaisants
pour la reconnaissance des noms de personne et de lieu. Elle montre ses limites pour la
reconnaissance des noms d’organisation et d’entreprise. L’analyse des résultats obtenus nous a
permis de souligner deux problèmes récurrents de la reconnaissance des entités nommeés : la
délimitation des entités nommeés et la délimitation des catégories.

Les règles d’annotation sont loin de faire consensus. Elles suscitent toujours des vives
discussions et plusieurs remises en cause du guide d’annotation, par exemple dans le cadre de la
campagne ETAPE (Évaluations en Traitement Automatique de la Parole). Le premier problème
rencontré concerne la délimitation des entités nommeés. En effet, les règles de délimitation de
Nemesis ne sont pas les mêmes que celles utiliseés pour annoter le corpus AFP et le corpus
BBN. Par exemple, Nemesis inclut les titres dans les noms de personne (<PERSON> M. Dorgan
</PERSON>) alors que ces derniers ne sont pas inclus dans le corpus AFP (M. <PERSON>
Dorgan </PERSON>). Nous avons dû adapter les règles de délimitation de Nemesis aux
spécificités du corpus traité. Cependant, plusieurs erreurs de délimitation ont été releveés. Le
deuxième problème concerne la délimitation des catégories. Nemesis adopte une catégorisation
fine (5 catégories et 30 sous-catégories). Cette typologie a l’avantage de pouvoir s’adapter aux
typologies moins fines en regroupant des sous-catégories. Nous avons donc adapté la typologie
de Nemesis en fonction des catégories du corpus AFP et du corpus BBN. Toutefois, beaucoup
d’erreurs sont dues à une incohérence de catégorisation. Par exemple, la notion d’organisation et
d’entreprise n’est pas identique entre Nemesis et le corpus BBN (l’entité « Federal Reserve Board
» est annoteé comme étant une entreprise par le système Nemesis alors qu’elle est considéreé
comme étant une organisation dans le corpus BBN).
7    Conclusion et perspectives

Cet article présente une méthode peu coûteuse pour porter un système symbolique de REN
dédié pour le français vers l’anglais. L’adaptation est baseé principalement sur les ressources
développeés pour le français. Elle consiste à traduire les lexiques français et à adapter légèrement
quelques règles de la grammaire. L’évaluation du système adapté montre des résultats satisfai-
sants pour la reconnaissance des noms de personne et de lieu. En revanche, les résultats restent
insuffisants pour les noms d’organisation et d’entreprise. Un traitement plus approfondi est néces-
saire pour ces deux catégories. Pour cela, nous comptons mesurer l’impact d’un enrichissement
des lexiques de Nemesis (notamment les listes d’organisation et d’entreprise). D’un autre côté,
nous envisageons d’adapter les règles de reé́criture automatiquement et de tester cette méthode
sur d’autres langues qui sont moins proches du français que l’anglais.
159
Références
BÉCHET, F. et CHARTON, E. (2010). Unsupervised knowledge acquisition for extracting named
entities from speech. In Proceedings of the 35th IEEE International Conference on Acoustics, Speech,
and Signal Processing (ICASSP’10), pages 5338–5341, Dallas, Texas, USA.
BIKEL, D. M., MILLER, S., SCHWARTZ, R. et WEISCHEDEL, R. (1997). Nymble : a high-performance
learning name-finder. In Proceedings of the 5th Conference on Applied Natural Language Processing
(ANLP’97), pages 194–201, Washington, DC, USA.
BRUN, C. et EHRMANN, M. (2010). Un système de détection d’entités nommeés adapté pour la
campagne d’évaluation ester 2. In Actes de la 17ème conférence sur le Traitement Automatique
des Langues Naturelles (TALN’10), Montréal, Canada.
EHRMANN, M. (2008). Les Entités Nommeés, de la Linguistique au TAL - Statut Théorique et
Méthodes de Désambiguïsation. Thèse de doctorat, Université Paris 7, France.
FINKEL, J. R., GRENAGER, T. et MANNING, C. (2005). Incorporating non-local information into
information extraction systems by gibbs sampling. In Proceedings of the 43rd Annual Meeting on
Association for Computational Linguistics (ACL’05), pages 363–370, Ann Arbor, Michigan, USA.
FOUROUR, N. (2002). Nemesis, un système de reconnaissance incrémentielle des entités nom-
meés pour le français. In Actes de la 9ème conférence sur le Traitement Automatique des Langues
Naturelles (TALN’02), pages 265–274, Nancy, France.
FOUROUR, N. (2003). Apport du web dans la reconnaissance des entités nommeés. In Revue
Québécoise de Linguistique (RQL), pages 41–60.
GALLIANO, S., GRAVIER, G. et CHAUBARD, L. (2009). The ester 2 evaluation campaign for the rich
transcription of french radio broadcasts. In Proceedings of the 10th conference Interspeech, pages
2583–2586, Brighton, UK.
GAMON, M., LOZANO, C., PINKHAM, J. et REUTTER, T. (1997). Practical experience with grammar
sharing in multilingual nlp. In Workshop From research to commercial applications : making NLP
work in practice, pages 49–56, Madrid, Spain.
GRISHMAN, R. et SUNDHEIM, B. (1996). Message Understanding Conference-6 : a brief history.
In Proceedings of the 16th conference on Computational linguistics (COLING’06), pages 466–471,
Copenhagen, Denmark.
KLEMENTIEV, A. et ROTH, D. (2006). Named entity transliteration and discovery from multilingual
comparable corpora. In Proceedings of Human Language Technology Conference of the North
American Chapter of the Association of Computational Linguistics (HLT-NAACL’06), pages 82–88,
New York, USA.
MAUREL, D., FRIBURGER, N., ANTOINE, J.-Y., ESHKOL-TARAVELLA, I. et NOUVEL, D. (2011). Cascades
de transducteurs autour de la reconnaissance des entités nommeés. In Traitement Automatique
des Langues (TAL), pages 69–96.
MCDONALD, D. D. (1996). Internal and external evidence in the identification and semantic
categorization of proper names. In Corpus processing for lexical acquisition, pages 21–39. MIT
Press, Cambridge, MA, USA.
NOTHMAN, J., MURPHY, T. et CURRAN, J. R. (2009). Analysing wikipedia and gold-standard
corpora for ner training. In Proceedings of the 12th Conference of the European Chapter of the
Association for Computational Linguistics (EACL’09), pages 612–620, Athens, Greece.
160
POIBEAU, T. (2003). The multilingual named entity recognition framework. In Proceedings of the
10th Conference on European chapter of the Association for Computational Linguistics (EACL’03),
pages 155–158, Budapest, Hungary.
RAYMOND, C. et FAYOLLE, J. (2010). Reconnaissance robuste d’entités nommés sur de la parole
transcrite automatiquement. In Actes de la 17ème conférence sur le Traitement Automatique des
Langues Naturelles (TALN’10), pages 19–23, Montréal, Canada.
STERN, R. et SAGOT, B. (2010). Détection et résolution d’entités nommeés dans des dépêches
d’agence. In Actes de la 17ème conférence sur le Traitement Automatique des Langues Naturelles
(TALN’10), Montréal, Canada.
TJONG KIM SANG, E. F. (2002). Introduction to the conll-2002 shared task : language-independent
named entity recognition. In Proceedings of the 6th Workshop on Computational Language
Learning (CoNLL’02), pages 155–158, Taipei, Taiwan.
161
