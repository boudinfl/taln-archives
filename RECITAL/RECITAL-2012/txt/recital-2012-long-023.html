<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Analyse automatique de discours en langue des signes : Repr&#233;sentation et traitement de l&#8217;espace de signation</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 3: RECITAL, pages 219&#8211;232,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Analyse automatique de discours en langue des signes :
Repr&#233;sentation et traitement de l&#8217;espace de signation
</p>
<p>Monia Ben Mlouka
IRIT -TCI , UMR5505, 31000 Toulouse
</p>
<p>mlouka@irit.fr
</p>
<p>R&#201;SUM&#201;
En langue des signes, l&#8217;espace est utilis&#233; pour localiser et faire r&#233;f&#233;rence &#224; certaines entit&#233;s dont
l&#8217;emplacement est important pour la compr&#233;hension du sens. Dans cet article, nous proposons
une repr&#233;sentation informatique de l&#8217;espace de signation et les fonctions de cr&#233;ation et d&#8217;acc&#232;s
associ&#233;es, afin d&#8217;analyser les gestes manuels et non manuels qui contribuent &#224; la localisation
et au r&#233;f&#233;rencement des signes et de mat&#233;rialiser leur effet. Nous proposons une approche
bi-directionnelle qui se base sur l&#8217;analyse de donn&#233;es de capture de mouvement de discours en
langue des signes dans le but de caract&#233;riser les &#233;v&#233;nements de localisation et de r&#233;f&#233;rencement.
</p>
<p>ABSTRACT
Automatic Analysis of Discourse in Sign Language : Signing Space Representation and
Processing
</p>
<p>In sign language, signing space is used to locate and refer to entities whose locations are important
for understanding the meaning. In this paper, we propose a computer-based representation of
the signing space and their associated functions. It aims to analyze manual and non-manual
gestures, that contribute to locating and referencing signs, and to make real their effect. For that,
we propose an approach based on the analysis of motion capture data of entities&#8217; assignment and
activation events in the signing space.
</p>
<p>MOTS-CL&#201;S : Langue des signes, Espace de signation, gestes de pointage, capture de mouvement,
suivi du regard.
</p>
<p>KEYWORDS: Sign language, Signing space, pointing gestures, motion capture, gaze tracker.
</p>
<p>219</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1 Introduction
</p>
<p>L&#8217;&#233;tude de l&#8217;aspect gestuel dans les langues naturelles fait l&#8217;objet de plusieurs travaux. Plusieurs
&#233;tudes ont port&#233; sur l&#8217;analyse des gestes manuels et non manuels en situation de dialogue.
L&#8217;une d&#8217;entre elles a apport&#233; une classification fonctionnelle des gestes manuels et non manuels
(Cosnier, 1997). Celle de (Montredon, 2001) &#233;tablit une relation entre les caract&#233;ristiques spatio-
temporelles des gestes manuels et leurs r&#244;les dans l&#8217;&#233;nonc&#233;. En langue des signes, le canal &#233;tant
visuo-gestuel, l&#8217;analyse d&#8217;&#233;nonc&#233;s est en premier lieu une analyse d&#8217;un signal visuel. Elle peut
&#234;tre enti&#232;rement r&#233;alis&#233;e &#224; ce seul niveau ou &#234;tre compl&#233;t&#233;e par des analyses du geste 3D si l&#8217;on
sait reconstruire cette information &#224; partir de donn&#233;es visuelles.
</p>
<p>Nous proposons dans cette &#233;tude une repr&#233;sentation informatique de l&#8217;espace de signation comme
&#233;tant un &#233;l&#233;ment important pour la compr&#233;hension d&#8217;un discours dans la langue des signes. Pour
cela, nous introduirons, en premier lieu, l&#8217;espace de signation et les gestes qui contribuent &#224; la
localisation de signes. Dans un second lieu, nous d&#233;crirons le corpus sur lequel se base notre
analyse. Par la suite, nous pr&#233;senterons notre approche d&#8217;analyse g&#233;om&#233;trique 3D suivie de
quelques r&#233;sultats.
</p>
<p>2 L&#8217;espace de signation
</p>
<p>L&#8217;espace de signation est d&#233;fini comme &#233;tant l&#8217;espace qui entoure le signeur et qui est atteignable
par ses deux mains. L&#8217;espace de signation sert &#224; localiser les entit&#233;s ou notions associ&#233;es &#224; certains
signes, &#233;ventuellement &#224; sp&#233;cifier leurs propri&#233;t&#233;s de forme et de taille et &#224; &#233;tablir des relations
spatiales entre les entit&#233;s (Cuxac, 2000).
</p>
<p>2.1 Ev&#233;nements li&#233;s &#224; l&#8217;espace de signation
</p>
<p>Notre repr&#233;sentation informatique de l&#8217;espace de signation &#233;tant un graphe d&#8217;entit&#233;s spatialis&#233;es
dans un espace 3D. Elle dispose des fonctions classiques de cr&#233;ation, de modification, de sup-
pression et d&#8217;acc&#232;s. Chacune de ces fonctions est d&#233;clench&#233;e par un &#233;v&#233;nement survenu dans
l&#8217;espace de signation. L&#8217;image (1a) est un exemple d&#8217;un signe [TABLE] qui occupe une zone de
l&#8217;espace. L&#8217;image (1b) illustre une association spatiale d&#8217;une action [S&#8217;ASSOIR]. L&#8217;image (1c) est
un exemple d&#8217;un pointage manuel vers une zone particuli&#232;re de l&#8217;entit&#233; [TABLE]. La zone est
sp&#233;cifi&#233;e par la direction de la main dominante.
</p>
<p>2.2 Aspect multilin&#233;aire
</p>
<p>L&#8217;&#233;tude de (Fusellier-Souza, 2004) s&#8217;est int&#233;ress&#233;e aux gestes manuels et non manuels qui contri-
buent aux changements d&#8217;&#233;tats de l&#8217;espace de signation. Une &#233;tude similaire, celle de (Thompson
et al., 2006) a port&#233; sur la relation entre le regard et la r&#233;alisation d&#8217;actions spatialis&#233;es. Les deux
&#233;tudes soulignent l&#8217;aspect multilin&#233;aire dans la r&#233;alisation de gestes. Dans cette &#233;tude nous nous
focaliserons sur les gestes de cr&#233;ation et de r&#233;f&#233;rencement d&#8217;entit&#233;s dans l&#8217;espace de signation.
Comme nous l&#8217;avons cit&#233; pr&#233;c&#233;demment, les gestes sont manuels et non manuels que ce soit pour
les &#233;v&#233;nements de cr&#233;ation ou de r&#233;f&#233;rencement. Les gestes manuels de cr&#233;ation d&#8217;entit&#233;s dans
</p>
<p>220</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FIGURE 1 &#8211; a : Un objet spatialis&#233; [TABLE], b : Une action spatialis&#233;e [S&#8217;ASSOIR], c : Un pointage
vers une partie de la portion de l&#8217;espace occup&#233; par le signe[TABLE]
</p>
<p>l&#8217;espace de signation repr&#233;sentent les signes effectu&#233;s &#224; un emplacement sp&#233;cifique ou les signes
localis&#233;s sur le corps puis situ&#233;s dans l&#8217;espace de signation par un pointage :
</p>
<p>&#8211; L&#8217;orientation du regard et l&#8217;inclinaison de la t&#234;te permettent d&#8217;associer une zone de l&#8217;espace de
signation au signe en cours de r&#233;alisation.
</p>
<p>&#8211; Les gestes manuels peuvent associer une forme &#224; l&#8217;entit&#233; et pr&#233;ciser la taille qu&#8217;elle occupe
dans l&#8217;espace.
</p>
<p>Les images (1a), (1b) et (1c) repr&#233;sentent des exemples de r&#233;alisation de l&#8217;aspect de multi-
lin&#233;arit&#233; :
&#8211; Dans (1a) et (1c), on observe que le regard du signeur est orient&#233; vers la m&#234;me zone d&#8217;espace
</p>
<p>occup&#233;e par l&#8217;entit&#233;.
&#8211; On observe &#233;galement une posture particuli&#232;re dans (1b) qui se manifeste par une inclinaison
</p>
<p>de la t&#234;te vers l&#8217;emplacement de la main qui effectue le signe [S&#8217;ASSOIR].
&#8211; Dans (1c), on ne peut pas d&#233;terminer si le regard fixe cet endroit de l&#8217;espace car la t&#234;te du
</p>
<p>signeur est baiss&#233;e mais on peut le d&#233;duire gr&#226;ce &#224; la position de la t&#234;te l&#233;g&#232;rement inclin&#233;e
vers le bas.
</p>
<p>Par ces exemples, nous avons illustr&#233; l&#8217;importance de l&#8217;aspect multilin&#233;aire de gestes qui contri-
buent aux fonctions de cr&#233;ation, de r&#233;f&#233;rencement de l&#8217;entit&#233; [S&#8217;ASSEOIR] : fixation du regard,
gestes manuels et mouvements de la t&#234;te. Dans la litt&#233;rature, peu de travaux ont port&#233; sur la
repr&#233;sentation informatique de l&#8217;espace de signation. Nous citons l&#8217;&#233;tude de (Lenseigne, 2005)
qui a port&#233; sur la repr&#233;sentation informatique de la structure de l&#8217;espace de signation dans un
discours en langue des signes fran&#231;aise. L&#8217;aspect gestuel a &#233;t&#233; pris en compte dans l&#8217;&#233;tude de
(Braffort, 1996) qui consistait &#224; mod&#233;liser les gestes dans les verbes directionnels et d&#233;ictiques &#224;
partir de donn&#233;es fournies par un gant num&#233;rique. (Lu et Huenerfauth, 2011) a d&#233;velopp&#233; une
technique qui, &#224; partir de donn&#233;es de capture de mouvement, permet de mod&#233;liser les gestes dont
la r&#233;alisation est influenc&#233;e par la localisation spatiale des entit&#233;s dans l&#8217;espace de signation.Dans
cette derni&#232;re &#233;tude, (Lu et Huenerfauth, 2011) s&#8217;est int&#233;ress&#233; aux gestes exprimant des verbes.
Notre travail s&#8217;inscrit dans le m&#234;me cadre et s&#8217;int&#233;resse &#224; l&#8217;aspect multilin&#233;aire (combinaisons de
gestes manuels et non manuels) et se base &#224; la fois sur des donn&#233;es tri-dimensionnelles de capture
de mouvement et sur des donn&#233;es de suivi du regard synchronis&#233;es avec les enregistrements
vid&#233;os.
</p>
<p>221</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>3 Acquisition du Corpus
</p>
<p>Le corpus sur lequel nous avons appliqu&#233; notre approche d&#8217;analyse a &#233;t&#233; enregistr&#233; dans le
cadre du partenariat franco-qu&#233;b&#233;cois (Marqspat) 1. Les sessions de capture ont &#233;t&#233; r&#233;alis&#233;es
avec un syst&#232;me de capture de mouvement (VICON) 2, une cam&#233;ra vid&#233;o pour filmer le cadre
complet de la sc&#232;ne et un syst&#232;me de capture du regard (FaceLab) 3 . Lors de l&#8217;enregistrement,
le signeur commence et termine sa production par un &quot;clap&quot; manuel qui permettra d&#8217;effectuer
ult&#233;rieurement une synchronisation de la vid&#233;o et des donn&#233;es de la capture de mouvement et
commence &#224; r&#233;pondre &#224; des questions sous forme de vid&#233;os projet&#233;es. Les questions concernent
des d&#233;tails &#224; propos de sc&#232;nes enregistr&#233;es pr&#233;alablement. Les donn&#233;es de capture de mouvement
et celles de suivi du regard feront l&#8217;objet d&#8217;une analyse automatique (Ben Mlouka et al., 2010)
dont on d&#233;taillera les &#233;tapes dans la section suivante.
</p>
<p>4 Annotations et repr&#233;sentations informatiques
</p>
<p>Nous avons adopt&#233; une m&#233;thode compos&#233;e de plusieurs &#233;tapes :
</p>
<p>4.1 Grille d&#8217;annotation
</p>
<p>L&#8217;annotation 4 du corpus a &#233;t&#233; r&#233;alis&#233;e et v&#233;rifi&#233;e par plusieurs annotateurs qu&#233;b&#233;cois de comp&#233;-
tences vari&#233;es en Langue des Signes Fran&#231;aise, Qu&#233;b&#233;coise et Am&#233;ricaine. La grille d&#8217;annotation
se compose de :
</p>
<p>Une annotation en gloses Les annotateurs ont transcrit les signes effectu&#233;s par les deux mains
et qui peuvent avoir ou non une association spatiale sp&#233;cifique. La capture d&#8217;&#233;cran de la grille
d&#8217;annotation (2) montre un exemple de valeurs attribu&#233;es aux pistes : la main droite (MD) :
[S&#8217;ASSEOIR], la piste (MG) transcrit les signes effectu&#233;s par la main gauche, la piste (2M) inclut
ceux &#224; deux mains.
</p>
<p>Une annotation de gestes et de signes en liaison avec l&#8217;espace Les gestes manuels et non
manuels transcrits sont n&#233;cessairement associ&#233;s &#224; une zone de l&#8217;espace de signation. A chaque
geste ou signe spatialis&#233;, on associe une &#233;tiquette (ex. x, y, z, etc.) pour &#233;tiqueter la zone &#224;
laquelle est associ&#233; ce geste ou ce signe. Dans l&#8217;exemple (2), la piste (MC) mentionne le nom de
la zone associ&#233;e au signe [S&#8217;ASSEOIR], cela veut dire qu&#8217;une zone est occup&#233;e par une entit&#233; &quot;y&quot;
dont le signifiant est l&#8217;action [S&#8217;ASSEOIR]. Le reste des pistes visibles inclut les noms d&#8217;entit&#233;s
spatiales vers lesquelles un composant corporel fait r&#233;f&#233;rence :
</p>
<p>1. Lien vers le site web du projet : http ://www.irit.fr/marqspat/index.html
2. Il s&#8217;agit d&#8217;un syst&#232;me de capture compos&#233; de 8 cam&#233;ras infrarouges qui enregistrent les positions 3D de marqueurs
</p>
<p>r&#233;fl&#233;chissants pos&#233;s sur les membres du signeur
3. Un syst&#232;me non invasif compos&#233; de deux cam&#233;ras et d&#8217;un &#233;metteur infra-rouge. Il fournit sous forme de donn&#233;es
</p>
<p>3D, l&#8217;orientation du regard. Une cam&#233;ra de sc&#232;ne qui permet de synchroniser les donn&#233;es vid&#233;os et donn&#233;es 3D
4. Ces annotations manuelles ont &#233;t&#233; effectu&#233;es par l&#8217;&#233;quipe &quot;Groupe de recherche sur la langue des signes qu&#233;b&#233;coise
</p>
<p>et le bilinguisme sourd&quot; qui pilote le projet (Marqspat)
</p>
<p>222</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FIGURE 2 &#8211; Un exemple de valeurs d&#8217;annotation
</p>
<p>1. La piste (MR), repr&#233;sente les entit&#233;s cibl&#233;es par les pointages manuels
</p>
<p>2. La piste (TR) celle des entit&#233;s r&#233;f&#233;renc&#233;es par la t&#234;te.
</p>
<p>3. La piste (RM) celle de la direction du regard o&#249; on nomme l&#8217;entit&#233; sur laquelle se focalise
le regard.
</p>
<p>Dans l&#8217;image (3a), la zone de l&#8217;espace occup&#233;e par le signe [S&#8217;ASSOIR] est &#233;tiquet&#233;e x . L&#8217;image
(3b) illustre un exemple o&#249; la main dominante effectue le signe [FILLE], le regard et la t&#234;te se
dirigent vers une m&#234;me cible (x)
</p>
<p>La lecture transversale de la grille d&#8217;annotation est un moyen qui permet de grouper les m&#234;mes
&#233;tiquettes d&#8217;entit&#233;s (x dans les deux exemples pr&#233;c&#233;dents). Une interpr&#233;tation simple de cette
lecture transversale : Le signeur associe une zone de l&#8217;espace &#224; une entit&#233; (x) gr&#226;ce &#224; l&#8217;orientation
du regard et de la t&#234;te et associe le r&#233;f&#233;rent [FILLE] &#224; la zone (x) gr&#226;ce au signe effectu&#233; pr&#232;s de
la t&#234;te.
</p>
<p>Cette mise en correspondance entre les gestes et leurs interpr&#233;tations sera g&#233;n&#233;ralis&#233;e gr&#226;ce
&#224; l&#8217;extraction et la synchronisation automatique des annotations manuelles avec les donn&#233;es
de capture de mouvement qui leurs correspondent dans le but de mettre en place des mod&#232;les
g&#233;om&#233;triques propres aux gestes qui contribuent &#224; la cr&#233;ation ou au r&#233;f&#233;rencement d&#8217;une m&#234;me
entit&#233;.
</p>
<p>223</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FIGURE 3 &#8211; Une lecture transversale d&#8217;annotation d&#8217;un &#233;v&#233;nement de r&#233;f&#233;rencement : a- Locali-
sation manuelle et non manuelle (regard) du signe [S&#8217;ASSOIR], b- Localisation non manuelle
(t&#234;te et regard) du signe [FILLE] car celui-ci se r&#233;alise par la main dominante &#224; un emplacement
sp&#233;cifique (pr&#232;s de la t&#234;te)
</p>
<p>4.2 Repr&#233;sentation g&#233;om&#233;trique
</p>
<p>Comme nous l&#8217;avons mentionn&#233; dans 4.1, les articulateurs repr&#233;sent&#233;es sont la main dominante,
la t&#234;te et le regard.
</p>
<p>Mesure de l&#8217;enveloppe de la main La main dominante est repr&#233;sent&#233;e par une sph&#232;re de
centre milieu des bases de l&#8217;index et celui de l&#8217;auriculaire, de rayon la longueur du majeur(voir
figure 4).
</p>
<p>! FIGURE 4 &#8211; Repr&#233;sentation g&#233;om&#233;trique de la main
224</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La cible du regard La cible du regard est repr&#233;sent&#233;e par un point dont les coordonn&#233;es sont
fournies 5 par le syst&#232;me de suivi du regard. Il fournit la position 3D de la cible du regard &#224; un
instant donn&#233;, exprim&#233;e dans le m&#234;me rep&#232;re que celui des positions des marqueurs de capture
de mouvement 6. Nous avons not&#233; que le taux de points de vergence reconstruits par (FaceLab)
est relativement faible par rapport aux donn&#233;es enregistr&#233;es. Ceci est d&#251; au fait que &#224; plusieurs
moments, les directions du regard calcul&#233;es ne sont pas convergentes et par cons&#233;quent ne
permettent pas de calculer les positions des points de vergence.
</p>
<p>TOPH
</p>
<p>RHEA LHEA
</p>
<p>TOPH
</p>
<p>FORHLHEA
</p>
<p>RHEA
</p>
<p>FORH
</p>
<p>Orientation de la t&#234;te
</p>
<p>Orientation de la t&#234;te
</p>
<p>FIGURE 5 &#8211; Repr&#233;sentation g&#233;om&#233;trique de l&#8217;orientation de la t&#234;te (&#224; gauche : vue de face, &#224;
droite : vue de dessus)
</p>
<p>Mesure de l&#8217;orientation de la t&#234;te L&#8217;orientation de la t&#234;te est mesur&#233;e comme &#233;tant la normale
&#224; la droite passant par les marqueurs &quot;RHEA&quot; et &quot;LHEA&quot; et passant par le marqueur &quot;FORH&quot; (voir
figure 5). Le vecteur ~n est le vecteur normal au plan form&#233; par les marqueurs : RHEA, LHEA et
TOPH. La figure (5) indique la position de ces marqueurs en vue de dessus. L&#8217;&#233;quation du plan
&#233;tant :
</p>
<p>P : a.x + b.y + c.z+ d = 0 (1)
</p>
<p>Le vecteur normal est le r&#233;sultat du produit vectoriel suivant :
</p>
<p>~n= ~AB &#8743; ~AC (2)
Tels que : A, B et C repr&#233;sentent la position g&#233;om&#233;triques des marqueurs RHEA, TOPH et LHEA
respectivement. Dans la suite nous allons caract&#233;riser l&#8217;aspect multi-composant entre les diff&#233;rents
mod&#232;les g&#233;om&#233;triques.
</p>
<p>5. (FaceLab) fournit une liste de mesures sur : la position des globes oculaires, les pupilles, le degr&#233; de fermeture
des yeux, l&#8217;angle d&#8217;orientation du regard, etc. Dans ce travail, nous nous sommes int&#233;ress&#233;s aux positions de points de
vergence seulement
</p>
<p>6. Nous avons fusionn&#233; les donn&#233;es fournies par le syst&#232;me de capture de mouvement et celles fournies par (FaceLab)
dans un m&#234;me rep&#232;re
</p>
<p>225</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4.3 Mesures et relations
</p>
<p>On se propose dans cette phase de prendre en compte le sens comme cela a &#233;t&#233; d&#233;taill&#233; dans 4.1
et d&#8217;extraire les positions g&#233;om&#233;triques correspondantes de chaque composant corporel. Par la
suite nous caract&#233;riserons la convergence des composants corporels comme &#233;tant l&#8217;intersection
simultan&#233;e ou diff&#233;r&#233;e des repr&#233;sentations g&#233;om&#233;triques de l&#8217;orientation de la t&#234;te, la position
de la main dominante et la cible du regard. La notion d&#8217;intersection g&#233;om&#233;trique inclut deux
diff&#233;rents composants corporels, on parle ainsi d&#8217;une relation entre composants. On qualifie
l&#8217;intersection diff&#233;r&#233;e de deux positions g&#233;om&#233;triques d&#8217;un m&#234;me composant de relation intra-
composant.
</p>
<p>4.3.1 Relations entre composants
</p>
<p>Mesures de l&#8217;intersection orientation t&#234;te et main dominante On se propose de mesurer la
distance d entre la droite portant l&#8217;orientation de la t&#234;te D et le centre de la main S :
</p>
<p>d =
|| ~n&#8743; ~SMD ||
|| ~n || (3)
</p>
<p>Tels que M est un point appartenant &#224; la droite D. Cette m&#234;me formule s&#8217;applique &#233;galement
pour la mesure de l&#8217;intersection entre la cible fix&#233;e ou point&#233;e et l&#8217;orientation de la t&#234;te.
</p>
<p>Mesures de l&#8217;intersection cible du regard et main dominante On se propose de mesurer la
distance d entre le point qui repr&#233;sente la cible fix&#233;e par le regard et P et le centre de la main S :
</p>
<p>d =
&#198;
(xC &#8722; xp)2 + (yC &#8722; yp)2 + (zC &#8722; zp)2 (4)
</p>
<p>Tels que C est le centre de la main dominante et p et le point cible du regard. Cette formule
s&#8217;applique &#233;galement pour la mesure de l&#8217;intersection entre la cible fix&#233;e et espace r&#233;f&#233;renc&#233; par
la main dominante.
</p>
<p>4.3.2 Relations intra-composant
</p>
<p>Mesures de la convergence des espaces occup&#233;es par une seule entit&#233; On se propose de
mesurer la distance d entre deux sph&#232;res repr&#233;sentatives de la position de la main dominante &#224;
deux instants distincts :
</p>
<p>d =
&#198;
(xC1 &#8722; xC2)2 + (yC1 &#8722; yC2)2 + (zC1 &#8722; zC2)2 (5)
</p>
<p>Tels que C1 et C2 sont les centres des sph&#232;res qui repr&#233;sentent la main dominante &#224; deux instants
diff&#233;rents. Cette formule s&#8217;applique &#233;galement pour la mesure de convergence entre espace
occup&#233; et espace r&#233;f&#233;renc&#233; par la main dominante.
</p>
<p>Mesure de la variation de l&#8217;orientation de la t&#234;te Dans le but de mesurer la variation de cette
orientation au cours d&#8217;un &#233;v&#233;nement de r&#233;f&#233;rencement, nous nous proposons de mesurer l&#8217;angle
</p>
<p>226</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>form&#233; par deux vecteurs porteurs des droites D1 et D2 d&#8217;orientation de la t&#234;te correspondante &#224;
deux instants distincts.
</p>
<p>L&#8217;angle &#952; est mesur&#233; selon cette formule :
</p>
<p>cos(&#952;)
~n1. ~n2p|| ~n1 || . || ~n2 || (6)
</p>
<p>Tels que ~n1 et ~n2 sont les vecteurs directeurs de D1 et D2 respectivement dont les coefficients
sont calcul&#233;s selon la formule &#233;nonc&#233;e en (4.2).
</p>
<p>4.4 Premiers r&#233;sultats
</p>
<p>4.4.1 Objectifs de l&#8217;analyse
</p>
<p>On se propose d&#8217;apporter des &#233;l&#233;ments de r&#233;ponses par rapport &#224; l&#8217;&#233;tat de l&#8217;espace de signation.
En particulier, on veut d&#233;terminer si l&#8217;espace de signation, tel qu&#8217;il est per&#231;u par le signeur,
subit des transformations g&#233;om&#233;triques (translation et/ou rotation) au cours des &#233;v&#233;nements
de r&#233;f&#233;rencement. Pour cela, on &#233;tudiera la relation entre l&#8217;emplacement de l&#8217;entit&#233; qui occupe
une partie de l&#8217;espace de signation et la position de la main dominante du signeur quand celui-ci
pointe vers cette m&#234;me entit&#233;.
</p>
<p>Pointages manuel vers une m&#234;me entit&#233; Comme cela a &#233;t&#233; d&#233;taill&#233; dans 4.3.2, nous avons
mesur&#233; la distance qui s&#233;pare deux positions de la main dominante lors de la r&#233;alisation d&#8217;un
signe spatialis&#233; et lors d&#8217;un pointage vers cette m&#234;me entit&#233; 6.
</p>
<p>FIGURE 6 &#8211; a- Cr&#233;ation d&#8217;une entit&#233; - X, b, c et d- Pointages vers X
</p>
<p>Figure 6b Figure 6c Figure 6d
Moyenne de la distance (mm) 685, 6 611, 5 569,7
Ecart-type de la distance (mm) 3, 2 1, 6 25,2
</p>
<p>TABLE 1 &#8211; Mesure de la distance qui s&#233;pare deux positions de la main dominante lors de la
r&#233;alisation d&#8217;un signe spatialis&#233; et lors d&#8217;un pointage vers cette m&#234;me entit&#233;
</p>
<p>227</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Les valeurs moyennes des distances du tableau 1 sont significatives car elles v&#233;rifient la r&#232;gle
68-95-99.7 de la loi normale 7
</p>
<p>&#181;&#8722; 3 &#8727;&#963; &lt; 99.7% &#8727; N &lt; &#181;+ 3 &#8727; si gma (7)
&#181;&#8722; 2 &#8727;&#963; &lt; 95% &#8727; N &lt; &#181;+ 2 &#8727; si gma (8)
&#181;&#8722;&#963; &lt; 68% &#8727; N &lt; &#181;+ si gma (9)
</p>
<p>Tels que : &#181; est la valeur moyenne et &#963; est l&#8217;&#233;cart-type de l&#8217;ensemble des valeurs de distance N
</p>
<p>De ce fait, on d&#233;duit que les distance entre positions de la main dominante illustr&#233;es dans les
images (6b, c et d) et celle de l&#8217;image (6a) peuvent &#234;tre g&#233;n&#233;r&#233;es par une m&#234;me loi de distribution
normale de moyenne : 622,3 et d&#8217;&#233;cart-type :58,7 (en mm). Cela veut dire que dans ces trois
exemples (Cr&#233;ation-R&#233;f&#233;rencement), les distances qui s&#233;parent deux positions diff&#233;rentes de la
main dominante (la premi&#232;re en phase de cr&#233;ation et la deuxi&#232;me en phase de r&#233;f&#233;rencement)
ne sont pas exactement les m&#234;mes mais varient autour d&#8217;une m&#234;me moyenne.
</p>
<p>Pointages manuels vers deux entit&#233;s diff&#233;rentes La m&#234;me formule 4.3.2 a &#233;t&#233; appliqu&#233;e sur
les s&#233;quences 7.
</p>
<p>FIGURE 7 &#8211; a- Cr&#233;ation d&#8217;une entit&#233; - X, b- Pointage vers X, c- Cr&#233;ation d&#8217;une entit&#233; - Y, d- Pointage
vers Y
</p>
<p>TABLE 2 &#8211; Mesure de la distance qui s&#233;pare deux positions de la main dominante lors de la
r&#233;alisation d&#8217;un signe spatialis&#233; et lors d&#8217;un pointage vers une m&#234;me entit&#233;
</p>
<p>Figure 7b Figure 7d
Moyenne de la distance (mm) 685, 6 194, 3
Ecart-type de la distance (mm) 3, 2 10, 6
</p>
<p>Les valeurs moyennes des distances du tableau 2 ne v&#233;rifient pas la r&#232;gle 68-95-99.7.
Bien que la variation des distances n&#8217;est pas importante car l&#8217;&#233;cart type est de l&#8217;ordre de (6.9)mm,
les distances mesur&#233;es ne v&#233;rifient pas une distribution normale.
</p>
<p>7. Loi normale : 68% de la population se trouve entre &#181;&#8722;&#963; et &#181;+&#963;, 95% de la population se trouve entre &#181;&#8722; 2 &#8727;&#963;
et &#181;+ 2 &#8727;&#963;,99.7% de la population se trouve entre &#181;&#8722; 3 &#8727;&#963; et &#181;+ 3 &#8727;&#963;
</p>
<p>228</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Pointages Par la t&#234;te La m&#234;me formule 4.3.1 a &#233;t&#233; appliqu&#233;e sur les s&#233;quences de la figure
(8).
</p>
<p>FIGURE 8 &#8211; a- Localisation d&#8217;une entit&#233; - X, b- cr&#233;ation d&#8217;une entit&#233; X, c- cr&#233;ation et pointage non
manuel vers X
</p>
<p>TABLE 3 &#8211; Mesure de la distance entre la droite portant l&#8217;orientation de la t&#234;te et la position de la
main dominante
</p>
<p>Figure 8a Figure 8b Figure 8c
Moyenne de la distance (mm) 168,1 221,6 106,1
Ecart-type de la distance (mm) 8, 2 2, 7 2,1
</p>
<p>&#8211; La distance moyenne 168, 1 mm est la distance qui s&#233;pare la droite portant l&#8217;orientation de la
t&#234;te (voir 8c) et la position de la main dominante illustr&#233;e dans (8a).
</p>
<p>&#8211; La distance moyenne 221, 6 mm est la distance qui s&#233;pare la droite portant l&#8217;orientation de la
t&#234;te (voir 8c) et la position de la main dominante illustr&#233;e dans (8b).
</p>
<p>&#8211; La distance moyenne 106, 1 mm est la distance qui s&#233;pare la droite portant l&#8217;orientation de la
t&#234;te et la position de la main dominante illustr&#233;es dans (8c).
</p>
<p>Dans le paragraphe 4.4.1, nous avons mesur&#233; la distance qui s&#233;pare la position de la main domi-
nante &#224; deux instants diff&#233;rents, lorsque la main r&#233;alise un signe spatiali&#233; et lorsqu&#8217;elle le pointe.
Dans ce paragraphe, nous avons appliqu&#233; la m&#234;me m&#233;thode en rempla&#231;ant le r&#233;f&#233;rencement
manuel par le r&#233;f&#233;rencement r&#233;alis&#233; par la t&#234;te (comme l&#8217;illustre la figure la figure 9c). Nous
avons calcul&#233; non pas la distance entre deux positions de la main mais la distance entre une
position de la main et la droite qui porte l&#8217;orientation de la t&#234;te. D&#8217;apr&#232;s les mesures du tableau
3, n&#8217;appartiennent pas &#224; une m&#234;me loi de distribution normale. Bien qu&#8217;il s&#8217;agisse de la m&#234;me
entit&#233;, les mesures de distances (T&#234;te-main) varient diff&#233;remment pour chaque cas.
</p>
<p>Pointages par le regard La m&#234;me formule 4.3.1 a &#233;t&#233; appliqu&#233;e sur les s&#233;quences 10.
</p>
<p>&#8211; La distance moyenne 545, 3 mm est la distance qui s&#233;pare la position de la cible du regard et
la position de la main dominante dans les figures (10a) et (10b) .
</p>
<p>229</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FIGURE 9 &#8211; Posture de la t&#234;te et position de la main dominante qui r&#233;alisent la localisation d&#8217;une
m&#234;me entit&#233;
</p>
<p>Position de la cible 
du regard 
</p>
<p>reconstruite par le 
syst&#232;me de suivi 
</p>
<p>du regard
</p>
<p>Position de la main 
dominante
</p>
<p>Position de la cible 
du regard
</p>
<p>FIGURE 10 &#8211; a- Localisation d&#8217;une entit&#233; (Y) par le regard et par la main dominante , b- Localisation
de la m&#234;me entit&#233; par le regard
</p>
<p>TABLE 4 &#8211; Mesure de la distance entre la position de la cible du regard et la position de la main
dominante
</p>
<p>Moyenne des distances (mm) 545, 3
Ecart-type des distance (mm) 9, 1
</p>
<p>230</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4.5 Retour sur r&#233;sultats
</p>
<p>Pointages manuels D&#8217;apr&#232;s les mesures de distances r&#233;alis&#233;es sur une session de capture, les
trois pointages manuels qui pointent vers une m&#234;me zone spatiale (6b, c et d) pr&#233;sentent un
m&#234;me comportement spatial par rapport &#224; la position de l&#8217;entit&#233; cr&#233;&#233;e dans l&#8217;espace de signation
(6 a). Nous en d&#233;duisons que la position spatiale de la zone occup&#233;e par l&#8217;entit&#233; [S&#8217;ASSOIR]
per&#231;ue par le signeur est conserv&#233;e au cours des trois pointages manuels. Les s&#233;quences de
pointages manuels illustr&#233;s dans (7 b et d) font r&#233;f&#233;rence &#224; deux entit&#233;s diff&#233;rentes (X) et (Y)
respectivement. Les m&#234;mes mesures de distance indiquent une &#233;volution diff&#233;rente de la distance.
Ceci est en relation avec l&#8217;entit&#233; point&#233;e non pas avec la notion de pointage en tant que notion
linguistique qui ne d&#233;pend pas de la cible vers laquelle pointe le signeur.
</p>
<p>Pointages non manuel Les mesures du tableau (3) montrent que les distances entre la droite
portant l&#8217;orientation de la t&#234;te et la position de la main dominante illustr&#233;es dans (8a) et (8b)
ne sont pas similaires. Nous en d&#233;duisons que l&#8217;orientation de la t&#234;te est &#233;troitement li&#233;e &#224;
la position de la main dominante courante pour le signe [S&#8217;ASSOIR]. En d&#8217;autres termes, la
position qu&#8217;occupe l&#8217;entit&#233; [S&#8217;ASSOIR] dans l&#8217;espace telle qu&#8217;elle est per&#231;ue par le signeur n&#8217;est
pas conserv&#233;e lors des deux diff&#233;rents pointages par la t&#234;te. Les mesures du tableau (4) montrent
que la distance entre la mire (cible du regard) et la position de la main dominante garde une
valeur quasi constante ce qui signifie que la position de l&#8217;entit&#233; [S&#8217;ASSOIR] per&#231;ue par le signeur
est la m&#234;me lors des deux pointages distincts par le regard.
</p>
<p>5 Perspectives
</p>
<p>L&#8217;approche que nous avons pr&#233;sent&#233;e concerne l&#8217;analyse de gestes manuels et non manuels
li&#233;s &#224; la localisation d&#8217;entit&#233;s dans l&#8217;espace de signation. Cette approche pourrait apporter des
&#233;l&#233;ments de r&#233;ponses par rapport aux propri&#233;t&#233;s spatiales des entit&#233;s qui occupent l&#8217;espace de
signation au moment du discours. Les premi&#232;res interpr&#233;tations 4.5 des mesures effectu&#233;es sur
une base de donn&#233;es de capture de mouvement r&#233;v&#232;lent que la zone occup&#233;e par une entit&#233;
telle qu&#8217;elle est per&#231;ue chez le signeur ne change pas au cours d&#8217;un discours continu. Nous avons
abouti &#224; cette conclusion gr&#226;ce aux positions relatives de la main dominante, de la cible du
regard et de l&#8217;orientation de la t&#234;te. Cela veut dire que l&#8217;espace de signation dans sa globalit&#233; ne
subit pas de changement (translation ou rotation) au cours des s&#233;quences d&#8217;enregistrements sur
lesquelles nous avons effectu&#233; nos mesures. Ceci &#233;carte l&#8217;hypoth&#232;se d&#8217;un &#233;ventuel changement
de position de l&#8217;espace de signation au cours d&#8217;un discours continu et apporte des pr&#233;cisions
pour sa repr&#233;sentation informatique. Toutefois, il serait int&#233;ressant d&#8217;analyser l&#8217;&#233;volution de l&#8217;&#233;tat
de l&#8217;espace de signation lors des pseudo-transferts de r&#244;le 8 o&#249; l&#8217;hypoth&#232;se de changement de
positions de l&#8217;espace de signation est fortement appuy&#233;e.
</p>
<p>8. ou semi-transfert personnel : Un court moment o&#249; le signeur &#233;met une action (verbe) et devient le personnage qui
fait l&#8217;action &#224; travers sa posture et son expression faciale(Cuxac, 2000)
</p>
<p>231</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>6 Conclusion
</p>
<p>L&#8217;approche propos&#233;e se base sur l&#8217;interpr&#233;tation linguistique d&#8217;un discours en langue des signes
et exploite les donn&#233;es tridimensionnelles fournies afin d&#8217;extraire des comportements r&#233;p&#233;titifs
des gestes li&#233;s &#224; l&#8217;espace de signation. Cette analyse prend en compte la multi-lin&#233;arit&#233; des gestes
effectu&#233;s &#224; la fois par la main dominante et la t&#234;te. Le regard contribue par des fixations vers
des emplacements sp&#233;cifiques de l&#8217;espace de signation. Cependant, nous nous sommes focalis&#233;s
seulement sur l&#8217;analyse de deux fonctions linguistiques, celles de cr&#233;ation et de r&#233;f&#233;rencement
d&#8217;entit&#233;s dans l&#8217;espace de signation.
</p>
<p>L&#8217;analyse que nous avons men&#233;e visait &#224; apporter des pr&#233;cisions sur l&#8217;&#233;volution de la structure
de l&#8217;espace de signation. En particulier, nous avons pu d&#233;duire que le signeur per&#231;oit les zones
occup&#233;es par des entit&#233;s comme &#233;tant des zones fixes. Par cons&#233;quent, l&#8217;espace de signation reste
fig&#233; au cours de pointages manuels et de pointages par le regard.
</p>
<p>Remerciements
</p>
<p>Le corpus 3D a &#233;t&#233; r&#233;alis&#233; dans Le cadre du projet (Maqspat) qui porte sur le th&#232;me du marquage
spatial dans les langues des signes fran&#231;aise, am&#233;ricaine et qu&#233;b&#233;coise. Le projet est soutenu par
le CRSH, dans le cadre d&#8217;un partenariat strat&#233;gique soutenu par le CFQCU. Le corpus d&#8217;illustration
(1a et c) a &#233;t&#233; r&#233;alis&#233; en interne par Juliette Dalle, assistante ing&#233;nieur de l&#8217;&#233;quipe Traitement et
compr&#233;hension de d&#8217;Image de l&#8217;Institut de Recherche en Informatique de Toulouse (IRIT).
</p>
<p>R&#233;f&#233;rences
</p>
<p>BEN MLOUKA, M., ALBARET-LEFEBVRE, F., DALLE, J. et DALLE, P. (2010). Annotation automatique
d&#8217;une vid&#233;o en lsf &#224; partir de donn&#233;es de capture de mouvement. In TALS, Montr&#233;al, Canada.
BRAFFORT, A. (1996). Reconnaissance et compr&#233;hension de gestes, application &#224; la langue des
signes. Th&#232;se de doctorat, Universit&#233; de Paris XI.
COSNIER, J. (1997). S&#233;miotique des gestes communicatifs. Nouveaux actes s&#233;miotiques, 52:7&#8211;28.
CUXAC, C. (2000). Faits de Langues - La langue des signes fran&#231;aise (LSF) - Les voies de l&#8217;iconicit&#233;.
Faits Des Langues : Ophrys, Paris.
FUSELLIER-SOUZA, I. (2004). S&#233;miogen&#232;se des langues des signes : &#233;tude de langues des signes
primaires (LSP) pratiqu&#233;es par des sourds br&#233;siliens. Th&#232;se de doctorat, Universit&#233; Paris 8.
LENSEIGNE, B. (2005). Mod&#233;lisation de l&#8217;espace discursif pour l&#8217;analyse de la langue des signes.
In TALN, Dourdan.
LU, P. et HUENERFAUTH, M. (2011). Synthesizing American Sign Language Spatially Inflected
Verbs from Motion-Capture Data. In SLTAT, Dundee, UK.
MONTREDON, J. (2001). De la gestualit&#233; co-verbale, dimensions cognitives et symboliques. In
PRESSES UNIV. LIMOGES, ., &#233;diteur : S&#233;mio, pages 15&#8211;18.
THOMPSON, R., EMMOREY, K. et KLUENDER, R. (2006). The Relationship between Eye Gaze and
Verb Agreement in American Sign Language : An Eye-tracking Study. Natural Language &amp;
Linguistic Theory, 24(2):571&#8211;604.
</p>
<p>232</p>

</div></div>
</body></html>