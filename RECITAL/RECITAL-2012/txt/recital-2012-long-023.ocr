Analyse automatique de discours en langue des signes :
Représentation et traitement de l’espace de signation

Monia Ben Mlouka
IRIT —TCI , UMR5505, 31000 Toulouse
mloukatﬁirit . fr

RESUME
En langue des signes, l’espace est utilisé pour localiser et faire référence a certaines entités dont
l’emplacement est important pour la compréhension du sens. Dans cet article, nous proposons
une représentation informatique de l’espace de signation et les fonctions de création et d’accés
associées, afin d’analyser les gestes manuels et non manuels qui contribuent ‘a la localisation
et au référencement des signes et de matérialiser leur effet. Nous proposons une approche
bi-directionnelle qui se base sur l’analyse de données de capture de mouvement de discours en
langue des signes dans le but de caractériser les événements de localisation et de référencement.

ABSTRACT
Automatic Analysis of Discourse in Sign Language : Signing Space Representation and
Processing

In sign language, signing space is used to locate and refer to entities whose locations are important
for understanding the meaning. In this paper, we propose a computer-based representation of
the signing space and their associated functions. It aims to analyze manual and non-manual
gestures, that contribute to locating and referencing signs, and to make real their effect. For that,
we propose an approach based on the analysis of motion capture data of entities’ assignment and
activation events in the signing space.

MOTS-CLES : Langue des signes, Espace de signation, gestes de pointage, capture de mouvement,
suivi du regard.

KEYWORDS: Sign language, Signing space, pointing gestures, motion capture, gaze tracker.

Actes de la con_fe'rence conjointe JEP-TALN-RECITAL 2012, volume 3: RECITAL, pages 219-232,
Grenoble, 4 au 8 juin 2012. ©2012 ATAI.A 8: AFCP

219

1 Introduction

I.’étude de l’aspect gestuel dans les langues naturelles fait l’objet de plusieurs travaux. Plusieurs
études ont porté sur l’analyse des gestes manuels et non manuels en situation de dialogue.
L’une d’entre elles a apporté une classiﬁcation foncﬁonnelle des gestes manuels et non manuels
(Cosnier, 1997). Celle de (Montredon, 2001) établit une relation entre les caractéristiques spatio-
temporelles des gestes manuels et leurs roles dans l’énoncé. En langue des signes, le canal étant
visuo-gestuel, l’analyse d’énoncés est en premier lieu une analyse d’un signal visuel. Elle peut
étre entiérement réalisée a ce seul niveau ou étre complétée par des analyses du geste 3D si l’on
sait reconsuuire cette information a partir de données visuelles.

Nous proposons dans cette étude une représentation informatique de l’espace de signation comme
étant un élément important pour la compréhension d’un discours dans la langue des signes. Pour
cela, nous introduirons, en premier lieu, l’espace de signation et les gestes qui contribuent ‘a la
localisation de signes. Dans un second lieu, nous décrirons le corpus sur lequel se base notre
analyse. Par la suite, nous présenterons notre approche d’analyse géométrique 3D suivie de
quelques résultats.

2 L’espace de signation

L’espace de signation est déﬁni comme étant l’espace qui entoure le signeur et qui est atteignable
par ses deux mains. L’espace de signation sert a localiser les entités ou notions associées a certains
signes, éventuellement a spéciﬁer leurs propriétés de forme et de taille et a établir des relations
spatiales entre les entités (Cuxac, 2000).

2.1 Evénements liés :31 l’espace de signation

Notre représentation informatique de l’espace de signation étant un graphe d’entités spatialisées
dans un espace 3D. Elle dispose des fonctions classiques de création, de modiﬁcation, de sup-
pression et d’acces. Chacune de ces fonctions est déclenchée par un événement survenu dans
l’espace de signation. L’image (la) est un exemple d’un signe [TABLE] qui occupe une zone de
l’espace. L’image (lb) illustre une association spatiale d’une action [S’ASSOIR]. L’image (lc) est
un exemple d’un pointage manuel vers une zone particuliere de l’entité [TABLE]. La zone est
spéciﬁée par la direction de la main dominante.

2.2 Aspect multilinéaire

L’étude de (Fusellier-Souza, 2004) s’est intéressée aux gestes manuels et non manuels qui contri-
buent aux changements d’états de l’espace de signation. Une étude similaire, celle de (Thompson
et aL, 2006) a porté sur la relation entre le regard et la réalisation d’actions spatialisées. Les deux
études soulignent l’aspect multilinéaire dans la réalisation de gestes. Dans cette étude nous nous
focaliserons sur les gestes de création et de référencement d’entités dans l’espace de signation.
Comme nous l’avons cité précédemment, les gestes sont manuels et non manuels que ce soit pour
les événements de création ou de référencement. les gestes manuels de création d’entités dans

220

 

FIGURE 1 — a : Un objet spatialisé [TABLE], b : Une action spatialisée [S’ASSOIR], c : Un pointage
vers une partie de la portion de l’espace occupé par le signe [TABLE]

1’espace de signation représentent les signes effectués a un emplacement spéciﬁque ou les signes
localisés sur le corps puis situés dans l’espace de signation par un pointage :

— L’orientation du regard et 1’inc1inaison de la téte permettent d’associer une zone de 1’espace de
signation au signe en cours de réalisation.

— Les gestes manuels peuvent associer une forme a l’entité et préciser la taille qu’elle occupe
dans l’espace.

Les images (1a), (1b) et (1c) représentent des exemples de realisation de l’aspect de multi-

linéarité :

— Dans (1a) et (1c), on observe que le regard du signeur est orienté vers la méme zone d’espace
occupée par l’entité.

— On observe également une posture particuliere dans (1b) qui se manifeste par une inclinaison
de la téte vers l’emplacen1ent de la main qui effectue le signe [S’ASSOIR].

— Dans (1c), on ne peut pas determiner si le regard ﬁxe cet endroit de l’espace car la téte du
signeur est baissée mais on peut le déduire grace a la position de la téte légerement inclinée
vers le bas.

Par ces exemples, nous avons illustré l’importance de l’aspect multilinéaire de gestes qui contri-

buent aux fonctions de création, de référencement de l’entité [S’ASSEOIR] : ﬁxation du regard,

gestes manuels et mouvements de la téte. Dans la littérature, peu de travaux ont porté sur la

représentation informatique de l’espace de signation. Nous citons l’étude de (Lenseigne, 2005)

qui a porté sur la représentation informatique de la structure de l’espace de signation dans un

discours en langue des signes francaise. L’aspect gestuel a été pris en compte dans l’étude de

(Braffort, 1996) qui consistait a modéliser les gestes dans les verbes directionnels et déictiques a

partir de données fournies par un gant numérique. (Lu et Huenerfauth, 2011) a développé une

technique qui, a partir de données de capture de mouvement, permet de modéliser les gestes dont
la réalisation est inﬂuencée par la localisation spatiale des entités dans l’espace de signation.Dans
cette derniere étude, (Lu et Huenerfauth, 2011) s’est intéressé aux gestes exprimant des verbes.

Notre travail s’inscrit dans le méme cadre et s’intéresse a 1’aspect multilinéaire (combinaisons de

gestes manuels et non manuels) et se base a la fois sur des données tri-dimensionnelles de capture

de mouvement et sur des données de suivi du regard synchronisées avec les enregistrements
videos.

221

3 Acquisition du Corpus

Le corpus sur lequel nous avons appliqué notre approche d’analyse a été enregistré dans le
cadre du partenariat franco-québécois (Marqspat) 1. Les sessions de capture ont été réalisées
avec un systeme de capture de mouvement (VICON) 2, une camera video pour filmer le cadre
complet de la scene et un systeme de capture du regard CFaceLab) 3 . Lors de l’enregistrement,
le signeur commence et terrnine sa production par un "clap" manuel qui permettra d’effectuer
ultérieurement une synchronisation de la vidéo et des données de la capture de mouvement et
commence a répondre a des questions sous forme de vidéos projetées. Les questions concernent
des détails a propos de scénes enregistrées préalablement. Les données de capture de mouvement
et celles de suivi du regard feront l’objet d’une analyse automatique (Ben Mlouka et al., 2010)
dont on détaillera les étapes dans la section suivante.

4 Annotations et représentations informatiques

Nous avons adopté une méthode composée de plusieurs étapes :

4. 1 Grille d’annotation

L’annotation4 du corpus a été réalisée et vériﬁée par plusieurs annotateurs québécois de compé-
tences variées en Langue des Signes Francaise, Québécoise et Américaine. La grille d’annotation
se compose de :

Une annotation en gloses Les annotateurs ont transcrit les signes effectués par les deux mains
et qui peuvent avoir on non une association spatiale spécifique. La capture d’écran de la grille
d’annotation (2) montre un exemple de valeurs attribuées aux pistes : la main droite (MD) :
[S’ASSEOIR], la piste (MG) transcrit les signes effectués par la main gauche, la piste (2M) inclut
ceux a deux mains.

Une annotation de gestes et de signes en liaison avec1’espace Les gestes manuels et non
manuels transcrits sont nécessairement associés a une zone de l’espace de signation. A chaque
geste ou signe spatialisé, on associe une étiquette (ex. x, y, z, etc.) pour étiqueter la zone a
laquelle est associé ce geste ou ce signe. Dans l’exemple (2), la piste (MC) mentionne le nom de
la zone associée au signe [S’ASSEOIR], cela veut dire qu’une zone est occupée par une entité “y“
dont le signiﬁant est l’action [S’ASSEOIR]. Le reste des pistes visibles inclut les noms d’entités
spatiales vers lesquelles un composant corporel fait référence :

1. Lien vers le site web du projet : http ://www.irit.fr/marqspat/index.htrn1

2. Il s’agit d’un systéme de capture composé de 8 caméras infrarouges qui enregistrent les positions 3D de marqueurs
réﬂéchissants posés sur les membres du signeur

3. Un systérne non invasif composé de deux caméras et d’un érnetteur infra-rouge. I1 fournit sous forme de données
3D, Porientation du regard. Une camera de scene qui perrnet de synchroniser les données vidéos et données 3D

4. Ces annotations manuelles ont été effectuées par 1’équipe "Groupe de recherche sur la langue des signes québécoise
et le bilinguisme sourd"quipi1ote1e projet (Marqspat)

222

(10.03 03.075

411 14 N -H > » um»: ill

 
       

n
00:03 0:

MD!h~MARCH CL: bvS'ASSE HUM gesu
l75|

MG

[5]

ma F~%
IZSI

MR

lk’

 -|’—|l’—?| la

1500 00 00-03-05 500

 

FIGURE 2 — Un exemple de valeurs d’annotation

1. La piste (MR), représente les entités ciblées par les pointages manuels
2. La piste (TR) celle des entités référencées par la téte.

3. La piste (RM) celle de la direction du regard ou on nomme l’entité sur laquelle se focalise
le regard.

Dans l’image (3a), la zone de l’espace occupée par le signe [S’ASSOIR] est étiquetée x. L’image
(3b) illustre un exemple ou la main dominante effectue le signe [FILLE], le regard et la téte se
dirigent vers une méme cible (x)

La lecture transversale de la grille d’annotation est un moyen qui permet de grouper les mémes
étiquettes d’entités (x dans les deux exemples précédents). Une interprétation simple de cette
lecture transversale : Le signeur associe une zone de l’espace a une entité (x) grace a l’orientation
du regard et de la téte et associe le référent [FILLE] a la zone (x) grace au signe effectué pres de
la téte.

Cette mise en correspondance entre les gestes et leurs interpretations sera généralisée grace
a l’extraction et la synchronisation automatique des annotations manuelles avec les données
de capture de mouvement qui leurs correspondent dans le but de mettre en place des modeles
géométriques propres aux gestes qui contribuent a la création ou au référencement d’une méme
entité.

223

    

mum mt Slluﬂmn mum u1:—nn

nn .1; HY 3.. 5...,“ nn .1,‘
IJIIIIIIEIIIIIIIIIIIIIIJI + mmmﬁnu
.

  
  

*n‘2«‘aéa‘aia‘ ‘ ‘a‘a‘a‘2«‘vs‘a‘a‘a‘ ‘ ‘o‘o‘u‘2‘va‘a‘aia‘ ‘ ‘a‘a‘a‘2ﬁa‘a‘a‘ ‘ ‘a‘a‘a‘2‘v2‘«€aia‘ 1‘ dub‘ ‘ ‘.Ju‘n‘2‘5g‘u‘u};‘ ‘ ‘a‘a‘a‘3.‘m‘a‘aL7‘ ‘ ‘a‘a‘a‘:‘m‘.£a;a‘ ‘ ‘a‘a‘a‘:.‘u‘.£aL7‘ ‘ ‘a‘a‘a5‘m‘
MD M0 3”“ “N MD "L3:-MA CL3n-S'A am nus CL3b- CL
""7 rm
MC  mx x zv w‘

125} Mg,

MR

.5, 2 2 Mg

~~a%  e W 2 2 2
"" um

YR ‘

m :1 ml

FIGURE 3 — Une lecture transversale d’annotation d’un événement de référencement : a— Locali-
sation manuelle et non manuelle (regard) du signe [S’ASSOIR], b— Localisation non manuelle
(téte et regard) du signe [FILLE] car celui-ci se réalise par la main dominante :1 un emplacement
spéciﬁque (pres de la téte)

4.2 Représentation géométrique

Comme nous l’avons mentionné dans 4.1, les articulateurs représentées sont la main dominante,
la téte et le regard.

Mesure de l’enveloppe de la main La main dominante est représentée par une sphere de
centre milieu des bases de l’index et celui de l’auriculaire, de rayon la longueur du majeur(voir
ﬁgure 4).

 

FIGURE 4 — Représentation géométrique de la main

224

La cible du regard La cible du regard est représentée par un point dont les coordonnées sont
fournies 5 par le systeme de suivi du regard. Il fournit la position 3D de la cible du regard a un
instant donné, exprimée dans le méme repere que celui des positions des marqueurs de capture
de mouvemente. Nous avons noté que le taux de points de vergence reconstruits par (FaceLab)
est relativement faible par rapport aux données enregistrées. Ceci est dﬁ au fait que a plusieurs
moments, les directions du regard calculées ne sont pas convergentes et par conséquent ne
permettent pas de calculer les positions des points de vergence.

RHEA

 

FORH LHEA

 

Orientation de la téte l

Orientation de la téle

FIGURE 5 — Representation géométrique de l’orientation de la téte (a gauche : vue de face, a
droite : vue de dessus)

Mesure de l’orientation de la téte L’orientation de la téte est mesurée comme étant la normale
a la droite passant par les marqueurs “RHEA" et “LHEA" et passant par le marqueur “FORH" (Voir
ﬁgure 5). Le vecteur F1’ est le vecteur normal au plan formé par les marqueurs : RHEA, LHEA et
TOPH. La ﬁgure (5) indique la position de ces marqueurs en vue de dessus. L’équation du plan
étant :

P:a.x+b.y+c.z+d=O (1)

Le vecteur normal est le résultat du produit vectoriel suivant :
H = A7; AA? (2)
Tels que : A, B et C représentent la position géométriques des marqueurs RHEA, TOPH et LHEA

respectivement. Dans la suite nous allons caractériser l’aspect multi-composant entre les différents
modeles géométriques.

S. (FaceLab) fournit une liste de mesures sur : la position des globes oculaires, les pupilles, le degre' de fermeture
des yeux, l’angle d’orientation du regard, etc. Dans ce travail, nous nous sommes intéressés aux positions de points de
vergence seulement

6. Nous avons fusionné les données foumies par le systéme de capture de mouvement et celles foumies par (FaceLab)
dans un meme repere

225

4.3 Mesures et relations

On se propose dans cette phase de prendre en compte 1e sens comme cela a été détaﬂlé dans 4.1
et d’extraire les positions géométriques correspondantes de chaque composant corporel. Par la
suite nous caractériserons 1a convergence des composants corporels comme étant1’intersection
simultanée ou différée des représentations géométriques de 1’orientation de la téte, la position
de la main dominante et la cible du regard. La notion d’intersection géométrique inclut deux
différents composants corporels, on parle ainsi d’une relation entre composants. On qualifie
1’intersection différée de deux positions géométriques d’un méme composant de relation intra-
composant.

4.3.1 Relations entre composants

Mesures de1’intersection orientation téte et main dominante On se propose de mesurer la
distance d entre la droite portant1’orientation de la téte D et le centre de la main S :

_ llﬁ/\S1\7In||
Man

(3)

Tels que M est un point appartenant a la droite D. Cette méme formule s’app1ique également
pour la mesure de 1’intersection entre la cible ﬁxée ou pointée et1’orientation de la téte.

Mesures de 1’intersection cible du regard et main dominante On se propose de mesurer 1a
distance d entre le point qui représente la cible ﬁxée par le regard et P et le centre de la main S :

d = t/(xc — x,,)2 +(}’c —y,,)2 +(Zc —z,,)2 (4)

Tels que C est le centre de la main dominante et p et le point cible du regard. Cette formule
s’app1ique également pour la mesure de 1’intersection entre la cible ﬁxée et espace référencé par
la main dominante.

4.3.2 Relations intra-composant

Mesures de la convergence des espaces occupées par une seule entité On se propose de
mesurer la distance d entre deux spheres représentatives de la position de la main dominante a
deux instants distincts :

d = \/(XC1 ‘ xC2)2 + (.Yc1 — }’c2)2 4' (ZC1 —Zc2)2 (5)

Tels que C1 et C2 sont les centres des spheres qui représentent la main dominante a deux instants
différents. Cette formule s’app1ique également pour la mesure de convergence entre espace
occupé et espace référencé par la main dominante.

Mesure de la variation de1’orientation de la téte Dans le but de mesurer 1a variation de cette
orientation au cours d’un événement de référencement, nous nous proposons de mesurer1’ang1e

226

formé par deux vecteurs porteurs des droites D1 et D2 d’orientation de la téte correspondante a
deux instants distincts.

L’angle 9 est mesuré selon cette formule :

cos(9)L (6)
||T71||-||Tl'§||

Tels que Ii] et rig sont les vecteurs directeurs de D1 et D2 respectivement dont les coefﬁcients
sont calculés selon la formule énoncée en (4.2).

4.4 Premiers résultats
4.4.1 Objectifs de l’analyse

On se propose d’apporter des éléments de réponses par rapport a l’état de l’espace de signation.
En particulier, on veut déterminer si l’espace de signation, tel qu’il est percu par le signeur,
subit des transformations géométriques (translation et/ou rotation) au cours des événements
de référencement. Pour cela, on étudiera la relation entre l’emplacen1ent de l’entité qui occupe
une partie de l’espace de signation et la position de la main dominante du signeur quand celui-ci
pointe vers cette méme entité.

Pointages manuel vers une méme entité Comme cela a été détaillé dans 4.3.2, nous avons
mesuré la distance qui sépare deux positions de la main dominante lors de la réalisation d’un
signe spatialisé et lors d’un pointage vers cette méme entité 6.

 

FIGURE 6 — a— Création d’une entité — X, b, c et d— Pointages vers X

Figure 6b Figure 6c Figure 6d
Moyenne de la distance (mm) 685,6 611, 5 569, 7
Ecart—type de la distance (mm) 3,2 1,6 25,2

TABLE 1 — Mesure de la distance qui sépare deux positions de la main dominante lors de la
réalisation d’un signe spatialisé et lors d’un pointage vers cette méme entité

227

Les valeurs moyennes des distances du tableau 1 sont signiﬁcatives car elles vériﬁent la regle
68-95—99.7 de la loi normale 7

u—3>s<a<99.7%>s<N<u+3>s<sigma (7)
u—2*o'<95%>kN<[L+2*sigma (8)
11-0 <68%>s<N <u+sigma (9)

Tels que : 11 est la valeur moyenne et 0' est l’écart—type de l’ensemble des valeurs de distance N

De ce fait, on déduit que les distance entre positions de la main dominante illustrées dans les
images (6b, c et d) et celle de l’image (6a) peuvent étre générées par une méme loi de distribution
normale de moyenne : 622,3 et d’écart—type :58, 7 (en mm). Cela veut dire que dans ces trois
exemples (Création-Référencement), les distances qui séparent deux positions différentes de la
main dominante (la premiere en phase de création et la deuxiéme en phase de référencement)
ne sont pas exactement les mémes mais varient autour d’une méme moyenne.

Pointages manuels vers deux entités différentes La méme formule 4.3.2 a été appliquée sur
les séquences 7.

 

FIGURE 7 — a- Création d’une entité - X, b- Pointage vers X, c- Création d’une entité - Y, d- Pointage
vers Y

TABLE 2 — Mesure de la distance qui sépare deux positions de la main dominante lors de la
réalisation d’un signe spatialisé et lors d’un pointage vers une méme entité

Figure 7b Figure 7d
Moyenne de la distance (mm) 685,6 194,3
Ecart—type de la distance (mm) 3, 2 10,6

Les valeurs moyennes des distances du tableau 2 ne vériﬁent pas la régle 68—95—99.7.
Bien que la Variation des distances n’est pas importante car l’écart type est de l’ordre de (6.9)mm,
les distances mesurées ne vériﬁent pas une distribution normale.

7. Loi normale : 68% de la population se trouve entre M — 0 et M + 0, 95% de la population se trouve entre M — 2 * 0
et )1 + 2 >9: c7,99.7% de la population se trouve entre M — 3 >s= (7 et )1 + 3 >9: 0

228

Pointages Par la téte La méme formule 4.3.1 a été appliquée sur les séquences de la ﬁgure

(8).

 

FIGURE 8 — a- Localisation d’une entité - X, b- création d’une entité X, c- création et pointage non
manuel vers X

TABLE 3 — Mesure de la distance entre la droite portant 1’orientation de la téte et la position de la
main dominante

Figure 8a Figure 8b Figure 8c
Moyenne de la distance (mm) 168, 1 221, 6 106, 1
Ecart—type de la distance (mm) 8, 2 2, 7 2,1

— La distance moyenne 168, 1 mm est la distance qui sépare la droite portant 1’orientation de la
téte (Voir 8c) et la position de la main dominante illustrée dans (8a).

— La distance moyenne 221, 6 mm est la distance qui sépare la droite portant 1’orientation de la
téte (Voir 8c) et la position de la main dominante illustrée dans (Sb).

— La distance moyenne 106, 1 mm est la distance qui sépare la droite portant 1’orientation de la
téte et la position de la main dominante illustrées dans (Sc).

Dans le paragraphe 4.4.1, nous avons mesuré la distance qui sépare la position de la main domi-
nante a deux instants différents, lorsque la main réalise un signe spatialié et lorsqu’e]1e 1e pointe.
Dans ce paragraphe, nous avons applique la méme méthode en remplacant 1e référencement
manuel par le référencement réalise par la téte (comme 1’i11ustre la ﬁgure la ﬁgure 9c). Nous
avons calcule non pas la distance entre deux positions de la main mais la distance entre une
position de la main et la droite qui porte 1’orientation de la téte. D’aprés les mesures du tableau
3, n’appartiennent pas a une méme loi de distribution normale. Bien qu’i1 s’agisse de la méme
entité, les mesures de distances (Téte-main) varient différemment pour chaque cas.

Pointages par le regard La méme formule 4.3.1 a été appliquée sur les séquences 10.

— La distance moyenne 545, 3 mm est la distance qui sépare la position de la cible du regard et
la position de la main dominante dans les ﬁgures (10a) et (10b) .

229

an E2 iv am

 

1{a‘a‘2‘sa‘a‘a‘a‘ ‘ ‘a‘a‘o‘2‘se‘u‘n ‘”a‘a‘a‘:.‘aa‘a‘a‘a‘ ‘ ‘a‘a‘a‘:‘a{a‘aia‘ ‘ ‘dal
MC W x zv
an

M
m

 

FIGURE 9 — Posture de la téte et position de la main dominante qui réalisent la localisation d’une
niéme entité

‘ ‘ Position de la cible
\ Position de la cible du regard
du regard
reoonstruite par la
systéme de suivi
du regard

Position de la main
dominante

   

FIGURE 10 — a- Localisation d’une entité (Y) par le regard et par la main dominante , b- Localisation
de la niéme entité par le regard

TABLE 4 — Mesure de la distance entre la position de la cible du regard et la position de la main
dominante

Moyenne des distances (mm) 545,3
Ecart—type des distance (mm) 9, 1

230

4.5 Retour sur résultats

Pointages manuels D’apres les mesures de distances réalisées sur une session de capture, les
trois pointages manuels qui pointent vers une méme zone spatiale (6b, c et d) présentent un
méme comportement spatial par rapport a la position de l’entité créée dans l’espace de signation
(6 a). Nous en déduisons que la position spatiale de la zone occupée par l’entité [S’ASSOIR]
percue par le signeur est conservée au cours des trois pointages manuels. Les séquences de
pointages manuels illustrés dans (7 b et d) font référence a deux entités différentes (X) et (Y)

respectivement. Les mémes mesures de distance indiquent une évolution différente de la distance.

Ceci est en relation avec l’entité pointée non pas avec la notion de pointage en tant que notion
linguistique qui ne dépend pas de la cible vers laquelle pointe le signeur.

Pointages non manuel Les mesures du tableau (3) montrent que les distances entre la droite
portant l’orientation de la téte et la position de la main dominante illustrées dans (8a) et (8b)
ne sont pas similaires. Nous en déduisons que l’orientation de la téte est étroitement liée a
la position de la main dominante courante pour le signe [S’ASSOIR]. En d’autres termes, la
position qu’occupe l’entité [S’ASSOIR] dans l’espace telle qu’elle est percue par le signeur n’est
pas conservée lors des deux différents pointages par la téte. Les mesures du tableau (4) montrent
que la distance entre la mire (cible du regard) et la position de la main dominante garde une
valeur quasi constante ce qui signiﬁe que la position de l’entité [S’ASSOIR] pergue par le signeur
est la méme lors des deux pointages distincts par le regard.

5 Perspectives

L’approche que nous avons présentée concerne l’analyse de gestes manuels et non manuels
liés ‘a la localisation d’entités dans l’espace de signation. Cette approche pourrait apporter des
éléments de réponses par rapport aux propriétés spatiales des entités qui occupent l’espace de
signation au moment du discours. Les premieres interprétations 4.5 des mesures effectuées sur
une base de données de capture de mouvement révelent que la zone occupée par une entité
telle qu’elle est pergue chez le signeur ne change pas au cours d’un discours continu. Nous avons
abouti ‘a cette conclusion grace aux positions relatives de la main dominante, de la cible du
regard et de l’orientation de la téte. Cela veut dire que l’espace de signation dans sa globalité ne
subit pas de changement (translation ou rotation) au cours des séquences d’enregistrements sur
lesquelles nous avons effectué nos mesures. Ceci écarte l’hypothese d’un éventuel changement
de position de l’espace de signation au cours d’un discours continu et apporte des précisions
pour sa représentation informatique. Toutefois, il serait intéressant d’ana1yserl’évolution de l’état
de l’espace de signation lors des pseudo-transferts de role 8 o1‘1l’hypoth<‘=.se de changement de
positions de l’espace de signation est fortement appuyée.

8. ou semi-transfett personnel : Un court moment o1‘.1 le signeur émet une action (verbe) et devient le personnage qui
fait1’ac1ion £1 travers sa posture et son expression faciale(Cuxac, 2000)

231

6 Conclusion

L’approche proposée se base sur l’interprétation linguistique d’un discours en langue des signes
et exploite les données tridimensionnelles fournies aﬁn d’extraire des comportements répétitifs
des gestes liés a l’espace de signation. Cette analyse prend en compte la multi-linéarité des gestes
effectués ‘a la fois par la main dominante et la téte. Le regard contribue par des ﬁxations vers
des emplacements spéciﬁques de l’espace de signation. Cependant, nous nous sommes focalisés
seulement sur l’analyse de deux fonctions linguistiques, celles de création et de référencement
d’entités dans l’espace de signation.

L’analyse que nous avons menée visait ‘a apporter des précisions sur l’évolution de la structure
de l’espace de signation. En particulier, nous avons pu déduire que le signeur pergoit les zones
occupées par des entités comme étant des zones ﬁxes. Par conséquent, l’espace de signation reste
ﬁgé au cours de pointages manuels et de pointages par le regard.

Remerciements

Le corpus 3D a été réalisé dans Le cadre du projet (Maqspat) qui porte sur le theme du marquage
spatial dans les langues des signes frangaise, américaine et québécoise. Le projet est soutenu par
le CRSH, dans le cadre d’un partenariat stratégique soutenu par le CFQCU. Le corpus d’illustration
(la et c) a été réalisé en interne par Juliette DaJle, assistante ingénieur de l’équipe Traitement et
compréhension de d’Image de 1’Institut de Recherche en Informatique de Toulouse (IRI'I‘).

Références

BEN MLOUKA, M., ALBARET-LEFEBVRE, F., DALLE, J. et DALLE, P. (2010). Annotation automatique
d’une vidéo en lsf a panir de données de capture de mouvement. In TALS, Montréal, Canada.
BRAFFORT, A. (1996). Reconnaissance et comprehension de gestes, application a la langue des
signes. These de doctorat, Université de Paris XI.

COSNIER, J. (1997). Sémiotique des gestes communicatifs. Nouveaux actes sémiotiques, 52:7—28.

CUxAc, C. (2000). Faits de Langues - La langue des signes francaise (LSF) - Les voies de l’iconicite’.
Faits Des Langues : Ophrys, Paris.

FUSELLIER-SOUZA, I. (2004). Sémiogenese des langues des signes : e’tude de langues des signes
primaires (LSP) pratiquées par des sourds brésiliens. These de doctorat, Université Paris 8.
LENSEIGNE, B. (2005). Modélisation de l’espace discursif pour l’analyse de la langue des signes.
In TALN, Dourdan.

LU, P. et HUENERFAUTH, M. (2011). Synthesizing American Sign Language Spatially Inﬂected
Verbs from Motion-Capture Data. In SLTAT, Dundee, UK.

MONTREDON, J. (2001). De la gestualité co-verbale, dimensions cognitives et symboliques. In
PRESSES UNIV. LIMOGES, ., éditeur : Sémio, pages 15-18.

THOMPSON, R., EMMOREY, K. et KLUENDER, R. (2006). The Relationship between Eye Gaze and
Verb Agreement in American Sign Language : An Eye-tracking Study. Natural Language &
Linguistic Theory, 24(2):571—604.

232

