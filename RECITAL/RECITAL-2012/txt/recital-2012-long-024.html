<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>&#201;tat de l&#8217;art : l&#8217;influence du domaine sur la classification de l&#8217;opinion, Dis-moi de quoi tu parles, je te dirai ce que tu penses</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 3: RECITAL, pages 177&#8211;190,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>&#201;tat de l&#8217;art : l&#8217;influence du domaine
sur la classification de l&#8217;opinion
</p>
<p>Dis-moi de quoi tu parles, je te dirai ce que tu penses
</p>
<p>Morgane Marchand1,2
(1) CEA, LIST, Laboratoire Vision et Ing&#233;nierie des Contenus
</p>
<p>Centre Nano-Innov Saclay, 91191 Gif-sur-Yvette Cedex
(2) LIMSI-CNRS, Univ. Paris-Sud
</p>
<p>91403 Orsay Cedex
morgane.marchand@cea.fr
</p>
<p>R&#201;SUM&#201;
L&#8217;int&#233;r&#234;t pour la fouille d&#8217;opinion s&#8217;est d&#233;velopp&#233; en m&#234;me temps que se sont r&#233;pandus les blogs,
forums et autres plate-formes o&#249; les internautes peuvent librement exprimer leur opinion. La tr&#232;s
grande quantit&#233; de donn&#233;es disponibles oblige &#224; avoir recours &#224; des traitements automatiques de
fouille d&#8217;opinion. Cependant, la mani&#232;re dont les gens expriment leur avis change selon ce dont
ils parlent. Les distributions des mots utilis&#233;s sont diff&#233;rentes d&#8217;un domaine &#224; l&#8217;autre. Aussi, il est
tr&#232;s difficile d&#8217;obtenir un classifieur d&#8217;opinion fonctionnant sur tous les domaines. De plus, on ne
peut appliquer sans adaptation sur un domaine cible un classifieur entra&#238;n&#233; sur un domaine
source diff&#233;rent. L&#8217;objet de cet article est de recenser les moyens de r&#233;soudre ce probl&#232;me difficile.
</p>
<p>ABSTRACT
State of the Art : Influence of Domain on Opinion Classification
</p>
<p>The interest in opinion mining has grown concurrently with blogs, forums, and others platforms
where the internauts can freely write about their opinion on every topic. As the amounts of
available data are increasingly huge, the use of automatic methods for opinion mining becomes
imperative. However, sentiment is expressed differently in different domains : words distributions
can indeed differ significantly. An effective global opinion classifier is therefore hard to develop.
Moreover, a classifier trained on a source domain can&#8217;t be used without adaptation on a target
domain. This article aims to describe the state-of-the-art methods used to solve this difficult task.
</p>
<p>MOTS-CL&#201;S : &#201;tat de l&#8217;art, Fouille d&#8217;opinion, Multi-domaines, Cross-domaines.
</p>
<p>KEYWORDS: State of the art, Opinion mining, Multi-domain, Cross-domain.
</p>
<p>177</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1 Introduction
</p>
<p>Savoir ce que les autres pensent est, depuis toujours, une information tr&#232;s importante pour
prendre une d&#233;cision. Nous consultons des critiques de consommateurs avant d&#8217;acheter un
appareil photo, des sondages avant des &#233;lections ou encore dans le domaine professionnel des
lettres de recommandation. Depuis le d&#233;veloppement d&#8217;Internet, de plus en plus de personnes
rendent leurs avis disponibles. Nous avons donc facilement acc&#232;s &#224; un tr&#232;s large corpus d&#8217;opinion
en tout genre.
Les applications possibles de la fouille d&#8217;opinion sont multiples (Pang et Lee, 2008). Elle peut,
par exemple, &#234;tre utilis&#233;e pour agr&#233;ger des critiques, faire des syst&#232;mes de recommandation
ou bien des outils de marketing et de business intelligence. Certains moteurs de recherche
proposent d&#233;j&#224; des applications pour r&#233;sumer les opinions des consommateurs dans des
interfaces d&#233;di&#233;es au shopping (Blair-Goldensohn et al., 2008). L&#8217;id&#233;al serait de pouvoir disposer
de telles fonctionnalit&#233;s pour des recherches d&#8217;ordre g&#233;n&#233;ral.
</p>
<p>La diversit&#233; et la quantit&#233; de ces t&#233;moignages rendent leur traitement manuel long et
co&#251;teux. C&#8217;est pourquoi l&#8217;exploitation automatique de ces donn&#233;es est un enjeu majeur.
</p>
<p>La fouille d&#8217;opinion se compose de plusieurs t&#226;ches, qu&#8217;il est utile ou non de mettre en
&#339;uvre selon les applications vis&#233;es. :
&#8211; d&#233;tection de la pr&#233;sence ou non de l&#8217;opinion ;
&#8211; classification de l&#8217;axiologie de l&#8217;opinion (positif, n&#233;gatif, neutre) ;
&#8211; classification de l&#8217;intensit&#233; de l&#8217;opinion ;
&#8211; identification de l&#8217;objet de l&#8217;opinion (ce sur quoi porte l&#8217;opinion) ;
&#8211; identification de la source de l&#8217;opinion (qui exprime l&#8217;opinion).
L&#8217;analyse de l&#8217;opinion peut se situer au niveau du texte entier, du paragraphe, de la phrase ou
bien du fragment selon les applications envisag&#233;es.
</p>
<p>Dans cet article, nous nous int&#233;resserons uniquement &#224; la t&#226;che de classification de
l&#8217;axiologie de l&#8217;opinion, dont nous donnons un aper&#231;u des probl&#232;mes dans la section 2, de fa&#231;on
g&#233;n&#233;rale et dans le cas particulier des domaines diff&#233;rents. En section 3, nous expliciterons
bri&#232;vement pourquoi les techniques classiques pour la constitution des ressources ou des
classifieurs sont moins efficaces lorsque l&#8217;on change de domaine d&#8217;expression. Nous dresserons
alors, dans la section 4, un &#233;tat de l&#8217;art des recherches actuelles visant &#224; am&#233;liorer les
performances des classifieurs dans ce cas particulier. Dans une derni&#232;re partie, nous &#233;voquerons
les travaux pr&#233;liminaires effectu&#233;s ainsi que les perspectives d&#8217;exploration.
</p>
<p>2 La subjectivit&#233; dans le langage
</p>
<p>2.1 Pr&#233;sentation et d&#233;finition
</p>
<p>La terminologie utilis&#233;e en fouille d&#8217;opinion est multiple : opinion, sentiment, subjectivit&#233;,
polarit&#233;, etc. Nous nous int&#233;ressons ici sp&#233;cifiquement &#224; l&#8217;expression de l&#8217;opinion, qui peut se
classer sur un axe positif/n&#233;gatif.
On peut distinguer deux niveaux de subjectivit&#233; dans le langage (Benveniste, 1966) :
</p>
<p>178</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#8211; le premier niveau n&#8217;implique pas l&#8217;expression d&#8217;une &#233;valuation. Il t&#233;moigne simplement du
degr&#233; de pr&#233;sence de l&#8217;&#233;nonciateur dans son &#233;nonc&#233;. Cette pr&#233;sence peut &#234;tre implicite ou bien
explicite en fonction de la pr&#233;sence ou l&#8217;absence de certains marqueurs ;
</p>
<p>&#8211; le second niveau est celui des &#233;valuations exprim&#233;es par l&#8217;&#233;nonciateur. Elles se caract&#233;risent
par la pr&#233;sence d&#8217;un pr&#233;dicat exprimant l&#8217;&#233;valuation. Ce pr&#233;dicat peut avoir ou non une valeur
axiologique (positif, n&#233;gatif, neutre...)
</p>
<p>C&#8217;est ce deuxi&#232;me niveau qui nous int&#233;resse ici. Il est cependant parfois difficile de distinguer les
deux niveaux de subjectivit&#233; et cela peut amener &#224; des erreurs de classification.
</p>
<p>2.2 Diff&#233;rences d&#8217;expression selon les domaines ou les niveaux de langage
</p>
<p>Selon le sujet d&#8217;un texte, ce ne sont pas les m&#234;mes mots de vocabulaire qui sont employ&#233;s.
On pourrait cependant penser que les expressions d&#8217;&#233;valuation sont universelles. En effet,
certains mots et certaines structures reviennent avec r&#233;gularit&#233; tels que &quot;j&#8217;adore&quot; ou bien &quot;je
le d&#233;conseille&quot;. De plus, les dictionnaires notent que certains mots sont p&#233;joratifs (&quot;avare&quot;),
d&#8217;autres, au contraire, m&#233;lioratifs (&quot;g&#233;n&#233;reux&quot;). Ainsi, selon (Pupier, 1998), il y a des mots &#224;
valeur intrins&#232;quement positive (&quot;g&#233;n&#233;reux, d&#233;licieux&quot;) et d&#8217;autres &#224; valeur intrins&#232;quement
n&#233;gative (&quot;avare, mauvais&quot;). D&#8217;autres mots semblent en revanche neutres : &quot;table&quot; est l&#8217;exemple
classiquement donn&#233; par les linguistes. On parle ici d&#8217;orientation a priori.
</p>
<p>N&#233;anmoins, &#224; c&#244;t&#233; de mots intrins&#232;quement positifs ou n&#233;gatifs, il existe des mots dont
l&#8217;orientation peut changer selon le contexte dans lequel ils sont employ&#233;s (Riloff et Wiebe, 2003).
Il peut s&#8217;agir de mots polys&#233;miques ou bien d&#8217;homonymes ayant des axiologies diff&#233;rentes. C&#8217;est
le cas du &quot;navet&quot; qui est un l&#233;gume tout &#224; fait ordinaire en cuisine mais un film &#224; &#233;viter d&#232;s
lors que l&#8217;on parle de cin&#233;ma. La d&#233;sambigu&#239;sation lexicale (savoir quel sens est effectivement
utilis&#233;) s&#8217;appuie justement sur les mots du contexte. Les m&#233;thodes existantes utilisent des corpus,
annot&#233;s ou non, ainsi que des dictionnaires inventoriant les sens existant (Navigli, 2009).
L&#8217;orientation d&#8217;un mot non polys&#233;mique peut &#233;galement changer &#224; l&#8217;int&#233;rieur d&#8217;un m&#234;me
domaine, selon l&#8217;objet qu&#8217;il &#233;value. Par exemple pour un ordinateur portable, une batterie
&quot;large&quot; est un inconv&#233;nient mais un &#233;cran &quot;large&quot; est un atout. L&#8217;orientation des mots peut aussi
d&#233;pendre des pr&#233;f&#233;rences et de l&#8217;id&#233;ologie de l&#8217;auteur et c&#8217;est alors bien plus difficile &#224; d&#233;tecter.
Les textes politiques sont notamment tr&#232;s sensibles &#224; cela. Par exemple, le mot &quot;bourgeois&quot;
est fond&#233; sur une s&#233;mantique neutre mais quand il s&#8217;agit de pr&#233;jug&#233; ou d&#8217;opinion, ce qui est
&quot;bourgeois&quot; est souvent mal vu.
</p>
<p>Un probl&#232;me proche de l&#8217;adaptation au domaine est l&#8217;adaptation au niveau de langage.
On retrouve un vocabulaire diff&#233;rent selon les niveaux mais aussi des mots communs qui
changent de polarit&#233; (&quot;C&#8217;est terrible !, C&#8217;est mortel !&quot;). Ces inversions de sens peuvent &#234;tre
extr&#234;mement fortes comme le mot &quot;bad&quot; qui signifie exactement le contraire de son sens litt&#233;ral
dans le domaine du blues &#224; une certaine &#233;poque.
</p>
<p>Dans la prochaine partie, nous allons voir que les m&#233;thodes classiques pour obtenir des
lexiques et des classifieurs d&#8217;opinions ne sont pas toujours adapt&#233;es pour prendre en compte le
changement de vocabulaire induit par le changement de domaine.
</p>
<p>179</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>3 Les probl&#232;mes d&#8217;adaptation des ressources et des classi-
fieurs classiques
</p>
<p>Cette partie se focalise sur les probl&#232;mes d&#8217;adaptation des ressources et des classifieurs classiques.
Pour obtenir plus de d&#233;tails sur les m&#233;thodes de construction classiques, le lecteur se r&#233;f&#233;rera &#224;
(Pang et Lee, 2008).
</p>
<p>3.1 Les ressources
</p>
<p>Pour la constitution de ressources, on distingue deux grandes familles d&#8217;approches. La premi&#232;re
consiste &#224; utiliser des dictionnaires. A partir d&#8217;un petit ensemble de mots, appel&#233;s mots racines,
le lexique est &#233;tendu en utilisant les relations de synonymie et d&#8217;antonymie (Kim et Hovy, 2005;
Esuli et Sebastiani, 2006) ou bien les d&#233;finitions (Andreevskaia et Bergler, 2006). La seconde
consiste &#224; s&#8217;appuyer sur un corpus. Le lexique de mots racines est &#233;tendu en s&#8217;appuyant sur
plusieurs indices comme les conjonctions et/mais (Hatzivassiloglou et McKeown, 1997), la
cooccurrence entre mots(Turney et Littman, 2002) ou la proximit&#233; des contextes d&#8217;&#233;valuation
(Turney et al., 2003). Il existe &#233;galement des approches mixtes, combinant l&#8217;utilisation de corpus
et de dictionnaires (Taboada et al., 2011) ou bien de patrons d&#8217;extraction (Riloff et Wiebe, 2003).
</p>
<p>Les lexiques obtenus en utilisant des dictionnaires ne sont pas sp&#233;cifiques &#224; un domaine mais
leur couverture est souvent faible et ils sont pour la plupart limit&#233;s au sens a priori des mots,
c&#8217;est-&#224;-dire hors contexte. Les m&#233;thodes &#224; base de corpus sont quant &#224; elles applicables &#224; tous
les corpus, quel que soit leur domaine. Cependant, le lexique finalement appris d&#233;pendra du
domaine du lexique utilis&#233;. Enfin, les patrons d&#8217;extraction sont longs et co&#251;teux &#224; cr&#233;er. De plus,
les r&#233;sultats n&#233;cessitent souvent un nettoyage manuel avant d&#8217;&#234;tre r&#233;ellement exploitables.
</p>
<p>3.2 Les classifieurs
</p>
<p>En ce qui concerne la cr&#233;ation de classifieurs pour l&#8217;axiologie positive/n&#233;gative, on distingue
&#233;galement deux approches principales. La premi&#232;re consiste &#224; utiliser principalement des
lexiques et des indices linguistiques (Takamura et al., 2005; Ferrari et al., 2009). La seconde
consiste &#224; utiliser des donn&#233;es d&#8217;apprentissage afin de construire un classifieur statistique. Le
type de classifieur a moins d&#8217;importance que les traits utilis&#233;es qui peuvent &#234;tre des n-grammes
(Pang et al., 2002), des arbres de relations syntaxiques (Kudo et Matsumoto, 2004), tous les mots
ou bien certains mots particuliers comme les adjectifs et les adverbes (Benamara et al., 2007).
</p>
<p>Les classifieurs d&#233;velopp&#233;s &#224; partir de ressources g&#233;n&#233;rales ont plusieurs d&#233;fauts. En ef-
fet ces ressources sont trop g&#233;n&#233;rales et ne captent pas la sp&#233;cificit&#233; des domaines. Par exemple,
(Denecke, 2009) teste les score du lexique g&#233;n&#233;ral SentiWordNet dans la t&#226;che de classification
des opinions sur six corpus diff&#233;rents. Leurs classifieurs statistiques mono-domaines ont de
bien meilleurs r&#233;sultats que les classifieurs &#224; base de r&#232;gles utilisant uniquement les mots de
SentiWordNet. Un autre probl&#232;me des ressources g&#233;n&#233;rales est que certains mots a priori positifs
ou n&#233;gatifs peuvent en r&#233;alit&#233; &#234;tre employ&#233;s dans des contextes neutres voire de polarit&#233; oppos&#233;e
(Wilson et al., 2009). Quant aux classifieurs d&#233;velopp&#233;s sur un domaine particulier, les utiliser
</p>
<p>180</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>directement sur d&#8217;autres domaines donne en g&#233;n&#233;ral de mauvais r&#233;sultats. Par exemple, dans
(Aue et Gamon, 2005), les auteurs comparent des classifieurs entra&#238;n&#233;s sur quatre domaines
diff&#233;rents. Leurs r&#233;sultats montrent que l&#8217;utilisation d&#8217;un classifieur entra&#238;n&#233; sur un domaine
source diff&#233;rent du domaine cible fait perdre entre 2 et 38 % d&#8217;exactitude (accuracy).
</p>
<p>4 Ressources et techniques pour l&#8217;adaptation au domaine
</p>
<p>Afin de surmonter les d&#233;fauts de performance des m&#233;thodes classiques, la premi&#232;re possibilit&#233; est
de s&#8217;attacher &#224; d&#233;velopper des ressources g&#233;n&#233;rales plus performantes (section 4.1). Le but est
d&#8217;obtenir une performance acceptable sur tous les domaines ou, au moins, sur un grand nombre
de domaines. Une autre possibilit&#233; est de d&#233;velopper des m&#233;thodes permettant, &#224; moindre co&#251;t,
d&#8217;adapter automatiquement une ressource g&#233;n&#233;rale &#224; un domaine particulier (section 4.2). Enfin,
lorsque l&#8217;on dispose d&#233;j&#224; de ressources ou d&#8217;outils adapt&#233;s &#224; un domaine particulier, on peut les
adapter &#224; un domaine proche (section 4.3).
</p>
<p>4.1 Am&#233;liorer les performances des classifieurs g&#233;n&#233;raux
</p>
<p>Comme nous l&#8217;avons vu pr&#233;c&#233;demment, les lexiques d&#8217;opinion g&#233;n&#233;raux donnent des scores
de polarit&#233; a priori. Or cet a priori change selon le contexte et il faudrait disposer de lexiques
capables d&#8217;en rendre compte.
Il existe un flou sur ce qu&#8217;on appelle le contexte d&#8217;un mot d&#8217;opinion : cela peut aller de la cible
directe de l&#8217;opinion (Jijkoun et al., 2010) &#224; un sac de mots repr&#233;sentant le th&#232;me abord&#233; (Li et
Zong, 2008). Un lexique donnant des scores diff&#233;rents selon l&#8217;&#233;tiquette grammaticale du mot,
comme SentiWordNet, peut &#234;tre consid&#233;r&#233; comme faiblement contextuel (Dang et al., 2010). On
peut &#233;galement imaginer des lexiques d&#8217;opinion g&#233;n&#233;raux bien plus fortement contextuels. Par
exemple, (Gindl et al., 2010) cr&#233;ent tout d&#8217;abord deux lexiques contextuels et valu&#233;s sur deux
corpus A et B. Ils d&#233;terminent ensuite pour quels termes l&#8217;ajout du contexte a &#233;t&#233; utile, nocif ou
neutre pour A et B. Les r&#233;sultats obtenus gr&#226;ce au lexique contextuel sont ainsi compar&#233;s &#224; ceux
obtenus gr&#226;ce au lexique non-contextuel. Ils ne gardent ensuite que les termes contextuels qui
sont soit utiles soit neutres sur les deux domaines &#224; la fois, cr&#233;ant ainsi un lexique contextuel qui
donne de bon r&#233;sultats sur plusieurs domaines.
(Wilson et al., 2009) ne cr&#233;ent pas un lexique contextuel, mais utilisent les relations d&#233;duites
d&#8217;arbres de d&#233;pendance syntaxiques afin de temp&#233;rer les informations apport&#233;es par les
orientations des mots a priori.
</p>
<p>Une autre carence des lexiques d&#8217;opinion g&#233;n&#233;raux classiques est de manquer souvent
d&#8217;expressions polylexicales. Les mots simples sont les plus faciles &#224; rep&#233;rer mais ils ne suffisent
pas &#224; capter la richesse de l&#8217;expression de l&#8217;opinion dans la langue. Certaines expressions
polylexicales sont m&#234;me int&#233;gralement compos&#233;es de mots qui ne sont pas eux m&#234;me &#233;valuatifs,
par exemple &quot;un coup de bol&quot; ou bien &quot;une bouff&#233;e d&#8217;air frais&quot;. C&#8217;est pourquoi des lexiques
exhaustifs sont tr&#232;s difficiles &#224; constituer.
Les travaux de (Vernier et al., 2010) utilisent des marqueurs d&#8217;intensit&#233; (comme &quot;tr&#232;s&quot;) pour
pallier ce manque. Ils ont en effet observ&#233; que ces marqueurs s&#8217;appliquaient le plus souvent &#224; des
expressions subjectives. Ils utilisent donc des requ&#234;tes Yahoo pour s&#233;lectionner les candidats
qu&#8217;ils s&#233;parent ensuite entre objectif et subjectif &#224; l&#8217;aide d&#8217;un SVM. Ils ont &#233;valu&#233; manuellement
</p>
<p>181</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>l&#8217;efficacit&#233; de ce nouveau lexique par rapport &#224; un lexique de base sur un corpus de blog qui
m&#233;langeait des textes de domaines diff&#233;rents. Ils observent un gain de 15,6% en pr&#233;cision par
rapport au lexique de base pour la d&#233;tection de fragments subjectifs.
</p>
<p>Enfin, si on veut utiliser des classifieurs fond&#233;s uniquement sur des m&#233;thodes d&#8217;appren-
tissage statistique tout en &#233;tant les plus g&#233;n&#233;raux possible, il faut des donn&#233;es d&#8217;apprentissage
venant du plus grand nombre de domaines possible. En effet, quand on a un peu de donn&#233;es
annot&#233;es dans plusieurs domaines, on peut faire en sorte que les domaines s&#8217;aident les uns
les autres. C&#8217;est ce qu&#8217;on appelle de l&#8217;apprentissage multit&#226;ches. Dans ce cadre, fusionner les
classifieurs fonctionne mieux que fusionner directement les donn&#233;es d&#8217;apprentissage (Li et Zong,
2008; Li et al., 2011). La fusion la plus efficace dans ces travaux est r&#233;alis&#233;e par la somme
pond&#233;r&#233;e des r&#233;sultats des diff&#233;rents classifieurs, les poids de cette somme &#233;tant appris sur un
petit corpus de d&#233;veloppement du domaine cible.
Cette approche donne un classifieur donnant de bons r&#233;sultats sur plusieurs domaines si l&#8217;on
dispose d&#8217;un peu de donn&#233;es annot&#233;es pour tous. N&#233;anmoins, il est impossible de garantir des
r&#233;sultats pour des domaines compl&#232;tement nouveaux.
</p>
<p>4.2 Passer automatiquement du g&#233;n&#233;ral au particulier
</p>
<p>Les lexiques d&#8217;opinion g&#233;n&#233;raux peuvent &#234;tre adapt&#233;s &#224; un domaine particulier en utilisant les
m&#233;thodes d&#8217;expansion classiques sur un corpus s&#233;lectionn&#233; pour &#234;tre th&#233;matique. C&#8217;est le cas de
(Harb et al., 2008) qui extraient automatiquement du Web un corpus th&#233;matique en utilisant des
requ&#234;tes du type &#171; +opinion +cinema +good -bad -poor -nasty ... &#187;. Ils extraient ensuite les
adjectifs porteurs d&#8217;opinion en mesurant la cooccurrence dans les phrases entre les adjectifs
candidats et les mots racines du lexique initial.
The Double Propagation method, d&#233;crite dans (Qiu et al., 2009, 2011), peut &#234;tre utilis&#233;e pour
trouver de nouveaux mots d&#8217;opinion associ&#233;s &#224; leur cible sur un corpus particulier. Elle permet
&#224; la fois de d&#233;couvrir les mots d&#8217;opinion et leurs cibles gr&#226;ce &#224; un processus d&#8217;amor&#231;age
(bootstrap). Les travaux se fondent sur la reconnaissance des relations grammaticales reliant
les mots d&#8217;opinion et leur cible. Ces relations sont d&#233;crites au pr&#233;alable manuellement. Lors
de l&#8217;expansion, les relations sont d&#233;tect&#233;es &#224; l&#8217;aide d&#8217;un analyseur en d&#233;pendances. Ainsi, &#224;
partir d&#8217;un lexique d&#8217;opinion g&#233;n&#233;ral on augmente d&#8217;une part les cibles d&#233;tect&#233;es et d&#8217;autre part
le lexique de mots d&#8217;opinion en utilisant les relations une fois dans un sens et une fois dans l&#8217;autre.
</p>
<p>Une autre mani&#232;re d&#8217;adapter un lexique g&#233;n&#233;ral &#224; un domaine particulier est non pas
de l&#8217;&#233;tendre mais de le restreindre. C&#8217;est ce que font (Jijkoun et al., 2010) dans leurs travaux. Ils
r&#233;alisent une d&#233;tection de relations syntaxiques afin d&#8217;associer &#224; chaque mot du vocabulaire
g&#233;n&#233;ral un certain nombre de candidats pouvant &#234;tre la cible de l&#8217;opinion. Ils font l&#8217;hypoth&#232;se
que les cibles des opinions sont plus diverses que les autres &#233;l&#233;ments syntaxiquement li&#233;s &#224; un
terme d&#8217;opinion et ne retiennent donc que les mots cibles ayant un fort score d&#8217;entropie.
</p>
<p>Enfin, sans &#233;tendre ou restreindre le vocabulaire, on peut juste vouloir adapter au do-
maine le score de polarit&#233; des mots contenus dans le lexique g&#233;n&#233;ral. C&#8217;est par exemple le cas
dans les travaux de (Choi et Cardie, 2009). A l&#8217;aide d&#8217;une formulation en probl&#232;me lin&#233;aire en
nombres entiers, ils exploitent les relations entre les mots d&#8217;une m&#234;me expression et les mots et
la polarit&#233; des expressions qui les contiennent afin d&#8217;adapter la polarit&#233; a priori des mots.
</p>
<p>182</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4.3 Faciliter l&#8217;adaptation d&#8217;un domaine &#224; un autre
</p>
<p>Lorsqu&#8217;on utilise des algorithmes d&#8217;apprentissage, on pr&#233;suppose g&#233;n&#233;ralement que les donn&#233;es
d&#8217;entra&#238;nement ont la m&#234;me distribution que les donn&#233;es de test. En pratique, cela n&#8217;est pas le
cas. On ne peut bien s&#251;r pas esp&#233;rer obtenir de bons r&#233;sultats si les distributions des donn&#233;es
sources et cibles diff&#232;rent de mani&#232;re trop importante. Cependant, si elles ne sont que l&#233;g&#232;rement
diff&#233;rentes, l&#8217;apprentissage peut &#234;tre efficace.
</p>
<p>4.3.1 M&#233;langer les corpus ou les traits
</p>
<p>Si l&#8217;on dispose d&#8217;un corpus annot&#233; suffisamment grand, la m&#233;thode donnant les meilleurs
r&#233;sultats repose, de fa&#231;on naturelle, sur un entra&#238;nement direct sur les donn&#233;es du domaine. En
revanche, dans le cas o&#249; l&#8217;on ne dispose pas de donn&#233;es annot&#233;es, il devient utile de s&#8217;entra&#238;ner
sur d&#8217;autres corpus. Dans (Yoshida et al., 2011), les auteurs &#233;tudient l&#8217;influence du nombre de
domaines source et cible, allant jusqu&#8217;&#224; quatorze domaines diff&#233;rents. Plus le nombre de corpus
source est &#233;lev&#233;, plus les r&#233;sultats sur un corpus cible diff&#233;rent sont bons. De plus, leur mod&#232;le
probabiliste g&#233;n&#233;ratif permet de d&#233;terminer si la polarit&#233; inf&#233;r&#233;e pour un certain mot d&#233;pend
ou non du domaine du texte o&#249; se trouve le mot. Ainsi, ils construisent automatiquement des
dictionnaires valu&#233;s pour chaque domaine.
Afin de s&#8217;adapter plus pr&#233;cis&#233;ment au domaine cible, des poids peuvent &#234;tre attribu&#233;s aux
exemples (Bickel et al., 2007) ou aux traits (Satpal et Sarawagi, 2007). Ces m&#233;thodes s&#8217;appliquent
&#233;galement &#224; l&#8217;extraction d&#8217;information g&#233;n&#233;rale (Gupta et Sarawagi, 2009).
</p>
<p>Un probl&#232;me peut se poser lorsque les corpus sont h&#233;t&#233;rog&#232;nes et couvrent plusieurs
domaines. Dans le domaine de la classification d&#8217;image, (Hoffman et al., 2011) s&#8217;attaquent
au probl&#232;me de plusieurs domaines sources dont on ne conna&#238;t pas a priori les &#233;tiquettes. Ils
s&#233;parent d&#8217;abord les domaines sources &#224; l&#8217;aide d&#8217;une variante de l&#8217;algorithme des k-means avant
de poursuivre plus classiquement en combinant les classifieurs appris sur les domaines ainsi
s&#233;par&#233;s. A notre connaissance, il n&#8217;y a pas de travaux en classification d&#8217;opinion traitant ce
probl&#232;me particulier.
</p>
<p>4.3.2 Domaine de repr&#233;sentation commune
</p>
<p>Une autre approche est d&#8217;essayer de d&#233;tecter des pivots, des structures communes entre deux
domaines. La m&#233;thode d&#233;velopp&#233;e dans (Blitzer et al., 2006), le Structural Correspondance
Learning (SCL) se fonde sur la recherche de pivots entre les deux domaines permettant de
comparer les histogrammes de r&#233;partition des diff&#233;rents termes des domaines. Elle est motiv&#233;e
par un algorithme d&#8217;apprentissage multit&#226;ches, ASO (Alternating Structural Optimization),
propos&#233; par (Ando et Zhang, 2005). Cette m&#233;thode a &#233;t&#233; appliqu&#233;e &#224; la recherche d&#8217;opinion
dans (Blitzer et al., 2007), travaux que nous reproduisons dans la partie 5. Les pivots sont ici
des mots fr&#233;quents utiles &#224; la d&#233;termination de l&#8217;opinion dans le domaine source annot&#233;. Des
classifieurs pivots sont cr&#233;&#233;s qui permettent de comparer les distributions des autres mots par
rapport &#224; ces mots pivots. Ce sont les projections de ces distributions qui deviennent les traits
repr&#233;sentatifs des textes.
Dans (Blitzer et al., 2011), les auteurs s&#8217;int&#233;ressent plus sp&#233;cifiquement au cas o&#249; les supports
</p>
<p>183</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>des domaines source et cibles (l&#8217;ensemble des mots qui apparaissent dans chaque domaine) ont
peu de mots en commun. Les cooccurrences entre les termes des domaines source et cible ne
sont donc pas uniquement apprises par rapport &#224; des mots pivots communs au deux domaines
mais &#233;galement par rapport &#224; des mots sp&#233;cifiques &#224; un seul domaine.
</p>
<p>Un travail plus r&#233;cent &#224; ce sujet est celui de (Pan et al., 2010). Ils se servent &#233;galement
comme pivots de mots ind&#233;pendants du domaine s&#233;lectionn&#233; pour leur fr&#233;quence dans le
domaine cible et leur information mutuelle par rapport aux &#233;tiquettes du corpus source. Ils
construisent ensuite un graphe bipartite de corr&#233;lation entre les traits pivots et les traits
non-pivots. Puis &#224; l&#8217;aide d&#8217;algorithmes de clustering spectral, ils cr&#233;ent des clusters entre des
traits d&#233;pendants des domaines source et cible. Ils obtiennent ainsi un espace de repr&#233;sentation
commun aux deux domaines. Les r&#233;sultats obtenus dans (Pan et al., 2010) montre que la
m&#233;thode SFA obtient de meilleurs r&#233;sultats en exactitude que d&#8217;autres m&#233;thodes, dont SCL.
</p>
<p>Plusieurs travaux mettent &#233;galement en lumi&#232;re que lorsque l&#8217;on peut disposer en plus
d&#8217;une petite partie annot&#233;e du corpus cible, cela permet d&#8217;am&#233;liorer les r&#233;sultats de mani&#232;re
cons&#233;quente (Daum&#233;, 2007; Blitzer et al., 2007; Aue et Gamon, 2005).
</p>
<p>4.3.3 Comment &#233;valuer la transportabilit&#233; d&#8217;un domaine &#224; un autre ?
</p>
<p>Tous les travaux &#233;tudiant la portabilit&#233; d&#8217;un domaine &#224; un autre font &#233;tat de domaines plus
semblables pour lesquels le transfert se passe mieux (Denecke, 2009; Blitzer et al., 2007; Aue et
Gamon, 2005). La question de savoir comment mesurer la proximit&#233; de deux domaines devient
donc centrale.
</p>
<p>Dans (Ben-David et al., 2007), les auteurs d&#233;veloppent une borne sup&#233;rieure pour l&#8217;er-
reur de g&#233;n&#233;ralisation d&#8217;un classifieur entra&#238;n&#233; sur un domaine source et test&#233; sur un domaine
cible. Cette borne comprend deux termes variables. Le premier est l&#8217;erreur effectu&#233;e sur le
domaine source. Le second est une mesure de la divergence entre les distributions des domaines
sources et cibles sous une certaine repr&#233;sentation. Selon la repr&#233;sentation choisie pour les textes
(unigrammes, bigrammes, r&#244;les s&#233;mantiques...), les distributions des traits seront diff&#233;rentes.
Par cons&#233;quent, la divergence entre les deux domaines d&#233;pend de la repr&#233;sentation choisie.
En choisissant une repr&#233;sentation tr&#232;s simplifi&#233;e, on peut rendre la divergence entre les deux
domaines faible. Mais alors, l&#8217;erreur effectu&#233;e sur le domaine source sera tr&#232;s grande. Il faut
donc choisir avec soin la repr&#233;sentation des textes pour obtenir une divergence faible entre les
deux domaines tout en conservant une erreur raisonnable sur le domaine source.
Une fois la repr&#233;sentation d&#233;finie, se pose le probl&#232;me de calculer la divergence des deux
distributions. Une mesure naturelle serait la distance L1 ou variationnelle. Cependant, cette
distance n&#8217;est pas calculable &#224; partir d&#8217;un corpus fini pour des distributions &#224; valeur r&#233;elle.
C&#8217;est pourquoi (Ben-David et al., 2007) utilisent ce qu&#8217;ils appellent la A-distance. Il s&#8217;agit d&#8217;une
restriction de la distance variationnelle &#224; une collection A d&#8217;ensembles de textes issus des corpus
de fa&#231;on &#224; ce que chaque &#233;l&#233;ment de A soit mesurable sous les deux distributions. On ob-
tient ainsi une borne sup&#233;rieure calculable pour l&#8217;erreur de g&#233;n&#233;ralisation du classifieur consid&#233;r&#233;.
</p>
<p>D&#8217;un point de vue pratique, calculer la A-distance &#224; l&#8217;aide de donn&#233;es r&#233;elles est comme entra&#238;ner
un classifieur pour d&#233;partager les textes selon s&#8217;ils appartiennent au domaine source ou cible.
</p>
<p>184</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La A-distance fonctionne pour une classification de type 0/1. Les travaux de (Mansour
et al., 2009) introduisent la discrepancy distance qui peut &#233;galement &#234;tre utilis&#233;e pour comparer
des distributions dans le cadre d&#8217;une t&#226;che de r&#233;gression.
</p>
<p>5 Pistes de recherche et travaux pr&#233;liminaires
</p>
<p>Notre th&#232;me de recherche concerne l&#8217;adaptation au domaine pour la fouille d&#8217;opinion et la
constitution automatique de lexiques pour ce probl&#232;me. Les travaux cherchant &#224; projeter deux
corpus de domaines diff&#233;rents dans un espace commun semblent prometteurs. Aussi, nous nous
sommes attach&#233;s &#224; reproduire les travaux pr&#233;sent&#233;s dans (Blitzer et al., 2007). Cet article d&#233;crit
une heuristique pour l&#8217;adaptation au domaine appel&#233; Structural Correspondance Learning (SCL).
SCL utilise des donn&#233;es non-&#233;tiquet&#233;es provenant de deux domaines diff&#233;rents afin de d&#233;tecter
des correspondances de comportement entre des traits sp&#233;cifiques au domaine source et des
traits sp&#233;cifiques au domaine cible.
</p>
<p>5.1 Description de la m&#233;thode SCL
</p>
<p>Pour r&#233;aliser leur &#233;tude, les auteurs ont constitu&#233; des corpus th&#233;matiques &#224; partir de critiques
collect&#233;es sur le site internet Amazon. Ils ont utilis&#233; quatre corpus th&#233;matiques, DVDs, kitchen,
electronics et books. Les critiques sont repr&#233;sent&#233;es en sac de mots en utilisant les unigrammes et
les bigrammes pr&#233;sents. Gr&#226;ce au nombre d&#8217;&#233;toiles attribu&#233;es aux critiques, les auteurs se sont
assur&#233;s que leurs corpus contiennent autant de critiques positives (quatre et cinq &#233;toiles) que de
critiques n&#233;gatives (une et deux &#233;toiles). Les textes ayant obtenus trois &#233;toiles n&#8217;ont pas &#233;t&#233; pris
en compte &#224; cause de leur polarit&#233; ambig&#252;e.
Les travaux des auteurs cherchent &#224; reproduire la situation r&#233;elle o&#249; l&#8217;on dispose d&#8217;un grand
nombre de donn&#233;es non annot&#233;es &#224; la fois pour le domaine cible et pour le domaine source,
mais seulement une petite partie de corpus source annot&#233;. Aussi, lors de chaque exp&#233;rience,
on consid&#232;re que l&#8217;on ne conna&#238;t les &#233;tiquettes que de 2000 critiques du corpus source : 1000
positives et 1000 n&#233;gatives.
</p>
<p>L&#8217;id&#233;e de la m&#233;thode SCL est d&#8217;&#233;tablir des correspondances entre des mots du domaine
source et des mots du domaine cible en fonction de leur comportement par rapport &#224; des
mots pivots communs aux deux domaines. Consid&#233;rons le mot S qui n&#8217;appara&#238;t que dans
le corpus source et le mot C qui n&#8217;appara&#238;t que dans le corpus cible. Un classifieur usuel
entra&#238;n&#233; sur le domaine source ne saura pas quoi faire de C. Mais si S et C, chacun dans
son corpus, co-occurrent avec les mots pivots communs de la m&#234;me fa&#231;on, on peut suppo-
ser que C &#233;quivaut &#224; S dans le domaine cible. Le classifieur devra donc traiter C comme si c&#8217;&#233;tait S.
</p>
<p>En pratique, la premi&#232;re &#233;tape est donc d&#8217;identifier quels mots joueront le r&#244;le de pi-
vots. Les auteurs commencent par s&#233;lectionner un ensemble de traits qui apparaissent
fr&#233;quemment dans les deux domaines. Ces traits sont ensuite class&#233;s selon leur information
mutuelle par rapport aux classes positive et n&#233;gative pour les 2000 critiques du corpus
source dont on conna&#238;t la polarit&#233;. Seuls les 1000 plus informatifs sont conserv&#233;s. Ces traits
</p>
<p>185</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>pivots sont donc fr&#233;quents dans les deux domaines et relativement utile &#224; la t&#226;che de classifi-
cation de l&#8217;opinion pour le domaine source (par exemple &quot;a-must&quot;, &quot;loved-it&quot;, &quot;weak&quot;, &quot;awful&quot;, etc.)
</p>
<p>Une fois les traits pivots s&#233;lectionn&#233;s, les auteurs mod&#233;lisent la corr&#233;lation entre tous
les traits des deux corpus et les traits pivots en entra&#238;nant pour chaque trait pivot un classifieur
lin&#233;aire appel&#233; classifieur pivot. Ce classifieur, appris sur l&#8217;ensemble des corpus source et cible,
r&#233;pond &#224; la question : &quot;Est-ce que le mot pivot consid&#233;r&#233; &#224; des chances d&#8217;appara&#238;tre dans ce
texte sachant tous les autres mots du texte&quot;. Les vecteurs de poids de ces classifieurs pivots sont
agr&#233;g&#233;s en une matrice. Celle-ci est ensuite r&#233;duite par d&#233;composition en valeurs singuli&#232;re.
Les auteurs ne conservent que 50 dimensions. Ils obtiennent ainsi une matrice de projection
permettant de calculer 50 nouveaux traits (&#224; valeur r&#233;elle) pour chaque texte source et cible.
Les textes du corpus source et cible sont repr&#233;sent&#233;s par un vecteur contenant &#224; la fois les traits
initiaux (les unigrammes et bigrammes) et les nouveaux traits calcul&#233;s &#224; l&#8217;aide de la matrice
de projection. C&#8217;est sur ces corpus &#233;tendus source et cible qu&#8217;un classifieur est entra&#238;n&#233; et
test&#233;. Les auteurs utilisent un classifieur lin&#233;aire dont les coefficients sont obtenus par descente
stochastique de gradient.
</p>
<p>Par rapport &#224; un classifieur entra&#238;n&#233; sur un domaine source et test&#233; sur un domaine
cible sans rajouter les nouveaux traits, leur approche am&#233;liore souvent les performances (10 cas
sur 12). En une occasion, ils arrivent m&#234;me &#224; d&#233;passer les performances d&#8217;un classifieur entra&#238;n&#233;
et test&#233; sur le domaine cible.
</p>
<p>5.2 Nos travaux de reproduction
</p>
<p>Nous utilisons deux des corpus constitu&#233;s et utilis&#233;s par les auteurs : les corpus DVDs et
kitchen du Multi-Domain Sentiment Dataset. Le corpus source DVDs contient 5586 critiques et le
corpus cible kitchen 7945 critiques &#233;galement r&#233;parties entre n&#233;gatives et positives. Comme dit
pr&#233;c&#233;demment, le domaine source contient 1000 critiques positives et 1000 critiques n&#233;gatives
pour lesquelles on conna&#238;t les &#233;tiquettes. En moyenne, les critiques du corpus kitchen contiennent
145 unigrammes et bigrammes, celles de DVDs, 269.
</p>
<p>Nous avons &#233;tudi&#233; le sens d&#8217;adaptation de DVDs vers kitchen. Les r&#233;f&#233;rences que nous
utilisons sont les suivantes : un classifieur entra&#238;n&#233; et test&#233; sur le domaine source, un classifieur
entra&#238;n&#233; et test&#233; sur le domaine cible et un classifieur entra&#238;n&#233; sur le domaine source et test&#233;
sur le domaine cible sans ajouter les traits obtenus par SCL. Nous comparons &#233;galement nos
r&#233;sultats avec ceux pr&#233;sent&#233;s dans (Blitzer et al., 2007).
</p>
<p>Les tests effectu&#233;s ont mis en valeur le fait que le choix des traits pivots influence &#233;nor-
m&#233;ment les performances du classifieur. Les r&#233;sultats fournis par les auteurs sont des r&#233;sultats
d&#8217;exactitude. Il nous a sembl&#233; int&#233;ressant d&#8217;&#233;tudier l&#8217;influence de la s&#233;lection des traits pivots sur
la performance en pr&#233;cision pour les deux classes.
Nous avons s&#233;lectionn&#233; des ensembles de 1000 traits pivots de trois fa&#231;ons diff&#233;rentes :
&#8211; s&#233;lection uniquement selon l&#8217;information mutuelle (MI) par rapport aux &#233;tiquettes du domaine
</p>
<p>source ;
&#8211; s&#233;lection uniquement selon la fr&#233;quence d&#8217;apparition dans les domaines source et cible ;
&#8211; combinaison des deux crit&#232;re pr&#233;c&#233;dent.
</p>
<p>186</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Le tableau 1 pr&#233;sente les r&#233;sultats obtenus pour un classifieur entra&#238;n&#233; sur DVDs et test&#233; sur
kitchen ainsi que les r&#233;f&#233;rences pr&#233;sent&#233;es plus haut.
De plus, dans (Blitzer et al., 2007), les auteurs normalisent les nouveaux traits afin que leur
norme moyenne &#233;quivaille &#224; &#945; fois celle des anciens traits. Ils obtiennent de cette fa&#231;on de
meilleurs r&#233;sultats. La derni&#232;re ligne du tableau pr&#233;sente donc les r&#233;sultats avec un seuil &#945; de
pond&#233;ration que nous avons exp&#233;rimentalement fix&#233; &#224; 0,5.
</p>
<p>Blitzer
et al.
</p>
<p>Exactitude
(Accuracy)
</p>
<p>Pr&#233;cision
classe
positive
</p>
<p>Pr&#233;cision
classe
n&#233;gative
</p>
<p>Rappel
classe
positive
</p>
<p>Rappel
classe
n&#233;gative
</p>
<p>R&#233;f. source-&gt;cible 74,0 78,5 79,4 77,6 76,5 80,4
R&#233;f. source-&gt;source 82,4 81,8 80,3 83,4 84,6 79,0
R&#233;f. cible-&gt;cible 87,7 87,7 88,4 87,0 86,4 88,9
Pivots : fr&#233;quence 79,4 79,8 80,9 78,7 77,6 81,9
Pivots : MI . 79,6 85,0 75,7 71,6 87,6
Pivots : mixte . 79,9 83,9 76,7 73,6 86,1
Pivots : mixte pond. 81,4 80,7 82,5 79,13 77,6 83,8
</p>
<p>TABLE 1 &#8211; R&#233;sultats pour un classifieur entra&#238;n&#233; sur DVDs et test&#233; sur kitchen
</p>
<p>Nous observons quelques diff&#233;rences de r&#233;sultats entre l&#8217;article original et notre impl&#233;mentation,
notamment pour la r&#233;f&#233;rence domaine source sur domaine cible. Ces diff&#233;rences s&#8217;expliquent par
l&#8217;utilisation d&#8217;un classifieur SVM &#224; noyau lin&#233;aire dans notre cas, alors que les auteurs utilisent
une descente de gradient stochastique pour d&#233;terminer les coefficients de leur classifieur lin&#233;aire.
Nous observons cependant &#233;galement une augmentation des r&#233;sultats gr&#226;ce &#224; la m&#233;thode SCL.
</p>
<p>Les pivots s&#233;lectionn&#233;s uniquement par la fr&#233;quence am&#232;nent une petite am&#233;lioration
par rapport &#224; la r&#233;f&#233;rence sans toutefois changer l&#8217;&#233;cart de performance entre la classe positive et
la classe n&#233;gative. Les pivots s&#233;lectionn&#233;s uniquement par MI, quant &#224; eux, favorisent bien plus
la classe positive. En combinant les deux crit&#232;res de s&#233;lection on arrive &#224; r&#233;duire un peu cette
diff&#233;rence de performance entre les deux classes, d&#8217;autant plus si l&#8217;on pond&#232;re la contribution
des nouveaux et des anciens traits.
Nous observons donc une difficult&#233; particuli&#232;re &#224; la classe n&#233;gative. Plus de textes positifs sont
faussement class&#233;s en n&#233;gatif que l&#8217;inverse. Une difficult&#233; similaire a &#233;t&#233; not&#233;e par (Vernier
et al., 2009) pour la d&#233;tection pr&#233;cise de passages subjectifs n&#233;gatifs. Il faudra donc porter une
attention particuli&#232;re au traitement des opinions n&#233;gatives.
</p>
<p>5.3 Perspectives
</p>
<p>L&#8217;utilisation de la matrice de projection cr&#233;&#233;e par la m&#233;thode SCL est donc utile &#224; la classification
des opinions. Cependant, elle peut &#233;galement r&#233;aliser de mauvais alignements. Cela peut
notamment arriver lorsqu&#8217;un des corpus est plus h&#233;t&#233;rog&#232;ne que l&#8217;autre. Par exemple le corpus
DVDs, bien que rassemblant des textes d&#8217;un m&#234;me domaine, fait r&#233;f&#233;rence &#224; plusieurs sujets
qui sont les sujets des films. Les mots se rapportant aux sujets ne sont pas informatifs pour
</p>
<p>187</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>notre t&#226;che de classification de l&#8217;opinion. Ils apparaissent peu fr&#233;quemment en proportion du
corpus et risquent d&#8217;&#234;tre mis en corr&#233;lation avec des mots du second domaine peu fr&#233;quents mais
informatifs. Lorsque le classifieur est adapt&#233; du domaine h&#233;t&#233;rog&#232;ne vers le domaine homog&#232;ne,
il manque donc les informations contenus dans les mots peu fr&#233;quents et informatifs du domaine
cible. Dans l&#8217;autre sens, le classifieur va attribuer des poids &#224; des mots qui ne sont pas informatifs
pour la classification d&#8217;opinions.
</p>
<p>L&#8217;utilisation d&#8217;une matrice de projection obtenue par une d&#233;composition en valeurs sin-
guli&#232;res rend l&#8217;interpr&#233;tation des r&#233;sultats plus difficiles car les traits finaux ne sont plus des
unigrammes ou des bigrammes. Nous aimerions pouvoir rendre cette m&#233;thode plus interpr&#233;table,
c&#8217;est-&#224;-dire garder des traits li&#233;s aux mots de fa&#231;on directe. Notre id&#233;e serait d&#8217;utiliser une
m&#233;thode s&#8217;inspirant de (Pan et al., 2010). Une fois les traits sources et cibles projet&#233;s dans
l&#8217;espace commun nouvellement cr&#233;&#233;, on peut les regrouper en clusters. Ce sont ces clusters qui
seraient alors les nouveaux traits.
Une autre possibilit&#233; est d&#8217;utiliser l&#8217;hyperplan s&#233;parateur du classifieur afin de donner des scores
d&#8217;opinion aux termes cibles qui serait la distance &#224; cet hyperplan s&#233;parateur. Nous faisons
l&#8217;hypoth&#232;se que les mots r&#233;ellement polaris&#233;s auront une grande distance &#224; cet hyperplan.
</p>
<p>6 Conclusion
</p>
<p>Nous nous sommes int&#233;ress&#233;s dans cet article &#224; la fouille d&#8217;opinion et plus particuli&#232;rement &#224;
la classification de l&#8217;opinion et nous avons pr&#233;sent&#233; un &#233;tat de l&#8217;art des diff&#233;rentes m&#233;thodes
utilis&#233;es pour cette t&#226;che, en particulier pour traiter le probl&#232;me de l&#8217;adaptation au domaine.
Nous avons vu que l&#8217;expression de l&#8217;opinion prend des formes tr&#232;s vari&#233;es et qui d&#233;pendent du
domaine o&#249; l&#8217;on se place. Un mot ayant une polarit&#233; neutre dans un certain contexte peut avoir
une polarit&#233; positive dans un autre. C&#8217;est pourquoi il est tr&#232;s difficile de mettre au point un
classifieur ayant de bonnes performances dans tous les domaines.
</p>
<p>Les pistes &#233;tudi&#233;es pour pallier ce probl&#232;me sont multiples. On peut tout d&#8217;abord am&#233;-
liorer les ressources g&#233;n&#233;rales, notamment en cr&#233;ant des lexiques contextuels pr&#233;cis. Une autre
approche est de d&#233;velopper des techniques pour particulariser automatiquement des ressources
ou des classifieurs g&#233;n&#233;raux &#224; l&#8217;aide d&#8217;un corpus mono-domaine sp&#233;cifique. Enfin, une troisi&#232;me
possibilit&#233; est de travailler sur l&#8217;adaptation entre domaines. Pour cela, on peut projeter l&#8217;espace
cible sur l&#8217;espace source ou bien projeter les deux espaces dans un espace commun. La difficult&#233;
r&#233;side alors dans la d&#233;termination de cet espace de projection.
</p>
<p>Nous avons &#233;galement pr&#233;sent&#233; nos premi&#232;res pistes de recherche pour d&#233;finir cet es-
pace de projection de telle sorte qu&#8217;il reste li&#233; &#224; un lexique, pour rester interpr&#233;table.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ANDO, R. et ZHANG, T. (2005). A framework for learning predictive structures from multiple
tasks and unlabeled data. The Journal of Machine Learning Research, 6:1817&#8211;1853.
</p>
<p>188</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ANDREEVSKAIA, A. et BERGLER, S. (2006). Mining wordnet for fuzzy sentiment : Sentiment tag
extraction from wordnet glosses. In EACL, volume 6.
</p>
<p>AUE, A. et GAMON, M. (2005). Customizing sentiment classifiers to new domains : A case study.
In Recent Advances in Natural Language Processing.
</p>
<p>BEN-DAVID, S., BLITZER, J., CRAMMER, K. et PEREIRA, F. (2007). Analysis of representations for
domain adaptation. Advances in neural information processing systems, 19:137.
</p>
<p>BENAMARA, F., CESARANO, C., PICARIELLO, A., REFORGIATO, D. et SUBRAHMANIAN, V. (2007). Senti-
ment analysis : Adjectives and adverbs are better than adjectives alone. In ICWSM.
</p>
<p>BENVENISTE, E. (1966). Probl&#232;mes de linguistique g&#233;n&#233;rale I. Gallimard.
</p>
<p>BICKEL, S., BR&#220;CKNER, M. et SCHEFFER, T. (2007). Discriminative learning for differing training
and test distributions. In 24th international conference on Machine learning. ACM.
</p>
<p>BLAIR-GOLDENSOHN, S., HANNAN, K., MCDONALD, R., NEYLON, T., REIS, G. et REYNAR, J. (2008).
Building a sentiment summarizer for local service reviews. In WWW Workshop on NLP.
</p>
<p>BLITZER, J., DREDZE, M. et PEREIRA, F. (2007). Biographies, bollywood, boom-boxes and blenders :
Domain adaptation for sentiment classification. In Annual Meeting of the ACL.
</p>
<p>BLITZER, J., FOSTER, D. et KAKADE, S. (2011). Domain adaptation with coupled subspaces.
Journal of Machine Learning Research - Proceedings Track, 15:173&#8211;181.
</p>
<p>BLITZER, J., MCDONALD, R. et PEREIRA, F. (2006). Domain adaptation with structural correspon-
dence learning. In EMNLP.
</p>
<p>CHOI, Y. et CARDIE, C. (2009). Adapting a polarity lexicon using integer linear programming for
domain-specific sentiment classification. In EMNLP.
</p>
<p>DANG, Y., ZHANG, Y. et CHEN, H. (2010). A lexicon enhanced method for sentiment classification :
An experiment on online product reviews.
</p>
<p>DAUM&#201;, H. (2007). Frustratingly easy domain adaptation. In Annual Meeting of the ACL.
</p>
<p>DENECKE, K. (2009). Are sentiwordnet scores suited for multi-domain sentiment classification ?
In International Conference on Digital Information Management.
</p>
<p>ESULI, A. et SEBASTIANI, F. (2006). Sentiwordnet : A publicly available lexical resource for
opinion mining. In LREC.
</p>
<p>FERRARI, S., CHARNOIS, T., MATHET, Y., RIOULT, F. et LEGALLOIS, D. (2009). Analyse de discours
&#233;valuatif, mod&#232;le linguistique et applications. RNTI, E-17:71&#8211;93.
</p>
<p>GINDL, S., WEICHSELBRAUN, A. et SCHARL, A. (2010). Cross-domain contextualisation of sentiment
lexicons. European Conference on Artificial Intelligence.
</p>
<p>GUPTA, R. et SARAWAGI, S. (2009). Domain adaptation of information extraction models. ACM
SIGMOD Record, 37(4):35&#8211;40.
</p>
<p>HARB, A., DRAY, G., PLANTI&#201;, M., PONCELET, P., ROCHE, M., TROUSSET, F. et al. (2008). D&#233;tection
d&#8217;opinion : Apprenons les bons adjectifs ! Atelier FOuille des Donn&#233;es d&#8217;OPinions.
</p>
<p>HATZIVASSILOGLOU, V. et MCKEOWN, K. (1997). Predicting the semantic orientation of adjectives.
In EACL.
</p>
<p>HOFFMAN, J., SAENKO, K., KULIS, B. et DARRELL, T. (2011). Domain adaptation with multiple
latent domains. In NIPS Domain Adaptation Workshop.
</p>
<p>JIJKOUN, V., RIJKE, M. et WEERKAMP, W. (2010). Generating focused topic-specific sentiment
lexicons. In Annual Meeting of the ACL.
</p>
<p>189</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>KIM, S. et HOVY, E. (2005). Automatic detection of opinion bearing words and sentences. In
International Joint Conference on Natural Language Processing, pages 61&#8211;66.
KUDO, T. et MATSUMOTO, Y. (2004). A boosting algorithm for classification of semi-structured
text. In EMNLP.
LI, S., HUANG, C. et ZONG, C. (2011). Multi-domain sentiment classification with classifier
combination. Journal of Computer Science and Technology, 26:25&#8211;33.
LI, S. et ZONG, C. (2008). Multi-domain sentiment classification. In Annual Meeting of the ACL.
MANSOUR, Y., MOHRI, M. et ROSTAMIZADEH, A. (2009). Domain adaptation : Learning bounds
and algorithms. In Conference on Learning Theory.
NAVIGLI, R. (2009). Word sense disambiguation : A survey. ACM Computing Surveys.
PAN, S., NI, X., SUN, J., YANG, Q. et CHEN, Z. (2010). Cross-domain sentiment classification via
spectral feature alignment. In International Conference on World Wide Web.
PANG, B. et LEE, L. (2008). Opinion mining and sentiment analysis. Foundations and Trends in
Information Retrival, 2:1&#8211;2.
PANG, B., LEE, L. et VAITHYANATHAN, S. (2002). Thumbs up ? : sentiment classification using
machine learning techniques.
PUPIER, P. (1998). Une premi&#232;re syst&#233;matique des &#233;valuatifs en fran&#231;ais. Revue qu&#233;b&#233;coise de
linguistique, 26(1).
QIU, G., LIU, B., BU, J. et CHEN, C. (2009). Expanding domain sentiment lexicon through double
propagation. In International Joint Conference on Artificial Intelligence.
QIU, G., LIU, B., BU, J. et CHEN, C. (2011). Opinion word expansion and target extraction
through double propagation. Computational Linguistics, 37:9&#8211;27.
RILOFF, E. et WIEBE, J. (2003). Learning extraction patterns for subjective expressions. In
EMNLP.
SATPAL, S. et SARAWAGI, S. (2007). Domain adaptation of conditional probability models via
feature subsetting. In Knowledge Discovery in Databases : PKDD.
TABOADA, M., BROOKE, J., TOFILOSKI, M., VOLL, K. et STEDE, M. (2011). Lexicon-based methods
for sentiment analysis. In Computational linguistics.
TAKAMURA, H., INUI, T. et OKUMURA, M. (2005). Extracting semantic orientations of words using
spin model. In ACL.
TURNEY, P. et LITTMAN, M. (2002). Unsupervised learning of semantic orientation from a
hundred-billion-word corpus. Erb-1094, Institute for Information Technology, Canada.
TURNEY, P., LITTMAN, M. et al. (2003). Measuring praise and criticism : Inference of semantic
orientation from association. In ACM Transactions on Information Systems.
VERNIER, M., MONCEAUX, L. et DAILLE, B. (2010). Learning subjectivity phrases missing from
resources through a large set of semantic tests. In LREC.
VERNIER, M., MONCEAUX, L. et DUBREIL, E. (2009). Cat&#233;gorisation s&#233;mantico-discursive des
&#233;valuations exprim&#233;es dans la blogosph&#232;re. In TALN.
WILSON, T., WIEBE, J. et HOFFMANN, P. (2009). Recognizing contextual polarity : An exploration
of features for phrase-level sentiment analysis. Computational Linguistics, 35:339&#8211;433.
YOSHIDA, Y., HIRAO, T., IWATA, T., NAGATA, M. et MATSUMOTO, Y. (2011). Transfer learning
for multiple-domain sentiment analysis - identifying domain dependent/independent word
polaritys. In Porceedings of AAAI.
</p>
<p>190</p>

</div></div>
</body></html>