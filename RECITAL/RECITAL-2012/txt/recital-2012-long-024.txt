ﬁtat de l’art : l’inﬂuence du domaine
sur la classiﬁcation de l’opinion

Dis-moi de quoi tu parles, je te dirai ce que tu penses

Morgane Marchand1»2
(1) CEA, LIST; Laboratoire Vision et Ingénierie des Contenus
Centre Nano—Innov Saclay, 91191 Gif—sur—Yvette Cedex
(2) LIMSI—CNRS, Univ. Paris—Sud
91403 Orsay Cedex
morgane . marchandcea . fr

RESUME
L’intérét pour la fouille d’opinion s’est développé en méme temps que se sont répandus les blogs,
forums et autres plate-formes o1‘1 les internautes peuvent librement exprimer leur opinion. La trés
grande quantité de données disponibles oblige a avoir recours a des traitements automatiques de
fouille d’opinion. Cependant, la maniére dont les gens expriment leur avis change selon ce dont
ils parlent. Les distributions des mots utilisés sont différentes d’un domaine 5 l’autre. Aussi, il est
tres difﬁcile d’obtenir un classiﬁeur d’opinion fonctionnant sur tous les domaines. De plus, on ne
peut appliquer sans adaptation sur un domaine cible un classiﬁeur entrainé sur un domaine
source différent. L’objet de cet article est de recenser les moyens de résoudre ce probléme difﬁcile.

AB STRACT
State of the Art : Inﬂuence of Domain on Opinion Classiﬁcation

The interest in opinion mining has grown concurrently with blogs, forums, and others platforrr1s
where the intemauts can freely write about their opinion on every topic. As the amounts of
available data are increasingly huge, the use of automatic methods for opinion mining becomes
imperative. However, sentiment is expressed differently in different domains : words distributions
can indeed differ signiﬁcantly. An effective global opinion classiﬁer is therefore hard to develop.
Moreover, a classiﬁer trained on a source domain can’t be used without adaptation on a target
domain. This article aims to describe the state-of-the-art methods used to solve this difﬁcult task.

MOTS-CLES : Etat de l’art, Fouille d’opinion, Multi-domaines, Cross-domaines.

KEYWORDS: State of the art, Opinion mining, Multi-domain, Cross-domain.

Actes de la con_fe'rence conjointe JEP-TALN-RECITAL 2012, volume 3: RECITAL, pages 177-190,
Grenoble, 4 an 8 juin 2012. ©2012 ATAI.A 8: AFCP

177

1 Introduction

Savoir ce que les autres pensent est, depuis toujours, une information tres importante pour
prendre une décision. Nous consultons des critiques de consommateurs avant d’acheter un
appareil photo, des sondages avant des élections ou encore dans le domaine professionnel des
lettres de recommandation. Depuis le développement d’Intemet, de plus en plus de personnes
rendent leurs avis disponibles. Nous avons donc facilement accés a un trés large corpus d’opinion
en tout genre.

Les applications possibles de la fouille d’opinion sont multiples (Pang et lee, 2008). Elle peut,
par exemple, étre utilisée pour agréger des critiques, faire des systemes de recommandation
ou bien des outils de marketing et de business intelligence. Certains moteurs de recherche
proposent déj‘a des applications pour résumer les opinions des consommateurs dans des
interfaces dédiées au shopping (Blair-Goldensohn et aL, 2008). L’idéal serait de pouvoir disposer
de telles fonctionnalités pour des recherches d’ordre général.

La diversité et la quantité de ces témoignages rendent leur traitement manuel long et
coﬁteux. C’est pourquoi l’exploitation automatique de ces données est un enjeu majeur.

La fouille d’opinion se compose de plusieurs taches, qu’il est utile ou non de mettre en
oeuvre selon les applications visées. :

— détection de la présence ou non de l’opinion;

— classiﬁcation de l’axiologie de l’opinion (positif, négatif, neutre) ;

— classiﬁcation de l’intensité de l’opinion;

— identiﬁcation de l’objet de l’opinion (ce sur quoi porte l’opinion) ;

identiﬁcation de la source de l’opinion (qui exprime l’opinion).

L’analyse de l’opinion peut se situer au niveau du texte entier, du paragraphe, de la phrase ou
bien du fragment selon les applications envisagées.

Dans cet article, nous nous intéresserons uniquement ‘a la tache de classiﬁcation de
l’axiologie de l’opinion, dont nous donnons un apercu des problémes dans la section 2, de fagon
générale et dans le cas particulier des domaines différents. En section 3, nous expliciterons
brievement pourquoi les techniques classiques pour la constitution des ressources ou des
classiﬁeurs sont moins efﬁcaces lorsque l’on change de domaine d’expression. Nous dresserons
alors, dans la section 4, un état de l’art des recherches actuelles visant ‘a améliorer les
performances des classiﬁeurs dans ce cas particulier. Dans une derniére partie, nous évoquerons
les travaux prélirninaires effectués ainsi que les perspectives d’exploration.

2 La subjectivité dans le langage

2.1 Présentation et déﬁnition

La terminologie utilisée en fouille d’opinion est multiple : opinion, sentiment, subjectivité,
polarité, etc. Nous nous intéressons ici spéciﬁquement a l’expression de l’opinion, qui peut se
classer sur un axe positif/négatif.

On peut distinguer deux niveaux de subjectivité dans le langage (Benveniste, 1966) :

178

Le tableau 1 présente les résultats obtenus pour un classiﬁeur entrainé sur DVDs et testé sur
kitchen ainsi que les références présentées plus haut.

De plus, dans (Blitzer et al., 2007), les auteurs normalisent les nouveaux traits afin que leur
norme moyenne équivaille ‘a on fois celle des anciens traits. Ils obtiennent de cette facon de
meilleurs résultats. La demiére ligne du tableau présente donc les résultats avec un seuil (1 de
pondération que nous avons expérimentalement ﬁxé a 0,5.

Blitzer Exactitude Précision Précision Rappel Rappel
et al. (Accuracy) classe classe classe classe
positive négative positive négative

Réf. source->cible 74,0 78,5 79,4 77,6 76,5 80,4
Réf. source->source 82,4 81,8 80,3 83,4 84,6 79,0
Réf. cible->cible 87,7 87,7 88,4 87,0 86,4 88,9
Pivots : fréquence 79,4 79,8 80,9 78,7 77,6 81,9
Pivots : MI . 79,6 85,0 75,7 71,6 87,6
Pivots : mixte . 79,9 83,9 76,7 73,6 86,1
Pivots : mixte pond. 81,4 80,7 82,5 79,13 77,6 83,8

TABLE 1 — Résultats pour un classiﬁeur entrainé sur DVDs et testé sur kitchen

Nous observons quelques différences de résultats entre l’artic1e original et notre implémentation,
notamment pour la référence domaine source sur domaine cible. Ces différences s’expliquent par
l’utilisation d’un classiﬁeur SVM ‘a noyau linéaire dans notre cas, alors que les auteurs utilisent
une descente de gradient stochastique pour déterminer les coefﬁcients de leur classiﬁeur linéaire.
Nous observons cependant également une augmentation des résultats grace a la méthode SCL.

Les pivots sélectionnés uniquement par la fréquence aménent une petite amélioration
par rapport a la référence sans toutefois changer l’écart de performance entre la classe positive et
la classe négative. Les pivots sélectionnés uniquement par MI, quant a eux, favorisent bien plus
la classe positive. En combinant les deux critéres de sélection on arrive ‘a réduire un peu cette
différence de performance entre les deux classes, d’autant plus si l’on pondére la contribution
des nouveaux et des anciens traits.

Nous observons donc une difﬁculté particuliére a la classe négative. Plus de textes positifs sont
faussement classés en négatif que l’inverse. Une difﬁculté similaire a été notée par (Vernier
et al., 2009) pour la détection précise de passages subjectifs négatifs. I1 faudra donc porter une
attention particuliére au traitement des opinions négatives.

5.3 Perspectives

L’utilisation de la matrice de projection créée par la méthode SCL est donc utile a la classiﬁcation
des opinions. Cependant, elle peut également réaliser de mauvais alignements. Cela peut
notamment arriver lorsqu’un des corpus est plus hétérogéne que l’autre. Par exemple le corpus
DVDs, bien que rassemblant des textes d’un méme domaine, fait référence ‘a plusieurs sujets
qui sont les sujets des films. Les mots se rapportant aux sujets ne sont pas informatifs pour

187

notre tache de classiﬁcation de l’opinion. Ils apparaissent peu fréquemment en proportion du
corpus et risquent d’étre mis en corrélation avec des mots du second domaine peu fréquents mais
informatifs. Lorsque le classiﬁeur est adapté du domaine hétérogéne vers le domaine homogene,
il manque donc les informations contenus dans les mots peu fréquents et informatifs du domaine
cible. Dans l’autre sens, le classiﬁeur va attribuer des poids a des mots qui ne sont pas informatifs
pour la classiﬁcation d’opinions.

L’utilisation d’une matrice de projection obtenue par une décomposition en valeurs sin-
guliéres rend l’interprétat1'on des résultats plus difﬁciles car les traits ﬁnaux ne sont plus des
unigrammes ou des bigrammes. Nous aimerions pouvoir rendre cette méthode plus interprétable,
c’est-a-dire garder des traits liés aux mots de facon directe. Notre idée serait d’ut1'liser une
méthode s’inspirant de (Pan et al., 2010). Une fois les traits sources et cibles projetés dans
l’espace commun nouvellement créé, on peut les regrouper en clusters. Ce sont ces clusters qui
seraient alors les nouveaux traits.

Une autre possibilité est d’utiliser l’hyperplan séparateur du classiﬁeur aﬁn de donner des scores
d’opinion aux termes cibles qui serait la distance ‘a cet hyperplan séparateur. Nous faisons
l’hypothése que les mots réellement polarisés auront une grande distance a cet hyperplan.

6 Conclusion

Nous nous sommes intéressés dans cet article a la fouille d’opinion et plus particuliérement a
la classiﬁcation de l’opinion et nous avons présenté un état de l’art des différentes méthodes
utilisées pour cette tache, en particulier pour traiter le probleme de l’adaptation au domaine.
Nous avons vu que l’expression de l’opinion prend des formes trés variées et qui dépendent du
domaine o1‘1l’on se place. Un mot ayant une polarité neutre dans un certain contexte peut avoir
une polarité positive dans un autre. C’est pourquoi il est trés difﬁcile de mettre au point un
classiﬁeur ayant de bonnes performances dans tous les domaines.

Les pistes étudiées pour pallier ce probléme sont multiples. On peut tout d’abord amé-
liorer les ressources générales, notamment en créant des lexiques contextuels précis. Une autre
approche est de développer des techniques pour particulariser automatiquement des ressources
ou des classiﬁeurs généraux a l’aide d’un corpus mono-domaine spéciﬁque. Enﬁn, une troisiéme
possibilité est de travailler sur l’adaptation entre domaines. Pour cela, on peut projeter l’espace
cible sur l’espace source ou bien projeter les deux espaces dans un espace commun. La difﬁculté
réside alors dans la détermination de cet espace de projection.

Nous avons également présenté nos premieres pistes de recherche pour déﬁnir cet es-
pace de projection de telle sorte qu’il reste lié a un lexique, pour rester interprétable.

Références

ANDO, R. et ZHANG, T. (2005). A framework for learning predictive structures from multiple
tasks and unlabeled data. The Journal of Machine Learning Research, 6: 1817-1853.

188

ANDREEVSKAIA, A. et BERGLER, S. (2006). Mining wordnet for fuzzy sentiment : Sentiment tag
extraction from wordnet glosses. In EACL, volume 6.

AUE, A. et GAMoN, M. (2005). Customizing sentiment classiﬁers to new domains : A case study.
In Recent Advances in Natural Language Processing.

BEN—DAV'ID, S., BLITZER, J., CRAMMER, K. et PEREIRA, E (2007). Analysis of representations for
domain adaptation. Advances in neural information processing systems, 19:137.

BENAMARA, F., CEsARANo, C., P1cAR1ELLo, A., REFORGIATO, D. et SUBRAHMANIAN, V (2007). Senti-
ment analysis : Adjectives and adverbs are better than adjectives alone. In ICWSM.

BENVENISTE, E. (1966). Problemes de linguistique ge’ne’rale I. Gallimard.

BICKEL, S., BRI"JcKNER, M. et SCHEFFER, 'I'. (2007). Discriminative learning for differing training
and test distributions. In 24th international conference on Machine learning. ACM.

BLAIR-GoLDENsoHN, S., HANNAN, K, McDoNALD, R., NEYLON, T., RE1s, G. et REYNAR, J. (2008).
Building a sentiment summarizer for local service reviews. In WWW Workshop on NLP.

BLITZER, J., DREDZE, M. et PEREIRA, F. (2007). Biographies, bollywood, boom-boxes and blenders :
Domain adaptation for sentiment classiﬁcation. In Annual Meeting of the ACL.

BLITZER, J., FOSTER, D. et KAKADE, S. (2011). Domain adaptation with coupled subspaces.
Journal of Machine Learning Research - Proceedings Track, 15: 173-181.

BLITZER, J., MCDONALD, R. et PEREIRA, F. (2006). Domain adaptation with structural correspon-
dence learning. In EMNLP.

CHo1, Y. et CARDIE, C. (2009). Adapting a polarity lexicon using integer linear programming for
domain-speciﬁc sentiment classiﬁcation. In EMNLP.

DANG, Y., ZHANG, Y. et CHEN, H. (2010). A lexicon enhanced method for sentiment classiﬁcation :
An experiment on online product reviews.

DAUME, H. (2007). Frustratingly easy domain adaptation. In Annual Meeting of the ACL.

DENECKE, K. (2009). Are sentiwordnet scores suited for multi-domain sentiment classiﬁcation ?
In International Conference on Digital Information Management.

EsUL1, A. et SEBASTIANI, E (2006). Sentiwordnet : A publicly available lexical resource for
opinion mining. In LREC.

FERRARI, S., CHARNo1s, T., MATHET, Y., RIOULT, F‘. et LEGALLOIS, D. (2009). Analyse de discours
évaluatif, modéle linguistique et applications. RN'I'I, E-17:71-93.

GINDL, S., WEICHSELBRAUN, A. et SCHARL, A. (2010). Cross-domain contextualisation of sentiment
lexicons. European Conference on Artificial Intelligence.

GUPTA, R. et SARAwAG1, S. (2009). Domain adaptation of information extraction models. ACM
SIGMOD Record, 37(4):35—40.

HARB, A., DRAY, G., PLANTIE, M., PONCELET, P., ROCHE, M., TROUSSET, F. et al. (2008). Détection
d’opinion : Apprenons les bons adjectifs! Atelier FOuille des Donne’es d’OPinions.

HATZIVASSILOGLOU, V et McKEowN, K. (1997). Predicting the semantic orientation of adjectives.
In EACL.

HOFFMAN, J., SAENKO, K., KUL1s, B. et DARRELL, T. (2011). Domain adaptation with multiple
latent domains. In NIPS Domain Adaptation Workshop.

JIJKOUN, V, RIJKE, M. et WEERKAMP, W. (2010). Generating focused topic-speciﬁc sentiment
lexicons. In Annual Meeting of the ACL.

189

KIM, S. et Hovv, E. (2005). Automatic detection of opinion bearing words and sentences. In
International Joint Conference on Natural Language Processing, pages 61-66.

KUDo, T. et MATSUMOTO, Y. (2004). A boosting algorithm for classification of semi-structured
text. In EMNI.P.

LI, S., HUANG, C. et ZoNG, C. (2011). Multi-domain sentiment classification with classifier
combination. Journal of Computer Science and Technology, 26:25-33.

1.1, S. et ZoNG, C. (2008). Multi-domain sentiment classiﬁcation. In Annual Meeting of the ACL.

MANSOUR, Y., MOHRI, M. et ROSTAMIZADEH, A. (2009). Domain adaptation : Learning bounds
and algorithms. In Conference on Learning Theory.

NAVIGLI, R. (2009). Word sense disambiguation : A survey. ACM Computing Surveys.

PAN, S., N1, X., SUN, J., YANG, Q. et CHEN, Z. (2010). Cross-domain sentiment classiﬁcation via
spectral feature alignment. In International Conference on World Wide Web.

PANG, B. et LEE, L. (2008). Opinion mining and sentiment analysis. Foundations and Trends in
Information Retrival, 2: 1-2.

PANG, B., LEE, L. et VAITHYANATHAN, S. (2002). Thumbs up? : sentiment classification using
machine learning techniques.

PUPIER, P. (1998). Une premiere systématique des évaluatifs en francais. Revue québécoise de
linguistique, 26(1).

QIU, G., LIU, B., BU, J. et CHEN, C. (2009). Expanding domain sentiment lexicon through double
propagation. In International Joint Conference on Artificial Intelligence.

QIU, G., LIU, B., BU, J. et CHEN, C. (2011). Opinion word expansion and target extraction
through double propagation. Computational Linguistics, 37:9-27.

RILOFF, E. et WIEBE, J. (2003). Learning extraction patterns for subjective expressions. In
EMNLP.

SATPAL, S. et SARAWAGI, S. (2007). Domain adaptation of conditional probability models via
feature subsetting. In Knowledge Discovery in Databases : PKDD.

TABOADA, M., BROOKE, J., To1=1LosK1, M., VoLL, K. et STEDE, M. (2011). lexicon-based methods
for sentiment analysis. In Computational linguistics.

TAKAMURA, H., INU1, T. et OKUMURA, M. (2005). Extracting semantic orientations of words using
spin model. In ACL.

TURNEY, F! et LITTMAN, M. (2002). Unsupervised learning of semantic orientation from a
hundred-billion-word corpus. Erb-1094, Institute for Information Technology, Canada.
TURNEY, 1?, LITTMAN, M. et al. (2003). Measuring praise and criticism : Inference of semantic
orientation from association. In ACM Transactions on Information Systems.

VERNIER, M., MoNcEAUx, L. et DAILLE, B. (2010). Learning subjectivity phrases missing from
resources through a large set of semantic tests. In LREC.

VERNIER, M., MoNcEAUx, L. et DUBREIL, E. (2009). Catégorisation sémantico-discursive des
évaluations exprimées dans la blogosphére. In TALN.

WILSON, 'I'., WIEBE, J. et HOFFMANN, P. (2009). Recognizing contextual polarity : An exploration
of features for phrase-level sentiment analysis. Computational Linguistics, 35:339-433.
YosH1DA, Y., HIRAO, T., IWATA, T., NAGATA, M. et MATSUMOTO, Y. (2011). Transfer learning
for multiple-domain sentiment analysis - identifying domain dependent/ independent word
polaritys. In Porceedings ofAAAI.

190

— le premier niveau n’implique pas l’expression d’une évaluation. Il témoigne simplement du
degré de présence de l’énonciateur dans son énoncé. Cette présence peut étre implicite ou bien
explicite en fonction de la présence ou l’absence de certains marqueurs;

— le second niveau est celui des évaluations exprimées par l’énonciateur. Elles se caractérisent
par la présence d’un prédicat exprimant l’évaluation. Ce prédicat peut avoir ou non une valeur
axiologique (positif, négatif, neutre...)

C’est ce deuxiéme niveau qui nous intéresse ici. Il est cependant parfois difﬁcile de distinguer les
deux niveaux de subjectivité et cela peut amener a des erreurs de classiﬁcation.

2.2 Différences d’expression selon les domaines ou les niveaux de langage

Selon le sujet d’un texte, ce ne sont pas les mémes mots de vocabulaire qui sont employés.
On pourrait cependant penser que les expressions d’évaluation sont universelles. En effet,
certains mots et certaines structures reviennent avec régularité tels que "j’adore" ou bien "je
le déconseille". De plus, les dictionnaires notent que certains mots sont péjoratifs ("avare"),
d’autres, au contraire, mélioratifs ("généreux"). Ainsi, selon (Pupier, 1998), i1 y a des mots ‘a
valeur intrinsequement positive ("généreux, délicieux") et d’autres a valeur intrinsequement
négative ("avare, mauvais"). D’autres mots semblent en revanche neutres : "table" est l’exemple
classiquement donné par les linguistes. On parle ici d’orientation a priori.

Néanmoins, ‘a cété de mots intrinsequement positifs ou négatifs, il existe des mots dont
l’orientation peut changer selon le contexte dans lequel ils sont employés (Riloff et Wiebe, 2003).
Il peut s’agir de mots polysémiques ou bien d’homonymes ayant des axiologies différentes. C’est
le cas du "navet" qui est un légume tout ‘a fait ordinaire en cuisine mais un ﬁlm ‘a éviter des
lors que l’on parle de cinéma. La désarnbiguisation lexicale (savoir quel sens est effectivement
utilisé) s’appuie justement sur les mots du contexte. Les méthodes existantes utilisent des corpus,
annotés ou non, ainsi que des dictionnaires inventoriant les sens existant (Navigli, 2009).
L’orientation d’un mot non polysémique peut également changer ‘a l’intérieur d’un méme
domaine, selon l’objet qu’il évalue. Par exemple pour un ordinateur portable, une batterie
"large" est un inconvénient mais un écran "large" est un atout. L’orientation des mots peut aussi
dépendre des préférences et de l’idéologie de l’auteur et c’est alors bien plus difﬁcile a détecter.
Les textes politiques sont notamment tres sensibles ‘a cela. Par exemple, le mot "bourgeois"
est fondé sur une sémantique neutre mais quand il s’agit de préjugé ou d’opinion, ce qui est
"bourgeois" est souvent mal vu.

Un probleme proche de l’adaptation au domaine est l’adaptation au niveau de langage.
On retrouve un vocabulaire différent selon les niveaux mais aussi des mots communs qui
changent de polarité ("C’est terrible !, C’est mortell"). Ces inversions de sens peuvent étre
exuémement fortes comme le mot "bad" qui signiﬁe exactement le contraire de son sens littéral
dans le domaine du blues a une certaine époque.

Dans la prochaine partie, nous allons voir que les méthodes classiques pour obtenir des

lexiques et des classiﬁeurs d’opinions ne sont pas toujours adaptées pour prendre en compte le
changement de vocabulaire induit par le changement de domaine.

179

3 Les problémes d’adaptation des ressources et des classi-
ﬁeurs classiques

Cette partie se focalise sur les problémes d’adaptation des ressources et des classiﬁeurs classiques.
Pour obtenir plus de détails sur les méthodes de construction classiques, le lecteur se référera a
(Pang et Lee, 2008).

3.1 Les ressources

Pour la constitution de ressources, on distingue deux grandes familles d’approches. La premiére
consiste a utiliser des dict1'onnaires.A partir d’un peﬁt ensemble de mots, appelés mots racines,
le lexique est étendu en utilisant les relations de synonymie et d’antonymie (Kim et Hovy, 2005;
Esuli et Sebastiani, 2006) cu bien les déﬁnitions (Andreevskaia et Bergler, 2006). La seconde
consiste ‘a s’appuyer sur un corpus. Le lexique de mots racines est étendu en s’appuyant sur
plusieurs indices comme les conjonctions et/mais (Hatzivassiloglou et McKeown, 1997), la
cooccurrence entre mots('Iurney et Littrnan, 2002) ou la proximité des contextes d’évaluation
(Turney et al., 2003). Il existe également des approches mixtes, combinant l’utilisation de corpus
et de dictionnaires (Taboada et al., 2011) ou bien de patrons d’extraction (Riloff et Wiebe, 2003).

Les lexiques obtenus en utilisant des dictionnaires ne sont pas spécifiques ‘a un domaine mais
leur couverture est souvent faible et ils sont pour la plupart limités au sens a priori des mots,
c’est-a-dire hors contexte. Les méthodes ‘a base de corpus sont quant a elles applicables ‘a tous
les corpus, quel que soit leur domaine. Cependant, le lexique ﬁnalement appris dépendra du
domaine du lexique utilisé. Enﬁn, les patrons d’extraction sont longs et coﬁteux a créer. De plus,
les résultats nécessitent souvent un nettoyage manuel avant d’étre réellement exploitables.

3.2 Les classifieurs

En ce qui conceme la création de classiﬁeurs pour l’axiologie positive/négative, on distingue
également deux approches principales. La premiere consiste ‘a utiliser principalement des
lexiques et des indices linguistiques (Takamura et al., 2005; Ferrari et al., 2009). La seconde
consiste ‘a utiliser des données d’apprentissage aﬁn de construire un classiﬁeur statistique. Le
type de classiﬁeur a moins d’importance que les traits utilisées qui peuvent étre des n-grammes
(Pang et aL, 2002), des arbres de relations syntaxiques (Kudo et Matsumoto, 2004), tous les mots
ou bien certains mots parﬁculiers comme les adjectifs et les adverbes (Benamara et al., 2007).

Les classiﬁeurs développés ‘a partir de ressources générales ont plusieurs défauts. En ef-
fet ces ressources sont trop générales et ne captent pas la spéciﬁcité des domaines. Par exemple,
(Denecke, 2009) teste les score du lexique général SentiWordNet dans la tache de classiﬁcation
des opinions sur six corpus différents. Leurs classifieurs statistiques mono-domaines ont de
bien meilleurs résultats que les classiﬁeurs ‘a base de regles utilisant uniquement les mots de
SentiWordNet. Un autre probléme des ressources générales est que certains mots a priori positifs
ou négatifs peuvent en réalité étre employés dans des contextes neutres voire de polarité opposée
(Wilson et al., 2009). Quant aux classiﬁeurs développés sur un domaine par11'culier, les utiliser

180

directement sur d’autres domaines donne en général de mauvais résultats. Par exemple, dans
(Aue et Gamon, 2005), les auteurs comparent des classiﬁeurs entrainés sur quatre domaines
différents. Leurs résultats montrent que l’ut1'lisation d’un classifieur entrainé sur un domaine
source différent du domaine cible fait perdre entre 2 et 38 % d’exactitude (accuracy).

4 Ressources et techniques pour 1’adaptation au domaine

Aﬁn de surmonter les défauts de performance des méthodes classiques, la premiere possibilité est
de s’attacher ‘a développer des ressources générales plus performantes (section 4.1). Le but est
d’obtenir une performance acceptable sur tous les domaines ou, au moins, sur un grand nombre
de domaines. Une autre possibilité est de développer des méthodes permettant, a moindre coﬁt,
d’adapter automatiquement une ressource générale a un domaine particulier (section 4.2). Enﬁn,
lorsque l’on dispose déja de ressources ou d’outils adaptés a un domaine par11'culier, on peut les
adapter a un domaine proche (section 4.3).

4.1 Améliorer les performances des classifieurs généraux

Comme nous l’avons vu précédemment, les lexiques d’opinion généraux donnent des scores
de polarité a priori. Or cet a priori change selon le contexte et il faudrait disposer de lexiques
capables d’en rendre compte.

Il existe un ﬂou sur ce qu’on appelle le contexte d’un mot d’opinion : cela peut aller de la cible
directe de l’opinion (Jijkoun et al., 2010) ‘a un sac de mots représentant le theme abordé (Li et
Zong, 2008). Un lexique donnant des scores différents selon l’étiquette grammaticale du mot,
comme SentiWordNet, peut étre considéré comme faiblement contextuel (Dang et aL, 2010). On
peut également imaginer des lexiques d’opinion généraux bien plus fortement contextuels. Par
exemple, (Gindl et al., 2010) créent tout d’abord deux lexiques contextuels et valués sur deux
corpus A et B. Ils déterminent ensuite pour quels termes l’ajout du contexte a été utile, nocif ou
neutre pour A et B. Les résultats obtenus grace au lexique contextuel sont ainsi comparés a ceux
obtenus grace au lexique non-contextuel. Ils ne gardent ensuite que les termes contextuels qui
sont soit utiles soit neutres sur les deux domaines a la fois, créant ainsi un lexique contextuel qui
donne de bon résultats sur plusieurs domaines.

(Wilson et al., 2009) ne créent pas un lexique contextuel, mais utilisent les relations déduites
d’arbres de dépendance syntaxiques afin de tempérer les informations apportées par les
orientations des mots a priori.

Une autre carence des lexiques d’opinion généraux classiques est de manquer souvent
d’expressions polylexicales. Les mots simples sont les plus faciles 21 repérer mais ils ne sufﬁsent
pas a capter la richesse de l’expression de l’opinion dans la langue. Certaines expressions
polylexicales sont méme intégralement composées de mots qui ne sont pas eux méme évaluatifs,
par exemple "un coup de bol" ou bien "une bouffée d’air frais". C’est pourquoi des lexiques
exhaustifs sont trés difﬁciles a constituer.

Les travaux de (Vernier et al., 2010) utilisent des marqueurs d’intensité (comme "trés") pour
paJlier ce manque. Ils ont en effet observé que ces marqueurs s’appliquaient le plus souvent a des
expressions subjectives. Ils utilisent donc des requétes Yahoo pour sélectionner les candidats
qu’ils séparent ensuite entre objecﬁf et subjectif a l’aide d’un SVM. Ils ont évalué manuellement

181

l’efficacité de ce nouveau lexique par rapport a un lexique de base sur un corpus de blog qui
mélangeait des textes de domaines différents. Ils observent un gain de 15,6% en précision par
rapport au lexique de base pour la détection de fragments subjectifs.

Enﬁn, si on veut utiliser des classiﬁeurs fondés uniquement sur des méthodes d’appren-
tissage statistique tout en étant les plus généraux possible, il faut des données d’apprentissage
venant du plus grand nombre de domaines possible. En effet, quand on a un peu de données
annotées dans plusieurs domaines, on peut faire en sorte que les domaines s’aident les uns
les autres. C’est ce qu’on appelle de l’apprentissage multitaches. Dans ce cadre, fusionner les
classiﬁeurs fonctionne mieux que fusionner directement les données d’apprentissage (Li et Zong,
2008; Li et al., 2011). La fusion la plus efficace dans ces travaux est réalisée par la somme
pondérée des résultats des différents classiﬁeurs, les poids de cette somme étant appris sur un
petit corpus de développement du domaine cible.

Cette approche donne un classiﬁeur donnant de bons résultats sur plusieurs domaines si l’on
dispose d’un peu de données annotées pour tous. Néanmoins, il est impossible de garantir des
résultats pour des domaines complétement nouveaux.

4.2 Passer automatiquement du général au particulier

Les lexiques d’opinion généraux peuvent étre adaptés ‘a un domaine particulier en utilisant les
méthodes d’expansion classiques sur un corpus sélectionné pour étre thématique. C’est le cas de
(Harb et al., 2008) qui extraient automatiquement du Web un corpus thématique en utilisant des
requétes du type << +opinion +cinema +good -bad -poor -nasty  >>. Ils extraient ensuite les
adjectifs porteurs d’opinion en mesurant la cooccurrence dans les phrases entre les adjectifs
candidats et les mots racines du lexique initial.

The Double Propagation method, décrite dans (Qiu et al., 2009, 2011), peut étre utilisée pour
trouver de nouveaux mots d’opinion associés ‘a leur cible sur un corpus particulier. Elle permet
‘a la fois de découvrir les mots d’opinion et leurs cibles grace ‘a un processus d’amorcage
(bootstrap). Les travaux se fondent sur la reconnaissance des relations grammaticales reliant
les mots d’opinion et leur cible. Ces relations sont décrites au préalable manuellement. Lors
de l’expansion, les relations sont détectées ‘a l’aide d’un analyseur en dépendances. Ainsi, ‘a
par11'r d’un lexique d’opinion général on augmente d’une part les cibles détectées et d’autre part
le lexique de mots d’opinion en utilisant les relations une fois dans un sens et une fois dans l’autre.

Une autre maniére d’adapter un lexique général ‘a un domaine particulier est non pas
de l’étendre mais de le restreindre. C’est ce que font (Jijkoun et al., 2010) dans leurs travaux. Ils
réalisent une détection de relations syntaxiques afin d’associer ‘a chaque mot du vocabulaire
général un certain nombre de candidats pouvant étre la cible de l’opinion. Ils font l’hypothése
que les cibles des opinions sont plus diverses que les autres éléments syntaxiquement liés ‘a un
terme d’opinion et ne retiennent donc que les mots cibles ayant un fort score d’entropie.

Enfin, sans étendre ou restreindre le vocabulaire, on peut juste vouloir adapter au do-
maine le score de polarité des mots contenus dans le lexique général. C’est par exemple le cas
dans les travaux de (Choi et Cardie, 2009). A l’aide d’une formulation en probleme linéaire en
nombres entiers, ils exploitent les relations entre les mots d’une méme expression et les mots et
la polarité des expressions qui les contiennent aﬁn d’adapter la polarité a priori des mots.

182

4.3 Faciliter l’adaptation d’un domaine a un autre

Lorsqu’on utilise des algorithmes d’apprentissage, on présuppose généralement que les données
d’entrainement ont la méme distribution que les données de test. En pratique, cela n’est pas le
cas. On ne peut bien sﬁr pas espérer obtenir de bons résultats si les distributions des données
sources et cibles différent de maniére trop importante. Cependant, si elles ne sont que légérement
différentes, l’apprenu'ssage peut étre efﬁcace.

4.3.1 Mélanger les corpus ou les traits

Si l’on dispose d’un corpus annoté suffisamment grand, la méthode donnant les meilleurs
résultats repose, de facon naturelle, sur un entrainement direct sur les données du domaine. En
revanche, dans le cas o1‘1l’on ne dispose pas de données annotées, il devient utile de s’entrainer
sur d’autres corpus. Dans (Yoshida et al., 2011), les auteurs étudient l’inﬂuence du nombre de
domaines source et cible, allant jusqu’a quatorze domaines différents. Plus le nombre de corpus
source est élevé, plus les résultats sur un corpus cible différent sont bons. De plus, leur modéle
probabiliste génératif permet de déterminer si la polarité inférée pour un certain mot dépend
ou non du domaine du texte o1‘1 se trouve le mot. Ainsi, ils construisent automatiquement des
dictionnaires valués pour chaque domaine.

Aﬁn de s’adapter plus précisément au domaine cible, des poids peuvent étre attribués aux
exemples (Bickel et al., 2007) ou aux traits (Satpal et Sarawagi, 2007). Ces méthodes s’appliquent
également a l’ext1'act1'on d’informau'on générale (Gupta et Sarawagi, 2009).

Un probléme peut se poser lorsque les corpus sont hétérogénes et couvrent plusieurs
domaines. Dans le domaine de la classification d’image, (Hoffman et al., 2011) s’attaquent
au probléme de plusieurs domaines sources dont on ne connait pas a priori les étiquettes. Ils
séparent d’abord les domaines sources a l’aide d’une variante de l’algorithme des k-means avant
de poursuivre plus classiquement en combinant les classifieurs appris sur les domaines ainsi
séparés. A notre connaissance, il n’y a pas de travaux en classification d’opinion traitant ce
probléme particulier.

4.3.2 Domaine de représentation commune

Une autre approche est d’essayer de détecter des pivots, des structures communes entre deux
domaines. La méthode développée dans (Blitzer et al., 2006), le Structural Correspondance
Learning (SCL) se fonde sur la recherche de pivots entre les deux domaines permettant de
comparer les histogrammes de répartition des différents termes des domaines. Elle est motivée
par un algorithme d’apprenu'ssage multitaches, ASO (Alternating Structural Optimization),
proposé par (Ando et Zhang, 2005). Cette méthode a été appliquée ‘a la recherche d’opinion
dans (Blitzer et al., 2007), travaux que nous reproduisons dans la partie 5. Les pivots sont ici
des mots fréquents utiles ‘a la déterrnination de l’opinion dans le domaine source annoté. Des
classifieurs pivots sont créés qui permettent de comparer les distributions des autres mots par
rapport ‘a ces mots pivots. Ce sont les projections de ces distributions qui deviennent les traits
représentatifs des textes.

Dans (Blitzer et al., 2011), les auteurs s’intéressent plus spéciﬁquement au cas o1‘1les supports

183

des domaines source et cibles (l’ensemble des mots qui apparaissent dans chaque domaine) ont
peu de mots en commun. Les cooccurrences entre les termes des domaines source et cible ne
sont donc pas uniquement apprises par rapport ‘a des mots pivots communs au deux domaines
mais également par rapport a des mots spéciﬁques a un seul domaine.

Un travail plus récent ‘a ce sujet est celui de (Pan et al., 2010). Ils se servent également
comme pivots de mots indépendants du domaine sélectionné pour leur fréquence dans le
domaine cible et leur information mutuelle par rapport aux étiquettes du corpus source. Ils
construisent ensuite un graphe bipartite de corrélation entre les traits pivots et les traits
non-pivots. Puis ‘a l’aide d’algorithmes de clustering spectral, ils créent des clusters entre des
traits dépendants des domaines source et cible. Ils obﬁennent ainsi un espace de représentation
commun aux deux domaines. Les résultats obtenus dans (Pan et al., 2010) montre que la
méthode SFA obtient de meilleurs résultats en exactitude que d’autres méthodes, dont SCL.

Plusieurs travaux mettent également en lumiere que lorsque l’on peut disposer en plus
d’une petite partie annotée du corpus cible, cela permet d’améliorer les résultats de maniere
conséquente (Daumé, 2007; Blitzer et al., 2007; Aue et Gamon, 2005).

4.3.3 Comment évaluer la transportabilité d’un domaine a un autre ?

Tous les travaux étudiant la portabilité d’un domaine ‘a un autre font état de domaines plus
semblables pour lesquels le transfert se passe mieux (Denecke, 2009; Blitzer et al., 2007; Aue et
Gamon, 2005). La question de savoir comment mesurer la proximité de deux domaines devient
donc centrale.

Dans (Ben-David et al., 2007), les auteurs développent une borne supérieure pour l’er-
reur de généralisation d’un classiﬁeur entrainé sur un domaine source et testé sur un domaine
cible. Cette borne comprend deux termes variables. Le premier est l’erreur effectuée sur le
domaine source. Le second est une mesure de la divergence entre les distributions des domaines
sources et cibles sous une certaine représentation. Selon la représentation choisie pour les textes
(unigrammes, bigrammes, r6les sémantiques...), les distributions des traits seront différentes.
Par conséquent, la divergence entre les deux domaines dépend de la représentation choisie.
En choisissant une représentation tres simpliﬁée, on peut rendre la divergence entre les deux
domaines faible. Mais alors, l’erreur effectuée sur le domaine source sera tres grande. Il faut
donc choisir avec soin la représentation des textes pour obtenir une divergence faible entre les
deux domaines tout en conservant une erreur raisonnable sur le domaine source.

Une fois la représentation déﬁnie, se pose le probleme de calculer la divergence des deux
distributions. Une mesure naturelle serait la distance L1 ou variationnelle. Cependant, cette
distance n’est pas calculable ‘a par11'r d’un corpus fini pour des distributions ‘a valeur réelle.
C’est pourquoi (Ben-David et al., 2007) utilisent ce qu’ils appellent la A-distance. I1 s’agit d’une
restriction de la distance variationnelle a une collection A d’ensembles de textes issus des corpus
de facon ‘a ce que chaque élément de A soit mesurable sous les deux distributions. On ob-
tient ainsi une borne supérieure calculable pour l’erreur de généralisation du classiﬁeur considéré.

D’un point de vue pratique, calculer la A-distance a l’aide de données réelles est comme entrainer
un classiﬁeur pour départager les textes selon s’ils appartiennent au domaine source ou cible.

184

La A-distance fonctionne pour une classiﬁcation de type 0/ 1. Les travaux de (Mansour
et al., 2009) introduisent la discrepancy distance qui peut également étre utilisée pour comparer
des distributions dans le cadre d’une tache de régression.

5 Pistes de recherche et travaux préliminaires

Notre theme de recherche concerne l’adaptation au domaine pour la fouille d’opinion et la
constitution automatique de lexiques pour ce probleme. Les travaux cherchant ‘a projeter deux
corpus de domaines différents dans un espace commun semblent prometteurs. Aussi, nous nous
sommes attachés a reproduire les travaux présentés dans (Blitzer et al., 2007). Get article décrit
une heuristique pour l’adaptation au domaine appelé Structural Correspondanoe Learning (SCL).
SCL utilise des données non-étiquetées provenant de deux domaines différents aﬁn de détecter
des correspondances de comportement entre des traits spéciﬁques au domaine source et des
traits spéciﬁques au domaine cible.

5.1 Description de la méthode SCL

Pour réaliser leur étude, les auteurs ont constitué des corpus thématiques ‘a partir de critiques
collectées sur le site internet Amazon. Ils ont utilisé quatre corpus thématiques, DVDs, kitchen,
electronics et books. Les critiques sont représentées en sac de mots en utilisant les unigrammes et
les bigrammes présents. Grace au nombre d’étoiles attribuées aux critiques, les auteurs se sont
assurés que leurs corpus contiennent autant de critiques positives (quatre et cinq étoiles) que de
critiques négatives (une et deux étoiles). Les textes ayant obtenus trois étoiles n’ont pas été pris
en compte a cause de leur polarité ambigiie.

Les travaux des auteurs cherchent ‘a reproduire la situation réelle o1‘1 l’on dispose d’un grand
nombre de données non annotées a la fois pour le domaine cible et pour le domaine source,
mais seulement une petite partie de corpus source annoté. Aussi, lors de chaque experience,
on considere que l’on ne connait les étiquettes que de 2000 critiques du corpus source : 1000
positives et 1000 négatives.

L’idée de la méthode SCL est d’établir des correspondances entre des mots du domaine
source et des mots du domaine cible en fonction de leur comportement par rapport ‘a des
mots pivots communs aux deux domaines. Considérons le mot S qui n’apparait que dans
le corpus source et le mot C qui n’apparait que dans le corpus cible. Un classifieur usuel
entrainé sur le domaine source ne saura pas quoi faire de G. Mais si S et C, chacun dans
son corpus, co-occurrent avec les mots pivots communs de la méme facon, on peut suppo-
ser que C équivaut a S dans le domaine cible. Le classiﬁeur devra donc traiter C comme si c’était 5.

En pratique, la premiere étape est donc d’identiﬁer quels mots joueront le role de pi-
vots. les auteurs commencent par sélectionner un ensemble de traits qui apparaissent
fréquemment dans les deux domaines. Ces traits sont ensuite classés selon leur information
mutuelle par rapport aux classes positive et négative pour les 2000 critiques du corpus
source dont on connait la polarité. Seuls les 1000 plus informatifs sont conservés. Ces traits

185

pivots sont donc fréquents dans les deux domaines et relativement utile ‘a la tache de classiﬁ-
cation de l’opinion pour le domaine source (par exemple “a-must“, “loved-it“, “wea.k“, “awful“, etc.)

Une fois les traits pivots sélectionnés, les auteurs modélisent la corrélation entre tous
les traits des deux corpus et les traits pivots en entrainant pour chaque trait pivot un classiﬁeur
linéaire appelé classiﬁeur pivot. Ce classiﬁeur, appris sur l’ensemble des corpus source et cible,
répond ‘a la question : "Est-ce que le mot pivot considéré ‘a des chances d’apparaitre dans ce
texte sachant tous les autres mots du texte". Les vecteurs de poids de ces classiﬁeurs pivots sont
agrégés en une matrice. Celle-ci est ensuite réduite par décomposition en valeurs singuliére.
Les auteurs ne conservent que 50 dimensions. Ils obtiennent ainsi une matrice de projection
permettant de calculer 50 nouveaux traits (‘a valeur réelle) pour chaque texte source et cible.
Les textes du corpus source et cible sont représentés par un vecteur contenant a la fois les traits
initiaux (les unigrammes et bigrammes) et les nouveaux traits calculés ‘a l’aide de la matrice
de projection. C’est sur ces corpus étendus source et cible qu’un classifieur est entrainé et
testé. Les auteurs utilisent un classiﬁeur linéaire dont les coefﬁcients sont obtenus par descente
stochastique de gradient.

Par rapport a un classiﬁeur entrainé sur un domaine source et testé sur un domaine
cible sans rajouter les nouveaux traits, leur approche améliore souvent les performances (10 cas
sur 12). En une occasion, ils arrivent méme a dépasser les performances d’un classiﬁeur entrainé
et testé sur le domaine cible.

5.2 Nos travaux de reproduction

Nous utilisons deux des corpus constitués et utilisés par les auteurs : les corpus DVDs et
kitchen du Multi-Domain Sentiment Dataset. Le corpus source DVDs contient 5586 critiques et le
corpus cible kitchen 7945 critiques également réparties entre négatives et positives. Comme dit
précédemment, le domaine source contient 1000 critiques positives et 1000 critiques négatives
pour lesquelles on connait les étiquettes. En moyenne, les critiques du corpus kitchen contiennent
145 unigrammes et bigrammes, celles de DVDs, 269.

Nous avons étudié le sens d’adaptation de DVDs vers kitchen. Les références que nous
utilisons sont les suivantes : un classiﬁeur entrainé et testé sur le domaine source, un classiﬁeur
entrainé et testé sur le domaine cible et un classifieur entrainé sur le domaine source et testé
sur le domaine cible sans ajouter les traits obtenus par SCL. Nous comparons également nos
résultats avec ceux présentés dans (Blitzer et al., 2007).

Les tests effectués ont mis en valeur le fait que le choix des traits pivots inﬂuence énor-
mément les performances du classiﬁeur. Les résultats foumis par les auteurs sont des résultats
d’exactitude. Il nous a semblé intéressant d’étudier l’inﬂuence de la sélection des traits pivots sur
la performance en précision pour les deux classes.

Nous avons sélectionné des ensembles de 1000 traits pivots de trois facons différentes :

— sélection uniquement selon l’information mutuelle (MI) par rapport aux étiquettes du domaine

source;
— sélection uniquement selon la fréquence d’apparition dans les domaines source et cible;
— combinaison des deux critére précédent.

186

