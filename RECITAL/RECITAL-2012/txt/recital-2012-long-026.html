<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Extraction de PCFG et analyse de phrases pr&#233;-typ&#233;es</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 3: RECITAL, pages 205&#8211;218,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Extraction de PCFG et analyse de phrases pr&#233;-typ&#233;es
</p>
<p>No&#233;mie-Fleur Sandillon-Rezer
CNRS, Esplanade des Arts et M&#233;tiers, 33402 Talence
</p>
<p>LaBRI, 351 Cours de la Lib&#233;ration, 33405 Talence
nfsr@labri.fr
</p>
<p>R&#201;SUM&#201;
Cet article explique la cha&#238;ne de traitement suivie pour extraire une grammaire PCFG &#224;
partir du corpus de Paris VII. Dans un premier temps cela n&#233;cessite de transformer les arbres
syntaxiques du corpus en arbres de d&#233;rivation d&#8217;une grammaire AB, ce que nous effectuons en
utilisant un transducteur d&#8217;arbres g&#233;n&#233;ralis&#233; ; il faut ensuite extraire de ces arbres une PCFG.
Le transducteur d&#8217;arbres g&#233;n&#233;ralis&#233; est une variation des transducteurs d&#8217;arbres classiques et
c&#8217;est l&#8217;extraction de la grammaire &#224; partir des arbres de d&#233;rivation qui donnera l&#8217;aspect proba-
biliste &#224; la grammaire. La PCFG extraite est utilis&#233;e via l&#8217;algorithme CYK pour l&#8217;analyse de phrases.
</p>
<p>ABSTRACT
PCFG Extraction and Pre-typed Sentences Analysis
</p>
<p>This article explains the way we extract a PCFG from the Paris VII treebank. Firslty, we need to
transform the syntactic trees of the corpus into derivation trees. The transformation is done with
a generalized tree transducer, a variation of the usual top-down tree transducers, and gives as
result some derivation trees for an AB grammar. Secondely, we have to extract a PCFG from the
derivation trees. For this, we assume that the derivation trees are representative of the grammar.
The extracted grammar is used, via the CYK algorithm, for sentence analysis.
</p>
<p>MOTS-CL&#201;S : Extraction de grammaire, grammaire de Lambek, PCFG, transducteur d&#8217;arbre,
algorithme CYK.
</p>
<p>KEYWORDS: Grammar Extraction, Lambek grammar, PCFG, tree transducer, CYK Algorithm.
</p>
<p>205</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1 Introduction
</p>
<p>Cet article d&#233;crit les m&#233;thodes que nous employons pour transformer les arbres syntaxiques
du corpus de Paris VII en arbres de d&#233;rivation d&#8217;une grammaire AB (Lambek, 1958), pour
l&#8217;extraction de cette grammaire et son utilisation pour l&#8217;analyse de phrases. Les grammaires
AB sont utilis&#233;es dans des algorithmes d&#8217;apprentissage tels que celui de Buskowsky et Penn
(Buszkowski et Penn, 1990), qui permet d&#8217;apprendre une grammaire AB rigide 1, ou celui de
Kanazawa (Kanazawa, 1998), permettant d&#8217;apprendre une grammaire k-valu&#233;e 2 ; c&#8217;est pour cela
que nous avons souhait&#233;, dans un premier temps, utiliser de telles grammaires. Les grammaires
AB repr&#233;sentent un fragment des grammaires de Lambek, comprenant uniquement des r&#232;gles
de d&#233;rivation de type a&#8594; a/b b et a&#8594; b b\a. Le corpus de Paris VII (Abeill&#233; et al., 2003) est
compos&#233; de 12855 phrases tir&#233;es du journal Le Monde, annot&#233;es et analys&#233;es par le laboratoire
de Paris VII. Les arbres syntaxiques sont planaires, le nombre de fils par noeud et la profondeur
ne sont pas fix&#233;s. Cela rend l&#8217;application d&#8217;algorithmes d&#8217;apprentissage usuels impossible ; nous
avons donc pris le parti d&#8217;utiliser un transducteur d&#8217;arbres.
</p>
<p>Nous avons utilis&#233;, pour notre travail, une sous-partie du corpus, pr&#233;sent&#233;e sous forme parenth&#233;-
s&#233;e de 12351 phrases, alors que le corpus complet est au format XML. Les 504 phrases laiss&#233;es
de c&#244;t&#233; forment un corpus annexe dont nous nous servons pour l&#8217;&#233;valuation.
</p>
<p>En premier lieu, nous pr&#233;senterons le transducteur, utilis&#233; pour transformer les arbres syntaxiques
en arbres de d&#233;rivation, puis nous nous pencherons sur l&#8217;extraction d&#8217;une grammaire PCFG.
La troisi&#232;me partie d&#233;taillera l&#8217;analyse du placement des syntagmes pr&#233;positionnels dans la
phrase ; tandis que la quatri&#232;me pr&#233;sentera les r&#233;sultats exp&#233;rimentaux obtenus en utilisant notre
grammaire PCFG pour trouver la meilleure analyse possible pour une phrase via l&#8217;algorithme
CYK (Younger, 1967).
</p>
<p>2 Transducteur d&#8217;arbres g&#233;n&#233;ralis&#233;
</p>
<p>Ce n&#8217;est pas la premi&#232;re fois que les transducteurs sont utilis&#233;s dans le cadre de la linguis-
tique computationnelle ; on peut citer Knight et Graehl (Knight et Graehl, 2005), qui utilisent
des transducteurs d&#8217;arbres &#224; &#233;tats finis, dont h&#233;las l&#8217;utilisation ne correspondait pas &#224; notre
probl&#233;matique.
</p>
<p>Des travaux de recherche plus appliqu&#233;s, tels que (Hockenmaier et Steedman, 2007; Moot,
2010a,b; Moortgat et Moot, 2001), utilisent des algorithmes sp&#233;cialis&#233;s qui s&#8217;appliquent uni-
quement &#224; un corpus donn&#233;, avec un espoir faible de r&#233;utilisation. Etant donn&#233; les diff&#233;rences
d&#8217;annotations d&#8217;un corpus &#224; l&#8217;autre, et les variations grammaticales que l&#8217;on peut trouver entre
deux langues, adapter un outil pour le corpus de Paris VII est toujours particuli&#232;rement laborieux.
Etant donn&#233; que nous avons totalement s&#233;par&#233;, lors de l&#8217;impl&#233;mentation, le fonctionnement du
transducteur de l&#8217;ensemble des donn&#233;es qui lui sont pass&#233;es en entr&#233;e ( telles que les fichiers
de r&#232;gles et le corpus sous forme parenth&#233;s&#233;e), nous pensons qu&#8217;un lissage des donn&#233;es suffit &#224;
appliquer notre transducteur &#224; d&#8217;autres ensembles d&#8217;arbres.
</p>
<p>Le transducteur que nous avons cr&#233;&#233; est le pivot central du processus d&#8217;extraction de grammaire.
</p>
<p>1. Chaque mot du lexique n&#8217;a le droit d&#8217;avoir qu&#8217;un seul type.
2. Chaque mot du lexique peut avoir jusqu&#8217;&#224; k types.
</p>
<p>206</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>En effet, c&#8217;est la binarisation des arbres syntaxiques, fond&#233;e sur les r&#232;gles usuelles de d&#233;rivation
d&#8217;une grammaire AB 3 et les annotations morpho-syntaxiques du corpus (Abeill&#233; et Cl&#233;ment,
2003), qui param&#233;trise la grammaire extraite.
</p>
<p>Nous avons d&#8217;abord mis au point une version th&#233;orique de notre G-transducteur (G pour g&#233;n&#233;ra-
lis&#233;) avant de l&#8217;impl&#233;menter pour le tester sur le corpus de Paris VII.
</p>
<p>La cr&#233;ation du transducteur d&#8217;arbres est d&#233;crite en d&#233;tail dans (Sandillon-Rezer et Moot, 2011).
</p>
<p>En nous fondant sur les transducteurs d&#8217;arbres top-down d&#233;crits dans TATA (Comon et al., 2007),
nous avons g&#233;n&#233;ralis&#233; les r&#232;gles de transduction de mani&#232;re &#224; cr&#233;er un outil plus adapt&#233; au
corpus de Paris VII. Ainsi, on peut dire que les trois principales diff&#233;rences entre un transducteur
top-down classique et notre G-transducteur sont : sa r&#233;cursivit&#233;, sa param&#233;trisation et son syst&#232;me
de r&#232;gles de priorit&#233;.
</p>
<p>La r&#233;cursivit&#233; permet d&#8217;appliquer un ensemble de r&#232;gles &#224; un n&#339;ud, jusqu&#8217;&#224; ce qu&#8217;il soit trait&#233;
en entier, sans pour autant changer l&#8217;&#233;tat du transducteur ni utiliser un nouvel ensemble
de r&#232;gles de transduction (voir figure 1).
</p>
<p>La param&#233;trisation permet de d&#233;finir des r&#232;gles avec variables. Ainsi, on peut donner une
transduction g&#233;n&#233;rale pour les adverbes et les modificateurs (voir figure 2).
</p>
<p>Les r&#232;gles de priorit&#233; : assurent le d&#233;terminisme de notre transducteur. Ainsi, lorsque deux
r&#232;gles peuvent s&#8217;appliquer, on leur donne un ordre d&#8217;application qui permet d&#8217;avoir toujours
les m&#234;mes arbres de sortie (voir figure 3).
</p>
<p>P : x
</p>
<p>X1 . . . Xn Xn+1 . . . Xn+k &#8594;
</p>
<p>P : x
</p>
<p>P : y
</p>
<p>X1 . . . Xn
</p>
<p>T : z
</p>
<p>Xn+1 . . . Xn+k
</p>
<p>FIGURE 1 &#8211; Le nouveau n&#339;ud P : y a moins de fils qu&#8217;avant la transduction et pour le transducteur,
il restera dans le m&#234;me &#233;tat et avec le m&#234;me label que le n&#339;ud parent P :x . G&#233;n&#233;ralement, la
r&#232;gle sera &#233;crite de mani&#232;re &#224; ce que le sous arbre T :z soit binaire et les types y et z doivent
obligatoirement se combiner pour donner le type x .
</p>
<p>SENT : s
</p>
<p>. . . X &#8594;
</p>
<p>SENT : s
</p>
<p>SENT : s
</p>
<p>. . .
</p>
<p>X : s\ s
</p>
<p>FIGURE 2 &#8211; La m&#234;me r&#232;gle sera appliqu&#233;e pour X &#8712; {ADV, PP&#8722;MOD,AdP&#8722;MOD,AP&#8722;MOD, ...}
</p>
<p>3. les groupes nominaux auront le type np etc.
</p>
<p>207</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>SENT : s
</p>
<p>ADV . . . ADV &#8594;
</p>
<p>SENT : s
</p>
<p>ADV : s/s SENT : s
</p>
<p>. . . ADV
</p>
<p>FIGURE 3 &#8211; Lorsque plus d&#8217;une r&#232;gle peut s&#8217;appliquer &#224; un arbre, le fait de suivre un ordre pr&#233;d&#233;fini
permet d&#8217;&#233;viter le non-d&#233;terminisme du transducteur.
</p>
<p>Les r&#232;gles ont &#233;t&#233; d&#233;duites d&#8217;une analyse syst&#233;matique des formes pr&#233;sentes dans le corpus. Un
exemple de r&#232;gle est donn&#233; dans la figure 4 et un de r&#233;sultat dans la figure 5. Une fois le corpus
transform&#233; en for&#234;t d&#8217;arbres de d&#233;rivations, nous n&#8217;utilisons plus le transducteur, que ce soit pour
l&#8217;extraction de grammaire ou l&#8217;analyse de phrases.
</p>
<p>(rule
(SENT:* NP-SUJ (VN tree VPP) PP-OBJ)
(&quot;SENT:*&quot; &quot;NP-SUJ:np&quot;
</p>
<p>(&quot;VN:np\\*&quot; &quot;VN:(np\\*)/(np\\s_p)&quot;
(&quot;:np\\s_p&quot; &quot;VPP:(np\\s_)/pp&quot;
</p>
<p>PP-OBJ:pp))))
</p>
<p>FIGURE 4 &#8211; Exemple de r&#232;gle telle que donn&#233;e au transducteur. On note deux points importants,
directement d&#233;riv&#233;s des sp&#233;cifications de notre G-transducteur : le mot clef tree, qui permet de
remplacer &quot;un certain nombre de n&#339;uds&quot;, qui peut appara&#238;tre plusieurs fois dans le motif de
d&#233;part mais pas dans le motif de remplacement ; et le type *, qui remplace n&#8217;importe quel type
h&#233;rit&#233; des &#233;tapes pr&#233;c&#233;dentes.
</p>
<p>3 Extraction de grammaire
</p>
<p>M&#234;me si le lexique, r&#233;cup&#233;r&#233; &#224; partir des feuilles des arbres de d&#233;rivation, suffirait &#224; repr&#233;senter
la grammaire AB, il nous limite aux mots pr&#233;sents dans le corpus. Or, bien que nous puissions
avoir des probabilit&#233;s sur les types des mots, nous voulions une grammaire PCFG. Par cons&#233;quent,
nous avons pris le parti d&#8217;extraire une grammaire probabiliste &#224; partir des arbres.
</p>
<p>Les arbres en sortie du transducteur donnent des informations &#224; la fois syntaxiques, car nous
gardons les labels donn&#233;s par le corpus et, bien s&#251;r, des informations structurelles. Nous avons
pris le parti de laisser le choix des informations que nous souhaitons garder, en effectuant une
passe de pr&#233;traitement, sachant bien s&#251;r que les types sont, de toute fa&#231;on, obligatoirement
conserv&#233;s. La grammaire extraite sera de toute fa&#231;on une grammaire hors contexte, avec une
probabilit&#233; calcul&#233;e sur les r&#232;gles en fonction de leur racine. Pour plus de simplicit&#233;, on rappelle
que les grammaires sont de la forme {N , T,S,R} :
N l&#8217;ensemble des symboles non terminaux, correspondant aux n&#339;uds internes de l&#8217;arbre.
</p>
<p>T l&#8217;ensemble des symboles terminaux, correspondant &#224; l&#8217;ensemble des mots typ&#233;s.
</p>
<p>208</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>SENT
</p>
<p>NP-SUJ
</p>
<p>NPP
</p>
<p>Pohlmann
</p>
<p>VN
</p>
<p>V
</p>
<p>lancera
</p>
<p>NP-OBJ
</p>
<p>DET
</p>
<p>les
</p>
<p>NC
</p>
<p>demandes
</p>
<p>PP
</p>
<p>P
</p>
<p>de
</p>
<p>NP
</p>
<p>NC
</p>
<p>permis_de_construire
</p>
<p>PP-MOD
</p>
<p>P+D
</p>
<p>au
</p>
<p>NP
</p>
<p>NC
</p>
<p>mois
</p>
<p>PP
</p>
<p>P
</p>
<p>de
</p>
<p>NP
</p>
<p>NC
</p>
<p>janvier
</p>
<p>PONCT
</p>
<p>.
</p>
<p>TEXT t x t
</p>
<p>SENT s
</p>
<p>SENT s
</p>
<p>NP-SUJ np
</p>
<p>NP np
</p>
<p>NPP np
</p>
<p>Pohlmann np
</p>
<p>np\s
VN (np\s)/np
V (np\s)/np
</p>
<p>lancera (np\s)/np
</p>
<p>NP-OBJ np
</p>
<p>DET np/n
</p>
<p>les np/n
</p>
<p>NP n
</p>
<p>NC n
</p>
<p>demandes n
</p>
<p>PP n\n
P (n\n)/n
de (n\n)/n
</p>
<p>NP n
</p>
<p>NC n
</p>
<p>permis_de_construire n
</p>
<p>PP-MOD s\s
P+D (s\s)/n
au (s\s)/n
</p>
<p>NP n
</p>
<p>NC n
</p>
<p>mois n
</p>
<p>PP n\n
P (n\n)/n
de (n\n)/n
</p>
<p>NP n
</p>
<p>NC n
</p>
<p>janvier n
</p>
<p>PONCT s\t x t
. s\t x t
</p>
<p>FIGURE 5 &#8211; Arbre d&#8217;entr&#233;e et de sortie du transducteur correspondant &#224; la phrase &quot;Pholmann
lancera les demandes de permis de construire au mois de janvier.&quot;.
</p>
<p>S le symbole initial. On choisira, en fonction de la passe de pr&#233;-traitement, TXT :txt ou txt.
</p>
<p>R l&#8217;ensemble des r&#232;gles.
</p>
<p>L&#8217;algorithme utilis&#233; pour extraire la grammaire consiste &#224; parcourir les arbres donn&#233;s en pa-
ram&#232;tre et stocker les r&#232;gles de d&#233;rivation que l&#8217;on rencontre. On consid&#232;re qu&#8217;une r&#232;gle de
d&#233;rivation est constitu&#233;e d&#8217;une racine et d&#8217;un ou deux fils :
</p>
<p>La racine a deux fils : On est dans le cas de figure classique d&#8217;une r&#232;gle d&#8217;&#233;limination &#224; droite
ou &#224; gauche (a&#8594; a/b b ou a&#8594; b a\b).
</p>
<p>La racine a un seul fils : Il y a simplement transmission de type au fils. Ce cas de figure appara&#238;t,
par exemple, lorsqu&#8217;un groupe nominal est compos&#233; uniquement d&#8217;un nom propre, ou
encore lorsqu&#8217;on est au niveau du n&#339;ud pr&#233;-terminal, c&#8217;est &#224; dire l&#8217;&#233;tiquette de partie du
discours (POS-tag) de la feuille. Dans ce cas, la feuille h&#233;ritera directement du type du
POS-tag.
</p>
<p>Chaque r&#232;gle est accompagn&#233;e d&#8217;un compteur et les probabilit&#233;s sur les r&#232;gles sont calcul&#233;es par
groupe ayant la m&#234;me racine. On r&#233;cup&#232;re aussi des informations de profondeur minimale et
maximale d&#8217;apparition de la r&#232;gle, cependant elles ne sont pas utilis&#233;es pour l&#8217;instant.
</p>
<p>209</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ainsi, on r&#233;sume dans le tableau 1 les diff&#233;rentes grammaires que peut g&#233;n&#233;rer l&#8217;extracteur 4
</p>
<p>.Chacune des versions montre un int&#233;r&#234;t : autant la premi&#232;re, extraite des arbres juste apr&#232;s
transduction, garde les informations syntaxiques donn&#233;es par le corpus ; autant les suivantes sont
plus utiles pour appliquer un algorithme d&#8217;analyse de phrases, tel que CYK (voir section 4), sur
des phrases non typ&#233;es. Le tableau 2 montre des extraits des diff&#233;rentes grammaires en fonction
des arbres donn&#233;s en entr&#233;e.
</p>
<p>Forme des arbres R&#232;gles extraites Sp&#233;cifications Nombre de r&#232;gles
</p>
<p>Arbres de d&#233;rivation
bruts
</p>
<p>n1&#8594; n2 n3 Facilement normalisable
en FNC : il suffit
d&#8217;enlever les chaines
unaires
</p>
<p>63368
n1&#8594; n2
n1&#8594; t1
</p>
<p>Retrait des chaines
unaires et des labels
sauf les POS-tag
</p>
<p>n1&#8594; n2 n3 La grammaire est en
FNC.
</p>
<p>59505
n1&#8594; t1
</p>
<p>Retrait de tous les labels
et des chaines unaires. Il
n&#8217;y a plus de diff&#233;rence
entre N et T .
</p>
<p>n1&#8594; n2 n3 Les mots n&#8217;apparaissent
plus, ce qui laisse uni-
quement le squelette des
arbres.
</p>
<p>3494
</p>
<p>TABLE 1 &#8211; Grammaires extraites en fonction des arbres de d&#233;rivation donn&#233;s en entr&#233;e. On pr&#233;cise
que ni &#8712; N et t i &#8712; T .
</p>
<p>Arbres de d&#233;rivation bruts
</p>
<p>Exemple de r&#232;gles
NP :np&#8594; NPP :np 1.01x10&#8722;1
NP :np&#8594; DET :np/n NC :n 2.02x10&#8722;1
. . .
</p>
<p>Retrait des chaines unaires et des labels sauf les POS-tag
</p>
<p>Exemple de r&#232;gles
(np\si)/(np\sp)&#8594; VINF :(np\si)/(np\sp) 9.53x10&#8722;1
(np\s)/(np\sp)&#8594; CLR :clr clr\((np\s)/(np\sp)) 2.88x10&#8722;2
. . .
</p>
<p>Retrait de tous les labels et des chaines unaires
</p>
<p>Exemple de r&#232;gles
</p>
<p>s&#8594; np np\s 3, 81x10&#8722;1
s&#8594; s s\s 2, 65x10&#8722;1
s&#8594; np\sp (np\sp)\s 1, 13x10&#8722;3
n&#8594; n n\n 7, 97x10&#8722;1
np&#8594; np/n n 8, 02x10&#8722;1
. . .
</p>
<p>TABLE 2 &#8211; Exemples des diff&#233;rentes r&#232;gles que l&#8217;on peut extraire des arbres.
</p>
<p>4 Analyse de phrases
</p>
<p>La question de l&#8217;analyse de phrases en fonction d&#8217;une grammaire PCFG se subdivise en deux
probl&#232;mes. En effet, il faut d&#8217;une part trouver les types des mots et d&#8217;autre part que les r&#232;gles
</p>
<p>4. Les POS-tags sont les &#233;tiquettes de parties du discours.
</p>
<p>210</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>existent dans la grammaire pass&#233;e en param&#232;tre &#224; l&#8217;analyseur.
</p>
<p>4.1 Typages des mots
</p>
<p>En r&#233;unissant les feuilles des arbres de d&#233;rivation, nous pouvons collecter un lexique contenant
les mots, leur occurrence, les types de ceux-ci et la probabilit&#233; du type (nb_occurrences_du_type/
nb_occurrences_du_mot). Cependant, nous n&#8217;utilisons pas encore le lexique pour typer les phrases
que nous analysons. Il faudrait pourtant s&#233;lectionner les types apparaissant le plus souvent et
les lier aux mots. Cette technique n&#8217;assurerait pas l&#8217;analyse syst&#233;matique de la phrase, car si le
type n&#233;cessaire fait partie de ceux &#233;cart&#233;s, une phrase juste pourrait ne pas avoir d&#8217;analyse. Nous
avons pris le parti de typer les mots soit en utilisant le Supertagger ((Moot, 2010a,b)), soit en
utilisant les phrases typ&#233;es &#224; la sortie du transducteur. La premi&#232;re m&#233;thode nous permet &#224; la
fois de valider les types donn&#233;s aux mots par le Supertagger et d&#8217;analyser des phrases dont les
mots n&#8217;apparaissent pas dans le corpus de Paris VII, tandis que la seconde m&#233;thode nous permet
de tester nos diff&#233;rentes grammaires en fonction des arbres de d&#233;rivation. On peut aussi utiliser
un typage plus manuel, qui utilise le Supertagger pour effectuer une premi&#232;re passe de typage et
qui permet ensuite &#224; l&#8217;utilisateur de modifier &#224; loisir les types propos&#233;s.
</p>
<p>4.2 Analyse des phrases typ&#233;es
</p>
<p>Pour l&#8217;algorithme de reconstruction des phrases, nous avons d&#233;cid&#233; d&#8217;utiliser l&#8217;algorithme CYK
(Younger, 1967; Knuth, 1997; Hopcroft et Ullman, 1979) et d&#8217;en impl&#233;menter une version
probabiliste : en effet, &#233;tant donn&#233; que cet algorithme a d&#233;j&#224; &#233;t&#233; test&#233; et est une r&#233;f&#233;rence, il
nous a permis de tester l&#8217;efficacit&#233; de notre grammaire sans avoir &#224; s&#8217;inqui&#233;ter de l&#8217;efficacit&#233; de
l&#8217;algorithme. D&#8217;autres algorithmes auraient pu &#234;tre utilis&#233;s, tel que celui d&#8217;Earley (Earley, 1973),
cependant CYK demandait en entr&#233;e une grammaire tr&#232;s proche de celle que nous obtenions
apr&#232;s extraction. De plus, l&#8217;ajout de l&#8217;aspect probabiliste &#233;tait trivial sur cet algorithme. La seule
modification que nous avons effectu&#233;e &#233;tait de retirer la phase de typage des mots, initialement
effectu&#233;e par CYK gr&#226;ce aux r&#232;gles de type n1 &#8594; t t . Nous avons donc pu donc utiliser la
grammaire la plus simple, de 3494 r&#232;gles, pour analyser les phrases. Le premier test effectu&#233;,
pour savoir si l&#8217;algorithme fonctionnait correctement, a &#233;t&#233; d&#8217;analyser les phrases extraites des
arbres de d&#233;rivation avec les r&#232;gles provenant de ces m&#234;mes arbres. Nous avons ensuite pu tester
l&#8217;analyse avec des phrases typ&#233;es par le Supertagger ou notre transducteur et des grammaires
extraites soit du corpus de 12351 phrases, soit du corpus de phrases laiss&#233;es de c&#244;t&#233; (cf section
6).
</p>
<p>Les arbres de d&#233;rivation correspondants aux phrases &quot;Pourtant tout n&#8217;est pas gagn&#233;.&quot; et &quot;Ce
proc&#232;s gagn&#233; donne au Cr&#233;dit Lyonnais les coud&#233;es franches pour g&#233;rer MGM&quot; sont montr&#233;s
dans la figure 6 et 7. A chaque fois, on a pris les deux arbres les plus probables, typ&#233;s par
le Supertagger et les phrases ont &#233;t&#233; analys&#233;es avec la m&#234;me grammaire et l&#8217;algorithme CYK.
Deux informations sont int&#233;ressantes pour choisir quel est le meilleur arbre de d&#233;rivation sur
les phrases : on regarde &#224; la fois la complexit&#233; des types et la probabilit&#233;. Cependant, nous
sommes conscient qu&#8217;il est complexe de comparer deux arbres qui n&#8217;ont ni la m&#234;me structure,
ni les m&#234;mes feuilles. La pr&#233;f&#233;rence que l&#8217;on porte &#224; un r&#233;sultat sera fortement d&#233;pendante
des crit&#232;res de s&#233;lection donn&#233;s. Ainsi, sur la figure 6, on remarque que les deux arbres ont la
m&#234;me probabilit&#233;, cependant nous s&#233;lectionnons celui qui a l&#8217;indexation la plus faible pendant
</p>
<p>211</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>l&#8217;ex&#233;cution de CYK. Sur la seconde phrase (figure 7), c&#8217;est majoritairement l&#8217;attachement du
groupe pr&#233;positionnel final qui modifie la forme de l&#8217;arbre. L&#8217;attachement de la pr&#233;position &#224; un
groupe nominal est plus repr&#233;sentatif du corpus d&#8217;origine (voir section 5) .
</p>
<p>t x t
</p>
<p>s
</p>
<p>Tout np np\s
n&#8217; (np\s)/(np\s) np\s
</p>
<p>est (np\s)/(n\n) n\n
pourtant (n\n)/(n\n) n\n
</p>
<p>pas (n\n)/(n\n) gagn&#233; n\n
</p>
<p>. s\t x t
</p>
<p>t x t
</p>
<p>s
</p>
<p>Tout np np\s
(np\s)/(n\n)
</p>
<p>(np\s)/(n\n)
n&#8217; ((np\s)/(n\n))/((np\s)/(n\n)) est (np\s)/(n\n)
</p>
<p>pourtant ((np\s)/(n\n))\((np\s)/(n\n))
n\n
</p>
<p>pas (n\n)/(n\n) gagn&#233; n\n
</p>
<p>. s\t x t
</p>
<p>FIGURE 6 &#8211; Le premier arbre est g&#233;n&#233;r&#233; avec le typage du transducteur et a une probabilit&#233; de
9, 6x10&#8722;05 et le second est typ&#233; avec le Supertagger, avec une probabilit&#233; de 1,9x10&#8722;05
</p>
<p>5 Analyse des pr&#233;positions
</p>
<p>Nous allons nous focaliser sur l&#8217;analyse des syntagmes pr&#233;positionnels (PP, PP-MOD, PP-OBJ
etc.) et de l&#8217;attachement par rapport &#224; la phrase. Dans un premier temps, nous &#233;tudierons
l&#8217;attachement des groupes pr&#233;positionnels dans le corpus d&#8217;origine, puis nous nous focaliserons
sur les types des pr&#233;positions, via le transducteur et le Supertagger pour enfin nous pencher sur
l&#8217;attachement dans les arbres de d&#233;rivation g&#233;n&#233;r&#233;s via l&#8217;algorithme CYK.
</p>
<p>5.1 Attachement dans le corpus
</p>
<p>Les groupes pr&#233;positionnels sont particuli&#232;rement nombreux dans le corpus (49039 occurrences).
Comme nous pouvons le voir dans le tableau 3, ils sont majoritairement &#233;tiquet&#233;s PP. Leur
attachement de d&#233;part dans le corpus est aussi particuli&#232;rement important, car c&#8217;est celui-ci qui
d&#233;finira le type de la pr&#233;position. Le tableau 4 r&#233;sume la r&#233;partition des syntagmes pr&#233;positionnels
dans le corpus, en fonction de leur parent. En effet, la transduction aura tendance &#224; donner un
type aux syntagmes pr&#233;positionnels qui correspond &#224; leur place dans la structure de la phrase.
</p>
<p>212</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>t x t
</p>
<p>s
</p>
<p>np
</p>
<p>Ce np/n n
</p>
<p>proc&#232;s n gagn&#233; n\n
</p>
<p>np\s
</p>
<p>(np\s)/np
</p>
<p>donne (np\s)/np ((np\s)/np)\((np\s)/np)
</p>
<p>au (((np\s)/np)\((np\s)/np))/n Cr&#233;dit_Lyonnais n
</p>
<p>np
</p>
<p>les np/n n
</p>
<p>n
</p>
<p>coud&#233;es n franches n\n
</p>
<p>n\n
</p>
<p>pour (n\n)/(n\n) n\n
</p>
<p>g&#233;rer (n\n)/np MGM np
</p>
<p>. s\t x t
</p>
<p>t x t
</p>
<p>s
</p>
<p>s
</p>
<p>np
</p>
<p>Ce np/n n
</p>
<p>proc&#232;s n gagn&#233; n\n
</p>
<p>np\s
</p>
<p>(np\s)/np
</p>
<p>donne (np\s)/np ((np\s)/np)\((np\s)/np)
</p>
<p>au (((np\s)/np)\((np\s)/np))/n Cr&#233;dit_Lyonnais n
</p>
<p>np
</p>
<p>les np/n n
</p>
<p>coud&#233;es n franches n\n
</p>
<p>s\s
</p>
<p>pour (s\s)/(s\s) s\s
</p>
<p>g&#233;rer (s\s)/np MGM np
</p>
<p>. s\t x t
</p>
<p>FIGURE 7 &#8211; Probabilit&#233; du premier arbre : 2, 2x10&#8722;09. Probabilit&#233; du second arbre : 1, 5x10&#8722;09.
</p>
<p>Ainsi, dans un groupe nominal, le PP aura plus souvent le type n\n, alors qu&#8217;au milieu d&#8217;une
phrase le typage sera plus complexe. Lors de la transduction, on ne change pas l&#8217;ordre des mots,
mais quelques fois leur attachement au sein de la structure. Cependant, on peut dire que les
groupes pr&#233;positionnels ne bougent pas, sauf s&#8217;ils sont &#224; l&#8217;ext&#233;rieur d&#8217;un noyau verbal et que
celui-ci se termine par un VPP, auquel cas on lie plus sp&#233;cifiquement le participe pass&#233; au groupe
pr&#233;positionnel, comme on peut voir figure 4.
</p>
<p>Label occurrence Label occurrence Label occurrence
PP 32023 PP-MOD 11899 PP-DE_OBJ 1668
PP-A_OBJ 1565 PP-P_OBJ 1389 PP-ATS 323
PP-OBJ 130 PP-ATO 30 PP-SUJ 12
</p>
<p>TABLE 3 &#8211; Distribution des groupes pr&#233;positionnels en fonction de leur label.
</p>
<p>5.2 Typage des syntagmes pr&#233;positionnels
</p>
<p>Pour &#233;tudier le typage, nous nous sommes focalis&#233;s sur les groupes pr&#233;positionnels dont, bien
s&#251;r, la transduction avait r&#233;ussi. Cela fait tomber le nombre de syntagmes pr&#233;positionnels &#224;
45351 (92,5% du total). Les quatre familles de types les plus donn&#233;s (au dessus de 2000 fois)
par le transducteur sont r&#233;sum&#233;s dans le tableau 5. Ils couvrent 92,2% des types que l&#8217;on peut
trouver pour des pr&#233;positions. Les types restants, marginaux, correspondent, par exemple, &#224; un
syntagme pr&#233;positionnel contenant uniquement un pronom relatif, qui prend en argument une
</p>
<p>213</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Syntagme parent occurrence Label le plus courant pourcentage
Syntagme Nominal 24817 PP 99, 2%
Phrase compl&#232;te 8478 PP-MOD 72, 2%
Proposition rel. ou sub. 3833 PP-MOD 57, 9%
Proposition participiale 3552 PP 80, 1%
Proposition infinitive 3190 PP-MOD 63, 5%
Syntagme pr&#233;positionnel 843 PP 89, 2%
Noyau verbal 45 PP 88, 9%
</p>
<p>TABLE 4 &#8211; Distribution des groupes pr&#233;positionnels en fonction de leurs parents. On remarque
que les groupes nominaux sont ceux qui regroupent le plus de PP , c&#8217;est &#224; dire presque la moiti&#233;.
</p>
<p>subordonn&#233;e.
</p>
<p>Le typage effectu&#233; avant l&#8217;analyse via CYK, avec le Supertagger, nous permet de r&#233;gler la pr&#233;cision
que l&#8217;on souhaite sur les types : en effet, on peut r&#233;gler le param&#232;tre &#946; , qui d&#233;terminera le nombre
de types possibles autoris&#233;s par mot. On gardera alors les types ayant une probabilit&#233; sup&#233;rieure
ou &#233;gale &#224; &#946; fois la plus grande probabilit&#233; trouv&#233;e 5. Le tableau 6 r&#233;sume la justesse des types
donn&#233;s aux pr&#233;positions en fonction de &#946; . On remarque que ce sont des mots difficiles &#224; typer,
&#233;tant donn&#233; que les r&#233;sultats sont inf&#233;rieurs aux r&#233;sultats globaux, bien que les adverbes et les
verbes soient encore plus complexes &#224; typer de mani&#232;re exacte.
</p>
<p>Il faut cependant noter qu&#8217;il n&#8217;est pas n&#233;cessaire d&#8217;avoir une formule correcte pour que l&#8217;attache-
ment du syntagme pr&#233;positionnel dans la phrase soit correct.
</p>
<p>Famille de type occurrence
n\n ou np\np ou n\np 23901
a\a (ex. s\s) 8548
pp ou ppa ou ppd e 6486
a/a (ex. s/s) 2882
</p>
<p>TABLE 5 &#8211; Les quatre familles de types les plus courants correspondent &#224; un modificateur de
groupe nominal, un groupe pr&#233;positionnel g&#233;n&#233;ralement argument d&#8217;un groupe verbal et des
modificateurs de phrase, plac&#233;s au d&#233;but ou &#224; la fin de la phrase.
</p>
<p>&#946; pertinence des types pertinence globale
1.0 61, 0% 76,9%
0.1 83, 1% 87,0%
0.05 86, 2% 88,9%
0.01 90, 2% 91,7%
</p>
<p>TABLE 6 &#8211; Justesse du typage via le Supertagger.
</p>
<p>5. Plus &#946; est petit, plus il y a de types propos&#233;s et plus on a de chance de trouver le type qui se combinera avec ceux
des autres mots.
</p>
<p>214</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>5.3 Attachement des syntagmes pr&#233;positionnels dans les arbres reconsti-
tu&#233;s
</p>
<p>Pour cette partie, nous nous sommes focalis&#233;s sur 55 PP, que nous avons s&#233;lectionn&#233;s dans le
corpus d&#8217;origine, de mani&#232;re &#224; respecter le ratio pr&#233;sent&#233; dans le tableau 3. Cela correspond &#224; 21
phrases, dont l&#8217;analyse a r&#233;ussi. Nous avons g&#233;n&#233;r&#233; les types possibles avec &#946; = 0.05. Ensuite,
nous avons &#233;tudi&#233; la diff&#233;rence de types donn&#233;s aux pr&#233;positions ainsi que leur attachement.
On remarque, dans le tableau 7, que les syntagmes pr&#233;positionnels li&#233;s aux groupes nominaux
sont attach&#233;s sensiblement au m&#234;me endroit. On note une diff&#233;rence faible entre les groupes
pr&#233;positionnels qui seront arguments d&#8217;un verbe, un peu plus importante entre les modificateurs
globaux qui agissent sur toute la phrase. Il y a 4 cas, dans les arbres r&#233;g&#233;n&#233;r&#233;s via CYK, o&#249;
l&#8217;algorithme a jug&#233; plus pertinent de pr&#233;f&#233;rer le type n ou np pour le syntagme pr&#233;positionnel
(&quot;On ne porte pas impun&#233;ment atteinte &#224; des tabous.&quot;), alors qu&#8217;on s&#8217;attend plut&#244;t &#224; une analyse
qui lierait &quot;atteinte&quot; et &quot;&#224;&quot; et qui prendrait en argument le groupe nominal &quot;des tabous&quot; 6.
</p>
<p>On peut dire que le typage et l&#8217;attachement des syntagmes pr&#233;positionnels semblent coh&#233;rents
avec l&#8217;attachement pr&#233;sent dans le corpus d&#8217;origine, ainsi que le typage effectu&#233; par le transduc-
teur. Cependant, pour pouvoir l&#8217;affirmer, il faudrait faire des tests plus pouss&#233;s, qui prendraient
en compte la totalit&#233; du corpus.
</p>
<p>Type occurrence apr&#232;s transduction occurrence apr&#232;s CYK
pp, ppde ou ppa 6 3
Modificateur de NP 35 37
Modificateur de SENT 9 4
np 0 4
Modificateur autre 5 7
</p>
<p>TABLE 7 &#8211; Typage des pr&#233;positions dans le cadre d&#8217;une transduction compar&#233;es &#224; celui effectu&#233; via
le Supertagger avant reconstitution des arbres de d&#233;rivation avec CYK. Les modificateurs autres
sont des modificateurs de proposition infinitive ou de syntagme adjectivaux.
</p>
<p>Le typage, cependant, n&#8217;est pas enti&#232;rement li&#233; &#224; l&#8217;attachement dans la phrase. Nous avons
compar&#233; l&#8217;attachement des syntagmes pr&#233;positionnels et nous pouvons dire que, sur les 55 cas, il
y en a 37 plac&#233;s de mani&#232;re identique et 18 non, soit 67,3% de ressemblance. Les diff&#233;rences
majeures sont au niveau des pr&#233;positions qui sont plus souvent attach&#233;es aux groupes nominaux
et argument des noyaux verbaux (ceux-ci peuvent alors prendre le type np plut&#244;t que pp).
</p>
<p>6 &#201;valuation et r&#233;sultats
</p>
<p>L&#8217;&#233;valuation des diff&#233;rentes m&#233;thodes a &#233;t&#233; effectu&#233;e avec diff&#233;rents ensembles de donn&#233;es. Pour
tester la totalit&#233; de nos travaux, nous avons utilis&#233; le corpus de Paris VII dans son int&#233;gralit&#233;,
c&#8217;est &#224; dire :
&#8211; Les 12351 phrases parenth&#233;s&#233;es que nous avons &#233;tudi&#233;es en profondeur pour fonder l&#8217;ensemble
</p>
<p>de r&#232;gles de notre transducteur, que nous appellerons corpus principal.
</p>
<p>6. L&#8217;analyse CYK fait ressortir l&#8217;aspect idiomatique de &quot;porter atteinte &#224;&quot;.
</p>
<p>215</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#8211; Les 504 phrases qui n&#8217;existaient pas sous forme parenth&#233;s&#233;e. Ce corpus annexe a &#233;t&#233; adapt&#233;
pour &#234;tre sous forme parenth&#233;s&#233;e et pour que les &#233;tiquettes soient celles utilis&#233;es par les r&#232;gles.
</p>
<p>Quel que soit le corpus utilis&#233;, on parlera d&#8217;un corpus partiel pour d&#233;noter le fragment dont
la transduction a r&#233;ussi. Les grammaires extraites des arbres de d&#233;rivation, donc des corpus
partiels, auront le m&#234;me nom que le corpus dont elles sont extraites, soit grammaire principale
et grammaire annexe. L&#8217;&#233;valuation du transducteur et de l&#8217;analyseur de phrases se mesure en
pourcentage de phrases sur lesquelles l&#8217;op&#233;ration a r&#233;ussi. Dans le cadre du transducteur, cette
notion correspond &#224; la transformation des arbres syntaxiques en arbres de d&#233;rivation et dans le
cadre de l&#8217;analyseur, elle correspond &#224; la r&#233;ussite de la combinaison des types donn&#233;s aux mots
par le Supertagger.
</p>
<p>6.1 Transducteur
</p>
<p>Le transducteur transforme pour l&#8217;instant, avec 1671 r&#232;gles, 92,6% du corpus principal (soit
11447 phrases) et 87,3% du corpus annexe (404 phrases) en arbres de d&#233;rivation d&#8217;une gram-
maire AB. On peut r&#233;sumer l&#8217;utilisation des r&#232;gles, dans le cadre de la transduction du corpus
principal, dans le tableau 8. On remarque que, bien qu&#8217;il y ait de nombreuses r&#232;gles qui sont
utilis&#233;es peu de fois, elles ont un poids faible sur la totalit&#233; des transductions effectu&#233;es. Les r&#232;gles
les plus importantes sont exprim&#233;es dans le tableau 9, sous forme parenth&#233;s&#233;e telle qu&#8217;utilis&#233;e
dans la syntaxe de Tregex (Levy et Andrew, 2006). La derni&#232;re r&#232;gle, g&#233;rant la ponctuation finale,
n&#8217;est pas utilis&#233;e autant de fois qu&#8217;il y a d&#8217;arbres de d&#233;rivation. Cela vient du fait que nous avons
souhait&#233; traiter diff&#233;remment les phrases comprenant uniquement un groupe nominal et que
certaines phrases, tels les titres d&#8217;articles, n&#8217;ont pas de ponctuation finale. De m&#234;me, la r&#232;gle qui
s&#8217;occupe du d&#233;terminant au d&#233;but d&#8217;un nom commun devrait &#234;tre employ&#233;e plus que &#231;a, vu le
nombre de groupes nominaux du corpus. Cependant, une r&#232;gle prioritaire s&#8217;occupe du cas o&#249; le
groupe nominal est compos&#233; d&#8217;un d&#233;terminant et d&#8217;un nom commun et est appel&#233;e 8892 fois.
</p>
<p>Nombre de r&#232;gles Occurrence minimale et maximale nombre d&#8217;applications
1148 entre 1 et 20 005818
303 entre 21 et 100 014174
170 entre 101 et 1000 054266
41 entre 1001 et 10000 125405
4 sup&#233;rieur &#224; 10000 060779
</p>
<p>TABLE 8 &#8211; R&#233;capitulatif de l&#8217;utilisation des r&#232;gles.
</p>
<p>motif de d&#233;part motif d&#8217;arriv&#233;e nombre d&#8217;applications
( NP :* NC PP ) ( NP :* NC :n PP :n\*) 17767
(NP :* DET tree ) ( NP :* DET :np/n NP :n ) 16232
(PP :* P NP ) (PP :* P :*/np NP :np) 16037
(SENT tree PONCT ) (TEXT :txt SENT :s PONCT :s\ txt ) 10819
(NP :* tree (COORD CC NP)) (NP :* ( :* NP :*
</p>
<p>(COORD :*\* CC :(*\*)/np NP :np))) 2511
(SENT :* NP-SUJ VN NP-OBJ) (SENT :* NP-SUJ :np
</p>
<p>( :np\* VN :(np\*)/np NP-OBJ :np)) 1820
TABLE 9 &#8211; Quelques r&#232;gles du transducteur, dont les quatre r&#232;gles les plus utilis&#233;es.
</p>
<p>216</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Les arbres de d&#233;rivation des deux corpus nous permettent d&#8217;extraire deux grammaires, sur
lesquelles les tests d&#8217;analyse que nous avons effectu&#233;s seront d&#233;taill&#233;s dans la partie suivante 6.2.
En addition des grammaires, nous pouvons cr&#233;er un lexique, contenant les mots et les diff&#233;rents
types qui leur sont associ&#233;s en fonction des transductions. Le lexique correspondant au corpus
principal contient 26765 mots sur les 27589 pr&#233;sents, il couvre donc 96,9% du vocabulaire
pr&#233;sent dans le corpus de Paris VII.
</p>
<p>6.2 Analyse de phrases
</p>
<p>Nous avons effectu&#233; de nombreux tests avec notre analyseur de phrases. En effet, nous avons
utilis&#233; les deux grammaires diff&#233;rentes et nous avions &#224; disposition des phrases typ&#233;es par le
transducteur ou par le Supertagger, avec &#946; = 0.01.
</p>
<p>Gr&#226;ce au Supertagger, nous avons pu analyser aussi bien les phrases venant du transducteur que
les phrases laiss&#233;es de c&#244;t&#233;. Les r&#233;sultats sont regroup&#233;s dans la table 10. On remarque que les
r&#233;sultats sont proportionnellement moins bons, mais que certaines phrases venant de la partie
non trait&#233;e des diff&#233;rents corpus sont analys&#233;es et transform&#233;es en arbre de d&#233;rivation.
</p>
<p>Origine des phrases Phrases analys&#233;es Grammaire utilis&#233;e R&#233;sultat
</p>
<p>Transducteur
Corpus principal partiel Grammaire annexe 54, 4%
Corpus annexe partiel Grammaire principale 85%
</p>
<p>Supertagger
Corpus principal grammaire principale 89, 38%
Corpus annexe grammaire principale 83, 1%
</p>
<p>TABLE 10 &#8211; Tableau de r&#233;sultat.
</p>
<p>7 Conclusion et perspectives
</p>
<p>Dans cet article, nous avons rapidement rappel&#233; le principe du G-transducteur dont nous nous
servons pour transformer les arbres syntaxiques du corpus de Paris VII en arbres de d&#233;rivation
d&#8217;une grammaire AB, puis expliqu&#233; la m&#233;thode que nous employons pour extraire une PCFG de
ces arbres. Les r&#233;sultats exp&#233;rimentaux d&#8217;analyse de phrase via l&#8217;algorithme CYK, en utilisant
notre PCFG et des phrases typ&#233;es au pr&#233;alable, nous permettent de comparer les annotations
produites par le transducteur et la m&#233;thode semi-automatique mise en place par Moot.
</p>
<p>Cependant, ce travail est loin d&#8217;&#234;tre termin&#233; et nous avons encore plusieurs perspectives &#224; &#233;tudier.
Bien s&#251;r, nous souhaitons am&#233;liorer la couverture du transducteur par rapport au corpus et
d&#233;passer les 95% de phrases analys&#233;es, bien qu&#8217;il ne reste plus que des cas complexes &#224; traiter.
Etant donn&#233; que les grammaires AB peuvent sembler limitatives lorsque l&#8217;on souhaite traiter
d&#8217;une langue complexe, nous souhaiterions transformer notre transducteur en un transducteur
d&#8217;arbres vers les graphes. Cela nous permettrait d&#8217;utiliser l&#8217;ensemble des r&#232;gles de Lambek et
de nous rapprocher de travaux plus modernes sur la question. Par rapport &#224; l&#8217;analyseur de
phrase, il manque cruellement d&#8217;un typage relatif au lexique que nous extrayons des arbres de
d&#233;rivation. Cette m&#233;thode de typage devrait &#234;tre impl&#233;ment&#233;e rapidement. De m&#234;me, il pourrait
&#234;tre int&#233;ressant d&#8217;utiliser d&#8217;autres algorithmes que CYK, tel que l&#8217;algorithme d&#8217;Earley, ou de typer
les phrases en utilisant un syst&#232;me tel que SYGFRAN (Chauch&#233;, 2011).
</p>
<p>217</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Notre travail est disponible &#224; (Sandillon-Rezer, 2012), sous licence GNU General Public Licence.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ABEILL&#201;, A. et CL&#201;MENT, L. (2003). Annotation morpho-syntaxique.
</p>
<p>ABEILL&#201;, A., CL&#201;MENT, L. et TOUSSENEL, F. (2003). Building a treebank for french. Treebanks,
Kluwer, Dordrecht.
</p>
<p>BUSZKOWSKI, W. et PENN, G. (1990). Categorial grammars determined from linguistic data by
unification. Studia Logica, 49(4):431&#8211;454.
</p>
<p>CHAUCH&#201;, J. (2011). Une application de la grammaire structurelle : L&#8217;analyseur syntaxique du
francais sygfran.
</p>
<p>COMON, H., DAUCHET, M., GILLERON, R., L&#214;DING, C., JACQUEMARD, F., LUGIEZ, D., TISON, S.
et TOMMASI, M. (2007). Tree automata techniques and applications. Available on : http:
//www.grappa.univ-lille3.fr/tata. release October, 12th 2007.
EARLEY, J. (1973). An efficient context-free parsing algorithm.
</p>
<p>HOCKENMAIER, J. et STEEDMAN, M. (2007). CCGbank : a corpus of CCG derivations and depen-
dency structures extracted from the penn treebank. Computational Linguistics, page 355&#8211;396.
</p>
<p>HOPCROFT, J. E. et ULLMAN, J. D. (1979). Introduction to Automata Theory, Languages, and
Computation. Adison-Wesley Publishing Company, Reading, Massachusets, USA.
</p>
<p>KANAZAWA, M. (1998). Learnable Classes of Categorial Grammars. Center for the Study of
Language and Information, Stanford University.
</p>
<p>KNIGHT, K. et GRAEHL, J. (2005). An overview of probabilistic tree transducers for natural
language processing.
</p>
<p>KNUTH, D. E. (1997). The Art of Computer Programming Volume 2 : Seminumerical Algorithms
(3rd ed.). Adison-Wesley Professional.
</p>
<p>LAMBEK, J. (1958). The mathematics of sentence structure. The American Mathematical Monthly,
65(3).
</p>
<p>LEVY, R. et ANDREW, G. (2006). Tregex and tsurgeon : tools for querying and manipulating tree
data structures.
</p>
<p>MOORTGAT, M. et MOOT, R. (2001). CGN to Grail : Extracting a type-logical lexicon from the
CGN annotation. In DAELEMANS, W., &#233;diteur : Proceedings of Computational Linguistics in the
Netherlands CLIN 2000.
</p>
<p>MOOT, R. (2010a). Automated extraction of type-logical supertags from the spoken dutch
corpus. Complexity of Lexical Descriptions and its Relevance to Natural Language Processing : A
Supertagging Approach.
</p>
<p>MOOT, R. (2010b). Semi-automated extraction of a wide-coverage type-logical grammar for
french. Proceedings TALN 2010, Monreal.
</p>
<p>SANDILLON-REZER, N. (2012). Syntab : http ://www.labri.fr/perso/nfsr/.
</p>
<p>SANDILLON-REZER, N.-F. et MOOT, R. (2011). Using tree tranducers for grammatical inference.
Proceedings of Logical Aspects of Computational Linguistics 2011.
</p>
<p>YOUNGER, D. (1967). Context free grammar processing in n3.
</p>
<p>218</p>

</div></div>
</body></html>