TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Inférence grammaticale guidée par clustering

Noémie-Fleur Sandillon-Rezer
CNRS, Esplanade des Arts et Métiers, 33402 Talence
LaBRl, 351 Cours de la Libération, 33405 Talence
nfsr@1abri . fr

RESUME
Dans cet article, nous nous focalisons sur la maniere d’utiliser du clustering hiérarchique pour
apprendre une grammaire AB a partir d’arbres de dérivation partiels. Nous décrirons briévement
les grammaires AB ainsi que les arbres de dérivation dont nous nous servons comme entrée pour
l’algorithme, puis la maniere dont nous extrayons les informations des corpus arborés pour
l’étape de clustering. L’algorithme d’uniﬁcation, dont le pivot est le cluster, sera décrit et les
résultats analysés en détails.

ABSTRACT
Clustering for categorial grammar induction

In this article, we describe the way we use hierarchical clustering to learn an AB grammar from
partial derivation trees. We describe AB grammars and the derivation trees we use as input
for the clustering, then the way we extract information from Treebanks for the clustering. The
uniﬁcation algorithm, based on the information extracted from our cluster, will be explained and
the results discussed.

MOTS-CLES : grammaires catégorielles, clustering hiérarchique, inférence grammaticale.

KEYWORDS: categorial grammars, hierarchical clustering, grammatical inference.

1 Introduction

Le but de cet article est de présenter une nouvelle méthode d’inférence grammaticale. En effet,
nous utilisons en entrée de notre algorithme des arbres de dérivations d’une grammaire AB
partiellement remplis, et l’algorithme est ensuite guidé par le clustering pour savoir quelles
variables vont étre uniﬁées. L’idée de base est que les mots qui sont dans des contextes similaires
doivent avoir des types similaires.

L’inférence grammaticale appliquée aux grammaires catégorielles peut étre classée en trois
catégories distinctes, en fonction des méthodes employées et des structures d’entrée.

La méthode décrite par Adriaans (Trautwein et al., 2000; Adriaans, 1999) a pour point de
départ des phrases sans structure. Bien qu’elle fonctionne dans la plupart des cas, ce genre de
méthode d’inférence rencontre des problemes avec des phrases permettant plusieurs analyses
syntaxiques qu’on ne peut pas distinguer et qui sont fondées seulement sur la chaine des mots

28 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

—par exemple l’attachement des syntagmes prépositionnels. I1 semble donc logique, étant donné
que cette information est généralement annotée dans des corpus arborés, de l’utiliser lors de
l’apprentissage.

Des structures partielles sont utilisées dans les méthodes de Buszkowski et Penn (Buszkowski et
Penn, 1990) ou Kanazawa (Kanazawa, 1998). Ces méthodes sont clairement dans la lignée du
paradigme de Gold (Gold, 1967). Les structures d’entrée sont décrites ultérieurement, section
3. La sortie de ces algorithmes donne soit une grammaire rigide 1 (algorithme de Buszkowski
et Penn) soit une grammaire k-valuée 2 (algorithme de Kanazawa). Une grammaire rigide n’est
pas représentative d’un langage naturel, et des k 2 2, l’uniﬁcation devient un probleme NP—dur
(Costa—Floréncio, 2001). Outre ce fait, comme k n’est pas connu par avance, il convient de trouver
la valeur optimale, ce qui est particuliérement complexe. On doit alors appliquer une recherche
dichotomique pour trouver k, partant du principe que celui—ci se situe au départ entre 1 et oo.
L’idée est de prendre une valeur arbitraire qui semble raisonnable, de tester. Si cela fonctionne,
on divise la valeur par deux et on tente a nouveau, sinon on la multiplie par deux en partant du
principe que la bonne valeur devra étre supérieure ou égale a k + 1. Il est a noter, cependant,
que méme une grammaire 2—Valuée ne peut pas représenter une langue naturelle : l’expérience
avec les grammaires extraites montre que le nombre maximum de types par mot est grand, et
de nombreux mots fréquents (déterminants, conjonctions de coordinations) possédent plus de
quarante types (Hockenmaier et Steedman, 2007; Sandillon-Rezer et Moot, 2011).

Enﬁn, les méthodes utilisent des structures totalement déﬁnies, comme celle d’Hockenmaier
(Hockenmaier, 2003), qui construit une grammaire catégorielle combinatoire, ou notre méthode
(Sandillon-Rezer et Moot, 2011), qui utilise un transducteur d’arbres généralisé pour transformer
des arbres syntaxiques en arbres de dérivation d’une grammaire AB (Lambek, 1958). C’est la
sortie de notre transducteur qui nous servira de standard d’éValuation ainsi que d’entrée apres
modiﬁcation des arbres pour notre algorithme d’inférence grammaticale.

Dans cet article nous combinons les méthodes du second type avec des structures partielles
(agrémentées de certaines informaﬁons provenant des corpus) et du clustering. Nous évaluons a
la fois la complexité du probleme et la qualité du lexique obtenu. Le clustering est effectué en
utilisant une mesure de similarité fondée sur le contexte local du mot, qui est directement extrait
des arbres syntaxiques.

Les arbres de dérivation sont extraits de corpus annotés. Nous utilisons deux corpus différents en
guise de base : le corpus de Paris VII (Abeillé et al., 2003) et Sequoia (Candito et Seddah, 2012).
Les deux corpus sont annotés de maniere syntaxique par les mémes protocoles d’annotation
(Abeillé et Clément, 2003). Les principales différences entre les deux corpus résident dans le
nombre de phrases et l’origine de celles-ci. Le corpus de Paris VII est composé de 12351 phrases
qui proviennent d’une sélection d’articles du journal Le Monde, et Sequoia est composé de 3204
phrases venant de différents horizons, comme Wikipedia, le journal BEst Républicain ou encore des
notices médicales. La ﬁgure 1 donne un exemple d’arbre syntaxique. Les noeuds pré—terminaux
contiennent les POS—tag3 du mot, les autres noeuds internes contiennent le type syntagmatique
du sous—arbre et les feuilles représentent les mots de la phrase.

Etant donné que le format des annotations ne correspond pas aux arbres de dérivation d’une
grammaire AB, nous utilisons le transducteur d’arbres généralisé pour transformer les arbres du

1. Une grammaire catégorielle rigide force les mots du lexique a n’avoir qu’un seul type.
2. Une grammaire k-valuée permet aux mots d’un lexique d’avoir k types au maximum.
3. les annotations parties du discours

29 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
adjectif, ce qui pourtant correspond mieux au contexte, cependant la CCG Bank (Hockenmaier et

Steedman, 2007) contient une regle spéciale qui permet une translation de np\sp a n\n; on peut
donc dire que le fait de considérer les deux types comme équivalents pour 1’évaluation semble

étre justiﬁé.
Le type donné a change est une vraie erreur : a la place d’étre traité comme un verbe transiu'f qui
prendrait donc deux arguments, il est traité comme un verbe intransitif. Cette erreur Vient de

l’étape de clustering, ou change est proche d’un autre verbe intransitif.

paires erronées 569 8,7%

paires équivalentes 336 6,2%
paires identiques 4 832 85,1%
paires utilisables 5 168 91,3%

TABLE 6 — Ratio entre les différences des lexiques, comptées en paire mot-type. On note que

91,3% du lexique est sans erreur, donc utilisable en l’état.

Uniﬁcation Transduction

Mot
accumulé np\sp n\n
Change nP\5 (nP\5)/ HP

TABLE 7 — Un exemple de chaque classe de mots.

La ﬁgure 8 montre deux clusters de niveau zéro. Le gauche est un cluster d’adVerbes. La variable
ab331 sera uniﬁée avec np. Le cluster de droite contient uniquement des variables qui seront

uniﬁées en une seule. Il rassemble des adjectifs et des participes passés utilisés en tant qu’adjectifs.

§

.1ez‘qe rsemle

O .exIgeameg aa_45
tl’D-5,7,9

75120

FIGURE 8 — Zoom sur deux clusters de niveau zéro.

6 Discussions

La méthode que nous utilisons est faite pour fonctionner avec des arbres de dérivation : il s’agit

d’apprentissage non supervisé, mais avec des structures d’entrée contenant beaucoup d’infor—
mations dont des informations syntaxiques. Cependant, cela pourrait étre étendu a n’importe
© ATALA

38

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

quel ensemble de phrases qui ne sont pas sous forme d’arbres avec quelques modiﬁcations. L’idée
serait d’utiliser a la fois des phrases simples et d’autres phrases sous forme d’arbres de dérivation.

Le probléme est d’avoir les vecteurs de mots pour les phrases qui n’ont pas d’arbres syntaxiques
attachés. On pourrait alors utiliser les vecteurs d’un sous—espace car certaines informations,
comme le POS—tag des mots, peuvent étre facilement retrouvées avec un tagger (Moot, 2012).

Ensuite, nous pouvons effectuer une étape de clustering avec ces vecteurs partiels et ceux extraits
d’arbres syntaxiques en faisant une projection sur les seconds pour diminuer le nombre de
dimensions. De cette maniere, les mots pourraient avoir le type le plus utilisé par le cluster
de niveau zéro leur correspondant. Cela nous permettrait d’avoir une plus grande Visibilité sur
les mots que si nous leur donnions juste le type le plus utilisé dans un lexique de référence en
fonction de leur POS—tag. Etant donné que nos vecteurs ont un grand nombre de dimensions et
sont tres vides, nous pourrions aussi appliquer la méthode décrite par Kailing et al. (Kailing et al.,
2004) pour les manipuler.

6.1 Application a de plus grands corpus

Nous souhaitons appliquer notre méthode actuelle a des ensembles plus larges, mais nous
aurons alors affaire a des clusters beaucoup plus larges pour le corpus Sequoia complet (plus de
63000 mots) ou encore pour le corpus de Paris VII (environ 300000 mots). L’étape de clustering
est, avec la méthode de Ward (Ward, 1963), d’une complexité O(n3), et cela commence a
devenir problématique pour ces grands ensembles. Il faut cependant noter que cela constitue une
amélioration par rapport aux autres algorithmes d’apprentissage, étant donné que les grammaires
k—valuées ont une complexité exponentielle.

6.2 Optimisation de l’uniﬁcation des types

Pour l’instant, nous utilisons le critére “premier trouvé” pour uniﬁer les variables lorsque nous
n’avons pas d’autre critere de choix. Une solution plus optimale serait de regarder toutes les
variables dans leur globalité, de leur assigner une liste d’uniﬁcations possibles et d’utiliser
l’algorithme de Kuhn-Munkres (Kuhn, 1955; Munkres, 1957) pour choisir la meilleure uniﬁcation
globale, comme par exemple celle qui donne l’instantiation des variables avec les types les plus
simples.

7 Conclusion

Dans cet article, nous avons montré une nouvelle méthode pour extraire une grammaire AB
par uniﬁcation en utilisant le clustering pour nous guider. Une implémentation est disponible
(Sandillon-Rezer, 2013).

Nous avons décidé d’utiliser un clustering hiérarchique, ce qui nous permettait d’uniﬁer le lexique
pas a pas, soit jusqu’a convergence, soit jusqu’a ce qu’un conﬂit bloque l’uniﬁcation. Cependant,
il serait intéressant de tester notre méthode avec d’autres types de clustering, comme la méthode
des k-means ou celle appelée Clustering By Committee (Pantel, 2003). Cette derniere méthode

39 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

cherche le meilleur centro'1'de de chaque cluster qui est sense’ étre représentatif de chacun; elle
ne peut cependant pas étre appliqué en l’état, parce que nous souhaitons faire l’uniﬁcation aprés
le clustering et que les types des centro'1'des ne sont donc pas encore déﬁnis.

Les résultats que nous avons sont prometteurs surtout si on garde a l’esprit le fait que le format
d’entrée est peu détaillé, ce qui nécessite donc moins d’heures aux annotateurs, mais que nous
sommes proches de notre lexique de référence : nous avons 91,3% du lexique qui est similaire et
85,1% qui est identique.

Références

ABEILLE, A. et CLEMENT, L. (2003). Annotation morpho—syntaxique.

ABEILLE, A., CLEMENT, L. et ToUssENEL, F. (2003). Building a treebank for french. Treebanks,
Kluwer, Dordrecht.

ADRIAANS, P W. (1999). Learning shallow Context-Free languages under simple distributions.
AJDUKIEWICZ, K. (1935). Die syntaktische konnexitat. Stud. Philos., 1:1—27.
AUBER, D. et MARY, P (2007). Tulip : Better visualization through research.

BAR-HILLEL, Y. (1964). Language and information : selected essays on their theory and application.
Addison-Wesley Pub. Co.

BUszKowsKI, W. et PENN, G. (1990). Categorial grammars determined from linguistic data by
uniﬁcation. Studia Logica.

CANDITO, M. et SEDDAH, D. (2012). Le cor usse uoia : annotation s ntaxi ue et ex loitation
P (1 Y (1 P
pour l’adaptation d’analyseur par pont lexical.

C0sTA-FL0RENc1o, C. (2001). Consistent identiﬁcation in the limit of any of the classes k-valued
is np—hard. Lecture Notes in Artiﬁcial Intelligence.

GOLD, E. (1967). Language identiﬁcation in the limit. Information and Control, 10.

HOCKENMAIER, J. (2003). Data and models for statistical parsing with combinatory categorial
grammar.

HOCKENMAIER, J. et STEEDMAN, M. (2007). CCGbank : a corpus of CCG derivations and depen-
dency structures extracted from the penn treebank. Computational Linguistics, 33 (3):355—396.

IHAKA, R. et GENTLEMAN, R. (1993). R project.

KAILING, K., KRIEGEL, H. et KROGER, P. (2004). Density—connected subspace clustering for
high-dimensional data. Proceedings of the Fourth SIAM International Conference on Data Mining.

KANAZAWA, M. (1998). Leamable Classes of Categorial Grammars. Center for the Study of
Language and Information, Stanford University.

KUHN, H. (1955). The hungarian method for the assignment problem. Naval Research Logistics
Quarterly.

LAMBEK, J. (1958). The mathematics of sentence structure. The American Mathematical Monthly,
65.

M001", R. (2012). Wide—coverage semantics for spau'o—temporal reasoning. Traitement Automa-
tique des Langues 52.

40 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
MUNKRES, J. (1957). Algorithms for the assignment and transportation problems. Journal of the
Society for Industrial and Applied Mathematics.
PANTEL, R (2003). Clustering by committee. PhD thesis.
SANDILLON-REZER, N.—E (2013). http ://www.1abri.fr/perso/nfsr.

SANDILLON-REZER, N.—E et MooT, R. (2011). Using tree tranducers for grammatical inference.
Proceedings of Logical Aspects of Computational Linguistics 201 1 .

TRAUTWEIN, H., ADRIAANS, R et VERVOORT, M. (2000). Towards high speed grammar induction
on large text corpora.

WARD, J. (1963). Hierarchical grouping to optimize an objective function. Journal of the
American Statistical Association.

41 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
corpus de Paris VII et de Sequoia en arbres de dérivation.

Nous commencerons par décrire la grammaire AB générée par le transducteur généralisé, ensuite
nous rappellerons le principe général de l’algorithme d’uniﬁcation pour les grammaires AB et
décrirons celui que nous utilisons. Dans la section quatre, nous décrirons le format de vecteurs
utilisés pour l’étape de clustering. L’évaluation de notre méthode suivra, ainsi qu’une discussion
sur les extensions possible de ce travail.

1  \\
/ \ 1 1 g/ \\ 1
1 1 1_ 1 1 / \ /\ / \ '
Le   1 1 1 1 1 L / \

ne_pas déposer d’ OPA sur
la CPR

FIGURE 1 — Exemple d’arbre syntaxique du corpus de Paris VII.

2 Arbres de dérivation d’une grammaire AB

Les grammaires AB ont été déﬁnies séparément par Ajdukiewicz (Ajdukiewicz, 1935) et Bar—Hillel
(Bar—Hillel, 1964) a partir du coeur des grammaires catégorielles et sont a présent considérées
comme une sous—partie du calcul de Lambek (Lambek, 1958) et des grammaires catégorielles
combinatoires4 (Hockenmaier et Steedman, 2007). Les grammaires AB ont seulement deux
regles d’éliminations, comme montré tableau 1.

’% [/EJ %“ [\E]

TABLE 1 — The elimination rules for AB grammar

Les arbres de dérivation d’une grammaire AB représentent l’application successive des régles
d’éliminations.
Notre transducteur généralisé, qui correspond a une version modiﬁée d’un transducteur descen-

dant, transforme les arbres syntaxiques des deux corpus en dérivations d’une grammaire AB. La
ﬁgure 2 montre un exemple de sortie du transducteur correspondant a l’arbre syntaxique de la

4. Il est 21 noter cependant que nous suivons la convention déterminée par Lambek d’avoir toujours la catégorie qui
sert d’arg'ument sous le slash.

30 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

ﬁgure 1. Moins de 1.650 regles de transduction sont nécessaires pour convertir 92% du corpus
de Paris VII (93% de Sequoia).

/ \>
J R,
/ \ \
1 1 //
Le  / \ ‘

1 1 a

1 1 /

1/ \
1 i

ne_pas déposer

\
1/\
\ /\
/

9.-:<—
(Z
4:
4:

OPA la CPR

FIGURE 2 — Soru'e du transducteur. Les informations provenant de l’arbre syntaxique sont toujours
présentes. Il est a noter que sur la sortie réelle, les types sont aussi présents dans les feuilles; ils
sont hérités des noeuds pré—terminaux.

Le transducteur utilise quelques types atomiques pour l’étape de transduction : np, n, s, txt, pp,
cs, cl,. Cela correspond respectivement, a : un syntagme nominal, un nom commun, une phrase,
un "texte" (une phrase avec une ponctuation ﬁnale), un syntagme prépositionnel, une clause
subordonnée et un clitique réﬂexif. En plus, nous utilisons les types np\s,, et np\s,- pour les
syntagmes participiaux et inﬁnitivaux. Cependant, le transducteur est relativement modulaire.
Chacun peut créer un ensemble de régles pour binariser les arbres et le transducteur vériﬁera que
les arbres sont bien binaires a la sortie et que les types sont cohérents au sens de Ajdukiewicz,
c’est a dire qu’on a bien a chaque étape une application d’une des régles d’éliminau'on.

Nous utiliserons ces types pour initialiser nos arbres avant l’étape d’uniﬁcation; la description du
format d’entrée est effectuée dans la section 3.

3 Inférence grammaticale

Un algorithme d’inférence grammaticale bien connu est celui décrit par Buszkowski et Penn
(Buszkowski et Penn, 1990). Pour apprendre une grammaire rigide, cela ne pose pas de probléme

31 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

(voir algorithme 1) : soit les types du lexique peuvent étre uniﬁés jusqu’a ce qu’il n’y en ait plus
qu’un par mot, soit l’algorithme échoue. Pour apprendre une grammaire k—valuée (Kanazawa,
1998) i1 y a besoin du meme format d’entrée, comme montre la ﬁgure 3. Le coeur du probleme
avec les grammaires k-valuées est de décider quels types doivent étre uniﬁés, car la meilleure
uniﬁcation possible ne peut étre décidée que d’un point de vue global. C’est pour cela que ce
probléme d’inférence grammaticale est NP—dur (Costa—Floréncio, 2001) des que k 2 2. Il est
également important de noter que k n’est généralement pas connu d’avance, ce qui complique la
résolution de l’algorithme.

/ N . a\s
/ \ Z \
Le b/c CBV c

/\ /\

autorise ((b\a)/d)/e Indosuez e ('1 d/f

/ \

sur (g\f)/k

/\ /\ /\

ne_pas (g/h)/i déposeri d’ h/ j OPA j la k/l CPR l

FIGURE 3 — Exemple d’entrée pour les deux algorithmes d’uniﬁcation.

Données: arbres dont la racine est étiquetée s, les noeuds internes / ou \, et les feuilles
avec des variables
Résultat: une grammaire rigide
création d’un lexique de mots contenant toutes les variables qui leurs sont liées ;
tant que chaque mat a plusieurs types qui lui sont lie’s faire
rechercher l’uniﬁcateur le plus généraliste, de maniere a réduire globalement le nombre
de variables liées aux mots;
si l’uniﬁcation n’est pas possible alors l’algorithme échoue;
fin
Algorithm 1: Algorithme d’apprentissage d’une grammaire rigide.

Pour illustrer le probleme de l’uniﬁcation, il sufﬁt de prendre deux phrases du corpus de Paris VII :
Nous avons de plus en plus de monde dans les DOM—TOM et Le gouvernement n’avait ni écrit ni choisi
cet accord dont nous avons he’rite’. Le lexique avant uniﬁcation est décrit tableau 2. En appliquant
l’algorithme de Buszkowski et Penn, le verbe avons aura deux types qui se ressemblent : (d \c) / e
et (w\v) / x. En effet, a chaque fois avons prend deux arguments, l’un a sa gauche et l’autre a sa
droite. Cependant, nous ne pouvons pas uniﬁer ces deux types, parce que dans le premier cas

32 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

l’argument de droite est un groupe nominal et dans le second cas un participe passé; en outre
nous ne souhaitons pas que les deux aient le meme type, pour éviter des phrases agrammaticales.
Pour ces deux phrases, nous avons donc besoin au minimum d’une grammaire 2—va1uée, et avons
do1t avo1r deux types differents : (np\s)/np et(np\s)/(np\s1,).

nous d, w avons (d \c)/ e de _p1us_en _p1us e / f
, (W \V)/X
de f / g monde g dans (c\a) / h
les h / i DOM-TOM i le l/m
gouvemement m n’ ((1 \k) / n) / p avait (o/ p) /q
ni q / r, p /s écrit r cet n / t
accord u dont (u\t) / v hérité x
k\J', a\b

TABLE 2 — Lexique avant uniﬁcation

Entre ces algorithmes standards d’inférence grammaticale et le nétre, il y a deux différences
principales.

La premiere différence réside dans le fait que nous utilisons les informations provenant des
annotations du corpus, comme résumé dans la table 3. Les types assignés aux noeuds ont été
choisis en fonction de leur fréquence dans le lexique extrait des arbres apres transduction. Si
le label n’est pas dans la table, le type du noeud sera une variable dans le cas d’un noeud
argument. Si le noeud est foncteur, son type sera instancié en méme temps que celui de son
argument, puisque cette méthode est descendante. Les arbres utilisés en entrée contiennent donc
des sous—formu1es avec des variables libres. L’inférence grammaticale consiste a transformer ces
arbres aux types partiellement spéciﬁés en arbres de dérivation sans variable. Un exemple d’arbre
d’entrée est montré ﬁgure 4. On remarque que certains mots, méme si leur POS—tag n’est pas
dans la table 3, ont déja des types complexes sans variable.

label type label type
TEXT txt SENT S

NP np NP-ARG np

PP pp AP-ARG n\n
CLS np CLS—SUJ np

NC n NPP np
VPP np\ sp VINF np \ s,-

TABLE 3 — Extrait de la liste des types assignés aux noeuds lorsque ceux-ci ont le bon label, si et
seulement s’i1s sont arguments et non foncteurs au niveau des dérivations d’une grammaire AB.

La seconde différence est l’utilisation de clusters pour guider 1’étape d’uniﬁcation. Nous avons
pris le paru' d’utiliser un algorithme de clustering hiérarchique pour ce faire. Un cluster peut aussi
bien regrouper un ensemble de cluster que des mots. Chaque cluster est associé a une hauteur
qui représente la similarité entre les données qu’i1 regroupe. Ainsi, les clusters de hauteur zéro
regroupent les mots dont les vecteurs sont identiques, et les clusters de hauteur plus importante
regroupent aussi bien des mots que d’autres clusters qui leurs sont proches, comme montré ﬁgure
5. Nous uniﬁons les clusters par hauteur croissante, ce qui nous permet d’uniﬁer par ordre de

33 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Ol0nne

/\
/\
/\ XX,

\ ./

. s\txt

Le np/n CBV n

/

autorise ((np\s)/(np\s,<))/np Indosuez np ti (np\si)/aal /

sur (ab1\aa1)/np

/\ /\ /\

ne_pas (abl/np)/acl déposer acl d’ np/n OPA n la np/n CPR n

FIGURE 4 — Arbre d’entrée pour notre algorithme d’inférence grammaticale. Certains types sont
déja traités par l’étape de transduction et les autres sont remplacés par des variables.

similarité. Lorsque, pour une hauteur donnée, nous avons plusieurs possibilités d’uniﬁcation,
nous appliquons un ordre de priorité qui peut étre résumé par :

1. uniﬁer les plus petits clusters,
2. uniﬁer les clusters pour lesquels il n’y a qu’un seul choix par variable,

3. uniﬁer avec le plus simple candidat (la complexite’ d’un candidat est calculée en fonction
du nombre de \et de / qu’il contient),

4. choisir le premier venu pour les autres variables, avec la possibilité de choisir aléatoirement
l’uniﬁcation.

11 se peut que tous les mots ne soient pas représentés a un niveau donné, par conséquent il peut
rester des variables dans les types aprés une étape de clustering. Dans ce cas, on passe a un
nouveau niveau de clustering. Cette maniére de procéder nous assure 1’uniﬁcation des variables
qui apparaissent en premier lieu dans des contextes les plus similaires possibles.

Il est a noter que méme avec des variables, les arbres de dérivation partiels restent des dérivations
valides et représentatives d’une grammaire AB : Les deux regles d’é1imination sont les seules
utilisées pour créer les arbres.

34 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

\— (\]‘_

_q,!G,|,,,l_| l—I 1a,l—l—
>‘®~q) (|).q).q) :5.”
C-<1)---—' 5 o->

93°“ E on::“1"‘1’ 0 an an
W U1='E'6 E "5
030- ‘CD .3) O

C0 E “C5 :1)

FIGURE 5 — Extrait d’un cluster de 5 phrases. Les participes passés sont regroupés d’abord par
contexte puis tous ensemble dans de plus larges clusters jusqu’a n’en former plus qu’un.

4 Clustering

4.1 Extraction de vecteurs

Nous avons décidé d’assigner des vecteurs aux mots en extrayant les informations des corpus
avant transductions.

Les vecteurs ont six dimensions :

1 POS—tag du mot (pére),
2 information morpho—syntaxique (grand—pére),
3-4 POS—tag du frére a gauche et a droite,

5-6 distance jusqu’au plus proche ancétre commun avec le voisin de gauche et de droite.

S’i1 n’y a pas de voisin de droite ou de gauche (dernier ou premier mot d’une phrase), la valeur
correspondant a la coordonnée de ce vecteur sera instanciée a NIL ou -5, suivant si c’est un
label ou un nombre. Deux exemples de vecteurs sont donnés ﬁgure 6.

lel < DET, NP-SUJ,NIL, NC, —5,2 >

leg < DET, NP-MOD, VPB ADJ, 3, 2 >

FIGURE 6 — Deux vecteurs correspondant au déterminant "1e".

Pour comparer les vecteurs, nous avons besoin de les transformer en vecteurs dans Z", n E N.
Nous avons pris le parti de transformer chaque label en vecteur ou seulement une ou deux
dimensions possede la valeur 1 et le reste des coordonnées a pour valeur 0. Les POS—tags
et les informations syntaxiques sont transformés de cette maniere. Les distances numériques
restent telles quelles, comme montré ﬁgure 6. La transformation est illustrée par la table 4 avec
seulement une portion des données. 11 y a une “dimension” pour presque chacun des POS—tags
(avec cependant quelques exceptions pour des cas que nous souhaitons voir uniﬁés ensemble,

35 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

comme ET pour les mots étrangers et NPP pour les noms propres) ; pour les informations morpho-
syntaxiques, en plus d’une dimension pour chaque catégorie de base (NP, PP...) on fait seulement
la différence entre les arguments ( représentés par le —SU.I, —OB.I, —ATS... a la ﬁn des labels) et les
modiﬁcateurs —MOD.

POS-tag NC DET P 
NC 1 0 0 0...0
DET 1 0 0...0
P+D 1 1 0...0
Other NP  -ARG -MOD
NP 1 0...

NP-SUJ 1 0... 0
NP-MOD 1 0...0 0 1

TABLE 4 — Exemple de transformation de vecteurs.

4.2 Création des clusters

Pour calculer le cluster hiérarchique nous utilisons le logiciel R (Ihaka et Gentleman, 1993), la
distance métrique Manhattan et pour le clustering en lui-meme la méthode de variance minimum
de Ward (Ward, 1963). Pour mieux Visualiser le cluster complet nous utilisons Tulip (Auber et
Mary, 2007), ce qui permet de créer des graphes comme ceux de la ﬁgure 7. Les détails du
graphe seront montrés dans la section suivante.

5 Evaluation

Nous avons testé notre méthode sur 754 phrase de Sequoia et 553 phrases du corpus de Paris VII.
Le tableau 5 montre l’efﬁcacité de la méthode, calculée en fonction du pourcentage de variables
restant apres uniﬁcation.

Corpus Sequoia (754 phrases) Paris VII (553 phrases)
variables restantes 3 0
nombre total de variables 1.429 686
ratio 99,8% 100%

TABLE 5 — Pourcentage de variables restantes aprés uniﬁcations sur l’extrait de Sequoia et Paris
VII.

Cependant le nombre de variables restantes sont un faible critére de succés. En effet, si les
variables sont uniﬁées mais que les types résultants sont trop complexes, on ne peut pas dire que
notre méthode soit un réel succés, méme si toutes les phrases ont un arbre de dérivation valide.

Pour le corpus Sequoia, lorsque l’on compare les lexiques extraits aprés transduction et avec
notre nouvel algorithme d’inférence grammaticale, on peut noter que 82,7% des lexiques sont
identiques : cela signiﬁe qu’il y a seulement 2967 paires mot—type différentes sur les 17110

36 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d'Olonne

   

FIGURE 7 ~ Cluster correspondant a notre ensemble test de phrases. La partie entourée en
pointillés correspond a l’endroit ou il y a le plus de Verbes; celle entourée par des tirets aux
déterminants et la partie simplement cerclée correspond aux adjectifs. On peut noter que les
adjectifs et les déterminants sont proches les uns des autres. Cela s’explique parce qu’ils prennent
généralement tous les deux un nom commun en argument et qu’ils sont présents dans des
groupes nominaux.

paires du lexique. Cela correspond a 1012 entrées dans le lexique qui ont au moins une différence.

Pour les 553 phrases du corpus de Paris VII, nous comparons plus en détail les deux lexiques.
Cela correspond a 2076 mots, soit 5731 paires mot-types.

Les différences entre les deux lexiques correspondent a 899 paires qui s’étalent sur 379 mots,
soit 14,9% du lexique. Cela signiﬁe que 85,1% des lexiques sont identiques. Dans ces 85,1%
il faut noter cependant qu’il y a 2% de modiﬁcations mineures, telles qu’un np qui devient
un 11 (majoritairement dans des cas tels que "Le président Merem") ou qu’une inversion entre
les différents types des prépositions, pp, p pde ou p pa (les trois correspondent a des syntagmes
prépositionnels, mais les deux derniers ajoutent comme information que la préposition utilisée
est un 61 ou un de. Il faut noter cependant que certaines prépositions ne sont pas annotées
comme ayant un 61 ou un de dans le corpus). Nous travaillons actuellement a faire disparaitre ces
modiﬁcations mineures.

Le tableau 6 trie les différences en deux catégories : d’un cété les types qui sont présents dans le
lexique provenant du transducteur mais qui n’ont pas la méme occurrence, et de l’autre ceux qui
n’apparaissent pas dans le lexique de référence. Quelques exemples sont montrés dans le tableau
7. Le participe passé accumulé peut étre utilisé aussi bien comme un adjectif. Le type donné par
l’uniﬁcation correspond a un noeud VPP utilisé comme un participe passé et non comme un

37 © ATALA

