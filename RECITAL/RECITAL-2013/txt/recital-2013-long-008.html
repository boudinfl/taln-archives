<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>&#201;tat de l&#8217;art des m&#233;thodes d&#8217;extraction automatique de termes-cl&#233;s</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;tat de l&#8217;art des m&#233;thodes d&#8217;extraction automatique de
termes-cl&#233;s
</p>
<p>Adrien Bougouin
LINA - UMR CNRS 6241, Universit&#233; de Nantes, France
</p>
<p>adrien.bougouin@univ-nantes.fr
</p>
<p>R&#201;SUM&#201;
Cet article pr&#233;sente les principales m&#233;thodes d&#8217;extraction automatique de termes-cl&#233;s. La t&#226;che
d&#8217;extraction automatique de termes-cl&#233;s consiste &#224; analyser un document pour en extraire
les expressions (phras&#232;mes) les plus repr&#233;sentatives de celui-ci. Les m&#233;thodes d&#8217;extraction
automatique de termes-cl&#233;s sont r&#233;parties en deux cat&#233;gories : les m&#233;thodes supervis&#233;es et
les m&#233;thodes non supervis&#233;es. Les m&#233;thodes supervis&#233;es r&#233;duisent la t&#226;che d&#8217;extraction de
termes-cl&#233;s &#224; une t&#226;che de classification binaire (tous les phras&#232;mes sont class&#233;s parmi les termes-
cl&#233;s ou les non termes-cl&#233;s). Cette classification est possible gr&#226;ce &#224; une phase pr&#233;liminaire
d&#8217;apprentissage, phase qui n&#8217;est pas requise par les m&#233;thodes non-supervis&#233;es. Ces derni&#232;res
utilisent des caract&#233;ristiques (traits) extraites du document analys&#233; (et parfois d&#8217;une collection
de documents de r&#233;f&#233;rences) pour v&#233;rifier des propri&#233;t&#233;s permettant d&#8217;identifier ses termes-cl&#233;s.
</p>
<p>ABSTRACT
State of the Art of Automatic Keyphrase Extraction Methods
</p>
<p>This article presents the state of the art of the automatic keyphrase extraction methods. The
aim of the automatic keyphrase extraction task is to extract the most representative terms of
a document. Automatic keyphrase extraction methods can be divided into two categories :
supervised methods and unsupervised methods. For supervised methods, the task is reduced
to a binary classification where terms are classified as keyphrases or non keyphrases. This
classification requires a learning step which is not required by unsupervised methods. The
unsupervised methods use features extracted from the analysed document (sometimes a
document collection) to check properties which allow keyphrase identification.
</p>
<p>MOTS-CL&#201;S : extraction de termes-cl&#233;s ; m&#233;thodes supervis&#233;es ; m&#233;thodes non-supervis&#233;es ;
&#233;tat de l&#8217;art .
</p>
<p>KEYWORDS: keyphrase extraction ; supervised methods ; unsupervised methods ; state of the
art .
</p>
<p>1 Introduction
</p>
<p>Les termes-cl&#233;s sont des mots ou des expressions (multi-mots) repr&#233;sentant les aspects principaux
qui sont abord&#233;s dans un document. De ce fait, ils sont utilis&#233;s dans de nombreux domaines
du Traitement Automatique des Langues (TAL). Turney (1999) &#233;met l&#8217;hypoth&#232;se qu&#8217;ils peuvent
faciliter la lecture d&#8217;un utilisateur en lui permettant de surfer d&#8217;un point cl&#233; &#224; un autre lorsqu&#8217;ils
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>96 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>sont mis en &#233;vidence dans un texte. D&#8217;autres chercheurs utilisent leurs vertus synth&#233;tiques dans
des m&#233;thodes de construction automatique de r&#233;sum&#233;s (Wan et al., 2007; Litvak et Last, 2008;
Boudin et Morin, 2013), mais ils s&#8217;av&#232;rent surtout de plus en plus utiles avec l&#8217;essor de l&#8217;Internet
et la disponibilit&#233; de nombreux documents num&#233;riques qu&#8217;il faut pouvoir indexer de mani&#232;re
pertinente pour faciliter leur recherche par des utilisateurs (Medelyan et Witten, 2008). Dans ce
contexte de recherche d&#8217;information, les termes-cl&#233;s peuvent aussi &#234;tre directement b&#233;n&#233;fiques
aux utilisateurs en servant de suggestions &#224; une requ&#234;te qu&#8217;ils essaient de formuler (Jones et
Staveley, 1999).
</p>
<p>Bien que les termes-cl&#233;s soient utiles pour de multiples t&#226;ches, tr&#232;s peu de documents en sont
pourvus, du fait du co&#251;t important de production de ceux-ci, en termes de temps et de ressources
humaines. Pour y rem&#233;dier de nombreux chercheurs s&#8217;int&#233;ressent &#224; l&#8217;extraction automatique de
ceux-ci et certaines campagnes d&#8217;&#233;valuations, telles que DEFT (Paroubek et al., 2012) et SemEval
(Kim et al., 2010), proposent des t&#226;ches d&#8217;extraction automatique de termes-cl&#233;s dans le but de
confronter les diff&#233;rents syst&#232;mes existants. Pour ce faire, les donn&#233;es et la m&#233;thode d&#8217;&#233;valuation
sont les m&#234;mes pour tous les syst&#232;mes.
</p>
<p>Il existe aussi une autre t&#226;che nomm&#233;e assignation automatique de termes-cl&#233;s. Cette t&#226;che est
tr&#232;s proche de l&#8217;extraction automatique de termes-cl&#233;s, mais elle est plus contr&#244;l&#233;e. Elle consiste
aussi &#224; donner un ensemble de termes-cl&#233;s pour un document, mais certains de ces termes
peuvent ne pas &#234;tre pr&#233;sents dans celui-ci. Ceci est d&#251; au fait que les m&#233;thodes d&#8217;assignation de
termes-cl&#233;s utilisent des ressources suppl&#233;mentaires telles que des r&#233;f&#233;rentiels terminologiques.
Ceux-ci contiennent des termes sp&#233;cifiques au(x) domaine(s) trait&#233;(s) et l&#8217;assignation de ces
termes peut &#234;tre d&#233;clench&#233;e par la pr&#233;sence de certains autres dans le document analys&#233;.
</p>
<p>Dans cet article, seules les m&#233;thodes d&#8217;extraction automatique de termes-cl&#233;s sont pr&#233;sent&#233;es.
Celles-ci appartiennent &#224; deux cat&#233;gories distinctes : les m&#233;thodes supervis&#233;es et les m&#233;thodes
non-supervis&#233;es. Dans le cas supervis&#233;, l&#8217;extraction des termes-cl&#233;s est effectu&#233;e gr&#226;ce &#224; un
apprentissage pr&#233;alable servant &#224; calibrer la m&#233;thode avec un corpus dont les documents sont
annot&#233;s en termes-cl&#233;s. Les m&#233;thodes non-supervis&#233;es ne requi&#232;rent pas de phase d&#8217;apprentissage.
Elles exploitent des repr&#233;sentations efficaces des documents ainsi que des propri&#233;t&#233;s d&#233;finies &#224;
partir de traits statistiques pour extraire les termes-cl&#233;s parmi des termes candidats.
</p>
<p>Dans la section 2 de cet article, nous pr&#233;sentons les m&#233;thodes existantes d&#8217;extraction automatique
de termes-cl&#233;s, en commen&#231;ant par les m&#233;thodes non-supervis&#233;es, puis les m&#233;thodes supervis&#233;es.
Dans la section 3 nous terminons par un bilan de l&#8217;&#233;tat de l&#8217;art et nous discutons des perspectives
de travaux futurs.
</p>
<p>2 Les m&#233;thodes d&#8217;extraction automatique de termes-cl&#233;s
</p>
<p>L&#8217;extraction de termes-cl&#233;s est une t&#226;che qui consiste &#224; analyser un document et &#224; en extraire
les aspects importants. Alors que les m&#233;thodes de r&#233;sum&#233; automatique utilisent des phrases
pour construire une vision synth&#233;tique du document, l&#8217;extraction de termes-cl&#233;s se focalise sur
les unit&#233;s textuelles qui composent ces phrases. Un ensemble de termes-cl&#233;s peut donc &#234;tre
per&#231;u comme un r&#233;sum&#233; dont les points cl&#233;s sont exprim&#233;s sans liaisons entre eux. Les unit&#233;s
textuelles sur lesquelles travaillent les syst&#232;mes d&#8217;extraction automatique de termes-cl&#233;s sont
appel&#233;es termes candidats. Ces derniers sont des mots ou des multi-mots (phras&#232;mes) pouvant
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>97 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#234;tre promus au statut de terme-cl&#233;.
</p>
<p>L&#8217;extraction de termes candidats est une &#233;tape pr&#233;liminaire de l&#8217;extraction de termes-cl&#233;s, que ce
soit pour les m&#233;thodes non-supervis&#233;es ou supervis&#233;es. Cette &#233;tape est importante, car si certains
termes-cl&#233;s du document analys&#233; ne sont pas pr&#233;sents dans l&#8217;ensemble des termes candidats, alors
ceux-ci ne pourront pas &#234;tre extrait. Hulth (2003) &#233;tudie trois m&#233;thodes d&#8217;extraction des termes
candidats. L&#8217;une consiste &#224; extraire les chunks nominaux 1, tandis que les deux autres extraient
tous les n-grammes et les filtrent, soit pour retirer les termes contenant des mots outils dans le
premier cas, soit pour ne retenir que les termes respectant certains patrons syntaxiques dans
le second cas (usage des parties du discours). Dans ses exp&#233;riences Hulth (2003) montre que
l&#8217;extraction de termes-cl&#233;s &#224; partir de n-grammes filtr&#233;s avec les mots outils donne les meilleurs
r&#233;sultats parmi les trois m&#233;thodes qu&#8217;elle propose.
</p>
<p>Les travaux de Hulth (2003) sont &#233;valu&#233;s avec un corpus dont les documents sont des r&#233;sum&#233;s
d&#8217;articles scientifiques. Cependant, dans d&#8217;autres domaines tels que la bio-m&#233;decine, la nature
des termes &#224; extraire n&#8217;est pas la m&#234;me. En effet, ce sont les acronymes et les entit&#233;s nomm&#233;es
(noms de prot&#233;ines par exemple) qu&#8217;il est n&#233;cessaire d&#8217;extraire en tant que termes-cl&#233;s (Nobata
et al., 2008). Pour cela, l&#8217;extraction de termes candidats est sp&#233;cifique au domaine d&#8217;application.
Les m&#233;thodes d&#8217;extraction de termes-cl&#233;s pr&#233;sent&#233;es dans cet article traitent des documents
suppos&#233;s sans sp&#233;cificit&#233;s particuli&#232;res, les m&#233;thodes d&#8217;extraction de termes candidats sont donc
les m&#234;mes que celles exp&#233;riment&#233;es par Hulth (2003), mais il est envisageable de les adapter &#224;
des domaines pr&#233;sentant des sp&#233;cificit&#233;s particuli&#232;res.
</p>
<p>Utilis&#233;s avec les m&#233;thodes non-supervis&#233;es, les termes candidats sont ordonn&#233;s selon un score
d&#8217;importance obtenu soit &#224; partir d&#8217;eux-m&#234;mes, soit &#224; partir de l&#8217;importance des mots qui les
composent. Si une m&#233;thode s&#8217;appuie uniquement sur les mots, alors le score d&#8217;un terme candidat
est g&#233;n&#233;ralement calcul&#233; en faisant la somme des mots qui le composent. Cependant, ceci
n&#8217;est pas toujours juste, c&#8217;est donc un inconv&#233;nient important des m&#233;thodes travaillant sur
les mots pour extraire les termes-cl&#233;s. En effet, la sommation peut privil&#233;gier des termes qui
contiennent beaucoup de mots non-importants vis-&#224;-vis de termes contenant tr&#232;s peu de mots,
mais importants.
</p>
<p>Utilis&#233;s dans les m&#233;thodes supervis&#233;es, les termes candidats sont class&#233;s en tant que termes-cl&#233;s
ou non termes-cl&#233;s gr&#226;ce &#224; des m&#233;thodes de classification.
</p>
<p>2.1 M&#233;thodes non-supervis&#233;es
</p>
<p>Les m&#233;thodes non-supervis&#233;es d&#8217;extraction de termes-cl&#233;s ont la particularit&#233; de s&#8217;abstraire du
domaine et de la langue des documents &#224; analyser 2. Cette abstraction est due au fait que les
termes candidats sont analys&#233;s avec des r&#232;gles simples d&#233;duites &#224; partir de traits statistiques
issus seulement du texte analys&#233;, ou bien d&#8217;un corpus de r&#233;f&#233;rence non annot&#233;.
</p>
<p>De nombreuses approches sont propos&#233;es. Certaines se fondent uniquement sur des statistiques
alors que d&#8217;autres les combinent avec des repr&#233;sentations plus complexes des documents. Ces
</p>
<p>1. Un chunk est une unit&#233; minimale de sens constitu&#233;e d&#8217;un ou de plusieurs mots. Un chunk nominal est un chunk
dont la t&#234;te est un nom ou un pronom. Par exemple, dans &#171; Nous avons une bonne politique qualitative. &#187;, &#171; Nous &#187; et
&#171; une bonne politique qualitative &#187; sont des chunks nominaux.
</p>
<p>2. L&#8217;abstraction de la langue est vraie pour ce qui est de la m&#233;thodologie, cependant les pr&#233;-traitements tels que la
segmentation en phrases, en mots et l&#8217;&#233;tiquetage en parties du discours sont eux sp&#233;cifiques &#224; la langue.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>98 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>repr&#233;sentations peuvent aller de groupes de mots s&#233;mantiquement similaires &#224; des graphes dont
les n&#339;uds sont des unit&#233;s textuelles (mots, expressions, phrases, etc.) li&#233;es par des relations de
recommandation 3.
</p>
<p>2.1.1 Approches statistiques
</p>
<p>Plusieurs approches cherchent &#224; d&#233;finir ce qu&#8217;est un terme-cl&#233; en s&#8217;appuyant sur certains traits
statistiques et en &#233;tudiant leur rapport avec la notion d&#8217;importance d&#8217;un terme candidat. Plus un
terme candidat est jug&#233; important vis-&#224;-vis du document analys&#233;, plus celui-ci est pertinent en
tant que terme-cl&#233;.
</p>
<p>TF-IDF (cf. &#233;quation 1) de Jones (1972) et Likey (cf. &#233;quation 2) de Paukkeri et Honkela (2010)
sont deux m&#233;thodes qui comparent le comportement d&#8217;un terme candidat dans le document
analys&#233; avec son comportement dans une collection de documents (corpus de r&#233;f&#233;rence). L&#8217;objectif
est de trouver les termes candidats dont le comportement dans le document varie positivement
compar&#233; &#224; leur comportement global dans la collection. Dans les deux m&#233;thodes ceci s&#8217;exprime
par le fait qu&#8217;un terme a une forte importance vis-&#224;-vis du document analys&#233; s&#8217;il y est tr&#232;s pr&#233;sent,
alors qu&#8217;il ne l&#8217;est pas dans le reste de la collection.
</p>
<p>TF-IDF(terme) = T F(terme)&#215; log
&#65535;
</p>
<p>N
DF(terme)
</p>
<p>&#65535;
(1)
</p>
<p>Like y(terme) =
rangdocument(terme)
rangcorpus(terme)
</p>
<p>(2)
</p>
<p>Dans TF-IDF, T F repr&#233;sente le nombre d&#8217;occurrences d&#8217;un terme dans le document analys&#233; et
DF repr&#233;sente le nombre de documents dans lequel il est pr&#233;sent, N &#233;tant le nombre total de
documents. Plus le score TF-IDF d&#8217;un terme candidat est &#233;lev&#233;, plus celui-ci est important dans le
document analys&#233;. Dans Likey, le rang d&#8217;un terme candidat dans le document et dans le corpus
est obtenu &#224; partir de son nombre d&#8217;occurrences, respectivement dans le document et dans le
corpus de r&#233;f&#233;rence. Plus le rapport entre ces deux rangs est faible, plus le terme candidat &#233;valu&#233;
est important dans le document analys&#233;.
</p>
<p>Okapi (ou BM25) (Robertson et al., 1999) est une mesure alternative &#224; TF-IDF. En Recherche
d&#8217;Information (RI), celle-ci est plus utilis&#233;e que le TF-IDF. Bien que l&#8217;extraction automatique de
termes-cl&#233;s soit une discipline &#224; la fronti&#232;re entre le TAL et la RI, la m&#233;thode de pond&#233;ration
Okapi n&#8217;a, &#224; notre connaissance, pas &#233;t&#233; appliqu&#233;e pour l&#8217;extraction de termes-cl&#233;s. Dans l&#8217;article
de Claveau (2012), Okapi est d&#233;crit comme un TF-IDF prenant mieux en compte la longueur des
documents. Cette derni&#232;re est utilis&#233;e pour normaliser le T F (qui devient T FBM25) :
</p>
<p>Okapi(terme) = T FBM25(terme)&#215; log
&#65535;
N &#8722; DF(terme) + 0,5
</p>
<p>DF(terme) + 0,5
</p>
<p>&#65535;
(3)
</p>
<p>T FBM25 =
T F(terme)&#215; (k1 + 1)
</p>
<p>T F(terme) + k1 &#215;
&#65535;
1&#8722; b+ b&#215; DL
</p>
<p>DLmoyenne
</p>
<p>&#65535; (4)
3. Pour une &#233;tude comparative de certaines des m&#233;thodes par regroupement (Liu et al., 2009) et &#224; base de graphe
</p>
<p>(Mihalcea et Tarau, 2004; Wan et Xiao, 2008b), voir l&#8217;article de Hasan et Ng (2010).
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>99 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Dans la formule (4), k1 et b sont des constantes fix&#233;es &#224; 2 et 0, 75 respectivement. DL repr&#233;sente
la longueur du document analys&#233; et DLmoyenne la longueur moyenne des documents de la
collection utilis&#233;e.
</p>
<p>Barker et Cornacchia (2000) estiment que les grands phras&#232;mes sont plus informatifs et qu&#8217;ils
doivent &#234;tre privil&#233;gi&#233;s. Pour cela, leur approche est tr&#232;s simple : plus un groupe nominal est
long et fr&#233;quent dans le document analys&#233;, plus il est jug&#233; pertinent en tant que terme-cl&#233; de ce
document. Cependant, pour &#233;viter la r&#233;p&#233;tition dans le texte, les auteurs des documents utilisent
les m&#234;me expression sous des formes alternatives (plus courtes, par exemple). La fr&#233;quence
d&#8217;une expression ne refl&#232;te donc pas forc&#233;ment sa fr&#233;quence r&#233;elle d&#8217;utilisation, car celle-ci est
r&#233;partie dans les diff&#233;rentes alternatives. De ce fait, Barker et Cornacchia (2000) rep&#232;rent dans
les groupes nominaux la t&#234;te nominale et utilisent en plus la fr&#233;quence de celle-ci.
</p>
<p>Tomokiyo et Hurst (2003) tentent de v&#233;rifier deux propri&#233;t&#233;s, en utilisant des mod&#232;les de langue
uni-grammes et n-grammes et en calculant leur divergence (Kullback-Leibler). Les deux propri&#233;t&#233;s
qu&#8217;ils tentent de v&#233;rifier sont les suivantes :
</p>
<p>- La grammaticalit&#233; : un terme-cl&#233; doit &#234;tre bien form&#233; syntaxiquement.
</p>
<p>- L&#8217;informativit&#233; : un terme-cl&#233; doit capturer au moins une des id&#233;es essentielles exprim&#233;es
dans le document analys&#233;.
</p>
<p>Pour un terme candidat donn&#233;, plus sa probabilit&#233; en passant du mod&#232;le uni-gramme g&#233;n&#233;r&#233; &#224;
partir du document vers le mod&#232;le n-gramme g&#233;n&#233;r&#233; &#224; partir du m&#234;me document augmente, plus
il respecte la propri&#233;t&#233; de grammaticalit&#233;. De m&#234;me, plus sa probabilit&#233; en passant du mod&#232;le
n-gramme g&#233;n&#233;r&#233; &#224; partir d&#8217;un corpus de r&#233;f&#233;rence vers le mod&#232;le n-gramme g&#233;n&#233;r&#233; &#224; partir du
document analys&#233; augmente, plus le terme candidat est informatif.
</p>
<p>La m&#233;thode que propose Ding et al. (2011) utilise TF-IDF comme indicateur de l&#8217;importance d&#8217;un
terme-cl&#233;. Dans un ensemble, cette importance doit &#234;tre maximis&#233;e pour chaque terme-cl&#233;, mais
les auteurs estiment que ceci n&#8217;est pas suffisant. Comme Tomokiyo et Hurst (2003), ils d&#233;finissent
deux propri&#233;t&#233;s qui doivent &#234;tre respect&#233;es :
</p>
<p>- La couverture : un ensemble de termes-cl&#233;s doit couvrir l&#8217;int&#233;gralit&#233; des sujets abord&#233;s
dans le document repr&#233;sent&#233;.
</p>
<p>- La coh&#233;rence : les termes-cl&#233;s doivent &#234;tre coh&#233;rents entre eux.
</p>
<p>La propri&#233;t&#233; de couverture est &#233;valu&#233;e avec le mod&#232;le Latent Dirichlet Allocation (LDA) qui donne
la probabilit&#233; d&#8217;un terme candidat sachant un sujet. La coh&#233;rence est &#233;valu&#233;e pour chaque paire
de termes-cl&#233;s de l&#8217;ensemble avec la mesure d&#8217;information mutuelle. Ces deux propri&#233;t&#233;s sont
d&#233;finies comme contraintes que les auteurs utilisent avec une m&#233;thode de programmation par les
entiers (technique d&#8217;optimisation), la maximisation de la pertinence de chaque terme-cl&#233; &#233;tant
l&#8217;objectif &#224; atteindre.
</p>
<p>Les traits statistiques utilis&#233;s dans les m&#233;thodes pr&#233;c&#233;dentes sont uniquement utilis&#233;s pour
d&#233;terminer un score de pertinence des termes candidats en tant que termes-cl&#233;s. Une donn&#233;e
statistique non cit&#233;e pr&#233;c&#233;demment, mais pourtant r&#233;currente dans les m&#233;thodes d&#8217;extraction de
termes-cl&#233;s, est la fr&#233;quence de co-occurrences entre deux phras&#232;mes (termes). Deux phras&#232;mes
co-occurrent s&#8217;ils apparaissent ensemble dans le m&#234;me contexte. La co-occurrence peut &#234;tre
calcul&#233;e de mani&#232;re stricte (les phras&#232;mes doivent &#234;tre c&#244;te-&#224;-c&#244;te) ou bien dans une fen&#234;tre
de mots. Compter le nombre de co-occurrences entre deux termes permet d&#8217;estimer s&#8217;ils sont
s&#233;mantiquement li&#233;s ou non. Ce lien s&#233;mantique &#224; lui seul ne peut pas servir &#224; extraire des
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>100 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>termes-cl&#233;s, mais il permet de mieux organiser les termes d&#8217;un document pour affiner l&#8217;extraction
(Matsuo et Ishizuka, 2004; Liu et al., 2009; Mihalcea et Tarau, 2004).
</p>
<p>2.1.2 Approches par regroupement
</p>
<p>L&#8217;objectif des approches par regroupement est de d&#233;finir des groupes dont les unit&#233;s textuelles
partagent une ou plusieurs caract&#233;ristiques communes. Ainsi, lorsque des termes-cl&#233;s sont
extraits &#224; partir de chaque groupe, cela permet de mieux couvrir le document analys&#233; selon les
caract&#233;ristiques utilis&#233;es.
</p>
<p>Dans la m&#233;thode de Matsuo et Ishizuka (2004), ce sont les termes (phras&#232;mes) qui sont regroup&#233;s.
Parmi ceux-ci, seuls les plus fr&#233;quents sont concern&#233;s par le regroupement. Celui-ci s&#8217;effectue en
fonction du lien s&#233;mantique 4 entre les termes. Apr&#232;s le regroupement, la m&#233;thode consiste &#224;
comparer les termes candidats du document analys&#233; avec les groupes de termes fr&#233;quents, en
faisant l&#8217;hypoth&#232;se qu&#8217;un terme candidat qui co-occurre plus que selon toute probabilit&#233; avec les
termes fr&#233;quents d&#8217;un ou plusieurs groupes est plus vraisemblablement un terme-cl&#233;.
</p>
<p>Dans l&#8217;algorithme KeyCluster, Liu et al. (2009) utilisent aussi un regroupement s&#233;mantique, mais
dans leur cas ils consid&#232;rent les mots du document analys&#233; et ils excluent les mots outils. Dans
chaque groupe s&#233;mantique, le mot qui est le plus proche du centro&#239;de est s&#233;lectionn&#233; comme mot
de r&#233;f&#233;rence. L&#8217;ensemble des mots de r&#233;f&#233;rence est ensuite utilis&#233; pour filtrer les termes candidats
en ne consid&#233;rant comme termes-cl&#233;s que ceux qui contiennent au moins un mot de r&#233;f&#233;rence
(tous les mots de r&#233;f&#233;rence devant &#234;tre utilis&#233;s dans au moins un terme-cl&#233;).
</p>
<p>2.1.3 Approches &#224; base de graphe
</p>
<p>Les approches &#224; base de graphe consistent &#224; repr&#233;senter le contenu d&#8217;un document sous la forme
d&#8217;un graphe. La m&#233;thodologie appliqu&#233;e est issue de PageRank (Brin et Page, 1998), un algo-
rithme d&#8217;ordonnancement de pages Web (n&#339;uds du graphe) gr&#226;ce aux liens de recommandation
qui existent entre elles (arcs du graphe). TextRank (Mihalcea et Tarau, 2004) et SingleRank (Wan
et Xiao, 2008b) sont les deux adaptations de base de PageRank pour l&#8217;extraction automatique
de termes-cl&#233;s 5. Dans celles-ci, les pages Web sont remplac&#233;es par des unit&#233;s textuelles dont
la granularit&#233; est le mot et un arc est cr&#233;&#233; entre deux n&#339;uds si les mots qu&#8217;ils repr&#233;sentent
co-occurrent dans une fen&#234;tre de mots donn&#233;e.
</p>
<p>Le graphe est not&#233; G = (N ,A), o&#249; N est l&#8217;ensemble des n&#339;uds du graphe et o&#249; A est l&#8217;ensemble
de ses arcs entrants et sortant : Aentrant &#8746; Asor tant 6. Pour chaque n&#339;ud du graphe, un score est
calcul&#233; par un processus it&#233;ratif destin&#233; &#224; simuler la notion de recommandation d&#8217;une unit&#233;
textuelle par d&#8217;autres 7 (cf. &#233;quation 5). Ce score &#224; chaque n&#339;ud ni permet d&#8217;ordonner les mots
par degr&#233; d&#8217;importance dans le document analys&#233;. La liste ordonn&#233;e des mots peut ensuite &#234;tre
</p>
<p>4. Deux phras&#232;mes qui co-occurrent fr&#233;quemment ensemble sont jug&#233;s s&#233;mantiquement li&#233;s.
5. TextRank a aussi &#233;t&#233; utilis&#233; pour faire du r&#233;sum&#233; automatique.
6. Dans le cas de TextRank et de SingleRank Aentrant = Asor tant , car le graphe n&#8217;est pas orient&#233;.
7. Plus le score d&#8217;une unit&#233; textuelle est &#233;lev&#233;, plus celle-ci est importante dans le document analys&#233;.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>101 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>utilis&#233;e pour extraire les termes-cl&#233;s.
</p>
<p>S(ni) = (1&#8722;&#955;) +&#955;&#215;
&#65535;
</p>
<p>nj&#8712;Aentrant(ni)
</p>
<p>pj,i &#215; S(nj)&#65535;
nk&#8712;Asortant(nj)
</p>
<p>pj,k
(5)
</p>
<p>&#955; est un facteur d&#8217;att&#233;nuation qui peut &#234;tre consid&#233;r&#233; ici comme la probabilit&#233; pour que le n&#339;ud
ni soit atteint par recommandation. pj,i repr&#233;sente le poids de l&#8217;arc allant du n&#339;ud nj vers le
n&#339;ud ni , soit le nombre de co-occurrences entre les deux mots i et j 8.
</p>
<p>Dans leurs travaux, Wan et Xiao (2008b) s&#8217;int&#233;ressent &#224; l&#8217;ajout d&#8217;informations dans le graphe
gr&#226;ce &#224; des documents similaires (voisins) et aux relations de co-occurrences qu&#8217;ils poss&#232;dent
(ExpandRank). L&#8217;objectif est de faire mieux ressortir les mots importants du graphe en ajoutant
de nouveaux liens de recommandation ou bien en renfor&#231;ant ceux qui existent d&#233;j&#224;. L&#8217;usage de
documents similaires peut cependant ajouter ou renforcer des liens qui ne devraient pas l&#8217;&#234;tre.
Pour &#233;viter cela, les auteurs r&#233;duisent l&#8217;impact des documents voisins en utilisant leur degr&#233;
de similarit&#233; avec le document analys&#233;. Une alternative &#224; ExpandRank, CollabRank, &#233;galement
propos&#233;e par Wan et Xiao (2008a), fonctionne de la m&#234;me mani&#232;re, mais certains choix des
auteurs rendent impossible l&#8217;usage du degr&#233; de similarit&#233; pour r&#233;duire l&#8217;impact des documents
voisins. Les r&#233;sultats moins concluants de CollabRank tendent &#224; confirmer l&#8217;importance de l&#8217;usage
du degr&#233; de similarit&#233;.
</p>
<p>Dans l&#8217;optique d&#8217;am&#233;liorer encore TextRank/SingleRank, Liu et al. (2010) proposent une m&#233;thode
qui cherche cette fois-ci &#224; augmenter la couverture de l&#8217;ensemble des termes-cl&#233;s extraits dans le
document analys&#233; (TopicalPageRank). Pour ce faire, ils tentent d&#8217;affiner le rang d&#8217;importance des
mots dans le document en tenant compte de leur rang dans chaque sujet abord&#233;. Le rang d&#8217;un
mot pour un sujet est obtenu en int&#233;grant &#224; son score PageRank la probabilit&#233; qu&#8217;il appartienne
au sujet (cf. &#233;quation 6). Le rang global d&#8217;un terme candidat est ensuite obtenu en fusionnant ses
rangs pour chaque sujet.
</p>
<p>Ssujet(Ni) = (1&#8722;&#955;)&#215; p(sujet|i) +&#955;&#215;
&#65535;
</p>
<p>Nj&#8712;Aentrant(Ni)
</p>
<p>pj,i &#215; S(Nj)&#65535;
Nk&#8712;Asortant(Nj)
</p>
<p>pj,k
(6)
</p>
<p>Les approches &#224; bases de graphe pr&#233;sent&#233;es ci-dessus effectuent toutes un ordonnancement des
mots du document analys&#233; selon leur importance dans celui-ci. Pour extraire les termes-cl&#233;s il est
donc n&#233;cessaire d&#8217;effectuer du travail suppl&#233;mentaire &#224; partir de la liste ordonn&#233;e de mots. Dans
la m&#233;thode TextRank, les k mots les plus importants sont s&#233;lectionn&#233;s et retourn&#233;s (apr&#232;s que
ceux apparaissant en collocation dans le document aient &#233;t&#233; concat&#233;n&#233;s). La technique utilis&#233;e
dans les autres m&#233;thodes consiste &#224; ordonner les termes candidats en fonction de la somme du
score des mots qui les composent. Cependant, puisque l&#8217;un des avantages du graphe est que les
n&#339;uds peuvent avoir une granularit&#233; contr&#244;l&#233;e, Liang et al. (2009) d&#233;cident d&#8217;utiliser des mots
et des multi-mots au lieu de simples mots et de tirer profit de traits suppl&#233;mentaires, la taille du
terme ou encore sa premi&#232;re position dans le document analys&#233;.
</p>
<p>8. TextRank utilise un graphe non-pond&#233;r&#233;. Dans ce cas, pj,i vaut toujours 1.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>102 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>2.2 M&#233;thodes supervis&#233;es
</p>
<p>Les m&#233;thodes supervis&#233;es sont des m&#233;thodes capables d&#8217;apprendre &#224; r&#233;aliser une t&#226;che parti-
culi&#232;re, soit ici l&#8217;extraction de termes-cl&#233;s. L&#8217;apprentissage se fait gr&#226;ce &#224; un corpus dont les
documents sont annot&#233;s en termes-cl&#233;s. L&#8217;annotation permet d&#8217;extraire les exemples et les contres-
exemples dont les traits statistiques et/ou linguistiques servent &#224; apprendre une classification
binaire. La classification binaire consiste &#224; indiquer si un terme candidat est un terme-cl&#233; ou non.
</p>
<p>De nombreux algorithmes d&#8217;apprentissage sont utilis&#233;s dans divers domaines. Ils peuvent po-
tentiellement s&#8217;adapter &#224; n&#8217;importe quelle t&#226;che, dont celle de l&#8217;extraction automatique de
termes-cl&#233;s. Les algorithmes utilis&#233;s pour celle-ci construisent des mod&#232;les probabilistes, des
arbres de d&#233;cision, des S&#233;parateurs &#224; Large Marge (SVM) ou encore des r&#233;seaux de neurones 9.
</p>
<p>KEA (Witten et al., 1999) est une m&#233;thode qui utilise une classification na&#239;ve bay&#233;sienne pour
attribuer un score de vraisemblance &#224; chaque terme candidat, le but &#233;tant d&#8217;indiquer s&#8217;ils sont des
termes-cl&#233;s ou non 10. Witten et al. (1999) utilisent trois distributions conditionnelles apprises &#224;
partir du corpus d&#8217;apprentissage. La premi&#232;re correspond &#224; la probabilit&#233; pour que chaque terme
candidat soit &#233;tiquet&#233; oui (terme-cl&#233;) ou non (non terme-cl&#233;). Les deux autres correspondent &#224;
deux diff&#233;rents traits qui sont le poids TF-IDF du terme candidat et sa premi&#232;re position dans le
document :
</p>
<p>P(terme) =
Poui(terme)
</p>
<p>Poui(terme) + Pnon(terme)
(7)
</p>
<p>Poui(terme) = P(terme|oui)&#215;
&#65535;
</p>
<p>trait&#8712;{TF-IDF,position}
Ptrait (trait(terme)|oui)
</p>
<p>Pnon(terme) = P(terme|non)&#215;
&#65535;
</p>
<p>trait&#8712;{TF-IDF,position}
Ptrait (trait(terme)|non)
</p>
<p>L&#8217;un des avantages de la classification na&#239;ve bay&#233;sienne est que chaque distribution est suppos&#233;e
ind&#233;pendante. L&#8217;ajout de nouveaux traits dans la m&#233;thode KEA est donc tr&#232;s ais&#233;.
</p>
<p>Parmi les variantes de KEA propos&#233;es, Frank et al. (1999) ajoutent un troisi&#232;me trait : le nombre
de fois que le terme candidat est un terme-cl&#233; dans le corpus d&#8217;apprentissage. L&#8217;ajout de ce trait
permet d&#8217;am&#233;liorer les performances de la version originale de KEA, mais uniquement lorsque
la quantit&#233; de donn&#233;es d&#8217;apprentissage est tr&#232;s importante. Une autre am&#233;lioration de KEA,
propos&#233;e par Turney (2003), tente d&#8217;augmenter la coh&#233;rence entre les termes candidats les
mieux class&#233;s. Pour ce faire, une premi&#232;re &#233;tape de classification est effectu&#233;e avec la m&#233;thode
originale. Cette premi&#232;re &#233;tape permet d&#8217;obtenir un premier classement des termes candidats
selon leur score de vraisemblance. Ensuite, de nouveaux traits sont ajout&#233;s et une nouvelle
&#233;tape de classification est lanc&#233;e. Les nouveaux traits ont pour but d&#8217;augmenter le score de
vraisemblance des termes candidats ayant un fort lien s&#233;mantique avec certains des termes
les mieux class&#233;s apr&#232;s la premi&#232;re &#233;tape. Enfin, Nguyen et Kan (2007) proposent l&#8217;ajout des
</p>
<p>9. Sarkar et al. (2012) proposent une &#233;tude comparative de l&#8217;usage des arbres de d&#233;cision, de la classification na&#239;ve
bay&#233;sienne et des r&#233;seaux de neurones pour l&#8217;extraction automatique de termes-cl&#233;s.
10. Il est important de noter que le score de vraisemblance pour chaque terme candidat permet aussi de les ordonner
</p>
<p>entre eux.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>103 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>informations concernant la structure des documents. En effet, certaines sections telles que
l&#8217;introduction et la conclusion dans les articles scientifiques sont plus susceptibles de contenir
des termes-cl&#233;s qu&#8217;une section pr&#233;sentant des r&#233;sultats exp&#233;rimentaux, par exemple. Dans leur
version modifi&#233;e de KEA, ils proposent aussi l&#8217;usage de traits linguistiques tels que les parties du
discours qui ont prouv&#233;es jouer un r&#244;le non-n&#233;gligeable pour l&#8217;extraction de termes-cl&#233;s (Hulth,
2003).
</p>
<p>En m&#234;me temps que KEA (Witten et al., 1999), Turney (1999) met au point l&#8217;algorithme g&#233;n&#233;tique
GenEx. GenEx est constitu&#233; de deux composants. Le premier composant, le g&#233;niteur, sert &#224;
apprendre des param&#232;tres lors de la phase d&#8217;apprentissage. Ces param&#232;tres sont utilis&#233;s par le
second composant, l&#8217;extracteur, pour donner un score d&#8217;importance &#224; chaque terme candidat.
Plus les param&#232;tres sont optimaux, meilleure est la classification des termes. Pour ce faire, les
param&#232;tres sont repr&#233;sent&#233;s sous la forme de bits qui constituent une population d&#8217;individus que
le g&#233;niteur fait &#233;voluer jusqu&#8217;&#224; obtenir un &#233;tat stable correspondant aux param&#232;tres optimaux.
</p>
<p>Dans son article pr&#233;sentant GenEx, Turney (1999) discute une autre m&#233;thode pour l&#8217;extraction de
termes-cl&#233;s. Cette m&#233;thode utilise de nombreux traits qui servent &#224; entra&#238;ner 50 arbres de d&#233;cision
C4.5 (technique de Random Forest). Dans un arbre de d&#233;cision, chaque branche repr&#233;sente un test
sur l&#8217;un des traits d&#8217;un terme candidat. Les tests permettent un routage du terme candidat vers la
feuille de l&#8217;arbre qui d&#233;termine sa classe. Gr&#226;ce &#224; la technique de Random Forest, soit l&#8217;usage de
plusieurs arbres entra&#238;n&#233;s sur un &#233;chantillon diff&#233;rent du corpus d&#8217;apprentissage, l&#8217;extraction
automatique de termes-cl&#233;s est r&#233;duite &#224; un vote de chaque arbre pour chaque terme candidat.
Cela permet un classement des termes candidats en fonction de leur nombre de votes positifs.
Les termes-cl&#233;s extraits correspondent aux termes candidats les mieux class&#233;s.
</p>
<p>La m&#234;me ann&#233;e que les travaux de Hulth (2003) sur le bien fond&#233; d&#8217;utiliser des traits linguistiques
pour l&#8217;extraction automatique de termes-cl&#233;s, Sujian et al. (2003) proposent une m&#233;thode utilisant
un mod&#232;le d&#8217;entropie maximale (cf. &#233;quation 8) dont l&#8217;un des traits repose sur les parties du
discours des mots qui composent les termes candidats. Un mod&#232;le de maximum d&#8217;entropie
consiste &#224; trouver parmi plusieurs distributions, une pour chaque trait, laquelle a la plus forte
entropie. La distribution ayant la plus forte entropie est par d&#233;finition celle qui contient le moins
d&#8217;informations, ce qui la rend de ce fait moins arbitraire pour l&#8217;extraction des termes-cl&#233;s.
</p>
<p>Score(terme) =
P(oui|terme)
P(non|terme) (8)
</p>
<p>P(classe|terme) =
exp
</p>
<p>&#65535;&#65535;
trait
</p>
<p>&#945;trait &#215; trait(terme, classe)
&#65535;
</p>
<p>&#65535;
c&#8712;{oui,non}
</p>
<p>exp
</p>
<p>&#65535;&#65535;
trait
</p>
<p>&#945;trait &#215; trait(terme, c)
&#65535;
</p>
<p>Le param&#232;tre &#945;trait d&#233;finit l&#8217;importance du trait auquel il est associ&#233;.
</p>
<p>Les S&#233;parateurs &#224; Large Marge sont aussi des classifieurs utilis&#233;s par les m&#233;thodes d&#8217;extraction
automatique de termes-cl&#233;s. Ils exploitent divers traits afin de projeter des exemples et des
contres-exemples sur un plan, puis ils cherchent l&#8217;hyperplan qui les s&#233;pare. Cet hyperplan sert
ensuite dans l&#8217;analyse de nouvelles donn&#233;es. Dans le contexte de l&#8217;extraction de termes-cl&#233;s,
les exemples sont les termes-cl&#233;s et les contres-exemples sont les termes candidats qui ne sont
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>104 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>pas des termes-cl&#233;s. Ce mode de fonctionnement des SVM est utilis&#233; par Zhang et al. (2006),
mais un autre type de SVM est plus largement utilis&#233; dans les m&#233;thodes supervis&#233;es d&#8217;extraction
de termes-cl&#233;s. Il s&#8217;agit de SVM qui utilisent de multiples marges repr&#233;sentant des rangs. Ces
classifieurs permettent donc d&#8217;ordonnancer les termes-cl&#233;s lors de leur extraction (Herbrich et al.,
1999; Joachims, 2006; Jiang et al., 2009). La m&#233;thode KeyWE de Eichler et Neumann (2010)
utilise ce type de SVM avec le trait TF-IDF ainsi qu&#8217;un trait bool&#233;en ayant la valeur vraie si le terme
candidat appara&#238;t dans un titre d&#8217;un article Wikipedia (un terme candidat apparaissant dans le
titre d&#8217;un article de Wikipedia a une plus forte probabilit&#233; d&#8217;&#234;tre un terme-cl&#233;). L&#8217;ordonnancement
des termes candidats par le SVM permet ensuite de contr&#244;ler le nombre de termes-cl&#233;s &#224; extraire
(choix des k termes candidats les mieux class&#233;s).
</p>
<p>Tout comme Turney (1999), Ercan et Cicekli (2007) utilisent eux aussi une for&#234;t d&#8217;arbres C4.5
dans leur m&#233;thode d&#8217;extraction de termes-cl&#233;s. Ils utilisent des traits classiques et leur contribution
se situe au niveau de l&#8217;utilisation d&#8217;un trait calcul&#233; &#224; partir de cha&#238;nes lexicales. Une cha&#238;ne
lexicale lie les mots d&#8217;un document selon certaines relations telles que la synonymie, l&#8217;hyponymie
ou la m&#233;ronymie. Ces relations permettent de calculer un score qui sert de trait. Cette approche
est int&#233;ressante, mais du fait de limitations des cha&#238;nes lexicales actuellement disponibles elle
pr&#233;sente l&#8217;inconv&#233;nient de ne retourner que des mots (aucun multi-mot). Cependant, l&#8217;usage
d&#8217;une for&#234;t d&#8217;arbre C4.5 permet un classement des mots &#224; partir de leur nombre de votes positifs.
Il est donc envisageable de d&#233;duire les termes-cl&#233;s &#224; partir de la liste ordonn&#233;e et pond&#233;r&#233;e des
mots cl&#233;s (voir les m&#233;thodes non-supervis&#233;es &#224; bases de graphe &#8211; section 2.1).
</p>
<p>Une autre m&#233;thode pour l&#8217;extraction automatique de termes-cl&#233;s consiste &#224; utiliser un perceptron
multi-couches (Sarkar et al., 2010). Un perceptron multi-couches est un r&#233;seau de neurones
constitu&#233; d&#8217;au moins trois couches, chaque couche &#233;tant compos&#233;e de neurones. Dans les deux
couches extr&#234;mes les neurones repr&#233;sentent respectivement les entr&#233;es et les sorties. Les couches
centrales sont des couches cach&#233;es qui permettent d&#8217;acheminer les valeurs des entr&#233;es vers les
sorties, o&#249; de nouvelles valeurs sont obtenues gr&#226;ce &#224; la pond&#233;ration des transitions d&#8217;un neurone
d&#8217;une couche vers un neurone de la couche suivante. Les entr&#233;es correspondent aux traits d&#8217;un
terme candidat (ici TF-IDF, la position, la taille, etc.) et les sorties repr&#233;sentent les classes qu&#8217;il
peut prendre (terme-cl&#233; ou non terme-cl&#233;). La valeur obtenue pour chaque sortie (classe) permet
d&#8217;obtenir une probabilit&#233; pour que le terme candidat analys&#233; soit un terme-cl&#233; ou non. Dans leur
m&#233;thode, Sarkar et al. (2010) utilisent cette probabilit&#233; pour ordonner les termes candidats afin
de mieux contr&#244;ler le nombre de termes-cl&#233;s &#224; extraire.
</p>
<p>Dans leurs travaux, Liu et al. (2011) proposent une m&#233;thode d&#8217;extraction de termes-cl&#233;s bas&#233;e sur
un mod&#232;le g&#233;n&#233;ratif. Leur m&#233;thode est tr&#232;s diff&#233;rente de celle de Witten et al. (1999) puisqu&#8217;ils
d&#233;cident d&#8217;utiliser une approche de traduction automatique. L&#8217;usage original de cette approche est
justifi&#233; par le fait qu&#8217;un ensemble de termes-cl&#233;s doit d&#233;crire de mani&#232;re synth&#233;tique le document.
Leur hypoth&#232;se est donc qu&#8217;un ensemble de termes-cl&#233;s est une traduction d&#8217;un document dans
un autre langage. Le mod&#232;le est appris &#224; partir de paires de traductions dont l&#8217;un des termes est
issu des titres ou des r&#233;sum&#233;s des documents du corpus d&#8217;apprentissage et dont l&#8217;autre terme est
issu des corps de ces m&#234;mes documents. Les titres et les r&#233;sum&#233;s sont utilis&#233;s comme langage
synth&#233;tique et les corps des documents comme le langage naturel de ceux-ci.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>105 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>3 Conclusion et perspectives
</p>
<p>L&#8217;extraction automatique de termes-cl&#233;s est une t&#226;che importante qui permet la valorisation d&#8217;un
document (repr&#233;sentation synth&#233;tique, mise en &#233;vidence des points cl&#233;s dans le document, etc.)
et qui facilite l&#8217;acc&#232;s aux documents pertinents pour une requ&#234;te utilisateur (indexation pour la
recherche d&#8217;information).
</p>
<p>Les m&#233;thodes existantes pour la t&#226;che d&#8217;extraction automatique de termes-cl&#233;s sont soit supervi-
s&#233;es, soit non-supervis&#233;es. Les m&#233;thodes non-supervis&#233;es sont des m&#233;thodes &#233;mergentes ayant
la particularit&#233; de s&#8217;abstraire de la sp&#233;cificit&#233; des donn&#233;es trait&#233;es. Cette abstraction s&#8217;explique
par des approches bas&#233;es sur des constatations &#224; propos de ce qu&#8217;est un terme-cl&#233; au sens
g&#233;n&#233;ral : importance s&#233;mantique, degr&#233; d&#8217;information, structure syntaxique, etc. Contrairement
aux m&#233;thodes non-supervis&#233;es, les m&#233;thodes supervis&#233;es n&#8217;utilisent pas de propri&#233;t&#233;s d&#233;finies &#224;
partir des traits statistiques et linguistiques, mais elles utilisent des mod&#232;les de d&#233;cision appris &#224;
partir de ces traits, calcul&#233;s sur les termes-cl&#233;s d&#8217;un corpus d&#8217;apprentissage. L&#8217;usage d&#8217;un corpus
d&#8217;apprentissage implique que les mod&#232;les appris soient sp&#233;cifiques au domaine disciplinaire et &#224;
la langue de celui-ci. Cette sp&#233;cificit&#233; peut s&#8217;av&#233;rer avantageuse lorsque le domaine et la langue
que repr&#233;sente le corpus sont les m&#234;mes pour les documents qui sont ensuite analys&#233;s, mais si
tel n&#8217;est pas le cas les r&#233;sultats de l&#8217;extraction peuvent en p&#226;tir.
</p>
<p>De futurs travaux peuvent se focaliser sur une hybridation des m&#233;thodes non-supervis&#233;es et
supervis&#233;es. Dans un premier temps, il peut &#234;tre int&#233;ressant de tenter d&#8217;am&#233;liorer les m&#233;thodes &#224;
base de graphe existantes. En effet, le graphe poss&#232;de plusieurs points de variabilit&#233; sur lesquels
il est possible d&#8217;agir pour affiner l&#8217;extraction : la granularit&#233; des n&#339;uds, le type de relations
permettant la cr&#233;ation des arcs ou encore le facteur d&#8217;att&#233;nuation &#955; utilis&#233; dans le calcul du score
des n&#339;uds. La granularit&#233; peut &#234;tre &#233;tendue &#224; des groupes de phras&#232;mes similaires (des variantes
dont le sens est sensiblement le m&#234;me). Cette nouvelle granularit&#233; peut impliquer la d&#233;finition
d&#8217;une nouvelle relation pour la cr&#233;ation des arcs entre les n&#339;uds. Enfin, des traits peuvent &#234;tre
appris, pond&#233;r&#233;s gr&#226;ce &#224; de l&#8217;apprentissage pr&#233;alable, puis utilis&#233;s avec le facteur (1&#8722;&#955;) dans le
calcul du score pour chaque n&#339;ud (voir la modification du score dans TopicalPageRank (Liu et al.,
2010)). Il est possible que ce dernier point demande de modifier la formule du score PageRank
afin d&#8217;utiliser le score de recommandation et de nouveaux traits de mani&#232;re coh&#233;rente (sans que
la valeur d&#8217;un trait ne puisse annihiler le score de recommandation).
</p>
<p>Remerciements
</p>
<p>Ce travail a b&#233;n&#233;fici&#233; d&#8217;une aide de l&#8217;Agence Nationale de la Recherche portant la r&#233;f&#233;rence
(ANR-12-CORD-0029).
</p>
<p>R&#233;f&#233;rences
</p>
<p>BARKER, K. et CORNACCHIA, N. (2000). Using Noun Phrase Heads to Extract Document Keyphrases.
In Proceedings of the 13th Biennial Conference of the Canadian Society on Computational Studies
of Intelligence : Advances in Artificial Intelligence.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>106 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>BOUDIN, F. et MORIN, E. (2013). Keyphrase Extraction for N-best Reranking in Multi-Sentence
Compression. In Proceedings of the North American Chapter of the Association for Computational
Linguistics (NAACL).
BRIN, S. et PAGE, L. (1998). The Anatomy of a Large-Scale hypertextual Web Search Engine. In
Proceedings of the 7th International Conference on World Wide Web.
CLAVEAU, V. (2012). Vectorisation, Okapi et Calcul de Similarit&#233; pour le TAL : pour Oublier Enfin
le TF-IDF. In Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2 : TALN.
DING, Z., ZHANG, Q. et HUANG, X. (2011). Keyphrase Extraction from Online News Using Binary
Integer Programming. In Proceedings of 5th International Joint Conference on Natural Language
Processing.
EICHLER, K. et NEUMANN, G. (2010). DFKI KeyWE : Ranking Keyphrases Extracted from Scientific
Articles. In Proceedings of the 5th International Workshop on Semantic Evaluation.
ERCAN, G. et CICEKLI, I. (2007). Using Lexical Chains for Keyword Extraction.
</p>
<p>FRANK, E., PAYNTER, G., WITTEN, I., GUTWIN, C. et NEVILL-MANNING, C. (1999). Domain-Specific
Keyphrase Extraction.
</p>
<p>HASAN, K. et NG, V. (2010). Conundrums in Unsupervised Keyphrase Extraction : Making Sense
of the State-of-the-Art. In Proceedings of the 23rd International Conference on Computational
Linguistics : Posters.
HERBRICH, R., GRAEPEL, T. et OBERMAYER, K. (1999). Support Vector Learning for Ordinal
Regression. In Artificial Neural Networks, 1999.
HULTH, A. (2003). Improved Automatic Keyword Extraction Given More Linguistic Knowledge.
In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing.
JIANG, X., HU, Y. et LI, H. (2009). A Ranking Approach to Keyphrase Extraction. In Proceedings
of the 32nd international ACM SIGIR conference on Research and development in information
retrieval.
JOACHIMS, T. (2006). Training Linear SVMs in Linear Time. In Proceedings of the 12th ACM
SIGKDD international conference on Knowledge discovery and data mining.
JONES, K. (1972). A Statistical Interpretation of Term Specificity and its Application in Retrieval.
</p>
<p>JONES, S. et STAVELEY, M. (1999). Phrasier : a System for Interactive Document Retrieval Using
Keyphrases. In Proceedings of the 22nd annual international ACM SIGIR conference on Research
and development in information retrieval.
KIM, S. N., MEDELYAN, O., KAN, M. et BALDWIN, T. (2010). Semeval-2010 Task 5 : Automatic
Keyphrase Extraction from Scientific Articles. In Proceedings of the 5th International Workshop
on Semantic Evaluation.
LIANG, W., HUANG, C., LI, M. et LU, B. (2009). Extracting Keyphrases from Chinese News Articles
Using Textrank and Query Log Knowledge. In Proceedings of the 23rd Pacific Asia Conference on
Language, Information and Computation.
LITVAK, M. et LAST, M. (2008). Graph-Based Keyword Extraction for Single-Document Summari-
zation. In Proceedings of the workshop on Multi-source Multilingual Information Extraction and
Summarization.
LIU, Z., CHEN, X., ZHENG, Y. et SUN, M. (2011). Automatic Keyphrase Extraction by Bridging
Vocabulary Gap. In Proceedings of the 15th Conference on Computational Natural Language
Learning.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>107 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LIU, Z., HUANG, W., ZHENG, Y. et SUN, M. (2010). Automatic Keyphrase Extraction via Topic
Decomposition. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language
Processing.
</p>
<p>LIU, Z., LI, P., ZHENG, Y. et SUN, M. (2009). Clustering to Find Exemplar Terms for Keyphrase
Extraction. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language
Processing : Volume 1.
</p>
<p>MATSUO, Y. et ISHIZUKA, M. (2004). Keyword Extraction from a Single Document Using Word
Co-occurrence Statistical Information.
</p>
<p>MEDELYAN, O. et WITTEN, I. (2008). Domain-Independent Automatic Keyphrase Indexing with
Small Training Sets.
</p>
<p>MIHALCEA, R. et TARAU, P. (2004). Textrank : Bringing Order Into Texts. In Proceedings of the
2004 Conference on Empirical Methods in Natural Language Processing.
</p>
<p>NGUYEN, T. et KAN, M. (2007). Keyphrase Extraction in Scientific Publications. In Proceedings of
the 10th international conference on Asian digital libraries : looking back 10 years and forging
new frontiers.
</p>
<p>NOBATA, C., COTTER, P., OKAZAKI, N., REA, B., SASAKI, Y., TSURUOKA, Y., TSUJII, J. et ANANIADOU, S.
(2008). Kleio : a Knowledge-enriched Information Retrieval System for Biology. In Proceedings of
the 31st annual international ACM SIGIR conference on Research and development in information
retrieval.
</p>
<p>PAROUBEK, P., ZWEIGENBAUM, P., FOREST, D. et GROUIN, C. (2012). Indexation Libre et Contr&#244;l&#233;e
d&#8217;Articles Scientifiques Pr&#233;sentation et R&#233;sultats du D&#233;fi Fouille de Textes DEFT2012.
</p>
<p>PAUKKERI, M. et HONKELA, T. (2010). Likey : Unsupervised Language-Independent Keyphrase
Extraction. In Proceedings of the 5th International Workshop on Semantic Evaluation.
</p>
<p>ROBERTSON, S. E., WALKER, S., BEAULIEU, M. et WILLETT, P. (1999). Okapi at TREC-7 : Automatic
Ad Hoc, Filtering, VLC and Interactive Track.
</p>
<p>SARKAR, K., NASIPURI, M. et GHOSE, S. (2010). A New Approach to Keyphrase Extraction Using
Neural Networks.
</p>
<p>SARKAR, K., NASIPURI, M. et GHOSE, S. (2012). Machine Learning Based Keyphrase Extraction :
Comparing Decision Trees, Na&#239;ve Bayes, and Artificial Neural Networks.
</p>
<p>SUJIAN, L., HOUFENG, W., SHIWEN, Y. et CHENGSHENG, X. (2003). News-Oriented Keyword
Indexing with Maximum Entropy Principle.
</p>
<p>TOMOKIYO, T. et HURST, M. (2003). A Language Model Approach to Keyphrase Extraction.
In Proceedings of the ACL 2003 workshop on Multiword expressions : analysis, acquisition and
treatment-Volume 18.
</p>
<p>TURNEY, P. (1999). Learning Algorithms for Keyphrase Extraction.
</p>
<p>TURNEY, P. (2003). Coherent Keyphrase Extraction via Web Mining.
</p>
<p>WAN, X. et XIAO, J. (2008a). Collabrank : Towards a Collaborative Approach to Single-Document
Keyphrase Extraction. In Proceedings of the 22nd International Conference on Computational
Linguistics-Volume 1.
</p>
<p>WAN, X. et XIAO, J. (2008b). Single Document Keyphrase Extraction Using Neighborhood
Knowledge. In Proceedings of Association for the Advancement of Artificial Intelligence.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>108 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>WAN, X., YANG, J. et XIAO, J. (2007). Towards an Iterative Reinforcement Approach for
Simultaneous Document Summarization and Keyword Extraction. In Annual Meeting-association
For Computational Linguistics.
</p>
<p>WITTEN, I., PAYNTER, G., FRANK, E., GUTWIN, C. et NEVILL-MANNING, C. (1999). KEA : Practical
Automatic Keyphrase Extraction. In Proceedings of the 4th ACM conference on Digital libraries.
</p>
<p>ZHANG, K., XU, H., TANG, J. et LI, J. (2006). Keyword Extraction Using Support Vector Machine.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>109 c&#65535; ATALA</p>

</div></div>
</body></html>