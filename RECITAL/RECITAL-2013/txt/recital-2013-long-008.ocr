TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

ﬁtat de 1’art des méthodes d’extraction automatique de
termes—clés

Adrien Bougouin
LINA - UMR CNRS 6241, Université de Nantes, France
adrien . bougouin<0u.niv—na.ntes . fr

RESUME
Cet article présente les principales méthodes d’extraction automatique de termes—clés. La tache
d’extraction automatique de termes—clés consiste a analyser un document pour en extraire
les expressions (phrasémes) les plus représentatives de celui—ci. Les méthodes d’extraction
automatique de termes—clés sont réparties en deux catégories : les méthodes supervisées et
les méthodes non supervisées. Les méthodes supervisées réduisent la tache d’extraction de
terrnes-clés a une téche de classiﬁcation binaire (tous les phrasemes sont classés parmi les termes-
clés ou les non termes—clés). Cette classiﬁcation est possible grace a une phase préliminaire
d’apprentissage, phase qui n’est pas requise par les méthodes non-supervisées. Ces derniéres
utilisent des caractéristiques (traits) extraites du document analysé (et parfois d’une collection
de documents de références) pour vériﬁer des propriétés permettant d’idenu'ﬁer ses termes—clés.

ABSTRACT
State of the Art of Automatic Keyphrase Extraction Methods

This article presents the state of the art of the automatic keyphrase extraction methods. The
aim of the automatic keyphrase extraction task is to extract the most representative terms of
a document. Automatic keyphrase extraction methods can be divided into two categories :
supervised methods and unsupervised methods. For supervised methods, the task is reduced
to a binary classiﬁcation where terms are classiﬁed as keyphrases or non keyphrases. This
classiﬁcation requires a learning step which is not required by unsupervised methods. The
unsupervised methods use features extracted from the analysed document (sometimes a
document collection) to check properties which allow keyphrase identiﬁcation.

MOTS-CLES : extraction de termes—clés; méthodes supervisées; méthodes non—supervisées;
état de l’art .

KEYWORDS: keyphrase extraction; supervised methods; unsupervised methods; state of the
art .

1 Introduction

Les terrnes-clés sont des mots ou des expressions (multi—mots) représentant les aspects principaux
qui sont abordés dans un document. De ce fait, ils sont utilisés dans de nombreux domaines
du Traitement Automatique des Langues (TAL). Turney (1999) émet l’hypothése qu’ils peuvent
faciliter la lecture d’un utilisateur en lui permettant de surfer d’un point clé a un autre 1orsqu’ils

96 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

sont mis en évidence dans un texte. D’autres chercheurs utilisent leurs vertus synthétiques dans
des méthodes de construction automatique de résumés (Wan et al., 2007; Litvak et Last, 2008;
Boudin et Morin, 2013), mais ils s’avérent surtout de plus en plus utiles avec 1’essor de l’Internet
et la disponibilité de nombreux documents numériques qu’il faut pouvoir indexer de maniere
pertinente pour faciliter leur recherche par des utilisateurs (Medelyan et Witten, 2008). Dans ce
contexte de recherche d’information, les termes—clés peuvent aussi étre directement bénéﬁques
aux utilisateurs en servant de suggestions a une requéte qu’ils essaient de formuler (Jones et
Staveley, 1999).

Bien que les termes—clés soient utiles pour de multiples taches, tres peu de documents en sont
pourvus, du fait du coﬁt important de production de ceux—ci, en termes de temps et de ressources
humaines. Pour y remédier de nombreux chercheurs s’intéressent a l’extraction automatique de
ceux—ci et certaines campagnes d’évaluau'ons, telles que DEFT (Paroubek et al., 2012) et SemEval
(Kim et al., 2010), proposent des taches d’extraction automatique de termes—clés dans le but de
confronter les différents systémes existants. Pour ce faire, les données et la méthode d’évaluau'on
sont les mémes pour tous les systémes.

I1 existe aussi une autre tache nommée assignation automatique de termes—clés. Cette tache est
trés proche de l’extraction automatique de termes—clés, mais elle est plus controlée. Elle consiste
aussi a donner un ensemble de termes—clés pour un document, mais certains de ces termes
peuvent ne pas étre présents dans celui-ci. Ceci est dﬁ au fait que les méthodes d’assignation de
termes—clés utilisent des ressources supplémentaires telles que des référentiels terminologiques.
Ceux—ci contiennent des termes spéciﬁques au(x) domaine(s) traité(s) et l’assignation de ces
termes peut étre déclenchée par la présence de certains autres dans le document analysé.

Dans cet article, seules les méthodes d’extraction automatique de termes—clés sont présentées.
Celles—ci appartiennent a deux catégories distinctes : les méthodes supervisées et les méthodes
non—supervisées. Dans le cas supervisé, l’extraction des termes—clés est effectuée grace a un
apprentissage préalable servant a calibrer la méthode avec un corpus dont les documents sont
annotés en termes—clés. Les méthodes non-supervisées ne requiérent pas de phase d’apprentissage.
Elles exploitent des représentations efﬁcaces des documents ainsi que des propriétés déﬁnies a
partir de traits statistiques pour extraire les termes—clés parmi des termes candidats.

Dans la section 2 de cet article, nous présentons les méthodes existantes d’extraction automatique
de termes—clés, en commencant par les méthodes non-supervisées, puis les méthodes supervisées.
Dans la section 3 nous terminons par un bilan de l’état de l’art et nous discutons des perspectives
de travaux futurs.

2 Les méthodes d’extraction automatique de termes—clés

L’extraction de termes—clés est une tache qui consiste a analyser un document et a en extraire
les aspects importants. Alors que les méthodes de résumé automatique utilisent des phrases
pour construire une vision synthétique du document, l’extraction de termes—clés se focalise sur
les unités textuelles qui composent ces phrases. Un ensemble de termes—clés peut donc étre
percu comme un résumé dont les points clés sont exprimés sans liaisons entre eux. Les unités
textuelles sur lesquelles travaillent les systemes d’extraction automatique de termes—clés sont
appelées termes candidats. Ces derniers sont des mots ou des multi—mots (phrasémes) pouvant

97 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
étre promus au statut de terrne—clé.

L’extraction de termes candidats est une étape préliminaire de l’extracu'on de termes—clés, que ce
soit pour les méthodes non-supervisées ou supervisées. Cette étape est importante, car si certains
terrnes—clés du document analysé ne sont pas présents dans l’ensemble des termes candidats, alors
ceux—ci ne pourront pas étre extrait. Hulth (2003) étudie trois méthodes d’extraction des termes
candidats. L’une consiste a extraire les chunks nominaux 1, tandis que les deux autres extraient
tous les n—grammes et les ﬁltrent, soit pour retirer les termes contenant des mots outils dans le
premier cas, soit pour ne retenir que les termes respectant certains patrons syntaxiques dans
le second cas (usage des parties du discours). Dans ses expériences Hulth (2003) montre que
l’extraction de termes—clés a partir de n—grammes ﬁltrés avec les mots outils donne les meilleurs
résultats parrni les trois méthodes qu’elle propose.

Les travaux de Hulth (2003) sont évalués avec un corpus dont les documents sont des résumés
d’articles scientiﬁques. Cependant, dans d’autres domaines tels que la bio—médecine, la nature
des termes a extraire n’est pas la méme. En effet, ce sont les acronymes et les entités nommées
(noms de protéines par exemple) qu’il est nécessaire d’extraire en tant que termes—clés (Nobata
et al., 2008). Pour cela, l’extraction de termes candidats est spéciﬁque au domaine d’application.
Les méthodes d’extraction de termes—clés présentées dans cet article traitent des documents
supposés sans spéciﬁcités particuliéres, les méthodes d’extraction de termes candidats sont donc
les mémes que celles expérimentées par Hulth (2003), mais il est envisageable de les adapter a
des domaines présentant des spéciﬁcités particuliéres.

Utilisés avec les méthodes non-supervisées, les termes candidats sont ordonnés selon un score
d’importance obtenu soit a partir d’eux-mémes, soit a partir de l’importance des mots qui les
composent. Si une méthode s’appuie uniquement sur les mots, alors le score d’un terme candidat
est généralement calculé en faisant la somme des mots qui le composent. Cependant, ceci
n’est pas toujours juste, c’est donc un inconvénient important des méthodes travaillant sur
les mots pour extraire les termes—clés. En effet, la sommation peut privilégier des termes qui
contiennent beaucoup de mots non-importants vis-a-vis de termes contenant trés peu de mots,
mais importants.

Utilisés dans les méthodes supervisées, les termes candidats sont classés en tant que termes—clés
ou non termes—clés grace a des méthodes de classiﬁcation.

2.1 Méthodes non-supervisées

Les méthodes non-supervisées d’extraction de termes—clés ont la particularité de s’abstraire du
domaine et de la langue des documents a analyserz. Cette abstraction est due au fait que les
termes candidats sont analysés avec des régles simples déduites a partir de traits statistiques
issus seulement du texte analysé, ou bien d’un corpus de référence non annoté.

De nombreuses approches sont proposées. Certaines se fondent uniquement sur des statistiques
alors que d’autres les combinent avec des représentations plus complexes des documents. Ces

1. Un chunk est une unité minimale de sens constituée d’un ou de plusieurs mots. Un chunk nominal est un chunk
dont la téte est un nom ou un pronom. Par exemple, dans « Nous avons une bonne politique qualitative. », « Nous » et
<< une bonne politique qualitative >> sont des chunks nominaux.

2. L’abstraction de la langue est vraie pour ce qui est de la méthodologie, cependant les pré-traitements tels que la
segmentation en phrases, en mots et l’étiquetage en parties du discours sont eux spéciﬁques 21 la langue.

98 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

représentaﬁons peuvent aller de groupes de mots sémantiquement similaires a des graphes dont
les noeuds sont des unités textuelles (mots, expressions, phrases, etc.) liées par des relations de
recommandation 3.

2.1. 1 Approches statistiques

Plusieurs approches cherchent a déﬁnir ce qu’est un terme—clé en s’appuyant sur certains traits
statistiques et en étudiant leur rapport avec la notion d’importance d’un terme candidat. Plus un
terme candidat est jugé important Vis—a—vis du document analysé, plus celui-ci est pertinent en
tant que terme-clé.

TF—IDF (cf. équation 1) de Jones (1972) et Likey (cf. équation 2) de Paukkeri et Honkela (2010)
sont deux méthodes qui comparent le comportement d’un terme candidat dans le document
analysé avec son comportement dans une collection de documents (corpus de référence). L’objecu'f
est de trouver les termes candidats dont le comportement dans le document varie positivement
compare a leur comportement global dans la collection. Dans les deux méthodes ceci s’exprime
par le fait qu’un terme a une forte importance vis—a—vis du document analysé s’il y est trés présent,
alors qu’il ne l’est pas dans le reste de la collection.

TF-IDF(terme) = TF(terme) X log  ) (1)
L,-kemerme, 2  (2)
rangcorpus(terme)

Dans TF—IDE TF représente le nombre d’occurrences d’un terme dans le document analysé et
DF représente le nombre de documents dans lequel il est présent, N étant le nombre total de
documents. Plus le score TF—IDF d’un terme candidat est élevé, plus celui-ci est important dans le
document analysé. Dans Likey, le rang d’un terme candidat dans le document et dans le corpus
est obtenu a partir de son nombre d’occurrences, respectivement dans le document et dans le
corpus de référence. Plus le rapport entre ces deux rangs est faible, plus le terme candidat évalué
est important dans le document analysé.

Okapi (ou BM25) (Robertson et al., 1999) est une mesure alternative a TF—IDE En Recherche
d’Information (RI), celle—ci est plus utilisée que le TF-IDE Bien que l’extraction automatique de
termes—clés soit une discipline a la frontiére entre le TAL et la RI, la méthode de pondération
Okapi n’a, a notre connaissance, pas été appliquée pour l’extraction de termes—clés. Dans l’article
de Claveau (2012), Okapi est décrit comme un TF-IDF prenant mieux en compte la longueur des
documents. Cette derniere est utilisée pour normaliser le TF (qui devient TFBM25) :

Ok _(t ) TF (t ) 1 N — DF(terme) + 0, 5 (3)
= X  
ap1 erme BM25 erme og Dmterme) + 0, 5
TF(terme) x (k + 1)
TFBM25 = 1 (4)

TF(terme)+k1x(1—b+bx DL )

D Lmoyerme

3. Pour une étude comparative de certaines des méthodes par regroupement (Liu et al., 2009) et a base de graphe
(Mihalcea et Tarau, 2004; Wan et Xiao, 2008b), voir l’article de Hasan et Ng (2010).

99 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Dans la formule (4), k1 et b sont des constantes ﬁxées a 2 et 0, 75 respectivement. DL représente
la longueur du document analysé et DL,,,oye,,,,e la longueur moyenne des documents de la
collection utilisée.

Barker et Cornacchia (2000) estiment que les grands phrasemes sont plus informatifs et qu’ils
doivent étre privilégiés. Pour cela, leur approche est tres simple : plus un groupe nominal est
long et fréquent dans le document analysé, plus il est jugé pertinent en tant que terme-clé de ce
document. Cependant, pour éviter la répétition dans le texte, les auteurs des documents utilisent
les méme expression sous des formes alternatives (plus courtes, par exemple). La fréquence
d’une expression ne reﬂéte donc pas forcément sa fréquence réelle d’uti1isation, car celle—ci est
répartie dans les différentes alternatives. De ce fait, Barker et Cornacchia (2000) reperent dans
les groupes nominaux la téte nominale et utilisent en plus la fréquence de ce1le—ci.

Tomokiyo et Hurst (2003) tentent de vériﬁer deux propriétés, en utilisant des modéles de langue
uni—grammes et n—grammes et en calculant leur divergence (Kullback—Leibler). Les deux propriétés
qu’ils tentent de vériﬁer sont les suivantes :

- La grammaticalité : un terme-clé doit étre bien formé syntaxiquement.

— L’inforrnativité : un terme-clé doit capturer au moins une des idées essentielles exprimées
dans le document analysé.

Pour un terrne candidat donne’, plus sa probabilité en passant du modele uni—gramme généré a
partir du document vers le modéle n—gramme généré a partir du méme document augrnente, plus
il respecte la propriété de grammaticalité. De méme, plus sa probabilité en passant du modéle
n—gramme généré a partir d’un corpus de référence vers le modéle n—gramme généré a partir du
document analysé augmente, plus le terrne candidat est informatif.

La méthode que propose Ding et al. (2011) utilise TF—IDF comme indicateur de l’importance d’un
terme-clé. Dans un ensemble, cette importance doit étre maximisée pour chaque terme-clé, mais
les auteurs estiment que ceci n’est pas sufﬁsant. Comme Tomokiyo et Hurst (2003), ils déﬁnissent
deux propriétés qui doivent étre respectées :

— La couverture : un ensemble de termes-clés doit couvrir l’intégralité des sujets abordés
dans le document représenté.

- La cohérence : les termes-clés doivent étre cohérents entre eux.

La propriété de couverture est évaluée avec le modéle Latent Dirichlet Allocation (LDA) qui donne
la probabilité d’un terme candidat sachant un sujet. La cohérence est évaluée pour chaque paire
de termes-clés de l’ensemble avec la mesure d’information mutuelle. Ces deux propriétés sont
déﬁnies comme contraintes que les auteurs utilisent avec une méthode de programmation par les
entiers (technique d’optimisation), la maximisation de la pertinence de chaque terme-clé étant
l’objectif a atteindre.

Les traits statistiques utilisés dans les méthodes précédentes sont uniquement utilisés pour
déterminer un score de pertinence des termes candidats en tant que termes-clés. Une donnée
statistique non citée précédemment, mais pourtant récurrente dans les méthodes d’extracu'on de
termes-clés, est la fréquence de co—occurrences entre deux phrasémes (termes). Deux phrasémes
co—occurrent s’ils apparaissent ensemble dans le méme contexte. La co—occurrence peut étre
calculée de maniere stricte (les phrasemes doivent étre c6te—a—c6te) ou bien dans une fenétre
de mots. Compter le nombre de co—occurrences entre deux termes permet d’estimer s’ils sont
sémantiquement liés ou non. Ce lien sémantique a lui seul ne peut pas servir a extraire des

100 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

termes-clés, mais il permet de mieux organiser les termes d’un document pour afﬁner l’extraction
(Matsuo et Ishizuka, 2004; Liu et al., 2009; Mihalcea et Tarau, 2004).

2.1.2 Approches par regroupement

L’objectif des approches par regroupement est de déﬁnir des groupes dont les unités textuelles
partagent une ou plusieurs caractéristiques communes. Ainsi, lorsque des termes-clés sont
extraits a partir de chaque groupe, cela permet de mieux couvrir le document analysé selon les
caractéristiques utilisées.

Dans la méthode de Matsuo et Ishizuka (2004), ce sont les termes (phrasemes) qui sont regroupés.
Parmi ceux—ci, seuls les plus fréquents sont concemés par le regroupement. Celui—ci s’effectue en
fonction du lien sémantique4 entre les termes. Aprés le regroupement, la méthode consiste a
comparer les termes candidats du document analysé avec les groupes de termes fréquents, en
faisant l’hypothése qu’un terme candidat qui co-occurre plus que selon toute probabilité avec les
termes fréquents d’un ou plusieurs groupes est plus vraisemblablement un terme—c1é.

Dans 1’a1gorithme KeyC1uster, Liu et al. (2009) utilisent aussi un regroupement sémantique, mais
dans leur cas ils considerent les mots du document analyse’ et ils excluent les mots outils. Dans
chaque groupe sémantique, le mot qui est le plus proche du centro'1'de est sélectionné comme mot
de référence. L’ensemble des mots de référence est ensuite utilisé pour ﬁltrer les termes candidats
en ne considérant comme termes-clés que ceux qui contiennent au moins un mot de référence
(tous les mots de référence devant étre utilisés dans au moins un terme—c1é).

2.1.3 Approches a base de graphe

Les approches a base de graphe consistent a représenter le contenu d’un document sous la forme
d’un graphe. La méthodologie appliquée est issue de PageRank (Brin et Page, 1998), un algo-
rithme d’ordonnancement de pages Web (noeuds du graphe) grace aux liens de recommandation
qui existent entre elles (arcs du graphe). TextRank (Mihalcea et Tarau, 2004) et SingleRank (Wan
et Xiao, 2008b) sont les deux adaptations de base de PageRank pour l’extraction automatique
de termes-clés 5. Dans celles-ci, les pages Web sont remplacées par des unités textuelles dont
la granularité est le mot et un arc est créé entre deux noeuds si les mots qu’i1s représentent
co-occurrent dans une fenétre de mots donnée.

Le graphe est noté G = (N ,A), ou N est l’ensemb1e des noeuds du graphe et ou A est 1’ensemb1e
de ses arcs entrants et sortant :Ae,,m,,,, UAso,,a,,t 6. Pour chaque noeud du graphe, un score est
calculé par un processus itératif destiné a simuler la notion de recommandation d’une unité
textuelle par d’autres 7 (cf. équation 5). Ce score a chaque noeud n,- permet d’ordonner les mots
par degré d’importance dans le document analysé. La liste ordonnée des mots peut ensuite étre

4. Deux phrasémes qui co-occurrent fréquemment ensemble sont jugés sémantiquement liés.

5. TextRank a aussi été utilisé pour faire du résumé automatique.

6. Dans le cas de TextRank et de SingleRankAe,ma,” =As,,,m,lt, car le graphe n’est pas orienté.

7. Plus le score d’une unité textuelle est élevé, plus celle-ci est importante dans le document analysé.

101 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

utilisée pour extraire les termes—clés.

P3. )( 
S(n,-)=(1—l)+lx Z “J1 (5)
"jEAenuam("i) Z Pjxk
"kEAsommt("j)

A est un facteur d’atténuation qui peut étre considéré ici comme la probabilité pour que le noeud
n,- soit atteint par recommandation. pj,,- représente le poids de l’arc allant du noeud nj vers le
noeud n,-, soit le nombre de co—occurrences entre les deux mots i et js.

Dans leurs travaux, Wan et Xiao (2008b) s’intéressent a l’ajout d’informations dans le graphe
grace a des documents similaires (voisins) et aux relations de co—occurrences qu’ils possédent
(ExpandRank). L’objectif est de faire mieux ressortir les mots importants du graphe en ajoutant
de nouveaux liens de recommandation ou bien en renforcant ceux qui existent déja. L’usage de
documents similaires peut cependant ajouter ou renforcer des liens qui ne devraient pas l’étre.
Pour éviter cela, les auteurs réduisent l’impact des documents voisins en utilisant leur degré
de similarité avec le document analysé. Une alternative a ExpandRank, CollabRank, également
proposée par Wan et Xiao (2008a), fonctionne de la méme maniére, mais certains choix des
auteurs rendent impossible l’usage du degré de similarité pour réduire l’impact des documents
voisins. Les résultats moins concluants de CollabRank tendent a conﬁrmer l’importance de l’usage
du degré de similarité.

Dans l’optique d’améliorer encore TextRank/ SingleRank, Liu et al. (2010) proposent une méthode
qui cherche cette fois—ci a augmenter la couverture de l’ensemble des termes—clés extraits dans le
document analysé ('I‘opicalPageRank). Pour ce faire, ils tentent d’afﬁner le rang d’importance des
mots dans le document en tenant compte de leur rang dans chaque sujet abordé. Le rang d’un
mot pour un sujet est obtenu en intégrant a son score PageRank la probabilité qu’il appartienne
au sujet (cf. équation 6). Le rang global d’un terme candidat est ensuite obtenu en fusionnant ses
rangs pour chaque sujet.

. . p  >< S(N-)
Ssujet(Ni) = <1 — A) x P(S11Jet|l) + A x Z] L (6)
Nj€AenIIam(Ni) 2 PH‘
NkEAsommt(Nj)

Les approches a bases de graphe présentées ci—dessus effectuent toutes un ordonnancement des
mots du document analysé selon leur importance dans celui—ci. Pour extraire les termes—clés il est
donc nécessaire d’effectuer du travail supplémentaire a partir de la liste ordonnée de mots. Dans
la méthode TextRank, les k mots les plus importants sont sélectionnés et retournés (aprés que
ceux apparaissant en collocation dans le document aient été concaténés). La technique utilisée
dans les autres méthodes consiste a ordonner les termes candidats en fonction de la somme du
score des mots qui les composent. Cependant, puisque l’un des avantages du graphe est que les
noeuds peuvent avoir une granularité controlée, Liang et al. (2009) décident d’utiliser des mots
et des multi—mots au lieu de simples mots et de tirer proﬁt de traits supplémentaires, la taille du
terme ou encore sa premiere position dans le document analysé.

8. TextRank utilise un graphe non-pondéré. Dans ce cas, p Li vaut toujours 1.

102 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

2.2 Méthodes supervisées

Les méthodes supervisées sont des méthodes capables d’apprendre a réaliser une tache parti-
culiere, soit ici l’extraction de termes-clés. L’apprentissage se fait grace a un corpus dont les
documents sont annotés en terrnes—clés. L’annotation permet d’extraire les exemples et les contres-
exemples dont les traits statistiques et/ou linguistiques servent a apprendre une classiﬁcation
binaire. La classiﬁcation binaire consiste a indiquer si un terme candidat est un terme-clé ou non.

De nombreux algorithmes d’apprentissage sont utilisés dans divers domaines. Ils peuvent po-
tentiellement s’adapter a n’importe quelle tache, dont celle de l’extraction automatique de
termes-clés. Les algorithmes utilisés pour celle—ci construisent des modeles probabilistes, des

arbres de décision, des Séparateurs a Large Marge (SVM) ou encore des réseaux de neurones 9.

KEA (Witten et al., 1999) est une méthode qui utilise une classiﬁcation naive bayésienne pour
attribuer un score de vraisemblance a chaque terme candidat, le but étant d’indiquer s’ils sont des
termes—c1és ou non 1°. Witten et al. (1999) utilisent trois distributions conditionnelles apprises a
partir du corpus d’apprentissage. La premiere correspond a la probabilité pour que chaque terme
candidat soit étiqueté oui (terme-clé) ou non (non terrne—clé). Les deux autres correspondent a
deux différents traits qui sont le poids TF—IDF du terme candidat et sa premiere position dans le
document :

P -(terme)
P(terme) = °  (7)
Poui(terme) + Pmm(terme)

P0ui(terme) = P(terme|oui) x n Ptrait (trait(terme)|oui)
traitE{'I'F-IDF,position}

Pm,n(terme) = P(terme|non) x n Ptrait (trait(terme)|non)
traitE{'I'F-IDF,position}

L’un des avantages de la classiﬁcation naive bayésienne est que chaque distribution est supposée
indépendante. L’ajout de nouveaux traits dans la méthode KEA est donc tres aisé.

Parmi les variantes de KEA proposées, Frank et al. (1999) ajoutent un troisieme trait : le nombre
de fois que le terme candidat est un terme-clé dans le corpus d’apprentissage. L’ajout de ce trait
permet d’améliorer les performances de la version originale de KEA, mais uniquement lorsque
la quantité de données d’apprentissage est tres importante. Une autre amélioration de KEA,
proposée par Turney (2003), tente d’augmenter la cohérence entre les termes candidats les
mieux classés. Pour ce faire, une premiere étape de classiﬁcation est effectuée avec la méthode
originale. Cette premiere étape permet d’obtenir un premier classement des termes candidats
selon leur score de vraisemblance. Ensuite, de nouveaux traits sont ajoutés et une nouvelle
étape de classiﬁcation est lancée. Les nouveaux traits ont pour but d’augmenter le score de
vraisemblance des termes candidats ayant un fort lien sémantique avec certains des termes
les mieux classés apres la premiere étape. Enﬁn, Nguyen et Kan (2007) proposent l’ajout des

9. Sarkar et al. (2012) proposent une étude comparative de l’usage des arbres de décision, de la classiﬁcation naive
bayésienne et des réseaux de neurones pour l’extraction automatique de termes-clés.
10. Il est important de noter que le score de vraisemblance pour chaque terme candidat permet aussi de les ordonner
entre eux.

103 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

informations concernant la structure des documents. En effet, certaines sections telles que
l’introduction et la conclusion dans les articles scientiﬁques sont plus susceptibles de contenir
des termes—clés qu’une section présentant des résultats expérimentaux, par exemple. Dans leur
version modiﬁée de KEA, ils proposent aussi l’usage de traits linguistiques tels que les parties du
discours qui ont prouvées jouer un role non—négligeable pour l’extraction de terrnes-clés (Hulth,
2003).

En méme temps que KEA (Witten et al., 1999), 'I11rney (1999) met au point l’algorithme génétique
GenEx. GenEx est constitué de deux composants. Le premier composant, le géniteur, sert a
apprendre des parametres lors de la phase d’apprentissage. Ces parametres sont utilisés par le
second composant, l’extracteur, pour donner un score d’importance a chaque terme candidat.
Plus les parametres sont optimaux, meilleure est la classiﬁcation des termes. Pour ce faire, les
paramétres sont représentés sous la forme de bits qui constituent une population d’individus que
le géniteur fait évoluer jusqu’a obtenir un état stable correspondant aux paramétres optimaux.

Dans son article présentant GenEx, 'I11rney (1999) discute une autre méthode pour l’extraction de
termes-clés. Cette méthode utilise de nombreux traits qui servent a entrainer 50 arbres de décision
C4.5 (technique de Random Forest). Dans un arbre de décision, chaque branche représente un test
sur l’un des traits d’un terme candidat. Les tests permettent un routage du terme candidat vers la
feuille de l’arbre qui détermine sa classe. Grace a la technique de Random Forest, soit l’usage de
plusieurs arbres entrainés sur un échantillon différent du corpus d’apprentissage, l’extraction
automatique de terrnes-clés est réduite a un vote de chaque arbre pour chaque terme candidat.
Cela permet un classement des termes candidats en fonction de leur nombre de votes positifs.
Les termes—clés extraits correspondent aux termes candidats les mieux classés.

La méme année que les travaux de Hulth (2003) sur le bien fondé d’ut1'liser des traits linguistiques
pour l’extraction automatique de termes—clés, Sujian et al. (2003) proposent une méthode utilisant
un modele d’entropie maximale (cf. équation 8) dont l’un des traits repose sur les parties du
discours des mots qui composent les termes candidats. Un modele de maximum d’entropie
consiste a trouver parmi plusieurs distributions, une pour chaque trait, laquelle a la plus forte
entropie. La distribution ayant la plus forte entropie est par déﬁnition celle qui contient le moins
d’informau'ons, ce qui la rend de ce fait moins arbitraire pour l’extraction des termes—clés.
P(oui|terme)

S = T 8
coreuerme) P(non|terme) ( )

exp Zauait x trait(terme, classe)
trait

2 exp Zauait x trait(terme,c)

cE{oui,non} trait

P(classe|terme) =

Le paramétre amt déﬁnit l’importance du trait auquel il est associé.

Les Séparateurs a Large Marge sont aussi des classiﬁeurs utilisés par les méthodes d’extraction
automatique de termes-clés. Ils exploitent divers traits aﬁn de projeter des exemples et des
contres—exemples sur un plan, puis ils cherchent l’hyperplan qui les sépare. Cet hyperplan sert
ensuite dans l’analyse de nouvelles données. Dans le contexte de l’extraction de termes—clés,
les exemples sont les termes—clés et les contres—exemples sont les termes candidats qui ne sont

104 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

pas des termes—clés. Ce mode de fonctionnement des SVM est utilisé par Zhang et al. (2006),
mais un autre type de SVM est plus largement utilisé dans les méthodes supervisées d’extraction
de termes—clés. I1 s’agit de SVM qui utilisent de multiples marges représentant des rangs. Ces
classiﬁeurs permettent donc d’ordonnancer les termes—clés lors de leur extraction (Herbrich et al.,
1999; Joachims, 2006; Jiang et al., 2009). La méthode KeyWE de Eichler et Neumann (2010)
utilise ce type de SVM avec le trait TF-IDF ainsi qu’un trait booléen ayant la valeur vraie si le terme
candidat apparait dans un titre d’un article Wikipedia (un terme candidat apparaissant dans le
titre d’un article de Wikipedia a une plus forte probabilité d’étre un terme-clé). L’ordonnancement
des termes candidats par le SVM permet ensuite de controler le nombre de termes—clés a extraire
(choix des k termes candidats les mieux classés).

Tout comme Turney (1999), Ercan et Cicekli (2007) utilisent eux aussi une forét d’arbres C4.5
dans leur méthode d’extraction de termes—clés. Ils utilisent des traits classiques et leur contribution
se situe au niveau de l’utilisation d’un trait calculé a partir de chaines lexicales. Une chaine
lexicale lie les mots d’un document selon certaines relations telles que la synonymie, l’hyponymie
ou la méronymie. Ces relations permettent de calculer un score qui sert de trait. Cette approche
est intéressante, mais du fait de limitations des chaines lexicales actuellement disponibles elle
présente l’inconvénient de ne retourner que des mots (aucun multi—mot). Cependant, l’usage
d’une forét d’arbre C4.5 permet un classement des mots a partir de leur nombre de votes positifs.
Il est donc envisageable de déduire les termes—clés a partir de la liste ordonnée et pondérée des
mots clés (voir les méthodes non—supervisées a bases de graphe — section 2.1).

Une autre méthode pour l’extraction automatique de termes—clés consiste a utiliser un perceptron
multi—couches (Sarkar et al., 2010). Un perceptron multi—couches est un réseau de neurones
constitué d’au moins trois couches, chaque couche étant composée de neurones. Dans les deux
couches extremes les neurones représentent respectivement les entrées et les sorties. Les couches
centrales sont des couches cachées qui permettent d’acheminer les Valeurs des entrées Vers les
sorties, ou de nouvelles Valeurs sont obtenues grace a la pondération des transitions d’un neurone
d’une couche Vers un neurone de la couche suivante. Les entrées correspondent aux traits d’un
terme candidat (ici TF—IDE la position, la taille, etc.) et les sorties représentent les classes qu’il
peut prendre (terme—clé ou non terme—clé). La valeur obtenue pour chaque sortie (classe) permet
d’obtenir une probabilité pour que le terme candidat analysé soit un terme—clé ou non. Dans leur
méthode, Sarkar et al. (2010) utilisent cette probabilité pour ordonner les termes candidats aﬁn
de mieux contréler le nombre de termes—clés a extraire.

Dans leurs travaux, Liu et al. (2011) proposent une méthode d’extraction de termes—clés basée sur
un modéle génératif. Leur méthode est trés différente de celle de Witten et al. (1999) puisqu’ils
décident d’utiliser une approche de traduction automatique. L’usage original de cette approche est
justiﬁé par le fait qu’un ensemble de termes—clés doit décrire de maniére synthétique le document.
Leur hypothése est donc qu’un ensemble de termes—clés est une traduction d’un document dans
un autre langage. Le modéle est appris a partir de paires de traductions dont l’un des termes est
issu des titres ou des résumés des documents du corpus d’apprentissage et dont l’autre terme est
issu des corps de ces memes documents. Les titres et les résumés sont utilisés comme langage
synthétique et les corps des documents comme le langage naturel de ceux—ci.

105 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
3 Conclusion et perspectives

L’extraction automatique de termes—clés est une tache importante qui permet la valorisaﬁon d’un
document (représentation synthétique, mise en évidence des points clés dans le document, etc.)
et qui facilite l’acces aux documents pertinents pour une requéte utilisateur (indexation pour la
recherche d’information).

Les méthodes existantes pour la tache d’extraction automatique de termes—clés sont soit supervi-
sées, soit non—supervisées. Les méthodes non—supervisées sont des méthodes émergentes ayant
la particularité de s’abstraire de la spéciﬁcité des données traitées. Cette abstraction s’explique
par des approches basées sur des constatations a propos de ce qu’est un terme—clé au sens
général : importance sémantique, degré d’information, structure syntaxique, etc. Contrairement
aux méthodes non—supervisées, les méthodes supervisées n’utilisent pas de propriétés déﬁnies a
partir des traits statistiques et linguistiques, mais elles utilisent des modeles de décision appris a
partir de ces traits, calculés sur les termes—clés d’un corpus d’apprentissage. L’usage d’un corpus
d’apprentissage implique que les modeles appris soient spéciﬁques au domaine disciplinaire et a
la langue de celui—ci. Cette spéciﬁcité peut s’avérer avantageuse lorsque le domaine et la langue
que représente le corpus sont les mémes pour les documents qui sont ensuite analysés, mais si
tel n’est pas le cas les résultats de l’extracu'on peuvent en patir.

De futurs travaux peuvent se focaliser sur une hybridation des méthodes non—supervisées et
supervisées. Dans un premier temps, il peut étre intéressant de tenter d’améliorer les méthodes a
base de graphe existantes. En effet, le graphe possede plusieurs points de variabilité sur lesquels
il est possible d’agir pour afﬁner l’extraction : la granularité des noeuds, le type de relations
permettant la création des arcs ou encore le facteur d’atténuau'on A utilisé dans le calcul du score
des noeuds. La granularité peut étre étendue a des groupes de phrasemes similaires (des variantes
dont le sens est sensiblement le méme). Cette nouvelle granularité peut impliquer la déﬁnition
d’une nouvelle relation pour la création des arcs entre les noeuds. Enﬁn, des traits peuvent étre
appris, pondérés grace a de l’apprentissage préalable, puis utilisés avec le facteur (1 — A) dans le
calcul du score pour chaque noeud (voir la modiﬁcation du score dans TopicalPageRank (Liu et al.,
2010)). Il est possible que ce dernjer point demande de modiﬁer la formule du score PageRank
aﬁn d’utiliser le score de recommandation et de nouveaux traits de maniere cohérente (sans que
la valeur d’un trait ne puisse annihiler le score de recommandation).

Remerciements

Ce travail a bénéﬁcié d’une aide de l’Agence Nationale de la Recherche portant la référence
(ANR- 12-CORD-0029).

Références

BARKER, K. et CORNACCHIA, N. (2000). Using Noun Phrase Heads to Extract Document Keyphrases.
In Proceedings of the 13th Biennial Conference of the Canadian Society on Computational Studies
of Intelligence : Advances in Artificial Intelligence.

106 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

BOUDIN, E et MORIN, E. (2013). Keyphrase Extraction for N-best Reranking in Multi-Sentence
Compression. In Proceedings of the North American Chapter of the Association for Computational
Linguistics (NAACL).

BRIN, S. et PAGE, L. (1998). The Anatomy of a Large—Sca1e hypertextual Web Search Engine. In
Proceedings of the 7th International Conference on World Wide Web.

CLAVEAU, V (2012). Vectorisation, Okapi et Calcul de Similarité pour le TAL : pour Oublier Enﬁn
le TF—IDF. In Proceedings of the Joint Conference JEP—TAIN—RECITAL 2012, volume 2 : TALN.
DING, Z., ZHANG, Q. et HUANG, X. (2011). Keyphrase Extraction from Online News Using Binary
Integer Programming. In Proceedings of 5th International Joint Conference on Natural Language
Processing.

EICHLER, K. et NEUMANN, G. (2010). DFKI KeyWE : Ranking Keyphrases Extracted from Scientiﬁc
Articles. In Proceedings of the 5th International Workshop on Semantic Evaluation.

ERCAN, G. et CICEKLI, I. (2007). Using Lexical Chains for Keyword Extraction.

FRANK, E., PAYNTER, G., WITTEN, I., GUTWIN, C. et NEVILL-MANNING, C. (1999). Domain—Speciﬁc
Keyphrase Extraction.

HASAN, K. et No, V (2010). Conundrums in Unsupervised Keyphrase Extraction : Making Sense
of the State-of—the—Art. In Proceedings of the 23rd International Conference on Computational
Linguistics : Posters.

HERBRICH, R., GRAEPEL, T. et OBERMAYER, K. (1999). Support Vector Learning for Ordinal
Regression. In Artificial Neural Networks, 1999.

HULTH, A. (2003). Improved Automatic Keyword Extraction Given More Linguistic Knowledge.
In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing.

JIANG, X., HU, Y. et LI, H. (2009). A Ranking Approach to Keyphrase Extraction. In Proceedings
of the 32nd international ACM SIGIR conference on Research and development in information
retrieval.

JOACHIMS, T. (2006). Training Linear SVMs in Linear Time. In Proceedings of the 12th ACM
SIGKDD international conference on Knowledge discovery and data mining.

JONES, K. (1972). A Statistical Interpretation of Term Speciﬁcity and its Application in Retrieval.

JONES, S. et STAVELEY, M. (1999). Phrasier : a System for Interactive Document Retrieval Using
Keyphrases. In Proceedings of the 22nd annual international ACM SIGIR conference on Research
and development in information retrieval.

KIM, S. N., MEDELYAN, 0., KAN, M. et BALDWIN, T. (2010). Semeval-2010 Task 5 : Automatic
Keyphrase Extraction from Scientiﬁc Articles. In Proceedings of the 5th International Workshop
on Semantic Evaluation.

LIANG, W., HUANG, C., L1, M. et LU, B. (2009). Extracting Keyphrases from Chinese News Articles
Using Textrank and Query Log Knowledge. In Proceedings of the 23rd Paciﬁc Asia Conference on
Language, Information and Computation.

LITVAK, M. et LAST, M. (2008). Graph—Based Keyword Extraction for Single—Document Summari-
zation. In Proceedings of the workshop on Multi—source Multilingual Information Extraction and
Summarization.

LIU, Z., CHEN, X., ZHENG, Y. et SUN, M. (2011). Automatic Keyphrase Extraction by Bridging
Vocabulary Gap. In Proceedings of the 15th Conference on Computational Natural Language
Learning.

107 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

LIU, Z., HUANG, W., ZHENG, Y. et SUN, M. (2010). Automatic Keyphrase Extraction via Topic
Decomposition. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language
Processing.

LIU, 2., LI, R, ZHENG, Y. et SUN, M. (2009). Clustering to Find Exemplar Terms for Keyphrase
Extraction. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language
Processing: Volume 1.

MATSUO, Y. et IsHIzUKA, M. (2004). Keyword Extraction from a Single Document Using Word
Co-occurrence Statistical Information.

MEDELYAN, O. et WITTEN, I. (2008). Domain—Independent Automatic Keyphrase Indexing with
Small Training Sets.

MIHALCEA, R. et TARAU, P. (2004). Textrank : Bringing Order Into Texts. In Proceedings of the
2004 Conference on Empirical Methods in Natural Language Processing.

NGUYEN, 'I‘. et KAN, M. (2007). Keyphrase Extraction in Scientiﬁc Publications. In Proceedings of
the 10th international conference on Asian digital libraries : looking back 1 0 years and forging
new frontiers.

NOBATA, C., COTTER, R, OKAZAKI, N., REA, B., SASAKI, Y., TSURUOKA, Y., TsUJ11, J. et ANANIADOU, S.
(2008). Kleio : a Knowledge-enriched Information Retrieval System for Biology. In Proceedings of
the 31st annual international ACM SIGIR conference on Research and development in information
retrieval.

PAROUBEK, R, ZWEIGENBAUM, R, FOREST, D. et GROUIN, C. (2012). Indexation Libre et Contrélée
d’Articles Scientiﬁques Présentation et Résultats du Déﬁ Fouille de Textes DEFT2012.

PAUKKERI, M. et HONKELA, ‘T. (2010). Likey : Unsupervised Language—Independent Keyphrase
Extraction. In Proceedings of the 5th International Workshop on Semantic Evaluation.

ROBERTSON, S. E., WALKER, S., BEAULIEU, M. et WILLETT, R (1999). Okapi at TREC—7 : Automatic
Ad Hoc, Filtering, VLC and Interactive Track.

SARKAR, K., NASIPURI, M. et GHOsE, S. (2010). A New Approach to Keyphrase Extraction Using
Neural Networks.

SARKAR, K., NASIPURI, M. et GHosE, S. (2012). Machine Learning Based Keyphrase Extraction :
Comparing Decision Trees, Naive Bayes, and Artiﬁcial Neural Networks.

SUJIAN, L., HOUFENG, W., SHIWEN, Y. et CHENGSHENG, X. (2003). News—Oriented Keyword
Indexing with Maximum Entropy Principle.

ToMoKIYo, T. et HURST, M. (2003). A Language Model Approach to Keyphrase Extraction.
In Proceedings of the ACL 2003 workshop on Multiword expressions : analysis, acquisition and
treatment—Volume 18.

TURNEY, R (1999). Learning Algorithms for Keyphrase Extraction.
TURNEY, R (2003). Coherent Keyphrase Extraction via Web Mining.

WAN, X. et XIAO, J. (2008a). Collabrank : Towards a Collaborative Approach to Single—Document
Keyphrase Extraction. In Proceedings of the 22nd International Conference on Computational
Linguistics—Volume 1.

WAN, X. et XIAo, J. (2008b). Single Document Keyphrase Extraction Using Neighborhood
Knowledge. In Proceedings of Association for the Advancement of Artiﬁcial Intelligence.

108 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

WAN, X., YANG, J. et X1Ao, J. (2007). Towards an Iterative Reinforcement Approach for
Simultaneous Document Summarization and Keyword Extraction. In Annual Meeting—association
For Computational Linguistics.

WITTEN, I., PAYNTER, G., FRANK, E., GUTWIN, C. et NEVILL-MANNING, C. (1999). KEA : Practical
Automatic Keyphrase Extraction. In Proceedings of the 4th ACM conference on Digital libraries.

ZHANG, K., XU, H., TANG, J. et L1, J. (2006). Keyword Extraction Using Support Vector Machine.

109 © ATALA

