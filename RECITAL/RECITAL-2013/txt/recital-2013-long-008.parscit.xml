<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K et CORNACCHIA BARKER</author>
<author>N</author>
</authors>
<title>Using Noun Phrase Heads to Extract Document Keyphrases.</title>
<date>2000</date>
<booktitle>In Proceedings of the 13th Biennial Conference of the Canadian Society on Computational Studies of Intelligence : Advances in Artificial Intelligence.</booktitle>
<marker>BARKER, N, 2000</marker>
<rawString>BARKER, K. et CORNACCHIA, N. (2000). Using Noun Phrase Heads to Extract Document Keyphrases. In Proceedings of the 13th Biennial Conference of the Canadian Society on Computational Studies of Intelligence : Advances in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>c ATALA TALN-RÉCITAL</author>
</authors>
<title>Keyphrase Extraction for N-best Reranking in Multi-Sentence Compression.</title>
<date>2013</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<pages>17--21</pages>
<contexts>
<context position="2573" citStr="TALN-RÉCITAL 2013" startWordPosition="360" endWordPosition="361">extraction de termes-clés ; méthodes supervisées ; méthodes non-supervisées ; état de l’art . KEYWORDS: keyphrase extraction ; supervised methods ; unsupervised methods ; state of the art . 1 Introduction Les termes-clés sont des mots ou des expressions (multi-mots) représentant les aspects principaux qui sont abordés dans un document. De ce fait, ils sont utilisés dans de nombreux domaines du Traitement Automatique des Langues (TAL). Turney (1999) émet l’hypothèse qu’ils peuvent faciliter la lecture d’un utilisateur en lui permettant de surfer d’un point clé à un autre lorsqu’ils 96 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne sont mis en évidence dans un texte. D’autres chercheurs utilisent leurs vertus synthétiques dans des méthodes de construction automatique de résumés (Wan et al., 2007; Litvak et Last, 2008; Boudin et Morin, 2013), mais ils s’avèrent surtout de plus en plus utiles avec l’essor de l’Internet et la disponibilité de nombreux documents numériques qu’il faut pouvoir indexer de manière pertinente pour faciliter leur recherche par des utilisateurs (Medelyan et Witten, 2008). Dans ce contexte de recherche d’information, les termes-clés peuvent aussi être directement bé</context>
<context position="6284" citStr="TALN-RÉCITAL 2013" startWordPosition="901" endWordPosition="902">un document et à en extraire les aspects importants. Alors que les méthodes de résumé automatique utilisent des phrases pour construire une vision synthétique du document, l’extraction de termes-clés se focalise sur les unités textuelles qui composent ces phrases. Un ensemble de termes-clés peut donc être perçu comme un résumé dont les points clés sont exprimés sans liaisons entre eux. Les unités textuelles sur lesquelles travaillent les systèmes d’extraction automatique de termes-clés sont appelées termes candidats. Ces derniers sont des mots ou des multi-mots (phrasèmes) pouvant 97 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne être promus au statut de terme-clé. L’extraction de termes candidats est une étape préliminaire de l’extraction de termes-clés, que ce soit pour les méthodes non-supervisées ou supervisées. Cette étape est importante, car si certains termes-clés du document analysé ne sont pas présents dans l’ensemble des termes candidats, alors ceux-ci ne pourront pas être extrait. Hulth (2003) étudie trois méthodes d’extraction des termes candidats. L’une consiste à extraire les chunks nominaux 1, tandis que les deux autres extraient tous les n-grammes et les filtrent, soit </context>
<context position="10046" citStr="TALN-RÉCITAL 2013" startWordPosition="1476" endWordPosition="1477"> les combinent avec des représentations plus complexes des documents. Ces 1. Un chunk est une unité minimale de sens constituée d’un ou de plusieurs mots. Un chunk nominal est un chunk dont la tête est un nom ou un pronom. Par exemple, dans « Nous avons une bonne politique qualitative. », « Nous » et « une bonne politique qualitative » sont des chunks nominaux. 2. L’abstraction de la langue est vraie pour ce qui est de la méthodologie, cependant les pré-traitements tels que la segmentation en phrases, en mots et l’étiquetage en parties du discours sont eux spécifiques à la langue. 98 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne représentations peuvent aller de groupes de mots sémantiquement similaires à des graphes dont les nœuds sont des unités textuelles (mots, expressions, phrases, etc.) liées par des relations de recommandation 3. 2.1.1 Approches statistiques Plusieurs approches cherchent à définir ce qu’est un terme-clé en s’appuyant sur certains traits statistiques et en étudiant leur rapport avec la notion d’importance d’un terme candidat. Plus un terme candidat est jugé important vis-à-vis du document analysé, plus celui-ci est pertinent en tant que terme-clé. TF-IDF (cf. équ</context>
<context position="12918" citStr="TALN-RÉCITAL 2013" startWordPosition="1944" endWordPosition="1945">appliquée pour l’extraction de termes-clés. Dans l’article de Claveau (2012), Okapi est décrit comme un TF-IDF prenant mieux en compte la longueur des documents. Cette dernière est utilisée pour normaliserle T F (qui devient T FBM25) : N − DF( terme) + 0,5 Okapi(terme) = T FBM25(terme)× log (3)DF(terme) + 0,5 T F(term T FBM25 = e)× (k1 + 1)  (4) T F(terme) + k1 × 1− b+ b× DLDLmoyenne 3. Pour une étude comparative de certaines des méthodes par regroupement (Liu et al., 2009) et à base de graphe (Mihalcea et Tarau, 2004; Wan et Xiao, 2008b), voir l’article de Hasan et Ng (2010). 99 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Dans la formule (4), k1 et b sont des constantes fixées à 2 et 0, 75 respectivement. DL représente la longueur du document analysé et DLmoyenne la longueur moyenne des documents de la collection utilisée. Barker et Cornacchia (2000) estiment que les grands phrasèmes sont plus informatifs et qu’ils doivent être privilégiés. Pour cela, leur approche est très simple : plus un groupe nominal est long et fréquent dans le document analysé, plus il est jugé pertinent en tant que terme-clé de ce document. Cependant, pour éviter la répétition dans le texte, les auteurs</context>
<context position="16577" citStr="TALN-RÉCITAL 2013" startWordPosition="2498" endWordPosition="2499">t que termes-clés. Une donnée statistique non citée précédemment, mais pourtant récurrente dans les méthodes d’extraction de termes-clés, est la fréquence de co-occurrences entre deux phrasèmes (termes). Deux phrasèmes co-occurrent s’ils apparaissent ensemble dans le même contexte. La co-occurrence peut être calculée de manière stricte (les phrasèmes doivent être côte-à-côte) ou bien dans une fenêtre de mots. Compter le nombre de co-occurrences entre deux termes permet d’estimer s’ils sont sémantiquement liés ou non. Ce lien sémantique à lui seul ne peut pas servir à extraire des 100 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne termes-clés, mais il permet de mieux organiser les termes d’un document pour affiner l’extraction (Matsuo et Ishizuka, 2004; Liu et al., 2009; Mihalcea et Tarau, 2004). 2.1.2 Approches par regroupement L’objectif des approches par regroupement est de définir des groupes dont les unités textuelles partagent une ou plusieurs caractéristiques communes. Ainsi, lorsque des termes-clés sont extraits à partir de chaque groupe, cela permet de mieux couvrir le document analysé selon les caractéristiques utilisées. Dans la méthode de Matsuo et Ishizuka (2004), ce sont l</context>
<context position="19838" citStr="TALN-RÉCITAL 2013" startWordPosition="3020" endWordPosition="3021"> notion de recommandation d’une unité textuelle par d’autres 7 (cf. équation 5). Ce score à chaque nœud ni permet d’ordonner les mots par degré d’importance dans le document analysé. La liste ordonnée des mots peut ensuite être 4. Deux phrasèmes qui co-occurrent fréquemment ensemble sont jugés sémantiquement liés. 5. TextRank a aussi été utilisé pour faire du résumé automatique. 6. Dans le cas de TextRank et de SingleRank Aentrant = Asor tant , car le graphe n’est pas orienté. 7. Plus le score d’une unité textuelle est élevé, plus celle-ci est importante dans le document analysé. 101 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne utilisée pour extraire les termes-clés. p S(ni) = ( j, 1−λ) +λ×  i × S(nj) (5) n pj∈Aentrant(ni) j,k nk∈Asortant(nj) λ est un facteur d’atténuation qui peut être considéré ici comme la probabilité pour que le nœud ni soit atteint par recommandation. pj,i représente le poids de l’arc allant du nœud nj vers le nœud ni , soit le nombre de co-occurrences entre les deux mots i et j 8. Dans leurs travaux, Wan et Xiao (2008b) s’intéressent à l’ajout d’informations dans le graphe grâce à des documents similaires (voisins) et aux relations de co-occurrences qu’ils po</context>
<context position="22954" citStr="TALN-RÉCITAL 2013" startWordPosition="3509" endWordPosition="3510">dans le document aient été concaténés). La technique utilisée dans les autres méthodes consiste à ordonner les termes candidats en fonction de la somme du score des mots qui les composent. Cependant, puisque l’un des avantages du graphe est que les nœuds peuvent avoir une granularité contrôlée, Liang et al. (2009) décident d’utiliser des mots et des multi-mots au lieu de simples mots et de tirer profit de traits supplémentaires, la taille du terme ou encore sa première position dans le document analysé. 8. TextRank utilise un graphe non-pondéré. Dans ce cas, pj,i vaut toujours 1. 102 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 2.2 Méthodes supervisées Les méthodes supervisées sont des méthodes capables d’apprendre à réaliser une tâche particulière, soit ici l’extraction de termes-clés. L’apprentissage se fait grâce à un corpus dont les documents sont annotés en termes-clés. L’annotation permet d’extraire les exemples et les contresexemples dont les traits statistiques et/ou linguistiques servent à apprendre une classification binaire. La classification binaire consiste à indiquer si un terme candidat est un terme-clé ou non. De nombreux algorithmes d’apprentissage sont utilisés dans</context>
<context position="26243" citStr="TALN-RÉCITAL 2013" startWordPosition="3993" endWordPosition="3994">ation est lancée. Les nouveaux traits ont pour but d’augmenter le score de vraisemblance des termes candidats ayant un fort lien sémantique avec certains des termes les mieux classés après la première étape. Enfin, Nguyen et Kan (2007) proposent l’ajout des 9. Sarkar et al. (2012) proposent une étude comparative de l’usage des arbres de décision, de la classification naïve bayésienne et des réseaux de neurones pour l’extraction automatique de termes-clés. 10. Il est important de noter que le score de vraisemblance pour chaque terme candidat permet aussi de les ordonner entre eux. 103 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne informations concernant la structure des documents. En effet, certaines sections telles que l’introduction et la conclusion dans les articles scientifiques sont plus susceptibles de contenir des termes-clés qu’une section présentant des résultats expérimentaux, par exemple. Dans leur version modifiée de KEA, ils proposent aussi l’usage de traits linguistiques tels que les parties du discours qui ont prouvées jouer un rôle non-négligeable pour l’extraction de termes-clés (Hulth, 2003). En même temps que KEA (Witten et al., 1999), Turney (1999) met au point l’al</context>
<context position="29692" citStr="TALN-RÉCITAL 2013" startWordPosition="4506" endWordPosition="4507"> × trait(terme, c) c∈{oui,non} trait Le paramètre αtrait définit l’importance du trait auquel il est associé. Les Séparateurs à Large Marge sont aussi des classifieurs utilisés par les méthodes d’extraction automatique de termes-clés. Ils exploitent divers traits afin de projeter des exemples et des contres-exemples sur un plan, puis ils cherchent l’hyperplan qui les sépare. Cet hyperplan sert ensuite dans l’analyse de nouvelles données. Dans le contexte de l’extraction de termes-clés, les exemples sont les termes-clés et les contres-exemples sont les termes candidats qui ne sont 104 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne pas des termes-clés. Ce mode de fonctionnement des SVM est utilisé par Zhang et al. (2006), mais un autre type de SVM est plus largement utilisé dans les méthodes supervisées d’extraction de termes-clés. Il s’agit de SVM qui utilisent de multiples marges représentant des rangs. Ces classifieurs permettent donc d’ordonnancer les termes-clés lors de leur extraction (Herbrich et al., 1999; Joachims, 2006; Jiang et al., 2009). La méthode KeyWE de Eichler et Neumann (2010) utilise ce type de SVM avec le trait TF-IDF ainsi qu’un trait booléen ayant la valeur vraie s</context>
<context position="33597" citStr="TALN-RÉCITAL 2013" startWordPosition="5110" endWordPosition="5111">original de cette approche est justifié par le fait qu’un ensemble de termes-clés doit décrire de manière synthétique le document. Leur hypothèse est donc qu’un ensemble de termes-clés est une traduction d’un document dans un autre langage. Le modèle est appris à partir de paires de traductions dont l’un des termes est issu des titres ou des résumés des documents du corpus d’apprentissage et dont l’autre terme est issu des corps de ces mêmes documents. Les titres et les résumés sont utilisés comme langage synthétique et les corps des documents comme le langage naturel de ceux-ci. 105 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 3 Conclusion et perspectives L’extraction automatique de termes-clés est une tâche importante qui permet la valorisation d’un document (représentation synthétique, mise en évidence des points clés dans le document, etc.) et qui facilite l’accès aux documents pertinents pour une requête utilisateur (indexation pour la recherche d’information). Les méthodes existantes pour la tâche d’extraction automatique de termes-clés sont soit supervisées, soit non-supervisées. Les méthodes non-supervisées sont des méthodes émergentes ayant la particularité de s’abstraire de</context>
</contexts>
<marker>TALN-RÉCITAL, 2013</marker>
<rawString>106 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne BOUDIN, F. et MORIN, E. (2013). Keyphrase Extraction for N-best Reranking in Multi-Sentence Compression. In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S et PAGE BRIN</author>
<author>L</author>
</authors>
<title>The Anatomy of a Large-Scale hypertextual Web Search Engine.</title>
<date>1998</date>
<booktitle>In Proceedings of the 7th International Conference on World Wide Web.</booktitle>
<marker>BRIN, L, 1998</marker>
<rawString>BRIN, S. et PAGE, L. (1998). The Anatomy of a Large-Scale hypertextual Web Search Engine. In Proceedings of the 7th International Conference on World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V CLAVEAU</author>
</authors>
<title>Vectorisation, Okapi et Calcul de Similarité pour le TAL : pour Oublier Enfin le TF-IDF.</title>
<date>2012</date>
<booktitle>In Proceedings of the Joint Conference JEP-TALN-RECITAL 2012,</booktitle>
<volume>2</volume>
<publisher>TALN.</publisher>
<marker>CLAVEAU, 2012</marker>
<rawString>CLAVEAU, V. (2012). Vectorisation, Okapi et Calcul de Similarité pour le TAL : pour Oublier Enfin le TF-IDF. In Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2 : TALN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z DING</author>
<author>Q et HUANG ZHANG</author>
<author>X</author>
</authors>
<title>Keyphrase Extraction from Online News Using Binary Integer Programming.</title>
<date>2011</date>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing.</booktitle>
<marker>DING, ZHANG, X, 2011</marker>
<rawString>DING, Z., ZHANG, Q. et HUANG, X. (2011). Keyphrase Extraction from Online News Using Binary Integer Programming. In Proceedings of 5th International Joint Conference on Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K et NEUMANN EICHLER</author>
<author>G</author>
</authors>
<title>DFKI KeyWE : Ranking Keyphrases Extracted from Scientific Articles.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation.</booktitle>
<marker>EICHLER, G, 2010</marker>
<rawString>EICHLER, K. et NEUMANN, G. (2010). DFKI KeyWE : Ranking Keyphrases Extracted from Scientific Articles. In Proceedings of the 5th International Workshop on Semantic Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G et CICEKLI ERCAN</author>
<author>I</author>
</authors>
<title>Using Lexical Chains for Keyword Extraction.</title>
<date>2007</date>
<marker>ERCAN, I, 2007</marker>
<rawString>ERCAN, G. et CICEKLI, I. (2007). Using Lexical Chains for Keyword Extraction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E FRANK</author>
<author>G PAYNTER</author>
<author>I WITTEN</author>
<author>C et NEVILL-MANNING GUTWIN</author>
<author>C</author>
</authors>
<title>Domain-Specific Keyphrase Extraction.</title>
<date>1999</date>
<marker>FRANK, PAYNTER, WITTEN, GUTWIN, C, 1999</marker>
<rawString>FRANK, E., PAYNTER, G., WITTEN, I., GUTWIN, C. et NEVILL-MANNING, C. (1999). Domain-Specific Keyphrase Extraction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K et NG HASAN</author>
<author>V</author>
</authors>
<title>Conundrums in Unsupervised Keyphrase Extraction : Making Sense of the State-of-the-Art.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics :</booktitle>
<publisher>Posters.</publisher>
<marker>HASAN, V, 2010</marker>
<rawString>HASAN, K. et NG, V. (2010). Conundrums in Unsupervised Keyphrase Extraction : Making Sense of the State-of-the-Art. In Proceedings of the 23rd International Conference on Computational Linguistics : Posters.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R HERBRICH</author>
<author>T et OBERMAYER GRAEPEL</author>
<author>K</author>
</authors>
<title>Support Vector Learning for Ordinal Regression.</title>
<date>1999</date>
<booktitle>In Artificial Neural Networks,</booktitle>
<marker>HERBRICH, GRAEPEL, K, 1999</marker>
<rawString>HERBRICH, R., GRAEPEL, T. et OBERMAYER, K. (1999). Support Vector Learning for Ordinal Regression. In Artificial Neural Networks, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A HULTH</author>
</authors>
<title>Improved Automatic Keyword Extraction Given More Linguistic Knowledge.</title>
<date>2003</date>
<marker>HULTH, 2003</marker>
<rawString>HULTH, A. (2003). Improved Automatic Keyword Extraction Given More Linguistic Knowledge.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<marker></marker>
<rawString>In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X JIANG</author>
<author>Y et LI HU</author>
<author>H</author>
</authors>
<title>A Ranking Approach to Keyphrase Extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval.</booktitle>
<marker>JIANG, HU, H, 2009</marker>
<rawString>JIANG, X., HU, Y. et LI, H. (2009). A Ranking Approach to Keyphrase Extraction. In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T JOACHIMS</author>
</authors>
<title>Training Linear SVMs in Linear Time.</title>
<date>2006</date>
<booktitle>In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining.</booktitle>
<marker>JOACHIMS, 2006</marker>
<rawString>JOACHIMS, T. (2006). Training Linear SVMs in Linear Time. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K JONES</author>
</authors>
<title>A Statistical Interpretation of Term Specificity and its Application in Retrieval.</title>
<date>1972</date>
<marker>JONES, 1972</marker>
<rawString>JONES, K. (1972). A Statistical Interpretation of Term Specificity and its Application in Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S et STAVELEY JONES</author>
<author>M</author>
</authors>
<title>Phrasier : a System for Interactive Document Retrieval Using Keyphrases.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval.</booktitle>
<marker>JONES, M, 1999</marker>
<rawString>JONES, S. et STAVELEY, M. (1999). Phrasier : a System for Interactive Document Retrieval Using Keyphrases. In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S N KIM</author>
<author>O MEDELYAN</author>
<author>M et BALDWIN KAN</author>
<author>T</author>
</authors>
<date>2010</date>
<booktitle>Semeval-2010 Task 5 : Automatic Keyphrase Extraction from Scientific Articles. In Proceedings of the 5th International Workshop on Semantic Evaluation.</booktitle>
<marker>KIM, MEDELYAN, KAN, T, 2010</marker>
<rawString>KIM, S. N., MEDELYAN, O., KAN, M. et BALDWIN, T. (2010). Semeval-2010 Task 5 : Automatic Keyphrase Extraction from Scientific Articles. In Proceedings of the 5th International Workshop on Semantic Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W LIANG</author>
<author>C HUANG</author>
<author>M et LU LI</author>
<author>B</author>
</authors>
<title>Extracting Keyphrases from Chinese News Articles Using Textrank and Query Log Knowledge.</title>
<date>2009</date>
<booktitle>In Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation.</booktitle>
<marker>LIANG, HUANG, LI, B, 2009</marker>
<rawString>LIANG, W., HUANG, C., LI, M. et LU, B. (2009). Extracting Keyphrases from Chinese News Articles Using Textrank and Query Log Knowledge. In Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M et LAST LITVAK</author>
<author>M</author>
</authors>
<title>Graph-Based Keyword Extraction for Single-Document Summarization.</title>
<date>2008</date>
<booktitle>In Proceedings of the workshop on Multi-source Multilingual Information Extraction and Summarization.</booktitle>
<marker>LITVAK, M, 2008</marker>
<rawString>LITVAK, M. et LAST, M. (2008). Graph-Based Keyword Extraction for Single-Document Summarization. In Proceedings of the workshop on Multi-source Multilingual Information Extraction and Summarization.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z LIU</author>
<author>X CHEN</author>
<author>Y et SUN ZHENG</author>
<author>M</author>
</authors>
<title>Automatic Keyphrase Extraction by Bridging Vocabulary Gap.</title>
<date>2011</date>
<booktitle>In Proceedings of the 15th Conference on Computational Natural Language Learning.</booktitle>
<marker>LIU, CHEN, ZHENG, M, 2011</marker>
<rawString>LIU, Z., CHEN, X., ZHENG, Y. et SUN, M. (2011). Automatic Keyphrase Extraction by Bridging Vocabulary Gap. In Proceedings of the 15th Conference on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>c ATALA TALN-RÉCITAL</author>
</authors>
<title>Automatic Keyphrase Extraction via Topic Decomposition.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<pages>17--21</pages>
<contexts>
<context position="2573" citStr="TALN-RÉCITAL 2013" startWordPosition="360" endWordPosition="361">extraction de termes-clés ; méthodes supervisées ; méthodes non-supervisées ; état de l’art . KEYWORDS: keyphrase extraction ; supervised methods ; unsupervised methods ; state of the art . 1 Introduction Les termes-clés sont des mots ou des expressions (multi-mots) représentant les aspects principaux qui sont abordés dans un document. De ce fait, ils sont utilisés dans de nombreux domaines du Traitement Automatique des Langues (TAL). Turney (1999) émet l’hypothèse qu’ils peuvent faciliter la lecture d’un utilisateur en lui permettant de surfer d’un point clé à un autre lorsqu’ils 96 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne sont mis en évidence dans un texte. D’autres chercheurs utilisent leurs vertus synthétiques dans des méthodes de construction automatique de résumés (Wan et al., 2007; Litvak et Last, 2008; Boudin et Morin, 2013), mais ils s’avèrent surtout de plus en plus utiles avec l’essor de l’Internet et la disponibilité de nombreux documents numériques qu’il faut pouvoir indexer de manière pertinente pour faciliter leur recherche par des utilisateurs (Medelyan et Witten, 2008). Dans ce contexte de recherche d’information, les termes-clés peuvent aussi être directement bé</context>
<context position="6284" citStr="TALN-RÉCITAL 2013" startWordPosition="901" endWordPosition="902">un document et à en extraire les aspects importants. Alors que les méthodes de résumé automatique utilisent des phrases pour construire une vision synthétique du document, l’extraction de termes-clés se focalise sur les unités textuelles qui composent ces phrases. Un ensemble de termes-clés peut donc être perçu comme un résumé dont les points clés sont exprimés sans liaisons entre eux. Les unités textuelles sur lesquelles travaillent les systèmes d’extraction automatique de termes-clés sont appelées termes candidats. Ces derniers sont des mots ou des multi-mots (phrasèmes) pouvant 97 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne être promus au statut de terme-clé. L’extraction de termes candidats est une étape préliminaire de l’extraction de termes-clés, que ce soit pour les méthodes non-supervisées ou supervisées. Cette étape est importante, car si certains termes-clés du document analysé ne sont pas présents dans l’ensemble des termes candidats, alors ceux-ci ne pourront pas être extrait. Hulth (2003) étudie trois méthodes d’extraction des termes candidats. L’une consiste à extraire les chunks nominaux 1, tandis que les deux autres extraient tous les n-grammes et les filtrent, soit </context>
<context position="10046" citStr="TALN-RÉCITAL 2013" startWordPosition="1476" endWordPosition="1477"> les combinent avec des représentations plus complexes des documents. Ces 1. Un chunk est une unité minimale de sens constituée d’un ou de plusieurs mots. Un chunk nominal est un chunk dont la tête est un nom ou un pronom. Par exemple, dans « Nous avons une bonne politique qualitative. », « Nous » et « une bonne politique qualitative » sont des chunks nominaux. 2. L’abstraction de la langue est vraie pour ce qui est de la méthodologie, cependant les pré-traitements tels que la segmentation en phrases, en mots et l’étiquetage en parties du discours sont eux spécifiques à la langue. 98 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne représentations peuvent aller de groupes de mots sémantiquement similaires à des graphes dont les nœuds sont des unités textuelles (mots, expressions, phrases, etc.) liées par des relations de recommandation 3. 2.1.1 Approches statistiques Plusieurs approches cherchent à définir ce qu’est un terme-clé en s’appuyant sur certains traits statistiques et en étudiant leur rapport avec la notion d’importance d’un terme candidat. Plus un terme candidat est jugé important vis-à-vis du document analysé, plus celui-ci est pertinent en tant que terme-clé. TF-IDF (cf. équ</context>
<context position="12918" citStr="TALN-RÉCITAL 2013" startWordPosition="1944" endWordPosition="1945">appliquée pour l’extraction de termes-clés. Dans l’article de Claveau (2012), Okapi est décrit comme un TF-IDF prenant mieux en compte la longueur des documents. Cette dernière est utilisée pour normaliserle T F (qui devient T FBM25) : N − DF( terme) + 0,5 Okapi(terme) = T FBM25(terme)× log (3)DF(terme) + 0,5 T F(term T FBM25 = e)× (k1 + 1)  (4) T F(terme) + k1 × 1− b+ b× DLDLmoyenne 3. Pour une étude comparative de certaines des méthodes par regroupement (Liu et al., 2009) et à base de graphe (Mihalcea et Tarau, 2004; Wan et Xiao, 2008b), voir l’article de Hasan et Ng (2010). 99 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Dans la formule (4), k1 et b sont des constantes fixées à 2 et 0, 75 respectivement. DL représente la longueur du document analysé et DLmoyenne la longueur moyenne des documents de la collection utilisée. Barker et Cornacchia (2000) estiment que les grands phrasèmes sont plus informatifs et qu’ils doivent être privilégiés. Pour cela, leur approche est très simple : plus un groupe nominal est long et fréquent dans le document analysé, plus il est jugé pertinent en tant que terme-clé de ce document. Cependant, pour éviter la répétition dans le texte, les auteurs</context>
<context position="16577" citStr="TALN-RÉCITAL 2013" startWordPosition="2498" endWordPosition="2499">t que termes-clés. Une donnée statistique non citée précédemment, mais pourtant récurrente dans les méthodes d’extraction de termes-clés, est la fréquence de co-occurrences entre deux phrasèmes (termes). Deux phrasèmes co-occurrent s’ils apparaissent ensemble dans le même contexte. La co-occurrence peut être calculée de manière stricte (les phrasèmes doivent être côte-à-côte) ou bien dans une fenêtre de mots. Compter le nombre de co-occurrences entre deux termes permet d’estimer s’ils sont sémantiquement liés ou non. Ce lien sémantique à lui seul ne peut pas servir à extraire des 100 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne termes-clés, mais il permet de mieux organiser les termes d’un document pour affiner l’extraction (Matsuo et Ishizuka, 2004; Liu et al., 2009; Mihalcea et Tarau, 2004). 2.1.2 Approches par regroupement L’objectif des approches par regroupement est de définir des groupes dont les unités textuelles partagent une ou plusieurs caractéristiques communes. Ainsi, lorsque des termes-clés sont extraits à partir de chaque groupe, cela permet de mieux couvrir le document analysé selon les caractéristiques utilisées. Dans la méthode de Matsuo et Ishizuka (2004), ce sont l</context>
<context position="19838" citStr="TALN-RÉCITAL 2013" startWordPosition="3020" endWordPosition="3021"> notion de recommandation d’une unité textuelle par d’autres 7 (cf. équation 5). Ce score à chaque nœud ni permet d’ordonner les mots par degré d’importance dans le document analysé. La liste ordonnée des mots peut ensuite être 4. Deux phrasèmes qui co-occurrent fréquemment ensemble sont jugés sémantiquement liés. 5. TextRank a aussi été utilisé pour faire du résumé automatique. 6. Dans le cas de TextRank et de SingleRank Aentrant = Asor tant , car le graphe n’est pas orienté. 7. Plus le score d’une unité textuelle est élevé, plus celle-ci est importante dans le document analysé. 101 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne utilisée pour extraire les termes-clés. p S(ni) = ( j, 1−λ) +λ×  i × S(nj) (5) n pj∈Aentrant(ni) j,k nk∈Asortant(nj) λ est un facteur d’atténuation qui peut être considéré ici comme la probabilité pour que le nœud ni soit atteint par recommandation. pj,i représente le poids de l’arc allant du nœud nj vers le nœud ni , soit le nombre de co-occurrences entre les deux mots i et j 8. Dans leurs travaux, Wan et Xiao (2008b) s’intéressent à l’ajout d’informations dans le graphe grâce à des documents similaires (voisins) et aux relations de co-occurrences qu’ils po</context>
<context position="22954" citStr="TALN-RÉCITAL 2013" startWordPosition="3509" endWordPosition="3510">dans le document aient été concaténés). La technique utilisée dans les autres méthodes consiste à ordonner les termes candidats en fonction de la somme du score des mots qui les composent. Cependant, puisque l’un des avantages du graphe est que les nœuds peuvent avoir une granularité contrôlée, Liang et al. (2009) décident d’utiliser des mots et des multi-mots au lieu de simples mots et de tirer profit de traits supplémentaires, la taille du terme ou encore sa première position dans le document analysé. 8. TextRank utilise un graphe non-pondéré. Dans ce cas, pj,i vaut toujours 1. 102 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 2.2 Méthodes supervisées Les méthodes supervisées sont des méthodes capables d’apprendre à réaliser une tâche particulière, soit ici l’extraction de termes-clés. L’apprentissage se fait grâce à un corpus dont les documents sont annotés en termes-clés. L’annotation permet d’extraire les exemples et les contresexemples dont les traits statistiques et/ou linguistiques servent à apprendre une classification binaire. La classification binaire consiste à indiquer si un terme candidat est un terme-clé ou non. De nombreux algorithmes d’apprentissage sont utilisés dans</context>
<context position="26243" citStr="TALN-RÉCITAL 2013" startWordPosition="3993" endWordPosition="3994">ation est lancée. Les nouveaux traits ont pour but d’augmenter le score de vraisemblance des termes candidats ayant un fort lien sémantique avec certains des termes les mieux classés après la première étape. Enfin, Nguyen et Kan (2007) proposent l’ajout des 9. Sarkar et al. (2012) proposent une étude comparative de l’usage des arbres de décision, de la classification naïve bayésienne et des réseaux de neurones pour l’extraction automatique de termes-clés. 10. Il est important de noter que le score de vraisemblance pour chaque terme candidat permet aussi de les ordonner entre eux. 103 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne informations concernant la structure des documents. En effet, certaines sections telles que l’introduction et la conclusion dans les articles scientifiques sont plus susceptibles de contenir des termes-clés qu’une section présentant des résultats expérimentaux, par exemple. Dans leur version modifiée de KEA, ils proposent aussi l’usage de traits linguistiques tels que les parties du discours qui ont prouvées jouer un rôle non-négligeable pour l’extraction de termes-clés (Hulth, 2003). En même temps que KEA (Witten et al., 1999), Turney (1999) met au point l’al</context>
<context position="29692" citStr="TALN-RÉCITAL 2013" startWordPosition="4506" endWordPosition="4507"> × trait(terme, c) c∈{oui,non} trait Le paramètre αtrait définit l’importance du trait auquel il est associé. Les Séparateurs à Large Marge sont aussi des classifieurs utilisés par les méthodes d’extraction automatique de termes-clés. Ils exploitent divers traits afin de projeter des exemples et des contres-exemples sur un plan, puis ils cherchent l’hyperplan qui les sépare. Cet hyperplan sert ensuite dans l’analyse de nouvelles données. Dans le contexte de l’extraction de termes-clés, les exemples sont les termes-clés et les contres-exemples sont les termes candidats qui ne sont 104 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne pas des termes-clés. Ce mode de fonctionnement des SVM est utilisé par Zhang et al. (2006), mais un autre type de SVM est plus largement utilisé dans les méthodes supervisées d’extraction de termes-clés. Il s’agit de SVM qui utilisent de multiples marges représentant des rangs. Ces classifieurs permettent donc d’ordonnancer les termes-clés lors de leur extraction (Herbrich et al., 1999; Joachims, 2006; Jiang et al., 2009). La méthode KeyWE de Eichler et Neumann (2010) utilise ce type de SVM avec le trait TF-IDF ainsi qu’un trait booléen ayant la valeur vraie s</context>
<context position="33597" citStr="TALN-RÉCITAL 2013" startWordPosition="5110" endWordPosition="5111">original de cette approche est justifié par le fait qu’un ensemble de termes-clés doit décrire de manière synthétique le document. Leur hypothèse est donc qu’un ensemble de termes-clés est une traduction d’un document dans un autre langage. Le modèle est appris à partir de paires de traductions dont l’un des termes est issu des titres ou des résumés des documents du corpus d’apprentissage et dont l’autre terme est issu des corps de ces mêmes documents. Les titres et les résumés sont utilisés comme langage synthétique et les corps des documents comme le langage naturel de ceux-ci. 105 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 3 Conclusion et perspectives L’extraction automatique de termes-clés est une tâche importante qui permet la valorisation d’un document (représentation synthétique, mise en évidence des points clés dans le document, etc.) et qui facilite l’accès aux documents pertinents pour une requête utilisateur (indexation pour la recherche d’information). Les méthodes existantes pour la tâche d’extraction automatique de termes-clés sont soit supervisées, soit non-supervisées. Les méthodes non-supervisées sont des méthodes émergentes ayant la particularité de s’abstraire de</context>
</contexts>
<marker>TALN-RÉCITAL, 2013</marker>
<rawString>107 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne LIU, Z., HUANG, W., ZHENG, Y. et SUN, M. (2010). Automatic Keyphrase Extraction via Topic Decomposition. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z LIU</author>
<author>P LI</author>
<author>Y et SUN ZHENG</author>
<author>M</author>
</authors>
<title>Clustering to Find Exemplar Terms for Keyphrase Extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing : Volume</booktitle>
<volume>1</volume>
<marker>LIU, LI, ZHENG, M, 2009</marker>
<rawString>LIU, Z., LI, P., ZHENG, Y. et SUN, M. (2009). Clustering to Find Exemplar Terms for Keyphrase Extraction. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing : Volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y et ISHIZUKA MATSUO</author>
<author>M</author>
</authors>
<title>Keyword Extraction from a Single Document Using Word Co-occurrence Statistical Information.</title>
<date>2004</date>
<marker>MATSUO, M, 2004</marker>
<rawString>MATSUO, Y. et ISHIZUKA, M. (2004). Keyword Extraction from a Single Document Using Word Co-occurrence Statistical Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O et WITTEN MEDELYAN</author>
<author>I</author>
</authors>
<title>Domain-Independent Automatic Keyphrase Indexing with Small Training Sets.</title>
<date>2008</date>
<marker>MEDELYAN, I, 2008</marker>
<rawString>MEDELYAN, O. et WITTEN, I. (2008). Domain-Independent Automatic Keyphrase Indexing with Small Training Sets.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R et TARAU MIHALCEA</author>
<author>P</author>
</authors>
<title>Textrank : Bringing Order Into Texts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<marker>MIHALCEA, P, 2004</marker>
<rawString>MIHALCEA, R. et TARAU, P. (2004). Textrank : Bringing Order Into Texts. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T et KAN NGUYEN</author>
<author>M</author>
</authors>
<title>Keyphrase Extraction in Scientific Publications.</title>
<date>2007</date>
<booktitle>In Proceedings of the 10th international conference on Asian digital libraries : looking back 10</booktitle>
<marker>NGUYEN, M, 2007</marker>
<rawString>NGUYEN, T. et KAN, M. (2007). Keyphrase Extraction in Scientific Publications. In Proceedings of the 10th international conference on Asian digital libraries : looking back 10 years and forging new frontiers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C NOBATA</author>
<author>P COTTER</author>
<author>N OKAZAKI</author>
<author>B REA</author>
<author>Y SASAKI</author>
<author>Y TSURUOKA</author>
<author>J et ANANIADOU TSUJII</author>
<author>S</author>
</authors>
<title>Kleio : a Knowledge-enriched Information Retrieval System for Biology.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval.</booktitle>
<marker>NOBATA, COTTER, OKAZAKI, REA, SASAKI, TSURUOKA, TSUJII, S, 2008</marker>
<rawString>NOBATA, C., COTTER, P., OKAZAKI, N., REA, B., SASAKI, Y., TSURUOKA, Y., TSUJII, J. et ANANIADOU, S. (2008). Kleio : a Knowledge-enriched Information Retrieval System for Biology. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P PAROUBEK</author>
<author>P ZWEIGENBAUM</author>
<author>D et GROUIN FOREST</author>
<author>C</author>
</authors>
<date>2012</date>
<booktitle>Indexation Libre et Contrôlée d’Articles Scientifiques Présentation et Résultats du Défi Fouille de Textes DEFT2012.</booktitle>
<marker>PAROUBEK, ZWEIGENBAUM, FOREST, C, 2012</marker>
<rawString>PAROUBEK, P., ZWEIGENBAUM, P., FOREST, D. et GROUIN, C. (2012). Indexation Libre et Contrôlée d’Articles Scientifiques Présentation et Résultats du Défi Fouille de Textes DEFT2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M et HONKELA PAUKKERI</author>
<author>T</author>
</authors>
<title>Likey : Unsupervised Language-Independent Keyphrase Extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation.</booktitle>
<marker>PAUKKERI, T, 2010</marker>
<rawString>PAUKKERI, M. et HONKELA, T. (2010). Likey : Unsupervised Language-Independent Keyphrase Extraction. In Proceedings of the 5th International Workshop on Semantic Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E ROBERTSON</author>
<author>S WALKER</author>
<author>M et WILLETT BEAULIEU</author>
<author>P</author>
</authors>
<date>1999</date>
<booktitle>Okapi at TREC-7 : Automatic Ad Hoc, Filtering, VLC and Interactive Track.</booktitle>
<marker>ROBERTSON, WALKER, BEAULIEU, P, 1999</marker>
<rawString>ROBERTSON, S. E., WALKER, S., BEAULIEU, M. et WILLETT, P. (1999). Okapi at TREC-7 : Automatic Ad Hoc, Filtering, VLC and Interactive Track.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K SARKAR</author>
<author>M et GHOSE NASIPURI</author>
<author>S</author>
</authors>
<title>A New Approach to Keyphrase Extraction Using Neural Networks.</title>
<date>2010</date>
<marker>SARKAR, NASIPURI, S, 2010</marker>
<rawString>SARKAR, K., NASIPURI, M. et GHOSE, S. (2010). A New Approach to Keyphrase Extraction Using Neural Networks.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K SARKAR</author>
<author>M et GHOSE NASIPURI</author>
<author>S</author>
</authors>
<title>Machine Learning Based Keyphrase Extraction : Comparing Decision Trees, Naïve Bayes, and Artificial Neural Networks.</title>
<date>2012</date>
<marker>SARKAR, NASIPURI, S, 2012</marker>
<rawString>SARKAR, K., NASIPURI, M. et GHOSE, S. (2012). Machine Learning Based Keyphrase Extraction : Comparing Decision Trees, Naïve Bayes, and Artificial Neural Networks.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L SUJIAN</author>
<author>W HOUFENG</author>
<author>Y et CHENGSHENG SHIWEN</author>
<author>X</author>
</authors>
<title>News-Oriented Keyword Indexing with Maximum Entropy Principle.</title>
<date>2003</date>
<marker>SUJIAN, HOUFENG, SHIWEN, X, 2003</marker>
<rawString>SUJIAN, L., HOUFENG, W., SHIWEN, Y. et CHENGSHENG, X. (2003). News-Oriented Keyword Indexing with Maximum Entropy Principle.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T et HURST TOMOKIYO</author>
<author>M</author>
</authors>
<title>A Language Model Approach to Keyphrase Extraction.</title>
<date>2003</date>
<marker>TOMOKIYO, M, 2003</marker>
<rawString>TOMOKIYO, T. et HURST, M. (2003). A Language Model Approach to Keyphrase Extraction.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the ACL 2003 workshop on Multiword expressions : analysis, acquisition and treatment-Volume 18.</booktitle>
<marker></marker>
<rawString>In Proceedings of the ACL 2003 workshop on Multiword expressions : analysis, acquisition and treatment-Volume 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P TURNEY</author>
</authors>
<title>Learning Algorithms for Keyphrase Extraction.</title>
<date>1999</date>
<marker>TURNEY, 1999</marker>
<rawString>TURNEY, P. (1999). Learning Algorithms for Keyphrase Extraction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P TURNEY</author>
</authors>
<title>Coherent Keyphrase Extraction via Web Mining.</title>
<date>2003</date>
<marker>TURNEY, 2003</marker>
<rawString>TURNEY, P. (2003). Coherent Keyphrase Extraction via Web Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X et XIAO WAN</author>
<author>J</author>
</authors>
<title>Collabrank : Towards a Collaborative Approach to Single-Document Keyphrase Extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1.</booktitle>
<marker>WAN, J, 2008</marker>
<rawString>WAN, X. et XIAO, J. (2008a). Collabrank : Towards a Collaborative Approach to Single-Document Keyphrase Extraction. In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X et XIAO WAN</author>
<author>J</author>
</authors>
<title>Single Document Keyphrase Extraction Using Neighborhood Knowledge.</title>
<date>2008</date>
<booktitle>In Proceedings of Association for the Advancement of Artificial Intelligence.</booktitle>
<marker>WAN, J, 2008</marker>
<rawString>WAN, X. et XIAO, J. (2008b). Single Document Keyphrase Extraction Using Neighborhood Knowledge. In Proceedings of Association for the Advancement of Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>c ATALA TALN-RÉCITAL</author>
</authors>
<title>Towards an Iterative Reinforcement Approach for Simultaneous Document Summarization and Keyword Extraction. In Annual Meeting-association For Computational Linguistics.</title>
<date>2013</date>
<pages>17--21</pages>
<contexts>
<context position="2573" citStr="TALN-RÉCITAL 2013" startWordPosition="360" endWordPosition="361">extraction de termes-clés ; méthodes supervisées ; méthodes non-supervisées ; état de l’art . KEYWORDS: keyphrase extraction ; supervised methods ; unsupervised methods ; state of the art . 1 Introduction Les termes-clés sont des mots ou des expressions (multi-mots) représentant les aspects principaux qui sont abordés dans un document. De ce fait, ils sont utilisés dans de nombreux domaines du Traitement Automatique des Langues (TAL). Turney (1999) émet l’hypothèse qu’ils peuvent faciliter la lecture d’un utilisateur en lui permettant de surfer d’un point clé à un autre lorsqu’ils 96 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne sont mis en évidence dans un texte. D’autres chercheurs utilisent leurs vertus synthétiques dans des méthodes de construction automatique de résumés (Wan et al., 2007; Litvak et Last, 2008; Boudin et Morin, 2013), mais ils s’avèrent surtout de plus en plus utiles avec l’essor de l’Internet et la disponibilité de nombreux documents numériques qu’il faut pouvoir indexer de manière pertinente pour faciliter leur recherche par des utilisateurs (Medelyan et Witten, 2008). Dans ce contexte de recherche d’information, les termes-clés peuvent aussi être directement bé</context>
<context position="6284" citStr="TALN-RÉCITAL 2013" startWordPosition="901" endWordPosition="902">un document et à en extraire les aspects importants. Alors que les méthodes de résumé automatique utilisent des phrases pour construire une vision synthétique du document, l’extraction de termes-clés se focalise sur les unités textuelles qui composent ces phrases. Un ensemble de termes-clés peut donc être perçu comme un résumé dont les points clés sont exprimés sans liaisons entre eux. Les unités textuelles sur lesquelles travaillent les systèmes d’extraction automatique de termes-clés sont appelées termes candidats. Ces derniers sont des mots ou des multi-mots (phrasèmes) pouvant 97 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne être promus au statut de terme-clé. L’extraction de termes candidats est une étape préliminaire de l’extraction de termes-clés, que ce soit pour les méthodes non-supervisées ou supervisées. Cette étape est importante, car si certains termes-clés du document analysé ne sont pas présents dans l’ensemble des termes candidats, alors ceux-ci ne pourront pas être extrait. Hulth (2003) étudie trois méthodes d’extraction des termes candidats. L’une consiste à extraire les chunks nominaux 1, tandis que les deux autres extraient tous les n-grammes et les filtrent, soit </context>
<context position="10046" citStr="TALN-RÉCITAL 2013" startWordPosition="1476" endWordPosition="1477"> les combinent avec des représentations plus complexes des documents. Ces 1. Un chunk est une unité minimale de sens constituée d’un ou de plusieurs mots. Un chunk nominal est un chunk dont la tête est un nom ou un pronom. Par exemple, dans « Nous avons une bonne politique qualitative. », « Nous » et « une bonne politique qualitative » sont des chunks nominaux. 2. L’abstraction de la langue est vraie pour ce qui est de la méthodologie, cependant les pré-traitements tels que la segmentation en phrases, en mots et l’étiquetage en parties du discours sont eux spécifiques à la langue. 98 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne représentations peuvent aller de groupes de mots sémantiquement similaires à des graphes dont les nœuds sont des unités textuelles (mots, expressions, phrases, etc.) liées par des relations de recommandation 3. 2.1.1 Approches statistiques Plusieurs approches cherchent à définir ce qu’est un terme-clé en s’appuyant sur certains traits statistiques et en étudiant leur rapport avec la notion d’importance d’un terme candidat. Plus un terme candidat est jugé important vis-à-vis du document analysé, plus celui-ci est pertinent en tant que terme-clé. TF-IDF (cf. équ</context>
<context position="12918" citStr="TALN-RÉCITAL 2013" startWordPosition="1944" endWordPosition="1945">appliquée pour l’extraction de termes-clés. Dans l’article de Claveau (2012), Okapi est décrit comme un TF-IDF prenant mieux en compte la longueur des documents. Cette dernière est utilisée pour normaliserle T F (qui devient T FBM25) : N − DF( terme) + 0,5 Okapi(terme) = T FBM25(terme)× log (3)DF(terme) + 0,5 T F(term T FBM25 = e)× (k1 + 1)  (4) T F(terme) + k1 × 1− b+ b× DLDLmoyenne 3. Pour une étude comparative de certaines des méthodes par regroupement (Liu et al., 2009) et à base de graphe (Mihalcea et Tarau, 2004; Wan et Xiao, 2008b), voir l’article de Hasan et Ng (2010). 99 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Dans la formule (4), k1 et b sont des constantes fixées à 2 et 0, 75 respectivement. DL représente la longueur du document analysé et DLmoyenne la longueur moyenne des documents de la collection utilisée. Barker et Cornacchia (2000) estiment que les grands phrasèmes sont plus informatifs et qu’ils doivent être privilégiés. Pour cela, leur approche est très simple : plus un groupe nominal est long et fréquent dans le document analysé, plus il est jugé pertinent en tant que terme-clé de ce document. Cependant, pour éviter la répétition dans le texte, les auteurs</context>
<context position="16577" citStr="TALN-RÉCITAL 2013" startWordPosition="2498" endWordPosition="2499">t que termes-clés. Une donnée statistique non citée précédemment, mais pourtant récurrente dans les méthodes d’extraction de termes-clés, est la fréquence de co-occurrences entre deux phrasèmes (termes). Deux phrasèmes co-occurrent s’ils apparaissent ensemble dans le même contexte. La co-occurrence peut être calculée de manière stricte (les phrasèmes doivent être côte-à-côte) ou bien dans une fenêtre de mots. Compter le nombre de co-occurrences entre deux termes permet d’estimer s’ils sont sémantiquement liés ou non. Ce lien sémantique à lui seul ne peut pas servir à extraire des 100 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne termes-clés, mais il permet de mieux organiser les termes d’un document pour affiner l’extraction (Matsuo et Ishizuka, 2004; Liu et al., 2009; Mihalcea et Tarau, 2004). 2.1.2 Approches par regroupement L’objectif des approches par regroupement est de définir des groupes dont les unités textuelles partagent une ou plusieurs caractéristiques communes. Ainsi, lorsque des termes-clés sont extraits à partir de chaque groupe, cela permet de mieux couvrir le document analysé selon les caractéristiques utilisées. Dans la méthode de Matsuo et Ishizuka (2004), ce sont l</context>
<context position="19838" citStr="TALN-RÉCITAL 2013" startWordPosition="3020" endWordPosition="3021"> notion de recommandation d’une unité textuelle par d’autres 7 (cf. équation 5). Ce score à chaque nœud ni permet d’ordonner les mots par degré d’importance dans le document analysé. La liste ordonnée des mots peut ensuite être 4. Deux phrasèmes qui co-occurrent fréquemment ensemble sont jugés sémantiquement liés. 5. TextRank a aussi été utilisé pour faire du résumé automatique. 6. Dans le cas de TextRank et de SingleRank Aentrant = Asor tant , car le graphe n’est pas orienté. 7. Plus le score d’une unité textuelle est élevé, plus celle-ci est importante dans le document analysé. 101 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne utilisée pour extraire les termes-clés. p S(ni) = ( j, 1−λ) +λ×  i × S(nj) (5) n pj∈Aentrant(ni) j,k nk∈Asortant(nj) λ est un facteur d’atténuation qui peut être considéré ici comme la probabilité pour que le nœud ni soit atteint par recommandation. pj,i représente le poids de l’arc allant du nœud nj vers le nœud ni , soit le nombre de co-occurrences entre les deux mots i et j 8. Dans leurs travaux, Wan et Xiao (2008b) s’intéressent à l’ajout d’informations dans le graphe grâce à des documents similaires (voisins) et aux relations de co-occurrences qu’ils po</context>
<context position="22954" citStr="TALN-RÉCITAL 2013" startWordPosition="3509" endWordPosition="3510">dans le document aient été concaténés). La technique utilisée dans les autres méthodes consiste à ordonner les termes candidats en fonction de la somme du score des mots qui les composent. Cependant, puisque l’un des avantages du graphe est que les nœuds peuvent avoir une granularité contrôlée, Liang et al. (2009) décident d’utiliser des mots et des multi-mots au lieu de simples mots et de tirer profit de traits supplémentaires, la taille du terme ou encore sa première position dans le document analysé. 8. TextRank utilise un graphe non-pondéré. Dans ce cas, pj,i vaut toujours 1. 102 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 2.2 Méthodes supervisées Les méthodes supervisées sont des méthodes capables d’apprendre à réaliser une tâche particulière, soit ici l’extraction de termes-clés. L’apprentissage se fait grâce à un corpus dont les documents sont annotés en termes-clés. L’annotation permet d’extraire les exemples et les contresexemples dont les traits statistiques et/ou linguistiques servent à apprendre une classification binaire. La classification binaire consiste à indiquer si un terme candidat est un terme-clé ou non. De nombreux algorithmes d’apprentissage sont utilisés dans</context>
<context position="26243" citStr="TALN-RÉCITAL 2013" startWordPosition="3993" endWordPosition="3994">ation est lancée. Les nouveaux traits ont pour but d’augmenter le score de vraisemblance des termes candidats ayant un fort lien sémantique avec certains des termes les mieux classés après la première étape. Enfin, Nguyen et Kan (2007) proposent l’ajout des 9. Sarkar et al. (2012) proposent une étude comparative de l’usage des arbres de décision, de la classification naïve bayésienne et des réseaux de neurones pour l’extraction automatique de termes-clés. 10. Il est important de noter que le score de vraisemblance pour chaque terme candidat permet aussi de les ordonner entre eux. 103 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne informations concernant la structure des documents. En effet, certaines sections telles que l’introduction et la conclusion dans les articles scientifiques sont plus susceptibles de contenir des termes-clés qu’une section présentant des résultats expérimentaux, par exemple. Dans leur version modifiée de KEA, ils proposent aussi l’usage de traits linguistiques tels que les parties du discours qui ont prouvées jouer un rôle non-négligeable pour l’extraction de termes-clés (Hulth, 2003). En même temps que KEA (Witten et al., 1999), Turney (1999) met au point l’al</context>
<context position="29692" citStr="TALN-RÉCITAL 2013" startWordPosition="4506" endWordPosition="4507"> × trait(terme, c) c∈{oui,non} trait Le paramètre αtrait définit l’importance du trait auquel il est associé. Les Séparateurs à Large Marge sont aussi des classifieurs utilisés par les méthodes d’extraction automatique de termes-clés. Ils exploitent divers traits afin de projeter des exemples et des contres-exemples sur un plan, puis ils cherchent l’hyperplan qui les sépare. Cet hyperplan sert ensuite dans l’analyse de nouvelles données. Dans le contexte de l’extraction de termes-clés, les exemples sont les termes-clés et les contres-exemples sont les termes candidats qui ne sont 104 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne pas des termes-clés. Ce mode de fonctionnement des SVM est utilisé par Zhang et al. (2006), mais un autre type de SVM est plus largement utilisé dans les méthodes supervisées d’extraction de termes-clés. Il s’agit de SVM qui utilisent de multiples marges représentant des rangs. Ces classifieurs permettent donc d’ordonnancer les termes-clés lors de leur extraction (Herbrich et al., 1999; Joachims, 2006; Jiang et al., 2009). La méthode KeyWE de Eichler et Neumann (2010) utilise ce type de SVM avec le trait TF-IDF ainsi qu’un trait booléen ayant la valeur vraie s</context>
<context position="33597" citStr="TALN-RÉCITAL 2013" startWordPosition="5110" endWordPosition="5111">original de cette approche est justifié par le fait qu’un ensemble de termes-clés doit décrire de manière synthétique le document. Leur hypothèse est donc qu’un ensemble de termes-clés est une traduction d’un document dans un autre langage. Le modèle est appris à partir de paires de traductions dont l’un des termes est issu des titres ou des résumés des documents du corpus d’apprentissage et dont l’autre terme est issu des corps de ces mêmes documents. Les titres et les résumés sont utilisés comme langage synthétique et les corps des documents comme le langage naturel de ceux-ci. 105 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 3 Conclusion et perspectives L’extraction automatique de termes-clés est une tâche importante qui permet la valorisation d’un document (représentation synthétique, mise en évidence des points clés dans le document, etc.) et qui facilite l’accès aux documents pertinents pour une requête utilisateur (indexation pour la recherche d’information). Les méthodes existantes pour la tâche d’extraction automatique de termes-clés sont soit supervisées, soit non-supervisées. Les méthodes non-supervisées sont des méthodes émergentes ayant la particularité de s’abstraire de</context>
</contexts>
<marker>TALN-RÉCITAL, 2013</marker>
<rawString>108 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne WAN, X., YANG, J. et XIAO, J. (2007). Towards an Iterative Reinforcement Approach for Simultaneous Document Summarization and Keyword Extraction. In Annual Meeting-association For Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I WITTEN</author>
<author>G PAYNTER</author>
<author>E FRANK</author>
<author>C et NEVILL-MANNING GUTWIN</author>
<author>C</author>
</authors>
<title>KEA : Practical Automatic Keyphrase Extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of the 4th ACM conference on Digital libraries.</booktitle>
<marker>WITTEN, PAYNTER, FRANK, GUTWIN, C, 1999</marker>
<rawString>WITTEN, I., PAYNTER, G., FRANK, E., GUTWIN, C. et NEVILL-MANNING, C. (1999). KEA : Practical Automatic Keyphrase Extraction. In Proceedings of the 4th ACM conference on Digital libraries.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K ZHANG</author>
<author>H XU</author>
<author>J et LI TANG</author>
<author>J</author>
</authors>
<title>Keyword Extraction Using Support Vector Machine. 109 c ATALA</title>
<date>2006</date>
<marker>ZHANG, XU, TANG, J, 2006</marker>
<rawString>ZHANG, K., XU, H., TANG, J. et LI, J. (2006). Keyword Extraction Using Support Vector Machine. 109 c ATALA</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>