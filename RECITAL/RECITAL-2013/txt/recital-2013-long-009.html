<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Influence de l&#8217;&#233;tiquetage syntaxique des t&#234;tes sur l&#8217;analyse en d&#233;pendances discontinues du fran&#231;ais</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Influence de l&#8217;&#233;tiquetage syntaxique des t&#234;tes sur l&#8217;analyse en
d&#233;pendances discontinues du fran&#231;ais
</p>
<p>Oph&#233;lie Lacroix1
(1) LINA - Universit&#233; de Nantes, 2 Rue de la Houssini&#232;re, 44322 Nantes Cedex 3
</p>
<p>R&#201;SUM&#201;
Dans cet article nous souhaitons mettre en &#233;vidence l&#8217;utilit&#233; d&#8217;un &#233;tiquetage syntaxique appliqu&#233;
en amont d&#8217;une analyse syntaxique en d&#233;pendances. Les r&#232;gles de la grammaire cat&#233;gorielle
de d&#233;pendances du fran&#231;ais utilis&#233;es pour l&#8217;analyse g&#232;rent les d&#233;pendances discontinues et
les relations syntaxiques &#224; longue distance. Une telle m&#233;thode d&#8217;analyse g&#233;n&#232;re un nombre
cons&#233;quent de structures de d&#233;pendances et emploie un temps d&#8217;analyse trop important. Nous
voulons alors montrer qu&#8217;une m&#233;thode locale d&#8217;&#233;tiquetage peut diminuer l&#8217;ampleur de ces
difficult&#233;s et par la suite aider &#224; r&#233;soudre le probl&#232;me global de d&#233;sambigu&#239;sation d&#8217;analyse en
d&#233;pendances. Nous adaptons alors une m&#233;thode d&#8217;&#233;tiquetage aux cat&#233;gories de la grammaire
cat&#233;gorielle de d&#233;pendance. Nous obtenons ainsi une pr&#233;-s&#233;lection des t&#234;tes des d&#233;pendances
permettant de r&#233;duire l&#8217;ambigu&#239;t&#233; de l&#8217;analyse et de voir que les r&#233;sultats locaux d&#8217;une telle
m&#233;thode permettent de trouver des relations distantes de d&#233;pendances.
</p>
<p>ABSTRACT
On the Effect of Head Tagging on Parsing Discontinuous Dependencies in French
</p>
<p>In this paper we want to show the strong impact of syntactic tagging on syntactic dependency
parsing. The rules of categorial dependency grammar used to parse French deal with discon-
tinuous dependencies and long distance syntactic relations. Such parsing method produces a
substantial number of dependency structures and takes too much parsing time. We want to show
that a local tagging method can reduce these problems and help to solve the global problem of
dependency parsing disambiguation. Then we adapt a tagging method to types of the categorial
dependency grammar. We obtain a dependency-head pre-selection allowing to reduce parsing
ambiguity and to see that we can find distant relation of dependencies through local results of
such method.
</p>
<p>MOTS-CL&#201;S : Analyse syntaxique en d&#233;pendances discontinues, &#201;tiquetage syntaxique.
KEYWORDS: Discontinuous Dependency Parsing, Syntactic Tagging.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>110 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1 Introduction
</p>
<p>L&#8217;analyse syntaxique est une t&#226;che bien connue dans le domaine du traitement automatique du
langage naturel, permettant d&#8217;obtenir des structures syntaxiques &#224; partir de phrases du langage
naturel. On oppose couramment les repr&#233;sentations syntaxiques des structures par consituants et
des structures en d&#233;pendances. Ici, nous nous int&#233;ressons particuli&#232;rement &#224; la repr&#233;sentation en
d&#233;pendances de ces structures (Tesni&#232;re, 1959; Mel&#8217;cuk, 1988). En utilisant cette repr&#233;sentation,
nous souhaitons exprimer correctement les relations syntaxiques existantes entre les mots d&#8217;une
phrase. Ces relations sont des relations binaires (d&#233;pendances) entre un gouverneur g et un
</p>
<p>subordonn&#233; s o&#249; le type de d&#233;pendance d est la fonction syntaxique existante entre g et s (g
d&#8722;&#8594; s).
</p>
<p>Une telle d&#233;pendance est projective si chaque mot dans l&#8217;intervalle [g,s] d&#233;pend de g (sinon
elle est discontinue). Le type de d&#233;pendance d est aussi la d&#233;pendance-t&#234;te 1 du subordonn&#233;
s. Notre travail se situe au niveau de l&#8217;analyse syntaxique en d&#233;pendances pour le fran&#231;ais. Or
cette langue admet des cas de discontinuit&#233; &#224; travers des relations de longue distance comme la
cor&#233;f&#233;rence (voir figure 1) ou la comparaison ou des relations locales fr&#233;quentes, par exemple de
n&#233;gation ou de clitique. Nous avons choisi une m&#233;thode d&#8217;analyse guid&#233;e par les r&#232;gles d&#8217;une
</p>
<p>&#1;&#2; &#3; &#4; &#5;&#6; &#2;&#7;&#8;&#9;&#10;&#11;&#12;&#13;&#5; &#14;&#15;&#16; &#6;&#2; &#8;&#16; &#4; &#17;&#11;&#5;&#5;&#11;&#8;&#10;&#6; &#15;&#8;&#11; &#10;&#11;&#2;&#2;&#11; &#5;&#7;&#2;&#6;&#10;&#15;&#18;&#11; &#14;&#15;&#11; &#19;&#16; &#11;&#5;&#10; &#15;&#8; &#20;&#11;&#17;&#10;&#6;&#9;&#11; &#21;
</p>
<p>&#18;&#6;&#5;&#10;&#22;&#17;&#11;&#2;
</p>
<p>&#19;&#7;&#17;&#11;&#23;
</p>
<p>&#12;&#7;&#18;&#6;&#23;
&#19;&#24;&#19;&#7;&#13;&#15;&#2;
&#19;&#7;&#12;&#13;&#4;&#17;&#25;&#22;&#19;&#2;&#6;&#10;&#22;&#2;
</p>
<p>&#13;&#17;&#11;&#18; &#13;&#17;&#11;&#18;
&#8;&#11;&#9;
</p>
<p>&#4;&#22;&#7;&#26;&#27;
</p>
<p>&#4;&#15;&#28;
</p>
<p>&#19;&#2;&#4;&#15;&#5;
</p>
<p>&#13;&#17;&#11;&#18; &#18;&#11;&#10;
&#8;&#24;&#19;&#7;&#13;&#15;&#2;&#19;&#2;&#4;&#15;&#5;
</p>
<p>&#23;&#5;
</p>
<p>&#18;&#11;&#10;
</p>
<p>FIGURE 1 &#8211; Structure de d&#233;pendances pour la phrase &quot;Il y a si longtemps qu&#8217;il n&#8217;a ressenti une telle
solitude que c&#8217;est un vertige.&quot;. Les d&#233;pendances projectives sont repr&#233;sent&#233;es par des lignes plaines
tandis que les d&#233;pendances discontinues sont repr&#233;sent&#233;es par des lignes pointill&#233;es. Les types des
d&#233;pendances sont les types utilis&#233;s par une grammaire cat&#233;gorielle de d&#233;pendances du fran&#231;ais.
</p>
<p>grammaire permettant d&#8217;obtenir des structures de d&#233;pendances projectives et des structures de
d&#233;pendances discontinues 2. Le mod&#232;le de grammaire cat&#233;gorielle de d&#233;pendances (Dikovsky,
2004; B&#233;chet et al., 2005; Dekhtyar et Dikovsky, 2008; Dekhtyar et al., 2012) &#233;tend la gestion
des d&#233;pendances aux d&#233;pendances discontinues et est donc tout &#224; fait adapt&#233;e &#224; la repr&#233;sentation
syntaxique en d&#233;pendances de phrases du fran&#231;ais. Le CDG Lab (Alfared et al., 2011) est un
outil, destin&#233; &#224; l&#8217;analyse syntaxique avec des grammaires cat&#233;gorielles de d&#233;pendances et au
d&#233;veloppement de corpus arbor&#233;s en d&#233;pendances. Il propose trois modes d&#8217;analyses diff&#233;rents
que nous red&#233;finirons par la suite. Le mode nous int&#233;ressant ici est le mode semi-automatique de
s&#233;lection des t&#234;tes. Dans ce mode, un utilisateur souhaitant proc&#233;der &#224; une analyse syntaxique en
</p>
<p>1. La d&#233;pendance-t&#234;te est le type de la d&#233;pendance arrivant sur le subordonn&#233;.
2. Une structure de d&#233;pendances discontinue est une structure dans laquelle on trouve au moins une d&#233;pendance
</p>
<p>discontinue. Dans ces structures les d&#233;pendances peuvent se croiser. Par exemple, les clitiques engendrent des d&#233;pendances
discontinues d&#232;s lors qu&#8217;une forme compos&#233;e verbale est employ&#233;e, s&#233;parant le verbe et son objet cliticis&#233;. La n&#233;gation
produit fr&#233;quemment une discontinuit&#233; puisqu&#8217;elle est commun&#233;ment compos&#233; de deux particules, parfois distantes
(&quot;Ne ... que&quot;), parfois invers&#233;s (&quot;Jamais ... ne&quot;). Par ailleurs, la relation de cor&#233;f&#233;rence (figure 1) est intraphrasale, elle
correspond &#224; la co-pr&#233;dication d&#233;finie par (Mel&#8217;cuk, 1988).
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>111 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>d&#233;pendances pourra s&#233;lectionner manuellement les d&#233;pendances-t&#234;tes. Cette s&#233;lection des t&#234;tes
en amont de l&#8217;analyse syntaxique am&#233;liore grandement la vitesse d&#8217;analyse par rapport &#224; une
analyse automatique &#224; partir des phrases brutes du fran&#231;ais. Nous souhaitons donc remplacer,
pour notre travail, cette s&#233;lection des t&#234;tes manuelles par une s&#233;lection automatique. Cette t&#226;che
est similaire &#224; celle d&#8217;&#233;tiquetage grammaticale ou d&#8217;&#233;tiquetage morphosyntaxique. L&#8217;id&#233;e d&#8217;utiliser
un pr&#233;-&#233;tiquetage pour r&#233;duire l&#8217;ambigu&#239;t&#233; et am&#233;liorer une analyse syntaxique en d&#233;pendances &#224;
d&#233;j&#224; &#233;t&#233; exploit&#233;e dans ce cadre (Nasr, 2006; Candito et al., 2010). Ici, nous souhaitons mettre en
place un proc&#233;d&#233; de type supertagging (Bangalore et Joshi, 2010b). La s&#233;lection des t&#234;tes est en
fait un &#233;tiquetage syntaxique des unit&#233;s lexicales des phrases du fran&#231;ais adapt&#233; &#224; la grammaire
cat&#233;gorielle de d&#233;pendance du fran&#231;ais utilis&#233;e pour l&#8217;analyse en d&#233;pendance. Il ne s&#8217;agit donc pas
d&#8217;apporter des informations grammaticales ou morphosyntaxiques (propres aux unit&#233;s lexicales)
&#224; l&#8217;analyseur mais bien d&#8217;apporter des informations syntaxiques qui d&#233;finissent des fonctions
binaires entre unit&#233;s lexicales. La difficult&#233; est alors de trouver les bonnes &#233;tiquettes syntaxiques
de mani&#232;re locale, avec des informations locales, bien que la fonction syntaxique auquelle
l&#8217;&#233;tiquette r&#233;f&#232;re concerne deux unit&#233;s lexicales potentiellement distantes. Nous proc&#233;derons
alors dans un premier temps &#224; cet &#233;tiquetage syntaxique en utilisant la m&#233;thode des CRF 3
</p>
<p>adapt&#233;e aux types de d&#233;pendances de la grammaire cat&#233;gorielle de d&#233;pendances du fran&#231;ais.
Nous essayons ici d&#8217;utiliser une m&#233;thode locale pour r&#233;soudre un probl&#232;me global. Il s&#8217;agit de
la principale difficult&#233; de cette m&#233;thode. Nous souhaitons donc voir si elle permettra d&#8217;obtenir
les bonnes d&#233;pendances-t&#234;tes. Puis nous ex&#233;cuterons l&#8217;analyse en d&#233;pendances sur les phrases
ainsi &#233;tiquet&#233;es pour constater l&#8217;effet positif de cet &#233;tiquetage sur le temps d&#8217;analyse et sur la
production (les structures de d&#233;pendances sortantes) de l&#8217;analyseur. Pour conclure, nous nous
questionnerons sur la place de cette m&#233;thode dans une analyse totalement autonome. Est-elle
suffisante vis-&#224;-vis des r&#233;sultats obtenus ou peut-elle &#234;tre associ&#233;e &#224; d&#8217;autres proc&#233;d&#233;s permettant
de combler les imperfections de celle-ci ?
</p>
<p>Ce travail s&#8217;inscrit dans un travail de plus grande envergure qui comprendra un travail de
d&#233;coupage des phrases en unit&#233;s lexicales, ainsi que leur &#233;tiquetage grammaticale, un travail
d&#8217;&#233;tiquetage syntaxique pr&#233;c&#233;dant celui d&#8217;analyse syntaxique en d&#233;pendances, puis finira par un
travail concernant le tri des structures de d&#233;pendances en sortie de l&#8217;analyseur. Ici nous nous
int&#233;ressons en particulier &#224; l&#8217;&#233;tiquetage syntaxique. Nous supposons donc avoir en entr&#233;e un bon
d&#233;coupage des phrases en unit&#233;s lexicales compos&#233;es ainsi qu&#8217;un bon &#233;tiquetage grammatical de
ces unit&#233;s.
</p>
<p>2 Grammaires cat&#233;gorielles de d&#233;pendances
</p>
<p>Le mod&#232;le de grammaires cat&#233;gorielles de d&#233;pendances est un mod&#232;le de grammaires similaire
aux grammaires cat&#233;gorielles classiques (Bar-Hillel et al., 1964) auxquelles est ajout&#233;e la notion
de valence polaris&#233;e permettant d&#8217;introduire les d&#233;pendances discontinues. Dans ce mod&#232;le,
les cat&#233;gories sont des types de d&#233;pendances et permettent de repr&#233;senter les d&#233;pendances
projectives tandis que les valences polaris&#233;es sont des types de d&#233;pendances associ&#233;es &#224; des
polarit&#233;s duales (&#65535;&#65535;et &#65535;&#65535;) permettant de repr&#233;senter les d&#233;pendances discontinues (voir
(Dekhtyar et Dikovsky, 2008)). Les r&#232;gles utilis&#233;es par cette classe de grammaires sont pr&#233;sent&#233;es
dans la figure 1. Les structures de d&#233;pendances produites &#224; l&#8217;aide de ces grammaires sont alors
des graphes orient&#233;s acycliques.
</p>
<p>3. Conditional Random Fields en anglais ou champs markovien conditionnels en fran&#231;ais.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>112 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L1 CP1
&#65535;
C\&#946;&#65535;P2 &#65535; &#65535;&#946;&#65535;P1P2
</p>
<p>I1 CP1
&#65535;
C&#8727;\&#946;&#65535;P2 &#65535; &#65535;C&#8727;\&#946;&#65535;P1P2
</p>
<p>&#8486;1
&#65535;
C&#8727;\&#946;&#65535;P &#65535; &#65535;&#946;&#65535;P
</p>
<p>D1 &#945;P1(&#65535;C)P(&#65535;C)P2 &#65535; &#945;P1PP2 , si (&#65535; C)(&#65535; C) satisfait le principe FA
TABLE 1 &#8211; R&#232;gles gauches des grammaires cat&#233;gorielles de d&#233;pendances. Des r&#232;gles sym&#233;triques sont
utilis&#233;es dans le cas des d&#233;rivations &#224; droite. Les r&#232;gles L, I et &#8486; permettent d&#8217;&#233;liminer les cat&#233;gories
classiques et les cat&#233;gories it&#233;rables (i.e. d&#233;rivables infiniement), et de concat&#233;ner ou conserver
les valences polaris&#233;es en une cha&#238;ne que l&#8217;on appelle potentiel. L&#8217;&#233;limination des valences dans la
d&#233;rivation (r&#232;gle D) se fait sur le principe FA (First Available) : les valences duales les plus proches
dans un potentiel sont &#233;limin&#233;es en premier.
</p>
<p>2.1 Donn&#233;es de la grammaire cat&#233;gorielle de d&#233;pendances du fran&#231;ais
</p>
<p>Pour notre travail, nous utiliserons une grammaire cat&#233;gorielle de d&#233;pendances du fran&#231;ais
(Dikovsky, 2011). Elle est constitu&#233;e d&#8217;un ensemble cons&#233;quent de r&#232;gles elles-m&#234;mes compos&#233;es
de types de d&#233;pendances (les cat&#233;gories de la grammaire). Ces types de d&#233;pendances, 117 au
total, repr&#233;sentent un vaste champ de fonctions syntaxiques exprimant les particularit&#233;s du
fran&#231;ais. Ces nombreux types de d&#233;pendances sont rassembl&#233;s en 39 groupes de d&#233;pendances
selon leurs fonctions syntaxiques. Par exemple, les d&#233;pendances de type objet accusatif (a-obj),
objet datif (d-obj), objet g&#233;nitif (g-obj) sont r&#233;unies dans le groupe des objets : OBJ. Par ailleurs,
les types de d&#233;pendances peuvent &#234;tre associ&#233;s &#224; des d&#233;pendances discontinues, on en compte 27.
Parmi les types associ&#233;s aux d&#233;pendances discontinues on trouve ceux appartenant aux groupes
des clitiques (CLIT), des modifieurs (MODIF), des r&#233;flexifs (REFLEX), des cor&#233;f&#233;rences (COREF)
et appositions (APPOS), des &#233;l&#233;ments de n&#233;gation (NEG), des aggr&#233;gations (AGRR), etc.
</p>
<p>En outre, les r&#232;gles de la grammaire sont associ&#233;es &#224; des classes grammaticales. Lors d&#8217;une
analyse, avec le choix des r&#232;gles se fait le choix de ces classes grammaticales et des traits
morphologiques des unit&#233;s lexicales &#233;tablies en fonction des valeurs des traits employ&#233;s par le
Lefff 4 (Sagot, 2010). On d&#233;nombre 185 classes grammaticales.
</p>
<p>2.2 CDG Lab : Analyseur en d&#233;pendances
</p>
<p>Le CDG Lab (Alfared et al., 2011) est un outil de travail d&#233;di&#233; &#224; l&#8217;analyse en d&#233;pendances guid&#233;e
par les r&#232;gles de grammaires cat&#233;gorielles de d&#233;pendances. L&#8217;analyseur en d&#233;pendances du CDG
Lab propose 3 modes d&#8217;analyse diff&#233;rents mais compl&#233;mentaires :
&#8211; l&#8217;analyse autonome est un mode permettant de lancer l&#8217;analyse &#224; partir d&#8217;une phrase du fran&#231;ais
sans indiquer manuellement d&#8217;informations compl&#233;mentaires. La phrase est donc d&#233;coup&#233;e
en mots qui sont eux-m&#234;mes r&#233;associ&#233;s en unit&#233;s lexicales possibles 5. L&#8217;analyse (bas&#233;e sur un
algorithme CYK modifi&#233;) est alors ex&#233;cut&#233;e &#224; partir de ce d&#233;coupage.
</p>
<p>&#8211; l&#8217;analyse par s&#233;lection des t&#234;tes est un mode semi-automatique. Avant de proc&#233;der &#224; l&#8217;analyse,
l&#8217;utilisateur &#224; la possibilit&#233; de choisir les bonnes unit&#233;s lexicales, leurs classes grammaticales et
leurs d&#233;pendances-t&#234;tes. L&#8217;analyse peut ensuite &#234;tre lanc&#233;e en tenant compte de ces choix.
</p>
<p>4. Lexique des formes fl&#233;chies du fran&#231;ais.
5. Bas&#233;es sur Lefff (Sagot, 2010).
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>113 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#8211; l&#8217;analyse par approximation s&#8217;effectue &#224; la suite d&#8217;une analyse automatique ou d&#8217;une analyse
par s&#233;lection des t&#234;tes. Elle permet d&#8217;annoter positivement ou n&#233;gativement les attributions des
classes grammaticales et/ou des types de d&#233;pendances. Appliqu&#233; autant de fois que n&#233;cessaire,
ce mode permet de raffiner la production de l&#8217;analyse : la(les) structure(s) de d&#233;pendances
r&#233;sultante(s).
</p>
<p>Le mode qui nous int&#233;resse ici est celui de la s&#233;lection des t&#234;tes en amont de l&#8217;analyse syntaxique
en d&#233;pendances. Nous savons que choisir manuellement les d&#233;pendances-t&#234;tes d&#8217;une phrase
avant analyse permet de r&#233;duire l&#8217;ambigu&#239;t&#233; en faisant converger l&#8217;analyse vers un ensemble de
solutions plus restreint. Les avantages se remarquent au niveau du temps de calcul de l&#8217;analyse et
au niveau de la production de l&#8217;analyseur, celui-ci produisant moins de structures de d&#233;pendances
en sortie. Notons que la s&#233;lection des t&#234;tes peut se faire au niveau des types de d&#233;pendances ou
des groupes de d&#233;pendances. On appellera alors respectivement : d&#233;pendance-t&#234;te ou groupe-
t&#234;te, le type ou le groupe de d&#233;pendances s&#233;lectionn&#233; pour une unit&#233; lexicale. Nous souhaitons
donc remplacer la s&#233;lection manuelle des t&#234;tes par une s&#233;lection automatique et comprendre
l&#8217;apport r&#233;el de cette t&#226;che avec un algorithme standard d&#8217;apprentissage.
</p>
<p>2.3 Corpus en d&#233;pendances, donn&#233;es grammaticales et syntaxiques
</p>
<p>Le corpus que nous utiliserons pour nos exp&#233;rimentations a &#233;t&#233; annot&#233; en d&#233;pendances semi-
automatiquement gr&#226;ce &#224; l&#8217;outil CDG Lab. Il est compos&#233; de 2778 structures de d&#233;pendances
associ&#233;es &#224; des phrases du fran&#231;ais provenant de registres vari&#233;s et comprenant au total 35203
unit&#233;s lexicales compos&#233;es. Les d&#233;pendances discontinues repr&#233;sentent 4% du nombre total de
d&#233;pendances du corpus et elles sont pr&#233;sentes (au moins une fois) dans 41% des structures de
d&#233;pendances.
Les types de d&#233;pendances utilis&#233;s dans la repr&#233;sentation de ces structures correspondent aux types
de la grammaire cat&#233;gorielle de d&#233;pendances du fran&#231;ais. De plus, chaque unit&#233; lexicale dans
le corpus est annot&#233;e correctement par une classe grammaticale. Pour proc&#233;der &#224; l&#8217;&#233;tiquetage
syntaxique les donn&#233;es utilis&#233;es seront :
&#8211; les unit&#233;s lexicales compos&#233;es
&#8211; les d&#233;pendances-t&#234;tes (ou groupes-t&#234;tes)
&#8211; les classes grammaticales
Le nombre de classes grammaticales &#233;tant important, nous d&#233;cidons de sous-cat&#233;goriser ces
classes pour arriver &#224; deux formes de sous-classification : les classes grammaticales simples (28
classes) et les classes grammaticales &#233;tendues (86 classes). Une classe grammaticale simple
indique la classe grammaticale d&#8217;une unit&#233; lexicale sans autre information tandis qu&#8217;une classe
grammaticale &#233;tendue ajoute des informations (parfois s&#233;mantiques) potentiellement utiles
syntaxiquement. Les classes grammaticales &#233;tendues, plus pr&#233;cises, permettent de mieux cibler
les types et groupes de d&#233;pendances comme expos&#233; dans la table 2.
</p>
<p>Nombre moyen de types (max.) groupes (max.)
Par classe simple 13 (43) 7 (18)
grammaticale &#233;tendue 6 (31) 4 (16)
</p>
<p>TABLE 2 &#8211; Nombre moyen (et maximum) de types et groupes de d&#233;pendances possibles par classe
grammaticale simple ou &#233;tendue.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>114 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Un exemple, regroupant les donn&#233;es par groupe/type de d&#233;pendances et par classe grammaticale
simple et &#233;tendue, est donn&#233; par la figure 2.
</p>
<p>&#1;&#2; &#3;&#4;&#5;&#6; &#7;&#4;&#5;&#8;&#9; &#10;&#11; &#12;&#13;&#14; &#15;&#14;&#11; &#13;&#16;&#13;&#8;&#6; &#17;
</p>
<p>&#13;&#18;&#4;&#3;&#19;
</p>
<p>&#20;&#21;&#12;&#10; &#10;&#12;&#6;&#18;&#20;
&#22;&#4;&#7;&#20;&#13;&#21; &#22;&#4;&#8;&#19;&#18;&#15;&#14;&#12;
</p>
<p>&#10;&#5;&#9;&#6;&#18;&#21;&#12;&#2;
</p>
<p>&#23;&#9;
</p>
<p>Unit&#233; D&#233;pendance-t&#234;te Classe grammaticale
lexicale type groupe simple &#233;tendue
Il pred PRED PN PN-pers-n
boit S SENT Vt Vt-fin
moins compar COMPAR Adv Adv-degr-compar
d&#8217; det-p DET Det Det
eau a-obj OBJ N N
qu&#8217; dist-rel REL Conj Conj-comp
avant conj-que CONJ Adv Adv
. fs PUNCT FullStop FullStop
</p>
<p>FIGURE 2 &#8211; Structure de d&#233;pendances et tableau rapportant les d&#233;pendances-t&#234;tes, les groupes-t&#234;tes,
les classes grammaticales simples et les classes grammaticales &#233;tendues de chaque unit&#233; lexicale de la
phrase &quot;Il boit moins d&#8217;eau qu&#8217;avant.&quot; Les classes grammaticales &#233;tendues ajoutent des informations
en plus de la classe. Par exemple, Adv-degr-compar et Conj-comp indique un adverbe et une
conjonction qui sont tous deux impliqu&#233;s dans une comparaison. Pour ce travail, nous n&#8217;avons pas
utilis&#233; les traits de Lefff.
</p>
<p>3 &#201;tiquetage syntaxique
</p>
<p>Le probl&#232;me de l&#8217;&#233;tiquetage est un probl&#232;me largement &#233;tudi&#233; dans le domaine du traitement
automatique de la langue naturelle. Les t&#226;ches d&#8217;&#233;tiquetage grammatical ou morphosyntaxique
sont les plus r&#233;pandues mais diff&#232;rent de l&#8217;&#233;tiquetage syntaxique. N&#233;anmoins les outils restent
les m&#234;mes. Parmi les m&#233;thodes existantes pour accomplir la t&#226;che d&#8217;&#233;tiquetage syntaxique on
trouvera, les mod&#232;les graphiques probabilistes tels que les mod&#232;les de Markov cach&#233;s (HMM)
(Rabiner, 1989), les mod&#232;les d&#8217;entropie maximale (MEMM) (Ratnaparkhi, 1996) et les champs
markoviens conditionnels (CRF) (Sutton et McCallum, 2006; Lafferty et al., 2001). Pour notre
travail, nous avons choisi d&#8217;utiliser ces derniers car ils permettent de prendre en compte plus
d&#8217;informations que les HMM et qu&#8217;ils sont bien adapt&#233;s &#224; l&#8217;attribution de s&#233;quences d&#8217;&#233;tiquettes
alors que les MEMM sont plus performants pour la classification.
</p>
<p>3.1 Logiciel et patrons de traits
</p>
<p>Nous avons choisi le logiciel Wapiti (Lavergne et al., 2010) pour entra&#238;ner un mod&#232;le et &#233;tiqueter
syntaxiquement notre corpus car il est capable de travailler avec un grand nombre d&#8217;&#233;tiquettes .
Il utilise les CRF pour cet entra&#238;nement et attribue donc des poids &#224; des traits choisis. Ces traits
peuvent &#234;tre extraits &#224; partir de patrons de traits d&#233;finis &#224; l&#8217;avance. Le logiciel nous laisse la
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>115 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>possibilit&#233; de lui fournir des patrons de traits modifiables que nous avons test&#233;s.
Comme indiqu&#233; dans la partie 2.3, chaque phrase du corpus est d&#233;compos&#233;e en unit&#233;s lexicales
elles-m&#234;mes &#233;tiquet&#233;es grammaticalement (par des classes grammaticales simples ou &#233;tendues
selon le choix d&#8217;exp&#233;rimentation). Nous disposons donc de ces informations. Nous pouvons
choisir une largeur de fen&#234;tre (appliqu&#233;e autour d&#8217;une unit&#233; lexicale) pour indiquer si l&#8217;on
tient compte des unit&#233;s lexicales et des classes grammaticales pr&#233;c&#233;dentes et suivantes lors de
l&#8217;assignation d&#8217;une &#233;tiquette syntaxique. Nous constatons qu&#8217;une fen&#234;tre de 5 (2 mots avant, 2
mots apr&#232;s) donne de bons r&#233;sultats, qu&#8217;&#233;largir la fen&#234;tre &#224; 7 pour les unit&#233;s lexicales g&#233;n&#232;re
beaucoup de traits pour peu d&#8217;am&#233;liorations mais qu&#8217;&#233;largir la fen&#234;tre &#224; 7 autour des classes
grammaticales est beaucoup plus efficace. Il est aussi int&#233;ressant d&#8217;associer unit&#233; lexicale et classe
grammaticale dans un m&#234;me trait. Les premiers patrons de traits choisis sont les suivants :
</p>
<p>Unit&#233; lexicale courante
Unit&#233; lexicale pr&#233;cedente de 1
Unit&#233; lexicale pr&#233;cedente de 2
Unit&#233; lexicale suivante de 1
Unit&#233; lexicale suivante de 2
Classe grammaticale de l&#8217;unit&#233; lexicale courante
Classe grammaticale de l&#8217;unit&#233; lexicale pr&#233;cedente de 1
Classe grammaticale de l&#8217;unit&#233; lexicale pr&#233;cedente de 2
Classe grammaticale de l&#8217;unit&#233; lexicale pr&#233;cedente de 3
Classe grammaticale de l&#8217;unit&#233; lexicale suivante de 1
Classe grammaticale de l&#8217;unit&#233; lexicale suivante de 2
Classe grammaticale de l&#8217;unit&#233; lexicale suivante de 3
Unit&#233; lexicale courante et sa classe grammaticale
</p>
<p>Nous testons aussi quelques traits comme l&#8217;extraction du suffixe des unit&#233;s lexicales (test&#233; pour 2,
3 ou 4 lettres) et le fait de savoir si une unit&#233; lexicale commence par une majuscule et retenons
les suivants :
</p>
<p>Suffixe de 3 lettres de l&#8217;unit&#233; lexicale courante
L&#8217;unit&#233; lexicale pr&#233;c&#233;dente commence-t-elle par une majuscule ?
</p>
<p>Notons ici que les traits choisis sont toujours des traits unigrammes, les traits bigrammes g&#233;n&#233;rant
trop de traits non pertinants. Cependant, pour chaque trait unigramme, la probabilit&#233; qu&#8217;il
appara&#238;sse avec chacune des &#233;tiquettes possibles est calcul&#233;e lors de l&#8217;apprentissage. L&#8217;ensemble de
ces patrons de traits g&#233;n&#232;re alors plus d&#8217;un million 6 de traits pour chaque mod&#232;le d&#8217;apprentissage
et permet d&#8217;obtenir de bons r&#233;sultats d&#8217;&#233;tiquetage pr&#233;cis&#233;s dans la section suivante.
</p>
<p>3.2 Exp&#233;rimentations et &#201;valuation
</p>
<p>Pour proc&#233;der &#224; l&#8217;&#233;tiquetage syntaxique nous avons divis&#233; le corpus (voir section 2.3) en 10
parties &#233;gales. Chaque partie est &#233;tiquet&#233;e selon un mod&#232;le entra&#238;n&#233; sur les 9 autres parties.
L&#8217;entra&#238;nement se fait sur des donn&#233;es parfaitement &#233;tiquet&#233;es grammaticalement et syntaxi-
quement. La possibilit&#233; de choisir des donn&#233;es plus ou moins informatives (classe grammaticale
simple ou &#233;tendue ; d&#233;pendance-t&#234;te ou groupe-t&#234;te) permet de r&#233;aliser 4 exp&#233;rimentations
</p>
<p>6. L&#8217;ensemble des patrons de traits g&#233;n&#232;re, au pire, plus de 32000 traits unigrammes diff&#233;rents qui associ&#233;s aux
diff&#233;rentes possibilit&#233;s d&#8217;&#233;tiquettes (au maximum 117 pour les types) produit jusqu&#8217;&#224; 3,7 millions de traits.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>116 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>diff&#233;rentes. De plus, l&#8217;outil Wapiti nous permet d&#8217;engendrer les n meilleurs &#233;tiquetages pour une
s&#233;quence donn&#233;e. Nous avons donc choisi de produire les 10 meilleurs &#233;tiquetages syntaxiques
pour chaque phrase d&#8217;entr&#233;e. Ainsi &#224; chaque exp&#233;rimentation, nous r&#233;cup&#233;rons 10 s&#233;quences
d&#8217;&#233;tiquettes pour chaque phrase du corpus. Ces s&#233;quences sont potentiellement assez similaires.
Souvent, seulement quelques &#233;tiquettes varient d&#8217;une s&#233;quence &#224; une autre. Pour &#233;valuer la
qualit&#233; de l&#8217;&#233;tiquetage syntaxique nous consid&#233;rons les 1, 2, 5 ou 10 meilleures &#233;tiquettes de
chaque unit&#233; lexicale de chaque phrase du corpus. Les r&#233;sultats de l&#8217;&#233;valuation sont pr&#233;sent&#233;s
dans la table 3.
</p>
<p>&#201;tiquetage des d&#233;pendances-t&#234;tes
Classes Grammaticales simples Classes Grammaticales &#233;tendues
Pr&#233;. (Moy.) Rap. (Moy.) Pr&#233;. (Moy.) Rap. (Moy.)
</p>
<p>Top 1 87.8 (70.7) 87.8 (62.9) 91.1 (77.8) 91.1 (70.1)
Top 2 83.4 (66.0) 90.0 (67.5) 86.5 (72.5) 93.2 (74.1)
Top 5 73.0 (56.2) 92.9 (73.4) 75.1 (61.3) 95.5 (79.6)
Top 10 62.9 (46.6) 94.6 (77.2) 63.6 (51.0) 96.6 (82.4)
</p>
<p>&#201;tiquetage des groupes-t&#234;tes
Classes Grammaticales simples Classes Grammaticales &#233;tendues
Pr&#233;. (Moy.) Rap. (Moy.) Pr&#233;. (Moy.) Rap. (Moy.)
</p>
<p>Top 1 90.4 (86.5) 90.4 (80.1) 91.6 (89.5) 91.6 (85.6)
Top 2 85.6 (81.0) 92.5 (83.6) 86.8 (83.8) 93.7 (87.9)
Top 5 74.3 (67.7) 95.1 (87.9) 75.0 (71.8) 96.0 (91.2)
Top 10 63.3 (55.2) 96.4 (90.6) 63.4 (57.8) 97.1 (93.1)
</p>
<p>TABLE 3 &#8211; &#201;valuation de l&#8217;&#233;tiquetage syntaxique produit par Wapiti. D&#8217;une part, la pr&#233;cision et le
rappel sont calcul&#233;s globalement sur toutes les &#233;tiquettes. La pr&#233;cision est le nombre d&#8217;&#233;tiquettes
correctes sur le nombre d&#8217;&#233;tiquettes diff&#233;rentes attribu&#233;es. Le nombre d&#8217;&#233;tiquettes diff&#233;rentes attribu&#233;es
varie selon le top, il peut y en avoir 1, de 1 &#224; 2, de 1 &#224; 5 ou de 1 &#224; 10 (on ne compte pas deux
fois la m&#234;me &#233;tiquette). Le rappel est le nombre d&#8217;unit&#233;s lexicales pour lesquelles on a trouv&#233; la
bonne &#233;tiquette (parmi les 1, 2, 5 ou 10 &#233;tiquettes attribu&#233;es) sur le nombre d&#8217;&#233;tiquettes du corpus
d&#8217;entr&#233;e (i.e. le nombre d&#8217;unit&#233;s lexicales). D&#8217;autre part, une moyenne de la pr&#233;cision et du rappel
sur les types/groupes de d&#233;pendances est aussi calcul&#233;e (entre parenth&#232;ses). Dans ce cas, pour chaque
type/groupe, la pr&#233;cision est le nombre d&#8217;&#233;tiquettes correctement attribu&#233;es sur le nombre d&#8217;&#233;tiquettes
diff&#233;rentes attribu&#233;es pour ce type/groupe. Le rappel pour un type/groupe est le nombre d&#8217;unit&#233;s
lexicales y appartenant pour lesquelles on a trouv&#233; la bonne &#233;tiquette sur le nombre d&#8217;&#233;tiquettes de ce
type/groupe existantes dans le corpus d&#8217;entr&#233;e.
</p>
<p>Un permier constat face aux r&#233;sultats d&#8217;&#233;tiquetage est de voir l&#8217;utilit&#233; des informations apport&#233;es
par les classes grammaticales &#233;tendues. De ce c&#244;t&#233; les r&#233;sultats sont meilleurs en pr&#233;cision et
en rappel. De mani&#232;re plus approfondie, on peut voir que plus on consid&#232;re d&#8217;&#233;tiquettes plus
la pr&#233;cision diminue tandis que le rappel augmente. En effet plus on a d&#8217;&#233;tiquettes diff&#233;rentes
pour une unit&#233; lexicale plus on a de chance d&#8217;avoir la bonne &#233;tiquette parmi celles-ci mais on ne
sait pas de laquelle il s&#8217;agit, on perd donc en pr&#233;cision. En fait, les r&#233;sultats par &#233;tiquette varient
grandement. Parmi les 2, 5 ou 10 s&#233;quences d&#8217;&#233;tiquettes pour une m&#234;me phrase, seulement
quelques &#233;tiquettes varient. Les &#233;tiquettes qui ne changent pas (ou peu) &#224; chaque s&#233;quence sont
globalement &quot;s&#251;res&quot; et perdent peu en pr&#233;cision (comme les d&#233;terminants DET, la ponctuation
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>117 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PUNCT, la n&#233;gation NEG dans le cas des groupes). Celles qui gagnent fortement en rappel sont
celles qui sont souvent mal attribu&#233;es dans la premi&#232;re s&#233;quence mais que l&#8217;on finit par trouver
dans les suivantes (comme les relations souvent distantes de cor&#233;f&#233;rence COREF ou d&#8217;apposition
APPOS). Nous souhaitons voir quel impact a ce gain en rappel sur l&#8217;analyse syntaxique en d&#233;pen-
dance. Dans la section suivante nous verrons dans quelle mesure l&#8217;&#233;tiquetage syntaxique r&#233;duit
le temps d&#8217;analyse en d&#233;pendance et permet d&#8217;obtenir une meilleure structure de d&#233;pendances
selon les diff&#233;rents crit&#232;res d&#8217;&#233;tiquetage que nous avons &#233;tablis auparavant.
</p>
<p>4 Analyse syntaxique en d&#233;pendances et &#233;valuation
</p>
<p>4.1 Proc&#233;dure d&#8217;analyse et d&#8217;&#233;valuation
</p>
<p>Pour proc&#233;der &#224; l&#8217;analyse syntaxique en d&#233;pendances nous souhaitons adapter l&#8217;outil d&#8217;analyse
par s&#233;lection des t&#234;tes du CDG Lab pour assigner automatiquement les &#233;tiquettes syntaxiques,
trouv&#233;es par Wapiti, en tant que d&#233;pendances-t&#234;tes (ou groupes-t&#234;tes). Nous attribuons donc
1, 1 &#224; 2, 1 &#224; 5 ou 1 &#224; 10 types (ou groupes) de d&#233;pendances diff&#233;rents &#224; chaque unit&#233; lexicale
compos&#233;e selon les r&#233;sultats des top 1, 2, 5 et 10 de l&#8217;&#233;tiquetage syntaxique. Nous utilisons ici les
meilleurs r&#233;sultats, c&#8217;est &#224; dire ceux trouv&#233;s avec les classes grammaticales &#233;tendues. L&#8217;analyse
syntaxique en d&#233;pendances guid&#233;e par les r&#232;gles de la grammaire cat&#233;gorielle de d&#233;pendances
du fran&#231;ais s&#8217;&#233;xecute en tenant compte des diff&#233;rentes d&#233;pendances-t&#234;tes (ou groupes-t&#234;tes)
possibles. Le CDG Lab est con&#231;u pour produire une liste des structures de d&#233;pendances possibles
pour chaque analyse 7. La s&#233;lection des t&#234;tes permet de r&#233;duire l&#8217;ambigu&#239;t&#233; en contraignant
l&#8217;analyseur &#224; chercher des structures de d&#233;pendances dont les types sont en accord avec cette
s&#233;lection. Vis-&#224;-vis d&#8217;une analyse autonome, ici, le nombre de structures de d&#233;pendances en
sortie est moindre. Nous observons donc des temps d&#8217;analyse &#233;galement r&#233;duits. Les structures
de d&#233;pendances en sortie de l&#8217;analyseur ne sont pas tri&#233;es. Or nous souhaitons avant tout savoir
si parmi les structures de d&#233;pendances produites pour une phrase donn&#233;e se trouve la bonne
structure de d&#233;pendances (i.e. la structure de d&#233;pendances associ&#233;e &#224; cette phrase dans le corpus
en d&#233;pendances de r&#233;f&#233;rence, 2.3). L&#8217;id&#233;e est donc de trier ces structures de la plus proche &#224; la
plus &#233;loign&#233;e de la structure originale. La plus proche &#233;tant celle ayant le plus de d&#233;pendances en
commun 8 avec la structure de r&#233;f&#233;rence. Les diff&#233;rentes &#233;tapes de ce traitement sont illustr&#233;es
dans la figure 3.
</p>
<p>Nous nous int&#233;ressons alors seulement &#224; la premi&#232;re structure de d&#233;pendances de chaque liste
(la plus proche de la structure originale). N&#233;anmoins, parfois, il n&#8217;existe aucune structure de
d&#233;pendances produite. Deux raisons sont possibles :
&#8211; les d&#233;pendances-t&#234;tes (ou groupes-t&#234;tes) assign&#233;es sont en contradiction avec les r&#232;gles de la
</p>
<p>grammaire, cela entra&#238;ne alors un &#233;chec de l&#8217;analyse ;
&#8211; le temps d&#8217;analyse est trop &#233;lev&#233; (commun&#233;ment due &#224; la longueur de la phrase), l&#8217;analyse
</p>
<p>s&#8217;interrompt donc avant d&#8217;aboutir.
Nous souhaitons donc conna&#238;tre le nombre de structures de d&#233;pendances obtenues en sortie. Les
r&#233;sultats de ses exp&#233;rimentations sont pr&#233;sent&#233;s dans la section suivante.
</p>
<p>7. En accord avec les d&#233;pendances-t&#234;tes (ou groupes-t&#234;tes) s&#233;lectionn&#233;es ainsi qu&#8217;avec la grammaire.
8. Une d&#233;pendance est commune aux deux structures de d&#233;pendances si elle poss&#232;de dans les deux structures le
</p>
<p>m&#234;me gouverneur, le m&#234;me subordonn&#233; et le m&#234;me type de d&#233;pendance.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>118 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#1;&#2;&#2;&#3;&#4;&#5;&#6;&#7;&#8;&#8;&#9;&#10;&#4;
</p>
<p>&#11;&#6;&#7;&#12;&#13;&#4;&#6;&#9;&#10;&#4;
</p>
<p>&#14;&#3;&#9;&#15;&#15;&#9;&#7;&#3;&#4;&#16;
&#17;&#9;&#6;&#18;&#10;&#19;&#3;&#7;&#4;&#20;&#20;&#4;
</p>
<p>&#21;&#4;&#16;&#21;&#18;&#2;&#4;&#5;&#21;&#9;&#5;&#17;&#4;&#8;&#16;
&#21;&#13;&#16;&#22;&#3;&#9;&#5;&#23;&#9;&#7;&#8;
</p>
<p>&#1;&#2;&#3;&#4;&#5;&#6;&#7;&#8;&#9;
</p>
<p>&#10;&#3;&#11;&#12;&#13;&#12;&#14;&#15;&#9;&#11;&#8;&#6;&#16;&#17;&#18;&#16;&#24;&#25;&#3;&#9;&#5;&#23;&#9;&#7;&#8;&#26;
</p>
<p>&#27;&#5;&#8;&#4;&#15;&#28;&#20;&#4;&#16;&#21;&#4;&#16;
&#8;&#6;&#3;&#13;&#17;&#6;&#13;&#3;&#4;&#8;
</p>
<p>&#21;&#4;&#16;
&#21;&#18;&#2;&#4;&#5;&#21;&#9;&#5;&#17;&#4;&#8;
&#5;&#19;&#5;&#29;&#6;&#3;&#7;&#18;&#4;&#8;
&#2;&#19;&#13;&#3;&#16;&#17;&#30;&#9;&#12;&#13;&#4;
</p>
<p>&#2;&#30;&#3;&#9;&#8;&#4;
&#19;&#12;&#4;&#13;&#9;&#7;
</p>
<p>&#31; !
</p>
<p>&quot;&#4;&#7;&#20;&#20;&#4;&#13;&#3;&#4;
&#8;&#6;&#3;&#13;&#17;&#6;&#13;&#3;&#4;
</p>
<p>&#21;&#4;&#16;
&#21;&#18;&#2;&#4;&#5;&#21;&#9;&#5;&#17;&#4;&#8;
&#2;&#19;&#13;&#3;&#16;&#17;&#30;&#9;&#12;&#13;&#4;
</p>
<p>&#2;&#30;&#3;&#9;&#8;&#4;&#1;&#5;&#9;&#20;#&#8;&#4;&#16;&#2;&#9;&#3;&#16;
&#8;&#18;&#20;&#4;&#17;&#6;&#7;&#19;&#5;&#16;&#21;&#4;&#8;&#16;&#6;$&#6;&#4;&#8;
</p>
<p>&#14;&#20;&#17;&#16;&#21;&#1;&#22;
</p>
<p>FIGURE 3 &#8211; Sch&#233;ma expliquatif du traitement complet. Wapiti est utilis&#233; pour proc&#233;der &#224; l&#8217;apprentis-
sage sur 90% du corpus et &#224; l&#8217;&#233;tiquetage sur 10%. La partie &#233;tiquet&#233;e est analys&#233;e par l&#8217;analyseur du
CDG Lab en tenant compte des d&#233;pendances-t&#234;tes (ou groupes-t&#234;tes). On obtient plusieurs structures
de d&#233;pendances pour chaque phrase qui sont ensuite tri&#233;es selon leur conformit&#233; avec la structure
originale du corpus de r&#233;f&#233;rence (filtre). Le traitement est op&#233;r&#233; sur chaque partie du corpus.
</p>
<p>4.2 R&#233;sultats et discussions
</p>
<p>Les premiers r&#233;sultats expos&#233;s dans la table 4 pr&#233;sente les taux d&#8217;analyses abouties ainsi que le
nombre d&#8217;unit&#233;s lexicales par phrase et le temps de calcul.
</p>
<p>Nous rapportions dans la section 3.2 qu&#8217;en ayant plus de choix de t&#234;tes pour chaque unit&#233; lexicale
nous avions plus de chance d&#8217;obtenir la bonne t&#234;te parmi ceux-ci. Il en est de m&#234;me pour les
d&#233;pendances lorsqu&#8217;on laisse entre 1 &#224; 10 choix de t&#234;tes pour chaque unit&#233; lexicale : ayant plus de
chance d&#8217;avoir les bonnes d&#233;pendances-t&#234;tes (ou groupes-t&#234;tes) nous avons aussi plus de chance
d&#8217;obtenir une structure de d&#233;pendances proche de la structure de d&#233;pendances de r&#233;f&#233;rence
parmi toutes celles produites. Pour la m&#234;me raison, on obtient de meilleurs taux d&#8217;analyses
ayant abouti. Dans le meilleur des cas (s&#233;lection de 10 &#233;tiquettes), nous avons 2548 analyses
sur 2778 (91.7%) ayant abouti dont 2088 ayant trouv&#233;, parmi les structures de d&#233;pendances
produites, une structure de d&#233;pendances enti&#232;rement correcte. Les temps d&#8217;analyse augmentent
relativement &#224; l&#8217;ambigu&#239;t&#233; (en obtenant plus de structures de d&#233;pendances en sortie) ainsi qu&#8217;&#224; la
longueur des phrases. Effectivement les phrases qui sont analys&#233;es avec un choix de dix &#233;tiquettes
alors qu&#8217;elles ne l&#8217;&#233;taient pas avec un choix inf&#233;rieur sont souvent plus longues car plus difficiles
&#224; &#233;tiqueter correctement et exploitent plus de temps d&#8217;analyse. Par ailleurs, on constate que le
nombre moyen d&#8217;unit&#233;s lexicales par phrase augmente l&#233;g&#232;rement dans le cas des analyses ayant
abouti quand le choix d&#8217;&#233;tiquettes est plus large. Ce qui montre que des phrases plut&#244;t longues
qui n&#8217;ont pas &#233;t&#233; analys&#233;es avec un seul choix d&#8217;&#233;tiquettes l&#8217;ont &#233;t&#233; avec plus de choix. Cependant
un nombre d&#8217;&#233;tiquettes plus important en entr&#233;e augmente l&#8217;ambigu&#239;t&#233; de l&#8217;analyse et donc le
temps d&#8217;analyse. On obtient donc un peu plus de phrases non-analys&#233;es par manque de temps
lorsqu&#8217;on augmente le choix d&#8217;&#233;tiquettes.
Lorsque l&#8217;on compare les r&#233;sultats des exp&#233;rimentations faites avec les d&#233;pendances-t&#234;tes et
les groupes-t&#234;tes, on constate plusieurs points int&#233;ressants. Les taux d&#8217;analyses abouties sont
meilleurs lorsqu&#8217;on utilise les groupes-t&#234;tes car on laisse un plus large choix &#224; l&#8217;analyseur (les
groupes comprennent parfois plusieurs types de d&#233;pendances). N&#233;anmoins on note une diff&#233;rence
au niveau du temps d&#8217;analyse qui est inf&#233;rieur lorsqu&#8217;on utilise les d&#233;pendances-t&#234;tes. En effet,
l&#8217;analyseur converge plus vite. On peut donc voir qu&#8217;il y a moins d&#8217;analyses n&#8217;ayant pas abouti
par manque de temps mais que le nombre d&#8217;analyses n&#8217;ayant pas abouti car &#233;tant non-conforme
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>119 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Analyse autonome
Nb de Nombre de phrases UL/phrase Temps d&#8217;analyse
t&#234;tes AA (%) NA-C (%) NA-T (%) AA NA-C NA-T AA NA
0 1150 (41.4) 3 (00.1) 1625 (58.5) 7.2 7.3 17.6 42min24 4h30
</p>
<p>Analyse avec s&#233;lection des d&#233;pendances-t&#234;tes
Nb de Nombre de phrases UL/phrase Temps d&#8217;analyse
t&#234;tes AA (%) NA-C (%) NA-T (%) AA NA-C NA-T AA NA
1 1805 (65.0) 969 (34.9) 4 (00.1) 11.5 16.5 52.5 3min03 1min35
1 &#224; 2 2054 (73.9) 718 (25.8) 6 (00.2) 11.6 17.7 56.1 4min16 1min53
1 &#224; 5 2335 (84.1) 438 (15.8) 5 (00.2) 12.0 20.0 49.4 6min02 1min29
1 &#224; 10 2505 (90.2) 262 (09.4) 11 (00.4) 12.2 22.5 42.8 8min01 2min23
</p>
<p>Analyse avec s&#233;lection des groupes-t&#234;tes
Nb de Nombre de phrases UL/phrase Temps d&#8217;analyse
t&#234;tes AA (%) NA-C (%) NA-T (%) AA NA-C NA-T AA NA
1 1931 (69.5) 832 (29.9) 15 (00.5) 11.5 16.9 45.8 6min41 3min31
1 &#224; 2 2172 (78.2) 586 (21.1) 20 (00.7) 11.6 18.6 45.0 8min52 4min15
1 &#224; 5 2439 (87.8) 302 (10.9) 37 (01.3) 11.8 21.6 43.6 12min05 6min47
1 &#224; 10 2548 (91.7) 179 (06.4) 51 (01.8) 12.0 24.4 41.6 16min43 9min03
</p>
<p>TABLE 4 &#8211; Calcul du nombre de phrases dont l&#8217;analyse a abouti (AA), du nombre de phrases dont
l&#8217;analyse n&#8217;a pas abouti car elle est non-conforme &#224; la grammaire (NA-C), du nombre de phrases
dont l&#8217;analyse n&#8217;a pas abouti par manque de temps (NA-T). Le temps d&#8217;analyse est limit&#233; &#224; 10s
maximum. Calcul du nombre moyen d&#8217;unit&#233;s lexicales (UL) par phrase dont l&#8217;analyse a abouti et
dont l&#8217;analyse n&#8217;a pas abouti (car non-conforme ou par manque de temps). Calcul du temps total
d&#8217;analyse pour celles ayant abouti et celles n&#8217;ayant pas abouti.
</p>
<p>&#224; la grammaire est plus &#233;lev&#233;. En fait, l&#8217;&#233;tiquetage est plus pr&#233;cis donc plus rapide mais conduit
plus facilement &#224; une analyse non-conforme &#224; la grammaire s&#8217;il y a une ou plusieurs &#233;tiquettes
fausses. On obtient plus facilement une incoh&#233;rence vis-&#224;-vis de la grammaire.
</p>
<p>D&#8217;autre part, nous pr&#233;sentons dans la table 5 en tant que score de pr&#233;cision, les scores d&#8217;atta-
chement obtenus sur les analyses abouties. On y trouve le pourcentage d&#8217;unit&#233;s lexicales pour
lesquelles le bon gouverneur et la bonne &#233;tiquette ont &#233;t&#233; trouv&#233;s (LAS) et le taux d&#8217;unit&#233;s
lexicales pour lesquelles le bon gouverneur a &#233;t&#233; trouv&#233; (UAS). Encore une fois, nous pouvons
voir que plus large est le choix d&#8217;&#233;tiquettes en entr&#233;e plus les scores sont meilleurs. Ils at-
teignent globalement des taux &#233;lev&#233;s et sont quelques peu meilleurs dans le cas o&#249; l&#8217;on consid&#232;re
seulement l&#8217;exactitude du gouverneur. Lorsqu&#8217;on s&#8217;int&#233;resse aux d&#233;pendances discontinues, on
remarque que la pr&#233;cision sur ces d&#233;pendances est l&#233;g&#232;rement moins bonne que sur l&#8217;ensemble
des d&#233;pendances.
La diff&#233;rence de pr&#233;cision entre les analyses ayant re&#231;u des d&#233;pendances-t&#234;tes ou des groupes-
t&#234;tes est n&#233;gligeable sur l&#8217;ensemble des d&#233;pendances mais moins bonne sur les d&#233;pendances
discontinues dans le cas de la s&#233;lection des groupes-t&#234;tes. Cela peut s&#8217;expliquer par le fait que le
taux de d&#233;pendances discontinues est moins &#233;lev&#233; parmi les d&#233;pendances des analyses abouties
dans le cas de la s&#233;lection des d&#233;pendances-t&#234;tes 9. Les cas difficiles de d&#233;pendances discontinues
distantes sont &#233;cart&#233;s du calcul de la pr&#233;cision si la pr&#233;-s&#233;lection des t&#234;tes est non-conforme &#224; la
</p>
<p>9. On obtient de 4,3% &#224; 4,6% de d&#233;pendances discontinues parmis les d&#233;pendances des analyses abouties avec
s&#233;lection des d&#233;pendances-t&#234;tes pour 4,8% &#224; 4,9% avec la s&#233;lection des groupes-t&#234;tes.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>120 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>grammaire et engendre une mauvaise analyse. Nous avons vu que cette non-conformit&#233; est plus
facile &#224; atteindre avec la s&#233;lection des d&#233;pendances-t&#234;tes. Les scores sont donc moins bons avec
la s&#233;lection des groupes-t&#234;tes car plus d&#8217;analyse aboutissent sans forcement avoir r&#233;solu les cas
discontinus difficiles.
</p>
<p>Analyse autonome
Nb de
t&#234;tes
</p>
<p>Toutes d&#233;pendances D&#233;pendances discontinues
LAS UAS LAS UAS
</p>
<p>0 98.3 99.0 92.7 93.2
</p>
<p>Analyse avec s&#233;lection des d&#233;pendances-t&#234;tes
Nb de
t&#234;tes
</p>
<p>Toutes d&#233;pendances D&#233;pendances discontinues
LAS UAS LAS UAS
</p>
<p>1 93.7 96.7 92.4 93.7
1 &#224; 2 95.1 97.3 94.3 95.5
1 &#224; 5 96.2 97.8 94.4 95.5
1 &#224; 10 96.4 97.9 94.5 95.4
</p>
<p>Analyse avec s&#233;lection des groupes-t&#234;tes
Nb de
t&#234;tes
</p>
<p>Toutes d&#233;pendances D&#233;pendances discontinues
LAS UAS LAS UAS
</p>
<p>1 93.9 96.7 88.8 93.3
1 &#224; 2 95.1 97.2 90.0 93.7
1 &#224; 5 96.3 97.9 90.5 93.8
1 &#224; 10 96.7 98.0 91.1 94.3
</p>
<p>TABLE 5 &#8211; &#201;valuation de l&#8217;analyse autonome (sans pr&#233;-s&#233;lection des t&#234;tes) et de l&#8217;analyse avec pr&#233;-
s&#233;lection des d&#233;pendances-t&#234;tes et des groupes-t&#234;tes. Cette &#233;valuation est r&#233;alis&#233;e sur la meilleure
structure de d&#233;pendances produite par l&#8217;analyseur (i.e. la plus proche de la structure de d&#233;pendances
de r&#233;f&#233;rence) pour chaque analyse aboutie. Les scores d&#8217;attachement LAS et UAS correspondent
respectivement au score d&#8217;attachement avec d&#233;pendances &#233;tiquet&#233;es (Labeled Attachment Score) et
au score d&#8217;attachement avec d&#233;pendances non-&#233;tiquet&#233;es (Unlabeled Attachment Score). Ils sont
calcul&#233;s sur toutes les d&#233;pendances d&#8217;une part et sur les seules d&#233;pendances discontinues d&#8217;autre part,
en excluant les d&#233;pendances li&#233;es &#224; des signes de ponctuations dans les deux cas.
</p>
<p>4.3 Travaux reli&#233;s
</p>
<p>Plusieurs travaux ont d&#233;j&#224; mis en &#233;vidence l&#8217;utilit&#233; des m&#233;thodes de type supertagging sur l&#8217;analyse
syntaxique (Clark et Curran, 2004; Sarkar, 2010). Les r&#233;sultats de ces travaux sont difficiles
&#224; comparer avec d&#8217;autres pour plusieurs raisons. D&#8217;une part les fonctions syntaxiques utilis&#233;es
ici pour l&#8217;analyse en d&#233;pendances diff&#232;rent et sont plus nombreuses que dans les travaux o&#249;
les d&#233;pendances proviennent des t&#234;tes de constituants. De plus les d&#233;pendances discontinues
ne sont pas toujours prises en compte. D&#8217;autres part, l&#8217;analyse en d&#233;pendances n&#8217;est ici pas
totalement autonome en s&#8217;appuyant sur certains pr&#233;-requis. Nous pouvons tout de m&#234;me tenter
de rapprocher ces travaux d&#8217;autres t&#226;ches de supertagging pour l&#8217;anglais (Nasr et Rambow, 2004)
ou pour l&#8217;allemand (Foth et al., 2006). Les travaux les plus proches sont sans doute ceux de (Nasr
et Rambow, 2010) obtenant une pr&#233;cision de 85,7% pour l&#8217;anglais.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>121 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>5 Conclusion et travaux &#224; venir
</p>
<p>Les r&#233;sultats de l&#8217;analyse syntaxique en d&#233;pendances contrainte par la s&#233;lection des t&#234;tes refl&#232;te
d&#8217;une r&#233;elle utilit&#233; de cette s&#233;lection automatique. Dans un premier temps, la s&#233;lection des
d&#233;pendances-t&#234;tes ou des groupes-t&#234;tes en amont de l&#8217;analyse en d&#233;pendances permet de r&#233;duire
de mani&#232;re significative le temps d&#8217;analyse. De nombreuses phrases, d&#8217;une longueur cons&#233;quente,
ne permettant pas d&#8217;aboutir &#224; une analyse autonome peuvent &#234;tre finalement analys&#233;es gr&#226;ce &#224;
la s&#233;lection des t&#234;tes. Ce facteur est tr&#232;s important pour atteindre des taux de r&#233;ussite (analyses
abouties) int&#233;ressant et donc des r&#233;sultats r&#233;ellement exploitables. Par ailleurs, en &#233;tiquetant
syntaxiquement les unit&#233;s lexicales des phrases de 1 &#224; 10 &#233;tiquettes diff&#233;rentes, on obtient un
bon score en pr&#233;cision. Il nous indique que parmi les structures de d&#233;pendances produites par
l&#8217;analyseur du CDG Lab, on obtient tr&#232;s souvent la bonne structure de d&#233;pendances pour une
phrase donn&#233;e.
Cependant, nous supposons ici avoir un bon d&#233;coupage des phrases en unit&#233;s lexicales et un bon
&#233;tiquetage en entr&#233;e ainsi qu&#8217;un tri des structures de d&#233;pendances en sortie qui s&#8217;appuie sur la
structure de d&#233;pendances de r&#233;f&#233;rence. Dans l&#8217;id&#233;e de mettre en place un analyseur totalement
autonome, nous souhaitons, par la suite, faire de ces &#233;tapes des t&#226;ches automatiques. Nous
avons donc l&#8217;intention d&#8217;ajouter une &#233;tape de d&#233;coupage des unit&#233;s lexicales et d&#8217;&#233;tiquetage
grammatical de ces unit&#233;s en amont de l&#8217;&#233;tiquetage syntaxique pr&#233;sent&#233; dans cet article. Puis
nous appliquerons une m&#233;thode de tri automatique des structures de d&#233;pendances en sortie de
l&#8217;analyseur permettant de trouver la structure de d&#233;pendances la plus proche de la structure de
r&#233;f&#233;rence sans s&#8217;y &#234;tre r&#233;f&#233;r&#233;.
En outre, notons que le taux d&#8217;analyse non abouties car l&#8217;&#233;tiquetage &#233;tait non-conforme avec la
grammaire varie de 6 &#224; 35% du meilleur au pire des cas. Un mauvais &#233;tiquetage local peut &#234;tre la
cause de cette non-conformit&#233;. Cependant le score g&#233;n&#233;ral d&#8217;&#233;tiquetage &#233;tant bon (le meilleur est
de 97.1 en rappel pour 10 choix d&#8217;&#233;tiquettes), il est &#233;vident que la majorit&#233; des &#233;tiquettes pour
une phrase donn&#233;e sont correctes et permettraient d&#8217;obtenir une (ou plusieurs) sous-structure(s)
de d&#233;pendances correcte(s) pour cette phrase. L&#8217;&#233;volution de l&#8217;analyseur du CDG Lab ira dans ce
sens : permettre &#224; l&#8217;analyseur de produire des structures de d&#233;pendances partielles lorsque la
s&#233;lection des t&#234;tes n&#8217;est pas totalement conforme avec la grammaire. La solution partielle pourra
ensuite &#234;tre compl&#233;t&#233;e en appliquant une analyse par approximation. Le nombre de structures
de d&#233;pendances analys&#233;es augmentera et cela permettra d&#8217;obtenir de meilleurs taux d&#8217;analyses
abouties.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ALFARED, R., B&#201;CHET, D. et DIKOVSKY, A. (2011). &#8220;CDG Lab&#8221; : a Toolbox for Dependency
Grammars and Dependency Treebanks Development. In Proceedings of DEPLING 2011, pages
272&#8211;281.
</p>
<p>BANGALORE, S. et JOSHI, A., &#233;diteurs (2010a). Complexity of Lexical Descriptions and its Relevance
to Natural Language Processing : A Supertagging Approach. MIT Press.
BANGALORE, S. et JOSHI, A. K. (2010b). Supertagging : Using Complex Lexical Descriptions in
Natural Language Processing. Mit Press.
BAR-HILLEL, Y., GAIFMAN, C. et SHAMIR, E. (1964). On Categorial and Phrase Structure Grammars.
In Language and information, pages 99&#8211;115. Addison-Wesley.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>122 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>B&#201;CHET, D., DIKOVSKY, A. et FORET, A. (2005). Dependency structure grammar. In Proceedings of
LACL 2005, pages 18&#8211;34.
</p>
<p>CANDITO, M., CRABB&#201;, B. et DENIS, P. (2010). Statistical french dependency parsing : treebank
conversion and first results. In Proceedings of LREC 2010, pages 1840&#8211;1847.
</p>
<p>CLARK, S. et CURRAN, J. R. (2004). The importance of supertagging for wide-coverage ccg
parsing. In Proceedings of COLING 2004, pages 282&#8211;288.
</p>
<p>DEKHTYAR, M. et DIKOVSKY, A. (2004). Categorial dependency grammars. In Proceedings of
Intern. Conf. on Categorial Grammars, pages 76&#8211;91.
</p>
<p>DEKHTYAR, M. et DIKOVSKY, A. (2008). Generalized categorial dependency grammars. In
Trakhtenbrot/Festschrift, LNCS 4800, pages 230&#8211;255. Springer.
DEKHTYAR, M., DIKOVSKY, A. et KARLOV, B. (2012). Iterated dependencies and kleene iteration.
In Formal Grammar 2010/2011, LNCS 7395, pages 66&#8211;81.
DIKOVSKY, A. (2004). Dependencies as categories. In Proceedings of COLING 2004 Workshop,
&quot;Recent Advances in Dependency Grammars&quot;, pages 90&#8211;97.
</p>
<p>DIKOVSKY, A. (2011). Categorial dependency grammars : from theory to large scale grammars.
In DEPLING 2011.
</p>
<p>FOTH, K., BY, T. et MENZEL, W. (2006). Guiding a constraint dependency parser with supertags.
In Proceedings of COLING 2006, pages 289&#8211;296.
</p>
<p>LAFFERTY, J., MCCALLUM, A. et PEREIRA, F. (2001). Conditional random fields : Probabilistic
models for segmenting and labeling sequence data. In Proceedings of ICML 2001.
</p>
<p>LAVERGNE, T., CAPP&#201;, O. et YVON, F. (2010). Practical very large scale CRFs. In ACL 2010.
</p>
<p>MEL&#8217;CUK, I. (1988). Dependency syntax : Theory and Practice. State University of New York Press.
</p>
<p>NASR, A. (2006). Grammaires de d&#233;pendances g&#233;n&#233;ratives probabilistes. mod&#232;le th&#233;orique et
application &#224; un corpus arbor&#233; du fran&#231;ais. Traitement Automatique des Langues, 46(1):115&#8211;153.
</p>
<p>NASR, A. et RAMBOW, O. (2004). Supertagging and full parsing. In Proceedings of TAG+7.
NASR, A. et RAMBOW, O. (2010). Non-lexical chart parsing for tag. In (Bangalore et Joshi,
2010a).
</p>
<p>RABINER, L. R. (1989). A tutorial on hidden markov models and selected applications in speech
recognition. In Proceedings of IEEE 1989.
</p>
<p>RATNAPARKHI, A. (1996). A maximum entropy model for part-of-speech tagging. In Proceedings
of EMNLP 1996.
</p>
<p>SAGOT, B. (2010). The Lefff, a freely available and large-coverage morphological and syntactic
lexicon for French. In Proceedings of LREC 2010.
</p>
<p>SARKAR, A. (2010). Combining supertagging and lexicalized tree-adjoining grammar parsing. In
(Bangalore et Joshi, 2010a).
</p>
<p>SUTTON, C. et MCCALLUM, A. (2006). An introduction to conditional random fields for relational
learning. In Introduction to Statistical Relational Learning. MIT Press.
</p>
<p>TESNI&#200;RE, L. (1959). &#201;l&#233;ments de syntaxe structurale. Klincksieck.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>123 c&#65535; ATALA</p>

</div></div>
</body></html>