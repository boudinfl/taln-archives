TALN-RÃ‰CITAL 2013, 17-21 Juin, Les Sables dâ€™Olonne
Influence de lâ€™Ã©tiquetage syntaxique des tÃªtes sur lâ€™analyse en
dÃ©pendances discontinues du franÃ§ais
OphÃ©lie Lacroix1
(1) LINA - UniversitÃ© de Nantes, 2 Rue de la HoussiniÃ¨re, 44322 Nantes Cedex 3
RÃ‰SUMÃ‰
Dans cet article nous souhaitons mettre en Ã©vidence lâ€™utilitÃ© dâ€™un Ã©tiquetage syntaxique appliquÃ©
en amont dâ€™une analyse syntaxique en dÃ©pendances. Les rÃ¨gles de la grammaire catÃ©gorielle
de dÃ©pendances du franÃ§ais utilisÃ©es pour lâ€™analyse gÃ¨rent les dÃ©pendances discontinues et
les relations syntaxiques Ã  longue distance. Une telle mÃ©thode dâ€™analyse gÃ©nÃ¨re un nombre
consÃ©quent de structures de dÃ©pendances et emploie un temps dâ€™analyse trop important. Nous
voulons alors montrer quâ€™une mÃ©thode locale dâ€™Ã©tiquetage peut diminuer lâ€™ampleur de ces
difficultÃ©s et par la suite aider Ã  rÃ©soudre le problÃ¨me global de dÃ©sambiguÃ¯sation dâ€™analyse en
dÃ©pendances. Nous adaptons alors une mÃ©thode dâ€™Ã©tiquetage aux catÃ©gories de la grammaire
catÃ©gorielle de dÃ©pendance. Nous obtenons ainsi une prÃ©-sÃ©lection des tÃªtes des dÃ©pendances
permettant de rÃ©duire lâ€™ambiguÃ¯tÃ© de lâ€™analyse et de voir que les rÃ©sultats locaux dâ€™une telle
mÃ©thode permettent de trouver des relations distantes de dÃ©pendances.
ABSTRACT
On the Effect of Head Tagging on Parsing Discontinuous Dependencies in French
In this paper we want to show the strong impact of syntactic tagging on syntactic dependency
parsing. The rules of categorial dependency grammar used to parse French deal with discon-
tinuous dependencies and long distance syntactic relations. Such parsing method produces a
substantial number of dependency structures and takes too much parsing time. We want to show
that a local tagging method can reduce these problems and help to solve the global problem of
dependency parsing disambiguation. Then we adapt a tagging method to types of the categorial
dependency grammar. We obtain a dependency-head pre-selection allowing to reduce parsing
ambiguity and to see that we can find distant relation of dependencies through local results of
such method.
MOTS-CLÃ‰S : Analyse syntaxique en dÃ©pendances discontinues, Ã‰tiquetage syntaxique.
KEYWORDS: Discontinuous Dependency Parsing, Syntactic Tagging.
110 ï¿¿c ATALA
TALN-RÃ‰CITAL 2013, 17-21 Juin, Les Sables dâ€™Olonne
1 Introduction
Lâ€™analyse syntaxique est une tÃ¢che bien connue dans le domaine du traitement automatique du
langage naturel, permettant dâ€™obtenir des structures syntaxiques Ã  partir de phrases du langage
naturel. On oppose couramment les reprÃ©sentations syntaxiques des structures par consituants et
des structures en dÃ©pendances. Ici, nous nous intÃ©ressons particuliÃ¨rement Ã  la reprÃ©sentation en
dÃ©pendances de ces structures (TesniÃ¨re, 1959; Melâ€™cuk, 1988). En utilisant cette reprÃ©sentation,
nous souhaitons exprimer correctement les relations syntaxiques existantes entre les mots dâ€™une
phrase. Ces relations sont des relations binaires (dÃ©pendances) entre un gouverneur g et un
d
subordonnÃ© s oÃ¹ le type de dÃ©pendance d est la fonction syntaxique existante entre g et s (g âˆ’â†’ s).
Une telle dÃ©pendance est projective si chaque mot dans lâ€™intervalle [g,s] dÃ©pend de g (sinon
elle est discontinue). Le type de dÃ©pendance d est aussi la dÃ©pendance-tÃªte 1 du subordonnÃ©
s. Notre travail se situe au niveau de lâ€™analyse syntaxique en dÃ©pendances pour le franÃ§ais. Or
cette langue admet des cas de discontinuitÃ© Ã  travers des relations de longue distance comme la
corÃ©fÃ©rence (voir figure 1) ou la comparaison ou des relations locales frÃ©quentes, par exemple de
nÃ©gation ou de clitique. Nous avons choisi une mÃ©thode dâ€™analyse guidÃ©e par les rÃ¨gles dâ€™une




 
   
  

  	    

    	
     
  
 
   
  
	 
FIGURE 1 â€“ Structure de dÃ©pendances pour la phrase "Il y a si longtemps quâ€™il nâ€™a ressenti une telle
solitude que câ€™est un vertige.". Les dÃ©pendances projectives sont reprÃ©sentÃ©es par des lignes plaines
tandis que les dÃ©pendances discontinues sont reprÃ©sentÃ©es par des lignes pointillÃ©es. Les types des
dÃ©pendances sont les types utilisÃ©s par une grammaire catÃ©gorielle de dÃ©pendances du franÃ§ais.
grammaire permettant dâ€™obtenir des structures de dÃ©pendances projectives et des structures de
dÃ©pendances discontinues 2. Le modÃ¨le de grammaire catÃ©gorielle de dÃ©pendances (Dikovsky,
2004; BÃ©chet et al., 2005; Dekhtyar et Dikovsky, 2008; Dekhtyar et al., 2012) Ã©tend la gestion
des dÃ©pendances aux dÃ©pendances discontinues et est donc tout Ã  fait adaptÃ©e Ã  la reprÃ©sentation
syntaxique en dÃ©pendances de phrases du franÃ§ais. Le CDG Lab (Alfared et al., 2011) est un
outil, destinÃ© Ã  lâ€™analyse syntaxique avec des grammaires catÃ©gorielles de dÃ©pendances et au
dÃ©veloppement de corpus arborÃ©s en dÃ©pendances. Il propose trois modes dâ€™analyses diffÃ©rents
que nous redÃ©finirons par la suite. Le mode nous intÃ©ressant ici est le mode semi-automatique de
sÃ©lection des tÃªtes. Dans ce mode, un utilisateur souhaitant procÃ©der Ã  une analyse syntaxique en
1. La dÃ©pendance-tÃªte est le type de la dÃ©pendance arrivant sur le subordonnÃ©.
2. Une structure de dÃ©pendances discontinue est une structure dans laquelle on trouve au moins une dÃ©pendance
discontinue. Dans ces structures les dÃ©pendances peuvent se croiser. Par exemple, les clitiques engendrent des dÃ©pendances
discontinues dÃ¨s lors quâ€™une forme composÃ©e verbale est employÃ©e, sÃ©parant le verbe et son objet cliticisÃ©. La nÃ©gation
produit frÃ©quemment une discontinuitÃ© puisquâ€™elle est communÃ©ment composÃ© de deux particules, parfois distantes
("Ne ... que"), parfois inversÃ©s ("Jamais ... ne"). Par ailleurs, la relation de corÃ©fÃ©rence (figure 1) est intraphrasale, elle
correspond Ã  la co-prÃ©dication dÃ©finie par (Melâ€™cuk, 1988).
111 ï¿¿c ATALA
TALN-RÃ‰CITAL 2013, 17-21 Juin, Les Sables dâ€™Olonne
dÃ©pendances pourra sÃ©lectionner manuellement les dÃ©pendances-tÃªtes. Cette sÃ©lection des tÃªtes
en amont de lâ€™analyse syntaxique amÃ©liore grandement la vitesse dâ€™analyse par rapport Ã  une
analyse automatique Ã  partir des phrases brutes du franÃ§ais. Nous souhaitons donc remplacer,
pour notre travail, cette sÃ©lection des tÃªtes manuelles par une sÃ©lection automatique. Cette tÃ¢che
est similaire Ã  celle dâ€™Ã©tiquetage grammaticale ou dâ€™Ã©tiquetage morphosyntaxique. Lâ€™idÃ©e dâ€™utiliser
un prÃ©-Ã©tiquetage pour rÃ©duire lâ€™ambiguÃ¯tÃ© et amÃ©liorer une analyse syntaxique en dÃ©pendances Ã 
dÃ©jÃ  Ã©tÃ© exploitÃ©e dans ce cadre (Nasr, 2006; Candito et al., 2010). Ici, nous souhaitons mettre en
place un procÃ©dÃ© de type supertagging (Bangalore et Joshi, 2010b). La sÃ©lection des tÃªtes est en
fait un Ã©tiquetage syntaxique des unitÃ©s lexicales des phrases du franÃ§ais adaptÃ© Ã  la grammaire
catÃ©gorielle de dÃ©pendance du franÃ§ais utilisÃ©e pour lâ€™analyse en dÃ©pendance. Il ne sâ€™agit donc pas
dâ€™apporter des informations grammaticales ou morphosyntaxiques (propres aux unitÃ©s lexicales)
Ã  lâ€™analyseur mais bien dâ€™apporter des informations syntaxiques qui dÃ©finissent des fonctions
binaires entre unitÃ©s lexicales. La difficultÃ© est alors de trouver les bonnes Ã©tiquettes syntaxiques
de maniÃ¨re locale, avec des informations locales, bien que la fonction syntaxique auquelle
lâ€™Ã©tiquette rÃ©fÃ¨re concerne deux unitÃ©s lexicales potentiellement distantes. Nous procÃ©derons
alors dans un premier temps Ã  cet Ã©tiquetage syntaxique en utilisant la mÃ©thode des CRF 3
adaptÃ©e aux types de dÃ©pendances de la grammaire catÃ©gorielle de dÃ©pendances du franÃ§ais.
Nous essayons ici dâ€™utiliser une mÃ©thode locale pour rÃ©soudre un problÃ¨me global. Il sâ€™agit de
la principale difficultÃ© de cette mÃ©thode. Nous souhaitons donc voir si elle permettra dâ€™obtenir
les bonnes dÃ©pendances-tÃªtes. Puis nous exÃ©cuterons lâ€™analyse en dÃ©pendances sur les phrases
ainsi Ã©tiquetÃ©es pour constater lâ€™effet positif de cet Ã©tiquetage sur le temps dâ€™analyse et sur la
production (les structures de dÃ©pendances sortantes) de lâ€™analyseur. Pour conclure, nous nous
questionnerons sur la place de cette mÃ©thode dans une analyse totalement autonome. Est-elle
suffisante vis-Ã -vis des rÃ©sultats obtenus ou peut-elle Ãªtre associÃ©e Ã  dâ€™autres procÃ©dÃ©s permettant
de combler les imperfections de celle-ci ?
Ce travail sâ€™inscrit dans un travail de plus grande envergure qui comprendra un travail de
dÃ©coupage des phrases en unitÃ©s lexicales, ainsi que leur Ã©tiquetage grammaticale, un travail
dâ€™Ã©tiquetage syntaxique prÃ©cÃ©dant celui dâ€™analyse syntaxique en dÃ©pendances, puis finira par un
travail concernant le tri des structures de dÃ©pendances en sortie de lâ€™analyseur. Ici nous nous
intÃ©ressons en particulier Ã  lâ€™Ã©tiquetage syntaxique. Nous supposons donc avoir en entrÃ©e un bon
dÃ©coupage des phrases en unitÃ©s lexicales composÃ©es ainsi quâ€™un bon Ã©tiquetage grammatical de
ces unitÃ©s.
2 Grammaires catÃ©gorielles de dÃ©pendances
Le modÃ¨le de grammaires catÃ©gorielles de dÃ©pendances est un modÃ¨le de grammaires similaire
aux grammaires catÃ©gorielles classiques (Bar-Hillel et al., 1964) auxquelles est ajoutÃ©e la notion
de valence polarisÃ©e permettant dâ€™introduire les dÃ©pendances discontinues. Dans ce modÃ¨le,
les catÃ©gories sont des types de dÃ©pendances et permettent de reprÃ©senter les dÃ©pendances
projectives tandis que les valences polarisÃ©es sont des types de dÃ©pendances associÃ©es Ã  des
polaritÃ©s duales (ï¿¿ï¿¿et ï¿¿ï¿¿) permettant de reprÃ©senter les dÃ©pendances discontinues (voir
(Dekhtyar et Dikovsky, 2008)). Les rÃ¨gles utilisÃ©es par cette classe de grammaires sont prÃ©sentÃ©es
dans la figure 1. Les structures de dÃ©pendances produites Ã  lâ€™aide de ces grammaires sont alors
des graphes orientÃ©s acycliques.
3. Conditional Random Fields en anglais ou champs markovien conditionnels en franÃ§ais.
112 ï¿¿c ATALA
TALN-RÃ‰CITAL 2013, 17-2ï¿¿1 Juin, Les Sables dâ€™Olonne
L1 CP1 C\ ï¿¿P ï¿¿Î² 2 ï¿¿ ï¿¿ PÎ² 1P2
I1 CP
ï¿¿
1 Câˆ—\ ï¿¿PÎ² 2 ï¿¿ ï¿¿Câˆ—\ ï¿¿PÎ² 1P2
Î©1
ï¿¿
Câˆ—\ ï¿¿PÎ² ï¿¿ ï¿¿ ï¿¿PÎ²
D1 Î±P1(ï¿¿C)P(ï¿¿C)P2 ï¿¿ Î±P1PP2 , si (ï¿¿ C)(ï¿¿ C) satisfait le principe FA
TABLE 1 â€“ RÃ¨gles gauches des grammaires catÃ©gorielles de dÃ©pendances. Des rÃ¨gles symÃ©triques sont
utilisÃ©es dans le cas des dÃ©rivations Ã  droite. Les rÃ¨gles L, I et Î© permettent dâ€™Ã©liminer les catÃ©gories
classiques et les catÃ©gories itÃ©rables (i.e. dÃ©rivables infiniement), et de concatÃ©ner ou conserver
les valences polarisÃ©es en une chaÃ®ne que lâ€™on appelle potentiel. Lâ€™Ã©limination des valences dans la
dÃ©rivation (rÃ¨gle D) se fait sur le principe FA (First Available) : les valences duales les plus proches
dans un potentiel sont Ã©liminÃ©es en premier.
2.1 DonnÃ©es de la grammaire catÃ©gorielle de dÃ©pendances du franÃ§ais
Pour notre travail, nous utiliserons une grammaire catÃ©gorielle de dÃ©pendances du franÃ§ais
(Dikovsky, 2011). Elle est constituÃ©e dâ€™un ensemble consÃ©quent de rÃ¨gles elles-mÃªmes composÃ©es
de types de dÃ©pendances (les catÃ©gories de la grammaire). Ces types de dÃ©pendances, 117 au
total, reprÃ©sentent un vaste champ de fonctions syntaxiques exprimant les particularitÃ©s du
franÃ§ais. Ces nombreux types de dÃ©pendances sont rassemblÃ©s en 39 groupes de dÃ©pendances
selon leurs fonctions syntaxiques. Par exemple, les dÃ©pendances de type objet accusatif (a-obj),
objet datif (d-obj), objet gÃ©nitif (g-obj) sont rÃ©unies dans le groupe des objets : OBJ. Par ailleurs,
les types de dÃ©pendances peuvent Ãªtre associÃ©s Ã  des dÃ©pendances discontinues, on en compte 27.
Parmi les types associÃ©s aux dÃ©pendances discontinues on trouve ceux appartenant aux groupes
des clitiques (CLIT), des modifieurs (MODIF), des rÃ©flexifs (REFLEX), des corÃ©fÃ©rences (COREF)
et appositions (APPOS), des Ã©lÃ©ments de nÃ©gation (NEG), des aggrÃ©gations (AGRR), etc.
En outre, les rÃ¨gles de la grammaire sont associÃ©es Ã  des classes grammaticales. Lors dâ€™une
analyse, avec le choix des rÃ¨gles se fait le choix de ces classes grammaticales et des traits
morphologiques des unitÃ©s lexicales Ã©tablies en fonction des valeurs des traits employÃ©s par le
Lefff 4 (Sagot, 2010). On dÃ©nombre 185 classes grammaticales.
2.2 CDG Lab : Analyseur en dÃ©pendances
Le CDG Lab (Alfared et al., 2011) est un outil de travail dÃ©diÃ© Ã  lâ€™analyse en dÃ©pendances guidÃ©e
par les rÃ¨gles de grammaires catÃ©gorielles de dÃ©pendances. Lâ€™analyseur en dÃ©pendances du CDG
Lab propose 3 modes dâ€™analyse diffÃ©rents mais complÃ©mentaires :
â€“ lâ€™analyse autonome est un mode permettant de lancer lâ€™analyse Ã  partir dâ€™une phrase du franÃ§ais
sans indiquer manuellement dâ€™informations complÃ©mentaires. La phrase est donc dÃ©coupÃ©e
en mots qui sont eux-mÃªmes rÃ©associÃ©s en unitÃ©s lexicales possibles 5. Lâ€™analyse (basÃ©e sur un
algorithme CYK modifiÃ©) est alors exÃ©cutÃ©e Ã  partir de ce dÃ©coupage.
â€“ lâ€™analyse par sÃ©lection des tÃªtes est un mode semi-automatique. Avant de procÃ©der Ã  lâ€™analyse,
lâ€™utilisateur Ã  la possibilitÃ© de choisir les bonnes unitÃ©s lexicales, leurs classes grammaticales et
leurs dÃ©pendances-tÃªtes. Lâ€™analyse peut ensuite Ãªtre lancÃ©e en tenant compte de ces choix.
4. Lexique des formes flÃ©chies du franÃ§ais.
5. BasÃ©es sur Lefff (Sagot, 2010).
113 ï¿¿c ATALA
TALN-RÃ‰CITAL 2013, 17-21 Juin, Les Sables dâ€™Olonne
â€“ lâ€™analyse par approximation sâ€™effectue Ã  la suite dâ€™une analyse automatique ou dâ€™une analyse
par sÃ©lection des tÃªtes. Elle permet dâ€™annoter positivement ou nÃ©gativement les attributions des
classes grammaticales et/ou des types de dÃ©pendances. AppliquÃ© autant de fois que nÃ©cessaire,
ce mode permet de raffiner la production de lâ€™analyse : la(les) structure(s) de dÃ©pendances
rÃ©sultante(s).
Le mode qui nous intÃ©resse ici est celui de la sÃ©lection des tÃªtes en amont de lâ€™analyse syntaxique
en dÃ©pendances. Nous savons que choisir manuellement les dÃ©pendances-tÃªtes dâ€™une phrase
avant analyse permet de rÃ©duire lâ€™ambiguÃ¯tÃ© en faisant converger lâ€™analyse vers un ensemble de
solutions plus restreint. Les avantages se remarquent au niveau du temps de calcul de lâ€™analyse et
au niveau de la production de lâ€™analyseur, celui-ci produisant moins de structures de dÃ©pendances
en sortie. Notons que la sÃ©lection des tÃªtes peut se faire au niveau des types de dÃ©pendances ou
des groupes de dÃ©pendances. On appellera alors respectivement : dÃ©pendance-tÃªte ou groupe-
tÃªte, le type ou le groupe de dÃ©pendances sÃ©lectionnÃ© pour une unitÃ© lexicale. Nous souhaitons
donc remplacer la sÃ©lection manuelle des tÃªtes par une sÃ©lection automatique et comprendre
lâ€™apport rÃ©el de cette tÃ¢che avec un algorithme standard dâ€™apprentissage.
2.3 Corpus en dÃ©pendances, donnÃ©es grammaticales et syntaxiques
Le corpus que nous utiliserons pour nos expÃ©rimentations a Ã©tÃ© annotÃ© en dÃ©pendances semi-
automatiquement grÃ¢ce Ã  lâ€™outil CDG Lab. Il est composÃ© de 2778 structures de dÃ©pendances
associÃ©es Ã  des phrases du franÃ§ais provenant de registres variÃ©s et comprenant au total 35203
unitÃ©s lexicales composÃ©es. Les dÃ©pendances discontinues reprÃ©sentent 4% du nombre total de
dÃ©pendances du corpus et elles sont prÃ©sentes (au moins une fois) dans 41% des structures de
dÃ©pendances.
Les types de dÃ©pendances utilisÃ©s dans la reprÃ©sentation de ces structures correspondent aux types
de la grammaire catÃ©gorielle de dÃ©pendances du franÃ§ais. De plus, chaque unitÃ© lexicale dans
le corpus est annotÃ©e correctement par une classe grammaticale. Pour procÃ©der Ã  lâ€™Ã©tiquetage
syntaxique les donnÃ©es utilisÃ©es seront :
â€“ les unitÃ©s lexicales composÃ©es
â€“ les dÃ©pendances-tÃªtes (ou groupes-tÃªtes)
â€“ les classes grammaticales
Le nombre de classes grammaticales Ã©tant important, nous dÃ©cidons de sous-catÃ©goriser ces
classes pour arriver Ã  deux formes de sous-classification : les classes grammaticales simples (28
classes) et les classes grammaticales Ã©tendues (86 classes). Une classe grammaticale simple
indique la classe grammaticale dâ€™une unitÃ© lexicale sans autre information tandis quâ€™une classe
grammaticale Ã©tendue ajoute des informations (parfois sÃ©mantiques) potentiellement utiles
syntaxiquement. Les classes grammaticales Ã©tendues, plus prÃ©cises, permettent de mieux cibler
les types et groupes de dÃ©pendances comme exposÃ© dans la table 2.
Nombre moyen de types (max.) groupes (max.)
Par classe simple 13 (43) 7 (18)
grammaticale Ã©tendue 6 (31) 4 (16)
TABLE 2 â€“ Nombre moyen (et maximum) de types et groupes de dÃ©pendances possibles par classe
grammaticale simple ou Ã©tendue.
114 ï¿¿c ATALA
TALN-RÃ‰CITAL 2013, 17-21 Juin, Les Sables dâ€™Olonne
Un exemple, regroupant les donnÃ©es par groupe/type de dÃ©pendances et par classe grammaticale
simple et Ã©tendue, est donnÃ© par la figure 2.
	
 
	

  
 
  	 
    
UnitÃ© DÃ©pendance-tÃªte Classe grammaticale
lexicale type groupe simple Ã©tendue
Il pred PRED PN PN-pers-n
boit S SENT Vt Vt-fin
moins compar COMPAR Adv Adv-degr-compar
dâ€™ det-p DET Det Det
eau a-obj OBJ N N
quâ€™ dist-rel REL Conj Conj-comp
avant conj-que CONJ Adv Adv
. fs PUNCT FullStop FullStop
FIGURE 2 â€“ Structure de dÃ©pendances et tableau rapportant les dÃ©pendances-tÃªtes, les groupes-tÃªtes,
les classes grammaticales simples et les classes grammaticales Ã©tendues de chaque unitÃ© lexicale de la
phrase "Il boit moins dâ€™eau quâ€™avant." Les classes grammaticales Ã©tendues ajoutent des informations
en plus de la classe. Par exemple, Adv-degr-compar et Conj-comp indique un adverbe et une
conjonction qui sont tous deux impliquÃ©s dans une comparaison. Pour ce travail, nous nâ€™avons pas
utilisÃ© les traits de Lefff.
3 Ã‰tiquetage syntaxique
Le problÃ¨me de lâ€™Ã©tiquetage est un problÃ¨me largement Ã©tudiÃ© dans le domaine du traitement
automatique de la langue naturelle. Les tÃ¢ches dâ€™Ã©tiquetage grammatical ou morphosyntaxique
sont les plus rÃ©pandues mais diffÃ¨rent de lâ€™Ã©tiquetage syntaxique. NÃ©anmoins les outils restent
les mÃªmes. Parmi les mÃ©thodes existantes pour accomplir la tÃ¢che dâ€™Ã©tiquetage syntaxique on
trouvera, les modÃ¨les graphiques probabilistes tels que les modÃ¨les de Markov cachÃ©s (HMM)
(Rabiner, 1989), les modÃ¨les dâ€™entropie maximale (MEMM) (Ratnaparkhi, 1996) et les champs
markoviens conditionnels (CRF) (Sutton et McCallum, 2006; Lafferty et al., 2001). Pour notre
travail, nous avons choisi dâ€™utiliser ces derniers car ils permettent de prendre en compte plus
dâ€™informations que les HMM et quâ€™ils sont bien adaptÃ©s Ã  lâ€™attribution de sÃ©quences dâ€™Ã©tiquettes
alors que les MEMM sont plus performants pour la classification.
3.1 Logiciel et patrons de traits
Nous avons choisi le logiciel Wapiti (Lavergne et al., 2010) pour entraÃ®ner un modÃ¨le et Ã©tiqueter
syntaxiquement notre corpus car il est capable de travailler avec un grand nombre dâ€™Ã©tiquettes .
Il utilise les CRF pour cet entraÃ®nement et attribue donc des poids Ã  des traits choisis. Ces traits
peuvent Ãªtre extraits Ã  partir de patrons de traits dÃ©finis Ã  lâ€™avance. Le logiciel nous laisse la
115 ï¿¿c ATALA
TALN-RÃ‰CITAL 2013, 17-21 Juin, Les Sables dâ€™Olonne
possibilitÃ© de lui fournir des patrons de traits modifiables que nous avons testÃ©s.
Comme indiquÃ© dans la partie 2.3, chaque phrase du corpus est dÃ©composÃ©e en unitÃ©s lexicales
elles-mÃªmes Ã©tiquetÃ©es grammaticalement (par des classes grammaticales simples ou Ã©tendues
selon le choix dâ€™expÃ©rimentation). Nous disposons donc de ces informations. Nous pouvons
choisir une largeur de fenÃªtre (appliquÃ©e autour dâ€™une unitÃ© lexicale) pour indiquer si lâ€™on
tient compte des unitÃ©s lexicales et des classes grammaticales prÃ©cÃ©dentes et suivantes lors de
lâ€™assignation dâ€™une Ã©tiquette syntaxique. Nous constatons quâ€™une fenÃªtre de 5 (2 mots avant, 2
mots aprÃ¨s) donne de bons rÃ©sultats, quâ€™Ã©largir la fenÃªtre Ã  7 pour les unitÃ©s lexicales gÃ©nÃ¨re
beaucoup de traits pour peu dâ€™amÃ©liorations mais quâ€™Ã©largir la fenÃªtre Ã  7 autour des classes
grammaticales est beaucoup plus efficace. Il est aussi intÃ©ressant dâ€™associer unitÃ© lexicale et classe
grammaticale dans un mÃªme trait. Les premiers patrons de traits choisis sont les suivants :
UnitÃ© lexicale courante
UnitÃ© lexicale prÃ©cedente de 1
UnitÃ© lexicale prÃ©cedente de 2
UnitÃ© lexicale suivante de 1
UnitÃ© lexicale suivante de 2
Classe grammaticale de lâ€™unitÃ© lexicale courante
Classe grammaticale de lâ€™unitÃ© lexicale prÃ©cedente de 1
Classe grammaticale de lâ€™unitÃ© lexicale prÃ©cedente de 2
Classe grammaticale de lâ€™unitÃ© lexicale prÃ©cedente de 3
Classe grammaticale de lâ€™unitÃ© lexicale suivante de 1
Classe grammaticale de lâ€™unitÃ© lexicale suivante de 2
Classe grammaticale de lâ€™unitÃ© lexicale suivante de 3
UnitÃ© lexicale courante et sa classe grammaticale
Nous testons aussi quelques traits comme lâ€™extraction du suffixe des unitÃ©s lexicales (testÃ© pour 2,
3 ou 4 lettres) et le fait de savoir si une unitÃ© lexicale commence par une majuscule et retenons
les suivants :
Suffixe de 3 lettres de lâ€™unitÃ© lexicale courante
Lâ€™unitÃ© lexicale prÃ©cÃ©dente commence-t-elle par une majuscule ?
Notons ici que les traits choisis sont toujours des traits unigrammes, les traits bigrammes gÃ©nÃ©rant
trop de traits non pertinants. Cependant, pour chaque trait unigramme, la probabilitÃ© quâ€™il
apparaÃ®sse avec chacune des Ã©tiquettes possibles est calculÃ©e lors de lâ€™apprentissage. Lâ€™ensemble de
ces patrons de traits gÃ©nÃ¨re alors plus dâ€™un million 6 de traits pour chaque modÃ¨le dâ€™apprentissage
et permet dâ€™obtenir de bons rÃ©sultats dâ€™Ã©tiquetage prÃ©cisÃ©s dans la section suivante.
3.2 ExpÃ©rimentations et Ã‰valuation
Pour procÃ©der Ã  lâ€™Ã©tiquetage syntaxique nous avons divisÃ© le corpus (voir section 2.3) en 10
parties Ã©gales. Chaque partie est Ã©tiquetÃ©e selon un modÃ¨le entraÃ®nÃ© sur les 9 autres parties.
Lâ€™entraÃ®nement se fait sur des donnÃ©es parfaitement Ã©tiquetÃ©es grammaticalement et syntaxi-
quement. La possibilitÃ© de choisir des donnÃ©es plus ou moins informatives (classe grammaticale
simple ou Ã©tendue ; dÃ©pendance-tÃªte ou groupe-tÃªte) permet de rÃ©aliser 4 expÃ©rimentations
6. Lâ€™ensemble des patrons de traits gÃ©nÃ¨re, au pire, plus de 32000 traits unigrammes diffÃ©rents qui associÃ©s aux
diffÃ©rentes possibilitÃ©s dâ€™Ã©tiquettes (au maximum 117 pour les types) produit jusquâ€™Ã  3,7 millions de traits.
116 ï¿¿c ATALA
TALN-RÃ‰CITAL 2013, 17-21 Juin, Les Sables dâ€™Olonne
diffÃ©rentes. De plus, lâ€™outil Wapiti nous permet dâ€™engendrer les n meilleurs Ã©tiquetages pour une
sÃ©quence donnÃ©e. Nous avons donc choisi de produire les 10 meilleurs Ã©tiquetages syntaxiques
pour chaque phrase dâ€™entrÃ©e. Ainsi Ã  chaque expÃ©rimentation, nous rÃ©cupÃ©rons 10 sÃ©quences
dâ€™Ã©tiquettes pour chaque phrase du corpus. Ces sÃ©quences sont potentiellement assez similaires.
Souvent, seulement quelques Ã©tiquettes varient dâ€™une sÃ©quence Ã  une autre. Pour Ã©valuer la
qualitÃ© de lâ€™Ã©tiquetage syntaxique nous considÃ©rons les 1, 2, 5 ou 10 meilleures Ã©tiquettes de
chaque unitÃ© lexicale de chaque phrase du corpus. Les rÃ©sultats de lâ€™Ã©valuation sont prÃ©sentÃ©s
dans la table 3.
Ã‰tiquetage des dÃ©pendances-tÃªtes
Classes Grammaticales simples Classes Grammaticales Ã©tendues
PrÃ©. (Moy.) Rap. (Moy.) PrÃ©. (Moy.) Rap. (Moy.)
Top 1 87.8 (70.7) 87.8 (62.9) 91.1 (77.8) 91.1 (70.1)
Top 2 83.4 (66.0) 90.0 (67.5) 86.5 (72.5) 93.2 (74.1)
Top 5 73.0 (56.2) 92.9 (73.4) 75.1 (61.3) 95.5 (79.6)
Top 10 62.9 (46.6) 94.6 (77.2) 63.6 (51.0) 96.6 (82.4)
Ã‰tiquetage des groupes-tÃªtes
Classes Grammaticales simples Classes Grammaticales Ã©tendues
PrÃ©. (Moy.) Rap. (Moy.) PrÃ©. (Moy.) Rap. (Moy.)
Top 1 90.4 (86.5) 90.4 (80.1) 91.6 (89.5) 91.6 (85.6)
Top 2 85.6 (81.0) 92.5 (83.6) 86.8 (83.8) 93.7 (87.9)
Top 5 74.3 (67.7) 95.1 (87.9) 75.0 (71.8) 96.0 (91.2)
Top 10 63.3 (55.2) 96.4 (90.6) 63.4 (57.8) 97.1 (93.1)
TABLE 3 â€“ Ã‰valuation de lâ€™Ã©tiquetage syntaxique produit par Wapiti. Dâ€™une part, la prÃ©cision et le
rappel sont calculÃ©s globalement sur toutes les Ã©tiquettes. La prÃ©cision est le nombre dâ€™Ã©tiquettes
correctes sur le nombre dâ€™Ã©tiquettes diffÃ©rentes attribuÃ©es. Le nombre dâ€™Ã©tiquettes diffÃ©rentes attribuÃ©es
varie selon le top, il peut y en avoir 1, de 1 Ã  2, de 1 Ã  5 ou de 1 Ã  10 (on ne compte pas deux
fois la mÃªme Ã©tiquette). Le rappel est le nombre dâ€™unitÃ©s lexicales pour lesquelles on a trouvÃ© la
bonne Ã©tiquette (parmi les 1, 2, 5 ou 10 Ã©tiquettes attribuÃ©es) sur le nombre dâ€™Ã©tiquettes du corpus
dâ€™entrÃ©e (i.e. le nombre dâ€™unitÃ©s lexicales). Dâ€™autre part, une moyenne de la prÃ©cision et du rappel
sur les types/groupes de dÃ©pendances est aussi calculÃ©e (entre parenthÃ¨ses). Dans ce cas, pour chaque
type/groupe, la prÃ©cision est le nombre dâ€™Ã©tiquettes correctement attribuÃ©es sur le nombre dâ€™Ã©tiquettes
diffÃ©rentes attribuÃ©es pour ce type/groupe. Le rappel pour un type/groupe est le nombre dâ€™unitÃ©s
lexicales y appartenant pour lesquelles on a trouvÃ© la bonne Ã©tiquette sur le nombre dâ€™Ã©tiquettes de ce
type/groupe existantes dans le corpus dâ€™entrÃ©e.
Un permier constat face aux rÃ©sultats dâ€™Ã©tiquetage est de voir lâ€™utilitÃ© des informations apportÃ©es
par les classes grammaticales Ã©tendues. De ce cÃ´tÃ© les rÃ©sultats sont meilleurs en prÃ©cision et
en rappel. De maniÃ¨re plus approfondie, on peut voir que plus on considÃ¨re dâ€™Ã©tiquettes plus
la prÃ©cision diminue tandis que le rappel augmente. En effet plus on a dâ€™Ã©tiquettes diffÃ©rentes
pour une unitÃ© lexicale plus on a de chance dâ€™avoir la bonne Ã©tiquette parmi celles-ci mais on ne
sait pas de laquelle il sâ€™agit, on perd donc en prÃ©cision. En fait, les rÃ©sultats par Ã©tiquette varient
grandement. Parmi les 2, 5 ou 10 sÃ©quences dâ€™Ã©tiquettes pour une mÃªme phrase, seulement
quelques Ã©tiquettes varient. Les Ã©tiquettes qui ne changent pas (ou peu) Ã  chaque sÃ©quence sont
globalement "sÃ»res" et perdent peu en prÃ©cision (comme les dÃ©terminants DET, la ponctuation
117 ï¿¿c ATALA
TALN-RÃ‰CITAL 2013, 17-21 Juin, Les Sables dâ€™Olonne
PUNCT, la nÃ©gation NEG dans le cas des groupes). Celles qui gagnent fortement en rappel sont
celles qui sont souvent mal attribuÃ©es dans la premiÃ¨re sÃ©quence mais que lâ€™on finit par trouver
dans les suivantes (comme les relations souvent distantes de corÃ©fÃ©rence COREF ou dâ€™apposition
APPOS). Nous souhaitons voir quel impact a ce gain en rappel sur lâ€™analyse syntaxique en dÃ©pen-
dance. Dans la section suivante nous verrons dans quelle mesure lâ€™Ã©tiquetage syntaxique rÃ©duit
le temps dâ€™analyse en dÃ©pendance et permet dâ€™obtenir une meilleure structure de dÃ©pendances
selon les diffÃ©rents critÃ¨res dâ€™Ã©tiquetage que nous avons Ã©tablis auparavant.
4 Analyse syntaxique en dÃ©pendances et Ã©valuation
4.1 ProcÃ©dure dâ€™analyse et dâ€™Ã©valuation
Pour procÃ©der Ã  lâ€™analyse syntaxique en dÃ©pendances nous souhaitons adapter lâ€™outil dâ€™analyse
par sÃ©lection des tÃªtes du CDG Lab pour assigner automatiquement les Ã©tiquettes syntaxiques,
trouvÃ©es par Wapiti, en tant que dÃ©pendances-tÃªtes (ou groupes-tÃªtes). Nous attribuons donc
1, 1 Ã  2, 1 Ã  5 ou 1 Ã  10 types (ou groupes) de dÃ©pendances diffÃ©rents Ã  chaque unitÃ© lexicale
composÃ©e selon les rÃ©sultats des top 1, 2, 5 et 10 de lâ€™Ã©tiquetage syntaxique. Nous utilisons ici les
meilleurs rÃ©sultats, câ€™est Ã  dire ceux trouvÃ©s avec les classes grammaticales Ã©tendues. Lâ€™analyse
syntaxique en dÃ©pendances guidÃ©e par les rÃ¨gles de la grammaire catÃ©gorielle de dÃ©pendances
du franÃ§ais sâ€™Ã©xecute en tenant compte des diffÃ©rentes dÃ©pendances-tÃªtes (ou groupes-tÃªtes)
possibles. Le CDG Lab est conÃ§u pour produire une liste des structures de dÃ©pendances possibles
pour chaque analyse 7. La sÃ©lection des tÃªtes permet de rÃ©duire lâ€™ambiguÃ¯tÃ© en contraignant
lâ€™analyseur Ã  chercher des structures de dÃ©pendances dont les types sont en accord avec cette
sÃ©lection. Vis-Ã -vis dâ€™une analyse autonome, ici, le nombre de structures de dÃ©pendances en
sortie est moindre. Nous observons donc des temps dâ€™analyse Ã©galement rÃ©duits. Les structures
de dÃ©pendances en sortie de lâ€™analyseur ne sont pas triÃ©es. Or nous souhaitons avant tout savoir
si parmi les structures de dÃ©pendances produites pour une phrase donnÃ©e se trouve la bonne
structure de dÃ©pendances (i.e. la structure de dÃ©pendances associÃ©e Ã  cette phrase dans le corpus
en dÃ©pendances de rÃ©fÃ©rence, 2.3). Lâ€™idÃ©e est donc de trier ces structures de la plus proche Ã  la
plus Ã©loignÃ©e de la structure originale. La plus proche Ã©tant celle ayant le plus de dÃ©pendances en
commun 8 avec la structure de rÃ©fÃ©rence. Les diffÃ©rentes Ã©tapes de ce traitement sont illustrÃ©es
dans la figure 3.
Nous nous intÃ©ressons alors seulement Ã  la premiÃ¨re structure de dÃ©pendances de chaque liste
(la plus proche de la structure originale). NÃ©anmoins, parfois, il nâ€™existe aucune structure de
dÃ©pendances produite. Deux raisons sont possibles :
â€“ les dÃ©pendances-tÃªtes (ou groupes-tÃªtes) assignÃ©es sont en contradiction avec les rÃ¨gles de la
grammaire, cela entraÃ®ne alors un Ã©chec de lâ€™analyse ;
â€“ le temps dâ€™analyse est trop Ã©levÃ© (communÃ©ment due Ã  la longueur de la phrase), lâ€™analyse
sâ€™interrompt donc avant dâ€™aboutir.
Nous souhaitons donc connaÃ®tre le nombre de structures de dÃ©pendances obtenues en sortie. Les
rÃ©sultats de ses expÃ©rimentations sont prÃ©sentÃ©s dans la section suivante.
7. En accord avec les dÃ©pendances-tÃªtes (ou groupes-tÃªtes) sÃ©lectionnÃ©es ainsi quâ€™avec la grammaire.
8. Une dÃ©pendance est commune aux deux structures de dÃ©pendances si elle possÃ¨de dans les deux structures le
mÃªme gouverneur, le mÃªme subordonnÃ© et le mÃªme type de dÃ©pendance.
118 ï¿¿c ATALA
TALN-RÃ‰CITAL 2013, 17-21 Juin, Les Sables dâ€™Olonne
			 
 
	
 	
		  
	
 
"

	  
		 	
 	
	 	 	
	#	 	 	
 ! 	
 $
FIGURE 3 â€“ SchÃ©ma expliquatif du traitement complet. Wapiti est utilisÃ© pour procÃ©der Ã  lâ€™apprentis-
sage sur 90% du corpus et Ã  lâ€™Ã©tiquetage sur 10%. La partie Ã©tiquetÃ©e est analysÃ©e par lâ€™analyseur du
CDG Lab en tenant compte des dÃ©pendances-tÃªtes (ou groupes-tÃªtes). On obtient plusieurs structures
de dÃ©pendances pour chaque phrase qui sont ensuite triÃ©es selon leur conformitÃ© avec la structure
originale du corpus de rÃ©fÃ©rence (filtre). Le traitement est opÃ©rÃ© sur chaque partie du corpus.
4.2 RÃ©sultats et discussions
Les premiers rÃ©sultats exposÃ©s dans la table 4 prÃ©sente les taux dâ€™analyses abouties ainsi que le
nombre dâ€™unitÃ©s lexicales par phrase et le temps de calcul.
Nous rapportions dans la section 3.2 quâ€™en ayant plus de choix de tÃªtes pour chaque unitÃ© lexicale
nous avions plus de chance dâ€™obtenir la bonne tÃªte parmi ceux-ci. Il en est de mÃªme pour les
dÃ©pendances lorsquâ€™on laisse entre 1 Ã  10 choix de tÃªtes pour chaque unitÃ© lexicale : ayant plus de
chance dâ€™avoir les bonnes dÃ©pendances-tÃªtes (ou groupes-tÃªtes) nous avons aussi plus de chance
dâ€™obtenir une structure de dÃ©pendances proche de la structure de dÃ©pendances de rÃ©fÃ©rence
parmi toutes celles produites. Pour la mÃªme raison, on obtient de meilleurs taux dâ€™analyses
ayant abouti. Dans le meilleur des cas (sÃ©lection de 10 Ã©tiquettes), nous avons 2548 analyses
sur 2778 (91.7%) ayant abouti dont 2088 ayant trouvÃ©, parmi les structures de dÃ©pendances
produites, une structure de dÃ©pendances entiÃ¨rement correcte. Les temps dâ€™analyse augmentent
relativement Ã  lâ€™ambiguÃ¯tÃ© (en obtenant plus de structures de dÃ©pendances en sortie) ainsi quâ€™Ã  la
longueur des phrases. Effectivement les phrases qui sont analysÃ©es avec un choix de dix Ã©tiquettes
alors quâ€™elles ne lâ€™Ã©taient pas avec un choix infÃ©rieur sont souvent plus longues car plus difficiles
Ã  Ã©tiqueter correctement et exploitent plus de temps dâ€™analyse. Par ailleurs, on constate que le
nombre moyen dâ€™unitÃ©s lexicales par phrase augmente lÃ©gÃ¨rement dans le cas des analyses ayant
abouti quand le choix dâ€™Ã©tiquettes est plus large. Ce qui montre que des phrases plutÃ´t longues
qui nâ€™ont pas Ã©tÃ© analysÃ©es avec un seul choix dâ€™Ã©tiquettes lâ€™ont Ã©tÃ© avec plus de choix. Cependant
un nombre dâ€™Ã©tiquettes plus important en entrÃ©e augmente lâ€™ambiguÃ¯tÃ© de lâ€™analyse et donc le
temps dâ€™analyse. On obtient donc un peu plus de phrases non-analysÃ©es par manque de temps
lorsquâ€™on augmente le choix dâ€™Ã©tiquettes.
Lorsque lâ€™on compare les rÃ©sultats des expÃ©rimentations faites avec les dÃ©pendances-tÃªtes et
les groupes-tÃªtes, on constate plusieurs points intÃ©ressants. Les taux dâ€™analyses abouties sont
meilleurs lorsquâ€™on utilise les groupes-tÃªtes car on laisse un plus large choix Ã  lâ€™analyseur (les
groupes comprennent parfois plusieurs types de dÃ©pendances). NÃ©anmoins on note une diffÃ©rence
au niveau du temps dâ€™analyse qui est infÃ©rieur lorsquâ€™on utilise les dÃ©pendances-tÃªtes. En effet,
lâ€™analyseur converge plus vite. On peut donc voir quâ€™il y a moins dâ€™analyses nâ€™ayant pas abouti
par manque de temps mais que le nombre dâ€™analyses nâ€™ayant pas abouti car Ã©tant non-conforme
119 ï¿¿c ATALA
TALN-RÃ‰CITAL 2013, 17-21 Juin, Les Sables dâ€™Olonne
Analyse autonome
Nb de Nombre de phrases UL/phrase Temps dâ€™analyse
tÃªtes AA (%) NA-C (%) NA-T (%) AA NA-C NA-T AA NA
0 1150 (41.4) 3 (00.1) 1625 (58.5) 7.2 7.3 17.6 42min24 4h30
Analyse avec sÃ©lection des dÃ©pendances-tÃªtes
Nb de Nombre de phrases UL/phrase Temps dâ€™analyse
tÃªtes AA (%) NA-C (%) NA-T (%) AA NA-C NA-T AA NA
1 1805 (65.0) 969 (34.9) 4 (00.1) 11.5 16.5 52.5 3min03 1min35
1 Ã  2 2054 (73.9) 718 (25.8) 6 (00.2) 11.6 17.7 56.1 4min16 1min53
1 Ã  5 2335 (84.1) 438 (15.8) 5 (00.2) 12.0 20.0 49.4 6min02 1min29
1 Ã  10 2505 (90.2) 262 (09.4) 11 (00.4) 12.2 22.5 42.8 8min01 2min23
Analyse avec sÃ©lection des groupes-tÃªtes
Nb de Nombre de phrases UL/phrase Temps dâ€™analyse
tÃªtes AA (%) NA-C (%) NA-T (%) AA NA-C NA-T AA NA
1 1931 (69.5) 832 (29.9) 15 (00.5) 11.5 16.9 45.8 6min41 3min31
1 Ã  2 2172 (78.2) 586 (21.1) 20 (00.7) 11.6 18.6 45.0 8min52 4min15
1 Ã  5 2439 (87.8) 302 (10.9) 37 (01.3) 11.8 21.6 43.6 12min05 6min47
1 Ã  10 2548 (91.7) 179 (06.4) 51 (01.8) 12.0 24.4 41.6 16min43 9min03
TABLE 4 â€“ Calcul du nombre de phrases dont lâ€™analyse a abouti (AA), du nombre de phrases dont
lâ€™analyse nâ€™a pas abouti car elle est non-conforme Ã  la grammaire (NA-C), du nombre de phrases
dont lâ€™analyse nâ€™a pas abouti par manque de temps (NA-T). Le temps dâ€™analyse est limitÃ© Ã  10s
maximum. Calcul du nombre moyen dâ€™unitÃ©s lexicales (UL) par phrase dont lâ€™analyse a abouti et
dont lâ€™analyse nâ€™a pas abouti (car non-conforme ou par manque de temps). Calcul du temps total
dâ€™analyse pour celles ayant abouti et celles nâ€™ayant pas abouti.
Ã  la grammaire est plus Ã©levÃ©. En fait, lâ€™Ã©tiquetage est plus prÃ©cis donc plus rapide mais conduit
plus facilement Ã  une analyse non-conforme Ã  la grammaire sâ€™il y a une ou plusieurs Ã©tiquettes
fausses. On obtient plus facilement une incohÃ©rence vis-Ã -vis de la grammaire.
Dâ€™autre part, nous prÃ©sentons dans la table 5 en tant que score de prÃ©cision, les scores dâ€™atta-
chement obtenus sur les analyses abouties. On y trouve le pourcentage dâ€™unitÃ©s lexicales pour
lesquelles le bon gouverneur et la bonne Ã©tiquette ont Ã©tÃ© trouvÃ©s (LAS) et le taux dâ€™unitÃ©s
lexicales pour lesquelles le bon gouverneur a Ã©tÃ© trouvÃ© (UAS). Encore une fois, nous pouvons
voir que plus large est le choix dâ€™Ã©tiquettes en entrÃ©e plus les scores sont meilleurs. Ils at-
teignent globalement des taux Ã©levÃ©s et sont quelques peu meilleurs dans le cas oÃ¹ lâ€™on considÃ¨re
seulement lâ€™exactitude du gouverneur. Lorsquâ€™on sâ€™intÃ©resse aux dÃ©pendances discontinues, on
remarque que la prÃ©cision sur ces dÃ©pendances est lÃ©gÃ¨rement moins bonne que sur lâ€™ensemble
des dÃ©pendances.
La diffÃ©rence de prÃ©cision entre les analyses ayant reÃ§u des dÃ©pendances-tÃªtes ou des groupes-
tÃªtes est nÃ©gligeable sur lâ€™ensemble des dÃ©pendances mais moins bonne sur les dÃ©pendances
discontinues dans le cas de la sÃ©lection des groupes-tÃªtes. Cela peut sâ€™expliquer par le fait que le
taux de dÃ©pendances discontinues est moins Ã©levÃ© parmi les dÃ©pendances des analyses abouties
dans le cas de la sÃ©lection des dÃ©pendances-tÃªtes 9. Les cas difficiles de dÃ©pendances discontinues
distantes sont Ã©cartÃ©s du calcul de la prÃ©cision si la prÃ©-sÃ©lection des tÃªtes est non-conforme Ã  la
9. On obtient de 4,3% Ã  4,6% de dÃ©pendances discontinues parmis les dÃ©pendances des analyses abouties avec
sÃ©lection des dÃ©pendances-tÃªtes pour 4,8% Ã  4,9% avec la sÃ©lection des groupes-tÃªtes.
120 ï¿¿c ATALA
TALN-RÃ‰CITAL 2013, 17-21 Juin, Les Sables dâ€™Olonne
grammaire et engendre une mauvaise analyse. Nous avons vu que cette non-conformitÃ© est plus
facile Ã  atteindre avec la sÃ©lection des dÃ©pendances-tÃªtes. Les scores sont donc moins bons avec
la sÃ©lection des groupes-tÃªtes car plus dâ€™analyse aboutissent sans forcement avoir rÃ©solu les cas
discontinus difficiles.
Analyse autonome
Nb de Toutes dÃ©pendances DÃ©pendances discontinues
tÃªtes LAS UAS LAS UAS
0 98.3 99.0 92.7 93.2
Analyse avec sÃ©lection des dÃ©pendances-tÃªtes
Nb de Toutes dÃ©pendances DÃ©pendances discontinues
tÃªtes LAS UAS LAS UAS
1 93.7 96.7 92.4 93.7
1 Ã  2 95.1 97.3 94.3 95.5
1 Ã  5 96.2 97.8 94.4 95.5
1 Ã  10 96.4 97.9 94.5 95.4
Analyse avec sÃ©lection des groupes-tÃªtes
Nb de Toutes dÃ©pendances DÃ©pendances discontinues
tÃªtes LAS UAS LAS UAS
1 93.9 96.7 88.8 93.3
1 Ã  2 95.1 97.2 90.0 93.7
1 Ã  5 96.3 97.9 90.5 93.8
1 Ã  10 96.7 98.0 91.1 94.3
TABLE 5 â€“ Ã‰valuation de lâ€™analyse autonome (sans prÃ©-sÃ©lection des tÃªtes) et de lâ€™analyse avec prÃ©-
sÃ©lection des dÃ©pendances-tÃªtes et des groupes-tÃªtes. Cette Ã©valuation est rÃ©alisÃ©e sur la meilleure
structure de dÃ©pendances produite par lâ€™analyseur (i.e. la plus proche de la structure de dÃ©pendances
de rÃ©fÃ©rence) pour chaque analyse aboutie. Les scores dâ€™attachement LAS et UAS correspondent
respectivement au score dâ€™attachement avec dÃ©pendances Ã©tiquetÃ©es (Labeled Attachment Score) et
au score dâ€™attachement avec dÃ©pendances non-Ã©tiquetÃ©es (Unlabeled Attachment Score). Ils sont
calculÃ©s sur toutes les dÃ©pendances dâ€™une part et sur les seules dÃ©pendances discontinues dâ€™autre part,
en excluant les dÃ©pendances liÃ©es Ã  des signes de ponctuations dans les deux cas.
4.3 Travaux reliÃ©s
Plusieurs travaux ont dÃ©jÃ  mis en Ã©vidence lâ€™utilitÃ© des mÃ©thodes de type supertagging sur lâ€™analyse
syntaxique (Clark et Curran, 2004; Sarkar, 2010). Les rÃ©sultats de ces travaux sont difficiles
Ã  comparer avec dâ€™autres pour plusieurs raisons. Dâ€™une part les fonctions syntaxiques utilisÃ©es
ici pour lâ€™analyse en dÃ©pendances diffÃ¨rent et sont plus nombreuses que dans les travaux oÃ¹
les dÃ©pendances proviennent des tÃªtes de constituants. De plus les dÃ©pendances discontinues
ne sont pas toujours prises en compte. Dâ€™autres part, lâ€™analyse en dÃ©pendances nâ€™est ici pas
totalement autonome en sâ€™appuyant sur certains prÃ©-requis. Nous pouvons tout de mÃªme tenter
de rapprocher ces travaux dâ€™autres tÃ¢ches de supertagging pour lâ€™anglais (Nasr et Rambow, 2004)
ou pour lâ€™allemand (Foth et al., 2006). Les travaux les plus proches sont sans doute ceux de (Nasr
et Rambow, 2010) obtenant une prÃ©cision de 85,7% pour lâ€™anglais.
121 ï¿¿c ATALA
TALN-RÃ‰CITAL 2013, 17-21 Juin, Les Sables dâ€™Olonne
5 Conclusion et travaux Ã  venir
Les rÃ©sultats de lâ€™analyse syntaxique en dÃ©pendances contrainte par la sÃ©lection des tÃªtes reflÃ¨te
dâ€™une rÃ©elle utilitÃ© de cette sÃ©lection automatique. Dans un premier temps, la sÃ©lection des
dÃ©pendances-tÃªtes ou des groupes-tÃªtes en amont de lâ€™analyse en dÃ©pendances permet de rÃ©duire
de maniÃ¨re significative le temps dâ€™analyse. De nombreuses phrases, dâ€™une longueur consÃ©quente,
ne permettant pas dâ€™aboutir Ã  une analyse autonome peuvent Ãªtre finalement analysÃ©es grÃ¢ce Ã 
la sÃ©lection des tÃªtes. Ce facteur est trÃ¨s important pour atteindre des taux de rÃ©ussite (analyses
abouties) intÃ©ressant et donc des rÃ©sultats rÃ©ellement exploitables. Par ailleurs, en Ã©tiquetant
syntaxiquement les unitÃ©s lexicales des phrases de 1 Ã  10 Ã©tiquettes diffÃ©rentes, on obtient un
bon score en prÃ©cision. Il nous indique que parmi les structures de dÃ©pendances produites par
lâ€™analyseur du CDG Lab, on obtient trÃ¨s souvent la bonne structure de dÃ©pendances pour une
phrase donnÃ©e.
Cependant, nous supposons ici avoir un bon dÃ©coupage des phrases en unitÃ©s lexicales et un bon
Ã©tiquetage en entrÃ©e ainsi quâ€™un tri des structures de dÃ©pendances en sortie qui sâ€™appuie sur la
structure de dÃ©pendances de rÃ©fÃ©rence. Dans lâ€™idÃ©e de mettre en place un analyseur totalement
autonome, nous souhaitons, par la suite, faire de ces Ã©tapes des tÃ¢ches automatiques. Nous
avons donc lâ€™intention dâ€™ajouter une Ã©tape de dÃ©coupage des unitÃ©s lexicales et dâ€™Ã©tiquetage
grammatical de ces unitÃ©s en amont de lâ€™Ã©tiquetage syntaxique prÃ©sentÃ© dans cet article. Puis
nous appliquerons une mÃ©thode de tri automatique des structures de dÃ©pendances en sortie de
lâ€™analyseur permettant de trouver la structure de dÃ©pendances la plus proche de la structure de
rÃ©fÃ©rence sans sâ€™y Ãªtre rÃ©fÃ©rÃ©.
En outre, notons que le taux dâ€™analyse non abouties car lâ€™Ã©tiquetage Ã©tait non-conforme avec la
grammaire varie de 6 Ã  35% du meilleur au pire des cas. Un mauvais Ã©tiquetage local peut Ãªtre la
cause de cette non-conformitÃ©. Cependant le score gÃ©nÃ©ral dâ€™Ã©tiquetage Ã©tant bon (le meilleur est
de 97.1 en rappel pour 10 choix dâ€™Ã©tiquettes), il est Ã©vident que la majoritÃ© des Ã©tiquettes pour
une phrase donnÃ©e sont correctes et permettraient dâ€™obtenir une (ou plusieurs) sous-structure(s)
de dÃ©pendances correcte(s) pour cette phrase. Lâ€™Ã©volution de lâ€™analyseur du CDG Lab ira dans ce
sens : permettre Ã  lâ€™analyseur de produire des structures de dÃ©pendances partielles lorsque la
sÃ©lection des tÃªtes nâ€™est pas totalement conforme avec la grammaire. La solution partielle pourra
ensuite Ãªtre complÃ©tÃ©e en appliquant une analyse par approximation. Le nombre de structures
de dÃ©pendances analysÃ©es augmentera et cela permettra dâ€™obtenir de meilleurs taux dâ€™analyses
abouties.
RÃ©fÃ©rences
ALFARED, R., BÃ‰CHET, D. et DIKOVSKY, A. (2011). â€œCDG Labâ€ : a Toolbox for Dependency
Grammars and Dependency Treebanks Development. In Proceedings of DEPLING 2011, pages
272â€“281.
BANGALORE, S. et JOSHI, A., Ã©diteurs (2010a). Complexity of Lexical Descriptions and its Relevance
to Natural Language Processing : A Supertagging Approach. MIT Press.
BANGALORE, S. et JOSHI, A. K. (2010b). Supertagging : Using Complex Lexical Descriptions in
Natural Language Processing. Mit Press.
BAR-HILLEL, Y., GAIFMAN, C. et SHAMIR, E. (1964). On Categorial and Phrase Structure Grammars.
In Language and information, pages 99â€“115. Addison-Wesley.
122 ï¿¿c ATALA
TALN-RÃ‰CITAL 2013, 17-21 Juin, Les Sables dâ€™Olonne
BÃ‰CHET, D., DIKOVSKY, A. et FORET, A. (2005). Dependency structure grammar. In Proceedings of
LACL 2005, pages 18â€“34.
CANDITO, M., CRABBÃ‰, B. et DENIS, P. (2010). Statistical french dependency parsing : treebank
conversion and first results. In Proceedings of LREC 2010, pages 1840â€“1847.
CLARK, S. et CURRAN, J. R. (2004). The importance of supertagging for wide-coverage ccg
parsing. In Proceedings of COLING 2004, pages 282â€“288.
DEKHTYAR, M. et DIKOVSKY, A. (2004). Categorial dependency grammars. In Proceedings of
Intern. Conf. on Categorial Grammars, pages 76â€“91.
DEKHTYAR, M. et DIKOVSKY, A. (2008). Generalized categorial dependency grammars. In
Trakhtenbrot/Festschrift, LNCS 4800, pages 230â€“255. Springer.
DEKHTYAR, M., DIKOVSKY, A. et KARLOV, B. (2012). Iterated dependencies and kleene iteration.
In Formal Grammar 2010/2011, LNCS 7395, pages 66â€“81.
DIKOVSKY, A. (2004). Dependencies as categories. In Proceedings of COLING 2004 Workshop,
"Recent Advances in Dependency Grammars", pages 90â€“97.
DIKOVSKY, A. (2011). Categorial dependency grammars : from theory to large scale grammars.
In DEPLING 2011.
FOTH, K., BY, T. et MENZEL, W. (2006). Guiding a constraint dependency parser with supertags.
In Proceedings of COLING 2006, pages 289â€“296.
LAFFERTY, J., MCCALLUM, A. et PEREIRA, F. (2001). Conditional random fields : Probabilistic
models for segmenting and labeling sequence data. In Proceedings of ICML 2001.
LAVERGNE, T., CAPPÃ‰, O. et YVON, F. (2010). Practical very large scale CRFs. In ACL 2010.
MELâ€™CUK, I. (1988). Dependency syntax : Theory and Practice. State University of New York Press.
NASR, A. (2006). Grammaires de dÃ©pendances gÃ©nÃ©ratives probabilistes. modÃ¨le thÃ©orique et
application Ã  un corpus arborÃ© du franÃ§ais. Traitement Automatique des Langues, 46(1):115â€“153.
NASR, A. et RAMBOW, O. (2004). Supertagging and full parsing. In Proceedings of TAG+7.
NASR, A. et RAMBOW, O. (2010). Non-lexical chart parsing for tag. In (Bangalore et Joshi,
2010a).
RABINER, L. R. (1989). A tutorial on hidden markov models and selected applications in speech
recognition. In Proceedings of IEEE 1989.
RATNAPARKHI, A. (1996). A maximum entropy model for part-of-speech tagging. In Proceedings
of EMNLP 1996.
SAGOT, B. (2010). The Lefff, a freely available and large-coverage morphological and syntactic
lexicon for French. In Proceedings of LREC 2010.
SARKAR, A. (2010). Combining supertagging and lexicalized tree-adjoining grammar parsing. In
(Bangalore et Joshi, 2010a).
SUTTON, C. et MCCALLUM, A. (2006). An introduction to conditional random fields for relational
learning. In Introduction to Statistical Relational Learning. MIT Press.
TESNIÃˆRE, L. (1959). Ã‰lÃ©ments de syntaxe structurale. Klincksieck.
123 ï¿¿c ATALA
