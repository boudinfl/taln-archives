TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Inﬂuence de l’étiquetage syntaxique des tétes sur1’ana1yse en
dépendances discontinues du francais

Ophélie Lacroixl
(1) LINA - Université de Nantes, 2 Rue de la Houssiniere, 44322 Nantes Cedex 3

ophelie . lacroix©univ—nantes .fr

RESUME
Dans cet article nous souhaitons mettre en évidence l’utilité d’un étiquetage syntaxique appliqué
en amont d’une analyse syntaxique en dépendances. Les régles de la grammaire catégorielle
de dépendances du francais utilisées pour l’analyse gérent les dépendances discontinues et
les relations syntaxiques a longue distance. Une telle méthode d’analyse génére un nombre
conséquent de structures de dépendances et emploie un temps d’analyse trop important. Nous
voulons alors montrer qu’une méthode locale d’étiquetage peut diminuer l’ampleur de ces
difﬁcultés et par la suite aider a résoudre le probleme global de désambiguisation d’analyse en
dépendances. Nous adaptons alors une méthode d’étiquetage aux catégories de la grammaire
catégorielle de dépendance. Nous obtenons ainsi une pré—sélection des tétes des dépendances
permettant de réduire l’ambigu'1'té de l’analyse et de voir que les résultats locaux d’une telle
méthode permettent de trouver des relations distantes de dépendances.

ABSTRACT
On the Effect of Head Tagging on Parsing Discontinuous Dependencies in French

In this paper we want to show the strong impact of syntactic tagging on syntactic dependency
parsing. The rules of categorial dependency grammar used to parse French deal with discon-
tinuous dependencies and long distance syntactic relations. Such parsing method produces a
substantial number of dependency structures and takes too much parsing time. We want to show
that a local tagging method can reduce these problems and help to solve the global problem of
dependency parsing disambiguation. Then we adapt a tagging method to types of the categorial
dependency grammar. We obtain a dependency—head pre—selection allowing to reduce parsing
ambiguity and to see that we can ﬁnd distant relation of dependencies through local results of
such method

MOTS-CLES : Analyse syntaxique en dépendances discontinues, Etiquetage syntaxique.

KEYWORDS: Discontinuous Dependency Parsing, Syntactic Tagging.

110 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
1 Introduction

L’analyse syntaxique est une tache bien connue dans le domaine du traitement automatique du
langage naturel, permettant d’obtenir des structures syntaxiques a partir de phrases du langage
naturel. On oppose couramment les représentations syntaxiques des structures par consituants et
des structures en dépendances. Ici, nous nous intéressons particulierement a la représentation en
dépendances de ces structures (Tesniére, 1959; Mel’cuk, 1988). En utilisant cette représentation,
nous souhaitons exprimer correctement les relations syntaxiques existantes entre les mots d’une
phrase. Ces relations sont des relations binaires (dépendances) entre un gouverneur g et un

subordonné s ou le type de dépendance d est la fonction syntaxique existante entre g et 5 (g L s).
Une telle dépendance est projective si chaque mot dans l’intervalle [g,s] dépend de g (sinon
elle est discontinue). Le type de dépendance d est aussi la dépendance—téte1 du subordonné
s. Notre travail se situe au niveau de l’analyse syntaxique en dépendances pour le francais. Or
cette langue admet des cas de discontinuité a travers des relations de longue distance comme la
coréférence (voir ﬁgure 1) ou la comparaison ou des relations locales fréquentes, par exemple de
négation ou de clitique. Nous avons choisi une méthode d’analyse guidée par les régles d’une

 

I'| y a si longtemps qu' il n' a ressenti une telle solitude que c' est un vertige .

FIGURE 1 — Structure de dépendances pour la phrase "11 y a si longtemps qu’il n’a ressenti une telle
solitude que c’est un Vertige.". Les dépendances projectives sont repre’sente'es par des lignes plaines
tandis que les dépendances discontinues sont représentées par des lignes pointillées. Les types des
dépendances sont les types utilise's par une grammaire catégorielle de dépendances du frangais.

grammaire permettant d’obtenir des structures de dépendances projectives et des structures de
dépendances discontinues 2. Le modéle de grammaire catégorielle de dépendances (Dikovsky,
2004; Béchet et al., 2005; Dekhtyar et Dikovsky, 2008; Dekhtyar et al., 2012) étend la gestion
des dépendances aux dépendances discontinues et est donc tout a fait adaptée a la représentation
syntaxique en dépendances de phrases du francais. Le CDG Lab (Alfared et al., 2011) est un
outil, destiné a l’analyse syntaxique avec des grammaires catégorielles de dépendances et au
développement de corpus arborés en dépendances. I1 propose trois modes d’analyses différents
que nous redéﬁnirons par la suite. Le mode nous intéressant ici est le mode semi—automatique de
se'lection des tétes. Dans ce mode, un utilisateur souhaitant procéder a une analyse syntaxique en

1. La dépendance-téte est le type de la dépendance arrivant sur le subordonné.

2. Une structure de dépendances discontinue est une structure dans laquelle on trouve au moins une dépendance
discontinue. Dans ces structures les dépendances peuvent se croiser. Par exemple, les clitiques engendrent des dépendances
discontinues des lors qu’une forme composée verbale est employée, séparant le verbe et son objet cliticisé. La négation
produit fréquemment une discontinuité puisqu’elle est communément composé de deux particules, parfois distantes
(“Ne  que“), parfois inversés (“Jamais  ne“). Par ailleurs, la relation de coréférence (ﬁgure 1) est intraphrasale, elle
correspond a la co-prédication déﬁnie par (Mel’cuk, 1988).

111 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Analyse autonome

Nb de Nombre de phrases UL/phrase Temps d’analyse
tétes AA NA-C NA-T AA NA-C NA-T AA NA

0 1 150 3 1625 7.2 7.3 17.6 42min24 4h30

Analyse avec sélection des dépendances-tétes

Nb de Nombre de phrases UL/phrase Temps d’analyse
tétes AA NA-C NA-T AA NA-C NA-T AA NA

1 1805 969 4 11.5 16.5 52.5 3min03 1min35
1 a 2 2054 718 6 11.6 17.7 56.1 4min16 1min53
1 a 5 2335 438 5 12.0 20.0 49.4 6min02 1min29
1 A 10 2505 262 11 12.2 22.5 42.8 8min01 2min23

Analyse avec sélection des groupes-tétes

Nb de Nombre de phrases UL/phrase Temps d’analyse
tétes AA NA-C NA-T AA NA-C NA-T AA NA

1 1931 832 15 11.5 16.9 45.8 6min41 3min31
1 a 2 2172 586 20 11.6 18.6 45.0 8min52 4min15
1 a 5 2439 302 37 11.8 21.6 43.6 12min05 6min47
1 5 10 2548 179 51 12.0 24.4 41.6 16min43 9min03

TABLE 4 — Calcul du nombre de phrases dont l’anal_yse a abouti (AA), du nombre de phrases dont
l’anal_yse n’a pas abouti car elle est non—conforme a la grammaire (NA-C), du nombre de phrases
dont l’anal_yse n’a pas abouti par manque de temps (NA-T). Le temps d’analyse est limite’ a 10s
maximum. Calcul du nombre moyen d’unités lexicales (UL) par phrase dont l’anal_yse a abouti et
dont l’anal_yse n’a pas abouti (car non—conforme ou par manque de temps). Calcul du temps total
d’analyse pour celles ayant abouti et celles n’a_yant pas abouti.

a la grammaire est plus élevé. En fait, l’éu'quetage est plus précis donc plus rapide mais conduit
plus facilement a une analyse non—conforme a la grammaire s’il y a une ou plusieurs étiquettes
fausses. On obtient plus facilement une incohérence vis-a-vis de la grammaire.

D’autre part, nous présentons dans la table 5 en tant que score de précision, les scores d’atta—
chement obtenus sur les analyses abouties. On y trouve le pourcentage d’unités lexicales pour
lesquelles le bon gouverneur et la bonne étiquette ont été trouvés (LAS) et le taux d’unités
lexicales pour lesquelles le bon gouverneur a été trouvé (UAS). Encore une fois, nous pouvons
voir que plus large est le choix d’étiquettes en entrée plus les scores sont meilleurs. Ils at-
teignent globalement des taux élevés et sont quelques peu meilleurs dans le cas o1‘1 l’on considére
seulement l’exactitude du gouverneur. Lorsqu’on s’intéresse aux dépendances discontinues, on
remarque que la précision sur ces dépendances est légerement moins bonne que sur l’ensemble
des dépendances.

La différence de précision entre les analyses ayant regu des dépendances—tétes ou des groupes—
tétes est négligeable sur l’ensemble des dépendances mais moins bonne sur les dépendances
discontinues dans le cas de la sélection des groupes—tétes. Cela peut s’exp1iquer par le fait que le
taux de dépendances discontinues est moins élevé parmi les dépendances des analyses abouties
dans le cas de la sélection des dépendances—tétes 9. Les cas difﬁciles de dépendances discontinues
distantes sont écartés du calcul de la précision si la pré—sé1ecu'on des tétes est non—conforme a la

9. On obtient de 4,3% £1 4,6% de dépendances discontinues parmis les dépendances des analyses abouties avec
sélection des dépendances-tétes pour 4,8% 5 4,9% avec la sélection des groupes-tétes.

120 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

grammaire et engendre une mauvaise analyse. Nous avons vu que cette non—conforrnité est plus
facile a atteindre avec la sélection des dépendances—tétes. Les scores sont donc moins bons avec
la sélection des groupes—tétes car plus d’analyse aboutissent sans forcement avoir résolu les cas
discontinus difficiles.

Analyse autonome
Nb de Toutes dépendances Dépendances discontinues
tétes LAS UAS LAS UAS
0 98.3 99.0 92.7 93.2

Analyse avec sélection des dépendances-tétes
Nb de Toutes dépendances Dépendances discontinues

tétes LAS UAS LAS UAS
1 93.7 96.7 92.4 93.7
1 a 2 95.1 97.3 94.3 95.5
1 a 5 96.2 97.8 94.4 95.5
1 5 10 96.4 97.9 94.5 95.4

Analyse avec sélection des groupes-tétes
Nb de Toutes dépendances Dépendances discontinues

tétes LAS UAS LAS UAS
1 93.9 96.7 88.8 93.3
1 a 2 95.1 97.2 90.0 93.7
1 a 5 96.3 97.9 90.5 93.8
1 5 10 96.7 98.0 91.1 94.3

TABLE 5 — Evaluation de l’analyse autonome (sans pre’—se’lection des tétes) et de l’analyse avec pre’—
sélection des dépendances-tétes et des groupes—tétes. Cette e’valuation est re’alise’e sur la meilleure
structure de dépendances produite par l’anal_yseur (i.e. la plus proche de la structure de dépendances
de re’fe’rence) pour chaque analyse aboutie. Les scores d’attachement LAS et UAS correspondent
respectivement au score d’attachement avec dépendances e’tiquete’es (Labeled Attachment Score) et
au score d’attachement avec dépendances non—e’tiquete’es (Unlabeled Attachment Score). Ils sont
calculés sur toutes les dépendances d’une part et sur les seules dépendances discontinues d’autre part,
en excluant les dépendances lie'es (‘z des signes de ponctuations dans les deux cas.

4.3 'I'raVaux reliés

Plusieurs travaux ont déja mis en évidence l’utilité des méthodes de type supertagging sur l’analyse
syntaxique (Clark et Curran, 2004; Sarkar, 2010). Les résultats de ces travaux sont difﬁciles
a comparer avec d’autres pour plusieurs raisons. D’une part les fonctions syntaxiques utilisées
ici pour l’analyse en dépendances different et sont plus nombreuses que dans les travaux ou
les dépendances proviennent des tétes de constituants. De plus les dépendances discontinues
ne sont pas toujours prises en compte. D’autres part, l’analyse en dépendances n’est ici pas
totalement autonome en s’appuyant sur certains pré—requis. Nous pouvons tout de meme tenter
de rapprocher ces travaux d’autres taches de supertagging pour l’anglais (Nasr et Rambow, 2004)
ou pour l’allemand (Foth et al., 2006). Les travaux les plus proches sont sans doute ceux de (Nasr
et Rambow, 2010) obtenant une précision de 85,7% pour l’anglais.

121 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
5 Conclusion et travaux a venir

Les résultats de l’analyse syntaxique en dépendances contrainte par la sélection des tétes reﬂete
d’une réelle utilité de cette sélection automatique. Dans un premier temps, la sélection des
dépendances—tetes ou des groupes—tetes en amont de l’analyse en dépendances permet de réduire
de maniere signiﬁcative le temps d’analyse. De nombreuses phrases, d’une longueur conséquente,
ne permettant pas d’aboutir a une analyse autonome peuvent étre ﬁnalement analysées grace a
la sélection des tétes. Ce facteur est trés important pour atteindre des taux de réussite (analyses
abouties) intéressant et donc des résultats réellement exploitables. Par ailleurs, en étiquetant
syntaxiquement les unités lexicales des phrases de 1 a 10 étiquettes différentes, on obtient un
bon score en précision. Il nous indique que parmi les structures de dépendances produites par
l’analyseur du CDG Lab, on obtient trés souvent la bonne structure de dépendances pour une
phrase donnée.

Cependant, nous supposons ici avoir un bon découpage des phrases en unités lexicales et un bon
étiquetage en entrée ainsi qu’un tri des structures de dépendances en sortie qui s’appuie sur la
structure de dépendances de référence. Dans l’idée de mettre en place un analyseur totalement
autonome, nous souhaitons, par la suite, faire de ces étapes des taches automatiques. Nous
avons donc l’intention d’ajouter une étape de découpage des unités lexicales et d’étiquetage
grammatical de ces unités en amont de l’étiquetage syntaxique présenté dans cet article. Puis
nous appliquerons une méthode de tri automatique des structures de dépendances en sortie de
l’analyseur permettant de trouver la structure de dépendances la plus proche de la structure de
référence sans s’y étre référé.

En outre, notons que le taux d’analyse non abouties car l’étiquetage était non—conforme avec la
grammaire varie de 6 a 35% du meilleur au pire des cas. Un mauvais étiquetage local peut étre la
cause de cette non—conformité. Cependant le score général d’étiquetage étant bon (le meilleur est
de 97.1 en rappel pour 10 choix d’étiquettes), il est évident que la majorité des étiquettes pour
une phrase donnée sont correctes et permettraient d’obtenir une (ou plusieurs) sous—structure(s)
de dépendances correcte(s) pour cette phrase. L’évoluu'on de l’analyseur du CDG Lab ira dans ce
sens : permettre a l’analyseur de produire des structures de dépendances partielles lorsque la
sélection des tétes n’est pas totalement conforme avec la grammaire. La solution partielle pourra
ensuite étre complétée en appliquant une analyse par approximation. Le nombre de structures
de dépendances analysées augmentera et cela permettra d’obtenir de meilleurs taux d’analyses
abouties.

Références

ALFARED, R., BECHET, D. et DIKoVsKY, A. (2011). “CDG Lab” : a Toolbox for Dependency
Grammars and Dependency Treebanks Development. In Proceedings of DEPLING 201 1, pages
272-281.

BANGALORE, S. et JOSHI, A., éditeurs (2010a). Complexity of Lexical Descriptions and its Relevance
to Natural Language Processing : A Supertagging Approach. MIT Press.

BANGALORE, S. et JosHI, A. K. (2010b). Supertagging : Using Complex Lexical Descriptions in
Natural Language Processing. Mit Press.

BAR-HILLEL, Y., GAIFMAN, C. et SHAMIR, E. (1964). On Categorial and Phrase Structure Grammars.
In Language and information, pages 99-115. Addison—Wesley.

122 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
BECHET, D., DIKOVSKY, A. et FORET, A. (2005). Dependency structure grammar. In Proceedings of
LACL 2005, pages 18-34.

CANDITO, M., CRABBE, B. et DENIS, P. (2010). Statistical french dependency parsing : treebank
conversion and ﬁrst results. In Proceedings of LREC 2010, pages 1840-1847.

CLARK, S. et CURRAN, J. R. (2004). The importance of supertagging for wide—coverage ccg
parsing. In Proceedings of COLING 2004, pages 282-288.

DEKHTYAR, M. et DIKOVSKY, A. (2004). Categorial dependency grammars. In Proceedings of
Intern. Conﬁ on Categorial Grammars, pages 76-91.

DEKHTYAR, M. et DIKOVSKY, A. (2008). Generalized categorial dependency grammars. In
Trakhtenbrot/Festschrift, LNCS 4800, pages 230-255. Springer.

DEKHTYAR, M., DIKOVSKY, A. et KARLOV, B. (2012). Iterated dependencies and kleene iteration.
In Formal Grammar 2010/20] 1, LNCS 7395, pages 66-81.

DIKOVSKY, A. (2004). Dependencies as categories. In Proceedings of COLING 2004 Workshop,
"Recent Advances in Dependency Grammars", pages 90-97.

DIKOVSKY, A. (2011). Categorial dependency grammars : from theory to large scale grammars.
In DEPLING 201 1.

FOTH, K., BY, T. et MENZEL, W. (2006). Guiding a constraint dependency parser with supertags.
In Proceedings of COLING 2006, pages 289-296.

LAFFERTY, J., MCCALLUM, A. et PEREIRA, E (2001). Conditional random ﬁelds : Probabilistic
models for segmenting and labeling sequence data. In Proceedings of ICML 2001.

LAVERGNE, 'I‘., CAPPE, O. et Yv0N, E (2010). Practical very large scale CRFs. In ACL 2010.
MEL’cU1<, I. (1988). Dependency syntax: Theory and Practice. State University of New York Press.

NASR, A. (2006). Grammaires de dépendances génératives probabilistes. modele théorique et
application a un corpus arboré du francais. Traitement Automatique des Langues, 46(1):115—153.

NASR, A. et RAMBOW, O. (2004). Supertagging and full parsing. In Proceedings of TAG+7.

NASR, A. et RAMBOW, O. (2010). Non—lexical chart parsing for tag. In (Bangalore et Joshi,
2010a).

RABINER, L. R. (1989). A tutorial on hidden markov models and selected applications in speech
recognition. In Proceedings of IEEE 1989.

RATNAPARKHI, A. (1996). A maximum entropy model for part—of-speech tagging. In Proceedings
ofEMNLP 1996.

SAGOT, B. (2010). The Lefff, a freely available and large—coverage morphological and syntactic
lexicon for French. In Proceedings of LREC 2010.

SARKAR, A. (2010). Combining supertagging and lexicalized tree-adjoining grammar parsing. In
(Bangalore et Joshi, 2010a).

SUTTON, C. et MCCALLUM, A. (2006). An introduction to conditional random ﬁelds for relational
learning. In Introduction to Statistical Relational Learning. MIT Press.

TESNIERE, L. (1959). I§'le'ments de syntaxe structurale. Klincksieck.

123 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

dépendances pourra sélectionner manuellement les dépendances—tétes. Cette sélection des tétes
en amont de l’analyse syntaxique améliore grandement la vitesse d’analyse par rapport a une
analyse automatique a partir des phrases brutes du francais. Nous souhaitons donc remplacer,
pour notre travail, cette sélection des tétes manuelles par une sélection automatique. Cette tache
est similaire a celle d’éu'quetage grammaticale ou d’éu'quetage morphosyntaxique. L’idée d’utiliser
un pré-étiquetage pour réduire l’ambigu'ité et améliorer une analyse syntaxique en dépendances a
déja été exploitée dans ce cadre (Nasr, 2006; Candito et al., 2010). Ici, nous souhaitons mettre en
place un procédé de type supertagging (Bangalore et Joshi, 2010b). La sélection des tétes est en
fait un étiquetage syntaxique des unités lexicales des phrases du francais adapté a la grammaire
catégorielle de dépendance du francais utilisée pour l’analyse en dépendance. Il ne s’agit donc pas
d’apporter des informations grammaticales ou morphosyntaxiques (propres aux unités lexicales)
a l’analyseur mais bien d’apporter des informations syntaxiques qui déﬁnissent des fonctions
binaires entre unités lexicales. La difﬁculté est alors de trouver les bonnes étiquettes syntaxiques
de maniere locale, avec des informations locales, bien que la fonction syntaxique auquelle
l’étiquette référe concerne deux unités lexicales potentiellement distantes. Nous procéderons
alors dans un premier temps a cet étiquetage syntaxique en utilisant la méthode des CRF3
adaptée aux types de dépendances de la grammaire catégorielle de dépendances du francais.
Nous essayons ici d’utiliser une méthode locale pour résoudre un probléme global. Il s’agit de
la principale difﬁculté de cette méthode. Nous souhaitons donc voir si elle permettra d’obtenir
les bonnes dépendances-tétes. Puis nous exécuterons l’analyse en dépendances sur les phrases
ainsi étiquetées pour constater l’effet positif de cet étiquetage sur le temps d’analyse et sur la
production (les structures de dépendances sortantes) de l’analyseur. Pour conclure, nous nous
questionnerons sur la place de cette méthode dans une analyse totalement autonome. Est—elle
sufﬁsante vis—a—vis des résultats obtenus ou peut—elle étre associée a d’autres procédés permettant
de combler les imperfections de cel1e—ci ?

Ce travail s’inscrit dans un travail de plus grande envergure qui comprendra un travail de
découpage des phrases en unités lexicales, ainsi que leur étiquetage grammaticale, un travail
d’éu‘quetage syntaxique précédant celui d’analyse syntaxique en dépendances, puis ﬁnira par un
travail concernant le tri des structures de dépendances en sortie de l’analyseur. Ici nous nous
intéressons en particulier a l’éu'quetage syntaxique. Nous supposons donc avoir en entrée un bon
découpage des phrases en unités lexicales composées ainsi qu’un bon étiquetage grammatical de
ces unités.

2 Grammaires catégorielles de dépendances

Le modele de rammaires cate’ orielles de dé endances est un modele de rammaires similaire

8 8 P 8
aux grammaires catégorielles classiques (Bar—Hillel et al., 1964) auxquelles est ajoutée la notion
de valence polarisée permettant d’introduire les dépendances discontinues. Dans ce modele,
les caté ories sont des es de dé endances et ermettent de re résenter les dé endances
8 P P P P P
projectives tandis que les valences polarisées sont des types de dépendances associées a des
polarités duales (/\et /'\) permettant de représenter les dépendances discontinues (voir
(Dekhtyar et Dikovsky, 2008)). Les régles utilisées par cette classe de grammaires sont présentées
dans la ﬁ ure 1. Les structures de de’ endances roduites a l’aide de ces rammaires sont alors
8 P P 8
des graphes orientés acycliques.

3. Conditional Random Fields en anglais ou champs markovien conditionnels en frangais.

112 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

L1 CPI  |_ |:ﬂ]P1P2

I1 CPI [C*\ﬂ]P2 |_ |:C*\ﬂ]P1P2

01 [c*\x3]” F U31”

D1 aP1(/C)P(\C)P2 |- ap 1P P 2, si (/ C)('\ C) satisfait le principe FA

TABLE 1 — Regles gauches des grammaires cate'gorielles de dépendances. Des regles syme’triques sont
utilise'es dans le cas des derivations (‘z droite. Les regles L, I et (2 perrnettent d’e’liminer les categories
classiques et les catégories itérables (i.e. dérivables infiniement), et de concaténer ou conserver
les valences polarisées en une chaine que l’on appelle potentiel. L’e’limination des valences dans la
derivation (regle D) se fait sur le principe FA (First Available) : les valences duales les plus proches
dans un potentiel sont e’limine'es en premier.

2.1 Données de la grammaire catégorielle de dépendances du francais

Pour notre travail, nous utiliserons une grammaire catégorielle de dépendances du francais
(Dikovsky, 2011). Elle est constituée d’un ensemble conséquent de regles elles—mémes composées
de types de dépendances (les catégories de la grammaire). Ces types de dépendances, 117 au
total, représentent un vaste champ de fonctions syntaxiques exprimant les particularités du
francais. Ces nombreux types de dépendances sont rassemblés en 39 groupes de dépendances
selon leurs fonctions syntaxiques. Par exemple, les dépendances de type objet accusatif (a—obj),
objet datif (d-obj), objet génitif (g—obj) sont réunies dans le groupe des objets : OBJ. Par ailleurs,
les types de dépendances peuvent étre associés a des dépendances discontinues, on en compte 27.
Parmi les types associés aux dépendances discontinues on trouve ceux appartenant aux groupes
des clitiques (CLIT), des modiﬁeurs (MODIF), des réﬂexifs (REFLEX), des coréférences (COREF)
et appositions (APPOS), des éléments de négation (NEG), des aggrégations (AGRR), etc.

En outre, les régles de la grammaire sont associées a des classes grammaticales. Lors d’une
analyse, avec le choix des régles se fait le choix de ces classes grammaticales et des traits
morphologiques des unités lexicales établies en fonction des Valeurs des traits employés par le
Leﬂ‘f4 (Sagot, 2010). On dénombre 185 classes grammaticales.

2.2 CDG Lab : Analyseur en dépendances

Le CDG Lab (Alfared et al., 2011) est un ouu'l de travail dédié a l’analyse en dépendances guidée
par les régles de grammaires catégorielles de dépendances. L’analyseur en dépendances du CDG
Lab propose 3 modes d’analyse différents mais complémentaires :

— l’analyse autonome est un mode perrnettant de lancer l’analyse a partir d’une phrase du francais
sans indiquer manuellement d’informations complémentaires. La phrase est donc découpée
en mots qui sont eux—mémes réassociés en unités lexicales possibles 5. L’analyse (basée sur un
algorithme CYK modiﬁé) est alors exécutée a partir de ce découpage.

— l’analyse par sélection des tétes est un mode semi—automatique. Avant de procéder a l’analyse,
l’ut1'lisateur a la possibilité de choisir les bonnes unités lexicales, leurs classes grammaticales et
leurs dépendances-tétes. L’analyse peut ensuite étre lancée en tenant compte de ces choix.

4. Lexique des formes ﬂéchies du francais.
5. Basées sur Lefff (Sagot, 2010).

113 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

— l’analyse par approximation s’effectue a la suite d’une analyse automatique ou d’une analyse
par sélection des tétes. Elle permet d’annoter positivement ou négativement les attributions des
classes grammaticales et/ou des types de dépendances. Appliqué autant de fois que nécessaire,
ce mode permet de rafﬁner la production de l’analyse : la(les) structure(s) de dépendances
résultante (s).

Le mode qui nous intéresse ici est celui de la sélection des tétes en amont de l’analyse syntaxique
en dépendances. Nous savons que choisir manuellement les dépendances—tétes d’une phrase
avant analyse permet de réduire l’ambigu'1'té en faisant converger l’analyse vers un ensemble de
solutions plus restreint. Les avantages se remarquent au niveau du temps de calcul de l’analyse et
au niveau de la production de l’analyseur, celui—ci produisant moins de structures de dépendances
en sortie. Notons que la sélection des tétes peut se faire au niveau des types de dépendances ou
des groupes de dépendances. On appellera alors respectivement : dépendance-téte ou groupe-
téte, le type ou le groupe de dépendances sélectionné pour une unité lexicale. Nous souhaitons
donc remplacer la sélection manuelle des tétes par une sélection automatique et comprendre
l’apport réel de cette tache avec un algorithme standard d’apprentissage.

2.3 Corpus en dépendances, données grammaticales et syntaxiques

Le corpus que nous utiliserons pour nos expérimentations a été annoté en dépendances semi-
automatiquement grace a l’outil CDG Lab. Il est composé de 2778 structures de dépendances
associées a des phrases du francais provenant de registres variés et comprenant au total 35203
unités lexicales composées. Les dépendances discontinues représentent 4% du nombre total de
dépendances du corpus et elles sont présentes (au moins une fois) dans 41% des structures de
dépendances.

Les types de dépendances utilisés dans la représentation de ces structures correspondent aux types
de la grammaire catégorielle de dépendances du francais. De plus, chaque unité lexicale dans
le corpus est annotée correctement par une classe grammaticale. Pour procéder a l’étiquetage
syntaxique les données utilisées seront :

— les unités lexicales composées

— les dépendances—tétes (ou groupes—tétes)

— les classes grammaticales

Le nombre de classes grammaticales étant important, nous décidons de sous—catégoriser ces
classes pour arriver a deux formes de sous-classiﬁcation : les classes grammaticales simples (28
classes) et les classes grammaticales étendues (86 classes). Une classe grammaticale simple
indique la classe grammaticale d’une unite’ lexicale sans autre information tandis qu’une classe
grammaticale étendue ajoute des informations (parfois sémantiques) potentiellement utiles
syntaxiquement. Les classes grammaticales étendues, plus précises, permettent de mieux cibler
les types et groupes de dépendances comme exposé dans la table 2.

Nombre moyen de types groupes
Par classe simple 13 7
grammaﬁcale étendue 6 4

TABLE 2 — Nombre moyen (et maximum) de types et groupes de dépendances possibles par classe
grammaticale simple ou étendue.

114 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Un exemple, regroupant les données par groupe / type de dépendances et par classe grammaticale
simple et étendue, est donné par la ﬁgure 2.

  

II boit mo'ins 'eau qu' avant .

Unité Dépendance-téte Classe grammaﬁcale
lexicale type groupe simple étendue
[I pred PRED PN PN-pers-n
boit S SENT Vt Vt-ﬁn
moins compar COMPAR Adv Adv-degr-compar
d’ det-p DET Det Det
eau a-obj OBJ N N
qu’ dist-rel REL Conj Conj-comp
avant conj-que CONJ Adv Adv
fs PUNCT FullStop FullStop

FIGURE 2 — Structure de dépendances et tableau rapportant les de’pendances—té‘tes, les groupes—té‘tes,
les classes grammaticales simples et les classes grammaticales e’tendues de chaque unite’ lexicale de la
phrase "11 boit moins d’eau qu’avant." Les classes grammaticales étendues ajoutent des inforrnations
en plus de la classe. Par exemple, Adv—degr—compar et Conj-comp indique un adverbe et une
conjonction qui sont tous deux impliqués dans une comparaison. Pour ce travail, nous n’avons pas
utilise’ les traits de Leﬁf

3 Etiquetage syntaxique

Le probleme de l’étiquetage est un probleme largement étudié dans le domaine du traitement
automatique de la langue naturelle. Les taches d’étiquetage grammatical ou morphosyntaxique
sont les plus répandues mais different de l’étiquetage syntaxique. Néanmoins les outils restent
les memes. Parmi les méthodes existantes pour accomplir la téiche d’étiquetage syntaxique on
trouvera, les modeles graphiques probabilistes tels que les modeles de Markov cachés (HMM)
(Rabiner, 1989), les modeles d’entropie maximale (MEMM) (Ratnaparkhi, 1996) et les champs
markoviens conditionnels (CRF) (Sutton et McCallum, 2006; Lafferty et al., 2001). Pour notre
travail, nous avons choisi d’utiliser ces derniers car ils permettent de prendre en compte plus
d’informations que les HMM et qu’ils sont bien adaptés a l’attribution de séquences d’étiquettes
alors que les MEMM sont plus performants pour la classiﬁcation.

3.1 Logiciel et patrons de traits

Nous avons choisi le logiciel Wapiti (Lavergne et al., 2010) pour entrainer un modele et étiqueter
syntaxiquement notre corpus car il est capable de travailler avec un grand nombre d’étiquettes .
I1 utilise les CRF pour cet entrainement et attribue donc des poids a des traits choisis. Ces traits
peuvent étre extraits a partir de patrons de traits déﬁnis a l’avance. Le logiciel nous laisse la

115 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

possibilité de lui fournir des patrons de traits modiﬁables que nous avons testés.

Comme indiqué dans la partie 2.3, chaque phrase du corpus est décomposée en unités lexicales
elles—mémes étiquetées grammaticalement (par des classes grammaticales simples ou étendues
selon le choix d’expérimentation). Nous disposons donc de ces informations. Nous pouvons
choisir une largeur de fenétre (appliquée autour d’une unité lexicale) pour indiquer si l’on
tient compte des unités lexicales et des classes grammaticales précédentes et suivantes lors de
l’assignation d’une étiquette syntaxique. Nous constatons qu’une fenétre de 5 (2 mots avant, 2
mots aprés) donne de bons résultats, qu’élargir la fenétre a 7 pour les unités lexicales génére
beaucoup de traits pour peu d’améliorations mais qu’élargir la fenétre a 7 autour des classes
grammaticales est beaucoup plus efﬁcace. Il est aussi intéressant d’associer unité lexicale et classe
grammaticale dans un méme trait. Les premiers patrons de traits choisis sont les suivants :

Unité lexicale courante
Unité lexicale récedente de 1
P

Unité lexicale précedente de 2

Unité lexicale suivante de 1

Unité lexicale suivante de 2

Classe grammaticale de l’unité lexicale courante

Classe grammaticale de l’unité lexicale précedente de 1
Classe grammaticale de l’unité lexicale précedente de 2
Classe grammaticale de l’unité lexicale précedente de 3
Classe grammaticale de l’unité lexicale suivante de 1
Classe grammaticale de l’unité lexicale suivante de 2
Classe grammaticale de l’unité lexicale suivante de 3
Unité lexicale courante et sa classe grammaticale

Nous testons aussi quelques traits comme l’extraction du sufﬁxe des unités lexicales (testé pour 2,
3 ou 4 lettres) et le fait de savoir si une unité lexicale commence par une majuscule et retenons
les suivants :

Suﬂixe de 3 lettres de l’unité lexicale courante
L’unité lexicale précédente commence-t-elle par une majuscule?

Notons ici que les traits choisis sont toujours des traits unigrammes, les traits bigrammes générant
trop de traits non pertinants. Cependant, pour chaque trait unigramme, la probabilité qu’il
apparaisse avec chacune des étiquettes possibles est calculée lors de l’apprentissage. L’ensemble de
ces patrons de traits génére alors plus d’un million 5 de traits pour chaque modéle d’apprentissage
et permet d’obtenir de bons résultats d’éu'quetage précisés dans la section suivante.

3.2 Expérimentations et Evaluation

Pour procéder a l’étiquetage syntaxique nous avons divisé le corpus (voir section 2.3) en 10
parties égales. Chaque partie est étiquetée selon un modéle entrainé sur les 9 autres parties.
L’entrainement se fait sur des données parfaitement étiquetées grammaticalement et syntaxi-
quement. La possibilité de choisir des données plus ou moins inforrnatives (classe grammaticale
simple ou étendue; dépendance—téte ou groupe—téte) permet de réaliser 4 expérimentations

6. L’ensemble des patrons de traits génére, au pire, plus de 32000 traits unigrammes différents qui associés aux
différentes possibilités d’étiquettes (au maximum 117 pour les types) produit jusqu’a 3,7 millions de traits.

116 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

différentes. De plus, l’ouu'l Wapiti nous permet d’engendrer1es n meilleurs étiquetages pour une
séquence donnée. Nous avons donc choisi de produire les 10 meilleurs étiquetages syntaxiques
pour chaque phrase d’entrée. Ainsi a chaque experimentation, nous récupérons 10 séquences
d’étiquettes pour chaque phrase du corpus. Ces séquences sont potentiellement assez similaires.
Souvent, seulement quelques étiquettes varient d’une séquence a une autre. Pour évaluer la
qualité de l’étiquetage syntaxique nous considérons les 1, 2, 5 cu 10 meilleures étiquettes de
chaque unité lexicale de chaque phrase du corpus. Les résultats de l’éValuation sont présentés
dans la table 3.

Eﬁquetage des dépendances-tétes
Classes Grammaticales simples Classes Grammaticales étendues

Pré. Rap. Pré. Rap.
Top 1 87.8 87.8 91.1 91.1
Top 2 83.4 90.0 86.5 93.2
Top 5 73.0 92.9 75.1 95.5
Top 10 62.9 94.6 63.6 96.6

Etiquetage des groupes-tétes
Classes Grammaticales simples Classes Grammaticales étendues

Pré. Rap. Pré. Rap.
Top 1 90.4 90.4 91.6 91.6
Top 2 85.6 92.5 86.8 93.7
Top 5 74.3 95.1 75.0 96.0
Top 10 63.3 96.4 63.4 97.1

TABLE 3 — Evaluation de l’e’tiquetage syntaxique produit par Wapiti. D’une part, la pre’cision et le
rappel sont calculés globalement sur toutes les étiquettes. La précision est le nombre d’étiquettes
correctes sur le nombre d’étiquettes diﬁérentes attribuées. Le nombre d’étiquettes diﬁérentes attribuées
varie selon le top, il peut y en avoir 1, de 1 a 2, de 1 a 5 ou de 1 a 10 (on ne compte pas deux
fois la méme étiquette). Le rappel est le nombre d’unite’s lexicales pour lesquelles on a trouve’ la
bonne étiquette (parmi les 1, 2, 5 ou 10 étiquettes attribuées) sur le nombre d’étiquettes du corpus
d’entre’e (i.e. le nombre d’unite’s lexicales). D’autre part, une moyenne de la pre’cision et du rappel
sur les types /groupes de dépendances est aussi calculée (entre parentheses). Dans ce cas, pour chaque
type/groupe, la précision est le nombre d’étiquettes correctement attribuées sur le nombre d’étiquettes
diﬁ‘e’rentes attribuées pour ce type /groupe. Le rappel pour un type/groupe est le nombre d’unite’s
lexicales y appartenant pour lesquelles on a trouvé la bonne étiquette sur le nombre d’étiquettes de ce
type/groupe existantes dans le corpus d’entrée.

Un permier constat face aux résultats d’étiquetage est de voir l’uu'lité des informaﬁons apportées
par les classes grammaticales étendues. De ce cété les résultats sont meilleurs en précision et
en rappel. De maniere plus approfondie, on peut voir que plus on considere d’étiquettes plus
la précision diminue tandis que le rappel augmente. En effet plus on a d’étiquettes différentes
pour une unité lexicale plus on a de chance d’avoir la bonne étiquette parmi celles-ci mais on ne
sait pas de laquelle il s’agit, on perd donc en précision. En fait, les résultats par étiquette varient
grandement. Parmi les 2, 5 cu 10 sequences d’étiquettes pour une méme phrase, seulement
quelques étiquettes varient. Les étiquettes qui ne changent pas (ou peu) 2 chaque séquence sont
globalement "sﬁres" et perdent peu en précision (comme les déterminants DET, la ponctuation

117 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

PUNCT, la négation NEG dans le cas des groupes). Celles qui gagnent fortement en rappel sont
celles qui sont souvent mal attribuées dans la premiere séquence mais que l’on ﬁnit par trouver
dans les suivantes (comme les relations souvent distantes de coréférence COREF ou d’apposition
APPOS). Nous souhaitons voir quel impact a ce gain en rappel sur l’analyse syntaxique en dépen—
dance. Dans la section suivante nous Verrons dans quelle mesure l’étiquetage syntaxique réduit
le temps d’analyse en dépendance et permet d’obtenir une meilleure structure de dépendances
selon les différents criteres d’étiquetage que nous avons établis auparavant.

4 Analyse syntaxique en dépendances et évaluation

4.1 Procédure d’analyse et d’évaluation

Pour procéder a l’analyse syntaxique en dépendances nous souhaitons adapter l’outil d’analyse
par sélection des tétes du CDG Lab pour assigner automatiquement les étiquettes syntaxiques,
trouvées par Wapiti, en tant que dépendances—tétes (ou groupes—tétes). Nous attribuons donc
1, 1 a 2, 1 a 5 cu 1 a 10 types (ou groupes) de dépendances différents a chaque unité lexicale
composée selon les résultats des top 1, 2, 5 et 10 de l’éu'quetage syntaxique. Nous utilisons ici les
meilleurs résultats, c’est a dire ceux trouvés avec les classes grammaticales étendues. L’analyse
syntaxique en dépendances guidée par les régles de la grammaire catégorielle de dépendances
du francais s’éxecute en tenant compte des différentes dépendances-tétes (ou groupes—tétes)
possibles. Le CDG Lab est concu pour produire une liste des structures de dépendances possibles
pour chaque analyse 7. La sélection des tétes permet de réduire l’ambigu'ité en contraignant
l’analyseur a chercher des structures de dépendances dont les types sont en accord avec cette
sélection. Vis—a—vis d’une analyse autonome, ici, le nombre de structures de dépendances en
sortie est moindre. Nous observons donc des temps d’analyse également réduits. Les structures
de dépendances en sortie de l’analyseur ne sont pas triées. Or nous souhaitons avant tout savoir
si parmi les structures de dépendances produites pour une phrase donnée se trouve la bonne
structure de dépendances (i.e. la structure de dépendances associée a cette phrase dans le corpus
en dépendances de référence, 2.3). L’idée est donc de trier ces structures de la plus proche a la
plus éloignée de la structure originale. La plus proche étant celle ayant le plus de dépendances en
commun 8 avec la structure de référence. Les différentes étapes de ce traitement sont illustrées
dans la ﬁgure 3.

Nous nous intéressons alors seulement a la premiere structure de dépendances de chaque liste
(la plus proche de la structure originale). Néanmoins, parfois, il n’existe aucune structure de
dépendances produite. Deux raisons sont possibles :
— les dépendances—tétes (ou groupes-tétes) assignées sont en contradiction avec les regles de la
grammaire, cela entraine alors un échec de l’analyse;
— le temps d’analyse est trop élevé (communément due a la longueur de la phrase), l’analyse
s’interrompt donc avant d’aboutir.
Nous souhaitons donc connaitre le nombre de structures de dépendances obtenues en sortie. Les
résultats de ses expérimentations sont présentés dans la section suivante.

7. En accord avec les dépendances-tétes (ou groupes-tétes) sélectionnées ainsi qu’avec la grammaire.
8. Une dépendance est commune aux deux structures de dépendances si elle possede dans les deux structures le
méme gouverneur, le méme subordonné et le méme type de dépendance.

118 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

    

Corpus GS (frangais) Wipiti CDG LAB
Apprentissage A"a|Y5e|-"'
Grammaire Egiﬁjrgifege Memeure
} Ca'Cé90Fle"e d W structure
de dépendances dépendeances _. de

du Francais ., + ' dé endances
I non-truees _ Olzrcha ue

V pour chaque F|""'e P q

. I Analyse par phrase Pmase

10% VI. Etiqlfetage ‘ selection des tetes

FIGURE 3 — Sche'ma expliquatif du traitement complet. Wapiti est utilise’ pour proce'der 81 l’apprentis—
sage sur 90% du corpus et 61 l’e’tiquetage sur 10%. La partie étiquetée est analysée par l’analyseur du
CDG Lab en tenant compte des de'pendances—tétes (ou groupes—tétes). On obtient plusieurs structures
de dépendances pour chaque phrase qui sont ensuite trie’es selon leur conformite’ avec la structure
originale du corpus de re’fe’rence (ﬁltre). Le traitement est ope’re’ sur chaque partie du corpus.

4.2 Résultats et discussions

Les premiers résultats expose’s dans la table 4 présente les taux d’analyses abouties ainsi que le
nombre d’unités lexicales par phrase et le temps de calcul.

Nous rapportions dans la section 3.2 qu’en ayant plus de choix de tétes pour chaque unité lexicale
nous avions plus de chance d’obtenir la bonne téte parmi ceux-ci. 11 en est de méme pour les
dépendances lorsqu’on laisse entre 1 a 10 choix de tétes pour chaque unité lexicale : ayant plus de
chance d’avoir les bonnes dépendances—tétes (ou groupes—tétes) nous avons aussi plus de chance
d’obtenir une structure de dépendances proche de la structure de dépendances de référence
parmi toutes celles produites. Pour la méme raison, on obtient de meilleurs taux d’analyses
ayant abouti. Dans le meilleur des cas (sélection de 10 étiquettes), nous avons 2548 analyses
sur 2778 (91.7%) ayant abouti dont 2088 ayant trouvé, parmi les structures de dépendances
produites, une structure de dépendances entiérement correcte. Les temps d’analyse augmentent
relativement a l’ambigu'1'té (en obtenant plus de structures de dépendances en sortie) ainsi qu’a la
longueur des phrases. Effectivement les phrases qui sont analysées avec un choix de dix étiquettes
alors qu’e11es ne l’étaient pas avec un choix inférieur sont souvent plus longues car plus difﬁciles
a étiqueter correctement et exploitent plus de temps d’analyse. Par ailleurs, on constate que le
nombre moyen d’unités lexicales par phrase augmente légérement dans le cas des analyses ayant
abouti quand le choix d’e’tiquettes est plus large. Ce qui montre que des phrases plutét longues
qui n’ont pas été analysées avec un seul choix d’étiquettes l’ont été avec plus de choix. Cependant
un nombre d’étiquettes plus important en entrée augmente l’ambigu'1'té de l’analyse et donc le
temps d’analyse. On obtient donc un peu plus de phrases non-analysées par manque de temps
lorsqu’on augmente le choix d’étiquettes.

Lorsque l’on compare les résultats des expérimentations faites avec les dépendances—tétes et
les groupes-tétes, on constate plusieurs points intéressants. Les taux d’analyses abouties sont
meilleurs lorsqu’on utilise les groupes—tétes car on laisse un plus large choix a l’analyseur (les
groupes comprennent parfois plusieurs types de dépendances). Néanmoins on note une différence
au niveau du temps d’analyse qui est inférieur lorsqu’on utilise les dépendances—tétes. En effet,
l’analyseur converge plus Vite. On peut donc Voir qu’il y a moins d’analyses n’ayant pas abouti
par manque de temps mais que le nombre d’analyses n’ayant pas abouti car étant non—conforme

119 © ATALA

