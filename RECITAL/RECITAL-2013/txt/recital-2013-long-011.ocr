TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Extraction_ de_s I_not_s simples dig lexique scientifique
tI'aI1Sd1_SC1p11I1a1l'e dan_s‘1es ecrIts_de sciences
humaines : une premiere experimentation

Sylvain Hatier
LIDILEM, BP 25, 38040 Grenoble Cedex 09

sylvain.hatier@u-grenoble3.fr

RESUME

Nous présentons dans cet article les premiers résultats de nos travaux sur l'extraction de
mots simples appartenant au lexique scientiﬁque transdisciplinaire sur un corpus analysé
morpho-syntaxiquement composé d'articles de recherche en sciences humaines et
sociales. La ressource générée sera utilisée lors de l'indexation automatique de textes
comme ﬁltre d'exclusion aﬁn d'isoler ce lexique de la terminologie. Nous comparons
plusieurs méthodes d'extraction et montrons qu'un premier lexique de mots simples peut
étre dégagé et que la prise en compte des unités polylexicales ainsi que de la distribution
seront nécessaires par la suite aﬁn d'extraire l'ensemble de la phraséologie
transdisciplinaire.

ABSTRACT
EXTRACFION OF ACADEMIC LEXIO0N'S SIMPLE WORDS IN HUMANITIES WRITINGS

This paper presents a ﬁrst extraction of academic lexicon's simple words in french
academic writings in the ﬁelds of humanities and social sciences through a corpus study
of research articles using morpho-syntactic analysis. This academic lexicon resource will
be used for automatic indexing as a stoplist in order to exclude this lexicon from the
terminology. We try various extraction methods and show that a ﬁrst simple words
lexicon can be generated but that multiwords expressions and words distribution should
be taken into consideration to extract academic phraseology.

MOTS-CLES : corpus — écrits scientiﬁques — lexique - phraséologie

KEYWORDS : corpus — scientiﬁc writings — lexicon - phraseology

138 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

1 Introduction

Notre but est la constitution d'une ressource lexicale du lexique scientiﬁque
transdisciplinaire en procédant a son extraction automatique. Ce travail s'inscrit dans le
cadre du projet ANR Contint Termith (Terminologie et Indexation de Textes en sciences
Humaines), dont le but principal est l'indexation automatique d'écrits scientiﬁques en
sciences humaines. Cette indexation requiert l'identiﬁcation de la terminologie aﬁn de
lister les termes les plus signiﬁcatifs pour un document donné, terminologie dont un des
principaux criteres de reconnaissance est la spéciﬁcité (propriété des mots
statistiquement sur-représenté dans un corpus en comparaison d'une référence). Or, les
écrits scientiﬁques font une large part a un autre lexique spéciﬁque, le lexique scientiﬁque
transdisciplinaire, que l'on peut déﬁnir comme le lexique servant a la description et la
présentation de l'activité scientiﬁque (Tutin, 2oo7c). Cela nous amene a identiﬁer ce
lexique, aﬁn de diminuer le bruit qu'il provoque lors de l'indexation automatique en
l'utilisant comme ﬁltre d'exclusion.

Nous nous limiterons ici a l'extraction des mots simples, en nous restreignant aux
catégories syntaxiques des noms et des verbes. Nous testons, a l'instar de (Paquot, 2010),
différentes méthodes statistiques et procédons a une évaluation humaine des extractions
résultantes pour identiﬁer la plus performante. A terme, ces lexiques constitueront une
ressource couvrant l'ensemble de la phraséologie de l'écrit scientiﬁque telles les
expressions polylexicales (collocations, expressions ﬁgées, etc.), et devront étre structurés
selon une typologie restant a déterminer (syntaxique, notionnelle, fonctionnelle,
rhétorique) aﬁn de permettre des applications telles que la caractérisation automatique
de documents, l'aide a la rédaction scientiﬁque (pour natifs ou apprenants),
l'identiﬁcation des segments introducteurs de déﬁnition ou dénomination.

Notre travail est ciblé sur les écrits dans les sciences humaines et sociales, ceci pour
plusieurs raisons. Le projet Termith, auquel nous sommes associé, a comme objet d'étude
les écrits en sciences humaines. La distinction entre lexique scientiﬁque transdisciplinaire
et terminologie est plus complexe pour les sciences humaines que pour les sciences
exactes, dans la mesure ou la frontiere inter-lexiques y est davantage indéterminée. Enﬁn,
dans une optique de développement de ressource a but pédagogique, un tel travail s'avere
particulierement utile en sciences humaines et sociales o1‘1l'écriture académique se révele
plus complexe.

Apres avoir présenté dans un premier temps les caractéristiques de l'écrit scientiﬁque et
des lexiques le composant, nous reviendrons sur les travaux traitant de notre objet de
recherche. Nous détaillerons par la suite la méthodologie d'extraction avant d'analyser les
résultats puis nous conclurons sur les apports et limites de notre procedure.

1.1 Ecrits scientifiques et lexiques associés:

1.1.1 L'écrit scientiﬁque

Le genre de l'écrit scientiﬁque est particulierement normé, homogénéisé. Il est fonction
de la communauté de discours dans laquelle s'inscrit le scripteur et a laquelle est adressé
le discours (Swales, 1990). Dans l'écrit scientiﬁque sont combinés plusieurs types de

139 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

lexique: lexique scientiﬁque transdisciplinaire, lexique « abstrait » général (non
spéciﬁque aux écrits scientiﬁques mais tres fréquent en rapport de la langue générale),
lexique terminologique (lié a la discipline, non traversant), lexique de la langue générale
(déﬁni par exclusion des lexiques précédents). Le lexique scientiﬁque transdisciplinaire
fait donc partie d'un continuum de lexiques aux frontieres ﬂoues, lexiques de langue
spécialisée dont l'univocité et la monosémie ne sont qu'apparentes (Bertels, 2007).
L'extraction d'un lexique commun aux écrits en sciences humaines et sociales, dont la
langue, comme le note (Blumenthal, 2007), est différente de celle des sciences exactes,
nous permet de mieux caractériser la production des savoirs. De plus, cette extraction
participe a concrétiser l'existence d'une communauté de discours qui donne sens a la
notion de « transdisciplinarité ».

1.1.2 Déﬁnition du lexique scientiﬁque transdisciplinaire

A la suite de (Tutin, 2007a), nous déﬁnissons le lexique scientiﬁque transdisciplinaire
(désormais LST) comme le lexique renvoyant au discours sur les objets et les procédures
scientiﬁques. Il est par nature non terminologique, et a pour fonction la désignation des
procédures et outils de l'activité scientiﬁque. (Da Sylva, 2010) le décrit comme abstrait et
largement transdisciplinaire. Pour (Drouin, 2007), le LST se situe au coeur de
l’argumentation et de la structuration du discours et de la pensée scientiﬁque. C'est donc
un lexique méta-scientiﬁque et méta-discursif (c'est-a-dire qui prend pour objet le
discours lui-meme).

Le LST a pour principales propriétés d'étre :

- transversal aux différentes disciplines, donc réparti dans différents corpus
disciplinaires. Ce critere exclut la terminologie, intra-disciplinaire et thématique.

- spéciﬁque a l'écrit scientiﬁque étudié ici, donc absent ou moins fréquent dans la
« langue générale » qui sera représentée dans cette étude par un lexique général du
francais.

Nous présentons ci-dessous un extrait d'article de recherche en psychologie, pour illustrer
les différents lexiques présents dans ce genre d'écrit.

Les segments en gras appartiennent au LST ou au lexique abstrait général, les segments
soulignés a la terminologie.

[...] l’orqanisation matricielle a renforcé et multiplié
les situations de coopération directe tout au long du
processus. Zarifian (1996) estime qu’on a assisté :51 un
changement de paradigme et identifie une << version
faible >> de la coopération qui prévaut dans les
orqanisations traditionnelles de la conception.
L’objectif est d’assurer une bonne coordination du
‘:22/'<‘=1il-1

1Francoise Darses « Résolution collective des problémes de conception >>, Le travail humain
1/2009 (Vol. 72). P. 43-59.

140 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

2 Travaux sur le lexique de1'écrit scientifique

Plusieurs travaux ont porté sur un lexique spéciﬁque aux écrits scientiﬁques,
majoritairement en anglais. (Coxhead, 2002), par exemple, dans un but didactique, a
extrait, en se basant sur les fréquences, une liste de mots anglais. Pour le francais, (Phal,
1971) a analysé ce vocabulaire général d'orientation scientiﬁque sur un corpus de manuels
scolaires et d'ouvrages non universitaires concernant les sciences dures. Peu d'études se
sont donc intéressées a l'écrit scientiﬁque en francais dans le domaine des sciences
humaines et sociales.

Les différences de procédure, de méthodologie, entre sciences expérimentales et sciences
humaines se retrouvent dans les lexiques. Or, la majorité des travaux ont porté sur les
sciences expérimentales, ou sur un mélange de sciences exactes et sciences humaines
(Paquot, 2010).

Nous nous situons dans la continuité des travaux de (Tutin, 2007c), (Drouin, 2007) et
(Da Sylva, 2010), mais en nous appuyant sur un corpus analysé morpho-syntaxiquement
uniquement composé d'articles de recherche et ce, seulement en sciences humaines et
sociales.

Plusieurs types de statistiques sont utilisés dans les travaux cités. Nous reprenons en
partie la méthodologie de (Drouin, 2007) qui combine au critere de fréquence (fréquence
relative dans le corpus d'analyse en comparaison avec un corpus de référence) le critere
de répartition par tranche. Ce critere permet de s'assurer de la répartition d'un mot dans
l'ensemble du corpus et évite ainsi d'extraire des mots certes fréquents mais limités a une
sous-partie du corpus. Contrairement a ces travaux ciblés sur les sciences dures, notre
corpus d'analyse se restreint aux sciences humaines et sociales. De plus, nous avons pour
but la constitution d'un corpus de référence intégrant des textes littéraires,
journalistiques ainsi que des transcriptions de l'oral aﬁn de disposer d'un corpus de
référence le plus large possible.

En plus de ces criteres statistiques de fréquence et de répartition, nous ajoutons un
ﬁltrage des segments répétés (aﬁn de ne pas traiter isolément les mots les constituant) , et
nous nous basons sur un corpus analysé morpho-syntaxiquement. Nous utilisons les
méthodes lexicométriques basées sur les spéciﬁcités du lexique examiné par comparaison
de fréquences, ce qui mene a l'identiﬁcation de particularités lexicales, subdivisées en
spéciﬁcités positives (sur-représentation), négatives (sous-représentation) et banales
(scores comparables) a partir desquelles nous pouvons décomposer, contrastivement, les
différents lexiques constituant notre corpus.

Ces travaux préliminaires devront étre poursuivis en se basant sur un corpus de référence
du francais a large échelle. Le traitement des éléments polylexicaux du LST sera intégré et
une typologie des éléments de notre ressource lexicale devra étre effectuée aﬁn de la
structurer et de permettre des applications didactiques d'aide a la rédaction d'écrits
scientiﬁques.

141 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
3 Méthodologie

3.1 Corpus

Pour garantir une homogénéité maximum, le corpus d'analyse est composé d'articles de
revues préalablement sélectionnées, dont la qualité est vériﬁée par la notation ERIH
et/ou AERES et dont le(s) auteur(s) sont francophones natifs. Nous utilisons une
sous-partie (ultérieurement augmentée) du corpus du projet Scientextz.

Notre corpus d'analyse comporte plus de 3,5 millions de mots et sera étendu pour
atteindre les 5 millions. Les textes ont été formatés au format TEI Lite (Burnard, 1995) et
analysé avec le logiciel Syntex (Bourigault, 2000). Nous utilisons, comme lexique de
comparaison de fréquences, la base de données lexicales lexique3 (New, 2006) qui integre
des informations de fréquence.

Notre corpus d'analyse est précisément composé de 339 articles et de 3 511 716 mots
provenant de dix disciplines des sciences humaines et sociales : anthropologie, économie,
géographie, histoire, linguistique, sciences de l'éducation, sciences politiques, sciences de
l'information, sociologie, psychologie.

3.2 Extraction automatique

Nous avons précédemment déﬁni le LST comme un lexique fréquent, traversant (donc
réparti dans les diverses disciplines) et spéciﬁque aux écrits scientiﬁques (donc plus
fréquent dans ces écrits que dans un corpus de référence). Ces hypotheses sur les
propriétés linguistiques du LST peuvent se traduire sous forme de criteres statistiques
que nous appliquons a notre corpus aﬁn d'extraire les éléments qui nous intéressent.
Nous combinons les criteres suivants :

1. Répartition: le corpus est découpé en 100 tranches de tailles égales. Les mots
extraits doivent apparaitre dans un minimum de 50 tranches, et un minimum de
5 disciplines sur les 10 composant le corpus d'analyse.

2. Fréquence et Spéciﬁté : les éléments doivent étre sur-représenté par rapport au
corpus de référence (spéciﬁcité positive + seuil du nombre d'occurrences minimal
dans l'ensemble du corpus ﬁxé a 100)

3. non-présence systématique dans un segment répété : nous otons a la fréquence
d'un mot simple le nombre d'occurrences des segments répétés dans lesquels il
intervient pour ne pas intégrer des composantes d'unités lexicales qui n'ont pas
d'appartenance autonome au LST (par exemple, point apparait une fois sur deux
au sein du polylexical point de vue et a donc sa fréquence divisée par 2).

4. non-appartenance a une stop-liste ad hoc permettant d'amoindrir le bruit généré
par exemple par les segments en langue étrangere (par exemple l'article anglais
the lemmatisé en nom francais thé)

Nous calculons le critere de spéciﬁcité selon trois formules (ratio de fréquence, chi-carré,
rapport de vraisemblance) aﬁn d'identiﬁer, a l'instar de (Paquot, 2009), la plus adaptée,

2 http://scientext.msh-a|pes.fr
142 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

en confrontant les différentes listes de mots extraits. Plusieurs calculs peuvent étre
envisageables, certains offrent de meilleurs résultats sur les événements rares lorsque
d'autres fonctionnent mieux sur les événements fréquents : (Labbé, 2001) pointe par
exemple la faible efﬁcacité du calcul de spéciﬁcité sur les fréquences basses.

Pour les trois calculs statistiques, nous reprenons les formules décrites par Drouin sur le
site de son logiciel TermoStat3.

Le fait de travailler sur un corpus analysé morpho-syntaxiquement nous permet d'une
part d'effectuer un regroupement ﬂexionnel et ainsi d'amoindrir la dispersion de
fréquence, et d'autre part d'utiliser les relations de dépendances récurrentes aﬁn d'ajouter
aux lemmes extraits des informations d'ordre lexico-syntaxique. Ces relations, utilisées a
ce jour seulement pour contextualiser les mots lors de l'évaluation, devront étre intégrées
a terme dans le processus d'extraction pour la désambiguisation.

La fréquence est utilisée de maniere absolue, par le biais de seuils, pour valider la
présence minimale d'un candidat-LST a l'intérieur d'une discipline et d'une tranche de
corpus dans le corpus d'analyse, et de maniere relative lors de la comparaison a la base de
données qui fait ofﬁce de corpus contrastif.

Comme il n'existe pas a ce jour de lexique de référence pour vériﬁer la validité des mots
extraits comme éléments du LST, cette appartenance est jugée dans le cadre d'une
évaluation effectuée par trois juges experts (chercheurs en linguistique travaillant sur les
écrits scientiﬁques), dont la tache est présentée dans la section suivante.

3.3 Evaluation

Nous avons créé deux listes, une de 100 verbes et une de 100 noms, compilant les
résultats d'extraction des trois différents calculs, en prenant soin de représenter les
tranches hautes, moyennes et basses pour chacun d'eux.

Les juges avaient pour consigne de classer ces 200 candidats-LST monolexicaux dans 3
lexiques :

- LST : lexique scientiﬁque transdisciplinaire et lexique abstrait général
- LT : lexique terminologique

- LG : lexique de la langue générale

Ils devaient classer chaque mot dans un lexique au minimum et dans tous au maximum :
ceci pour tenir compte de la difﬁculté a circonscrire ces lexiques comme le note (Tutin,
2oo7b).

3Université de Montréal. Patrick Drouin

http:[[o|st.|ing.umontrea|.ca[~drouinp[termostat webldoc termostaydoc termostat.htm|
[consu|té Ie 22/03/2013]

143 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Candidat LST LT LG Rel() Contexte
illustrer_V + - - exemp1e_N_SUJ Cet exemple paradigmatique illustre le
cas_N_SUJ choix que nous faisons [...]
synthese_N + - - proposer_V_OBJ [...] la seconde propose une synthese
réaliser_V_O BJ des principales interventions [...]

TABLEAU 1 — Exemple de grille d'évaluation

Dans cet extrait de grille d'évaluation, la premiere colonne présente le candidat-LST sous
sa forme lemmatisée suivie de son étiquette de catégorie syntaxique (N pour nom et V
pour verbe).

Les deux dernieres colonnes, rel() et contexte, ont pour fonction d'aider a la décision en
apportant une recontextualisation des candidats-LST.

La colonne rel() indique les deux associations lexico-syntactiques les plus fréquentes,
c'est a dire les couples mot-relation syntaxique les plus fréquemment reliés au
candidat-LST (apres ﬁltrage des relations peu informatives sur le contexte, telles celles
impliquant un verbe auxiliaire ou un pronom). Y sont détaillés le cooccurrent syntaxique,
par son lemme et sa catégorie, suivi du type de la relation (objet ou sujet par exemple).

La derniere colonne contexte permet la visualisation d'une phrase contenant l'association
lexico-syntaxique la plus fréquente impliquant le candidat-LST.

4 Résultats

4.1 Analyse des évaluations

Pour les verbes, les 3 juges sont en accord sur 68 des 100 candidats (55 sont validés, 13
sont invalidés comme élément du LST). De plus, 27 verbes sont validés par 2 des 3 juges.

Pour les noms, les 3 juges sont en accord sur 79 des 100 candidats-LST (55 sont validés,
24 sont invalidés). 21 noms sont validés par 2 des 3 juges. Dans le tableau ci-dessous, un
+ représente la validation d'un juge sur l'appartenance au LST, un - représente la
non-validation en tant qu'élément du LST.

Appartenance au LST + + + + + - - - - - - + Accord a 3
Verbes 55 27 13 5 68
Noms 55 21 24 o 79

TABLEAU 2 — Résultats d'évaluation
144 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
Ces faibles pourcentages d'accord s'expliquent par deux principaux facteurs :

0 L'objet d'étude, le LST, est un lexique a frontiere ﬂoue, inscrit dans un continuum
de lexiques. I1 existe ainsi une grande variabilité quant a sa perception selon le
juge.

0 Les mots s'étudient en contexte. L'apport des associations lexico-syntaxiques
récurrentes et la mise en contexte phrastique ne permettent pas une
désambigu'isation systématique des différentes acceptions des candidats-LST.

Cette premiere observation sur l'évaluation met en lumiere la difﬁculté de circonscrire
notre objet d'étude, partie d'un continuum qu'il nous faut discrétiser en vue de
l'extraction. L'évaluation doit étre complétée par une tache d"annotation en contexte, ce
qui permettrait une évaluation précise du silence occasionné par notre méthode
d'extraction.

De plus, les cas problématiques d'évaluation sont le plus souvent lies a des mots au sens
vague entrant dans des collocations tel formuler dans formuler une hypothe‘se. L'ajout
futur d'une phase de traitement des expressions polylexicales permettra d'éviter cet
écueil.

La difﬁculté majeure se situe au niveau de la frontiere entre LST et lexique de la langue
générale : dans tous les cas o1‘1 les juges ont validé l'appartenance d'un mot a plusieurs
lexiques, les lexiques concernés étaient le LST et le lexique de la langue générale.

4.2 Analyse par méthodes statistiques

Nous comparons ci-dessous les 3 formules statistiques utilisées étudiant plus
particulierement les cas o1‘1 les trois juges sont en accord sur l'appartenance ou non d'un
élément au LST.

Nous observons les rangs d'extraction, parmi les trois calculs utilisés, des différents mots
de nos listes (validés ou non), le mot de rang 1 étant considéré comme l'élément le plus
caractéristique du LST selon le critere de spéciﬁcité positive. Les trois calculs que nous
utilisons ne donnent pas d'indice certain sur l'appartenance ou non au LST pour un
candidat-LST extrait d'apres les criteres détaillés dans la partie précédente (fréquence
haute et répartition large). Par exemple revenu est un candidat-LST invalidé par les 3
juges, et classé 82”“ selon le ratio, 87”” selon le rapport de vraisemblance et 79é"’e selon le
chi-carré. Nous ne pouvons cependant pas conclure sur l'appartenance au LST des
candidats-LST ayant un rang inférieur ou supérieur a celui de revenu : cout, candidat-LST
invalidé, a un rang entre 7 et 13 selon les calculs, alors que argument, candidat-LST
validé, a un rang entre 214 et 235.

Des mots a spéciﬁcité positive, traversant les disciplines, peuvent donc étre éléments du
LST (argument, méthode, expliquer) ou du lexique de la langue générale ou du lexique
terminologique (cout, mobilisation, multiplier). Méme si 158 des 200 mots sont validés
par au moins 2 juges sur 3, le critere de spéciﬁcité ne sufﬁt pas a conﬁrmer ou inﬁrmer
l'hypothese d'appartenance au LST. La prise en compte de la fréquence des segments
répétés permet d'éliminer certains composants de ces segments mais ne peut gérer les cas
d'expressions polylexicales acceptant des modiﬁeurs et donc sujettes a des variations.

145 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

En examinant la répartition des occurrences par discipline, nous pouvons dégager un
probleme récurrent lié aux acceptions variées que peut recouvrir un mot. Par exemple, le
nom emit a une fréquence totale (dans les 10 disciplines combinées de notre corpus
d'analyse) de 976 occurrences, dont 688 dans le seul sous-corpus d'économie, et entre 10
et 80 dans les 9 autres disciplines. En calculant l'écart-type, ce phénomene de
sur-présence dans une discipline serait identiﬁé et nous pourrions alors différencier la
fréquence du mot dans son acception générale de sa fréquence dans son acception
disciplinaire. D'autres exemples plus complexes peuvent étre rencontrés, par exemple le
cas de sujet: il peut avoir plusieurs sens disciplinaires (Le sujet de la phrase en
linguistique, Le sujet de l'expérience en psychologie) ou un sens transdisciplinaire (Le
sujet de l'article).

Nous pouvons donc observer qu'aucun calcul n'est sufﬁsant pour valider ou invalider de
facon certaine un candidat-LST. La ﬁxation d'un seuil ou d'un rang engendre un silence et
un bruit trop importants pour ne tenir compte que de ce critere. Nous privilégierons donc
la méthode la plus simple, a savoir le ratio de fréquence, et ajouterons le calcul de
l'écart-type aﬁn de diminuer le bruit occasionné par les mots a multiples acceptions dont
l'une est sur-représentée dans une discipline.

Malgré les apports certains des techniques lexicométriques, celles-ci ne sont pas
sufﬁsantes pour extraire automatiquement les mots simples du LST. Une prise en compte
de la distribution est nécessaire, que ce soit en vue de la gestion des éléments polylexicaux
ou pour la discrimination des diverses acceptions que peut recouvrir un candidat-LST.

Enﬁn, l'absence d'un lexique de référence du LST, a grande échelle, nous impose une
évaluation humaine et ne permet pas de confronter les résultats d'extractions dans leur
totalité (nous avons sélectionné 200 mots parmi plus de 1000 composant nos différentes
listes) pour quantiﬁer précisément le bruit et le silence générés.

5 Conclusion et perspectives

Nous avons pu, en combinant méthodes statistiques et informations morpho-syntaxiques,
procéder a une premiere extraction des mots simples du lexique scientiﬁque
transdisciplinaire dans les articles de recherche en sciences humaines et sociales.

Ces premiers résultats, intéressants du strict point de vue des mots simples, soulignent
l'importance de la prise en compte de leur contexte d'apparition, aﬁn de gérer le cas des
expressions polylexicales (pour ﬁltrer les mots simples non autonomes), et pour identiﬁer
les cas de polysémie et ainsi discriminer les différentes acceptions, transdisciplinaires ou
non. La prise en compte de l'écart-type au niveau de la répartition des fréquences
intra-disciplinaires est une piste d'identiﬁcation de ces phénomenes, la distribution en
étant une autre, par exemple a l'aide des cooccurrents de deuxieme ordre (Bertels 2012).

Le traitement automatique des expressions polylexicales devra étre la prochaine étape,
étant donné leur part importante dans le LST (Pecman, 2007).

Les travaux de (Kister, 2012) sur le lien syntaxique récurrent entre lexeme scientiﬁque
transdisciplinaire et terme sont également une piste pour identiﬁer l'acception
transdisciplinaire d'un élément ambigu.

146 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

L'étape d'évaluation (que nous effectuerons avec plus de juges) devra étre remaniée sur
deux principaux points :

- Une plus grande recontextualisation des candidats-LST via un plus grand nombre
d'exemples phrastiques et d'associations lexico-syntaxiques récurrentes.

- Un travail d'annotation manuelle sur corpus pour évaluer précisément le silence.

Dans l'optique d'afﬁner les calculs de spéciﬁcité, la constitution d'un corpus contrastif
« hybride » de grande échelle, intégrant une partie orale, journalistique, et littéraire, sera
nécessaire. Le travail ici présenté utilise pour l'étude contrastive une base de donnée ne
permettant pas les comparaisons distributionnelles ou la recherche de segments répétés.

Notre corpus d'analyse suivant le format TEI Lite, les informations de structure textuelle
pourront étre croisées avec les fréquences pour caractériser les parties textuelles d'un
article : quel est le lexique le plus présent dans les résumés, conclusions, en regard par
exemple des observations sur la prédominance de la terminologie dans les introductions
(Rinck, 2010).

Au niveau théorique, l'extraction aura pour but une analyse ﬁne de la phraséologie (au
sens large des combinaisons récurrentes et stabilisées) des écrits en sciences humaines et
sociales menant a une description de ce type d'écrit. Par ailleurs, compte tenu de la
difﬁcile acquisition du métadiscours propre a la production scientiﬁque, une application
didactique d'aide a la rédaction pourrait proﬁter d'une ressource lexicale structurée du
LST.

Remerciement

Nous remercions la région Rhone-Alpes qui ﬁnance nos travaux de recherche, le projet
ANR-Contint Termith, Olivier Kraif pour son aide précieuse sur les aspects
lexicométriques ainsi que les relecteurs pour leurs nombreux conseils.

6 Références

BERTELS, A. et GEERAERTS, D. (2012). L’importance du recoupement des cooccurrents de
deuxieme ordre pour étudier la corrélation entre la spéciﬁcité et la monosémie. Actes de
JADT 2012, 135-147.

BLUMENTHAL, P. (2007). Sciences de l'Homme vs sciences exactes: combinatoire des mots
dans la vulgarisation scientiﬁque. Revue francaise de linguistique appliquée, 12(2),
15-28.

BOURIGAULT, D., FABRE, C., FREROT, C., JACQUES, M. P., et OzD0wsKA, S. (2005). Syntex,
analyseur syntaxique de corpus. In Actes des 12émes journées sur le Traitement
Automatique des Langues Naturelles.

BURNARD, L., et SPERBERG-MCQUEEN, C. M. (1995). TEI lite: An introduction to text encoding

147 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
for interchange (pp. 23-152). SURFnet.

COXHEAD, A. (2002), The academic word list: a corpus-based Word List for Academic
Purposes in Teaching and Language Corpora (TALC) 2000 Conference Proceedings.
Atlanta : Rodopi.

DA SYLVA, L. (2010), Extraction semi-automatique d’un Vocabulaire savant de base pour
1’indexation automatique , Actes de TALN 2010, 2010.

DROUIN, P. (2007). Identiﬁcation automatique du lexique scientiﬁque
transdisciplinaire. Revue francaise de linguistique appliquée, 12(2), 45-64.

EVERT, S. (2008). Corpora and collocations. Corpus Linguistics. An International
Handbook, 2.

KISFER, L., et JACQUEY, E. (2012). Relation syntaxiques entre lexique terminologique et
transdisciplinaire: analyse en texte intégral. CMLF 2012.

LABBE C. et LABBE D. (2001). Que mesure la spéciﬁcité du vocabulaire?, Lexicometria, no 3,
23 p.
NEW, B., PALLIER C., FERRAND L. et MATOS R. (2001) Une base de données lexicales du

francais contemporain sur internet: LEXIQUE, L'Année Psychologique, 101, 447-462.
http://www.lexique.org [consulté 1e 22 / 03/ 2013]

PAQUOT, M. et BESTGEN, Y. (2009). Distinctive words in academic writing: A comparison of
three statistical tests for keyword extraction. Language and Computers, 68(1), 247-269.

PAQUOT, M. (2010). Academic vocabulary in learner writing: From extraction to analysis.
Continuum.

PECMAN M. (2004), Phraséologie contrastive anglais-francais : analyse et traitement en vue
de l’aide a la rédaction scientiﬁque. These de doctorat. 9 déc. 2004. Dir. Henri Zinglé.
Université de Nice-Sophia Antipolis. 467p.

PECMAN, M. (2007). Approche onomasiologique de la langue scientiﬁque générale. Revue
francaise de linguistique appliquée, 12(2), 79-96.

PHAL, A. (1971), Vocabulaire général d'orientation scientiﬁque (V.G.O.S) — Part du lexique
commun dans l'expression scientiﬁque ». Paris : Didier, Crédif

Rmcx, F. (2010), L'analyse linguistique des enjeux de connaissance dans le discours
scientiﬁque, Revue d 'anthropologie des connaissances 3/2010 (V014, n° 3), p. 427-450.

SWALES, J. (1990). Genre Analysis: English in Academic and Research Settings:
Cambridge Applied Linguistics. Cambridge University Press.

TUTIN, A. (2007a). Modélisation linguistique et annotation des collocations: une
application au lexique transdisciplinaire des écrits scientiﬁques. Formaliser les langues
avec l'ordinateur: actes des sixiemes, Soﬁa 2003, et septie‘mes, Tours 2004, journées
Intex-Nooj, 3, 189.

TUTIN, A. (2007b). Autour du lexique et de la phraséologie des écrits scientiﬁques. Revue
francaise de linguistique appliquée, 12(2), pages 5-14.

148 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

TUTIN, A. (2oo7c). Traitement sémantique par analyse distributionnelle des noms
transdjsciplinaires des écrits scientiﬁques.Actes de Traitement Automatique des
Langues Naturelles (TALN), pages 283-292.

TUTIN, A., GROSSMANN, F., FALAISE, A. et KRAIF, O. (2009). Autour du projet Scientext: étude
des marques linguistiques du positionnement de 1’auteur dans les écrits
scientiﬁques. Actes des éesjournées de linguistique de corpus.

149 © ATALA

