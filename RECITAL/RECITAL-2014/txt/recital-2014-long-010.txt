[P-R.1]
21Ã¨me Traitement Automatique des Langues Naturelles, Marseille, 2014
MÃ©thodes par extraction pour le rÃ©sumÃ© automatique de conversations parlÃ©es
provenant de centres dâ€™appels

JÃ©rÃ©my Trione1
(1) Aix-Marseille UniversitÃ©, CNRS, LIF UMR 7279, 13000, Marseille, France
Jeremy.trione@lif.univ-mrs.fr
RÃ©sumÃ©.         Dans ce papier nous traitons des rÃ©sumÃ©s automatiques de conversations parlÃ©es spontanÃ©es. Pour cela
nous utilisons des conversations provenant de cas rÃ©els dâ€™appels tÃ©lÃ©phoniques de centre dâ€™appels issues du corpus
DECODA. Nous testons des mÃ©thodes extractives classiques utilisÃ©es en rÃ©sumÃ© de texte (MMR) ainsi que des mÃ©thodes
basÃ©es sur des heuristiques du dialogue dans le cadre des centres dâ€™appels. Il sâ€™agit de la sÃ©lection du tour de parole le
plus long dans le premier quart de la conversation, dans lâ€™ensemble de la conversation et dans le dernier quart de la
conversation. Lâ€™ensemble est Ã©valuÃ© avec la mÃ©trique ROUGE. Les rÃ©sultats obtenus soulignent les limites de ces
approches Â« classiques Â» et confirment la nÃ©cessitÃ© dâ€™envisager des mÃ©thodes abstractives intÃ©grant des informations de
structures sur les conversations. En effet, ces premiers rÃ©sultats montrent que les mÃ©thodes heuristiques basÃ©es sur la
structure produisent des rÃ©sultats comparables, voir meilleurs que des mÃ©thodes telles que MMR.

Abstract. In this paper we speak about automatic spoken conversation summaries. We use conversation from some
real cases call from a call center extracted from the DECODA corpus. We test some extractive summary methods used in
text summary (MMR) and some dialogue heuristics methods. Itâ€™s mainly to select the longest speaker turn in different
part of the dialogue, the first quarter, the whole dialogue, and the last quarter of the dialogue. All the results are evaluated
thanks the ROUGE software. The results show the limits of these classical approaches and suggest that we need some
abstractive methods including some structural features of the conversation. In fact, these results show that the structural
heuristics based methods are even or better than the classic method like MMR.

Mots-clÃ©s : RÃ©sumÃ© de conversations parlÃ©es, rÃ©sumÃ© par extraction, ROUGE, corpus DECODA, MMR.
Keywords: spoken conversation summarization, extractive summary, ROUGE, DECODA corpus, MMR.
1     Introduction
Dans les centres dâ€™appels, lâ€™Ã©tude des traces (ou Â« logs Â») dâ€™interaction entre conseillers et clients permet dâ€™Ã©valuer le
travail des conseillers tÃ©lÃ©phoniques afin dâ€™optimiser les relations avec les usagers, ou encore faciliter la recherche
dâ€™informations sur lâ€™ensemble des appels pour dÃ©tecter dâ€™Ã©ventuels problÃ¨mes et extraire des statistiques sur les besoins
des usagers du service. Aujourdâ€™hui seule une infime partie des donnÃ©es recueillies dans les centres dâ€™appels est utilisÃ©e
pour les tÃ¢ches citÃ©es au-dessus (moins de 1%). Le traitement automatique de ces conversations et notamment la
gÃ©nÃ©ration de rÃ©sumÃ©s pourrait alors permettre de gÃ©nÃ©raliser les traitements et ainsi amÃ©liorer les services proposÃ©s. Dans
la suite de cet article nous nous intÃ©resserons donc Ã  la gÃ©nÃ©ration de rÃ©sumÃ©s de conversations tÃ©lÃ©phoniques provenant
de centres dâ€™appels.
Le corpus RATP-DECODA1 contient des transcriptions de conversations entre des usagers et des conseillers de la RATP.
Il contient Ã©galement des rÃ©sumÃ©s de ces conversations, sous la forme de Â« synopsis Â» de quelques lignes, Ã©tablies par des
experts de ce service Ã  des fins dâ€™analyse. Lâ€™Ã©tude prÃ©sentÃ©e dans cet article consiste Ã  comparer ces synopsis Ã  des
rÃ©sumÃ©s produits par des mÃ©thodes classiques de rÃ©sumÃ©s automatiques de texte par extraction. En analysant les limites
1   http://sldr.org/sldr000847/fr
104

[P-R.1]
METHODES PAR EXTRACTION POUR LE RESUME AUTOMATIQUE DE CONVERSATIONS PARLEES PROVENANT DE CENTRES
Dâ€™APPELS

de ces systÃ¨mes, nous justifions la nÃ©cessitÃ© dâ€™enrichir les systÃ¨mes automatiques avec des informations de structure sur
les conversations dans la perspective produire des rÃ©sumÃ©s par abstraction.

2    Etat de lâ€™art
De faÃ§on gÃ©nÃ©rale on peut identifier deux types de rÃ©sumÃ©s, les rÃ©sumÃ©s extractifs et les rÃ©sumÃ©s abstractifs. Le rÃ©sumÃ©
extractif est aujourdâ€™hui lâ€™approche la plus rÃ©pandue, elle consiste Ã  pondÃ©rer les phrases selon leur reprÃ©sentativitÃ© (Li,et
al, 2006). Le rÃ©sumÃ© abstractif consiste Ã  extraire des informations ou des notions du document Ã  rÃ©sumer afin de rÃ©diger
un tout nouveau texte. Ces informations peuvent Ãªtre par exemple des concepts dâ€™opinions (Ganesan et al, 2010).

La plupart des travaux rÃ©alisÃ©s sont des rÃ©sumÃ©s extractifs, certains traitent des journaux tÃ©lÃ©visÃ©s (Ribeiro et Martins de
Matos, 2007), dâ€™autres concernent des rÃ©sumÃ©s de rÃ©unions comme les travaux de G. Murray (2008), en se basant sur le
corpus des rÃ©unions de lâ€™ICSI2 (Janin. et al, 2003) et AMI3 (Carletta et al, 2006). Il base ses premiÃ¨res expÃ©riences sur
des systÃ¨mes de rÃ©sumÃ©s de textes classiques (en utilisant une version modifiÃ©e de MMR), ainsi que sur des approches
basÃ©es sur la structure des rÃ©unions. De la mÃªme faÃ§on des travaux ont Ã©tÃ© rÃ©alisÃ©s sur le rÃ©sumÃ© dâ€™e-mails comme G.
Murray (2008) ou encore J. Lin (2007) principalement sur le corpus dâ€™e-mails dâ€™Enron. Ici deux approches sont Ã©tudiÃ©es,
le rÃ©sumÃ© de lâ€™ensemble des e-mails dâ€™une conversation, et le rÃ©sumÃ© des e-mails individuellement. J. Lin et al (2008)
utilisent un modÃ¨le probabiliste basÃ© sur la mÃ©thode de sentence compression (K. Knight et D. Marcu, 2000). Dâ€™autres
travaux rÃ©alisÃ©s par Xiaodan Zhu et Gerald Penn (2006) portent sur le rÃ©sumÃ© de conversations spontanÃ©es, ils utilisent
les donnÃ©es de SWITCHBOARD, qui contiennent des conversations annotÃ©es manuellement. Ils utilisent des mÃ©thodes
de rÃ©sumÃ©s classiques (i.e. MMR) ainsi que des heuristiques de localisation, de prosodie ou de disfluence. Enfin des
recherches concernent aussi le rÃ©sumÃ© de cours dâ€™enseignement oraux (Togashi, 2006) en utilisant aussi des transcriptions
manuelles et automatiques et en prenant en compte dâ€™autres concepts audio comme la prosodie pour la gÃ©nÃ©ration de
rÃ©sumÃ©s. Dans cette Ã©tude aussi il est question dâ€™utiliser des techniques de rÃ©sumÃ©s de textes classiques, ainsi que des
informations structurelles mais aussi des informations sur lâ€™audio (prosodie et disfluences). Nous noterons aussi que
lâ€™ensemble de ces Ã©tudes a Ã©tÃ© Ã©valuÃ© grÃ¢ce Ã  la mÃ©trique ROUGE.

3    Corpus
Dans le cadre de notre Ã©tude notre corpus sera composÃ© de 200 conversations tÃ©lÃ©phoniques issues dâ€™un centre dâ€™appels
de la RATP. Ces appels proviennent du corpus du projet DECODA 4 (Bechet, et al. 2012). Chaque conversation est
disponible en version audio et textuelle, les transcriptions utilisÃ©es ont Ã©tÃ© rÃ©alisÃ©es manuellement.

Ces conversations ont Ã©tÃ© recueillies dans un centre de la RATP sur une pÃ©riode dâ€™une journÃ©e. Etant donnÃ© quâ€™elles ont
Ã©tÃ© enregistrÃ©es Ã  partir dâ€™un centre dâ€™appels de transport, elles traitent de tous sujets se rapportant de prÃ¨s ou de loin au
transport. Cela va de la demande dâ€™itinÃ©raire, aux oublis dâ€™objets sur le rÃ©seau, en passant par des plaintes de
fonctionnement. Ci-dessous le tableau regroupe les dix sujets dâ€™appel les plus courants :

Raison de lâ€™appel        %
Info trafic          22.5
ItinÃ©raire          17.2
Objets trouvÃ©s/perdus      15.9
Souscription aux forfaits   11.4
Horaires             4.6
Billets            4.5
Appels spÃ©cialisÃ©s        4.5
Aucun sujet particulier     3.6
Nouvel enregistrement       3.4
Information tarifaire      3.0

TABLE 1 : Top 10 des sujets dâ€™appels sur le corpus DECODA.
2   International Computer Science Institute
3   https://www.idiap.ch/dataset/ami/
4   DEpouillement automatique de Conversation provenant de centre Dâ€™Appels : http://decoda.univ-avignon.fr/
105

[P-R.1]
METHODES PAR EXTRACTION POUR LE RESUME AUTOMATIQUE DE CONVERSATIONS PARLEES PROVENANT DE CENTRES
Dâ€™APPELS

Notons que la rÃ©partition de ces sujets reste la mÃªme sur les 200 conversations choisies au prÃ©alable.

La durÃ©e de lâ€™appel varie entre 55 secondes pour les plus courts et 16 minutes pour les plus longs. Le tableau ci-dessous
regroupe plus de dÃ©tails en ce qui concerne la taille du corpus en termes de mots.

En moyenne par conversation   Sur lâ€™ensemble du corpus
Nombre de mots                   414.1                         82819
Nombre de phrases                  66.8                         13351

TABLE 2 : DÃ©tails structurels sur le corpus de DECODA

Afin dâ€™enrichir ce corpus pour notre Ã©tude, chaque conversation sâ€™est vu attribuer un minimum de deux rÃ©sumÃ©s rÃ©alisÃ©s
par deux annotateurs diffÃ©rents. Le premier est un expert du domaine ayant rÃ©alisÃ© un premier jeu de synopsis afin de se
repÃ©rer dans les conversations traitÃ©es. Le second annotateur est un Ã©tudiant nâ€™ayant aucune notion particuliÃ¨re dans la
rÃ©alisation de rÃ©sumÃ©. Dans un premier temps aucune contrainte nâ€™a Ã©tÃ© donnÃ©e aux annotateurs, que ce soit des contraintes
de temps, de langue ou autre. Le but Ã©tait dâ€™observer dans quelle mesure les synopsis de chacun pouvaient diffÃ©rer et si
des schÃ©mas se retrouvaient entre les individus.

La principale contrainte qui nous concernait Ã©tait la taille, aprÃ¨s lâ€™Ã©tude des 400 premiers synopsis recueillis nous avons
obtenu une taille moyenne pour les rÃ©sumÃ©s de 6% Ã  7% de la taille de la conversation originale (cette taille est basÃ©e sur
le nombre de mots de la conversation et du synopsis). De cette seule contrainte dÃ©coule plusieurs autres. Par exemple le
langage utilisÃ© ne devra pas forcÃ©ment suivre une syntaxe trÃ¨s poussÃ©e, les phrases simples et courtes seront alors
privilÃ©giÃ©es par les annotateurs, de la mÃªme faÃ§on la quantitÃ© de dÃ©tails rapportÃ©s sera elle aussi limitÃ©e par la taille du
document, effectivement seule lâ€™information principale devra remonter sous peine de dÃ©passer la limite de taille imposÃ©e
prÃ©cÃ©demment.

Ci-dessous est prÃ©sentÃ© un exemple de conversation que lâ€™on peut trouver dans le corpus RATP-DECODA.

Usager : allÃ´ bonjour monsieur monsieur je m'excuse de vous dÃ©ranger je vous appelle de la Haute-Loire pourriez-
vous m'indiquer s'il vous plaÃ®t le bus qui correspond de la Gare de Lyon Ã  la Gare heu Montparnasse ?

Conseiller : alors vous avez le 91 Madame

Usager : c'est le 91 ?

Conseiller: oui

Conseiller : Gare de Lyon Gare Montparnasse ce sera le 91

Usager : d'accord Monsieur

Conseiller : oui

Usager : et c'est une ligne directe donc ?

Conseiller : c'est une ligne directe tout Ã  fait

Usager : vous Ãªtes trÃ¨s gentil monsieur je vous remercie

Conseiller : je vous en prie

Usager : bonne journÃ©e au revoir

Conseiller : au revoir Monsieur bonne journÃ©e

Usager : au revoir

Conseiller : merci au revoir
TABLE 3 : Exemple de conversation du corpus DECODA
106

[P-R.1]
METHODES PAR EXTRACTION POUR LE RESUME AUTOMATIQUE DE CONVERSATIONS PARLEES PROVENANT DE CENTRES
Dâ€™APPELS
4     RÃ©sumÃ©s de conversations
En partant de ce qui existe dans la littÃ©rature pour les textes, et en se basant sur quelques heuristiques du dialogue
concernant la position de lâ€™information au sein dâ€™une conversation issue dâ€™un centre dâ€™appels, nous appliquons des
mÃ©thodes classiques utilisÃ©es en rÃ©sumÃ© automatique, lâ€™ensemble de ces mÃ©thodes constitue ce que nous appellerons
baseline. Les conversations utilisÃ©es sont issues du corpus du projet DECODA. Ce sont des conversations spontanÃ©es,
provenant de cas concrets et rÃ©els (câ€™est-Ã -dire non jouÃ©s par des acteurs) entre des utilisateurs de la RATP5 et les
conseillers tÃ©lÃ©phoniques.

DÃ©finissons dans un premier temps ce quâ€™est une conversation dans cette Ã©tude ainsi que le rÃ©sumÃ© qui peut lui Ãªtre
associÃ©.

4.1    Conversation

La dÃ©finition la plus classique dâ€™une conversation, serait : un Ã©change dâ€™informations entre au moins deux individus
portant sur un ou plusieurs sujets prÃ©cis. Dans notre cas la partie qui va nous intÃ©resser concerne lâ€™Ã©change dâ€™informations.
En effet dans le cadre de la rÃ©daction dâ€™un rÃ©sumÃ©, la dÃ©tection des informations importantes et intÃ©ressantes est
primordiale.

Dâ€™un point de vu structurel, le dÃ©coupage dâ€™une conversation ne peut pas se faire grÃ¢ce Ã  des phrases, puisque la notion
mÃªme de phrase est difficilement dÃ©finissable au sein dâ€™une conversation, ceci Ã©tant dÃ» Ã  lâ€™absence de ponctuation
concrÃ¨te. Pour nous donner alors une unitÃ© de dÃ©coupage, nous utiliserons le tour de parole. On appelle tour de parole le
laps de temps pendant lequel un interlocuteur sâ€™exprime. Chaque tour de parole sera alors susceptible de contenir une
certaine quantitÃ© dâ€™informations relatives Ã  la conversation.

Ã€ la diffÃ©rence dâ€™un texte classique (câ€™est-Ã -dire rÃ©digÃ© et rÃ©flÃ©chi) une conversation est un Ã©change spontanÃ© entre
individus, de ce fait les informations au sein de celle-ci peuvent Ãªtre altÃ©rÃ©es par de nombreux phÃ©nomÃ¨nes directement
liÃ©s Ã  la spontanÃ©itÃ©. Ce caractÃ¨re spontanÃ© de la conversation introduit du bruit dans les donnÃ©es, il sâ€™agit par exemple de
nombreuses rÃ©pÃ©titions, des changements brusques dâ€™idÃ©es, des erreurs de langue et autres. Ã€ cela nous pouvons aussi
ajouter le fait que nous travaillons essentiellement sur des conversations tÃ©lÃ©phoniques, la comprÃ©hension devient encore
plus bruitÃ©e par des problÃ¨mes liÃ©s Ã  la qualitÃ© sonore. Afin de pallier ces problÃ¨mes, nous utilisons essentiellement les
transcriptions manuelles des conversations pour la suite de ce papier.

4.2    Synopsis

En ce qui concerne le rÃ©sumÃ©, une dÃ©finition simple serait : Forme abrÃ©gÃ©e du contenu dâ€™un texte, dâ€™un document, dâ€™un
film. Pour une conversation cette forme abrÃ©gÃ©e doit contenir lâ€™ensemble des informations clÃ©s qui ont Ã©tÃ© abordÃ©es au
cours de celle-ci. Nous appellerons cette forme Â« synopsis Â» pour la suite de lâ€™Ã©tude. Chaque synopsis doit Ãªtre capable
de retranscrire les informations vÃ©hiculÃ©es dans la conversation en un nombre de phrases (ou mots) rÃ©duit. Il est important
de prÃ©ciser que la forme de nos synopsis est textuelle et abstractive, câ€™est-Ã -dire que la forme rÃ©sumÃ©e de nos conversations
ne sera pas une nouvelle conversation plus courte ou une sÃ©lection des tours de parole les plus pertinents, mais un court
texte rappelant les idÃ©es abordÃ©es Ã  lâ€™instar des synopsis de films.

Le principal problÃ¨me de ces synopsis est directement liÃ© Ã  leur nature. En effet un synopsis est le rÃ©sultat produit par une
personne qui souhaite rÃ©sumer une conversation, mais cette mÃªme conversation pourrait trÃ¨s bien Ãªtre rÃ©sumÃ©e dâ€™une
faÃ§on totalement diffÃ©rente par un second individu. Afin de limiter ce caractÃ¨re subjectif dans notre Ã©tude, nous nous
basons pour notre Ã©valuation sur plusieurs (au moins deux) rÃ©sumÃ©s de rÃ©fÃ©rences pour une mÃªme conversation. Ã€ cela
sâ€™ajoute la crÃ©ation dâ€™un guide dâ€™annotation en synopsis pour tout annotateur dÃ©sirant enrichir le corpus, afin que tous les
synopsis produits suivent la mÃªme orientation.

Ã€ ce caractÃ¨re de subjectivitÃ© liÃ© Ã  lâ€™individu, on peut ajouter des variantes dans lâ€™orientation dâ€™un rÃ©sumÃ©. Dans le cadre
des centres dâ€™appels on peut identifier deux catÃ©gories de synopsis : des synopsis basÃ©s sur le contenu sÃ©mantique, câ€™est-
Ã -dire sur le sujet rÃ©el de la conversation, et des synopsis basÃ©s sur les interactions entre lâ€™usager et le conseiller, cela
correspondrait par exemple Ã  privilÃ©gier la durÃ©e et lâ€™efficacitÃ© du conseiller par rapport au problÃ¨me mÃªme de lâ€™usager.
Dans notre Ã©tude nous nous intÃ©ressons principalement aux synopsis basÃ©s sur le contenu sÃ©mantique de la conversation.
5   RÃ©gie Autonome des Transport Parisien (http://www.ratp.fr)
107

[P-R.1]
METHODES PAR EXTRACTION POUR LE RESUME AUTOMATIQUE DE CONVERSATIONS PARLEES PROVENANT DE CENTRES
Dâ€™APPELS

4.3     Exemples

Pour illustrer nos propos voici deux exemples concrets de synopsis rÃ©digÃ©s par nos annotateurs.

Annotateur 1                                        Annotateur 2
Demande de renseignement sur une ligne de
Conversation 1    quel bus pour gare de Lyon vers Montparnasse           bus pour aller de de Gare de Lyon Ã  Gare
Montparnasse.
Demande dâ€™horaires de train de la gare de
Conversation 2     horaires RER E de Meaux Ã  la Gare de l'Est
Maux Ã  la gare de lâ€™Est Ã  une heure donnÃ©e

TABLE 4 : Exemples de synopsis

Comme on peut facilement le voir, les synopsis de lâ€™annotateur 2 sont syntaxiquement mieux construits que ceux de
lâ€™annotateur 1, mais en termes dâ€™informations, les deux synopsis sont trÃ¨s similaires.

5     MÃ©thodes de rÃ©sumÃ©s
Dans cette partie nous prÃ©sentons les mÃ©thodes classiques de rÃ©sumÃ©s extractifs et heuristiques de sÃ©lection selon la
position que nous utilisons dans notre Ã©tude.

5.1     Maximal Marginal Relevance (MMR)

MMR (Corbonnell et Goldstein, 1998) est largement utilisÃ© dans le rÃ©sumÃ© de conversation du fait de sa simplicitÃ© et de
son efficacitÃ©. Il sÃ©lectionne les tours de paroles les plus riches de sens dâ€™un texte tout en Ã©vitant la redondance des
informations. Dans le cadre du rÃ©sumÃ© extractif le score attribuÃ© Ã  un tour de parole S est calculÃ© comme suit :

ğ‘€ğ‘€ğ‘…(ğ‘†i) = ğœ† Ã— ğ‘†ğ‘–ğ‘š1(ğ‘†i, ğ·) âˆ’ (1 âˆ’ ğœ†) Ã— ğ‘†ğ‘–ğ‘š2(ğ‘†i, ğ‘†ğ‘¢ğ‘šğ‘š)

OÃ¹ D reprÃ©sente le vecteur document, Summ reprÃ©sente les tours de paroles qui ont Ã©tÃ© extraits pour le rÃ©sumÃ©, et ğœ† est
une constante utilisÃ©e pour ajuster la relation entre la pertinence et la redondance. Les deux fonctions de similaritÃ© (Sim1
et Sim2) reprÃ©sentent respectivement la similaritÃ© entre un tour de parole par rapport Ã  lâ€™ensemble du document et par
rapport au rÃ©sumÃ© courant. Les tours de paroles avec le plus haut score MMR sont sÃ©lectionnÃ©s itÃ©rativement pour gÃ©nÃ©rer
le rÃ©sumÃ©, jusquâ€™Ã  ce que la limite de taille soit atteinte. Ici on sÃ©lectionne des tours de paroles jusquâ€™Ã  ce que le nombre
de mots excÃ¨de 6% de la totalitÃ© des mots qui composent le texte de base.

5.2     Heuristiques basÃ©es sur le dialogue.

Pour Ã©tablir notre baseline nous avons utilisÃ© quelques heuristiques basÃ©es sur les conversations. Nos conversations sont
essentiellement les appels provenant de centres dâ€™appels. De ce fait on peut facilement penser quâ€™il existe une certaine
structure qui se rÃ©pÃ¨te dans ces appels. On notera que pour la sÃ©lection des tours de parole selon leur position, tous les
tours de parole sont pris en compte, autant les tours de parole de lâ€™usager que ceux du conseillÃ©.

Le premier constat et le plus Ã©vident est que lâ€™usager appelle le centre pour obtenir des informations sur un sujet bien
prÃ©cis. Il est donc normal de penser que lâ€™information essentielle de lâ€™appel se trouve en dÃ©but de conversation dans les
tous premiers tours de parole, juste aprÃ¨s les Ã©changes de politesse conventionnels (Â« bonjour Â»). Dâ€™autre part lâ€™opÃ©rateur
se doit dâ€™Ã©couter lâ€™appelant pour savoir quelle est sa requÃªte. Ã€ partir de ces deux constats nous Ã©tablissons notre premiÃ¨re
heuristique : Le rÃ©sumÃ© (que lâ€™on notera LB pour la suite de ce papier) sera constituÃ© de lâ€™unique tour de parole dont la
taille en mot est maximale parmi tous les tours de parole du premier quart de la conversation.

Dans la mÃªme optique que prÃ©cÃ©demment nous prenons cette fois comme rÃ©sumÃ© (que lâ€™on notera LA pour la suite)
lâ€™unique tour de parole dont la taille est maximale sur lâ€™ensemble de la conversation. Celui-ci peut symboliser soit une
explication dÃ©taillÃ©e de la requÃªte par lâ€™usager, soit une explication de la rÃ©ponse Ã  cette requÃªte par lâ€™opÃ©rateur. Dans les
deux cas nous espÃ©rons aussi rÃ©vÃ©ler une prise dâ€™informations importante dans la conversation.

Afin dâ€™observer si la fin de la conversation contient ou non des informations utiles, nous utiliserons comme rÃ©sumÃ© (que
lâ€™on notera LE) lâ€™unique tour de parole dont la taille est maximale parmi les tours de parole contenus dans le dernier quart
108

[P-R.1]
METHODES PAR EXTRACTION POUR LE RESUME AUTOMATIQUE DE CONVERSATIONS PARLEES PROVENANT DE CENTRES
Dâ€™APPELS

de la conversation. La fin dâ€™une conversation pourrait trÃ¨s bien reprÃ©senter un rappel global de ce quâ€™il sâ€™est dit tout au
long de lâ€™appel, mais pourrait aussi contenir la solution apportÃ©e ou non par lâ€™opÃ©rateur Ã  lâ€™usager.

Enfin nous testons un systÃ¨me complÃ¨tement alÃ©atoire pour se donner une idÃ©e de son efficacitÃ© dans cette situation. Pour
cela nous relevons des tours de parole alÃ©atoirement tant que la contrainte de taille nâ€™a pas Ã©tÃ© atteinte. Nous noterons ce
rÃ©sumÃ© RS.

6     RÃ©sultats et interprÃ©tations
Dans cette partie nous prÃ©sentons dâ€™une part la mÃ©thode dâ€™Ã©valuation utilisÃ©e, et dâ€™autre part les rÃ©sultats obtenus Ã  partir
de cette derniÃ¨re.

6.1    Evaluation

Lâ€™Ã©valuation de rÃ©sumÃ©s par des humains est une tÃ¢che longue et coÃ»teuse. De ce fait pour Ã©valuer nos systÃ¨mes nous
nous sommes tournÃ©s vers une Ã©valuation automatique. Pour cela nous utiliserons lâ€™Ã©valuation ROUGE. Celle-ci est basÃ©e
sur les occurrences de mots entre les rÃ©sumÃ©s produits automatiquement et les rÃ©sumÃ©s humains dits Â« idÃ©aux Â». ROUGE
compare alors le texte produit par les systÃ¨mes avec un ensemble de rÃ©sumÃ©s humains sur le mÃªme document original.
ROUGE-1 Ã  ROUGE-4 sont de simples mesures dâ€™occurrences de n-grammes, qui dÃ©tectent les mÃªmes segments entre
les rÃ©sumÃ©s produits et ceux de rÃ©fÃ©rences. ROUGE-L mesure les sÃ©quences communes entre les deux types de rÃ©sumÃ©s.

âˆ‘ğ‘†âˆˆ{ğ‘…ğ‘’ğ‘“ğ‘’ğ‘Ÿğ‘’ğ‘›ğ‘ğ‘’ğ‘†ğ‘¢ğ‘šğ‘šğ‘ğ‘Ÿğ‘–ğ‘’ğ‘ } âˆ‘ğ‘”ğ‘Ÿğ‘ğ‘šnâˆˆğ‘† ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡match(ğ‘”ğ‘Ÿğ‘ğ‘šn)
ğ‘…ğ‘‚ğ‘ˆğºğ¸ âˆ’ ğ‘ =
âˆ‘ğ‘†âˆˆ{ğ‘…ğ‘’ğ‘“ğ‘’ğ‘Ÿğ‘’ğ‘›ğ‘ğ‘’ğ‘†ğ‘¢ğ‘šğ‘šğ‘ğ‘Ÿğ‘–ğ‘’ğ‘ } âˆ‘ğ‘”ğ‘Ÿğ‘ğ‘šnâˆˆğ‘† ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡(ğ‘”ğ‘Ÿğ‘ğ‘šn)

OÃ¹ n correspond au nombre de mots contenus dans la sÃ©quence de mots Ã  rechercher lors de
lâ€™Ã©valuation, ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡match(ğ‘”ğ‘Ÿğ‘ğ‘šn) reprÃ©sente le nombre maximum de mots qui interviennent Ã  la fois dans le rÃ©sumÃ© Ã 
Ã©valuer et dans les Ã©chantillons de rÃ©sumÃ©s de rÃ©fÃ©rence.

Lin (Lin, 2003) a montrÃ© que ROUGE-1 et ROUGE-2 constituaient un bon indicateur du jugement humain.

6.2    RÃ©sultat et interprÃ©tation

Nous avons donc lancÃ© nos Ã©valuations avec les rÃ©sumÃ©s gÃ©nÃ©rÃ©s Ã  partir dâ€™heuristiques basÃ©es sur les conversations : le
plus long tour de parole en dÃ©but de conversation (LB), le plus long tour de parole sur toute la conversation (LA) et le
plus long tour de parole en fin de conversation (LE), ainsi que la mÃ©thode dâ€™extraction de tours de parole alÃ©atoires (RS).
Nous utilisons aussi Ã  titre de comparaison un rÃ©sumÃ© constituÃ© de lâ€™ensemble de la conversation (FT). Les rÃ©sultats sont
regroupÃ©s dans le tableau ci-dessous :

ROUGE-1       ROUGE-2       ROUGE-L
LB       0.183         0.613          0.145
LA       0.175         0.051          0.132
MMR       0.150         0.051          0.119
FT       0.092         0.035          0.070
LE       0.055         0.009          0.043
RS       0.049         0.011          0.041

TABLE 5 : RÃ©sultats de lâ€™Ã©valuation

On notera tout dâ€™abord que lâ€™Ã©valuation des synopsis extractifs gÃ©nÃ©rÃ©s se fait avec des synopsis abstractifs. Cela aurait
pour effet de rÃ©duire le score de chaque mÃ©thode, mais Ã©tant donnÃ© que toutes les mÃ©thodes Ã©valuÃ©es ici sont basÃ©es sur
de lâ€™extraction de tours de parole, la variation des scores sera la mÃªme pour toutes. Cependant ces rÃ©sultats pourraient Ãªtre
difficilement comparables avec dâ€™autres rÃ©sultats impliquant lâ€™utilisation de ces mÃ©thodes dans un autre cadre que celui
dÃ©crit dans ce papier.

Cela mis de cÃ´tÃ© on sâ€™aperÃ§oit que les meilleurs rÃ©sultats sont obtenus avec lâ€™extraction du tour de parole le plus long en
dÃ©but de conversation (LB), cela met bien valeur le fait que dans les conversations du corpus de RATP-DECODA
109

[P-R.1]
METHODES PAR EXTRACTION POUR LE RESUME AUTOMATIQUE DE CONVERSATIONS PARLEES PROVENANT DE CENTRES
Dâ€™APPELS

lâ€™information essentielle est souvent contenue dans les tout premiers Ã©changes entre lâ€™usager et lâ€™opÃ©rateur. De la mÃªme
faÃ§on il nâ€™y a que trÃ¨s peu dâ€™informations en fin de conversation comme nous le montre le rÃ©sultat de lâ€™Ã©valuation LE.

Lâ€™extraction du plus long tour de parole en dÃ©but de conversation et sur toute la conversation donne des rÃ©sultats assez
proches. Cela peut sâ€™expliquer par la nature la conversation. En effet lors dâ€™un appel, le consommateur va souvent
expliquer son problÃ¨me en dÃ©but dâ€™appel sans que lâ€™opÃ©rateur ne lâ€™interrompe. En revanche au cours de la conversation,
câ€™est-Ã -dire pendant la rÃ©solution dudit problÃ¨me, il y aura souvent de nombreux Ã©changes rapides entre les deux
interlocuteurs.

En ce qui concerne les rÃ©sultats donnÃ©s par lâ€™algorithme de MMR, ce-dernier peut facilement Ãªtre biaisÃ© avec ce genre de
donnÃ©es. La nature spontanÃ©e et naturelle de la conversation introduit de nombreux bruits, dont la rÃ©pÃ©tition frÃ©quente
dâ€™un mÃªme terme ou dâ€™une mÃªme idÃ©e. Au niveau de lâ€™appel cela peut se retranscrire par une pÃ©riode dâ€™incomprÃ©hension
entre les deux parties, menant alors Ã  de nombreuses rÃ©pÃ©titions dâ€™informations peu importantes. MMR va alors se
concentrer sur ces rÃ©pÃ©titions et ne renvoyer que des tours de parole de faible importance au niveau information.
Cependant les rÃ©sultats restent tout de mÃªme relativement proches des heuristiques basÃ©es sur le dialogue les plus
efficaces.

6.3    Exemples de rÃ©sumÃ©s produits

Ci-dessous est prÃ©sentÃ© un exemple de rÃ©sumÃ© produit en utilisant le MMR et les heuristiques simples de la conversation.

ROUGE-1                                                 Synopsis
Humain 1          /                                    perdu tÃ©lÃ©phone mais pas retrouvÃ©
Demande de renseignements sur la perte dâ€™un tÃ©lÃ©phone portable Alcatel Blanc sur la
Humain 2          /
ligne de bus 20. Non retrouvÃ©.
allÃ´ oui bonjour monsieur je tÃ©lÃ©phonais pour savoir si par hasard vous auriez trouvÃ© un
LB           0.205          tÃ©lÃ©phone portable euh hier dans l'autobus euh la ligne 20 en fin en fin d'aprÃ¨s midi
disons en soirÃ©e plutÃ´t
allÃ´ oui bonjour monsieur je tÃ©lÃ©phonais pour savoir si par hasard vous auriez trouvÃ© un
LA           0.205          tÃ©lÃ©phone portable euh hier dans l'autobus euh la ligne 20 en fin en fin d'aprÃ¨s midi
disons en soirÃ©e plutÃ´t
allÃ´ oui bonjour monsieur je tÃ©lÃ©phonais pour savoir si par hasard vous auriez trouvÃ© un
MMR          0.178          tÃ©lÃ©phone portable euh hier dans l'autobus euh la ligne 20 en fin en fin d'aprÃ¨s midi
disons en soirÃ©e plutÃ´t. ligne numÃ©ro 20, un tÃ©lÃ©phone portable.
LE             0                                          bonne journÃ©e au revoir

TABLE 6 : DiffÃ©rents synopsis obtenus sur un exemple concret.

Comme on peut le voir, le MMR et LB sont les deux mÃ©thodes qui semblent le plus efficace en terme de rÃ©cupÃ©ration
dâ€™informations, avec un point supplÃ©mentaire pour le MMR, mais ceci est dÃ» au fait quâ€™il rÃ©cupÃ¨re deux tours de parole
pour son synopsis alors que LB, LA et LE nâ€™en rÃ©cupÃ¨re quâ€™une seule. De la mÃªme faÃ§on LE nâ€™est clairement pas
significatif.

7     Conclusion et perspectives
Dans notre Ã©tude nous nâ€™avons testÃ© et Ã©valuÃ© que des systÃ¨mes basÃ©s sur des mÃ©thodes extractives classiques des rÃ©sumÃ©s
de textes afin de se donner une idÃ©e de lâ€™efficacitÃ© de ces derniers. Cependant nos rÃ©sumÃ©s de rÃ©fÃ©rences sont abstractifs,
ce qui fausse nos rÃ©sultats dans la mesure oÃ¹ les rÃ©sultats obtenus ne sont comparables quâ€™entre eux. Notre systÃ¨me
dâ€™Ã©valuation ROUGE atteint aussi ses limites en ne capturant pas la variabilitÃ© lexicale, de ce fait il faudra penser Ã  faire
une Ã©valuation manuelle.

Cependant on sâ€™aperÃ§oit tout de mÃªme dâ€™aprÃ¨s les rÃ©sultats obtenus que les mÃ©thodes les plus efficaces sont directement
liÃ©es Ã  la structure de lâ€™appel. La mÃ©thode de rÃ©sumÃ© par MMR qui fonctionne bien dans les cas des rÃ©sumÃ©s de texte, est
ici battue par les mÃ©thodes basÃ©es sur les heuristiques du dialogue (LB et LA). De ce fait pour la suite de nos Ã©tudes nous
nous orienterons plus dans la direction de la structure des appels reÃ§us dans les centres tÃ©lÃ©phoniques, en essayant de
trouver par exemple une segmentation de la conversation en unitÃ©s logiques.
110

[P-R.1]
METHODES PAR EXTRACTION POUR LE RESUME AUTOMATIQUE DE CONVERSATIONS PARLEES PROVENANT DE CENTRES
Dâ€™APPELS
Remerciements
Ces travaux de recherche ont Ã©tÃ© financÃ©s en partie par l'Union EuropÃ©enne Ã  travers le projet SENSEI6 (FP7/2007-2013
- nÂ° 610916 â€“ SENSEI).

RÃ©fÃ©rences
JANIN, A., BARON, D., EDWARDS, J., ELLIS, D., GELBART, D., MORGAN, N., ... & WOOTERS, C. (2003).
The ICSI meeting corpus. Acoustics, Speech, and Signal Processing, 2003. Proceedings.(ICASSP'03). 2003 IEEE
International Conference on. Vol. 1. I-364. IEEE.

GODFREY, J. J., HOLLIMAN, E. C., & MCDANIEL, J. (1992). SWITCHBOARD: Telephone speech corpus for
research and development. Acoustics, Speech, and Signal Processing, 1992. ICASSP-92., 1992 IEEE International
Conference on (Vol. 1, pp. 517-520). IEEE.

CARLETTA, J., ASHBY, S., BOURBAN, S., FLYNN, M., GUILLEMOT, M., HAIN, T., ... & WELLNER, P.
(2006). The AMI meeting corpus: A pre-announcement. Machine learning for multimodal interaction. 28-39. Springer
Berlin Heidelberg.

RIBEIRO R.,   DE MATOS DM. (2007). Extractive Summarization of Broadcast News: Comparing Strategies for
European Portuguese. Text, Speech and Dialogue, 115-122.

MURRAY G., CARENINI G. (2008).Summarizing Spoken and Written Conversations. EMNLP, 773-782.

LIN J., ZAJIC D. M., DORR B. J. (2007). Single-document and multi-document summarization techniques for email
threads using sentence compression, IPM 44, 1600-1610.

KNIGHT K., DANIEL M. (2000) Statistics-based summarization-step one: Sentence compression, AAAI/IAAI, 703-710.

ZHU X., PENN G (2006). Summarization of Spontaneous Conversations, INTERSPEECH, 1531-1534.

TOGASHI S., YAMAGUSHI M, NAKAGAWA S. (2006). Summarization of spoken lectures based on linguistic surface
and prosodic information, STL, 34-37.

BECHET F., MAZA B., BIGOUROUX N., BAZILLON T., EL-BEZE M., DE MORI R., ARBILLOT E. (2012).
DECODA: a call-center human-human spoken conversation corpus. LREC.

GANESAN K., ZHAI CX, HAN J. (2010). . Opinosis: A Graph-Based Approach to Abstractive Summarization of
Highly Redundant Opinions. International Conference on Computational Linguistics 23, 340-348.

LI W., WU M., LU Q, XU W., YUAN C (2006). Extractive Summarization using Inter- and Intra- Event Relevance.
ACL 44, 369-376.

LIN C.-Y., HOVY E. H. (2003). Autonamic evaluation of summaries using n-gram co-occurrence statistics, HLT-
NAACL.

CARBONNELL J., GOLDSTEIN J. (1998), The use of MMR, the diversity-based reranking for reordering documents
and producing summaries, SIGIR.
6   http://www.sensei-conversation.eu/
111
