<?xml version="1.0" encoding="UTF-8"?>
<!-- 
	Fichier construit à partir de la page http://talana.linguist.jussieu.fr/taln99/ps/ disponible sur Web Archives.
	Articles problématiques ayant été OCRisés : taln-1999-long-026
-->
<conference>
	<edition>
		<acronyme>TALN'1999</acronyme>
		<titre>6ème conférence sur le Traitement Automatique des Langues Naturelles</titre>
		<ville>Cargèse</ville>
		<pays>France</pays>
		<dateDebut>1999-07-12</dateDebut>
		<dateFin>1999-07-17</dateFin>
		<presidents>
			<president>
				<prenom>Pascal</prenom>
				<nom>Amsili</nom>
			</president>
		</presidents>
		<typeArticles>
			<type id="long">Communications orales</type>
			<type id="poster">Affiches</type>
		</typeArticles>
		<siteWeb>http://talana.linguist.jussieu.fr/taln99/</siteWeb>
	</edition>
	<articles>
		<article id="taln-1999-long-001" session="">
			<auteurs>
				<auteur>
					<prenom>Gilles</prenom>
					<nom>Adda</nom>
					<email>gadda@limsi.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Joseph</prenom>
					<nom>Mariani</nom>
					<email>mariani@limsi.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Patrick</prenom>
					<nom>Paroubek</nom>
					<email>pap@limsi.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Martin</prenom>
					<nom>Rajman</nom>
					<email>martin.rajman@epfl.ch</email>
					<affiliationId>2</affiliationId>
				</auteur>
				<auteur>
					<prenom>Josette</prenom>
					<nom>Lecomte</nom>
					<email>josette.lecomte@inalf.cnrs.fr</email>
					<affiliationId>3</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LIMSI-CNRS BP 133, F-91403 Orsay Cedex</affiliation>
				<affiliation affiliationId="2">Laboratoire d'Intelligence Artificielle Département Informatique Ecole Polytechnique Fédérale de Lausanne CH-1015 Lausanne, Suisse</affiliation>
				<affiliation affiliationId="3">CNRS-INaLF 44, Avenue de la Libération, BP 30687 F-54063 Nancy-Cedex</affiliation>
			</affiliations>
			<titre>Métrique et premiers résultats de l’évaluation GRACE des étiqueteurs morphosyntaxiques pour le français</titre>
			<type>long</type>
			<pages></pages>
			<resume>L'action GRACE est le premier exemple d’application du paradigme d'évaluation aux étiqueteurs morphosyntaxiques pour le français dans le cadre d'une campagne d'évaluation formelle, à participation ouverte et utilisant des données de grande taille. Après une rapide description de l’organisation et du déroulement de l'action ainsi que des problèmes posés par la nécessaire mise en place d’un référentiel commun pour l’évaluation, nous présenterons en détail la métrique Précision-Décision qui a été développée dans le cadre de GRACE pour la mesure quantitative des performances des systèmes d’étiquetage. Nous nous intéresserons ensuite aux résultats obtenus pour les participants à la phase de test de la campagne et indiquerons les aspects du protocole d’évaluation qui restent encore à valider sur les données recueillies. Enfin, nous conclurons en soulignant les incidences positives d’une campagne d’évaluation comme GRACE sur le domaine de l’ingénierie linguistique.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-002" session="">
			<auteurs>
				<auteur>
					<prenom>Roberto</prenom>
					<nom>Basili</nom>
					<email>basili@info.uniroma2.it</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Maria Teresa</prenom>
					<nom>Pazienza</nom>
					<email>pazienza@info.uniroma2.it</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Fabio Massimo</prenom>
					<nom>Zanzotto</nom>
					<email>zanzotto@info.uniroma2.it</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">University of Rome Tor Vergata, Department of Computer Science, Systems and Production, 00133 Roma (Italy)</affiliation>
				<affiliation affiliationId="2"></affiliation>
				<affiliation affiliationId="3"></affiliation>
			</affiliations>
			<titre></titre>
			<type>long</type>
			<pages></pages>
			<resume></resume>
			<mots_cles></mots_cles>
			<title>Lexicalizing a shallow parser</title>
			<abstract>Current NL parsers are expected to run with throughput rate suitable to satisfy ”time constraints” in real applications. The aim of the present work is, on the one hand, to investigate the effects of lexical information in a shallow parsing environment, on the other hand, to study the limits of a bootstrapping architecture that, automatically learning the lexical information in an unsupervised fashion, guarantees the reliability and portability of the parser to different domains. The investigated parser is Chaos (Chunk analysis oriented system), a robust parser based on stratification and lexicalization. Large scale evaluation over a standard tree bank is discussed.</abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-003" session="">
			<auteurs>
				<auteur>
					<prenom>Frédéric</prenom>
					<nom>Béchet</nom>
					<email>frederic.bechet@lia.univ-avignon.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Alexis</prenom>
					<nom>Nasr</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Thierry</prenom>
					<nom>Spriet</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Renato</prenom>
					<nom>De Mori</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Laboratoire Informatique d'Avignon – Université d'Avignon Agroparc BP 1228 – 84911 Avignon Cedex 9</affiliation>
			</affiliations>
			<titre>Modèles de langage à portée variable : Application au traitement des homophones</titre>
			<type>long</type>
			<pages></pages>
			<resume>L'objectif de cette étude concerne le traitement d'homophones singulier/pluriel dans un Système de Reconnaissance de la Parole en exploitant les contraintes d'accord dans la phrase à reconnaître. Un certain nombre de ces contraintes ne peut être traité par les modèles de langage à portée locale de type n-gram utilisés habituellement. Les deux modèles proposés, le modèle à base de syntagme et le modèle Homophone-Cache, permettent de résoudre certains cas d'homophonie par deux méthodes différentes : le modèle à base de syntagme permet d'introduire des contraintes syntaxiques ; le modèle Homophone-Cache a pour objet de discriminer les homophones singulier/pluriel, de manière robuste, en étant peu sensible à la mauvaise reconnaissance d'un mot au sein de la phrase.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-004" session="">
			<auteurs>
				<auteur>
					<prenom>Gabriel</prenom>
					<nom>Bès</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Philippe</prenom>
					<nom>Blache</nom>
					<email></email>
					<affiliationId>2</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">GRIL, Université de Clermont-Ferrand II, 34 Avenue Carnot, 63000 Clermont-Ferrand</affiliation>
				<affiliation affiliationId="2">LPL-CRNS, Université de Provence, 29 Avenue Robert Schuman, 13621 Aix-en-Provence</affiliation>
			</affiliations>
			<titre>Propriétés et analyse d’un langage</titre>
			<type>long</type>
			<pages></pages>
			<resume>Nous présentons dans cet article une nouvelle approche, que nous appelons 5P, permettant la description des propriétés d’un langage et son utilisation pour une analyse automatique. Nous montrons comment cette approche permet la prise en compte de la dimension descriptive de la linguistique. Par ailleurs, nous présentons une technique d’analyse, appelée analyse par Filtrage et Fusion, qui tire parti de cette description en propriétés. Nous montrons en quoi ces deux projets (description d’une langue et analyse automatique) convergent et ouvrent de nouvelles perspectives.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-005" session="">
			<auteurs>
				<auteur>
					<prenom>Ismaïl</prenom>
					<nom>Biskri</nom>
					<email>Ismail_Biskri,@uqtr.uquebec.ca</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Sylvain</prenom>
					<nom>Delisle</nom>
					<email>Sylvain_Delisle@uqtr.uquebec.ca</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Département de mathématiques et d’informatique Université du Québec à Trois-Rivières, Québec, Canada</affiliation>
			</affiliations>
			<titre>Un modèle hybride pour le textual data mining : un mariage de raison entre le numérique et le linguistique</titre>
			<type>long</type>
			<pages></pages>
			<resume>Une des recherches de pointe menée actuellement en informatique est l’extraction des connaissances dans un texte électronique (textual data mining). Ce thème de recherche est de première importance pour les technologies de l’information qui sont confrontées à des marées de documents électroniques. Pour résoudre ce problème, plusieurs stratégies sont possibles : les unes relèvent des mathématiques et les autres de l’informatique linguistique. Nous présentons dans cet article un modèle hybride, à la fois robuste et fin, qui s’inspire des modèles neuronaux et de l’analyse linguistique informatique.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-006" session="">
			<auteurs>
				<auteur>
					<prenom>Béatrice</prenom>
					<nom>Bouchou</nom>
					<email>bouchou@univ-tours.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Denis</prenom>
					<nom>Maurel</nom>
					<email>maurel@univ-tours.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LI/E3i, Université François Rabelais 64, avenue Jean Portalis, 37200 Tours</affiliation>
			</affiliations>
			<titre>Une bibliothèque d’opérateurs linguistiques pour la consultation de base de données en langue naturelle</titre>
			<type>long</type>
			<pages></pages>
			<resume>L’interrogation de bases de données en langue naturelle est une application directe du traitement automatique des langues naturelles. Son utilité va en s’accroissant avec le développement d’outils d’information accessibles au grand public à travers la Toile Internet. L’approche que nous proposons s’appuie d’une part sur les fondations linguistiques établies par la théorie de Z. S. Harris (dans l’élaboration du dictionnaire, et surtout dans la définition des opérateurs linguistiques), et d’autre part sur un outil informatique précis (les transducteurs). Elle représente une alternative aux traitements syntaxico-sémantiques habituellement développés dans des formalismes logiques. Elle s’appuie sur la constitution d’une bibliothèque d’opérateurs linguistiques pour les domaines d’application.</resume>
			<mots_cles>interrogation de base de données, langage naturel, opérateurs linguistiques, transducteur (automate à nombre fini d’états)</mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-007" session="">
			<auteurs>
				<auteur>
					<prenom>Pierre</prenom>
					<nom>Boullier</nom>
					<email>Pierre.Boullier@inria.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">INRIA-Rocquencourt Domaine de Voluceau B.P. 105 78153 Le Chesnay Cedex, France</affiliation>
			</affiliations>
			<titre></titre>
			<type>long</type>
			<pages></pages>
			<resume></resume>
			<mots_cles></mots_cles>
			<title>On TAG Parsing</title>
			<abstract>The subject of tree adjoining grammar parsing inspired many researches but they all failed to beat the O(n6) parse time wall. Thus, some present researches in this field try to identify efficient parser implementations either for the full grammar class, or for linguistically significant subclasses. This paper addresses both issues and proposes a method which uses range concatenation grammars as an intermediate implementation formalism. Range concatenation grammar is a syntactic formalism which is both powerful, in so far as it extends linear contextfree rewriting systems, and efficient, in so far as its sentences can be parsed in polynomial time. We show two methods by which unrestricted tree adjoining grammars can be transformed into equivalent range concatenation grammars which can be parsed in O(n 6) time, and, moreover, if the input tree adjoining grammar has some restricted form, its parse time decreases to O(n5).</abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-008" session="">
			<auteurs>
				<auteur>
					<prenom>Patrick</prenom>
					<nom>Caudal</nom>
					<email>caudal@linguist.jussieu.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">TALANA, UFR de Linguistique, Université Paris 7, Case 7003 2, place Jussieu, 75251 Paris Cedex 05</affiliation>
			</affiliations>
			<titre></titre>
			<type>long</type>
			<pages></pages>
			<resume></resume>
			<mots_cles></mots_cles>
			<title>Achievements vs. Accomplishments : A Computational Treatment of Atomicity, Incrementality, and Perhaps of Event Structure</title>
			<abstract>Achievements and accomplishments are argued in this paper to differ w.r.t. atomicity (rather than punctuality), a notion strongly but not exclusively related to incrementality, i.e., to eventobject mapping functions ; the latter will be shown to be unsufficient to account for certain cases of non-atomicity. A computational treatment of incrementality and atomicity will be presented, and a number of related empirical problems considered, notably lexical polysemy in verb – argument relationships. Finally, the approach will be shown to be extendable to the notion of telicity, opening the way to a broader treatment of event structure.</abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-009" session="">
			<auteurs>
				<auteur>
					<prenom>Jean-Cédric</prenom>
					<nom>Chappelier</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Martin</prenom>
					<nom>Rajman</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Ramon</prenom>
					<nom>Aragües</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Antoine</prenom>
					<nom>Rozenknop</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">EPFL, DI-LIA, INR (Ecublens), CH-1015 LAUSANNE (SUISSE)</affiliation>
			</affiliations>
			<titre></titre>
			<type>long</type>
			<pages></pages>
			<resume></resume>
			<mots_cles></mots_cles>
			<title>Lattice Parsing for Speech Recognition</title>
			<abstract>A lot of work remains to be done in the domain of a better integration of speech recognition and language processing systems. This paper gives an overview of several strategies for integrating linguistic models into speech understanding systems and investigates several ways of producing sets of hypotheses that include more “semantic” variability than usual language models. The main goal is to present and demonstrate by actual experiments that sequential couplingmay be efficiently achieved byword-lattice syntactic analyzers, efficiently parsing the huge number of hypothesis (i.e. possible sentences) contained in the lattice produced by the speech recognizer.</abstract>
			<keywords>lattice parsing, speech recognition, syntactic processing</keywords>
		</article>
		<article id="taln-1999-long-010" session="">
			<auteurs>
				<auteur>
					<prenom>Béatrice</prenom>
					<nom>Daille</nom>
					<email>daille@irin.univ-nantes.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">IRIN, 2, rue de la Houssinière, BP 92208, 44322 NANTES cedex 3, France</affiliation>
			</affiliations>
			<titre>Identification des adjectifs relationnels en corpus</titre>
			<type>long</type>
			<pages></pages>
			<resume>Cet article présente l’identification en corpus des adjectifs relationnels considérés par les linguistes comme hautement dénominatifs. Notre approche utilise un programme d’extraction terminologique qui s’applique sur un corpus préalablement étiqueté et lemmatisé. Après avoir rappelé quelques propriétés linguistiques des adjectifs relationnels, nous présenterons le programme d’extraction de terminologie et les modifications apportées à celui-ci pour effectuer cette identification. Nous évaluerons le caractère dénominatif de ces adjectifs et des termes nominaux où ils apparaissent en les comparant à un thesaurus. Nous conclurons sur l’intérêt de ces adjectifs à la fois pour l’extraction de terminologie mais aussi pour d’autres problématiques comme l’extraction de connaissances à partir de corpus ou la mise à jour d’un thesaurus.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-011" session="">
			<auteurs>
				<auteur>
					<prenom>Georgette</prenom>
					<nom>Dal</nom>
					<email>dal@univ-lille3.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Nabil</prenom>
					<nom>Hathout</nom>
					<email>hathout@univ-tlse2.fr</email>
					<affiliationId>2</affiliationId>
				</auteur>
				<auteur>
					<prenom>Fiammetta</prenom>
					<nom>Namer</nom>
					<email>namer@clsh.univ-nancy2.fr</email>
					<affiliationId>3</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">« SILEX », CNRS &amp; Un. Lille3</affiliation>
				<affiliation affiliationId="2">CNRS, INaLF Nancy &amp; ERSS</affiliation>
				<affiliation affiliationId="3">LANDISCO &amp; Université Nancy2</affiliation>
			</affiliations>
			<titre>Construire un lexique dérivationnel : théorie et réalisations</titre>
			<type>long</type>
			<pages></pages>
			<resume>Le travail qui suit teste différentes façons de concevoir et de construire un lexique dérivationnel. Afin de mener à bien cette tâche, nous centrerons l’analyse sur les suffixations par -able et -ité du français (et les dérivés qu’elles forment), et nous les soumettrons à des éclairages différents : un éclairage proprement théorique et deux éclairages plus finalisés, DériF et DéCor, qui présentent des techniques différentes pour le traitement automatique de la morphologie. Au terme de ce travail, nous comparerons les résultats obtenus.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-012" session="">
			<auteurs>
				<auteur>
					<prenom>Brahim</prenom>
					<nom>Djioua</nom>
					<email>djioua@msh-paris.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">CAMS Equipe LaLIC Centre d'Analyse de Mathématiques et Sociales UMR 17 – CNRS / EHESS/ Université de Paris IV 96, Bd Raspail 75006 Paris</affiliation>
			</affiliations>
			<titre>DISCC : Un outil de construction et d'utilisation d'une Base de Connaissances Sémantico-Cognitives des verbes</titre>
			<type>long</type>
			<pages></pages>
			<resume>Cette communication décrit un outil informatique de construction et de consultation d'un lexique verbal saisi sur des supports informatiques en vue d'une utilisation par des linguistes et qui peut être appelé à certaines étapes d'un traitement automatique de textes écrits. L’analyse du lexique verbal s’inscrit dans un modèle, celui de la Grammaire Applicative et Cognitive (GAC) développé dans l’équipe LaLIC. Le formalisme utilisé est celui du 􀁨-calcul typé et de la logique combinatoire typée avec ses combinateurs. Le lexique verbal est organisé à l’aide d’un langage de représentation sémantico-cognitif (LRSC) s'appuyant sur un ensemble de relateurs et de primitives sémantico-cognitives typées. Dans un premier temps nous présentons un outil informatique (DISCC) qui a pour tâche d'aider un sémanticien à construire des représentations sémantico-cognitives associées aux significations des verbes; et dans un second temps, nous montrons comment il est possible de consulter les différentes significations d'un vocable verbal polysémique représenté sous forme d'un réseau. La présentation ne présente pas un dictionnaire mais développe une méthodologie de construction et de manipulation d’une base de connaissances sémantico-cognitives des verbes.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-013" session="">
			<auteurs>
				<auteur>
					<prenom>Cédrick</prenom>
					<nom>Fairon</nom>
					<email>fairon@ladl.jussieu.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Jean</prenom>
					<nom>Senellart</nom>
					<email>senella@ladl.jussieu.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LADL, Université Paris 7 2, place Jussieu, 75251 Paris Cedex 05</affiliation>
			</affiliations>
			<titre>Réflexions sur la localisation, l'étiquetage, la reconnaissance et la traduction d'expressions linguistiques complexes</titre>
			<type>long</type>
			<pages></pages>
			<resume></resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract>We describe a process translating automatically time adverbs from English to French. The mechanism is based on the use of finite state transducers. We discuss about the different ways of locating complex linguistic sentences. In order to translate this sentences, we show that the description must be accurate and that the tagging process is not involved. The quality of the translation obtained in this application is an indirect proof of the validity of our description method. Besides, we show the limitations of local approaches to translation.</abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-014" session="">
			<auteurs>
				<auteur>
					<prenom>Françoise</prenom>
					<nom>Gayral</nom>
					<email>fg@lipn.univ-paris13.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Patrick</prenom>
					<nom>Saint-Dizier</nom>
					<email>stdizier@irit.fr</email>
					<affiliationId>2</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LIPN</affiliation>
				<affiliation affiliationId="2">IRIT-CNRS</affiliation>
			</affiliations>
			<titre>Peut-on couper à la polysémie verbale ?</titre>
			<type>long</type>
			<pages></pages>
			<resume>Dans ce bref document, nous présentons des résultats préliminaires d’une méthode de description de la sémantique des formes prédicatives dans un cadre génératif. Nous proposons une méthode pour découper les sens, en identifiant les types d’inférences qu’ils entrainent. Nous proposons une analyse intégrée des métaphores et des métonymies, ainsi qu’une représentation des sens sous forme typée et sous-spécifiée.</resume>
			<mots_cles>sémantique lexicale, prédicats, lexique génératif</mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-015" session="">
			<auteurs>
				<auteur>
					<prenom>Jean-Philippe</prenom>
					<nom>Goldman</nom>
					<email>goldman@latl.unige.ch</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Christopher</prenom>
					<nom>Laenzlinger</nom>
					<email>laenzlinger@latl.unige.ch</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Éric</prenom>
					<nom>Wehrli</nom>
					<email>wehrli@latl.unige.ch</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LATL- Département de linguistique 2 rue de Candolle, CH-1211 Genève-4</affiliation>
			</affiliations>
			<titre>La phonétisation de "plus", "tous" et de certains nombres : une analyse phono-syntaxique</titre>
			<type>long</type>
			<pages></pages>
			<resume>En synthèse automatique de la parole, la phonétisation est une étape cruciale pour une bonne intelligibilité et une bonne qualité de voix. Elle consiste à convertir une suite de mots en chaîne phonétique, qui sera par la suite utilisée pour générer le signal sonore. Les homographes hétérophones et les ajustements phonologiques tels que la liaison et l'élision sont les sources d'erreurs les plus courantes. De plus, des mots comme 'plus' , 'tous' et certains nombres ('cinq', 'six', 'dix',…) pour lesquels plusieurs réalisations phonétiques sont possibles, peuvent également être problématiques. Nous proposons ici une résolution de ces cas complexes par l'utilisation d'une analyse syntaxique.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-016" session="">
			<auteurs>
				<auteur>
					<prenom>Natalia</prenom>
					<nom>Grabar</nom>
					<email>ngr@biomath.jussieu.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Pierre</prenom>
					<nom>Zweigenbaum</nom>
					<email>ngr@biomath.jussieu.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">DIAM - SIM/AP-HP et Université Paris 6</affiliation>
			</affiliations>
			<titre>Acquisition automatique de connaissances morphologiques sur le vocabulaire médical</titre>
			<type>long</type>
			<pages></pages>
			<resume>La morphologie médicale est riche et productive. À côté de la simple flexion, dérivation et composition sont d’autres moyens pour créer des mots nouveaux. La connaissance morphologique se révèle par conséquent très importante pour toute application dans le traitement automatique du langage médical. Nous proposons une méthode simple et puissante pour l’acquisition automatique d’une telle connaissance. Cette méthode tire avantage de listes de termes synonymes disponibles afin d’amorcer le processus d’acquisition. Nous l’avons expérimentée dans le domaine médical sur le Microglossaire de Pathologie SNOMED. Les familles de mots morphologiquement reliés que nous avons obtenues sont correctes à 95 %. Utilisées dans un outil d’aide au codage avec expansion de requête, elles permettent d’en améliorer les performances.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-017" session="">
			<auteurs>
				<auteur>
					<prenom>Gabriel</prenom>
					<nom>Illouz</nom>
					<email>gabrieli@limsi.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LIMSI, CNRS B.P.133, 91403 ORSAY Cedex</affiliation>
			</affiliations>
			<titre>Méta-Étiqueteur Adaptatif : vers une utilisation pragmatique des ressources linguistiques</titre>
			<type>long</type>
			<pages></pages>
			<resume>Le traitement automatique du langage requiert des corpus textuels de plus en plus volumineux, entre autres pour les étiqueteurs morpho-syntaxiques. Ces processus de traitement ne sont pas exempts d'erreurs. Dans l'optique d'améliorer cet étiquetage de corpus hétérogènes (composés de textes tout-venant), une approche adaptative au type de texte utilisant les ressources produites par une campagne d'évaluation sera proposée. Les résultats d'une première validation seront présentés sur les données MULTITAG. Les faits suivants sont constatés : les textes ne sont pas homogènes en terme de distribution de parties du discours, les classifications a priori ne fournissent pas une homogénéité en terme de performance et un même texte peut produire des variations positives pour un système et négatives pour un autre. De plus, il existe une relation entre la typologie de textes obtenue de façon non supervisée sur le jeu de caractères et les variations de performance.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-018" session="">
			<auteurs>
				<auteur>
					<prenom>Alexandra</prenom>
					<nom>Kinyon</nom>
					<email>Alexandra.Kinyon@linguist.jussieu.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">TALANA, UFR de Linguistique, Université Paris 7, Case 7003 2, place Jussieu, 75251 Paris Cedex 05</affiliation>
			</affiliations>
			<titre>Hiérarchisation d'analyses basée sur des informations dépendancielles dans le cadre des LTAGs</titre>
			<type>long</type>
			<pages></pages>
			<resume>Depuis [Kimball 73], les préférences d'attachement telles que "l'association droite" et "l'attachement minimal" ont essentiellement été formulées en termes d'arbres de constituants (e.g. forme, nombre de noeuds ...) . Nous présentons 2 principes de préférence d'attachement formulés en termes d'arbres de dérivation (i.e. d'information dépendancielle) dans le cadre du formalisme des Grammaires d'Arbres Adjoints Lexicalisées (LTAG) . Nous montrons pourquoi ce type d'approche permet de remédier aux défauts des approches structurales exprimées en termes d'arbres de constituants et rendent compte d'heuristiques largement acceptées (i.e. argument / modifieur, idiomes).</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-019" session="">
			<auteurs>
				<auteur>
					<prenom>Olivier</prenom>
					<nom>Kraif</nom>
					<email>kraif@lilla.unice.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LILLA, Université de Nice Sophia Antipolis, 98 Bd. E. Herriot BP 369 06007 Nice Cedex</affiliation>
			</affiliations>
			<titre>Identification des cognats et alignement bi-textuel : une étude empirique</titre>
			<type>long</type>
			<pages></pages>
			<resume>Nous nous intéressons ici aux méthodes d’alignement automatique destinées à produire des corpus bi-textuels, utiles au traducteur, au terminologue ou au linguistique. Certaines techniques ont obtenu des résultats probants en s’appuyant sur la détermination empirique des « cognats » (de l’anglais « cognate »), des mots qui se traduisent l’un par l’autre et qui présentent une ressemblance graphique. Or les cognats sont généralement captés au moyen d’une approximation abrupte, de nature opératoire : on considère tous les 4-grammes (mots possédants 4 lettres en commun) comme cognats potentiels. Aucune étude n’a été faite, à notre connaissance, à propos de la validité de cette approximation. Afin d’en démontrer les possibilités et les limites, nous avons cherché à déterminer empiriquement la qualité de cette simplification, en termes de bruit et de silence (ou de manière complémentaire, de précision et de rappel). Nous avons ensuite essayé de développer un filtrage plus efficace, basé sur l’utilisation des sous-chaînes maximales. Enfin, nous avons corrélé les améliorations du filtrage avec les résultats de l’alignement, en nous basant sur une méthode générale développée par nous : nous avons pu constater un net progrès en terme de rappel et de précision de l’alignement.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-020" session="">
			<auteurs>
				<auteur>
					<prenom>Claude</prenom>
					<nom>Laï</nom>
					<email>lai@lim.univ-mrs.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Robert</prenom>
					<nom>Pasero</nom>
					<email>pasero@lim.univ-mrs.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Laboratoire d’Informatique de Marseille CNRS &amp; Université de la Méditerranée Case 901, 163 Avenue de Luminy, F-13288 Marseille Cedex 9 FRANCE</affiliation>
				<affiliation affiliationId="2"></affiliation>
				<affiliation affiliationId="3"></affiliation>
			</affiliations>
			<titre>Technique de résolution de proformes enchâssées</titre>
			<type>long</type>
			<pages></pages>
			<resume>Nous présentons une technique de résolution de proformes enchâssées à l’aide des métastructures Prolog. Nous montrons tout d’abord un exemple d’utilisation de ces métastructures pour contrôler l’appartenance d’un élément à un domaine. Une plus grande utilité est ensuite démontrée dans la résolution de contraintes contextuelles dynamiques, qui sont particulières dans le sens où elles interviennent en fonction des contraintes déjà existantes sur les éléments considérés. Une application utile de ces contraintes est d’éviter les redondances dans la recherche des possibilités de référents pour un discours considéré, notamment dans le cas de proformes enchâssées.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-021" session="">
			<auteurs>
				<auteur>
					<prenom>Patrice</prenom>
					<nom>Lopez</nom>
					<email>lopez@loria.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Christine</prenom>
					<nom>Fay-Varnier</nom>
					<email>fay@loria.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Azim</prenom>
					<nom>Roussanaly</nom>
					<email>azim@loria.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LORIA BP 239 - 54506 Vandoeuvre-lès-Nancy, France</affiliation>
			</affiliations>
			<titre>Sous-langages d’application et LTAG : le système EGAL</titre>
			<type>long</type>
			<pages></pages>
			<resume>Nous présentons un système dédié à la conception et au test d’un sous-language d’application pour un système de Dialogue Homme-Machine. EGAL se base sur une grammaire LTAG générale de la langue qui est spécialisée à une application donnée à l’aide d’un corpus d’entraînement. Un double effort a porté premièrement sur la définition d’une méthodologie précise passant par une expérimentation de type Magicien d’Oz pour le recueil des corpus et des estimations de la représentativité du corpus de conception, et, deuxièmement, sur la spécification des composants du système en vue de mettre en oeuvre des outils convivaux, génériques et ouverts.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-022" session="">
			<auteurs>
				<auteur>
					<prenom>Piet</prenom>
					<nom>Mertens</nom>
					<email>Piet.Mertens@arts.kuleuven.ac.be</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Centrum voor Computerlinguïstiek, K.U.Leuven, BP 33, 3000 Leuven (Belgique)</affiliation>
			</affiliations>
			<titre>Un algorithme pour la génération de l’intonation dans la parole de synthèse</titre>
			<type>long</type>
			<pages></pages>
			<resume>L’article décrit l’implémentation d’un modèle d’intonation dans son application à la synthèse de la parole pour le français. Le modèle se caractérise par l’importance accordée à la syntaxe et par une approche analytique de l’intonation qui, en synthèse, permet une manipulation explicite et compositionnelle du sens intonatif. Le traitement proprement dit est précédé d’une analyse syntaxique identifiant les constituants, certains rapports de dépendance ou certaines constructions qui demandent une intonation particulière. Ces aspects intonatifs sont représentés par des marqueurs symboliques. À partir de l’arborescence sont constitués les groupes intonatifs, tout en tenant compte du rythme. Dans certaines conditions, des réajustements de la structure syntaxique seront effectués. Les tons mélodiques sont attribués aux groupes en fonction des marqueurs et des rapports syntaxiques.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-023" session="">
			<auteurs>
				<auteur>
					<prenom>Laurent</prenom>
					<nom>Miclet</nom>
					<email>miclet@enssat.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Jacques</prenom>
					<nom>Chodorowski</nom>
					<email>chodorow@enssat.fr</email>
					<affiliationId></affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">ENSSAT - IRISA</affiliation>
			</affiliations>
			<titre>Apprentissage et Evaluation de Modèles de Langage par des Techniques de Correction d’Erreurs</titre>
			<type>long</type>
			<pages></pages>
			<resume>Cet article a pour but de décrire la mise au point et l’expérimentation de méthodes d’apprentissage de syntaxe à partir d’exemples positifs, en particulier pour des applications de Reconnaissance de la Parole et de Dialogue Oral. Les modèles syntaxiques, destinés à être intégrés dans une chaîne de traitement de la parole, sont extraits des données par des méthodes d’inférence grammaticale symbolique et stochastique. Ils sont fondés sur des techniques de correction d’erreurs dans les séquences. L’ensemble de ce travail a été réalisé dans le cadre du contrat 97- 1B-004 avec France-Telecom (Centre National d’Etudes des Télécommunications). Dans la première partie de cet article, nous rappellons les distances entre séquences basées sur des opérations élémentaires de correction d’erreur. Nous décrivons ensuite un algorithme classique d’inférence grammaticale fondé sur cette notion, et nous en proposons une amélioration. Nous abordons à cet endroit le problème de l’évaluation d’un concept appris seulement à partir d’exemples positifs, sans contre-exemples. Par la suite, le modèle syntaxique est étendu en attribuant des probabilités (apprises à partir des données) aux règles de la grammaire. On dispose dans ce cadre d’un outil d’évaluation de la qualité de l’apprentissage : la perplexité ; cependant pour obtenir des résultats significatifs, il faut être capable de probabiliser l’espace entier des séquences, ce qui implique de lisser la grammaire stochastique apprise. Une technique de lissage est proposée, qui permet alors d’évaluer l’apprentissage sur le corpus de données issues de l’expérimentation en dialogue oral.</resume>
			<mots_cles>Inférence grammaticale régulière, analyse corrective, évaluation du modèle de language</mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-024" session="">
			<auteurs>
				<auteur>
					<prenom>Frédéric</prenom>
					<nom>Meunier</nom>
					<email>frederic.meunier@lcr.thomson-csf.com</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Laboratoire central de Recherches Thomson-CSF Domaine de Corbeville 91404 Orsay cedex</affiliation>
			</affiliations>
			<titre>Modélisation des ressources linguistiques d’une application industrielle</titre>
			<type>long</type>
			<pages></pages>
			<resume>Cet article présente les avantages qu’apporte la modélisation des ressources linguistiques utilisées dans une application. Le lecteur trouvera également dans cet article une présentation rapide de deux méthodes répandues dans le monde de l’informatique (Merise et UML) et leur modèle associé (entité relation et objet). Enfin, nous donnerons un exemple de modélisation des ressources linguistiques d’une application en cours de développement.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-025" session="">
			<auteurs>
				<auteur>
					<prenom>Christiane</prenom>
					<nom>Panissod</nom>
					<email>panissod@lrl.univ-bpclermont.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LRL, Laboratoire de Recherche sur le Langage, Maison de la Recherche Université Clermont II Blaise Pascal 4, rue Ledru 63057 Clermont-Ferrand Cedex 1</affiliation>
			</affiliations>
			<titre>Quantification et anaphore : entité anaphorique complexe (méronymique, processuelle, situationnelle)</titre>
			<type>long</type>
			<pages></pages>
			<resume>Quels types d'informations sont nécessaires à l'interprétation de référents évolutifs et de référents associés ? Nous verrons que les anaphores évolutives et associatives sont construites à partir de processus et de situations, et que leur interprétation nécessite une représentation lexicale complexe. Les approches atomiques peuvent par conséquent difficilement rendre compte de ce type d'anaphores : cependant les propriétés des quantificateurs semblent jouer un rôle dans ces phénomènes.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-026" session="">
			<auteurs>
				<auteur>
					<prenom>Manuel</prenom>
					<nom>Palomar</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Antonio</prenom>
					<nom>Ferràndez</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Lidia</prenom>
					<nom>Moreno</nom>
					<email></email>
					<affiliationId>2</affiliationId>
				</auteur>
				<auteur>
					<prenom>Maximiliano</prenom>
					<nom>Saiz-Noeda</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Raphael</prenom>
					<nom>Muñoz</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Patricio</prenom>
					<nom>Martìnez-Barco</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Jesùs</prenom>
					<nom>Peral</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Borja</prenom>
					<nom>Navarro</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Universidad de Alicante</affiliation>
				<affiliation affiliationId="2">Universidad de Valencia</affiliation>
			</affiliations>
			<titre></titre>
			<type>long</type>
			<pages></pages>
			<resume></resume>
			<mots_cles></mots_cles>
			<title>A Robust Partial Parsing Strategy based on the Slot Unification Grammars</title>
			<abstract>In this paper we present a robust partial parser (Slot Unification Partial Parser, SUPP) based on the Slot Unification Grammars, SUG. Our parsing strategy analyzes coordinated nouns and prepositional phrases and verbal chunks (verbs in their simple and compound forms and verbal periphrasis) and it’s guided to the linguistic phenomena resolution. Its adaptability to different taggers or dictionaries makes it a general purpose system. To show this universality, the system has been evaluated with two Spanish corpora (LEXESP and Blue Book), achieving precision and recall values between 95 %-97%.</abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-027" session="">
			<auteurs>
				<auteur>
					<prenom>Ronan</prenom>
					<nom>Pichon</nom>
					<email>rpichon@irisa.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Pascale</prenom>
					<nom>Sébillot</nom>
					<email>sebillot@irisa.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">IRISA Campus de Beaulieu 35042 Rennes cedex</affiliation>
				<affiliation affiliationId="2"></affiliation>
				<affiliation affiliationId="3"></affiliation>
			</affiliations>
			<titre>Différencier les sens des mots à l’aide du thème et du contexte de leurs occurrences : une expérience</titre>
			<type>long</type>
			<pages></pages>
			<resume>Dans cet article, nous montrons, à travers l’exposé de résultats d’une expérience menée sur corpus, comment la connaissance des thèmes dans lesquels apparaissent des mots et la mise en évidence de similarités et de différences entre les voisinages de leurs occurrences dans les parties de textes abordant ces thèmes permettent de mettre au jour des différences fines dans les acceptions associées aux mots dans chacun de ces thèmes. La méthode proposée pour ce faire est presque entièrement automatique et est basée sur le calcul d’intersections et de différences ensemblistes entre des séquences de mots constituant des contextes.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-028" session="">
			<auteurs>
				<auteur>
					<prenom>Ludovic</prenom>
					<nom>Tanguy</nom>
					<email>Ludovic.Tanguy@issco.unige.ch</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Susan</prenom>
					<nom>Armstrong</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Derek</prenom>
					<nom>Walker</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">ISSCO - Université de Genève 54 Route des Acacias - 1227 Genève - Suisse</affiliation>
			</affiliations>
			<titre>Isotopies sémantiques pour la vérification de traduction</titre>
			<type>long</type>
			<pages></pages>
			<resume>A des fins d’automatisation de la vérification de traduction, les méthodes traditionnelles se basent généralement sur un fort niveau de littéralité dans le style de la traduction. En faisant appel à des bases terminologiques multilingues et des algorithmes d’alignement de textes parallèles, il est possible de vérifier dans un travail de traduction le respect de normes strictes, sous la forme d’une liste de possibilités de traduction pour un terme donné. Nous proposons ici une méthode alternative basée sur le repérage, dans les deux textes, de structures sémantiques générales, ou isotopies, et la comparaison des schémas qu’elles présentent au niveau du texte et non plus de la phrase ou du paragraphe, permettant ainsi une plus grande tolérance dans le style de traduction à vérifier.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-long-029" session="">
			<auteurs>
				<auteur>
					<prenom>Graham</prenom>
					<nom>Wilcock</nom>
					<email>graham@ccl.umist.ac.uk</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Centre for Computational Linguistics University of Manchester Institute of Science and Technology PO Box 88, Manchester M60 1QD, United Kingdom</affiliation>
			</affiliations>
			<titre>Héritage Multiple et Templates dans l'Implantation de HPSG</titre>
			<type>long</type>
			<pages></pages>
			<resume>L'analyse des propositions relatives en anglais telle que déecrite par Sag (1997) se base sur une classification à deux dimensions des constructions syntaxiques en HPSG. Nous présentons ici une implémentation de cette analyse, fondée sur l'héritage multiple et les templates à deux dimensions dans le système ProFIT (Erbach, 1995).</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-001" session="">
			<auteurs>
				<auteur>
					<prenom>Elisabeth</prenom>
					<nom>Aimelet</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Veronika</prenom>
					<nom>Lux</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Corinne</prenom>
					<nom>Jean</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Frédérique</prenom>
					<nom>Segond</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Xerox Research Centre Europe 6, chemin de Maupertuis, 38240 Meylan France</affiliation>
				<affiliation affiliationId="2"></affiliation>
				<affiliation affiliationId="3"></affiliation>
			</affiliations>
			<titre></titre>
			<type>poster</type>
			<pages></pages>
			<resume></resume>
			<mots_cles></mots_cles>
			<title>WSD evaluation and the looking-glass</title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-002" session="">
			<auteurs>
				<auteur>
					<prenom>Chiraz</prenom>
					<nom>Ben Othmane Zribi</nom>
					<email>chiraz@apexmail.com</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Adnane</prenom>
					<nom>Zribi</nom>
					<email>Adnane.Zribi@isg.rnu.tn</email>
					<affiliationId>2</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Université Paris-sud, Orsay, France</affiliation>
				<affiliation affiliationId="2">Université Tunis III, I.S.G., Tunisie</affiliation>
			</affiliations>
			<titre>Algorithmes pour la correction des erreurs orthographiques en arabe</titre>
			<type>poster</type>
			<pages></pages>
			<resume>Nous traitons dans ce papier du problème de la détection et de la correction des graphies fautives dans les textes arabes. Nous commençons par présenter une expérience visant à mesurer de manière comparative la difficulté du problème pour l'arabe, le français et l'anglais. L'idée est d'évaluer le degré de "ressemblance" (proximité) des mots au sein de chaque langue. Ensuite les algorithmes de base de notre méthode de correction sont présentés.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-003" session="">
			<auteurs>
				<auteur>
					<prenom>Pierre</prenom>
					<nom>Boullier</nom>
					<email>Pierre.Boullier@inria.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">INRIA-Rocquencourt Domaine de Voluceau B.P. 105 78153 Le Chesnay Cedex, France</affiliation>
			</affiliations>
			<titre></titre>
			<type>poster</type>
			<pages></pages>
			<resume></resume>
			<mots_cles></mots_cles>
			<title>On Multicomponent TAG Parsing</title>
			<abstract>The notion of mild context-sensitivity is an attempt to express the formal power needed to define the syntax of natural languages. However, all incarnations of mildly context-sensitive formalisms are not equivalent. On the one hand, near the bottom of the hierarchy, we find tree adjoining grammars and, on the other hand, near the top of the hierarchy, we find multicomponent tree adjoining grammars. This paper proposes a polynomial parse time method for multicomponent tree adjoining grammars. This method uses range concatenation grammars as a high-level intermediate definition formalism. We show some upper bounds on the parse time of the set-local version of multicomponent tree adjoining grammar, and we introduce a hierarchy of restricted forms which can be parsed more efficiently. Our approach aims at giving both a new insight into the multicomponent adjunction mechanism and at providing a practical implementation schema.</abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-004" session="">
			<auteurs>
				<auteur>
					<prenom>Gustavo</prenom>
					<nom>Crispino</nom>
					<email>crispino@fing.edu.uy</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Slim</prenom>
					<nom>Ben Hazez</nom>
					<email>benhazez@msh-paris.fr</email>
					<affiliationId>2</affiliationId>
				</auteur>
				<auteur>
					<prenom>Jean-Luc</prenom>
					<nom>Minel</nom>
					<email>minel@msh-paris.fr</email>
					<affiliationId>2</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Université de la République</affiliation>
				<affiliation affiliationId="2">CAMS/LaLic, UMR du CNRS</affiliation>
			</affiliations>
			<titre>Architecture logicielle de Context plate-forme d’ingénierie linguistique</titre>
			<type>poster</type>
			<pages></pages>
			<resume>Nous présentons dans cet article l'architecture logicielle de Context, plate-forme d'ingénierie linguistique dédiée au filtrage sémantique. Nous avons défini un modèle conceptuel et un langage de description et de traitement des connaissances linguistiques. Ces connaissances sont gérées par un système dédié et indépendant des applications qui les utilisent. Les traitements sont spécifiés sous forme déclarative dans un langage formel que nous présentons.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-005" session="">
			<auteurs>
				<auteur>
					<prenom>Gaël</prenom>
					<nom>Dias</nom>
					<email>ddg@di.fct.unl.pt</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Sylvie</prenom>
					<nom>Guilloré</nom>
					<email>sylvie.guillore@lifo.univ-orleans.fr</email>
					<affiliationId>2</affiliationId>
				</auteur>
				<auteur>
					<prenom>Gabriel Pereira</prenom>
					<nom>Lopes</nom>
					<email>gpl@di.fct.unl.pt</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Universidade Nova de Lisboa, FCT/DI Quinta da Torre, 2825-114, Monte da Caparica, Portugal</affiliation>
				<affiliation affiliationId="2">Université d'Orléans, Laboratoire d'Informatique Fondamentale d'Orléans BP 6102 - 45061, Orléans Cédex 2, France</affiliation>
			</affiliations>
			<titre></titre>
			<type>poster</type>
			<pages></pages>
			<resume></resume>
			<mots_cles></mots_cles>
			<title>Language Independent Automatic Acquisition of Rigid Multiword Units from Unrestricted Text Corpora</title>
			<abstract>Multiword units are groups of words that occur together more often than expected by chance in sub-languages. Président de la république, coupe du monde and Traité de Maastricht are multiword units. Unfortunately, most of the machine-readable dictionaries contain clearly insufficient information about multiword unitsi. Therefore, their automatic extraction from corpora is an important issue not only for natural language processing but also for applications on Information Retrieval, Information Extraction and Machine Translation. In this paper, we propose a new extraction system based on a new association measure, the Mutual Expectation, and a new acquisition process based on an algorithm of local maxima, the LocalMax algorithm.</abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-006" session="">
			<auteurs>
				<auteur>
					<prenom>Mohamed</prenom>
					<nom>Gouiaa</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Sylvain</prenom>
					<nom>Delisle</nom>
					<email>Sylvain_Delisle@uqtr.uquebec.ca</email>
					<affiliationId>2</affiliationId>
				</auteur>
				<auteur>
					<prenom>Bernard</prenom>
					<nom>Moulin</nom>
					<email>moulin@ift.ulaval.ca</email>
					<affiliationId>1</affiliationId>
					<affiliationId>3</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Département d’informatique, Université Laval, Québec, Canada</affiliation>
				<affiliation affiliationId="2">Centre de recherche en géomatique de l’Université Laval</affiliation>
				<affiliation affiliationId="3">Département de mathématiques et d’informatique Université du Québec à Trois-Rivières, Québec, Canada</affiliation>
			</affiliations>
			<titre>L’analyse sémantique de dialogues oraux transcrits</titre>
			<type>poster</type>
			<pages></pages>
			<resume>Nous présentons les principaux résultats obtenus à ce jour dans le cadre du projet MAREDI qui vise à développer un système de traitement de la langue naturelle permettant d’analyser des transcriptions de dialogues oraux et de générer un modèle conceptuel de la conversation. Nous discutons principalement des aspects touchant l’analyse sémantique, en l’occurrence le rôle qu’y jouent les actes de discours et l’analyse casuelle, tout en présentant brièvement l’architecture globale du système et les caractéristiques de ses différentes composantes.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-007" session="">
			<auteurs>
				<auteur>
					<prenom>Franciscus</prenom>
					<nom>Grootjen</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Vera</prenom>
					<nom>Kamphuis</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Janos</prenom>
					<nom>Sarbo</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Computing Science Institute &amp; Dept. of Language and Speech University of Nijmegen, P.O. Box 9010, 6500 GL Nijmegen, The Netherlands</affiliation>
			</affiliations>
			<titre></titre>
			<type>poster</type>
			<pages></pages>
			<resume></resume>
			<mots_cles></mots_cles>
			<title>Coordination and multi-relational modelling: ‘X and X’ revisited</title>
			<abstract>A relational model of language is developed which unifies traditional features of X-bar theory with lexicon based modelling. It is argued that such a model provides the appropriate basis for handling problematic cases of non-constituent coordination and gapping. A prototype implementation is discussed on the basis of six representative examples, corpus-based.</abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-008" session="">
			<auteurs>
				<auteur>
					<prenom>Mathieu</prenom>
					<nom>Lafourcade</nom>
					<email>lafourcade@lirmm.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Eugène</prenom>
					<nom>Sandford</nom>
					<email>sandford@lirmm.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LIRMM - 161, rue Ada - 34392 Montpellier Cedex 5 - France</affiliation>
			</affiliations>
			<titre>Analyse et dsambigusation lexicale par vecteurs smantiques</titre>
			<type>poster</type>
			<pages></pages>
			<resume>Cet article introduit une reprsentation du sens base sur des vecteurs de notions. Ces vecteurs smantiques ont pour but de rendre compte de lÕensemble des ides voques dans un segment textuel. Ce type de reprsentation utilis en conjonction avec une analyse morphosyntaxique classique permet dÕeffectuer dans de nombreux cas une dsambigusation lexicale efficace.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-009" session="">
			<auteurs>
				<auteur>
					<prenom>Jérôme</prenom>
					<nom>Lehuen</nom>
					<email>Jerome.Lehuen@univ-lemans.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Daniel</prenom>
					<nom>Luzzati</nom>
					<email>Daniel.Luzzati@univ-lemans.fr</email>
					<affiliationId></affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Équipe Langue &amp; Dialogue - LIUM - Université du Maine Avenue Laennec, 72085 Le Mans Cedex 9</affiliation>
			</affiliations>
			<titre>Acquisition coopérative d’une compétence langagière interprétative en dialogue homme-machine</titre>
			<type>poster</type>
			<pages></pages>
			<resume>Nous présentons dans cet article une approche acquisitionniste de la langue naturelle dans le cadre du dialogue homme-machine finalisé, ainsi qu’une première implémentation. Le système de dialogue COALA, qui tente de mettre en oeuvre cette approche, se constitue ses propres représentations à partir de son expérience, au lieu d’utiliser des connaissances langagières pré-codées. Les premiers dialogues obtenus sont de ce fait laborieux, mais ils deviennent progressivement conviviaux. Le système COALA réunit d’une part un modèle de dialogue (non décrit dans cet article) et d’autre part une méthode d’analyse par chart hypothéticodéductif qui permet une forme d’apprentissage par extraction de régularités structurelles.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-010" session="">
			<auteurs>
				<auteur>
					<prenom>Jean-Luc</prenom>
					<nom>Manguin</nom>
					<email>manguin@elsap.unicaen.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Bernard</prenom>
					<nom>Victorri</nom>
					<email>Bernard.Victorri@ens.fr</email>
					<affiliationId>2</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Laboratoire ELSAP CNRS – Université de Caen Esplanade de la Paix 14032 Caen Cedex</affiliation>
				<affiliation affiliationId="2">Laboratoire LTM CNRS – ENS Montrouge 1 , rue Maurice Arnoux 92120 Montrouge</affiliation>
				<affiliation affiliationId="3"></affiliation>
			</affiliations>
			<titre>Représentation géométrique d’un paradigme lexical</titre>
			<type>poster</type>
			<pages></pages>
			<resume></resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-011" session="">
			<auteurs>
				<auteur>
					<prenom>Christoph</prenom>
					<nom>Neumann</nom>
					<email></email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">School of Information Science Tokyo Institute of Technology Oookayama 2-12-1, Meguro-ku, Tokyo 152-855 Japon</affiliation>
				<affiliation affiliationId="2">neumann@cs.titech.ac.jp</affiliation>
			</affiliations>
			<titre>Une représentation interlingua de la modalité</titre>
			<type>poster</type>
			<pages></pages>
			<resume>Notre étude propose un modèle cohérent pour formaliser la modalité pour une implémentation en tant que module interlingua d'un système de traduction automatique (TA). Un grand nombre d'erreurs de traduction en TA peut être attribué à l'absence d'un traitement autonome de modalité. Le modèle tient compte de l'hétérogénéité des éléments modaux et permet la combinaison des éléments déclencheurs.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-012" session="">
			<auteurs>
				<auteur>
					<prenom>David</prenom>
					<nom>Mowatt</nom>
					<email>dmowatt@fs1.ccl.umist.ac.uk</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">UMIST, Manchester, UK</affiliation>
			</affiliations>
			<titre></titre>
			<type>poster</type>
			<pages></pages>
			<resume></resume>
			<mots_cles></mots_cles>
			<title>Types of Semantic Information Necessary in a Machine Translation Lexicon</title>
			<abstract>This paper describes research undertaken into assessing what types of semantic information (SI) are needed in a Machine Translation (MT) lexicon in order for ‘good’ translation quality to be attainable. We present a typology of semantic information, allowing the use of semantics in any MT system to be quantified in precise and absolute, rather than relative, terms. This typology was used to survey the SI present in twenty commercial and research MT systems. An automatically translated corpus was analysed to identify which types of semantics were necessary to achieve high quality translation. The survey and the analysis allowed us to conclude that four of the nine types of SI identified should always be included and that a further two complex SI types should be considered for inclusion pending further analysis. A formal lexicon specification incorporating these six SI types is presented.</abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-013" session="">
			<auteurs>
				<auteur>
					<prenom>David</prenom>
					<nom>Roussel</nom>
					<email>David.Roussel@imag.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Jean</prenom>
					<nom>Caelen</nom>
					<email>Jean.Caelen@imag.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Michel</prenom>
					<nom>Grabisch</nom>
					<email>grabisch@thomson-lcr.fr</email>
					<affiliationId>2</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Laboratoire CLIPS Univ. Joseph Fourier BP 53, 38041 Grenoble Cedex</affiliation>
				<affiliation affiliationId="2">THOMSON/CSF-LCR Domaine de Corbeville 91404 Orsay Cedex</affiliation>
			</affiliations>
			<titre>Classification multicritère floue d’analyses robustes pour les systèmes de dialogue parlé</titre>
			<type>poster</type>
			<pages></pages>
			<resume>Nous présentons une méthode de classification d’analyses robustes sur des hypothèses concurrentes d’un système de reconnaissance de la parole. Pour réaliser cette classification, différents critères hétérogènes sont combinés, comme le score de reconnaissance, diverses caractéristiques syntaxiques et sémantiques propres à l’analyse robuste effectuée ou encore des estimations de la cohérence pragmatique. L’analyse est fondée sur une variante des LTAG (Lexicalized Tree Adjoining Grammars). La classification proposée est évaluée à partir d’un corpus d’analyses robustes d’hypothèses de reconnaissance.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-014" session="">
			<auteurs>
				<auteur>
					<prenom>David</prenom>
					<nom>Roussel</nom>
					<email>David.Roussel@imag.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
				<auteur>
					<prenom>Patrice</prenom>
					<nom>Lopez</nom>
					<email>lopez@loria.fr</email>
					<affiliationId></affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Laboratoire CLIPS Univ. Joseph Fourier, BP 53 38041 Grenoble Cedex</affiliation>
				<affiliation affiliationId="2">LORIA Univ. Henri Poincaré Nancy 1, BP 239 54506 Vandoeuvre Cedex</affiliation>
			</affiliations>
			<titre>Contribution à l’analyse robuste non déterministe pour les systèmes de dialogue parlé</titre>
			<type>poster</type>
			<pages></pages>
			<resume>Nous présentons une technique d’analyse robuste dans le but de relayer la décision d’un système de reconnaissance de la parole. La stratégie d’analyse proposée est fondée sur une grammaire d’arbres adjoints lexicalisée compactée et sur la mise en concurrence des différentes hypothèses du système de reconnaissance de la parole. Les problèmes de robustesse sont étudiés en considérant les interférences entre erreurs de reconnaissance de la parole et phénomènes de parole spontanée dans les dialogues homme-machine.</resume> 
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
		<article id="taln-1999-poster-015" session="">
			<auteurs>
				<auteur>
					<prenom>Luc</prenom>
					<nom>Steels</nom>
					<email>steels@arti.vub.ac.be</email>
					<affiliationId>1</affiliationId>
					<affiliationId>2</affiliationId>
				</auteur>
				<auteur>
					<prenom>Frédéric</prenom>
					<nom>Kaplan</nom>
					<email>kaplan@csl.sony.fr</email>
					<affiliationId>1</affiliationId>
					<affiliationId>3</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Sony CSL Paris - 6 rue Amyot, 75005 Paris</affiliation>
				<affiliation affiliationId="2">VUB AI Laboratory - Pleinlaan 2, 1050 Brussels</affiliation>
				<affiliation affiliationId="3">LIP6 - OASIS - UPMC - 4, place Jussieu F-75252 Paris</affiliation>
			</affiliations>
			<titre>Amorçage d’une sémantique lexicale dans une population d’agents autonomes, ancrés et situés</titre>
			<type>poster</type>
			<pages></pages>
			<resume>Cet article décrit l’amorçage d’une ontologie et d’un lexique partagé dans une population d’agents robotiques dotés de capacités visuelles. Cette évolution a lieu alors que les agents jouent un jeu de langage, appelé ”guessing game”. Nous étudions les dynamiques d’un tel système et montrons, en particulier, comment la synonymie et l’ambiguïté du système sémantique, qui émergent dans un premier temps, sont progressivement réduites au fur et à mesure que l’environnement physique se complexifie.</resume>
			<mots_cles></mots_cles>
			<title></title>
			<abstract></abstract>
			<keywords></keywords>
		</article>
	</articles>
</conference>
