Conf√©rence TALN 1999, Carg√®se, 12-17 juillet 1999
On TAG Parsing

Pierre Boullier

INRIA-Rocquencourt
Domaine de Voluceau
78153 Le Chesnay Cedex, France
E-mail: Pierre.Boullier@inria.fr
R√©sum√©
The subject of tree adjoining grammar parsing inspired many researches but they all failed
O
to beat the
n6
parse time wall. Thus, some present researches in this field try to identify
efficient parser implementations either for the full grammar class, or for linguistically signif-
icant subclasses. This paper addresses both issues and proposes a method which uses range
concatenation grammars as an intermediate implementation formalism. Range concatenation
grammar is a syntactic formalism which is both powerful, in so far as it extends linear context-
free rewriting systems, and efficient, in so far as its sentences can be parsed in polynomial time.
We show two methods by which unrestricted tree adjoining grammars can be transformed into
O
equivalent range concatenation grammars which can be parsed in
n6
time, and, moreover,
if the input tree adjoining grammar has some restricted form, its parse time decreases to
n5
.    O
1. Introduction
The subject of tree adjoining grammar (TAG) parsing, or equivalent formalisms such as
linear indexed grammar (LIG), inspired many researches but they all failed to beat the
n6
O
parse time wall.1 Thus, current researches in this field, can be divided into two parts. A first one
which tries to find parsing methods which can be efficiently implemented, and a second one,
which tries to identify linguistically significant TAG subclasses whose theoretical parse time
O
is smaller than
n6
. In this paper, we try to reconcile these two approaches. To reach this
goal, we propose a method which uses range concatenation grammar (RCG) as an intermediate
implementation formalism for TAG parsing.
The notion of RCG is introduced in [Boullier, 1998a]; it is a syntactic formalism which is
a variant of the simple version of literal movement grammar, described in [Groenink, 1997],
and which is also related to the framework of LFP developed by [Rounds, 1988]. This formal-
ism extends context-free grammars (CFGs) and is even more powerful than linear context-free
An
extended version of this paper is in [Boullier, 1999a]
1
Asymptotically faster methods are known, but they all possess large hidden constants. There are even some
arguments (see [Satta, 1994]) against the existence of faster algorithms with small constants.

Pierre Boullier
rewriting systems (LCFRS)2 [Vijay-Shanker, Weir, and Joshi, 1987], while staying computa-
tionally tractable: its sentences can be parsed in polynomial time. This paper will not address
the usage of RCGs as a formalism in which the syntax of natural languages (NLs) can be directly
defined. We will rather explore an indirect usage as an intermediate implementation formalism.
This usage of RCGs has already been studied in [Boullier, 1998a] for syntactic formalisms such
as LIGs or LCFRS. The TAG parsing case has been particularly studied in [Boullier, 1998b], but
the algorithm which transforms a TAG into an equivalent RCG is only proposed for a restricted
O
class of adjunction constraints, and, moreover, the
n6
parse time is only reached when the
original TAG is in a special normal form.
This paper shows two new ways to parse TAGs with RCGs. Both methods accept unrestricted
TAGs as inputs, however, the first one directly produces an equivalent RCG which is, in turn,
transformed into another RCG, while the second one first dissects the elementary trees of the
input TAG before applying a transformation into an object RCG. Both methods produce an
O
equivalent RCG which can be parsed in
n6
time. Moreover, if the initial TAG is in the
restricted form introduced in [Satta and Schuler, 1998], the corresponding RCG has an
n5
O
parse time.
2. Range Concatenation Grammars
This section introduces the notion of RCG, more details can be found in [Boullier, 1998a].
A positive range concatenation grammar (PRCG) G =
N; T; V; P; S
is a 5-tuple where
N is a finite set of predicate names, T and V are finite, disjoint sets of terminal symbols and
2
variable symbols respectively, S N is the start predicate name, and P is a finite set of clauses

0 ! 1 : : : m
where m        0 and each of 0 ; 1; : : : ; m is a predicate of the form
A
1; : : : ; i; : : : ; p

where p      1 is its arity, A 2 N and each of i 2
T V
 , 1  i  p, is an argument.
Each occurrence of a predicate in the RHS of a clause is a predicate call, it is a predicate
definition if it occurs in its LHS. Clauses which define predicate A are called A-clauses. This
definition assigns a fixed arity to each predicate name. The arity of the start predicate is one.
The arity k of a grammar (we have a k -PRCG), is the maximum arity of its predicates.
Lower case letters such as a; b; c; : : : will denote terminal symbols, while upper case letters
such as L; R; X; Y; Z will denote elements of V .
The language defined by a PRCG is based on the notion of range. For a given input string
w = a1 : : : an a range is a couple
i; j
, 0  i  j  n of integers which denotes the occurrence
of some substring ai : : : aj in w . The number j , i is its size. We will use several equivalent
+1

denotations for ranges: an explicit dotted notation like w1 w2 w3 or, if w2 extends from
positions i + 1 through j , a tuple notation hi::j iw , or hi::j i when w is understood or of no
importance. For a range hi::j i, i is its lower bound and j is its upper bound. If i = j , we have
2
In [Boullier, 1999b], we argue that this extra power can be used in natural language processing.

On TAG Parsing
an empty range. Of course, only consecutive ranges can be concatenated into new ranges. In any
PRCG, terminals, variables and arguments in a clause are supposed to be bound to ranges by
a substitution mechanism. An instantiated clause is a clause in which variables and arguments
are consistently (w.r.t. the concatenation operation) replaced by ranges; its components are
instantiated predicates.
h       ih ih i ! h
For example, A
g::h ; i::j ; k::l
ih         ih       i
B
g+1::h ; i+1::j -1 ; k::l-1
is an instantiation of
the clause A
aX; bY c; Zd
!   B
X; Y; Z
if the source text a1 : : : an is such that ag+1 =
a; ai+1 = b; aj = c and al = d. In this case, the variables X , Y and Z are bound to g+1::h ,      h       i
h       i      h      i
i+1::j -1 and k::l-1 respectively.
For a given PRCG and an input string
, is defined on
w, a derive relation, denoted by G;w
strings of instantiated predicates. If an instantiated predicate is the LHS of some instantiated
clause, it can be replaced by the RHS of that instantiated clause.
The language of a PRCG G =
N; T; V; P; S
is the set
+ "g
L
G
= fw j S
w
G;w
An input string w = a1 : : : an is a sentence iff the empty string (of instantiated predicates)
h        i
can be derived from S
0::n
. Note that the order of predicate calls in the RHS of a clause is
of no importance.3
The arguments of a given predicate may denote discontinuous or even overlapping ranges.
Fundamentally, a predicate name A defines a notion (property, structure, dependency, . . . ) be-
tween its arguments whose ranges can be arbitrarily scattered over the source text. PRCGs are
therefore well suited to describe long distance dependencies. Overlapping ranges arise as a con-
sequence of the non-linearity of the formalism. For example, the same variable (denoting the
same range) may occur in different arguments in the RHS of some clause, expressing different
views (properties) of the same portion of the source text. However, in this paper, we do not need
the full power of RCGs and we will restrict our attention to the simple subclass of PRCGs.
A clause is simple4 if it is

non-combinatorial: each argument of its RHS predicates consists of a single variable, and
non-erasing and linear: each of its variables appears exactly one time in its LHS and one time
in its RHS.

A simple RCG is an RCG in which all its clauses are simple.
As an example, the following simple 3-PRCG defines the three-copy language               fwww j w 2
fa; bgg which is not a CFL and is not even a TAL.
S
XY Z
!            A
X; Y; Z

A
aX; aY; aZ
!              A
X; Y; Z

A
bX; bY; bZ
!              A
X; Y; Z

A
"; "; "
!            "
3
In [Boullier, 1998a], we also define negative RCG (NRCG), which allows negative predicate calls. These
negative calls define the complement language w.r.t. T  of their positive counterpart. A range concatenation
grammar (RCG) is either a PRCG or a NRCG.
4
This is not Groenink‚Äôs definition of simple.

Pierre Boullier
A parsing algorithm for RCGs has been presented in [Boullier, 1998a]. For an RCG G and
an input string of length n, it produces a parse forest in time polynomial with n and linear with
j j
G . The degree of this polynomial is at most the number of free (independent) bounds in any
Oj j
clause. For a simple k -RCG, its parse time is at worst
G nd
with d = maxcj 2P
kj + vj
if cj denotes the j th clause in P , kj is the arity of its LHS predicate and vj is the number of its
variables.
3. First Transformation from Unrestricted TAG to Simple PRCG
The notion of mild context-sensitivity originates in an attempt by [Joshi, 1985] to express the
formal power needed to define the syntax of NLs, and the most popular incarnation of mildly
context-sensitive formalisms is certainly the TAG formalism. A TAG is a tree rewriting system
where trees are composed by means of the operations of adjunction and substitution. Here, we
assume that the reader is familiar with TAGs (see [Joshi, 1987] for an introduction).
First, we introduce the notion of decoration strings.
The set of nodes (addresses) in a tree or in a set of trees is denoted by      . LetN     =   T
IA

VN ; T; ; ; S
be an input TAG. Every node
2N
in every elementary (either initial or
auxiliary) tree   2I A   is decorated as follows.

If
is an adjunction node, it is decorated by two symbols, a left decoration L
and a right
decoration R
called its LR-variables. These symbols are RCG variables which capture
the terminal yields of the complete derived trees that can be adjoined at
. Its left (resp.
right) terminal yield, lays to the left (resp. right) of the foot node and is captured by L

(resp. R
).
If
is an substitution node, it is decorated by a single symbol S
, called its S -variable.
This RCG variable captures the terminal yield of the complete derived trees that can be
substituted at
If
is a terminal node, it has a single decoration which is either its terminal label or ".

Afterwards, during a top-down left to right traversal of , we collect into a decoration string
the previous annotations. For an adjunction node, its L-variable is collected during its top-
down traversal while its R-variable is collected during the bottom-up traversal. S -variables
and terminal decorations, associated with leaves, are gathered during the traversal of these leaf
nodes. If is an auxiliary tree, its left decoration string l and its right decoration string r
are the parts of  gathered during the previous traversal, respectively before and after the foot
node of (i.e. we have l = Lr : : : Lf and r = Rf : : : Rr if r and f are the root and foot
nodes of ).
Now, we are ready to describe the TAG to simple PRCG transformation algorithm.
We will generate a simple PRCG G =
N; T; V; P; S
which is equivalent to an initial TAG
T              IA
VN ; T; ; ; S
. We assume that the set N of its predicate names and the set V of its
variables are implicitly defined by the clauses in P .
In a first phase, for each initial S -tree , we initialize P with

S
X
X
On TAG Parsing
Let be an elementary tree and let be its decoration string. Of course, if is an auxiliary
tree,    is cut into its left and right part: = l r . To each such , we associate a simple
clause, constructed as follows:

its LHS is the predicate definition

, if    is the initial tree ;

its LHS is the predicate definition
l ; r
, if   is the auxiliary tree ;

its RHS is 1 : : : i : : : m , 1    i  m; m = jN j with
‚Äì    i = adj

i

L
i ; R
i
, if
i is an adjunction node in N ,
‚Äì    i = sbst

i

S
i
, if
i is a substitution node in N , and
‚Äì    i = ", if
i is a terminal node in N .

The denotations adj

i
and sbst

i
are predicate names which respectively symbolize
the adjunction or substitution operations that can be performed at node
i .
For each nonterminal node
2 NI       A , we define these predicates by the following clauses.

If
is an adjunction node, and if adj is the adjunction constraint function, whose value is
2
the set of auxiliary trees that can be adjoined at
(we write nil adj
, for an optional
adjunction), then, for every          2
adj
we produce the clause
adj
L; R
L; R

if       2 A or
adj
"; "
! "
if       = nil.
If
is a substitution node, and if sbst is the substitution constraint function, whose value
2
is the set of initial trees that can be substituted at
(we write nil sbst
, for an optional
substitution), then, for every         2
sbst
we produce the clause
sbst
S
S

if       2 I or
sbst
! "
if       = nil.

Since these clauses are all simple and positive, and since predicates are all at most binaries,
G is a simple 2-PRCG.5
Let us now examine the complexity of the parsing algorithm for G. Applying to our simple
2-PRCG the general result on parsing with simple k -RCG, we get an
nv+2
parse time. O
Expressed in terms of the original TAG, and since there are two LR-variables per adjunction
5
In this paper, we will not address the correctness of the previous algorithm and we assume that it generates a
PRCG which is equivalent to the original TAG.

Pierre Boullier
O
node, in the worst case, we have an
n2p+2
parse time for unrestricted TAGs, if                            p is the
maximum number of adjunction nodes in an elementary tree.
The idea is now to see whether G can be transformed into an equivalent RCG G0 with a
better parse time, and in particular whether we can reached the classical
n6
bound. The        O
purpose of what follows is to transform each previously generated clause into a sequence of
equivalent clauses in such a way that the number of their variables (and thus the number of their
free bounds) is as small as possible.
If we consider the decoration string associated with any elementary tree , it is not difficult
to figure out that    is a well parenthesized (Dyck) string where, on the one hand, the couples
of parentheses are the L and R-variables associated with its adjunction nodes, and, on the other
hand, the basic vocabulary is formed both by T , the set of terminal symbols, and by the set of
its S -variables.
Fundamentally, a Dyck language is recursively defined from initial strings in its basic vo-
cabulary either by concatenation of two Dyck languages or by wrapping a Dyck language into
a couple of parentheses. Conversely, each Dyck string can be recursively and unambiguously
decomposed (parsed) either into concatenation of two Dyck strings or into a wrapped Dyck
string. In our case, at each step of such decomposition of a Dyck (decoration) string , we can
associate an RCG clause which exhibits, either its cutting into a wrapped prefix part 1 and a
suffix part 2 , or its unwrapping. However, this process is slightly complicated by the fact that
, in the auxiliary tree case, is itself decomposed into two arguments, a left argument l and
a right argument r . In [Boullier, 1999a], we show that this decomposition produces, for each
original clause, a sequence of equivalent clauses6 which, in the worst case, define binary predi-
cates with four variables.7 Therefore, we have a method which parses the language defined by
an unrestricted TAG in worst case time
n6
.     O

4. Second Transformation from Unrestricted TAG to Simple PRCG
The idea of this second algorithm is to dissect the elementary trees of a TAG in such a way
O
that each excised subtree directly generates at worst an
n6
time parsable clause.
The same symbol or will be used to denote both any elementary tree and the root node
of that elementary tree. If
is not a leaf node in some elementary tree, its ith daughter, from left
to right, is denoted
:i. A node on a spine is termed as spinal node. If the root of a (sub)tree is a
spinal node, we have a spinal tree. Thus, a spinal tree is a subtree of an auxiliary tree rooted on
its spine. A tree rooted at node
is denoted either by
if it is a spinal tree or by
if it is a non
.                          M
spinal tree.8 The over hanging circle depicts its root node while the underlying triangles depict
its subtrees. For a given node
, we define a full open tree as the list of its daughter trees. This
full open tree is noted
or
according as
is a spinal or a non spinal node. An open tree is
. M
f                       g
a list of consecutive daughter trees
:i;
:i+1; : : : ;
:j . In the sequel we will handle two kinds
of open trees
and
where
denotes the left daughters whose rank is less or equal than i and
i     i.        i

denotes the right daughters whose rank is greater or equal than i. By contrast with the term
i.
open, a ‚Äúnormal‚Äù tree will be sometimes called a close tree.
6
Their number is linear in the number of adjunction nodes in the original elementary tree.
7
This most costly case corresponds to an adjunction at a spinal node.
8
Note that the   initial trees are also denoted by , and the   auxiliary trees by       .
M                                  .

On TAG Parsing
For a given TAG   T                  IA
VN ; T; ; ; S
, we will build an equivalent simple 2-PRCG G =

N; T; V; P; S
. Except for S , the predicates names of N are the previously defined tree denota-
tions. The spinal tree predicates are binary while the non spinal tree predicates are unary. The
set of clauses P is built, following the transformation rules listed below, each clause introduces
its own variables.
In a first phase, for each initial S -tree , we initialize P with
S
X
!       M

X
(1)

Afterwards, the elementary trees of        I A are processed in turn. Each elementary tree is
cut into smaller pieces, starting from the root. Intuitively, at each step, a (sub)tree is cut into
two parts, its root and its full open tree. The type of processing for the root node depends
whether adjunctions are allowed or not. While the processing of a full open tree consists of
a partitioning into its constituent parts which are either (smaller) open trees or close trees. Of
course, this processing differs whether spinal or non spinal open trees are considered. We iterate
until the leaves are reached. If we reach a substitution node, we apply the possible substitutions.
We first consider the transformation of non spinal close trees rooted at node

If
is a non trivial tree, we have
M

8

2 adj
M
L X R
! .
L; R
1
X

a

(2)
X           : nil 2 adj
M
X
! 1
X

b
If
is a leaf tree, depending of its label, we have
M
for an empty leaf (i.e.   " = lab
! "
M
(3)

for a terminal leaf a (i.e.   a = lab
; a 2 T )
a
! "
M
(4)

a
for a substitution node (i.e.   A = lab
; A 2 VN )
8
2 sbst
; M

X
! M
X

a

(5)

A               : nil 2 sbst
; M

! "
b
Pierre Boullier
Now, we consider the transformation of non spinal open trees rooted at
. The components
of such trees are processed from left to right in the case
or from right to left in the case
i.                                   i
For an open tree of the form
, we know that the left daughters of
whose rank is less than i
i.
must not be considered, thus such an open tree is processed by extracting its ith daughter close
tree and by iteratively processing
, until completion. Of course, this completion is reached
i+1.
when, after the extraction of the ith daughter, the resulting open tree is empty.
8
Y 6= ;; i.

X Y
:i
X
i+1
Y

a
:i     Y       =
M
(6)
: Y = ;;

X
:i
X

b

X                               i.                M
For a right to left processing, we have
8
i 1;
i
Y X
i-1
Y

:i
X

a

Y
:i            =
M
(7)
: i = 1;

X
:M1
X

b
Now, we consider the transformation of spinal trees rooted at

For each spinal close tree such as
, we must handle both a possible set of adjunctions at
and the processing of the full spinal open subtree
. Thus, we have the transformation rule

8

2 adj
LX; Y R
! .
L; R

X; Y

a

(8)
XY             : nil 2 adj
X; Y
X; Y

b
For each spinal open tree
, we have, if
:i is the spinal daughter node
L
:i       R     =

LX; Y R

L

:i
X; Y
R

i-1    .          i+1.
XY
In that case, the number of free bounds in the corresponding clause is six. We can remark
that, on the one hand, the left and right open trees
and
are independent and may thus
i-1     i+1.
be computed one after the other and, on the other hand, that any of them, or both, can be
empty. Thus, equivalently, if
r denotes an intermediate predicate name, we have the following
transformation rules

On TAG Parsing
8                     8
LX; Y
i-1
L

r
X; Y

a

L 6= ;; R 6= ;;
r
X; Y R
:i.
X; Y
i+1
R

b

L
:i R             =
L = ;; R 6= ;;
X; Y R
:i.
X; Y
i+1
R

c
(9)

XY                     L 6= ;; R = ;;
LX; Y

L

:i
X; Y

i-1       .

d

: L = ;; R = ;;
X; Y
:i.
X; Y

e
where the number of free bounds is now less or equal to five.
And last, for a foot node
, we have
8
2 adj
L; R
! .
L; R

a

(10)

: nil 2 adj
"; "
! "
b
By inspection of the generated clauses, we can verify that we have a simple 2-PRCG. The
degree of the polynomial time complexity of this grammar is the maximum number of free
bounds in each clause. We see that the maximum number of free bounds is six and is only
reached one time in the clause resulting of transformation (8a). Transformations (9a‚Äìd) cost
five (recall that they all arise as an optimization of a six free bound clause), while all the others
contribute to a number less or equal to four. This transformation explicitly ranks by cost the
operations used in TAG parsing. In particular, we confirm that the most costly operation is an
adjunction at a spinal node.9
We have shown that each TAG can be translated into an equivalent simple 2-PRCG which
O
can be parsed, at worst, in
n6
time.
To account for the dependency from the input grammar size, we define         =
2NI A
1 + jT j P
j      j j               j
adj
+ sbst
. We can easily see that the number of generated clauses is proportional to
jT j
. Since the parse time of an RCG is linear in the size of its input grammar, we finally get an
O jT j

n6
parse time for G.

5. Conclusion
In this paper, we proposed two methods to implement a TAG parser in
n6
time. These       O
algorithms both use RCGs, a powerful high level syntactic description formalism, as an interme-
diate object language. Since [Boullier, 1998b], we know that RCGs can be used to implement
O
parsers for TAGs. However, the
n6
bound was only reached with a restricted form of adjunc-
tion constraints and when the initial TAG was in some normal form. In particular, this normal
form assumes that elementary trees are in a binary branching form, form in which the original
structure has disappeared. At the contrary, the algorithms presented here, work for completely
O
unrestricted TAGs though their corresponding parsers still work in
n6
time at worst.
9
As for the first algorithm, we leave aside the proof of the correctness of the above algorithm.

Pierre Boullier
In [Satta and Schuler, 1998], the authors introduced a linguistically significant restricted form
O
of TAGs that can be parsed in
n5
, in [Boullier, 1999a], we have shown that their subclass
O
can be transformed into an equivalent RCG that can also be parsed in
n5
time, whether we
start from their inference rules, or directly from the elementary trees representation.
The usage of RCGs as an intermediate structure may result in several advantages. First, since
the RCG formalism is simple, the transformations proposed in this paper give another view of
the (rather complicated) adjunction mechanism and may help to understand when and why it
is costly to implement. Second, since RCGs can be efficiently implemented, we are convinced
that these methods are good candidates for practical TAG implementations.
R√©f√©rences
[Boullier, 1998a] Boullier P. (1998). Proposal for a Natural Language Processing Syntactic Back-
bone. In Research Report No 3342 at http://www.inria.fr/RRRT/RR-3342.html, INRIA-
Rocquencourt, France, Jan. 1998, 41 pages.
[Boullier, 1998b] Boullier P. (1998). A Generalization of Mildly Context-Sensitive Formalisms. In Pro-
ceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks
(TAG+4), University of Pennsylvania, Philadelphia, PA, 1‚Äì3 August, pages 17‚Äì20.
[Boullier, 1999a] Boullier P. (1999). On TAG and Multicomponent TAG parsing. In Research Report
No 3668 at http://www.inria.fr/RRRT/RR-3668.html, INRIA-Rocquencourt, France, Apr.
1999, 39 pages.
[Boullier, 1999b] Boullier P. (1999). Chinese Numbers, MIX, Scrambling, and Range Concatenation
Grammars In Proceedings of the 9th Conference of the Europwean Chapter of the Association for
Computational Linguistics (EACL‚Äô99), Bergen, Norway, June 8‚Äì12.
[Groenink, 1997] Groenink A. (1997). S URFACE WITHOUT S TRUCTURE Word order and tractability
issues in natural language analysis. PhD thesis, Utrecht University, The Netherlands, Nov. 1977, 250
pages.
[Joshi, 1985] Joshi A. (1985). How much context-sensitivity is necessary for characterizing structural
descriptions ‚Äî Tree Adjoining Grammars. In Natural Language Processing ‚Äî Theoritical, Compu-
tational and Psychological Perspective, D. Dowty, L. Karttunen, and A. Zwicky, editors, Cambridge
University Press, New-York, NY.
[Joshi, 1987] Joshi A. (1987). An Introduction to Tree Adjoining Grammars. In Mathematics of Lan-
guage, Manaster-Ramer, A., editors, John Benjamins, Amsterdam, pages 87‚Äì114.
[Rounds, 1988] Rounds W. (1988). LFP: A Logic for Linguistic Descriptions and an Analysis of its
Complexity. In ACL Computational Linguistics, Vol. 14, No. 4, pages 1‚Äì9.
[Satta, 1994] Satta G. (1994). Tree adjoining grammars parsing and boolean matrix multiplication. In
Computational Linguistics, 20(2), pages 173‚Äì192.
[Satta and Schuler, 1998] Satta G. and Schuler W. (1998). Restrictions on Tree Adjoining Languages. In
Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th In-
ternational Conference on Computational Linguistics (COLING-ACL‚Äô98), Universit√© de Montr√©al, Mon-
tr√©al, Qu√©bec, Canada, 10‚Äì14 August, vol. II, pages 1176‚Äì1182.
[Vijay-Shanker, Weir, and Joshi, 1987] Vijay-Shanker K., Weir D. and Joshi A. (1987). Characterizing
Structural Descriptions Produced by Various Grammatical Formalisms. In Proceedings of the 25th Meet-
ing of the Association for Computational Linguistics (ACL‚Äô87), Stanford University, CA, pages 104‚Äì111.
