Extraction automatique de correspondances lexicales :
Ã©valuation dâ€™indices et dâ€™algorithmes
Olivier Kraif
LILLA, UniversitÃ© de Nice Sophia Antipolis, 98 Bd. E. Herriot BP 369 06007 Nice Cedex
okraif@mageos.fr
http://lilla2.unice.fr
RÃ©sumÃ©
Les bi-textes sont des corpus bilingues parallÃ¨les, gÃ©nÃ©ralement segmentÃ©s et alignÃ©s au niveau des phrases.
Une des applications les plus directes de ces corpus consiste Ã  en extraire automatiquement des correspondances
lexicales, fournissant une information utile aux traducteurs, aux lexicographes comme aux terminologues.
Comme pour lâ€™alignement, des mÃ©thodes statistiques ont donnÃ© de bons rÃ©sultats dans ce domaine. Nous pensons
quâ€™une exploitation judicieuse dâ€™indices statistiques adaptÃ©s et dâ€™algorithmes de conception simple permet
dâ€™obtenir des correspondances fiables. AprÃ¨s avoir prÃ©sentÃ© les indices classiques, auxquels nous essayons
dâ€™apporter des amÃ©liorations, nous proposons dans cette article une Ã©tude empirique destinÃ©e Ã  en montrer les
potentialitÃ©s.
1. Introduction
Depuis le dÃ©but des annÃ©es 90, un nouveau champ dâ€™investigation est apparu dans le domaine du Traitement
Automatique des Langues : lâ€™exploitation des corpus bilingues parallÃ¨les, constituÃ©s dâ€™un ensemble de textes et
de leurs traductions respectives. Le problÃ¨me de lâ€™alignement de tels corpus, visant Ã  la segmentation des textes
en unitÃ©s plus petites (la phrase Ã©tant lâ€™Ã©talon le plus courant) et Ã  lâ€™appariement des unitÃ©s en relation de
traduction mutuelle, a trÃ¨s tÃ´t rencontrÃ© des solutions efficaces et opÃ©rationnelles, permettant dâ€™obtenir de
grandes quantitÃ©s de textes parallÃ¨les alignÃ©s, ou bi-textes, de faÃ§on totalement automatisÃ©e. Une campagne
dâ€™Ã©valuation sous lâ€™Ã©gide de lâ€™Aupelf-Uref, le projet Arcade (Langlais et al., 1998), a montrÃ© que les techniques
dâ€™appariement basÃ©es sur des indices superficiels comme la longueur des phrases ou la prÃ©sence de mots
apparentÃ©s (les cognats) aboutissait Ã  des rÃ©sultats satisfaisant sur des textes de nature variÃ©e, allant de la
traduction juridique Ã  celle, plus â€œ libre â€, de texte littÃ©raire.
Comme le note Isabelle (1992), les bi-textes ainsi obtenus constituent une mine dâ€™information pour le
traducteur, le linguiste ou le terminologue : de par leur taille importante, ils reprÃ©sentent un vÃ©ritable gisement de
solutions rÃ©utilisables Ã  chaque fois quâ€™un problÃ¨me de traduction dÃ©jÃ  rencontrÃ© surgit Ã  nouveau. Ainsi que le
souligne Macklovitch (1992), ce type de ressource a lâ€™avantage de mettre lâ€™accent sur la pratique rÃ©elle de la
traduction, Ã  la diffÃ©rence des dictionnaires bilingues qui ne retiennent le plus souvent que les usages les plus
standardisÃ©s.
Nous nous intÃ©ressons ici Ã  une des applications les plus prometteuses des bi-textes : lâ€™extraction automatique
de correspondances lexicales (certains auteurs utilisent le terme dâ€™â€œ alignement lexical â€1). Il sâ€™agit de donner,
pour des unitÃ©s lexicales identifiÃ©es dans le texte source, lâ€™Ã©quivalent traductionnel employÃ© dans la cible2. Ainsi
1
Nous prÃ©fÃ©rons le terme de correspondance dans la mesure oÃ¹ nous pensons quâ€™il y a une solution de continuitÃ©
entre lâ€™alignement au niveau des paragraphes ou des phrases, et lâ€™alignement au niveau des mots, qui prÃ©suppose
en quelque sorte le concept de traduction mot-Ã -mot. Pour une discussion de ce problÃ¨me, cf. Kraif (Ã  paraÃ®tre).
2
Pour la clartÃ© de lâ€™Ã©noncÃ©, nous utilisons les termes source et cible afin de diffÃ©rencier les deux parties dâ€™un bi-
texte, mais sans nous soucier du sens de la traduction effectuÃ©e initialement par lâ€™humain, puisquâ€™ici la relation
dâ€™Ã©quivalence traductionnelle est considÃ©rÃ©e comme Ã©tant symÃ©trique.

automatisÃ©e, ce type dâ€™extraction permet par exemple de constituer automatiquement des glossaires bilingues
utiles aux lexicographes.
TrÃ¨s tÃ´t, depuis la constitution des premiers bi-textes, des mÃ©thodes statistiques ont Ã©tÃ© dÃ©veloppÃ©es pour
obtenir automatiquement ce type de correspondance. DiffÃ©rents indices dâ€™association ont Ã©tÃ© proposÃ©s,
permettant de mesurer quantitativement lâ€™importance de la corrÃ©lation statistique entre les occurrences de deux
unitÃ©s de part et dâ€™autre dâ€™un bi-texte. A ce jour, ce sont des algorithmes sophistiquÃ©s, inspirÃ©s de lâ€™algorithme
EM (Dempster et al., 1977), qui ont obtenu les meilleurs rÃ©sultats. Nous proposons dans cette Ã©tude dâ€™Ã©valuer
quelques uns des indices statistiques les plus utilisÃ©s (Church et al, 1992, Dunning 1993, Fung et al, 1994,
Gaussier et al, 1995), sur la base dâ€™algorithmes simples. Nous dÃ©sirons ainsi montrer quâ€™une utilisation
judicieuse de ces indices peut donner de bons rÃ©sultats, et peut permettre, pour certaines applications, de faire
lâ€™Ã©conomie des mÃ©thodes itÃ©ratives3 coÃ»teuses en temps de calcul et en espace mÃ©moire.

2. Constitution du corpus et mise en Å“uvre de lâ€™Ã©valuation
La premiÃ¨re Ã©tape dâ€™une telle Ã©valuation consiste Ã  se doter dâ€™un corpus de rÃ©fÃ©rence contenant des
correspondances Ã©tablies manuellement, afin de disposer dâ€™un Ã©talon auquel on puisse comparer les rÃ©sultats.
Or, il existe plusieurs faÃ§ons de concevoir lâ€™extraction de correspondances lexicales : en particulier,
lâ€™appariement peut Ãªtre complet, si lâ€™on cherche Ã  apparier toutes les unitÃ©s du texte source avec les unitÃ©s
correspondantes dans le texte cible ; ou fragmentaire, si lâ€™on sâ€™intÃ©resse Ã  une liste dâ€™unitÃ©s sources
prÃ©alablement dÃ©terminÃ©es (cf. le â€œ lexical spotting â€ du Projet Arcade). Dans un cas comme dans lâ€™autre,
lâ€™appariement dÃ©pend bien sÃ»r de ce que lâ€™on entend par unitÃ© lexicale. En fait, quel que soit le type dâ€™extraction
considÃ©rÃ©, il est trÃ¨s difficile de donner une dÃ©finition rigoureuse des correspondances lexicales, qui soit
linguistiquement motivÃ©e et qui permette en mÃªme temps dâ€™Ã©noncer des critÃ¨res explicites pour la segmentation
et lâ€™appariement. Nous avons montrÃ© (Kraif, Ã  paraÃ®tre) que la notion dâ€™alignement lexical, basÃ© sur le concept de
compositionnalitÃ© traductionnelle (Isabelle, 1992), soulevait des problÃ¨mes dâ€™indÃ©termination : la traduction
Ã©tant dâ€™abord une opÃ©ration de transformation appliquÃ©e Ã  des messages, et non Ã  des unitÃ©s linguistiques, la
compositionnalitÃ© traductionnelle nâ€™a pas toujours de pertinence en deÃ§Ã  de la phrase. La distance sÃ©mantique
des unitÃ©s sources et cibles est variable, et dÃ©pend Ã©troitement du contexte. En outre cette distance est
indissociable du niveau de segmentation choisi (phrase, syntagme, mot). La dÃ©finition de lâ€™alignement conduit
donc Ã  une intrication profonde entre appariement et segmentation.
Afin de lever ces indÃ©terminations, nous prÃ©fÃ©rons abandonner le concept de compositionnalitÃ©. Nous
prÃ´nons une conception restreinte des correspondances lexicales, en distinguant, dâ€™une part, lâ€™identification des
unitÃ©s, et dâ€™autre part, leur appariement. Notre dÃ©finition des correspondances est donc basÃ©e sur deux conditions
indÃ©pendantes :
- la dÃ©termination des unitÃ©s doit Ãªtre effectuÃ©e prÃ©alablement, sur des critÃ¨res monolingues. Dans cette tÃ¢che,
nous avons retenu toutes les unitÃ©s lexicales au sens large (la lexie au sens de Melâ€™cuk et al., 1995), incluant des
formes simples, des mots composÃ©s, des unitÃ©s phrasÃ©ologiques et des termes polylexicaux (dont lâ€™unitÃ© est due
Ã  des critÃ¨res extra-linguistiques) :
(1)     mots composÃ©s : letter of formal notice <-> mise en demeure
(2)     unitÃ©s phrasÃ©ologiques : building a nuclear arsenal <-> se doter de l'arme nuclÃ©aire
(3)     termes polylexicaux : Board of Governors <-> Conseil des gouverneurs
Lâ€™identification de ces unitÃ©s pose parfois problÃ¨me : le plus simple est de caractÃ©riser les unitÃ©s figÃ©es
(exemple 1) qui satisfont aux critÃ¨res Ã©noncÃ©s par G. Gross (1996). Mais le figement est un phÃ©nomÃ¨ne scalaire
par nature, et certaines unitÃ©s se situent Ã  la limite, comme par exemple â€œ huile dâ€™olive â€. Sans compter que
certaines unitÃ©s Ã©chappent totalement au figement et prÃ©sentent toutefois un intÃ©rÃªt pour le traducteur : câ€™est le
cas des tournures idiomatiques (exemple 2), ou des termes (exemple 3). Nous avons adoptÃ© une acception large
de la polylexicalitÃ©, en reconnaissant les unitÃ©s dans les cas de figement, de tournure idiomatique ou dâ€™unitÃ©
terminologique dÃ©finie par un concept sous-jacent.
3
Il sâ€™agit des algorithmes inspirÃ©s de lâ€™algorithme EM, dont le but est dâ€™estimer lâ€™ensemble des paramÃ¨tres
maximisant la probabilitÃ© du corpus dâ€™apprentissage. Dans la version la plus simple, les paramÃ¨tres sont
constituÃ©s des probabilitÃ©s liÃ©es Ã  chaque correspondance lexicale. La convergence vers les paramÃ¨tres optimaux
est atteinte par la rÃ©pÃ©tition de deux Ã©tapes : 1. A partir des paramÃ¨tres, on compte le nombre de fois quâ€™une lexie
est susceptible dâ€™Ãªtre en correspondance avec une autre lexie, dans le corpus. 2. On rÃ©estime les paramÃ¨tres
(probabilitÃ©s des correspondances) en fonction de ces comptes.

- dans un second temps, lâ€™appariement doit Ãªtre basÃ© sur lâ€™Ã©quivalence traductionnelle. Ce type dâ€™Ã©quivalence
pouvant concerner diffÃ©rents niveaux (Ã©quivalence dynamique, sÃ©mantique, conceptuelle, rÃ©fÃ©rentielle,
stylistique, etc.), nous nâ€™avons retenu quâ€™un seul critÃ¨re : celui de gÃ©nÃ©ralitÃ©, lâ€™Ã©quivalence devant Ãªtre
envisageable dans dâ€™autres contextes.
Bien sÃ»r, chacune de ces deux conditions autorise une grande variÃ©tÃ© dâ€™interprÃ©tations. Afin de donner un
maximum de cohÃ©rence Ã  lâ€™extraction manuelle, nous avons cherchÃ© Ã  expliciter des critÃ¨res prÃ©cis permettant de
trancher dans les cas litigieux. Il aurait Ã©tÃ© souhaitable, Ã  lâ€™instar des prÃ©cÃ©dentes Ã©valuations (Melamed, 1998,
Langlais, 1998), dâ€™assurer un consensus intersubjectif en faisant appel Ã  plusieurs annotateurs.
Malheureusement, cette tÃ¢che nâ€™a pu Ãªtre confiÃ©e quâ€™Ã  une seule personne. Les critÃ¨res choisis, ainsi que les
correspondances manuelles sont disponibles pour consultation Ã  lâ€™adresse : http:\\lilla2.unice.fr.
Pour cette Ã©valuation, nous avons rÃ©utilisÃ© le corpus JOC fourni pour la deuxiÃ¨me campagne du projet
Arcade. Nous avons alignÃ© automatiquement ce corpus au niveau des phrases4, en utilisant les techniques
dâ€™alignement dÃ©crites dans (Kraif, 1999). Nous sommes parti dâ€™un bi-texte alignÃ© automatiquement afin de
montrer que les quelques erreurs qui subsistent (Ã©valuÃ©es comme Ã©tant infÃ©rieures Ã  3%) ne compromettent pas
lâ€™utilisation des techniques ici prÃ©sentÃ©es. Cet alignement nous a fourni environ 69 000 couples de phrases.
La totalitÃ© de ce corpus a Ã©tÃ© utilisÃ©e comme corpus dâ€™apprentissage (dans le compte des cooccurrences),
mais une partie seulement a Ã©tÃ© appariÃ©e manuellement, pour lâ€™Ã©valuation. Pour constituer cet Ã©chantillon, nous
avons effectuÃ© un tirage alÃ©atoire de 1 000 couples de phrases, parmi lesquels nous avons supprimÃ© les phrases
ne contenant quâ€™une seule forme, pour aboutir finalement Ã  767 couples de phrases. Au final, lâ€™extraction
manuelle a donnÃ© un peu plus 9 000 couples de lexies correspondantes. Notons quâ€™au cours de lâ€™appariement
environ 30% des mots nâ€™ont pas trouvÃ© de correspondant lexical satisfaisant : nous nommerons â€œ rÃ©sidu â€ ces
unitÃ©s.

Corpus dâ€™apprentissage              Echantillon
Anglais       FranÃ§ais         Anglais     FranÃ§ais
Nombre de mots                               1 060 174     1 168 555         16 216       20 002
Nombre de couples de phrases                         69 160                          767
Nombre de mots retenus dans les couples                                      11 736       13 041
RÃ©partitions des 9079 couples appariÃ©s manuellement
Nombre de lexies simples                                                       7 383         6 983
Nombre de lexies polylexicales                                                 1 996         2096
tableau 1 : constitution du corpus dâ€™apprentissage et de lâ€™Ã©chantillon de rÃ©fÃ©rence
Sur la base des couples de rÃ©fÃ©rence, nous nous proposons dâ€™Ã©valuer trois tÃ¢ches diffÃ©rentes (un exemple de
ces trois tÃ¢ches est fourni Ã  lâ€™annexe 1) :
- lâ€™extraction des correspondances entre toutes les lexies : il sâ€™agit, Ã©tant donnÃ©es les lexies identifiÃ©es dans le
texte source et le texte cible, dâ€™Ã©tablir automatiquement les appariements entre unitÃ©s Ã©quivalentes. Ces lexies
incluent mots simples et unitÃ©s polylexicales, quâ€™il sâ€™agisse de mots pleins ou de mots fonctionnels.
Les couples ainsi extraits sont comparÃ©s aux couples de rÃ©fÃ©rence par le biais des mesures classiques de
prÃ©cision, de rappel et de F-mesure. Si lâ€™on note C lâ€™ensemble des couples Ã  Ã©valuer, Cref lâ€™ensemble des couples
de rÃ©fÃ©rence, on a donc :
C  C ref          C  C ref              2 Ã— ( P Ã— R)
P=                 R=                 et   F=                                                1(1)
C                 C ref                 ( P + R)
- lâ€™extraction des correspondances entre lemmes : en supprimant les variations morphologiques superficielles
des lexies (nombre pour les substantifs, genre et nombre pour les adjectifs, temps, mode et personne pour les
verbes, etc.) on recalcule les cooccurrences et lâ€™on effectue une extraction similaire Ã  la prÃ©cÃ©dente.
- lâ€™extraction des correspondances entre formes simples : les unitÃ©s considÃ©rÃ©es sont des mots simples
(groupes de lettres sÃ©parÃ©s par des espaces) nâ€™ayant subi aucun prÃ©-traitement. Dans ce cas de figure, on obtient
parfois des correspondances fragmentaires, lorsque des parties de lexies complÃ¨tes sont appariÃ©s : dans le calcul
4
Par soucis de simplicitÃ©, nous nous placerons toujours dans le cas dâ€™alignement mettant en jeu des couples de
phrases : en fait, il peut sâ€™agir de couples rÃ©sultant de lâ€™appariement dâ€™agrÃ©gats de 0, 1, 2 ou 3 phrases. Par abus
de langage, nous dÃ©nommerons phrase ce type de dâ€™agrÃ©gat.

de la prÃ©cision, on considÃ©rera comme Ã©tant valide tout couple de formes inclus dans un couple de lexies
appariÃ©es manuellement. Pour le calcul du rappel, le dÃ©nominateur correspond au nombre de formes simples
engagÃ©es du cÃ´tÃ© source dans les couples de rÃ©fÃ©rence.
A la diffÃ©rence de lâ€™Ã©valuation menÃ©e au sein du Projet Arcade, nous ne nous concentrons pas sur un
ensemble rÃ©duit de mots-test, choisis en fonction dâ€™aspects sÃ©mantiques (polysÃ©mie), morphologiques
(substantifs, verbes et adjectifs) et de leurs frÃ©quences. Dans la mesure oÃ¹ les mÃ©thodes les plus efficaces
sâ€™appuient sur des appariements exhaustifs, il nâ€™est pas prÃ©maturÃ© de sâ€™intÃ©resser aux extractions globales qui
engagent toutes les unitÃ©s.

3. Indices
La mise en Å“uvre de la plupart des indices dâ€™association se base sur le raisonnement suivant : si deux unitÃ©s
ont des distributions similaires, respectivement dans le texte source et le texte cible, i.e. si elles apparaissent
frÃ©quemment dans des zones en relation de traduction, il est probable quâ€™elles soient elles-mÃªmes en relation de
traduction. Le fait dâ€™apparaÃ®tre ensemble dans des zones alignÃ©es est gÃ©nÃ©ralement dÃ©signÃ© par le terme de
cooccurrence. On devrait prÃ©ciser â€œ cooccurrence parallÃ¨le â€, afin dâ€™Ã©viter toute ambiguÃ¯tÃ© avec la cooccurrence
dans le cas monolingue. Nous prÃ©ciserons Ã  chaque fois quâ€™il pourrait y avoir confusion. Comme lâ€™a montrÃ©
Melamed, le dÃ©nombrement des cooccurrences dans un bi-texte peut Ãªtre effectuÃ© suivant diffÃ©rents modÃ¨les.
Dans la suite de cet exposÃ©, nous nous limiterons au plus simple et au plus courant de ces modÃ¨les : deux unitÃ©s
sont cooccurrentes Ã  chaque fois quâ€™elles apparaissent de part et dâ€™autre dâ€™un couple de phrases alignÃ©es5.
âˆ’   Lâ€™indice le plus classique est lâ€™information mutuelle (Church et Hovy, 1992) : câ€™est le rapport entre le
nombre de cooccurrences observÃ©es, et le nombre thÃ©orique basÃ© sur lâ€™hypothÃ¨se de lâ€™indÃ©pendance des
unitÃ©s u1 et u2. Si n reprÃ©sente le nombre de couples de phrases alignÃ©es, n1 et n2 reprÃ©sentent le nombre des
occurrences respectives de u1 et u2, et n12 le nombre total de cooccurrences de u1 et u2, alors lâ€™information
mutuelle se calcule de la maniÃ¨re suivante :
ï£« p ï£¶
IM = logï£¬ï£¬ 12 ï£·ï£·                                                     2(2)
ï£­ p1 p 2 ï£¸
n1          n2           n
avec   p1 =        p2 =           p12 = 12
n           n             n
Un dÃ©faut majeur de lâ€™information mutuelle est sa tendance Ã  surÃ©valuer lâ€™association entre les unitÃ©s peu
frÃ©quentes. GÃ©nÃ©ralement, on estime quâ€™une IM Ã©levÃ©e nâ€™a pas de signification pour des unitÃ©s cooccurrant
moins de 3 fois.
âˆ’   Afin de pallier ce dÃ©faut, Fung (1994), dans un article oÃ¹ elle dÃ©veloppe une mÃ©thode dâ€™alignement basÃ©e
sur lâ€™extraction prÃ©alable de correspondances lexicales, propose dâ€™employer le t-score. Son calcul est voisin
de celui de lâ€™IM :
p 12 âˆ’ p 1 p 2
t â‰ˆ                                                                  3(3)
p 12
n
âˆ’   Par ailleurs, Dunning (1993) note avec justesse que les unitÃ©s peu frÃ©quentes nâ€™ont rien de â€œ rare â€. Ainsi les
mÃ©thodes basÃ©es sur le test du Qi2 ou du z-score (supposant la normalitÃ© des distributions) seraient invalides
pour la plupart des unitÃ©s lexicales. En modÃ©lisant lâ€™occurrence dâ€™une unitÃ© par une distribution binomiale,
Dunning dÃ©duit un indice Ã©valuant la plausibilitÃ© de lâ€™hypothÃ¨se dâ€™indÃ©pendance des occurrences de deux
unitÃ©s quelconques. Lâ€™opposÃ© du logarithme permet alors dâ€™exprimer le degrÃ© dâ€™association entre deux ces
unitÃ©s. Pour deux unitÃ©s u1 et u2, on donne la table de contingence suivante :
occurrence de u2        non occurrence de u2
occurrence de u1                      a                        b
non occurrence de u1                  c                        d
tableau 2 : occurrences et cooccurrences de u1 et u2
5
En fait, le calcul est un peu plus compliquÃ© : lorsque dans un mÃªme couple de phrases, lâ€™unitÃ© lexicale f
apparaÃ®t p fois, et lâ€™unitÃ© fâ€™ apparaÃ®t q fois, le nombre de cooccurrences engendrÃ©es par ce couple est donnÃ© par :
cooc=min(p,q).

On a alors, en notant RV lâ€™indice issu du rapport de vraisemblance :

RV = âˆ’ 2 log Î» = 2 ( S + âˆ’ S âˆ’ )
S + = a log a + b log b + c log c + d log d + n log n                                                                    4(4)
S       = ( a + c ) log( a + c ) + ( b + d ) log( b + d ) + ( a + b ) log( a + b ) + ( c + d ) log( c + d )
Dans lâ€™observation des cooccurrences, cet indice sâ€™est rÃ©vÃ©lÃ© Ãªtre un des plus simples et des plus fiables
(Gaussier et LangÃ©, 1995).
âˆ’   Nous avons dÃ©veloppÃ© un autre indice basÃ© sur le modÃ¨le binomial : nous avons tout simplement cherchÃ© Ã 
Ã©valuer la probabilitÃ© de lâ€™hypothÃ¨se nulle, supposant lâ€™indÃ©pendance des occurrences de u1 et u2. En
reprenant les notations prÃ©cÃ©dentes, on a :
Cnn Cnn Cnn âˆ’âˆ’n n
1     12      2       12
n2 âˆ’ n12
(n âˆ’ n1 âˆ’ n2 + n12 + k ) n12 (n1 âˆ’ n12 + k )(n2 âˆ’ n12 + k ) 5(5)
P0 (n12 / n, n1 , n2 ) =            1           1
=    âˆ                                 âˆ
(n âˆ’ n2 + n12 + k ) k =1          k (n âˆ’ n 2 + k )
Cnn Cnn
1   2                  k =1
En prenant lâ€™opposÃ© du logarithme , on obtient Ã  nouveau un indice permettant dâ€™Ã©valuer le degrÃ©
dâ€™association de u1 et u2. On note P0 lâ€™indice rÃ©sultant.
Enfin, nous avons mis au point un dernier type dâ€™indice, basÃ© non plus sur lâ€™observation des distributions, mais
sur les similitudes formelles entre les unitÃ©s lexicales : il sâ€™agit cette fois dâ€™identifier les transfuges (lexies
invariantes) et les cognats (lexies apparentÃ©es), dont la ressemblance superficielle peut Ãªtre une source
dâ€™information prÃ©cieuse. Lâ€™Ã©laboration de cet indice repose sur lâ€™identification des sous-chaÃ®nes maximales,
telles que nous les avons utilisÃ©es dans les mÃ©thodes dâ€™alignement (cf. Kraif, 1999). Pour chaque couple
candidat, nous distinguons onze cas, en fonction desquels nous avons calculÃ© empiriquement la probabilitÃ© de
non-correspondance (cf. annexe).
Lâ€™opposÃ© du logarithme de cette probabilitÃ© aboutit Ã  lâ€™indice notÃ© CO. Lâ€™addition de cet indice avec lâ€™indice P0
nous donne un dernier indice combinÃ©, PC, mÃªlant information distributionnelle et ressemblances superficielles.
En rÃ©sumÃ© nous Ã©tudierons 6 indices : lâ€™information mutuelle IM, le t-score TS, le rapport de vraisemblance RV,
lâ€™invraisemblance de lâ€™hypothÃ¨se nulle P0, lâ€™indice basÃ© sur les ressemblances de surface CO, et lâ€™indice
combinÃ© PC.

4. Algorithmes
Pour les lexies comme pour les formes simples, nous avons intÃ©grÃ© ces indices dans deux cadres
algorithmiques trÃ¨s simples :
- recherche de lâ€™indice maximum : pour chaque unitÃ© de la phrase source, on retient une correspondance
obtenant la meilleure valeur de lâ€™indice.
- recherche de la meilleur affectation biunivoque : on suppose que les correspondances se rÃ©alisent sous la
forme dâ€™une relation biunivoque entre les unitÃ©s cibles et les unitÃ©s sources. Dans ce cadre, une mÃªme unitÃ© ne
peut entrer dans plusieurs correspondances Ã  lâ€™intÃ©rieur dâ€™un mÃªme couple de phrases. Cet algorithme est itÃ©ratif
Ã  partir de lâ€™Ã©tape 2 :

1. Constitution de lâ€™ensemble des candidats Cand : on calcule des indices pour toutes les unitÃ©s (u1,u2) du
couple de phrases (P1,P2). Tous ces couples sont placÃ©s dans Cand.
2. SÃ©lection : on sÃ©lectionne un couple (U1,U2) de Cand obtenant la meilleure valeur de lâ€™indice. On retient
ce couple dans lâ€™ensemble Corresp contenant le rÃ©sultats des correspondances, et on Ã©limine de Cand tous
les couples qui mettent en jeu (U1) ou (U2).
3. Retour en 2 tant que lâ€™ensemble Cand nâ€™est pas vide.
4. Terminaison. Corresp contient le rÃ©sultat.
Dans la mise en Å“uvre de ce dernier algorithme, nous avons procÃ©dÃ© Ã  quelques simplification, pour des
raisons dâ€™efficacitÃ© des calculs. Dâ€™une part, au sein de chaque phrase, une mÃªme unitÃ© ne peut rentrer que dans
un seul couple, mÃªme si elle y compte plusieurs occurrences. Cette approximation affecte lÃ©gÃ¨rement le rappel,
puisque 9 % des couples de rÃ©fÃ©rences concernent des unitÃ©s rÃ©pÃ©tÃ©es dans un mÃªme couple de phrases. Dâ€™autre
part, les unitÃ©s dÃ©passant 5 000 occurrences dans la totalitÃ© du corpus dâ€™apprentissage ne sont pas prises en

compte. Cela concerne 29 unitÃ©s en anglais et 38 en franÃ§ais, essentiellement des mots outils et des signes de
ponctuation. De par ces simplifications, 31 % des couples corrects ne pouvant Ãªtre considÃ©rÃ©s, le rappel ne
pourra dÃ©passer la limite de 69 %.

5. Evaluation
Lâ€™application de ces deux algorithmes sur les 6 indices donne les valeurs de prÃ©cision et de rappel
reprÃ©sentÃ©es sur les figures 1-4. Les indices sont symbolisÃ©s de bas en haut : CO losange vide, IM carrÃ© plein, TS
triangle plein, RV carrÃ© vide, P0 barre horizontale, PC astÃ©risque. Par FS, Lex et Lem on dÃ©signe les trois tÃ¢ches
prÃ©cÃ©demment Ã©numÃ©rÃ©es. Les rÃ©sultats permettent dâ€™Ã©tablir des comparaisons selon les 3 axes suivants :
-    Comparaison des algorithmes :
On constate une amÃ©lioration globale des rÃ©sultats entre 1 et 2. Câ€™est lâ€™information mutuelle qui en bÃ©nÃ©ficie
le plus, car dans lâ€™algorithme 1, cet indice concentre toutes les correspondances sur les mÃªmes unitÃ©s ; ce dÃ©faut
est compensÃ© par lâ€™affectation biunivoque. Il est notable que CO se maintient au niveau plancher : lâ€™information
apportÃ©e par les cognats Ã©tant plutÃ´t rare Ã  lâ€™intÃ©rieur dâ€™un mÃªme couple de phrases, il est peu frÃ©quent que deux
unitÃ©s cibles soient en concurrence pour Ãªtre appariÃ©es avec une mÃªme unitÃ© source.
-    Comparaison des tÃ¢ches :
De maniÃ¨re Ã©tonnante, lâ€™extraction des formes simples paraÃ®t obtenir une meilleure prÃ©cision : cela peut Ãªtre
dÃ» Ã  la tolÃ©rance du mode dâ€™Ã©valuation choisi, dans la mesure oÃ¹ il suffit quâ€™un appariement soit inclus dans un
couple de rÃ©fÃ©rence pour quâ€™il soit comptÃ© comme correct. Dâ€™ailleurs, malgrÃ© ce biais, cette extraction demeure
infÃ©rieure au deux autres vis-Ã -vis de la F-mesure. Les meilleurs rÃ©sultats globaux sont obtenus avec lâ€™extraction
Lem, mÃªme si celle-ci connaÃ®t un rappel infÃ©rieur Ã  Lex. Cette dÃ©gradation est due Ã  un autre artefact :
lâ€™algorithme nÃ©gligeant les occurrences des unitÃ©s rÃ©pÃ©tÃ©es dans un mÃªme couple de phrases, la rÃ©duction
morphologique amplifie lâ€™effet de cette simplification.
-    Comparaison des indices :
Enfin, quel que soit lâ€™algorithme ou la tÃ¢che, une hiÃ©rarchie se dessine au niveau des indices : les meilleurs
rÃ©sultats sont toujours produits par la mesure combinÃ©e PC, et les moins bons par CO. Les informations

                                                                              

                                                                              

                                                                              

                                                                              

                                                                              

                                                                              
)6 /H[ /HP                  )6 /H[ /HP                     )6 /H[ /HP                  )6 /H[ /HP
apportÃ©es par les cognats sont donc complÃ©mentaires des cooccurrences, puisquâ€™elles se cumulent
harmonieusement dans PC. En outre P0 semble se comporter de maniÃ¨re identique Ã  RV, puisque leur deux
courbes se chevauchent.
figure 1 : P algo. 1    figure 2 : R algo. 1       figure 3 : P algo. 2      figure 4 : R algo. 2
Afin de vÃ©rifier certaines des analyses prÃ©cÃ©dentes, nous avons effectuÃ© une autre extraction en supprimant
tous les mots outils du corpus (comme des correspondances de rÃ©fÃ©rence). En prenant la moyenne des six
indices, avec lâ€™algorithme 2, on constate une amÃ©lioration globale des rÃ©sultats, notamment du rappel. Ceci pour
deux raisons : dâ€™une part les mots outils sont plus frÃ©quents dans le rÃ©sidu de traduction que dans les couples

appariÃ©s ; dâ€™autre part lâ€™effet des simplifications de lâ€™algorithme (absence des unitÃ©s rÃ©pÃ©tÃ©es et/ou de frÃ©quence
supÃ©rieure Ã  5000) est estompÃ© du fait de la suppression des mots outils. Ainsi, lâ€™extraction Lem nâ€™obtient plus
un rappel infÃ©rieur Ã  celui de Lex.

P%                            R%                           F%
Algorithme 2
FS     Lex      Lem          FS      Lex     Lem           FS     Lex      Lem
avec toutes les unitÃ©s       65,6    64,3     67,4        50,1     56,1    55,6         56,8    59,9     60,9
sans mots fonctionnels        69,8    68,5     71,1        63,9     76,9    78,1         66,7    72,4     74,5
tableau 3 : comparaison des extractions avec et sans mots fonctionnels
Ainsi les Ã©carts entre les trois tÃ¢ches apparaissent plus nettement, ce qui confirme nos hypothÃ¨ses. Les
meilleurs rÃ©sultats sont atteints avec lâ€™indice PC : on obtient P = 78,8 %, R = 86,5 % et F = 82,5 %.

6. Filtrage des rÃ©sultats
Les correspondances ainsi extraites peuvent donner lieu Ã  diffÃ©rents filtrages permettant dâ€™Ã©liminer les
appariements les plus improbables. Nous distinguons trois types de filtrage :
- filtrage par valeur seuil : on ne retient que les couples obtenant une valeur de lâ€™indice supÃ©rieure Ã  un
certain seuil. Pour chaque indice, 7 seuils ont Ã©tÃ© testÃ©s : la moyenne de lâ€™indice multipliÃ©e par 7 facteurs allant
de 0,25 Ã  10.
- filtrage relatif : pour chaque phrase, on classe les couples par valeur dÃ©croissante de lâ€™indice, et lâ€™on ne
retient que les meilleurs premiers couples dans les proportions suivantes : 80%, 60%, 40%, 20%.
- filtrage diffÃ©rentiel : pour chaque unitÃ© source, on ne retient son appariement avec une unitÃ© cible que si la
valeur de lâ€™indice obtenue avec cette unitÃ© est supÃ©rieure Ã  toutes les valeurs obtenues avec les unitÃ©s
concurrentes, dans des proportions supÃ©rieures Ã  diffÃ©rentes valeurs, allant de 1,05 Ã  4.
On trouvera en annexe les figures reprÃ©sentant les rÃ©sultats pour lâ€™appariement des lexies avec lâ€™algorithme 2
(les filtrages prÃ©sentent, mutatis mutandis, les mÃªmes caractÃ©ristiques pour les lemmes et les formes simples, et
avec les deux algorithmes).
On constate que :
- les filtrages sont opÃ©rants puisquâ€™ils permettent une augmentation de la prÃ©cision.
- les valeurs optimales de F sont atteintes avec le filtrage Ã  valeur seuil, de paramÃ¨tre 0,5 (PC atteint
F=69 %). Pour les zones de rappel important (>50%), cette mÃ©thode obtient une meilleure prÃ©cision Ã  rappel Ã©gal
que les autres filtrages (pour les trois meilleurs indices).
- pour les zones de faible rappel (<50%), le filtrage diffÃ©rentiel apporte une prÃ©cision plus grande Ã  rappel
Ã©gal.
Ces filtrages prÃ©sentent donc des profils lÃ©gÃ¨rement diffÃ©rents : si lâ€™on privilÃ©gie le rappel, le filtrage avec
seuil convient mieux. Si lâ€™on recherche des prÃ©cisions trÃ¨s Ã©levÃ©es, avec un rappel mÃ©diocre, le filtrage
diffÃ©rentiel paraÃ®t plus adaptÃ©. Le filtrage relatif nâ€™a dâ€™intÃ©rÃªt que dans la mesure oÃ¹ il autorise une Ã©volution
continue et contrÃ´lÃ©e de lâ€™Ã©quilibre entre P et R.

8. Conclusion et Perspectives
Pour pouvoir vÃ©rifier la validitÃ© et la gÃ©nÃ©ralitÃ© des remarques prÃ©cÃ©dentes, il faudrait certes pousser ces
Ã©tudes empiriques vers des investigations plus approfondies, en variant le type de corpus. Dâ€™un point de vue
global, elles tendent Ã  confirmer la possibilitÃ©, moyennant des algorithmes trÃ¨s simples et des mesures
statistiques adÃ©quates, dâ€™extraire Ã  partir des bi-textes des informations de premier choix pour les traducteurs
comme pour les lexicographes.
Plus spÃ©cifiquement, deux indices statistiques semblent plus adaptÃ©s Ã  cette tÃ¢che : le rapport de
vraisemblance et lâ€™inverse de la probabilitÃ© de lâ€™hypothÃ¨se nulle. La premiÃ¨re est plus simple de calcul, mais la
seconde prÃ©sente lâ€™avantage dâ€™Ãªtre facilement combinable avec dâ€™autres informations sous une forme
probabiliste.
En outre, nous avons montrÃ© que des sources dâ€™information complÃ©mentaires, comme les ressemblances de
surface, pouvait se rÃ©vÃ©ler utiles. Dans des recherches ultÃ©rieures, il serait intÃ©ressant dâ€™Ã©tudier ces techniques en

les combinant Ã  des informations linguistiques, issues notamment de dictionnaires bilingues sous format
Ã©lectronique.
RÃ©fÃ©rences
Church, K., Hovy, E. (1992). Good Application for Crummy Machine Translation, Machine Translation, 8.
Debili F, Sammouda E. (1992). Appariements de Phrases de Textes bilingues FranÃ§ais-Anglais et FranÃ§ais-
Arabes. In Actes de COLING-92, Nantes, pp. 528-524
Dempster, A., Laird, N., Rubin, D. (1977) Maximum likelihood from incomplete data via the EM algorithm.
Journal of the Royal Statistical Society 34 (B).
Dunning, T. (1993). Accurate Methods for the Statistics of surprise and Coincidence. Computational Linguistics.
Vol 19, 1, pp. 61-74
Fung P., Church K.W. (1994). K-vec : A New Approach for Aligning Parallel Texts. In Proceedings of the 15th
International Conference on Computational Linguistics, Kyoto
Gale W., Church K. W. (1991). A program for aligning sentences in bilingual corpora. In Proceedings of the 29th
Annual Meeting of the ACL, Berkeley, CA, pp. 177-184
Gaussier, E., LangÃ© J.-M. (1995). ModÃ¨les statistitiques pour lâ€™extraction de lexiques bilingues, T.A.L., Vol. 36,
NÂ° 1-2, pp. 133-155
Gross G. (1996). Les expressions figÃ©es en franÃ§ais, Ophrys, Paris
Isabelle P. (1992), La bi-textualitÃ© : vers une nouvelle gÃ©nÃ©ration dâ€™aides Ã  la traduction et la terminologie, Meta,
XXXVII, 4, pp.721-731
Kraif O. (1999). Identification des cognats et alignement bi-textuel :une Ã©tude empirique, Actes de TALNâ€™99,
CargÃ¨se, France, pp. 205-214
Kraif O. (Ã  paraÃ®tre). Translation alignment and lexical correspondences : a methodological reflection. In B.
Altenberg & S. Granger, Ed., Lexis in contrast. Studies in Corpus Linguistics. John Benjamins
Langlais P., Simard M., Veronis J. et al, (1998), ARCADE : A cooperative Research Project on Parallel Text
Alignment Evaluation, disponible sur le WEB Ã  http://www.lpl.univ-aix.fr/projects/arcade
Macklovitch, E. (1992). Corpus-Based Tools for Translators, Proceedings of the 33rd Annual Conference of the
American Translators Association, San Diego California.
Melâ€™cuk, I., Clas, A., Polguere, A. (1995). Introduction Ã  la lexicologie explicative et combinatoire, Duculot,
Louvain-la-neuve.
Melamed, D. (1998). Manual Annotation of Translational Equivalence : The Blinker Project. Institute for
Research in Cognitive Science. Technical Report#98-06, University of Pennsylvania
Annexe
1. Exemple dâ€™extraction :
fr. : Pour la bonne tenue de ces registres, l'Ã©valuation des cas de mortalitÃ© constatÃ©s par les autoritÃ©s
apporte des informations importantes.
ang. : The assessment of the official cause of death is a piece of information vital to these registers.

Lexies : (Pour ;to) (ces ; these) (registres ; registers) (lâ€™ ; the) (Ã©valuation ; assessment) (des ; of the)
(cas de mortalitÃ© ; cause of death) (des ; a piece of) (informations ; information) (importantes ; vital)
Lemmes : (Pour ;to) (ce ; this) (registre ; register) (le ;the) (Ã©valuation ;assessment) (de le ; of the) (cas
de mortalitÃ© ;cause of death) (de le ; a piece of) (information ; information) (importante ;vital)

Formes simples : (Pour ;to) (ces ; these) (registres ;register) (l ; the) (Ã©valuation ;assessment) (des ; of)
(cas ;cause) (de ; of) (mortalitÃ© ; death) (des ; piece) (informations ;information) (importante ;vital)

2. ParamÃ¨tres pour lâ€™indice CO :
Cas 1 = transfuge numÃ©rique, cas 2 = transfuge de long. sup. Ã  3, cas 3 : 4-gram de long. inf. Ã  7,
cas 4-10 : SCM comportant 4-10 caractÃ¨res, cas 0 : tout le reste.
Cas        0       1      2       3        4        5         6     7       8      9        10
p(cas) 0,979 0,001 0,028 0,280 0,497 0,290 0,217 0,125 0,149 0,101 0,058
Ces probabilitÃ©s ont Ã©tÃ© calculÃ©es sur lâ€™Ã©chantillon. Nous pensons quâ€™elles sont rÃ©utilisables pour
dâ€™autres corpus et quâ€™elles dÃ©pendent surtout du couple de langues.
3. RÃ©sultats pour les diffÃ©rents types de filtrage :
100%                                                              70%
60%
80%
50%
60%                                                              40%

40%                                                              30%
20%
20%
10%
0%                                                               0%
100%    80%        60%         40%          20%                 100%      80%          60%            40%       20%
PC                 P0                      RV                     PC                   P0                      RV
Figure 5   :TS
Ã©volution   de   PIM
avec      le            relatif
filtrageCOb        Figure 6   :TS
Ã©volution     de   RIMavec        le filtrageCOb
relatif

100%                                                               70%
60%
80%
50%
60%                                                               40%

40%                                                               30%
20%
20%
10%
0%                                                                0%
0   0,25 0,5      1     2,5    4       6    10                   0    0,25 0,5        1        2,5    4    6    10
PC                  P0                      RV                    PC                       P0                   RV
TS                  IM                      COb                   TS                       IM                   COb
100%                                                               70%

7 : Ã©volution de P avec le filtrage avec seuil Figure60%
Figure80%                                                      8 : Ã©volution de R avec le filtrage avec seuil
50%
60%                                                               40%

40%                                                               30%
20%
20%
10%
0%                                                                0%
1   1,05 1,2 1,5        2      2,5     3     4                   1    1,05 1,2    1,5          2     2,5   3     4
PC                  P0                      RV                    PC                       P0                   RV
TS                  IM                      COb                   TS                       IM                   COb
Figure 9 : Ã©volution de P avec le filtrage diff.                 Figure 10 : Ã©volution de R avec le filtrage diff.
