TALN 2001, Tours, 2-5 juillet 2001

Modéle d’exploration contextuelle
pour l’analyse sémantique de textes

Slim Ben Hazez, Jean—Pierre Descles, Jean—Luc Minel

CAMS—LaLIC, UMR 8557 du CNRS, EHESS, Universite de Paris—Sorbonne
96 boulevard Raspail
75 006 Paris — France
{Slim.Ben—Hazez}@paris4.sorbonne.fr

Résumé — Abstract

Nous presentons dans cet article un modele d’exploration contextuelle et une plate—forrne
logicielle qui perrnet d’acceder au contenu semantique des textes et d’en extraire des
sequences particulierement pertinentes. L'objectif est de developper et d’exploiter des
ressources linguistiques pour identifier dans les textes, independamment des domaines traites,
certaines des relations organisatrices des connaissances ainsi que les organisations discursives
mises en places par l'auteur. L'analyse semantique du texte est guidee par le reperage d'indices
linguistiques declencheurs dont l'emploi est representatif des notions etudiees.

In this paper, we present a model of contextual exploration and a workstation dedicated to
semantic filtering and relevant sentence extracting. The purpose is to develop and to exploit
linguistics resources in order to identify in texts, independently of processed domains, some
specific relations which organize knowledge and author discourse. Semantic analysis is driven
by the identification of linguistic indicators which are relevant clues for the studied notions.

1 Introduction

Les techniques actuelles d’analyse semantique de textes tendent de plus en plus a mettre en
oeuvre une analyse locale fondee sur le reperage d'indices textuels de certaines informations
semantiques presentes dans les textes. La strategie generalement adoptee par les systemes
d’extraction d’information (Pazienza, 1997) repose sur une analyse locale qui utilise des
techniques de pattem—matching (Grishman, 1997). En pratique, les indices textuels sont des
patrons d’extraction tres specialises qui dependent etroitement du domaine traite. Ces
systemes ont revele leur limites en termes de portabilite et d’evolution par rapport aux besoins
des utilisateurs (Poibeau et Nazarenko, 1999). Pour chaque application et pour chaque
nouveau domaine, il faut elaborer de nouveaux patrons specifiques, les tester et construire les
automates

Les evaluations realisees sur certains systemes de resume automatique (Minel et al., 1997 ;
Jing et al., 1998) ainsi que les travaux menes en collaboration avec les resumeurs
professionnels (Enddes—Niggemeyr, 1993) ou en comparaison avec les resumes produits par

Slim Ben Hazez, Jean—Pierre Desclés et Jean—Luc Minel

ces professionnels (Saggion et Lapalme, 1998) ont néanmoins montré la difficulté a réaliser
des resumes standard, c’est—a—dire construits sans tenir compte des besoins des utilisateurs.

En dépit des performances obtenues dans les systemes de resume automatique et d’extraction
d’inforrnation, l'étude des strategies utilisées souleve un certains nombre de questions:
Comment définir des taches réutilisables dont les ressources et les traitements peuvent
s'adapter aux besoins de l'utilisateur ? Comment modéliser les ressources linguistiques et les
rendre accessibles ? Comment exploiter l’organisation du texte et explorer le contexte
linguistique pour lever l’indétermination sémantique des indices linguistiques recherchés ?

L'objectif de nos travaux est de construire une plate—forme de filtrage sémantique de textes qui
Vise a donner quelques éléments opérationnels pour répondre a ces questions. L'originalité de
notre approche (Desclés et al., 1997, Minel et al., 2001) revient a se donner les moyens
d’accéder au contenu sémantique des textes, pour mieux les cibler et en extraire des sequences
particulierement pertinentes. D’une part, nous cherchons a exploiter directement
l’organisation textuelle des propos de l’auteur. D’autre part, nous nous intéressons aux
manifestations textuelles de certaines relations organisatrices de connaissances (relations
définitoires, causales, spatiales. . .). Notre but est de cibler, a l’aide de marqueurs linguistiques
et de certaines connaissances grammaticales, des sequences textuelles qui peuvent exprimer
un certain savoir sur le monde. Ce savoir ne se réduit pas a une nomenclature (objets,
propriétés, événements, etc.). 11 est notamment structure par un certain nombre de relations

entre concepts, événements, etc.

Le modele adopté pour répondre aux besoins du filtrage sémantique de textes consiste a
identifier, indépendamment d'un domaine particulier, certaines informations sémantiques
adaptables en fonction des besoins des utilisateurs. Ce modele est fondé d'une part, sur
l'identification dans les textes de marqueurs linguistiques d'une catégorie (grammaticale ou
discursive) ou d'une notion étudiée, et d'autre part sur une exploration du contextel des
marqueurs identifies. Cette exploration permet: d'interpréter le contexte d'un marqueur
linguistique; d'analyser la position d'un marqueur dans le texte (debut de phrase, premier
paragraphe, etc.); de manipuler les elements structurels du texte (titres, paragraphes,...);
d'identifier la structure thématique, etc. Pour mettre en ceuvre ce modele et foumir des outils
qui permettent de développer et de déployer des ressources linguistiques orientées Vers le
filtrage sémantique de textes, nous avons développé la plate—forme Filtext en utilisant le
modele d’exploration contextuelle. Nous allons presenter, a travers des exemples de
ressources et de taches réalisées, la modele d'exploration contextuelle et de données
linguistiques et l'architecture de la plate—forme.

2 Modélisation des données linguistiques
2.1 Acquisition des données linguistiques

La méthode d’exploration contextuelle est issue d’une réflexion initiale sur le traitement
informatique des Valeurs aspecto—temporelles SECAT (Desclés et al., 1991). La méthode a été

1 Cette analyse du contexte d'un marqueur linguistique ne se limite pas aux notions dc "concatenation" ou de
"contexte contigué".

Modéle d’expl0rati0n contextuelle pour l’analyse sémantique de textes

ensuite généralisée en tenant compte des indications présentes dans le contexte pour un calcul
des valeurs sémantiques relevant de différentes taches (Jouis, 1993, Berri, 1996, Desclés et
al., 1997a, 1997b).

D'apres le modele d’exploration contextuelle, l’étude linguistique consiste a determiner les
valeurs sémantiques des marqueurs linguistiques d'une catégorie grammaticale ou d’une
notion discursive. Selon les cas, une carte sémantique (par exemple, le réseau des relateurs de
repérage) (Desclés, 1987) peut étre construite pour une catégorie ou une notion étudiée. Le
processus d’acquisition (figure 1) pour chaque tache est fondé sur une etude systématique de
corpus de textes pour y rechercher des indicateurs discursifs explicites dont l’emploi est
représentatif de la valeur sémantique considérée ou de la notion étudiée. C’est en ce sens que
ces indicateurs deviennent des marqueurs de valeurs sémantiques. Comme exemple de champ
grammatical, donnons celui qui couvre l’identification des valeurs aspecto—temporelles
associées aux morphemes des temps grammaticaux du francais. Pour le champ du discours,
mentionnons par exemple les indicateurs discursifs des annonces thématiques, des
expressions définitoires, des relations entre concepts, des relations de causalité, des relations
temporelles entre événements, etc.

L’identification d’un marqueur (grammatical ou discursif) n’est cependant pas suffisante pour
determiner completement la valeur sémantique du marqueur. En effet, un indicateur
linguistique (indice déclencheur) est rarement un marqueur univoque d’une valeur sémantique
unique. Ayant identifié une occurrence de marqueur sous la forme d’un indicateur répertorié,
il faut, dans un deuxieme temps, explorer le contexte de cette occurrence pour rechercher
d’autres indices linguistiques, sous la forme d’occurrences d’indices complémentaires. Ceux—
ci permettront dans un cas favorable de lever l’indétermination sémantique attachée a priori
au marqueur analyse. Dans ce cas une etiquette sémantique pourra étre attribuée a un segment
linguistique (syntagme, phrase, paragraphe selon les cas). Les indices permettront également
d’invalider les hypotheses sémantiques qui pouvaient étre envisagées a propos du marqueur
analyse dans son contexte. L’exploration contextuelle est gouvernée par un ensemble de
regles (dite d’exploration) qui, pour un indicateur donné et une decision a prendre,
recherchent d’autres indices explicites dans un espace de recherche (phrase, paragraphe,...).
Par exemple, pour la proposition j’ai pris mon cachet, la marque du passe compose ne suffit
pas elle seule pour decider de la valeur aspecto—temporelle attachée a la proposition (on parle
d’indétermination sémantique). Les deux classes d'indices contextuels (ouf, enﬁn, ga y est,. . .)
et (ce matin,. . .) contribueront a lever l'indétermination sémantique et orienteront
respectivement vers la valeur "d'état resultant" et "d'événement" (Desclés et al., 1997a).

carte sémantique

r 

C0.’P"-‘idiétude Identifier les indices Identifier les indices et
l'"g'”-"t“I""’ _F declencheurs ’ les regles contextuels

~§/ A

1

, 
Corpus de tests

Tests et validation

1

 

m/

Figure 1 : Processus d'acquisition des données linguistiques

Slim Ben Hazez, Jean—Pierre Desclés et Jean—Luc Minel

L’acquisition de ces donnees linguistiques necessite le choix d'un corpus de travail qui depend
generalement de la tache a realiser et une fouille systematique des textes en vue d'accumuler
les indicateurs, les indices contextuelles et les regles qui les combinent ; cette fouille est
completee par un travail de reﬂexion linguistique, afin de degager des regularites textuelles.

2.2 Modéle de données linguistiques

Le travail de modelisation a pour objectif de capitaliser et de rendre accessibles les ressources
linguistiques. Pour repondre a l’objectif d’une acquisition incrementale et capitalisable des
donnees linguistiques, nous avons defini un modele et des outils qui permettent au linguiste
de construire et de maintenir des bases de donnees linguistiques specifiques a des taches
d’identification d’informations semantiques (Ben Hazez et Minel, 2000). Ce modele repond
aux specifications suivantes:

— Les donnees linguistiques sont organises par tache. Chaque tache se voit associee une base
de donnees de marqueurs linguistiques et de regles d'eXploration contextuelle. La notion
de tache est un moyen qui permet au linguiste d'organiser ces connaissances de maniere
independante. Le modele permet de gerer plusieurs bases linguistiques et de les organiser
sous forme d'arbre. Par exemple, la base de donnees linguistique associee a la tache de
resume automatique est composee de plusieurs sous—taches de reperage: des annonces
thematiques, des conclusions/recapitulations, des resultats, des hypotheses, etc.

— La strategie d’exploration de texte est guidee par des indices déclencheurs (indicateurs).
Contrairement a une strategie guidee par les regles, la description et la reconnaissance de
ces indicateurs ne sont pas donc codees dans les regles.

L'interface homme machine (IHM) presentee dans la figure 2 illustre un extrait des tables de
creation et de manipulation des donnees linguistiques. Cette interface permet au linguiste de
constituer sa base de donnees linguistiques en specifiant, les taches, les classes d'indicateurs et
les regles d’exploration contextuelle associees:

— La table "TACHE_fr" permet de declarer ou de selectionner une tache. Comme le montre
l'exemple de la figure 2, les donnees affichees representent une vue de la base globale
relative a la tache selectionnee << Resume >>.

— La table "CLASSES_MARQUEURS_fr" contient les declarations des classes
d'indicateurs (indices declencheurs) et les indices contextuels. Par exemple, la classe
"&Crecap1.10" selectionnee contient des indicateurs d'enonces de recapitulation.

— La table "MARQUEURS_fr" contient la description des marqueurs (motifs linguistiques)
pour chaque classe de la tache courante. Par exemple, les expressions linguistiques
selectionnees ("en conclusion", "pour finir", "en resume",...) representent des indicateurs
de recapitulation de la classe "&Crecap1. 10

— La table "REGLES_fr" permet de declarer pour chaque regle, le nom de la regle,
l'etiquette semantique associee, la classe des indicateurs qui declenche la regle et le
segment textuel a etiquete. Par exemple, la ligne selectionnee de la table specifie le nom
de la regle declenchee par les indicateurs de la classe "&Crecap1.10". L'action de cette

regle consiste a attribuer l'etiquette semantique "Recapitulation" a chaque phrase
contenant un indicateur de la classe "&Crecap1.10" verifiant les contraintes de la regle.

Modéle d’expl0rati0n contextuelle pour l’analyse sémantique de textes

Ces tables sont organisées selon un schema conceptuel implanté dans un systeme de gestion
de base de données relationnelle. Pour faciliter la gestion des bases linguistiques nous avons
intégré dans l'IHM des fonctions de tri, de recherche, de filtrage ainsi que des outils
d'interrogation et de Verification des contraintes d'intégrités des données linguistiques.

Eichier Edition ﬂfﬁchage lnsertlan Formal; Egreglstrements Qutils Fegétre 3

NONI TACHE PARENT CODE LANGUE A NONI ETIQUETFE IA NOM CLASSE TYPE
CadreDIscours EIDLEC fr Plan 11 e indice
Cause Cualis EIDLEC fr Elﬂfil indifie
Citatlon EIDLEC fr e|oc2 Indlce
Commentaire EIDLEC fr EIUC3 iﬂdice
Relations St EIDLEC fr e|0c4 indice

indice

9% F\I'1II=r‘ fr Induce
Enr: |1|1|ﬁ > |n|r* sur 6 A indicate“
2 indicaleur
2 Q . indicateur
Salon 1 indicaleur
DESCRIPTION MARQUEUR NONI CLASSE Pradicaliun 1 . Indlcaieur

gmgmm de 1 Predicaiion 2 . indicaleur
~ D»-nr~lir--Hinn 2 _ jndice

5‘ -1 em  Ijs 41 e
Induce
Indlcaleur

Enr:- h] 4 |_| _ 103 > n He "sur 3EI1(FI|tré) 4

NOM REGLE INDICATEUR ET|QUE‘|'l'E SEGMENT A
.RCenthe113 .:1 2
&Caction-enoncﬂ. Plan 1
1D 1 Souli 0
1|] Soul: I]
1El Soul: El
.RCenlhe111

élal des Iieux &CacliUn-anUnc3.1
era the &moda|3
cnnviendra de &moda|3
cnmrlent de &moda|3
cunviendrai de &mUda|3 ,

Enr: HI 4 88 b |>| |>aoe| sur 3529 (Filtré) 1 g
15 &moda|3 -

Enr: I<| I  19 > >I|Hé| sur 73(Filtré) ‘I I ’ 4

v

1 D
|Mnde Fnrmulaire IE I: I: F NUM F

Figure 2 : Tables de definition et de manipulation des données linguistiques

2.2.1 Langage de description des marqueurs linguistiques

Les marqueurs linguistiques sont des unites lexicales simples ou composées (morphemes,
mots, expressions et locutions, ...) formées a partir d'unités atomiques ("tokens") et des
opérateurs de concatenation, de disjonction et de repetition. Chaque motif linguistique décrit
un ensemble de réalisations possibles de sequences textuelles continues ou éventuellement
discontinues. Ces marqueurs linguistiques sont regroupés dans des classes en fonction de
criteres syntaxiques ou sémantiquesz. Une classe est identifiée par un nom precede par le
symbole "&". Par exemple, l'expression il est + cfzimportance permet de repérer des lexies du
type: il est primordial ; il est particuliérement important ; il est,. . ., essentiel ; etc. Pour une
tache donnée seules certaines ﬂexions d’un Verbe sont significatives. Ainsi, si le but est de

2 A partir d‘une premiere expression il est possible de construire une classe d‘expressions par des opérations de
synonymie, de nominalisation ou de paraphrase. L‘utilisateur doit par la suite valider les expressions
engendrées et éliminer les expressions incorrectes on non équivalentes.

Slim Ben Hazez, Jean—Pierre Desclés et Jean—Luc Minel

rechercher les annonces thématiques d'un article scientifique, le Verbe présenter est
significatif seulement lorsqu'il est employé a l'indicatif present ou au futur, a la premiere
personne du singulier ou du pluriel. Le langage integre un ensemble de classes d'eXpressions
prédéfinies (dates, énumérations, abréviations, nombres, etc.) identifiées par un "tokenizeur".
L'intégration d'un étiqueteur morpho—syntaXique permet d'améliorer la qualité de la
reconnaissance en effectuant des recherches par lemmes, par categories grammaticales et par
utilisation des informations flexionnelles.

2.2.2 Langage de description des régles

Les regles d’eXploration contextuelle sont exprimées dans un langage formel de type
déclaratif comme le montre l’eXemple de la figure 3. Ce langage est centre sur la notion d'un
espace de recherche, c'est—a—dire un segment textuel determine a partir de l'indicateur, espace
dans lequel les indices complémentaires doivent étre recherches. Il est important de pouvoir
exprimer des contraintes qui prennent en compte la dimension textuelle. La partie condition
de la regle explicite les conditions que doivent Verifier les indicateurs et les indices
complémentaires. Le langage permet d’exprimer différentes conditions, comme l'existence, la
position dans le texte et l'agencement des indices. La partie action consiste a attribuer une
etiquette a un segment textuel ou a déclencher une autre regle.

/* Téche déclenchante zthématique ;

caple un schéma du type : il semble .. crucial

lndicateur : &moda|3; */

E1 := Créer_espace(PhraseParent_de lndicateur);

L1 := &verbe-etat3 ; L2 := &adjectii-necessité

Condition: ||_existe_un_indice y apparienanl_a E1 ie|_que
c|asse_de y appartient_a (L1 ) ;

Condition : ||_existe_un_indice 2 apparienant_a E1 ie|_que
c|asse_de z appartient_a (L2) ;

Actions : Attribuer_Eliqueiie ("Sou|ignement_Auteur ")

Figure 3 : Exemple d’une regle pour repérer des énonces de soulignement par l’auteur

3 Architecture de la plate—forme

La plate—forme FilTeXt s'appuie sur le modele conceptuel des données linguistiques et le
modele d’eXploration contextuelle présentées précédemment. L'une des particularités du
systeme est son ouVerture: les utilisateurs peuvent créer de nouvelles bases linguistiques pour
d'autres taches et réutiliser des données ou des composants logiciels. Les traitements sont
encapsulés dans des API3 Java et produisent des sorties selon un format d'échange standard
XML, ce qui favorise un déploiement plus facile des ressources linguistiques. Comme le
montre la figure 4, la plate—forme est compose de trois sous—systemes qui cooperent : i) un
gestionnaire des données linguistiques doté d'une IHM; ii) un moteur d’eXploration
contextuelle qui exploite les données linguistiques pour une ou plusieurs taches choisies par
l’utilisateur et produit une structure hiérarchique du texte avec des "decorations sémantiques";
iii) un ensemble d'agents specialises dotés d'IHM et de connaissances qui exploitent les
decorations sémantiques générées par le moteur d'exploration contextuel.

3 Application Programming Interface.

Modéle d’expl0rati0n contextuelle pour l’analyse sémantique de textes

nom de ldches texte
I I
M oteur d’expl0rati0n ¢
contextuelle
Analyseur
Reconnaissance

Gestionnaire Requéte des mdlces

des donnees {L declencheurs

linguistiques

   

Structure
cl1ique du texte

 ' occurrences régles / . ,
tfindicateurs déclenchables hleraf

     

indicateurs
indices ll
régles Executeur de
bases étiquettes Regles Structure decoree
linguistiques du texte

 

   

 
   

 
  

Agent
spécialisé

Agent

extraz't/ résnme’ / graphe spécialisé

Figure 4 : Architecture generale de la plate—forrne

3.1 Gestionnaire des données linguistiques

Les donnees linguistiques sont capitalisees dans un systeme de gestion de bases de donnees
relationnelles (SGBDR). Le gestionnaire des donnees linguistiques est implemente sous
forme d'une API Java qui communiquent avec le SGBDR via la passerelle JDBC (Java
Database Connectivity). Cette API offre une vue objet de la base de donnees permettant le
developpement d'une IHM et de repondre 51 des requetes lancees par les autres sous—systemes
de la plate—forme. Ce module implemente un simple langage de requete qui permet differentes
operations sur la base de donnees linguistiques: importation de donnees, selection,
modification, etc. 11 integre aussi un module de reconnaissance de motifs linguistiques
(pattern—matching) utilise par les autres composants de la plate—forme. Ce dernier est un
automate qui permet de chercher dans un segment textuel (sequence de tokens, phrase, etc.)
toutes les occurrences d'un motif linguistique donne. Le resultat de recherche d'un marqueur
linguistique dans un segment S est represente sous forme d'un ensemble de paires de valeurs
notees S(u, v); u et v representent respectivement les positions du premier et demier elements
de chaque occurrence du motif.

3.2 Moteur d’eXpl0rati0n contextuelle

Le moteur d’eXploration contextuelle permet l’etiquetage semantique des segments textuels ;
il est compose de trois modules qui cooperent :

O L’analyseur de textes qui construit une premiere representation qui reflete l’organisation
structurelle du texte. La construction de cette structure hierarchique s'appuie sur le texte

Slim Ben Hazez, Jean—Pierre Descle's et Jean—Luc Minel

segmenté en unités structurelles: sections, paragraphes, phrases. L’analyseur fait appel a
trois modules indépendants: un segmenteur en unités structurelles; un tokeniseur qui
effectue le découpage en tokens et permet d’identifier la catégorie de chaque token (date,
énumération,...); un constructeur du modele objet du texte qui représente la structure
hiérarchique du texte.

0 Le module de reconnaissance des indicateurs qui a pour tache de compiler les indicateurs
(indices déclencheurs) pour l'ensemble des taches déclenchées et de les appliquer sur le
texte. Cette étape permet de rechercher toutes les occurrences des indicateurs et de
determiner quelles sont les regles a déclencher.

O Executeur de regles qui permet d'exécuter les regles associées a chaque occurrence d'un
indicateur trouvée. Les regles sont considérées comme indépendantes. Ce mode de
fonctionnement correspond a l’hypothese que, pour une tache donnée, certains marqueurs
sémantiques ne sont pas exclusifs entre eux. Par exemple, la presence d’une negation dans
une phrase conclusive n’implique pas que cette phrase ne soit pas par ailleurs une
« conclusion >>. D’autre part, une phrase étiquetée comme << définitoire >> peut aussi étre
étiquetée comme << conclusion». Toutes les déductions effectuées par les regles sont
attribuées aux éléments qui composent la hiérarchie du texte et produisent ainsi une
structure hiérarchique << décorée >> par des informations sémantiques.

L'algorithme ci—dessous illustre le fonctionnement du moteur d'eXploration contextuelle. La
premiere étape consiste a compiler les données linguistiques pour une ou plusieurs taches a
déclencher, puis a determiner la liste des indicateurs a appliquer sur le texte. Dans cette
exemple le moteur applique une analyse du texte par phrase. L'étape suivante du moteur
consiste d'abord a chercher dans chaque phrase du texte toutes les occurrences de la liste des
indicateurs, puis a exécuter les regles associées a chaque occurrence trouvée.

Fonctions fournies par l’interface (API) du systéme de gestion des données linguistiques:
T 6 compi|e(nom téches) I compiler l'ensemble de données linguistiques des téiches déclenchées dans une vue T.
M 6 se|ect|ndicaleurs(T) I renvoie l'ensemble M des classes d'indicateurs de T.
R 6 se|ectReg|es(T, Mi) 2 renvoie l'ensemble des régles d'exploraIion R associées a un indicateur M] de M.
OCC 6 identiIier_|ndicateurs(Si, Mi) 2 identiﬁe dans un segment S; toutes les occurrences dc l'indicateur M].

Algorithme du moteur:
DEBUT

T 6 compi|e(nom de téches);

M 6 se|ect|ndicateurs(T) ;

POUR TOUT phrase Si FAIRE

POUR TOUT indicateur M,-de M FAIRE
OCCG identifier_|ndicateurs(Si, M,-);
SI (OCC <>vide) ALORS R 6 se|ectReg|es(T, M,-);
POUR TOUT occurrence Sim, V, de OCC FAIRE

Executer_Reg|e(R, Sim, .,,);
//appliquer l'ensemble des régles R sur

//chaque occurrence de l ’indicateur  et
F| N P0 UR //étiqueter le segment S,-
FINSI
Fl N PO UR
Fl N PO UR
FIN

3.3 Agents spécialisés

Les agents spécialisés ont pour tache d’eXploiter les << decorations sémantiques» du texte en
fonction des objectifs définis par l’utilisateur. Chaque agent possede ces propres
connaissances et une IHM de presentation des résultats.

Modele d’expl0rati0n contextuelle pour l’analyse se'mantique de textes

Ainsi, l’agent résumeur—filtreur4 exploite des connaissances linguistiques qui permettent de
repérer des énoncés structurants, des definitions, des relations causales, etc. Par exemple,
l’étiquette "annonce thématique" est attribuée aux phrases exprimant le sujet, le theme d’un
segment textuel quelconque. L’étiquette "récapitulation/conclusion thématique" est attribuée
aux phrases explicitant les conclusions et enseignements généraux du texte. Certaines phrases
étant étiquetées, il devient possible de construire des extraits qui répondent aux besoins
spécifiques d’un utilisateur en appliquant différentes strategies de selection. Cependant, cette
extraction brise la coherence du texte source et peut meme introduire des contresens. Des
heuristiques simples ont été définies pour détecter potentiellement certains liens
anaphoriques, manipuler les marqueurs d'intégration linéaire (comme en premier lieu, en
second lieu, etc), exploiter la structure et les énumérations du texte, etc. En outre le
développement d'IHM qui permettent d'afficher l'arborescence du texte et d’offrir a
l'utilisateur des moyens pour naviguer entre l'extrait et le texte source constitue une des
réponses offerte par Filtext. Plutot que de chercher a produire un resume autonome,
indépendant du texte source, en appliquant une analyse profonde pour résoudre les problemes
d'anaphore, et repérer les liens de cohesion et de coherence, l'objectif se déplace Vers la
production d'un texte réduit aux informations jugées saillantes pour le lecteur, et la
construction de liens qui permettent au lecteur, au Vu des informations partielles qui lui sont
présentées, de fouiller, a la demande, le texte source.

D'autres agents sont intégrés dans la plate—forrne: identification des citations dans les textes
(Mourad, 2000) et d’extraire des relations sémantiques (localisation, composition, partie—tout,
attribution,...) entre concepts (Le Priol, 2000). Les résultats de ce dernier systeme sont
représentés sous forme de graphes ou de tables relationnelles.

4 Conclusion

Nous avons présenté un modele d'exploration de texte et une plate—forme logicielle permettant
de développer des ressources linguistiques pour extraire certaines informations sémantiques.
Les ressources linguistiques peuvent prendre la forme de base de données de marqueurs et de
regles, ou de textes avec des "decorations" sémantiques. L'une des particularités du systeme
est son ouverture : il permet aux utilisateurs de développer et manipuler des bases de données
linguistiques pour de nouvelles taches d'identification, l'enrichir en fonction des informations
qu'ils recherchent, réutiliser des données et des fonctionnalités du systeme, etc.

Le modele envisage doit étre adapté aux besoins des utilisateurs et applicable a tout type de
texte. Nous travaillons actuellement a l'intégration d'une analyse thématique fondée d'une part
sur des criteres statistiques et d'autre part sur le repérage des introducteurs thématiques (Ferret
et al., 2001).

L'analyse mise en ceuvre et l'acquisition des données linguistiques dependent étroitement de la
nature du corpus et de l'information recherchée. La couverture du corpus, le choix des bons
indices textuels et la realisation de taches réutilisables constitue une problématique
fondamentale de l'analyse textuelle qui nécessite une etude linguistique plus fouillée.

4 Le lecteur trouvera dans (Minel et al., 1997) une évaluation détaillée et dans (Minel et al., 2001) un exemple de
résumé produit par cet agent.

Slim Ben Hazez, Jean—Pierre Descle's et Jean—Luc Minel

Références

Ben Hazez, S., Minel J -L. (2000). Designing Tasks of Identification of Complex Patterns Used for Text
Filtering. RIAO 2000, Paris, 1558-1567.

Berri, J . (1996). Contribution a la méthode d‘exploration contextuelle. Applications au resume automatique et
aux representations temporelles. Réalisation inforrnatique du systeme SERAPIHN. These de doctorat, Université
Paris—Sorbonne, Paris.

Desclés, J -P. (1987). Réseaux sémantiques : la nature logique et ling11istique des relateurs, langages,
Se’mantiques et Intelligence Artiﬁcielle, n° 87, p. 55-78.

Desclés, J-P., Jo11is, C., Oh, H—G., Reppert, D. M. (1991). Exploration Contextuelle et sémantique : un systeme
expert qui trouve les vale11rs sémantiques des temps de l‘indicatif dans un texte. In Knowledge modeling and
expertise transfer, pp.371-400, D. Herin—Aime, R. Dieng, J -P. Regourd, J .P. Angoujard (eds), Amsterdam.

Desclés, J -P. (1997a). Systemes d'exploration contextuelle. Co-texte et calcul du sens. (ed Claude G11imier),
Presses Universitaires de Caen, 215-232.

Desclés, J -P., Cartier, E., Jackiewicz, A., Minel, J -L. (1997b). Textual Processing and Contextual Exploration
Method. In CONT EXT ‘97, Rio de Janeiro, Brésil.

Endres-Niggemeyer, B. (1993). An empirical process model of abstracting. In Workshop on Summarizing Text
for Intelligent Communication, Dagsthul, Germany.

Ferret, O., Grau, B., Minel, J .-L., Porhiel, S. (2001). Repérage de structures thématiques dans les textes. T ALN
2001, Tours.

Grishman, R. (1997) . Information extraction : techniques and challenges. In : Pazienza, M.T. ed. Information
extraction. Berlin : Springer verlag, 10-27.

Jing, Hongyan, Regina Barzilay et Kathleen McKeown. (1998). Summarization evaluation methods :
Experiments and analysis. In Symposium on Intelligent Text Summarization, Stanford, CA.

Jo11is, C. (1993). Contribution a la conceptualisation et a la modélisation des connaissances a partir d‘une analyse
linguistique de textes. These de doctorat, EHESS, Paris.

Le Priol, F. (2000). Extraction et capitalisation de connaissances a partir de documents text11els. SEEK-JAVA :
Identification et interpretation de relation entre concepts. These de doctorat, Université Paris—Sorbonne, Paris.

Minel , J -L., Nugier, S., Piat, G. (1997). How to appreciate the Quality of Automatic Text Summarization.
Workshop Intelligent Scalable Text Summarization, EACL 97, Madrid, 25-30.

Minel J -L., Cartier, E , Crispino, G., Desclés J -P, Ben Hazez S, Jackiewicz, A. (2001) Resume automatique par
filtrage sémantique d’inforrnations dans des textes. Technique et Science Informatiques, Paris, n° 3.

Mourad, G. (2000). Presentation de connaissances linguistiques pour le repérage et l’extraction de citations.
TALN (RECIT AL ’2000), Lausanne, p 495-501.

Pazienza, M.T. (1997) (ed). Information extraction (a multidisciplinary approach to an emerging information
technology), International Summer School, SCIE ‘97, Springer Verlag (Lectures Notes in Computer Science).

Poibeau, T., Nazarenko, A.(1999). L’extraction d’inforrnation, une nouvelle conception de la comprehension de
texte ?, T.A.L. vol 40., n°2, p 87-115.

Saggion, H., Lapalme, G. (1998). Where does information come from ? Corpus Analysis for Automatic
Abstracting. RIFRA ’98, Rencontre Internationale sur l ’Extraction le F iltrage et le Re’sume’ automatiques, Sfax,
Tunisie.

