<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>lléﬁérences Balpe</author>
<author>J P Lelu</author>
<author>A Papy</author>
<author>F</author>
</authors>
<title>Techniques avancées pour l ’hypertexte.</title>
<date>1996</date>
<location>Paris, Hermes.</location>
<contexts>
<context position="3751" citStr="Balpe et al. (1996)" startWordPosition="556" endWordPosition="559">le cas de termes composes en langue allemande comme, par exemple, lebensversicherungsgesellschaﬁsangestellter (“employe d’une compagnie d’assurance Vie”), ou pour la langue arabe dans laquelle les pronoms sujets et complements sont dans certains cas attaches aux Verbes et une seule chaine de caracteres represente ainsi une phrase comme, par exemple, kathabthouhou (“je l’ai ecrit”), cette notion de tokens devient inadequate (Manning &amp; Schiitze, 1999). Si le mot simple ne convient pas a toutes les langues, quelle est donc l’unite d’information atomique la plus adequate pour segmenter un texte ? Balpe et al. (1996) soulignent que dependant de l’objectif de lecture et de comprehension que nous nous donnons, la deﬁnition de l’unite d’information depend de l’usage qui en est attendu. Dans une perspective de classiﬁcation numerique a des ﬁns d’extraction de connaissances, la deﬁnition d’une unite d’information est tributaire des contraintes suivantes : 0 L’unite d&apos;information doit étre une portion du texte soumis a l’analyse numerique. 0 I1 doit étre facile sur le plan informatique de reperer les unites d’information. 0 La deﬁnition d’une unite d’information doit étre independante de la langue dans laquelle</context>
</contexts>
<marker>Balpe, Lelu, Papy, F, 1996</marker>
<rawString>GRAMEXCO. lléﬁérences Balpe, J.P., Lelu, A. Papy, F. (1996), Techniques avancées pour l ’hypertexte. Paris, Hermes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G Meunier</author>
<author>S Hamidi</author>
<author>Z Remaki</author>
<author>M Nyongwa</author>
</authors>
<date>1998</date>
<booktitle>Etude Expérimentale Comparative des Méthodes Statistiques pour la Classiﬁcation des Données Textuelles”, Actes de JADT-98,</booktitle>
<location>Nice, France.</location>
<marker>Meunier, Hamidi, Remaki, Nyongwa, 1998</marker>
<rawString>Benhadid, 1., Meunier, J.G., Hamidi, S., Remaki, Z., Nyongwa, M. (1998), “Etude Expérimentale Comparative des Méthodes Statistiques pour la Classiﬁcation des Données Textuelles”, Actes de JADT-98, Nice, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Delisle</author>
</authors>
<title>User-Relevant Access To Textual Information Through Flexible Identiﬁcation Of Terms: A Semi-Automatic Method And Software Based On A Combination Of N-Grams And Surface Linguistic Filters”, Actes de RIAO-2000,</title>
<date>2000</date>
<pages>1059--1068</pages>
<location>Paris,</location>
<contexts>
<context position="26529" citStr="Delisle, 2000" startWordPosition="4059" endWordPosition="4060">iver a regrouper les segments 32, 35, 41 et 48 dans la meme classe sans avoir recours a la lemmatisation etant donne que le seul mot commun est russe. Reste que la lemmatisation est relativement coﬁteuse en temps d’execution et est une operation speciﬁque a chaque langue. Nous evitons ces inconvenients en utilisant les n-grams de caracteres. Les raisons d’aussi bonnes performances nous les retrouvons dans les resultats de la deuxiéme évaluation principale. En effet, celle-ci consistait a passer un texte de deux pages forme d’extraits d’un corpus sur les biotechnologies (utilise dans Biskri et Delisle, 2000) par une classiﬁcation basee sur les n-grams avec, comme parametre, n=4 et la taille du segment ramenee a un mot seulement. Ainsi les segments regroupes dans une meme classe seraient constitues des mots ayant des points communs, en particulier un radical commun et, donc, referant a une notion commune. Cette evaluation a permis de construire l’echantillon de classes suivantes : Classe 101 : {survecu, survie} Classe 102 : {utilisee, outil} Classe 110 : {congele, décongele, congeles, congélateur} Classe 112 : {simple, simplifier, simplifiée} Classe 162 : {avenir, devenir} Classe 4 : {principale, </context>
</contexts>
<marker>Delisle, 2000</marker>
<rawString>Biskri, 1., Delisle, S. (2000), “User-Relevant Access To Textual Information Through Flexible Identiﬁcation Of Terms: A Semi-Automatic Method And Software Based On A Combination Of N-Grams And Surface Linguistic Filters”, Actes de RIAO-2000, Paris, France, 1059-1068.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Delisle</author>
</authors>
<title>Un Modele Hybride pour le Textual Data Mining : Un Mariage de Raison entre le Numérique et le Linguistique”, Actes de TALN-99,</title>
<date>1999</date>
<pages>55--64</pages>
<location>Cargese, France,</location>
<contexts>
<context position="10197" citStr="Delisle (1999)" startWordPosition="1530" endWordPosition="1531">s mots information, informationnel, etc., ce qui peut étre considere a juste titre comme du bruit, a moins bien sﬁr que l’on evoque une interpretation semantique particuliere de l’informatique comme etant une science de l’information. 3. GRAMEXCO : n-GRAMs pour l’EXtraction des COnnaissances GRAMEXCO est un outil logiciel que nous avons developpe pour la classiﬁcation numerique des gros corpus et l’extraction de connaissances sur le contenu des textes. La classiﬁcation Ismai&apos;l Biskri &amp; Sylvain Delisle numerique s’effectue au moyen d’un reseau de neurones ART comme celui utilise dans Biskri et Delisle (1999). L’unite d’information consideree est le n-gram de caracteres, la valeur de n etant parametrable. L’objectif vise est de fournir la meme chaine de traitement, peu importe la langue du corpus, avec toutefois des amenagements dans la presentation des resultats pour en permettre une relative facilite de lecture comme nous le verrons plus loin. Le fonctionnement de GRAMEXCO n’est pas totalement automatique. Le choix de certains parametres est fait par l’utilisateur en fonction de ses propres obj ectifs. Du choix de ces parametres depend l’interpretation des resultats qui se fait par l’utilisateur</context>
</contexts>
<marker>Delisle, 1999</marker>
<rawString>Biskri, 1., Delisle, S., (1999), “Un Modele Hybride pour le Textual Data Mining : Un Mariage de Raison entre le Numérique et le Linguistique”, Actes de TALN-99, Cargese, France, 55-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Damashek</author>
</authors>
<title>Gauging Similarity with n-Grams :</title>
<date>1995</date>
<journal>Language-Independent Categorization Of Text”, Science,</journal>
<volume>267</volume>
<pages>843--848</pages>
<contexts>
<context position="6171" citStr="Damashek (1995)" startWordPosition="909" endWordPosition="910">ui incontournable : l’essor du Web conﬁrme ce besoin de multilinguisme. I1 semble donc imperatif que les modeles pour l’analyse de corpus, qu’ils soient numeriques ou linguistiques, tiennent compte du caractere multilingue des textes a analyser. 2. Les n-grams dc caracteres Bien qu’ayant ete proposee depuis longtemps et utilisee principalement en reconnaissance de la parole, la notion de n-grams dc caractércs prit davantage d’importance avec les travaux de Extraction de connaissances dans des bases de donnees textuelles multilingues Greffenstette (1995) sur l’identiﬁcation de la langue, et de Damashek (1995) sur le traitement de l’ecrit. Autre autres, ils prouverent que ce decoupage, bien que different d’un decoupage en mots, ne faisait pas perdre d’information. Parrni des applications recentes des n-grams on retrouve des travaux sur : l’indexation (Mayﬁeld &amp; McNamee, 1998) ; l’hypertextualisation automatique multilingue avec les travaux de Halleb et Lelu (1998) qui, a travers une methode de classiﬁcation thematique de collections de textes, independante du langage, construisent des interfaces de navigation hypertextuelle ; ou l’analyse exploratoire multidimensionnelle en vue d’une recherche d’in</context>
</contexts>
<marker>Damashek, 1995</marker>
<rawString>Damashek, M., (1995), “Gauging Similarity with n-Grams : Language-Independent Categorization Of Text”, Science, 267, 843-848.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greffenstette</author>
</authors>
<title>Comparing Two Language Identiﬁcation Schemes”, Actes de JADT95,85-96 Halleb</title>
<date>1995</date>
<location>Nice, France.</location>
<contexts>
<context position="6115" citStr="Greffenstette (1995)" startWordPosition="900" endWordPosition="901">ltilingues de l’analyse. Ce dernier facteur devient aujourd’hui incontournable : l’essor du Web conﬁrme ce besoin de multilinguisme. I1 semble donc imperatif que les modeles pour l’analyse de corpus, qu’ils soient numeriques ou linguistiques, tiennent compte du caractere multilingue des textes a analyser. 2. Les n-grams dc caracteres Bien qu’ayant ete proposee depuis longtemps et utilisee principalement en reconnaissance de la parole, la notion de n-grams dc caractércs prit davantage d’importance avec les travaux de Extraction de connaissances dans des bases de donnees textuelles multilingues Greffenstette (1995) sur l’identiﬁcation de la langue, et de Damashek (1995) sur le traitement de l’ecrit. Autre autres, ils prouverent que ce decoupage, bien que different d’un decoupage en mots, ne faisait pas perdre d’information. Parrni des applications recentes des n-grams on retrouve des travaux sur : l’indexation (Mayﬁeld &amp; McNamee, 1998) ; l’hypertextualisation automatique multilingue avec les travaux de Halleb et Lelu (1998) qui, a travers une methode de classiﬁcation thematique de collections de textes, independante du langage, construisent des interfaces de navigation hypertextuelle ; ou l’analyse expl</context>
</contexts>
<marker>Greffenstette, 1995</marker>
<rawString>Greffenstette, (1995), “Comparing Two Language Identiﬁcation Schemes”, Actes de JADT95,85-96 Halleb M., Lelu A., (1998), “Hypertextualisation Automatique Multilingue a Partir des Fréquences de n-Grammes”, Actes de JADT-98, Nice, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lelu</author>
<author>M Halleb</author>
</authors>
<title>Recherche d’inforrnation et Cartographie dans des Corpus Textuels a Partir des Fréquences de n-Grammes”, Actes de JADT-98,</title>
<date>1998</date>
<location>Nice, France.</location>
<marker>Lelu, Halleb, 1998</marker>
<rawString>Lelu A., Halleb M. , Delprat B. (1998), “Recherche d’inforrnation et Cartographie dans des Corpus Textuels a Partir des Fréquences de n-Grammes”, Actes de JADT-98, Nice, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>H Sch11tze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing,</booktitle>
<publisher>MIT Press.</publisher>
<marker>Manning, Sch11tze, 1999</marker>
<rawString>Manning, C.D., Sch1&amp;quot;1tze, H., (1999), Foundations of Statistical Natural Language Processing, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Mayﬁeld</author>
<author>P Mcnamee</author>
</authors>
<title>Indexing Using both n-Grams and Words”,</title>
<date>1998</date>
<journal>NIST Special Publication 500-242 .&apos; TREC</journal>
<volume>7</volume>
<pages>419--424</pages>
<marker>Mayﬁeld, Mcnamee, 1998</marker>
<rawString>Mayﬁeld, J., Mcnamee, P., (1998), “Indexing Using both n-Grams and Words”, NIST Special Publication 500-242 .&apos; TREC 7, 419-424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Nault</author>
<author>M Nyongwa</author>
</authors>
<date>1997</date>
<booktitle>Aladin et le Traitement Connexionniste de l’Analyse Terminologique”, Actes de RIAO—97,</booktitle>
<pages>661--664</pages>
<location>Montréal, Canada,</location>
<marker>Nault, Nyongwa, 1997</marker>
<rawString>Meunier, J.G., Biskri, 1., Nault, G., Nyongwa, M. (1997), “Aladin et le Traitement Connexionniste de l’Analyse Terminologique”, Actes de RIAO—97, Montréal, Canada, 661-664.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Turenne</author>
</authors>
<title>Apprentissage statistique pour l ’extraction de concepts a partir de textes (Application au ﬁltrage d ’informations textuelles), these de doctorat en informatique, Université Louis-Pasteur,</title>
<date>2000</date>
<location>Strasbourg, France.</location>
<contexts>
<context position="14974" citStr="Turenne (2000)" startWordPosition="2252" endWordPosition="2253">’un réseau de neurones (ART dans notre cas). Les segments qui sont semblables, étant donnée une certaine fonction de similarité, sont classés dans les mémes groupes. En simplifiant, on peut dire que deux segments sont semblables s’ils sont constitués des mémes n-grams avec des fréquences presque identiques. Le choix du réseau ART pour la classification n’est pas dicté par des raisons de performances particulieres car tel n’est pas notre objectif pour le moment. Nous aurions tout aussi bien pu choisir un autre réseau neuronal qui aurait certes donné des résultats différents — nous recommandons Turenne (2000) au lecteur intéressé aux méthodes et outils de classification pour le texte. De telles variations apparaissent dans les résultats d’une étude expérimentale et comparative des méthodes statistiques et des champs de Markov pour l’analyse de textes par ordinateur présentés dans Benhadid et al. (1998). Comme suite a ce travail, nous gardons d’ailleurs l’idée de parametrer GRAMEXCO afm de permettre a l’utilisateur de choisir d’autres réseaux de neurones. 3. La configuration du résultat de la classification numérique se présente par l’aff1chage des classes de segments et, pour chaque classe, l’aff1</context>
</contexts>
<marker>Turenne, 2000</marker>
<rawString>Turenne, N. (2000), Apprentissage statistique pour l ’extraction de concepts a partir de textes (Application au ﬁltrage d ’informations textuelles), these de doctorat en informatique, Université Louis-Pasteur, Strasbourg, France.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>