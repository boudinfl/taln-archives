
Les n-grams dc caractéres pour l'aide £1 l’extraction dc
connaissances dans des bases de données textuelles multilingues

Isma'1'l Biskri & Sylvain Delisle

Université du Québec a Trois Rivieres
Département de mathématiques et d’informatique
C.P. 500, Trois-Rivieres, Québec, Canada, G9A 5H7
{ismail_biskri, sylvain_delisle} @uqtr.uquebec.ca

Résumé — Abstract

Une véritable classification numérique multilingue est impossible si on considere seulement le
mot comme unité d’information privilégiée. En traitant les mots comme jetons, la tokenisation
s’avere relativement simple pour le francais et l’anglais, mais tres difficile pour des langues
comme l’allemand ou l’arabe. D’autre part, la lemmatisation utilisée comme moyen de
normalisation et de réduction du lexique constitue un écueil non moins négligeable. La notion
de n-grams, qui depuis une décennie donne de bons résultats dans l’identification de la langue
ou dans l’analyse de l’oral, est, par les recherches récentes, devenue un axe privilégié dans
l’acquisition et l’extraction des connaissances dans les textes. Dans cet article, nous
présenterons un outil de classification numérique basé sur le concept de n-grams de
caracteres. Nous évaluons aussi les résultats de cet outil que nous comparons a des résultats
obtenus au moyen d’une classification fondée sur des mots.

Real multilingual numerical classification is impossible if only words are treated as the
privileged unit of information. Although it makes tokenisation (in which words are considered
as tokens) relatively easy in English or French, it makes it much more difficult for other
languages such as German or Arabic. Moreover, lemmatisation, typically used to normalise
and reduce the size of the lexicon, poses another challenge. The notion of n-grams which, for
the last ten years, seems to have produced good results both in language identification and
speech analysis, has recently become a privileged research axis in several areas of knowledge
acquisition and extraction from text. In this paper, we present a text classification tool based
on n-grams of characters and evaluate its results and compare them with those obtained from a
different classification tool based solely on the processing of words.

Mots clés 2 classification numérique de textes, n-grams, multilinguisme.

Ismail Biskri & Sylvain Delisle

1. Introduction

Normalement la premiere etape dans un processus de traitement d’un gros corpus au moyen
d’un outil statistique est de subdiviser le texte a traiter en plusieurs unites d’information
appelees tokens qui sont, traditionnellement, des mots simples. Ce processus de tokenisation
pose une question primordiale: sur le plan informatique, comment reperer un mot ? En
d’autres termes, quels sont les indicateurs formels de surface, non ambigus, qui peuvent
delimiter un mot ? Si pour le francais ou l’anglais litteraire, ou des langues apparentees, la
reponse est presgue triviale — a savoir que toute chaine de caracteres precedee et suivie d’un
espace est consideree comme un mot simple — il en Va tout autrement pour d’autres langues.
Dans le cas de termes composes en langue allemande comme, par exemple,
lebensversicherungsgesellschaﬁsangestellter (“employe d’une compagnie d’assurance Vie”),
ou pour la langue arabe dans laquelle les pronoms sujets et complements sont dans certains
cas attaches aux Verbes et une seule chaine de caracteres represente ainsi une phrase comme,
par exemple, kathabthouhou (“je l’ai ecrit”), cette notion de tokens devient inadequate
(Manning & Schiitze, 1999).

Si le mot simple ne convient pas a toutes les langues, quelle est donc l’unite d’information
atomique la plus adequate pour segmenter un texte ? Balpe et al. (1996) soulignent que
dependant de l’objectif de lecture et de comprehension que nous nous donnons, la deﬁnition
de l’unite d’information depend de l’usage qui en est attendu. Dans une perspective de
classiﬁcation numerique a des ﬁns d’extraction de connaissances, la deﬁnition d’une unite
d’information est tributaire des contraintes suivantes :

0 L’unite d'information doit étre une portion du texte soumis a l’analyse numerique.

0 I1 doit étre facile sur le plan informatique de reperer les unites d’information.

0 La deﬁnition d’une unite d’information doit étre independante de la langue dans laquelle
le texte est ecrit. Une telle deﬁnition permet a l’analyse numerique, moyennant des
modiﬁcations minimes, de couvrir un large eventail de langues.

0 Les unites d’information doivent étre statistiquement comparables. I1 doit étre aise d’en
calculer les frequences d’apparition dans les differentes parties du texte et par consequent
d’estimer leur distribution et la regularite a laquelle plusieurs unites cooccurrent dans les
memes parties du texte.

Que l’unite linguistique dans une analyse de classiﬁcation numerique soit linguistiquement
comprise dans une certaine mesure hors de son contexte n’est pas en soit une contrainte lors
de la phase de classiﬁcation. Toutefois a l’afﬁchage des resultats, ce facteur devient important
des lors que l’interpretation faite par l’utilisateur en depend. La plupart des analyseurs
statistiques fondes sur le calcul de la frequence des cooccurrences utilisent le mot comme
unite d’information, meme si celui-ci ne repond pas a toutes les contraintes enumerees ici.
Cependant, l’importance de l’ergonomie interpretative des mots a prevalu sur tout autre
aspect, particulierement ceux liees aux aspects multilingues de l’analyse. Ce dernier facteur
devient aujourd’hui incontournable : l’essor du Web conﬁrme ce besoin de multilinguisme. I1
semble donc imperatif que les modeles pour l’analyse de corpus, qu’ils soient numeriques ou
linguistiques, tiennent compte du caractere multilingue des textes a analyser.

2. Les n-grams dc caracteres

Bien qu’ayant ete proposee depuis longtemps et utilisee principalement en reconnaissance de
la parole, la notion de n-grams dc caractércs prit davantage d’importance avec les travaux de

Extraction de connaissances dans des bases de donnees textuelles multilingues

Greffenstette (1995) sur l’identiﬁcation de la langue, et de Damashek (1995) sur le traitement
de l’ecrit. Autre autres, ils prouverent que ce decoupage, bien que different d’un decoupage en
mots, ne faisait pas perdre d’information. Parrni des applications recentes des n-grams on
retrouve des travaux sur : l’indexation (Mayﬁeld & McNamee, 1998) ; l’hypertextualisation
automatique multilingue avec les travaux de Halleb et Lelu (1998) qui, a travers une methode
de classiﬁcation thematique de collections de textes, independante du langage, construisent
des interfaces de navigation hypertextuelle ; ou l’analyse exploratoire multidimensionnelle en
vue d’une recherche d’information dans des corpus textuels (Lelu et al., 1998).

On deﬁnira un n-gram de caracteres par une suite de n caracteres : bi-grams pour n=2, tri-
grams pour n=3, quadri-grams pour n=4, etc. 11 n’est plus question de chercher un delimiteur
comme c’etait le cas pour le mot. Un decoupage en n-grams de caracteres, quelque soit n,
reste Valable pour toutes les langues utilisant un alphabet et la concatenation comme operateur
de construction de texte. Le choix des n-grams apporte un autre avantage tres important : il
permet de contr6ler la taille du lexique et de la maintenir a un seuil raisonnable. La taille du
lexique etait jusqu’a present l’aspect le plus controverse et considere comme une limite des
techniques fondees sur la comparaison des chaines de caracteres. En effet, un decoupage en
mots fait que la taille du lexique est d’autant plus grande que le corpus est grand. Cette limite
subsiste malgre certains amenagements tels le “nettoyage” des mots fonctionnels, la
lemmatisation et la suppression des hapax. Un lexique obtenu suite a un decoupage en n-
grams de caracteres ne peut depasser la taille de l’alphabet a la puissance n. Le choix d’un
decoupage en quadri-grams pour une langue de 26 caracteres donnerait une taille maximale de
264 entrees, soit un lexique de 456 976 quadri-grams possibles. Si on elimine les
combinaisons qu’il est impossible de rencontrer (p.ex. AAAA, ABBB, BBBA, etc.), ce
nombre diminue de facon considerable. D’ailleurs ce nombre est estime par Lelu et al. (1998)
a quelques 13 087 quadri-grams pour un texte de 173 000 caracteres.

Dans une approche avec decoupage en n-grams de caracteres, contrairement aux approches
avec decoupage en mots, il n’est pas question d’utiliser la lemmatisation pour reduire le
lexique. La lemmatisation (qui consiste a remplacer une forme ﬂechie par son lemme) est,
d’une part, relativement lourde a mettre en oeuvre sur le plan informatique mais en plus,
impose un traitement speciﬁque a chaque langue. Qui plus est, plusieurs lemmatiseurs ne
semblent pas étre en mesure de ramener des terrnes comme informatisation, informatique, et
informatiser a un meme concept qu’est l’informatique. Or souvent dans les corpus, on utilise des
expressions ayant quasiment le meme contenu informationnel comme, par exemple, dans les
segments suivants : “l’informatisation de l’ecole”, “informatiser l’ecole” et “introduire
l’informatique a l’ecole”. Le decoupage des trois segments en n-grams est sufﬁsant pour
classer les trois segments dans la meme classe car, outre le mot ecole qui est redondant dans
les trois expressions, les tri-grams m, m, E, E, E, m_a’t et a_ti, permettent par un calcul de
similarite d’afﬁrmer que c’est d’informatique dont il est question. Par ailleurs, les tri-grams
susmentionnes apparaissent aussi dans le decoupage des mots information, informationnel, etc.,
ce qui peut étre considere a juste titre comme du bruit, a moins bien sﬁr que l’on evoque une
interpretation semantique particuliere de l’informatique comme etant une science de
l’information.

3. GRAMEXCO : n-GRAMs pour l’EXtraction des COnnaissances

GRAMEXCO est un outil logiciel que nous avons developpe pour la classiﬁcation numerique
des gros corpus et l’extraction de connaissances sur le contenu des textes. La classiﬁcation

Ismai'l Biskri & Sylvain Delisle

numerique s’effectue au moyen d’un reseau de neurones ART comme celui utilise dans Biskri
et Delisle (1999). L’unite d’information consideree est le n-gram de caracteres, la valeur de n
etant parametrable. L’objectif vise est de fournir la meme chaine de traitement, peu importe la
langue du corpus, avec toutefois des amenagements dans la presentation des resultats pour en
permettre une relative facilite de lecture comme nous le verrons plus loin. Le fonctionnement
de GRAMEXCO n’est pas totalement automatique. Le choix de certains parametres est fait
par l’utilisateur en fonction de ses propres obj ectifs. Du choix de ces parametres depend
l’interpretation des resultats qui se fait par l’utilisateur en fonction de sa subjectivite.
GRAMEXCO prend en entree un texte brut (non indexe) sous format ASCII. 11 s’en suit trois
grandes etapes ou l’utilisateur peut parametrer certains traitements.

Elptiuns de I'anaIyseur

Segmentation ] Meram] Ciassirieur]

Type de segmentation

N I: U ccurences
EI|:II:iI:In§ de I'anaIy-seur

Segmentation Nafam I Classifieuli

1|

Caractere:

Cﬂnvetsiﬂn des Caracléres en rnaiL.ISE:L.I|e
Pa'aQ'aF'h'3 Mm Conversion des caracteres en minuscule

F“ Phage (R Marqueur Auoune conversion

?| 1'35)

Conveltil les caracteres non alphanumériques
en blancs

Conveltil les ohiffres en blanos

U

Nomble de caracteres

3

1.
Segmentation I NGIam CIESSIHBUI 1
Uptions sur Ie Ie:-cioue des classes
|_ Lemmatisation du Ie:-iioue

I7 Nettoyage des mots fonotionnels

Figure 1 : Paramétrage de l’outil GRAMEXCO

La premiére étape consiste a construire la liste des n-grams de caracteres contenus dans
le texte ainsi qu’a partitionner le corpus en plusieurs segments. Les deux operations se
faisant simultanement, nous recuperons en sortie une matrice ou seront repertories les
frequences d’apparition de chaque n-gram dans les differents segments. Le choix de la
valeur du n (bi-gram, tri-gram, quadri-gram, etc.) depend de l’utilisateur et de l’expertise
qu’il veut mener. Outre la valeur du n, d’autres parametres (voir Figure 1) sont la
possibilite d’effectuer la conversion des caracteres non alphanumeriques en caractere
espace, ou encore la conversion des chiffres en caractere espace. Ces deux parametres
repondent aux besoins d’une analyse pour laquelle les chiffres, la ponctuation ou encore
d’autres caracteres speciﬁques seraient importants pour la qualité des resultats. Dans un
texte technique par exemple, il serait peut etre interessant de savoir si versionl est
differente de version2 et, par consequent, les chiffres pourraient avoir autant d’impact
informatif que les caracteres alphabetiques. Le dernier parametre pour les n-gram est en
rapport avec la conversion des caracteres majuscules en minuscules, ou vice versa. Si
aucune de ces conversions n’est choisie, alors GRAMEXCO distinguera les lettres
minuscules des majuscules. L’autre aspect important de cette premiere etape est le
parametrage de la segmentation. Ainsi, nous pouvons partager le texte soit en des

Extraction de connaissances dans des bases de donne’es textuelles multilingues

sections formées d’un nombre déterminé de phrases, de paragraphes ou de mots, ou tout
simplement des sections séparées par un caractere spécial. Ce parametre est toujours
choisi par l’utilisateur. Le pseudo-lexique forme de n-grams subit au cours de cette
premiere étape un nettoyage (voir Figure 2) soit, l’élimination des “n-grams hapax” dont
la fréquence est inférieure a un certain seuil ou supérieure a un autre seuil, l’élimination
de n-grams spécifiques sélectionnés dans la liste (par exemple des n-grams contenant
des espaces) ou encore, si on veut pousser les choses plus loin, l’élimination de certains
n-grams considérés comme fonctionnels, particulierement les suffixes.

Nettoyage des HGran1s en fréquence‘ ‘ X
NGIam Fléq. Totale A _ _
aada 7 Enlever Ia selection

aage
Fiéinitialiser la liste
Enlevel nGram fnnetinnnel

Min 1 Max 3333
abon

Enlever intervalle fréquence
abet
7
7 "" [I Enlever nGIam avec espaces

abéc
aban
abd
abet
abet
abﬂ
abm
abh
abﬂ
abm
able
ebb
abﬁ

njngngememmnwmenn

Figure 2 : Nettoyage de la liste des n-grams produits par GRAMEXCO

2. Dans la deuxiéme étape, les segments représentés dans la matrice obtenue a l’étape
précédente sont comparés entre eux au moyen d’un réseau de neurones (ART dans notre
cas). Les segments qui sont semblables, étant donnée une certaine fonction de similarité,
sont classés dans les mémes groupes. En simplifiant, on peut dire que deux segments
sont semblables s’ils sont constitués des mémes n-grams avec des fréquences presque
identiques. Le choix du réseau ART pour la classification n’est pas dicté par des raisons
de performances particulieres car tel n’est pas notre objectif pour le moment. Nous
aurions tout aussi bien pu choisir un autre réseau neuronal qui aurait certes donné des
résultats différents — nous recommandons Turenne (2000) au lecteur intéressé aux
méthodes et outils de classification pour le texte. De telles variations apparaissent dans
les résultats d’une étude expérimentale et comparative des méthodes statistiques et des
champs de Markov pour l’analyse de textes par ordinateur présentés dans Benhadid et
al. (1998). Comme suite a ce travail, nous gardons d’ailleurs l’idée de parametrer
GRAMEXCO afm de permettre a l’utilisateur de choisir d’autres réseaux de neurones.

3. La configuration du résultat de la classification numérique se présente par l’aff1chage
des classes de segments et, pour chaque classe, l’aff1chage des segments qui la
constituent d’une part, et du lexique qui la forme d’autre part (voir Figure 3). A cette
troisiéme étape la notion de n-gram n’est plus de mise. Il serait en effet impossible a un
utilisateur d’interpréter des résultats et de donner des themes aux différentes classes a
partir d’une seule liste de n-grams. Comme le souligne Turenne (2000), l’interprétation
de telles classes est déja un exercice non trivial en lui-méme, dependant des points de
vue de l’utilisateur : il ne serait donc pas utile de lui rendre cette phase moins intuitive
en utilisant une liste de n-grams. Le lexique de chaque classe est formé par les mots que

Ismail Biskri & Sylvain Delisle

contiennent les differents segments de cette classe. L’utilisateur pourra considerer le
lexique comme l’union des mots des segments pour determiner le theme global des
classes, leur intersection pour determiner le theme commun partage par les segments,
leur difference pour identiﬁer des gains informationnels, ou encore tous ceux dont la
freguence est au dessus d’un certain seuil, etc. L’utilisateur peut egalement lemmatiser
le lexique des classes comme il peut en retirer les mots fonctionnels. L’utilisateur peut
appliquer l’operation de lemmatisation a l’ensemble des lexiques de toutes les classes ou
seulement au lexique d’une seule classe, ceci en fonction de contraintes de temps. Il est
a retenir que la lemmatisation et la suppression des mots fonctionnels n’interviennent
que pour ameliorer l’aspect des resultats et n’interviennent nullement avant la
classification a proprement parler. Toutes ces conﬁgurations du lexique sont a meme
d’aider l’utilisateur a proposer son interpretation des resultats. En effet, il demeure que
GRAMEXCO, comme nous l’avons souligne plus haut, ne propose pas d’interpretation
automatique. Il ne fait que faire ressortir les similarites et les regularites decouvertes
dans le corpus.

Segment selectionne

Classe: 23 7 Les communications intercellulaires assurees entre autres par les A
hormones assurent la coherence de |'enseml:u|e Un caractere genetioue
Segment donne a done lui-meme peu de chance de ne dependre que d'un seul

de la gene au sens moleculaire du terme L'ei-ramen des proteines en particulier

a |'aide d'electrophorese, permet d'etal:u|ir dans certains cas favorables des

classe correlations entre un caractere genetique donne et la presence d'une
loande dans un electrophoregramme Des sondes d'acide nucleique qui
peuvent, e—. la base pres, reveler aisement une mutation dans un gene
constituent des outils incomparalzilement plus precis pour proceder a une
selection genetique fine ll convient de ce point de we de faire des —
distinctions entre les differents types de sondes que l'on peut utiliser
J _ Eertaines correspondent directement e—. la sequence d'un gene codant
l:'l3'3'E'l'°" pour une proteine bien definie tandis que d'autres detectent des regions
if‘ Union F“ non fonctionnelles ou supposees telles du genome Les informations ﬂ
I7 Intersection I”
F" Difference I“ Te:-rte source

F DCCUTEVICE E:-recuter En ce qui concerne |'ege de |'eml:ur_I,Ion, la principale contrainte est la 4-

technique du transfert. Chez la vache, |'uti|isation de la i-.-'oie cervicale

Mots cle haw impose le depet dans l'uterus : l'eml3r_I,Ion_ doit etre ege de 5 iours DU plus.
la classe Coupe Che: les petits rpminants, pendant la chirurgie ou la laparoscopie,

déﬁni |'oviducte peut etre‘atteint aussr atsement que |'uterus : les eml:ur_I,Ipns des
dilectemem stades pronulcleus a blastocyste [ages de 1 a F iours] sont transferaloles
""'5'“‘E'“ eV3eCcLeni~i%gEaHirLlé'ii:i?N
l_::?ét2u|ai[e Entre les uterus des dpnneuses et des receveuses, les emloryons sont

nucléase manrpules et co_nsewes_in vitro pendant quelques minutes, plusieurs

nucléique heures, ou plusieurs m_ois ou annees_ Dans les conditions optimum les

pefmet eml:ur_I.Jons passent in vitro le temps le plus court possible [1 a 2 heﬁures] ,'

polymmphism] pour des temps plus longs [E a ‘I2 heures] les conditions doivent etre

région optimisees [wars milieu:-r de culture, co-culture sur tapis cellulaire]. Dans ce

Iesmction cas cependant, les tau:-: de succesiapres transfert sont diminues_ \

,;.,, ﬂ Duand un delai plus long est impose entre collecte et transfert [24 a 48
heures], on peut recourir a la conservation entre El et +al-°|:_ Le tau:-r de

| succes apres 24 heures ne differe pas de celui olotenu apres transfert
d'eml:ir_I,Ions frais. .-'1‘-. partir de 48 heures de conservation, le tau:-r de succes j
lmprimer classe selectionnee l lmprimer toutes les classes | Fermer |

Figure 3 : Configuration des résultats de GRAMEXCO

Dependant des parametres choisis, les resultats de GRAMEXCO peuvent servir a plus d’une
ﬁnalite. Comme nous le Verrons a l’aide des exemples de la prochaine section, nous pouvons :
0 determiner le contenu lexical des segments similaires, et ainsi connaitre le theme principal
de ces segments ;
0 determiner l’acception et la signiﬁcation d’un mot de par les mots qui lui sont associes
dans une classe donnee ; et

Traitement sur les classes X _

Extraction de coririaissances dans des bases de donnees textiielles multilingues

0 construire des classes de mots formes a partir d’un radical commun comme pour
l’exemple avec informatiser, informatisation, et informatique.

4. Evaluation

Nous avons mene deux evaluations principales gualitatives (et deux complementaires). La
premiere Voulait montrer le comportement d’une classification numerique fondee sur les n-
grams de caracteres. Elle a ete realisee sur un corpus forme d’une cinquantaine de pages
(format ASCII) construit a partir d’extraits de documents trouves sur le Web. Ces documents
couvrent divers domaines et perrnettent une heterogeneite du contenu du corpus et, par
consequent, une meilleure comprehension des resultats de la classification. La deuxieme
evaluation avait pour but d’expliquer pourquoi la classification avec les n-grams pouvait etre
aussi performante sinon plus performante qu’une “classification + lemmatisation”. Cette
evaluation a ete realisee sur un texte de deux pages. Sa finalite n’en exigeait pas plus pour
construire des classes de mots ayant un meme radical.

Pour les operations preliminaires de la premiere evaluation principale, soit la segmentation
et l’extraction des n-grams, nous avons opte pour les parametres suivants : 10 (phrases) pour
determiner la taille d’un segment et 4 (caracteres) pour determiner la taille des n-grams . De
plus, a l’aide des parametres de GRAMEXCO, nous avons considere les lettres majuscules
identiques aux lettres minuscules et nous avons remplace les caracteres non alphanumeriques
et les chiffres par des espaces. Nous avons ainsi recupere 174 segments et 4 857 quadri-grams,
apres un “menage” de la liste des n-grams qui a consiste a supprimer les n-grams contenant un
ou plusieurs espaces et les n-grams ayant une frequence egale a 1. La classification elle-
meme, au moyen du reseau de neurones ART avec un parametre de vigilance de 0.1, donne
lieu a la production de 100 classes de segments presentants des similarites. Examinons
maintenant quelques resultats :

0 La classe 100 regroupe les segments 137 et 157. Le lexique de cette classe forme de
l’intersection des lexiques des deux segments est constitue par : {bourse, francs, marchés,
millions, mobile, pdg, prix}. On constate, au regard de ce lexique, que le mot francs designe la
monnaie frangaise et n’a aucun rapport avec la franchise ou avec les fameuses tribus “le_s
francs”. Ce meme lexique nous renseigne egalement sur le theme commun que se
partagent les segments 137 et 157, en l’occurrence le domaine financier.

0 La classe 54 regroupe les segments 141 et 143. L’intersection des lexiques des segments
de la classe 54 est forrnee de : {appel, cour, décidé, juge}. Ainsi pour le mot cour, une seule
signification est possible au regard des mots qui l’accompagnent : cour de justice. On
ecarte aisement les sens suivants : la cour qu’on fait a une demoiselle, la cour de
recreation, ou encore les toilettes des Belges. Le theme de la classe 54 est par ailleurs bien
identifie en ce sens qu’il s’agit de segments dont le contenu traite d’affaires judiciaires.

0 La classe 98 regroupe les segments 71 et 73. Le lexique issu de l’intersection des lexiques
des deux segments est forme des mots : {culture, économiques, eurasistes, matérialiste,
occident}. Dans ce contexte, le terme culture ne peut signifier que culture economigue, et
son utilisation n’est pas pour introduire une quelconque notion d’agriculture. Ce qui se
confirrne d’ailleurs avec le mot occident qui est utilise ici dans le sens bloc geopolitigue et
non “la on se couche le soleil”. Le theme de la classe 98 traite sans conteste d’options
economigues ce que nous pouvons d’ailleurs verifier au travers de la lecture des segments
71 et 73.

1 Selon Darnashek (1995), les quadri-grams donneraient les meilleurs resultats pour l’anglais. Lelu et al. (1998)
semblent corifirrner cela pour le francais.

Ismail Biskri & Sylvain Delisle

0 La classe 64 regroupe les segments 166 et 167. Le lexique qu’on retiendra pour cette
classe est forme de tous les mots dont la frequence dans les segments 166 et 167 est
superieure ou egale a 2, en l’occurrence les mots : {chance, derniere, dire, match, stade,
supporters, vélodrome}. Le mot stade, du fait particulierement de la presence des mots
match, supporters et vélodrome, est compris comme etant un stade de football. Par ailleurs,
pour un public averti qui sait que le Velodrome est le stade de Marseille, on comprend
aisement que les deux segments 166 et 167 traite des supporters de l’OlVmpique
Marseillais.

0 La classe 13 regroupe les segments 32, 35, 41 et 48. Le lexique de cette classe forme de
l’intersection des lexiques des quatre segments est constitue du seul mot : russe. Celui-ci
est suffisant pour nous permettre de conclure que le theme partage par les quatre segments
se rapporte a la Russie. L’union des lexiques, formee entre autres des mots : conservateur,
socialisme, marxiste, conservateur, revolutionnaire, Dostoievski, doctrine, imperial, slavophile,
etc., nous permet de precisermque le theme de la classe 13 est dedie aux slavophiles et a la
culture politique russe du 191°“ siecle. Une remarque s’impose : on imagine mal comment
une classiﬁcation fondee sur les mots aurait pu arriver a regrouper les segments 32, 35, 41
et 48 dans la meme classe sans avoir recours a la lemmatisation etant donne que le seul
mot commun est russe. Reste que la lemmatisation est relativement coﬁteuse en temps
d’execution et est une operation speciﬁque a chaque langue. Nous evitons ces
inconvenients en utilisant les n-grams de caracteres.

Les raisons d’aussi bonnes performances nous les retrouvons dans les resultats de la
deuxiéme évaluation principale. En effet, celle-ci consistait a passer un texte de deux pages
forme d’extraits d’un corpus sur les biotechnologies (utilise dans Biskri et Delisle, 2000) par
une classiﬁcation basee sur les n-grams avec, comme parametre, n=4 et la taille du segment
ramenee a un mot seulement. Ainsi les segments regroupes dans une meme classe seraient
constitues des mots ayant des points communs, en particulier un radical commun et, donc,
referant a une notion commune. Cette evaluation a permis de construire l’echantillon de
classes suivantes :

Classe 101 : {survecu, survie}

Classe 102 : {utilisee, outil}

Classe 110 : {congele, décongele, congeles, congélateur}
Classe 112 : {simple, simplifier, simplifiée}

Classe 162 : {avenir, devenir}

Classe 4 : {principale, principalement}

Classe 48 : {optimisées, optimum}

Classe 60 : {cellules, cellulaire}

Classe 65 : {collecte, collectifs}

Classe 7 : {transfert, transférables, transférés, pénétrant, transferts, retransfert}
Classe 81 : {glycol, glycerol}

Classe 88 : {déshydratées, déshydratation}

Si nous prenons la classe 110 par exemple, nous nous apercevons que non seulement congelé
et congelés sont regroupes, ce qu’aurait d’ailleurs fait une lemmatisation standard, mais en
plus la classiﬁcation leur associe décongelé et congélateur. En somme la classe 110 regroupe
tout ce qui se rapporte a la notion de congelation. 11 en est de meme pour les autres classes qui
chacune regroupe des mots partageant des notions communes. Ainsi la classe 101 porte sur la
notion de survie, la classe 102 sur la notion d’outils utiles, la classe 112 sur la simplicite, la
classe 48 sur l’optimalite, la classe 65 sur la notion de cellule, la classe 65 sur celle de la
collection, la classe 7 sur la notion de transfert, la classe 81 sur un concept chimique
particulier, et la classe 88 sur la notion de deshydratation.

Nous avons aussi effectue une troisiéme évaluation, complementaire aux deux premieres.
Elle a consiste particulierement a comparer les resultats de GRAMEXCO lors de la premiere

Extraction de connaissances dans des bases de donnees textuelles multilingues

evaluation a des resultats obtenus avec NUMEXCO (Biskri et Delisle,1999 ; Meunier et al.,
1997) — NUMEXCO est un autre outil logiciel que nous avons developpe et qui,
contrairement a GRAMEXCO, considere comme unite d’information le mot (et non les n-
grams de caracteres). Nous avons soumis a NUMEXCO le meme texte ASCII que lors de
notre seconde evaluation et ce, avec le meme parametre de segmentation. Nous avons obtenu
un lexique de 4 884 mots, apres lemmatisation et suppression des mots fonctionnels. La
suppression des hapax (mots dont la frequence est egale a 1) aurait diminue le lexique a 1 755
unites d’information. Notons cependant que la suppression des hapax renvoie en quelque sorte
a une suppression de n-grams dont la frequence pourrait depasser 1, ce qui n’etait pas le cas
dans notre premiere evaluation ou nous n’avons supprime que les n-grams dont la frequence
etait egale a 1 — ce facteur donne lieu a une comparaison biaisee. Ceci dit, il est important de
souligner que pour un texte ne depassant pas les 200 pages environ, la taille du lexique et le
nombre de n-grams ne different pas de beaucoup. Pour certains textes, le nombre de n-grams
peut depasser la taille du lexique. Cependant, des lors que la taille du texte depasse les 200
pages, voire les 300 pages, la taille du lexique tend a augmenter alors que le nombre de n-
grams se stabilise. Sur le plan de la classification a proprement parler, les classes que nous
sommes arrives a construire avec GRAMEXCO ont ete impossibles a reproduire avec
NUMEXCO et ce, en raison du peu de mots communs apres lemmatisation se trouvant dans
les differents segments des classes.

Finalement, dans le cadre d’une derniére évaluation complementaire, nous sommes revenus
a la question du multilinguisme et avons soumis a GRAMEXCO un corpus constitue de deux
textes anglais portant respectivement sur la meteo et la mecanique des petits moteurs — nous
ferons prochainement d’autres evaluations sur un corpus constitue de plusieurs textes anglais
provenant de differents sites Web. Nous avons obtenu des resultats tout a faire similaires a
ceux des evaluation precedentes effectuees sur des corpus francais et ce, sans aucun
traitement spéciﬁque a la langue anglaise. Il reste toutefois a l’utilisateur d’interpreter les
resultats issus d’un corpus d’une ou de plusieurs autres langues. Cependant, avec la
disponibilite de certains outils de traduction automatique modernes, on peut penser que
l’utilisateur pourrait d’abord s’interesser a la traduction du lexique construit a partir de
l’occurrence des mots dans les segments d’une meme classe pour decider s’il y a lieu de
poursuivre son examen des textes correspondants.

Enﬁn, nous sommes conscients que les evaluations que nous presentons ici sont plus
qualitatives que quantitatives. De plus, elles ne tiennent pas compte de l’inﬂuence des
parametres. Nous aurons certainement l’occasion dans nos prochaines publications de
presenter d’autres evaluations complementaires a celles presentees dans le present article.

5. Conclusion

Notre travail semble tres concluant quant a l’importance des n-grams de caracteres dans
l’acquisition des connaissances a partir de grands corpus, ce qui va dans le meme sens que
d’autres travaux recents. Comme nous l’avons montre, l’utilisation des n-grams dans une
classiﬁcation numerique permet de penser l’outil comme etant multilingue : aucun module
11 ’est spéciﬁque d une langue particuliére. Les deux grandes contraintes que nous avions avec
des outils de classiﬁcation fondes sur les mots, a savoir la deﬁnition inforrnatique du mot et la
lemmatisation, se voient deﬁnitivement ecartees, du moins aux etapes de classiﬁcation. La
conﬁguration des resultats a ses propres contraintes et nous devons necessairement choisir de
presenter les resultats dans une forme admissible par l’utilisateur, ce qui n’est pas une

Ismail Biskri & Sylvain Delisle

question simple au plan ergonomique. Nous avons opté pour les classes de segments et les
classes de mots. Les deux résultats fondamentaux auxquels nous sommes arrives, outre
l’aspect multilingue, sont d’une part la qualité remarquable de la classiﬁcation et d’autre part
le fait que le choix des n-grams restreint la taille des vecteurs soumis a la classiﬁcation pour
des textes d’une taille supérieure a 200-300 pages. Comme suite a ce travail, nous
envisageons de greffer GRAMEXCO a un systeme d’aide a la recherche d’inforrnation sur le
Web et ce, dans le but de classiﬁer les sites obtenus suite a une requéte formulée a1’aide d’un
moteur de recherche. L’idée serait de cemer les sites contenant les mots clés de notre requéte
avec la bonne acception des mots d’une part et, d’autre part, la possibilité de reformuler la
requéte en fonction des résultats de la classiﬁcation. De telles perspectives ne sont
envisageables de facon réaliste que grace a des outils supportant le multilinguisme, comme
GRAMEXCO.

lléﬁérences

Balpe, J.P., Lelu, A. Papy, F. (1996), Techniques avancées pour l ’hypertexte. Paris, Hermes.

Benhadid, 1., Meunier, J.G., Hamidi, S., Remaki, Z., Nyongwa, M. (1998), “Etude
Expérimentale Comparative des Méthodes Statistiques pour la Classiﬁcation des Données
Textuelles”, Actes de JADT-98, Nice, France.

Biskri, 1., Delisle, S. (2000), “User-Relevant Access To Textual Information Through Flexible
Identiﬁcation Of Terms: A Semi-Automatic Method And Software Based On A Combination
Of N-Grams And Surface Linguistic Filters”, Actes de RIAO-2000, Paris, France, 1059-1068.

Biskri, 1., Delisle, S., (1999), “Un Modele Hybride pour le Textual Data Mining : Un Mariage
de Raison entre le Numérique et le Linguistique”, Actes de TALN-99, Cargese, France, 55-64.

Damashek, M., (1995), “Gauging Similarity with n-Grams : Language-Independent
Categorization Of Text”, Science, 267, 843-848.

Greffenstette, (1995), “Comparing Two Language Identiﬁcation Schemes”, Actes de JADT-
95,85-96

Halleb M., Lelu A., (1998), “Hypertextualisation Automatique Multilingue a Partir des
Fréquences de n-Grammes”, Actes de JADT-98, Nice, France.

Lelu A., Halleb M. , Delprat B. (1998), “Recherche d’inforrnation et Cartographie dans des
Corpus Textuels a Partir des Fréquences de n-Grammes”, Actes de JADT-98, Nice, France.

Manning, C.D., Sch1"1tze, H., (1999), Foundations of Statistical Natural Language Processing,
MIT Press.

Mayﬁeld, J., Mcnamee, P., (1998), “Indexing Using both n-Grams and Words”, NIST Special
Publication 500-242 .' TREC 7, 419-424.

Meunier, J.G., Biskri, 1., Nault, G., Nyongwa, M. (1997), “Aladin et le Traitement
Connexionniste de l’Analyse Terminologique”, Actes de RIAO—97, Montréal, Canada, 661-
664.

Turenne, N. (2000), Apprentissage statistique pour l ’extraction de concepts a partir de textes
(Application au ﬁltrage d ’informations textuelles), these de doctorat en informatique,
Université Louis-Pasteur, Strasbourg, France.
