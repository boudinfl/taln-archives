<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Utilisation des entit&#233;s nomm&#233;es et des variantes terminologiques dans un syst&#232;me de question-r&#233;ponse</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2001, Tours, 2-5 juillet 2001
</p>
<p>Utilisation des entit&#233;s nomm&#233;es et des variantes terminologiques
dans un syst&#232;me de question-r&#233;ponse
</p>
<p>Olivier Ferret (1), Brigitte Grau (1), Martine Hurault-Plantet (1),
Gabriel Illouz (1) et Christian Jacquemin (1)
</p>
<p>(1) LIMSI-CNRS, BP 133, 91403 Orsay cedex
{ferret, bg, mhp, gabrieli, jacquemin}@limsi.fr
</p>
<p>R&#233;sum&#233; &#8211; Abstract
Nous pr&#233;sentons dans cet article le syst&#232;me QALC qui a particip&#233; &#224; la t&#226;che Question
Answering de la conf&#233;rence d&#8217;&#233;valuation TREC. Ce syst&#232;me repose sur un ensemble de
modules de Traitement Automatique des Langues (TAL) intervenant essentiellement en aval
d&#8217;un moteur de recherche op&#233;rant sur un vaste ensemble de documents : typage des questions,
reconnaissance des entit&#233;s nomm&#233;es, extraction et reconnaissance de termes, simples et
complexes, et de leurs variantes. Ces traitements permettent soit de mieux s&#233;lectionner ces
documents, soit de d&#233;cider quelles sont les phrases susceptibles de contenir la r&#233;ponse &#224; une
question.
</p>
<p>We developed a system, QALC, that participated to the Question Answering track of the
TREC evaluation conference. QALC exploits an analysis of documents, selected by a search
engine, based on the search for multi-words terms and their variations both to select a
minimal number of documents to be processed and to give indices for comparing question and
sentence representations. This comparison also takes advantage of a question analysis module
and a recognition of numeric and named entities in the documents.
</p>
<p>Mots-cl&#233;s
Syst&#232;me de question-r&#233;ponse, entit&#233; nomm&#233;e, variante terminologique, recherche
d'information
</p>
<p>1 Introduction
L'introduction de la t&#226;che &quot;Question Answering&quot; lors de la conf&#233;rence d&#8217;&#233;valuation TREC8
(Text REtrieval Conference), en 1999, est r&#233;v&#233;latrice du besoin de d&#233;velopper des syst&#232;mes
capables d'apporter l'information attendue par un utilisateur, celle qui r&#233;pond le mieux &#224; sa
requ&#234;te. C'est ainsi que les nouveaux syst&#232;mes de recherche d&#8217;information ne doivent plus
s'arr&#234;ter &#224; la seule proposition de documents, mais doivent en extraire les parties pertinentes,
soit en proposant la r&#233;ponse, s&#8217;il s'agit d'une question d&#8217;ordre factuel, ou un r&#233;sum&#233; si la
requ&#234;te est d'ordre th&#233;matique. Dans un syst&#232;me de question-r&#233;ponse, la recherche de
documents pertinents est compl&#233;t&#233;e par la s&#233;lection de courts extraits de texte contenant la
r&#233;ponse &#224; la question pos&#233;e. Cette s&#233;lection est op&#233;r&#233;e par un ensemble de modules de TAL, &#224;
la fois de nature syntaxique et s&#233;mantique, devant poss&#233;der une grande couverture
linguistique et s&#8217;appliquer ind&#233;pendamment du domaine abord&#233;. La probl&#233;matique &quot;question-
r&#233;ponse&quot; a &#233;t&#233; introduite d&#232;s la fin des ann&#233;es 70 lorsque Lehnert (1977) a jet&#233; les bases d&#8217;un</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>O. Ferret, B. Grau, M. Hurault-Plantet, G. Illouz, C. Jacquemin
</p>
<p>syst&#232;me de question-r&#233;ponse avec le syst&#232;me QUALM. Plus r&#233;cemment, Molla et al (2000)
ont propos&#233; EXTRANS, un syst&#232;me de question-r&#233;ponse sur le manuel Unix. M&#234;me dans ce
domaine limit&#233;, les auteurs associent une approche fond&#233;e sur une analyse syntaxique et
s&#233;mantique des questions et du manuel &#224; une approche fond&#233;e sur des mots-cl&#233;s de mani&#232;re &#224;
rendre leur syst&#232;me plus robuste.
</p>
<p>Dans cet article, nous pr&#233;sentons notre syst&#232;me de question-r&#233;ponse QALC, con&#231;u pour traiter
des questions factuelles ou encyclop&#233;diques portant sur n&#8217;importe quel domaine. QALC a
particip&#233; aux &#233;valuations TREC8 et TREC9. La campagne 1999 consistait &#224; proposer
5 r&#233;ponses ordonn&#233;es, &#224; trouver dans un corpus de 500 000 documents environ, pour chacune
des 200 questions pos&#233;es. En 2000, la m&#234;me t&#226;che s&#8217;appliquait &#224; environ 700 questions et
1 million de documents. Chaque r&#233;ponse propos&#233;e devait &#234;tre un tr&#232;s court extrait (250
caract&#232;res maximum) d&#8217;un document du corpus. Les documents sont des articles de journaux
am&#233;ricains, tels que le Wall Street Journal, le Los Angeles Times, etc.
</p>
<p>Apr&#232;s avoir pr&#233;sent&#233; l'architecture g&#233;n&#233;rale de QALC, nous d&#233;taillerons ses diff&#233;rents
modules : reconnaissance des entit&#233;s nomm&#233;es, des termes et de leurs variantes dans les
documents ainsi que l&#8217;utilisation de ces informations dans la s&#233;lection des documents
pertinents et dans le module d&#8217;appariement entre une question et les phrases candidates &#224; la
r&#233;ponse. La pr&#233;sentation des r&#233;sultats obtenus lors de la derni&#232;re &#233;valuation TREC sera suivie
d&#8217;une discussion sur des travaux connexes, puis nous conclurons sur les &#233;volutions envisag&#233;es
pour notre syst&#232;me.
</p>
<p>2 Architecture du syst&#232;me
Les composants TAL du syst&#232;me QALC (cf. Figure 1) visent soit &#224; d&#233;duire le type attendu de
la r&#233;ponse afin de s&#233;lectionner la r&#233;ponse pr&#233;cise &#224; l&#8217;int&#233;rieur d&#8217;un document, soit &#224; enrichir la
description des documents s&#233;lectionn&#233;s afin que la recherche de la r&#233;ponse s'appuie sur des
indices allant au del&#224; des simples mots des documents.
</p>
<p>Analyse des
 questions
</p>
<p>Moteur de
recherche
</p>
<p>R&#233;-indexation et s&#233;lection des documents (FASTR)
</p>
<p>Reconnaissance des entit&#233;s nomm&#233;es
</p>
<p>Types des questions : 
type d&#8217;entit&#233; nomm&#233;e
</p>
<p>Phrases annot&#233;es : types d&#8217;entit&#233; nomm&#233;e et
indexation par les termes et variantes
</p>
<p>Vocabulaire &amp;
fr&#233;quences
</p>
<p>Appariement Question/Phrase
</p>
<p>S&#233;quence ordonn&#233;e de 250 et 50
caract&#232;res
</p>
<p>Questions Corpus
</p>
<p>Documents s&#233;lectionn&#233;sTermes
</p>
<p>Sous-ensemble de documents pond&#233;r&#233;s
</p>
<p>Figure 1. Architecture du syst&#232;me QALC
L'analyse des questions est r&#233;alis&#233;e par un analyseur partiel d&#233;di&#233; qui attribue aux questions
des cat&#233;gories correspondant aux types d'entit&#233;s nomm&#233;es pouvant r&#233;pondre &#224; la question. La
s&#233;lection d&#8217;un sous-ensemble de documents pertinents repose sur la reconnaissance des
termes de la question ou de leurs variantes dans les documents s&#233;lectionn&#233;s par un moteur de</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Entit&#233;s nomm&#233;es et variantes dans un syst&#232;me de question-r&#233;ponse
</p>
<p>recherche classique. Cette reconnaissance est effectu&#233;e par FASTR (Jacquemin, 1999) sur la
base des termes extraits de la question. Cette s&#233;lection rev&#234;t toute son importance lorsque le
syst&#232;me applique les processus ult&#233;rieurs, &#224; savoir la reconnaissance des entit&#233;s nomm&#233;es
telles que les personnes, organisations, lieux et valeurs num&#233;riques, et la comparaison entre
phrase et question, processus fortement consommateurs de temps de traitement.
</p>
<p>Le dernier module, qui propose un ensemble limit&#233; de r&#233;ponses &#224; chaque question, met en
&#339;uvre un calcul de similarit&#233; entre une question, repr&#233;sent&#233;e par un vecteur contenant ses
mots pleins lemmatis&#233;s, ses termes et le type attendu de sa r&#233;ponse, et les phrases des
documents retenus, repr&#233;sent&#233;es de mani&#232;re analogue. Les r&#233;ponses donn&#233;es par QALC sont
des phrases, unit&#233;s les plus significatives du point de vue de l&#8217;utilisateur final, mais peuvent
&#234;tre rendues plus concises gr&#226;ce &#224; un ensemble d&#8217;heuristiques permettant d&#8217;extraire de la
phrase une r&#233;ponse pr&#233;cise.
</p>
<p>3 Les Entit&#233;s Nomm&#233;es
QALC utilise les entit&#233;s nomm&#233;es &#224; la fois pour sp&#233;cifier le type de la r&#233;ponse attendue et
pour d&#233;tecter ensuite les entit&#233;s de m&#234;me type dans les documents afin d'aider &#224; localiser la
r&#233;ponse.
</p>
<p>3.1 D&#233;termination du type de la r&#233;ponse
Conna&#238;tre le type de la r&#233;ponse &#224; une question permet au module d&#8217;appariement de
privil&#233;gier, parmi plusieurs phrases candidates &#224; la r&#233;ponse, celles qui contiennent un groupe
de mots qui correspond &#224; ce type. L&#8217;analyse d&#8217;une question conduit &#224; lui attribuer une
&#233;tiquette s&#8217;identifiant au type de l&#8217;entit&#233; nomm&#233;e qu&#8217;elle admet comme r&#233;ponse. Par
exemple :
</p>
<p>Question : How many people live in the Falklands ? &#8212;&gt; type = NUMBER
(Combien de personnes habitent les Falklands ?)
</p>
<p>R&#233;ponse : Falkland population of &lt;b_numex_TYPE=N U M B E R&gt; 2,100 &lt;e_numex&gt; is
concentrated &#8230;
</p>
<p>(La population des Falklands, de 2 100 habitants, est concentr&#233;e &#8230;)
</p>
<p>Les &#233;tiquettes utilis&#233;es sont pr&#233;sent&#233;es Figure 2. Les &#233;tiquettes typant les r&#233;ponses
correspondent aux feuilles de l&#8217;arbre, auxquelles s&#8217;ajoutent les &#233;tiquettes nomPropre et
nombre et sont similaires &#224; ceux adopt&#233;s dans la t&#226;che MUC (Grishman, Sundheim, 1995).
Les &#233;tiquettes sont organis&#233;es en une hi&#233;rarchie afin d&#8217;avoir plus de souplesse dans la
recherche de la r&#233;ponse.
</p>
<p>NomPropre Fonction ExpressionTemps Nombre
</p>
<p>Ville Endroit
</p>
<p>Entit&#233; nomm&#233;e Entit&#233; num&#233;rique
</p>
<p>Entit&#233;
</p>
<p>Personne Organisation Age Date P&#233;riode Heure Physique Longueur Poids Volume FinancierLieu
</p>
<p>Figure 2 : Hi&#233;rarchie de types de r&#233;ponses et de cat&#233;gories s&#233;mantiques
</p>
<p>L&#8217;analyse des questions est effectu&#233;e par un analyseur d&#233;di&#233; fond&#233; sur le d&#233;clenchement de
r&#232;gles d&#233;crivant diff&#233;rents types de questions. Les indices utilis&#233;s dans les r&#232;gles pour d&#233;cider
de l&#8217;attribution d&#8217;une &#233;tiquette sont d&#8217;ordre lexical, avec la d&#233;tection de mots sp&#233;cifiques,</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>O. Ferret, B. Grau, M. Hurault-Plantet, G. Illouz, C. Jacquemin
</p>
<p>d&#8217;ordre syntaxique et s&#233;mantique. Les cat&#233;gories s&#233;mantiques ont &#233;t&#233; constitu&#233;es
manuellement, et permettent d&#8217;&#233;tiqueter la tr&#232;s grande majorit&#233; des questions r&#233;pondant aux
types pr&#233;vus, soit environ 60% des 700 questions de TREC9. Une am&#233;lioration pr&#233;vue
consiste &#224; utiliser WordNet pour compl&#233;ter les cat&#233;gories s&#233;mantiques.
</p>
<p>3.2 Reconnaissance des entit&#233;s nomm&#233;es
Les entit&#233;s nomm&#233;es sont marqu&#233;es dans les documents par une balise dont le type
correspond aux types de r&#233;ponses pr&#233;sent&#233;s &#224; la Figure 2. Les types retenus sont reconnus par
des r&#232;gles gr&#226;ce &#224; l&#8217;exploitation conjointe de deux sources d&#8217;information :
&#8226; des lexiques g&#233;n&#233;raux permettant de trouver des traits syntaxiques et s&#233;mantiques associ&#233;s
</p>
<p>aux mots simples en compl&#233;ment de traits lexicaux, et
&#8226; des dictionnaires d'entit&#233;s nomm&#233;es.
</p>
<p>Les ressources utilis&#233;es sont CELEX (CELEX 1998), un lexique de 160 595 mots fl&#233;chis
auxquels sont associ&#233;s leur lemme et leur cat&#233;gorie syntaxique, une liste de 8 070 pr&#233;noms
(6 763 provenant de l'archive de CLR (CLR 1998)) et une liste de 211 587 noms de familles,
provenant aussi de CLR, une liste de 22 095 entreprises provenant du &quot;Wall Street Research
Network&quot; et 649 noms d'organisations obtenus &#224; partir d'une acquisition lexicale sur Internet
(Jacquemin 2000), deux listes d&#233;di&#233;es aux noms de lieux : l'une de 7 813 villes et l'autre de
1 144 pays issus de CLR, plus des listes constitu&#233;es manuellement sur les unit&#233;s physiques et
mon&#233;taires.
</p>
<p>4 Les termes et leurs variantes
La reconnaissance et le marquage dans les documents des termes caract&#233;risant la question et
de leurs variantes servent dans un premier temps &#224; r&#233;aliser une post-s&#233;lection des documents
apr&#232;s celle effectu&#233;e par le moteur de recherche. Elle sert dans un second temps  &#224; donner des
indices suppl&#233;mentaires au module d&#8217;appariement question/r&#233;ponse.
</p>
<p>4.1 Extraction des termes
</p>
<p>L&#8217;extraction automatique des termes &#224; partir des questions utilise une technique simple de
filtrage par des patrons de cat&#233;gories syntaxiques. Les questions sont d&#8217;abord segment&#233;es,
&#233;tiquet&#233;es et lemmatis&#233;es par le TreeTagger (Schmid 1999). Des patrons de cat&#233;gories
syntaxiques sont ensuite utilis&#233;s pour extraire des termes des questions. Ces patrons ne
diff&#232;rent de ceux d&#233;finis par Justeson et Katz (Justeson, Katz 1995) que par le fait que nous ne
prenons pas en compte les syntagmes pr&#233;positionnels postpos&#233;s. Les patrons utilis&#233;s sont
synth&#233;tis&#233;s par l&#8217;expression r&#233;guli&#232;re suivante1 :
</p>
<p>(((((JJ | NN | NP | VBG)) ? (JJ | NN | NP | VBG) (NP | NN))) | (VBD) | (NN) | (NP) | (CD))
La cha&#238;ne la plus longue est acquise en premier et les sous-cha&#238;nes ne peuvent &#234;tre extraites
que si elles ne commencent pas par le m&#234;me mot que la surcha&#238;ne. Par exemple, dans la
s&#233;quence nameNN ofIN theDT US NP helicopterNN pilotNN shotVBD downRP (nom du pilote
d'h&#233;licopt&#232;re am&#233;ricain abattu), les quatre termes suivants sont extraits : US helicopter pilot
(pilote d'h&#233;licopt&#232;re am&#233;ricain), helicopter pilot (pilote d'h&#233;licopt&#232;re), pilot (pilote) et shoot
(abattre).
</p>
<p>                                                 
</p>
<p>1
 JJ : adjectif, NN : nom, NP : nom propre, VBG et VBD : verbe au g&#233;rondif ou au participe pass&#233;, ? : indiquant au
</p>
<p>plus une occurrence de l&#8217;un des &#233;l&#233;ments entre parenth&#232;ses.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Entit&#233;s nomm&#233;es et variantes dans un syst&#232;me de question-r&#233;ponse
</p>
<p>4.2 Reconnaissance et marquage des variantes par FASTR
</p>
<p>Pour chaque question, nous ne retenons que les 200 premiers documents renvoy&#233;s par le
moteur de recherche2. D'apr&#232;s les tests3 que nous avons effectu&#233;s (Ferret et al. 2000), c'est le
nombre minimum de documents qui permet de conserver le maximum de documents
contenant la r&#233;ponse. Les performances des moteurs de recherche que nous avons utilis&#233; sont
tr&#232;s bonnes : ils conservent les documents pertinents, c'est &#224; dire ceux qui contiennent les
r&#233;ponses correctes, pour plus de 95% des questions. Une indexation automatique de ces
documents en fonction des termes de la question est ensuite faite par FASTR, un analyseur
transformationnel de surface pour la reconnaissance de variantes terminologiques. Les termes
extraits de la question sont transform&#233;s en r&#232;gles de grammaire et les mots simples qui les
composent sont stock&#233;s dans un lexique munis de liens morphologiques et s&#233;mantiques.
</p>
<p>La famille morphologique d'un mot simple m est l'ensemble M(m) des mots simples de la base
CELEX (CELEX 1998) qui ont la m&#234;me racine que m . Par exemple, la famille
morphologique du nom maker (fabricant) se compose des noms maker, make (marque) et
remake (remake), et des verbes to make (faire) et to remake (refaire).
La famille s&#233;mantique d'un mot simple m  est l'union S(m) des synsets de WordNet1.6
(Fellbaum 1998) auxquels ce mot m  appartient. Un synset est l'ensemble des mots qui
partagent un lien de synonymie sur une de leurs entr&#233;es s&#233;mantiques. Par exemple, la famille
s&#233;mantique de maker se compose de trois noms : maker, manufacturer (fabricant), shaper
(fa&#231;onneur) et la famille s&#233;mantique de car (voiture) est car, auto, automobile, machine et
motorcar (voiture &#224; moteur).
Les patrons de variations qui reposent sur des familles morphologiques et s&#233;mantiques sont
engendr&#233;s au moyen de m&#233;tar&#232;gles. Le patron suivant4, d&#233;nomm&#233; NtoVSemArg, extrait
l'occurrence making many automobiles (fabricant de nombreuses voitures) comme variante de
car maker (fabricant de voitures) :
</p>
<p>VM ('maker') RP ? PREP ? (DT (NN | NP) ? PREP) ? DT ? (JJ | NN | NP
| VBD | VBG) [0-3] NS ('car')
</p>
<p>o&#249; VM('maker') est tout verbe de la famille morphologique du nom maker et NS('car') tout
nom de la famille s&#233;mantique de car. En s'appuyant sur les familles morphologiques et
s&#233;mantiques et sur le jeu de m&#233;tar&#232;gles pour l'anglais, les occurrences suivantes sont extraites
comme des variantes du terme d'origine car maker (fabricant de voitures) :
</p>
<p>auto maker (fabricant d'autos), auto parts maker (fabricant de pi&#232;ces d&#233;tach&#233;es
automobiles), car manufacturer (fabricant de voitures), make autos (fabriquer des
voitures) et making many automobiles (fabricant beaucoup de voitures).
</p>
<p>5 Filtrage des documents
Le r&#233;sultat de l'indexation des documents par FASTR est une liste d'occurrences de termes et
de leurs variantes comprenant chacune un identificateur de document d, un identificateur de
termes &#8212; une paire t(q, i) compos&#233;e d'un num&#233;ro de question q et d'un indice unique i &#8212;, la
                                                 
</p>
<p>2
 Nous avons en particulier utilis&#233; Indexal (de Loupy et al. 1998), moteur de recherche qui nous a &#233;t&#233; fourni
</p>
<p>par Bertin Technologie
</p>
<p>3
 Ces tests ont &#233;t&#233; effectu&#233;s gr&#226;ce aux donn&#233;es fournies par le NIST apr&#232;s la campagne TREC8.
</p>
<p>4
 RP sont les particules, PREP les pr&#233;positions, DT les d&#233;terminants et V les verbes.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>O. Ferret, B. Grau, M. Hurault-Plantet, G. Illouz, C. Jacquemin
</p>
<p>variante reconnue et un identificateur de variation v (une m&#233;tar&#232;gle). Par exemple, l'index
suivant :
</p>
<p>LA092690-0038 t(131,1) making many automobiles NtoVSemArg
</p>
<p>signifie que l'occurrence making many automobiles du document n &#176; LA092690-0038 est
reconnue comme une variante du terme 1 (car maker) de la question q=131 au moyen de la
variation NtoVSemArg donn&#233;e en section 4.2.
</p>
<p>Chaque document s&#233;lectionn&#233; pour une question re&#231;oit un poids. La fonction de pond&#233;ration
Wq(d) (voir la formule (1)) repose sur une mesure de qualit&#233; des diff&#233;rentes familles de
variations d&#233;crite dans (Jacquemin 1999) : le poids (w(v)) des occurrences de termes sans
variation est 3, celui des variantes morphologiques et morpho-syntaxiques est 2 et celui des
variantes s&#233;mantiques et morpho-s&#233;mantico-syntaxiques est 1. Les noms propres repr&#233;sentent
des indices importants. Chaque terme t(q, i) re&#231;oit un poids P(t(q, i)) entre 0 et 1
correspondant &#224; sa proportion de noms propres. Par exemple, President Cleveland's wife (la
femme du pr&#233;sident Cleveland) a un poids de 2/3=0,67 selon ce crit&#232;re. Enfin, le dernier
facteur de fiabilit&#233; est le nombre de mots du terme, repr&#233;sent&#233; par la quantit&#233; |t(q, i)| dans la
formule (1). Ce facteur favorise donc les termes les plus longs. Le poids Wq(d) d'un document
d  par rapport &#224; une question q  est alors donn&#233; par la formule (1). Les produits des
pond&#233;rations de chaque terme identifi&#233; par FASTR sont somm&#233;s sur les index I(d) extraits du
document d et sont normalis&#233;s en fonction du nombre de termes |T(q)| dans la question q.
</p>
<p>  
</p>
<p>W (d)
( ) ( ( ( , ))) ( , )
</p>
<p>( )
q
</p>
<p>( ( , ), ) ( )
</p>
<p>=
</p>
<p>&#215; + &#215;
</p>
<p>&#8712;
</p>
<p>&#8721; w v P t q i t q iT qt q i v I d
1 2
</p>
<p> (1)
</p>
<p>Ce poids est calcul&#233; pour les 200 documents retenus par le moteur de recherche pour chaque
question. La distribution de ces poids permet de r&#233;aliser un filtrage plus s&#233;lectif des
documents. On observe principalement deux types de courbes de pond&#233;ration des documents
s&#233;lectionn&#233;s pour une question : les courbes avec un plateau et une chute brutale des valeurs
des poids au-del&#224; d'un certain rang (Figure 3.a) et les courbes avec des valeurs de poids en
d&#233;croissance progressive (Figure 3.b).
</p>
<p>0 010 1020 2030 3040 4050 5060 6070 7080 8090 90100 100
0 0
1
</p>
<p>12
</p>
<p>23
</p>
<p>3
4
</p>
<p>4
</p>
<p>5
</p>
<p>5
</p>
<p>6
</p>
<p>6
</p>
<p>7
</p>
<p>8
9
</p>
<p>10
</p>
<p>po
id
</p>
<p>s
</p>
<p>po
id
</p>
<p>s
</p>
<p>Question num&#233;ro 87 Question num&#233;ro 86
rang du documentrang du document
</p>
<p>(a) (b)
</p>
<p>Troncation de la liste ordonn&#233;e
</p>
<p>Figure 3 : Deux types de courbes de pond&#233;ration
</p>
<p>Lorsque le syst&#232;me reconna&#238;t une pente suffisamment forte, il s&#233;lectionne les documents
apparaissant avant la chute, sinon il s&#233;lectionne un nombre de documents fix&#233; a priori (nous
avons fix&#233; ce nombre &#224; 100). Dans le cas d'une courbe ayant un profil semblable &#224; celui de la
Figure 3.a, le seuil correspondant &#224; la chute du poids est d&#233;tect&#233; en analysant simultan&#233;ment
la pente de la courbe (la diff&#233;rence entre le poids d'un document et le poids du document
pr&#233;c&#233;dent) et la variation de second ordre (la diff&#233;rence entre la pente &#224; une &#233;tape et la pente &#224;
l'&#233;tape pr&#233;c&#233;dente). Dans le cas de la Figure 3.a, qui correspond &#224; la question 87 des donn&#233;es</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Entit&#233;s nomm&#233;es et variantes dans un syst&#232;me de question-r&#233;ponse
</p>
<p>de TREC8 Who followed Willy Brandt as chancellor of the Federal Republic of Germany?
(Qui a succ&#233;d&#233; &#224; Willy Brandt comme chancelier de la R&#233;publique F&#233;d&#233;rale d'Allemagne ?),
QALC a trouv&#233; un seuil &#233;gal &#224; 8 documents. En revanche la courbe de la Figure 3b ne
pr&#233;sente pas de seuil d&#233;tectable. Pour la question 86 Who won two gold medals in skiing in the
Olympic Games in Calgary? (Qui a gagn&#233; deux m&#233;dailles d'or au ski aux Jeux Olympiques de
Calgary ?), QALC a donc retenu 100 documents.
Nous avons &#233;valu&#233; l'efficacit&#233; du filtrage en appliquant notre cha&#238;ne de traitement sur les
donn&#233;es de TREC8, une fois avec le processus de filtrage, et une autre sans cette s&#233;lection.
Sans filtrage, les 200 documents issus du moteur de recherche &#233;taient donc conserv&#233;s pour
chacune des 200 questions. Nos tests ont donn&#233; un score de 0.463 dans le premier cas, et de
0.452 dans le second. Ces r&#233;sultats montrent que les performances ne diminuent pas quand on
traite moins de documents, car ce sont les documents les plus pertinents qui sont gard&#233;s. De
plus, les performances de notre syst&#232;me sont en g&#233;n&#233;ral meilleures pour les questions pour
lesquelles moins de 100 documents sont gard&#233;s.
</p>
<p>6 Appariement question/r&#233;ponse
Le principe g&#233;n&#233;ral de cet appariement consiste d&#8217;abord &#224; comparer la question consid&#233;r&#233;e
avec chaque phrase des documents retenus pour cette question, et &#224; conserver enfin les Na
phrases les plus similaires (Na est &#233;gal &#224; 5 pour la t&#226;che Question Answering de TREC). Pour
effectuer cette comparaison, QALC construit une m&#234;me repr&#233;sentation pour la question et
pour la phrase candidate &#224; la r&#233;ponse. Cette repr&#233;sentation consiste en un vecteur contenant
trois types d&#8217;&#233;l&#233;ments : des mots pleins, des termes, et des entit&#233;s nomm&#233;es. Chacun de ces
&#233;l&#233;ments est pond&#233;r&#233; en fonction de son importance par rapport aux autres.
</p>
<p>Les mots pleins sont essentiellement les adjectifs, les verbes et noms, sous leur forme
lemmatis&#233;e, telle qu&#8217;elle est donn&#233;e par le TreeTagger (Schmid 1999). Les mots de la phrase
qui ne sont pas pr&#233;sents dans la question re&#231;oivent un poids nul. Les autres se voient attribuer
un poids, de type tf.idf, en rapport avec leur fr&#233;quence dans un corpus de r&#233;f&#233;rence. Les
termes proviennent de l&#8217;extracteur de termes d&#233;crit au paragraphe 4.1. Les termes de la
question sont affect&#233;s d&#8217;un poids fixe. Pour la phrase, les termes consid&#233;r&#233;s sont les variantes
des termes de la question reconnues par FASTR dont le poids est celui qui permet de pond&#233;rer
les documents et qui exprime la distance entre la variante et le terme correspondant (voir
paragraphe 5). Les entit&#233;s nomm&#233;es sont, pour la question, celles qui correspondent au type
attendu de la r&#233;ponse, et pour la phrase, celles qui ont &#233;t&#233; reconnues dans la phrase par le
module de reconnaissance des entit&#233;s nomm&#233;es. Les entit&#233;s nomm&#233;es correspondant au type
attendu de la r&#233;ponse re&#231;oivent un poids fixe.
</p>
<p>Finalement, la comparaison entre la question et la phrase est r&#233;alis&#233;e par le calcul de la
similarit&#233; entre les vecteurs qui les repr&#233;sentent suivant la mesure suivante :
</p>
<p>&#229;
</p>
<p>&#229;
</p>
<p>=
</p>
<p>j j
</p>
<p>i i
</p>
<p>dq wq
</p>
<p>wd
VVsim ),( (2)
</p>
<p>o&#249; wqj est le poids d&#8217;un &#233;l&#233;ment du vecteur Vq repr&#142;sentant la question et wdi est le poids d&#8217;un
&#233;l&#233;ment du vecteur Vd repr&#142;sentant la phrase. Le poids des termes et entit&#233;s nomm&#233;es est
mod&#233;r&#233; par un coeficient afin de rester inf&#233;rieur au poids des mots de la question. Lorsque la
valeur de similarit&#233; est la m&#234;me pour deux phrases diff&#233;rentes, QALC s&#233;lectionne la phrase
o&#249; les mots pleins de la question sont le moins dispers&#233;s.
</p>
<p>Nous allons montrer sur l&#8217;exemple de la question What two US biochemists won the Nobel
Prize in medicine in 1992?, qui a &#142;t&#142; propos&#142;e &#136; TREC8, comment chaque phrase est &#142;valu&#142;e.
La question est d&#213;abord transform&#142;e en un vecteur, o&#249; &lt;PERSON&gt; est le type attendu de la</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>O. Ferret, B. Grau, M. Hurault-Plantet, G. Illouz, C. Jacquemin
</p>
<p>r&#233;ponse, 16.01 est l&#8217;identificateur du terme US biochemist et 16.04 est l&#8217;identificateur du
terme Nobel Prize5 :
</p>
<p>two (1.0) us (1.0) biochemist (0.9) nobel (1.0)
prize (0,6) medicine (0,5) win (0,3) 1992 (1.0)
&lt;PERSON&gt; (0.5) 16.01 (0.5) 16.04 (0.5)
</p>
<p>Le m&#234;me type de vecteur est construit pour chaque phrase du document FT924-14045,
s&#233;lectionn&#233; pour cette question. Par exemple la phrase &#233;tiquet&#233;e par le module des entit&#233;s
nomm&#233;es : &lt;NUMBER&gt; Two &lt;/NUMBER&gt; US biochemists, &lt;PERSON&gt; Edwin Krebs
&lt;/PERSON&gt; and &lt;CITY&gt; Edmond &lt;/CITY&gt; Fischer, jointly won the &lt;NUMBER&gt; 1992
&lt;/NUMBER&gt; Nobel Medicine Prize for work that could advance the search for an anti-
cancer drug donne le vecteur suivant :
</p>
<p>two (1.0) us (1.0) biochemist (0.9) nobel (1.0)
prize (0,6) medicine (0,5) win (0,3) 1992 (1.0)
edwin (0.0) krebs (0.0) edmond (0.0) fischer (0.0)
work (0.0) advance (0.0) search (0.0) anti-cancer (0.0)
</p>
<p>jointly (0.0) drug (0.0) &lt;PERSON&gt; (0.5) &lt;NUMBER&gt; (0.0)
&lt;CITY&gt; (0.0) 16.01 (0.5) 16.04 (0.3)
</p>
<p>o&#249; le poids 0.0 est donn&#233; aux &#233;l&#233;ments qui ne font pas partie du vecteur repr&#233;sentant la
question. Le terme US biochemist est trouv&#233; sans variation et Nobel Prize appara&#238;t sous la
forme de la variante syntaxique Nobel Medicine Prize. Finalement, en appliquant (2), on
trouve une mesure de similarit&#233; de 0.974 entre les deux vecteurs.
</p>
<p>Le module d&#8217;appariement consid&#232;re la phrase en tant qu&#8217;unit&#233; de r&#233;ponse de base mais,
lorsque l&#8217;on souhaite une r&#233;ponse plus concise, QALC s&#8217;appuie sur un ensemble
d&#8217;heuristiques simples pour r&#233;duire la taille des phrases d&#233;passant la limite fix&#233;e. Lorsqu&#8217;une
entit&#233; nomm&#233;e correspondant au type attendu de la r&#233;ponse, ou d&#8217;un type proche, a &#233;t&#233;
trouv&#233;e, QALC s&#233;lectionne la partie de la phrase entourant cette entit&#233; nomm&#233;e. Dans le cas
contraire, ou dans le cas o&#249; le type attendu de la r&#233;ponse n&#8217;a pu &#234;tre d&#233;termin&#233;, il extrait une
partie de la phrase contigu&#235; &#224; celle contenant les mots de la question. On suppose ainsi que la
phrase contenant la r&#233;ponse poss&#232;de une structure comparable &#224; ce que serait la forme
affirmative de la question pos&#233;e.
</p>
<p>7 R&#233;sultats et discussion
Dans le cadre de TREC9, les r&#233;sultats de QALC ont &#233;t&#233; &#233;valu&#233;s dans trois conditions
diff&#233;rentes, les variations de l&#8217;une &#224; l&#8217;autre concernant le moteur de recherche utilis&#233; et la
taille de la r&#233;ponse (250 ou 50 caract&#232;res). Le meilleur de ces tests a obtenu un score de 0,407
avec 375 r&#233;ponses trouv&#233;es sur 682, pour des r&#233;ponses sur 250 caract&#232;res. Le calcul de ce
score tient compte du rang de classement (de 1 &#224; 5) de la r&#233;ponse trouv&#233;e. Ce score nous a
plac&#233; en 6i&#232;me position sur 28 participants. Le premier (Harabagiu et al, 2000) a obtenu un
score de 0,760, le deuxi&#232;me (Kwok et al, 2000) un score de 0,464, et les trois suivants
respectivement des scores de 0,460, 0,457 (Ittycheriah et al, 2000) et 0,425.
La conf&#233;rence d&#8217;&#233;valuation TREC offre une r&#233;f&#233;rence int&#233;ressante pour mesurer l&#8217;efficacit&#233;
des m&#233;thodes utilis&#233;es par les diff&#233;rents syst&#232;mes de question-r&#233;ponse. L&#8217;architecture de base
g&#233;n&#233;ralement adopt&#233;e par les syst&#232;mes participants est conforme &#224; celle de notre syst&#232;me
QALC, avec &#233;ventuellement quelques variantes.
                                                 
</p>
<p>5
 Nous ne retenons ici que les expressions les plus longues des diff&#233;rents termes</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Entit&#233;s nomm&#233;es et variantes dans un syst&#232;me de question-r&#233;ponse
</p>
<p>Le typage de la r&#233;ponse attendue est &#233;videmment une fonctionnalit&#233; indispensable &#224; un
syst&#232;me de question-r&#233;ponse, particuli&#232;rement lorsqu&#8217;il s&#8217;agit de donner une r&#233;ponse courte
(50 caract&#232;res). Parmi les questions pos&#233;es &#224; TREC, certaines attendent en r&#233;ponse une entit&#233;
nomm&#233;e telle qu&#8217;une date, un nom de personne ou un nom d&#8217;organisation par exemple. Dans
ce cas, le typage de la r&#233;ponse est simple m&#234;me si son exploitation n&#233;cessite un bon syst&#232;me
de reconnaissance des entit&#233;s nomm&#233;es et si le nombre de cat&#233;gories de types peut &#234;tre
augment&#233; de mani&#232;re &#224; raffiner le typage. En revanche, lorsque la r&#233;ponse attendue est
constitu&#233;e d&#8217;un nom commun ou d&#8217;une phrase, son typage, plus complexe, est rarement
r&#233;alis&#233;. Certains syst&#232;mes, comme le syst&#232;me FALCON (Harabagiu et al, 2000), utilisent les
hi&#233;rarchies des classes de mots dans WordNet pour typer les r&#233;ponses. Pour sa part, le
syst&#232;me d&#233;velopp&#233; par (Ittycheriah et al, 2000) se fonde sur un mod&#232;le de l&#8217;entropie
maximum pour la classification des types de r&#233;ponse. Sur les 682 questions de TREC9, 57,5%
ont &#233;t&#233; analys&#233;es par QALC comme &#233;tant des questions &#224; entit&#233; nomm&#233;e, les autres n&#8217;ont pas
&#233;t&#233; typ&#233;es. Parmi les r&#233;ponses correctes de notre meilleur test, 62,7% r&#233;pondent &#224; des
questions &#224; entit&#233; nomm&#233;e. Par ailleurs, le test que nous avons fait pour des r&#233;ponses plus
courtes donne 84% de r&#233;ponses poss&#233;dant une entit&#233; nomm&#233;e parmi les bonnes r&#233;ponses.
Typer la r&#233;ponse permet donc de mieux cibler la portion de phrase qui peut la contenir.
</p>
<p>Tous les syst&#232;mes ayant particip&#233; &#224; TREC9 utilisent un moteur de recherche pour effectuer la
s&#233;lection d&#8217;un sous-ensemble de documents dans la base d&#8217;environ un million de documents
mise &#224; disposition par le NIST. Dans le syst&#232;me QALC, nous conservons dans son int&#233;gralit&#233;
chaque document retrouv&#233; par le moteur. Mais d&#8217;autres syt&#232;mes s&#233;lectionnent le ou les
paragraphes pertinents de chaque document retrouv&#233;. Comme dans QALC, la recherche des
meilleures r&#233;ponses est fond&#233;e sur un appariement entre question et r&#233;ponse reposant sur la
comparaison des mots des questions avec ceux des phrases s&#233;lectionn&#233;es et tenant compte du
type attendu de la r&#233;ponse et des entit&#233;s nomm&#233;es. Les crit&#232;res retenus pour effectuer
l&#8217;appariement peuvent varier d&#8217;un syst&#232;me &#224; l&#8217;autre. Kwok et al (Kwok et al, 2000) par
exemple utilisent entre autres un dictionnaire de synonymes qu&#8217;ils ont extrait manuellement
de WordNet. Le syst&#232;me FALCON, quant &#224; lui, (Harabagiu et al, 2000) utilise une approche
s&#233;mantique pour r&#233;aliser cet appariement : une unification est recherch&#233;e entre la
repr&#233;sentation s&#233;mantique de la question et les repr&#233;sentations s&#233;mantiques des paragraphes
s&#233;lectionn&#233;s. C&#8217;est &#233;galement le seul syst&#232;me &#224; effectuer une justification de ses r&#233;ponses.
</p>
<p>8 Conclusion
Un syst&#232;me de question-r&#233;ponse doit trouver la r&#233;ponse &#224; une question pr&#233;cise, dans un temps
suffisamment court pour &#234;tre compatible avec une &#233;ventuelle utilisation interactive. Cette
r&#233;ponse &#233;tant recherch&#233;e dans une grande masse de documents, il est tentant d&#8217;appliquer des
m&#233;thodes essentiellement num&#233;riques pour la trouver. N&#233;anmoins les exp&#233;riences montrent
que l&#8217;ajout de raisonnements fond&#233;s sur des connaissances s&#233;mantiques et pragmatiques est
n&#233;cessaire si on veut obtenir, &#224; terme, un syst&#232;me r&#233;ellement efficace. En effet, le syst&#232;me qui
a obtenu les meilleurs r&#233;sultats &#224; TREC9 est aussi celui qui utilise le plus largement les
techniques d&#8217;analyse syntaxique et s&#233;mantique (Harabagiu et al, 2000). Les futures
orientations de la t&#226;che question-r&#233;ponse de la conf&#233;rence TREC vont d&#8217;ailleurs dans ce sens.
En effet, &#224; un horizon de 5 ans, les organisateurs pr&#233;voient des am&#233;liorations &#224; la fois sur la
rapidit&#233; de la r&#233;ponse, la v&#233;rification de sa justesse, la possibilit&#233; de fusionner plusieurs
r&#233;ponses pour obtenir une r&#233;ponse compl&#232;te, et enfin des possibilit&#233;s de dialogue permettant &#224;
l&#8217;utilisateur de pr&#233;ciser sa demande. Les futurs syst&#232;mes devront aussi pouvoir d&#233;cider si la
r&#233;ponse se trouve ou non dans le corpus de recherche. De plus, ils devront &#234;tre capable de
d&#233;duire la r&#233;ponse compl&#232;te de r&#233;ponses fragmentaires dispers&#233;es dans diff&#233;rents documents.
Toutes ces am&#233;liorations ne pourront se faire sans une int&#233;gration plus importante des
m&#233;thodes propres au traitement s&#233;mantique de la langue.
</p>
<p>Les am&#233;liorations que nous voulons apporter &#224; notre syst&#232;me rel&#232;vent donc essentiellement
d&#8217;une approche s&#233;mantique et pragmatique. Ainsi, la base de connaissances WordNet, que</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>O. Ferret, B. Grau, M. Hurault-Plantet, G. Illouz, C. Jacquemin
</p>
<p>nous utilisons d&#233;j&#224; pour trouver les variantes s&#233;mantiques d&#8217;un mot, pourra aussi &#234;tre
exploit&#233;e pour une classification plus fine des types de r&#233;ponses. Nous utiliserons aussi une
analyse syntaxico-s&#233;mantique robuste pour construire les repr&#233;sentations s&#233;mantiques de la
question et de l&#8217;ensemble des r&#233;ponses candidates, afin de s&#233;lectionner les r&#233;ponses &#224; la fois
sur les termes de la question et sur les liens s&#233;mantiques que ces termes ont entre eux.
</p>
<p>R&#233;f&#233;rences
CELEX, 1998, http://www.ldc.upenn.edu/readme_files/celex.readme.html, UPenns, Eds.,
Actes Consortium for Lexical Resources, (1998)
CLR, 1998, http://crl.nmsu.edu/cgi-bin/Tools/CLR/clrcat#D3, NMSUs, Eds., Actes
Consortium for Lexical Resources, New Mexico (1998)
Fellbaum C., (1998) WordNet: An Electronic Lexical Database, Cambridge, MA, MIT Press.
Ferret O., Grau B., Hurault-Plantet M., Illouz G., Jacquemin C. (2000), QALC &#8212; the
Question-Answering system of LIMSI-CNRS, pre-proceedings of TREC9, NIST.
Grishman R., Sundheim B., (1995), Design of the MUC-6 evaluation, Actes de MUC-6,
NISTs, Eds., Morgan Kauffmann Publisher, Columbia, MD.
</p>
<p>Harabagiu S., Pasca M., Maiorano J., (2000), Experiments with Open-Domain Textual
Question Answering, Actes de Coling'2000, Saarbrucken, Germany.
Ittycheriah A., Franz M., Zhu W-J., Ratnaparkhi A., (2000), IBM's statistical Question
Answering System, , Actes pr&#233;liminaires de TREC9, Gaithersburg, MD, NIST Eds, 60-65.
</p>
<p>Jacquemin C., (1999), Syntagmatic and paradigmatic representations of term variation, Actes
de ACL'99, 341-348.
</p>
<p>Jacquemin C., Bush C., Fouille du Web pour la collecte d'entit&#233;s nomm&#233;es, Actes de
TALN 2000, Lausanne (2000), 187-196.
Justeson J., Katz S., (1995), Technical terminology: some linguistic properties and an
algorithm for identification in texte, Natural Language Engineering , Vol 1, pp. 9-27.
</p>
<p>Kwok K.L., Grunfeld L., Dinstl N., Chan M., (2000), TREC9 Cross Language, Web and
Question-Answering Track experiments using PIRCS, Actes pr&#233;liminaires de TREC9,
Gaithersburg, MD, NIST Eds., 26-35.
</p>
<p>Lehnert W., (1977), Human and computational question answering, Cognitive Science , 1,
p. 47-63.
</p>
<p>de Loupy C., Bellot P., El-B&#232;ze M., Marteau P.-F. (1998). Query Expansion and
Classification of Retrieved Documents, TREC7 , p.382-389.
</p>
<p>Moll&#224; A. D. et al., (2000), EXTRANS, An Answer Extraction System, Traitement
automatique des langues , 41, p. 495-522.
</p>
<p>Schmid H., (1999), Improvements in Part-of-Speech Tagging with an Application To
German, Natural Language Processing Using Very Large Corpora, Dordrecht, S. Armstrong,
K. W. Chuch, P. Isabelle, E. Tzoukermann, D. Yarowski, Eds., Kluwer Academic Publisher.</p>

</div></div>
</body></html>