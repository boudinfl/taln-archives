TALN 2001, Tours, 2-5 juillet 2001

Utilisation des entités nommées et des variantes terminologiques
dans un systéme de question-réponse

Olivier Ferret (1), Brigitte Grau (1), Martine Hurault—Plantet (1),
Gabriel Illouz (1) et Christian Jacquemin (1)

(1) LIlVlSI—CNRS, BP 133, 91403 Orsay cedex
{ferret, bg, mhp, gabrieli, jacquemin}@1imsi.fr

Résumé — Abstract

Nous présentons dans cet article le systeme QALC qui a participé a la tache Question
Answering de la conférence d’évaluation TREC. Ce systeme repose sur un ensemble de
modules de Traitement Automatique des Langues (TAL) intervenant essentiellement en aval
d’un moteur de recherche opérant sur un vaste ensemble de documents : typage des questions,
reconnaissance des entités nommées, extraction et reconnaissance de termes, simples et
complexes, et de leurs variantes. Ces traitements permettent soit de mieux sélectionner ces
documents, soit de décider quelles sont les phrases susceptibles de contenir la réponse a une
question.

We developed a system, QALC, that participated to the Question Answering track of the
TREC evaluation conference. QALC exploits an analysis of documents, selected by a search
engine, based on the search for multi-words terms and their variations both to select a
minimal number of documents to be processed and to give indices for comparing question and
sentence representations. This comparison also takes advantage of a question analysis module
and a recognition of numeric and named entities in the documents.

Mots-clés

Systeme de question-réponse, entité nommée, variante terminologique, recherche
d'inforInation

1 Introduction

L'introduction de la tache "Question Answering" lors de la conférence d’évaluation TREC8
(Text REtrieval Conference), en 1999, est révélatrice du besoin de développer des systemes
capables d'apporter l'information attendue par un utilisateur, celle qui répond le mieux a sa
requéte. C'est ainsi que les nouveaux systemes de recherche d’information ne doivent plus
s'arréter a la seule proposition de documents, mais doivent en extraire les parties pertinentes,
soit en proposant la réponse, s’il s'agit d'une question d’ordre factuel, ou un résumé si la
requéte est d'ordre thématique. Dans un systeme de question-réponse, la recherche de
documents pertinents est complétée par la sélection de courts extraits de texte contenant la
réponse a la question posée. Cette sélection est opérée par un ensemble de modules de TAL, a
la fois de nature syntaxique et sémantique, devant posséder une grande couverture
linguistique et s’appliquer indépendamment du domaine abordé. La problématique "question-
réponse" a été introduite des la ﬁn des années 70 lorsque Lehnert (1977) a jeté les bases d’un

0. Ferret, B. Grau, M. Hurault-Plantet, G. Illouz, C. Jacquemin

systeme de question-réponse avec le systeme QUALM. Plus récemment, Molla et al (2000)
ont proposé EXTRANS, un systeme de question-réponse sur le manuel Unix. Meme dans ce
domaine limité, les auteurs associent une approche fondée sur une analyse syntaxique et
sémantique des questions et du manuel a une approche fondée sur des mots-clés de maniere a
rendre leur systeme plus robuste.

Dans cet article, nous présentons notre systeme de question-réponse QALC, concu pour traiter
des questions factuelles ou encyclopédiques portant sur n’importe quel domaine. QALC a
participé aux évaluations TREC8 et TREC9. La campagne 1999 consistait a proposer
5 réponses ordonnées, a trouver dans un corpus de 500 000 documents environ, pour chacune
des 200 questions posées. En 2000, la meme tache s’appliquait a environ 700 questions et
1 million de documents. Chaque réponse proposée devait étre un tres court extrait (250
caracteres maximum) d’un document du corpus. Les documents sont des articles de journaux
américains, tels que le Wall Street Journal, le Los Angeles Times, etc.

Apres avoir présenté l'architecture générale de QALC, nous détaillerons ses différents
modules : reconnaissance des entités nommées, des termes et de leurs variantes dans les
documents ainsi que l’utilisation de ces informations dans la sélection des documents
pertinents et dans le module d’appariement entre une question et les phrases candidates a la
réponse. La présentation des résultats obtenus lors de la demiere évaluation TREC sera suivie
d’une discussion sur des travaux connexes, puis nous conclurons sur les évolutions envisagées
pour notre systeme.

2 Architecture du systéme

Les composants TAL du systeme QALC (cf. Figure 1) visent soit a déduire le type attendu de
la réponse afin de sélectionner la réponse précise a l’intérieur d’un document, soit a enrichir la
description des documents sélectionnés afin que la recherche de la réponse s'appuie sur des
indices allant au dela des simples mots des documents.

Questions Corpus
p

Analyse des Motcur dc

questions recherche

Termes Documents séﬁtionnés

/

|Ré-indexation et sélection des documents (FASTR) ‘

Sous-ensemble del documents pondérés

| Reconnaissance des entités nommées |

Types des questions : Phrases armotées : types d’entité nommée et Vocabulaire &
type d’entité nommée indexation par lsfs termes et variantes fréquences
L p.

Appariement Question/Phrase

Séquence ordonnée de 250 et 50
caracteres

Figure 1. Architecture du systeme QALC

L'analyse des questions est réalisée par un analyseur partiel dédié qui attribue aux questions
des catégories correspondant aux types d'entités nommées pouvant répondre a la question. La
sélection d’un sous-ensemble de documents pertinents repose sur la reconnaissance des
termes de la question ou de leurs variantes dans les documents sélectionnés par un moteur de

Entités nommées et variantes dans un systéme de question-réponse

recherche classique. Cette reconnaissance est effectuée par FASTR (J acquemin, 1999) sur la
base des termes extraits de la question. Cette sélection revét toute son importance lorsque le
systeme applique les processus ultérieurs, a savoir la reconnaissance des entités nommées
telles que les personnes, organisations, lieux et valeurs numériques, et la comparaison entre
phrase et question, processus fortement consommateurs de temps de traitement.

Le dernier module, qui propose un ensemble limité de réponses a chaque question, met en
oeuvre un calcul de similarité entre une question, représentée par un vecteur contenant ses
mots pleins lemmatisés, ses termes et le type attendu de sa réponse, et les phrases des
documents retenus, représentées de maniere analogue. Les réponses données par QALC sont
des phrases, unités les plus significatives du point de vue de l’utilisateur final, mais peuvent
étre rendues plus concises grace a un ensemble d’heuristiques permettant d’extraire de la
phrase une réponse précise.

3 Les Entités Nommées

QALC utilise les entités nommées a la fois pour spécifier le type de la réponse attendue et
pour détecter ensuite les entités de meme type dans les documents afin d'aider a localiser la
réponse.

3.1 Détermination du type de la réponse

Connaitre le type de la réponse a une question permet au module d’appariement de
privilégier, parmi plusieurs phrases candidates a la réponse, celles qui contiennent un groupe
de mots qui correspond a ce type. L’analyse d’une question conduit a lui attribuer une
étiquette s’identifiant au type de l’entité nommée qu’elle admet comme réponse. Par
exemple :

Question 2 How many people live in the Falklands ? —> type = NUMBER
(Combien de personnes habitent les Falklands ?)
Réponse 2 Falkland population of <b_numex_TYPE=NUMBER> 2,100 <e_numex> is
concentrated 
(La population des Falklands, de 2 I00 habitants, est concentrée )

Les étiquettes utilisées sont présentées Figure 2. Les étiquettes typant les réponses
correspondent aux feuilles de l’arbre, auxquelles s’ajoutent les étiquettes n0mPr0pre et
nombre et sont similaires a ceux adoptés dans la tache MUC (Grishman, Sundheim, 1995).
Les étiquettes sont organisées en une hiérarchie afin d’avoir plus de souplesse dans la
recherche de la réponse.

    
   

ExpressionTemps

I LieuI I Personne I IOrganisatiorI I Age I IDateI IPériodeI I Heure I IPhysique I I LongueurI IPoidsI I Vo1umeI I Financier I

Ville Endroit

Figure 2 : Hiérarchie de types de réponses et de catégories sémantiques

L’analyse des questions est effectuée par un analyseur dédié fondé sur le déclenchement de
regles décrivant différents types de questions. Les indices utilisés dans les regles pour décider
de l’attribution d’une étiquette sont d’ordre lexical, avec la détection de mots spécifiques,

0. Ferret, B. Grau, M. Hurault-Plantet, G. Illouz, C. Jacquemin

d’ordre syntaxique et semantique. Les categories semantiques ont ete constituees
manuellement, et permettent d’etiqueter la tres grande maj orite des questions repondant aux
types prevus, soit environ 60% des 700 questions de TREC9. Une amelioration prevue
consiste a utiliser WordNet pour completer les categories semantiques.

3.2 Reconnaissance des entités nommées

Les entites nommees sont marquees dans les documents par une balise dont le type
correspond aux types de reponses presentes a la Figure 2. Les types retenus sont reconnus par
des regles grace a l’exploitation conjointe de deux sources d’information :

0 des lexiques generaux permettant de trouver des traits syntaxiques et semantiques associes
aux mots simples en complement de traits lexicaux, et
0 des dictionnaires d'entites nommees.

Les ressources utilisees sont CELEX (CELEX 1998), un lexique de 160 595 mots ﬂechis
auxquels sont associes leur lemme et leur categorie syntaxique, une liste de 8 070 prenoms
(6 763 provenant de l'archive de CLR (CLR 1998)) et une liste de 211 587 noms de familles,
provenant aussi de CLR, une liste de 22 095 entreprises provenant du "Wall Street Research
Network" et 649 noms d'organisations obtenus a partir d'une acquisition lexicale sur Internet
(J acquemin 2000), deux listes dediees aux noms de lieux : l'une de 7 813 villes et l'autre de
1 144 pays issus de CLR, plus des listes constituees manuellement sur les unites physiques et
monetaires.

4 Les termes et leurs variantes

La reconnaissance et le marquage dans les documents des termes caracterisant la question et
de leurs variantes servent dans un premier temps a realiser une post-selection des documents
apres celle effectuee par le moteur de recherche. Elle sert dans un second temps a donner des
indices supplementaires au module d’appariement question/reponse.

4.1 Extraction des termes

L’extraction automatique des termes a partir des questions utilise une technique simple de
filtrage par des patrons de categories syntaxiques. Les questions sont d’abord segmentees,
etiquetees et lemmatisees par le TreeTagger (Schmid 1999). Des patrons de categories
syntaxiques sont ensuite utilises pour extraire des termes des questions. Ces patrons ne
different de ceux deﬁnis par Justeson et Katz (Justeson, Katz 1995) que par le fait que nous ne
prenons pas en compte les syntagmes prepositionnels postposes. Les patrons utilises sont
synthetises par l’expression reguliere suivante :

(((((JJ I NN I NP I VBG)) ? (JJ I NN I NP I VBG) (NP I NN))) I (VBD) I (NN) I (NP) I (CD))

La chaine la plus longue est acquise en premier et les sous-chaines ne peuvent etre extraites
que si elles ne commencent pas par le meme mot que la surchaine. Par exemple, dans la
sequence nameNN of,N them USNP helicopterNN pilotNN shotVBD downm, (nom du pilote
d'helicoptere americain abattu), les quatre termes suivants sont extraits : US helicopter pilot
(pilote d'helicoptere americain), helicopter pilot (pilote d'helicoptere), pilot (pilote) et shoot
(abattre).

1 JJ : adjectif, NN : nom, NP : nom propre, VBG et VBD : Verbe au gerondif ou au participe passe, ‘.7 : indiquant au
plus une occurrence de l’un des elements entre parentheses.

Entités nommées et variantes dans un systeme de question-re’ponse

4.2 Reconnaissance et marquage des variantes par FASTR

Pour chaque question, nous ne retenons que les 200 premiers documents renvoyés par le
moteur de recherchez. D'apres les tests3 que nous avons effectués (Ferret et al. 2000), c'est le
nombre minimum de documents qui permet de conserver le maximum de documents
contenant la réponse. Les performances des moteurs de recherche que nous avons utilisé sont
tres bonnes : ils conservent les documents pertinents, c'est a dire ceux qui contiennent les
réponses correctes, pour plus de 95% des questions. Une indexation automatique de ces
documents en fonction des termes de la question est ensuite faite par FASTR, un analyseur
transformationnel de surface pour la reconnaissance de variantes terminologiques. Les termes
extraits de la question sont transformés en regles de grammaire et les mots simples qui les
composent sont stockés dans un lexique munis de liens morphologiques et sémantiques.

La famille morphologique d'un mot simple m est l'ensemble M(m) des mots simples de la base
CELEX (CELEX 1998) qui ont la méme racine que m. Par exemple, la famille
morphologique du nom maker (fabricant) se compose des noms maker, make (marque) et
remake (remake), et des verbes to make (faire) et to remake (refaire).

La famille sémantique d'un mot simple m est l'union S(m) des synsets de WordNet1.6
(Fellbaum 1998) auxquels ce mot m appartient. Un synset est l'ensemble des mots qui
partagent un lien de synonymie sur une de leurs entrées sémantiques. Par exemple, la famille
sémantique de maker se compose de trois noms : maker, manufacturer (fabricant), shaper
(faconneur) et la famille sémantique de car (voiture) est car, auto, automobile, machine et
motorcar (voiture a moteur).

Les patrons de variations qui reposent sur des familles morphologiques et sémantiques sont
engendrés au moyen de métaregles. Le patron suivant4, dénommé NtoVSemArg, extrait
l'occurrence making many automobiles (fabricant de nombreuses voitures) comme variante de
car maker (fabricant de voitures) :

VM (‘maker’) RP ? PREP ? (DT (NN I NP) ? PREP) '2 DT '2 (JJ I NN I NP
I VBD I VBG) [°-31 NS (‘car’)

ou VM('maker') est tout verbe de la famille morphologique du nom maker et NS('car') tout
nom de la famille sémantique de car. En s'appuyant sur les familles morphologiques et
sémantiques et sur le jeu de métaregles pour l'anglais, les occurrences suivantes sont extraites
comme des variantes du terme d'origine car maker (fabricant de voitures) :

auto maker (fabricant d'autos), auto parts maker (fabricant de pieces détachées
automobiles), car manufacturer (fabricant de voitures), make autos (fabriquer des
voitures) et making many automobiles (fabricant beaucoup de voitures).

5 Filtrage des documents

Le résultat de l'indexation des documents par FASTR est une liste d'occurrences de termes et
de leurs variantes comprenant chacune un identificateur de document d, un identificateur de
termes — une paire t(q, i) composée d'un numéro de question q et d'un indice unique i—, la

2 Nous avons en particulier utilisé Indexal (de Loupy et al. 1998), moteur de recherche qui nous a été fourni

par Bertin Technologie
Ces tests ont été effectués grace aux données foumies par le NIST apres la campagne TREC8.

4 RP sont les particules, PREP les prépositions, DT les déterminants et V les verbes.

0. Ferret, B. Grau, M. Hurault-Plantet, G. Illouz, C. Jacquemin

variante reconnue et un identificateur de variation v (une métaregle). Par exemple, l'index
suivant :

LA092690-0038 t(131,1) making many automobiles NtoVSemArg

signifie que l'occurrence making many automobiles du document n°LA092690-0038 est
reconnue comme une variante du terme 1 (car maker) de la question q=131 au moyen de la
variation NtoVSemArg donnée en section 4.2.

Chaque document sélectionne pour une question recoit un poids. La fonction de pondération
Wq(d) (voir la formule (1)) repose sur une mesure de qualité des différentes familles de
variations décrite dans (Jacquemin 1999) : le poids (w(v)) des occurrences de termes sans
variation est 3, celui des variantes morphologiques et morpho-syntaxiques est 2 et celui des
variantes sémantiques et morpho-sémantico-syntaxiques est 1. Les noms propres représentent
des indices importants. Chaque terme t(q, i) recoit un poids P(t(q, i)) entre 0 et 1
correspondant a sa proportion de noms propres. Par exemple, President Cleveland ’s wife (la
femme du président Cleveland) a un poids de 2/3=0,67 selon ce critere. Enfin, le dernier
facteur de fiabilité est le nombre de mots du terme, représenté par la quantité |t(q, i)| dans la
formule (1). Ce facteur favorise donc les termes les plus longs. Le poids Wq(d) d'un document
d par rapport a une question q est alors donné par la formule (1). Les produits des
pondérations de chaque terme identifié par FASTR sont sommés sur les index I(d) extraits du
document d et sont normalisés en fonction du nombre de termes |T(q)| dans la question (1.

w(v>><(1+2P(t(q,i>>>><|t(q,i>|

Wq(d) =
(t(q.i>.v>eI(d> |T(q)|

(1)

Ce poids est calculé pour les 200 documents retenus par le moteur de recherche pour chaque
question. La distribution de ces poids permet de réaliser un filtrage plus sélectif des
documents. On observe principalement deux types de courbes de pondération des documents
sélectionnés pour une question : les courbes avec un plateau et une chute brutale des valeurs
des poids au-dela d'un certain rang (Figure 3.a) et les courbes avec des valeurs de poids en
décroissance progressive (Figure 3.b).

    

 

1U 0
9 - H
8 / Troncation de la liste ordonnée -_ 5  X F
7 _ _
5 6 — — :§4 _
8. 5 _ _ 83 _
4 _ _
3 — — 2 ’
2 — — 1 
1 — — _
0 - - - - - - - - - - 0 - - - - - - - - - -
0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100
rang du document rang du document
(a) Ollqsﬁnn numérn 87 lb] ( h_]§s1;iQn n_]_]_mQm’ Sﬂ

Figure 3 : Deux types de courbes de pondération

Lorsque le systeme reconnait une pente suffisamment forte, il sélectionne les documents
apparaissant avant la chute, sinon il sélectionne un nombre de documents fixé a priori (nous
avons fixé ce nombre a 100). Dans le cas d'une courbe ayant un profil semblable a celui de la
Figure 3.a, le seuil correspondant a la chute du poids est détecté en analysant simultanément
la pente de la courbe (la différence entre le poids d'un document et le poids du document
précédent) et la variation de second ordre (la différence entre la pente a une étape et la pente a
l'étape précédente). Dans le cas de la Figure 3.a, qui correspond a la question 87 des données

Entités nommées et variantes dans un systeme de question-re’ponse

de TREC8 Who followed Willy Brandt as chancellor of the Federal Republic of Germany?
(Qui a succédé a Willy Brandt comme chancelier de la République Fédérale d'Allemagne ?),
QALC a trouvé un seuil égal a 8 documents. En revanche la courbe de la Figure 3b ne
présente pas de seuil détectable. Pour la question 86 Who won two gold medals in skiing in the
Olympic Games in Calgary? (Qui a gagné deux médailles d'or au ski aux Jeux Olympiques de
Calgary ?), QALC a donc retenu 100 documents.

Nous avons évalué l'efficacité du filtrage en appliquant notre chaine de traitement sur les
données de TREC8, une fois avec le processus de filtrage, et une autre sans cette sélection.
Sans filtrage, les 200 documents issus du moteur de recherche étaient donc conservés pour
chacune des 200 questions. Nos tests ont donné un score de 0.463 dans le premier cas, et de
0.452 dans le second. Ces résultats montrent que les performances ne diminuent pas quand on
traite moins de documents, car ce sont les documents les plus pertinents qui sont gardés. De
plus, les performances de notre systeme sont en général meilleures pour les questions pour
lesquelles moins de 100 documents sont gardés.

6 Appariement question/réponse

Le principe general de cet appariement consiste d’abord a comparer la question considérée
avec chaque phrase des documents retenus pour cette question, et a conserver enfin les Na
phrases les plus similaires (Na est égal a 5 pour la tache Question Answering de TREC). Pour
effectuer cette comparaison, QALC construit une meme représentation pour la question et
pour la phrase candidate a la réponse. Cette représentation consiste en un vecteur contenant
trois types d’éléments : des mots pleins, des termes, et des entités nommées. Chacun de ces
éléments est pondéré en fonction de son importance par rapport aux autres.

Les mots pleins sont essentiellement les adjectifs, les verbes et noms, sous leur forme
lemmatisée, telle qu’elle est donnée par le TreeTagger (Schmid 1999). Les mots de la phrase
qui ne sont pas présents dans la question recoivent un poids nul. Les autres se voient attribuer
un poids, de type tf.idf, en rapport avec leur fréquence dans un corpus de référence. Les
termes proviennent de l’extracteur de termes décrit au paragraphe 4.1. Les termes de la
question sont affectés d’un poids fixe. Pour la phrase, les termes considérés sont les variantes
des termes de la question reconnues par FASTR dont le poids est celui qui permet de pondérer
les documents et qui exprime la distance entre la variante et le terme correspondant (voir
paragraphe 5). Les entités nommées sont, pour la question, celles qui correspondent au type
attendu de la réponse, et pour la phrase, celles qui ont été reconnues dans la phrase par le
module de reconnaissance des entités nommées. Les entités nommées correspondant au type
attendu de la réponse recoivent un poids fixe.

Finalement, la comparaison entre la question et la phrase est réalisée par le calcul de la
similarité entre les vecteurs qui les représentent suivant la mesure suivante :

Ziwdi
Zj wqf

o1‘1 wqj est le poids d’un élément du vecteur Vq représentant la question et wd,. est le poids d’un
élément du vecteur Vd représentant la phrase. Le poids des termes et entités nommées est
modéré par un coeﬁcient afin de rester inférieur au poids des mots de la question. Lorsque la
valeur de similarité est la meme pour deux phrases différentes, QALC sélectionne la phrase
o1‘1 les mots pleins de la question sont le moins dispersés.

sim(Vq , Vd) =

(2)

Nous allons montrer sur l’eXemple de la question What two US biochemists won the Nobel
Prize in medicine in 1992?, qui a été proposée a TREC8, comment chaque phrase est évaluée.
La question est d’abord transformée en un Vecteur, o1‘1 <PERSON> est le type attendu de la

0. Ferret, B. Grau, M. Hurault-Plantet, G. Illouz, C. Jacquemin

réponse, 16.01 est l’identificateur du terme US biochemist et 16.04 est l’identificateur du
terme Nobel Prize5 :

two (1.0) us (1.0) biochemist (0.9) nobel (1.0)
prize (0,6) medicine (0,5) win (0,3) 1992 (1.0)
<PERSON> (0.5) 16.01 (0.5) 16.04 (0.5)

Le meme type de vecteur est construit pour chaque phrase du document FT924-14045,
sélectionne pour cette question. Par exemple la phrase étiquetée par le module des entités
nommées: <NUMBER> Two </NUMBER> US biochemists, <PERSON> Edwin Krebs
</PERSON> and <CITY> Edmond </CITY> Fischer, jointly won the <NUMBER> I992
</NUMBER> Nobel Medicine Prize for work that could advance the search for an anti-
cancer drug donne le vecteur suivant :

two (1.0) us (1.0) biochemist (0.9) nobel (1.0)
prize (0,6) medicine (0,5) win (0,3) 1992 (1.0)
edwin (0.0) krebs (0.0) edmond (0.0) fischer (0.0)
work (0.0) advance (0.0) search (0.0) anti—cancer (0.0)

jointly (0.0) drug (0.0) <PERSON> (0.5) <NUMBER> (0.0)
<CITY> (0.0) 16.01 (0.5) 16.04 (0.3)

ou le poids 0.0 est donne aux éléments qui ne font pas partie du vecteur représentant la
question. Le terme US biochemist est trouvé sans variation et Nobel Prize apparait sous la
forme de la variante syntaxique Nobel Medicine Prize. Finalement, en appliquant (2), on
trouve une mesure de sirnilarité de 0.974 entre les deux vecteurs.

Le module d’appariement considere la phrase en tant qu’unité de réponse de base mais,
lorsque l’on souhaite une réponse plus concise, QALC s’appuie sur un ensemble
d’heuristiques simples pour réduire la taille des phrases dépassant la limite fixée. Lorsqu’une
entité nommée correspondant au type attendu de la réponse, ou d’un type proche, a été
trouvée, QALC sélectionne la partie de la phrase entourant cette entité nommée. Dans le cas
contraire, ou dans le cas ou le type attendu de la réponse n’a pu étre déterminé, il extrait une
partie de la phrase contigue a celle contenant les mots de la question. On suppose ainsi que la
phrase contenant la réponse possede une structure comparable a ce que serait la forme
afﬁrmative de la question posée.

7 Résultats et discussion

Dans le cadre de TREC9, les résultats de QALC ont été évalués dans trois conditions
différentes, les variations de l’une a l’autre concemant le moteur de recherche utilisé et la
taille de la réponse (250 ou 50 caracteres). Le meilleur de ces tests a obtenu un score de 0,407
avec 375 réponses trouvées sur 682, pour des réponses sur 250 caracteres. Le calcul de ce
score tient_compte du rang de classement (de 1 a 5) de la réponse trouvée. Ce score nous a
place en 6‘°"‘° position sur 28 participants. Le premier (Harabagiu et al, 2000) a obtenu un
score de 0,760, le deuxieme (Kwok et al, 2000) un score de 0,464, et les trois suivants
respectivement des scores de 0,460, 0,457 (Ittycheriah et al, 2000) et 0,425.

La conference d’évaluation TREC offre une référence intéressante pour mesurer l’efﬁcacité
des méthodes utilisées par les différents systemes de question-réponse. L’architecture de base
généralement adoptée par les systemes participants est conforme a celle de notre systeme
QALC, avec éventuellement quelques variantes.

5 Nous ne retenons ici que les expressions les plus longues des différents termes

Entités nommées et variamfes dans un systéme de question-réponse

Le typage de la réponse attendue est évidemment une fonctionnalité indispensable a un
systeme de question-réponse, particulierement lorsqu’il s’agit de donner une réponse courte
(50 caracteres). ParIr1i les questions posées a TREC, certaines attendent en réponse une entité
nommée telle qu’une date, un nom de personne ou un nom d’organisation par exemple. Dans
ce cas, le typage de la réponse est simple méme si son exploitation nécessite un bon systeme
de reconnaissance des entités nommées et si le nombre de catégories de types peut étre
augmenté de maniere a raffiner le typage. En revanche, lorsque la réponse attendue est
constituée d’un nom commun ou d’une phrase, son typage, plus complexe, est rarement
réalisé. Certains systemes, comme le systeme FALCON (Harabagiu et al, 2000), utilisent les
hiérarchies des classes de mots dans WordNet pour typer les réponses. Pour sa part, le
systeme développé par (Ittycheriah et al, 2000) se fonde sur un modele de l’entropie
maximum pour la classiﬁcation des types de réponse. Sur les 682 questions de TREC9, 57,5%
ont été analysées par QALC comme étant des questions a entité nommée, les autres n’ont pas
été typées. Parmi les réponses correctes de notre meilleur test, 62,7% répondent a des
questions a entité nommée. Par ailleurs, le test que nous avons fait pour des réponses plus
courtes donne 84% de réponses possédant une entité nommée parmi les bonnes réponses.
Typer la réponse permet donc de mieux cibler la portion de phrase qui peut la contenir.

Tous les systemes ayant participé a TREC9 utilisent un moteur de recherche pour effectuer la
sélection d’un sous-ensemble de documents dans la base d’environ un million de documents
mise a disposition par le NIST. Dans le systeme QALC, nous conservons dans son intégralité
chaque document retrouvé par le moteur. Mais d’autres sytemes sélectionnent le ou les
paragraphes pertinents de chaque document retrouvé. Comme dans QALC, la recherche des
meilleures réponses est fondée sur un appariement entre question et réponse reposant sur la
comparaison des mots des questions avec ceux des phrases sélectionnées et tenant compte du
type attendu de la réponse et des entités nommées. Les criteres retenus pour effectuer
l’appariement peuvent varier d’un systeme a l’autre. Kwok et al (Kwok et al, 2000) par
exemple utilisent entre autres un dictionnaire de synonymes qu’ils ont extrait manuellement
de WordNet. Le systeme FALCON, quant a lui, (Harabagiu et al, 2000) utilise une approche
sémantique pour réaliser cet appariement : une unification est recherchée entre la
représentation sémantique de la question et les représentations sémantiques des paragraphes
sélectionnés. C’est également le seul systeme a effectuer une justification de ses réponses.

8 Conclusion

Un systeme de question-réponse doit trouver la réponse a une question précise, dans un temps
suffisamment court pour étre compatible avec une éventuelle utilisation interactive. Cette
réponse étant recherchée dans une grande masse de documents, il est tentant d’appliquer des
méthodes essentiellement numériques pour la trouver. Néanmoins les expériences montrent
que l’ajout de raisonnements fondés sur des connaissances sémantiques et pragmatiques est
nécessaire si on veut obtenir, a terme, un systeme réellement efﬁcace. En effet, le systeme qui
a obtenu les meilleurs résultats a TREC9 est aussi celui qui utilise le plus largement les
techniques d’analyse syntaxique et sémantique (Harabagiu et al, 2000). Les futures
orientations de la tache question-réponse de la conférence TREC vont d’ailleurs dans ce sens.
En effet, a un horizon de 5 ans, les organisateurs prévoient des améliorations a la fois sur la
rapidité de la réponse, la vérification de sa justesse, la possibilité de fusionner plusieurs
réponses pour obtenir une réponse complete, et enfin des possibilités de dialogue permettant a
l’utilisateur de préciser sa demande. Les futurs systemes devront aussi pouvoir décider si la
réponse se trouve ou non dans le corpus de recherche. De plus, ils devront étre capable de
déduire la réponse complete de réponses fragmentaires dispersées dans différents documents.
Toutes ces améliorations ne pourront se faire sans une intégration plus importante des
méthodes propres au traitement sémantique de la langue.

Les améliorations que nous voulons apporter a notre systeme relevent donc essentiellement
d’une approche sémantique et pragmatique. Ainsi, la base de connaissances WordNet, que

0. Ferret, B. Grau, M. Hurault-Plantet, G. Illouz, C. Jacquemin

nous utilisons déja pour trouver les variantes sémantiques d’un mot, pourra aussi étre
exploitée pour une classification plus fine des types de réponses. Nous utiliserons aussi une
analyse syntaxico-sémantique robuste pour construire les représentations sémantiques de la
question et de l’ensemble des réponses candidates, afin de sélectionner les réponses a la fois
sur les termes de la question et sur les liens sémantiques que ces termes ont entre eux.

Références

CELEX, 1998, http://www.ldc.upenn.edu/readme_files/celex.readme.html, UPenns, Eds.,
Actes Consortium for Lexical Resources, (1998)

CLR, 1998, http://crl.nmsu.edu/cgi-bin/Tools/CLR/clrcat#D3, NMSUs, Eds., Actes
Consortium for Lexical Resources, New Mexico (1998)

Fellbaum C., (1998) WordNet.' An Electronic Lexical Database, Cambridge, MA, MIT Press.

Ferret 0., Grau B., Hurault-Plantet M., Illouz G., Jacquemin C. (2000), QALC — the
Question-Answering system of LIMSI-CNRS, pre-proceedings of TREC9, NIST.

Grishman R., Sundheim B., (1995), Design of the MUC-6 evaluation, Actes de M UC-6,
NISTs, Eds., Morgan Kauffmann Publisher, Columbia, MD.

Harabagiu S., Pasca M., Maiorano J., (2000), Experiments with Open-Domain Textual
Question Answering, Actes de Coling’2000, Saarbrucken, Germany.

Ittycheriah A., Franz M., Zhu W-J., Ratnaparkhi A., (2000), IBM's statistical Question
Answering System, , Actes préliminaires de TREC9, Gaithersburg, MD, NIST Eds, 60-65.

J acquemin C., (1999), Syntagmatic and paradigmatic representations of term variation, Actes
de ACL’99, 341-348.

Jacquemin C., Bush C., Fouille du Web pour la collecte d'entités nommées, Actes de
TALN 2000, Lausanne (2000), 187-196.

Justeson J ., Katz S., (1995), Technical terminology: some linguistic properties and an
algorithm for identiﬁcation in texte, Natural Language Engineering , Vol 1, pp. 9-27.

Kwok K.L., Grunfeld L., Dinstl N., Chan M., (2000), TREC9 Cross Language, Web and
Question-Answering Track experiments using PIRCS, Actes préliminaires de TREC9,
Gaithersburg, MD, NIST Eds., 26-35.

Lehnert W., (1977), Human and computational question answering, Cognitive Science , 1,
p. 47-63.

de Loupy C., Bellot P., El-Beze M., Marteau P.-F. (1998). Query Expansion and
Classification of Retrieved Documents, TREC7 , p.382-389.

Molla A. D. et al., (2000), EXTRANS, An Answer Extraction System, Traitement
automatique des langues , 41, p. 495-522.

Schmid H., (1999), Improvements in Part-of-Speech Tagging with an Application To
German, Natural Language Processing Using Very Large Corpora, Dordrecht, S. Armstrong,
K. W. Chuch, P. Isabelle, E. Tzoukermann, D. Yarowski, Eds., Kluwer Academic Publisher.

