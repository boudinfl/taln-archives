TALN 2001, Tours, 2-5jui11et 2001

Compréhension Automatique de la Parole combinant syntaxe
locale et sémantique globale pour une CHM portant sur des
taches relativement complexes

J eréme Goulian, J ean-Yves Antoine
VALORIA, EA 2593 - Universite de Bretagne Sud
Site de Tohannic, rue Yves Mainguy, 56000 Vannes, France
{j erome. goulian,j ean-yves.antoine} @univ-ubs .fr

Résumé - Abstract

Nous presentons dans cet article un systeme de Comprehension Automatique de la Parole (CAP)
tentant de concilier les contraintes antinomiques de robustesse et d’analyse detaillee de la pa-
role spontanee. Dans une premiere partie, nous montrons l’importance de la mise en oeuvre
d’une CAP ﬁne dans l’optique d’une Communication Homme-Machine (CHM) sur des taches
moyennement complexes. Nous presentons ensuite l’architecture de notre systeme qui repose
sur une analyse en deux etapes : une premiere etape d’analyse syntaxique de surface (Shallow
Parsing) generique suivie d’une seconde etape d’analyse semantico-pragmatique — dependante
du domaine d’application — de la structure profonde de l’enonce complet.

This paper presents a spoken french understanding system which aims at providing a detailed
linguistic analysis as well as preserving the robustness of standard methods. The ﬁrst part fo-
cusses on the importance of a richer analysis for applications that are not dedicated to a very re-
stricted task. We then present our two-level architecture system : a robust independant-domain
shallow parsing step followed by a task based analysis of the whole structure of the utterance.

Mots clefs - Keywords : Communication Homme-Machine, Comprehension Automatique de
la Parole, robustesse, analyse syntaxique partielle, grammaires de dependances.

Man Machine Dialogue, speech understanding, robustness, shallow parsing, dependency gram-
mars.

1 Introduction

Au cours de ces dernieres annees, la Communication orale Homme-Machine a atteint une matu-
rite dont temoigne l’apparition recente de systemes grands publics operationnelsl. Ces reussites
reposent principalement sur les progres signiﬁcatifs des modules de reconnaissance de la pa-
role. Situes en entree de la chaine de traitement, leur role est de transformer le signal vocal en
une (souvent les 11 meilleures) sequence(s) de mots tenant lieu d’enonce reconnu. Nous nous
interessons dans cet article aux modules de Comprehension Automatique de la Parole (CAP par
la suite) qui se situent en aval de la reconnaissance. Le but de ces systemes est de fournir une
representation semantique de l’enonce exploitable par la suite par les modules de gestion du di-
alogue. Notons qu’il s’agit ici d’une comprehension hors-contexte, la resolution des references

1Citons par exemple le systeme de reservation par telephone des chemins de fer neerlandais faisant suite au
projet europeen ARISE (den Os et a1., 1999).

J érome Goulian, J ean-Yves Antoine

en contexte étant traitée par le gestionnaire du dialogue.

La parole spontanée induit l’apparition d’inattendus structurels (hésitations, répétitions, correc-
tions, inachevements) (Blanche-Benveniste et al., 1990) qui cassent la régularité syntaxique des
énoncés. La compréhension de la parole ne peut donc s’envisager aisément sous la forme d’une
analyse linguistique détaillée, du moins avec les modeles traditionnels développés pour le traite-
ment de l’écrit. C’est la raison pour laquelle la plupart des systemes de dialogues développés
a l’heure actuelle ne concernent que des domaines applicatifs tres ﬁnalisés (celui du renseigne-
ment aérien —ATIS2— ou ferroviaire). Ces taches tres spécialisées ont en effet permis la mise
en oeuvre d’approches tres pragmatiques ne reposant sur aucune analyse détaillée des énoncés
oraux. En particulier, les approches dites sélectives (Minker et al., 1999) consistent a ne détecter
et ne considérer dans l’énoncé que certains segments-clés nécessaires a l’élaboration d’une
requéte d’interrogation d’une base de données (sens dit “utile” de l’énoncé). Si ces méthodes
se sont révélées robustes face au traitement de la parole spontanée, rien ne garantit cepen-
dant qu’elles se réveleraient toujours aussi efﬁcaces sur des domaines d’application plus riches.
Ainsi, la question de la généralité des méthodes utilisées constitue une interrogation centrale du
domaine (Hirschman, 1998).

Dans cet article, nous nous placons précisément dans un cadre applicatif qui, s’il reste ﬁ-
nalisé, est néanmoins relativement plus riche que les domaines étudiés classiquement : celui
du renseignement touristique. Dans une premiere partie, nous évoquons les besoins que semble
nécessiter une interaction Homme-Machine qui ne soit plus limitée a une recherche d’informa-
tion tres ﬁnalisée. Nous présentons ensuite un systeme de compréhension s’appuyant sur des
techniques d’analyses robustes et des formalismes développés pour le TAL. Son objectif est de
mener une analyse ﬁne de l’énoncé tout en respectant la contrainte de robustesse imposée par
le caractere spontané des productions orales.

2 CAP et téiches moyennement complexes : quelles difﬁcultés ?

En raison du caractere tres ﬁnalisé3 des domaines d’application classiquement étudiés par les
systemes de compréhension, les énoncés oraux sur lesquels ils travaillent présentent une am-
bigu'1'té lexicale tres limitée4. Les méthodes de CAP sélectives peuvent ainsi se limiter a la
recherche de séquences clés (ilots ou segments conceptuels) dans l’énoncé. Ces segments con-
ceptuels (groupes de mots exprimant un contenu sémantique “utile” a l’application considérée)
sont utilisés pour remplir des structures types (ou schémas) prédéﬁnies qui tiennent lieu de
représentation sémantique de l’énoncé.

Or la généralisation du dialogue oral a des cadres applicatifs plus riches se traduit par une
augmentation sensible de l’ambigu'1'té lexicale. On peut noter par exemple l’augmentation tres
sensible de la perplexité des modeles de langage utilisés en reconnaissance de parole entre le
domaine ATIS (renseignement aérien) et l’application Broadcast News (information générale)
(Roukos, 1995). De meme, l’étude du corpus Pariscorp (Bonneau-Maynard, Devillers, 1998)
que nous avons menée (Goulian, 2000) nous renseigne sur le nombre de schémas (requétes
types) et le nombre de concepts (objets de l’application sur lesquels peuvent porter les requétes,
propriétes de ces objets, etc.) nécessaires dans ce cadre applicatif. Nous comparons ces résulats
dans le tableau 1 avec le nombre de schémas et de concepts répertoriés dans deux domaines
applicatifs limités (AT IS et MASK) (Minker et al., 1999).

2Air Transport Information System.
3Ceux-ci se caractérisent ainsi par un Vocabulaire de généralement moins de 10000 formes ﬂéchies.
4Nous ne considérons pas ici l’ambigu'1'té due aux résultats issus de la reconnaissance de parole.

CAP pour une CHM portant sur des taches relativement complexes

rens. aérien(ATIS) rens. SNCF(MASK) rens. tourist. (PARISCORP)
schémas 5 8 18
concepts 38 44 1 13

Table 1: Nombre de schémas et de concepts en fonction du type d’application

On constate clairement une nette augmentation pour le domaine du renseignement touristique.
Pour se rendre compte de l’importance de cet accroissement pour la compréhension de la parole,
prenons par exemple le concept horaire. Ce concept se limite, dans le domaine des renseigne-
ments ferroviaires, aux horaires des trains. Dans notre domaine d’étude, ce concept peut se
décliner non seulement en horaires de train (ou d’avion) mais aussi en horaires d ’0uverture
et/ou de fermeture de commerces, de monuments, etc. Ainsi, dans l’exemple (1),

(1) “J e crois qu’il y a une brasserie dans la salle Méditerranée vous savez celle des TGV pour
Marseille c’est quoi ses horaires au juste”

la brasserie et le TGV sont tous les deux des objets potentiels d’une requéte de type horaire,
aInbigui'té a laquelle risque de se heurter une méthode uniquement orientée par la tache.

De meme, le calcul de la référence hors contexte, qui prend une importance plus grande dans
de tels domaines, pose probleme. Enﬁn, (Pierrel, 2000) insiste sur l’importance d’une détection
plus ﬁne des intentions de l’usager pour un dialogue réellement coopératif. La prise en compte
de domaines applicatifs plus riches risque ainsi de requérir une analyse linguistique détaillée de
la structure de l’énoncé (Van Noord et al., 1998).

Si la nécessité d’une analyse détaillée des énoncés semble s’imposer, se pose néanmoins le
probleme du traitement des inattendus de l’oral (répétitions, hésitations, etc.). Quel type d’ana-
lyse envisager ? Une premiere réponse peut nous étre donnée par l’étude linguistique de corpus
oraux. Les études de (Blanche-Benveniste et al., 1990) attestent par exemple que ces inattendus
présentent des régularités sur lesquelles une analyse automatique peut utilement se reposer. On
peut noter entre autres que les répétitions ou les reprises s’effectuent touj ours au début des syn-
tagmes enrichis ou avortés. De ce point de vue, une analyse syntaxique de surface garde toute
sa pertinence en permettant d’exploiter localement la structure interne des syntagmes. De tels
outils d’analyse syntaxique robustes ont été développés pour le TAL (Chanod, 2000), certaines
méthodes récentes d’analyse structurelle de surface (Shallow Parsing) ayant démontré leur ca-
pacité a analyser de maniere robuste des textes portant sur des domaines relativement larges
(Abney, 1996) (A'1't-Mokhtar, Chanod, 1997).

Si ces méthodes nous permettent d’envisager une analyse détaillée de surface des énoncés
oraux, reste le probleme de l’analyse de la structure profonde de l’énoncé. La question de
la variabilité de l’ordre des mots en francais parlé est a ce niveau importante. Ainsi, on ne
po11rra pas s’affranchir des problemes posés par le traitement de la variabilité faible (i.e. mou-
vements n’entrainant pas de discontinuités (Holan et al., 2000)), problemes déja relevés par
des systemes sélectifs utilisés dans un cadre tres ﬁnalisé (Minker et al., 1999). Pour traiter
ces phénomenes, nous envisageons une analyse globale basée majoritairement sur des criteres
sémantico-pragmatiques5. Le traitement des structures discontinues ne semblant pas en re-
vanche étre central dans le cadre du dialogue oral homme-machine (Antoine, Goulian, 2001),
cette analyse po11rra reposer sur un formalisme proj ectif.

5Le tenne “pragmatique” fait ici référence au domaine de l’application et non a la prise en compte du dialogue.

J érome Goulian, J ean-Yves Antoine

3 Un systeme combinant syntaxe locale et sémantique globale

Nous présentons dans ce paragraphe un systeme de compréhension ayant pour objectif de per-
mettre la génération d’une représentation sémantique ﬁne de l’énoncé tout en respectant la
contrainte de robustesse imposée par le caractere spontané du frangais parlé. Nous proposons
d’adopter une approche proche des outils d’analyse syntaxique robustes développés pour le
TAL. Ces systemes sont congus pour pouvoir marquer (ou extraire) des structures syntaxiques
prédéﬁnies et légitimées. (Ejerhed, 1993) précise qu’ils s’articulent en général sur deux étapes :
une premiere étape repérant des structures Ininimales et une seconde étape calculant des struc-
tures ou relations plus complexes. La compréhension des énoncés est précisément réalisée
suivant une approche comparable en deux étapes (ﬁgure 1). L’ architecture correspondante est
présentée brievement ici. Nous détaillons chacune des étapes dans les paragraphes suivants.

structure sémantique

ANALYSEUR DE
DEPENDANCES
PRAGMATICO-SEMANTIQUES

1

"segments conceptuels "

Grarnmaires de Liens

ETIQUETEUR SEMANTIQUE
+
SEGMENTEUR

T

énoncé

FST

 

Figure 1: Architecture du systeme

1. La premiere étape a pour but de foumir une analyse robuste et détaillée au niveau du
syntagme. Il s’agit d’une :
0 segmentation syntaxique partielle de 1’énoncé,

o foumissant une structuration partielle de celui-ci en constituants minimaux non
récursifs (Chunks) (Abney, 1991). Ces groupes correspondent aux unités de reprise
en cas d’interruption de la production orale (Blanche-Benveniste et al., 1990),

0 suivie d’un étiquetage sémantique. Cet étiquetage a pour but d’identiﬁer les dépen-
dances internes a ces constituants existantes autour de leur téte lexicale.
Cette premiere analyse a été implémentée sous forme de cascades de transducteurs a états
ﬁnis, compiles a partir d’expressions régulieres (utilitaire Fsa (Van Noord, 1997)). Elle
présente les deux propriétés principales suivantes :
o robustesse : il s’agit d’une analyse partielle ne cherchant pas a porter de jugement
syntaxique global sur la totalité de l’énoncé.

0 généricité : il s’agit d’une analyse syntaxique donc indépendante du domaine d’appli-
cation; la construction des dépendances locales (l’étiquetage sémantique) réalisé est
lui-meme générique (cf. infra). Cette caractéristique est importante comme nous
l’avons déja mentionnée (cf. §2).

2. La seconde étape a pour but d’extraire la représentation sémantique complete de l’énoncé
par la recherche des dépendances globales entre les tétes lexicales associées aux segments
détectés6. Il s’agit d’une analyse :

5Les dépendances locales internes aux syntagmes ayant déja été construites dans 1’étape précédente.

CAP pour une CHM portant sur des taches relativement complexes

0 maj oritairement dépendante de l’application, la recherche des dépendances s’effectu-
ant a un niveau sémantico-pragmatique. Cette analyse est proche en ce sens des
méthodes sélectives mais récupere néanmoins les structures issues de l’analyse dé-
taillée réalisée lors de la premiere étape.

0 utilisant le formalisme des grammaires de liens (Sleator, Temperley, 1991). Ce for-
malisme lexicalisé, inspiré des grammaires de dépendances, repose sur le postulat de
la projectivité du langage étudié (cf. §2). Les travaux de (Grinberg et al., 1995) ont
montré la capacité des grammaires de liens a analyser de facon robuste des corpus
de dialogues oraux. On notera que dans un tel formalisme, les dépendances syntax-
iques sous-tendent les dépendances sémantiques (Mel’cuk, 1988). Ceci, ajouté au
fait que notre analyse — partielle — reste ﬁnalisée, devrait faciliter l’adaptation de ce
formalisme, concu pour l’analyse de la syntaxe, a notre problématique.

3.1 Segmentation syntagmatique de l’énoncé et étiquetage sémantique

Cette étape se veutIr1inimale et superﬁcielle et ne cherche pas a lever toute l’ambigu'1'té struc-
turale. En particulier, les rattachements (syntagmes prépositionnels, portée des conjonctions de
coordinations, etc.) sont laissés a l’étape suivante et s’effectuent, dans notre cas, sur des criteres
sémantico-pragmatiques. Plusieurs actions sont réalisées ; nous les détaillons ci-dessous en
prenant l’exemple de l’analyse de l’énoncé (2).

(2) je voudrais cormaftre les tarifs du petit du petit restaurant chinois prés de la gare non prés de I ’h6tel

1. Pré-étiquetage. Cette premiere sous-étape a pour objectif le repérage des locutions et
le pré-étiquetage syntaxique des mots constituant l’énoncé. Nous avons choisi un nom-
bre réduit d’étiquettes syntaxiques qui nous paraissent sufﬁsantes pour caractériser les
relations de sous-catégorisation nécessaires a la modélisation du syntagme. En effet,
notre domaine d’application restant relativement ﬁnalisé7, l’utilisation d’informations
morphologiques ne nous est pas utile. Notre étiqueteur repose sur des regles contextuelless
écrites sous forme d’expressions régulieres. En cas d’ambigu'1'té, nous conservons les
différentes séquences, traitées en parallele par les étapes suivantes.

pr_pers[je] mod[voudrais] V_inf[conna1‘tre] art[les] n[tarzfs] prep[du] adj [petit] prep[du] adj [petit] n[restaurant]
adj [chinois] prep[prés—de] art[la] n[gare] neg[non] prep[prés—de] art[l] n[h6tel]

2. Segmentation syntaxique en syntagmes. Nous proposons un découpage en consti-
tuants minimaux a l’image d’(Abney, 1991) que nous adaptons au cadre du dialogue
oral. Le tableau 2 répertorie quelques uns des groupes syntagmatiques que nous con-
sidérons. Trois catégories syntagmatiques sont ainsi envisagées. La premiere correspond
aux grands groupes syntaxiques classiques de l’écrit. S’agissant de constituants mini-
maux, les groupes verbaux par exemple n’incluent jamais leurs arguments. En revanche,
leurs modalités (présence de négation, d’un modal) sont identiﬁées. La seconde corre-
spond aux expressions langagieres indépendantes du domaine d’application (date, heure,
adresse). Enﬁn, la derniere catégorie est spéciﬁque au dialogue oral. Elle permet de
repérer et de délimiter les marqueurs des inattendus dans la production orale. Conserver
ces marqueurs nous semble judicieux pour aider le traitement de ces phénomenes dans
la phase suivante. Des approches de prétraitements (patterns d’extragraInmaticalité par
exemple (Bear et al., 1992)), non implantées a l’heure actuelle dans notre systeme, pour-
raient néanmoins étre utilisées.

7Ambigu'1'té lexicale relativement limitée.
8On notera :21 Ce sujet qu’a l’heure actuelle, les approches :21 bases de régles et les approches stochastiques
présentent des performances équivalentes que ce soit pour l’étiquetage morpho—syntaxique ou la CAP.

J érome Goulian, J ean-Yves Antoine

Catégorie Groupe Exemples
GVerbaux GVmod[veux rése rve r] ,GV[coute] ,GVinf[alle r] . ..
GAdj ectivaux Gadj { [chinois],[trés cher] } 
GNominaux GN{ [l ’h6tel Caumartin],[deux places], 
syntaxe GPrépositionne1s GPNom[du quartier],GPLoc[prés de la gare],GP[avec restaurant]...

GAdVerbiaux GadV[essentiellement]...

Coordjnations Coo[ou]...

Pronoms relatifs PrRe1[qui]...
expressions Date Date{[mardi 6 mars],[mardi prochain]}...
langagieres Heure Heure{[trois heures du matin],[cinq heures mains le quart]}...
Adresse Adresse[rue de la paix]...
spécifcités Hésitations Hes[euh]...
de l’ora1 Corrections Cor{[non pardon],[non en fait]}...

Table 2: Groupes syntagmatiques utilisés pour la segmentation

En pratique, cette analyse résulte de l’application d’une séquence ﬁnie et ordonnée de
transducteurs. Chaque transducteur est utilisé pour introduire, dans l’énoncé étiqueté
syntaxiquement, des marqueurs de délimitation autour des instances d’un groupe partic-
ulier. Chacun de ces groupes est décrit par un ensemble de regles exprimées au moyen
d’expressions régulieres. L’ambigu'1'té de segmentation est gérée par l’heuristique suiv-
ant : nous privilégions comme (Abney, 1991) la détection des groupes les plus longs.
Ce choix permet la capture, des ce niveau de l’analyse, d’un maximum de dépendances
locales sur lesquelles l’analyse suivante n’aura pas a revenir. Pour ce faire, les expres-
sions integrent un opérateur spéciﬁque exprimant une relation de remplacement contrainte
par la direction gauche-droite de l’analyse et favorisant cette détection maximale des in-
stances considérées (Karttunen et al., 1996) (Karttunen, 1996). Nous donnons ci-apres
un exemple (simpliﬁé) d’une telle regle pour la délimitation des instances maximales des
groupes nominaux, formées par la succession d’un article optionnel, d’un ou plusieurs
groupes adjectivaux, d’un nom puis d’un ou plusieurs groupes adjectivaux9, suivi du
résulat de l’analyse de l’énoncé (2).
replace ( (’GN’ ——> [c(art) ” ,c(’GAdj’ ) *,c(n) ,c(’GAdj’ ) *] ))

GN[pr_pers(je)] GVmod[mod(voudrais) V_inf(connai‘tre)] GN[art(les) n(tarifs)] prep[du] Gadj[adj(petit)]
GPNom[prep(du) GN[Gadj(adj(petit)) n(restaurant) Gadj (adj (chinois))] GPLoc[prep(prés—de) GN(art(la)
n(gare))] Cor[neg(non)] GPLoc[prep(prés-de) GN(art(l) n(h6tel))]

Notre segmenteur a fait l’objet d’une évaluation préliminaire sur 300 énoncés dans le
cadre de la campagne d’évaluation “par déﬁ” des systemes de CAP initiée par le Groupe
de Travail 5.1 du GDR-PRC-I3 (Antoine, 2001). Le tableau 3 donne le pourcentage
d’erreur en substitution (étiquette erronée), en scission (un chunk attendu segmenté en
plusieurs chunks), et en regroupement (plusieurs chunks attendus regroupés en un seul).

%Erreur %Précision %Décision
Substitution Scission Regroupement
3.38% 6.4% 2.1% 88.12% 100%

Table 3: Evaluation préliminaire du segmenteur

Notons que cette précision de 88%, obtenue sur cette évaluation préliminaire, po11rra
étre améliorée. Notre decision a 100% résulte quant a elle du choix de notre stratégie

9repl ace est 1’opérateur déﬁni dans (Karttunen, 1996), ——> introduit les marqueurs [..] autour des instances
detectées, c (X) repere une catégorie X et transforme les marqueurs [..] en marqueurs (..), cm (X, m) est identique
a c (X) mais Valable uniquement pour le mot m ; les autres operateurs etant ceux des expressions régulieres.

CAP pour une CHM portant sur des taches relativement complexes

d’analyse.

3. Etiquetage sémantique. I1 s’agit d’un remplacement, réalisé au fur et a mesure de la
segmentation, des étiquettes syntaxiques par des étiquettes sémantiques “génériques”
articulées autour de la téte lexicale des groupes détectés. Ces étiquettes sont issues
de l’étude du corpus Pariscorp. Elles ont été validées sur 1000 énoncés mais restent
indépendantes du domaine d’application. Elles correspondent en effet a de grands types
sémantiques : la classe générique des objets de l’univers quel que soit celui-ci, la classe
des propriétés portant sur ces objets, la classe des relations sur des objets, etc. Chaque
groupe recoit la classe sémantique correspondant a sa téte lexicale (étiquetée ’T’ pour
’Type’). Le tableau 4 donne un apercu de cette classiﬁcation (exemples du tableau 2).

Syntagmes Classes sémantiques Exemples
GV Acte ActeMod[mod(veux) T(réserver)], Acte[T(co12te)], Action[T(aller)]
Gadj PteObj PteObj { [T(chinois)], [PteModiﬁeur(trés)T(che r)] . ..
GNo1ninaux Obj ObjDéﬁni[PteNb(l ) T(hotel) Référence(Caumartin)], Obj [PteNb(2) T(places)], 
GP Pte PteRéférence[T(quartier)], Pte[T(avec) Obj (restaurant)],
PteLoc[T(prés—de) ObjDéﬁni(PteNb(l) T(gare))]...
Gadv PteModiﬁeur PteModiﬁeur[T(essentiellement)]...
Coo Coo Coo[T(ou)]...
PrRel ObjRéférent ObjRéférent[T(qui)]...
Date Date Date{ [Nomj our(mardi) Numj our(6) Nommois(mars)],
Heure Heure Heure{ [Nheure(3) PteMomentj oumée(matin)],
[NHeure(5) ModiﬁeurMinutes(moins) NMinutes(l5)]}...
Adresse Adresse Adresse[T(rue) PteRéférence(de-la—paix)]
Hes Hes Hes[T(euh)]...
Cor Cor Cor[T(non) Pte(pardon)], 

Table 4: Correspondances catégories syntagmatiques / classes sémantiques utilisées

Le groupe nominal “un restaurant chinois” de téte lexicale “restaurant” correspond ainsi
a un Objet de type restaurant possédant deux propriétés : une spécialité : chinois (PteObj)
et le fait d’étre indéﬁni : article un (PteDéﬁni(non)). Ces propriétés correspondent a des
dépendances locales autour de la téte lexicale, internes a ces segments. Cet étiquetage,
basé sur des regles génériques de correspondances catégories syntagmatiques / classes
sémantiques et réalisé en partie en contexte, servira de base au rattachement (dépendances
globales) effectué en seconde partie1°. La ﬁgure 2 donne le résultat de l’analyse de (2).

ActeMod PteRéférence

ObjDéﬁni PteLoc PteLoc
connaitre tat-ifs PteObj Tesla t Prés'de Cor
Mod ‘ PteNb l (prep[du]> Pteolyllipteobj bjDéﬁni l
Voudfais mus petit chinois Safe

     

Figure 2: Segmentation de l’exemple (2) et construction des dépendances locales sémantiques

3.2 Analyse de la structure de l’énoncé par rattachements pragmatiques

Cette deuxieme étape a pour but d’établir les relations de dépendances globales existantes en-
tre les segments identiﬁés. Nous utilisons pour cela un formalisme lexicalisé : les Grammaires
de Liens (Link Grammars)(Sleator, Temperley, 1991). Inspiré des grammaires de dépendances
(Tesniere, 1959), ce formalisme envisage traditionnellement la structure de la phrase non plus

1°Un étiquetage lexicalisé dépendant de l’application est tout de meme réalisé (transducteurs) avant la seconde
phase d’analyse. Il pennet par exemple de remplacer l’étiquette Pte0bj de l’objet restaurant en Spécialité.

J érome Goulian, J ean-Yves Antoine

en termes de constituants mais uniquement selon les relations syntaxiques que les mots entre-
tiennent entre eux. Chaque unité lexicale possede des connecteurs indiquant les liens pouvant
étre établis avec les autres mots de la phrase. Les liens sont établis en respectant cette contrainte
locale sur l’ordre des mots de la phrase. L’ analyse repose également sur deux contraintes glo-
bales : la connectivité (tous les mots doivent étre reliés entre eux) et la planarité (les liens ne
doivent pas se croiser — non-projectivité — cf. §2). Nous proposons deux adaptations de ce
formalisme :

1. Les liens ne s’effectuent plus sur les mots de l’énoncé mais uniquement sur les tétes

lexicales des segments identiﬁés. Deux observations doivent étre faites :

o les dépendances locales identiﬁées précédemment n’interviennent donc plus ici.

o les mots de l’énoncé n’ayant pu étre insérés dans un syntagme (pour (2) c’est le cas
de la préposition du) sont exclus de cette analyse. Le caractere partiel de l’analyse
n’est lié qu’a l’étape précédente, la contrainte de connectivité étant respectée ici.

2. Les relations envisagées sont ici essentiellement pragmatiques i.e. dépendantes du do-
maine d’application. Elles ont été caractérisées manuellement sur le corpus Pariscorp
(Goulian, 2000). On distingue deux types de relations :

o Celles caractérisant la nature de l’énoncé. Pour une requéte de type Selection (de-
mande d’une liste d’objets ayant certaines propriétés), on retiendra par exemple
deux types de relations. La premiere (0bjSe’lecti0n) fait le lien entre la nature de la
requéte et la nature de l’objet a sélectionner; la seconde (CritereSe’lecti0n) indique
le ou les criteres souhaité(s) sur les objets (critere de proximité, de tarifs, etc.)

o Celles caractérisant les propriétés des objets. Les relations expriment alors pour
chaque type d’objet du domaine les propriétés valides qu’il peut supporter. Pour
un hétel par exemple, il s’agira de relations de Catégorie (1 étoile), de Services
proposés, etc.

Par ailleurs, des relations particulieres permettent de traiter les inattendus structuraux tels
que les reprises marquées, les conjonctions de coordination et les relatives (cf. §3.2.l).

3.2.1 Représentation des relations

Nous expliquons dans ce paragraphe comment les relations évoquées ci-dessus sont représentées
en grammaires de Liens. Chaque relation est exprimée au moyen de formules logiques. En pra-
tique, nous utilisons deux types de regles :

des régles lexicalisées simples, permettant d’exprimer des relations dépendantes de la téte lex-
icale du segment considéré. Nous donnons ci-dessous deux exemples (tres simpliﬁés pour les
besoins de l’eXplication) de telles regles nécessaires au traitement de l’énoncé (2).

(1) PteRéférence(T(restaurant)) : Objet — Tarif*&{Taille‘}&{Spécialité+}@

(2) ObjDéfini(T(tarif)) : Objet — Tarif*

La regle (1) conceme uniquement le mot restaurant correspondant dans la phrase a la catégorie
PteRe’fe’rence et indique qu’il doit étre objet d ’une requéte (dans cet exemple simpliﬁé 0bjet-
Tarzf) placée avant ou apres lui dans l’énoncé (opérateur *) et possédant éventuellement (entre
{}) une relation de type Taille située a sa gauche et une ou plusieurs relations (opérateur @) de
type Spe’cialite’ située(s) a sa droite dans l’énoncé (opérateur +). De la meme maniere, la regle
(2) indique que le mot-clé tarif doit faire l’objet d’une relation Objet-Tarzf.

Ces regles permettent par ailleurs de traiter les inattendus non marqués (regle (1) en ce qui con-
cerne la répétition non marquée présente dans l’énoncé (2)).

CAP pour une CHM portant sur des taches relativement complexes

des meta régles, correspondant a un ensemble factorisé des regles precédentes et permettant
d’exprimer des relations valables pour toutes ou un sous-ensemble des tetes lexicales possi-
bles pour un segment donné (chaque regle particuliere en est automatiquement deduite). C’est
le cas par exemple de la regle (3) qui indique que tous les segments étiquetes PteL0c, quelle
que soit leur tete lexicale (symbole *) (preposition prés-de, loin-de, etc.), peuvent conduire a
un lien de type Localisation-Objet. De meme la regle (4) indique la possibilité d’une relation
L0calisati0n0bjet entre des objets PteRe’fe’rence dont la tete lexicale appartient a l’ensemble
0bjL0calisables.

(3) PteL0c(T(*)) : L0calisati0n0bjet‘

(4) PteRéférence(T(ObjL0calisables)) : L0calisati0n0bjet+

De telles meta regles permettent entre autres de gerer les coordinations ainsi que les inattendus
marques (notamment les corrections) qui sont traites de maniere identique“ : les liens se font
sur des segments de meme classe sémantique ou incluant cette classe. La regle (5) exprime par
exemple que la coordination doit etre reliee a droite et a gauche a des segments de meme classe
sémantique.

(5) C'00(Type(*)) : (PteL0c‘&PteL0c+)|...

3.2.2 Obtention de la représentation sémantique ﬁnale

La représentation sémantique ﬁnale de l’enoncé est obtenue par la structure établie a l’issue de
cette analyse (ﬁgure 3), elle-meme transformée en requete d’interrogation de base de données.

OBIET-TARIF LOCALISA'I‘ION— OBIET

TAILLE
AGENT TARIF

N/\ COR COR
A°’‘° 05 ObjDéﬁni P‘°Réfé“”“°"’ He (W£eLm
Obj connaitre tarifs d Pteobj resta t . , plies-de C pres-de
Mod | PteNb | (prepl “D Taille Spécialite bJD°ﬁ“1 | bjDéﬁni |
vouloir tous peﬁt chinois gare hotel

Figure 3: Construction des dépendances globales sur l’exemple (2)

L’ algorithme utilise repose sur la contrainte de connectivité. Cette contrainte ne permet pas en
l’etat de gérer les inachevements ou les incises. Nous envisageons d’adapter notre algorithme
en relachant cette contrainte en cas d’échec de l’analyse.

4 Conclusion

Le systeme de comprehension presente resulte d’une mise en oeuvre conjointe de methodes
issues du TAL robuste et de la CAP selective. Son objectif est de permettre une analyse ro-
buste et detaillée d’énonces oraux dans le contexte d’une CHM portant sur des taches rela-
tivement complexes. L’analyseur des dépendances globales est a l’heure actuelle en cours de
développement”. Une premiere phase d’évaluation portera ensuite sur 1000 enoncés du corpus
Pariscorp et permettra d’apprecier la qualite de l’analyse linguistique detaillée réalisee et la ro-
bustesse de l’ensemble du systeme. Cette evaluation se poursuivra dans le cadre de la campagne
du G.T. 5.1 du GDR-PRC I3 (Antoine, 2001).

“Le traitement des corrections demande encore a etre evalue en detail. 11 reste toutefois que leur presence
ne perturbe pas l’analyse et que les marqueurs, s’ils existent, sont conserves pour d’eVentuels pre—traitements ou
post—traitements a la demiere etape de l’analyse.

12ActiVites de recherche ﬁnancees par le conseil regional de Bretagne.

J érome Goulian, J ean-Yves Antoine

Références

Abney S. (1991), Parsing by Chunks, Kluwer, in Berwick, A. & T. (ed.), “Principle Based Parsing”.
Abney S. (1996), Partial parsing via ﬁnite-state cascades, Actes de W Robust Parsing, ESSLLI’96, 8-15.
A‘1’t-Mokhtar S., Chanod J .P. (1997), Incremental ﬁnite-state parsing, Actes de ANLP’97, 72-79.

Antoine J .Y., Goulian J . (2001), Etude des phénoménes d’ extraction en francais parlé sur deux corpus de
dialogue oral ﬁnalisé, application a la CHM orale. T.A.L., Vol. 42.1, (a paraitre).

Antoine J .Y. (2001), Evaluation des systémes de CAP, Campagne d’ évaluation “par déﬁ”, Rapport tech-
nique, GDR-PRC-I3, Pole Parole, G.T. 5.1., http://www.univ-ubs.fr/valoria/antoine/Gt51/Eval_deﬁ.htrnl

Bear J ., Dowding J ., Shriberg E. (1992), Integrating multiple knowledge sources for detection and cor-
rection of repairs in Human-Computer dialogue, Actes de ACL’92, 56-63.

Blanche-Benveniste C., Bilger M., Rouget C., van den Eynde K. (1990), Le Francais parlé : e’tudes
grammaticales, Paris, CNRS Editions.

Bonneau-Maynard H., Devillers L. (1998), Acquisition, Transcription et Annotation du Corpus
Pariscorp, Rapport interne, Action de Recherche Concerte’e “dialogue oral ” de l ’AUF

Chanod J .P. (2000), Robust Parsing and Beyond, Kluwer, in Van Noord & Junqua (ed.), “Robustness in
Language Technology”.

Ejerhed E. (1993), Nouveaux courants en analyse syntaxique, T.A.L., Vol. 34.1, 61-82.

Goulian J . (2000), Représentations sémantiques pour la CAP dans le cadre d’ une application de demande
de renseignements touristiques, Rapport interne, laboratoire VALORIA, Université de Bretagne-Sud.

Grinberg D., Lafferty J ., Sleator D. (1995), A robust parsing algorithm for Link Grammar, Rapport de
recherche CMU-CS-TR-95-125, School of Computer Science, Carnegie Mellon University.

Hirschman L. (1998), Language understanding evaluations 2 lessons learned from MUC and ATIS, Actes
de LREC’98, Grenade, Espagne, 117-122.

Holan T., Kubon V., Oliva K., Platek M. (2000), On complexity of word order, T.A.L., Vol. 41.1, 273-300.
Karttunen L. (1996), Directed Replacement, Actes de ACL’96, Santa-Cruz.

Karttunen L., Chanod J .P., Grefenstette G., Schiller A. (1996), Regular expressions for language engi-
neering, Natural language Engineering, Vol. 2(4), 305-328.

Mel’cuk I.A. (1988), Dependency Syntax, Theory and practice, State University of New York Press, Alb.
Minker W., Waibel A., Mariani J . (1999), Stochastically based semantic analysis, Amsterdam, Kluwer.

den Os E., Boves L., Lamel L., Baggia P. (1999), Overview of the ARISE project, Actes de Eu-
rospeech’99, Budapest, Hongrie, 1527-1530.

Pierrel J .M., Romary L. (2000), Dialogue Homme-Machine, in Pierrel (ed.) “Ingénierie des langues”,
Hermes, 331-349.

Roukos S. (1995), Survey of the state of the art in Human Language Technology, Chapter language
representation, in Cole R.A. et al. (ed.), NSF & DG XHI de la communauté Européenne, CSLU, 35-42.

Sleator D., Temperley D. (1991), Parsing English with a Link Grammar, Rapport de recherche CMU-
CS-91-196, School of Computer Science, Carnegie Mellon University.

Tesniére L. (1959), Elements de syntaxe structurale, Paris, Klincksiek.

Van Noord G. (1997), Fsa utilities : a toolbox to manipulate ﬁnite-state automata, Springer Verlag, in
Raymond, Wood & Yu (ed.), “Automata Implementation”, 87-108.

Van Noord G., Bouma G., Koeling R., Nederhof M.J. (1998), Robust grammatical analysis for spoken
dialogue systems, Natural language Engineering, Vol. 1, 1-48.

