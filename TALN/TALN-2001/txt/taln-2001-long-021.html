<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Synonymies et vecteurs conceptuels</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2001, Tours, 2-5 juillet 2001
</p>
<p>Synonymies et vecteurs conceptuels
</p>
<p>Mathieu Lafourcade, Violaine Prince
LIRMM : De&#769;p. ARC, grp. TAL, Universite&#769; Montpellier 2
</p>
<p>161, rue Ada, 35392 Montpellier Cedex 5, France
www.lirmm.fr/&#732;lafourca - www.lirmm.fr/&#732;prince
</p>
<p>Re&#769;sume&#769; - Abstract
La synonymie est une relation importante en TAL mais qui reste proble&#769;matique. La distinction entre
synonymie relative et synonymie subjective permet de contourner certaines difficulte&#769;s. Dans le cadre des
vecteurs conceptuels, il est alors possible de de&#769;finir formellement des fonctions de test de synonymie et
d&#8217;en expe&#769;rimenter l&#8217;usage. Mots-cle&#769;s. Synonymie relative, synonymie subjective, approches statistiques,
distances the&#769;matiques.
Synonymy is a pivot relation in NLP but remains problematic. Putting forward, the distinction between
relative and subjective synonymy, allows us to circunvent some difficulties. In the framework of con-
ceptual vectors, it is then possible to formalize test functions for synonymy and to experiment their use.
Keywords. Relative synonymy, subjective synonymy, statistical approaches, thematic distances.
</p>
<p>1 Introduction
La synonymie est, avec l&#8217;hyperonymie, une des fonctions lexicales qui ont e&#769;te&#769; les plus e&#769;tudie&#769;es
en traitement automatique des langues, sans parler de la linguistique. Parmi les travaux les plus
re&#769;cents, dans la communaute&#769; franc&#807;aise, fortement de&#769;die&#769;s a&#768; la synonymie, on peut citer [Hamon
et al. 1999] qui traite de l&#8217;extraction de synonymes, et s&#8217;appuie essentiellement sur des liens
de synonymie pour faire e&#769;merger des structures de connaissances dans des textes techniques ;
ou encore, [Selva 1999], qui fonde en grande partie l&#8217;apprentissage du franc&#807;ais langue seconde
sur les fonctions lexicales et en particulier, la synonymie. On pensera e&#769;galement aux travaux
multiples sur l&#8217;extraction des relations se&#769;mantiques en ge&#769;ne&#769;ral, a&#768; partir de corpus : citons, dans
le paysage francophone, les actions incitatives (au sein de l&#8217;ARC A3 de l&#8217;Aupelf-Uref), les
the&#768;ses (par exemple [Morin 1999]), et dans la communaute&#769; anglo-saxonne, les travaux re&#769;alise&#769;s a&#768;
partir de Wordnet [Hearst 1998].
Si la synonymie est une relation e&#769;tudie&#769;e en TAL c&#8217;est parce qu&#8217;elle permet, entre autres : a)
d&#8217;aider a&#768; la constitution de dictionnaires ; b) de re&#769;aliser une recherche d&#8217;information plus fine
que le simple appariement d&#8217;une cha&#305;&#770;ne de caracte&#768;res ; c) de ne pas multiplier les concepts dans
les bases de connaissances (un me&#770;me concept sera associe&#769; a&#768; une liste de termes synonymes) ; d)
de ge&#769;rer une qualite&#769; stylistique en ge&#769;ne&#769;ration.
Quelques proprie&#769;te&#769;s de la synonymie sont cependant proble&#769;matiques. Telle qu&#8217;elle est entendue,
la synonymie devrait e&#770;tre une relation d&#8217;e&#769;quivalence se&#769;mantique entre termes. Or, pour que cette
e&#769;quivalence soit exploitable sur le plan formel, la relation devrait e&#770;tre re&#769;flexive, syme&#769;trique
et transitive. Malheureusement, ces proprie&#769;te&#769;s ne sont pas toujours ve&#769;rifie&#769;es comme nous le
montrons plus loin.
Dans cet article, nous abordons d&#8217;abord les proble&#768;mes lie&#769;s a&#768; la synonymie, ce qui nous conduit
a&#768; de&#769;finir plusieurs types de synonymies et a&#768; pre&#769;ciser le concept de synonymie relative. Nous
pre&#769;sentons ensuite de fac&#807;on ge&#769;ne&#769;rale, les notions et les traitements lie&#769;s aux vecteurs conceptuels</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Lafourcade et Prince
</p>
<p>qui sont au c&#339;ur du formalisme que nous avons choisi d&#8217;adopter. Nous pre&#769;cisons enfin les
diffe&#769;rentes fonctions de test lie&#769;es aux synonymies. Ces fonctions sont base&#769;es sur les vecteurs
conceptuels.
</p>
<p>2 Synonymies
Un des premiers de&#769;fauts connus de la synonymie, en tant que relation entre termes c&#8217;est qu&#8217;elle
n&#8217;est pas ne&#769;cessairement transitive, lorsque l&#8217;on prend les termes deux a&#768; deux, sans plus de
pre&#769;cautions [Lewis 1952]. Ainsi par exemple, &#0; trier &#1; et &#0; ordonner &#1; , &#0; trier &#1; et &#0; choisir &#1; , qui sont syn-
onymes deux a&#768; deux, sont tels que &#0; ordonner &#1; et &#0; choisir &#1; ne sont pas synonymes. En pratique, au
moins trois concepts sont de&#769;signe&#769;s par &#0; trier &#1; : ORDONNER
</p>
<p>&#2;
</p>
<p>trier une liste de cinquante e&#769;le&#769;ments &#3; les
e&#769;le&#769;ments de la liste sont mis dans un ordre donne&#769; mais aucun d&#8217;eux n&#8217;est soustrait ; CHOISIR
</p>
<p>&#2;
</p>
<p>c&#8217;est
un personnel trie&#769; &#3; ou les personnes se&#769;lectionne&#769;es constituent un sous-ensemble d&#8217;un ensemble
possible de personnes ; et enfin, R &#180;EPARTIR
</p>
<p>&#2;
</p>
<p>trier le courrier &#3; . [Fischer 1973] montre que la syn-
onymie est au mieux une relation de tole&#769;rance1.
Le deuxie&#768;me de&#769;faut de la synonymie est qu&#8217;elle peut se confondre au moins partiellement avec
l&#8217;hyperonymie. Par exemple, &#0; morceler &#1; a pour synonyme &#0; couper &#1; alors qu&#8217;il en est hyponyme.
On a, en effet, MORCELER
</p>
<p>&#2;
</p>
<p>couper en plusieurs morceaux &#3; , par opposition a&#768; l&#8217;ide&#769;e de couper en deux,
ou couper dans le sens de soustraire une partie. Ce de&#769;faut fait appara&#305;&#770;tre une fragilite&#769; dans la
syme&#769;trie de la relation, ce qui remet me&#770;me en cause son statut de relation de tole&#769;rance au sens
fort. En effet, si un hyperonyme appara&#305;&#770;t comme synonyme parce que le terme partage avec lui
toutes ses proprie&#769;te&#769;s, en revanche sur un plan se&#769;mantique, l&#8217;hyponyme n&#8217;est pas un synonyme.
Ainsi &#0; cisailler &#1; n&#8217;appara&#305;&#770;t pas comme synonyme de &#0; couper &#1; , alors que l&#8217;inverse semble plus
admissible.
Enfin, il y a une petite &#8220;de&#769;convenue&#8221; pre&#769;visible qui veut que deux hyponymes d&#8217;un me&#770;me
terme, tout en e&#769;tant parents, ne sont pas force&#769;ment synonymes. Si &#0; poignarder &#1; et &#0; abattre &#1; sont
hyponymes d&#8217; &#0; assassiner &#1; , ils ne sont pas en mesure de pre&#769;senter des qualite&#769;s de synonymie.
Ce qui ame&#768;ne a&#768; de&#769;finir la synonymie comme la qualite&#769;, pour deux termes, de partager le
plus grand nombre de contenus se&#769;mantiques2, ou avoir la plus grande base commune possible
(lorsqu&#8217;il s&#8217;agit d&#8217;une repre&#769;sentation plus nume&#769;rique ou topologique). `A l&#8217;inverse, on remar-
quera e&#769;galement, que la polyse&#769;mie d&#8217;un terme peut faire qu&#8217;il ait plusieurs hyperonymes.
Par conse&#769;quent, si l&#8217;on souhaite exploiter les liens de synonymie entre termes pour faire de
l&#8217;indexation, de la recherche d&#8217;information dans un corpus, ou pour ge&#769;ne&#769;rer du texte, il est
important de de&#769;finir des relations de synonymie qui pourraient avoir de meilleures proprie&#769;te&#769;s
que celles de la synonymie vue in abstracto.
</p>
<p>2.1 Notion de Synonymie relative
Pour pallier le premier de&#769;faut, nous avions propose&#769; de&#768;s 1991 [Prince 1991] une notion de syn-
onymie relative qui part du principe que deux termes peuvent e&#770;tre synonymes par rapport a&#768;
l&#8217;ide&#769;e centrale de&#769;veloppe&#769;e par un troisie&#768;me, ou par un des deux. Cette notion avait de&#769;ja&#768; e&#769;te&#769;
appre&#769;hende&#769;e par [Sabah 1984] sous la forme de synonymie approche&#769;e contextuelle dans un
mode&#768;le lexical de type re&#769;seau se&#769;mantique. Ainsi, &#0; trier &#1; et &#0; choisir &#1; sont synonymes par rap-
port au concept discriminant de CHOISIR, alors que &#0; trier &#1; et &#0; ranger &#1; sont synonymes par rapport
a&#768; RANGER.
</p>
<p>1Une relation de tole&#769;rance peut-e&#770;tre syme&#769;trique et re&#769;flexive mais n&#8217;est pas transitive. Il existe plusieurs niveaux
de tole&#769;rance, selon le nombre de proprie&#769;te&#769;s ve&#769;rifie&#769;es.
</p>
<p>2La se&#769;mantique componentielle dirait : le plus grand nombre de se&#768;mes communs.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Synonymies et vecteurs conceptuels
</p>
<p>Avec un troisie&#768;me terme, cela peut fonctionner de la me&#770;me manie&#768;re. Le concept ORDONNER,
permet de lier &#0; trier &#1; et &#0; ranger &#1; , &#0; trier &#1; et &#0; ordonner &#1; , &#0; trier &#1; et &#0; ventiler &#1; . L&#8217;ide&#769;e est que tous les
synonymes, par rapport a&#768; un me&#770;me tiers (qui peut e&#770;tre en l&#8217;occurrence, l&#8217;un des termes), sont
synonymes entre eux deux a&#768; deux ; de&#768;s lors, la synonymie relative au tiers est transitive. Par
exemple, &#0; choisir &#1; et &#0; se&#769;lectionner &#1; sont synonymes par rapport a&#768; CHOISIR, par conse&#769;quent, &#0; trier &#1;
et &#0; se&#769;lectionner &#1; le sont aussi.
L&#8217;inte&#769;re&#770;t d&#8217;une telle relation est qu&#8217;elle devient alors une relation d&#8217;e&#769;quivalence (une de&#769;monstration
formelle en a e&#769;te&#769; faite dans [Prince op. cit]), ce qui rend toute sa valeur au lien de synonymie.
</p>
<p>2.2 Notion de Synonymie subjective
Si on veut utiliser plus largement la synonymie dans le cadre de l&#8217;indexation ou de la recherche
d&#8217;information, il faudrait tenir compte d&#8217;une notion de synonymie &#8220;force&#769;e&#8221; par un point de vue.
Bien que deux hyponymes d&#8217;un me&#770;me terme ne soient pas synonymes si on se place dans le
champs se&#769;mantique le plus proche de ces termes, il n&#8217;en va pas de me&#770;me lorsque l&#8217;on s&#8217;e&#769;loigne
se&#769;mantiquement d&#8217;eux.
Ainsi, dans des textes consacre&#769;s a&#768; l&#8217;usinage, the&#768;me qui fera figure de concept point de vue,
</p>
<p>&#0;
</p>
<p>cisailler &#1; et &#0; morceler &#1; seront force&#769;ment diffe&#769;rencie&#769;s et doivent l&#8217;e&#770;tre lors de l&#8217;indexation. En
revanche, dans un texte consacre&#769; au transport, on peut ne&#769;gliger la diffe&#769;rence entre ces termes,
voire les assimiler a&#768; leur hyperonyme &#0; couper &#1; . C&#8217;est cette capacite&#769; a&#768; &#8220;confondre&#8221; des termes
parce que leur diffe&#769;rence se&#769;mantique est faible au regard de la the&#769;matique ge&#769;ne&#769;rale que nous
nommons synonymie subjective.
La synonymie subjective reste une notion ope&#769;ratoire de&#769;finie pour des besoins de recherche
d&#8217;information, par opposition a&#768; a) la synonymie he&#769;rite&#769;e qui est une proprie&#769;te&#769; fonctionelle de
l&#8217;hyperonymie, et b) la synonymie relative, ou&#768; le concept pivot est un des sens des termes
polyse&#768;mes a&#768; comparer, et qui est une proprie&#769;te&#769; fonctionnelle de la polyse&#769;mie.
</p>
<p>3 Vecteurs conceptuels
Dans le cadre de recherche sur la repre&#769;sentation du sens en TALN et son application a&#768; la
recherche d&#8217;information, nous nous concentrons sur la repre&#769;sentation de l&#8217;aspect the&#769;matique
(des segments textuels tels que les documents, paragraphes, syntagmes, etc.) sous la forme de
vecteurs conceptuels [Lafourcade et Sanford 1999]. Cette approche tire son origine de [Chauche&#769;
1990] pour l&#8217;utilisation d&#8217;un jeu de concepts pre&#769;de&#769;termine&#769;, mais s&#8217;inspire aussi du mode&#768;le vec-
toriel [Salton et MacGill 1983] et du mode&#768;le LSI [Deerwester et all. 1990] pour la reconnaissance
et l&#8217;exploitation de l&#8217;inter-de&#769;pendance des concepts. Par contre, son application a&#768; l&#8217;indexation
et la recherche d&#8217;information textuelle se distingue nettement de [Salton 1988], en ce qu&#8217;elle
se base explicitement pour son calcul sur la ge&#769;ome&#769;trie et les variables morphosyntaxiques des
arbres d&#8217;analyse structurelle issus du texte et non pas sur une analyse de surface par mots-
cle&#769;s. D&#8217;une fac&#807;on ge&#769;ne&#769;rale les documents sont traite&#769;s inde&#769;pendamment (ce qui constitue une
diffe&#769;rence majeure d&#8217;avec LSI) et l&#8217;accent est mis sur la se&#769;lection lexicale en contexte. Les
me&#770;mes conside&#769;rations peut e&#770;tre faite avec [Resnik 1995] a&#768; propos de l&#8217;usage exclusif de tax-
onomies.
Pour me&#769;moire, le mode&#768;le de vecteurs conceptuels s&#8217;appuie paradigmatiquement sur la projec-
tion dans un mode&#768;le mathe&#769;matique de la notion linguistique de champ se&#769;mantique. Les concepts
sont de&#769;finis selon un the&#769;saurus (en ce qui nous concerne, il s&#8217;agit de la langue franc&#807;aise [Larousse
1992] ou&#768; 873 concepts sont re&#769;pertorie&#769;s). L&#8217;hypothe&#768;se principale est que cet ensemble forme un</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Lafourcade et Prince
</p>
<p>espace ge&#769;ne&#769;rateur pour les mots de la langue (espace qui n&#8217;est probablement pas libre). De&#768;s
lors, tout mot se projette sur cet espace selon le principe e&#769;nonce&#769; ci-apre&#768;s.
</p>
<p>3.1 Principe
Soit
</p>
<p>&#0;
</p>
<p>un ensemble fini de &#1; concepts. Un vecteur conceptuel &#2; est une combinaison line&#769;aire
des e&#769;le&#769;ments &#3; &#4; de
</p>
<p>&#0;
</p>
<p>. Pour un sens &#5; , le vecteur &#2;&#7;&#6; est la description (en extension) des acti-
vations des concepts de
</p>
<p>&#0;
</p>
<p>. Par exemple, les sens de &#8; ranger &#9; et de &#8; couper &#9; peuvent e&#770;tre projete&#769;s
sur les concepts suivant (les CONCEPT &#10; intensite&#769; &#11; e&#769;tant ordonne&#769;s par intensite&#769; de&#769;croissante) :
</p>
<p>&#2;&#13;&#12; &#14; &#15; &#16; &#17; &#12;&#19;&#18; (CHANGEMENT &#10; 0.84 &#11; , VARIATION &#10; 0.83 &#11; ,
&#180;EVOLUTION &#10; 0.82 &#11; , ORDRE &#10; 0.77 &#11; , SITUATION &#10; 0.76 &#11; ,
STRUCTURE &#10; 0.76 &#11; , RANG &#10; 0.76 &#11;&#21;&#20; &#20; &#20; ).
</p>
<p>&#2;&#7;&#22; &#23; &#24; &#25; &#17; &#12;&#26;&#18; (JEU &#10; 0.8 &#11; , LIQUIDE &#10; 0.8 &#11; , CROIX &#10; 0.79 &#11; ,
PARTIE &#10; 0.78 &#11; M &#180;ELANGE &#10; 0.78 &#11; FRACTION &#10; 0.75 &#11; SUP-
PLICE &#10; 0.75 &#11; BLESSURE &#10; 0.75 &#11; BOISSON &#10; 0.74 &#11;ff&#20; &#20; &#20; ).
</p>
<p>La description du processus d&#8217;apprentissage calculant les valeurs respectives des intensite&#769;s pour
chaque coordonne&#769;es d&#8217;un vecteur a e&#769;te&#769; expose&#769; dans [Lafourcade 2001]. Il est clair, que pour des
vecteurs denses (ayant te&#768;s peu de coordonne&#769;es nulles), l&#8217;e&#769;nume&#769;ration des concepts active&#769;s est
vite fastidieuse et surtout difficile a&#768; e&#769;valuer. On pre&#769;ferera en ge&#769;ne&#769;ral, proce&#769;der par se&#769;lection
de termes the&#769;matiquement proches (cf 3.2). Par exemple, les termes proches (et ordonne&#769;s par
distance the&#769;matique de&#769;croissante) des mots &#8; ranger &#9; et &#8; couper &#9; sont :
fi ranger fl : fi trier fl , fi cataloguer fl , fi se&#769;lectionner fl ,
fi
</p>
<p>classer fl , fi distribuer fl , fi grouper fl , fi ordonner fl ,
fi
</p>
<p>re&#769;partir fl , fi aligner fl , fi caser fl , fi arranger fl , fi nettoyer fl ,
fi distribuer fl , fi de&#769;me&#770;ler fl , fi ajuster fl&#31;ffi ffi ffi
</p>
<p>fi couper fl : fi cisailler fl , fi e&#769;mincer fl , fi scier fl ,
fi tronc&#807;onnner fl , fi e&#769;barber fl , fi entrecouper fl , fi baptiser fl ,
fi
</p>
<p>recouper fl , fi sectionner fl , fi be&#770;cher fl , fi hongrer fl ,
fi
</p>
<p>essoriller fl , fi rogner fl , fi e&#769;gorger fl , fi e&#769;cimer fl , ffi ffi ffi
</p>
<p>En pratique, plus
&#0;
</p>
<p>est grand, plus fines seront les descriptions de sens offertes par les vecteurs,
mais plus leur manipulation informatique est lourde (on rappelle que dans nos expe&#769;rimentations,
 &#13;! &quot;$# &#0;&amp;%
</p>
<p>&#18;('*) + , ce qui correspond au niveau 4 des concepts de&#769;finis dans [Larousse op. cit.].) La
construction d&#8217;un lexique conceptuel (ensemble de triplets (mot, variables morphologiques,
vecteur)) est re&#769;alise&#769;e automatiquement a&#768; partir de corpora (de de&#769;finitions, de the&#769;saurii, etc.
[Lafourcade op. cit.]). Au moment de l&#8217;e&#769;criture de cet article, le corpus du franc&#807;ais repre&#769;sente en-
viron , -*.&#31;.&#31;.&#31;. de&#769;finitions correspondants a&#768; /&#31;0&#31;.&#31;.&#31;. mots vedettes (pour 0&#31;/&#31;.&#31;.&#31;. mots monose&#769;miques
et 0*) .&#31;.&#31;. mots polyse&#769;miques - pour ces derniers le nombre moyen de de&#769;finitions, certaines
e&#769;ventuellement redondantes, e&#769;tant de -&#7;&#20; / - ).
</p>
<p>3.2 Distance angulaire
Il est souhaitable de pouvoir mesurer la proximite&#769; entre les sens repre&#769;sente&#769;s par deux vecteurs (et
donc celle de leur mot associe&#769;). Soit 1&amp;2 3 # 4$5 67% la mesure de similarite&#769;, utilise&#769;e habituellement
en recherche d&#8217;informations, entre deux vecteurs de&#769;finie selon la formule (1) ci-dessous (avec
&#8220; 8 &#8221; e&#769;tant le produit scalaire). On notera que l&#8217;on suppose ici que les composantes des vecteurs
sont toujours positives ou nulles (ce qui n&#8217;est pas ne&#769;cessairement le cas). Enfin, nous de&#769;finissons
une fonction de distance angulaire 9:&#6; entre deux vecteurs
</p>
<p>4
</p>
<p>et
6
</p>
<p>selon la formule (2).
</p>
<p>1&amp;2 3
</p>
<p># 4$5 67%
</p>
<p>&#18;&lt;; =*&gt;
</p>
<p># 4$5 6?%
</p>
<p>&#18;
</p>
<p>4
</p>
<p>8
</p>
<p>6
</p>
<p>@
</p>
<p>4
</p>
<p>@BAC@
</p>
<p>6
</p>
<p>@ (1)
9B&#6;
</p>
<p># 4$5 67%
</p>
<p>&#18;&lt;D E ; ; =*&gt;
</p>
<p>#
</p>
<p>1&amp;2 3
</p>
<p># 4$5 67% % (2)
Intuitivement, cette fonction constitue une e&#769;valuation de la proximite&#769; the&#769;matique et est en pra-
tique la mesure de l&#8217;angle forme&#769; par les deux vecteurs. On conside&#769;rera, en ge&#769;ne&#769;ral, que pour</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Synonymies et vecteurs conceptuels
</p>
<p>une distance &#0;&#2;&#1;&#4;&#3; &#5;&#7;&#6; &#8;&#10;&#9;&#12;&#11;&#14;&#13;&#16;&#15; &#17; , &#5; et &#8; sont se&#769;mantiquement proche et partagent des concepts.
Pour
</p>
<p>&#0;&#2;&#1;&#4;&#3; &#5;&#7;&#6; &#8;&#10;&#9;&#19;&#18;&#20;&#13;&#16;&#15; &#17;
</p>
<p>, la proximite&#769; se&#769;mantique de &#21; et &#22; sera conside&#769;re&#769;e comme faible.
Aux alentours de &#13;&#16;&#15; &#23; , les sens sont sans rapport. La synonymie (dans son acception la plus
large) est incluse dans la proximite&#769; the&#769;matique, cependant elle exige de plus la concordance des
cate&#769;gories morphosyntaxiques. L&#8217;inverse n&#8217;est e&#769;videment pas vrai.
Il s&#8217;agit d&#8217;une vraie distance (contrairement a&#768; la mesure de similarite&#769;) et elle ve&#769;rifie les pro-
prie&#769;te&#769;s de re&#769;flexivite&#769; (3), syme&#769;trie (4) et ine&#769;galite&#769; triangulaire (5) :
</p>
<p>&#0;&#2;&#1;&#4;&#3; &#5;&#7;&#6; &#5;&#24;&#9;&#12;&#25;ff&#26; (3)
&#0;&#2;&#1;&#4;&#3; &#5;&#7;&#6; &#8;&#10;&#9;&#4;&#25;fi&#0;&#2;&#1;&#4;&#3; &#8;fl&#6; &#5;&#24;&#9; (4)
</p>
<p>&#0;&#2;&#1;&#4;&#3; &#5;&#7;&#6; &#8;&#10;&#9;&#31;ffi &#0;&#2;&#1;&#4;&#3; &#8;fl&#6; !&quot;&#9;fl&#18;fi&#0;&#2;&#1;&#4;&#3; &#5;&#7;&#6; !&quot;&#9; (5)
</p>
<p>Par de&#769;finition, nous posons : &#0;#&#1;&#4;&#3; $% &#6;&amp;$% &#9;'&#25;(&#26; et &#0;&#2;&#1;&#4;&#3; &#5;&#7;&#6;&amp;$% &#9;&#10;&#25;(&#13;&#16;&#15; &#23; avec $% de&#769;notant le vecteur
nul3. On conside&#769;rera, en toute ge&#769;ne&#769;ralite&#769;, l&#8217;extension du domaine image de &#0;)&#1; a&#768; * &#26;+&#6; &#13;-, afin de
comparer des vecteurs ayant des composantes ne&#769;gatives. Cette ge&#769;ne&#769;ralisation ne change pas les
proprie&#769;te&#769;s de &#0;&#2;&#1; . On remarquera, de plus, que la distance angulaire est insensible a&#768; la norme
des vecteurs ( . et / e&#769;tant des scalaires) :
</p>
<p>&#0;&#2;&#1;&#4;&#3;
</p>
<p>.
</p>
<p>&#5;&#7;&#6;
</p>
<p>/
</p>
<p>&#8;)&#9;fl&#25;fi&#0;&#2;&#1;&#4;&#3; &#5;&#7;&#6; &#8;)&#9;
</p>
<p>avec .&#31;/10
&#26; (6)
</p>
<p>&#0;&#2;&#1;&#4;&#3;
</p>
<p>.
</p>
<p>&#5;&#7;&#6;
</p>
<p>/
</p>
<p>&#8;&#10;&#9;&#4;&#25;ff&#13;32 &#0;&#2;&#1;&#4;&#3; &#5;&#7;&#6; &#8;)&#9;
</p>
<p>avec .&#31;/14
&#26; (7)
</p>
<p>Par exemple4 dans le tableau qui suit, nous avons les distances angulaire (en radian) entre les
vecteurs de plusieurs termes. Le tableau est syme&#769;trique (a&#768; cause de la syme&#769;trie de &#0;)&#1; ) et la
diagonale est toujours e&#769;gale a&#768; &#26; (a&#768; cause de la re&#769;flexivite&#769; de &#0;#&#1; ). On remarquera qu&#8217;une valeur
prend toute sa signification relativement a&#768; une autre. En particulier, il est satisfaisant d&#8217;avoir,
par exemple : a) 5+6 &#11; 587 et 5&amp;9 &#11; 587 ce qui correspond bien au fait que : trier ; et : ordonner ; d&#8217;une
part, et : trier ; et : choisir ; sont &#8220;plus synonymes&#8221; que : ordonner ; et : choisir ; ; b) 5&amp;&lt; est la plus
petite valeur de &#0;&#2;&#1;&#4;&#3; ranger &#6; &#8;#&#9; car les concepts CLASSER et R &#180;EPARTIR sont relativement proches, et
de plus : ranger ; est par ailleurs polyse&#769;mique (CLASSER, RASSEMBLER et NETTOYER) et seul CLASSER est
pre&#769;sent dans le tableau.
</p>
<p>=fl&gt;&#16;? @&#2;A B&#12;C
</p>
<p>trier ranger choisir ordonner ventiler classer re&#769;partir
trier 0.0 0.517 0.662 D8E 0.611 D F 0.551 0.441 0.462
ranger 0.0 0.829 0.6 0.523 0.409 D G 0.444
choisir 0.0 0.848 D H 0.77 0.796 0.758
ordonner 0.0 0.595 0.523 0.519
ventiler 0.0 0.471 0.391
classer 0.0 0.36
re&#769;partir 0.0
</p>
<p>3.3 Ope&#769;rateurs
Somme vectorielle. Soit &#5; et &#8; deux vecteurs, on de&#769;finit I comme leur somme norme&#769;e :
</p>
<p>I
</p>
<p>&#25;&#14;&#5;KJ &#8;MLON P&#31;&#25;fi&#3; QRPRffi1S P &#9; &#15;RT
</p>
<p>I
</p>
<p>T (8)
3Le vecteur n&#8217;est sans doute pas repre&#769;sente&#769; par un mot de la langue. Il s&#8217;agit d&#8217;une ide&#769;e qui n&#8217;active U U U aucun
</p>
<p>concept ! C&#8217;est l&#8217;ide&#769;e vide.
4Tous les exemples de cet article sont issus de &lt;http://www.lirmm.fr/&#732;lafourca&gt;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Lafourcade et Prince
</p>
<p>Cet ope&#769;rateur est idempotent et nous avons &#0;&#2;&#1;&#3;&#0;&#5;&#4;&#6;&#0; . Le vecteur nul
&#7;
</p>
<p>&#8;
</p>
<p>est l&#8217;e&#769;le&#769;ment neutre
de la somme vectorielle et, par de&#769;finition, nous posons que
</p>
<p>&#7;
</p>
<p>&#8;
</p>
<p>&#1;
</p>
<p>&#7;
</p>
<p>&#8;
</p>
<p>&#4;
</p>
<p>&#7;
</p>
<p>&#8;
</p>
<p>. De ce qui pre&#769;ce&#768;de, nous
de&#769;duisons (sans le de&#769;montrer) les proprie&#769;te&#769;s de rapprochement (local et ge&#769;ne&#769;ralise&#769;) :
</p>
<p>&#9;&#11;&#10;&#13;&#12; &#0;&#2;&#1;&#3;&#0;&#15;&#14; &#16;&#17;&#1;&#3;&#0;&#19;&#18;&#20;&#4;&#17;&#9;&#11;&#10;&#13;&#12; &#0;&#15;&#14; &#16;&#21;&#1;&#3;&#0;&#19;&#18;&#23;&#22;&#17;&#9;&#11;&#10;&#13;&#12; &#0;&#15;&#14; &#16;&#24;&#18; (9)
&#9;&#11;&#10;&#13;&#12; &#0;&#25;&#1;&#6;&#26;ff&#14; &#16;&#17;&#1;fi&#26;fl&#18;&#20;&#22;&#17;&#9;&#11;&#10;&#13;&#12; &#0;&#15;&#14; &#16;&#24;&#18; (10)
</p>
<p>Soustraction vectorielle. Soit &#0; et &#16; deux vecteurs distincts, on de&#769;finit ffi comme leur sous-
traction norme&#769;e :
</p>
<p>ffi
</p>
<p>&#4;fi&#0;&#25;&#31;&#3;&#16;! #&quot; $%&#4;&amp;&#12; '($*)&#3;+ $ &#18; ,(-
</p>
<p>ffi
</p>
<p>- (11)
</p>
<p>Cet ope&#769;rateur n&#8217;est pas idempotent et on aura par de&#769;finition : ffi &#4;fi&#0;&#2;&#31;&#3;&#0;.&#4;
&#7;
</p>
<p>&#8;
</p>
<p>. On remarquera
que, dans le cas ge&#769;ne&#769;ral, les valeurs &quot;/$ peuvent e&#770;tre ne&#769;gatives et que la fonction de distance a
son image sur 0 1 &#14; 2%3 .
Produit terme a&#768; terme normalise&#769;. Soit &#0; et &#16; deux vecteurs, on de&#769;finit ffi comme leur produit
terme a&#768; terme normalise&#769; :
</p>
<p>ffi
</p>
<p>&#4;fi&#0;&#2;4&#6;&#16;! 5&quot; $6&#4;&#21;7 '($ + $ (12)
</p>
<p>Cet ope&#769;rateur est idempotent ( ffi &#4;&#6;&#0;&#25;4&#3;&#0;.&#4;fi&#0; ) et
&#7;
</p>
<p>&#8;
</p>
<p>est absorbant ( ffi &#4;&#6;&#0;&#25;4
&#7;
</p>
<p>&#8;
</p>
<p>&#4;
</p>
<p>&#7;
</p>
<p>&#8; ).
Contextualisation et Anti-contextualisation. Lorsque que deux termes sont en pre&#769;sence, pour
chacun d&#8217;eux certains de leur sens se trouvent se&#769;lectionne&#769;s par le contexte que constitue l&#8217;autre
terme. Ce phe&#769;nome&#768;ne de contextualisation consiste a&#768; augmenter chaque sens de ce qu&#8217;il a de
commun avec l&#8217;autre. `A des fins ope&#769;ratoires, nous de&#769;finissons e&#769;galement la fonction oppose&#769;e,
l&#8217;anti-contextualisation. Soit &#0; et &#16; deux vecteurs, on de&#769;finit 8 &#12; &#0;&#15;&#14; &#16;&#24;&#18; (resp. 8 &#12; &#0;&#15;&#14; &#16;&#24;&#18; ) comme
la contextualisation (resp. l&#8217;anti-contextualisation) de &#0; par &#16; comme :
</p>
<p>8
</p>
<p>&#12; &#0;&#15;&#14; &#16;&#24;&#18;&#20;&#4;fi&#0;&#2;&#1;&#21;&#12; &#0;&#25;4&#3;&#16;&#24;&#18;
</p>
<p>et 8
&#12; &#0;&#15;&#14; &#16;&#24;&#18;&#20;&#4;&#6;&#0;&#25;&#31;&#21;&#12; &#0;&#2;4&#6;&#16;9&#18; (13)
</p>
<p>Ces fonctions ne sont pas syme&#769;triques. L&#8217;ope&#769;rateur 8 est idempotent ( 8 &#12; &#0;&#15;&#14; &#0;&#19;&#18;&#15;&#4;:&#0; ) et le
vecteur nul est un e&#769;le&#769;ment neutre ( 8 &#12; &#0;&#15;&#14;
</p>
<p>&#7;
</p>
<p>&#8;
</p>
<p>&#18;&#19;&#4;;&#0;;&#1;
</p>
<p>&#7;
</p>
<p>&#8;
</p>
<p>&#4;;&#0; ). L&#8217;ope&#769;rateur 8 est nulpotent
( 8 &#12; &#0;&#15;&#14; &#0;&#19;&#18;&#15;&#4;.&#0;&#5;&#31;&#17;&#0;&lt;&#4;
</p>
<p>&#7;
</p>
<p>&#8; ) et
&#7;
</p>
<p>&#8;
</p>
<p>est e&#769;galement un e&#769;le&#769;ment neutre. On remarquera (sans les
de&#769;montrer) que nous avons les proprie&#769;te&#769;s (de rapprochement et d&#8217;e&#769;loignement) suivantes :
</p>
<p>&#9;&#11;&#10;&#13;&#12;
</p>
<p>8
</p>
<p>&#12; &#0;&#15;&#14; &#16;&#24;&#18; &#14;
</p>
<p>8
</p>
<p>&#12; &#16;&#20;&#14; &#0;&#19;&#18; &#18;&#23;&#22;&#17;=&gt;&#9;&#11;&#10;&#13;&#12; &#0;&#15;&#14;
</p>
<p>8
</p>
<p>&#12; &#16;&#20;&#14; &#0;&#19;&#18; &#18; &#14; &#9;&#11;&#10;&#13;&#12;
</p>
<p>8
</p>
<p>&#12; &#0;&#15;&#14; &#16;&#24;&#18; &#14; &#16;9&#18; ?@&#22;&#17;&#9;&#11;&#10;&#13;&#12; &#0;&#15;&#14; &#16;&#24;&#18; (14)
&#9;&#11;&#10;&#13;&#12;
</p>
<p>8
</p>
<p>&#12; &#0;&#15;&#14; &#16;&#24;&#18; &#14;
</p>
<p>8
</p>
<p>&#12; &#16;&#20;&#14; &#0;&#19;&#18; &#18;&#23;A&#17;=&gt;&#9;&#11;&#10;&#13;&#12; &#0;&#15;&#14;
</p>
<p>8
</p>
<p>&#12; &#16;&#20;&#14; &#0;&#19;&#18; &#18; &#14; &#9;&#11;&#10;&#13;&#12;
</p>
<p>8
</p>
<p>&#12; &#0;&#15;&#14; &#16;&#24;&#18; &#14; &#16;9&#18; ?@A&#17;&#9;&#11;&#10;&#13;&#12; &#0;&#15;&#14; &#16;&#24;&#18; (15)
La contextualisation 8 &#12; &#0;&#15;&#14; &#16;&#24;&#18; rapproche le vecteur &#0; de &#16; proportionnellement a&#768; leur in-
tersection. L&#8217;anti-contextualisation 8 &#12; &#0;&#15;&#14; &#16;9&#18; proce&#768;de inversement. Dans la tableau qui suit,
nous avons dans la partie supe&#769;rieure les valeurs de (a) &#9;@&#10;&#13;&#12; 8 &#12; &#0;&#15;&#14; &#16;&#24;&#18; &#14; 8 &#12; &#16;&#20;&#14; &#0;&#19;&#18; &#18; et dans la partie
infe&#769;rieure les valeurs de (b) &#9;@&#10;&#13;&#12; 8 &#12; &#0;&#15;&#14; &#16;9&#18; &#14; 8 &#12; &#16;&#20;&#14; &#0;&#19;&#18; &#18; .
B C D
</p>
<p>trier ranger choisir ordonner ventiler classer re&#769;partir
trier 0.0 0.269 0.363 0.322 0.288 0.228 0.239
ranger 2.183 0.0 0.474 0.316 0.273 0.211 0.23
choisir 2.401 2.17 0.0 0.485 0.434 0.451 0.425
ordonner 2.382 2.374 2.314 0.0 0.313 0.272 0.27
ventiler 2.334 2.303 2.282 2.483 0.0 0.244 0.201
classer 2.505 2.481 2.313 2.648 2.535 0.0 0.185
re&#769;partir 2.476 2.388 2.364 2.637 2.53 2.761 0.0</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Synonymies et vecteurs conceptuels
</p>
<p>4 Synonymie Relative
Nous de&#769;finissons la fonction de synonymie relative
</p>
<p>&#0;&#2;&#1;&#4;&#3;&#6;&#5;
</p>
<p>entre trois vecteurs &#7; , &#8; et &#9; , ce
dernier jouant le ro&#770;le de pivot, comme suit :
</p>
<p>&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#2;&#11;
</p>
<p>&#7;&#13;&#12; &#8;&#14;&#12; &#9;&#13;&#15;&#17;&#16;&#19;&#18;&#21;&#20;
</p>
<p>&#11; &#22;&#17;&#11;
</p>
<p>&#7;&#13;&#12; &#9;&#13;&#15; &#12;
</p>
<p>&#22;&#17;&#11;
</p>
<p>&#8;&#14;&#12; &#9;&#13;&#15; &#15;
</p>
<p>&#16;&#19;&#18;&#21;&#20;
</p>
<p>&#11;
</p>
<p>&#7;&#24;&#23;
</p>
<p>&#11;
</p>
<p>&#7;&#26;&#25;&#26;&#9;&#13;&#15; &#12; &#8;ff&#23;
</p>
<p>&#11;
</p>
<p>&#8;fi&#25;ff&#9;&#13;&#15; &#15; (16)
L&#8217;interpre&#769;tation correspond bien a&#768; celle pre&#769;sente&#769;e ci-dessus, a&#768; savoir que l&#8217;on cherche a&#768; tester
la proximite&#769; the&#769;matique de deux sens ( &#7; et &#8; ), chacun augmente&#769; de ce qu&#8217;il a de commun avec
un tiers ( &#9; ).
</p>
<p>4.1 Proprie&#769;te&#769;s
Pour rendre compte des trois proprie&#769;te&#769;s the&#769;oriques de la relation de synonymie (re&#769;flexivite&#769;,
syme&#769;trie et transitivite&#769;), nous les ve&#769;rifions comme suit :
</p>
<p>1.
&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#2;&#11;
</p>
<p>&#7;&#13;&#12; &#7;&#13;&#12; &#9;&#13;&#15;&#17;&#16;fffl La re&#769;flexivite&#769; est he&#769;rite&#769;e de celle de la distance angulaire &#18;&#13;&#20; .
2.
&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#2;&#11;
</p>
<p>&#7;&#13;&#12; &#8;&#14;&#12; &#9;&#13;&#15;ffi&#16;
</p>
<p>&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#17;&#11;
</p>
<p>&#8;&#14;&#12; &#7;&#13;&#12; &#9;&#13;&#15; La syme&#769;trie pour les deux premiers arguments,
provient e&#769;galement de celle de la distance angulaire.
</p>
<p>3.
&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#2;&#11;
</p>
<p>&#7;&#13;&#12; &#8;&#14;&#12; &#31;&#13;&#15;! 
</p>
<p>&#0;&#2;&#1;&#4;&#3;&#10;&#5;&quot;&#11;
</p>
<p>&#8;&#14;&#12; &#9;#&#12; &#31;&#13;&#15;%$
</p>
<p>&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#17;&#11;
</p>
<p>&#7;&#13;&#12; &#9;#&#12; &#31;&#13;&#15; C&#8217;est un he&#769;ritage de l&#8217;ine&#769;galite&#769;
triangulaire de &#18;&#21;&#20; . Elle repre&#769;sente une forme de transivite&#769; pour la synonymie relative.
Elle est en outre plus pre&#769;cise que la ve&#769;rification de la proprie&#769;te&#769; de transitivite&#769; : elle indique
que la distance entre &#7; et &#9;#&amp;!&#31; est au pire e&#769;gale a&#768; la somme des mesures de synonymie
de &#7; et &#8;'&amp;!&#31; d&#8217;une part, et &#8; et &#9;#&amp;!&#31; d&#8217;autre part.
</p>
<p>4.
&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#2;&#11;
</p>
<p>&#7;&#13;&#12; &#8;&#14;&#12; fl(&#15;)&#16;*&#18;&#21;&#20;
</p>
<p>&#11;
</p>
<p>&#7;+&#23;-,
</p>
<p>.
</p>
<p>&#12; &#8;/&#23;0,
</p>
<p>.
</p>
<p>&#15;1&#16;2&#18;&#21;&#20;
</p>
<p>&#11;
</p>
<p>&#7;&#13;&#12; &#8;'&#15; Le vecteur nul ,. rame&#768;ne la
synonymie relative a&#768; la distance angulaire.
</p>
<p>5.
&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#2;&#11;
</p>
<p>&#7;&#13;&#12; &#8;&#14;&#12; &#9;&#13;&#15;&#2;3&#19;&#18;&#21;&#20;
</p>
<p>&#11;
</p>
<p>&#7;&#13;&#12; &#8;'&#15; Par he&#769;ritage du rapprochement de &#18;&#13;&#20; , quelque soit le
point de vue, la synonymie relative ne peut que rapprocher &#7; et &#8; .
</p>
<p>4.2 Exemples
Dans la tableau qui suit, nous avons dans la partie supe&#769;rieure le rappel des valeurs de (a)
&#18;&#21;&#20;
</p>
<p>&#11; 4
</p>
<p>&#12; 5&#14;&#15; et dans la partie infe&#769;rieure les valeurs de (b) &#0;&#2;&#1;&#4;&#3;&#6;&#5;&#17;&#11; 4 &#12; 5%&#12; trier &#15; .
On voit bien appara&#305;&#770;tre ici la mise en lumie&#768;re de la polyse&#769;mie. Nous avons, par exemple,
&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#2;&#11;
</p>
<p>classer &#12; ranger &#12; trier &#15; valant fl&#4;&#12; 6!7!8 , ce qui indique une forte synonymie relative de 9 classer :
et 9 ranger : par rapport a&#768; 9 trier : , chose que la distance angulaire correspondante ( fl&#4;&#12; ;(fl!&lt; ) n&#8217;indiquait
pas aussi fortement. `A l&#8217;inverse,
</p>
<p>&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#17;&#11;
</p>
<p>choisir &#12; ordonner &#12; trier &#15; vaut fl&#4;&#12; =!8!= , ce qui montre que
9 choisir : et 9 ordonner : ne sont pas synonymes entre eux par rapport a&#768; 9 trier : , alors qu&#8217;ils sont
deux synonymes possible de 9 trier : . La synonymie relative appara&#305;&#770;t comme un bon indicateur
de polyse&#769;mie : 9 choisir : et 9 ordonner : rele&#768;vent majoritairement des deux &#8220;zones&#8221; se&#769;mantiques
diffe&#769;rentes. De plus, 9 ordonner : est lui-me&#770;me polyse&#769;mique.
&gt; ? @
</p>
<p>trier ranger choisir ordonner ventiler classer re&#769;partir
trier 0.0 0.517 0.662 0.611 0.551 0.441 0.462
ranger 0.402 0.0 0.829 0.6 0.523 0.409 0.444
choisir 0.5 0.623 0.0 0.848 0.77 0.796 0.758
ordonner 0.478 0.43 0.636 0.0 0.595 0.523 0.519
ventiler 0.435 0.365 0.575 0.435 0.0 0.471 0.391
classer 0.369 0.283 0.607 0.385 0.344 0.0 0.36
re&#769;partir 0.376 0.309 0.57 0.383 0.272 0.268 0.0</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Lafourcade et Prince
</p>
<p>5 Synonymie Subjective
Nous de&#769;finissons la fonction de synonymie subjective &#0;&#2;&#1;&#4;&#3;&#6;&#5; entre trois vecteurs &#7; , &#8; et &#9; , ce
dernier jouant le ro&#770;le de point de vue, comme suit :
</p>
<p>&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#12;&#11;
</p>
<p>&#7;&#14;&#13; &#8;&#15;&#13; &#9;&#14;&#16;&#18;&#17;&#20;&#19;&#22;&#21;
</p>
<p>&#11; &#23;&#18;&#11;
</p>
<p>&#7;&#14;&#13; &#9;&#14;&#16; &#13;
</p>
<p>&#23;&#6;&#11;
</p>
<p>&#8;&#15;&#13; &#9;&#14;&#16; &#16;
</p>
<p>&#17;&#20;&#19;&#22;&#21;
</p>
<p>&#11;
</p>
<p>&#7;&#25;&#24;
</p>
<p>&#11;
</p>
<p>&#7;ff&#26;fi&#9;&#14;&#16; &#13; &#8;fi&#24;
</p>
<p>&#11;
</p>
<p>&#8;fl&#26;fi&#9;&#14;&#16; &#16; (17)
L&#8217;interpre&#769;tation naturelle consiste a&#768; conside&#769;rer &#9; comme un point de vue a&#768; partir duquel &#7; et
&#8; sont compare&#769;s. Plus le point de vue &#9; s&#8217;e&#769;loigne de &#7; et de &#8; , plus ceux-ci semblent se
confondre. `A l&#8217;inverse, plus &#9; est proche de &#7; et &#8; (plus il se trouve entre eux) plus il est a&#768;
me&#770;me de les distinguer.
Avec &#7;&#31;ffi&#17;&#20;&#8; ffi&#17;&#20;&#9; , nous avons donc : ! &#9;&quot;!$#&amp;%('
</p>
<p>&#0;&#2;&#1;&#4;&#3;&#6;&#5;&#12;&#11;
</p>
<p>&#7;&#14;&#13; &#8;&#15;&#13; &#9;&#14;&#16;&#18;#() .
</p>
<p>5.1 Proprie&#769;te&#769;s
Certaines des proprie&#769;te&#769;s de la synonymie subjective sont analogues a&#768; celle de la synonymie
relative, mis a&#768; part la dernie&#768;re qui est originale.
</p>
<p>1.
&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#12;&#11;
</p>
<p>&#7;&#14;&#13; &#8;&#15;&#13; &#9;&#14;&#16;*&#17;
</p>
<p>&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#12;&#11;
</p>
<p>&#8;&#15;&#13; &#7;&#14;&#13; &#9;&#14;&#16; Nous avons commutativite&#769; pour les deux pre-
miers arguments, par simple he&#769;ritage de la commutativite&#769; de la distance angulaire.
</p>
<p>2.
&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#12;&#11;
</p>
<p>&#7;&#14;&#13; &#8;&#15;&#13;,+
</p>
<p>-
</p>
<p>&#16;.&#17;/&#19;&#22;&#21;
</p>
<p>&#11;
</p>
<p>&#7;ff&#24;/+
</p>
<p>-
</p>
<p>&#13; &#8;fl&#24;0+
</p>
<p>-
</p>
<p>&#16;.&#17;1&#19;&#22;&#21;
</p>
<p>&#11;
</p>
<p>&#7;&#14;&#13; &#8;2&#16; Si le point de vue est le vecteur
nul on se rame&#768;ne a&#768; la distance angulaire.
</p>
<p>3.
&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#12;&#11;
</p>
<p>&#7;&#14;&#13; &#7;&#14;&#13; &#9;&#14;&#16;&#2;&#17;&#20;&#19;&#22;&#21;
</p>
<p>&#11;
</p>
<p>&#7;ff&#24;
</p>
<p>&#11;
</p>
<p>&#7;&#25;&#26;fi&#9;&#14;&#16; &#13; &#7;&#25;&#24;
</p>
<p>&#11;
</p>
<p>&#7;ff&#26;fi&#9;&#14;&#16; &#16;3&#17;fl) Deux sens identiques sont
toujours a&#768; une distance angulaire e&#769;gale a&#768; 0 quelque soit le point de vue.
</p>
<p>4.
&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#12;&#11;
</p>
<p>&#7;&#14;&#13; &#8;&#15;&#13; 4&#14;&#16;&#10;5
</p>
<p>&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#12;&#11;
</p>
<p>&#8;&#15;&#13; &#9;6&#13; 4&#14;&#16;37
</p>
<p>&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#12;&#11;
</p>
<p>&#7;&#14;&#13; &#9;6&#13; 4&#14;&#16;
</p>
<p>He&#769;ritage de l&#8217;ine&#769;galite&#769; triangulaire.
5.
&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#12;&#11;
</p>
<p>&#7;&#14;&#13; &#8;&#15;&#13; &#9;&#14;&#16;&#2;7&#20;&#19;&#22;&#21;
</p>
<p>&#11;
</p>
<p>&#7;&#14;&#13; &#8;2&#16; He&#769;ritage de l&#8217;e&#769;loignement.
6.
&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#12;&#11;
</p>
<p>&#7;&#14;&#13; &#8;&#15;&#13; &#8;2&#16;&#18;&#17;&#20;&#19;&#22;&#21;
</p>
<p>&#11;
</p>
<p>&#7;ff&#24;
</p>
<p>&#11;
</p>
<p>&#7;&#25;&#26;fi&#8;2&#16; &#13; &#8;fi&#24;
</p>
<p>&#11;
</p>
<p>&#8;fi&#26;fi&#8;2&#16; &#16;3&#17;fl&#19;&#22;&#21;
</p>
<p>&#11;
</p>
<p>&#7;ff&#24;
</p>
<p>&#11;
</p>
<p>&#7;&#25;&#26;fi&#8;2&#16; &#13;,+
</p>
<p>-
</p>
<p>&#16;&#2;&#17;fl8&#18;9 :
</p>
<p>&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#12;&#11;
</p>
<p>&#7;&#14;&#13; &#8;&#15;&#13; &#8;2&#16;;&#17;
</p>
<p>&#0;&#2;&#1;&#4;&#3;&#10;&#5;&#12;&#11;
</p>
<p>&#7;&#14;&#13; &#8;&#15;&#13; &#7;&#22;&#16; Si le point de vue est l&#8217;un des sens conside&#769;re&#769;s, la
discrimination de sens est maximale.
</p>
<p>5.2 Exemples
Dans la tableau qui suit, nous avons dans la partie supe&#769;rieure le rappel des valeurs de (a)
&#19;&#22;&#21;
</p>
<p>&#11; &lt;
</p>
<p>&#13; =&#15;&#16; et dans la partie infe&#769;rieure les valeurs de (b) &#0;&#2;&#1;&#4;&#3;&#6;&#5;&#12;&#11; &lt; &#13; =3&#13; trier &#16; .
&gt; ? @
</p>
<p>trier ranger choisir ordonner ventiler classer re&#769;partir
trier 0.0 0.517 0.662 0.611 0.551 0.441 0.462
ranger 1.571 0.0 0.829 0.6 0.523 0.409 0.444
choisir 1.571 1.643 0.0 0.848 0.77 0.796 0.758
ordonner 1.571 1.433 1.624 0.0 0.595 0.523 0.519
ventiler 1.571 1.395 1.543 1.36 0.0 0.471 0.391
classer 1.571 1.259 1.741 1.292 1.323 0.0 0.36
re&#769;partir 1.571 1.324 1.613 1.245 1.132 1.158 0.0
</p>
<p>On notera, en particulier, que la colonne correspondant a&#768; A trier B n&#8217;a que des valeurs e&#769;gales a&#768; 8&#18;9 : ,
ce qui est conforme a&#768; la proprie&#769;te&#769; 6. On remarque donc que la synonymie subjective agit comme
un &#8220;objectif&#8221;. Plus un terme se rapproche de point de vue, plus la discrimination est forte. Par
exemple, A re&#769;partir B et A ventiler B gardent le meilleur score ( CD&#13; C ED: ) car ils sont tre&#768;s proches entre
eux. Par contre, A ordonner B et A choisir B ont un score supe&#769;rieur a&#768; 8&#18;9 : . Dans ce cas la polyse&#769;mie
est bien discrimine&#769;e. C&#8217;est e&#769;galement le cas de A classer B et A choisir B ( CD&#13; F G&#12;C ).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Synonymies et vecteurs conceptuels
</p>
<p>6 Conclusion
Les travaux que nous avons mene&#769;s sur la synonymie dans des sources de connaissances lex-
icales ont montre&#769; que : 1) Dans une mode&#769;lisation globaliste comme celle des vecteurs con-
ceptuels, ou&#768; l&#8217;on travaille a&#768; partir de mots qui invoquent des ide&#769;es et non pas sur des con-
cepts qui se combinent en mots, la synonymie a des proprie&#769;te&#769;s pouvant s&#8217;exprimer sous formes
de mesure. 2) Pour que ces mesures de synonymie nous rapprochent des bonnes proprie&#769;te&#769;s
mathe&#769;matiques (e&#769;quivalence ou quasi-e&#769;quivalence) que l&#8217;on voudrait leur voir attribuer, nous
avons e&#769;te&#769; amene&#769;s a&#768; de&#769;finir deux types de synonymies : a) la synonymie relative, qui permet par
rapport a&#768; un the&#768;me donne&#769;, de montrer les groupements de termes qui seraient quasi-e&#769;quivalents
entre eux; et b) la synonymie subjective, qui appara&#305;&#770;t comme un discriminateur fort, si le the&#768;me
est se&#769;mantiquement proche des termes a&#768; examiner, ou au contraire, comme un me&#769;canisme de
lissage si le the&#768;me est e&#769;loigne&#769;.
Nous poursuivons nos travaux avec l&#8217;aide de ces deux mesures pour re&#769;aliser de la de&#769;tection
d&#8217;hyperonymie. Si cette dernie&#768;re appara&#305;&#770;t comme e&#769;vidente quand on travaille dans le sens
concept &#0; mot, elle est beaucoup plus difficile a&#768; asserter dans le sens mot &#0; concept. La
synonymie relative et la synonymie subjective qui traquent toutes deux a&#768; la fois la ressemblance
et la diffe&#769;rence se&#769;mantiques, forment une structure fonctionelle de base a&#768; partir de laquelle nous
cherchons a&#768; reconstruire bon nombre de fonctions lexicales de&#769;finies en linguistique.
</p>
<p>Re&#769;fe&#769;rences
Chauche&#769; J. De&#769;termination se&#769;mantique en anal-
yse structurelle : une expe&#769;rience base&#769;e sur une
de&#769;finition de distance. TA Information, 1990, vol
31/1, p 17-24.
</p>
<p>Deerwester S. and S. Dumais, T. Landauer, G.
Furnas, R. Harshman, Indexing by latent semantic
analysis. In Journal of the American, Society of
Information science, 1990, 416(6), p 391-407.
Fischer, W. L. &#168;Aquivalenz und Toleranz Strukturen
in der Linguistik zur Theory der Synonyma. Max
Hu&#776;ber Verlag, Mu&#776;nchen, 1973.
</p>
<p>Hamon, T. et D. Garcia, A. Nazarenko, De&#769;tection
de liens de synonymie : comple&#769;mentarite&#769; des
ressources ge&#769;ne&#769;rales et spe&#769;cialise&#769;es. Terminolo-
gies Nouvelles. 1999, pp 61-69.
</p>
<p>Hearst, M. A. Automated discovery of Wordnet re-
lations. In C Fellbaum ed. &#8221;Wordnet An Electronic
Lexical Database&#8221;. MIT Press, Cambridge, MA,
1998, pp 131-151.
</p>
<p>Lafourcade M. et E. Sandford, Analyse
et de&#769;sambigu&#168;isation lexicale par vecteurs
se&#769;mantiques. In Proc. of TALN&#8217;99 (Carge&#768;se, July
1999) pp 351-356.
Lafourcade M. Lexical sorting and lexical trans-
fer by conceptual vectors. In Proc. of The First
</p>
<p>International Workshop on MultiMedia Annotation
(MMA&#8217;2001) (Tokyo, January 2001) 6 p.
Larousse. The&#769;saurus Larousse - des ide&#769;es aux mots
- des mots au ide&#769;es. Larousse, ISBN 2-03-320-
148-1, 1992.
</p>
<p>Lewis, C. I. The modes of meaning. in Linsky ed,
&#8221;Semantics and the philosophy of language&#8221;. Ur-
bana. NY, 1952.
</p>
<p>Morin, E. Extraction de liens se&#769;mantiques entre
termes a&#768; partir de corpus techniques. The&#768;se de
doctorat de l&#8217;Universite&#769; de Nantes, 1999.
</p>
<p>Prince, V. Notes sur l&#8217;e&#769;valuation de la re&#769;ponse
dans TEDDI : introduction d&#8217;une relation
d&#8217;e&#769;quivalence pour la synonymie relative. Notes
et Documents LIMSI 91-20. 1991, CNRS. 22 p.
</p>
<p>Resnik P. Using Information contents to evaluate
semantic similarity in a taxonomy. In Proceedings
of IJCAI-95, 1995.
</p>
<p>Riloff E. and J. Shepherd, A corpus-based boot-
strapping algorithm for Semi-Automated semantic
lexicon construction. In Natural Language Engi-
neering, Vol 5, part 2, June 1995, pp 147-156.
</p>
<p>Sabah, G. Diffe&#769;rentes notions de synonymies lie&#769;es
a&#768; la compre&#769;hension du langage. Actes du col-
loque de l&#8217;Association pour la Recherche Cognitive</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Lafourcade et Prince
</p>
<p>1984.
Salton G. Term-Weighting Approaches in Auto-
matic Text Retrieval. McGraw-Hill computer sci-
ence serie. McGraw-Hill, Volume 24, 1988.
Salton G and M. J. MacGill. Introduction to Mod-
ern Information Retrieval. McGraw-Hill computer
science serie. McGraw-Hill, New-York, 1983.
Selva T. Ressources et activite&#769;s pe&#769;dagogiques
dans un environnement informatique d&#8217;aide a&#768;
</p>
<p>l&#8217;apprentissage lexical du franc&#807;ais langue seconde.
The&#768;se d&#8217;Universite&#769;, Universite&#769; de Franche-Comte&#769;,
Besanc&#807;on, octobre 1999, 210 p.
</p>
<p>Sparck Jones K. Synonymy and Semantic Classifi-
cation. Edinburgh Information Technology Serie,
1986.
</p>
<p>Ploux S. et B. Victorri Construction d&#8217;espaces
se&#769;mantiques a&#768; l&#8217;aide de dictionnaires de syn-
onymes. In TAL, Vol 39/1, 1998 pp 161-182.
</p>
<p>Annexes - Re&#769;sultats de synonymie relative
</p>
<p>ranger
&#0;
</p>
<p>choisir trier ranger choisir ordonner ventiler classer re&#769;partir
trier 0.0 0.392 0.459 0.437 0.385 0.302 0.318
ranger 0.398 0.0 0.598 0.471 0.416 0.336 0.363
choisir 0.519 0.703 0.0 0.601 0.519 0.55 0.512
ordonner 0.461 0.442 0.698 0.0 0.435 0.382 0.381
ventiler 0.421 0.366 0.654 0.439 0.0 0.344 0.273
classer 0.36 0.287 0.689 0.396 0.342 0.0 0.265
re&#769;partir 0.368 0.312 0.661 0.389 0.279 0.269 0.0
</p>
<p>ordonner
&#0;
</p>
<p>ventiler trier ranger choisir ordonner ventiler classer re&#769;partir
trier 0.0 0.348 0.464 0.46 0.39 0.306 0.325
ranger 0.344 0.0 0.591 0.45 0.365 0.276 0.308
choisir 0.456 0.568 0.0 0.629 0.541 0.573 0.536
ordonner 0.438 0.428 0.601 0.0 0.455 0.41 0.404
ventiler 0.409 0.385 0.544 0.454 0.0 0.345 0.273
classer 0.302 0.277 0.55 0.384 0.368 0.0 0.266
re&#769;partir 0.316 0.302 0.517 0.378 0.312 0.261 0.0
</p>
<p>classer
&#0;
</p>
<p>re&#769;partir trier ranger choisir ordonner ventiler classer re&#769;partir
trier 0.0 0.344 0.455 0.433 0.382 0.299 0.316
ranger 0.345 0.0 0.567 0.426 0.365 0.283 0.307
choisir 0.451 0.563 0.0 0.598 0.515 0.548 0.509
ordonner 0.439 0.428 0.595 0.0 0.432 0.384 0.378
ventiler 0.381 0.358 0.515 0.429 0.0 0.346 0.271
classer 0.303 0.278 0.544 0.383 0.337 0.0 0.268
re&#769;partir 0.325 0.312 0.511 0.385 0.279 0.273 0.0</p>

</div></div>
</body></html>