TALN 2001, Tours, 2-5 juillet 2001

Synonymies et vecteurs conceptuels

Mathieu Lafourcade, Violaine Prince
LIRMM : Dép. ARC, grp. TAL, Université Montpellier 2
161, rue Ada, 35392 Montpellier Cedex 5, France
www.lirmm.fr/”1afourca - www.lirmm.fr/"prince

Résumé - Abstract

La synonymie est une relation importante en TAL mais qui reste problématique. La distinction entre
synonymie relative et synonyn1ie subjective permet de contourner certaines difﬁcultés. Dans le cadre des
vecteurs conceptuels, il est alors possible de déﬁnir forrnellement des fonctions de test de synonymie et
d’en experimenter l’usage. Mots-clés. Synonymie relative, synonymie subjective, approches statistiques,
distances thématiques.

Synonymy is a pivot relation in NLP but remains problematic. Putting forward, the distinction between
relative and subjective synonymy, allows us to circunvent some difﬁculties. In the framework of con-
ceptual vectors, it is then possible to formalize test functions for synonymy and to experiment their use.
Keywords. Relative synonymy, subjective synonymy, statistical approaches, thematic distances.

1 Introduction

La synonymie est, avec l’hyperonyInie, une des fonctions lexicales qui ont été les plus étudiées
en traitement automatique des langues, sans parler de la linguistique. Parmi les travaux les plus
récents, dans la communauté francaise, fortement dédiés a la synonymie, on peut citer [Hamon
et a1. 1999] qui traite de l’extraction de synonymes, et s’appuie essentiellement sur des liens
de synonymie pour faire émerger des structures de connaissances dans des textes techniques ;
ou encore, [Selva 1999], qui fonde en grande partie Papprentissage du francais langue seconde
sur les fonctions lexicales et en particulier, la synonymie. On pensera également aux travaux
multiples sur l’extraction des relations sémantiques en général, a partir de corpus : citons, dans
le paysage francophone, les actions incitatives (au sein de l’ARC A3 de l’Aupelf-Uref), les
theses (par exemple [Morin 1999]), et dans la communauté anglo-saxonne, les travaux réalisés a
partir de Wordnet [Hearst 1998].

Si la synonymie est une relation étudiée en TAL c’est parce qu’elle permet, entre autres : a)
d’aider a la constitution de dictionnaires ; b) de réaliser une recherche d’information plus ﬁne
que le simple appariement d’une chaine de caractéres ; c) de ne pas multiplier les concepts dans
les bases de connaissances (un méme concept sera associé a une liste de termes synonymes) ; (1)
de gérer une qualité stylistique en génération.

Quelques propriétés de la synonymie sont cependant problématiques. Telle qu’ elle est entendue,
la synonymie devrait étre une relation d’ équivalence sémantique entre termes. Or, pour que cette
équivalence soit exploitable sur le plan formel, la relation devrait étre réﬂexive, symétrique
et transitive. Malheureusement, ces propriétés ne sont pas toujours vériﬁées comme nous le
montrons plus loin.

Dans cet article, nous abordons d’abord les problémes liés a la synonymie, ce qui nous conduit
51 déﬁnir plusieurs types de synonymies et a préciser le concept de synonymie relative. Nous
présentons ensuite de facon générale, les notions et les traitements liés aux vecteurs conceptuels

Lafourcade et Prince

qui sont au coeur du formalisme que nous avons choisi d’adopter. Nous précisons enﬁn les
différentes fonctions de test liées aux synonymies. Ces fonctions sont basées sur les vecteurs
conceptuels.

2 Synonymies

Un des premiers défauts connus de la synonymie, en tant que relation entre termes c’est qu’elle
n’est pas nécessairement transitive, lorsque l’on prend les termes deux a deux, sans plus de
précautions [Lewis 1952]. Ainsi par exemple, ‘trier’ et ‘ordonner°, ‘trier’ et ‘choisir°, qui sont syn-
onymes deux a deux, sont tels que <ordonner= et <choisir= ne sont pas synonymes. En pratique, au
moins trois concepts sont désignés par <trier= : 0RD0NNER[trier une liste de cinqucmte e’le’memtsj les
éléments de la liste sont mis dans un ordre donné mais aucun d’eux n’est soustrait ; CHOISIR [c’est
un personnel triéj ou les personnes sélectionnées constituent un sous-ensemble d’un ensemble
possible de personnes ; et enﬁn, RE’PART1R[trier le courrierj. [Fischer 1973] montre que la syn-
onymie est au mieux une relation de tolérancel.

Le deuxieme défaut de la synonymie est qu’elle peut se confondre au moins partiellement avec
l’hyperonymie. Par exemple, ‘m0rceler° a pour synonyme ‘couper’ alors qu’il en est hyponyme.
On a, en effet, MORCELER [couper en plusieurs morceauxj , par opposition a l’idée de couper en deux,
ou couper dans le sens de soustraire une partie. Ce défaut fait apparaitre une fragilité dans la
symétrie de la relation, ce qui remet meme en cause son statut de relation de tolérance au sens
fort. En effet, si un hyperonyme apparait comme synonyme parce que le terme partage avec lui
toutes ses propriétés, en revanche sur un plan sémantique, l’hyponyme n’est pas un synonyme.
Ainsi ‘cisailler° n’apparait pas comme synonyme de <couper>, alors que l’inverse semble plus
admissible.

Enﬁn, il y a une petite “déconvenue” prévisible qui veut que deux hyponymes d’un meme
terme, tout en étant parents, ne sont pas forcément synonymes. Si °p0ignarder° et <abattre= sont
hyponymes d’<assassiner=, ils ne sont pas en mesure de présenter des qualités de synonymie.
Ce qui amene a déﬁnir la synonymie comme la qualité, pour deux termes, de partager le
plus grand nombre de contenus sémantiquesz, ou avoir la plus grande base commune possible
(lorsqu’il s’agit d’une représentation plus numérique ou topologique). A l’inverse, on remar-
quera également, que la polysémie d’un terme peut faire qu’il ait plusieurs hyperonymes.

Par conséquent, si l’on souhaite exploiter les liens de synonymie entre termes pour faire de
l’indexation, de la recherche d’information dans un corpus, ou pour générer du texte, il est
important de déﬁnir des relations de synonymie qui pourraient avoir de meilleures propriétés
que celles de la synonymie vue in abstracto.

2.1 Notion de Synonymie relative

Pour pallier le premier défaut, nous avions proposé des 1991 [Prince 1991] une notion de syn-
onymie relative qui part du principe que deux termes peuvent étre synonymes par rapport a
l’idée centrale développée par un troisieme, ou par un des deux. Cette notion avait déja été
appréhendée par [Sabah 1984] sous la forme de synonymie approchée contextuelle dans un
modele lexical de type réseau sémantique. Ainsi, <trier= et <choisir= sont synonymes par rap-
port au concept discriminant de CHOISIR, alors que <trier= et ‘ranger’ sont synonymes par rapport
a RANGER.

1Une relation de tolérance peut—étre symétrique et réﬂexive mais n’est pas transitive. Il existe plusieurs niveaux
de tolérance, selon le nombre de propriétés vériﬁées.
2La sémantique componentielle dirait : le plus grand nombre de sémes communs.

Synonymies et vecteurs conceptuels

Avec un troisieme terme, cela peut fonctionner de la méme maniere. Le concept ORDONNER,
permet de lier ‘trier’ et ‘ranger’, ‘trier’ et ‘ordonner’, ‘trier’ et ‘ventiler’. L’idée est que tous les
synonymes, par rapport a un méme tiers (qui peut étre en l’occurrence, l’un des termes), sont
synonymes entre eux deux a deux ; des lors, la synonymie relative au tiers est transitive. Par
exemple, ‘choisir’ et ‘sélectionner’ sont synonymes par rapport a CHOISIR, par conséquent, ‘trier’

et ‘sélectionner’ le sont aussi.

L’ intérét d’une telle relation est qu’ elle devient alors une relation d’équivalence (une démonstration
formelle en a été faite dans [Prince op. cit]), ce qui rend toute sa valeur au lien de synonymie.

2.2 Notion de Synonymie subjective

Si on veut utiliser plus largement la synonymie dans le cadre de l’indexation ou de la recherche
d’information, il faudrait tenir compte d’une notion de synonymie “forcée” par un point de vue.
Bien que deux hyponymes d’un méme terme ne soient pas synonymes si on se place dans le
champs sémantique le plus proche de ces termes, il n’en va pas de méme lorsque l’on s’éloigne
sémantiquement d’eux.

Ainsi, dans des textes consacrés a l’usinage, theme qui fera ﬁgure de concept point de vue,
‘cisailler’ et ‘morceler’ seront forcément différenciés et doivent l’étre lors de l’indexation. En
revanche, dans un texte consacré au transport, on peut négliger la différence entre ces termes,
voire les assimiler a leur hyperonyme ‘couper’. C’est cette capacité a “confondre” des termes
parce que leur différence sémantique est faible au regard de la thématique générale que nous
nommons synonymie subjective.

La synonymie subjective reste une notion opératoire déﬁnie pour des besoins de recherche
d’information, par opposition a a) la synonymie héritée qui est une propriété fonctionelle de
l’hyperonymie, et b) la synonymie relative, ou le concept pivot est un des sens des termes
polysemes a comparer, et qui est une propriété fonctionnelle de la polysémie.

3 Vecteurs conceptuels

Dans le cadre de recherche sur la représentation du sens en TALN et son application a la
recherche d’information, nous nous concentrons sur la représentation de l’aspect thématique
(des segments textuels tels que les documents, paragraphes, syntagmes, etc.) sous la forme de
vecteurs conceptuels [Lafourcade et Sanford 1999]. Cette approche tire son origine de [Chauché
1990] pour l’utilisation d’un jeu de concepts prédéterminé, mais s’inspire aussi du modele vec-
toriel [Salton et MacGill 1983] et du modele LSI [Deerwester et all. 1990] pour la reconnaissance
et l’exploitation de l’inter-dépendance des concepts. Par contre, son application a l’indexation
et la recherche d’information textuelle se distingue nettement de [Salton 1988], en ce qu’elle
se base explicitement pour son calcul sur la géométrie et les variables morphosyntaxiques des
arbres d’analyse structurelle issus du texte et non pas sur une analyse de surface par mots-
clés. D’une facon générale les documents sont traités indépendamment (ce qui constitue une
différence majeure d’avec LSI) et l’accent est Inis sur la sélection lexicale en contexte. Les
memes considérations peut étre faite avec [Resnik 1995] a propos de l’usage exclusif de tax-
onomies.

Pour mémoire, le modele de vecteurs conceptuels s’appuie paradigmatiquement sur la projec-
tion dans un modele mathématique de la notion linguistique de champ sémantique. Les concepts
sont déﬁnis selon un thésaurus (en ce qui nous concerne, il s’agit de la langue francaise [Larousse
1992] on 873 concepts sont répertoriés). L’ hypothese principale est que cet ensemble forme un

Lafourcade et Prince

espace générateur pour les mots de la langue (espace qui n’est probablement pas libre). Des
lors, tout mot se projette sur cet espace selon le principe énoncé ci-apres.

3.1 Principe

Soit C un ensemble ﬁni de n concepts. Un vecteur conceptuel V est une combinaison linéaire
des éléments cl» de C. Pour un sens A, le vecteur VA est la description (en extension) des acti-
vations des concepts de C. Par exemple, les sens de ‘ranger’ et de <couper= peuvent étre projetés
sur les concepts suivant (les c0NcEPT[intensite’j étant ordonnés par intensité décroissante) :

Wanger : (cHANGEMENT[0.84j, VAR1AT10N[0.83j, l/Coupe, : (JEU[0.8j, LIQU11)E[0.8j, cR01X[0.79j,
E’V0LUT10N[0.82j, 0RDRE[0.77j, s1TUAT10N[0.76j, PART1E[0.78j ME’LANGE[0.78j FRAcT10N[0.75j SUP-
sTRUcTURE[0.76j, RANG[0.76j . . . ). PLIcE[0.75j BLEssURE[0.75j B01ss0N[0.74j . . . ).

La description du processus d’apprentissage calculant les valeurs respectives des intensités pour
chaque coordonnées d’un vecteur a été exposé dans [Lafourcade 2001]. Il est clair, que pour des
vecteurs denses (ayant tes peu de coordonnées nulles), l’énumération des concepts activés est
vite fastidieuse et surtout difﬁcile a évaluer. On préferera en général, procéder par sélection
de termes thématiquement proches (cf 3.2). Par exemple, les termes proches (et ordonnés par
distance thématique décroissante) des mots ‘ranger’ et ‘c0uper° sont :

<ranger> 2 <trier>, <cataloguer>, <sélectionner>, <c0uper> 2 <cisailler>, <émincer>, <scier>,
<classer>, <distribuer>, <grouper>, <ordonner>, <trongommer> , <ébarber>, <emfrecouper>, <baptiser>,
<répartir>, <aligner>, <caser>, <arranger>, <nettoyer>, <recouper>, <sectionner>, <bécher>, <hongrer>,
<distribuer>, <déméler>, <ajuster> . . . <essoriller>, <rogner>, <égorger>, <écimer>, . . .

En pratique, plus C est grand, plus ﬁnes seront les descriptions de sens offertes par les vecteurs,
mais plus leur manipulation informatique est lourde (on rappelle que dans nos expérimentations,
dim(C) = 873, ce qui correspond au niveau 4 des concepts déﬁnis dans [Larousse op. cit.].) La
construction d’un lexique conceptuel (ensemble de triplets (mot, variables morphologiques,
vecteur)) est réalisée automatiquement a partir de corpora (de déﬁnitions, de thésaurii, etc.
[Lafourcade op. cit.]). Au moment de l’écriture de cet article, le corpus du francais représente en-
viron 140000 déﬁnitions correspondants a 52000 mots vedettes (pour 25000 mots monosémiques
et 27000 mots polysémiques - pour ces derniers le nombre moyen de déﬁnitions, certaines
éventuellement redondantes, étant de 4.54).

3.2 Distance angulaire

Il est souhaitable de pouvoir mesurer la proximité entre les sens représentés par deux vecteurs (et
donc celle de leur mot associé). Soit Sim(X, Y) la mesure de similarite’, utilisée habituellement
en recherche d’informations, entre deux vecteurs déﬁnie selon la formule (1) ci-dessous (avec
“-” étant le produit scalaire). On notera que l’on suppose ici que les composantes des vecteurs
sont toujours positives ou nulles (ce qui n’est pas nécessairement le cas). Enﬁn, nous déﬁnissons

une fonction de distance angulaire D A entre deux vecteurs X et Y selon la formule (2).

Sim(X,Y) : c0s(X,Y) :  (1)
DA(X,Y) : arcc0s(Sim(X,Y)) (2)

Intuitivement, cette fonction constitue une évaluation de la proximite’ thématique et est en pra-
tique la mesure de l’angle formé par les deux vecteurs. On considérera, en général, que pour

Synonymies et vecteurs conceptuels

une distance D A(X , Y) 3 7r / 4, X et Y sont sémantiquement proche et partagent des concepts.
Pour D A(X , Y) 2 7r / 4, la proximité sémantique de A et B sera considérée comme faible.
Aux alentours de 7r/ 2, les sens sont sans rapport. La synonymie (dans son acception la plus
large) est incluse dans la proximité thématique, cependant elle exige de plus la concordance des
catégories morphosyntaxiques. L’ inverse n’est évidement pas vrai.

I1 s’agit d’une vraie distance (contrairement a la mesure de similarité) et elle vériﬁe les pro-
priétés de réﬂexivité (3), symétrie (4) et inégalité triangulaire (5) :

DA(XvX) = 0 (3)
DA(X7Y) :  
DA(X,Y)—|—DA(Y,Z)ZDA(X Z) (5)

Par déﬁnition, nous posons : D A(0, 0) : 0 et D A(X , 0) = 7r/2 avec 0 dénotant le vecteur
nul3. On considérera, en toute généralité, l’extension du domaine image de DA a [0, 7r] aﬁn de
comparer des vecteurs ayant des composantes négatives. Cette généralisation ne change pas les
propriétés de DA. On remarquera, de plus, que la distance angulaire est insensible a la norme
des vecteurs (oz et [3 étant des scalaires) :

DA(aX,ﬂY) = DA(X, Y) avec ozﬂ > 0 (6)
DA(ozX,ﬂY)=7r—DA(X,Y) avec ozﬂ<0 (7)

Par exemple4 dans le tableau qui suit, nous avons les distances angulaire (en radian) entre les
vecteurs de plusieurs termes. Le tableau est symétrique (a cause de la symétrie de DA) et la
diagonale est toujours égale a 0 (a cause de la réﬂexivité de DA). On remarquera qu’une valeur
prend toute sa signiﬁcation relativement a une autre. En particulier, il est satisfaisant d’avoir,
par exemple : a) d1 3 d3 et d2 3 d3 ce qui correspond bien au fait que ‘trier’ et <ordonner= d’une
part, et ‘trier’ et ‘choisir° sont “plus synonymes” que <ordonner= et <choisir= ; b) d4 est la plus
petite valeur de DA (ranger, Y) car les concepts CLASSER et REPARTIR sont relativement proches, et
de plus ‘ranger’ est par ailleurs polysémique (CLASSER, RASSEMBLER et NETTOYER) et seul CLASSER est
présent dans le tableau.

DA (X , Y) trier ranger choisir ordormer ventiler classer re’partir
trier 0.0 0.517 0.662 d1 0.611 d2 0.551 0.441 0.462
ranger 0.0 0.829 0.6 0.523 0.409 d4 0.444
choisir 0.0 0.848 d3 0.77 0.796 0.758
ordonner 0.0 0.595 0.523 0.519
ventiler 0.0 0.471 0.391
classer 0.0 0.36
répartir 0.0

3.3 Opérateurs

Somme vectorielle. Soit X et Y deux vecteurs, on déﬁnit V comme leur somme normée :

V=X€9Y I v2'=(«’Ih'+y¢)/HVVN (8)

3Le vecteur n’est sans doute pas représenté par un mot de la langue. Il s’agit d’une idée qui n’actiVe . . . aucun
concept ! C’est l’idée Vide.
4Tous les exemples de cet article sont issus de <http : //www . lirmm . fr/ " lafourca>

Lafourcade et Prince

Cet opérateur est idempotent et nous avons X Q3 X : X. Le vecteur nul 0 est l’élément neutre
de la somme vectorielle et, par déﬁnition, nous posons que 0 Q3 0 : 0. De ce qui précede, nous
déduisons (sans le démontrer) les propriétés de rapprochement (local et généralisé) :

DA(X®X,Y@§X)=DA(X,Y@9X)§DA(X,Y) (9)
DA(XG9Z,Y@9Z)§DA(X,Y) (10)

Soustraction vectorielle. Soit X et Y deux vecteurs distincts, on déﬁnit V comme leur sous-
traction normée :

V=X@Y I U2':(952"y2')/llvll (11)

Cet opérateur n’est pas idempotent et on aura par déﬁnition : V = X 6 X = 0. On remarquera
que, dans le cas général, les valeurs v, peuvent étre négatives et que la fonction de distance a
son image sur [0, 7r].

Produit terme :71 terme normalisé. Soit X et Y deux vecteurs, on déﬁnit V comme leur produit
terme a terme normalisé :

V:X®Y | u,=\/ﬁg, (12)

Cet opérateur est idempotent (V : X 69 X : X) et 0 est absorbant (V = X 69 0 = 0).

Contextualisation et Anti-contextualisation. Lorsque que deux termes sont en présence, pour
chacun d’euX certains de leur sens se trouvent sélectionnés par le contexte que constitue l’autre
terme. Ce phénomene de contextualisation consiste a augmenter chaque sens de ce qu’il a de
commun avec l’autre. A des ﬁns opératoires, nous déﬁnissons également la fonction opposée,
l’anti-contextualisation. Soit X et Y deux vecteurs, on déﬁnit F(X, Y) (resp. f(X, Y)) comme
la contextualisation (resp. 1’anti-contextualisation) de X par Y comme :

F(X,Y):X69(X®Y) et F(X,Y)=X@(X®Y) (13)

Ces fonctions ne sont pas symétriques. L’opérateur F est idempotent (F(X, X) = X) et le
vecteur nul est un élément neutre (F(X, 0) = X Q3 0 : X). L’opérateur T est nulpotent
(T(X, X) = X 6 X = 0) et 0 est également un élément neutre. On remarquera (sans les
démontrer) que nous avons les propriétés (de rapprochement et d’e’l0ignement) suivantes :

DA(F(X,Y),F(Y,X)) 3 {DA(X,F(Y,X)),DA(F(X,Y),Y)} 3 DA(X,Y) (14)
DA(T(X,Y),T(Y,X)) Z {DA(X,T(Y,X)),DA(T(X,Y),Y)} Z DA(X,Y) (15)

La contextualisation F(X, Y) rapproche le vecteur X de Y proportionnellement a leur in-
tersection. L’anti-contextualisation F(X, Y) procede inversement. Dans la tableau qui suit,
nous avons dans la partie supérieure les valeurs de (a) D A(F(X , Y), F(Y, X et dans la partie

inférieure les valeurs de (b) D A(F(X , Y), F(Y, X

b\a trier ranger choisir ordonner ventiler classer répartir
trier 0.0 0.269 0.363 0.322 0.288 0.228 0.239
ranger 2.183 0.0 0.474 0.316 0.273 0.211 0.23
choisir 2.401 2.17 0.0 0.485 0.434 0.451 0.425
ordonner 2.382 2.374 2.314 0.0 0.313 0.272 0.27
ventiler 2.334 2.303 2.282 2.483 0.0 0.244 0.201
classer 2.505 2.481 2.313 2.648 2.535 0.0 0.185
répartir 2.476 2.388 2.364 2.637 2.53 2.761 0.0

Synonymies et vecteurs conceptuels

4 Synonymie Relative

Nous déﬁnissons la fonction de synonymie relative Syn R entre trois vecteurs A, B et 0, ce
demier jouant le role de pivot, comme suit :

SynR(A, B, O) : DA(P(A, O), F(B, 0))
=DA(Ae3(A®O),Be3(B®O)) (16)

L’ interprétation correspond bien a celle présentée ci-dessus, a savoir que l’on cherche a tester
la proximité thématique de deux sens (A et B), chacun augmenté de ce qu’il a de commun avec
un tiers (C).

4.1 Propriétés

Pour rendre compte des trois propriétés théoriques de la relation de synonymie (réﬂexivité,
symétrie et transitivité), nous les vériﬁons comme suit :
1. SynR(A, A, C ) : 0 La réﬂexivité est héritée de celle de la distance angulaire DA.
2. SynR(A, B, C) : SynR(B, A, 0) La symétrie pour les deux premiers arguments,
provient également de celle de la distance angulaire.
3. SynR(A, B, E) + SynR(B, C, E) Z SynR(A, C, E) C’est un héritage de l’inégalité
triangulaire de DA. Elle représente une forme de transivité pour la synonymie relative.
Elle est en outre plus précise que la vériﬁcation de la propriété de transitivité : elle indique
que la distance entre A et 0/ E est au pire égale a la somme des mesures de synonymie
de A et B/E d’une part, et B et O/E d’autre part.
4. SynR(A, B,0) : DA(A Q3 0, B Q3 0) : DA(A, B) Le vecteur nul 0 ramene la
synonymie relative a la distance angulaire.
5. SynR(A, B, C) 3 DA (A, B) Par héritage du rapprochement de DA, quelque soit le
point de vue, la synonymie relative ne peut que rapprocher A et B.

4.2 Exemples

Dans la tableau qui suit, nous avons dans la partie supérieure le rappel des valeurs de (a)
DA (X, Y) et dans la partie inférieure les valeurs de (b) Syn R(X, Y, trier).

On voit bien apparaitre ici la Inise en lumiere de la polysémie. Nous avons, par exemple,
Syng (classer, ranger, trier) valant 0, 283, ce qui indique une forte synonymie relative de <classer=
et ‘ranger’ par rapport a ‘trier’, chose que la distance angulaire correspondante (0, 409) n’indiquait
pas aussi fortement. A l’inverse, SynR(choisir, ordonner, trier) vaut 0, 636, ce qui montre que
‘choisir° et ‘ordonner’ ne sont pas synonymes entre eux par rapport a ‘trier’, alors qu’ils sont
deux synonymes possible de ‘trier’. La synonymie relative apparait comme un bon indicateur
de polysémie : ‘choisir° et ‘ordonner’ relevent majoritairement des deux “zones” sémantiques
différentes. De plus, ‘ordonner’ est lui-meme polysémique.

b\ a trier ranger choisi r ordonner ventiler classer réparti r
trier 0.0 0.517 0.662 0.611 0.551 0.441 0.462
ranger 0.402 0.0 0.829 0.6 0.523 0.409 0.444
choisi r 0.5 0.623 0.0 0.848 0.77 0.796 0.75 8
ordonner 0.478 0.43 0.636 0.0 0.595 0.523 0.519
ventiler 0.435 0.365 0.575 0.435 0.0 0.471 0.391
classer 0.369 0.283 0.607 0.385 0.344 0.0 0.36
réparti r 0.376 0.309 0.57 0.383 0.272 0.268 0.0

Lafourcade et Prince

5 Synonymie Subjective

Nous déﬁnissons la fonction de synonymie subjective Syn 5 entre trois vecteurs A, B et 0, ce
dernier jouant le role de point de vue, comme suit :

Syng(A, B, O) : DA(T(A, O),T(B, 0))
=DA(A6(A®O),B6(B®O)) (17)

L’ interprétation naturelle consiste a considérer 0 come un point de vue a partir duquel A et
B sont comparés. Plus le point de Vue 0 s’éloigne de A et de B, plus ceux-ci semblent se
confondre. A l’inverse, plus 0 est proche de A et B (plus il se trouve entre eux) plus il est a
meme de les distinguer.

Avec A 7E B 7E C, nous avons donc:  —> oo :> Syn5(A, B, C) —> 0.

5.1 Propriétés

Certaines des propriétés de la synonymie subjective sont analogues a celle de la synonymie
relative, Inis a part la derniere qui est originale.
1. Syn5(A, B, C) = Syn5(B, A, C) Nous avons commutativité pour les deux pre-
miers arguments, par simple héritage de la commutativité de la distance angulaire.
2. Syn5(A, B, 0) : DA(A 6 0, B 6 0) = DA(A, B) Si le point de vue est le vecteur
nul on se ramene a la distance angulaire.
3. Syn5(A, A, C) : DA(A 6 (A (8 O), A 6 (A (8 0)) : 0 Deux sens identiques sont
toujours a une distance angulaire égale a 0 quelque soit le point de vue.
4. Sy7”LS(/1, B,  + Syng(B, O,  Z Sy7”LS(/1, C, 
Héritage de l’inégalité triangulaire.
5. Syng(A, B, C) 2 DA(A, B) Héritage de l’éloignement.
6. Syng(A, B, B) = DA(A 6 (A <59 B), B 9 (B <59 B)) = DA(A 9 (A <59 B), 6) = 4/2
Syng(A, B, B) : Syn5(A, B, A) Si le point de vue est l’un des sens considérés, la
discrimination de sens est maximale.

5.2 Exemples

Dans la tableau qui suit, nous avons dans la partie supérieure le rappel des valeurs de (a)
DA (X, Y) et dans la partie inférieure les valeurs de (b) Syns(X, Y, trier).

b\a trier ranger choisir ordormer ventiler classer répartir
trier 0.0 0.517 0.662 0.611 0.551 0.441 0.462
ranger 1.571 0.0 0.829 0.6 0.523 0.409 0.444
choisir 1.571 1.643 0.0 0.848 0.77 0.796 0.758
ordonner 1.571 1.433 1.624 0.0 0.595 0.523 0.519
ventiler 1.571 1.395 1.543 1.36 0.0 0.471 0.391
classer 1.571 1.259 1.741 1.292 1.323 0.0 0.36
répartir 1.571 1.324 1.613 1.245 1.132 1.158 0.0

On notera, en particulier, que la colonne correspondant a ‘trier’ n’a que des valeurs égales a 7r / 2,
ce qui est conforme a la propriété 6. On remarque donc que la synonymie subjective agit comme
un “objectii”. Plus un terme se rapproche de point de vue, plus la discrimination est forte. Par
exemple, <re’partir= et <vemtiler= gardent le meilleur score (1, 132) car ils sont tres proches entre
eux. Par contre, <ordonner= et <choisir= ont un score supérieur a 7r/ 2. Dans ce cas la polysémie
est bien discriminée. C’est également le cas de ‘classer° et <choisir= (1, 741).

Synonymies et vecteurs conceptuels

6 Conclusion

Les travaux que nous avons menés sur la synonymie dans des sources de connaissances lex-
icales ont montré que : 1) Dans une modélisation globaliste comme celle des vecteurs con-
ceptuels, ou l’on travaille a partir de mots qui invoquent des idées et non pas sur des con-
cepts qui se combinent en mots, la synonymie a des propriétés pouvant s’exprimer sous formes
de mesure. 2) Pour que ces mesures de synonymie nous rapprochent des bonnes propriétés
mathématiques (equivalence ou quasi-equivalence) que l’on voudrait leur voir attribuer, nous
avons été amenés a déﬁnir deux types de synonymies : a) la synonymie relative, qui permet par
rapport a un theme donné, de montrer les groupements de termes qui seraient quasi-equivalents
entre eux; et b) la synonymie subjective, qui apparait comme un discriminateur fort, si le theme
est sémantiquement proche des termes a examiner, ou au contraire, comme un mécanisme de
lissage si le theme est éloigné.

Nous poursuivons nos travaux avec l’aide de ces deux mesures pour réaliser de la détection
d’hyperonyInie. Si cette derniere apparait comme évidente quand on travaille dans le sens
concept —> mot, elle est beaucoup plus difﬁcile a asserter dans le sens mot —> concept. La
synonymie relative et la synonymie subjective qui traquent toutes deux a la fois la ressemblance
et la différence sémantiques, forment une structure fonctionelle de base a partir de laquelle nous
cherchons a reconstruire bon nombre de fonctions lexicales déﬁnies en linguistique.

Références

Chauché J. De’termination sémantique en anal-
yse structurelle : une expérience basée sur une
deﬁnition de distance. TA Information, 1990, vol
31/1, p 17-24.

Deerwester S. and S. Dumais, T. Landauer, G.
Furnas, R. Harshman, Indexing by latent semantic
analysis. In Journal of the American, Society of
Information science, 1990, 416(6), p 391-407.

Fischer, W. L. Aquivalenz und Toleranz Strukturen
in der Linguistik zur Theory der Synonyma. Max
Hﬁber Verlag, Mﬁnchen, 1973.

Hamon, T. et D. Garcia, A. Nazarenko, Détection
de liens de synonymie : complémentarité des
ressources générales et spécialisées. Terminolo-
gies Nouvelles. 1999, pp 61-69.

Hearst, M. A. Automated discovery of Wordnet re-
lations. In C Fellbaum ed. ”Wordnet An Electronic
Lexical Database”. MIT Press, Cambridge, MA,
1998, pp 131-151.

Lafourcade M. et E. Sandford, Analyse
et désambiguisation lexicale par vecteurs
sémantiques. In Proc. of TALN’99 (Cargése, July
1999) pp 351-356.

Lafourcade M. Lexical sorting and lexical trans-
fer by conceptual vectors. In Proc. of The First

International Workshop on MultiMedia Annotation
(MMA’ 2001) (Tokyo, January 2001) 6 p.

Larousse. Thésaurus Larousse - des idées aux mots
- des mots au idées. Larousse, ISBN 2-03-320-
148-1, 1992.

Lewis, C. I. The modes of meaning. in Linsky ed,
”Semantics and the philosophy of language”. Ur-
bana. NY, 1952.

Morin, E. Extraction de liens sémantiques entre
termes a partir de corpus techniques. These de
doctorat de l’Université de Nantes, 1999.

Prince, V. Notes sur l ’évaluation de la réponse
dans TEDDI introduction d ’une relation
d ’équivalence pour la synonymie relative. Notes
et Documents LIMSI 91-20. 1991, CNRS. 22 p.

Resnik P. Using Information contents to evaluate
semantic similarity in a taxonomy. In Proceedings
of IJCAI-95, 1995.

Riloff E. and J. Shepherd, A corpus-based boot-
strapping algorithm for Semi-Automated semantic
lexicon construction. In Natural Language Engi-
neering, V015, part 2, June 1995, pp 147-156.

Sabah, G. Diﬁférentes notions de synonymies liées
a la compréhension du langage. Actes du col-
loque de1’Association pour la Recherche Cognitive

1984.

Salton G. Term-Weighting Approaches in Auto-
matic Text Retrieval. McGraw-Hill computer sci-
ence serie. McGraw-Hill, Volume 24, 1988.

Salton G and M. J. MacGill. Introduction to Mod-
ern Information Retrieval. McGraw-Hill computer
science serie. McGraw-Hill, New-York, 1983.

Selva T. Ressources et activités pédagogiques
dans un environnement informatique d ’aide a

Lafourcade et Prince

l’apprentissage lexical dufrancais langue seconde.
These d’UniVersité, Université de Franche-Comte,
Besancon, octobre 1999, 210 p.

Sparck Jones K. Synonymy and Semantic Classifi-
cation. Edinburgh Information Technology Serie,
1986.

Ploux S. et B. Victorri Construction d’espaces

sémantiques a l’aide de dictionnaires de syn-
onymes. In TAL, Vol 39/1, 1998 pp 161-182.

Annexes - Résultats de synonymie relative

ranger \ choisir trier ranger choisir ordonner ventiler classer répartir
trier 0.0 0.392 0.459 0.437 0.385 0.302 0.318
ranger 0.398 0.0 0.598 0.471 0.416 0.336 0.363
choisir 0.519 0.703 0.0 0.601 0.519 0.55 0.512
ordonner 0.461 0.442 0.698 0.0 0.435 0.382 0.381
ventiler 0.421 0.366 0.654 0.439 0.0 0.344 0.273
classer 0.36 0.287 0.689 0.396 0.342 0.0 0.265
répartir 0.368 0.312 0.661 0.389 0.279 0.269 0.0
ordonner \ ventiler trier ranger choisir ordonner ventiler classer répartir
trier 0.0 0.348 0.464 0.46 0.39 0.306 0.325
ranger 0.344 0.0 0.591 0.45 0.365 0.276 0.308
choisir 0.456 0.568 0.0 0.629 0.541 0.573 0.536
ordonner 0.438 0.428 0.601 0.0 0.455 0.41 0.404
ventiler 0.409 0.385 0.544 0.454 0.0 0.345 0.273
classer 0.302 0.277 0.55 0.384 0.368 0.0 0.266
répartir 0.316 0.302 0.517 0.378 0.312 0.261 0.0
classer \ répartir trier ranger choisir ordonner ventiler classer répartir
trier 0.0 0.344 0.455 0.433 0.382 0.299 0.316
ranger 0.345 0.0 0.567 0.426 0.365 0.283 0.307
choisir 0.451 0.563 0.0 0.598 0.515 0.548 0.509
ordonner 0.439 0.428 0.595 0.0 0.432 0.384 0.378
ventiler 0.381 0.358 0.515 0.429 0.0 0.346 0.271
classer 0.303 0.278 0.544 0.383 0.337 0.0 0.268
répartir 0.325 0.312 0.511 0.385 0.279 0.273 0.0

