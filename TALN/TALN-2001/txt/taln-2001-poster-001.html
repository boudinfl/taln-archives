<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Mod&#232;les de langage hi&#233;rarchiques pour les applications de dialogue en parole spontan&#233;e</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2001, Tours, 2-5 juillet 2001
</p>
<p>Mode&#768;les de langage hie&#769;rarchiques pour les applications de
dialogue en parole spontane&#769;e
</p>
<p>F. Be&#769;chet, Y. Este&#768;ve, R. De Mori
LIA - Universite&#769; d&#8217;Avignon - BP1228 - Avignon Cedex 9
</p>
<p>1 Re&#769;sume&#769; - Abstract
</p>
<p>Le cadre de cette e&#769;tude 1 concerne les syste&#768;mes de dialogue via le te&#769;le&#769;phone entre un serveur de
donne&#769;es et un utilisateur. Nous nous inte&#769;resserons au cas de dialogues non contraints ou&#768; l&#8217;util-
isateur a&#768; toute liberte&#769; pour formuler ses reque&#770;tes. Ge&#769;ne&#769;ralement, le module de Reconnaissance
Automatique de la Parole (RAP) de tels serveurs utilise un seul Mode&#768;le de Langage (ML) de
type bigramme ou trigramme pour mode&#769;liser l&#8217;ensemble des interventions possibles de l&#8217;util-
isateur. Ces ML sont appris sur des corpus de phrases retranscrites a&#768; partir de sessions entre le
serveur et plusieurs utilisateurs. Nous proposons dans cette e&#769;tude une me&#769;thode de segmenta-
tion de corpus d&#8217;apprentissage de dialogue utilisant une strate&#769;gie mixte base&#769;e a&#768; la fois sur des
connaissances explicites mais aussi sur l&#8217;optimisation d&#8217;un crite&#768;re statistique. Nous montrons
qu&#8217;un gain en terme de perplexite&#769; et de taux d&#8217;erreurs/mot peut e&#770;tre constate&#769; en utilisant un en-
semble de sous mode&#768;les de langage issus de la segmentation pluto&#770;t qu&#8217;un mode&#768;le unique appris
sur l&#8217;ensemble du corpus.
</p>
<p>Within the framework of Human-Computer dialogue in spontaneous speech, we propose in this
paper a method which automatically builds, from a training corpus, a set of Language Models
(LMs) organized as a binary tree. Each LM correspond to a specific dialogue state, where
the general LM is attached to the root node and the more specialized ones are represented by
the leaves. Such LMs can be used to automatically adapt the decoding process to the dialog
situation performed. We propose a two-pass decoding strategy, which implements this idea by
dynamically selecting a set of LMs according to the dialog situation detected.
</p>
<p>Reconnaissance Automatique de la Parole ; Mode&#768;les de Langage statistique ; Serveurs de Dia-
logue ; Arbre de De&#769;cision
</p>
<p>2 Introduction
</p>
<p>Les Mode&#768;les de Langage (ML) utilise&#769;s habituellement dans les syste&#768;mes de reconnaissance
automatique de la parole sont base&#769;s sur une approche probabiliste ne&#769;cessitant un apprentissage
sur corpus. Cet apprentissage permet d&#8217;estimer les probabilite&#769;s de transition entre les mots
d&#8217;une me&#770;me phrase. Durant la reconnaissance, l&#8217;historique utilise&#769; pour pre&#769;dire le prochain mot
est ge&#769;ne&#769;ralement re&#769;duit aux deux ou trois mots pre&#769;ce&#769;dents (mode&#768;les bigrammes ou trigrammes).
</p>
<p>1Ces travaux sont re&#769;alise&#769;s en collaboration avec France-Telecom R&amp;D sous le contrat 971b427</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>F. Be&#769;chet, Y. Este&#768;ve, R. De Mori
</p>
<p>Si ces caracte&#769;ristiques sont communes a&#768; l&#8217;ensemble des syste&#768;mes, le nombre de ML utilise&#769; et
leurs combinaisons de&#769;pendent fortement de l&#8217;application vise&#769;e. Dans le cas d&#8217;un syste&#768;me de
dicte&#769;e ge&#769;ne&#769;raliste, il est bien difficile de segmenter a priori les diffe&#769;rents cas d&#8217;utilisation du
syste&#768;me : un seul ML, me&#769;langeant the&#768;mes et types de phrases, est ge&#769;ne&#769;ralement employe&#769;.
</p>
<p>Dans les applications de dialogue pour les serveurs te&#769;le&#769;phoniques, il est en revanche possible
de segmenter le corpus d&#8217;apprentissage du ML selon diffe&#769;rents e&#769;tats de dialogue correspondant
aux interactions entre le serveur et l&#8217;utilisateur. Cependant il reste a&#768; de&#769;terminer d&#8217;une part les
situations de dialogue les plus discriminantes du point de vue de la reconnaissance et d&#8217;autre
part la me&#769;thode de se&#769;lection et de combinaison des ML obtenus sur chacun des sous-corpus
d&#8217;apprentissage.
</p>
<p>Ces travaux proposent des re&#769;ponses a&#768; ces questions en pre&#769;sentant une me&#769;thode de classement
d&#8217;un corpus de dialogue en sous-corpus base&#769;e sur une approche mixte : des connaissances
linguistiques explicites sont tout d&#8217;abord utilise&#769;es pour segmenter le corpus d&#8217;apprentissage du
ML. Puis, une technique de classification statistique base&#769;e sur des arbres de de&#769;cision permet
de segmenter a&#768; nouveau chacun des sous-corpus selon un crite&#768;re largement utilise&#769; en RAP :
la perplexite&#769;. Enfin, nous proposons un ML hie&#769;rarchique codant l&#8217;ensemble des sous-ML a&#768;
l&#8217;inte&#769;rieur d&#8217;une structure d&#8217;arbre utilisable dans un de&#769;codage a&#768; deux passes.
</p>
<p>3 Segmentation de corpus
</p>
<p>Les corpus d&#8217;apprentissage des ML utilise&#769;s dans les syste&#768;mes de RAP pour les applications de
dialogue te&#769;le&#769;phonique sont constitue&#769;s de retranscriptions orthographiques de sessions de dia-
logue entre un utilisateur (na&#305;&#776;f ou expert) et le serveur de dialogue. Ces sessions correspondent
au traitement d&#8217;une reque&#770;te comple&#768;te d&#8217;un utilisateur, aboutissant ou non a&#768; un succe&#768;s, com-
pose&#769;es de questions et de re&#769;ponses entre le serveur et l&#8217;utilisateur. Si le serveur admet un
dialogue ouvert, il est laisse&#769; toute liberte&#769; a&#768; l&#8217;utilisateur pour formuler ses reque&#770;tes. Dans ce cas,
le syste&#768;me doit e&#770;tre a&#768; me&#770;me de pouvoir traiter les phe&#769;nome&#768;nes inhe&#769;rents a&#768; la parole spontane&#769;e,
tels que les phrases agrammaticales, les he&#769;sitations, les reprises, etc. Cette extre&#770;me variabilite&#769;
est compense&#769;e par, d&#8217;une part un domaine se&#769;mantique ge&#769;ne&#769;ralement restreint (horaire de train,
programme de cine&#769;ma, etc.), d&#8217;autre part des re&#769;gularite&#769;s fortes dans les structures de phrases
lie&#769;es a&#768; certaines situations de dialogue. Ainsi, les premie&#768;res reque&#770;tes exprime&#769;es par un utilisa-
teur commencent ge&#769;ne&#769;ralement par des patrons de phrases tels que : je + [voudrais , recherche
, de&#769;sire , . . . ]
Les diverses situations de dialogue qui peuvent e&#770;tre rencontre&#769;es dans une session entre un util-
isateur et un serveur de&#769;pendent bien e&#769;videmment de l&#8217;application vise&#769;e. Cependant, a&#768; un niveau
d&#8217;abstraction e&#769;leve&#769;, il est possible de distinguer des macro-classes de situations de dialogue
inde&#769;pendantes du serveur et du domaine d&#8217;application.
</p>
<p>Avant de pre&#769;senter notre me&#769;thode de de&#769;coupage de corpus utilisant ces macro-classes, nous
pre&#769;sentons les donne&#769;es sur lesquelles ont e&#769;te&#769; effectue&#769;es toutes nos expe&#769;riences :
</p>
<p>Nous avons utilise&#769;, dans cette e&#769;tude, le corpus AGS (Sadek et al., 1996) constitue&#769; de transcrip-
tions de dialogue entre plusieurs utilisateurs et un serveur te&#769;le&#769;phonique. Deux domaines d&#8217;ap-
plication sont vise&#769;s par le serveur AGS : les informations me&#769;te&#769;orologiques et la recherche de
petites annonces d&#8217;emploi. Le corpus d&#8217;apprentissage est constitue&#769; de &#0;&#2;&#1; &#3;&#5;&#4; phrases prononce&#769;es
par plusieurs locuteurs et couvrant les deux domaines d&#8217;application. Le corpus de test est com-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mode&#768;les de langage hie&#769;rarchiques
</p>
<p>pose&#769; de &#0; &#1;&#2;&#0; &#3; phrases repre&#769;sentant plusieurs sessions et plusieurs locuteurs diffe&#769;rents. Le vo-
cabulaire utilise&#769; dans le corpus d&#8217;apprentissage contient &#4;&#6;&#5;&#8;&#7; mots.
</p>
<p>3.1 Segmentation en macro-classes
</p>
<p>Une e&#769;tude de&#769;taille&#769;e du corpus d&#8217;apprentissage permet de regrouper les interventions de l&#8217;util-
isateur en diffe&#769;rentes classes. Nous avons choisi, dans un premier temps, d&#8217;isoler des macro-
classes inde&#769;pendantes de l&#8217;e&#769;tat d&#8217;avancement du dialogue et des interventions de la machine.
Ce choix s&#8217;explique essentiellement par le faible nombre de sessions comple&#768;tes disponibles
dans le corpus d&#8217;apprentissage. Ces macro-classes sont de&#769;termine&#769;es a&#768; partir de la structure des
phrases prononce&#769;es par l&#8217;utilisateur, structure repre&#769;sente&#769;e sous la forme de patrons syntaxiques
et lexicaux.
</p>
<p>Les phrases du corpus d&#8217;apprentissage sont tout d&#8217;abord e&#769;tiquete&#769;es et lemmatise&#769;es a&#768; l&#8217;aide d&#8217;un
tagger morpho-syntaxique statistique (Spriet &amp; El-be&#768;ze, 1995). Une analyse syntaxique par-
tielle est ensuite effectue&#769;e sur le corpus e&#769;tiquete&#769; afin d&#8217;extraire les syntagmes composant les
phrases. Par exemple, la phrase : &#8221;J&#8217;aurais aime&#769; conna&#305;&#770;tre le nume&#769;ro de te&#769;le&#769;phone . . . &#8221; sera
e&#769;tiquete&#769;e :
</p>
<p>[(J&#8217;,PPER) (aurais,AA) (aime&#769;,VRPAS) (conna&#305;&#770;tre,VINF)]
[(le,DET) (nume&#769;ro,N) (de,PREP) (te&#769;le&#769;phone,N)]
Nous avons de&#769;termine&#769; quatre macro-classes a&#768; partir du corpus d&#8217;apprentissage : &#9;&#11;&#10;&#13;&#12;&#13;&#14;&#15;&#10;&#15;&#16;&#11;&#10; ,
contient l&#8217;ensemble des phrases repre&#769;sentant une premie&#768;re demande de l&#8217;utilisateur juste apre&#768;s
le prompt du syste&#768;me ; &#12;&#13;&#14;&#15;&#10;&#13;&#17;&#18;&#16;&#20;&#19;&#22;&#21;&#13;&#23; , contient les questions pose&#769;es par l&#8217;utilisateur apre&#768;s une
re&#769;ponse du serveur ; &#9;&#11;&#10;&#13;&#24;&#13;&#21;&#15;&#23;&#25;&#17;&#18;&#10; , contient les re&#769;ponses de l&#8217;utilisateur a&#768; une question du
serveur ; &#26;&#15;&#14;&#11;&#16;&#20;&#9;&#15;&#10; , contient ce qui n&#8217;a pu e&#770;tre e&#769;tiquete&#769; dans les autres classes. On trouve
ici des interventions de gestion du dialogue (ex : &#8221;annulation&#8221;, &#8221;au revoir&#8221;, &#8221;merci&#8221;) des
phe&#769;nome&#768;nes extra linguistiques (ex : &#8221;ah&#8221;, &#8221;hum&#8221;, &#8221;euh&#8221;) des phrases tronque&#769;es ou encore
des mouvements d&#8217;humeur suite a&#768; une mauvaise interpre&#769;tation du dialogue par la machine (ex :
&#8221;laisse tomber&#8221;, &#8221;c&#8217;est pas grave&#8221;).
Un ensemble de re&#768;gles base&#769;es sur la pre&#769;sence de certains mots, de certaines classes syntax-
iques ou encore de certaines structures syntaxiques ont e&#769;te&#769; e&#769;crites afin de classer les phrases
d&#8217;apprentissage dans chacune de ces cate&#769;gories.
</p>
<p>3.2 Segmentation hie&#769;rarchique
</p>
<p>Cette me&#769;thode consiste a&#768; raffiner la premie&#768;re segmentation du corpus en macro-classes en op-
timisant, de manie&#768;re ite&#769;rative, un parame&#768;tre influenc&#807;ant directement la reconnaissance : la per-
plexite&#769;. C&#8217;est une mesure commune&#769;ment employe&#769;e pour estimer les performances d&#8217;un mode&#768;le
de langage inde&#769;pendamment de l&#8217;aspect acoustique de la reconnaissance. Bien qu&#8217;il n&#8217;existe
pas de lien formel liant les performances de reconnaissance et la mesure de perplexite&#769;, ces
deux quantite&#769;s suivent ge&#769;ne&#769;ralement des e&#769;volutions communes. En mesurant la perplexite&#769; d&#8217;un
mode&#768;le sur un texte, on est a&#768; me&#770;me d&#8217;appre&#769;cier la capacite&#769; du mode&#768;le a&#768; pre&#769;dire ce me&#770;me texte.
Plus cette mesure est petite, plus le texte est proche du corpus utilise&#769; pour apprendre le mode&#768;le.
</p>
<p>Durant cette phase de segmentation nous allons utiliser une structure d&#8217;arbre binaire ou&#768; deux
informations sont associe&#769;es a&#768; chaque noeud : une expression re&#769;gulie&#768;re et un sous-corpus sat-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>F. Be&#769;chet, Y. Este&#768;ve, R. De Mori
</p>
<p>isfaisant l&#8217;expression re&#769;gulie&#768;re du noeud. Un noeud peut ge&#769;ne&#769;rer deux fils si une extension de
l&#8217;expression re&#769;gulie&#768;re courante permet de scinder le sous-corpus en deux et si des mode&#768;les de
langage appris sur ces deux sous-corpus fils obtiennent des perplexite&#769;s plus faibles que celle
obtenue avec le mode&#768;le de langage du noeud pe&#768;re. Cette me&#769;thode est inspire&#769;e des Arbres de
Classification Se&#769;mantiques introduit par (Kuhn &amp; de Mori, 1996).
Contrairement aux proble&#768;mes de classification re&#769;solus habituellement par des me&#769;thodes a&#768; base
d&#8217;arbres de de&#769;cision, nous ne connaissons pas dans notre cas le nombre optimal de classes
a&#768; discerner. Le nombre minimal correspond au nombre de macro-classes de&#769;ja&#768; pre&#769;sente&#769;es. Le
nombre maximal de classes est borne&#769; a&#768; la fois par la taille de corpus ne&#769;cessaire a&#768; l&#8217;apprentissage
d&#8217;un mode&#768;le bigramme et par le gain minimum en perplexite&#769; requis entre le noeud pe&#768;re et les
deux noeuds fils.
</p>
<p>Le seuil choisi sur la taille minimale d&#8217;un sous-corpus permet de contro&#770;ler la taille de l&#8217;arbre.
La figure 1 pre&#769;sente les premie&#768;res branches d&#8217;un exemple d&#8217;arbre obtenu sur le corpus d&#8217;ap-
prentissage AGS en fixant une taille minimale de &#0;&#2;&#1;&#3;&#1; phrases pour chaque noeud. Cet arbre
contient &#4; &#0; noeuds internes et &#4;&#2;&#5; feuilles, ce qui repre&#769;sente un ensemble de &#6;&#2;&#6; sous-corpus et
sous-ML.
</p>
<p>ML
</p>
<p>ML
</p>
<p>ML
</p>
<p>ML
</p>
<p>ML MLML
</p>
<p>ML
</p>
<p>ML ML
</p>
<p>REQUETE
</p>
<p>QUESTION
</p>
<p>+ travail +
</p>
<p>+ cherche +
</p>
<p>+ cherche + le + + VPPMS +
</p>
<p>+ le m&#233;t&#233;o +
</p>
<p>+ le t&#233;l&#233;phone +
</p>
<p>+ le +
</p>
<p>REPONSE
</p>
<p>AUTRE
</p>
<p>NULL
</p>
<p>+ moi +
</p>
<p>+ r&#233;p&#233;tez +
</p>
<p>+ C&#244;te d&#8217;Armor +
</p>
<p>nonoui
</p>
<p>oui
</p>
<p>oui
</p>
<p>oui
</p>
<p>oui
</p>
<p>oui
</p>
<p>non
</p>
<p>non
</p>
<p>non
</p>
<p>non
</p>
<p>non
</p>
<p>non
</p>
<p>non
</p>
<p>non non
</p>
<p>non
</p>
<p>non
</p>
<p>non
</p>
<p>oui
</p>
<p>oui
</p>
<p>oui
</p>
<p>oui
oui
</p>
<p>oui
</p>
<p>oui
</p>
<p>oui
</p>
<p>Figure 1: Exemple d&#8217;arbre de sous-ML
</p>
<p>3.3 Evaluation de la segmentation hie&#769;rarchique
</p>
<p>Nous avons e&#769;value&#769; l&#8217;arbre de sous-ML a&#768; travers deux aspects : les gains en perplexite&#769; obtenus
sur le corpus de test et l&#8217;e&#769;volution du taux d&#8217;erreurs/mot en utilisant le mode&#768;le ge&#769;ne&#769;ral et
les sous-ML (tableau 1). Pour cela, nous avons analyse&#769; les phrases retranscrites du corpus
de test avec les expressions re&#769;gulie&#768;res lie&#769;es aux noeuds de l&#8217;arbre et nous avons de&#769;termine&#769; a&#768;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mode&#768;les de langage hie&#769;rarchiques
</p>
<p>quelle feuille chacune des phrases appartenait. Enfin, nous les avons de&#769;code&#769;es avec le sous-ML
&#0;&#2;&#1;&#4;&#3; &#5; &#6; &#7; &#8; &#8; &#5;
</p>
<p>correspondant a&#768; la feuille choisie.
</p>
<p>Me&#770;me si les gains obtenus en reconnaissance sont de&#769;cevants par rapport aux gains constate&#769;s en
perplexite&#769;, ils sont ne&#769;anmoins significatifs et valident l&#8217;apport d&#8217;une segmentation pre&#769;alable du
corpus d&#8217;apprentissage en diffe&#769;rents sous-corpus. Il n&#8217;est cependant pas e&#769;vident de choisir a
priori, lors de la reconnaissance, l&#8217;un des sous-mode&#768;les uniquement a&#768; partir de l&#8217;historique du
dialogue en cours. De plus, il se peut que certaines situations du test correspondent a&#768; plusieurs
sous-corpus de l&#8217;apprentissage. Pour ces raisons, nous pre&#769;sentons maintenant une me&#769;thode de
se&#769;lection dynamique de sous-ML base&#769;e sur une exploration hie&#769;rarchique de l&#8217;arbre contenant
les ML.
</p>
<p>classe PP &#9;&#11;&#10;&#5; &#12; &#10;&#5; &#13; &#14; &#8; PP &#3; &#5; &#6; &#7; &#8; &#8; &#5; gain Err &#9;&#11;&#10;&#5; &#12; &#10;&#5; &#13; &#14; &#8; Err &#3; &#5; &#6; &#7; &#8; &#8; &#5; gain
&#15;&#17;&#16;&#19;&#18;&#19;&#20;&#21;&#16;&#21;&#22;&#17;&#16; &#23;&#11;&#24; &#25;ff&#26; fi&#11;&#24; flffi&#25; &#31;! ff&#24; &#25;ff&#23; %  &#23;!&#24; &#26;ffi&#23;  fffiffi&#24; &#26;ff&#25;  &quot;&#11;&#24; &#26;ffifl %
&#15;&#21;&#16;&#19;#&#21;$&#19;%'&amp;(&#16;  fl&#11;&#24; &#25;ffi&#31;  &quot;!&#24; fiffi &#26;fffl!&#24; &#26; ) % &#31; )*&#24; fi &#31;ff&#26;&#11;+ fi &#23; &#26;&#11;&#24; fi %
&#18;&#21;&#20;&#19;&#16;&#19;&amp;&#4;&#22;-,ffi$&#19;%  &#26;&#11;&#24; .ffi. &#25;!&#24; fiff&#31; &#26;ff.!&#24; flff&#31; % &#31;fffl!&#24; &#23; &#31;ffi.&#11;&#24; )ffi&#23; .&#11;&#24; &#31;&#11; %
/
</p>
<p>&#20;&#21;&#22;-&#15;&#17;&#16; &#31;ff.&#11;&#24; )ffi) &#23;!&#24; &#23;ffi&#26; &#26;ffi&#23;&#11;&#24; &quot;ff. % .fffl!&#24; &#26;ffi&#31; .ffi&quot;&#11;&#24;  &#31;  ff %
</p>
<p>Table 1: Re&#769;sultats en perplexite&#769; et taux d&#8217;erreurs/mot par classe de mots sur la segmentation
hie&#769;rarchique
</p>
<p>4 Se&#769;lection dynamique de sous-mode&#768;les de langage
</p>
<p>Les syste&#768;mes de reconnaissance disposant de plusieurs ML utilisent ge&#769;ne&#769;ralement deux strate&#769;gies :
soit les ML sont combine&#769;s a&#768; l&#8217;aide de coefficients fixes ou dynamiques (Kalai et al., 1999) ; soit
un processus de se&#769;lection intervient avant la reconnaissance pour de&#769;terminer dans quelle situa-
tion le syste&#768;me se trouve (d&#8217;un point de vue the&#769;matique ou du point de vue de l&#8217;historique du
dialogue) et le ML est choisi en conse&#769;quence (Riccardi &amp; Gorin, 2000).
Notre me&#769;thode de se&#769;lection dynamique emprunte a&#768; chacune de ces me&#769;thodes : d&#8217;un cote&#769; notre
arbre de sous-ML contient de&#769;ja&#768; des combinaisons de ML, et il suffit de parcourir une branche
depuis la racine jusqu&#8217;a&#768; une feuille pour spe&#769;cialiser de plus en plus la reconnaissance ; d&#8217;un
autre cote&#769; nous allons choisir un sous-mode&#768;le en parcourant l&#8217;arbre gra&#770;ce a&#768; un processus de
se&#769;lection utilisant les re&#769;sultats d&#8217;un premier de&#769;codage. Cette me&#769;thode, inspire&#769;e des me&#769;thodes
d&#8217;adaptation de mode&#768;les acoustiques aux caracte&#769;ristiques d&#8217;un locuteur, permet d&#8217;adapter le ML
a&#768; la situation de dialogue de&#769;tecte&#769;e.
</p>
<p>Dans cette me&#769;thode, un premier de&#769;codage est effectue&#769; en utilisant le ML ge&#769;ne&#769;ral associe&#769; a&#768; la
racine de l&#8217;arbre. Cette premie&#768;re hypothe&#768;se, appele&#769;e 021 , va nous servir a&#768; se&#769;lectionner un noeud
de l&#8217;arbre dont le sous-ML correspondant sera utilise&#769; pour effectuer un deuxie&#768;me de&#769;codage et
ainsi produire l&#8217;hypothe&#768;se 0&#19;3 . La me&#769;thode de se&#769;lection consiste simplement a&#768; parcourir l&#8217;arbre,
depuis la racine, en choisissant a&#768; chaque noeud le fils qui offre le sous-ML ayant la perplexite&#769;
la plus basse sur 0 1 . Lorsqu&#8217;on arrive a&#768; une feuille, ou lorsque la descente d&#8217;un noeud en
son fils n&#8217;offre pas un gain de perplexite&#769; sur 041 , l&#8217;algorithme s&#8217;arre&#770;te et le sous-ML attache&#769;
au noeud courant est se&#769;lectionne&#769; pour effectuer le second de&#769;codage. En proce&#769;dant ainsi, on ne
fait aucune hypothe&#768;se sur l&#8217;e&#769;tat du dialogue, et la structure hie&#769;rarchique de l&#8217;arbre permet de
me&#769;langer divers ML pour traiter n&#8217;importe quelle phrase prononce&#769;e par l&#8217;utilisateur.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>F. Be&#769;chet, Y. Este&#768;ve, R. De Mori
</p>
<p>Pour e&#769;valuer la me&#769;thode de se&#769;lection dynamique, nous avons dans un premier temps calcule&#769;
toutes les hypothe&#768;ses &#0;&#2;&#1; correspondant aux phrases du corpus de test. Pour chacune d&#8217;entre
elle, nous avons se&#769;lectionne&#769; le noeud &#3; avec la me&#769;thode pre&#769;sente&#769;e au paragraphe pre&#769;ce&#769;dent.
Pour chaque noeud &#4; sur le chemin de la racine a&#768; &#3; , nous avons e&#769;value&#769; les performances du
sous-ML &#5;&#7;&#6;&#9;&#8; &#10; &#11; &#12; &#13; &#14; en terme de taux d&#8217;erreurs/mot sur l&#8217;ensemble du corpus de test. Plus &#4;
augmente, plus le sous-ML se spe&#769;cialise, et l&#8217;optimum devrait se trouver en &#3; . Les re&#769;sultats
sont pre&#769;sente&#769;s dans le tableau 2. Il est inte&#769;ressant de constater que la courbe respecte le com-
portement attendu : le taux d&#8217;erreurs/mot diminue au fur et a&#768; mesure de la descente dans l&#8217;arbre.
Me&#770;me si on n&#8217;obtient pas les gains pre&#769;sente&#769;s dans le paragraphe 3.3 a&#768; cause des erreurs con-
tenues dans &#0;
</p>
<p>&#1;
</p>
<p>, les gains sont toutefois re&#769;guliers et semblent justifier la me&#769;thode. Cependant
une marge d&#8217;ame&#769;lioration importante re&#769;side dans la me&#769;thode de se&#769;lection pour s&#8217;approcher de
la se&#769;lection optimale.
</p>
<p>prof. 0 1 2 4 6 8 10 12
err. &#15; &#16;&#18;&#17; &#19; &#15;&#20;&#16;&#18;&#17; &#21; &#15; &#16;&#18;&#17; &#15; &#15;&#20;&#16;&#18;&#17; &#22; &#15;&#20;&#23;&#24;&#17; &#25; &#15;&#26;&#23;&#24;&#17; ff &#15;&#20;&#23;&#18;&#17; ff &#15;&#26;&#23;&#24;&#17; &#19;
</p>
<p>Table 2: Evolution du taux d&#8217;erreurs/mot en fonction de la profondeur dans l&#8217;arbre
</p>
<p>5 Conclusion
</p>
<p>Les me&#769;thodes de segmentation de corpus pre&#769;sente&#769;es re&#769;pondent aux questions pose&#769;es dans l&#8217;in-
troduction : en comple&#769;tant une me&#769;thode base&#769;e sur l&#8217;e&#769;tude de situations de dialogue avec une
me&#769;thode utilisant un crite&#768;re purement statistique, nous montrons qu&#8217;un gain significatif, a&#768; la fois
en perplexite&#769; et en taux d&#8217;erreurs/mot peut e&#770;tre obtenu a&#768; condition de choisir le sous-mode&#768;le de
langage ade&#769;quat. Notre me&#769;thode de se&#769;lection dynamique permet d&#8217;adapter la reconnaissance a&#768;
la phrase prononce&#769;e en re&#769;pondant au proble&#768;me du choix du ML. Nous pensons cependant que
les re&#769;sultats obtenus pourraient e&#770;tre ame&#769;liore&#769;s en augmentant la robustesse de la me&#769;thode de
se&#769;lection aux erreurs de reconnaissance des hypothe&#768;ses &#0;&#2;&#1; .
</p>
<p>Re&#769;fe&#769;rences
</p>
<p>KALAI A., CHEN S., BLUM A. &amp; ROSENFELD R. (1999). On-line algorithms for combining language
models. In ICASSP.
KUHN R. &amp; DE MORI R. (1996). The application of semantic classification trees to natural language
understanding. IEEE Transactions on Pattern Analysis and Machine Intelligence, 17(5), 449&#8211;460.
RICCARDI G. &amp; GORIN A. L. (2000). Stochastic language adaptation over time and state in natural
spoken dialogue systems. IEEE Transactions on Speech and Audio, 8,1.
SADEK D., FERRIEUX A., COZANNET A., BRETIER P., PANAGET F. &amp; SIMONIN J. (1996). Effective
human-computer cooperative spoken dialogue: the ags demonstrator. In ICSLP&#8217;96, USA.
</p>
<p>SPRIET T. &amp; EL-BE&#768;ZE M. (1995). Etiquetage probabiliste et contraintes syntaxiques. Traitement Au-
tomatique des Langues, Vol 36, n1-2.</p>

</div></div>
</body></html>