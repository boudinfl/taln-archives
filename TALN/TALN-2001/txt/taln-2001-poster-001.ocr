TALN 2001, Tours, 2-5 juillet 2001

Modéles de langage hiérarchiques pour les applications de
dialogue en parole spontanée

F. Béchet, Y. Esteve, R. De Mori
LIA - Université d’Avignon - BP1228 - Avignon Cedex 9

1 Résumé - Abstract

Le cadre de cette étude 1 concerne les systemes de dialogue via le téléphone entre un serveur de
données et un utilisateur. Nous nous intéresserons au cas de dialogues non contraints ou l’util-
isateur a toute liberté pour formuler ses requétes. Généralement, le module de Reconnaissance
Automatique de la Parole (RAP) de tels serveurs utilise un seul Modele de Langage (ML) de
type bigramme ou trigramme pour modéliser l’ensemble des interventions possibles de l’util-
isateur. Ces ML sont appris sur des corpus de phrases retranscrites a partir de sessions entre le
serveur et plusieurs utilisateurs. Nous proposons dans cette étude une méthode de segmenta-
tion de corpus d’apprentissage de dialogue utilisant une stratégie mixte basée a la fois sur des
connaissances explicites mais aussi sur l’optimisation d’un critere statistique. Nous montrons
qu’un gain en terme de perplexité et de taux d’erreurs/mot peut étre constaté en utilisant un en-
semble de sous modeles de langage issus de la segmentation plutot qu’un modele unique appris
sur l’ensemble du corpus.

Within the framework of Human-Computer dialogue in spontaneous speech, we propose in this
paper a method which automatically builds, from a training corpus, a set of Language Models
(LMs) organized as a binary tree. Each LM correspond to a speciﬁc dialogue state, where
the general LM is attached to the root node and the more specialized ones are represented by
the leaves. Such LMs can be used to automatically adapt the decoding process to the dialog
situation performed. We propose a two-pass decoding strategy, which implements this idea by
dynamically selecting a set of LMs according to the dialog situation detected.

Reconnaissance Automatique de la Parole ; Modeles de Langage statistique ; Serveurs de Dia-
logue ; Arbre de Decision

2 Introduction

Les Modeles de Langage (ML) utilisés habituellement dans les systemes de reconnaissance
automatique de la parole sont basés sur une approche probabiliste nécessitant un apprentissage
sur corpus. Cet apprentissage permet d’estimer les probabilités de transition entre les mots
d’une meme phrase. Durant la reconnaissance, l’historique utilisé pour prédire le prochain mot
est généralement réduit aux deux ou trois mots précédents (modeles bigrammes ou trigrammes).

1Ces travaux sont réalisés en collaboration avec France-Telecom R&D sous le contrat 971b427

F. Béchet, Y. Esteve, R. De Mori

Si ces caractéristiques sont communes a l’ensemble des systemes, le nombre de ML utilisé et
leurs combinaisons dépendent fortement de l’application visée. Dans le cas d’un systeme de
dictée généraliste, il est bien difﬁcile de segmenter a priori les différents cas d’utilisation du
systeme : un seul ML, mélangeant themes et types de phrases, est généralement employé.

Dans les applications de dialogue pour les serveurs téléphoniques, il est en revanche possible
de segmenter le corpus d’apprentissage du ML selon différents états de dialogue correspondant
aux interactions entre le serveur et l’utilisateur. Cependant il reste a déterminer d’une part les
situations de dialogue les plus discriminantes du point de vue de la reconnaissance et d’autre
part la méthode de sélection et de combinaison des ML obtenus sur chacun des sous-corpus
d’apprentissage.

Ces travaux proposent des réponses a ces questions en présentant une méthode de classement
d’un corpus de dialogue en sous-corpus basée sur une approche Inixte : des connaissances
linguistiques explicites sont tout d’abord utilisées pour segmenter le corpus d’apprentissage du
ML. Puis, une technique de classiﬁcation statistique basée sur des arbres de décision permet
de segmenter a nouveau chacun des sous-corpus selon un critere largement utilisé en RAP :
la perplexité. Enﬁn, nous proposons un ML hiérarchique codant l’ensemble des sous-ML a
l’intérieur d’une structure d’arbre utilisable dans un décodage a deux passes.

3 Segmentation de corpus

Les corpus d’apprentissage des ML utilisés dans les systemes de RAP pour les applications de
dialogue téléphonique sont constitués de retranscriptions orthographiques de sessions de dia-
logue entre un utilisateur (na'1'f ou expert) et le serveur de dialogue. Ces sessions correspondent
au traitement d’une requéte complete d’un utilisateur, aboutissant ou non a un succes, com-
posées de questions et de réponses entre le serveur et l’utilisateur. Si le serveur admet un
dialogue ouvert, il est laissé toute liberté a l’utilisateur pour formuler ses requétes. Dans ce cas,
le systeme doit étre a meme de pouvoir traiter les phénomenes inhérents a la parole spontanée,
tels que les phrases agrammaticales, les hésitations, les reprises, etc. Cette extreme variabilité
est compensée par, d’une part un domaine sémantique généralement restreint (horaire de train,
programme de cinéma, etc.), d’autre part des régularités fortes dans les structures de phrases
liées a certaines situations de dialogue. Ainsi, les premieres requétes exprimées par un utilisa-
teur commencent généralement par des patrons de phrases tels que : je + [voudrais , recherche
, de’sire, ...]

Les diverses situations de dialogue qui peuvent étre rencontrées dans une session entre un util-
isateur et un serveur dépendent bien évidemment de l’application visée. Cependant, a un niveau
d’abstraction élevé, il est possible de distinguer des macro-classes de situations de dialogue
indépendantes du serveur et du domaine d’application.

Avant de présenter notre méthode de découpage de corpus utilisant ces macro-classes, nous
présentons les données sur lesquelles ont été effectuées toutes nos expériences :

Nous avons utilisé, dans cette étude, le corpus AGS (Sadek et al., 1996) constitué de transcrip-
tions de dialogue entre plusieurs utilisateurs et un serveur téléphonique. Deux domaines d’ap-
plication sont visés par le serveur AGS : les informations météorologiques et la recherche de
petites annonces d’emploi. Le corpus d’apprentissage est constitué de 9842 phrases prononcées
par plusieurs locuteurs et couvrant les deux domaines d’application. Le corpus de test est com-

Modeles de langage hiérarchiques

posé de 1419 phrases représentant plusieurs sessions et plusieurs locuteurs différents. Le vo-
cabulaire utilisé dans le corpus d’apprentissage contient 823 mots.

3.1 Segmentation en macro-classes

Une étude détaillée du corpus d’apprentissage permet de regrouper les interventions de l’util-
isateur en différentes classes. Nous avons choisi, dans un premier temps, d’isoler des macro-
classes indépendantes de l’état d’avancement du dialogue et des interventions de la machine.
Ce choix s’explique essentiellement par le faible nombre de sessions completes disponibles
dans le corpus d’apprentissage. Ces macro-classes sont déterminées a partir de la structure des
phrases prononcées par l’utilisateur, structure représentée sous la forme de patrons syntaxiques
et lexicaux.

Les phrases du corpus d’apprentissage sont tout d’abord étiquetées et lemmatisées a l’aide d’un
tagger morpho-syntaxique statistique (Spriet & El-beze, 1995). Une analyse syntaxique par-
tielle est ensuite effectuée sur le corpus étiqueté aﬁn d’extraire les syntagmes composant les
phrases. Par exemple, la phrase : ”J’aurais aime’ connaitre le numéro de téléphone  ” sera
étiquetée :

[ (J ’, PPER) (aurais,AA) (aimé, VRPAS) (connaitre, VINF)]
[(le,DET) (numér0,N) (de,PREP) (te’le’ph0ne,N)]

Nous avons déterminé quatre macro-classes a partir du corpus d’apprentissage : RE QU ET E,
contient l’ensemble des phrases représentant une premiere demande de l’utilisateur juste apres
le prompt du systeme ; QUESTION, contient les questions posées par l’utilisateur apres une
réponse du serveur ; REPON S E, contient les réponses de l’utilisateur a une question du
serveur ; AUTRE, contient ce qui n’a pu étre étiqueté dans les autres classes. On trouve
ici des interventions de gestion du dialogue (ex : ”annulati0n”, ”au rev0ir”, ”merci”) des
phénomenes extra linguistiques (ex : ”ah”, ”hum”, ”euh”) des phrases tronquées ou encore
des mouvements d’humeur suite a une mauvaise interpretation du dialogue par la machine (ex :

7’ 7’ 7

”laisse tomber , c est pas grave”).

Un ensemble de regles basées sur la présence de certains mots, de certaines classes syntax-
iques ou encore de certaines structures syntaxiques ont été écrites aﬁn de classer les phrases
d’apprentissage dans chacune de ces catégories.

3.2 Segmentation hiérarchique

Cette méthode consiste a rafﬁner la premiere segmentation du corpus en macro-classes en op-
timisant, de maniere iterative, un parametre inﬂuencant directement la reconnaissance : la per-
plexité. C’est une mesure communément employée pour estimer les performances d’un modele
de langage indépendamment de l’aspect acoustique de la reconnaissance. Bien qu’il n’existe
pas de lien formel liant les performances de reconnaissance et la mesure de perplexité, ces
deux quantités suivent généralement des évolutions communes. En mesurant la perplexité d’un
modele sur un texte, on est a meme d’apprécier la capacité du modele a prédire ce meme texte.
Plus cette mesure est petite, plus le texte est proche du corpus utilisé pour apprendre le modele.

Durant cette phase de segmentation nous allons utiliser une structure d’arbre binaire ou deux
informations sont associées a chaque noeud : une expression réguliere et un sous-corpus sat-

F. Béchet, Y. Esteve, R. De Mori

isfaisant l’expression réguliere du noeud. Un noeud peut générer deux ﬁls si une extension de
l’expression réguliere courante permet de scinder le sous-corpus en deux et si des modeles de
langage appris sur ces deux sous-corpus ﬁls obtiennent des perplexités plus faibles que celle
obtenue avec le modele de langage du noeud pere. Cette méthode est inspirée des Arbres de
Classiﬁcation Sémantiques introduit par (Kuhn & de Mori, 1996).

Contrairement aux problemes de classiﬁcation résolus habituellement par des méthodes a base
d’arbres de décision, nous ne connaissons pas dans notre cas le nombre optimal de classes
a discerner. Le nombre minimal correspond au nombre de macro-classes déja présentées. Le
nombre maximal de classes est borné a la fois par la taille de corpus nécessaire a l’apprentissage
d’un modele bigramme et par le gain minimum en perplexité requis entre le noeud pere et les
deux noeuds ﬁls.

Le seuil choisi sur la taille minimale d’un sous-corpus permet de controler la taille de l’arbre.
La ﬁgure 1 présente les premieres branches d’un exemple d’arbre obtenu sur le corpus d’ap-
prentissage AGS en ﬁxant une taille minimale de 300 phrases pour chaque noeud. Cet arbre
contient 43 noeuds intemes et 45 feuilles, ce qui représente un ensemble de 88 sous-corpus et
sous-ML.

REQUETE

_ + répétez + H on QUESTION
0 U1 0 U i
I] OI]

.
a-Cote d Armor + Ron I
oui \ ou1 non
_ +moi +
“ I + cherche + H on A
0111 Gui
IIOII

+ cherche + le + mm _+ VppMs +
,A...- ‘J37 
0 0   A

+ le météa +
II

A \°" A

+ le téléphane +

_ H01]
0111

Figure 1: Exemple d’arbre de sous-ML

+
R‘
+

O
\

3.3 Evaluation de la segmentation hiérarchique

Nous avons évalué l’arbre de sous-ML a travers deux aspects : les gains en perplexité obtenus
sur le corpus de test et l’évolution du taux d’erreurs/mot en utilisant le modele général et
les sous-ML (tableau 1). Pour cela, nous avons analysé les phrases retranscrites du corpus
de test avec les expressions régulieres liées aux noeuds de l’arbre et nous avons determine a

Modeles de langage hiérarchiques

quelle feuille chacune des phrases appartenait. Enﬁn, nous les avons décodées avec le sous-ML
M L fe,,,»11e correspondant a la feuille choisie.

Meme si les gains obtenus en reconnaissance sont décevants par rapport aux gains constatés en
perplexité, ils sont néanmoins signiﬁcatifs et valident l’apport d’une segmentation préalable du
corpus d’apprentissage en différents sous-corpus. I1 n’est cependant pas évident de choisir a
priori, lors de la reconnaissance, l’un des sous-modeles uniquement a partir de l’historique du
dialogue en cours. De plus, il se peut que certaines situations du test correspondent a plusieurs
sous-corpus de l’apprentissage. Pour ces raisons, nous présentons maintenant une méthode de
sélection dynamique de sous-ML basée sur une exploration hiérarchique de l’arbre contenant
les ML.

013333 Ppgénémz Ppfeuille gain Effgénéraz Efffemzze gain
REQUETE 9,33 7,68 21,39% 19,39 17,33 10,36%
REPONSE 16,82 10, 71 36, 34 % 24, 7 23.79 3, 7%
QUESTION 13, 55 3, 72 35, 62 % 26, 9 25,49 5, 21%
AUTRE 25,44 9,93 39,05% 56,32 50,12 11%

Table 1: Résultats en perplexité et taux d’erreurs/mot par classe de mots sur la segmentation
hiérarchique

4 Sélection dynamique de sous-modéles de langage

Les systemes de reconnaissance disposant de plusieurs ML utilisent généralement deux stratégies :
soit les ML sont combines a l’aide de coefﬁcients ﬁxes ou dynamiques (Kalai et al., 1999) ; soit
un processus de sélection intervient avant la reconnaissance pour déterminer dans quelle situa-
tion le systeme se trouve (d’un point de vue thématique ou du point de vue de l’historique du
dialogue) et le ML est choisi en conséquence (Riccardi & Gorin, 2000).

Notre méthode de sélection dynamique emprunte a chacune de ces méthodes : d’un coté notre
arbre de sous-ML contient déja des combinaisons de ML, et il sufﬁt de parcourir une branche
depuis la racine jusqu’a une feuille pour spécialiser de plus en plus la reconnaissance ; d’un
autre coté nous allons choisir un sous-modele en parcourant l’arbre grace a un processus de
sélection utilisant les résultats d’un premier décodage. Cette méthode, inspirée des méthodes
d’adaptation de modeles acoustiques aux caractéristiques d’un locuteur, permet d’adapter le ML
a la situation de dialogue détectée.

Dans cette méthode, un premier décodage est effectué en utilisant le ML général associé a la
racine de l’arbre. Cette premiere hypothese, appelée H1, Va nous servir a sélectionner un noeud
de l’arbre dont le sous-ML correspondant sera utilisé pour effectuer un deuxieme décodage et
ainsi produire l’hypothese H 2. La méthode de sélection consiste simplement a parcourir l’arbre,
depuis la racine, en choisissant a chaque noeud le ﬁls qui offre le sous-ML ayant la perplexité
la plus basse sur H1. Lorsqu’on arrive a une feuille, ou lorsque la descente d’un noeud en
son ﬁls n’offre pas un gain de perplexité sur H1, l’algorithme s’arréte et le sous-ML attaché
au noeud courant est sélectionné pour effectuer le second décodage. En procédant ainsi, on ne
fait aucune hypothese sur l’état du dialogue, et la structure hiérarchique de l’arbre permet de
mélanger divers ML pour traiter n’importe quelle phrase prononcée par l’utilisateur.

F. Béchet, Y. Esteve, R. De Mori

Pour évaluer la méthode de sélection dynamique, nous avons dans un premier temps calculé
toutes les hypotheses H1 correspondant aux phrases du corpus de test. Pour chacune d’entre
elle, nous avons sélectionné le noeud N avec la méthode présentée au paragraphe précédent.
Pour chaque noeud i sur le chemin de la racine a N, nous avons évalué les performances du
sous-ML M Lmwdl. en terme de taux d’erreurs/mot sur l’ensemble du corpus de test. Plus i
augmente, plus le sous-ML se spécialise, et l’optimum devrait se trouver en N. Les résultats
sont présentés dans le tableau 2. Il est intéressant de constater que la courbe respecte le com-
portement attendu : le taux d’erreurs/mot diminue au fur et a mesure de la descente dans l’arbre.
Meme si on n’obtient pas les gains présentés dans le paragraphe 3.3 a cause des erreurs con-
tenues dans H1, les gains sont toutefois réguliers et semblent justiﬁer la méthode. Cependant
une marge d’amélioration importante réside dans la méthode de sélection pour s’approcher de
la sélection optimale.

prof. 0 1 2 4 6 8 10 12
err. 24.7 24.5 24.2 24.1 23.9 23.8 23.8 23.7

Table 2: Evolution du taux d’erreurs/mot en fonction de la profondeur dans l’arbre

5 Conclusion

Les méthodes de segmentation de corpus présentées répondent aux questions posées dans l’in-
troduction : en complétant une méthode basée sur l’étude de situations de dialogue avec une
méthode utilisant un critere purement statistique, nous montrons qu’un gain signiﬁcatif, a la fois
en perplexité et en taux d’erreurs/mot peut etre obtenu a condition de choisir le sous-modele de
langage adéquat. Notre méthode de sélection dynamique permet d’adapter la reconnaissance a
la phrase prononcée en répondant au probleme du choix du ML. Nous pensons cependant que
les résultats obtenus pourraient étre améliorés en augmentant la robustesse de la méthode de
sélection aux erreurs de reconnaissance des hypotheses H1.

Références

KALAI A., CHEN S., BLUM A. & ROSENFELD R. (1999). On—line algorithms for combining language
models. In ICASSP.

KUHN R. & DE MORI R. (1996). The application of semantic classiﬁcation trees to natural language
understanding. IEEE Transactions on Pattern Analysis and Machine Intelligence, 17(5), 449-460.

RICCARDI G. & GORIN A. L. (2000). Stochastic language adaptation over time and state in natural
spoken dialogue systems. IEEE Transactions on Speech and Audio, 8,1.

SADEK D., FERRIEUX A., COZANNET A., BRETIER P., PANAGET F. & SIMONIN J. (1996). Effective
human—computer cooperative spoken dialogue: the ags demonstrator. In I CSLP ’96, USA.

SPRIET T. & EL—BEZE M. (1995). Etiquetage probabiliste et contraintes syntaxiques. Traitement Au-
tomatique des Langues, Vol 36, n1-2.

