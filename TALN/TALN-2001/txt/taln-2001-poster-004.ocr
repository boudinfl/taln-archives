TALN 2001, Tours, 2-5jui11et 2001

Cartographie de Textes:
Une aide a l’utilisateur dans le cadre
de la découverte de nouveaux domaines

Isabelle Debourges, Sylvie Guilloré-Billot, Christel Vrain
Laboratoire d’Informatique Fondamentale d’Orléans
Batiment IIIA
Rue Léonard de Vinci — B.P. 6759
F-45067 Orléans Cedex 2
{debourge, guillore, cv}@lifo.univ-orleans.fr

Résumé - Abstract

Nous présentons les avancées d’un projet dans un theme que nous qualiﬁons de Cartographic de
Textes qui permet a l’utilisateur novice d’explorer un nouveau domaine par navigation au sein
d’un corpus homogene grace in des cartes conceptuelles interactives. Une carte est composée de
concepts pertinents relativement a la requéte initiale et a son évolution, au sein du corpus; des
relations extraites du corpus les lient aux mots de la requéte. Des techniques d’apprentissage
automatique sont combinées avec des heuristiques statistiques de Traitement Automatique des
Langues pour la mise en évidence de collocations aﬁn de construire les cartes.

Mots clés: Cartographic de Textes, Recherche d’Information, Extraction d’Information, Ap-
prentissage Automatique.

We present an ongoing research project on the new ﬁeld of Text Mapping that allows a novice
user to explore a new domain by navigation through an homogeneous corpus thanks to inter-
active conceptual maps. A map is composed of concepts (the nodes) depending on the user’s
request and its evolution, and semantic/lexical relations (the links). Machine Learning tech-
niques are combined with Natural Language Processing methodologies to build the maps.

Keywords: Text Mapping, Information Retrieval, Information Extraction, Machine Learning.

1 Introduction

Les utilisateurs ont aujourd’hui besoin d’outils qui leur permettent de retrouver ce qu’ils cher-
chent au sein de grandes sources d’informations. La Recherche Documentaire et l’Extraction
d’Information sont les deux grands types d’aide Inis a leur disposition.

La Recherche Documentaire (Salton, 1995; Fondin, 1998) nécessite la saisie de mots clés par
l’utilisateur pour produire une sélection de textes jugés pertinents vis a vis de cette requéte.
Mais l’utilisateur n’a que tres rarement la possibilité de parcourir lui-méme l’ensemble des
textes sélectionnés par un outil de recherche documentaire aussi performant soit-il. Le manque
de temps et/ou le volume des textes a exploiter en sont les principales causes.

L’Extracti0n d’Inf0rInati0n (Wilks, 1997) peut, a partir d’un ensemble de textes traitant
d’un theme commun et de patrons d’extraction (ou templates), fournir des instanciations de
ces patrons a partir des informations contenues dans les textes du corpus foumi. L’utilisation

Isabelle Debourges, Sylvie Guilloré-Billot, Christel Vrain

d’un outil d’Extraction d’Information nécessite que l’utilisateur soit sufﬁsamment familier du
theme traité par le corpus pour étre capable de déﬁnir ce patron. On pourrait envisager que
l’acquisition automatique de patrons (Riloff, 1996; Califf, 1998) puisse aider notre utilisa-
teur. Mais ces outils demandent une validation des patrons qu’ils proposent par l’utilisateur. . . ce
qui est difﬁcile si l’utilisateur ne connait pas le domaine .

Ainsi, un utilisateur qui souhaite découvrir un nouveau domaine ne peut pas accéder aisément
aux informations qu’il recherche sur celui-ci. Les aides proposées par la Recherche Documen-
taire et l’Extraction d’Information sont une premiere avancée, mais elles restent largement in-
sufﬁsantes dans le cas ou la recherche porte sur un domaine ou le nombre des textes disponibles
n’est pas restreint. Le probleme subsiste pour un corpus ne contenant pas d’informations corres-
pondant a un meme modele et donc pour lequel on ne peut pas déﬁnir de patron d’extraction.

2 Architecture d’une solution

Aﬁn de s’attaquer a ce probleme de recherche d’information pertinente dans des collections de
textes, nous proposons une méthode innovante pour la construction de cartes conceptuelles de
textes. L’ architecture générale, présentée a la ﬁgure ?? est la suivante: l’utilisateur constitue, a
l’aide d’un outil de recherche documentaire, un corpus homogenel spécialisé dans le domaine
qui l’intéresse. Aﬁn de lui permettre d’extraire les connaissances présentes au sein de son
corpus, la Cartographie de Textes lui propose des cartes conceptuelles interactives présentant
les concepts les plus pertinents ainsi que les relations qui les lient, au sein des textes. Les
cartes conceptuelles proposées dépendent directement de la requéte et de son évolution. Ainsi
l’utilisateur peut-il demander une carte plus spéciﬁque autour d’un concept qu’il sélectionne.
La carte obtenue tiendra alors compte des requétes précédentes.

Une carte conceptuelle est un réseau dynamique construit autour des mots de la requéte. Elle
est constituée:

0 de concepts pertinents par rapport a la requéte courante, en tenant compte des requétes
précédentes

0 des relations sémantiques ou lexicales qui émergent au sein du corpus entre les concepts
extraits et les mots de la requéte.

Comme les cartes sont interactives et dépendent de l’évolution de la requéte de l’utilisateur, des
informations plus ﬁnes peuvent étre obtenues a partir de la carte courante. Ainsi, un utilisa-
teur novice qui souhaite découvrir un nouveau domaine peut-il constituer un corpus homogene
spécialisé en utilisant un outil de recherche documentaire. Il peut ensuite, au ﬁl des cartes et
des nouvelles requétes explorer les notions fortes contenues au sein des textes. Il prend ainsi
connaissance du contenu sémantique du corpus sans avoir a procéder a une lecture exhaustive
du texte. De plus, les idées qui ressortent dans les cartes peuvent lui permettre de retrouver
rapidement les séquences de texte qui y sont liées, par des pointeurs vers le texte original. Les
cartes obtenues et les connaissances acquises lui permettront de construire, s’il le souhaite, des
patrons d’extraction pertinents par rapport au corpus. La cartographie de textes constitue en ce
sens un lien nouveau entre recherche documentaire et extraction d’information.

Nous proposons une méthode de construction automatique des cartes conceptuelles. Elle est
composée de trois grandes étapes. Le corpus est tout d’abord prétraité pour permettre des
calculs plus rapides au cours des étapes suivantes. La construction d’une carte comprend:

1. l’extraction des concepts pertinents au sein du corpus, par rapport a la requéte courante et
aux requétes antérieures.
1il est préférable que le corpus soit homogéne du point de vue du genre des textes et de la langue utilisée

Cartographie de Textes

2. l’emergence des relations semantiques et lexicales presentes au sein du corpus, entre les

mots cles de la reguete et les concepts extraits.
Travaux apparentes

Le formalisme graphique que nous utilisons pour les cartes conceptuelles peut etre apparente a
celui des graphes conceptuels (Sowa, 1984), eux meme derives des reseaux semantiques (Quil-
lian, 1968). La difference majeure reside dans le fait que nous ne representons pas les in-
formations presentes au niveau d’une phrase, mais plutet une generalisation des informations
disponibles dans le corpus, autour d’un theme represente par le mot cle. De plus, dans les cartes
conceptuelles que nous construisons, les concepts constituent les noeuds tandis que les relations
etiquettent les liens.

3 Prétraitements et Extraction de Concepts

3.1 Prétraitements

Une phase de pretraitement du corpus permet de realiser des traitements simples utilises au
cours des traitements plus lourds que sont l’extraction des concepts et l’emergence des relations.
Le texte est decoupe en phrases, les mots vides et caracteres speciaux sont omis. Le texte est
lemmatise et une categorie grammaticale est associee a chaque mot (Debourges et al., 2001).

3.2 Extraction des Concepts

L’ algorithme de selection des concepts les plus pertinents par rapport a la requete (ensemble
de mots cles) est base sur la volonte de selectionner les unites lexicales (ou polylexicales) qui
apparaissent dans le contexte de la requete. Pour cela, les mots cles sont tout d’abord etendus
en ajoutant les synonymes/hyponymes/hyperonymes aﬁn de selectionner les phrases traitant de
la meme idee, meme si l’auteur a fait un effort pour ne pas repeter exactement le meme mot.
Ensuite, on selectionne les phrases qui contiennent les mots etendus; l’ensemble des termes
les plus frequemment rencontres dans le cont exte de la requéte est genere: les
concepts qui apparaissent le plus avec les mots cles sont selectionnes. Les iterations suivantes
du processus (selection de phrases, et calcul de frequents) propagent la selection des mots
apparaissant dans le contexte de la requete. Le processus s’arrete quand le point ﬁxe est atteint.
Cet algorithme d’extraction des concepts est original sous deux aspects: l’extraction des con-
cepts depend directement des mots cles fournis par l’utilisateur et l’heu1istique est constr11ite
sur une recherche de point ﬁxe (Debourges et al., 2001). Ces resultats mettent en evidence la
dependance des cartes par rapport a l’evolution de la requete.

3.3 Exemple

Nous nous interessons ici a des resultats obtenus sur un corpus decrivant des universites. Ce
corpus est compose de pres de 1000 textes descriptifs d’autant d’universites reparties sur les 5
continents. Les textes ont ete recueillis sur le webz. Chaque texte est long d’une a deux pages.
Les concepts obtenus avec le mot cle initial UNIVERSITY et un rafﬁnement sur RESEARCH
sont presentes dans la ﬁgure 1. La ﬁgure 2 montre la carte obtenue avec le mot cle initial
RESEARCH.

4 Emergence de Relations

4.1 Motivations

L’extraction des concepts donne une approximation de l’intensite des liens qui existent entre
un mot cle (C 1) et un concept extrait (C 2): elle donne une mesure numerique fondee sur le
denombrement des apparitions conjointes au point ﬁxe.

zhttp://www-icd1.open.ac.uk/icdl/, site de1’Intemational Centre for Distance Learning

Isabelle Debourges, Sylvie Guilloré-Billot, Christel Vrain

education semester

academic registration
course
research
student
ﬁeld
level ti _t
N’ ac v1 y
11 T UNIVERSITY }
co age \ RESEARCH
J diploma /
programme institute
centre
degree campus
school admission bachelor

Figure 1: Mot clé initial UNIVERSITY et rafﬁnement sur RESEARCH

teacher ve oppemem
de 1
/ education
RESEARCH 3

technology
/ \

C€IlU'6

science

Figure 2: Mot clé initial RESEARCH.

Des étiquettes sémantiques/lexicales sur un lien entre un mot clé et un concept émergent per-
mettent a l’utilisateur de connaitre les idées qui relient ces deux notions, au sein du corpus.
L’utilisateur découvre de fagon plus complete le contenu du corpus qu’il a fourni, sans avoir a
regarder les textes originaux.

Dans un premier temps nous étiquetons le lien entre un mot clé et un concept par la liste des
unités lexicales (composées de un ou plusieurs mots) qui apparaissent fréquemment avec ces
deux mots. L’ algorithme est donné en 4.2.

Par exemple, les expérimentations menées sur le corpus des universités nous montrent, entre
autres, que le concept ADMISSION émerge avec le mot clé UNIVERSITY (ﬁgure 1). L’utilisateur
a, a ce niveau, conscience de l’existence d’un lien fort entre ces deux notions. Ces memes ex-
périmentations nous permettent alors d’expliciter les liens entre UNIVERSITY et ADMISSION
(ﬁgure 3-a) avec l’émergence des unités lexicales APPLICANT STUDENT ENTRANCE, DE-
GREE, REQUIREMENT. On retrouve alors les idées fortes concernant l’entrée a l’Université:

. 2 - \ - - 2 . - I -
Pour devemr etudzant+ (entrer a l ’Unwe7“szte@), un centam mveau' est requzsg‘ pour les p0stulants*.
UNIVERSITY UNIVERSITY

  
   
  

_ *
applicant
student*

entrance @

  
    

I distance education

degree

requirement“ b. distance learning

ADMISSION STUDENT

Figure 3: Exemples de relations issues d’expérimentations menées sur le prototype

4.2 Algorithme

Aﬁn de proposer des étiquettes sémantiques et/ou lexicales aux liens entre mots clés et concepts,
nous avons étudié l’apport d’algorithmes initialement dédiés a l’extraction de connaissances
dans des bases de données transactionnelles, permettant de faire émerger des associations entre

Cartographie de Textes

items d’une meme transaction (Srikant et al., 1996; ?; Agrawal et al., 1994). Ces algorithmes
sont fondés sur une notion de support déﬁnie comme suit:

l’ensemble Si d ’items a pour support 8 dans l’ensemble des transactions
D si 8% des transactions de D contiennent Z ’ensemble Si.

Seuls les ensembles d’items fréquents3 sont recherchés. Nous avons implanté un tel algorithme
ou une phrase est vue comme un ensemble d’items représentés par les mots. La recherche
s’effectue de la facon suivante:

1. chaque phrase contenant simultanément le mot clé C1 et le concept C2 est sélectionnée
et devient une transaction (sélection des cooccurrences de 0 1 et C 2)

2. l’algorithme d’Agrawal est exécuté sur les transactions et ne conserve que les ensembles
fréquents (émergence des collocations)

3. pour tout ensemble fréquent d’items Si, on déﬁnit Ri = Si\{C 1, C 2} come une relation
candidate entre C 1 et C 2, composée de un ou plusieurs mots.

On obtient ainsi les ensembles de mots qui apparaissent fréquemment avec les deux concepts
C1 et C2 entre lesquels on cherche les relations existantes au sein du corpus. Pourtant, ces
ensembles ont besoin d’étre ﬁltrés, puisque nous sommes intéressés par les relations seman-
tiques et/ou lexicales les plus pertinentes. Elles sont sélectionnées par une grammaire basée
sur les combinaisons d’étiquettes grammaticales apposées aux mots au cours du prétraitement.
Par exemple, parmi les relations composées de deux éléments nous préférerons la combinaison
(verbe + adv erbe) a la combinaison (adv erbe + adv erbe) moins pertinente, qui sera abandon-
nee.

4.3 Exemples

La ﬁgure 3-b présente les relations composées de un a deux mots qui émergent entre le mot
clé UNIVERSITY et le concept STUDENT, au sein du corpus. En effet, dans le cas présent,
il existe des ensembles fréquents Si de taille 3 et de taille 4 qui permettent l’eXtraction des
relations programme, degree et distance education, distance learning. L’ordre de présentation
des mots qui composent les unités polylexicales a ici été choisi manuellement. Un tel choix
sera prochainement inspiré par une consultation de leur ordre classique d’apparition au sein
du corpus. En particulier, on voit ici que le corpus s’intéresse aux programmes d’éducation
a distance (distance education et distance learning). Cette particularité du corpus s’explique
par son objectif initial: proposer des formations dans des universités des cinq continents a
l’ensemble des habitants de la planete.

5 Perspectives

Evolution de Palgorithme 4.2. L’ algorithme d’Agrawal ne se préoccupe pas de l’ordre des
items dans les transactions. Ainsi, l’ordre d’apparition des mots dans une phrase n’est pas pris
en considération dans l’algorithme dérivé que nous proposons. Pourtant, lorsque l’étiquette
obtenue pour la relation est une unité polylexicale, cet ordre a un role important a jouer. Cette
prise en compte de l’ordre d’apparition des mots dans la phrase constitue une prochaine étape
dans l’eXtraction des relations pour la construction des cartes conceptuelles.

Proposition de patrons d’extraction d’information. Le fait d’avoir découvert un domaine
(concepts et relations) po11rra permettre a l’utilisateur de déﬁnir des patrons d’extraction d’infor-
mation. L’une des applications dérivées des cartes conceptuelles est donc d’aider l’utilisateur

3Un ensemble Si est fréquent si son support est plus grand qu’un seuil donné: support(Si) 2 min_support

Isabelle Debourges, Sylvie Guilloré-Billot, Christel Vrain

dans cette tache. En effet, s’il dispose d’un corpus contenant des informations de meme
type, une aide a la généralisation des cartes peut contribuer a obtenir des patrons d’extraction
d’information. Cette généralisation sera basée sur deux types d’uniﬁcation:

0 les concepts émergents (qui apparaissent dans les cartes) peuvent étre regroupés au sein
d’un concept plus général en utilisant une ontologie

o deux relations identiques sur des liens différents issus d’un méme mot clé constituent un
indice de regroupement des concepts.

6 Conclusion

La Cartographie de Textes, telle que nous la proposons, établit un lien entre Recherche Docu-
mentaire et Extraction d’Information en proposant une méthode pour accéder a l’information
recherchée au sein de larges collections de textes. Un utilisateur peut ainsi découvrir un do-
Inaine sur un corpus obtenu par recherche documentaire et déﬁnir des patrons d’Extraction
d’ Information.

Les algorithmes que nous proposons pour la cartographie de textes sont basés sur des heuris-
tiques inspirées du Traitement Automatique des Langues d’une part, et l’utilisation de l’Appren-
tissage Automatique d’autre part. Nous avons délibérément privilégié des méthodes simples
pour des questions d’efﬁcacité et de portabilité.

Les algorithmes présentés pour la construction des cartes conceptuelles sont indépendants du
domaine étudié, et portables d’une langue a une autre. De plus ils ne requierent pas d’analyse
ﬁne du texte, d’ou une efﬁcacité accrue.

Références

Agrawal R., Srikant R. (1994), Fast Algorithm for Mining Association Rules, Actes de The VLDB Con-
ference.

Califf M-E. (1998), Relational Learning Techniques for Natural Language Information Extraction.

Debourges I., Guilloré S., Vrain C. (2001), Cartographic de Textes. Une nouvelle approche pour
l’exploration sémantique des corpus homogénes de grande dimension, RR-2001-01 du Laboratoire
d’Informatique Fondamentale d’Orléans.

Fondin H. (1998), Les modéles de recherche documentaire, Le traitement numérique des documents
Editions Hermes.

Novak J. D. (1993), How do we learn our lesson? 2 Taking students through the process, The Science
Teacher 60(3).

Quillian M.R. (1968), Semantic Memory, dans Semantic Information Processing, M.I.T. Press.

Riloff E. (1996), Automatically Generating Extraction Patterns from Untagged Text, Actes de Thirteenth
National Conference on Artificial Intelligence, AAAI-96, 1044-1049.

Salton G., McGill J. (1995), Introduction to Modern Information Retrieval Mc Graw Hill.
Sowa J .F. (1984), Conceptual Structures. Information Processing in Mind and Machine, Addison Welsey.

Srikant R., Agrawal R. (1996), Fast Discovery of Association Rules, Actes de Advances in knowledge
discovery and data mining, AAAI Press, 307-328.

VV1lks Y. (1997), Information Extraction as a Core Language Technology, Information Extraction 1997,
LNCS 1299, Springer, 1-9.

