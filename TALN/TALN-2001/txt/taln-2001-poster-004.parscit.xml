<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Agrawal</author>
<author>R Srikant</author>
</authors>
<title>Fast Algorithm for Mining Association Rules,</title>
<date>1994</date>
<booktitle>Actes de The VLDB Conference.</booktitle>
<marker>Agrawal, Srikant, 1994</marker>
<rawString>Agrawal R., Srikant R. (1994), Fast Algorithm for Mining Association Rules, Actes de The VLDB Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-E Califf</author>
</authors>
<title>Relational Learning Techniques for Natural Language Information Extraction.</title>
<date>1998</date>
<contexts>
<context position="2994" citStr="Califf, 1998" startWordPosition="425" endWordPosition="426">t les principales causes. L’Extracti0n d’Inf0rInati0n (Wilks, 1997) peut, a partir d’un ensemble de textes traitant d’un theme commun et de patrons d’extraction (ou templates), fournir des instanciations de ces patrons a partir des informations contenues dans les textes du corpus foumi. L’utilisation Isabelle Debourges, Sylvie Guilloré-Billot, Christel Vrain d’un outil d’Extraction d’Information nécessite que l’utilisateur soit sufﬁsamment familier du theme traité par le corpus pour étre capable de déﬁnir ce patron. On pourrait envisager que l’acquisition automatique de patrons (Riloff, 1996; Califf, 1998) puisse aider notre utilisateur. Mais ces outils demandent une validation des patrons qu’ils proposent par l’utilisateur. . . ce qui est difﬁcile si l’utilisateur ne connait pas le domaine . Ainsi, un utilisateur qui souhaite découvrir un nouveau domaine ne peut pas accéder aisément aux informations qu’il recherche sur celui-ci. Les aides proposées par la Recherche Documentaire et l’Extraction d’Information sont une premiere avancée, mais elles restent largement insufﬁsantes dans le cas ou la recherche porte sur un domaine ou le nombre des textes disponibles n’est pas restreint. Le probleme su</context>
</contexts>
<marker>Califf, 1998</marker>
<rawString>Califf M-E. (1998), Relational Learning Techniques for Natural Language Information Extraction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Debourges</author>
<author>S Guilloré</author>
<author>C Vrain</author>
</authors>
<title>Cartographic de Textes. Une nouvelle approche pour l’exploration sémantique des corpus homogénes de grande dimension, RR-2001-01 du Laboratoire d’Informatique Fondamentale d’Orléans.</title>
<date>2001</date>
<contexts>
<context position="7777" citStr="Debourges et al., 2001" startWordPosition="1154" endWordPosition="1157"> d’un theme represente par le mot cle. De plus, dans les cartes conceptuelles que nous construisons, les concepts constituent les noeuds tandis que les relations etiquettent les liens. 3 Prétraitements et Extraction de Concepts 3.1 Prétraitements Une phase de pretraitement du corpus permet de realiser des traitements simples utilises au cours des traitements plus lourds que sont l’extraction des concepts et l’emergence des relations. Le texte est decoupe en phrases, les mots vides et caracteres speciaux sont omis. Le texte est lemmatise et une categorie grammaticale est associee a chaque mot (Debourges et al., 2001). 3.2 Extraction des Concepts L’ algorithme de selection des concepts les plus pertinents par rapport a la requete (ensemble de mots cles) est base sur la volonte de selectionner les unites lexicales (ou polylexicales) qui apparaissent dans le contexte de la requete. Pour cela, les mots cles sont tout d’abord etendus en ajoutant les synonymes/hyponymes/hyperonymes aﬁn de selectionner les phrases traitant de la meme idee, meme si l’auteur a fait un effort pour ne pas repeter exactement le meme mot. Ensuite, on selectionne les phrases qui contiennent les mots etendus; l’ensemble des termes les p</context>
</contexts>
<marker>Debourges, Guilloré, Vrain, 2001</marker>
<rawString>Debourges I., Guilloré S., Vrain C. (2001), Cartographic de Textes. Une nouvelle approche pour l’exploration sémantique des corpus homogénes de grande dimension, RR-2001-01 du Laboratoire d’Informatique Fondamentale d’Orléans.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Fondin</author>
</authors>
<title>Les modéles de recherche documentaire, Le traitement numérique des documents Editions Hermes.</title>
<date>1998</date>
<contexts>
<context position="2004" citStr="Fondin, 1998" startWordPosition="283" endWordPosition="284">ng on the user’s request and its evolution, and semantic/lexical relations (the links). Machine Learning techniques are combined with Natural Language Processing methodologies to build the maps. Keywords: Text Mapping, Information Retrieval, Information Extraction, Machine Learning. 1 Introduction Les utilisateurs ont aujourd’hui besoin d’outils qui leur permettent de retrouver ce qu’ils cherchent au sein de grandes sources d’informations. La Recherche Documentaire et l’Extraction d’Information sont les deux grands types d’aide Inis a leur disposition. La Recherche Documentaire (Salton, 1995; Fondin, 1998) nécessite la saisie de mots clés par l’utilisateur pour produire une sélection de textes jugés pertinents vis a vis de cette requéte. Mais l’utilisateur n’a que tres rarement la possibilité de parcourir lui-méme l’ensemble des textes sélectionnés par un outil de recherche documentaire aussi performant soit-il. Le manque de temps et/ou le volume des textes a exploiter en sont les principales causes. L’Extracti0n d’Inf0rInati0n (Wilks, 1997) peut, a partir d’un ensemble de textes traitant d’un theme commun et de patrons d’extraction (ou templates), fournir des instanciations de ces patrons a pa</context>
</contexts>
<marker>Fondin, 1998</marker>
<rawString>Fondin H. (1998), Les modéles de recherche documentaire, Le traitement numérique des documents Editions Hermes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Novak</author>
</authors>
<title>How do we learn our lesson? 2 Taking students through the process,</title>
<date>1993</date>
<journal>The Science Teacher</journal>
<volume>60</volume>
<issue>3</issue>
<marker>Novak, 1993</marker>
<rawString>Novak J. D. (1993), How do we learn our lesson? 2 Taking students through the process, The Science Teacher 60(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Quillian</author>
</authors>
<date>1968</date>
<booktitle>Semantic Memory, dans Semantic Information Processing,</booktitle>
<publisher>M.I.T. Press.</publisher>
<contexts>
<context position="6948" citStr="Quillian, 1968" startWordPosition="1029" endWordPosition="1031">nd: 1. l’extraction des concepts pertinents au sein du corpus, par rapport a la requéte courante et aux requétes antérieures. 1il est préférable que le corpus soit homogéne du point de vue du genre des textes et de la langue utilisée Cartographie de Textes 2. l’emergence des relations semantiques et lexicales presentes au sein du corpus, entre les mots cles de la reguete et les concepts extraits. Travaux apparentes Le formalisme graphique que nous utilisons pour les cartes conceptuelles peut etre apparente a celui des graphes conceptuels (Sowa, 1984), eux meme derives des reseaux semantiques (Quillian, 1968). La difference majeure reside dans le fait que nous ne representons pas les informations presentes au niveau d’une phrase, mais plutet une generalisation des informations disponibles dans le corpus, autour d’un theme represente par le mot cle. De plus, dans les cartes conceptuelles que nous construisons, les concepts constituent les noeuds tandis que les relations etiquettent les liens. 3 Prétraitements et Extraction de Concepts 3.1 Prétraitements Une phase de pretraitement du corpus permet de realiser des traitements simples utilises au cours des traitements plus lourds que sont l’extraction</context>
</contexts>
<marker>Quillian, 1968</marker>
<rawString>Quillian M.R. (1968), Semantic Memory, dans Semantic Information Processing, M.I.T. Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
</authors>
<title>Automatically Generating Extraction Patterns from Untagged Text,</title>
<date>1996</date>
<booktitle>Actes de Thirteenth National Conference on Artificial Intelligence, AAAI-96,</booktitle>
<pages>1044--1049</pages>
<contexts>
<context position="2979" citStr="Riloff, 1996" startWordPosition="423" endWordPosition="424">ploiter en sont les principales causes. L’Extracti0n d’Inf0rInati0n (Wilks, 1997) peut, a partir d’un ensemble de textes traitant d’un theme commun et de patrons d’extraction (ou templates), fournir des instanciations de ces patrons a partir des informations contenues dans les textes du corpus foumi. L’utilisation Isabelle Debourges, Sylvie Guilloré-Billot, Christel Vrain d’un outil d’Extraction d’Information nécessite que l’utilisateur soit sufﬁsamment familier du theme traité par le corpus pour étre capable de déﬁnir ce patron. On pourrait envisager que l’acquisition automatique de patrons (Riloff, 1996; Califf, 1998) puisse aider notre utilisateur. Mais ces outils demandent une validation des patrons qu’ils proposent par l’utilisateur. . . ce qui est difﬁcile si l’utilisateur ne connait pas le domaine . Ainsi, un utilisateur qui souhaite découvrir un nouveau domaine ne peut pas accéder aisément aux informations qu’il recherche sur celui-ci. Les aides proposées par la Recherche Documentaire et l’Extraction d’Information sont une premiere avancée, mais elles restent largement insufﬁsantes dans le cas ou la recherche porte sur un domaine ou le nombre des textes disponibles n’est pas restreint.</context>
</contexts>
<marker>Riloff, 1996</marker>
<rawString>Riloff E. (1996), Automatically Generating Extraction Patterns from Untagged Text, Actes de Thirteenth National Conference on Artificial Intelligence, AAAI-96, 1044-1049.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>J McGill</author>
</authors>
<title>Introduction to Modern Information Retrieval</title>
<date>1995</date>
<publisher>Mc Graw Hill.</publisher>
<marker>Salton, McGill, 1995</marker>
<rawString>Salton G., McGill J. (1995), Introduction to Modern Information Retrieval Mc Graw Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Sowa</author>
</authors>
<title>Conceptual Structures. Information Processing in Mind and Machine,</title>
<date>1984</date>
<location>Addison Welsey.</location>
<contexts>
<context position="6889" citStr="Sowa, 1984" startWordPosition="1021" endWordPosition="1022">es étapes suivantes. La construction d’une carte comprend: 1. l’extraction des concepts pertinents au sein du corpus, par rapport a la requéte courante et aux requétes antérieures. 1il est préférable que le corpus soit homogéne du point de vue du genre des textes et de la langue utilisée Cartographie de Textes 2. l’emergence des relations semantiques et lexicales presentes au sein du corpus, entre les mots cles de la reguete et les concepts extraits. Travaux apparentes Le formalisme graphique que nous utilisons pour les cartes conceptuelles peut etre apparente a celui des graphes conceptuels (Sowa, 1984), eux meme derives des reseaux semantiques (Quillian, 1968). La difference majeure reside dans le fait que nous ne representons pas les informations presentes au niveau d’une phrase, mais plutet une generalisation des informations disponibles dans le corpus, autour d’un theme represente par le mot cle. De plus, dans les cartes conceptuelles que nous construisons, les concepts constituent les noeuds tandis que les relations etiquettent les liens. 3 Prétraitements et Extraction de Concepts 3.1 Prétraitements Une phase de pretraitement du corpus permet de realiser des traitements simples utilises</context>
</contexts>
<marker>Sowa, 1984</marker>
<rawString>Sowa J .F. (1984), Conceptual Structures. Information Processing in Mind and Machine, Addison Welsey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Srikant</author>
<author>R Agrawal</author>
</authors>
<title>Fast Discovery of Association Rules, Actes de Advances in knowledge discovery and data mining,</title>
<date>1996</date>
<pages>307--328</pages>
<publisher>AAAI Press,</publisher>
<marker>Srikant, Agrawal, 1996</marker>
<rawString>Srikant R., Agrawal R. (1996), Fast Discovery of Association Rules, Actes de Advances in knowledge discovery and data mining, AAAI Press, 307-328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y VV1lks</author>
</authors>
<title>Information Extraction as a Core Language Technology, Information Extraction</title>
<date>1997</date>
<pages>1299</pages>
<publisher>Springer,</publisher>
<marker>VV1lks, 1997</marker>
<rawString>VV1lks Y. (1997), Information Extraction as a Core Language Technology, Information Extraction 1997, LNCS 1299, Springer, 1-9.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>