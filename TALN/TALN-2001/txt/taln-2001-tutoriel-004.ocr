TALN 2001, Tours, 2-5 juillet 2001

Formal Languages for Linguists: Classical and Nonclassical
Models

Extended version of the chapter 8: C. Martin-Vide, Formal grammars and languages, in R.
Mitkov, ed., Oxford Handbook of Computational Linguistics. Oxford University Press, Oxford,
2001.

Carlos Martin-Vide
Research Group on Mathematical Linguistics
Rovira i Virgili University
Pl. Imperial Tarraco, 1
43005 Tarragona, Spain
E-mail: cmv@correu.urv.es, cmv@nil.fut.es
Web: http://www.urv.es/centres/Grups/grlmc/grlmc.html

Abstract

The basics of classical formal language theory are introduced, as well as a wide coverage is
given of some new nonstandard devices motivated in molecular biology, which are challenging
traditional conceptions, are making the theory revived and could have some linguistic relevance.
Only deﬁnitions and a few results are presented, without including any proof. The chapter
can be proﬁtably read without any special previous mathematical background. A long list of
references completes the chapter, which intends to give a ﬂavour of the ﬁeld and to encourage
young researchers to go deeper into it.

1 Languages

1.1 Basic Notions
An alphabet or vocabulary V is a ﬁnite set of letters. By concatenating the letters from V again
and again, one obtains V*, an inﬁnite set of strings or words. The empty string is denoted by

A and contains no letter: it is the unit element of V* under the concatenation operation. The
concatenation of strings is an associative and noncommutative operation, which closes V*, i.e.:

for every 111,12 6 V* : am 6 V*.

The length of a string, denoted by |w|, is the number of letters the string consists of. It is clear
that:

° |/\|=0,

Carlos Martin-Vide

o |wv| = |w| + 

w is a substring or subword of 12 if and only if there exist ul, U2 such that 12 = ’Ll.1’LU’U.2. Special
cases of a substring include:

o if 112 7é A and w 75 12, then 112 is a proper substring of 22,
o if u1 = A, then 112 is a preﬁx or a head,

0 ifug = A, then 11) is a sufﬁx or a tail.
The i-times iterated concatenation of w is practically showed in the following:
Example 1.1 Ifw = ab, then U13 = (ab)3 = ababab. (wo = A.)

1

If U) = 0.102 . . . can, then its mirror image 11)‘ = a,,a,,_1 . . . a1. It is clear that:

(w‘1)’1 = w, (w‘1)i = (w”)‘1 (for everyi Z 0).

Any subset L Q V* (including both (I) and {A}) is a language. One denotes VJ’ = V* — 

Regarding cardinality (generally, the number of elements a set contains):

0 V* is denumerably inﬁnite, i.e. |V*| = N0 (the smallest transﬁnite number),
0 73(V*) is nondenumerably inﬁnite, i.e. |73(V*)| = 2N0 (also called N1).

We do not go here deeper into the details of inﬁnite sets, which would require an extensive
presentation.

Examples of languages include:

Example 1.2 L = {a,b,A}, L = {ai,bi : 2' Z O}, L ={ww‘1:w E V*}, L = {a"2 : n 2 1},
L = {w : w E {a, b}+ and |w|a = |w|b} (|w|w denotes the number ofoccurrences ofx in w).

1.2 Chomsky Grammars. The Chomsky Hierarchy

A (formal) grammar is a construct G = (N, T, S, P), where N, T are alphabets, with N ﬂ T =
(D, S E N and P is a ﬁnite set of pairs (11), U) such that w, 1) E (N U T)* and 11) contains at
least one letter from N. ((w, 12) uses to be written w —> 22.) N is the nonterminal alphabet,
T the terminal alphabet, S the initial letter or axiom, and P the set of rewriting rules or
productions.

Given G = (N, T, S, P) and w, 12 E (N U T)*, an immediate or direct derivation (in 1 step)
11) :>G 1) holds if and only if:

Formal Languages for Linguists: Classical and Nonclassical Models

(i) there exist ul, U2 6 (N U T)* such that w = ’LL1CY’LL2 and 12 = ulﬂug, and

(ii) there exists at —> ,6 E P.

Given G = (N, T, S, P) and 111,12 6 (N U T)*, a derivation w =>’f; 22 holds if and only if
either 11) = 12 or there exists z E (N U T)* such that w =>’f; z and z =>G 12.

=>’f; denotes the reﬂexive transitive closure and =>g the transitive closure, respectively, of
:>(; .

The language generated by a grammar is deﬁned by:

L(G) = {w : S =>’f; wandw E T*}.

Example 1.3 Let G = (N, T, S’, P) be a grammar such that.‘

N={S,A,B},

T={a,b},

P = {S —> aB,S —> bA,A —> a,A —> aS,A —> bAA,B —> b,B —>
bS',B—>aBB}.

The language generated by G is the following.‘

L(G) = {w : w E {a,b}+and|w|a = |w|b}.

Example 1.4 Let G = (N, T, S’, P) be a grammar such that.‘

N = {S,A,B},

T = {a, b, C},

P = {S —> abc,S —> aAbc,Ab —> bA,Ac —> Bbcc,bB —> Bb,aB —>
aaA, aB —> aa}.
The language generated by G is the following.‘

L(G) = {a"b"c" : n 2 1}.

Grammars can be classiﬁed according to several criteria. The most spread one is the form of
their productions. According to it, a grammar is said to be of type:

Carlos Martin-Vide

o 0 (phrase-structure grammar, RE) if and only if there are no restrictions on the form of
the productions: everything at both the left-hand side and the right-hand side of the rules
is allowed.

0 1 (context-sensitive grammar, CS) if and only if every production is of the form:
ul/lug —> ’Ll.1'LU'LL2,

with u1,u2,w E (N U T)*, A E N and w 75 A (except possibly for the rule 3 —> A, in
which case S does not occur on any right-hand side of a rule).

0 2 (context-free grammar, CF) if and only if every production is of the form:
A —> w,

MmA€NwmﬂNUﬂﬁ

0 3 (regular or ﬁnite-state grammar, REG) if and only if every production is of any of
the forms:

A—>wB,
A—>w,

mmABeMweTt

A language is said to be of type 71 (i = 0, 1, 2, 3) if it is generated by a type 71 grammar. The
family of type 71 languages is denoted by Li.

One of the most important and early results in formal language theory is the so-called Chomsky
hierarchy of languages: £3 C £2 C £1 C £0.

Note that every grammar generates a unique language. However, one language can be generated
by several different grammars.

Two grammars are said to be:

0 (weakly) equivalent if they generate the same string language,

0 strongly equivalent if they generate both the saIne string language and the same tree
language.

(We shall see later that a context-free grammar generates not only a set of strings, but a set of
trees too: each one of the trees is associated with one string and pictures the way how this latter
is derived in the grammar.)

Formal Languages for Linguists: Classical and Nonclassical Models

1.3 Operations on Languages

Usual set-theoretic operations on languages include:

o Union: L1UL2 = {w : w 6 L1 orw 6 L2}.

o Intersection: L1 ﬂ L2 = {w : w 6 L1 and w 6 L2}.

o Difference: L1 — L2 = {w : w 6 L1 andw gé L2}.

0 Complement of L Q V* with respect to V* : L = V* — L.
Speciﬁc language-theoretic operations on languages include:

o Concatenation: L1L2 = {w1w2 : 1111 6 L1 and ‘(.02 6 L2}.

o Iteration:
L0 = {A},
L1 = L,
L2 = LL,

L* = U Li (closure of the iteration: Kleene star),
Z20

L+ = U Li (positive closure of the iteration: Kleene plus).
Z21

Note that L+ equals L* if A E L, and equals L* — {A} if A 9;‘ L.

o Mirror image: L‘1 = {w : w"1 E L}.
Note that (L‘1)‘1 = L and (L‘1)i = (Li)‘1, for everyi Z 0.

0 Right quotient of L1 over L2: L1 / L2 = {w : there exists 1) 6 L2 such that U11) 6 L1}.
0 Right derivative ofL over 12: 85L = L/{U} = {w : U11) 6 L}.

0 Head ofL Q V*: HE/lD(L) = {w E V* : there exists 1} E V* such that U11) 6 L}.
Note that for every L : L Q H EAD(L).

0 Left quotient of L1 over L2: L2\L1 = {w : there exists 1) 6 L2 such that my 6 L1}.
0 Left derivative ofL over 1): 8f,L = {v}\L = {w : my 6 L}.

0 Tail ofL Q V*: TAIL(L) = {w E V* : there exists 1) E V* such that mu 6 L}.
Note that for every L : L Q TAIL(L).

o Morphism: Given two alphabets V1, 16, a mapping h : V1* —> IQ is a morphism if and
only if:

(i) for every 11) E V*, there exists 1) 6 lg‘ such that U = h(w) and U is unique,
(ii) for every w,u 6 V1* : h(wu) = h(w)h(u).

Carlos Martin-Vide

A morphism is called )\-free if, for every 11) E Vf‘, if 01 7E A then h(w) 7E A.
o Morphic image: h(L) = «[0 E V; : 0 = h(w), for some 02 E L}.

0 A morphism is called an isomorphism if, for every 01, u 6 V1*, if h(w) = h(u) then
01 = u.

Example 1.5 An isomorphism between V1 = [0,1,2,. . .,9} and I6 = [0,1} is the
binary coded decimal representation of the integers.‘

/1(0) = 0000, /1(1) = 0001, . . . , /1(9) = 1001.

Union, concatenation and Kleene star are called regular operations.

Theorem 1.6 Each of the language families £,~, for every 2' E [0, 1, 2, 3}, is closed under
regular operations.

A systematic study of the common properties of language families has led to the theory of
abstract families of languages (AFL’s). An abstract family of languages is a class of those
languages that satisfy certain speciﬁed closure axioms. If one ﬁxes an AFL, one can prove
general theorems about all languages in the family.

A few simple closure properties are depicted next:

REG CF CS RE

union + + + +

intersection + — + +

complement + — + —

concatenation + + + +

Kleene star + + + +

intersection with regular languages + + + +
morphisms + + — +

left/right quotient + — — +

left/right quotient with regular languages + + — +
left/right derivative + + + +

Inirror image + + + +

The table must be interpreted in the following way. Using the ﬁrst + to the left as an example,
it means that the union of two regular languages is always a regular language. And so on.

2 Grammars

2.1 Context-Free Grammars

Theorem 2.1 For every CF grammar G, one can ﬁnd an equivalent CF grammar G’ such that
the right-hand sides of its productions are all diﬁferent from A except when A E L(G). In this

Formal Languages for Linguists: Classical and Nonclassical Models

latter case, S —> A is the only rule with the right-hand side A, but then S does not occur on
any right-hand side of the rules. (This is also true for REG grammars.)

A grammar is said to be A-free if none of its rules has the right-hand side A.

An CF grammar is said to be in Chomsky normal form (CNF) if each of its rules has either of
the two following forms:

0 X—>a,X€N,aET,
o X—>YZ,X,Y,ZEN.

Theorem 2.2 For every A-free CF grammar, one can eﬁectively ( algorithmically ) ﬁnd an equiv-
alent grammar in CNF

Theorem 2.3 For every CF grammar G, it is decidable whether or not an arbitrary strings w
belongs to L(G).

Corollary 2.4 Given an CF grammar G and a ﬁnite language L, both L Q L(G) and L F)
L(G) = (Z) are solvable.

2.2 Derivation Trees

A very common and practical representation of the derivation process in a grammar (particu-
larly, in an CF grammar) is a tree.

A derivation tree is deﬁned as T = (V, D), where V is a set of nodes or vertices and D is a
dominance relation, which is a binary relation in V that satisﬁes:

(i) D is a weak order:

(i.a) reﬂexive: for every a E V : aDa,
(i.b) antisymmetric: for every a, b E V, if aDb and bDa, then a = b,
(i.c) transitive: for every a, b, c E V, if aDb and bDc, then aDc.

(ii) root condition: there exists 7" E V such that for every I) E V : rDb,

(iii) nonbranching condition: for every a, a’, b E V, if aDb and a’ Db, then aDa’ or a’Da.

Special cases of the dominance relation include, for every a, b E V:

o a strictly dominates b (aSDb) if and only if aDb and a 7E b; so SD is a strict order in V:

(i) irreﬂexive: it is not the case that aSDa,

Carlos Martin-Vide

(ii) asymmetric: if aS Db, then it is not the case that bSDa,
(iii) transitive: if aSDb and bSDc, then aSDc.

o a immediately dominates b (aI Db) if and only if aSDb and there does not exist any 0
such that aSDc and cSDb.

The degree of a node deg(b) = |{a E V : bIDa}  Consequences of this deﬁnition are:

c b is a terminal node or a leaf if and only if deg(b) = 0,
o b is a unary node if and only if deg(b) = 1,
o b is a branching node if and only if deg(b) > 1,

0 T is an n-ary derivation tree if and only if all its nonterminal nodes are of degree n.

Two nodes a, b are independent of each other: a] N Db if and only if neither aDb nor bDa.

Some family relations among nodes include:

o a is a mother node of b: aM b if and only if a] Db,

o a is a sister node of b: aS b if and only if there exists d such that dMa and dM b.

The mother relation has the following features:

(i) there does not exist any a E V such that aMr,

(ii) if b 7é 7", then it has just one mother node.

Given T = (V, D), for every b E V, a derivation subtree or a constituent is Tb = (Vb, Db),
where Vb = {c E V : bDc} and :cDby if and only ifx E Vb and y E Vb and :vDy.
Given T = (V, D), for every a, b E V: a c-commands b (aCCb) if and only if:
(1) aINDb,
(ii) there exists a branching node that strictly dominates a,

(iii) every branching node that strictly dominates at dominates b.

a asymmetrically c-commands b if and only if a0 0 b and it is not the case that bC Ca.

Given two derivation trees T = (V, D), T’ = (V’, D’) and h : V —> V’ :

o h preserves D if and only if for every a, b E V : aDb —> h(a)D’h(b).

Formal Languages for Linguists: Classical and Nonclassical Models

0 h is an isomorphism of T in T’ (T x T’) if and only if h is a bijection and preserves D.

(Note that a mapping f : A —> B is a bijection if and only if:

(i) f is one-to-one or injective: for every :v,y E A, if :3 7E y then f 75 f or,
equivalently, if f = f then :3 = y,

(ii) f is onto or exhaustive: for every 2 E B : there exists :3 E A such that f = z.)

Any two isomorphic derivation trees share all their properties:

0 aSDb if and only if h(a)SD’h(b),
o aIDb if and only if h(a)ID’h(b),
o deg(a) = deg(h(a)),
o aCCb if and only if h(a)CCh(b),
o a is the root of T if and only if h(a) is the root of T’,
o dept/1(a) = dept/1(h(a)),
(dept/1(a) = |{b E V : bDa}| — 1.)
o heig/1t(T) = heig/1t(T’).
(heig/1t(T) = ma:v{depth(a) : a E V}.]

Once one has an T = (V, D), one may enrich its deﬁnition to get a labelled derivation tree
T = (V, D, L), where (V, D) is a derivation tree and L is a mapping from V to a speciﬁed set
of labels.

GivenT = V,D,L and T’ = V’,D’,L’ ,one sa sT x T’ ifand only if:
Y

(i) h : V —> V’ is a bijection,
(ii) h preserves D,

(iii) for every a, b E V : L(a) = L(b) if and only if L’(h(a)) = L’(h(b)).

A terminally ordered derivation tree is T = (V, D, <), where (V, D) is a derivation tree and
< is a strict total (or linear) order on the terminal nodes of V, i.e. a relation that is:
(i) irreﬂexive: for every a terminal: it is not the case that a < a,
(ii) asymmetric: if a < b, then it is not the case that b < a,
(iii) transitive: if a < b and b < c, then a < 0,

(iv) connected: either a < b or b < a.

Carlos Martin-Vide

Given T = (V, D, <), for every b, c, d, e E V : b <’ c (b precedes c) if and only if:

if bDd, d is terminal, cDe and e is terminal, then d < e.

The following exclusivity condition completely orders a tree. Given T = (V, D, <), for every
b, d E V, if b] N Dd, then either b <’ d or d <’ b). Consequently, every two nodes of the tree
must hold one, and only one, of the dominance and precedence relations.

2.3 More about Context-Free Languages

An CF grammar is called redundant if it contains useless nonterminal letters. A nonterminal
letter is useless if:
(i) either no terminal string is derivable from it: inactive or dead letter,

(ii) or it does not occur in any string derivable from S : unreachable letter.

Theorem 2.5 For any CF grammar G = (N, T, S, P):

o A E N is inactive if and only if the language generated by G A = (N, T, A, P) is empty.

0 A is unreachable if and only if the language generated by G)‘ = ((N —  U T, {A}, 5',
P1 U {X —> A : X E (N —  U T}) (P1 being the set of rules remaining after having
removed from P the productions that have A on their left-hand sides) is 

An CF grammar is nonredundant or reduced if each of its nonterminal letters is both active
and reachable.

Theorem 2.6 For every CF grammar, one can eﬁectively (algorithmically) ﬁnd an equivalent
nonredundant grammar.

Given an CF grammar G , w E L(G) is an ambiguous string if and only if 11) has at least two
derivation trees in G . G is said to be an ambiguous grammar if and only if there exists some
string in L(G) that is ambiguous. L is an inherently ambiguous context-free language if and
only if every CF grammar generating L is ambiguous.

An example of ambiguity is the following:

Example2.7 GivenG = ({S'},{a,+,>I<},S,{S—> S+S,S —> S>:<S,S —> a}),w = a>s<a+a
has two diﬁerent derivation trees in G .'

Formal Languages for Linguists: Classical and Nonclassical Models

S S
/I\ /I\
S * S S + S
I /R I
a S -I- S >|< a
I I I I
(1 C1 C1 (1

An example of inherent ambiguity is the following:
Example 2.8 Let L = {a’”b'”c" : m,n Z 1} U {a"‘b"c" : m,n Z 1}. Every CF grammar

generating it will produce two diﬁferent derivation trees for the strings of the form a"b"c" (which
belong to both components of the language).

The Bar-Hillel pumping lemma for CF languages allows one to prove that a language is not
CF just looking at the structure of the strings:

for every L 6 CF there existp, q E N such that for every 2 E L, if > p, then 2 =
uvwzty, where u,v,w,:t,y E T*, IUUJIEI 3 q,v:t 75 A, and uvzwxzy E L, for everyi Z 0.

Since not all languages satisfy the pumping lemma above, the following corollary is obvious.
Corollary 2.9 There are noncontext-free languages.
Examples of this include:

{a"b"c" : n 2 1},
{a"2 : n 2 1},

{a"b"‘c"d’" : m,n Z 1}.

2.4 Linear and Regular Languages

An CF grammar is called linear (LIN) if each production has either of the forms:

0 A—>w,A€N,wET*,

O A :)’Ll}1B’Ll)2,14,B E N, ’LU1,'LU2 E 

Further, it is called left-linear (LLIN) (respectively, right-linear (RLIN)) if U11 (respectively,
U12) is A in every rule of the second form.

Thus, the class of right-linear grammars exactly coincides with REG. Also:

Carlos Martin-Vide

Theorem 2.10 Every LLIN grammar generates an REG language.

And now, one can pose the following question: do all linear grammars generate languages in
£3? The answer is: no!, and a counterexample is next.

Example 2.11 Consider the languages.‘

L1 = {a"b"c'° : n 2 1,19 2 1},

L2 = {a'°b"c" : n 2 1,19 2 1}.

Both are generated by linear grammars. For instance, the ﬁrst one by.‘

G = ({S', A}, {a, b, c},S, P},P = {S —> Sc,S —> Ac,/1 —> ab,/1 —> a/lb}.
However, could one build a regular grammar generating any of them? Since.‘
L1 0 L2 = {a"b"c" : n 2 1} ¢ CF

and it is known that CF 0 REG = CF, one gets that neither L1 nor L2 can be REG.

Theorem 2.12 Every language in £3 can be generated by a grammar having the following two
types of productions.‘ X —> aY, X —> a, with X, Y E N, a E T.

An CF grammar G = (N, T, S, P) is said to be self-embedding if there exists an A E N such
thatA =>* XAY, for some X, Y E (N U T)+.

Theorem 2.13 If an CF grammar is reduced and not self-embedding, then L(G) 6 £3.

Thus, self-embedding is the very characteristic feature of C F languages which separates them
from smaller language classes. Since that feature (it is the case with relative sentences, for
instance) does appear in natural languages (being the source for its recursiveness leading to the
inﬁnite set of sentences which a natural language is), it is obvious that a natural language cannot
be smaller than an O F language. This discussion will continue later.

An CF grammar is said to be in Greibach normal form (GNF) if each rule is of the form:
A —>aX,A E N,a E T,X E N*.

Theorem 2.14 For every A-free CF grammar, one can ﬁnd an equivalent grammar in GNF

Formal Languages for Linguists: Classical and Nonclassical Models

Given a ﬁnite alphabet V, a regular expression is inductively deﬁned as follows:

(i) A is a regular expression,
(ii) for every a E V, a is a regular expression,
(iii) if R is a regular expression, then so is R*,

(iv) if Q, R are regular expressions, then so are QR and Q U R.

Every regular expression denotes an REG language. For example:

A denotes {A},

a denotes {a},

a U b denotes {a, b},

ab denotes {ab},

a* denotes {a}*,

(a U b)* denotes {a, b}*,

(a U b)a* denotes {a, b}a* = aa* U ba* = {aa*, ba*}.

The following question now arises: is every REG language describable by means of a regular
expression? The answer is simply yes!

Theorem 2.15 Every regular expression denotes a language in £3 and, conversely, every lan-
guage in L3 is denoted by a regular expression.

A short list of valid equations for all regular expressions P, Q, R includes:

PU(QUR)=(PUQ)UR,
P(QR) = (PQ)R,
PUQ=QUP,

P(QUR) =PQUPR,
(PUQ)R=PRUQR,
P*=AUPP*,
AP=P)\=P,

P*= (AUP)*.

Carlos Martin-Vide

The concept of a regular expression suggests the operation on languages called substitution.

Given a ﬁnite alphabet V, let Va denote an alphabet and 8(a) Q Va* a language for each a E V.
For each string 11) = 0.102 . . . an E V*, one deﬁnes the substitution:

s(w) = s(a1)s(a2) . . .s(a,,)

as the concatenation of the languages corresponding to the letters of w. This is extended to any
L Q V* by:

s(L) = {'1} :1) E s(w), for somew E L}.

The family £3 is closed under substitution, i.e. the set of regular expressions is closed under
substitution of a regular expression for each of its letters. Substitution can be regarded as the
generalization of the notion of morphism.

As for CF languages, for both families LIN and REG there are necessary conditions in the form
of pumping lemmata.

Pumping lemma for linear languages:

for every L E LIN, there exist p, q E N such that for every 2 E L, if > p then z =
uvwxy, where u,v,w,:v,y E T*, |uvxy| 3 q, vac 7é A, and uviwxiy E L, for everyi 2 0.

Pumping lemma for regular languages:

for every L E REG, there exist p, q E N such that for every
z E L, if  > pthen z = uvw, where u,v,w E T*, |uv| 3 q,v 75 A, and uviw E L, for
everyi Z 0.

2.5 Semilinear, Context-Sensitive and
Mildly Context-Sensitive Languages

Whether or not natural languages are context-free sets of sentences was a much discussed issue
in the eighties. To enter the discussion’s core, cfr. the following papers: Gazdar (1981), Bres-
nan, Kaplan, Peters and Zaenen (1982), Pullum and Gazdar (1982), Culy (1985), and Shieber
(1985) (all of them were collected in Savitch, Bach, Marsh and Safran-Naveh 1987).

Today, there is a relative agreement that natural languages are not context-free. However, how
large they are continues to be a not so simple matter. There are two main noncompatible options.
A natural language:

(i) either forms a class of sentences that includes the context-free family but is larger than it
(so still comfortably placed within the Chomsky hierarchy),

Formal Languages for Linguists: Classical and Nonclassical Models

(ii) or occupies a position eccentric with respect to that hierarchy, in such a way that it does
not contain any whole family in the hierarchy but is spread along all of them.

Following the ﬁrst alternative gave origin to a new family of languages, which is of a clear
linguistic interest.

A family of mildly context-sensitive languages (MCS) is a family £ such that:

(i) each language in L is semilinear,

(ii) for each language in £, the membership problem (whether or not a string belongs to the
language) is solvable in deterministic polynomial time,

(iii) L contains the following three nonCF languages:

0 L = {a"b"c" : n 2 0}: multiple agreements,
o L = {a"b"‘c"d"‘ : n, m 2 0}: crossed dependencies,

o L = {ww : w E {a, b}*}: duplications.

MCS is a linguistically-motivated family, as both it contains the above three languages, which
are more or less agreed to represent structures that exist in natural languages, and enjoys good
complexity conditions (i.e. fast processing), as stated by the deterministic polynomial time
requirement.

In order to see what a semilinear language is, let us assume V = {a1,a2, . . . , ak}. Being N the
set of integers, the Parikh mapping of a string is:

xi: ; V* —> Nk
\Il(/LU):(i/(‘Ui0«17i/(‘Ui0«27"'7i/(‘Uiak)7/(‘U E V*'
Given a language, its Parikh set is:
\II(L) =  :w E L}.

A linear set is a set M Q Nk such that:
7771
M = {U0 + Zvixi : :3, E N, forsomev0,v1, . . . ,1)", E Nk}.
i=1

A semilinear set is a ﬁnite union of linear sets. A semilinear language is an L such that \II(L)
is a semilinear set.

A phrase-structure grammar is called length-increasing if, for every production 11) —> 12 E P,
one has |w| 3 |v  This is clear for every CS grammar. Moreover:

Carlos Martin-Vide

Theorem 2.16 Every length-increasing grammar generates an CS language.

The length-increasing property is, therefore, equivalent to context-sensitivity with the sole ex-
ception of the rule S —> A, which is needed only to derive A.

A length-increasing grammar is said to be in Kuroda normal form (KNF) if each of its pro-
ductions is of any of the following forms:
0 A —> a,
0 A —> B,
0 A —> B C ,

0 AB —> C D,
for A, B, C, D nonterminals and a terminal.

Theorem 2.17 For every length-increasing grammar, one can ﬁnd an equivalent grammar in
KNF.

Corollary 2.18 Every A-free CS language can be generated by a grammar in KNF.

A )\-free CS grammar is said to be in Penttonen or one-sided normal form (PNF) if each of
its productions is of any of the following forms:
0 A —> a,
o A —> B,
o A —> B0,
c AB —> A0,
o AB —> BA.

An example of an CS grammar generating a nonCF language is the following:
Example 2.19 Let G = (IV, I S, P) be a grammar such that.‘

N : {S7Al7A27Bl7B27Cl7C2}:

T = {a, b, C},

P =  *) A1B1C1,* A1 ?) aA2B2,B2B1 ?) B2B2,B2C1 *) B2026,
*A2 *) aA1B1,B1B2 *) B1B1,B1C2 ?) B1C1C,A1 *) Cl,B1 *) 17,01 *)
0,142 *) Cl,B2 *)b,C2 *>C}.

Formal Languages for Linguists: Classical and Nonclassical Models

The generated language is.‘
L(G) = {a"b"c" : n 2 1} 9;‘ CF.

As is easily seen, every application of the rules marked with * sends a signal through the B ’s to
C1 or C2 on their right, which may be killed on its way or reach the C ’s, where it deposits a c.

3 Automata

3.1 Finite Automata

Grammars are generating devices which may simulate the productive (i.e. speaking) behaviour
of speakers/hearers. Automata are recognizing devices which may simulate the receptive (i.e.
hearing) behaviour of them. Each class of mechanisms serves to model one of the two aspects
of human linguistic capacity. As well, there are surprising, strong formal connections between
grammar theory and automata theory. Let us see.

A ﬁnite automaton (FA) is a construct:
A : (Q7T7M7q07F)7

with:

Q a ﬁnite nonempty set of states,

T a ﬁnite alphabet of input letters,

0 M a transition function: Q X T —> Q,

qo E Q the initial state,

F Q Q the set of ﬁnal (accepting) states.

A accepts or recognizes a string if it reads until the last letter of it and enters a ﬁnal state.

Example 3.1
A : (Q7T7M7q07F):

Q = {qo,q1,q2,q3},

T = {a,b},

F = {(10}:

JV-[(9070) = €12 : JV-[(9075) = €11,

Carlos Martin-Vide

M(q1,a)=q3 , M(q1,b)=qo,
M(q2,a) = 610 , JV-[(61275) = €13,
M(q3,a) =q1 , JV-[(61375) =92-

The transition table and the transition graph forA are, respectively.‘

M a b
610 C12 C11
C11 C13 C10
612 C10 C13
613 C11 C12

 

One can check that L(A) = {w E {a, b}* : |w|a is even, |w|b is even

If M is a one-valued function, the ﬁnite automaton is called deterministic (DFA). Otherwise, it
is called nondeterministic (NFA). In the ﬁrst case, M contains exactly one transition with the
saIne left-hand side. Notice that the deﬁnition of M does not require M to be a total function,
i.e. M may well be not deﬁned for some combinations of a state and a letter.

The symbols |- and I-* for transitions are, respectively, equivalent to the symbols => and =>*
for derivations in grammars.

The language accepted by a ﬁnite automaton is:

L(A) = {w E T* : qow I-*p,p E 
Take notice that A E L(A) if and only if qo ﬂ F 75 (2).

Theorem 3.2 For every NFA, one can ﬁnd an equivalent REG grammar.
Theorem 3.3 For every REG grammar, one can ﬁnd an equivalent NFA.

Corollary 3.4 £3 coincides with the family of languages accepted by NFA’s.

The following question arises now: is there some language in £3 that cannot be accepted by
any DFA? The answer is simply no! Consequently, one can always simulate the behaviour of
an NFA by means of an DFA (with more states).

A number of important consequences for the languages in £3 follow from the concept of an FA,
among others:

0 L3 is a Boolean algebra,

o it is decidable whether two REG grammars are equivalent, etc.

Formal Languages for Linguists: Classical and Nonclassical Models

3.2 Pushdown Automata

Let us introduce now a new element in the deﬁnition of an automaton: memory. Pushdown

automata result.
moving <— input tape
d1rect1on
read
control
device

read and write

storing directio

_ _ _ FILO: ﬁrst in, last out method
<—clear1ng d1rect1o

pushdown store

A pushdown automaton (PDA) is a construct A = (Z, Q, T, M, zo, qo,  with:

0 Z a ﬁnite alphabet of pushdown letters,

0 Q a ﬁnite set of internal states,

T a ﬁnite set of input letters,

M the transition function:

Z x Q X (TU#) —>73f,~,,(Z* x Q),

2'0 6 Z the initial letter,

qo E Q the initial state,

0 F g Q a set of ﬁnal or accepting states.

A conﬁguration of an PDA is a string zq, where z E Z * is the current contents of the pushdown
store and q E Q is the present state of the control device.

A nondeterministic pushdown automaton (NPDA) may reach a ﬁnite number of different
new conﬁgurations from one conﬁguration in one move:

M(Z7q7a) = {(/w17p1)7 (/w27p2)7 ' ' ' 7 (/wm7pm)}7 a E T: /wi E Z*9 6 Q71 S  S Tn’-

Carlos Martin-Vide

There may be A-moves too, which make it possible for the PDA to change its conﬁguration
without reading any input.

For a string to be accepted, the three following conditions must hold:

(i) the control device read the whole string,
(ii) the PDA reached a ﬁnal state,

(iii) the pushdown store is empty.

Note that only the existence of at least one sequence of moves leading to an accepting conﬁgu-
ration is required, while others may lead to nonaccepting ones.

Example 3.5 To accept L = {a"b" : n 2 1}, the following PDA is adequate.‘

A = ({z07 a}: {(107 qlv C12}: {av b}: M7 Z07 (107 {q2})7
with.‘

M l a b #
(Z0,q0) (300,610) (D (D
(a,qo) (aa,qo) (A,q1) 0
(30791) ll) lb
(@791) ll) (A7611)
(2) (D

(D (D

(Z0; 612)
(av (12)

An PDA A = (Z, Q, T, M, zo, qo, F) is said to be deterministic (DPDA) if and only if for every
WQEZXQ

(i) either M (z, q, a) contains exactly one element, for every a E T, while M (z, q, A) = (2),

(ii) or M (z, q, A) contains exactly one element, while M (z, q, a) = (Z), for every a E T.

Theorem 3.6 The family of languages accepted by DPDA’s is strictly contained in the family
of languages accepted by NPDA’s.

To illustrate this, let us observe the following:

Example 3.7
L1 ={wcw_1:w 6 {a,b}*},

L2 ={ww_1:w 6 {a,b}*}.

While L1 belongs to both NPDA and DPDA, L2 belongs only to NPDA.

Formal Languages for Linguists: Classical and Nonclassical Models

The following results establish the relationship of N PDA’ .9 to C F languages.
Theorem 3.8 NPDA = CF.

Theorem 3.9 For every CF grammar, an algorithm exists to transform it into an equivalent
NPDA.

Theorem 3.10 For every PDA, an algorithm exists to transform it into an equivalent CF gram-
mar.

Turing machines are the most powerful recognizing devices, and are able to recognize any
RE language. They are the foundation of computation theory and involve a lot of complexities
which cannot be addressed here.

4 Regulated and Parallel Rewriting

4.1 A Sample of Regulated Rewriting

Next, a few important types of regulated grammars are presented, without being exhaustive at
all. In order to have a regulated (i.e. controlled) grammar, one more or less modiﬁes/restricts
the notion of a grammar, and as a consequence one usually gets either a different (often greater)
generative capacity or a simpler method of generation.

A matrix grammar is:

GM=(N,T,S,M),

where M is a ﬁnite set of ﬁnite nonempty sequences (matrices) of the form:
m : [7"1,7"2,...,7",,],n Z 1,
with:

7", : oz, f> ﬂi, 06;" E (NUT)*N(NUT)*,,3Z~ E (NUT)*.

A derivation in a matrix grammar is as follows:

for every 13,3; 6 (N U T)*,:t :>GM y if and only ifthere exist $0,131, . . . ,:t,, E (N U T)* and
there exist [7"1,7"2, . . . ,r,,] E M, 7", : or, —> ﬂi, 1 3 71 3 n, such that :t,~_1 = :t§_1oi,~:t;’_1 and
:3, = :t;_1,6,~:t§’_1, for some :t§_1,:t§’_1 E (NU T)*,0 3 2' 3 n — 1.

Carlos Martin-Vide

Example 4.1 The grammar G M with the following matrices.‘

m1: [3 —> ABC],
mg : [A —>aA,B —>bB,C —>cC],

m3:[A—>a,B—>b,C—>c],

yield L(GM) = {a"b"c" : TL 2 1}.

A programmed grammar is:
Gp = (N, T, S, P),

where P is a ﬁnite set of triples (T : oz —> ,6, a(T), <]5(7“)), T is a label, T : oz —> ,6 E (N U T)*
and 0(T), <;5(T) are two sets of labels of rules.

An immediate derivation in a programmed grammar is as follows:

for every(:r,T1), (y,T2) E (NU T)* X Lab(P) : (:E,7“1) =>GP (y,T2) if and only if :

(i) eitherx = 20105132 andy = 1101,6132 ($1,132 6 (NUT)*) and (T1 : oz —> ,6,0(T1), ¢(T1)) E
P) and T2 6 0(T1),

(ii) or :3 = y and T1 : 0; —> ,6 (for (T1 : oz —> ,8,0(T1), q5(T1)) E P) cannot be applied to :3
and T2 6 ¢(7"1).

The language generated by a programmed grammar is:

L(Gp) = {:3 : :3 E T*and there eXlSt7“1,7“2 E Lab(P)such that(S, T1) =>’f;P (£E,7“2)}.

Example 4.2 The grammar G p with the following productions.‘

(T1 : S’ —> AA, {T1}, {7“2,7“3}),
(T2114 —> 5', {T2}, {T1}),
(T3 : A —> a, {T3}, (0),

yield L(Gp) = {a2" : TL 2 1}.

A random context grammar is:

Formal Languages for Linguists: Classical and Nonclassical Models

GRC: (N7T7S7P)7

where Pis aﬁnite set ofrules ofthe form (oz —> ,6, Q, R), Withoz —> ,6 E (NUT)*, Q Q N,
R Q N.

An immediate derivation in a random context grammar is as follows:

for every :v,y E (N U T)* : :3 =>GRO y if and only ifx = :v’ozx” and
y = :v’,8:v”(:v’,x” E (N U T)*) and (oz —> ,6,Q,R) E P and for every u E Q : u E :v’:v” and
for everyv E R : 12 ¢ :v’x”.

Example 4.3 The grammar G RG with the following productions.‘

S —> AA, (2), {B, D}),
A —> B, (Z), {S, D}),

(
(
(B —> 3, 9), {A, D}),
(A —> D, 0, {s, 3}),
(

D —> a,(D, {S,A,B}),

yield L(GRG) = {aw : n 2 1}.

A grammar with regular control is:
GREG = (N, T, S, P, R),
where R is a regular language over P.

The language generated by an GREG consists of the strings resulting from a derivation:

S :>p1 wl :>I(?ﬂEG U12 :>GREG ' ' ' :>pn wn = 7-U E T*

GREG GREG

such that plpg . . .p,, E R.

Example 4.4 The grammar GREG consisting of:

N = {S,A,B},

T = {a, b, C},

P={p1:S'—>AB,p2:A—>aAb,p3:B—>Bc,p4:A—>ab,p5:B—>c},

R = {P1}{P2P3}*{P4P5},

generates.‘
L(GREG) = {a"b"c" : n 2 1}.
An additive valence grammar is:
GAV = (N, T, S, P, 1)),

where 12 : P —> Z(Z is the set of integers).

The language generated by an G AV is:

L(GAV) = {w : w E T* andS=>’(’;1AV U11 =>'('§AV U12 =>GAV 

v(p1) + v(p2) + . . . + 12(1)”) = 0}.

Example 4.5 The grammar G AV consisting of:

N = {S,A,B},

T = {a, b, 0},

Carlos Martin-Vide

P={p1:S'—>AB,p2:A—>aA,p3:B—>bBc,p4:A—>a,p5:B—>bc},

W191) = 1/(P4): “($75) = 0, W192) = 1, W193) = *1,

generates.‘

L(G,4V) = {a"b"c" : n 2 1}.

Notice that the rules p2 and p3 must be applied the same number of times.

A multiplicative valence grammar is:
GMV = (N7T7S7P7U)7

where 12 : P —> 62”’ (Q is the set of rational numbers).

The language generated by an G My is:

L(GMV) = {w : w E T* andS =>’gMV U11 :>’E§MV U12 :>GMV 

v(p1)v(p2) . . .v(pn) = 1}.

#71

GMV wn = w and

Formal Languages for Linguists: Classical and Nonclassical Models

Example 4.6 As G My, take G AV in the last example, with the following speciﬁc valence map-

ping.‘
1}(P1) = 1/(P4): ?}(P5) = 1,
v(p2) = 2,
v(p3) = 1 / 2.
It generates.‘

L(GMV) = {a"b"c" : n 2 1}.

An ordered grammar is:
G0 = (N, T, S, P, <),

where < is a strict partial order (i.e. irreﬂexive, asymmetric and transitive) over P.

An immediate derivation in an ordered grammar :3 =>Go y holds if and only if:

(i) there exist :31, :32 E (N U T)* such that IE = 131711132 and y = 13125132,

(ii) 11) —> z E P and there does not exist any substring w’ of IE such that there exists 2'’ such
thatw’ —> z’ E Pandw’ —> z’ > w —> 2.

Thus, the production that is utilized at each step is maximal in the ordered set of rules.

Example 4.7 The ordered grammar.‘

GO : ({S7A7B7A,7B,7A,,7M}7{a7b7C}7S7P7 <)7
where P = {(1)/l” —> M, (2)B —> be, (3)/l’ —> M, (4)B’ —> B, (5)/l —> M, (6)B —>

bB’c, (7)B’ —> M, (8)A —> A”, (9)A —> aA’, (10)B —> M, (11)A” —> a, (12)A’ —>
A, (13)S —> AB} and the order relation is satisﬁed by the following pairs.‘

(2) < (3), (2) < (5), (4) < (3), (5) < (1): 5) < (5), (8) < (7), (9) < (7): (11) < (10),
(12) < (10),

generates.‘

L(G0) = {a"b"c" : n 2 1}.

Carlos Martin-Vide

Generally speaking, there exist two main types of grammar derivations:

0 sequential: as is the case with grammars in the Chomsky hierarchy as well as all other
ones presented in this chapter so far;

0 parallel: which appear in several mechanisms, particularly in:

(i) Indian parallel grammars: at each step of the derivation, every occurrence of one
letter is rewritten (by using the same production),

(ii) Lindenmayer systems: at each step of the derivation, all occurrences of all letters
are rewritten (using different productions for different occurrences of one letter is
allowed: see below for details).

An Indian parallel grammar is a construct:
GIP = (N, T, S, P).
The immediate derivation runs as follows:
for every :3 E (N U T)+, for every y E (N U T)* : :3 =>G,P y if and only if:

(i) :3 = :31A:32A. . .:3,,A:3,,+1,A E N, :3, E ((NUT) — {A})*, 1 3 2' 3 73+ 1,
(ii) y = :31w:32w . . .:3,,w:3,,+1,

(iii) A —> w E P.

Example 4.8 The Indian parallel grammar.‘

GIP = ({3}, {a},S, {S —> SS,S —> a})

TL

yields L(G]p) = {a2 2n 2 0}.

A Russian parallel grammar is a construct:
GRP = (N7T7S7P)9
WhereP=P1UP2,P1ﬂP2=ll).

An immediate derivation in a Russian parallel grammar is:

:3 =>GRP y if and only if:

(i) either :3 = :31/1:32 and y = :31w:32 (:31, :32 E (N U T)*) and A —> w 6 P1,

(ii) or :3 = :31A:32A. . .:3,,A:3,,+1 and y = :31w:32w . . .:3,,w:3,,+1 (:3, E ((N U T) — {A})*,
1§z'§n+1)andA—>wEP2.

If P1 = (I), one gets an GIP. If P2 = (I), one gets an CF.

Formal Languages for Linguists: Classical and Nonclassical Models

4.2 Lindenmayer Systems

The motivation behind Lindenmayer systems (L systems for short) is biological. They are
intended to model the (parallel) growth of living beings.

An interactionless Lindemnayer system (OL) is a context-free pure (without a nonterminal
alphabet) grammar with parallel derivations:

G= (V,w,P),

where V is an alphabet, w E V* is an axiom and P is a ﬁnite set of rules of the form a —> 12,
with a E V and U E V* such that for each a E V there is at least one rule a —> 12 in P (P is said
to be complete).

Given 1111,1112 E V*, one writes U11 2 7112 if and only if wl = 0.102 . . .a,, and U12 = 121122 . . .12”,
for a, —> U, E P, 1 3 71 3 n. The generated language is:

L(G) ={IE €V*:w2* 

There are several important variants of L systems:

o if for each rule a —> 12 E P one has 12 7é A, then G is propagating (nonerasing);
o if for each a E V there is only one rule a —> 12 E P, then G is deterministic;

o if a subset T of V is distinguished and L(G) is deﬁned as the set {:3 E T* : w 2* :3},
then G is extended.

Regarding the generative power of L systems, many results are known, among others the fol-
lowing ones:

0 The family of deterministic 0L languages is incomparable with FIN, REG, LIN, CF
(FIN is the family of ﬁnite languages).
0 G F is a strict subset of the family of extended 0L languages.

0 All L languages are contained in G S .

A remarkable feature of a deterministic 0L system G is that it generates its language in a se-
quence L(G) = w = w0, w1, U12, . . . such that U10 2 U11 2 7112 2 . . . Thus, one can deﬁne
the growth function of G, denoted growthg : N —> , by:

g7“0wthG(n) = |w,,|,n Z O.

Carlos Martin-Vide

5 Nonstandard Generative Mechanisms

5.1 Contextual Grammars

A contextual grammar is a construct:
G = (V,B, (S1,C1), (S2,C2), . . . , (S,,,C,,)),
consisting of:

0 V an alphabet,

o B Q V* a ﬁnite set: the base or the set of axioms,

S, Q V* selectors,

C, Q V* X V* contexts,

(3,, Ci) productions, 1 3 71 3 n.

In a contextual grammar, one considers two main types of immediate derivation:

o external derivation:

foreVery:3,yEV*::3:>e,,yifandonlyify=u:3w,:3€S,,(u,v) EC,~,1 371373.

c internal derivation:

for every :3, y E V* : :3 =>,~,, y if and only if:3 = :31:32:33 and
y = :31u:32v:33,:32 6 Si, (u,v) 6 Ci, 1 3 2' 3 n.

The language generated by an internal contextual grammar is:
L,~,,(G) = {z E V*such that there existsw E Bsuch thatw  
Another way of deﬁning L,” (G) is to say that it is the smallest language L such that:

(i) B Q L,

(ii) for every :3 E L : if:3 = 31332333 and :32 6 3,, for some 71, 1 3 71 3 n, then :31u:32v:33 E L,
for every (u, 22) 6 Ci.

If one introduces several different restrictions, the following natural variants of derivation arise:

Formal Languages for Linguists: Classical and Nonclassical Models

o minimal local derivation:

for everym, y E V* : m =>m; y if and only if :

(1) 13 = 131132133,
(ii) y = IE1'LtIE2’UIE3 (IE2 E 3,, (u,v) 6 Ci, 1 3 2' 3 n), and

(iii) there do not exist m’1, mg, mg 6 V* such that m =  and mg 6 S, and  Z |m1|

and  Z |m3| and  < 
A context is adjoined to a selector provided this is minimal (i.e. the shortest one) in such
a position.

o maximal local derivation:

for everym, y E V* : m =>M; y if and only if :

(1) 13 = 131132133,

(ii) y = IE1'LtIE2’UIE3 (IE2 E 3,, (u,v) 6 Ci, 1 3 2' 3 n), and

(iii) there do not exist m’1, mg, mg 6 V* such that m =  and mg 6 S, and  3 |m1|

and  3 |m3| and  > 

A context is adjoined to a selector provided this is maximal (i.e. the longest one) in such
a position.

0 minimal global derivation (=>,,,_,,): In the deﬁnition of =>,,,l, one replaces mg 6 S,
with mg E 3,, for every j : 1 3 j 3 n. Note that the chosen selector has to be the shortest
one among all the selectors.

o maximal global derivation (=>M_,,): In the deﬁnition of =>M;, the same substitution
as above is introduced. Note that the chosen selector has to be the longest one among all
the selectors.

Given oz 6 {ml, mg, Ml, M g}, the language generated by the contextual grammar is:

LO,(G) = {z E V*such that there existw E Bsuch thatw =>:, 

If all the languages in S, belong to the same family F of languages in the Chomsky hierarchy,
G is said to be a contextual grammar with selection of type F.

Example 5.1 The contextual grammar.‘

G = ({a» 3}» {G503}, (ab+a» {(0, a)})» (ba+b» {(3, b)}))

generates.‘

L,~,,(G) = L,,,_,,(G) = {a"b'"a"b'” : n,m Z 1}.

Carlos Martin-Vide

Example 5.2 The language.‘
L = {a"cb"a'”cb'" : mm 2 1}
is generated by.‘
Gm = ({a» by 0}» {C0}, (0, {(0, b)}))-
Example 5.3 The language.‘

L: {a+}U{a"b" : n 2 1}

is generated by.‘
0M9 = ({a» 5}» {Ga ab}, (av {(A7 a)}), (“+52 {(0, b)}))-

Contextual grammars allow one to produce families of languages that are eccentric with respect
to the Chomsky hierarchy, as shall be seen below. This seems to be a very relevant feature from
a linguistic viewpoint, as natural languages could possibly occupy an eccentric position with
regard to that hierarchy.

5.2 Grammar Systems

Grammar systems are complex, modular generating architectures intended for either increasing
the generative power or decreasing the complexity of the generative strategy of the mechanism.
Several types can be distinguished.

A cooperating distributed grammar system (CDGS) is a construct:
F = (N,T, S, P1,P2, . . . ,P,,),
where:

oNﬂT=(D,
OSEN,

0 P1, P2, . . . ,P,, are ﬁnite sets of rewriting rules: the components of the system.

Several modes of derivation can be considered (being N the set of integers):

o in exactly k steps: =>;'° (k E N),

Formal Languages for Linguists: Classical and Nonclassical Models

in at most is steps: 

in at least is steps: 

arbitrary derivation: 

o terminal or maximal derivation: =>;,2,:

:3 =>;2, y if and only if :3 =>;,1 y and there does not exist any 2 E (N U T)* such that
y :>,,2. 2'.

Given amode of derivation f E D = {>:<, 15} U {g k, = k, 2 k : k 2 1}, the language generated
by an CDGS is:

Lf(I‘)={w€T*:S=>{,2,1w1=>j:i2w2:>...=>{,im wm=w,mZ1,1§z'j§n,1§j§m}.

Thus, ﬁve languages are associated with F.

Example 5.4 The CDGS:
F = 14,14’, B, BI}, {a, b, C}, 3, P1, P2)
consisting of:

P1={S—>S,S—>AB,A’—>A,B’—>B},

P2 = {A —> aA’b,B —> cB’,A —> ab,B —> 0},
generates:

:2(I‘) = {a"b"c",n Z 1},

Example 5.5 The CDGS.‘

F = ({S,A,A,}, {a,b},S',P1,P2,P3)

consisting of:

P1={S—>S,S—>AA,A’—>A},

P2={A—>aA',A—>a},

Carlos Martin-Vide

P3={A?)bA,,A*)b},

generates:
L:2(I‘) = LZ2(I‘) = {ww : w E {a, b}+}.

Let CD,,( f) denote the family of languages generated by CDGS’s of degree (the number of
components) at most 73 (n 2 1) working in the mode f. If the number of components is not
limited, one writes 00 instead of n. The union of all families CD00 (= k) (respectively, CD00 (2
k), CDoo(3 13)), k 2 1, is denoted by CDoo(=) (respectively, CDoo(2), CDoo(3)). If )\-rules
are accepted, one writes C D,’)( f ), CD30 (f), etc. Many results on CDGS’s’ generative capacity
are known:

0 CDoo(f)=CF,foreveryf€ {>s<,t,= 1,2 1}U{3 kzk 2 1}.

CF = CD10‘) C CD20‘) 2 CD10‘) 9 C¥Doo(.f)9f01-everyf 6 {= /6,2 is : is 2 2},
7" Z 3.

D,(= 3/3), for every 13,7", .9 2 1.

CD,(2 k) Q D,(2 k + 1), for every 13,7" 2 1.
o CDoo(2) Q CDoo(=).

All the six relations above are also true for CD’\ systems.

A parallel communicating grammar system (PCGS) is a construct:

F = (N7K7T7(P1731):(P27S2)7"'7(Pn7Sn))7

where:

N, T, K are pairwise disjoint alphabets,

K = {Q1, Q2, . . . , Q,,} are query letters (the subindex associates the letter to the corre-
sponding component),

Si€N,

P, are ﬁnite sets of productions over N U K U T, 1 3 71 3 73.

Given V1~ = (N U K U T), every n-uple (:31, :32, . . . ,:3,,), :3, 6 V5‘, is a conﬁguration of the
system.

Given two conﬁgurations (:31, :32, . . . ,:3,,), (y1, y2, . . . ,y,,), :3,~, y, E V13‘, 1 3 71 3 73, one deﬁnes
the immediate derivation (:31, :32, . . . ,:3,,) =>p (y1, y2, . . . ,y,,) if and only if either of the
following situations occur:

Formal Languages for Linguists: Classical and Nonclassical Models

(i) either = 0) and ((:vi =>pi  or E T* and xi = yi)), 1 3 71 3 n,

(ii) or there exists 71, 1 3 71 3 n such that  K > 0; in such a case, for every 71 one writes
in = Z1Qi1Z2Qi2 - - -ztQiiZt+1at Z 1, 2;‘ E V13‘,  = 0, 1 SJ St-1' 1; if  = 0,
1 3 j 3 t, then yi = z1:vi1z2:vi2 . . . zi:vitzi+1 [and yi]. = Si], 1 3 j 3 t]; if, for some j,
1 3 j 3 t, |:vi]. |K 75 0, then yi = xi; for every 71, 1 3 71 3 n, for which yi is not speciﬁed
above, one has yi = xi.

(i) is a rewriting step, (ii) is a communication step: the latter has a priority over the former (i.e.
if both are possible at a certain stage of the derivation process, communication must be applied
before).

The blocking of an PCGS may happen in either of the following cases:
0 when one component mi in (:31, ..., xii) is not terminal but cannot be rewritten according
to Pi, or

0 when a circular query occurs: i1 introduces Qi2 , Pi, introduces Qi3, . . . , Pi k_1 introduces

Qik , and i k introduces Qil (communication has priority but it cannot take place, because
strings to be communicated must contain no query letters at all).

The language generated by an PCGS is:

L(I‘)={:E€T*: (S1,S2,...,Sii)=>* (:E,oz2,...,ozii),0zi€V1i‘,23i3n}.

Thus, the language of the system is the language of the master component, which is the ﬁrst
component of the system: S1.

An PCGS is said to be centralized if and only ifPi Q (NUT)* >< (NUT)*, 2 3 z’ 3 n (i.e. only
the master is allowed to introduce query letters). Otherwise, it is said to be noncentralized.

An PCGS is called returning if and only if, after communication, each component that has
communicated goes back to its axiom and starts again. Otherwise, it is called nonreturning.
An PCGS P will produce two languages, Li (F) and Liii (F), according to the returning or non-
returning mode of working, respectively.

By default, one understands that an PCGS works in a noncentralized, returning mode. Some
conventional notations include:

PCiiX : family of languages generated by noncentralized, returning PCGS’s with at most
n components of type X, X E {REG, LIN, CF, CS, RE},

CPCiiX : PCiiX + centralized mode,

N PCiiX : PCiiX + nonreturning mode,

N CPCiiX : CPCiiX+ nonreturning mode,

Carlos Martin-Vide

PCOOX = URN PCHX (analogously for CPCOOX, NPCOOX, NCPCOOX).

Example 5.6 The PCGS:
F = ({S17 S27 S3}7 K7 {a7 b}7 (P17 S1)7 (P27 S2)7 (P37 
consisting of:

P1 = {S1 ?> 0731,31 *) U73Q2,S2 *) b2Q3,S3 ?> C},
P2 = {S2 *> 1732},
P3 = {S3 *> CS3},

generates.‘

L,(I‘) = Lm(I‘) = {a"b"c" : n 2 1}.

Example 5.7 The PCGS:

F : ({S17S2}7K7 {a’7b}7 (P17S1)7 (132732))
consisting of:

P1 = {$1 —> 51731 —> Q2622},

P2 = {S2 :) 0732,32 *) bS2,S2 *) 07,32 *) b},
generates.‘

LT(I‘) = Lm(I‘) = {ww : w E {a,b}+}.

Let H = {P0, CPO, NPC, NCPC The following results about PCGS’s’ generative power
are known:

0 YnCS’\ = RE, for every n, for every Y E H, where CS’\ indicates that productions of
arbitrary type are utilized.

0 YHREG — LIN 75 (Z), YHLIN — CF 75 (Z) (n 2 2), and YHREG — CF 75 (Z) (n 2 3), for
every Y E H.

o YHREG — CF 75 (D, n 2 2, for every Y E {NPC, NCPC).

Formal Languages for Linguists: Classical and Nonclassical Models

0 LIN — (CPCOOREG U NCPCOOREG) 75 (D.

o CPC2REG C CF, PC2REG Q CF.

0 CPCOOREG contains only semilinear languages.
0 CPC2C F contains nonsemilinear languages.

0 If L Q V*, L E CPCHREG, then there exists a constant q such that for every 2 E L, if
|z| > q then z = IE1y1IE2y2 . . .:vmymxm+1, 1 3 m 3 n, y, 7é A, 1 3 71 3 m, and for every
k 2 1 : :c1y'f:r2y§...xmyf,,xm+1 E L.

. CPCHREG c CPC,,+1REG, n 3 1.
. PCHREG c PC,,+1REG, n 3 1.
. CPCHREG c CPCHLIN c CPCHCF, n 3 1.

o N CPCOOCF Q PCOOCF (i.e. a centralized + nonreturning working mode is weaker
than a noncentralized + returning one).

0 CS = YHCS = YOOCS, n 2 1, for every Y E {CPC, NCPC} (i.e. by using centralized
CS PCGS’s, one does not go beyond the family CS).

0 C5 = PC1CS = PC2CS C PC3CS = PCOOCS = RE (noncentralized returning
PCGS’s with three CS components sufﬁce to generate every RE).

0 C3 = N PCHCS C N PC2CS' = N PCOOCS = RE (noncentralized nonreturning
PCGS’s with just two CS components are enough to generate every RE).

. Given XHCSA, n 3 1, X e {P0, CPO, NPC, NCPC} ; C3 = X103" c X203‘ =
X,,CS’\ = RE, for every n 2 2.

5.3 Grammar Ecosystems

The postulates behind the notion of a grammar ecosystem are the following:

a) An ecosystem consists of an environment and some agents. The state of the environment
as well as the states of the agents are all described by means of strings of letters from
certain alphabets.

b) There exists one universal clock for the evolution of both the environment and the agents.

c) Both the environment and the agents have speciﬁc evolution rules, which are Linden-
mayer rules (i.e. they are applied in parallel to all the letters describing the states of the
environment and of the agents).

d) The rules for the evolution of the environment are independent from the agents and from
the state of the environment. The rules for the evolution of the agents depend on the state
of the environment in such a way that, at each step of the derivation, a speciﬁc appropriate
subset of rules is selected from the set of rules of each agent.

Carlos Martin-Vide

e) The agents act on the environment through action rules, which are sequential (i.e. non-
parallel) rewriting rules. The selection of the speciﬁc action rule to be applied at each
step depends on the current state of the agent.

f) Agents’ action on the environment has a priority over the environment’s evolution. At
each step, the rules for the evolution of the environment rewrite in a parallel way only the
environment letters that are not affected by agent’s actions.

A grammar ecosystem is a construct:

E: (E,A1,A2,...,An)

consisting of:

O E = (VE,PE), Wlthi

(i) V}; a ﬁnite alphabet,

(ii) PE a ﬁnite set of 0L rules over VE (evolution rules of E).
.  = (l/i7Pi7Ri7§0i71/}i)9 1 S  S n9 

(i) V, a ﬁnite alphabet,

(ii) P, a ﬁnite set of 0L rules over V, (evolution rules of the agent 1'),
(iii) R, a ﬁnite set of rules :3 —> y, with :3 6 V5 , y 6 V5 (action rules of the agent 1'),
(iv) go, : V5 —> 73(P,) (it selects the rules for the current evolution of the agent 2'),

(v) 1/1, : V,.+ —> 73(R,), 1 3 71 3 n (it selects the rules for the current action of A, on
the environment).

A grammar ecosystem works by modifying the strings representing the agents as well as the
environment.

A state of a grammar ecosystem is:

0 = (wE,w1,w2, . . . ,w,,),
where:
0 UJE 6 V5,
0 w,€V,~*,1§z'§n.
Given 0 = (11113, wl, U12, . . . ,w,,), A, is an active agent in 0 if and only if 1/1, 7S (2). An

action of A, in 0 is an application of 7" E 1/1, on wE. A simultaneous action of the
agents A,1, A,2, . . . , A,T, «[711, 712, . . . , 71,} Q «[1, 2, . . . ,n}, on the environment is a 1-step parallel
derivation UJE =>g 1115 such that:

Formal Languages for Linguists: Classical and Nonclassical Models

(i) UJE = IE1’I.t1IE2’I.L2 . . .’Ll,,~£E,»+1,
.. , _
(ii) ’LUE — IE1’U1IE2’U2 . . .vT:v,+1, and

 ’LL_7'—)’l}_7'€’(/1Z'].(’(1)Z'].),1SjST,IEi€V§,1S’iST+1.

A state change of a grammar ecosystem is an 0L evolution of the states of all the agents (i.e.
wi =>g wg, according to the productions in goi (1113), 1 3 71 3 n) together with an 0L evolution
of the environment in all its points (i.e. UJE =>g wjg, according to the productions in PE),
except those ones that are currently affected by the agents’ actions (according to the productions

in 1/10-

Given two states in E, 0 = (wE,w1,w2, . . . ,wn), 0’ = (w}3,w’1,w§, . . . ,w;L), one says that 0

changes to 0’ (or 0’ directly derives from 0: 0 =>g 0’) if and only if:

(i) UJE = 211131212132 . . . zm:cmzm+1 and H131; = ziy1z§y2...z;nymz;n+1 and 25113122132 . . . Zm£EmZm+1 =>g
Z1y1Z2y2 . . . zmymzm+1 is a simultaneous action of all the agents Ail , Ab, . . . ,AZ~m , «[711, i2, . . . , Q

«[1, 2, . . . ,n}, that are active in 0 and  . . .z;nz;n+1 is an evolution from Z1252 . . .zmzm+1,

(ii) U); is an evolution of Ai from wi, 1 3 71 3 n.

The sequences of states characterize the evolutionary behaviour of 2. Let 00 be an initial state.
One may deﬁne:

o The set of sequences of states of E:

Seq(E,00) = {{0Z~};’:0 : 00 :>g 01 :>g 02 :>g 
0 The set of sequences of states of E:

SeqE(E,00) = {{wE2.};’:0 : {0,~};?°;0 E Seq(E,00) and aj = (wE].,w1j,w2]., . . . ,wnj)}.
o The set of sequences of states of 14]’ (1 3 j 3 n):

S'eqj(E,00) = {{wjk},‘:":0 : {0k},‘:":0 E Seq(E,00) and ak = (wEk,w1k, . . .,
wjk, . . . 

o The language of the environment:
LE(E,00) = {UJE 6 V5 : {0}-};?°;0 E Seq(E,00) and aj = (wE,w1,w2, . . . ,wn)}.
o The language of the agent Ai (1 3 71 3 n):

LZ~(E,00) = {wi E  : {a,~};:0 E Seq(E,00) and 03- = (wE,w1, . . . ,wZ~, . . . ,wn)}.

Carlos Martin-Vide

Example 5.8 The grammar ecosystem.‘

E Z (E7141)
with.‘
E = (VE, PE), where.‘
VE = {CL},
PE = {a —> a}.
A1 = (V1, P1, R1, 901,1/11), where.‘

V1 = 

P1 Z  *> b},

R1 = {a —> a4},

g01(w) = P1, for every 11) 6 V5,
1/11 = R1, for every u E V1+.

produces.‘

Seq(E, 00) = {(a, b), (a4, b), (a7, b), . . . , (a3i+1, b), . . .},
LE(E,o0) = {a3i+1,z' Z O},

L1(E, 00) = 

If P1 above is replaced by P1’ = {b —> A}, the agent becomes inactive after the ﬁrst step and
therefore does not act on the environment anymore.‘

Seq(E,o0) = {(a, b), (a4,)\)},
LE(E,o0) = {a,a4}.

Example 5.9 The grammar ecosystem.‘

E = (E, 141)
with.‘
E = (VE, PE), where.‘

VE : {enf}:

Formal Languages for Linguists: Classical and Nonclassical Models

PE={e—>e,f—>f}.
A1 = (V1, P1, R1, 901,1/11), where.‘

V1={a},

P1 = {a—>a,a—>a3},
901(6) = {G —> 03}:
€01(f) = {G —* G}:

R1 ={€—>f,f—>f}:

1/11(0) ={6—>f},
1/11(a3) = {f —>f}-

produces.‘

L1(E, (6, a)) = {a, a3}.

5.4 Why Nonstandard Generative Mechanisms
5.4.1 Adjoining

Let I CL(F), F E {FI N , REG}, denote the family of languages generated by contextual
grammars with selection of type F. Some major results concerning the generative capacity of
contextual grammars are the following:

. ICL(FIN) c ICL(REG) c ICL(CF) c ICL(CS) c ICL(RE).
. REG c ICL(FIN).

o LIN and CF are incomparable with all families ICL(F), F E {REG, CF, CS, RE},
but I CL (C S ) C C S . (Incomparability, meaning that the respective differences are nonempty,
leads to eccentricity, which seems to be a linguistically valuable point to take into ac-
count.)

0 I CL(FI N ) is an abstract anti-family of languages, i.e. a set closed to none of the six
AFL operations: union, concatenation, Kleene star, morphisms, inverse morphisms and
intersection with regular languages.

The latter result makes natural the question of ﬁnding the smallest AFL containing ICL(FIN
The result is surprising.

Theorem 5.10 For every L 6 RE : L = L1\L2, L1 6 REG, L2 6 ICL(FIN).

Carlos Martin-Vide

So, iterated adjoining of contexts (i.e. paste), as selected by ﬁnite sets of strings, plus a left
quotient (i.e. cut) by a regular language are able to simulate any Turing machine. What is
needed is both: context-sensing and erasing abilities.

The same could be got by using a one-sided internal contextual grammar, all whose contexts
are of the form (A, U). The family of languages generated by one-sided internal contextual
grammars is denoted by 1IGL(F) (with selection of type F).

Theorem 5.11 For every L 6 RE : L = (L1\L2) ﬂ V*, L1 6 REG, L2 6 1IGL(GF).

5.4.2 Inserting
An insertion grammar is a construct:

G = (V, A, P),
where:

0 V is an alphabet,
o A is a ﬁnite set of axioms,

o P is a ﬁnite set of triples (u, :3, U), u, :3, U E V* (insertion rules).

The immediate derivation works as follows:

foreveryw, z E V* : w :> 2' if and only ifw = 'LU1'Ll/U'LU2, z = w1u:3vw2, U11, U12 6 V*, (13, :3, U) E P.

For an insertion grammar G, one deﬁnes its weight w:
w(G) = ma:3{|u| : (u,:3,v) E Por(v,:3,u) E P}.

The family of languages generated by insertion grammars of weight at most 73, n 2 0, is denoted
by I N S”. The union of all those families is I N 300. The following results are known:
o FIN C INS0 C INS1 C C INSOO C CS.
0 REG is incomparable with all families I N S”, n 2 1, and REG C I N 300.
o INS1 C CF, but CF is incomparable with all families INS”, n 2 2, and INSOO.

o LIN is incomparable with all families I N S”, n 2 1, and I N S00.

Formal Languages for Linguists: Classical and Nonclassical Models

0 All families I N S”, n 2 0, are anti-AFL’s.

Theorem 5.12 For every L 6 RE : L = L1\L2, L1 6 REG, L2 6 INS”, n 2 7.

What one does in this case is ﬁrst to make use of insertion operations, and then to cut a preﬁx
of the string by means of a quotient with respect to a regular language. If the cutting operation
is introduced into the grammar, the so-called insertion-deletion grammars are obtained.

An insertion-deletion grammar is a construct:

G: (V7A7PI7PD)9

where:

V is an alphabet,

A is a set of axioms,

PI is a set of insertion rules (a ﬁnite subset of V* X V* X V*),

PD is a set of deletion rules (a ﬁnite subset of V* X V* X V*).

The immediate derivation works as follows:
for everyw, z E V* : 11) => 2 if and only if :

(i) either 11) = 'LU1'Ll/U'LU2, z = ’Ll}1’Ll.IE'U'LU2, (u, :3, U) E P], U11, U12 6 V*,

(ii) orw = ’(1}1’I,LIE’l}’(1}2, z = ’(.l}1’I.l/l}’(1}2,(’I.l.,IE,’U) E PD,w1,w2 E V*.

The family of languages generated by insertion-deletion grammars is denoted by I N S DEL.

Theorem 5.13 For every L 6 RE, L = L’ (1 V*, for some L’ E INSDEL.

If the length of the strings that are inserted/deleted is taken into consideration, one can be more
precise: L’ E I N SfDEL% (i.e. strings of length at most one are inserted in contexts of weight
at most two, and strings of length at most one are deleted from contexts of weight at most one).
As well, L’ belongs to both I N SQDELS and I N SfDEL3.

Carlos Martin-Vide

5.4.3 Splicing

A splicing rule over an alphabet V is a string 7" = u1#u2$u3#u4, u, E V*, 1 3 7} 3 4,
#, $ ¢ v.

The immediate derivation relation runs as follows:

for everyx,y, z E V* : (:v,y) |-, z if and only if :

(1) 53 = 1E1U1U21E2,

(ii) y = y1U3U4.U2,

(iii) 2' = :v1u1u4y2,

 x17x27y17y2 E 
An H scheme is a pair 0 = (V, R), R Q V*#V*$V*#V*.

Given 0 = (V, R) and a language L Q V*, one deﬁnes:

o 0(L) ={z€V* : (x,y) I-T z,:E,yEL,7“€R},

This allows the introduction of a new generative mechanism. An extended H system is a
construct:

'7 = (V,T,A,R),

where:

V is an alphabet,
o T Q V is a set of terminal letters,
0 A Q V* is a set of axioms,

R g V*#V*$V*#V*.

Formal Languages for Linguists: Classical and Nonclassical Models

(0 = (V, R) is the underlying H scheme of 7.)

The language generated by 7 is:
L('y) = o*(A) ﬂ T*.

Given two families of languages F1, F2, EH (F1, F2) denotes the family of languages L('y),
7 = (V, T, A, R), with A 6 F1, R 6 F2. A surprising result is obtained again.

Theorem 5.14 EH(F1,F2) = RE,forevery F1,F2 : FIN Q F1, REG Q F2.

Thus, by using nonstandard resources the greatest generative power is achieved, while keeping
the complexity of the mechanism at a very low level.

6 Papers Cited

0 Bresnan, J ., R.M. Kaplan, S. Peters and A. Zaenen. 1982. ”Cross-serial dependencies in
Dutch”. Linguistic Inquiry, 13(4), 613-635.

0 Culy, C. 1985. ”The complexity of the vocabulary of Bambara”. Linguistics and Philos-
ophy, 8, 345-351.

0 Gazdar, G. 1981. ”Unbounded dependencies and coordinate structure”. Linguistic In-
quiry, 12(2), 155-184.

0 Pullum, G.K. and G. Gazdar. 1982. ”Natural languages and context-free languages”.
Linguistics and Philosophy, 4, 471-504.

0 Shieber, S.M. 1985. ”Evidence against the context-freeness of natural language”. Lin-
guistics and Philosophy, 8, 333-343.

7 Further Reading and Relevant Resources

Generally speaking, for a linguist wishing to be introduced into the ﬁeld of mathematical meth-
ods in linguistics, which is a scope notably larger than the one taken in the present chapter,
Partee, ter Meulen and Wall (1990) is strongly recommended. It is a book thought for initiating
mathematically nontrained students. Brainerd (1971), Wall (1972) and Partee (1978) may be
still valid references, too. One chapter in Cole, Varile and Zampolli (1997) explains the main
trends for connecting different mathematical models with computational developments.

The most comprehensive and updated handbook of classical as well as nonclassical formal
languages is Rozenberg and Salomaa (1997).

Very cited treatises in classical formal language theory (with different levels of difﬁculty)
include Aho and Ullman (1971-1973), Davis, Sigal and Weyuker (1994), Harrison (1978),
Hopcroft and Ullman (1979), Révész (1991), Salomaa (1988), and Wood (1987). Other good

Carlos Martin-Vide

books (not all of them having a completely general scope) are Brookshear (1989), Dassow and
Paun (1989), Drobot (1989), Floyd and Beigel (1994), Gurari (1989), Howie (1991), Kelley
(1995), Lewis and Papadimitriou (1981), Linz (1990), McNaughton (1982), Moll, Arbib and
Kfoury (1988), and Sudkamp (1988).

Some of the developments in nonstandard formal language theory can be found in Csuhaj-
Varju, Dassow, Kelemen and Paun (1994), Paun (1995), Paun (1997), and Paun, Rozenberg and
Salomaa (1998).

The present state-of-the-art of the ﬁeld is well pictured in Martin-Vide and Mitrana (2001a),
and Martin-Vide and Mitrana (2001b).

The following references may be of help to the reader interested in knowing more about lin-
guistic applications of formal language theory: Kolb and Monnich (1999), Levelt (1974),
Manaster Ramer (1987), Martin-Vide (1994), Martin-Vide (1998), Martin-Vide (1999), Martin-
Vide and Paun (2000), Paun (1994), Savitch, Bach, Marsh and Safran-Naveh (1987), Savitch
and Zadrozny (1994), Sells, Shieber and Wasow (1991), and Zadrozny, Manaster Ramer and
Moshier (1993).

References

8 Books

Aho, A.V., J .E. Hopcroft and J .D. Ullman. 1974. The design and analysis of computer algo-
rithms. Reading, MA: Addison-Wesley.

Aho, A.V., R. Sethi and J .D. Ullman. 1986. Compilers.‘ principles, techniques, and tools.
Reading, MA: Addison-Wesley.

Aho, A.V. and J .D. Ullman. 1971-1973. The theory of parsing, translation and compiling, 2
vols. Englewood Cliffs, NJ: Prentice-Hall.

Aho, A.V. and J .D. Ullman. 1977. Principles of compiler design. Reading, MA: Addison-
Wesley.

Amos, M. 2001. Theoretical and experimental DNA computation. Berlin: Springer.
Arbib, M.A. 1969. Theories of abstract automata. Englewood Cliffs, NJ: Prentice-Hall.

Atallah, M.J. (Editor). 1998. CRC handbook of algorithms and theory of computation. Boca
Raton, FL: CRC.

Bavel, Z. 1983. Introduction to the theory of automata. Reston, VA: Reston.
Berstel, J . 1979. Transductions and context-free languages. Stuttgart: Teubner.
Berstel, J . and C. Reutenauer. 1988. Rational series and their languages. Berlin: Springer.

Book, R.V. (Editor). 1980. Formal language theory.‘ perspectives and open problems. New
York, NY: Academic Press.

Formal Languages for Linguists: Classical and Nonclassical Models

Booth, T.L. 1967. Sequential machines and automata theory. New York, NY: John Wiley.
Brainerd, B. 1971. Introduction to the mathematics of language study. New York, NY: Elsevier.
Brainerd, W.S. and L.H. Landweber. 1974. Theory of computation. New York, NY: John Wiley.

Brookshear, J .G. 1989. Theory of computation.‘ formal languages, automata, and complexity.
Redwood City, CA: Benjamin/Cummings.

Carroll, J . and D. Long. 1989. Theory of ﬁnite automata. Englewood Cliffs, NJ: Prentice-Hall.

Cohen, D.I.A. 1986. Introduction to computer theory. New York, NY: John Wiley. (2nd ed.,
1991.)

Cole, R., G.B. Varile and A. Zampolli (Editors). 1997. Survey of the state of the art in human
language technology. Cambridge: Cambridge University Press.

Csuhaj-Varju, E., J . Dassow, J . Kelemen and Gh. Paun. 1994. Grammar systems: a grammat-
ical approach to distribution and cooperation. London: Gordon and Breach.

Dassow, J . and Gh. Paun. 1989. Regulated rewriting in formal language theory. Berlin:
Springer.

Davis, M.D. (Editor). 1965. The undecidable: basic papers on undecidable propositions, un-
solvable problems and computable functions. New York, NY: Raven.

Davis, M.D., R. Sigal and E.J. Weyuker. 1983. Computability, complexity, and languages.‘ fun-
damentals of theoretical computer science. New York, NY: Academic Press. (2nd ed., 1994.)

Denning, P.J., J .B. Dennis and J .E. Qualitz. 1978. Machines, languages, and computation.
Englewood Cliffs, NJ: Prentice-Hall.

Drobot, V. 1989. Formal languages and automata theory. Rockville, MD: Computer Science
Press.

Eilenberg, S. 1974-1976. Automata, languages, and machines, 2 Vols. New York, NY: Aca-
demic Press.

Engeler, E. 1968. Formal languages. Chicago, IL: Markham.

Floyd, R.W. and R. Beigel. 1994. The language of machines.‘ an introduction to computability
and formal languages. Rockville, MD: Computer Science Press.

Gécseg, F. and 1. Peak. 1972. Algebraic theory of automata. Budapest: Akadémiai Kiado.
Gécseg, F. and M. Steinby. 1984. Tree automata. Budapest: Akadémiai Kiado.

Gill, A. 1962. Introduction to the theory of ﬁnite-state machines. New York, NY: McGraw-
Hill.

Ginsburg, S. 1962. An introduction to mathematical machine theory. Reading, MA: Addison-
Wesley.

Ginsburg, S. 1966. The mathematical theory of context-free languages. New York, NY:
McGraw-Hill.

Carlos Martin-Vide

Ginsburg, S. 1975. Algebraic and automata-theoretic properties of formal languages. Amster-
dam: North-Holland.

Ginsburg, S., S. Greibach and J .E. Hopcroft. 1969. Studies in abstract families of languages.
Providence, RI: American Mathematical Society.

Ginzburg, A. 1968. Algebraic theory of automata. New York, NY: Academic Press.

Gurari, E. 1989. An introduction to the theory of computation. New York, NY: Computer
Science Press.

Harrison, M.A. 1965. Introduction to switching and automata theory. New York, NY:
McGraw-Hill.

Harrison, M.A. 1969. Lectures on linear sequential machines. New York, NY: Academic Press.
Harrison, M.A. 1978. Introduction to formal language theory. Reading, MA: Addison-Wesley.
Hennie, F.C. 1968. Finite-state models for logical machines. New York, NY: John Wiley.
Herken, R. (Editor). 1988. The universal Turing machine. Oxford: Oxford University Press.

Herman, G.T. and G. Rozenberg. 1975. Developmental systems and languages. Amsterdam:
North-Holland.

Hofstadter, D.R. 1979. Godel, Escher, Bach: an eternal golden braid. New York, NY: Basic
Books.

Hopcroft, J .E. and J .D. Ullman. 1969. Formal languages and their relation to automata. Read-
ing, MA: Addison-Wesley.

Hopcroft, J .E. and J .D. Ullman. 1979. Introduction to automata theory, languages, and com-
putation. Reading, MA: Addison-Wesley.

Howie, J .M. 1991. Automata and languages. Oxford: Oxford University Press.

Ito, M. and H. Jiirgensen (Editors). 1994. Words, languages and combinatorics 2. Singapore:
World Scientiﬁc.

Karhumaki, J ., H.A. Maurer, Gh. Paun and G. Rozenberg (Editors). 1999. Jewels are forever.
Berlin: Springer.

Karhumaki, J ., H.A. Maurer and G. Rozenberg (Editors). 1994. Results and trends in theoret-
ical computer science. Berlin: Springer.

Kelley, D. 1995. Automata and formal languages.‘ an introduction. Englewood Cliffs, NJ:
Prentice-Hall.

Kolb, H.-P. and U. Monnich (Editors). 1999. The mathematics of syntactic structure.‘ trees and
their logics. Berlin: Mouton de Gruyter.

Kuich, W. and A. Salomaa. 1986. Formal power series and languages. Berlin: Springer.

Kuich, W. and A. Salomaa. 1986. Semirings, automata, languages. Berlin: Springer.

Formal Languages for Linguists: Classical and Nonclassical Models

Leeuwen, J. van (Editor). 1990. Handbook of theoretical computer science, 2 vols. Amster-
dam/Cambridge, MA: North-Holland/MIT Press.

Levelt, W.J.M. 1974. Formal grammars in linguistics and psycholinguistics, 3 Vols. The
Hague: Mouton.

Lewis, H.R. and C.H. Papadimitriou. 1981. Elements of the theory of computation. Englewood
Cliffs, NJ: Prentice-Hall.

Linz, P. 1990. An introduction to formal languages and automata. Lexington, MA: D.C. Heath.
(2nd ed., 1996.)

Manaster Ramer, A. (Editor). 1987. Mathematics of language. Amsterdam: John Benjamins.
Marcus, S. 1967. Algebraic linguistics: analytical models. New York, NY: Academic Press.

Martin-Vide, C. (Editor). 1994. Current issues in mathematical linguistics. Amsterdam:
North-Holland.

Martin-Vide, C. (Editor). 1998. Mathematical and computational analysis of natural lan-
guage. Amsterdam: John Benjamins.

Martin-Vide, C. (Editor). 1999. Issues in mathematical linguistics. Amsterdam: John Ben-
jamins.

Martin-Vide, C. and V. Mitrana (Editors). 2001a. Grammars and automata for string pro-
cessing: from mathematics and computer science to biology, and back. London: Gordon and
Breach.

Martin-Vide, C. and V. Mitrana (Editors). 2001b. Where mathematics, computer science, lin-
guistics and biology meet. Dordrecht: Kluwer.

Martin-Vide, C. and Gh. Paun (Editors). 2000. Recent topics in mathematical and computa-
tional linguistics. Bucharest: Editura AcadeIr1iei Romane.

McNaughton, R. 1982. Elementary computability, formal languages, and automata. Engle-
wood Cliffs, NJ: Prentice-Hall.

Minsky, M.L. 1967. Computation.‘ ﬁnite and inﬁnite machines. Englewood Cliffs, NJ:
Prentice-Hall.

Moll, R.N., M.A. Arbib and A.J. Kfoury. 1988. An introduction to formal language theory.
Berlin: Springer.

Moore, E.F. (Editor). 1964. Sequential machines.‘ selected papers. Reading, MA: Addison-
Wesley.

Nelson, R.J. 1968. Introduction to automata. New York, NY: John Wiley.
Nijholt, A. 1980. Context-free grammars.‘ covers, normal forms and parsing. Berlin: Springer.
Nijholt, A. 1988. Computers and languages.‘ theory and practice. Amsterdam: North-Holland.

Papadimitriou, C.H. 1994. Computational complexity. Reading, MA: Addison-Wesley.

Carlos Martin-Vide

Partee, B.H. 1978. Foundations of mathematics for linguistics. Harrisburg, PA: Greylock.

Partee, B.H., A.G.B. ter Meulen and R.E. Wall. 1990. Mathematical methods in linguistics.
Dordrecht: Kluwer.

Paun, Gh. (Editor). 1994. Mathematical aspects of natural and formal languages. Singapore:
World Scientiﬁc.

Paun, Gh. (Editor). 1995. Artiﬁcial life: grammatical models. Bucharest: Black Sea University
Press.

Paun, Gh. 1997. Marcus contextual grammars. Dordrecht: Kluwer.

Paun, Gh. (Editor). 1998. Computing with bio-molecules.‘ theory and experiments. Singapore:
Springer.

Paun, Gh., G. Rozenberg and A. Salomaa. 1998. DNA computing: new computing paradigms.
Berlin: Springer.

Paun, Gh. and A. Salomaa (Editors). 1997. New trends informal languages.‘ control, cooper-
ation, and combinatorics. Berlin: Springer.

Paun, Gh. and A. Salomaa (Editors). 1999. Grammatical models of multi-agent systems. Lon-
don: Gordon and Breach.

Paz, A. 1971. Introduction to probabilistic automata. New York, NY: Academic Press.
Pin, J .-E. 1986. Varieties of formal languages. Oxford: Plenum. (Orig., 1984.)

Révész, G.E. 1983. Introduction to formal languages. New York, NY: McGraw-Hill. (2nd ed.:
New York, NY: Dover, 1991.)

Rozenberg, G. and A. Salomaa. 1980. The mathematical theory of L systems. New York, NY:
Academic Press.

Rozenberg, G. and A. Salomaa (Editors). 1986. The book of L. Berlin: Springer.

Rozenberg, G. and A. Salomaa (Editors). 1992. Lindenmayer systems: impacts on theoretical
computer science, computer graphics and developmental biology. Berlin: Springer.

Rozenberg, G. and A. Salomaa (Editors). 1997. Handbook of formal languages, 3 vols. Berlin:
Springer.

Rozenberg, G. and W. Thomas (Editors). 2000. Developments in language theory: founda-
tions, applications and perspectives. Singapore: World Scientiﬁc.

Salomaa, A. 1969. Theory of automata. Oxford: Pergamon.

Salomaa, A. 1973. Formal languages. New York, NY: Academic Press.

Salomaa, A. 1981. Jewels of formal language theory. Rockville, MD: Computer Science Press.
Salomaa, A. 1985. Computation and automata. Cambridge: Cambridge University Press.

Salomaa, A. and M. Soittola. 1978. Automata-theoretic aspects of formal power series. Berlin:
Springer.

Formal Languages for Linguists: Classical and Nonclassical Models

Savitch, W.J., E.W. Bach, W. Marsh and G. Safran-Naveh (Editors). 1987. The formal com-
plexity of natural language. Dordrecht: Reidel.

Savitch, W.J. and W. Zadrozny (Editors). 1994. Mathematics of language, Linguistics and
Philosophy, 17(6). Dordrecht: Kluwer.

Sells, P., S.M. Shieber and T. Wasow (Editors). 1991. Foundational issues in natural language
processing. Cambridge, MA: MIT Press.

Sikkel, K. 1996. Parsing schemata.‘ a framework for speciﬁcation and analysis of parsing
algorithms. Berlin: Springer.

Sippu, S. and E. Soisalon-Soininen. 1988-1990. Parsing theory, 2 vols. Berlin: Springer.
Sudkamp, T.A. 1988. Languages and machines. Reading, MA: Addison-Wesley.
Trakhtenbrot, B.A. and Y.M. Barzdin. 1973. Finite automata. Amsterdam: North-Holland.
Turing, A.M. 1992. Mechanical intelligence, ed. by D.C. Ince. Amsterdam, North-Holland.

Wall, R.E. 1972. Introduction to mathematical linguistics. Englewood Cliffs, NJ: Prentice-
Hall.

Wood, D. 1980. Grammar and L forms.‘ an introduction. Berlin: Springer.
Wood, D. 1987. Theory of computation. New York, NY: John Wiley.

Zadrozny, W., A. Manaster Ramer and M.A. Moshier (Editors). 1993. Mathematics of lan-
guage, Annals of Mathematics and Artiﬁcial Intelligence, 8(1-2). Basel: J .C. Baltzer.

9 Journals

Acta Cybernetica

Acta Informatica

BioSystems

Bulletin of the European Association for Theoretical Computer Science
Communications of the Association for Computing Machinery
Computational Intelligence

Computational Linguistics

Computers and Artiﬁcial Intelligence

Discrete Mathematics

F undamenta Informaticae

Grammars. A Journal of Mathematical Research on Formal and Natural Languages

Carlos Martin-Vide

Information and Computation (before, Information and Control)
Information Processing Letters

International Journal of Computer Mathematics

International Journal of Foundations of Computer Science
Journal of Automata, Languages and Combinatorics

Journal of Computer and System Sciences

Journal of Logic, Language and Information

Journal of the Association for Computing Machinery

Journal of Universal Computer Science

Kybernetika

Linguistics and Philosophy

Mathematical Structures in Computer Science (before, Mathematical Systems Theory)
New Generation Computing

Revue Franaise d’Automatique, Informatique et Recherche 0pe’rationelle (RAIRO): Informa-
tique The’orique

Revue Roumaine de Mathématiques Pures et Applique’es

Theoretical Computer Science

10 Major Conferences

0 ACL Annual Meeting of the Association for Computational Linguistics

0 AFL Conference on Automata and Formal Languages

0 AMiLP Algebraic Methods in Language Processing

0 CIAA International Conference on Implementation and Application of Automata
o CLIN Computational Linguistics in the Netherlands Meeting

0 COLING International Conference on Computational Linguistics

0 DCAGRS Workshop on Descriptional Complexity of Automata, Grammars and Related
Structures

0 DIIVIACS International Meeting on DNA Based Computing
0 DLT International Conference Developments in Language Theory

0 ESSLLI European Summer School of Logic, Language and Information

Formal Languages for Linguists: Classical and Nonclassical Models

11

12

13

FCT Fundamentals of Computation Theory

GS International Workshop Grammar Systems

ICALP International Colloquium on Automata, Languages and Programming
ICWLC International Colloquium on Words, Languages and Combinatorics

IWPT International Workshop on Parsing Technologies

LACL International Conference on Logical Aspects of Computational Linguistics
MCU International Conference on Machines, Computations and Universality

MFCS International Symposium on Mathematical Foundations of Computer Science
MOL Meeting on Mathematics of Language

UMC Conference on Unconventional Models of Computing

Professional Associations

Association for Computational Linguistics, Special Interest Group on Mathematics of
Language, http://www.cis.upenn.edu/ ircs/mo1/mol.html

Association for Computing Machinery, Special Interest Group on Algorithms and Com-
puting Theory, http://sigact.acm.org/

European Association for Theoretical Computer Science, http://www.eatcs.org/

Web Sites

American Mathematical Society Preprint Server, http://www.ams.org/preprints/

Collection of Computer Science Bibliographies, http://liinwww.ira.uka.de/bibliography/index.html
Computing Research Repository, http://xxX.lanl.gov/archive/cs/intro.html

Mathematics WWW Virtual Library, http://euclid.math.fsu.edu/Science/math.html

Networked Computer Science Technical Reference Library, http://www.ncstrl.org/

Research Centres

Leiden Institute of Advanced Computer Science, http://www. wi.leidenuniv.n1/CS/

Turku Centre for Computer Science, http://www.tucs.ﬁ/

