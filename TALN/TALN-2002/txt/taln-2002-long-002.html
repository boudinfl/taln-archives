<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Ressources terminologiques et traduction probabiliste: premiers pas positifs vers un syst&#232;me adaptatif</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2002, Nancy, 24&#8211;27 juin 2002
</p>
<p>Ressources terminologiques et traduction probabiliste:
premiers pas positifs vers un syst&#232;me adaptatif
</p>
<p>Philippe Langlais
RALI/DIRO - Universit&#233; de Montr&#233;al
</p>
<p>C.P. 6128, succursale Centre-ville
Montr&#233;al (Qu&#233;bec)
Canada, H3C 3J7
</p>
<p>felipe@iro.umontreal.ca
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>Traduction statistique, adapatabilit&#233;, terminologie
Statistical machine translation, adaptativity, terminology
</p>
<p>R&#233;sum&#233; - Abstract
</p>
<p>Cette derni&#232;re d&#233;cennie a &#233;t&#233; le t&#233;moin d&#8217;importantes avanc&#233;es dans le domaine de la traduction
statistique (TS). Aucune &#233;valuation fine n&#8217;a cependant &#233;t&#233; propos&#233;e pour mesurer l&#8217;ad&#233;quation
de l&#8217;approche statistique dans un contexte applicatif r&#233;el.
</p>
<p>Dans cette &#233;tude, nous &#233;tudions le comportement d&#8217;un engin de traduction probabiliste lorsqu&#8217;il
traduit un texte de nature tr&#232;s &#233;loign&#233;e de celle du corpus utilis&#233; lors de l&#8217;entra&#238;nement. Nous
quantifions en particulier la baisse de performance du syst&#232;me et d&#233;veloppons l&#8217;id&#233;e que l&#8217;int&#233;-
gration de ressources terminologiques dans le processus est une solution naturelle et salutaire &#224;
la traduction. Nous d&#233;crivons cette int&#233;gration et &#233;valuons son potentiel.
</p>
<p>The past decade witnessed exciting work in the field of Statistical Machine Translation (SMT).
However, accurate evaluation of its potential in a real-life context is still a questionable issue.
</p>
<p>In this study, we investigate the behavior of a SMT engine faced with a corpus far different from
the one it has been trained on. We show that terminological databases are obvious ressources
that should be used to boost the performance of a statistical engine. We propose and evaluate a
way of integrating terminology into a SMT engine which yields a significant reduction in word
error rate.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Langlais
</p>
<p>1 Introduction
</p>
<p>La traduction statistique est devenue populaire au sein de la communaut&#233; langagi&#232;re suite aux
travaux de (Brown et al., 1993). Depuis, de nombreux chercheurs se sont attel&#233;s &#224; la r&#233;alisation
de meilleurs mod&#232;les, et plusieurs approches s&#233;duisantes ont &#233;t&#233; propos&#233;es.
</p>
<p>M&#234;me si les &#233;tudes sur la traduction statistique incluent habituellement une section d&#8217;&#233;valuation
fournie, il reste cependant difficile de savoir ce qu&#8217;on est en droit d&#8217;attendre des performances
d&#8217;un moteur de traduction statistique sur une t&#226;che donn&#233;e1. Nous savons des travaux de (Wang,
1998) que dans une t&#226;che de traduction de parole, le moteur de traduction qu&#8217;il a d&#233;velopp&#233; se
comparait favorablement &#224; un syst&#232;me symbolique d&#233;velopp&#233; par plusieurs de ses coll&#232;gues. Il
est n&#233;anmoins hasardeux de g&#233;n&#233;raliser ce constat &#224; d&#8217;autres applications.
</p>
<p>Nous ne connaissons pas d&#8217;&#233;tude syst&#233;matique tentant d&#8217;&#233;valuer l&#8217;ad&#233;quation de la solution
statistique dans des environnements de traduction r&#233;els; terme que nous pr&#233;f&#233;rons d&#8217;ailleurs
laisser sans d&#233;finition. Il nous semble cependant &#233;vident qu&#8217;un syst&#232;me de traduction (statis-
tique ou non) est d&#8217;autant plus viable &#224; servir des applications vari&#233;es qu&#8217;il est capable de
s&#8217;adapter facilement &#224; des textes d&#8217;une nature tr&#232;s diff&#233;rente de celle des corpus utilis&#233;s lors
de la mise au point du syst&#232;me. Nous excluons donc de notre champ d&#8217;&#233;tude des syst&#232;mes
hautement sp&#233;cialis&#233;s qui par nature ne servent qu&#8217;une application tr&#232;s cibl&#233;e et peu &#233;volutive,
comme par exemple les syst&#232;mes METEO et ALT/Flash2. Curieusement, nous ne connais-
sons aucune &#233;tude sur l&#8217;adaptabilit&#233; des moteurs de traduction statistiques, et ce en d&#233;pit de
l&#8217;abondante litt&#233;rature d&#233;crivant des mod&#232;les de langue statistiques et adaptatifs.
</p>
<p>Dans ce travail, nous &#233;valuons les performances d&#8217;un moteur de traduction statistique lorsqu&#8217;il
traduit des textes relevant de domaines tr&#232;s pointus, c&#8217;est &#224; dire, tr&#232;s diff&#233;rents des corpus util-
is&#233;s pour l&#8217;entra&#238;nement des mod&#232;les de langue et de traduction sous-jacents. Nous d&#233;crivons
tout d&#8217;abord en section 2 notre engin de traduction. Nous quantifions ensuite en section 3 la
baisse de performance d&#8217;un engin entra&#238;n&#233; sur un corpus &#8220;g&#233;n&#233;ral&#8221; (le HANSARD) lorsqu&#8217;on
s&#8217;en sert pour traduire un texte tr&#232;s sp&#233;cifique (dans cette &#233;tude, un manuel militaire pour les
tireurs d&#8217;&#233;lite). Nous proposons alors en section 4 une m&#233;thode simple et naturelle d&#8217;am&#233;liorer
un syst&#232;me de traduction g&#233;n&#233;ral; &#224; savoir, son ouverture &#224; des ressources terminologiques
disponibles. Nous montrons en section 5 les performances obtenues en impl&#233;mentant notre
approche et discutons en section 6 d&#8217;autres travaux auxquels la pr&#233;sente &#233;tude est li&#233;e.
</p>
<p>2 Le moteur statistique
</p>
<p>2.1 Les mod&#232;les statistiques
</p>
<p>Pour ce travail, nous avons r&#233;alis&#233; un engin traduisant du fran&#231;ais vers l&#8217;anglais qui adopte le
paradigme du canal bruit&#233;, initialement pr&#233;sent&#233; dans le cadre de la traduction dans (Brown
et al., 1993) et qui peut se d&#233;crire simplement par l&#8217;&#233;quation 1, o&#249; eI&#770;1 repr&#233;sente la s&#233;quence
de mots cibles (ici des mots anglais) &#224; trouver, &#233;tant donn&#233;e la phrase &#224; traduire (ici des mots
fran&#231;ais) de J mots fJ1 .
</p>
<p>1Le m&#234;me constat peut d&#8217;ailleurs &#234;tre fait &#224; l&#8217;&#233;gard des syst&#232;mes non probabilistes.
2Je tiens &#224; remercier mes relecteurs pour leurs commentaires avis&#233;s.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ressources terminologiques et traduction probabiliste
</p>
<p>eI&#770;1 = argmax
I,eI1
</p>
<p>P (eI1)&#65080; &#65079;&#65079; &#65080;
langage
</p>
<p>. P (fJ1 |eI1)&#65080; &#65079;&#65079; &#65080;
traduction
</p>
<p>(1)
</p>
<p>Pour entra&#238;ner les mod&#232;les probabilistes sous-jacents, nous avons r&#233;uni un bitexte de 1 639 250
paires de phrases du HANSARD align&#233;es automatiquement au niveau des phrases. Dans cette
exp&#233;rience, tous les mots ont &#233;t&#233; convertis en lettres minuscules.
</p>
<p>Nous avons utilis&#233; un mod&#232;le trigramme interpol&#233; entra&#238;n&#233; sur la partie anglaise de notre bitexte.
La perplexit&#233; du mod&#232;le r&#233;sultant est assez basse &#8211; 65 &#8211; ce qui refl&#232;te les nombreuses formes
fig&#233;es pr&#233;sentes dans le HANSARD (ex: pursuant to standing order / conform&#233;ment
&#224; l&#8217;alin&#233;a).
Le mod&#232;le de traduction invers&#233; (de l&#8217;anglais vers le fran&#231;ais) utilis&#233; ici est similaire au mod&#232;le
2 d&#233;crit dans (Brown et al., 1993). Dix it&#233;rations du processus d&#8217;estimation des param&#232;tres
du mod&#232;le 1 ont &#233;t&#233; lanc&#233;es (r&#233;duisant la perplexit&#233; de 7 776 &#224; 90), suivies de 10 it&#233;rations du
processus d&#8217;estimation des param&#232;tres du mod&#232;le 2 (pour une perplexit&#233; finale de 54). Nous
avons &#233;galement r&#233;duit le nombre de param&#232;tres du mod&#232;le de transfert (voir &#233;quation 2), en
appliquant un algorithme d&#233;crit par (Foster, 2000) qui s&#233;lectionne les paires de mots les plus
int&#233;ressantes d&#8217;un mod&#232;le3.
</p>
<p>Le mod&#232;le 2 met &#233;galement en jeu un mod&#232;le de longueur tel que sp&#233;cifi&#233; dans l&#8217;&#233;quation 2.
Dans cette &#233;tude nous avons fait l&#8217;hypoth&#232;se que la longueur (compt&#233;e en mots) d&#8217;une phrase
fran&#231;aise, traduction d&#8217;une phrase anglaise &#233;tait normalement distribu&#233;e.
</p>
<p>p(fJ1 |eI1) = p(J |I)
J&#8719;
</p>
<p>j=1
</p>
<p>I&#8721;
</p>
<p>i=0
</p>
<p>p(i|j, J, I)&#65080; &#65079;&#65079; &#65080;
alignement
</p>
<p>. p(fj|ei)&#65080; &#65079;&#65079; &#65080;
transfert
</p>
<p>(2)
</p>
<p>2.2 L&#8217;algorithme de recherche de la meilleure traduction
</p>
<p>Nous avons &#233;tendu &#224; un mod&#232;le trigramme le d&#233;codeur propos&#233; par (Nie&#223;en et al., 1998). L&#8217;id&#233;e
de cet algorithme est d&#8217;&#233;tendre progressivement (c&#8217;est &#224; dire mot &#224; mot) les hypoth&#232;ses de
traductions, tout en couvrant progressivement les positions de la cha&#238;ne source. Nous invitons
le lecteur &#224; lire la description exacte de la r&#233;cursion sur laquelle est construite la recherche et
proposons &#224; la place en figure 1 une vue programmatique du d&#233;codeur. Une hypoth&#232;se dans
cette recherche est compl&#232;tement d&#233;termin&#233;e par quatre param&#232;tres: les positions source et
cible, la couverture source d&#8217;une hypoth&#232;se et la nature du mot cible &#224; la position cible. De ce
fait, l&#8217;espace peut-&#234;tre cod&#233; par une matrice creuse de dimension 4; chaque item dans cet espace
de recherche contenant des informations de cha&#238;nage arri&#232;re (backtracking) ainsi que le score
de l&#8217;hypoth&#232;se associ&#233;e.
</p>
<p>Nous savons que de meilleurs mod&#232;les de traduction ont &#233;t&#233; propos&#233;s et syst&#233;matiquement
compar&#233;s entre eux (Och &amp; Ney, 2000). Les performances que nous avons relev&#233;es avec notre
d&#233;codeur sur notre corpus HANSARD (voir la section 3) sont cependant comparables &#224; (voire
meilleures que) celles publi&#233;es ailleurs sur le m&#234;me type de corpus. Notre but &#233;tant avant tout
de comparer les performances d&#8217;un traducteur statistique utilis&#233; dans des conditions amicales
</p>
<p>3Nous avons ainsi conserv&#233; 1 million de param&#232;tres sur un total initial de 34 969 331 param&#232;tres</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Langlais
</p>
<p>ou au contraire adverses, il nous semble donc que le moteur que nous avons utilis&#233; sert tout &#224;
fait notre cause comparative.
</p>
<p>Entr&#233;e: f1 . . . fj . . . fJ
</p>
<p>Initialize the search space table Space
Select a maximum target length: Imax
Compute the active vocabulary
</p>
<p>for all target position i = 1, 2, . . . , Imax do
prune(i&#8722; 1);
for all alive hyp. h = Space(i, j, c, e) do
</p>
<p>uv &#8592; History(h);
zones &#8592; FreeSrcPositions(h);
bestWords &#8592; NBestTgtWords(uv);
for all w in bestWords do
</p>
<p>prob &#8592; Score(h) + log p(w|uv);
setIfBetter(i, j, c, b, prob, 0, j, v);
for all free source position d do
</p>
<p>s &#8592; prob;
for all f &#8712; [1, fmax] / d + f &#8722; 1 is free do
</p>
<p>s+ = log a(i|d, J) + log t(fd|ei);
setIfBetter(i, d, c + f, w, s, f, j, w);
</p>
<p>maxs &#8592; &#8722;&#8734;
for all i &#8712; [1, Imax] do
</p>
<p>for all alive hyp. h = Space(i, j, c, e) do
s &#8592; Score(h) + p(J |i);
if ((c == J) and (s &gt; maxs)) then
</p>
<p>maxs &#8592; s
&#12296;maxi,maxj,maxe&#12297; &#8592; &#12296;i, j, e&#12297;
</p>
<p>if (maxs! = &#8734;) then
Return Space(maxi,maxj, J,maxe);
</p>
<p>else
Failure
</p>
<p>Sortie: e1 . . . ei . . . emaxi
</p>
<p>Figure 1: Principe de base de notre d&#233;codeur
</p>
<p>3 Performances du moteur de traduction
</p>
<p>3.1 Corpus de test
</p>
<p>Dans cette section nous mesurons l&#8217;impact du type de corpus sur la performance de notre sys-
t&#232;me. Nous utilisons &#224; cet effet les deux corpus que nous d&#233;crivons ci-apr&#232;s. Le premier cor-
pus (nomm&#233;ment, HANSARD) est une collection de phrases extraites d&#8217;une partie du corpus</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ressources terminologiques et traduction probabiliste
</p>
<p>HANSARD non utilis&#233;e lors de l&#8217;entra&#238;nement. Nous n&#8217;avons utilis&#233; aucune strat&#233;gie partic-
uli&#232;re pour s&#233;lectionner ces phrases de mani&#232;re par exemple &#224; ce qu&#8217;elles soient proches des
textes d&#8217;entra&#238;nement.
</p>
<p>Le second corpus (dans la suite SNIPER) est un extrait d&#8217;un manuel militaire sur l&#8217;entra&#238;nement
et le d&#233;ploiement des tireurs d&#8217;&#233;lite; manuel qui a fait l&#8217;objet d&#8217;une autre &#233;tude (Macklovitch,
1995). Ce corpus rel&#232;ve hautement du domaine militaire et poserait sans aucun doute de nom-
breux probl&#232;me &#224; tout moteur (statistique ou non) non adapt&#233; &#224; ce type de texte. Les caract&#233;ris-
tiques principales de nos deux corpus sont regroup&#233;es dans la table 1.
</p>
<p>corpus nb |long.| SER WER
HANSARD 1038 &#12296;16.2, 7.8&#12297; 95.6 59.6
SNIPER 203 &#12296;20.8, 6.8&#12297; 100 74.6
</p>
<p>Table 1: Caract&#233;ristiques principales de nos corpus de test et performance de notre moteur de
traduction (voir la section suivante pour une description des taux SER et WER). |long.| indique
la longueur moyenne (compt&#233;e en mots) des phrases sources ainsi que l&#8217;&#233;cart type de cette
distribution; nb est le nombre de phrases dans le corpus.
</p>
<p>3.2 Performances du syst&#232;me
</p>
<p>Dans cette &#233;tude, nous &#233;valuons la performance de notre moteur de traduction en terme de
taux d&#8217;erreur mesur&#233;s au niveau de la phrase (SER) et des mots (WER). Ces deux taux sont
mesur&#233;s en r&#233;f&#233;rence &#224; un oracle disponible du fait que les deux corpus ont &#233;t&#233; publi&#233;s dans les
deux langues. Le premier taux mesure le pourcentage de phrases pour lesquelles la traduction
n&#8217;&#233;tait pas exactement celle de l&#8217;oracle, alors que le second taux est calcul&#233; par une distance de
Levenstein qui comptabilise le nombre minimal d&#8217;op&#233;rations qu&#8217;il faut effectuer pour passer de
la traduction produite &#224; la traduction oracle. Les trois op&#233;rations consid&#233;r&#233;es ici sont l&#8217;insertion,
la suppression et la substitution qui re&#231;oivent toutes le m&#234;me poids.
</p>
<p>Nous sommes conscients que ces mesures &#224; elles seules ne sont pas garantes d&#8217;une &#233;valuation
de qualit&#233;, mais nous &#233;tions h&#233;sitant &#224; recourir dans cette &#233;tude &#224; des &#233;valuations humaines,
en suivant par exemple le protocole d&#233;crit dans (Wang, 1998). En fait, un regard rapide sur la
d&#233;gradation des performances mesur&#233;e sur le corpus SNIPER est tellement criante (voir la table
1), qu&#8217;il nous a sembl&#233; inutile de passer par des &#233;valuations humaines pour la mettre en relief.
D&#8217;apr&#232;s la table 1, nous observons que les taux d&#8217;erreur au niveau des mots sur HANSARD
sont de l&#8217;ordre de 60% alors qu&#8217;il est de 74% sur le corpus SNIPER. Il est int&#233;ressant de noter
qu&#8217;aucune traduction sur ce dernier corpus n&#8217;a &#233;t&#233; identique &#224; la traduction de l&#8217;oracle.
</p>
<p>Bien qu&#8217;indiquant clairement une d&#233;gradation, il est difficile d&#8217;appr&#233;cier ce que ces taux d&#8217;erreur
signifient v&#233;ritablement. La table 2 nous aide &#224; mieux comprendre les valeurs prises par le WER
4
. Il convient de noter que les taux observ&#233;s sur le corpus hansard sont l&#233;g&#232;rement inf&#233;rieurs &#224;
</p>
<p>ceux rapport&#233;s r&#233;cemment par (Och et al., 2001) sur un corpus de m&#234;me type. Lors d&#8217;une &#233;tude
comparative de diff&#233;rents syst&#232;mes de d&#233;codage, les auteurs ont observ&#233; un taux de WER de
l&#8217;ordre de 69% sur un corpus de 250 phrases (d&#8217;au plus 14 mots) extraites du corpus HANSARD.
</p>
<p>4Les s&#233;ances de traduction au complet sont disponibles &#224; l&#8217;adresse:
www.iro.umontreal.ca/&#8764;felipe/ResearchOutput/TALN2002</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Langlais
</p>
<p>SRC cependant , il y a ici deux probl&#232;mes qui apparaissent .
REF however , there are two problems here .
CAN however , there are two problems emerging here . 11%
SRC les limites des circonscriptions &#233;lectorales
REF electoral boundaries
CAN the electoral boundaries 33%
SRC nous sommes fiers de ces habitants de london et d&#8217; autres canadiens qui con-
</p>
<p>sacrent leur temps et leur &#233;nergie &#224; b&#226;tir un monde meilleur .
REF we are proud of these londoners and of other canadians who devote their time
</p>
<p>and energies to improving our world .
CAN we are proud of these people of london and other people spend their time and
</p>
<p>energy to build a better world
50%
</p>
<p>SRC le mois de la nutrition
REF nutrition month
CAN in the month of nutrition 80 %
SRC quelle plus belle image peut on donner du canada ?
REF this is canada at its best .
CAN what more can be nice to canada ? 100%
</p>
<p>Table 2: Exemples de traductions extraites du corpus HANSARD &#224; diff&#233;rents niveaux de WER.
</p>
<p>3.3 Analyse de la baisse de performance
</p>
<p>Deux raisons majeures expliquent les pi&#232;tres performances observ&#233;es sur le corpus SNIPER:
la pr&#233;sence de mots hors vocabulaire et la traduction erron&#233;e des nombreuses unit&#233;s termi-
nologiques pr&#233;sentes dans le corpus.
</p>
<p>Sur le corpus SNIPER, 3.5% des mots sources (formes) et 6.5% des mots cibles sont en effet
inconnus des mod&#232;les statistiques. 44% des phrases sources et 77% des phrases cibles contien-
nent au moins un mot inconnu. Sur le corpus HANSARD, le taux de mots inconnus est beaucoup
plus faible: environ 0.5% des mots sources et cibles sont inconnus et seulement 5% des phrases
sources contiennent au moins un mot inconnu.
</p>
<p>De mani&#232;re pr&#233;visible, la pr&#233;sence massive de mots inconnus a un impact direct sur les perfor-
mances et en particulier, sur la couverture du vocabulaire actif &#224; partir duquel les traductions
sont construites. Sur le corpus SNIPER, on mesure une couverture du vocabulaire de la traduc-
tion oracle de l&#8217;ordre de 72% (0.5% des phrases cibles oracles sont totalement couvertes), tandis
que cette couverture s&#8217;&#233;l&#232;ve &#224; 86% sur le corpus HANSARD (24% des traductions de l&#8217;oracle
sont compl&#232;tement couvertes).
Il est en revanche beaucoup plus difficile de quantifier l&#8217;impact de la pr&#233;sence d&#8217;une terminolo-
gie sp&#233;cifique sur la qualit&#233; de la traduction. Cela demanderait pour le moins d&#8217;identifier tous
les termes et leur traduction. Une &#233;valuation indirecte de cet impact est cependant fournie dans
la section 5 o&#249; nous montrons que l&#8217;introduction d&#8217;entr&#233;es terminologiques am&#233;liore de mani&#232;re
significative les performances du syst&#232;me. La table 3 montre quelques exemples de mauvaise
traduction impliquant des termes sp&#233;cifiques au corpus SNIPER.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ressources terminologiques et traduction probabiliste
</p>
<p>terme source traduction oracle traduction automatique
&#226;me bore heart
huile polyvalente general purpose oil oil polyvalente
chambre chamber house of common
tireur d&#8217; &#233;lite sniper issuer of elite
la longueur de la crosse butt length the length of the crosse
</p>
<p>Table 3: Exemples de traduction erron&#233;e pour quelques termes du corpus SNIPER.
</p>
<p>4 Int&#233;gration de ressources terminologiques non probabilistes
</p>
<p>Plusieurs strat&#233;gies sont envisageables pour tenter d&#8217;am&#233;liorer la situation. En tout premier lieu,
il est possible que nous ayons &#224; disposition des corpus sp&#233;cifiques d&#8217;un domaine particulier
en taille suffisante pour que l&#8217;on puisse entra&#238;ner un mod&#232;le sp&#233;cifique que l&#8217;on peut ensuite
combiner avec le mod&#232;le &#8220;g&#233;n&#233;ral&#8221;.
</p>
<p>Nous pourrions de mani&#232;re plus r&#233;aliste tenter de d&#233;velopper un mod&#232;le de traduction adap-
tatif. Un mod&#232;le cache pourrait par exemple &#234;tre utilis&#233; en combinaison avec notre mod&#232;le
trigramme statique en ce qui concerne la composante langagi&#232;re de notre moteur. La r&#233;alisa-
tion d&#8217;une composante traductionnelle adaptative est cependant une entreprise beaucoup plus
sp&#233;culative qui n&#233;cessiterait entre autre une localisation assez pr&#233;cise des erreurs produites dans
des traductions ant&#233;rieures. Nous savons, suite aux travaux r&#233;alis&#233;s au sein du groupe de travail
ARCADE (V&#233;ronis &amp; Langlais, 2000), que l&#8217;alignement fin de mots est une t&#226;che difficile.
Une troisi&#232;me option s&#8217;offre &#224; nous: tirer profit de ressources terminologiques existantes, comme
par exemple Termium5. En fait, une des premi&#232;res t&#226;ches du traducteur est souvent celle de la
recherche terminologique; &#233;tape souvent prise en charge dans les organismes de traduction par
des traducteurs terminologues (Langlais et al., 2001). Il semble donc naturel d&#8217;un point de vue
utilisateur d&#8217;ouvrir un syst&#232;me de traduction &#224; des ressources terminologiques existantes (ou
lexiques terminologiques dans la suite).
Parce qu&#8217;il est peu vraisemblable que ces ressources terminologiques soient livr&#233;es avec des
probabilit&#233;s de traduction, nous pr&#233;f&#233;rons voir un lexique terminologique comme un faisceau
de contraintes qui permet de r&#233;duire l&#8217;espace de recherche de notre moteur. Savoir par exemple
que le terme tireur d&#8217;&#233;lite se traduit souvent par le terme sniper, nous permet d&#8217;imposer &#224;
notre d&#233;codeur ayant &#224; traduire une phrase contenant le terme fran&#231;ais, de trouver une traduction
contenant le terme sniper. Seule la position de ce dernier terme est &#224; d&#233;terminer par notre
d&#233;codeur.
</p>
<p>Dans notre impl&#233;mentation, nous avons l&#233;g&#232;rement modifi&#233; l&#8217;algorithme d&#233;crit dans la figure 1
afin, 1) d&#8217;interdire &#224; tout mot anglais non valid&#233; par le lexique terminologique d&#8217;&#234;tre associ&#233; &#224;
un mot source appartenant &#224; une unit&#233; terminologique source, et 2) d&#8217;ajouter &#224; toute position
cible une hypoth&#232;se liant le terme source &#224; l&#8217;une de ses traductions telles qu&#8217;identifi&#233;es dans le
lexique. La survie de ces hypoth&#232;ses d&#233;pend des contraintes globales impos&#233;es par l&#8217;op&#233;ration
de maximisation (de l&#8217;&#233;quation 1) sur laquelle repose la recherche.
Le score associ&#233; &#224; une unit&#233; terminologique cible ei&#8242;i lorsque li&#233;e &#224; sa contrepartie source f
</p>
<p>j&#8242;
j est
</p>
<p>donn&#233;e par l&#8217;&#233;quation 3 o&#249; k d&#233;signe un indice cible et a(.) le mod&#232;le d&#8217;alignement intervenant
5Voir http://www.termium.com pour plus d&#8217;information.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Langlais
</p>
<p>dans l&#8217;&#233;quation 2. L&#8217;intuition de cette &#233;quation est que les mod&#232;les consult&#233;s, &#224; savoir le mod&#232;le
trigramme et le mod&#232;le d&#8217;alignement, poss&#232;dent tous les deux une information qui peut aider
&#224; d&#233;cider de l&#8217;ad&#233;quation d&#8217;une extension en position cible i. Le premier mod&#232;le fournit la
probabilit&#233; qu&#8217;un mot donn&#233; (inconnu ou pas6) suive les deux derniers d&#8217;une hypoth&#232;se que
l&#8217;on &#233;tend, tandis que le second mod&#232;le a une id&#233;e (faible) de la position source qui devrait &#234;tre
associ&#233;e &#224; un mot cible donn&#233;. Nous esp&#233;rons qu&#8217;en l&#8217;absence de meilleurs alli&#233;s (un mod&#232;le
cache am&#233;liorerait certainement les choses) ce m&#233;canisme suffise &#224; lui seul &#224; contr&#244;ler la place
finale de l&#8217;unit&#233; terminologique cible dans la traduction.
</p>
<p>&#8721;
</p>
<p>k&#8712;[i,i&#8242;]
log p(ek|ek&#8722;2ek&#8722;1) + max
</p>
<p>l&#8712;[j,j&#8242;]
log(a(k|l, J, I)) (3)
</p>
<p>5 R&#233;sultats
</p>
<p>Nous avons utilis&#233; trois lexiques terminologiques dont les caract&#233;ristiques sont r&#233;sum&#233;es dans
la table 5. Ils diff&#232;rent essentiellement par le nombre d&#8217;entr&#233;es qu&#8217;ils contiennent. Le pre-
mier lexique (sniper-1) contient les 33 entr&#233;es qui ont &#233;t&#233; employ&#233;es dans une &#233;tude sur la
v&#233;rification automatique de la consistance terminologique dans des traductions (Macklovitch,
1995). Le deuxi&#232;me (sniper-2) et troisi&#232;me (sniper-3) lexiques contiennent ces m&#234;mes
entr&#233;es plus d&#8217;autres ajout&#233;es manuellement apr&#232;s inspection incr&#233;mentale de notre corpus de
test SNIPER7.
</p>
<p>Comme le montre la table 5, l&#8217;introduction d&#8217;un lexique terminologique dans le processus de
traduction diminue les taux d&#8217;erreur mesur&#233;s au niveau des phrases et des mots, et ce, m&#234;me
avec des lexiques peu couvrants. Avec le lexique sniper-1 nous observons une r&#233;duction
absolue de 9.6% et une r&#233;duction de 13.8% avec le lexique sniper-3. La table 4 propose
deux exemples de traductions produites avec et sans l&#8217;aide de lexiques sp&#233;cialis&#233;s.
</p>
<p>Il est important de noter, que si les performances sont meilleures, tous les probl&#232;mes ne sont pas
pour autant r&#233;gl&#233;s. Une inspection syst&#233;matique des traductions propos&#233;es par notre engin de
traduction en conjonction avec sniper-3, montre que si la traduction est de meilleure qualit&#233;
que lorsque l&#8217;engin est utilis&#233; sans lexique, il n&#8217;en reste pas moins qu&#8217;elle est moins fid&#232;le au
texte source que ne le sont les traductions obtenues sur le corpus HANSARD: les mots inconnus
sont toujours un obstacle.
</p>
<p>6 Discussion
</p>
<p>Dans cette &#233;tude, nous avons montr&#233; que la traduction de textes hautement sp&#233;cialis&#233;s &#224; l&#8217;aide
d&#8217;un engin de traduction probabiliste g&#233;n&#233;ral est une t&#226;che p&#233;rilleuse. Ceci sugg&#232;re une strat&#233;gie
adaptative. Parmi les sc&#233;narios adaptatifs possibles, nous avons montr&#233; que l&#8217;ouverture du
moteur de traduction &#224; des ressources terminologiques est une approche naturelle et payante
qui permet d&#8217;assouplir le moteur de traduction.
</p>
<p>Ce travail est reli&#233; en partie &#224; une &#233;tude r&#233;cente de (Marcu, 2001), o&#249; l&#8217;auteur s&#8217;est int&#233;ress&#233; &#224;
6Notre mod&#232;le trigramme a &#233;t&#233; entra&#238;n&#233; pour nous fournir des param&#232;tres du type p(UNK|wiwi+1).
7Ce qui correspond &#224; ce que fait le terminologue lorsqu&#8217;il identifie des termes dans le texte &#224; traduire.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ressources terminologiques et traduction probabiliste
</p>
<p>Source le tireur d&#8217; &#233;lite voit simultan&#233;ment les fils crois&#233;s et l&#8217; image ( l&#8217; objectif ) .
Target the sniper sees the crosshairs and the image - target - at the same time .
avec the gunman being same son sit and picture of the hon. members : agreed .
sans the sniper simultaneously see the crosshairs and the image (objective . )
Source contr&#244;le de la d&#233;tente .
Target exercising trigger control .
avec the control of d&#233;tente .
sans control of the trigger .
</p>
<p>Table 4: Deux exemples de traduction avec et sans lexique terminologique. Les termes con-
cern&#233;s par le lexique sont typographi&#233;s en gras.
</p>
<p>lexique nb couverture SER WER
sniper-1 33 20/247 99 67.4
sniper-2 59 47/299 98 66.2
sniper-3 146 132/456 98 64.3
</p>
<p>Table 5: Performances du moteur de traduction avec diff&#233;rents lexiques terminologiques. nb
est le nombre d&#8217;entr&#233;es dans le lexique et couverture indique le nombre d&#8217;unit&#233;s sources dif-
f&#233;rentes de ce lexique qui sont &#233;galement dans le texte source &#224; traduire, ainsi que le nombre
total de leurs occurrences.
</p>
<p>l&#8217;unification des approches de traduction statistique et bas&#233;e sur l&#8217;exemple. Plus pr&#233;cis&#233;ment,
l&#8217;auteur a d&#233;riv&#233; automatiquement du corpus HANSARD ce qu&#8217;il appelle une m&#233;moire de tra-
duction; en fait, une liste de paires de s&#233;quences de mots sources et cibles qui sont en relation de
traduction. Ces paires ont &#233;t&#233; extraites &#224; l&#8217;aide d&#8217;un alignement de viterbi utilisant un mod&#232;le
de traduction de type IBM-4 (Brown et al., 1993) &#233;galement entra&#238;n&#233; sur le corpus HANSARD.
Cette liste (probabilis&#233;e) de s&#233;quences &#233;tait alors ins&#233;r&#233;e &#224; un d&#233;codeur afin d&#8217;am&#233;liorer les
performances globales de traduction.
</p>
<p>Ce que cette &#233;tude sugg&#232;re, c&#8217;est qu&#8217;une liste d&#8217;&#233;quivalents bilingues automatiquement extraite
d&#8217;un corpus utilis&#233; &#233;galement pour l&#8217;entra&#238;nement d&#8217;un mod&#232;le de traduction statistique peut
am&#233;liorer la performance de l&#8217;engin de traduction sous-jacent; r&#233;sultat tr&#232;s int&#233;ressant en soi.
Nous avons men&#233; une &#233;tude semblable dans le contexte diff&#233;rent du projet TRANSTYPE, avec
des r&#233;sultats bien moins concluants (Langlais et al., 2000). Au del&#224; des diff&#233;rences li&#233;es aux
mod&#232;les de traduction employ&#233;s dans ces deux &#233;tudes (nous utilisions seulement un mod&#232;le
2), ainsi qu&#8217;aux diff&#233;rentes m&#233;triques utilis&#233;es, nous pensons que la diff&#233;rence de performance
observ&#233;e dans ces deux &#233;tudes s&#8217;explique par la nature m&#234;me des corpus de tests. Le corpus
utilis&#233; dans (Marcu, 2001) consistait en un ensemble de 500 phrases d&#8217;au plus 10 mots, alors
que le corpus utilis&#233; dans (Langlais et al., 2000) &#233;tait plus larges et plus diversifi&#233;.
L&#8217;&#233;tude que nous avons d&#233;crite ici s&#8217;apparente aux deux &#233;tudes susmentionn&#233;es, &#224; l&#8217;exception du
fait que nous ne nous occupons pas ici de l&#8217;extraction automatique d&#8217;&#233;quivalents bilingues. Ce
choix est motiv&#233; par les deux raisons suivantes: s&#8217;il est possible d&#8217;extraire automatiquement des
unit&#233;s bilingues8, il est cependant difficile de statuer sur la nature terminologique de ces unit&#233;s.
Nous pensons de plus qu&#8217;il est souhaitable que le traducteur soit responsable de la qualit&#233; des
</p>
<p>8Des listes d&#8217;&#233;quivalents automatiquement acquis lors des exp&#233;riences d&#233;crites dans (Langlais et al., 2000) sont
consultables &#224; l&#8217;adresse www.iro.umontreal.ca/&#8764;felipe/ResearchOutput/ANLP2000.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Langlais
</p>
<p>lexiques introduits dans le moteur de traduction, car ils constituent un des rares moyens dont
il dispose pour garder un peu de contr&#244;le sur la sortie automatique produite; un point que les
traducteurs professionnels semblent appr&#233;cier (Langlais et al., 2001).
En guise de remarque finale, nous souhaitons souligner que nous concevons cette &#233;tude comme
un premier pas vers l&#8217;unification entre l&#8217;approche bas&#233;e sur l&#8217;exemple et l&#8217;approche statistique9.
Nous souscrivons donc pleinement &#224; l&#8217;id&#233;e d&#233;velopp&#233;e dans (Marcu, 2001). Bien s&#251;r, la tra-
duction &#224; partir d&#8217;exemples peut fournir bien plus que la simple liste d&#8217;&#233;quivalents utilis&#233;e dans
cette &#233;tude (nous pensons notamment aux patrons traductionnels). La strat&#233;gie que nous en-
trevoyons pour cette unification est cependant identique dans l&#8217;id&#233;e &#224; celle d&#233;crite ici; &#224; savoir
int&#233;grer des contraintes dans le probl&#232;me de recherche de la meilleure traduction. L&#8217;extension
de cette notion de contrainte &#224; des cha&#238;nes de mots qui ne sont pas n&#233;cessairement des s&#233;quences
adjacentes de mots, ni m&#234;me des cha&#238;nes compl&#232;tement instanci&#233;es (patrons &#224; trous) fait partie
des pistes que nous souhaitons &#233;tudier dans le futur.
</p>
<p>R&#233;f&#233;rences
BROWN P. F., PIETRA S. A. D., PIETRA V. J. D. &amp; MERCER R. L. (1993). The mathematics of
statistical machine translation: Parameter estimation. Computational Linguistics, 19(2), 263&#8211;311.
FOSTER G. (2000). A Maximum Entropy / Minimum Divergence translation model. In Proceedings of
the 38th Annual Meeting of the ACL, p. 37&#8211;44, Hong Kong.
LANGLAIS P., FOSTER G. &amp; LAPALME G. (2000). Unit completion for a computer-aided translation
typing system. In Proceedings of the 5th Conference on Applied Natural Language Processing (ANLP),
p. 135&#8211;141, Seattle, Washington.
LANGLAIS P., FOSTER G. &amp; LAPALME G. (2001). Integrating bilingual lexicons in a probabilistic
translation assistant. In Proceedings of the 8th Machine Translation Summit, p. 197&#8211;202, Santiago de
Compostela, Galicia, Spain: IAMT.
MACKLOVITCH E. (1995). Can Terminological Consistency be Validated Automatically ? Rapport
interne, CITI/RALI, Montr&#233;al, Canada.
MARCU D. (2001). Towards a unified approach to memory- and statistical-based machine translation.
In Proceedings of the 39th Annual Meeting of the ACL, p. 378&#8211;385, Toulouse, France.
NIESSEN S., VOGEL S., NEY H. &amp; TILLMANN C. (1998). A dp based search algorithm for statistical
machine translation. In Proceedings of the 36th Annual Meeting of the ACL and the 17th COLING, p.
960&#8211;966, Montr&#233;al, Canada.
OCH F. J. &amp; NEY H. (2000). A comparison of alignement models for statistical machine translation. In
Proceedings of the International Conference on Computational Linguistics (COLING) 2000, p. 1086&#8211;
1090, Saarbrucken, Luxembourg, Nancy.
OCH F. J., UEFFING N. &amp; NEY H. (2001). An efficient a* search algorithm for statistical machine
translation. In Proceedings of the Workshop on Data Driven Machine Translation yielded at the 39th
Annual Meeting of the ACL, p. 55&#8211;62, Toulouse, France.
V&#201;RONIS J. &amp; LANGLAIS P. (2000). Evaluation of parallel text alignment systems: The ARCADE
project, volume 13, chapter 19, p. 369&#8211;388. Parallel Text Processing, Kluwer.
WANG Y.-Y. (1998). Grammar Inference and Statistical Machine Translation. PhD thesis, CMU-LTI,
Carnegie Mellon University.
</p>
<p>9En fait, les deux approches sont bas&#233;es sur l&#8217;exemple mais nous reprenons ici la terminologie anglophone
(EBMT versus SMT).</p>

</div></div>
</body></html>