TALN 2002, Nancy, 24-27 juin 2002

Ressources terminologiques et traduction probabiliste:
premiers pas positifs vers un systeme adaptatif

Philippe Langlais
RALI/DIRO - Université de Montréal
C.P. 6128, succursale Centre-ville
Montréal (Québec)

Canada, H3C 3J7
felipe@iro.umontreal.ca

Mots-clefs — Keywords

Traduction statistique, adapatabilité, terminologie
Statistical machine translation, adaptativity, terminology

Résumé - Abstract

Cette derniere décennie a été le témoin d’importantes avancées dans le domaine de la traduction
statistique (TS). Aucune évaluation ﬁne n’a cependant été proposée pour mesurer l’adéquation
de l’approche statistique dans un contexte applicatif réel.

Dans cette étude, nous étudions le comportement d’un engin de traduction probabiliste lorsqu’il
traduit un texte de nature tres éloignée de celle du corpus utilisé lors de l’entrainement. Nous
quantiﬁons en particulier la baisse de performance du systeme et développons l’idée que l’inté-
gration de ressources terminologiques dans le processus est une solution naturelle et salutaire a
la traduction. Nous décrivons cette intégration et évaluons son potentiel.

The past decade witnessed exciting work in the ﬁeld of Statistical Machine Translation (SMT).
However, accurate evaluation of its potential in a real-life context is still a questionable issue.

In this study, we investigate the behavior of a SMT engine faced with a corpus far different from
the one it has been trained on. We show that terminological databases are obvious ressources
that should be used to boost the performance of a statistical engine. We propose and evaluate a
way of integrating terminology into a SMT engine which yields a signiﬁcant reduction in word
error rate.

Philippe Langlais

1 Introduction

La traduction statistique est devenue populaire au sein de la communaute langagiere suite aux
travaux de (Brown et al., 1993). Depuis, de nombreux chercheurs se sont atteles a la realisation
de meilleurs modeles, et plusieurs approches seduisantes ont ete proposees.

Meme si les etudes sur la traduction statistique incluent habituellement une section d’evaluation
foumie, il reste cependant difﬁcile de savoir ce qu’on est en droit d’attendre des performances
d’un moteur de traduction statistique sur une tache donneel. Nous savons des travaux de (Wang,
1998) que dans une tache de traduction de parole, le moteur de traduction qu’il a developpe se
comparait favorablement a un systeme symbolique developpe par plusieurs de ses collegues. Il
est neanmoins hasardeux de generaliser ce constat a d’autres applications.

Nous ne connaissons pas d’etude systematique tentant d’evaluer l’adequation de la solution
statistique dans des environnements de traduction réels; terme que nous preferons d’ailleurs
laisser sans deﬁnition. I1 nous semble cependant evident qu’un systeme de traduction (statis-
tique ou non) est d’autant plus viable a servir des applications variees qu’il est capable de
s’adapter facilement a des textes d’une nature tres differente de celle des corpus utilises lors
de la Inise au point du systeme. Nous excluons donc de notre champ d’etude des systemes
hautement specialises qui par nature ne servent qu’une application tres ciblee et peu evolutive,
comme par exemple les systemes METEO et ALT/Flashz. Curieusement, nous ne connais-
sons aucune etude sur l’adaptabilite’ des moteurs de traduction statistiques, et ce en depit de
l’abondante litterature decrivant des modeles de langue statistiques et adaptatifs.

Dans ce travail, nous evaluons les performances d’un moteur de traduction statistique lorsqu’il
traduit des textes relevant de domaines tres pointus, c’est a dire, tres differents des corpus util-
ises pour l’entrainement des modeles de langue et de traduction sous-jacents. Nous decrivons
tout d’abord en section 2 notre engin de traduction. Nous quantiﬁons ensuite en section 3 la
baisse de performance d’un engin entraine sur un corpus “general” (le HANSARD) lorsqu’on
s’en sert pour traduire un texte tres speciﬁque (dans cette etude, un manuel Inilitaire pour les
tireurs d’elite). Nous proposons alors en section 4 une methode simple et naturelle d’ameliorer
un systeme de traduction general; a savoir, son ouverture a des ressources terminologiques
disponibles. Nous montrons en section 5 les performances obtenues en implementant notre
approche et discutons en section 6 d’autres travaux auxquels la presente etude est liee.

2 Le moteur statistique

2.1 Les modéles statistiques

Pour ce travail, nous avons realise un engin traduisant du frangais vers l’anglais qui adopte le
paradigme du canal bruite, initialement presente dans le cadre de la traduction dans (Brown
et al., 1993) et qui peut se decrire simplement par l’equation 1, 011 e{ represente la sequence
de mots cibles (ici des mots anglais) a trouver, etant donnee la phrase a traduire (ici des mots
frangais) de J mots ff.

1Le meme constat peut d’ailleurs étre fait a1’egard des systemes non probabilistes.
2] e tiens a remercier mes relecteurs pour leurs commentaires avises.

Ressources terminologiques et traduction probabiliste

ef = argmax P(e{) .P(f{|e{) (1)
Le{ §,_/ 
langage traduction

Pour entrainer les modeles probabilistes sous-jacents, nous avons réuni un bitexte de 1639 250
paires de phrases du HANSARD alignées automatiquement au niveau des phrases. Dans cette
experience, tous les mots ont été convertis en lettres minuscules.

Nous avons utilisé un modele trigramme interpolé entrainé sur la partie anglaise de notre bitexte.
La perplexité du modele résultant est assez basse — 65 — ce qui reﬂete les nombreuses formes
ﬁgées présentes dans le HANSARD (ex: pursuant to standing order / conformément
£1 l’aline’a).

Le modele de traduction inversé (de l’anglais vers le frangais) utilisé ici est similaire au modele
2 décrit dans (Brown et al., 1993). Dix itérations du processus d’estimation des parametres
du modele 1 ont été lancées (réduisant la perplexité de 7 776 a 90), suivies de 10 iterations du
processus d’estimation des parametres du modele 2 (pour une perplexité ﬁnale de 54). Nous
avons également réduit le nombre de parametres du modele de transfert (voir equation 2), en
appliquant un algorithme décrit par (Foster, 2000) qui sélectionne les paires de mots les plus
intéressantes d’un modele3.

Le modele 2 met également en jeu un modele de longueur tel que spéciﬁé dans l’équation 2.
Dans cette étude nous avons fait l’hypothese que la longueur (comptée en mots) d’une phrase
frangaise, traduction d’une phrase anglaise était normalement distribuée.

I

p(fi’|e{) =P(J|I) HZP(i|J',J,I) -P(fj|€z') (2)
J-=1,i=0  ‘—v—’
alignement transfert

2.2 L’algorithme de recherche de la meilleure traduction

Nous avons étendu a un modele trigramme le décodeur proposé par (NieBen et al., 1998). L’idée
de cet algorithme est d’étendre progressivement (c’est a dire mot a mot) les hypotheses de
traductions, tout en couvrant progressivement les positions de la chaine source. Nous invitons
le lecteur a lire la description exacte de la récursion sur laquelle est construite la recherche et
proposons a la place en ﬁgure 1 une vue programmatique du décodeur. Une hypothese dans
cette recherche est completement déterminée par quatre parametres: les positions source et
cible, la couverture source d’une hypothese et la nature du mot cible a la position cible. De ce
fait, l’espace peut-étre codé par une matrice creuse de dimension 4; chaque item dans cet espace
de recherche contenant des informations de chainage arriere (backtracking) ainsi que le score
de l’hypothese associée.

Nous savons que de meilleurs modeles de traduction ont été proposés et systématiquement
comparés entre eux (Och & Ney, 2000). Les performances que nous avons relevées avec notre
décodeur sur notre corpus HANSARD (voir la section 3) sont cependant comparables a (voire
meilleures que) celles publiées ailleurs sur le méme type de corpus. Notre but étant avant tout
de comparer les performances d’un traducteur statistique utilisé dans des conditions amicales

3Nous avons ainsi conservé 1 million de paramétres sur un total initial de 34 969 331 paramétres

Philippe Langlais

ou au contraire adverses, il nous semble donc que le moteur que nous avons utilisé sert tout a
fait notre cause comparative.

Entrée: 

Initialize the search space table Space
Select a maximum target length: I max
Compute the active vocabulary

for all target position i = 1, 2, . . . , Imam do
prune(z' — 1);
for all alive hyp. h = Space(i, j, c, e) do
m; <— History(h);
zones <— FreeSrcPositions(h);
bestWords <— NBestTgtWords(m1);
for all win bestWords do
prob <— Score(h) + log p(w|m1);
setIfBetter(z', j, c, b, prob, 0, j, 11);
for all free source position d do
3 <— prob;
forallf E [1,fma,,] / d+f — 1 is free do
3+ = log a(i|d, J) + 1ogt(fd|e,-);
setIfBetter(i,d,c+ f,w,s,f,j,w);

moms <— -00
for alli E [1, Image] do
for all alive hyp. h = Space(i, j, c, e) do
3 <— Score(h) +p(J|i);
if ((c == J) and (s > maa:s)) then
moms <— s
(mam-,maa:j,maa:e) <— (i,j, e)
if (moms! = oo) then
Return Space(maJ:,-, max]-, J, maxe);
else
Failure

Sortie: e1 . . . e,- . . . em”,

Figure 1: Principe de base de notre décodeur

3 Performances du moteur de traduction

3.1 Corpus de test

Dans cette section nous mesurons l’impact du type de corpus sur la performance de notre sys-
teme. Nous utilisons a cet effet les deux corpus que nous décrivons ci-apres. Le premier cor-
pus (nommément, HANSARD) est une collection de phrases extraites d’une partie du corpus

Ressources terminologiques et traduction probabiliste

HANSARD non utilisée lors de l’entrainement. Nous n’avons utilisé aucune stratégie partic-
uliere pour sélectionner ces phrases de maniere par exemple a ce qu’elles soient proches des
textes d’entrainement.

Le second corpus (dans la suite SNIPER) est un extrait d’un manuel militaire sur l’entrainement
et le déploiement des tireurs d’élite; manuel qui a fait l’objet d’une autre étude (Macklovitch,
1995). Ce corpus releve hautement du domaine militaire et poserait sans aucun doute de nom-
breux probleme a tout moteur (statistique ou non) non adapté a ce type de texte. Les caracté1is-
tiques principales de nos deux corpus sont regroupées dans la table 1.

corpus nb | long. | SER WER
HANSARD 1038 (16.2, 7.8) 95.6 59.6
SNIPER 203 (20.8, 6.8) 100 74.6

Table 1: Caractéristiques principales de nos corpus de test et performance de notre moteur de
traduction (voir la section suivante pour une description des taux SER et WER). |long.| indique
la longueur moyenne (comptée en mots) des phrases sources ainsi que l’écart type de cette
distribution; nb est le nombre de phrases dans le corpus.

3.2 Performances du systéme

Dans cette étude, nous évaluons la performance de notre moteur de traduction en terme de
taux d’erreur mesurés au niveau de la phrase (SER) et des mots (WER). Ces deux taux sont
mesurés en reference a un oracle disponible du fait que les deux corpus ont été publiés dans les
deux langues. Le premier taux mesure le pourcentage de phrases pour lesquelles la traduction
n’était pas exactement celle de l’oracle, alors que le second taux est calculé par une distance de
Levenstein qui comptabilise le nombre minimal d’opérations qu’il faut effectuer pour passer de
la traduction produite a la traduction oracle. Les trois opérations considérées ici sont l’ insertion,
la suppression et la substitution qui recoivent toutes le méme poids.

Nous sommes conscients que ces mesures a elles seules ne sont pas garantes d’une évaluation
de qualité, mais nous étions hésitant a recourir dans cette étude a des évaluations humaines,
en suivant par exemple le protocole décrit dans (Wang, 1998). En fait, un regard rapide sur la
dégradation des performances mesurée sur le corpus SNIPER est tellement criante (voir la table
1), qu’il nous a semblé inutile de passer par des évaluations humaines pour la mettre en relief.

D’apres la table 1, nous observons que les taux d’erreur au niveau des mots sur HANSARD
sont de l’ordre de 60% alors qu’il est de 74% sur le corpus SNIPER. Il est intéressant de noter
qu’aucune traduction sur ce demier corpus n’a été identique a la traduction de l’oracle.

Bien qu’indiquant clairement une dégradation, il est difﬁcile d’apprécier ce que ces taux d’ erreur
signiﬁent véritablement. La table 2 nous aide a mieux comprendre les valeurs prises par le WER
4. Il convient de noter que les taux observés sur le corpus hansard sont légerement inférieurs a
ceux rapportés récemment par (Och et al., 2001) sur un corpus de méme type. Lors d’une étude
comparative de différents systemes de décodage, les auteurs ont observé un taux de WER de
l’ordre de 69% sur un corpus de 250 phrases (d’au plus 14 mots) extraites du corpus HANSARD.

4Les séances de traduction au complet sont disponibles a l’adresse:
www . iro . umont real . ca/~felipe/Researchoutput /TALN2 0 02

Philippe Langlais

SRC cependant , il y a ici deux problemes qui apparaissent .
REF however , there are two problems here .
CAN however , there are two problems emerging here . 11%

SRC les limites des circonscriptions électorales
REF electoral boundaries
CAN the electoral boundaries 33%

SRC nous sommes ﬁers de ces habitants de london et d’ autres canadiens qui con-
sacrent leur temps et leur énergie a batir un monde meilleur .

REF we are proud of these londoners and of other canadians who devote their time
and energies to improving our world .

CAN we are proud of these people of london and other people spend their time and 50%
energy to build a better world

SRC le mois de la nutrition
REF nutrition month
CAN in the month of nutrition 80 %

SRC quelle plus belle image peut on donner du canada ?
REF this is canada at its best .
CAN what more can be nice to canada ? 100%

Table 2: Exemples de traductions extraites du corpus HANSARD a différents niveaux de WER.

3.3 Analyse de la baisse de performance

Deux raisons majeures expliquent les pietres performances observées sur le corpus SNIPER:
la présence de mots hors vocabulaire et la traduction erronée des nombreuses unités termi-
nologiques présentes dans le corpus.

Sur le corpus SNIPER, 3.5% des mots sources (formes) et 6.5% des mots cibles sont en effet
inconnus des modeles statistiques. 44% des phrases sources et 77% des phrases cibles contien-
nent au moins un mot inconnu. Sur le corpus HANSARD, le taux de mots inconnus est beaucoup
plus faible: environ 0.5% des mots sources et cibles sont inconnus et seulement 5% des phrases
sources contiennent au moins un mot inconnu.

De maniere prévisible, la présence massive de mots inconnus a un impact direct sur les perfor-
mances et en particulier, sur la couverture du vocabulaire actif a partir duquel les traductions
sont constr11ites. Sur le corpus SNIPER, on mesure une couverture du vocabulaire de la traduc-
tion oracle de l’ordre de 72% (0.5% des phrases cibles oracles sont totalement couvertes), tandis
que cette couverture s’éleve a 86% sur le corpus HANSARD (24% des traductions de l’oracle
sont completement couvertes).

Il est en revanche beaucoup plus difﬁcile de quantiﬁer l’impact de la présence d’une terminolo-
gie spéciﬁque sur la qualité de la traduction. Cela demanderait pour le moins d’identiﬁer tous
les termes et leur traduction. Une évaluation indirecte de cet impact est cependant foumie dans
la section 5 ou nous montrons que l’introduction d’entrées terminologiques améliore de maniere
signiﬁcative les performances du systeme. La table 3 montre quelques exemples de mauvaise
traduction impliquant des termes spéciﬁques au corpus SNIPER.

Ressources terminologiques et traduction probabiliste

terme source traduction oracle traduction automatique
ame bore heart

huile polyvalente general purpose oil oil polyvalente
chambre chamber house of common
tireur d’ elite sniper issuer of elite

la longueur de la crosse butt length the length of the crosse

Table 3: Exemples de traduction erronee pour quelques termes du corpus SNIPER.

4 Integration de ressources terminologiques non probabilistes

Plusieurs strategies sont envisageables pour tenter d’ameliorer la situation. En tout premier lieu,
il est possible que nous ayons a disposition des corpus speciﬁques d’un domaine particulier
en taille sufﬁsante pour que l’on puisse entrainer un modele speciﬁque que l’on peut ensuite
combiner avec le modele “general”.

Nous pourrions de maniere plus realiste tenter de developper un modele de traduction adap-
tatif. Un modele cache pourrait par exemple étre utilise en combinaison avec notre modele
trigramme statique en ce qui conceme la composante langagiere de notre moteur. La realisa-
tion d’une composante traductionnelle adaptative est cependant une entreprise beaucoup plus
speculative qui necessiterait entre autre une localisation assez precise des erreurs produites dans
des traductions anterieures. Nous savons, suite aux travaux realises au sein du groupe de travail
ARCADE (Veronis & Langlais, 2000), que l’alignement ﬁn de mots est une tache difﬁcile.

Une troisieme option s’offre a nous: tirer proﬁt de ressources terminologiques existantes, comme
par exemple Termium5. En fait, une des premieres taches du traducteur est souvent celle de la
recherche terminologique; etape souvent prise en charge dans les organismes de traduction par
des traducteurs terminologues (Langlais et al., 2001). I1 semble donc naturel d’un point de vue
utilisateur d’ouvrir un systeme de traduction a des ressources terminologiques existantes (ou
lexiques terminologiques dans la suite).

Parce qu’il est peu vraisemblable que ces ressources terminologiques soient livrees avec des
probabilites de traduction, nous preferons voir un lexique terminologique comme un faisceau
de contraintes qui permet de reduire l’espace de recherche de notre moteur. Savoir par exemple
que le terme tireur d ’e’lite se traduit souvent par le terme sniper, nous permet d’imposer a
notre decodeur ayant a traduire une phrase contenant le terme francais, de trouver une traduction
contenant le terme sniper. Seule la position de ce dernier terme est a determiner par notre
decodeur.

Dans notre implementation, nous avons legerement modiﬁe l’algorithme decrit dans la ﬁgure 1
aﬁn, 1) d’interdire a tout mot anglais non valide par le lexique terminologique d’etre associe a
un mot source appartenant a une unite terminologique source, et 2) d’ajouter a toute position
cible une hypothese liant le terme source a l’une de ses traductions telles qu’identiﬁees dans le
lexique. La survie de ces hypotheses depend des contraintes globales imposees par l’operation
de maximisation (de l’equation 1) sur laquelle repose la recherche.

. ‘I
Le score associe a une unite terIn1nolog1que cible ef lorsque l1ee a sa contrepartie source fa? est
donnee par l’equation 3 ou k designe un indice cible et a(.) le modele d’alignement intervenant

5Voir http : / /www . termium . com pour plus d’information.

Philippe Langlais

dans l’équation 2. L’ intuition de cette équation est que les modeles consultés, a savoir le modele
trigramme et le modele d’a1ignement, possedent tous les deux une information qui peut aider
a décider de l’adéquation d’une extension en position cible 1'. Le premier modele fournit la
probabilité qu’un mot donné (inconnu ou pas6) suive les deux derniers d’une hypothese que
l’on étend, tandis que le second modele a une idée (faible) de la position source qui devrait étre
associée a un mot cible donné. Nous espérons qu’en l’absence de meilleurs alliés (un modele
cache améliorerait certainement les choses) ce mécanisme sufﬁse a lui seul a controler la place
ﬁnale de l’unitéterIr1inologique cible dans la traduction.

Z 10gp(ek|ek_2ek_1) + lxerbaicq 10g(a(k|l, J, I )) (3)

kE[i,i’]

5 Résultats

Nous avons utilisé trois lexiques terminologiques dont les caractéristiques sont résumées dans
la table 5. Ils different essentiellement par le nombre d’entrées qu’ils contiennent. Le pre-
mier lexique (snipe r—l) contient les 33 entrées qui ont été employées dans une étude sur la
vériﬁcation automatique de la consistance terminologique dans des traductions (Macklovitch,
1995). Le deuxieme (sniper—2) et troisieme (snipe r—3) lexiques contiennent ces memes
entrées plus d’autres ajoutées manuellement apres inspection incrémentale de notre corpus de
test SNIPER7.

Comme le montre la table 5, l’introduction d’un lexique terminologique dans le processus de
traduction diminue les taux d’erreur mesurés au niveau des phrases et des mots, et ce, méme
avec des lexiques peu couvrants. Avec le lexique snipe r—l nous observons une réduction
absolue de 9.6% et une réduction de 13.8% avec le lexique snipe r—3. La table 4 propose
deux exemples de traductions produites avec et sans l’aide de lexiques spécialisés.

Il est important de noter, que si les performances sont meilleures, tous les problemes ne sont pas
pour autant réglés. Une inspection systématique des traductions proposées par notre engin de
traduction en conjonction avec snipe r—3, montre que si la traduction est de meilleure qualité
que lorsque l’engin est utilisé sans lexique, il n’en reste pas moins qu’elle est moins ﬁdele au
texte source que ne le sont les traductions obtenues sur le corpus HANSARD: les mots inconnus
sont toujours un obstacle.

6 Discussion

Dans cette étude, nous avons montré que la traduction de textes hautement spécialisés a l’aide
d’un engin de traduction probabiliste général est une tache périlleuse. Ceci suggere une stratégie
adaptative. Parmi les scénarios adaptatifs possibles, nous avons montré que l’ouverture du
moteur de traduction a des ressources terminologiques est une approche naturelle et payante
qui permet d’assouplir le moteur de traduction.

Ce travail est relié en partie a une étude récente de (Marcu, 2001), ou l’auteur s’est intéressé a

5Notre modéle trigramme a été entrainé pour nous fournir des paramétres du type p(UNK|w,-w,-+1).
7Ce qui correspond :21 ce que fait le tenninologue lorsqu’il identiﬁe des termes dans le texte a traduire.

Ressources terminologiques et traduction probabiliste

Source le tireur d’ élite voit simultanément les ﬁls croisés et 1’ image ( 1’ objectif) .
Target the sniper sees the crosshairs and the image - target - at the same time .
avec the gunman being same son sit and picture of the hon. members .' agreed .
sans the sniper simultaneously see the crosshairs and the image (objective . )
Source controle de la détente .

Target exercising trigger control .

avec the control of détente .

sans control of the trigger .

Table 4: Deux exemples de traduction avec et sans lexique terminologique. Les termes con-
cemés par le lexique sont typographiés en gras.

lexique nb couverture SER WER
sniper—l 33 20/247 99 67.4
snipe r—2 59 47/299 98 66.2

sniper—3 146 132/456 98 64.3

Table 5: Performances du moteur de traduction avec différents lexiques terminologiques. nb
est le nombre d’entrées dans le lexique et couverture indique le nombre d’unités sources dif-
férentes de ce lexique qui sont également dans le texte source a traduire, ainsi que le nombre
total de leurs occurrences.

l’uniﬁcation des approches de traduction statistique et basée sur l’exemple. Plus précisément,
l’auteur a dérivé automatiquement du corpus HANSARD ce qu’il appelle une mémoire de tra-
duction; en fait, une liste de paires de séquences de mots sources et cibles qui sont en relation de
traduction. Ces paires ont été extraites a l’aide d’un alignement de viterbi utilisant un modele
de traduction de type IBM-4 (Brown et al., 1993) également entrainé sur le corpus HANSARD.
Cette liste (probabilisée) de séquences était alors insérée a un décodeur aﬁn d’amé1iorer les
performances globales de traduction.

Ce que cette étude suggere, c’est qu’une liste d’équivalents bilingues automatiquement extraite
d’un corpus utilisé également pour l’entrainement d’un modele de traduction statistique peut
améliorer la performance de l’engin de traduction sous-jacent; résultat tres intéressant en soi.
Nous avons mené une étude semblable dans le contexte différent du projet TRANSTYPE, avec
des résultats bien moins concluants (Langlais et al., 2000). Au dela des differences liées aux
modeles de traduction employés dans ces deux études (nous utilisions seulement un modele
2), ainsi qu’aux différentes métriques utilisées, nous pensons que la différence de performance
observée dans ces deux études s’explique par la nature meme des corpus de tests. Le corpus
utilisé dans (Marcu, 2001) consistait en un ensemble de 500 phrases d’au plus 10 mots, alors
que le corpus utilisé dans (Langlais et al., 2000) était plus larges et plus diversiﬁé.

L’ étude que nous avons décrite ici s’apparente aux deux études susmentionnées, a l’exception du
fait que nous ne nous occupons pas ici de l’extraction automatique d’équivalents bilingues. Ce
choix est motivé par les deux raisons suivantes: s’il est possible d’extraire automatiquement des
unités bilinguesg, il est cependant difﬁcile de statuer sur la nature terminologique de ces unités.
Nous pensons de plus qu’il est souhaitable que le traducteur soit responsable de la qualité des

8Des listes d’équivalents automatiquement acquis lors des expériences décrites dans (Langlais et al., 2000) sont
consultables a 1’adresse www . iro . umont real . ca/~felipe/Researchoutput /ANLP2 O O O.

Philippe Langlais

lexiques introduits dans le moteur de traduction, car ils constituent un des rares moyens dont
il dispose pour garder un peu de controle sur la sortie automatique produite; un point que les
traducteurs professionnels semblent apprécier (Langlais et al., 2001).

En guise de remarque ﬁnale, nous souhaitons souligner que nous concevons cette étude comme
un premier pas vers l’uniﬁcation entre l’approche basée sur l’exemple et l’approche statistique9.
Nous souscrivons donc pleinement a l’idée développée dans (Marcu, 2001). Bien sur, la tra-
duction a partir d’exemples peut fournir bien plus que la simple liste d’équivalents utilisée dans
cette étude (nous pensons notamment aux patrons traductionnels). La stratégie que nous en-
trevoyons pour cette uniﬁcation est cependant identique dans l’idée a celle décrite ici; a savoir
intégrer des contraintes dans le probleme de recherche de la meilleure traduction. L’ extension
de cette notion de contrainte a des chaines de mots qui ne sont pas nécessairement des séquences
adjacentes de mots, ni meme des chaines completement instanciées (patrons a trous) fait partie
des pistes que nous souhaitons étudier dans le futur.

Références

BROWN P. F., PIETRA S. A. D., PIETRA V. J. D. & MERCER R. L. (1993). The mathematics of
statistical machine translation: Parameter estimation. Computational Linguistics, 19(2), 263-311.

FOSTER G. (2000). A Maximum Entropy / Minimum Divergence translation model. In Proceedings of
the 38th Annual Meeting of the ACL, p. 37-44, Hong Kong.

LANGLAIS P., FOSTER G. & LAPALME G. (2000). Unit completion for a computer-aided translation
typing system. In Proceedings of the 5th Conference on Applied Natural Language Processing (ANLP),
p. 135-141, Seattle, Washington.

LANGLAIS P., FOSTER G. & LAPALME G. (2001). Integrating bilingual lexicons in a probabilistic
translation assistant. In Proceedings of the 8th Machine Translation Summit, p. 197-202, Santiago de
Compostela, Galicia, Spain: IAMT.

MACKLOVITCH E. (1995). Can Terminological Consistency be Validated Automatically ? Rapport
interne, CITI/RALI, Montréal, Canada.

MARCU D. (2001). Towards a uniﬁed approach to memory- and statistical-based machine translation.
In Proceedings of the 39th Annual Meeting of the ACL, p. 378-385, Toulouse, France.

NIESSEN S., VOGEL S., NEY H. & TILLMANN C. (1998). A dp based search algorithm for statistical
machine translation. In Proceedings of the 36th Annual Meeting of the ACL and the 17th COLING, p.
960-966, Montréal, Canada.

OCH F. J . & NEY H. (2000). A comparison of alignement models for statistical machine translation. In
Proceedings of the International Conference on Computational Linguistics (COLING) 2000, p. 1086-
1090, Saarbrucken, Luxembourg, Nancy.

OCH F. J ., UEFFING N. & NEY H. (2001). An efﬁcient a* search algorithm for statistical machine
translation. In Proceedings of the Workshop on Data Driven Machine Translation yielded at the 39th
Annual Meeting of the ACL, p. 55-62, Toulouse, France.

VERONIS J . & LANGLAIS P. (2000). Evaluation of parallel text alignment systems: The ARCADE
project, Volume 13, chapter 19, p. 369-388. Parallel Text Processing, Kluwer.

WANG Y.-Y. (1998). Grammar Inference and Statistical Machine Translation. PhD thesis, CMU-LTI,
Carnegie Mellon University.

9En fait, les deux approches sont basées sur l’exemple mais nous reprenons ici la tenninologie anglophone
(EBMT Versus SMT).

