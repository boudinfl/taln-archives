<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>UPERY : un outil d'analyse distributionnelle &#233;tendue pour la construction d&#8217;ontologies &#224; partir de corpus</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2002, Nancy, 24-27 juin 2002 
</p>
<p>UPERY : un outil d'analyse distributionnelle &#233;tendue 
pour la construction d&#8217;ontologies &#224; partir de corpus 
</p>
<p>Didier Bourigault 
</p>
<p> 
Equipe de Recherche en Syntaxe et S&#233;mantique 
</p>
<p>CNRS &#8211; Universit&#233; Toulouse le Mirail 
Maison de la Recherche 
</p>
<p>5, all&#233;es Antonio Machado 
31058 Toulouse Cedex 1 
</p>
<p>didier.bourigault@univ-tlse2.fr 
</p>
<p>R&#233;sum&#233; &#8211; Abstract 
</p>
<p>Nous pr&#233;sentons un module mettant en oeuvre une m&#233;thode d'analyse distributionnelle dite 
&quot;&#233;tendue&quot;. L'analyseur syntaxique de corpus SYNTEX  effectue l'analyse en d&#233;pendance de 
chacune des phrases du corpus, puis construit un r&#233;seau de mots et syntagmes, dans lequel 
chaque syntagme est reli&#233; &#224; sa t&#234;te et &#224; ses expansions. A partir de ce r&#233;seau, le module 
d'analyse distributionnelle UPERY construit pour chaque terme du r&#233;seau l'ensemble de ses 
contextes syntaxiques. Les termes et les contextes syntaxiques peuvent &#234;tre simples ou 
complexes. Le module rapproche ensuite les termes, ainsi que les contextes syntaxiques, sur 
la base de mesures de proximit&#233; distributionnelle. L'ensemble de ces r&#233;sultats est utilis&#233; 
comme aide &#224; la construction d'ontologie &#224; partir de corpus sp&#233;cialis&#233;s. 
</p>
<p>We present a software that implements a method of &quot;extended&quot; distributional analysis. The 
corpus syntactic analyser SYNTEX yields a dependency syntactic analyse of each sentence of 
the corpus. It  builds a network of words and phrases in which each phrase is connected to its 
head and its expansion. The distributional analysis module UPERY relies on this network to 
associate to each term in the network a set of syntactic contexts. Syntactic contexts as well as 
terms may be simple or complex. The UPERY module calculates distributional proximities 
between terms as well as between contexts. The results are used for the building of 
ontological resources from specialized corpora. 
</p>
<p>Keywords &#8211; Mots Cl&#233;s 
</p>
<p>analyse syntaxique automatique, analyse distributionnelle, corpus, ontologie, terminologie. 
parsing, distributional analysis, corpus, ontology, terminology 
</p>
<p>75 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault 
</p>
<p>1 Analyse distributionnelle et construction d&#8217;ontologies 
</p>
<p>L&#8217;analyse distributionnelle &#171; &#224; la Harris &#187; (Harris 1968) est une technique bien connue dans le 
milieu du Traitement Automatique des Langues. Dans la communaut&#233; fran&#231;aise d&#8217;Ing&#233;nierie 
des Connaissances, cette technique est exploit&#233;e depuis une dizaine d&#8217;ann&#233;e pour des 
applications de construction de ressources terminologiques ou d&#8217;ontologies &#224; partir de textes 
(Assadi, Bourigault 1995) (Habert, Nazarenko 1996) (Faure, N&#233;dellec 1998). Les 
rapprochements de mots effectu&#233;s sur la base de contextes syntaxiques partag&#233;s s&#8217;av&#232;rent &#234;tre 
des amorces le plus souvent tr&#232;s utiles pour l&#8217;analyste charg&#233; de construire un mod&#232;le de 
connaissances &#224; partir d&#8217;un corpus sp&#233;cialis&#233;. 
</p>
<p> Le travail pr&#233;sent&#233; dans ce papier constitue la suite des &#233;tudes entam&#233;es avec H. Assadi sur 
l&#8217;utilisation en acquisition de connaissances &#224; partir de textes de l&#8217;outil d&#8217;extraction de termes 
LEXTER (Bourigault 1994) et de proc&#233;dures d&#8217;analyse distributionnelle exploitant les r&#233;sultats 
de cet analyseur (Assadi, Bourigault 1998) (Bourigault, Assadi 2000). Ces &#233;tudes ont montr&#233; 
&#224; la fois l&#8217;int&#233;r&#234;t de l&#8217;analyse distributionnelle pour la construction de ressources 
terminologiques &#224; partir de textes, et aussi la n&#233;cessit&#233; d&#8217;utiliser, en amont, des outils 
d&#8217;analyse syntaxique large, qui prennent en compte en particulier les relations de d&#233;pendance 
syntaxique autour des verbes. Nous pr&#233;sentons dans cet article, une m&#233;thode et un outil 
d'analyse distributionnelle &#233;tendue (section 2), qui s'appuie sur le r&#233;seau de d&#233;pendance 
syntaxique construit par l'analyseur syntaxique de corpus SYNTEX. Par rapport aux travaux 
classiques, la m&#233;thode que nous proposons &#233;tend les fonctionnalit&#233;s habituelles en ce qu'elle 
prend en compte des unit&#233;s complexes, &#224; la fois du c&#244;t&#233; des termes class&#233;s que de celui des 
contextes syntaxiques classificateurs. Dans la section 3, nous pr&#233;cisons comment se situe 
notre approche par rapport &#224; l&#8217;&#233;tat de l&#8217;art. 
</p>
<p>2 Analyse distributionnelle &#233;tendue 
</p>
<p>2.1 Analyse syntaxique de corpus et construction d'un r&#233;seau de 
d&#233;pendance syntaxique 
</p>
<p>La m&#233;thode d'analyse distributionnelle que nous pr&#233;sentons dans cette section s'appuie sur les 
r&#233;sultats fournis par l'analyse syntaxique d'un corpus, sous la forme de relations de 
d&#233;pendance entre mots au sein des phrases du corpus.  Dans les exp&#233;riences d&#233;crites ici, nous 
avons utilis&#233; les r&#233;sultats de l'analyseur syntaxique de corpus SYNTEX (Bourigault, Fabre, 
1999). A partir des r&#233;sultats de l'analyse syntaxique des phrases du corpus, un module 
d'extraction de syntagmes (ES) construit un r&#233;seau de mots et syntagmes, calcul&#233; &#224; partir des 
relations de d&#233;pendance identifi&#233;es dans chacune des phrases. Nous d&#233;crivons dans cette 
section comment est construit ce r&#233;seau, qui fournira les donn&#233;es de base &#224; l'analyse 
distributionnelle &#233;tendue. 
</p>
<p>Dans un premier temps, pour chaque phrase, le module ES proc&#232;de &#224; l'identification des 
constituants syntaxiques maximaux (verbaux, nominaux, adjectivaux) que d&#233;termine la 
structuration en relation de d&#233;pendance. Pour chaque mot recteur, il construit un syntagme 
maximal en parcourant toutes les relations de d&#233;pendance syntaxique dont ce mot est la cible 
jusqu'&#224; aboutir &#224; des mots qui soit ne sont pas recteurs, soit sont t&#234;te d'un syntagme maximal 
d&#233;j&#224; construit. La caract&#233;risation de la structure d'un syntagme est la suivante : 
</p>
<p>76 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Upery : un outil d'analyse distributionnelle &#233;tendue &#8230; 
</p>
<p>- une t&#234;te, qui est constitu&#233;e du mot recteur avec sa cat&#233;gorie ; 
</p>
<p>- une liste de couples (relation, expansion), chaque expansion &#233;tant (le lemme d') un 
mot r&#233;gi ou (la forme normalis&#233;e d') un syntagme dont la t&#234;te est un mot r&#233;gi, et la 
relation &#233;tant la relation de d&#233;pendance syntaxique ; 
</p>
<p>- une forme normalis&#233;e, constitu&#233;e &#224; partir du lemme de la t&#234;te et de la s&#233;quence des 
lemmes ou formes normalis&#233;e des expansions1. 
</p>
<p>Dans un second temps, le module ES construit le r&#233;seau de d&#233;pendance en ajoutant pour 
chaque syntagme maximal diff&#233;rent rencontr&#233; : (1) un n&#339;ud dont le label est la forme 
normalis&#233;e du syntagme, (2) des liens vers les n&#339;uds correspondant &#224; ses expansions, 
&#233;tiquet&#233;s par le nom de la relation de d&#233;pendance. 
</p>
<p>Le r&#233;seau est ensuite enrichi suite &#224; des op&#233;rations de r&#233;duction et de simplification sur les 
syntagmes maximaux (des exemples illustratifs seront donn&#233;s dans le tableau 1 de la section 
suivante). 
</p>
<p>- L'op&#233;ration de r&#233;duction op&#232;re sur des syntagmes qui ont au moins deux 
expansions. Elle consiste &#224; g&#233;n&#233;rer, &#224; partir d'un syntagme donn&#233;,  autant de 
syntagmes r&#233;duits qu'il y a d'expansion : chaque syntagme r&#233;duit est constitu&#233; de la 
t&#234;te du syntagme maximal, et d'une seule expansion, un couple (relation, 
expansion) extrait de la liste des expansions du syntagme maximal. La r&#233;duction est 
totale dans le sens o&#249; l'on extrait des syntagmes r&#233;duits &#224; une seule expansion2. 
</p>
<p>- L'op&#233;ration de simplification op&#232;re sur des syntagmes, maximaux ou r&#233;duits, dont 
au moins une expansion est un syntagme. Elle consiste &#224; g&#233;n&#233;rer, &#224; partir d'un 
syntagme donn&#233;, des syntagmes dans lesquels les expansions syntagmes ont &#233;t&#233; 
remplac&#233;es par leur t&#234;te. La simplification est totale dans le sens o&#249; l'on r&#233;duit 
chaque expansion syntagme &#224; sa t&#234;te3. 
</p>
<p>Ces op&#233;rations de r&#233;duction et de simplification visent d'une part &#224; &#233;tablir des liens directs 
dans le r&#233;seau entre des syntagmes correspondant &#224; des variations syntaxiques par expansion 
ou par insertion, et d'autre part &#224; multiplier, de fa&#231;on contr&#244;l&#233;e, le nombre de contextes 
syntaxiques qui vont &#234;tre exploit&#233;s par l'analyse distributionnelle. L'op&#233;ration de 
simplification s'apparente &#224; celle effectu&#233;e par Habert et Fabre [1999] dans l'outil d'analyse 
distributionnelle ZELLIG pour obtenir des contextes &#233;l&#233;mentaires. 
</p>
<p>                                                 
1 Notons que c'est &#224; ce niveau que nous avons choisi d'op&#233;rer la normalisation actif/passif. 
</p>
<p>2 Nous travaillons &#224; d&#233;finir une op&#233;ration de r&#233;duction plus compl&#232;te, telle que, par exemple, pour un syntagme 
&#224; trois expansions, on extraie des syntagmes partiellement r&#233;duits &#224; deux expansions. 
</p>
<p>3 Nous travaillons &#224; d&#233;finir une op&#233;ration de simplification plus compl&#232;te, de telle sorte que, par exemple, l'on 
remplace un syntagme expansion ayant lui-m&#234;me deux expansions pas uniquement par sa t&#234;te, mais aussi par 
ses syntagmes r&#233;duits. 
</p>
<p>77 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault 
</p>
<p>2.2 Les donn&#233;es de l'analyse distributionnelle : des contextes syntaxiques 
complexes et des termes complexes 
</p>
<p>Le module d'analyse distributionnelle UPERY exploite l'ensemble des donn&#233;es pr&#233;sentes dans 
le r&#233;seau pour effectuer un calcul des proximit&#233;s distributionnelles entre les mots et 
syntagmes du r&#233;seau. Ce calcul s'effectue sur la base des contextes syntaxiques partag&#233;s. Il 
s'agit d'une mise en &#339;uvre du principe de l'analyse distributionnelle &quot;&#224; la Harris&quot;. Les donn&#233;es 
de l'analyse sont constitu&#233;es ainsi :  
</p>
<p>(1) pour chaque syntagme du r&#233;seau ayant une seule expansion, le module construit une 
information &#233;l&#233;mentaire pour le calcul distributionnel. Celle-ci se formalise sous la forme d'un 
couple (contexte, terme) : 
</p>
<p>- le contexte est le couple constitu&#233; de la t&#234;te et de la relation de d&#233;pendance ; Il 
s'agit d'un contexte simple. 
</p>
<p>- le terme est l'expansion. 
</p>
<p>(2) pour chaque syntagme du r&#233;seau ayant plus d'une expansion (N expansions, N sup&#233;rieur 
ou &#233;gal &#224; 2), le module construit N(N-1) informations &#233;l&#233;mentaires pour le calcul 
distributionnel. Pour chaque expansion E, il construit N-1 couples (contexte, terme), un pour 
chacune des autres expansions E' : 
</p>
<p>- le contexte est le couple constitu&#233; du syntagme r&#233;duit construit avec la t&#234;te et 
l'expansion E, et de la relation de d&#233;pendance R' correspondant &#224; l'expansion E'; il 
s'agit d'un contexte complexe. 
</p>
<p>- le terme est l'expansion E'. 
</p>
<p>Nous sommes en mesure maintenant de d&#233;rouler un exemple complet, pour illustrer en quoi 
on peut parler d&#8217;analyse distributionnelle &#171; &#233;tendue &#187;. Les donn&#233;es extraites pour l&#8217;analyse 
distributionnelle &#224; partir de l&#8217;analyse syntaxique de la phrase &#171; Les roches cristallines 
r&#233;sistent &#224; l&#8217;&#233;rosion &#187;, sont pr&#233;sent&#233;es dans le tableau 1. Le syntagme roche cristalline 
appara&#238;t dans le contexte simple &#171; sujet de r&#233;sister &#187; ainsi que dans le contexte complexe 
&#171; sujet de r&#233;sister &#224; &#233;rosion&#187;. De m&#234;me, le mot &#233;rosion appara&#238;t dans le contexte syntaxique 
simple &#171; compl&#233;ment de r&#233;sister &#224; &#187; et dans les contextes complexes &#171; compl&#233;ment de roche 
r&#233;sister &#224; &#187; et &#171; compl&#233;ment de roche cristalline  r&#233;sister &#224; &#187;. 
</p>
<p>Il est donc possible d'avoir des unit&#233;s complexes &#224; la fois du c&#244;t&#233; des contextes syntaxiques 
classificateurs et de celui des termes class&#233;s. A titre d&#8217;illustration, nous donnons quelques 
exemples et des r&#233;sultats num&#233;riques obtenus sur les 4 corpus suivants : le code civil fran&#231;ais 
(CCIV, 145 000 mots), un recueil d&#8217;article scientifiques dans le domaine de l&#8217;ing&#233;nierie des 
connaissances (IC, 200 000 mots), un ouvrage de g&#233;omorphologie (GEOM, 210 000 mots), 
un corpus de compte-rendus d&#8217;hospitalisation dans le domaine de la r&#233;animation chirurgicale 
(REA 178 000 mots). Les r&#233;sultats sont obtenus avec des valeurs de seuils de proximit&#233; 
donn&#233;s dans la section suivante. On constate sur le tableau 2 en particulier que sur les 
difff&#233;rents corpus entre 60 et 100 syntagmes nominaux ont &#233;t&#233; rapproch&#233;s d&#8217;autres noms ou 
syntagmes nominaux par l&#8217;analyse distributionnelle. Le tableau 3 illustre le fait que les types 
de couples de cat&#233;gories rapproch&#233;s par l'analyse distributionnelle se r&#233;partissent de fa&#231;on 
sensiblement diff&#233;rente d'un corpus &#224; l'autre. 
</p>
<p>78 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Upery : un outil d'analyse distributionnelle &#233;tendue &#8230; 
</p>
<p>Terme Contexte 
</p>
<p>cristalline roche_ADJ 
</p>
<p>roche r&#233;sister_SUJ 
</p>
<p>roche r&#233;sister_&#224;_&#233;rosion_SUJ 
</p>
<p>roche cristalline r&#233;sister_SUJ 
</p>
<p>roche cristalline r&#233;sister_&#224;_&#233;rosion_SUJ 
</p>
<p>&#233;rosion r&#233;sister_&#224; 
</p>
<p>&#233;rosion r&#233;sister_SUJ_roche_&#224; 
</p>
<p>&#233;rosion r&#233;sister_SUJ_roche cristalline_&#224; 
</p>
<p>Tableau 1 : Donn&#233;es extraites pour l&#8217;analyse distributionnelle &#233;tendue &#224; partir de 
l&#8217;analyse syntaxique de la phrase &#171; Les roches cristallines r&#233;sistent &#224; l&#8217;&#233;rosion &#187;. 
</p>
<p> 
</p>
<p> CCIV IC GEOM REA 
</p>
<p>Adj 82 955 9 % 176 1482 12 % 271 2140 13 % 264 2004 13% 
</p>
<p>Adv 16 470 3 % 29 622 5 % 31 701 4 % 10 181 6 % 
</p>
<p>Nom 267 2220 12 % 356 2923 12 % 287 4264 7 % 301 5737 5 % 
</p>
<p>SN 60 10343 0,5 % 97 22764 0,5 % 44 24198 0,2 % 100 21236 0,5 %
</p>
<p>Tableau 2 : Nombre de mots ou syntagmes rapproch&#233;s par l&#8217;analyse 
distributionnelle, par cat&#233;gorie. Pour chaque corpus, dans la premi&#232;re colonne 
figure le nombre de mots de la cat&#233;gorie qui ont au moins un voisin, dans la 
deuxi&#232;me le nombre total de mots de la cat&#233;gorie, et dans la troisi&#232;me le 
pourcentage correspondant 
</p>
<p> 
</p>
<p>  CCIV IC GEOM REA 
</p>
<p>Nom Nom 690 38,94% 1346 56,39% 524 36,16% 690 38,94% 
</p>
<p>Nom SNom 125 7,05% 222 9,30% 46 3,17% 125 7,05% 
</p>
<p>SNom SNom 72 4,06% 16 0;67 4 0,28% 72 4,06% 
</p>
<p>Tableau 3 : Types de couples de cat&#233;gories (nominales) rapproch&#233;s par l'analyse 
distributionnelle 
</p>
<p>79 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault 
</p>
<p>2.3 Trois mesures de proximit&#233; 
</p>
<p>L'analyse distributionnelle rapproche d&#8217;abord deux &#224; deux des termes qui partagent les m&#234;mes 
contextes. L'analyse distributionnelle est sym&#233;trique, en ce sens qu'elle peut rapprocher aussi 
les contextes, en fonction des termes qu'ils partagent. Nous travaillons actuellement sur trois 
mesures qui permettent d'appr&#233;hender la proximit&#233; entre deux unit&#233;s (termes ou contextes). 
Ces mesures ont l'avantage d'&#234;tre simples &#224; appr&#233;hender par l'utilisateur final, et de recouvrir 
des aspects diff&#233;rents et compl&#233;mentaires des conditions dans lesquelles deux unit&#233;s peuvent 
&#234;tre jug&#233;es plus ou moins proches. Notre application cible est l&#8217;aide &#224; la construction de 
ressources terminologiques ou ontologiques &#224; partir de textes. Notre objectif est de fournir &#224; 
l'utilisateur, avec ces quelques mesures de proximit&#233;, diff&#233;rents outils pour l&#8217;aider &#224; trouver 
au plus vite les relations qu&#8217;il jugera les plus int&#233;ressantes.  
</p>
<p>On dispose pour un contexte donn&#233; de l'ensemble des termes (mots ou syntagmes) qui 
apparaissent dans ce contexte, et pour un terme donn&#233; l'ensemble des contextes (simples ou 
complexes) dans lesquels il appara&#238;t. On d&#233;finit la productivit&#233; d'un contexte et la productivit&#233; 
d'un terme ainsi : 
</p>
<p>- la productivit&#233; d'un contexte est &#233;gale au nombre de termes qui apparaissent dans 
ce contexte ; 
</p>
<p>- la productivit&#233; d'un terme est &#233;gale au nombre de contextes dans lesquels ce terme 
appara&#238;t. 
</p>
<p>Les trois mesures de la proximit&#233; sont les suivantes : 
</p>
<p>Le coefficient a. Soient deux termes t1 et t2. Le coefficient a est &#233;gal au nombre de contextes 
syntaxiques partag&#233;s par les deux termes. Cette mesure donne une premi&#232;re indication de la 
proximit&#233; entre deux termes, facile &#224; interpr&#233;ter. Mais l'exp&#233;rience montre que cette mesure 
refl&#232;te de fa&#231;on insatisfaisante la proximit&#233; : il faut tenir compte, d'un c&#244;t&#233;, de la productivit&#233; 
des contextes partag&#233;s (coefficient prox), d'un autre c&#244;t&#233;, du nombre de contextes que chaque 
terme a en propre (coefficients j1 et j2). 
</p>
<p>Le coefficient prox. Avec ce coefficient, nous visons &#224; formaliser le fait si un contexte 
partag&#233; par deux termes est tr&#232;s productif, sa contribution au rapprochement des deux termes 
est a priori plus faible que celle d'un contexte peu productif. Le coefficient prox est calcul&#233; 
ainsi : 
</p>
<p>prox = &#8721;c&#8712;C 1/ prod(c)1/2  
o&#249; C est l'ensemble des contextes partag&#233;s par t1 et t2, et prod(c) la productivit&#233; du 
</p>
<p>contexte c 
</p>
<p>Les coefficients j1 et j2. Pour &#233;valuer la proximit&#233; entre deux unit&#233;s, il est important de tenir 
compte non seulement de ce qu'elles partagent, mais aussi de ce qu'elles ont en propre. Un 
certain nombre de mesures statistiques impl&#233;mentent cette id&#233;e, sous des formes diverses (e.g. 
information mutuelle, Jaccard, Anderberg). Ces mesures pr&#233;sentent presque toujours la 
particularit&#233; de &quot;sym&#233;triser&quot; la relation de proximit&#233;. Cette propri&#233;t&#233;, qui dans beaucoup de 
contextes d'application, constitue un avantage, voire une n&#233;cessit&#233;, nous est apparue 
finalement comme masquant un ph&#233;nom&#232;ne marquant &#224; l'&#339;uvre dans les corpus : la 
dissym&#233;trie de la relation de proximit&#233;. Quand deux termes partagent un certain nombre de 
contextes en commun, il arrive le plus souvent que l'un des deux termes poss&#232;de un nombre 
</p>
<p>80 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Upery : un outil d'analyse distributionnelle &#233;tendue &#8230; 
</p>
<p>&#233;lev&#233; de contextes, tandis que l'autre en poss&#232;de beaucoup moins et en partage l'essentiel avec 
le premier. C'est pourquoi, nous caract&#233;risons la proximit&#233; entre deux termes &#224; l'aide de deux 
indices, simples et eux aussi faciles &#224; interpr&#233;ter : rapport entre le nombre de contextes 
partag&#233;s et le nombre total de contextes 
</p>
<p>j1 = a / prod(t1) 
</p>
<p>j2 = a / prod(t2) 
</p>
<p>Le module d'analyse distributionnelle UPERY calcule pour chaque couple de termes 
l'ensemble de ces coefficients. Dans l'interface, on ne pr&#233;sente &#224; l'utilisateur que les couples 
dont les coefficients d&#233;passent certains seuils. Ces seuils sont d&#233;finis de fa&#231;on empirique et 
varient en fonction d'une part de l'homog&#233;n&#233;it&#233; et de la redondance du corpus et d'autre part 
du contexte dans lequel doivent &#234;tre exploit&#233;s les r&#233;sultats de l'analyse distributionnelle. Pour 
les exemples pr&#233;sent&#233;s dans ce papier, les diff&#233;rents corpus ont &#233;t&#233; trait&#233;s avec les seuils 
suivants :   
</p>
<p>- le nombre de contextes partag&#233;s a doit &#234;tre sup&#233;rieur ou &#233;gal &#224; 3 
</p>
<p>- le coefficient prox doit &#234;tre sup&#233;rieur &#224; 0.75 
</p>
<p>- l'un des deux coefficients j1 ou j2 doit &#234;tre sup&#233;rieur &#224; 0.25 (l'un des deux termes 
doit partager au moins le quart de ses contextes avec l'autre) 
</p>
<p>2.4 Le concept de double clique 
</p>
<p>Le module d'analyse distributionnelle UPERY calcule des proximit&#233;s entre couples de termes 
(et de contextes). Nous n'avons pas encore impl&#233;ment&#233; de calcul automatique de 
regroupement de termes, sous forme d'arbre de classification hi&#233;rarchique ascendante [Assadi 
1998] ou de cliques et composantes connexes [Nazarenko &amp; al. 2000]. A l'instar de [Faure 
2000], nous laissons &#224; l'utilisateur le soin de rep&#233;rer et de valider des regroupements qu'il juge 
pertinents, gr&#226;ce &#224; une interface sp&#233;cialement con&#231;ue pour cette t&#226;che. Celle-ci guide 
l'utilisateur vers les regroupements a priori pertinents en lui permettant d'acc&#233;der rapidement 
&#224; des structures que nous nommons doubles cliques : un double clique est constitu&#233;e d'un 
ensemble de termes et d'un ensemble de contextes, tels que chacun des termes appara&#238;t dans 
chacun des contextes. Il s'agit d'une clique de termes, car chaque terme est reli&#233; &#224; chacun des 
autres termes par une relation de proximit&#233; &#233;tablie sur le m&#234;me ensemble de contextes 
partag&#233;s. Il s'agit aussi d'une clique de contextes, car chaque contexte est reli&#233; &#224; chacun des 
autres contextes par une relation de proximit&#233; &#233;tablie sur le m&#234;me ensemble de termes 
partag&#233;s. Ces doubles cliques constituent des rapprochements directement interpr&#233;tables, qui 
sont d'une grande utilit&#233; &#224; l'utilisateur pour la constitution de classes s&#233;mantiques ou 
conceptuelles. Des exemples de doubles cliques sont donn&#233;s dans le tableau 4. La notion de 
double clique est &#224; rapprocher de celles de classe d'op&#233;rateurs et de classe d'arguments de Z. 
Harris. 
</p>
<p> 
</p>
<p>81 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault 
</p>
<p>Termes Contextes 
</p>
<p>Code civil 
</p>
<p>&#233;poux, donateur, d&#233;biteur, cr&#233;ancier profit_de, faveur_de, h&#233;ritier_de, 
s'obliger_SUJ 
</p>
<p>tribunal, juridiction, cour, conseil de 
prud'homme 
</p>
<p>disposition_&#224;, fonctionnement_de, 
comp&#233;tence_de, proc&#233;dure_devant 
</p>
<p>immeuble, bien, r&#233;colte, chose partie_de, fruit_de, prix_de, quotit&#233;_de, 
portion_de 
</p>
<p>R&#233;animation chirurgicale 
</p>
<p>r&#233;animation chirurgicale, 
neurochirurgie, chirurgie cardiaque 
</p>
<p>transferer_OBJ_patient_en, service_de, 
transferer_en 
</p>
<p>d&#233;tresse respiratoire, syndrome, 
insuffisance 
</p>
<p>pr&#233;senter_OBJ, pr&#233;senter_SUJ_patient_OBJ, 
apparition_de, tableau_de, 
</p>
<p>d&#233;velopper_SUJ_patient_OBJ, 
d&#233;velopper_OBJ 
</p>
<p>Tableau 4 : Quelques exemples de doubles cliques construites &quot;&#224; la main&quot; &#224; partir des 
r&#233;sultats de l'analyse distributionnelle fournis UPERY sur diff&#233;rents corpus. Chacun des 
termes (colonne de gauche) de la clique de termes appara&#238;t dans chacun des contextes 
(colonne de droite) de la clique des contextes. 
</p>
<p> 
</p>
<p>3 Travaux li&#233;s 
</p>
<p>Nous parlerons ici essentiellement des travaux de Gregory Greffenstette (Greffenstette 1994). 
L&#224; o&#249; G. Greffenstette se contente volontairement d&#8217;une analyse syntaxique relativement 
rudimentaire, r&#233;alis&#233;e par l&#8217;analyseur SEXTANT, nous avons fait le choix d&#8217;une analyse, certes 
encore partielle, mais plus large et plus pr&#233;cise, r&#233;alis&#233;e par SYNTEX. De ce fait, les 
proc&#233;dures statistiques d&#8217;analyse distributionnelle de Greffenstette ne concernent que des 
mots simples, alors que nous pouvons prendre en compte des entit&#233;s complexes (contextes ou 
termes). Les mesures statistiques utilis&#233;es par Greffenstette sont beaucoup sophistiqu&#233;es que 
les n&#244;tres. Outre leur degr&#233; de complexit&#233;, et le fait que nous tenons &#224; une mesure de 
proximit&#233; dissym&#233;trique, la diff&#233;rence tient aussi &#224; ce que nous avons fait le choix de ne pas 
tenir compte du tout des fr&#233;quences. Greffenstette introduit la fr&#233;quence des mots dans la 
mesure de pond&#233;ration, alors que les mesures de proximit&#233; sur lesquelles nous travaillons 
n&#233;gligent la fr&#233;quence (au profit de la productivit&#233;). Ce choix s&#8217;appuie sur le constat maintes 
fois confirm&#233; que, dans le contexte de la construction de ressources terminologiques ou 
ontologiques &#224; partir de corpus, l&#8217;utilisateur peut juger pertinents des ph&#233;nom&#232;nes rares dans 
le corpus. 
</p>
<p>82 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Upery : un outil d'analyse distributionnelle &#233;tendue &#8230; 
</p>
<p>Par ailleurs, contrairement &#224; Greffenstette, nous maintenons une distinction entre recteur et 
r&#233;gi dans l&#8217;analyse distributionnelle. Par exemple, dans notre approche, les noms peuvent &#234;tre 
rapproch&#233;s d&#8217;un c&#244;t&#233; par les contextes syntaxiques dans lesquels ils apparaissent (en tant que 
r&#233;gis), et d&#8217;un autre c&#244;t&#233;, de fa&#231;on ind&#233;pendante, par les modifieurs qu&#8217;ils r&#233;gissent (en tant 
que recteurs). Par exemple, dans le corpus sur la r&#233;animation chirurgicale, &#233;chographie et 
scanner c&#233;r&#233;bral sont rapproch&#233;s &#224; la fois en tant que r&#233;gis car apparaissant tous les deux 
dans les contextes r&#233;sultat_de, r&#233;alisation_de, noter_SUJ, r&#233;aliser_OBJ, montrer_SUJ, et en 
tant que recteur modifi&#233;s par les participe pass&#233;s r&#233;alis&#233;, effectu&#233;, pratiqu&#233;. 
</p>
<p>4 Conclusion 
</p>
<p>Les pistes de recherche sont nombreuses. Outre l&#8217;am&#233;lioration de l&#8217;analyse syntaxique, nous 
travaillons sur l'extension des op&#233;rations de r&#233;duction et de simplification, et sur l'affinement 
des mesures de proximit&#233;, avec le souci de v&#233;rifier la pertinence de pond&#233;rer ces mesures en 
fonction de la nature simple ou complexe des contextes et des termes. En ce qui concerne 
l&#8217;&#233;valuation et la validation, nous privil&#233;gions un mode de validation par l&#8217;usage. Toute 
ressource terminologique ou ontologique est construite pour un usage sp&#233;cifi&#233;, et c'est donc 
au sein de cet usage qu'elle peut &#234;tre &#233;valu&#233;e. Plut&#244;t que de comparer les rapprochements 
effectu&#233;s par le module d&#8217;analyse distributionnelle UPERY &#224; des ressources d&#233;j&#224; constitu&#233;es, 
nous nous effor&#231;ons de multiplier les exp&#233;riences dans lesquelles les r&#233;sultats du logiciel 
UPERY sont exploit&#233;s dans des t&#226;ches de construction de ressources terminologiques ou 
ontologiques. C&#8217;est sur la base des retours d&#8217;exp&#233;rience que nous &#233;valuons comment 
am&#233;liorer les diff&#233;rents modules de la cha&#238;ne de traitement. L&#8217;une des derni&#232;res exp&#233;riences 
en date concerne la construction d&#8217;une ontologie dans le domaine de la r&#233;animation 
chirurgicale. A partir des r&#233;sultats d' UPERY sur un corpus de 600 comptes-rendus 
d&#8217;hospitalisation (corpus REA), un m&#233;decin a construit une ontologie d&#8217;environ 2000 
concepts et 200 relations en un peu moins de 80 heures (Le Moigno &amp; al 2002). Dans autre 
exp&#233;rience (Bourigault, Lame 2002), une ontologie documentaire du Droit fran&#231;ais codifi&#233;, 
construite &#224; partir, entre autre, des r&#233;sultats fournis par le module UPERY, est &#233;valu&#233;e au sein 
de son environnement d'usage, &#224; savoir en tant qu'outil d'aide &#224; la reformulation et &#224; 
l'expansion de requ&#234;te sur le site d'acc&#232;s &#224; une base documentaire de textes juridiques 
(www.droit.org). 
</p>
<p>R&#233;f&#233;rences 
</p>
<p>Assadi H., Bourigault D. (1995). Classification d&#8217;adjectifs extraits d&#8217;un corpus pour l&#8217;aide &#224; 
la mod&#233;lisation des connaissances. Actes des 3&#232;mes Journ&#233;es internationales d&#8217;Analyse 
statistique de Donn&#233;es Textuelles (JADT 95), Rome 
</p>
<p>Assadi H. (1998) Construction d'ontologies &#224; partir de textes techniques. Application aux 
syst&#232;mes documentaires. Th&#232;se Universit&#233; Paris VI, Paris, 1998 
</p>
<p>Bourigault D., Assadi  H. (2000). Analyse syntaxique et analyse statistique pour la 
construction d&#8217;ontologie &#224; partir de textes, in Charlet  J, Zacklad  M., Kassel  G., Bourigault 
D. &#233;ds. Ing&#233;nierie des connaissances. Tendances actuelles et nouveaux d&#233;fis. Editions 
Eyrolles/France Telecom, Paris 
</p>
<p>83 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault 
</p>
<p>84 
</p>
<p>Bourigault  D, Fabre  C. (2000). Approche linguistique pour l'analyse syntaxique de corpus. 
Cahiers de grammaire, 25, 131-151, Universit&#233; Toulouse le Mirail 
</p>
<p>Bourigault D., Lame G. (2002). Analyse distributionnelle et structuration de terminologie. 
Application &#224; la construction d'une ontologie documentaire du Droit. Revue Traitement 
automatique des langues, n&#176; 47:1, Herm&#232;s, Paris  
</p>
<p>Faure D. (2000) Conception de m&#233;thode d'apprentissage symbolique et automatique pour 
l'acquisition de cadres de sous-cat&#233;gorisation de verbes et de connaissances s&#233;mantique &#224; 
partir de textes : le syst&#232;me ASIUM, th&#232;se de l'Universit&#233; Paris XI Orsay 
</p>
<p>Faure D., N&#233;dellec C. (1998). Apprentissage de cadres de sous-cat&#233;gorisation et de 
restrictions de s&#233;lection &#224; partir de textes. Actes de la 5&#232;me conf&#233;rence annuelle sur le 
Traitement Automatique des Langues Naturelles (TALN 98), 233-235 
</p>
<p>Grefenstette G. (1994). Exploration in Automatic Thesaurus Discovery, Londres, Kluwer 
Academic Publishers. 
</p>
<p>Habert B., Fabre C. (1999). Elementary dependancy trees for identifying corpus-specific 
semantic classes. Computer and the Humanities 33 :3, 207-219 
</p>
<p>Habert B., Nazarenko A. (1996). La syntaxe comme marche-pied cd l&#8217;acquisition des 
connaissances : bilan critique d&#8217;une exp&#233;rience. Actes des Journ&#233;es d&#8217;acquisition des 
connaissances (JAC 96), 137-149 
</p>
<p>Harris Z. (1968) Mathematical Structures of Language, New-York, John Wiley &amp; Sons. 
</p>
<p>Le Moigno S., Charlet J., Bourigault D., Jaulent M.-C. (2002). Construction d&#8217;une ontologie &#224; 
partir de corpus : exp&#233;rimentation et validation dans le domaine de la r&#233;animation chirugicale. 
Actes des 13&#232;mes journ&#233;es francophones d'ing&#233;nierie des connaissances (IC 2002), Rouen </p>

</div></div>
</body></html>