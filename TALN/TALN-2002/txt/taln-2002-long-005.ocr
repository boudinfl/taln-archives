TALN 2002, Nancy, 24-27 juin 2002

UPERY : un outil d'analyse distributionnelle étcnduc
pour la construction d’ontologics £1 partir dc corpus

Didier Bourigault

Equipe de Recherche en Syntaxe et Sémantique
CNRS — Université Toulouse le Mirail
Maison de la Recherche
5, allées Antonio Machado
31058 Toulouse Cedex 1
didier .bourigault@uniV-tlse2 .fr

Résumé — Abstract

Nous présentons un module mettant en oeuvre une méthode d'analyse distributionnelle dite
"étendue". L'analyseur syntaxique de corpus SYNTEX effectue l'analyse en dépendance de
chacune des phrases du corpus, puis construit un réseau de mots et syntagmes, dans lequel
chaque syntagme est relié a sa téte et a ses expansions. A partir de ce réseau, le module
d'analyse distributionnelle UPERY construit pour chaque terme du réseau l'ensemble de ses
contextes syntaxiques. Les termes et les contextes syntaxiques peuvent étre simples ou
complexes. Le module rapproche ensuite les termes, ainsi que les contextes syntaxiques, sur
la base de mesures de proximité distributionnelle. L'ensemble de ces résultats est utilisé
comme aide a la construction d'ontologie a partir de corpus spécialisés.

We present a software that implements a method of "extended" distributional analysis. The
corpus syntactic analyser SYNTEX yields a dependency syntactic analyse of each sentence of
the corpus. It builds a network of words and phrases in which each phrase is connected to its
head and its expansion. The distributional analysis module UPERY relies on this network to
associate to each term in the network a set of syntactic contexts. Syntactic contexts as well as
terms may be simple or complex. The UPERY module calculates distributional proximities
between terms as well as between contexts. The results are used for the building of
ontological resources from specialized corpora.

Keywords — Mots Clés

analyse syntaxique automatique, analyse distributionnelle, corpus, ontologie, terminologie.
parsing, distributional analysis, corpus, ontology, terminology

75

D. Bourigault

1 Analyse distributionnelle et construction d’ontologies

L’analyse distributionnelle << a la Harris >> (Harris 1968) est une technique bien connue dans le
milieu du Traitement Automatique des Langues. Dans la communauté francaise d’Ingénierie
des Connaissances, cette technique est exploitée depuis une dizaine d’année pour des
applications de construction de ressources terminologiques ou d’ontologies a partir de textes
(Assadi, Bourigault 1995) (Habert, Nazarenko 1996) (Faure, Nédellec 1998). Les
rapprochements de mots effectués sur la base de contextes syntaxiques partagés s’aVerent étre
des amorces le plus souvent tres utiles pour l’analyste chargé de construire un modele de
connaissances a partir d’un corpus spécialisé.

Le travail présenté dans ce papier constitue la suite des études entamées avec H. Assadi sur
l’utilisation en acquisition de connaissances a partir de textes de l’outil d’extraction de termes
LEXTER (Bourigault 1994) et de procédures d’analyse distributionnelle exploitant les résultats
de cet analyseur (Assadi, Bourigault 1998) (Bourigault, Assadi 2000). Ces études ont montré
a la fois l’intérét de l’analyse distributionnelle pour la construction de ressources
terminologiques a partir de textes, et aussi la nécessité d’utiliser, en amont, des outils
d’analyse syntaxique large, qui prennent en compte en particulier les relations de dépendance
syntaxique autour des Verbes. Nous présentons dans cet article, une méthode et un outil
d'analyse distributionnelle étendue (section 2), qui s'appuie sur le réseau de dépendance
syntaxique construit par l'analyseur syntaxique de corpus SYNTEX. Par rapport aux travaux
classiques, la méthode que nous proposons étend les fonctionnalités habituelles en ce qu'elle
prend en compte des unités complexes, a la fois du c6té des termes classés que de celui des
contextes syntaxiques classiﬁcateurs. Dans la section 3, nous précisons comment se situe
notre approche par rapport a l’état de l’art.

2 Analyse distributionnelle étendue

2.1 Analyse syntaxique de corpus et construction d'un réseau de
dépendance syntaxique

La méthode d'analyse distributionnelle que nous présentons dans cette section s'appuie sur les
résultats foumis par l'analyse syntaxique d'un corpus, sous la forme de relations de
dépendance entre mots au sein des phrases du corpus. Dans les expériences décrites ici, nous
avons utilisé les résultats de l'analyseur syntaxique de corpus SYNTEX (Bourigault, Fabre,
1999). A partir des résultats de l'analyse syntaxique des phrases du corpus, un module
d'extraction de syntagmes (ES) construit un réseau de mots et syntagmes, calculé a partir des
relations de dépendance identiﬁées dans chacune des phrases. Nous décrivons dans cette
section comment est construit ce réseau, qui foumira les données de base a l'analyse
distributionnelle étendue.

Dans un premier temps, pour chaque phrase, le module ES procede a l'identiﬁcation des
constituants syntaxiques maximaux (Verbaux, nominaux, adj ectivaux) que détermine la
structuration en relation de dépendance. Pour chaque mot recteur, il construit un syntagme
maximal en parcourant toutes les relations de dépendance syntaxique dont ce mot est la cible
jusqu'a aboutir a des mots qui soit ne sont pas recteurs, soit sont téte d'un syntagme maximal
déja construit. La caractérisation de la structure d'un syntagme est la suivante :

76

Upery .' un outil d'anab/se distributionnelle étendue 

- une téte, qui est constituee du mot recteur avec sa categorie ;

- une liste de couples (relation, expansion), chaque expansion etant (le lemme d') un
mot regi ou (la forme norrnalisee d') un syntagme dont la téte est un mot regi, et la
relation etant la relation de dependance syntaxique ;

- une forme normalisee, constituee a partir du lemme de la téte et de la sequence des
. , . 1
lemmes ou formes normal1see des expansions .

Dans un second temps, le module ES construit le reseau de dependance en ajoutant pour
chaque syntagme maximal different rencontre : (1) un noeud dont le label est la forme
norrnalisee du syntagme, (2) des liens Vers les noeuds correspondant a ses expansions,
etiquetes par le nom de la relation de dependance.

Le reseau est ensuite enrichi suite a des operations de réduction et de simpliﬁcation sur les
syntagmes maximaux (des exemples illustratifs seront donnes dans le tableau 1 de la section
suivante).

- L'operation de réduction opere sur des syntagmes qui ont au moins deux
expansions. Elle consiste a generer, a partir d'un syntagme donne, autant de
syntagmes reduits qu'il y a d'expansion : chaque syntagme reduit est constitue de la
téte du syntagme maximal, et d'une seule expansion, un couple (relation,
expansion) extrait de la liste des expansions du syntagme maximal. La reduction est
totale dans le sens ou l'on extrait des syntagmes reduits a une seule expansion2.

- L'operation de simpliﬁcation opere sur des syntagmes, maximaux ou reduits, dont
au moins une expansion est un syntagme. Elle consiste a generer, a partir d'un
syntagme donne, des syntagmes dans lesquels les expansions syntagmes ont ete
remplacees par leur téte. La simplification est totale dans le sens ou l'on reduit
chaque expansion syntagme a sa téte3.

Ces operations de reduction et de simplification Visent d'une part a etablir des liens directs
dans le reseau entre des syntagmes correspondant a des Variations syntaxiques par expansion
ou par insertion, et d'autre part a multiplier, de facon contr6lee, le nombre de contextes
syntaxiques qui Vont étre exploites par l'analyse distributionnelle. L'operation de
simplification s'apparente a celle effectuee par Habert et Fabre [1999] dans l'outil d'analyse
distributionnelle ZELLIG pour obtenir des contextes elementaires.

1Notons que c'est a ce niveau que nous avons choisi d'operer la normalisation actif/passif.

2 Nous travaillons a definir une operation de reduction plus complete, telle que, par exemple, pour un syntagme
a trois expansions, on extraie des syntagmes partiellement reduits a deux expansions.

3 Nous travaillons a definir une operation de simplification plus complete, de telle sorte que, par exemple, l'on

remplace un syntagme expansion ayant lui-meme deux expansions pas uniquement par sa tete, mais aussi par
ses syntagmes reduits.

77

D. Bourigault

2.2 Les données de l'analyse distributionnelle : des contextes syntaxiques
complexes et des termes complexes

Le module d'analyse distributionnelle UPERY exploite l'ensemble des données présentes dans
le réseau pour effectuer un calcul des proximités distributionnelles entre les mots et
syntagmes du réseau. Ce calcul s'effectue sur la base des contextes syntaxiques partagés. Il
s'agit d'une mise en oeuvre du principe de l'analyse distributionnelle "a la Harris". Les données
de l'analyse sont constituées ainsi :

(1) pour chaque syntagme du réseau ayant une seule expansion, le module construit une
information élémentaire pour le calcul distributionnel. Celle-ci se formalise sous la forme d'un
couple (contexte, terme) :

- le contexte est le couple constitué de la téte et de la relation de dépendance ; ll
s'agit d'un contexte simple.

- le terme est l'expansion.

(2) pour chaque syntagme du réseau ayant plus d'une expansion (N expansions, N supérieur
ou égal a 2), le module construit N(N-1) inforrnations élémentaires pour le calcul
distributionnel. Pour chaque expansion E, il construit N-1 couples (contexte, terme), un pour
chacune des autres expansions E‘ :

- le contexte est le couple constitué du syntagme réduit construit avec la téte et
l'expansion E, et de la relation de dépendance R‘ correspondant a l'expansion E‘; il
s'agit d'un contexte complexe.

- le terme est l'expansion E‘.

Nous sommes en mesure maintenant de dérouler un exemple complet, pour illustrer en quoi
on peut parler d’analyse distributionnelle << étendue >>. Les données extraites pour l’analyse
distributionnelle a partir de l’analyse syntaxique de la phrase «Les roches cristallines
résistent a l’érosion>>, sont présentées dans le tableau 1. Le syntagme roche cristalline
apparait dans le contexte simple << sujet de résister >> ainsi que dans le contexte complexe
<< suj et de résister d ér0si0n>>. De méme, le mot érosion apparait dans le contexte syntaxique
simple << complément de résister a >> et dans les contextes complexes << complément de roche
résister cl » et << complément de roche cristalline résister d ».

Il est donc possible d'aVoir des unités complexes a la fois du c6té des contextes syntaxiques
classificateurs et de celui des termes classes. A titre d’illustration, nous donnons quelques
exemples et des résultats numériques obtenus sur les 4 corpus suivants : le code civil francais
(CCIV, 145 000 mots), un recueil d’article scientifiques dans le domaine de l’ingénierie des
connaissances (IC, 200 000 mots), un ouvrage de géomorphologie (GEOM, 210 000 mots),
un corpus de compte-rendus d’hospitalisation dans le domaine de la réanimation chirurgicale
(REA 178 000 mots). Les résultats sont obtenus avec des Valeurs de seuils de proximité
donnés dans la section suivante. On constate sur le tableau 2 en particulier que sur les
diffférents corpus entre 60 et 100 syntagmes nominaux ont été rapprochés d’autres noms ou
syntagmes nominaux par l’analyse distributionnelle. Le tableau 3 illustre le fait que les types
de couples de catégories rapprochés par l'analyse distributionnelle se répartissent de facon
sensiblement différente d'un corpus a l'autre.

78

Upery .' un outil d'anab/se distributionnelle étendue 

Terme Contexte
cristalline roche_ADJ
roche résister_SUJ
roche résister_a_érosion_SUJ

roche cristalline

résister_SUJ

roche cristalline

résister_a_érosion_SUJ

érosion résister_a
érosion résister_SUJ_roche_a
érosion résister_SUJ_roche crista11ine_a

Tableau 1 : Données extraites pour 1’analyse distributionnelle étendue £1 partir de

1’ana1yse syntaxique de la phrase << Les roches cristallines résistenta1’érosion».

CCIV IC GEOM REA

Adj 82 955 9 % 176 1482 12 % 271 2140 13 % 264 2004 13%
Adv 16 470 3 % 29 622 5% 31 701 4% 10 181 6%
Nom 267 2220 12 % 356 2923 12 % 287 4264 7 % 301 5737 5 %

SN 60 10343 0,5 % 97 22764 0,5 % 44 24198 0,2 % 100 21236 0,5 %

Tableau 2 Nombre de mots ou syntagmes rapprochés par l’ana1yse

distributionnelle, par catégorie. Pour chaque corpus, dans la premiere colonne
ﬁgure 1e nombre de mots de la catégorie qui ont au moins un Voisin, dans la
deuxieme 1e nombre total de mots de la catégorie, et dans la troisieme 1e
pourcentage correspondant

CCIV IC GEOM REA
Nom Nom 690 38,94% 1346 56,39% 524 36,16% 690 38,94%
Nom SNom 125 7,05% 222 9,30% 46 3,17% 125 7,05%
SNom SNom 72 4,06% 16 0,67 4 0,28% 72 4,06%

Tableau 3 : Types de couples de categories (nominales) rapprochés par 1'ana1yse
distributionnelle

79

D. Bourigault

2.3 Trois mesures de proximité

L'analyse distributionnelle rapproche d’abord deux a deux des termes qui partagent les mémes
contextes. L'analyse distributionnelle est symétrique, en ce sens qu'elle peut rapprocher aussi
les contextes, en fonction des termes qu'ils partagent. Nous travaillons actuellement sur trois
mesures qui permettent d'appréhender la proximité entre deux unités (termes ou contextes).
Ces mesures ont l'aVantage d'étre simples a appréhender par l'utilisateur final, et de recouvrir
des aspects différents et complémentaires des conditions dans lesquelles deux unités peuvent
étre jugées plus ou moins proches. Notre application cible est l’aide a la construction de
ressources terminologiques ou ontologiques a partir de textes. Notre obj ectif est de foumir a
l'utilisateur, avec ces quelques mesures de proximité, différents outils pour l’aider a trouver
au plus Vite les relations qu’il jugera les plus intéressantes.

On dispose pour un contexte donné de l'ensemble des termes (mots ou syntagmes) qui
apparaissent dans ce contexte, et pour un terme donné l'ensemble des contextes (simples ou
complexes) dans lesquels il apparait. On définit la productivité d'un contexte et la productivité
d'un terme ainsi :

- la productivité d'un contexte est égale au nombre de termes qui apparaissent dans
ce contexte ;

- la productivité d'un terme est égale au nombre de contextes dans lesquels ce terme
apparait.

Les trois mesures de la proximité sont les suivantes :

Le coefficient a. Soient deux termes t1 et t2. Le coefficient a est égal au nombre de contextes
syntaxiques partagés par les deux termes. Cette mesure donne une premiere indication de la
proximité entre deux termes, facile a interpréter. Mais l'expérience montre que cette mesure
reﬂete de facon insatisfaisante la proximité : il faut tenir compte, d'un cote, de la productivité
des contextes partagés (coefficient prox), d'un autre cote, du nombre de contextes que chaque
terme a en propre (coefficients j 1 Ctjz).

Le coefficient prox. Avec ce coefficient, nous Visons a formaliser le fait si un contexte
partagé par deux termes est tres productif, sa contribution au rapprochement des deux termes
est a priori plus faible que celle d'un contexte peu productif. Le coefficient prox est calculé
ainsi :

prox = Zcec 1/ prod(c)1/2

ou C est l'ensemble des contextes partagés par t1 et t2, et prod(c) la productivité du
contexte c

Les coefficients j1 etjz. Pour évaluer la proximité entre deux unités, il est important de tenir
compte non seulement de ce qu'elles partagent, mais aussi de ce qu'elles ont en propre. Un
certain nombre de mesures statistiques implémentent cette idée, sous des formes diverses (e. g.
information mutuelle, Jaccard, Anderberg). Ces mesures présentent presque toujours la
particularité de "symétriser" la relation de proximité. Cette propriété, qui dans beaucoup de
contextes d'application, constitue un avantage, Voire une nécessité, nous est apparue
finalement comme masquant un phénomene marquant a l'oeuVre dans les corpus : la
dissymétrie de la relation de proximité. Quand deux termes partagent un certain nombre de
contextes en commun, il arrive le plus souvent que l'un des deux termes possede un nombre

80

Upery .' un outil d'anab/se distributionnelle étendue 

élevé de contextes, tandis que l'autre en possede beaucoup moins et en partage l'essentiel avec
le premier. C'est pourquoi, nous caractérisons la proximité entre deux termes a l'aide de deux
indices, simples et eux aussi faciles a interpréter : rapport entre le nombre de contextes
partagés et le nombre total de contextes

j1 = a / prod(t1)
j 2 = a / prod(t2)

Le module d'analyse distributionnelle UPERY calcule pour chaque couple de termes
l'ensemble de ces coefficients. Dans l'interface, on ne présente a l'utilisateur que les couples
dont les coefficients dépassent certains seuils. Ces seuils sont définis de facon empirique et
Varient en fonction d'une part de l'homogénéité et de la redondance du corpus et d'autre part
du contexte dans lequel doivent étre exploités les résultats de l'analyse distributionnelle. Pour
les exemples présentés dans ce papier, les différents corpus ont été traités avec les seuils
suivants :

- le nombre de contextes partagés a doit étre supérieur ou égal a 3
- le coefficient prox doit étre supérieur a 0.75

- l'un des deux coefficients j] ou jg doit étre supérieur a 0.25 (l'un des deux termes
doit partager au moins le quart de ses contextes avec l'autre)

2.4 Le concept de double clique

Le module d'analyse distributionnelle UPERY calcule des proximités entre couples de termes
(et de contextes). Nous n'aVons pas encore implémenté de calcul automatique de
regroupement de termes, sous forme d'arbre de classification hiérarchique ascendante [Assadi
1998] ou de cliques et composantes connexes [Nazarenko & al. 2000]. A l'instar de [Faure
2000], nous laissons a l'utilisateur le soin de repérer et de Valider des regroupements qu'il juge
pertinents, grace a une interface spécialement concue pour cette tache. Celle-ci guide
l'utilisateur vers les regroupements a priori pertinents en lui perrnettant d'accéder rapidement
a des structures que nous nommons doubles cliques : un double clique est constituée d'un
ensemble de termes et d'un ensemble de contextes, tels que chacun des termes apparait dans
chacun des contextes. Il s'agit d'une clique de termes, car chaque terme est relié a chacun des
autres termes par une relation de proximité établie sur le méme ensemble de contextes
partagés. Il s'agit aussi d'une clique de contextes, car chaque contexte est relié a chacun des
autres contextes par une relation de proximité établie sur le méme ensemble de termes
partagés. Ces doubles cliques constituent des rapprochements directement interprétables, qui
sont d'une grande utilité a l'utilisateur pour la constitution de classes sémantiques ou
conceptuelles. Des exemples de doubles cliques sont donnés dans le tableau 4. La notion de
double clique est a rapprocher de celles de classe dbpérateurs et de classe d’arguments de Z.
Harris.

81

D. Bourigault

Termes Contextes

Code civil

époux, donateur, débiteur, créancier proﬁt_de, faVeur_de, héritier_de,
s'ob1iger_SUJ

tribunal, juridiction, cour, conseil de disposition_a, fonctionnement_de,
prud'homme compétence_de, procédure_devant
immeuble, bien, récolte, chose partie_de, fruit_de, prix_de, quotité_de,
portion_de

Réanimation chirurgicale

réanimation chirurgicale, transferer_OBJ_patient_en, service_de,
neurochirurgie, chirurgie cardiaque transferer_en
détresse respiratoire, syndrome, présenter_OBJ, présenter_SUJ_patient_OBJ,
insufﬁsance apparition_de, tableau_de,

développer_SUJ_patient_OBJ,
déVelopper_OBJ

Tableau 4 : Quelques exemples de doubles cliques construites "a la main" a partir des
résultats de l'analyse distributionnelle fournis UPERY sur différents corpus. Chacun des
termes (colonne de gauche) de la clique de termes apparait dans chacun des contextes
(colonne de droite) de la clique des contextes.

3 Travaux liés

Nous parlerons ici essentiellement des travaux de Gregory Greffenstette (Greffenstette 1994).
La ou G. Greffenstette se contente Volontairement d’une analyse syntaxique relativement
rudimentaire, réalisée par l’analyseur SEXTANT, nous avons fait le choix d’une analyse, certes
encore partielle, mais plus large et plus précise, réalisée par SYNTEX. De ce fait, les
procédures statistiques d’analyse distributionnelle de Greffenstette ne concernent que des
mots simples, alors que nous pouvons prendre en compte des entités complexes (contextes ou
termes). Les mesures statistiques utilisées par Greffenstette sont beaucoup sophistiquées que
les n6tres. Outre leur degré de complexité, et le fait que nous tenons a une mesure de
proximité dissymétrique, la difference tient aussi a ce que nous avons fait le choix de ne pas
tenir compte du tout des fréquences. Greffenstette introduit la fréquence des mots dans la
mesure de pondération, alors que les mesures de proximité sur lesquelles nous travaillons
négligent la fréquence (au proﬁt de la productivité). Ce choix s’appuie sur le constat maintes
fois conﬁrmé que, dans le contexte de la construction de ressources terminologiques ou
ontologiques a partir de corpus, l’utilisateur peut juger pertinents des phénomenes rares dans
le corpus.

82

Upery .' un outil d'anab/se distributionnelle étendue 

Par ailleurs, contrairement a Greffenstette, nous maintenons une distinction entre recteur et
régi dans l’analyse distributionnelle. Par exemple, dans notre approche, les noms peuvent étre
rapprochés d’un c6té par les contextes syntaxiques dans lesquels ils apparaissent (en tant que
régis), et d’un autre cote, de facon indépendante, par les modifieurs qu’ils régissent (en tant
que recteurs). Par exemple, dans le corpus sur la réanimation chirurgicale, échogmphie et
scanner cerebral sont rapprochés a la fois en tant que régis car apparaissant tous les deux
dans les contextes résultat_de, réalisation_de, noter_SUJ, réaliser_0BJ, montrer_SUJ, et en
tant que recteur modiﬁés par les participe passés réalisé, eﬂectué, pratiqué.

4 Conclusion

Les pistes de recherche sont nombreuses. Outre l’amélioration de l’analyse syntaxique, nous
travaillons sur l'extension des opérations de réduction et de simplification, et sur l'affinement
des mesures de proximité, avec le souci de vérifier la pertinence de pondérer ces mesures en
fonction de la nature simple ou complexe des contextes et des terrnes. En ce qui concerne
l’éValuation et la Validation, nous privilégions un mode de validation par l’usage. Toute
ressource terminologique ou ontologique est construite pour un usage spéciﬁé, et c'est donc
au sein de cet usage qu'elle peut étre évaluée. Plut6t que de comparer les rapprochements
effectués par le module d’analyse distributionnelle UPERY a des ressources déja constituées,
nous nous efforcons de multiplier les expériences dans lesquelles les résultats du logiciel
UPERY sont exploités dans des taches de construction de ressources terrninologiques ou
ontologiques. C’est sur la base des retours d’expérience que nous évaluons comment
améliorer les différents modules de la chaine de traitement. L’une des demieres expériences
en date concerne la construction d’une ontologie dans le domaine de la réanimation
chirurgicale. A partir des résultats d' UPERY sur un corpus de 600 comptes-rendus
d’hospitalisation (corpus REA), un médecin a construit une ontologie d’enViron 2000
concepts et 200 relations en un peu moins de 80 heures (Le Moigno & al 2002). Dans autre
expérience (Bourigault, Lame 2002), une ontologie documentaire du Droit francais codifié,
construite a partir, entre autre, des résultats fournis par le module UPERY, est évaluée au sein
de son environnement d'usage, a savoir en tant qu'outil d'aide a la reformulation et a
l'expansion de requéte sur le site d'acces a une base documentaire de textes juridiques
(www.droit.org).

Références

Assadi H., Bourigault D. (1995). Classification d’adjectifs extraits d’un corpus pour l’aide a
la modélisation des connaissances. Actes des 3emes Journées internationales d’/lnab/se
statistique de Données T extuelles (JADT 95), Rome

Assadi H. (1998) Construction d'ontologies a partir de textes techniques. Application aux
systemes documentaires. These Université Paris VI, Paris, 1998

Bourigault D., Assadi H. (2000). Analyse syntaxique et analyse statistique pour la
construction d’ontologie a partir de textes, in Charlet J, Zacklad M., Kassel G., Bourigault
D. éds. Ingénierie des connaissances. T endances actuelles et nouveaux déﬁs. Editions
Eyrolles/France Telecom, Paris

83

D. Bourigault

Bourigault D, Fabre C. (2000). Approche linguistique pour l'analyse syntaxique de corpus.
Cahiers de grammaire, 25, 131-151, Université Toulouse le Mirail

Bourigault D., Lame G. (2002). Analyse distributionnelle et structuration de terminologie.
Application a la construction d'une ontologie documentaire du Droit. Revue Traitement
automatique des langues, n° 47: 1, Hermes, Paris

Faure D. (2000) Conception de méthode d'apprentissage symbolique et automatique pour
l’acquisition de cadres de sous-catégorisation de verbes et de connaissances sémantique a
partir de textes .' le systeme ASIUM, these de l'UniVersité Paris XI Orsay

Faure D., Nédellec C. (1998). Apprentissage de cadres de sous-catégorisation et de
restrictions de selection a partir de textes. Actes de la 5é’”" conférence annuelle sur le
T raitement Automatique des Langues Naturelles (TALN 98), 233-235

Grefenstette G. (1994). Exploration in Automatic Thesaurus Discovery, Londres, Kluwer
Academic Publishers.

Habert B., Fabre C. (1999). Elementary dependancy trees for identifying corpus-specific
semantic classes. Computer and the Humanities 33 :3, 207-219

HabertB., Nazarenko A. (1996). La syntaxe comme marche-pied cd l’acquisition des
connaissances: bilan critique d’une expérience. Actes des Journées d’acquisition des
connaissances (J AC 96), 13 7- 149

Harris Z. (1968) Mathematical Structures of Language, New-York, John Wiley & Sons.

Le Moigno S., Charlet J., Bourigault D., Jaulent M.-C. (2002). Construction d’une ontologie a
partir de corpus : expérimentation et validation dans le domaine de la réanimation chirugicale.
Actes des ISemesjournéesfrancophones d'ingénierie des connaissances (IC 2002), Rouen

84

