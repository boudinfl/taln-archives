TALN 2002, Nancy, 24-27 juin 2002

Extraction d’informations
£1 partir dc corpus dégradés

Fabrice Evenl, Chantal Enguehard

Institut de Recherche en Informatique de Nantes
Université de Nantes
Faculte des Sciences et des Techniques
2 rue de la Houssiniere, BP 92208
44322 NANTES cedex 3, France
{eVen,enguehard} @irin.uniV-nantes.fr

Résumé — Abstract

Nous présentons une méthode automatique d’extraction d’information a partir d’un corpus
mono-domaine de mauvaise qualité, sur lequel il est impossible d’appliquer les méthodes
classiques de traitement de la langue naturelle. Cette approche se fonde sur la construction
d’une ontologie semi-formelle (modélisant les informations contenues dans le corpus et les
relations entre elles). Notre méthode se déroule en trois phases: 1) la normalisation du
corpus, 2) la construction de l’ontologie, et 3) sa formalisation sous la forme d’une
grammaire. L’extraction d’information a proprement parler exploite un étiquetage utilisant les
regles défmies par la grammaire. Nous illustrons notre démarche d’une application sur un
corpus bancaire.

We present an information extraction automatic method from poor quality specific-domain
corpus (with which it is impossible to apply classical natural language methods). This
approach is based on building a semi-formal ontology in order to modelise information
present in the corpus and their relation. Our method happens in three stage : 1) corpus
normalisation, 2) ontology building and 3) model formalisation in grammar. The information
extraction itself is made by a tagging process using grammar rules. We illustrate our approach
by an application working on a bank corpus.

Mots Clés — Keywords

Extraction d’information, modélisation, construction d’ontologie, corpus dégradés.
Information extraction, modelling, building ontology, poor quality corpus..

1 These finance’e par le Credit Mutuel Loire-Atlantique Centre-Ouest dans le cadre d’un contrat CIFRE

105

F abrice Even, Chantal Enguehard

1 Introduction

Cette recherche est directement issue de la Volonte d’extraire des informations a partir d’un
corpus degrade (nombreuses abreviations, phrases asyntaxiques, ponctuation inexistante,
etc.). L’extraction d’inforrnation est deﬁnie comme un processus en deux etapes : la
modelisation des types d’informations recherches et l’identiﬁcation de leurs instances dans le
corpus. La premiere etape utilise des sources de connaissances externes au corpus afin de
batir une ontologie semi-
formelle recouvrant une partie du domaine dans lequel s’inscrit le corpus. Seul le sous-
domaine limite a la connaissance exprimee dans le corpus est effectivement modelise. La
deuxieme etape s’appuie sur cette ontologie aﬁn d’extraire les informations du corpus.

Apres une breve presentation des methodes de construction d’ontologic et leur confrontation a
des corpus degrades, nous detaillons les differentes etapes de notre demarche : la construction
de l’ontologie, sa representation formelle sous forme d’une grammaire, puis l’extraction des
informations a l’aide de cette grammaire. Les resultats de l’extraction sont evalues et
analyses.

Nous travaillons sur un corpus compose de textes issus du milieu bancaire. Il est compose de
textes relatant des entretiens passes entre des clients et des employes. Notre but est d’extraire
automatiquement certains types d’informations decrites informellement, comme les differents
projets des clients ou un changement dans leur situation familiale. Les informations extraites
Viendront enrichir une base de donnees.

Exemple : a partir du texte suivant,
« PRJACHT STUDIO EN 12 01 PARIS POUR 400 KFRCS » [1]

le processus doit reperer les projets d’achat du client et identifier ses parametres :
l’objet (studio), la date (12/01), le lieu (Paris) et le montant (400KF).

2 Méthodcs dc construction d’ontologic

De nombreuses methodes Visent a construire des ontologies a partir de corpus. La plupart se
fondent sur le contenu des textes pour construire l’ontologie, les textes sont alors la source
principale de connaissance pour l’acquisition d’information (Nobecourt, 2000). L’ensemble
des concepts du modele ainsi que leurs relations sont exclusivement issus d’une analyse des
textes, sans apport de connaissance exterieur. (Aussenac-Gilles et al., 2000) s’inscriVent dans
cette demarche meme s’il est reconnu que les textes peuvent ne pas constituer l’unique source
de connaissance. Cette approche endogene se decompose en plusieurs etapes : l’extraction des
termes se referant aux concepts de base (primitives conceptuelles (Nobecourt, 2000)), puis
des relations lexicales qu’ils entretiennent (creation d’une base terrninologique (Aussenac-
Gilles et al., 2000), (Lame, 2000)) afin de faire emerger les premieres relations inter-concepts.
L’etape suivante s’appuie sur l’analyse des relations semantiques entre termes pour extraire
de nouvelles relations entre les concepts ainsi que de nouveaux concepts aﬁn d’aboutir a un
reseau semantique de concepts. Le reseau semantique doit étre Valide par un expert du
domaine afin de preciser les relations signiﬁcatives (normalisation (Bouaud, Bachimont et al
1995)). Le resultat correspond a la deﬁnition de (Swartout et al., 1996) << Une ontologie est

106

Extraction d ’informations a partir de corpus dégradés

une structure hiérarchique d’un ensemble de termes du domaine », soit une ontologie pouvant
étre représentée de maniere forrnelle ou semi-formelle.

Les différentes étapes s’appuient sur des outils de TAL peu adaptés aux corpus de mauvaise
qualité. La phase terminologique est envisageable apres une correction des textes, mais
l’extraction de relations lexicales et sémantiques se révele peu efficace sur de tels corpus a
cause de leur tres faible qualité syntaxique et lexicale.

3 Modélisation du domaine

3.1 Prétraitements

Les textes de notre corpus sont si dégradés (incorrections typologiques ou orthographiques,
emploi d'abréViations non normalisées) qu’il est nécessaire d’effectuer avant tout autre
processus une correction et une normalisation du corpus. C’est a partir de ce corpus corrigé
que nous procédons a la modélisation puis a l’extraction d’information a proprement parler.
Cette normalisation porte surle format des Valeurs (nombres avec unités), les dates, les
abréviations et la correction orthographique des fautes lexicales et typographiques. Ces
prétraitements sont réalisés a l’aide d’expressions régulieres écrites en fonction du corpus.

Exemple : l’extrait [l] devient : « projet achat studio en 1 2/01 paris pour 400lsf» [2]

3.2 Construction du modéle

D’apres Bachimont (Bachimont 2001), i1 n’existe pas de concepts indépendants du contexte
ou du probleme traité permettant de construire toute la connaissance d’un domaine. Une
ontologie fonctionne comme un cadre théorique du domaine construit en fonction du
probleme traité. Le processus de modélisation décrit ici est fondé sur cette derniere deﬁnition.
Nous construisons l’ontologie en nous appuyant sur les connaissances présentes dans le
corpus et des connaissances externes au corpus (experts).

3.2.1 Deﬁnition de I ’ontologie initiale .' expression des informations recherchées

Les inforrnations a rechercher, exprimées informellement, sont réécrites sous la forme de
prédicats modélisés par des patrons d’informations. Cette tache doit étre réalisée avec des
experts du domaine ayant une bonne connaissance du corpus et sachant exprimer la nature des
informations a extraire. Cette phase aboutit a la description d'un ensemble de hiérarchies de
concepts constituant une premiere sous-ontologie (ontologie initiale). Cette ontologie met en
jeu des relations argumentatives entre concepts (un concept est lié a un autre car il en est un
argument). Les relations argumentatives respectent l’Attribute Consistency Postulate
(Guarino 1992): dans chaque relation argumentative, toute Valeur d’un argument est une
instance du concept correspondant a cet argument.

107

F abrice Even, Chantal Enguehard

3.2.2 Deﬁnition de la terminologie

Elle est issue d’une part d’une étude terrninologique des textes par le logiciel, ANA
(Enguehard, Pantéra 1995), caractérisé par sa robustesse. Et d’autre part d’un ensemble de
documents référencant la terminologie spéciﬁque au domaine dans lequel nous trouvons une
partie des terrnes potentiellement utilisés dans notre corpus.

3.2.3 Normalisation .' Fusion de I ’0nt0logie initiale et de la terminologie

A chaque terrne ne correspond pas un concept de l’ontologie initiale. Il faut pouvoir relier les
terrnes du corpus aux concepts déﬁnis dans cette ontologie. Un processus de normalisation est
nécessaire. 11 se déroule en trois étapes : 1) extension de l'ontologie initiale, 2) definition
d'une semi-base terrninologique et 3) uniﬁcation des modeles ainsi déﬁnis.

1. L’ontologie initiale est révisée avec l'aide d'experts du domaine. De nouveaux
concepts completent les hiérarchies (on parlera d'ontologie initiale étendue).

2. Grace aux mémes experts, et en nous appuyant sur des documents propres au
domaine, nous spéciﬁons a partir de la terminologie un autre ensemble de concepts,
les concepts de base. Récursivement de nouveaux concepts sont déﬁnis par heritage
a partir des concepts de base. Le résultat est un ensemble de petites hiérarchies ayant
chacune un ancétre unique dont les derniers descendants sont des concepts de base.
Ces hiérarchies sont normées, c’est-a-dire organisées de maniere systématique, car
chaque pere se décompose en ﬁls selon un critere unique. Elles respectent également
le critere de rigidité de Guarino (Guarino 2000).

3. Les deux processus précédents donnent d'une part une ontologie liée au probleme
traité et un ensemble de sous-hiérarchies directement liées a la terminologie du texte.
Nous procédons a l’uniﬁcation des sous-hiérarchies et de l'ontologie initiale étendue
en analysant si des concepts ancétres (peres) des sous-hiérachies sont déja présents
dans l'ontologie ou si une relation peut étre déﬁnie avec des concepts de cette
ontologie.

Nous obtenons une modélisation du domaine couvrant l’ensemble des concepts qui nous
intéressent pour la recherche d’information. Cette modélisation est décrite par un schéma
relationnel formalisé par un ensemble de graphes orientés. Elle établit une ontologie décrite
de maniere semi-formelle car indépendante d’un langage de représentation (Barry et al.
2001).

3.3 Représentation formelle

Nous représentons la modélisation précédemment obtenue sous la forme d’une grammaire,
afin de la rendre utilisable. Comme indiqué en 3.2, l'ontologie met en jeu deux types de
relations entre concepts : des relations hiérarchiques et des relations "argumentatiVes". Dans
cette formalisation les relations hiérarchiques sont appelées relations constitutives car nous
nous placons ici du point de vue de la base de chacune des hiérarchies et non pas de celui de
son sommet. Lorsqu'une relation hiérarchique existe entre un concept pere A et un concept
ﬁls B, on dit que B constitue A (on part du ﬁls pour remonter jusqu'au pere puis au pere du

108

Extraction d ’inf0rmati0ns a partir de corpus dégradés

pere et ainsi de suite). Une telle relation peut s'apparenter a une relation d'hyperonymie (A est
un hyperonyme de B) ou a l'inVerse d'hyponymie (B est un hyponyme de A). Lorsque l’on a
une relation de type argumentative entre deux concepts C et D, le concept D est un argument
(dont le type dépend de la relation) du concept C. La grammaire doit donc pouVoir rendre
compte de ces deux types de relations. Aussi nous définissons pour celle-ci deux types de
regles : les regles constitutives et les regles prédicatives.

3.3.1 Régles constitutives

Un concept A est déﬁni par un ensemble de regles Def(a) impliquant des termes ou des
concepts. Ces regles sont dites constitutives car le concept A est déﬁni (constitué) par ces
regles. Quel que soit X appartenant a Def(A), X ne peut définir un autre concept que A. Ces
regles s'écriVent A ::= Def(A) et sont de trois types: les regles sélectives, les regles
conjonctives et les regles disjonctives.

Les regles sélectives sont du type A ::= Bl | B2 |  . L’opérateur << | >> est équivalant au OU
exclusif: la Valeur de l’expression Bl | B2 est soit Bl, soit B2 mais pas les deux.

Exemple ; < VEHICULE> .-.- : <A UT0> \ <M0 T0> \ <DIV_ I/EHI>

Les regles conjonctives sont du type A ::= Bl + B2 +  . L'opérateur << +>> est non
commutatif et correspond a la conjonction classique : la Valeur de l’expression Bl + B2 est
exclusivement "Bl ET B2".

Exemple ; <P_A UTO> .-.-: <DC_PRET> + <VEHICULE>

Les regles disjonctives sont du type A ::= Bl V B2 V  . L’opérateur << V» équiVaut a la
disjonction classique : la Valeur de l’expression Bl V B2 est soit Bl, soit B2, soit les deux.

Exemple : <PERSO]VNE> .'.': <NOM> v <PRENOM>

3.3.2 Régles prédicatives

Ces regles décriVent les concepts-prédicats (appelés aussi prédicats), c'est-a-dire les concepts
mettant en jeu une ou plusieurs relations argumentatiVes. Elles définissent un prédicat P par
un descripteur et un obj et. Le descripteur est un concept unique (un concept ne pouVant étre le
descripteur de plus d’une regle). L’objet est un concept pris parmi un certain nombre de
concepts possibles, ceux ci étant déduits de la modélisation.

Ces regles peuVent également s’accompagner d’un ou plusieurs arguments supplémentaires
dits options. Ceux ci lorsqu’ils sont Valués donnent plus d’informations sur le prédicat P mais
ne sont ni nécessaires, ni sufﬁsants pour le déﬁnir.

Les regles prédicatiVes s’expriment de la forme P ::= (descripteur = D ; objet = 01 | 02 | 03
 ;option 1 =Al |A2|A3 ; option2=Bl |B2 ; 

Exemple : <ACHAT> .'.': (

descripteur : <DC_ACHAT> ,'

objet : <lZW\40BILIER> l <VEHICULE> l <PROD_BANCAIRE> ,'

109

F abrice Even, Chantal Enguehard

date : <DATE> ,'
montant : <SO]W\4E>)

4 Moteur d'extraction

Le moteur d'extraction s'appuie sur la grammaire modélisant le domaine (la grammaire issue
de l’ontologie). Il comprend quatre phases : l’alimentation d’une base de regle, deux
étiquetages successifs et le recueil des informations alimentant la base de données.

La base de regles se compose de deux sous-ensembles de regles (les regles constitutives et les
regles prédicatives) déduites de la grammaire. L’étiquetage constitutif du corpus s’appuie sur
les regles constitutives de la base (chaque terme est étiqueté par le concept qui lui est associé,
et chaque concept est lui-méme étiqueté en fonction de sa description dans la grammaire). Le
second étiquetage s’appuie sur les regles prédicatives pour instancier les prédicats. Apres ce
double étiquetage, le processus de recueil d’information est directement opérationnel. Son
résultat alimente la base de données.

4.1 Construction de la base de régles

Les regles de la base sont déduites de la grammaire, directement pour les regles prédicatives,
apres transformation pour les regles constitutives.

0 les regles sélectives perrnettant d’identiﬁer les concepts de base a partir des termes
sont transformées en ensemble de regles simples du type A ::= terme (regles
sélectives terminales).

0 les regles sélectives sur les concepts sont transformées en un ensemble de regles
simples A ::= B. Les regles conjonctives et disjonctives sont adaptées afin de se
conformer a la syntaxe du corpus. Cette adaptation consiste a adj oindre a ces regles
une notion d’ordre (l’opérateur + n’étant pas commutatif) et de proximité.
L’ensemble de ces regles transformées forme l’ensemble des regles conceptuelles.

4.2 Etiquetage constitutif

L’étiquetage constitutif repere dans le texte les différents termes puis les concepts en
appliquant récursivement les regles constitutives. A chaque fois qu’un concept est repéré, il
est marqué par une balise. Certains concepts tres spéciﬁques (dont la syntaxe répond a un
formalisme connu) comme les dates, les montants ou les sommes sont traités au préalable.
Ensuite l’étiquetage se déroule en deux étapes : 1) l’étiquetage des termes et 2) la propagation
des concepts.

1. Les regles sélectives terminales sont appliquées sur le corpus. Lorsque toutes les
regles sont appliquées, tous les termes reconnus par la grammaire sont étiquetés par
des concepts (exemple 3).

2. La propagation des concepts permet de détecter de nouveaux concepts. La regle
A ::= B permet de repérer le concept A en rajoutant les balises de A a celles

llO

Extraction d ’inf0rmati0ns a partir de corpus dégradés

identiﬁant B. Les regles conceptuelles sont appliquées sur le corpus autant de fois
qu’il est possible de le faire. Le processus s’arréte lorsque plus aucune d’entre elles
n’est applicable. A ce point, le corpus est entierement étiqueté par les regles
constitutives (exemple 4).

L'cxtIait [3] deviant aprés propagation des coiuzcpts :

Uextrait [2] deviant apré:-3 l'étiquetage des tennes :
<DC_PROJET>prujet</DC_PROJET>
<DC_ACHAT>achat<fDC_ACHAT>

<DC_PROJET>projet<fDC_PROJET> d
SPQACHf‘-T>‘aCha‘</DC,ACI1AT>* <[MMOBILlER><APPARTEMENT>studio</APPARTEMENT><fIMMOBILIER>
BI‘!
<APPARTEM ENT>sludio<fAPPARTEMENT> <DATE> 11/01 </DATE>f
en <L1EU><V1LLE>puris< V1]_,LE><iL1EU>
DATE I2 01 MDATE 1”“

:VILLE>>pa/]_iS:,fV[LLh>> <SOMME>40(lkf'<fSOMME> [4]

P0111‘ en appliquant les regles : <lMMOBlLlER> ::= <APPARTEMENT>
<SOMME>400kf<!SOMME> [3] <LIEU> ;:= <VlLLE> | <PAYS> \ <REGlON>

Exemple 3 Exemple 4

4.3 Etiquetage prédicatif

Les regles prédicatives reperent les instances des prédicats décrits dans la grammaire. Elles
sont appliquées sur le corpus en recherchant pour chaque descripteur de concept trouvé, un
des concepts objets possibles du prédicat mis en jeu. On cherche a instancier les prédicats
jusqu’a ce qu’il soit impossible de le faire en procédant de la facon suivante. Le texte est
parcouru de gauche a droite. Lorsqu’un descripteur de prédicat est reconnu, on recherche un
argument obj et (concept ou prédicat) Valable pour ce prédicat avant le prochain descripteur de
prédicat non traité. Si c’est le cas l’objet est value, puis le systeme cherche a Valuer les
éventuels autres arguments et passe au prochain descripteur du texte. Sinon ce descripteur est
laissé de coté et le systeme passe au suivant. Cela est fait jusqu’a l’extrémité du texte. S’il
reste des descripteurs non traités, c’est a dire décrivant des prédicats dont l’objet n’a pu étre
Valué, le processus est répété a partir du début du texte. Cette opération est réitérée jusqu’a ce
qu’il ne reste plus de descripteurs a traiter ou que ceux qui restent ne peuvent plus l’étre. Dans
ce demier cas ils seront marques comme décrivant des instances de prédicats Vides (sans
obj et). Un prédicat peut étre obj et d’un autre prédicat. Dans ce cas les arguments du dernier
prédicat sont Valués lorsque cela est possible par ceux du premier prédicat.

l.‘cxtrai1 |-t| dc\':cn1 : _ _ _
['J'ou les In.<I-.1I1<'e:: >'l||\-':Irl[U>«

 

-:I‘R()J[IT In--.n(' PROJ|E'l"-prui.::‘=»'|'}(' r'R{)JIiT>-'--"F'Rt)Jl?.T is ‘*9 F"*'’*“°“'* ='\"”*‘T ~‘1"R‘7“‘-T5
z.I“R()JEIT E.-\ ' 011]!"-.T:» _ _ __ _

‘-i.'\('1|A'i' ]->-=-1J(' N.'H.-‘\'1'I‘an.'11:11<.-DC .-\('!lA'I':..;.-,i\L'lla'\'l' |:- “-M"-'\' '-’| __ _ y__ I
.,_.,.m,JH 1 _,W;__Um,;-,-,. o|;s(__1_u1 1|:L_|{-actual
d. DISH‘. J --sludun
J.-\('H.-'\T |.-'\Rl’i mm-:1‘> "N.*"'1"".'_ _ _ _

-:IM\.Ii'miI .II-.Ru«:.-\ PM R'I'|-MI-.N'I‘.~uI1Jdinm'A PM k't'J-..'u!-.h.—'| -.~-s.-‘IM .\A('JIiII .II-'.k-,~ {Hi  -f!‘‘--_’\_1 H)?‘ Wm“
'-'-’.-\('l|.v'\'|' l:\|l('- om» '”0'“'[-'‘'‘“ ‘l‘’‘’''“'

I.'|l I
u.]‘R()JliT_I ARG l}A'FlE.-- 

--=m'1I»\ I" 1 m::='—n» " " anm'I':=r-I2-In-'.-IM’I'I-..=—r.-‘swimI‘ I M<c'.—n;\'I'I-..- ‘-1’R"”' ' I-"l _ __ _
.._.,.,“_,_..._.- 1_.W; ],,m._, |)i~..H'(.'H|1'||:l‘H--[Irnycl
~'-'PROJi:'T I.-’\R(i LU{_‘!\l.|S!\Tl0}\!»~ ‘“”"3_T “*“-“"‘T ""

1;.-\(‘]InT mm; J.:H"M.|Sr\T|E'JN:~ 0-'\T_F*» '§-'0' ‘ _

<'.[.I[fU:»<t\-'|E.|.|i.-pnri \-'1].[.l  .||"-.[.':» I-UK «_\_l-I3-;\_"J‘I<>='\—Vr-arr»

~:.-'m.'n.-\'|' I .~’\R{j =Lor_'.-\1_15.-\'|'{m::- MUN I -"W l"'1‘3W
- -'|’i{(JJl:'l' 1 a‘\J(ti—~LU('AL]SA'['JIJN  |
‘'10!!!
.:I-sum-fr Inkri Mm~.='r.wr.»

«:.»\r1m':' mum M()N']'a\N'|':--<:.\‘.(')MMF.‘-»d[!tIkf-':.-‘SUMM|-tw:.-‘A(‘|Ia\'I' 1.#\R(i'M('1>.I'l'n>.I'I'I':
-ammn-:'I' mm". Mor~e'I'AM'-~

 

  

Exemple 5

lll

F abrice Even, Chantal Enguehard

Les instanciations de prédicats se traduisent par un balisage du texte (exemple 5). Le
descripteur est étiqueté par la référence du prédicat, c’est a dire son nom et un numéro
d’instance (pour les cas ou un méme prédicat peut étre instancié plusieurs fois dans le texte).
Chaque concept argument d’un prédicat est balisé par la référence du prédicat dont il est
argument et par son type (Obj et, Date, ...).

4.4 Recueil des informations

Les concepts ainsi que leurs relations apparaissent clairement dans le corpus grace aux
balises. Lors de la phase d’extraction, il suffit de spécifier les concepts a rechercher. Les
balises permettent de localiser ces concepts ainsi que leurs différents arguments. Ces
informations nourrissent une base de données dont les tables correspondent aux prédicats de
la grammaire.

5 Résultats

Le corpus est constitué d’un million d’enregistrements. Chaque enregistrement est issu d’un
entretien d’un employé d’une agence de la banque avec un client. 11 se présente sous la forme
d’une ligne constituée d’un entéte numérique et d’un champ texte. L’entéte contient le
numéro d’identifiant et la date de l’enregistrement. Le champ texte contient le texte saisi par
le banquier rendant compte de l’entretien. Le nombre de mots de ce champ Varie d’un
enregistrement a l’autre : de quelques mots a plus d’une trentaine. Avant toute analyse, ce
champ est soumis a un traitement pour le mettre en conformité avec les regles de la CNIL.
L’extraction terminologique avec ANA (Enguehard, Pantéra 1995) déﬁnit 15000 candidats-
terrnes. Apres écrémage (rassemblement des candidats-termes et élimination des parasites), il
reste 1300 termes. Sur les 350 termes qu’ils contiennent, les documents terminologiques ont
fourni 200 nouveaux termes supplémentaires.

5.1 Méthode d’évaluation

Le but de la recherche est d’extraire automatiquement les évenements concernant les clients,
c’est-a-dire leurs projets et les refus de proposition (de leur part ou de celle de la banque). Le
résultat est un ensemble d’instances du prédicat recherché. Comme ces prédicats ont plusieurs
arguments, nous définissons 3 degrés de Validité en fonction de la maniere dont sont Valués
ces arguments :

1. Une instance d’un prédicat est dite Valide si les arguments Valués le sont par les
bonnes Valeurs. Le taux de Validité est le nombre d’instances Valides par rapport au
nombre d’instances trouvées ;

2. Une instance Valide est dite totalement Valide si tous ses arguments sont Valués, et
partiellement Valide si au moins un de ces arguments n’est pas Valué ;

3. Une instance partiellement Valide est dite incomplete lorsqu'au moins un argument
n’est pas value a cause d’un manquement du processus, et complete lorsque la
totalité des arguments non valués est due a l’absence des informations
correspondantes dans le texte.

112

Extraction d ’inf0rmati0ns a partir de corpus dégradés

5.2 Expérimentation

Notre premiere expérimentation porte sur un échantillon de 4000 enregistrements pris au
hasard dans le corpus. Il s’agit d’extraire les projets présents dans cet échantillon. Les
résultats trouvés ont été Validés manuellement par les experts qui ont aligné l’échantillon avec
les instances de la table PROJET créées par notre application. D'apres les experts, 265 projets
sont présents dans cet échantillon dans lequel 253 instances sont détectées. Nous obtenons
les résultats décrits par la ﬁgure 1.

 
   
 
      

Instances Valides: 234

Instances partiellement Valides : 211

Incompletes
55 Completes
155

 
     
  

Instances totalement
Valides ' 23

Figure 1 : Résultats

5.3 Analyse des résultats

Le taux de couverture n’est pas significatif car de nombreux enregistrements ne contiennent
pas de projets (95 %). Les taux de rappel (correspondant au nombre d’instances trouvées par
rapport a celle présentes et égal a 95,4 %) et de Validité (92,5 %) sont tres satisfaisants mais
nombre d’instances ne sont que partiellement Valides (90 % des projets Valides). 73,4 % de
celles-ci le sont en raison de l’incomplétude du corpus qui ne peut nous délivrer toutes les
informations mais le reste est du au processus. Une analyse des enregistrements dans lesquels
ces cas sont observes fait apparaitre deux principaux problemes :

0 un tres grand nombre de dates sont présentes sous une forme littérale de maniere plus
ou moins ﬂoue (au prochain semestre, dans quelques mois) et ne sont pas détectées.

0 des arguments d’un prédicat décrit par un descripteur X peuvent se trouver avant lui
dans le texte ou en dehors de la fenétre de recherche et ne sont pas pris en compte.

Nous travaillons actuellement au reglement de ces deux problemes. Pour le 26“ nous
proposons de modifier le processus d’étiquetage prédicatif pour détecter les arguments
presents a gauche d’un descripteur de prédicat. Quant aux dates, nous introduisons la notion
de date ﬂoue associée a un degré.

6 Conclusion et Perspectives

Nous avons décrit une méthode permettant d’extraire des informations a partir de textes de
qualité dégradée, sur lesquels sont inopérants les processus d’extraction d’inforrnation

ll3

F abrice Even, Chantal Enguehard

existants. Cette approche s’appuie sur la construction d’une ontologie, guidée par la nature
des informations a rechercher dans les textes. Nous obtenons avec cette approche de tres bons
résultats avec une couverture tres importante des informations présentes dans chaque
enregistrement. De plus méme quand celle-ci est minimale, le systeme permet de repérer les
enregistrements dans lesquels est présente une information. Cette méthode peut s’appliquer a
d’autres corpus d’autres domaines. La modélisation du domaine et les prétraitements sont liés
aux textes, mais le reste du processus est générique et ne nécessite pas de modiﬁcation du
systeme. Une expérimentation en ce sens est en cours sur des corpus concemant un domaine
proche de celui de notre corpus actuel (textes de nature similaire d’une autre banque).

Références

Aussenac-GillesN., BiébowB., Szulman S. (2000), Corpus analysis for conceptual
modelling, Proceeding of EKA W’2000, 13-20.

Aussenac-Gilles N., Bourigault D., Condamines A., Gross C. (1995), How can knowledge
acquisition benefit from terminology ?, Proceedings of EKAW’95.

BachimontB. (2001), Modélisation linguistique et modélisation logique des ontologies :
l’apport de l’ontologie forrnelle, Actes d’IC 2001, 349-368

Barry C., Cormier C., Kassel G., Nobécourt J. (2001), Evaluation de langages opérationnels
de représentation d’ontologies, Actes d’IC ’200I, 309-327.

BiébowB., Szulman S. (1998), Une approche terrninologique pour catégoriser les concepts
d’une ontologie, Actes d’IC ’98, 51-58.

Bouaud J., BachimontB., Charlet J., Zweigenbaum P. (1995), Methodological Principles for
Structuring an Ontology, Proceedings of IJCA1-95

Enguehard C., Pantéra L. (1995), Automatic Natural Acquisition of a Terminology, Journal
of quantitative linguistics, Vol. 2, n°1, pp.27-32.

Guarino N., Welty W. (2000), A Formal Ontology of Properties, Proceedings of the ICAI-00
Workshop on Applications of Ontologies and Problem-SolvingMethods, 12/ 1-12/ 8.

Guarino N. (1992), Concepts, Attributes and Arbitrary Relations : Some Linguistic and
Ontological Criteria for Structuring Knowledge Bases, Data & Knowledge Bases
Engineering, 8(2) : 249-261.

Lame G. (2000), Knowledge acquisition from texts towards an ontology of French law,
Proceedings of EKA W’2000, 53-62.

Nobécourt J. (2000), A method to build formal ontologies from texts, Proceedings of
EKAW’2000, 21-27.

Nestorov S. & al. (1997), Representative objects : concise representation of semistructured,
hierarchical data., Proceedings of International Conference on Data Engineering, 79-90.

114

Extraction d ’inf0rmati0ns a partir de corpus degrades

Riloff E. (1996), Automatically Generating Extraction Patterns from Untagged Text,
Proceedings of Ylzirteenth National Conference on Artificial Intelligence, 1044-1049.

Soderland S. (1997), Learning Text Analysis Rules for Domain-specific Natural Language
Processing, Ph.D. thesis, University of Massachusetts, Amherst.

115

