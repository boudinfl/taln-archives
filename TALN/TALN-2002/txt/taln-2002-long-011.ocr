IALIV ZUUZ, Nancy, 24-2’/jum ZUUZ

Filtrages syntaxiques de co-occurrences pour la
représentation vectorielle de documents

Romaric Besancon, Martin Rajman
Laboratoire d’Intelligence Artiﬁcielle
Faculté Informatique et Communications
Ecole Polytechnique Fédérale de Lausanne, (IN) Ecublens 1015 Lausanne
{Romaric.Besancon,Martin.Rajman} @epﬂ.ch

Mots-clefs — Keywords

Similarités textuelles, représentation vectorielle de textes, sémantique distributionnelle, contexte
de co-occurrence
Textual similarities, vector space representation, distributional semantics, co-occurrence context

Résumé - Abstract

L’intégration de co-occurrences dans les modeles de représentation vectorielle de documents
s’est avérée une source d’amélioration de la pertinence des mesures de similarités textuelles cal-
culées dans le cadre de ces modeles (Rajman et al., 2000; Besancon, 2001). Dans cette optique,
la déﬁnition des contextes pris en compte pour les co-occurrences est cruciale, par son inﬂuence
sur les performances des modeles a base de co-occurrences. Dans cet article, nous proposons
d’étudier deux méthodes de ﬁltrage des co-occurrences fondées sur l’utilisation d’informations
syntaxiques supplémentaires. Nous présentons également une évaluation de ces méthodes dans
le cadre de la tache de la recherche documentaire.

The integration of co-occurrence information in the vector-space representation models for texts
has proven to improve the relevance of textual similarities (Rajman et al., 2000; Besancon,
2001). In this framework, the deﬁnition of what is the context considered for the co-occurrences
is an important issue. In this paper, we provide the study of two methods for the ﬁltering of the
co-occurrences, both using additional syntactic information. We also present an evaluation of
these methods in the framework of information retrieval.

135

l\. IJCJIA/ID?!/ID, 171- l\Il/JIILIA/ID

1 Introduction

La notion de similarite entre textes est tres souvent utilisee dans les applications du traitement de
la langue destinees a l’ exploitation de collections de documents de grande taille. Par exemple, en
recherche documentaire, les documents pertinents retournes par le moteur de recherche peuvent
etre deﬁnis comme les plus proches de la requete selon une certaine mesure de similarite (Salton
& McGill, 1983); de meme, le regroupement incremental de documents en classes en fonction
de leurs similarites peut permettre une structuration automatique de bases de donnees textuelles
a l’aide de techniques de classiﬁcation automatique non supervisee (Salton et al., 1975).

La notion de similarite entre documents est evidemment fortement liee au choix de la methode
de representation des textes. La representation la plus utilisee est la representation vectorielle
(mise en oeuvre, en particulier, dans les systemes de recherche documentaire tels que SMART
(Salton, 1971)), dans le cadre de laquelle un document est represente par un vecteur dans un
espace vectoriel dont les dimensions sont associees a des unites linguistiques speciﬁques (mot,
stems, lemmes, etc). La similarite entre documents est alors evaluee par une mesure de similarite
deﬁnie sur cet espace vectoriel.

Des ameliorations peuvent egalement etre apportees dans ce modele de representation par
l’integration de connaissances externes (Besangon, 2001). En particulier, dans l’optique de
la semantique distributionnelle (Rajman et al., 2000), des connaissances de co-occurrences
peuvent etre utilisees pour integrer plus d’informations semantiques dans la representation.
L’ objectif de cet article est d’etudier l’inﬂuence de la methode de selection des co-occurrences
considerees sur la qualite des representations et des mesures de similarite entre documents.

Dans la section 2, nous presentons brievement le modele de representation vectoriel standard,
ainsi que le modele DSIR, qui etend le modele standard par l’integration de co-occurrences dans
la representation des documents. Dans la section 3, nous presentons deux methodes de ﬁltrage
des co-occurrences utilisant des informations syntaxiques pour determiner quelles seront les co-
occurrences effectivement considerees. Enﬁn, dans la section 4, nous proposons une evaluation
de ces methodes de ﬁltrage pour la tache de la recherche documentaire.

2 Le modele de représentation DSIR

2.1 Modéle vectoriel

Dans le cadre du modele vectoriel standard (VS), un document d est represente par un vecteur
dVS = (dl/S, . . . , dllﬁ), appele proﬁl lexical, dans lequel la j° composante d}/S represente le
poids (ou importance), dans le document d, du terme d’indexation tj associe a la j° dimen-
sion de l’espace vectoriel. D’une fagon generale, le poids est le plus souvent une fonction de
la frequence du terme dans le document et se decompose habituellement en une ponderation
locale, une ponderation globale et un facteur de normalisation (par rapport a la longueur du
document). Pour nos experiences, nous avons utilise le schema de ponderation ltn de SMART
(Salton & Buckley, 1988; Singhal, 1997) :

dj” = wj = idf x (1 + log(tf)) (1)

011 tf est la frequence du mot dans le document et idf est le facteur de frequence en document
inverse idf = log d—1f, ou df est la frequence en documents du terme (c’est-a-dire le nombre de

136

I'll/I/I M600 s))’Il«l/Ila/ldrlil/l«Cs) (JD bl/'1/Dbl/l«I ICIDDCO

documents dans lesquels le terme apparait). Dans ce cas, le facteur de pondération locale est
1 + log(tf) , le facteur de pondération globale est idf (ce facteur permet d’accorder un poids
plus important aux termes qui apparaissent moins fréquemment dans la collection et sont donc
plus utiles pour la discrimination). Aucun facteur de normalisation n’est intégré directement
dans cette pondération mais une normalisation implicite est effectuée en utilisant la mesure de
similarité du cosinus, indépendante de la norme.

2.2 Modéle £1 base de co-occurrences

Le modele DSIR est un modele vectoriel permettant d’intégrer des informations sémantiques
supplémentaires par l’utilisation de co-occurrences (Rajman & Bonnet, 1992; Rajman et al.,
2000; Besancon, 2001).

Dans le cadre de ce modele, les unités linguistiques ui considérées sont représentées par un
vecteur ci = (cm, . . . , c,~|T|), appelé proﬁl de co-occurrence, dont chaque composante cij est la
fréquence de co-occurrence de l’unité linguistique ui avec un terme d’indexation tj. Un docu-
ment d est alors représenté comme la somme pondérée des proﬁls de co-occurrence des unités

linguistidues qu’il contient, c’est-a-dire par un vecteur dDS = (d{7S, . . . ,d|1%|S) ou chaque djps
est déﬁni par :
dfs = Z ‘LUZ’ Cij
u,-Ed

ou la pondération wi est celle déﬁnie par l’équation (1).

Notons que, dans le modele DSIR, les termes effectivement présents dans les documents ne sont
pris en compte qu’indirectement, par le biais de leur proﬁl de co-occurrence. Pour cette raison,
un modele DSIR hybride prenant en compte a la fois les occurrences et les co-occurrences des
termes dans les documents a également été proposé (Rungsawang, 1997; Rajman et al., 2000).
Dans ce modele un document est représenté par un vecteur dont la j ° composante est déﬁnie
par :

dJDS=ozwj+(1—oz) Zwicij (2)

u,-Ed

ou oz est le coefﬁcient d’hybridation entre le modele DSIR pur et le modele VS.

3 Filtrage syntaxique des co-occurrences

Le calcul des fréquences de co-occurrence cij dépend bien évidemment en premier lieu des
choix effectués pour ce qui est de la sélection des relations de co-occurrence considérées, et
donc, en particulier, de la déﬁnition des contextes qui seront pris en compte pour le calcul de
ces co-occurrences. Ces contextes peuvent étre de trois types : documentaire, positionnel ou
syntaxique.

L’ approche la plus simple est de considérer soit un contexte positionnel, soit un contexte docu-
mentaire et donc de calculer, a partir d’un corpus de référence, toutes les co-occurrences entre
toutes les unités linguistiques prises deux a deux dans une fenétre de taille donnée (contexte po-
sitionnel) ou sur une unité documentaire donnée, comme la phrase ou le paragraphe par exemple
(contexte documentaire).

137

l\. IJCJIA/ID?!/ID, 171- l\Il/JIILIA/ID

Ces deux approches simples peuvent néanmoins s’avérer insufﬁsantes. En effet, dans l’une
comme dans l’autre, des co-occurrences non linguistiquement pertinentes peuvent étre prises
en compte. Prenons par exemple le contexte représenté par la phrase suivante :

<< L’acteur porte an masque grimagam,‘ de théatre antique. >>

Une premiere phase de pré-traitement permet d’identiﬁer les unités linguistiques qui com-
posent la phrase. Par exemple, si les unités considérées sont les lemmes associés a leur étiquette
morpho-syntaxique, on obtient :

le|Ds acteur|Ncms p0n‘er|Vs un|Dms masque|Ncms grimagam,‘|Ams de|s the’atre|Ncms antique] As

Si l’on calcule alors les co-occurrences sur l’ensemble de la phrase, des co-occurrences per-
tinentes comme (masque—grimagam,‘) ou (the’atre—antique) seront effectivement sélectionnées,
mais des co-occurrences croisées comme (acteur—antique) ou (théatre—grimagam,‘), qui semblent
en revanche beaucoup moins pertinentes (et, en tout cas, ne sont pas suggérées par la structure
de la phrase) seront également prises en compte.

L’ utilisation, dans la déﬁnition des contextes, d’une information supplémentaire sur les dépen-
dances syntaxiques entre les unités linguistiques de la phrase permet une déﬁnition plus ﬁne des
co-occurrences a considérer (Rajman, 1995; Rungsawang, 1997).

Nous présentons dans les deux sections suivantes deux approches possibles : la premiere re-
pose sur l’idée d’un ﬁltrage des co-occurrences, l’objectif étant d’éliIniner certaines des co-
occurrences non souhaitées, sans faire d’hypotheses sur les co-occurrences restantes ; la seconde
repose sur l’idée d’une sélection des co-occurrences, l’objectif étant cette fois-ci de ne garder
que les co-occurrences syntaxiquement fondées, et de rejeter toutes les autres.

Dans les deux cas, les relations de co-occurrence prises en compte seront synthétisées dans
un graphe de co-occurrences, dans lequel les noeuds sont associés aux unités linguistiques
considérées et les arcs représentent les relations de co-occurrence. Un exemple de tels graphes
est donné dans le tableau récapitulatif de la ﬁgure 1 a la ﬁn de la section 3.

3.1 Filtrage par les groupes syntaxiques

Dans l’exemple donné ci-dessus, une catégorie de co-occurrences qui paraissent clairement non
pertinentes sont les co-occurrences entre un nom et un adjectif qui qualiﬁe un autre nom de la
phrase (des co-occurrences du type (acteur-antique) ou (théatre-grimagam,‘)). L’ objectif de la
méthode de ﬁltrage proposée dans cette section est donc d’éliIniner ce type de co-occurrences.

Pour ce faire, nous utilisons un analyseur syntaxique de surface (shallow parser) pour produire
les groupes syntaxiques élémentaires correspondant a la structure de la phrase, associés chacun
a une unité linguistique particuliere représentant la téte du groupe (en pratique, la téte d’un
groupe nominal est le nom de ce groupe, et la téte d’un groupe verbal est le verbe principal
— i. e. pas les auxiliaires). Les seules co-occurrences considérées sont alors les co-occurrences
entre unités linguistiques d’un meme groupe syntaxique ou entre tétes de différents groupes
syntaxiques (Besancon et al., 1999). Cela permet effectivement d’éviter de prendre en compte
des co-occurrences entre des unités linguistiques qui seraient toutes deux des dépendances dans
des groupes syntaxiques différents, ou entre des unités linguistiques qui seraient l’une la téte
d’un groupe syntaxique et l’autre une dépendance dans un autre groupe syntaxique.

Apres lemmatisation, un découpage en groupes syntaxiques de la phrase d’eXemple pourrait

138

I'll/I/I M600 s))’Il«l/Ila/ldrlil/l«Cs) (JD bl/'1/Dbl/l«I ICIDDCO

étre le suivantl :

(( le|Ds *acteur|Ncms )( *p0n‘er|Vs ) ( un|Dms *masque|Ncms grimagam,‘|Ams ) ( de|s *the’dtre|Ncms
am,‘ique|As ))

ou les groupes syntaxiques sont délimités par les parentheses et les tétes des groupes sont iden-
tiﬁées par le symbole << * >> antéposée.

3.2 Sélection par les relations syntaxiques

La seconde approche proposée repose sur l’idée de sélectionner les << bonnes >> co-occurrences,
i. e. les co-occurrences a conserver en raison de leur pertinence syntaxique.

La méthode retenue pour cette approche repose sur l’utilisation des résultats d’une analyse syn-
taxique produisant différentes relations syntaxiques entre les unités linguistiques de la phrase,
comme par exemple les relations de type sujet-verbe (SUJ), verbe-objet (OBJ), complément de
nom (CNOM), ou qualiﬁcation d’un nom par un adjectif (ADJ). Les seules co-occurrences qui
sont alors considérées sont celles entre les unités qui sont effectivement reliées par une relation
syntaxique identiﬁée.

Par exemple, les relations syntaxiques produites par l’analyseur syntaxique XeLDA de Xerox
(Xerox, 1990) pour la phrase d’eXemple sont :

SUJ(acteur, porter)

OBJ (porter, masque)
ADJ (masque, grimagant)
ADJ (thédtre, antique)
CNOM(masque, thédtre)

Les graphes de co-occurrences produits pour la phrase d’eXemple pour chacune des méthodes
présentées sont indiqués dans le tableau récapitulatif de la ﬁgure 1. Dans tous les cas, un pré-
traitement ne gardant que les lemmes des noms, des verbes et des adjectifs a été réalisé.

Deux constatations peuvent étre faites sur la base de l’exemple traité : d’une part, les méthodes
de ﬁltrage/sélection réduisent comme prévu le nombre de co-occurrences prises en compte, en
éliminant les co-occurrences entre termes non liés syntaxiquement. D’autre part, on remarque
qu’elles présentent néanmoins certains inconvénients : en particulier, la sélection sur la base des
relations syntaxiques supprime les co-occurrences entre sujet et objet de l’action (ici << acteur >>
et << masque >>), de meme que des co-occurrences comme << acteur—the’dtre >>, qui pourraient
toutes deux sembler sémantiquement pertinentes.

4 Evaluation

L’évaluation des méthodes de ﬁltrage syntaxique des co-occurrences a été effectuée pour la
tache de la recherche documentaire. Les résultats présentés ici ont été obtenus sur des données
provenant de la seconde campagne d’évaluation AMARYLLIS (Coret et al., 1997; Landi et al.,
1998), présentées dans le tableau 1.

1Ce parenthésage a été produit par l’ana1yseur syntaxique Sylex.

139

l\. IJCJIA/ID?!/ID, 171- l\Il/JIILIA/ID

<< L’acteur porte un masque grimagant de theatre antique >>

 

contexte co-occurrences
/ acteur
(a) acteur porter masque porter
contexts grimag:ant theatre ,L _
. . . theatre — rimagant
pos1t1onnel antique \ _ .
antique
(b) ( *acteur) / aCte”r\
ﬁltrage par ( *p0rter) porlte/r jmaslque
les groupes (*masque grimagant) the’atre\ grimagant
syntaxiques ( *the’atre antique) antique
(c) SUJ(acteur,porter) / acteur
sélection OBJ(porter,masque) ponyerj masque
par les ADJ (masque,grimacant) M _ '
. ,,, . th 1‘ t
relations ADJ (theatre,ant1que) ea re\aml_ uirlmagan
syntaxiques CNOM(masque,théatre) q

FIG. 1 — Exemples de graphes de co-occurrences , (a) toutes les co-occurrences, (b) avec ﬁltrage
des co-occurrences par les groupes syntaxiques, (c) avec sélection des co-occurrences sur les
relations syntaxiques.

Corpus Sujet type nom Nb docs Nb mots
extraits de livres sur la documents md1 355 428803
LRSA Mélanésie requetes mt1 15 1301
OFIL articles extraits du documents od1 11016 4915890
journal << Le Monde >> requetes ot1 26 1412
INIST notes bibliographjques documents od1 163308 13678485
requetes ot1 30 2022

TAB. 1 — Données utilisées pour les tests, provenant de la campagne AMARYLLIS

Filtrage des co-occurrences par les groupes syntaxiques Dans une premiere phase, les cor-
pus ont été analysés a l’aide d’un analyseur syntaxique (SYLEX, de INGENIA-LN (Constant,
1995)) pour déterminer les categories morpho-syntaxiques des mots ainsi que leurs lemmes.
Des lexiques ont alors été extraits, comprenant les lemmes des noms, verbes et adjectifs appa-
raissant dans les corpus. Ces lexiques forment l’ensemble U des unités linguistiques qui seront
considérées. L’ ensemble T des termes d’indexation a été créé a partir de U en sélectionnant les
unités linguistiques de fréquence en documents comprise entre 11% et 1%, avec D l’ensemble des
documents du corpus. Les matrices de co-occurrence (de dimension |U | X |T |) ont été construites
pour les corpus LRSA, OFIL et INIST, en utilisant des contextes positionnels (matrices Cm, CO,
C, respectivement), puis en utilisant le ﬁltrage par les groupes syntaxiques (matrices C;",f, 055,
Cf”). Le tableau 2 présente la taille des lexiques et des matrices de co-occurrences, en indi-
quant également pour ces dernieres le taux de remplissage t, (c’est-a-dire le pourcentage de
co-occurrences de fréquence non nulle parIr1i les |U | X |T| co-occurrences possibles), et le taux
tﬂs de diminution du nombre de co-occurrences prises en compte par rapport a l’approche sans
ﬁltrage syntaxique. Il est a noter que l’utilisation du ﬁltrage syntaxique permet une réduction
d’environ 25 a 30% des matrices manipulées.

140

I'll/I/I M600 s))’Il«l/Ila/ldrlil/l«Cs) (JD bl/'1/Dbl/l«I ICIDDCO

Les performances obtenues avec le modele de représentation DSIR hybride (avec un coefﬁcient
d’hybridation alpha = 0.5) sont présentés pour les trois corpus dans les tableaux 2. Les mesures
d’évaluation choisies sont les suivantes : précision moyenne (notée avg _p), R-précisionz (notée
R_p), les précisions a plusieurs points de coupure (la précision a N documents est notée pN),
le nombre total de documents pertinents retoumés par le systeme (notée relret), et le rappel
ﬁnal a 1000 documents (noté r1000). Les résultats sont présentés en indiquant les pourcentages
d’ amélioration par rapport a un résultat de base (présent dans la premiere colonne des tableaux),
avec le coefﬁcient de risque pw du test de Wilcoxon qui lui est associé (Van Rij sbergen, 1979).
Cette valeur indique la conﬁance que l’on accorde au fait que la différence mesurée n’est pas due
au hasard (plus la valeur de pw est petite, plus l’hypothese que la différence médiane est nulle
peut étre rej etée, et on peut donc conclure que les résultats sont signiﬁcativement différents).

taille des lexiques et des matrices LRSA
de co-occurrences Cm 0‘ = 0-5 055 0‘ = 0-5
aVg_p 0.3942 0.4048 (+2.69%),,u,:0.012
LRSA OFIL INIST R_p 0.3993 0.4087 (+2.35%)pw:0.44
unités p5 0.6533 0.6667 (+2.05%)pw:0.75
M 9762 28691 23390 p10 0.6333 0.62 (—2.15%),,w:0_38
m 4635 2796 3398 p15 0.5422 0.5422 (+0%)pw:1
_ p20 0.47 0.4867 (+3o55%)pw:0.16
matr1ce Cm 00 Ci p30 0.3911 0.4022 (+2.84%)pw:0.31
“"113 3M0 25 M0 10 M0 p100 0.19 0.1927 (+1.42%)pw:0.58
tr 155% 8-11% 3-05% p200 0.1197 0.12 (+0.251%%w:0.31
matrice 073? 05” Ci” p500 0.0509 0.0515 (+1.18%%w:0_12
taille 2M0 20 M0 7M0 p1000 0.0255 0.0257 (+0.784%)pw:0.12
tr 114% 6-16% 3-04% relret 382 386 (+1.05%)pw:0.12
1533 31.7% 24.1% 23.8% r1000 0.9031 0.9125 (+1.05%)pw:0.12
INIST OFIL
C'¢oz=0.5 C';qsoz=0.5 C',,oz=0.5 C'g3oz=0.5
aVg_p 0.1095 0.111 (+1.37%)pw:0_39 0.196 0.1867 (-4.98%),,w:0_84
R_p 0.1581 0.1595 (+0.886%),,w:0_53 0.2333 0.2308 ('1.08%)pw:0_81
p5 0.3 0.3133 (+4.43%),,w:0_55 0.3538 0.3308 ('6.95%)pw:0_5
p10 0.24 0.2633 (+9.71%),,w:0_15 0.2769 0.2846 (+2.78%)pw:0_54
p15 0.2156 0.2133 (-1.08%)pw=0.64 0.2462 0.2333 ('5.53%)pw:0_23
p20 0.2083 0.2067 (—0.774%)pw:0.89 0.2269 0.2154 (-5.34%)pw:0_18
p30 0.1833 0.18 ('1.83%)pw:0_45 0.1949 0.1949 (+0%),,w:0.76
p100 0.103 0.107 (+3.88%)pw:0_1g 0.1008 0.0969 ('4.02%)pw:0_11
p200 0.071 0.0748 (+5.35%)pw:0_018 0.0604 0.0581 ('3.96%)pw:0_22
p500 0.0317 0.0324 (+2.21%)pw=o.12 0.0248 0.0246 (-0.813%),,w:0_73
pl000 0.0159 0.0162 (+l.89%)pw=0.074 0.0124 0.0123 (-0.813%),,w:0_g2
relret 476 486 (+2.1%)pw:0_1 322 320 (—0.625%),,w:0.57
r1000 0.3383 0.3454 (+2.1%)pw:0.039 0.5486 0.5451 (—0.625%),,w:0.57

TAB. 2 — Résultats sur les corpus LRSA, OFIL et INIST pour le ﬁltrage des co-occurrences par
les groupes syntaxiques (les résultats en gras indiquent les résultats signiﬁcativement meilleurs

(pm < 0.5))

2La R-precision est la precision obtenue pour un nombre de documents retoumes correspondant au nombre de
documents pertinents presents dans la base. Donc en particulier, dans ce cas, la precision est égale au rappel.

141

l\. IJCJIA/ID?!/ID, 171- l\Il/JIILIA/ID

Une premiere analyse globale de ces résultats indique que le ﬁltrage par les groupes syn-
taxiques ne change pas les performances de facon tres signiﬁcative. Ce résultat est en lui-méme
intéressant car il montre que, malgré une réduction de l’information de co-occurrence de l’ordre
de un quart a un tiers, le systeme ne subit aucune dégradation signiﬁcative des performances.
I1 semble donc que la méthode de ﬁltrage choisie est efﬁcace, et permet de n’éliIr1iner majo-
ritairement que des co-occurrences qui n’apportent pas d’autres d’informations utiles pour la
représentation que celles déja prises en compte par les co-occurrences conservées.

Une analyse plus attentive montre meme qu’on observe en fait de légeres améliorations (< 5%)
sur les corpus LRSA et INIST, pour lesquelles les coefﬁcients de Wilcoxon indiquent qu’elles
sont signiﬁcatives (i. e. elles ne sont pas dues au hasard). Cela montre que les co-occurrences
supprimées peuvent également correspondre a du << bruit >>, i. e. de l’information non utile pour
la représentation des documents et dont la suppression permet donc une amélioration des perfor-
mances. Notons que, pour le corpus OFIL, les performances sont plutot légerement dégradées,
mais les coefﬁcients de Wilcoxon associés indiquent que cette dégradation n’est souvent pas
signiﬁcative.

Sélection des co-occurrences par les relations syntaxiques Pour cette seconde méthode, la
production des relations syntaxiques a été réalisée a l’aide de l’analyseur syntaxique XeLDA
de Xerox (Xerox, 1990). L’ensemble des unités linguistiques et l’ensemble des termes d’in-
dexation sont donc différents de ceux utilisés dans les évaluations précédentes. Les principales
caractéristiques des données utilisées sont présentées dans le tableau 3 ou l’on trouve les tailles
des ensembles d’unités linguistiques et celles des matrices de co-occurrences construites sur le
corpus OFIL. Cm, représente la matrice sans ﬁltrage syntaxique et 0;"; la matrice avec sélection
sur les relations syntaxiques. Le pré-traitement syntaxique étant relativement long, les tests sur
les autres corpus n’ont pas été effectués.

L’analyse de ces données indique de facon tres claire que la sélection par les relations syn-
taxiques est beaucoup plus restrictive que le ﬁltrage par les groupes syntaxiques. Le nombre de
co-occurrences conservées est en effet réduit de plus de 80%.

Pour ce qui est des performances, les résultats de la recherche obtenus pour le corpus OFIL sont
présentés dans le tableau 3. L’ analyse de ces résultats permet de conclure a une forte diminution
(statistiquement signiﬁcative) des performances. Cette diminution est tres probablement liée a
une trop forte réduction de l’information de co-occurrence utilisée et peut étre également due
a la qualité moyenne des relations syntaxiques extraites, qui ne sont pas toutes identiquement
ﬁables.

I1 apparait donc que, si un ﬁltrage syntaxique peut étre bénéﬁque, la Inise en oeuvre de contraintes
de sélection trop fortes entraine une diminution des performances. Une interprétation possible
de cet état de fait peut étre que certaines co-occurrences, qui ne reposent pas sur des relations
syntaxiques, peuvent malgré tout correspondre a une information sémantique sous-jacente, et
qu’un ﬁltrage trop brutal entraine la perte de cette information utile a la bonne représentation
des documents.

Le mécanisme de ﬁltrage des co-occurrences doit donc trouver un juste équilibre entre la
nécessaire élimination de co-occurrences inutiles ou génératrices de bruit dans la représentation
d’une part et la conservation de la maj orité de l’information utile a la représentation. Si le ﬁltrage
devient trop sélectif, la matrice de co-occurrence se creuse et devient donc plus discriminante,
mais au-dela d’un certain seuil de réduction, le pouvoir de discrimination accru ne semble plus

142

I'll/I/I M600 s))’Il«l/Ila/ldrlil/l«Cs) (JD bl/'1/Dbl/l«I ICIDDCO

taille des lexiques et des matrices de

0055 oz = 0.5 0;; 04 = 0.5
°°'°°°““e“°eS aVg_p 0.1077 0.0717 (—50.2%)pw:0_0018
    
unites P ' ' ' ' 0 ”“’:°'11
p10 0.188 0.136 (-38.2%),,w:0_037
|U| 20158 p15 0.1653 0.1227 (—34.7%)pw:0_02
l_T| 1992 p20 0.154 0.108 (—42.6%),,w:0_0052
matrrce Cox p30 0.1293 0.0987 (-31%)pw:0_015
tallle 17 M0 p100 0.0684 0.052 (—31.5%)pw:0_001
_tr 10.6% p200 0.0426 0.0324 (—31.5%)pw:0_0002
matrice     (-27%)pw=0_00017
taille 3 Mo pl000 0.009 0.007 (-28.6%)pw:0_000g
15¢  relret 224 176 (-27.3%)pw=0_00017
15,1 81.1% r1000 0.3875 0.3045 (—27.3%)pw:0_00034

TAB. 3 — Resultats sur le corpus OFIL pour la selection des co-occurrences par les relations
syntaxiques

contrebalancer la perte d’information. Dans nos experiences, le ﬁltrage des co-occurrences par
les groupes syntaxiques semble constituer un comprornis efﬁcace alors que la selection des
co-occurrences par les relations syntaxiques privilegie trop la reduction d’information et mene
donc a une degradation des performances.

5 Conclusion

Nous avons presente dans cet article l’etude de deux methodes de ﬁltrage syntaxique pour le
calcul des co-occurrences prises en compte dans une representation vectorielle distributionnelle
des documents : d’une part, une methode prenant en compte un ﬁltrage reposant sur les groupes
syntaxiques, et d’autre part une methode prenant en compte un mecanisme de selection fonde
sur les relations syntaxiques. Ces deux methodes ont ete testees dans le cadre de la recherche
documentaire et ont montre que le ﬁltrage du premier type permet non seulement d’eliminer
un nombre important de co-occurrences dont la disparition n’altere pas les performances, mais
egalement de ﬁltrer des co-occurrences qui introduisent du bruit dans la representation et dont
l’elirr1ination est donc beneﬁque. Le ﬁltrage du deuxieme type semble quanta lui trop restrictif
et deteriore de facon signiﬁcative les performances du systeme.

Du fait du faible gain en performance observe dans nos experiences, il apparait que les in-
formations sur les groupes syntaxiques permettent essentiellement de reduire le volume des
donnees de co-occurrences a manipuler sans degradation des resultats. Pour ce qui est des
relations syntaxiques, cette information nous parait interessante malgre les resultats negatifs
observes lors de nos experiences et d’autres methodes d’integration devraient etre envisagees
pour ces donnees. Une piste de recherche interessante pourrait par exemple etre de typer les co-
occurrences, de facon par exemple a preserver dans la representation la distinction entre les co-
occurrences de type sujet-verbe ou verbe-objet, ou entre les co-occurrences de type tete-tete ou
tete-dependance. Une autre piste pourrait etre d’etudier l’apport de representations semantiques
du type predicat-argument pour la selection des co-occurrences (cela permettrait en particulier

143

l\. IJCJIA/ID?!/ID, 171- l\Il/JIILIA/ID

de retrouver les co-occurrences sujet-objet a travers un prédicat verbal).

D’autre part, les résultats présentés restent des résultats quantitatifs globaux et une étude qua-
litative plus ﬁne serait nécessaire pour permettre de conﬁrmer les intuitions dégagées de cette
premiere évaluation.

Références

BESANQON R. (2001). Integration de connaissances syntaxiques et sémantiques dans les
representations vectorielles de textes. PhD thesis, Ecole Polytechnique Fédérale de Lausanne.

BESANQON R., RAJMAN M. & CHAPPELIER J .-C. (1999). Textual similarities based on a distribu-

tional approach. In Proceedings of the Tenth International Workshop on Database and Expert Systems
Applications (DEXA’99), p. 180-184, Firenze (Italy).

CONSTANT P. (1995). Manuel de développement S YLEX-BASE. INGENIA-LN, Paris, France.

CORET A., KREMER P., LANDI B., SCHIBLER D. & SCHMITT L. (1997). Towards a methodology
for evaluating information retrieval systemsadapted to textual documents in the french language 2 the
amaryllis exploratory cycle. In SALT Workshop on Evaluation in Speech and Language Technology,
Shefﬁeld, UK.

LANDI B., KREMER P. & SCHMITT L. (1998). Amaryllis 2 an evaluation experiment on search engine in
a french-speaking context. In Proceedings of the First International Conference on Language Resources
and Evaluation (LREC), Granada, Spain.

RAJMAN M. (1995). Apports d ’une approche a base de corpus aux techniques de traitement automa-
tique de langage naturel. PhD thesis, ENST, Paris.

RAJMAN M., BESANQON R. & CHAPPELIER J .-C. (2000). Le modéle DSIR 2 Une approche a base

de sémantique distributionnelle pour la recherche documentaire. Traitement Automatique des Langues,
41(2), 549-578.

RAJMAN M. & BONNET A. (1992). Corpora-base linguistics 2 new tools for natural language proces-
sing. In 1 st Annual Conference of the Association for Global Strategic Information, Bad Kreuznach,
Germany.

RUNGSAWANG A. (1997). Recherche Documentaire a base de sémantique distributionnelle. PhD thesis,
ENST, Paris.

G. SALTON, Ed. (1971). The SMART Retrieval System — Experiments in Automatic Document Proces-
sing. Prentice Hall.

SALTON G. & BUCKLEY C. (1988). Term weighting approaches in automatic text retrieval. Information
Processing and Management, 24, 513-523.

SALTON G. & MCGILL M. (1983). Introduction to Modern Information Retrieval. McGraw Hill.

SALTON G., WONG A. & YANG C. S. (1975). A vector space model for automatic indexing. Commu-
nications of the ACM, 18(11), 613-620.

SINGHAL A. (1997). Term Weighting Revisited. PhD thesis, Department of Computer Science, Cornell
University.

VAN RIJSBERGEN C. (1979). Information Retrieval. London 2 Buttherwords.

XEROX (1990). Xelda 2 Xerox linguistic development architecture.
http 2//www.xrce.xerox.corn/ats/xelda/.

144

