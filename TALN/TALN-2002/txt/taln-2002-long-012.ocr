IALIV ZUUZ, Nancy, 24-2’/jum ZUUZ

WSIM : une méthode de détection de theme fondée sur la
similarité entre mots

Armelle BRUN, Kamel SMAILI, J ean-Paul HATON
LORIA BP 239 54506 Vandoeuvre-Les-Nancy, France -
Tel : (33|0) 3-83-59-20-97, Fax :(33|0) 3-83-41-30-79
{brun, smaili, jph} @loria.fr

Résumé - Abstract

L’ adaptation des modeles de langage dans les systemes de reconnaissance de la parole est un
des enjeux importants de ces dernieres années. Elle permet de poursuivre la reconnaissance en
utilisant le modele de langage adéquat : celui correspondant au theme identiﬁé.

Dans cet article nous proposons une méthode originale de détection de theme fondée sur des
vocabulaires caractéristiques de themes et sur la similarité entre mots et themes. Cette méthode
dépasse la méthode classique (TFIDF) de 14%, ce qui représente un gain important en terme
d’identiﬁcation. Nous montrons également l’intérét de choisir un vocabulaire adéquat. Notre
méthode de détermination des vocabulaires atteint des performances 3 fois supérieures a celles
obtenues avec des vocabulaires construits sur la fréquence des mots.

Speech recognition systems beneﬁt from statistical language model adaptation, which is cur-
rently one of the most important challenge. This adaptation may go through the use of a parti-
cular language model : the one of the topic identiﬁed. In this article, a new and original topic
identiﬁcation method is presented, it is based on the similarity between words and topics. The
performance of this method overcomes the one of reference, the TFIDF. The increase is 14% of
topic identiﬁcation.

The importance of the choice of topic vocabularies is also put forward. A judicious way to
create them, instead of choosing the most probable words, makes performance triple.

Mots-clefs — Keywords

Reconnaissance de la parole, modélisation statistique du langage, détection de theme, informa-
tion mutuelle, similarité.

Automatic speech recognition, statistical language modeling, topic detection, mutual informa-
tion, similarity.

145

11. JJII/LIL, IX. LJIILIA/LI/Ir, Jul. . llil/I/I./Il«

1 Introduction

Les modeles de langage (MLs) sont utilises dans de nombreux domaines comme la reconnais-
sance de la parole, la traduction automatique, la recherche d’informations, la reconnaissance
de l’ecriture, etc. Les performances d’un systeme de reconnaissance automatique de la parole,
notamment, sont fortement dependantes des modeles de langage.

Un ML a pour but de modeliser le comportement de la langue. Ainsi, un ML statistique la repre-
sente sous la forme d’une distribution de probabilites de sequences de mots. Dans le cas d’un
systeme de reconnaissance de la parole, le score fourni par le module acoustique, qui represente
la correspondance entre le signal et une suite de mots donnee, est combine avec celui fourni par
le modele de langage, qui represente la vraisemblance de cette meme sequence. La sequence de
mots correspondant au meilleur score sera celle retenue par le systeme.

Les modeles de langage les plus utilises sont les modeles de type n-grammes, qui evaluent la
probabilite d’un mot sachant les n — 1 mots precedents. Le principal avantage de ces modeles
reside dans leur simplicite de Inise en oeuvre. Cependant, lors de leur construction, on est sou-
vent confronte a des problemes de manque de donnees, resolus par l’utilisation de methodes de
lissage (cf (Chen & Goodman, 1996) pour une synthese de ces methodes). Plus la valeur de 71.
est elevee, plus le probleme du manque de donnees est important. Par consequent, en pratique,
la valeur de n excede rarement 3 (modele trigrammes). Cependant, il est evident que la quantite
d’information prise en compte par ces modeles pour evaluer la probabilite d’un mot est large-
ment inferieure a celle qui joue effectivement un role lors de la prediction d’un mot. Pour cette
raison, de nombreux travaux ont ete menes dans le but d’augmenter la taille de l’historique pris
en compte : (Kuhn & De Mori, 1990) integrent un cache au modele de langage, ce qui a pour
consequence d’augmenter la probabilite des mots deja apparus dans l’historique. Dans le meme
ordre d’idees, (Rosenfeld, 1996) y integre des triggers de mots. Recemment, (Chelba & J elinek,
2000) ont developpe un modele de langage qui combine un modele n-grammes, un analyseur
et un etiqueteur, permettant ainsi d’exploiter des mots apparaissant tres loin dans l’historique.
Dans notre cas, nous travaillons dans l’hypothese que le langage, ou plus exactement son vo-
cabulaire caracteristique, varie en fonction du theme traite. Il est donc utile, toujours dans le
but d’augmenter l’information prise en compte pour predire un mot, de chercher a connaitre le
theme d’un texte pour ensuite adapter le ML a ce theme.

Nous nous interessons tout particulierement a cette phase de recherche du theme d’un texte.
Dans cet article, nous proposons une nouvelle methode de detection de themes, WSIlV[ (Word
SIMilarity), fondee non seulement sur la probabilite des mots dans les themes, unique infor-
mation habituellement exploitee, mais egalement sur la similarite des mots avec les themes et
l’utilisation de vocabulaires caracteristiques.

La section 2 explique en quoi les taches de categorisation de textes et detection de themes sont
similaires puis presente un etat de l’art des methodes de categorisation de textes. Nous introdui-
sons, en section 3, les principes de notre methode de detection de themes, dont les performances
seront etudiees, et comparees a d’autres methodes, en section 4. Enﬁn, nous conclurons et pre-
senterons quelques perspectives.

146

VVLJIIVI. . WILD IILCI/Ill/(1/0 ll/C ll/Cl/Dbl/Ll/Il« (JD I/ILCIILC J1/IMJCC OI/DI I/It Olrlllvlrl/Ilrl Ll/C CID!/ID Illvl/IA)

2 La détection de thémes

2.1 Déﬁnition

Soit un document di et 0 = {C1, . . . , CJ} un ensemble de classes. La catégorisation de textes
est la tache qui consiste a assigner une ou plusieurs classes a d,~. Pour cela, nous disposons
d’un corpus dit “d’apprentissage” composé d’un ensemble de documents dont la(es) classe(s)
d’appartenance sont connues. Le systeme de détection de theme est ensuite entrainé sur cet en-
semble d’apprentissage, dans le but de correctement catégoriser un nouveau document. Dans
notre cas, une classe peut étre assimilée a un theme, l’objectif étant de retrouver le theme ck du
document d,~.

2.2 Les travaux en catégorisation

Les méthodes classiques de catégorisation exploitent l’information contenue dans le document
pour déterminer sa classe. Dans la majorité des cas, ce sont les mots qui sont utilisés pour
représenter cette information.

Le probleme de la catégorisation de textes a été largement étudié, nous en présentons ici plu-
sieurs grandes approches, parmi les plus utilisées.

Le document est tout d’abord transformé sous la forme d’un Vecteur o1‘1 chaque élément re-
présente “grossierement” le poids d’un mot dans le document. Dans de rares cas, comme par
exemple les arbres de décision binaires, ce Vecteur contient des valeurs booléennes, représen-
tant la présence ou non du mot dans le document : 1 si le mot est present, 0 sinon, voir (Lewis
& Ringuette, 1994).

Certaines méthodes sont fondées sur une approche probabiliste, elles évaluent la probabilité de
chaque classe sachant le document donné. Le modele unigramme thématique est l’exemple le
plus connu de ces classiﬁeurs (Mc Donough & Ng, 1994).

On peut a nouveau citer les arbres de décision (Mitchell, 1996). Chaque noeud représente un
terme et chaque branche un test sur la fréquence de ce terme dans le document. Enﬁn les feuilles
représentent une classe. La classe affectée au document est celle qui correspond a la feuille ob-
tenue par parcours de l’arbre.

Dans l’approche par réseaux de neurones (Dagan et al., 1997), le document a classer est pré-
senté a l’entrée du réseau. La couche de sortie, quanta elle, représente l’ensemble des classes.
Apres activation du réseau, les valeurs de la couche de sortie représentent les classes possibles
du document.

Enﬁn les Machines a Vecteur Support (SVMs), sont une famille de classiﬁeurs qui minimise une
borne supérieure sur l’erreur de généralisation. Elles sont fondées sur la séparation de données
par hyperplan. Elles ont été appliquées a la catégorisation de textes dans (J oachims, 1998).

Les approches présentées ci-dessus ne sont pas exhaustives, on peut également citer les classi-
ﬁeurs a base de regles de décision (Apté et al., 1994), a base de régression avec notamment le
modele LLSF (Yang & Chute, 1994), la méthode Rocchio (Joachims, 1997) avec tout particu-
lierement la TFIDF (Salton, 1991; Seymore & Rosenfeld, 1997), etc.

Certaines études ont également été menées en vue de l’eXploitation d’informations de plus haut
niveau que le mot. Ainsi, (Lewis, 1992) integre des séquences de mots extraites en accord
avec une grammaire, et (Caropreso et al., 2001) des séquences de mots de nature purement

147

11. JJII/LIL, IX. LJIILIA/LI/Ir, Jul. . llil/I/I./Il«

statistique. Les deux approches n’ont montré aucune amélioration des performances.

3 Description de WSIM

Dans cet article, nous proposons une nouvelle méthode de détection de theme, WSIM. Nous
pouvons la classer dans la famille des méthodes probabilistes. Chaque theme est représenté
par un vecteur, ou chaque élément représente un mot. Contrairement aux méthodes classiques
comme la TFIDF (Seymore & Rosenfeld, 1997), les éléments du vecteur ne représentent pas
uniquement le poids du mot dans le theme, celui-ci est combiné avec leur “similarité”. La simi-
larité entre un mot 33 et un theme Tj est fondée sur la similarité entre ce mot et l’ensemble des
mots caractéristiques du theme Tj.

3.1 La mesure de similarité entre deux mots

(Dagan et al., 1999) introduit une mesure de similarité entre 2 mots :3 et 3/, évaluée en se basant
sur leurs comportements respectifs en contexte (droit et gauche). Plus précisément, deux mots
sont considérés comme similaires si leurs informations mutuelles avec l’ensemble des autres
mots du vocabulaire sont proches. Cette similarité est évaluée de la maniere suivante :

1 1“ mm<I<z.,x>,I<z.,y>> + mm<I<x,z.>,I<y,z.>>

W 1.21 ma1:(I(z,~,:3),I(z,,y)) mad: (I(a3, z,~), I(y,  (1)

Sz'mz'la7"z'te(:3, y) =

on V est le vocabulaire et I (z,, :3) est l’information mutuelle entre les mots z,~ et :3.

Cette mesure a été initialement développée dans le but d’ estimer la probabilité de cooccurrences
de mots, non observées a l’apprentissage. Nous avons adopté cette mesure pour développer
une méthode permettant d’identiﬁer le theme d’un document. Cette méthode est fondée sur
l’information mutuelle I calculée sur une fenétre glissante de 31 mots, la nature de la similarité
est donc plus sémantique que syntaxique. I (z,~, :3) est évaluée de la maniere suivante :

I(z,~,:3) = Pd(z,~,:3) l 
o1‘1 d représente la distance ou la taille de la fenétre glissante. Pd(z,~, 33) est la probabilité de
succession des mots z,~ et :3 a une distance au plus 31. P(a3) représente la probabilité a priori du
mot 33.

Toujours dans un but de détection de theme, nous ne cherchons pas a connaitre la similarité
entre deux mots dans le langage, mais dans un theme donné. Par conséquent, la similarité entre
deux mots, pour le theme Tj, sera évaluée comme suit :

i ll’ mz'n(Ij(z,~,a3),IJ
2lj Z.:1 mad: (IJ-(2,-,1:),Ij(z,~,y)) max (I1-(33, z,~),

Similaritej (33, y) =

ou lj est le vocabulaire du theme Tj, et I ,~(z,~, :3) est évaluée sur le corpus d’apprentissage du
theme Tj.

148

VVLJIIVI. . WILD IILCI/Ill/(1/0 ll/C ll/Cl/Dbl/Ll/Il« (JD I/ILCIILC J1/IMJCC OI/DI I/It Olrlllvlrl/Ilrl Ll/C CID!/ID Illvl/IA)

TAB. 1 — Label des themes étudiés et leur taille d’apprentissage

Theme Nombre de mots d’apprentissage Theme Nombre de mots d’apprentissage
Culture 25 M Politique 13 M

Economie 21 M Sciences 2 M

Etranger 24 M Sports 170 K

Histoire 560 K

3.2 La similarité entre un mot et un théme

Soit Vj = '[}j;L-1, '[}j;L-2, . . . ,'l}j$|lj| le vecteur représentant le theme Tj. Chaque élément du vecteur
représente la similarité entre un mot et le theme.

Nous proposons d’estimer la similarité entre le mot :3 et le theme Tj comme étant la moyenne
des similarités entre le mot :3 et les mots du vocabulaire caractéristique de Tj. Cette derniere est
ensuite pondérée par la probabilité du mot dans le theme :

Zlcljzll Similaritej (:3, yk)

|z-| |z-| . . .
{:1 k’:1 Szmzlamteﬂx, yk)

was = 3im(~”6aTg') = P(~”6 | Ta’) (3)

3.3 La détermination du théme d’un document

En phase detest, pour chaque theme Tj (j E 1..J), nous disposons d’un vecteur  Le score de
chaque theme sachant le document de test d composé de N mots d = wl, 'LU2, . . . , wN est évalué
comme étant la somme normalisée des similarités entre les mots du document et le theme :

N _ N
 l d) = ¢. *Z5ij (4)

J J N
231,21 2121 “km, i=1

1 siw,~Elj

0 Sinon et 2,]; 6,~j représente le nombre de mots de l j dans d, <p,~ est un

avec 6,3 = {

coefﬁcient de pondération thématique avec Z3721 goj = 1. Les valeurs de <pj sont déterminées
par validation croisée, sur un corpus d’optiInisation. Finalement, le theme retenu est celui qui
maximise (4).

4 Expérimentations

4.1 Les données

Les expériences de détection de themes sont évaluées sur un corpus issu du journal Le Monde,
des années 1987 a 1991 (plus de 80 M mots). Ce corpus est divisé en 7 themes, inégalement
représentés. La liste des themes ainsi que leur taille d’apprentissage sont présentées TAB. 1. Ce
corpus est disponible sous forme d’articles. Cependant, a l’intérieur d’un méme article, on peut
étre confronté a des changements de themes, probleme auquel nous ne nous intéressons pas. Par

149

11. JJII/LIL, IX. LJIILIA/LI/Ir, Jul. . llil/I/I./Il«

conséquent, nous avons extrait aléatoirement 835 paragraphes, que nous considérons ne traiter
que d’un seul theme, et qui forment le corpus de test.

4.2 Construction du vocabulaire

Dans l’équation (2), la similarité entre deux mots :3 et y pour le theme Tj se calcule sur le vo-
cabulaire du theme, qu’il nous faut donc construire. Comme le montrent de nombreuses études
(Brun et al., 2000; Mladenic, 1998), le vocabulaire d’un theme constitue le noyau de base sur
lequel repose toute méthode d’identiﬁcation. Par conséquent, il est indispensable de ne pas se
contenter des mots les plus fréquents des themes, mais d’en trouver les termes caractéristiques.
Nous étudions ici deux méthodes de construction des vocabulaires de themes : une méthode
classique et une méthode adaptée a la categorisation de textes/détection de themes.

4.2.1 Mots les plus fréquents de chaque théme

Le premier ensemble de vocabulaires étudié est construit de facon tres classique, o1‘1 chaque vo-
cabulaire de theme contient les n mots les plus fréquents (en absolu) du corpus d’apprentissage
de ce theme. Les mots outils (non porteurs de sens) ont évidemment été supprimés.

4.2.2 Information mutuelle mot-théme

Le second ensemble de vocabulaires de themes est construit d’une maniere plus judicieuse. Il
s’agit d’évaluer la quantité d’information apportée par la variable T (theme) a la variable X
(mot). Cette quantité est mesurée a l’aide de l’information mutuelle :
P(rva T1)

I(55=Tj) = P($=%)108 

(5)
avec P(:v,  est la probabilité conjointe d’apparition de :3 et Tj, P(1:) est la probabilité a priori
du mot 35 et P(Tj) la probabilité a priori du theme Tj.

Une information mutuelle élevée entre un mot et un theme est le signe d’un lien fort entre ces
deux éléments. Par conséquent, les vocabulaires de themes seront composés des mots d’infor-
mation mutuelle les plus élevées.

Le nombre de mots par theme doit maintenant étre ﬁxé. Nous choisissons volontairement un
nombre de mots identique pour chaque theme. Concemant la méthode exploitant l’information
mutuelle, aﬁn de déterminer le nombre de mots a conserver, nous trions, pour chaque theme,
les mots par ordre décroissant de valeur d’information mutuelle avec le theme, et nous tra-
cons la courbe de cette évolution (FIG. 1). A l’aide de cette courbe, nous pouvons remarquer
que globalement, au dessus de 2000 mots, l’information mutuelle des mots se “stabilise”, nous
choisissons donc de conserver 2000 mots par theme.

Dans un souci de rigueur de comparaison des méthodes, nous avons également ﬁxé n a 2000
pour les vocabulaires composés des mots les plus fréquents.

Nous avons évalué les performances de WSIM sur chacun des deux vocabulaires. Les résultats
sont présentés TAB. 2. La différence spectaculaire des résultats peut étre expliquée par des
vocabulaires de themes tres différents : en effet, en moyenne les deux ensembles de vocabulaires

150

VVLJIIVI. . WILD IILCI/Ill/(1/0 ll/C ll/Cl/Dbl/Ll/Il« (JD I/ILCIILC J1/IMJCC OI/DI I/It Olrlllvlrl/Ilrl Ll/C CID!/ID Illvl/IA)

36-4 v I I I I I
Culture
Economie
gl Etranger """ "
2—se~4  p‘3I:::;II: :99 e
‘I Sciences
2‘ Sports — — ’
26-4 I ’

l.5e—4

Information Mutuelle

 

'_x-_ ._.\I_7.:.*_*. :.t<;.;:;. _—.L :_—,J= ;—g ._I. _ I=.__ _._J____._.I___,_

0
0 500 1000 1500 2000 2500 3000 3500 4000 4500

Mots

FIG. 1 — Information mutuelle classée par valeur décroissante pour chaque theme

TAB. 2 — Taux de detection des themes en fonction du vocabulaire

Vocabulaire Performance (%)
Plus fréquents 27.5
Information mutuelle 82.4

ont seulement 31% des mots en commun. De plus, les vocabulaires construits avec la méthode
des n plus fréquents, ont un taux de recouvrement de 64%, alors que pour les vocabulaires
construits avec l’information mutuelle, ce taux n’est que de 25%.

Nous pouvons ainsi noter que la méthode WSIM semble étre tres dépendante du vocabulaire
choisi. En effet, la similarité entre deux mots est fondée sur leur comportement avec l’ensemble
des autres mots du vocabulaire. Par consequent, les mots du theme doivent étre particulierement
bien choisis pour obtenir une similarité ﬁable.

Nous décidons donc de conserver les vocabulaires créés a l’aide de la mesure d’information
mutuelle.

4.3 Résultats

Aﬁn d’étudier les performances de WSIIVI, nous proposons de la comparer avec d’autres mé-
thodes de detection de themes.

Nous choisissons pour cela, de la comparer a la TFIDF (Salton, 1991), qui est la méthode citée
comme référence dans le domaine. Cette derniere évalue la distance cosine entre les distribu-
tions de probabilités des mots dans les themes et celle du document de test.

Nous comparons également les performances (en termes de rappel) de notre méthode a celle du
modele cache (Bigi et al., 2000). Les experiences menées dans une étude récente (Bigi et al.,
2001), et qui comparait 5 méthodes donnait la méthode d’identiﬁcation par cache en téte. La
méthode cache évalue la distance de Kullback-Leibler entre les distributions de mots des themes
et celle du cache du document de test.

151

11. JJII/LIL, IX. LJIILIA/LI/Ir, Jul. . llil/I/I./Il«

TAB. 3 — Performance des trois méthodes étudiées

Méthode Performance (%)
TFIDF 72. 1
Cache 82.0
WSIM 82.4

TAB. 4 — Rappel, précision et F1 pour chaque méthode et chaque theme

TFIDF Cache WSIlV[
Theme Rap Prec F1 Rap Prec F1 Rap Prec F1
Culture 83.2 82.3 82.8 84.7 90.4 87.4 85.3 87.1 86.2

Economie 60.8 89.8 72.4 74.6 91.0 82 78.8 84.6 81.6

Etranger 57.8 58.4 58.2 86.3 73.9 79.6 85.3 79.8 82.5
Histoire 58.3 13.2 21.6 16.6 14.3 14.4 8.3 33.3 13.3

Politique 70.7 79.5 74.8 85.1 75.1 79.8 86.2 83.0 84.6
Sciences 90.8 66.7 76.9 88.1 82.7 85.4 83.5 79.8 81.6
Sports 66.7 59.3 62.8 75 72 73.4 83.3 62.5 71.4

Dans TAB. 3, nous comparons les performances de notre méthode a la TFIDF et au cache
sur l’ensemble des 835 paragraphes. Les performances de la TFIDF, qui est la méthode de
référence, sont largement dépassées par les deux autres méthodes. De plus, les performances du
modele cache ont été dépassées, pour la premiere fois, par la méthode WSIM, méme si leurs
performances restent cependant tres proches.

Aﬁn de mieux analyser les performances de ces 3 méthodes, il serait donc intéressant de les
étudier theme par theme. Pour cette raison, nous présentons les performances de chacune des
méthodes en termes de rappel et précision, ou :

_ Nb textes correctement étiquetés T
_ Nb textes d’étiquette T

, _ _ Nb textes correctement étiquetés T
Prec1s1onT = , _ , (7)
Nb textes etiquetes T

RappelT (6)

Rappelons ici que l’objectif ﬁnal de la détection de themes est l’adaptation du modele de lan-
gage au theme. Par conséquent, nous cherchons une méthode qui détecte a la fois le theme du
plus grand nombre de documents (rappel) mais fournisse également une étiquette ﬁable (preci-
sion).
Pour cette raison, les résultats seront également présentés en termes de mesure F1, qui permet
de combiner le rappel et la précision dans une seule valeur.

_ 2 >:< rappelT >:< précisionT

(8)

rappe1T + précisionT
TAB. 4 présente, par theme, les valeurs de rappel, précision et F1 pour les 3 méthodes étudiées.

Nous pouvons remarquer que les performances des méthodes varient signiﬁcativement d’un
theme a l’autre. Une des raisons de ces différences peut étre la taille d’apprentissage des themes,
les themes bien appris ayant tendance a étre bien détectés. En effet, comme présenté dans la

152

VVLJIIVI. . WILD IILCI/Ill/(1/0 ll/C ll/Cl/Dbl/Ll/Il« (JD I/ILCIILC J1/IMJCC OI/DI I/It Olrlllvlrl/Ilrl Ll/C CID!/ID Illvl/IA)

table 1, la taille d’apprentissage entre Culture et Sports differe d’un facteur environ 150. Une
autre raison peut egalement etre le recouvrement entre themes.

Les performances par theme de la TFIDF sont representatives de son comportement general :
seules ses valeurs de rappel pour les themes Histoire et Sciences surpassent les deux autres
methodes.

On peut remarquer que le theme Histoire n’est bien reconnu par aucune des methodes. En
plus d’une taille d’apprentissage faible, le theme Histoire souffre d’un manque de vocabulaire
propre. En effet, on peut intuitivement dire que le theme H istoire ne peut étre represente a l’aide
de mots de vocabulaires speciﬁques. Ce dernier est plutot represente par des dates (ensemble
quasi-inﬁni) ou encore par l’emploi d’un temps passe. I1 serait donc interessant d’integrer des
informations d’un niveau superieur au mot et eventuellement des connaissances syntaxiques
pour ameliorer les performances de detection.

Bien que la methode WSIM obtienne les meilleures performances sur le corpus general, on peut
remarquer que le modele cache la depasse legerement dans certains cas, et notamment au niveau
de la precision. Cependant, WSIlV[ a un taux de rappel beaucoup plus homogene sur l’ensemble
des themes, hors Histoire, que le modele cache, ses performances ne semblant pas dependre de
la taille d’apprentissage.

5 Conclusions et perspectives

Nous avons presente une nouvelle methode de detection de theme WSIM, originale par l’infor-
mation qu’elle exploite. En plus de la probabilite des mots dans les themes, celle-ci utilise la
similarite mot-theme, elle-meme basee sur la similarite inter-mots.

Cette methode est tres dependante du vocabulaire utilise en raison de l’utilisation de l’inte-
gralite des mots des vocabulaires pour calculer la similarite inter-mots. Nous avons montre
l’importance du choix des vocabulaires : nos tests donnent des performances 3 fois superieures
a celles obtenues avec un vocabulaire compose des mots les plus frequents.

Comparee a la methode TFIDF classique, la methode WSIM obtient des resultats meilleurs de
14%. Les performances en detection de themes depassent egalement celles du modele cache,
qui n’avait jusque la jamais ete egale. Meme si cette amelioration n’est pour le moment pas
spectaculaire, nous travaillons actuellement sur plusieurs pistes en vue d’ameliorer nos resul-
tats.

Nous avons volontairement choisi des vocabulaires de themes composes d’un nombre egal de
mots. Cependant, les vocabulaires des themes avec une taille d’apprentissage faible, comportent
vraisemblablement des mots non caracteristiques. I1 serait donc interessant d’etudier des voca-
bulaires avec des tailles differentes, en ﬁxant par exemple une valeur d’information mutuelle
normalisee minimale.

De plus, malgre des etudes prouvant la non amelioration des performances de detection en uti-
lisant des sequences de mots, nous envisageons d’inserer des sequences de mots. Tout d’abord
en raison de la taille d’apprentissage de nos themes, qui est largement superieure a celle des
etudes citees precedemment. De plus, la facon dont nous souhaitons proceder pour l’extraction
de sequences est fondee sur des connaissances semantiques.

Pour le traitement de themes comme Histoire, il serait interessant d’utiliser des classes seman-
tiques, pour notamment representer des notions de dates, lieux, noms propres, etc., le vocabu-
laire devenant ainsi un vocabulaire de classes.

153

11. JJII/LIL, IX. LJIILIA/LI/Ir, Jul. . llil/I/I./Il«

Références

APTE G., DAMERAU F. & WEISS S. (1994). Automated learning of decision rules for text categoriza-
tion. ACM Transactions on Information Systems, 12(3), 233-251.

BIGI B., BRUN A., HATON J ., SMAILI K. & ZITOUNI I. (2001). Dynamic topic identiﬁcation 2 To-
wards combination of methods. In Proceedings of the Recent Advances in Natural Language Processing
(RANLP), p. 255-257.

BIGI B., DE MORI R. & EL BEZE M. (2000). A fuzzy decision strategy for topic identiﬁcation and
dynamic selection of language models. Signal Processing Journal, 80(6), 1085-1097.

BRUN A., SMAILI K. & HATON J . (2000). Experiment analysis in newspaper topic detection. In 7th
International Symposium on String Processing and Information Retrieval, SPIRE-2000, p. 55-64.

CAROPRESO M., MATWIN S. & SEBASTIANI F. (2001). A leamer-independant evaluation of the use-
fulness of statistical phrases for automatic text categorization, p. 78-102. Hershey, US.

CHELBA C. & J ELINEK F. (2000). Structured language modeling. Computer Speech and Language,
14(4), 283-332.

CHEN S. F. & GOODMAN J . (1996). An empirical study of smoothing techniques for language mode-
ling. In Proceedings id the 34th Annual Meeting of the ACL, p. 310-318.

DAGAN I., KAROV Y. & ROTH D. (1997). Mistake-driven learning in text categorization. In Procee-
dings of the EMNLP-97, 2nd Conference on Empirical Methods in Natural Language Processing, p.
55-63.

DAGAN I., LEE L. & PEREIRA F. C. N. (1999). Similarity-based models of word coocurrence proba-
bilities. Machine Learning, 34, 43-69.

J OACHIMS T. (1997). A probabilistic analysis of the rocchio algorithm with tﬁdf for text categorization.
In Proceedings of I CML-97, I 4th International Conference on Machine Learning, p. 143-151.

J OACHIMS T. (1998). Text categorization with support vector machines 2 learning with many relevant
features. In Proceeding of ECML-99, 16th European Conference on Machine Learning, p. 137-142.
KUHN R. & DE MORI R. (1990). A cache-based natural language model for speech reproduction. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 12(6), 570-583.

LEWIS D. (1992). An evaluation of phrasal and clustered representations on a text categorization task.
In A. PRESS, Ed., Proceedings of SIGIR-92, 15th ACM International Conference on Research and De-
velopment in Information Retrieval, p. 37-50, New York, US.

LEWIS D. & RINGUETTE M. (1994). A comparison of two learning algorithms for text categorization.

In Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval,
p. 81-93.

MC DONOUGH J . & NG K. (1994). Approaches to topic identiﬁcation on the switchboard corpus. In
International Conference on Acoustics, Speech and Signal Processing, p. 385-388, Yokohama, Japan.

MITCHELL T. (1996). Machine Learning, chapter 3. Mc Graw Hill.

MLADENIC D. (1998). Feature subset selection in text-learning. In 10th European Conference on
Machine Learning ECML98.

ROSENFELD R. (1996). A maximum entropy approach to adaptive statistical language modeling. Com-
puter Speech and Language, 10, 187-228.

SALTON G. (1991). Developments in automatic text retrieval. Science, 253, 974-979.

SEYMORE K. & ROSENFELD R. (1997). Large-scale Topic Detection And Language Model Adaptation.
Rapport interne CMU-CS-97-152, School of Computer Science,CMU.

YANG Y. & CHUTE C. (1994). An example-based mapping method for text categorization. ACM
Transactions on Information Systems, 12(3), 252-277.

154

