<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Segmenter et structurer th&#233;matiquement des textes par l&#8217;utilisation conjointe de collocations et de la r&#233;currence lexicale</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2002, Nancy, 24-27 juin 2002 
</p>
<p>Segmenter et structurer th&#233;matiquement des textes par 
l&#8217;utilisation conjointe de collocations et de la r&#233;currence lexicale 
</p>
<p>Olivier Ferret 
</p>
<p>CEA &#8211; LIST 
92265 Fontenay-aux-Roses Cedex 
</p>
<p>olivier.ferret@cea.fr 
</p>
<p>R&#233;sum&#233; &#8211; Abstract 
</p>
<p>Nous exposons dans cet article une m&#233;thode r&#233;alisant de fa&#231;on int&#233;gr&#233;e deux t&#226;ches de 
l&#8217;analyse th&#233;matique : la segmentation et la d&#233;tection de liens th&#233;matiques. Cette m&#233;thode 
exploite conjointement la r&#233;currence des mots dans les textes et les liens issus d&#8217;un r&#233;seau de 
collocations afin de compenser les faiblesses respectives des deux approches. Nous 
pr&#233;sentons son &#233;valuation concernant la segmentation sur un corpus en fran&#231;ais et un corpus 
en anglais et nous proposons une mesure d&#8217;&#233;valuation sp&#233;cifiquement adapt&#233;e &#224; ce type de 
syst&#232;mes. 
</p>
<p>We present in this paper a method for achieving in an integrated way two tasks of topic analy-
sis: segmentation and link detection. This method combines the lexical recurrence in texts and 
the relations from a collocation network to compensate for the respective weaknesses of the 
two approaches. We report its evaluation for segmentation on a corpus in French and another 
in English and we propose an evaluation measure that specifically suits that kind of systems. 
</p>
<p>Mots Cl&#233;s &#8211; Keywords 
</p>
<p>Analyse du discours, analyse th&#233;matique, segmentation, d&#233;tection de liens th&#233;matiques. 
Discourse analysis, topic analysis, topic segmentation, link detection. 
</p>
<p>1 Introduction 
</p>
<p>L&#8217;analyse th&#233;matique, dont le but est d&#8217;identifier les th&#232;mes d&#8217;un texte1, d&#8217;en d&#233;limiter 
l&#8217;extension et de trouver les relations entre les segments ainsi d&#233;limit&#233;s, a fait l&#8217;objet d&#8217;un 
nombre important de travaux r&#233;cents. La plupart d&#8217;entre eux sont consacr&#233;s &#224; la segmentation 
</p>
<p>                                                 
1  Nous d&#233;finissons ici le th&#232;me comme une configuration d&#8217;unit&#233;s s&#233;mantiques de nature inter-textuelle, c&#8217;est-
</p>
<p>&#224;-dire observable entre plusieurs textes et plusieurs auteurs. 
</p>
<p>155 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier Ferret 
</p>
<p>th&#233;matique ou s&#8217;inscrivent dans le cadre de l&#8217;&#233;valuation TDT (Topic Detection and Tracking). 
Cette derni&#232;re aborde les trois axes &#233;voqu&#233;s ci-dessus mais en se pla&#231;ant dans des domaines 
restreints et en les consid&#233;rant principalement sous l&#8217;angle de t&#226;ches ind&#233;pendantes. 
</p>
<p>Les syst&#232;mes impl&#233;mentant ces travaux peuvent &#234;tre cat&#233;goris&#233;s en fonction du type des 
connaissances dont ils font usage. La plus grande partie de ceux d&#233;di&#233;s &#224; la segmentation 
th&#233;matique, c&#8217;est-&#224;-dire au d&#233;coupage des textes en segments th&#233;matiquement homog&#232;nes, 
s&#8217;appuient uniquement sur les caract&#233;ristiques intrins&#232;ques des textes tels que la distribution 
des mots (Hearst, 1997 ; Choi, 2000 ; Utiyama, Isahara, 2001) ou des marqueurs linguistiques 
(Passonneau, Litman, 1997). Ils peuvent &#234;tre utilis&#233;s sans restriction quant au domaine abord&#233; 
mais leurs performances sont faibles lorsque la structure th&#233;matique des textes ne transpara&#238;t 
pas au travers des marques de surface qu&#8217;ils exploitent. Un second type de syst&#232;mes utilise 
des connaissances caract&#233;risant la notion de coh&#233;sion lexicale. Ces connaissances, non li&#233;es &#224; 
un domaine, prennent la forme d&#8217;un r&#233;seau de mots construit &#224; partir d&#8217;un dictionnaire 
(Kozima, 1993 ; Morris, Hirst, 1991) ou d&#8217;un large ensemble de collocations issues d&#8217;un 
corpus (Ferret, 1998 ; Kaufmann, 1999 ; Choi, 2001). Gr&#226;ce aux relations entre mots qu&#8217;elles 
contiennent (synonymie, hyperonymie &#8230;), ces connaissances permettent d&#8217;&#233;carter des 
changements de th&#232;me erron&#233;s d&#233;finis sur la base de ruptures existant au niveau de la 
r&#233;currence des mots. Un dernier type de syst&#232;mes s&#8217;appuie sur des connaissances directement 
li&#233;es aux th&#232;mes apparaissant dans les textes qu&#8217;ils traitent. Dans le cas de TDT par exemple, 
ces connaissances sont construites de mani&#232;re automatique &#224; partir d&#8217;un ensemble de textes de 
r&#233;f&#233;rence caract&#233;risant chaque th&#232;me consid&#233;r&#233;. (Bigi et al., 1998) se situe dans la m&#234;me 
perspective mais s&#8217;int&#233;resse &#224; des th&#232;mes plus larges que les &#233;v&#233;nements propres &#224; TDT. Ces 
syst&#232;mes ont un champ d&#8217;action assez limit&#233; du fait de leur d&#233;pendance vis-&#224;-vis de 
repr&#233;sentations de th&#232;mes. &#192; l&#8217;int&#233;rieur de ce champ d&#8217;action, elles leur permettent en 
revanche d&#8217;&#234;tre plus pr&#233;cis. 
</p>
<p>La m&#233;thode d&#8217;analyse th&#233;matique que nous proposons dans cet article se distingue des 
travaux que nous venons d&#8217;&#233;voquer sur deux points principaux. Tout d&#8217;abord, elle vise &#224; 
assurer simultan&#233;ment une segmentation th&#233;matique des textes et une mise en &#233;vidence des 
liens entre les segments faisant r&#233;f&#233;rence au m&#234;me th&#232;me (cf. t&#226;che Link Detection de TDT), 
premi&#232;re &#233;tape vers la structuration th&#233;matique des textes. Ensuite, elle met en &#339;uvre une 
approche hybride : elle s&#8217;appuie en effet sur une ressource rendant compte de la coh&#233;sion 
lexicale, en l&#8217;occurrence un r&#233;seau de collocations, mais l&#8217;exploite en conjonction avec la 
r&#233;currence lexicale dans les textes. Nous d&#233;taillons dans cet article l&#8217;impl&#233;mentation de cette 
m&#233;thode par le syst&#232;me TOPICOLL, son &#233;valuation en mati&#232;re de segmentation pour le fran&#231;ais 
et l&#8217;anglais ainsi qu&#8217;une &#233;valuation plus globale de ses capacit&#233;s par une nouvelle mesure. 
</p>
<p>2 Vue d&#8217;ensemble du syst&#232;me TOPICOLL 
</p>
<p>Dans le prolongement de nombreux travaux portant sur la segmentation du discours, 
TOPICOLL traite les textes lin&#233;airement : il d&#233;tecte les changements de th&#232;me et identifie les 
liens entre segments sans diff&#233;rer sa d&#233;cision, c&#8217;est-&#224;-dire en tenant compte uniquement des 
&#233;l&#233;ments qu&#8217;il a pu extraire de la partie du texte d&#233;j&#224; analys&#233;e. Une fen&#234;tre d&#233;limitant l&#8217;espace 
de focalisation de l&#8217;analyse est d&#233;plac&#233;e sur l&#8217;ensemble du texte consid&#233;r&#233;. Cette fen&#234;tre 
contient sous forme lemmatis&#233;e les mots pleins du texte issus de son pr&#233;-traitement. Un 
contexte th&#233;matique est associ&#233; &#224; cette fen&#234;tre de focalisation. Il est constitu&#233; &#224; la fois des 
mots de la fen&#234;tre et des mots d&#8217;un r&#233;seau de collocations jug&#233;s les plus fortement li&#233;s aux 
</p>
<p>156 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmenter et structurer th&#233;matiquement des textes 
</p>
<p>mots de la fen&#234;tre. Les segments se voient &#233;galement associer un contexte th&#233;matique. Celui-
ci r&#233;sulte de la fusion des contextes associ&#233;s &#224; la fen&#234;tre de focalisation lorsque celle-ci se 
situe dans leur espace. Un changement de th&#232;me est d&#233;tect&#233; d&#232;s lors qu&#8217;une diff&#233;rence 
significative et durable est observ&#233;e entre le contexte de la fen&#234;tre et celui du segment dans 
laquelle elle se trouve. La d&#233;tection de liens th&#233;matiques s&#8217;effectue quant &#224; elle en comparant 
le contexte th&#233;matique de chaque nouveau segment avec celui des segments pr&#233;c&#233;demment 
d&#233;finis. TOPICOLL reprend donc le principe g&#233;n&#233;ral d&#8217;analyse du syst&#232;me SEGAPSITH (Ferret, 
Grau, 2000) en introduisant au niveau des contextes th&#233;matiques la caract&#233;risation de la 
coh&#233;sion lexicale d&#233;velopp&#233;e dans le cadre du syst&#232;me SEGCOHLEX (Ferret, 1998). 
</p>
<p>L&#8217;utilisation d&#8217;un r&#233;seau de collocations2 permet &#224; TOPICOLL de trouver des relations entre les 
mots au-del&#224; de la simple r&#233;it&#233;ration et d&#8217;associer &#224; chaque segment une repr&#233;sentation 
th&#233;matique plus riche, ce qui facilite des t&#226;ches comme la d&#233;tection de liens th&#233;matiques. 
N&#233;anmoins, des travaux tels que (Kozima, 1993), (Ferret, 1998) ou (Kaufmann, 1999) ont 
montr&#233; que le recours &#224; des connaissances lexicales g&#233;n&#233;rales n&#8217;am&#233;liore souvent pas les 
performances par rapport &#224; l&#8217;exploitation de la seule distribution des mots dans les textes. Les 
m&#233;thodes utilis&#233;es ne contr&#244;lent pas en effet assez pr&#233;cis&#233;ment le type des relations qu&#8217;elles 
s&#233;lectionnent et ne tiennent pas compte de l&#8217;incompl&#233;tude de leurs connaissances. De ce fait, 
en m&#234;me temps qu&#8217;elles permettent d&#8217;invalider &#224; juste titre certains des changements de 
th&#232;me correspondant &#224; une rupture dans l&#8217;usage du vocabulaire, elles introduisent des 
ruptures th&#233;matiques incorrectes du fait de l&#8217;absence dans leurs connaissances des relations 
lexicales ad&#233;quates ou passent &#224; c&#244;t&#233; de changements de th&#232;me r&#233;els &#224; cause de la s&#233;lection 
de relations lexicales non pertinentes du point de vue th&#233;matique. En combinant la r&#233;currence 
des mots et la s&#233;lection de relations dans un r&#233;seau de collocations, TOPICOLL vise donc &#224; 
exploiter de fa&#231;on plus pr&#233;cise une source de connaissances non li&#233;e &#224; un domaine. 
</p>
<p>3 Les r&#233;seaux de collocations 
</p>
<p>TOPICOLL s&#8217;appuie sur un r&#233;seau de collocations propre &#224; chaque langue qu&#8217;il traite. Celui 
pour le fran&#231;ais a &#233;t&#233; construit &#224; partir de 24 mois du journal Le Monde s&#233;lectionn&#233;s entre 
1990 et 1994 en respectant un &#233;quilibre entre les ann&#233;es et entre les mois ; celui pour l&#8217;anglais 
&#224; partir de deux ans du journal Los Angeles Times, issus du corpus TREC. Dans les deux cas, le 
corpus contient environ 40 millions de mots. Pour chaque r&#233;seau, le corpus initial a d&#8217;abord 
&#233;t&#233; pr&#233;-trait&#233; afin de caract&#233;riser les textes par leurs mots les plus th&#233;matiquement 
significatifs, en l&#8217;occurrence les noms, les verbes et les adjectifs, donn&#233;s sous forme 
lemmatis&#233;e. Les ambigu&#239;t&#233;s de lemmatisation ont &#233;t&#233; lev&#233;es gr&#226;ce &#224; un &#233;tiqueteur morpho-
syntaxique. Les collocations ont ensuite &#233;t&#233; extraites en utilisant une fen&#234;tre glissante selon la 
m&#233;thode d&#233;crite dans (Church, Hanks, 1990). Les param&#232;tres de cette extraction ont &#233;t&#233; fix&#233;s 
pour favoriser la capture de relations th&#233;matiques : une fen&#234;tre assez large (20 mots), 
respectant la fin des textes et ne conservant pas l&#8217;ordre des collocations. Nous avons comme 
Church et Hanks adopt&#233; une &#233;valuation de l&#8217;information mutuelle en tant que mesure de 
coh&#233;sion des collocations, mesure normalis&#233;e dans notre cas par l&#8217;information mutuelle 
maximale relative au corpus. Apr&#232;s filtrage des collocations les moins significatives 
(coh&#233;sion &lt; 0,1 et moins de 10 occurrences), nous avons obtenu un r&#233;seau d&#8217;environ 23.000 
</p>
<p>                                                 
2  Les n&#339;uds de ce r&#233;seau sont constitu&#233;s par des mots et les ar&#234;tes, par des collocations entre ces mots. 
</p>
<p>157 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier Ferret 
</p>
<p>mots et 5,2 millions de collocations pour le fran&#231;ais et un r&#233;seau de 30.000 mots et 4,8 
millions de collocations pour l&#8217;anglais. 
</p>
<p>4 Description du syst&#232;me TOPICOLL 
</p>
<p>TOPICOLL fonde son fonctionnement sur la cr&#233;ation, la mise &#224; jour et l&#8217;utilisation d&#8217;une 
repr&#233;sentation th&#233;matique des segments qu&#8217;il d&#233;finit et du contenu de sa fen&#234;tre de 
focalisation &#224; chaque position d&#8217;un texte. Ces repr&#233;sentations sont appel&#233;es des contextes 
th&#233;matiques. 
</p>
<p>4.1 Les contextes th&#233;matiques 
</p>
<p>Un contexte th&#233;matique caract&#233;rise la dimension th&#233;matique de l&#8217;entit&#233; &#224; laquelle il est 
associ&#233; par l&#8217;interm&#233;diaire de deux vecteurs : le vecteur texte et le vecteur collocation. 
Chacune de leurs coordonn&#233;es repr&#233;sente un mot et sa valeur correspond &#224; un poids traduisant 
l&#8217;importance relative de ce mot par rapport aux autres mots du vecteur. Le vecteur texte est 
compos&#233; des mots venant du texte analys&#233; tandis que le vecteur collocation contient les mots 
du r&#233;seau de collocations consid&#233;r&#233;s comme fortement li&#233;s aux mots du texte. 
</p>
<p>4.1.1 Le contexte th&#233;matique de la fen&#234;tre de focalisation (Cf) 
</p>
<p>Le vecteur texte du contexte associ&#233; &#224; la fen&#234;tre de focalisation est constitu&#233; des mots pleins 
de cette fen&#234;tre. Leur poids combine leur importance dans la partie du texte d&#233;limit&#233;e par la 
fen&#234;tre, donn&#233;e par leur nombre d&#8217;occurrences, et leur degr&#233; de sp&#233;cificit&#233; hors contexte, 
exprim&#233; comme dans (Kozima, 1993) par l&#8217;information normalis&#233;e par rapport &#224; un corpus de 
r&#233;f&#233;rence, en l&#8217;occurrence celui ayant permis la construction du r&#233;seau de collocations utilis&#233;. 
</p>
<p>0,14
</p>
<p>0,21 0,10
</p>
<p>0,18 0,13
</p>
<p>0,17
</p>
<p>m5m4m3m2m1
</p>
<p>0,48 = pm3 . 0,18 + pm4 . 0,13 +
           pm5 . 0,17
</p>
<p>mot s&#233;lectionn&#233; du r&#233;seau de collocations (avec son poids)
</p>
<p>1,0
mot du texte (avec pmi, son poids dans la fen&#234;tre, &#233;gal &#224; 1,0
</p>
<p>0,21 relation dans le r&#233;seau de collocations (avec sa valeur de coh&#233;sion)
</p>
<p>1,0 1,0 1,0 1,0 1,0
</p>
<p>r1 r2
</p>
<p>pour tous les mots de la fen&#234;tre dans cet exemple)
</p>
<p>0,48
</p>
<p> 
Figure 1 : S&#233;lection et pond&#233;ration des mots du r&#233;seau de collocations 
</p>
<p>La construction du vecteur collocation du contexte de la fen&#234;tre de focalisation s&#8217;inspire de la 
proc&#233;dure pr&#233;sent&#233;e dans (Ferret, 1998) pour &#233;valuer la coh&#233;sion lexicale d&#8217;un texte. Elle 
consiste &#224; s&#233;lectionner les mots du r&#233;seau de collocations th&#233;matiquement proches de ceux de 
la fen&#234;tre. Nous faisons l&#8217;hypoth&#232;se que cette proximit&#233; est li&#233;e au nombre de liens existant 
entre un mot du r&#233;seau et les mots de la fen&#234;tre. Un mot du r&#233;seau est ainsi retenu s&#8217;il est li&#233; &#224; 
un nombre minimum &#8211; 3 dans nos exp&#233;riences &#8211; de mots de la fen&#234;tre. Chaque mot retenu se 
</p>
<p>158 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmenter et structurer th&#233;matiquement des textes 
</p>
<p>voit ensuite assigner un poids, &#233;gal &#224; la somme des contributions des mots de la fen&#234;tre 
auxquels il est li&#233; (cf. Figure 1). La contribution d&#8217;un mot de la fen&#234;tre est le r&#233;sultat de la 
combinaison, selon une moyenne g&#233;om&#233;trique, de son poids dans la fen&#234;tre et de la valeur de 
coh&#233;sion entre les deux mots dans le r&#233;seau. On obtient donc pour une position t de la 
fen&#234;tre : 
</p>
<p> &#8721; &#8901;=
i
</p>
<p>iitxtcoll mmcohtCfmpoidstCfmpoids ),(),,(),,(  (1) 
</p>
<p>avec coh(m,mi), la valeur de coh&#233;sion entre m et mi dans le r&#233;seau de collocations. 
</p>
<p>4.1.2 Le contexte th&#233;matique d&#8217;un segment (Cs) 
</p>
<p>Le contexte th&#233;matique d&#8217;un segment est le produit de la fusion des contextes associ&#233;s &#224; la 
fen&#234;tre de focalisation lorsque celle-ci se trouvait dans le segment. Cette fusion est r&#233;alis&#233;e &#224; 
chaque nouvelle extension du segment : le contexte associ&#233; &#224; la nouvelle position englob&#233;e 
est aussit&#244;t combin&#233; au contexte courant du segment. Cette combinaison, r&#233;alis&#233;e s&#233;par&#233;ment 
pour les vecteurs texte et collocation, consiste &#224; fusionner deux listes de mots pond&#233;r&#233;s : les 
mots du contexte de la fen&#234;tre qui ne sont pas dans celui du segment y sont ajout&#233;s ; le poids 
des mots de la liste r&#233;sultante est calcul&#233; en fonction de leur poids dans le contexte de la 
fen&#234;tre et de leur pr&#233;c&#233;dent poids dans le contexte du segment : 
</p>
<p> )),,()(()1,,(),,( tCfmpoidsmsigniftCsmpoidstCsmpoids xxx &#8901;+&#8722;=  (2) 
avec Cf, le contexte de la fen&#234;tre, Cs, celui du segment, poidsx(m, C{s,f},t), le poids du mot m 
dans le vecteur x (txt ou coll) du contexte C{s,f} pour la position t et signif(m), le degr&#233; de 
sp&#233;cificit&#233; hors contexte de m (cf. 4.1.1). Pour les mots de Cf initialement absents de Cs, 
poidsx(m, Cs,t-1) est &#233;gal &#224; 0. Pour ceux de Cs, la r&#233;&#233;valuation du poids donn&#233;e par (2) 
repr&#233;sente un compromis concernant la vitesse d&#8217;&#233;volution des contextes de segment : elle 
permet de s&#8217;affranchir des micro-variations dans la fa&#231;on dont un th&#232;me est exprim&#233; au sein 
d&#8217;un segment tout en suivant les &#233;volutions th&#233;matiques du contexte de la fen&#234;tre de 
suffisamment pr&#232;s pour ne pas passer &#224; c&#244;t&#233; d&#8217;un changement de th&#232;me. 
</p>
<p>4.1.3 La similarit&#233; entre contextes th&#233;matiques 
</p>
<p>Pour d&#233;terminer si le contenu de la fen&#234;tre de focalisation est th&#233;matiquement coh&#233;rent avec 
le segment courant, on compare les contextes associ&#233;s &#224; ces deux entit&#233;s. Cette comparaison 
est r&#233;alis&#233;e en deux &#233;tapes : une mesure de similarit&#233; est d&#8217;abord calcul&#233;e entre les vecteurs 
des deux contextes ; les valeurs obtenues sont ensuite exploit&#233;es par une proc&#233;dure de 
d&#233;cision statuant sur la similarit&#233; des deux contextes. De m&#234;me que (Choi, 2000) et 
(Kaufmann, 1999), nous utilisons la mesure du cosinus pour &#233;valuer le degr&#233; de similarit&#233; 
entre un vecteur du contexte de la fen&#234;tre (Vf) et le vecteur de m&#234;me type dans le contexte du 
segment (Vs) : 
</p>
<p> &#8721;&#8721;
&#8721;
</p>
<p>&#8901;
&#8901;
</p>
<p>=
i
</p>
<p>ix
i
</p>
<p>ix
</p>
<p>i
i
</p>
<p>xix
</p>
<p>xx
tCfmpoidstCsmpoids
</p>
<p>tCfmpoidstCsmpoids
tVfVssim
</p>
<p>22 ),,(),,(
</p>
<p>),,(),,(
),,(  (3) 
</p>
<p>o&#249; poidsx(mi,C{s,f}, t) est le poids du mot mi dans le vecteur x (txt ou coll) du contexte C{s,f}. 
</p>
<p>159 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier Ferret 
</p>
<p>Afin de minimiser le bruit dans les vecteurs, cette mesure ne prend en compte que les mots les 
plus r&#233;currents des contextes des segments, l&#8217;importance d&#8217;un mot dans un contexte &#233;tant 
suppos&#233;e corr&#233;l&#233;e avec sa r&#233;currence au sein de celui-ci. Cette r&#233;currence est d&#233;finie comme 
la proportion, parmi les contextes de fen&#234;tre de focalisation ayant permis de constituer le 
contexte de segment, de ceux contenant le mot consid&#233;r&#233;. Ce rapport doit &#234;tre sup&#233;rieur &#224; un 
seuil fix&#233; pour que le mot soit retenu. Du fait de la plus grande h&#233;t&#233;rog&#233;n&#233;it&#233; des mots venant 
des textes, ce seuil est plus exigeant pour les vecteurs texte que pour les vecteurs collocation. 
</p>
<p>La proc&#233;dure de d&#233;cision s&#8217;inspire quant &#224; elle des travaux relatifs &#224; la combinaison de 
plusieurs syst&#232;mes r&#233;alisant la m&#234;me t&#226;che. Dans le cas pr&#233;sent, l&#8217;&#233;valuation de la similarit&#233; 
entre les contextes Cs et Cf s&#8217;appuie sur un vote synth&#233;tisant le point de vue des vecteurs 
texte et celui des vecteurs collocation. La valeur de similarit&#233; obtenue gr&#226;ce &#224; (3) est d&#8217;abord 
discr&#233;tis&#233;e pour chaque type de vecteurs par comparaison avec un seuil fixe : un vote positif 
en faveur de la similarit&#233; des contextes est d&#233;cid&#233; si la valeur est sup&#233;rieure &#224; ce seuil. Au 
final, la similarit&#233; des contextes n&#8217;est rejet&#233;e que si le vote des deux types de vecteurs est 
n&#233;gatif. 
</p>
<p>4.2 Segmentation th&#233;matique 
</p>
<p>L&#8217;algorithme de segmentation th&#233;matique de TOPICOLL reprend dans son principe celui 
pr&#233;sent&#233; dans (Ferret, Grau, 2000) : si la similarit&#233; entre le contexte de la fen&#234;tre de 
focalisation et celui du segment actif est rejet&#233;e (cf. 4.1.3), TOPICOLL en d&#233;duit la pr&#233;sence 
d&#8217;un changement de th&#232;me &#224; la position correspondante et le segment actif est clos. Sinon, le 
segment actif est &#233;tendu afin d&#8217;englober la position courante. Cet algorithme de base suppose 
que la phase de transition entre deux segments soit ponctuelle et sans ambigu&#239;t&#233;. En r&#233;alit&#233;, la 
similarit&#233; entre contextes peut &#234;tre localement fluctuante du fait de la forme de surface des 
textes. Il est donc pr&#233;f&#233;rable d&#8217;introduire un d&#233;lai avant de d&#233;cider v&#233;ritablement si le 
segment actif se termine ou si un nouveau segment s&#8217;ouvre. Pour tenir compte de cette 
incertitude, l&#8217;algorithme de segmentation prend la forme d&#8217;un automate (cf. Figure 2) dont les 
transitions sont contr&#244;l&#233;es par les trois param&#232;tres suivants : 
</p>
<p>&#8226; l&#8217;&#233;tat courant de TOPICOLL ; 
&#8226; la similarit&#233; entre le contexte de la fen&#234;tre de focalisation et le contexte du segment 
</p>
<p>courant : Sim ou non Sim ; 
</p>
<p>&#8226; le nombre de positions successives de la fen&#234;tre de focalisation caract&#233;ris&#233;es par un 
m&#234;me &#233;tat courant de TOPICOLL : nbConfirm. Il doit &#234;tre sup&#233;rieur &#224; Sconfirm pour 
sortir des &#233;tats D&#233;tectionNouveauTh&#232;me et D&#233;tectionChangementTh&#232;me. 
</p>
<p>160 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmenter et structurer th&#233;matiquement des textes 
</p>
<p>D&#233;tection
Nouveau
Th&#232;me
</p>
<p>D&#233;tection
Changement
</p>
<p>Th&#232;me
</p>
<p>Changement
Th&#232;me
</p>
<p>D&#233;veloppement
Th&#232;me
</p>
<p>Sim
</p>
<p>Sim
</p>
<p>Sim
</p>
<p>non Sim
</p>
<p>non Sim
</p>
<p>non Sim
</p>
<p>non Sim
&amp;
</p>
<p>nbConfirm =
Sconfirm
</p>
<p>non Sim
&amp;
</p>
<p>nbConfirm &lt;
Sconfirm
</p>
<p>Sim
&amp;
</p>
<p>nbConfirm =
Sconfirm
</p>
<p>Sim
&amp;
</p>
<p>nbConfirm &lt;
Sconfirm
</p>
<p> 
Figure 2 : L&#8217;automate de d&#233;tection des changements de th&#232;me 
</p>
<p>Au d&#233;but d&#8217;un nouveau texte ou &#224; la suite de la d&#233;tection de la fin d&#8217;un segment, TOPICOLL se 
trouve dans l&#8217;&#233;tat ChangementTh&#232;me. D&#232;s que le contexte th&#233;matique de la fen&#234;tre de 
focalisation demeure stable d&#8217;une position &#224; une autre au regard de (3), il entre dans l&#8217;&#233;tat 
D&#233;tectionNouveauTh&#232;me. Il ne peut ensuite atteindre l&#8217;&#233;tat D&#233;veloppementTh&#232;me que si cette 
stabilit&#233; est conserv&#233;e pour les nbConfirm - 1 positions suivantes. Sinon, il fait l&#8217;hypoth&#232;se 
qu&#8217;il s&#8217;agit d&#8217;une fausse alarme et revient &#224; l&#8217;&#233;tat ChangementTh&#232;me. La d&#233;tection de la fin 
d&#8217;un segment est le sym&#233;trique de la d&#233;tection de son d&#233;but. TOPICOLL entre dans l&#8217;&#233;tat 
D&#233;tectionChangementTh&#232;me d&#232;s que le contexte de la fen&#234;tre de focalisation change de fa&#231;on 
significative entre deux positions successives. La transition vers l&#8217;&#233;tat ChangementTh&#232;me 
n&#8217;est cependant op&#233;r&#233;e que si ce changement se confirme pour les nbConfirm - 1 positions 
suivantes. 
</p>
<p>4.3 D&#233;tection de liens th&#233;matiques 
</p>
<p>L&#8217;algorithme de TOPICOLL pour d&#233;tecter les liens d&#8217;identit&#233; th&#233;matique entre segments est 
&#233;troitement li&#233; &#224; son algorithme de segmentation. Avant d&#8217;entrer dans l&#8217;&#233;tat 
D&#233;veloppementTh&#232;me, TOPICOLL v&#233;rifie si le contexte du nouveau segment est similaire au 
contexte de l&#8217;un des segments d&#233;j&#224; d&#233;finis. La similarit&#233; repose dans ce cas sur l&#8217;application 
de (3) entre les vecteurs collocation des contextes et la comparaison par rapport &#224; un seuil 
sp&#233;cifique. Si l&#8217;une des valeurs de similarit&#233; d&#233;passe ce seuil, le nouveau segment est li&#233; au 
segment correspondant et adopte son contexte comme contexte propre. TOPICOLL fait ainsi 
l&#8217;hypoth&#232;se que le nouveau segment continue &#224; d&#233;velopper le th&#232;me d&#233;j&#224; abord&#233;. Lorsque 
plusieurs segments sont possibles, TOPICOLL choisit celui pour lequel la similarit&#233; des 
contextes est la plus forte. 
</p>
<p>5 Exp&#233;rimentations 
</p>
<p>5.1 Segmentation th&#233;matique 
</p>
<p>Pour &#233;valuer les capacit&#233;s de segmentation th&#233;matique de TOPICOLL, nous l&#8217;avons appliqu&#233; &#224; 
la t&#226;che classique de red&#233;couverte des fronti&#232;res d&#8217;un ensemble de textes concat&#233;n&#233;s. Pour la 
mesure des performances, nous avons utilis&#233; la mesure d&#8217;erreur probabiliste Pk propos&#233;e dans 
</p>
<p>161 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier Ferret 
</p>
<p>(Beeferman et al., 1999) et maintenant largement utilis&#233;e3. Nous avons &#233;galement calcul&#233; la 
pr&#233;cision et le rappel afin de permettre la comparaison avec certains syst&#232;mes plus anciens. 
</p>
<p>5.1.1 &#201;valuation de la segmentation pour le fran&#231;ais : corpus du journal Le Monde 
</p>
<p>L&#8217;&#233;valuation pour le fran&#231;ais a &#233;t&#233; r&#233;alis&#233;e sur un ensemble de 49 textes longs de 133 mots en 
moyenne, extraits du journal Le Monde (1995) et couvrant 11 th&#232;mes. Les r&#233;sultats du 
Tableau 1 sont des moyennes obtenues sur 10 ordonnancements diff&#233;rents de ces textes. Une 
proc&#233;dure (BASE) choisissant al&#233;atoirement un nombre fixe de fins de phrase comme bornes 
de segment a servi de r&#233;f&#233;rence basse. Ses r&#233;sultats dans le Tableau 1 sont des moyennes sur 
1.000 tirages au sort. TOPICOLL1 est le syst&#232;me d&#233;crit au paragraphe 4. TOPICOLL2 est le m&#234;me 
syst&#232;me mais avec inactivation de la partie d&#233;tection de liens th&#233;matiques. Les r&#233;sultats de ces 
deux variantes indiquent que la recherche de liens entre segments ne d&#233;grade pas 
significativement  les  r&#233;sultats de TOPICOLL en  mati&#232;re de  segmentation.  TEXTTILING est  
notre impl&#233;- 
</p>
<p>Syst&#232;mes Rappel Pr&#233;cision F1-
mesure
</p>
<p>Faux 
n&#233;gatif 
</p>
<p>Fausse 
alarme 
</p>
<p>Pk 
</p>
<p>SEGCOHLEX (Ferret, 1998) 0,68 0,37 0,48 nc nc nc 
SEGAPSITH (Ferret, Grau, 2000) 0,92 0,52 0,67 nc nc nc 
</p>
<p>TEXTTILING 0,72 0,81 0,76 nc nc nc 
BASE 0,51 0,28 0,36 0,46 0,55 0,50
</p>
<p>TOPICOLL1 0,86 0,74 0,80 0,17 0,24 0,21
TOPICOLL2 0,86 0,78 0,81 0,17 0,22 0,20
</p>
<p>Tableau 1 : Pr&#233;cision/rappel et Pk pour le corpus du Monde4 
</p>
<p>mentation de l&#8217;algorithme de Hearst en utilisant les valeurs standards de ses param&#232;tres. Le 
Tableau 1 montre clairement que TOPICOLL obtient de meilleurs r&#233;sultats qu&#8217;un syst&#232;me tel 
que SEGCOHLEX se fondant seulement sur un r&#233;seau de collocations. Cet avantage existe aussi 
par rapport aux syst&#232;mes tels que TEXTTILING qui s&#8217;appuient sur la seule r&#233;currence lexicale 
et travaillent comme TOPICOLL &#224; partir d&#8217;un contexte local. Ces &#233;l&#233;ments semblent indiquer 
que l&#8217;utilisation conjointe de collocations et de la r&#233;currence lexicale est une approche 
int&#233;ressante. Ceci est d&#8217;ailleurs confirm&#233; par le fait que TOPICOLL est aussi plus pr&#233;cis que des 
syst&#232;mes manipulant des repr&#233;sentations de th&#232;me, &#224; l&#8217;image de SEGAPSITH. Ses performances 
sont &#233;galement l&#233;g&#232;rement sup&#233;rieures &#224; celles obtenues par (Bigi et al., 1998) en exploitant 
de telles repr&#233;sentations dans un cadre probabiliste : pr&#233;cision de 0,75, rappel de 0,80 et f1-
mesure de 0,77 sur un corpus constitu&#233; d&#8217;articles du Monde, a priori diff&#233;rents des n&#244;tres. 
</p>
<p>                                                 
3  Pk &#233;value la probabilit&#233; que deux mots choisis al&#233;atoirement dans un texte et s&#233;par&#233;s par k mots soient jug&#233;s 
</p>
<p>comme appartenant au m&#234;me segment alors qu&#8217;ils sont dans des segments diff&#233;rents (faux n&#233;gatif) ou qu&#8217;ils 
soient jug&#233;s comme appartenant &#224; des segments diff&#233;rents alors qu&#8217;ils sont dans le m&#234;me (fausse alarme). k 
est &#233;gal &#224; la moiti&#233; de la taille moyenne des segments au niveau du corpus de r&#233;f&#233;rence. 
</p>
<p>4  La pr&#233;cision est d&#233;finie par Nc / Nb et le rappel par Nc / D, o&#249; Nb est le nombre de bornes trouv&#233;es par 
TOPICOLL, Nc est le nombre de bornes trouv&#233;es correctes, i.e. correspondant &#224; des fronti&#232;res de textes dans un 
intervalle de 9 mots pleins autour de cette fronti&#232;re, et D le nombre total de fronti&#232;res de texte. 
</p>
<p>162 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmenter et structurer th&#233;matiquement des textes 
</p>
<p>5.1.2 &#201;valuation de la segmentation pour l&#8217;anglais : corpus de Choi 
</p>
<p>Pour l&#8217;anglais, nous avons utilis&#233; un corpus construit par Choi (Choi, 2000) pour comparer 
des syst&#232;mes de segmentation th&#233;matique. Ce corpus est compos&#233; de 700 textes artificiels 
constitu&#233;s chacun de 10 segments, chaque segment &#233;tant form&#233; des n premi&#232;res phrases de 
documents  issus du  corpus Brown.  Les sept premi&#232;res lignes du Tableau 2  proviennent des  
</p>
<p>Syst&#232;mes n &#8712;  [3,11] n &#8712;  [3,5] n &#8712;  [6,8] n &#8712; [9,11] 
base - Choi 0,45 0,38 0,39 0,36 
</p>
<p>CWM (Choi, 2001) 0,09 0,10 0,07 0,05 
U00 (Utiyama, Isahara, 2001) 0,10 0,09 0,07 0,05 
</p>
<p>C99 (Choi, 2000) 0,12 0,11 0,09 0,09 
DOTPLOT (Reynar, 1998) 0,18 0,20 0,15 0,12 
</p>
<p>SEGMENTER (Kan et al., 1998) 0,36 0,23 0,33 0,43 
TEXTTILING - Choi 0,46 0,44 0,43 0,48 
</p>
<p>TOPICOLL1 0,30 0,28 0,27 0,34 
TOPICOLL2 0,31 0,28 0,28 0,34 
</p>
<p>Tableau 2 : Pk pour le corpus de Choi 
</p>
<p>exp&#233;riences r&#233;alis&#233;es par Choi (Choi, 2001). La proc&#233;dure de base partitionne 
syst&#233;matiquement chaque document en 10 segments de m&#234;me longueur. Le Tableau 2 
confirme que la d&#233;tection de liens th&#233;matiques n&#8217;alt&#232;re pas les capacit&#233;s de segmentation de 
TOPICOLL. Il montre &#233;galement que les r&#233;sultats de TOPICOLL sur ce corpus sont 
significativement inf&#233;rieurs &#224; ceux obtenus sur le corpus du Monde. Une des causes possibles 
de cette diff&#233;rence r&#233;side dans notre r&#233;seau de collocations pour l&#8217;anglais : sa densit&#233;, c&#8217;est-&#224;-
dire le rapport entre la taille de son vocabulaire et son nombre de collocations, est inf&#233;rieure 
de 30% &#224; celle du r&#233;seau pour le fran&#231;ais, ce qui a certainement un impact significatif. Le 
Tableau 2 montre aussi que TOPICOLL, qui n&#8217;utilise qu&#8217;un contexte local, a des performances 
inf&#233;rieures &#224; des syst&#232;mes tels que CWM, U00, C99 ou DOTPLOT, qui traitent globalement les 
textes qui leur sont soumis. Cette vue globale am&#233;liore la pr&#233;cision mais se traduit par une 
plus grande complexit&#233; algorithmique. Par ailleurs, la d&#233;tection de liens th&#233;matiques permise 
par les contextes th&#233;matiques rend TOPICOLL fonctionnellement plus riche. 
</p>
<p>5.2 &#201;valuation globale 
</p>
<p>L&#8217;&#233;valuation globale d&#8217;un syst&#232;me tel que TOPICOLL se heurte &#224; un probl&#232;me : une r&#233;f&#233;rence 
pour les liens th&#233;matiques est n&#233;cessairement li&#233;e &#224; une segmentation de r&#233;f&#233;rence. Or, 
projeter cette r&#233;f&#233;rence sur les segments d&#233;finis par le syst&#232;me &#224; &#233;valuer n&#8217;est pas une 
op&#233;ration directe. Pour contourner ce probl&#232;me, nous avons choisi une m&#233;thode proche de 
celle adopt&#233;e dans TDT pour la t&#226;che Link Detection : nous &#233;valuons la probabilit&#233; d&#8217;une 
erreur dans la classification de chaque couple de positions d&#8217;un texte comme faisant partie du 
m&#234;me th&#232;me (Cpident) ou appartenant &#224; des th&#232;mes diff&#233;rents (Cpdiff). Un faux n&#233;gatif est 
comptabilis&#233; lorsque les positions d&#8217;un couple sont suppos&#233;es relever de th&#232;mes diff&#233;rents 
alors qu&#8217;ils sont relatifs au m&#234;me th&#232;me. Une fausse alarme correspond au cas 
compl&#233;mentaire. 
</p>
<p>163 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier Ferret 
</p>
<p>Syst&#232;mes Faux n&#233;gatif Fausse alarme Erreur (Pk) 
base 0,85 0,06 0,45 
</p>
<p>TOPICOLL 0,73 0,01 0,37 
</p>
<p>Tableau 3 : Mesures globales pour le corpus du Monde 
</p>
<p>Le nombre de couples Cpdiff &#233;tant en g&#233;n&#233;ral beaucoup plus grand que le nombre de couples 
Cpident, nous avons al&#233;atoirement s&#233;lectionn&#233; un nombre de couples Cpdiff &#233;gal au nombre de 
couples Cpident de mani&#232;re &#224; pr&#233;server une plage de valeurs assez &#233;tendue. Le Tableau 3 
montre les r&#233;sultats de TOPICOLL pour cette mesure et les compare &#224; une proc&#233;dure de base 
choisissant al&#233;atoirement un nombre fixe de bornes de segments et de liens d&#8217;identit&#233; 
th&#233;matique entre segments. Cette mesure est une premi&#232;re proposition qui doit encore &#234;tre 
am&#233;lior&#233;e, en particulier pour obtenir un meilleur &#233;quilibre entre les faux n&#233;gatifs et les 
fausses alarmes. 
</p>
<p>6 Conclusion 
</p>
<p>Nous avons propos&#233; une m&#233;thode r&#233;alisant de fa&#231;on int&#233;gr&#233;e la segmentation th&#233;matique de 
textes et la d&#233;tection de liens d&#8217;identit&#233; th&#233;matique en utilisant conjointement des collocations 
et la r&#233;currence lexicale. Son &#233;valuation a montr&#233; l&#8217;int&#233;r&#234;t de cette approche pour des 
syst&#232;mes travaillant avec un contexte local. Afin d&#8217;&#233;largir sa validation, nous envisageons de 
l&#8217;appliquer &#224; des m&#233;thodes se fondant sur une appr&#233;hension globale des textes. Par ailleurs, 
nous souhaitons &#233;tendre son &#233;valuation en am&#233;liorant la mesure globale que nous avons 
propos&#233;e et en confrontant nos r&#233;sultats &#224; des jugements humains. 
</p>
<p>R&#233;f&#233;rences 
</p>
<p>Beeferman D., Berger A., Lafferty J. (1999), Statistical Models for Text Segmentation, Ma-
chine Learning, Vol. 34(1/3), pp. 177-210. 
</p>
<p>Bigi B., de Mori R., El-B&#232;ze M., Spriet T. (1998), Detecting topic shifts using a cache mem-
ory, Actes de la 5&#232;me International Conference on Spoken Language Processing, 2331-2334. 
</p>
<p>Church K. W., Hanks P. (1990), Word Association Norms, Mutual Information, And Lexi-
cography, Computational Linguistics, Vol. 16(1), pp. 177-210. 
</p>
<p>Choi F., Wiemer-Hastings P., Moore J. (2001), Latent Semantic Analysis for Text Segmenta-
tion, Actes de NAACL&#8217;01, 109-117. 
</p>
<p>Choi F. (2000), Advances in domain independent linear text segmentation, Actes de 
NAACL&#8217;00, 26-33. 
</p>
<p>Ferret O., Grau B. (2000), A Topic Segmentation of Texts based on Semantic Domains, Actes 
de ECAI 2000, 426-430. 
</p>
<p>Ferret O. (1998) How to thematically segment texts by using lexical cohesion?, Actes de 
ACL-COLING&#8217;98, 1481-1483. 
</p>
<p>164 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmenter et structurer th&#233;matiquement des textes 
</p>
<p>165 
</p>
<p>Hearst M. (1997), TextTiling: Segmenting Text into Multi-paragraph Subtopic Passages, 
Computational Linguistics, Vol. 23(1) , pp. 33-64. 
</p>
<p>Kan M-Y., Klavans J., McKeown K. (1998), Linear segmentation and segment significance, 
Actes du 6&#232;me Workshop on Very Large Corpora, 197-205. 
</p>
<p>Kaufmann S. (1999), Cohesion and Collocation: Using Context Vectors in Text Segmenta-
tion, Actes de ACL&#8217;99, 591-595. 
</p>
<p>Kozima H. (1993), Text Segmentation Based on Similarity between Words, Actes de ACL&#8217;93, 
286-288. 
</p>
<p>Morris J., Hirst G. (1991), Lexical Cohesion Computed by Thesaural Relations as an Indica-
tor of the Structure of Text, Computational Linguistics, Vol. 17(1) , pp. 21-48. 
</p>
<p>Passonneau R., Litman D. (1997), Discourse Segmentation by Human and Automated Means, 
Computational Linguistics, Vol. 23(1) , pp. 103-139. 
</p>
<p>Reynar R. (1998), Topic segmentation: Algorithms and applications, Ph.D. thesis, Computer 
and Information Science, University of Pennsylvania. 
</p>
<p>Utiyama M., Isahara H. (2001), A Statistical Model for Domain-Independent Text 
Segmentation, Actes de ACL 2001, 491-498. </p>

</div></div>
</body></html>