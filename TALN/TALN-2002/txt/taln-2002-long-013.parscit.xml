<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Beeferman</author>
<author>A Berger</author>
<author>J Lafferty</author>
</authors>
<title>Statistical Models for Text Segmentation,</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<volume>34</volume>
<issue>1</issue>
<pages>177--210</pages>
<contexts>
<context position="20477" citStr="Beeferman et al., 1999" startWordPosition="3246" endWordPosition="3249">ontexte comme contexte propre. TOPICOLL fait ainsi l’hypothèse que le nouveau segment continue à développer le thème déjà abordé. Lorsque plusieurs segments sont possibles, TOPICOLL choisit celui pour lequel la similarité des contextes est la plus forte. 5 Expérimentations 5.1 Segmentation thématique Pour évaluer les capacités de segmentation thématique de TOPICOLL, nous l’avons appliqué à la tâche classique de redécouverte des frontières d’un ensemble de textes concaténés. Pour la mesure des performances, nous avons utilisé la mesure d’erreur probabiliste Pk proposée dans 161 Olivier Ferret (Beeferman et al., 1999) et maintenant largement utilisée3. Nous avons également calculé la précision et le rappel afin de permettre la comparaison avec certains systèmes plus anciens. 5.1.1 Évaluation de la segmentation pour le français : corpus du journal Le Monde L’évaluation pour le français a été réalisée sur un ensemble de 49 textes longs de 133 mots en moyenne, extraits du journal Le Monde (1995) et couvrant 11 thèmes. Les résultats du Tableau 1 sont des moyennes obtenues sur 10 ordonnancements différents de ces textes. Une procédure (BASE) choisissant aléatoirement un nombre fixe de fins de phrase comme borne</context>
</contexts>
<marker>Beeferman, Berger, Lafferty, 1999</marker>
<rawString>Beeferman D., Berger A., Lafferty J. (1999), Statistical Models for Text Segmentation, Machine Learning, Vol. 34(1/3), pp. 177-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Bigi</author>
<author>R de Mori</author>
<author>M El-Bèze</author>
<author>T Spriet</author>
</authors>
<title>Detecting topic shifts using a cache memory,</title>
<date>1998</date>
<booktitle>Actes de la 5ème International Conference on Spoken Language Processing,</booktitle>
<pages>2331--2334</pages>
<marker>Bigi, de Mori, El-Bèze, Spriet, 1998</marker>
<rawString>Bigi B., de Mori R., El-Bèze M., Spriet T. (1998), Detecting topic shifts using a cache memory, Actes de la 5ème International Conference on Spoken Language Processing, 2331-2334.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>P Hanks</author>
</authors>
<date>1990</date>
<journal>Word Association Norms, Mutual Information, And Lexicography, Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<pages>177--210</pages>
<marker>Church, Hanks, 1990</marker>
<rawString>Church K. W., Hanks P. (1990), Word Association Norms, Mutual Information, And Lexicography, Computational Linguistics, Vol. 16(1), pp. 177-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Choi</author>
<author>P Wiemer-Hastings</author>
<author>J Moore</author>
</authors>
<title>Latent Semantic Analysis for Text Segmentation, Actes de NAACL’01,</title>
<date>2001</date>
<pages>109--117</pages>
<marker>Choi, Wiemer-Hastings, Moore, 2001</marker>
<rawString>Choi F., Wiemer-Hastings P., Moore J. (2001), Latent Semantic Analysis for Text Segmentation, Actes de NAACL’01, 109-117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Choi</author>
</authors>
<title>Advances in domain independent linear text segmentation,</title>
<date>2000</date>
<booktitle>Actes de NAACL’00,</booktitle>
<pages>26--33</pages>
<contexts>
<context position="2598" citStr="Choi, 2000" startWordPosition="379" endWordPosition="380"> TDT (Topic Detection and Tracking). Cette dernière aborde les trois axes évoqués ci-dessus mais en se plaçant dans des domaines restreints et en les considérant principalement sous l’angle de tâches indépendantes. Les systèmes implémentant ces travaux peuvent être catégorisés en fonction du type des connaissances dont ils font usage. La plus grande partie de ceux dédiés à la segmentation thématique, c’est-à-dire au découpage des textes en segments thématiquement homogènes, s’appuient uniquement sur les caractéristiques intrinsèques des textes tels que la distribution des mots (Hearst, 1997 ; Choi, 2000 ; Utiyama, Isahara, 2001) ou des marqueurs linguistiques (Passonneau, Litman, 1997). Ils peuvent être utilisés sans restriction quant au domaine abordé mais leurs performances sont faibles lorsque la structure thématique des textes ne transparaît pas au travers des marques de surface qu’ils exploitent. Un second type de systèmes utilise des connaissances caractérisant la notion de cohésion lexicale. Ces connaissances, non liées à un domaine, prennent la forme d’un réseau de mots construit à partir d’un dictionnaire (Kozima, 1993 ; Morris, Hirst, 1991) ou d’un large ensemble de collocations is</context>
<context position="14822" citStr="Choi, 2000" startWordPosition="2344" endWordPosition="2345">ions thématiques du contexte de la fenêtre de suffisamment près pour ne pas passer à côté d’un changement de thème. 4.1.3 La similarité entre contextes thématiques Pour déterminer si le contenu de la fenêtre de focalisation est thématiquement cohérent avec le segment courant, on compare les contextes associés à ces deux entités. Cette comparaison est réalisée en deux étapes : une mesure de similarité est d’abord calculée entre les vecteurs des deux contextes ; les valeurs obtenues sont ensuite exploitées par une procédure de décision statuant sur la similarité des deux contextes. De même que (Choi, 2000) et (Kaufmann, 1999), nous utilisons la mesure du cosinus pour évaluer le degré de similarité entre un vecteur du contexte de la fenêtre (Vf) et le vecteur de même type dans le contexte du segment (Vs) : ∑ poidsx (mi ,Cs,t) ⋅ poidsx (mi ,Cf ,t) sim(Vsx ,Vfx ,t) = i∑ ⋅∑ (3) poidsx (mi ,Cs,t)2 poidsx (mi ,Cf ,t)2 i i où poidsx(mi,C{s,f}, t) est le poids du mot mi dans le vecteur x (txt ou coll) du contexte C{s,f}. 159 Olivier Ferret Afin de minimiser le bruit dans les vecteurs, cette mesure ne prend en compte que les mots les plus récurrents des contextes des segments, l’importance d’un mot dans</context>
<context position="23875" citStr="Choi, 2000" startWordPosition="3801" endWordPosition="3802">e). k est égal à la moitié de la taille moyenne des segments au niveau du corpus de référence. 4 La précision est définie par Nc / Nb et le rappel par Nc / D, où Nb est le nombre de bornes trouvées par TOPICOLL, Nc est le nombre de bornes trouvées correctes, i.e. correspondant à des frontières de textes dans un intervalle de 9 mots pleins autour de cette frontière, et D le nombre total de frontières de texte. 162 Segmenter et structurer thématiquement des textes 5.1.2 Évaluation de la segmentation pour l’anglais : corpus de Choi Pour l’anglais, nous avons utilisé un corpus construit par Choi (Choi, 2000) pour comparer des systèmes de segmentation thématique. Ce corpus est composé de 700 textes artificiels constitués chacun de 10 segments, chaque segment étant formé des n premières phrases de documents issus du corpus Brown. Les sept premières lignes du Tableau 2 proviennent des Systèmes n ∈ [3,11] n ∈ [3,5] n ∈ [6,8] n ∈ [9,11] base - Choi 0,45 0,38 0,39 0,36 CWM (Choi, 2001) 0,09 0,10 0,07 0,05 U00 (Utiyama, Isahara, 2001) 0,10 0,09 0,07 0,05 C99 (Choi, 2000) 0,12 0,11 0,09 0,09 DOTPLOT (Reynar, 1998) 0,18 0,20 0,15 0,12 SEGMENTER (Kan et al., 1998) 0,36 0,23 0,33 0,43 TEXTTILING - Choi 0,46</context>
</contexts>
<marker>Choi, 2000</marker>
<rawString>Choi F. (2000), Advances in domain independent linear text segmentation, Actes de NAACL’00, 26-33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Ferret</author>
<author>B Grau</author>
</authors>
<title>A Topic Segmentation of Texts based on Semantic Domains, Actes de ECAI</title>
<date>2000</date>
<pages>426--430</pages>
<marker>Ferret, Grau, 2000</marker>
<rawString>Ferret O., Grau B. (2000), A Topic Segmentation of Texts based on Semantic Domains, Actes de ECAI 2000, 426-430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Ferret</author>
</authors>
<title>How to thematically segment texts by using lexical cohesion?, Actes de ACL-COLING’98, 1481-1483. Segmenter et structurer thématiquement des textes</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>1</issue>
<pages>33--64</pages>
<contexts>
<context position="3228" citStr="Ferret, 1998" startWordPosition="472" endWordPosition="473">a, 2001) ou des marqueurs linguistiques (Passonneau, Litman, 1997). Ils peuvent être utilisés sans restriction quant au domaine abordé mais leurs performances sont faibles lorsque la structure thématique des textes ne transparaît pas au travers des marques de surface qu’ils exploitent. Un second type de systèmes utilise des connaissances caractérisant la notion de cohésion lexicale. Ces connaissances, non liées à un domaine, prennent la forme d’un réseau de mots construit à partir d’un dictionnaire (Kozima, 1993 ; Morris, Hirst, 1991) ou d’un large ensemble de collocations issues d’un corpus (Ferret, 1998 ; Kaufmann, 1999 ; Choi, 2001). Grâce aux relations entre mots qu’elles contiennent (synonymie, hyperonymie …), ces connaissances permettent d’écarter des changements de thème erronés définis sur la base de ruptures existant au niveau de la récurrence des mots. Un dernier type de systèmes s’appuie sur des connaissances directement liées aux thèmes apparaissant dans les textes qu’ils traitent. Dans le cas de TDT par exemple, ces connaissances sont construites de manière automatique à partir d’un ensemble de textes de référence caractérisant chaque thème considéré. (Bigi et al., 1998) se situe </context>
<context position="6676" citStr="Ferret, 1998" startWordPosition="1001" endWordPosition="1002">ns leur espace. Un changement de thème est détecté dès lors qu’une différence significative et durable est observée entre le contexte de la fenêtre et celui du segment dans laquelle elle se trouve. La détection de liens thématiques s’effectue quant à elle en comparant le contexte thématique de chaque nouveau segment avec celui des segments précédemment définis. TOPICOLL reprend donc le principe général d’analyse du système SEGAPSITH (Ferret, Grau, 2000) en introduisant au niveau des contextes thématiques la caractérisation de la cohésion lexicale développée dans le cadre du système SEGCOHLEX (Ferret, 1998). L’utilisation d’un réseau de collocations2 permet à TOPICOLL de trouver des relations entre les mots au-delà de la simple réitération et d’associer à chaque segment une représentation thématique plus riche, ce qui facilite des tâches comme la détection de liens thématiques. Néanmoins, des travaux tels que (Kozima, 1993), (Ferret, 1998) ou (Kaufmann, 1999) ont montré que le recours à des connaissances lexicales générales n’améliore souvent pas les performances par rapport à l’exploitation de la seule distribution des mots dans les textes. Les méthodes utilisées ne contrôlent pas en effet asse</context>
<context position="11765" citStr="Ferret, 1998" startWordPosition="1813" endWordPosition="1814"> du réseau de collocations utilisé. 0,48 = pm3 . 0,18 + pm4 . 0,13 + r1 r2 pm5 . 0,17 0,21 0,10 0,17 0,18 0,13 0,14 1,0 1,0 1,0 1,0 1,0 0,48 m1 m2 m3 m4 m5 mot sélectionné du réseau de collocations (avec son poids) mot du texte (avec pmi, son poids dans la fenêtre, égal à 1,0 1,0 pour tous les mots de la fenêtre dans cet exemple) 0,21 relation dans le réseau de collocations (avec sa valeur de cohésion) Figure 1 : Sélection et pondération des mots du réseau de collocations La construction du vecteur collocation du contexte de la fenêtre de focalisation s’inspire de la procédure présentée dans (Ferret, 1998) pour évaluer la cohésion lexicale d’un texte. Elle consiste à sélectionner les mots du réseau de collocations thématiquement proches de ceux de la fenêtre. Nous faisons l’hypothèse que cette proximité est liée au nombre de liens existant entre un mot du réseau et les mots de la fenêtre. Un mot du réseau est ainsi retenu s’il est lié à un nombre minimum – 3 dans nos expériences – de mots de la fenêtre. Chaque mot retenu se 158 Segmenter et structurer thématiquement des textes voit ensuite assigner un poids, égal à la somme des contributions des mots de la fenêtre auxquels il est lié (cf. Figur</context>
<context position="21635" citStr="Ferret, 1998" startWordPosition="3431" endWordPosition="3432">atoirement un nombre fixe de fins de phrase comme bornes de segment a servi de référence basse. Ses résultats dans le Tableau 1 sont des moyennes sur 1.000 tirages au sort. TOPICOLL1 est le système décrit au paragraphe 4. TOPICOLL2 est le même système mais avec inactivation de la partie détection de liens thématiques. Les résultats de ces deux variantes indiquent que la recherche de liens entre segments ne dégrade pas significativement les résultats de TOPICOLL en matière de segmentation. TEXTTILING est notre implé- Systèmes Rappel Précision F1- Faux Fausse Pk mesure négatif alarme SEGCOHLEX (Ferret, 1998) 0,68 0,37 0,48 nc nc nc SEGAPSITH (Ferret, Grau, 2000) 0,92 0,52 0,67 nc nc nc TEXTTILING 0,72 0,81 0,76 nc nc nc BASE 0,51 0,28 0,36 0,46 0,55 0,50 TOPICOLL1 0,86 0,74 0,80 0,17 0,24 0,21 TOPICOLL2 0,86 0,78 0,81 0,17 0,22 0,20 Tableau 1 : Précision/rappel et Pk pour le corpus du Monde4 mentation de l’algorithme de Hearst en utilisant les valeurs standards de ses paramètres. Le Tableau 1 montre clairement que TOPICOLL obtient de meilleurs résultats qu’un système tel que SEGCOHLEX se fondant seulement sur un réseau de collocations. Cet avantage existe aussi par rapport aux systèmes tels que T</context>
</contexts>
<marker>Ferret, 1998</marker>
<rawString>Ferret O. (1998) How to thematically segment texts by using lexical cohesion?, Actes de ACL-COLING’98, 1481-1483. Segmenter et structurer thématiquement des textes Hearst M. (1997), TextTiling: Segmenting Text into Multi-paragraph Subtopic Passages, Computational Linguistics, Vol. 23(1) , pp. 33-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-Y Kan</author>
<author>J Klavans</author>
<author>K McKeown</author>
</authors>
<title>Linear segmentation and segment significance,</title>
<date>1998</date>
<booktitle>Actes du 6ème Workshop on Very Large Corpora,</booktitle>
<pages>197--205</pages>
<contexts>
<context position="24432" citStr="Kan et al., 1998" startWordPosition="3896" endWordPosition="3899">nous avons utilisé un corpus construit par Choi (Choi, 2000) pour comparer des systèmes de segmentation thématique. Ce corpus est composé de 700 textes artificiels constitués chacun de 10 segments, chaque segment étant formé des n premières phrases de documents issus du corpus Brown. Les sept premières lignes du Tableau 2 proviennent des Systèmes n ∈ [3,11] n ∈ [3,5] n ∈ [6,8] n ∈ [9,11] base - Choi 0,45 0,38 0,39 0,36 CWM (Choi, 2001) 0,09 0,10 0,07 0,05 U00 (Utiyama, Isahara, 2001) 0,10 0,09 0,07 0,05 C99 (Choi, 2000) 0,12 0,11 0,09 0,09 DOTPLOT (Reynar, 1998) 0,18 0,20 0,15 0,12 SEGMENTER (Kan et al., 1998) 0,36 0,23 0,33 0,43 TEXTTILING - Choi 0,46 0,44 0,43 0,48 TOPICOLL1 0,30 0,28 0,27 0,34 TOPICOLL2 0,31 0,28 0,28 0,34 Tableau 2 : Pk pour le corpus de Choi expériences réalisées par Choi (Choi, 2001). La procédure de base partitionne systématiquement chaque document en 10 segments de même longueur. Le Tableau 2 confirme que la détection de liens thématiques n’altère pas les capacités de segmentation de TOPICOLL. Il montre également que les résultats de TOPICOLL sur ce corpus sont significativement inférieurs à ceux obtenus sur le corpus du Monde. Une des causes possibles de cette différence r</context>
</contexts>
<marker>Kan, Klavans, McKeown, 1998</marker>
<rawString>Kan M-Y., Klavans J., McKeown K. (1998), Linear segmentation and segment significance, Actes du 6ème Workshop on Very Large Corpora, 197-205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kaufmann</author>
</authors>
<title>Cohesion and Collocation: Using Context Vectors</title>
<date>1999</date>
<booktitle>in Text Segmentation, Actes de ACL’99,</booktitle>
<pages>591--595</pages>
<contexts>
<context position="3245" citStr="Kaufmann, 1999" startWordPosition="475" endWordPosition="476"> marqueurs linguistiques (Passonneau, Litman, 1997). Ils peuvent être utilisés sans restriction quant au domaine abordé mais leurs performances sont faibles lorsque la structure thématique des textes ne transparaît pas au travers des marques de surface qu’ils exploitent. Un second type de systèmes utilise des connaissances caractérisant la notion de cohésion lexicale. Ces connaissances, non liées à un domaine, prennent la forme d’un réseau de mots construit à partir d’un dictionnaire (Kozima, 1993 ; Morris, Hirst, 1991) ou d’un large ensemble de collocations issues d’un corpus (Ferret, 1998 ; Kaufmann, 1999 ; Choi, 2001). Grâce aux relations entre mots qu’elles contiennent (synonymie, hyperonymie …), ces connaissances permettent d’écarter des changements de thème erronés définis sur la base de ruptures existant au niveau de la récurrence des mots. Un dernier type de systèmes s’appuie sur des connaissances directement liées aux thèmes apparaissant dans les textes qu’ils traitent. Dans le cas de TDT par exemple, ces connaissances sont construites de manière automatique à partir d’un ensemble de textes de référence caractérisant chaque thème considéré. (Bigi et al., 1998) se situe dans la même pers</context>
<context position="7035" citStr="Kaufmann, 1999" startWordPosition="1054" endWordPosition="1055">finis. TOPICOLL reprend donc le principe général d’analyse du système SEGAPSITH (Ferret, Grau, 2000) en introduisant au niveau des contextes thématiques la caractérisation de la cohésion lexicale développée dans le cadre du système SEGCOHLEX (Ferret, 1998). L’utilisation d’un réseau de collocations2 permet à TOPICOLL de trouver des relations entre les mots au-delà de la simple réitération et d’associer à chaque segment une représentation thématique plus riche, ce qui facilite des tâches comme la détection de liens thématiques. Néanmoins, des travaux tels que (Kozima, 1993), (Ferret, 1998) ou (Kaufmann, 1999) ont montré que le recours à des connaissances lexicales générales n’améliore souvent pas les performances par rapport à l’exploitation de la seule distribution des mots dans les textes. Les méthodes utilisées ne contrôlent pas en effet assez précisément le type des relations qu’elles sélectionnent et ne tiennent pas compte de l’incomplétude de leurs connaissances. De ce fait, en même temps qu’elles permettent d’invalider à juste titre certains des changements de thème correspondant à une rupture dans l’usage du vocabulaire, elles introduisent des ruptures thématiques incorrectes du fait de l’</context>
<context position="14842" citStr="Kaufmann, 1999" startWordPosition="2347" endWordPosition="2348"> du contexte de la fenêtre de suffisamment près pour ne pas passer à côté d’un changement de thème. 4.1.3 La similarité entre contextes thématiques Pour déterminer si le contenu de la fenêtre de focalisation est thématiquement cohérent avec le segment courant, on compare les contextes associés à ces deux entités. Cette comparaison est réalisée en deux étapes : une mesure de similarité est d’abord calculée entre les vecteurs des deux contextes ; les valeurs obtenues sont ensuite exploitées par une procédure de décision statuant sur la similarité des deux contextes. De même que (Choi, 2000) et (Kaufmann, 1999), nous utilisons la mesure du cosinus pour évaluer le degré de similarité entre un vecteur du contexte de la fenêtre (Vf) et le vecteur de même type dans le contexte du segment (Vs) : ∑ poidsx (mi ,Cs,t) ⋅ poidsx (mi ,Cf ,t) sim(Vsx ,Vfx ,t) = i∑ ⋅∑ (3) poidsx (mi ,Cs,t)2 poidsx (mi ,Cf ,t)2 i i où poidsx(mi,C{s,f}, t) est le poids du mot mi dans le vecteur x (txt ou coll) du contexte C{s,f}. 159 Olivier Ferret Afin de minimiser le bruit dans les vecteurs, cette mesure ne prend en compte que les mots les plus récurrents des contextes des segments, l’importance d’un mot dans un contexte étant s</context>
</contexts>
<marker>Kaufmann, 1999</marker>
<rawString>Kaufmann S. (1999), Cohesion and Collocation: Using Context Vectors in Text Segmentation, Actes de ACL’99, 591-595.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kozima</author>
</authors>
<date>1993</date>
<booktitle>Text Segmentation Based on Similarity between Words, Actes de ACL’93,</booktitle>
<pages>286--288</pages>
<contexts>
<context position="3133" citStr="Kozima, 1993" startWordPosition="457" endWordPosition="458">èques des textes tels que la distribution des mots (Hearst, 1997 ; Choi, 2000 ; Utiyama, Isahara, 2001) ou des marqueurs linguistiques (Passonneau, Litman, 1997). Ils peuvent être utilisés sans restriction quant au domaine abordé mais leurs performances sont faibles lorsque la structure thématique des textes ne transparaît pas au travers des marques de surface qu’ils exploitent. Un second type de systèmes utilise des connaissances caractérisant la notion de cohésion lexicale. Ces connaissances, non liées à un domaine, prennent la forme d’un réseau de mots construit à partir d’un dictionnaire (Kozima, 1993 ; Morris, Hirst, 1991) ou d’un large ensemble de collocations issues d’un corpus (Ferret, 1998 ; Kaufmann, 1999 ; Choi, 2001). Grâce aux relations entre mots qu’elles contiennent (synonymie, hyperonymie …), ces connaissances permettent d’écarter des changements de thème erronés définis sur la base de ruptures existant au niveau de la récurrence des mots. Un dernier type de systèmes s’appuie sur des connaissances directement liées aux thèmes apparaissant dans les textes qu’ils traitent. Dans le cas de TDT par exemple, ces connaissances sont construites de manière automatique à partir d’un ense</context>
<context position="6999" citStr="Kozima, 1993" startWordPosition="1049" endWordPosition="1050">celui des segments précédemment définis. TOPICOLL reprend donc le principe général d’analyse du système SEGAPSITH (Ferret, Grau, 2000) en introduisant au niveau des contextes thématiques la caractérisation de la cohésion lexicale développée dans le cadre du système SEGCOHLEX (Ferret, 1998). L’utilisation d’un réseau de collocations2 permet à TOPICOLL de trouver des relations entre les mots au-delà de la simple réitération et d’associer à chaque segment une représentation thématique plus riche, ce qui facilite des tâches comme la détection de liens thématiques. Néanmoins, des travaux tels que (Kozima, 1993), (Ferret, 1998) ou (Kaufmann, 1999) ont montré que le recours à des connaissances lexicales générales n’améliore souvent pas les performances par rapport à l’exploitation de la seule distribution des mots dans les textes. Les méthodes utilisées ne contrôlent pas en effet assez précisément le type des relations qu’elles sélectionnent et ne tiennent pas compte de l’incomplétude de leurs connaissances. De ce fait, en même temps qu’elles permettent d’invalider à juste titre certains des changements de thème correspondant à une rupture dans l’usage du vocabulaire, elles introduisent des ruptures t</context>
<context position="11034" citStr="Kozima, 1993" startWordPosition="1682" endWordPosition="1683">mot par rapport aux autres mots du vecteur. Le vecteur texte est composé des mots venant du texte analysé tandis que le vecteur collocation contient les mots du réseau de collocations considérés comme fortement liés aux mots du texte. 4.1.1 Le contexte thématique de la fenêtre de focalisation (Cf) Le vecteur texte du contexte associé à la fenêtre de focalisation est constitué des mots pleins de cette fenêtre. Leur poids combine leur importance dans la partie du texte délimitée par la fenêtre, donnée par leur nombre d’occurrences, et leur degré de spécificité hors contexte, exprimé comme dans (Kozima, 1993) par l’information normalisée par rapport à un corpus de référence, en l’occurrence celui ayant permis la construction du réseau de collocations utilisé. 0,48 = pm3 . 0,18 + pm4 . 0,13 + r1 r2 pm5 . 0,17 0,21 0,10 0,17 0,18 0,13 0,14 1,0 1,0 1,0 1,0 1,0 0,48 m1 m2 m3 m4 m5 mot sélectionné du réseau de collocations (avec son poids) mot du texte (avec pmi, son poids dans la fenêtre, égal à 1,0 1,0 pour tous les mots de la fenêtre dans cet exemple) 0,21 relation dans le réseau de collocations (avec sa valeur de cohésion) Figure 1 : Sélection et pondération des mots du réseau de collocations La co</context>
</contexts>
<marker>Kozima, 1993</marker>
<rawString>Kozima H. (1993), Text Segmentation Based on Similarity between Words, Actes de ACL’93, 286-288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Morris</author>
<author>G Hirst</author>
</authors>
<title>Lexical Cohesion Computed by Thesaural Relations as an</title>
<date>1991</date>
<journal>Indicator of the Structure of Text, Computational Linguistics,</journal>
<volume>17</volume>
<issue>1</issue>
<pages>21--48</pages>
<marker>Morris, Hirst, 1991</marker>
<rawString>Morris J., Hirst G. (1991), Lexical Cohesion Computed by Thesaural Relations as an Indicator of the Structure of Text, Computational Linguistics, Vol. 17(1) , pp. 21-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Passonneau</author>
<author>D Litman</author>
</authors>
<title>Discourse Segmentation by Human and Automated Means,</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>1</issue>
<pages>103--139</pages>
<marker>Passonneau, Litman, 1997</marker>
<rawString>Passonneau R., Litman D. (1997), Discourse Segmentation by Human and Automated Means, Computational Linguistics, Vol. 23(1) , pp. 103-139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Reynar</author>
</authors>
<title>Topic segmentation: Algorithms and applications,</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="24383" citStr="Reynar, 1998" startWordPosition="3889" endWordPosition="3890">r l’anglais : corpus de Choi Pour l’anglais, nous avons utilisé un corpus construit par Choi (Choi, 2000) pour comparer des systèmes de segmentation thématique. Ce corpus est composé de 700 textes artificiels constitués chacun de 10 segments, chaque segment étant formé des n premières phrases de documents issus du corpus Brown. Les sept premières lignes du Tableau 2 proviennent des Systèmes n ∈ [3,11] n ∈ [3,5] n ∈ [6,8] n ∈ [9,11] base - Choi 0,45 0,38 0,39 0,36 CWM (Choi, 2001) 0,09 0,10 0,07 0,05 U00 (Utiyama, Isahara, 2001) 0,10 0,09 0,07 0,05 C99 (Choi, 2000) 0,12 0,11 0,09 0,09 DOTPLOT (Reynar, 1998) 0,18 0,20 0,15 0,12 SEGMENTER (Kan et al., 1998) 0,36 0,23 0,33 0,43 TEXTTILING - Choi 0,46 0,44 0,43 0,48 TOPICOLL1 0,30 0,28 0,27 0,34 TOPICOLL2 0,31 0,28 0,28 0,34 Tableau 2 : Pk pour le corpus de Choi expériences réalisées par Choi (Choi, 2001). La procédure de base partitionne systématiquement chaque document en 10 segments de même longueur. Le Tableau 2 confirme que la détection de liens thématiques n’altère pas les capacités de segmentation de TOPICOLL. Il montre également que les résultats de TOPICOLL sur ce corpus sont significativement inférieurs à ceux obtenus sur le corpus du Mond</context>
</contexts>
<marker>Reynar, 1998</marker>
<rawString>Reynar R. (1998), Topic segmentation: Algorithms and applications, Ph.D. thesis, Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Utiyama</author>
<author>H Isahara</author>
</authors>
<title>A Statistical Model for Domain-Independent Text Segmentation, Actes de ACL</title>
<date>2001</date>
<pages>491--498</pages>
<marker>Utiyama, Isahara, 2001</marker>
<rawString>Utiyama M., Isahara H. (2001), A Statistical Model for Domain-Independent Text Segmentation, Actes de ACL 2001, 491-498.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>