IALIV ZUUZ, Nancy, 24-2’/jum ZUUZ

LOGUS : un systéme formel de compréhension du francais
parlé spontané — présentation et évaluation

Jeanne Villaneau (1), J ean-Yves Antoine (1), Olivier Ridoux (2)
(1) VALORIA — Université de Bretagne Sud
4, rue Jean Zay, 56100 LORIENT
{J eanne.Villaneau,J ean-YVes.Antoine} @uniV-ubs .fr
(2) IRISA / IFSIC — Université de Rennes 1
Campus universitaire de Beaulieu, 35042 RENNES cedex
Olivier. Ridoux @ irisa.fr

Résumé - Abstract

Le systeme de compréhension présenté dans cet article propose une approche logique et
lexicalisée associant syntaxe et sémantique pour une analyse non sélective et hors-cadres
sémantiques prédéterminés. L’analyse se déroule suivant deux grandes étapes ; un chunking
est suivi d’une Inise en relation des chunks qui aboutit a la construction de la représentation
sémantique ﬁnale : formule logique ou graphe conceptuel. Nous montrons comment le for-
malisme a dﬁ évoluer pour accroitre l’importance de la syntaxe et améliorer la généricité des
regles. Malgré l’utilisation d’une connaissance pragmatico-sémantique liée a l’application,
la spéciﬁcité du systeme est circonscrite au choix des mots du lexique et a la déﬁnition de
cette connaissance. Les résultats d’une campagne d’évaluation ont mis en évidence une bonne
tolérance aux inattendus et aux phénomenes complexes, prouvant ainsi la validité de l’approche.

We present in this paper a speech understanding system with a lexicalized logical approach com-
bining syntax and pragmatic knowledge, but without selective methods or predeﬁned semantic
frames. The analysis is split into two phases: a chunking phase is followed with a second phase
in which different chunks are combined in order to obtain the semantic representation of the
sentence: logical formula or conceptual graph. We show how we have changed the formalism
to increase the part of the syntax and to obtain generic rules. Despite the use of a semantic
knowledge linked to the application, the speciﬁcity of the system is limited to the lexicon and
to the deﬁnition of this knowledge. The results of an evaluation campaign have showed a good
tolerance with the spontaneous spoken utterances and with the complex phenomena, and so,
they have showed the value of this approach.

Mots-clefs — Keywords

langue parlée spontanée, compréhension automatique, méthodes formelles
spontaneous spoken language, automated understanding, formal methods

165

JCIJIDIDC Vlrl/I/|lrIl«C|lrl/l«, JCIA/IL-1 V00 l_lIl«l/I/LIED, L/I/LVLCI l\lr(lrl/I/In/l«

1 Introduction et présentation générale

L’ apparition de serveurs vocaux mis a la disposition du grand public temoigne des progres ac-
complis depuis quelques annees dans la Communication orale Homme-Machine (CHM orale).
Cependant, ces indeniables succes sont encore restreints a des taches tres speciﬁques dans
des domaines d’application etroits. En aval des modules de reconnaissance de la parole, les
modules de comprehension s’appuient sur des analyses souvent selectives, minimalistes d’un
point de vue strictement linguistique. Bien que ces methodes aient prouve leur efﬁcacite pour
ce type d’application, la question n’est pas tranchee de savoir si elles sont encore utilisables
pour des taches moins restrictives (Hirschman, 1998). Par ailleurs, dans ces applications, la
comprehension d’un enonce correspond souvent a la reconnaissance d’un schema lie a la tache
et predetermine ; la Inise en oeuvre d’un dialogue plus cooperatif passe par une comprehension
plus ﬁne des intentions du locuteur (Pierrel et Romary, 2000). Le probleme est donc de proposer
des analyses d’enonces oraux qui soient ﬂexibles et tolerantes aux inattendus mais neanmoins
detaillees, et qui puissent produire une representation semantique souple et ﬁne de ces enonces.
Notre demarche consiste a faire reposer l’analyse sur une approche a la fois syntaxique et
semantiquel en nous appuyant, autant que cela est possible, sur les etudes linguistiques ex-
istantes de l’oral spontane.

Les inattendus de la parole spontanee rendent illusoire une analyse syntaxique complete des
enonces oraux. Cependant, des arguments linguistiques plaident en faveur de la possibilite
d’une analyse syntaxique locale de ces enonces : les etudes de Blanche-Benveniste sur le
francais parle (Blanche-Benveniste, 1990) attestent de regularites dans les “modes de produc-
tion de la langue orale”. L’une d’entre elles, particulierement interessante pour l’analyse, est
l’entassement paradigmatique : la recherche des mots suscite chez le locuteur un processus de
repetitions-corrections dans lequel les syntagmes sont systematiquement repris en leur debut
comme dans cet exemple : “pour la euh vers la station enﬁn euh vers la station de métro”.
Ainsi, ce processus preserve des structures Ininimales de groupes de mots syntaxiquement
coherentes. Les methodes d’analyse partielle deviennent courantes en TALN : ex. bunsetsu
pour la langue japonaise, ou chunks pour la langue anglaise, decrits par Abney comme des
unites semantiques et prosodiques (Abney, 1991). La correspondance entre les syntagmes de
Blanche-Benveniste et les chunks d’Abney est evidente. On peut en conclure qu’un chunking
est possible pour les enonces oraux, avec l’avantage essentiel de reduire le nombre d’elements
de l’enonce tout en rendant chacun d’entre eux plus “signiﬁants”.

La structure generale de l’enonce correspond aux liens entre chunks. Or si, en frangais, l’ordre
des mots est relativement respecte dans un chunk, il n’en est pas de meme de l’ordre des chunks
dans un enonce (Antoine et Goulian, 1999). Dans la mesure cependant ou les chunks possedent
une identite semantique sufﬁsante, on peut penser que la determination de ces liens entre chunks
peut etre etayee par les connaissances semantiques du systeme. 11 Va de soi que celles-ci seront
d’autant plus faciles a mettre en oeuvre que le domaine de l’application permettra de restreindre
l’ambigu'1'te.

Le systeme de comprehension presente dans cet article s’appuie sur le principe d’une analy-
se en deux grandes etapes : la premiere locale et a forte dominante syntaxique, la seconde
plus globale et syntaxico-semantique. L’approche est logique, tant dans les representations
choisies pour la comprehension que pour le formalisme des regles appliquees. Le domaine

1Parmi les travaux adoptant des approches plus ou moins similaires, citons (Lopez, 1999; Kurdi, 2001; Goulian
et Antoine, 2001).

166

IJL/KJL/L} u PI Cs)CIl«l/Ilrl/Ll/Il« CL CVIJI/I/l«Ilrl/lrl/Il«

d’application est celui du renseignement touristique, sufﬁsamment vaste pour qu’il soit difﬁcile
de prédéterminer toutes les requétes possibles et néanmoins sufﬁsamment restreint pour qu’il
soit possible de déﬁnir une connaissance sémantique spéciﬁquez. Notre présentation se base
sur la comparaison entre les deux premiers prototypes du systeme. En effet, le premier objec-
tif était la mise en oeuvre d’une analyse a la fois ﬁne et robuste, sans faire appel a des cadres
sémantiques prédéterminés, mais en s’appuyant sur une connaissance sémantique spéciﬁque au
domaine d’application. Une évaluation du premier prototype a prouvé que cet objectif était,
sinon completement atteint, du moins réalisable. Le second systeme, LOGUS 3, correspond a un
objectif de généricité : en effet, vouloir s’appuyer sur les connaissances sémantiques spéciﬁques
au domaine et en meme temps prétendre concevoir des regles indépendantes de ce domaine peut
sembler a priori paradoxal. Le formalisme adopté dans LOGUS semble prouver qu’il est possi-
ble de concilier une certaine généralité des regles et l’utilisation d’une connaissance sémantique
spéciﬁque. La comparaison des résultats des 2 systemes montre que LOGUS cumule les avan-
tages d’une plus grande généricité et d’une plus grande ﬁnesse dans l’analyse.

2 Premier prototype : principes et limites

Si l’on veut construire un systeme de compréhension relativement générique, il convient de
choisir une modélisation du “sens” de l’énoncé indépendante de l’application et qui permette
d’exprimer tout acte de dialogue lié a cette demiere : le systeme cherche a construire une
formule logique de facon compositionnelle (ex. a la Montague (Montague, 1974), mais avec un
formalisme simpliﬁé). La meme formule correspond a un graphe conceptuel a la Sowa (Sowa,
1984; Sowa, 1900). Par exemple, l’énoncé

“est-ce que c ’est possible de euh de réserver trois chambres non pardon deux chambres doubles
et une chambre simple.”

correspond a la formule suivante ou au graphe conceptuel de la ﬁgure 1 :

(interrogation possibilite
(de reservation (et (chambre (et (quantite (entier2))
(qualites doub1e)))
(chambre (et (quantite (entier 1))

(qualites simp1e))))))

<9

   
   
 

Figure 1: Representation de la phrase-exemple sous forme de graphe conceptuel

Dans le premier prototype, l’analyse se déroule suivant deux étapes principales (Villaneau et al,
2001) :

2On considére que le lexique lié a une telle application comprend entre 5000 et 10000 entrées.
3LOGica1 Understanding System

167

JCIJIDIDC Vlrl/I/|lrIl«C|lrl/l«, JCIA/IL-1 V00 l_lIl«l/I/LIED, L/I/LVLCI l\lr(lrl/I/In/l«

0 Le lexique donne, pour chaque lexeme connu, une ou plusieurs déﬁnitions dont chacune
est un A-terme. Dans l’étape de chunking, les regles utilisées sont d’ordre exclusive-
ment syntaxiques. Elles correspondent aux deux regles de composition des grammaires
catégorielles de type AB (Retoré, 2000) :

— (A, A\B) —> B : composition d’un élément de catégorie A avec un élément de
catégorie fractionnaire A\B situé a sa droite pour former un élément de catégorie B.

— (B /A, A) —> B : composition d’un élément de catégorie fractionnaire B /A avec
un élément de catégorie A situé a sa droite pour former un élément de catégorie B.

Les “représentations sémantiques” de ces chunks sont obtenues par composition de
A-termes suivant le principe du calcul de Lambeck (Moorgat, 1997). Ainsi par exem-
ple, les mots pas et cher correspondent respectivement aux A-termes (adj/adj Ax. (pas x ) )
et (adj cher). L’ application de la premiere regle donne en résultat (adj (pas cher)).

\

o A l’issue de l’étape de chunking, les syntagmes peuvent étre classés en trois catégories :

— les propriétés et objets de l’application,
— les syntagmes qui permettent de connaitre la nature de l’énoncé,

— les marqueurs des coordinations : coordinations proprement dites mais aussi mar-
ques d’hésitation ou de reprise.

La connaissance sémantique du systeme est déﬁnie par des relations de deux types :

— Les relations entre les objets, entre les objets et les propriétés et entre les pro-
priétés elles-memes peuvent étre considérées comme des graphes conceptuels
élémentaires ou comme des contraintes imposées a ces graphes, comme par exemple
estJ0us_0bjet( chambre,de, hotel) ou est_pr0priete_de((entier X ),quam‘ite, chambre ).
Si les objets et propriétés sont spéciﬁques au domaine d’application, les relations
elles-memes ont été choisies pour leur généricité. Le systeme s’appuie sur ces re-
lations pour construire des graphes conceptuels sémantiquement cohérents (appelés
“chaines d ’0bjets” ).

— Une autre partie de la connaissance sémantique est générique. Elle concerne par
exemple la nature de l’énoncé. En particulier, lorsque l’énoncé correspond a une
requéte, la détermination de la nature de cette requéte repose sur une relation d’ordre
partiel déﬁnie sur les “m0ts_questi0ns”ou “m0ts_requétes”. Dans les deux exem-
ples suivants, la requéte correspond au “mot” le plus fort indiqué par la relation
d’ordre :

([“je v0udrais”],[“sav0ir s” ],[ “il y a”]) —> il_y_a
([ “je v0udrais”],[ “la liste”],[ “s il vous plait”]) —> liste

La formule sémantique d’une phrase s’obtient par composition de la nature de l’énoncé
avec la ou les chaines d’objets obtenues, sous le controle de la connaissance sémantique
qui en vériﬁe la cohérence.

Le premier prototype a été soumis a une campagne d’évaluation dans le cadre du groupe de
travail 5.1 “compréhension robuste” du GDR I3 du CNRS (Antoine, 2001). L’objectif de cette
évaluation était de porter un diagnostic sur les systemes testés par une analyse ﬁne des erreurs
observées en regard des approches adoptées. Les résultats obtenus (les chiffres et quelques

168

IJL/KJL/L} u PI Cs)CIl«l/Ilrl/Ll/Il« CL CVIJI/I/l«Ilrl/lrl/Il«

commentaires concemant les différentes séries d’énoncés tests sont donnés au §4) montrent une
grande robustesse du systeme face a l’ordre des différents chunks, a la plupart des inattendus
structuraux de l’expression orale (corrections, répétitions, reprises) et aux objets complexes.
Entre autres, tres peu d’erreurs sont engendrées par l’étape du chunking et les liens sémantiques
établis entre les objets et leurs propriétés sont rarement erronés. Les erreurs les plus fréquentes
concement les incises et les faux-départs. En effet, l’absence totale de syntaxe dans la deuxieme
partie de l’analyse a laquelle s’ajoute une ignorance pure et simple des mots hors vocabulaire
rend impossible leur reconnaissance. Cette meme absence de syntaxe ne permet pas de dis-
tinguer les différentes parties d’un énoncé du type information-requéte, absent des tests de
l’évaluation mais assez fréquemment rencontré dans les corpus, tel que, par exemple : “j’ai
réserve’ 61 Z ’h6tel Caumartin comment je peuxfaire pour y aller d ’ici ”.

Par ailleurs et surtout, ce premier prototype est trop dépendant de l’application étudiée. La
connaissance sémantique y est mal circonscrite, et si ses grands principes sont réapplicables,
il n’en est pas de meme des regles utilisées, tant dans la phase du chunking que dans la phase
d’établissement des liens sémantiques.

3 LOGUS : représentations et régles

Des considérations sémantiques peuvent intervenir pour simpliﬁer le chunking : par exemple,
la préposition pour n’est pas indispensable a la compréhension dans l’expression “c’est pour
une demande...”. Mais surtout, l’analyse des erreurs a montré la nécessité d’introduire des

éléments syntaxiques dans la deuxieme partie de l’analyse.

Le formalisme élaboré pour LOGUS répond donc a un double objectif : d’une part il doit offrir
la possibilité d’associer la syntaxe et la sémantique tout au long de l’analyse ; d’autre part, il
doit aussi permettre de déﬁnir des regles de composition indépendantes de l’application et ce,
dans les deux étapes de l’analyse.

3.1 Modélisation

Pour concilier ces exigences, qui peuvent sembler contradictoires, de regles fondées sur des
arguments en grande partie sémantiques et en meme temps indépendantes de l’application, les
lexemes, puis, a chaque étape de l’analyse, les composants obtenus, sont représentés par un
triplet composé de :

1. Une catégorie syntaxique : les catégories peuvent étre simples ou fractionnaires, par
exemple : adjectif n0m_c0mmun, (det indefplur) (pour (déterminant indéﬁni pluriel))
sont des catégories syntaxiques simples.

2. Un réle sémantique qui peut également étre simple ou fractionnaire ; il correspond a
une classiﬁcation des différents constituants en objets, propriétés et autres mots. Par
exemple, objet, (prop quantite) (pour propriété de quantite’), interrogation sont des roles
sémantiques simples.

3. Une représentation sémantique qui correspond a la traduction proprement dite du consti-
tuant.

169

JCIJIDIDC Vlrl/I/|lrIl«C|lrl/l«, JCIA/IL-1 V00 l_lIl«l/I/LIED, L/I/LVLCI l\lr(lrl/I/In/l«

Ainsi, la deﬁnition du mot “réserver” est < in f initi f , obj ct, reservation >, le lexeme “peut-
on” correspond au triplet : < (gv 3 present), interrogation, possibilitc > ou la catégorie
syntaxique indique un groupe verbal a la troisieme personne au présent4. Les mots inconnus se
voient attribuer une catégorie syntaxique et un role sémantique spéciﬁques.

Les catégories syntaxiques sont totalement indépendantes de l’application. Les roles
sémantiques le sont dans une tres large mesure mais pas completement, en particulier pour
ce qui concerne les étiquettes des propriétés : aussi génériques soient-elles, des propriétés telles
que lieu et temps peuvent ne pas etre des propriétés des objets du domaine. Dans le déroulement
de l’analyse, a quelque niveau que ce soit, les regles utilisées sont déﬁnies a partir des deux pre-
miers éléments du triplet et des relations qui constituent la connaissance sémantique du systeme
concernant les objets de l’application.

3.2 Le chunking

Les deux premiers champs du triplet peuvent étre de type fractionnaires (au sens des regles des
grammaires AB). La représentation sémantique correspondante est alors une abstraction au sens
des A-termes. Le regroupement des mots dans un chunk correspond a l’application des deux
regles suivantes5, directement dérivées des deux regles des grammaires AB. La “representation
sémantique ” du triplet issu de la regle est le résultat de l’application de l’abstraction a la
representation sémantique du triplet “atomique” :

C (< C1,R1, S1 >, < C1\O2,R1\R2, ((1/b8t’I"  >) —> < O2,R2,  S1) >
C (< C1[C2,R1[R2, ((1/b8t7"  >, < O2,R2,S2 >) *> < O1,R1,  S2) >

Par exemple, les mots “trap” et “pas” ont respectivement pour catégorie syntaxique
(adjecti f\adjecti f) et (adjectif\c_adj) (c_adj correspondant a “chunk adjectival”), pour
role sémantique (prop R)\(prop R) ; les A-termes qui leur sont associés sont respective-
ment F1 = )\:t.:t et F2 = )\:1:.(pa3 1:) ; C’est ainsi que l’expression “pas trop cher” corres-
pond au triplet < c_adj, (prop tari f), (pas eleve) > ou (pas eleve) correspond au A-terme
()\:t.(F2 (F1  eleve).

La Inise en oeuvre du chunking correspond a l’application de toutes les compositions possibles.
Les solutions retenues sont celles qui aboutissent a un nombre minimum de constituants. Le
chunking est délibérément Ininimaliste (c-a-d. les chunks sont tres courts)6 ce qui fait que dans
la pratique, le chunking produit rarement plusieurs solutions optimales.

A l’issue du chunking, certains constituants sont éliminés : c’est le cas par exemple des
déterminants et prépositions ainsi que, d’une maniere générale de ceux qui correspondent a
des catégories syntaxiques et roles sémantiques fractionnaires, ce qui constitue un premier
traitement des reprises et hésitations. Ainsi, dans l’exemple ’’pour la euh vers la station”,
le syntagme incomplet ’’pour la” se trouve éliminé.

4Ce lexique dépend de l’application dans le choix des mots et de leurs déﬁnitions : le mot “prix” ne fait
référence qu’a la Valeur Vénale (et pas a la recompense) et le mot “ étoile ” ne se référe qu’aux hotels et restaurants.

5Les regles utilisées font également intervenir des relations d’ordre sur les catégories suivant un formalisme
inspiré du calcul sur les prégroupes (Buszkowski, 2001).

5Par exemple, dans l’expression “une chambre double euh non simple”, l’autocorrection est plus facile a gérer
si 1’on est en présence des quatre chunks [“une chambre”] [ “double ” ] [“euh non”] [ “simple” ] que des trois
chunks [ “une chambre double ”] [ “euh non”] [ “simple ”].

170

IJL/KJL/L} u PI Cs)CIl«l/Ilrl/Ll/Il« CL CVIJI/I/l«Ilrl/lrl/Il«

3.3 Liens sémantiques

La construction des “chaines d’objets” se fait a partir d’une base de regles qui utilisent la
connaissance sémantique. Cependant, ces regles ne dépendent que des relations déﬁnies entre
les objets et non des objets eux-mémes. Outre les coordinations, les regles traitent également
les répétitions, reprises et coordinations, lorsqu’elles correspondent a des syntagmes complets.
Ainsi la regle suivante gere une répétition avec enrichissement lexical (“un hotel deux étoiles
un hétel pas trop cher”) :

< C, objet, 01 > + < C, objet, 02 >
et —> < C, objet, R0 >
rnerne_ettquette(O1, O2), meme_prep(O1, O2)

ou R0 est l’objet obtenu par réunion des propriétés de 01 et 02.

Les lexemes qui permettent de déterminer la nature de l’énoncé sont également traités par ce
type de regles. Par exemple :

< 01; R11; RQ1 > + < 02, R12, RQ2 >
et —> < C, RI, RQ >
RI1 et R12 6 {z'nterr0gat7§0n, requete}

ou C et RI sont obtenus a partir de relations d’ordre (partiel) déﬁnies respectivement sur les
catégories syntaxiques et les roles sémantiques. La représentation sémantique RQ s’obtient
également a partir d’une relation d’ordre, qui correspond a celle déﬁnie pour le premier proto-
type sur les “m0ts_questi0ns” et “m0ts_requétes”. A l’issue de l’application de cette regle, les
triplets correspondants aux deux chunks [ “est-ce que”],[ “on peut”] correspondent au triplet

< (gv 3 present), interrogation, posstbtltte >.

La mise en oeuvre des regles fait intervenir plusieurs niveaux d’application7 qui ont une triple
justiﬁcation :

o logique : les liens sémantiques entre constituants ne sont pas de meme “poids” ; cer-
taines regles sont considérées comme prioritaires, par exemple la juxtaposition d’un objet
avec un nom propre correspondant au méme objet (composition des deux chunks “le
musée”, “du Louvre ”)8. Le premier niveau de composition correspond a l’application de
ce type de regles. Ensuite, les deux niveaux de composition suivants consistent a appli-
quer les regles dans leur ensemble, d’abord avec la barriere des mots inconnus, puis sans
cette barriere. Ce procédé correspond a un premier traitement, certes tres élémentaire, du
probleme des mots inconnus. Actuellement, les regles sont donc appliquées suivant trois
niveaux distincts.

o linguistique : les hésitations, reprises et auto-corrections induisent des “ratés” des la phase
du chunking. Certaines compositions évidentes ne sont pas effectuées lors de la phase ou
elles auraient dﬁ l’étre. La méthode utilisée correspond en quelque sorte a un relachement
progressif des contraintes de composition.

7On retrouve, appliquées a des regles sémantiques, un idée de l’ana1yse en cascade d’Abney (Abney, 1996).
8Le fait que “le musée du Louvre” corresponde a deux chunks est une illustration du caractere “mjnimaliste”
des chunks dont il a été question précédemment (cf. 3.2).

171

JCIJIDIDC Vlrl/I/|lrIl«C|lrl/l«, JCIA/IL-1 V00 l_lIl«l/I/LIED, L/I/LVLCI l\lr(lrl/I/In/l«

o calculatoire : la succession des différentes étapes de composition constitue un procédé
efﬁcace et rapide.

La derniere phase de composition essaie de trouver ce que Blanche-Benveniste appelle le
“noyau principal” de chacune des propositions dont est constitué l’énoncé (par exemple une
question ou un verbe lorsqu’ils existent) et de le relier aux autres éléments (qui a ce stade ne
sont plus si nombreux) ; si l’énoncé est composé de plusieurs noyaux principaux, le systeme
tente de les coordonner (le premier noyau sert de contexte au noyau suivant). Cette derniere
partie n’est pas actuellement completement achevée (cf. 5).

4 Quelques résultats

L’ évaluation du GDRI3 a laquelle a été soumis le premier prototype consiste en 1200 énoncés
tests répartis suivant quatre séries de 300 énoncés tres différentesg. Bien que simulés, ces tests,
qui représentent une sorte de catalogue des difﬁcultés rencontrées par tous les participants du
GDR, avec des points de vue tres différents, ont été tres révélateurs des comportements des
systemes testés.

Dans le tableau ci-dessous, les énoncés sont classés dans la catégorie “comprehension in-
complete” lorsque le sens general de l’énoncé a été dégagé mais qu’il y a eu omission d’un
élément non essentiel (l’une des propriétés d’un objet par exemple). Les series 1 et 2 permet-
tent essentiellement de mesurer la résistance du systeme face aux inattendus de l’expression
orale. Les résultats obtenus par les deux prototypes sont sensiblement égaux. La série 4 per-
met essentiellement de mesurer la couverture sémantique du systeme. La série 3 est composée
d’énoncés complexes ou les manifestations de l’expression orale sont poussées a l’extréme (tres
larges incises, reprises et expressions diverses). Ce sont essentiellement les résultats de cette
série qui permettent de mesurer les réels progres de l’analyse induits par la prise en compte
d’éléments syntaxiques lors de la deuxieme partie ; en effet, les énoncés tests de la série 3 ap-
partiennent en general a des domaines linguistiques sémantiques déja couverts par le premier
prototype. Le fait que le systeme puisse dégager le “sens” général d’énoncés aussi complexes
est un résultat tres encourageant.

Premier prototype Série 1 Série 2 Série 3 Série 4 Total
Enoncés compris : nb 277 279 144 157 857
Compréhension incomplete : nb 11 10 50 48 119
Nombre total 288 289 194 205 976
Enoncés compris : % 92.3 93 48 52.3 71.4
Compréhension incomplete : % 3.7 3.3 16.7 16 9.9
% total 96 96.3 64.7 68.3 81.3
Second prototype Série 1 Série 2 Série 3 Série 4 Total
Enoncés compris : nb 278 284 185 219 966
Compréhension incomplete : nb 16 10 71 50 147
Nombre total 294 294 256 269 1 1 13
Enoncés compris : % 92.7 94.7 61.7 73 80.5
Compréhension incomplete : % 5.3 3.3 23.7 16.7 12.3
% total 98 98 85.3 89.7 92.8

9Le protocole est décrit dans (Antoine, 2001).

172

IJL/KJL/L} u PI Cs)CIl«l/Ilrl/Ll/Il« CL CVIJI/I/l«Ilrl/lrl/Il«

5 Perspectives et conclusion

Actuellement, les erreurs de reconnaissance de la parole ne font l’objet d’aucun traitement par-
ticulier, la plupart étant résorbées par la souplesse donnée a l’analyse. Cependant, certaines
d’entre elles peuvent casser les régularités syntaxiques locales. Ces repercussions sur le chunk-
ing nous font envisager désormais un traitement particulier de ce type d’erreurs.

Par ailleurs, malgré l’introduction d’éléments syntaxiques dans la deuxieme partie de l’analyse,
le probleme qui consiste a distinguer les différentes propositions d’un énoncé n’est pas en-
core completement maitrisé. Le probleme est assez simple dans des énoncés comme : “j’ai
réserve’ une chambre an Caumartin comment je peux aller la-bas.” ou les deux propositions
sont centrées sur un groupe verbal et ou le temps du premier verbe et l’adverbe interrogatif sont
des indices sufﬁsantslo. Il en est tout autrement dans des énoncés sans verbe, tres fréquents dans
les différents actes de dialogue. Ce probleme rejoint alors celui de l’interprétation contextuelle,
qui ne se réduit pas, selon nous, a une simple adjonction a l’interprétation littérale. Mis a
part en effet les cas ou le contexte permet de compléter un énoncé sémantiquement cohérent
mais incomplet“, certains énoncés ne peuvent se “comprendre” qu’en fonction du contexte.
Pire encore, il est des cas ou l’absence de prise en compte du contexte rend les énoncés in-
cohérents au sens de l’interprétation littérale telle que nous l’avons déﬁnie : dans l’énoncé
“deux pour demain” par exemple, aucun lien sémantique ne relie a priori les deux propriétés”.
L’interprétation contextuelle est donc un élément essentiel de notre systeme dont nous avons
entamé l’implémentation. Le formalisme adopté semble contenir les éléments nécessaires pour
sa realisation.

La Inise au point de ce formalisme est d’ailleurs au centre de notre travail car il correspond in
des réponses possibles a quelques problemes selon nous fondamentaux :

o Représenter le sens d’un énoncé sans faire appel a des cadres sémantiques prédéterminés :
les travaux développés sur les graphes conceptuels (équivalences, inclusions), inutilisés
jusqu’a présent, sont l’une des raisons de notre choix et devraient se révéler bien utiles
par la suite.

0 Combiner les approches syntaxiques et sémantiques : le double étiquetage syntaxique et
sémantique semble particulierement bien adapté a cette démarche.

o Représenter la connaissance sémantique et concilier son utilisation avec la généricité des
regles utilisées : la encore, le double étiquetage semble étre un bon moyen de déﬁnir des
regles largement indépendantes de l’application. Le systeme actuel de ces regles est assez
efﬁcace mais surtout le formalisme adopté le rend aisément perfectible.

En fait, l’efﬁcacité de LOGUS montre que les réponses apportées a ces différentes questions
sont une voie possible pour mettre en oeuvre une analyse a la fois ﬁne et robuste des énoncés

1°Dans notre systeme, l’objet “chambre de I ’h6tel Caumartin” est le contexte de la requéte “comment aller la-
bas ” . Les contrajntes sémantiques imposent que “la—bas ” corresponde a l’h6tel Caumartin (et non a la cha1nbre...).
“Cette notion d’incomplétude ne Va d’ailleurs pas de soi des lors que l’on pretend s’abstrajre de requétes
prédéﬁnies avec des champs sémantiques a remplir d’une maniere obligatoire.
12Ce probleme est soulevé par Pierrel et Romary dans (Pierrel et Romary, 2000).

173

JCIJIDIDC Vlrl/I/|lrIl«C|lrl/l«, JCIA/IL-1 V00 l_lIl«l/I/LIED, L/I/LVLCI l\lr(lrl/I/In/l«

oraux. Quelle que soit la méthode adoptée pour y parvenir, les progres dans le domaine du
DOHM passent, selon nous, par de tels travaux.

Références

S. Abney. Parsing by chunks. In Principle Based Parsing. R.Berwick, S.Abney and C.Tenny, Eds.,
Kluwer Academic Publishers., 1991.

S. Abney. Partial parsing via ﬁnite-state cascades. In J. Carroll, editor, Workshop on Robust Parsing
ESSLLI’96, pages 8-15, 1996.

J .-Y. Antoine and J . Goulian. Le francais parlé spontané est-il un langage a ordre variable ? In Actes des
Journe’es Intemationales de Linguistique Applique’e, JIIA’99, Nice, France, 1999.

J .-Y. Antoine. Evaluation des systemes de CAP, campagne d’évaluation “par déﬁ”. Technical report,
GDR-PRC-I3, Ple Parole, G.T. 5.1., http://www.univ-ubs.fr/valoria/antoine/Gt51/EvaL deﬁ.html, 2001.

C. Blanche-Benveniste. Le francais park ; e’tudes grammaticales. CNRS Editions, Paris, 1990.

W. Buszkowski. Lambek grammars based on pregroups. In Logical Aspects of Computational Linguis-
tics, pages 95-109, Le Croisic, 2001. Springer.

J . Goulian and J .-Y. Antoine. Comprehension automatique de la parole combinant syntaxe locale et
sémantique globale pour une CHM portant sur des taches relativement complexes. In TALN 2001, pages
203-212, Tours, France, 2001.

L. Hirschman. Language understanding evaluation: lessons learned from MUC and ATIS. In Ist Int.
Conf Language Ressources and Evaluation, LREC’98, Grenade, Espagne, pages 117-122, 1998.

M.Z. Kurdi. A spoken understanding approach which combines the parsing robustness with the inter-
pretation deepness. In ICAI, Las Vegas, USA, 2001.

P. Lopez. Analyse d ’e’nonce’s oraux pour le dialogue homme-machinea l ’aide de grammaires lexicalisées
d ’arbres. PhD thesis, UHP-Nancy I, 1999.

R. Montague. Formal Philosophy. Yale University Press, New Haven, USA, 1974.

M. Moorgat. Categorial Type Logics. In Elsevier Science B.V., editor, Handbook of Logic and Lan-
guage, pages 93-177. J . van Benthem and A. ter Meulen, 1997.

J .M. Pierrel and L. Romary. Inge’nierie des langues, chapitre Dialogue Homme-Machine, pages 331-
349. Hermes, 2000.

C. Retoré. Systemes déductifs et traitement des langues 2 un panorama des grammaires catégorielles.

Technique et Science Informatique, numéro spe’cial de Traitement automatique du langage naturel,
20(3):301-336, 2000.

J . F. Sowa. Conceptual Structures : Information Processing in Mind and Machine. Addison-Wesley,
Reading, MA, 1984.

J .F. Sowa. Knowledge Representation. Brooks/Cole Thomson Learning, USA, 2000.

J . Villaneau, J .-Y. Antoine, and O. Ridoux. Combining syntax and pragmatic knowledge for the un-
derstanding of spontaneous spoken sentences. In Logical Aspects of Computational Linguistics, pages
279-295, Le Croisic, 2001. Springer.

174

