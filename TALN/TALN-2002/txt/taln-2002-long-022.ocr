IALIV ZUUZ, Nancy, 24-2’/jum ZUUZ

Webafﬁx : un outil d’acquisition morphologique
dérivationnelle a partir du Web

Ludovic Tanguy & Nabil Hathout
ERSS — CNRS & Université de Toulouse Le Mirail
{tanguy, hathout} @univ-tlse2.fr

Résumé - Abstract

L’ article présente Webafﬁx, un outil d’acquisition de couples de lexemes morphologiquement
apparentés a partir du Web. La méthode utilisé est inductive et indépendante des langues parti-
culieres. Webafﬁx (1) utilise un moteur de recherche pour collecter des formes candidates qui
contiennent un sufﬁxe graphémique donné, (2) prédit les bases potentielles de ces candidats
et (3) recherche sur le Web des cooccurrences des candidats et de leurs bases prédites. L’ou-
til a été utilisé pour enrichir Verbaction, un lexique de liens entre verbes et noms d’action ou
d’événement correspondants. L’ article inclut une évaluation des liens morphologiques acquis.

This paper presents Webafﬁx, a tool for ﬁnding pairs of morphologically related words on the
Web. The method used is inductive and language-independent. Using the W as a corpus, the
Webafﬁx tool detects the occurrences of new derived lexemes based on a given graphemic sufﬁx,
proposes a base lexeme, and then performs a compatibility test on the word pairs produced,
using the Web again, but as a source of cooccurrences. The resulting pairs of words are used to
enrich the Verbaction lexical database, which contains French verbs and their related nominals.
The results are described and evaluated.

Mots-clefs — Keywords

Morphologie dérivationnelle, ressource lexicale, Web comme corpus, analogie.
Derivational morphology, lexical resource, Web as corpus, analogy.

1 Introduction

Ce travail s’inscrit dans le cadre général du développement de ressources lexicales pouvant étre
utilisées dans différentes applications du TAL. L’ exemple qui nous a servi de tremplin est le
lexique Verbactionl qui contient 6 471 couples verbe:nom, tels que le nom est morphologique-
ment apparenté au verbe et qu’il dénote l’action ou l’événement correspondant a ce verbe. I1
s’agit d’une ressource lexicale générique dont des exemples d’uti1isation seront présentés ci-
dessous. Notre but initial est d’étendre ce lexique, en y aj outant des liens morphologiques entre

1Ce lexique a été réalisé a l’INaLF (CNRS, USR705) a partir de TLFnome, en 1997, par A. Berche, F. Mougin,
N. Hathout et J. Lecomte. TLFnome est un lexique de formes ﬂéchies construit a1’INaLF par J. Maucourt et M.
Papin, a partir de la nomenclature du Trésor de la langue Frangaise (TLF).

245

141/LIA/I/Vila Ill/IP61/I1)’ LX. IVIJL/LL llllrl/Ill/I/It

des lexemes moins courants, voire des néologismes, et en travaillant pour ce faire sur corpus.
Mais plutot que d’exploiter un corpus « traditionnel » comme les archives électroniques de jour-
naux (Le Monde, Libération, etc.), nous avons préféré utiliser le Web comme corpus. Ce choix,
aisément justiﬁable par la masse d’information textuelle disponible, rend toutefois nécessaire
de prendre un certain nombre de précautions, ce corpus étant caractérisé par son hétérogénéité
et le manque de controle sur son contenu.

2 Vue d’ensemble

- I I Recherche de **
L1ste de reference jr nouvelles formes I WWW
Base d’amorgage +
Lexique fllexionnel Liste de formes candidates

Regles de prédiction :>- Prédiction des bases

+

Liste de couples ca1ndidat:base—prédite

Filtrage par >
les cooccurrences

+

Liste de couples filtrée

WWW

FIG. 1 — Vue d’ensemble des modules de Webafﬁx.

Notre méthode est représentée graphiquement en ﬁgure 1. Elle peut se résumer de la facon sui-
vante : nous recherchons sur le Web, a 1’aide d’un moteur de recherche généraliste, des formes
lexicales nouvelles, en fonction de leur terminaison (en fait, d’un sufﬁxe graphémique donné).
Par « nouvelles », nous entendons simplement absentes d’une liste de référence, par exemple un
lexique électronique. Les terminaisons sélectionnées pour l’enrichissement de Verbaction sont
les principaux sufﬁxes qui permettent de construire des noms d’action et d’événement a partir
de verbes (-ade, -age, -ance, -ement, -ence, -erie, -tion). On trouve ainsi par exemple comme
formes candidates démshage, hélitreuillage pour -age, ou judiciarisation ou icémﬁcation pour
-tion. Une fois ces nouvelles formes collectées, nous calculons pour chacune d’elles des formes
graphémiques susceptibles d’étre des formes ﬂéchies du lexeme base du candidat. Cette pre-
diction est réalisée par analogie avec une base dérivationnelle existante (comme Verbaction),
ou bien a 1’aide d’un ensemble de regles d’afﬁxation apprises a partir d’un lexique ﬂexionnel,
par exemple, en utilisant la technique proposée dans DéCor (Dal et al. 1999). Dans le cas de
notre expérience, les formes candidates sont supposées nominales et les formes bases verbales
sont calculées en utilisant Verbaction. Nous prédisons par exemple, pour le candidat ic6mﬁca-
tion, les formes icéniﬁait, icémﬁant, icémﬁe, icémﬁent, icémﬁer, icéniﬁera... de son lexeme
base. Enﬁn, dans une troisieme étape, nous ﬁltrons les couples lexeme-candidat:lexeme-base-
prédit ainsi constitués en recherchant, toujours sur le Web, a l’aide d’un moteur de recherche,
des cooccurrences dans une méme page des formes des deux lexemes du couple candidat. Ne
retenant que les couples pour lesquels une telle cooccurrence a été trouvée, nous procédons a
une révision manuelle ﬁnale, grandement facilitée par le fait que les contextes des formes co-

246

VVCL/Ildlllv./l«

occurrentes sont conservés par la derniere étape. Notre but n’est pas ici d’obtenir, dans la base
de données construite in ﬁne, une couverture la plus large possible, mais plutot de garantir une
bonne précision dans les résultats obtenus.

La méthode que nous proposons est assez proche de celle implémentée dans GéDériF (Dal et
Namer 2000). Cet outil génere un ensemble de mots possibles candidats a partir d’un lexique
puis les ﬁltre pour ne conserver que ceux qui sont attestés en particulier sur le Web. Comme pour
Webafﬁx, le traitement comporte trois étapes : un ensemble de radicaux est constitué en analy-
sant les lemmes du lexique en -able et en -iser a l’aide de l’analyseur morphologique DériF ; il
concatene ensuite a ces lemmes les -able, -iser et -ite’ (complémentaire avec la terminaison ori-
ginale du radical); GéDériF ﬁltre les candidats obtenus en recherchant leurs attestations éven-
tuelles dans des corpus textuels et sur le Web en utilisant le moteur www . yahoo . fr. L’ objectif
de GéDériF est plus théorique que le notre dans la mesure ou la construction de lexemes en -
abiliser, -abilite’, -isable, -isabilite’... vise autant a valider les hypotheses linguistiques proposées
par les autrices qu’a construire un ensemble de micro-familles constructionnelles.

Il est a noter des a present que cette méthode ne demande pour son établissement que peu de
ressources : une liste de référence permettant de ﬁltrer les unités déja répertoriées pour la pre-
miere étape; et pour la deuxieme étape, un ensemble de regles ou de schémas dérivationnels
et ﬂexionnels appris a partir d’une éventuelle base existante et d’un lexique de formes ﬂéchies.
Aucune connaissance linguistique n’étant implémentée dans l’outil, il est adapté a l’acquisition
d’autres types de liens morphologiques (nom:adjectif, adjectif:adverbe...), mais aussi d’autres
langues a morphologie concaténative comme les langues romanes et germaniques. Par ailleurs,
cette méthode est incrémentale : Webafﬁx est destiné a étre régulierement applique sur le Web,
proﬁtant de l’accumulation de l’information obtenue lors de passages précédents, et de la dyna-
mique des bases de documents indexes par les moteurs de recherche.

3 Le lexique Verbaction

Les ressources que Webafﬁx permet de constituer sont du type du lexique Verbaction. Cette
base est avant tout une ressource pour le TAL destinée au traitement des variations morpho-
syntaxiques (Jacquemin 1997). Les hypotheses théoriques sous-jacentes sont minimales. Au-
cune distinction n’est faite entre les conversions et les constructions sufﬁxales dans la mesure
ou la nature de converti ou de sufﬁxé n’est pas prise en compte par les systemes qui utilisent
cette ressource (seule compte la relation sémantique entre le verbe et le nom). Les liens séman-
tiques spéciﬁques entre noms et verbes ne sont pas explicités. Le principe est ici seulement de
répertorier des liens sémantiques entre un verbe et un nom d’action ou d’événement auquel il
est dérivationnellement apparenté comme e’lire:e’lecti0n, de’me’nager:de’me’nagement... Ce type
de ressource est utile a divers titres. Nous nous donnons ici quelques exemples de son utilisation.

En recherche d’information, l’équivalence sémantique des variantes morpho-syntaxiques peut
aisément étre utilisée pour l’extension de requétes. Par exemple, rechercher élection pre’siden-
tielle est equivalent, en RI, a rechercher élire le président.

En analyse syntaxique automatique, certaines relations argumentales peuvent étre partagées
par les prédicats nominaux et verbaux. L’ analyseur syntaxique Syntex (Bourigault et Fabre
2000) utilise dans sa procédure d’apprentissage endogene les liens contenus dans le lexique
Verbaction pour repérer ce type de partage. Par exemple, la présence d’un SN comme des phe’-
noménes de transport sur coussin d ’air emprisonne’ est un indice en faveur du rattachement de

247

141/LIA/I/Vila Ill/IP61/I1)’ LX. IVIJL/LL llllrl/Ill/I/It

sur le fond au Verbe transporter dans les vagues transportent des Sables sur le fond. 2

Toutes ces utilisations visent donc a aj outer une annotation supplémentaire d’un corpus (préala-
blement étiqueté morphosyntaxiquement), et celle-ci sera d’autant plus complete que le lexique
recensant ces relations morphologiques sera plus étendu.

4 Le Web comme corpus

Le corpus sur lequel porte notre étude, et notre recherche d’unités et d’informations lexicales,
est le Web, et non un corpus classique. Comme le note Grefenstette (1999), nombre de lin-
guistes peuvent, a juste titre, se montrer réticents a utiliser le Web comme source d’attestations,
étant donné l’impossibilité technique de caractériser les pages sur le plan du domaine, du genre,
du statut de l’auteur, de la validité du contenu, etc. 11 n’en reste pas moins que le Web constitue
actuellement la masse textuelle accessible la plus importante.

L’uti1isation du Web comme corpus se généralise. Signalons, par exemple, le projet Web-
Corp (http: / /www.webcorp . org.uk) qui met la technologie de base d’un concordancier
a l’échelle du Web, en se ﬁant a plusieurs moteurs de recherche génériques. Ces moteurs restent
de toute facon le seul moyen d’acces au Web, a moins de développer un systeme de parcours
et d’indexation spéciﬁque, qui ne po11rra de toute facon pas prétendre a l’exhaustivité d’un
GoogleTM et autre AltaVistaTM. Notre approche n’échappe pas a ce ﬁltre, et nous ne travaillons,
comme tous les autres « webolinguistes », que sur la partie du Web (dont la proportion est
d’ailleurs inconnue) indexée par ces moteurs, et donc sur un sous-ensemble des pages acces-
sible qui varie avec le temps, et sur lequel aucun critere de sélection ﬁable n’est applicable.

La question se pose alors du type d’études sur corpus pour lesquelles le recours au Web est
justiﬁé. Les études actuelles vont du repérage d’entités nommées (J acquemin et Bush 2000) a
l’étude de textes paralleles bilingues (Resnik 1999), et en regle générale se limitent a l’étude
d’unités lexicales en utilisant des extracteurs de contextes et des mesures de cooccurrence. I1
parait en effet plus délicat de mener des études relevant de la syntaxe ou de la sémantique sur
un corpus aussi « incontrolable », et pour lequel on dispose de si peu d’informations.

Nous nous situons ici dans le cadre de la morphologie, avec come but afﬁché de constituer
des ressources facilement réutilisables. Nous proposons une méthode permettant de construire
des bases de données lexicales, dont la couverture va croissante, et dont le contenu peut étre
suppose indépendant d’un domaine particu1ier3. Puisque nous nous concentrons sur des unités
non référencées dans des dictionnaires usuels, les unités que nous recueillons relevent soit de
la création lexicale spontanée et éphémere, soit de langues de spécialité. Dans tous les cas, leur
description et leur accumulation, apres revision manuelle, constitue une ressource aisément uti-
lisable et utile pour divers traitements des textes en TAL (cf. §3). Notre hypothese de travail sera
donc minimale, et ne suppose qu’un comportement linguistique tres général sur le mode de for-
mation et d’usage des unités lexicales construites, indépendante du type de texte et du domaine
dans lesquels ces constructions apparaissent (a quelques exceptions pres, certains documents
disponibles sur le Web ayant un statut particulier, comme nous l’explicitons en §8).

2Ces exemples sont emprlmtés a (Hathout et Fabre 2002).

311 existe un biais dont nous devons prendre conscience : il est illusoire de penser que le Web serait un corpus
de << langue générale ». Si la Variété des domaines abordés, et donc des sous—langages de spécialité représentés peut
paraitre sufﬁsante, nous n’aVons pas d’idée claire de la representation de chacun de ces domaines. En attendant la
mise en place de procedures génériques de proﬁlage et de caractérisation des pages Web, comme celle proposée
que le projet TyPWEB (Beaudouin et al. 2001) nous nous contentons de ce qui est disponible.

248

VVCL/Ildlllv./l«

5 La cooccurrence des lexémes construits et des lexémes bases

(Baayen et Neijt 1997) ont montré que les contextes des mots dérivés contiennent fréquemment
des « ancres » c’est-a-dire des indices qui facilitent leur interprétation. C’est ainsi que les mots
dérivés apparaissent régulierement précédés (et plus rarement suivis) d’une forme du lexeme
sur lequel ils sont construits.

La présence du lexeme base dans le contexte peut relever de la coopération conversationnelle :
il s’agit alors de fournir des éléments permettant d’interpréter le dérivé en le mettant en relation
avec sa base. Si la dérivation morphologique est un moyen d’exprimer des notions complexes
de maniere concise, on peut néanmoins supposer qu’en francais comme dans d’autres langues,
elle permet assurer la continuité thématique et référentielle dans le discours mais aussi d’éviter
les répétitions et méme de varier la facon dont les idées sont présentées et développées. Dans
tous ces cas, on peut faire l’hypothese que les lexemes construits peuvent étre utilisés pour pa-
raphraser leurs lexemes bases. La cooccurrence des deux lexemes est ainsi prévisible sans étre
systématique. Cette observation a été exploitée en RI par (Xu et Croft 1998) pour ﬁltrer des
appariements morphologiques produits par un raciniseur. Le ﬁltrage est basé sur une variante
de la mesure d’information mutuelle attendue (EMIM ; Expected Mutual Information Measure)
calculée entre des formes morphologiquement apparentées cooccurrentes dans des fenétres de
200 mots. En nous appuyant sur cette méme observation, nous proposons une technique simple
permettant des liens morphologiques, en l’occurrence des couples de lexemes dérivationnel-
lement apparentés. I1 s’agit d’explorer le Web pour y chercher des pages qui contiennent des
formes des deux lexemes qui composent le lien.

Les formes de la base potentielle étant prédites (cf. §7), leur attestation est un premier indice
du caractere construit du lexeme candidat —Webafﬁx rej oint sur ce point GéDériF. Par ailleurs,
la cooccurrence des formes du lexeme candidat et de la base prédite constitue un indice fort
de l’existence d’une relation sémantique entre ces deux unités. La nature exacte de cette rela-
tion n’est cependant pas connue, méme s’il est probable qu’elle corresponde au sens associé a
l’afﬁxe dont on a fait l’hypothese de la présence pour prédire le lexeme base.

Dans les trois sections suivantes, nous décrivons en détails la méthode employée par Webafﬁx
pour collecter et ﬁltrer des informations morphologiques dérivationnelle en explorant le Web.

6 Premiere étape : recherche de nouvelles formes sur le Web

Le but de la premiere étape est de constituer un ensemble de formes se terminant par un sufﬁxe
graphémique donné, et qui n’appartiennent pas un lexique de référence. Pour compléter Ver-
baction, nous avons utilisé le lexique TLFnome, mais l’on peut aussi partir des listes de formes
accessibles sur le Web. Webafﬁx peut aussi fonctionner sans lexique de référence mais un im-
portant travail de dépouillement initial est alors nécessaire ainsi qu’une application répétée de
la méthode aﬁn d’obtenir un noyau de base.

Comme pour chaque utilisation du Web comme corpus, il est impératif de prendre en compte
les spéciﬁcités et les limites des moteurs de recherche. Dans notre cas, la recherche est basée
uniquement sur la terminaison des formes. Peu de moteurs proposent cette fonctionnalité, tres
coﬁteuse en temps de calcul et d’une utilité jugée faible pour l’usage classique des moteurs par
les internautes. A notre connaissance, seuls NorthemLightTM et AltaVista offrent un tel service4.

4http : //www . northernlight . comet http : //www . altavista . com

249

141/LIA/I/Vila Ill/IP61/I1)’ LX. IVIJL/LL llllrl/Ill/I/It

Ces deux moteurs imposent toutefois de speciﬁer un nombre minimum de lettres a l’initiale de
la chaine recherchee : quatre pour NorthernLight et trois pour Altavista. Par exemple, pour
rechercher les formes en -tion, on doit soumettre dans le cas d’AltaVista un ensemble de sous-
requétes : aba*tion, abc*tion, ..., zyt*tior1. Les trigrammes initiaux peuvent etre generes
en enumerant les 60 000 combinaisons de trois des caracteres du francais (lettres accentuees
comprises). Une reponse plus economique consiste a se liIr1iter aux seules sequences qui se
trouvent a l’initiale des entrees de notre lexique de reference, le nombre de trigrammes est ainsi
reduit a 3 500. Les sous-requétes sont completees en interdisant les reponses deja presentes
dans notre liste de reference. Par exemple, nous interdisons la presence de la forme ablation
dans les pages ramenees par la sous-requete abl*tion. Ce premier ﬁltrage se fait en utilisant
les fonctionnalites du langage de requete du moteur AltaVista5. Enﬁn, nous restreignons la
recherche aux pages indexees par le moteur comme etant redigees en francais. Ce dernier critere
n’est pas entierement ﬁable, comme il sera precise en §9.1.

Les pages foumies en reponse par le moteur sont ensuite analysees une a une. Pour chaque
sous-requéte, vingt pages sont considerees au maximum. Elles sont rapatriees et analysees par
Webafﬁx, car le moteur ne fournit pas la forme qui a motive leur selection. Un ﬁltrage im-
portant doit etre effectue sur ces reponses pour eliminer le bruit. Les erreurs ont des origines
diverses : fautes de frappe et d’orthographe; segments de textes en langue etrangere; noms
propres; adresses de courrier electronique; segments d’URL; noms de variables ou de fonc-
tions des langages de scripts; noms de ﬁchiers; extraits de code informatique... Des methodes
speciﬁques sont employees pour chacun de ces problemes. Un mini-correcteur orthographique,
gerant essentiellement les problemes d’accentuation, de redoublement de lettres, et de concate-
nation de mots, a ete mis en place. Pour les noms propres et les variables de code, nous nous
appuyons sur la casse (nous ne retenons que les mots composes uniquement en minuscule) et
sur les caracteres environnants la chaine reperee (/, @, $...). Enﬁn, pour identiﬁer les pages
et les segments rediges dans des langues autres que le francais6, nous utilisons une procedure
de detection basee sur le reperage, dans le voisinage de la forme candidate, de mots-outils de
langues « parasites » —actuellement, l’anglais, l’allemand, l’espagnol et l’italien. Par ailleurs,
une partie non negligeable des liens retournes par le moteur de recherche sont obsoletes : page
inexistante ou ne contenant pas (ou plus) l’unite qui a servi a l’indexer. C’est notamment le
cas des periodiques en ligne, dont les pages changent regulierement de contenu mais pas de
reference dans l’index.

Le temps total de calcul necessaire a la collecte des formes candidates (cf. ﬁgure 1) est d’environ
40 heures par sufﬁxe, le facteur limitant etant le debit de la connexion Internet. Toutes les
donnees presentees dans le present article ont ete obtenues en interrogeant AltaV1sta entre le
28 J anvier et le 4 Fevrier 2002. Le tableau 1 resume les resultats globaux de la premiere etape.
Les operations de ﬁltrage citees plus haut eliIr1inent environs 60% des formes candidates. La
repartition des differentes causes de rejet de ces occurrences7 est presentee dans le tableau 2.

5L’interdiction des formes de TLFnome peut bien sﬁr entrainer le rejet de certaines occurrences, dans le cas
exceptionnel ou une forme du lexeme construit candidat apparait dans la meme page qu’une forme de la liste de
reference ayant les memes lettres a l’initiale et en ﬁnale. Toutefois, la reduction du rapport signal/br11it est telle
que nous preferons courir le risque de manquer ces quelques occurrences pour ne pas avoir :21 en ﬁltrer par la suite
plusieurs dizaines de milliers.

5En effet, les moteurs de recherche n’ attribuent qu’une seule langue a chaque document indexe, et peuvent ainsi
declarer comme francophones des pages bilingues, ou redigees en latin, occitan, picard, ancien frangais...

7Dans les cas d’absence du candidat dans la page et de lien obsolete, nous considerons que chaque réponse
d’AltaVista conceme une occurrence seulement. Ceci n’est bien sﬁr pas toujours le cas, certaines pages peuvent
contenir plusieurs occurrences de formes repondant au schema recherche.

250

VVCL/Ildlllv./l«

Sufﬁxe -ade -age -cmce -ememf -ence -erie -tion Total
Pages analysées 11 618 22 599 15 132 19 528 9 945 12 951 27 664 120 170
Occurrences retenues 2 507 9 962 4 093 10 857 3 503 2 979 12 162 47 429
Noms candidats 813 2 189 1 097 3 791 999 995 3 564 13 448

TAB. 1 — Résultats globaux du premier module.

Sufﬁxe -ade -age -cmce -ememf -ence -erie -tion Moyenne
Code informatique 6,0 7,2 12,5 3,2 8,0 2,7 5,2 6,3
Absence de la page 26,7 39,1 37,5 42,7 37,2 35,9 36,9 37,0
Mot en majuscules 57,0 39,8 37,8 34,0 39,5 50,1 40,7 41,9
Langue étrangere 1,8 3,3 3,3 3,5 4,3 0,4 7,0 4,0
Liens obsoletes 8,1 7,9 7,6 10,4 9,5 8,6 8,0 8,4
Faute d’orthographe simple 0,3 2,7 1,4 6,1 1,6 2,4 2,3 2,5

TAB. 2 — Répartition par sufﬁxe des opérations de ﬁltrage (en pourcentage d’occurrences).

7 Prédiction des formes des lexémes bases

(crénelage OR crénelages) AND (crénela OR crénelai OR crénelaient OR
crénelais OR crénelait OR crénelant OR m OR créneler OR crénelez OR
créneliez OR crénelions OR crénelle OR crénellent OR crénellera OR

OR crénelleront OR crénelles OR crénelons OR m OR crénelé OR crénelée
OR crénelées OR crénelés OR crénéle OR crénélent OR crénélera OR m OR
crénéleront OR crénéles)

FIG. 2 — Requéte construite pour le candidat crénelage par analogie avec agnelage:agneler.

Le lexique Verbaction permet de prédire les formes ﬂéchies des verbes susceptibles d’étre les
bases des formes candidates fournies par le premier module. La prédiction s’appuie sur un en-
semble de schémas de sufﬁxation spéciﬁques a chaque sufﬁxe, appris en extrayant de Verbaction
les couples de lemmes dont le nom se termine par ce sufﬁxe; on génere ensuite l’ensemble des
couples de formes ﬂéchies correspondant en utilisant TLFnome. Les membres de ces couples
sont munis de leurs catégories morphosyntaxiques. On applique ensuite une technique similaire
a celle de (Dal et al. 1999) : un ensemble de schémas bruts est constitué en supprimant dans
chaque couple le préﬁxe graphémique commun a ses deux formes (le préﬁxe doit comporter
au moins trois caracteres) et on retient le schéma brut le plus fréquent. Les schémas retenus
sont alors appliqués aux formes candidates. Pour chacune des catégories morphosyntaxique
de formes a prédire, et pour chaque forme candidate, on identiﬁe le plus long sufﬁxe de cette
demiere qui apparait dans un schéma de sufﬁxation. On applique ensuite a la forme candidate
l’ensemble des schémas qui contiennent ce sufﬁxe. Le choix de travailler directement sur des
formes ﬂéchies présente un avantage important : il permet de prédire pour une forme candidate
l’ensemble des allomorphies possibles de son éventuel lexeme base comme cela est illustré en
ﬁgure 2.

Une correction des approximations induites par l’apprentissage et l’application des schémas
est effectuées lorsque l’on peut identiﬁer le lemme correspondant dans TLFnome. Ainsi, si
pour un candidat, trois des formes prédites au moins ﬁgurent dans TLFnome comme formes
ﬂéchies d’un méme lemme, alors on remplace toutes les formes prédites par les formes ﬂé-
chies de ce lemme. Par ailleurs, on supprime dans tous les cas l’ensemble des formes prédites
qui, dans TLFnome, appartiennent a une catégorie non verbale. On garantit ainsi que seules

251

141/LIA/I/Vila Ill/IP61/I1)’ LX. IVIJL/LL llllrl/Ill/I/It

les formes verbales seront considérées lors du ﬁltrage par les cooccurrences. Cette réduction de
l’ensemble des formes prédites a par exemple permis d’éliminer un couple candidat comme aﬁ-
cheriexyjﬁcher —aﬁ€cherie est constr11it sur a]j€che— malgré le fait que les formes du substantif
aﬁﬁche soient aussi des formes du verbe aﬁﬁcher.

8 Filtrage des couples par recherche de cooccurrences

Sufﬁxe -ade -age -ance -emem,‘ -ence -erie -tion Total
Couples recherchés 813 2 189 1 097 3 791 999 995 3 564 13 448
Couples ﬁltrées 55 450 154 385 81 85 611 1 821
Moyenne (%) 6,77 20,56 14,04 10,16 8,11 8,54 17,14 13,54

TAB. 3 — Résultats quantitatifs du ﬁltrage basé sur les cooccurrences.

La troisieme étape projette sur le Web les liens construits par le deuxieme module pour ne
retenir que les couples de formes qui apparaissent simultanément dans au moins une page Web.
Cette étape utilise Altavista car ce moteur accepte des requétes longues, jusque 800 caracteres.
On ne soumet ainsi qu’une requéte par lien, ce qui réduit le temps d’eXécution de cette étapeg.
Les pages proposées par le moteur de recherche sont analysées pour veriﬁer, comme dans la
premiere étape, que les occurrences sont « valides ». Nous présentons dans le tableau 3 les
résultats quantitatifs de cette étape pour chaque sufﬁxe étudié.

Notons, lors de ce traitement, l’apparition d’une nouvelle source de bruit, constituée par des
pages qui ne sont pas des textes mais des listes de mots : dictionnaires et glossaires en ligne,
bases de données lexicales mises a disposition sur le Web par des linguistes informaticiens, listes
de mots utilisées respectivement par les pirates informatiques et les responsables de sécurité
pour attaquer (resp. protéger) les mots de passe... Ces pages ne sont pas génantes pour la collecte
des formes candidates par le premier module. Elles sont en revanche préjudiciables au bon
fonctionnement de notre ﬁltrage par la cooccurrence : la présence simultanée de deux unités
lexicales sur des bases purement lexicographiques ne peut pas servir de test linguistique. Nous
procédons donc a la détection et au ﬁltrage de ces pages Web, en vériﬁant la présence d’unités
lexicales graphémiquement proches du candidat, ordonnées suivant l’ordre lexicographique.

9 Evaluation des résultats et discussion

Nous présentons ici une évaluation des résultats de Webafﬁx, obtenus apres un étiquetage ma-
nuel des candidats et des couples produits par les des différents modules.

9.1 Collecte des formes candidates

La qualité des résultats a la sortie du premier module a été évaluée manuellement par les auteurs
en prélevant un échantillon aléatoire de 100 occurrences pour chaque sufﬁxe. L’ évaluation de la
qualité du premier module est résumée dans le tableau 4. Sont considérées correctes les formes
candidates nominales qui se terminent par le sufﬁxe recherché, meme s’il ne s’agit pas d’un
déverbal. Si la forme n’est pas un nom commun, elle est étiquetée mauvaise catégozie comme

8Comme nous l’a signaler un relecteur anonyme, ces requétes peuvent étre scindées en sous-requétes plus
courtes que l’on pourrait soumettre a d’autres moteurs, comme Google.

252

VVCL/Ildlllv./l«

Sufﬁxe -ade -age -ance -ement -ence -erie -tion Moyenne
Candidat correct (%) 29 66 40 17 34 59 53 45
Mauvaise catégorie (%) 14 1 5 23 2 10 1 8
Langue étrangere (%) 36 7 14 6 11 11 18 12
Faute d’orthographe (%) 16 23 36 51 50 16 27 33
Code, URL, etc. (%) 5 3 5 3 3 4 1 3

TAB. 4 — Répartition des candidats noms dans les différentes catégories

dans le cas de vibratoirement qui est un adverbe9. Certains contextes en langues étrangeres
échappent au test présenté précédemment. I1 s’agit de segments trop courts, souvent de cita-
tions (comme Parole d ’alcove et outrageous statement), de traductions partielles (comme « Sept
jours pour expier » (days of atonement)), d’ancien francais (oultrageusement) et divers parlers
romans, trop proches du francais modeme pour étre efﬁcacement ﬁltrés. De méme, les fautes
d’orthographe résiduelles sont trop complexes pour étre traitées efﬁcacement. L’ utilisation d’un
correcteur orthographique ﬁltre la majorité des créations lexicales que nous recherchons; cette
solution a donc été rejetée. Enﬁn, les codes informatiques vont de langages de programmation
a faible ponctuation a des textes parlant d’informatique (la fonction comptelement [ D.

11 est clair qu’une précision moyenne de 45% est assez faible a ce stade, et pourrait étre amélio-
rée. Toutefois, le véiitable ﬁltrage est effectué par le troisieme module, lors de la recherche de
cooccurrences. De plus, certaines ﬁnales ont plus de propension que d’autres a apparaitre dans
des contextes erronés : c’est le cas de ement qui permet aussi de construire des adverbes, et de
ade qui apparait dans de tres nombreuses formes espagnoles.

9.2 Evaluation des liens ﬁltrés

Sufﬁxe -ade -age -ance -ement -ence -erie -tion Total
Couples candidats 55 450 154 385 81 85 61 1 1 821
Corrects 13 355 31 123 9 14 415 960
Précision (%) 24 79 20 32 11 16 68 52.7

TAB. 5 — Evaluation du ﬁltrage par les cooccurrences

La qualité des résultats du troisieme module a également été évaluée manuellement1°. Sont
considérés comme corrects les liens tels que le lexeme candidat est un nom d’action ou d’évé-
nement correspondant au verbe prédit. Nous avons aussi accepté les couples dont le candidat
n’est pas construit par l’afﬁxe mais l’est par conversion (cytoponction:cytoponctionner). L’ éva-
luation du ﬁltrage par les cooccurrences est résumée dans le tableau 5.

10 Conclusion

Nous avons présenté une méthode d’acquisition seIni-automatique de connaissances dérivation-
nelles a partir du Web. Cette méthode comporte trois phases : la collecte sur le Web de formes

9L’utilisation d’un étiqueteur morphosyntaxique serait trop lourde pour la masse de données a traiter, et les
étiqueteurs étant dc toute fagon peu annés pour catégoriser efﬁcacement les néologismes que nous recherchons.

1°Pour les sufﬁxes -age, —ance, -ement et -tion les valeurs présentées sont extrapolées a partir de l’éva1uation
d’échantillons aléatoires de 100 lexémes candidats.

253

141/LIA/I/Vila Ill/IP61/I1)’ LX. IVIJL/LL llllrl/Ill/I/It

candidates qui comportent un sufﬁxe graphémique; la prédiction des formes des bases que ces
candidats pourraient avoir; le ﬁltrage par la cooccurrence des couples ainsi constitués. L’ar-
ticle présente une évaluation des résultats centrée sur la précision : elle constitue notre objectif
premier.

Notre méthode présente plusieurs points forts que nous envisageons de développer prochai-
nement : elle ne met en oeuvre aucune connaissance linguistique, ce qui permet de l’utiliser
directement pour d’autres schémas dérivationnels comme adjectif:adverbe, nom:adjectif... et
d’autres langues, par exemple pour compléter la partie anglaise de la base morphologique CE-
LEX (B aayen et al. 1995). Cette méthode pourrait également servir de base a une approche plus
intuitive et moins applicative pour caractériser les pages Web en fonction des sufﬁxes qu’elles
contiennent (en s’intéressant en particulier a l’effet de sensibilisation aux regles ou rule pri-
ming), en vue de dégager des afﬁnités entre certains parametres extra-linguistiques et la création
lexicale.

Remerciements

Nous remercions Marc Plénat (ERSS, CNRS & Université Toulouse le Mirail) pour l’idée qui
est a l’origine de Webafﬁx, ainsi que Natalia Grabar (DIAM, SIM/AP-HP & Université Paris 6)
pour ses conseils techniques.

Références

Baayen, R. H., Neijt, A. (1997), Productivity in context: a case study of a Dutch sufﬁx, Linguistics, Vol.
35, 565-587.

Baayen, R. H., Piepenbrock, R., Gulikers, L. (1995), The CELEX Lexical Database (Release 2), CD-
ROM, Linguistic Data Consortium, University of Pennsylvania, USA.

Beaudouin, V., Fleury, S., Habert, B., Illiouz, G., Licoppe, C., Pasquier, M. (2001), TyPWeb : Décrire la
Toile pour mieux comprendre les parcours. Actes de CIUST’0I : Colloque International sur les Usages
et les Services de Télécommunications, Paris.

Bourigault, D., Fabre, C. (2000), Approche linguistique pour l’analyse linguistique de corpus, Cahiers
de Grammaire, Vol. 25, 131-151.

Dal, G., Hathout, N., Namer, F. (1999), Construire un lexique dérivationnel 2 théorie et réalisation, Actes
de la 6econfe’rence sur le Traitement Automatique des Langues Naturelle, 115-124.

Dal, G., Namer, F. (2000), Génération et analyse automatiques de ressources lexicales construites utili-
sables en recherche d’informations, T.A.L., Vol. 41, Num. 2, 423-446.

Grefenstette, G. (1999), The W as a Resource for Example-Based MT Tasks, Actes de ASLIB ‘Trans-
lating and the Computer’ Conference, London.

Hathout, N., Fabre, C. (2002), Constitution et exploitation de lexiques de formes déverbales, Journées
d’études sur les déverbaux, SILEX, Lille.

Jacquemin, C. (1997), Variation terminologique : Reconnaissance et acquisition automatique de termes
et de leurs variantes en corpus, Mémoire d’habilitation a diriger des recherches, Université de Nantes.

Jacquemin, C., Bush, C. (2000), Fouille du Web pour la collecte d’entités nommées, Actes de la
79 Conference sur le Traitement Automatique des Langues Naturelles.

Resnik, P. (1999), Mining the Web for bilingual text, Acte de 37th Meeting of ACL, 527-534, Maryland,
USA.

Xu, J ., Croft, W. B. (1998). Corpus-Based Stemming using Co-occurrence of Word Variants, ACM Tran-
saction on Information Systems, Vol. 16, Num. 1, 61-81.

254

