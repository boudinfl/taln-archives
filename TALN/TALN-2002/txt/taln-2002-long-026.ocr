TALN 2002, Nancy, 24-2 7juin 2002

Traduction automatique ancrée dans l’analyse linguistique

Jessie Pinkham et Martine Smets
Microsoft Research
One l\/Iicrosoft Way
Redmond, WA 98052, USA
iessiep@microsoft.com
martines@microsoft.com

Résumé — Abstract

Nous présentons dans cet article le systeme de traduction francais-anglais MSR-MT
développé a Microsoft dans le groupe de recherche sur le traitement du language (NLP). Ce
systeme est basé sur des analyseurs sophistiqués qui produisent des forrnes logiques, dans la
langue source et la langue cible. Ces forrnes logiques sont alignées pour produire la base de
données du transfert, qui contient les correspondances entre langue source et langue cible,
utilisées lors de la traduction. Nous présentons différents stages du développement de notre
systeme, commence en novembre 2000. Nous montrons que les performances d’octobre 2001
de notre systeme sont meilleures que celles du systeme commercial Systran, pour le domaine
technique, et décrivons le travail linguistique qui nous a permis d’arriver a cette performance.
Nous présentons enfrn les résultats préliminaires sur un corpus plus général, les débats
parlementaires du corpus du Hansard. Quoique nos résultats ne soient pas aussi concluants
que pour le domaine technique, nous sommes convaincues que la résolution des problemes
d’analyse que nous avons identifrés nous perrnettra d’améliorer notre performance.

In this paper, we present an overview of the MSR-MT translation system for French-English,
developed at Microsoft Research in the NLP group. Our system is based on rule-based
analysis which produces logical form representations of the source language and the target
language. These are aligned to produce mappings then stored in an example-base. We
examine the development of the system since November 2000, and show that by October
2001, we had exceeded the quality of the commercial system Systran in the technical domain.
We describe the linguistic work that allowed our system to improve. We present preliminary
results on the Hansard parliamentary corpus. While these results are less impressive
currently, we are convinced that changes to linguistic analysis will allow the system
performance to improve.

Keywords — Mots Clés

Traduction automatique, francais-anglais, base d’exemples.
Automatic translation, French-English, example-base.

287

Jessie Pinkham et Martine Smets

1 Présentation du systéme de traduction

Les systemes de traduction automatiques peuvent étre basés sur des dictionnaires bilingues
(Gerber 1997, voir Boitet 2001 sur l’importance des dictionnaires),et peuvent utiliser soit des
regles de transfert, des bases de données d’exemples de traduction (Kaji 92, Meyers 2000,
Watanabe et al. 2000), une langue intermédiaire pivot ou interlangue (Poyen et Vauquois
1959, Vauquois 1968, Nyberg 1991, Dorr 1993) ou des modele statistiques (Brown et al.
1993, Al-Onaizan et al. 1999).

Le transfert dans notre systeme est basé sur les exemples; le module de transfert est composé
d’une base de données d’exemples de traduction appris durant l’alignement de textes
bilingues pendant la phase d’apprentissage. L’alignement est effectué entre les formes
logiques des langues source et cible, qui sont le résultat de l’analyse des textes
d’apprentissage. C’est donc dire l’importance que revét l’analyse linguistique dans notre
systeme. Le systeme francais-anglais comprend les modules suivants:

0 un analyseur du francais, a base de regles

un dictionnaire monolingue francais
0 une base de données de transfert, composée de textes alignés

0 un dictionnaire bilingue francais-anglais automatiquement appris a partir des textes de
la base de données du transfert

0 un générateur de l’anglais, a base de regles
0 un dictionnaire monolingue anglais.

Certains de ces modules existaient avant que nous ne commencions notre travail en traduction
automatique : l’analyseur et les dictionnaires monolingues ont été utilisés pour les
correcteurs de grammaire, qui font partie des logiciels Word. Le générateur de l’anglais est
utilisé pour la traduction automatique d’autres langues Vers l’anglais, par exemple l’espagnol,
le japonais et le chinois.

Nous n’utilisons plus de dictionnaire bilingue général traditionnel construit a la main. Nous
avons en effet remarqué (Pinkham et Smets 2002a) qu’un dictionnaire bilingue général
n’améliore pas la traduction, dans le type de systeme que nous avons, et peut méme nuire a la
qualité de la traduction. Nous avons donc décidé de n’utiliser qu’un dictionnaire bilingue
appris automatiquement sur les corpus d’apprentissage.1

Dans le reste de cette section, nous présentons avec plus de détails l’analyseur et le module de
transfert.

1 Le dictionnaire bilingue appris comprend 30,000 paires de mots dans le domaine technique. Nous utilisons

un dictionnaire bilingue traditionnel de 500 mots pour les pre’posi11'ons, conjonctions, et pronoms.

288

T raduction automatique ancrée dans l’anab/se linguistique

1.1 Analyseur a base de régles

L’analyseur comprend trois modules différents : la grammaire syntaxique, le rattachement, et
les regles de la forme logique.

La grammaire est une grammaire syntagmatique augmentée (augmented phrase structure
grammar). Les regles sont binaires (Jensen 1993), et expriment des contraintes et conditions
sur leur application. Par exemple, la regle ci-dessous introduit le complément d’un Verbe : la
contrainte exprimée sur le Verbe a gauche de la ﬂeche spécifie qu’il doit étre transitif et
l’action déclarée sur le syntagme Verbal (SV) a droite de la ﬂeche déﬁnit le syntagme nominal
(SN) comme l’objet du Verbe. Cette regle est bien sﬁr tres simpliﬁée, mais illustre le type de
regle de la grammaire.

SV[Transitif] SN 9 SV [Objet = SN]

11 est nécessaire de préciser deux points importants : nous n’essayons pas de capturer une
théorie linguistique précise en développant la grammaire. Notre point de départ est empirique.
Nous travaillons avec des corpus dont nous essayons de couvrir les constructions. Si nous
pouvons adopter l’analyse d’un phénomene linguistique qui ait un fondement théorique et qui
apporte une explication cohérente, nous le faisons Volontiers. Mais notre but n’est pas
d’essayer de démontrer la Validité d’une approche théorique. De méme, nous n’excluons pas
l’adoption de différentes approches théoriques dans notre grammaire, pour autant que ces
approches rendent compte des faits linguistiques observés.

Un deuxieme point important a souligner est que nous n’essayons pas de contraindre la
grammaire a n’analyser que des phrases grammaticales (Heidom 2000). C’est une grammaire
d’anal se et non de énération et nous la Voulons robuste. Les contraintes ue nous a'outons
y 7 7

aux regles ont pour but de bloquer les mauvaises analyses des phrases rencontrées dans les
corpus, non pas d’éliminer les analyses de phrases potentiellement émises mais non
grammaticales. En d’autres mots, nous ne nous préoccupons pas de surgénération.

Nous Voulons une grammaire ﬂexible, et qui puisse rendre compte des faits linguistiques
rencontrés dans des corpus Variés. Notre grammaire est d’ailleurs a large couverture et tres
robuste. Méme si l’analyse de la phrase complete échoue, nous obtenons quand méme une
analyse partielle des syntagmes qui ont été analysés avec succes.

Lors du développement de la grammaire, nous nous assurons que nous n’introduisons pas de
problemes pour des constructions traitées précédemment en maintenant des suites de
régression contenant plusieurs milliers de phrases (plus de 6000 phrases2 de corpus général, et
plus de 1000 phrases d’un corpus technique de manuels d’ordinateur). Nous Venons de créer
un corpus supplémentaire de plus de 18000 phrases que nous allons utiliser a cette fin.

La grammaire produit ce que nous appelons le sketch: un arbre syntaxique, associé a un
agrégat d’attributs et de Valeurs de ces attributs, qui définissent les constituants de l’arbre. A
ce niveau, nous n’aVons pas résolu le probleme de l’attachement de certains constituants, tels
que les post-modificateurs (groupes prépositionnels, adjectifs, propositions relatives). En

2 L’analyse des 6000 phrases de notre corpus general prend moins de deux minutes.

289

Jessie Pinkham et Martine Smets

effet, pour pouvoir avec certitude déterminer l’endroit ou s’attachent ces constituants, on a
souvent besoin de pouvoir considérer l’arbre syntaxique dans sa totalité (donc, lorsque
l’analyse en arbre est terminée). La stratégie adoptée est donc d’attacher ce type de
constituant le plus bas et le plus a droite possible dans l’arbre. Et c’est lors du stage suivant de
l’analyse, lors du rattachement, que le site de l’attachement de ces post-modificateurs est
déterminé.

Le module de rattachement est composé d’un nombre limité de regles qui rattachent des
constituants au site estimé correct. Ces regles sont heuristiques et se basent sur des données
morphologiques, syntaxiques et sémantiques. Dans la phrase suivante, par exemple, la
relative introduite par que est attachée dans le sketch a commandes (Image 1). Une regle de
rattachement la rattache a ﬁchier, utilisant l’information que commandes fait partie d’un
syntagme prépositionnel introduit par de et n’est pas précédé d’un article (Image 2). Le
syntagme nominal exprime donc, probablement, un type d’objet, et la relative devrait étre
attachée a la téte du syntagme nominal, non au syntagme prépositionnel. Dans cette méme
phrase, le syntagme prépositionnel introduit par avant est rattaché au Verbe. Pour tester nos
regles de rattachement, nous utilisons un corpus de régressions de 18.000 phrases.

Vous insérez la commande pause avant une section du ﬁchier de commandes que vous ne
voulez pas traiter.

DECL1 NP1sPRDM1' "VcIus"

VERB1* "insérez" (Subject MP1 Object MP2)
MP2 ETP1 ADJ1* "la"
MOUM1* "cclrrlnande"
MP3 MOUM2* "pause"
:~PP1 PPZTPREPF "avant"

ETP2 ADJ2" "une"
MOUM3" "sect'icIn"
PP3 PP4ePREP2" "de"
ETP3 A:DJ3* "1 E"
NDUM4" "f'ich'ier"'
PP5 PP6sPREP3" "de"
EEMOUM5' "cI:|I'rlI1andes"
NP4sPRDN2' "que"

RELCL1
NP5ePRDN3' "VDIJ5"
AVP1 ﬂ:DV1" "HE"
VERB2* "\."Dl]]EZ" (Subject MP5

IMFCL1 AVP2 AD\r2* " as"
:VERB3* "traiter" P
HAR1
Image 1
:~d‘isp1ay portrait
DECL1 NP1sPRDN1" "'U'I:Iu5"
VERB1* "insérez" (Subject MP1 Object MP2)
MP2 ETP1 ADJ1* "'Ia"
E§MOUM1* "cclninande"
MPSTMOUMP "pause"
PP1 PPZTPREPF "avant"
ETP2 ADJ2" "une"
MOUM3" "section"
PP3 PP4sPREP2" "de"
ETP3 ADJ3" "112"
NDUH-4* "‘F‘ich‘ier"' d
PP5 PPGTPREP? " E"
:MOUM5* "ccII1I11am:|es"
RELCL1 HP4sPRDN2" "que"
HP5sPRDN3" "Venus"
AVP ITADVI " " n E"
\|'ERB2* "vcIu'|ez" (Subject MP5 Object IMFCL1)
AVP ZTADVZ " " p as"
INFCL1TVERB3" "tr'a‘iter"'
HAR1 "."
Image 2

290

T raduction automatique ancrée dans l’anab/se linguistique

La forme logique représente l’analyse profonde de la phrase (les fonctions syntaxiques, par
exemple, telles que le sujet profond), et certaines informations sémantiques (par exemple, la
signiﬁcation de certaines prépositions : temporelles, de lieu, etc.). La forme logique est un
graphe orienté étiqueté non ordonné, qui doit determiner les fonctions syntaxiques dans des
constructions a problemes, telles que le contr6leur dans les infinitives et les roles syntaxiques
dans les constructions avec dépendances a longue distance (par exemple, l’objet dans la
phrase le ﬁchier de commandes que vous voulez traiter). La forme logique relie les formes
actives et passives en leur donnant la méme représentation; elle exprime également la
quantiﬁcation, et les anaphores sont résolues dans la forme logique, mais seulement au niveau
de la phrase.

L’image 3 représente la forme logique de la phrase analysée dans les images 1 et 2. La
relation exprimée par le syntagme prépositionnel est représente par l’attribut TmeAt; la
relative par l’attribut Attrib, qui introduit également les adjectifs modificateurs. Le sujet
profond de vouloir est indiqué, de méme que les compléments de traiter.

La forme logique est le but de l’analyse syntaxique, et également la base de notre composant
de transfert: en effet, l’alignement est basé sur les formes logiques des segments alignés dans
les deux langues.

hdisplay 1f

insérerl [+Pres +Indicat +Prupusitiun +T1 +Pu1ite +Huv)
sub vnusl (+Fem +Hasc +Pers2 +P1ur +Anim +Humn +Pu1ite)
nbj
“ﬁnds

cummandel (+Def +Fem +Pers3 +Sing +Cnunt)

pausel (+Fem +Pers3 +5ing +ED +Cuunt)
meAt———sectiun1 (+Indef +Fem +Pers3 +5ing +Cuunt +Luc)
‘Ede

fichierl (+Def +Hasc +Pers3 +Sing +Cuunt +Luc]

de cummande2 (+Fem +Pers3 +P1ur +Cuunt +Luc)
Attrib——MDu1uir1 (+Pres +Heg +Indicat +Prupusitiun +T2
sub vnusl
ubj traiterl
sub vnusl
ubj fichierl
Image 3

1.2 Le composant de transfert

A la base du composant de transfert sont les formes logiques de la langue source et de la
langue cible, ce qui souligne l’importance de l’analyse linguistique dans notre systeme. Les
formes logiques résultant de l’analyse des corpus bilingues sont alignées, phrase par phrase,
et des correspondances de traduction entre mots isolés, structures ancrées dans des mots
spécifiques, ou syntagmes sont déduites de ces alignements. L’algorithme d’alignement
procede en deux phases. Durant la premiere phase, des correspondances lexicales sont
établies entre noeuds individuels des graphes de la langue source et de la langue cible, sur la
base d’un dictionnaire appris automatiquement. Dans la seconde phase, les noeuds sont
alignés sur la base de l’information structurale en plus de l’information lexicale. L’alignement
se fait a partir des noeuds dont la correspondance lexicale est la plus étroite (meilleur d’abord,
‘best—first’). Une série de regles d’alignement basées sur l’information linguistique sont
utilisées dans cette deuxieme phase. Plus de détails et des exemples sont donnés dans
(Menezes et Richardson 2001).

Le dictionnaire bilingue utilisé dans la premiere phase d’alignement est appris
automatiquement d’apres un algorithme décrit dans (Moore 2001), a partir des corpus

291

Jessie Pinkham et Martine Smets

bilingues d’apprentissage. Les corpus bilingues utilisés pour l’alignement comportent un
nombre de phrases important : plus de 200.000 pour le corpus technique, et 500.000 pour le
corpus du Hansard. Le corpus du Hansard est beaucoup plus général que notre corpus
technique, ce qui explique la différence de taille. Les correspondances extraites de cet
alignement sont représentées comme une base de données d’exemples pour la traduction.
Durant la traduction, cette base de données est consultée pour la traduction de termes isolés
ou de syntagmes entiers.

2 Evaluations du systéme de traduction

2.1 Méthode d’évaluation

La méthode dont nous nous servons a été décrite dans plusieurs articles récents (Richardson et
al. 2001, Pinkham et al. 2001). Nous traduisons un ensemble de phrases non vues avec notre
systeme de traduction, et avec le systeme de comparaison, en l’occurrence le systeme
francais-anglais de Systran. Nous associons a ces paires de traduction la phrase traduite par
un traducteur humain, donc supposée correcte. Ce trio de phrases est présenté a plusieurs
évaluateurs (entre 5 et 7), et les traductions automatiques sont présentées au hasard de facon a
ce que les évaluateurs n’en sachent pas la provenance. La traduction humaine, ou traduction
de référence est clairement indiquée. Les évaluateurs comparent les traductions
automatiques, et notent celle qui est la plus proche de la traduction humaine comme étant la
meilleure. Lors du calcul des scores, une préférence pour notre systeme se traduit par un
score de 1 et une préférence pour Systran par un score de -1. Le score 0 indique que les
systemes sont équivalents. Nous utilisons de 250 a 400 phrases dans chaque évaluation.

2.2 Traduction pour le domaine technique (informatique)

Les progres de notre systeme sont illustrés dans la Tableau 1, ou nous indiquons tous les
scores de novembre 2000 a janvier 2002. Le score de novembre 2000, par exemple, indique
que la performance de notre systeme était sensiblement inférieure a celle de Systran (-0,50 sur
une échelle de -1 a 1. L’expression +/- 0,1 indique l’intervalle de confiance).

Date de Description du Score vs. Nombre de

l’évaluation systeme Systran phrases

Novembre 2000 Systeme de base -0,50 +/- 0,1 308

Février 2001 Dictionnaire amélioré -0,18 +/- 0,1 250

Mars 2001 Lexique bilingue appris -0,14 +/- 0,11 250
du domaine

Octobre 2001 Améliorations +0,20 +/- 0,1 250
linguistiques

Janvier 2002 Dictionnaires appris +0,28 +/- 0,11 400
automatiquement

Tableau 1 : Progres du systeme technique

292

T raduction automatique ancrée dans l’anab/se linguistique

En novembre 2000, les modules du systeme existaient, mais n’aVaient pas ete appliques au
francais-anglais. Nous avons cree une base de donnee (‘example-base’) contenant des
exemples de transfert a partir de 200 000 paires de phrases techniques bilingues alignees.
Une premiere Version tres rudimentaire d’un dictionnaire bilingue a ete employee. Les
resultats par rapport a Systran etaient assez mauvais (-0,5). En fevrier 2001, nous avons
remplace la premiere Version du dictionnaire bilingue par une Version de meilleure qualite, et
les resultats sont devenus meilleurs car les alignements se sont ameliores. En mars, nous
avons ajoute un lexique de paires de mots appris directement des textes d’apprentissage, ce
qui a apporte une amelioration a peine significative. Ces resultats sont expliques en detail
dans l’article de Pinkham et Corston-Oliver (2001a). Pour examiner la contribution de
chaque module du systeme, nous avions decide de ne pas faire de modifications linguistiques
pour l’analyse du francais, et de ne pas faire non plus de changements a la generation de
l’anglais motives par les problemes du francais.

Nous avons attaque les problemes d’analyse du francais a partir d’aoﬁt 2001. Les
ameliorations linguistiques nous ont permis de depasser la qualite de Systran en octobre 2001,
avec un score de +0,20, qui montre que les evaluateurs ont trouve notre systeme meilleur que
Systran dans ce domaine technique. Bien sﬁr, nous savons que seul notre systeme avait ete
entraine dans ce domaine. L’importance du resultat neanmoins, est que nous avons pu, en
moins d’un an, avec un personnel tres reduit (2 personnes pour le francais), ameliorer la
performance de notre systeme de facon importante.

Les systemes evalues jusqu’en octobre comprenaient un dictionnaire bilingue traditionnel.
Nous avons ete amenees alors a eliminer ce dictionnaire pour nous servir uniquement de
dictionnaires de traductions appris des corpus eux-memes (Pinkham et Smets 2002a, Pinkham
et Smets 2002b). L’evaluation de janvier donne les resultats d’un systeme qui ne comprend
pas de dictionnaire bilingue traditionnel. Ce resultat de +0,28 represente notre meilleur
resultat jusqu’a present. Le meilleur score pour MSR-MT est en espagnol-anglais (+0,48), et
nous sommes persuadees qu’aVec davantage de travail linguistique, nous atteindrions des
resultats semblables.

2.2.1 Exemples de modiﬁcations linguistiques dans le corpus technique

Dans cette section, nous discutons du travail linguistique qui a ete necessaire pour ameliorer
la qualite de la traduction dans le domaine technique. Nous avons remarque qu’un probleme
lie au corpus technique est l’utilisation tres frequente de groupes nominaux avec fonction
d’apposition. Ces groupes nominaux sont le plus souvent des noms de commandes ou de
menus. Un exemple illustratif est le syntagme nominal la commande pause. Ce syntagme
pourrait étre analyse en syntagme Verbal (le sujet la commande suivi du verbe pauser) ou en
syntagme nominal, avec pause apposition de commande. Nous avons dﬁ modifier la
grammaire pour obtenir l’analyse correcte, tout en nous assurant que nous n’adaptions pas la
grammaire a ce domaine specifique mais preservions les analyses correctes de notre corpus de
regression. D’autres exemples d’apposition incluent des syntagmes du type la boite de
dialogue Ouvrir un ﬁchier. Dans cet exemple, la difﬁculte vient du fait que l’apposition est
en fait un syntagme Verbal, mais qui dans ce cas doit étre analyse comme syntagme nominal.
La majuscule est un indice que ce syntagme est un nom de menu, mais il n’est pas touj ours
aise de determiner ou se termine le nom de menu (1). La phrase (2) presente un probleme
similaire, la presence d’un syntagme Verbal qui doit étre interprete comme syntagme nominal.
Ces deux phrases sont maintenant correctement analysees par notre systeme.

293

Jessie Pinkham et Martine Smets

(1) Si Dr. Watson ne peut pas utiliser le chemin spéciﬁé pour créer un ﬁchier de vidage sur
incident, la boite de dialogue Ouvrir un ﬁchier s'aﬁ‘iche pour vous permettre de speciﬁer un
nouveau chemin

(2) Si vous souhaitez toujours utiliser le rappel, cliquez sur T oujours me rappeler au(x) ou
aux numéro(s) ci-dessous, et sélectionnez le modem ou le périphérique a rappeler.

Nous avons dﬁ également résoudre des problemes d’analyse plus généraux aﬁn d’améliorer
notre performance, tels que désambigu'1'ser des, qui peut étre une préposition ou un
déterminant, désambigu'1'ser entre participe passé et participe passif, etc. Enfin, nous nous
sommes également penchés sur la traduction d’idiomes tels que mettre a jour, mettre a
niveau, prendre en charge, etc. (Menezes et al. 2002)

Au niveau du rattachement, de nombreux syntagmes ont la structure SN de N SN (apposition)
SA/SV, pour lesquels le syntagme adjectival (SA) ou Verbal doit étre rattaché a la téte du
premier groupe nominal. Par exemple, dans la phrase (3), la participiale déﬁni dans... est
rattachée a protocole. La regle de rattachement se base sur le fait que la structure SN de N
sans déterminant indique un type d’objet (identifié par l’apposition) et qu’un modificateur
suivant l’apposition est en général attaché a la téte du premier SN.

(3) Les serveurs d'acces distant et leurs clients utilisent le protocole de conﬁguration PPP
IPXCP (IPX ///Configuration Protocol) a'e'fini dans RFC 15552, << The PPP Internetwork
Packet Exchange Control Protocol (IPXCP) >> pour conﬁgurer la connexion d'acces distant
pour IPX.

En améliorant l’analyse de ce type de phrases, nous facilitons l’alignement des textes
bilingues qui est nécessaire a la création de la base d’exemples de traduction.

2.3 Traduction pour le corpus du Hansard

Le corpus du Hansard est composé de débats parlementaires canadiens. Nous avons construit
une base de données d’exemples (‘example-base’) avec 500 000 phrases alignées. Ces
phrases ont été prises au hasard dans les 1,3 million de phrases disponibles sur le site web de
Ulrich Germann (http://www.isi.edu/natural-language/download/hansard/index.html).

Les résultats de l’évaluation sont présentés dans le Tableau 2.

Date de Description du Score vs. Nombre de

l’évaluation systeme Systran phrases

Janvier 2002 Systeme de base sans -0,16 +/- .12 250
changements

Tableau 2: Traduction de texte Hansard

Le score de -0,16 montre que notre systeme général est pour l’instant moins bon que Systran.
Pour ce test, nous avons incorporé plusieurs dictionnaires spécialisés de Systran (politique,
économique, etc.) et nous considérons que le Hansard est un domaine général ou
l’entrainement est moins avantageux. Mais si nous comparons ce score au score technique,
nous pouvons noter que nous étions au méme point en mars de 2001, et que nous avons réussi

294

T raduction automatique ancrée dans l’anab/se linguistique

a améliorer le systeme en six mois.

Nous pensons donc que nous pourrons améliorer la

traduction de la méme facon. Les plus gros problemes que nous Voyons sont des problemes

d’analyse.

2.3.1 Exemples de problémes linguistiques dans le corpus Hansard

Texte original Référence MSR_MT Systran c'asse.s de
probleme
Mr. President, my
Monsieur le Président, additional
ma question Mr. Speaker, my My supplementary question, which is Vocatif

supplémentaire, qui
s'adresse encore une
fois au ministre, est
trés simple.

supplementary
question again to
the minister is very
simple.

question, which is
once again to the
minister, is very
simple Mr. Speaker.

addressed to the
minister once
again, is very
simple

C'est la seule arme
qu'i| leur reste.

It is the only tool we
have left.

It is the only weapon
that it remains for
them.

It is the only
weapon that it
remains forthem.

Verbe impersonnel

Le véritable probleme,
ce sont les
récidivistes.

The real problem is
the repeat
offenders.

The real problem, it is
the recidivists.

The true problem,
they are the
recidivists.

Complément
disloqué a gauche

Quand la ministre
entend-elle agir?

When does the
minister intend to

When does the
minister intend for it to

When the minister
intend does to act?

Sujet double avec
pronom dans les

act ? act? interrogatives

Tableau 3 : Classes d’erreurs a corriger pour le domaine général

Les exemples présentés dans le Tableau 3 illustrent certaines constructions ou nous savons
que nous pouvons faire des progres en améliorant l’analyse du francais et de l’anglais si
nécessaire. Ces constructions sont typiques du style parlé, ce qui explique que nous n’ayons
pas rencontré beaucoup de cas jusqu’a présent dans nos ﬁchiers de régression.

Le Vocatif est tres courant dans le corpus du Hansard. Lorsque le Vocatif n’est pas reconnu
comme tel par la grammaire, il risque de devenir l’objet direct ou indirect de la phrase par
erreur. Dans la traduction MSR-MT (ligne 1 du tableau), nous remarquons qu’il n’a pas été
reconnu correctement, et n’est pas placé en téte de phrase. Un autre exemple a corriger dans
notre représentation est la dislocation du nom a gauche (ligne 3). En corrigeant la forme
logique, nous pourrons facilement arriver a la traduction modele de la référence, et donc
dépasser la qualité de la traduction de Systran. Les autres erreurs, elles aussi typiques du
langage parlé, pourront étre corrigées dans notre systeme d’analyse.

3. Conclusion

La traduction de MSR-MT dépasse la qualité de la traduction de Systran dans le domaine
technique, grace en partie au travail linguistique sur les analyses du francais. Nos résultats
dans un domaine plus général (Hansard) montrent que la traduction est assez proche de la
qualité de Systran, bien que nous n’ayons pour l’instant fait aucun travail spécifique au
domaine. Nous avons identifié des problemes linguistiques auxquels nous devons nous
adresser pour améliorer la qualité de notre traduction automatique dans ce nouveau domaine.

Bibliographie

295

Jessie Pinkham et Martine Smets

A1-Onaizan Y, Curin J ., Jahr M., Knight K., Lafferty J ., Melamed D., Och F-J, Purdy D., Smith N. A.,
Yarowsky D. (1999), Statistical Machine Translation: Final Report, Johns Hopkins University 1999 Summer
Workshop on Language Engineering, Center for Speech and Language Processing, Baltimore, MD.

Boitet C. (2001), Me'thodes d'acquisition lexicale en TAO : des dictiomiaires specialises proprie'taires aux bases
lexicales ge'ne'ralistes et ouvertes, Actes de l ’Atelier sur la T raduction automatique et applications en
grandeur réelle, TALN 2001.

Brown P., Della Pietra S., Della Pietra V., Mercer R. (1993), The mathematics of statistical machine translation,
Computational Linguistics, 19, 263-312.

Dorr B. (1993), Interlingual Machine Translation: a Parameterized Approach, Artiﬁcial Intelligence 63(l&2),
429-492.

Dorr Bonnie, Johnson P, Benoit J (1999), A Survey of Current Paradigms in Translation, Advances in
Computers, Vol. 49, M. Zelkowitz (Ed), Academic Press, London, 1-68.

Kaji H., Kida Y., Morimoto Y. (1992), Learning Translation Templates from Bilingual Text, Actes de COLING
1992, 672-678.

Heidom G. (2000), Intelligent Writing Assistance, Handbook of Natural Language Processing, Robert Dale,
Hermarm Moisl et Harold Somers, eds., 181-207.

Hutchins W. J . (2001), Machine Translation over fifty years, Histoire Epistémologie Langage vol. 23 (1), 7-31.

Jensen K (1993), The PLNLP English grammar, Natural Language Processing: The PLNLP approach Jensen
K., Heidom G. et Richardson S. eds. Boston: Kluwer Academic.

Meyers A., Kosaka M., Grishman R. (2000), Chart-based transfer mle application in machine translation, Actes
de COLING 1998, 843-847.

Menezes A., Richardson S. (2001), A best-first alignment algorithm for automatic extraction of transfer
mappings from bilingual corpora, Proceedings of the Workshop on Data—Driven Machine Translation, ACL
Conference, 39-46.

Nyberg E., Mitamura T. (1991), An Efficient Interlingua Translation System for Multilingual Document
Production, Actes de MT Summit 111, 55-61.

Pinkham J . and Corston-Oliver M. (2001a), Adding Domain Specificity to an MT system, Proceedings of the
Workshop on Data—Driven Machine Translation, ACL Conference, 103-110.

Pinkham J., Corston-Oliver M., Smets M., Pettenaro M. (2001b), Rapid assembly of a large-scale French-
English MT system, Actes de MT Summit VIII, 277-282.

Pinkham.J., Smets M. (2002a), Machine Translation without a Bilingual Dictionary, Actes de TMI, 146-156.

Pinkham J ., Smets M. (2002b), Modular MT with a learned bilingual dictionary: rapid deployment of a new
language pair, A paraitre dans Actes de COLING 2002.

Poyen J ., Vauquois B. (1959), A propos d'un langage universel, IFIP Congress 1959, 132-137.

Richardson S., Dolan W., Menezes A., Corston-Oliver M. (2001), Overcoming the Customisation Bottleneck
Using Example-Based MT, Proceedings of the Workshop on Data—Driven Machine Translation, ACL
Conference, 9-16.

Menezes A., Pentheroudakis J ., Smets M. (2002), Translation of verbal idioms, A paraitre dans Proceedings of
International Workshop on Computational Approaches to Collocations.

Moore R.C. (2001), Towards a Simple and Accurate Statistical Approach to Learning Translation Relationships
among Words, Proceedings of the Workshop on Data—Driven Machine Translation, ACL Conference, 79-86
Vauquois B. (1968), A Survey of Fomial Grammars and Algorithms for Recognition and Transfomiation in

Machine Translation, IFIP Congress 68, 254-260.

Watanabe H., Kurohashi S. and Aramaki E. (2000), Finding Structural Correspondences from Bilingual Parsed

Corpus for Corpus-based Translation, Actes de COLING 2000, 906-912.

296

