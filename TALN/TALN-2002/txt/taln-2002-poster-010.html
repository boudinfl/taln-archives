<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Segmentation en th&#232;mes de conversations t&#233;l&#233;phoniques : traitement en amont pour l&#8217;extraction d&#8217;information</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmentation en the&#768;mes de conversations
te&#769;le&#769;phoniques :traitement en amont pour l&#8217;extraction
</p>
<p>d&#8217;information
</p>
<p>Narje&#768;s Boufaden, Guy Lapalme, Yoshua Bengio
&#0;boufaden, lapalme, bengioy&#1;@iro.umontreal.ca
</p>
<p>De&#769;partement d&#8217;informatique et Recherche Ope&#769;rationnelle
Universite&#769; de Montre&#769;al, Que&#769;bec Canada
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>segmentation en the&#768;mes, analyse des conversations, extraction d&#8217;information
topic segmentation, conversation analysis, information extraction
</p>
<p>Re&#769;sume&#769; - Abstract
</p>
<p>Nous pre&#769;sentons une approche de de&#769;coupage the&#769;matique que nous utiliserons pour faciliter l&#8217;ex-
traction d&#8217;information a&#768; partir de conversations te&#769;le&#769;phoniques transcrites. Nous expe&#769;rimentons
avec un mode&#768;le de Markov cache&#769; utilisant des informations de diffe&#769;rents niveaux linguistiques,
des marques d&#8217;extra-grammaticalite&#769;s et les entite&#769;s nomme&#769;es comme source additionnelle d&#8217;in-
formation. Nous comparons le mode&#768;le obtenu avec notre mode&#768;le de base utilisant uniquement
les marques linguistiques et les extra-grammaticalite&#769;s. Les re&#769;sultats montrent l&#8217;efficacite&#769; de
l&#8217;approche utilisant les entite&#769;s nomme&#769;es.
</p>
<p>We study the problem of topic segmentation as a means to facilitate information extraction from
manually transcribed convesrations. We experiment with a first order HMM using a combination
of linguistic-level cues and named entities. We compare the results of our linguistic-levels cues
based model with the named entities based model. Results show the effectiveness of named
entities as an additional source of information for topic segmentation.
</p>
<p>377</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1 Introduction
</p>
<p>Une e&#769;tape cruciale de l&#8217;extraction d&#8217;information est la localisation des e&#769;nonce&#769;s contenant de
l&#8217;information pertinente. Cette e&#769;tape ma&#305;&#770;trise&#769;e pour les textes e&#769;crits structure&#769;s ne l&#8217;est pas
encore pour les textes oraux. Les conversations (Figure 1) pre&#769;sentent plusieurs particularite&#769;s
compliquant l&#8217;extraction d&#8217;information notamment l&#8217;aspect collaboratif des conversations et la
pre&#769;sence d&#8217;extra-grammaticalite&#769;s. Ces deux caracte&#769;ristiques font que (1) les e&#769;le&#769;ments d&#8217;une
re&#769;ponse ne se trouvent pas ne&#769;cessairement dans le me&#770;me e&#769;nonce&#769; et (2) il faut pouvoir re-
constituer la re&#769;ponse correcte a&#768; partir d&#8217;un segment dont la structure grammaticale est alte&#769;re&#769;e
par les extra-grammaticalite&#769;s. Dans nos travaux ante&#769;rieurs, nous soutenions que le de&#769;coupage
the&#769;matique peut faciliter l&#8217;extraction d&#8217;information a&#768; partir des conversations (Boufaden et al.,
2001; Boufaden et al., 2002). Nous avons e&#769;labore&#769; un syste&#768;me de de&#769;coupage the&#769;matique qui
de&#769;tecte les changements de the&#768;mes a&#768; partir de marques lexicales, syntaxiques, discursives et des
interruptions. Dans notre premier syste&#768;me la marque discursive e&#769;tait ajoute&#769; manuellement ce
qui ne permettait pas un de&#769;coupage comple&#768;tement automatise&#769;. Dans cet article, nous pre&#769;sentons,
tout d&#8217;abord, les re&#769;sultats de l&#8217;automatisation du calcul de la marque discursive. Ensuite, nous
proposons l&#8217;utilisation des entite&#769;s nomme&#769;es comme source d&#8217;information additionnelle pour
ame&#769;liorer le de&#769;coupage the&#769;matique.
</p>
<p>1 C Maritime operation centre, (INAUDIBLE) hello.
2 O Hi, Mr. Green, it&#8217;s captain Mr. Red
3 C Yes.
</p>
<p>. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
</p>
<p>4 O Ha, I don&#8217;nt know if I was handled over to you at all, but
we&#8217;ve got an overdue boat on the south coast of Town2, just in
the area quite between Town1 and Town3.
</p>
<p>5 O It&#8217;s on the south east coast of Town2.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
</p>
<p>6 O This is been going on for, for 24 hours that the case has, or almost
anyway, and we had an Airplane1 up flying this morning
</p>
<p>7 O They did a radar search for us in that area.
8 C Yes.
</p>
<p>. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
</p>
<p>9 O And their search turned up nothing.
10 C yeah.
</p>
<p>. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
</p>
<p>11 C Thanks.
12 O All right.
13 O Bye
</p>
<p>FIG. 1 &#8211; Extrait d&#8217;un compte rendu entre deux locuteurs : Caller (C) et Operator (O).
Pour des raisons de confidentialite&#769; certaines entite&#769;s nomme&#769;es ont e&#769;te&#769; remplace&#769;es par des noms
ge&#769;ne&#769;riques. Les lignes pointille&#769;es sont les frontie&#768;res des segments the&#769;matiques.
</p>
<p>2 &#180;Expe&#769;riences et re&#769;sultats
</p>
<p>Notre approche pour le de&#769;coupage the&#769;matique repose sur l&#8217;utilisation d&#8217;informations linguis-
tiques (Halliday et al., 1976; Maynard, 1980) et extra-linguistiques pour de&#769;tecter les change-
</p>
<p>378</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ments de the&#768;mes. Les informations linguistiques sont essentiellement :
&#8211; des mots tels que ok, right, well que nous appelons marques lexicales,
&#8211; des adverbes temporaux, conjonctions qui sont des marques syntaxiques,
&#8211; le ro&#770;le du locuteur dans le de&#769;veloppement du the&#768;me que nous appelons marque discur-
</p>
<p>sive. Dans une conversation entre deux locuteurs, chaque locuteur montre son inte&#769;re&#770;t et
sa compre&#769;hension de ce qui est communique&#769; gra&#770;ce a&#768; des re&#769;ponses typiques tels que ok,
yeah, right. En fonction du ro&#770;le du locuteur dans le processus de&#769;veloppemental du
the&#768;me, ces re&#769;ponses peuvent e&#770;tre perc&#807;ues comme un incitateur a&#768; continuer le the&#768;me ou au
contraire comme un inhibiteur dans le but d&#8217;interrompre le the&#768;me. En particulier (Maynard,
1980) parle de locuteur initiateur du the&#768;me topical speaker, comme e&#769;tant le locuteur qui
verbalise son intention communicative, par opposition au destinataire recipient qui va inci-
ter a&#768; de&#769;velopper le the&#768;me ou au contraire changer de the&#768;ne. Nous avons montre&#769; que cette
information ame&#769;liore les re&#769;sultats de la segmentation (Boufaden et al., 2001).
</p>
<p>La marque extra-linguistique que nous utilisons est l&#8217;interruption transcrite dans les conver-
sations par des points de suspension. Les statistiques faites sur notre corpus ont montre&#769; une
corre&#769;lation entre les interruptions et les changements de the&#768;mes.
</p>
<p>2.1 Mode&#768;le de langue
</p>
<p>Dans (Boufaden et al., 2001), nous avons montre&#769; que le proble&#768;me de de&#769;tection d&#8217;un changement
de the&#768;me peut e&#770;tre transpose&#769; en un proble&#768;me de classification des e&#769;nonce&#769;s. Nous e&#769;mettions
l&#8217;hypothe&#768;se qu&#8217;entre chaque vecteur de marques se situe une frontie&#768;re qui permet de de&#769;limiter
deux classes d&#8217;e&#769;nonce&#769;. Nous avons construit un mode&#768;le de Markov cache&#769; d&#8217;ordre 1 compose&#769; de
cinq e&#769;tats (Figure 2) ou&#768; chacun des e&#769;tats repre&#769;sente une classe d&#8217;e&#769;nonce&#769; :
&#8211; Les e&#769;nonce&#769;s qui indiquent un de&#769;but de conversation. Ge&#769;ne&#769;ralement ils contiennent des salu-
</p>
<p>tations ainsi que l&#8217;identification des locuteurs. Ces e&#769;nonce&#769;s sont repre&#769;sente&#769;s par la classe BC
(Begin Conversation)
</p>
<p>&#8211; Les e&#769;nonce&#769;s qui clo&#770;turent une conversation sont repre&#769;sente&#769;s par la classe EC (End Conversa-
tion). Ces e&#769;nonce&#769;s contiennent souvent des expressions type&#769;es tels que talk to you later, bye,
have a good day.
</p>
<p>&#8211; Les e&#769;nonce&#769;s qui de&#769;butent un nouveau the&#768;me forment la classe TC (Topic Change).
&#8211; Les e&#769;nonce&#769;s qui font partie du corps d&#8217;un the&#768;me sont repre&#769;sente&#769;s par la classe NO-TC (No
</p>
<p>Topic Change).
&#8211; Les e&#769;nonce&#769;s qui clo&#770;turent un the&#768;me sont repre&#769;sente&#769;s par la classe ET (End of Topic). Ces
</p>
<p>e&#769;nonce&#769;s sont souvent compose&#769;s d&#8217;unite&#769;s lexicales tels que ok, right, well.
</p>
<p>&#1;&#2;&#3;&#4;&#5;&#6;&#7;&#8;BC &#0;&#0;&#1; &#1;&#1;
&#0;&#2;&#3;
</p>
<p>&#2;&#2; &#1;&#2;&#3;&#4;&#5;&#6;&#7;&#8;TC
&#0;&#4;
</p>
<p>&#3;&#3;
&#0;&#2;&#2;&#4;&#4;
</p>
<p>&#0;&#4;&#5;
</p>
<p>&#5;&#5;&#9;&#10;&#11;&#12;&#13;&#14;&#15;&#16;No-TC
&#0;&#0;&#5;
</p>
<p>&#1;&#1;&#0;&#3;&#1;
&#2;&#2;
</p>
<p>&#6;&#0;&#4;&#5;
</p>
<p>&#6;&#6;
&#1;&#2;&#3;&#4;&#5;&#6;&#7;&#8;ET
</p>
<p>&#0;&#0;&#5;
</p>
<p>&#2;&#2;
</p>
<p>&#0;&#6;&#7;
</p>
<p>&#1;&#1;
</p>
<p>&#0;&#3;&#8;
</p>
<p>&#7;&#7;
&#1;&#2;&#3;&#4;&#5;&#6;&#7;&#8;EC
</p>
<p>&#0;&#8;&#9;
</p>
<p>&#2;&#2;
</p>
<p>&#0;&#6;&#9;
</p>
<p>&#8;&#8;
</p>
<p>FIG. 2 &#8211; HMM d&#8217;ordre 1 pour la segmentation en topique
</p>
<p>La Figure 2 illustre notre mode&#768;le de langue. Les valeurs repre&#769;sente&#769;es au dessus des arcs sont les
probabilite&#769;s &#0; &#0;&#1;
</p>
<p>&#1;
</p>
<p>&#0;&#1;
</p>
<p>&#2;
</p>
<p>&#1; de ge&#769;ne&#769;rer l&#8217;e&#769;tat &#1;
&#1;
</p>
<p>sachant que l&#8217;on est dans l&#8217;e&#769;tat &#1;
&#2;
</p>
<p>.
</p>
<p>379</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Nous avons montre&#769; que, parmi les combinaisons de marque possibles (lexicale-discursive, lexicale-
discursive-syntaxique, lexicale-discursive-syntaxique-interruption) pour la segmentation, la meilleure
performance e&#769;tait obtenue avec la combinaison de toutes les marques c&#8217;est-a&#768;-dire lexicale, syn-
taxique, discursive et interruption (mode&#768;le SLDI) utilise&#769;e avec un mode&#768;le de Markov cache&#769;
d&#8217;ordre 1. Les re&#769;sultats rapporte&#769;s dans (Boufaden et al., 2001) e&#769;taient base&#769;s sur un corpus d&#8217;en-
tra&#305;&#770;nement ou&#768; la marque discursive e&#769;tait ajoute&#769;e manuellement. Afin de rendre le de&#769;coupage
comple&#768;tement automatise&#769;, nous avons imple&#769;mente&#769; un mode&#768;le de Markov d&#8217;ordre 1 qui per-
met la ge&#769;ne&#769;ration automatique du trait discursif. Ensuite, dans le but d&#8217;ame&#769;liorer les re&#769;sultats
du syste&#768;me de de&#769;coupage the&#769;matique, nous avons extrait automatiquement les entite&#769;s nomme&#769;es
pour les utiliser comme une source d&#8217;information additionnelle. Dans ce qui suit, nous de&#769;crivons
les re&#769;sultats de ces deux expe&#769;riences.Tous les re&#769;sultats pre&#769;sente&#769;s ici sont obtenus par validation
croise&#769;e et avec des proportions de 85% pour l&#8217;apprentissage et 15% pour le test. Le corpus de
base pour la segmentation est compose&#769; de 65 conversations, environ 3,700 e&#769;nonce&#769;s.
</p>
<p>2.2 Calcul de la marque discursive
</p>
<p>Pour pre&#769;dire les traits discursifs, la premie&#768;re ide&#769;e e&#769;tait de conside&#769;rer le locuteur (Operator O
et Caller C) comme un trait discriminant en plus des marques syntaxiques et lexicales utilise&#769;es
pour la segmentation. Afin de ne retenir que les traits les plus inte&#769;ressants pour le mode&#768;le,
nous avons teste&#769; diffe&#769;rentes combinaisons entre les traits locuteur, syntaxique et lexical. Les
combinaisons retenues sont celles ou&#768; le locuteur est utilise&#769; conjointement avec les traits lexical
et syntaxique et une autre ou&#768; le trait locuteur n&#8217;est pas conside&#769;re&#769;. Nous avons entra&#305;&#770;ne&#769; deux
mode&#768;les de Markov cache&#769; sur 82 conversations qui ont e&#769;te&#769; manuellement annote&#769;es avec le trait
discursif et ils ont e&#769;te&#769; teste&#769;s sur 13 conversations. Les tableaux 1 et 2 repre&#769;sentent respective-
ment le taux d&#8217;erreur de classification, la pre&#769;cision et le rappel pour les classes destinataire (R)
et initiateur de the&#768;me (S).
</p>
<p>Trait discursif R S Moyenne
ponde&#769;re&#769;e
</p>
<p>(+) locuteur 24.1% 19.9% 21.7%
(-) locuteur 21.3% 20.6% 20.9%
</p>
<p>TAB. 1 &#8211; Taux d&#8217;erreur de pre&#769;diction du trait
discursif pour les mode&#768;les de Markov d&#8217;ordre
1 avec locuteur et sans locuteur
</p>
<p>Trait discursif Rappel Pre&#769;cision
R 74.8% 78.5%
S 79.3% 79.7%
Moy.ponde&#769;re&#769;e 77.3% 78.9%
</p>
<p>TAB. 2 &#8211; Rappel et Pre&#769;cision par trait discursif
pour le mode&#768;le sans locuteur
</p>
<p>Il est inte&#769;ressant d&#8217;observer que seules les marques lexicales et syntaxiques suffisent a&#768; de&#769;terminer
le ro&#770;le du locuteur dans le processus de&#769;veloppemental. L&#8217;utilisation de la marque discursive
ge&#769;ne&#769;re&#769;e automatiquement a diminue&#769; le&#769;ge&#768;rement les performances du syste&#768;me de de&#769;coupage
the&#769;matique. Le taux d&#8217;erreur moyen ponde&#769;re&#769; de de&#769;coupage e&#769;tait de 16.5% avec la marque dis-
cursive ajoute&#769;e manuellement, tandis qu&#8217;avec celle calcule&#769;e automatiquement il est de 18.5%.
</p>
<p>2.3 Entite&#769;s nomme&#769;es source additionnelle d&#8217;information
</p>
<p>Le but de cette expe&#769;rimentation est d&#8217;ame&#769;liorer les performances du syste&#768;me pre&#769;sente&#769; dans
(Boufaden et al., 2001). Un des proble&#768;mes souligne&#769;s dans (Boufaden et al., 2001) e&#769;tait le
</p>
<p>380</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>manque de marques dans certains e&#769;nonce&#769;s tels que ceux qui commence un nouveau the&#768;me ainsi
que ceux de&#769;butant une conversation. Nous avons remarque&#769; que 30.7% des e&#769;nonce&#769;s classe&#769;s BC
et 46.8% des e&#769;nonce&#769;s que nous avons classe&#769;s TC dans le corpus d&#8217;entra&#305;&#770;nement contiennent
uniquement la marque discursive. Par contre, nous avions aussi constate&#769; la pre&#769;sence d&#8217;en-
tite&#769;s nomme&#769;es dans ces me&#770;mes e&#769;nonce&#769;s. Lors d&#8217;un de&#769;but de conversation les locuteurs se
pre&#769;sentent et identifient l&#8217;organisme auquel ils appartiennent, ce qui implique la pre&#769;sence d&#8217;en-
tite&#769;s nomme&#769;es de type ORGANISME et PERSONNE. `A chaque changement de the&#768;me de nouveaux
objets sont introduits et a&#768; cause de la nature informative de nos conversations ces objets, cor-
respondent souvent a&#768; des entite&#769;s nomme&#769;es tels que les types d&#8217;avion, de bateaux, d&#8217;organisme
ou les lieux. Suite a&#768; ces observations, nous avons proce&#769;de&#769; a&#768; l&#8217;extraction automatique des entite&#769;s
nomme&#769;es PERSONNE, ORGANISME, AVION, BATEAU et LIEUX pour les inte&#769;grer a&#768; l&#8217;ensemble
des marques utilise&#769;es pour le de&#769;coupage the&#769;matique. D&#8217;emble&#769;e, cette proce&#769;dure a permis de
diminuer les pourcentages d&#8217;e&#769;nonce&#769;s annote&#769;s uniquement avec le trait discursif a&#768; 16.5% pour la
classe BC et 35.9% pour la classe TC (par rapport a&#768; 30.7% et 46.8%). Ensuite, nous avons uti-
lise&#769; les types d&#8217;entite&#769;s nomme&#769;es avec les anciennes marques pour re&#769;entra&#305;&#770;ner notre mode&#768;le de
Markov. Les re&#769;sultats de cette expe&#769;rience sont repre&#769;sente&#769;s dans les tableaux 3 et 4. La colonne
&#8220;(+) entite&#769;s nomme&#769;es&#8221; fait re&#769;fe&#769;rence au syste&#768;me qui utilise les entite&#769;s nomme&#769;es comme source
additionnelle d&#8217;information. La colonne &#8220;(-) entite&#769;s nomme&#769;es&#8221; repre&#769;sente le syste&#768;me de base
qui utilise les marques linguistiques et extra-linguistiques. Pour les deux mode&#768;les les marques
sont extraites de manie&#768;re automatique.
</p>
<p>Classe d&#8217;e&#769;nonce&#769; (+) entite&#769;s nomme&#769;es (-) entite&#769;s nomme&#769;es
BC 24.0% 39.4%
EC 12.1% 12.1%
TC 38.6% 39.2%
No-TC 9.9% 9.4%
Moy. ponde&#769;re&#769;e 17.0% 18.1%
</p>
<p>TAB. 3 &#8211; Taux d&#8217;erreurs par classe d&#8217;e&#769;nonce&#769; avec le mode&#768;le de Markov d&#8217;ordre 1 entra&#305;&#770;ne&#769; sur
toutes les marques plus (+) les entite&#769;s nomme&#769;es, et sans (-) les entite&#769; nomme&#769;es
</p>
<p>Classe d&#8217;e&#769;nonce&#769; (+) entite&#769;s nomme&#769;es (-) entite&#769;s nomme&#769;es
Pre&#769;c. Rapp. Pre&#769;c. Rapp.
</p>
<p>BC 83.0% 76.0% 78.9% 60.6%
EC 82.6% 87.9% 80.4% 87.9%
TC 67.3% 61.4% 67.5% 86.0%
No-TC 87.0% 90.1% 85.8% 90.6%
Moy. ponde&#769;re&#769;e 82.6% 83.0% 81.3% 81.9%
</p>
<p>TAB. 4 &#8211; Rappel et Pre&#769;cision par classe d&#8217;e&#769;nonce&#769;
</p>
<p>C&#8217;est au niveau de la classe BC que l&#8217;on observe la plus grande ame&#769;lioration. Dans le syste&#768;me
qui utilise les entite&#769;s nomme&#769;es le taux d&#8217;erreurs a diminue&#769; pour passer de 39.4% a&#768; 24%. Aussi,
le rappel a significativement augmente&#769; pour passer de 60% a&#768; 76%, ce qui indique que le syste&#768;me
de&#769;tecte plus d&#8217;e&#769;nonce&#769;s de la classe BC, mais aussi se trompe moins dans sa classification puisque
la pre&#769;cision a aussi augmente&#769; pour passer de 78.9% a 83%.
</p>
<p>Toutefois, nous ne pouvons attester des me&#770;mes ame&#769;liorations pour les autres classes. En par-
ticulier pour la classe TC, nous avons diminue&#769; le taux d&#8217;erreur de 1.5% ce qui est un maigre
</p>
<p>381</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>re&#769;sultat comparativement a&#768; celui de 39.9% pour la classe BC. Nous pensons que le manque de
raffinement du module d&#8217;extraction d&#8217;entite&#769;s nomme&#769;es en est la cause principale.
</p>
<p>3 Conclusion et travaux futurs
</p>
<p>La majorite&#769; des me&#769;thodes de segmentation en the&#768;mes, que ce soit dans le cadre d&#8217;applications
telles que la recherche d&#8217;information ou dans des applications de&#769;die&#769;es a&#768; la segmentation uti-
lise&#769;es dans les confe&#769;rence TDT (Topic Detection and Tracking)(Allan et al., 1998), utilisent des
unite&#769;s lexicales et la prosodie mode&#769;lise&#769;s par des approches statistiques tels que les mode&#768;les de
Markov et/ou des arbres de de&#769;cisions (Litman et al., 1995; Laferty et al., 1999). Dans notre
approche, nous avons utilise&#769; des unite&#769;s lexicales dans le processus de segmentation, toutefois,
nous avons ajoute&#769; deux autres sources d&#8217;information : le trait discursif pour mode&#769;liser l&#8217;aspect
collaboratif des conversations et les cate&#769;gories d&#8217;entite&#769;s nomme&#769;es pour enrichir notre mode&#768;le.
Les re&#769;sultats montrent que les entite&#769;s nomme&#769;es accroissent les performances du syste&#768;me glo-
balement puisque le score ponde&#769;re&#769; pour le rappel est passe&#769; de 81.3% a&#768; 82.6% et de 81.9% a&#768;
83% pour la pre&#769;cision. La plus grande ame&#769;lioration a e&#769;te&#769; enregistre&#769;e pour la classe BC avec
39.9% de diminution du taux d&#8217;erreur. Toutefois, plusieurs ame&#769;liorations doivent e&#770;tre apporte&#769;es
au module d&#8217;extraction des entite&#769;s nomme&#769;es pour ame&#769;liorer les re&#769;sultats de la classe TC. En-
fin, a&#768; notre connaissance peu ou pas de travaux en segmentation de dialogues ont e&#769;te&#769; publie&#769;s,
de ce fait il est difficile d&#8217;e&#769;valuer nos re&#769;sultats comparativement a&#768; d&#8217;autres travaux. Toutefois,
ceux-ci sont assez concluants pour permettre le passage a&#768; l&#8217;e&#769;tape d&#8217;extraction d&#8217;information.
La deuxie&#768;me e&#769;tape de notre projet consiste a&#768; extraire les informations a&#768; partir des segments
the&#769;matiques. Notre but est de de&#769;finir une approche d&#8217;extraction centre&#769;e sur l&#8217;utilisation du seg-
ment the&#769;matique comme unite&#769; d&#8217;extraction, en plus d&#8217;e&#770;tre robuste pour extraire l&#8217;information
en de&#769;pit des alte&#769;rations de la structure syntaxique des e&#769;nonce&#769;s.
</p>
<p>Re&#769;fe&#769;rences
J. Allan, J. Carbonnel, G. Doddington, J. Yamron, and Y. Yang. Topic Detection and Tracking pilot study
final report. In Proc. of the DARPA Broadcast News Transcription and Understanding Workshop, 1998.
N. Boufaden, G. Lapalme, and Y. Bengio. Topic segmentation : A first stage to dialog-based information
extraction. In Natural Language Processing Rim Symposium, NLPRS&#8217;01, pages 273&#8211;280, 2001.
N. Boufaden, G. Lapalme, and Y. Bengio. De&#769;coupage the&#769;matique : un outil d&#8217;aide a&#768; l&#8217;extraction d&#8217;infor-
mation. In TALN 2002, Nancy, France, Juin 2002.
J. Lafferty D. Beeferman, A. Berger. Statistical models for text segmentation. Machine Learning, 34(1-
3), Fevrier 1999.
M.A.K Halliday and R. Hassan. Cohesion in English. Longman, London, 1976.
W.J.M. Levelt. Speaking From Intention to Articulation. MIT Press, 1989.
D.J. Litman and R.J. Passonneau. Combining multiple knowledge sources for discourse segmentation.
In Proc. of ACL&#8217;95, pages 108&#8211;115, 95.
D.W. Maynard. Placement of topic changes in conversation. In Semiotica, volume 30, pages 263&#8211;290.
Mouton Publishers, 1980.
H. Sacks, E.A. Schegloff, and G. Jefferson. A simplest systematics for the organization of turn-taking.
In Language, volume 50, pages 696&#8211;735. 1974.
</p>
<p>382</p>

</div></div>
</body></html>