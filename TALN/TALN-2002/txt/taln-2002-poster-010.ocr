Segmentation en themes de conversations
téléphoniques :traitement en amont pour l’extraction
d’information

Narjes Boufaden, Guy Lapalme, Yoshua Bengio
{boufaden, lapalme, bengioy} @iro.umontreal.ca
Département d’informatique et Recherche Opérationnelle
Université de Montréal, Québec Canada

Mots-clefs — Keywords

segmentation en themes, analyse des conversations, extraction d’information
topic segmentation, conversation analysis, information extraction

Résumé - Abstract

Nous présentons une approche de découpage thématique que nous utiliserons pour faciliter 1’ ex-
traction d’information a partir de conversations téléphoniques transcrites. Nous expérimentons
avec un modele de Markov caché utilisant des informations de différents niveaux linguistiques,
des marques d’extra-grammaticalités et les entités nommées comme source additionnelle d’in-
formation. Nous comparons le modele obtenu avec notre modele de base utilisant uniquement
les marques linguistiques et les extra-grammaticalités. Les résultats montrent l’efﬁcacité de
l’approche utilisant les entités nommées.

We study the problem of topic segmentation as a means to facilitate information extraction from
manually transcribed convesrations. We experiment with a ﬁrst order HMM using a combination
of linguistic-level cues and named entities. We compare the results of our linguistic-levels cues
based model with the named entities based model. Results show the effectiveness of named
entities as an additional source of information for topic segmentation.

377

1 Introduction

Une étape cruciale de l’eXtraction d’information est la localisation des énoncés contenant de
l’information pertinente. Cette étape maitrisée pour les textes écrits structurés ne l’est pas
encore pour les textes oraux. Les conversations (Figure 1) présentent plusieurs particularités
compliquant l’eXtraction d’information notamment l’aspect collaboratif des conversations et la
présence d’eXtra-grammaticalités. Ces deux caractéristiques font que (1) les éléments d’une
réponse ne se trouvent pas nécessairement dans le meme énoncé et (2) il faut pouvoir re-
constituer la réponse correcte a partir d’un segment dont la structure grammaticale est altérée
par les extra-grammaticalités. Dans nos travaux antérieurs, nous soutenions que le découpage
thématique peut faciliter l’eXtraction d’information a partir des conversations (Boufaden et al.,
2001; Boufaden et al., 2002). Nous avons élaboré un systeme de découpage thématique qui
détecte les changements de themes a partir de marques lexicales, syntaxiques, discursives et des
interruptions. Dans notre premier systeme la marque discursive était ajouté manuellement ce
qui ne permettait pas un découpage completement automatisé. Dans cet article, nous présentons,
tout d’abord, les résultats de l’automatisation du calcul de la marque discursive. Ensuite, nous
proposons l’utilisation des entités nommées comme source d’information additionnelle pour
améliorer le découpage thématique.

l C Maritime operation centre, (INAUDIBLE) hello.

2 0 Hi, Mr. Green, it’s captain Mr. Red

3 C Yes.

4 0 Ha, I don ’nt know if I was handled over to you at all, but
we ’ve got an overdue boat on the south coast of Town2, just in
the area quite between Town] and Town3.

5 0 It’s on the south east coast of Town2.

6 O This is been going on for, for 24 hours that the case has, or almost
anyway, and we had an Airplane] up ﬂying this morning

7 0 They did a radar search for us in that area.
8 C Yes.

9 0 And their search turned up nothing.

lO C yeah.

ll C Thanks.
12 0 All right.
13 0 Bye

FIG. 1 — Extrait d’un compte rendu entre deux locuteurs : Caller (C) et Operator (0).
Pour des raisons de conﬁdentialité certaines entités nommées ont été remplacées par des noms
génériques. Les lignes pointillées sont les frontieres des segments thématiques.

2 Expériences et résultats

Notre approche pour le découpage thématique repose sur l’utilisation d’informations linguis-
tiques (Halliday et al., 1976; Maynard, 1980) et extra-linguistiques pour détecter les change-

378

ments de themes. Les informations linguistiques sont essentiellement :

— des mots tels que ok, right, well que nous appelons marques lexicales,

— des adverbes temporaux, conjonctions qui sont des marques syntaxiques,

— le role du locuteur dans le développement du theme que nous appelons marque discur-
sive. Dans une conversation entre deux locuteurs, chaque locuteur montre son intérét et
sa compréhension de ce qui est communiqué grace in des réponses typiques tels que ok,
yeah, right. En fonction du role du locuteur dans le processus développemental du
theme, ces réponses peuvent etre percues comme un incitateur a continuer le theme ou au
contraire comme un inhibiteur dans le but d’interrompre le theme. En particulier (Maynard,
1980) parle de locuteur initiateur du theme topical speaker, comme étant le locuteur qui
verbalise son intention communicative, par opposition au destinataire recipient qui va inci-
ter a développer le theme ou au contraire changer de thene. Nous avons montré que cette
information améliore les résultats de la segmentation (Boufaden et al., 2001).

La marque extra-linguistique que nous utilisons est l’interruption transcrite dans les conver-

sations par des points de suspension. Les statistiques faites sur notre corpus ont montré une

corrélation entre les interruptions et les changements de themes.

2.1 Modéle de langue

Dans (B oufaden et al., 2001), nous avons montré que le probleme de détection d’un changement
de theme peut étre transposé en un probleme de classiﬁcation des énoncés. Nous émettions
l’hypothese qu’entre chaque vecteur de marques se situe une frontiere qui permet de délimiter
deux classes d’énoncé. Nous avons construit un modele de Markov caché d’ordre 1 composé de
cinq états (Figure 2) ou chacun des états représente une classe d’énoncé :

— Les énoncés qui indiquent un début de conversation. Généralement ils contiennent des salu-
tations ainsi que l’identiﬁcation des locuteurs. Ces énoncés sont représentés par la classe BC
(Begin Conversation)

— Les énoncés qui cloturent une conversation sont représentés par la classe EC (End Conversa-
tion). Ces énoncés contiennent souvent des expressions typées tels que talk to you later, bye,
have a good day.

— Les énoncés qui débutent un nouveau theme forment la classe TC (Topic Change).

— Les énoncés qui font partie du corps d’un theme sont représentés par la classe NO—TC (No
Topic Change).

— Les énoncés qui cloturent un theme sont représentés par la classe ET (End of Topic). Ces
énoncés sont souvent composés d’unités lexicales tels que ok, right, well.

.13
.6 .1 .23
.2 Z’ .64
V’\"353/

.05

.95

 

FIG. 2 — HMM d’ordre 1 pour la segmentation en topique

La Figure 2 illustre notre modele de langue. Les valeurs représentées au dessus des arcs sont les
probabilités P(q,~ |qj) de générer l’état q, sachant que l’on est dans l’état qj.

379

Nous avons montré que, parmi les combinaisons de marque possibles (lexicale-discursive, lexicale-
discursive-syntaxique, lexicale-discursive-syntaxique-interruption) pour la segmentation, la meilleure
performance était obtenue avec la combinaison de toutes les marques c’est-a-dire lexicale, syn-
taxique, discursive et interruption (modele SLDI) utilisée avec un modele de Markov caché
d’ordre 1. Les résultats rapportés dans (Boufaden et al., 2001) étaient basés sur un corpus d’en-
trainement ou la marque discursive était ajoutée manuellement. Aﬁn de rendre le découpage
completement automatisé, nous avons implémenté un modele de Markov d’ordre 1 qui per-
met la génération automatique du trait discursif. Ensuite, dans le but d’améliorer les résultats
du systeme de découpage thématique, nous avons extrait automatiquement les entités nommées
pour les utiliser comme une source d’information additionnelle. Dans ce qui suit, nous décrivons
les résultats de ces deux expériences.Tous les résultats présentés ici sont obtenus par validation
croisée et avec des proportions de 85% pour l’apprentissage et 15% pour le test. Le corpus de
base pour la segmentation est composé de 65 conversations, environ 3,700 énoncés.

2.2 Calcul de la marque discursive

Pour prédire les traits discursifs, la premiere idée était de considérer le locuteur (Operator 0
et Caller C) comme un trait discriminant en plus des marques syntaxiques et lexicales utilisées
pour la segmentation. Aﬁn de ne retenir que les traits les plus intéressants pour le modele,
nous avons testé différentes combinaisons entre les traits locuteur, syntaxique et lexical. Les
combinaisons retenues sont celles ou le locuteur est utilisé conjointement avec les traits lexical
et syntaxique et une autre ou le trait locuteur n’est pas considéré. Nous avons entrainé deux
modeles de Markov caché sur 82 conversations qui ont été manuellement annotées avec le trait
discursif et ils ont été testés sur 13 conversations. Les tableaux 1 et 2 représentent respective-
ment le taux d’erreur de classiﬁcation, la précision et le rappel pour les classes destinataire (R)
et initiateur de theme (S).

Trait discursif R S Moyenne | Trait discursif | Rappel | Precision |
pondérée R 74.8% 78.5%

(+) locuteur 24.1% 19.9% 21.7% S 79.3% 79.7%

(-) locuteur 21.3% 20.6% 20.9% Moy.pondérée 77.3% 78.9%

TAB. 1 — Taux d’erreur de prédiction du trait TAB. 2 — Rappel et Précision par trait discursif
discursif pour les modeles de Markov d’ordre pour le modele sans locuteur
1 avec locuteur et sans locuteur

Il est intéressant d’observer que seules les marques lexicales et syntaxiques sufﬁsent a déterminer
le role du locuteur dans le processus développemental. L’utilisation de la marque discursive
générée automatiquement a diminué légerement les performances du systeme de découpage
thématique. Le taux d’erreur moyen pondéré de découpage était de 16.5% avec la marque dis-
cursive ajoutée manuellement, tandis qu’avec celle calculée automatiquement il est de 18.5%.

2.3 Entités nommées source additionnelle d’information

Le but de cette expérimentation est d’améliorer les performances du systeme présenté dans
(Boufaden et al., 2001). Un des problemes soulignés dans (Boufaden et al., 2001) était le

380

manque de marques dans certains énoncés tels que ceux qui commence un nouveau theme ainsi
que ceux débutant une conversation. Nous avons remarqué que 30.7% des énoncés classés BC
et 46.8% des énoncés que nous avons classés TC dans le corpus d’entrainement contiennent
uniquement la marque discursive. Par contre, nous avions aussi constaté la présence d’en-
tités nommées dans ces memes énoncés. Lors d’un début de conversation les locuteurs se
présentent et identiﬁent l’organisme auquel ils appartiennent, ce qui implique la présence d’en-
tités nommées de type ORGANISME et PERSONNE. A chaque changement de theme de nouveaux
objets sont introduits et a cause de la nature informative de nos conversations ces objets, cor-
respondent souvent a des entités nommées tels que les types d’avion, de bateaux, d’organisme
ou les lieux. Suite a ces observations, nous avons procédé a l’eXtraction automatique des entités
nommées PERSONNE, ORGANISME, AVION, BATEAU et LIEUX pour les intégrer a1’ensemb1e
des marques utilisées pour le découpage thématique. D’emblée, cette procedure a permis de
diIr1inuer les pourcentages d’énoncés annotés uniquement avec le trait discursif a 16.5% pour la
classe BC et 35.9% pour la classe TC (par rapport a 30.7% et 46.8%). Ensuite, nous avons uti-
lisé les types d’entités nommées avec les anciennes marques pour réentrainer notre modele de
Markov. Les résultats de cette expérience sont représentés dans les tableaux 3 et 4. La colonne
“(+) entités nommées” fait référence au systeme qui utilise les entités nommées comme source
additionnelle d’information. La colonne “(-) entités nommées” représente le systeme de base
qui utilise les marques linguistiques et extra-linguistiques. Pour les deux modeles les marques
sont extraites de maniere automatique.

(+) entités nommées | (-) entités nommées |

| Classe d’énoncé

BC 24.0% 39.4%
EC 12.1% 12.1%
TC 38.6% 39.2%
No-TC 9.9% 9.4%
| Moy.pondérée | 17.0% | 18.1% |

TAB. 3 — Taux d’erreurs par classe d’énoncé avec le modele de Markov d’ordre 1 entrainé sur
toutes les marques plus (+) les entités nommées, et sans (-) les entité nommées

Classe d’énoncé (+) entités nommées (-) entités nommées

Préc. | Rapp. Préc. | Rapp.
BC 83.0% 76.0% 78.9% 60.6%
EC 82.6% 87.9% 80.4% 87.9%
TC 67.3% 61.4% 67.5% 86.0%
No-TC 87.0% 90.1% 85.8% 90.6%

| Moy.pondérée | 82.6% | 83.0% | 81.3% | 81.9% |

TAB. 4 — Rappel et Précision par classe d’énoncé

C’est au niveau de la classe BC que l’on observe la plus grande amélioration. Dans le systeme
qui utilise les entités nommées le taux d’erreurs a diminué pour passer de 39.4% a 24%. Aussi,
le rappel a signiﬁcativement augmenté pour passer de 60% a 76%, ce qui indique que le systeme
détecte plus d’énoncés de la classe BC, mais aussi se trompe moins dans sa classiﬁcation puisque
la précision a aussi augmenté pour passer de 78.9% a 83%.

Toutefois, nous ne pouvons attester des memes améliorations pour les autres classes. En par-
ticulier pour la classe TC, nous avons diminué le taux d’erreur de 1.5% ce qui est un maigre

381

résultat comparativement a celui de 39.9% pour la classe BC. Nous pensons que le manque de
rafﬁnement du module d’extraction d’entités nommées en est la cause principale.

3 Conclusion et travaux futurs

La majorité des méthodes de segmentation en themes, que ce soit dans le cadre d’applications
telles que la recherche d’information ou dans des applications dédiées a la segmentation uti-
lisées dans les conférence TDT (Topic Detection and Tracking)(Allan et al., 1998), utilisent des
unités lexicales et la prosodie modélisés par des approches statistiques tels que les modeles de
Markov et/ou des arbres de décisions (Litman et al., 1995; Laferty et al., 1999). Dans notre
approche, nous avons utilisé des unités lexicales dans le processus de segmentation, toutefois,
nous avons ajouté deux autres sources d’information : le trait discursif pour modéliser l’aspect
collaboratif des conversations et les catégories d’entités nommées pour enrichir notre modele.
Les résultats montrent que les entités nommées accroissent les performances du systeme glo-
balement puisque le score pondéré pour le rappel est passé de 81.3% a 82.6% et de 81.9% a
83% pour la précision. La plus grande amélioration a été enregistrée pour la classe BC avec
39.9% de diminution du taux d’erreur. Toutefois, plusieurs améliorations doivent étre apportées
au module d’extraction des entités nommées pour améliorer les résultats de la classe TC. En-
ﬁn, a notre connaissance peu ou pas de travaux en segmentation de dialogues ont été publiés,
de ce fait il est difﬁcile d’évaluer nos résultats comparativement a d’autres travaux. Toutefois,
ceux-ci sont assez concluants pour permettre le passage a l’étape d’extraction d’information.
La deuxieme étape de notre projet consiste a extraire les informations a partir des segments
thématiques. Notre but est de déﬁnir une approche d’extraction centrée sur l’utilisation du seg-
ment thématique comme unité d’extraction, en plus d’étre robuste pour extraire l’information
en dépit des altérations de la structure syntaxique des énoncés.

Références

J. Allan, J. Carbonnel, G. Doddington, J. Yamron, and Y. Yang. Topic Detection and Tracking pilot study
ﬁnal report. In Proc. of the DARPA Broadcast News Transcription and Understanding Workshop, 1998.

N. Boufaden, G. Lapalme, and Y. Bengio. Topic segmentation 2 A ﬁrst stage to dialog-based information
extraction. In Natural Language Processing Rim Symposium, NLPRS’0I, pages 273-280, 2001.

N. Boufaden, G. Lapalme, and Y. Bengio. Découpage thématique 2 un outil d’ aide a l’extraction d’infor-
mation. In TALN 2002, Nancy, France, Juin 2002.

J . Lafferty D. Beeferman, A. Berger. Statistical models for text segmentation. Machine Learning, 34(1-
3), Fevrier 1999.

M.A.K Halliday and R. Hassan. Cohesion in English. Longman, London, 1976.
W.J.M. Levelt. Speaking From Intention to Articulation. MIT Press, 1989.

D.J. Litman and R.J. Passonneau. Combining multiple knowledge sources for discourse segmentation.
In Proc. ofACL’95, pages 108-115, 95.

D.W. Maynard. Placement of topic changes in conversation. In Semiotica, Volume 30, pages 263-290.
Mouton Publishers, 1980.

H. Sacks, E.A. Schegloff, and G. Jefferson. A simplest systematics for the organization of tum-taking.
In Language, Volume 50, pages 696-735. 1974.

382

