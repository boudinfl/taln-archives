<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allan</author>
<author>J Carbonnel</author>
<author>G Doddington</author>
<author>J Yamron</author>
<author>Y Yang</author>
</authors>
<title>Topic Detection and Tracking pilot study ﬁnal report.</title>
<date>1998</date>
<booktitle>In Proc. of the DARPA Broadcast News Transcription and Understanding Workshop,</booktitle>
<contexts>
<context position="13597" citStr="Allan et al., 1998" startWordPosition="2088" endWordPosition="2091">es memes améliorations pour les autres classes. En particulier pour la classe TC, nous avons diminué le taux d’erreur de 1.5% ce qui est un maigre 381 résultat comparativement a celui de 39.9% pour la classe BC. Nous pensons que le manque de rafﬁnement du module d’extraction d’entités nommées en est la cause principale. 3 Conclusion et travaux futurs La majorité des méthodes de segmentation en themes, que ce soit dans le cadre d’applications telles que la recherche d’information ou dans des applications dédiées a la segmentation utilisées dans les conférence TDT (Topic Detection and Tracking)(Allan et al., 1998), utilisent des unités lexicales et la prosodie modélisés par des approches statistiques tels que les modeles de Markov et/ou des arbres de décisions (Litman et al., 1995; Laferty et al., 1999). Dans notre approche, nous avons utilisé des unités lexicales dans le processus de segmentation, toutefois, nous avons ajouté deux autres sources d’information : le trait discursif pour modéliser l’aspect collaboratif des conversations et les catégories d’entités nommées pour enrichir notre modele. Les résultats montrent que les entités nommées accroissent les performances du systeme globalement puisque</context>
</contexts>
<marker>Allan, Carbonnel, Doddington, Yamron, Yang, 1998</marker>
<rawString>J. Allan, J. Carbonnel, G. Doddington, J. Yamron, and Y. Yang. Topic Detection and Tracking pilot study ﬁnal report. In Proc. of the DARPA Broadcast News Transcription and Understanding Workshop, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Boufaden</author>
<author>G Lapalme</author>
<author>Y Bengio</author>
</authors>
<title>Topic segmentation 2 A ﬁrst stage to dialog-based information extraction.</title>
<date>2001</date>
<booktitle>In Natural Language Processing Rim Symposium, NLPRS’0I,</booktitle>
<pages>273--280</pages>
<contexts>
<context position="2388" citStr="Boufaden et al., 2001" startWordPosition="308" endWordPosition="311">rsations (Figure 1) présentent plusieurs particularités compliquant l’eXtraction d’information notamment l’aspect collaboratif des conversations et la présence d’eXtra-grammaticalités. Ces deux caractéristiques font que (1) les éléments d’une réponse ne se trouvent pas nécessairement dans le meme énoncé et (2) il faut pouvoir reconstituer la réponse correcte a partir d’un segment dont la structure grammaticale est altérée par les extra-grammaticalités. Dans nos travaux antérieurs, nous soutenions que le découpage thématique peut faciliter l’eXtraction d’information a partir des conversations (Boufaden et al., 2001; Boufaden et al., 2002). Nous avons élaboré un systeme de découpage thématique qui détecte les changements de themes a partir de marques lexicales, syntaxiques, discursives et des interruptions. Dans notre premier systeme la marque discursive était ajouté manuellement ce qui ne permettait pas un découpage completement automatisé. Dans cet article, nous présentons, tout d’abord, les résultats de l’automatisation du calcul de la marque discursive. Ensuite, nous proposons l’utilisation des entités nommées comme source d’information additionnelle pour améliorer le découpage thématique. l C Mariti</context>
<context position="5118" citStr="Boufaden et al., 2001" startWordPosition="756" endWordPosition="759">es tels que ok, yeah, right. En fonction du role du locuteur dans le processus développemental du theme, ces réponses peuvent etre percues comme un incitateur a continuer le theme ou au contraire comme un inhibiteur dans le but d’interrompre le theme. En particulier (Maynard, 1980) parle de locuteur initiateur du theme topical speaker, comme étant le locuteur qui verbalise son intention communicative, par opposition au destinataire recipient qui va inciter a développer le theme ou au contraire changer de thene. Nous avons montré que cette information améliore les résultats de la segmentation (Boufaden et al., 2001). La marque extra-linguistique que nous utilisons est l’interruption transcrite dans les conversations par des points de suspension. Les statistiques faites sur notre corpus ont montré une corrélation entre les interruptions et les changements de themes. 2.1 Modéle de langue Dans (B oufaden et al., 2001), nous avons montré que le probleme de détection d’un changement de theme peut étre transposé en un probleme de classiﬁcation des énoncés. Nous émettions l’hypothese qu’entre chaque vecteur de marques se situe une frontiere qui permet de délimiter deux classes d’énoncé. Nous avons construit un </context>
<context position="7327" citStr="Boufaden et al., 2001" startWordPosition="1101" endWordPosition="1104">e 2 illustre notre modele de langue. Les valeurs représentées au dessus des arcs sont les probabilités P(q,~ |qj) de générer l’état q, sachant que l’on est dans l’état qj. 379 Nous avons montré que, parmi les combinaisons de marque possibles (lexicale-discursive, lexicalediscursive-syntaxique, lexicale-discursive-syntaxique-interruption) pour la segmentation, la meilleure performance était obtenue avec la combinaison de toutes les marques c’est-a-dire lexicale, syntaxique, discursive et interruption (modele SLDI) utilisée avec un modele de Markov caché d’ordre 1. Les résultats rapportés dans (Boufaden et al., 2001) étaient basés sur un corpus d’entrainement ou la marque discursive était ajoutée manuellement. Aﬁn de rendre le découpage completement automatisé, nous avons implémenté un modele de Markov d’ordre 1 qui permet la génération automatique du trait discursif. Ensuite, dans le but d’améliorer les résultats du systeme de découpage thématique, nous avons extrait automatiquement les entités nommées pour les utiliser comme une source d’information additionnelle. Dans ce qui suit, nous décrivons les résultats de ces deux expériences.Tous les résultats présentés ici sont obtenus par validation croisée e</context>
<context position="10043" citStr="Boufaden et al., 2001" startWordPosition="1517" endWordPosition="1520">intéressant d’observer que seules les marques lexicales et syntaxiques sufﬁsent a déterminer le role du locuteur dans le processus développemental. L’utilisation de la marque discursive générée automatiquement a diminué légerement les performances du systeme de découpage thématique. Le taux d’erreur moyen pondéré de découpage était de 16.5% avec la marque discursive ajoutée manuellement, tandis qu’avec celle calculée automatiquement il est de 18.5%. 2.3 Entités nommées source additionnelle d’information Le but de cette expérimentation est d’améliorer les performances du systeme présenté dans (Boufaden et al., 2001). Un des problemes soulignés dans (Boufaden et al., 2001) était le 380 manque de marques dans certains énoncés tels que ceux qui commence un nouveau theme ainsi que ceux débutant une conversation. Nous avons remarqué que 30.7% des énoncés classés BC et 46.8% des énoncés que nous avons classés TC dans le corpus d’entrainement contiennent uniquement la marque discursive. Par contre, nous avions aussi constaté la présence d’entités nommées dans ces memes énoncés. Lors d’un début de conversation les locuteurs se présentent et identiﬁent l’organisme auquel ils appartiennent, ce qui implique la prés</context>
</contexts>
<marker>Boufaden, Lapalme, Bengio, 2001</marker>
<rawString>N. Boufaden, G. Lapalme, and Y. Bengio. Topic segmentation 2 A ﬁrst stage to dialog-based information extraction. In Natural Language Processing Rim Symposium, NLPRS’0I, pages 273-280, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Boufaden</author>
<author>G Lapalme</author>
<author>Y Bengio</author>
</authors>
<title>Découpage thématique 2 un outil d’ aide a l’extraction d’information.</title>
<date>2002</date>
<booktitle>In TALN 2002,</booktitle>
<location>Nancy, France, Juin</location>
<contexts>
<context position="2412" citStr="Boufaden et al., 2002" startWordPosition="312" endWordPosition="315">sentent plusieurs particularités compliquant l’eXtraction d’information notamment l’aspect collaboratif des conversations et la présence d’eXtra-grammaticalités. Ces deux caractéristiques font que (1) les éléments d’une réponse ne se trouvent pas nécessairement dans le meme énoncé et (2) il faut pouvoir reconstituer la réponse correcte a partir d’un segment dont la structure grammaticale est altérée par les extra-grammaticalités. Dans nos travaux antérieurs, nous soutenions que le découpage thématique peut faciliter l’eXtraction d’information a partir des conversations (Boufaden et al., 2001; Boufaden et al., 2002). Nous avons élaboré un systeme de découpage thématique qui détecte les changements de themes a partir de marques lexicales, syntaxiques, discursives et des interruptions. Dans notre premier systeme la marque discursive était ajouté manuellement ce qui ne permettait pas un découpage completement automatisé. Dans cet article, nous présentons, tout d’abord, les résultats de l’automatisation du calcul de la marque discursive. Ensuite, nous proposons l’utilisation des entités nommées comme source d’information additionnelle pour améliorer le découpage thématique. l C Maritime operation centre, (IN</context>
</contexts>
<marker>Boufaden, Lapalme, Bengio, 2002</marker>
<rawString>N. Boufaden, G. Lapalme, and Y. Bengio. Découpage thématique 2 un outil d’ aide a l’extraction d’information. In TALN 2002, Nancy, France, Juin 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lafferty D Beeferman</author>
<author>A Berger</author>
</authors>
<title>Statistical models for text segmentation.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--1</pages>
<marker>Beeferman, Berger, 1999</marker>
<rawString>J . Lafferty D. Beeferman, A. Berger. Statistical models for text segmentation. Machine Learning, 34(1-3), Fevrier 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
<author>R Hassan</author>
</authors>
<title>Cohesion in English.</title>
<date>1976</date>
<publisher>Longman,</publisher>
<location>London,</location>
<marker>Halliday, Hassan, 1976</marker>
<rawString>M.A.K Halliday and R. Hassan. Cohesion in English. Longman, London, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J M Levelt</author>
</authors>
<title>Speaking From Intention to Articulation.</title>
<date>1989</date>
<booktitle>In Proc. ofACL’95,</booktitle>
<pages>108--115</pages>
<publisher>MIT Press,</publisher>
<marker>Levelt, 1989</marker>
<rawString>W.J.M. Levelt. Speaking From Intention to Articulation. MIT Press, 1989. D.J. Litman and R.J. Passonneau. Combining multiple knowledge sources for discourse segmentation. In Proc. ofACL’95, pages 108-115, 95. D.W. Maynard. Placement of topic changes in conversation. In Semiotica, Volume 30, pages 263-290.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mouton Publishers</author>
</authors>
<title>A simplest systematics for the organization of tum-taking.</title>
<date>1980</date>
<marker>Publishers, 1980</marker>
<rawString>Mouton Publishers, 1980. H. Sacks, E.A. Schegloff, and G. Jefferson. A simplest systematics for the organization of tum-taking.</rawString>
</citation>
<citation valid="true">
<authors>
<author>In Language</author>
</authors>
<date>1974</date>
<volume>50</volume>
<pages>696--735</pages>
<marker>Language, 1974</marker>
<rawString>In Language, Volume 50, pages 696-735. 1974.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>