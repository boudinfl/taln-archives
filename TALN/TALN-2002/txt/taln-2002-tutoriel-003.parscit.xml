<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Robert A Amsler</author>
</authors>
<date>1984</date>
<booktitle>Machine-Readable Dictionaries’, Annual Review of Information Science and Technology</booktitle>
<pages>19--161</pages>
<contexts>
<context position="9421" citStr="Amsler (1984)" startWordPosition="1539" endWordPosition="1540">ralverband zoologischer Fachgeschäfte &apos;central committee of zoological stores&apos;. 6 Such a distribution is called an LNRE distribution (for Large Number of Rare Events). See Baayen (2001) for statistical models and techniques in dealing with LNRE distributions. 63- Pius ten Hacken Kinds of new words Consider the hapax legomena (words occurring only once) in Table 1: some of them are names (Zywietz, Zyzik), some are regular words from a genre that is not typically covered in a newspaper (here biology: zytos, zytotoxisch) and some are compounds (ZZTop-Käfer-Nachbau). To illustrate the same point, Amsler (1984) carried out a comparison between the vocabulary found in a college dictionary (Webster’s 7th) and a text corpus (New York Times News Service) and noted that the overlap was only 23% of the total vocabulary in either source. Three quarters of the 41% which only occurred in the corpus could be accounted for in terms of inflection, hyphenation at the end of a line, proper nouns, and obvious misspellings. Assuming that inflection is accounted for by a rule system, hyphenation is covered in a trivial pre-processing step, and misspellings are treated separately, proper nouns constitute an important</context>
</contexts>
<marker>Amsler, 1984</marker>
<rawString>Amsler, Robert A. (1984), ‘Machine-Readable Dictionaries’, Annual Review of Information Science and Technology 19:161-209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen R Anderson</author>
</authors>
<title>A-Morphous Morphology, Cambridge:</title>
<date>1992</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="14358" citStr="Anderson (1992)" startWordPosition="2345" endWordPosition="2346">ic category Adjective and the meaning of an antonym of clear. The examples in (2) require additional rules to modify the stem. In (2a), stem vowel change is the only thing marking the difference between the two words. The alternative model is called Item &amp; Process (IP). In this model, word formation rules are processes applying to a base. In (1a), the process adds un to the left of the stem clear. In (2a), the process changes the stem vowel of sing. In IP there are no morphemes but only lexemes and processes. In modern morphological theories both are represented, e.g. Lieber (1992) for IA and Anderson (1992) for IP. An important difference for our purposes is that in IA we have a tree structure whereas in IP we have a derivation history. A tree structure represents the relationship between morphemes, e.g. (3). A derivation history lists the different stages rules applying, e.g. (4). It should be noted that there are many variants of IA and IP. (3) A Af A un clear (4) clear ⇒ Antonym formation ⇒ unclear Tree structures such as (3) are very convenient for the representation of concatenative processes, i.e. prefixation, suffixation, and compounding. Non-concatenative (aspects of) word formation rule</context>
<context position="25996" citStr="Anderson (1992)" startWordPosition="4220" endWordPosition="4221">ms look like inflected forms (the so-called paradigmic forms) it is sometimes argued that these are inflected forms in word formation. There are good arguments against this view: (a) there are many stems that do not change in word formation, (b) changed stems do not necessarily have the semantics of the corresponding plural form and unchanged stems do not necessarily have the semantics of the singular, and (c) there are also non-paradigmic forms. See the discussions in Fuhrhop (1998) and Eisenberg (1998). The existence of stem changes is often used as an argument against the IA model, e.g. by Anderson (1992). An analysis in terms of “stem formation” is elaborated by ten Hacken (1994). 68 Word Formation in Computational Linguistics Sproat (2000a) do not even mention inflection and word formation as terms, let alone make the conceptual distinction. The starting point of the approaches they describe is clearly inflection. As far as word formation phenomena are treated, e.g. Sproat (2000a:50), they are not considered from the perspective of the creation of new lexemes, but as examples of more difficult combinations of formatives. From a technical point of view, the domain of inflectional morphology i</context>
</contexts>
<marker>Anderson, 1992</marker>
<rawString>Anderson, Stephen R. (1992), A-Morphous Morphology, Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evan L Antworth</author>
</authors>
<title>PC-KIMMO: A Two-level Processor for Morphological Analysis,</title>
<date>1990</date>
<institution>Summer Institute of Linguistics.</institution>
<location>Dallas (Texas):</location>
<contexts>
<context position="28432" citStr="Antworth (1990)" startWordPosition="4591" endWordPosition="4592">ossible to know whether un- can be prefixed until we arrive at the suffix. • An important difference between inflection and derivation is the handling of information. In plural formation of nouns, e.g. readers, the feature plural is added to the lexeme reader. In the formation of reader from the verb read, however, the feature noun replaces the feature verb in the slot for syntactic category. Whereas readers is a plural noun, reader is not a noun-verb, but simply a noun. The last problem is not necessarily linked to finite-state approaches, but in two-level morphology, cf. Koskenniemi (1983), Antworth (1990), the way features are handled is specifically geared towards inflection. The first two problems are inherent in finite-state technology and can only be handled by one of the following strategies: • Giving up the finite-state constraint and using a more powerful rule type such as context-free rewrite rules. This implies a loss of computational efficiency, because context-free rules do not work in linear time. 10 An example of this type of work is Kiraz (2001). In Arabic a root such as ktb is combined with a vowel pattern to produce words such as kitaab (‘book’) and kutub (‘books’). It is inter</context>
</contexts>
<marker>Antworth, 1990</marker>
<rawString>Antworth, Evan L. (1990), PC-KIMMO: A Two-level Processor for Morphological Analysis, Dallas (Texas): Summer Institute of Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Aronoff</author>
<author>Fuhrhop</author>
</authors>
<title>Restricting suffix combinations in German and English: closing suffixes and the monosuffix constraint’, Natural Language and Linguistic Theory.</title>
<date>2001</date>
<location>Nanna</location>
<contexts>
<context position="40588" citStr="Aronoff &amp; Fuhrhop 2001" startWordPosition="6480" endWordPosition="6483"> the appropriate examples: stem Frau &apos;woman&apos; -keit (noun les- &apos;to read&apos; forming suffix) derivation stem fräu- - les forms frauderivation Fräulein &apos;Miss&apos; - lesbar examples fraulich &apos;feminine&apos; compounding frauen- keits lese stem forms compounding Frauenzeitung Sauberkeitsfimmel Leselampe examples &apos;women&apos;s &apos;cleanliness mania&apos; &apos;reading lamp&apos; newspaper&apos; Table 4: word formation stem forms for some morphological elements 73 Pius ten Hacken Here you can see that the suffix –keit has no derivation stem form. That means that it cannot be used in further derivation (it is a so-called closing suffix, see Aronoff &amp; Fuhrhop 2001). It has a compounding stem form, however. The word formation stem forms are propagated in complex words using these elements: each complex word ending in –keit, for example, will automatically have a compounding stem form ending in –keits.17 Such an approach minimized the ambiguities that stem changes can cause. However, one has to acquire all the word formation stem forms. For our lexicon this is done semi-automatically as described in Heid, Säuberlich &amp; Fitschen (2002). Analysis &amp; structure The word formation rules build on the information collected in the tables and lists as well as on the</context>
</contexts>
<marker>Aronoff, Fuhrhop, 2001</marker>
<rawString>Aronoff, Mark &amp; Fuhrhop, Nanna (2001), ‘Restricting suffix combinations in German and English: closing suffixes and the monosuffix constraint’, Natural Language and Linguistic Theory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark H Aronoff</author>
</authors>
<title>Morphology by Itself: Stems and Inflectional Classes,</title>
<date>1994</date>
<publisher>MIT Press.</publisher>
<location>Cambridge (Mass.):</location>
<contexts>
<context position="46973" citStr="Aronoff (1994)" startWordPosition="7511" endWordPosition="7512">uality of many of the intricate rule systems developed in computational linguistics could not be used in practice because they did not have a lexicon, cf. Ritchie (1987). The obvious solution was of course making lexical resources reusable. The originality of WM lies in its approach to reusability. Ten Hacken &amp; Domenig (1996) present this approach in terms of the diagram in Fig. 1. Text words 1 Lexeme 2 Readings Fig. 1: The bow-tie model adopted by WM. The central position in the bow-tie model is taken by the lexeme. The notion of lexeme in WM is similar to the one adopted by Matthews (1974), Aronoff (1994) and others. A lexeme is a word considered as an inflectional paradigm. Fig. 1 highlights two mappings involving the lexeme: 1. the mapping between the lexeme and a list of text words, i.e. forms as they appear between spaces and punctuation marks in a text; 2. the mapping between the lexeme and a list of readings, i.e. words with syntactic and semantic analysis as required by the theory and application of a system of computational linguistics. The independence of the two mappings is illustrated by classical cases of homonymy, e.g. bank. Depending on the type of application, different readings</context>
</contexts>
<marker>Aronoff, 1994</marker>
<rawString>Aronoff, Mark H. (1994), Morphology by Itself: Stems and Inflectional Classes, Cambridge (Mass.): MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harald Baayen</author>
<author>Lieber</author>
</authors>
<title>Productivity and English derivation: a corpus-based study’,</title>
<date>1991</date>
<journal>Linguistics</journal>
<pages>29--801</pages>
<location>Rochelle</location>
<contexts>
<context position="18787" citStr="Baayen &amp; Lieber 1991" startWordPosition="3068" endWordPosition="3071"> new words more readily than others – an intuition which cannot be formalized. In quantitative studies this intuition is approximated by the question: how probable is it that we will see a new type (lexeme) produced by word formation process X after we have sampled a certain amount of text? Quantitative studies of the productivity of word formation processes are important for the design of word formation systems if the resources are limited and one has to concentrate on the most productive word formation processes (on the quantitative aspects of productivity see for example Baayen 1992, 2000; Baayen &amp; Lieber 1991; Plag 1999; for a discussion of some corpus related problems in calculating productivity indices see Evert &amp; Lüdeling 2001). There are two descriptive aspects of word formation that we want to cover here in a little more detail because they are important for the description of the word formation systems DeKo and Word Manager below. We use mainly German examples here because both DeKo and Word Manager deal with German word formation. However, both issues are relevant for other languages as well. First we talk about possible 66 Word Formation in Computational Linguistics restrictions on word fo</context>
</contexts>
<marker>Baayen, Lieber, 1991</marker>
<rawString>Baayen, Harald &amp; Lieber, Rochelle (1991), ‘Productivity and English derivation: a corpus-based study’, Linguistics 29:801-843.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harald Baayen</author>
</authors>
<title>Quantitative aspects of morphological productivity’,</title>
<date>1992</date>
<booktitle>in Yearbook of Morphology</booktitle>
<contexts>
<context position="18759" citStr="Baayen 1992" startWordPosition="3065" endWordPosition="3066">les seem to produce new words more readily than others – an intuition which cannot be formalized. In quantitative studies this intuition is approximated by the question: how probable is it that we will see a new type (lexeme) produced by word formation process X after we have sampled a certain amount of text? Quantitative studies of the productivity of word formation processes are important for the design of word formation systems if the resources are limited and one has to concentrate on the most productive word formation processes (on the quantitative aspects of productivity see for example Baayen 1992, 2000; Baayen &amp; Lieber 1991; Plag 1999; for a discussion of some corpus related problems in calculating productivity indices see Evert &amp; Lüdeling 2001). There are two descriptive aspects of word formation that we want to cover here in a little more detail because they are important for the description of the word formation systems DeKo and Word Manager below. We use mainly German examples here because both DeKo and Word Manager deal with German word formation. However, both issues are relevant for other languages as well. First we talk about possible 66 Word Formation in Computational Linguis</context>
</contexts>
<marker>Baayen, 1992</marker>
<rawString>Baayen, Harald (1992), ‘Quantitative aspects of morphological productivity’, in Yearbook of Morphology 1991:109-149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harald Baayen</author>
</authors>
<title>Word Frequency Distributions,</title>
<date>2001</date>
<publisher>Kluwer.</publisher>
<location>Dordrecht:</location>
<contexts>
<context position="8746" citStr="Baayen (2001)" startWordPosition="1434" endWordPosition="1435">resting? Because it shows us that adding more text also adds more new words. Even if we produced a lexicon that contained the 715,972 lemmas from the Stuttgarter Zeitung, there would probably be new words in the newspaper issue of the next day. 4 This was noticed in the early 20th century by George Kingsley Zipf among others and led to the formulation of the so-called Zipf&apos;s law which states that the most frequent type occurs twice as often as the second frequent type and three times as often as the third frequent type etc. A short discussion of Zipf&apos;s law and similar formulas can be found in Baayen (2001) and in Manning &amp; Schütze (1999).. 5 Where ZZF stands for Zentralverband zoologischer Fachgeschäfte &apos;central committee of zoological stores&apos;. 6 Such a distribution is called an LNRE distribution (for Large Number of Rare Events). See Baayen (2001) for statistical models and techniques in dealing with LNRE distributions. 63- Pius ten Hacken Kinds of new words Consider the hapax legomena (words occurring only once) in Table 1: some of them are names (Zywietz, Zyzik), some are regular words from a genre that is not typically covered in a newspaper (here biology: zytos, zytotoxisch) and some are c</context>
</contexts>
<marker>Baayen, 2001</marker>
<rawString>Baayen, Harald (2001), Word Frequency Distributions, Dordrecht: Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurie Bauer</author>
</authors>
<title>Introducing Linguistic Morphology,</title>
<date>1988</date>
<publisher>Edinburgh University Press.</publisher>
<location>Edinburgh:</location>
<contexts>
<context position="12297" citStr="Bauer (1988)" startWordPosition="2002" endWordPosition="2003">. Basic word formation: elements and rules8 Morphology is traditionally divided into inflection and word formation. Intuitively, inflection is the formation of word forms of a lexeme for the appropriate syntactic 7 This is quite common: think for example of English song texts, film titles, advertisements or quotations in German or French newspaper text. 8 In this tutorial we do not have the space to explain word formation in a lot of detail. Therefore, many of the problematic (and interesting!) cases and issues cannot be touched upon. For more comprehensive introductions to word formation see Bauer (1988), Spencer (1991), Carstairs (1992). You can find introductions and overviews for a lot of issues in Spencer &amp; Zwicky (1998) and Booij, Lehmann &amp; Mugdan (2000). We also have to warn you that we need to gloss over a number of really problematic definitions. 64 Word Formation in Computational Linguistics environment (e.g. pushes for push, craignent for craindre) whereas word formation is the formation of new lexemes. Although this distinction is by no means uncontroversial and it is difficult to classify certain borderline cases (e.g. participles, the comparative and superlative of adjectives), w</context>
</contexts>
<marker>Bauer, 1988</marker>
<rawString>Bauer, Laurie (1988), Introducing Linguistic Morphology, Edinburgh: Edinburgh University Press.</rawString>
</citation>
<citation valid="true">
<title>22 Note that the server is case-sensitive and that the first two characters of “LIlab” are capitals, the rest of the url lower case. 83-Pius ten Hacken Bauer,</title>
<date>2001</date>
<publisher>Cambridge University Press.</publisher>
<location>Laurie</location>
<contexts>
<context position="8746" citStr="(2001)" startWordPosition="1435" endWordPosition="1435">? Because it shows us that adding more text also adds more new words. Even if we produced a lexicon that contained the 715,972 lemmas from the Stuttgarter Zeitung, there would probably be new words in the newspaper issue of the next day. 4 This was noticed in the early 20th century by George Kingsley Zipf among others and led to the formulation of the so-called Zipf&apos;s law which states that the most frequent type occurs twice as often as the second frequent type and three times as often as the third frequent type etc. A short discussion of Zipf&apos;s law and similar formulas can be found in Baayen (2001) and in Manning &amp; Schütze (1999).. 5 Where ZZF stands for Zentralverband zoologischer Fachgeschäfte &apos;central committee of zoological stores&apos;. 6 Such a distribution is called an LNRE distribution (for Large Number of Rare Events). See Baayen (2001) for statistical models and techniques in dealing with LNRE distributions. 63- Pius ten Hacken Kinds of new words Consider the hapax legomena (words occurring only once) in Table 1: some of them are names (Zywietz, Zyzik), some are regular words from a genre that is not typically covered in a newspaper (here biology: zytos, zytotoxisch) and some are c</context>
<context position="15836" citStr="(2001)" startWordPosition="2586" endWordPosition="2586">us word with a different syntactic category is created. This is frequent in English, where nouns can become verbs (e.g. house) or the reverse (e.g. break). Various solutions have been proposed in an IA perspective. In an IP perspective, these problems do not arise, because prefixation and suffixation are considered as special cases of a more general rule of the type “affect the form of the input in ... way and the meaning in ... way.” 65- Pius ten Hacken The reason we are interested in word formation rules is their productivity. Productivity is a difficult and controversial concept, cf. Bauer (2001). Basically, a productive word formation rule can be used to produce new lexical items. When a speaker has a productive word formation rule at her disposal, she can use a word not in her mental lexicon and be understood as far as other speakers have the same word formation rule available. The productivity of word formation makes it impossible to cover the entire lexicon in a finite list. Productivity is not quite the same as regularity. To the extent a word formation rule is regular, we can predict properties of the output on the basis of properties of the input. Regularity can be seen as a cl</context>
<context position="28895" citStr="(2001)" startWordPosition="4667" endWordPosition="4667">un. The last problem is not necessarily linked to finite-state approaches, but in two-level morphology, cf. Koskenniemi (1983), Antworth (1990), the way features are handled is specifically geared towards inflection. The first two problems are inherent in finite-state technology and can only be handled by one of the following strategies: • Giving up the finite-state constraint and using a more powerful rule type such as context-free rewrite rules. This implies a loss of computational efficiency, because context-free rules do not work in linear time. 10 An example of this type of work is Kiraz (2001). In Arabic a root such as ktb is combined with a vowel pattern to produce words such as kitaab (‘book’) and kutub (‘books’). It is interesting to note that the traditional approach to Arabic roots results in approximately 10,000 different items. This number corresponds more closely to the number of simple lexemes to be expected in the lexicon of a language than to the number of lexemes. It is then not surprising to find items such as kaatib (‘writer’), kutib (‘be written’) with the same root. 11 In principle we could of course reverse the entire system. Thus, languages such as Navajo, which u</context>
<context position="44282" citStr="(2001)" startWordPosition="7065" endWordPosition="7065">xicon, one could leave the decision to an automatic choice function (for example one that associates &apos;costs&apos; or probabilities with rules)18 or one could accept all legal analyses and let another component decide. We have chosen to combine the first and the last strategy, so that the application can either rely on manually corrected lexicon information alone or it can accept all legal analyses. Implementation DeKo is implemented as a series of finite-state transducers, using the FST-suite provided by AT&amp;T (Sproat 2000b). A more detailed description of the architecture is given in Schmid et al. (2001) and examples for the rule format are provided in Säuberlich (2001). We need to model three types of rules: • The sequential analysis into morphemes is done in a declarative grammar. For example, the adjective unregierbar &apos;ungovernable&apos; which has to be divided into the morphological elements un- + regier + -bar can be treated by the following grammar: START PREF un[adj.pref] + PREF STEM regier[verb] STEM SUFF + bar[suff][adj] where the parts in the square brackets provide the restrictions. Here we can formulate restrictions on all relevant linguistic levels as long as the information is presen</context>
<context position="62330" citStr="(2001)" startWordPosition="10014" endWordPosition="10014">the database in a particular way. Tools are very specific, for instance in the format of their output. An example of the implications of these differences can be taken from the use of word formation in WM in the context of Computer-Assisted Language Learning. Ten Hacken (1998) compares the treatment of word formation in WM with its treatment in learner’s dictionaries published as books and in a number of other electronic dictionaries which do not have a word formation component. The conclusion is that the WM treatment offers possibilities unknown in the other contexts. Ten Hacken &amp; Tschichold (2001) describe these possibilities more concretely, concentrating on the information available in the WM lexicon database and the browsers giving access to this information. Thus, it is immediately visible how many lexemes in the 200,000 entry database for German were formed by a particular process or set of processes, or which entries are derived from the noun kind (‘child’). The result of developing a number of dedicated lexical tools for CALL can be seen at http://www.canoo.net/. Here it is also possible, for instance, to have one’s text checked for one of the recognized style sheets implementin</context>
</contexts>
<marker>2001</marker>
<rawString>22 Note that the server is case-sensitive and that the first two characters of “LIlab” are capitals, the rest of the url lower case. 83-Pius ten Hacken Bauer, Laurie (2001), Morphological Productivity, Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geert Booij</author>
</authors>
<title>Inflection and Derivation’,</title>
<date>2000</date>
<pages>360--369</pages>
<editor>in Booij et al. (eds.),</editor>
<contexts>
<context position="13099" citStr="Booij (2000)" startWordPosition="2130" endWordPosition="2131">we need to gloss over a number of really problematic definitions. 64 Word Formation in Computational Linguistics environment (e.g. pushes for push, craignent for craindre) whereas word formation is the formation of new lexemes. Although this distinction is by no means uncontroversial and it is difficult to classify certain borderline cases (e.g. participles, the comparative and superlative of adjectives), we will assume here that it is possible to distinguish the two. An overview of the discussion is given in ten Hacken (1994), a brief summary from a somewhat different perspective is found in Booij (2000). Here we concentrate on word formation. There are different ways of conceiving the rules of word formation. Consider the processes in (1) and (2), corresponding between English (a) and French (b). (1) a. clear unclear b. fidèle infidèle (2) a. sing song b. fleur floral Hockett (1954) outlines two models of describing what we can observe in these examples. In the Item and Arrangement (IA) model, (1a) is the combination of a stem clear and a prefix un. This combination results in the concatenation of the two forms and the compositional combination of syntactic and semantic properties. In (1a) t</context>
</contexts>
<marker>Booij, 2000</marker>
<rawString>Booij, Geert (2000), ‘Inflection and Derivation’, in Booij et al. (eds.), 360-369.</rawString>
</citation>
<citation valid="false">
<booktitle>Ein Internationales Handbuch zur Flexion und Wortbildung – An International Handbook on Inflection and Word-Formation</booktitle>
<volume>1</volume>
<editor>Booij, Geert; Lehmann, Christian &amp; Mugdan, Joachim (eds.) (2000), Morphologie – Morphology:</editor>
<location>Berlin:</location>
<note>Walter de Gruyter.</note>
<marker></marker>
<rawString>Booij, Geert; Lehmann, Christian &amp; Mugdan, Joachim (eds.) (2000), Morphologie – Morphology: Ein Internationales Handbuch zur Flexion und Wortbildung – An International Handbook on Inflection and Word-Formation (Vol. 1), Berlin: Walter de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Bopp</author>
</authors>
<title>Computerimplementation der italienischen Flexions- und Wortbildungsmorphologie,</title>
<date>1993</date>
<location>Hildesheim: Olms.</location>
<contexts>
<context position="53502" citStr="Bopp (1993)" startWordPosition="8584" endWordPosition="8585">her parts, documentation was not extensively published. The mechanism for deriving finite-state tools from lexicon databases is described by Pedrazzini &amp; ten Hacken (1998) and Pedrazzini (1999). WM was conceived as a language-independent system. Although the formalism is very flexible, the system is not equally adapted to all languages. It works best with languages having a morphological system such as Germanic and Romance languages, with a moderate amount of inflection and non-concatenative processes. The first morphological rule database to be developed was the Italian database described by Bopp (1993). Other complete rule databases were developed for German and English. The German rule database uses PM for the analysis of separable verbs, such as aufhören in (5): (5) a. Anna glaubt, dass Bernard aufhört. (‘Anna believes that Bernard stops’) b. Claudia hört jetzt auf. (‘Claudia stops now PRT’) c. Daniel versucht aufzuhören. (‘Daniel tries to_stop’) As described by ten Hacken &amp; Bopp (1998), the interaction of inflection rules, word formation rules, clitic rules (for (5c)), and rules for multi-word units (for (5b)) makes it possible to analyse all occurrences of aufhören in (5) as instances o</context>
</contexts>
<marker>Bopp, 1993</marker>
<rawString>Bopp, Stephan (1993), Computerimplementation der italienischen Flexions- und Wortbildungsmorphologie, Hildesheim: Olms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew D Carstairs-McCarthy</author>
</authors>
<date>1992</date>
<location>Current Morphology, London: Routledge.</location>
<marker>Carstairs-McCarthy, 1992</marker>
<rawString>Carstairs-McCarthy, Andrew D. (1992), Current Morphology, London: Routledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Chandioux</author>
</authors>
<title>10 Ans de METEO’,</title>
<date>1989</date>
<booktitle>La Traduction Assistée par Ordinateur,</booktitle>
<pages>169--175</pages>
<editor>in Abbou, André (ed.),</editor>
<publisher>Daicadif,</publisher>
<location>Paris:</location>
<contexts>
<context position="2461" citStr="Chandioux (1989)" startWordPosition="363" endWordPosition="364">ch can, of course, work with a finite lexicon) and applications that deal with unseen text.1 These applications make use of basic components such as taggers, lemmatizers / stemmers, parsers etc. Often these components (and accordingly the application) – no matter 1 This distinction does not primarily depend on the application type (e.g. machine translation, text summarization), but rather on such factors as the context of use and the strategy chosen to solve the problem at hand. Thus a machine translation system for weather forecasts such as Météo (with its restrictions of use as described by Chandioux (1989)) has a closed set vocabulary. If the domain of a machine translation system is less restricted it is bound to be confronted with new, unseen words. In the case of text summarization, a different distinction can be made (cf. Endres-Niggemeyer (1998)). Here there is one strategy which basically consists of determining a set of key words and ranking sentences of the text to be summarized in terms of their use of key words and their position in the text. A summary is then compiled by putting together the highest-ranked sentences. In this strategy, a fairly small vocabulary is sufficient, because </context>
</contexts>
<marker>Chandioux, 1989</marker>
<rawString>Chandioux, John (1989), ‘10 Ans de METEO’, in Abbou, André (ed.), La Traduction Assistée par Ordinateur, Paris: Daicadif, p. 169-175.</rawString>
</citation>
<citation valid="true">
<date>1997</date>
<booktitle>Survey of the State of the Art in Human Language Technology,</booktitle>
<editor>Cole, Ronald; Mariani, Joseph; Uszkoreit, Hans; Varile, Giovanni Battista; Zaenen, Annie; Zampolli, Antonio &amp; Zue, Victor (eds.)</editor>
<publisher>Cambridge University Press &amp; Pisa: Giardini.</publisher>
<location>Cambridge:</location>
<contexts>
<context position="25279" citStr="(1997)" startWordPosition="4102" endWordPosition="4102">ation systems Compared to the treatment of morphology in linguistic theory, the treatment in computational linguistics is marked by two features: • Word formation is usually not a separate issue. It is integrated with inflectional morphology or ignored altogether. • Morphological components are generally based on written text. Even in systems with spoken input or output, the morphological component works on an orthographic transcription. The marginal position of word formation is illustrated by the treatment in general surveys of computational linguistics. Surveys such as Karlsson &amp; Karttunen (1997) and 9 Stem changes have been analysed in a number of different ways in the literature. Since many forms look like inflected forms (the so-called paradigmic forms) it is sometimes argued that these are inflected forms in word formation. There are good arguments against this view: (a) there are many stems that do not change in word formation, (b) changed stems do not necessarily have the semantics of the corresponding plural form and unchanged stems do not necessarily have the semantics of the singular, and (c) there are also non-paradigmic forms. See the discussions in Fuhrhop (1998) and Eisen</context>
</contexts>
<marker>1997</marker>
<rawString>Cole, Ronald; Mariani, Joseph; Uszkoreit, Hans; Varile, Giovanni Battista; Zaenen, Annie; Zampolli, Antonio &amp; Zue, Victor (eds.) (1997), Survey of the State of the Art in Human Language Technology, Cambridge: Cambridge University Press &amp; Pisa: Giardini.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danielle Corbin</author>
</authors>
<title>Morphologie dérivationelle et structuration du lexique,</title>
<date>1987</date>
<journal>Niemeyer</journal>
<booktitle>Handbook of Natural Language Processing,</booktitle>
<volume>2</volume>
<editor>vol.). Dale, Robert; Moisl, Hermann &amp; Somers, Harold (eds.)</editor>
<publisher>Dekker.</publisher>
<location>Tübingen:</location>
<contexts>
<context position="17052" citStr="Corbin (1987)" startWordPosition="2793" endWordPosition="2794"> with a gradual transition from fully regular to completely irregular. Some interesting points on this cline are: • semi-regularity, in which the output can be related to the output, but not predicted by it, e.g. abbreviations and clippings; • a higher degree of regularity in which the form and meaning of the output can be predicted from the input, but not the application of the WFR, e.g. unclear, but not *undeep; • full regularity, in which also the existence of the output can be predicted, e.g. -ing-forms of English verbs. The relationship between productivity and regularity is discussed by Corbin (1987). In a computational context, the regularity of a word formation rule is what makes it possible to describe it in the form of a procedure which can be used to recognize new words. The productivity of word formation rules is, of course, responsible for many of the unknown words found in unseen text, as described in the previous section. Recall the examples: quite a few of the hapax legomena were compounds (ZZ-Top-Hit), compounding is a very productive process in German (and English), therefore we expect many of the unknown words to be productively formed compounds. There are two approaches to a</context>
</contexts>
<marker>Corbin, 1987</marker>
<rawString>Corbin, Danielle (1987), Morphologie dérivationelle et structuration du lexique, Tübingen: Niemeyer (2 vol.). Dale, Robert; Moisl, Hermann &amp; Somers, Harold (eds.) (2000), Handbook of Natural Language Processing, New York: Dekker.</rawString>
</citation>
<citation valid="true">
<title>Deutsche Wortbildung 1: Kühnhold, Ingeburg &amp; Wellmann,</title>
<date>1973</date>
<booktitle>Deutsche Wortbildung: Typen und Tendenzen in der Gegenwartssprache 1: Das Verb,</booktitle>
<publisher>Schwann.</publisher>
<location>Hans</location>
<marker>1973</marker>
<rawString>Deutsche Wortbildung 1: Kühnhold, Ingeburg &amp; Wellmann, Hans (1973), Deutsche Wortbildung: Typen und Tendenzen in der Gegenwartssprache 1: Das Verb, Düsseldorf: Schwann.</rawString>
</citation>
<citation valid="true">
<title>Deutsche Wortbildung 2: Wellmann, Hans</title>
<date>1975</date>
<publisher>Schwann.</publisher>
<location>Düsseldorf:</location>
<marker>1975</marker>
<rawString>Deutsche Wortbildung 2: Wellmann, Hans (1975), Deutsche Wortbildung: Typen und Tendenzen in der Gegenwartssprache 2: Das Substantiv, Düsseldorf: Schwann.</rawString>
</citation>
<citation valid="true">
<title>Deutsche Wortbildung 3: Kühnhold, Ingeburg; Putzer, Oskar &amp; Wellmann,</title>
<date>1978</date>
<booktitle>Deutsche Wortbildung: Typen und Tendenzen in der Gegenwartssprache 3: Das Adjektiv,</booktitle>
<publisher>Schwann.</publisher>
<location>Hans</location>
<marker>1978</marker>
<rawString>Deutsche Wortbildung 3: Kühnhold, Ingeburg; Putzer, Oskar &amp; Wellmann, Hans (1978), Deutsche Wortbildung: Typen und Tendenzen in der Gegenwartssprache 3: Das Adjektiv, Düsseldorf: Schwann.</rawString>
</citation>
<citation valid="true">
<title>Deutsche Wortbildung 4: Ortner, Lorelies; Bollhagen-Müller,</title>
<date>1991</date>
<booktitle>Deutsche Wortbildung: Typen und Tendenzen in der Gegenwartssprache 4: Substantivkomposita,</booktitle>
<location>Elgin; Ortner, Hanspeter; Wellmann, Hans; Pümpel-Mader, Maria &amp; Gärtner, Hildegard</location>
<note>de Gruyter.</note>
<contexts>
<context position="12313" citStr="(1991)" startWordPosition="2005" endWordPosition="2005">: elements and rules8 Morphology is traditionally divided into inflection and word formation. Intuitively, inflection is the formation of word forms of a lexeme for the appropriate syntactic 7 This is quite common: think for example of English song texts, film titles, advertisements or quotations in German or French newspaper text. 8 In this tutorial we do not have the space to explain word formation in a lot of detail. Therefore, many of the problematic (and interesting!) cases and issues cannot be touched upon. For more comprehensive introductions to word formation see Bauer (1988), Spencer (1991), Carstairs (1992). You can find introductions and overviews for a lot of issues in Spencer &amp; Zwicky (1998) and Booij, Lehmann &amp; Mugdan (2000). We also have to warn you that we need to gloss over a number of really problematic definitions. 64 Word Formation in Computational Linguistics environment (e.g. pushes for push, craignent for craindre) whereas word formation is the formation of new lexemes. Although this distinction is by no means uncontroversial and it is difficult to classify certain borderline cases (e.g. participles, the comparative and superlative of adjectives), we will assume he</context>
</contexts>
<marker>1991</marker>
<rawString>Deutsche Wortbildung 4: Ortner, Lorelies; Bollhagen-Müller, Elgin; Ortner, Hanspeter; Wellmann, Hans; Pümpel-Mader, Maria &amp; Gärtner, Hildegard (1991), Deutsche Wortbildung: Typen und Tendenzen in der Gegenwartssprache 4: Substantivkomposita, Berlin: de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Pümpel-Mader</author>
<author>Elsbeth Gassner-Koch</author>
<author>Wellmann</author>
</authors>
<date>1992</date>
<booktitle>Deutsche Wortbildung: Typen und Tendenzen in der Gegenwartssprache 5: Adjektivkomposita und Partizipialbildungen,</booktitle>
<location>Hans</location>
<note>de Gruyter.</note>
<marker>Pümpel-Mader, Gassner-Koch, Wellmann, 1992</marker>
<rawString>Deutsche Wortbildung 5: Pümpel-Mader, Maria; Gassner-Koch, Elsbeth &amp; Wellmann, Hans (1992), Deutsche Wortbildung: Typen und Tendenzen in der Gegenwartssprache 5: Adjektivkomposita und Partizipialbildungen, Berlin: de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Domenig</author>
</authors>
<title>Word Manager: A system for the Specification, Use, and Maintenance of Morphological Knowledge,</title>
<date>1989</date>
<location>Habilitationsschrift, Universität Zürich.</location>
<contexts>
<context position="51013" citStr="Domenig (1989)" startWordPosition="8193" endWordPosition="8194">overage are particularly striking in the domain of word formation, for which a system taking a lexicon as modelled in Fig. 2B as a basis lacks the procedural component. Thus a formalism such as DATR, as described by Evans &amp; Gazdar (1996), though able to represent word formation relationships, cannot deal with unseen words without a separate recognition module. In WM, word formation rules are at the same time available declaratively, as the structural backbone of the database, and procedurally for the recognition of new words. History WM is a long-term, open-ended project which originated with Domenig (1989). Subsequently it was developed at Universities in Basel, Amsterdam (Vrije Universiteit), and Lugano (SUPSI and USI), funded in part by the Swiss federal government and by private companies. 77- lexicon Pius ten Hacken In order to describe the history of the development of WM, the best starting point is the development stages leading to a directly applicable component which can be integrated in a real-life environment. There are three main stages involved: 1. The morphological system of a language (inflection and word formation) is described in terms of the WM formalism. The result of this lin</context>
</contexts>
<marker>Domenig, 1989</marker>
<rawString>Domenig, Marc (1989), Word Manager: A system for the Specification, Use, and Maintenance of Morphological Knowledge, Habilitationsschrift, Universität Zürich.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Domenig</author>
<author>ten Hacken</author>
</authors>
<title>Word Manager: A System for Morphological Dictionaries,</title>
<date>1992</date>
<location>Pius</location>
<marker>Domenig, Hacken, 1992</marker>
<rawString>Domenig, Marc &amp; ten Hacken, Pius (1992), Word Manager: A System for Morphological Dictionaries, Hildesheim: Olms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Eisenberg</author>
</authors>
<title>Grundriss der deutschen Grammatik. Band 1: Das Wort,</title>
<date>1998</date>
<location>Stuttgart: Metzler.</location>
<contexts>
<context position="25890" citStr="Eisenberg (1998)" startWordPosition="4201" endWordPosition="4202">1997) and 9 Stem changes have been analysed in a number of different ways in the literature. Since many forms look like inflected forms (the so-called paradigmic forms) it is sometimes argued that these are inflected forms in word formation. There are good arguments against this view: (a) there are many stems that do not change in word formation, (b) changed stems do not necessarily have the semantics of the corresponding plural form and unchanged stems do not necessarily have the semantics of the singular, and (c) there are also non-paradigmic forms. See the discussions in Fuhrhop (1998) and Eisenberg (1998). The existence of stem changes is often used as an argument against the IA model, e.g. by Anderson (1992). An analysis in terms of “stem formation” is elaborated by ten Hacken (1994). 68 Word Formation in Computational Linguistics Sproat (2000a) do not even mention inflection and word formation as terms, let alone make the conceptual distinction. The starting point of the approaches they describe is clearly inflection. As far as word formation phenomena are treated, e.g. Sproat (2000a:50), they are not considered from the perspective of the creation of new lexemes, but as examples of more dif</context>
<context position="39557" citStr="Eisenberg (1998)" startWordPosition="6321" endWordPosition="6322">&lt;n&gt; in Anzeigenadel could, for example, belong to Nadel &apos;pin&apos; or it could be a linking element for Anzeige &apos;advertisement, display&apos;; the compound could then either be Anzeige+Nadel &apos;display needle&apos; (as in a speedometer or a scale) or Anzeigen+Adel &apos;advertisement nobility&apos;. The latter reading is improbable but word formation systems do not normally contain a semantic component. And it is, of course, not an illegal or impossible reading. In an Item and Process approach stem changes are dealt with via rules. Since stem changes in German are not regular or predictable we follow Fuhrhop (1998) and Eisenberg (1998) on listing the forms that an element may take. These forms are called word formation stem forms. Free and bound morphological elements have one or more derivation stem form(s) and one or more compounding stem form(s). Very often these stem forms look just like the regular stem. Consider the examples in Table 4 where we have listed the word formation stem forms of some morphological elements together with the appropriate examples: stem Frau &apos;woman&apos; -keit (noun les- &apos;to read&apos; forming suffix) derivation stem fräu- - les forms frauderivation Fräulein &apos;Miss&apos; - lesbar examples fraulich &apos;feminine&apos; c</context>
</contexts>
<marker>Eisenberg, 1998</marker>
<rawString>Eisenberg, Peter (1998), Grundriss der deutschen Grammatik. Band 1: Das Wort, Stuttgart: Metzler.</rawString>
</citation>
<citation valid="true">
<title>Word Formation in Computational Linguistics Endres-Niggemeyer,</title>
<date>1998</date>
<publisher>Springer.</publisher>
<location>Brigitte</location>
<contexts>
<context position="2710" citStr="(1998)" startWordPosition="405" endWordPosition="405">tter 1 This distinction does not primarily depend on the application type (e.g. machine translation, text summarization), but rather on such factors as the context of use and the strategy chosen to solve the problem at hand. Thus a machine translation system for weather forecasts such as Météo (with its restrictions of use as described by Chandioux (1989)) has a closed set vocabulary. If the domain of a machine translation system is less restricted it is bound to be confronted with new, unseen words. In the case of text summarization, a different distinction can be made (cf. Endres-Niggemeyer (1998)). Here there is one strategy which basically consists of determining a set of key words and ranking sentences of the text to be summarized in terms of their use of key words and their position in the text. A summary is then compiled by putting together the highest-ranked sentences. In this strategy, a fairly small vocabulary is sufficient, because no attempt to arrive at a full-scale analysis of the text is undertaken. Unseen words occur frequently, but are ignored. Of course a more sophisticated strategy which assumes a stage at which the structure and meaning of the text is represented as a</context>
<context position="12420" citStr="(1998)" startWordPosition="2023" endWordPosition="2023">inflection is the formation of word forms of a lexeme for the appropriate syntactic 7 This is quite common: think for example of English song texts, film titles, advertisements or quotations in German or French newspaper text. 8 In this tutorial we do not have the space to explain word formation in a lot of detail. Therefore, many of the problematic (and interesting!) cases and issues cannot be touched upon. For more comprehensive introductions to word formation see Bauer (1988), Spencer (1991), Carstairs (1992). You can find introductions and overviews for a lot of issues in Spencer &amp; Zwicky (1998) and Booij, Lehmann &amp; Mugdan (2000). We also have to warn you that we need to gloss over a number of really problematic definitions. 64 Word Formation in Computational Linguistics environment (e.g. pushes for push, craignent for craindre) whereas word formation is the formation of new lexemes. Although this distinction is by no means uncontroversial and it is difficult to classify certain borderline cases (e.g. participles, the comparative and superlative of adjectives), we will assume here that it is possible to distinguish the two. An overview of the discussion is given in ten Hacken (1994),</context>
<context position="25869" citStr="(1998)" startWordPosition="4199" endWordPosition="4199">Karttunen (1997) and 9 Stem changes have been analysed in a number of different ways in the literature. Since many forms look like inflected forms (the so-called paradigmic forms) it is sometimes argued that these are inflected forms in word formation. There are good arguments against this view: (a) there are many stems that do not change in word formation, (b) changed stems do not necessarily have the semantics of the corresponding plural form and unchanged stems do not necessarily have the semantics of the singular, and (c) there are also non-paradigmic forms. See the discussions in Fuhrhop (1998) and Eisenberg (1998). The existence of stem changes is often used as an argument against the IA model, e.g. by Anderson (1992). An analysis in terms of “stem formation” is elaborated by ten Hacken (1994). 68 Word Formation in Computational Linguistics Sproat (2000a) do not even mention inflection and word formation as terms, let alone make the conceptual distinction. The starting point of the approaches they describe is clearly inflection. As far as word formation phenomena are treated, e.g. Sproat (2000a:50), they are not considered from the perspective of the creation of new lexemes, but as</context>
<context position="39536" citStr="(1998)" startWordPosition="6319" endWordPosition="6319">icult. The &lt;n&gt; in Anzeigenadel could, for example, belong to Nadel &apos;pin&apos; or it could be a linking element for Anzeige &apos;advertisement, display&apos;; the compound could then either be Anzeige+Nadel &apos;display needle&apos; (as in a speedometer or a scale) or Anzeigen+Adel &apos;advertisement nobility&apos;. The latter reading is improbable but word formation systems do not normally contain a semantic component. And it is, of course, not an illegal or impossible reading. In an Item and Process approach stem changes are dealt with via rules. Since stem changes in German are not regular or predictable we follow Fuhrhop (1998) and Eisenberg (1998) on listing the forms that an element may take. These forms are called word formation stem forms. Free and bound morphological elements have one or more derivation stem form(s) and one or more compounding stem form(s). Very often these stem forms look just like the regular stem. Consider the examples in Table 4 where we have listed the word formation stem forms of some morphological elements together with the appropriate examples: stem Frau &apos;woman&apos; -keit (noun les- &apos;to read&apos; forming suffix) derivation stem fräu- - les forms frauderivation Fräulein &apos;Miss&apos; - lesbar examples </context>
<context position="50376" citStr="(1998)" startWordPosition="8092" endWordPosition="8092"> readings should be covered in a different component. The two perspectives can be represented as in Fig. 2: A B C 1 2 3 4 morphologicaldictionary Fig. 2: Coverage of WM resources (C) as opposed to more traditional lexicons (B). Somewhat simplified, the areas in Fig. 2A can be characterized as follows: 1. syntactic and semantic lexical knowledge, 2. syntactic and semantic rule knowledge, 3. morphological lexical knowledge, and 4. morphological rule knowledge. The combination of lexical knowledge and rule knowledge enables WM to function as a full morphological component. As shown by ten Hacken (1998), the effects of this coverage are particularly striking in the domain of word formation, for which a system taking a lexicon as modelled in Fig. 2B as a basis lacks the procedural component. Thus a formalism such as DATR, as described by Evans &amp; Gazdar (1996), though able to represent word formation relationships, cannot deal with unseen words without a separate recognition module. In WM, word formation rules are at the same time available declaratively, as the structural backbone of the database, and procedurally for the recognition of new words. History WM is a long-term, open-ended project</context>
<context position="53062" citStr="(1998)" startWordPosition="8520" endWordPosition="8520">of clitics and multi-word units, Phrase Manager (PM), is described in Pedrazzini (1994). A module for the use of word formation rules as a basis for the semi-automatic classification of new entries is described by Hsiung (1995). This module proposes a number of analyses for a new word on the basis of word formation rules and existing lexemes and formatives. Holz (1995) developed an interface for the specification of entries. For other parts, documentation was not extensively published. The mechanism for deriving finite-state tools from lexicon databases is described by Pedrazzini &amp; ten Hacken (1998) and Pedrazzini (1999). WM was conceived as a language-independent system. Although the formalism is very flexible, the system is not equally adapted to all languages. It works best with languages having a morphological system such as Germanic and Romance languages, with a moderate amount of inflection and non-concatenative processes. The first morphological rule database to be developed was the Italian database described by Bopp (1993). Other complete rule databases were developed for German and English. The German rule database uses PM for the analysis of separable verbs, such as aufhören in</context>
<context position="57414" citStr="(1998)" startWordPosition="9212" endWordPosition="9212">ions). They are important for the treatment of certain word formation processes, e.g. German separable verbs as illustrated in (5) and English multi-word compounds such as fire brigade. The latter type does not add anything conceptually relevant apart from the fact that it is possible to treat fire brigade as a morphological formation on a par with girlfriend. Separable verbs constitute a rather complex phenomenon in a text-based system because of the interplay between one-word and multi-word forms of the same lexeme. The treatment of the phenomenon is explained in detail in ten Hacken &amp; Bopp (1998). 20 The selection of the suffix is restricted by the position of the rule in the word formation tree. For details cf. Domenig &amp; ten Hacken (1992). 79- Pius ten Hacken target by marking the relevant feature in the source. Thus for the verbal prefix ri-, corresponding to English re-, the inflection class of the base is passed on to the target. In this way the verb riandare (‘go again’) is inflected in the same, highly irregular way as andare (’go’). The differences between IRules and WFRules express the differences between inflection and word formation as they are analysed in WM. Whereas inflec</context>
<context position="62001" citStr="(1998)" startWordPosition="9962" endWordPosition="9962">e derived from the database for any platform desired. • The lexicon database contains all the information about inflection and word formation rules and relationships for a language. It is an object-oriented database with high flexibility. A lexical tool is dedicated to a particular task, using a selection of the information in the database in a particular way. Tools are very specific, for instance in the format of their output. An example of the implications of these differences can be taken from the use of word formation in WM in the context of Computer-Assisted Language Learning. Ten Hacken (1998) compares the treatment of word formation in WM with its treatment in learner’s dictionaries published as books and in a number of other electronic dictionaries which do not have a word formation component. The conclusion is that the WM treatment offers possibilities unknown in the other contexts. Ten Hacken &amp; Tschichold (2001) describe these possibilities more concretely, concentrating on the information available in the WM lexicon database and the browsers giving access to this information. Thus, it is immediately visible how many lexemes in the 200,000 entry database for German were formed </context>
<context position="63797" citStr="(1998)" startWordPosition="10246" endWordPosition="10246">n a terminological database, cf. Zappatore &amp; ten Hacken (2000). Here the WFRules are used not only as a structuring device of the terminological lexicon, but also as a way for recognizing terms when they are ‘hidden’ in nominalizations, compounds, etc. Thus, Verwaltungsrat (‘board of directors’) is also recognized in Verwaltungsratsvakanz (‘vacancy in the board of directors’). One of the reasons why WM is particularly suited to this task in a multilingual system (German, English, Italian) is that it can treat singleword and multi-word terms equally. As a final example, Pedrazzini &amp; ten Hacken (1998) describe the prototype of a “generative spellchecker”. In particular in German, where compounds are written as one word, spellcheckers regularly fail on words such as Nordostgrenze (‘north-eastern border’) because they are not in the dictionary. The generative spellchecker recognizes these words as possible words. Depending on the elaboration of the prototype they may be proposed as a list to be checked for spelling errors21 or for enlarging the lexicon database. Applied to a German corpus of newspaper text with a 100,000 entry lexicon, 7% of the words in the corpus were recognized with the g</context>
</contexts>
<marker>1998</marker>
<rawString>Word Formation in Computational Linguistics Endres-Niggemeyer, Brigitte (1998), Summarizing Information, Berlin: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Evans</author>
<author>Gerald Gazdar</author>
</authors>
<title>DATR: A Language for Lexical Knowledge Representation’,</title>
<date>1996</date>
<journal>Computational Linguistics</journal>
<pages>22--167</pages>
<contexts>
<context position="50636" citStr="Evans &amp; Gazdar (1996)" startWordPosition="8135" endWordPosition="8138">ed, the areas in Fig. 2A can be characterized as follows: 1. syntactic and semantic lexical knowledge, 2. syntactic and semantic rule knowledge, 3. morphological lexical knowledge, and 4. morphological rule knowledge. The combination of lexical knowledge and rule knowledge enables WM to function as a full morphological component. As shown by ten Hacken (1998), the effects of this coverage are particularly striking in the domain of word formation, for which a system taking a lexicon as modelled in Fig. 2B as a basis lacks the procedural component. Thus a formalism such as DATR, as described by Evans &amp; Gazdar (1996), though able to represent word formation relationships, cannot deal with unseen words without a separate recognition module. In WM, word formation rules are at the same time available declaratively, as the structural backbone of the database, and procedurally for the recognition of new words. History WM is a long-term, open-ended project which originated with Domenig (1989). Subsequently it was developed at Universities in Basel, Amsterdam (Vrije Universiteit), and Lugano (SUPSI and USI), funded in part by the Swiss federal government and by private companies. 77- lexicon Pius ten Hacken In o</context>
</contexts>
<marker>Evans, Gazdar, 1996</marker>
<rawString>Evans, Roger &amp; Gazdar, Gerald (1996), ‘DATR: A Language for Lexical Knowledge Representation’, Computational Linguistics 22:167-216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
<author>Lüdeling</author>
</authors>
<title>Measuring morphological productivity: Is automatic preprocessing sufficient?’,</title>
<date>2001</date>
<booktitle>Proceedings of Corpus Linguistics 2001,</booktitle>
<location>Anke</location>
<contexts>
<context position="18911" citStr="Evert &amp; Lüdeling 2001" startWordPosition="3087" endWordPosition="3090">pproximated by the question: how probable is it that we will see a new type (lexeme) produced by word formation process X after we have sampled a certain amount of text? Quantitative studies of the productivity of word formation processes are important for the design of word formation systems if the resources are limited and one has to concentrate on the most productive word formation processes (on the quantitative aspects of productivity see for example Baayen 1992, 2000; Baayen &amp; Lieber 1991; Plag 1999; for a discussion of some corpus related problems in calculating productivity indices see Evert &amp; Lüdeling 2001). There are two descriptive aspects of word formation that we want to cover here in a little more detail because they are important for the description of the word formation systems DeKo and Word Manager below. We use mainly German examples here because both DeKo and Word Manager deal with German word formation. However, both issues are relevant for other languages as well. First we talk about possible 66 Word Formation in Computational Linguistics restrictions on word formation rules and second we describe some of the stem changes that occur in word formation. Word formation rules can be rest</context>
</contexts>
<marker>Evert, Lüdeling, 2001</marker>
<rawString>Evert, Stefan &amp; Lüdeling, Anke (2001), ‘Measuring morphological productivity: Is automatic preprocessing sufficient?’, Proceedings of Corpus Linguistics 2001, Lancaster.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Fleischer</author>
<author>Barz</author>
</authors>
<title>Wortbildung der deutschen Gegenwartsprache,</title>
<date>1992</date>
<location>Irmhild</location>
<contexts>
<context position="19720" citStr="Fleischer &amp; Barz (1992)" startWordPosition="3220" endWordPosition="3223"> and Word Manager below. We use mainly German examples here because both DeKo and Word Manager deal with German word formation. However, both issues are relevant for other languages as well. First we talk about possible 66 Word Formation in Computational Linguistics restrictions on word formation rules and second we describe some of the stem changes that occur in word formation. Word formation rules can be restricted on all linguistic levels (for examples you can refer to any good descriptive work on word formation in the language you are studying; in German descriptive overviews are given in Fleischer &amp; Barz (1992) and in Deutsche Wortbildung 1-5; in addition there are numerous studies on individual affixes). The following constraints all refer to productive rules; each affix has also formed lexicalized words which have to be memorized. • syntax: Most (if not all) affixes attach only to stems of a certain part-of-speech. The German adjective-forming suffix –bar attaches only to transitive verbs: essen &apos;to eat&apos; – essbar &apos;edible&apos;. It corresponds to English and French –able. The English noun forming suffix –ness attaches only to adjectives etc. • semantics: Some affixes attach only to stems with a certain </context>
</contexts>
<marker>Fleischer, Barz, 1992</marker>
<rawString>Fleischer, Wolfgang &amp; Barz, Irmhild (1992), Wortbildung der deutschen Gegenwartsprache, Tübingen: Niemeyer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nanna Fuhrhop</author>
</authors>
<date>1998</date>
<booktitle>Grenzfälle morphologischer Einheiten,</booktitle>
<location>Tübingen: Stauffenberg.</location>
<contexts>
<context position="25869" citStr="Fuhrhop (1998)" startWordPosition="4198" endWordPosition="4199">lsson &amp; Karttunen (1997) and 9 Stem changes have been analysed in a number of different ways in the literature. Since many forms look like inflected forms (the so-called paradigmic forms) it is sometimes argued that these are inflected forms in word formation. There are good arguments against this view: (a) there are many stems that do not change in word formation, (b) changed stems do not necessarily have the semantics of the corresponding plural form and unchanged stems do not necessarily have the semantics of the singular, and (c) there are also non-paradigmic forms. See the discussions in Fuhrhop (1998) and Eisenberg (1998). The existence of stem changes is often used as an argument against the IA model, e.g. by Anderson (1992). An analysis in terms of “stem formation” is elaborated by ten Hacken (1994). 68 Word Formation in Computational Linguistics Sproat (2000a) do not even mention inflection and word formation as terms, let alone make the conceptual distinction. The starting point of the approaches they describe is clearly inflection. As far as word formation phenomena are treated, e.g. Sproat (2000a:50), they are not considered from the perspective of the creation of new lexemes, but as</context>
<context position="39536" citStr="Fuhrhop (1998)" startWordPosition="6318" endWordPosition="6319">ore difficult. The &lt;n&gt; in Anzeigenadel could, for example, belong to Nadel &apos;pin&apos; or it could be a linking element for Anzeige &apos;advertisement, display&apos;; the compound could then either be Anzeige+Nadel &apos;display needle&apos; (as in a speedometer or a scale) or Anzeigen+Adel &apos;advertisement nobility&apos;. The latter reading is improbable but word formation systems do not normally contain a semantic component. And it is, of course, not an illegal or impossible reading. In an Item and Process approach stem changes are dealt with via rules. Since stem changes in German are not regular or predictable we follow Fuhrhop (1998) and Eisenberg (1998) on listing the forms that an element may take. These forms are called word formation stem forms. Free and bound morphological elements have one or more derivation stem form(s) and one or more compounding stem form(s). Very often these stem forms look just like the regular stem. Consider the examples in Table 4 where we have listed the word formation stem forms of some morphological elements together with the appropriate examples: stem Frau &apos;woman&apos; -keit (noun les- &apos;to read&apos; forming suffix) derivation stem fräu- - les forms frauderivation Fräulein &apos;Miss&apos; - lesbar examples </context>
</contexts>
<marker>Fuhrhop, 1998</marker>
<rawString>Fuhrhop, Nanna (1998), Grenzfälle morphologischer Einheiten, Tübingen: Stauffenberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ten Hacken</author>
</authors>
<title>Defining Morphology: A Principled Approach to Determining the Boundaries of Compounding, Derivation, and Inflection,</title>
<date>1994</date>
<location>Pius</location>
<contexts>
<context position="13019" citStr="Hacken (1994)" startWordPosition="2117" endWordPosition="2118"> Zwicky (1998) and Booij, Lehmann &amp; Mugdan (2000). We also have to warn you that we need to gloss over a number of really problematic definitions. 64 Word Formation in Computational Linguistics environment (e.g. pushes for push, craignent for craindre) whereas word formation is the formation of new lexemes. Although this distinction is by no means uncontroversial and it is difficult to classify certain borderline cases (e.g. participles, the comparative and superlative of adjectives), we will assume here that it is possible to distinguish the two. An overview of the discussion is given in ten Hacken (1994), a brief summary from a somewhat different perspective is found in Booij (2000). Here we concentrate on word formation. There are different ways of conceiving the rules of word formation. Consider the processes in (1) and (2), corresponding between English (a) and French (b). (1) a. clear unclear b. fidèle infidèle (2) a. sing song b. fleur floral Hockett (1954) outlines two models of describing what we can observe in these examples. In the Item and Arrangement (IA) model, (1a) is the combination of a stem clear and a prefix un. This combination results in the concatenation of the two forms a</context>
<context position="26073" citStr="Hacken (1994)" startWordPosition="4233" endWordPosition="4234">rgued that these are inflected forms in word formation. There are good arguments against this view: (a) there are many stems that do not change in word formation, (b) changed stems do not necessarily have the semantics of the corresponding plural form and unchanged stems do not necessarily have the semantics of the singular, and (c) there are also non-paradigmic forms. See the discussions in Fuhrhop (1998) and Eisenberg (1998). The existence of stem changes is often used as an argument against the IA model, e.g. by Anderson (1992). An analysis in terms of “stem formation” is elaborated by ten Hacken (1994). 68 Word Formation in Computational Linguistics Sproat (2000a) do not even mention inflection and word formation as terms, let alone make the conceptual distinction. The starting point of the approaches they describe is clearly inflection. As far as word formation phenomena are treated, e.g. Sproat (2000a:50), they are not considered from the perspective of the creation of new lexemes, but as examples of more difficult combinations of formatives. From a technical point of view, the domain of inflectional morphology is a rather well-explored area, in which most efforts are devoted to developme</context>
</contexts>
<marker>Hacken, 1994</marker>
<rawString>ten Hacken, Pius (1994), Defining Morphology: A Principled Approach to Determining the Boundaries of Compounding, Derivation, and Inflection, Hildesheim: Olms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ten Hacken</author>
<author>Pius</author>
<author>Marc Domenig</author>
</authors>
<title>Reusable Dictionaries for NLP: The Word Manager Approach’,</title>
<date>1996</date>
<journal>Lexicology</journal>
<pages>2--232</pages>
<marker>Hacken, Pius, Domenig, 1996</marker>
<rawString>ten Hacken, Pius &amp; Domenig, Marc (1996), ‘Reusable Dictionaries for NLP: The Word Manager Approach’, Lexicology 2:232-255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ten Hacken</author>
</authors>
<date>1998</date>
<booktitle>Word Formation in Electronic Dictionaries’, Dictionaries</booktitle>
<pages>19--158</pages>
<location>Pius</location>
<contexts>
<context position="50376" citStr="Hacken (1998)" startWordPosition="8091" endWordPosition="8092">mes and readings should be covered in a different component. The two perspectives can be represented as in Fig. 2: A B C 1 2 3 4 morphologicaldictionary Fig. 2: Coverage of WM resources (C) as opposed to more traditional lexicons (B). Somewhat simplified, the areas in Fig. 2A can be characterized as follows: 1. syntactic and semantic lexical knowledge, 2. syntactic and semantic rule knowledge, 3. morphological lexical knowledge, and 4. morphological rule knowledge. The combination of lexical knowledge and rule knowledge enables WM to function as a full morphological component. As shown by ten Hacken (1998), the effects of this coverage are particularly striking in the domain of word formation, for which a system taking a lexicon as modelled in Fig. 2B as a basis lacks the procedural component. Thus a formalism such as DATR, as described by Evans &amp; Gazdar (1996), though able to represent word formation relationships, cannot deal with unseen words without a separate recognition module. In WM, word formation rules are at the same time available declaratively, as the structural backbone of the database, and procedurally for the recognition of new words. History WM is a long-term, open-ended project</context>
<context position="53062" citStr="Hacken (1998)" startWordPosition="8519" endWordPosition="8520">atment of clitics and multi-word units, Phrase Manager (PM), is described in Pedrazzini (1994). A module for the use of word formation rules as a basis for the semi-automatic classification of new entries is described by Hsiung (1995). This module proposes a number of analyses for a new word on the basis of word formation rules and existing lexemes and formatives. Holz (1995) developed an interface for the specification of entries. For other parts, documentation was not extensively published. The mechanism for deriving finite-state tools from lexicon databases is described by Pedrazzini &amp; ten Hacken (1998) and Pedrazzini (1999). WM was conceived as a language-independent system. Although the formalism is very flexible, the system is not equally adapted to all languages. It works best with languages having a morphological system such as Germanic and Romance languages, with a moderate amount of inflection and non-concatenative processes. The first morphological rule database to be developed was the Italian database described by Bopp (1993). Other complete rule databases were developed for German and English. The German rule database uses PM for the analysis of separable verbs, such as aufhören in</context>
<context position="62001" citStr="Hacken (1998)" startWordPosition="9961" endWordPosition="9962">y can be derived from the database for any platform desired. • The lexicon database contains all the information about inflection and word formation rules and relationships for a language. It is an object-oriented database with high flexibility. A lexical tool is dedicated to a particular task, using a selection of the information in the database in a particular way. Tools are very specific, for instance in the format of their output. An example of the implications of these differences can be taken from the use of word formation in WM in the context of Computer-Assisted Language Learning. Ten Hacken (1998) compares the treatment of word formation in WM with its treatment in learner’s dictionaries published as books and in a number of other electronic dictionaries which do not have a word formation component. The conclusion is that the WM treatment offers possibilities unknown in the other contexts. Ten Hacken &amp; Tschichold (2001) describe these possibilities more concretely, concentrating on the information available in the WM lexicon database and the browsers giving access to this information. Thus, it is immediately visible how many lexemes in the 200,000 entry database for German were formed </context>
<context position="63797" citStr="Hacken (1998)" startWordPosition="10245" endWordPosition="10246">entry in a terminological database, cf. Zappatore &amp; ten Hacken (2000). Here the WFRules are used not only as a structuring device of the terminological lexicon, but also as a way for recognizing terms when they are ‘hidden’ in nominalizations, compounds, etc. Thus, Verwaltungsrat (‘board of directors’) is also recognized in Verwaltungsratsvakanz (‘vacancy in the board of directors’). One of the reasons why WM is particularly suited to this task in a multilingual system (German, English, Italian) is that it can treat singleword and multi-word terms equally. As a final example, Pedrazzini &amp; ten Hacken (1998) describe the prototype of a “generative spellchecker”. In particular in German, where compounds are written as one word, spellcheckers regularly fail on words such as Nordostgrenze (‘north-eastern border’) because they are not in the dictionary. The generative spellchecker recognizes these words as possible words. Depending on the elaboration of the prototype they may be proposed as a list to be checked for spelling errors21 or for enlarging the lexicon database. Applied to a German corpus of newspaper text with a 100,000 entry lexicon, 7% of the words in the corpus were recognized with the g</context>
</contexts>
<marker>Hacken, 1998</marker>
<rawString>ten Hacken, Pius (1998), ‘Word Formation in Electronic Dictionaries’, Dictionaries 19:158-187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ten Hacken</author>
<author>Pius</author>
<author>Stephan Bopp</author>
</authors>
<title>Separable Verbs in a Morphological Dictionary for German’,</title>
<date>1998</date>
<booktitle>in Coling - ACL ’98: Proceedings of the Conference, Université de Montréal,</booktitle>
<pages>471--475</pages>
<marker>Hacken, Pius, Bopp, 1998</marker>
<rawString>ten Hacken, Pius &amp; Bopp, Stephan (1998), ‘Separable Verbs in a Morphological Dictionary for German’, in Coling - ACL ’98: Proceedings of the Conference, Université de Montréal, p. 471-475.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ten Hacken</author>
</authors>
<title>Two Perspectives on the Reusability of Lexical Resources’, McGill Working Papers in Linguistics 14:39-49.</title>
<date>1999</date>
<location>Pius</location>
<contexts>
<context position="49205" citStr="Hacken (1999)" startWordPosition="7905" endWordPosition="7906"> or as the third person singular of nuire (‘damage’), but the operation is a matter of classification only. Case 2 concerns unseen words analysed by word formation. Cases 3 and 4 involve operations on the string of text words preceding the classification process. An example of case 3 is a-t-il analysed as the third person singular of avoir followed by the personal pronoun il. Case 76 Word Formation in Computational Linguistics 4 applies to multi-word units in the orthographic sense. This includes a considerable part of word formation, for instance most English compounds, cf. fire brigade. Ten Hacken (1999) describes the opposition between the coverage of the lexical component in the standard approach and in WM in terms of two orthogonal dichotomies: • The standard approach distinguishes the lexicon from the grammar, such that information about individual entries is in the lexicon whereas rules are in the grammar. • The WM approach distinguishes between the two mappings in the bow-tie model, such that information for the mapping between text words and lexemes (both rules and entries) is in the WM database, whereas information for the mapping between lexemes and readings should be covered in a di</context>
</contexts>
<marker>Hacken, 1999</marker>
<rawString>ten Hacken, Pius (1999), ‘Two Perspectives on the Reusability of Lexical Resources’, McGill Working Papers in Linguistics 14:39-49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ten Hacken</author>
<author>Pius</author>
<author>Tschichold</author>
</authors>
<title>Word Manager and CALL: Structured access to the lexicon as a tool for enriching learners’ vocabulary’,</title>
<date>2001</date>
<journal>ReCALL</journal>
<volume>13</volume>
<pages>121--131</pages>
<location>Cornelia</location>
<marker>Hacken, Pius, Tschichold, 2001</marker>
<rawString>ten Hacken, Pius &amp; Tschichold, Cornelia (2001), ‘Word Manager and CALL: Structured access to the lexicon as a tool for enriching learners’ vocabulary’, ReCALL 13: 121-131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ten Hacken</author>
</authors>
<title>Word Formation and the Validation of Lexical Resources’, to appear in the proceedings of LREC</title>
<date>2002</date>
<booktitle>Language Resources &amp; Evaluation Conference, Las Palmas, 27 May - 2</booktitle>
<location>Pius</location>
<contexts>
<context position="54701" citStr="Hacken (2002)" startWordPosition="8772" endWordPosition="8773">as instances of the same lexeme. For English, Tschichold (2000) describes the rules for the analysis of multi-word units more generally. The first lexicon database to be developed was for German. It has now reached a size of 200,000 lexemes. The development of English and Italian lexicon databases was 78 Word Formation in Computational Linguistics undertaken in a parallel effort, funded by the Swiss National Science Foundation. The parallelism entails that the same lexicographic guidelines are used for both languages. Word formation plays a central role in the development, as discussed by ten Hacken (2002) and ten Hacken &amp; Smyk (2002). Linguistic Approach The basic entity in a WM database is the formative. A formative is a combination of a string and a set of features. There are three types of rule for manipulating formatives: IRules, WFRules, and SRules.19 IRules and WFRules combine formatives in slightly different ways. SRules change the form of formatives. In an IRule, a set of stems and a set of affixes are combined to produce the inflectional paradigms for the lexemes with the stems as their base. The combination of formatives in an IRule leads to the concatenation of the forms and the com</context>
</contexts>
<marker>Hacken, 2002</marker>
<rawString>ten Hacken, Pius (2002), ‘Word Formation and the Validation of Lexical Resources’, to appear in the proceedings of LREC 2002 - Language Resources &amp; Evaluation Conference, Las Palmas, 27 May - 2 June 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ten Hacken</author>
<author>Pius</author>
<author>Smyk</author>
</authors>
<title>Word Formation versus Etymology</title>
<date>2002</date>
<booktitle>in Electronic Dictionaries’, to appear in the proceedings of Euralex 2002,</booktitle>
<location>Dorota</location>
<marker>Hacken, Pius, Smyk, 2002</marker>
<rawString>ten Hacken, Pius &amp; Smyk, Dorota (2002), ‘Word Formation versus Etymology in Electronic Dictionaries’, to appear in the proceedings of Euralex 2002, København, 13-17 August 2002.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ulrich Heid</author>
</authors>
<title>DeKo: Derivations- und Kompositionsmorphologie, Zwischenbericht, Technical report IMS, University of Stuttgart, available at http://www.ims.uni-stuttgart.de/projekte/DeKo/ Heid, Uli; Säuberlich, Bettina &amp; Fitschen,</title>
<date>2001</date>
<booktitle>in Proceedings of the Third International Conference on Language Resources and Engineering (LREC),</booktitle>
<location>Arne</location>
<contexts>
<context position="31837" citStr="Heid 2001" startWordPosition="5156" endWordPosition="5157">ormation restricting the application of word formation rules. This will be illustrated in the discussion of two systems, DeKo and Word Manager. DeKo DeKo (for Derivation and Komposition, funded by the state of Baden-Württemberg from Jan 2000 – June 2001) is designed as a German word formation component in a larger computational linguistic application.13 It was done on a much smaller scale than Word Manager and is not used in any commercial products. In this tutorial we focus on some basic design features – especially where they differ from Word Manager&apos;s features. More details can be found in Heid 2001, Schmid et al. 2001 and at http://www.ims.uni-stuttgart.de/projekte/DeKo/. Here we want to concentrate on the corpus-based acquisition of data, the item-and-arrangement design, analysis and structure, and the interaction between DeKo and the lexicon. Although the DeKo project proper is finished, work is still being done to improve the program and especially to extend the lexicon. Acquisition of data As indicated above, word formation can be restricted on all linguistic levels. DeKo is designed so that it can, in principle, use all this information in its rules in order to minimize ambiguities</context>
</contexts>
<marker>Heid, 2001</marker>
<rawString>Heid, Ulrich (2001), DeKo: Derivations- und Kompositionsmorphologie, Zwischenbericht, Technical report IMS, University of Stuttgart, available at http://www.ims.uni-stuttgart.de/projekte/DeKo/ Heid, Uli; Säuberlich, Bettina &amp; Fitschen, Arne (2002), ‘Using descriptive generalizations in the Acquisition of lexical data for a word formation analyzer’, in Proceedings of the Third International Conference on Language Resources and Engineering (LREC), Las Palmas, Gran Canaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles F Hockett</author>
</authors>
<title>Two Models of Grammatical Description’,</title>
<date>1954</date>
<pages>10--210</pages>
<location>Word</location>
<contexts>
<context position="13384" citStr="Hockett (1954)" startWordPosition="2177" endWordPosition="2178">l and it is difficult to classify certain borderline cases (e.g. participles, the comparative and superlative of adjectives), we will assume here that it is possible to distinguish the two. An overview of the discussion is given in ten Hacken (1994), a brief summary from a somewhat different perspective is found in Booij (2000). Here we concentrate on word formation. There are different ways of conceiving the rules of word formation. Consider the processes in (1) and (2), corresponding between English (a) and French (b). (1) a. clear unclear b. fidèle infidèle (2) a. sing song b. fleur floral Hockett (1954) outlines two models of describing what we can observe in these examples. In the Item and Arrangement (IA) model, (1a) is the combination of a stem clear and a prefix un. This combination results in the concatenation of the two forms and the compositional combination of syntactic and semantic properties. In (1a) the result is a form unclear with the syntactic category Adjective and the meaning of an antonym of clear. The examples in (2) require additional rules to modify the stem. In (2a), stem vowel change is the only thing marking the difference between the two words. The alternative model i</context>
</contexts>
<marker>Hockett, 1954</marker>
<rawString>Hockett, Charles F. (1954), ‘Two Models of Grammatical Description’, Word 10:210-231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dieter Holz</author>
</authors>
<title>Über das Entwerfen von Gebrauchssoftware: Lehren aus dem Entwurfsprozeß einer Arbeitsumgebung für einen Lexikographen, unpublished Ph.D. Dissertation, Universität Basel. 85-Pius ten Hacken Hsiung,</title>
<date>1995</date>
<location>Alain</location>
<contexts>
<context position="52827" citStr="Holz (1995)" startWordPosition="8486" endWordPosition="8487">mbined was implemented and tested. The formalism is described in Domenig &amp; ten Hacken (1992). This core WM system served as a basis for a number of Ph.D. dissertations in which further components were added. The extension for the treatment of clitics and multi-word units, Phrase Manager (PM), is described in Pedrazzini (1994). A module for the use of word formation rules as a basis for the semi-automatic classification of new entries is described by Hsiung (1995). This module proposes a number of analyses for a new word on the basis of word formation rules and existing lexemes and formatives. Holz (1995) developed an interface for the specification of entries. For other parts, documentation was not extensively published. The mechanism for deriving finite-state tools from lexicon databases is described by Pedrazzini &amp; ten Hacken (1998) and Pedrazzini (1999). WM was conceived as a language-independent system. Although the formalism is very flexible, the system is not equally adapted to all languages. It works best with languages having a morphological system such as Germanic and Romance languages, with a moderate amount of inflection and non-concatenative processes. The first morphological rule</context>
</contexts>
<marker>Holz, 1995</marker>
<rawString>Holz, Dieter (1995), Über das Entwerfen von Gebrauchssoftware: Lehren aus dem Entwurfsprozeß einer Arbeitsumgebung für einen Lexikographen, unpublished Ph.D. Dissertation, Universität Basel. 85-Pius ten Hacken Hsiung, Alain (1995), Lexicon Acquisition through High-Level Rule Compilation, Hildesheim: Olms.</rawString>
</citation>
<citation valid="true">
<date>1997</date>
<booktitle>Sub-Sentential Processing’, in Cole</booktitle>
<pages>96--100</pages>
<editor>Karlsson, Fred &amp; Karttunen,</editor>
<location>Lauri</location>
<contexts>
<context position="25279" citStr="(1997)" startWordPosition="4102" endWordPosition="4102">ation systems Compared to the treatment of morphology in linguistic theory, the treatment in computational linguistics is marked by two features: • Word formation is usually not a separate issue. It is integrated with inflectional morphology or ignored altogether. • Morphological components are generally based on written text. Even in systems with spoken input or output, the morphological component works on an orthographic transcription. The marginal position of word formation is illustrated by the treatment in general surveys of computational linguistics. Surveys such as Karlsson &amp; Karttunen (1997) and 9 Stem changes have been analysed in a number of different ways in the literature. Since many forms look like inflected forms (the so-called paradigmic forms) it is sometimes argued that these are inflected forms in word formation. There are good arguments against this view: (a) there are many stems that do not change in word formation, (b) changed stems do not necessarily have the semantics of the corresponding plural form and unchanged stems do not necessarily have the semantics of the singular, and (c) there are also non-paradigmic forms. See the discussions in Fuhrhop (1998) and Eisen</context>
</contexts>
<marker>1997</marker>
<rawString>Karlsson, Fred &amp; Karttunen, Lauri (1997), ‘Sub-Sentential Processing’, in Cole et al. (eds.), p. 96-100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Kiraz</author>
</authors>
<title>Computational Nonlinear Morphology With Emphasis on Semitic Languages, Cambridge:</title>
<date>2001</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="28895" citStr="Kiraz (2001)" startWordPosition="4666" endWordPosition="4667">y a noun. The last problem is not necessarily linked to finite-state approaches, but in two-level morphology, cf. Koskenniemi (1983), Antworth (1990), the way features are handled is specifically geared towards inflection. The first two problems are inherent in finite-state technology and can only be handled by one of the following strategies: • Giving up the finite-state constraint and using a more powerful rule type such as context-free rewrite rules. This implies a loss of computational efficiency, because context-free rules do not work in linear time. 10 An example of this type of work is Kiraz (2001). In Arabic a root such as ktb is combined with a vowel pattern to produce words such as kitaab (‘book’) and kutub (‘books’). It is interesting to note that the traditional approach to Arabic roots results in approximately 10,000 different items. This number corresponds more closely to the number of simple lexemes to be expected in the lexicon of a language than to the number of lexemes. It is then not surprising to find items such as kaatib (‘writer’), kutib (‘be written’) with the same root. 11 In principle we could of course reverse the entire system. Thus, languages such as Navajo, which u</context>
</contexts>
<marker>Kiraz, 2001</marker>
<rawString>Kiraz, George A. (2001), Computational Nonlinear Morphology With Emphasis on Semitic Languages, Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kimmo Koskenniemi</author>
</authors>
<title>Two-Level Morphology: A General Computational Model for Word-Form Recognition and Production,</title>
<date>1983</date>
<volume>11</volume>
<institution>University of Helsinki, Department of General Linguistics Publications No.</institution>
<contexts>
<context position="28415" citStr="Koskenniemi (1983)" startWordPosition="4589" endWordPosition="4590"> Therefore it is impossible to know whether un- can be prefixed until we arrive at the suffix. • An important difference between inflection and derivation is the handling of information. In plural formation of nouns, e.g. readers, the feature plural is added to the lexeme reader. In the formation of reader from the verb read, however, the feature noun replaces the feature verb in the slot for syntactic category. Whereas readers is a plural noun, reader is not a noun-verb, but simply a noun. The last problem is not necessarily linked to finite-state approaches, but in two-level morphology, cf. Koskenniemi (1983), Antworth (1990), the way features are handled is specifically geared towards inflection. The first two problems are inherent in finite-state technology and can only be handled by one of the following strategies: • Giving up the finite-state constraint and using a more powerful rule type such as context-free rewrite rules. This implies a loss of computational efficiency, because context-free rules do not work in linear time. 10 An example of this type of work is Kiraz (2001). In Arabic a root such as ktb is combined with a vowel pattern to produce words such as kitaab (‘book’) and kutub (‘boo</context>
</contexts>
<marker>Koskenniemi, 1983</marker>
<rawString>Koskenniemi, Kimmo (1983), Two-Level Morphology: A General Computational Model for Word-Form Recognition and Production, University of Helsinki, Department of General Linguistics Publications No. 11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rochelle Lieber</author>
</authors>
<title>Deconstructing Morphology: Word Formation in Syntactic Theory,</title>
<date>1992</date>
<publisher>University of Chicago Press.</publisher>
<location>Chicago:</location>
<contexts>
<context position="14331" citStr="Lieber (1992)" startWordPosition="2340" endWordPosition="2341"> unclear with the syntactic category Adjective and the meaning of an antonym of clear. The examples in (2) require additional rules to modify the stem. In (2a), stem vowel change is the only thing marking the difference between the two words. The alternative model is called Item &amp; Process (IP). In this model, word formation rules are processes applying to a base. In (1a), the process adds un to the left of the stem clear. In (2a), the process changes the stem vowel of sing. In IP there are no morphemes but only lexemes and processes. In modern morphological theories both are represented, e.g. Lieber (1992) for IA and Anderson (1992) for IP. An important difference for our purposes is that in IA we have a tree structure whereas in IP we have a derivation history. A tree structure represents the relationship between morphemes, e.g. (3). A derivation history lists the different stages rules applying, e.g. (4). It should be noted that there are many variants of IA and IP. (3) A Af A un clear (4) clear ⇒ Antonym formation ⇒ unclear Tree structures such as (3) are very convenient for the representation of concatenative processes, i.e. prefixation, suffixation, and compounding. Non-concatenative (aspe</context>
</contexts>
<marker>Lieber, 1992</marker>
<rawString>Lieber, Rochelle (1992), Deconstructing Morphology: Word Formation in Syntactic Theory, Chicago: University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anke Lüdeling</author>
<author>Arne Fitschen</author>
</authors>
<title>An integrated lexicon for the analysis of complex words’ to appear in</title>
<date>2002</date>
<booktitle>Proceedings of EURALEX 2002,</booktitle>
<location>Copenhagen.</location>
<contexts>
<context position="24196" citStr="Lüdeling &amp; Fitschen 2002" startWordPosition="3938" endWordPosition="3941">guage&apos;. Such changes in the form of the base in a word formation process are also widespread in other languages. We have seen examples from French and English in (2) above. What is important to note here is that these stem changes are not always fully regular or predictable. That is, even phonologically and semantically very similar words do not always have the same changed stems in word formation. Bund &apos;union&apos; and Grund &apos;basis&apos; which belong to the same inflectional class, for example, look different in compounds, compare Grundgesetz &apos;constitution&apos; and Bundesgesetz &apos;federal law&apos; (example from Lüdeling &amp; Fitschen 2002). Or consider Frau which is Fräu in Fräulein but Frau in fraulich &apos;feminine&apos; while the compound Jungfrau &apos;virgin&apos; is umlauted when it attaches to –lich: jungfräulich. Some stems have different forms, for example Schwein &apos;pig&apos; can be found as Schweine in Schweinebraten &apos;pork roast&apos;, as Schweins in Schweinsauge &apos;pig&apos;s eye&apos;. This makes it very difficult to treat this phenomenon automatically. As you see below, DeKo and Word Manager approach stem changes differently. Word formation systems Compared to the treatment of morphology in linguistic theory, the treatment in computational linguistics is m</context>
<context position="42060" citStr="Lüdeling &amp; Fitschen 2002" startWordPosition="6717" endWordPosition="6720"> projects for German that we are aware of does this). Hierarchical structure can add a lot of information to the morpheme analysis – it is especially important because it features in pronunciation rules (TTS system), but it is also useful in information retrieval. Interaction between DeKo and the lexicon The DeKo rules can only work if they can refer to detailed information on lexical items – therefore the DeKo team and other researchers at the IMS in Stuttgart developed a highly flexible lexicon concept where different kinds of information are stored together with morphological elements (see Lüdeling &amp; Fitschen 2002 for more details). At the moment the relevant information is still being collected and encoded into the IMSLex. Therefore, the DeKo rules as they stand now are much less specific than they should be. The following analysis for the noun Abörtchen &apos;little toilet&apos; which should have been analysed as Abort+-chen can be prevented if the noun prefix a- has the restriction that it only combines with neoclassical elements and if all elements in the lexicon are marked by origin. Abörtchen {{A[npref][++]Borte[nomen][sg][fem][stem]}[pref_derivat][++]chen[suff][ nomen][pl][neut][stem]}[suff_derivat] Very </context>
</contexts>
<marker>Lüdeling, Fitschen, 2002</marker>
<rawString>Lüdeling, Anke &amp; Fitschen, Arne (2002), ‘An integrated lexicon for the analysis of complex words’ to appear in Proceedings of EURALEX 2002, Copenhagen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anke Lüdeling</author>
<author>Tanja Schmid</author>
<author>Kiokpasoglou</author>
</authors>
<date>2002</date>
<location>Sawwas</location>
<note>On neoclassical word formation in German’, to appear in Yearbook of Morphology</note>
<marker>Lüdeling, Schmid, Kiokpasoglou, 2002</marker>
<rawString>Lüdeling, Anke; Schmid, Tanja &amp; Kiokpasoglou, Sawwas (2002), ‘On neoclassical word formation in German’, to appear in Yearbook of Morphology 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Manning</author>
<author>Schütze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing,</booktitle>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="8778" citStr="Manning &amp; Schütze (1999)" startWordPosition="1438" endWordPosition="1441">hows us that adding more text also adds more new words. Even if we produced a lexicon that contained the 715,972 lemmas from the Stuttgarter Zeitung, there would probably be new words in the newspaper issue of the next day. 4 This was noticed in the early 20th century by George Kingsley Zipf among others and led to the formulation of the so-called Zipf&apos;s law which states that the most frequent type occurs twice as often as the second frequent type and three times as often as the third frequent type etc. A short discussion of Zipf&apos;s law and similar formulas can be found in Baayen (2001) and in Manning &amp; Schütze (1999).. 5 Where ZZF stands for Zentralverband zoologischer Fachgeschäfte &apos;central committee of zoological stores&apos;. 6 Such a distribution is called an LNRE distribution (for Large Number of Rare Events). See Baayen (2001) for statistical models and techniques in dealing with LNRE distributions. 63- Pius ten Hacken Kinds of new words Consider the hapax legomena (words occurring only once) in Table 1: some of them are names (Zywietz, Zyzik), some are regular words from a genre that is not typically covered in a newspaper (here biology: zytos, zytotoxisch) and some are compounds (ZZTop-Käfer-Nachbau). </context>
</contexts>
<marker>Manning, Schütze, 1999</marker>
<rawString>Manning, Christopher &amp; Schütze, Hinrich (1999), Foundations of Statistical Natural Language Processing, Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter H Matthews</author>
</authors>
<title>Morphology: An Introduction to the Theory of Word Structure, Cambridge:</title>
<date>1974</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="46957" citStr="Matthews (1974)" startWordPosition="7509" endWordPosition="7510">alized that the quality of many of the intricate rule systems developed in computational linguistics could not be used in practice because they did not have a lexicon, cf. Ritchie (1987). The obvious solution was of course making lexical resources reusable. The originality of WM lies in its approach to reusability. Ten Hacken &amp; Domenig (1996) present this approach in terms of the diagram in Fig. 1. Text words 1 Lexeme 2 Readings Fig. 1: The bow-tie model adopted by WM. The central position in the bow-tie model is taken by the lexeme. The notion of lexeme in WM is similar to the one adopted by Matthews (1974), Aronoff (1994) and others. A lexeme is a word considered as an inflectional paradigm. Fig. 1 highlights two mappings involving the lexeme: 1. the mapping between the lexeme and a list of text words, i.e. forms as they appear between spaces and punctuation marks in a text; 2. the mapping between the lexeme and a list of readings, i.e. words with syntactic and semantic analysis as required by the theory and application of a system of computational linguistics. The independence of the two mappings is illustrated by classical cases of homonymy, e.g. bank. Depending on the type of application, di</context>
</contexts>
<marker>Matthews, 1974</marker>
<rawString>Matthews, Peter H. (1974), Morphology: An Introduction to the Theory of Word Structure, Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandro Pedrazzini</author>
</authors>
<title>Phrase Manager: A system for Phrasal and Idiomatic Dictionaries,</title>
<date>1994</date>
<location>Hildesheim: Olms.</location>
<contexts>
<context position="52543" citStr="Pedrazzini (1994)" startWordPosition="8437" endWordPosition="8438">con database. The result is a small, efficient module performing a specific task independently of the lexicon database. At the start of the project, the computational environment was developed. First the formalism and compiler for the mappings in which text words need not be split up or combined was implemented and tested. The formalism is described in Domenig &amp; ten Hacken (1992). This core WM system served as a basis for a number of Ph.D. dissertations in which further components were added. The extension for the treatment of clitics and multi-word units, Phrase Manager (PM), is described in Pedrazzini (1994). A module for the use of word formation rules as a basis for the semi-automatic classification of new entries is described by Hsiung (1995). This module proposes a number of analyses for a new word on the basis of word formation rules and existing lexemes and formatives. Holz (1995) developed an interface for the specification of entries. For other parts, documentation was not extensively published. The mechanism for deriving finite-state tools from lexicon databases is described by Pedrazzini &amp; ten Hacken (1998) and Pedrazzini (1999). WM was conceived as a language-independent system. Althou</context>
</contexts>
<marker>Pedrazzini, 1994</marker>
<rawString>Pedrazzini, Sandro (1994), Phrase Manager: A system for Phrasal and Idiomatic Dictionaries, Hildesheim: Olms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandro Pedrazzini</author>
<author>ten Hacken</author>
</authors>
<title>Centralized Lexeme Management and Distributed Dictionary Use in Word ManagerTM’,</title>
<date>1998</date>
<booktitle>Computers, Linguistics and Phonetics between Language and Speech, Proceedings of the 4th Conference on NLP, Konvens&apos;98,</booktitle>
<pages>365--370</pages>
<editor>in Schröder, Bernhard; Lenders, Winfried; Hess, Wolfgang &amp; Portele, Thomas (eds.),</editor>
<location>Pius</location>
<marker>Pedrazzini, Hacken, 1998</marker>
<rawString>Pedrazzini, Sandro &amp; ten Hacken, Pius (1998), ‘Centralized Lexeme Management and Distributed Dictionary Use in Word ManagerTM’, in Schröder, Bernhard; Lenders, Winfried; Hess, Wolfgang &amp; Portele, Thomas (eds.), Computers, Linguistics and Phonetics between Language and Speech, Proceedings of the 4th Conference on NLP, Konvens&apos;98, Bonn, Germany, Frankfurt am Main: Lang, p. 365-370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandro Pedrazzini</author>
</authors>
<title>The Finite State Automata’s Design Patterns’,</title>
<date>1999</date>
<booktitle>Automata Implementation, Third International Workshop on Implementing Automata, WIA’98,</booktitle>
<pages>213--219</pages>
<editor>in Champarnaud, Jean-Marc; Maurel, Denis &amp; Ziadi, Djelloud (eds.),</editor>
<publisher>Springer,</publisher>
<location>Rouen, France, Berlin:</location>
<contexts>
<context position="53084" citStr="Pedrazzini (1999)" startWordPosition="8522" endWordPosition="8523">and multi-word units, Phrase Manager (PM), is described in Pedrazzini (1994). A module for the use of word formation rules as a basis for the semi-automatic classification of new entries is described by Hsiung (1995). This module proposes a number of analyses for a new word on the basis of word formation rules and existing lexemes and formatives. Holz (1995) developed an interface for the specification of entries. For other parts, documentation was not extensively published. The mechanism for deriving finite-state tools from lexicon databases is described by Pedrazzini &amp; ten Hacken (1998) and Pedrazzini (1999). WM was conceived as a language-independent system. Although the formalism is very flexible, the system is not equally adapted to all languages. It works best with languages having a morphological system such as Germanic and Romance languages, with a moderate amount of inflection and non-concatenative processes. The first morphological rule database to be developed was the Italian database described by Bopp (1993). Other complete rule databases were developed for German and English. The German rule database uses PM for the analysis of separable verbs, such as aufhören in (5): (5) a. Anna glau</context>
</contexts>
<marker>Pedrazzini, 1999</marker>
<rawString>Pedrazzini, Sandro (1999), ‘The Finite State Automata’s Design Patterns’, in Champarnaud, Jean-Marc; Maurel, Denis &amp; Ziadi, Djelloud (eds.), Automata Implementation, Third International Workshop on Implementing Automata, WIA’98, Rouen, France, Berlin: Springer, p. 213-219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ingo Plag</author>
</authors>
<title>Morphological Productivity: Structural Constraints in English Derivation,</title>
<date>1999</date>
<location>Berlin: Mouton</location>
<note>de Gruyter.</note>
<contexts>
<context position="18798" citStr="Plag 1999" startWordPosition="3072" endWordPosition="3073">y than others – an intuition which cannot be formalized. In quantitative studies this intuition is approximated by the question: how probable is it that we will see a new type (lexeme) produced by word formation process X after we have sampled a certain amount of text? Quantitative studies of the productivity of word formation processes are important for the design of word formation systems if the resources are limited and one has to concentrate on the most productive word formation processes (on the quantitative aspects of productivity see for example Baayen 1992, 2000; Baayen &amp; Lieber 1991; Plag 1999; for a discussion of some corpus related problems in calculating productivity indices see Evert &amp; Lüdeling 2001). There are two descriptive aspects of word formation that we want to cover here in a little more detail because they are important for the description of the word formation systems DeKo and Word Manager below. We use mainly German examples here because both DeKo and Word Manager deal with German word formation. However, both issues are relevant for other languages as well. First we talk about possible 66 Word Formation in Computational Linguistics restrictions on word formation rul</context>
</contexts>
<marker>Plag, 1999</marker>
<rawString>Plag, Ingo (1999), Morphological Productivity: Structural Constraints in English Derivation, Berlin: Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Ritchie</author>
</authors>
<title>The Lexicon’,</title>
<date>1987</date>
<pages>225--256</pages>
<editor>in Whitelock et al. (eds.),</editor>
<contexts>
<context position="46528" citStr="Ritchie (1987)" startWordPosition="7432" endWordPosition="7433">formation systems it is worth considering WM from this perspective. 18 It is, of course, difficult to train or find the appropriate choice function. Since the same issue is problematic in parsers the strategies of dealing with too much ambiguity can be transferred from there. 75- Pius ten Hacken The original motivation for WM stems from the discovery of the so-called “lexical bottleneck”. In the course of the 1980s it was realized that the quality of many of the intricate rule systems developed in computational linguistics could not be used in practice because they did not have a lexicon, cf. Ritchie (1987). The obvious solution was of course making lexical resources reusable. The originality of WM lies in its approach to reusability. Ten Hacken &amp; Domenig (1996) present this approach in terms of the diagram in Fig. 1. Text words 1 Lexeme 2 Readings Fig. 1: The bow-tie model adopted by WM. The central position in the bow-tie model is taken by the lexeme. The notion of lexeme in WM is similar to the one adopted by Matthews (1974), Aronoff (1994) and others. A lexeme is a word considered as an inflectional paradigm. Fig. 1 highlights two mappings involving the lexeme: 1. the mapping between the lex</context>
</contexts>
<marker>Ritchie, 1987</marker>
<rawString>Ritchie, Graeme (1987), ‘The Lexicon’, in Whitelock et al. (eds.), p. 225-256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bettina Säuberlich</author>
</authors>
<title>Aufbau und Regelformat von DeKo, Technical report IMS, available at http://www.ims.uni-stuttgart.de/projekte/DeKo/ Schiller,</title>
<date>2001</date>
<booktitle>Deutsche Flexions und Kompositionsmorphologie mit PCKIMMO’, in Hausser, Roland (ed), Linguistische Verifikation. Dokumentation zur ersten Morpholympics</booktitle>
<location>Anne</location>
<contexts>
<context position="44349" citStr="Säuberlich (2001)" startWordPosition="7075" endWordPosition="7076">ce function (for example one that associates &apos;costs&apos; or probabilities with rules)18 or one could accept all legal analyses and let another component decide. We have chosen to combine the first and the last strategy, so that the application can either rely on manually corrected lexicon information alone or it can accept all legal analyses. Implementation DeKo is implemented as a series of finite-state transducers, using the FST-suite provided by AT&amp;T (Sproat 2000b). A more detailed description of the architecture is given in Schmid et al. (2001) and examples for the rule format are provided in Säuberlich (2001). We need to model three types of rules: • The sequential analysis into morphemes is done in a declarative grammar. For example, the adjective unregierbar &apos;ungovernable&apos; which has to be divided into the morphological elements un- + regier + -bar can be treated by the following grammar: START PREF un[adj.pref] + PREF STEM regier[verb] STEM SUFF + bar[suff][adj] where the parts in the square brackets provide the restrictions. Here we can formulate restrictions on all relevant linguistic levels as long as the information is present in the lexicon. • The hierarchical structure is provided by a con</context>
</contexts>
<marker>Säuberlich, 2001</marker>
<rawString>Säuberlich, Bettina (2001), Aufbau und Regelformat von DeKo, Technical report IMS, available at http://www.ims.uni-stuttgart.de/projekte/DeKo/ Schiller, Anne (1996), ‘Deutsche Flexions und Kompositionsmorphologie mit PCKIMMO’, in Hausser, Roland (ed), Linguistische Verifikation. Dokumentation zur ersten Morpholympics 1994, Tübingen: Niemeyer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees’,</title>
<date>1994</date>
<booktitle>in International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester,</location>
<contexts>
<context position="33294" citStr="Schmid 1994" startWordPosition="5385" endWordPosition="5386">the moment it is used in the Text-To-Speech system IMS-FESTIVAL within the SmartKom Project and in a terminology extraction project. There are plans to use it as a backup-program for unknown words with the German LFG parser in the ParGram project. 70 Word Formation in Computational Linguistics standardized collection of the relevant data that we could use. Therefore we first collected and systematized the data ourselves (using every available source, of course). Data acquisition in DeKo was done on the basis of a corpus: we used German newspaper corpora, which were tagged with the TreeTagger (Schmid 1994) and lemmatized with DMOR (Schiller 1996), for searching and pre-processing we used the Corpus Query Processor (Schiller 1996) and a number of Perl scripts. In acquiring and systematizing the data we made a distinction between word formation involving selecting elements (roughly derivation) and word formation involving only categories (compounding). For expository purposes we concentrate on a derivation process here and only briefly describe a compounding process below. We described each derivational process on three levels. First we collected information about the selecting element (affix) it</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Schmid, Helmut (1994), ‘Probabilistic part-of-speech tagging using decision trees’, in International Conference on New Methods in Language Processing, Manchester, p. 44-49.</rawString>
</citation>
<citation valid="true">
<title>Word Formation in Computational Linguistics Schmid, Tanja; Lüdeling, Anke; Säuberlich, Bettina; Heid, Ulrich and Möbius,</title>
<date>2001</date>
<booktitle>DeKo: Ein System zur Analyse komplexer Wörter’, in GLDV -Jahrestagung</booktitle>
<pages>49--57</pages>
<location>Bernd</location>
<contexts>
<context position="8746" citStr="(2001)" startWordPosition="1435" endWordPosition="1435">? Because it shows us that adding more text also adds more new words. Even if we produced a lexicon that contained the 715,972 lemmas from the Stuttgarter Zeitung, there would probably be new words in the newspaper issue of the next day. 4 This was noticed in the early 20th century by George Kingsley Zipf among others and led to the formulation of the so-called Zipf&apos;s law which states that the most frequent type occurs twice as often as the second frequent type and three times as often as the third frequent type etc. A short discussion of Zipf&apos;s law and similar formulas can be found in Baayen (2001) and in Manning &amp; Schütze (1999).. 5 Where ZZF stands for Zentralverband zoologischer Fachgeschäfte &apos;central committee of zoological stores&apos;. 6 Such a distribution is called an LNRE distribution (for Large Number of Rare Events). See Baayen (2001) for statistical models and techniques in dealing with LNRE distributions. 63- Pius ten Hacken Kinds of new words Consider the hapax legomena (words occurring only once) in Table 1: some of them are names (Zywietz, Zyzik), some are regular words from a genre that is not typically covered in a newspaper (here biology: zytos, zytotoxisch) and some are c</context>
<context position="15836" citStr="(2001)" startWordPosition="2586" endWordPosition="2586">us word with a different syntactic category is created. This is frequent in English, where nouns can become verbs (e.g. house) or the reverse (e.g. break). Various solutions have been proposed in an IA perspective. In an IP perspective, these problems do not arise, because prefixation and suffixation are considered as special cases of a more general rule of the type “affect the form of the input in ... way and the meaning in ... way.” 65- Pius ten Hacken The reason we are interested in word formation rules is their productivity. Productivity is a difficult and controversial concept, cf. Bauer (2001). Basically, a productive word formation rule can be used to produce new lexical items. When a speaker has a productive word formation rule at her disposal, she can use a word not in her mental lexicon and be understood as far as other speakers have the same word formation rule available. The productivity of word formation makes it impossible to cover the entire lexicon in a finite list. Productivity is not quite the same as regularity. To the extent a word formation rule is regular, we can predict properties of the output on the basis of properties of the input. Regularity can be seen as a cl</context>
<context position="28895" citStr="(2001)" startWordPosition="4667" endWordPosition="4667">un. The last problem is not necessarily linked to finite-state approaches, but in two-level morphology, cf. Koskenniemi (1983), Antworth (1990), the way features are handled is specifically geared towards inflection. The first two problems are inherent in finite-state technology and can only be handled by one of the following strategies: • Giving up the finite-state constraint and using a more powerful rule type such as context-free rewrite rules. This implies a loss of computational efficiency, because context-free rules do not work in linear time. 10 An example of this type of work is Kiraz (2001). In Arabic a root such as ktb is combined with a vowel pattern to produce words such as kitaab (‘book’) and kutub (‘books’). It is interesting to note that the traditional approach to Arabic roots results in approximately 10,000 different items. This number corresponds more closely to the number of simple lexemes to be expected in the lexicon of a language than to the number of lexemes. It is then not surprising to find items such as kaatib (‘writer’), kutib (‘be written’) with the same root. 11 In principle we could of course reverse the entire system. Thus, languages such as Navajo, which u</context>
<context position="44282" citStr="(2001)" startWordPosition="7065" endWordPosition="7065">xicon, one could leave the decision to an automatic choice function (for example one that associates &apos;costs&apos; or probabilities with rules)18 or one could accept all legal analyses and let another component decide. We have chosen to combine the first and the last strategy, so that the application can either rely on manually corrected lexicon information alone or it can accept all legal analyses. Implementation DeKo is implemented as a series of finite-state transducers, using the FST-suite provided by AT&amp;T (Sproat 2000b). A more detailed description of the architecture is given in Schmid et al. (2001) and examples for the rule format are provided in Säuberlich (2001). We need to model three types of rules: • The sequential analysis into morphemes is done in a declarative grammar. For example, the adjective unregierbar &apos;ungovernable&apos; which has to be divided into the morphological elements un- + regier + -bar can be treated by the following grammar: START PREF un[adj.pref] + PREF STEM regier[verb] STEM SUFF + bar[suff][adj] where the parts in the square brackets provide the restrictions. Here we can formulate restrictions on all relevant linguistic levels as long as the information is presen</context>
<context position="62330" citStr="(2001)" startWordPosition="10014" endWordPosition="10014">the database in a particular way. Tools are very specific, for instance in the format of their output. An example of the implications of these differences can be taken from the use of word formation in WM in the context of Computer-Assisted Language Learning. Ten Hacken (1998) compares the treatment of word formation in WM with its treatment in learner’s dictionaries published as books and in a number of other electronic dictionaries which do not have a word formation component. The conclusion is that the WM treatment offers possibilities unknown in the other contexts. Ten Hacken &amp; Tschichold (2001) describe these possibilities more concretely, concentrating on the information available in the WM lexicon database and the browsers giving access to this information. Thus, it is immediately visible how many lexemes in the 200,000 entry database for German were formed by a particular process or set of processes, or which entries are derived from the noun kind (‘child’). The result of developing a number of dedicated lexical tools for CALL can be seen at http://www.canoo.net/. Here it is also possible, for instance, to have one’s text checked for one of the recognized style sheets implementin</context>
</contexts>
<marker>2001</marker>
<rawString>Word Formation in Computational Linguistics Schmid, Tanja; Lüdeling, Anke; Säuberlich, Bettina; Heid, Ulrich and Möbius, Bernd (2001), ‘DeKo: Ein System zur Analyse komplexer Wörter’, in GLDV -Jahrestagung 2001, p. 49-57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Spencer</author>
</authors>
<title>Morphological Theory; An Introduction to Word Structure in Generative Grammar,</title>
<date>1991</date>
<publisher>Blackwell.</publisher>
<location>Oxford:</location>
<contexts>
<context position="12313" citStr="Spencer (1991)" startWordPosition="2004" endWordPosition="2005">ormation: elements and rules8 Morphology is traditionally divided into inflection and word formation. Intuitively, inflection is the formation of word forms of a lexeme for the appropriate syntactic 7 This is quite common: think for example of English song texts, film titles, advertisements or quotations in German or French newspaper text. 8 In this tutorial we do not have the space to explain word formation in a lot of detail. Therefore, many of the problematic (and interesting!) cases and issues cannot be touched upon. For more comprehensive introductions to word formation see Bauer (1988), Spencer (1991), Carstairs (1992). You can find introductions and overviews for a lot of issues in Spencer &amp; Zwicky (1998) and Booij, Lehmann &amp; Mugdan (2000). We also have to warn you that we need to gloss over a number of really problematic definitions. 64 Word Formation in Computational Linguistics environment (e.g. pushes for push, craignent for craindre) whereas word formation is the formation of new lexemes. Although this distinction is by no means uncontroversial and it is difficult to classify certain borderline cases (e.g. participles, the comparative and superlative of adjectives), we will assume he</context>
</contexts>
<marker>Spencer, 1991</marker>
<rawString>Spencer, Andrew (1991), Morphological Theory; An Introduction to Word Structure in Generative Grammar, Oxford: Blackwell.</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<booktitle>The Handbook of Morphology,</booktitle>
<editor>Spencer, Andrew &amp; Zwicky, Arnold M. (eds.)</editor>
<publisher>Blackwell.</publisher>
<location>Oxford:</location>
<contexts>
<context position="2710" citStr="(1998)" startWordPosition="405" endWordPosition="405">tter 1 This distinction does not primarily depend on the application type (e.g. machine translation, text summarization), but rather on such factors as the context of use and the strategy chosen to solve the problem at hand. Thus a machine translation system for weather forecasts such as Météo (with its restrictions of use as described by Chandioux (1989)) has a closed set vocabulary. If the domain of a machine translation system is less restricted it is bound to be confronted with new, unseen words. In the case of text summarization, a different distinction can be made (cf. Endres-Niggemeyer (1998)). Here there is one strategy which basically consists of determining a set of key words and ranking sentences of the text to be summarized in terms of their use of key words and their position in the text. A summary is then compiled by putting together the highest-ranked sentences. In this strategy, a fairly small vocabulary is sufficient, because no attempt to arrive at a full-scale analysis of the text is undertaken. Unseen words occur frequently, but are ignored. Of course a more sophisticated strategy which assumes a stage at which the structure and meaning of the text is represented as a</context>
<context position="12420" citStr="(1998)" startWordPosition="2023" endWordPosition="2023">inflection is the formation of word forms of a lexeme for the appropriate syntactic 7 This is quite common: think for example of English song texts, film titles, advertisements or quotations in German or French newspaper text. 8 In this tutorial we do not have the space to explain word formation in a lot of detail. Therefore, many of the problematic (and interesting!) cases and issues cannot be touched upon. For more comprehensive introductions to word formation see Bauer (1988), Spencer (1991), Carstairs (1992). You can find introductions and overviews for a lot of issues in Spencer &amp; Zwicky (1998) and Booij, Lehmann &amp; Mugdan (2000). We also have to warn you that we need to gloss over a number of really problematic definitions. 64 Word Formation in Computational Linguistics environment (e.g. pushes for push, craignent for craindre) whereas word formation is the formation of new lexemes. Although this distinction is by no means uncontroversial and it is difficult to classify certain borderline cases (e.g. participles, the comparative and superlative of adjectives), we will assume here that it is possible to distinguish the two. An overview of the discussion is given in ten Hacken (1994),</context>
<context position="25869" citStr="(1998)" startWordPosition="4199" endWordPosition="4199">Karttunen (1997) and 9 Stem changes have been analysed in a number of different ways in the literature. Since many forms look like inflected forms (the so-called paradigmic forms) it is sometimes argued that these are inflected forms in word formation. There are good arguments against this view: (a) there are many stems that do not change in word formation, (b) changed stems do not necessarily have the semantics of the corresponding plural form and unchanged stems do not necessarily have the semantics of the singular, and (c) there are also non-paradigmic forms. See the discussions in Fuhrhop (1998) and Eisenberg (1998). The existence of stem changes is often used as an argument against the IA model, e.g. by Anderson (1992). An analysis in terms of “stem formation” is elaborated by ten Hacken (1994). 68 Word Formation in Computational Linguistics Sproat (2000a) do not even mention inflection and word formation as terms, let alone make the conceptual distinction. The starting point of the approaches they describe is clearly inflection. As far as word formation phenomena are treated, e.g. Sproat (2000a:50), they are not considered from the perspective of the creation of new lexemes, but as</context>
<context position="39536" citStr="(1998)" startWordPosition="6319" endWordPosition="6319">icult. The &lt;n&gt; in Anzeigenadel could, for example, belong to Nadel &apos;pin&apos; or it could be a linking element for Anzeige &apos;advertisement, display&apos;; the compound could then either be Anzeige+Nadel &apos;display needle&apos; (as in a speedometer or a scale) or Anzeigen+Adel &apos;advertisement nobility&apos;. The latter reading is improbable but word formation systems do not normally contain a semantic component. And it is, of course, not an illegal or impossible reading. In an Item and Process approach stem changes are dealt with via rules. Since stem changes in German are not regular or predictable we follow Fuhrhop (1998) and Eisenberg (1998) on listing the forms that an element may take. These forms are called word formation stem forms. Free and bound morphological elements have one or more derivation stem form(s) and one or more compounding stem form(s). Very often these stem forms look just like the regular stem. Consider the examples in Table 4 where we have listed the word formation stem forms of some morphological elements together with the appropriate examples: stem Frau &apos;woman&apos; -keit (noun les- &apos;to read&apos; forming suffix) derivation stem fräu- - les forms frauderivation Fräulein &apos;Miss&apos; - lesbar examples </context>
<context position="50376" citStr="(1998)" startWordPosition="8092" endWordPosition="8092"> readings should be covered in a different component. The two perspectives can be represented as in Fig. 2: A B C 1 2 3 4 morphologicaldictionary Fig. 2: Coverage of WM resources (C) as opposed to more traditional lexicons (B). Somewhat simplified, the areas in Fig. 2A can be characterized as follows: 1. syntactic and semantic lexical knowledge, 2. syntactic and semantic rule knowledge, 3. morphological lexical knowledge, and 4. morphological rule knowledge. The combination of lexical knowledge and rule knowledge enables WM to function as a full morphological component. As shown by ten Hacken (1998), the effects of this coverage are particularly striking in the domain of word formation, for which a system taking a lexicon as modelled in Fig. 2B as a basis lacks the procedural component. Thus a formalism such as DATR, as described by Evans &amp; Gazdar (1996), though able to represent word formation relationships, cannot deal with unseen words without a separate recognition module. In WM, word formation rules are at the same time available declaratively, as the structural backbone of the database, and procedurally for the recognition of new words. History WM is a long-term, open-ended project</context>
<context position="53062" citStr="(1998)" startWordPosition="8520" endWordPosition="8520">of clitics and multi-word units, Phrase Manager (PM), is described in Pedrazzini (1994). A module for the use of word formation rules as a basis for the semi-automatic classification of new entries is described by Hsiung (1995). This module proposes a number of analyses for a new word on the basis of word formation rules and existing lexemes and formatives. Holz (1995) developed an interface for the specification of entries. For other parts, documentation was not extensively published. The mechanism for deriving finite-state tools from lexicon databases is described by Pedrazzini &amp; ten Hacken (1998) and Pedrazzini (1999). WM was conceived as a language-independent system. Although the formalism is very flexible, the system is not equally adapted to all languages. It works best with languages having a morphological system such as Germanic and Romance languages, with a moderate amount of inflection and non-concatenative processes. The first morphological rule database to be developed was the Italian database described by Bopp (1993). Other complete rule databases were developed for German and English. The German rule database uses PM for the analysis of separable verbs, such as aufhören in</context>
<context position="57414" citStr="(1998)" startWordPosition="9212" endWordPosition="9212">ions). They are important for the treatment of certain word formation processes, e.g. German separable verbs as illustrated in (5) and English multi-word compounds such as fire brigade. The latter type does not add anything conceptually relevant apart from the fact that it is possible to treat fire brigade as a morphological formation on a par with girlfriend. Separable verbs constitute a rather complex phenomenon in a text-based system because of the interplay between one-word and multi-word forms of the same lexeme. The treatment of the phenomenon is explained in detail in ten Hacken &amp; Bopp (1998). 20 The selection of the suffix is restricted by the position of the rule in the word formation tree. For details cf. Domenig &amp; ten Hacken (1992). 79- Pius ten Hacken target by marking the relevant feature in the source. Thus for the verbal prefix ri-, corresponding to English re-, the inflection class of the base is passed on to the target. In this way the verb riandare (‘go again’) is inflected in the same, highly irregular way as andare (’go’). The differences between IRules and WFRules express the differences between inflection and word formation as they are analysed in WM. Whereas inflec</context>
<context position="62001" citStr="(1998)" startWordPosition="9962" endWordPosition="9962">e derived from the database for any platform desired. • The lexicon database contains all the information about inflection and word formation rules and relationships for a language. It is an object-oriented database with high flexibility. A lexical tool is dedicated to a particular task, using a selection of the information in the database in a particular way. Tools are very specific, for instance in the format of their output. An example of the implications of these differences can be taken from the use of word formation in WM in the context of Computer-Assisted Language Learning. Ten Hacken (1998) compares the treatment of word formation in WM with its treatment in learner’s dictionaries published as books and in a number of other electronic dictionaries which do not have a word formation component. The conclusion is that the WM treatment offers possibilities unknown in the other contexts. Ten Hacken &amp; Tschichold (2001) describe these possibilities more concretely, concentrating on the information available in the WM lexicon database and the browsers giving access to this information. Thus, it is immediately visible how many lexemes in the 200,000 entry database for German were formed </context>
<context position="63797" citStr="(1998)" startWordPosition="10246" endWordPosition="10246">n a terminological database, cf. Zappatore &amp; ten Hacken (2000). Here the WFRules are used not only as a structuring device of the terminological lexicon, but also as a way for recognizing terms when they are ‘hidden’ in nominalizations, compounds, etc. Thus, Verwaltungsrat (‘board of directors’) is also recognized in Verwaltungsratsvakanz (‘vacancy in the board of directors’). One of the reasons why WM is particularly suited to this task in a multilingual system (German, English, Italian) is that it can treat singleword and multi-word terms equally. As a final example, Pedrazzini &amp; ten Hacken (1998) describe the prototype of a “generative spellchecker”. In particular in German, where compounds are written as one word, spellcheckers regularly fail on words such as Nordostgrenze (‘north-eastern border’) because they are not in the dictionary. The generative spellchecker recognizes these words as possible words. Depending on the elaboration of the prototype they may be proposed as a list to be checked for spelling errors21 or for enlarging the lexicon database. Applied to a German corpus of newspaper text with a 100,000 entry lexicon, 7% of the words in the corpus were recognized with the g</context>
</contexts>
<marker>1998</marker>
<rawString>Spencer, Andrew &amp; Zwicky, Arnold M. (eds.) (1998), The Handbook of Morphology, Oxford: Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
</authors>
<title>Morphology and Computation,</title>
<date>1992</date>
<publisher>MIT Press.</publisher>
<location>Cambridge (Mass.):</location>
<contexts>
<context position="26813" citStr="Sproat (1992)" startWordPosition="4344" endWordPosition="4345"> alone make the conceptual distinction. The starting point of the approaches they describe is clearly inflection. As far as word formation phenomena are treated, e.g. Sproat (2000a:50), they are not considered from the perspective of the creation of new lexemes, but as examples of more difficult combinations of formatives. From a technical point of view, the domain of inflectional morphology is a rather well-explored area, in which most efforts are devoted to development rather than research. Techniques used are based on finite-state transducers as used originally in two-level morphology, cf. Sproat (1992) for an overview. Research concentrates to a large extent on complicated phenomena such as Arabic nonlinear morphology.10 Transferring the finite-state approach from inflection to word formation does not by itself cause many additional problems, but it does exacerbate a number of well-known problems of finite-state mechanisms: • A finite-state rule system concatenates formatives from left to right.11 As long as we are dealing with suffixation, there is no problem. For languages such as Finnish, Turkish, and Basque, which have only suffixation and a lot of it, finitestate morphology is ideal. W</context>
</contexts>
<marker>Sproat, 1992</marker>
<rawString>Sproat, Richard (1992), Morphology and Computation, Cambridge (Mass.): MIT Press.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Richard Sproat</author>
</authors>
<title>(2000a), ‘Lexical Analysis’,</title>
<pages>37--57</pages>
<editor>in Dale et al. (eds.),</editor>
<marker>Sproat, </marker>
<rawString>Sproat, Richard (2000a), ‘Lexical Analysis’, in Dale et al. (eds.), p. 37-57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
</authors>
<title>A toolkit for finite-state linguistic analysis, Technical report, available at http://www.research.att.com/sw/tools/lextools Trost,</title>
<date>1993</date>
<booktitle>in Proceedings of the 6th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>368--376</pages>
<location>Harald</location>
<marker>Sproat, 1993</marker>
<rawString>Sproat, Richard (2000b), Lextools. A toolkit for finite-state linguistic analysis, Technical report, available at http://www.research.att.com/sw/tools/lextools Trost, Harald (1993), ‘Coping With Derivation in a Morphological Component’, in Proceedings of the 6th Conference of the European Chapter of the Association for Computational Linguistics, Utrecht, p. 368-376.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cornelia Tschichold</author>
</authors>
<date>2000</date>
<booktitle>Multi-Word Units in Natural Language Processing,</booktitle>
<location>Hildesheim: Olms.</location>
<contexts>
<context position="54151" citStr="Tschichold (2000)" startWordPosition="8687" endWordPosition="8688">were developed for German and English. The German rule database uses PM for the analysis of separable verbs, such as aufhören in (5): (5) a. Anna glaubt, dass Bernard aufhört. (‘Anna believes that Bernard stops’) b. Claudia hört jetzt auf. (‘Claudia stops now PRT’) c. Daniel versucht aufzuhören. (‘Daniel tries to_stop’) As described by ten Hacken &amp; Bopp (1998), the interaction of inflection rules, word formation rules, clitic rules (for (5c)), and rules for multi-word units (for (5b)) makes it possible to analyse all occurrences of aufhören in (5) as instances of the same lexeme. For English, Tschichold (2000) describes the rules for the analysis of multi-word units more generally. The first lexicon database to be developed was for German. It has now reached a size of 200,000 lexemes. The development of English and Italian lexicon databases was 78 Word Formation in Computational Linguistics undertaken in a parallel effort, funded by the Swiss National Science Foundation. The parallelism entails that the same lexicographic guidelines are used for both languages. Word formation plays a central role in the development, as discussed by ten Hacken (2002) and ten Hacken &amp; Smyk (2002). Linguistic Approach</context>
</contexts>
<marker>Tschichold, 2000</marker>
<rawString>Tschichold, Cornelia (2000), Multi-Word Units in Natural Language Processing, Hildesheim: Olms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Volk</author>
<author>Simon Clematide</author>
</authors>
<title>Learn-Filter-Apply-Forget. Mixed Approaches to Named Entity Recognition’,</title>
<date>2001</date>
<booktitle>in Proceedings of the 6th International Workshop on Applications of Natural Language for Information Systems,</booktitle>
<location>Madrid.</location>
<marker>Volk, Clematide, 2001</marker>
<rawString>Volk, Martin &amp; Clematide, Simon (2001), ‘Learn-Filter-Apply-Forget. Mixed Approaches to Named Entity Recognition’, in Proceedings of the 6th International Workshop on Applications of Natural Language for Information Systems, Madrid.</rawString>
</citation>
<citation valid="true">
<date>1987</date>
<booktitle>Linguistic Theory and Computer Applications,</booktitle>
<editor>Whitelock, Pete; McGee Wood, Mary; Somers, Harold L.; Johnson, Rod &amp; Bennett, Paul (eds.)</editor>
<publisher>Academic Press.</publisher>
<location>London:</location>
<contexts>
<context position="17052" citStr="(1987)" startWordPosition="2794" endWordPosition="2794"> gradual transition from fully regular to completely irregular. Some interesting points on this cline are: • semi-regularity, in which the output can be related to the output, but not predicted by it, e.g. abbreviations and clippings; • a higher degree of regularity in which the form and meaning of the output can be predicted from the input, but not the application of the WFR, e.g. unclear, but not *undeep; • full regularity, in which also the existence of the output can be predicted, e.g. -ing-forms of English verbs. The relationship between productivity and regularity is discussed by Corbin (1987). In a computational context, the regularity of a word formation rule is what makes it possible to describe it in the form of a procedure which can be used to recognize new words. The productivity of word formation rules is, of course, responsible for many of the unknown words found in unseen text, as described in the previous section. Recall the examples: quite a few of the hapax legomena were compounds (ZZ-Top-Hit), compounding is a very productive process in German (and English), therefore we expect many of the unknown words to be productively formed compounds. There are two approaches to a</context>
<context position="46528" citStr="(1987)" startWordPosition="7433" endWordPosition="7433">n systems it is worth considering WM from this perspective. 18 It is, of course, difficult to train or find the appropriate choice function. Since the same issue is problematic in parsers the strategies of dealing with too much ambiguity can be transferred from there. 75- Pius ten Hacken The original motivation for WM stems from the discovery of the so-called “lexical bottleneck”. In the course of the 1980s it was realized that the quality of many of the intricate rule systems developed in computational linguistics could not be used in practice because they did not have a lexicon, cf. Ritchie (1987). The obvious solution was of course making lexical resources reusable. The originality of WM lies in its approach to reusability. Ten Hacken &amp; Domenig (1996) present this approach in terms of the diagram in Fig. 1. Text words 1 Lexeme 2 Readings Fig. 1: The bow-tie model adopted by WM. The central position in the bow-tie model is taken by the lexeme. The notion of lexeme in WM is similar to the one adopted by Matthews (1974), Aronoff (1994) and others. A lexeme is a word considered as an inflectional paradigm. Fig. 1 highlights two mappings involving the lexeme: 1. the mapping between the lex</context>
</contexts>
<marker>1987</marker>
<rawString>Whitelock, Pete; McGee Wood, Mary; Somers, Harold L.; Johnson, Rod &amp; Bennett, Paul (eds.) (1987), Linguistic Theory and Computer Applications, London: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniela Zappatore</author>
<author>ten Hacken</author>
</authors>
<title>Word Manager and Banking Terminology: Industrial Application of a General System’,</title>
<date>2000</date>
<booktitle>Proceedings of the Ninth Euralex International Congress, Euralex 2000, Stuttgart: Institut für Maschinelle Sprachverarbeitung, Universität Stuttgart,</booktitle>
<pages>325--335</pages>
<editor>in Heid, Ulrich; Evert, Stefan; Lehmann, Egbert &amp; Rohrer, Christian (eds.),</editor>
<location>Pius</location>
<marker>Zappatore, Hacken, 2000</marker>
<rawString>Zappatore, Daniela &amp; ten Hacken, Pius (2000), ‘Word Manager and Banking Terminology: Industrial Application of a General System’, in Heid, Ulrich; Evert, Stefan; Lehmann, Egbert &amp; Rohrer, Christian (eds.), Proceedings of the Ninth Euralex International Congress, Euralex 2000, Stuttgart: Institut für Maschinelle Sprachverarbeitung, Universität Stuttgart, p. 325-335.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>