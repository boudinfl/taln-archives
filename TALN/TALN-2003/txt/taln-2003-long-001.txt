TALN 2003, Batz-sur-Mer, 11-14 juin 2003 
Quand le TAL robuste sattaque au langage parlé : 
analyse incrémentale pour la compréhension de la parole spontanée 
Antoine Jean-Yves, Goulian Jérôme, Villaneau Jeanne 
Laboratoire VALORIA  Université de Bretagne Sud 
Rue Yves Mainguy, F-56000 Vannes  Mel : {Nom.Prenom}@univ-ubs.fr 
 
Résumé  Abstract 
Dans cet article, nous discutons de lapplication au langage parlé des techniques danalyse 
syntaxique robuste développées pour lécrit. Nous présentons deux systèmes de compréhension 
de parole spontané en situation de dialogue homme-machine finalisé, dont les performances 
montrent la pertinence de ces méthodes pour atteindre une compréhension fine et robuste des 
énoncés oraux.  
This papers discusses the relevance of robust parsing techniques for the analysis of spontaneous 
spoken language. It presents two speech understanding systems devoted to human-machine 
communication that implement such robust methods. Their performances suggest that robust 
parsing should apply usefully to spontaneous speech. 
Keywords  Mots Clés 
Analyse syntaxique robuste, compréhension de la parole, dialogue homme-machine. 
Robust parsing, spoken language understanding, human-machine dialogue.  
1 TAL robuste et ingénierie des langues 
Le TALN a connu au cours de la dernière décennie une révolution épistémologique que résume 
lémergence de la notion dingénierie des langues. Alors que les recherches antérieures 
privilégiaient une approche en compétence suivant la démarche de lIntelligence Artificielle, les 
années 1990 se sont concentrées sur la réalisation de systèmes performants mettant en jeu des 
utilisateurs réels (Cunningham, 2000). Cette évolution sest traduite par lapparition dapproches 
qui, sans renier lapport des travaux antérieurs à fort ancrage linguistique,  recherchent en 
priorité une robustesse et une efficacité danalyse sur du langage libre. On a ainsi vu se 
développer des analyseurs syntaxiques robustes reposant sur deux postulats principaux (Ejerhed, 
1993) : 
Antoine J.Y., Goulian J., Villaneau J. 
• Analyse complète mais superficielle (shallow parsing) limitée par exemple à une 
segmentation en constituants minimaux non récursifs, appelés chunks (Abney, 1991). 
• Analyse non destructrice cest-à-dire conservant toute linformation présente dans lénoncé 
pour des traitements ultérieurs plus profonds. En particulier, ces analyseurs privilégient la 
robustesse à une désambiguïsation complète  mais risquée   au niveau danalyse 
considéré. On parle alors de sous-spécification de lanalyse. 
La généralisation de cette démarche sur plusieurs niveaux de traitements conduit à une analyse 
incrémentale où chaque étape répond aux mêmes exigences (Aït-Mokhtar et al, 2003): 
• Analyse sous-spécifiée et superficielle, au sens où la profondeur des représentations 
élaborées ne saccroît que légèrement dun niveau à lautre,  
• Indépendance conceptuelle vis-à-vis de lanalyse globale : les connaissances manipulées à 
un niveau donné font sens par elles-mêmes, 
• Mise en uvre à laide de techniques efficaces (automates à états finis par exemple). 
Regroupées souvent sous le terme de TAL robuste (robust parsing), ces approches présentent 
des performances intéressantes sur des textes libres. Elles ont jusquà présent surtout concerné le 
langage écrit. Au contraire, cet article sintéresse à leur application au langage parlé et plus 
précisément à la compréhension de parole en situation de dialogue homme-machine finalisé. 
2 Compréhension de parole et dialogue oral homme-machine 
Les systèmes de dialogue reposent sur une architecture proche, en première approximation, de 
celle donnée en figure 1. Le message oral de l'utilisateur est tout d'abord traité par un module de 
reconnaissance de parole qui fournit une (ou plusieurs) solution(s) classée(s) par scores de 
vraisemblance décroissants. Ces énoncés reconnus sont traités par un module de compréhension 
de parole qui en construit une représentation sémantique caractérisant la structuration de 
linformation littérale présente dans lénoncé. Cette représentation est ensuite actualisée dans 
une étape dinterprétation contextuelle qui va résoudre certaines ambiguïtés et co-références. 
reconnaissance énoncé(s) compréhension structure
parole de parole reconnu(s) sémantique
gestion du
réponse dialogue
génération de
réponse application
 
Figure 1  Architecture générale d'un système de dialogue oral homme  machine 
Lobjectif de cette interprétation est également de caractériser les buts de lutilisateur en 
identifiant les actes de dialogues présents dans lénoncé. Cest pourquoi elle est souvent du 
ressort du contrôleur de dialogue qui gère linterface avec lapplication (base de données par 
exemple) ainsi que linteraction avec lutilisateur (chaîne de génération variant en fonction de la 
modalité de sortie).  
TAL robuste et langage parlé 
Nous nous intéresserons ici exclusivement à létape de compréhension des énoncés oraux, qui 
doit faire face à deux problèmes quon ne rencontre pas à lécrit. Dune part, elle intervient sur 
une séquence de mots fortement bruitée par les erreurs du module de reconnaissance. En cas de 
dialogue interactif, on observe d'autre part de nombreuses constructions orales spontanées qui, 
tout en perturbant la reconnaissance, gênent lidentification de la structure des énoncés : 
• hésitations Je voudrais un aller simple pour euh attendez Rosporden c'est cela 
• réparations  Savez-vous s'il y a un hôtel un hôtel-restaurant dans la gare (répétition) 
                   Ce serait donc pour le retour non excusez-moi pour l'aller (correction) 
• incises Je prends le premier train c'est à dire je suis très pressé hein pour Paris 
Afin de contourner ces difficultés, certains systèmes cherchent à pré-traiter les énoncés oraux 
pour les corriger avant leur analyse. Les taux de correction rapportés (Heeman, 1997) restent 
cependant éloignés dun traitement réellement robuste. 
3 Compréhension sélective de la parole 
Une réponse aux difficultés de traitement du langage parlé consiste à profiter du caractère 
finalisé du dialogue pour développer des approches orientées par la tâche. Dans ce cas, la 
compréhension se limite à lidentification dîlots-clés représentant des unités de sens pertinentes 
dans lunivers de la tâche ou utiles à la gestion du canal de communication. On parle alors de 
compréhension sélective restreinte au « sens utile » de l'énoncé (Pérennou, 1996). Celui-ci est 
représenté par un ensemble de rôles pragmatiques prédéfinis qui sont instanciés par les 
segments-clés caractérisés. 
Bonjour je voudrais les vols euh la liste des <type_requete = vols> 
vols pour Paris merci <départ = LOCAL> <arrivée = Paris> 
<date_depart = AUHOURD'HUI> 
Figure 2  Exemple de schéma obtenu en compréhension sélective de la parole 
Le caractère partiel de ces traitements leur garantit une certaine robustesse danalyse. 
Néanmoins, on peut sinterroger sur leur extension à des applications plus complexes. Toute 
augmentation de complexité se traduit en effet par une ambiguïté lexicale accrue qui posera 
problème à des approches présupposant « quil existe une projection non ambiguë des énoncés 
de lusager vers les schémas de lapplication » (Pierrel, Romary, 2000 : 332). Dans le cas 
dapplications étendues (multi-domaines), le recours à une analyse linguistique plus détaillée 
apparaît donc comme une nécessité (van Noord et al., 1999). Elle facilite par ailleurs la 
représentation dobjets complexes comme lidentification précise des intentions de lutilisateur 
(modaux ou des adverbes de degré par exemple). Cette finesse danalyse ne pouvant être atteinte 
aux dépends de la robustesse, il nous a semblé intéressant dadopter une démarche proche de 
celles employées pour lécrit en TAL robuste. 
Antoine J.Y., Goulian J., Villaneau J. 
4 Analyse incrémentale robuste pour la compréhension de parole 
Plusieurs systèmes de compréhension de la parole ont déjà cherché à étudier la structure 
profonde des énoncés oraux. Ainsi, le système TINA combine un analyseur syntaxique profond à 
un module de compréhension sélective prenant le relais du premier en cas déchec (Seneff, 
1992). Pour pouvoir apprécier les très bonnes performances du système, il faudrait néanmoins 
savoir dans quelle mesure le module sélectif a pris le relais de lanalyse linguistique. A lopposé, 
les systèmes ROMUS et LOGUS développés dans notre laboratoire mettent en uvre une 
stratégie danalyse qui applique directement les principes du TAL robuste. Le domaine 
dapplication retenu est le renseignement touristique. Il sagit dune tâche présentant une 
complexité relativement importante, comme en témoignent les ambiguïtés lexicales rencontrées 
dans nos corpus.  
4.1 Caractéristiques communes des systèmes ROMUS et LOGUS 
Tout en reposant sur des techniques différentes, ROMUS et LOGUS suivent la même stratégie 
danalyse incrémentale. Elle implique une succession détapes (figure 3) assez classique en TAL 
robuste et que lon retrouve chez (Zechner, 1998) pour le langage oral. Nous avons toutefois 
apporté plusieurs modifications à cette stratégie générale pour répondre à la fois au caractère 
spontané de lélocution et à la nature finalisée du dialogue mis en jeu. 
Séquence(s) étiquetage liste de segmentation liste de dépendances structure
 de mots mots (chunks) chunks sémantiques sémantique
typés typés
 Figure 3  Architecture générique des systèmes de compréhension LOGUS et ROMUS 
Etiquetage  Cette étape consiste à associer à chaque mot une partie du discours. Plus 
précisément, on utilise un jeu de catégories syntaxiques associées éventuellement à quelques 
informations morpho-syntaxiques.  Contrairement à (Zechner, 1998), cette étape ne vise pas un 
étiquetage totalement désambiguïsé. On retrouve ici le principe de sous-spécification qui limite 
la propagation ultérieure des erreurs et nous permet datteindre à ce stade des taux de précision 
élevés. Létape suivante poursuivra cette désambiguïsation en considérant un contexte danalyse 
plus large. 
Segmentation  Cette étape segmente lénoncé en constituants minimaux (chunks) tout en 
analysant leur structure interne. Il sagit dune analyse syntaxique qui se base sur les parties du 
discours. Ces chunks correspondent souvent à des unités de sens représentant les objets de 
lunivers. La segmentation facilite donc la transition vers les traitements sémantico-pragmatiques 
ultérieurs. Mais surtout, cette unité de segmentation est adaptée au langage parlé spontané. Il a 
en effet été démontré que ces constituants sont le lieu de réalisation privilégié des réparations à 
loral (Blanche-Benveniste, 1997 : 47). Cette observation permet denvisager un traitement 
intégré des réparations en analysant le reparandum et laltération comme la réalisation de deux 
chunks distincts. Afin daligner la segmentation avec ces éléments oraux, nos chunks ont une 
taille minimale, comme le montre lexemple ci-dessous : 
(1) [je] [veux] [les tarifs] [pour une chambre] [enfin] [une chambre double] [à lhôtel] 
[Caumartin] [et] [au Crillon] 
TAL robuste et langage parlé 
On remarquera que la segmentation nest jamais destructrice, même en présence de réparations. 
En effet, le reparandum nest pas effacé par laltération comme dans les pré-traitements 
correctifs (Heeman, 1997). On conserve ainsi lensemble de linformation véhiculée par le 
message oral, ce qui permet une identification plus fine des intentions du locuteur. Les 
réparations seront analysées ultérieurement par létape de caractérisation de dépendances entre 
chunks. 
La portée limitée de la segmentation garantit une certaine robustesse tout en autorisant une 
analyse plus détaillée des énoncés oraux. Contrairement aux approches sélectives, aucun élément 
nest en effet ignoré à ce stade. De même, cette étape analyse la structure interne des constituants 
en plus de caractériser leurs frontières. Enfin, létiquetage et la segmentation reposent sur une 
connaissance syntaxique totalement indépendante de la tâche. Cette architecture présente donc 
dindéniables atouts en matière de généricité. Ce ne sera pas le cas de la dernière étape de 
traitement. 
Dépendances sémantiques   Cette étape conduit à la représentation finale de lénoncé. Cette 
dernière sobtient par la caractérisation de dépendances sémantico-pragmatiques entre les 
chunks. En règle générale, ces relations concernent les têtes lexicales des chunks. Chaque 
constituant syntaxique est considéré comme une instance de concepts sémantico-pragmatiques. 
Un lexique pragmatique, spécifique à lapplication, décrit alors les attentes des concepts sous 
forme de relations de dépendances prédicat/argument entre les éléments de la tâche (par 
exemple, un tarif peut-être associé à différentes propriétés). Lanalyse revient à construire un 
graphe de dépendances par recherche dassociations. Elle suit une heuristique privilégiant la 
solution la plus couvrante qui minimise le nombre des concepts finaux ou les dépendances les 
plus courtes. Cette stratégie autorise une analyse partielle en cas de difficultés. De même, les 
chunks qui correspondent au reparandum et à laltération des réparations sont associés dans un 
même concept à ce niveau de traitement. Cette étape cherche également à déterminer le type 
dacte de dialogue véhiculé par lénoncé. Suivant le principe de sous-spécification déjà 
rencontré, cette caractérisation reste volontairement grossière (assertion / demande / 
confirmation, etc.). Le contrôleur de dialogue laffinera ultérieurement. 
Nous allons maintenant étudier les spécificités des deux systèmes qui, dépassant les simples 
questions dimplémentation, ne sont toutefois pas fondamentales dun point de vue théorique. 
4.2 Système ROMUS 
Le système ROMUS (Goulian 2002) répond assez fidèlement à larchitecture décrite ci-dessus. 
Nous ne donnerons donc que quelques informations sur son implémentation.  
Etiquetage  Le lexique utilisé pour létiquetage en parties du discours (45 000 mots, 34 
étiquettes grammaticales) est représenté sous la forme dun automate à états finis déterministe. 
La désambiguïsation seffectue à laide dun nombre limité de règles locales compilées en 
transducteurs déterministes utilisés en cascade. Elle reste partielle afin déviter des erreurs 
pénalisantes pour la suite de lanalyse. Létiquetage présente ainsi un taux de décision de 80,4 % 
(corpus de test de 1200 énoncés) pour une précision de 97,5 %.  
Segmentation  La segmentation repose sur une modélisation symbolique. Chaque chunk est 
décrit par un ensemble dexpressions régulières portant sur les parties du discours des mots de 
Antoine J.Y., Goulian J., Villaneau J. 
lénoncé. Ces expressions sont également compilées en transducteurs déterministes et donnent 
lieu de la même manière à une analyse en cascade. Lambiguïté de la segmentation est gérée par 
une heuristique de maximisation des segments détectés. Au final, cette étape segmente lénoncé 
en constituants minimaux généraux (chunks nominaux, verbaux, etc.) mais aussi suivant des 
segments correspondant à des expressions langagières particulières (date, heure, prix) ou encore 
à des marques (interjections, appuis du discours) de loral spontané (cf. exemple 1 du paragraphe 
4.1).  
Les règles de segmentation permettent un typage syntaxique des constituants ainsi quune 
caractérisation de leur structure (tête lexicale, dépendances locales). En fin de segmentation, 
chaque chunk est représenté par un arbre dont la racine est un triplet <S, T, M>, où S est la 
catégorie syntaxique du segment, T sa tête lexicale et M un ensemble de marques 
morphologiques.  
Dépendances  La caractérisation des dépendances entre chunks repose sur une adaptation du 
formalisme des grammaires de liens (Sleator, Temperley, 1991) permettant lutilisation dune 
connaissance sémantico-pragmatique. Les grammaires de liens ne peuvent modéliser les 
structures non projectives mais nos études de corpus (Antoine, Goulian, 2001) ont montré que 
cette limitation est sans conséquence en dialogue finalisé. A chaque entrée de la grammaire de 
liens (lexique) correspond un ensemble dattentes sémantiques spécifiques à la tâche. Elles 
sexpriment au moyen de connecteurs étiquetés et orientés qui doivent sassocier deux à deux 
pour former une relation valide. Ces relations concernent des triplets <S,T,M> et non pas des 
mots comme dans le formalisme originel des grammaires de liens. Nous avons par ailleurs défini 
deux types de relations : 
• Relations spécifiques aux items lexicaux, comme par exemple la relation Catégorie qui 
peut relier deux segments <GN, « hôtel », indéfini> et <GN, « étoile », défini>. 
• Relations exprimant des constructions syntaxiques génériques comme les coordinations 
marquées par une conjonction (<Coo, «et», ∅> par exemple). Les réparations marquées 
peuvent également être modélisées ainsi : <Cor, « non », ∅> par exemple. 
La stratégie danalyse repose sur lalgorithme de (Sleator & Temperley, 1991). Eventuellement 
partielle, elle procède par expansion dîlots en rattachant les éléments ayant des attentes 
compatibles. Ce rattachement permet de détecter les réparations qui nont pas encore été 
caractérisées. En effet, nous modélisons par un opérateur spécifique le phénomène 
dentassement paradigmatique qui résulte de ces réparations (Blanche-Benveniste, 1997). 
                                +-----------------------------------Etablissement-Ref----------------------------------+   
                                +-----OBJTARIF------+                                            +-------COOEt----------- +---COOEt----+ 
       |              |        |                 |                   | 
  +AGENT+InfoTarif-+                 +-CORtar--+-COOtar+-TypeCH --+        +REFObjId -+                 |                   | 
   |              |                  |                      |                |                |                 |         |                   |                  |                   | 
GN         GV         GN(tarif    GP(pour,         Cor    GN(chambre   GAdj    GP(à,             GNnp        Coo          GP(au,  
 (je)   (vouloir)     .def)      chambre.def)  (enfin)        .def)        (double)    hôtel.def)  (Caumartin)   (et)        Crillon) 
Figure 4  Exemple de structure de liens obtenu en sortie du système ROMUS 
En fin danalyse, un système de coût permet de hiérarchiser les différents graphes de 
dépendances obtenus. Nous privilégions, par ordre de coût décroissant, les analyses complètes, 
TAL robuste et langage parlé 
les analyses partielles avec îlots complets puis les analyses partielles avec éléments isolés. La 
représentation sémantique qui est obtenue en sortie est une structure de liens. A titre dexemple, 
la figure 4 donne la structure de liens correspondant à l'exemple (1) du paragraphe 4.1.  
4.3 Système LOGUS 
Le système LOGUS (Villaneau, Antoine, Ridoux, 2002) repose sur lutilisation de techniques 
originales dans le domaine de la parole. Il sagit en effet dun système logique utilisant le λ-
calcul pour construire une représentation sémantique à la Montague de lénoncé. Lintérêt de 
lapproche logique est sa compatibilité avec de nombreux travaux portant sur le dialogue. On 
pense ainsi à la DRT (Kamp, Reyle, 1993) ou encore à la formalisation logique de la théorie des 
actes de langage de Searle (logique illocutoire : Vanderveken, 1994). LOGUS vise donc une 
intégration forte de la compréhension et de la gestion du dialogue. Il répond aux caractéristiques 
ci-dessous. 
Etiquetage  Cet étape est minimale : par accès au lexique, elle consiste à associer à chaque 
mot sa ou ses définitions : un triplet <C,R,S> où C est la catégorie syntaxique, R le rôle du 
segment vis-à-vis de la tâche (objet, (prop quantité) pour une propriété de quantité, etc.) et S un 
λ-terme qui correspond à la traduction de lélément dans le langage cible. Les éventuelles 
ambiguïtés sont levées lors des étapes ultérieures de traitement.  
Segmentation  La segmentation repose sur la composition des λ-termes représentant chaque 
mot, suivant deux règles dérivées de lapplication des grammaires catégorielles de type AB (Bar-
Hillel, 1964 ; Moorgat, 1997) :    (A1) A, A\B ⇒ B (A2) B/A, A ⇒ B 
Par exemple, le chunk adjectival pas trop cher est caractérisé par les applications suivantes : 
« pas »  <adj/adj , (prop R)/(prop R), λx.(pas x)> 
« trop »  <adj/adj, (prop R)/(prop R), λx.x> 
« cher »  <adj,(prop tarif), cher> 
« pas trop cher » <adj, (prop tarif), (λx.(pas x) (λx.x cher))  
                                                                 ≡β(pas cher)>       
La stratégie danalyse suivie correspond à lapplication de toutes les compositions possible, 
associée à une heuristique finale qui privilégie la construction dun minimum de constituants. A 
lissue de la segmentation, les éléments isolés (correspondant à des catégories fractionnaires non 
réduites) sont éliminés. On réalise ainsi un premier traitement des réparations très fragmentaires. 
Ainsi, lhésitation et la préposition corrigée seront éliminées dans lénoncé « un aller simple vers 
euh pour Paris ».  
Dépendances entre segments  Les possibilités de rattachement des segments sont décrites par 
des prédicats logiques qui constituent une connaissance pragmatique spécifique à lapplication. 
Un jeu de règles syntaxico-sémantiques, qui portent sur les triplets <C, R, S>, permet de 
composer progressivement ces différents constituants et dobtenir une formule logique 
représentant le sens de lénoncé. Comme pour ROMUS, on définit des règles propres à la 
caractérisation des relations entre objets et des règles génériques de coordination. Les 
réparations sont également traitées par des règles génériques semblables. Enfin, on a également 
défini des règles qui caractérisent à partir de certains segments lacte de dialogue de lénoncé. 
Antoine J.Y., Goulian J., Villaneau J. 
Les règles sont réparties en plusieurs sous-ensembles correspondant à autant de niveaux 
dapplication successifs suivant une stratégie danalyse incrémentale. Chaque niveau danalyse 
correspond à un relâchement plus important des contraintes sur la caractérisation des 
dépendances. Pour une présentation détaillée de cette application en cascade, on consultera 
(Villaneau, Antoine, Ridoux, 2002). On relèvera seulement que cette stratégie autorise les 
analyses partielles. Enfin, cette étape permet une résolution précoce des co-références les plus 
simples par consultation dun historique des énoncés utilisateur. La figure 5 donne ainsi la 
formule logique qui correspond à la représentation sémantique de lénoncé du paragraphe 4.1. 
 ((requete vouloir) (et  (de (tarif [ ])  (de  (chambre [(taille_chambre double)])  
                                                        (de    (hotel [identification Caumartin]))) 
                                    (de (tarif [ ])  (de (chambre [(taille_chambre double)])  
                                                                 (de    (hotel [identification Crillon])))  )  ) 
Figure 5  Exemple de formule logique obtenue en sortie du système LOGUS 
5 Résultats 
Les systèmes ont été testés au cours dune campagne dévaluation de la compréhension de parole 
réalisée dans le cadre du GDR-I3 du CNRS (Antoine et al., 2002). Cette évaluation avait une 
visée diagnostic ne permettant pas une comparaison directe entre les participants (CLIPS-IMAG, 
IRIT,  LIMSI, VALORIA). Les systèmes ont en effet été testés sur des jeux de tests comparables 
(1200 énoncés présentant les mêmes procédés oraux) mais différents, chaque système 
sintéressant à une tâche spécifique. Le tableau 1 présente les derniers résultats obtenus par nos 
systèmes.  
Type de difficulté ROMUS-2003 LOGUS-2003 
(1) oral spontané 94,2 % (dont 2,9 % compréhension partielle) 98,0 % (dont 4,3 % comp. partielle) 
(2) complexité  94,4 % (dont 4,6 % comp. partielle) 89,7 % (dont 16,7 % comp. partielle) 
(1) et (2) combinés  62,5 % (dont 10,4 % comp. partielle) 85,4 % (dont 23,7 % comp. partielle) 
Tableau 1  Performances (taux dénoncés compris) des systèmes sur les tests de la campagne 
dévaluation par défi du GDR-I3. Chaque système est évalué sur un jeu de test spécifique. 
Compréhension partielle : non-identification déléments « non essentiels » de lénoncé 
Ces résultats sont regroupés par séries de tests. La première regroupe des énoncés comportant 
des procédés de loral spontané ou des dislocations tandis que la seconde concerne des énoncés 
de structure complexe (requêtes multiples, rattachement darguments récursifs, etc.). La dernière 
série combine ces deux difficultés et concerne des énoncés qui se rapprochent du dialogue oral 
humain. On constate que les deux systèmes présentent une robustesse appréciable sur les 
structures linguistiques complexes (à lexclusion de certaines requêtes multiples) ainsi que sur 
des phénomènes de loral spontané tels que les réparations ou les dislocations. Les résultats plus 
mitigés de la troisième série sont à la mesure de la difficulté que représente le traitement 
dénoncés libres proches de la conversation humaine. Ils se retrouvent chez les autres 
participants. 
Par ailleurs, nous avons cherché à évaluer linfluence des erreurs de reconnaissance sur le 
comportement du système ROMUS. Partant de 600 énoncés oraux traités par une dictée vocale 
TAL robuste et langage parlé 
grand public (IBM Via Voice), nous avons obtenu un corpus de test comportant 358 énoncés 
présentant une ou plusieurs erreurs de reconnaissance de type lexical (insertion, substitution ou 
élision) et 140 énoncés présentant au moins une erreur daccord. Ces erreurs ont eu une 
influence sur la compréhension dans 16% des cas. Elles nont cependant jamais conduit à une 
représentation erronée de lénoncé, mais simplement à la construction de structures incomplètes. 
6 Conclusion et perspectives 
ROMUS et LOGUS participeront à la prochaine campagne dévaluation MEDIA-EVALDA sur 
la compréhension de parole en contexte dialogique. Cette évaluation, qui portera sur le 
renseignement touristique, devrait permettre de mieux situer la pertinence de notre approche. 
Dans limmédiat, nous poursuivons ces recherches en étendant notre stratégie incrémentale 
robuste dans deux directions : 
• Pré-traitement des réparations de loral spontané fondé sur une analyse superficielle de 
lénoncé intégrant toutefois une information morpho-syntaxique. Contrairement aux 
approches classiques du domaine (Heeman, 1997), cette normalisation ne sera pas 
destructrice. Elle se limitera en effet à la délimitation et non à la correction des réparations. 
• Interprétation contextuelle des énoncés oraux en amont du dialogue. Lobjectif est 
didentifier et de résoudre de certaines co-références ne nécessitant pas une analyse fine du 
dialogue et de lévolution de la tâche. Cette étape générique sinspire de techniques issues 
du TAL robuste et appliquées jusquici à lécrit (Mitkov, 1998). Les co-références non 
résolues à ce stade (sous-spécification de lanalyse) seront ensuite confiées au contrôleur 
de dialogue suivant une stratégie incrémentale. 
Références 
Abney S. (1991), Parsing by chunks, In. Berwick, Abney, Tenny (Eds.) Principle-based parsing. 
Amsterdam, Kluwer Academic Publishers 
Aït-Mokhtar S., Chanod J.-P., Roux C. (2003), Robustness beyond shallowness: incremental 
deep parsing, Natural Language Enginerring, Vol. 8 (3-2). 
Antoine J.-Y., Goulian J. (2001), Etude des phénomènes dextraction en français parlé sur deux 
corpus de dialogue finalisé, Traitement Automatique des Langues, 42(2), pp. 413-440. 
Antoine J.-Y. et al. (2002), Predictive and objective evaluation of speech understanding : the 
« challenge » evaluation campaign of the I3 speech workgroup of the French CNRS. Actes 
LREC2002, Las Palmas de Gran Canaria, Espagne, pp. 529-536. 
Bar-Hillel Y. (1964). Language and information. Addison-Wesley, Reading, Etats-Unis. 
Belleannée C., Brisset P., Ridoux O. (1999) A pragmatic reconstruction of λProlog. Journal of 
Logic Programming, 41(1). 67-10 
Blanche-Benveniste C. (1997), Approches de la langue parlée en français, Coll. Lessentiel 
Français, Paris, France : Ophrys. 
Antoine J.Y., Goulian J., Villaneau J. 
Cunningham H. (2000), A definition and short history of Language Engineering, Natural 
Language Enginerring, Vol. 5(1), pp.1-16. 
Ejerhed E. (1993), Nouveaux courants en analyse syntaxique, TAL, 34(1), pp.61-82. 
Goulian J. (2002), Stratégie danalyse détaillée pour la compréhension automatique robuste de 
la parole. Thèse de doctorat. Vannes : Université de Bretagne Sud. 13 décembre 2002. 
Heeman P. (1997), Speech repairs, intonational boundaries and discourse markers : modeling 
speakers utterances in spoken dialog. PhD dissertation, University of Rochester. 
Kamp H., Reyle U. (1993), From discourse to logic, Amsterdam : Kluwer Academic Publ. 
Mitkov R., (1998) Robust pronoun resolution with limited knowledge, COLING98/ACL98. 
Montréal, Canada, pp. 869-875. 
Moorgat M. (1997), Categorial type logics. In van Benthem J., ter Meulen A. (Eds.) Handbook 
of logic and language. Elsevier Sciences, North-Holland, Amsterdam, Pays-Bas, pp. 93-177. 
van Noord G., Bouma G., Koeling R., Nederhof M.J. (1999), Robust grammatical analysis for 
spoken dialogue systems. Natural Language Enginerring, 5(1).  
Pérennou G. (1996), Compréhension du dialogue oral : le rôle du lexique dans lapproche par 
segments conceptuels. Actes de latelier Lexique et Communication Parlée, GDR-PRC CHM, 
Toulouse, France. pp. 169-178. 
Seneff  S. (1992), Robust parsing for spoken language systems. International Conference on 
Acoustics, Speech and Signal, ICASSP1992, San Francisco, Etats-Unis, pp. 189-192. 
Sleator D. D. K., Temperley D. (1991), Parsing English with a link grammar, rapport CMU-CS-
91-196, School of Computer Science, Carnegie Mellon University, Pittsburgh. 
Vanderveken D. (1994), A complete formulation of a simple logic of elementary illocutionary 
acts. In Tsohatzidis S. L. (Ed.), Foundations of speech act theory : philosophical and linguistic 
perspectives. Routldege, pp. 99-131. 
Villaneau J., Antoine J.-Y., Ridoux O. (2002), LOGUS : un système formel de compréhension 
du français parlé spontané. Actes TALN2002, Nancy, France, pp. 165-174. 
Zechner K. (1998), Automatic construction of frame representations for spontaneous speech in 
unrestricted domains. Actes COLING-ACL1998. Montréal, Canada, pp. 1448-1452. 
