<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique : r&#233;sultats sur les cooccurrences</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2003, Batz-sur-Mer, 11-14 juin 2003 
</p>
<p>Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique : 
r&#233;sultats sur les cooccurrences 
</p>
<p>Laurent AUDIBERT 
</p>
<p>Jeune &#233;quipe DELIC &#150; Universit&#233; de Provence 
29 Av. Robert SCHUMAN - 13621 Aix-en-Provence Cedex 1 
</p>
<p>laurent.audibert@up.univ-aix.fr 
</p>
<p>R&#233;sum&#233; &#150; Abstract 
</p>
<p>Nous pr&#233;sentons dans cet article une &#233;tude sur les crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique 
automatique bas&#233;s sur les cooccurrences. L&#146;algorithme de d&#233;sambigu&#239;sation utilis&#233; est du type 
liste de d&#233;cision, il s&#233;lectionne une cooccurrence unique suppos&#233;e v&#233;hiculer l'information la 
plus fiable dans le contexte cibl&#233;. Cette &#233;tude porte sur 60 vocables r&#233;partis, de mani&#232;re &#233;gale, 
en trois classes grammaticales (nom, adjectif et verbe) avec une granularit&#233; fine au niveau des 
sens. Nous commentons les r&#233;sultats obtenus par chacun des crit&#232;res &#233;valu&#233;s de mani&#232;re 
ind&#233;pendante et nous nous int&#233;ressons aux particularit&#233;s qui diff&#233;rencient les trois classes 
grammaticales &#233;tudi&#233;es. Cette &#233;tude s&#146;appuie sur un corpus fran&#231;ais &#233;tiquet&#233; s&#233;mantiquement 
dans le cadre du projet SyntSem. 
</p>
<p>This paper describes a study on cooccurrence-based criteria for automatic word sense 
disambiguation. We use a decision-list algorithm which selects the best disambiguating cue in 
the target context. The algorithm is tested on 60 words equally distributed among three parts 
of speech (noun, adjective and verb) with a fine sense granularity. We present the results 
obtained by each criterion evaluated in an independent way and we discuss the characteristics 
which differentiate the three parts of speech studied. The study uses a French sense-tagged 
corpus developed in the SyntSem project. 
</p>
<p>Mots Cl&#233;s &#150; Keywords 
</p>
<p>D&#233;sambigu&#239;sation s&#233;mantique automatique, corpus s&#233;mantiquement &#233;tiquet&#233;, cooccurrences. 
</p>
<p>Word sense disambiguation, sense tagged corpora, cooccurrences. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Laurent AUDIBERT 
</p>
<p>1 Introduction 
</p>
<p>La d&#233;sambigu&#239;sation s&#233;mantique automatique est un enjeu important dans la plupart des 
applications de traitement automatique des langues : recherche d&#146;information, traduction 
automatique, reconnaissance de la parole, etc. (Ide, V&#233;ronis, 1998). Cependant, les ressources 
n&#233;cessaires pour aborder correctement ce probl&#232;me commencent &#224; peine &#224; &#234;tre disponibles. 
Ceci est particuli&#232;rement vrai pour le fran&#231;ais. 
</p>
<p>Nous avons d&#233;j&#224; pr&#233;sent&#233; les d&#233;buts d&#146;un travail visant &#224; rechercher et &#224; &#233;tudier les crit&#232;res de 
d&#233;sambigu&#239;sation s&#233;mantique automatique (Audibert, 2002). Cette &#233;tude pr&#233;liminaire portait 
sur 7 noms avec une granularit&#233; grossi&#232;re au niveau des sens (2 &#224; 3 sens par mot). Nous 
&#233;tendons ici notre &#233;tude &#224; 60 vocables r&#233;partis, de mani&#232;re &#233;gale, en trois classes 
grammaticales (nom, adjectif et verbe) avec une granularit&#233; de sens bien plus fine (18 lexies 
par vocable en moyenne). Nous pr&#233;sentons une s&#233;rie de r&#233;sultats sur le pouvoir 
d&#233;sambigu&#239;sateur de crit&#232;res bas&#233;s sur les cooccurrences1 sans chercher &#224; combiner ces 
crit&#232;res. Nous appelons crit&#232;re, un ensemble de &#171; ph&#233;nom&#232;nes &#187; susceptibles de survenir dans 
le contexte d'un vocable (ex : lemme des cooccurrences).   
</p>
<p>2 M&#233;thodologie 
</p>
<p>2.1 Corpus de travail 
</p>
<p>La premi&#232;re phase de notre travail est l'&#233;tiquetage de notre corpus avec le logiciel Cordial 
Analyseur (d&#233;velopp&#233; par la soci&#233;t&#233; Synapse D&#233;veloppement), qui offre une lemmatisation et 
un &#233;tiquetage morpho-syntaxique d&#146;une exactitude satisfaisante (Valli, V&#233;ronis, 1999). Cette 
phase nous affranchit de toute ambigu&#239;t&#233; cat&#233;gorielle comme le pr&#233;conise (Kilgarriff, 1997). 
</p>
<p>L&#146;une des difficult&#233;s majeures de l&#146;&#233;tiquetage s&#233;mantique automatique r&#233;side dans 
l&#146;inad&#233;quation des dictionnaires traditionnels (V&#233;ronis, 2001) ou d&#233;di&#233;s (Palmer, 1998) pour 
cette t&#226;che. Une autre difficult&#233; (Gale, Church, Yarowsky, 1993) provient du manque de 
corpus s&#233;mantiquement &#233;tiquet&#233;s sur lesquels des m&#233;thodes d'apprentissage supervis&#233; peuvent 
&#234;tre entra&#238;n&#233;es. Ce manque se transforme m&#234;me en absence totale pour une langue comme le 
fran&#231;ais alors qu&#146;il commence &#224; appara&#238;tre de tels corpus pour l'anglais, notamment dans le 
cadre de l'action d'&#233;valuation Senseval (Kilgarriff, Rosenzweig, 2000). Pour ces multiples 
raisons, notre &#233;quipe a entrepris la construction d&#146;un dictionnaire distributionnel en se basant 
sur un ensemble de crit&#232;res diff&#233;rentiels stricts (Reymond, 2001). Ce dictionnaire comporte 
pour l'instant la description d&#233;taill&#233;e de 20 noms, 20 verbes et 20 adjectifs totalisant plus de 
53000 occurrences dans le corpus du projet SyntSem2 (Corpus d&#146;environ 5.5 millions de 
</p>
<p>                                                 
1  Nous emploierons, dans cet article, le mot &#171; cooccurrence &#187; dans son acception la plus large, c&#146;est-&#224;-dire des 
</p>
<p>mots apparaissant dans le contexte, sans contrainte de fr&#233;quence, de figement ou de lien syntaxique. 
2  Le projet SyntSem, financ&#233; par l&#146;ELRA/ELDA, vise &#224; produire un corpus &#233;tiquet&#233; au niveau morpho-
</p>
<p>syntaxique avec en plus un marquage syntaxique peu profond et un marquage s&#233;mantique de mots 
s&#233;lectionn&#233;s. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique 
</p>
<p>mots, compos&#233; de textes de genres vari&#233;s). C&#146;est sur ce corpus que nous r&#233;alisons 
l'entra&#238;nement et l'&#233;valuation de nos algorithmes de d&#233;sambigu&#239;sation s&#233;mantique. 
</p>
<p>Les donn&#233;es d&#146;apprentissage, sur lesquelles nous entra&#238;nons et &#233;valuons nos algorithmes, sont 
fonction du crit&#232;re &#233;tudi&#233;. Nous avons d&#233;velopp&#233; un outil (Audibert, 2001) qui permet de 
mod&#233;liser un crit&#232;re et de l&#146;appliquer au corpus pour g&#233;n&#233;rer les donn&#233;es d&#146;apprentissage. 
</p>
<p>2.2 Vocables &#233;tudi&#233;s 
</p>
<p>NOMS ADJECTIFS VERBES 
Vocable freq lex H 2H Vocable freq lex H 2H Vocable freq lex H 2H 
</p>
<p>barrage 92 5 1,18 2,26 correct 116 5 1,81 3,50 couvrir 518 21 3,25 9,51 
restauration 104 5 1,85 3,60 sain 129 10 2,45 5,46 importer 576 8 2,57 5,93 
suspension 110 5 1,50 2,82 courant 168 4 0,63 1,55 parvenir 653 8 2,31 4,97 
</p>
<p>d&#233;tention 112 2 0,85 1,80 r&#233;gulier 181 11 2,54 5,82 exercer 698 8 1,52 2,88 
lancement 138 5 0,99 1,99 frais 182 18 3,10 8,57 conclure 727 16 2,36 5,13 
</p>
<p>concentration 246 6 1,98 3,93 secondaire 195 5 1,69 3,23 arr&#234;ter 913 15 2,97 7,85 
station 266 8 2,58 5,98 strict 220 9 2,23 4,69 ouvrir 919 41 3,80 13,92
</p>
<p>vol 278 10 2,20 4,61 exceptionnel 226 3 1,45 2,73 poursuivre 978 16 2,71 6,53 
organe 366 6 2,24 4,71 utile 359 9 2,39 5,23 tirer 1001 47 3,88 14,72
</p>
<p>compagnie 412 12 1,62 3,08 vaste 368 6 2,08 4,22 conduire 1082 15 2,28 4,85 
constitution 422 6 1,64 3,13 sensible 425 11 2,63 6,19 entrer 1210 38 3,65 12,55
</p>
<p>degr&#233; 507 18 2,47 5,53 traditionnel 447 2 0,49 1,40 conna&#238;tre 1635 16 2,24 4,71 
observation 572 3 0,68 1,60 populaire 457 5 2,02 4,05 rendre 1985 27 2,88 7,35 
</p>
<p>passage 601 19 2,70 6,49 biologique 475 4 0,55 1,46 comprendre 2136 13 2,76 6,79 
solution 880 4 0,44 1,36 clair 556 20 3,10 8,57 pr&#233;senter 2140 18 2,56 5,90 
</p>
<p>&#233;conomie 930 10 2,16 4,46 historique 620 3 0,67 1,59 porter 2328 59 4,01 16,07
pied 960 62 3,55 11,70 s&#251;r 645 14 2,61 6,12 r&#233;pondre 2529 9 0,99 1,99 
chef 1133 11 1,47 2,77 plein 844 35 3,99 15,93 passer 2547 83 4,49 22,49
</p>
<p>formation 1528 9 1,66 3,17 haut 1016 29 3,46 10,98 venir 3788 33 3,21 9,29 
communication 1703 13 2,44 5,42 simple 1051 14 2,14 4,41 mettre 5095 140 3,65 12,55
</p>
<p>Total 11360    Total 8680    Total 33458    
Tableau 1 : Les 60 vocables avec la fr&#233;quence (freq), le nombre de lexies (lex),  
l&#146;entropie de la fr&#233;quence des lexies (H) et le nombre de lexies &#233;quiprobables  
</p>
<p>n&#233;cessaires pour une m&#234;me entropie (perplexit&#233; : 2H) 
</p>
<p>Le Tableau 1 d&#233;taille l&#146;ensemble des 60 vocables de notre &#233;tude. On notera la grande disparit&#233; 
de la fr&#233;quence de ces vocables. Le moins fr&#233;quent &#233;tant barrage, avec une fr&#233;quence de 92, 
et le plus fr&#233;quent &#233;tant le verbe mettre, avec une fr&#233;quence de 5095. On remarquera 
&#233;galement que le nombre de lexies peut atteindre 140 pour le verbe mettre. Nous travaillons 
avec une granularit&#233; au niveau des sens relativement importante : environ 11 lexies par 
vocable en moyenne pour les noms et les adjectifs et plus de 30 pour les verbes.  
</p>
<p>Cependant, le nombre de lexies n&#146;est pas un bon indice de la difficult&#233; de la t&#226;che. En effet, il 
est plus facile de lever l&#146;ambigu&#239;t&#233; d&#146;un vocable ayant 10 lexies, mais dont la quasi-totalit&#233; 
des occurrences est regroup&#233;e sous une seule lexie, que de lever l&#146;ambigu&#239;t&#233; d&#146;un vocable 
comportant 2 lexies &#233;quiprobables. L&#146;entropie de la r&#233;partition des occurrences du vocable 
sur ses diff&#233;rentes lexies est un meilleur indicateur de la difficult&#233; de la lev&#233;e de l&#146;ambigu&#239;t&#233; 
pour ce vocable, d&#146;o&#249; la pr&#233;sence de la colonne (H), pour l&#146;entropie, et de la colonne (2H) qui 
mesure la perplexit&#233;, ce qui peut s&#146;av&#233;rer plus parlant. Ainsi, pour une entropie inchang&#233;e, si 
les lexies &#233;taient &#233;quiprobables, les noms auraient une moyenne de 4 lexies par vocables, les 
adjectifs de plus de 5 et les verbes de pratiquement 9. Il s&#146;agit l&#224; d&#146;un indice qui laisse 
pr&#233;sager une plus grande difficult&#233; pour lever l&#146;ambigu&#239;t&#233; des adjectifs, et encore plus des 
verbes, par rapport aux noms. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Laurent AUDIBERT 
</p>
<p>2.3 D&#233;finition des crit&#232;res 
</p>
<p>Il existe de nombreuses sources d&#146;information pour lever l&#146;ambigu&#239;t&#233; du sens des mots. 
Comme l&#146;ont montr&#233; (McRoy, 1992), (Wilks, Stevenson, 1998) ou encore (Ng, Lee, 1996) 
toutes ces sources peuvent &#234;tre utilis&#233;es simultan&#233;ment pour aboutir &#224; une meilleure 
d&#233;sambigu&#239;sation. Nous avons d&#233;j&#224; pr&#233;sent&#233; un inventaire non exhaustif des crit&#232;res qui 
peuvent &#234;tre &#233;tudi&#233;s (Audibert, 2002). 
</p>
<p>De nombreuses &#233;tudes, comme par exemple (Ng, Lee, 1996), (Mooney, 1996) ou encore 
(Yarowsky, 1993), montrent que les cooccurrences constituent un bon crit&#232;re pour identifier 
le sens d&#146;un mot. Dans cette &#233;tude, nous nous proposons d&#146;&#233;tudier des crit&#232;res &#233;l&#233;mentaires, 
bas&#233;s sur les cooccurrences, sans chercher &#224; les combiner. Notre objectif est de fournir des 
informations de r&#233;f&#233;rence pour l&#146;&#233;laboration de crit&#232;res plus complexes et de r&#233;pondre &#224; des 
questions comme l&#146;int&#233;r&#234;t de la lemmatisation, l&#146;utilit&#233; des fen&#234;tres de mots sans distinction 
de position (unordered set of surrounding words en anglais), l&#146;importance des mots 
grammaticaux ou encore les diff&#233;rences de comportement entre les cat&#233;gories grammaticales. 
</p>
<p>2.4 Algorithme de d&#233;sambigu&#239;sation 
</p>
<p>L'algorithme de classification des lexies utilis&#233; est du type liste de d&#233;cision (Rivest, 1987) 
pour sa simplicit&#233; de mise en &#156;uvre et son efficacit&#233;. Cette approche ne combine pas 
l'information de tous les attributs de la description dont on cherche &#224; d&#233;terminer la classe, 
mais se focalise sur un attribut unique, suppos&#233; v&#233;hiculer l'information la plus fiable. 
L&#146;algorithme ici utilis&#233; diff&#232;re de celui de l&#146;&#233;tude pr&#233;liminaire (Audibert, 2002) bas&#233; sur une 
mesure de dispersion. Il s&#146;agit d&#146;un algorithme tr&#232;s proche de celui de (Golding, 1995) qui 
constitue une g&#233;n&#233;ralisation &#224; plus de deux classes de l&#146;algorithme de (Yarowsky, 1995). 
</p>
<p>Soit un exemple E dont nous d&#233;sirons d&#233;terminer la lexie la plus probable lE, parmi un 
ensemble de lexies possibles L, en se basant sur la description D de E compos&#233;e d'un certain 
nombre d'indices D={i1 &#133; in} g&#233;n&#233;r&#233;s par l&#146;application du crit&#232;re &#233;tudi&#233; sur l&#146;exemple E. Soit 
A l'ensemble des indices des exemples d'apprentissage g&#233;n&#233;r&#233;s par l&#146;application du crit&#232;re 
&#233;tudi&#233; sur le corpus d&#146;apprentissage. 
</p>
<p>La lexie choisie est d&#233;termin&#233;e en se basant sur l&#146;indice consid&#233;r&#233; comme &#233;tant le plus fiable 
dans la liste de d&#233;cision : ( ))/(maxarg IndFialexiepl
</p>
<p>Llexie
E
</p>
<p>&#8712;
=  
</p>
<p>L&#146;indice le plus fiable de la liste est : ( ))(maxarg indicefiabilit&#233;IndFia
ADindice &#8745;&#8712;
</p>
<p>= . 
</p>
<p>La mesure utilis&#233;e pour ordonner les indices est : ( ))/(max)( indicelexiepindicefiabilit&#233;
Llexie&#8712;
</p>
<p>= . 
</p>
<p>Lorsque les indices de la description n&#146;ont jamais &#233;t&#233; rencontr&#233;s dans le corpus 
d&#146;apprentissage, AD&#8745;  est vide et il n&#146;y a pas d&#146;indice le plus fiable IndFia. Dans ce cas, la 
lexie choisie est la lexie la plus fr&#233;quente.  
</p>
<p>L&#146;estimation des probabilit&#233;s p(lexie/indice) se fait sur les exemples d&#146;apprentissage. Nous 
utilisons une m-estimation (Cussens, 1993) en raison de certains d&#233;nombrements faibles et 
</p>
<p>parfois nuls : mn
pmnindicelexiep
</p>
<p>indice
</p>
<p>indicelexieindicelexie
</p>
<p>+
+= ,, .)/( . 
</p>
<p>&#8226; nlexie,indice est le nombre d&#146;exemples d&#146;apprentissage dont la description contient 
l&#146;indice indice et dont la lexie du vocable &#233;tudi&#233; est lexie ; </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique 
</p>
<p>&#8226; nindice est le nombre d&#146;exemples d&#146;apprentissage dont la description contient l&#146;indice 
indice ; 
</p>
<p>&#8226; plexie,indice est une estimation a priori de la probabilit&#233; recherch&#233;e, comme nous ne 
connaissons pas cette estimation, nous supposons une r&#233;partition uniforme de 
probabilit&#233; et nous posons )(
</p>
<p>1, Lcardp indicelexie =  ; 
</p>
<p>&#8226; m est une constante &#224; d&#233;terminer. 
Le lissage r&#233;alis&#233; dans (Golding, 1995) revient &#224; fixer m=card(L). D&#146;apr&#232;s notre exp&#233;rience, 
poser indicefr&#233;quencem=  donne de bien meilleurs r&#233;sultats. 
</p>
<p>Pour &#233;valuer un crit&#232;re sur le corpus, nous utilisons une m&#233;thode d&#146;&#233;valuation crois&#233;e k fois 
(k-fold cross validation en anglais), conform&#233;ment &#224; l&#146;usage commun, k=10 dans notre 
exp&#233;rience. Cette m&#233;thode est co&#251;teuse en temps de calcul mais permet d&#146;&#233;valuer le crit&#232;re 
sur la totalit&#233; du corpus. 
</p>
<p>3 R&#233;sultats de notre &#233;tude 
</p>
<p>Nous appelons pr&#233;cision de l&#146;&#233;tiquetage majoritaire (Gale, Church, Yarowsky, 1992) la 
pr&#233;cision obtenue en &#233;tiquetant toutes les occurrences avec la lexie la plus fr&#233;quente. 
</p>
<p>Nous appelons pr&#233;cision le rapport entre le nombre d&#146;&#233;tiquetages corrects et le nombre 
d&#146;&#233;tiquetages effectu&#233;s :  
</p>
<p>Pr&#233;cision = (Nombre d&#146;&#233;tiquetages corrects) / (Nombre d&#146;&#233;tiquetages effectu&#233;s). 
</p>
<p>Nous appelons gain l&#146;am&#233;lioration de la pr&#233;cision obtenue par rapport &#224; la pr&#233;cision d&#146;un 
&#233;tiquetage majoritaire : 
</p>
<p>Gain = ( Pr&#233;cision(&#233;tiq.) - Pr&#233;cision(&#233;tiq. majoritaire) ) / ( 1 - Pr&#233;cision(&#233;tiq. majoritaire) ). 
</p>
<p>3.1 Evaluation de diff&#233;rents crit&#232;res 
</p>
<p>La Figure 1 montre la pr&#233;cision de la d&#233;sambigu&#239;sation obtenue par huit crit&#232;res. Les noms de 
ces crit&#232;res pr&#233;cisent leur nature et sont de la forme [info1]-[info2]-[info3]. info3 indique si le 
crit&#232;re consid&#232;re tous les mots ou seulement les mots pleins. info2 indique si les mots 
consid&#233;r&#233;s sont diff&#233;renci&#233;s par leur position ou pas. info1 indique si l&#146;on regarde la forme 
brute des mots ou leur lemme. Le Tableau 2 permet de synth&#233;tiser les informations de la 
Figure 1.  
</p>
<p>On peut remarquer que tous ces crit&#232;res atteignent leur meilleure pr&#233;cision pour de petites 
fen&#234;tres allant de &#177;1 mot &#224; &#177;4 mots. Dans tous les cas, le retrait des mots grammaticaux se 
traduit par une baisse significative des performances. Traiter les mots sans tenir compte de 
leur position par rapport au mot &#224; d&#233;sambigu&#239;ser entra&#238;ne &#233;galement une baisse des 
performances. De plus, les performances des crit&#232;res qui tiennent compte de la position des 
mots pr&#233;sentent une dynamique moins importante. Ces crit&#232;res sont ainsi moins sensibles que 
les autres au choix de la taille du contexte. Cette robustesse constitue une raison de plus de les 
privil&#233;gier. Enfin, la lemmatisation n&#146;a permis une augmentation significative des 
performances que pour les adjectifs.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Laurent AUDIBERT 
</p>
<p>3.2 Particularit&#233;s des cat&#233;gories grammaticales 
</p>
<p>En observant la Figure 1 on peut d&#233;j&#224; relever trois diff&#233;rences de comportement entre les 
noms, les adjectifs et les verbes. La premi&#232;re diff&#233;rence se situe au niveau des pr&#233;cisions 
atteintes. La pr&#233;cision de l&#146;&#233;tiquetage r&#233;alis&#233; est la meilleure pour les noms, elle est moins 
bonne pour les adjectifs et encore moins bonne pour les verbes. Comme nous l&#146;avions pr&#233;dit 
dans la section 2.2, cela peut s&#146;expliquer par le nombre moyen de lexies par vocable. Si l&#146;on 
&#233;tiquette chaque occurrence d&#146;un vocable avec sa lexie la plus fr&#233;quente (&#233;tiquetage 
majoritaire) on obtient une pr&#233;cision de 57% pour les noms, 46% pour les adjectifs et 37% 
pour les verbes (cf. Tableau 2). Ainsi le gain r&#233;alis&#233; par le meilleur crit&#232;re pour chaque 
cat&#233;gorie de vocable est de 52% pour les noms, 53% pour les adjectifs et 50% pour les verbes 
(cf. Tableau 2). Ces chiffres montrent bien que l&#146;algorithme et les crit&#232;res de 
d&#233;sambigu&#239;sation utilis&#233;s fonctionnent aussi bien pour nos trois cat&#233;gories de vocables.  
</p>
<p>La seconde diff&#233;rence est la pente de la d&#233;croissance de la pr&#233;cision qui est bien plus 
importante pour les adjectifs et les verbes que pour les noms (cf. Figure 1). Nous avons tent&#233; 
</p>
<p> 
Figure 1 : Pr&#233;cision des 8 crit&#232;res pour les 3 cat&#233;gories de vocables 
</p>
<p>Cat&#233;gorie Grammaticale 
Noms Adjectifs Verbes Crit&#232;re 
</p>
<p>R T P % G % R T P % G % R T P % G %
[lemme]- [ordonn&#233;] -[tous] 2 4 78,9 50,7 1 3 74,9 53,2 1 3 68,9 50,4
</p>
<p>[mot]- [ordonn&#233;] -[tous] 1 3 79,4 51,8 3 1 73,8 51,2 2 3 68,6 49,9
[lemme]- [non-ordonn&#233;] -[tous] 8 3 76,1 44,1 2 1 74,1 51,7 4 3 65,3 44,6
</p>
<p>[mot]- [non-ordonn&#233;] -[tous] 7 4 76,2 44,2 4 1 73,3 50,1 3 3 65,7 45,3
[lemme]- [ordonn&#233;] -[mots pleins] 3 1 77,9 48,2 6 1 70,7 45,3 5 1 62,2 39,7
</p>
<p>[mot]- [ordonn&#233;] -[mots pleins] 4 1 77,4 47,2 5 1 71,0 45,8 6 2 61,0 37,8
[lemme]- [non-ordonn&#233;] -[mots pleins] 5 1 77,3 47,0 8 1 70,4 44,8 8 2 59,1 34,7
</p>
<p>[mot]- [non-ordonn&#233;] -[mots pleins] 6 1 76,2 44,3 7 1 70,5 45,0 7 2 59,7 35,7
Etiquetage majoritaire 9 x 57,3 0 9 x 46,4 0 9 x 37,4 0 
</p>
<p>Tableau 2 : Meilleure pr&#233;cision (colonne P) et donc meilleur gain (colonne G) des 8 crit&#232;res 
pour les 3 cat&#233;gories de vocables, la colonne R indique le rang du crit&#232;re (du meilleur 1 
</p>
<p>au moins bon 8) et la colonne T indique la taille du demi-contexte </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique 
</p>
<p>de d&#233;sambigu&#239;ser chacun de nos 60 vocables en 
regardant une fen&#234;tre de 4 mots pleins situ&#233;e &#224; une 
distance de &#177;x mots de la cible. Les courbes de la 
Figure 2 montrent le gain obtenu en fonction de cette 
distance de x mots. On observe imm&#233;diatement que 
lorsque l&#146;on s&#146;&#233;loigne de la cible, le gain tend vers z&#233;ro 
de mani&#232;re beaucoup plus rapide pour les adjectifs et 
les verbes que pour les noms. L&#146;information qui permet 
de lever l&#146;ambigu&#239;t&#233; d&#146;un vocable est donc plus 
concentr&#233;e autour de ce vocable quand il s&#146;agit d&#146;un 
verbe ou d&#146;un adjectif que quand il s&#146;agit d&#146;un nom. 
</p>
<p>La troisi&#232;me diff&#233;rence tient dans la m&#233;diocrit&#233; de la d&#233;sambigu&#239;sation des verbes pour un 
contexte de &#177;1 mot, et ce, m&#234;me s&#146;il s&#146;agit de mots pleins. Nous apporterons une explication &#224; 
ce ph&#233;nom&#232;ne dans la suite de cette section. 
</p>
<p>En utilisant le crit&#232;re [mot]-[ordonn&#233;]-[tous], qui consid&#232;re tous les mots en tenant compte de 
leur position et sans lemmatisation, avec un contexte de &#177;3 mots, nous nous sommes int&#233;ress&#233; 
&#224; la cat&#233;gorie grammaticale du mot ayant servi &#224; la lev&#233;e de l&#146;ambigu&#239;t&#233; (Tableau 3). Cette 
exp&#233;rience permet d&#146;observer que les adjectifs sont les mots qui permettent le mieux de 
d&#233;sambigu&#239;ser les noms (pr&#233;cision de 95.3%) et qu&#146;ils sont utilis&#233;s dans 12.4% des cas (sur 
un total de 11360 cas, cf. Tableau 1). Les noms donnent de bons r&#233;sultats pour d&#233;sambigu&#239;ser 
nos trois cat&#233;gories de vocables, et sp&#233;cialement les adjectifs et les verbes pour lesquels ils 
sont utilis&#233;s dans environ 25% des cas. Les verbes &#224; l&#146;infinitif fonctionnent bien pour les trois 
cat&#233;gories, ce qui n&#146;est pas forc&#233;ment le cas des autres formes verbales. Les adverbes 
fonctionnent bien pour d&#233;sambigu&#239;ser les adjectifs. Au niveau des mots grammaticaux, on 
observe que les pr&#233;positions sont int&#233;ressantes pour les noms, les d&#233;terminants pour les 
adjectifs et les pronoms personnels pour les verbes. 
</p>
<p>Nous avons &#233;galement cherch&#233; &#224; observer comment les principales cat&#233;gories grammaticales 
se r&#233;partissaient autour de nos trois cat&#233;gories de vocables &#224; d&#233;sambigu&#239;ser. La Figure 3 
montre les pourcentages des principales cat&#233;gories grammaticales utilis&#233;es pour 
d&#233;sambigu&#239;ser le vocable en fonction de la position o&#249; se trouvait le mot utilis&#233; pour la lev&#233;e 
de l&#146;ambigu&#239;t&#233;. 
</p>
<p>Figure 2 : Gain des 3 cat&#233;gories 
</p>
<p>Tableau 3 : Principales cat&#233;gories grammaticales des mots utilis&#233;es pour lever l&#146;ambigu&#239;t&#233; 
</p>
<p>NOMS ADJECTIFS VERBES 
Cat&#233;gorie P % Utilis. % Cat&#233;gorie P % Utilis. % Cat&#233;gorie P % Utilis. %
</p>
<p>Adjectifs 95,3 12,4 Noms 93,4 24,2 Noms 87,6 25,3 
Verbes &#224; l'inf. 87,3 0,6 Adverbes 81,1 8,9 Conj. de sub. 82,6 2,6 
</p>
<p>Noms 82,0 32,6 Verbes &#224; l'inf. 80,7 0,7 Verbes &#224; l'inf. 75,6 3,7 
Verbes au par. 81,1 0,3 Adjectifs 68,8 19,3 Pronoms pers. 68,9 9,8 
</p>
<p>Pr&#233;positions 79,9 19,1 D&#233;terminants 68,5 15,6 Adjectifs 67,1 3,0 
Conjonctions 75,0 3,1 Pronoms pers. 68,0 2,6 Pr&#233;positions 65,4 15,2 
D&#233;terminants 72,2 20,8 Conj. de coord. 66,1 3,4 Adverbes 63,8 4,8 
Verbes conj. 63,6 1,0 Verbes restants 48,1 2,4 Verbes restants 59,1 16,5 
</p>
<p>Autres 67,6 10,0 Autres 60,6 23,1 Autres 52,6 19,2 
TOTAL 79,4 100,0 TOTAL 73,3 100,0 TOTAL 68,6 100,0 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Laurent AUDIBERT 
</p>
<p>La position 0 est celle du vocable &#224; 
d&#233;sambigu&#239;ser. On peut remarquer que 
la forme du vocable &#224; d&#233;sambigu&#239;ser est 
utilis&#233;e dans 17% des cas pour les noms, 
14 % pour les adjectifs et 12% pour les 
verbes. On pourrait penser que la 
pr&#233;cision de l&#146;&#233;tiquetage, quand elle est 
bas&#233;e sur la seule forme du mot &#224; 
d&#233;sambigu&#239;ser, doit &#234;tre proche de la 
pr&#233;cision d&#146;un &#233;tiquetage majoritaire. 
En fait, il n&#146;en est rien. Le gain obtenu, 
lorsque c&#146;est la forme du mot &#224; 
d&#233;sambigu&#239;ser qui a permis de lever 
l&#146;ambigu&#239;t&#233;, est de 45% pour les noms, 
42% pour les adjectifs et 37% pour les 
verbes. 
</p>
<p>Les noms qui permettent de lever 
l&#146;ambigu&#239;t&#233; des adjectifs sont 
directement coll&#233;s &#224; cet adjectif et se 
trouvent indiff&#233;remment &#224; droite ou &#224; 
gauche. 
</p>
<p>La dissym&#233;trie de la figure des verbes 
est tr&#232;s instructive. Tout d&#146;abord elle 
permet d&#146;expliquer la forme des courbes 
de la Figure 1. En effet, nous avions 
remarqu&#233; la m&#233;diocrit&#233; de la 
d&#233;sambigu&#239;sation des verbes pour un 
contexte de &#177;1 mot. On comprend 
maintenant pourquoi, contrairement aux 
</p>
<p>noms et aux adjectifs o&#249; la majeure partie de l&#146;information permettant la lev&#233;e de l&#146;ambigu&#239;t&#233; 
&#233;tait puis&#233;e en position &#150;1 et +1, la majeure partie de l&#146;information pour les verbes se trouve 
en position +2 et une part non n&#233;gligeable se trouve en +3. Ensuite, on peut se rendre compte 
que la d&#233;sambigu&#239;sation des verbes se fait plus en fonction de leur objet que de leur sujet 
puisque la forme sujet-verbe-compl&#233;ment est la plus fr&#233;quente. Enfin, la forme de ce 
graphique inciterait &#224; ne pas utiliser un contexte sym&#233;trique mais plut&#244;t un contexte 
dissym&#233;trique de la forme &#150;2 +4 par exemple.  
</p>
<p>Sur les particularit&#233;s des cat&#233;gories grammaticales (Yarowsky, 1993) obtenait des r&#233;sultats 
analogues sur l&#146;anglais en se limitant &#224; deux lexies par mot et en utilisant des pseudo-mots 
poss&#233;dant deux &#171; sens &#187;. Ces pseudo-mots peuvent &#234;tre obtenus en fusionnant deux mots 
quelconques, ou homographes dans une autre langue, ou encore ne se distinguant que par une 
seule lettre, en un seul en gardant l&#146;information du mot d&#146;origine. Ces pseudo-mots 
permettent d&#146;obtenir directement des corpus de grande taille en s&#146;affranchissant de la phase 
d&#146;&#233;tiquetage manuel. 
</p>
<p>Figure 3 : R&#233;partition, autour du mot &#224; 
d&#233;sambigu&#239;ser, des principales cat&#233;gories 
</p>
<p>grammaticales utilis&#233;es pour lever l&#146;ambigu&#239;t&#233;. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique 
</p>
<p>4 Perspectives et conclusion 
</p>
<p>Le travail pr&#233;sent&#233; dans cet article sera &#233;tendu &#224; d&#146;autres crit&#232;res pour mesurer, par exemple, 
l&#146;utilit&#233; des &#233;tiquettes morpho-syntaxique ou des n-grammes. Il faudra &#233;galement &#233;tudier les 
interactions entre ces crit&#232;res de mani&#232;re &#224; pouvoir les utiliser conjointement pour aboutir &#224; 
une d&#233;sambigu&#239;sation automatique plus efficace et plus robuste. 
</p>
<p>On peut remarquer que, parmi les travaux similaires d&#233;j&#224; r&#233;alis&#233;s, peu l&#146;ont &#233;t&#233; sur des corpus 
manuellement &#233;tiquet&#233;s en raison de leur raret&#233;. Pour pallier ce probl&#232;me, les chercheurs 
utilisent souvent des pseudo-mots qui ne comportent que deux &#171; sens &#187; et dont les contextes 
sont parfois tr&#232;s distincts, ce qui facilite leur d&#233;sambigu&#239;sation et biaise les r&#233;sultats. Notre 
&#233;tude porte sur de &#171; vrais &#187; mots et s&#146;appuie sur un corpus de taille suffisante manuellement 
&#233;tiquet&#233;. D&#146;autre part, l&#146;une des difficult&#233;s de l&#146;&#233;tiquetage s&#233;mantique automatique r&#233;side 
dans l&#146;inad&#233;quation des dictionnaires traditionnels. Pour cette raison, notre corpus a &#233;t&#233; 
&#233;tiquet&#233; en utilisant les d&#233;finitions d&#146;un dictionnaire distributionnel &#233;tabli sur un ensemble de 
crit&#232;res diff&#233;rentiels stricts. 
</p>
<p>Cette &#233;tude a port&#233; sur 60 vocables r&#233;partis en 20 noms, 20 adjectifs et 20 verbes. Le nombre 
de lexies est de pratiquement 18 en moyenne pour ces 60 mots. Les r&#233;sultats obtenus sur des 
crit&#232;res simples et sans combinaison de plusieurs crit&#232;res sont encourageants. La pr&#233;cision 
moyenne obtenue atteint 79% pour les noms, 75% pour les adjectifs et 69% pour les verbes, 
ce qui constitue, par rapport &#224; un &#233;tiquetage majoritaire bas&#233; sur la lexie la plus fr&#233;quente, un 
gain respectivement de 52%, 53% et 50%. Les meilleurs algorithmes de l'action d'&#233;valuation 
Senseval (Kilgarriff, Rosenzweig, 2000) atteignent des performances de plus de 80% pour les 
noms, 70% pour les verbes et environ 75% pour les adjectifs. Nous sommes tr&#232;s proche de 
ces r&#233;sultats, mais la comparaison est difficile car nous ne travaillons ni sur les m&#234;mes corpus, 
ni sur la m&#234;me langue, ni avec le m&#234;me dictionnaire. 
</p>
<p>R&#233;f&#233;rences 
</p>
<p>Audibert L. (2001), LoX : outil polyvalent pour l'exploration de corpus annot&#233;s, Actes de 
RECITAL (TALN) 2001, pp.411-419. 
</p>
<p>Audibert L. (2002), Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique : 
pr&#233;sentation et premiers r&#233;sultats sur les cooccurrences, Actes de RECITAL (TALN) 2002, 
pp.415-424. 
</p>
<p>Cussens J. (1993), Bayes and Pseudo-Bayes Estimates of Conditional Probabilities and Their 
Reliability, Actes de European Conference on Machine Learning (Machine Learning: ECML-
93), pp.136-152. 
</p>
<p>Gale W. A., Church K. W., Yarowsky D. (1992), Estimating upper and lower bounds on the 
performance of word-sense disambiguation programs, 30th Annual Meeting of the Association 
for Computational Linguistics, pp.249-256. 
</p>
<p>Gale W. A., Church K. W., Yarowsky D. (1993), A method for disambiguating word senses 
in a large corpus, Actes de Computers and the Humanities, pp.415-439. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Laurent AUDIBERT 
</p>
<p>Golding A. R. (1995), A bayesian hybrid method for context-sensitive spelling correction, 
Actes de Third Workshop on Very Large Corpora, pp.39-53. 
</p>
<p>Ide N., V&#233;ronis J. (1998), Word sense disambiguation : the state of the art, Special Issue on 
Word Sense Disambiguation, Presses de l'Universit&#233; de Montr&#233;al, pp.1-40. 
</p>
<p>Kilgarriff A. (1997), Evaluating word sense disambiguation programs : progress report, SALT 
Workshop on Evaluation in Speech and Language Technology, pp.114-120. 
</p>
<p>Kilgarriff A., Rosenzweig J. (2000), English SENSEVAL: Report and Results, Actes de 2nd 
International Conference on Language Resources and Evaluation, pp.1239-1244. 
</p>
<p>McRoy S. (1992), Using multiple knowledge sources for word sense discrimination, Actes de 
Computational Linguistics, pp.1-30. 
</p>
<p>Mooney R. J. (1996), Comparative experiments on disambiguating word senses : an 
illustration of the role of bias in machine learning, Conference on Empirical Methods in 
Natural Language Processing, pp.82-91. 
</p>
<p>Ng H. T., Lee H. B. (1996), Integrating multiple knowledge sources to disambiguate word 
sense : an exemplar-based approach, Actes de 34th Annual Meeting of the Society for 
Computational Linguistics, pp.40-47. 
</p>
<p>Palmer M. (1998), Are WordNet sense distinctions appropriate for computational lexicons ?, 
Actes de SIGLEX-98, SENSEVAL. 
</p>
<p>Reymond D. (2001), Dictionnaires distributionnels et &#233;tiquetage lexical de corpus, Actes de 
RECITAL (TALN) 2001, pp.479-488. 
</p>
<p>Rivest R. L. (1987), Learning Decision Lists, Actes de Machine Learning, pp.229-246. 
</p>
<p>Valli A., V&#233;ronis J. (1999), Etiquetage grammatical de corpus oraux : probl&#232;mes et 
perpectives, Revue Fran&#231;aise de Linguistique Appliqu&#233;e, Association pour le traitement 
informatique des langues (ASSTRIL), pp.113-133. 
</p>
<p>V&#233;ronis J. (2001), Sense tagging : does it makes sense ?, Actes de Corpus Linguistics'2001. 
</p>
<p>Wilks Y., Stevenson M. (1998), Word sense disambiguation using optimised combinations of 
knowledge sources, Actes de COLING-ACL'98, pp.1398-1402. 
</p>
<p>Yarowsky D. (1993), One sense per collocation, Actes de ARPA Human Language 
Technology Workshop, pp.266-271. 
</p>
<p>Yarowsky D. (1995), Decision lists for lexical ambiguity resolution : application to accent 
restoration in spanish and french, Actes de  33rd Annual Meeting of the Association for 
Computational Linguistics, pp.88-95. </p>

</div></div>
</body></html>