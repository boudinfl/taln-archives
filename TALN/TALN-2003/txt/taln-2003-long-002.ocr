TALN 2003, Batz—sur—Mer, I I -1 4 juin 2003

Etude des critéres de désambigu'1'sation sémantique automatique :
résultats sur les cooccurrences

Laurent AUDIBERT

Jeune équipe DELIC — Université de Provence
29 Av. Robert SCHUl\/IAN - 13621 Aix-en-Provence Cedex 1
laurent.audibert@up.univ-aix.fr

Résumé — Abstract

Nous présentons dans cet article une étude sur les criteres de désambigu'1'sation sémantique
automatique basés sur les cooccurrences. L’algorithme de désambigu'1'sation utilisé est du type
liste de décision, il sélectionne une cooccurrence unique supposée véhiculer l'information la
plus fiable dans le contexte ciblé. Cette étude porte sur 60 vocables répartis, de maniere égale,
en trois classes grammaticales (nom, adj ectif et verbe) avec une granularité ﬁne au niveau des
sens. Nous commentons les résultats obtenus par chacun des criteres évalués de maniere
indépendante et nous nous intéressons aux particularités qui différencient les trois classes
grammaticales étudiées. Cette étude s’appuie sur un corpus francais étiqueté sémantiquement
dans le cadre du projet SyntSem.

This paper describes a study on cooccurrence-based criteria for automatic word sense
disambiguation. We use a decision-list algorithm which selects the best disambiguating cue in
the target context. The algorithm is tested on 60 words equally distributed among three parts
of speech (noun, adjective and verb) with a fine sense granularity. We present the results
obtained by each criterion evaluated in an independent way and we discuss the characteristics
which differentiate the three parts of speech studied. The study uses a French sense-tagged
corpus developed in the SyntSem project.

Mots Clés — Keywords

Désambiguisation sémantique automatique, corpus sémantiquement étiqueté, cooccurrences.

Word sense disambiguation, sense tagged corpora, cooccurrences.

Laurent A UDIBERT

1 Introduction

La desambiguisation semantique automatique est un enjeu important dans la plupart des
applications de traitement automatique des langues: recherche d’information, traduction
automatique, reconnaissance de la parole, etc. (Ide, Veronis, 1998). Cependant, les ressources
necessaires pour aborder correctement ce probleme commencent a peine a étre disponibles.
Ceci est particulierement vrai pour le francais.

Nous avons deja presente les debuts d’un travail visant a rechercher et a etudier les criteres de
desambiguisation semantique automatique (Audibert, 2002). Cette etude preliminaire portait
sur 7 noms avec une granularite grossiere au niveau des sens (2 a 3 sens par mot). Nous
etendons ici notre etude a 60 vocables repartis, de maniere egale, en trois classes
grammaticales (nom, adjectif et verbe) avec une granularite de sens bien plus fine (18 lexies
par vocable en moyenne). Nous presentons une serie de resultats sur le pouvoir
desambiguisateur de criteres bases sur les cooccurrencesl sans chercher a combiner ces
criteres. Nous appelons critere, un ensemble de << phenomenes >> susceptibles de survenir dans
le contexte d'un vocable (ex : lemme des cooccurrences).

2 Méthodologic

2.1 Corpus de travail

La premiere phase de notre travail est l'etiquetage de notre corpus avec le logiciel Cordial
Analyseur (developpe par la societe Synapse Developpement), qui offre une lemmatisation et
un etiquetage morpho-syntaxique d’une exactitude satisfaisante (Valli, Veronis, 1999). Cette
phase nous affranchit de toute ambigu'1'te categorielle comme le preconise (Kilgarriff, 1997).

L’une des difﬁcultes majeures de l’etiquetage semantique automatique reside dans
l’inadequation des dictionnaires traditionnels (Veronis, 2001) ou dedies (Palmer, 1998) pour
cette tache. Une autre difﬁculte (Gale, Church, Yarowsky, 1993) provient du manque de
corpus semantiquement etiquetes sur lesquels des methodes d'apprentissage supervise peuvent
étre entrainees. Ce manque se transforme meme en absence totale pour une langue comme le
francais alors qu’il commence a apparaitre de tels corpus pour l'anglais, notamment dans le
cadre de l'action d'evaluation Senseval (Kilgarriff, Rosenzweig, 2000). Pour ces multiples
raisons, notre equipe a entrepris la construction d’un dictionnaire distributionnel en se basant
sur un ensemble de criteres differentiels stricts (Reymond, 2001). Ce dictionnaire comporte
pour l'instant la description detaillee de 20 noms, 20 verbes et 20 adjectifs totalisant plus de
53000 occurrences dans le corpus du projet SyntSem2 (Corpus d’environ 5.5 millions de

Nous emploierons, dans cet article, le mot << cooccurrence » dans son acception la plus large, c’est-a-dire des
mots apparaissant dans le contexte, sans contrainte de frequence, de figement ou de lien syntaxique.

Le projet SyntSem, finance par l’ELRA/ELDA, vise a produire un corpus etiquete au niveau morpho-
syntaxique avec en plus un marquage syntaxique peu profond et un marquage semantique de mots
selectionnes.

Etude des critéres de désambiguisation sémantique automatique

mots, composé de textes de genres variés). C’est sur ce corpus que nous réalisons
l'entrainement et l'évaluation de nos algorithmes de désambiguisation sémantique.

Les données d’apprentissage, sur lesquelles nous entrainons et évaluons nos algorithmes, sont

fonction du critere étudié. Nous avons développé un outil (Audibert, 2001) qui permet de
modéliser un critere et de l’appliquer au corpus pour générer les données d’apprentissage.

2.2 Vocables étudiés

NOMS ADJECTIFS VERBES
Vocable I freq lex H 2" Vocable freq lex H 2" Vocable I freq lex H 2"
barrage 92 5 1,18 2,26 correct 116 5 1,81 3,50 couvri 518 21 3,25 9,51
restauration 104 5 1 ,85 3,60 sain 129 10 2,45 5,46 importe 576 8 2,57 5,93
suspension 110 5 1,50 2,82 courant 168 4 0,63 1,55 parveni 653 8 2,31 4,97
détention 112 2 0,85 1,80 régulier 181 11 2,54 5,82 exerce 698 8 1,52 2,88
lancement 138 5 0,99 1,99 frais 182 18 3,10 8,57 conclure 727 16 2,36 5,13
concentration 246 6 1,98 3,93 secondaire 195 5 1,69 3,23 arréte 913 15 2,97 7,85
station 266 8 2,58 5,98 strict 220 9 2,23 4,69 ouvri 919 41 3,80 13,92
vol 278 10 2,20 4,61 exceptionnel 226 3 1,45 2,73 poursuivre 978 16 2,71 6,53
organe 366 6 2,24 4,71 utile 359 9 2,39 5,23 tire 1001 47 3,88 14,72
compagnie 412 12 1,62 3,08 vaste 368 6 2,08 4,22 conduire 1082 15 2,28 4,85
constitution 422 6 1,64 3,13 sensible 425 11 2,63 6,19 entre 1210 38 3,65 12,55
degré 507 18 2,47 5,53 traditionnel 447 2 0,49 1,40 connaitre 1635 16 2,24 4,71
observation 572 3 0,68 1,60 populaire 457 5 2,02 4,05 rendre 1985 27 2,88 7,35
passage 601 19 2,70 6,49 biologique 475 4 0,55 1,46 comprendre 2136 13 2,76 6,79
solution 880 4 0,44 1,36 clai 556 20 3,10 8,57 présente 2140 18 2,56 5,90
économie 930 10 2,16 4,46 historique 620 3 0,67 1,59 porte 2328 59 4,01 16,07
pied 960 62 3,55 11,70 sl‘l 645 14 2,61 6,12 répondre 2529 9 0,99 1,99
chef 1133 11 1,47 2,77 plein 844 35 3,99 15,93 passe 2547 83 4,49 22,49
formation 1528 9 1,66 3,17 hau 1016 29 3,46 10,98 veni 3788 33 3,21 9,29
communication 1703 13 2,44 5,42 simple 1051 14 2,14 4,41 mettre 5095 140 3,65 12,55
Total 11360 Total | 8680 Total |3345s

Tableau 1 : Les 60 vocables avec la fréquence (freq), le nombre de lexies (lex),
l’entropie de la fréquence des lexies (H) et le nombre de lexies équiprobables
nécessaires pour une méme entropie (perplexité : 2”)

Le Tableau 1 détaille l’ensemble des 60 vocables de notre étude. On notera la grande disparité
de la fréquence de ces vocables. Le moins frequent étant barrage, avec une fréquence de 92,
et le plus fréquent étant le verbe mettre, avec une fréquence de 5095. On remarquera
également que le nombre de lexies peut atteindre 140 pour le verbe mettre. Nous travaillons
avec une granularité au niveau des sens relativement importante : environ ll lexies par
vocable en moyenne pour les noms et les adj ectifs et plus de 30 pour les verbes.

Cependant, le nombre de lexies n’est pas un bon indice de la difﬁculté de la tache. En effet, il
est plus facile de lever l’ambigu'1'té d’un vocable ayant 10 lexies, mais dont la quasi-totalité
des occurrences est regroupée sous une seule lexie, que de lever l’ambigu'1'té d’un vocable
comportant 2 lexies équiprobables. L’entropie de la répartition des occurrences du vocable
sur ses différentes lexies est un meilleur indicateur de la difﬁculté de la levée de l’ambigu'1'té
pour ce vocable, d’ou la présence de la colonne (H), pour l’entropie, et de la colonne (2”) qui
mesure la perplexité, ce qui peut s’avérer plus parlant. Ainsi, pour une entropie inchangée, si
les lexies étaient équiprobables, les noms auraient une moyenne de 4 lexies par vocables, les
adjectifs de plus de 5 et les verbes de pratiquement 9. Il s’agit la d’un indice qui laisse
présager une plus grande difﬁculté pour lever l’ambigu'1'té des adjectifs, et encore plus des
verbes, par rapport aux noms.

Laurent A UDIBERT

2.3 Définition des critéres

Il existe de nombreuses sources d’information pour lever l’ambigu'1'té du sens des mots.
Comme l’ont montré (McRoy, 1992), (VVilks, Stevenson, 1998) ou encore (Ng, Lee, 1996)
toutes ces sources peuvent étre utilisées simultanément pour aboutir a une meilleure
désambigu'1'sation. Nous avons déja présenté un inventaire non exhaustif des criteres qui
peuvent étre étudiés (Audibert, 2002).

De nombreuses études, comme par exemple (Ng, Lee, 1996), (Mooney, 1996) ou encore
(Y arowsky, 1993), montrent que les cooccurrences constituent un bon critere pour identiﬁer
le sens d’un mot. Dans cette étude, nous nous proposons d’étudier des criteres élémentaires,
basés sur les cooccurrences, sans chercher a les combiner. Notre objectif est de fournir des
informations de référence pour l’élaboration de criteres plus complexes et de répondre a des
questions comme l’intérét de la lemmatisation, l’utilité des fenétres de mots sans distinction
de position (unordered set of surrounding words en anglais), l’importance des mots
grammaticaux ou encore les differences de comportement entre les catégories grammaticales.

2.4 Algorithme de désambiguisation

L'algorithme de classification des lexies utilisé est du type liste de décision (Rivest, 1987)
pour sa simplicité de mise en oeuvre et son efﬁcacité. Cette approche ne combine pas
l'information de tous les attributs de la description dont on cherche a déterminer la classe,
mais se focalise sur un attribut unique, supposé véhiculer l'information la plus ﬁable.
L’algorithme ici utilisé differe de celui de l’étude préliminaire (Audibert, 2002) base sur une
mesure de dispersion. Il s’agit d’un algorithme tres proche de celui de (Golding, 1995) qui
constitue une généralisation a plus de deux classes de l’algorithme de (Y arowsky, 1995).

Soit un exemple E dont nous désirons déterminer la lexie la plus probable IE, parmi un
ensemble de lexies possibles L, en se basant sur la description D de E composée d'un certain
nombre d'indices D:ﬁ1  in} générés par l’application du critere étudié sur l’exemple E. Soit
A l'ensemble des indices des exemples d'apprentissage générés par l’application du critere
étudié sur le corpus d’apprentissage.

La lexie choisie est déterminée en se basant sur l’indice considéré comme étant le plus fiable
dans la liste de décision : IE=argmax(p(lexie/IndFia))

lexieeL

L’indice le plus fiable de la liste est : IndFia:argmax(ﬁabilité(indice)).

indiceeDnA
La mesure utilisée pour ordonner les indices est : ﬁabilité(indice):ma>E(p(lexie/indice)).
extee

Lorsque les indices de la description n’ont jamais été rencontrés dans le corpus
d’apprentissage, DnA est vide et il n’y a pas d’indice le plus fiable IndFia. Dans ce cas, la
lexie choisie est la lexie la plus fréquente.

L’estimation des probabilités p(lexie/indice) se fait sur les exemples d’apprentissage. Nous
utilisons une m-estimation (Cussens, 1993) en raison de certains dénombrements faibles et
parfois nuls : p(lexie/indice)= 

0 ngem,-,,,,;,-Ce est le nombre d’exemples d’apprentissage dont la description contient

l’indice indice et dont la lexie du vocable étudié est lexie ;

Etude des critéres de désambiguisation sémantique automatique

0 n,-M,-Ce est le nombre d’exemples d’apprentissage dont la description contient l’indice
indice ;

0 pzm-e,;,,,;,-m est une estimation a priori de la probabilité recherchée, comme nous ne
connaissons pas cette estimation, nous supposons une répartition uniforme de

probabilité et nous posons pzex:e,:m:ce:  ;
0 m est une constante a déterminer.
Le lissage réalisé dans (Golding, 1995) revient a ﬁxer m:cara'(L). D’apres notre expérience,

poser m: _ﬁ'éqlI€I’lC€indice donne de bien meilleurs résultats.

Pour évaluer un critere sur le corpus, nous utilisons une méthode d’éValuation croisée k fois
(k-fold cross validation en anglais), conforrnément a l’usage commun, k=l0 dans notre
expérience. Cette méthode est coﬁteuse en temps de calcul mais permet d’éValuer le critere
sur la totalité du corpus.

3 Résultats de notre étude

Nous appelons précision de l’étiquetage majoritaire (Gale, Church, Yarowsky, 1992) la
précision obtenue en étiquetant toutes les occurrences avec la lexie la plus fréquente.

Nous appelons précision le rapport entre le nombre d’étiquetages corrects et le nombre
d’étiquetages effectués :

Précision : Wombre d ’étiquetages corrects) / Wombre d ’ét1'quetages e/fectués).

Nous appelons gain l’amélioration de la précision obtenue par rapport a la précision d’un
étiquetage majoritaire :

Gain : (Précisi0n(ét1'q.) — Précisi0n(étiq. majoritaire) ) / ( I — Précisi0n(étiq. majoritaire) ).

3.1 Evaluation de différents critéres

La Figure 1 montre la précision de la désambigu'1'sation obtenue par huit criteres. Les noms de
ces criteres précisent leur nature et sont de la forme [info] ]-[inf02]-[inf03]. inf03 indique si le
critere considere tous les mots ou seulement les mots pleins. inf02 indique si les mots
considérés sont différenciés par leur position ou pas. info] indique si l’on regarde la forme
brute des mots ou leur lemme. Le Tableau 2 permet de synthétiser les informations de la
Figure 1.

On peut remarquer que tous ces criteres atteignent leur meilleure précision pour de petites
fenétres allant de il mot a i4 mots. Dans tous les cas, le retrait des mots grammaticaux se
traduit par une baisse significative des performances. Traiter les mots sans tenir compte de
leur position par rapport au mot a désambigu'1'ser entraine également une baisse des
performances. De plus, les performances des criteres qui tiennent compte de la position des
mots présentent une dynamique moins importante. Ces criteres sont ainsi moins sensibles que
les autres au choix de la taille du contexte. Cette robustesse constitue une raison de plus de les
privilégier. Enfin, la lemmatisation n’a permis une augmentation significative des
performances que pour les adjectifs.

Laurent A UDIBERT

Adjectifs Verbes
80% ——————~——~———~————— 80%

75% 75%

 

70% ‘

70%

65% 65%

60% + [mot]-[ordonné]-[ytous] 60%
4» [lemme]-[ordonne]-[tous]
+ [mot]-[ordonné]-[mots pleins]
+ [lemme]-[ordonné]-[mots pleins]
55% + [mot]-[non-ordonné]-[tous] 55%
4} [Iemme]-[non-ordonné]-[tous]
-4- [mot]-[non-ordonné]-[mots pleins]
—A— [Iemme]-[non-ordonné]-[mots p|eins'
50% 50%
24531o1214161320 246810121416182D 2468101214161820

|:)emi_fenét[e en ngmbfe de mats Demi—fené-tre en nombre de mots Demi—fenétre en nombre de mots

 

 

Figure 1 : Précision des 8 criteres pour les 3 catégories de Vocables

catégorie Grammaticale
Cfitéfe Noms Adjectifs Verbes

RTP%G%RTP%G%RTP%G%

[|emme]- [ordonné] -[tous] 2 4 78,9 50,7 1 3 74,9 53,2 1 3 68,9 50,4
[mot]- [ordonné] -[tous] 1 3 79,4 51,8 3 1 73,8 51,2 2 3 68,6 49,9
[|emme]- [non-ordonné] -[tous] 8 3 76,1 44,1 2 1 74,1 51,7 4 3 65,3 44,6
[mot]- [non-ordonné] -[tous] 7 4 76,2 44,2 4 1 73,3 50,1 3 3 65,7 45,3
[|emme]- [ordonné] -[mots pleins] 3 1 77,9 48,2 6 1 70,7 45,3 5 1 62,2 39,7
[mot]- [ordonné] -[mots pleins] 4 1 77,4 47,2 5 1 71,0 45,8 6 2 61,0 37,8
[|emme]- [non-ordonné] -[mots pleins] 5 1 77,3 47,0 8 1 70,4 44,8 8 2 59,1 34,7
[mot]- [non-ordonné] -[mots pleins] 6 1 76,2 44,3 7 1 70,5 45,0 7 2 59,7 35,7

Etiquetage majoritaire 9 x 57,3 0 9 x 46,4 0 9 x 37,4 0

Tableau 2 : Meilleure précision (colonne P) et donc meilleur gain (colonne G) des 8 criteres
pour les 3 categories de Vocables, la colonne R indique le rang du critere (du meilleur 1
au moins bon 8) et la colonne T indique la taille du demi-contexte

3.2 Particularités des catégories grammaticales

En observant la Figure 1 on peut déja relever trois différences de comportement entre les
noms, les adjectifs et les Verbes. La premiere différence se situe au niveau des précisions
atteintes. La précision de l’étiquetage réalisé est la meilleure pour les noms, elle est moins
bonne pour les adj ectifs et encore moins bonne pour les Verbes. Comme nous l’aVions prédit
dans la section 2.2, cela peut s’expliquer par le nombre moyen de lexies par vocable. Si l’on
étiquette chaque occurrence d’un Vocable avec sa lexie la plus fréquente (étiquetage
majoritaire) on obtient une précision de 57% pour les noms, 46% pour les adjectifs et 37%
pour les Verbes (cf. Tableau 2). Ainsi le gain réalisé par le meilleur critere pour chaque
catégorie de Vocable est de 52% pour les noms, 53% pour les adjectifs et 50% pour les Verbes
(cf. Tableau 2). Ces chiffres montrent bien que l’algorithme et les criteres de
désambigu'1'sation utilisés fonctionnent aussi bien pour nos trois catégories de Vocables.

La seconde différence est la pente de la décroissance de la précision qui est bien plus
importante pour les adjectifs et les Verbes que pour les noms (cf. Figure 1). Nous avons tenté

Etude des critéres de désambiguisation sémantique automatique

de désambigu'1'ser chacun de nos 60 vocables en 50% _O_ Noms
regardant une fenétre de 4 mots pleins située a une 40% + Adjectifs
distance de irx mots de la cible. Les courbes de la *}Ve'be5
Figure 2 montrent le gain obtenu en fonction de cette 30%
distance de x mots. On observe immédiatement que
lorsque l’on s’éloigne de la cible, le gain tend vers zéro
de maniere beaucoup plus rapide pour les adjectifs et
les verbes que pour les noms. L’information qui permet
de lever l’ambigu'1'té d’un vocable est donc plus 0%
concentrée autour de ce vocable quand il s’agit d’un
verbe ou d’un adjectif que quand il s’agit d’un nom.

20%

10%

 

1 2 3 4 6 8 10 12 14 16

Figure 2 : Gain des 3 categories

La troisieme difference tient dans la médiocrité de la désambigu'1'sation des verbes pour un
contexte de i1 mot, et ce, méme s’il s’agit de mots pleins. Nous apporterons une explication a
ce phénomene dans la suite de cette section.

En utilisant le critere [mot]-[ordonné]-[tous], qui considere tous les mots en tenant compte de
leur position et sans lemmatisation, avec un contexte de i3 mots, nous nous sommes intéressé
a la catégorie grammaticale du mot ayant servi a la levée de l’ambigu'1'té (Tableau 3). Cette
expérience perrnet d’observer que les adjectifs sont les mots qui perrnettent le mieux de
désambigu'1'ser les noms (précision de 95.3%) et qu’ils sont utilisés dans 12.4% des cas (sur
un total de 11360 cas, cf. Tableau 1). Les noms donnent de bons résultats pour désambigu'1'ser
nos trois catégories de vocables, et spécialement les adjectifs et les verbes pour lesquels ils
sont utilisés dans environ 25% des cas. Les verbes a l’inﬁnitif fonctionnent bien pour les trois
catégories, ce qui n’est pas forcément le cas des autres formes verbales. Les adverbes
fonctionnent bien pour désambigu'1'ser les adjectifs. Au niveau des mots grammaticaux, on
observe que les prépositions sont intéressantes pour les noms, les déterminants pour les
adj ectifs et les pronoms personnels pour les verbes.

Nous avons également cherché a observer comment les principales catégories grammaticales
se répartissaient autour de nos trois catégories de vocables a désambigu'1'ser. La Figure 3
montre les pourcentages des principales catégories grammaticales utilisées pour
désambigu'1'ser le vocable en fonction de la position ou se trouvait le mot utilisé pour la levée
de l’ambigu'1'té.

NOMS ADJECTIFS VERBES
catégorie P % Utilis. % catégorie P % Utilis. % catégorie P % Utilis. %
Adjectifs 95,3 12,4 Noms 93,4 24,2 Noms 87,6 25,3
Verbesa|'inf. 87,3 0,6 Adverbes 81,1 8,9 Conj.de sub. 82,6 2,6
Noms 82,0 32,6 Verbesa|'inf. 80,7 0,7 Verbesa|'inf. 75,6 3,7
Verbes au par. 81,1 0,3 Adjectifs 68,8 19,3 Pronoms pers. 68,9 9,8
Prépositions 79,9 19,1 Déterminants 68,5 15,6 Adjectifs 67,1 3,0
Conjonctions 75,0 3,1 Pronoms pers. 68,0 2,6 Prépositions 65,4 15,2
Déterminants 72,2 20,8 Conj.de coord. 66,1 3,4 Adverbes 63,8 4,8
Verbes conj. 63,6 1,0 Verbes restants 48,1 2,4 Verbes restants 59,1 16,5
Autres 67,6 10,0 Autres 60,6 23,1 Autres 52,6 19,2
TOTAL 79,4 100,0 TOTAL 73,3 100,0 TOTAL 68,6 100,0

Tableau 3 : Principales catégories grammaticales des mots utilisées pour lever l’ambigu'1'té

Laurent A UDIBERT

Noms La position 0 est celle du Vocable a
_ Adjecﬁfs I désamb1gu'1'ser. On peut remarquer que
— P'éP°5111°“S 3 la forme du Vocable a désambigu'1'ser est

Déterminants _ _ , 0
‘ ut1l1see dans 17A: des cas pour les noms,

21%
18%
15%

 
 
     
 
      
 
 

Noms

12% 14 % pour les adjectifs et 12% pour les
00 _

:0: Verbes. On pourra1t penser que la

30/; précision de l’étiquetage, quand elle est

0% basée sur la seule forme du mot a

'3 '2 '1 0 1 2 3 désambigu'1'ser, doit étre proche de la

Adjectifs précision d’un étiquetage majoritaire.

241’ Adecﬁfs En fait, il n’en est rien. Le ain obtenu,
210/0 ‘ J _

18% —AdVerbeS _ lorsque c’est la forme du mot a

Determinants , . .. . .
15% Noms — desambiguiser qui a permis de lever

12% l’ambigu'1'té, est de 45% pour les noms,
:2: 42% pour les adjectifs et 37% pour les
3% Verbes.
0%
'3 '2 '1 0 1 2 3 Les noms qui permettent de lever
Verbes l’ambigu'1'té des adj ectif s sont

directement collés a cet adjectif et se
trouvent indifféremment a droite ou a
gauche.

18% 2 Verbes
15% 2 Pré-positions
Pronoms personnels

12% Noms

9%
6%
3%
0%

La dissymétrie de la ﬁgure des Verbes
est tres instructive. Tout d’abord elle
permet d’expliquer la forme des courbes

'3 '2 '1 0 1 2 3 de la Figure 1. En effet, nous avions
Figure 3 I Répartition, autour du 1'1’10t E‘). remarqué la médiocrité de la
désambigulsera des Principales Catégories désambigu'1'sation des Verbes pour un
grammaticales utilisées pour1eVer1’ambigu'1'té. contexte dc i1 mot on commend

maintenant pourquoi, contrairement aux
noms et aux adj ectifs ou la majeure partie de l’information permettant la levée de l’ambigu'1'té
était puisée en position -1 et +1, la majeure partie de l’information pour les Verbes se trouve
en position +2 et une part non négligeable se trouve en +3. Ensuite, on peut se rendre compte
que la désambigu'1'sation des Verbes se fait plus en fonction de leur objet que de leur sujet
puisque la forme sujet-verbe-complément est la plus fréquente. Enﬁn, la forme de ce
graphique inciterait a ne pas utiliser un contexte symétrique mais plut6t un contexte
dissymétrique de la forme -2 +4 par exemple.

Sur les particularités des catégories grammaticales (Yarowsky, 1993) obtenait des résultats
analogues sur l’anglais en se limitant a deux lexies par mot et en utilisant des pseudo-mots
possédant deux << sens >>. Ces pseudo-mots peuvent étre obtenus en fusionnant deux mots
quelconques, ou homographes dans une autre langue, ou encore ne se distinguant que par une
seule lettre, en un seul en gardant l’inforrnation du mot d’origine. Ces pseudo-mots
perrnettent d’obtenir directement des corpus de grande taille en s’affranchissant de la phase
d’étiquetage manuel.

Etude des criteres de désambiguisation sémantique automatique

4 Perspectives et conclusion

Le travail présenté dans cet article sera étendu a d’autres criteres pour mesurer, par exemple,
l’utilité des étiquettes morpho-syntaxique ou des n-grammes. Il faudra également étudier les
interactions entre ces criteres de maniere a pouvoir les utiliser conjointement pour aboutir a
une désambiguisation automatique plus efﬁcace et plus robuste.

On peut remarquer que, parmi les travaux similaires déja réalisés, peu l’ont été sur des corpus
manuellement étiquetés en raison de leur rareté. Pour pallier ce probleme, les chercheurs
utilisent souvent des pseudo-mots qui ne comportent que deux << sens >> et dont les contextes
sont parfois tres distincts, ce qui facilite leur désambiguisation et biaise les résultats. Notre
étude porte sur de << Vrais >> mots et s’appuie sur un corpus de taille sufﬁsante manuellement
étiqueté. D’autre part, l’une des difﬁcultés de l’étiquetage sémantique automatique réside
dans l’inadéquation des dictionnaires traditionnels. Pour cette raison, notre corpus a été
étiqueté en utilisant les deﬁnitions d’un dictionnaire distributionnel établi sur un ensemble de
criteres différentiels stricts.

Cette étude a porté sur 60 Vocables répartis en 20 noms, 20 adjectifs et 20 Verbes. Le nombre
de lexies est de pratiquement 18 en moyenne pour ces 60 mots. Les résultats obtenus sur des
criteres simples et sans combinaison de plusieurs criteres sont encourageants. La précision
moyenne obtenue atteint 79% pour les noms, 75% pour les adj ectifs et 69% pour les Verbes,
ce qui constitue, par rapport a un étiquetage majoritaire basé sur la lexie la plus fréquente, un
gain respectivement de 52%, 53% et 50%. Les meilleurs algorithmes de l'action d'éValuation
Senseval (Kilgarriff, Rosenzweig, 2000) atteignent des performances de plus de 80% pour les
noms, 70% pour les Verbes et environ 75% pour les adjectifs. Nous sommes tres proche de
ces résultats, mais la comparaison est difﬁcile car nous ne travaillons ni sur les mémes corpus,
ni sur la méme langue, ni avec le méme dictionnaire.

Références

Audibert L. (2001), LoX : outil polyvalent pour l'exploration de corpus annotés, Actes de
RECITAL (TALN) 2001, pp.4l 1-419.

Audibert L. (2002), Etude des criteres de désambiguisation sémantique automatique :
presentation et premiers résultats sur les cooccurrences, Actes de RECITAL (TALN) 2002,
pp.4l5-424.

Cussens J. (1993), Bayes and Pseudo-Bayes Estimates of Conditional Probabilities and Their
Reliability, Actes de European Conference on Machine Learning ﬂllachine Learning: ECW-
93),pp.136-152.

Gale W. A., Church K. W., Yarowsky D. (1992), Estimating upper and lower bounds on the
performance of word-sense disambiguation programs, 30th Annual Meeting of the Association
for Computational Linguistics, pp.249-256.

Gale W. A., Church K. W., Yarowsky D. (1993), A method for disambiguating word senses
in a large corpus, Actes de Computers and the Humanities, pp.415-439.

Laurent A UDIBERT

Golding A. R. (1995), A bayesian hybrid method for context-sensitive spelling correction,
Actes de Third Workshop on Very Large Corpora, pp.39-53.

Ide N., Véronis J. (1998), Word sense disambiguation : the state of the art, Special Issue on
Word Sense Disambiguation, Presses de l'Université de Montréal, pp. 1-40.

Kilgarriff A. (1997), Evaluating word sense disambiguation programs : progress report, SALT
Workshop on Evaluation in Speech and Language Technology, pp. 1 14-120.

Kilgarriff A., Rosenzweig J. (2000), English SENSEVAL: Report and Results, Actes de 2nd
International Conference on Language Resources and Evaluation, pp. 1239-1244.

McRoy S. (1992), Using multiple knowledge sources for word sense discrimination, Actes de
Computational Linguistics, pp. 1-3 0.

Mooney R. J. (1996), Comparative experiments on disambiguating word senses : an
illustration of the role of bias in machine learning, Conference on Empirical Methods in
Natural Language Processing, pp.82-91.

Ng H. T., Lee H. B. (1996), Integrating multiple knowledge sources to disambiguate word
sense : an exemplar-based approach, Actes de 34th Annual Meeting of the Society for
Computational Linguistics, pp.40-47.

Palmer M. (1998), Are WordNet sense distinctions appropriate for computational lexicons ?,
Actes de SIGLEX-98, SENSEVAL.

Reymond D. (2001), Dictionnaires distributionnels et étiquetage lexical de corpus, Actes de
RECITAL (TALN) 2001, pp.479-488.

Rivest R. L. (1987), Learning Decision Lists, Actes de Machine Learning, pp.229-246.

Valli A., Véronis J. (1999), Etiquetage grammatical de corpus oraux : problemes et
perpectives, Revue Francaise de Linguistique Appliquée, Association pour le traitement
informatique des langues (ASSTRIL), pp.113-133.

Véronis J. (2001), Sense tagging : does it makes sense ?, Actes de Corpus Linguistics’200I.

Wilks Y., Stevenson M. (1998), Word sense disambiguation using optimised combinations of
knowledge sources, Actes de COLING-ACL'98, pp. 1398-1402.

Yarowsky D. (1993), One sense per collocation, Actes de ARPA Human Language
Technology Workshop, pp.266-271.

Yarowsky D. (1995), Decision lists for lexical ambiguity resolution : application to accent
restoration in spanish and french, Actes de 33rd Annual Meeting of the Association for
Computational Linguistics, pp. 88-95.

