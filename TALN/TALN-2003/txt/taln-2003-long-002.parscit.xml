<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Audibert</author>
</authors>
<title>LoX : outil polyvalent pour l&apos;exploration de corpus annotés, Actes de RECITAL (TALN)</title>
<date>2001</date>
<pages>411--419</pages>
<contexts>
<context position="5272" citStr="Audibert, 2001" startWordPosition="745" endWordPosition="746">lien syntaxique. 2 Le projet SyntSem, financé par lELRA/ELDA, vise à produire un corpus étiqueté au niveau morphosyntaxique avec en plus un marquage syntaxique peu profond et un marquage sémantique de mots sélectionnés. Etude des critères de désambiguïsation sémantique automatique mots, composé de textes de genres variés). Cest sur ce corpus que nous réalisons l&apos;entraînement et l&apos;évaluation de nos algorithmes de désambiguïsation sémantique. Les données dapprentissage, sur lesquelles nous entraînons et évaluons nos algorithmes, sont fonction du critère étudié. Nous avons développé un outil (Audibert, 2001) qui permet de modéliser un critère et de lappliquer au corpus pour générer les données dapprentissage. 2.2 Vocables étudiés NOMS ADJECTIFS VERBES Vocable freq lex H 2H Vocable freq lex H 2H Vocable freq lex H 2H barrage 92 5 1,18 2,26 correct 116 5 1,81 3,50 couvrir 518 21 3,25 9,51 restauration 104 5 1,85 3,60 sain 129 10 2,45 5,46 importer 576 8 2,57 5,93 suspension 110 5 1,50 2,82 courant 168 4 0,63 1,55 parvenir 653 8 2,31 4,97 détention 112 2 0,85 1,80 régulier 181 11 2,54 5,82 exercer 698 8 1,52 2,88 lancement 138 5 0,99 1,99 frais 182 18 3,10 8,57 conclure 727 16 2,36 5,13 concentrat</context>
</contexts>
<marker>Audibert, 2001</marker>
<rawString>Audibert L. (2001), LoX : outil polyvalent pour l&apos;exploration de corpus annotés, Actes de RECITAL (TALN) 2001, pp.411-419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Audibert</author>
</authors>
<title>Etude des critères de désambiguïsation sémantique automatique : présentation et premiers résultats sur les cooccurrences, Actes de RECITAL (TALN)</title>
<date>2002</date>
<pages>415--424</pages>
<contexts>
<context position="2438" citStr="Audibert, 2002" startWordPosition="334" endWordPosition="335">pora, cooccurrences. Laurent AUDIBERT 1 Introduction La désambiguïsation sémantique automatique est un enjeu important dans la plupart des applications de traitement automatique des langues : recherche dinformation, traduction automatique, reconnaissance de la parole, etc. (Ide, Véronis, 1998). Cependant, les ressources nécessaires pour aborder correctement ce problème commencent à peine à être disponibles. Ceci est particulièrement vrai pour le français. Nous avons déjà présenté les débuts dun travail visant à rechercher et à étudier les critères de désambiguïsation sémantique automatique (Audibert, 2002). Cette étude préliminaire portait sur 7 noms avec une granularité grossière au niveau des sens (2 à 3 sens par mot). Nous étendons ici notre étude à 60 vocables répartis, de manière égale, en trois classes grammaticales (nom, adjectif et verbe) avec une granularité de sens bien plus fine (18 lexies par vocable en moyenne). Nous présentons une série de résultats sur le pouvoir désambiguïsateur de critères basés sur les cooccurrences1 sans chercher à combiner ces critères. Nous appelons critère, un ensemble de « phénomènes » susceptibles de survenir dans le contexte d&apos;un vocable (ex : lemme des</context>
<context position="9199" citStr="Audibert, 2002" startWordPosition="1438" endWordPosition="1439">es verbes de pratiquement 9. Il sagit là dun indice qui laisse présager une plus grande difficulté pour lever lambiguïté des adjectifs, et encore plus des verbes, par rapport aux noms. Laurent AUDIBERT 2.3 Définition des critères Il existe de nombreuses sources dinformation pour lever lambiguïté du sens des mots. Comme lont montré (McRoy, 1992), (Wilks, Stevenson, 1998) ou encore (Ng, Lee, 1996) toutes ces sources peuvent être utilisées simultanément pour aboutir à une meilleure désambiguïsation. Nous avons déjà présenté un inventaire non exhaustif des critères qui peuvent être étudiés (Audibert, 2002). De nombreuses études, comme par exemple (Ng, Lee, 1996), (Mooney, 1996) ou encore (Yarowsky, 1993), montrent que les cooccurrences constituent un bon critère pour identifier le sens dun mot. Dans cette étude, nous nous proposons détudier des critères élémentaires, basés sur les cooccurrences, sans chercher à les combiner. Notre objectif est de fournir des informations de référence pour lélaboration de critères plus complexes et de répondre à des questions comme lintérêt de la lemmatisation, lutilité des fenêtres de mots sans distinction de position (unordered set of surrounding words en</context>
</contexts>
<marker>Audibert, 2002</marker>
<rawString>Audibert L. (2002), Etude des critères de désambiguïsation sémantique automatique : présentation et premiers résultats sur les cooccurrences, Actes de RECITAL (TALN) 2002, pp.415-424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cussens</author>
</authors>
<title>Bayes and Pseudo-Bayes Estimates of Conditional Probabilities and Their Reliability,</title>
<date>1993</date>
<booktitle>Actes de European Conference on Machine Learning (Machine Learning: ECML93),</booktitle>
<pages>136--152</pages>
<contexts>
<context position="11703" citStr="Cussens, 1993" startWordPosition="1813" endWordPosition="1814">iable dans la liste de décision : lE=argmax(p(lexie/IndFia)) lexie∈L Lindice le plus fiable de la liste est : IndFia=argmax( fiabilité(indice)) . indice∈D∩A La mesure utilisée pour ordonner les indices est : fiabilité(indice)=max(p(lexie/indice)) . lexie∈L Lorsque les indices de la description nont jamais été rencontrés dans le corpus dapprentissage, D∩A est vide et il ny a pas dindice le plus fiable IndFia. Dans ce cas, la lexie choisie est la lexie la plus fréquente. Lestimation des probabilités p(lexie/indice) se fait sur les exemples dapprentissage. Nous utilisons une m-estimation (Cussens, 1993) en raison de certains dénombrements faibles et parfois nuls : p(lexie/indice)=nlexie,indice+m.plexie,indicenindice+m . • nlexie,indice est le nombre dexemples dapprentissage dont la description contient lindice indice et dont la lexie du vocable étudié est lexie ; Etude des critères de désambiguïsation sémantique automatique • nindice est le nombre dexemples dapprentissage dont la description contient lindice indice ; • plexie,indice est une estimation a priori de la probabilité recherchée, comme nous ne connaissons pas cette estimation, nous supposons une répartition uniforme de probab</context>
</contexts>
<marker>Cussens, 1993</marker>
<rawString>Cussens J. (1993), Bayes and Pseudo-Bayes Estimates of Conditional Probabilities and Their Reliability, Actes de European Conference on Machine Learning (Machine Learning: ECML93), pp.136-152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Gale</author>
<author>K W Church</author>
<author>D Yarowsky</author>
</authors>
<title>Estimating upper and lower bounds on the performance of word-sense disambiguation programs,</title>
<date>1992</date>
<booktitle>30th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>249--256</pages>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>Gale W. A., Church K. W., Yarowsky D. (1992), Estimating upper and lower bounds on the performance of word-sense disambiguation programs, 30th Annual Meeting of the Association for Computational Linguistics, pp.249-256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Gale</author>
<author>K W Church</author>
<author>D Yarowsky</author>
</authors>
<title>A method for disambiguating word senses in a large corpus,</title>
<date>1993</date>
<booktitle>Actes de Computers and the Humanities,</booktitle>
<pages>415--439</pages>
<marker>Gale, Church, Yarowsky, 1993</marker>
<rawString>Gale W. A., Church K. W., Yarowsky D. (1993), A method for disambiguating word senses in a large corpus, Actes de Computers and the Humanities, pp.415-439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurent AUDIBERT Golding A R</author>
</authors>
<title>A bayesian hybrid method for context-sensitive spelling correction,</title>
<date>1995</date>
<booktitle>Actes de Third Workshop on Very Large Corpora,</booktitle>
<pages>39--53</pages>
<marker>R, 1995</marker>
<rawString>Laurent AUDIBERT Golding A. R. (1995), A bayesian hybrid method for context-sensitive spelling correction, Actes de Third Workshop on Very Large Corpora, pp.39-53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>J Véronis</author>
</authors>
<title>Word sense disambiguation : the state of the art,</title>
<date>1998</date>
<booktitle>Special Issue on Word Sense Disambiguation, Presses de l&apos;Université de Montréal,</booktitle>
<pages>1--40</pages>
<marker>Ide, Véronis, 1998</marker>
<rawString>Ide N., Véronis J. (1998), Word sense disambiguation : the state of the art, Special Issue on Word Sense Disambiguation, Presses de l&apos;Université de Montréal, pp.1-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
</authors>
<title>Evaluating word sense disambiguation programs : progress report,</title>
<date>1997</date>
<booktitle>SALT Workshop on Evaluation in Speech and Language Technology,</booktitle>
<pages>114--120</pages>
<contexts>
<context position="3460" citStr="Kilgarriff, 1997" startWordPosition="488" endWordPosition="489">res basés sur les cooccurrences1 sans chercher à combiner ces critères. Nous appelons critère, un ensemble de « phénomènes » susceptibles de survenir dans le contexte d&apos;un vocable (ex : lemme des cooccurrences). 2 Méthodologie 2.1 Corpus de travail La première phase de notre travail est l&apos;étiquetage de notre corpus avec le logiciel Cordial Analyseur (développé par la société Synapse Développement), qui offre une lemmatisation et un étiquetage morpho-syntaxique dune exactitude satisfaisante (Valli, Véronis, 1999). Cette phase nous affranchit de toute ambiguïté catégorielle comme le préconise (Kilgarriff, 1997). Lune des difficultés majeures de létiquetage sémantique automatique réside dans linadéquation des dictionnaires traditionnels (Véronis, 2001) ou dédiés (Palmer, 1998) pour cette tâche. Une autre difficulté (Gale, Church, Yarowsky, 1993) provient du manque de corpus sémantiquement étiquetés sur lesquels des méthodes d&apos;apprentissage supervisé peuvent être entraînées. Ce manque se transforme même en absence totale pour une langue comme le français alors quil commence à apparaître de tels corpus pour l&apos;anglais, notamment dans le cadre de l&apos;action d&apos;évaluation Senseval (Kilgarriff, Rosenzweig</context>
</contexts>
<marker>Kilgarriff, 1997</marker>
<rawString>Kilgarriff A. (1997), Evaluating word sense disambiguation programs : progress report, SALT Workshop on Evaluation in Speech and Language Technology, pp.114-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
<author>J Rosenzweig</author>
</authors>
<title>English SENSEVAL: Report and Results,</title>
<date>2000</date>
<booktitle>Actes de 2nd International Conference on Language Resources and Evaluation,</booktitle>
<pages>1239--1244</pages>
<marker>Kilgarriff, Rosenzweig, 2000</marker>
<rawString>Kilgarriff A., Rosenzweig J. (2000), English SENSEVAL: Report and Results, Actes de 2nd International Conference on Language Resources and Evaluation, pp.1239-1244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S McRoy</author>
</authors>
<title>Using multiple knowledge sources for word sense discrimination,</title>
<date>1992</date>
<booktitle>Actes de Computational Linguistics,</booktitle>
<pages>1--30</pages>
<contexts>
<context position="8936" citStr="McRoy, 1992" startWordPosition="1401" endWordPosition="1402">pour lentropie, et de la colonne (2H) qui mesure la perplexité, ce qui peut savérer plus parlant. Ainsi, pour une entropie inchangée, si les lexies étaient équiprobables, les noms auraient une moyenne de 4 lexies par vocables, les adjectifs de plus de 5 et les verbes de pratiquement 9. Il sagit là dun indice qui laisse présager une plus grande difficulté pour lever lambiguïté des adjectifs, et encore plus des verbes, par rapport aux noms. Laurent AUDIBERT 2.3 Définition des critères Il existe de nombreuses sources dinformation pour lever lambiguïté du sens des mots. Comme lont montré (McRoy, 1992), (Wilks, Stevenson, 1998) ou encore (Ng, Lee, 1996) toutes ces sources peuvent être utilisées simultanément pour aboutir à une meilleure désambiguïsation. Nous avons déjà présenté un inventaire non exhaustif des critères qui peuvent être étudiés (Audibert, 2002). De nombreuses études, comme par exemple (Ng, Lee, 1996), (Mooney, 1996) ou encore (Yarowsky, 1993), montrent que les cooccurrences constituent un bon critère pour identifier le sens dun mot. Dans cette étude, nous nous proposons détudier des critères élémentaires, basés sur les cooccurrences, sans chercher à les combiner. Notre obj</context>
</contexts>
<marker>McRoy, 1992</marker>
<rawString>McRoy S. (1992), Using multiple knowledge sources for word sense discrimination, Actes de Computational Linguistics, pp.1-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Mooney</author>
</authors>
<title>Comparative experiments on disambiguating word senses : an illustration of the role of bias</title>
<date>1996</date>
<booktitle>in machine learning, Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>82--91</pages>
<contexts>
<context position="9272" citStr="Mooney, 1996" startWordPosition="1449" endWordPosition="1450">ne plus grande difficulté pour lever lambiguïté des adjectifs, et encore plus des verbes, par rapport aux noms. Laurent AUDIBERT 2.3 Définition des critères Il existe de nombreuses sources dinformation pour lever lambiguïté du sens des mots. Comme lont montré (McRoy, 1992), (Wilks, Stevenson, 1998) ou encore (Ng, Lee, 1996) toutes ces sources peuvent être utilisées simultanément pour aboutir à une meilleure désambiguïsation. Nous avons déjà présenté un inventaire non exhaustif des critères qui peuvent être étudiés (Audibert, 2002). De nombreuses études, comme par exemple (Ng, Lee, 1996), (Mooney, 1996) ou encore (Yarowsky, 1993), montrent que les cooccurrences constituent un bon critère pour identifier le sens dun mot. Dans cette étude, nous nous proposons détudier des critères élémentaires, basés sur les cooccurrences, sans chercher à les combiner. Notre objectif est de fournir des informations de référence pour lélaboration de critères plus complexes et de répondre à des questions comme lintérêt de la lemmatisation, lutilité des fenêtres de mots sans distinction de position (unordered set of surrounding words en anglais), limportance des mots grammaticaux ou encore les différences d</context>
</contexts>
<marker>Mooney, 1996</marker>
<rawString>Mooney R. J. (1996), Comparative experiments on disambiguating word senses : an illustration of the role of bias in machine learning, Conference on Empirical Methods in Natural Language Processing, pp.82-91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H T Ng</author>
<author>H B Lee</author>
</authors>
<title>Integrating multiple knowledge sources to disambiguate word sense : an exemplar-based approach,</title>
<date>1996</date>
<booktitle>Actes de 34th Annual Meeting of the Society for Computational Linguistics,</booktitle>
<pages>40--47</pages>
<marker>Ng, Lee, 1996</marker>
<rawString>Ng H. T., Lee H. B. (1996), Integrating multiple knowledge sources to disambiguate word sense : an exemplar-based approach, Actes de 34th Annual Meeting of the Society for Computational Linguistics, pp.40-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
</authors>
<title>Are WordNet sense distinctions appropriate for computational lexicons ?,</title>
<date>1998</date>
<booktitle>Actes de SIGLEX-98, SENSEVAL.</booktitle>
<contexts>
<context position="3631" citStr="Palmer, 1998" startWordPosition="508" endWordPosition="509">able (ex : lemme des cooccurrences). 2 Méthodologie 2.1 Corpus de travail La première phase de notre travail est l&apos;étiquetage de notre corpus avec le logiciel Cordial Analyseur (développé par la société Synapse Développement), qui offre une lemmatisation et un étiquetage morpho-syntaxique dune exactitude satisfaisante (Valli, Véronis, 1999). Cette phase nous affranchit de toute ambiguïté catégorielle comme le préconise (Kilgarriff, 1997). Lune des difficultés majeures de létiquetage sémantique automatique réside dans linadéquation des dictionnaires traditionnels (Véronis, 2001) ou dédiés (Palmer, 1998) pour cette tâche. Une autre difficulté (Gale, Church, Yarowsky, 1993) provient du manque de corpus sémantiquement étiquetés sur lesquels des méthodes d&apos;apprentissage supervisé peuvent être entraînées. Ce manque se transforme même en absence totale pour une langue comme le français alors quil commence à apparaître de tels corpus pour l&apos;anglais, notamment dans le cadre de l&apos;action d&apos;évaluation Senseval (Kilgarriff, Rosenzweig, 2000). Pour ces multiples raisons, notre équipe a entrepris la construction dun dictionnaire distributionnel en se basant sur un ensemble de critères différentiels stri</context>
</contexts>
<marker>Palmer, 1998</marker>
<rawString>Palmer M. (1998), Are WordNet sense distinctions appropriate for computational lexicons ?, Actes de SIGLEX-98, SENSEVAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Reymond</author>
</authors>
<title>Dictionnaires distributionnels et étiquetage lexical de corpus, Actes de RECITAL (TALN)</title>
<date>2001</date>
<pages>479--488</pages>
<contexts>
<context position="4250" citStr="Reymond, 2001" startWordPosition="594" endWordPosition="595"> cette tâche. Une autre difficulté (Gale, Church, Yarowsky, 1993) provient du manque de corpus sémantiquement étiquetés sur lesquels des méthodes d&apos;apprentissage supervisé peuvent être entraînées. Ce manque se transforme même en absence totale pour une langue comme le français alors quil commence à apparaître de tels corpus pour l&apos;anglais, notamment dans le cadre de l&apos;action d&apos;évaluation Senseval (Kilgarriff, Rosenzweig, 2000). Pour ces multiples raisons, notre équipe a entrepris la construction dun dictionnaire distributionnel en se basant sur un ensemble de critères différentiels stricts (Reymond, 2001). Ce dictionnaire comporte pour l&apos;instant la description détaillée de 20 noms, 20 verbes et 20 adjectifs totalisant plus de 53000 occurrences dans le corpus du projet SyntSem2 (Corpus denviron 5.5 millions de 1 Nous emploierons, dans cet article, le mot « cooccurrence » dans son acception la plus large, cest-à-dire des mots apparaissant dans le contexte, sans contrainte de fréquence, de figement ou de lien syntaxique. 2 Le projet SyntSem, financé par lELRA/ELDA, vise à produire un corpus étiqueté au niveau morphosyntaxique avec en plus un marquage syntaxique peu profond et un marquage séman</context>
</contexts>
<marker>Reymond, 2001</marker>
<rawString>Reymond D. (2001), Dictionnaires distributionnels et étiquetage lexical de corpus, Actes de RECITAL (TALN) 2001, pp.479-488.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Rivest</author>
</authors>
<title>Learning Decision Lists,</title>
<date>1987</date>
<booktitle>Actes de Machine Learning,</booktitle>
<pages>229--246</pages>
<contexts>
<context position="10052" citStr="Rivest, 1987" startWordPosition="1560" endWordPosition="1561">r des critères élémentaires, basés sur les cooccurrences, sans chercher à les combiner. Notre objectif est de fournir des informations de référence pour lélaboration de critères plus complexes et de répondre à des questions comme lintérêt de la lemmatisation, lutilité des fenêtres de mots sans distinction de position (unordered set of surrounding words en anglais), limportance des mots grammaticaux ou encore les différences de comportement entre les catégories grammaticales. 2.4 Algorithme de désambiguïsation L&apos;algorithme de classification des lexies utilisé est du type liste de décision (Rivest, 1987) pour sa simplicité de mise en uvre et son efficacité. Cette approche ne combine pas l&apos;information de tous les attributs de la description dont on cherche à déterminer la classe, mais se focalise sur un attribut unique, supposé véhiculer l&apos;information la plus fiable. Lalgorithme ici utilisé diffère de celui de létude préliminaire (Audibert, 2002) basé sur une mesure de dispersion. Il sagit dun algorithme très proche de celui de (Golding, 1995) qui constitue une généralisation à plus de deux classes de lalgorithme de (Yarowsky, 1995). Soit un exemple E dont nous désirons déterminer la lex</context>
</contexts>
<marker>Rivest, 1987</marker>
<rawString>Rivest R. L. (1987), Learning Decision Lists, Actes de Machine Learning, pp.229-246.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Valli</author>
<author>J Véronis</author>
</authors>
<title>Etiquetage grammatical de corpus oraux : problèmes et perpectives, Revue Française de Linguistique Appliquée, Association pour le traitement informatique des langues (ASSTRIL),</title>
<date>1999</date>
<pages>113--133</pages>
<marker>Valli, Véronis, 1999</marker>
<rawString>Valli A., Véronis J. (1999), Etiquetage grammatical de corpus oraux : problèmes et perpectives, Revue Française de Linguistique Appliquée, Association pour le traitement informatique des langues (ASSTRIL), pp.113-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Véronis</author>
</authors>
<title>Sense tagging : does it makes sense ?, Actes de Corpus Linguistics&apos;2001.</title>
<date>2001</date>
<contexts>
<context position="3606" citStr="Véronis, 2001" startWordPosition="504" endWordPosition="505"> dans le contexte d&apos;un vocable (ex : lemme des cooccurrences). 2 Méthodologie 2.1 Corpus de travail La première phase de notre travail est l&apos;étiquetage de notre corpus avec le logiciel Cordial Analyseur (développé par la société Synapse Développement), qui offre une lemmatisation et un étiquetage morpho-syntaxique dune exactitude satisfaisante (Valli, Véronis, 1999). Cette phase nous affranchit de toute ambiguïté catégorielle comme le préconise (Kilgarriff, 1997). Lune des difficultés majeures de létiquetage sémantique automatique réside dans linadéquation des dictionnaires traditionnels (Véronis, 2001) ou dédiés (Palmer, 1998) pour cette tâche. Une autre difficulté (Gale, Church, Yarowsky, 1993) provient du manque de corpus sémantiquement étiquetés sur lesquels des méthodes d&apos;apprentissage supervisé peuvent être entraînées. Ce manque se transforme même en absence totale pour une langue comme le français alors quil commence à apparaître de tels corpus pour l&apos;anglais, notamment dans le cadre de l&apos;action d&apos;évaluation Senseval (Kilgarriff, Rosenzweig, 2000). Pour ces multiples raisons, notre équipe a entrepris la construction dun dictionnaire distributionnel en se basant sur un ensemble de cr</context>
</contexts>
<marker>Véronis, 2001</marker>
<rawString>Véronis J. (2001), Sense tagging : does it makes sense ?, Actes de Corpus Linguistics&apos;2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
<author>M Stevenson</author>
</authors>
<title>Word sense disambiguation using optimised combinations of knowledge sources,</title>
<date>1998</date>
<booktitle>Actes de COLING-ACL&apos;98,</booktitle>
<pages>1398--1402</pages>
<marker>Wilks, Stevenson, 1998</marker>
<rawString>Wilks Y., Stevenson M. (1998), Word sense disambiguation using optimised combinations of knowledge sources, Actes de COLING-ACL&apos;98, pp.1398-1402.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>One sense per collocation,</title>
<date>1993</date>
<journal>Actes de ARPA Human Language Technology Workshop,</journal>
<pages>266--271</pages>
<contexts>
<context position="3701" citStr="Yarowsky, 1993" startWordPosition="518" endWordPosition="519">avail La première phase de notre travail est l&apos;étiquetage de notre corpus avec le logiciel Cordial Analyseur (développé par la société Synapse Développement), qui offre une lemmatisation et un étiquetage morpho-syntaxique dune exactitude satisfaisante (Valli, Véronis, 1999). Cette phase nous affranchit de toute ambiguïté catégorielle comme le préconise (Kilgarriff, 1997). Lune des difficultés majeures de létiquetage sémantique automatique réside dans linadéquation des dictionnaires traditionnels (Véronis, 2001) ou dédiés (Palmer, 1998) pour cette tâche. Une autre difficulté (Gale, Church, Yarowsky, 1993) provient du manque de corpus sémantiquement étiquetés sur lesquels des méthodes d&apos;apprentissage supervisé peuvent être entraînées. Ce manque se transforme même en absence totale pour une langue comme le français alors quil commence à apparaître de tels corpus pour l&apos;anglais, notamment dans le cadre de l&apos;action d&apos;évaluation Senseval (Kilgarriff, Rosenzweig, 2000). Pour ces multiples raisons, notre équipe a entrepris la construction dun dictionnaire distributionnel en se basant sur un ensemble de critères différentiels stricts (Reymond, 2001). Ce dictionnaire comporte pour l&apos;instant la descri</context>
<context position="9299" citStr="Yarowsky, 1993" startWordPosition="1453" endWordPosition="1454"> pour lever lambiguïté des adjectifs, et encore plus des verbes, par rapport aux noms. Laurent AUDIBERT 2.3 Définition des critères Il existe de nombreuses sources dinformation pour lever lambiguïté du sens des mots. Comme lont montré (McRoy, 1992), (Wilks, Stevenson, 1998) ou encore (Ng, Lee, 1996) toutes ces sources peuvent être utilisées simultanément pour aboutir à une meilleure désambiguïsation. Nous avons déjà présenté un inventaire non exhaustif des critères qui peuvent être étudiés (Audibert, 2002). De nombreuses études, comme par exemple (Ng, Lee, 1996), (Mooney, 1996) ou encore (Yarowsky, 1993), montrent que les cooccurrences constituent un bon critère pour identifier le sens dun mot. Dans cette étude, nous nous proposons détudier des critères élémentaires, basés sur les cooccurrences, sans chercher à les combiner. Notre objectif est de fournir des informations de référence pour lélaboration de critères plus complexes et de répondre à des questions comme lintérêt de la lemmatisation, lutilité des fenêtres de mots sans distinction de position (unordered set of surrounding words en anglais), limportance des mots grammaticaux ou encore les différences de comportement entre les ca</context>
<context position="21983" citStr="Yarowsky, 1993" startWordPosition="3505" endWordPosition="3506">linformation permettant la levée de lambiguïté était puisée en position 1 et +1, la majeure partie de linformation pour les verbes se trouve en position +2 et une part non négligeable se trouve en +3. Ensuite, on peut se rendre compte que la désambiguïsation des verbes se fait plus en fonction de leur objet que de leur sujet puisque la forme sujet-verbe-complément est la plus fréquente. Enfin, la forme de ce graphique inciterait à ne pas utiliser un contexte symétrique mais plutôt un contexte dissymétrique de la forme 2 +4 par exemple. Sur les particularités des catégories grammaticales (Yarowsky, 1993) obtenait des résultats analogues sur langlais en se limitant à deux lexies par mot et en utilisant des pseudo-mots possédant deux « sens ». Ces pseudo-mots peuvent être obtenus en fusionnant deux mots quelconques, ou homographes dans une autre langue, ou encore ne se distinguant que par une seule lettre, en un seul en gardant linformation du mot dorigine. Ces pseudo-mots permettent dobtenir directement des corpus de grande taille en saffranchissant de la phase détiquetage manuel. Etude des critères de désambiguïsation sémantique automatique 4 Perspectives et conclusion Le travail présen</context>
</contexts>
<marker>Yarowsky, 1993</marker>
<rawString>Yarowsky D. (1993), One sense per collocation, Actes de ARPA Human Language Technology Workshop, pp.266-271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Decision lists for lexical ambiguity resolution : application to accent restoration in spanish and french,</title>
<date>1995</date>
<booktitle>Actes de 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>88--95</pages>
<contexts>
<context position="10596" citStr="Yarowsky, 1995" startWordPosition="1645" endWordPosition="1646">ication des lexies utilisé est du type liste de décision (Rivest, 1987) pour sa simplicité de mise en uvre et son efficacité. Cette approche ne combine pas l&apos;information de tous les attributs de la description dont on cherche à déterminer la classe, mais se focalise sur un attribut unique, supposé véhiculer l&apos;information la plus fiable. Lalgorithme ici utilisé diffère de celui de létude préliminaire (Audibert, 2002) basé sur une mesure de dispersion. Il sagit dun algorithme très proche de celui de (Golding, 1995) qui constitue une généralisation à plus de deux classes de lalgorithme de (Yarowsky, 1995). Soit un exemple E dont nous désirons déterminer la lexie la plus probable lE, parmi un ensemble de lexies possibles L, en se basant sur la description D de E composée d&apos;un certain nombre d&apos;indices D={i1 in} générés par lapplication du critère étudié sur lexemple E. Soit A l&apos;ensemble des indices des exemples d&apos;apprentissage générés par lapplication du critère étudié sur le corpus dapprentissage. La lexie choisie est déterminée en se basant sur lindice considéré comme étant le plus fiable dans la liste de décision : lE=argmax(p(lexie/IndFia)) lexie∈L Lindice le plus fiable de la liste es</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>Yarowsky D. (1995), Decision lists for lexical ambiguity resolution : application to accent restoration in spanish and french, Actes de 33rd Annual Meeting of the Association for Computational Linguistics, pp.88-95.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>