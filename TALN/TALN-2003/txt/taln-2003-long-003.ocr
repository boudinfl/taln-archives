TALN 2003, Batz-sur-Mer, 11—14juin 2003

Nouvelle approche de la sélection de vocabulaire pour la
détection de theme

Armelle BRUN, Kamel SMAILI, J ean-Paul HATON
LORIA BP 239 54506 Vandoeuvre-Les-Nancy, France -
Tel : (33|0) 3-83-59-20-97, Fax :(33|0) 3-83-41-30-79
{brun, smaili, jph} @loria.fr

Mots-clefs — Keywords

Détection de theme, création de vocabulaire, combinaison
Topic detection, vocabulary creation, combination

Résumé - Abstract

En reconnaissance de la parole, un des moyens d’améliorer les performances des systemes est
de passer par l’adaptation des modeles de langage. Une étape cruciale de ce processus consiste a
détecter le theme du document traité et a adapter ensuite le modele de langage. Dans cet article,
nous proposons une nouvelle approche de création des vocabulaires utilisés pour la détection
de theme. Cette derniere est fondée sur le développement de vocabulaires spéciﬁques et ca-
ractéristiques des différents themes. Nous montrons que cette approche permet non seulement
d’améliorer les performances des méthodes, mais exploite également des vocabulaires de taille
réduite. De plus, elle permet d’améliorer de facon tres signiﬁcative les performances de mé-
thodes de détection lorsqu’elles sont combinées.

One way to improve performance of Automatic Speech Recognition (ASR) systems consists in
adapting language models. We are particularly interested in adapting language models to the
topic related in data. Before adapting the language model, this topic has to be detected. In this
work, we present a new way to create vocabularies used to detect the topic in a given text.
This new method results in the improvement of topic detection performance of the methods
studied, it also results in the reduction of the vocabulary size required. Finally, we show a
large improvement of the performance when combining topic identiﬁcation methods, when new
vocabularies are used.

A. Brun, K. Sma'1'li, J .P. Haton

1 Introduction

Les systemes de Reconnaissance Automatique de la Parole (RAP) actuels atteignent des perfor-
mances interessantes dans des applications ciblees. Les donnees en entree d’un systeme de RAP
se presentent sous la forme d’un signal acoustique correspondant a une phrase prononcee. Ces
donnees sont tout d’abord traitees par un module de traitement du signal acoustique. Malgre
des performances tres elevees de ce dernier, son utilisation seule ne permet pas d’obtenir des
resultats de reconnaissance sufﬁsamment eleves. En effet, bien que les phrases proposees par le
systeme soient tres proches acoustiquement de la suite de mots prononcee, ces demieres sont
bien souvent syntaxiquement incorrectes. Pour palier les faiblesses de ce module, un second
modele est exploite, en complement de celui-ci. 11 a pour fonction de modeliser la langue et
aura donc pour role d’afﬁner les differents scores des phrases proposees par le module acous-
tique, c’est le modele de langage.

Les modeles statistiques de langage des systemes de RAP modelisent la langue sous forme
probabiliste. Plus particulierement, ils evaluent la probabilite d’apparition d’un mot sachant les
mots le precedant dans la phrase (son historique). Les modeles les plus utilises a l’heure actuelle
sont les modeles de langage dits n—grammes. Ils estiment la probabilite d’apparition d’un mot
uniquement en fonction des n — 1 derniers mots le precedant. Pour des raisons d’estimation
de probabilites et de stockage, la taille de l’historique pris en compte (n — 1) ne depasse ge-
neralement pas 3. Le reproche fait a ce type de modele est justement de prendre en compte un
historique trop restreint. Pour pallier cet inconvenient, de nombreux modeles ont ete developpes
dans le but de mieux predire les mots.

Une des approches utilisees pour l’amelioration de la qualite de ces modeles consiste a adapter
le modele de langage du systeme aux caracteristiques du texte en cours de traitement. Dans
ce cadre, nous nous interessons a l’adaptation des modeles de langage au theme traite dans le
document. Nous considerons, en effet, que le vocabulaire utilise dans un texte est dependant du
theme traite dans ce dernier. Dans le cadre de l’adaptation, nous choisirons donc d’exploiter un
modele de langage representatif du theme traite dans le texte. Par consequent, l’etape cruciale
de cette adaptation est la recherche du theme traite dans le document.

Dans cet article, nous allons tout d’abord presenter le domaine de la detection de theme, et
notamment les deux grands parametres inﬂuengant la detection de theme : le vocabulaire et la
methode de detection de theme. Apres avoir introduit les donnees sur lesquelles nous travaillons,
nous allons exposer les performances en detection de theme obtenues par les methodes de l’etat
de l’art. Ensuite, nous presenterons une nouvelle methode de selection de vocabulaire et nous
etudierons les performances obtenues avec les nouveaux vocabulaires. Enﬁn, nous concluerons
et nous presenterons quelques perspectives a nos travaux.

2 La détection de théme

Soient un document donne et un ensemble predeﬁni de themes, la detection de theme a pour
but de rechercher le(s) theme(s) traite(s) dans ce document. Cette derniere est fonction de deux
parametres principaux qui sont le vocabulaire utilise et la methode de detection de theme. Le
vocabulaire deﬁnit l’ensemble des elements caracteristiques d’un theme. Classiquement, c’est
sur la base de l’ensemble des mots le constituant que la plupart des methodes fondent leurs
principes de detection.

Nouvelle approche de la sélection de vocabulaire pour la détection de theme

2.1 Vocabulaire

Dans un texte, toutes les informations présentes ne sont pas utiles pour la détection de theme.
Par exemple, il est assez intuitif que dans un document contenant la phrase « le gardien de
but n’a pas réussi a arréter le tir », les deux occurrences du mot « le » n’apportent aucune
information quant au theme traité dans un texte. A l’opposé, l’expression « gardien de but» est
tres importante et suggere que le texte traite de sport.

Dans le cadre de la détection de theme, un vocabulaire recense l’ensemble des caractéristiques
des themes utiles pour cette tache. Dans le domaine de la recherche d’informations, (Lewis,
1992) a montré que l’utilisation du mot comme unité de représentation d’un document semble
étre adaptée pour des taches de classiﬁcation. Pour cette raison, la majorité des méthodes de
détection de theme utilise le mot comme unité de représentation du document (représentation
bag of words). Par conséquent, les vocabulaires utilisés seront eux aussi composés de mots,
ceux les plus utiles pour la détection de theme. Dans nos travaux, nous considérons les mots
sous forme ﬂéchie, des travaux précédents (Frakes & Baeza-Yates, 1992) n’ayant montré aucun
gain dans l’emploi de lemmes.

La question qui se pose alors est de savoir quels sont ces mots. I1 existe dans la littérature plu-
sieurs méthodes permettant de trouver ces ensembles de mots (qui composeront le vocabulaire).
Nous présentons ici quatre méthodes de sélection de vocabulaire, parmi les plus étudiées.

2.1.1 Fréquence des mots

Dans le cas d’un vocabulaire sélectionné par fréquence de mots, on calcule, pour chacun des
mots du corpus d’apprentissage, sa fréquence d’apparition. Le vocabulaire sera ensuite composé
des mots de fréquence élevée. On considere dans ce cas que plus les mots sont fréquents a
l’apprentissage, plus ils sont utiles pour la détection de theme.

2.1.2 Fréquence de document des mots

Dans ce cas, on ne prend pas en compte la fréquence des mots a l’apprentissage, mais le nombre
de documents dans lesquels chaque mot est apparu. Le vocabulaire résultant sera composé des
mots apparus dans le plus grand nombre de documents.

2.1.3 Information mutuelle

La mesure d’information mutuelle quantiﬁe le lien existant entre un mot et un theme. Plus
précisément, elle évalue l’inﬂuence qu’a, sur le theme d’un texte, la présence d’un mot dans ce
texte. Pour un mot et un theme donnés, elle est évaluée de la facon suivante (Seymore et al.,
1998) :

I('w,-,T,-) = logP(wz- |  —1ogP(w,~) (1)

Classiquement, pour un mot donné, on calcule sa valeur d’information mutuelle avec chacun
des themes. Ensuite, ces valeurs sont combinées aﬁn d’obtenir une valeur unique pour chaque
mot. (Yang & Pedersen, 1997) montre que dans ce cas la meilleure facon de combiner consiste

A. Brun, K. Sma'1'li, J .P. Haton

a retenir, pour chaque mot, la valeur d’information mutuelle maximale parIr1i l’ensemble des
themes.

2.1.4 Gain d’information

Le gain d’information (également appelé information mutuelle moyenne) (Mitchell, 1996), per-
met, tout comme la mesure d’information mutuelle, de quantiﬁer le lien existant entre un mot
et un theme mais ne prend pas seulement en compte l’inﬂuence qu’a l’apparition d’un mot sur
un theme, il considere également sa non apparition, etc. La mesure de gain d’information se
calcule de la facon suivante :

P(w,T)

IG(w,-,T,-)= Z Z P(w,T)1og 

TE{Tj:Tj} w€{wi»"7z'}

(2)

Come dans le cas de l’information mutuelle, pour un mot donné, on a une valeur par theme
traité. Dans ce cas, (Yang & Pedersen, 1997) montre qu’il faut utiliser la moyenne pondérée des
valeurs de gain d’information entre le mot et chaque theme.

Pour l’ensemble des quatre mesures présentées ici, la qualité de chacun des mots dans le langage
est calculée. Celle-ci ne tient pas compte des caractéristiques des mots dans les themes, elle est
évaluée tous themes confondus. Le vocabulaire résultant sera composé de l’ensemble des mots
ayant, selon la mesure choisie, les valeurs les plus élevées.

2.2 Méthodes de détection de théme

Le second parametre dans cette approche est la méthode de détection de theme, qui déﬁnit la
facon dont les informations (mots) présentes dans les textes (suivant le vocabulaire utilisé) sont
exploitées.

Nous avons décidé d’étudier un ensemble de méthodes de l’état de l’art parIr1i les plus anciennes
(TFIDF), les plus performantes (cache et unigramme) ainsi que les plus récentes (SVM). Nous
avons également étudié une méthode issue du domaine de la RAP (perplexité). Toutes ces mé-
thodes ont été largement présentées dans la littérature, pour cette raison nous ne nous attarderons
pas sur leur presentation.

Sachant un vocabulaire donné, chacun des themes est tout d’abord schématisé sous la forme
d’un vecteur ou chaque élément représente la fréquence d’un mot du vocabulaire dans le corpus
d’apprentissage du theme. De la meme facon, le document de test (celui dont on recherche le
theme) est représenté sous forme de vecteur. L’ ensemble des méthodes présentées exploite ces
representations vectorielles.

2.2.1 Le classiﬁeur TFIDF

Le classiﬁeur TFIDF (Salton, 1991) est la référence dans le domaine, celui-ci étant un des
premiers modeles a avoir été développé. Dans le cas du classiﬁeur TFIDF, chacun des éléments
des vecteurs est pondéré par un facteur reﬂétant la proportion de themes dans lequel le mot est
présent. Ensuite, une distance cosine (3) est calculée entre le vecteur représentant le document

Nouvelle approche de la sélection de vocabulaire pour la détection de theme

et celui de chacun des themes. Le theme correspondant a la distance la plus faible sera celui
affecté au document.

Zi::1 djlcdik

3m(D"’D'")= IVI 2 IVI 2
Zk=1(djk) Zlczl dik)

(3)

2.2.2 Le modéle unigramme

Dans le modele unigramme (McDonough et al., 1994), une distribution de probabilités des
mots est calculée pour chaque theme. Ensuite, la probabilité de chaque theme est calculée (4),
le theme correspondant a la probabilité a posteriori la plus élevée sera le theme retenu.

‘ 2,{:1P(Tk)P(W1NlT.) (4)

2.2.3 Le modéle cache

Le modele cache (Bigi et al., 2000), dérive lui aussi une distribution de probabilités des mots
dans chacun des themes, mais également des mots dans le document de test (plus précisément
d’une fenétre cache des mots du test). Ensuite, la distance de Kullback-Leibler symétrique est
calculée entre la distribution des mots dans le document de test et celle des mots dans les themes.
Le theme retenu sera celui correspondant a la distance la plus faible. Pour de plus amples détails
sur ce modele, voir (Bigi et al., 2000).

2.2.4 Les Machines :71 Vecteur Support (SVM)

Contrairement aux trois autres méthodes déja présentées, la méthode SVM (Vapnik, 1995) traite
le cas biclasse. Dans ce cas, elle oppose le theme en cours de traitement a l’ensemble des autres
themes. Sachant une représentation dans un espace donné, des documents du theme ainsi que de
l’ensemble des autres documents, on recherche l’hyperplan optimal séparant les deux ensembles
de données. L’ originalité des SVM est qu’elles cherchent a maitriser l’erreur en généralisation.
Pour traiter le cas ou plus de deux classes (themes) sont utilisées, une étape de recombinaison
des scores est ensuite nécessaire pour retrouver le theme d’un document donné.

2.2.5 La perplexité

La perplexité (J elinek & Mercer, 1980) est issue du domaine de la reconnaissance de la parole.
La mesure de perplexité permet de mesurer l’adéquation entre un modele de langage et un
document donné. Si l’on développe un modele de langage par theme et que l’on calcule la
valeur de perplexité pour chacun des modeles de langage de theme sur le document de test,
alors le theme correspondant a la perplexité Ininimale sera considéré comme étant celui du
theme.

A. Brun, K. Sma'1'li, J.P. Haton

3 Résultats
3.1 Données

Les données sur lesquelles nous travaillons sont extraites de 5 années (1987-1991) du journal Le
Monde et sont divisées en 7 themes. Des ces demieres (environ 86M mots) nous avons extrait les
données de test, le reste formant le corpus d’apprentissage. Dans nos travaux, nous nous situons
dans le cadre de la recherche d’un seul theme dans un document. Cependant, les données sont
présentées sous la forme d’articles de journaux et nombre d’articles joumalistiques traitent de
plusieurs themes. Nous faisons l’hypothese qu’il est fort probable qu’un paragraphe donné ne
traite que d’un theme. Par conséquent, nous considérons que le corpus est constitué d’une suite
de paragraphes et que l’identiﬁcation porte sur chaque paragraphe et non sur l’article entier.
Le corpus de test regroupe un peu plus de 800 paragraphes, tirés aléatoirement des données,
étiquetés a la main par une unique personne. Les ﬁgures 1 et 2 présentent les proportions, en
fonction des themes, des données d’apprentissage et de test.

I I I I I I I I I—-I-—. I I I I I
I

I I I I I :11. I I I I I I I
Culture Economie Etranger Hiswire Politique Sciences Sports CI_I1tI_II.e Ewmmie EI_IaIIgeI. Hiswire Politique sciences sports

F1G- 1 — Répartition des données d’aPPFentiS' FIG. 2 — Répartition des données de test en
sage en fonction des themes fonction des themes

3.2 Performances

Les performances en détection de theme sont évaluées par rapport au taux de paragraphes dont
l’étiquette a été retrouvée par le module de détection de theme. Pour une méthode de détection
de theme et de sélection de vocabulaire ﬁxées, nous évaluons les performances en détection de
theme. Un parametre supplémentaire intervient, celui correspondant a la taille du vocabulaire
choisi, celle-ci ayant une grande inﬂuence sur les performances. La ﬁgure 3 présente, sachant
une méthode de détection de theme (unigramme) et une méthode de sélection de vocabulaire
(information mutuelle) ﬁxées, l’évolution des performances en fonction de la taille du voca-
bulaire. Dans ce cas, la taille optimale du vocabulaire est de 10K mots. Si le nombre de mots
retenus est inférieur ou supérieur, les performances sont plus faibles.

Par conséquent, pour chacune des méthodes de détection de theme, chacune des méthodes de
sélection de vocabulaire et un ensemble de tailles de vocabulaire, nous avons évalué les perfor-
mances en détection de theme. Dans le tableau 1 nous présentons seulement les performances
maximales obtenues par association du meilleur vocabulaire et de chaque méthode. La méthode
de sélection de vocabulaire ainsi que la taille correspondantes sont également précisées.

Nous pouvons remarquer que l’ensemble des méthodes atteint des performances supérieures a
74%. De plus, les vocabulaires optimaux sont composés de plus de 30K mots. Les deux mé-

Nouvelle approche de la sélection de vocabulaire pour la détection de theme

80 _  ' _

75 -fr". -

65 -5 —

55 I I I I I I I
0 5000 10000 15000 20000 25000 30000 35000 40C

FIG. 3 — Evolution des performances du modele unigramme utilisant un vocabulaire sélectionné
par information mutuelle en fonction de la taille du vocabulaire retenue

Méthode de détection Méthode de sélection Taille de Performances
de théme de vocabulaire vocabulaire

Unigramme Fréquence de document 30K 83.1 %
TFIDF Fréquence de mots 30K 74.3%

Cache Fréquence de mots 34K 82.5%
Perplexité Fréquence de mots 64K 79.0%

SVM Information mutuelle 40K 78.3%

TAB. 1 — Performances de chacune des méthodes de détection de theme en fonction de la
meilleure méthode de sélection de vocabulaire

thodes les plus performantes sont 1e modele cache et le modele unigramme, ce demier atteignant
des performances de 83.1%.

4 Nouvelle méthode de sélection de vocabulaire

Comme nous 1’avons déja mentionné, dans les méthodes classiques de sélection de vocabulaire,
la mesure de la qualité d’un mot est déﬁnie dans le langage, i. e. tous themes confondus. Les
meilleurs mots sont ensuite retenus.

Nous considérons, de notre cote, que le vocabulaire ne doit pas étre déﬁni au niveau de la langue
en général mais plutot au niveau des themes. Nous sommes convaincus que chaque theme a un
vocabulaire qui lui est propre et que les performances en détection de theme pourraient étre
améliorées si de tels vocabulaires pouvaient étre pris en compte. Prenons par exemple 1e cas des
deux mots «temps » et « match ». Le mot «temps » est un mot tres courant dans 1’ensemb1e des
themes. Si la méthode de sélection de vocabulaire est celle par fréquence de mots, ce mot sera
sélectionné pour composer le vocabulaire. Cependant, la présence de celui-ci dans un document
de test ne nous permettra pas de déterminer de facon efﬁcace 1e theme du texte puisqu’il est
fréquent dans 1’ensemb1e des themes. A 1’opposé, 1e mot « match » a une fréquence faible dans
1’ensemb1e des themes sauf pour le theme Sports. Dans le cas classique, ce mot ne sera pas
conservé puisqu’il n’est pas assez fréquent dans le corpus d’apprentissage. A 1’opposé, si 1’on
raisonne au niveau du theme, 1e mot « match » sera retenu pour le vocabulaire du theme Sports,
puisque fréquent dans ce demier.

A. Brun, K. Sma'1'li, J .P. Haton

Méthode de détection Méthode de sélection Taille de Performances
de théme de vocabulaire vocabulaire

TFIDF Information mutuelle 5K 74.4 %

Uni gramme Information mutuelle 1 5K 83.4 %

SVM Gain d’information 22K 78.7%

TAB. 2 — Performances en détection de theme de trois méthodes pour des vocabulaires de theme
de taille équivalente

Dans cette optique, nous exploitons les mesures présentées dans la section 2.1. Celles-ci se-
ront déﬁnies non plus au niveau du langage mais au niveau du theme. Ainsi, pour un theme
donné, nous évaluons la mesure pour l’ensemble des mots de l’apprentissage du theme. Nous
conservons ensuite les mots ayant les valeurs les plus élevées. Nous obtenons dans ce cas un
vocabulaire pour chacun des themes traités. Nous effectuons ensuite l’union de ces demiers aﬁn
de former le vocabulaire utilisé pour la représentation des données.

Dans ce cas, la méme question que dans le cas d’un vocabulaire déﬁni au niveau global se pose :
combien de mots doit-on conserver pour chaque vocabulaire ? Nous présentons maintenant un
cas spéciﬁque pour les vocabulaires de themes : nous conservons un nombre identique de mots
par theme.

4.1 Nombre identique de mots par théme

Dans le cas qui vient d’étre présenté, nous créons les vocabulaires de theme et nous retenons le
méme nombre de mots pour chaque theme. Ensuite, pour chacune des méthodes de détection de
theme et pour chaque méthode de sélection de vocabulaire, nous avons étudié les performances
en détection de theme en fonction du nombre de mots retenu par theme.

Le tableau 2 présente les meilleures performances associées a trois des méthodes de détection
de theme, ainsi que la méthode de sélection de vocabulaire associée et la taille du vocabulaire
correspondante.

Nous pouvons remarquer que pour les trois méthodes étudiées, les performances se sont ame-
liorées. Cette amélioration n’est cependant pas statistiquement signiﬁcative (entre +0.1% et
+0.4%). Un des points importants que nous pouvons noter est que les tailles de vocabulaire re-
quises par ce nouveau type de vocabulaire se sont largement réduites. Les méthodes unigramme
et SVM voient la taille de leur vocabulaire divisée par 2 et la TFIDF par 6.

4.2 Combinaison

Dans cette étude, nous avons présenté un ensemble de méthodes de détection de theme et nous
avons pu remarquer que chacune de ces méthodes obtenait des performances maximales avec
un vocabulaire qui lui était propre. De plus, celles-ci exploitent les données de facon différente.
Aﬁn d’améliorer les performances, nous envisageons d’exploiter les avantages de chacune de
ces méthodes. Pour atteindre cet objectif, nous avons décidé de combiner ces différentes mé-
thodes.

Pour les combiner, nous avons étudié un ensemble de méthodes : vote maj oritaire, combinaison

Nouvelle approche de la selection de vocabulaire pour la detection de theme

lineaire, SVM et reseau de neurones. Nous presentons ici la methode qui a permis d’obtenir les
meilleurs resultats : le reseau de neurones (perceptron multi-couches).

Sur la couche d’ entree du perceptron, nous disposons de 35 valeurs (chaque methode foumissant
un score pour l’ensemble des 7 themes, et nous etudions 5 methodes). La couche de sortie
comporte 7 neurones, un pour chacun des themes possibles. Le perceptron utilise comporte une
seule couche cachee avec 15 neurones et exploite l’algorithme de retropropagation. Aﬁn de ﬁxer
les poids des neurones du perceptron, nous utilisons une methode de validation croisee : nous
avons divise le corpus des 835 paragraphes en 7 sous-ensembles de tailles quasiment egales.
Ensuite, nous avons effectue 7 tests : nous avons optimise les parametres du perceptron sur 6/ 7
du corpus, puis nous avons evalue la qualite de ces valeurs sur 1/7 (le reste) du corpus.

Apres avoir effectue la combinaison, nous avons evalue le gain en performances obtenu pour
les deux types de vocabulaires etudies : tout d’abord les vocabulaires de l’etat de l’art et ensuite
les vocabulaires que nous proposons.

La combinaison des 5 methodes en utilisant les vocabulaires deﬁnis dans l’etat de l’art permet
d’atteindre des performances en detection de theme de 87.2%, ce qui correspond a une amelio-
ration des performances d’environ 5% (les performances les plus elevees dans ce cas etaient de
83.1%, modele unigramme). Cette amelioration est statistiquement signiﬁcative.

La methode de contruction de vocabulaire que nous avons propose ici a permis d’ ameliorer lege-
rement les performances (modele unigramme : 83.4%). Lorsque nous combinons les methodes
avec ces vocabulaires, les performances atteignent 93.1%, ce qui correspond a une amelioration
de pres 11.6% des performances en detection de theme.

Nous pouvons conclure que la methode de selection de vocabulaire que nous proposons per-
met non seulement d’ameliorer legerement les performances en detection de theme. De plus,
celle-ci amene a une reduction de la taille du vocabulaire necessaire pour atteindre les resultats
optimaux. Enﬁn, elle permet d’ameliorer les performances en detection de theme de facon tres
consequente (11.6%) lorsque les methodes sont combinees.

Pour essayer de comprendre cette amelioration, nous nous sommes interesses a la correlation
existant entre les scores foumis par les differentes methodes, en fonction des vocabulaires uti-
lises. Nous avons pu remarquer que lorsque les vocabulaires utilises etaient crees a l’aide de la
methode que nous proposons, la correlation existant entre les methodes est considerablement
reduite, ce qui permet un gain potentiel plus eleve. Cependant, il serait interessant d’etudier
l’apport de chacune des methodes dans le gain en performance, ce qui permettrait ensuite l’uti-
lisation d’un sous ensemble de celles-ci.

5 Conclusion et perspectives

Dans cet article, nous avons presente un ensemble de methodes de detection de theme ainsi que
des methodes de selection de vocabulaire. Nous avons evalue les performances obtenues par
ces methodes lorsqu’elles sont appliquees a nos donnees. L’ensemble de ces methodes atteint
des performances superieures a 74%. La methode la plus performante est le modele unigramme
avec 83.1%.

Apres avoir montre l’importance de la taille du vocabulaire utilise pour la detection de theme,
nous avons presente une nouvelle approche de la creation de vocabulaires. Celle-ci passe par

A. Brun, K. Sma'1'li, J .P. Haton

l’exploitation de vocabulaires de themes. Ensuite, on procede a l’union de ces demiers pour
obtenir le vocabulaire utilisé pour la détection de theme. L’ utilisation de ces vocabulaires a tout
d’abord montré deux avantages, elle permet non seulement d’améliorer les performances en de-
tection de themes des méthodes étudiées, mais également la réduction de la taille du vocabulaire
requise pour atteindre les performances maximales (facteur variant entre 2 et 6 en fonction des
méthodes).

Dans l’optique d’améliorer les performances en détection de theme, nous avons ensuite étudié
la combinaison des méthodes présentées. Nous avons cherché a combiner les résultats des mé-
thodes dans le cas o1‘1 les vocabulaires de la littérature sont exploités et également dans le cas o1‘1
les vocabulaires utilisés sont ceux que nous proposons. Le gain obtenu dans le premier cas est
important (5%). Celui constaté dans le cas de l’utilisation des vocabulaires que nous proposons
est beaucoup plus grand puisqu’un gain de 11.6% a été obtenu.

Au vu du gain obtenu par la combinaison de méthodes, nous envisageons de nous intéresser
a une autre facon de créer les vocabulaires utilisés pour la détection de theme. Jusqu’a pre-
sent, nous avons cherché les vocabulaires qui permettaient de maximiser les performances des
méthodes indépendamment les unes des autres. Il serait peut-étre intéressant de rechercher les
vocabulaires qui permettent d’obtenir les performances maximales en combinant les méthodes,
ces vocabulaires n’obtenant peut étre pas les meilleures performances pour chacune des mé-
thodes utilisées seules.

Références

BIGI B., DE MORI R., EL-BEZE M. & SPRIET T. (2000). A fuzzy decision strategy for topic identi-
ﬁcation and dynamic selection of language models. Special issue on Fuzzy Logic in Signal Processing,
Signal Processing Journal, 80(6), 1085-1097.

FRAKES W. & BAEZA-YATES R. (1992). Information Retrieval : Data Structures and Algorithms.
Prentice Hall, Englewood Cliffs,NJ.

JELINEK F. & MERCER R. (1980). Interpolated estimation of markov source parameters from sparse
data. In Proceedings of Workshop Pattern Recognition in Practice, p. 381-397, Amsterdam.

LEWIS D. (1992). An Evaluation of Phrasal and Clustered Representation on a Text Categorization Task.
In Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval,
p. 37-50.

MCDONOUGH J ., NG K., JEANRENAUD P., GISH H. & ROHLICEK J . (1994). Approaches to Topic
Identiﬁcation On The Switchboard Corpus. In IEEE Transactions on Acoustics, Speech, and Signal
Processing, p. 385-388.

MITCHELL T. (1996). Machine Learning, chapter 3. Mc Graw Hill.
SALTON G. (1991). Developments in Automatic Text Retrieval. Science, 253, 974-979.

SEYMORE K., CHEN S. & ROSENFELD R. (1998). Nonlinear Interpolation of Topic Models for Lan-
guage Model Adaptation. In Proceedings of the International Conference on Spoken Language Proces-
sing, Sydney, Australia.

VAPNIK V. (1995). The Nature of Statistical Learning Theory. Spinger, New York.

YANG Y. & PEDERSEN J . (1997). A comparative study on feature selection in text categorization. In
D. H. FISHER, Ed., 14th International Conference on Machine Learning, ICML-97, p. 412-420, San
Francisco, US 2 Morgan Kaufmann.

