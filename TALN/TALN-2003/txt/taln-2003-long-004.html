<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Classification automatique de textes &#224; partir de leur analyse syntaxico-s&#233;mantique</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2003, Batz-sur-Mer, 11&#8211;14 juin 2003
</p>
<p>Classification automatique de textes &#224; partir de leur analyse
syntaxico-s&#233;mantique
</p>
<p>Jacques Chauch&#233; , Violaine Prince
Simon Jaillet, Maguelonne Teisseire
</p>
<p>LIRMM-CNRS- Universit&#233; Montpellier 2
161 rue Ada, 34392 Montpellier cedex 5
</p>
<p>chauche@lirmm.fr, prince@lirmm.fr, jaillet@lirmm.fr, teisseir@lirmm.fr
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>Analyse, Classification, Extraction d&#8217;information
Parsing, Categorization, Information Extraction
</p>
<p>R&#233;sum&#233; - Abstract
</p>
<p>L&#8217;hypoth&#232;se soutenue dans cet article est que l&#8217;analyse de contenu, quand elle est r&#233;alis&#233;e par
un analyseur syntaxique robuste avec calcul s&#233;mantique dans un mod&#232;le ad&#233;quat, est un outil de
classification tout aussi performant que les m&#233;thodes statistiques. Pour &#233;tudier les possibilit&#233;s
de cette hypoth&#232;se en mati&#232;re de classification, &#224; l&#8217;aide de l&#8217;analyseur du Fran&#231;ais, SYGMART,
nous avons r&#233;alis&#233; un projet en grandeur r&#233;elle avec une soci&#233;t&#233; qui propose des s&#233;lections
d&#8217;articles en revue de presse. Cet article pr&#233;sente non seulement les r&#233;sultats de cette &#233;tude (sur
4843 articles finalement s&#233;lectionn&#233;s), mais aussi cherche &#224; montrer que l&#8217;analyse de contenu
automatis&#233;e, quand elle est possible, est un moyen fiable de produire une cat&#233;gorisation issue
du sens (quand il est calculable), et pas simplement cr&#233;&#233;e &#224; partir d&#8217;une reconnaissance de &quot;sim-
ilarit&#233;s&quot; de surface.
</p>
<p>This paper presents the assumption that discourse analysis, when perfomed by a robust parser
backed up by an accurate semantic model, is a classification tool as efficient as statistical meth-
ods. To study the capabilities of discourse analysis in classification, we have used a parser for
French, SYGMART, and applied it to a real project of press articles classification. This article
presents the results of this research (on a corpus of 4843 texts), and tries to show that auto-
matic discourse analysis, when possible, is an efficient way of classification through meaning
discrimination, and not simply relying on surface similarities recognition.
.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Chauch&#233;,Prince, Jaillet,Teisseire
</p>
<p>1 Introduction
</p>
<p>La classification automatique de textes est un domaine o&#249; la fouille de textes et les techniques
statistiques produisent des r&#233;sultats &#224; partir des calculs de fr&#233;quence d&#8217;occurrence de termes ex-
traits ( Salton et al 1983 ) . On peut aussi leur adjoindre des m&#233;thodes d&#8217;apprentissage, incluant
des mod&#232;les de r&#233;gression , l&#8217;approche k &#8722; nn (Yang et Liu 1999), des approches bayesiennes
na&#239;ves, ou adjointes &#224; des arbres de d&#233;cision (Lewis et Ringuetee 1994). L&#8217;analyse syntaxico-
s&#233;mantique &#233;tait consid&#233;r&#233;e, jusqu&#8217;&#224; pr&#233;sent, comme p&#233;nalisante en raison des limitations des
analyseurs eux-m&#234;mes. L&#8217;id&#233;e fondamentale de notre travail est que l&#8217;analyse de contenu, quand
elle est soutenue par un analyseur robuste1 avec calcul s&#233;mantique dans un mod&#232;le ad&#233;quat, est
un outil de classification tout aussi performant que les m&#233;thodes statistiques. En outre, elle
est peu sensible &#224; la qualit&#233; des corpus d&#8217;entra&#238;nement puisqu&#8217;elle se sert de ressources stables
(des dictionnaires non variants), alors que les m&#233;thodes statistiques y sont tr&#232;s sensibles. Pour
&#233;tudier les possibilit&#233;s de l&#8217;analyse syntaxique et du calcul s&#233;mantique en classification, &#224; l&#8217;aide
de nos outils (d&#233;crits en section 2), nous avons r&#233;alis&#233; un projet en grandeur r&#233;elle avec une so-
ci&#233;t&#233; qui propose des s&#233;lections d&#8217;articles en revue de presse, apr&#232;s une veille sur l&#8217;ensemble
des sources journalistiques possibles. Cette soci&#233;t&#233; doit classer plus de 5000 textes par jour et
a rapidement cherch&#233; &#224; automatiser la classification des textes obtenus. Elle a demand&#233; &#224; notre
&#233;quipe d&#8217;&#233;tudier les capacit&#233;s de classification des textes dans des cat&#233;gories journalistiques
quand on utilise l&#8217;analyseur SYGMARTTM. Cet article pr&#233;sente les r&#233;sultats de cette &#233;tude.
Les outils utilis&#233;s sont d&#233;crits dans la section 2, la m&#233;thode de cat&#233;gorisation et la proc&#233;dure
sont propos&#233;es en section 3. Quelques r&#233;sultats num&#233;riques sont pr&#233;sent&#233;s en section 4, et la
conclusion (section 5) cherchera &#224; instruire les m&#233;rites telle d&#233;marche.
Le principe de classification retenu et que expliciterons, est celui du filtrage s&#233;mantique de
textes par des cat&#233;gories repr&#233;sent&#233;es par des centro&#239;des, dans une m&#233;thode de cat&#233;gorisation
supervis&#233;e. L&#8217;originalit&#233; de la d&#233;marche est que l&#8217;outil d&#8217;analyse utilis&#233; pour la classification
n&#8217;est pas modifi&#233; par elle, et les algorithmes de classification se fondent sur la stabilit&#233; des
centro&#239;des.
</p>
<p>2 Outils de traitement automatique du langage appliqu&#233;s au
probl&#232;me de la cat&#233;gorisation
</p>
<p>Les outils utilis&#233;s pour r&#233;aliser cette cat&#233;gorisation sont un environnement complet d&#8217;analyse
syntaxique et s&#233;mantique (SYGMART) et les vecteurs s&#233;mantiques.
L&#8217;analyseur SYGMART est fond&#233; sur les algorithmes de Markov &#233;tendus aux arbres (?). Il a
&#233;t&#233; pr&#233;vu pour analyser tout langage dont on pourrait &#233;crire la grammaire sous forme de trans-
ducteurs d&#8217;arbres. Pour le Fran&#231;ais, une grammaire (3000 r&#232;gles &#224; ce jour) a &#233;t&#233; &#233;crite, inspir&#233;e
des travaux du linguiste J. Weissenborn. Associ&#233; &#224; SYGMART, se trouve un dictionnaire des
lexies (50000 entr&#233;es) poss&#233;dant par ailleurs une repr&#233;sentation vectorielle pour la s&#233;mantique.
La conjugaison de l&#8217;analyse syntaxique et de la repr&#233;sentation vectorielle permet d&#8217;affecter une
&quot;repr&#233;sentation s&#233;mantique&quot; &#224; des sous-textes, voire &#224; des textes entiers.
</p>
<p>1par robuste nous entendons capable de r&#233;aliser une analyse &#233;ventuellement partielle de toute phrase, m&#234;me
pour les phrases agrammaticales.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Classification automatique de textes
</p>
<p>2.1 Les vecteurs s&#233;mantiques &#224; la Roget
</p>
<p>Dans les d&#233;marches inspir&#233;es de Salton, on d&#233;finit un espace vectoriel &#224; partir des mots les plus
courants, o&#249; chaque texte est repr&#233;sent&#233; par un vecteur ~T tel que, lorsqu&#8217;il est projet&#233; sur la
composante i vaut ni, o&#249; ni est le nombre d&#8217;occurrences du mot i dans T . Cet espace devrait
varier chaque fois que l&#8217;on change de corpus de r&#233;f&#233;rence. Dans notre proposition, on projette
la totalit&#233; des lexies du dictionnaire sur un espace d&#233;fini &#224; partir d&#8217;une famille de concepts &quot;&#224; la
Roget&quot; (Roget 1852). Pour le Fran&#231;ais, les lexicologues du Larousse ont d&#233;fini une famille de
873 concepts hi&#233;rarchis&#233;s en 4 niveaux (Larousse 1992). Sur un plan vectoriel, cela produit un
espace &#224; 873 dimensions que l&#8217;on admet comme &#233;tant de dimension donn&#233;e.2.Notons que les
approches &#224; la &quot;Roget&quot; sont relativement nombreuses depuis quelques ann&#233;es, dans la litt&#233;rature
anglo-saxonne, (Yarowsky, 1992), (Ellman et Tait 1999). Pour le Fran&#231;ais, elle a &#233;t&#233; propos&#233;e &#224;
l&#8217;origine par Chauch&#233; (Chauch&#233; 1990), mais on retrouve des utilisations vectorielles autres que
saltoniennes dans (Besan&#231;on et Rajman 2002), et des approches avec th&#233;saurus comme celles
de Sin&#233;qua.
</p>
<p>2.1.1 Indexation des termes par les vecteurs
</p>
<p>Larousse propose pour chaque terme une indexation sur des concepts parmi les 873 du th&#233;saurus.
Par exemple, pour le terme &quot;autrefois&quot; on trouve : Autrefois : 195.1, 201.3 ce qui signifie que
l&#8217;adverbe &quot;autrefois&quot; se projette sur les concepts 195 (PASS&#201;) et 201 (ANCIENNET&#201;). Les
valeurs apr&#232;s le point (&quot;.&quot;) sont des indications morphologiques que l&#8217;on ne repr&#233;sentera pas ici.
Le vecteur de &quot;autrefois&quot; se pr&#233;sentera de la mani&#232;re suivante :
12 . . . . . . . . . . . . . . . . . . . . . . . . 195 ... 201.................... . . . . . . . . . . . . . . . . . . 873
(00 . . . . . . . . . . . . . . . . . . 0000..1..000..1 0 . . . . . . . . . . . . . . . . . . . . . . . . ..........0)
Le vecteur comprend des z&#233;ros sur toutes les composantes qui ne sont pas propos&#233;es comme
signifiantes par le Larousse, et comprend un &quot;1&quot; sur les composantes dites d&#8217;indexation, c&#8217;est-
&#224;-dire celles qui permettent de d&#233;finir le sens de ce terme.
</p>
<p>2.1.2 Espace vectoriel lexical
</p>
<p>On consid&#232;re que tout terme t du dictionnaire est repr&#233;sent&#233; par un vecteur ~t unique dans
l&#8217;espace vectoriel consid&#233;r&#233;, que l&#8217;on nommera ~V . On suppose qu&#8217;il existe une application qui
plonge l&#8217;espace lexical linguistique dans l&#8217;espace vectoriel engendr&#233; par la famille de concepts
du th&#233;saurus. Pour des besoins de calcul, si ~t est d&#8217;abord repr&#233;sent&#233; de la mani&#232;re indiqu&#233;e ci-
dessus pour &quot;autrefois&quot;, en revanche, seule une version norm&#233;e~tnor de ce vecteur est conserv&#233;e
dans l&#8217;espace. Comme on ne traite que de vecteurs norm&#233;s, par convention, on &#233;crira ~t pour
d&#233;signer le vecteur norm&#233; du terme t.
Pour normer les vecteurs on introduit une norme euclidienne sur l&#8217;espace vectoriel s&#233;mantique
~V . En se r&#233;f&#233;rant aux propri&#233;t&#233;s des espaces vectoriels, on d&#233;finit des lois de composition
interne et externe, dont la somme norm&#233;e, le produit par un scalaire (norm&#233;), et le produit vec-
toriel.
Somme norm&#233;e : Soient deux vecteurs ~t1, et ~t2 repr&#233;sentant les vecteurs (norm&#233;s) de deux
termes t1 et t2.
</p>
<p>&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8594;
(t1 + t2)nor =
</p>
<p>~t1+~t2
&#8214;~t1+~t2&#8214;
</p>
<p>(1)
</p>
<p>2Le choix de la repr&#233;sentation du th&#233;saurus a &#233;t&#233; discut&#233; dans deux pr&#233;c&#233;dents articles de l&#8217;&#233;quipe du LIRMM,
dans cette m&#234;me conf&#233;rence en 2001 et 2002. Le lecteur se r&#233;f&#232;rera aux actes idoines pour l&#8217; argumentation.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Chauch&#233;,Prince, Jaillet,Teisseire
</p>
<p>Remarque : la somme norm&#233;e n&#8217;est pas associative : &#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8594;(t1 + t2 + t3)nor n&#8217;est pas &#233;gal &#224; (&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8594;(t1 + t2)nor+
~t3))nor. Par convention, on ne retiendra comme op&#233;ration de somme que la somme norm&#233;e, et
on omettra dor&#233;navant l&#8217;indice &#8217;nor&#8217;.
Distance &quot;angulaire&quot;:La distance selon Salton, servant de mesure de similarit&#233; est calcul&#233;e
comme le cosinus de l&#8217;angle de deux vecteurs.
</p>
<p>sim(~t1, ~t2) = cos ~&#770;t1, ~t2 =
~t1.~t2
</p>
<p>&#8214;~t1 &#8727; ~t2&#8214;
(2)
</p>
<p>o&#249; &quot;.&quot; est le produit vectoriel classiquement d&#233;fini. La distance que nous utilisons correspond &#224;
une mesure relative &#224; l&#8217;angle ~&#770;t1, ~t2. Comme nous ramenons tous les angles consid&#233;r&#233;s &#224; l&#8217;espace
[0, pi
</p>
<p>2
], alors la mesure que nous proposons se calcule par :
</p>
<p>&#948;(~t1, ~t2) = 1&#8722; cos ~&#770;t1, ~t2 (3)
Remarques: Ramener les valeurs de &#948; &#224; [0, 1] est plus pratique que de mesurer des valeurs entre
0 et 1, 67 radiants. Lorsque deux vecteurs sont totalement divergents (intersection vide), leur
angle est de pi
</p>
<p>2
, et le cosinus vaut 0 : leur distance est maximale et vaut 1. Lorsque ces vecteurs
</p>
<p>sont tr&#232;s proches, leur angle tend vers 0 , le cosinus tend vers 1 et la distance, vers 0. Tous
les vecteurs ont un angle forc&#233;ment compris entre 0 et pi
</p>
<p>2
, par construction, et appartiennent au
</p>
<p>m&#234;me espace vectoriel.
</p>
<p>2.1.3 Espace vectoriel s&#233;mantique
</p>
<p>L&#8217;espace des points de ~V &#233;tant beaucoup plus grand que le nombre d&#8217;entr&#233;es dans un diction-
naire D, l&#8217;espace vectoriel peut contenir une quantit&#233; de vecteurs qui ne sont pas ceux des ter-
mes de D. Si l&#8217;on admet une hypoth&#232;se de compositionalit&#233; en s&#233;mantique linguistique, selon
laquelle le sens d&#8217;un ensemble de mots est une fonction des sens de chaque mot, on peut dire
que ~V d&#233;finit un v&#233;ritable espace s&#233;mantique, et pas seulement un espace s&#233;mantique lexical.
Pour toute suite x = w1w2 . . . .wn de mots de D, de vecteurs respectifs ~w1, ~w2, . . . , ~wn, il existe
un vecteur ~x dans ~V , et il existe une fonction fn de ~Vn dans ~V tels que : ~x = fn( ~w1, ~w2, . . . , ~wn)
et ce, pour tout n. Tout le probl&#232;me est donc de d&#233;finir les fn telles qu&#8217;elles puissent &#234;tre des
images formelles des fonctions linguistiques pr&#233;valant pour l&#8217;obtention de la s&#233;mantique des
ensembles ordonn&#233;s de mots que sont les phrases et, plus largement, les textes.
</p>
<p>2.2 Modes de calcul des vecteurs s&#233;mantiques des textes
</p>
<p>Le calcul du vecteur s&#233;mantique de tout segment de texte comprenant une suite de mots sera
fond&#233; sur une analyse syntaxique pr&#233;alable qui permettra de pond&#233;rer par un scalaire le vecteur
de chaque mot ou groupe de mots en fonction de son r&#244;le syntaxique.
</p>
<p>2.2.1 Vecteurs de groupe et de phrase
</p>
<p>L&#8217;analyseur SYGMART, apr&#232;s avoir affect&#233; des &#233;tiquettes aux diff&#233;rents termes d&#8217;une phrase,
commence par reconna&#238;tre des groupes (verbaux, nominaux, pr&#233;positionnels). Le calcul s&#233;man-
tique d&#8217;un vecteur est donc attach&#233; au groupe comme premier segment. Les vecteurs de groupe
sont des sommes norm&#233;es des vecteurs de mots du groupe pond&#233;r&#233;s, ou des vecteurs de groupe
qui composent le groupe. C&#8217;est pourquoi, tout groupe de niveau i dans l&#8217;arbre d&#8217;analyse, s&#8217;&#233;crit:
</p>
<p>~&#947;i =
</p>
<p>&#8721;
j
</p>
<p>&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8594;
(&#955;jvj,i+1)nor
</p>
<p>&#8214;&#8721;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8722;&#8594;(&#955;jvj,i+1)nor&#8214; (4)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Classification automatique de textes
</p>
<p>o&#249; les ~vj,i+1 d&#233;signent soit des vecteurs de mots, soit des vecteurs de sous-groupe d&#8217;un groupe,
de niveau imm&#233;diatement inf&#233;rieur (i + 1). &#955;j est une pond&#233;ration du r&#244;le syntaxique du mot
(respectivement du sous-groupe) dans le groupe. &#955;j est tel que si&#8722;&#8722;&#8722;&#8594;vj,i+1 a un r&#244;le de gouverneur,
alors &#955;j est &#233;gal au double des pond&#233;rations des autres vecteurs.
Le vecteur d&#8217;une phrase est calcul&#233; r&#233;cursivement comme celui d&#8217;un groupe de groupes. A
chaque &#233;tape d&#8217;analyse, tout groupe incluant un autre groupe (exemple GV -&gt; V GN : le calcul
du vecteur de GV imposera d&#8217;abord d&#8217;avoir calcul&#233; celui de son GN compl&#233;ment). Le vecteur
d&#8217;une phrase &#966; est donc celui du groupe de niveau 0 (ou racine). Au niveau de la phrase les
pond&#233;rations sont calcul&#233;es r&#233;cursivement de fa&#231;on &#224; maintenir une att&#233;nuation exponentielle.
</p>
<p>2.2.2 Vecteurs de textes et ensembles de textes
</p>
<p>Bien qu&#8217;il existe, dans un texte, une articulation qui donne une importance relative &#224; certaines
portions par rapport &#224; d&#8217;autres, dans un premier temps, nous avons consid&#233;r&#233; que les phrases
d&#8217;un texte &#233;taient &#233;quipotentes, et d&#233;fini le vecteur de texte comme &#233;tant le barycentre des
vecteurs de phrases. En pratique, l&#8217;application a montr&#233; que les introductions (attaques) et les
conclusions (chutes) pouvaient jouer un r&#244;le important. Les travaux de (Pery-Woodley 2000)
ou de Nadine Lucas, sur l&#8217;articulation des textes, nous ont permis d&#8217;am&#233;liorer la couverture
th&#233;matique des textes. Si le vecteur d&#8217;un texte T est calcul&#233; comme le barycentre des vecteurs
de ses phrases, le vecteur d&#8217;un ensemble de textes est calcul&#233; comme le barycentre des vecteurs
de textes, et est aussi un centro&#239;de.
</p>
<p>3 Application &#224; la classification de textes
</p>
<p>La projection s&#233;mantique de textes et d&#8217;ensembles de textes dans un espace permet de classer
des textes par rapport &#224; une direction vectorielle d&#233;finie comme r&#233;f&#233;rence. A la demande de
l&#8217;entreprise commanditaire, nous adoptons les cat&#233;gories qu&#8217;elle a d&#233;fini dans son r&#233;f&#233;rentiel
&quot;m&#233;tier&quot; et nous consid&#233;rons une m&#233;thode de classification supervis&#233;e.
</p>
<p>3.1 Constitution des vecteurs de chaque cat&#233;gorie
</p>
<p>Pour chaque cat&#233;gorie K un ensemble EK de textes est fourni comme &#233;tant le &quot;repr&#233;sentant&quot;
de K. Pour cela, nous calculons, pour chaque K, son vecteur de r&#233;f&#233;rence qui correspond au
centro&#239;de de EK . La repr&#233;sentation par centro&#239;de est courante dans le domaine (e.g. ( Eu-
Hong et Karypis 2000)) mais diff&#232;re tr&#232;s fortement des n&#244;tres par son mode d&#8217;obtention. Deux
conditions apparaissent n&#233;cessaires pour notre m&#233;thode :
il faut , tout d&#8217;abord, que le nombre de textes soit suffisamment grand pour que le centro&#239;de (le
vecteur de r&#233;f&#233;rence) soit le plus pr&#233;cis possible.
En outre, le centro&#239;de doit &#234;tre stable, c&#8217;est-&#224;-dire que la cat&#233;gorie puisse avoir une direction
vectorielle unique dans l&#8217;espace, qui ne fluctue plus, et qui puisse repr&#233;senter une tendance.
On dit que le centro&#239;de ~&#954; est stable si &#948;(~&#954; + ~T , ~T ) tend fortement vers 0, quel que soit T , le
texte consid&#233;r&#233;. L&#8217;avantage de la stabilisation du centro&#239;de d&#8217;une cat&#233;gorie K, repr&#233;sent&#233; par
~K, est que pour chaque nouveau texte, si on l&#8217;ajoute l&#233;gitimement &#224; EK , c&#8217;est-&#224;-dire qu&#8217;on le
r&#233;injecte dans le centro&#239;de, il ne modifie rien, et sa comparaison avec ~K (avec une m&#233;thode de
filtrage que nous allons expliciter) est fiable.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Chauch&#233;,Prince, Jaillet,Teisseire
</p>
<p>3.2 Classement d&#8217;un article dans une cat&#233;gorie par filtrage
</p>
<p>3.2.1 Vecteurs pour un article
</p>
<p>En th&#233;orie, c&#8217;est le centro&#239;de du texte qui repr&#233;sente le vecteur ~T . Cependant, pour chaque texte,
nous avons consid&#233;r&#233; un triplet compos&#233; de son centro&#239;de, de son vecteur introduction &#8722;&#8722;&#8722;&#8594;Tintro et
de son vecteur conclusion &#8722;&#8722;&#8722;&#8594;Tconcl. &#8722;&#8722;&#8722;&#8594;Tintro est calcul&#233; comme une somme norm&#233;e de l&#8217;ensemble
des phrases du texte mais avec une att&#233;nuation exponentielle des phrases en fonction de leur
rang. Les scalaires affect&#233;s sont de la forme &#945; &#8727; 1
</p>
<p>i
o&#249; i est le rang de la phrase. &#8722;&#8722;&#8722;&#8594;Tconcl est le
</p>
<p>vecteur sym&#233;trique de&#8722;&#8722;&#8722;&#8594;Tintro . Les coefficients affect&#233;s aux phrases sont de la forme &#945;&#8727;(1&#8722; 1n&#8722;i)
o&#249; n est le nombre total de phrases du texte. Pour classer un texte T dans une cat&#233;gorie K il
faut comparer son triplet (~T ,&#8722;&#8722;&#8722;&#8594;Tintro, &#8722;&#8722;&#8722;&#8594;Tconcl) avec le centro&#239;de ~K. Pour cela, nous avons envisag&#233;
plusieurs solutions, qui ont &#233;t&#233; appliqu&#233;es l&#8217;une apr&#232;s l&#8217;autre dans une recherche d&#8217;am&#233;lioration
de la classification.
La premi&#232;re est l&#8217;utilisation de la distance &#948; entre vecteurs : pour qu&#8217;elle soit suffisamment dis-
criminante, il faut que les vecteurs des cat&#233;gories soient bien diff&#233;renci&#233;s (donc distants) dans
~V .
Deuxi&#232;mement, le calcul d&#8217;une &quot;mesure de concordance&quot; et son utilisation comme crit&#232;re de
classement: si la pr&#233;c&#233;dente solution est insuffisante, il faut utiliser le vecteur de cat&#233;gorie
comme filtre s&#233;mantique.
Enfin, l&#8217;utilisation de la distance entre vecteurs concordants : c&#8217;est le probl&#232;me du choix
pr&#233;f&#233;rentiel d&#8217;une cat&#233;gorie par rapport &#224; une autre en fonction de l&#8217;intensit&#233; de la concordance.
</p>
<p>3.2.2 Mesure de concordance
</p>
<p>Tout vecteur de ~V a 873 composantes dont certaines n&#8217;ont que des intensit&#233;s tr&#232;s faibles et sont
donc peu significatives. Pour avoir une comparaison fiable et plus discriminante entre deux
vecteurs, nous avons consid&#233;r&#233; qu&#8217;ils devaient comparables sur les concepts qu&#8217;ils &quot;activent&quot;
le plus fortement, et jusqu&#8217;&#224; quel point ils activent ces concepts. Pour cela, il &#233;tait inutile
de conserver pour le centro&#239;de ~K toutes ses composantes et nous l&#8217;avons r&#233;duit, apr&#232;s l&#8217;avoir
tri&#233; (par ordre d&#233;croissant d&#8217;intensit&#233; de ses composantes) &#224; sa projection dans un espace plus
restreint, &#224; Nb dimensions, o&#249; Nb &lt; 873. Exp&#233;rimentalement, nous avons d&#233;termin&#233; que Nb
valait 250. Au-dessus, on conservait beaucoup de &quot;bruit&quot; dans la comparaison, et en dessous,
on n&#8217;avait pas un vecteur assez pr&#233;cis. On appelle ~Ktr le vecteur de cat&#233;gorie r&#233;duit tri&#233;. C&#8217;est
lui qui va servir de filtre.
On proc&#232;de de la m&#234;me mani&#232;re avec les vecteurs de texte et on produit ~Ttr (respectivement
les vecteurs introduction, et conclusion tri&#233;s. On ne proposera les formules ici que pour le
vecteur de texte). Il est clair que les composantes de ~Ktr ne sont pas forc&#233;ment les m&#234;mes
que celles de ~Ttr. Mais deux solutions sont possibles : ou bien les deux vecteurs n&#8217;ont aucune
composante (forte) commune, et auquel cas, cela se voit directement au calcul de la distance &#948;
(elle devient tr&#232;s proche de 1) ou bien ~Ktr et ~Ttr ont des plus fortes composantes communes, et
il est important de mesurer deux types d&#8217;&#233;cart: l&#8217;&#233;cart de rang et l&#8217;&#233;cart en intensit&#233;.
Ecart de rang : Soit i le rang d&#8217;une composante Ct du vecteur de r&#233;f&#233;rence ~Ktr , et &#961;(i) le rang
de cette m&#234;me composante dans le vecteur ~Ttr . La formule de l&#8217;&#233;cart est la suivante :
</p>
<p>E(i, &#961;(i)) =
(i&#8722; &#961;(i))2
</p>
<p>(Nb2 + (1 + i2 )
(5)
</p>
<p>Ecart en intensit&#233; : Non seulement le rang des composantes communes fortes est compar&#233;,
mais aussi leurs intensit&#233;s respectives. Soit ai l&#8217;intensit&#233; de la composante de rang i dans ~Ktr,</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Classification automatique de textes
</p>
<p>et b&#961;(i) l&#8217;intensit&#233; de cette m&#234;me composante, qui a le rang &#961;(i) dans ~Ttr. La formule de l&#8217;&#233;cart
en intensit&#233; est la suivante:
</p>
<p>I(i, &#961;(i)) =
&#8214;ai &#8722; b&#961;(i)&#8214;
Nb2 + 1+i2
</p>
<p>(6)
</p>
<p>Ces deux mesures sont ensuite utilis&#233;es dans la mesure de concordance P , dont la formule est:
</p>
<p>P ( ~Ksort, ~Tsort) = (
</p>
<p>&#8721;Nb&#8722;1
i=0
</p>
<p>1
1+E(i,&#961;(i))&#8727;I(i,&#961;(i))
</p>
<p>Nb
)2 (7)
</p>
<p>I(i, &#961;(i)) =
&#8214;ai &#8722; b&#961;(i)&#8214;
Nb2 + 1+i2
</p>
<p>(8)
</p>
<p>Propri&#233;t&#233;s: P n&#8217;est pas une mesure de similarit&#233; classique, car on peut montrer que P n&#8217;est pas
sym&#233;trique.Elle mesure l&#8217;ad&#233;quation entre deux vecteurs quand l&#8217;un des deux agit comme filtre.
P fonctionne de mani&#232;re &quot;inverse&quot; &#224; la distance de type angulaire &#948;. En effet, P est &#233;lev&#233;e lors
que &#948; tend vers 0. P est calcul&#233;e aussi de la m&#234;me fa&#231;on pour les autres vecteurs du triplet.
</p>
<p>3.2.3 Mesure de concordance et distance
</p>
<p>Pour affecter ensuite un texte &#224; une cat&#233;gorie, il ne suffit pas de savoir si le vecteur de ce texte
est suffisamment concordant avec le vecteur de la cat&#233;gorie, car la mesure de concordance peut
faire en sorte qu&#8217;il concorde avec plusieurs cat&#233;gories. Il faut alors classer pr&#233;f&#233;rentiellement le
texte dans une cat&#233;gorie. Soit &#948;( ~Ktr, ~Ttr) la distance &quot;angulaire&quot; entre le vecteur de texte et le
centro&#239;de de r&#233;f&#233;rence. Une nouvelle mesure de distance est propos&#233;e avec la formule ci-apr&#232;s
o&#249; &#946; est un coefficient permettant de renforcer l&#8217;importance de la concordance.
</p>
<p>4(( ~Ktr, ~Ttr) = P ((
~Ktr, ~Ttr)) &#8727; &#948;( ~Ktr, ~Ttr)
</p>
<p>&#946; &#8727; P (( ~Ktr, ~Ttr) + (1&#8722; &#946;)&#948;( ~Ktr, ~Ttr)
(9)
</p>
<p>4 est aussi calcul&#233; pour les autres vecteurs du triplet du texte.
</p>
<p>3.2.4 Vecteur de classement d&#8217;un texte
</p>
<p>Pour tout texte T , s&#8217;il existe p cat&#233;gories g&#233;n&#233;riquement nomm&#233;es Ki, on calcule un vecteur de
classement &#8722;&#8722;&#8722;&#8594;Tclass tel que la composante i&#232;me de ce vecteur est &#233;gale &#224; P ( ~Ktr(i), ~Ttr) (respec-
tivement &#224; 4( ~Ktr(i), ~Ttr)). Cela signifie que tout texte T est class&#233; puisqu&#8217;on peut calculer la
concordance par rapport &#224; chaque cat&#233;gorie. D&#8217;autre part, en triant son vecteur de classement
ce qui donne le vecteur &#8722;&#8722;&#8722;&#8722;&#8594;Tclass,tr, dans l&#8217;ordre d&#233;croissant des intensit&#233;s de ses concordances, on
obtient un vecteur dont les premi&#232;res composantes correspondent aux cat&#233;gories les plus con-
cordantes.
On calcule alors le vecteur des cat&#233;gories du texte T , qui est en fait le vecteur de dimension p
et d&#8217;intensit&#233;s Ki, par ordre d&#8217;importance. Il suffit de s&#233;lectionner la dimension du sous-vecteur
de ce vecteur pour avoir le nombre de cat&#233;gories, par ordre d&#233;croissant, avec lesquelles le texte
concorde le mieux, ainsi que les num&#233;ros (ou noms) de ces cat&#233;gories. On calcule de m&#234;me le
vecteur des cat&#233;gories de l&#8217;introduction et de la conclusion du texte T .</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Chauch&#233;,Prince, Jaillet,Teisseire
</p>
<p>3.3 Description de l&#8217;application
</p>
<p>3.3.1 Les donn&#233;es : corpus et cat&#233;gories
</p>
<p>Le jeu d&#8217;essai comporte 4843 articles de presse en Fran&#231;ais en provenance de plusieurs sources
(agences de presse, journaux, autres) se r&#233;partissant en 37 cat&#233;gories, repr&#233;sentant des rubriques
journalistiques, et livr&#233;es sous forme d&#8217;une liste plate. (Theeramunkong et Lertnattee 2002)
montrent qu&#8217;une liste plate pose intrins&#232;quement un probl&#232;me de pr&#233;cision de la classification.
Non seulement ces cat&#233;gories n&#8217;&#233;taient pas hi&#233;rarchis&#233;es, mais elles pouvaient avoir des re-
coupements entre elles.
Les cat&#233;gories repr&#233;sentent des secteurs et des m&#233;tiers (Banque, Logistique, H&#244;tellerie, Mode
et Textile, Recherche, etc.). Les textes peuvent contenir de quelques phrases &#224; quelques pages
chacun. Comme certains articles pouvent appartenir &#224; plus d&#8217;une cat&#233;gorie, la multiplicit&#233; des
affectations a permis d&#8217;&#233;tablir 5026 liens entre articles et cat&#233;gories. Les centro&#239;des ont &#233;t&#233; sta-
bilis&#233;s sur un noyau &#224; partir d&#8217;une centaine d&#8217;articles par cat&#233;gorie.
Le noyau repr&#233;sente 2400 premiers articles du jeu d&#8217;essai, soit environ 50%. Aucun choix s&#233;-
mantique n&#8217;a pr&#233;valu &#224; la d&#233;termination du noyau, &#224; part le fait qu&#8217;il fallait au moins 30 articles
par cat&#233;gorie pour avoir une chance de stabiliser une tendance (nombre &#224; partir duquel on peut
raisonnablement avoir une gaussienne). Le noyau contient 2555 liens de classe (plusieurs arti-
cles &#233;taient class&#233;s dans plusieurs cat&#233;gories). Le reste des articles a &#233;t&#233; utilis&#233; comme corpus
de v&#233;rification.
</p>
<p>3.3.2 Objectifs de la classification
</p>
<p>Les mesures de classification commun&#233;ment invoqu&#233;es sont le rappel et la pr&#233;cision du classe-
ment. La pr&#233;cision est traditionnellement d&#233;finie par le nombre de liens correctement produits
par rapport au nombre de liens produits (par le syst&#232;me). Le rappel est traditionnellement d&#233;fini
par le nombre de liens produits correctement (par le syst&#232;me) par rapport au nombre de liens
produits par les experts humains. Comme nous calculons toujours le vecteur de classement d&#8217;un
texte par rapport &#224; toutes les cat&#233;gories, la pr&#233;cision traditionnelle n&#8217;est pas tr&#232;s pertinente. En
revanche, ce qui int&#233;ressait le commanditaire, c&#8217;&#233;tait de retrouver , dans le vecteur des cat&#233;-
gories d&#8217;un texte, la ou les cat&#233;gories de classement propos&#233;e(s) par l&#8217;expert humain et dans
quelle position. Cela pourrait correspondre &#224; une notion de rappel (traditionnel). Cependant,
dans la mesure o&#249; d&#8217;une part, plusieurs articles relevaient de classements multiples, et d&#8217;autres
part, l&#8217;entreprise cherchait &#233;ventuellement &#224; d&#233;couvrir quelques classements in&#233;dits, nous avons
d&#233;fini une notion de largeur de recherche, d&#233;not&#233;e par m, qui correspond au nombre de cat&#233;-
gories parmi lesquelles on cherche &#224; retrouver le classement de l&#8217;expert. Si on consid&#232;re cette
fois-ci le nombre de liens produits par le syst&#232;me &#233;gal &#224; la largeur m, alors, ce que l&#8217;on mesure
est effectivement une &quot;pr&#233;cision&quot;, mais d&#8217;une facture un peu particuli&#232;re. Soit cr le compteur
des classements corrects. Soit cat(exp, T ) le(s) num&#233;ro(s)(ou nom de la cat&#233;gorie(s)) affect&#233;(s)
par l&#8217;expert au texte T . L&#8217;algorithme de d&#233;compte des classements corrects (en figure 1) incr&#233;-
mente ce compteur si le lien est correct dans deux vecteurs des cat&#233;gories au moins du triplet
&#8217;(texte, introduction, conclusion)&#8217;, dont le vecteur des cat&#233;gories du texte. cr(m) donne le nom-
bre de classements corrects sur une largeur m, c&#8217;est-&#224;-dire que cr(m)
</p>
<p>m
fournit la pr&#233;cision. Si on
</p>
<p>devait calculer le rappel sur une largeur m on aurait d&#251; avoir de la part des experts humains,
un nombre de liens &#233;gal &#224; au moins m par texte, or ce n&#8217;est pas le cas. On ne peut donc pas
calculer un rappel traditionnel dans des conditions rigoureuses. C&#8217;est pourquoi nous d&#233;finissons</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Classification automatique de textes
</p>
<p>Pour tout texte T , ~VT son vecteur de cat&#233;gorie, et ~VT (i) la i&#232;me composante de ~VT
Pour i = 1 &#224; m faire
</p>
<p>si ~VT (i) = cat(exp, T ) et ~VT intro(i) = cat(exp, T )
ou ~VT (i) = cat(exp, T ) et ~VT concl(i) = cat(exp, T )
</p>
<p>alors cr = cr + 1
</p>
<p>Figure 1: D&#233;compte des classements corrects
</p>
<p>une mesure pi(m) de la mani&#232;re suivante. Soit cr(m) le nombre de liens de classement corrects
pour les articles du corpus. Soit n le nombre de liens de r&#233;f&#233;rence du corpus. pi(m) = cr(m)
</p>
<p>n
.
</p>
<p>4 R&#233;sultats
</p>
<p>La distance &#948; entre deux cat&#233;gories &#233;tant elle-m&#234;me souvent inf&#233;rieure &#224; 0, 01 (un angle de
quelques degr&#233;s seulement), la discrimination de cette seule mesure n&#8217;&#233;tait pas suffisante. Le
passage &#224; la recherche de la concordance P ( ~Ktr(i), ~Ttr) (respectivement les deux autres vecteurs
du triplet), pour les valeurs des composantes du vecteur de classement, est de meilleure qualit&#233;
car on a pu s&#233;lectionner les vecteurs concordants &#224; une cat&#233;gorie avec plus de nettet&#233;. C&#8217;est
4(( ~Ktr(i), ~Ttr) (respectivement les deux autres vecteurs du triplet) qui a &#233;t&#233; finalement choisie
car la plus probante. Gr&#226;ce &#224; elle, pi(1), qui est le &quot;pire des cas&quot; a quand m&#234;me atteint 47%. Nos
premiers essais ont donn&#233; les r&#233;sultats fournis en figure 2. Les pourcentages ont &#233;t&#233; arrondis &#224;
l&#8217;unit&#233; la plus proche. Remarques : Il est difficile d&#8217;avoir des corpus dont la taille et le nombre
</p>
<p>Valeurs de pi(m) Noyau Corpus V&#233;rification
pi(1), 1 cat&#233;gorie 49% 42%
pi(2), 2 cat&#233;gories 64% 58%
pi(3),3 cat&#233;gories 75% 70%
Nombre de textes 2400 2443
Nombre de liens 2555 2471
</p>
<p>Figure 2: Comparaison du noyau et du corpus de v&#233;rification
</p>
<p>de liens sont exactement identiques. Nous avons fait au mieux pour avoir des nombres tr&#232;s
proches . Les r&#233;sultats montrent une diff&#233;rence relativement faible entre le noyau et le corpus
de v&#233;rification (elle est au pire de 7%), c&#8217;est qui nou am&#232;ne &#224; dire que la m&#233;thode est peu sen-
sible &#224; un entra&#238;nement. Les essais faits avec des m&#233;thodes comme k &#8722; nn ou comme SVM
montrent des diff&#233;rences tr&#232;s nettes entre noyau d&#8217;entra&#238;nement et corpus de test (Jaillet et al.
2003). Les premiers r&#233;sultats (que nous mentionnons juste) montrent pour k &#8722; nn un rappel de
71, 5% pour le noyau, mais de 16, 5% sur le corpus de test. Ces r&#233;sultats sont temporaires (non
valid&#233;s sur les m&#234;mes corpus) mais relativement indicatifs. Le fait d&#8217;avoir doubl&#233; le nombre
d&#8217;articles (au total) ne change pas significativement les valeurs de pi. La &quot;largeur&quot; (nombre de
cat&#233;gories consid&#233;r&#233;es) introduit une diff&#233;rence de plus grande ampleur. C&#8217;est pourquoi nous
avons fourni (au commanditaire) un classement global de 4483 articles avec un ratio de 72%
environ sur une largeur de trois cat&#233;gories.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Chauch&#233;,Prince, Jaillet,Teisseire
</p>
<p>5 Conclusion
</p>
<p>Dans cet article nous avons pr&#233;sent&#233; une m&#233;thode de classification de documents fond&#233;e sur
l&#8217;analyse syntaxique et le calcul s&#233;mantique &#224; base de vecteurs d&#8217;indexation. Nous avons donn&#233;
les r&#232;gles de calcul s&#233;mantique, et les extensions de la repr&#233;sentation aux textes et ensembles
de textes, dont certains peuvent &#234;tre regroup&#233;s th&#233;matiquement. Ces r&#232;gles sont fond&#233;es sur la
capacit&#233; d&#8217;analyse syntaxique automatique qui n&#8217;est souvent pas compl&#232;te en raison des am-
bigu&#239;t&#233;s ou des formes inconnues qui &#233;maillent les textes r&#233;els. SYGMART r&#233;alise toujours
une analyse partielle, et l&#8217;on peut calculer les vecteurs de groupes, sinon de phrase. L&#8217;analyse
partielle peut induire une mauvaise repr&#233;sentation aussi bien au niveau du centro&#239;de de cat&#233;-
gorie qu&#8217;au niveau des vecteurs de texte. C&#8217;est pourquoi, afin d&#8217;am&#233;liorer la classification, nous
orientons notre recherche vers l&#8217;&#233;tude de l&#8217;impact du seuil d&#8217;analyse syntaxique sur la classifi-
cation. Un passage complet des 4843 textes montre qu&#8217;environ 56, 5% d&#8217;entre eux poss&#233;daient
un seuil d&#8217;analyse de de 30% (un tiers seulement des phrases de chaque texte sont analys&#233;es
enti&#232;rement et correctement). Nous menons des exp&#233;riences sur des sous-ensembles de textes
pour la recherche d&#8217; un seuil d&#8217;analyse optimal sur un corpus compl&#233;mentaire de 14000 textes.
</p>
<p>R&#233;f&#233;rences
Besan&#231;on R., Rajman M. (2002) Validation de la notion de similarit&#233; textuelle dans un cadre multilingue.
Actes des JADT2002. Pp.149-159.
Chauch&#233; J.(1984) Un outil d&#8217;analyse multi-dimensionnelle du discours. Proc. of COLING-84.
Chauch&#233; J. (1990) D&#233;termination s&#233;mantique en analyse structurelle : une exp&#233;rience bas&#233;e sur une
d&#233;finition de distance. TA Information vol 1/1, p 17-24.
Ellman J., Tait, J. (1999) Roget&#8217;s thesaurus: An additional Knowledge Source for Textual CBR? Proc.
of 19th SGES Int. Conf. on Knowledge-Based and Applied AI. Springer-Verlag.pp 204 &#8211; 217.
Eui-Hong H., Karypis, G. (2000) Centroid-Based Document Classification: Analysis and Experimental
Results. Proc. of PKDD, p 424-431.
Jaillet S., Chauch&#233; J., Prince V., Teisseire M.(2003) Classification automatique de documents: la mesure
de deux &#233;carts. Rapport de Recherche LIRMM 18p.
Larousse.(1992) Th&#233;saurus Larousse - des id&#233;es aux mots, des mots aux id&#233;es. Paris.
Lewis D.D., Ringuetee, M.(1994) A Comparison of Two Learning Algorithms for Text Categorization.
Proc. of 3rd An. Symp.on Document Analysis and Information Retrieval Pp 81-93.
Pery-Woodley, M.P. (2000) Une pragmatique &#224; fleur de texte : approche en corpus de l&#8217;organisation
textuelle. Carnets de grammaire N&#9702;8, 164 p, Universit&#233; deToulouse-Le Mirail : ERSS.
Roget P.(1852) Thesaurus of English Words and Phrases Longman, London.
Salton G. , Fox E.A, Wu H. (1983) Extended Boolean Information retrieval. Communications of the ACM
26 (12). Pp. 1022-1036.
Theeramunkong T., Lertnattee V. (2002) Multi-Dimensional Text Classification. Proc.of COLING2002.
Pp1002-1008.
Yang Y., Liu X.(1999)A Re-examination of Text Categorization Methods Proc. of the 22nd ACM SIGIR
Conference, Pp 42-49.
Yarowsky D. (1992) Word-Sense Disambiguation Using Statistical Models of Roget&#8217;s Categories Trained
on Large Corpora. Proc. of COLING92.</p>

</div></div>
</body></html>