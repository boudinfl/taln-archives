TALN 2003, Batz-sur-Mer, 11-14 juin 2003

Classiﬁcation automatique de textes a partir de leur analyse
syntaxico-sémantique

Jacques Chauché , Violaine Prince
Simon J aillet, Maguelonne Teisseire
LIRMM-CNRS- Université Montpellier 2
161 rue Ada, 34392 Montpellier cedex 5
chauche@lirmm.fr, prince@lirrnm.fr, jaillet@lirmm.fr, teisseir@lirmm.fr

Mots-clefs — Keywords

Analyse, Classiﬁcation, Extraction d’information
Parsing, Categorization, Information Extraction

Résumé - Abstract

L’hypothese soutenue dans cet article est que l’analyse de contenu, quand elle est réalisée par
un analyseur syntaxique robuste avec calcul sémantique dans un modele adéquat, est un outil de
classiﬁcation tout aussi performant que les méthodes statistiques. Pour étudier les possibilités
de cette hypothese en matiere de classiﬁcation, a l’aide de l’analyseur du Frangais, SYGMART,
nous avons réalisé un projet en grandeur réelle avec une société qui propose des selections
d’articles en revue de presse. Cet article présente non seulement les résultats de cette étude (sur
4843 articles ﬁnalement sélectionnés), mais aussi cherche a montrer que l’analyse de contenu
automatisée, quand elle est possible, est un moyen ﬁable de produire une categorisation issue
du sens (quand il est calculable), et pas simplement créée a partir d’une reconnaissance de "sim-
ilarités" de surface.

This paper presents the assumption that discourse analysis, when perfomed by a robust parser
backed up by an accurate semantic model, is a classiﬁcation tool as efﬁcient as statistical meth-
ods. To study the capabilities of discourse analysis in classiﬁcation, we have used a parser for
French, SYGMART, and applied it to a real project of press articles classiﬁcation. This article
presents the results of this research (on a corpus of 4843 texts), and tries to show that auto-
matic discourse analysis, when possible, is an efﬁcient way of classiﬁcation through meaning
discrimination, and not simply relying on surface similarities recognition.

Chauche,Prince, J aillet,Teisseire

1 Introduction

La classiﬁcation automatique de textes est un domaine ou la fouille de textes et les techniques
statistiques produisent des resultats a partir des calculs de frequence d’occurrence de termes ex-
traits ( Salton et al 1983 ) . On peut aussi leur adjoindre des methodes d’apprentissage, incluant
des modeles de regression , l’approche is — rm (Yang et Liu 1999), des approches bayesiennes
na'1'ves, ou adjointes a des arbres de decision (Lewis et Ringuetee 1994). L’ analyse syntaxico-
semantique etait consideree, jusqu’a present, comme penalisante en raison des limitations des
analyseurs eux-memes. L’ idee fondamentale de notre travail est que l’analyse de contenu, quand
elle est soutenue par un analyseur robustel avec calcul semantique dans un modele adequat, est
un outil de classiﬁcation tout aussi performant que les methodes statistiques. En outre, elle
est peu sensible a la qualite des corpus d’entrainement puisqu’elle se sert de ressources stables
(des dictionnaires non variants), alors que les methodes statistiques y sont tres sensibles. Pour
etudier les possibilites de l’analyse syntaxique et du calcul semantique en classiﬁcation, a l’aide
de nos outils (decrits en section 2), nous avons realise un projet en grandeur reelle avec une so-
ciete qui propose des selections d’articles en revue de presse, apres une veille sur l’ensemble
des sources journalistiques possibles. Cette societe doit classer plus de 5000 textes par jour et
a rapidement cherche a automatiser la classiﬁcation des textes obtenus. Elle a demande a notre
equipe d’etudier les capacites de classiﬁcation des textes dans des categories journalistiques
quand on utilise l’analyseur SYGMARTTM. Cet article presente les resultats de cette etude.
Les outils utilises sont decrits dans la section 2, la methode de categorisation et la procedure
sont proposees en section 3. Quelques resultats numeriques sont presentes en section 4, et la
conclusion (section 5) cherchera a instruire les merites telle demarche.

Le principe de classiﬁcation retenu et que expliciterons, est celui du ﬁltrage sémantique de
textes par des categories representees par des centro'1'des, dans une methode de categorisation
supervisee. L’ originalite de la demarche est que l’outil d’analyse utilise pour la classiﬁcation
n’est pas modiﬁe par elle, et les algorithmes de classiﬁcation se fondent sur la stabilite des
centro'1'des.

2 Outils de traitement automatique du langage appliqués au
probléme de la categorisation

Les outils utilises pour realiser cette categorisation sont un environnement complet d’analyse
syntaxique et semantique (SYGMART) et les vecteurs semantiques.

L’ analyseur SYGMART est fonde sur les algorithmes de Markov etendus aux arbres (?). II a
ete prevu pour analyser tout langage dont on pourrait ecrire la grammaire sous forme de trans-
ducteurs d’arbres. Pour le Frangais, une grammaire (3000 regles a ce jour) a ete ecrite, inspiree
des travaux du linguiste J. Weissenborn. Associe a SYGMART, se trouve un dictionnaire des
lexies (50000 entrees) possedant par ailleurs une representation vectorielle pour la semantique.
La conjugaison de l’analyse syntaxique et de la representation vectorielle permet d’affecter une
"representation semantique" a des sous-textes, voire a des textes entiers.

lpar robuste nous entendons capable de realiser une analyse eventuellement paxtielle de toute phrase, meme
pour les phrases agrammaticales.

Classiﬁcation automatique de textes

2.1 Les vecteurs sémantiques £1 la Roget

Dans les démarches inspirées de Salton, on déﬁnit un espace vectoriel a partir des mots les plus
courants, o1‘1 chaque texte est représenté par un vecteur if tel que, lorsqu’il est projeté sur la
composante i vaut n,-, o1‘1 72,- est le nombre d’occurrences du mot i dans T. Cet espace devrait
varier chaque fois que l’on change de corpus de référence. Dans notre proposition, on projette
la totalité des lexies du dictionnaire sur un espace déﬁni a partir d’une famille de concepts "a la
Roget" (Roget 1852). Pour le Francais, les lexicologues du Larousse ont déﬁni une famille de
873 concepts hiérarchisés en 4 niveaux (Larousse 1992). Sur un plan vectoriel, cela produit un
espace a 873 dimensions que l’on admet comme étant de dimension donnée.2.Notons que les
approches a la "Roget" sont relativement nombreuses depuis quelques années, dans la littérature
anglo-saxonne, (Yarowsky, 1992), (Ellman et Tait 1999). Pour le Francais, elle a été proposée a
l’origine par Chauché (Chauché 1990), mais on retrouve des utilisations vectorielles autres que
saltoniennes dans (Besancon et Rajman 2002), et des approches avec thésaurus comme celles
de Sinéqua.

2.1.1 Indexation des termes par les vecteurs

Larousse propose pour chaque terme une indexation sur des concepts parmi les 87 3 du thésaurus.
Par exemple, pour le terme "autrefois" on trouve : Autrefois : 195.1, 201.3 ce qui signiﬁe que
l’adverbe "autrefois" se projette sur les concepts 195 (PASSI-/3) et 201 (ANCIENNETI-/3). Les
valeurs apres le point (".") sont des indications morphologiques que l’on ne représentera pas ici.
Le vecteur de "autrefois" se présentera de la maniere suivante :

12 . . . . . . . . . . . . . . . . . . . . . . ..195   . . . . . . . . . . . . . . . . ..873

(00 . . . . . . . . . . . . . . . . ..0000..1..000..10..................................0)

Le vecteur comprend des zéros sur toutes les composantes qui ne sont pas proposées comme
signiﬁantes par le Larousse, et comprend un "1" sur les composantes dites d’indexation, c’est-
a-dire celles qui permettent de déﬁnir le sens de ce terme.

2.1.2 Espace vectoriel lexical

On considere que tout terme t du dictionnaire est représenté par un vecteur 5 unique dans

l’espace vectoriel considéré, que l’on nommera )7 . On suppose qu’il existe une application qui
plonge l’espace lexical linguistique dans l’espace vectoriel engendré par la famille de concepts

du thésaurus. Pour des besoins de calcul, si 7? est d’abord représenté de la maniere indiquée ci-
dessus pour "autrefois", en revanche, seule une version norméetmr de ce vecteur est conservée

dans l’espace. Come on ne traite que de vecteurs normés, par convention, on écrira F pour
désigner le vecteur normé du terme t.
Pour normer les vecteurs on introduit une norme euclidienne sur l’espace vectoriel sémantique

V. En se référant aux propriétés des espaces vectoriels, on déﬁnit des lois de composition
interne et exteme, dont la somme normée, le produit par un scalaire (normé), et le produit vec-
toriel. _’ _’

Somme normée : Soient deux vecteurs 751, et 75; représentant les vecteurs (normés) de deux
termes t1 et t2.

ti+tE

T (1)
”t1+t2|l

T)
(t1 + t2)7wr =

2Le choix de la representation du thesaurus a été discuté dans deux precedents articles de1’équipe du LIRMM,
dans cette meme conference en 2001 et 2002. Le lecteur se réferera aux actes idoines pour 1’ argumentation.

Chauché,Prince, J aillet,Teisseire

, , u u   , / \  
Remarque : la somme normee n est pas assoc1at1ve : (751 + t2 + t3)m,, n est pas egal a ((751 + t2)m,T+

t_3:))m,,. Par convention, on ne retiendra comme opération de somme que la somme normée, et
on omettra dorénavant l’indice ’nor’.

Distance "angulaire":La distance selon Salton, servant de mesure de similarité est calculée
comme le cosinus de l’angle de deux vecteurs.

_ .. .. :\.. t_‘.t_‘
s1m(t1,t2) = cos t1,t = e (2)
H751 * 752 ||

ou "." est le produit vectoriel classiquement déﬁni. La distance que nous utilisons correspond a
une mesure relative a l’angle t1, t3. Comme nous ramenons tous les angles considérés a l’espace
[0, g], alors la mesure que nous proposons se calcule par :

6(t“1,t;) = 1 — costﬁ (3)

Remarques: Ramener les valeurs de 6 a [0, 1] est plus pratique que de mesurer des valeurs entre
0 et 1, 67 radiants. Lorsque deux vecteurs sont totalement divergents (intersection vide), leur
angle est de 3, et le cosinus vaut 0 : leur distance est maximale et vaut 1. Lorsque ces vecteurs
sont tres proches, leur angle tend vers 0 , le cosinus tend vers 1 et la distance, vers 0. Tous
les vecteurs ont un angle forcément compris entre 0 et 5, par construction, et appartiennent au
méme espace vectoriel.

2.1.3 Espace vectoriel sémantique

L’espace des points de 17 étant beaucoup plus grand que le nombre d’entrées dans un diction-
naire D, l’espace vectoriel peut contenir une quantité de vecteurs qui ne sont pas ceux des ter-
mes de D. Si l’on admet une hypothese de compositionalité en sémantique linguistique, selon
laquelle le sens d’un ensemble de mots est une fonction des sens de chaque mot, on peut dire
que 17 déﬁnit un véritable espace sémantique, et pas seulement un espace sémantique lexical.
Pour toute suite 1: = 11111112 . . . .111“ de mots de D, de vecteurs respectifs 1171,1172, . . . ,117,,, il existe
un vecteur if dans 17, et il existe une fonction fn de 17” dans 17 tels que : if = f,,(1171, 1172, . . . , 117“)
et ce, pour tout n. Tout le probleme est donc de déﬁnir les fn telles qu’elles puissent étre des
images formelles des fonctions linguistiques prévalant pour l’obtention de la sémantique des
ensembles ordonnés de mots que sont les phrases et, plus largement, les textes.

2.2 Modes de calcul des vecteurs sémantiques des textes

Le calcul du vecteur sémantique de tout segment de texte comprenant une suite de mots sera
fondé sur une analyse syntaxique préalable qui permettra de pondérer par un scalaire le vecteur
de chaque mot ou groupe de mots en fonction de son role syntaxique.

2.2.1 Vecteurs de groupe et de phrase

L’ analyseur SYGMART, apres avoir affecté des étiquettes aux différents termes d’une phrase,
commence par reconnaitre des groupes (verbaux, nominaux, prépositionnels). Le calcul séman-
tique d’un vecteur est donc attaché au groupe comme premier segment. Les vecteurs de groupe
sont des sommes normées des vecteurs de mots du groupe pondérés, ou des vecteurs de groupe
qui composent le groupe. C’est pourquoi, tout groupe de niveau 1' dans l’arbre d’analyse, s’écrit:

T)
.. Z3’ ()‘j”j,i+1)nor

71 = L. (4)
II E (/\jvj,1+1)nor||

Classiﬁcation automatique de textes

ou les 113-3+1 designent soit des vecteurs de mots, soit des vecteurs de sous-groupe d’un groupe,
de niveau immediatement inferieur (i + 1). Aj est une ponderation du role syntaxique du mot
(respectivement du sous-groupe) dans le groupe. Aj est tel que si  a un role de gouverneur,
alors Aj est egal au double des ponderations des autres vecteurs.

Le vecteur d’une phrase est calcule recursivement comme celui d’un groupe de groupes. A
chaque etape d’analyse, tout groupe incluant un autre groupe (exemple GV -> V GN : le calcul
du vecteur de GV imposera d’abord d’avoir calcule celui de son GN complement). Le vecteur
d’une phrase qﬁ est donc celui du groupe de niveau 0 (ou racine). Au niveau de la phrase les
ponderations sont calculees recursivement de facon a maintenir une attenuation exponentielle.

2.2.2 Vecteurs de textes et ensembles de textes

Bien qu’il existe, dans un texte, une articulation qui donne une importance relative a certaines
portions par rapport a d’autres, dans un premier temps, nous avons considere que les phrases
d’un texte etaient equipotentes, et deﬁni le vecteur de texte comme etant le barycentre des
vecteurs de phrases. En pratique, l’application a montre que les introductions (attaques) et les
conclusions (chutes) pouvaient jouer un role important. Les travaux de (Pery-Woodley 2000)
ou de Nadine Lucas, sur l’articulation des textes, nous ont permis d’ame1iorer la couverture
thematique des textes. Si le vecteur d’un texte T est calcule comme le barycentre des vecteurs
de ses phrases, le vecteur d’un ensemble de textes est calcule comme le barycentre des vecteurs
de textes, et est aussi un centro'1'de.

3 Application a la classiﬁcation de textes

La projection semantique de textes et d’ensembles de textes dans un espace permet de classer
des textes par rapport a une direction vectorielle deﬁnie comme reference. A la demande de
l’entreprise commanditaire, nous adoptons les categories qu’elle a deﬁni dans son referentiel
"metier" et nous considerons une methode de classiﬁcation supervisee.

3.1 Constitution des vecteurs de chaque catégorie

Pour chaque categorie K un ensemble E K de textes est foumi comme etant le "representant"
de K . Pour cela, nous calculons, pour chaque K , son vecteur de reference qui correspond au
centro'1'de de EK. La representation par centro'1'de est courante dans le domaine (e.g. ( Eu-
Hong et Karypis 2000)) mais differe tres fortement des notres par son mode d’obtention. Deux
conditions apparaissent necessaires pour notre methode :

il faut , tout d’abord, que le nombre de textes soit sufﬁsamment grand pour que le centro'1'de (le
vecteur de reference) soit le plus precis possible.

En outre, le centro'1'de doit etre stable, c’est-a-dire que la categorie puisse avoir une direction
vectorielle unique dans l’espace, qui ne ﬂuctue plus, et qui puisse representer une tendance.
On dit que le centroi'de F5 est stable si 6(F5 + Cf, Tl) tend fortement vers 0, quel que soit T, le
texte considere. L’ avantage de la stabilisation du centro'1'de d’une categorie K , represente par
I-6, est que pour chaque nouveau texte, si on l’ajoute legitimement a EK, c’est-a-dire qu’on le
reinjecte dans le centro'1'de, il ne modiﬁe rien, et sa comparaison avec I? (avec une methode de
ﬁltrage que nous allons expliciter) est ﬁable.

Chauché,Prince, J aillet,Teisseire

3.2 Classement d’un article dans une catégorie par ﬁltrage
3.2.1 Vecteurs pour un article

En théorie, c’est le centro'1'de du texte qui représente le vecteur T. Cependant, pour chaque texte,
nous avons considéré un triplet composé de son centro'1'de, de son vecteur introduction T,-mm et
de son vecteur conclusion   est calculé comme une somme normée de l’ensemble
des phrases du texte mais avec une atténuation exponentielle des phrases en fonction de leur
rang. Les scalaires affectés sont de la forme oz *  ou i est le rang de la phrase. Tm: est le

vecteur symétrique de  . Les coefﬁcients affectés aux phrases sont de la forme oz * (1 — 
ou 12 est le nombre total de;phi>esﬂ>eXte. Pour classer un texte T dans une catégorie K il
faut comparer son triplet (T,T,-mm, Tamcl) avec le centro'1'de K. Pour cela, nous avons envisagé
plusieurs solutions, qui ont été appliquées l’une apres l’autre dans une recherche d’amélioration
de la classiﬁcation.

La premiere est l’utilisation de la distance 6 entre Vecteurs : pour qu’elle soit sufﬁsamment dis-
criminante, il faut que les Vecteurs des catégories soient bien différenciés (donc distants) dans
17.

Deuxiemement, le calcul d’une "mesure de concordance" et son utilisation comme critere de
classement: si la précédente solution est insufﬁsante, il faut utiliser le vecteur de catégorie
comme ﬁltre sémantique.

Enﬁn, l’utilisation de la distance entre Vecteurs concordants : c’est le probleme du choix
préférentiel d’une catégorie par rapport a une autre en fonction de l’intensité de la concordance.

3.2.2 Mesure de concordance

Tout vecteur de 17 a 873 composantes dont certaines n’ont que des intensités tres faibles et sont
donc peu signiﬁcatives. Pour avoir une comparaison ﬁable et plus discriminante entre deux
Vecteurs, nous avons considéré qu’ils devaient comparables sur les concepts qu’ils "activent"
le plus fortement, et jusqu’a quel point ils activent ces concepts. Pour cela, il était inutile

de conserver pour le centro'1'de K toutes ses composantes et nous l’avons réduit, apres l’avoir
trié (par ordre décroissant d’intensité de ses composantes) a sa projection dans un espace plus
restreint, a Nb dimensions, o1‘1 Nb < 873. Expérimentalement, nous avons déterminé que Nb
valait 250. Au-dessus, on conservait beaucoup de "bruit" dans la comparaison, et en dessous,

on n’avait pas un vecteur assez précis. On appelle 13,, 1e vecteur de catégorie réduit trié. C’est
lui qui Va servir de ﬁltre.

On procede de la méme maniere avec les Vecteurs de texte et on produit Tt, (respectivement
les Vecteurs introduction, et conclusion triés. On ne proposera les formules ici que pour le

vecteur de texte). Il est clair que les composantes de Kt, ne sont pas forcément les mémes

que celles de ﬁr. Mais deux solutions sont possibles : ou bien les deux Vecteurs n’ont aucune
composante (forte) commune, et auquel cas, cela se voit directement au calcul de la distance 6

(elle devient tres proche de 1) ou bien Kt, et ﬁr ont des plus fortes composantes communes, et
il est important de mesurer deux types d’écart: l’écart de rang et l’écart en intensité.

Ecart de rang : Soiti le rang d’une composante Ct du vecteur de référence Rt, , et  le rang
de cette méme composante dans le vecteur Tt, . La formule de l’écart est la suivante :

(i — 90))"

EU» 90)) = 

(5)

Ecart en intensité : Non seulement le rang des composantes communes fortes est comparé,
mais aussi leurs intensités respectives. Soit a,- l’intensité de la composante de rang i dans KW,

Classiﬁcation automatique de textes

et b,,(,-) l’intensité de cette méme composante, qui ale rang  dans ﬁr. La formule de l’écart
en intensité est la suivante:

_ llai — bp(i)”

_ Nb2+% (6)

I (1390))

Ces deux mesures sont ensuite utilisées dans la mesure de concordance P, dont la formule est:

§;%‘”’—1  . .1 . .
p(Ks';mTs;Tt) = (  (7)
Nb
. . llai — 5 (7l)”
I(%P(%)) = W? (8)

Propriétés: P n’est pas une mesure de similarité classique, car on peut montrer que P n’est pas
symétrique.Elle mesure l’adéquation entre deux vecteurs quand l’un des deux agit comme ﬁltre.

P fonctionne de maniere "inverse" a la distance de type angulaire 6. En effet, P est élevée lors
que 6 tend vers 0. P est calculée aussi de la méme facon pour les autres vecteurs du triplet.

3.2.3 Mesure de concordance et distance

Pour affecter ensuite un texte a une catégorie, il ne sufﬁt pas de savoir si le Vecteur de ce texte
est sufﬁsamment concordant avec le Vecteur de la catégorie, car la mesure de concordance peut
faire en sorte qu’il concorde avec plusieurs categories. 11 faut alors classer préférentiellement le

texte dans une catégorie. Soit 6(I?t,, ﬁr) la distance "angulaire" entre le Vecteur de texte et le
centro'1'de de référence. Une nouvelle mesure de distance est proposée avec la formule ci-apres
oh 3 est un coefﬁcient permettant de renforcer l’importance de la concordance.

P((-Rltra  * 6(-Etrafifr)
:8 * P((I?t7'7Tl57') + (1 _ /8)6(I_{‘t7'7:Z-—lf7')

A((I?t., ﬁr) = (9)

A est aussi calculé pour les autres vecteurs du triplet du texte.

3.2.4 Vecteur de classement d’un texte

Pour tout texte T, s’il existe p categories génériquement nommées K ,-, on calcule un Vecteur de
classement ITS; tel que la composante ieme de ce Vecteur est égale a P(I_€,;T(i), ﬁr) (respec-
tivement a A(I?t,(i), T;,)). Cela signiﬁe que tout texte T est classe’ puisqu’on peut calculer la
concordance par rapport a chaque catégorie. D’autre part, en triant son Vecteur de classement
ce qui donne le Vecteur Tc;,,ss,,;,, dans l’ordre décroissant des intensités de ses concordances, on
obtient un Vecteur dont les premieres composantes correspondent aux catégories les plus con-
cordantes.

On calcule alors 1e Vecteur des catégories du texte T, qui est en fait le Vecteur de dimension p
et d’intensités K ,-, par ordre d’importance. I1 sufﬁt de sélectionner la dimension du sous-Vecteur
de ce Vecteur pour avoir le nombre de catégories, par ordre décroissant, avec lesquelles le texte
concorde le Inieux, ainsi que les numéros (ou noms) de ces catégories. On calcule de méme le
Vecteur des catégories de l’introduction et de la conclusion du texte T.

Chauche,Prince, J aillet,Teisseire

3.3 Description de l’application
3.3.1 Les données : corpus et catégories

Le jeu d’essai comporte 4843 articles de presse en Frangais en provenance de plusieurs sources
(agences de presse, joumaux, autres) se repartissant en 37 categories, representant des rubriques
joumalistiques, et livrees sous forme d’une liste plate. (Theeramunkong et Lertnattee 2002)
montrent qu’une liste plate pose intrinsequement un probleme de precision de la classiﬁcation.
Non seulement ces categories n’etaient pas hierarchisees, mais elles pouvaient avoir des re-
coupements entre elles.

Les categories representent des secteurs et des metiers (Banque, Logistique, Hotellerie, Mode
et Textile, Recherche, etc.). Les textes peuvent contenir de quelques phrases a quelques pages
chacun. Comme certains articles pouvent appartenir a plus d’une categorie, la multiplicite des
affectations a permis d’etablir 5026 liens entre articles et categories. Les centroides ont ete sta-
bilises sur un noyau a partir d’une centaine d’articles par categorie.

Le noyau represente 2400 premiers articles du jeu d’essai, soit environ 50%. Aucun choix se-
mantique n’a prevalu a la determination du noyau, a part le fait qu’il fallait au moins 30 articles
par categorie pour avoir une chance de stabiliser une tendance (nombre a partir duquel on peut
raisonnablement avoir une gaussienne). Le noyau contient 2555 liens de classe (plusieurs arti-
cles etaient classes dans plusieurs categories). Le reste des articles a ete utilise comme corpus
de veriﬁcation.

3.3.2 Objectifs de la classiﬁcation

Les mesures de classiﬁcation communement invoquees sont le rappel et la precision du classe-
ment. La précision est traditionnellement deﬁnie par le nombre de liens correctement produits
par rapport au nombre de liens produits (par le systeme). Le rappel est traditionnellement deﬁni
par le nombre de liens produits correctement (par le systeme) par rapport au nombre de liens
produits par les experts humains. Comme nous calculons toujours le vecteur de classement d’un
texte par rapport a toutes les categories, la precision traditionnelle n’est pas tres pertinente. En
revanche, ce qui interessait le commanditaire, c’etait de retrouver , dans le vecteur des cate-
gories d’un texte, la ou les categories de classement proposee(s) par l’expert humain et dans
quelle position. Cela pourrait correspondre a une notion de rappel (traditionnel). Cependant,
dans la mesure ou d’une part, plusieurs articles relevaient de classements multiples, et d’autres
part, l’entreprise cherchait eventuellement a decouvrir quelques classements inedits, nous avons
deﬁni une notion de largeur de recherche, denotee par m, qui correspond au nombre de cate-
gories parmi lesquelles on cherche a retrouver le classement de l’expert. Si on considere cette
fois-ci le nombre de liens produits par le systeme egal a la largeur m, alors, ce que l’on mesure
est effectivement une "precision", mais d’une facture un peu particuliere. Soit cr le compteur
des classements corrects. Soit cat(ea:p, T) le(s) numero(s)(ou nom de la categorie(s)) affecte(s)
par l’expert au texte T. L’ algorithme de decompte des classements corrects (en ﬁgure 1) incre-
mente ce compteur si le lien est correct dans deux vecteurs des categories au moins du triplet
’(texte, introduction, conclusion)’, dont le vecteur des categories du texte. cr(m) donne le nom-
bre de classements corrects sur une largeur m, c’est-a-dire que # foumit la precision. Si on
devait calculer le rappel sur une largeur m on aurait dﬁ avoir de la part des experts humains,
un nombre de liens egal a au moins m par texte, or ce n’est pas le cas. On ne peut donc pas
calculer un rappel traditionnel dans des conditions rigoureuses. C’est pourquoi nous deﬁnissons

Classiﬁcation automatique de textes

Pour tout texte T, V} son Vecteur de catégorie, et  la iéme composante de V}
Pouri = 1 amfaire
si  = cat(eJ:p, T) et VT,-_,’m0(i) = cat(eJ:p, T)
ouVT(i) = cat(eJ:p, T) et VTCOM;  = cat(eJ:p, T)
alors cr = C7‘ + 1

Figure 1: Décompte des classements corrects

une mesure 7r(m) de la maniere suivante. Soit cr(m) le nombre de liens de classement corrects

pour les articles du corpus. Soit n le nombre de liens de référence du corpus. 7r(m) = 

4 Résultats

La distance 6 entre deux catégories étant elle-meme souvent inférieure a 0, 01 (un angle de
quelques degrés seulement), la discrimination de cette seule mesure n’était pas sufﬁsante. Le
passage a la recherche de la concordance P(I?tT(i), T;T) (respectivement les deux autres vecteurs
du triplet), pour les valeurs des composantes du vecteur de classement, est de meilleure qualité
car on a pu sélectionner les vecteurs concordants a une catégorie avec plus de netteté. C’est
mi), T;T) (respectivement les deux autres vecteurs du triplet) qui a été ﬁnalement choisie
car la plus probante. Grace a elle, 7r(1), qui est le "pire des cas" a quand meme atteint 47%. Nos
premiers essais ont donné les résultats fournis en ﬁgure 2. Les pourcentages ont été arrondis a
l’unité la plus proche. Remarques : Il est difﬁcile d’avoir des corpus dont la taille et le nombre

Valeurs de 7r(m) Noyau Corpus Vériﬁcation
7r(1), 1 catégorie 49% 42%

7r(2), 2 categories 64% 58%

7r(3) ,3 categories 75% 70%
Nombre de textes 2400 2443
Nombre de liens 2555 2471

Figure 2: Comparaison du noyau et du corpus de vériﬁcation

de liens sont exactement identiques. Nous avons fait au Inieux pour avoir des nombres tres
proches . Les résultats montrent une différence relativement faible entre le noyau et le corpus
de vériﬁcation (elle est au pire de 7%), c’est qui nou amene a dire que la me’th0de est peu sen-
sible £1 un entrafnement. Les essais faits avec des méthodes come is — nn ou comme SVM
montrent des différences tres nettes entre noyau d’entrainement et corpus de test (J aillet et al.
2003). Les premiers résultats (que nous mentionnons juste) montrent pour k — nn un rappel de
71, 5% pour le noyau, mais de 16, 5% sur le corpus detest. Ces résultats sont temporaires (non
validés sur les memes corpus) mais relativement indicatifs. Le fait d’avoir doublé le nombre
d’articles (au total) ne change pas signiﬁcativement les valeurs de 7r. La "largeur" (nombre de
catégories considérées) introduit une difference de plus grande ampleur. C’est pourquoi nous
avons fourni (au commanditaire) un classement global de 4483 articles avec un ratio de 72%
environ sur une largeur de trois catégories.

Chauche,Prince, J aillet,Teisseire

5 Conclusion

Dans cet article nous avons presente une methode de classiﬁcation de documents fondee sur
l’analyse syntaxique et le calcul semantique a base de vecteurs d’indexation. Nous avons donne
les regles de calcul semantique, et les extensions de la representation aux textes et ensembles
de textes, dont certains peuvent etre regroupes thematiquement. Ces regles sont fondees sur la
capacite d’analyse syntaxique automatique qui n’est souvent pas complete en raison des am-
bigu'1'tes ou des formes inconnues qui emaillent les textes reels. SYGMART realise toujours
une analyse partielle, et l’on peut calculer les vecteurs de groupes, sinon de phrase. L’analyse
partielle peut induire une mauvaise representation aussi bien au niveau du centro'1'de de cate-
gorie qu’au niveau des vecteurs de texte. C’est pourquoi, aﬁn d’ameliorer la classiﬁcation, nous
orientons notre recherche vers l’etude de l’impact du seuil d’analyse syntaxique sur la classiﬁ-
cation. Un passage complet des 4843 textes montre qu’environ 56, 5% d’entre eux possedaient
un seuil d’analyse de de 30% (un tiers seulement des phrases de chaque texte sont analysees
entierement et correctement). Nous menons des experiences sur des sous-ensembles de textes
pour la recherche d’ un seuil d’analyse optimal sur un corpus complementaire de 14000 textes.

Références

Besangon R., Rajman M. (2002) Validation de la notion de similarite textuelle dans un cadre multilingue.
Actes des JADT2002. Pp.149- 159.

Chauche J .(1984) Un outil d’analyse multi-dimensionnelle du discours. Proc. of COLING-84.

Chauche J. (1990) Determination semantique en analyse structurelle 2 une experience basee sur une
deﬁnition de distance. TA Information Vol 1/ 1, p 17-24.

Ellman J ., Tait, J . (1999) Roget’s thesaurus: An additional Knowledge Source for Textual CBR? Proc.
of 19th SGES Int. Conf on Knowledge-Based and Applied AI. Springer-Ver1ag.pp 204 — 217.

Eui-Hong H., Karypis, G. (2000) Centroid-Based Document Classiﬁcation: Analysis and Experimental
Results. Proc. of PKDD, p 424-431.

J aillet S., Chauche J ., Prince V., Teisseire M.(2003) Classiﬁcation automatique de documents: la mesure
de deux ecarts. Rapport de Recherche LIRMM 18p.

Larousse.(1992) The’saurus Larousse - des idées aux mots, des mots aux idées. Paris.

Lewis D.D., Ringuetee, M.(1994) A Comparison of Two Learning Algorithms for Text Categorization.
Proc. of 3rd An. Symp.on Document Analysis and Information Retrieval Pp 81-93.

Pery-Woodley, M.P. (2000) Une pragmatique a ﬂeur de texte 2 approche en corpus de 1’organisation
textuelle. Carnets de grammaire N°8, 164 p, Universite deToulouse-Le Mirail 2 ERSS.

Roget P.(1852) Thesaurus of English Words and Phrases Longman, London.

Salton G. , Fox E.A, Wu H. (1983) Extended Boolean Information retrieval. Communications of the ACM
26 (12). Pp. 1022-1036.

Theeramunkong T., Lertnattee V. (2002) Multi-Dimensional Text Classiﬁcation. Proc.of COLING2002.
Pp1002-1008.

Yang Y., Liu X.(1999)A Re-examination of Text Categorization Methods Proc. of the 22nd ACM SIGIR
Conference, Pp 42-49.

Yarowsky D. (1992) Word-Sense Disambiguation Using Statistical Models of Roget’s Categories Trained
on Large Corpora. Proc. of COLING92.

