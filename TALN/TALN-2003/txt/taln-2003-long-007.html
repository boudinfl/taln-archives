<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Peut-on trouver la taille de contexte optimale en d&#233;sambigu&#239;sation s&#233;mantique?</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2003, Batz-sur-Mer, 11-14 juin 2003 
</p>
<p>Peut-on trouver la taille de contexte optimale en 
d&#233;sambigu&#239;sation s&#233;mantique? 
</p>
<p>&#201;ric Crestan (1,2), Marc El-B&#232;ze(1) et Claude de Loupy (2) 
</p>
<p>(1) Laboratoire Informatique d&#8217;Avignon 
339, ch des Meinajaries, BP 1228 
</p>
<p>F-84911 Avignon Cedex 9 
{eric.crestan, marc.elbeze}@lia.univ-avignon.fr 
</p>
<p> 
(2) Sinequa S.A.S. 
</p>
<p>51-59 rue Ledru-Rollin  
F-94200 Ivry-sur-Seine 
</p>
<p>{crestan, loupy}@sinequa.com  
</p>
<p>R&#233;sum&#233; &#8211; Abstract 
</p>
<p>Dans la t&#226;che de d&#233;sambigu&#239;sation s&#233;mantique, la d&#233;termination de la taille optimale 
de fen&#234;tre de contexte &#224; utiliser, a fait l'objet de plusieurs &#233;tudes. Dans cet article, 
nous proposons une approche &#224; deux niveaux pour r&#233;pondre &#224; cette probl&#233;matique de 
mani&#232;re automatique. Trois syst&#232;mes concurrents &#224; base d'arbres de classification 
s&#233;mantique sont, dans un premier temps, utilis&#233;s pour d&#233;terminer les trois sens les 
plus vraisemblables d'un mot. Ensuite, un syst&#232;me d&#233;cisionnel tranche entre ces sens 
au regard d'un contexte plus &#233;tendu. Les am&#233;liorations constat&#233;es lors d'exp&#233;riences 
men&#233;es sur les donn&#233;es de SENSEVAL-1 et v&#233;rifi&#233;es sur les donn&#233;es SENSEVAL-2 sont 
significatives. 
</p>
<p>The determination of context length to use for Word Sense Disambiguation (WSD) 
has been the object of several studies. In this paper, we propose to use a monitoring 
system in order to select automatically the optimal window size among three 
possibilities. We used a two-step strategy based on Semantic Classification Trees 
(SCT) and on a similarity measure. Whereas SCTs are employed on a short window 
size of 3, 5 and 7 words, the technique based on similarity measure is appllied to a 
&#8216;wider&#8217; context size. The improvements observed in the SENSEVAL-1 lexical-sample 
task are verified on the SENSEVAL-2 data.  
</p>
<p>Mots cl&#233;s &#8211; Keywords  
</p>
<p>D&#233;sambigu&#239;sation s&#233;mantique, arbres de classification s&#233;mantique. 
</p>
<p>Word sense disambiguation, semantic classification trees, monitoring system. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;ric Crestan, Marc El-B&#232;ze et Claude de Loupy 
</p>
<p>1 Introduction 
</p>
<p>Dans les ann&#233;es 50, Kaplan (1950) a observ&#233;, &#224; l&#8217;occasion d&#8217;une exp&#233;rimentation, que 
la traduction d&#8217;un mot par sept traducteurs diff&#233;rents n&#8217;&#233;tait ni meilleure ni pire 
lorsque ceux-ci n&#8217;avaient &#224; leur disposition que deux mots de contexte de chaque c&#244;t&#233; 
du mot &#224; traduire, plut&#244;t que la phrase au complet. Plus r&#233;cemment, Yarowsky (1993) 
a d&#233;clar&#233; que la plupart des indices utiles &#224; la d&#233;sambigu&#239;sation s&#233;mantique se 
trouvent dans un micro-contexte de 6 &#224; 8 mots. Toutefois, il faut noter que dans un 
contexte de &#171; si grande taille &#187;, il est souvent difficile de discerner les &#233;l&#233;ments cl&#233;s, 
par rapport aux &#233;l&#233;ments non porteurs d&#8217;information pour la d&#233;termination du sens 
d&#8217;un mot.  
</p>
<p>Au-del&#224; de cette r&#233;duction de la fen&#234;tre de contexte n&#233;cessaire &#224; la d&#233;sambigu&#239;sation, 
il para&#238;t &#233;vident qu&#8217;une taille fixe n&#8217;est pas adapt&#233;e &#224; tous les mots. Pour s&#8217;affranchir 
de ce probl&#232;me, il est possible dans le cadre de syst&#232;mes supervis&#233;s, de d&#233;terminer la 
taille de fen&#234;tre optimale au regard du corpus d&#8217;apprentissage. Nous appellerons cette 
m&#233;thode &quot;adaptation statique&quot;. Le d&#233;savantage d&#8217;une telle approche est qu'elle est tr&#232;s 
sensible &#224; la qualit&#233; du corpus d&#8217;apprentissage. Une autre solution, que nous 
nommerons &#171; adaptation dynamique &#187;, est de d&#233;terminer une taille optimale de 
contexte appropri&#233;e pour chaque test. 
</p>
<p>L&#8217;approche propos&#233;e dans ce papier est bas&#233;e sur une approche mixte &#224; deux niveaux. 
Dans un premier temps, la phrase contenant le mot &#224; d&#233;sambigu&#239;ser est soumise &#224; trois 
syst&#232;mes identiques entra&#238;n&#233;s sur diff&#233;rentes tailles de contexte. Ensuite, lors de la 
seconde phase, le sens final est s&#233;lectionn&#233; parmi les sens propos&#233;s sur des crit&#232;res 
plus th&#233;matiques. Les exp&#233;riences, propos&#233;es dans cet article, ont &#233;t&#233; men&#233;es sur les 
corpus issus des campagnes d'&#233;valuation SENSEVAL-1 et 2 (Kilgarriff et Rosenzweig, 
2000). Le but de ces &#233;valuations &#233;tant de d&#233;sambigu&#239;ser un mot en contexte, pour 
lequel un corpus d'apprentissage &#233;tait fourni. 
</p>
<p>Le papier est organis&#233; de la mani&#232;re suivante : une br&#232;ve pr&#233;sentation du syst&#232;me 
pour la d&#233;sambigu&#239;sation s&#233;mantique &#224; base d&#8217;arbres de classification s&#233;mantique 
(SCT) est tout d&#8217;abord donn&#233;e (section 2). Dans la section 3, la technique du 
leave-one-out, m&#233;thode tr&#232;s r&#233;pandue notamment dans la mod&#233;lisation statistique du 
langage (Ney, Martin et Wessel, 1997), est employ&#233;e pour op&#233;rer une adaptation 
statique de la taille de fen&#234;tre de contexte. Enfin, dans la section 4, nous d&#233;montrons 
que l&#8217;utilisation d&#8217;un syst&#232;me de d&#233;tection de longueur optimale de contexte, coupl&#233; 
avec les SCT, am&#233;liore les r&#233;sultats au-del&#224; de ce qui aurait pu &#234;tre obtenu par une 
adaptation statique dans le meilleur des cas. 
</p>
<p>2 Arbres de classification s&#233;mantique pour la 
d&#233;sambigu&#239;sation du sens 
</p>
<p>Kuhn et De Mori (1995) ont &#233;t&#233; les premiers &#224; introduire l&#8217;id&#233;e des arbres de 
Classification S&#233;mantique (Semantic Classification Trees,  SCT) dans le domaine de la 
compr&#233;hension du langage naturel. Plus r&#233;cemment, les m&#234;me techniques ont &#233;t&#233; 
utilis&#233;es par Loupy et al. (2000) en d&#233;sambigu&#239;sation s&#233;mantique dans le cadre de 
l&#8217;&#233;valuation SENSEVAL-1 avec quelque succ&#232;s. Dans la suite de cette section, le 
principe de l&#8217;approche est bri&#232;vement rappel&#233;, et nous montrons comment elle peut </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Peut-on Trouver la Taille de Contexte Optimale en D&#233;sambigu&#239;sation S&#233;mantique? 
</p>
<p>&#234;tre &#233;tendue pour am&#233;liorer les performances au-del&#224; de ce qui a &#233;t&#233; obtenu jusqu&#8217;&#224; 
pr&#233;sent.  
</p>
<p>Les SCT sont des arbres de d&#233;cision binaires entra&#238;n&#233;s sur un corpus d&#8217;apprentissage 
annot&#233;. Le corpus d&#8217;entra&#238;nement de la t&#226;che lexical sample de l&#8217;&#233;valuation 
SENSEVAL-2 a donc &#233;t&#233; utilis&#233; pour construire un arbre de classification pour chaque 
mot &#224; d&#233;sambigu&#239;ser. Le processus de construction des arbres consiste &#224; trouver &#224; 
chaque &#233;tape de la construction, la question optimale qui s&#233;pare au mieux l&#8217;espace 
constitu&#233; par les diff&#233;rentes populations d&#8217;exemples. Les questions pos&#233;es &#224; chaque 
n&#339;ud de l&#8217;arbre sont de la forme : 
</p>
<p> &#8216;Est-ce que l&#8217;&#233;l&#233;ment (lemme, stemme ou graphie) &#224; la position P est &#233;gale &#224; X ?&#8217; 
</p>
<p>Dans le cadre de cette exp&#233;rience, le crit&#232;re d&#8217;impuret&#233; de Gini (Breiman et al. 1984) 
a &#233;t&#233; employ&#233; comme crit&#232;re de d&#233;cision. 
</p>
<p>Avant de pouvoir construire les SCT, les donn&#233;es ont subi un pr&#233;-traitement. Tout 
d&#8217;abord, les contextes ont &#233;t&#233; lemmatis&#233;s pour augmenter le pouvoir de g&#233;n&#233;ralisation 
lors de la s&#233;lection des questions. Le mot de r&#233;f&#233;rence (&#224; d&#233;sambigu&#239;ser) est conserv&#233; 
&#224; l&#8217;&#233;tat de graphie pour utiliser le maximum d&#8217;indices susceptibles d&#8217;apporter une 
information sur le sens de celui-ci (typiquement : mot capitalis&#233; : &quot;Sense&quot;, flexion : 
&quot;senses&quot;). Par la suite, les adjectifs, adverbes et d&#233;terminants/articles ont &#233;t&#233; retir&#233;s 
conform&#233;ment aux observations faites par Loupy et El-B&#232;ze (2000). Les pronoms, 
quant &#224; eux, sont remplac&#233;s par la d&#233;signation g&#233;n&#233;rique PRP.  
</p>
<p>Un &#233;chantillon du corpus d&#8217;apprentissage utilis&#233; pour entra&#238;ner l&#8217;arbre de d&#233;cision 
pour le nom anglais sense est donn&#233; en Figure 1. Pour les quatre sens diff&#233;rents du 
mot, les exemples sont pr&#233;sent&#233;s avec 3 mots de contexte de chaque c&#244;t&#233; du mot &#224; 
d&#233;sambigu&#239;ser apr&#232;s pr&#233;-traitement, donc une fen&#234;tre de 7 mots (K=7). On observera 
que les ponctuations fortes provoquent, s&#8217;il y a lieu, un raccourcissement de la fen&#234;tre. 
L&#8217;arbre pr&#233;sent&#233; en Figure 2 a, quant &#224; lui, &#233;t&#233; construit sur le m&#234;me corpus 
d&#8217;apprentissage, mais sur un contexte plus court qui correspond &#224; la partie gris&#233;e sur 
</p>
<p>sense%1:10:00:: firebreak , in sense of material burning 
sense%1:10:00:: someone , in sense of appear , 
sense%1:10:00:: which people make sense of situation ,  &#8220;the meaning of a word or expression&#8221; 
sense%1:10:00:: way of make sense of be to 
sense%1:10:00:: make sort of sense of relatedness . 
 
sense%1:09:05:: be inhibit by sense that government and 
sense%1:09:05:: Jess feel such sense of disappointment that 
sense%1:09:05:: of credo underpin sense of faith in   &#8220;a general conscious awareness&#8221; 
sense%1:09:05:: ceiling add to sense of space and 
sense%1:09:05:: inspire reader with sense of presence of 
 
sense%1:09:04:: against law make sense .  
sense%1:09:04:: PRP make more sense to annex quality  &#8220;sound practical judgment&#8221; 
sense%1:09:04:: PRP have sense than PRP have 
sense%1:09:04:: , and make sense in term of 
 
sense%1:09:02:: to ensure that senses can operate . 
sense%1:09:02:: take in via senses and process .    &#8220;the faculty through which the external
sense%1:09:02:: whether PRP have senses be anybody 's      world is apprehended&#8221; 
</p>
<p>Figure 1: &#201;chantillon du corpus d&#8217;apprentissage pour le nom &#8216;sense&#8217; </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;ric Crestan, Marc El-B&#232;ze et Claude de Loupy 
</p>
<p>l&#8217;&#233;chantillon pr&#233;sent&#233; plus haut (K=3). Consid&#233;rant que le terme central est &#224; la 
position 0, les questions ne peuvent porter que sur les lemmes en position &#8211;1 et 1, 
ainsi que la graphie du mot sur lequel l&#8217;arbre est construit (position 0). 
</p>
<p>Les feuilles de cet arbre contiennent le sens dominant (le r&#233;f&#233;rentiel &#233;tant Wordnet 
1.7). Les n&#339;uds de l&#8217;arbre contiennent pour leur part, les questions qui ont &#233;t&#233; jug&#233;es 
les plus pertinentes par le processus d&#8217;inf&#233;rence. Les annotations y et n sur les arcs 
correspondent respectivement &#224; une r&#233;ponse positive ou n&#233;gative apport&#233;e &#224; la 
question sur le n&#339;ud pr&#233;c&#233;dent. Ainsi, la question s&#233;lectionn&#233;e comme la plus 
pertinente &#224; la racine de l&#8217;arbre concerne la pr&#233;sence (ou absence) de la pr&#233;position in 
en position &#8211;1 (terme pr&#233;c&#233;dant le nom sense). Cette question semble pertinente au vu 
de l&#8217;&#233;chantillon. Seul les exemples donn&#233;s pour le sens sense%1:10:00:: (sens 
WordNet) ont une pr&#233;position in qui pr&#233;c&#232;de le mot &#224; d&#233;sambigu&#239;ser. 
</p>
<p>Pour ne pas souffrir du manque de donn&#233;es, nous avons propos&#233; l&#8217;utilisation 
d&#8217;&#233;l&#233;ments d&#8217;information extra-contectuels. Pour chaque lemme en contexte, toutes 
ses Classes S&#233;mantiques (CS), telles qu&#8217;elles sont d&#233;finies dans Wordnet, ont &#233;t&#233; 
ajout&#233;es comme questions potentielles et cela ind&#233;pendamment de toute cat&#233;gorie 
grammaticale. Cela a pour avantage d&#8217;accro&#238;tre consid&#233;rablement le champ de 
couverture des questions car elles concernent dor&#233;navant non seulement les lemmes, 
mais aussi leurs classes s&#233;mantiques (pour plus d&#8217;information se r&#233;f&#233;rer &#224; Crestan et 
al., 2001b). Cela ouvre la voie &#224; un nouveau format de question : 
</p>
<p> &#8216;Est-ce que l&#8217;&#233;l&#233;ment &#224; la position X appartient &#224; la Classe S&#233;mantique CS ?&#8217; 
</p>
<p>3 Optimisation de param&#232;tres : Leave-one-Out  
</p>
<p>3.1 Principe 
</p>
<p>Le r&#233;glage des param&#232;tres n'est pas une chose &#233;vidente dans le cadre de syst&#232;mes 
supervis&#233;s. Pour cela, la technique bien connue du leave-one-out (Lachenbruch et 
Michey, 1968) a &#233;t&#233; employ&#233;e pour optimiser les param&#232;tres entrant en jeu dans la 
construction des arbres. Le principe de cette technique consiste &#224; effectuer une 
&#233;valuation circulaire sur le corpus d'apprentissage, en excluant &#224; chaque tour un 
</p>
<p>W(-1)=&#8217;in&#8217;  
</p>
<p>W(+1)=&#8217;of&#8217;  
</p>
<p>W(0)=&#8217;senses&#8217;  
</p>
<p>W(-1)=&#8217;make&#8217;  
</p>
<p>W(-1)=&#8217;of&#8217;  
</p>
<p>sense%1:10:00:: sense%1:10:00:: 
</p>
<p>sense%1:10:00:: 
</p>
<p>sense%1:09:05:: 
</p>
<p>sense%1:09:04:: 
</p>
<p>sense%1:09:02:: 
</p>
<p>y 
</p>
<p>n 
</p>
<p>n 
</p>
<p>n 
</p>
<p>n 
</p>
<p>n 
y 
</p>
<p>y 
</p>
<p>y 
</p>
<p>y 
</p>
<p>Figure 2: SCT construit pour le nom 'sense' </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Peut-on Trouver la Taille de Contexte Optimale en D&#233;sambigu&#239;sation S&#233;mantique? 
</p>
<p>exemple du corpus d'apprentissage qui sera utilis&#233; par la suite comme &#233;l&#233;ment de test. 
Le corpus d'apprentissage de SENSEVAL-2 a &#233;t&#233; utilis&#233; pour effectuer ces r&#233;glages. Les 
r&#233;sultats pr&#233;sent&#233;s dans la prochaine section  
</p>
<p>Cette technique rend possible plusieurs types d'optimisations : 
</p>
<p>&#183; Optimisation de la taille de la fen&#234;tre de contexte : des exp&#233;riences 
men&#233;es pr&#233;c&#233;demment sur les donn&#233;es SENSEVAL-1 ont montr&#233; que la 
taille de fen&#234;tre optimale varie d'un mot &#224; l'autre (cf. 4.1) ; 
</p>
<p>&#183; Utilisation des informations additionnelles : bien que l'utilisation des CS 
apporte une am&#233;lioration sensible des performances en pr&#233;cision 
moyenne, ce surcro&#238;t d'information p&#233;nalise, malgr&#233; tout, certains mots; 
</p>
<p>&#183; Optimisation de profondeur d'arbre : la profondeur optimale de chaque 
arbre est &#233;galement variable selon les arbres. 
</p>
<p>Dans la section suivante, seul le crit&#232;re d'optimisation de la longueur de contexte sera 
&#233;tudi&#233;. 
</p>
<p>3.2 Application &#224; la d&#233;tection de taille optimale de contexte 
</p>
<p>Le but de cette exp&#233;rience est de v&#233;rifier l&#8217;hypoth&#232;se selon laquelle il serait possible 
d&#8217;appliquer la technique du leave-one-out afin de d&#233;tecter, de mani&#232;re automatique, la 
taille de fen&#234;tre optimale (dans le cadre des SCT). 
</p>
<p>Lors de r&#233;cents travaux (Crestan et El-B&#232;ze, 2001a) nous avons observ&#233; qu&#8217;il n&#8217;y a 
pas de taille de fen&#234;tre unique adapt&#233;e &#224; tous les noms (corpus SENSEVAL-1), mais que 
celle-ci varie d&#8217;un mot &#224; l&#8217;autre. D&#8217;apr&#232;s ces m&#234;mes travaux, il a &#233;t&#233; montr&#233; qu&#8217;un 
gain en pr&#233;cision globale de 1% serait possible si l&#8217;on pouvait d&#233;terminer a priori la 
longueur de fen&#234;tre optimale &#224; utiliser lors de l&#8217;apprentissage. Des tests similaires, 
r&#233;alis&#233;s sur les donn&#233;es SENSEVAL-2, ont conduit aux m&#234;mes conclusions.  
</p>
<p> 
R&#233;sultats sur corpus d'apprentissage  
</p>
<p>(leave-one-out) R&#233;sultats sur corpus de test 
</p>
<p> Nb Test SCT k=3 SCT k=5 SCT k=7 Avec k&#770;  SCT k=3 
</p>
<p>Moyenne 98 57.0 55.3 54.0 63.6 65.3 
</p>
<p>Tableau 1: Optimisation de taille de fen&#234;tre par leave-one-out sur les NOMS 
</p>
<p>Partant des observations faites pr&#233;c&#233;demment, la technique du leave-one-out a &#233;t&#233; 
appliqu&#233;e au corpus d'apprentissage des 29 NOMS fournis lors de l'&#233;valuation 
SENSEVAL-2 (art, authority, bar, bum, chair, channel, child, church, circuit, day, 
detention, dyke, facility, fatigue, feeling, grip, hearth, holiday, lady, material, mouth, 
nation, nature, post, restraint, sense, spade, stress et yew). Ces r&#233;sultats sont pr&#233;sent&#233;s 
dans le Tableau 1. Pour chaque longueur de fen&#234;tre consid&#233;r&#233;e (k=3, 5 et 7), les arbres 
ont &#233;t&#233; construits s&#233;quentiellement sur tous les exemples sauf un, puis test&#233;s sur celui-
ci. Les colonnes SCT k=3, 5 et 7 indiquent la pr&#233;cision moyenne obtenue pour chacun 
des mots (en prenant successivement chaque exemple comme test et tous les autres 
comme entra&#238;nement). La fen&#234;tre qui donne globalement la meilleure pr&#233;cision pour </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;ric Crestan, Marc El-B&#232;ze et Claude de Loupy 
</p>
<p>un mot m est consid&#233;r&#233;e par la suite comme la longueur de fen&#234;tre optimale (k&#770; ) lors 
du test de m. De par la finesse des sens de Wordnet, plusieurs exemples du corpus 
d'apprentissage n'ont pas &#233;t&#233; d&#233;sambigu&#239;s&#233;s par les juges. Pour respecter le caract&#232;re 
ambigu de ces exemples, nous les avons dupliqu&#233;s selon autant d'exemple qu'il y avait 
de sens. 
</p>
<p>3.3 Validation de l'approche 
</p>
<p>Les tests men&#233;s sur le corpus d'&#233;valuation de SENSEVAL-2 ne sont malheureusement 
pas corr&#233;l&#233;s avec les observations faites sur le corpus d'apprentissage. En effet, les 
r&#233;sultats obtenus en utilisant les tailles de fen&#234;tre &quot;optimales&quot; d&#233;termin&#233;es par la 
m&#233;thode du leave-one-out ( k&#770; ) sont en de&#231;&#224; des r&#233;sultats obtenus avec une fen&#234;tre fixe 
k=3. La pr&#233;cision moyenne est de 1.7% plus mauvaise. Sur les 29 noms de cette 
exp&#233;rience, la colonne ( k&#770; ) pr&#233;sente seulement 2 fois des r&#233;sultats sup&#233;rieurs &#224; la 
colonne (SCT k=3), alors que le cas contraire se v&#233;rifie 9 fois, le reste des r&#233;sultats 
&#233;tant identique.  
</p>
<p>Plusieurs raisons peuvent &#234;tre avanc&#233;es pour expliquer cet &#233;chec. Tout d'abord, le 
nombre d'exemples pour chaque sens est tr&#232;s faible. Qui plus est, pour certains sens 
seuls un ou deux exemples sont pr&#233;sents dans le corpus d'apprentissage, ce qui 
provoque forc&#233;ment des erreurs sur ces exemples lors de l'utilisation du leave-one-out. 
Ainsi, 1 seul exemple est fourni pour 3 sens diff&#233;rents du nom art et seulement 2 pour 
5 autres sens de ce mot. Le processus de construction des arbres ne pouvant pas 
caract&#233;riser ces sens par manque de donn&#233;es, les r&#233;sultats sont d'autant plus mauvais. 
La pr&#233;sence de plusieurs sens possibles pour un m&#234;me exemple est &#233;galement source 
de probl&#232;mes. Il n'est pas possible de trouver une question pour s&#233;parer ces exemples 
dupliqu&#233;s car les contextes sont identiques. D'autres exp&#233;riences devront &#234;tre men&#233;es 
dans cette direction pour d&#233;terminer quelle est la meilleure strat&#233;gie &#224; appliquer avec 
les exemples &quot;ambigus&quot; (par exemple ne conserver qu'un seul des sens). La m&#233;thode 
du leave-one-out ne semble donc pas &#234;tre appropri&#233;e pour d&#233;tecter automatiquement 
la taille optimale de fen&#234;tre de contexte, dans le cadre de notre approche par SCT. 
</p>
<p>4 S&#233;lection automatique de fen&#234;tre optimale 
</p>
<p>Diff&#233;rents travaux ont &#233;t&#233; men&#233;s par le pass&#233; sur l&#8217;optimisation de la taille de fen&#234;tre 
de contexte. Il convient de citer les travaux de Yarowsky (1992) qui avance que deux 
types d&#8217;ambigu&#239;t&#233; existent : l&#8217;ambigu&#239;t&#233; relevant du domaine, qui n&#233;cessite une 
fen&#234;tre d&#8217;&#233;tude de 20 &#224; 50 mots et l&#8217;ambigu&#239;t&#233; locale pour laquelle une fen&#234;tre de 2 &#224; 
3 mots semble suffisante. N&#233;anmoins, il ne fournit pas de solution &#224; ce probl&#232;me de 
s&#233;lection de taille de fen&#234;tre. Les exp&#233;riences pr&#233;sent&#233;es par la suite permettent d&#8217;y 
r&#233;pondre en partie. 
</p>
<p>4.1 Principe 
</p>
<p>Dans la section pr&#233;c&#233;dente, nous avons montr&#233; que la technique du leave-one-out 
n&#8217;est pas adapt&#233;e &#224; l&#8217;optimisation de la taille de fen&#234;tre de contexte. Cette section est 
centr&#233;e sur une approche novatrice, faisant intervenir un syst&#232;me d&#233;cisionnel, ce qui 
permet de s&#8217;affranchir de la t&#226;che d&#8217;optimisation de taille de fen&#234;tre de contexte. 
L&#8217;id&#233;e principale consiste &#224; trouver des informations utiles &#224; la d&#233;sambigu&#239;sation 
s&#233;mantique dans un contexte plus &#233;tendu, dans le but de renforcer les observations </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Peut-on Trouver la Taille de Contexte Optimale en D&#233;sambigu&#239;sation S&#233;mantique? 
</p>
<p>effectu&#233;es en contexte court. Ce syst&#232;me &#224; l&#8217;avantage d&#8217;&#234;tre dynamique, dans le sens 
o&#249; il s&#233;lectionne la fen&#234;tre optimale pour chaque phrase de test et non pas une fois 
pour toute pour un mot donn&#233; comme c'&#233;tait le cas en section 3. Le principe en est le 
suivant : pour chaque mot &#224; d&#233;sambigu&#239;ser W, trois SCT sont entra&#238;n&#233;s sur le corpus 
d&#8217;apprentissage en utilisant pour chacun des contextes de longueur diff&#233;rente 
(respectivement, SCTk=3(W), SCTk=5(W) et SCTk=7(W) ). Ensuite, lors de la phase de 
d&#233;sambigu&#239;sation, pour chaque test t, les arbres sont parcourus successivement, ce qui 
a pour but de g&#233;n&#233;rer trois propositions de sens ( )(3 tS k= , )(5 tS k= , )(7 tS k= ). Le syst&#232;me 
d&#233;cisionnel prend alors le relais et d&#233;termine, parmi ces sens, lequel semble le plus 
conforme aux indices r&#233;colt&#233;s sur un contexte plus large. 
</p>
<p>Le point crucial de cette approche reste la fonction de d&#233;cision. L'approche 
d&#233;cisionnelle la plus simple consiste &#224; utiliser un syst&#232;me probabiliste bas&#233; sur un 
mod&#232;le unisem, mais les exp&#233;riences que nous avons men&#233;es dans cette voie ont 
conduit &#224; des r&#233;sultats d&#233;cevants.  
</p>
<p>En 1993, Gale et al. ont appliqu&#233; une approche d'extraction d'information au domaine 
de la d&#233;sambigu&#239;sation s&#233;mantique. Ils ont utilis&#233; une taille de fen&#234;tre de contexte 
arbitraire de 50 mots &#224; gauche, ainsi qu'&#224; droite du mot &#224; d&#233;sambigu&#239;ser. Ensuite, ils 
ont utilis&#233; un syst&#232;me de recherche documentaire probabiliste pour comparer le 
contexte des mots &#224; d&#233;sambigu&#239;ser, avec le contexte de ces m&#234;mes mots contenus 
dans le corpus d'apprentissage. Leurs conclusions furent que les r&#233;sultats sont 
significativement am&#233;lior&#233;s lorsque l'on utilise un contexte plus vaste. Le syst&#232;me 
d&#233;cisionnel utilis&#233; dans cette exp&#233;rience est inspir&#233; de ces travaux, il met en &#339;uvre 
une mesure de distance entre une phrase de test t et un pseudo-document cr&#233;&#233; &#224; partir 
du corpus d'apprentissage. Pour un mot donn&#233; W, un pseudo-document 
</p>
<p>)(WSD i
 est un 
</p>
<p>document construit par la concat&#233;nation de toutes les phrases pr&#233;sentes dans le corpus 
d'entra&#238;nement pour un m&#234;me sens de ce mot )(WSi . La mesure de similarit&#233; classique 
du Cosinus d&#233;finie  par Salton et McGill (1986), est alors utilis&#233;e pour calculer la 
distance entre les phrases de test et les pseudo-documents. 
</p>
<p>4.2 Validation de l&#8217;approche 
</p>
<p>Pour v&#233;rifier la validit&#233; de l&#8217;approche pr&#233;sent&#233;e dans la section pr&#233;c&#233;dente, des tests 
ont &#233;t&#233; men&#233;s sur les donn&#233;es d&#8217;&#233;valuation SENSEVAL-1. Le syst&#232;me de d&#233;tection 
automatique de taille de contexte a &#233;t&#233; appliqu&#233; aux 12 noms, ainsi qu&#8217;aux 13 verbes 
de l&#8217;&#233;valuation. Les r&#233;sultats sont pr&#233;sent&#233;s dans le Tableau 2 : 
</p>
<p> SCT k=3 SCT k=5 SCT k=7 MaxStat SCT + Cos 
</p>
<p>NOMS 83,3 82,1 82,1 84,3 85,7 
VERBES 71,1 68,6 68,0 71,6 72,8 
</p>
<p>Tableau 2: &#201;valuation sur les donn&#233;es SENSEVAL-1 (en %) 
</p>
<p>La colonne intitul&#233;e MaxStat correspond &#224; la pr&#233;cision moyenne qu&#8217;aurait pu atteindre 
un syst&#232;me op&#233;rant une s&#233;lection de taille de fen&#234;tre de contexte appropri&#233;e &#224; chaque 
mot. Il faut toutefois noter que cela ne garantit pas l&#8217;optimalit&#233; au niveau de chaque 
test, mais seulement au niveau du mot. Cela correspond donc &#224; la borne sup&#233;rieure 
pour une adaptation statique. La derni&#232;re colonne (SCT+Cos) contient les pr&#233;cisions 
moyennes obtenues pour les noms et les verbes en utilisant l&#8217;adaptation dynamique </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;ric Crestan, Marc El-B&#232;ze et Claude de Loupy 
</p>
<p>avec le syst&#232;me bas&#233; sur la mesure de similarit&#233; du Cosinus. Ces r&#233;sultats sont tout &#224; 
fait satisfaisants car, en plus d&#8217;&#234;tre significativement sup&#233;rieurs aux r&#233;sultats obtenus 
par les SCT seuls, ils sont &#233;galement sup&#233;rieurs aux meilleurs r&#233;sultats que nous 
aurions pu obtenir par adaptation statique. Au vu de ces r&#233;sultats, il semble clair qu'il 
n'existe pas de taille fixe pour un mot donn&#233;. En &#233;largissant le contexte, il est possible 
de choisir entre trois tailles de fen&#234;tre au niveau du test. 
</p>
<p>NOMS Nb Test SCT k=3 SCT k=5 SCT k=7 MaxStat SCT  +Cos 
art 98 63,3 64,3 62,2 64,3 63,3 
authority 92 72,8 67,4 66,3 72,8 72,8 
bar 151 61,6 53,6 56,3 61,6 58,9 
bum 45 75,6 73,3 68,9 75,6 80,0 
chair 69 79,7 81,2 76,8 81,2 81,2 
channel 73 54,8 54,8 53,4 54,8 56,2 
child 64 54,7 57,8 60,9 60,9 62,5 
church 64 54,7 46,9 42,2 54,7 56,3 
circuit 85 57,6 48,2 57,6 57,6 57,6 
day 145 64,8 61,4 60,0 64,8 65,5 
detention 32 84,4 84,4 84,4 84,4 87,5 
dyke 28 78,6 71,4 67,9 78,6 78,6 
facility 58 65,5 67,2 58,6 67,2 67,2 
fatigue 43 86,0 76,7 76,7 86,0 86,0 
feeling 51 66,7 64,7 64,7 66,7 66,7 
grip 51 54,9 64,7 66,7 66,7 62,7 
hearth 32 75,0 78,1 71,9 78,1 81,3 
holiday 31 83,9 80,6 83,9 83,9 83,9 
lady 53 62,3 58,5 56,6 62,3 66,0 
material 69 52,2 52,2 46,4 52,2 58,0 
mouth 60 63,3 60,0 55,0 63,3 65,0 
nation 37 73,0 64,9 62,2 73,0 78,4 
nature 46 56,5 54,3 52,2 56,5 63,0 
post 79 67,1 64,6 60,8 67,1 72,2 
restraint 45 60,0 60,0 55,6 60,0 62,2 
sense 53 73,6 75,5 73,6 75,5 75,5 
spade 33 72,7 72,7 66,7 72,7 72,7 
stress 39 51,3 51,3 48,7 51,3 48,7 
yew 28 78,6 78,6 78,6 78,6 78,6 
Moyenne 98 65,3 62,9 61,5 66,1 67,1 
</p>
<p>Tableau 3 : Influence du syst&#232;me d&#233;cisionnel sur fen&#234;tre de contexte &#8211; donn&#233;es 
SENSEVAL-2 (en %) 
</p>
<p>4.3 &#201;valuation sur SENSEVAL-2 
</p>
<p>Pour v&#233;rifier les r&#233;sultats obtenus sur le corpus SENSEVAL-1, les donn&#233;es d&#8217;&#233;valuation 
de la t&#226;che lexical-sample de SENSEVAL-2 ont &#233;t&#233; employ&#233;es. Les r&#233;sultats obtenus 
pour les 29 noms de cette &#233;valuation sont pr&#233;sent&#233;s dans le Tableau 3. Il faut noter 
que les r&#233;sultats obtenus dans ce tableau ne sont pas directement comparables avec les 
r&#233;sultats obtenus sur l&#8217;&#233;valuation pr&#233;c&#233;dente car le r&#233;f&#233;rentiel s&#233;mantique n&#8217;est pas le 
m&#234;me. Comme pour les tests pr&#233;c&#233;dents, la pr&#233;cision moyenne d&#233;cro&#238;t lorsque la taille 
de la fen&#234;tre de contexte utilis&#233;e pour construire les arbres cro&#238;t (k=3, 5 et 7). Par 
contre, cela n&#8217;est pas vrai pour chaque mot pris de mani&#232;re individuelle. C&#8217;est le cas 
pour les noms child, grip, sense, qui voient leur pr&#233;cision moyenne am&#233;lior&#233;e de 
mani&#232;re significative avec une fen&#234;tre de contexte plus &#233;tendue. L&#8217;exemple de sense 
est &#233;loquent puisque le gain est de presque 2% lorsque l&#8217;on passe d&#8217;une fen&#234;tre k=3 &#224; 
k=5. Une analyse rapide des donn&#233;es montre que le gain est principalement d&#251; &#224; la 
possibilit&#233; de distinguer les acceptions &#171; sense of humour &#187;, gr&#226;ce &#224; la pr&#233;sence du </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Peut-on Trouver la Taille de Contexte Optimale en D&#233;sambigu&#239;sation S&#233;mantique? 
</p>
<p>mot humour en position p=+2 par rapport au mot &#224; d&#233;sambigu&#239;ser. Bien que 
l&#8217;&#233;largissement de la taille de fen&#234;tre de contexte soit b&#233;n&#233;fique dans certain cas, cela 
reste toutefois une erreur dans la plupart des cas. Par exemple, le nom nation voit sa 
pr&#233;cision moyenne d&#233;cro&#238;tre de mani&#232;re tr&#232;s importante avec l&#8217;&#233;largissement de la 
taille de fen&#234;tre. 
</p>
<p>De la m&#234;me mani&#232;re que dans la section 4.2, les colonnes MaxStat et SCT+Cos ont 
&#233;t&#233; calcul&#233;es. Les observations sont les m&#234;mes que sur le jeu de donn&#233;es pr&#233;c&#233;dent : 
un syst&#232;me d&#233;cisionnel utilis&#233; en seconde phase aide &#224; l&#8217;optimisation automatique de 
la taille de fen&#234;tre contextuelle. Il faut noter que le nom nature obtient un gain de 
6,5% par rapport au meilleur score obtenu par les SCT seuls (k=3). Une &#233;tude 
approfondie pour ce nom, montre que dans 41% des cas, les 3 sens propos&#233;s (k=3, 5 
et 7) sont identiques. Donc, le gain de 6,5% n&#8217;est obtenu que sur les 59% des tests 
restants, ce qui correspond &#224; 27 tests. Cette approche ne permet cependant pas &#224; tous 
les coups de s&#233;lectionner la meilleure fen&#234;tre car, dans le cas des noms, la bonne 
r&#233;ponse ne se trouve que dans 72,9% des cas dans les 3 sens propos&#233;s. 
</p>
<p>4.4 Discussion 
Pour d&#233;montrer la capacit&#233; d&#8217;un tel syst&#232;me &#224; utiliser des informations dans un 
contexte &#233;tendu, l&#8217;exemple suivant apporte des &#233;l&#233;ments de r&#233;ponse int&#233;ressants : 
</p>
<p>&#8216;furthermore , nothing have yet be say about all the research that do not depend on the collection 
of datum by the sociologist ( primary datum ) but instead make use of secondary datum - the 
wealth of material already available from other source , such as government statistics , personal 
diary , newspaper , and other kind of information .&#8217; 
</p>
<p>Le nom material est pr&#233;sent&#233; dans son contexte apr&#232;s pr&#233;-traitement, avec la partie 
gris&#233;e correspondant &#224; la fen&#234;tre maximale prise en compte par les SCT. Deux sens 
sont propos&#233;s par les SCT : material%1:27:00:: (&#8216;tangible substance that goes in the 
makeup of a physical object&#8217;) pour k=3 et 7, et material%1:10:00:: (&#8216;information that 
can be reworked into a finished form&#8217;) pour k=5. L&#8217;utilisation du contexte dans sa 
globalit&#233;, permet de faire le bon choix entre ces deux sens, notamment gr&#226;ce aux mots 
research, collection, newspaper et datum qui d&#233;crivent une th&#233;matique pr&#233;cise 
(domaine documentaire). Il semblerait donc qu&#8217;un syst&#232;me d&#233;cisionnel utilisant un 
contexte plus &#233;tendu soit capable de tirer profit d&#8217;indices &#224; un niveau plus th&#233;matique. 
</p>
<p> Les tests conduits sur les verbes et les adjectifs ont montr&#233; des comportements 
similaires (voir Tableau 4). Il y a toutefois une nuance &#224; apporter en ce concernant les 
verbes. Le score obtenu avec SCT+Cos, bien que sup&#233;rieur de presque 3% aux 
SCT (k=3), reste inf&#233;rieur au score avec s&#233;lection optimale de taille de fen&#234;tre par mot 
(MaxStat). Cela peut s&#8217;expliquer par le caract&#232;re tr&#232;s ambigu des verbes de la t&#226;che 
SENSEVAL-2.  
</p>
<p> SCT k=3 SCT k=5 SCT k=7 MaxStat SCT + Cos
</p>
<p>Noms 65,3 62,9 61,5 66,1 67,1 
Verbes 50,7 50,4 49,9 54,2 53,5 
</p>
<p>Adjectifs 64,6 59,1 57,4 65,9 66,4 
Total 59,1 57,0 55,9 61,1 61,3 
</p>
<p>Tableau 4 : Am&#233;liorations apport&#233;es par un syst&#232;me d&#233;cisionnel (en %) 
</p>
<p>Ces r&#233;sultats nous ont permis de nous positionner dans les 3 premiers syst&#232;mes (dans 
les 5 premiers apr&#232;s re-soumission des tests) &#224; moins de 3% du participant 
&#171; vainqueur &#187; de l&#8217;&#233;valuation. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;ric Crestan, Marc El-B&#232;ze et Claude de Loupy 
</p>
<p>5 Conclusion 
Nous avons montr&#233;, par nos exp&#233;riences, qu'il est possible d'accro&#238;tre les 
performances d'un syst&#232;me de d&#233;sambigu&#239;sation s&#233;mantique au-del&#224; des performances 
optimales obtenues de mani&#232;re statique. L&#8217;utilisation d&#8217;un syst&#232;me &#224; adaptation 
dynamique pour la d&#233;sambigu&#239;sation s&#233;mantique a montr&#233; des am&#233;liorations 
substantielles. Bien que les verbes ne semblent pas profiter autant que les noms et les 
adjectifs de cette approche, le gain moyen reste tout de m&#234;me de 2,3 %, toutes 
cat&#233;gories grammaticales confondues. De futures exp&#233;riences devront &#234;tre men&#233;es en 
utilisant un contexte &#233;tendu, pour d&#233;terminer dans quelles mesures la 
d&#233;sambigu&#239;sation d&#8217;un mot se joue &#233;galement dans un contexte plus large. D&#8217;autres 
pistes sont &#233;galement &#224; explorer, notamment concernant l&#8217;utilisation d&#8217;une grammaire 
fonctionnelle pour augmenter les champs d&#8217;application des questions des SCT. Cela 
pourrait profiter grandement aux verbes, principalement gr&#226;ce aux structures : 
sujet+verbe+objet. Enfin, il serait int&#233;ressant d&#8217;utiliser un autre r&#233;f&#233;rentiel 
s&#233;mantique que Wordnet  pour la g&#233;n&#233;ralisation par classes s&#233;mantiques. La pr&#233;sence 
de sens trop fins au niveau des mots en contexte, g&#233;n&#232;re une multitude de CS possible 
pour ceux-ci. Par exemple le nom dog est &#233;galement associ&#233; &#224; la classe humain par 
l&#8217;interm&#233;diaire de son sens familier qui est rarement utilis&#233;. 
</p>
<p>R&#233;f&#233;rences 
Breiman L., Friedman J. H., Olshen R. A., et Stone C. J. (1984). Classification and Regression Trees. 
</p>
<p>Wadsworth International, Belmont, CA. 
Crestan E. et El-B&#232;ze M. (2001a). Improving Supervised WSD by Including Rough Semantic Features 
</p>
<p>in a Multi-Level View of the Context. SEMPRO Workshop, Edinburgh.  
Crestan E., El-B&#232;ze M. et Loupy C. de (2001b). Improving WSD with Multi-Level View of Context 
</p>
<p>Monitored by Similarity Measure. In Proc. of SENSEVAL-2 Workshop, Toulouse, pp. 67-70.  
</p>
<p>Gale W., Church K. W., et Yarowsky D. (1993). A Method for Disambiguating Word Senses in a Large 
Corpus. Computers and the Humanities, 26 : pp. 415-39. 
</p>
<p>Kaplan A. (1950) An experimental study of ambiguity and context. Mechanical Translation, (2:2), 39-
46 (issue appeared in 1955). 
</p>
<p>Kilgarriff A. et Rosenzweig J. (2000). English SENSEVAL : Report and Results. In Proc. LREC, 
Athens, Greece, 3 : pp. 1239-44. http://www.itri.ac.uk/events/senseval 
</p>
<p>Kuhn R. et De Mori R. (1995). The Application of Semantic Classification Trees to Natural Language 
Understanding. IEEE Transactions on Pattern Analysis and Machine Intelligence, 17(5) : pp. 449-60. 
</p>
<p>Lachenbruch P. A. et Mickey M. R. (1968). Estimation of Error Rate in Discriminant Analysis, 
Technometrics, 10, no.1 pp. 1-10. 
</p>
<p>Loupy C. de et El-B&#232;ze M. (2000), Using Few Clues can compensate the small amount of resources 
available for Word Sense Disambiguation. LREC, Athens, Greece, 1 : pp. 219-23. 
</p>
<p>Loupy C. de, El-B&#232;ze M. et Marteau P. F. (2000), Using Semantic Classification Trees for WSD. 
Computer and the Humanities, Kluwer Academic Publishers, 34: pp. 187-92. 
</p>
<p>Ney H., Martin S. et Wessel F. (1997). &quot;Statistical Language Modeling Using Leaving-One-Out&quot;, in S. 
Young &amp; G. Bloothooft (eds.), Corpus-Based Methods in Language and Speech Processing, Kluwer 
Academic Publishers, pp. 174-207. 
</p>
<p>Salton G. et McGill M. (1983). Introduction to Modern Information Retrieval. McGraw-Hill, NY. 
</p>
<p>Yarowsky D. (1992). Word-Sense Disambiguation Using Statistical Models of Roget's Categories 
Trained on Large Corpora . In Proceedings of COLING-92, Nantes, France, pp 454-460. 
</p>
<p>Yarowsky D. (1993). One sense per collocation. In Proceedings of the ARPA Workshop on Human 
Language Technology, Princeton, pp. 266-71. </p>

</div></div>
</body></html>