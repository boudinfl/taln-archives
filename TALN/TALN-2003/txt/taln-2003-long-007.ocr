TALN 2003, Batz-sur-Mer, II -14 juin 2003

Peut-on trouver la taille de contexte optimale en
désambiguisation sémantique?

Eric Crestan (1,2), Marc El-Beze(1) et Claude de Loupy (2)

(1) Laboratoire Informatique d’Avignon
339, ch des Meinajaries, BP 1228
F-84911 Avignon Cedex 9
{eric.crestan, marc.elbeze} @lia.univ-avignon.fr

(2) Sinequa S.A.S.
51-59 rue Ledru-Rollin
F-94200 Ivry-sur-Seine

{crestan, loupy} @ sinequa.com

Résumé — Abstract

Dans la tache de désambigu'1'sation sémantique, la determination de la taille optimale
de fenétre de contexte a utiliser, a fait l'objet de plusieurs études. Dans cet article,
nous proposons une approche a deux niveaux pour répondre a cette problématique de
maniere automatique. Trois systemes concurrents a base d'arbres de classiﬁcation
sémantique sont, dans un premier temps, utilisés pour determiner les trois sens les
plus vraisemblables d'un mot. Ensuite, un systeme décisionnel tranche entre ces sens
au regard d'un contexte plus étendu. Les améliorations constatées lors d'eXpériences
menées sur les données de SENSEVAL-1 et vériﬁées sur les données SENSEVAL-2 sont
signiﬁcatives.

The determination of context length to use for Word Sense Disambiguation (WSD)
has been the object of several studies. In this paper, we propose to use a monitoring
system in order to select automatically the optimal window size among three
possibilities. We used a two-step strategy based on Semantic Classiﬁcation Trees
(SCT) and on a similarity measure. Whereas SCTs are employed on a short window
size of 3, 5 and 7 words, the technique based on similarity measure is appllied to a
‘wider’ context size. The improvements observed in the SENSEVAL-1 lexical-sample
task are veriﬁed on the SENSEVAL-2 data.

Mots clés — Keywords
Désambigu'1'sation sémantique, arbres de classiﬁcation sémantique.

Word sense disambiguation, semantic classiﬁcation trees, monitoring system.

Eric Crestan, Marc El-Beze et Claude de Loupy

1 Introduction

Dans les annees 50, Kaplan (1950) a observe, a l’occasion d’une experimentation, que
la traduction d’un mot par sept traducteurs differents n’etait ni meilleure ni pire
lorsque ceux-ci n’avaient a leur disposition que deux mots de oontexte de chaque 06te
du mot a traduire, plut6t que la phrase au complet. Plus recemment, Yarowsky (1993)
a declare que la plupart des indices utiles a la desambigu'1'sation semantique se
trouvent dans un Inicro-contexte de 6 a 8 mots. Toutefois, il faut noter que dans un
contexte de « si grande taille », il est souvent difﬁcile de discemer les elements cles,
par rapport aux elements non porteurs d’information pour la determination du sens
d’un mot.

Au-dela de cette reduction de la fenétre de oontexte necessaire a la desambigu'1'sation,
il parait evident qu’une taille ﬁxe n’est pas adaptee a tous les mots. Pour s’affranchir
de ce probleme, il est possible dans le cadre de systemes supervises, de determiner la
taille de fenetre optimale au regard du corpus d’apprentissage. Nous appellerons cette
methode "adaptation statique". Le desavantage d’une telle approche est qu'elle est tres
sensible a la qualite du corpus d’apprentissage. Une autre solution, que nous
nommerons « adaptation dynamique », est de determiner une taille optimale de
contexte appropriee pour chaque test.

L’approche proposee dans ce papier est basee sur une approche mixte a deux niveaux.
Dans un premier temps, la phrase oontenant le mot a desaInbigu'1'ser est soumise a trois
systemes identiques entraines sur differentes tailles de oontexte. Ensuite, lors de la
seconde phase, le sens ﬁnal est selectionne parmi les sens proposes sur des criteres
plus thematiques. Les experiences, proposees dans cet article, ont ete menees sur les
corpus issus des campagnes d'evaluation SENSEVAL-1 et 2 (Kilgarriff et Rosenzweig,
2000). Le but de ces evaluations etant de desambiguiser un mot en contexte, pour
lequel un corpus d'apprentissage etait fourni.

Le papier est organise de la maniere suivante: une breve presentation du systeme
pour la desambigu'1'sation semantique a base d’arbres de classiﬁcation semantique
(SCT) est tout d’abord donnee (section 2). Dans la section 3, la technique du
leave-one-out, methode tres repandue notamment dans la modelisation statistique du
langage (Ney, Martin et Wessel, 1997), est employee pour operer une adaptation
statique de la taille de fenetre de oontexte. Enﬁn, dans la section 4, nous demontrons
que l’utilisation d’un systeme de detection de longueur optimale de contexte, oouple
avec les SCT, ameliore les resultats au-dela de ce qui aurait pu etre obtenu par une
adaptation statique dans le meilleur des cas.

2 Arbres de classiﬁcation semantique pour la
désambiguisation du sens

Kulm et De Mori (1995) ont ete les premiers a introduire l’idee des arbres de
Classiﬁcation Semantique (Semantic Classification Trees, SCT) dans le domaine de la
oomprehension du langage naturel. Plus recemment, les meme techniques ont ete
utilisees par Loupy et al. (2000) en desambigu'1'sation semantique dans le cadre de
l’evaluation SENSEVAL-1 avec quelque succes. Dans la suite de cette section, le
principe de l’approche est brievement rappele, et nous montrons comment elle peut

Pent-on Trouver la Taille de Contexte Optimale en Désambiguisation Sémantique?

etre etendue pour ameliorer les performances au-dela de ce qui a ete obtenu jusqu’a
present.

Les SCT sont des arbres de decision binaires entraines sur un corpus dapprentissage
armote. Le corpus d’entrainement de la tache lexical sample de l’evaluation
SENSEVAL-2 a donc ete utilise pour construire un arbre de classiﬁcation pour chaque
mot a desaInbigu'1'ser. Le processus de construction des arbres consiste a trouver a
chaque etape de la construction, la question optimale qui separe au Inieux l’espace
constitue par les differentes populations d’exemples. Les questions posees a chaque
noeud de l’arbre sont de la forme :

‘Est-ce que l ’e’le’ment (lemme, stemme on graphie) 61 la position P est égale 61 X ?’

Dans le cadre de cette experience, le critere d’iInpurete de Gini (Breiman et al. 1984)
a ete employe comme critere de decision.

sense°/.1:1o:oo::firebreak , in sense of material burning

sense%1:10:0O:: someone , in sense of appear ,

sense%1:10:O0::WhlCh people make sense of situation , “the meaning of a word or expression”
sense%1:10:00::Way of make sense of be to

sense%1:10:OO:: make sort of sense of relatedness .

sense%1:O9:05:: be inhibit by sense thatgovernment and
sense%1 :o9:o5:: Jess feel such sense of disappointment that
sense%1:09:05::Ol credo underpin sense offaith in “a general conscious awareness”

sense%1:09:O5:: ceiling add to sense of space and
sense%1:09:05:: inspire reader with sense of presence of

sense%1:09:O4:: PRP make more sense to annex quality
sense%1:09:O4:: PRP have sense than PRP have
sense%1:09:04::, and make sense in term of

sense%1:09:04:: against law make sense .
} “sound practicaljudgment”

“thefaculty through which the external
world is apprehended”

sense%1 :o9:o2:: to ensure that senses can operate .
sense°/.1 :o9:o2:: take in via senses and process .

sense%1 :o9:o2:: whether PRP have sensesbe anybody 's

Figure 1: Echantillon du corpus d’ apprentissage pour le nom ‘sense’

Avant de pouvoir construire les SCT, les donnees ont subi un pre-traitement, Tout
d’abord, les contextes ont ete lemInatises pour augmenter le pouvoir de generalisation
lors de la selection des questions. Le mot de reference (a desaInbigu'1'ser) est conserve
a l’etat de graphie pour utiliser le maximum d’indices susceptibles d’apporter une
information sur le sens de celui-ci (typiquement: mot capitalise: "Sense", ﬂexion:
"senses"). Par la suite, les adjectifs, adverbes et determinants/articles ont ete retires
conformement aux observations faites par Loupy et El-Beze (2000). Les pronoms,
quant a eux, sont remplaces par la designation generique PRP.

Un echantillon du corpus d’apprentissage utilise pour entrainer l’arbre de decision
pour le nom anglais sense est donne en Figure 1. Pour les quatre sens differents du
mot, les exemples sont presentes avec 3 mots de contexte de chaque cote du mot a
desaInbigu'1'ser apres pre-traitement, donc une fenetre dz 7 mots Q{=7). On observera
que les ponctuations fortes provoquent, s’il y a lieu, un racoourcissement de la fenetre.
L’arbre presente en Figure 2 a, quant a lui, ete construit sur le meme corpus
d’apprentissage, mais sur un contexte plus court qui correspond a la partie grisee sur

Eric Crestan, Marc El-Béze et Claude de Loupy

l’echantillon presente plus haut (K=3). Considerant que le terme central est a la
position 0, les questions ne peuvent porter que sur les lemmes en position -1 et 1,
ainsi que la graphie du mot sur lequel l’arbre est construit (position 0).

Les feuilles de cet arbre contiennent le sens dominant (le referentiel etant Wordnet
1.7). Les noeuds de l’arbre contiennent pour leur part, les questions qui ont ete jugees
les plus pertinentes par le processus d’inference. Les armotations y et 11 sur les arcs
correspondent respectivement a une reponse positive ou negative apportee a la
question sur le noeud precedent. Ainsi, la question selectionnee comme la plus
pertinente a la racine de l’arbre concerne la presence (ou absence) de la preposition in
en position -1 (terme precedant le nom sense). Cette question semble pertinente au vu
de l’echantillon. Seul les exemples donnes pour le sens sense%1:10:00:: (sens
W0rdNet) ont une preposition in qui precede le mot a desaInbigu'1'ser.

sense%1:10:00:: sense%1:10:00::

     
   
     
    

SeﬂSe°/o1 :10:00::

 
 

sense%1 :09:05::

W(0)= ‘senses’

sense%1 :09:04::

Figure 2: SCT construit pour le nom ’sense ’

Pour ne pas souffrir du manque de donnees, nous avons propose l’utilisation
d’elements d’information extra-contectuels. Pour chaque lemme en contexte, toutes
ses Classes Semantiques (CS), telles qu’elles sont deﬁnies dans Wordnet, ont ete
ajoutees comme questions potentielles et cela independamment de toute categorie
grammaticale. Cela a pour avantage d’accroitre considerablement le champ de
couverture des questions car elles concement dorenavant non seulement les lemmes,
mais aussi leurs classes semantiques (pour plus d’information se referer a Crestan et
al., 2001b). Cela ouvre la voie a un nouveau format de question :

‘Est-ce que Z ’e’le’ment 61 la position X appartient 61 la Classe Sémantique CS ?’
3 Optimisation de paramétres : Leave-one-Out

3.1 Principe

Le reglage des parametres n'est pas une chose evidente dans le cadre de systemes
supervises. Pour cela, la technique bien connue du leave-one-out (Lachenbruch et
Michey, 1968) a ete employee pour optimiser les parametres entrant en jeu dans la
construction des arbres. Le principe de cette technique consiste a effectuer une
evaluation circulaire sur le corpus d'apprentissage, en excluant a chaque tour un

Peut-on Trouver la Taille de Contexte Optimale en Desambiguisation Semantique?

exemple du corpus d'apprentissage qui sera utilise par la suite comme element de test.
Le corpus d'apprentissage de SENSEVAL-2 a ete utilise pour effectuer ces reglages. Les
resultats presentes dans la prochaine section

Cette technique rend possible plusieurs types d'optimisations :

0 Optimisation de la taille de la fenétre de contexte: des experiences
menees precedemment sur les donnees SENSEVAL-1 ont montre que la
taille de fenétre optiIr1ale varie d'un mot a l'autre (cf. 4.1) ;

0 Utilisation des informations additionnelles: bien que l'utilisation des CS
apporte une amelioration sensible des performances en precision
moyenne, ce surcroit d'information penalise, malgre tout, certains mots;

0 Optimisation de profondeur d'arbre: la profondeur optimale de chaque
arbre est egalement variable selon les arbres.

Dans la section suivante, seul le critere d'optiInisation de la longueur de contexte sera
etudie.

3.2 Application £1 la détection de taille optimale de contexte

Le but de cette experience est de veriﬁer l’hypothese selon laquelle il serait possible
d’appliquer la technique du leave-one-out aﬁn de detecter, de maniere automatique, la
taille de fenétre optimale (dans le cadre des SCT).

Lors de recents travaux (Crestan et El-Beze, 2001a) nous avons observe qu’il n’y a
pas de taille de fenétre unique adaptee a tous les noms (corpus SENSEVAL- 1), mais que
celle-ci varie d’un mot a l’autre. D’apres ces memes travaux, il a ete montre qu’un
gain en precision globale de 1% serait possible si l’on pouvait determiner a priori la
longueur de fenétre optiIr1ale a utiliser lors de l’apprentissage. Des tests siIr1ilaires,
realises sur les donnees SENSEVAL- 2, ont conduit aux memes conclusions.

Résultats sur corpus d'apprentissage

(leave _0ne_0ut) Resultats sur corpus de test

Nb Test SCT k=3 SCT k=5 SCT k=7 Avec 19 SCT k=3

Moyennel 98 57.0 55.3 54.0 63.6 65.3

Tableau 1: Optimisation de taille de fenétre par leave-one-out sur les NOMS

Partant des observations faites precedemment, la technique du leave-one-out a ete
appliquee au corpus d'apprentissage des 29 NOMS fournis lors de l'evaluation
SENSEVAL-2 (art, authority, bar, bum, chair, channel, child, church, circuit, day,
detention, dyke, facility, fatigue, feeling, grip, hearth, holiday, lady, material, mouth,
nation, nature, post, restraint, sense, spade, stress et yew). Ces resultats sont presentes
dans le Tableau 1. Pour chaque longueur de fenétre consideree (k=3, 5 et 7), les arbres
ont ete construits sequentiellement sur tous les exemples sauf un, puis testes sur celui-
ci. Les colonnes SCT k=3, 5 et 7 indiquent la precision moyenne obtenue pour chacun
des mots (en prenant successivement chaque exemple comme test et tous les autres
oomme entrainement). La fenétre qui donne globalement la meilleure precision pour

Eric Crestan, Marc El-Béze et Claude de Loupy

un mot m est consideree par la suite comme la longueur de fenetre optimale (k) lors
du test de m. De par la ﬁnesse des sens de Wordnet, plusieurs exemples du corpus
d'apprentissage n'ont pas ete desambiguises par les juges. Pour respecter le caractere
ambigu de ces exemples, nous les avons dupliques selon autant d'exemple qu'il y avait
de sens.

3.3 Validation de l'approche

Les tests menes sur le corpus d'evaluation de SENSEVAL-2 ne sont malheureusement
pas correles avec les observations faites sur le corpus d'apprentissage. En effet, les
resultats obtenus en utilisant les tailles de fenetre "optiInales" determinees par la
methode du leave-one-out (I3 ) sont en dega des resultats obtenus avec une fenétre ﬁxe
k=3. La precision moyenne est de 1.7% plus mauvaise. Sur les 29 noIns de cette
experience, la colonne (IQ) presente seulement 2 fois des resultats superieurs a la
colonne (SCT k=3), alors que le cas contraire se veriﬁe 9 fois, le reste des resultats
etant identique.

Plusieurs raisons peuvent étre avancees pour expliquer cet echec. Tout d'abord, le
nombre d'exemples pour chaque sens est tres faible. Qui plus est, pour certains sens
seuls un ou deux exemples sont presents dans le corpus d'apprentissage, ce qui
provoque forcement des erreurs sur ces exemples lors de l'utilisation du leave-one-out.
Ainsi, 1 seul exemple est fourni pour 3 sens differents du nom art et seulement 2 pour
5 autres sens de ce mot. Le processus de construction des arbres ne pouvant pas
caracteriser ces sens par manque de donnees, les resultats sont d'autant plus mauvais.
La presence de plusieurs sens possibles pour un meme exemple est egalement source
de problemes. I1 n'est pas possible de trouver une question pour separer ces exemples
dupliques car les contextes sont identiques. D'autres experiences devront etre menees
dans cette direction pour determiner quelle est la meilleure strategie a appliquer avec
les exemples "ambigus" (par exemple ne oonserver qu'un seul des sens). La methode
du leave-one-out ne semble donc pas étre appropriee pour detecter automatiquement
la taille optimale de fenétre de contexte, dans le cadre de notre approche par SCT.

4 Selection automatique de fenétre optimale

Differents travaux ont ete menes par le passe sur l’optiInisation de la taille de fenétre
de contexte. I1 convient de citer les travaux de Yarowsky (1992) qui avance que deux
types d’ambigu'1'te existent : l’ambigu'1'te relevant du domaine, qui necessite une
fenétre d’etude de 20 a 50 mots et l’ambigu'1'te locale pour laquelle une fenetre de 2 a
3 mots semble sufﬁsante. Neanmoins, il ne fournit pas de solution a ce probleme de
selection de taille de fenetre. Les experiences presentees par la suite permettent d’y

repondre en partie.
4.1 Principe

Dans la section precedente, nous avons montre que la technique du leave-one-out
n’est pas adaptee a l’optimisation de la taille de fenetre de contexte. Cette section est
centree sur une approche novatrice, faisant intervenir un systeme decisionnel, ce qui
permet de s’affranchir de la tache d’optiInisation de taille de fenétre de contexte.
L’idee principale consiste a trouver des informations utiles a la desambigu'1'sation
semantique dans un contexte plus etendu, dans le but de renforcer les observations

Peat-on Trouver la Taille de Contexte Optimale en Désambiguilsation Sémantique?

effectuées en contexte court. Ce systeme a l’avantage d’étre dynamique, dans le sens
o1‘1 il sélectionne la fenétre optimale pour chaque phrase de test et non pas une fois
pour toute pour un mot donné comme c'était le cas en section 3. Le principe en est le
suivant: pour chaque mot a désambigu'1'ser W, trois SCT sont entrainés sur le corpus
d’apprentissage en utilisant pour chacun des contextes de longueur différente
(respectivement, SCI"=3 (W), SCT"=5(W) et SCT"=7(W) ). Ensuite, lors de la phase de
désambigu'1'sation, pour chaque test 2,‘, les arbres sont parcourus successivement, ce qui
a pour but de générer trois propositions de sens (S "=3 (t) , S "=5 (t), S"=7 (t) ). Le systeme

décisionnel prend alors le relais et determine, parmi ces sens, lequel semble le plus
conforme aux indices réooltés sur un contexte plus large.

Le point crucial de cette approche reste la fonction de décision. L'approche
décisionnelle la plus simple consiste a utiliser un systeme probabiliste basé sur un
modele unisem, mais les expériences que nous avons menées dans cette voie ont

conduit a des résultats décevants.

En 1993, Gale et al. ont appliqué une approche d'extraction d'information au domaine
de la désambigu'1'sation sémantique. Ils ont utilisé une taille de fenétre de contexte
arbitraire de 50 mots a gauche, ainsi qu'a droite du mot a désambigu'1'ser. Ensuite, ils
ont utilisé un systeme de recherche documentaire probabiliste pour comparer le
contexte des mots a désambiguiser, avec le contexte de ces mémes mots oontenus
dans le corpus d'apprentissage. Leurs conclusions furent que les résultats sont
signiﬁcativement améliorés lorsque l'on utilise un contexte plus vaste. Le systeme
décisionnel utilisé dans cette expérience est inspiré de ces travaux, il met en oeuvre
une mesure de distance entre une phrase de test 2,‘ et un pseudo-document créé a partir

du corpus d'apprentissage. Pour un mot donné W, un pseudo-document D SW) est un

document construit par la concaténation de toutes les phrases présentes dans le corpus
d'entrainement pour un méme sens de ce mot S,.<W>. La mesure de similarité classique
du Cosinus déﬁnie par Salton et McGill (1986), est alors utilisée pour calculer la
distance entre les phrases de test et les pseudo- documents.

4.2 Validation de l’approche

Pour vériﬁer la validité de l’approche présentée dans la section précédente, des tests
ont été menés sur les données d’évaluation SENSEVAL-1. Le systeme de détection
automatique de taille de contexte a été appliqué aux 12 noms, ainsi qu’aux 13 verbes
de l’évaluation. Les résultats sont présentés dans le Tableau 2 :

SCT k=3 SCT k=5 SCT k=7 MaxStat SCT + Cos

NOMS 83,3 82,1 82,1 84,3 85,7
VERBES 71,1 68,6 68,0 71,6 72,8

Tableau 2: Evaluation sur les données SENSEVAL-1 (en %)

La colonne intitulée MaxStat correspond a la précision moyenne qu’aurait pu atteindre
un systeme opérant une sélection de taille de fenétre de contexte appropriée a chaque
mot. Il faut toutefois noter que cela ne garantit pas l’optima1ité au niveau de chaque
test, mais seulement au niveau du mot. Cela correspond donc a la borne supérieure
pour une adaptation statique. La derniere colonne (S‘CT+C0s) contient les précisions
moyennes obtenues pour les noIns et les verbes en utilisant l’adaptati0n dynamique

Eric Crestan, Marc El-Beze et Claude de Loupy

avec le systeme base sur la mesure de similarite du Cosinus. Ces resultats sont tout a
fait satisfaisants car, en plus d’etre signiﬁcativement superieurs aux resultats obtenus
par les SCT seuls, ils sont egalement superieurs aux meilleurs resultats que nous
aurions pu obtenir par adaptation statique. Au vu de ces resultats, il semble clair qu'il
n'eXiste pas de taille ﬁxe pour un mot donne. En elargissant le contexte, il est possible
de choisir entre trois tailles de fenetre au niveau du test.

NOMs Nb Test SCT k=3 SCT k=5 SCT k=7 MaxStat SCT +Cos
art 98 63,3 64,3 62,2 64,3 63,3
authority 92 72,8 67,4 66,3 72,8 72,8
bar 151 61,6 53,6 56,3 61,6 58,9
bum 45 75,6 73,3 68,9 75,6 80,0
chair 69 79,7 81,2 76,8 81,2 81,2
channel 73 54,8 54,8 53,4 54,8 56,2
child 64 54,7 57,8 60,9 60,9 62,5
church 64 54,7 46,9 42,2 54,7 56,3
circuit 85 57,6 48,2 57,6 57,6 57,6
day 145 64,8 61,4 60,0 64,8 65,5
detention 32 84,4 84,4 84,4 84,4 87,5
dyke 28 78,6 71,4 67 ,9 7 8,6 7 8,6
facility 58 65 ,5 67,2 58,6 67,2 67,2
fatigue 43 86,0 76,7 76,7 86,0 86,0
feeling 51 66,7 64,7 64,7 66,7 66,7
grip 51 54,9 64,7 66,7 66,7 62,7
hearth 32 75,0 78,1 71,9 78,1 81,3
holiday 31 83,9 80,6 83,9 83,9 83,9
lady 53 62,3 58,5 56,6 62,3 66,0
material 69 52,2 52,2 46,4 52,2 58,0
mouth 60 63,3 60,0 55,0 63,3 65,0
nation 37 73,0 64,9 62,2 73,0 78,4
nature 46 56,5 54,3 52,2 56,5 63,0
post 79 67,1 64,6 60,8 67,1 72,2
restraint 45 60,0 60,0 55,6 60,0 62,2
sense 53 73,6 75,5 73,6 75,5 75,5
spade 33 72,7 72,7 66,7 72,7 72,7
stress 39 51,3 51,3 48,7 51,3 48,7
yew 28 78,6 78,6 78,6 78,6 78,6
Moyenne 98 65,3 62,9 61,5 66,1 67,1

Tableau 3 : Inﬂuence du systeme decisionnel sur fenetre de contexte — donnees
SENsEVAL—2 (en %)

4.3 Evaluation sur SENSEVAL-2

Pour veriﬁer les resultats obtenus sur le corpus SENSEVAL-1, les donnees d’evaluation
de la tache lexical-sample de SENSEVAL-2 ont ete employees. Les resultats obtenus
pour les 29 noIns de cette evaluation sont presentes dans le Tableau 3. Il faut noter
que les resultats obtenus dans ce tableau ne sont pas directement comparables avec les
resultats obtenus sur l’evaluation precedente car le referentiel semantique n’est pas le
meme. Comme pour les tests precedents, la precision moyenne decroit lorsque la taille
de la fenetre de contexte utilisee pour construire les arbres croit (k=3, 5 et 7). Par
contre, cela n’est pas vrai pour chaque mot pris de maniere individuelle. C’est le cas
pour les noIns child, grip, sense, qui voient leur precision moyenne amelioree de
maniere signiﬁcative avec une fenetre de contexte plus etendue. L’exemple de sense
est eloquent puisque le gain est de presque 2% lorsque l’on passe d’une fenetre k=3 a
k=5. Une analyse rapide des donnees montre que le gain est principalement dﬁ a la
possibilite de distinguer les acceptions «sense of humour », grace a la presence du

Peut-on Trouver la Taille de Contexte Optimale en Désambiguisation Sémantique?

mot humour en position p=+2 par rapport au mot a désaInbigu'1'ser. Bien que
l’élargissement de la taille de fenétre de contexte soit bénéﬁque dans certain cas, cela
reste toutefois u1e erreur dans la plupart des cas. Par exemple, le nom nation voit sa
precision moyenne décroitre de maniere tres importante avec l’élargissement de la
taille de fenétre.

De la méme maniere que dans la section 4.2, les colonnes MaxStat et SCT+Cos ont
été calculées. Les observations sont les memes que sur le jeu de données précédent:
un systeme décisionnel utilisé en seconde phase aide a l’optiInisation automatique de
la taille de fenétre contextuelle. Il faut noter que le nom nature obtient un gain de
6,5% par rapport au meilleur score obtenu par les SCT seuls (k=3). Une étude
approfondie pour ce nom, montre que dans 41% des cas, les 3 sens proposés (k=3, 5
et 7) sont identiques. Donc, le gain de 6,5% n’est obtenu que sur les 59% des tests
restants, ce qui correspond a 27 tests. Cette approche ne permet cependant pas a tous
les coups de sélectionner la meilleure fenétre car, dans le cas des noms, la bonne
réponse ne se trouve que dans 72,9% des cas dans les 3 sens proposés.

4.4 Discussion

Pour démontrer la capacité d’un tel systeme a utiliser des informations dans un
contexte étendu, l’eXemple suivant apporte des éléments de réponse intéressants :

‘furthermore , nothing have yet be say about all the research that do not depend on the collection

of datum by the sociologist ( primary datum ) but instead make use of secondary datum - the
wealth of material already available from other source , such as government statistics , personal

diary , newspaper , and other kind of information .’

Le nom material est présenté dans son contexte apres pré-traitement, avec la partie
grisée correspondant a la fenétre maximale prise en compte par les SCT. Deux sens
sont proposés par les SCT: materiaI%1:27:oo:: (‘tangible substance that goes in the
makeup of a physical object’) pour k=3 et 7, et material%1:10:oo:: (‘information that
can be reworked into a ﬁnished form’) pour k=5. L’utilisation du contexte dans sa
globalité, permet de faire le bon choix entre ces deux sens, notamment grace aux mots
research, collection, newspaper et datum qui décrivent une thématique précise
(domaine documentaire). Il semblerait donc qu’un systeme décisionnel utilisant un
contexte plus étendu soit capable de tirer proﬁt d’indices a un niveau plus thématique.

Les tests conduits sur les verbes et les adjectifs ont montre des comportements
similaires (voir Tableau 4). 11 y a toutefois une nuance a apporter en ce concernant les
verbes. Le score obtenu avec SCT+Cos, bien que supérieur de presque 3% aux
SCT (k=3), reste inférieur au score avec sélection optimale de taille de fenétre par mot
(MaxStat). Cela peut s’expliquer par le caractere tres aInbigu des verbes de la tache
SENSEVAL-2.

SCT k=3 SCT ké SCT k=7MaXStaIi SCT + Cos
Noms 65,3 62,9 61,5 66,1 67,1
Verbes 50,7 50,4 49,9 54,2 53,5
Adjectifsl 64,6 59,1 57,4 65,9 66,4
Total 59,1 57,0 55,9 61,1 61,3
Tableau 4 :Améliorations apportées par un systeme décisionnel (en %)

Ces résultats nous ont permis de nous positionner dans les 3 premiers systemes (dans
les 5 premiers apres re-soumission des tests) a moins de 3% du participant
« vainqueur » de l’évaluation.

Eric Crestan, Marc El-Beze et Claude de Loupy

5 Conclusion

Nous avons montre, par nos experiences, qu'il est possible d'accroitre les
performances d'un systeme de desambigu'1'sation semantique au-dela des performances
optimales obtenues de maniere statique. L’utilisation d’un systeme a adaptation
dynamique pour la desambiguisation semantique a montre des ameliorations
substantielles. Bien que les verbes ne semblent pas proﬁter autant que les noms et les
adjectifs de cette approche, le gain moyen reste tout de meme de 2,3 %, toutes
categories grammaticales confondues. De futures experiences devront etre menees en
utilisant un contexte etendu, pour determiner dans quelles mesures la
desambigu'1'sation d’un mot se joue egalement dans un contexte plus large. D’autres
pistes sont egalement a explorer, notamment ooncemant l’utilisation d’une grammaire
fonctionnelle pour augmenter les champs d’app1ication des questions des SCT. Cela
pourrait proﬁter grandement aux verbes, principalement grace aux structures:
sujet+verbe+0bjet. Enﬁn, il serait interessant d’utiliser un autre referentiel
semantique que Wordnet pour la generalisation par classes semantiques. La presence
de sens trop ﬁns au niveau des mots en contexte, genere une multitude de CS possible
pour ceux-ci. Par exemple le nom dog est egalement associe a la classe humain par
l’interrnediaire de son sens familier qui est rarement utilise.

References

Breiman L., Friedman J. H., Olshen R. A., et Stone C. J. (1984). Classiﬁcation and Regression Trees.
Wadsworth International, Belmont, CA.

Crestan E. et El-Beze M. (2001a). Improving Supervised WSD by Including Rough Semantic Features
in a Multi-Level View of the Context. SEMPRO Workshop, Edinburgh.

Crestan E., El-Beze M. et Loupy C. de (2001b). Improving WSD with Multi-Level View of Context
Monitored by Similarity Measure. In Proc. of SENSEVAL-2 Workshop, Toulouse, pp. 67-70.

Gale W., Church K. W., et Yarowsky D. (1993). A Method for Disambiguating Word Senses in a Large
Co rpus. Computers and the Humanities, 26 : pp. 415-39.

Kaplan A. (1950) An experimental study of ambiguity and context. Mechanical Translation, (2:2), 39-
46 (issue appeared in 1955).

Kilganiff A. et Rosenzweig J. (2000). English SENSEVAL : Report and Results. In Proc. LREC,
Athens, Greece, 3 : pp. 1239-44. httn://www.itri.ac.uk/events/senseval

Kulm R. et De Mori R. (1995). The Application of Semantic Classiﬁcation Trees to Natural Language
Understanding. IEEE Transactions on Pattern Analysis and Machine Intelligence, 17(5) : pp. 449-60.

Lachenbruch P. A. et Mickey M. R. (1968). Estimation of Error Rate in Discriminant Analysis,
Technonntrics, 10, no.1 pp. 1-10.

Loupy C. de et El-Beze M. (2000), Using Few Clues can compensate the small amount of resources
available for Word Sense Disambiguation. LREC, Athens, Greece, 1 : pp. 219-23.

Loupy C. de, El-Beze M. et Marteau P. F. (2000), Using Semantic Classification Trees for WSD.
Computer and the Humanities, Kluwer Academic Publishers, 34: pp. 187-92.

Ney H., Martin S. et Wessel F. (1997). "Statistical Language Modeling Using Leaving-One-0ut", in S.
Young & G. Bloothooft (eds.), Corpus-Based Methods in Language and Speech Processing, Kluwer
Academic Publishers, pp. 174-207.

Salton G. et McGill M. (1983). Introduction to Modern Information Retrieval. McGraw-I-Iill, NY.

Yarowsky D. (1992). Word-Sense Disambiguation Using Statistical Models of Roget's Categories
Trained on Large Corpora. In Proceedings of COLING-92, Nantes, France, pp 454-460.

Yarowsky D. (1993). One sense per collocation. In Proceedings of the ARPA Workshop on Human
Language Technology, Princeton, pp. 266-71.

