<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Breiman</author>
<author>J H Friedman</author>
<author>R A Olshen</author>
<author>et Stone C J</author>
</authors>
<title>Classification and Regression Trees.</title>
<date>1984</date>
<publisher>Wadsworth International,</publisher>
<location>Belmont, CA.</location>
<contexts>
<context position="6051" citStr="Breiman et al. 1984" startWordPosition="918" endWordPosition="921">issage annoté. Le corpus d’entraînement de la tâche lexical sample de l’évaluation SENSEVAL-2 a donc été utilisé pour construire un arbre de classification pour chaque mot à désambiguïser. Le processus de construction des arbres consiste à trouver à chaque étape de la construction, la question optimale qui sépare au mieux l’espace constitué par les différentes populations d’exemples. Les questions posées à chaque nœud de l’arbre sont de la forme : ‘Est-ce que l’élément (lemme, stemme ou graphie) à la position P est égale à X ?’ Dans le cadre de cette expérience, le critère d’impureté de Gini (Breiman et al. 1984) a été employé comme critère de décision. sense%1:10:00:: firebreak , in sense of material burning sense%1:10:00:: someone , in sense of appear , sense%1:10:00:: which people make sense of situation , “the meaning of a word or expression” sense%1:10:00:: way of make sense of be to sense%1:10:00:: make sort of sense of relatedness . sense%1:09:05:: be inhibit by sense that government and sense%1:09:05:: Jess feel such sense of disappointment that sense%1:09:05:: of credo underpin sense of faith in “a general conscious awareness” sense%1:09:05:: ceiling add to sense of space and sense%1:09:05:: </context>
</contexts>
<marker>Breiman, Friedman, Olshen, J, 1984</marker>
<rawString>Breiman L., Friedman J. H., Olshen R. A., et Stone C. J. (1984). Classification and Regression Trees. Wadsworth International, Belmont, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Crestan E et El-Bèze M</author>
</authors>
<title>Improving Supervised WSD by Including Rough Semantic Features in a Multi-Level View of the Context. SEMPRO Workshop,</title>
<date>2001</date>
<location>Edinburgh.</location>
<marker>M, 2001</marker>
<rawString>Crestan E. et El-Bèze M. (2001a). Improving Supervised WSD by Including Rough Semantic Features in a Multi-Level View of the Context. SEMPRO Workshop, Edinburgh.</rawString>
</citation>
<citation valid="false">
<authors>
<author>E Crestan</author>
<author>M El-Bèze</author>
</authors>
<title>et Loupy C. de (2001b). Improving WSD with Multi-Level View of Context Monitored by Similarity Measure.</title>
<booktitle>In Proc. of SENSEVAL-2 Workshop,</booktitle>
<pages>67--70</pages>
<location>Toulouse,</location>
<marker>Crestan, El-Bèze, </marker>
<rawString>Crestan E., El-Bèze M. et Loupy C. de (2001b). Improving WSD with Multi-Level View of Context Monitored by Similarity Measure. In Proc. of SENSEVAL-2 Workshop, Toulouse, pp. 67-70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K W Church</author>
<author>et Yarowsky D</author>
</authors>
<title>A Method for Disambiguating Word Senses in a Large Corpus.</title>
<date>1993</date>
<journal>Computers and the Humanities,</journal>
<volume>26</volume>
<pages>415--39</pages>
<marker>Gale, Church, D, 1993</marker>
<rawString>Gale W., Church K. W., et Yarowsky D. (1993). A Method for Disambiguating Word Senses in a Large Corpus. Computers and the Humanities, 26 : pp. 415-39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kaplan</author>
</authors>
<title>An experimental study of ambiguity and context.</title>
<date>1950</date>
<journal>Mechanical Translation,</journal>
<volume>2</volume>
<pages>39--46</pages>
<note>issue appeared in</note>
<contexts>
<context position="1993" citStr="Kaplan (1950)" startWordPosition="286" endWordPosition="287"> We used a two-step strategy based on Semantic Classification Trees (SCT) and on a similarity measure. Whereas SCTs are employed on a short window size of 3, 5 and 7 words, the technique based on similarity measure is appllied to a ‘wider’ context size. The improvements observed in the SENSEVAL-1 lexical-sample task are verified on the SENSEVAL-2 data. Mots clés – Keywords Désambiguïsation sémantique, arbres de classification sémantique. Word sense disambiguation, semantic classification trees, monitoring system. Éric Crestan, Marc El-Bèze et Claude de Loupy 1 Introduction Dans les années 50, Kaplan (1950) a observé, à l’occasion d’une expérimentation, que la traduction d’un mot par sept traducteurs différents n’était ni meilleure ni pire lorsque ceux-ci n’avaient à leur disposition que deux mots de contexte de chaque côté du mot à traduire, plutôt que la phrase au complet. Plus récemment, Yarowsky (1993) a déclaré que la plupart des indices utiles à la désambiguïsation sémantique se trouvent dans un micro-contexte de 6 à 8 mots. Toutefois, il faut noter que dans un contexte de « si grande taille », il est souvent difficile de discerner les éléments clés, par rapport aux éléments non porteurs d</context>
</contexts>
<marker>Kaplan, 1950</marker>
<rawString>Kaplan A. (1950) An experimental study of ambiguity and context. Mechanical Translation, (2:2), 39-46 (issue appeared in 1955).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kilgarriff A et Rosenzweig J</author>
</authors>
<title>English SENSEVAL : Report and Results. In</title>
<date>2000</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<booktitle>Proc. LREC,</booktitle>
<volume>17</volume>
<issue>5</issue>
<pages>1239--44</pages>
<location>Athens, Greece, 3 :</location>
<note>http://www.itri.ac.uk/events/senseval</note>
<marker>J, 2000</marker>
<rawString>Kilgarriff A. et Rosenzweig J. (2000). English SENSEVAL : Report and Results. In Proc. LREC, Athens, Greece, 3 : pp. 1239-44. http://www.itri.ac.uk/events/senseval Kuhn R. et De Mori R. (1995). The Application of Semantic Classification Trees to Natural Language Understanding. IEEE Transactions on Pattern Analysis and Machine Intelligence, 17(5) : pp. 449-60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lachenbruch P A et Mickey M R</author>
</authors>
<title>Estimation of Error Rate in Discriminant Analysis,</title>
<date>1968</date>
<journal>Technometrics,</journal>
<volume>10</volume>
<pages>1--1</pages>
<marker>R, 1968</marker>
<rawString>Lachenbruch P. A. et Mickey M. R. (1968). Estimation of Error Rate in Discriminant Analysis, Technometrics, 10, no.1 pp. 1-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Loupy C de et El-Bèze M</author>
</authors>
<title>Using Few Clues can compensate the small amount of resources available for Word Sense Disambiguation.</title>
<date>2000</date>
<journal>LREC, Athens, Greece,</journal>
<volume>1</volume>
<pages>219--23</pages>
<marker>M, 2000</marker>
<rawString>Loupy C. de et El-Bèze M. (2000), Using Few Clues can compensate the small amount of resources available for Word Sense Disambiguation. LREC, Athens, Greece, 1 : pp. 219-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Loupy C de</author>
<author>El-Bèze M et Marteau P F</author>
</authors>
<title>Using Semantic Classification Trees for WSD. Computer and the Humanities,</title>
<date>2000</date>
<journal>Kluwer Academic Publishers,</journal>
<volume>34</volume>
<pages>187--92</pages>
<marker>de, F, 2000</marker>
<rawString>Loupy C. de, El-Bèze M. et Marteau P. F. (2000), Using Semantic Classification Trees for WSD. Computer and the Humanities, Kluwer Academic Publishers, 34: pp. 187-92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ney</author>
<author>Martin S et Wessel F</author>
</authors>
<title>Statistical Language Modeling Using Leaving-One-Out&amp;quot;,</title>
<date>1997</date>
<booktitle>Corpus-Based Methods in Language and Speech Processing,</booktitle>
<pages>174--207</pages>
<editor>in S. Young &amp; G. Bloothooft (eds.),</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<marker>Ney, F, 1997</marker>
<rawString>Ney H., Martin S. et Wessel F. (1997). &amp;quot;Statistical Language Modeling Using Leaving-One-Out&amp;quot;, in S. Young &amp; G. Bloothooft (eds.), Corpus-Based Methods in Language and Speech Processing, Kluwer Academic Publishers, pp. 174-207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Salton G et McGill M</author>
</authors>
<title>Introduction to Modern Information Retrieval.</title>
<date>1983</date>
<location>McGraw-Hill, NY.</location>
<marker>M, 1983</marker>
<rawString>Salton G. et McGill M. (1983). Introduction to Modern Information Retrieval. McGraw-Hill, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Word-Sense Disambiguation Using Statistical Models of Roget&apos;s Categories Trained on Large Corpora .</title>
<date>1992</date>
<booktitle>In Proceedings of COLING-92,</booktitle>
<pages>454--460</pages>
<location>Nantes, France,</location>
<contexts>
<context position="16134" citStr="Yarowsky (1992)" startWordPosition="2492" endWordPosition="2493">iqués car les contextes sont identiques. D&apos;autres expériences devront être menées dans cette direction pour déterminer quelle est la meilleure stratégie à appliquer avec les exemples &amp;quot;ambigus&amp;quot; (par exemple ne conserver qu&apos;un seul des sens). La méthode du leave-one-out ne semble donc pas être appropriée pour détecter automatiquement la taille optimale de fenêtre de contexte, dans le cadre de notre approche par SCT. 4 Sélection automatique de fenêtre optimale Différents travaux ont été menés par le passé sur l’optimisation de la taille de fenêtre de contexte. Il convient de citer les travaux de Yarowsky (1992) qui avance que deux types d’ambiguïté existent : l’ambiguïté relevant du domaine, qui nécessite une fenêtre d’étude de 20 à 50 mots et l’ambiguïté locale pour laquelle une fenêtre de 2 à 3 mots semble suffisante. Néanmoins, il ne fournit pas de solution à ce problème de sélection de taille de fenêtre. Les expériences présentées par la suite permettent d’y répondre en partie. 4.1 Principe Dans la section précédente, nous avons montré que la technique du leave-one-out n’est pas adaptée à l’optimisation de la taille de fenêtre de contexte. Cette section est centrée sur une approche novatrice, fa</context>
</contexts>
<marker>Yarowsky, 1992</marker>
<rawString>Yarowsky D. (1992). Word-Sense Disambiguation Using Statistical Models of Roget&apos;s Categories Trained on Large Corpora . In Proceedings of COLING-92, Nantes, France, pp 454-460.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>One sense per collocation.</title>
<date>1993</date>
<booktitle>In Proceedings of the ARPA Workshop on Human Language Technology,</booktitle>
<pages>266--71</pages>
<location>Princeton,</location>
<contexts>
<context position="2298" citStr="Yarowsky (1993)" startWordPosition="334" endWordPosition="335">al-sample task are verified on the SENSEVAL-2 data. Mots clés – Keywords Désambiguïsation sémantique, arbres de classification sémantique. Word sense disambiguation, semantic classification trees, monitoring system. Éric Crestan, Marc El-Bèze et Claude de Loupy 1 Introduction Dans les années 50, Kaplan (1950) a observé, à l’occasion d’une expérimentation, que la traduction d’un mot par sept traducteurs différents n’était ni meilleure ni pire lorsque ceux-ci n’avaient à leur disposition que deux mots de contexte de chaque côté du mot à traduire, plutôt que la phrase au complet. Plus récemment, Yarowsky (1993) a déclaré que la plupart des indices utiles à la désambiguïsation sémantique se trouvent dans un micro-contexte de 6 à 8 mots. Toutefois, il faut noter que dans un contexte de « si grande taille », il est souvent difficile de discerner les éléments clés, par rapport aux éléments non porteurs d’information pour la détermination du sens d’un mot. Au-delà de cette réduction de la fenêtre de contexte nécessaire à la désambiguïsation, il paraît évident qu’une taille fixe n’est pas adaptée à tous les mots. Pour s’affranchir de ce problème, il est possible dans le cadre de systèmes supervisés, de dé</context>
</contexts>
<marker>Yarowsky, 1993</marker>
<rawString>Yarowsky D. (1993). One sense per collocation. In Proceedings of the ARPA Workshop on Human Language Technology, Princeton, pp. 266-71.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>