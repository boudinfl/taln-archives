<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Apprentissage Automatique de Paraphrases pour l&#8217;Am&#233;lioration d&#8217;un Syst&#232;me de Questions-R&#233;ponses</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2003, Batz-sur-Mer, 11&#8211;14 juin 2003
</p>
<p>Apprentissage Automatique de Paraphrases pour
l&#8217;Am&#233;lioration d&#8217;un Syst&#232;me de Questions-R&#233;ponses
</p>
<p>Florence Duclaye (1 et 2), Olivier Collin (1), Fran&#231;ois Yvon (2)
(1) France T&#233;l&#233;com R&amp;D
2 avenue Pierre Marzin
22307 Lannion Cedex
</p>
<p>{florence.duclaye,olivier.collin}@rd.francetelecom.fr
(2) GET/ENST et LTCI, CNRS URA 820
</p>
<p>46 rue Barrault
75624 Paris Cedex 13
</p>
<p>{fduclaye,yvon}@enst.fr
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>Questions-R&#233;ponses, Apprentissage Automatique, Acquisition de Paraphrase
Question Answering, Machine Learning, Paraphrase extraction
</p>
<p>R&#233;sum&#233; - Abstract
</p>
<p>Dans cet article, nous pr&#233;sentons une m&#233;thodologie d&#8217;apprentissage faiblement supervis&#233; pour
l&#8217;extraction automatique de paraphrases &#224; partir du Web. &#192; partir d&#8217;un seule exemple de paire
(pr&#233;dicat, arguments), un corpus est progressivement accumul&#233; par sondage du Web. Les phases
de sondage alternent avec des phases de filtrage, durant lesquelles les paraphrases les moins
plausibles sont &#233;limin&#233;es &#224; l&#8217;aide d&#8217;une proc&#233;dure de clustering non supervis&#233;e. Ce m&#233;canisme
d&#8217;apprentissage s&#8217;appuie sur un syst&#232;me de Questions-R&#233;ponses existant et les paraphrases ap-
prises seront utilis&#233;es pour en am&#233;liorer le rappel. Nous nous concentrons ici sur le m&#233;canisme
d&#8217;apprentissage de ce syst&#232;me et en pr&#233;sentons les premiers r&#233;sultats.
</p>
<p>In this paper, we present a nearly unsupervised learning methodology for automatically extract-
ing paraphrases from the Web. Starting with one single instance of a pair (predicate,arguments),
a corpus is incrementally built by sampling the Web. Sampling stages alternate with filter-
ingstages, during which implausible paraphrases are filtered out using an EM-based unsuper-
vised clustering procedure. This learning machinery is built on top of an existing question-
answering system and the learnt paraphrases will eventually be used to improve its recall. We
focus here on the learning aspect of this system and report preliminary results.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florence Duclaye, Olivier Collin, Fran&#231;ois Yvon
</p>
<p>1 Introduction
</p>
<p>Les syst&#232;mes de Questions-R&#233;ponses (Voorhees, 1999) n&#233;cessitent des outils efficaces et so-
phistiqu&#233;s de traitement automatique des langues, capables de traiter la variabilit&#233; linguistique
des questions et des r&#233;ponses: une m&#234;me signification peut, en effet, &#234;tre v&#233;hicul&#233;e par de multi-
ples structures lexico-syntaxiques. Cette variabilit&#233; est une source de difficult&#233;s dans la plupart
des applications de traitement automatique des langues.
</p>
<p>Cette variabilit&#233; se manifeste au niveau syntaxique, o&#249; elle prend, par exemple, la forme de
transformations r&#233;guli&#232;res de la voix actice &#224; la voix passive. Un traitement plus syst&#233;matique de
ce ph&#233;nom&#232;ne n&#233;cessite n&#233;anmoins des connaissances s&#233;mantiques, comme celles disponibles
dans des r&#233;seaux s&#233;mantiques (Miller et al., 1990). Le b&#233;n&#233;fice de telles ressources est toute-
fois limit&#233; car (i) les relations de synonymie qu&#8217;elles contiennent sont d&#233;finies hors de tout
contexte d&#8217;usage; (ii) la synonymie implique une notion de la paraphrase qui est beaucoup trop
restreinte pour l&#8217;application vis&#233;e. La r&#233;ponse &#224; une question est en effet souvent exprim&#233;e
&#224; l&#8217;aide de termes qui ne sont que faiblement (par ex. m&#233;taphoriquement) li&#233;s &#224; ceux de la
question. Ainsi l&#8217;expression &#8220;X a caus&#233; Y&#8221; peut &#234;tre consid&#233;r&#233;e comme s&#233;mantiquement simi-
laire &#224; &#8220;la responsabilit&#233; de Y est attribu&#233;e &#224; X&#8221; dans le contexte des Questions-R&#233;ponses (Lin
&amp; Pantel, 2001). Au lieu d&#8217;essayer de compl&#233;ter manuellement ces ressources statiques, nous
avons choisi d&#8217;exploiter les avantages d&#8217;une approche fond&#233;e sur des corpus et d&#8217;apprendre
de telles &#233;quivalences de mani&#232;re automatique. Nous utilisons le terme de paraphrase pour
faire r&#233;f&#233;rence &#224; ces relations, bien que la d&#233;finition du terme adopt&#233;e ici soit surtout focalis&#233;e
sur deux types de ph&#233;nom&#232;nes linguistiques : les paraphrases linguistiques et les d&#233;rivations
s&#233;mantiques. (Fuchs, 1982) d&#233;crit les paraphrases comme des phrases dont le sens linguis-
tique d&#233;notatif est &#233;quivalent. Les d&#233;rivations s&#233;mantiques sont des phrases dont le sens est
pr&#233;serv&#233; mais dont la structure lexico-syntaxique est diff&#233;rente (ex : AOL a achet&#233; Netscape /
l&#8217;acquisition de Netscape par AOL ). Le corpus utilis&#233; pour acqu&#233;rir les paraphrases est le Web.
Cette utilisation du Web comme corpus offre plusieurs avantages (Grefenstette, 1994). (i) Les
informations qu&#8217;il contient sont d&#8217;une grande vari&#233;t&#233; et d&#8217;une grande redondance, une m&#234;me
information pouvant appara&#238;tre sous de multiples formes. Notre algorithme d&#8217;apprentissage re-
pose fortement sur cette propri&#233;t&#233;. (ii) Le Web contient des informations contextuelles pouvant
contraindre la port&#233;e de la relation de paraphrase. En outre, comme notre syst&#232;me de Questions-
R&#233;ponses utilise le Web comme unique source d&#8217;information, il est important d&#8217;extraire les
formulations d&#8217;un concept qui sont les plus fr&#233;quemment utilis&#233;es sur le Web. Cette strat&#233;gie
n&#8217;est pas sans difficult&#233;s: la r&#233;duction du niveau de bruit dans les donn&#233;es extraites est en par-
ticulier un probl&#232;me important. Le m&#233;canisme d&#8217;apprentissage que nous proposons est capable
d&#8217;acqu&#233;rir automatiquement de multiples formulations d&#8217;une relation s&#233;mantique donn&#233;e &#224; par-
tir d&#8217;un seul exemple. Cette donn&#233;e de d&#233;part consiste en un exemple de la relation s&#233;mantique
vis&#233;e, o&#249; l&#8217;expression linguistique (formulation) de la relation et le couple d&#8217;arguments ont tous
deux &#233;t&#233; identifi&#233;s. Ce type de donn&#233;es est directement fourni par notre syst&#232;me de Questions-
R&#233;ponses, mais il est &#233;galement largement disponible dans les dictionnaires. &#201;tant donn&#233; cet
exemple positif, notre m&#233;canisme d&#8217;apprentissage envoie de mani&#232;re r&#233;p&#233;titive des requ&#234;tes sur
le Web et utilise alternativement les formulations connues pour acqu&#233;rir des nouveaux couples
d&#8217;arguments, et les couples d&#8217;arguments connus pour trouver de nouvelles formulations. Ce
m&#233;canisme se d&#233;compose en deux &#233;tapes: d&#8217;une part la recherche de paraphrases potentielles
de la relation s&#233;mantique et d&#8217;autre part la validation de ces paraphrases en se basant sur des
comptages de fr&#233;quences et sur l&#8217;algorithme d&#8217;Estimation-Maximisation (EM).
Cet article pr&#233;sente &#224; la Section 2 les travaux techniques de l&#8217;&#233;tat de l&#8217;art ayant influenc&#233; notre</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Apprentissage Automatique de Paraphrases
</p>
<p>approche, ainsi que les travaux de recherche li&#233;s &#224; l&#8217;apprentissage automatique de paraphrases.
La Section 3 d&#233;crit ensuite les d&#233;tails du fonctionnement de notre syst&#232;me. Avant de conclure,
la Section 4 pr&#233;sente quelques r&#233;sultats exp&#233;rimentaux obtenus qui permettent de mettre en
&#233;vidence l&#8217;int&#233;r&#234;t de notre approche.
</p>
<p>2 &#201;tat de l&#8217;art
2.1 Apprentissage automatique de paraphrases
</p>
<p>Comme les paraphrases peuvent &#234;tre utilis&#233;es dans de nombreux contextes et applications, leur
apprentissage peut &#234;tre r&#233;alis&#233; &#224; l&#8217;aide de diverses m&#233;thodologies. (Barzilay &amp; McKeown,
2001) distinguent trois m&#233;thodes diff&#233;rentes pour la collecte des paraphrases. La premi&#232;re est
leur collecte manuelle, la seconde est l&#8217;utilisation de ressources linguistiques existantes et la
troisi&#232;me est l&#8217;extraction de mots ou d&#8217;expressions similaires en se basant sur un corpus. De
ces trois m&#233;thodes, la premi&#232;re est sans doute la plus facile &#224; impl&#233;menter, mais probablement
la plus fastidieuse et la plus longue.
</p>
<p>Les ressources linguistiques tels que les dictionnaires peuvent s&#8217;av&#233;rer utiles pour la collecte
ou la g&#233;n&#233;ration de paraphrases. Par exemple, (Kurohashi &amp; Sakai, 1999) utilise un dictio-
nnaire construit manuellement pour reformuler des groupes nominaux ambigus en groupes
verbaux. Ces ressources peuvent &#234;tre utiles pour des besoins de d&#233;sambigu&#239;sation, mais en
l&#8217;absence d&#8217;information contextuelle suppl&#233;mentaire, les relations de synonymie qu&#8217;elles con-
tiennent doivent &#234;tre utilis&#233;es avec pr&#233;caution. De plus, elles sont souvent consid&#233;r&#233;es comme
peu adapt&#233;es aux traitements automatiques (Habert et al., 1997). (Torisawa, 2001) propose une
m&#233;thode bas&#233;e sur l&#8217;algorithme d&#8217;Estimation-Maximisation pour s&#233;lectionner les constructions
verbales servant &#224; paraphraser certaines expressions.
</p>
<p>Enfin, certains travaux men&#233;s dans le domaine de l&#8217;extraction bas&#233;e sur un corpus de mots ou
d&#8217;expressions similaires s&#8217;appuient sur l&#8217;hypoth&#232;se distributionnelle de Harris, selon laquelle
les mots apparaissant dans le m&#234;me contexte tendent &#224; avoir des sens similaires. Partant de ce
postulat, (Barzilay &amp; McKeown, 2001) et (Akira &amp; Takenobu, 2002) travaillent sur un ensemble
de corpus align&#233;s et utilisent des informations contextuelles bas&#233;es sur des similarit&#233;s lexicales
pour extraire des paraphrases. De mani&#232;re similaire, (Lin &amp; Pantel, 2001) utilise un algorithme
non supervis&#233; pour la d&#233;couverte de r&#232;gles d&#8217;inf&#233;rence &#224; partir de textes. Au lieu d&#8217;appliquer
l&#8217;hypoth&#232;se harrissienne aux mots, les auteurs l&#8217;appliquent &#224; des chemins dans les arbres de
d&#233;pendance d&#8217;un corpus analys&#233;.
</p>
<p>2.2 Extraction d&#8217;informations par bootstrapping
</p>
<p>Des travaux r&#233;cents men&#233;s en extraction d&#8217;informations nous fournissent des approches in-
t&#233;ressantes, pouvant &#234;tre adapt&#233;es au probl&#232;me de l&#8217;apprentissage automatique de paraphrases.
Ainsi, (Riloff &amp; Jones, 1999) d&#233;crit un syst&#232;me d&#8217;extraction d&#8217;informations reposant sur un m&#233;-
canisme de bootstrapping &#224; deux niveaux. Le niveau de &#8221;bootstrapping mutuel&#8221; construit alter-
nativement un lexique et des patrons d&#8217;extraction contextuels. Le niveau de &#8220;meta-bootstrapping&#8221;
ne conserve que les cinq meilleurs nouveaux termes extraits durant une it&#233;ration d&#8217;apprentissage,
avant de poursuivre avec le boostrapping mutuel. L&#8217;auteur parvient ainsi &#224; r&#233;duire la quantit&#233;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florence Duclaye, Olivier Collin, Fran&#231;ois Yvon
</p>
<p>de termes invalides trouv&#233;s en appliquant les patrons d&#8217;extraction.
</p>
<p>La technique DIPRE (Dual Iterative Pattern Relation Extraction), pr&#233;sent&#233;e dans (Brin, 1998)
est aussi une m&#233;thode de bootstrapping, utilis&#233;e pour l&#8217;acquisition de paires (auteur, titre) &#224;
partir d&#8217;un corpus de documents du Web. &#192; partir d&#8217;une collection d&#8217;exemples de tels exemples,
l&#8217;auteur construit des patrons d&#8217;extraction utilis&#233;s pour collecter de nouvelles paires (auteur,
titre). &#192; leur tour, ces paires sont recherch&#233;es dans le corpus et sont utilis&#233;es pour construire de
nouveaux patrons d&#8217;extraction, et ainsi de suite.
</p>
<p>Enfin, (Collins &amp; Singer, 1999) d&#233;crit une m&#233;thode de reconnaissance d&#8217;entit&#233;s nomm&#233;es ca-
pable d&#8217;apprendre &#224; partir d&#8217;un faible nombre de donn&#233;es de supervision, en construisant en
parall&#232;le deux classifieurs utilisant des ensembles disjoints d&#8217;attributs.
</p>
<p>3 Description du syst&#232;me d&#8217;apprentissage de paraphrases
</p>
<p>3.1 Fonctionnement global du syst&#232;me
</p>
<p>Notre algorithme d&#8217;inf&#233;rence de paraphrases commence son apprentissage &#224; partir d&#8217;un unique
exemple positif et utilise un m&#233;canisme de bootstrapping &#224; deux niveaux. Cet exemple de d&#233;-
part est, par exemple, une r&#233;ponse automatiquement calcul&#233;e par notre syst&#232;me de Questions-
R&#233;ponses. Dans notre mod&#232;le, un exemple est repr&#233;sent&#233; comme l&#8217;association d&#8217;une for-
mulation linguistique
</p>
<p>&#0;
</p>
<p>d&#8217;un pr&#233;dicat avec son couple d&#8217;arguments &#1; . Par exemple, la re-
lation d&#8217;auteur pourrait &#234;tre repr&#233;sent&#233;e ainsi :
</p>
<p>&#0;
</p>
<p>=&#8221;&#234;tre l&#8217;auteur de&#8221;, &#1; =(&#8221;Melville&#8221;, &#8221;Moby
Dick&#8221;). L&#8217;identification des paraphrases repose sur un mod&#232;le de d&#233;cision probabiliste dont
les param&#232;tres sont estim&#233;s de mani&#232;re presque non supervis&#233;e. L&#8217;estimation repose sur un
algorithme de clustering fond&#233; sur l&#8217;algorithme EM (voir la Section 3.2): il prend en entr&#233;e
une matrice contenant les fr&#233;quences de cooccurrence d&#8217;un ensemble de formulations &#2; et des
couples d&#8217;arguments correspondants &#3; , mesur&#233;es dans le corpus &#4; .
</p>
<p>Notre corpus initial &#4;&#6;&#5; contient un unique exemple de d&#233;part exprimant la relation s&#233;mantique
vis&#233;e, repr&#233;sent&#233; comme la cooccurrence d&#8217;une formulation
</p>
<p>&#0;
</p>
<p>&#5; et d&#8217;un couple d&#8217;arguments &#1;&#7;&#5; .
Avec ces donn&#233;es de d&#233;part, nous souhaitons construire un nouveau corpus &#4; contenant poten-
tiellement beaucoup plus d&#8217;exemples de la relation s&#233;mantique vis&#233;e. Cette t&#226;che est r&#233;alis&#233;e en
utilisant ind&#233;pendemment
</p>
<p>&#0;
</p>
<p>&#5; et &#1;&#8;&#5; pour formuler des requ&#234;tes sur le Web. Les documents trou-
v&#233;s sont parcourus pour y trouver de nouvelles formulations et paires d&#8217;arguments int&#233;ressantes,
qui sont utilis&#233;es successivement pour produire de nouvelles requ&#234;tes, ces derni&#232;res &#233;tant &#224; leur
tour utilis&#233;es pour extraire plus d&#8217;arguments et de formulations... Durant cette &#233;tape, nous avons
donc besoin de (i) g&#233;n&#233;rer des requ&#234;tes et traiter les documents trouv&#233;s afin de (ii) extraire de
nouvelles formulations et de nouveaux couples d&#8217;arguments. De plus amples d&#233;tails concernant
ces proc&#233;dures sont donn&#233;s dans la Section 3.3.
</p>
<p>La qualit&#233; des paraphrases extraites d&#233;pend beaucoup de notre capacit&#233; &#224; maintenir le corpus
suffisamment focalis&#233; sur la relation s&#233;mantique vis&#233;e: pour ce faire, les phases d&#8217;acquisition
sont entrecoup&#233;es d&#8217;&#233;tapes de filtrage reposant sur notre clustering &#224; base d&#8217;EM. Le filtrage
est en effet une &#233;tape cruciale pour assurer la convergence de cette proc&#233;dure. L&#8217;architecture
globale de notre syst&#232;me est repr&#233;sent&#233;e sur la figure 1.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Apprentissage Automatique de Paraphrases
</p>
<p>Extracteur de formulations&#13; Extracteur d'arguments&#13;
</p>
<p>Phrase 1&#13;
</p>
<p>...&#13;
</p>
<p>Phrase k&#13;
</p>
<p>Requ&#234;te 1&#13;
</p>
<p>...&#13;
</p>
<p>Requ&#234;te k&#13;
</p>
<p>Phrase 1&#13;
</p>
<p>...&#13;
</p>
<p>Phrase l&#13;
</p>
<p>Requ&#234;te 1&#13;
</p>
<p>...&#13;
</p>
<p>Requ&#234;te l&#13;
</p>
<p>Ens. de tuples&#13;
d'argument&#13;
{a&#13;1&#13;, ..., a&#13;k&#13;}&#13;
</p>
<p>Ens. de&#13;
formulations&#13;
</p>
<p>{f&#13;1&#13;, ...,f&#13; j&#13;}&#13;
</p>
<p>Phrase&#13;
initiale&#13;
</p>
<p>ETAPE D'ACQUISITION&#13;
</p>
<p>E&#13;
T&#13;
A&#13;
P&#13;
E&#13;
</p>
<p>D&#13;
E&#13;
</p>
<p>F&#13;
I&#13;
L&#13;
T&#13;
R&#13;
A&#13;
G&#13;
E&#13;
</p>
<p>Figure 1: Syst&#232;me d&#8217;apprentissage automatique de paraphrases
</p>
<p>3.2 Filtrage par l&#8217;algorithme d&#8217;Estimation-Maximisation
</p>
<p>Le filtrage consiste &#224; distinguer les paraphrases valides de la relation s&#233;mantique de d&#233;part des
paraphrases qui sont incorrectes. Ce filtrage intervient &#224; deux endroits de notre m&#233;canisme
d&#8217;apprentissage: (i) pour identifier les formulations qui vont d&#233;clencher une nouvelle s&#233;rie de
requ&#234;tes et donc une nouvelle it&#233;ration; (ii) pour s&#233;lectionner les paraphrases qui seront fi-
nalement conserv&#233;es (voir la Figure 1). Cette &#233;tape revient &#224; classifier chaque formulation du
corpus comme 1 (paraphrase valide) ou 0 (paraphrase invalide), en se basant sur des donn&#233;es
de cooccurrence entre couples d&#8217;arguments et formulations. Ce probl&#232;me de partitionnement
en 2 classes est faiblement supervis&#233; car nous ne disposons initialement que d&#8217;un seul exem-
ple &#233;tiquet&#233; (positif): la formulation de d&#233;part. Il est possible d&#8217;utiliser pour ce probl&#232;me des
algorithmes de clustering utilisant des des donn&#233;es de cooccurrence de type EM (Hofmann &amp;
Puzicha, 1998). Nous consid&#233;rons donc que chaque phrase (consistant en une formulation &#0; et
ses arguments &#1; ) est g&#233;n&#233;r&#233;e par le mod&#232;le stochastique suivant:
</p>
<p>&#9;&#11;&#10;
</p>
<p>&#0;&#13;&#12;
</p>
<p>&#1;&#15;&#14;&#17;&#16; &#18;&#6;&#19;&#21;&#20;&#23;&#22;
</p>
<p>&#9;&#24;&#10;
</p>
<p>&#0;&#25;&#12;
</p>
<p>&#1;ff&#26;flfiffi&#14;
</p>
<p>&#9;&#24;&#10;
</p>
<p>fi&#31;&#14; (1)
&#16; &#18;&#6;&#19;&#21;&#20;&#23;&#22;
</p>
<p>&#9;&#24;&#10;
</p>
<p>&#0;
</p>
<p>&#26;flfiffi&#14;
</p>
<p>&#9;&#11;&#10;
</p>
<p>&#1;ff&#26; fi&#31;&#14;
</p>
<p>&#9;&#24;&#10;
</p>
<p>fiffi&#14; (2)
</p>
<p>o&#249; ! est l&#8217;ensemble des relations s&#233;mantiques exprim&#233;es par des phrases de notre corpus. Nous
consid&#233;rons &#233;galement que notre corpus ne contient que deux relations s&#233;mantiques, dont les
valeurs sont soit !&quot;&#16; # , signifiant qu&#8217;une phrase donn&#233;e exprime la m&#234;me relation s&#233;man-
tique que la phrase de d&#233;part, soit !$&#16;&amp;% , signifiant que la phrase exprime une autre relation
s&#233;mantique (non sp&#233;cifi&#233;e). &#201;tant donn&#233; ce mod&#232;le, les formules de r&#233;estimation se d&#233;rivent
facilement (Hofmann &amp; Puzicha, 1998). Elles sont pr&#233;sent&#233;es dans la Table 1, o&#249; ' &#10; &#14; d&#233;note
la fonction de comptage.
</p>
<p>Ce mod&#232;le nous permet d&#8217;incorporer des connaissances durant la phase d&#8217;initialisation, o&#249; nous
utilisons les valeurs suivantes : &#9;&#24;&#10; !(&#16; #)&#26;
</p>
<p>&#0;
</p>
<p>&#5;
</p>
<p>&#12;
</p>
<p>&#1;*&#5;+&#14;,&#16; # et
&#9;&#24;&#10;
</p>
<p>!(&#16; #)&#26;
</p>
<p>&#0;
</p>
<p>&#5;
</p>
<p>&#12;
</p>
<p>&#1;&#15;&#14;,&#16; %)-/.
</p>
<p>&#12;10
</p>
<p>&#1;&amp;2&#16; &#1;*&#5;
</p>
<p>dans l&#8217;&#233;quation (3). Toutes les autres valeurs de &#9;&#24;&#10; !3&#26; &#2; &#12; &#3;4&#14; sont &#233;gales &#224; %)-65 . EM est ensuite</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florence Duclaye, Olivier Collin, Fran&#231;ois Yvon
</p>
<p>E-Step
&#9;&#11;&#10;
</p>
<p>fi)&#26;
</p>
<p>&#0;&#13;&#12;
</p>
<p>&#1;&#15;&#14;7&#16;
</p>
<p>&#9;&#11;&#10;
</p>
<p>fiffi&#14;
</p>
<p>&#9;&#24;&#10;
</p>
<p>&#0;
</p>
<p>&#26;flfiffi&#14;
</p>
<p>&#9;&#11;&#10;
</p>
<p>&#1;ff&#26; fi&#31;&#14;
</p>
<p>8
</p>
<p>&#5;
</p>
<p>&#9;&#24;&#10;
</p>
<p>fi&#23;&#5;9&#14;
</p>
<p>&#9;&#11;&#10;
</p>
<p>&#0;
</p>
<p>&#26;flfi:&#5;;&#14;
</p>
<p>&#9;&#24;&#10;
</p>
<p>&#1;ff&#26;flfi:&#5;+&#14;
</p>
<p>(3)
</p>
<p>M-Step
</p>
<p>&#9;&#11;&#10;
</p>
<p>&#1;ff&#26; fi&#31;&#14;&#17;&#16;
</p>
<p>8=&lt;
</p>
<p>&#20;:&gt;
</p>
<p>'
</p>
<p>&#10;
</p>
<p>&#0;&#25;&#12;
</p>
<p>&#1;&#15;&#14;
</p>
<p>&#9;&#11;&#10;
</p>
<p>fi)&#26;
</p>
<p>&#0;&#25;&#12;
</p>
<p>&#1;&#15;&#14;
</p>
<p>8=?
</p>
<p>&#20;&#23;@
</p>
<p>8=&lt;
</p>
<p>&#20;&#23;&gt;
</p>
<p>'
</p>
<p>&#10;
</p>
<p>&#0;&#25;&#12;
</p>
<p>&#1;A&#14;
</p>
<p>&#9;&#24;&#10;
</p>
<p>fi)&#26;
</p>
<p>&#0;&#25;&#12;
</p>
<p>&#1;A&#14;
</p>
<p>(4)
&#9;&#11;&#10;
</p>
<p>&#0;
</p>
<p>&#26; fi&#31;&#14;&#17;&#16;
</p>
<p>8B?
</p>
<p>&#20;&#23;@
</p>
<p>'
</p>
<p>&#10;
</p>
<p>&#0;&#13;&#12;
</p>
<p>&#1;&#15;&#14;
</p>
<p>&#9;&#11;&#10;
</p>
<p>fi)&#26;
</p>
<p>&#0;&#13;&#12;
</p>
<p>&#1;&#15;&#14;
</p>
<p>8 &lt;
</p>
<p>&#20;:&gt;
</p>
<p>8 ?
</p>
<p>&#20;:@
</p>
<p>'
</p>
<p>&#10;
</p>
<p>&#0;&#25;&#12;
</p>
<p>&#1;A&#14;
</p>
<p>&#9;&#24;&#10;
</p>
<p>fi)&#26;
</p>
<p>&#0;&#25;&#12;
</p>
<p>&#1;A&#14;
</p>
<p>(5)
&#9;&#24;&#10;
</p>
<p>fi&#31;&#14;&#17;&#16;
</p>
<p>8 &lt;
</p>
<p>&#20;:&gt;
</p>
<p>8 ?
</p>
<p>&#20;:@
</p>
<p>'
</p>
<p>&#10;
</p>
<p>&#0;&#25;&#12;
</p>
<p>&#1;A&#14;
</p>
<p>&#9;&#24;&#10;
</p>
<p>fi)&#26;
</p>
<p>&#0;&#25;&#12;
</p>
<p>&#1;A&#14;
</p>
<p>8 &lt;
</p>
<p>&#20;&#23;&gt;
</p>
<p>8 ?
</p>
<p>&#20;:@
</p>
<p>'
</p>
<p>&#10;
</p>
<p>&#0;&#25;&#12;
</p>
<p>&#1;&#15;&#14;
</p>
<p>(6)
</p>
<p>Table 1: Formules de r&#233;estimation pour EM
</p>
<p>lanc&#233; jusqu&#8217;&#224; convergence des param&#232;tres maximis&#233;s. Dans notre cas, cette convergence est
g&#233;n&#233;ralement atteinte au bout de #C% it&#233;rations.
</p>
<p>Une fois les param&#232;tres appris, nous utilisons ce mod&#232;le pour d&#233;cider si une formulation
&#0;
</p>
<p>est
une paraphrase valide en nous basant sur le rapport entre &#9;&#24;&#10; !D&#16;E#)&#26;
</p>
<p>&#0;
</p>
<p>&#14; et
&#9;&#24;&#10;
</p>
<p>!F&#16;G%H&#26;
</p>
<p>&#0;
</p>
<p>&#14; , calcul&#233;
comme suit: IJ&#16;LKNM &#22;&#31;OHPRQ KNM
</p>
<p>&lt;CS
</p>
<p>&#22;&#31;OHPRQ
</p>
<p>KNM
</p>
<p>&#22;&#31;OUT&#21;Q
</p>
<p>KNM
</p>
<p>&lt;CS
</p>
<p>&#22;&#31;OUT&#21;Q
</p>
<p>. &#201;tant donn&#233; que &#9;&#24;&#10; !V&#16;&#17;#ffi&#14; est fortement sur-estim&#233;e dans
notre corpus (qui est pr&#233;cis&#233;ment focalis&#233; autour de tels exemples), la r&#232;gle de d&#233;cision utilis&#233;e
impose que ce rapport soit sup&#233;rieur &#224; un seuil pr&#233;-d&#233;fini WYXZX[# . De mani&#232;re alternative, nous
avons &#233;galement consid&#233;r&#233; des sc&#233;narios dans lesquels ces probabilit&#233;s ne servent qu&#8217;&#224; ordonner
les candidats paraphrases, que ce soit pendant les diff&#233;rentes &#233;tapes de filtrage ou m&#234;me lors
de la d&#233;cision finale. Ceci rendant finalement notre approche moins d&#233;pendante de la validit&#233;
des hypoth&#232;ses sous-jacentes au mod&#232;le probabiliste utilis&#233;, dont certaines sont discutables:en
particulier &#224; la condition d&#8217;ind&#233;pendance exprim&#233;e en 2, ou encore l&#8217;hypoth&#232;se que seules deux
relations s&#233;mantiques sont repr&#233;sent&#233;es dans notre corpus.
</p>
<p>3.3 Proc&#233;dure d&#8217;acquisition automatique
</p>
<p>L&#8217;outil utilis&#233; pour la phase d&#8217;acquisition est un syst&#232;me de Questions-R&#233;ponses, fonctionnant
ici comme un outil d&#8217;extraction d&#8217;informations. Ce syst&#232;me est constitu&#233; de deux composants
principaux: le premier transforme une question en entr&#233;e en une requ&#234;te sur le Web et d&#233;clenche
la recherche; le second analyse les pages retourn&#233;es (plus pr&#233;cis&#233;ment les extraits de page)
et y cherche des r&#233;ponses potentielles, par appariemment de patrons d&#8217;extraction pr&#233;-d&#233;finis.
La requ&#234;te et les patrons d&#8217;extraction sont d&#233;riv&#233;s de la question de d&#233;part &#224; l&#8217;aide de r&#232;gles.
Les d&#233;tails concernant ce syst&#232;me de QA et les proc&#233;dures d&#8217;analyse linguistique impliqu&#233;s
&#224; chaque &#233;tape du traitement sont donn&#233;s dans (Duclaye et al., 2002). En mode &#8220;extraction
d&#8217;information&#8221;, l&#8217;&#233;tape de construction de requ&#234;te est supprim&#233;e, la requ&#234;te &#233;tant d&#233;duite des
couples d&#8217;arguments (ou de formulations). La phase d&#8217;analyse utilise des patrons d&#8217;extraction
tr&#232;s g&#233;n&#233;raux, construits &#224; partir des arguments (ou formulations) en cours de traitement. Sup-
posons, par exemple, que nous recherchons des paraphrases, la paire d&#8217;arguments courante &#233;tant
&#233;gale &#224; [&#8220;Melville&#8221;, &#8221;Moby Dick&#8221;]. Ces arguments seront tous deux utilis&#233;s comme mots-cl&#233;s,
et deux patrons d&#8217;extraction sont utilis&#233;s pour faire les extractions dans les documents trou-
v&#233;s : &#8220;Melville [verb] Moby Dick&#8221; et &#8220;Moby Dick [verb] Melville&#8221;. Dans cet exemple, il est</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Apprentissage Automatique de Paraphrases
</p>
<p>n&#233;cessaire qu&#8217;un verbe appara&#238;sse entre les deux mots-cl&#233;s pour &#234;tre extrait. Ce verbe sera
consid&#233;r&#233; comme une paraphrase potentielle de la formulation de d&#233;part. Pour chaque requ&#234;te,
seuls les ' premiers documents retourn&#233;s par le moteur de recherche sont pris en compte. Les
paires (arguments, formulations) ainsi extraites sont accumul&#233;es, it&#233;ration apr&#232;s it&#233;ration, pour
constituer un corpus sur lequel des statistiques utilis&#233;es lors du filtrage sont calcul&#233;es. Ce pro-
cessus it&#233;ratif d&#8217;acquisition de formulations et de couples d&#8217;arguments, combin&#233; avec celui de
validation/filtrage, converge et se termine quand aucune nouvelle formulation n&#8217;est trouv&#233;e.
</p>
<p>4 R&#233;sultats exp&#233;rimentaux
</p>
<p>Les exp&#233;riences d&#233;crites dans cette section ont &#233;t&#233; r&#233;alis&#233;es sur 18 phrases initiales, repr&#233;sentant
12 relations s&#233;mantiques diff&#233;rentes. La Table 2 pr&#233;sente quelques exemples de relations, ainsi
que les formulations et couples d&#8217;arguments choisis. Pour chacune de ces phrases, la proc&#233;dure
d&#8217;apprentissage d&#233;crite &#224; la Section 3 a &#233;t&#233; lanc&#233;e sur une it&#233;ration. Les r&#233;sultats pr&#233;sent&#233;s ici
ont &#233;t&#233; obtenus en prenant les ' =1000 premiers r&#233;sum&#233;s retourn&#233;s par le moteur de recherche.
</p>
<p>achat de &quot;acheter&quot; AOL; Netscape
auteur de &quot;&#233;crire&quot; Melville; Moby Dick
inventeur de &quot;inventer&quot; Gutenberg; imprimerie
assassinat de &quot;assassiner&quot; Oswald; Kennedy
</p>
<p>Table 2: Exemples de relations avec leurs formulations et couples d&#8217;arguments
</p>
<p>Les paraphrases extraites ont &#233;t&#233; v&#233;rifi&#233;es manuellement et class&#233;es comme valides ou invalides.
Dans cette application, le succ&#232;s peut &#234;tre mesur&#233; comme la pr&#233;cision moyenne des paraphrases
extraites, qui devraient &#224; terme &#234;tre ajout&#233;es au syst&#232;me de Questions-R&#233;ponses. Le rappel, par
contre, n&#8217;est pas important car nous souhaitons simplement trouver les paraphrases les plus
fr&#233;quentes. Le taux de s&#233;lection repr&#233;sente le pourcentage de formulations class&#233;es comme
valides par notre syst&#232;me. Rappelons que la d&#233;cision de classer une formulation comme une
paraphrase valide ou invalide est bas&#233;e sur le rapport entre \+]ffi^ &#10;R&#9;&#11;&#10; !G&#16;L#)&#26;
</p>
<p>&#0;
</p>
<p>&#14;_&#14; et \+]ffi^
&#10;R&#9;&#11;&#10;
</p>
<p>!G&#16;
</p>
<p>%H&#26;
</p>
<p>&#0;
</p>
<p>&#14;_&#14; , appel&#233; W . Les taux de s&#233;lection et les r&#233;sultats de pr&#233;cision pour diff&#233;rentes valeurs de W
sont donn&#233;s dans la Table 3.
</p>
<p>W 7 25 48 117 186 232
Taux de s&#233;lection 44.0% 29.8% 23.9% 14.2% 10% 9.4%
Pr&#233;cision 42.9% 47.3% 47.3% 54.9% 66.6% 65.4%
</p>
<p>Table 3: R&#233;sultats exp&#233;rimentaux
</p>
<p>Dans ces exp&#233;rimentations, la meilleure pr&#233;cision moyenne atteinte est de 66.6%, quand W`&#16;
#Ca*. . Effectu&#233;es sur plusieurs relations s&#233;mantiques, ces exp&#233;rimentations ont montr&#233; que le taux
de pr&#233;cision peut varier de mani&#232;re importante d&#8217;une relation s&#233;mantique &#224; une autre: il peut
atteindre 100% pour certaines relations, et descendre jusqu&#8217;&#224; 6% pour d&#8217;autres. Ces r&#233;sultats
peuvent para&#238;tre faibles. Cela est d&#251; en partie &#224; la quantit&#233; variable de donn&#233;es extraites du
Web pour les relations s&#233;mantiques. Le fait d&#8217;appliquer le m&#234;me seuil W &#224; toutes les relations
s&#233;mantiques n&#8217;est certainement pas la meilleure m&#233;thode. De plus, la majorit&#233; des formulations</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florence Duclaye, Olivier Collin, Fran&#231;ois Yvon
</p>
<p>class&#233;es &#224; tort comme de bonnes paraphrases sont th&#233;matiquement li&#233;es &#224; la formulation de
d&#233;part et ne peuvent donc &#234;tre consid&#233;r&#233;es comme totalement mauvaises.
</p>
<p>Comme indiqu&#233; dans la Table 3, l&#8217;augmentation des valeurs de W provoque la diminution du taux
de s&#233;lection et l&#8217;augmentation de la pr&#233;cision. La tendance g&#233;n&#233;rale est que plus W augmente,
plus la quantit&#233; de formulations class&#233;es comme mauvaises paraphrases augmente, de sorte que
finalement, seule la formulation de d&#233;part est conserv&#233;e comme valide. Augmenter W n&#8217;est donc
pas suffisant pour am&#233;liorer la pr&#233;cicion moyenne des paraphrases extraites. Il est n&#233;cessaire de
trouver un &#233;quilibre entre le taux de s&#233;lection et la pr&#233;cision des paraphrases extraites.
</p>
<p>Une autre strat&#233;gie de filtrage consiste &#224; conserver les b meilleures formulations &#224; chaque it&#233;ra-
tion ( bc&#16;d5 &#12; #C% &#12; -e-f- ). La Table 4 porte sur la premi&#232;re it&#233;ration de la relation d&#8217;achat et compare
les taux de pr&#233;cision obtenus pour diff&#233;rents seuils de b . La deuxi&#232;me colonne repr&#233;sente les
taux de pr&#233;cision dans l&#8217;ensemble (de taille b ) des formulations class&#233;es comme paraphrases
valides. La troisi&#232;me colonne repr&#233;sente les taux de pr&#233;cision dans l&#8217;ensemble (de taille tou-
jours b ) des formulations class&#233;es comme paraphrases invalides. Il est int&#233;ressant de noter
que les formulations class&#233;es comme paraphrases invalides ont globalement une meilleure pr&#233;-
cision que celles class&#233;es comme valides. Dans de prochaines exp&#233;rimentations, on pourrait
envisager d&#8217;utiliser ces formulations class&#233;es comme paraphrases invalides comme exemples
n&#233;gatifs d&#8217;apprentissage.
</p>
<p>Formu. class&#233;es en paraph. valides Formu. class&#233;es en paraph. invalides
Classe enti&#232;re 39.6% 85.2%
b =5 60% 80%
b =10 80% 80%
b =15 73.3% 73.3%
</p>
<p>Table 4: Taux de pr&#233;cision en fonction de k, pour la relation d&#8217;achat
</p>
<p>Des exp&#233;riences compl&#233;mentaires ont &#233;t&#233; conduites sur plusieurs it&#233;rations, en ne conservant
que les b =5 meilleures formulations &#224; chaque it&#233;ration. La Table 5 montre les r&#233;sultats obtenus
pour la relation d&#8217;achat, apr&#232;s cinq it&#233;rations d&#8217;apprentissage. On note que la pr&#233;cision aug-
mente entre la premi&#232;re (60%) et la cinqui&#232;me (80%) it&#233;ration. Des exp&#233;riences similaires sont
en cours pour d&#8217;autres relations s&#233;mantiques.
</p>
<p>It&#233;ration. Formulations class&#233;es comme paraphrases valides
# racheter, acqu&#233;rir, acheter, utiliser, recevoir
g
</p>
<p>racheter, acqu&#233;rir, acheter, reprendre, absorber
h
</p>
<p>racheter, acheter, acqu&#233;rir, qui racheter, devenir
i
</p>
<p>racheter, acheter, acqu&#233;rir, absorber, grouper
5 racheter, acheter, reprendre, devenir, acqu&#233;rir
</p>
<p>Table 5: R&#233;sultats sur cinq it&#233;rations d&#8217;apprentissage pour la relation s&#233;mantique d&#8217;achat
</p>
<p>5 Conclusions et perspectives
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; une m&#233;thodologie faiblement supervis&#233;e pour l&#8217;apprentissage
automatique de paraphrases, commen&#231;ant avec un unique exemple positif d&#8217;apprentissage. En</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Apprentissage Automatique de Paraphrases
</p>
<p>utilisant une strat&#233;gie de validation bas&#233;e sur l&#8217;algorithme EM, nous pouvons filtrer les para-
phrases potentielles invalides extraites durant les phases d&#8217;acquisition. Non seulement ces para-
phrases sont utiles pour am&#233;liorer les r&#233;sultats de notre syst&#232;me de Questions-R&#233;ponses, mais
les couples d&#8217;arguments acquis pourraient &#233;galement &#234;tre utilis&#233;s pour d&#8217;autres besoins que
l&#8217;apprentissage de paraphrases, comme la construction de lexiques s&#233;mantiques. Dans cette
optique, l&#8217;&#233;tape de filtrage pourrait aussi bien &#234;tre appliqu&#233;e aux couples d&#8217;arguments acquis.
</p>
<p>Au-del&#224; de r&#233;sultats exp&#233;rimentaux prometteurs, obtenus dans un sc&#233;nario relativement simple,
de nombreuses am&#233;liorations portant sur les phases d&#8217;acquisition et de validation sont actuelle-
ment envisag&#233;es. Concernant l&#8217;&#233;tape de filtrage, les d&#233;veloppements concernent principalement
(i) une variante consistant &#224; conserver des informations sur les valeurs des param&#232;tres du mod&#232;le
stochastique entre deux &#233;tapes successives de filtrage; (ii) l&#8217;utilisation de strat&#233;gies incr&#233;men-
tales les paraphrases potentielles qui seront utilis&#233;es dans de nouvelles requ&#234;tes pour augmenter
le corpus d&#8217;exemples; (iii) l&#8217;utilisation d&#8217;autres algorithmes de filtrages, exploitant des prox-
imit&#233;s distributionnelles entre la formulation d&#8217;origine et les autres formulations trouv&#233;es sur
Internet. Le but recherch&#233; &#233;tant d&#8217;obtenir un maximum d&#8217;exemples diff&#233;rents, tout en gardant
le corpus en expansion suffisamment focalis&#233; sur la relation s&#233;mantique en cours d&#8217;examen.
</p>
<p>Concernant la phase d&#8217;acquisition, nous projetons d&#8217;apprendre des paraphrases multilingues,
ainsi que des structures plus complexes de formulations (comme les nominalisations). Nous
projetons &#233;galement d&#8217;utiliser des informations de contexte automatiquement apprises, afin
d&#8217;am&#233;liorer la qualit&#233; des requ&#234;tes soumises au moteur de recherche: l&#8217;id&#233;e est d&#8217;extraire, dans
le voisinage lexical des paraphrases identifi&#233;es comme valides, des termes discriminant per-
mettant (i) de raffiner et/ou de varier les requ&#234;tes et (ii) de qualifier plus finement le contexte
(th&#233;matique) dans lequel les relations de paraphrases sont valides. Il appara&#238;t en effet clairement
que de nombreuses relations de paraphrases de valent que dans un contexte bien d&#233;fini, qu&#8217;il est
essentiel de pouvoir d&#233;crire.
</p>
<p>Bas&#233; sur une strat&#233;gie d&#8217;apprentissage ind&#233;pendante de la langue, notre syst&#232;me d&#8217;apprentissage
de paraphrases sera int&#233;gr&#233; au syst&#232;me de Questions-R&#233;ponses. Notre syst&#232;me fonctionnera
alors comme un composant ind&#233;pendant du module de QA et apprendra des paraphrases &#224; par-
tir des r&#233;ponses fournies par le syst&#232;me de QA. Son int&#233;gration ne n&#233;cessite en fait que peu
de d&#233;veloppements nouveaux, dans la mesure o&#249; notre syst&#232;me de Questions-R&#233;ponses int&#232;gre
d&#233;j&#224; des r&#232;gles de paraphrasage entr&#233;es manuellement. Il ne s&#8217;agit donc que d&#8217;automatiser ce
processus d&#8217;ajout de r&#232;gles de paraphrasage des questions et des r&#233;ponses. Ceci nous perme-
ttra d&#8217;&#233;valuer dans un contexte applicatif notre m&#233;thodologie et de mesurer les am&#233;liorations
apport&#233;es par les paraphrases extraites.
</p>
<p>R&#233;f&#233;rences
AKIRA T. &amp; TAKENOBU T. (2002). Automatic disabbreviation by using context information. In Pro-
ceedings of the NLPRS Workshop on Automatic Paraphrasing : Theories and Applications.
BARZILAY R. &amp; MCKEOWN K. R. (2001). Extracting paraphrases from a parallel corpus. In Proceed-
ing of the 39th Annual Meeting of the Association for Computational Linguistics, p. 50&#8211;57, Toulouse.
BRIN S. (1998). Extracting patterns and relations from the world wide web. In Proceedings of WebDB
Workshop at EDBT.
COLLINS M. &amp; SINGER Y. (1999). Unsupervised models for named entity classification. In Proceed-
ings of the Workshop on Empirical Methods for Natural Language Processing.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florence Duclaye, Olivier Collin, Fran&#231;ois Yvon
</p>
<p>DUCLAYE F., FILOCHE P., SITKO J. &amp; COLLIN O. (2002). A polish question-answering system for
business information. In Proceedings of the Business Information Systems Conference, Poznan.
FUCHS C. (1982). La Paraphrase. Presses Universitaires de France.
GREFENSTETTE G. (1994). Explorations in Automatic Thesaurus Discovery. Boston: Kluwer Aca-
demic Publishers.
</p>
<p>HABERT B., NAZARENKO A. &amp; SALEM A. (1997). Les linguistiques de corpus. Armand Colin, Paris.
HOFMANN T. &amp; PUZICHA J. (1998). Statistical Models for Co-occurrence Data. Rapport interne AI.
1625, MIT, AI Lab.
KUROHASHI S. &amp; SAKAI Y. (1999). Semantic analysis of japanese noun phrases : a new approach
to dictionary-based understanding. In Proceedings of the 37th Annual Meeting of the Association for
Computational Linguistics, p. 481&#8211;488.
LIN D. &amp; PANTEL P. (2001). Discovery of inference rules for question-answering. In Natural Language
Engineering, volume 7, p. 343&#8211;360.
MILLER G., BECKWITH R., FELLBAUM C., GROSS D. &amp; MILLER K. (1990). Introduction to wordnet:
An on-line lexical database. In Journal of Lexicography, volume 3, p. 234&#8211;244.
RILOFF E. &amp; JONES R. (1999). Learning dictionaries for information extraction by multi-level boot-
strapping. In Proceedings of the 16th National Conference on Artificial Intelligence.
TORISAWA K. (2001). A nearly unsupervised learning method for automatic paraphrasing of japanese
noun phrases. In Proceedings of the NLPRS 2002 workshop on Automatic Paraphrasing : Theories and
Applications, Tokyo.
VOORHEES E. (1999). The TREC-8 question answering track report. In Proceedings of TREC-8.</p>

</div></div>
</body></html>