TALN 2003, Batz-sur-Mer, 11—14juin 2003

Apprentissage Automatique de Paraphrases pour
l’Amélioration d’un Systéme de Questions-Réponses

Florence Duclaye (1 et 2), Olivier Collin (1), Francois Yvon (2)
(1) France Télécom R&D
2 avenue Pierre Marzin
22307 Lannion Cedex
{ﬂorence.duclaye,olivier.collin} @rd.francetelecom.fr
(2) GET/ENST et LTCI, CNRS URA 820
46 rue Barrault

75624 Paris Cedex 13

{fduclaye,yvon} @enst.fr

Mots-clefs — Keywords

Questions-Réponses, Apprentissage Automatique, Acquisition de Paraphrase
Question Answering, Machine Learning, Paraphrase extraction

Résumé - Abstract

Dans cet article, nous présentons une méthodologie d’apprentissage faiblement supervisé pour
l’extraction automatique de paraphrases a partir du Web. A partir d’un seule exemple de paire
(prédicat, arguments), un corpus est progressivement accumulé par sondage du Web. Les phases
de sondage alternent avec des phases de ﬁltrage, durant lesquelles les paraphrases les moins
plausibles sont éliminées a l’aide d’une procédure de clustering non supervisée. Ce mécanisme
d’apprentissage s’appuie sur un systeme de Questions-Réponses existant et les paraphrases ap-
prises seront utilisées pour en améliorer le rappel. Nous nous concentrons ici sur le mécanisme
d’apprentissage de ce systeme et en présentons les premiers résultats.

In this paper, we present a nearly unsupervised learning methodology for automatically extract-
ing paraphrases from the Web. Starting with one single instance of a pair (predicate,arguments),
a corpus is incrementally built by sampling the Web. Sampling stages alternate with ﬁlter-
ingstages, during which implausible paraphrases are ﬁltered out using an EM-based unsuper-
vised clustering procedure. This learning machinery is built on top of an existing question-
answering system and the learnt paraphrases will eventually be used to improve its recall. We
focus here on the learning aspect of this system and report preliminary results.

Florence Duclaye, Olivier Collin, Francois Yvon

1 Introduction

Les systemes de Questions-Reponses (Voorhees, 1999) necessitent des outils efﬁcaces et so-
phistiques de traitement automatique des langues, capables de traiter la variabilite linguistique
des questions et des reponses: une meme signiﬁcation peut, en effet, etre vehiculee par de multi-
ples structures lexico-syntaxiques. Cette variabilite est une source de difﬁcultes dans la plupart
des applications de traitement automatique des langues.

Cette variabilite se manifeste au niveau syntaxique, o1‘1 elle prend, par exemple, la forme de
transformations regulieres de la voix actice a la voix passive. Un traitement plus systematique de
ce phenomene necessite neanmoins des connaissances semantiques, comme celles disponibles
dans des reseaux semantiques (Miller et al., 1990). Le beneﬁce de telles ressources est toute-
fois limite car (i) les relations de synonymie qu’elles contiennent sont deﬁnies hors de tout
contexte d’usage; (ii) la synonymie implique une notion de la paraphrase qui est beaucoup trop
restreinte pour l’application visee. La reponse a une question est en effet souvent exprimee
a l’aide de termes qui ne sont que faiblement (par ex. metaphoriquement) lies a ceux de la
question. Ainsi l’expression “X a cause Y” peut étre consideree comme semantiquement simi-
laire a “la responsabilite de Y est attribuee a X” dans le contexte des Questions-Reponses (Lin
& Pantel, 2001). Au lieu d’essayer de completer manuellement ces ressources statiques, nous
avons choisi d’exploiter les avantages d’une approche fondee sur des corpus et d’apprendre
de telles equivalences de maniere automatique. Nous utilisons le terme de paraphrase pour
faire reference a ces relations, bien que la deﬁnition du terme adoptee ici soit surtout focalisee
sur deux types de phenomenes linguistiques : les paraphrases linguistiques et les derivations
semantiques. (Fuchs, 1982) decrit les paraphrases comme des phrases dont le sens linguis-
tique denotatif est equivalent. Les derivations semantiques sont des phrases dont le sens est
preserve mais dont la structure lexico-syntaxique est differente (ex : AOL a achete Netscape /
1’acquisition de Netscape par AOL). Le corpus utilise pour acquerir les paraphrases est le Web.
Cette utilisation du Web comme corpus offre plusieurs avantages (Grefenstette, 1994). (i) Les
informations qu’il contient sont d’une grande variete et d’une grande redondance, une meme
information pouvant apparaitre sous de multiples formes. Notre algorithme d’apprentissage re-
pose fortement sur cette propriete. (ii) Le Web contient des informations contextuelles pouvant
contraindre la portee de la relation de paraphrase. En outre, comme notre systeme de Questions-
Reponses utilise le Web comme unique source d’information, il est important d’extraire les
formulations d’un concept qui sont les plus frequemment utilisees sur le Web. Cette strategie
n’est pas sans difﬁcultes: la reduction du niveau de bruit dans les donnees extraites est en par-
ticulier un probleme important. Le mecanisme d’apprentissage que nous proposons est capable
d’acquerir automatiquement de multiples formulations d’une relation semantique donnee a par-
tir d’un seul exemple. Cette donnee de depart consiste en un exemple de la relation semantique
visee, o1‘1 l’expression linguistique (formulation) de la relation et le couple d’arguments ont tous
deux ete identiﬁes. Ce type de donnees est directement foumi par notre systeme de Questions-
Reponses, mais il est egalement largement disponible dans les dictionnaires. Etant donne cet
exemple positif, notre mecanisme d’apprentissage envoie de maniere repetitive des requétes sur
le Web et utilise alternativement les formulations connues pour acquerir des nouveaux couples
d’arguments, et les couples d’arguments connus pour trouver de nouvelles formulations. Ce
mecanisme se decompose en deux etapes: d’une part la recherche de paraphrases potentielles
de la relation semantique et d’autre part la validation de ces paraphrases en se basant sur des
comptages de frequences et sur l’algorithme d’Estimation-Maximisation (EM).

Cet article presente a la Section 2 les travaux techniques de l’etat de l’art ayant inﬂuence notre

Apprentissage Automatique de Paraphrases

approche, ainsi que les travaux de recherche lies a l’apprentissage automatique de paraphrases.
La Section 3 décrit ensuite les détails du fonctionnement de notre systeme. Avant de conclure,
la Section 4 présente quelques résultats expérimentaux obtenus qui permettent de mettre en
évidence l’intérét de notre approche.

2 Etat de l’art

2.1 Apprentissage automatique de paraphrases

Comme les paraphrases peuvent étre utilisées dans de nombreux contextes et applications, leur
apprentissage peut étre réalisé a l’aide de diverses methodologies. (Barzilay & McKeown,
2001) distinguent trois méthodes différentes pour la collecte des paraphrases. La premiere est
leur collecte manuelle, la seconde est l’utilisation de ressources linguistiques existantes et la
troisieme est l’extraction de mots ou d’expressions similaires en se basant sur un corpus. De
ces trois méthodes, la premiere est sans doute la plus facile a implémenter, mais probablement
la plus fastidieuse et la plus longue.

Les ressources linguistiques tels que les dictionnaires peuvent s’avérer utiles pour la collecte
ou la génération de paraphrases. Par exemple, (Kurohashi & Sakai, 1999) utilise un dictio-
nnaire construit manuellement pour reformuler des groupes noIr1inaux ambigus en groupes
verbaux. Ces ressources peuvent étre utiles pour des besoins de désambiguisation, mais en
l’absence d’information contextuelle supplémentaire, les relations de synonymie qu’elles con-
tiennent doivent étre utilisées avec précaution. De plus, elles sont souvent considérées comme
peu adaptées aux traitements automatiques (Habert et al., 1997). (Torisawa, 2001) propose une
méthode basée sur l’algorithme d’Estimation-Maximisation pour sélectionner les constructions
verbales servant a paraphraser certaines expressions.

Enﬁn, certains travaux menés dans le domaine de l’extraction basée sur un corpus de mots ou
d’expressions similaires s’appuient sur l’hypothese distributionnelle de Harris, selon laquelle
les mots apparaissant dans le meme contexte tendent a avoir des sens similaires. Partant de ce
postulat, (Barzilay & McKeown, 2001) et (Akira & Takenobu, 2002) travaillent sur un ensemble
de corpus alignés et utilisent des informations contextuelles basées sur des similarités lexicales
pour extraire des paraphrases. De maniere similaire, (Lin & Pantel, 2001) utilise un algorithme
non supervisé pour la découverte de regles d’inférence a partir de textes. Au lieu d’appliquer
l’hypothese harrissienne aux mots, les auteurs l’appliquent a des chemins dans les arbres de
dépendance d’un corpus analysé.

2.2 Extraction d’informations par bootstrapping

Des travaux récents menés en extraction d’informations nous fournissent des approches in-
téressantes, pouvant étre adaptées au probleme de l’apprentissage automatique de paraphrases.
Ainsi, (Riloff & Jones, 1999) décrit un systeme d’extraction d’informations reposant sur un mé-
canisme de bootstrapping a deux niveaux. Le niveau de ”bootstrapping mutuel” construit alter-
nativement un lexique et des patrons d’extraction contextuels. Le niveau de “meta-bootstrapping”
ne conserve que les cinq meilleurs nouveaux termes extraits durant une itération d’apprentissage,
avant de poursuivre avec le boostrapping mutuel. L’ auteur parvient ainsi a réduire la quantité

Florence Duclaye, Olivier Collin, Francois Yvon

de termes invalides trouvés en appliquant les patrons d’extraction.

La technique DIPRE (Dual Iterative Pattern Relation Extraction), présentée dans (Brin, 1998)
est aussi une méthode de bootstrapping, utilisée pour l’acquisition de paires (auteur, titre) a
partir d’un corpus de documents du Web. A partir d’une collection d’exemples de tels exemples,
l’auteur construit des patrons d’extraction utilisés pour collecter de nouvelles paires (auteur,
titre). A leur tour, ces paires sont recherchées dans le corpus et sont utilisées pour construire de
nouveaux patrons d’extraction, et ainsi de suite.

Enﬁn, (Collins & Singer, 1999) décrit une méthode de reconnaissance d’entités nommées ca-
pable d’apprendre a partir d’un faible nombre de données de supervision, en construisant en
parallele deux classiﬁeurs utilisant des ensembles disjoints d’attributs.

3 Description du systéme d’apprentissage de paraphrases

3.1 Fonctionnement global du systéme

Notre algorithme d’inférence de paraphrases commence son apprentissage a partir d’un unique
exemple positif et utilise un mécanisme de bootstrapping a deux niveaux. Cet exemple de de-
part est, par exemple, une réponse automatiquement calculée par notre systeme de Questions-
Réponses. Dans notre modele, un exemple est représenté comme l’association d’une for-
mulation linguistique f d’un prédicat avec son couple d’arguments a. Par exemple, la re-
lation d’auteur pourrait étre représentée ainsi : f=”étre l’auteur de”, a=(”Melville”, ”Moby
Dick”). L’identiﬁcation des paraphrases repose sur un modele de décision probabiliste dont
les parametres sont estimés de maniere presque non supervisée. L’estimation repose sur un
algorithme de clustering fondé sur l’algorithme EM (voir la Section 3.2): il prend en entrée
une matrice contenant les fréquences de cooccurrence d’un ensemble de formulations F et des
couples d’arguInents correspondants A, mesurées dans le corpus 0.

Notre corpus initial Ci contient un unique exemple de départ exprimant la relation sémantique
visée, représenté comme la cooccurrence d’une formulation fi et d’un couple d’arguments a,-.
Avec ces données de départ, nous souhaitons construire un nouveau corpus C contenant poten-
tiellement beaucoup plus d’exemples de la relation sémantique visée. Cette tache est réalisée en
utilisant indépendemment f,- et ai pour formuler des requétes sur le Web. Les documents trou-
vés sont parcourus pour y trouver de nouvelles formulations et paires d’ arguments intéressantes,
qui sont utilisées successivement pour produire de nouvelles requétes, ces demieres étant a leur
tour utilisées pour extraire plus d’arguments et de formulations... Durant cette étape, nous avons
donc besoin de (i) générer des requétes et traiter les documents trouvés aﬁn de (ii) extraire de
nouvelles formulations et de nouveaux couples d’arguments. De plus amples détails concernant
ces procédures sont donnés dans la Section 3.3.

La qualité des paraphrases extraites dépend beaucoup de notre capacité a maintenir le corpus
sufﬁsammentfocalise’ sur la relation sémantique visée: pour ce faire, les phases d’acquisition
sont entrecoupées d’étapes de ﬁltrage reposant sur notre clustering a base d’EM. Le ﬁltrage
est en effet une étape cruciale pour assurer la convergence de cette procédure. L’ architecture
globale de notre systeme est représentée sur la ﬁgure 1.

Apprentissage Automatique de Paraphrases

Phrase 1 Requéte 1

?
Ens. de tuples
{a ,  a }

E Requétek ' K
D V
E Extracteur de formulations ETAPE D'ACQU|5|T|0N Extracteur d'arguments
F L
I
2' f°""u'ati°"S %  Z

1. {f1,...,f.}
G  J Requétel Phrasel
E at 2 2

Phrase
initiale

Figure 1: Systeme d’apprentissage automatique de paraphrases

3.2 Filtrage par l’algorithme d’Estimati0n-Maximisation

Le ﬁltrage consiste a distinguer les paraphrases valides de la relation sémantique de départ des
paraphrases qui sont incorrectes. Ce ﬁltrage intervient a deux endroits de notre mécanisme
d’apprentissage: (i) pour identiﬁer les formulations qui vont déclencher une nouvelle série de
requétes et donc une nouvelle itération; (ii) pour sélectionner les paraphrases qui seront ﬁ-
nalement conservées (voir la Figure 1). Cette étape revient a classiﬁer chaque formulation du
corpus come 1 (paraphrase valide) ou 0 (paraphrase invalide), en se basant sur des données
de cooccurrence entre couples d’arguments et formulations. Ce probleme de partitionnement
en 2 classes est faiblement supervisé car nous ne disposons initialement que d’un seul exem-
ple étiqueté (positif): la formulation de départ. Il est possible d’utiliser pour ce probleme des
algorithmes de clustering utilisant des des données de cooccurrence de type EM (Hofmann &
Puzicha, 1998). Nous considérons donc que chaque phrase (consistant en une formulation f et
ses arguments a) est générée par le modele stochastique suivant:

P(.f7a’) : 2565'-P(.f7a’|S)'P(S) 
Esesl’ (f |8)P (a|8)P (8) (2)

011 S est l’ensemble des relations sémantiques exprimées par des phrases de notre corpus. Nous
considérons également que notre corpus ne contient que deux relations sémantiques, dont les
valeurs sont soit S = 1, signiﬁant qu’une phrase donnée exprime la méme relation séman-
tique que la phrase de départ, soit S = 0, signiﬁant que la phrase exprime une autre relation
sémantique (non spéciﬁée). I-/Etant donné ce modele, les formules de réestimation se dérivent
facilement (Hofmann & Puzicha, 1998). Elles sont présentées dans la Table 1, 011 N dénote
la fonction de comptage.

Ce modele nous permet d’incorporer des connaissances durant la phase d’initialisation, o1‘1 nous
utilisons les valeurs suivantes : P(S = 1|f,-, a,-) = 1 et P(S = 1|f,~, a) = 0.6, Va 76 a,
dans l’équation (3). Toutes les autres valeurs de P (S|F, A) sont égales a 0.5. EM est ensuite

Florence Duclaye, Olivier Collin, Francois Yvon

E-Step
_ P(s)P(f|s)P(a|s)
PW“) ‘ Z.-P(si)P(f|sz~)P(a|sz-) ‘3’
M-Step
  
ZGEA  a)P(8l.f7 a’)
PW’ ZfeF 2.6.1 No: a>P<sm a) (5)
P(8) ZfEF ZGEA  a)P(8|-f7 a’) 

Zfep EaEA Nlf, 11)

Table 1: Formules de réestimation pour EM

lancé jusqu’a convergence des parametres maximisés. Dans notre cas, cette convergence est
généralement atteinte au bout de 10 iterations.

Une fois les parametres appris, nous utilisons ce modele pour décider si une formulation f est
une paraphrase valide en nous basant sur le rapport entre P (S = 1 | f) et P (S = 0| f), calculé
comme suit: 7* =  . Etant donné que P(S = 1) est fortement sur-estimée dans
notre corpus (qui est précisément focalisé autour de tels exemples), la regle de décision utilisée
impose que ce rapport soit supérieur a un seuil pré-déﬁni 0 >> 1. De maniere alternative, nous
avons également considéré des scénarios dans lesquels ces probabilités ne servent qu’a ordonner
les candidats paraphrases, que ce soit pendant les différentes étapes de ﬁltrage ou méme lors
de la décision ﬁnale. Ceci rendant ﬁnalement notre approche moins dépendante de la validité
des hypotheses sous-jacentes au modele probabiliste utilisé, dont certaines sont discutables:en
particulier a la condition d’indépendance exprimée en 2, ou encore l’hypothese que seules deux
relations sémantiques sont représentées dans notre corpus.

3.3 Procédure d’acquisition automatique

L’ outil utilisé pour la phase d’acquisition est un systeme de Questions-Réponses, fonctionnant
ici comme un outil d’extraction d’informations. Ce systeme est constitué de deux composants
principaux: le premier transforme une question en entrée en une requéte sur le Web et déclenche
la recherche; le second analyse les pages retournées (plus précisément les extraits de page)
et y cherche des réponses potentielles, par appariemment de patrons d’extraction pré-déﬁnis.
La requéte et les patrons d’extraction sont dérivés de la question de départ a l’aide de regles.
Les détails concernant ce systeme de QA et les procédures d’analyse linguistique impliqués
a chaque étape du traitement sont donnés dans (Duclaye et al., 2002). En mode “extraction
d’information”, l’étape de construction de requéte est supprimée, la requéte étant déduite des
couples d’arguments (ou de formulations). La phase d’analyse utilise des patrons d’extraction
tres généraux, construits a partir des arguments (ou formulations) en cours de traitement. Sup-
posons, par exemple, que nous recherchons des paraphrases, la paire d’ arguments courante étant
égale a [“Melville”, ”Moby Dick”]. Ces arguments seront tous deux utilisés comme mots-clés,
et deux patrons d’extraction sont utilisés pour faire les extractions dans les documents trou-
vés : “Melville [verb] Moby Dick” et “Moby Dick [verb] Melville”. Dans cet exemple, il est

Apprentissage Automatique de Paraphrases

nécessaire qu’un verbe apparaisse entre les deux mots-clés pour étre extrait. Ce verbe sera
considéré comme une paraphrase potentielle de la formulation de départ. Pour chaque requéte,
seuls les N premiers documents retournés par le moteur de recherche sont pris en compte. Les
paires (arguments, formulations) ainsi extraites sont accumulées, itération apres itération, pour
constituer un corpus sur lequel des statistiques utilisées lors du ﬁltrage sont calculées. Ce pro-
cessus itératif d’acquisition de formulations et de couples d’arguments, combiné avec celui de
validation/ﬁltrage, converge et se termine quand aucune nouvelle formulation n’est trouvée.

4 Résultats expérimentaux

Les expériences décrites dans cette section ont été réalisées sur 18 phrases initiales, représentant
12 relations sémantiques différentes. La Table 2 présente quelques exemples de relations, ainsi
que les formulations et couples d’arguments choisis. Pour chacune de ces phrases, la procédure
d’apprentissage décrite a la Section 3 a été lancée sur une itération. Les résultats présentés ici
ont été obtenus en prenant les N =1000 premiers résumés retournés par le moteur de recherche.

achat de "acheter" AOL; Netscape

auteur de "écrire" Melville; Moby Dick
inventeur de "inventer" Gutenberg; imprimerie
assassinat de "assassiner" Oswald; Kennedy

Table 2: Exemples de relations avec leurs formulations et couples d’arguments

Les paraphrases extraites ont été vériﬁées manuellement et classées comme valides ou invalides.
Dans cette application, le succes peut étre mesuré comme la précision moyenne des paraphrases
extraites, qui devraient a terme étre ajoutées au systeme de Questions-Réponses. Le rappel, par
contre, n’est pas important car nous souhaitons simplement trouver les paraphrases les plus
fréquentes. Le taux de sélection représente le pourcentage de formulations classées comme
valides par notre systeme. Rappelons que la décision de classer une formulation comme une
paraphrase valide ou invalide est basée sur le rapport entre log(P(S = 1|f et log(P(S =
0| f )), appelé 0. Les taux de sélection et les résultats de précision pour différentes valeurs de 0
sont donnés dans la Table 3.

0 7 25 48 117 186 232
Taux de sélection 44.0% 29.8% 23.9% 14.2% 10% 9.4%
Précision 42.9% 47.3% 47.3% 54.9% 66.6% 65.4%

Table 3: Résultats expérimentaux

Dans ces expérimentations, la meilleure précision moyenne atteinte est de 66.6%, quand 0 =
186. Effectuées sur plusieurs relations sémantiques, ces expérimentations ont montré que le taux
de précision peut varier de maniere importante d’une relation sémantique a une autre: il peut
atteindre 100% pour certaines relations, et descendre jusqu’a 6% pour d’autres. Ces résultats
peuvent paraitre faibles. Cela est dﬁ en partie a la quantité variable de données extraites du
Web pour les relations sémantiques. Le fait d’appliquer le méme seuil 0 a toutes les relations
sémantiques n’est certainement pas la meilleure méthode. De plus, la maj orité des formulations

Florence Duclaye, Olivier Collin, Francois Yvon

classees a tort comme de bonnes paraphrases sont thematiquement liees a la formulation de
depart et ne peuvent donc etre considerees comme totalement mauvaises.

Comme indique dans la Table 3, l’augmentation des valeurs de 0 provoque la diminution du taux
de selection et l’augmentation de la precision. La tendance generale est que plus 6 augmente,
plus la quantite de formulations classees comme mauvaises paraphrases augmente, de sorte que
ﬁnalement, seule la formulation de depart est conservee comme valide. Augmenter 6 n’est donc
pas sufﬁsant pour ameliorer la precicion moyenne des paraphrases extraites. Il est necessaire de
trouver un equilibre entre le taux de selection et la precision des paraphrases extraites.

Une autre strategie de ﬁltrage consiste a conserver les k meilleures formulations a chaque itera-
tion (k = 5, 10, ...). La Table 4 porte sur la premiere iteration de la relation d’achat et compare
les taux de precision obtenus pour differents seuils de 1:. La deuxieme colonne represente les
taux de precision dans l’ensemble (de taille k) des formulations classees comme paraphrases
valides. La troisieme colonne represente les taux de precision dans l’ensemble (de taille tou-
jours k) des formulations classees comme paraphrases invalides. Il est interessant de noter
que les formulations classees comme paraphrases invalides ont globalement une meilleure pre-
cision que celles classees comme valides. Dans de prochaines experimentations, on pourrait
envisager d’utiliser ces formulations classees comme paraphrases invalides comme exemples
negatifs d’apprentissage.

Formu. classees en paraph. valides Formu. classees en paraph. invalides
Classe entiere 39.6% 85.2%
k=5 60% 80%
k=10 80% 80%
k=15 73.3% 73.3%

Table 4: Taux de precision en fonction de k, pour la relation d’achat

Des experiences complementaires ont ete conduites sur plusieurs iterations, en ne conservant
que les k=5 meilleures formulations a chaque iteration. La Table 5 montre les resultats obtenus
pour la relation d’achat, apres cinq iterations d’apprentissage. On note que la precision aug-
mente entre la premiere (60%) et la cinquieme (80%) iteration. Des experiences similaires sont
en cours pour d’autres relations semantiques.

| Iteration.  Formulations classees comme paraphrases valides |

1 racheter, acquerir, acheter, utiliser, recevoir

2 racheter, acquerir, acheter, reprendre, absorber
3 racheter, acheter, acquerir, qui racheter, devenir
4 racheter, acheter, acquerir, absorber, grouper

5 racheter, acheter, reprendre, devenir, acquerir

Table 5: Resultats sur cinq iterations d’apprentissage pour la relation semantique d’achat

5 Conclusions et perspectives

Dans cet article, nous avons presente une methodologie faiblement supervisee pour l’apprentissage
automatique de paraphrases, commencant avec un unique exemple positif d’apprentissage. En

Apprentissage Automatique de Paraphrases

utilisant une strategie de validation basee sur l’algorithme EM, nous pouvons ﬁltrer les para-
phrases potentielles invalides extraites durant les phases d’acquisition. Non seulement ces para-
phrases sont utiles pour ameliorer les resultats de notre systeme de Questions-Reponses, mais
les couples d’arguments acquis pourraient egalement etre utilises pour d’autres besoins que
l’apprentissage de paraphrases, comme la construction de lexiques semantiques. Dans cette
optique, l’etape de ﬁltrage pourrait aussi bien etre appliquee aux couples d’arguInents acquis.

Au-dela de resultats experimentaux prometteurs, obtenus dans un scenario relativement simple,
de nombreuses ameliorations portant sur les phases d’acquisition et de validation sont actuelle-
ment envisagees. Concernant l’etape de ﬁltrage, les developpements concernent principalement
(i) une variante consistant a conserver des informations sur les valeurs des parametres du modele
stochastique entre deux etapes successives de ﬁltrage; (ii) l’utilisation de strategies incremen-
tales les paraphrases potentielles qui seront utilisees dans de nouvelles requetes pour augmenter
le corpus d’exemples; (iii) l’utilisation d’autres algorithmes de ﬁltrages, exploitant des prox-
imites distributionnelles entre la formulation d’origine et les autres formulations trouvees sur
Internet. Le but recherche etant d’obtenir un maximum d’exemples differents, tout en gardant
le corpus en expansion sufﬁsarnment focalise sur la relation semantique en cours d’examen.

Concernant la phase d’acquisition, nous projetons d’apprendre des paraphrases multilingues,
ainsi que des structures plus complexes de formulations (comme les nominalisations). Nous
projetons egalement d’utiliser des informations de contexte automatiquement apprises, aﬁn
d’ameliorer la qualite des requetes soumises au moteur de recherche: l’idee est d’extraire, dans
le voisinage lexical des paraphrases identiﬁees comme valides, des termes discriminant per-
mettant (i) de rafﬁner et/ou de varier les requetes et (ii) de qualiﬁer plus ﬁnement le contexte
(thematique) dans lequel les relations de paraphrases sont valides. Il apparait en effet clairement
que de nombreuses relations de paraphrases de valent que dans un contexte bien deﬁni, qu’il est
essentiel de pouvoir decrire.

Base sur une strategie d’apprentissage independante de la langue, notre systeme d’apprentissage
de paraphrases sera integre au systeme de Questions-Reponses. Notre systeme fonctionnera
alors comme un composant independant du module de QA et apprendra des paraphrases a par-
tir des reponses fournies par le systeme de QA. Son integration ne necessite en fait que peu
de developpements nouveaux, dans la mesure o1‘1 notre systeme de Questions-Reponses integre
deja des regles de paraphrasage entrees manuellement. Il ne s’agit donc que d’automatiser ce
processus d’ajout de regles de paraphrasage des questions et des reponses. Ceci nous perme-
ttra d’evaluer dans un contexte applicatif notre methodologie et de mesurer les ameliorations
apportees par les paraphrases extraites.

Références

AKIRA T. & TAKENOBU T. (2002). Automatic disabbreviation by using context information. In Pro-
ceedings of the NLPRS Workshop on Automatic Paraphrasing : Theories and Applications.

BARZILAY R. & MCKEOWN K. R. (2001). Extracting paraphrases from a parallel corpus. In Proceed-
ing of the 39th Annual Meeting of the Association for Computational Linguistics, p. 50-57, Toulouse.

BRIN S. (1998). Extracting patterns and relations from the world wide web. In Proceedings of WebDB
Workshop at EDBT.

COLLINS M. & SINGER Y. (1999). Unsupervised models for named entity classiﬁcation. In Proceed-
ings of the Workshop on Empirical Methods for Natural Language Processing.

Florence Duclaye, Olivier Collin, Francois Yvon

DUCLAYE F., FILOCHE P., SITKO J. & COLLIN O. (2002). A polish question—answering system for
business information. In Proceedings of the Business Information Systems Conference, Poznan.

FUCHS C. (1982). La Paraphrase. Presses Universitaires de France.

GREFENSTETTE G. (1994). Explorations in Automatic Thesaurus Discovery. Boston: Kluwer Aca-
demic Publishers.

HABERT B., NAZARENKO A. & SALEM A. (1997). Les linguistiques de corpus. Armand Colin, Paris.

HOFMANN T. & PUZICHA J. (1998). Statistical Models for Co-occurrence Data. Rapport inteme AI.
1625, MIT, AI Lab.

KUROHASHI S. & SAKAI Y. (1999). Semantic analysis of japanese noun phrases : a new approach
to dictionary—based understanding. In Proceedings of the 37th Annual Meeting of the Association for
Computational Linguistics, p. 481-488.

LIN D. & PANTEL P. (2001). Discovery of inference rules for question—answering. In Natural Language
Engineering, vol11Ine 7, p. 343-360.

MILLER G., BECKWITH R., FELLBAUM C., GROSS D. & MILLER K. (1990). Introduction to wordnet:
An on—line lexical database. In Journal of Lexicography, vol11me 3, p. 234-244.

RILOFF E. & JONES R. (1999). Learning dictionaries for information extraction by multi—level boot-
strapping. Ir1 Proceedings of the 16th National Conference on Artificial Intelligence.

TORISAWA K. (2001). A nearly unsupervised learning method for automatic paraphrasing of japanese
noun phrases. In Proceedings of the NLPRS 2002 workshop on Automatic Paraphrasing : Theories and
Applications, Tokyo.

VOORHEES E. (1999). The TREC—8 question answering track report. In Proceedings of TREC—8.

