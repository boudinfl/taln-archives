TALN 2003, Batz-sur-Mer, 11â€“14 juin 2003
Apprentissage Automatique de Paraphrases pour
lâ€™AmÃ©lioration dâ€™un SystÃ¨me de Questions-RÃ©ponses
Florence Duclaye (1 et 2), Olivier Collin (1), FranÃ§ois Yvon (2)
(1) France TÃ©lÃ©com R&D
2 avenue Pierre Marzin
22307 Lannion Cedex
{florence.duclaye,olivier.collin}@rd.francetelecom.fr
(2) GET/ENST et LTCI, CNRS URA 820
46 rue Barrault
75624 Paris Cedex 13
{fduclaye,yvon}@enst.fr
Mots-clefs â€“ Keywords
Questions-RÃ©ponses, Apprentissage Automatique, Acquisition de Paraphrase
Question Answering, Machine Learning, Paraphrase extraction
RÃ©sumÃ© - Abstract
Dans cet article, nous prÃ©sentons une mÃ©thodologie dâ€™apprentissage faiblement supervisÃ© pour
lâ€™extraction automatique de paraphrases Ã  partir du Web. Ã€ partir dâ€™un seule exemple de paire
(prÃ©dicat, arguments), un corpus est progressivement accumulÃ© par sondage du Web. Les phases
de sondage alternent avec des phases de filtrage, durant lesquelles les paraphrases les moins
plausibles sont Ã©liminÃ©es Ã  lâ€™aide dâ€™une procÃ©dure de clustering non supervisÃ©e. Ce mÃ©canisme
dâ€™apprentissage sâ€™appuie sur un systÃ¨me de Questions-RÃ©ponses existant et les paraphrases ap-
prises seront utilisÃ©es pour en amÃ©liorer le rappel. Nous nous concentrons ici sur le mÃ©canisme
dâ€™apprentissage de ce systÃ¨me et en prÃ©sentons les premiers rÃ©sultats.
In this paper, we present a nearly unsupervised learning methodology for automatically extract-
ing paraphrases from the Web. Starting with one single instance of a pair (predicate,arguments),
a corpus is incrementally built by sampling the Web. Sampling stages alternate with filter-
ingstages, during which implausible paraphrases are filtered out using an EM-based unsuper-
vised clustering procedure. This learning machinery is built on top of an existing question-
answering system and the learnt paraphrases will eventually be used to improve its recall. We
focus here on the learning aspect of this system and report preliminary results.
Florence Duclaye, Olivier Collin, FranÃ§ois Yvon
1 Introduction
Les systÃ¨mes de Questions-RÃ©ponses (Voorhees, 1999) nÃ©cessitent des outils efficaces et so-
phistiquÃ©s de traitement automatique des langues, capables de traiter la variabilitÃ© linguistique
des questions et des rÃ©ponses: une mÃªme signification peut, en effet, Ãªtre vÃ©hiculÃ©e par de multi-
ples structures lexico-syntaxiques. Cette variabilitÃ© est une source de difficultÃ©s dans la plupart
des applications de traitement automatique des langues.
Cette variabilitÃ© se manifeste au niveau syntaxique, oÃ¹ elle prend, par exemple, la forme de
transformations rÃ©guliÃ¨res de la voix actice Ã  la voix passive. Un traitement plus systÃ©matique de
ce phÃ©nomÃ¨ne nÃ©cessite nÃ©anmoins des connaissances sÃ©mantiques, comme celles disponibles
dans des rÃ©seaux sÃ©mantiques (Miller et al., 1990). Le bÃ©nÃ©fice de telles ressources est toute-
fois limitÃ© car (i) les relations de synonymie quâ€™elles contiennent sont dÃ©finies hors de tout
contexte dâ€™usage; (ii) la synonymie implique une notion de la paraphrase qui est beaucoup trop
restreinte pour lâ€™application visÃ©e. La rÃ©ponse Ã  une question est en effet souvent exprimÃ©e
Ã  lâ€™aide de termes qui ne sont que faiblement (par ex. mÃ©taphoriquement) liÃ©s Ã  ceux de la
question. Ainsi lâ€™expression â€œX a causÃ© Yâ€ peut Ãªtre considÃ©rÃ©e comme sÃ©mantiquement simi-
laire Ã  â€œla responsabilitÃ© de Y est attribuÃ©e Ã  Xâ€ dans le contexte des Questions-RÃ©ponses (Lin
& Pantel, 2001). Au lieu dâ€™essayer de complÃ©ter manuellement ces ressources statiques, nous
avons choisi dâ€™exploiter les avantages dâ€™une approche fondÃ©e sur des corpus et dâ€™apprendre
de telles Ã©quivalences de maniÃ¨re automatique. Nous utilisons le terme de paraphrase pour
faire rÃ©fÃ©rence Ã  ces relations, bien que la dÃ©finition du terme adoptÃ©e ici soit surtout focalisÃ©e
sur deux types de phÃ©nomÃ¨nes linguistiques : les paraphrases linguistiques et les dÃ©rivations
sÃ©mantiques. (Fuchs, 1982) dÃ©crit les paraphrases comme des phrases dont le sens linguis-
tique dÃ©notatif est Ã©quivalent. Les dÃ©rivations sÃ©mantiques sont des phrases dont le sens est
prÃ©servÃ© mais dont la structure lexico-syntaxique est diffÃ©rente (ex : AOL a achetÃ© Netscape /
lâ€™acquisition de Netscape par AOL ). Le corpus utilisÃ© pour acquÃ©rir les paraphrases est le Web.
Cette utilisation du Web comme corpus offre plusieurs avantages (Grefenstette, 1994). (i) Les
informations quâ€™il contient sont dâ€™une grande variÃ©tÃ© et dâ€™une grande redondance, une mÃªme
information pouvant apparaÃ®tre sous de multiples formes. Notre algorithme dâ€™apprentissage re-
pose fortement sur cette propriÃ©tÃ©. (ii) Le Web contient des informations contextuelles pouvant
contraindre la portÃ©e de la relation de paraphrase. En outre, comme notre systÃ¨me de Questions-
RÃ©ponses utilise le Web comme unique source dâ€™information, il est important dâ€™extraire les
formulations dâ€™un concept qui sont les plus frÃ©quemment utilisÃ©es sur le Web. Cette stratÃ©gie
nâ€™est pas sans difficultÃ©s: la rÃ©duction du niveau de bruit dans les donnÃ©es extraites est en par-
ticulier un problÃ¨me important. Le mÃ©canisme dâ€™apprentissage que nous proposons est capable
dâ€™acquÃ©rir automatiquement de multiples formulations dâ€™une relation sÃ©mantique donnÃ©e Ã  par-
tir dâ€™un seul exemple. Cette donnÃ©e de dÃ©part consiste en un exemple de la relation sÃ©mantique
visÃ©e, oÃ¹ lâ€™expression linguistique (formulation) de la relation et le couple dâ€™arguments ont tous
deux Ã©tÃ© identifiÃ©s. Ce type de donnÃ©es est directement fourni par notre systÃ¨me de Questions-
RÃ©ponses, mais il est Ã©galement largement disponible dans les dictionnaires. Ã‰tant donnÃ© cet
exemple positif, notre mÃ©canisme dâ€™apprentissage envoie de maniÃ¨re rÃ©pÃ©titive des requÃªtes sur
le Web et utilise alternativement les formulations connues pour acquÃ©rir des nouveaux couples
dâ€™arguments, et les couples dâ€™arguments connus pour trouver de nouvelles formulations. Ce
mÃ©canisme se dÃ©compose en deux Ã©tapes: dâ€™une part la recherche de paraphrases potentielles
de la relation sÃ©mantique et dâ€™autre part la validation de ces paraphrases en se basant sur des
comptages de frÃ©quences et sur lâ€™algorithme dâ€™Estimation-Maximisation (EM).
Cet article prÃ©sente Ã  la Section 2 les travaux techniques de lâ€™Ã©tat de lâ€™art ayant influencÃ© notre
Apprentissage Automatique de Paraphrases
approche, ainsi que les travaux de recherche liÃ©s Ã  lâ€™apprentissage automatique de paraphrases.
La Section 3 dÃ©crit ensuite les dÃ©tails du fonctionnement de notre systÃ¨me. Avant de conclure,
la Section 4 prÃ©sente quelques rÃ©sultats expÃ©rimentaux obtenus qui permettent de mettre en
Ã©vidence lâ€™intÃ©rÃªt de notre approche.
2 Ã‰tat de lâ€™art
2.1 Apprentissage automatique de paraphrases
Comme les paraphrases peuvent Ãªtre utilisÃ©es dans de nombreux contextes et applications, leur
apprentissage peut Ãªtre rÃ©alisÃ© Ã  lâ€™aide de diverses mÃ©thodologies. (Barzilay & McKeown,
2001) distinguent trois mÃ©thodes diffÃ©rentes pour la collecte des paraphrases. La premiÃ¨re est
leur collecte manuelle, la seconde est lâ€™utilisation de ressources linguistiques existantes et la
troisiÃ¨me est lâ€™extraction de mots ou dâ€™expressions similaires en se basant sur un corpus. De
ces trois mÃ©thodes, la premiÃ¨re est sans doute la plus facile Ã  implÃ©menter, mais probablement
la plus fastidieuse et la plus longue.
Les ressources linguistiques tels que les dictionnaires peuvent sâ€™avÃ©rer utiles pour la collecte
ou la gÃ©nÃ©ration de paraphrases. Par exemple, (Kurohashi & Sakai, 1999) utilise un dictio-
nnaire construit manuellement pour reformuler des groupes nominaux ambigus en groupes
verbaux. Ces ressources peuvent Ãªtre utiles pour des besoins de dÃ©sambiguÃ¯sation, mais en
lâ€™absence dâ€™information contextuelle supplÃ©mentaire, les relations de synonymie quâ€™elles con-
tiennent doivent Ãªtre utilisÃ©es avec prÃ©caution. De plus, elles sont souvent considÃ©rÃ©es comme
peu adaptÃ©es aux traitements automatiques (Habert et al., 1997). (Torisawa, 2001) propose une
mÃ©thode basÃ©e sur lâ€™algorithme dâ€™Estimation-Maximisation pour sÃ©lectionner les constructions
verbales servant Ã  paraphraser certaines expressions.
Enfin, certains travaux menÃ©s dans le domaine de lâ€™extraction basÃ©e sur un corpus de mots ou
dâ€™expressions similaires sâ€™appuient sur lâ€™hypothÃ¨se distributionnelle de Harris, selon laquelle
les mots apparaissant dans le mÃªme contexte tendent Ã  avoir des sens similaires. Partant de ce
postulat, (Barzilay & McKeown, 2001) et (Akira & Takenobu, 2002) travaillent sur un ensemble
de corpus alignÃ©s et utilisent des informations contextuelles basÃ©es sur des similaritÃ©s lexicales
pour extraire des paraphrases. De maniÃ¨re similaire, (Lin & Pantel, 2001) utilise un algorithme
non supervisÃ© pour la dÃ©couverte de rÃ¨gles dâ€™infÃ©rence Ã  partir de textes. Au lieu dâ€™appliquer
lâ€™hypothÃ¨se harrissienne aux mots, les auteurs lâ€™appliquent Ã  des chemins dans les arbres de
dÃ©pendance dâ€™un corpus analysÃ©.
2.2 Extraction dâ€™informations par bootstrapping
Des travaux rÃ©cents menÃ©s en extraction dâ€™informations nous fournissent des approches in-
tÃ©ressantes, pouvant Ãªtre adaptÃ©es au problÃ¨me de lâ€™apprentissage automatique de paraphrases.
Ainsi, (Riloff & Jones, 1999) dÃ©crit un systÃ¨me dâ€™extraction dâ€™informations reposant sur un mÃ©-
canisme de bootstrapping Ã  deux niveaux. Le niveau de â€bootstrapping mutuelâ€ construit alter-
nativement un lexique et des patrons dâ€™extraction contextuels. Le niveau de â€œmeta-bootstrappingâ€
ne conserve que les cinq meilleurs nouveaux termes extraits durant une itÃ©ration dâ€™apprentissage,
avant de poursuivre avec le boostrapping mutuel. Lâ€™auteur parvient ainsi Ã  rÃ©duire la quantitÃ©
Florence Duclaye, Olivier Collin, FranÃ§ois Yvon
de termes invalides trouvÃ©s en appliquant les patrons dâ€™extraction.
La technique DIPRE (Dual Iterative Pattern Relation Extraction), prÃ©sentÃ©e dans (Brin, 1998)
est aussi une mÃ©thode de bootstrapping, utilisÃ©e pour lâ€™acquisition de paires (auteur, titre) Ã 
partir dâ€™un corpus de documents du Web. Ã€ partir dâ€™une collection dâ€™exemples de tels exemples,
lâ€™auteur construit des patrons dâ€™extraction utilisÃ©s pour collecter de nouvelles paires (auteur,
titre). Ã€ leur tour, ces paires sont recherchÃ©es dans le corpus et sont utilisÃ©es pour construire de
nouveaux patrons dâ€™extraction, et ainsi de suite.
Enfin, (Collins & Singer, 1999) dÃ©crit une mÃ©thode de reconnaissance dâ€™entitÃ©s nommÃ©es ca-
pable dâ€™apprendre Ã  partir dâ€™un faible nombre de donnÃ©es de supervision, en construisant en
parallÃ¨le deux classifieurs utilisant des ensembles disjoints dâ€™attributs.
3 Description du systÃ¨me dâ€™apprentissage de paraphrases
3.1 Fonctionnement global du systÃ¨me
Notre algorithme dâ€™infÃ©rence de paraphrases commence son apprentissage Ã  partir dâ€™un unique
exemple positif et utilise un mÃ©canisme de bootstrapping Ã  deux niveaux. Cet exemple de dÃ©-
part est, par exemple, une rÃ©ponse automatiquement calculÃ©e par notre systÃ¨me de Questions-
RÃ©ponses. Dans notre modÃ¨le, un exemple est reprÃ©sentÃ© comme lâ€™association dâ€™une for-
 
mulation linguistique dâ€™un prÃ©dicat avec son couple dâ€™arguments  . Par exemple, la re-
 
lation dâ€™auteur pourrait Ãªtre reprÃ©sentÃ©e ainsi : =â€Ãªtre lâ€™auteur deâ€,  =(â€Melvilleâ€, â€Moby
Dickâ€). Lâ€™identification des paraphrases repose sur un modÃ¨le de dÃ©cision probabiliste dont
les paramÃ¨tres sont estimÃ©s de maniÃ¨re presque non supervisÃ©e. Lâ€™estimation repose sur un
algorithme de clustering fondÃ© sur lâ€™algorithme EM (voir la Section 3.2): il prend en entrÃ©e
une matrice contenant les frÃ©quences de cooccurrence dâ€™un ensemble de formulations  et des
couples dâ€™arguments correspondants  , mesurÃ©es dans le corpus  .
Notre corpus initial  contient un unique exemple de dÃ©part exprimant la relation sÃ©mantique
 
visÃ©e, reprÃ©sentÃ© comme la cooccurrence dâ€™une formulation  et dâ€™un couple dâ€™arguments  .
Avec ces donnÃ©es de dÃ©part, nous souhaitons construire un nouveau corpus  contenant poten-
tiellement beaucoup plus dâ€™exemples de la relation sÃ©mantique visÃ©e. Cette tÃ¢che est rÃ©alisÃ©e en
 
utilisant indÃ©pendemment  et  pour formuler des requÃªtes sur le Web. Les documents trou-
vÃ©s sont parcourus pour y trouver de nouvelles formulations et paires dâ€™arguments intÃ©ressantes,
qui sont utilisÃ©es successivement pour produire de nouvelles requÃªtes, ces derniÃ¨res Ã©tant Ã  leur
tour utilisÃ©es pour extraire plus dâ€™arguments et de formulations... Durant cette Ã©tape, nous avons
donc besoin de (i) gÃ©nÃ©rer des requÃªtes et traiter les documents trouvÃ©s afin de (ii) extraire de
nouvelles formulations et de nouveaux couples dâ€™arguments. De plus amples dÃ©tails concernant
ces procÃ©dures sont donnÃ©s dans la Section 3.3.
La qualitÃ© des paraphrases extraites dÃ©pend beaucoup de notre capacitÃ© Ã  maintenir le corpus
suffisamment focalisÃ© sur la relation sÃ©mantique visÃ©e: pour ce faire, les phases dâ€™acquisition
sont entrecoupÃ©es dâ€™Ã©tapes de filtrage reposant sur notre clustering Ã  base dâ€™EM. Le filtrage
est en effet une Ã©tape cruciale pour assurer la convergence de cette procÃ©dure. Lâ€™architecture
globale de notre systÃ¨me est reprÃ©sentÃ©e sur la figure 1.
Apprentissage Automatique de Paraphrases
E Phrase 1 RequÃªte 1
T Ens. de tuples
A ... ... d'argument
P {aPhrase k RequÃªte k 1
 , ..., ak}
E
D
E Extracteur de formulations ETAPE D'ACQUISITION Extracteur d'arguments
F
I
L
T RequÃªte 1 Phrase 1Ens. de
R formulations ... ...
A {f
G 1
, ...,f j}
RequÃªte l Phrase l
E
Phrase
initiale
Figure 1: SystÃ¨me dâ€™apprentissage automatique de paraphrases
3.2 Filtrage par lâ€™algorithme dâ€™Estimation-Maximisation
Le filtrage consiste Ã  distinguer les paraphrases valides de la relation sÃ©mantique de dÃ©part des
paraphrases qui sont incorrectes. Ce filtrage intervient Ã  deux endroits de notre mÃ©canisme
dâ€™apprentissage: (i) pour identifier les formulations qui vont dÃ©clencher une nouvelle sÃ©rie de
requÃªtes et donc une nouvelle itÃ©ration; (ii) pour sÃ©lectionner les paraphrases qui seront fi-
nalement conservÃ©es (voir la Figure 1). Cette Ã©tape revient Ã  classifier chaque formulation du
corpus comme 1 (paraphrase valide) ou 0 (paraphrase invalide), en se basant sur des donnÃ©es
de cooccurrence entre couples dâ€™arguments et formulations. Ce problÃ¨me de partitionnement
en 2 classes est faiblement supervisÃ© car nous ne disposons initialement que dâ€™un seul exem-
ple Ã©tiquetÃ© (positif): la formulation de dÃ©part. Il est possible dâ€™utiliser pour ce problÃ¨me des
algorithmes de clustering utilisant des des donnÃ©es de cooccurrence de type EM (Hofmann &
 
Puzicha, 1998). Nous considÃ©rons donc que chaque phrase (consistant en une formulation et
ses arguments  ) est gÃ©nÃ©rÃ©e par le modÃ¨le stochastique suivant:
   
	
 	
 	

  ffflfiffi fi (1)
 
	
 	
 	

  flfiffi ff fi fiffi (2)
oÃ¹ ! est lâ€™ensemble des relations sÃ©mantiques exprimÃ©es par des phrases de notre corpus. Nous
considÃ©rons Ã©galement que notre corpus ne contient que deux relations sÃ©mantiques, dont les
valeurs sont soit !" # , signifiant quâ€™une phrase donnÃ©e exprime la mÃªme relation sÃ©man-
tique que la phrase de dÃ©part, soit !$&% , signifiant que la phrase exprime une autre relation
sÃ©mantique (non spÃ©cifiÃ©e). Ã‰tant donnÃ© ce modÃ¨le, les formules de rÃ©estimation se dÃ©rivent
facilement (Hofmann & Puzicha, 1998). Elles sont prÃ©sentÃ©es dans 
la Table 1, oÃ¹ '  dÃ©note
la fonction de comptage.
Ce modÃ¨le nous permet dâ€™incorporer des connaissances durant la phase dâ€™initialisation, oÃ¹ nous
      10

 	

utilisons les valeurs sui 	vantes : !( #)  *+, # et !( #)  , %)-/. & 2 *
dans lâ€™Ã©quation (3). Toutes les autres valeurs de 	
 !3  4 sont Ã©gales Ã  %)-65 . EM est ensuite
Florence Duclaye, Olivier Collin, FranÃ§ois Yvon
E-Step
 
	
 	
 	

 
	
 fiffi flfiffi ff fi
 
	
 	
 	

fi) 7 (3)8
fi9 flfi:; ffflfi:+

M-Step
   

 	

8=<
'  fi) 
	

:>
   
ff fi 
 	
 (4)
8=? 8=<
' A fi) A
@ >
   

 	

8B?
 
	
 '  fi) 
@
   

 	

 fi (5)
8 8< ?
' A fi) A
:> :@
   

 	

8 8< ?
' A fi) A
	

:> :@
 


fi (6)
8 8< ?
' 
> :@
Table 1: Formules de rÃ©estimation pour EM
lancÃ© jusquâ€™Ã  convergence des paramÃ¨tres maximisÃ©s. Dans notre cas, cette convergence est
gÃ©nÃ©ralement atteinte au bout de #C% itÃ©rations.
 
Une fois les paramÃ¨tres appris, nous utilisons ce modÃ¨le pour dÃ©cider si une formulation est
   
	
 	

une paraphrase valide en no<CuS s basant sur le rapport entre !DE#)  et !FG%H  , calculÃ©
OHPRQ OHPRQ
<CS
comme suit: IJLKNM KNM . Ã‰tant donnÃ© 	
que !V#ffi est fortement sur-estimÃ©e dans
OUTQ OUTQ
notre corpus (qui esKNt M prÃ©cKNisM Ã©ment focalisÃ© autour de tels exemples), la rÃ¨gle de dÃ©cision utilisÃ©e
impose que ce rapport soit supÃ©rieur Ã  un seuil prÃ©-dÃ©fini WYXZX[# . De maniÃ¨re alternative, nous
avons Ã©galement considÃ©rÃ© des scÃ©narios dans lesquels ces probabilitÃ©s ne servent quâ€™Ã  ordonner
les candidats paraphrases, que ce soit pendant les diffÃ©rentes Ã©tapes de filtrage ou mÃªme lors
de la dÃ©cision finale. Ceci rendant finalement notre approche moins dÃ©pendante de la validitÃ©
des hypothÃ¨ses sous-jacentes au modÃ¨le probabiliste utilisÃ©, dont certaines sont discutables:en
particulier Ã  la condition dâ€™indÃ©pendance exprimÃ©e en 2, ou encore lâ€™hypothÃ¨se que seules deux
relations sÃ©mantiques sont reprÃ©sentÃ©es dans notre corpus.
3.3 ProcÃ©dure dâ€™acquisition automatique
Lâ€™outil utilisÃ© pour la phase dâ€™acquisition est un systÃ¨me de Questions-RÃ©ponses, fonctionnant
ici comme un outil dâ€™extraction dâ€™informations. Ce systÃ¨me est constituÃ© de deux composants
principaux: le premier transforme une question en entrÃ©e en une requÃªte sur le Web et dÃ©clenche
la recherche; le second analyse les pages retournÃ©es (plus prÃ©cisÃ©ment les extraits de page)
et y cherche des rÃ©ponses potentielles, par appariemment de patrons dâ€™extraction prÃ©-dÃ©finis.
La requÃªte et les patrons dâ€™extraction sont dÃ©rivÃ©s de la question de dÃ©part Ã  lâ€™aide de rÃ¨gles.
Les dÃ©tails concernant ce systÃ¨me de QA et les procÃ©dures dâ€™analyse linguistique impliquÃ©s
Ã  chaque Ã©tape du traitement sont donnÃ©s dans (Duclaye et al., 2002). En mode â€œextraction
dâ€™informationâ€, lâ€™Ã©tape de construction de requÃªte est supprimÃ©e, la requÃªte Ã©tant dÃ©duite des
couples dâ€™arguments (ou de formulations). La phase dâ€™analyse utilise des patrons dâ€™extraction
trÃ¨s gÃ©nÃ©raux, construits Ã  partir des arguments (ou formulations) en cours de traitement. Sup-
posons, par exemple, que nous recherchons des paraphrases, la paire dâ€™arguments courante Ã©tant
Ã©gale Ã  [â€œMelvilleâ€, â€Moby Dickâ€]. Ces arguments seront tous deux utilisÃ©s comme mots-clÃ©s,
et deux patrons dâ€™extraction sont utilisÃ©s pour faire les extractions dans les documents trou-
vÃ©s : â€œMelville [verb] Moby Dickâ€ et â€œMoby Dick [verb] Melvilleâ€. Dans cet exemple, il est
Apprentissage Automatique de Paraphrases
nÃ©cessaire quâ€™un verbe apparaÃ®sse entre les deux mots-clÃ©s pour Ãªtre extrait. Ce verbe sera
considÃ©rÃ© comme une paraphrase potentielle de la formulation de dÃ©part. Pour chaque requÃªte,
seuls les ' premiers documents retournÃ©s par le moteur de recherche sont pris en compte. Les
paires (arguments, formulations) ainsi extraites sont accumulÃ©es, itÃ©ration aprÃ¨s itÃ©ration, pour
constituer un corpus sur lequel des statistiques utilisÃ©es lors du filtrage sont calculÃ©es. Ce pro-
cessus itÃ©ratif dâ€™acquisition de formulations et de couples dâ€™arguments, combinÃ© avec celui de
validation/filtrage, converge et se termine quand aucune nouvelle formulation nâ€™est trouvÃ©e.
4 RÃ©sultats expÃ©rimentaux
Les expÃ©riences dÃ©crites dans cette section ont Ã©tÃ© rÃ©alisÃ©es sur 18 phrases initiales, reprÃ©sentant
12 relations sÃ©mantiques diffÃ©rentes. La Table 2 prÃ©sente quelques exemples de relations, ainsi
que les formulations et couples dâ€™arguments choisis. Pour chacune de ces phrases, la procÃ©dure
dâ€™apprentissage dÃ©crite Ã  la Section 3 a Ã©tÃ© lancÃ©e sur une itÃ©ration. Les rÃ©sultats prÃ©sentÃ©s ici
ont Ã©tÃ© obtenus en prenant les ' =1000 premiers rÃ©sumÃ©s retournÃ©s par le moteur de recherche.
achat de "acheter" AOL; Netscape
auteur de "Ã©crire" Melville; Moby Dick
inventeur de "inventer" Gutenberg; imprimerie
assassinat de "assassiner" Oswald; Kennedy
Table 2: Exemples de relations avec leurs formulations et couples dâ€™arguments
Les paraphrases extraites ont Ã©tÃ© vÃ©rifiÃ©es manuellement et classÃ©es comme valides ou invalides.
Dans cette application, le succÃ¨s peut Ãªtre mesurÃ© comme la prÃ©cision moyenne des paraphrases
extraites, qui devraient Ã  terme Ãªtre ajoutÃ©es au systÃ¨me de Questions-RÃ©ponses. Le rappel, par
contre, nâ€™est pas important car nous souhaitons simplement trouver les paraphrases les plus
frÃ©quentes. Le taux de sÃ©lection reprÃ©sente le pourcentage de formulations classÃ©es comme
valides par notre systÃ¨me. Rappelons que la dÃ©cision de classer une formulation comme une
 

R	

paraphrase valide ou invalide 
R	
est basÃ©e sur le rapport entre \+]ffi^ !GL#) _ et \+]ffi^ !G
 
%H _ , appelÃ© W . Les taux de sÃ©lection et les rÃ©sultats de prÃ©cision pour diffÃ©rentes valeurs de W
sont donnÃ©s dans la Table 3.
W 7 25 48 117 186 232
Taux de sÃ©lection 44.0% 29.8% 23.9% 14.2% 10% 9.4%
PrÃ©cision 42.9% 47.3% 47.3% 54.9% 66.6% 65.4%
Table 3: RÃ©sultats expÃ©rimentaux
Dans ces expÃ©rimentations, la meilleure prÃ©cision moyenne atteinte est de 66.6%, quand W`
#Ca*. . EffectuÃ©es sur plusieurs relations sÃ©mantiques, ces expÃ©rimentations ont montrÃ© que le taux
de prÃ©cision peut varier de maniÃ¨re importante dâ€™une relation sÃ©mantique Ã  une autre: il peut
atteindre 100% pour certaines relations, et descendre jusquâ€™Ã  6% pour dâ€™autres. Ces rÃ©sultats
peuvent paraÃ®tre faibles. Cela est dÃ» en partie Ã  la quantitÃ© variable de donnÃ©es extraites du
Web pour les relations sÃ©mantiques. Le fait dâ€™appliquer le mÃªme seuil W Ã  toutes les relations
sÃ©mantiques nâ€™est certainement pas la meilleure mÃ©thode. De plus, la majoritÃ© des formulations
Florence Duclaye, Olivier Collin, FranÃ§ois Yvon
classÃ©es Ã  tort comme de bonnes paraphrases sont thÃ©matiquement liÃ©es Ã  la formulation de
dÃ©part et ne peuvent donc Ãªtre considÃ©rÃ©es comme totalement mauvaises.
Comme indiquÃ© dans la Table 3, lâ€™augmentation des valeurs de W provoque la diminution du taux
de sÃ©lection et lâ€™augmentation de la prÃ©cision. La tendance gÃ©nÃ©rale est que plus W augmente,
plus la quantitÃ© de formulations classÃ©es comme mauvaises paraphrases augmente, de sorte que
finalement, seule la formulation de dÃ©part est conservÃ©e comme valide. Augmenter W nâ€™est donc
pas suffisant pour amÃ©liorer la prÃ©cicion moyenne des paraphrases extraites. Il est nÃ©cessaire de
trouver un Ã©quilibre entre le taux de sÃ©lection et la prÃ©cision des paraphrases extraites.
Une autre stratÃ©gie de filtrage consiste Ã  conserver les b meilleures formulations Ã  chaque itÃ©ra-
 
tion ( bcd5 #C% -e-f- ). La Table 4 porte sur la premiÃ¨re itÃ©ration de la relation dâ€™achat et compare
les taux de prÃ©cision obtenus pour diffÃ©rents seuils de b . La deuxiÃ¨me colonne reprÃ©sente les
taux de prÃ©cision dans lâ€™ensemble (de taille b ) des formulations classÃ©es comme paraphrases
valides. La troisiÃ¨me colonne reprÃ©sente les taux de prÃ©cision dans lâ€™ensemble (de taille tou-
jours b ) des formulations classÃ©es comme paraphrases invalides. Il est intÃ©ressant de noter
que les formulations classÃ©es comme paraphrases invalides ont globalement une meilleure prÃ©-
cision que celles classÃ©es comme valides. Dans de prochaines expÃ©rimentations, on pourrait
envisager dâ€™utiliser ces formulations classÃ©es comme paraphrases invalides comme exemples
nÃ©gatifs dâ€™apprentissage.
Formu. classÃ©es en paraph. valides Formu. classÃ©es en paraph. invalides
Classe entiÃ¨re 39.6% 85.2%
b =5 60% 80%
b =10 80% 80%
b =15 73.3% 73.3%
Table 4: Taux de prÃ©cision en fonction de k, pour la relation dâ€™achat
Des expÃ©riences complÃ©mentaires ont Ã©tÃ© conduites sur plusieurs itÃ©rations, en ne conservant
que les b =5 meilleures formulations Ã  chaque itÃ©ration. La Table 5 montre les rÃ©sultats obtenus
pour la relation dâ€™achat, aprÃ¨s cinq itÃ©rations dâ€™apprentissage. On note que la prÃ©cision aug-
mente entre la premiÃ¨re (60%) et la cinquiÃ¨me (80%) itÃ©ration. Des expÃ©riences similaires sont
en cours pour dâ€™autres relations sÃ©mantiques.
ItÃ©ration. Formulations classÃ©es comme paraphrases valides
# racheter, acquÃ©rir, acheter, utiliser, recevoir
g
racheter, acquÃ©rir, acheter, reprendre, absorber
h
racheter, acheter, acquÃ©rir, qui racheter, devenir
i
racheter, acheter, acquÃ©rir, absorber, grouper
5 racheter, acheter, reprendre, devenir, acquÃ©rir
Table 5: RÃ©sultats sur cinq itÃ©rations dâ€™apprentissage pour la relation sÃ©mantique dâ€™achat
5 Conclusions et perspectives
Dans cet article, nous avons prÃ©sentÃ© une mÃ©thodologie faiblement supervisÃ©e pour lâ€™apprentissage
automatique de paraphrases, commenÃ§ant avec un unique exemple positif dâ€™apprentissage. En
Apprentissage Automatique de Paraphrases
utilisant une stratÃ©gie de validation basÃ©e sur lâ€™algorithme EM, nous pouvons filtrer les para-
phrases potentielles invalides extraites durant les phases dâ€™acquisition. Non seulement ces para-
phrases sont utiles pour amÃ©liorer les rÃ©sultats de notre systÃ¨me de Questions-RÃ©ponses, mais
les couples dâ€™arguments acquis pourraient Ã©galement Ãªtre utilisÃ©s pour dâ€™autres besoins que
lâ€™apprentissage de paraphrases, comme la construction de lexiques sÃ©mantiques. Dans cette
optique, lâ€™Ã©tape de filtrage pourrait aussi bien Ãªtre appliquÃ©e aux couples dâ€™arguments acquis.
Au-delÃ  de rÃ©sultats expÃ©rimentaux prometteurs, obtenus dans un scÃ©nario relativement simple,
de nombreuses amÃ©liorations portant sur les phases dâ€™acquisition et de validation sont actuelle-
ment envisagÃ©es. Concernant lâ€™Ã©tape de filtrage, les dÃ©veloppements concernent principalement
(i) une variante consistant Ã  conserver des informations sur les valeurs des paramÃ¨tres du modÃ¨le
stochastique entre deux Ã©tapes successives de filtrage; (ii) lâ€™utilisation de stratÃ©gies incrÃ©men-
tales les paraphrases potentielles qui seront utilisÃ©es dans de nouvelles requÃªtes pour augmenter
le corpus dâ€™exemples; (iii) lâ€™utilisation dâ€™autres algorithmes de filtrages, exploitant des prox-
imitÃ©s distributionnelles entre la formulation dâ€™origine et les autres formulations trouvÃ©es sur
Internet. Le but recherchÃ© Ã©tant dâ€™obtenir un maximum dâ€™exemples diffÃ©rents, tout en gardant
le corpus en expansion suffisamment focalisÃ© sur la relation sÃ©mantique en cours dâ€™examen.
Concernant la phase dâ€™acquisition, nous projetons dâ€™apprendre des paraphrases multilingues,
ainsi que des structures plus complexes de formulations (comme les nominalisations). Nous
projetons Ã©galement dâ€™utiliser des informations de contexte automatiquement apprises, afin
dâ€™amÃ©liorer la qualitÃ© des requÃªtes soumises au moteur de recherche: lâ€™idÃ©e est dâ€™extraire, dans
le voisinage lexical des paraphrases identifiÃ©es comme valides, des termes discriminant per-
mettant (i) de raffiner et/ou de varier les requÃªtes et (ii) de qualifier plus finement le contexte
(thÃ©matique) dans lequel les relations de paraphrases sont valides. Il apparaÃ®t en effet clairement
que de nombreuses relations de paraphrases de valent que dans un contexte bien dÃ©fini, quâ€™il est
essentiel de pouvoir dÃ©crire.
BasÃ© sur une stratÃ©gie dâ€™apprentissage indÃ©pendante de la langue, notre systÃ¨me dâ€™apprentissage
de paraphrases sera intÃ©grÃ© au systÃ¨me de Questions-RÃ©ponses. Notre systÃ¨me fonctionnera
alors comme un composant indÃ©pendant du module de QA et apprendra des paraphrases Ã  par-
tir des rÃ©ponses fournies par le systÃ¨me de QA. Son intÃ©gration ne nÃ©cessite en fait que peu
de dÃ©veloppements nouveaux, dans la mesure oÃ¹ notre systÃ¨me de Questions-RÃ©ponses intÃ¨gre
dÃ©jÃ  des rÃ¨gles de paraphrasage entrÃ©es manuellement. Il ne sâ€™agit donc que dâ€™automatiser ce
processus dâ€™ajout de rÃ¨gles de paraphrasage des questions et des rÃ©ponses. Ceci nous perme-
ttra dâ€™Ã©valuer dans un contexte applicatif notre mÃ©thodologie et de mesurer les amÃ©liorations
apportÃ©es par les paraphrases extraites.
RÃ©fÃ©rences
AKIRA T. & TAKENOBU T. (2002). Automatic disabbreviation by using context information. In Pro-
ceedings of the NLPRS Workshop on Automatic Paraphrasing : Theories and Applications.
BARZILAY R. & MCKEOWN K. R. (2001). Extracting paraphrases from a parallel corpus. In Proceed-
ing of the 39th Annual Meeting of the Association for Computational Linguistics, p. 50â€“57, Toulouse.
BRIN S. (1998). Extracting patterns and relations from the world wide web. In Proceedings of WebDB
Workshop at EDBT.
COLLINS M. & SINGER Y. (1999). Unsupervised models for named entity classification. In Proceed-
ings of the Workshop on Empirical Methods for Natural Language Processing.
Florence Duclaye, Olivier Collin, FranÃ§ois Yvon
DUCLAYE F., FILOCHE P., SITKO J. & COLLIN O. (2002). A polish question-answering system for
business information. In Proceedings of the Business Information Systems Conference, Poznan.
FUCHS C. (1982). La Paraphrase. Presses Universitaires de France.
GREFENSTETTE G. (1994). Explorations in Automatic Thesaurus Discovery. Boston: Kluwer Aca-
demic Publishers.
HABERT B., NAZARENKO A. & SALEM A. (1997). Les linguistiques de corpus. Armand Colin, Paris.
HOFMANN T. & PUZICHA J. (1998). Statistical Models for Co-occurrence Data. Rapport interne AI.
1625, MIT, AI Lab.
KUROHASHI S. & SAKAI Y. (1999). Semantic analysis of japanese noun phrases : a new approach
to dictionary-based understanding. In Proceedings of the 37th Annual Meeting of the Association for
Computational Linguistics, p. 481â€“488.
LIN D. & PANTEL P. (2001). Discovery of inference rules for question-answering. In Natural Language
Engineering, volume 7, p. 343â€“360.
MILLER G., BECKWITH R., FELLBAUM C., GROSS D. & MILLER K. (1990). Introduction to wordnet:
An on-line lexical database. In Journal of Lexicography, volume 3, p. 234â€“244.
RILOFF E. & JONES R. (1999). Learning dictionaries for information extraction by multi-level boot-
strapping. In Proceedings of the 16th National Conference on Artificial Intelligence.
TORISAWA K. (2001). A nearly unsupervised learning method for automatic paraphrasing of japanese
noun phrases. In Proceedings of the NLPRS 2002 workshop on Automatic Paraphrasing : Theories and
Applications, Tokyo.
VOORHEES E. (1999). The TREC-8 question answering track report. In Proceedings of TREC-8.
