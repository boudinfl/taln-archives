<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>De la traduction probabiliste aux m&#233;moires de traduction (ou l&#8217;inverse)</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2003, Batz-sur-Mer, 11&#8211;14 juin 2003
</p>
<p>De la traduction probabiliste aux m&#233;moires de traduction
(ou l&#8217;inverse)
</p>
<p>Philippe Langlais et Michel Simard
RALI
</p>
<p>D&#233;partement d&#8217;Informatique et de Recherche Op&#233;rationnelle
Universit&#233; de Montr&#233;al
</p>
<p>CP. 6128 Succursale Centre-Ville
H3C3J7 Montr&#233;al, Qu&#233;bec, Canada
</p>
<p>{felipe,simardm}@iro.umontreal.ca
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>Traduction automatique, m&#233;moire de traduction sous-phrastique, alignement sous-phrastique
Automatic translation, translation memories, word alignment
</p>
<p>R&#233;sum&#233; - Abstract
</p>
<p>En d&#233;pit des travaux r&#233;alis&#233;s cette derni&#232;re d&#233;cennie dans le cadre g&#233;n&#233;ral de la traduction
probabiliste, nous sommes toujours bien loin du jour o&#249; un engin de traduction automatique
(probabiliste ou pas) sera capable de r&#233;pondre pleinement aux besoins d&#8217;un traducteur pro-
fessionnel. Dans une &#233;tude r&#233;cente (Langlais, 2002), nous avons montr&#233; comment un engin
de traduction probabiliste pouvait b&#233;n&#233;ficier de ressources terminologiques ext&#233;rieures. Dans
cette &#233;tude, nous montrons que les techniques de traduction probabiliste peuvent &#234;tre utilis&#233;es
pour extraire des informations sous-phrastiques d&#8217;une m&#233;moire de traduction. Ces informations
peuvent &#224; leur tour s&#8217;av&#233;rer utiles &#224; un engin de traduction probabiliste. Nous rapportons des
r&#233;sultats sur un corpus de test de taille importante en utilisant la m&#233;moire de traduction d&#8217;un
concordancier bilingue commercial.
</p>
<p>Despite the exciting work accomplished over the past decade in the field of Statistical Machine
Translation (SMT), we are still far from the point of being able to say that machine transla-
tion fully meets the needs of real-life users. In a previous study (Langlais, 2002), we have
shown how a SMT engine could benefit from terminological resources, especially when trans-
lating texts very different from those used to train the system. In the present paper, we discuss
the opening of SMT to examples automatically extracted from a Translation Memory (TM).
We report results on a fair-sized translation task using the database of a commercial bilingual
concordancer.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Langlais et Michel Simard
</p>
<p>1 Introduction
</p>
<p>Le fait que la traduction automatique ne soit viable que dans des contextes applicatifs tr&#232;s pr&#233;cis
(domaine limit&#233;, t&#226;che r&#233;p&#233;titive) est une &#233;vidence que les tentatives r&#233;centes, notamment dans
le domaine effervescent de la traduction probabiliste, n&#8217;ont pas r&#233;ussi &#224; d&#233;mentir. Ce constat
indique que des approches d&#8217;aide &#224; la traduction sont &#224; privil&#233;gier (du moins pour le moment) &#224;
une approche compl&#232;tement automatique. C&#8217;est dans ce contexte que des syst&#232;mes de m&#233;moire
de traduction comme ceux commercialis&#233;s par les firmes Trados (Translator&#8217;s Workbench), IBM
(Translation Manager/2), Atril (D&#233;j&#224;-Vu) et Star AG (Transit) ont vu le jour et connaissent un
certain succ&#232;s commercial.
</p>
<p>Ces syst&#232;mes op&#232;rent &#224; un niveau de granularit&#233; qui correspond grossi&#232;rement &#224; celui de la
phrase et ne sont donc utilisables que dans des contextes &#233;galement tr&#232;s pr&#233;cis comme la r&#233;vi-
sion de documents. Des syst&#232;mes travaillant &#224; un niveau sous-phrastique existent cependant sur
le march&#233;. C&#8217;est par exemple le cas des produits D&#233;j&#224;-Vu et MultiTrans (MultiCorpora R&amp;D
inc.). Il est cependant important de souligner, que ces outils ne s&#8217;appuient sur aucune technique
d&#8217;alignement sous-phrastique et font au contraire appel au bon sens des traducteurs qui ont &#224;
charge d&#8217;alimenter leur(s) base(s) avec des alignements (sous-phrastiques ou pas) pertinents.
&#192; notre connaissance, et au-del&#224; des arguments commerciaux avanc&#233;s par les diff&#233;rents con-
cepteurs de logiciels de m&#233;moire de traduction, il n&#8217;existe pas d&#8217;&#233;tude qui permet d&#8217;&#233;tablir de
mani&#232;re concluante que de tels outils augmentent la productivit&#233; des utilisateurs (traducteurs ou
cabinet de traduction).
Dans une &#233;tude pass&#233;e (Langlais &amp; Simard, 2001), nous avons montr&#233; qu&#8217;une m&#233;moire de
traduction syst&#233;matiquement interrog&#233;e &#224; un niveau sous-phrastique permettait d&#8217;obtenir une
couverture (source) d&#8217;un texte &#224; traduire de loin sup&#233;rieure (de 70% &#224; 95% selon la nature
du document) &#224; celle que l&#8217;on peut obtenir si l&#8217;on interroge la m&#234;me m&#233;moire &#224; un niveau
phrastique. Des couvertures comparables ont &#233;t&#233; d&#233;crites dans le cadre du syst&#232;me Pangloss
(Brown, 1996).
Nous avons &#233;galement montr&#233; que ce taux n&#8217;est qu&#8217;un indicateur tr&#232;s biais&#233; de la r&#233;utilisabilit&#233;
d&#8217;une m&#233;moire. D&#8217;autres &#233;tapes &#8212; non triviales dans le cas d&#8217;une m&#233;moire sous-phrastique
&#8212; telles que la s&#233;lection du mat&#233;riel source &#224; aller rechercher dans la m&#233;moire, l&#8217;identification
de son correspondant cible ainsi que les choix de pr&#233;sentation du mat&#233;riel ramen&#233; au traducteur
sont en effet autant de facteurs qui conditionnent l&#8217;utilisabilit&#233; d&#8217;une m&#233;moire. En simulant
plusieurs sc&#233;narios, nous avons montr&#233; dans (Langlais &amp; Simard, 2001) qu&#8217;en gros moins d&#8217;un
tiers du mat&#233;riel ramen&#233; d&#8217;une m&#233;moire pouvait &#234;tre utile &#224; la construction de moins d&#8217;un quart
du mat&#233;riel cible &#224; produire. Ces taux &#233;taient mesur&#233;s sur deux bitextes de r&#233;f&#233;rence de 100
paires de phrases chacun.
</p>
<p>Dans cette &#233;tude, nous proposons une nouvelle &#233;valuation &#8212; sur un corpus de plus grande taille
&#8212; d&#8217;un syst&#232;me d&#8217;interrogation de m&#233;moire de traduction (SIM) dont les composants ont &#233;t&#233;
am&#233;lior&#233;s par rapport &#224; (Langlais &amp; Simard, 2001). Nous nous int&#233;ressons de plus &#224; v&#233;rifier
dans quelle mesure un moteur de traduction probabiliste ne pourrait pas b&#233;n&#233;ficier d&#8217;exemples
extraits automatiquement d&#8217;une m&#233;moire.
</p>
<p>Dans la section 2, nous pr&#233;sentons l&#8217;architecture g&#233;n&#233;rale qui sous-tend les exp&#233;riences que
nous avons men&#233;es et d&#233;crivons la m&#233;moire de traduction que nous avons utilis&#233;e. Dans la
section 3, nous d&#233;crivons les exp&#233;riences que nous avons r&#233;alis&#233;es et qui valident l&#8217;id&#233;e qu&#8217;une
m&#233;moire de traduction et un moteur de traduction peuvent faire bon m&#233;nage. Nous discutons
nos exp&#233;riences dans la section 4.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>De la traduction probabiliste aux m&#233;moires de traduction (ou l&#8217;inverse)
</p>
<p>2 Architecture du syst&#232;me
</p>
<p>Nous clarifions d&#232;s &#224; pr&#233;sent que dans cette &#233;tude nous dissocions la ressource constitu&#233;e de
traductions d&#233;j&#224; disponibles &#8212; et que nous appelons la m&#233;moire de traduction &#8212; de son ex-
ploitation. La m&#233;moire que nous utilisons ici est un &#233;norme bitexte anglais-fran&#231;ais de plus de
100 millions de mots par langue align&#233; au niveau de la phrase. Ce mat&#233;riel contient tous les
textes parlementaires canadiens publi&#233;s entre avril 1986 et d&#233;cembre 2001 et constitue le c&#339;ur
de la m&#233;moire &#224; laquelle ont acc&#232;s les utilisateurs du syst&#232;me commercial TSRali.com 1.
Une vue d&#8217;ensemble de l&#8217;architecture est offerte en figure 1.
</p>
<p>this is the responsible thing to do .
an effort was made to find a loophole
</p>
<p>on a tente de trouver une echappatoire
le sens des responsabilites l&#8217;exige
</p>
<p>p(a|une)
p(1|2,3,5)
p(c|ab)
</p>
<p>EVAL
</p>
<p>STS
</p>
<p>bitexte
</p>
<p>texte a traduire traduction
</p>
<p>traductionnelles
briques
</p>
<p>SIM
</p>
<p>alignement
selection
</p>
<p>filtrage
</p>
<p>Figure 1: Architecture utilis&#233;e dans cette &#233;tude. Voir le texte pour des explications.
</p>
<p>2.1 Le moteur de traduction (STS)
Le syst&#232;me de traduction statistique utilis&#233; ici est un syst&#232;me &#8220;canal bruit&#233;&#8221; mettant en jeu
un mod&#232;le de langue (mod&#232;le trigramme interpol&#233;), et un mod&#232;le de traduction de type IBM2
(Brown et al., 1993). Les mod&#232;les embarqu&#233;s ont &#233;t&#233; entra&#238;n&#233;s sur un sous-ensemble d&#8217;environ
1.6 million de paires de phrases de la m&#233;moire. Le d&#233;codage est effectu&#233; par programmation
dynamique selon une am&#233;lioration de la m&#233;thode d&#233;crite par Nie&#223;en et al. (1998). L&#8217;algorithme
de recherche propos&#233; s&#8217;accommode de plus de contraintes &#8220;flottantes&#8221; exprim&#233;es sous la forme
de lexiques bilingues. Le d&#233;codeur garantit alors qu&#8217;une des traductions possibles de chaque
unit&#233; source du lexique qui se trouve dans la phrase &#224; traduire sera propos&#233;e dans la traduction.
Le choix de l&#8217;unit&#233; cible (dans le cas o&#249; le lexique amende plusieurs traductions) et de sa
position dans la traduction est d&#233;termin&#233; de mani&#232;re &#224; optimiser sur la phrase, les pr&#233;dictions
des mod&#232;les de langue et de traduction. La figure 2 montre un exemple de traduction produite
par le d&#233;codeur lorsqu&#8217;on lui fournit un lexique bilingue (smt + mt).
</p>
<p>1Consulter la page http://www.tsrali.com pour plus d&#8217;information.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Langlais et Michel Simard
</p>
<p>2.2 Le syst&#232;me d&#8217;interrogation de la m&#233;moire de traduction (SIM)
Le syst&#232;me d&#8217;interrogation de la m&#233;moire est bas&#233; sur trois op&#233;rations automatiques dont la
pr&#233;cision conditionne le succ&#232;s de l&#8217;architecture au complet.
</p>
<p>s&#233;lection consiste &#224; s&#233;lectionner dans le mat&#233;riel &#224; traduire des s&#233;quences de mots avec les-
quelles interroger la m&#233;moire. Nous appelons ces s&#233;quences les requ&#234;tes.
</p>
<p>Dans cette &#233;tude, le texte &#224; traduire est tout d&#8217;abord d&#233;coup&#233; en chunks &#224; l&#8217;aide d&#8217;une cascade
de mod&#232;les markoviens qui &#233;tiquette chaque mot par un marqueur de d&#233;but, ou d&#8217;interm&#233;diaire
de groupe (voir (Osborne, 2000) pour la description de la cascade de distributions mod&#233;lis&#233;es
en pratique). Toute s&#233;quence de chunks pr&#233;sente dans la m&#233;moire est alors une requ&#234;te valide.
Cette &#233;tape de segmentation en groupes simples n&#8217;est pas indispensable, mais nous pensons
qu&#8217;elle permet de limiter les requ&#234;tes &#224; des groupes de mots dont la traduction dans le texte
cible est plus facile &#224; localiser.
</p>
<p>Dans l&#8217;exemple de la figure 2, 15 requ&#234;tes sont valides; leur fr&#233;quence d&#8217;apparition dans la
m&#233;moire est indiqu&#233;e entre crochets; au total 564 couples de phrases sont s&#233;lectionn&#233;s dans la
m&#233;moire.
</p>
<p>alignement consiste &#224; identifier dans les paires de phrases de la m&#233;moire qui contiennent les
requ&#234;tes, leur traduction. Nous appelons les couples requ&#234;te/mat&#233;riel cible extrait de la m&#233;moire
les briques traductionnelles.
</p>
<p>Aligner des phrases au niveau des mots est une t&#226;che difficile. Dans le projet ARCADE, qui &#233;tait
d&#233;di&#233; &#224; l&#8217;&#233;valuation d&#8217;alignements bilingues, il a &#233;t&#233; montr&#233; que les meilleurs syst&#232;mes test&#233;s
obtenaient une performance de l&#8217;ordre de 75% (pr&#233;cision et rappel) dans une t&#226;che simplifi&#233;e
de localisation (dans un bitexte) des traductions de 60 mots choisis (V&#233;ronis &amp; Langlais, 2000).
Nous avons exp&#233;riment&#233; diff&#233;rentes strat&#233;gies d&#8217;alignement qui sont d&#233;crites et analys&#233;es dans
(Simard, 2003). La technique d&#8217;alignement que nous avons retenue ici est une version simpli-
fi&#233;e des grammaires stochastiques propos&#233;es par Wu (1997) qui consiste &#224; d&#233;tecter de mani&#232;re
descendante des points de coupures binaires dans la paire de phrase &#224; aligner, jusqu&#8217;&#224; isoler
(lorsque c&#8217;est possible) le segment dont on cherche la traduction. Le choix du d&#233;coupage est
fait en consultant le mod&#232;le de traduction.
</p>
<p>Dans notre exemple, 355 briques traductionnelles diff&#233;rentes ont ainsi &#233;t&#233; identifi&#233;es, parmi
lesquelles 316 (89%) ont &#233;t&#233; rencontr&#233;es une seule fois dans la m&#233;moire.
</p>
<p>filtrage consiste &#224; s&#233;lectionner les briques traductionnelles qui seront finalement propos&#233;es
au traducteur ou au moteur de traduction. Nous avons exp&#233;riment&#233; diff&#233;rentes strat&#233;gies de
filtrage (dont le d&#233;tail n&#8217;est pas pertinent ici) comme des seuillages (sur la probabilit&#233; des asso-
ciations ou sur leur fr&#233;quence dans la m&#233;moire), ou encore la s&#233;lection des requ&#234;tes de mani&#232;re
&#224; maximiser (par exemple) la couverture de la phrase &#224; traduire.
Dans notre exemple, des 355 briques traductionnelles identifi&#233;es, seulement 8 sont finalement
conserv&#233;es.
</p>
<p>2.3 Module d&#8217;&#233;valuation (EVAL)
Ce module vise deux objectifs; d&#8217;une part de mesurer le taux de r&#233;cup&#233;rabilit&#233; des briques
traductionnelles extraites de la m&#233;moire, d&#8217;autre part de v&#233;rifier si un syst&#232;me de traduction</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>De la traduction probabiliste aux m&#233;moires de traduction (ou l&#8217;inverse)
</p>
<p>probabiliste peut b&#233;n&#233;ficier du mat&#233;riel extrait automatiquement d&#8217;une m&#233;moire &#224; l&#8217;aide des
m&#234;mes mod&#232;les que le moteur utilise. Dans les deux cas, nous utilisons un bitexte de r&#233;f&#233;rence
dont la partie cible (une traduction produite par un humain) est le texte que nous cherchons &#224;
reproduire (traduction oracle).
</p>
<p>2.3.1 Taux de couverture et de pr&#233;cision
</p>
<p>Les deux taux suivants sont ind&#233;pendants du moteur de traduction et tentent de mesurer directe-
ment la r&#233;utilisabilit&#233; des briques traductionnelles extraites de la m&#233;moire.
</p>
<p>Le taux de couverture source (resp. cible) est le pourcentage de mots sources (resp. cibles)
du bitexte de r&#233;f&#233;rence qui sont couverts par le mat&#233;riel source (resp. cible) des briques traduc-
tionnelles. Ces taux sont mesur&#233;s sur les briques traductionelles enti&#232;res issues de l&#8217;&#233;tape de
filtrage.
</p>
<p>Dans l&#8217;exemple de la figure 2, les trois requ&#234;tes retenues (for the translation, immediately with-
out waiting et will the minister table the report) couvrent douze des treize mots de la phrase
&#224; traduire, la couverture source est donc de 12/13 (92.3%). De la m&#234;me mani&#232;re, les briques
cibles (la traduction et sans attendre) couvrent quatre des douze mots de la traduction oracle;
la couverture cible est donc de 4/12 (33%).
Taux de pr&#233;cision et de rappel. D&#232;s lors que l&#8217;on s&#8217;int&#233;resse &#224; la couverture cible, nous
avons montr&#233; dans (Langlais &amp; Simard, 2001) qu&#8217;il &#233;tait pr&#233;f&#233;rable de mesurer des taux de
pr&#233;cision et de rappel. Il est en effet possible de maximiser la couverture cible en gardant toutes
les traductions potentielles de toutes les requ&#234;tes valides, et ce au d&#233;triment d&#8217;un utilisateur qui
se verrait submerg&#233; de mat&#233;riel cible.
</p>
<p>Dans un contexte d&#8217;&#233;valuation automatique, cela signifie qu&#8217;il nous faut faire des hypoth&#232;ses
quant &#224; l&#8217;usage que ferait un utilisateur du mat&#233;riel cible qu&#8217;on lui propose. Dans cette &#233;tude,
nous avons imagin&#233; qu&#8217;un utilisateur (fictif) produit la traduction oracle en copiant/collant tout
ou partie du mat&#233;riel cible qui lui est propos&#233;. Nous d&#233;finissons alors la pr&#233;cision Pc comme de
rapport du nombre de mots coll&#233;s dans la traduction sur le nombre de mots cibles des briques
traductionnelles. Le taux de rappel Rc est quant &#224; lui mesur&#233; par le ratio du nombre de mots
coll&#233;s sur le nombre de mots cibles de la traduction oracle. L&#224; encore, il est important d&#8217;observer
que les taux ainsi mesur&#233;s d&#233;pendent grandement de la fa&#231;on avec laquelle on admet qu&#8217;un
utilisateur s&#233;lectionnera des mots dans une brique traductionnelle. Nous admettons ici qu&#8217;il
copiera au plus une s&#233;quence de mots d&#8217;au moins c mots de chaque brique traductionnelle.
c = 0 d&#233;signe le sc&#233;nario o&#249; le traducteur ne fera que copier/coller des briques cibles enti&#232;res.
Ces deux taux peuvent &#234;tre r&#233;sum&#233;s en un seul (la f-mesure) qui est leur moyenne harmonique.
Dans notre exemple, si l&#8217;on admet que l&#8217;utilisateur ne fait que des copier/coller de briques cibles
enti&#232;res (c = 0), alors 11 mots (ceux des briques dont la partie cible est en gras) sont copi&#233;s sur
un total de 30 mots cibles propos&#233;s, d&#8217;o&#249; une pr&#233;cision P0 de 11/30 (soit 36.6%). Le rappel R0
est alors de 11/13 (soit 84.6%).
</p>
<p>2.3.2 Mesures automatiques de la qualit&#233; d&#8217;une traduction
</p>
<p>Une mani&#232;re indirecte de mesurer la r&#233;utilisabilit&#233; des briques traductionnelles est de v&#233;rifier
leur apport &#224; la qualit&#233; d&#8217;une traduction. Bien qu&#8217;indirecte, cette &#233;valuation pr&#233;sente l&#8217;avantage</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Langlais et Michel Simard
</p>
<p>input:
source will the minister table the report immediately without waiting for the translation ?
oracle le ministre va il d&#233;poser imm&#233;diatement le rapport sans attendre la traduction ?
</p>
<p>requ&#234;tes:
will the minister table [64], will the minister table the report [3], the minister table [98], the
minister table the report [4], the report [100], the report immediately [1], immediately without
[34], immediately without waiting [1], immediately without waiting for [1], without waiting
[62], without waiting for [49], waiting for [98], waiting for the translation [3], for the transla-
tion [6], the translation [40]
briques traductionnelles:
</p>
<p>for the translation la traduction
for the translation pour entendre la traduction
for the translation pour la traduction de
for the translation pour qu&#8217;
immediately without waiting sans attendre
will the minister table the report le comit&#233;
will the minister table the report le ministre d&#233;posera il le rapport sur
will the minister table the report le ministre va il d&#233;poser le rapport
</p>
<p>output:
smt le ministre de d&#233;poser le rapport sans attendre la suite de la traduction ?
smt+mt le ministre va il d&#233;poser le rapport sans attendre la traduction ?
</p>
<p>alignements:
</p>
<p>REF: le min va il d&#233;p imm le rap san att la tra ?
SMT: le min de d&#233;p le rap san att la suite de la tra ?
SMT+: le min va il d&#233;p le rap san att la tra ?
</p>
<p>Figure 2: Illustration sur une session de traduction simple des principales &#233;tapes de
l&#8217;architecture d&#233;crite. Voir le texte pour des explications.
</p>
<p>de pouvoir s&#8217;appuyer sur des m&#233;triques existantes. Nous comparons ici la qualit&#233; des traduc-
tions produites par notre moteur de traduction avec et sans brique traductionnelle &#224; l&#8217;aide de
trois mesures automatiques qui sont couramment utilis&#233;es dans la litt&#233;rature.
</p>
<p>BLEU est une mesure qui comptabilise de mani&#232;re pond&#233;r&#233;e le nombre d&#8217;unigrammes, de
bigrammes, de trigrammes et de quadigrammes qu&#8217;une traduction &#224; &#233;valuer partage avec une
ou plusieurs traductions oracles. Les valeurs que peuvent prendre cette mesure sont entre 0 et
1; une valeur de 1 indiquant une bonne traduction. Papineni et al. (2002) rapportent que cette
mesure est corr&#233;l&#233;e &#224; des jugements produits par des humains. C&#8217;est la mesure qui est utilis&#233;e
dans les &#233;valuations NIST. Pour des questions de lisibilit&#233; nous multiplions par 100 les scores
obtenus par le programme mt-eval disponible sur le site de NIST 2.
</p>
<p>Deux traductions sont rapport&#233;es dans l&#8217;exemple de la figure 2. La premi&#232;re (smt) est produite
par le moteur probabiliste seul et obtient un score BLEU de 39.07; la seconde (smt + mt), est
</p>
<p>2http://wwww.nist.gov/speech/tests/mt/doc/index.htm</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>De la traduction probabiliste aux m&#233;moires de traduction (ou l&#8217;inverse)
</p>
<p>obtenue par le moteur de traduction aliment&#233; par les briques traductionnelles et son score BLEU
est de 76.77.
</p>
<p>WER est une version normalis&#233;e de ce que l&#8217;on appelle la distance d&#8217;&#233;dition (le nombre
d&#8217;op&#233;rations d&#8217;&#233;dition minimum qu&#8217;il faut appliquer &#224; la traduction candidate pour obtenir la
traduction oracle). Les valeurs de WER sont exprim&#233;es entre 0 et 100; une valeur de 0 indique
une traduction identique &#224; la traduction oracle.
</p>
<p>Dans notre exemple, le moteur de traduction seul propose une traduction dont le WER est de
37.5, alors que la traduction qu&#8217;il propose lorsque les briques traductionnelles sont disponibles
est de 7.7. Les alignements respectifs &#224; la traduction oracle sont indiqu&#233;s &#224; m&#234;me la figure 2.
</p>
<p>SER est le pourcentage de traductions qui ne sont pas identiques verbatim &#224; la traduction
oracle. Cette mesure est bien s&#251;rtr&#232;s s&#233;v&#232;re (une traduction pouvant &#234;tre bonne sans pour autant
&#234;tre celle produite par l&#8217;oracle). Dans notre exemple, aucune des deux traductions propos&#233;es
n&#8217;est identique &#224; la traduction oracle, et le SER sur ce corpus d&#8217;une phrase est donc de 100 dans
les deux cas.
</p>
<p>3 Exp&#233;riences
</p>
<p>Nous avons extrait du Hansard un passage de mars 2002 (une p&#233;riode non couverte par la
m&#233;moire de traduction) constitu&#233; de 1646 phrases de longueur source (resp. cible) moyenne de
23 (resp. 20) mots. Dans cette exp&#233;rience, nous avons choisi la langue anglaise comme langue
source car la traduction oracle a &#233;t&#233; produite dans cette direction.
</p>
<p>Il existe de nombreux param&#232;tres qui sont ajustables dans l&#8217;architecture que nous avons pr&#233;sen-
t&#233;e. Nous pouvons en particulier s&#233;lectionner la nature des requ&#234;tes faites &#224; la m&#233;moire de
m&#234;me que la quantit&#233; de briques traductionnelles ramen&#233;es (en tenant compte de diff&#233;rents
crit&#232;res de s&#233;lection). Nous avons test&#233; dans cette exp&#233;rience 462 instances de l&#8217;architecture
dont les d&#233;tails ne sont pas pertinents ici.
</p>
<p>3.1 Couverture des briques traductionnelles
</p>
<p>En terme de couverture source, les variantes test&#233;es diff&#232;rent sensiblement selon la quantit&#233; de
filtres appliqu&#233;s de 68% &#224; 80%, la moyenne entre tous ces syst&#232;mes &#233;tant de 74.7% (&#233;cart-type
de 3.9%). Les diff&#233;rences les plus importantes sont de mani&#232;re naturelle observ&#233;es sur les taux
de couverture cible. Les configurations les plus filtrantes (celles o&#249; par exemple on d&#233;cide de
ne retenir qu&#8217;une brique traductionnelle par requ&#234;te) montrent des taux de couverture cible de
l&#8217;ordre de 10%. Les configurations les plus permissives plafonnent quant &#224; elles &#224; 68%. La
moyenne des configurations est de 28.4% (&#233;cart type de 12.4%). Ces observations sont encore
une fois coh&#233;rentes avec les mesures faites dans (Langlais &amp; Simard, 2001).
La table 1 montre parmi l&#8217;ensemble des configurations pour chaque sc&#233;nario, les taux de pr&#233;-
cision, de rappel et de f-mesure que l&#8217;on obtient en maximisant ou bien la f-mesure (deuxi&#232;me
colonne), ou bien la pr&#233;cision (troisi&#232;me colonne). Les configurations qui correspondent &#224;
ces mesures sont toutes des configurations o&#249; une seule brique traductionnelle a &#233;t&#233; conserv&#233;e</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Langlais et Michel Simard
</p>
<p>par requ&#234;te; ce sont &#233;galement les configurations qui montrent des taux de couverture cible
minimum; ce qui confirme que les taux de couverture ne sont pas de bons indicateurs de la
r&#233;cup&#233;rabilit&#233; d&#8217;une m&#233;moire.
</p>
<p>On observe &#233;galement que si plus de la moiti&#233; des briques traductionnelles propos&#233;es &#224; un util-
isateur permet de reconstruire un peu moins de la moiti&#233; d&#8217;une traduction oracle en s&#233;lectionnant
des s&#233;quences d&#8217;un mot ou plus dans ce mat&#233;riel (c = 1), ces taux de r&#233;cup&#233;rabilit&#233; diminuent
avec la taille des segments que l&#8217;utilisateur s&#8217;autorise &#224; copier. &#192; l&#8217;extr&#234;me, un utilisateur qui ne
pourrait que cliquer sur les briques propos&#233;es pour construire sa traduction (c = 0) ne pourrait
utiliser qu&#8217;un sixi&#232;me environ des briques propos&#233;es pour construire &#224; peu pr&#232;s un cinqui&#232;me de
sa traduction. Ces chiffres sont plus faibles que ceux que nous avions mesur&#233;s dans (Langlais
&amp; Simard, 2001) sur le mat&#233;riel Hansard test&#233; &#224; ce moment. La taille plus grande du corpus de
test utilis&#233; ici et le fait que ce soit un texte d&#8217;une p&#233;riode non couverte par la m&#233;moire sont des
explications possibles de cette diff&#233;rence.
</p>
<p>meilleure Fc meilleure Pc
c Pc Rc Fc Pc Rc
0 14.1 19.9 16.5 18.6 10.5
1 56.9 42.3 48.6 57.1 32.0
2 34.4 25.6 29.3 34.4 25.6
3 24.7 18.4 21.0 24.7 18.4
4 17.2 12.8 14.7 17.2 12.8
</p>
<p>Table 1: Taux de pr&#233;cision et rappel en fonction du sc&#233;nario utilisateur. La deuxi&#232;me colonne
montre les meilleures f-mesures que l&#8217;on obtient parmi toutes les versions test&#233;es; la troisi&#232;me
colonne montre les configurations avec la meilleure pr&#233;cision.
</p>
<p>3.2 Qualit&#233; de la traduction
Nous rapportons en table 2 les r&#233;sultats de traduction obtenus par notre d&#233;codeur avec et sans
les briques traductionnelles en fonction de la longueur maximale des phrases consid&#233;r&#233;es3. On
note clairement ici la corr&#233;lation entre les diff&#233;rentes m&#233;triques et la longueur maximale des
phrases traduites: traduire une phrase plus courte est en moyenne plus facile. On observe
&#233;galement l&#8217;am&#233;lioration syst&#233;matique que les briques traductionnelles ont sur la qualit&#233; (telle
que mesur&#233;e) des traductions produites, et ce, quelque soit la longueur maximale des phrases
consid&#233;r&#233;es. L&#8217;am&#233;lioration relative de score BLEU mesur&#233;e pour l&#8217;ensemble des phrases d&#8217;au
plus 30 mots est de 46.8%. Ce r&#233;sultat est tr&#232;s int&#233;ressant et confirme les observations faites
par Marcu (2001), et ce, m&#234;me si les protocoles exp&#233;rimentaux entre les deux &#233;tudes sont assez
diff&#233;rents. En particulier, il est important de souligner que dans nos exp&#233;riences, les mod&#232;les de
traduction et de langue ont &#233;t&#233; entra&#238;n&#233;s sur une petite portion de la m&#233;moire utilis&#233;e ici et qu&#8217;il
n&#8217;est pas du tout certain que nous aurions observ&#233; de telles am&#233;liorations si les mod&#232;les avaient
&#233;t&#233; entra&#238;n&#233;s sur l&#8217;ensemble de la m&#233;moire. Il convient cependant d&#8217;ajouter que l&#8217;entra&#238;nement
d&#8217;un mod&#232;le de traduction sur des quantit&#233;s de textes sup&#233;rieures &#224; celles utilis&#233;es dans cette
&#233;tude n&#8217;est pas une t&#226;che simple4 et qu&#8217;il existe &#224; notre avis de nombreuses situations o&#249; il n&#8217;est
</p>
<p>3Seules les phrases d&#8217;au plus 30 mots ont &#233;t&#233; traduites ici.
4Des contraintes pratiques mais bien r&#233;elles, notamment de m&#233;moire vive, font que l&#8217;entra&#238;nement de gros
</p>
<p>mod&#232;les n&#233;cessite entre autres choses une version parall&#232;le de l&#8217;algorithme d&#8217;entra&#238;nement.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>De la traduction probabiliste aux m&#233;moires de traduction (ou l&#8217;inverse)
</p>
<p>SMT + MT SMT
L nb. BLEU WER SER perfect BLEU WER SER ratio
5 199 28.94 52.57 83.42 33 18.07 58.06 91.96 60.1
10 397 25.04 55.82 89.42 42 18.84 59.39 95.46 32.9
15 646 24.00 59.56 93.03 45 17.53 62.39 97.21 36.9
20 890 24.93 60.51 94.72 47 16.87 63.66 97.98 47.8
25 1026 23.65 62.24 95.42 47 15.98 64.64 98.25 48.0
30 1126 23.46 63.01 95.83 47 15.98 65.07 98.40 46.8
</p>
<p>Table 2: Mesures de la qualit&#233; des traductions produites par le d&#233;codeur seul (SMT ) et par le
d&#233;codeur aid&#233; des briques traductionnelles (SMT +MT ). ratio indique l&#8217;am&#233;lioration relative
du score BLEU.
</p>
<p>pas envisageable d&#8217;entra&#238;ner &#8220;r&#233;guli&#232;rement&#8221; de nouveaux mod&#232;les, alors qu&#8217;il est assez simple
de mettre &#224; jour une m&#233;moire de traduction.
</p>
<p>4 Discussions
</p>
<p>Nous avons propos&#233; deux types d&#8217;&#233;valuation de la r&#233;cup&#233;rabilit&#233; d&#8217;une m&#233;moire de traduc-
tion sous-phrastique. Nous avons montr&#233; sur un corpus de test de taille importante que les
taux de pr&#233;cision et de rappel des briques traductionnelles extraites de la m&#233;moire &#233;taient loin
d&#8217;approcher les taux de couvertures sources et cibles que l&#8217;on rapporte habituellement. Il est
important de noter cependant que le fait de n&#8217;utiliser qu&#8217;une traduction de r&#233;f&#233;rence ne nous
permet que de mesurer une borne inf&#233;rieure de r&#233;cup&#233;rabilit&#233; d&#8217;une m&#233;moire. Nous montrons
enfin, que les briques traductionnelles aident un engin de traduction probabiliste &#224; proposer des
traductions de meilleure qualit&#233; (dans la limite de la pertinence des m&#233;triques utilis&#233;es ici).
L&#8217;id&#233;e d&#8217;utiliser des exemples extraits d&#8217;une m&#233;moire pour g&#233;n&#233;rer ensuite une traduction n&#8217;est
pas nouvelle et sous-tend en fait tout syst&#232;me de traduction &#224; base d&#8217;exemples. Le syst&#232;me
Pangloss (Frederking et al., 1994; Brown, 1996) utilisait par exemple un mod&#232;le de langue pour
assembler les exemples extraits de diff&#233;rentes ressources et diff&#233;rents syst&#232;mes de traduction.
L&#8217;utilisation d&#8217;un moteur de traduction probabiliste pour assembler des exemples est cependant
moins populaire.
</p>
<p>Nous voyons cependant plusieurs avantages &#224; utiliser un moteur de traduction probabiliste pour
assembler des exemples. Premi&#232;rement, il convient de rappeler que la r&#233;alisation d&#8217;un mo-
teur probabiliste est une op&#233;ration relativement ais&#233;e. Des packages simples &#224; utiliser sont
en effet disponibles pour l&#8217;entra&#238;nement des mod&#232;les de langue (Clarkson &amp; Rosenfeld, 1997)
et de traduction (Och &amp; Ney, 2000) et un d&#233;codeur peut &#233;galement &#234;tre t&#233;l&#233;charg&#233; (Germann
et al., 2001). Deuxi&#232;mement, la relative simplicit&#233; d&#8217;un d&#233;codeur probabiliste rend assez sim-
ple l&#8217;int&#233;gration d&#8217;informations externes aux mod&#232;les probabilistes (Langlais, 2002), ce qui
n&#8217;est pas n&#233;cessairement le cas d&#8217;autres approches. Outre ces aspects pratiques, nous trou-
vons int&#233;ressante l&#8217;id&#233;e avanc&#233;e par Marcu (2001) qui mentionne que dans l&#8217;&#233;tat actuel des
technologies d&#8217;alignement (probabilistes ou non), il reste plus simple d&#8217;analyser une traduc-
tion que de la g&#233;n&#233;rer. Dans notre contexte, et peut-&#234;tre paradoxalement, cela signifie qu&#8217;il
est peut-&#234;tre plus productif d&#8217;extraire des exemples d&#8217;une m&#233;moire &#224; l&#8217;aide de mod&#232;les proba-
bilistes pour ensuite produire une traduction &#224; l&#8217;aide d&#8217;un moteur faisant usage de ces extraits</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Langlais et Michel Simard
</p>
<p>et de ces m&#234;mes mod&#232;les probabilistes, que d&#8217;utiliser directement cet engin de traduction. Les
exp&#233;riences d&#233;crites ici semblent confirmer la v&#233;racit&#233; de cette hypoth&#232;se bien que des exp&#233;ri-
mentations plus pouss&#233;es restent n&#233;cessaires &#224; sa validation.
</p>
<p>R&#233;f&#233;rences
BROWN P. F., PIETRA S. A. D., PIETRA V. J. D. &amp; MERCER R. L. (1993). The mathematics of
statistical machine translation: Parameter estimation. Computational Linguistics, 19(2), 263&#8211;311.
BROWN R. (1996). Example-based machine translation in the pangloss system. In Proceedings of
International Conference on Computational Linguistics (COLING), p. 169&#8211;174, Copenhagen, Denmark.
CLARKSON P. &amp; ROSENFELD R. (1997). Statistical language modeling using the CMU-cambridge
toolkit. In Proc. Eurospeech &#8217;97, p. 2707&#8211;2710, Rhodes, Greece.
</p>
<p>FREDERKING R., NIRENBURG S., FARWELL D., HELMREICH S., HOVY E., KNIGHT K., BEALE
S., DOMASHNEV C., ATTARDO D., GRANNES D. &amp; BROWN R. (1994). Integrating translations from
multiple sources within the pangloss mark iii machine translation. In Proceedings of the first conference
of the Association for Machine Translation in the Americas (AMTA), Columbia, MD.
GERMANN U., JAHR M., KNIGHT K., MARCU D. &amp; YAMADA K. (2001). Fast decoding and optimal
decoding for machine translation. In Proceedings of the 39th Annual Meeting of the ACL, Toulouse,
France.
</p>
<p>LANGLAIS P. (2002). Ressources terminologiques et traduction probabiliste: premiers pas positifs vers
un systeme adaptatif. In 9e Conf&#233;rence Annuelle sur le Traitement Automatique des Langues Naturelles
(TALN), p. 43&#8211;52, Nancy, France.
LANGLAIS P. &amp; SIMARD M. (2001). R&#233;cup&#233;ration d&#8217;unit&#233;s sous-phrastiques dans une m&#233;moire de
traduction. In 8e conf&#233;rence sur le Traitement Automatique des Langues Naturelles (TALN), p. 243&#8211;252,
Tours, France.
</p>
<p>MARCU D. (2001). Towards a unified approach to memory- and statistical-based machine translation.
In Proceedings of the 39th Annual Meeting of the ACL, p. 378&#8211;385, Toulouse, France.
NIESSEN S., VOGEL S., NEY H. &amp; TILLMANN C. (1998). A dp based search algorithm for statistical
machine translation. In Proceedings of the 36th Annual Meeting of the ACL and 17th COLING, p. 960&#8211;
966, Montr&#233;al, Canada.
OCH F. J. &amp; NEY H. (2000). Improved statistical alignment models. In Proceedings of the 38th Annual
Meeting of the ACL, p. 440&#8211;447, Hongkong, China.
OSBORNE M. (2000). Shallow parsing as part-of-speech tagging. In Proceedings of the 4th Computa-
tional Natural Language Learning Workshop (CoNLL), Lisbon, Portugal.
PAPINENI K., ROUKOS S., WARD T. &amp; ZHU W.-J. (2002). Bleu: a method for automatic evaluation of
machine translation. In Proceedings of the 40th Annual Meeting of the ACL, p. 311&#8211;318, Philadelphia,
Pennsylvania, USA.
</p>
<p>SIMARD M. (2003). M&#233;moire de traduction sous-phrastique. PhD thesis, Universit&#233; de Montr&#233;al.
V&#201;RONIS J. &amp; LANGLAIS P. (2000). Evaluation of parallel text alignment systems: The ARCADE
project, volume 13, chapter 19, p. 369&#8211;388. Parallel Text Processing, Kluwer.
WU D. (1997). Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3), 377&#8211;404.</p>

</div></div>
</body></html>