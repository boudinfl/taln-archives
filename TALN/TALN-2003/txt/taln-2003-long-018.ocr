TALN 2003, Batz-sur-Mer, 11-14 juin 2003

De la traduction probabiliste aux mémoires de traduction
(ou l’inverse)

Philippe Langlais et Michel Simard
RALI
Departement d’ Informatique et de Recherche Operationnelle
Universite de Montreal
CP. 6128 Succursale Centre-Ville
H3C3J7 Montreal, Quebec, Canada

{felipe,simardm}@iro.umontreal.ca

Mots-clefs — Keywords

Traduction automatique, memoire de traduction sous-phrastique, alignement sous-phrastique
Automatic translation, translation memories, word alignment

Resume - Abstract

En depit des travaux realises cette derniere decennie dans le cadre general de la traduction
probabiliste, nous sommes toujours bien loin du jour o1‘1 un engin de traduction automatique
(probabiliste ou pas) sera capable de repondre pleinement aux besoins d’un traducteur pro-
fessionnel. Dans une etude recente (Langlais, 2002), nous avons montre comment un engin
de traduction probabiliste pouvait beneﬁcier de ressources terminologiques exterieures. Dans
cette etude, nous montrons que les techniques de traduction probabiliste peuvent étre utilisees
pour extraire des informations sous-phrastiques d’une memoire de traduction. Ces informations
peuvent a leur tour s’averer utiles a un engin de traduction probabiliste. Nous rapportons des
resultats sur un corpus de test de taille importante en utilisant la memoire de traduction d’un
concordancier bilingue commercial.

Despite the exciting work accomplished over the past decade in the ﬁeld of Statistical Machine
Translation (SMT), we are still far from the point of being able to say that machine transla-
tion fully meets the needs of real-life users. In a previous study (Langlais, 2002), we have
shown how a SMT engine could beneﬁt from terminological resources, especially when trans-
lating texts very different from those used to train the system. In the present paper, we discuss
the opening of SMT to examples automatically extracted from a Translation Memory (TM).
We report results on a fair-sized translation task using the database of a commercial bilingual
concordancer.

Philippe Langlais et Michel Simard

1 Introduction

Le fait que la traduction automatique ne soit viable que dans des contextes applicatifs tres precis
(domaine limite, tache repetitive) est une evidence que les tentatives recentes, notamment dans
le domaine effervescent de la traduction probabiliste, n’ont pas reussi a dementir. Ce constat
indique que des approches d’aide a la traduction sont a privilegier (du moins pour le moment) a
une approche completement automatique. C’est dans ce contexte que des systemes de memoire
de traduction comme ceux commercialises par les ﬁrmes Trados (Translat0r’s Workbench), IBM
(Translation Manager/2), Atril (Déja-Vu) et Star AG (Transit) ont vu le jour et connaissent un
certain succes commercial.

Ces systemes operent a un niveau de granularite qui correspond grossierement a celui de la
phrase et ne sont donc utilisables que dans des contextes egalement tres precis comme la revi-
sion de documents. Des systemes travaillant a un niveau sous-phrastique existent cependant sur
le marche. C’est par exemple le cas des produits Déja-Vu et MultiTrans (MultiCorpora R&D
inc.). Il est cependant important de souligner, que ces outils ne s’appuient sur aucune technique
d’alignement sous-phrastique et font au contraire appel au bon sens des traducteurs qui ont a
charge d’alimenter leur(s) base(s) avec des alignements (sous-phrastiques ou pas) pertinents.
A notre connaissance, et au-dela des arguments commerciaux avances par les differents con-
cepteurs de logiciels de memoire de traduction, il n’existe pas d’etude qui permet d’etablir de
maniere concluante que de tels outils augmentent la productivite des utilisateurs (traducteurs ou
cabinet de traduction).

Dans une etude passee (Langlais & Simard, 2001), nous avons montre qu’une memoire de
traduction systematiquement interrogee a un niveau sous-phrastique permettait d’obtenir une
couverture (source) d’un texte a traduire de loin superieure (de 70% a 95% selon la nature
du document) a celle que l’on peut obtenir si l’on interroge la meme memoire a un niveau
phrastique. Des couvertures comparables ont ete decrites dans le cadre du systeme Pangloss
(Brown, 1996).

Nous avons egalement montre que ce taux n’est qu’un indicateur tres biaise de la réutilisabilité
d’une mémoire. D’autres etapes — non triviales dans le cas d’une memoire sous-phrastique
— telles que la selection du materiel source a aller rechercher dans la memoire, l’identiﬁcation
de son correspondant cible ainsi que les choix de presentation du materiel ramene au traducteur
sont en effet autant de facteurs qui conditionnent l’utilisabilite d’une memoire. En simulant
plusieurs scenarios, nous avons montre dans (Langlais & Simard, 2001) qu’en gros moins d’un
tiers du materiel ramene d’une memoire pouvait etre utile a la construction de moins d’un quart
du materiel cible a produire. Ces taux etaient mesures sur deux bitextes de reference de 100
paires de phrases chacun.

Dans cette etude, nous proposons une nouvelle evaluation — sur un corpus de plus grande taille
— d’un systeme d’interrogation de memoire de traduction (SIM) dont les composants ont ete
ameliores par rapport a (Langlais & Simard, 2001). Nous nous interessons de plus a veriﬁer
dans quelle mesure un moteur de traduction probabiliste ne pourrait pas beneﬁcier d’exemples
extraits automatiquement d’une memoire.

Dans la section 2, nous presentons l’architecture generale qui sous-tend les experiences que
nous avons menees et decrivons la memoire de traduction que nous avons utilisee. Dans la
section 3, nous decrivons les experiences que nous avons realisees et qui valident l’idee qu’une
memoire de traduction et un moteur de traduction peuvent faire bon menage. Nous discutons
nos experiences dans la section 4.

De la traduction probabiliste aux mémoires de traduction (ou l’inverse)

2 Architecture du systeme

Nous clariﬁons des a present que dans cette étude nous dissocions la ressource constituée de
traductions déja disponibles — et que nous appelons la mémoire de traduction — de son ex-
ploitation. La mémoire que nous utilisons ici est un énorme bitexte anglais-frangais de plus de
100 millions de mots par langue aligné au niveau de la phrase. Ce matériel contient tous les
textes parlementaires canadiens publiés entre avril 1986 et décembre 2001 et constitue le coeur
de la mémoire a laquelle ont acces les utilisateurs du systeme commercial TSRali . com 1.

Une vue d’ensemble de l’architecture est offerte en ﬁgure 1.

 
  

I

I

: this is the responsible thing to do . on a tente de trouver une echappatoire
I an effort was made to find a loophole le sens des responsabilites l’exige
I

: bitexte

I

I

I SIM

I

: selection

I alignement —> briqgtes —>

: ﬁgtmge traductwnnelles

I

I

 

texte a traduire EVAL ‘j traduction

Figure 1: Architecture utilisée dans cette étude. Voir le texte pour des explications.

2.1 Le moteur de traduction (STS)

/99

Le systeme de traduction statistique utilisé ici est un systeme “canal bruite mettant en jeu
un modele de langue (modele trigramme interpolé), et un modele de traduction de type IBM2
(Brown et al., 1993). Les modeles embarqués ont été entrainés sur un sous-ensemble d’environ
1.6 million de paires de phrases de la mémoire. Le décodage est effectué par programmation
dynamique selon une amelioration de la méthode décrite par NieBen et al. (1998). L’ algorithme
de recherche proposé s’accommode de plus de contraintes “ﬂottantes” exprimées sous la forme
de lexiques bilingues. Le décodeur garantit alors qu’une des traductions possibles de chaque
unité source du lexique qui se trouve dans la phrase a traduire sera proposée dans la traduction.
Le choix de l’unité cible (dans le cas ou le lexique amende plusieurs traductions) et de sa
position dans la traduction est déterminé de maniere a optimiser sur la phrase, les predictions
des modeles de langue et de traduction. La ﬁgure 2 montre un exemple de traduction produite
par le décodeur lorsqu’on lui foumit un lexique bilingue (smt + mt).

1Consulter la page http : / /www . t srali . com pour plus d’infonnation.

Philippe Langlais et Michel Simard

2.2 Le systéme d’interrogation de la mémoire de traduction (SIM)

Le systeme d’interrogation de la memoire est base sur trois operations automatiques dont la
precision conditionne le succes de l’architecture au complet.

sélection consiste a selectionner dans le materiel a traduire des sequences de mots avec les-
quelles interroger la memoire. Nous appelons ces sequences les requétes.

Dans cette etude, le texte a traduire est tout d’abord decoupe en chunks a l’aide d’une cascade
de modeles markoviens qui etiquette chaque mot par un marqueur de debut, ou d’intermediaire
de groupe (voir (Osborne, 2000) pour la description de la cascade de distributions modelisees
en pratique). Toute sequence de chunks presente dans la memoire est alors une requete valide.
Cette etape de segmentation en groupes simples n’est pas indispensable, mais nous pensons
qu’elle permet de limiter les requetes a des groupes de mots dont la traduction dans le texte
cible est plus facile a localiser.

Dans l’eXemple de la ﬁgure 2, 15 requetes sont valides; leur frequence d’apparition dans la
memoire est indiquee entre crochets; au total 564 couples de phrases sont selectionnes dans la
memoire.

alignement consiste a identiﬁer dans les paires de phrases de la memoire qui contiennent les
requetes, leur traduction. Nous appelons les couples requete/materiel cible extrait de la memoire
les briques traductionnelles.

Aligner des phrases au niveau des mots est une tache difﬁcile. Dans le projet ARCADE, qui etait
dedie a l’evaluation d’alignements bilingues, il a ete montre que les meilleurs systemes testes
obtenaient une performance de l’ordre de 75% (precision et rappel) dans une tache simpliﬁee
de localisation (dans un bitexte) des traductions de 60 mots choisis (Veronis & Langlais, 2000).

Nous avons experimente differentes strategies d’alignement qui sont decrites et analysees dans
(Simard, 2003). La technique d’alignement que nous avons retenue ici est une version simpli-
ﬁee des grammaires stochastiques proposees par Wu (1997) qui consiste a detecter de maniere
descendante des points de coupures binaires dans la paire de phrase a aligner, jusqu’a isoler
(lorsque c’est possible) le segment dont on cherche la traduction. Le choix du decoupage est
fait en consultant le modele de traduction.

Dans notre exemple, 355 briques traductionnelles differentes ont ainsi ete identiﬁees, parmi
lesquelles 316 (89%) ont ete rencontrees une seule fois dans la memoire.

ﬁltrage consiste a selectionner les briques traductionnelles qui seront ﬁnalement proposees
au traducteur ou au moteur de traduction. Nous avons experimente differentes strategies de
ﬁltrage (dont le detail n’est pas pertinent ici) comme des seuillages (sur la probabilite des asso-
ciations ou sur leur frequence dans la memoire), ou encore la selection des requétes de maniere
a maximiser (par exemple) la couverture de la phrase a traduire.

Dans notre exemple, des 355 briques traductionnelles identiﬁees, seulement 8 sont ﬁnalement
conservees.

2.3 Module d’évaluation (EVAL)

Ce module vise deux objectifs; d’une part de mesurer le taux de recuperabilite des briques
traductionnelles extraites de la memoire, d’autre part de veriﬁer si un systeme de traduction

De la traduction probabiliste aux mémoires de traduction (ou l’inverse)

probabiliste peut bénéﬁcier du matériel extrait automatiquement d’une mémoire a l’aide des
memes modeles que le moteur utilise. Dans les deux cas, nous utilisons un bitexte de référence
dont la partie cible (une traduction produite par un humain) est le texte que nous cherchons a
reproduire (traduction oracle).

2.3.1 Taux de couverture et de précision

Les deux taux suivants sont indépendants du moteur de traduction et tentent de mesurer directe-
ment la réutilisabilité des briques traductionnelles extraites de la mémoire.

Le taux de couverture source (resp. cible) est le pourcentage de mots sources (resp. cibles)
du bitexte de référence qui sont couverts par le matériel source (resp. cible) des briques traduc-
tionnelles. Ces taux sont mesurés sur les briques traductionelles entieres issues de l’étape de
ﬁltrage.

Dans l’exemple de la ﬁgure 2, les trois requétes retenues (for the translation, immediately with-
out waiting et will the minister table the report) couvrent douze des treize mots de la phrase
a traduire, la couverture source est donc de 12/13 (92.3%). De la meme maniere, les briques
cibles (la traduction et sans attendre) couvrent quatre des douze mots de la traduction oracle;
la couverture cible est donc de 4/12 (33%).

Taux de précision et de rappel. Des lors que l’on s’intéresse a la couverture cible, nous
avons montré dans (Langlais & Simard, 2001) qu’il était préférable de mesurer des taux de
précision et de rappel. Il est en effet possible de maximiser la couverture cible en gardant toutes
les traductions potentielles de toutes les requétes valides, et ce au détriment d’un utilisateur qui
se verrait submerge de matériel cible.

Dans un contexte d’évaluation automatique, cela signiﬁe qu’il nous faut faire des hypotheses
quant a l’usage que ferait un utilisateur du matériel cible qu’on lui propose. Dans cette étude,
nous avons imaginé qu’un utilisateur (ﬁctii) produit la traduction oracle en copiant/collant tout
ou partie du matériel cible qui lui est proposé. Nous déﬁnissons alors la précision PC comme de
rapport du nombre de mots collés dans la traduction sur le nombre de mots cibles des briques
traductionnelles. Le taux de rappel RC est quant a lui mesuré par le ratio du nombre de mots
collés sur le nombre de mots cibles de la traduction oracle. La encore, il est important d’ observer
que les taux ainsi mesurés dépendent grandement de la facon avec laquelle on admet qu’un
utilisateur sélectionnera des mots dans une brique traductionnelle. Nous admettons ici qu’il
copiera au plus une séquence de mots d’au moins c mots de chaque brique traductionnelle.
c = 0 désigne le scénario ou le traducteur ne fera que copier/coller des briques cibles entieres.
Ces deux taux peuvent étre résumés en un seul (la f-mesure) qui est leur moyenne harmonique.

Dans notre exemple, si l’on admet que l’utilisateur ne fait que des copier/coller de briques cibles
entieres (c = 0), alors 11 mots (ceux des briques dont la partie cible est en gras) sont copiés sur
un total de 30 mots cibles proposés, d’o1‘1 une précision P0 de 11/30 (soit 36.6%). Le rappel R0
est alors de 11/13 (soit 84.6%).

2.3.2 Mesures automatiques de la qualité d’une traduction

Une maniere indirecte de mesurer la réutilisabilité des briques traductionnelles est de vériﬁer
leur apport a la qualité d’une traduction. Bien qu’indirecte, cette évaluation présente l’avantage

Philippe Langlais et Michel Simard

input:
source will the minister table the report immediately without waiting for the translation ?
oracle le ministre va il déposer immédiatement le rapport sans attendre la traduction ?

requétes:

will the minister table [64], will the minister table the report [3], the minister table [98], the
minister table the report [4], the report [100], the report immediately [1], immediately without
[34], immediately without waiting [1], immediately without waiting for [1], without waiting
[62], without waiting for [49], waiting for [98], waiting for the translation [3], for the transla-
tion [6], the translation [40]

briques traductionnelles:

for the translation la traduction

for the translation pour entendre la traduction
for the translation pour la traduction de

for the translation pour qu’

immediately without waiting sans attendre

will the minister table the report le comité
will the minister table the report le Ininistre déposera il le rapport sur
will the minister table the report le n1inistre va il déposer le rapport

output:
smt le Ininistre de déposer le rapport sans attendre la suite de la traduction ?

smt+mt le ministre va il déposer le rapport sans attendre la traduction ?

alignements:

REF: le min va il dép imm le rap san att la tra ?
SMT: le min de dép le rap san att la suite de la tra ?
SMT+: le min va il dép le rap san att la tra ?

Figure 2: Illustration sur une session de traduction simple des principales étapes de
l’architecture décrite. Voir le texte pour des explications.

de pouvoir s’appuyer sur des métriques existantes. Nous comparons ici la qualité des traduc-
tions produites par notre moteur de traduction avec et sans brique traductionnelle a l’aide de
trois mesures automatiques qui sont couramment utilisées dans la littérature.

BLEU est une mesure qui comptabilise de maniere pondérée le nombre d’unigrammes, de
bigrammes, de trigrammes et de quadigrammes qu’une traduction a évaluer partage avec une
ou plusieurs traductions oracles. Les valeurs que peuvent prendre cette mesure sont entre 0 et
1; une valeur de 1 indiquant une bonne traduction. Papineni et al. (2002) rapportent que cette
mesure est corrélée a des jugements produits par des humains. C’est la mesure qui est utilisée
dans les évaluations NIST. Pour des questions de lisibilité nous multiplions par 100 les scores
obtenus par le programme mt—eval disponible sur le site de NIST 2.

Deux traductions sont rapportées dans l’eXemple de la ﬁgure 2. La premiere (smt) est produite
par le moteur probabiliste seul et obtient un score BLEU de 39.07; la seconde (smt + mt), est

Zhttp://wwww.nist.gov/speech/tests/mt/doc/index.htm

De la traduction probabiliste aux memoires de traduction (ou l’inverse)

obtenue par le moteur de traduction alimente par les briques traductionnelles et son score BLEU
est de 76.77.

WER est une version normalisee de ce que l’on appelle la distance d’edition (le nombre
d’operations d’edition minimum qu’il faut appliquer a la traduction candidate pour obtenir la
traduction oracle). Les valeurs de WER sont exprimees entre 0 et 100; une valeur de 0 indique
une traduction identique a la traduction oracle.

Dans notre exemple, le moteur de traduction seul propose une traduction dont le WER est de
37.5, alors que la traduction qu’il propose lorsque les briques traductionnelles sont disponibles
est de 7.7. Les alignements respectifs a la traduction oracle sont indiques a meme la ﬁgure 2.

SER est le pourcentage de traductions qui ne sont pas identiques verbatim a la traduction
oracle. Cette mesure est bien sﬁ tres severe (une traduction pouvant etre bonne sans pour autant
etre celle produite par l’oracle). Dans notre exemple, aucune des deux traductions proposees
n’est identique a la traduction oracle, et le SER sur ce corpus d’une phrase est donc de 100 dans
les deux cas.

3 Experiences

Nous avons extrait du Hansard un passage de mars 2002 (une periode non couverte par la
memoire de traduction) constitue de 1646 phrases de longueur source (resp. cible) moyenne de
23 (resp. 20) mots. Dans cette experience, nous avons choisi la langue anglaise comme langue
source car la traduction oracle a ete produite dans cette direction.

Il existe de nombreux parametres qui sont ajustables dans l’architecture que nous avons presen-
tee. Nous pouvons en particulier selectionner la nature des requetes faites a la memoire de
meme que la quantite de briques traductionnelles ramenees (en tenant compte de differents
criteres de selection). Nous avons teste dans cette experience 462 instances de l’architecture
dont les details ne sont pas pertinents ici.

3.1 Couverture des briques traductionnelles

En terme de couverture source, les variantes testees different sensiblement selon la quantite de
ﬁltres appliques de 68% a 80%, la moyenne entre tous ces systemes etant de 74.7% (ecart-type
de 3.9%). Les differences les plus importantes sont de maniere naturelle observees sur les taux
de couverture cible. Les conﬁgurations les plus ﬁltrantes (celles ou par exemple on decide de
ne retenir qu’une brique traductionnelle par requéte) montrent des taux de couverture cible de
l’ordre de 10%. Les conﬁgurations les plus permissives plafonnent quant a elles a 68%. La
moyenne des conﬁgurations est de 28.4% (ecart type de 12.4%). Ces observations sont encore
une fois coherentes avec les mesures faites dans (Langlais & Simard, 2001).

La table 1 montre parIr1i l’ensemble des conﬁgurations pour chaque scenario, les taux de pre-
cision, de rappel et de f-mesure que l’on obtient en maximisant ou bien la f-mesure (deuxieme
colonne), ou bien la precision (troisieme colonne). Les conﬁgurations qui correspondent a
ces mesures sont toutes des conﬁgurations ou une seule brique traductionnelle a ete conservee

Philippe Langlais et Michel Simard

par requéte; ce sont également les conﬁgurations qui montrent des taux de couverture cible
minimum; ce qui conﬁrme que les taux de couverture ne sont pas de bons indicateurs de la
récupérabilité d’une mémoire.

On observe également que si plus de la moitié des briques traductionnelles proposées a un util-
isateur permet de reconstruire un peu moins de la moitié d’une traduction oracle en sélectionnant
des séquences d’un mot ou plus dans ce matériel (c = 1), ces taux de récupérabilité diIr1inuent
avec la taille des segments que l’utilisateur s’autorise a copier. A l’extréme, un utilisateur qui ne
pourrait que cliquer sur les briques proposées pour construire sa traduction (c = O) ne pourrait
utiliser qu’un sixieme environ des briques proposées pour construire a peu pres un cinquieme de
sa traduction. Ces chiffres sont plus faibles que ceux que nous avions mesurés dans (Langlais
& Simard, 2001) sur le matériel Hansard testé a ce moment. La taille plus grande du corpus de
test utilisé ici et le fait que ce soit un texte d’une période non couverte par la mémoire sont des
explications possibles de cette différence.

meilleure F6 meilleure PC

PC RC F6 PC RC

14.1 19.9 16.5 18.6 10.5
56.9 42.3 48.6 57.1 32.0
34.4 25.6 29.3 34.4 25.6
24.7 18.4 21.0 24.7 18.4
17.2 12.8 14.7 17.2 12.8

-l>UJ[\)>—tOO

Table 1: Taux de précision et rappel en fonction du scénario utilisateur. La deuxieme colonne
montre les meilleures f-mesures que l’on obtient parIr1i toutes les versions testées; la troisieme
colonne montre les conﬁgurations avec la meilleure précision.

3.2 Qualité de la traduction

Nous rapportons en table 2 les résultats de traduction obtenus par notre décodeur avec et sans
les briques traductionnelles en fonction de la longueur maximale des phrases considérées3. On
note clairement ici la corrélation entre les différentes métriques et la longueur maximale des
phrases traduites: traduire une phrase plus courte est en moyenne plus facile. On observe
également l’amélioration systématique que les briques traductionnelles ont sur la qualité (telle
que mesurée) des traductions produites, et ce, quelque soit la longueur maximale des phrases
considérées. L’ amélioration relative de score BLEU mesurée pour l’ensemble des phrases d’au
plus 30 mots est de 46.8%. Ce résultat est tres intéressant et conﬁrme les observations faites
par Marcu (2001), et ce, méme si les protocoles expérimentaux entre les deux études sont assez
différents. En particulier, il est important de souligner que dans nos expériences, les modeles de
traduction et de langue ont été entrainés sur une petite portion de la mémoire utilisée ici et qu’il
n’est pas du tout certain que nous aurions observé de telles améliorations si les modeles avaient
été entrainés sur l’ensemble de la mémoire. I1 convient cependant d’ajouter que l’entrainement
d’un modele de traduction sur des quantités de textes supérieures a celles utilisées dans cette
étude n’est pas une tache simple4 et qu’il existe a notre avis de nombreuses situations o1‘1iln’est

3Seu1es les phrases d’au plus 30 mots ont été traduites ici.
4Des contraintes pratiques mais bien réelles, notamment de mémoire vive, font que Pentrainement de gros
modéles nécessite entre autres choses une version paralléle de 1’a1gorithme d’entrainement.

De la traduction probabiliste aux mémoires de traduction (ou l’inverse)

SMT + MT SMT
L nb. BLEU WER SER perfect BLEU WER SER ratio
5 199 28.94 52.57 83.42 33 18.07 58.06 91.96 60.1
10 397 25.04 55.82 89.42 42 18.84 59.39 95.46 32.9
15 646 24.00 59.56 93.03 45 17.53 62.39 97.21 36.9
20 890 24.93 60.51 94.72 47 16.87 63.66 97.98 47.8
25 1026 23.65 62.24 95.42 47 15.98 64.64 98.25 48.0
30 1126 23.46 63.01 95.83 47 15.98 65.07 98.40 46.8

Table 2: Mesures de la qualité des traductions produites par le décodeur seul (SM T) et par le
décodeur aidé des briques traductionnelles (S M T + MT). ratio indique l’amélioration relative
du score BLEU.

pas envisageable d’entrainer “régulierement” de nouveaux modeles, alors qu’il est assez simple
de mettre a jour une mémoire de traduction.

4 Discussions

Nous avons proposé deux types d’évaluation de la récupérabilité d’une mémoire de traduc-
tion sous-phrastique. Nous avons montré sur un corpus de test de taille importante que les
taux de précision et de rappel des briques traductionnelles extraites de la mémoire étaient loin
d’approcher les taux de couvertures sources et cibles que l’on rapporte habituellement. Il est
important de noter cependant que le fait de n’utiliser qu’une traduction de référence ne nous
permet que de mesurer une borne inférieure de récupérabilité d’une mémoire. Nous montrons
enﬁn, que les briques traductionnelles aident un engin de traduction probabiliste a proposer des
traductions de meilleure qualité (dans la liIr1ite de la pertinence des métriques utilisées ici).

L’ idée d’utiliser des exemples extraits d’une mémoire pour générer ensuite une traduction n’est
pas nouvelle et sous-tend en fait tout systeme de traduction a base d’exemples. Le systeme
Pangloss (Frederking et al. , 1994; Brown, 1996) utilisait par exemple un modele de langue pour
assembler les exemples extraits de différentes ressources et différents systemes de traduction.
L’ utilisation d’un moteur de traduction probabiliste pour assembler des exemples est cependant
moins populaire.

Nous voyons cependant plusieurs avantages a utiliser un moteur de traduction probabiliste pour
assembler des exemples. Premierement, il convient de rappeler que la réalisation d’un mo-
teur probabiliste est une opération relativement aisée. Des packages simples a utiliser sont
en effet disponibles pour l’entrainement des modeles de langue (Clarkson & Rosenfeld, 1997)
et de traduction (Och & Ney, 2000) et un décodeur peut également étre téléchargé (Germann
et al., 2001). Deuxiemement, la relative simplicité d’un décodeur probabiliste rend assez sim-
ple l’intégration d’informations externes aux modeles probabilistes (Langlais, 2002), ce qui
n’est pas nécessairement le cas d’autres approches. Outre ces aspects pratiques, nous trou-
vons intéressante l’idée avancée par Marcu (2001) qui mentionne que dans l’état actuel des
technologies d’alignement (probabilistes ou non), il reste plus simple d’analyser une traduc-
tion que de la générer. Dans notre contexte, et peut-étre paradoxalement, cela signiﬁe qu’il
est peut-étre plus productif d’extraire des exemples d’une mémoire a l’aide de modeles proba-
bilistes pour ensuite produire une traduction a l’aide d’un moteur faisant usage de ces extraits

Philippe Langlais et Michel Simard

et de ces memes modeles probabilistes, que d’utiliser directement cet engin de traduction. Les
expériences décrites ici semblent conﬁrmer la véracité de cette hypothese bien que des experi-
mentations plus poussées restent nécessaires a sa validation.

Références

BROWN P. F., PIETRA S. A. D., PIETRA V. J. D. & MERCER R. L. (1993). The mathematics of
statistical machine translation: Parameter estimation. Computational Linguistics, 19(2), 263-311.

BROWN R. (1996). Example-based machine translation in the pangloss system. In Proceedings of
International Conference on Computational Linguistics (COLING), p. 169-174, Copenhagen, Denmark.

CLARKSON P. & ROSENFELD R. (1997). Statistical language modeling using the CMU-cambridge
toolkit. In Proc. Eurospeech ’97, p. 2707-2710, Rhodes, Greece.

FREDERKING R., NIRENBURG S., FARWELL D., HELMREICH S., HOVY E., KNIGHT K., BEALE
S., DOMASHNEV C., ATTARDO D., GRANNES D. & BROWN R. (1994). Integrating translations from
multiple sources within the pangloss mark iii machine translation. In Proceedings of the ﬁrst conference
of the Association for Machine Translation in the Americas (AMTA), Columbia, MD.

GERMANN U., JAHR M., KNIGHT K., MARCU D. & YAMADA K. (2001). Fast decoding and optimal
decoding for machine translation. In Proceedings of the 39th Annual Meeting of the ACL, Toulouse,
France.

LANGLAIS P. (2002). Ressources terminologiques et traduction probabiliste: premiers pas positifs vers
un systeme adaptatif. In 9e Conférence Annuelle sur le Traitement Automatique des Langues Naturelles
(TALN), p. 43-52, Nancy, France.

LANGLAIS P. & SIMARD M. (2001). Récupération d’unités sous-phrastiques dans une mémoire de
traduction. In 8e conférence sur le Traitement Automatique des Langues Naturelles (TALN), p. 243-252,
Tours, France.

MARCU D. (2001). Towards a uniﬁed approach to memory- and statistical-based machine translation.
In Proceedings of the 39th Annual Meeting of the ACL, p. 378-385, Toulouse, France.

NIESSEN S., VOGEL S., NEY H. & TILLMANN C. (1998). A dp based search algorithm for statistical
machine translation. In Proceedings of the 36th Annual Meeting of the ACL and 17th COLING, p. 960-
966, Montreal, Canada.

OCH F. J. & NEY H. (2000). Improved statistical alignment models. In Proceedings of the 38th Annual
Meeting of the ACL, p. 440-447, Hongkong, China.

OSBORNE M. (2000). Shallow parsing as part-of-speech tagging. In Proceedings of the 4th Computa-
tional Natural Language Learning Workshop (CoNLL), Lisbon, Portugal.

PAPINENI K., ROUKOS S., WARD T. & ZHU W.-J. (2002). Bleu: a method for automatic evaluation of
machine translation. In Proceedings of the 40th Annual Meeting of the ACL, p. 311-318, Philadelphia,
Pennsylvania, USA.

SIMARD M. (2003). Me’moire de traduction sous-phrastique. PhD thesis, Université de Montréal.

VERONIS J. & LANGLAIS P. (2000). Evaluation of parallel text alignment systems: The ARCADE
project, volume 13, chapter 19, p. 369-388. Parallel Text Processing, Kluwer.

WU D. (1997). Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3), 377-404.

