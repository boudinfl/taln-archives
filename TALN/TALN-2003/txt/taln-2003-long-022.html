<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Am&#233;lioration de liens entre acceptions par fonctions lexicales vectorielles sym&#233;triques</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2003, Batz-sur-Mer, 11&#8211;14 juin 2003
</p>
<p>Am&#233;lioration de liens entre acceptions par fonctions lexicales
vectorielles sym&#233;triques
</p>
<p>Didier Schwab, Mathieu Lafourcade et Violaine Prince
LIRMM
</p>
<p>Laboratoire d&#8217;informatique, de Robotique
et de Micro&#233;lectronique de Montpellier
</p>
<p>MONTPELLIER - FRANCE.
{schwab,lafourca,prince}@lirmm.fr
</p>
<p>http://www.lirmm.fr/ &#732;{schwab, lafourca, prince}
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>repr&#233;sentation th&#233;matique, vecteurs conceptuels, fonctions lexicales, acceptions
thematic representation, conceptuals vectors, lexical functions, acceptions
</p>
<p>R&#233;sum&#233; - Abstract
</p>
<p>Dans le cadre du projet Papillon qui vise &#224; la construction de bases lexicales multilingues par ac-
ceptions, nous avons d&#233;fini des strat&#233;gies pour peupler un dictionnaire pivot de liens interlingues &#224;
partir d&#8217;une base vectorielle monolingue. Il peut y avoir un nombre important de sens par entr&#233;e et
donc l&#8217;identification des acceptions correspondantes peut &#234;tre erron&#233;e. Nous am&#233;liorons l&#8217;int&#233;grit&#233;
de la base d&#8217;acception gr&#226;ce &#224; des agents experts dans les fonctions lexicales comme la synonymie,
l&#8217;antonymie, l&#8217;hyp&#233;ronymie ou l&#8217;holonymie. Ces agents sont capable de calculer la pertinence d&#8217;une
relation s&#233;mantique entre deux acceptions par les diverses informations lexicales r&#233;colt&#233;es et les
vecteurs conceptuels. Si une certaine pertinence est au-dessus d&#8217;un seuil, ils cr&#233;ent un lien s&#233;mantique
qui peut &#234;tre utilis&#233; par d&#8217;autres agents charg&#233;s par exemple de la d&#233;sambigu&#239;sation ou du transfert
lexical. Les agents v&#233;rifiant l&#8217;int&#233;grit&#233; de la base cherchent les incoh&#233;rences de la base et en avertis-
sent les lexicographes le cas &#233;ch&#233;ant.
</p>
<p>In the framework of the Papillon project, we have defined strategies for populating a pivot dictionnary
of interlingual links from monolingual vectorial bases. There are quite a number of acceptions per
entry thus, the proper identification may be quite troublesome and some added clues beside acception
links may be useful. We improve the integrity of the acception base through well known semantic
relations like synonymy, antonymy, hyperonymy and holonymy relying on lexical functions agents.
These semantic relation agents can compute the pertinence of a semantic relation between two accep-
tions thanks to various lexical informations and conceptual vectors. When a given pertinence score is
above a threshold they create a semantic link which can be walked through by other agents in charge
of WSD ot lexical transfert. Base integrity agents walk throw the acceptions, look for incoherences
in the base and emit warning toward lexicographs when needed.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Didier Schwab, Mathieu Lafourcade et Violaine Prince
</p>
<p>1 Introduction
</p>
<p>La recherche en repr&#233;sentation de sens est un important probl&#232;me qui a &#233;t&#233; abord&#233; selon plusieurs ap-
proches. Notre &#233;quipe travaille actuellement sur l&#8217;analyse th&#233;matique de textes et la d&#233;sambigu&#239;sation
lexicale (Lafourcade, 2001). Nous construisons un syst&#232;me capable d&#8217;apprentissage automatique bas&#233;
sur les vecteurs conceptuels. Les vecteurs contiennent les id&#233;es associ&#233;es aux mots ou expressions.
Le syst&#232;me d&#8217;apprentissage construit ou r&#233;vise automatiquement les vecteurs conceptuels &#224; partir de
d&#233;finitions en langage naturel contenues dans les dictionnaires &#224; usage humain. Dans le cadre du pro-
jet Papillon, nous avons d&#233;fini des strat&#233;gies pour peupler un dictionnaire pivot de liens interlingues
(des acceptions) &#224; partir d&#8217;une base vectorielle monolingue. L&#8217;architecture g&#233;n&#233;rale a &#233;t&#233; d&#233;crite dans
(S&#233;rasset and Mangeot, 2001) et (Mangeot, 2001). Un dictionnaire pivot (que nous nommerons aussi
dictionnaire par acceptions) peut &#234;tre utilis&#233; avantageusement pour la d&#233;sambigu&#239;sation et le trans-
fert lexical. Il y a un certain nombre de sens par entr&#233;e (environ 5 sens dans nos exp&#233;riences pour
le fran&#231;ais) et donc l&#8217;identification des acceptions correspondantes peut &#234;tre erron&#233;e. L&#8217;am&#233;lioration
de l&#8217;int&#233;grit&#233; de la base d&#8217;acceptions peut &#234;tre r&#233;alis&#233;e gr&#226;ce &#224; des &#8220;agents experts&#8221; en relations s&#233;-
mantiques comme la synonymie, l&#8217;antonymie, l&#8217;hyp&#233;ronymie ou l&#8217;holonymie. Ces agents peuvent
calculer la pertinence d&#8217;une relation s&#233;mantique entre deux acceptions en conjuguant diverses infor-
mations lexicales et les vecteurs conceptuels. Lorsqu&#8217;un taux de pertinence est au-dessus d&#8217;un certain
seuil, ils peuvent mat&#233;rialiser un lien s&#233;mantique qui peut &#234;tre utilis&#233; par d&#8217;autres agents en charge
de la d&#233;sambigu&#239;sation ou du transfert lexical. Les agents v&#233;rifiant l&#8217;int&#233;grit&#233; de la base cherchent
les incoh&#233;rences de la base et en avertissent les lexicographes le cas &#233;ch&#233;ant. Dans cet article, nous
pr&#233;sentons, dans un premier temps, le mod&#232;le des vecteurs conceptuels puis celui du dictionnaire par
acception. Ensuite nous pr&#233;senterons les diverses fonctions lexicales et nous montrerons comment les
agents peuvent les utiliser pour cr&#233;er des liens ou les &#233;valuer.
</p>
<p>2 Vecteurs conceptuels
</p>
<p>Nous repr&#233;sentons les aspects th&#233;matiques des segments textuels (documents, paragraphes, syn-
tagmes, etc) par des vecteurs conceptuels. Les vecteurs ont &#233;t&#233; utilis&#233;s en informatique documentaire
pour la recherche d&#8217;information (Salton et MacGill, 1983). Leur emploi pour la repr&#233;sentation du
sens est plus le fait du mod&#232;le LSI (Deerwester et al, 90) issue de l&#8217;analyse s&#233;mantique latente en
psycho-linguistique. En informatique, et de fa&#231;on presque concurrente, c&#8217;est &#224; partir de (Chauch&#233;,
90) que l&#8217;on a une formalisation de la projection de la notion, linguistique cette fois, de champ s&#233;-
mantique dans un espace vectoriel. &#192; partir d&#8217;un ensemble de notions &#233;l&#233;mentaires dont nous faisons
l&#8217;hypoth&#232;se, les concepts, il est possible de construire des vecteurs (dits conceptuels) et de les associer
&#224; des items lexicaux1. Les termes polys&#233;miques combinent les diff&#233;rents vecteurs correspondant aux
diff&#233;rents sens. Cette approche vectorielle est fond&#233;e sur des propri&#233;t&#233;s math&#233;matiques bien connues
sur lesquelles il est possible d&#8217;effectuer des manipulations formellement pertinentes auxquelles sont
attach&#233;es des interpr&#233;tations linguistiques raisonnables. Les concepts sont donn&#233;s a priori. Dans notre
exp&#233;rimentation sur le fran&#231;ais nous utilisons (Larousse, 1992) dans lequel sont d&#233;finis 873 concepts.
L&#8217;hypoth&#232;se principale du th&#233;saurus, que nous adoptons ici, est que cet ensemble constitue un espace
g&#233;n&#233;rateur pour les termes et leurs sens. D&#8217;une fa&#231;on plus g&#233;n&#233;rale, n&#8217;importe quel sens peut s&#8217;y
projeter selon le principe suivant.
</p>
<p>1Les items lexicaux sont des mots ou des expressions qui constituent les entr&#233;es du lexique. Par exemple, &#0; voiture &#1; ou
&#0; pomme de terre &#1; sont des items lexicaux. Dans la suite, par abus de langage, nous utiliserons parfois mot ou terme pour
qualifier un item lexical. Nous noterons les items en minuscule et entre apostrophes ( &#0; vie &#1; ) et les concepts en majuscules
( VIE ).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Am&#233;lioration de liens entre acceptions par fonctions lexicales vectorielles
</p>
<p>Soit
&#2;
</p>
<p>un ensemble fini de &#3; concepts, un vecteur conceptuel &#4; est une combinaison lin&#233;aire d&#8217;&#233;l&#233;ments
&#5;&#7;&#6; de
</p>
<p>&#2;
</p>
<p>. Pour une id&#233;e &#8; , le vecteur &#4;&#10;&#9; est la description en extension des activations de tous les con-
cepts de
</p>
<p>&#2;
</p>
<p>. Par exemple, les diff&#233;rents sens de &#11; vie &#12; peuvent &#234;tre projet&#233;s sur les concepts suivants
(les CONCEPT &#13; intensit&#233; &#14; sont ordonn&#233;s par valeurs d&#233;croissantes) : &#4;&#15;&#11; vie &#12; = (VIE &#13; 0.7 &#14; , NAISSANCE &#13; 0.48 &#14; ,
ENFANCE &#13; 0.46 &#14; , MORT &#13; 0.43 &#14; , VIEILLESSE &#13; 0.41 &#14; , . . . ) En pratique, plus &#2; est large, plus fines sont les de-
scriptions de sens mais plus leur manipulation est lourde. Il est clair que pour les vecteurs denses,
ceux qui ont peu de coordonn&#233;es nulles, l&#8217;&#233;num&#233;ration des concepts activ&#233;s est longue et la pertinence
difficile &#224; &#233;valuer. En g&#233;n&#233;ral, pour &#233;valuer la qualit&#233; d&#8217;un vecteur, nous pr&#233;f&#232;rerons s&#233;lectionner les
termes th&#233;matiquements proches, le voisinage (not&#233; &#16; ). Par exemple, pour &#11; vie &#12; : &#16; ( &#11; vie &#12; ) : &#11; vie &#12; ,
&#11; vivant &#12; , &#11; en vie &#12; , &#11; na&#238;tre &#12; , . . . Cette op&#233;ration est r&#233;alis&#233;e &#224; l&#8217;aide de la distance angulaire.
</p>
<p>2.1 Distance angulaire
</p>
<p>Soit &#17;&#19;&#18;&#21;&#20;&#23;&#22;&#25;&#24;ff&#26;flfi&#31;ffi une des mesures de similarit&#233; entre deux vecteurs X et Y, souvent utilis&#233;e en recherche
d&#8217;information (Morin, 1999). &#17;&#19;&#18;&#21;&#20;&#23;&#22;&#25;&#24;ff&#26;flfi&#31;ffi! #&quot;%$'&amp;(&#22;*)&#24;ff&#26;flfi+ffi, -/. 01
</p>
<p>-
</p>
<p>13241
</p>
<p>0
</p>
<p>1 avec &#8220; 5 &#8221; d&#233;signant le produit
scalaire. Nous supposons ici que les composants des vecteurs sont positifs ou nuls, la distance angu-
laire entre deux vecteurs &#24; et fi est 67&#9;8&#22;&#25;&#24;9&#26;&#7;fi+ffi: &lt;;&gt;=?&quot;%&quot;@$'&amp;A&#22;&#21;&#17;&#19;&#18;B&#20;&#23;&#22;&#25;&#24;9&#26;&#7;fi&#31;ffi3ffi . Intuitivement, cette fonction
constitue une &#233;valuation de la proximit&#233; th&#233;matique et en pratique la mesure de l&#8217;angle entre les deux
vecteurs. Nous consid&#233;rons en g&#233;n&#233;ral que pour une distance 6!&#9;8&#22;&#25;&#24;9&#26;&#7;fi+ffiDCFEG ( HJILK ), X et Y sont th&#233;-
matiquement proches et partagent plusieurs concepts. Pour 6M&#9;8&#22;&#25;&#24;9&#26;&#7;fi+ffiONPEG , la proximit&#233; th&#233;matique
est consid&#233;r&#233;e comme faible et aux alentours de E Q ( R'SLK ), X et Y n&#8217;ont aucune relation. On remarquera
que ces seuils ne servent que d&#8217;indicateurs pour un r&#233;viseur humain et restent &#224; la fois subjectifs et
arbitraires. 6T&#9; est une vraie distance, elle v&#233;rifie donc les propri&#233;t&#233;s de r&#233;flexivit&#233;, de sym&#233;trie et
d&#8217;in&#233;galit&#233; triangulaire. Nous obtenons, par exemple, les angles suivants2.
UWV (V( &#0; locomotive &#1; ), V( &#0; locomotive &#1; ))=0 ( XAY ) UWV (V( &#0; locomotive &#1; ), V( &#0; locomotrice &#1; ))=0.24 ( Z\[]Y )
U
</p>
<p>V (V( &#0; locomotive &#1; ), V( &#0; automotrice &#1; ))=0.22 ( Z?^AY ) U V (V( &#0; locomotive &#1; ), V( &#0; train &#1; ))=0.54 ( ^(Z_Y )
U
</p>
<p>V (V( &#0; locomotive &#1; ), V( &#0; rhododendron &#1; ))=1.15 ( `%abY ) U V (V( &#0; locomotive &#1; ), V( &#0; gu&#233;pard &#1; ))=0,94 ( a&#7;[(Y )
Le premier r&#233;sultat a une interpr&#233;tation directe, &#11; locomotive &#12; ne peut &#234;tre plus proche d&#8217;autre chose que
de lui m&#234;me. Les termes &#11; automotrice &#12; et &#11; locomotrice &#12; sont synonymes de &#11; locomotive &#12; , ce qui explique
les deux r&#233;sultats suivants. Le peu de rapports entre &#11; locomotive &#12; et &#11; rhododendron &#12; explique l&#8217;&#233;cart
entre leur vecteurs. Dans le dernier exemple, l&#8217;angle peu important entre &#11; locomotive &#12; et &#11; gu&#233;pard &#12;
au regard de celui entre &#11; locomotive &#12; et &#11; rhododendron &#12; se comprend si on se rappelle que 6,&#9; est une
distance th&#233;matique et non une distance ontologique. Les deux items ont en commun de partager une
id&#233;e de rapidit&#233;. On remarquera que les comparaisons entre les valeurs sont plus significatives que les
valeurs elles-m&#234;mes. Seule une expertise humaine est capable de juger de la pertinence des vecteurs
(si les r&#233;sultats renvoy&#233;s sont coh&#233;rents avec la langue).
</p>
<p>2.2 Op&#233;rations sur les vecteurs
</p>
<p>Les op&#233;rations suivantes ont &#233;t&#233;s d&#233;finies dans (Lafourcade et Prince, 2001), nous les rappelons
bri&#232;vement.
c
</p>
<p>est la somme vectorielle normalis&#233;e d&#233;finie par &#4;d e&#24; c fi f g &#6;  Ph_ikjmlni1poq1
r
</p>
<p>est le produit terme &#224; terme normalis&#233; d&#233;fini par &#4;&lt; e&#24; r fi f g &#6;  ts u &#6;8vffw]&#6;
x
</p>
<p>est la contextualisation faible d&#233;finie par x &#22;&#25;&#24;9&#26;&#7;fi+ffiy e&#24; c &#22;z&#24; r fi{ffi
</p>
<p>2Les exemples sont extraits de http://www.lirmm.fr/&#732;{schwab, lafourca}</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Didier Schwab, Mathieu Lafourcade et Violaine Prince
</p>
<p>2.3 Construction des vecteurs conceptuels
</p>
<p>La construction des vecteurs conceptuels se fait &#224; partir de d&#233;finitions extraites de diverses sources
(dictionnaires, listes de synonymes, indexations manuelles, . . . ). Cette m&#233;thode d&#8217;analyse construit,
&#224; partir de vecteurs conceptuels d&#233;j&#224; existants et de nouvelles d&#233;finitions, de nouveaux vecteurs. Il
est n&#233;cessaire d&#8217;effectuer l&#8217;amor&#231;age du syst&#232;me d&#8217;apprentissage &#224; partir d&#8217;un noyau constitu&#233; de
vecteurs calcul&#233;s au pr&#233;alable pour les termes les plus courants. Les items lexicaux de ce noyau sont
consid&#233;r&#233;s comme pertinents. Cet ensemble constitue la base d&#8217;items lexicaux &#224; partir de laquelle
a d&#233;marr&#233; l&#8217;apprentissage. Nous cherchons &#224; mettre au point un apprentissage qui soit le plus co-
h&#233;rent possible afin d&#8217;obtenir une base augment&#233;e pertinente. Une des mani&#232;res d&#8217;am&#233;liorer cette
coh&#233;rence est de tirer parti des relations s&#233;mantiques3 qui existent entre les items. Une autre mani&#232;re
consiste &#224; faire de l&#8217;apprentissage sur des langues diff&#233;rentes puis de comparer les vecteurs gr&#226;ce &#224;
des dictionnaires interlingues. D&#8217;autres moyens pour am&#233;liorer les vecteurs existent ou peuvent &#234;tre
envisag&#233;s.
</p>
<p>2.4 Agents
</p>
<p>Dans cet article, nous consid&#233;rons comme agent toute entit&#233; humaine ou artificielle qui peut agir sur
la base d&#8217;acception. L&#8217;action peut se faire par la cr&#233;ation ou la suppression de liens entre acceptions,
la cr&#233;ation ou la suppression d&#8217;acceptions.
</p>
<p>Un agent sp&#233;cialiste d&#8217;un domaine (appel&#233; aussi agent expert) est un agent qui a une comp&#233;tence
particuli&#232;re dans un certain domaine (relation s&#233;mantique, analyse s&#233;mantique, d&#233;sambigu&#239;sation,
. . . ). Les agents sp&#233;cialistes d&#8217;un autre domaine sont appel&#233;s agents non-experts ou agents non-
sp&#233;cialistes. Par exemple, un agent sp&#233;cialiste de l&#8217;antonymie est consid&#233;r&#233; comme non-sp&#233;cialiste
de tous les autres domaines (en particulier des autres relations s&#233;mantiques).
</p>
<p>3 Description de la base lexicale
</p>
<p>3.1 Acceptions
</p>
<p>Une acception est un sens particulier d&#8217;un mot, admis et reconnu par l&#8217;usage. Il s&#8217;agit d&#8217;une unit&#233;
s&#233;mantique propre &#224; une langue donn&#233;e (S&#233;rasset and Mangeot, 2001). Par exemple, l&#8217;item lexical
&#11; botte &#12; a au moins trois acceptions, la chaussure, amas de paille ou le coup. Contrairement aux items
lexicaux, les acceptions sont donc monos&#233;miques. Cela a des cons&#233;quences sur les relations s&#233;man-
tiques, elles n&#8217;ont plus besoin d&#8217;&#234;tre appr&#233;ci&#233;es en contexte. Dans ce cas de figure, la synonymie est
une relation d&#8217;&#233;quivalence et les relations hi&#233;rarchiques sont transitives.
</p>
<p>3.2 Base d&#8217;acceptions
</p>
<p>Le mod&#232;le est constitu&#233; de deux parties : des dictionnaires monolingues et une base interm&#233;diaire,
celle des acceptions. Les entr&#233;es de chaque dictionnaire monolingue sont reli&#233;es aux acceptions
correspondantes. Ces acceptions font donc office de pivots entre les items de chaque langue (cf fig. 1
droite)
</p>
<p>3hyp&#233;ronymie/hyponymie et m&#233;ronymie/holonymie qui sont de type hi&#233;rarchique et synonymie et antonymie qui sont
de type sym&#233;trique.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Am&#233;lioration de liens entre acceptions par fonctions lexicales vectorielles
</p>
<p>SONNERIE
</p>
<p>BAGUE
</p>
<p>dictionnaire fran&#231;ais
</p>
<p>BAGUE/ANNEAU
</p>
<p>BAGUE/CIGARE
</p>
<p>SONNERIE/MECANISME
</p>
<p>SONNERIE/SON
</p>
<p>fran&#231;aise
acceptions
</p>
<p>RING
</p>
<p>dictionnaire anglaisanglais
acceptions
</p>
<p>RING/ANNEAU
</p>
<p>RING/MECANISME
</p>
<p>RING/SON
</p>
<p>SONNERIE
</p>
<p>BAGUE
</p>
<p>french dictionnary
</p>
<p>RING
</p>
<p>english dictionnary
</p>
<p>BAND
</p>
<p>interlingual dictionnary
</p>
<p>BAGUE/ANNEAU
</p>
<p>BAGUE/CIGARE
</p>
<p>BAGUE/MECANISME
</p>
<p>BAGUE/SON
</p>
<p>Figure 1: Architecture de la base lexicale. &#192; gauche, les dictionnaires monolingues et leurs accep-
tions. &#192; droite, la base d&#8217;acceptions interlingues o&#249; les acceptions &#8220;identiques&#8221; de chaque langue ont
&#233;t&#233;s fusionn&#233;es.
</p>
<p>Dans chaque base vectorielle monolingue, chaque item est reli&#233; &#224; une acception de sa langue (cf fig.
1 gauche). Chacune des acceptions a son propre vecteur conceptuel. Les acceptions interlingues
sont construites &#224; partir de ces acceptions monolingues (Lafourcade, 2002). La base d&#8217;acceptions est
de grande taille (plus de 500000 acceptions) et est construite par diff&#233;rents agents qui peuvent &#234;tre
humains ou artificiels. Nous consid&#233;rons qu&#8217;il est tr&#232;s difficile de maintenir intacte l&#8217;int&#233;grit&#233; de la
base sans contr&#244;le : un agent (certainement humain) peut toujours cr&#233;er une nouvelle acception m&#234;me
si une acception ad&#233;quate existe d&#233;ja. Un moyen de v&#233;rifier cette int&#233;grit&#233; est de chercher les liens
s&#233;mantiques entre acceptions. Nous consid&#233;rons plusieurs liens s&#233;mantiques dans le lexique et nous
montrons comment les utiliser pour v&#233;rifier l&#8217;int&#233;grit&#233; de la base ou comment un agent non-sp&#233;cialiste
peut utiliser les liens pour en &#233;valuer d&#8217;autres.
</p>
<p>4 Liens s&#233;mantiques
</p>
<p>Les relations s&#233;mantiques entre items lexicaux structurent le lexique sur le plan paradigmatique. Ces
relations sont de deux types : les relations hi&#233;rarchiques (hyponymie/hyp&#233;ronymie, m&#233;ronymie/holo-
nymie) et les relations d&#8217;&#233;quivalence/opposition (synonymie, antonymie). Elles sont souvent d&#233;crites
comme des relations bool&#233;ennes, i.e, elles existent entre deux items ou non (Polgu&#232;re, 2001).
Dans le cas des acceptions, monos&#233;miques par d&#233;finitions, les relations hi&#233;rarchiques sont transi-
tives et la synonymie peut &#234;tre consid&#233;r&#233;e comme une &#233;quivalence. Si nous mat&#233;rialisons toutes les
relations, nous nous heurtons au probl&#232;me de l&#8217;explosion des liens. Il s&#8217;agit, non seulement, d&#8217;un
probl&#232;me mat&#233;riel (taille en m&#233;moire) mais aussi d&#8217;un probl&#232;me qui met en avant la question de
l&#8217;inter&#234;t des liens : leur pouvoir de discrimination est inversement proportionnel &#224; leur nombre. Par
exemple, toutes les acceptions de noms seraient li&#233;es &#224; un terme g&#233;n&#233;ral comme &#11; objet concret &#12; pour un
lien hyp&#233;ronymique. Par exemple, pour &#11; chat &#12; , &#11; f&#233;lin &#12; semble &#234;tre un meilleur hyp&#233;ronyme que &#11; animal &#12;
ou &#11; mammif&#232;re &#12; . Pour &#233;viter ce probl&#232;me, et afin de pouvoir comparer deux liens, nous utilisons des
relations s&#233;mantiques valu&#233;es.
</p>
<p>4.1 Relations s&#233;mantiques valu&#233;es
</p>
<p>Les relations s&#233;mantiques valu&#233;es (RSV) ne sont pas bool&#233;ennes et ont une valeur qui exprime la
pertinence d&#8217;une relation entre deux items lexicaux. Une RSV | est une relation qui donne, pour
deux items, une valeur entre 0 et 1 : |~}'&#127;
</p>
<p>QW&#128; &#129;
</p>
<p>S4&#26;b&#130;%&#131; o&#249; &#127; est l&#8217;ensemble des items lexicaux. Plus la
valeur est proche de 1, plus la relation entre les deux items est pertinente, plus la valeur est proche de
0, moins la relation entre les deux items est pertinente. Si la valeur est de 0, nous pouvons consid&#233;rer
que la relation ne s&#8217;applique pas entre les deux termes. La valeur de la relation peut &#234;tre vue comme
la probabilit&#233; que la relation existe. Les d&#233;finitions des diff&#233;rentes relations sont donn&#233;es dans les
paragraphes correspondants.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Didier Schwab, Mathieu Lafourcade et Violaine Prince
</p>
<p>4.2 Cr&#233;ation et suppression de liens
</p>
<p>Nous voulons ajouter des liens s&#233;mantiques &#224; la base d&#8217;acceptions afin, non seulement de con-
stituer un r&#233;seau s&#233;mantique mais &#233;galement pour pouvoir v&#233;rifier son int&#233;grit&#233;. Les agents capables
d&#8217;&#233;valuer une relation s&#233;mantique valu&#233;e peuvent cr&#233;er des liens s&#233;mantiques valu&#233;s si la valuation est
sup&#233;rieure &#224; un seuil &#132; . Par exemple, si un agent expert d&#8217;antonymie &#233;value l&#8217;antonymie entre &#11; froid &#12;
et &#11; chaud &#12; &#224; une valeur &#3; sup&#233;rieure &#224; &#132; , il construit un lien s&#233;mantique entre les deux acceptions valu&#233;
&#224; &#3; . Le seuil n&#8217;est pas fix&#233; en avance et il &#233;volue constament en fonction du nombre de liens d&#233;j&#224; con-
struits. Le syst&#232;me apprend en fonction des nouvelles donn&#233;es (nouveaux dictionnaires monolingues
ou bilingues) ou en r&#233;visant les anciennes donn&#233;es et donc les agents doivent r&#233;guli&#232;rement recalculer
les relations et si la condition pour pr&#233;server le lien (&#234;tre sup&#233;rieur &#224; &#132; ) n&#8217;est plus respect&#233;e alors le
lien est d&#233;truit. Ces liens mat&#233;rialis&#233;s peuvent &#234;tre utilis&#233;s par des agents qui ne peuvent pas calculer
ces relations s&#233;mantiques par eux m&#234;me mais qui sont capables d&#8217;&#233;valuer rapidement les liens &#224; partir
de simples r&#232;gles. Par exemple, un agent peut &#233;valuer les propri&#233;t&#233;s de transitivit&#233; d&#8217;un hyp&#233;ronyme
pour &#233;valuer la valeur de &#133; w]&#134; &#22;&#25;&#8;{&#26;&#7;&#135;&#15;ffi &#224; partir &#133; w]&#134; &#22;&#25;&#8;{&#26;&#7;&#136;+ffi et de &#133; w]&#134; &#22;&#21;&#136;M&#26;&#7;&#135;&#15;ffi . Cela peut &#234;tre utile si
la base d&#8217;acceptions est utilis&#233;e pour une t&#226;che de d&#233;sambigu&#239;sation par exemple. En aucun cas, un
agent non-expert peut construire un lien.
</p>
<p>Bien qu&#8217;un certain nombre de pistes concernant les relations hi&#233;rarchiques aient &#233;t&#233; lanc&#233;es dans les
premi&#232;res pages de cet article, nous ne nous int&#233;resserons dans la suite qu&#8217;aux relations s&#233;mantiques
sym&#233;triques, antonymie et synonymie, ainsi qu&#8217;aux r&#232;gles qui peuvent &#234;tre appliqu&#233;es pour v&#233;rifier
l&#8217;int&#233;grit&#233; de la base et d&#233;duire de nouvelles relations &#224; partir de celles d&#233;j&#224; existantes.
</p>
<p>4.3 Synonymie
</p>
<p>La synonymie est la relation s&#233;mantique qu&#8217;il existe entre deux items lexicaux qui peuvent, dans un
contexte donn&#233;, exprimer le m&#234;me sens. Par exemple, &#11; avion &#12; et &#11; a&#233;roplane &#12; sont synonymes. Con-
trairement aux unit&#233;s lexicales, les acceptions sont monos&#233;miques par d&#233;finition. Dans ce contexte,
nous pouvons d&#233;finir la synonymie comme la relation s&#233;mantique qui existe entre deux acceptions
qui expriment le m&#234;me sens.
</p>
<p>4.3.1 Synonymie relative
</p>
<p>Dans (Lafourcade et Prince, 2001), la synonymie est &#233;tudi&#233;e &#224; travers la notion de synonymie relative.
Nous d&#233;finissons la fonction de synonymie relative &#17; w &#3;&#321;&#137; entre trois vecteurs &#8; , &#136; , &#135; , ce dernier &#233;tant
le r&#233;f&#233;rent, comme suit :
</p>
<p>&#17;
</p>
<p>w
</p>
<p>&#3;&#139;&#137;&#140;&#22;p&#8;{&#26;fl&#136;M&#26;&#7;&#135;&#15;ffi&#141; &#142;6&#31;&#9;&#19;&#22;
</p>
<p>x
</p>
<p>&#22;p&#8;{&#26;fl&#135;{ffi_&#26;
</p>
<p>x
</p>
<p>&#22;&#21;&#136;M&#26;&#7;&#135;&#15;ffi?ffi&#141; &#143;6&#31;&#9;&#19;&#22;&#25;&#8;
</p>
<p>c
</p>
<p>&#22;p&#8;
</p>
<p>r
</p>
<p>&#135;&#15;ffi&#144;&#26;&#7;&#136;
</p>
<p>c
</p>
<p>&#22;&#21;&#136;
</p>
<p>r
</p>
<p>&#135;&#15;ffi?ffi
</p>
<p>On cherche &#224; tester la proximit&#233; th&#233;matique de deux sens ( &#8; et &#136; ), chacun augment&#233; de ce qu&#8217;il a de
commun avec un troisi&#232;me (C). La synonymie relative est une distance, elle v&#233;rifie donc la r&#233;flexivit&#233;,
la sym&#233;trie et la transitivit&#233;.
</p>
<p>4.3.2 Relation s&#233;mantique valu&#233;e de la synonymie
</p>
<p>Soit la relation s&#233;mantique valu&#233;e de la synonymie d&#233;finie par &#145;&#147;&#146;b&#148;&#150;&#149;&#152;&#151;&#154;&#153;B&#155;&#157;&#156;&#150;&#158;&#159;Z&#150;&#160;&#23;&#161;
&#162;
</p>
<p>&#145;&#147;&#146;b&#148;J&#163;&#139;&#149;&#152;&#151;&#164;&#153;&#21;&#155;&#165;&#153;p&#151;&#167;&#166;{&#155;&#157;&#156; . Il
s&#8217;agit du passage de l&#8217;intervalle
</p>
<p>&#129;
</p>
<p>S4&#26;
</p>
<p>E
</p>
<p>Q
</p>
<p>&#131; &#224; l&#8217;intervalle
&#129;
</p>
<p>Sm&#26;b&#130;%&#131; de la synonymie relative. Cette transforma-
tion inverse le domaine image de fa&#231;on lin&#233;aire. Pour une transformation vers
</p>
<p>&#129;
</p>
<p>Sm&#26;b&#130;%&#131; , nous aurions pu</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Am&#233;lioration de liens entre acceptions par fonctions lexicales vectorielles
</p>
<p>utiliser le cosinus mais on se garde bien de le faire car on souhaite focaliser le pouvoir de discrimina-
tion dans les faibles valeurs de l&#8217;angle.
</p>
<p>4.3.3 Calcul de la synonymie par des agents non-sp&#233;cialistes
</p>
<p>Un agent non-expert peut &#233;valuer la synonymie entre deux acceptions gr&#226;ce &#224; la formule suivante :
&#17;
</p>
<p>w
</p>
<p>&#3;&#19;&#22;p&#8;&#15;&#26;&#7;&#135;{ffi&#141; &#142;&#168;&#142;&#18;B&#3;
</p>
<p>&#6;&#170;&#169;%&#171;
</p>
<p>&#22;&#21;&#168;&#142;&#18;B&#3;&#19;&#22;B&#17;
</p>
<p>w
</p>
<p>&#3;&#141;&#22;p&#8;&#15;&#26;?&#24;
</p>
<p>&#6;
</p>
<p>ffi&#144;&#26;&#7;&#17;
</p>
<p>w
</p>
<p>&#3;&#141;&#22;z&#24;
</p>
<p>&#6;
</p>
<p>&#26;fl&#136;&#31;ffi?ffi3ffi
</p>
<p>avec &#172; , l&#8217;ensemble des items reli&#233;s &#224; la fois &#224; &#8; et &#136; .
</p>
<p>B
</p>
<p>Syn(A, B)
</p>
<p>C
</p>
<p>Syn(B, C)
</p>
<p>Syn(A,C)
D
</p>
<p>Syn(C, D)
</p>
<p>Syn(B, D)
</p>
<p>A Syn=0,7Syn=0,8
</p>
<p>Syn=0,7 habitervivre/habiter
</p>
<p>loger
</p>
<p>Figure 2: Evaluation de la relation de synonymie.
</p>
<p>S&#8217;il existe un chemin allant de &#8; &#224; &#136; , nous consid&#233;rons que le RSV entre &#8; et &#136; est le plus petit
RSV du chemin. Lorsque plusieurs chemins sont possibles, la m&#234;me id&#233;e que pour les relations
hi&#233;rarchiques est adopt&#233;e, nous choisissons le plus mauvais chemin (le moins probable) pour &#233;valuer
le RSV. Dans la partie droite de la figure 2, la synonymie entre &#11; habiter &#12; et &#11; loger &#12; est &#233;valu&#233;e gr&#226;ce &#224;
la synonymie entre &#11; vivre/habiter &#12; et &#11; loger &#12; et la synonymie entre &#11; loger &#12; et &#11; habiter &#12; .
</p>
<p>4.4 Antonymie
</p>
<p>(Schwab et all., 2002) propose une d&#233;finition de l&#8217;antonymie compatible avec le mod&#232;le vectoriel
utilis&#233;. Le transfert aux acceptions ne modifie pas cette d&#233;finition. Deux acceptions sont en relation
d&#8217;antonymie si on peut exhiber une sym&#233;trie de leurs traits s&#233;mantiques par rapport &#224; un axe. Nous
consid&#233;rons que les relations d&#8217;antonymie d&#233;pendent du type de support de sym&#233;trie. Pour une accep-
tion, il peut exister plusieurs types de sym&#233;trie possibles comme il peut ne pas y en avoir d&#8217;&#233;vident si
le support de sym&#233;trie ne peut &#234;tre trouv&#233;. Plusieurs sortes de support peuvent &#234;tre distingu&#233;s : (i) une
propri&#233;t&#233; affectant une valeur &#233;talonnable (chaud et froid qui sont des valeurs sym&#233;triques de temp&#233;ra-
ture) (ii) l&#8217;application d&#8217;une propri&#233;t&#233; (applicable/inapplicable, pr&#233;sence/absence), l&#8217;existence d&#8217;une
propri&#233;t&#233; ou d&#8217;un &#233;l&#233;ment consid&#233;r&#233; comme sym&#233;trique par l&#8217;usage (e.g. soleil/lune), ou par des
propri&#233;t&#233;s naturelles ou physiques des objets consid&#233;r&#233;s (e.g. m&#226;le /femelle, t&#234;te/pied, . . . ).
</p>
<p>4.4.1 Acceptions sans antonymes
</p>
<p>Une cons&#233;quence importante de notre d&#233;finition est que tout vecteur conceptuel peut avoir un vecteur
antonyme. En effet, pour un axe donn&#233;, tout vecteur a un sym&#233;trique. La linguistique classique
consid&#232;re que certains termes, n&#8217;ont pas d&#8217;antonymes av&#233;r&#233;s4. Les id&#233;es principales constituant ces
acceptions, autrement dit, les concepts, ne sont pas obligatoirement opposables. Dans un espace
g&#233;om&#233;trique, un point qui n&#8217;a pas d&#8217;autre sym&#233;trique se trouve sur l&#8217;axe de sym&#233;trie. De m&#234;me, dans
notre formalisme, les id&#233;es qui ne sont pas opposables sont sur l&#8217;axe de sym&#233;trie et donc l&#8217;antonyme
d&#8217;un item lexical qui ne poss&#232;de pas d&#8217;antonyme av&#233;r&#233; est l&#8217;item lexical lui-m&#234;me. Nous appelons
cela, la propri&#233;t&#233; des points fixes. En pratique, les concepts poss&#232;dent plus facilement cette propri&#233;t&#233;
</p>
<p>4C&#8217;est le cas, par exemple, des objets mat&#233;riels comme &#0; table &#1; , &#0; voiture &#1; ou &#0; porte &#1; .</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Didier Schwab, Mathieu Lafourcade et Violaine Prince
</p>
<p>que les acceptions. Ces derniers, en se projetant sur plusieurs concepts (l&#8217;immense majorit&#233; des mots
de la langue &#233;tant polys&#232;me), peuvent, dans certains contextes, h&#233;riter de la capacit&#233; d&#8217;opposition de
certains concepts. Ainsi par exemple, en antonymie scalaire, une &#11; Ferrari &#12; , bien que sorte d&#8217;AUTOMOBILE,
concept sans antonyme, se projette aussi sur une notion de RAPIDIT&#201; qui, elle, est opposable. C&#8217;est
pourquoi on peut tr&#232;s bien imaginer une &#11; deux chevaux &#12; comme possible antonyme d&#8217;une &#11; Ferrari &#12; .
</p>
<p>&#192; partir de ces sp&#233;cifications, nous avions d&#233;fini dans (Schwab et all., 2002) une fonction &#8;*&#3;&#10;&#173;n&#18;?&#137; simu-
lant l&#8217;antonymie. Nous utilisons cette fonction pour cr&#233;er une mesure d&#8217;&#233;valuation de l&#8217;antonymie.
</p>
<p>4.4.2 Mesure d&#8217;&#233;valuation de l&#8217;antonymie
</p>
<p>Cette mesure permet de v&#233;rifier si deux items lexicaux (ou acceptions) peuvent &#234;tre antonymes.
Soit &#8; et &#136; deux vecteurs, la question est pr&#233;cis&#233;ment de savoir s&#8217;ils peuvent raisonnablement &#234;tre
antonymes dans un contexte &#135; . La mesure d&#8217;antonymie &#168;&#175;&#174;&#176;&#3;&#165;&#173;n&#18;n&#177;&#179;&#178;\&#180;3&#181; est la mesure en radians de l&#8217;angle
entre la somme de &#8; et &#136; et la somme de &#8;*&#3;&#165;&#173;n&#18;&#183;&#182;p&#184;&#185;&#22;p&#8;&#15;&#26;&#7;&#135;{ffi et &#8;O&#3;&#165;&#173;n&#18;&#21;&#182;&#21;&#184;q&#22;p&#136;M&#26;&#7;&#135;&#15;ffi . Ainsi, nous avons :
</p>
<p>&#168;&#175;&#174;&#176;&#3;&#165;&#173;n&#18;&#21;&#177;&#150;&#178;\&#180;\&#181;&#165; &#142;6&#31;&#9;&#19;&#22;&#25;&#8;
</p>
<p>c
</p>
<p>&#136;M&#26;fl&#8;O&#3;&#165;&#173;n&#18;&#183;&#137;&#19;&#22;p&#8;{&#26;fl&#135;{ffi
</p>
<p>c
</p>
<p>&#8;O&#3;&#165;&#173;n&#18;B&#137;&#141;&#22;&#21;&#136;M&#26;fl&#135;{ffi3ffi
</p>
<p>A
</p>
<p>B
</p>
<p>Anti(B,C)
</p>
<p>Anti(A,C)
</p>
<p>Anti(A,C)+Anti(B,C)
A+B
</p>
<p>Figure 3: repr&#233;sention g&#233;om&#233;trique en 2 dimensions de la mesure d&#8217;&#233;valuation de l&#8217;antonymie &#186;ff&#187;%&#148;&#176;&#188;z&#189;&#183;&#190;&#192;&#191;n&#193;&#183;&#194;
</p>
<p>La mesure d&#8217;antonymie est une pseudo-distance. Elle v&#233;rifie les propri&#233;t&#233;s de r&#233;flexivit&#233;, sym&#233;trie et
in&#233;galit&#233; triangulaire uniquement dans le sous ensemble des items qui n&#8217;ont pas d&#8217;antonymes. Dans le
cas g&#233;n&#233;ral, elle ne v&#233;rifie pas la r&#233;flexivit&#233;. Les composantes des vecteurs conceptuels sont positives
et nous avons la propri&#233;t&#233; 6M&#18;&#183;&#132;%&#173;3&#180;n&#195;%&#196; &#6;O&#197;
</p>
<p>&#129;
</p>
<p>Sm&#26;
</p>
<p>E
</p>
<p>Q
</p>
<p>&#131; . Plus la mesure est petite, plus les deux items lexicaux
sont antonymes dans le contexte. En revanche, ce serait une erreur de consid&#233;rer que deux antonymes
seraient &#224; une distance avoisinant &#198;&#321;&#199;L&#200; . Deux items lexicaux &#224; &#168;&#175;&#174;&#176;&#3;&#165;&#173;n&#18;n&#177;&#179;&#178;\&#180;3&#181;&#165; e&#198;q&#199;'&#200; l&#8217;un de l&#8217;autre n&#8217;ont
aucune id&#233;e en commun5, ce qui n&#8217;est pas le cas de deux antonymes qui on en commun les id&#233;es non
opposables ou celles qui le sont mais dont l&#8217;activation est proche. Ils ne s&#8217;opposent que par certaines
activations de concepts. Une distance de &#198;&#321;&#199;'&#200; entre deux items lexicaux devrait &#234;tre plut&#244;t interpr&#233;t&#233;
comme une sorte d&#8217;anti-synonymie. Ce r&#233;sultat confirme le fait que l&#8217;antonymie n&#8217;est pas exactement
l&#8217;inverse de la synonymie mais lui est tr&#232;s li&#233;e. L&#8217;antonyme d&#8217;un item &#11; m &#12; n&#8217;est pas un mot qui ne
partage aucune id&#233;e avec &#11; m &#12; mais un item qui s&#8217;oppose &#224; &#11; m &#12; sur certaines id&#233;es.
</p>
<p>4.4.3 Relation s&#233;mantique valu&#233;e de l&#8217;antonymie
</p>
<p>Nous d&#233;finissons la relation s&#233;mantique valu&#233;e de l&#8217;antonymie par &#201;q&#148;&#176;&#188;z&#189;&#202;&#149;k&#151;&#154;&#153;&#21;&#155;&#157;&#156;&#150;&#158;&#159;Z&#139;&#160;&#203;&#161;
&#162;
</p>
<p>&#186;ff&#187;%&#148;&#176;&#188;z&#189;
</p>
<p>&#190;&#192;&#191;n&#193;&#183;&#194;
</p>
<p>&#149;k&#151;&#154;&#153;&#21;&#155;/&#156;
</p>
<p>Il s&#8217;agit de la conversion lin&#233;aire de l&#8217;intervalle
&#129;
</p>
<p>Sm&#26;&#176;E
</p>
<p>Q
</p>
<p>&#131; &#224; l&#8217;intervalle
&#129;
</p>
<p>S4&#26;b&#130;%&#131; .
</p>
<p>5ce cas de figure est purement th&#233;orique, il n&#8217;existe dans aucune langue deux items lexicaux qui ne partagent aucune
id&#233;e.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Am&#233;lioration de liens entre acceptions par fonctions lexicales vectorielles
</p>
<p>5 Am&#233;lioration de l&#8217;int&#233;grit&#233; de la base d&#8217;acceptions
</p>
<p>5.1 Sch&#233;ma g&#233;n&#233;ral de coh&#233;rence
</p>
<p>Le sch&#233;ma g&#233;n&#233;ral de coh&#233;rence doit &#234;tre v&#233;rifi&#233; dans la base d&#8217;acceptions (fig. 4) sinon la base n&#8217;est
pas coh&#233;rente. Si &#8; est antonyme de &#136; et &#136; antonyme de &#135; alors &#8; et &#136; sont synonymes. De m&#234;me,
</p>
<p>B
Ant(A, B) Ant(B,C)
</p>
<p>Syn(A, C)
CA
</p>
<p>Figure 4: Sch&#233;ma g&#233;n&#233;ral de coh&#233;rence
</p>
<p>si &#8; et &#136; sont antonymes et &#8; et &#135; synonymes alors &#136; et &#135; sont antonymes. Des agents sp&#233;cialistes
cherchent ces sch&#233;mas et avertissent les lexicographes en cas d&#8217;incoh&#233;rences. Les lexicographes
peuvent alors indiquer si une acception doit &#234;tre divis&#233;e ou si un lien ne devrait pas &#234;tre mat&#233;rialis&#233;.
</p>
<p>5.2 &#201;valuation de la synonymie et de l&#8217;antonymie
Le sch&#233;ma g&#233;n&#233;ral de coh&#233;rence (fig. 4) peut aussi aider les agents non-sp&#233;cialistes pour &#233;valuer un
lien non-mat&#233;riel. Si &#8; est antonyme de &#136; et &#136; antonyme de &#135; alors nous avons &#8; et &#136; synonymes.
Dans le cas g&#233;n&#233;ral, nous avons :
</p>
<p>&#17;
</p>
<p>w
</p>
<p>&#3;&#19;&#22;p&#8;{&#26;fl&#135;{ffi&#141; &#142;&#168;&#142;&#18;B&#3;
</p>
<p>&#6;
</p>
<p>&#22;B&#168;&#142;&#18;&#21;&#3;&#141;&#22;p&#8;O&#3;&#165;&#173;@&#22;&#25;&#8;{&#26;?&#24;
</p>
<p>&#6;
</p>
<p>ffi_&#26;fl&#8;*&#3;&#10;&#173;@&#22;&#25;&#24;
</p>
<p>&#6;
</p>
<p>&#26;&#7;&#135;&#15;ffi?ffi3ffi
</p>
<p>La figure 5 montre un exemple d&#8217;&#233;valuation de la synonymie &#224; partir de l&#8217;antonymie.
</p>
<p>Syn=0,7
vie
</p>
<p>existence/vie
</p>
<p>inexistence/mort
Ant=0,75Ant=0,85
</p>
<p>Ant=0,7 Ant=0,8
mort
</p>
<p>mort
</p>
<p>inexistence/mort
</p>
<p>Ant=0,85Ant=0,6
</p>
<p>existence/vie
</p>
<p>Ant=0,8 Ant=0,65Syn=0,75
</p>
<p>mort
Syn=0,6
</p>
<p>Figure 5: Exemple d&#8217;&#233;valuation de la synonymie (&#224; gauche) et de l&#8217;antonymie (&#224; droite)
</p>
<p>De la m&#234;me mani&#232;re, nous pouvons aussi &#233;valuer l&#8217;antonymie:
&#8;*&#3;&#165;&#173;
</p>
<p>&#6;
</p>
<p>&#22;p&#8;{&#26;fl&#135;{ffi&#141; &#204;&#168;&#143;&#18;B&#3;
</p>
<p>&#6;
</p>
<p>&#22;B&#168;&#142;&#18;&#21;&#3;&#141;&#22;B&#17;
</p>
<p>w
</p>
<p>&#3;&#141;&#22;&#25;&#8;{&#26;?&#24;
</p>
<p>&#6;
</p>
<p>ffi_&#26;fl&#8;*&#3;&#10;&#173;@&#22;&#25;&#24;
</p>
<p>&#6;
</p>
<p>&#26;&#7;&#135;&#15;ffi?ffi3ffi
</p>
<p>La figure 5 montre un exemple d&#8217;&#233;valuation de la synonymie &#224; partir de l&#8217;antonymie.
</p>
<p>6 Conclusion et perspectives
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; une mani&#232;re d&#8217;am&#233;liorer l&#8217;int&#233;grit&#233; d&#8217;une base d&#8217;acceptions
gr&#226;ce aux relations s&#233;mantiques sym&#233;triques bien connues que sont la synonymie et l&#8217;antonymie.
Nous avons pr&#233;sent&#233; les relations s&#233;mantiques valu&#233;es (RSV) qui peuvent &#234;tre compar&#233;es &#224; la prob-
abilit&#233; que la relation existe entre deux items ou acceptions. Les RSV sont calcul&#233;es par des agents
sp&#233;cialistes gr&#226;ce &#224; diverses informations lexicales et aux vecteurs conceptuels pour cr&#233;er des liens</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Didier Schwab, Mathieu Lafourcade et Violaine Prince
</p>
<p>mat&#233;rialis&#233;s entre deux acceptions si ce RSV d&#233;passe un certain seuil. Nous avons montr&#233; comment
des agents non-sp&#233;cialistes (en charge du transfert lexical ou de la d&#233;sambigu&#239;sation du sens) peuvent
&#233;valuer des liens non-mat&#233;rialis&#233;s &#224; partir de liens mat&#233;rialis&#233;s. Les agents v&#233;rifiant l&#8217;int&#233;grit&#233; de la
base utilisent ces liens pour chercher les incoh&#233;rences de la base et avertissent les lexicographes le
cas &#233;ch&#233;ant. Il nous reste encore &#224; prolonger ces travaux en cherchant &#224; automatiser ces corrections
d&#8217;incoh&#233;rences. Ces travaux doivent aussi &#234;tre approfondis en ce qui concerne les relations hi&#233;rar-
chiques comme l&#8217;holonymie ou l&#8217;hyp&#233;ronymie. Notre &#233;quipe travaille actuellement sur le calcul de
RSV concernant ces relations ainsi que sur les moyens de les utiliser pour am&#233;liorer la coh&#233;rence de
bases d&#8217;acceptions.
</p>
<p>R&#233;f&#233;rences
Chauch&#233; Jacques, D&#233;termination s&#233;mantique en analyse structurelle : une exp&#233;rience bas&#233;e sur une d&#233;finition
de distance. TAL Information, 31/1, pp 17-24, 1990.
</p>
<p>Deerwester S. et Dumais S., Landauer S., Furnas G., Harshman R., Indexing by latent semantic anlysis. In
Journal of the American Society of Information science, 1990, 416(6), pp 391-407.
Lafourcade M., Automatically Populating Acception Lexical Database through Bilingual Dictionaries and Con-
ceptual Vectors. proc. de PAPILLON-2002, Tokyo, Japan, August 2002.
</p>
<p>Lafourcade M. et Prince V. Synonymies et vecteurs conceptuels. Proc. of Traitement Automatique du Langages
Naturel (TALN&#8217;2001) (Tours, France, Juillet 2001), pp 233-242.
Lafourcade M . Lexical sorting and lexical transfer by conceptual vectors. Proc. of the First International
Workshop on MultiMedia Annotation (Tokyo, Janvier 2001), 6 p.
Larousse. Le Petit Larousse Illustr&#233; 2001. Larousse, 2001.
</p>
<p>Larousse. Th&#233;saurus Larousse - des id&#233;es aux mots, des mots aux id&#233;es. Larousse, ISBN 2-03-320-148-1,
1992.
</p>
<p>Lyons J. Semantics. Cambridge : Cambridge University Press, 1977.
. Mangeot-Lerebours M. Environnements centralis&#233;s et distribu&#233;s pour lexicographes et lexicologues en con-
texte multilingues. th&#232;se de doctorat de l&#8217;Universit&#233; Joseph Fourier, 2001.
</p>
<p>Morin, E. Extraction de liens s&#233;mantiques entre termes &#224; partir de corpus techniques. Th&#232;se de doctorat de
l&#8217;Universit&#233; de Nantes, 1999.
Muehleisen V.L. Antonymy and semantic range in english. Northwestern university Phd, 1997.
</p>
<p>Palmer, F.R. Semantics : a new introduction. Cambridge University Press, 1976.
Polgu&#233;re A. Notions de base en lexicologie. Observatoire de linguistique sens-texte, 2001.
</p>
<p>Thesaurus of English Words and Phrases. Longman, London, 1852.
Salton G. et MacGill M.J. Introduction to modern Information Retrieval. McGraw-Hill, New-York, 1983.
Schwab D, Lafourcade M et Prince V. Vers l&#8217;apprentissage automatique, pour et par, les vecteurs conceptuels
de fonctions lexicales. L&#8217;exemple de l&#8217;antonymie., actes de TALN 2002, Nancy, Juin 2002.
S&#233;rasset G., Mangeot M. Papillon lexical databases project: monolingual dictionnaries &amp; interlingual links.
NLPRS 2001 processings, pp 119-125.</p>

</div></div>
</body></html>