<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Application d&#8217;algorithmes de classification automatique pour la d&#233;tection des contenus racistes sur l&#8217;Internet</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2003, Batz-sur-Mer, 11&#8211;14 juin 2003
</p>
<p>Application d&#8217;algorithmes de classification automatique pour
la d&#233;tection des contenus racistes sur l&#8217;Internet
</p>
<p>Romain Vinot
&#0;
</p>
<p>, Natalia Grabar
&#1;&#3;&#2; &#4;
</p>
<p>, Mathieu Valette
&#1;&#5;&#2; &#6;
</p>
<p>&#0;
</p>
<p>Ecole Nationale Sup&#233;rieure des T&#233;l&#233;communications
&#1;
</p>
<p>Centre de Recherche en Ing&#233;nierie Multilingue - INALCO
&#4;
</p>
<p>STIM - DIAM, AP-HP Piti&#233;-Salp&#234;tri&#232;re, Universit&#233; Paris 6
&#6;
</p>
<p>UMR 7114 CNRS/Paris X (MoDyCo)
romain.vinot@enst.fr, ngr@biomath.jussieu.fr, mathieu.valette@free.fr
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>Classification automatique, Rocchio, kPPV, SVM, Internet, filtrage de l&#8217;information
Text classification, Rocchio, kNN, SVM, Internet, information filtering
</p>
<p>R&#233;sum&#233; - Abstract
</p>
<p>Le filtrage de contenus illicites sur Internet est une probl&#233;matique difficile qui est actuellement
r&#233;solue par des approches &#224; base de listes noires et de mots-cl&#233;s. Les syst&#232;mes de classifica-
tion textuelle par apprentissage automatique n&#233;cessitant peu d&#8217;interventions humaines, elles
peuvent avantageusement remplacer ou compl&#233;ter les m&#233;thodes pr&#233;c&#233;dentes pour faciliter les
mises &#224; jour. Ces techniques, traditionnellement utilis&#233;es avec des cat&#233;gories d&#233;finies par leur
sujet (&#233;conomie ou sport par exemple), sont fond&#233;es sur la pr&#233;sence ou l&#8217;absence de mots. Nous
pr&#233;sentons une &#233;valuation de ces techniques pour le filtrage de contenus racistes. Contrairement
aux cas traditionnels, les documents ne doivent pas &#234;tre cat&#233;goris&#233;s suivant leur sujet mais sui-
vant le point de vue &#233;nonc&#233; (raciste ou antiraciste). Nos r&#233;sultats montrent que les classifieurs,
essentiellement lexicaux, sont n&#233;anmoins bien adapt&#233;es : plus de 90% des documents sont cor-
rectement class&#233;s, voir m&#234;me 99% si l&#8217;on accepte une classe de rejet (avec 20% d&#8217;exemples non
class&#233;s).
</p>
<p>Filtering of illicit contents on the Internet is a difficult issue which is currently solved with black
lists and keywords. Machine-learning text categorization techniques needing little human inter-
vention can replace or complete the previous methods to keep the filtering up-to-date easily.
These echniques, usually used with topic classes (economy or sport for instance), are based on
the presence or absence of words. We present an evaluation of these techniques for racism filte-
ring. Unlike the traditional systems, documents are not categorized according to their main topic
but according to the expressed point of view (racist or anti-racist). Our results show that these
lexical techniques are well adapted : more than 90% of the documents are correctly classified,
or even 99% if a rejection class is accepted (20% of the examples are not classified).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Romain Vinot, Natalia Grabar, Mathieu Valette
</p>
<p>1 Introduction
</p>
<p>L&#8217;exp&#233;rience pr&#233;sent&#233;e ici a &#233;t&#233; faite dans le cadre du projet europ&#233;en Princip (Plateforme pour
la Recherche, l&#8217;Identification et la Neutralisation des Contenus Ill&#233;gaux et Pr&#233;judiciables sur
l&#8217;Internet)1. Princip s&#8217;inscrit dans l&#8217;action Safer Internet Action Plan de la Communaut&#233; euro-
p&#233;enne et concerne la d&#233;tection de contenus illicites relatifs au racisme et au r&#233;visionnisme sur
le Web.
</p>
<p>Cette probl&#233;matique, semblable &#224; la d&#233;tection d&#8217;autres contenus pr&#233;judiciables (p&#233;dophilie, tra-
fic d&#8217;armes et de drogue, pornographie), peut &#234;tre abord&#233;e avec deux approches : filtrage par liste
noire et par mots cl&#233;s. Les deux approches peuvent donner des r&#233;sultats satisfaisants mais elles
ont &#233;galement des limites. Le filtrage par liste noire consiste &#224; filtrer les pages dont l&#8217;adresse
URL fait partie d&#8217;une liste constitu&#233;e pr&#233;alablement. Dans cette approche, il ne s&#8217;agit pas de
la d&#233;tection, mais uniquement du blocage de pages ind&#233;sirables. La faiblesse principale ici est
la mise &#224; jour des listes noires : le Web &#233;volue rapidement, de nouveaux sites apparaissent,
d&#8217;autres se d&#233;placent ou bien disparaissent. Le principe de filtrage par mots cl&#233;s suppose que
si un des mots cl&#233;s r&#233;v&#233;lateurs est trouv&#233; dans une page HTML, l&#8217;acc&#232;s &#224; cette page doit &#234;tre
r&#233;glement&#233;. Cette m&#233;thode s&#8217;av&#232;re faillible. Le sens des mots cl&#233;s est susceptible de changer, &#224;
la fois en synchronie (en fonction du contexte) et en diachronie (selon les &#233;poques). Ainsi, n&#232;gre
re&#231;oit des valeurs radicalement diff&#233;rentes selon qu&#8217;il s&#8217;agit de l&#8217;art n&#232;gre, de la t&#234;te de n&#232;gre,
du n&#232;gre d&#8217;un &#233;crivain ou du n&#232;gre tel que le mot &#233;tait couramment usit&#233; aux &#7;&#9;&#8;&#11;&#10;&#12;&#10;&#12;&#10;&#14;&#13;&#16;&#15;&#17;&#13; et
&#7;&#18;&#10;&#19;&#7;&#18;&#13;&#20;&#15;&#21;&#13; si&#232;cles. En somme, l&#8217;insulte sale n&#232;gre n&#8217;est qu&#8217;un cas d&#8217;instanciation parmi d&#8217;autres.
Avec des mots cl&#233;s discrimininants, cette technique peut donc permettre de rep&#233;rer les pages
qui traitent du racisme mais ne permet pas de d&#233;terminer si les pages exposent un propos ra-
ciste ou non. Une autre limite est la variabilit&#233; du contenu et de marqueurs lexicaux dans les
pages illicites. Les mots neutres &#224; l&#8217;origine peuvent &#234;tre r&#233;cup&#233;r&#233;s et utilis&#233;s dans un contexte
raciste (par exemple jeune sous-entend jeune d&#8217;origine &#233;trang&#232;re). Une &#171; r&#233;habilitation &#187; des
mots (leur passage des contenus racistes vers des contenus neutres et antiracistes) est aussi
possible. Les ph&#233;nom&#232;nes linguistiques de cr&#233;ativit&#233; lexicale rendent &#233;galement la t&#226;che plus
ardue. Par exemple, le verlan (beurs, feujs, rabzas), la modification de l&#8217;orthographe (naigre au
lieu de n&#232;gre), les emprunts (bougnoul, gnoul, Sieg Heil). Tous ces exemples montrent que les
mots cl&#233;s doivent aussi &#234;tre mis &#224; jour r&#233;guli&#232;rement et de pr&#233;f&#233;rence en puisant les donn&#233;es
directement &#224; la source : dans les pages Web.
</p>
<p>Dans notre projet, nous avons opt&#233; pour une utilisation de listes noires constitu&#233;es gr&#226;ce &#224;
une &#233;tude linguistique des documents. L&#8217;approche linguistique suppose que la combinaison
d&#8217;indices venant de plusieurs niveaux d&#8217;unit&#233;s linguistiques (caract&#232;res, morph&#232;mes, cat&#233;gories
syntaxiques, expressions complexes, isotopies s&#233;mantiques, code HTML, etc.) et bas&#233;e sur une
analyse plus globale des documents Web permet de mieux cerner et profiler le contenu de ces
documents. La d&#233;tection et l&#8217;analyse d&#8217;indices de diff&#233;rents niveaux devient possible avec des
outils lexicographiques, statistiques et de TAL.
</p>
<p>L&#8217;exp&#233;rience que nous pr&#233;sentons ici concerne l&#8217;application de syst&#232;mes de classification auto-
matique (classifieurs) pour la d&#233;tection de contenus racistes. Lorsqu&#8217;il est possible d&#8217;attribuer
une ou plusieurs cat&#233;gories &#224; un ensemble de documents, ces syst&#232;mes peuvent, &#224; partir d&#8217;un
corpus o&#249; la cat&#233;gorie de chaque document est connue a priori, &#171; apprendre &#187; une d&#233;finition
de ces cat&#233;gories et ensuite les attribuer automatiquement &#224; de nouveaux documents. Ces sys-
t&#232;mes fonctionnent g&#233;n&#233;ralement au niveau lexical des documents et fondent leur d&#233;cision sur
</p>
<p>1Des informations plus amples peuvent &#234;tre trouv&#233;es sur la page http ://www.princip.net.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;tection des contenus racistes sur l&#8217;Internet
</p>
<p>la pr&#233;sence ou l&#8217;absence de mots.
</p>
<p>Pour cette exp&#233;rience, nous disposons d&#8217;un corpus cat&#233;goris&#233;. L&#8217;algorithme de classification
doit donc discriminer les pages comportant des propos racistes de celles comportant des propos
antiracistes. Contrairement aux domaines d&#8217;application &#171; traditionnels &#187; de classifieurs (par
exemple, sport ou &#233;conomie) o&#249; une vue &#171; ontologique &#187; du domaine est possible avec des
mots-cl&#233;s pr&#233;cis et connus, la th&#233;matique que nous explorons ici est plus difficile &#224; cerner a
priori. D&#8217;autant plus que nous cherchons &#224; distinguer des points de vue diff&#233;rents qui portent
sur le m&#234;me sujet. La question que nous nous posons alors est de voir jusqu&#8217;&#224; quel point les
techniques lexicales sont utilisables pour discriminer ce genre de diff&#233;rence. Autrement dit,
existe-il des diff&#233;rences lexicales entre les discours racistes et antiracistes ?
</p>
<p>Dans la suite de cet article, nous mentionnons des travaux sur l&#8217;utilisation de classifieurs tex-
tuels sur des t&#226;ches non purement th&#233;matique (section 2), ensuite nous d&#233;crivons les corpus
d&#8217;apprentissage et de test (section 3) et les m&#233;thodes de traitement de ces corpus (section 4).
Nous pr&#233;sentons ensuite les r&#233;sultats et les discutons (section 5) et nous terminons avec une
conclusion (section 6).
</p>
<p>2 Travaux similaires
</p>
<p>Les travaux autour du filtrage de courriers &#233;lectroniques non sollicit&#233;s (couramment appel&#233;
spams) &#224; l&#8217;aide de classifieurs textuels exploitent diff&#233;rentes techniques d&#8217;apprentissage : Na&#239;ve
Bayes et k plus proches voisins (Androutsopoulos et al., 2000), algorithme g&#233;n&#233;tique, boosting
d&#8217;arbre de d&#233;cision (Carreras &amp; M&#225;rquez, 2001). Bien que la stricte d&#233;finition de la cat&#233;gorie
spam ne soit pas th&#233;matique, il est possible de d&#233;terminer quelques th&#232;mes g&#233;n&#233;raux (pornogra-
phie, transfert de fonds, etc) facilement d&#233;tectables par les indices lexicaux. Ces syst&#232;mes ont
de tr&#232;s bonnes performances et commencent &#224; &#234;tre d&#233;ploy&#233;s en environnement industriel.
</p>
<p>Le programme de recherche TDT (Topic Detection and Tracking) (TDT, 2001), sponsoris&#233; par
l&#8217;agence DARPA, concerne la classification d&#8217;un flux d&#8217;informations suivant l&#8217;&#233;v&#232;nement g&#233;-
n&#233;rateur (les nouvelles parlant de deux &#233;lections diff&#233;rentes doivent &#234;tre class&#233;es dans deux
cat&#233;gories s&#233;par&#233;es car l&#8217;&#233;v&#232;nement sous-jacent n&#8217;est pas le m&#234;me). Cette t&#226;che est tr&#232;s diffi-
cile car elle est fondamentalement non th&#233;matique. La majorit&#233; des syst&#232;mes propos&#233;s utilisent
n&#233;anmoins les classifieurs lexicaux standards et obtiennent des performances peu satisfaisantes.
</p>
<p>Pang, Lee et Vaithyanathan (Pang et al., 2002) ont utilis&#233; des classifieurs th&#233;matiques standards
pour discriminer des critiques de films positives et n&#233;gatives. Peter Turney (Turney, 2002) utilise
&#171; l&#8217;orientation s&#233;mantique &#187; (positive ou n&#233;gative) des adjectifs pour d&#233;terminer la cat&#233;gorie de
critiques de plusieurs types d&#8217;objets (films, voitures, banques et destinations de voyages). Les
deux &#233;valuations ont des performances moyennes (bien meilleures qu&#8217;un classement al&#233;atoire
mais insuffisantes pour une utilisation r&#233;elle). Dans les deux cas, les auteurs expliquent les
erreurs par le fait que tous ces syst&#232;mes fonctionnent par agr&#233;gation des indices trouv&#233;s sur
chaque zone de texte. Or, le jugement final d&#8217;une critique n&#8217;est pas une simple somme des
jugements de chaque sous-partie (un film peut avoir de bons acteurs et de bons dialogues et
recevoir n&#233;anmoins une mauvaise appr&#233;ciation globale).
Dans tous les cas, et comme dans celui du filtrage de propos racistes, il ne s&#8217;agit pas de d&#233;termi-
ner le sujet principal du document : mail sollicit&#233; ou non, &#233;v&#232;nement g&#233;n&#233;rateur de la nouvelle,
critique positive ou n&#233;gative.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Romain Vinot, Natalia Grabar, Mathieu Valette
</p>
<p>3 Constitution du corpus
</p>
<p>Comme l&#8217;outil final de d&#233;tection de contenus illicites est destin&#233; &#224; travailler sur le Web, les cor-
pus de travail sont construits &#233;galement &#224; partir de donn&#233;es existant sur le Web. Nous utilisons
les moteurs de recherche g&#233;n&#233;raux que nous interrogeons avec des mots cl&#233;s &#171; sensibles &#187;.
</p>
<p>La constitution du corpus est faite en deux &#233;tapes : collecte massive de documents et ensuite leur
cat&#233;gorisation manuelle. La collecte de documents est faite de deux mani&#232;res : interrogation
manuelle et automatique (Grabar &amp; Berland, 2001) de pages et de sites et leur rapatriement.
Lors de la cat&#233;gorisation manuelle, un document peut &#234;tre cat&#233;goris&#233; dans une des cat&#233;gories
pr&#233;d&#233;finies : raciste, antiraciste, r&#233;visionniste, anti-r&#233;visionniste et non pertinent. En cas de
doute, la cat&#233;gorie ind&#233;cidable est pr&#233;vue. Les documents de cette cat&#233;gorie sont analys&#233;s par
un organisme comp&#233;tent (Ligue Belge des Droits de l&#8217;Homme).
Au moment des exp&#233;riences pr&#233;sent&#233;es ici, les corpus sont en cours de constitution. Le corpus
que nous avons utilis&#233; contient 739 documents dont 286 pages racistes, 444 611 occurrences,
tir&#233;es de 43 sites et 453 pages antiracistes, 941 007 occ., tir&#233;es de 81 sites.
</p>
<p>4 Description des algorithmes
</p>
<p>Les algorithmes de classification fonctionnent au niveau lexical en prenant les tokens des docu-
ments comme unit&#233;s descriptives (termes). Habituellement, les classifieurs sont utilis&#233;s sur des
documents texte brut pr&#233;alablement segment&#233;s sur tous les caract&#232;res non-alphab&#233;tiques. Les
unit&#233;s linguistiques sont donc les mots, la ponctuation et les chiffres ayant &#233;t&#233; supprim&#233;s. Dans
l&#8217;exp&#233;rience que nous pr&#233;sentons ici, nous avons consid&#233;r&#233; les indices non textuelles (nombres,
code HTML) comme des ancrages suppl&#233;mentaires dans le texte et donc utiles pour la discri-
mination de contenus racistes et antiracistes. Nous avons donc effectu&#233; trois exp&#233;riences : sur
le texte brut et en conservant les nombres et le code HTML. Dans la suite de cette section, nous
pr&#233;cisons la mani&#232;re de traiter et de repr&#233;senter les documents et d&#233;crivons les algorithmes de
classification utilis&#233;s.
</p>
<p>Repr&#233;sentation des documents Comme dans la majorit&#233; des algorithmes de classification,
nous utilisons une repr&#233;sentation vectorielle (Salton et al., 1975) des documents : le sac de mots.
Ainsi chaque document &#22; est repr&#233;sent&#233; par un vecteur &#23;&#24;&#22;&#26;&#25; de ffflfi , o&#249; chaque coordonn&#233;e &#22;&#12;ffi est
calcul&#233;e par rapport &#224; la fr&#233;quence &#31;! &quot; $#&#16;%!&amp;'&#22;)( du terme % dans &#22; selon la formule :
</p>
<p>&#22;&#26;ffi+*-,/.fl&#10;102.3#&#16;%!&amp;'&#22;)(&#21;*5476&#5;89#;:=&lt;&gt;&#31;! &quot; $#&#16;%!&amp;'&#22;)(?(A@B476&#5;89#
</p>
<p>C
</p>
<p>C
</p>
<p>#&#16;%D(
</p>
<p>(
</p>
<p>o&#249; C est le nombre de documents du corpus et C #7%E( est le nombre de documents dans lequel
% appara&#238;t au moins une fois. Un terme se voit donc attribuer un poids d&#8217;autant plus fort qu&#8217;il
appara&#238;t souvent dans le document et rarement dans le corpus complet. Chaque vecteur &#23;&#24;&#22;&#19;&#25; est
ensuite normalis&#233; en &#23;F&#22; &#25; afin de ne pas favoriser les documents les plus longs. Pour effectuer la
normalisation, nous divisons chaque coordonn&#233;e &#22;)ffi par la norme euclidienne du vecteur :
</p>
<p>&#22;&#26;ffi *
</p>
<p>&#22;&#26;ffi
</p>
<p>G H
</p>
<p>ffi
</p>
<p>&#22;&#19;I
</p>
<p>ffi
</p>
<p>Ces valeurs sont ensuite trait&#233;es pas les algorithmes de classification que nous utilisons : Roc-
chio, k-PPV et SVM.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;tection des contenus racistes sur l&#8217;Internet
</p>
<p>Rocchio Rocchio (Rocchio, 1971) est un des plus vieux algorithmes de classification et l&#8217;un
des plus simples. Un profil prototypique &#23;&#24; J&#25; est calcul&#233; pour chaque classe  selon :
</p>
<p> Jffi+* KC&#11;L&#21;MNJO
</p>
<p>L
</p>
<p>&#22;&#26;ffi P
</p>
<p>:QP
</p>
<p>KC LRMNTSO
</p>
<p>L
</p>
<p>&#22;&#26;ffi (1)
</p>
<p>o&#249; C&#11;L est le nombre de documents dans  , C L est le nombre de documents n&#8217;appartenant pas
&#224;  , et
</p>
<p>K
</p>
<p>est un param&#232;tre du mod&#232;le compris entre 0 et 1. Dans les situations o&#249; un document
peut &#234;tre attribu&#233; &#224; une seule classe,
</p>
<p>K
</p>
<p>est souvent positionn&#233; &#224; 1. Ces profils correspondent au
barycentre des exemples (avec un coefficient positif pour les exemples de la classe et n&#233;gatif
pour les autres). Ces vecteurs sont &#233;galement normalis&#233;s de la m&#234;me fa&#231;on que les documents.
Le classement de nouveaux documents s&#8217;op&#232;re en calculant la distance euclidienne (&#233;quivalente
au produit scalaire et &#224; la similarit&#233; en cosinus puisque tous les vecteurs sont de norme 1) entre la
repr&#233;sentation vectorielle du document et celle de chacune des classes ; le document est assign&#233;
&#224; la classe la plus proche.
</p>
<p>K plus proches voisins (k-PPV) k-PPV est un algorithme de la reconnaissance des formes
qui a prouv&#233; son efficacit&#233; face au traitement de donn&#233;es textuelles (Yang, 1997). La phase
d&#8217;apprentissage consiste &#224; stocker les exemples &#233;tiquett&#233;s. Le classement de nouveaux textes
s&#8217;op&#232;re en calculant la distance euclidienne entre la repr&#233;sentation vectorielle du document et
celles des exemples du corpus ; les U &#233;l&#233;ments les plus proches sont s&#233;lectionn&#233;s et le document
est assign&#233; &#224; la classe majoritaire (le poids de chaque exemple dans le vote &#233;tant &#233;ventuellement
pond&#233;r&#233; par sa distance).
</p>
<p>Support Vector Machine (SVM) SVM (Vapnik, 1995) est un des algorithmes les plus perfor-
mants en classification textuelle (Joachims, 1998). L&#8217;id&#233;e principale est de trouver un hyperplan
qui s&#233;pare au mieux les donn&#233;es et dont la s&#233;paration (ou marge : distance s&#233;parant la fronti&#232;re
du plus proche exemple) est aussi grande que possible. Cette recherche correspond &#224; un pro-
bl&#232;me d&#8217;optimisation au cours duquel des vecteurs supports (les exemples les plus proches de
l&#8217;hyperplan) sont s&#233;lectionn&#233;s. L&#8217;hyperplan calcul&#233; permet ainsi de s&#233;parer l&#8217;espace en deux
zones. Pour classer les nouveaux documents, on calcule dans quelle r&#233;gion de l&#8217;espace ils se
situent et on leur attribue la classe correspondante.
</p>
<p>5 R&#233;sultats et Discussion
</p>
<p>5.1 Comparaison des performances des algorithmes
</p>
<p>Pour mesurer les performances de classifieurs, nous utilisons la m&#233;thode standard de validation.
Le corpus est al&#233;atoirement divis&#233; en deux parties : le corpus d&#8217;apprentissage avec lequel les
classifieurs apprennent et le corpus de test avec lequel on calcule le taux de performance.
</p>
<p>Les r&#233;sultats obtenus sont pr&#233;sent&#233;s dans la partie gauche du tableau 1. Les performances rela-
tives de chaque algorithme sont similaires &#224; celles de (Yang, 1997) et (Joachims, 1998) : Roc-
chio est moins performant que les k-PPV, eux-m&#234;mes &#233;tant l&#233;g&#232;rement inf&#233;rieurs aux SVMs.
Cette persistance des r&#233;sultats tend &#224; montrer que la nature du corpus trait&#233; n&#8217;est pas singu-
li&#232;rement diff&#233;rente des donn&#233;es trait&#233;es dans les probl&#232;mes classiques. Malgr&#233; le fait que la
d&#233;finition des classes ne soit pas th&#233;matique mais repose sur une analyse du discours, la des-
cription lexicale d&#8217;un document suffit &#224; discriminer ces deux classes. Dans tous les cas, les
performances sont assez impressionnantes, avec une moyenne sup&#233;rieure &#224; 0.90.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Romain Vinot, Natalia Grabar, Mathieu Valette
</p>
<p>Algorithme Performance
Rocchio 0.89
1-PPV 0.94
</p>
<p>10-PPV 0.94
30-PPV 0.92
</p>
<p>SVM 0.95
</p>
<p>Algorithme % d&#8217;exemples performance
non class&#233;s
</p>
<p>0% 0.94
10-PPV 10% 0.96
</p>
<p>20% 0.99
0% 0.89
</p>
<p>Rocchio 15% 0.93
35% 0.98
0% 0.95
</p>
<p>SVM 10% 0.97
20% 0.99
</p>
<p>TAB. 1 &#8211; Performance des diff&#233;rents algorithmes
</p>
<p>Tous les algorithmes pr&#233;sent&#233;s ici attribuent une valeur de confiance pour chaque pr&#233;diction
(qui n&#8217;est pas repr&#233;sent&#233;e dans les r&#233;sultats). Il est possible d&#8217;utiliser cette valeur afin d&#8217;affecter
les exemples trop ambigus &#224; une classe de rejet. Ainsi, les exemples dont la valeur de confiance
est inf&#233;rieure &#224; un seuil pr&#233;d&#233;fini sont &#171; rejet&#233;s &#187;. Ce mode de fonctionnement est utile lorsqu&#8217;il
est pr&#233;f&#233;rable d&#8217;avouer son ignorance plut&#244;t que de faire une erreur. Avec cette classe de rejet, il
est possible d&#8217;avoir plus de 99% d&#8217;exemples correctement class&#233;s en rejetant jusqu&#8217;&#224; 20% des
exemples (avec les K plus proches voisins ou les SVMs).
</p>
<p>5.2 Analyse manuelle des r&#233;sultats
</p>
<p>&#192; partir de l&#8217;analyse des 100 premi&#232;res formes d&#8217;un sac de mots (les termes avec les poids les
plus forts dans Rocchio) et des documents mal class&#233;s, nous allons tenter de d&#233;terminer quels
sont les atouts et les limites de la classification algorithmique.
</p>
<p>5.2.1 Les mots retenus par Rocchio
</p>
<p>Le sac de mots raciste est constitu&#233; de mots qui participent &#224; la construction des syntagmes
identificatoires des sites du corpus. Ces items, qui ont les pond&#233;rations les plus fortes, des-
sinent la &#8220;signature lexicale&#8221; de chaque site. Du point de vue des documents, les items rel&#232;vent
aussi bien du niveau textuel (slogans, mots d&#8217;ordre, qualifications des cibles) que p&#233;ritextuel
(sommaires, rubriques, titres), lesquels se r&#233;p&#232;tent &#224; l&#8217;identique dans plusieurs documents d&#8217;un
m&#234;me site. Ainsi, les mots racaille et racailles qui apparaissent parmi les quatre formes les plus
d&#233;terminantes, constituent la d&#233;nomination euph&#233;mique privil&#233;gi&#233;e des cibles pour les auteurs
du site sos-racaille.org.
</p>
<p>De m&#234;me, le mot visage, en 17&#232;me position, participe &#224; la construction d&#8217;une rubrique (&#8220;le vrai
visage des potes&#8221;) et du titre d&#8217;un article (&#8220;le vrai visage des islamistes&#8221;)2. En fait, les mots du
racisme qui ne sont pas sp&#233;cifiques &#224; un site particulier mais au discours raciste apparaissent au
</p>
<p>2Potes est un moyen de qualifier les victimes particuli&#232;rement fr&#233;quent sur le site SOS-Racaille, lequel parodie
celui de l&#8217;association antiraciste SOS-Racisme qui s&#8217;est fait conna&#238;tre dans les ann&#233;es 80 par le slogan &#8220;Touche
pas &#224; mon pote&#8221;.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;tection des contenus racistes sur l&#8217;Internet
</p>
<p>sommet du sac de mots &#224; condition qu&#8217;ils soient instanci&#233;s dans les sommaires (par exemple :
honte, envahie, agressions, d&#233;sinformation, etc.).
Quoi qu&#8217;il en soit, la forte pr&#233;gnance des informations p&#233;ritextuelles et identificatoires nous
renseigne sur l&#8217;importance de la structure du document Internet pour les pond&#233;rations effectu&#233;es
par les algorithmes de classification (en l&#8217;occurrence Rocchio). Ainsi, en l&#8217;&#233;tat actuel de nos
travaux, nous pouvons dire d&#8217;une part, que les algorithmes identifient et classent des documents
(Internet) plut&#244;t que des textes, pour autant que cette distinction soit pertinente, et d&#8217;autre part,
qu&#8217;ils identifient ces documents en fonction de signatures lexicales plut&#244;t que de modalit&#233;s
&#233;nonciatives racistes.
</p>
<p>Le linguiste, qui est naturellement enclin &#224; s&#8217;int&#233;resser davantage au texte lui-m&#234;me plut&#244;t qu&#8217;au
p&#233;ritexte, peut s&#8217;&#233;tonner que les &#233;l&#233;ments qui lui semblent caract&#233;ristiques du discours raciste
et non des sites racistes, soient rel&#233;gu&#233;s au second plan. Les r&#233;sultats obtenus dessinent en effet
tr&#232;s nettement une ontologie particuli&#232;re (on pourrait dire &#8220;r&#233;gionale&#8221;) &#224; quelques sites3. Or, le
discours raciste, en tant qu&#8217;il proc&#232;de d&#8217;une simple opposition (nous vs. les autres) avec d&#233;pr&#233;-
ciation et p&#233;joration des attributs des autres, ne rel&#232;ve pas &#224; proprement parler d&#8217;une ontologie.
Ainsi, on sait que le champ s&#233;mantique de la v&#233;racit&#233; (vrai, v&#233;ritable, etc.), caract&#233;ristique du
discours raciste (nous d&#233;tenons la v&#233;rit&#233; ; les autres et leurs complices promeuvent le mensonge)
appara&#238;t &#234;tre un crit&#232;re de premi&#232;re importance. Or, il est absent des 100 premi&#232;res formes du
sac de mots analys&#233;. Certes, &#224; mesure que le corpus augmentera, des &#233;l&#233;ments moins sp&#233;ci-
fiques aux sites gagneront en importance. On peut &#233;galement penser qu&#8217;une approche morph&#233;-
matique (mise en place dans le Projet Princip) neutraliserait les variations morpho-syntaxiques
(par exemple vraie, vrais, etc.) que ne peuvent traiter nos algorithmes. Des analyses ult&#233;rieures
devront en rendre compte.
</p>
<p>Dans le sac de mots antiraciste de Rocchio, ce sont tr&#232;s nettement les &#233;l&#233;ments lexicaux appar-
tenant &#224; la rh&#233;torique et aux modalit&#233;s d&#8217;actions antiracistes qui apparaissent en premier lieu4 :
entit&#233;s nomm&#233;es (m&#233;gret, vitrolles), qualifications (fascisme, extr&#234;me droite), explications (ch&#244;-
mage, &#233;ducation) et actions (mouvement, associations, manifestation). Les crit&#232;res choisis par
les algorithmes sont dans ce cas plus proches de ceux retenus par les linguistes.
</p>
<p>5.2.2 Les erreurs de classifications
</p>
<p>Du fait de l&#8217;orientation lexicale des techniques de classification algorithmiques, les &#233;cueils ren-
contr&#233;s sont sensiblement les m&#234;mes que dans la d&#233;tection par mot cl&#233;s (voir sec. 1). Ainsi, il
suffit que la connexion lexicale entre un texte antiraciste et le sous-corpus raciste d&#8217;apprentis-
sage soit un peu trop &#233;lev&#233; pour que ledit texte soit class&#233; comme raciste. Mais l&#8217;inverse n&#8217;est
pas vrai : les erreurs de classement des textes racistes ne rel&#232;vent pas &#224; proprement parler des
formes qui composent leur vocabulaire, mais des modalit&#233;s d&#8217;expression. Autrement dit, si les
algorithmes n&#8217;ont pas &#233;t&#233; capables de les classer correctement, c&#8217;est parce que le racisme y est
polic&#233; et euph&#233;mis&#233;.
</p>
<p>D&#8217;une mani&#232;re g&#233;n&#233;rale, il semble que les algorithmes aient mieux class&#233; les documents an-
tiracistes que les documents racistes. C&#8217;est, selon nous, l&#8217;indice que le discours antiraciste est
</p>
<p>3Pour information, les trente premi&#232;res formes du sac de mots raciste &#233;tudi&#233; sont : cliquez, racailles, islamistes,
racaille, antiblanc, photos, potes, moussaoui, sos, bois, am&#233;lie, site, brigadier, piti&#233;, silence, avocats, blancs, vi-
sage, justice, d&#233;p&#234;ches, banni&#232;res, henri, &#233;cran, musulmans, d&#233;sinformation, islamiste, attentats, terroristes, sou-
tenir, tournantes. Toutes ces formes sont actualis&#233;es dans le p&#233;ritexte des documents.
</p>
<p>4Pr&#233;cisons que dans les documents antiracistes, le p&#233;ritexte est souvent moindre, voire inexistant.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Romain Vinot, Natalia Grabar, Mathieu Valette
</p>
<p>d&#8217;une relative homog&#233;n&#233;it&#233;, tandis que le discours raciste se manifeste de fa&#231;ons beaucoup plus
vari&#233;es, d&#8217;une part parce que, comme nous l&#8217;avons vu, il se situe en de&#231;&#224; de l&#8217;ontologie garante
d&#8217;une unit&#233; lexicale, d&#8217;autre part, parce qu&#8217;il est actualis&#233; dans diff&#233;rents discours et genres
(discours id&#233;ologique, politique, genres pamphl&#233;taire, essayiste, journalistique, etc.).
Les textes antiracistes mal class&#233;s sont essentiellement (1) des textes litt&#233;raires (paroles de chan-
son, extraits de romans en ligne), c&#8217;est-&#224;-dire des textes qui ne r&#233;pondent pas au style argumen-
tatif caract&#233;ristique de l&#8217;antiracisme, et (2) des textes o&#249;, &#224; des fins rh&#233;toriques, les auteurs
recourent abondamment &#224; l&#8217;antiphrase et &#224; la citation5.
</p>
<p>Les documents racistes mal class&#233;s, beaucoup plus nombreux, sont le plus souvent des textes
politiques et id&#233;ologiques o&#249; le racisme n&#8217;est pas le th&#232;me principal et se trouve ench&#226;ss&#233; dans
une rh&#233;torique de l&#8217;euph&#233;misme (par exemple : &#233;loge de personnalit&#233;s vichystes, avec allusion &#224;
la situation contemporaine, article de webzine d&#8217;extr&#234;me droite s&#8217;en prenant ponctuellement aux
populations immigr&#233;es, etc.). Les mesures statistiques sur lesquelles reposent les algorithmes
de classification sont, en cons&#233;quence, inefficientes.
</p>
<p>En r&#233;sum&#233;, on peut dire que devant deux ensembles de documents tr&#232;s diff&#233;rents quant &#224;
leur structure et aux modalit&#233;s &#233;nonciatives, les algorithmes de classification et les linguistes
adoptent une strat&#233;gie semblable en ce qui concerne le discours antiraciste, et diff&#233;rente avec
le discours raciste : les algorithmes privil&#233;gient une approche globale du document et, d&#8217;une
certaine fa&#231;on, n&#233;glige la dimension &#233;nonciative, au sens classique, du discours raciste ; tandis
que les linguistes d&#233;laissent le p&#233;ritexte et se focalisent sur les modalit&#233;s d&#8217;&#233;nonciation. Dans le
cadre du Projet Princip, cette diff&#233;rence de &#8220;point de vue&#8221; nous a conduit &#224; r&#233;&#233;valuer le p&#233;ritexte
et &#224; consid&#233;rer le document Internet comme un objet textuel sp&#233;cifique dont la complexit&#233; peut
&#234;tre &#233;tudi&#233;e de mani&#232;re linguistique (nous avons ainsi attribu&#233;s une dimension pragmatique au
p&#233;ritexte). - Un bel exemple de communication machine-homme.
</p>
<p>5.3 Influence des nombres et du code HTML sur les r&#233;sultats
</p>
<p>Les r&#233;sultats obtenus avec la prise en compte du code HTML et de nombres sont indiqu&#233;s dans le
tableau 2. Ces informations compl&#233;mentaires influencent l&#233;g&#232;rement les r&#233;sultats en am&#233;liorant
les performances des algorithmes. L&#8217;influence est surtout visible avec la prise en compte du
code HTML.
</p>
<p>Algorithme Rocchio 1-PPV 10-PPV 30-PPV SVM
Sans chiffres ni HTML 0.89 0.94 0.94 0.92 0.95
</p>
<p>Avec les chiffres 0.89 0.93 0.94 0.92 0.95
Avec source HTML 0.94 0.94 0.95 0.96 0.96
</p>
<p>TAB. 2 &#8211; Performance avec des documents comportant les nombres et le code HTML
</p>
<p>L&#8217;analyse des nombres et du code HTML discriminants apporte la confirmation &#224; notre hypo-
th&#232;se que ces &#233;l&#233;ments constituent des ancrages suppl&#233;mentaires dans les textes.
</p>
<p>Nous constatons ainsi la pr&#233;sence de dates r&#233;centes (2001, 2002) dans les documents racistes,
5Ainsi, k-PPV n&#8217;a pas &#233;t&#233; capable - et c&#8217;est bien compr&#233;hensible ! - de d&#233;tecter l&#8217;ironie dans l&#8217;extrait sui-
</p>
<p>vant : &#8220;Ce n&#8217;est plus l&#8217;infection jud&#233;o-cosmopolite qui est dans la ligne de mire. Mais, l&#8217;invasion des allog&#232;nes
qui, dans leur perversit&#233;, imposent leur loi, celle des bandes ethniques - On n&#8217;est plus chez nous, bordel !&#8221;
(http ://www.homme-moderne.org/kroniks/vlad/001001.html)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;tection des contenus racistes sur l&#8217;Internet
</p>
<p>tr&#232;s gourmands des faits divers qui, &#224; travers des r&#233;cits dat&#233;s et document&#233;s, permettent d&#8217;avoir
un lien r&#233;el avec la vie quotienne. Les sites de ce type ont, en r&#232;gle g&#233;n&#233;ral, une m&#233;moire courte.
</p>
<p>En ce qui concerne les &#233;l&#233;ments du code HTML les plus discriminants, il s&#8217;agit de balises,
d&#8217;attributs, de valeurs d&#8217;attributs et d&#8217;entit&#233;s SGML. Ainsi, dans le corpus raciste, l&#8217;attribut
HTML pics indique que les documents de ce corpus utilisent et affichent souvent les images
(photos, dessins, caricatures, banni&#232;res, etc.). La balise meta, qui peut &#234;tre utilis&#233;e pour noter
une liste de mots cl&#233;s ou d&#8217;autres informations, est &#233;galement discriminante. Les polices de
caract&#232;res arial et verdana semblent &#234;tre d&#233;di&#233; &#224; ces documents, fait confirm&#233; par une &#233;tude sur
la pr&#233;sentation graphique des documents racistes (Nicinski, 2002).
Dans le corpus antiraciste, le terme class indique une utilisation plus fr&#233;quente de Java scripts
dans ces documents. Par contre, avec les entit&#233;s SGML (eacute, egrave, ecirc, ocirc, etc.)
comme termes discriminants, il est difficile de savoir si leur pr&#233;sence discriminante n&#8217;est pas
due &#224; l&#8217;utilisation d&#8217;un &#233;diteur HTML donn&#233;.
</p>
<p>On en vient &#224; se poser la question sur la repr&#233;sentativit&#233; et compl&#233;tude de corpus &#233;tudi&#233;s. Dans
quelle mesure les traits trouv&#233;s dans ces exp&#233;riences sont discriminants de contenus racistes et
antiracistes ? Vont-ils toujours &#234;tre discriminants sur d&#8217;autres corpus et sur les documents du
Web ? La convergence des r&#233;sultats provenant de diff&#233;rentes &#233;tudes et exp&#233;riences semblerait
indiquer que certains de ces traits (mots et expressions, polices de catact&#232;res, utilisation des
images et des balises meta, pr&#233;sence de dates r&#233;centes) sont r&#233;v&#233;lateurs de contenus que nous
cherchons &#224; d&#233;tecter. La tra&#231;abilit&#233; et l&#8217;explication d&#8217;autres traits est plus difficile et nuanc&#233;e.
Notons qu&#8217;une &#233;tude sp&#233;cifique du code HTML est en cours, de m&#234;me que l&#8217;&#233;tude de ces corpus
avec d&#8217;autres approches et outils.
</p>
<p>Il est clair que l&#8217;apprentissage effectu&#233; sur ces corpus devra &#234;tre confront&#233; &#224; un corpus raciste
plus grand, mais aussi &#224; un corpus neutre ou bien le corpus compos&#233; de documents proches
mais non pertinents. Il est clair aussi que ces corpus, en cours de constitution, doivent &#233;voluer.
</p>
<p>6 Conclusion
</p>
<p>Nous avons pr&#233;sent&#233; ici des exp&#233;riences de traitement de corpus raciste et antiraciste avec des
algorithmes de classification automatique. Ils fonctionnent sur un principe relativement simi-
laire au filtrage par mots-cl&#233;s mais permettent une r&#233;actualisation plus ais&#233;e puisque le r&#233;-
apprentissage est automatique d&#232;s lors que le corpus existe. Ces algorithmes, habituellement
utilis&#233;s pour la classification th&#233;matique &#171; classique &#187;, semblent &#234;tre adapt&#233;s aux donn&#233;es &#171; sp&#233;-
ciales &#187; des corpus trait&#233;s. Leur performance est sup&#233;rieure &#224; 90% et m&#234;me &#224; 99% si on accepte
une classe de rejet. Nous avons pr&#233;sent&#233; des exp&#233;riences faites avec du texte brut, mais aussi en
tenant compte des nombres et du code HTML. Ces informations compl&#233;mentaires am&#233;liorent
tr&#232;s l&#233;g&#232;rement les performances.
</p>
<p>A notre stade d&#8217;investigation, si l&#8217;on met de c&#244;t&#233; la question de l&#8217;euph&#233;misation, la plus grande
part des erreurs qui subsistent semblent &#234;tre du m&#234;me type que celles pr&#233;sent&#233;es dans les &#233;tudes
de (Pang et al., 2002 ; Turney, 2002) : seule une petite partie du document est caract&#233;ristique
du racisme. L&#8217;information est noy&#233;e dans le reste du texte et les algorithmes statistiques qui
op&#232;rent une moyenne de tous les termes du document ne parviennent pas &#224; d&#233;gager la ou les
phrases importantes. Cet &#233;chec semble li&#233; &#224; la pr&#233;dominance du p&#233;ritexte dans le choix des
mots discriminants (cf. 5.1.1) : du fait de la redondance des sommaires et autres informations</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Romain Vinot, Natalia Grabar, Mathieu Valette
</p>
<p>propre &#224; la structure des pages HTML, les documents globalement racistes sont mieux filtr&#233;s
que ceux qui ne le sont que localement. Pour pallier ces faiblesses, dans l&#8217;outil final Princip,
les documents seront &#233;galement pris en charge par des modules plus fins avec utilisation d&#8217;in-
formations plus complexes que la pr&#233;sence/absence de termes simples : cha&#238;ne de caract&#232;res
(morph&#232;mes), expressions complexes (lexies), isotopies, mesure de la cooccurrence, etc. Ces
modules collaboreront selon un ensemble de strat&#233;gies pr&#233;d&#233;finies.
</p>
<p>Remerciements
</p>
<p>Nous remercions Fran&#231;ois Rastier d&#8217;avoir nou&#233; cette collaboration. Nous remercions Monique
Slodzian, Fran&#231;ois Rastier, Fran&#231;ois Yvon et Pierre Zweigenbaum pour leurs conseils, discus-
sions et soutien pr&#233;cieux pour ce travail.
</p>
<p>R&#233;f&#233;rences
ANDROUTSOPOULOS I., KOUTSIAS J., CHANDRINOS K. V. &amp; SPYROPOULOS C. D. (2000). An
experimental comparison of naive Bayesian and keyword-based anti-spam filtering with personal e-mail
messages. In N. J. BELKIN, P. INGWERSEN &amp; M.-K. LEONG, Eds., Proceedings of SIGIR-00, 23rd
ACM International Conference on Research and Development in Information Retrieval, p. 160&#8211;167,
Athens, GR : ACM Press, New York, US.
CARRERAS X. &amp; M&#193;RQUEZ L. (2001). Boosting trees for anti-spam email filtering. In Proceedings of
RANLP-2001, 4th International Conference on Recent Advances in Natural Language Processing.
GRABAR N. &amp; BERLAND S. (2001). Construire un corpus web pour l&#8217;acquisition terminologique. In
Terminologie et intelligence artificielle, p. 44&#8211;54, Nancy.
JOACHIMS T. (1998). Text categorization with support vector machines : Learning with many relevant
features. In ECML-98, Tenth European Conference on Machine Learning, p. 137&#8211;142.
NICINSKI M. (2002). Analyse et typologie des images dans les sites racistes. Rapport interne, CRIM-
INALCO. M&#233;moire de DESS, Fran&#231;ois Rastier (dir.).
PANG B., LEE L. &amp; VAITHYANATHAN S. (2002). Thumbs up ? sentiment classification using machine
learning techniques. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language
Processing (EMNLP).
ROCCHIO J. J. (1971). The SMART Retrieval System : Experiments in Automatic Document Processing,
chapter 14, Relevance Feedback in Information Retrieval, p. 313&#8211;323. Gerard Salton (editor), Prentice-
Hall Inc. : New Jersey.
SALTON G., WONG A. &amp; YANG C. (1975). A vector space model for information retrieval. Communi-
cations of the ACM, 18(11), 613&#8211;620.
TDT (2001). The Topic Detection and Tracking 2001, evaluation project. http ://www.nist.gov/TDT.
TURNEY P. (2002). Thumbs up or thumbs down ? semantic orientation applied to unsupervised clas-
sification of reviews. In Proceedings of the 40th Annual Meeting of the Association for Computational
Linguistics, p. 417&#8211;424, Philadelphia.
VAPNIK V. N. (1995). The Nature of Statistical Learning Theory. Springer.
YANG Y. (1997). An evaluation of statistical approach to text categorization. Rapport interne Technichal
Report CMU-CS-97-127, Carnegie Mellon University.</p>

</div></div>
</body></html>