TALN 2003, Batz-sur-Mer, 11—14juin 2003

Application d’algorithmes de classiﬁcation automatique pour
la détection des contenus racistes sur l’Internet

Romain Vinotl, Natalia Grabar2’3, Mathieu Valette2=4
1 Ecole Nationale Supérieure des Telecommunications
2 Centre de Recherche en Ingénierie Multilingue - INALCO
3 STIM - DIAM, AP-HP Pitié-Salpétriere, Université Paris 6
4 UMR 7114 CNRS/Paris X (MoDyCo)

romain.vinot@enst.fr, ngr@biomath.jussieu.fr, mathieu.valette@free.fr

Mots-clefs — Keywords

Classiﬁcation automatique, Rocchio, kPPV, SVM, Internet, ﬁltrage de l’information
Text classiﬁcation, Rocchio, kNN, SVM, Internet, information ﬁltering

Résumé - Abstract

Le ﬁltrage de contenus illicites sur Internet est une problématique difﬁcile qui est actuellement
résolue par des approches a base de listes noires et de mots-clés. Les systemes de classiﬁca-
tion textuelle par apprentissage automatique nécessitant peu d’interventions humaines, elles
peuvent avantageusement remplacer ou compléter les méthodes précédentes pour faciliter les
Inises a jour. Ces techniques, traditionnellement utilisées avec des catégories déﬁnies par leur
sujet (économie ou sport par exemple), sont fondées sur la présence ou l’absence de mots. Nous
présentons une évaluation de ces techniques pour le ﬁltrage de contenus racistes. Contrairement
aux cas traditionnels, les documents ne doivent pas étre catégorisés suivant leur sujet mais sui-
vant le point de vue énoncé (raciste ou antiraciste). Nos résultats montrent que les classiﬁeurs,
essentiellement lexicaux, sont néanmoins bien adaptées : plus de 90% des documents sont cor-
rectement classés, voir méme 99% si l’on accepte une classe de rejet (avec 20% d’exemples non
classés).

Filtering of illicit contents on the Internet is a difﬁcult issue which is currently solved with black
lists and keywords. Machine-learning text categorization techniques needing little human inter-
vention can replace or complete the previous methods to keep the ﬁltering up-to-date easily.
These echniques, usually used with topic classes (economy or sport for instance), are based on
the presence or absence of words. We present an evaluation of these techniques for racism ﬁlte-
ring. Unlike the traditional systems, documents are not categorized according to their main topic
but according to the expressed point of view (racist or anti-racist). Our results show that these
lexical techniques are well adapted : more than 90% of the documents are correctly classiﬁed,
or even 99% if a rejection class is accepted (20% of the examples are not classiﬁed).

Romain Vinot, Natalia Grabar, Mathieu Valette

1 Introduction

L’ experience présentée ici a été faite dans le cadre du proj et européen Princip (Plateforme pour
la Recherche, l’Identiﬁcati0n et la Neutralisation des Contenus Illégaux et Préjudiciables sur
l ’Im,‘emet)1. Princip s’inscrit dans l’action Safer Internet Action Plan de la Communauté euro-
péenne et conceme la détection de contenus illicites relatifs au racisme et au révisionnisme sur
le Web.

Cette problématique, semblable a la détection d’autres contenus préjudiciables (pédophilie, tra-
ﬁc d’ armes et de drogue, pornographie), peut étre abordée avec deux approches : ﬁltrage par liste
noire et par mots clés. Les deux approches peuvent donner des résultats satisfaisants mais elles
ont également des limites. Le ﬁltrage par liste noire consiste a ﬁltrer les pages dont l’adresse
URL fait partie d’une liste constituée préalablement. Dans cette approche, il ne s’agit pas de
la détection, mais uniquement du blocage de pages indésirables. La faiblesse principale ici est
la mise a jour des listes noires : le Web évolue rapidement, de nouveaux sites apparaissent,
d’autres se déplacent ou bien disparaissent. Le principe de ﬁltrage par mots clés suppose que
si un des mots clés révélateurs est trouvé dans une page HTML, l’acces a cette page doit étre
réglementé. Cette méthode s’avere faillible. Le sens des mots clés est susceptible de changer, a
la fois en synchronie (en fonction du contexte) et en diachronie (selon les époques). Ainsi, negre
recoit des valeurs radicalement différentes selon qu’il s’agit de l’art negre, de la téte de negre,
du negre d’un écrivain ou du negre tel que le mot était couramInent usité aux X VI I I 9"” et
X I X “"8 siecles. En somme, l’insulte sale negre n’est qu’un cas d’instanciation parmi d’autres.
Avec des mots clés discrimininants, cette technique peut donc permettre de repérer les pages
qui traitent du racisme mais ne permet pas de déterminer si les pages exposent un propos ra-
ciste ou non. Une autre limite est la variabilité du contenu et de marqueurs lexicaux dans les
pages illicites. Les mots neutres a l’origine peuvent étre récupérés et utilisés dans un contexte
raciste (par exemple jeune sous-entend jeune d ’0rigine étrangere). Une « réhabilitation » des
mots (leur passage des contenus racistes vers des contenus neutres et antiracistes) est aussi
possible. Les phénomenes linguistiques de créativité lexicale rendent également la tache plus
ardue. Par exemple, le verlan (beurs, feujs, rabzas), la modiﬁcation de l’orthographe (naigre au
lieu de negre), les emprunts (bougnoul, gnoul, Sieg Heil). Tous ces exemples montrent que les
mots clés doivent aussi étre mis a jour régulierement et de préférence en puisant les données
directement a la source : dans les pages Web.

Dans notre projet, nous avons opté pour une utilisation de listes noires constituées grace a
une étude linguistique des documents. L’ approche linguistique suppose que la combinaison
d’indices venant de plusieurs niveaux d’unités linguistiques (caracteres, morphemes, catégories
syntaxiques, expressions complexes, isotopies sémantiques, code HTML, etc.) et basée sur une
analyse plus globale des documents Web permet de mieux cerner et proﬁler le contenu de ces
documents. La détection et l’analyse d’indices de différents niveaux devient possible avec des
outils lexicographiques, statistiques et de TAL.

L’ experience que nous présentons ici conceme l’application de systemes de classiﬁcation auto-
matique (classiﬁeurs) pour la détection de contenus racistes. Lorsqu’il est possible d’attribuer
une ou plusieurs categories a un ensemble de documents, ces systemes peuvent, a partir d’un
corpus ou la catégorie de chaque document est connue a priori, « apprendre » une déﬁnition
de ces catégories et ensuite les attribuer automatiquement a de nouveaux documents. Ces sys-
temes fonctionnent généralement au niveau lexical des documents et fondent leur décision sur

1Des infonnations plus amples peuvent étre trouvées sur la page http : / /www . princip . net.

Detection des contenus racistes sur l’Internet

la presence ou l’absence de mots.

Pour cette experience, nous disposons d’un corpus categorise. L’algorithme de classiﬁcation
doit donc discriminer les pages comportant des propos racistes de celles comportant des propos
antiracistes. Contrairement aux domaines d’application « traditionnels » de classiﬁeurs (par
exemple, sport ou economie) ou une vue « ontologique » du domaine est possible avec des
mots-cles precis et connus, la thematique que nous explorons ici est plus difﬁcile a cemer a
priori. D’autant plus que nous cherchons a distinguer des points de vue differents qui portent
sur le meme sujet. La question que nous nous posons alors est de voir jusqu’a quel point les
techniques lexicales sont utilisables pour discriminer ce genre de difference. Autrement dit,
existe-il des differences lexicales entre les discours racistes et antiracistes ?

Dans la suite de cet article, nous mentionnons des travaux sur l’utilisation de classiﬁeurs tex-
tuels sur des taches non purement thematique (section 2), ensuite nous decrivons les corpus
d’apprentissage et de test (section 3) et les methodes de traitement de ces corpus (section 4).
Nous presentons ensuite les resultats et les discutons (section 5) et nous terminons avec une
conclusion (section 6).

2 Travaux similaires

Les travaux autour du ﬁltrage de courriers electroniques non sollicites (couramment appele
spams) a l’aide de classiﬁeurs textuels exploitent differentes techniques d’apprentissage : Na'1've
Bayes et k plus proches voisins (Androutsopoulos et al., 2000), algorithme genetique, boosting
d’arbre de decision (Carreras & Marquez, 2001). Bien que la stricte deﬁnition de la categorie
spam ne soit pas thematique, il est possible de determiner quelques themes generaux (pomogra-
phie, transfert de fonds, etc) facilement detectables par les indices lexicaux. Ces systemes ont
de tres bonnes performances et commencent a etre deployes en environnement industriel.

Le programme de recherche TDT (Topic Detection and Tracking) (TDT, 2001), sponsorise par
l’agence DARPA, conceme la classiﬁcation d’un ﬂux d’informations suivant l’evenement ge-
nerateur (les nouvelles parlant de deux elections differentes doivent étre classees dans deux
categories separees car l’evenement sous-jacent n’est pas le meme). Cette tache est tres difﬁ-
cile car elle est fondamentalement non thematique. La maj orite des systemes proposes utilisent
neanmoins les classiﬁeurs lexicaux standards et obtiennent des performances peu satisfaisantes.

Pang, Lee et Vaithyanathan (Pang et al., 2002) ont utilise des classiﬁeurs thematiques standards
pour discriminer des critiques de ﬁlms positives et negatives. Peter Turney (Turney, 2002) utilise
« l’orientation semantique » (positive ou negative) des adj ectifs pour determiner la categorie de
critiques de plusieurs types d’objets (ﬁlms, voitures, banques et destinations de voyages). Les
deux evaluations ont des performances moyennes (bien meilleures qu’un classement aleatoire
mais insufﬁsantes pour une utilisation reelle). Dans les deux cas, les auteurs expliquent les
erreurs par le fait que tous ces systemes fonctionnent par agregation des indices trouves sur
chaque zone de texte. Or, le jugement ﬁnal d’une critique n’est pas une simple somme des
jugements de chaque sous-partie (un ﬁlm peut avoir de bons acteurs et de bons dialogues et
recevoir neanmoins une mauvaise appreciation globale).

Dans tous les cas, et comme dans celui du ﬁltrage de propos racistes, il ne s’agit pas de determi-
ner le sujet principal du document : mail sollicite ou non, evenement generateur de la nouvelle,
critique positive ou negative.

Romain Vinot, Natalia Grabar, Mathieu Valette

3 Constitution du corpus

Comme l’outil ﬁnal de detection de contenus illicites est destine a travailler sur le Web, les cor-
pus de travail sont construits egalement a partir de donnees existant sur le Web. Nous utilisons
les moteurs de recherche generaux que nous interrogeons avec des mots cles « sensibles ».

La constitution du corpus est faite en deux etapes : collecte massive de documents et ensuite leur
categorisation manuelle. La collecte de documents est faite de deux manieres : interrogation
manuelle et automatique (Grabar & Berland, 2001) de pages et de sites et leur rapatriement.
Lors de la categorisation manuelle, un document peut etre categorise dans une des categories
predeﬁnies : raciste, antiraciste, revisionniste, anti-revisionniste et non pertinent. En cas de
doute, la categorie indecidable est prevue. Les documents de cette categorie sont analyses par
un organisme competent (Ligue Belge des Droits de l’Homme).

Au moment des experiences presentees ici, les corpus sont en cours de constitution. Le corpus
que nous avons utilise contient 739 documents dont 286 pages racistes, 444 611 occurrences,
tirees de 43 sites et 453 pages antiracistes, 941 007 occ., tirees de 81 sites.

4 Description des algorithmes

Les algorithmes de classiﬁcation fonctionnent au niveau lexical en prenant les tokens des docu-
ments comme unites descriptives (termes). Habituellement, les classiﬁeurs sont utilises sur des
documents texte brut prealablement segmentes sur tous les caracteres non-alphabetiques. Les
unites linguistiques sont donc les mots, la ponctuation et les chiffres ayant ete supprimes. Dans
l’experience que nous presentons ici, nous avons considere les indices non textuelles (nombres,
code HTML) comme des ancrages supplementaires dans le texte et donc utiles pour la discri-
mination de contenus racistes et antiracistes. Nous avons donc effectue trois experiences : sur
le texte brut et en conservant les nombres et le code HTML. Dans la suite de cette section, nous
precisons la maniere de traiter et de representer les documents et decrivons les algorithmes de
classiﬁcation utilises.

Representation des documents Comme dans la majorite des algorithmes de classiﬁcation,
nous utilisons une representation vectorielle (Salton et al. , 1975) des documents : le sac de mots.
Ainsi chaque document d est represente par un vecteur [d] de R”, o1‘1 chaque coordonnee dw est
calculee par rapport a la frequence Occ(w, d) du terme w dans d selon la formule :
N
dw = TFIDF(w, d) = log(1 + 0cc(w, d)) >1: l0g(WU))
o1‘1 N est le nombre de documents du corpus et N (w) est le nombre de documents dans lequel
w apparait au moins une fois. Un terme se voit donc attribuer un poids d’autant plus fort qu’il
apparait souvent dans le document et rarement dans le corpus complet. Chaque vecteur [d] est

ensuite normalise en [Q] aﬁn de ne pas favoriser les documents les plus longs. Pour effectuer la
normalisation, nous divisons chaque coordonnee dw par la norme euclidienne du vecteur :

d.,, = L“
_ \/Em di

Ces valeurs sont ensuite traitees pas les algorithmes de classiﬁcation que nous utilisons : Roc-
chio, k-PPV et SVM.

Détection des contenus racistes sur l’Internet

Rocchio Rocchio (Rocchio, 1971) est un des plus vieux algorithmes de classiﬁcation et l’un
des plus simples. Un proﬁl prototypique [c] est calculé pour chaque classe c selon :
t 1 — t
cw = — d - i d (1)
NC dec jw NE gin

o1‘1 NC est le nombre de documents dans c, N5 est le nombre de documents n’appartenant pas
a c, et t est un parametre du modele compris entre 0 et 1. Dans les situations ou un document
peut étre attribué a une seule classe, t est souvent positionné a 1. Ces proﬁls correspondent au
barycentre des exemples (avec un coefﬁcient positif pour les exemples de la classe et négatif
pour les autres). Ces vecteurs sont également normalisés de la méme facon que les documents.
Le classement de nouveaux documents s’opere en calculant la distance euclidienne (équivalente
au produit scalaire et a la similarité en cosinus puisque tous les vecteurs sont de norme 1) entre la
représentation vectorielle du document et celle de chacune des classes ; le document est assigné
a la classe la plus proche.

K plus proches voisins (k-PPV) k-PPV est un algorithme de la reconnaissance des formes
qui a prouvé son efﬁcacité face au traitement de données textuelles (Yang, 1997). La phase
d’apprentissage consiste a stocker les exemples étiquettés. Le classement de nouveaux textes
s’opere en calculant la distance euclidienne entre la représentation vectorielle du document et
celles des exemples du corpus; les k éléments les plus proches sont sélectionnés et le document
est assigné a la classe majoritaire (le poids de chaque exemple dans le vote étant éventuellement
pondéré par sa distance).

Support Vector Machine (SVM) SVM (Vapnik, 1995) est un des algorithmes les plus perfor-
mants en classiﬁcation textuelle (J oachims, 1998). L’idée principale est de trouver un hyperplan
qui sépare au Inieux les données et dont la séparation (ou marge : distance séparant la frontiere
du plus proche exemple) est aussi grande que possible. Cette recherche correspond a un pro-
bleme d’optimisation au cours duquel des vecteurs supports (les exemples les plus proches de
l’hyperplan) sont sélectionnés. L’hyperplan calculé permet ainsi de séparer l’espace en deux
zones. Pour classer les nouveaux documents, on calcule dans quelle région de l’espace ils se
situent et on leur attribue la classe correspondante.

5 Résultats et Discussion

5.1 Comparaison des performances des algorithmes

Pour mesurer les performances de classiﬁeurs, nous utilisons la méthode standard de validation.
Le corpus est aléatoirement divisé en deux parties : le corpus d’apprentissage avec lequel les
classiﬁeurs apprennent et le corpus de test avec lequel on calcule le taux de performance.

Les résultats obtenus sont présentés dans la partie gauche du tableau 1. Les performances rela-
tives de chaque algorithme sont similaires a celles de (Yang, 1997) et (Joachims, 1998) : Roc-
chio est moins performant que les k-PPV, eux-mémes étant légerement inférieurs aux SVMs.
Cette persistance des résultats tend a montrer que la nature du corpus traité n’est pas singu-
lierement différente des données traitées dans les problemes classiques. Malgré le fait que la
déﬁnition des classes ne soit pas thématique mais repose sur une analyse du discours, la des-
cription lexicale d’un document sufﬁt a discriminer ces deux classes. Dans tous les cas, les
performances sont assez impressionnantes, avec une moyenne supérieure a 0.90.

Romain Vinot, Natalia Grabar, Mathieu Valette

Algorithme % d’exemples performance
non classés
. 0% 0.94
Algoritnme Performance 10_PPV 10% 0'96
ROCCh10 0.89
20% 0.99
1-PPV 0.94
0% 0.89
10-PPV 0.94 .
ROCCh10 15% 0.93
30-PPV 0.92
SVM 0 95 35% 0.98
' 0% 0.95
SVM 10% 0.97
20% 0.99

TAB. 1 — Performance des différents algorithmes

Tous les algorithmes présentés ici attribuent une valeur de conﬁance pour chaque prédiction
(qui n’est pas représentée dans les résultats). Il est possible d’utiliser cette valeur aﬁn d’affecter
les exemples trop ambigus a une classe de rejet. Ainsi, les exemples dont la valeur de conﬁance
est inférieure a un seuil prédéﬁni sont « rejetés ». Ce mode de fonctionnement est utile lorsqu’il
est préférable d’avouer son ignorance plutot que de faire une erreur. Avec cette classe de rejet, il
est possible d’avoir plus de 99% d’exemples correctement classés en rejetant jusqu’a 20% des
exemples (avec les K plus proches voisins ou les SVMs).

5.2 Analyse manuelle des résultats

A partir de l’analyse des 100 premieres formes d’un sac de mots (les termes avec les poids les
plus forts dans Rocchio) et des documents mal classés, nous allons tenter de déterminer quels
sont les atouts et les limites de la classiﬁcation algorithmique.

5.2.1 Les mots retenus par Rocchio

Le sac de mots raciste est constitué de mots qui participent a la construction des syntagmes
identiﬁcatoires des sites du corpus. Ces items, qui ont les pondérations les plus fortes, des-
sinent la “signature lexicale” de chaque site. Du point de vue des documents, les items relevent
aussi bien du niveau textuel (slogans, mots d’ordre, qualiﬁcations des cibles) que péritextuel
(sommaires, rubriques, titres), lesquels se répetent a l’identique dans plusieurs documents d’un
méme site. Ainsi, les mots racaille et racailles qui apparaissent parmi les quatre formes les plus
déterminantes, constituent la dénomination euphémique privilégiée des cibles pour les auteurs
du site sos—racaille . org.

De méme, le mot visage, en 17eme position, participe a la construction d’une rubrique (“le vrai
visage des potes”) et du titre d’un article (“le vrai visage des islamistes”)2. En fait, les mots du
racisme qui ne sont pas spéciﬁques a un site particulier mais au discours raciste apparaissent au

2Potes est un moyen de qualiﬁer les Victimes particulierement frequent sur le site SOS—Racai11e, lequel parodie
celui de 1’association antiraciste SOS—Racisme qui s’est fait connaitre dans les années 80 par le slogan “Touche
pas :21 mon pote”.

Detection des contenus racistes sur l’Intemet

sommet du sac de mots a condition qu’ils soient instancies dans les sommaires (par exemple :
honte, envahie, agressions, désinformation, etc.).

Quoi qu’il en soit, la forte pregnance des informations peritextuelles et identiﬁcatoires nous
renseigne sur l’importance de la structure du document Internet pour les ponderations effectuees
par les algorithmes de classiﬁcation (en l’occurrence Rocchio). Ainsi, en l’etat actuel de nos
travaux, nous pouvons dire d’une part, que les algorithmes identiﬁent et classent des documents
(Internet) plutot que des textes, pour autant que cette distinction soit pertinente, et d’autre part,
qu’ils identiﬁent ces documents en fonction de signatures lexicales plutot que de modalites
enonciatives racistes.

Le linguiste, qui est naturellement enclin a s’interesser davantage au texte lui-meme plutot qu’ au
peritexte, peut s’etonner que les elements qui lui semblent caracteristiques du discours raciste
et non des sites racistes, soient relegues au second plan. Les resultats obtenus dessinent en effet
tres nettement une ontologie particuliere (on pourrait dire “regionale”) a quelques sites3. Or, le
discours raciste, en tant qu’il procede d’une simple opposition (nous vs. les autres) avec depre-
ciation et pejoration des attributs des autres, ne releve pas a proprement parler d’une ontologie.
Ainsi, on sait que le champ semantique de la veracite (vrai, véritable, etc.), caracteristique du
discours raciste (nous detenons la verite ; les autres et leurs complices promeuvent le mensonge)
apparait etre un critere de premiere importance. Or, il est absent des 100 premieres formes du
sac de mots analyse. Certes, a mesure que le corpus augmentera, des elements moins speci-
ﬁques aux sites gagneront en importance. On peut egalement penser qu’une approche morphe-
matique (Ir1ise en place dans le Projet Princip) neutraliserait les variations morpho-syntaxiques
(par exemple vraie, vrais, etc.) que ne peuvent traiter nos algorithmes. Des analyses ulterieures
devront en rendre compte.

Dans le sac de mots antiraciste de Rocchio, ce sont tres nettement les elements lexicaux appar-
tenant a la rhetorique et aux modalites d’actions antiracistes qui apparaissent en premier lieu4 :
entites nommees (mégret, vitrolles), qualiﬁcations (fascisme, extreme droite), explications (cho-
mage, éducation) et actions (mouvement, associations, manifestation). Les criteres choisis par
les algorithmes sont dans ce cas plus proches de ceux retenus par les linguistes.

5.2.2 Les erreurs de classiﬁcations

Du fait de l’orientation lexicale des techniques de classiﬁcation algorithmiques, les ecueils ren-
contres sont sensiblement les memes que dans la detection par mot cles (voir sec. 1). Ainsi, il
sufﬁt que la connexion lexicale entre un texte antiraciste et le sous-corpus raciste d’apprentis-
sage soit un peu trop eleve pour que ledit texte soit classe comme raciste. Mais l’inverse n’est
pas vrai : les erreurs de classement des textes racistes ne relevent pas a proprement parler des
formes qui composent leur vocabulaire, mais des modalites d’expression. Autrement dit, si les
algorithmes n’ont pas ete capables de les classer correctement, c’est parce que le racisme y est
police et euphemise.

D’une maniere generale, il semble que les algorithmes aient mieux classe les documents an-
tiracistes que les documents racistes. C’est, selon nous, l’indice que le discours antiraciste est

3Pour information, les trente premieres formes du sac de mots raciste etudie sont : cliquez, racailles, islamistes,
racaille, antiblanc, photos, potes, moussaoui, sos, bois, ame’lie, site, brigadier, pitie’, silence, avocats, blancs, vi-
sage, justice, dépeches, bannieres, henri, e’cran, musulmans, desinformation, islamiste, attentats, terroristes, sou-
tenir, tournantes. Toutes ces formes sont actualisees dans le peritexte des documents.

4Precisons que dans les documents antiracistes, le peritexte est souvent moindre, Voire inexistant.

Romain Vinot, Natalia Grabar, Mathieu Valette

d’une relative homogénéité, tandis que le discours raciste se manifeste de facons beaucoup plus
variées, d’une part parce que, comme nous l’avons vu, il se situe en deca de l’ontologie garante
d’une unité lexicale, d’autre part, parce qu’il est actualisé dans différents discours et genres
(discours idéologique, politique, genres pamphlétaire, essayiste, journalistique, etc.).

Les textes antiracistes mal classés sont essentiellement (1) des textes littéraires (paroles de chan-
son, extraits de romans en ligne), c’est-a-dire des textes qui ne répondent pas au style argumen-
tatif caractéristique de l’antiracisme, et (2) des textes ou, a des ﬁns rhétoriques, les auteurs
recourent abondamment a l’antiphrase et a la citation5.

Les documents racistes mal classés, beaucoup plus nombreux, sont le plus souvent des textes
politiques et idéologiques ou le racisme n’est pas le theme principal et se trouve enchassé dans
une rhétorique de l’euphéIr1isme (par exemple : éloge de personnalités vichystes, avec allusion a
la situation contemporaine, article de webzine d’ extréme droite s’ en prenant ponctuellement aux
populations immigrées, etc.). Les mesures statistiques sur lesquelles reposent les algorithmes
de classiﬁcation sont, en conséquence, inefﬁcientes.

En resume, on peut dire que devant deux ensembles de documents tres différents quant a
leur structure et aux modalités énonciatives, les algorithmes de classiﬁcation et les linguistes
adoptent une stratégie semblable en ce qui conceme le discours antiraciste, et différente avec
le discours raciste : les algorithmes privilégient une approche globale du document et, d’une
certaine facon, néglige la dimension énonciative, au sens classique, du discours raciste; tandis
que les linguistes délaissent le péritexte et se focalisent sur les modalités d’énonciation. Dans le
cadre du Proj et Princip, cette difference de “point de vue” nous a conduit a réévaluer le péritexte
eta considérer le document Internet comme un obj et textuel spéciﬁque dont la complexité peut
étre étudiée de maniere linguistique (nous avons ainsi attribués une dimension pragmatique au
péritexte). - Un bel exemple de communication machine-homme.

5.3 Inﬂuence des nombres et du code HTML sur les résultats

Les résultats obtenus avec la prise en compte du code HTML et de nombres sont indiqués dans le
tableau 2. Ces informations complémentaires inﬂuencent légerement les résultats en améliorant
les performances des algorithmes. L’ inﬂuence est surtout visible avec la prise en compte du
code HTML.

Algorithme Rocchio 1-PPV 10-PPV 30-PPV SVM

Sans chiffres ni HTML 0.89 0.94 0.94 0.92 0.95
Avec les chiffres 0.89 0.93 0.94 0.92 0.95
Avec source HTML 0.94 0.94 0.95 0.96 0.96

TAB. 2 — Performance avec des documents comportant les nombres et le code HTML

L’ analyse des nombres et du code HTML discriminants apporte la conﬁrmation a notre hypo-
these que ces éléments constituent des ancrages supplémentaires dans les textes.

Nous constatons ainsi la présence de dates récentes (2001, 2002) dans les documents racistes,

5Ainsi, k—PPV n’a pas été capable — et c’est bien comprehensible! — de détecter l’ironie dans l’extrait sui-
Vant : “Ce n’est plus l’infection judéo—cosmopolite qui est dans la ligne de mire. Mais, l’inVasion des allogénes
qui, dans leur perversité, imposent leur loi, celle des bandes ethniques — On n’est plus chez nous, bordel !”
(http ://www . homme—moderne . org/kroniks/Vlad/001001 . html)

Détection des contenus racistes sur l’Internet

tres gourmands des faits divers qui, a travers des récits datés et documentés, permettent d’avoir
un lien réel avec la vie quotienne. Les sites de ce type ont, en regle général, une mémoire courte.

En ce qui conceme les éléments du code HTML les plus discriminants, il s’agit de balises,
d’attributs, de valeurs d’attributs et d’entités SGML. Ainsi, dans le corpus raciste, l’attribut
HTML pics indique que les documents de ce corpus utilisent et afﬁchent souvent les images
(photos, dessins, caricatures, bannieres, etc.). La balise meta, qui peut étre utilisée pour noter
une liste de mots clés ou d’autres informations, est également discriminante. Les polices de
caracteres arial et verdana semblent étre dédié a ces documents, fait conﬁrmé par une étude sur
la présentation graphique des documents racistes (Nicinski, 2002).

Dans le corpus antiraciste, le terme class indique une utilisation plus fréquente de Java scripts
dans ces documents. Par contre, avec les entités SGML (eacute, egrave, ecirc, ocirc, etc.)
comme termes discriminants, il est difﬁcile de savoir si leur présence discriminante n’est pas
due a l’utilisation d’un éditeur HTML donné.

On en vient a se poser la question sur la représentativité et complétude de corpus étudiés. Dans
quelle mesure les traits trouvés dans ces expériences sont discriminants de contenus racistes et
antiracistes ? Vont-ils toujours étre discriminants sur d’autres corpus et sur les documents du
Web ? La convergence des résultats provenant de différentes études et expériences semblerait
indiquer que certains de ces traits (mots et expressions, polices de catacteres, utilisation des
images et des balises meta, présence de dates récentes) sont révélateurs de contenus que nous
cherchons a détecter. La tracabilité et l’explication d’autres traits est plus difﬁcile et nuancée.
Notons qu’une étude spéciﬁque du code HTML est en cours, de méme que l’étude de ces corpus
avec d’autres approches et outils.

Il est clair que l’apprentissage effectué sur ces corpus devra étre confronté a un corpus raciste
plus grand, mais aussi a un corpus neutre ou bien le corpus composé de documents proches
mais non pertinents. Il est clair aussi que ces corpus, en cours de constitution, doivent évoluer.

6 Conclusion

Nous avons présenté ici des expériences de traitement de corpus raciste et antiraciste avec des
algorithmes de classiﬁcation automatique. Ils fonctionnent sur un principe relativement simi-
laire au ﬁltrage par mots-clés mais permettent une réactualisation plus aisée puisque le ré-
apprentissage est automatique des lors que le corpus existe. Ces algorithmes, habituellement
utilisés pour la classiﬁcation thématique « classique », semblent étre adaptés aux données « spé-
ciales » des corpus traités. Leur performance est supérieure a 90% et méme a 99% si on accepte
une classe de rejet. Nous avons présenté des expériences faites avec du texte brut, mais aussi en
tenant compte des nombres et du code HTML. Ces informations complémentaires améliorent
tres légerement les performances.

A notre stade d’investigation, si l’on met de coté la question de l’euphémisation, la plus grande
part des erreurs qui subsistent semblent étre du méme type que celles présentées dans les études
de (Pang et al., 2002; Turney, 2002) : seule une petite partie du document est caractéristique
du racisme. L’information est noyée dans le reste du texte et les algorithmes statistiques qui
operent une moyenne de tous les termes du document ne parviennent pas a dégager la ou les
phrases importantes. Cet échec semble lié a la prédominance du péritexte dans le choix des
mots discriminants (cf. 5.1.1) : du fait de la redondance des sommaires et autres informations

Romain Vinot, Natalia Grabar, Mathieu Valette

propre a la structure des pages HTML, les documents globalement racistes sont mieux ﬁltrés
que ceux qui ne le sont que localement. Pour pallier ces faiblesses, dans l’outil ﬁnal Princip,
les documents seront également pris en charge par des modules plus ﬁns avec utilisation d’in-
formations plus complexes que la présence/absence de termes simples 2 chaine de caracteres
(morphemes), expressions complexes (lexies), isotopies, mesure de la cooccurrence, etc. Ces
modules collaboreront selon un ensemble de stratégies prédéﬁnies.

Remerciements

Nous remercions Francois Rastier d’avoir noué cette collaboration. Nous remercions Monique
Slodzian, Francois Rastier, Francois Yvon et Pierre Zweigenbaum pour leurs conseils, discus-
sions et soutien précieux pour ce travail.

Références

ANDROUTSOPOULOS 1., KOUTSIAS J ., CHANDRINOS K. V. & SPYROPOULOS C. D. (2000). An
experimental comparison of naive Bayesian and keyword-based anti-spam ﬁltering with personal e-mail
messages. In N. J . BELKIN, P. INGWERSEN &  LEONG, Eds., Proceedings of SIGIR-00, 23rd
ACM International Conference on Research and Development in Information Retrieval, p. 160-167,
Athens, GR 2 ACM Press, New York, US.

CARRERAS X. & MARQUEZ L. (2001). Boosting trees for anti-spam email ﬁltering. In Proceedings of
RANLP-2001, 4th International Conference on Recent Advances in Natural Language Processing.
GRABAR N. & BERLAND S. (2001). Construire un corpus web pour l’acquisition terrninologique. In
Terminologie et intelligence artiﬁcielle, p. 44-54, Nancy.

J OACHIMS T. (1998). Text categorization with support vector machines 2 Learning with many relevant
features. In ECML-98, Tenth European Conference on Machine Learning, p. 137-142.

NICINSKI M. (2002). Analyse et typologie des images dans les sites racistes. Rapport interne, CRIM-
INALCO. Mémoire de DESS, Francois Rastier (dir.).

PANG B ., LEE L. & VAITHYANATHAN S. (2002). Thumbs up ? sentiment classiﬁcation using machine
learning techniques. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language
Processing (EMNLP).

ROCCHIO J . J . (1971). The SMARTRetrieval System : Experiments in Automatic Document Processing,
chapter 14, Relevance Feedback in Information Retrieval, p. 313-323. Gerard Salton (editor), Prentice-
Hall Inc. 2 New Jersey.

SALTON G., WONG A. & YANG C. (1975). A vector space model for information retrieval. Communi-
cations of the ACM, 18(11), 613-620.

TDT (2001). The Topic Detection and Tracking 2001, evaluation project. http 2//www.nist.gov/TDT.

TURNEY P. (2002). Thumbs up or thumbs down ? semantic orientation applied to unsupervised clas-
siﬁcation of reviews. In Proceedings of the 40th Annual Meeting of the Association for Computational
Linguistics, p. 417-424, Philadelphia.

VAPNIK V. N. (1995). The Nature of Statistical Learning Theory. Springer.

YANG Y. (1997). An evaluation of statistical approach to text categorization. Rapport interne Technichal
Report CMU-CS-97-127, Carnegie Mellon University.

