TALN 2003, Batz—sur—Mer, I I -1 4 juin 2003

Apport d’un modéle de langage statistique pour la
reconnaissance de l’écriture manuscrite en ligne

Freddy Perraud (l), Emmanuel Morin (2),
Christian Viard-Gaudin (3) et Pierre-Michel Lallican (1)

(l) Société Vision Objects - 9, rue du Pavillon - 44980 Sainte Luce sur Loire
{freddy.perraud, pmlallican} @visionobjects.com

(2) Institut de Recherche en Inforrnatique de Nantes
2, rue de la Houssiniere - BP 92208 - 44322 Nantes Cedex 3
morin@irin.univ-nantes.fr

(3) Institut de Recherche en Communications et Cybernétique de Nantes - Ul\/[R
CNRS La Chantrerie - Rue Christian Pauc - BP 50609 - 44306 Nantes Cedex 3
christian.viard-gaudin@polytech.univ-nantes.fr

Résumé — Abstract

Dans ce travail, nous e’tudions l’apport d’un modele de langage pour ame’1iorer les performances des systemes de
reconnaissance de l’e’criture manuscrite en-ligne. Pour cela, nous avons explore’ des modeles bases sur des
approches statistiques construits par apprentissage sur des corpus e’crits. Deux types de modeles ont été e’tudie’s :
les modeles n-grammes et ceux de type n-classes. En vue de l’inte'gration dans un systeme de faible capacite'
(engin nomade), un modele n-classe combinant criteres syntaxiques et contextuels a été de’fini, il a permis
d’obtenir des résultats surpassant ceux donne’s avec un modele beaucoup plus lourd de type n-gramme. Les
résultats pre'sente’s ici montrent qu’il est possible de prendre en compte les spe'cificite's d’un langage en vue de
reconnaitre l’e’criture manuscrite avec des modeles de taille tout a fait raisonnable.

This works highlights the interest of a language model in increasing the performances of on-line handwriting
recognition systems. Models based on statistical approaches, trained on written corpora, have been investigated.
Two kinds of models have been studied: n-gram models and n-class models. In order to integrate it into small
capacity systems (mobile device), a n-class model has been designed by combining syntactic and contextual
criteria. It outperforms bulkier models based on n-gram. The results we obtain show that it is possible to take
advantage of language specificities to recognize handwritten sentences by using reasonable size models.

Mots Clés — Keywords

Reconnaissance de l’e’criture manuscrite, modele de langage, n-gramme, n-classe, perplexite'.

Handwriting recognition, language modelling, n-gram, n-class, perplexity.

Freddy Perraud, Emmanuel Morin, Christian Viard-Gaudin et Pierre-1\lichelLallican

1 Introduction

Dans ce travail, nous nous interessons au probleme de la reconnaissance de l’ecriture dite en-
ligne. L’efficacite de celle-ci peut étre renforcee a l’aide d’un modele renferrnant des
connaissances a priori sur le langage. Dans un modele probabiliste, une phrase s peut étre
representee par une sequence de mots w,- de longueur L, soit : s : w;  w,-  wL : w1,L. En
considerant cette sequence comme une chaine de Markov, nous pouvons estimer la
probabilitep(s) d’une phrase s comme suit :

W1  )= 1:[p(w, W1 ...w,._,) (1)

Lorsque la longueur de l'historique du mot a predire devient importante, l'estimation de la
probabilite conditionnelle p(w,-\w1...w,--1) n ’est pas ﬁable. La reduction de l’ordre de la chaine
de Markov permet alors de restreindre l’historique en ne tenant compte que du contexte
proche des mots w,- (Manning et al., 2000). Dans un modele n-gramme, seuls les n-I
precedents mots sont pris en consideration :

w, w, )...p(wL

wi )p(w.

p(s)=p(w1.>=p(w.>p(w2

p(wi|wi—n+1"'wi—1)zp(wi|w1"'wi—1) 

Les probabilites p(w,-|w,-_,,+ 1...w,--1) sont calculees statistiquement par une simple methode de
comptage d’evenements completee par la methode de lissage absolute discounting backing-
oﬂ qui permet d’estimer p(w,-|w,-_,,+1...w,--1) pour des evenements non rencontres sur la base
d’apprentissage. Pour evaluer l’adequation du modele, nous utilisons la traditionnelle mesure
de perplexite :

1
lam 7 ‘
PPM (Ttest) : 10(5)] IT (ou LT“; est le nombre de phrases dans la base detest) (3)
i=1

Comme le nombre de n-grammes devient vite considerable pour un lexique de taille
importante des lors que n augmente, nous cherchons a reduire le nombre d’evenements
observables en regroupant les mots en classes (nous parlerons alors de modeles n-classes). En
appliquant ce regroupement, le modele predit non plus un mot en fonction des n-I mots le
precedant, mais en fonction des n-I classes qui le precedent.

p(S)= Z 1£[p(w,-

chemin i=1

gk (Wi ))P (gk (W: X815 (wi—l )gk" (W:  (4)

Dans le cas d’une classification << molle >>, chaque mot peut étre associe a une ou plusieurs
classes. Dans l’equation (4), un chemin correspond a une sequence g(w1). .. g(wL) possible de
classes. Dans le cas d’une classiﬁcation << dure >>, chaque mot est associe a une et une seule
classe; alors un seul chemin existe. Nous avons effectue la classiﬁcation suivant deux
criteres. D’une part, un critere statistique regroupe les mots partageant les memes contextes
lexicaux, et d’autre part, un critere syntaxique regroupe les mots selon leurs parties du
discours.

2 Performances des modélcs du langagc

Dans cette section, nous cherchons a etudier le comportement de differents modeles de
langage a savoir n-gramme, n-classe syntaxique et n-classe statistique sur differentes bases de
donnees textuelles. Le tableau 1 presente les principales caracteristiques des corpus utilises

Apport a’ ’un modéle de langage statistique pour la reconnaissance de l’écriture manuscrite
en ligne

pour l’apprentissage, puis pour l’éValuation des modeles. Pour des raisons de lisibilité, nous
introduisons les abréviations suivantes : MBG pour Modele BiGramme ; MBCSynt pour
Modele BiClasse Syntaxique et MBCStatX pour Modele BiClasse Statistique utilisant X
classes avec X={l0, 50, 100, 500, 1000}.

Nam Taille du corpus Taille du lexique Domaine de % mots avec
(million de mots) (million de mots) discours une occurrence
Corpus ABU 4,1 0,09 ’°“‘”“S)‘(‘)“(eXD(e °‘ 42 %
‘rapprentlssage ECI 4,2 0,1 aIﬁclesLi:s11\1:o(Il11(iig'oun1al 42 %
arti 1 ' d
Corpus de test TEST 1,6 0,072 J.0uma:X°:t‘fi:“f0IfanS 44 %

Tableau 1 : Caractéristiques des corpus utilisés pour l’apprentissage et l’éValuation

2.1 Modéles n-classes statistiques et modéles n-classes syntaxiques

Dans le cas des modeles n-classes statistiques, nous utilisons un algorithme de classiﬁcation
dure inspiré de celui des k-means pour construire les classes, k étant le nombre de classes.
Les résultats présentés a la ﬁgure 1 montrent, sans surprise, que plus le nombre de classes est
important, meilleures sont les performances car les estimations de probabilités sont alors plus
précises. Il est intéressant de noter que les MBCStat500/1000 parviennent presque a égaler les
modeles bigrammes, ce qui est un résultat tout a fait intéressant étant donné leur moindre
encombrement mémoire.

Dans le cas des modeles n-classes syntaxiques, nous utilisons des statistiques obtenues sur les
corpus d’apprentissage préalablement étiquetés par l’étiqueteur de Brill (Brill 94 ; Le Comte
et al., 1998) et de l’analyseur ﬂexionnel Flemm (Namer 2000). Les performances de ces
modeles qui comptent 210 classes sont inférieures a celles obtenues avec MBCStat500/1000
mais les MBCSynt prennent tout leurs intéréts lors de la combinaison avec d’autres modeles.

2.2 Combinaisons de modéles

A l’instar des travaux (Niesler, 1997 ; Jardino, 1994 ; Goodman, 2000 ; El-Beze 1993), nous
proposons d’étudier la combinaison linéaire de plusieurs de ces modeles, a savoir 1) modeles
bigramme et biclasse syntaxique; 2) modeles bigramme et biclasse statistique et enﬁn 3)
modeles biclasse syntaxique et biclasse statistique. Par la suite, nous désignerons ces modeles
sous le terme de modele combine. On peut observer sur la ﬁgure 2 les résultats correspondant
a la combinaison des MBG et des MBCStat. Ces deux types de modeles apparaissent tres
complémentaires. Les MBCStat améliorent jusqu'a 18 % les performances du modele
bigramme sur ABU et jusqu'a 16 % sur ECI, pour les modeles avec 500 classes.

Le modele biclasse syntaxique est également fortement complémentaire au modele bigramme.
Ainsi, la combinaison de ces deux modeles améliore de 45 % les performances sur ABU et de
33 % sur ECI. Les MBCStat500 présentaient de meilleures performances que les MBCSynt,
or la combinaison entre un MBG et un MBCStat500 est moins performante qu'une
combinaison entre un MBG et un MBCSynt. On peut en conclure que la nature des
informations contenues dans les MBCSynt est plus complémentaire de celle des MBG que ne

Freddy Perraud, Emmanuel Morin, Christian Viard-Gaudin et Pierre-1\lichelLallican

l'est celle des MBCStat. Un MBCStat est par nature proche des MBG et apporte donc moins
qu'un MBCSynt a un MBG.

Enﬁn, dans le cas d’une combinaison des modeles biclasse statistique et biclasse syntaxique,
laquelle conﬁguration correspond a une combinaison réellement intéressante car seuls des
modeles de faibles complexités sont pris en compte, les performances sont notablement
améliorées (cf. ﬁgure 2). Ses résultats surpassent tres significativement ceux obtenus par des
MBG. On obtient jusqu'a 47 % d'amélioration sur ABU et 35 % sur ECI avec un MBCSynt
combine a un MBCStat500 par rapport au MBG. Toutefois, on peut conjecturer que la
relative faiblesse des modeles bigrammes par rapport aux modeles n-classes combinés est en
partie due a la taille réduite de la base d’apprentissage (4 millions contre plusieurs dizaines de
millions de mots pour obtenir des modeles bigrammes Véritablement robustes).

Nous avons enﬁn essayé de combiner les trois modeles : MBG, MBCStatl0OO et MBCSynt.
Les performances obtenues ne sont que tres légerement supérieures (1 a 2 % sur ABU et 5 %
sur ECI) a celles correspondant a la combinaison des modeles biclasses seuls. Les MBG
n'apportent donc que peu d'informations complémentaires aux modeles MBCStat et MBCSynt
combinés. On peut en conclure que les modeles combinés MBCStat et MBCSynt se suffisent
a eux-mémes et ne nécessitent pas de combinaisons avec un MBG ce qui de toutes manieres
constituerait alors un modele beaucoup trop Volumineux.

600
500
400
300
200
100

   

Figure 1: Mesures de perplexité avec les Figure 2: Mesures de perplexité avec les
modeles simples sur le corpus TEST modeles combinés sur le corpus TEST.

3 Contribution des modéles de langage dans le systéme de
reconnaissance

Aﬁn d’éValuer la contribution des modeles du langage dans le systeme de reconnaissance de
l’écriture, nous avons utilisé une nouvelle base de test composée de 4 912 phrases distinctesl.

1 Cette base de test, composée de 37 700 mots de’finissant un lexique de 8 800 mots, est issue d’une collecte
re’alise'e a l’aide d’une ardoise éleclronique aupres de 400 scripteurs.

Apport a’ ’un modéle de langage statistique pour la reconnaissance de l’écriture manuscrite
en ligne

La ﬁgure 3 présente un exemple du signal d’entrée du systeme correspondant aux phrases
<< Mais jamais pour trés longtemps. » et << Ce n ’est pas si stir. ».

J ¢.- I

,.3_- ' - I '  ‘ E _. _.a I. . P‘
p-!['il.’§1l.'-3.‘?#_,f:f::IY'#‘n.:Lidt.¢7 ‘_,»_-,1.~.-.-.:c.-r. .=-=-zafa‘:1-::¢=1;\'?£5r?y-9*’. Li’. Fa  2,19%;  ﬁnu .
Lu‘ ‘

1'

Figure 3 : Echantillons de la base d’écriture manuscrite dynamique

Sur cette base, le taux d’erreur de reconnaissance mot, sans aucun modele de langage est égal
a 34 %. Cette Valeur est bien supérieure a ce que l’on obtient plus classiquement sur une base
de mots. Il faut souligner en particulier ici le fait que, outre la difﬁculté de la segmentation
inter-mot qui n’existe pas dans une reconnaissance base mot, la ponctuation est prise en
compte dans la reconnaissance (par exemple chaque erreur sur une Virgule est comptabilisée).
Si l’on raj oute un modele de langage élémentaire, consistant en l’intégration des
monogrammes dans le treillis de reconnaissance, alors le taux d’erreur chute a 29 %.

La figure 4 présente l’éVolution du taux d’erreur avec des systemes de reconnaissance
intégrant des modeles monogramme et des modeles biclasse, biclasse combiné ou bigramme.
La diminution du taux d’erreur est tres signiﬁcative. Pour le MBCStat500 seul, le taux
d’erreur est inférieur a 23 %, cela correspond a une diminution de l’erreur de 32 % par
rapport au systeme sans modele de langage. Le meilleur résultat est obtenu avec la
combinaison des modeles MBCStat500 et MBCSynt ou le taux d’erreur est de 22,5 %.

1ooo
27% —I—Taux Egg
260/ d'erreur
'5 ° —O—Perp|exité 700 1.
E 25% 500 3
- 500 —
3 24% 400 2.
.3 23% 300 3
F 22°/ 20°
° 100
21% 0
‘K.
00.;
$9 $9

 

Figure 4 : Mesures de perplexité et taux d’erreur avec le modele entrainé sur le corpus ECI.

De plus, ces courbes mettent clairement en évidence la forte corrélation entre la mesure de
perplexité et le taux d’erreurs. La mesure de perplexité semble donc bien un indicateur valide
pour mesurer la pertinence d’un modele de langage en vue de son utilisation dans un contexte
de reconnaissance de l’écriture manuscrite. Elle a l’avantage de pouvoir étre évaluée sur des
bases beaucoup plus faciles a obtenir que des bases d’écriture manuscrite. Ce point est
important et n’aVait pas a notre connaissance été préalablement mis en évidence
expérimentalement comme nous le faisons ici.

Si nous reprenons les exemples de la figure 3, le systeme de reconnaissance sans modele de
langage propose en sortie : << Mais jamais pour tirs longtemps. » et << Ce n ’est pas si (112. ». Par
exemple, le MBCSynt corrige l’erreur sur ces deux exemples. D’un point de vue syntaxique,

Freddy Perraud, Emmanuel Morin, Christian Viard-Gaudin et Pierre-[Michel Lallican

il est effectivement plus vraisemblable que l’adverbe de temps << longtemps >> soit précédé
d’un adverbe que d’un nom commun. De méme, apres l’adverbe << si >>, l’adjectif << sur >> est
plus probable que le participe passé << du >>.

4 Conclusion et perspectives

Dans ce travail, nous avons montré l’apport significatif des modeles de langage a un systeme
de reconnaissance de l’écriture manuscrite en ligne. Globalement, nous avons obtenu une
diminution de plus 34 % du taux d’erreur en recherchant le meilleur compromis
performance/coﬁt matériel.

Il reste bien entendu un certain nombre de points a améliorer. Tout d’abord, il serait
intéressant d’étudier les techniques de classification permettant de travailler sur des corpus
plus Volumineux (Beaujard et al., 1999 ; Goodman, 2000). Ensuite, nous devons affmer nos
modeles qui souffrent actuellement d’un manque de robustesse lorsqu’ils sont confrontés a
des noms propres ou a des mots d’origine étrangeres. Enfin, nos applications étant destinées a
des appareils nomades que l’utilisateur s’approprie, il serait intéressant d’adapter nos modeles
au domaine de discours de l’utilisateur.

Références
Beauj ard C., Jardino M., Classiﬁcation de mots non étiquetés par des méthodes statistiques,
Mathématiques informatique et Sciences Humaines, vol 147, pp. 7-23, 1999.

El-Beze M., Les modeles de langage probabilistes .' quelques domaines d ’application, HDR,
LIPN, 1993.

Brill E., Some Advances in Rule-Based Part of Speech Tagging, In Proceedings, Twelfth
National Conference on Artificial Intelligence (AAAI’94), pp 722-727, 1994.

Goodman J., Putting it all together .' Language model combination, ICASSP-2000, Istanbul,
2000.

Jardino M., Automatic determination of a stochastic bigram class model, International
Colloquium on Grammatical Inference, 1994.

Le Comte J., Paroubek P., Le catégoriseur d'Eric BRILL. [Wise en oeuvre de la version
entrainée a l’INALF, Rapport technique, Nancy, CNRS-InaLF, 1998.

Manning C., Scutze., H. Foundation of Statistical Natural Language Processing, The MIT
Press, 2000.

Namer F., Flemm .' Un anab/seur ﬂexionnel du francais a base de regles, T raitement
Automatique des Langues (TAL), 41(2) pp. 523-548, 2000.

Niesler T., Category Based Statistical Language Models, Ph. D. thesis, University of
Cambridge, June 1997.

