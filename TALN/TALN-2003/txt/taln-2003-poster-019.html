<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Le contexte au service de la correction des graphies fautives arabes</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2003, Batz-sur-Mer, 11-14 juin 2003 
</p>
<p>Le contexte au service de la correction  
des graphies fautives arabes 
</p>
<p>Chiraz Ben Othmane Zribi, Mohamed Ben Ahmed  
</p>
<p>Laboratoire de recherche RIADI 
Universit&#233; La Manouba, ENSI, La Manouba, Tunisie 
</p>
<p>adn@gnet.tn, Mohamed.BenAhmed@riadi.rnu.tn 
</p>
<p>R&#233;sum&#233; &#8211; Abstract   
Les mots arabes sont lexicalement beaucoup plus proches les uns des autres que les mots 
fran&#231;ais et anglais. Cette proximit&#233; a pour effet un grand nombre de propositions &#224; la 
correction d'une forme erron&#233;e arabe. Nous proposons dans cet article une m&#233;thode qui prend 
en consid&#233;ration le contexte de l'erreur pour &#233;liminer certaines propositions donn&#233;es par le 
correcteur. Le contexte de l'erreur sera dans un premier temps les mots voisinant l'erreur et 
s'&#233;tendra jusqu'&#224; l'ensemble des mots du texte contenant l'erreur. Ayant &#233;t&#233; test&#233;e sur un corpus 
textuel contenant des erreurs r&#233;elles, la m&#233;thode que nous proposons aura permis de r&#233;duire le 
nombre moyen de propositions d'environ 75% (de 16,8 &#224; 3,98 propositions en moyenne). 
Arabic words are lexically closer to each other than can be English or French words. This 
proximity mainly results a great number of candidates given by a spelling corrector when 
processing an erroneous word. We address in this paper a new method aiming to reduce the 
number of proposals given by automatic Arabic spelling correction tools. We suggest the use 
of error's context in order to eliminate some correction candidates. Context will be nearby 
words and can be extended to all words in the text. Our method was tested on a corpus 
containing genuine errors and has yield good results. The average number of proposals has 
been reduced of about 75% (from 16,8 to 3,98 proposals on average). 
Mots Cl&#233;s &#8211; Keywords   
Langue, Arabe, Erreur orthographique, Correction automatique, Contexte 
Language, Arabic, Misspelled word, Automatic correction, Context 
</p>
<p>1. Introduction  
La majorit&#233; des correcteurs orthographiques existants sont semi-automatiques, ils assistent 
l'utilisateur en lui proposant un ensemble de candidats proches du mot erron&#233;. Disposant d'un 
tel correcteur orthographique pour l'arabe [Ben Othmane Zribi et Zribi, 1999], nous nous 
sommes propos&#233;s de l'am&#233;liorer en diminuant le nombre de ses propositions. Deux motivations 
principales nous ont incit&#233; &#224; s'int&#233;resser &#224; ce probl&#232;me : D'abord la n&#233;cessit&#233; qu'ont certaines 
applications d'une correction des erreurs orthographiques compl&#232;tement automatique [Kukich, 
1992]. Ensuite, l'importance du nombre de candidats pour une forme erron&#233;e arabe compar&#233; &#224; 
d'autres langues comme le fran&#231;ais et l'anglais due &#224; la proximit&#233; lexicale des mots. Le nombre 
moyen de formes lexicalement voisines (mots qui diff&#232;rent d'une seule erreur d'&#233;dition: ajout, </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Chiraz Ben Othmane Zribi, Mohamed Ben Ahmed 
</p>
<p>suppression, substitution et interversion) qui est de 3 pour l'anglais et de 3,5 pour le fran&#231;ais 
est de 26,5 pour l'arabe non voyell&#233; [Ben Othmane Zribi et Zribi, 1999].  
Notre but &#233;tant une correction compl&#232;tement automatique, nous avons tent&#233; de l'approcher en 
minimisant autant que possible le nombre de candidats et ceci en commen&#231;ant par &#233;liminer les 
candidats les moins probables. La m&#233;thode que nous proposons pour diminuer le nombre de 
candidats s'appuie sur le contexte du mot erron&#233;. Elle consid&#232;re les mots voisinant l'erreur ainsi 
que l'ensemble des mots du texte contenant l'erreur.  
Dans ce qui suit, nous commen&#231;ons par pr&#233;senter notre syst&#232;me de correction ainsi qu'une 
&#233;valuation initiale de notre correcteur portant sur des erreurs r&#233;elles. Nous pr&#233;sentons par la 
suite notre m&#233;thode accompagn&#233;e d'une proc&#233;dure d'&#233;valuation mesurant son efficacit&#233;. 
</p>
<p>2. Le correcteur orthographique utilis&#233; 
Le syst&#232;me utilis&#233; pour la v&#233;rification et la correction des mots arabes se base principalement 
sur l&#8217;utilisation d&#8217;un dictionnaire contenant toutes les formes fl&#233;chies voyell&#233;es  (1 600 000 
entr&#233;es qui correspondent &#224; 577 546 formes non voyell&#233;es) de la langue arabe. &#192; cause de 
l&#8217;agglutination des proclitiques (articles, pr&#233;positions, conjonctions) et des enclitiques 
(pronoms) aux radicaux (formes fl&#233;chies), ce dictionnaire ne suffit pas pour reconna&#238;tre les 
formes textuelles arabes. Il a donc &#233;t&#233; accompagn&#233; d&#8217;un analyseur morphologique des formes 
textuelles. Cet analyseur utilise en plus du dictionnaire des formes fl&#233;chies, un petit dictionnaire 
incluant tous les enclinom&#232;nes (90 entr&#233;es) et applique un ensemble de r&#232;gles pour rechercher 
tous les d&#233;coupages possibles en proclitique, radical et enclitique. Ces m&#234;mes dictionnaires et 
grammaire servent pour la d&#233;tection et la correction des erreurs orthographiques. La d&#233;tection 
des erreurs est effectu&#233;e lors de l'analyse morphologique. La correction, quant &#224; elle, se fait par 
une version am&#233;lior&#233;e dite &quot;tol&#233;rante&quot; de l'analyseur morphologique. 
</p>
<p>3. &#201;valuation initiale du correcteur 
Pour &#233;valuer le correcteur utilis&#233; nous avons pris en consid&#233;ration les mesures suivantes: 
</p>
<p>&#8226; Couverture : pourcentage d'erreurs pour lesquelles le correcteur n'est pas silencieux 
c'est &#224; dire qu&#8217;il fournit des propositions  
</p>
<p>&#8226; Pr&#233;cision : pourcentage d'erreurs pour lesquelles le mot correct se trouve parmi les 
propositions  
</p>
<p>&#8226; Ambigu&#239;t&#233; : pourcentage d'erreurs pour lesquelles le correcteur fournit plus qu'une 
proposition 
</p>
<p>&#8226; Proposition
 : nombre moyen de propositions de correction par mot erron&#233;  
</p>
<p>Notre exp&#233;rimentation a port&#233; sur des erreurs r&#233;elles. Nous avons pris pour cela, trois textes 
(comptant au total environ 5 000 formes) traitant du m&#234;me domaine et contenant 151 formes 
erron&#233;es qui rel&#232;vent de l'une des quatre op&#233;rations d&#8217;&#233;dition. L&#8217;invocation de notre syst&#232;me 
de correction sur ces textes a donn&#233; les r&#233;sultats suivants : 
</p>
<p>Couverture Pr&#233;cision Ambigu&#239;t&#233;  Proposition 
</p>
<p>100% 100 % 78,80 % 12,50 [min:1, max:160] 
</p>
<p>Tableau 1. &#201;valuation initiale du correcteur orthographique  
Outre le fait que la couverture est maximale et le fait que le correcteur nous donne toujours la 
bonne correction parmi ses propositions, ces comptages nous apprennent que le taux 
d'ambigu&#239;t&#233; est tr&#232;s &#233;lev&#233;. Plus de 78% des erreurs pr&#233;sentent en effet plus d'une proposition &#224; </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Le contexte au service de la correction des graphies fautives arabes 
</p>
<p>leur correction. Par ailleurs, bien que le nombre moyen des propositions soit inf&#233;rieur &#224; la 
moyenne th&#233;orique pr&#233;vue pr&#233;c&#233;demment (27 formes candidates), il reste toujours trop &#233;lev&#233; si 
on le compare &#224; d'autres langues. Pour l'anglais par exemple le nombre moyen de candidats est 
de 3,4 pour des erreurs r&#233;elles [Agirre et al., 1998].   
4. Proposition 
Notons: Me : un mot erron&#233; ; 
</p>
<p>Mc
 : la correction de Me ; 
</p>
<p>C
 = {c1, .., cn} : l'ensemble des candidats &#224; la correction de Me ; 
</p>
<p>Mctxt
 = {m
</p>
<p>-k, &#8230;, m-1, m+1, &#8230;, m+k} : l&#8217;ensemble des mots entourant (avant et 
apr&#232;s) le mot erron&#233; Me dans le texte (en consid&#233;rant une fen&#234;tre de taille k). 
</p>
<p>Viser une correction compl&#232;tement automatique revient &#224; chercher &#224; r&#233;duire l'ensemble C &#224; un 
singleton qui correspond au mot correct Mc. On aurait alors : Card (C) = 1 avec Mc &#8712; C. 
Pour notre part, nous visons simplement &#224; ce que Card (C) soit le plus petit possible. Pour 
cela, nous allons chercher &#224; &#233;liminer les candidats les moins probables. L'utilisation du contexte 
qui est &#224; la base de notre m&#233;thode s'effectuera en deux temps. D&#8217;abord consid&#233;rer les mots 
voisinant l'erreur seulement, ensuite seront consid&#233;r&#233;s l'ensemble des mots du texte contenant 
l'erreur.  
</p>
<p>4.1 Mots en contexte 
L'hypoth&#232;se de d&#233;part est que chaque candidat ci poss&#232;de une certaine &#171; affinit&#233; &#187; lexicale 
avec les mots du contexte du mot erron&#233; Me
</p>
<p> 
</p>
<p>qu'il corrige. En cons&#233;quence, pour classer les 
candidats entre eux et &#233;liminer les moins probables, nous examinons le contexte et nous 
choisissons les candidats les plus &quot;proches&quot; des mots du contexte. 
Pour ce faire, nous avons opt&#233; pour une m&#233;thode statistique qui consiste &#224; calculer pour 
chaque candidat la probabilit&#233; d&#8217;&#234;tre la bonne solution &#233;tant donn&#233;s les mots qui entourent 
l'erreur dans le texte. Seuls les candidats ayant une probabilit&#233; jug&#233;e acceptable sont gard&#233;s, les 
autres sont &#233;limin&#233;s. 
Pour chaque candidat nous calculons p(ci\Mctxt) qui repr&#233;sente la probabilit&#233; que ci soit la 
bonne solution sachant que le mot erron&#233; Me est entour&#233; du contexte Mctxt. 
Calculer cette probabilit&#233; n'est pas chose ais&#233;e car elle n&#233;cessite beaucoup de donn&#233;es pour 
l&#8217;apprentissage. Nous utiliserons &#224; la place, la probabilit&#233; p(Mctxt\ci) et ceci en appliquant la 
r&#232;gle d'inversion de Bayes :  
</p>
<p>  p(Mctxt)
)p(c  )c\p(Mctxt
</p>
<p> Mctxt)\(c p iii &#215;=  
Puisque nous cherchons les candidats ayant la plus grande valeur p(ci\Mctxt), nous pouvons 
calculer uniquement la valeur p(Mctxt\ci) &#215; p(ci). La probabilit&#233; p(Mctxt) &#233;tant la m&#234;me pour 
tous les candidats (le contexte est le m&#234;me), elle n'a donc pas d'effet sur le r&#233;sultat. 
En supposant que la pr&#233;sence d&#8217;un mot dans un contexte ne d&#233;pend pas de la pr&#233;sence des 
autres mots dans ce m&#234;me contexte, nous pouvons effectuer l'approximation suivante comme 
l'ont d&#233;j&#224; d&#233;montr&#233; d'une mani&#232;re plus g&#233;n&#233;rale [Gale et al., 1994]: 
</p>
<p>  )c\p(m  )c\(Mctxt p k-k,...,
j
</p>
<p>iji &#8719;=   </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Chiraz Ben Othmane Zribi, Mohamed Ben Ahmed 
</p>
<p>Somme toute, nous calculons pour chaque candidat : 
 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p>4.1.1 Exp&#233;rience :  
Notre exp&#233;rience se r&#233;alise en deux &#233;tapes : une &#233;tape d'apprentissage pendant laquelle on 
collecte les probabilit&#233;s pour les candidats et une &#233;tape de test qui consiste &#224; utiliser ces 
probabilit&#233;s pour choisir entre les candidats. 
</p>
<p>&#8211; &#201;tape d&#8217;apprentissage 
Cette &#233;tape consiste en la construction d'un dictionnaire de co-occurrences &#224; partir d&#8217;un corpus 
d&#8217;apprentissage. Les entr&#233;es de ce dictionnaire sont les candidats propos&#233;s par notre syst&#232;me 
de correction pour les erreurs qu'il a d&#233;tect&#233;s dans le texte de test. On met au compte de 
chaque entr&#233;e sa probabilit&#233; d'apparition p(ci) dans le corpus d'apprentissage et l&#8217;ensemble de 
ses mots co-occurrents avec leur probabilit&#233; de co-occurrence p(mj\ci). 
</p>
<p>&#8211; &#201;tape de test 
Cette &#233;tape consiste &#224; invoquer le syst&#232;me de correction sur un texte de test et &#224; acc&#233;der pour 
chaque candidat au dictionnaire des co-occurrences pour calculer la probabilit&#233; p(ci\Mctxt). 
Seuls les candidats ayant une probabilit&#233; jug&#233;e satisfaisante (&gt; 0,3 dans notre exemple, car le 
corpus d'apprentissage n'est pas volumineux) sont choisis.  
4.1.2 R&#233;sultats : 
Textes d&#8217;apprentissage :  corpus textuel utilis&#233; pr&#233;c&#233;demment de 5000 formes environ 
Texte de test : une partie du corpus de 1763 formes dont 61 erron&#233;es 
</p>
<p> Couverture Pr&#233;cision Ambigu&#239;t&#233;  Proposition 
Initialement 100% 100 % 88,52 % 16,8 formes [min:1, max:160] 
</p>
<p>Mots en contexte 100% 93,44% 72,13% 10,33 formes [min:1, max:47] 
</p>
<p>Tableau 2. &#201;valuation du correcteur orthographique : Mots en contexte. 
</p>
<p>L'utilisation des mots en contexte a permis de r&#233;duire le nombre de candidats d'environ 40% . 
La pr&#233;cision a toutefois diminu&#233;, dans 6,6% des cas la bonne solution ne se trouve plus parmi 
les propositions.  
</p>
<p>4.2 Mots du texte 
L'id&#233;e de cette exp&#233;rience est n&#233;e &#224; partir de comptages effectu&#233;s sur le corpus textuel utilis&#233; 
pr&#233;c&#233;demment et qui contient les erreurs r&#233;elles. Ces comptages nous ont inform&#233; qu'un radical 
appara&#238;t en moyenne 5,6 fois et qu'un lemme appara&#238;t en moyenne  6,3 fois. 
Ceci nous a amen&#233;s &#224; d&#233;duire que dans un texte, les mots ont tendance &#224; souvent se r&#233;p&#233;ter. 
Partant de cette id&#233;e, on pourrait penser que les mots corrections des mots erron&#233;s dans un 
texte peuvent se trouver dans le texte lui-m&#234;me. En cons&#233;quence, la recherche des candidats &#224; 
</p>
<p> )(c p  )c\(m p ik-k,...,
j
</p>
<p>ij &#215;&#8719;  avec : 
</p>
<p>i
</p>
<p>ij
ij
</p>
<p>c de cesd'occurren Nombre
ntco-occurre cet  mo&#249;  fois de Nombre)c\p(m  =   
</p>
<p>mots de  totalNombre
 c de cesd'occurren Nombre)p(c ii  =  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Le contexte au service de la correction des graphies fautives arabes 
</p>
<p>la correction d'un mot erron&#233; va se faire d&#233;sormais dans des dictionnaires construits &#224; partir 
des mots du texte qui contient les erreurs au lieu des dictionnaires g&#233;n&#233;raux de la langue arabe 
que nous avons utilis&#233;s pr&#233;c&#233;demment.  
Deux exp&#233;riences ont &#233;t&#233; r&#233;alis&#233;es dans cette perspective: la premi&#232;re a port&#233; sur l'utilisation 
du dictionnaire des radicaux du texte et la seconde sur l'utilisation du dictionnaire de toutes les 
formes fl&#233;chies des radicaux du texte. 
4.2.1 Exp&#233;rience 1 : Dictionnaire des radicaux du texte 
La correction du texte de test en utilisant le dictionnaire de tous les radicaux du texte (1 025 
formes non voyell&#233;es) et le dictionnaire de tous les enclinom&#232;nes du texte (33 formes non 
voyell&#233;es) nous donne les r&#233;sultats suivants : 
</p>
<p>Couverture Pr&#233;cision Ambigu&#239;t&#233;  Proposition 
73,77% 97,61% 35,55% 2,36 formes [min:0, max:20] 
</p>
<p>Tableau 3.  Utilisation du dictionnaire des radicaux du texte 
</p>
<p>Nous pouvons lire &#224; partir de ce tableau que le taux d&#8217;ambigu&#239;t&#233; a diminu&#233; de plus que la 
moiti&#233;. Le nombre moyen de propositions a nettement diminu&#233; lui aussi, il est pass&#233; de 16,8 
formes &#224; environ 2,4 formes. Nous avons donc r&#233;ussi &#224; diminuer le nombre de propositions, 
mais nous avons perdu en couverture et en pr&#233;cision. 74% des erreurs ont des propositions. Ce 
qui nous  para&#238;t insuffisant, il faut donc essayer d'am&#233;liorer ce r&#233;sultat. Pour ce qui concerne la 
pr&#233;cision, 98% est un chiffre acceptable.   
4.2.2 Exp&#233;rience 2 : Dictionnaire des formes fl&#233;chies du texte 
La deuxi&#232;me exp&#233;rience ressemble &#224; la premi&#232;re sauf que nous avons utilis&#233; &#224; la place du 
dictionnaire des radicaux du texte, un dictionnaire de toutes les formes fl&#233;chies des radicaux du 
texte (21 712 formes non voyell&#233;es).  
La correction du texte pr&#233;c&#233;dent utilisant ce dictionnaire et le dictionnaire des enclinom&#232;nes 
construit dans l'exp&#233;rience pr&#233;c&#233;dente, nous donne les r&#233;sultats suivants : 
</p>
<p>Couverture Pr&#233;cision Ambigu&#239;t&#233;  Proposition 
86,75% 92% 58 % 4,88 formes [min:0, max:67] 
</p>
<p>Tableau 4. Utilisation du dictionnaire des formes fl&#233;chies du texte 
</p>
<p>On remarque que la m&#233;thode utilisant le dictionnaire des radicaux permet de diminuer 
d'avantage le nombre de propositions par rapport &#224; celle du dictionnaire des formes fl&#233;chies. 
Cependant ce dernier donne de meilleurs r&#233;sultats au niveau de la couverture. La pr&#233;cision 
quant &#224; elle a diminu&#233; en utilisant le dictionnaire des formes fl&#233;chies, car quand on utilise ce 
dernier, la chance de retrouver la bonne solution parmi les propositions diminue par rapport &#224; 
celle calcul&#233;e pour le dictionnaire des radicaux.   
</p>
<p>4.3 Combinaison 
Comme ultime exp&#233;rimentation, nous avons voulu combiner les deux exp&#233;riences pr&#233;c&#233;dentes: 
mots du texte et mots en contexte. Premi&#232;rement, la recherche des candidats a &#233;t&#233; effectu&#233;e 
dans le dictionnaire des formes fl&#233;chies des mots du texte. &#192; chaque candidat, nous avons 
attribu&#233; une probabilit&#233; mesurant sa proximit&#233; avec le contexte du mot erron&#233; qu'il corrige. Les 
candidats peu plausibles ont &#233;t&#233; &#233;limin&#233;s. Ainsi, nous avons obtenu 2,68 propositions en </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Chiraz Ben Othmane Zribi, Mohamed Ben Ahmed 
</p>
<p>moyenne (cf. Tableau 5), et un taux de couverture de 82%. La deuxi&#232;me combinaison, que 
nous jugeons meilleure, recherche les candidats dans le dictionnaire g&#233;n&#233;ral et leur attribue 
ensuite une probabilit&#233; contextuelle. Les candidats qui appartiennent au dictionnaire des formes 
fl&#233;chies des mots du texte sont pond&#233;r&#233;s par la note de 0,81 et les autres par 0,2. On proc&#232;de 
par la suite de la m&#234;me mani&#232;re que pr&#233;c&#233;demment, en ne laissant que les candidats les plus 
probables. Le nombre moyen de propositions obtenu dans ce cas est de 3,98 avec une 
couverture de 100% et une pr&#233;cision de 88,52%.  
</p>
<p> Couverture Pr&#233;cision Ambigu&#239;t&#233;  Proposition 
</p>
<p>Combinaison 1 81,97% 86% 46% 2,68 formes [min:0, max:20] 
Combinaison 2 100% 88,52% 62,29% 3,98 formes [min:0, max:20] 
</p>
<p>Tableau 5. &#201;valuation finale du correcteur orthographique  
5. Conclusion   
Dans ce travail nous nous sommes int&#233;ress&#233;s &#224; r&#233;duire le nombre de candidats propos&#233;s par un 
correcteur orthographique arabe. La m&#233;thode que nous avons propos&#233;e se base sur l'utilisation 
du contexte lexical de l'erreur. Elle nous a permis de r&#233;duire consid&#233;rablement le nombre de 
propositions au prix d&#8217;une baisse du taux de couverture que nous jugeons acceptable. Faut-il 
tenter de faire intervenir d&#8217;autres informations contextuelles telles que le contexte syntaxique 
(contraintes grammaticales) par exemple ? Bien que nous n'ayons pas mis &#224; contribution 
d'informations syntaxiques pour &#233;liminer encore plus de candidats superflus, nous avons 
mesur&#233; manuellement le r&#244;le que pourraient avoir ces informations si elles venaient &#224; &#234;tre 
utilis&#233;es. Nous avons trouv&#233; que les contraintes syntaxiques parviendraient &#224; diminuer le 
nombre de propositions d&#8217;environ 40%. Ce serait d&#233;j&#224; consid&#233;rable mais il faut h&#233;las compter 
avec les in&#233;vitables ambigu&#239;t&#233;s non r&#233;solues par un analyseur syntaxique automatique&#8230; 
</p>
<p>R&#233;f&#233;rences 
Agirre E., Gojenola K., Sarasola K., Voutilainen A. (1998), &quot;Towards a single proposal in spelling 
</p>
<p>correction&quot;, COLING-98,  pp. 22-28. 
Ben Othmane Zribi C. et Zribi A. (1999), &quot;Algorithmes pour la correction orthographique en arabe 
</p>
<p>&quot;, TALN' 99, Corse, 12-17 juillet 1999. 
Ben Othmane Zribi C. et Zribi A. (1999), &quot;Algorithmes pour la correction orthographique en arabe 
</p>
<p>&quot;, TALN' 99, Corse, 12-17 juillet 1999. 
Gale W., Church  K. W., Yarowsky D. (1994), &quot;Discrimination decisions for 100,000 dimensional 
</p>
<p>spaces&quot;, In Current Issues in Computational Linguistics: In Honour of Don Walker, pages 429-
450. Kluwer Academic Publishers. 
</p>
<p>Kukich K. (1992), &quot;Techniques for automatically correcting words in text&quot;. In ACM Computing 
Surveys, Vol.24, N.4,  pp.377-439  
</p>
<p>Oflazer K. (1994), &quot;Spelling correction in agglutinative languages&quot;, in Proceedings of the 4th ACL 
Conference on Applied Natural Language Processing, Stuttgart, Germany. 
</p>
<p>Yarowsky D. (1994), &quot;Decision lists for lexical ambiguity resolution: Application to Accent 
Restoration in Spanich and French&quot;, ACL' 94, pp. 88-95. 
</p>
<p>                                               
</p>
<p>1
  D'apr&#232;s 4.2.2, dans 80% des cas la bonne solution appartient au dict. des formes fl&#233;chies des mots du texte </p>

</div></div>
</body></html>