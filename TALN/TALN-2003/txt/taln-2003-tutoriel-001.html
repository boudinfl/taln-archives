<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Introduction &#224; la traduction guid&#233;e par l&#8217;exemple (Traduction par analogie)</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2003, Batz-sur-Mer, 11&#8211;14 juin 2003
</p>
<p>Introduction a&#768; la traduction guide&#769;e par l&#8217;exemple
(Traduction par analogie)
</p>
<p>Michael Carl
Institut fu&#776;r Angewandte Informationsforschung,
</p>
<p>Martin-Luther-Stra&#223;e 14,
66111 Saarbru&#776;cken, Germany,
</p>
<p>carl@iai.uni-sb.de
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>traduction guide&#769;e par l&#8217;exemple, traduction par analogie, traduction statistique, induction de grammaire
de traduction
example-based machine translation, analogical translation, statistical machine translation, induction of
translation grammar
</p>
<p>Re&#769;sume&#769; - Abstract
</p>
<p>Le nombre d&#8217;approches en traduction automatique s&#8217;est multiplie&#769; dans les dernie&#768;res anne&#769;es. Il existe
entre autres la traduction par re&#768;gles, la traduction statistique et la traduction guide&#769;e par l&#8217;exemple. Dans
cet article je decris les approches principales en traduction automatique. Je distingue les approches
qui se basent sur des re&#768;gles obtenues par l&#8217;inspection des approches qui se basent sur des exemples de
traduction. La traduction guide&#769;e par l&#8217;exemple se caracte&#769;rise par la phrase comme unite&#769; de traduction
ide&#769;ale. Une nouvelle traduction est ge&#769;nere&#769;e par analogie : seulement les parties qui changent par rapport
a&#768; un ensemble de traductions connues sont adapte&#769;es, modifie&#769;es ou substitue&#769;es.
</p>
<p>Je pre&#769;sente quelques techniques qui ont e&#769;te&#769; utilise&#769;es pour ce faire. Je discuterai un syste&#768;me spe&#769;cifique,
EDGAR, plus en detail. Je de&#769;montrerai comment des textes traduits aligne&#769;s peuvent e&#770;tre prepare&#769;s en
termes de compilation pour extraire des unite&#769;s de traduction sous-phrastiques. Je pre&#769;sente des re&#769;sultats
en traduction Anglais &#0; Franc&#807;ais produits avec le syste&#768;me EDGAR en les comparant avec ceux d&#8217;un
syste&#768;me statistique.
</p>
<p>In this paper I characterize a number of machine translation approaches: rule-based machine translation
(RBMT), statistical machine translation (SMT) and example-based machine translation (EBMT). While
RBMT systems make use of hand-build rules, SMT and EBMT systems explore and re-use a set of
reference translations. EBMT systems are rooted in analogical reasoning, where the ideal translation unit
is the sentence. Only if an identical sentence cannot be found in the reference material, EBMT systems
modify, substitute and adapt sequences of the retrieved examples to generate a suitable translation.
</p>
<p>I discuss runtime and compilation time techniques and I present a system, EDGAR, in more detail.
I show how translation units are extracted off-line and how they are re-used during translation. The
description of a series of experiments for the translation English &#0; French conclude this paper. An
extended bibliography provides further pointer for interested readers.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Michael Carl
</p>
<p>1 Contenu
&#1; Caracte&#769;risation des approches a&#768; la traduction automatique
</p>
<p>&#8212; Traduction base&#769;e sur des re&#768;gles, traduction statistique et traduction guide&#769;e par l&#8217;exemple
&#1; Traduction guide&#769;e par l&#8217;exemple (EBMT)
</p>
<p>&#8212; Approches en termes de temps d&#8217;exe&#769;cution et approches en termes de compilation
&#1; Le syste&#768;me EDGAR
</p>
<p>&#8212; Segmentation, ge&#769;ne&#769;ralisation, spe&#769;cification et raffinement
&#1; Acquisition de grammaires de traduction
</p>
<p>&#8212; Proprie&#769;te&#769;s de grammaires de traduction
&#8212; Algorithme d&#8217;extraction de grammaire
</p>
<p>&#1; Expe&#769;riences en traduction Anglais &#0; Franc&#807;ais
&#8212; Acquisition des grammaires Anglais &#0; Franc&#807;ais a&#768; partir du Canadian Hansards
&#8212; Echelonnement de l&#8217;approche
&#8212; Comparaison avec BabelFish et traduction statistique
&#8212; Inte&#769;gration EBMT et SMT
</p>
<p>2 Caracte&#769;risation des approches a&#768; la traduction automatique
</p>
<p>2.1 Traduction automatique base&#769;e sur re&#768;gles (RBMT)
</p>
<p>Des approches en traduction base&#769;e sur re&#768;gles (RBMT) sont fre&#769;quemment pre&#769;sente&#769;s par la pyramide de
(Vauquois, 1968) (voir en dessous). Ces syste&#768;mes contiennent typiquement une se&#769;rie de fonctions qui
analysent les phrases a&#768; traduire : analyses morphologiques, syntaxiques et/ou se&#769;mantiques, un module
de transfert de la langue source en langue cible qui de&#769;pend du degre&#769; d&#8217;abstraction de la repre&#769;sentation
du syste&#768;me, et une se&#769;rie de fonctions qui gene&#768;rent la phrase cible. Ces fonctions sont controle&#769;es par
des dictionnaires et par des grammaires qui sont le plus souvent obtenues par l&#8217;inspection d&#8217;un (ou d&#8217;un
groupe de) linguiste(s). Ceci a pour conse&#769;quence un de&#769;veloppement lent du syste&#768;me principalement du&#770;
au proble&#768;me d&#8217;acquisition de connaissances car les proble&#768;mes linguistiques de traduction doivent e&#770;tre
d&#8217;abord comple&#768;tement compris avant de les formuler en termes de re&#768;gles. Mais beaucoup de proble&#768;mes
en traduction automatique n&#8217;ont pas (encore) e&#769;te&#769; entie&#768;rement compris ou requie&#768;rent une analyse comple&#768;te
se&#769;mantique et pragmatique ce qui n&#8217;est pas toujours disponible dans la plus part des cas.
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2;
</p>
<p>&#2; &#3;&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4; &#5;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4;
</p>
<p>&#4; &#5;
</p>
<p>&#4;
</p>
<p>&#4; &#5;
</p>
<p>Langage pivot
</p>
<p>Transfert &#6;
</p>
<p>Traduction directe &#6;
</p>
<p>Langue source Langue cible
</p>
<p>Ressources :
&#1; Re&#768;gles linguistiques d&#8217;analyse
</p>
<p>(morphologique, syntaxique et/ou se&#769;mantique)
&#1; Re&#768;gles de transfert lexical et structurel
&#1; Re&#768;gles linguistiques pour la ge&#769;ne&#769;ration
</p>
<p>Proble&#768;mes:
&#1; Acquisition et maintenance des connaissances
&#1; De&#769;veloppement et maintenance de
</p>
<p>grandes ressource lexicales et grammaticales
&#1; Mode&#769;lisation linguistique de&#769;taille&#769;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La traduction guide&#769;e par l&#8217;exemple
</p>
<p>2.2 Traduction base&#769;e sur des donne&#769;es
</p>
<p>La traduction base&#769;e sur des donne&#769;es (Corpus-based Machine Translation (CBMT), mais aussi Data-
driven Machine Translation) subsume un ensemble de me&#769;thodes alternatives et re&#769;centes qui visent a&#768;
resoudre le proble&#768;me de l&#8217;acquisition des connaissances en traduction par re&#768;gles. Ces me&#769;thodes utilisent
des textes bilingues traduits qui sont consulte&#769;s lors de la traduction d&#8217;un texte ou d&#8217;une phrase nouvelle.
Les textes bilingues sont aligne&#769;s en segments de manie&#768;re suivante:
</p>
<p>Texte bilingue aligne&#769; (extrait du Canadian Hansard)
</p>
<p>1 LA CHARTE CANADIENNE DES DROITS
ET LIBERT &#180;ES
</p>
<p>canadian charter of rights and freedoms
</p>
<p>2 L&#8217;hon. Beno&#305;&#770;t Bouchard (secre&#769;taire d&#8217; &#180;Etat du
Canada):
</p>
<p>Hon. Beno&#305;&#770;t Bouchard (Secretary of State of
Canada):
</p>
<p>3 Monsieur le Pre&#769;sident, je voudrais porter a&#768;
l&#8217;attention de la Chambre que nous ce&#769;le&#769;brons
aujourd&#8217;hui, comme le savent les honorables
de&#769;pute&#769;s, l&#8217;anniversaire de la proclamation de
la Charte canadienne des droits et liberte&#769;s
qui a eu lieu le 17 avril 1982, ainsi que son
parache&#768;vement, il y a un an, avec l&#8217;entre&#769;e en
vigueur des dispositions garantissant l&#8217;e&#769;galite&#769;
a&#768; tous les membres de notre socie&#769;te&#769;.
</p>
<p>Mr. Speaker, I would like to bring to the
attention of the House that today, as Hon.
Members are no doubt aware, we are cele-
brating the anniversary of the proclamation of
the Canadian Charter of Rights and Freedoms
which took place on April 17, 1982, and also
of the coming into effect a year ago of the pro-
visions guaranteeing equality for all members
of our society.
</p>
<p>Parmis le paradigme CBMT, deux directions principales peuvent e&#770;tre distingue&#769;es : la traduction statis-
tique et la traduction guide&#769;e par l&#8217;exemple.
</p>
<p>2.2.1 Traduction statistique (SMT)
</p>
<p>La traduction statistique (SMT) se base sur la the&#769;orie mathe&#769;matique de distribution et d&#8217;estimation prob-
abiliste de&#769;veloppe&#769;e par Frederick Jelinek au IBM T.J. Watson Research Center et &#8212; en particulier &#8212; sur
un article de (Brown et al., 1990). Les syste&#768;mes statistiques apprennent un mode&#768;le probabiliste de tra-
duction ( &#7;&#9;&#8;&#11;&#10;&#13;&#12;&#15;&#14; &#16;&#18;&#17; ) a&#768; partir d&#8217;un texte bilingue et un mode&#768;le probabiliste de la langue cible ( &#7;&#9;&#8;&#11;&#10;&#13;&#12;&#19;&#17; ) a&#768;
partir d&#8217;un texte monolingue. En temps d&#8217;exe&#769;cution, la meilleure traduction pour une phrase nouvelle
est recherche&#769;e gra&#770;ce a&#768; la maximisation de ces deux mode&#768;les probabilistes.
</p>
<p>&#20;
</p>
<p>&#8;&#22;&#21;&#24;&#23;
</p>
<p>&#20;&#26;&#25;
</p>
<p>&#7;&#9;&#8;&#11;&#10;&#13;&#12;&#15;&#14; &#16;&#18;&#17;fiff
</p>
<p>&#20;
</p>
<p>&#8;&#22;&#21;&#24;&#23;
</p>
<p>&#20;fl&#25;&#31;ffi
</p>
<p>&#7; &#8;!&#10;&#13;&#12;&quot;&#17;$#%&#7; &#8;!&#10;&amp;&#16;'&#14; &#12;&#19;&#17;)(
</p>
<p>&#1; mode&#768;le de traduction &#7; &#8;!&#10;&amp;&#16;*&#14; &#12;&quot;&#17;
&#1; mode&#768;le de langue &#7; &#8;!&#10;&#13;&#12;&quot;&#17;
</p>
<p>&#1; Approche d&#8217;apprentissage non-supervise&#769;e base&#769;e sur les formes fle&#769;chies.
&#1; La traduction cible est synthe&#769;tise&#769;e a&#768; partir de traduction(s) de mots individuels.
&#1; Grande quantite&#769; de textes bilingues aligne&#769;s ne&#769;cessaire pour l&#8217;entra&#305;&#770;nement.
</p>
<p>Typiquement, RBMT et SMT ge&#769;ne&#768;rent la phrase cible a&#768; partir des traductions de mots simples et isole&#769;s.
La &#8216;meilleure&#8217; traduction est de&#769;termine&#769;e:
</p>
<p>en SMT par les probabilite&#769;s de &#7; &#8;!&#10;&amp;&#16;*&#14; &#12;&quot;&#17; et &#7; &#8;!&#10;&#13;&#12;&quot;&#17;
en RBMT par des contraintes exprime&#769;es par des re&#768;gles</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Michael Carl
</p>
<p>2.2.2 La traduction guide&#769;e par l&#8217;exemple (EBMT) : Traduction par Analogie
</p>
<p>La traduction guide&#769;e par l&#8217;exemple (Example-Based Machine Translation, EBMT) prend sa place en-
tre la RBMT et la SMT : beaucoup d&#8217;approches inte&#768;grent des re&#768;gles et des techniques statistiques.
Ne&#769;anmoins il y a des caracte&#769;ristiques qui distinguent l&#8217;EBMT de la SMT et de la RBMT :
&#1; La &#8216;phrase&#8217; est l&#8217;unite&#769; de traduction ide&#769;ale.
&#1; Traduction guide&#769;e par l&#8217;exemple consiste a&#768; :
</p>
<p>&#8212; rechercher les meilleurs exemple(s) de re&#769;fe&#769;rence dans une base de donne&#769;es.
&#8212; substituer, modifier et adapter des se&#769;quences diffe&#769;rentes.
</p>
<p>Beaucoup de techniques ont e&#769;te&#769; utilise&#769;es et invente&#769;es en EBMT pour substituer, modifier et adapter les
se&#769;quences de mots qui diffe&#768;rent dans les exemples de la base et les nouvelles phrases a&#768; traduire. Un
excellent survol de ces techniques et de leur enjeu se trouve dans (Somers, 1999; Somers, 2003). Dans
mon article je pre&#769;sente plus en detail :
&#1; Approches en termes de temps d&#8217;exe&#769;cution
&#1; Approches en termes de compilation
</p>
<p>&#8212; Repre&#769;sentations en sche&#769;mas
&#8212; Repre&#769;sentations en arbres syntaxiques
</p>
<p>3 La traduction guide&#769;e par l&#8217;exemple (EBMT)
</p>
<p>3.1 Approches en termes de temps d&#8217;exe&#769;cution
</p>
<p>3.1.1 Segmentation dynamique
</p>
<p>Dans l&#8217;approche propose&#769; par (Andriamanankasina et al., 2003; Andriamanankasina et al., 1999) les
exemples sont balise&#769;s et les correspondances entre les mots des deux phrases sont marque&#769;s. L&#8217;exemple
le plus proche a&#768; la phrase nouvelle a&#768; traduire est reche&#769;rche&#769; et des se&#769;quences e&#769;gaux sont traduites en
langue cible. Ce processus est itere&#769; jusqu&#8217;a&#768; ce que la phrase est entie&#768;remente traduite ou&#768; il n&#8217;y as plus
d&#8217;exemple proche disponible dans la base. La traduction peut e&#770;tre corrige&#769;e manuellement et insere&#769;e
dans la base de manie&#768;re dynamique. Andriamanankasina et al. montrent que ce cycle d&#8217;apprentissage
ameliore les re&#769;sultats de traduction obtenu.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La traduction guide&#769;e par l&#8217;exemple
</p>
<p>3.1.2 Adaptabilite&#769; versus similarite&#769; en recherche
</p>
<p>Dans le syste&#768;me de (Collins &amp; Cunningham, 1997; Collins, 1998), voir aussi : (Collins &amp; Somers,
2003), les exemples sont balise&#769;s et segmente&#769;s et portent l&#8217;information du ro&#770;le syntaxique. Les segments
correspondants sont connecte&#769;s d&#8217;une langue a&#768; l&#8217;autre. Le processus de recherche inclut une mesure
d&#8217;adaptabilite&#769; qui indique la similarite&#769; de l&#8217;exemple par rapport a&#768; son contexte externe. La notion
adaptation-guided retrieval (recherche guide&#769;e par l&#8217;adaptabilite&#769;) indique le degre&#769; auquel les exemples
retrouve&#769;s sont un bon mode&#768;le pour la traduction desire&#769; : alors que le &#8220;CASE A&#8221; est plus similaire du
&#8220;INPUT&#8221;, &#8220;CASE B&#8221; est le meilleur mode&#768;le pour sa traduction du&#770; a&#768; sa meilleure adaptabilite&#769;.
</p>
<p>3.2 Approches en termes de compilation
</p>
<p>3.2.1 Extraction &#8220;linguistic-light&#8221;
</p>
<p>Gu&#776;venir et Cicekli (Gu&#776;venir &amp; Cicekli, 1998; Cicekli &amp; Gu&#776;venir, 1996; Cicekli &amp; Gu&#776;venir, 2003)
pre&#769;sentent un algorithme pour l&#8217;extraction des correspondances lexicales de deux exemples de traduction
: des parties du co&#770;te&#769; source doivent correspondre aux parties similaires du co&#770;te&#769; cible et des cha&#305;&#770;nes de
mots diffe&#769;rentes en langue source doivent correspondre a&#768; des cha&#305;&#770;nes de mots diffe&#769;rentes en cible. Ces
correspondances sont apprises en forme de sche&#769;mas de traduction (translation template). Un sche&#769;ma
de traduction est un exemple de traduction ge&#769;neralise&#769; dont certaines parties ont e&#769;te&#769; remplace&#769;es par des
variables lie&#769;es.
</p>
<p>Deux exemples de traduction :
I took a ticket from Mary + Mary&#8217;den bir bilet aldim
I took a pen from Mary + Mary&#8217;den bir kalem aldim
</p>
<p>Ge&#769;ne&#769;ralisation de diffe&#769;rences et extraction de correspondances lexicales :
I took a ,.- from Mary + Mary&#8217;den bir /0- aldim
</p>
<p>ticket + bilet
pen + kalem</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Michael Carl
</p>
<p>3.2.2 Extraction &#8220;linguistic-heavy&#8221; : Microsoft Research MT (MSR-MT)
</p>
<p>(Richardson et al., 2001; Menezes &amp; Richardson, 2003) utilisent des re&#768;gles pour obtenir les formes
logiques des exemples. Ces repre&#769;sentations sont connecte&#769;es gra&#770;ce a&#768; un lexique bilingue. Ensuite des
connections ambigue&#776;s sont nettoye&#769;es avec des re&#768;gles de pre&#769;fe&#769;rence. Finalement des structures de transfert
de haute qualite&#769; (ce qu&#8217;ils apellent des transfer mappings) sont extraites. Pour chaque structure de
transfert la fre&#769;quence est calcule&#769;es et un contexte suffisant est garde&#769; pour distinguer les &#8220;mappings&#8221;
ambigue&#776;s pendant la traduction.
</p>
<p>Exemple de traduction:
</p>
<p>En Informacio&#769;n del hiperv&#305;&#769;nculo, haga clic en la direccio&#769;n del hiperv&#305;&#769;nculo.
12&#0;
</p>
<p>Under Hyperlink Information, click the hyperlink address.
</p>
<p>Correspondances lexicales entre les formes logiques (FL) Alignement entre FL espagnol et anglais
</p>
<p>Structures de transfert (transfer mappings) acquises de l&#8217;espagnol vers l&#8217;anglais</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La traduction guide&#769;e par l&#8217;exemple
</p>
<p>4 Pre&#769;sentation du syste&#768;me EDGAR
</p>
<p>Le syste&#768;me EDGAR (Carl, 1999) utilise des analyseurs morphologique et syntaxique en plus des ex-
emples de traduction. Un me&#769;canisme d&#8217;induction ge&#769;ne&#769;ralise des exemples et produit une grammaire de
traduction (Carl, 2003). La segmentation et ge&#769;ne&#769;ralisation d&#8217;une nouvelle phrase source ainsi que le raf-
finement de sa traduction dans la langue cible sont guide&#769;s par le contenu de la grammaire de traduction.
</p>
<p>4.1 Segmentation, ge&#769;ne&#769;ralisation, spe&#769;cification et raffinement
</p>
<p>La grammaire de traduction contient des unite&#769;s de traduction lexicales et des sche&#769;mas de traduction vari-
abilise&#769;s.
</p>
<p>1 (Every handsome man) 354 6&#24;7 (Jeder stattliche Mann) 384
2 (a pretty woman) 354 6&#24;7 (eine hu&#776;bsche Frau) 354
3t ( 9$354 love :5;&lt;30=&gt;354 ) ? 6&#24;7 ( 9$354 lieben :5;@30=&gt;384 ) ?
</p>
<p>Segmentation et Ge&#769;ne&#769;ralisation
</p>
<p>Every handsome man
A B&quot;C D
</p>
<p>loves a pretty woman
A B&quot;C D
</p>
<p>E E
</p>
<p>9GF
</p>
<p>3848H 3JILK
</p>
<p>love :5;@3 =NM
3848H O)P&amp;P
</p>
<p>A B&quot;C D
</p>
<p>E
</p>
<p>QSRLTVU
</p>
<p>F
</p>
<p>H
</p>
<p>MXW
</p>
<p>?YH :Z;&lt;3
</p>
<p>Spe&#769;cification et Raffinement
</p>
<p>Q
</p>
<p>R[TVU
</p>
<p>F
</p>
<p>H
</p>
<p>M[W
</p>
<p>E
</p>
<p>C D&quot;A B
</p>
<p>9
</p>
<p>F
</p>
<p>354\H 3]I[K
</p>
<p>lieben :5;&lt;3 = M
354\H O&#19;P&amp;P
</p>
<p>E E
</p>
<p>C D&#19;A B
</p>
<p>Jeder stattliche Mann liebt
C D&quot;A B
</p>
<p>eine hu&#776;bsche Frau
</p>
<p>4.2 Repre&#769;sentation dans le programme EDGAR
</p>
<p>Les entre&#769;es dans la grammaire portent l&#8217;information morphologique et les lemmas sous forme d&#8217;attribut/valeur,
des traits. Les traits d&#8217;une analyse d&#8217;un mot peuvent e&#770;tre complexe (p.ex. agr en bas) ou atomiques
(p.ex. lu en bas). De plus, les traits peuvent e&#770;tre atomique disjonctifs (p.ex. case=d;g) ou comples
disjonctifs. Par exemple, la repre&#769;sentation du mot allemand &#8220;der&#8221; porte les traits suivants:
^_
</p>
<p>_
</p>
<p>_
</p>
<p>_
</p>
<p>`
</p>
<p>_
</p>
<p>_
</p>
<p>_
</p>
<p>_a
</p>
<p>lu=d_art,c=w,sc=art,fu=def
</p>
<p>agr=
</p>
<p>^_
</p>
<p>`
</p>
<p>_a
</p>
<p>gen=f,
nb=sg,
case=d;g
</p>
<p>b _c
</p>
<p>_
</p>
<p>d
</p>
<p>;
</p>
<p>^_
</p>
<p>`
</p>
<p>_a
</p>
<p>gen=m,
nb=sg,
case=n
</p>
<p>b _c
</p>
<p>_
</p>
<p>d
</p>
<p>;
</p>
<p>^_
</p>
<p>`
</p>
<p>_a nb=plu,
case=g
</p>
<p>b _c
</p>
<p>_
</p>
<p>d
</p>
<p>b _
</p>
<p>_
</p>
<p>_
</p>
<p>_
</p>
<p>c
</p>
<p>_
</p>
<p>_
</p>
<p>_
</p>
<p>_
</p>
<p>d
</p>
<p>;
</p>
<p>^_
</p>
<p>_
</p>
<p>_
</p>
<p>_
</p>
<p>`
</p>
<p>_
</p>
<p>_
</p>
<p>_
</p>
<p>_a
</p>
<p>lu=d_rel,c=w,sc=rel,fu=np,
</p>
<p>agr=
</p>
<p>^_
</p>
<p>`
</p>
<p>_a
</p>
<p>case=n,
</p>
<p>g=m,
nb=sg
</p>
<p>b _c
</p>
<p>_
</p>
<p>d
</p>
<p>;
</p>
<p>^_
</p>
<p>`
</p>
<p>_a
</p>
<p>case=g;d,
nb=sg,
g=f
</p>
<p>b _c
</p>
<p>_
</p>
<p>d
</p>
<p>b _
</p>
<p>_
</p>
<p>_
</p>
<p>_
</p>
<p>c
</p>
<p>_
</p>
<p>_
</p>
<p>_
</p>
<p>_
</p>
<p>d
</p>
<p>4.3 Percoler des traits avec des re&#768;gles KURD
</p>
<p>L&#8217;analyseur KURD (Carl &amp; Schmidt-Wigger, 1998) sert a&#768; percoler les traits dans les arbres de de&#769;rivation
et a&#768; unifier et substituer des valeurs dans les noeuds. La re&#768;gle NP monte l&#8217;information d&#8217;accord des
noeuds terminaux dans le noeud pe&#768;re.
</p>
<p>NP = Aa ffi c=np ( [
e ffi c=w,sc=art,agr=_AGR ( ,
# a ffi c=adj,agr=_AGR ( ,
e
</p>
<p>e ffi c=noun,agr=_AGR (
]
</p>
<p>: Au ffi agr=_AGR (
</p>
<p>Les ope&#769;rations de KURD
</p>
<p>&#1; Unification et suppression de traits.
&#1; Concate&#769;nation et substitution de valeurs.
&#1; Insertion et suppression de noeuds.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Michael Carl
</p>
<p>5 Acquisition de grammaires de traduction
</p>
<p>5.1 Proprie&#769;te&#769;s des grammaires de traduction
</p>
<p>5.1.1 Grammaire de traduction homomorphe et arbres de de&#769;rivation isomorphes
</p>
<p>Les grammaires homomorphes produisent des arbres isomorphes et rendent possible un transfert 1-a&#768;-1
de la source a&#768; la cible.
</p>
<p>1 (Every handsome man) f&#19;g h0i (Jeder stattliche Mann) f&quot;g
2 (a pretty woman) f&#19;g h0i (eine hu&#776;bsche Frau) f&#19;g
3t ( j f&quot;g love k&quot;l
</p>
<p>ffim
</p>
<p>f&#19;g
</p>
<p>) n h0i ( j f&#19;g lieben k&quot;l
fom
</p>
<p>f&quot;g
</p>
<p>) n
</p>
<p>Every handsome man
p q[r s
</p>
<p>loves a pretty woman
p q[r s
</p>
<p>t t
</p>
<p>j f&#19;g love k&quot;l
f m
</p>
<p>f&quot;g
</p>
<p>p q[r s
</p>
<p>t
</p>
<p>uwv[x
</p>
<p>k&quot;l
</p>
<p>f
</p>
<p>uov[x
</p>
<p>k&quot;l
</p>
<p>f
</p>
<p>y
</p>
<p>r sLp q
</p>
<p>j f&#19;g
</p>
<p>x
</p>
<p>f)z[{ lieben k&#19;l
f m
</p>
<p>f&#19;g
</p>
<p>x |Y}~}
</p>
<p>y y
</p>
<p>r s[p q
</p>
<p>Jeder stattliche Mann liebt
r s[p q
</p>
<p>eine hu&#776;bsche Frau
</p>
<p>5.1.2 Traduction compositionelle versus non-monotone (partiellement compositionelle)
</p>
<p>Les grammaires compositionelles segmentent la phrase source re&#769;cursivement en expressions qui sont
traduites inde&#769;pendamment tandis que les grammaires non-monotones s&#8217;arre&#770;tent a&#768; un certain point.
</p>
<p>Exemple Grammaire
</p>
<p>compositionnelle: business trip &#127; viaje de negocios j&#128;fZzL&#129;)f
m
</p>
<p>fZzL&#129;)f
</p>
<p>&#127;
</p>
<p>m
</p>
<p>fZzL&#129;)f
</p>
<p>de j&#130;f)zL&#129;Zf
business &#127; negocios
</p>
<p>trip &#127; viaje
</p>
<p>non-compositionnelle: field trip &#127; viaje de estudio field trip &#127; viaje de estudio
</p>
<p>non-monotone long field trip &#127; viaje de estudio largo long &#127; largo
field trip &#127; viaje de estudio
</p>
<p>j
</p>
<p>|Y&#131;@&#132;
</p>
<p>m
</p>
<p>fZzL&#129;)f
</p>
<p>&#127;
</p>
<p>m
</p>
<p>fZzL&#129;)f
</p>
<p>j
</p>
<p>|Y&#131;@&#132;
</p>
<p>5.1.3 Grammaire ambigue&#776; versus inverse
</p>
<p>Les grammaires ambigue&#776;s permettent plusieurs traductions pour une expression source tandis que les
grammaires inverses ne produisent qu&#8217;une seule traduction.
</p>
<p>Grammaire ambigue&#776; :
</p>
<p>j&#128;fZzL&#129;Zf
</p>
<p>m
</p>
<p>fZzL&#129;)f
</p>
<p>&#127;
</p>
<p>m
</p>
<p>fZzL&#129;Zf
</p>
<p>de j&#128;f)z[&#129;)f
business &#127; negocios
</p>
<p>trip &#127; viaje
field &#127; estudio
field &#127; campo
</p>
<p>studies &#127; estudio
</p>
<p>Grammaire inverse :
</p>
<p>j0f)z[&#129;)f
</p>
<p>m
</p>
<p>f)zL&#129;Zf
</p>
<p>&#127;
</p>
<p>m
</p>
<p>fZzL&#129;)f
</p>
<p>de j0fZzL&#129;)f
business trip &#127; viaje de negocios
</p>
<p>business &#127; negocios
trip &#127; viaje
</p>
<p>field trip &#127; viaje de estudio</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La traduction guide&#769;e par l&#8217;exemple
</p>
<p>5.2 Extraction de grammaire de traduction : un algorithme
</p>
<p>L&#8217;extraction de grammaires a&#768; partir d&#8217;exemples de traduction se pousuit en quatre e&#769;tapes.
</p>
<p>5.2.1 Alignement partiellement analyse&#769; et ancre&#769; avec un dictionnaire bilingue
</p>
<p>D&#8217;abord l&#8217;analyse syntaxique partielle des deux co&#770;te&#769;s de l&#8217;alignement est effectue&#769;e. Des lexemes des
deux co&#770;te&#769;s sont connecte&#769;s gra&#770;ce a&#768; un dictionnaire bilingue.
All other sniper training is wasted if the sniper misses his target . If the target is missed, the mission is a failure.
</p>
<p>S&#8217;il rate sa cible , tout le reste de son instruction de tireur d&#8217;e&#769;lite ne lui sert a&#768; rien, et la mission est un e&#769;chec .
</p>
<p>5.2.2 De&#769;termination de correspondances phrase a&#768; phrase les plus significantes
</p>
<p>Les poids des correspondances des arbres sont calcule&#769;s a&#768; partir (i) des poids et le nombre des ancres
lexicales (ii) la fre&#769;quence des correspondances dans le texte et (iii) l&#8217;isomorphisme des analyses partielles
(cf. (Carl, 2003))
</p>
<p>other sniper training
</p>
<p>&#133;2&#134;
</p>
<p>R
</p>
<p>&#133;2&#134;&#136;&#135;
</p>
<p>&#133;2&#134;
</p>
<p>R)&#137;
</p>
<p>&#135;
</p>
<p>&#133;2&#134;
</p>
<p>M
</p>
<p>&#137;
</p>
<p>&#135;
</p>
<p>the sniper
</p>
<p>&#133;2&#134;&#139;&#321;
</p>
<p>&#133;2&#134;&#139;&#140;
</p>
<p>&#137;
</p>
<p>&#321;
</p>
<p>his target
</p>
<p>&#133;2&#134;
</p>
<p>FLM
</p>
<p>&#133;2&#134;
</p>
<p>F[F
</p>
<p>&#137;
</p>
<p>FLM
</p>
<p>&#133;2&#134;&#139;&#140;
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;2&#134;&#139;&#321;
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;2&#134;
</p>
<p>F[F
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;2&#134;&#139;&#321; &#133;2&#134;
</p>
<p>FLM
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;2&#134;
</p>
<p>F&#141;M
</p>
<p>&#133;2&#134;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>le reste de son instruction de tireur d&#8217;e&#769;lite
</p>
<p>26 correspondances
des phrases sont
</p>
<p>examine&#769;es
Anglais Franc&#807;ais
&#133;2&#134;
</p>
<p>M
</p>
<p>&#137;
</p>
<p>&#135;
</p>
<p>&#133;2&#134;
</p>
<p>R)&#137;
</p>
<p>&#135;
</p>
<p>&#133;2&#134;
</p>
<p>R
</p>
<p>&#133;2&#134;&#142;&#140;
</p>
<p>&#137;
</p>
<p>&#321;
</p>
<p>b
</p>
<p>_
</p>
<p>_
</p>
<p>c
</p>
<p>_
</p>
<p>_
</p>
<p>d
</p>
<p>^_
</p>
<p>_
</p>
<p>_
</p>
<p>_
</p>
<p>`
</p>
<p>_
</p>
<p>_
</p>
<p>_
</p>
<p>_a
</p>
<p>&#133;2&#134;
</p>
<p>&#140;
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;2&#134;&#139;&#321;
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;2&#134;
</p>
<p>F[F
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;2&#134;
</p>
<p>F&#141;M
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;2&#134;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;&#143;&#134;
</p>
<p>FXF
</p>
<p>&#137;
</p>
<p>F&#141;M&#145;&#144;
</p>
<p>^
</p>
<p>`
</p>
<p>a
</p>
<p>&#133;2&#134;&#139;&#140;
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;2&#134;&#139;&#321;
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;2&#134;
</p>
<p>F[F
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;&#143;&#134;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#137;
</p>
<p>F&#141;&#146;
</p>
<p>&#133;2&#134;
</p>
<p>&#140;
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;&#143;&#134;
</p>
<p>F
</p>
<p>&#321;
</p>
<p>&#137;
</p>
<p>ML&#147;
</p>
<p>&#133;2&#134;
</p>
<p>&#140;
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>&#133;&#143;&#134;
</p>
<p>MXM
</p>
<p>&#137;
</p>
<p>M
</p>
<p>R
</p>
<p>&#133;2&#134;
</p>
<p>&#140;
</p>
<p>&#137;
</p>
<p>F
</p>
<p>&#135;
</p>
<p>Cet extrait d&#8217;alignement de la section 5.2.1 montre trois segments anglais differents connecte&#769;s avec un
segment franc&#807;ais. Sont examine&#769;s 26 correspondances de phrases possibles dont la traduction &#148;&#149;&#7;$&#150;5&#151;!&#152;&#153;+
&#148;&#149;&#7;&#155;&#154;5&#151;&#156;-&#141;&#152; : &#8220;other sniper training + reste de son instruction de tireur d&#8217;e&#769;lite&#8221; est de&#769;tecte&#769;e la plus consis-
tente dans le texte aligne&#769;.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Michael Carl
</p>
<p>5.2.3 Sche&#769;mas de traduction ge&#769;ne&#769;re&#769;s
</p>
<p>Les sche&#769;mas sont ge&#769;ne&#769;re&#769;s par la substitution des correspondances compositionelles.
</p>
<p>All &#148;&#157;&#7; &#150;5&#151;!&#152; is wasted if the sniper misses &#148;&#157;&#7; -&quot;-&quot;&#151;&#156;-L&#150; . If the target is missed, &#148;&#149;&#7; &#150;&quot;&#158;5&#151;&#136;&#150;5- is &#148;&#157;&#7; &#150;&quot;&#159;5&#151;&#136;&#150;Y&#152; .
</p>
<p>S&#8217;il rate &#148;&#157;&#7;&#155;&#152;8&#151;&#136;&#160; , tout le &#148;&#149;&#7;&#155;&#154;5&#151;&#156;-&#141;&#152; ne lui sert a&#768; rien, et &#148;&#157;&#7;$&#150;&quot;&#150;5&#151;&#136;&#150;&quot;&#159; est &#148;&#149;&#7;$&#150;&quot;&#160;5&#151;&#136;&#150;&quot;&#161; .
</p>
<p>5.2.4 Grammaire de traduction ge&#769;ne&#769;re&#769;e
</p>
<p>Une grammaire de traduction compositionnelle et homomorphe est extraite re&#769;cursivement pour chaque
exemple de traduction:
</p>
<p>1 All other sniper training is wasted if the sniper misses his target.
If the target is missed, the mission is a failure.
</p>
<p>+
</p>
<p>S&#8217;il rate sa cible tout le reste de son instruction de tireur d&#8217;e&#769;lite ne lui sert a&#768; rien,
et la mission est un e&#769;chec.
</p>
<p>2 All &#148;&#149;&#7; - is wasted if the sniper misses &#148;&#149;&#7; &#150; . If the target is missed, &#148;&#149;&#7; &#159; is &#148;&#149;&#7; &#152; .
+ S&#8217;il rate &#148;&#149;&#7; &#150; tout le &#148;&#149;&#7;o- ne lui sert a&#768; rien, et &#148;&#157;&#7; &#159; est &#148;&#157;&#7; &#152; .
</p>
<p>3 other sniper training + reste de son instruction de tireur d&#8217;e&#769;lite
4 other &#148;&#157;&#7; - &#148;&#149;&#7; &#150; + reste de son &#148;&#149;&#7; &#150; de &#148;&#149;&#7; -
</p>
<p>5 training + instruction
6 sniper + tireur d&#8217;e&#769;lite
7 his target + sa cible
8 his &#148;&#149;&#7; - + sa &#148;&#149;&#7; -
</p>
<p>9 the mission + la mission
10 the &#148;&#149;&#7; - + la &#148;&#149;&#7; -
</p>
<p>11 mission + mission
12 a failure + un e&#769;chec
13 a &#148;&#149;&#7; - + un &#148;&#149;&#7; -
</p>
<p>6 Expe&#769;riences en traduction guide&#769;e par l&#8217;exemple
</p>
<p>Dans cette section nous ge&#769;ne&#769;rons des grammaires avec l&#8217;approche presente&#769; en section 5. Un texte test
est traduit avec EDGAR pre&#769;sente&#769; en section 4. Une description plus e&#769;tendue des expe&#769;riences peut e&#770;tre
trouve&#769; dans (Carl &amp; Langlais, 2003). Les expe&#769;riences se basent sur le Canadian Hansards, texte bilingue
Anglais + Franc&#807;ais. Nous pre&#769;sentons des expe&#769;riences diffe&#769;rentes d&#8217;extraction de grammaire aussi bien
en ce qui concerne le nombre d&#8217;exemples que le degre&#769; d&#8217;ambigu&#305;&#776;te&#769; de la grammaire ge&#769;ne&#769;re&#769;e.
</p>
<p>6.1 Extraction d&#8217;une grammaire de traduction
</p>
<p>Les ressources utilise&#769;es pour extraire une grammaire de traduction (GT - ) Anglais + Franc&#807;ais incluent
un dictionnaire bilingue de 77.016 entre&#769;es, un programme de segmentation en segments et un ensemble
de 50.000 exemples de traduction aligne&#769;s du Canadian Hansard. Le dictionnaire couvre pre&#768;sque 3/4 des
mots anglais et franc&#807;ais du ET - mais contient seulement a peu pre&#768;s 1/3 des mots differents qui occurent
dans les deux textes. Le programme de segmentation (parser partiel) ge&#769;ne&#768;re au moyen 11 et 13 segments</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La traduction guide&#769;e par l&#8217;exemple
</p>
<p>rsp. par exemple de traduction pour l&#8217;anglais et le franc&#807;ais. Plus que la moitie des segments diffe&#769;rents
(63% et 50% rsp.) font partie des re&#768;gles lexicales de la grammaire inverse extraite.
</p>
<p>Anglais Franc&#807;ais
Exemples de Traduction ET - :
#exemples 50.000 50.000
#mots 888.018 947.194
#mots different 17.915 23.675
#mots/exemples 17,76 18,94
</p>
<p>Grammaire de traduction extraite GT - :
#re&#768;gles lexicales 113.810
#sche&#769;mas de traduction 70.153
</p>
<p>Anglais Franc&#807;ais
Dictionnaire bilingue (DIC) :
#entre&#769;es du dictionnaire 77.016 77.016
%couvert en ET - 74,77% 74,99%
#mots different 7.688 7.714
%anchors (en ET - ) 42,28% 43,53%
</p>
<p>Segments ge&#769;ne&#769;re&#769;s par le parser partiel :
#segments 581,599 650,136
#segments diffe&#769;rents 180,006 226,339
</p>
<p>6.2 Traduction d&#8217;un texte test (TT)
</p>
<p>Un texte test de 500 phrases est traduit de l&#8217;anglais vers le franc&#807;ais avec les re&#768;gles lexicales de GT - .
Alors que la couverture du dictionnaire bilingue (DIC) est plus grande que celle de la grammaire GT - ,
la qualite&#769; de traduction, mesure&#769;e en WER1 et en BLEU (Papineni et al., 2002), est mieux en traduction
GT - . Nous voyons ici une corre&#769;lation entre la qualite&#769; des traductions et la longueur des segments utilise&#769;s
lors de la traduction.
</p>
<p>Texte Test (TT)
Anglais Franc&#807;ais
</p>
<p>#exemples 500 500
#mots 8.665 9.806
#mots/exemples 17,33 19,61
</p>
<p>GT - DIC
%mots couverts 66,38% 66,99%
BLEU 0,1421 0,0573
WER 68,89% 81,68%
</p>
<p>longueur segments &#162;&#164;&#163;
#segments 966 146
#mots couverts 2,652 325
%mots couverts 30,61% 3,75%
</p>
<p>6.3 Echelonnement de grammaires inverses et ambigue&#776;s
</p>
<p>Dans cette expe&#769;rience nous e&#769;tudions (i) la capacite&#769; de l&#8217;algorithme d&#8217;utiliser un nombre diffe&#769;rent d&#8217;exemples
de traduction et (ii) l&#8217;effet de l&#8217;utilisation d&#8217;unite&#769;s ambigue&#776;s. Nous comparons trois grammaires dif-
fere&#769;ntes ge&#769;ne&#769;re&#769;es a&#768; partir d&#8217;ensembles diffe&#769;rents d&#8217;exemples de traduction , tous extraites du Canadian
Hansards.
</p>
<p>ET &#158; ET - ET &#150;
#exemples de traduction 10.000 50.000 100.000
#mots anglais (En) 151.954 888.018 1.437.450
#mots franc&#807;ais (Fr) 163.113 947.194 1.503.196
#mots diffe&#769;rents En 7.343 17.915 22.501
#mots diffe&#769;rents Fr 9.528 23.675 29.559
</p>
<p>Ces trois ensembles de re&#769;ference sont utilise&#769;s afin de ge&#769;ne&#769;rer deux types de grammaires diffe&#769;rentes :
des grammaires inverses GT &#158; , GT - et GT &#150; (dont GT - est e&#769;gale a&#768; celle des sections 6.1 et 6.2) et des
grammaires ambigue&#776;s GT &#165;
</p>
<p>&#158;
</p>
<p>, GT &#165;
-
</p>
<p>et GT &#165;
&#150;
</p>
<p>. Les grammaires ambigue&#776;s contiennent pre&#768;sque 20% plus de
re&#768;gles de transfert lexical, alors que le nombre de mots diffe&#769;rents reste a&#768; peu pre&#768;s pareil dans les deux
</p>
<p>1Les chiffres WER supe&#769;rieures et chiffres BLEU inferieures indiquent le meilleur re&#769;sultat de traduction.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Michael Carl
</p>
<p>types de grammaires. On obverve aussi que le nombre moyen de mots par re&#768;gle augmente dans les
grammaires plus grandes.
</p>
<p>Re&#768;gles inverses de transfert lexical
GT &#158; GT - GT &#150;
</p>
<p>#re&#768;gles lexicales 23.214 113.810 180.745
#mots Anglais (En) 203.426 1.223.260 1.856.392
#mots Franc&#807;ais (Fr) 220.273 1.314.197 2.007.322
#mots diffe&#769;rents En 7.338 17.910 22.488
#mots diffe&#769;rents Fr 9.520 23.659 29.523
</p>
<p>Re&#768;gles ambigue&#776;s de transfert lexical
GT &#165;
&#158;
</p>
<p>GT &#165;
-
</p>
<p>GT &#165;
&#150;
</p>
<p>28.393 146.684 220.248
222.473 1,355.331 2,030.390
244.615 1,491.559 2,219.455
</p>
<p>7.340 17.914 22.495
9.521 23.670 29.542
</p>
<p>En ce qui concerne la qualite&#769; des traductions produites, les deux types de grammaire produisent un taux
de WER et BLEU a&#768; peu pre&#768;s e&#769;gal. Ceci alors qu&#8217;un nombre conside&#769;rable de segments de longueur
supe&#769;rieure a&#768; e&#769;te&#769; utilise&#769; pour produire la traduction avec des grammaires ambigue&#776;s. Nous concluons que
les entre&#769;es ambigue&#776;s repre&#769;sentent pour la plupart des unite&#769;s de traduction de qualite&#769; inferieure.
</p>
<p>Qualite&#769; du texte test en grammaires inverses . . .
GT &#158; GT - GT &#150;
</p>
<p>WER 71,91% 68,89% 66,93%
BLEU 0,1365 0,1421 0,1704
</p>
<p>#segments 3.581 4.405 4.685
#segments diffe&#769;rents 992 1.279 1.387
#mots couverts 4.611 5.752 6.146
</p>
<p>#segments longueur &#162; 2 767 966 1.050
#segments different 353 519 589
#mots couverts 1.952 2.652 2.863
</p>
<p>et qualite&#769; en grammaires ambigue&#776;
GT &#165;
&#158;
</p>
<p>GT &#165;
-
</p>
<p>GT &#165;
&#150;
</p>
<p>71,88% 69,75% 67,22%
0,1398 0,1519 0,1706
</p>
<p>3.599 4.314 4.659
1.055 1.343 1.450
4.680 5.752 6.228
</p>
<p>816 1.032 1.108
380 570 646
</p>
<p>2.170 2.844 3.062
</p>
<p>6.4 Comparaison de GT, SMT et BabelFish
</p>
<p>Dans cette expe&#769;rience nous comparons les re&#769;sultats de traduction obtenus utilisant les grammaires GT &#158;5&#151;&#136;&#150;
avec un syste&#768;me statistique (Langlais, 2002) entraine&#769; sur les me&#770;mes exemples de traduction ET &#158;5&#151;&#136;&#150; . Nous
voyons que les re&#769;sultats SMT sont infe&#769;rieurs (toujours WER et BLEU) a&#768; ceux obtenus en GT. Le syste&#768;me
SMT &#159; qui a e&#769;te&#769; entra&#305;&#770;ne&#769; sur un texte de 1,5 millions de exemples (15 fois plus que ET &#150; ) obtient les
meilleurs re&#769;sultats.
</p>
<p>score GT &#158; GT - GT &#150; SMT &#158; SMT - SMT &#150; SMT &#159; BabelFish
BLEU 0,1365 0,1421 0,1704 0,1156 0,1231 0,1378 0,2061 0,1578
WER 71,91% 68,89% 66,93% 74,72% 73,54% 71,52% 61,66% 66,03%
</p>
<p>Le syste&#768;me commercial BabelFish obtient des re&#769;sultats infe&#769;rieurs a&#768; ceux de SMT &#159; et GT &#150; . Ceci est
surtout du&#770; aux particularite&#769;s du texte traduit : alors que GT et SMT apprennent les traductions parti-
culie&#768;res, BabelFish n&#8217;a pas pu e&#770;tre adapte&#769; a&#768; ce type de texte. Ainsi, la traduction : &#8220;the speaker +
le pre&#769;sident&#8221; a e&#769;te&#769; re&#769;alise&#769;e par GT et SMT alors que BabelFish ge&#769;ne&#768;re la traduction &#8220;le haut-parleur&#8221;.
De me&#770;me : &#8220;some hon. members : oh , oh ! + des voix : oh , oh !&#8221; est une traduction qui se voit
fre&#769;quemment en Canadian Hansards mais BabelFish produit &#8220;membres d&#8217;un certain hon : l&#8217; OH OH&#8221;.
Alors que ce sont des traductions possibles correctes dans d&#8217;autres contextes, elles sont errone&#769;es quant a&#768;
la traduction du Canadian Hansards.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La traduction guide&#769;e par l&#8217;exemple
</p>
<p>6.5 Inte&#769;gration SMT et GT
</p>
<p>Finalement nous essayons d&#8217;inte&#769;grer les grammaires GT et le syste&#768;me statistique suivant (Langlais, 2002)
: quand la grammaire GT contient une entre&#769;e e&#769;gale a&#768; une se&#769;quence de mots dans la phrase a&#768; traduire, le
syste&#768;me SMT est force&#769; d&#8217;inte&#769;grer la traduction propose&#769;e par GT dans sa sortie. La qualite&#769; produite du
syste&#768;me hybride est meilleure quant aux grammaires inverses (SMT &#158;5&#151;&#136;&#150; -GT &#158;5&#151;&#136;&#150; ); pour l&#8217;inte&#769;gration des
grammaires ambigue&#776;s dans le systeme statistique (SMT &#158;5&#151;&#136;&#150; -GT &#165;
</p>
<p>&#158;5&#151;&#136;&#150;
</p>
<p>) une amelioration des re&#769;sultats n&#8217;a
pas pu e&#770;tre observe&#769;.
</p>
<p>SMT &#158; -GT &#158; SMT - -GT - SMT &#150; -GT &#150; SMT &#158; -GT &#165;
&#158;
</p>
<p>SMT - -GT &#165;
-
</p>
<p>SMT &#150; -GT &#165;
&#150;
</p>
<p>BLEU 0.1495 0.1684 0.1789 0.1406 0.1541 0.1654
WER 71.19% 70.32% 68.94% 72.70% 72.45% 71.41%
</p>
<p>7 Re&#769;sume et conclusion
</p>
<p>Dans cet article je pre&#769;sente d&#8217;approches en traduction automatique. Je fais la distinction entre la traduc-
tion par re&#768;gles (RBMT), la traduction statistique (SMT) et la traduction guide&#769;e par l&#8217;exemple (EBMT).
Les ressources necessaires en RBMT sont obtenues par l&#8217;inspection d&#8217;un (ou d&#8217;un groupe de) linguiste(s),
tandis que les approches EBMT et SMT extraient les connaissances de traduction a&#768; partir des textes
bilingues aligne&#769;s. Au contraste a&#768; la SMT, la &#8216;phrase&#8217; est l&#8217;unite&#769; de traduction ide&#769;ale en EBMT. Je
pre&#769;sente des syste&#768;mes EBMT qui extraient et acquirent ces unite&#769;s en termes de temps d&#8217;exe&#769;cution et en
termes de temps de compilation.
</p>
<p>En suite je discute plus en de&#769;tail le syste&#768;me EDGAR. A partir des exemples de traduction, EDGAR
produit la traduction des phrases nouvelles par analogie de manie&#768;re compositionnelle et isomorphe. Je
pre&#769;sente un algorithme pour extraire une grammaire de traduction a&#768; partir des exemples de traduction.
L&#8217;article conclu avec la description d&#8217;une se&#769;rie de expe&#769;riences en traduction guide&#769;e par l&#8217;exemple. De
ces expe&#769;riences nous concluons que :
&#1; La couverture de la grammaire est fonction du nombre des exemples de re&#769;fe&#769;rence.
&#1; Les grammaires produisent une meilleure qualite&#769; de traduction que la traduction SMT
</p>
<p>(taille identique de re&#769;fe&#769;rence)
&#1; Les re&#768;gles ambigue&#776;s n&#8217;ame&#769;liorent pas la qualite&#769; de la traduction.
&#1; L&#8217;inte&#769;gration des techniques EBMT et SMT ameliore les re&#769;sultats de la traduction.
</p>
<p>References
</p>
<p>Al-Adhaileh, M. H. &amp; Tang E. K. 1999. Example-Based Machine Translation Based on the Syn-
chronous SSTC Annotation Schema. Machine Translation Summit VII, Singapore, 244&#8211;249.
</p>
<p>Andriamanankasina, T., K. Araki, &amp; K, Tochinai. 2003. Ebmt of pos-tagged sentences with inductive
learning. In (Carl &amp; Way, 2003).
Andriamanankasina, T., K. Araki &amp; K. Tochinai. 1999. Example-Based Machine Translation of Part-
Of-Speech Tagged Sentences by Recursive Division. Machine Translation Summit VII, Singapore,
509&#8211;517.
</p>
<p>Brown, P. F., J. Cocke, S. A. Della Pietra, V. J. Della Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer
&amp; P. S. Roossin. 1990. A Statistical Approach to Machine Translation. Computational Linguistics 16,
79&#8211;85.
</p>
<p>Brown, R. D. 1996. Example-Based Machine Translation in the Pangloss System. Coling (1996),
169&#8211;174.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Michael Carl
</p>
<p>Brown, R. D. 1997. Automated Dictionary Extraction for &#8220;Knowledge-Free&#8221; Example-Based Transla-
tion. TMI (1997), 111&#8211;118.
Brown, R. D. 1999. Adding Linguistic Knowledge to a Lexical Example-based Translation System.
TMI (1999), 22&#8211;32.
Carl, M. &amp; A. Way, editors. 2003. Recent Advances in Example-Based Machine Translation. Kluwer,
Academic Publisher, Boston/Dordrecht/London. in press.
</p>
<p>Carl, M. 2003. Inducing translation grammars from bracketed alignments. In (Carl &amp; Way, 2003).
Carl, M. &amp; Langlais, P. 2003. Tuning general purpose translation knowledge to a sublanguage. In
Proceedings of EAMT/CLAW.
Carl, M. 1999. Inducing Translation Templates for Example-Based Machine Translation. Machine
Translation Summit VII, Singapore, 250&#8211;258.
</p>
<p>Carl, M. &amp; Schmidt-Wigger, A.. 1998. Shallow Postmorphological Processing with KURD. In Pro-
ceedings of NeMLaP3/CoNLL98, pages 257&#8211;265, Sydney.
Cicekli, I. &amp; H.A. Gu&#776;venir. 2003. Learning Translation Templates from Bilingual Translation Exam-
ples. In (Carl &amp; Way, 2003).
Cicekli, I. &amp; H. A. Gu&#776;venir. 1996. Learning Translation Rules From A Bilingual Corpus. NeMLaP-2:
Proceedings of the Second International Conference on New Methods in Language Processing, Ankara,
Turkey, 90&#8211;97.
</p>
<p>Collins, B. &amp; H. Somers. 2003. EBMT Seen as Case-based Reasoning. In (Carl &amp; Way, 2003).
Collins, B. 1998. Example-Based Machine Translation: An Adaptation-Guided Retrieval Approach.
PhD thesis, Trinity College, Dublin.
</p>
<p>Collins, B. &amp; P. Cunningham. 1997. Adaptation Guided Retrieval: Approaching EBMT with Caution.
TMI (1997), 119&#8211;126.
Cranias, L., H. Papageorgiou &amp; S. Piperidis. 1994. A Matching Technique in Example-Based Machine
Translation. Coling (1994), 100&#8211;104.
Furuse, O. &amp; H. Iida. 1992. An Example-Based Method for Transfer-Driven Machine Translation. TMI
(1992), 139&#8211;150.
Furuse, O. &amp; H. Iida. 1994. Constituent Boundary Parsing for Example-Based Machine Translation.
Coling (1994), 105&#8211;111.
Gu&#776;venir, H. A. &amp; I. Cicekli. 1998. Learning Translation Templates from Examples. Information Systems
23, 353&#8211;363.
</p>
<p>Kaji, H., Y. Kida &amp; Y. Morimoto. 1992. Learning Translation Templates from Bilingual Text. Coling
(1992), 672&#8211;678.
Langlais, P. 2002. Ressources terminologiques et traduction probabiliste: premiers pas positifs vers un
syste&#768;me adaptatif. In TALN-2002.
</p>
<p>Matsumoto, Y. &amp; M. Kitamura. 1995. Acquisition of Translation Rules from Parallel Corpora. In R.
Mitkov &amp; N. Nicolov (eds) Recent Advances in Natural Language Processing: Selected Papers from
RANLP&#8217;95, Amsterdam: John Benjamins, 405&#8211;416.
McTait, K. &amp; A. Trujillo. 1999. A Language-Neutral Sparse-Data Algorithm for Extracting Translation
Patterns. TMI (1999), 98&#8211;108.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La traduction guide&#769;e par l&#8217;exemple
</p>
<p>Menezes, A. &amp; S.D. Richardson. 2003. A best-first alignment algorithm for automatic extraction of
transfer mappings from bilingual corpora. In (Carl &amp; Way, 2003).
Meyers, A., R. Yangarber, R. Grishman, C. Macleod &amp; A. Moreno-Sandeval. 1998. Deriving Transfer
Rules from Dominance-Preserving Alignments. Coling-ACL (1998), 843&#8211;847.
Nagao, M. 1984. A Framework of a Mechanical Translation between Japanese and English by Analogy
Principle. In A. Elithorn and R. Banerji (eds) Artificial and Human Intelligence, 173&#8211;180, Amsterdam:
North-Holland.
</p>
<p>Nirenburg, S., S. Beale &amp; C. Domashnev. 1994. A Full-Text Experiment in Example-Based Machine
Translation. International Conference on New Methods in Language Processing (NeMLaP), Manch-
ester, England, 78&#8211;87.
</p>
<p>Papineni, K., S. Roukos, T. Ward, &amp; W.-J. Zhu. 2002. Bleu: a method for automatic evaluation of
machine translation. In Proceedings of the 40th Annual Meeting of the ACL, Philadelphia, Pennsylvania,
USA, 311&#8211;318.
</p>
<p>Richardson, S.D., W.B. Dolan, A. Menezes &amp; J. Pinkham. 2001. Achieving Commercial-quality Trans-
lation with Example-based Methods. MT Summit VIII: Machine Translation in the Information Age,
Santiago de Compostela, Spain, 293&#8211;298.
</p>
<p>Sato, S. &amp; M. Nagao. 1990. Toward Memory-Based Translation. Coling (1990), Vol. 3, 247&#8211;252.
Somers, H. 1999. Review Article: Example-based Machine Translation. Machine Translation,
14(2):113&#8211;157.
Somers, H. 2003. An Overview of EBMT. In (Carl &amp; Way, 2003).
Sumita, E. &amp; H. Iida. 1991. Experiments and Prospects of Example-Based Machine Translation. 29th
Annual Meeting of the Association for Computational Linguistics, Berkeley, California, 185&#8211;192.
Sumita, E., H. Iida &amp; H. Kohyama. 1990. Translating with Examples: A New Approach to Machine
Translation. TMI (1990), 203&#8211;212.
Vauquois, B. 1968. A Survey of Formal Grammars and Algorithms for Recognition and Transformation
in Machine Translation. IFIP Congress-68, Edinburgh, 254&#8211;260; reprinted in Ch. Boitet (ed.) Bernard
Vauquois et la TAO: Vingt-cinq Ans de Traduction Automatique &#8211; Analectes, 201&#8211;213, Grenoble (1988):
Association Champollion.
</p>
<p>Veale, T. &amp; A. Way. 1997. Gaijin: A Bootstrapping Approach to Example-Based Machine Translation.
International Conference, Recent Advances in Natural Language Processing, Tzigov Chark, Bulgaria,
239&#8211;244.
</p>
<p>Watanabe, H. 1992. A Similarity-Driven Transfer System. Coling (1992), 770&#8211;776.
Watanabe, H. 1993. A Method for Extracting Translation Patterns from Translation Examples. TMI
(1993), 292&#8211;301.
Watanabe, H. &amp; K. Takeda. 1998. A Pattern-Based Machine Translation System Extended by Example-
Based Processing. Coling-ACL (1998), 1369&#8211;1373.
Way, A. 1999. A Hybrid Architecture for Robust MT using LFG-DOP. Journal of Experimental and
Theoretical Artificial Intelligence 11, 441&#8211;471.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p> </p>

</div></div>
</body></html>