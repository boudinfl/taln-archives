TALN 2003, Batz-sur-Mer, 11-14 juin 2003

Introduction a la traduction guidée par l’exemple
(Traduction par analogie)

Michael Carl
Institut fur Angewandte Informationsforschung,
Martin-Luther-StraBe 14,
66111 Saarbriicken, Germany,
carl@iai.uni-sb.de

Mots-clefs — Keywords

traduction guidée par l’exemple, traduction par analogie, traduction statistique, induction de grammaire
de traduction

example-based machine translation, analogical translation, statistical machine translation, induction of
translation grammar

Résumé - Abstract

Le nombre d’approches en traduction automatique s’est multiplié dans les derniéres années. I1 existe
entre autres la traduction par régles, la traduction statistique et la traduction guidée par l’exemple. Dans
cet article je decris les approches principales en traduction automatique. Je distingue les approches
qui se basent sur des régles obtenues par l’inspection des approches qui se basent sur des exemples de
traduction. La traduction guidée par l’exemple se caractérise par la phrase comme unité de traduction
idéale. Une nouvelle traduction est génerée par analogie 2 seulement les parties qui changent par rapport
a un ensemble de traductions connues sont adaptées, modiﬁées ou substituées.

Je présente quelques techniques qui ont été utilisées pour ce faire. Je discuterai un systéme spéciﬁque,
EDGAR, plus en detail. J c démontrerai comment des textes traduits alignés peuvent étre preparés en
termes de compilation pour extraire des unités de traduction sous-phrastiques. J c présente des résultats
en traduction Anglais —> Frangais produits avec le systeme EDGAR en les comparant avec ceux d’un
systéme statistique.

In this paper I characterize a number of machine translation approaches: rule-based machine translation
(RBMT), statistical machine translation (SMT) and example-based machine translation (EBMT). While
RBMT systems make use of hand-build rules, SMT and EBMT systems explore and re-use a set of
reference translations. EBMT systems are rooted in analogical reasoning, where the ideal translation unit
is the sentence. Only if an identical sentence cannot be found in the reference material, EBMT systems
modify, substitute and adapt sequences of the retrieved examples to generate a suitable translation.

I discuss runtime and compilation time techniques and I present a system, EDGAR, in more detail.
I show how translation units are extracted off-line and how they are re-used during translation. The
description of a series of experiments for the translation English —> French conclude this paper. An
extended bibliography provides further pointer for interested readers.

Michael Carl

1 Contenu

0 Caracterisation des approches a la traduction automatique
— Traduction basee sur des regles, traduction statistique et traduction guidee par l’exemple
o Traduction guidee par l’exemple (EBMT)
— Approches en termes de temps d’execution et approches en termes de compilation
0 Le systeme EDGAR
— Segmentation, generalisation, speciﬁcation et raﬂinement
0 Acquisition de grammaires de traduction
— Proprietes de grammaires de traduction
— Algorithme d’ extraction de grammaire
0 Experiences en traduction Anglais —> Francais
— Acquisition des grammaires Anglais —> Francais a partir du Canadian Hansards
— Echelonnement de l’approche
— Comparaison avec BabelFish et traduction statistique
— Integration EBMT et SMT

2 Caractérisation des approches £1 la traduction automatique

2.1 Traduction automatique basée sur régles (RBMT)

Des approches en traduction basée sur régles (RBMT) sont frequemment presentes par la pyramide de
(Vauquois, 1968) (Voir en dessous). Ces systemes contiennent typiquement une serie de fonctions qui
analysent les phrases a traduire 2 analyses morphologiques, syntaxiques et/ou semantiques, un module
de transfert de la langue source en langue cible qui depend du degre d’abstraction de la representation
du systeme, et une serie de fonctions qui generent la phrase cible. Ces fonctions sont controlees par
des dictionnaires et par des grammaires qui sont le plus souvent obtenues par l’inspection d’un (ou d’un
groupe de) linguiste(s). Ceci a pour consequence un developpement lent du systeme principalement dﬁ
au probleme d’acquisition de connaissances car les problemes linguistiques de traduction doivent etre
d’abord completement compris avant de les formuler en termes de regles. Mais beaucoup de problemes
en traduction automatique n’ont pas (encore) ete entierement compris ou requierent une analyse complete
semantique et pragmatique ce qui n’est pas toujours disponible dans la plus part des cas.
Langage pivot
Ressources 2

  
  
 
 
 
 
 
  

o Regles linguistiques d’analyse

(morphologique, syntaxique et/ou semantique)
o Regles de transfert lexical et structurel
o Regles linguistiques pour la generation

Problemes:
0 Acquisition et maintenance des connaissances

0 Developpement et maintenance de
grandes ressource lexicales et grammaticales
0 Modelisation linguistique detaille

   

Traduction directe

/' :\

Langue source Langue cible

  

La traduction guidée par l’exemple

2.2 Traduction basée sur des données

La traduction basée sur des données (Corpus-based Machine Translation (CBMT), mais aussi Data-
driven Machine Translation) subsume un ensemble de méthodes alternatives et récentes qui Visent a
resoudre le probleme de l’acquisition des connaissances en traduction par regles. Ces méthodes utilisent
des textes bilingues traduits qui sont consultés lors de la traduction d’un texte ou d’une phrase nouvelle.
Les textes bilingues sont alignés en segments de maniere suiVante:

Texte bilingue aligné (extrait du Canadian Hansard)

LA CHARTE CANADIENNE DES DROITS
ET LIBERTES

L’hon. Benoit Bouchard (secrétaire d’Etat du
Canada):

Monsieur le President, je Voudrais porter a
l’attention de la Chambre que nous célébrons
aujourd’hui, comme le savent les honorables
députés, l’anniVersaire de la proclamation de
la Charte canadienne des droits et libertés
qui a eu lieu le 17 avril 1982, ainsi que son
parachevement, il y a un an, avec l’entrée en
Vigueur des dispositions garantissant l’égalité

canadian charter of rights and freedoms

Hon. Benoit Bouchard (Secretary of State of
Canada):

Mr. Speaker, I would like to bring to the
attention of the House that today, as Hon.
Members are no doubt aware, we are cele-
brating the armiversary of the proclamation of
the Canadian Charter of Rights and Freedoms
which took place on April 17, 1982, and also
of the coming into effect a year ago of the pro-
Visions guaranteeing equality for all members

a tous les membres de notre société.

of our society.

Parmis le paradigme CBMT, deux directions principales peuvent étre distinguées 2 la traduction statis-
tique et la traduction guidée par l ’exemple.

2.2.1 Traduction statistique (SMT)

La traduction statistique (SMT) se base sur la théorie mathématique de distribution et d’estimation prob-
abiliste développée par Frederick J elinek au IBM T.J. Watson Research Center et — en particulier— sur
un article de (Brown et al., 1990). Les systemes statistiques apprennent un modele probabiliste de tra-
duction (Pr(t|s)) a partir d’un texte bilingue et un modele probabiliste de la langue cible (Pr(t)) a
partir d’un texte monolingue. En temps d’exécution, la meilleure traduction pour une phrase nouVelle
est recherchée grace a la maximisation de ces deux modeles probabilistes.

arg ma:zP7"(t|s) = arg ma.:1;{P7‘(t) >1: P1'(s|t)}

modele de traduction Pr(s|t)
modele de langue Pr(t)

Approche d’ apprentissage non-supervisée basée sur les formes ﬂéchies.
La traduction cible est synthétisée a partir de traduction(s) de mots individuels.
Grande quantité de textes bilingues alignés nécessaire pour l’entrainement.

Typiquement, RBMT et SMT génerent la phrase cible a partir des traductions de mots simples et isolés.
La ‘meilleure’ traduction est déterminée:

en SMT par les probabilites de Pr(s|t) et Pr(t)
en RBMT par des contraintes exprimées par des regles

Michael Carl

2.2.2 La traduction guidée par l’exemple (EBMT) : Traduction par Analogie

La traduction guidée par l’exemple (Example-Based Machine Translation, EBMT) prend sa place en-
tre la RBMT et la SMT 2 beaucoup d’approches integrent des regles et des techniques statistiques.
Neanmoins il y a des caracteristiques qui distinguent l’EBMT de la SMT et de la RBMT 2

La ‘phrase’ est l’unite de traduction ideale.

Traduction guidee par l’exemple consiste a 2

— rechercher les meilleurs exemple(s) de reference dans une base de donnees.
— substituer, modiﬁer et adapter des sequences differentes.

Beaucoup de techniques ont ete utilisees et inventees en EBMT pour substituer, modiﬁer et adapter les
sequences de mots qui different dans les exemples de la base et les nouvelles phrases a traduire. Un
excellent survol de ces techniques et de leur enjeu se trouVe dans (Somers, 1999; Somers, 2003). Dans
mon article je presente plus en detail 2

Approches en termes de temps d’execution
Approches en termes de compilation

— Representations en schemas

— Representations en arbres syntaxiques

3 La traduction guidée par l’exemple (EBMT)

3.1 Approches en termes de temps d’exécution
3.1.1 Segmentation dynamique

Dans l’approche propose par (Andriamanankasina et al., 2003; Andriamanankasina et al., 1999) les
exemples sont balises et les correspondances entre les mots des deux phrases sont marques. L’ exemple
le plus proche a la phrase nouVelle a traduire est recherche et des sequences egaux sont traduites en
langue cible. Ce processus est itere jusqu’a ce que la phrase est entieremente traduite ou il n’y as plus
d’exemple proche disponible dans la base. La traduction peut etre corrigee manuellement et inseree
dans la base de maniere dynamique. Andriamanankasina et al. montrent que ce cycle d’appnemfissage
ameliore les resultats de traduction obtenu.

     
 
  
  

Input sentence

Translation

Input sentence: Jean est terriblement malade l

f

Matching sentence: Il est riche

1‘\\

Translation sentence: Kare ha kanemoti dew

Prediction of word

Translation result C01TeSP0Hde1'1°e5
of the new pair

Translation result: Jean ha terriblement malade desu Comcﬁon

La traduction guidée par l’exemple

3.1.2 Adaptabilité versus similarité en recherche

Dans le systeme de (Collins & Cunningham, 1997; Collins, 1998), Voir aussi 2 (Collins & Somers,
2003), les exemples sont balisés et segmentés et portent l’information du role syntaxique. Les segments
correspondants sont connectés d’une langue a l’autre. Le processus de recherche inclut une mesure
d’adaptabilité qui indique la similarité de l’exemple par rapport a son contexte externe. La notion
adaptation-guided retrieval (recherche guidée par l’adaptabilité) indique le degré auquel les exemples
retrouvés sont un bon modele pour la traduction desiré 2 alors que le “CASE A” est plus sirnilaire du
“INPUT”, “CASE B” est le meilleur modele pour sa traduction dﬁ a sa meilleure adaptabilité.

CASEA

zwischen den

FDENEH

between the
shapes

Hit der Option
Abstend

_ The Offset

legen

 

     
   

The Offset . between the
E Eh
INPUT?  
5 I

I
I to disk

your changes

1
& I The Save Option I I to save I

Hit der Option
Speichern

 

Ihre _
Andarungan euf Diskette

 

CASEB

3.2 Approches en termes de compilation
3.2.1 Extraction “linguistic-light”

Guvenir et Cicekli (Guvenir & Cicekli, 1998; Cicekli & Guvenir, 1996; Cicekli & Guvenir, 2003)
présentent un algorithme pour l’extraction des correspondances lexicales de deux exemples de traduction
2 des parties du coté source doivent correspondre aux parties similaires du coté cible et des chaines de
mots différentes en langue source doivent correspondre a des chaines de mots différentes en cible. Ces
correspondances sont apprises en forme de schémas de traduction (translation template). Un schéma
de traduction est un exemple de traduction géneralisé dont certaines parties ont été remplacées par des
Variables liées.

Deux exemples de traduction 2
I took a ticket from Mary <—> Mary’den bir bilet aldim
I took a pen from Mary <—> Mary’den bir kalem aldim

Généralisation de différences et extraction de correspondances lexicales 2

I took a X1 from Mary <—> Mary’den bir 391 aldim
ticket <—> bilet
pen <—> kalem

Michael Carl

3.2.2 Extraction “linguistic-heavy” : Microsoft Research MT (MSR-MT)

(Richardson et a1., 2001; Menezes & Richardson, 2003) utilisent des régles pour obtenir les formes
logiques des exemples. Ces représentations sont connectées grace a un lexique bilingue. Ensuite des
connections arnbigués sont nettoyées avec des régles de préférence. Finalement des structures de transfert
de haute qualité (ce qu’i1s apellent des transfer mappings) sont extraites. Pour chaque structure de
transfert la fréquence est calculées et un contexte sufﬁsant est gardé pour distinguer les “mappings”
ambigués pendant la traduction.

En Informacio’n del hipervinculo, haga clic en la direccio’n del hipervinculo.
(j)

E 1 ' 2
Kemp e de traducuon Under Hyperlink Information, click the hyperlink address.

      

Correspondances lexicales entre les formes logiques (FL) Alignement entre FL espagnol et anglais
hacer hac:er___
en en en  an
--'''''’F# Dsub Dob] EH‘ -""""-‘J Daub Dob]  N‘-K"
infunn aciﬁn ff directi ﬁn.‘ inform aciﬁn  direction:
dle usted clic dle  5' dle Listed clic  die
hineninculo ,5: i hinem'ncu|_::I   hipervinculcu  Ii  hiperx-inculp :5;

   

click 

    

I s
  D obj
 .i—ilyp|?r,1_ink—|nfDnn am“  Dsim Iii-|:\l,rper1ink_|nf0rmati0n  Dsim address‘; 55'
.. -.   Wu M Ind

hyperlink

 

Structures de transfert (transfer mappings) acquises de1’espagno1Vers 1’ang1ais

dire-I:c>i én Iﬁ address
hiprera.-'I'nI:L.Icr I:> hyperlirk
infcrrn acién
de :5 H-3-1::uer|irI|e:_|nfcrrn aticln
hipe-.r'H.-}nc:..i|cI
hacer click
Ds..|b Dob]. en 1'9 Daub Dcrbj
_- \-
(Pronj CI”: |ZNcIL.nj (P rcnnj I:NcIL.rIj|
hacer click
Ds..|b Dob]. en 1'9 Daub Dob]
! -S. /
(Prom) 9'": direc:-I:ic'In |f_‘F" ran) address
|.’."‘~"'E'I-|‘*3')
an (Verb)
il'IfCIl1'1'EEICii ﬁn Lnder
d lib
E H'y1::uE.-r1ink_lnfcIrm ﬁtiEIl‘I
hiperw.-1nc:1..||cI
direc':c:1'c'In address
de Ii‘; r-.-1cid

I I
hipen.-1'ncL.lcI hyperiink

La traduction guidee par l’exemple

4 Presentation du systeme EDGAR

Le systeme EDGAR (Carl, 1999) utilise des analyseurs morphologique et syntaxique en plus des ex-
emples de traduction. Un mecanisme d’induction generalise des exemples et produit une grammaire de
traduction (Carl, 2003). La segmentation et generalisation d’une nouVelle phrase source ainsi que le raf-
ﬁnement de sa traduction dans la langue cible sont guides par le contenu de la grammaire de traduction.

4.1 Segmentation, generalisation, speciﬁcation et rafﬁnement

La grammaire de traduction contient des unites de traduction lexicales et des schemas de traduction Vari-
abilises.

1 (Every handsome man),,,, (—> (Jeder stattliche Mann),,,,

2 (a pretty woman),,,, (—> (eine htibsche Frau),,p
3 (Xnp lovefin ynp)s (Z) (Xnp liebenfin ynp)s
Segmentation et Generalisation spéciﬁcatjon et Rafﬁnement
Every handsome man loves a pretty woman Z3t(1:2)
mm/ mm/
~: .¢ - i
;X"p’"°m lovefin ynp’ac€ X1ip,nom liebenfin y:p,acc
¢ ~L
Zﬁtﬁgz) Jeder stattliche Mann liebt eine htibsche Frau

4.2 Representation dans le programme EDGAR

Les entrees dans la grammaire portent l’information morphologique et les lemmas sous forme d’att1ibut/Valeur,
des traits. Les traits d’une analyse d’un mot peuvent etre complexe (p.ex. agr en bas) ou atomiques
(p.ex. lu en bas). De plus, les traits peuvent etre atomique disjonctifs (p.ex. case=d; g) ou comples
disjonctifs. Par exemple, la representation du mot allemand “der” porte les traits suiVants:

lu=d_art, c=w, sc=art, fu=def lu=d_rel, c=w, sc=rel, fu=np,
gen=f, gen=m, ' case=n, case=g; d,

agr= nb=sg, ; nb=sg, ; nb=plu, ’ agr= g=m, ; nb=sg,
case=d; g case=n case=g nb=sg g=f

4.3 Percoler des traits avec des regles KURD

L’ analyseur KURD (Carl & Schmidt-VV1gger, 1998) sert a percoler les traits dans les arbres de derivation
et a uniﬁer et substituer des Valeurs dans les noeuds. La regle NP monte l’information d’accord des
noeuds terminaux dans le noeud pere.

NP = Aa {c=np}[
e {c=w, sc=art , agr=_AGR},
*3. {c=adj , agr=_AGR},
+e {c=noun, agr=_AGR}
]
Au {agr=_AGR}

Les operations de KURD

Uniﬁcation et suppression de traits.
Concatenation et substitution de Valeurs.
Insertion et suppression de noeuds.

Michael Carl

5 Acquisition de grammaires de traduction

5.1 Propriétés des grammaires de traduction
5.1.1 Grammaire de traduction homomorphe et arbres de dérivation isomorphes

Les grammaires homomorphes produisent des arbres isomorphes et rendent possible un transfert 1-a-1
de la source a la cible.

Every handsome man loves a pretty woman
 /

\ 
i i
21.’ up love fin 3.1,”,
, ¢
1 (Every handsome man),.p (—) (Jeder stattliche Mann),,p  fin
2 (a pretty woman)n,, (—) (eine hiibsche Frau)M, ‘,1’ “-.:
3t  lovefin 3/np)S 1;) (xnp liebenfin ynp)S  Zejfin
an 3 ‘xx " I,’ "N I T I
 ___________________________ ” rx‘np,nom liebenfin 3-}np,a.c¢?
T T

f  f 
Jeder stattliche Mann liebt eine hiibsche Frau

5.1.2 Traduction compositionelle versus non-monotone (partiellement compositionelle)

Les grammaires compositionelles segmentent la phrase source récursivement en expressions qui sont
traduites indépendarnment tandis que les grammaires non-monotones s’arrétent a un certain point.

Exemple Grammaire
compositionnelle: business trip H viaje de negocios noun jinoun H jinoun de noun
business H negocios
trip H viaje
non-compositionnelle: ﬁeld trip H viaje de estudio ﬁeld trip H viaje de estudio
non-monotone long ﬁeld trip H viaje de estudio largo long H largo
ﬁeld trip H viaje de estudio
H

 

)7 noun adj
5.1.3 Grammaire ambigué versus inverse

Les grammaires ambigués permettent plusieurs traductions pour une expression source tandis que les
grammaires inverses ne produisent qu’une seule traduction.

Grammaire ambigue : Grammaire inverse :

 

Xnoun ynoun ynoun de Xnoun Xnoun ynoun

H H
business H negocios business trip H viaje de negocios
trip H viaje business H negocios
ﬁeld H estudio trip H viaje
ﬁeld H campo ﬁeld trip H viaje de estudio
studies H estudio

La traduction guidée par l’exemple

5.2 Extraction de grammaire de traduction : un algorithme

L’ extraction de grammaires a partir d’exemples de traduction se pousuit en quatre étapes.

5.2.1 Alignement partiellement analysé et ancré avec un dictionnaire bilingue

D’abord l’analyse syntaxique partielle des deux cotés de l’alignement est effectuée. Des lexemes des
deux cotés sont connectes grace a un dictionnaire bilingue.

All other sniper training is wasted if the sniper misses his target . If the target is missed, e mission is failure.

2‘ V

 

S’il rate sa cible , tout le reste de son instruction de tireur d’élite ne lui sert a rien, et la mission est un échec .

5.2.2 Détermination de correspondances phrase a phrase les plus signiﬁcantes

Les poids des correspondances des arbres sont calculés a partir (i) des poids et le nombre des ancres
lexicales (ii) la fréquence des correspondances dans le texte et (iii) l’isomorphisme des analyses partielles
(cf. (Carl, 2003))

other sniper training the sniper his target

l l 26 correspondances
NP4 NP12 des phrases sont

   

examinees
Anglais Frangais
NP8—14
NP2—4 NP2_4 NP9_14
NP3_4 NP11 14
NP _
NP8—14 NP3 NP12—14
8-9 NP14
NP8—14
NP11—12 } NP9—14
NP11—14

NP14—15 NP8—14
NP19—2o NP8—14

NP P
12 14 NP22—23 NP8—14

le reste de son instruction de tireur d’élite

Cet extrait d’alignement de la section 5.2.1 montre trois segments anglais differents connectés avec un
segment francais. Sont examines 26 correspondances de phrases possibles dont la traduction N P2_4 <—)
N P9_14 2 “other sniper training <—> reste de son instruction de tireur d’élite” est détectee la plus consis-
tente dans le texte aligné.

Michael Carl

5.2.3 Schémas de traduction générés

Les schemas sont generes par la substitution des correspondances compositionelles.

All N P2_4 is wasted if the sniper misses N P11_12. If the target is missed, N P20_21 is N P23_24.

S’il rate N P4_5 , tout le N P9_14 ne lui sert a rien, et N P22_23 est N P25_25.

5.2.4 Grammaire de traduction générée

Une grammaire de traduction compositionnelle et homomorphe est extraite recursivement pour chaque
exemple de traduction:

1 All other sniper training is wasted if the sniper misses his target.
If the target is missed, the mission is a failure.
(—)
S’il rate sa cible tout le reste de son instruction de tireur d’elite ne lui sert a rien,
et la mission est un echec.
2 All N P1 is wasted if the sniper misses N P2. If the target is missed, N P3 is N P4.

<—> S’il rate N P2 tout le N P1 ne lui sert a rien, et N P3 est N P4.

3 other sniper training <—> reste de son instruction de tireur d’elite
4 other N P1 N P2 <—> reste de son N P2 de N P1

5 training <—> instruction

6 sniper <—> tireur d’elite

7 his target <—> sa cible

8 his N P1 <—> sa N P1

9 the mission <—> la mission

10 the NP1 <—> la NP-1

1 1 mission <—> mission

12 a failure <—> un echec

13 a N P1 <—> un N P1

6 Experiences en traduction guidée par l’exemple

Dans cette section nous generons des grammaires avec l’approche presente en section 5. Un texte test
est traduit avec EDGAR presente en section 4. Une description plus etendue des experiences peut etre
trouve dans (Carl & Langlais, 2003). Les experiences se basent sur le Canadian Hansards, texte bilingue
Anglais <—> Francais. Nous presentons des experiences differentes d’extraction de grammaire aussi bien
en ce qui concerne le nombre d’ exemples que le degre d’ambigu’1’te de la grammaire generee.

6.1 Extraction d’une grammaire de traduction

Les ressources utilisees pour extraire une grammaire de traduction (GT1) Anglais <—> Francais incluent
un dictionnaire bilingue de 77.016 entrees, un programme de segmentation en segments et un ensemble
de 50.000 exemples de traduction alignes du Canadian Hansard. Le dictionnaire couvre presque 3/4 des
mots anglais et francais du ET1 mais contient seulement a peu pres 1/3 des mots differents qui occurent
dans les deux textes. Le programme de segmentation (parser partiel) genere au moyen 11 et 13 segments

La traduction guidee par l’exemple

rsp. par exemple de traduction pour l’anglais et le francais. Plus que la moitie des segments differents
(63% et 50% rsp.) font partie des regles lexicales de la grammaire inverse extraite.

Anglais Francais Anglais Francais
Exemples de Traduction ET1 2 Dictionnaire bilingue (DIC) 2
#exemples 50.000 50.000 #entrees du dictionnaire 77.016 77.016
#mots 888.018 947.194 %couVert en ET1 74,77% 74,99%
#mots different 17.915 23.675 #mots different 7.688 7.714
#mots/exemples 17,76 18,94 %anchors (en ET1) 42,28% 43,53%
Grammaire de traduction extraite GT1 2 Segments generes par le parser partiel 2
#regles lexicales 113.810 #segments 581,599 650,136
#schemas de traduction 70.153 #segments differents 180,006 226,339

6.2 Traduction d’un texte test (TT)

Un texte test de 500 phrases est traduit de l’anglais Vers le francais avec les regles lexicales de GT1.
Alors que la couverture du dictionnaire bilingue (DIC) est plus grande que celle de la grammaire GT1,
la qualite de traduction, mesuree en WER1 et en BLEU (Papineni et al., 2002), est rnieux en traduction
GT1. Nous Voyons ici une correlation entre la qualite des traductions et la longueur des segments utilises
lors de la traduction.

Texte Test (TT) GT1 DIC
Anglais Francais %mots couverts 66,38% 66,99%
#exemples 500 500 BLEU 0,1421 0,0573
#mots 8.665 9.806 WER 68,89% 81,68%

#mots/exemples 17,33 19,61
longueur segments 2 2
#segments 966 146
#mots couverts 2,652 325
%mots couverts 30,61% 3,75%

6.3 Echelonnement de grammaires inverses et ambigués

Dans cette experience nous etudions (i) la capacite de l’algorithme d’utiliser un nombre different d’exemples
de traduction et (ii) l’effet de l’utilisation d’unites ambigues. Nous comparons trois grammaires dif-
ferentes generees a partir d’ensembles differents d’exemples de traduction , tous extraites du Canadian
Hansards.

ET0 ET1 ET2
#exemples de traduction 10.000 50.000 100.000
#mots anglais (En) 151.954 888.018 1.437.450
#mots francais (Fr) 163.113 947.194 1.503.196
#mots differents En 7.343 17.915 22.501
#mots differents Fr 9.528 23.675 29.559

Ces trois ensembles de reference sont utilises aﬁn de generer deux types de grammaires differentes 2
des grammaires inverses GT0, GT1 et GT2 (dont GT1 est egale a celle des sections 6.1 et 6.2) et des
grammaires ambigues GT“, GT‘1‘ et GT3. Les grammaires ambigues contiennent presque 20% plus de
regles de transfert lexical, alors que le nombre de mots differents reste a peu pres pareil dans les deux

1Les chiffres WER superieures et chiffres BLEU inferieures indiquent le meilleur resultat de traduction.

Michael Carl

types de grammaires. On obverve aussi que le nombre moyen de mots par regle augmente dans les
grammaires plus grandes.

Regles inverses de transfert lexical Regles ambigues de transfert lexical
GT0 GT1 GT2 GT3 GT‘1‘ GT3
#regleslexica1es 23.214 113.810 180.745 28.393 146.684 220.248

#mots Anglais (En) 203.426 1.223.260 1.856.392 222.473 1,355.331 2,030.390
#mots Francais (Fr) 220.273 1.314.197 2.007.322 244.615 1,491.559 2,219.455
#mots differents En 7.338 17.910 22.488 7.340 17.914 22.495
#mots differents Fr 9.520 23.659 29.523 9.521 23.670 29.542

En ce qui concerne la qualite des traductions produites, les deux types de grammaire produisent un taux
de WER et BLEU a peu pres egal. Ceci alors qu’un nombre considerable de segments de longueur
superieure a ete utilise pour produire la traduction avec des grammaires ambigues. Nous concluons que
les entrees ambigues representent pour la plupart des unites de traduction de qualite inferieure.

Qualite du texte test en grammaires inverses ... et qualite en grammaires ambigue

GT0 GT1 GT2 GT3 GT‘f GT3
WER 71,91% 68,89% 66,93% 71,88% 69,75% 67,22%
BLEU 0,1365 0,1421 0,1704 0,1398 0,1519 0,1706
#segments 3.581 4.405 4.685 3.599 4.314 4.659
#segments differents 992 1.279 1.387 1.055 1.343 1.450
#mots couverts 4.611 5.752 6.146 4.680 5.752 6.228
#segments longueur 2 2 767 966 1.050 816 1.032 1.108
#segments different 353 519 589 380 570 646
#mots couverts 1.952 2.652 2.863 2.170 2.844 3.062

6.4 Comparaison de GT, SMT et BabelFish

Dans cette experience nous comparons les resultats de traduction obtenus utilisant les grammaires GT0_2
avec un systeme statistique (Langlais, 2002) entraine sur les memes exemples de traduction ET0_2. Nous
Voyons que les resultats SMT sont inferieurs (toujours WER et BLEU) a ceux obtenus en GT. Le systeme
SMT3 qui a ete entraine sur un texte de 1,5 millions de exemples (15 fois plus que ET2) obtient les
meilleurs resultats.

score GTO GT1 GT2 SMTO SMT1 SMT2 SMT3 BabelF
BLEU 0,1365 0,1421 0,1704 0,1156 0,1231 0,1378 0,2061 0,1578
WER 71,91% 68,89% 66,93% 74,72% 73,54% 71,52% 61,66% 66,03%

Le systeme commercial BabelFish obtient des resultats inferieurs a ceux de SMT3 et GT2. Ceci est
surtout dﬁ aux particularites du texte traduit 2 alors que GT et SMT apprennent les traductions parti-
culieres, BabelFish n’a pas pu etre adapte a ce type de texte. Ainsi, la traduction 2 “the speaker <—>
le president” a ete realisee par GT et SMT alors que BabelFish genere la traduction “le haut-parleur”.
De meme 2 “some hon. members 2 oh , oh ! <—> des Voix 2 oh , oh !” est une traduction qui se Voit
frequemment en Canadian Hansards mais BabelFish produit “membres d’un certain hon 2 1’ OH OH”.
Alors que ce sont des traductions possibles correctes dans d’autres contextes, elles sont erronees quanta
la traduction du Canadian Hansards.

La traduction guidee par l’exemple

6.5 Integration SMT et GT

Finalement nous essayons d’integrer les grammaires GT et le systeme statistique suivant (Langlais, 2002)
2 quand la grammaire GT contient une entree egale a une sequence de mots dans la phrase a traduire, le
systeme SMT est force d’integrer la traduction proposee par GT dans sa sortie. La qualite produite du
systeme hybride est meilleure quant aux grammaires inverses (SMT0_2-GT0_2); pour l’integration des
grammaires ambigues dans le systeme statistique (SMTg_2-GT3_2) une amelioration des resultats n’a
pas pu etre observe.

SMT0-GT0 SMT1-GT1 SMT2-GT2 SMTO-GT3 SMT1-GT‘1‘ SMT2-GT3
BLEU 0.1495 0.1684 0.1789 0.1406 0.1541 0.1654
WER 71.19% 70.32% 68.94% 72.70% 72.45% 71.41%

7 Resume et conclusion

Dans cet article je presente d’ approches en traduction automatique. J e fais la distinction entre la traduc-
tion par regles (RBMT), la traduction statistique (SMT) et la traduction guidee par l’exemple (EBMT).
Les ressources necessaires en RBMT sont obtenues par l’inspection d’un (ou d’un groupe de) linguiste(s),
tandis que les approches EBMT et SMT extraient les connaissances de traduction a partir des textes
bilingues alignes. Au contraste a la SMT, la ‘phrase’ est l’unite de traduction ideale en EBMT. Je
presente des systemes EBMT qui extraient et acquirent ces unites en terrnes de temps d’execution et en
terrnes de temps de compilation.

En suite je discute plus en detail le systeme EDGAR. A partir des exemples de traduction, EDGAR
produit la traduction des phrases nouvelles par analogie de maniere compositionnelle et isomorphe. J e
presente un algorithme pour extraire une grammaire de traduction a partir des exemples de traduction.
L’article conclu avec la description d’une serie de experiences en traduction guidee par l’exemple. De
ces experiences nous concluons que 2

0 La couverture de la grammaire est fonction du nombre des exemples de reference.
0 Les grammaires produisent une meilleure qualite de traduction que la traduction SMT
(taille identique de reference)
0 Les regles ambigues n’ameliorent pas la qualite de la traduction.
o L’ integration des techniques EBMT et SMT ameliore les resultats de la traduction.

References

Al-Adhaileh, M. H. & Tang E. K. 1999. Example-Based Machine Translation Based on the Syn-
chronous SSTC Annotation Schema. Machine Translation Summit VII, Singapore, 244-249.

Andriamanankasina, T., K. Araki, & K, Tochinai. 2003. Ebmt of pos-tagged sentences with inductive
learning. In ( Carl & Way, 2003).

Andriamanankasina, T., K. Araki & K. Tochinai. 1999. Example-Based Machine Translation of Part-
Of-Speech Tagged Sentences by Recursive Division. Machine Translation Summit VII, Singapore,
509-517.

Brown, P. F., J. Cocke, S. A. Della Pietra, V. J. Della Pietra, F. Jelinek, J . D. Lafferty, R. L. Mercer
& P. S. Roossin. 1990. A Statistical Approach to Machine Translation. Computational Linguistics 16,
79-85.

Brown, R. D. 1996. Example-Based Machine Translation in the Pangloss System. Coling (1996),
169-174.

Michael Carl

Brown, R. D. 1997. Automated Dictionary Extraction for “Knowledge-Free” Example-Based Transla-
tion. TMI (1997), 111-118.

Brown, R. D. 1999. Adding Linguistic Knowledge to a Lexical Example-based Translation System.
TMI (1999), 22-32.

Carl, M. & A. Way, editors. 2003. Recent Advances in Example-Based Machine Translation. Kluwer,
Academic Publisher, Boston/Dordrecht/London. in press.

Carl, M. 2003. Ir1ducing translation grammars from bracketed alignments. In ( Carl & Way, 2003).

Carl, M. & Langlais, P. 2003. Tuning general purpose translation knowledge to a sublanguage. In
Proceedings of EAM T/CLAW.

Carl, M. 1999. Inducing Translation Templates for Example-Based Machine Translation. Machine
Translation Summit VII, Singapore, 250-258.

Carl, M. & Schmidt-VV1gger, A.. 1998. Shallow Postmorphological Processing with KURD. In Pro-
ceedings of NeMLaP3/CoNLL98, pages 257-265, Sydney.

Cicekli, I. & H.A. Gﬁvenir. 2003. Learning Translation Templates from Bilingual Translation Exam-
ples. In (Carl & Way, 2003).

Cicekli, I. & H. A. Gﬁvenir. 1996. Learning Translation Rules From A Bilingual Corpus. NeMLaP-2:
Proceedings of the Second International Conference on New Methods in Language Processing, Ankara,
Turkey, 90-97.

Collins, B. & H. Somers. 2003. EBMT Seen as Case-based Reasoning. In ( Carl & Way, 2003).

Collins, B. 1998. Example-Based Machine Translation: An Adaptation-Guided Retrieval Approach.
PhD thesis, Trinity College, Dublin.

Collins, B. & P. Cunningham. 1997. Adaptation Guided Retrieval: Approaching EBMT with Caution.
TMI (1997), 119-126.

Cranias, L., H. Papageorgiou & S. Piperidis. 1994. A Matching Technique in Example-Based Machine
Translation. Coling (1994), 100-104.

Furuse, O. & H. Iida. 1992. An Example-Based Method for Transfer-Driven Machine Translation. TMI
(1992), 139-150.

Furuse, O. & H. Iida. 1994. Constituent Boundary Parsing for Example-Based Machine Translation.
Coling (1994), 105-111.

Gﬁvenir, H. A. & I. Cicekli. 1998. Learning Translation Templates from Examples. Information Systems
23, 353-363.

Kaji, H., Y. Kida & Y. Morimoto. 1992. Learning Translation Templates from Bilingual Text. Coling
(1992), 672-678.

Langlais, P. 2002. Ressources terminologiques et traduction probabiliste: premiers pas positifs Vers un
systeme adaptatif. In TALN-2002.

Matsumoto, Y. & M. Kitamura. 1995. Acquisition of Translation Rules from Parallel Corpora. In R.
MitkoV & N. Nicolov (eds) Recent Advances in Natural Language Processing: Selected Papers from
RANLP’95, Amsterdam: John Benjamins, 405-416.

McTait, K. & A. Trujillo. 1999. A Language-Neutral Sparse-Data Algorithm for Extracting Translation
Patterns. TMI (1999), 98-108.

La traduction guidée par l’exemple

Menezes, A. & S.D. Richardson. 2003. A best-ﬁrst alignment algorithm for automatic extraction of
transfer mappings from bilingual corpora. In ( Carl & Way, 2003 ).

Meyers, A., R. Yangarber, R. Grishman, C. Macleod & A. Moreno-Sandeval. 1998. Deriving Transfer
Rules from Dorninance-Preserving Alignments. Coling-ACL (1998), 843-847.

Nagao, M. 1984. A Framework of a Mechanical Translation between Japanese and English by Analogy
Principle. In A. Elithorn and R. Banerji (eds) Artificial and Human Intelligence, 173-180, Amsterdam:
North-Holland.

Nirenburg, S., S. Beale & C. Domashnev. 1994. A Full-Text Experiment in Example-Based Machine
Translation. International Conference on New Methods in Language Processing (NeMLaP), Manch-
ester, England, 78-87.

Papineni, K., S. Roukos, T. Ward, & W.-J. Zhu. 2002. Bleu: a method for automatic evaluation of
machine translation. In Proceedings of the 40th Annual Meeting of the ACL, Philadelphia, Pennsylvania,
USA, 311-318.

Richardson, S.D., W.B. Dolan, A. Menezes & J. Pinkham. 2001. Achieving Commercial-quality Trans-
lation with Example-based Methods. MT Summit VIII: Machine Translation in the Information Age,
Santiago de Compostela, Spain, 293-298.

Sato, S. & M. Nagao. 1990. Toward Memory-Based Translation. Coling (1990), Vol. 3, 247-252.

Somers, H. 1999. Review Article: Example-based Machine Translation. Machine Translation,
14(2):113-157.

Somers, H. 2003. An Overview of EBMT. In ( Carl & Way, 2003).

Sumita, E. & H. Iida. 1991. Experiments and Prospects of Example-Based Machine Translation. 29th
Annual Meeting of the Association for Computational Linguistics, Berkeley, California, 185-192.

Sumita, E., H. Iida & H. Kohyama. 1990. Translating with Examples: A New Approach to Machine
Translation. TMI (1990), 203-212.

Vauquois, B. 1968. A Survey of Formal Grammars and Algorithms for Recognition and Transformation
in Machine Translation. IFIP Congress-68, Edinburgh, 254-260; reprinted in Ch. Boitet (ed.) Bernard
Vauquois et la TAO: Vingt-cinq Ans de Traduction Automatique —Analectes, 201-213, Grenoble (1988):
Association Champollion.

Veale, T. & A. Way. 1997. Gaijin: A Bootstrapping Approach to Example-Based Machine Translation.
International Conference, Recent Advances in Natural Language Processing, Tzigov Chark, Bulgaria,
239-244.

Watanabe, H. 1992. A Similarity-Driven Transfer System. Coling (1992), 770-776.

Watanabe, H. 1993. A Method for Extracting Translation Patterns from Translation Examples. TMI
(1993), 292-301.

Watanabe, H. & K. Takeda. 1998. A Pattern-Based Machine Translation System Extended by Exarnple-
Based Processing. Coling-ACL (1998), 1369-1373.

Way, A. 1999. A Hybrid Architecture for Robust MT using LFG-DOP. Journal of Experimental and
Theoretical Artificial Intelligence 11, 441-471.

