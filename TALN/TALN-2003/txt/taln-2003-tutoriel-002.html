<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Construction d&#146;ontologies &#224; partir de textes</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2003, Batz-sur-Mer, 11-14 juin 2003 
</p>
<p>Construction d&#146;ontologies &#224; partir de textes 
</p>
<p>Didier Bourigault (1) et Nathalie Aussenac-Gilles  
</p>
<p>(1) ERSS &#150; CNRS &amp; Universit&#233; Toulouse le Mirail 
5, all&#233;es Antonio Machado 
31 058 Toulouse Cedex 1 
</p>
<p>didier.bourigault@univ-tlse2.fr 
(2) IRIT &#150; Universit&#233; Paul Sabatier 
</p>
<p>118, route de Narbonne, 31062 Toulouse Cedex 4 
aussenac@irit.fr 
</p>
<p>R&#233;sum&#233; &#150; Abstract 
</p>
<p>Cet article constitue le support d&#146;un cours pr&#233;sent&#233; lors de la conf&#233;rence TALN 2003. Il 
d&#233;fend la place du Traitement Automatique des Langues comme discipline cl&#233; pour le 
d&#233;veloppement de ressources termino-ontologiques &#224; partir de textes. Les contraintes et 
enjeux de ce processus sont identifi&#233;s, en soulignant l&#146;importance de consid&#233;rer cette t&#226;che 
comme un processus supervis&#233; par un analyste. Sont pr&#233;sent&#233;s un certain nombre d&#146;outils 
logiciels et m&#233;thodologiques venant de plusieurs disciplines comme le TAL et l&#146;ing&#233;nierie 
des connaissances qui peuvent aider l&#146;analyste dans sa t&#226;che. Divers retours d&#146;exp&#233;rience sont 
pr&#233;sent&#233;s. 
</p>
<p>This paper gathers the notes of a tutorial. We advocate in favour of the role of Natural 
Language Processing as a key discipline for the development of terminological and 
ontological resources from texts. The constraints and challenges of this process are identified, 
and lead to underline this task as a supervised processes carried out by an analyst. We present 
several software and methodological tools from NLP and knowledge engineering that can be 
use for to assist the analyst. Our suggestion rely on various experience feed-back. 
</p>
<p>Keywords &#150; Mots Cl&#233;s 
</p>
<p>Extraction de termes, extraction de relations, Terminologie, Ontologies, Ing&#233;nierie des 
connaissances, m&#233;thode, mod&#233;lisation de connaissances, interdisciplinarit&#233;. 
Term extraction, relation extraction, Terminology, ontologies, Knowledge Engineering, 
method, knowledge modelling, crossdisciplinarity. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault et N. Aussenac-Gilles 
</p>
<p>1 Introduction 
</p>
<p>Dans cet article, nous d&#233;veloppons les grandes lignes du cours pr&#233;sent&#233; lors de la dixi&#232;me 
conf&#233;rence Traitement Automatique des Langues le 14 juin 2003 &#224; Batz-sur-Mer. Ce cours 
fait suite aux tutoriels donn&#233;s en juin 2000 lors de la conf&#233;rence Ing&#233;nierie des connaissances 
(IC 2000, Toulouse) et en janvier 2002 lors de la conf&#233;rence Reconnaissance des Formes et 
Intelligence Artificielle (RFIA 2002, Angers), au cours desquels nous avons eu l&#146;occasion de 
pr&#233;senter les outils d&#233;velopp&#233;s en Traitement Automatique des Langues (TAL) aux membres 
de la communaut&#233; d&#146;Ing&#233;nierie des Connaissances (IC). L&#146;objectif du pr&#233;sent cours est, 
sym&#233;triquement, de pr&#233;senter aux chercheurs de la communaut&#233; Traitement Automatique des 
Langues les enjeux, pratiques et th&#233;oriques, l&#146;utilisation de certains outils de TAL dans une 
perspective d&#146;ing&#233;nierie des connaissances, ceci pour encourager les travaux 
interdisciplinaires autour de la probl&#233;matique de construction de ressources termino-
ontologiques (RTO)1, &#224; partir de textes. Cette probl&#233;matique constitue en effet un nouvel 
enjeu important aussi bien pour le Traitement Automatique des Langues que pour l&#146;Ing&#233;nierie 
des Connaissances. Les syst&#232;mes de traitement de l&#146;information qui doivent fonctionner dans 
des domaines de connaissances sp&#233;cialis&#233;s ne peuvent &#234;tre efficaces que s&#146;ils s&#146;appuient sur 
des ressources termino-ontologiques, construites pour le domaine et l&#146;application concern&#233;s. 
Les recherches et r&#233;alisations en TAL et en IC doivent &#234;tre men&#233;es de fa&#231;on 
pluridisciplinaire, pour, d&#146;une part, d&#233;velopper les outils de TAL pertinents pour la t&#226;che de 
construction de RTO &#224; partir de textes, et, d&#146;autre part, &#233;laborer des m&#233;thodes d&#146;acquisition 
des connaissances &#224; partir de textes qui sp&#233;cifient comment utiliser les outils de TAL et les 
environnements de mod&#233;lisation des connaissances dans le contexte de la construction de 
RTO. Au del&#224;, mais cet aspect sera moins d&#233;velopp&#233; dans ce cours, il s&#146;agit de s&#146;interroger 
sur le statut de la langue &#233;crite comme r&#233;v&#233;lateur de connaissances, d&#232;s lors que l&#146;on veut y 
acc&#233;der au moyens d&#146;outils informatiques. 
</p>
<p>2 Des ressources &#224; construire vari&#233;es, des outils g&#233;n&#233;riques 
</p>
<p>2.1 RTO et syst&#232;mes de traitements de l&#146;information 
</p>
<p>A la suite &#224; l&#146;utilisation g&#233;n&#233;ralis&#233;e des outils de bureautique, &#224; l&#146;internationalisation des 
&#233;changes et au d&#233;veloppement d'Internet, la production de documents sous forme &#233;lectronique 
s&#146;acc&#233;l&#232;re sans cesse. Or pour produire, diffuser, rechercher, exploiter et traduire ces 
documents, les syst&#232;mes de gestion de l&#146;information ont besoin de ressources termino-
ontologiques, qui d&#233;crivent les termes et les concepts du domaine, selon un mode propre au 
type de traitement effectu&#233; par le syst&#232;me. La gamme des ressources &#224; base terminologique et 
ontologique est aussi large que celle des syst&#232;mes de traitement de l&#146;information utilis&#233;s dans 
les entreprises et dans les institutions : 
</p>
<p>&#8226; bases de donn&#233;es terminologiques multilingues classiques pour l'aide &#224; la traduction, 
</p>
<p>                                                 
1 Dans ce cours, nous nous efforcerons d&#146;utiliser syst&#233;matiquement cette expression plut&#244;t que le terme tr&#232;s en 
</p>
<p>vogue d&#146;ontologie, adopt&#233; dans le titre du cours pour des raisons de concision. Ce choix terminologique sera 
justifi&#233; plus loin dans cet article. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Construction d&#146;ontologies &#224; partir de textes 
</p>
<p>&#8226; thesaurus pour les syst&#232;mes d'indexation automatique ou assist&#233;e, index 
hypertextuels pour les documentations techniques, 
</p>
<p>&#8226; terminologies de r&#233;f&#233;rence pour les syst&#232;mes d&#146;aide &#224; la r&#233;daction, 
</p>
<p>&#8226; r&#233;f&#233;rentiels terminologiques pour les syst&#232;mes de gestion de donn&#233;es techniques, 
</p>
<p>&#8226; ontologies pour les m&#233;moires d'entreprise, les syst&#232;mes d&#146;aide &#224; la d&#233;cision ou les 
syst&#232;mes d&#146;extraction d&#146;information, 
</p>
<p>&#8226; ontologies pour le Web s&#233;mantique, 
</p>
<p>&#8226; glossaires de r&#233;f&#233;rence, liste de termes pour les outils de communication interne et 
externe, 
</p>
<p>&#8226; etc. 
</p>
<p>Du c&#244;t&#233; de la recherche, chacune de ces ressources est prise en charge par une discipline 
diff&#233;rente. La terminologie focalise ses recherches, depuis l&#146;av&#232;nement des outils de 
bureautique, sur les bases de donn&#233;es terminologiques destin&#233;e aux traducteurs humains. Les 
sciences de l&#146;information et de la documentation concentrent leurs r&#233;flexions sur les thesaurus 
et langages de classification ou langages documentaires, exploit&#233;s par les documentalistes 
pour indexer et classer les &#233;l&#233;ments de fonds documentaire. En informatique, le domaine de la 
recherche d&#146;information (RI) s&#146;int&#233;resse &#224; des thesaurus d&#146;un type diff&#233;rent, con&#231;us pour 
limiter le bruit et augmenter le rappel des outils informatiques de recherche d&#146;information. 
L&#146;intelligence Artificielle et l&#146;Ing&#233;nierie des Connaissances travaillent sur les ontologies 
formelles qui constituent le c&#156;ur des syst&#232;mes &#224; base de connaissances. Ces diff&#233;rentes 
disciplines d&#233;veloppent de fa&#231;on relativement autonome et cloisonn&#233;e des recherches 
sp&#233;cifiques sur ces diff&#233;rents types de ressources. Or, sous la pression des besoins et des 
applications, elles sont amen&#233;es &#224; consid&#233;rer que, pour des raisons de pertinence et 
d&#146;efficacit&#233;, les ressources lexicales et/ou conceptuelles qu&#146;elles doivent construire et 
exploiter peuvent ou doivent &#234;tre construites &#224; partir de sources textuelles. Elles sont donc 
naturellement amen&#233;es &#224; proc&#233;der &#224; un rapprochement interdisciplinaire, dont le Traitement 
Automatique des Langues peut &#234;tre le catalyseur, en tant que pourvoyeur de m&#233;thodes et 
outils de construction de RTO &#224; partir de textes. 
</p>
<p>En terminologie, au cours des ann&#233;es 80, un rapprochement avec l&#146;informatique s&#146;est op&#233;r&#233; 
avec le d&#233;veloppement de la microinformatique. On s&#146;est int&#233;ress&#233; &#224; la conception de bases de 
donn&#233;es terminologiques susceptibles d&#146;aider les traducteurs professionnels dans les t&#226;ches de 
gestion et d&#146;exploitation de lexiques multilingues. Les r&#233;flexions ont port&#233; essentiellement sur 
le format de la fiche terminologique : &#224; l&#146;aide de quels champs d&#233;crire un terme dans une base 
de donn&#233;es qui sera utilis&#233;e par un traducteur humain ? Depuis la fin des ann&#233;es 90, la 
terminologie classique voit les bases th&#233;oriques de sa doctrine ainsi que ses rapports avec 
l&#146;informatique &#233;branl&#233;s par le renouvellement de la pratique terminologique que suscite le 
d&#233;veloppement des nouvelles applications de la terminologie. La multiplication des types de 
ressources terminologiques met &#224; mal le principe th&#233;orique de l&#146;unicit&#233; et de la fixit&#233; d&#146;une 
terminologie pour un domaine donn&#233;, ainsi que celui de la base de donn&#233;e terminologique 
comme seul type de ressource informatique pour la terminologie. Depuis le milieu des ann&#233;es 
90, un courant de recherche se d&#233;veloppe autour de la terminologie textuelle, qui pr&#233;conise la </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault et N. Aussenac-Gilles 
</p>
<p>construction de terminologies &#224; partir de textes, et qui sollicite le TAL pour des m&#233;thodes et 
outils d&#146;analyse de corpus (Slodzian, 2000). En Intelligence Artificielle, une &#233;volution 
importante du domaine s&#146;est produite de fa&#231;on concomitante et parall&#232;le &#224; ce renouvellement 
th&#233;orique et m&#233;thodologique en terminologie. L&#146;&#233;chec relatif des r&#233;alisations en IA a conduit 
&#224; remettre en cause l&#146;hypoth&#232;se qui &#233;tait &#224; la base du d&#233;veloppement des syst&#232;mes experts, 
selon laquelle l&#146;expert d&#146;un domaine serait le d&#233;positaire d&#146;un syst&#232;me conceptuel qu&#146;il 
suffirait de mettre au jour, en interrogeant l&#146;expert ou en l&#146;observant au travail. L&#146;Ing&#233;nierie 
des Connaissances (IC) s'est alors impos&#233;e comme une direction de recherche en IA, avec 
pour ambition de r&#233;soudre les difficult&#233;s soulev&#233;es par la construction des syst&#232;mes experts, 
et de proposer des concepts, m&#233;thodes et techniques permettant d'acqu&#233;rir et de mod&#233;liser les 
connaissances dans des domaines se formalisant peu ou pas. L&#146;IC s&#146;int&#233;resse en particulier au 
processus de construction d&#146;ontologies formelles pour les syst&#232;mes &#224; base de connaissances 
ou pour l&#146;interop&#233;rabilit&#233; entre syst&#232;mes dans le Web s&#233;mantique. Elle pr&#233;conise elle aussi 
que, dans certains contextes, ce processus s&#146;appuie sur l&#146;analyse de corpus de textes. Elle 
sollicite le TAL pour des outils rendant possible et efficace la t&#226;che de construction 
d&#146;ontologies &#224; partir de textes. 
</p>
<p>Des sollicitations analogues &#233;manent aussi d&#146;autres disciplines, comme les sciences de 
l&#146;information et de la documentation. Au sein m&#234;me du domaine du Traitement Automatique 
des Langues, certaines applications, comme la traduction automatique, la recherche 
d&#146;information ou l&#146;extraction d&#146;information, ont besoin de ressources termino-ontologiques, 
Le TAL est donc ainsi doublement concern&#233; par la probl&#233;matique de la construction de RTO 
&#224; partir de textes, en tant que consommateur de ressources et en tant que pourvoyeur d&#146;outils 
pour les construire. Le TAL se trouve donc &#224; la convergence de demandes &#233;manant de 
disciplines diverses et concernant la mise &#224; disposition d&#146;outils et de m&#233;thodes d&#146;analyse de 
textes pour la construction de ressources termino-ontologiques. Il peut adopter ainsi une 
position d&#233;cal&#233;e par rapport &#224; chacune de ces disciplines et saisir, gr&#226;ce &#224; cet angle de vue 
privil&#233;gi&#233;, les proximit&#233;s et les diff&#233;rences entre des diff&#233;rents types de ressources, avec une 
objectivit&#233; et un recul, que ne peuvent avoir ces disciplines seules. En ce sens, le TAL peut 
favoriser le d&#233;cloisonnement de ces disciplines et encourager le rapprochement 
pluridisciplinaire, autour d&#146;une r&#233;flexion sur la notion de ressource termino-ontologique. 
Cette r&#233;flexion doit permettre de mettre en &#233;vidence is les ressemblances et les particularit&#233;s 
de ces diff&#233;rents types de ressources, de fa&#231;on &#224; sp&#233;cifier les types d&#146;outils d&#146;analyse 
relativement g&#233;n&#233;riques et utilisables pour une large gamme de ressources et de contextes 
d&#146;exploitation. 
</p>
<p>2.2 Ontologie, terminologie, thesaurus, &#133; 
</p>
<p>Le TAL se trouve donc face &#224; des disciplines chacune pr&#233;occup&#233;e par le probl&#232;me de la 
construction de ressources termino-ontologiques de types diff&#233;rents, puisque destin&#233;es &#224; des 
usages diff&#233;rents. Dans ce contexte de sollicitations diversifi&#233;es, il est non pertinent pour le 
TAL de se lancer dans une r&#233;flexion th&#233;orique visant &#224; caract&#233;riser formellement et de fa&#231;on 
g&#233;n&#233;rique ce qu&#146;est une ressource termino-ontologique. L&#146;approche consiste plut&#244;t &#224; mettre 
en perspective les diff&#233;rentes d&#233;finitions travaill&#233;es par ces disciplines. L&#146;objectif est de saisir 
en quoi les caract&#233;ristiques sp&#233;cifiques de ces diff&#233;rents types de ressources d&#233;pendent des 
contextes applicatifs, pour finalement identifier ce qui diff&#233;rencie et, surtout, ce qui rapproche 
ces diff&#233;rents types de ressources. Il est alors possible de sp&#233;cifier les diff&#233;rents types d&#146;outils 
g&#233;n&#233;riques de TAL dont il convient de promouvoir le d&#233;veloppement.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Construction d&#146;ontologies &#224; partir de textes 
</p>
<p>Les r&#233;flexions sur les ontologies se sont d&#146;abord d&#233;velopp&#233;es en informatique (intelligence 
artificielle, sciences de la gestion), dans le cadre de travaux qui avaient comme objectif final 
la sp&#233;cification de syst&#232;mes informatiques, avec plus particuli&#232;rement &#224; l&#146;origine la volont&#233; 
de pouvoir r&#233;utiliser des composants g&#233;n&#233;riques d&#146;une application &#224; une autre, ou encore de 
favoriser la communication entre diff&#233;rentes applications. C&#146;est le cas encore des travaux 
men&#233;s en Ing&#233;nierie des Connaissances ou en repr&#233;sentation des connaissances autour des 
Syst&#232;mes &#224; Base de Connaissances et du Web s&#233;mantique. Dans ce contexte, une ontologie 
est une conceptualisation des objets du domaine selon un certain point de vue, impos&#233; par 
l&#146;application. Elle est con&#231;ue comme un ensemble de concepts, organis&#233;s &#224; l&#146;aide de relations 
structurantes, dont la principale, celle avec laquelle est construite l&#146;ossature de l&#146;ontologie, est 
la relation is-a. Cette conceptualisation est &#233;crite dans un langage de repr&#233;sentation des 
connaissances, qui propose des &#171; services inf&#233;rentiels &#187; (classification de concept, capacit&#233; de 
construire des concepts d&#233;finis &#224; partir de concepts primitifs, etc.). A l&#146;oppos&#233;, pour les 
thesaurus, un haut degr&#233; de formalisation et des services d&#146;inf&#233;rence ne sont pas n&#233;cessaires. 
Les thesaurus sont organis&#233;s avec les classiques relations d&#146;hyperonymie et de synonymie, 
auxquelles s&#146;ajoute la relation voir aussi. N&#233;anmoins, il faut bien distinguer les thesaurus 
selon qu&#146;ils sont exploit&#233;s par des indexeurs et documentalistes humains, ou par des syst&#232;mes 
informatiques. Au cours d&#146;une t&#226;che d&#146;indexation, pour choisir les meilleurs descripteurs, les 
agents humains proc&#232;dent &#224; des interpr&#233;tations et des inf&#233;rences, qui s&#146;appuient sur leur 
connaissance du domaine et des utilisateurs, connaissances implicites qui ne sont pas 
consign&#233;es dans le thesaurus. Les syst&#232;mes d&#146;indexation automatique ne peuvent approcher 
de tels comportements intelligents qu&#146;&#224; condition que ces connaissances soient autant que 
possible explicit&#233;es et repr&#233;sent&#233;es dans les thesaurus, qui tendent ainsi &#224; se rapprocher des 
ontologies de l&#146;Ing&#233;nierie des Connaissances.  
</p>
<p>Le principal crit&#232;re de discrimination entre RTO est le type de donn&#233;es d&#146;entr&#233;e du syst&#232;me 
de traitement de l&#146;information qui exploite la RTO. Selon que ces syst&#232;mes traitent de 
l&#146;information de nature textuelle ou non, les caract&#233;ristiques des RTO vont &#234;tre relativement 
diff&#233;rentes. Si le syst&#232;me analyse des entr&#233;e en langue naturelle, la premi&#232;re exigence est 
qu&#146;il soit capable de reconna&#238;tre sous des formes linguistiques diff&#233;rentes des occurrences de 
la m&#234;me unit&#233; et, inversement, de reconna&#238;tre des unit&#233;s diff&#233;rentes sous une m&#234;me forme. Il 
doit pouvoir g&#233;rer, aussi bien que l&#146;application l&#146;exige, les ph&#233;nom&#232;nes de synonymie, de 
paraphrase, de variabilit&#233; linguistique aux niveaux morphologique ou syntaxique ou lexical, 
pr&#233;sents en masse dans les textes en langues naturelles (Zweigenbaum, 1999). Ceci n&#146;est 
possible que si des r&#232;gles de correspondance sont r&#233;pertori&#233;es dans la RTO que va exploiter le 
syst&#232;me. Une des t&#226;ches de l&#146;analyste qui construit la RTO est donc de d&#233;crire des liens entre 
des motifs textuels et des unit&#233;s de traitement, unit&#233;s qui seront ensuite exploit&#233;es pour 
effectuer les traitements assign&#233;s aux syst&#232;me (classification de document, expansion de 
requ&#234;te, extraction d&#146;information, etc.).  Quand les motifs textuels ont la structure de noms ou 
syntagmes nominaux, ils sont naturellement d&#233;sign&#233;s sous le nom de termes. Les unit&#233;s de 
traitement sont les concepts. C&#146;est la raison pour laquelle nous parlons de ressources termino-
ontologiques. De ce point vue, le concept peut &#234;tre vu comme une classe d&#146;&#233;quivalence de 
termes, ou plus g&#233;n&#233;ralement de motifs textuels, modulo les contraintes de l&#146;application 
cible : deux motifs sont jug&#233;s &#233;quivalents, ou synonymes, en fonction de traitement que doit 
effectu&#233; par le syst&#232;me. Le concept est un mode de regroupement de termes. Ceci n&#146;est pas 
incompatible avec sa fonction de regroupement d&#146;objets (informatiques) du domaine qui lui 
est assign&#233;e dans les ontologies de l&#146;Ing&#233;nierie des Connaissances. Le syst&#232;me de traitement 
de l&#146;information dispose donc pour traiter de la synonymie de r&#232;gles d&#146;appariement qui </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault et N. Aussenac-Gilles 
</p>
<p>exploitent les liens termes/concepts pr&#233;sents dans la RTO. Il dispose de r&#232;gles analogues pour 
le traitement de la polys&#233;mie, de l&#146;homographie.  
</p>
<p>Si l&#146;application cible n&#146;est pas une application textuelle, l&#146;analyse des textes n&#146;en est pas 
moins fondamentale. M&#234;me s&#146;il s&#146;agit de construire une ontologie pour un syst&#232;me 
informatique, dont les donn&#233;es d&#146;entr&#233;e ne seront pas textuelles, mais num&#233;riques, par 
exemple des r&#233;sultats de mesures de capteur, l&#146;analyse de textes et la description du 
vocabulaire sont n&#233;anmoins primordiales pour la construction de l&#146;ontologie. En effet, 
l&#146;analyse des textes sert d&#146;indicateur &#224; l&#146;organisation d&#146;un syst&#232;me conceptuel et donc &#224; la 
mise en relation de concepts, et, par ailleurs, le choix des &#233;tiquettes de concepts doit &#234;tre 
judicieux pour assurer l&#146;interpr&#233;tabilit&#233; et l&#146;intelligibilit&#233; du syst&#232;me, ainsi que la 
maintenance de l&#146;ontologie (Bachimont, 2000). 
</p>
<p>Cette position constructiviste et fonctionnelle des notions de terme et de concept s&#146;&#233;loigne 
quelque peu des positions r&#233;f&#233;rentialistes et fixistes - le terme comme &#233;tiquette de concept -, 
qui sont classiquement adopt&#233;es dans les domaines de l&#146;Intelligence Artificielle, de la 
terminologie ou du Traitement Automatique des Langues, disciplines qui ont longtemps &#233;t&#233; 
largement influenc&#233;es par une s&#233;miotique du signe fond&#233;e sur la triade terme/concept/r&#233;f&#233;rent 
(Rastier, 1991). La conception classique pose que le terme existe en tant que repr&#233;sentant 
linguistique d&#146;un concept faisant partie d&#146;un syst&#232;me conceptuel unique et stable caract&#233;risant 
a priori le domaine. Mais le constat de la variabilit&#233; des terminologies s&#146;impose : &#233;tant donn&#233; 
un domaine d&#146;activit&#233;, il n&#146;y a pas une terminologie, qui repr&#233;senterait le savoir sur le 
domaine, mais autant de ressources termino-ontologiques que d&#146;applications dans lesquelles 
ces ressources sont utilis&#233;es. L&#146;ensemble de ces constats empiriques appelle &#224; un 
renouvellement th&#233;orique de la terminologie (Rastier, 1995) (Slodzian, 2000). A rebours de la 
conception fixiste et apriorique, on peut voir le terme et le concept comme le r&#233;sultat d&#146;un 
processus d&#146;analyse termino-conceptuelle. Un mot ou une unit&#233; complexe n&#146;acquiert le statut 
de terme que par d&#233;cision. Dans le cas qui nous concerne ici, cette d&#233;cision est prise par 
l&#146;analyste en charge de l&#146;&#233;laboration d&#146;une RTO pour une application bien identifi&#233;e. Celui-ci 
d&#233;finit son propre r&#233;f&#233;rentiel de d&#233;cision. Il proc&#232;de &#224; un travail de construction d&#146;une 
ressource termino-ontologique pour une application dans le domaine, et non de d&#233;couverte de 
la terminologie du domaine. Ce travail est guid&#233; par une double contrainte de pertinence : 
</p>
<p>&#8226; pertinence vis-&#224;-vis du corpus. Il s&#146;agit de retenir et de d&#233;crire des structures 
lexicales qui pr&#233;sentent des caract&#233;ristiques &#224; la fois sp&#233;cifiques au domaine et 
stables dans le corpus ; 
</p>
<p>&#8226; pertinence vis-&#224;-vis de l&#146;application vis&#233;e. Les unit&#233;s finalement retenues doivent 
l&#146;&#234;tre en fonction de leur utilit&#233; dans l&#146;application vis&#233;e, qui s&#146;exprime en termes 
d&#146;&#233;conomie, de coh&#233;rence interne et d&#146;efficacit&#233;. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Construction d&#146;ontologies &#224; partir de textes 
</p>
<p>3 El&#233;ments m&#233;thodologiques 
</p>
<p>3.1 Des outils d&#146;aide 
</p>
<p>Devant la masse des donn&#233;es &#224; analyser et &#233;tant donn&#233;s les d&#233;lais de r&#233;alisation impos&#233;s, les 
disciplines concern&#233;es par la construction de RTO se tournent vers le TAL pour des outils 
informatiques d&#146;analyse de corpus.  
</p>
<p>Les travaux de conception d&#146;outils de TAL pour la construction de RTO doivent d&#233;velopper 
une r&#233;flexion m&#233;thodologique sur l&#146;activit&#233; de construction elle-m&#234;me. Doit s&#146;imposer 
d&#146;embl&#233;e le postulat que cette activit&#233; est avant tout une activit&#233; humaine, intellectuelle, 
men&#233;e par un individu que nous nommerons ici &#171; analyste &#187;. Dans un projet de construction 
de RTO, les contraintes sont multiples et multiformes, les choix &#224; effectuer nombreux et de 
types divers, et ces choix comme ces contraintes, de type heuristique, sont difficilement 
explicitables. ont jusqu&#146;ici &#233;t&#233; peu explicit&#233;s. Par cons&#233;quent cette t&#226;che ne peut en rien se 
limiter &#224; l&#146;&#233;laboration automatique d&#146;un r&#233;seau de termes et de concepts par quelque outil que 
ce soit. Nous d&#233;fendons que la contribution du TAL doit &#234;tre la fourniture d&#146;outils d&#146;aide pour 
l&#146;analyste. Les recherches doivent se d&#233;velopper dans le paradigme de la coop&#233;ration, et non 
celui de l&#146;automatisation, m&#234;me partielle, et il faut assumer, dans une perspective 
ing&#233;nierique, le r&#244;le central de l&#146;analyste. Autant les outils de TAL consommateurs de 
ressources termino-ontologiques doivent et peuvent approcher l&#146;automaticit&#233;, autant les outils 
de TAL d&#146;aide &#224; la construction de RTO exigent l&#146;intervention d&#146;un agent humain. 
</p>
<p>Au-del&#224; des difficult&#233;s techniques traditionnellement li&#233;es au d&#233;veloppement d&#146;outils en 
TAL, il existe une tension particuli&#232;re propre au d&#233;veloppement d&#146;outils d&#146;aide &#224; la 
construction de RTO : il s&#146;agit de concilier le caract&#232;re ad hoc des ressources &#224; construire 
avec les outils, avec les contraintes de g&#233;n&#233;ricit&#233;, transportabilit&#233;, reproductibilit&#233;, qu&#146;impose 
le d&#233;veloppement de la recherche. Autrement dit, il faut chercher &#224; d&#233;velopper des outils de 
TAL relativement g&#233;n&#233;riques quant au domaine et au type d&#146;application, pour des utilisations 
elles tr&#232;s cibl&#233;es quant &#224; ces deux points. 
</p>
<p>Rapidement, on peut classer les types d&#146;outils &#224; construire selon deux axes. Du point de vue 
fonctionnel, on peut distinguer les outils d&#146;aide &#224; l&#146;acquisition de termes et les outils d&#146;aide &#224; 
la structuration de termes et au regroupement conceptuel (section 4). Du point de vue du 
mode d&#146;utilisation, on peut distinguer les outils qui fonctionnent &#171; en batch &#187; (ils traitent 
l&#146;ensemble du corpus, puis fournissent les r&#233;sultats &#224; l&#146;analyste), et les outils interactifs. Par 
ailleurs, puisque les d&#233;cisions prises par l&#146;expert s&#146;appuient in fine sur l&#146;analyse de contextes 
dans le corpus, &#224; c&#244;t&#233; des outils de traitement massif de corpus, il faut fournir &#224; l&#146;analyste des 
moyens d&#146;acc&#232;s au texte (concordanciers, outils de navigation hypertextuelle, etc.). 
</p>
<p>3.2 R&#244;le de l&#146;analyste 
</p>
<p>Dans l&#146;id&#233;al, la personne charg&#233;e de construire la RTO, l&#146;analyste, devrait avoir &#224; la fois des 
comp&#233;tences m&#233;tier, des comp&#233;tences en mod&#233;lisation des connaissances et en linguistique et 
des comp&#233;tences en informatique. Ce profil fait-il de l&#146;analyste un oiseau rare ? Dans la 
r&#233;alit&#233;, il faut mettre en place une collaboration entre acteurs de sp&#233;cialit&#233;s diff&#233;rentes. 
Plusieurs sortes de situations peuvent &#234;tre rencontr&#233;es. Pour les applications &#224; forte dimension </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault et N. Aussenac-Gilles 
</p>
<p>cognitive, l&#146;exp&#233;rience montre que l&#146;efficacit&#233; maximale peut &#234;tre atteinte quand la 
construction de la RTO est assur&#233;e par un sp&#233;cialiste m&#233;tier, passionn&#233; par les probl&#232;mes de 
langue et de connaissance, ou form&#233; &#224; ceux-ci, qui comprend bien les sp&#233;cifications de 
l&#146;application cible et qui est capable de dialoguer avec les informaticiens qui la d&#233;veloppent. 
A l&#146;oppos&#233;, certaines applications, de type documentaire, ne requi&#232;rent pas une implication 
forte des sp&#233;cialistes et la construction de la RTO peut &#234;tre r&#233;alis&#233;e par des personnes ayant le 
profil et l&#146;exp&#233;rience de documentaliste ou de terminologue. Dans tous les cas, l&#146;intervention 
d&#146;un analyste m&#233;diateur est n&#233;cessaire quand l&#146;application exige la participation de plusieurs 
sp&#233;cialistes.  
</p>
<p>3.3 Place du corpus 
</p>
<p>Dans un projet de construction de RTO &#224; partir de textes, la t&#226;che de construction du corpus 
est &#224; la fois primordiale et d&#233;licate. Puisque, d&#146;une part, le corpus est la source d&#146;information 
essentielle pour tout le processus de construction de la RTO et que, d&#146;autre part, il restera, une 
fois le processus achev&#233;, l&#146;&#233;l&#233;ment de documentation de la ressource construite, il doit &#234;tre 
compos&#233; avec un maximum de pr&#233;cautions m&#233;thodologiques. Dans ce domaine, il n&#146;est h&#233;las 
pas encore possible de d&#233;finir a priori des instructions m&#233;thodologiques tr&#232;s pr&#233;cises pour 
encadrer la t&#226;che de s&#233;lection des sources textuelles qui viendront constituer le corpus. Au-
del&#224; des probl&#232;mes techniques ou politiques de disponibilit&#233; des textes, cette collecte doit se 
faire avec l&#146;aide des sp&#233;cialistes et en fonction de l&#146;application cible vis&#233;e. Il convient en effet 
de s&#146;assurer aupr&#232;s des sp&#233;cialistes que les textes choisis ont un statut suffisamment 
consensuel pour &#233;viter toute remise en cause ult&#233;rieure de la part d&#146;utilisateurs ou de leur part. 
Par ailleurs, il convient de pr&#233;voir d&#146;embl&#233;e une boucle de r&#233;troaction au cours de laquelle 
une premi&#232;re version du corpus sera modifi&#233;e et enrichie en fonction d&#146;une premi&#232;re phase 
d&#146;analyse des r&#233;sultats fournis par les outils de TAL sur cette version initiale. Le crit&#232;re de la 
taille est &#233;videmment important, m&#234;me s&#146;il est impossible de donner un chiffre id&#233;al. Le choix 
est ici encore un compromis. Le corpus doit &#234;tre suffisamment &#171; gros &#187; pour justifier que des 
outils de traitement de la langue soient n&#233;cessaires pour le d&#233;pouiller de fa&#231;on efficace. Mais 
il doit &#234;tre suffisamment petit et/ou redondant pour pouvoir &#234;tre appr&#233;hend&#233; de fa&#231;on globale 
par l&#146;analyste, m&#234;me &#224; l&#146;aide d&#146;outils de TAL. Une fourchette entre 50 000 et 200 000 mots 
semble raisonnable. Les projets prenant le Web comme source de textes font rapidement 
exploser ces chiffres, posant par la m&#234;me des probl&#232;mes sp&#233;cifiques, comme celui de la 
d&#233;finition d&#146;un &#171; &#233;chantillon &#187; pertinent pour l&#146;&#233;tude. Enfin, dans la majorit&#233; des cas, le 
corpus sera h&#233;t&#233;rog&#232;ne dans le sens o&#249; il aura &#233;t&#233; constitu&#233; en rassemblant des textes 
d&#146;origine vari&#233;e. Il est alors absolument n&#233;cessaire de proc&#233;der &#224; un balisage du corpus qui 
permettra aux outils d&#146;analyse, et ainsi qu&#146;&#224; l&#146;analyste, de rep&#233;rer les diff&#233;rents sous-corpus 
pour proc&#233;der &#233;ventuellement &#224; des analyses contrastives. 
</p>
<p>3.4 Utilisation de ressources existantes 
</p>
<p>On l&#146;aura compris, nous ne nous int&#233;ressons ici ni aux ontologies g&#233;n&#233;riques (&#171; &#224; la Cyc &#187;) 
cens&#233;es repr&#233;senter un ensemble maximal de connaissances, de sens commun, ni aux 
ontologies formelles (au sens de Guarino) qui constitueraient un cadre r&#233;f&#233;rentiel universel et 
formellement valide, mais bien &#224; des ressources termino-ontologiques exploit&#233;es par un 
syst&#232;me particulier de traitement de l&#146;information dans un domaine particulier. C&#146;est l&#146;usage 
pr&#233;vu de la ressource qui contraint et encadre sa construction. Pour autant, nous ne souhaitons </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Construction d&#146;ontologies &#224; partir de textes 
</p>
<p>pas participer &#224; une pol&#233;mique sur l&#146;opposition ontologies g&#233;n&#233;rales vs. ontologies 
sp&#233;cialis&#233;es. Notre position est la suivante : il est primordial que les outils d&#146;aide &#224; la 
construction de RTO puissent recycler des donn&#233;es existantes afin de tirer le meilleur parti du 
patrimoine terminologique poss&#233;d&#233; par les entreprises et les institutions (Jacquemin, 1997). 
Pour une t&#226;che de construction de RTO, il faut faire feu de tout bois, et chercher &#224; exploiter 
autant que faire se peut toutes les ressources disponibles, et pas uniquement les textes. Sur le 
plan de la politique de la recherche, nous pensons qu&#146;il est utile de promouvoir des travaux 
montrant l&#146;utilit&#233; de ressources lexicales existantes (g&#233;n&#233;rales, comme la base WordNet ou 
des fichiers &#233;lectroniques de synonymes, ou sp&#233;cialis&#233;es, comme les grands thesaurus de la 
m&#233;decine comme UMLS) dans la perspective d&#146;am&#233;liorer le rendement du couple 
analyste/outils de TAL. Nous sommes plus r&#233;serv&#233;s sur la n&#233;cessit&#233; de d&#233;gager des 
financements lourds pour la r&#233;alisation de nouvelles ressources s&#233;mantico-conceptuelles de 
taille gigantesque, &#233;labor&#233;es hors de toute sp&#233;cification d&#146;application cible. Il nous semble 
plus pertinent que soient encourag&#233;s des exp&#233;riences d&#146;&#233;valuation, n&#233;cessairement tr&#232;s 
lourdes, proposant des protocoles exp&#233;rimentaux capables de mettre en &#233;vidence &#224; grande 
&#233;chelle les gains en temps et en qualit&#233; apport&#233;s par l&#146;introduction d&#146;une ontologie dans tel ou 
tel syst&#232;me de traitement de l&#146;information par rapport au co&#251;t de la construction de cette 
ontologie (cf. section 6). 
</p>
<p>3.5 De la n&#233;cessit&#233; d&#146;interface int&#233;gratrices 
</p>
<p>La t&#226;che de construction d&#146;une RTO est incr&#233;mentale et comporte de nombreux 
encha&#238;nements d&#146;essais/erreurs. Il faut des interfaces ergonomiques permettant une utilisation 
coordonn&#233;e et optimale des diff&#233;rents outils de traitement et de consultation du corpus de 
r&#233;f&#233;rence, par l&#146;analyste qui construit une RTO, &#224; l&#146;instar de (Ait El Mekki et Nazarenko, 
2002) pour la construction d&#146;index d&#146;ouvrages, de la plate-forme de mod&#233;lisation TERMINAE 
pour la construction de terminologies et d&#146;ontologies (Szulman et al., 2002). De fa&#231;on plus 
g&#233;n&#233;rale, l&#146;utilisation de ces diff&#233;rents outils doit &#234;tre encadr&#233;e par une m&#233;thodologie 
pr&#233;cisant &#224; quel stade du processus et selon quelles modalit&#233;s il convient de les utiliser. En 
effet, la solution au probl&#232;me de l&#146;acquisition de ressources termino-ontologiques &#224; partir de 
corpus ne r&#233;side pas uniquement en la fourniture d&#146;un ou de plusieurs outils de traitement 
automatique des langues. La mise &#224; disposition de tels outils doit s&#146;accompagner d&#146;une 
r&#233;flexion m&#233;thodologique pouss&#233;e, conduisant &#224; la r&#233;alisation de guides m&#233;thodologiques et 
de plates-formes logicielles int&#233;gratrices permettant la mise en &#156;uvre efficace des outils 
propos&#233;s. Cette n&#233;cessit&#233; appelle une coop&#233;ration entre TAL et IC. Cette r&#233;flexion sur 
l&#146;utilisation combin&#233;e de diff&#233;rents types d&#146;outils d&#146;analyse de textes en ing&#233;nierie 
terminologique est aussi tr&#232;s pr&#233;sente dans un certain nombre de travaux en ing&#233;nierie des 
connaissances (Charlet et al., 2000).  
</p>
<p>3.6 Une proposition m&#233;thodologique 
</p>
<p>A titre d&#146;exemple, nous &#233;voquons une proposition m&#233;thodologique int&#233;grant l&#146;utilisation de 
plusieurs outils de TAL et qui se veut une r&#233;ponse possible aux diff&#233;rents probl&#232;mes 
&#233;voqu&#233;s : la m&#233;thode TERMINAE (Szulman et al., 2002). Cette m&#233;thode s'appuie sur des 
travaux repr&#233;sentatifs du courant fran&#231;ais de travaux &#224; la convergence entre terminologie, </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault et N. Aussenac-Gilles 
</p>
<p>linguistique, ing&#233;nierie des connaissances et intelligence artificielle2. Elle s&#146;appuie sur les 
principes suivants : 
</p>
<p>! Partir de textes du domaine comme sources de connaissances : ils constituent un support 
tangible, rassemblant des connaissances stabilis&#233;es qui servent de r&#233;f&#233;rence et am&#233;liorent 
la qualit&#233; du mod&#232;le final ; 
</p>
<p>! Enrichir le mod&#232;le conceptuel d&#146;une composante linguistique : l&#146;acc&#232;s aux termes et aux 
textes qui justifient la d&#233;finition des concepts garantit une meilleure compr&#233;hension du 
mod&#232;le ; 
</p>
<p>! Utiliser des techniques et outils de TAL bas&#233;s sur des travaux linguistiques : ils 
permettent l'exploitation syst&#233;matique des textes et leurs r&#233;sultats facilitent la 
mod&#233;lisation ; 
</p>
<p>! Construire des ontologies &#171; r&#233;gionales &#187;, c&#146;est-&#224;-dire consensuelles dans un domaine et 
adapt&#233;es &#224; une application, mais non universelles ; 
</p>
<p>! Appliquer des principes de mod&#233;lisation syst&#233;matiques pour assurer une bonne 
structuration des donn&#233;es et faciliter la maintenance de l&#146;ontologie. 
</p>
<p>TERMINAE vise essentiellement la constitution de terminologies, r&#233;seaux conceptuels et 
ontologies. La m&#233;thode comprend quatre &#233;tapes, les trois derni&#232;res &#233;tant mises en oeuvre de 
mani&#232;re cyclique. L'importance de chacune d&#233;pend du produit terminologique vis&#233; et des 
objectifs d'utilisation de ce dernier.  
</p>
<p>&#8226; La Constitution d'un corpus vise &#224; choisir documents techniques, comptes rendus, 
livres de cours, etc. &#224; partir d'une analyse des besoins de l'application.  
</p>
<p>&#8226; L'&#233;tude linguistique consiste &#224; identifier des termes et des relations lexicales, en 
utilisant des outils de traitement de la langue naturelle (SYNTEX comme extracteur de 
termes, UPPERY comme outil d'analyse distributionnelle, Cam&#233;l&#233;on pour l&#146;aide au 
rep&#233;rage de relations par des patrons linguistiques, YAKWA comme concordancier).  
</p>
<p>&#8226; La normalisation s&#233;mantique conduit &#224; d&#233;finir dans un langage formel des concepts et 
des relations s&#233;mantiques que nous appelons terminologiques car provenant des 
termes et relations pr&#233;c&#233;demment &#233;tudi&#233;s (Bi&#233;bow &amp; Szulman, 1999). Leur 
structuration en r&#233;seau s'appuie sur les r&#233;sultats du d&#233;pouillement des textes tout en 
tenant compte de l'objectif d'utilisation de l'ontologie. Elle n&#233;cessite l'ajout de 
nouveaux concepts et relations dits de structuration.  
</p>
<p>&#8226; La formalisation permet de pr&#233;ciser, compl&#233;ter et valider le mod&#232;le construit lors de la 
nor-malisation. L'analyste indique si les concepts sont primitifs ou d&#233;finis, v&#233;rifie que 
les relations sont &#224; la bonne place pour favoriser un h&#233;ritage maximum, etc.  
</p>
<p>Le logiciel TERMINAE associ&#233; &#224; la m&#233;thode fournit des aides pour toutes les &#233;tapes de 
l'analyse des textes &#224; la formalisation. Il offre un support m&#233;thodologique qui permet 
d'&#233;voluer progressivement et en conservant des liens des textes vers les niveaux linguistique 
                                                 
2 Ce courant, anim&#233; au sein du GDR-I3 et de l'AFIA par le groupe TIA (http://www.biomath.jussieu.fr/TIA/) 
</p>
<p>dont les auteurs font partie. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Construction d&#146;ontologies &#224; partir de textes 
</p>
<p>et conceptuel. Le logiciel assure donc une continuit&#233; entre les diff&#233;rentes formes de 
l'ontologie. Celle-ci passe d'un &#233;tat proche d'une taxinomie de termes &#224; un r&#233;seau conceptuel 
enrichi de relations et de concepts de structuration pour aboutir &#224; une ontologie formelle. Elle 
est d&#233;crite dans un langage formel masqu&#233; &#224; l'analyste qui permet de v&#233;rifier des contraintes 
de validit&#233; minimale.  
</p>
<p>4 Outils de TAL pour la construction de RTO 
</p>
<p>4.1 Une typologie fonctionnelle 
</p>
<p>Dans cette section3, nous passons en revue un certain nombre de travaux de recherche sur le 
d&#233;veloppement d&#146;outils d&#146;aide &#224; la construction de RTO &#224; partir de textes. Nous avons choisi 
de les pr&#233;senter selon une typologie de fonctionnelle.  
</p>
<p>&#8226; Acquisition de termes. Une premi&#232;re classe regroupe les outils dont la vis&#233;e est 
l&#146;extraction &#224; partir du corpus analys&#233; de candidats termes, c&#146;est-&#224;-dire de mots ou 
groupes de mots susceptibles d&#146;&#234;tre retenus comme termes par un analyste, et de 
fournir des &#233;tiquettes de concepts. Ces outils diff&#232;rent principalement quant au type 
de techniques mises en &#156;uvre (syntaxique, statistique, autres). 
</p>
<p>&#8226; Structuration de termes et regroupement conceptuel. Les ressources termino-
ontologiques se pr&#233;sentent rarement sous la forme d&#146;une liste &#224; plat. Des outils 
d&#146;aide &#224; la structuration d&#146;ensembles de termes sont donc n&#233;cessaires. Dans cette 
classe, nous &#233;voquerons, d&#146;une part, des outils de classification automatique de 
termes, et, d&#146;autre part, des outils de rep&#233;rage de relation. Signalons que beaucoup 
d&#146;outils d&#146;extraction proposent d&#233;j&#224; une structuration des candidats termes extraits. 
</p>
<p>4.2 Acquisition de termes 
</p>
<p>L'outil TERMINO est une application pionni&#232;re de l'acquisition automatique de termes (David 
et Plante, 1990). Construit sur la base de l'atelier FX, un formalisme pour l'expression de 
grammaires du langage naturel et un analyseur associ&#233;, TERMINO se focalise sur le rep&#233;rage 
des syntagmes nominaux qui sont les seules structures suppos&#233;es produire des termes. Les 
candidats termes extraits par TERMINO sont appel&#233;s &#147; synapsies &#148; d'apr&#232;s les travaux de 
Benveniste. La cha&#238;ne de traitement de TERMINO se compose d&#146;une phase d&#146;analyse 
morphosyntaxique suivie d&#146;une phase de g&#233;n&#233;ration des synapsies &#224; partir des d&#233;pendances 
entre t&#234;te et compl&#233;ments rencontr&#233;s dans la structure de syntagme nominal retourn&#233;e par 
l'analyseur. ANA est un outil d'acquisition terminologique qui extrait des candidats termes sans 
effectuer d&#146;analyse linguistique (Enguehard et Pantera, 1995). Les termes sont reconnus au 
moyen d'&#233;galit&#233;s approximatives entre mots et d'une observation de r&#233;p&#233;titions de patrons. 
ACABIT extrait des candidats termes &#224; partir d&#146;un corpus pr&#233;alablement &#233;tiquet&#233; et 
d&#233;sambigu&#239;s&#233; (Daille, 1994). ACABIT m&#234;le des traitements linguistiques et des filtres 
                                                 
3 Cette partie est extraite et adapt&#233;e de (Bourigault et Jacquemin, 2000) parue dans l&#146;ouvrage Industrie des 
</p>
<p>langues (Herm&#232;s) coordonn&#233; par J.-M. Pierrel . Une bibliographie mise &#224; jour sera fournie lors du cours. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault et N. Aussenac-Gilles 
</p>
<p>statistiques. L'acquisition terminologique dans ACABIT se d&#233;roule en deux &#233;tapes : (1) analyse 
linguistique et regroupement de variantes, au cours de laquelle n ensemble de transducteurs 
analyse le corpus &#233;tiquet&#233; pour extraire des s&#233;quences nominales et les ramener &#224; des 
candidats termes binaires ; (2) filtrage statistique, au cours duquel les candidats termes 
binaires produits &#224; l'&#233;tape pr&#233;c&#233;dente sont tri&#233;s au moyen de mesures statistiques. A l&#146;instar 
d&#146;ACABIT, LEXTER extrait des candidats termes &#224; partir d&#146;un corpus pr&#233;alablement &#233;tiquet&#233; et 
d&#233;sambigu&#239;s&#233; (Bourigault, 1994). Il effectue une analyse syntaxique de surface pour rep&#233;rer 
les syntagmes nominaux maximaux, puis une analyse syntaxique profonde pour analyser et 
d&#233;composer ces syntagmes. Il est dot&#233; de proc&#233;dures d&#146;apprentissage endog&#232;ne pour acqu&#233;rir 
des informations de sous-cat&#233;gorisation des noms et adjectifs propres aux corpus. Il organise 
l&#146;ensemble des candidats termes extraits sous la forme d&#146;un r&#233;seau. FASTR est un analyseur 
syntaxique robuste d&#233;di&#233; &#224; la reconnaissance en corpus de termes appartenant &#224; une liste 
contr&#244;l&#233;e fournie au syst&#232;me (Jacquemin, 1997). Les termes n'ayant pas toujours, en corpus, 
la m&#234;me forme linguistique, le principal enjeu est de pouvoir identifier leurs variantes. FASTR 
est dot&#233; d&#146;un ensemble &#233;labor&#233; de m&#233;tar&#232;gles, qui lui permettent de rep&#233;rer diff&#233;rents types de 
variation : les variantes syntaxiques, morpho-syntaxiques et s&#233;mantico-syntaxiques. 
L&#146;environnement SYMONTOS (Velardi et al., 2001) propose des outils pour rep&#233;rer des termes 
simples et complexes dans des textes et des crit&#232;res pour d&#233;cider de d&#233;finir des concepts &#224; 
partir de ces termes. 
</p>
<p>4.3 Structuration de termes et regroupement conceptuel  
</p>
<p>La gamme des outils d&#146;aide &#224; la structuration de terminologie est tr&#232;s large. Sont susceptibles 
d&#146;&#233;marger &#224; cette cat&#233;gorie un certain nombre de types d&#146;outils qui n&#146;&#233;taient pas initialement 
con&#231;us sp&#233;cifiquement pour cette t&#226;che, mais qui ont &#233;t&#233; d&#233;velopp&#233;s pour des applications 
d&#146;informatique documentaire ou d&#146;extraction d&#146;informations, par exemple. Nous balayons 
rapidement un spectre assez large, couvrant les outils de classification de termes sur la base 
de cooccurrences dans des textes ou dans des fen&#234;tres, les outils de classification de termes 
sur la base de distributions syntaxiques et les outils de rep&#233;rage de relations. Les outils de 
cooccurrence d&#233;velopp&#233;s dans le domaine de la recherche d&#146;information rapprochent des 
termes qui apparaissent fr&#233;quemment dans les m&#234;mes (portions de) documents, et qui 
poss&#232;dent donc sans doute une certaine proximit&#233; s&#233;mantique. La technique de recherche de 
cooccurrents est d&#233;j&#224; ancienne (&#224; l'&#233;chelle de l'histoire de l'informatique) puisqu'elle a &#233;t&#233; 
promue tr&#232;s t&#244;t en informatique documentaire pour permettre l'expansion de requ&#234;tes (Sparck 
Jones, 1971). Parmi les applications dans le domaine de l&#146;acquisition terminologique, on peut 
citer le projet ILIAD (Toussaint et al., 1998), et les travaux de G. Lame (2002). Toujours dans 
le domaine de l&#146;informatique documentaire, les travaux dans le domaine de la construction 
automatique de thesaurus peuvent &#234;tre r&#233;investis dans des applications terminologiques. Par 
exemple, la cha&#238;ne de traitement d&#233;velopp&#233;e par G. Greffenstette construit automatiquement 
des classes comportant des noms qui se retrouvent r&#233;guli&#232;rement comme arguments des 
m&#234;mes verbes (Greffenstette, 1994). Ce rep&#233;rage de la position argumentale des noms se fait 
gr&#226;ce &#224; l&#146;exploitation d&#146;un analyseur syntaxique de surface &#224; large couverture. Ces techniques 
inspir&#233;es de la linguistique harrissienne, qui visent &#224; rapprocher les termes qui ont des 
distributions syntaxiques analogues, sont &#224; la base de nombreux travaux depuis plusieurs 
ann&#233;es (Assadi, 1998) (Habert et al, 1996) (Faure, 2000). 
</p>
<p>Les outils que nous venons d&#146;&#233;voquer visent &#224; rapprocher des termes &#224; partir d&#146;une analyse 
globale de l&#146;ensemble de leurs occurrences. Ils ne touchent que les termes fr&#233;quents, et donc </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Construction d&#146;ontologies &#224; partir de textes 
</p>
<p>le plus souvent des noms simples, et proposent une simple relation d&#146;&#233;quivalence 
(appartenance &#224; une classe). A c&#244;t&#233; de ces outils qui travaillent sur les types comme 
regroupement des occurrences, on trouve les outils de rep&#233;rage de relations, qui travaillent au 
niveau des occurrences elles-m&#234;mes. Ces outils d&#233;tectent en corpus des mots ou contextes 
syntaxiques r&#233;pertori&#233;s comme susceptibles de &#147; marquer &#148; telle ou telle relation entre deux 
&#233;l&#233;ments. Les travaux de M. Hearst, sur l'extraction automatique des liens d&#146;hyperonymie, 
font figure de r&#233;f&#233;rence (Hearst, 1992). Les recherches sur ce th&#232;me se d&#233;clinent de multiples 
fa&#231;ons. L&#146;un des enjeux principaux concerne la g&#233;n&#233;ralit&#233; des relations, et celles des 
marqueurs de relations. D&#146;un c&#244;t&#233;, il existe probablement des relations que l&#146;on jugera 
toujours pertinentes pour d&#233;crire un domaine de connaissance, par exemple les relations de 
type hi&#233;rarchique ou partitive, et des marqueurs pour ces relations eux aussi g&#233;n&#233;raux 
(Garcia, 1998). A l&#146;oppos&#233;, il est ind&#233;niable que chaque domaine est structur&#233; par des 
relations qui lui sont sp&#233;cifiques, et qu&#146;il convient n&#233;cessairement de prendre en compte pour 
d&#233;crire le domaine. De plus m&#234;me dans le cas de relations consid&#233;r&#233;es comme g&#233;n&#233;rales, il est 
possible que les marqueurs susceptibles de conduire &#224; les identifier diff&#232;rent d&#146;un corpus &#224; 
l&#146;autre. Se pose alors le probl&#232;me de l&#146;apprentissage inductif de ces marqueurs de relation. Un 
certain nombre de travaux en TAL et en IC sont consacr&#233;s &#224; ce probl&#232;me. Ils partent tous du 
m&#234;me principe d&#146;une recherche it&#233;rative altern&#233;e dans le corpus &#224; la fois des marqueurs d&#146;une 
relation donn&#233;e et des couples de termes qui entrent dans cette relation (Rousselot et al., 
1996) (S&#233;gu&#233;la et Aussenac-Gilles, 1999) (Morin, 1999) (Condamines et Rebeyrolles, 2000) 
(Maedche et Staab, 2000). 
</p>
<p>5 Trois retours d&#146;exp&#233;rience 
</p>
<p>5.1 Contextes 
</p>
<p>Les exemples, d&#233;monstrations et exp&#233;rimentations propos&#233;s pendant le cours sont issus 
principalement de 3 exp&#233;riences r&#233;elles de construction de RTO &#224; partir de textes4. Ces trois 
exp&#233;riences couvrent un spectre large de types de domaines et de types d&#146;applications : la 
premi&#232;re exp&#233;rience a &#233;t&#233; men&#233;e dans le domaine technique de la fabrication du verre (projet 
VERRE), avec comme application cible la classification de documents ; la deuxi&#232;me 
exp&#233;rience a &#233;t&#233; men&#233;e dans un domaine m&#233;dical de la r&#233;animation chirurgicale (projet REA), 
avec comme application cible le codage d&#146;actes m&#233;dicaux ; la troisi&#232;me exp&#233;rience a &#233;t&#233; 
men&#233;e dans le domaine juridique du Droit fran&#231;ais codifi&#233; (projet DROIT), avec comme 
application cible l&#146;aide &#224; la reformulation de requ&#234;tes. Il s&#146;agit &#224; chaque fois de projets de 
Recherche et D&#233;veloppement, dans lesquels l&#146;application cible n&#146;est pas strictement sp&#233;cifi&#233;e 
au d&#233;part du projet, comme cela devrait l&#146;&#234;tre dans un &#171; vrai &#187; projet industriel. On doit donc 
&#234;tre prudent au moment de tirer des conclusions g&#233;n&#233;rales. N&#233;anmoins, chacun de ces projets 
est all&#233; &#224; son terme, en ce sens qu&#146;il n&#146;a pas conduit &#224; des RTO &#171; jouets &#187;, mais &#224; des 
ressources compl&#232;tes qui sont ou seraient exploitables. Par ailleurs, chaque projet a permis de 
tester certaines hypoth&#232;ses m&#233;thodologiques faisant ainsi progresser les recherches dans le 
domaine de l&#146;acquisition des connaissances &#224; partir de textes. C&#146;est en multipliant ce type 
</p>
<p>                                                 
4 Cette partie est extraite et adapt&#233;e d&#146;un article &#224; para&#238;tre dans un num&#233;ro sp&#233;cial de la Revue d&#146;Intelligence 
</p>
<p>Artificielle, coordonn&#233; par M. Slodzian et J.-M. Pierrel (Aussenac-Gilles &amp; al, 2003) </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault et N. Aussenac-Gilles 
</p>
<p>d&#146;exp&#233;riences que l&#146;on avancera sur la d&#233;finition d&#146;un cadre m&#233;thodologique relativement 
pr&#233;cis qui aille au-del&#224; d&#146;un simple recueil de bonnes pratiques et qui puisse satisfaire les 
exigences d&#146;un transfert vers les applications industrielles. 
</p>
<p>5.1.1 Le projet VERRE : une ontologie dans le domaine de la fabrication et d&#146;utilisation 
de la fibre de verre 
</p>
<p>Le premier projet vient r&#233;pondre &#224; une demande du centre de recherche du groupe Saint-
Gobain. Au sein des diff&#233;rentes filiales du groupe, l&#146;avance technologique et industrielle est 
primordiale pour conserver une place comp&#233;titive par rapport aux entreprises concurrentes. 
Les activit&#233;s de veille documentaire et technologique jouent alors un r&#244;le crucial, et font 
l&#146;objet d&#146;un outillage informatique de plus en plus performant. Parmi ces activit&#233;s, une 
demande r&#233;currente des documentalistes porte sur la d&#233;finition d&#146;un outil d&#146;aide au rep&#233;rage 
de nouveaux documents pertinents sur le Web (comme des brevets, des d&#233;p&#234;ches de presse, 
etc.) et &#224; leur classement en fonction des domaines d&#146;int&#233;r&#234;t des ing&#233;nieurs qui les consultent. 
Or la plupart des outils de routage de documents s&#146;appuient sur un r&#233;seau conceptuel d&#146;autant 
plus performant qu&#146;il est enrichi des connaissances et de la terminologie du domaine de 
l&#146;entreprise. L&#146;objectif du projet &#233;tait donc de tester la faisabilit&#233; du d&#233;veloppement d&#146;une 
ontologie dans l&#146;objectif de l&#146;utiliser pour guider le classement de documents en fonction des 
profils des utilisateurs. Dans ce projet, les aspects m&#233;thodologiques &#233;taient tout aussi 
importants que l&#146;ontologie elle-m&#234;me. L&#146;&#233;tude a &#233;t&#233; men&#233;e par deux chercheurs de l&#146;IRIT, A. 
Busnel pour l&#146;analyse terminologique et ontologique, et N. Aussenac-Gilles sur les aspects 
m&#233;thodologiques. Un d&#233;but d&#146;ontologie (50 concepts, 20 relations) a &#233;t&#233; mis en forme &#224; l&#146;aide 
du logiciel de mod&#233;lisation TERMINAE, &#224; partir de l&#146;analyse d&#146;un corpus de langue anglaise 
compos&#233; de diff&#233;rents types de documents sur le domaine. Les logiciels de Traitement 
Automatique des Langues SYNTEX, UPERY et YAKWA ont &#233;t&#233; utilis&#233;s pour le d&#233;pouillement 
de ces corpus. Une proposition m&#233;thodologique utilisable dans le contexte de cette entreprise 
et pour ce type d&#146;application a &#233;t&#233; mise en forme (Aussenac-Gilles &amp; Busnel, 2002). 
</p>
<p>5.1.2 Le projet REA : une ontologie dans le domaine de la traumatologie en r&#233;animation 
chirurgicale 
</p>
<p>Le deuxi&#232;me projet a &#233;t&#233; encadr&#233; par M.-C. Jaulent et J. Charlet et a &#233;t&#233; men&#233; &#224; bien au sein 
de l&#146;UFR Broussais-Hotel-Dieu. Le contexte est celui du codage des actes m&#233;dicaux par les 
m&#233;decins. Pour leur activit&#233; de codage obligatoire, les praticiens s&#146;aident d&#146;un th&#233;saurus de 
sp&#233;cialit&#233; qui a &#233;t&#233; &#233;labor&#233; de fa&#231;on &#224; ce que les s&#233;jours de r&#233;animation soient le mieux 
possible valoris&#233;s. Il est aujourd&#146;hui reconnu que l&#146;ambigu&#239;t&#233; du th&#233;saurus est une source 
d&#146;erreurs et de disparit&#233;s de codage. Dans un domaine particulier tel que la r&#233;animation 
chirurgicale, on ne peut envisager de r&#233;aliser des outils informatiques d&#146;aide au codage 
qu&#146;apr&#232;s avoir pr&#233;alablement organis&#233; des objets du domaine, en fonction de la t&#226;che &#224; 
r&#233;soudre, par le biais d&#146;une ontologie. L&#146;objectif de ce deuxi&#232;me projet &#233;tait donc de 
construire une ontologie du domaine de la r&#233;animation chirurgicale. Les outils de Traitement 
Automatique des Langues SYNTEX et UPERY ont &#233;t&#233; utilis&#233;s pour traiter un corpus de comptes 
rendus d&#146;hospitalisation. Le travail a &#233;t&#233; r&#233;alis&#233; par S. Le Moigno, m&#233;decin sp&#233;cialiste, dans 
le cadre d&#146;un stage de DEA en informatique m&#233;dicale. L&#146;ontologie comprend environ 2 000 
concepts et 200 liens (Le Moigno et al., 2002). </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Construction d&#146;ontologies &#224; partir de textes 
</p>
<p>5.1.3 Le projet DROIT : une ressource ontologique dans le domaine du Droit 
</p>
<p>Le troisi&#232;me projet a &#233;t&#233; men&#233; par G. Lame, au cours de sa th&#232;se au Centre de Recherche en 
Informatique de l&#146;Ecole des Mines de Paris (Lame, 2002). Ce centre de recherche a cr&#233;&#233; et 
h&#233;berge le site juridique droit.org, qui diffuse l'&#233;dition Lois et d&#233;crets du Journal Officiel de la 
R&#233;publique fran&#231;aise, ce qui repr&#233;sente 95 000 documents (lois, d&#233;crets, arr&#234;t&#233;s), ainsi que les 
codes du droit fran&#231;ais (Code civil, Code p&#233;nal, etc.) et des textes europ&#233;ens (directives, 
r&#232;glements). L&#146;objectif du travail &#233;tait de tester l&#146;int&#233;r&#234;t et la faisabilit&#233; d&#146;une approche 
consistant &#224; int&#233;grer une ontologie du Droit susceptible de faciliter l&#146;acc&#232;s au site par les 
utilisateurs. Le r&#233;sultat est une ressource ontologique de tr&#232;s large couverture, couvrant tous 
les domaines du Droit, constitu&#233;e d&#146;environ 130 000 termes et 200 000 liens. Cette ressource 
est utilis&#233;e comme support pour un syst&#232;me d&#146;expansion de requ&#234;tes : &#224; un mot pos&#233; par 
l&#146;utilisateur, le syst&#232;me propose tous les termes reli&#233;s &#224; ce mot dans la ressource et laisse 
l&#146;utilisateur choisir ceux qu&#146;ils souhaitent retenir pour modifier sa requ&#234;te. Cette ressource a 
&#233;t&#233; construite en utilisant les r&#233;sultats bruts, sans aucun filtrage manuel, de diff&#233;rents outils ou 
techniques de Traitement Automatique des Langues (SYNTEX, cooccurrence statistique, 
UPERY), obtenus par analyse d&#146;un corpus constitu&#233; de l&#146;ensemble des Codes de la l&#233;gislation 
fran&#231;aise. 
</p>
<p>5.2 Trois outils de TAL pour la construction de RTO &#224; partir de textes 
</p>
<p>5.2.1 Extraction de termes : SYNTEX 
</p>
<p>Dans les trois projets, les r&#233;sultats de l&#146;outil SYNTEX ont &#233;t&#233; utilis&#233;s. SYNTEX (Bourigault et 
Fabre, 2000) est un analyseur syntaxique de corpus. Il existe actuellement une version pour le 
fran&#231;ais, qui a &#233;t&#233; utilis&#233;e dans les projets REA et DROIT, et une version pour l&#146;anglais, qui a 
&#233;t&#233; utilis&#233;e dans le projet VERRE. Apr&#232;s l&#146;analyse syntaxique en d&#233;pendance de chacune des 
phrases du corpus, SYNTEX construite un r&#233;seau de mots et de syntagmes (verbaux, nominaux, 
adjectivaux), dit &#171; r&#233;seau terminologique &#187;, dans lequel chaque syntagme est reli&#233; d&#146;une part 
&#224; sa t&#234;te et d&#146;autre part &#224; ses expansions. Les &#233;l&#233;ments du r&#233;seau (mots et syntagmes) sont 
appel&#233;s &#171; candidats termes &#187;. 
</p>
<p>A chaque candidat terme sont associ&#233;es un certain nombre d&#146;informations num&#233;riques, sur 
lesquelles l&#146;utilisateur peut se baser pour organiser son d&#233;pouillement : 
</p>
<p>&#8226; fr&#233;quence : c&#146;est le nombre d&#146;occurrences du candidat terme d&#233;tect&#233;es par le logiciel 
dans le corpus. L&#146;interface d&#146;analyse des r&#233;sultats permet &#224; l&#146;analyste d&#146;acc&#233;der &#224; 
l&#146;ensemble des contextes d&#146;apparition du candidat terme dans le corpus. Cet acc&#232;s au 
texte est d&#146;autant plus crucial que l&#146;utilisateur n&#146;est pas un sp&#233;cialiste du domaine.  
</p>
<p>&#8226; productivit&#233; en T&#234;te (resp. Expansion) : c&#146;est le nombre de &#171; descendants en T&#234;te &#187; 
(resp. &#171; descendants en Expansion &#187;) du candidat terme, c&#146;est-&#224;-dire le nombre de 
candidats termes plus complexes qui ont le candidat terme en position t&#234;te (resp. 
expansion). A partir de ces informations, l&#146;analyste peut visualiser des listes 
paradigmatiques de candidats termes partageant la m&#234;me t&#234;te ou la m&#234;me expansion 
(cf. figure 1), ce qui le guide vers la constitution de taxinomies locales. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault et N. Aussenac-Gilles 
</p>
<p>La difficult&#233; essentielle pour l&#146;utilisateur vient de la masse des r&#233;sultats fournis par 
l&#146;extraction. M&#234;me s&#146;il existe de nombreux travaux fort int&#233;ressants sur le filtrage statistique 
de candidats termes extraits automatiquement de corpus, l&#146;exp&#233;rience montre qu&#146;aucune 
mesure statistique ne peut suppl&#233;er l&#146;expertise de l&#146;analyste, en particulier parce qu&#146;il y a 
toujours des candidats termes de fr&#233;quence 1 dont l&#146;analyse est int&#233;ressante. De fa&#231;on 
g&#233;n&#233;rale, sachant qu&#146;il ne pourra analyser tous les candidats termes extraits du corpus, 
l&#146;analyste doit adopter une strat&#233;gie optimale qui, &#233;tant donn&#233; le temps qu&#146;il a choisi de 
consacrer &#224; la t&#226;che d&#146;analyse textuelle et en fonction du type de la ressource &#224; construire, lui 
garantit que, parmi les candidats qui auront &#233;chapp&#233; &#224; son analyse, la proportion de ceux qui 
auraient pu &#234;tre pertinents est faible.  
</p>
<p>5.2.2 Analyse distributionnelle : UPERY 
</p>
<p>Dans les trois projets, les r&#233;sultats de l&#146;outil UPERY ont &#233;t&#233; utilis&#233;s. UPERY (Bourigault, 2002) 
est outil d&#146;analyse distributionnelle. Il exploite l&#146;ensemble des donn&#233;es pr&#233;sentes dans le 
r&#233;seau de mots et syntagmes construits par SYNTEX pour effectuer un calcul des proximit&#233;s 
distributionnelles entre ces unit&#233;s. Ce calcul s&#146;effectue sur la base des contextes syntaxiques 
partag&#233;s. Il s&#146;agit d&#146;une mise en &#156;uvre du principe de l&#146;analyse distributionnelle du linguiste 
am&#233;ricain Z. S. Harris, r&#233;alis&#233;e dans la lign&#233;e des travaux de H. Assadi (Assadi &amp; Bourigault, 
1996). L&#146;analyse distributionnelle rapproche d&#146;abord deux &#224; deux des candidats termes qui 
partagent un grand nombre de contextes syntaxiques. Par exemple, dans le corpus REA, les 
candidats termes insuffisance r&#233;nale et d&#233;tresse respiratoire sont rapproch&#233;s car on les trouve 
dans les contextes syntaxiques suivants : compl&#233;ment de prise en charge, de apparition, de 
installation, de admettre en r&#233;animation chirurgicale pour. 
</p>
<p>Trois mesures permettent d&#146;appr&#233;hender la proximit&#233; entre deux candidats termes. Le 
coefficient a est &#233;gal au nombre de contextes syntaxiques partag&#233;s par les deux termes. Cette 
mesure donne une premi&#232;re indication de la proximit&#233; entre deux termes. Mais cette mesure 
refl&#232;te de fa&#231;on insatisfaisante la proximit&#233;. Il faut tenir compte de la productivit&#233; en T&#234;te des 
contextes partag&#233;s : plus un contexte partag&#233; par deux termes est productif, moins sa 
contribution au rapprochement des deux candidats termes doit &#234;tre importante. Cette intuition 
est prise en compte par le coefficient prox qui pond&#232;re chaque contexte partag&#233; par l&#146;inverse 
de sa productivit&#233;. Enfin, pour &#233;valuer la proximit&#233; entre deux unit&#233;s, il est important de tenir 
compte non seulement de ce qu&#146;elles partagent, mais aussi de ce qu&#146;elles ont en propre. On 
caract&#233;rise la proximit&#233; entre deux candidats termes &#224; l&#146;aide de deux indices 
suppl&#233;mentaires : pour chacun des deux candidats termes, le rapport entre le nombre de 
contextes partag&#233;s et le nombre total de contextes dans lesquels appara&#238;t le candidat terme. 
</p>
<p>Le module d&#146;analyse distributionnelle UPERY calcule chacun de ces coefficients pour chaque 
couple de candidats termes, et ne sont pr&#233;sent&#233;s &#224; l&#146;utilisateur que les couples dont les 
coefficients d&#233;passent certains seuils. Ceux-ci sont d&#233;finis de fa&#231;on empirique et varient en 
fonction d&#146;une part de l&#146;homog&#233;n&#233;it&#233; et de la redondance du corpus et d&#146;autre part du 
contexte dans lequel doivent &#234;tre exploit&#233;s les r&#233;sultats de l&#146;analyse distributionnelle. 
L&#146;analyse distributionnelle impl&#233;ment&#233;e dans UPERY est sym&#233;trique : on calcule aussi la 
proximit&#233; entre contextes syntaxiques. Deux contextes syntaxiques sont proches si on y 
trouve les m&#234;mes termes. Par exemple, dans le corpus REA, les verbes montrer et mettre en 
&#233;vidence sont proches car ils partagent en position sujet les termes &#233;chographie, bilan 
infectieux, tomodensitom&#233;trie, art&#233;riographie, auscultation pulmonaire, etc. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Construction d&#146;ontologies &#224; partir de textes 
</p>
<p> Il s&#146;av&#232;re que les rapprochements effectu&#233;s par UPERY sont extr&#234;mement utiles et pertinents 
pour la construction de classes conceptuelles. Le nombre de rapprochements effectu&#233;s d&#233;pend 
de la redondance du corpus. Par exemple, les corpus REA et le corpus du Code civil, l&#146;un des 
corpus exploit&#233; dans le projet DROIT, sont deux corpus diff&#233;rents quant &#224; ce param&#232;tre de la 
redondance. Le corpus REA est constitu&#233; dans un ensemble de comptes rendus m&#233;dicaux qui 
d&#233;crivent tous les m&#234;mes types d&#146;&#233;v&#233;nement et donc dans lesquels les m&#234;mes structures 
syntaxiques reviennent r&#233;guli&#232;rement. A l&#146;oppos&#233;, dans le Code civil, les redondances, 
r&#233;p&#233;titions, reformulations sont &#233;vit&#233;es. Cela se r&#233;percute de fa&#231;on assez sensible sur la 
richesse des r&#233;sultats fournis par UPERY sur chacun des 2 corpus, puisque dans le corpus REA 
30% des syntagmes nominaux et 47% des noms, de fr&#233;quence sup&#233;rieure ou &#233;gale &#224; 5, sont 
rapproch&#233;s d&#146;au moins un autre mot, alors qu&#146;ils ne sont que respectivement 20% et 43% pour 
le corpus du Code civil. Le ph&#233;nom&#232;ne est encore plus accentu&#233; dans le corpus LIVRE du 
projet VERRE. La taille du corpus est relativement r&#233;duite (100 000 mots, contre 400 000 
pour le corpus REA et 150 000 pour le Code civil) et les redondances sont tr&#232;s faibles 
(chaque chapitre traite d&#146;un sujet sp&#233;cifique, et l&#146;auteur s&#146;efforce de varier son style). De ce 
fait, seuls 3% des SN et 18% des noms, de fr&#233;quence sup&#233;rieure ou &#233;gale &#224; 5, ont des voisins,. 
</p>
<p>5.2.3 Extraction des relations : YAKWA et CAMELEON 
</p>
<p>D&#233;velopp&#233; &#224; l&#146;ERSS par L. Tanguy, YAKWA est un concordancier pour corpus &#233;tiquet&#233;s 
(Rebeyrolle et Tanguy, 2000). Il permet de rechercher des phrases et/ou des paragraphes 
contenant une s&#233;quence d&#233;finie par des marqueurs. Ce marqueurs s&#146;appuient sur les 
informations not&#233;es par l&#146;&#233;tiqueteur dans les corpus, comme les cat&#233;gories grammaticales des 
mots. Leur contenu peut &#234;tre form&#233; de formes lexicales (tronqu&#233;es, exactes, etc.), de formes 
canoniques des unit&#233;s lexicales du texte, de cat&#233;gories morpho-syntaxiques et de leur 
combinaisons (disjonctions, conjonction de marqueur lexical et de marqueur morpho-
syntaxique), de la n&#233;gation d'un des types de marqueurs pr&#233;c&#233;dents ou de jokers (mots non 
comptabilis&#233;s). YAKWA peut s&#146;adapter &#224; tout type d&#146;&#233;tiqueteur, par exemple CORDIAL 
universit&#233; pour le fran&#231;ais ou TREETAGGER pour l&#146;anglais. Son interface guide la construction 
de marqueurs et permet d&#146;en visualiser la projection sur un corpus. 
</p>
<p>CAMELEON est un logiciel de recherche de relations lexicales &#224; partir de marqueurs 
linguistiques (S&#233;gu&#233;la, 1999). Il est associ&#233; &#224; un module de mod&#233;lisation qui permet de 
valider (ou de rejeter) ces relations lexicales pour les int&#233;grer sous forme de relations 
s&#233;mantiques dans un mod&#232;le conceptuel. Les marqueurs utilis&#233;s dans CAMELEON peuvent &#234;tre 
des marqueurs g&#233;n&#233;riques pr&#233;d&#233;finis ou leur adaptation ou encore des marqueurs sp&#233;cifiques 
d&#233;finis par l&#146;utilisateur. L&#146;id&#233;e est de rechercher des relations avec des moyens adapt&#233;s au 
corpus &#233;tudi&#233;. Les relations sont donc g&#233;n&#233;riques (comme EST-UN) ou sp&#233;cifiques au corpus 
(comme &#171; used-in &#187; dans le projet VERRE), et les marqueurs associ&#233;s &#224; toutes les relations 
sont revus et adapt&#233;s &#224; chaque corpus. Le langage d&#146;expression des marqueurs est moins riche 
que celui de YAKWA car CAMELEON fonctionne sur un corpus brut non &#233;tiquet&#233;. En revanche, 
Cam&#233;l&#233;on pr&#233;sente deux points forts pour la construction de RTO : il propose une base 
g&#233;n&#233;rique de relations et de marqueurs associ&#233;s ; il s&#146;appuie sur les r&#233;sultats de SYNTEX pour 
sugg&#233;rer les concepts qui pourraient &#234;tre en relation &#224; partir de la forme lexicale trouv&#233;e.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault et N. Aussenac-Gilles 
</p>
<p>6 Le probl&#232;me de l&#146;&#233;valuation 
</p>
<p>Nous terminerons par quelques r&#233;flexions sur le probl&#232;me de l&#146;&#233;valuation. Il faut distinguer 
l&#146;&#233;valuation d&#146;une RTO particuli&#232;re construite dans un contexte particulier, de l&#146;&#233;valuation de 
tel outil ou tel outil de TAL d&#146;aide &#224; la construction de RTO. Dans les deux cas, il faut 
adopter une approche ing&#233;nierique, en adoptant les principes de base du g&#233;nie logiciel, ce qui 
exige, a minima, de prendre en compte autant que possible le contexte global d&#146;utilisation de 
la RTO ou de l&#146;outil. 
</p>
<p> En ce qui concerne les RTO, il faut distinguer validation et &#233;valuation. Dans le processus de 
construction d&#146;une RTO, il y a plusieurs moment de validation de la RTO, c&#146;est-&#224;-dire de 
moment o&#249; l&#146;analyste pr&#233;sente la ressource &#224; l&#146;experts (ou &#224; des experts), et lui (leur) 
demande de valider ou d&#146;invalider certains choix de mod&#233;lisation effectu&#233;s. Ces moments de 
validation sont d&#146;autant moins nombreux que les experts sont peu disponibles. Ce sont donc 
des &#233;tapes tr&#232;s importantes dans le processus. L&#146;enjeu est de s&#146;assurer avec les experts que la 
conceptualisation repr&#233;sent&#233;e dans la RTO n&#146;est pas en contradiction sur tel ou tel point avec 
les connaissances expertes. Le probl&#232;me ne se pose pas tant en terme de v&#233;rit&#233;, qu&#146;en terme 
de non violation des connaissances de l&#146;expert. En effet, pour construire la mod&#233;lisation, 
l&#146;analyste a adopt&#233; un point de vue, celui de l&#146;application cible dans laquelle sera int&#233;gr&#233;e la 
ressource, qui n&#146;est pas n&#233;cessairement exactement celui de l&#146;expert dans son activit&#233;. La 
t&#226;che n&#146;est pas simple. L&#146;analyste doit aider l&#146;expert, qui ne reconna&#238;t pas n&#233;cessairement &#224; 
premi&#232;re vue ses petits, &#224; prendre le recul n&#233;cessaire pour d&#233;celer la pr&#233;sence d&#146;erreurs, voire 
d&#146;absences, flagrantes. Une fois la RTO construite, s&#146;engage un processus d&#146;&#233;valuation. 
Comme nous l&#146;avons d&#233;j&#224; &#233;voqu&#233;, l&#146;&#233;valuation doit &#234;tre r&#233;alis&#233;e selon les proc&#233;dures de base 
du g&#233;nie logiciel. Il s&#146;agit de v&#233;rifier si la RTO satisfait bien le cahier des charges et r&#233;pond 
aux attentes sp&#233;cifi&#233;es au d&#233;but du projet. La difficult&#233;, habituelle, est que l&#146;ontologie n&#146;est 
qu&#146;un &#233;l&#233;ment de l&#146;application cible, qui est le dispositif &#224; valider. Il faut donc concevoir des 
exp&#233;riences et des bancs d&#146;essais qui permettent de cibler l&#146;&#233;valuation sur la seule ressource. 
Une fois ces g&#233;n&#233;ralit&#233;s affirm&#233;es, nous pouvons difficilement aller au-del&#224;, parce que nous 
manquons encore de retour d&#146;exp&#233;rience, et parce que chaque cas &#233;tant particulier il sera de 
toutes fa&#231;ons difficile de d&#233;finir des proc&#233;dures &#224; la fois pr&#233;cises et relativement g&#233;n&#233;riques, 
et que cela d&#233;passe quelque peu le cadre de la recherche. 
</p>
<p>L&#146;&#233;valuation des outils de construction de RTO est le probl&#232;me qui nous concerne ici. C&#146;est 
un probl&#232;me lui aussi difficile. La source des difficult&#233; est double : d&#146;abord il s&#146;agit d&#146;outils 
d&#146;aide, ensuite chaque outil est rarement utilis&#233; seul. Quand il s&#146;agit d&#146;&#233;valuer d&#146;un outil 
automatique, du type  &#171; boite noire &#187;, il est possible d&#146;&#233;valuer les performances de l&#146;outil en 
comparant les r&#233;sultats qu&#146;il fournit &#224; des r&#233;sultats attendus (&#171; gold standard &#187;). En revanche, 
la situation est plus complexe dans le cas des outils d&#146;aide qui nous int&#233;ressent ici. Les 
r&#233;sultats fournis par les outils sont interpr&#233;t&#233;s par l&#146;analyste, et le r&#233;sultat de cette 
interpr&#233;tation est variable : une modification, un enrichissement de la ressource &#224; un ou 
plusieurs points du r&#233;seau, voire dans certain cas l&#146;absence d&#146;action imm&#233;diate, sans que cela 
signifie n&#233;cessairement que les r&#233;sultats en question soient faux ni m&#234;me on pertinents. De 
plus, chaque cette interpr&#233;tation s&#146;appuie normalement sur une confirmation par retour aux 
textes. Il  n&#146;y a pas syst&#233;matiquement de trace directe entre un r&#233;sultats (ou un ensemble de 
r&#233;sultats) de l&#146;outil et telle ou telle portion de la ressource. Si on rajoute &#224; cela, qu&#146;une portion 
de RTO n&#146;a de sens que dans la globalit&#233; de la ressource, et la ressource elle-m&#234;me ne peut 
&#234;tre &#233;valu&#233;e qu&#146;en contexte, on saisit l&#146;ampleur de la t&#226;che.. Il y a un tel parcours interpr&#233;tatif 
entre les r&#233;sultats de l&#146;outil et la ressource construite que le mode d&#146;&#233;valuation par </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Construction d&#146;ontologies &#224; partir de textes 
</p>
<p>comparaison entre les r&#233;sultats de l&#146;outil et une ressource de r&#233;f&#233;rence ne peut apporter 
limit&#233;s, m&#234;me si cela peut donner des indications tr&#232;s int&#233;ressantes pour faire &#233;voluer l&#146;outil 
(Nazarenko et al., 2001). L&#224; encore, nous n&#146;avons de solution miracle &#224; proposer. L&#146;id&#233;al 
serait par exemple de comparer entre termes de temps de r&#233;alisation et de qualit&#233; deux 
ressources ontologiques, l&#146;une construite avec tel outil, et l&#146;autre sans. Quand on conna&#238;t le 
temps de d&#233;veloppement d&#146;une ontologie, on imagine la lourdeur, et la difficult&#233; de mise en 
&#156;uvre d&#146;une telle m&#233;thodologie. Le probl&#232;me reste ouvert. Pour mesurer, ne serait-ce que 
d&#146;un point de vue qualitatif, l&#146;int&#233;r&#234;t des outils, consid&#233;rons pour le moment qu&#146;il est 
primordial de les tester dans des contextes nombreux et vari&#233;s et aussi r&#233;els que possible pour 
faire avancer la recherche.  
</p>
<p>R&#233;f&#233;rence 
</p>
<p>Ait El Mekki T., Nazarenko A (2002), Comment aider un auteur &#224; construire l'index d'un 
ouvrage ?, Actes du Colloque International sur la Fouille de Texte CIFT'2002, Y. Toussaint 
et C. Nedellec Eds., oct. 2002, pp. 141-158 
</p>
<p>Assadi H. (1998), Construction d&#146;ontologies &#224; partir de textes techniques. Application aux 
syst&#232;mes documentaires, th&#232;se de l&#146;Universit&#233; Paris 6 
</p>
<p>Aussenac-Gilles N. (1999), GEDITERM, un logiciel de gestion de bases de connaissances 
terminologiques, in Actes des Journ&#233;es Terminologie et Intelligence Artificielle (TIA&#146;99), 
Nantes, Terminologies Nouvelles n&#176;19, 111-123.  
</p>
<p>Aussenac N., S&#233;gu&#233;la P. (2000), Les relations s&#233;mantiques : du linguistique au formel. 
Cahiers de grammaire, N&#176; sp&#233;cial sur la linguistique de corpus. A. Condamines (Ed.) Vol 25. 
D&#233;c. 2000. Toulouse : Presse de l&#146;UTM. Pp 175-198. 
</p>
<p>Aussenac-Gilles N., Bi&#233;bow B., Szulman N. (2000), Revisiting Ontology Design: a method 
based on corpus analysis. Knowledge engineering and knowledge management: methods, 
models and tools, Proc. of the 12th International Conference on Knowledge Engineering and 
Knowledge Management. Juan-Les-Pins (F). Oct 2000. R Dieng and O. Corby (Eds). Lecture 
Notes in Artificial Intelligence Vol 1937. Berlin: Springer Verlag. pp. 172-188. 
</p>
<p>Bachimont, B. (2000), Engagement s&#233;mantique et engagement ontologique : conception et 
r&#233;alisation d&#146;ontologies en ing&#233;nierie des connaissances &#187;. In J. Charlet et al. (eds), Ing&#233;nierie 
des Connaissances ; Evolutions r&#233;centes et nouveaux d&#233;fis, Eyrolles, pp. 305-323 
</p>
<p>Bourigault D. (2002), Upery : un outil d'analyse distributionnelle &#233;tendue pour la construction 
d&#146;ontologies &#224; partir de corpus, Actes de la 9&#232;me conf&#233;rence annuelle sur le Traitement 
Automatique des Langues (TALN 2002), Nancy, 2002, pp. 75-84 
</p>
<p>Bourigault D., Fabre C. (2000), Approche linguistique pour l'analyse syntaxique de corpus, 
Cahiers de Grammaires, n&#176; 25, 2000, Universit&#233; Toulouse - Le Mirail, pp. 131-151. 
</p>
<p>Bourigault D. &amp; Jacquemin C. (2000), Construction de ressources terminologiques, in J.-M. 
Pierrel (&#233;d.), Industrie des langues, Herm&#232;s, Paris, pp. 215-233 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D. Bourigault et N. Aussenac-Gilles 
</p>
<p>Charlet J., Zacklad M., Kassel G. &amp; Bourigault D. (eds) (2000), Ing&#233;nierie des 
connaissances : &#233;volutions r&#233;centes et nouveaux d&#233;fis, Eyrolles : Paris - Collection technique 
et scientifique des t&#233;l&#233;communications 
</p>
<p>Charlet J. (2002), L&#146;ing&#233;nierie des connaissances : r&#233;sultats, d&#233;veloppements et perspectives 
pour la gestion des connaissances m&#233;dicales. M&#233;moire d&#146;habilitation &#224; diriger des recherches, 
universit&#233; Pierre et Marie Curie 
</p>
<p>Chaumier J. (1988), Travail et m&#233;thodes du/de la documentaliste : Connaissance du 
probl&#232;me, Applications pratiques. 3e &#233;d. mise &#224; jour et compl&#233;t&#233;e. Paris : ESF, 1988 
</p>
<p>Condamines A. et Rebeyrolles J (2000), Construction d'une base de connaissances 
terminologiques &#224; partir de textes : exp&#233;rimentation et d&#233;finition d'une m&#233;thode. In Charlet J, 
Zacklad M., Kassel G. &amp; Bourigault D. &#233;ds. Ing&#233;nierie des connaissances. Tendances 
actuelles et nouveaux d&#233;fis. Editions Eyrolles/France Telecom, Paris 
</p>
<p>Daille B. (1994), Approche mixte pour l'extraction de terminologie : statistique lexicale et 
filtres linguistiques. Th&#232;se en Informatique Fondamentale, Universit&#233; de Paris 7, Paris 
</p>
<p>David S. et Plante P. (1990), De la n&#233;cessit&#233; d'une approche morpho-syntaxique dans l'analyse 
de textes. Intelligence Artificielle et Sciences Cognitives au Qu&#233;bec, 3(3):140-154 
</p>
<p>Enguehard C. et Pantera L. (1995), Automatic natural acquisition of a terminology. Journal of 
Quantitative Linguistics, 2(1):27-32 
</p>
<p>Faure D. (2000), Conception de m&#233;thode d'apprentissage symbolique et automatique pour 
l'acquisition de cadres de sous-cat&#233;gorisation de verbes et de connaissances s&#233;mantiques &#224; 
partir de textes : le syst&#232;me ASIUM, th&#232;se de Doctorat Universit&#233; de Paris Sud  
</p>
<p>Garcia D. (1998), Analyse automatique de textes pour l&#146;organisation causale des actions. 
R&#233;alisation du syst&#232;me informatique COATIS. Th&#232;se en informatique. Universit&#233; Paris IV 
</p>
<p>Grefenstette G. (1994), Explorations in Automatic Thesaurus Discovery. Kluwer Academic 
Publisher, Boston, MA 
</p>
<p>Habert B., Naulleau E. et Nazarenko A . (1996), Symbolic word clustering for medium-size 
corpora. Proceedings of the 16th International Conference on Computational Linguistics 
(COLING'96), Copenhagen, pp 490-495 
</p>
<p>Jacquemin C. (1997), Variation terminologique : Reconnaissance et acquisition automatiques 
de termes et de leurs variantes en corpus. M&#233;moire d'habilitation &#224; diriger des recherches en 
informatique fondamentale, Universit&#233; de Nantes 
</p>
<p>Lame G. (2002), Construction d&#146;ontologie &#224; partir de textes. Une ontologie du Droit fran&#231;ais 
d&#233;di&#233;e &#224; la recherche d&#146;information sur le Web, th&#232;se de l&#146;Ecole des Mines de Paris 
</p>
<p>Maedche A. &amp; Staab S. (2000), Mining Ontologies from Text. In Knowledge Engineering and 
Knowledge management: methods, models and tools, proceedings of EKAW2000. R. Dieng 
and O. Corby (Eds). Bonn : Springer Verlag. LNAI 1937.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Construction d&#146;ontologies &#224; partir de textes 
</p>
<p>Maynard D. et Ananiadou S. (2001),  Term extraction using a similarity-based approach, in 
Bourigault D., Jacquemin C. &amp; L&#146;Homme M.-C., Recent advances in computational 
terminology, John Benjamins Publishing, Amsterdam, pp 261-278 
</p>
<p>Morin E. (1999), Des patrons lexico-syntaxiques pour aider au d&#233;pouillement 
terminologiques, Traitement Automatique des Langues, volume 40, Num&#233;ro 1, pp. 143-166 
</p>
<p>Nazarenko A., Zweigenbaum P., Habert B. &amp; Bouaud J. (2001),  Corpus-based extension of a 
terminological semantic lexicon, in Bourigault D., Jacquemin C. &amp; L&#146;Homme M.-C., Recent 
advances in computational terminology, John Benjamins Publishing, Amsterdam, pp 327-352 
</p>
<p>Rastier F. (1991), S&#233;mantique et recherches cognitives, Presses Universitaires de France, 
Paris, 1991 
</p>
<p>Rastier F. (1995), Le terme : entre ontologie et linguistique, Actes des 1&#232;res Journ&#233;es 
&#147; Terminologie et Intelligence Artificielle&#148;, Villetaneuse, avril 1995, La banque des mots, 
Num&#233;ro sp&#233;cial 7-1995, pp. 35-65 
</p>
<p>Rousselot F., Frath P. et Oueslati R. (1996), Extracting concepts and relations from corpora, 
Procedings of the 12th European Conference on Artificial Intelligence (ECAI&#146;96), workshop 
on Corpus-Oriented Semantic Analysis, Budapest 
</p>
<p>S&#233;gu&#233;la P. et Aussenac-Gilles N. (1999), Extraction de relations s&#233;mantiques entre termes et 
enrichissement de mod&#232;les du domaine, Actes de la conf&#233;rence Ing&#233;nierie des Connaissances 
(IC'99), Paris, pp 79-88  
</p>
<p>Slodzian M. (2000), L'&#233;mergence d'une terminologie textuelle et le retour du sens, in Le sens 
en terminologie, publication du Centre de Recherche en Terminologie et Traduction de 
l&#146;Universit&#233; Lyon 2 
</p>
<p>Sparck Jones K. (1971), Automatic Keyword Classification for Information Retrieval. 
Butterworth, London 
</p>
<p>Szulman S., Bi&#233;bow B. &amp; Aussenac-Gilles N. (2002), Structuration de Terminologies &#224; l&#146;aide 
d&#146;outils d&#146;analyse de textes avec TERMINAE, Traitement Automatique de la Langue (TAL). 
Num&#233;ro sp&#233;cial sur le Structuration de Terminologie. Eds A. Nazarenko, T. Hammon. Vol43, 
N&#176;1; pp 103-128. 2002.  
</p>
<p>Toussaint Y., Namer F., Daille B., Jacquemin C., Royaut&#233; J. et Hathout N. (1998), Une 
approche linguistique et statistique pour l&#146;analyse de l&#146;information en corpus. Actes de la 5&#232;me 
conf&#233;rence annuelle sur le Traitement Automatiques des Langues Naturelles (TALN&#146;98), 
Paris, pp. 182-191 
</p>
<p>Velardi P., Missikoff M. &amp; Basili R. (2001) Identification of relevant terms to support the 
construction of domain ontologies. In ACL WS on Human Language Technologies and 
Knowledge Management. Toulouse (F), July 6-7, 2001. 18-28. 
</p>
<p>Zweigenbaum P. (1999) Encoder l'information m&#233;dicale : des terminologies aux syst&#232;mes de 
repr&#233;sentation des connaissances. Innovation Strat&#233;gique en Information de Sant&#233; 1999(23) </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p> </p>

</div></div>
</body></html>