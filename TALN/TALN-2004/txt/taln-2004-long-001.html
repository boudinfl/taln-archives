<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Evaluation de m&#233;thodes de segmentation th&#233;matique lin&#233;aire non supervis&#233;es apr&#232;s adaptation au fran&#231;ais</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2004, F&#232;s, 19&#8211;21 avril 2004
</p>
<p>Evaluation de m&#233;thodes de segmentation th&#233;matique lin&#233;aire
non supervis&#233;es apr&#232;s adaptation au fran&#231;ais
</p>
<p>Laurianne Sitbon, Patrice Bellot
Laboratoire d&#8217;Informatique d&#8217;Avignon - Universit&#233; d&#8217;Avignon
</p>
<p>339, chemin des Meinajaries - Agroparc BP 1228
84911 AVIGNON Cedex 9 - FRANCE
</p>
<p>T&#233;l : +33 (0) 4 90 84 35 09, Fax : +33 (0) 4 90 84 35 01
{laurianne.sitbon, patrice.bellot}@lia.univ-avignon.fr
</p>
<p>R&#233;sum&#233; - Abstract
</p>
<p>Nous proposons une &#233;valuation de diff&#233;rentes m&#233;thodes et outils de segmentation th&#233;matique
de textes. Nous pr&#233;sentons les outils de segmentation lin&#233;aire et non supervis&#233;e DotPlotting,
Segmenter, C99, TextTiling, ainsi qu&#8217;une mani&#232;re de les adapter et de les tester sur des docu-
ments fran&#231;ais. Les r&#233;sultats des tests montrent des diff&#233;rences en performance notables selon
les sujets abord&#233;s dans les documents, et selon que le nombre de segments &#224; trouver est fix&#233; au
pr&#233;alable par l&#8217;utilisateur. Ces travaux font partie du projet Technolangue AGILE-OURAL 1.
</p>
<p>This paper presents an empirical comparison between different methods for segmenting texts.
After presenting segmentation tools and more specifically linear segmentation algorithms, we
present a comparison of these methods on both French and English text corpora. This evalu-
tation points out that the performance of each method heavilly relies on the topic of the docu-
ments, and the number of boundaries to be found. This work is part of the project Technolangue
AGILE-OURAL.
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>Segmentation th&#233;matique, m&#233;triques de Beeferman et WindowDiff, coh&#233;sion lexicale, cha&#238;nes
lexicales
Topic segmentation, WindowDiff and Beeferman measures, lexical cohesion, lexical chains
</p>
<p>1 Introduction
</p>
<p>La segmentation d&#8217;un texte peut am&#233;liorer significativement les performances en recherche
d&#8217;information (J.Callan, 1994), en donnant une partie de document correspondant &#224; la requ&#234;te,
</p>
<p>1http://www.technolangue.net/article.php3?id_article=79</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L.Sitbon, P. Bellot
</p>
<p>et en indexant les documents de mani&#232;re plus pr&#233;cise. Elle peut aussi d&#233;terminer les limites entre
des articles dans un flux d&#8217;informations (broadcast news), t&#226;che repr&#233;sent&#233;e dans TDT (Topic
Detection and Tracking). Enfin, elle peut repr&#233;senter une importante part dans un processus de
r&#233;sum&#233; automatique de textes, comme dans TXTRACTOR (McDonald &amp; Chen, 2002). Apr&#232;s
segmentation, les blocs sont &#233;valu&#233;s afin de conserver les plus pertinents, ou on produit un
r&#233;sum&#233; pour chaque th&#232;me abord&#233;, donc pour chaque segment.
Nous nous sommes int&#233;ress&#233;s aux m&#233;thodes non supervis&#233;es et produisant une segmentation
lin&#233;aire (les segments trouv&#233;s sont adjacents). Nous avons test&#233; quelques uns des outils les plus
courants parmi lesquels DotPlotting (Reynar, 2000), C99 (Choi, 2000), Segmenter (Kan et al.,
1998), et Text Tiling (Hearst, 1997) - voir section 2. Ils ont &#233;t&#233; impl&#233;ment&#233;s et compar&#233;s pour
l&#8217;anglais par (Choi, 2000), mais a priori aucune comparaison de ces outils n&#8217;a &#233;t&#233; publi&#233;e pour
des documents en fran&#231;ais. Nous avons &#233;tudi&#233; leur comportement sur des textes fran&#231;ais, apr&#232;s
avoir effectu&#233; des adaptations liguistiques et cr&#233;&#233; un corpus fran&#231;ais. Ces tests permettent de
mettre en lumi&#232;re d&#8217;une part les diff&#233;rences existant entre l&#8217;efficacit&#233; des outils, et d&#8217;autre part
des diff&#233;rences entre les langues, les cat&#233;gories de documents trait&#233;s, et la taille des segments.
</p>
<p>2 M&#233;thodes de segmentation lin&#233;aire non supervis&#233;e
</p>
<p>Les m&#233;thodes utilis&#233;es s&#8217;appuient sur la notion de coh&#233;sion lexicale (Halliday &amp; Hasan, 1976),
c&#8217;est &#224; dire la r&#233;p&#233;tition des mots comme indicateur d&#8217;homog&#233;n&#233;it&#233; th&#233;matique. Nous pr&#233;sen-
tons tout d&#8217;abord deux m&#233;thodes bas&#233;es sur la notion de cha&#238;ne lexicale, puis deux autres fon-
d&#233;es sur la seule r&#233;partition des mots.
</p>
<p>2.1 Segmenter : cha&#238;nes lexicales
</p>
<p>Segmenter (Kan et al., 1998) effectue une segmentation lin&#233;aire bas&#233;e sur les cha&#238;nes lexicales
pr&#233;sentes dans le texte. Ces chaines relient les occurrences des termes dans les phrases. Une
cha&#238;ne est rompue si le nombre de phrases s&#233;parant deux occurrences est trop important. Ce
nombre d&#233;pend de la cat&#233;gorie syntaxique du terme consid&#233;r&#233;. Une fois tous les liens &#233;tablis,
un poids leur est assign&#233; en fonction de la cat&#233;gorie syntaxique des termes en jeu et de la
longueur du lien. Un score est ensuite donn&#233; &#224; chaque paragraphe en fonction des poids et des
origines des liens qui le traversent ou qui y sont cr&#233;&#233;s. Les marques de segmentation sont alors
appos&#233;es au d&#233;but des paragraphes ayant les scores maximaux.
Etant donn&#233; qu&#8217;un concept peut &#234;tre d&#233;sign&#233; par un ensemble de mots, le concept de cha&#238;nes
lexicales a &#233;t&#233; &#233;largi aux cha&#238;nes conceptuelles &#224; l&#8217;aide de WordNet (Fellbaum, 1998) ou
d&#8217;autres ressources s&#233;mantiques. (Kan et al., 1998) montre que l&#8217;am&#233;lioration est tr&#232;s peu si-
gnificative.
</p>
<p>2.2 Text Tiling : multicrit&#232;res sur la r&#233;partition des termes
</p>
<p>Text Tiling (Hearst, 1997) &#233;tudie la distribution des termes selon plusieurs crit&#232;res. Un score de
coh&#233;sion est attribu&#233; &#224; chacun des blocs de texte en fonction du bloc qui le suit. Ce score d&#233;pend
lui-m&#234;me d&#8217;un second score attribu&#233; &#224; chaque paire de phrases suivant la paire de phrases qui
la suit. Ce second score est calcul&#233; en tenant compte des mots communs, du nombre de mots</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Evaluation de m&#233;thodes de segmentation en fran&#231;ais
</p>
<p>nouveaux, et du nombre de cha&#238;nes lexicales actives dans les phrases consid&#233;r&#233;es.
Le score d&#8217;un segment de texte est alors le produit scalaire normalis&#233; des scores de chaque paire
de phrases qu&#8217;il contient. Si l&#8217;&#233;cart entre le score d&#8217;un segment et les scores du segment qui le
pr&#233;c&#232;de et du segment qui le suit est grand, une fronti&#232;re est appos&#233;e &#224; l&#8217;int&#233;rieur de ce segment.
La rupture entre deux unit&#233;s th&#233;matiques est situ&#233;e dans une zone du texte entour&#233;e de zones
pr&#233;sentant des valeurs de coh&#233;sion tr&#232;s diff&#233;rentes de la sienne.
</p>
<p>2.3 Dot Plotting : r&#233;p&#233;tition de termes
</p>
<p>L&#8217;algorithme que nous utilisons est propos&#233; par (Reynar, 2000), et est en fait une adaptation
pour la segmentation de la m&#233;thode des nuages de points pr&#233;sent&#233;e par (Helfman, 1994) pour la
recherche d&#8217;information. Il se base sur une repr&#233;sentation graphique du texte par les positions
des occurrences des termes du texte &#224; segmenter. Lorsqu&#8217;un terme appara&#238;t &#224; deux positions du
texte x et y, les quatre points (x, x), (x, y), (y, x) et (y, y) sont repr&#233;sent&#233;s sur un graphe, ce qui
permet de d&#233;terminer visuellement les zones du texte o&#249; les r&#233;p&#233;titions sont nombreuses.
Cette m&#233;thode est adapt&#233;e par (Reynar, 2000) &#224; la segmentation th&#233;matique de textes. Les po-
sitions de d&#233;but et de fin des zones les plus denses du graphe sont les limites des segments th&#233;-
matiquement coh&#233;rents. La densit&#233; est calcul&#233;e pour chaque unit&#233; d&#8217;aire en divisant le nombre
de points d&#8217;une r&#233;gion par l&#8217;aire de cette r&#233;gion. A partir de l&#224;, deux algorithmes peuvent d&#233;-
terminer les fronti&#232;res th&#233;matiques : indentifier les limites en maximisant la densit&#233; au sein des
segments, ou rep&#233;rer la configuration qui minimise la densit&#233; des zones entre les segments.
</p>
<p>2.4 C99 : mesure de similarit&#233;
</p>
<p>Cet algorithme propos&#233; par (Choi, 2000) utilise une mesure de similarit&#233; entre chaque unit&#233;
textuelle. L&#8217;id&#233;e de base de cette m&#233;thode est que les mesures de similarit&#233; entre des segments
de textes courts sont statistiquement insignifiantes, et que donc seul des classements locaux
(voir ci-dessous) sont &#224; consid&#233;rer pour ensuite appliquer un algorithme de cat&#233;gorisation sur
la matrice de similarit&#233;. Dans un premier temps, une matrice de similarit&#233; est donc construite,
repr&#233;sentant la similarit&#233; entre toutes les phrases du texte &#224; l&#8217;aide de la mesure de similarit&#233;
propos&#233;e par (Rijsbergen, 1979), calcul&#233;e pour chaque paire de phrases du texte, en utilisant
chaque mot commun entre les phrases, et apr&#232;s &#171; nettoyage &#187; du texte : suppression des mots
vides et lemmatisation.
On effectue ensuite un &#171; classement local &#187;, en d&#233;terminant pour chaque paire d&#8217;unit&#233;s tex-
tuelles, le rang de sa mesure de similarit&#233; par rapport &#224; ses m &#215; n &#8722; 1 voisins, m &#215; n &#233;tant le
masque de classement choisi. Le rang est le nombre d&#8217;&#233;l&#233;ments voisins ayant une mesure de
similarit&#233; plus faible, conserv&#233; sous la forme d&#8217;un ratio r afin de prendre en compte les effets
de bord.
</p>
<p>r =
rang
</p>
<p>nombre de voisins dans le masque
</p>
<p>Enfin, la derni&#232;re &#233;tape d&#233;termine les limites de chaque segment de la m&#234;me mani&#232;re que l&#8217;algo-
rithme Dotplotting (voir section 2.1) emploie la maximisation. En effet on cherche &#224; d&#233;terminer
quelle configuration offre la plus grande densit&#233;, en recherchant une nouvelle limite th&#233;matique
&#224; chaque &#233;tape. Les segments sont alors repr&#233;sent&#233;s par des carr&#233;s le long de la diagonale de la
matrice de similarit&#233; modifi&#233;e avec les classements locaux. Pour chaque segment de la r&#233;parti-
tion propos&#233;e &#224; une &#233;tape de la segmentation on consid&#232;re son aire not&#233;e ak et son poids sk qui</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L.Sitbon, P. Bellot
</p>
<p>est la somme des tous les rangs des phrases qu&#8217;il contient. On calcule alors la densit&#233; D de la
configuration avec :
</p>
<p>D =
&#8721;m
</p>
<p>k=1 sk&#8721;m
k=1 ak
</p>
<p>L&#8217;algorithme s&#8217;arr&#234;te lorsque la densit&#233; de la meilleure r&#233;partition propos&#233;e est suffisamment
faible, ou si le nombre de fronti&#232;res th&#233;matiques est d&#233;j&#224; d&#233;termin&#233;, lorsqu&#8217;il est atteint.
</p>
<p>3 Adaptation au fran&#231;ais et mise en place des tests
</p>
<p>Nous avons adapt&#233; les impl&#233;mentations effectu&#233;es par (Choi, 2000 ; http://www.cs.man.
ac.uk/~mary/choif/software.html) au fran&#231;ais. Une liste de mots vides permet de
retirer du texte les mots trop communs et donc non suffisamment porteurs de sens pour les
m&#233;thodes utillis&#233;es. De plus, &#233;tant tr&#232;s courants, ils peuvent fausser les mesures de similarit&#233;
ou les cha&#238;nes lexicales en incluant des r&#233;p&#233;titions de termes suppl&#233;mentaires et non pertinentes
th&#233;matiquement. La liste de mots fran&#231;ais utilis&#233;e se trouve dans (Veronis, 2004).
L&#8217;algorithme de Porter pour le stemming (Porter, 1980) est efficace pour l&#8217;anglais mais inadapt&#233;
au fran&#231;ais. Nous l&#8217;avons donc remplac&#233; par une impl&#233;mentation de Snowball (Porter, 2001),
avec un fichier de param&#232;tres pour le fran&#231;ais livr&#233; avec l&#8217;outil.
L&#8217;&#233;tiquetage morpho-syntaxique est utilis&#233; par l&#8217;outil Segmenter, et permet d&#8217;&#233;liminer de
l&#8217;analyse certaines cat&#233;gories non sp&#233;cifiquement porteuses de th&#232;me. Nous avons utilis&#233; Tree
Tagger, pr&#233;sent&#233; par (Schmid, 1994). Comme les &#233;tiquettes morphosyntaxiques ne sont plus les
m&#234;mes d&#8217;une langue &#224; l&#8217;autre, il a &#233;galement fallu changer l&#8217;interpr&#233;tation de l&#8217;&#233;tiquetage au
niveau du code. Ce changement &#233;tant sp&#233;cifique &#224; chaque langue et non d&#233;pendant d&#8217;un fichier
de param&#232;tres, il est plus compliqu&#233; de porter Segmenter &#224; une autre langue par la suite.
</p>
<p>3.1 M&#233;triques d&#8217;&#233;valuation
</p>
<p>Les deux standards d&#8217;&#233;valuation que sont le rappel et la pr&#233;cision (Baeza-Yates &amp; Ribeiro-
Neto, 1999), utilis&#233;s en recherche d&#8217;information, ont &#233;t&#233; employ&#233;s pour &#233;valuer les premiers
algorithmes de segmentation. Mais une baisse de l&#8217;un entra&#238;ne g&#233;n&#233;ralement une hausse de
l&#8217;autre, et dans notre cas on ne cherche pas &#224; en favoriser un, mais &#224; &#233;valuer l&#8217;efficacit&#233; des
algorithmes pour la segmentation. De plus ils &#233;valuent la pr&#233;sence ou non d&#8217;une fronti&#232;re &#224; sa
place de r&#233;f&#233;rence, mais ne permettent pas de diff&#233;rencier une erreur faible (un d&#233;calage d&#8217;une
phrase) d&#8217;une erreur grave (un oubli de fronti&#232;re).
(Beeferman et al., 1997) propose une nouvelle mesure, Pk, qui prend en compte la distance
entre une limite trouv&#233;e et celle qui aurait d&#251; &#234;tre trouv&#233;e. Elle &#233;value une probabilit&#233; d&#8217;erreur
sur la segmentation prenant en compte la probabilit&#233; pour deux phrases &#233;loign&#233;es d&#8217;une distance
k (valant la moiti&#233; de la longueur moyenne des segments du document) d&#8217;&#234;tre localement dans
les m&#234;mes segments du document de r&#233;f&#233;rence (ref ) et du document produit par l&#8217;outil (hyp),
c&#8217;est &#224; dire qu&#8217;aucune fronti&#232;re th&#233;matique ne les s&#233;pare dans les deux cas.
(Pevzner &amp; Hearst, 2002) montre que la mesure Pk propos&#233;e par Beeferman, bien que meilleure
que le rappel/pr&#233;cision, a encore des d&#233;fauts (des erreurs de m&#234;me type sont p&#233;nalis&#233;es diff&#233;re-
ment, les ajouts de petits segments sont ignor&#233;s, la signification de la mesure n&#8217;est pas claire).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Evaluation de m&#233;thodes de segmentation en fran&#231;ais
</p>
<p>Ils ont donc propos&#233; une nouvelle mani&#232;re d&#8217;&#233;valuer les algorithmes de segmentation, appe-
l&#233;e WindowDiff, fortement inspir&#233;e de Pk. En fait cette nouvelle mesure prend en compte le
nombre de fronti&#232;res s&#233;parant deux phrases espac&#233;es d&#8217;une distance k.
</p>
<p>WindowDiff(ref, hyp) = 1
N &#8722; k
</p>
<p>&#8721;
(|b(refi, refi+k)&#8722; b(hypi, hypi+k)|)
</p>
<p>o&#249; b(xi, xj) est le nombre de fronti&#232;res entre i et j dans le texte x, contenant N phrases.
(Pevzner &amp; Hearst, 2002) montre que cette mesure est d&#8217;une grande stabilit&#233; face aux variations
des tailles des segments, et qu&#8217;elle est aussi s&#233;v&#232;re avec les ajouts qu&#8217;avec les oublis de fron-
ti&#232;res th&#233;matiques. Cependant elle peut &#234;tre sup&#233;rieure &#224; 1, et ne peut donc plus &#234;tre assimil&#233;e
&#224; un taux d&#8217;erreur. Il est d&#233;sormais &#233;vident qu&#8217;elle n&#8217;est qu&#8217;un &#233;l&#233;ment de comparaison de la
fiabilit&#233; des m&#233;thodes, et non pas un indice absolu de leur qualit&#233;.
</p>
<p>3.2 Le corpus d&#8217;&#233;valuation.
</p>
<p>(Hearst, 1997) et (Kan et al., 1998) ont travaill&#233; sur peu de documents segment&#233;s manuelle-
ment. A la place, nous avons repris la m&#233;thode de (Choi, 2000) pour constituer un corpus de
tests m&#234;me si elle ne garantit pas que les segments assembl&#233;s aient pour autant une v&#233;ritable
discontinuit&#233; th&#233;matique. Cette m&#233;thode, si elle ne correspond pas &#224; un cas r&#233;el, pr&#233;sente l&#8217;avan-
tage d&#8217;&#234;tre rapidement applicable &#224; des corpus de nature diff&#233;rente. Nous avons ainsi choisi de
l&#8217;appliquer d&#8217;une part &#224; des articles du Monde (fortes discontinuit&#233;s th&#233;matiques) et, d&#8217;autre
part, &#224; des chapitres de la Bible (relative continuit&#233; stylistique et th&#233;matique mais fortes varia-
tion sur les entit&#233;s nomm&#233;es).
Un premier corpus a &#233;t&#233; r&#233;alis&#233; afin de d&#233;terminer l&#8217;influence des th&#232;mes et de la taille des
segments. Ce corpus est divis&#233; en 5 cat&#233;gories de documents : les articles journalistiques
de n&#8217;importe quel sujet, les articles journalistiques th&#233;matiquement coh&#233;rents : art, &#233;conomie,
sciences ou sport, et les chapitres litt&#233;raires. Pour chacune de ces cat&#233;gories, 4 ensembles de
100 documents ont &#233;t&#233; fabriqu&#233;s, avec pour chaque ensemble des crit&#232;res diff&#233;rents de tailles
de segments : des segments courts (entre 3 et 5 phrases), des segments moyens (entre 6 et
8 phrases), des segments longs (entre 9 et 11 phrases), ou des segments de tailles variables
(entre 3 et 11 phrases). Chaque document est constitu&#233; de 10 segments, qui sont autant de d&#233;-
but d&#8217;articles choisis al&#233;atoirement dans la cat&#233;gorie correspondant au crit&#232;re, et raccourcis &#224; la
longueur d&#233;finie par le crit&#232;re de taille. La base d&#8217;articles utilis&#233;e pour composer ce corpus est
l&#8217;ensemble des articles de l&#8217;ann&#233;e 2001 du Monde correspondant &#224; chaque crit&#232;re, et de plus de
10 phrases. A cette base s&#8217;ajoute un ensemble de chapitres de la Bible, pour la partie du corpus
concernant la litt&#233;rature. Ce corpus principal permet de tester de grandes variations dans la taille
des paragraphes.
Un second corpus plus petit a &#233;t&#233; constitu&#233;, o&#249; les segments sont des ensembles de paragraphes.
Il est constitu&#233; de 100 documents dont les segments sont issus de n&#8217;importe quelle cat&#233;gorie, et
comportent entre 3 et 5 paragraphes.
</p>
<p>4 Exp&#233;riences
</p>
<p>Une fois les transformations des outils effectu&#233;es, nous avons tout d&#8217;abord compar&#233; les r&#233;sultats
trouv&#233;s sur un corpus g&#233;n&#233;raliste en fran&#231;ais &#224; ceux trouv&#233;s sur un corpus g&#233;n&#233;raliste en anglais</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L.Sitbon, P. Bellot
</p>
<p>(Brown Corpus, utilis&#233; par (Choi, 2000)), afin de v&#233;rifier que les adaptations n&#8217;ont pas affect&#233;
certains outils. Quel que soit le test effectu&#233;, les r&#233;sultats sur les deux langues font appara&#238;tre
une diff&#233;rence constante de performance, d&#8217;une valeur d&#8217;environ 0,1 en faveur de l&#8217;anglais
selon la mesure WindowDiff. Cependant, cette diff&#233;rence &#233;tant faible, on peut consid&#233;rer que
les changements effectu&#233;s sur les outils sont valides.
</p>
<p>4.1 Evaluation avec un nombre de segments &#224; trouver non pr&#233;d&#233;fini
</p>
<p>Le tableau 1 repr&#233;sente, pour 5 impl&#233;mentations des m&#233;thodes (avec les param&#232;tres donnant les
meilleurs r&#233;sultats), la moyenne de la mesure WindowDiff sur tous les documents du corpus
principal. Ces impl&#233;mentations sont d&#233;crites dans le tableau 5 en annexe. Cela montre que C99
est l&#8217;outil le plus efficace, deux fois meilleur que TextTiling et Segmenter.
Le corpus utilis&#233;, en prenant les phrases comme unit&#233;s de traitement, restreint l&#8217;action de Seg-
menter et TextTiling pour la cr&#233;ation de cha&#238;nes lexicales, car ils se basent habituellement sur
des paragraphes, et donc les blocs unitaires &#233;tant plus courts, il est plus difficile d&#8217;y former
des cha&#238;nes lexicales avec les param&#232;tres de base. Nous avons donc compar&#233; les r&#233;sultats avec
ceux sur le second corpus, compos&#233; de paragraphes. La figure 1 montre que les diff&#233;rences sont
faibles pour les meilleures m&#233;thodes.
</p>
<p>JSegmenter 0,78
C99 basic 0,27
Text Tiling 0,53
JTextTile 0,9
Segmenter 0,50
</p>
<p>TAB. 1: Comparaison des m&#233;thodes pour les-
quelles le nombre de segments &#224; trouver n&#8217;est
pas pr&#233;d&#233;fini, selon la moyenne de la mesure
Window Diff sur l&#8217;ensemble du corpus fran&#231;ais
</p>
<p>Cat&#233;gories Tailles
Test no score Test no score
25 4 25 4
36 4 35 3
37 4 36 3
38 4 37 3
13 3 34 2
32 3 38 2
34 3
35 3
</p>
<p>TAB. 2: Meilleures impl&#233;mentations (voir Ta-
bleau 5 pour leur description) pour chaque ca-
t&#233;gorie, et pour chaque taille des segments
</p>
<p>4.2 Evaluation avec un nombre de segments &#224; trouver pr&#233;d&#233;fini
</p>
<p>Ces m&#233;thodes donnant des r&#233;sultats assez proches les uns des autres, nous avons cr&#233;&#233; une sorte
de tournoi afin de trouver les meilleures, selon des crit&#232;res de taille, ou selon chacune des
cat&#233;gories. Les 5 meilleures impl&#233;mentations &#224; chaque test re&#231;oivent un point, pour chaque
cat&#233;gorie d&#8217;une part, et chaque taille d&#8217;autre part. Le tableau 2 montre les r&#233;sultats de ce tournoi.
Il en ressort que C99 (tests 25 et 32 &#224; 38) est plus efficace que DotPlotting (test 15) lorsque le
nombre de fronti&#232;res th&#233;matiques &#224; trouver est connu &#224; l&#8217;avance.
</p>
<p>4.3 Utilisation d&#8217;un nombre approximatif de segments &#224; trouver
</p>
<p>Etant donn&#233; que les outils pour lesquels il faut fournir le nombre de segments &#224; trouver ont
naturellement des r&#233;sultats significativement meilleurs que les autres, nous les avons test&#233;s en
leur donnant un nombre diff&#233;rent de segments &#224; trouver, &#224; plus ou moins 5 segments du nombre
r&#233;el, afin de voir leur comportement dans le cas d&#8217;un nombre approximatif de limites.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Evaluation de m&#233;thodes de segmentation en fran&#231;ais
</p>
<p>FIG. 1: comparaison entre les r&#233;sultats pour le corpus principal, et le corpus secondaire, selon la mesure
Window Diff
</p>
<p>FIG. 2: r&#233;sultats suivant un nombre n variable de segments pr&#233;vus
</p>
<p>La figure 2 montre que m&#234;me avec une erreur d&#8217;un ordre de la moiti&#233; du nombre r&#233;el de seg-
ments, les r&#233;sultats sont aussi bons que les m&#233;thodes statistiques avec un nombre de segments
&#224; trouver connu et certains param&#232;tres, et sont meilleurs que TextTiling ou Segmenter dans
cette exp&#233;rimentation. Cela sugg&#232;re qu&#8217;on pourrait utiliser une granularit&#233; de segmentation d&#233;-
finie par l&#8217;utilisateur, sans baisser trop les performances par rapport &#224; des syst&#232;mes enti&#232;rement
automatiques qui ne permettent pas ce param&#233;trage.
</p>
<p>4.4 Efficacit&#233; par cat&#233;gorie ou par taille
</p>
<p>Le tableau 3 r&#233;sume l&#8217;&#233;valuation pour les trois impl&#233;mentations les plus performantes de chaque
cat&#233;gorie toutes tailles de segments confondues, et de chaque taille de segments toutes cat&#233;go-
ries confondues (moyenne arithm&#233;tique des scores). Les r&#233;sultats pour les segments entre 3 et 5
phrases sont les moins bons, cela montre donc qu&#8217;il est plus difficile de d&#233;terminer les fronti&#232;res
des petits segments. De plus les r&#233;sultats pour des segments entre 3 et 11 phrases sont moins</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L.Sitbon, P. Bellot
</p>
<p>bons que ceux entre 6 et 8 phrases, alors que la taille moyenne des segments est 7 phrases
dans les deux cas. On peut en d&#233;duire qu&#8217;une forte variation dans les tailles des segments est
&#233;galement un frein au bon fonctionnement des outils.
A propos des cat&#233;gories, les r&#233;sultats montrent que les donn&#233;es litt&#233;raires sont plus difficiles
&#224; traiter que les donn&#233;es journalistiques. Pour ces derni&#232;res, le th&#232;me de l&#8217;&#233;conomie ainsi que
les articles d&#8217;ordre g&#233;n&#233;ral sont les plus ais&#233;s &#224; segmenter. On peut supposer que les varia-
tions th&#233;matiques entre les segments de ce corpus sont plus grandes. Les documents du corpus
g&#233;n&#233;raliste sont en effet issus de toutes les th&#233;matiques du journal, et les documents traitant
d&#8217;&#233;conomie contiennent beaucoup de noms propres diff&#233;rents d&#8217;un segment &#224; l&#8217;autre.
</p>
<p>Taille Window Diff Cat&#233;gorie Window Diff
3-5 0,2244 G&#233;n&#233;ral 0,1670
3-5 0,2269 G&#233;n&#233;ral 0,1681
3-5 0,2270 G&#233;n&#233;ral 0,1686
6-8 0,1927 Art 0,2327
6-8 0,1927 Art 0,2335
6-8 0,1946 Art 0,2338
3-11 0,2131 Bible 0,2558
3-11 0,2131 Bible 0,2565
3-11 0,2178 Bible 0,2567
9-11 0,1669 Eco. 0,1672
9-11 0,16722 Eco. 0,1679
9-11 0,1678 Eco. 0,1686
</p>
<p>Sciences 0,1812
Sciences 0,1813
Sciences 0,1814
Sport 0,2114
Sport 0,2118
Sport 0,2121
</p>
<p>TAB. 3: meilleurs r&#233;sultats toutes impl&#233;men-
tations confondues pour chaque cat&#233;gorie et
chaque taille de segments.
</p>
<p>Cat&#233;gorie M&#233;thode Test no Window Diff
Art C99 37 0,2811
Art C99 38 0,2814
Art C99 36 0,2845
Bible DotPlot 13 0,3139
Bible DotPlot 14 0,3140
Bible C99 25 0,3161
Eco. C99 33 0,2243
Eco. DotPlot 13 0,2262
Eco. DotPlot 12 0,2264
</p>
<p>Sciences C99 25 0,2132
Sciences C99 35 0,2132
Sciences C99 34 0,2179
Sport C99 32 0,2839
Sport C99 38 0,2850
Sport C99 37 0,2854
</p>
<p>TAB. 4: les 3 meilleures impl&#233;mentations, pour
chaque cat&#233;gorie de document, pour des tailles
de segments entre 3 et 11 phrases.
</p>
<p>4.5 Param&#233;trage de Dotplotting ou C99
</p>
<p>C99 et Dotplotting sont les outils les plus efficaces (cf. sections 4.2 et 4.3), m&#234;me dans le cas
d&#8217;une valeur approch&#233;e (cf. section 4.4) pour la pr&#233;diction du nombre de segments &#224; trouver.
Mais le tableau 4 qui pr&#233;sente les 3 meilleures impl&#233;mentations pour chaque cat&#233;gorie, et pour
une taille des segments donn&#233;e (entre 3 et 11 phrases), montre que le meilleur param&#233;trage est
fonction du th&#232;me des documents, ainsi que du type de document &#224; segmenter (litt&#233;raire ou
journalistique). Ceci nous am&#232;ne &#224; sugg&#233;rer l&#8217;&#233;valuation sur un plus grand nombre de cat&#233;go-
ries, afin de d&#233;terminer statistiquement la meilleure m&#233;thode &#224; utiliser suivant le contenu des
documents. Il s&#8217;agirait alors d&#8217;une m&#233;thode supervis&#233;e s&#8217;appuyant sur des outils non supervis&#233;s.
</p>
<p>5 Conclusion
</p>
<p>Les exp&#233;riences que nous avons conduites sur des documents en fran&#231;ais montrent que dans
les conditions o&#249; le texte &#224; segmenter est une suite d&#8217;articles bien distincts, et o&#249; la qualit&#233;
des outils est &#233;valu&#233;e automatiquement en fonction de la distance entre les fronti&#232;res trouv&#233;es
et celles &#224; trouver, l&#8217;outil C99 est le plus efficace. Les exp&#233;riences ont confirm&#233; le fait que le
type de document que l&#8217;on segmente, son th&#232;me, la taille et la variation de taille des segments</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Evaluation de m&#233;thodes de segmentation en fran&#231;ais
</p>
<p>&#224; rep&#233;rer, sont autant de caract&#233;ristiques influen&#231;ant le travail des segmenteurs. D&#8217;autre part,
ces m&#233;thodes de segmentation pourraient &#234;tre am&#233;lior&#233;es en y int&#233;grant des crit&#232;res de choix
de limites suppl&#233;mentaires lorsque des marques de mise en forme sont pr&#233;sentes dans le texte
(titre, changement de paragraphe, ...). Enfin, nous avons montr&#233; que moyennant de petites adap-
tations, les m&#233;thodes classiques de segmentation non supervis&#233;s de documents en anglais sont
&#233;galement efficaces sur des textes en fran&#231;ais.
La prochaine &#233;tape de notre travail consistera &#224; tester des m&#233;thodes supervis&#233;es et semi-supervis&#233;es
pour finalement proposer une approche hybride (symbolique et probabiliste) capable de s&#8217;adap-
ter au mieux &#224; de nouveaux contextes et de profiter de la mise &#224; disposition de corpus d&#8217;appren-
tissage en fran&#231;ais. Cela sera effectu&#233; dans le projet Technolangue AGILE-OURAL.
</p>
<p>R&#233;f&#233;rences
BAEZA-YATES R. &amp; RIBEIRO-NETO B. (1999). Modern Information Retrieval. Addison-Wesley.
BEEFERMAN D., BERGER A. &amp; LAFFERTY J. (1997). Text segmentation using exponential models. In
Proceedings of the 2nd conf. on Empirical Methods in Natural Language Processing, USA.
CHOI F. Y. Y. (2000). Advances in domain independent linear text segmentation. In Proceedings of the
1st Meeting of the North American Chapter of the Association for Computational Linguistics, USA.
C. FELLBAUM, Ed. (1998). WordNet, an electronic lexical database. The MIT Press.
HALLIDAY M. &amp; HASAN R. (1976). Cohesion in English. Longman.
HEARST M. A. (1997). Text-tiling : segmenting text into multi-paragraph subtopic passages. Computa-
tional Linguistics, p. 59&#8211;66.
HELFMAN J. I. (1994). Similarity patterns in language. In IEEE Visual Languages, p. 173&#8211;175.
J.CALLAN (1994). Passage-level evidence in document retrieval. In Proccedings of the ACM/SIGIR
Conference of Research and Development in Information Retrieval, p. 302&#8211;310.
KAN M.-Y., KLAVANS J. L. &amp; MCKEOWN K. R. (1998). Linear segmentation and segment signifi-
cance. In Proceedings of the 6th International Workshop of Very Large Corpora (WVLC-6).
MCDONALD D. &amp; CHEN H. (2002). Using sentence selection heuristics to rank text segments in txtrac-
tor. In Proceedings of the 2nd ACM/IEEE Joint Conference on Digital Libraries, p. 28&#8211;35.
PEVZNER L. &amp; HEARST M. A. (2002). A critique and improvement of an evaluation metric for text
segmentation. Computational Linguistics, p. 19&#8211;36.
PORTER M. (1980). An algorithm for suffix stripping. Program, p. 130&#8211;137.
PORTER M. F. (2001). Snowball : A language for stemming algorithms. http ://snowball.tartarus.org.
REYNAR J. C. (2000). Topic segmentation : Algorithms and applications. PhD thesis, University of
Pennsylvania, Seattle, WA.
RIJSBERGEN C. J. V. (1979). Information Retrieval. Buttersworth.
SCHMID H. (1994). Probabilistic part-of-speech tagging using decision trees. In International Confe-
rence on New Methods in Language Processing, p. 44&#8211;49, Manchester, UK.
VERONIS J. (2004). stoplist. http ://www.up.univ-mrs.fr/ veronis/index.html.
</p>
<p>Annexe</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L.Sitbon, P. Bellot
</p>
<p>M&#233;thode Num&#233;ro de test Param&#232;tres
JTextTile (impl&#233;mentation de TextTiling par Choi)
</p>
<p>5 avec les param&#233;tres par d&#233;faut
Impl&#233;mentation de DotPlot par Choi, maximisation, cosine sim, stem, mots vides retir&#233;s
</p>
<p>6 Normal
7 Lissage
8 R&#233;duction du bruit
9 Seuil maximal
10 Masque 3x3
11 Masque 5x5
12 Masque 7x7
13 Masque 9x9
14 Masque 11x11(i.e. C99)
15 Masque 13x13
16 Masque 11x11 avec avec activation de la diffusion
17 Masque 11x11 , rang utilis&#233; en tant que poids dans la matrice de similarit&#233;
</p>
<p>DotPlot bas&#233; sur les blocs, maximisation, densit&#233; des points comme similarit&#233;
18 Steming activ&#233; mais pas de retrait des mots vides
19 Steming activ&#233; mais et retrait des mots vides
20 Activation de la diffusion
</p>
<p>Impl&#233;mentation exacte de DotPlot
21 Maximisation
22 Minimisation
</p>
<p>JSegmenter (impl&#233;mentation de Segmenter par Choi)
23 Mod&#232;le de distance fixe
24 Mod&#232;le de distance adaptatif
</p>
<p>C99
25 Nombre de fronti&#232;res connu
26 Nombre de fronti&#232;res inconnu
</p>
<p>TextTiling
27 Param&#232;tres par d&#233;faut
28 Param&#232;tres sugg&#233;r&#233;s par Hearst, k=6, w=20
</p>
<p>Simulation
29 Le document est d&#233;coup&#233; en 10 segments r&#233;guliers.
</p>
<p>C99 avec des masques variables
30 Masque 1x1, i.e. tous les rangs sont &#224; 0
31 Masque 3x3
32 Masque 5x5
33 Masque 7x7
34 Masque 9x9
35 Masque 11x11
36 Masque 13x13
37 Masque 15x15
38 Masque 17x17
</p>
<p>Segmenter
39 Segmenter 1.6 avec les param&#232;tres par d&#233;faut
</p>
<p>Autres tests avec C99
40 Prise en compte de l&#8217;entropie calcul&#233;e avec la fr&#233;quence des termes
41 Prise en compte de l&#8217;idf calcul&#233; avec la fr&#233;quence des termes
42 C99 avec un Masque 3x3, et une terminaison automatique
</p>
<p>TAB. 5: description des impl&#233;mentations avec les param&#232;tres utilis&#233;s</p>

</div></div>
</body></html>