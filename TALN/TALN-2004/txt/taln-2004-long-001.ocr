TALN 2004, Fés, 19-21 aVn'12004

Evaluation de méthodes de segmentation thématique linéaire
non supervisées apres adaptation au frangais

Laurianne Sitbon, Patrice Bellot
Laboratoire d’Inforrnatique d’AVignon — Université d’Avignon
339, chemin des Meinajaries — Agroparc BP 1228
84911 AVIGNON Cedex 9 — FRANCE
Tél : +33 (0)4 90 84 35 09, Fax : +33 (0)4 90 84 35 O1
{1aurianne.sitbon, patrice.be11ot} @1ia.uniV—avignon.fr

Résumé - Abstract

Nous proposons une évaluation de différentes méthodes et outils de segmentation thématique
de textes. Nous présentons les outils de segmentation linéaire et non supervisée DotPlottir1g,
Segmenter, C99, TextTiling, ainsi qu’une maniere de les adapter et de les tester sur des docu-
ments francais. Les résultats des tests montrent des différences en performance notables selon
les sujets abordés dans les documents, et selon que le nombre de segments a trouver est ﬁxé au
préalable par l’utilisateur. Ces travaux font partie du projet Technolangue AGILE-OURAL 1.

This paper presents an empirical comparison between different methods for segmenting texts.
After presenting segmentation tools and more speciﬁcally linear segmentation algorithms, we
present a comparison of these methods on both French and English text corpora. This evalu-
tation points out that the performance of each method heavilly relies on the topic of the docu-
ments, and the number of boundaries to be found. This work is part of the project Technolangue
AGILE-OURAL.

Mots-clefs — Keywords

Segmentation thématique, métriques de Beeferrnan et WindowDiff, cohésion lexicale, chaines
lexicales
Topic segmentation, Wir1dowDiff and Beeferrnan measures, lexical cohesion, lexical chains

1 Introduction

La segmentation d’un texte peut améliorer signiﬁcativement les performances en recherche
d’ir1forrnation (J .Callan, 1994), en donnant une partie de document correspondant a la requéte,

1http: //www. technolangue . net/article . php3 ?id_article=7 9

L.Sitbon, P. Bellot

et en indexant les documents de maniere plus precise. Elle peut aussi determiner les limites er1tre
des articles dans un ﬂux d’inforrnations (broadcast news), tache representee dans TDT (Topic
Detection and Tracking). Enﬁn, elle peut representer une importante part dans un processus de
resume automatique de textes, comme dans TXTRACTOR (McDonald & Chen, 2002). Apres
segmentation, les blocs sont evalues aﬁn de conserver les plus pertinents, ou on produit un
resume pour chaque theme aborde, donc pour chaque segment.

Nous nous sommes interesses aux methodes non supervisees et produisant une segmentation
lineaire (les segments trouves sont adjacents). Nous avons teste quelques uns des outils les plus
courants parmi lesquels DotPlotting (Reynar, 2000), C99 (Choi, 2000), Segmenter (Kan et al.,
1998), et Text Tiling (Hearst, 1997) - Voir section 2. Ils ont ete irnplementes et compares pour
l’anglais par (Choi, 2000), mais a priori aucune comparaison de ces outils n’a ete publiee pour
des documents en francais. Nous avons etudie leur comportement sur des textes francais, apres
avoir effectue des adaptations liguistiques et cree un corpus francais. Ces tests permettent de
mettre en lumiere d’une part les differences existant entre l’efﬁcacite des outils, et d’autre part
des differences entre les langues, les categories de documents traites, et la taille des segments.

2 Méthodes de segmentation linéaire non supervisée

Les methodes utilisees s’appuient sur la notion de cohesion lexicale (Halliday & Hasan, 1976),
c’est a dire la repetition des mots comme indicateur d’homogeneite thematique. Nous presen-
tons tout d’abord deux methodes basees sur la notion de chaine lexicale, puis deux autres fon-
dees sur la seule repartition des mots.

2.1 Segmenter : chaines lexicales

Segmenter (Kan et al., 1998) effectue une segmentation lineaire basee sur les chaines lexicales
presentes dans le texte. Ces chaines relient les occurrences des termes dans les phrases. Une
chaine est rompue si le nombre de phrases separant deux occurrences est trop important. Ce
nombre depend de la categorie syntaxique du terrne considere. Une fois tous les liens etablis,
un poids leur est assigne en fonction de la categorie syntaxique des termes en jeu et de la
longueur du lien. Un score est ensuite donne a chaque paragraphe en fonction des poids et des
origines des liens qui le traversent ou qui y sont crees. Les marques de segmentation sont alors
apposees au debut des paragraphes ayant les scores maximaux.

Etant donne qu’un concept peut etre designe par un ensemble de mots, le concept de chaines
lexicales a ete elargi aux chaines conceptuelles a l’aide de WordNet (Fellbaum, 1998) ou
d’autres ressources semantiques. (Kan et al., 1998) montre que l’amelioration est tres peu si-
gniﬁcative.

2.2 Text Tiling : multicriteres sur la repartition des termes

Text Tiling (Hearst, 1997) etudie la distribution des termes selon plusieurs criteres. Un score de
cohesion est attribue a chacun des blocs de texte en fonction du bloc qui le suit. Ce score depend
lui-meme d’un second score attribue a chaque paire de phrases suivant la paire de phrases qui
la suit. Ce second score est calcule en tenant compte des mots communs, du nombre de mots

Evaluation de méthodes de segmentation en frangais

nouveaux, et du nombre de chaines lexicales actives dans les phrases considerees.

Le score d’un segment de texte est alors le produit scalaire normalise des scores de chaque paire
de phrases qu’il contient. Si l’ecart entre le score d’un segment et les scores du segment qui le
precede et du segment qui le suit est grand, une frontiere est apposee a l’interieur de ce segment.
La rupture entre deux unites thematiques est situee dans une zone du texte entouree de zones
presentant des Valeurs de cohesion tres differentes de la sienne.

2.3 Dot Plotting : repetition de termes

L’algorithme que nous utilisons est propose par (Reynar, 2000), et est en fait une adaptation
pour la segmentation de la methode des nuages de points presentee par (Helfman, 1994) pour la
recherche d’information. Il se base sur une representation graphique du texte par les positions
des occurrences des termes du texte a segmenter. Lorsqu’un terme apparait a deux positions du
texte ac et y, les quatre points (at, at), (at, y), (y, at) et (y, y) sont representes sur un graphe, ce qui
permet de determiner Visuellement les zones du texte ou les repetitions sont nombreuses.

Cette methode est adaptee par (Reynar, 2000) a la segmentation thematique de textes. Les po-
sitions de debut et de ﬁn des zones les plus denses du graphe sont les limites des segments the-
matiquement coherents. La densite est calculee pour chaque unite d’aire en divisant le nombre
de points d’une region par l’aire de cette region. A partir de la, deux algorithmes peuvent de-
terminer les frontieres thematiques : indentiﬁer les limites en maximisant la densite au sein des
segments, ou reperer la conﬁguration qui minimise la densite des zones entre les segments.

2.4 C99 : mesure de similarite

Cet algorithme propose par (Choi, 2000) utilise une mesure de similarite entre chaque unite
textuelle. L’idee de base de cette methode est que les mesures de similarite entre des segments
de textes courts sont statistiquement insigniﬁantes, et que donc seul des classements locaux
(Voir ci-dessous) sont a considerer pour ensuite appliquer un algorithme de categorisation sur
la matrice de similarite. Dans un premier temps, une matrice de similarite est donc construite,
representant la similarite entre toutes les phrases du texte a l’aide de la mesure de similarite
proposee par (Rijsbergen, 1979), calculee pour chaque paire de phrases du texte, en utilisant
chaque mot commun entre les phrases, et apres << nettoyage » du texte : suppression des mots
Vides et lemmatisation.

On effectue ensuite un << classement local », en determinant pour chaque paire d’unites tex-
tuelles, le rang de sa mesure de similarite par rapport a ses m X n — 1 Voisins, m X n etant le
masque de classement choisi. Le rang est le nombre d’elements Voisins ayant une mesure de
similarite plus faible, conserve sous la forme d’un ratio 7' aﬁn de prendre en compte les effets
de bord.
rang
7‘ = . .
nombre de V01S1IlS dans le masque

Enﬁn, la demiere etape determine les limites de chaque segment de la meme maniere que l’algo-
rithme Dotplotting (Voir section 2.1) emploie la maximisation. En effet on cherche a determiner
quelle conﬁguration offre la plus grande densite, en recherchant une nouvelle limite thematique
a chaque etape. Les segments sont alors representes par des carres le long de la diagonale de la
matrice de similarite modiﬁee avec les classements locaux. Pour chaque segment de la reparti-
tion proposee a une etape de la segmentation on considere son aire notee ak et son poids sk qui

L.Sitbon, P. Bellot

est la somme des tous les rangs des phrases qu’il contient. On calcule alors la densite D de la
conﬁguration avec :

D :  SIC
2211 ale

L’algorithme s’arrete lorsque la densite de la meilleure repartition proposee est sufﬁsamment
faible, ou si le nombre de frontieres thematiques est deja determine, lorsqu’il est atteint.

3 Adaptation au frangais et mise en place des tests

Nous avons adapte les implementations effectuees par (Choi, 2000 ; http: / /www . cs . man .
ac . uk/ ~mary/ choif / software . html) au francais. Une liste de mots vides permet de
retirer du texte les mots trop communs et donc non sufﬁsamment porteurs de sens pour les
methodes utillisees. De plus, etant tres courants, ils peuvent fausser les mesures de similarite
ou les chaines lexicales en incluant des repetitions de termes supplementaires et non pertinentes
thematiquement. La liste de mots francais utilisee se trouve dans (Veronis, 2004).

L’algorithme de Porter pour le stemming (Porter, 1980) est efﬁcace pour l’anglais mais inadapte
au francais. Nous l’aVons donc remplace par une implementation de Snowball (Porter, 2001),
avec un ﬁchier de parametres pour le francais livre avec l’outil.

L’étiquetage morpho-syntaxique est utilise par l’outil Segmenter, et permet d’eliminer de
l’analyse certaines categories non speciﬁquement porteuses de theme. Nous avons utilise Tree
Tagger, presente par (Schmid, 1994). Come les etiquettes morphosyntaxiques ne sont plus les
memes d’une langue a l’autre, il a egalement fallu changer l’interpretation de l’etiquetage au
niveau du code. Ce changement etant speciﬁque a chaque langue et non dependant d’un ﬁchier
de parametres, il est plus complique de porter Segmenter a une autre langue par la suite.

3.1 Metriques d’evaluation

Les deux standards d’evaluation que sont le rappel et la precision (Baeza-Yates & Ribeiro-
Neto, 1999), utilises en recherche d’information, ont ete employes pour evaluer les premiers
algorithmes de segmentation. Mais une baisse de l’un entraine generalement une hausse de
l’autre, et dans notre cas on ne cherche pas a en favoriser un, mais a evaluer l’efﬁcacite des
algorithmes pour la segmentation. De plus ils evaluent la presence ou non d’une frontiere a sa
place de reference, mais ne permettent pas de differencier une erreur faible (un decalage d’une
phrase) d’une erreur grave (un oubli de frontiere).

(Beeferman et al., 1997) propose une nouvelle mesure, Pk, qui prend en compte la distance
entre une limite trouvee et celle qui aurait dﬁ etre trouvee. Elle evalue une probabilite d’erreur
sur la segmentation prenant en compte la probabilite pour deux phrases eloignees d’une distance
I: (Valant la moitie de la longueur moyenne des segments du document) d’etre localement dans
les memes segments du document de reference (re f ) et du document produit par l’outil (hyp),
c’est a dire qu’aucune frontiere thematique ne les separe dans les deux cas.

(Pevzner & Hearst, 2002) montre que la mesure Pk proposee par Beeferman, bien que meilleure
que le rappel/precision, a encore des defauts (des erreurs de meme type sont penalisees differe-
ment, les ajouts de petits segments sont ignores, la signiﬁcation de la mesure n’est pas claire).

Evaluation de méthodes de segmentation en frangais

Ils ont donc propose une nouvelle maniere d’evaluer les algorithmes de segmentation, appe-
lee WindowDiff, fortement inspiree de Pk. En fait cette nouvelle mesure prend en compte le
nombre de frontieres separant deux phrases espacees d’une distance 1:.

VVindowDiﬁ(reﬁ hyp) = % Z(|b(7‘efz-, weft-+k) — b(hyPz'a hyp.-ml)

ou b(ac,-, 30,-) est le nombre de frontieres entre 2' et j dans le texte ac, contenant N phrases.

(Pevzner & Hearst, 2002) montre que cette mesure est d’une grande stabilite face aux variations
des tailles des segments, et qu’elle est aussi severe avec les ajouts qu’avec les oublis de fron-
tieres thematiques. Cependant elle peut etre superieure a 1, et ne peut donc plus etre assimilee
a un taux d’erreur. Il est desormais evident qu’elle n’est qu’un element de comparaison de la
ﬁabilite des methodes, et non pas un indice absolu de leur qualite.

3.2 Le corpus d’évaluation.

(Hearst, 1997) et (Kan et al., 1998) ont travaille sur peu de documents segmentes manuelle-
ment. A la place, nous avons repris la methode de (Choi, 2000) pour constituer un corpus de
tests meme si elle ne garantit pas que les segments assembles aient pour autant une veritable
discontinuite thematique. Cette methode, si elle ne correspond pas a un cas reel, presente l’avan-
tage d’etre rapidement applicable a des corpus de nature differente. Nous avons ainsi choisi de
l’appliquer d’une part a des articles du Monde (fortes discontinuites thematiques) et, d’autre
part, a des chapitres de la Bible (relative continuite stylistique et thematique mais fortes varia-
tion sur les entites nommees).

Un premier corpus a ete realise aﬁn de determiner l’inﬂuence des themes et de la taille des
segments. Ce corpus est divise en 5 categories de documents : les articles joumalistiques
de n’importe quel sujet, les articles joumalistiques thematiquement coherents : art, economie,
sciences ou sport, et les chapitres litteraires. Pour chacune de ces categories, 4 ensembles de
100 documents ont ete fabriques, avec pour chaque ensemble des criteres differents de tailles
de segments : des segments courts (entre 3 et 5 phrases), des segments moyens (entre 6 et
8 phrases), des segments longs (entre 9 et 11 phrases), ou des segments de tailles variables
(entre 3 et 11 phrases). Chaque document est constitue de 10 segments, qui sont autant de de-
but d’articles choisis aleatoirement dans la categorie correspondant au critere, et raccourcis a la
longueur deﬁnie par le critere de taille. La base d’articles utilisee pour composer ce corpus est
l’ensemble des articles de l’aImee 2001 du Monde correspondant a chaque critere, et de plus de
10 phrases. A cette base s’ajoute un ensemble de chapitres de la Bible, pour la partie du corpus
concemant la litterature. Ce corpus principal permet de tester de grandes variations dans la taille
des paragraphes.

Un second corpus plus petit a ete constitue, ou les segments sont des ensembles de paragraphes.
Il est constitue de 100 documents dont les segments sont issus de n’importe quelle categorie, et
comportent entre 3 et 5 paragraphes.

4 Experiences

Une fois les transformations des outils effectuees, nous avons tout d’abord compare les resultats
trouves sur un corpus generaliste en francais a ceux trouves sur un corpus generaliste en anglais

L.Sitbon, P. Bellot

(Brown Corpus, utilise par (Choi, 2000)), aﬁn de Veriﬁer que les adaptations n’ont pas affecte
certains outils. Quel que soit le test effectue, les resultats sur les deux langues font apparaitre
une difference constante de performance, d’une Valeur d’enViron 0,1 en faveur de l’anglais
selon la mesure WindowDiff. Cependant, cette difference etant faible, on peut considerer que
les changements effectues sur les outils sont Valides.

4.1 Evaluation avec un nombre de segments a trouver non predeﬁni

Le tableau 1 represente, pour 5 implementations des methodes (avec les parametres donnant les
meilleurs resultats), la moyenne de la mesure WindowDiff sur tous les documents du corpus
principal. Ces implementations sont decrites dans le tableau 5 en armexe. Cela montre que C99
est l’outil le plus efﬁcace, deux fois meilleur que TextTiling et Segmenter.

Le corpus utilise, en prenant les phrases comme unites de traitement, restreint l’action de Seg-
menter et TextTiling pour la creation de chaines lexicales, car ils se basent habituellement sur
des paragraphes, et donc les blocs unitaires etant plus courts, il est plus difﬁcile d’y former
des chaines lexicales avec les parametres de base. Nous avons donc compare les resultats avec
ceux sur le second corpus, compose de paragraphes, La ﬁgure 1 montre que les differences sont
faibles pour les meilleures methodes.

 

Categories Tailles
Test no score Test no score

25 4 25 4

36 4 35 3

37 4 36 3

38 4 37 3

13 3 34 2

32 3 38 2

34 3

_ 35 3

TAB. 1: Comparatson des methodes pour les-
quelles le nombre de segments (2 trouver n’est TAB. 2: Meilleures implementations (voir Ta-
pas pre’de’ﬁni, selon la moyenne de la mesure bleau 5 pour leur description) pour chaque ca-
Window Dzﬁsur l’ensemble du corpus frangais te’gorie, et pour chaque taille des segments

4.2 Evaluation avec un nombre de segments a trouver predeﬁni

Ces methodes donnant des resultats assez proches les uns des autres, nous avons cree une sorte
de toumoi aﬁn de trouver les meilleures, selon des criteres de taille, ou selon chacune des
categories. Les 5 meilleures implementations a chaque test recoivent un point, pour chaque
categorie d’une part, et chaque taille d’autre part. Le tableau 2 montre les resultats de ce toumoi.
Il en ressort que C99 (tests 25 et 32 a 38) est plus efﬁcace que DotPlotting (test 15) lorsque le
nombre de frontieres thematiques a trouver est connu a l’aVance.

4.3 Utilisation d’un nombre approximatif de segments a trouver

Etant donne que les outils pour lesquels il faut foumir le nombre de segments a trouver ont
naturellement des resultats signiﬁcativement meilleurs que les autres, nous les avons testes en
leur donnant un nombre different de segments a trouver, a plus ou moins 5 segments du nombre
reel, aﬁn de Voir leur comportement dans le cas d’un nombre approximatif de limites.

Evaluation de me’thodes de segmentation en francais

Ouar oaraqranhes Aoar Dhrases

1.4

1,2

F‘
a

Window Duff
5’
m
-.
r
A
v
.5.
r

0,4

0,2

5 10 15 20 25 30 35 40 45
nn test

FIG. 1: comparaison entre les resultats pour le corpus principal, et le corpus secondaire, selon la mesure
Window Diﬁ‘

In=15 On=5 An=1O Xn non défini

1,2
1,1

0,9
0,8
0‘?
0,6
05
0,4
0,3
02
0,1

Window Diff

 

lest no

FIG. 2: resultats suivant un nombre n variable de segments pre’vus

La ﬁgure 2 montre que meme avec une erreur d’un ordre de la moitie du nombre reel de seg-
ments, les resultats sont aussi bons que les methodes statistiques avec un nombre de segments
a trouver connu et certains parametres, et sont meilleurs que TextTiling ou Segmenter dans
cette experimentation. Cela suggere qu’on pourrait utiliser une granularite de segmentation de-
ﬁnie par l’utilisateur, sans baisser trop les performances par rapport a des systemes entierement
automatiques qui ne perrnettent pas ce parametrage.

4.4 Efﬁcacité par categorie ou par taille

Le tableau 3 resume l’eValuation pour les trois implementations les plus perforrnantes de chaque
categorie toutes tailles de segments confondues, et de chaque taille de segments toutes catego-
ries confondues (moyenne arithmetique des scores). Les resultats pour les segments entre 3 et 5
phrases sont les moins bons, cela montre donc qu’il est plus difﬁcile de determiner les frontieres
des petits segments. De plus les resultats pour des segments entre 3 et 11 phrases sont moins

L.Sitbon, P. Bellot

bons que ceux entre 6 et 8 phrases, alors que la taille moyenne des segments est 7 phrases
dans les deux cas. On peut en deduire qu’une forte Variation dans les tailles des segments est
egalement un frein au bon fonctionnement des outils.

A propos des categories, les resultats montrent que les donnees litteraires sont plus difﬁciles
a traiter que les donnees journalistiques. Pour ces demieres, le theme de l’economie ainsi que
les articles d’ordre general sont les plus aises a segmenter. On peut supposer que les Varia-
tions thematiques entre les segments de ce corpus sont plus grandes. Les documents du corpus
generaliste sont en effet issus de toutes les thematiques du journal, et les documents traitant
d’economie contiennent beaucoup de noms propres differents d’un segment a l’autre.

Taille Window Diff Categorie Window Diff
3-5 0,2244 General 0,1670
3-5 0,2269 General 0,1681 , _ , _ _
3_5 0,2270 Général 0,1686 Categorie Methode Test no Window Diff
6-8 0,1927 Art 0,2327 Art C99 37 0,2811
6-8 0,1927 Art 0,2335 Art C99 38 0,2814
6-8 0,1946 Art 0,2338 Art C99 36 0,2845
3-11 0,2131 B11515 0,2553 Bible DotP1ot 13 0,3139
3-11 0,2131 1311,15 0,2555 Bible DotP1ot 14 0,3140
3-11 0,2178 Bible 0,2567 Bible C99 25 0,3161
9-11 0,1669 Eco. 0,1672 E00. C99 33 0,2243
9-11 0,15722 E95 0,1579 Eco. DotP1ot 13 0,2262
9-11 0,1573 Em 0,1585 Eco. DotP1ot 12 0,2264
Sciences 0,1812 Sciences C99 25 0,2132
Sciences 0,1813 Sciences C99 35 0,2132
Sciences 0,1814 Sciences C99 34 0,2179
Sport 0,2114 Sport C99 32 0,2839
Sport 0,2118 Sport C99 38 0,2850
Sport 0,2121 Sport C99 37 0,2854
TAB. 3: meilleurs re’sultats toutes imple’men— TAB. 4: les 3 meilleures implementations, pour
tations confondues pour chaque cate’gorie et chaque cate’gorie de document, pour des tailles
chaque taille de segments. de segments entre 3 et1I phrases.

4.5 Parametrage de Dotplotting ou C99

C99 et Dotplotting sont les outils les plus efﬁcaces (cf sections 4.2 et 4.3), meme dans le cas
d’une Valeur approchee (cf. section 4.4) pour la prediction du nombre de segments a trouver.
Mais le tableau 4 qui presente les 3 meilleures implementations pour chaque categorie, et pour
une taille des segments donnee (entre 3 et 11 phrases), montre que le meilleur parametrage est
fonction du theme des documents, ainsi que du type de document a segmenter (litteraire ou
joumalistique). Ceci nous amene a suggerer l’eValuation sur un plus grand nombre de catego-
ries, aﬁn de determiner statistiquement la meilleure methode a utiliser suivant le contenu des
documents. Il s’agirait alors d’une methode supervisee s’appuyant sur des outils non supervises.

5 Conclusion

Les experiences que nous avons conduites sur des documents en francais montrent que dans
les conditions ou le texte a segmenter est une suite d’articles bien distincts, et ou la qualite
des outils est evaluee automatiquement en fonction de la distance entre les frontieres trouvees
et celles a trouver, l’outil C99 est le plus efﬁcace. Les experiences ont conﬁrme le fait que le
type de document que l’on segmente, son theme, la taille et la Variation de taille des segments

Evaluation de me’thodes de segmentation en francais

a repérer, sont autant de caractéristiques inﬂuencant 1e travail des segmenteurs. D’autre part,
ces méthodes de segmentation pourraient etre améliorees en y intégrant des criteres de choix
de limites supplémentaires lorsque des marques de mise en forme sont présentes dans le texte
(titre, changement de paragraphe, ...). Enﬁn, nous avons montré que moyennant de petites adap-
tations, les méthodes classiques de segmentation non supervises de documents en anglais sont
également efﬁcaces sur des textes en francais.

La prochaine étape de notre travail consistera a tester des méthodes supervisées et semi-supervisées
pour ﬁnalement proposer une approche hybride (symbolique et probabiliste) capable de s’adap-
ter au mieux a de nouveaux contextes et de proﬁter de la mise a disposition de corpus d’appren-
tissage en francais. Cela sera effectué dans le projet Technolangue AGILE-OURAL.

Références

BAEZA-YATES R. & RIBEIRO-NETO B. (1999). Modern Information Retrieval. Addison-Wesley.

BEEFERMAN D., BERGER A. & LAFFERTY J. (1997). Text segmentation using exponential models. In
Proceedings of the 2nd conf. on Empirical Methods in Natural Language Processing, USA.

CHOI F. Y. Y. (2000). Advances in domain independent linear text segmentation. In Proceedings of the
I st Meeting of the North American Chapter of the Association for Computational Linguistics, USA.

C. FELLBAUM, Ed. (1998). WordNet, an electronic lexical database. The MIT Press.
HALLIDAY M. & HASAN R. (1976). Cohesion in English. Longman.

HEARST M. A. (1997). Text-tiling : segmenting text into multi-paragraph subtopic passages. Computa-
tional Linguistics, p. 59-66.

HELFMAN J . I. (1994). Similarity patterns in language. In IEEE Visual Languages, p. 173-175.

J.CALLAN (1994). Passage-level evidence in document retrieval. In Proccedings of the ACM/SIGIR
Conference of Research and Development in Information Retrieval, p. 302-310.

KAN M.-Y., KLAVANS J . L. & MCKEOWN K. R. (1998). Linear segmentation and segment signiﬁ-
cance. In Proceedings of the 6th International Workshop of Very Large Corpora (WVLC—6).

MCDONALD D. & CHEN H. (2002). Using sentence selection heuristics to rank text segments in txtrac-
tor. In Proceedings of the 2nd ACM/IEEE Joint Conference on Digital Libraries, p. 28-35.

PEVZNER L. & HEARST M. A. (2002). A critique and improvement of an evaluation metric for text
segmentation. Computational Linguistics, p. 19-36.

PORTER M. (1980). An algorithm for sufﬁx stripping. Program, p. 130-137.
PORTER M. F. (2001). Snowball : A language for stemming algorithms. http ://snowball.tartarus.org.

REYNAR J . C. (2000). Topic segmentation : Algorithms and applications. PhD thesis, University of
Pennsylvania, Seattle, WA.

RIJSBERGEN C. J. V. (1979). Information Retrieval. Buttersworth.

SCHMID H. (1994). Probabilistic part-of-speech tagging using decision trees. In International Confe-
rence on New Methods in Language Processing, p. 44-49, Manchester, UK.

VERONIS J. (2004). stoplist. http ://www.up.univ-n1rs.fr/ veronis/index.ht1nl.

Annexe

L.Sitbon, P. Bellot

Méthode | Numéro de test | Parametres
JTextTi1e (implémentation de TextTi]ing par Choi)
| 5 | avec les paramétres par défaut
Implémentation de DotP1ot par Choi, maximisation, cosine sim, stem, mots vides retirés
6 Normal
7 Lissage
8 Réduction du bruit
9 Seuil maximal
10 Masque 3x3
11 Masque 5x5
12 Masque 7x7
13 Masque 9x9
14 Masque 11x11(i.e. C99)
15 Masque 13x13
16 Masque 11x11 avec avec activation de la diffusion
17 Masque 11x11 , rang uti]1'sé en tant que poids dans la matrice de similarité
DotP1ot basé sur les blocs, maximisation, densité des points comme similarité
18 Steming activé mais pas de retrait des mots vides
19 Steming activé mais et retrait des mots vides
20 Activation de la diffusion
Implémentation exacte de DotP1ot
21 Maximisation
22 Minimisation
JSegmenter (implémentation de Segmenter par Choi)
23 Modele de distance ﬁxe
24 Modele de distance adaptatif
C99
25 Nombre de frontieres connu
26 Nombre de frontieres inconnu
TextTi]ing
27 Parametres par défaut
28 Parametres suggérés par Hearst, k=6, w=20
Simulation
| 29 | Le document est découpé en 10 segments réguliers.
C99 avec des masques variables
30 Masque 1x1, i.e. tous les rangs sont a 0
31 Masque 3x3
32 Masque 5x5
33 Masque 7x7
34 Masque 9x9
35 Masque 11x11
36 Masque 13x13
37 Masque 15x15
38 Masque 17x17
Segmenter
| 39 | Segmenter 1.6 avec les parametres par défaut
Autres tests avec C99
40 Prise en compte de 1’entropie calculée avec la fréquence des termes
41 Prise en compte de 1’idf calculé avec la fréquence des termes
42 C99 avec un Masque 3x3, et une terminaison automatique

TAB. 5: description des implémentations avec les paramétres utilisés

