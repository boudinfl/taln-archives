TALN 2004, Fés, I9-21 avril 2004

Découvrir des sens de mots :71 partir d’un réseau
de cooccurrences lexicales

Olivier Ferret

CEA — LIST/LIC2M
92265 Fontenay-aux-Roses Cedex
ferreto@zoe.cea.fr

Résumé — Abstract

Les réseaux lexico-sémantiques de type WordNet ont fait l’objet de nombreuses critiques
concemant la nature des sens qu’ils distinguent ainsi que la facon dont ils caractérisent ces
distinctions de sens. Cet article présente une solution possible a ces lirnites, solution
consistant a déﬁnir les sens des mots a partir de leur usage. Plus précisément, il propose de
différencier les sens d’un mot a partir d’un réseau de cooccurrences lexicales construit sur la
base d’un large corpus. Cette méthode a été testée a la fois pour le francais et pour l’anglais et
a fait l’objet dans ce dernier cas d’une premiere evaluation par comparaison avec WordNet.

Lexico-semantic networks such as WordNet have been criticized a lot on the nature of the
senses they distinguish as well as on the way they deﬁne these senses. In this article, we
present a possible solution to overcome these limits by deﬁning the sense of words from the
way they are used. More precisely, we propose to differentiate the senses of a word from a
network of lexical cooccurrences built from a large corpus. This method was tested both for
French and English and for English, was evaluated through a comparison with WordNet.

Keywords — Mots Clés

Sémantique lexicale, découverte du sens des mots, réseaux lexico-sémantiques
Lexical semantics, word sense discovery, lexico-semantic networks

1 Introduction

L’intérét de l’utilisation de ressources sémantiques en recherche ou en extraction
d’information a été montré depuis quelque temps déja au travers de travaux allant de
l’expansion de requétes (de Loupy, El-Beze, 2002) aux systemes de question/réponse (Pasca,
Harabagiu, 2001). Ces travaux ont également mis en avant le fait qu’une telle utilisation de-
vait étre entourée de precautions : une amelioration des performances n’est observée que si la
levée d’ambigu'1'té sur le sens des mots est réalisée avec une tres bonne ﬁabilité. Cette obser-
vation met l’accent sur l’un des roles premiers de la notion de ressource sémantique : déﬁnir
pour chacun de ses mots un inventaire de ses sens possibles ainsi qu’une caractérisation de
chacun d’entre eux. Les principales ressources sémantiques exploitables sous forme electro-

Olivier Ferret

nique et présentant une large couverture sont des réseaux lexico-sémantiques du type Word-
Net (Miller, 1995). De par leur mode de construction, essentiellement manuel, ces réseaux ne
se démarquent pas fondamentalement des dictionnaires sous forme papier. Ils s’appuient
avant tout sur une formalisation et une systématisation des pratiques lexicographiques
existantes. Les critiques formulées quant a leur inadéquation vis-a-vis du traitement
automatique des langues, comme par exemple dans (Harabagiu et al., 1999), ne sont des lors
pas surprenantes. Ces critiques portent a la fois sur la nature des sens qu’ils distinguent et sur
leur caractérisation. Ces sens sont jugés a la fois trop ﬁns et incomplets. Par ailleurs, leur
caractérisation, réalisée pour l’essentiel au travers des relations de synonymie, d’hyperonymie
et d’hyponymie, manque d’éléments défmissant leur contexte d’usage.

Deux grandes solutions ont été explorées pour remédier a cette situation. La premiere d’entre
elles consiste a enrichir automatiquement les réseaux de type WordNet pour y introduire les
informations permettant de répondre aux critiques formulées. Différents travaux, dont re-
cemment (Agirre, Lopez de Lacalle, 2003), se sont ainsi domes pour objectif de regrouper
des sens de WordNet pour obtenir une granularité de sens a plusieurs niveaux, donc adaptable
a la tache considérée. D’autres travaux, en particulier dans le cadre du projet eXtended
WordNet (Mihalcea, Moldovan, 2001), se sont orientés vers l’extraction de relations semanti-
ques plus diverses a partir des déﬁnitions (les << glosses ») associées aux synsets de WordNet,
ce qui permet de caractériser davantage le contexte d’usage de chacun d’entre eux.

La seconde solution consiste a extraire les sens des mots automatiquement a partir de corpus,
sans utilisation des dictionnaires existants. Chaque sens est alors décrit par une liste de mots
ne se limitant pas a des synonymes ou des hyperonymes. Les travaux déja menés dans ce ca-
dre se répartissent en trois grandes tendances. La premiere, illustrée par (Pantel, Lin, 2002),
ne place pas la découverte des différents sens des mots au centre de ses préoccupations. Son
objectif premier est en effet de rassembler les mots en classes d’équivalence et donc plutot de
former des classes de synonymes. La découverte de sens est une conséquence indirecte : la
méthode de classiﬁcation utilisée, Clustering by Committee, autorisant l’appartenance d’un
mot a plusieurs classes, chacune d’entre elles devient defacto un sens de ce mot. La deuxieme
tendance observée, que l’on retrouve dans (Schﬁtze, 1998), (Pedersen, Bruce, 1997) et a sa
suite (Purandare, 2003), caractérise pour sa part chaque occurrence d’un mot par un ensemble
de traits lies a son environnement plus ou moins proche et procede a une classiﬁcation non
supervisée de toutes les occurrences du mot sur la base de ces traits. Les différentes classes
formées constituent autant de sens du mot. La demiere approche enﬁn, représentée par (Vero-
nis, 2003), (Dorow, Widdows, 2003) et (Rapp, 2003), prend comme point de départ les cooc-
currents d’un mot enregistrés a partir d’un corpus et forme les différents sens de ce mot en
regroupant ses cooccurrents suivant leur similarité ou au contraire leur dissimilarité. C’est
dans cette demiere perspective que se situe le travail que nous décrivons dans cet article.

2 Principes

Le point de départ de la méthode que nous présentons est un réseau de cooccurrences lexica-
les, c’est-a-dire un graphe dont les noeuds sont les mots constituant le vocabulaire signiﬁcatif
d’un corpus et les arétes représentent les cooccurrences observées er1tre ces mots dans le cor-
pus. La découverte des sens des mots est réalisée mot par mot et le traitement d’un mot ne fait
intervenir que le sous-graphe rassemblant les cooccurrents de ce mot. La premiere étape de la
méthode consiste a construire une matrice de similarité de ces cooccurrents sur la base de
leurs relations dans le sous-graphe. Une méthode de classiﬁcation automatique non supervisée

Découvrir des sens de mots

est alors appliquée afm de regrouper ces cooccurrents et former les différents sens du mot
considéré. L’hypothese sous-jacente a cette méthode, hypothese qu’elle partage avec les tra-
vaux relevant de la troisieme tendance dégagée dans la section précédente, est bien entendu
que la connectivité au sein du sous-graphe des cooccurrents formant le sens d’un mot est plus
irnportante que leur connectivité avec les cooccurrents défmissant les autres sens de ce mot.
La méthode de classiﬁcation que nous utilisons est une adaptation de la méthode Shared Nea-
rest Neighbors (SNN), exposée dans (Ertoz et al., 2001). Cette méthode présente l’avantage
de déterminer automatiquement le nombre de classes, c’est-a-dire le nombre de sens dans le
cas présent, et de laisser de cote les éléments les moins représentatifs des classes formées. Ce
dernier point est particulierement utile pour cette application compte tenu du taux important
de << bruit » parrni les cooccurrents d’un mot.

3 Les réseaux de cooccurrence lexicale

Dans le cadre de ce travail, nous avons testé notre méthode de découverte de sens a la fois sur
le francais et sur l’anglais. Nous avons donc construit un réseau de cooccurrences lexicales
pour ces deux langues. Celui pour le francais a été constitué a partir de 24 mois du journal Le
Monde sélectionnés er1tre 1990 et 1994 ; celui pour l’anglais a partir de deux ans du journal
Los Angeles Times, issus du corpus TREC. Dans chacun des cas, la taille du corpus est
d’environ 40 millions de mots. Pour les deux réseaux, le corpus initial a d’abord été prétraité
afm de caractériser les textes par leurs mots les plus discriminants sur le plan thématique, en
l’occurrence les noms, les verbes et les adjectifs, domes sous forme lemmatisée. Dans le cas
du francais, les noms étaient a la fois des noms simples et des noms composés. Les cooccur-
rences ont ensuite été extraites en utilisant une fenétre glissante selon la méthode décrite dans
(Church, Hanks, 1990). Les parametres de cette extraction ont été fixes afm de favoriser la
capture de relations sémantiques et thématiques : la fenétre était assez large (20 mots), respec-
tait la ﬁn des textes et l’ordre des cooccurrences n’était pas conservé. Nous avons comme
Church et Hanks adopté une évaluation de l’information mutuelle comme mesure de la cohe-
sion de chaque cooccurrence, mesure norrnalisée dans notre cas par l’information mutuelle
maxirnale relative au corpus. Apres ﬁltrage des cooccurrences les moins signiﬁcatives (cohe-
sion < 0,1 et moins de 10 occurrences), nous avons obtenu un réseau d’approximativement
23 000 mots et 5,2 millions de cooccurrences pour le francais et un réseau de 30 000 mots et
4,8 millions de cooccurrences pour l’anglais.

4 Algorithme de découverte des sens

4.1 Construction de la matrice de similarité entre cooccurrents

Les algorithmes de classiﬁcation sont en général sufﬁsamment paramétrables pour inﬂuer sur
le nombre et l’étendue des classes forrnées. Mais cette adaptabilité est implicitement lirnitée
par la mesure de similarité défmie pour comparer les elements a classer, d’o1‘1 son importance.
Dans le cas présent, les elements a classer sont les cooccurrents dans le réseau de cooccur-
rence lexicale du mot dont on cherche a découvrir les sens. Tout en conservant le méme cadre
général, nous avons souhaité tester deux mesures de similarité er1tre cooccurrents dans la
perspective d’obtenir différents niveaux de granularité quant aux sens distingués. La premiere
mesure reprend simplement la valeur de cohésion existant dans le réseau de cooccurrence
entre les cooccurrents considérés. S’il n’existe pas de relation entre eux dans le réseau, leur
similarité est considérée comme nulle. Cette mesure possede l’avantage de la simplicité et de
l’efﬁcacité algorithmique mais elle est lirnitée par le fait que la relation de cooccurrence ne

Olivier Ferret

permet pas de capturer certaines proximités entre mots. On constate ainsi expérimentalement
que l’on retrouve parmi les cooccurrents d’un mot assez peu de ses synonymes reconnusl. On
peut donc s’attendre a ce que certains sens distingués en s’appuyant sur cette mesure ne soient
en fait qu’un seul et méme sens.

Pour prévenir ce risque, nous avons expérimenté une mesure de similarité entre cooccurrents
reposant non seulement sur une relation de cooccurrence de premier niveau mais également
de deuxieme niveau, cette demiere étant réputée plus stable (Schﬁtze, 1998). La mise en oeu-
vre de cette mesure se fait de la facon suivante : chaque cooccurrent se Voit associer un Vec-
teur de taille égale au nombre de cooccurrents du mot traité et contenant la Valeur de cohésion
entre ce cooccurrent et chacun des autres cooccurrents de ce mot. Comme précédemment,
cette Valeur est nulle s’il n’y a pas de relation dans le réseau entre deux cooccurrents. La ma-
trice de similarité entre cooccurrents est simplement construite en appliquant la mesure cosi-
nus entre les Vecteurs de chaque couple de cooccurrents. Avec cette seconde mesure de simi-
larité, deux cooccurrents n’ont plus nécessairement besoin d’entretenir une relation de cooc-
currence directe pour étre jugés proches : ils peuvent se contenter de partager un ensemble de
mots avec lesquels ils entretiennent une telle relation.

4.2 Algorithme SNN (Shared Nearest Neighbors)

L’algorithme SNN (Ertoz et al., 2001) s’inscrit dans la mouvance des algorithmes ramenant le
probleme de la classiﬁcation a celui de la détection de composantes de forte densité dans un
graphe de similarité. Dans un tel graphe, chaque noeud représente un element a classer et une
aréte relie deux noeuds lorsque la similarité entre les éléments qu’ils représentent est non
nulle. Lorsque la matrice de similarité est symétrique, comme c’est le cas ici, le graphe obtenu
est non orienté. On pourra noter que dans le cas de la découverte des sens d’un mot, le pro-
bleme est a la base un probleme de détection de composantes de forte densité, les sens, au
sein du graphe des cooccurrents de ce mot. Il est conservé tel quel avec la premiere mesure de
similarité mais transposé en un probleme plus general de classiﬁcation avec la seconde.

Dans son principe général, l’algorithme SNN comporte deux grandes étapes : la premiere Vise
a mettre en évidence les éléments les plus représentatifs de leur Voisinage en masquant les
relations les moins importantes du graphe de similarité. Ces éléments constituent les em-
bryons des futures classes, formées dans un second temps en agrégeant les autres elements a
ceux sélectionnés lors de la premiere phase. L’algorithme SNN, considéré dans le contexte de
la découverte de sens, se décompose plus précisément comme suit :

1. << éclaircissement » du graphe de similarité : pour chaque cooccurrent, seules les arétes en
direction des k (k = 15 en l’occurrence) plus proches cooccurrents sont conservées.

2. construction du graphe des plus proches Voisins partagés : cette étape consiste a remplacer
dans le graphe << éclairci » la Valeur portée par chaque aréte par le nombre de Voisins di-
rects que les deux cooccurrents reliés par l’aréte ont en commun.

3. calcul de la distribution en liens forts des cooccurrents: l’objectif de cette étape est,
comme lors de l’étape 1, de procéder a une sorte d’éclaircissement. Il s’agit de repérer les

1 Constatation faite en réalisant l’intersection pour chaque mot du réseau construit a partir du Los Angeles

Times entre ses cooccurrents et ses synonymes dans WordNet.

Découvrir des sens de mots

cooccurrents autour desquels s’organisent un ensemble d’autres cooccurrents, z'.e. des
germes de sens, mais aussi de repérer ceux qui sont visiblement sans connexion véritable
avec les autres. Pour ce faire, un seuil minimum est ﬁxé concemant le nombre de voisins
partagés par deux cooccurrents, seuil au-dessus duquel on considere les deux cooccurrents
comme fortement liés. On caractérise ensuite chaque cooccurrent par le nombre de liens
forts qu’il possede.

4. détermination des germes de sens et élimination du bruit: les germes de sens et les
cooccurrents laissés de cote sont déterminés par simple comparaison de leur nombre de
liens forts par rapport a un seuil.

5. construction des sens : cette étape consiste principalement a associer aux germes se sens
trouvés a l’étape précédente les cooccurrents non déja sélectionnés comme germe de sens
ou bruit pour former des classes représentant les sens du mot considéré. Pour associer un
cooccurrent a un germe de sens, la force du lien qui les unit doit étre supérieure a un seuil.
Si un rattachement a plusieurs germes est possible, est choisi le germe avec lequel la force
du lien est la plus grande. Par ailleurs, cette étape est aussi l’occasion de rassembler plu-
sieurs germes de sens considérés comme trop proches pour former des sens distincts : le
rattachement des cooccurrents fait donc également intervenir les germes de sens.

6. élargissement des sens : a l’issue des étapes précédentes, un nombre plus ou moins impor-
tant de cooccurrents n’ayant pas été considérés comme du bruit se retrouvent néanmoins
sans affectation a un sens. Ce nombre dépend bien entendu de la sévérité du seuil de ratta-
chement a un germe de sens mais l’objectif étant de former des classes homogenes, celle-
ci doit étre nécessairement assez forte. Néanmoins, il est également intéressant que les
sens puissent étre décrits de la facon la plus complete et la plus précise possible. Les sens
a ce stade étant caractérisés de facon plus sﬁre qu’a l’issue de l’étape 4, il est possible de
leur rattacher des cooccurrents dont la force de lien avec leurs constituants est plus faible.

4.3 Adaptation et modalités d’application de l’algorithme SNN

Les principes de l’algorithme SNN exposés dans la section précédente doivent étre précisés
sur certains points quant a leur mise en oeuvre. Le principal de ces points est le mode de ﬁxa-
tion de ses différents seuils. Nous avons opté pour un mode unique s’adaptant a la distribution
des Valeurs observées : chaque seuil est exprimé comme un certain quantile de ces valeurs.
Dans le cas du seuil de détermination des germes de sens (égal a 0,9) et de celui de deﬁnition
du bruit (égal a 0,2), il s’agit d’un quantile s’appliquant au nombre de liens forts des cooccur-
rents. Pour le seuil défmissant la notion de lien fort (égal a 0,65), celui de rattachement des
coocccurrents aux germes (égal a 0,5) et celui de rattachement des cooccurrents aux sens (égal
a 0,7), le quantile est appliqué directement a la force des liens entre cooccurrents dans le gra-
phe des plus proches voisins partagés.

Au-dela des modalités de mise en oeuvre des principes, nous avons également introduit des
adaptations. La plus importante d’entre elles est l’ajout d’une étape er1tre les deux demieres.
Nous avons en effet observé qu’en dépit de la possibilité, au niveau de la phase de construc-
tion des sens, de fusionner des classes par l’intermédiaire du rattachement d’un germe de sens
a un autre, certains sens restent divisés en plusieurs classes. Ce phénomene est observable
méme en faisant initialement appel a des cooccurrences d’ordre 2 et ne peut étre efﬁcacement

Olivier Ferret

traitéz par le seul ajustement du seuil controlant le rattachement des cooccurrents aux germes
de sens. Dans un nombre signiﬁcatif de cas, le sens << divisé » se répartit entre une ou plu-
sieurs classes ne regroupant que 3 a 4 mots et une classe de plus large ampleur. En pratique,
les germes de sens de ces classes <<minoritaires » n’ont pas pu étre rattachés a la classe
<<majoritaire » alors que la plupart des cooccurrents qui leur étaient liés s’y sont rattachés.
Plutot que de défmir un mécanisme spéciﬁque pour regrouper ces classes <<minoritaires »
avec la classe la plus importante, nous avons choisi de laisser l’algorithme dans sa forme ac-
tuelle le faire en détruisant ces classes (taille < 6) et en remettant leurs éléments dans
l’ensemble des cooccurrents non rattachés. La derniere étape de l’algorithme permet alors
dans la plupart des cas de rattacher ces cooccurrents a la classe <<majoritaire ». De plus, ce
mécanisme permet d’obtenir une plus grande stabilité des sens formés lorsque les parametres
de l’algorithme sont modiﬁés.

Une seconde adaptation, d’impact plus faible, a été opérée afm de s’assurer que les cooccur-
rents rattachés lors de la derniere étape n’introduisent pas de bruit. Nous avons ainsi impose’
que la condition de rattachement ne porte pas seulement sur la force de la relation entre le
cooccurrent a rattacher et l’un des membres de la classe mais sur la force moyenne des rela-
tions entre ce cooccurrent et les éléments de cette classe.

5 Expérimentation

Nous avons appliqué notre méthode de découverte de sens aux deux réseaux de cooccurrences
lexicales (LM : francais ; LAT : anglais) que nous avons construits avec les Valeurs de para-
metres précisées dans les sections précédentes. Pour chaque réseau, nous avons testé
l’utilisation initiale de cooccurrences d’ordre 1 (LM-1 et LAT-1) et d’ordre 2 (LM-2 et
LAT-2). Pour l’anglais, la seconde modalité n’a été testée que sur le sous-ensemble des mots
utilisés pour l’évaluation de la section 6 (LAT-2.no). Le tableau 1 synthétise les informations
concernant les sens découverts dans les différentes conﬁgurations. On remarquera qu’un
pourcentage signiﬁcatif de mots n’ont pas sens, meme avec les cooccurrences d’ordre 2. Ce
sont les mots dont les cooccurrents sont faiblement liés et dont le sens est probablement mal
représenté au sein de leur réseau de cooccurrences. Par ailleurs, on notera que l’utilisation des
cooccurrences d’ordre 2 conduit effectivement a réduire le nombre de sens par mot.

LM-1 LM-2 LAT-1 LAT-1.no LAT-2.no

nombre de mots 17.261 17.261 13.414 6.177 6.177
nombre de mots avec au 7.373 7.376 5.338 2.584 2.406
moins un sens (44,4%) (42,7%) (3 9,8%) (41.8%) (3 9%)
nombre moyen de sens 2,8 2,2 1,6 1,9 1,5
par mot

nombre moyen de mots 16,1 16,3 18,7 20,2 18,9
décrivant un sens

Tableau 1 : Statistiques concernant les résultats de la découverte de sens

A l’instar de Véronis (2003), nous illustrerons les résultats de notre algorithme en donnant
quelques uns des mots caractérisant les sens trouvés pour le mot barrage :

2 C’est-a-dire sans regrouper des classes correspondant :21 des sens différents.

Découvrir des sens de mots

LM-1 1.1 manifestant, forces_de_l’ordre, prefecture, agriculteur, protester, incendier, calrne, pierre
1.2 conducteur, routier, vehicule, poids_1ourd, camion, permis, trafic, bloquer, voiture, autoroute
1.3 ﬂeuve, lac, riviere, bassin, metre_cube, crue, arnont, pollution, aﬁluent, saumon, poisson
1.4 blessé, casque_bleu, soldat, milicien, tir, milice, convoi, évacuer, croate, milicien, combattant

LM-2 2.1 eau, metre, lac, pluie, riviere, bassin, ﬂeuve, site, poisson, aﬁluent, montagne, crue, vallee
2.2 conducteur, trafic, routier, route, camion, chauffeur, voiture, chauffeur_routier, poids_1ourd
2.3 casque_bleu, soldat, tir, convoi, milicien, blinde, milice, aeroport, blesse, incident, croate

On retrouve dans les deux cas 3 des 4 sens distingues dans (Veronis, 2003) : barrage hydrau-
lique (sens 1.3 et 2.1), barrage routier (sens 1.2 et 2.2), barrage frontiere (sens 1.4 et 2.3). Le
sens match de barrage n’est pas represente car faiblement present au niveau des cooccurren-
ces et de plus, au travers de certains mots ambigus, comme division, qui renvoient aussi a
d’autres domaines que le sport. Il faut preciser que barrage ne comporte ici que 1104 occur-
rences, a comparer avec environ 7000 occurrences pour (Veronis, 2003). Cet exemple illustre
egalement la difference de granularite des sens induite par l’utilisation des cooccurrences
d’ordre 1 ou 2. Le sens 1.1, qui est assez proche du sens 1.2, les deux faisant reference a des
manifestations de colere liee a une profession, disparait ainsi lorsqu’on fait appel aux cooc-
currences d’ordre 2. Nous donnons a la suite les sens pour d’autres mots en francais et en an-
glais avec des cooccurrences d’ordre 1 :

organe (1300) patient, transplantation, greffe, malade, therapeutique, medical, medecine, greffer, rein
procreation, embryon, ethique, humain, relatiﬂ bioethique, corps_humain, gene, cellule
constitutionnel, consultatif, constitution, instituer, executif, legislatif, sieger, disposition
article, hebdomadaire, publication, redaction, quotidien, journal, editorial, redacteur

mouse (563) compatible, sofvvare, computer, machine, user, desktop, pc, graphics, keyboard, device
laboratory, researcher, cell, gene, generic, human, hormone, research, scientist, rat

party (16999) candidate, democrat, republican, gubernatorial, presidential, partisan, reapportiomnent
ballroom, cocktail, champagne, guest, bash, gala, wedding, birthday, invitation, festivity
caterer, uninvited, party-goers, black-tie, hostess, buffet, glitches, napkins, catering

6 Evaluation

La decouverte de sens se heurte, comme les autres taches de construction de ressources lin-
guistiques, a la difﬁculte de l’evaluation du resultat obtenu. La voie la plus directe pour ce
faire est la comparaison avec une ressource de reference que l’on considere comme proche.
Dans le cas present, les reseaux lexico-semantiques de type WordNet s’imposent comme la
ressource de reference la plus proche. Utiliser ce type de reseaux pour evaluer les sens trouves
est certes critiquable puisqu’un des objectifs d’une telle decouverte est de depasser les limites
de ces reseaux. Neanmoins, compte tenu du caractere controle de ces derniers, une telle eva-
luation apporte au moins un element de jugement important quant a la ﬁabilite des sens mis
en evidence. Nous avons choisi de reprendre le protocole d’evaluation deﬁni dans (Pantel,
Lin, 2002), protocole qui s’appuie sur WordNet et dont l’accord avec un jugement manuel est
raisonnablement bon (88% pour Pantel et Lin). Notre evaluation ne portera donc que sur
l’anglais et a ete realisee avec Wordnet 1.7.1. Ce protocole consiste a essayer de mettre en
correspondance chaque sens trouve pour un mot avec l’un de ses synsets dans WordNet et ce,
au moyen d’une mesure de similarite. Il s’agit donc d’une mesure de precision. Pantel et Lin
precisent qu’une mesure de rappel n’est dans le cas present que faiblement signiﬁcative : un
sens decouvert peut etre valide et non present dans WordNet et a l’inverse certaines distinc-
tions de sens dans WordNet ne sont pas necessairement souhaitables. Ils defmissent nean-

Olivier Ferret

moins une mesure de rappel mais destinée seulement a classer un ensemble de systemes. Elle
n’est donc pas applicable a notre seule méthode.

La mesure de similarité entre un sens et un synset utilisée pour le calcul de la précision
s’appuie sur la mesure de similarité entre synsets déﬁnie par Lin :

2 x log P(s)

' 1, 2 =4
”"m(s S ) logP(sl)+logP(s2)

(1)
ou s est le synset le plus spéciﬁque subsumant les synset s1 et s2 dans la hiérarchie de Word-
Net et ou P(s) représente la probabilité du synset s calculée a partir d’un corpus de référence,
en l’occurrence le SemCor. Pour le calcul de cette mesure, nous nous avons utilise’ le module
Perl WordNet::Similarity V0.06 (Patwardhan, Pedersen, 2003).

La similarité entre un sens et un synset est plus précisément déﬁnie comme la moyenne des
similarités entre les mots composant le sens, ou une partie de ceux-ci, et le synset. La similari-
té entre un mot et un synset est elle-méme donnée par la plus forte des similarités entre le syn-
set et les synsets auxquels le mot considéré appartient, celles-ci reposant sur (1). Un sens est
affecté au synset qui lui est le plus similaire, a condition toutefois que la similarité entre les
deux soit supérieure a un seuil (égal ici a 0,25 comme dans (Pantel, Lin, 2002)). Finalement,
la précision pour un mot est donnée par le rapport entre le nombre de ses sens s’appariant
avec un de ses synsets et le nombre total de ses sens.

LAT-1.no LAT-2.no
nombre de liens forts 19,4 20,8
choix optimum 56,2 63,7

Tableau 2 : Précision moyenne des sens découverts pour l’anglais par rapport a WordNet

Le tableau 2 donne le résultat de l’éValuation de notre algorithme de découverte de sens pour
les mots du réseau de cooccurrences anglais qui ne sont que des noms et qui ont au moins un
sens. Deux mesures sont données. Comme Pantel et Lin, nous ne prenons en compte que 4
mots de chaque sens pour l’éValuation. Mais contrairement a eux, nous n’aVons pas de mesure
spéciﬁque de la proximité des mots d’un sens par rapport au mot qu’il décrit. Nous donnons
donc la précision moyenne obtenue en choisissant les 4 mots d’un sens ayant le plus grand
nombre de liens forts (les criteres de fréquence ou de cohésion dans le réseau de cooccurren-
ces donnent les mémes résultats) et celle obtenue en choisissant les 4 mots d’un sens permet-
tant d’aVoir un score maximal. Nous constatons a l’éVidence un écart important entre ces deux
mesures : la pertinence des sens distingués est comparable a celle obtenue par Pantel et Lin
lorsque le choix des 4 mots représentatifs d’un sens est optimal (Pantel et Lin obtiennent une
précision de 60,8 pour un nombre de mots par sens égal a 14) mais les mots choisis pour re-
présenter un sens dans notre cas ne sont pas fortement liés dans WordNet (selon la mesure de
Lin) au mot caractérisé par ce sens. Cela ne signiﬁe d’ailleurs pas que ces mots ne soient pas
intéressants pour décrire un sens mais plus sﬁrement que leur lien avec lui repose sur des rela-
tions sémantiques autres que l’hyperonymie. Le meilleur résultat obtenu par Pantel et Lin sur
ce point s’eXplique par le fait que la base de leur méthode est le regroupement de mots simi-
laires et non la classiﬁcation des cooccurrents d’un mot, lesquels ne comportent pas beaucoup
de synonymes de leur mot source. Enfm, il est a noter que leur corpus de départ est beaucoup
plus large (de l’ordre de 144 millions de mots) et qu’ils font appel a des moyens d’analyse
plus élaborés, en l’occurrence un analyseur syntaxique.

Découvrir des sens de mots

Sans surprise, les résultats obtenus avec les cooccurrences d’ordre l (LAT-l.no), qui condui-
sent a un nombre de sens plus important, sont inférieurs a ceux obtenus avec les cooccurren-
ces d’ordre 2 (LAT-2.no). En l’absence de rappel, il est néanmoins difﬁcile d’en tirer une
conclusion claire : il est probable que des sens se trouvent divisés de facon artiﬁcielle dans le
cas de LAT-l.no mais ce phénomene peut simultanément masquer la couverture d’un plus
grand ensemble de sens effectifs perrnise par la meilleure homogénéité des classes formées.

7 Discussion

De par sa nature, notre méthode se compare le plus directement a (Véronis, 2003) et (Dorow,
Widdows, 2003). Malgré une proximité d’approche générale avec (Rapp, 2003), la distance
avec ce dernier est plus grande car il ne repose pas sur la détection de composantes de forte
densité dans un graphe de cooccurrence. (Véronis, 2003) et (Dorow, Widdows, 2003) ne pre-
sentant pas d’évaluation formelle, seule une comparaison qualitative est possible. Deux diffe-
rences principales sont a noter avec notre travail. La premiere est l’utilisation directe du gra-
phe de cooccurrence. Nous avons opté pour notre part pour une approche plus générale en
travaillant au niveau d’un graphe de similarité : lorsque la similarité er1tre deux mots est don-
née par leur relation de cooccurrence, notre situation est la méme que celle des travaux cités
mais nous pouvons prendre en compte dans le méme cadre des relations de similarité plus
générales, telles que les cooccurrences de second ordre. La seconde différence est l’utilisation
d’une procédure itérative de distinction des sens. Cette procedure consiste a sélectionner a
chaque étape le sens se détachant le plus clairement puis a actualiser le graphe de cooccur-
rence en en éliminant les constituants du sens formé, ce qui permet de faire apparaitre plus
distinctement les sens résiduels. Nous avons préféré quanta nous mettre l’accent sur la possi-
bilité de réunir des sens tres proches, voire identiques, artiﬁciellement séparés par la seule
utilisation de formes de surface (cf. section 4.3). Plus globalement, les deux différences poin-
tées ont pour conséquence principale de conduire a des distinctions de sens plus fines que
celles que nous mettons en évidence. Cependant, les méthodes de découverte de sens a partir
de corpus ayant plutot tendance a distinguer un trop grand nombre de sens proches, il nous a
semblé plus important de favoriser la mise en évidence de sens stables et nettement délimités
que de rechercher une tres grande ﬁnesse dans les distinctions de sens réalisées.

8 Conclusion et perspectives

Nous avons présenté dans cet article une nouvelle méthode pour différencier et caractériser le
sens des mots a partir d’un réseau de cooccurrences lexicales. Cette méthode applique un al-
gorithme de classiﬁcation non supervisé, l’algorithme SNN, aux cooccurrents des mots dont
on veut différencier les sens en se fondant sur les relations que ces cooccurrents entretiennent
dans le réseau. Nous en avons réalisé une premiere évaluation suivant le protocole défmi dans
(Pantel, Lin, 2002), évaluation montrant que la pertinence des sens formés est comparable a
celle des sens formes par Pantel et Lin. Cette évaluation doit cependant étre approfondie. Il
semble en particulier nécessaire de s’appuyer sur une mesure de similarité er1tre synset et sens
formé permettant de prendre en compte un ensemble plus vaste de relations sémantiques telles
que celles implicitement présentes dans les << glosses » associées aux synsets. Par ailleurs, une
évaluation au travers d’une utilisation dans une tache telle que l’eXpansion de requétes nous
semble également nécessaire afm de juger de l’apport véritable de ce type de ressource par
rapport a une ressource de type WordNet.

Olivier Ferret

Références

AGIRRE E., LOPEZ DE LACALLE O. (2003), Clustering WordNet Word Senses, Actes de
RANLP 2003.

CHURCH K.W., HANKS P. (1990), Word Association Norms, Mutual Information, And Lexi-
cography, Computational Linguistics, Vol. 16(1), pp. 177-210.

DOROW B., WIDDOWS D. (2003), Discovering Corpus-Speciﬁc Word Senses, Actes de
EACL 2003, pp. 79-82.

ERTOZ L., STEINBACH M., KUMAR V. (2001), Finding Topics in Collections of Documents: A
Shared Nearest Neighbor Approach, Actes de Text Mine ’0I, Workshop of the I“ SIAM Inter-
national Conference on Data Mining.

HARABAGIU S, MILLER G.A., MOLDOVAN D (1999), WordNet 2 - A Morphologically and
Semantically Enhanced Resource, Actes de SIGLEX’99, pp. 1-8.

DE LOUPY C., EL-BEZE M. (2002), Managing Synonymy and Polysemy in a Document Re-
trieval, Actes de LREC 2002 Workshop on Creating and Using Semantics for Information
Retrieval.

MILLER G.A. (1995), WordNet: A lexical Database, Communications of the ACM

MIHALCEA R., MOLDOVAN D. (2001), eXtended WordNet: Progress Report, Actes de NAA CL
2001 Worshop on WordNet and Other Lexical Resources, pp. 95-100.

PASCA M AND HARABAGIU S. (2001), The informative role of WordNet in Open-Domain
Question Answering, Actes de NAACL 2001 Worshop on WordNet and Other Lexical Re-
sources, pp. 138-143.

PANTEL P., LIN D. (2002), Discovering Word Senses from Text, Actes de ACM SIGKDD
Conference on Knowledge Discovery and Data Mining 2002, pp. 613-619.

PATWARDHAN S., PEDERSEN T. (2003), WordNet::Similarity, http://www.d.umn.edu/
~tpederse/similarity.html.

PEDERSEN T., BRUCE R. (1997), Distinguishing Word Senses in Untagged Text, Actes de
EMNLP’97, pp. 197-207.

PURANDARE A. (2003), Discriminating Among Word Senses Using Mcquitty's Similarity
Analysis, Actes de HLT-NAA CL 03 - Student Research Workshop.

RAPP R. (2003), Word Sense Discovery Based on Sense Descriptor Dissimilarity, Actes de
Machine Translation Summit IX.

SCHUTZE H. (1998), Automatic Word Sense Discrimination, Computational Linguistics,
Vol. 24(1), pp. 97-123.

VERONIS J. (2003), Cartographie lexicale pour la recherche d’information, Actes de
TALN2003, pp. 265-274.

