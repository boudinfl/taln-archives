TALN 2004, Fe‘s, 19-21 avril 2004

Fusionner pour mieux analyser :
Conception et évaluation de la plate-forme de combinaison

Francis Brunet-Manquat

GETA-CLIPS — Université Joseph Fourier (Grenoble 1)
BP 53 — 38041 Grenoble Cedex 9, France
Francis.Brunet-Manquat@imag.fr

Résumé — Abstract

L’objectif de cet article est de présenter nos travaux concernant la combinaison d’analyseurs
syntaxiques pour produire un analyseur plus robuste. Nous avons créé une plate-forme nous
perrnettant de comparer des analyseurs syntaxiques pour une langue donnée en découpant
leurs résultats en informations élémentaires, en les normalisant, et en les comparant aux
résultats de référence. Cette méme plate-forme est utilisée pour combiner plusieurs analyseurs
pour produire un analyseur de dépendance plus couvrant et plus robuste. A long terrne, il sera
possible de “compiler” les connaissances extraites de plusieurs analyseurs dans un analyseur
de dépendance autonome.

The goal of this article is to present our works about the combination of syntactic parsers to
produce a more robust parser. We have built a platform which allows us to compare syntactic
parsers for a given language by splitting their results in elementary pieces, normalizing them,
and comparing them with reference results. The same platform is used to combine several
parsers to produce a dependency parser, which is big construction broader and more robust
than its component parsers. In the future, it should by possible to “compile” the knowledge
extracted from several analyzers into an autonomous dependency parser.

Mots Clés — Keywords

Analyse de dépendance, analyse syntaxique, combinaisons d’inforrnations.

Dependency parsing, syntactic parsing, Information combination.

1 Introduction

Notre laboratoire est impliqué dans deux projets internationaux importants : CSTAR et son
projet européen associé NESPOLE ! (http://nespole.itc.it) pour la traduction simultanée de
l’oral et Universal Networking Language, UNL (http://www.unl.ias.unu.edu), pour la
traduction de l’écrit. Ces projets se caractérisent notamment par la présence d’une
représentation pivot des énoncés et par le fait que l’énoncé a traduire est susceptible d’étre
bruite’, c’est-a-dire pas nécessairement conforme a la grammaire académique de la langue
francaise. Dans un systeme a pivot, l’énoncé d’une langue source donnée est analyse’ dans la
représentation pivot avant d’étre génére’ vers une ou plusieurs langues cibles. La nécessité de

Francis Brunet-Manquat

pouvoir traiter des entrees bruitees implique des outils robustes d’analyse de la langue,
capables de foumir une analyse meme partielle de la phrase.

L’objectif est de concevoir un analyseur prenant le << meilleur » d’un ensemble d’analyseurs.
Le principe de notre travail est de combiner differents resultats d’analyse obtenus pour le
meme enonce, puis de calculer les meilleures informations pour obtenir la ou les meilleures
analyses possibles. Notre approche se base sur la methode dite du << vote a la majorite », plus
une information sera commune aux diﬁérents analyseurs, plus le poids de cette information
sera fort, et sur un apprentissage permettant d’adapter les poids associes aux informations
foumies en fonction de l’enonce (par exemple, entree bruitee ou non) et des analyseurs.

L’approche utilisee, dite par combinaison, a deja connu de nombreux succes en
reconnaissance de la parole (Fiscus 1997, Schwenck et Gauvain 2000), en etiquetage morpho-
syntaxique (Halteren et al. 1998, Brill et al. 1998, Marquez et Padro 1998), en reconnaissance
des entites nommes (Borthwick et al. 1998), en desambigu'1'sation du sens des mots (Pedersen,
2000) et, plus recemment, en analyse syntaxique (Henderson et Brill 1999, Inui et Inui 2000,
Monceaux et Robba 2003). Ces travaux demontrent que combiner differents systemes apporte
le plus souvent une amelioration par rapport au meilleur systeme.

Nos travaux en analyse syntaxique se differencient de ceux de nos predecesseurs par la
methode de combinaison employee. En effet, notre plate-forme se compose a la fois d’un
mecanisme de re-construction et d’un traitement statistique. De plus, nous basons notre plate-
forrne d’analyse sur une representation par dependances, decrivant les relations syntaxiques
entre mots. En effet, l’analyse anterieure suggere fortement que ce type de representation est
plus adapte pour une analyse robuste. Il nous permet, par exemple, de representer clairement
et simplement l’analyse partielle d’une phrase mal formee.

Apres avoir detaille la conception de notre plate-forme d’analyse, nous decrivons notre
processus de construction de structures de dependance. Ensuite, nous presentons les
evaluations obtenues suivies par une conclusion et une discussion sur les perspectives.

2 Conception de la plate-forme d’analyse

La plate-forme d’analyse ne doit pas integrer les analyseurs, mais elle doit etre capable
d’extraire les informations linguistiques des resultats qu’ils produisent, de les interpreter, de
les fusionner et enfir1 de produire un arbre de dependance (ou plusieurs) combir1ant le meilleur
des informations extraites.

2.1 Etapes du traitement

Le processus supporte par la plate-forme comporte deux etapes : la normalisation des
resultats d’analyse et la construction des analyses de dependance.

L’etape de normalisation des resultats d’analyse se compose de deux phasesl :

' La phase d’extraction permet de recuperer les informations linguistiques des resultats
obtenus a partir des analyseurs linguistiques. Ces analyseurs se repartissent en trois
categories en fonction des resultats qu’ils fournissent (Monceaux et Robba 2002) :
les analyseurs fondes sur les constituants qui retournent une segmentation en

1 L’etape de normalisation a ete decrite et evaluee dans (Brtmet-Manquat 2003).

F usionner pour mieux analyser

groupes, les analyseurs fondes sur les dependances qui retournent les dependances
entre mots d’une phrase et les analyseurs fondes sur les constituants et les
dependances qui retournent une segmentation en groupes et des dependances er1tre
ces groupes et entre les mots.

La phase de projection traite les informations extraites pour obtenir un ensemble de
structures de dependance dites normalisees. A chaque information contenue dans ces
structures est associe un indice exprimant la confiance relative dans cette
l’inforrnation (categories, Variables grammaticales ou relations syntaxiques) en
fonction de l’analyseur l’ayant produite. Ces indices sont precalcules lors d’une
phase d’apprentissage (Voir 2.3 Apprentissage des indices de confiance). Une
structure de dependance est decrite par une representation matricielle qui presente de
nombreux avantages : maniabilite, efficacite, etc. (Voir 2.2 Matrice de dependances
(MD))-

L’etape de construction d’un ensemble d’analyses de dependance se compose de trois phases :

La phase de correspondance qui permet de lier les noeuds des differentes structures
norrnalisees foumies par l’etape precedente. Pour ce faire nous creons une structure,
appelee réseau de segmentation, representant differentes segmentations de la phrase
(treillis) et permettant de lier les noeuds des structures normalisees. Ce reseau peut
etre Vu comme un « pivot de liaison » er1tre ces structures (Voir 3.1 Correspondance
des structures de dependance).

La phase de fusion des informations linguistiques qui permet, a l’aide des
correspondances etablies precedemment, d’obtenir une unique representation de
dependance contenant toutes les informations linguistiques produites, meme les
informations contradictoires. Toutes ces informations ainsi fusionnees Verront leurs
indices de confiance recalcules (Voir 3.2 Fusion des informations).

La phase de production qui permet de construire les nouvelles structures de
dependance en fonction des informations fusionnees, des indices de confiance
recalcules, et de contraintes linguistiques et structurelles de production (Voir 3.3
Production des structures de dependance).

2.2 Matrice de dépendances (MD)

Notre plate-forme d’analyse est fondée sur les dépendances, c’est-a-dire qu’elle retourne les
dependances er1tre les mots d’une phrase. Une structure de dependance est decrite, dans notre
plate-forme, par une representation matricielle. Notre representation, nommee matrice de
dépendance (MD), est un couple <L, M> compose de :

Une liste de naeuds (L), un noeud etant compose d’informations linguistiques relatives
aux mots qu’il decrit ;

Une matrice carrée (M) permettant de decrire les dependances er1tre noeuds. La case
(i, j) contient l’ensemble des dependances er1tre le noeud i et le noeud j de la liste de
noeuds.

 
   

 
    

   

Deter  Complémem‘ Déterm%
La recherche frangaise perd ses moyens

Figure 1 : Structure de dependance syntaxique

Francis Brunet-Manquat

La MD correspondant a la structure de dependance syntaxique ci-dessus est :

L = M =
relation

la :: cat=determinant

recherche :: cat=nOm la recherche frangalse perd ses moyens
francaise :: cat= adjectif Ia Déterminam
perd :: cat=verbe

SGS 22 cat=deterrninant recherche Determinant Complément

moyens :: cat=nom

francaise
perd Sujet Objet
SSS
moyens

Une representation matricielle des donnees presente deux avantages pour le traitement
informatique :
' Maniabilite’ : de nombreux outils mathematiques sont associes aux matrices: ajout,

suppression, comparaison, etc. Tous ces outils permettent un traitement simple de
l’inforrnation contenue dans une matrice.

' Eﬂicacite’ : les methodes utilisant les matrices comme structures de donnees, telle que la
reconnaissance de motifs ou la fusion de matrice, se montrent tres efficaces et tres simples a
mettre en place.

2.3 Apprentissage des indices de confiance

Dans (Brunet-Manquat 2003), nous presentons les regles de projection perrnettant de transformer les
informations extraites en un ensemble d’informations norrnalisees. A chaque nouvelle information
norrnalisee I (categories, Variables grammaticales ou relations syntaxiques) est associe un indice de
confiance. Cet indice exprime la confiance relative de l’information I en fonction de l’analyseur
l’ayant produite.

Les indices sont calcules a l’aide des evaluations effectuees sur chaque analyseur. Pour chaque
analyseur Ai, nous calculons les taux de rappel et de precision de chaque information linguistique I
pouvant etre produite par Ai :

RappelA,.(I) = Nombre d’informations I correctes / Nombre d’informations I de référence

Pre’cisionA,.(I) = Nombre d’informations I correctes / Nombre d’informations I proposées
Un indice de confiance correspond au calcul de la F-mesure (efficacite globale) qui combine
precision et rappel en une mesure unique :

IndiceA,.(I) = ( Pre’cisi0nA,-(I) [3 RappelA,- (I) ) / ( Pre’cisi0nA,- (I) + RappelA,- (I )) )

Dans le cadre de nos travaux sur la construction d’un analyseur robuste et couvrant, ni le rappel ni la

precision ne sont a privilegier. La F-mesure permet de representer une moyenne harmonique entre
ces deux mesures.

3 Construction des structures de dépendance

A la fin de l’etape de normalisation, un ensemble de structures de dependance est associe a chaque
phrase. La phase suivante consiste a fusionner toutes ces structures pour obtenir une unique
representation de dependances contenant toutes les informations linguistiques presentes dans ces

F usionner pour mieux analyser

structures (categories, Variables grammaticales, relations syntaxiques). Pour réaliser cette fusion, il
faut, dans un premier temps, mettre en correspondance ces structures.

3.1 Correspondance des structures de dépendance

La correspondance de structures consiste a regrouper les noeuds représentant la meme segmentation
dans la phrase (information commune minimale). Mais elle consiste également a représenter les
discordances issues des différentes segmentations des structures et dues, par exemple, aux mots
composes, aux entrees des dictionnaires (Etats Unis ou Etats_Unis), etc.

Pour ce faire, nous créons une structure, appelée réseau de segmentation (RS), représentant les
différentes segmentations de la phrase et perrnettant de lier les noeuds des structures norrnalisées. Ce
réseau peut étre Vu comme un «pivot de liaison » entre ces structures. Ce réseau est un treillis,
chaque noeud du réseau représentant une segmentation possible d’un mot et servant de liaison entre
les noeuds des structures de dépendance. Concretement, un noeud N“ d’un RS contient deux
inforrnations :

' SNODE(N,s) : intervalles représentant la sous-chaine dans la phrase correspondant au noeud
N,s, Par exemple, les mots de la phrase << On avait dénombré cent Vingt-neuf candidats »
auront pour intervalles : 0n[1-2], avait[3-7], de’nombre’[8-I5], etc. Cette information est
basée sur la proposition de (Boitet et Zaharin, 1988) Structured String-Tree
Correspondences (SSTC).

' L : un ensemble contenant les noeuds des structures normalisees lies au noeud N,s.

La premiere étape consiste a créer un réseau de segmentation initial pour chaque arbre de
dépendance. Chaque noeud N,s d’un RS initial est crée en fonction d’un noeud N, de la structure de
dépendance Sk : SNODE(N,s) = SNODE(Sk.Ni) et L(Nrs) = {Sk.Ni}. Les noeuds du RS seront insérés
dans le treillis selon l’ordre d’apparition dans la phrase (en fonction du SNODE). Dans la suite du
traitement, nous prendrons comme exemple les deux structures de dépendance et leurs RS initiaux
suivants :

Structure 1 .' ‘/\

on avait dénombré cent Vingt-neuf candidats
RS4 _. on _ avlait _ dénolmbré _ cent _ Vingt-neuf _ candidats

1-2 3-7 8-15 16-19 20-29 30-38
structure 2 ' on avait dénombré cent Vingt-neuf candidats
R32 _. oln avlait dénolmbré cent virigt-neuf candidats

1-2 3-7 8-15 16-29 30-38

Faisons la correspondance entre RS-l et RS-2. Le premier réseau initial RS-l est désigné comme le
réseau de base RS-base, qui servira tout au long du traitement. La suite consiste a introduire les
particularités des autres RS initiaux dans le réseau de base. Pour ce faire, nous utilisons deux regles
de construction :

Francis Brunet-Manquat

' Régle 1) Correspondance : Si le noeud Ni de RS-k est equivalent a l’un des noeuds Nii de
RS-base (l’équiValence est Vraie si SNODE(Ni) == SNODE(Nis)), Nii sera lie aux noeuds de
la structure que représente Ni : L(Nii) = L(Nii) [3 L(Ni).

' Régle 2) Insertion : Si le noeud Ni de RS-k n’est equivalent a aucun noeud de RS-base, le
noeud Ni est inséré dans RS-base en fonction de son SNODE (ordre d’apparition dans la
phrase).

Les premiers noeuds on[1-2], avait[3-7], de’nombre’[8-I5] de RS-2 Vérifient la premiere regle, ils
correspondent aux noeuds on[1-2], avait[3-7], de’nombre’[8-15] de RS-base. Le quatrieme noeud cent
vingt-neuf[16-I9] de RS-2 Vérifie la seconde regle, il est donc inséré dans RS-base. Le dernier noeud
de RS-2 Vérifie la premiere regle. Nous obtenons donc le réseau suivant :

Structure 1 : ‘/\

on avait dénombré cent vingt—neuf candidats
_ ax/lait _ dénolmbré _ ceint _ vingt—neuf _ candidats
1-2 3-7 8-15 16-19 20-29 30-38
RS‘ -' I ,' I cent vingt—neuf I
j : ; 16-29 :
I I I E I
on avait dénombré cent vingt—neuf candidats

Structure 2 _- V\:\/v/  /V

Le réseau de segmentation final obtenu représente les segmentations possibles et lie les noeuds des
structures entre euxz. Maintenant que la correspondance entre les noeuds des structures est établie,
nous pouvons fusionner ces structures pour fournir une unique representation de dépendance
combinant toutes les informations linguistiques relatives aux structures.

3.2 Fusion des informations

Les correspondances entre les différentes structures étant établies, la phase de fusion des
informations linguistiques peut débuter. La méthode utilisée lors de cette phase est basée sur la
méthode dite de << Vote a la majorité » : plus une information sera commune aux diﬁ”e’rents
analyseurs, plus son poids augmentera, dans notre cas plus son indice de confiance augmentera.
Chaque indice po11rra étre Vu comme le vote ponde’re’ de l’analyseur pour l’inforrnation, ce Vote étant
adapte’ aux différentes capacités de l’analyseur en fonction de l’énoncé (par exemple, entree bruitée
ou non) lors de la phase d’apprentissage.

A la fin de la phase de correspondance, a chaque phrase sont associés un ensemble de structures de
dépendance et un réseau de segmentation permettant de les lier. La suite du traitement consiste a
créer pour chaque réseau de segmentation une structure de dépendance, nommee matrice de fusion
(les noeuds du RS serviront de noeuds pour cette representation), puis de la compléter en fusionnant
toutes les informations linguistiques contenues dans les structures de dépendance associees.

Nous proposons dans (Brunet-Manquat 2004) de parfaire la phase de correspondance en ajoutant des régles de
correspondance permettant de traiter les mots composés, par exemple, en établissant une relation entre le noeud
Etats_Unis et les noeuds Etats et Unis.

F usiormer pour mieux analyser

Certaines informations linguistiques seront équivalentes, d’autres contradictoires (par exemple la
dépendance SUBJ(x,y) est contradictoire avec la dépendance OBJ(x,y), les catégories morpho-
syntaxiques sont mutuellement contradictoires). Il ne s’agit pas simplement de regrouper toutes ces
informations, il faut également calculer de nouveaux indices de confiance, les indices de fusion,
pour chaque information, en fonction des indices de confiance foumis par l’étape de normalisation.
Deux calculs sont possibles : le calcul normalise ou le calcul corrigé.

Calcul normalisé : l’indice de fusion de l’information I est égal a la somme des indices de
confiance divisé par le nombre d’analyseurs pouvant fournir cette information: (11: nombre
d’analyseurs pouvant fournir l’inforrnation I)

( ﬁ(L) )

- '= alyseur fournissant
I I = 1 an
nd1ce,( ) 1'informationI
fusion
11

Par exemple, calculons l’indice de fusion a associer a l’inforrnation OBJ(x,y) (relation OBJ entre les
mots x et y), fournie a la fois par l’analyseur Al et par l’analyseur A2. L’indice de fusion associé a
OBJ(x,y) est égal a la somme des deux indices de confiance indice(OBJ::A1)=0,5 et
indice(OBJ::A2)=0,7 divisee par le nombre d’analyseurs pouvant fournir ce type d’inforrnation (ici
trois pour l’exemple), (0,5+0,7+0)/ 3 = 0,4. Si le troisieme analyseur fournit une information de type
SUBJ er1tre les mots x et y, et si l’indice de confiance relatif a cette information est de 0,8, l’indice
de fusion associé a SUBJ(x,y) est égal a (0+0+0,8)/3 = 0,26.

Calcul corrigé : L’indice de fusion de l’inforrnation I est égal a la somme des indices de confiance
des informations I moins la somme (multipliée par un coefficient de correction B) des indices de
confiance des informations contradictoires a l’information 1, le tout divisé par le nombre
d’analyseurs pouvant fournir l’inforrnation I :

( ﬁ(L) -BB 5(%) )

Indicea) _ i=analyseur fournissant p=analyseur fournissant une
_ Pinformation I information contradictoire a I

I1
Pour l’exemple precedent, les relations syntaxiques entre les mots x et y sont contradictoires : soit
OBJ(x,y), soit SUBJ(x,y). L’indice de fusion associé a OBJ(x,y) est égal a ((0,5+0,7) — (0,4 * 0,8))/3
= 0,29 (en prenant comme coefficient de correction 0,4) et l’indice de fusion associé a SUBJ(x,y) est
égal a (0,8 — 0,4 * (0,5+0,7))/3 = 0,1.

fusion

Ces calculs favorisent les informations fournies par le plus grand nombre d’analyseurs. Les
nouveaux indices de fusion ainsi calcules serviront lors de la phase de production.

3.3 Production des structures de dépendance

Cette demiere phase permet de construire les nouvelles structures de dépendance grace aux
informations recueillies précédemment. Ces structures sont produites a partir des indices de fusion
associés a ces informations et de contraintes linguistiques et structurelles. Le mécanisme de
production est base sur une méthode de satisfaction de contraintes comportant 3 regles :

Soit une information I de type catégorie morpho-syntaxique ou Variable grammaticale d’une
matrice de fusion MDMOD :

' Pour chaque noeud N de MDfusm, elle est conservée si son indice de fusion est supérieur aux
indices de fusion des informations contradictoires.

Francis Brunet-Manquat

Pour les dependances syntaxiques de MDfusi0,1 :

' Une seule dependance syntaxique entre deux noeuds Niet Nk est conservee, a savoir
l’information de dependance ayant l’indice de fusion le plus fort de la case M(i,k) de
mhsion 

' Un noeud Ni ne depend que d’un seul noeud Nk : de toutes les informations syntaxiques
designant Ni comme dependant (colonne M(i) de MDMOH), seule l’inforrnation ayant
l’indice le plus fort est conservee.

En ce qui concerne le traitement des noeuds discordants issus des differentes segmentations, nous
choisissons de conserver seulement les noeuds issus du << meilleur » segmenteur parmi nos
analyseurs (l’analyseur ayant la segmentation en unite lexicale la plus proche du corpus de
reference). Nous introduirons prochainement un mecanisme associant a chaque noeud un indice de
confiance sur sa segmentation exactement comme les indices de confiance sur les informations
linguistiques et permettant d’introduire une contrainte sur la segmentation lors de notre phase de
production.

4 Experimentation et mesures

4.1 Corpus et analyseurs

Nous disposons pour cette evaluation de trois analyseurs syntaxiques : l’analyseur IFSP
(Incremental Finite-State Parser) (Ait-Mokhtar et Chanod 1997) qui construit les groupes
syntagmatiques noyaux des phrases en entree, puis utilise la structure ainsi construite pour extraire
des relations syntaxique entre mots, l’analyseur syntaxique du GREYC (Vergne 1998) qui combine
des techniques d’etiquetage grammatical pour construire des segments non-recursifs et un
algorithme de calcul de dependances pour calculer la structure fonctionnelle et l’analyseur XIP (Ait-
mokhtar et al. 2002) qui disposent de differents processus linguistiques organises de facon
incrementale (annotation morphologique, decoupage en syntagme, extraction de dependances) pour
obtenir une analyse de dependance.

Le corpus utilise est le corpus arbore de l’uniVersite Paris VII (Abeille et Clement 1999). Ce corpus
est constitue d’un million de phrases extraites du journal Le Monde. Les phrases sont segmentees en
constituants et les mots sont annotes. Une petite partie de ce corpus a ete normalisee pour
correspondre a un corpus constitue de dependances. Nous utilisons pour cette experimentation un
corpus de 200 phrases, choisies arbitrairement, constitue de phrases longues et complexes, 30 mots
en moyenne par phrase (minimum 9 mots, maximum 73 mots). Par exemple :

<< La cessation de paiement constate’e, le tribunal de commerce nomme un administrateur judiciaire,
qui doit e’valuer les dettes - alors gele’es - et proposer soit un plan de continuation, soit la
liquidation judiciaire. »

4.2 Calcul des indices de conﬁance

Nous traitons dans un premier temps les 100 premieres phrases pour la phase d’apprentissage (Voir
table 1). Notre experimentation se restreint pour le moment a 5 informations linguistiques : 3
categories morpho-syntaxiques (nom, Verbe et adjectif) et 2 dependances syntaxiques (sujet et
complement de tous types).

Les mauvais resultats concemant les dependances s’expliquent par le nombre moyen de mots par
phrases et par leurs complexites. Les indices (F-mesures), ainsi calcules, nous permettent de
produire nos resultats de combinaison sur les 100 phrases restantes.

F usiormer pour mieux analyser

Corpus IF SP Vergne XIP
Nb R P F R P F R P F
Cat(N om) 806 84,8 78,4 78,4 78,6 77,1 77,8 86,1 74,5 79,9
Cat(Verb) 169 88,1 93,1 90,5 92,8 97,5 95,1 98,2 71,8 83,0
Cat(Adj) 189 76,7 72,8 74,7 87,8 57,6 69,6 75,1 57,4 65,1
Sujet 146 54,7 45,9 50,0 33,5 39,9 36,4 65,7 41,0 50,5
Comp 750 53,4 22,0 31,2 49,6 37,9 43,0 49,3 29,2 36,7

Table 1 : calcul des indices de confiance
4.3 Evaluation des résultats d’analyse

Nous evaluons maintenant nos resultats et egalement les resultats des autres analyseurs (voir table
2). Les resultats de combinaison sont obtenus en utilisant le calcul normalise vu precedemment.
Toutes les F-mesures concemant notre plate-forme de combinaison sont superieures aux mesures
effectuees sur les autres analyseurs. Ces mesures demontrent que combiner differents analyseurs
apportent une amelioration par rapport aux autres analyseurs.

Corpus IFSP Vergne XIP Combinaison
Nb R P F R P F R P F R P F

Cat(Nom) 684 85,6 77,2 81,2 82,6 76,7 79,5 87,1 75,6 80,9 87,5 81,8 84,6

Cat(Verb) 181 85,6 93,9 89,5 91,7 91,2 91,4 97,7 65,0 78,1 90,6 94,2 92,3

Cat(Adj) 174 81,6 85,0 83,2 87,9 74,2 80,5 80,4 60,3 68,9 77,0 86,4 81,4

Sujet 148 58,1 45,9 51,3 33,1 35,7 34,3 70,9 39,9 51,0 67,5 43,8 53,1

Comp 671 26,4 58,7 36,4 49,0 35,8 41,4 53,0 30,6 38,8 59,1 32,7 42,1

Table 2 : evaluation des analyseurs et des resultats de combinaison

5 Bilan et perspectives

Notre plate-forme perrnet de comparer des analyseurs syntaxiques pour une langue donnee en
decoupant leurs resultats en inforrnations elementaires, en les norrnalisant, et en les comparant aux
resultats de reference. Cette meme plate-forme combine plusieurs analyseurs pour produire un
analyseur de dependance plus couvrant et plus robuste que ces composants. Les evaluations
effectuees precedemment demontrent que notre methode de combinaison, un mecanisme de re-
construction associe a un traitement statistique, apportent une amelioration par rapport aux autres
analyseurs.

A court terme, notre plate-forme sera testee sur d’autres langues (une experimentation est en cours
de realisation sur l’anglais). Nous comptons egalement combiner d’autres types d’analyseur
(semantique par exemple) aux analyseurs syntaxiques pour produire des structures de dependance
multi-niveaux, contenant plusieurs niveaux linguistiques : semantique, logique, syntaxique, etc. A
plus long terme, nous comptons apprendre de cette combinaison. Par exemple, il sera possible de
« compiler » les connaissances extraites de plusieurs analyseurs dans un seul analyseur de
dependance autonome.

Remerciements

Je tiens a remercier Xerox et Jacques Vergne pour m’avoir perrnis d’utiliser les analyseurs.

Francis Brunet-Manquat

Références

ABEILLE A. and L. CLEMENT (1999). A tagged reference corpus for French, LINC’99 Proceedings,
EACL workshop, Bergen.

AIT-MOKHTAR S. and CHANOD JP. (1997), Incremental finite-state parsing, in Applied Natural
Language Processing I 997, April 1997, Washington.

AIT-MOKHTAR S., CHANOD JP. and ROUX C. (2002), Robustness beyond Shallowness: Incremental
Deep Parsing, in Natural Language Engineering, 8 (2/3), pp 121-144, Cambridge University Press.

BOITET CH. and ZAHARIN Y. (1988), “Representation trees and string-tree correspondences”,
published in COLING-88, pp 59-64.

BRILL E. and WU J. (1998) Classiﬁer Combinaison for Improved Lexical Disambiguation. In Proc.
of the 17”‘ COLING, PP. 191-195.

BROTHWICK A., STERLING J ., AGICHTEIN E. and GRISHMAN R. (1998) Exploiting diverse knowledge
sources via maximum entropy in named entity recognition. Proceedings of the sixth workshop on
Very large corpora, pages 152-160, Montreal.

BRUNET-MANQUAT F. (2003), “Fusionner pour mieux analyser: quelques ide’es et une premie‘re
expe’rience”, Proceedings of RECITAL’03, Vol. 1/2, France, 10-14 juin 2003, pp. 429-438.

BRUNET-MANQUAT F. (2004), “Description et conception d ’une plate-forme robuste combinant des
analyseurs d ’e’nonce’”, journal on line ISDM, Vol. 13, février 2004, 12 pages.

F‘ISCUS J .G. (1997), “A post-processing system to yield reduced error word rates: Recognizer output
voting error reduction (ROVER )”, published in IEEE Workshop on Automatic Speech Recognizer
and Understanding, pp 347-354.

HALTEREN H., J . ZAVREL and W. DAELEMANS (1998). Improving data driven wordclass tagging by
system combination. In Proc. of the 17”‘ COLING.

HENDERSON, J. C. and BRIL E. (1999). Exploiting Diversity in Natural Language Processing:
Combining Parsers. In Proc. of the 1999 SIGDAT Conference on EMNLP and VLC, pp. 187-194.

ILLOUZ G. (1999), “Me’ta-e’tiqueteur adaptatif: vers une utilisation pragmatique des resources
linguistiques”, published in TALN’99.

INUI T. and INUI K. (2000), Committee-based Decision Making in Probabilistic Partiel Parsing, In
Proc. of COLING-2000.

MARQUEZ and PADRO (1998). On the evaluation and comparaison of taggers : the eﬁect of noise in
test corpora. Actes COLING/ACL’98, Montreal, Canada.

MONCEAUX L. and ISABELLE ROBBA I. (2002), “Les analyseurs syntaxiques : atouts pour une
analyse des questions dans un syste‘me de question-re’ponse ? ”, Actes de TALN’2003, pp.195-204.

PEDERSEN T. (2000), A Simple Approach to Building Ensembles of Naive Bayesian Classifiers for
Word Sense Disambigusation In Proc. of the NAACL, pp. 63-69, 2000.

SCHWENK H. and GAUVAIN J.L. (2000), “Combining multiple speech recognizers using voting and
language model information”, published in IEEE International Conference on Speech and Language
Processing (ICSLP), pp. II:915-918.

VERGNE J . and GIGUET E. (1998), Regards the’orique sur le « Tagging », Actes de TALN’1998,
pp 24-33.

