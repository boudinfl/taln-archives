<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Interpr&#233;tariat &#224; distance et collecte de dialogues spontan&#233;s bilingues, sur une plate-forme g&#233;n&#233;rique multifonctionnelle</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2004, F&#232;s, 19-21 avril 2004
</p>
<p>Interpr&#233;tariat &#224; distance et collecte de dialogues spontan&#233;s
bilingues, sur une plate-forme g&#233;n&#233;rique multifonctionnelle
</p>
<p>Georges Fafiotte
</p>
<p>GETA, CLIPS-IMAG (UJF - Universit&#233; Grenoble 1)
385, rue de la Biblioth&#232;que, BP 53,  F-38041 GRENOBLE Cedex 9 (France)
</p>
<p>georges.fafiotte@imag.fr
</p>
<p>R&#233;sum&#233; &#8212; Abstract
</p>
<p>Parall&#232;lement &#224; l&#8217;int&#233;gration du fran&#231;ais en TA de Parole multilingue (projets C-STAR,
NESPOLE!), nous avons d&#233;velopp&#233; plusieurs plates-formes, dans le cadre des projets ERIM
(Environnement R&#233;seau pour l&#8217;Interpr&#233;tariat Multimodal) et ChinFaDial (collecte de dialogues
parl&#233;s spontan&#233;s fran&#231;ais-chinois), pour traiter diff&#233;rents aspects de la communication orale
spontan&#233;e bilingue non finalis&#233;e sur le web : interpr&#233;tariat humain &#224; distance, collecte de
donn&#233;es, int&#233;gration d&#8217;aides automatiques (serveur de TA de Parole utilisant des composants du
march&#233;, interaction multimodale entre interlocuteurs, et prochainement aides en ligne aux
intervenants, locuteurs ou interpr&#232;tes). Les corpus collect&#233;s devraient &#234;tre disponibles sur un site
DistribDial au printemps 2004. Ces plates-formes sont en cours d&#8217;int&#233;gration, en un syst&#232;me
g&#233;n&#233;rique multifonctionnel unique ERIMM d&#8217;aide &#224; la communication multilingue multimodale,
dont une variante s&#8217;&#233;tendra &#233;galement &#224; la formation &#224; distance (e-training) &#224; l&#8217;interpr&#233;tariat.
</p>
<p>In parallel with integrating the French language into multilingual Speech Machine Translation
(within the C-STAR and NESPOLE! projects), we have developed in recent years several
platforms, in the framework of projects ERIM (Network-based Environment for Multimodal
Interpreting) and ChinFaDial (collecting French-Chinese spontaneously spoken dialogues),
allowing to handle various aspects of spontaneous, general-purpose bilingual spoken dialogues
on the web: distant human interpreting, data collection, integration of machine aids including
server-based speech translation based on commercial products, multimodal user interaction, and
next, online aids to speakers and/or interpreters. Collected data should be available on the web
(DistribDial) in spring 2004. All platforms are being integrated into one single multifunctional
ERIMM generic system, which should then be extended to distant e-training in interpreting.
</p>
<p>Mots-cl&#233;s  &#8212; Keywords
</p>
<p>Interpr&#233;tariat &#224; distance sur r&#233;seau, collecte de corpus oraux bilingues, dialogues spontan&#233;s,
communication multilingue, mutualisation de ressources.
Web-based interpreting, bilingual spoken corpora collection, spontaneous dialogues, multilingual
communication, resource mutualization.
</p>
<p>Introduction
</p>
<p>Les progr&#232;s de la TA de Parole (TAP) ont &#233;t&#233; sensibles dans la derni&#232;re d&#233;cennie,
particuli&#232;rement en spontan&#233;it&#233; du style et en multilinguisme. La premi&#232;re d&#233;monstration fut
effectu&#233;e par NEC (septembre 1992) dans le domaine du tourisme, mais les recherches les plus
connues sur ces th&#232;mes peuvent &#234;tre cr&#233;dit&#233;es &#224; des actions tr&#232;s coordonn&#233;es, entre autres les</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G. Fafiotte
</p>
<p>projets C-STAR (international Consortium for Speech Translation Advanced Research) [8, 10],
en Europe les projets NESPOLE! IST [13] et l'allemand Verbmobil [15] et aux USA le DARPA
Communicator project [11] avec le Galaxy Communicator Software Infrastructure [12]. Ces
projets ont produit des plates-formes de traitement de la parole spontan&#233;e en communication
multilingue personne-personne ou personne-syst&#232;me, toujours dans des domaines cibl&#233;s.
</p>
<p>Le manque notoire de grands corpus de dialogues parl&#233;s bilingues en acc&#232;s libre
(ressources essentielles au d&#233;veloppement de syst&#232;mes de TAP spontan&#233;e), d'une part, et d'autre
part l'importance de l'&#233;tude de l'impact de la multimodalit&#233; sur la communication multilingue (&#224;
l'heure o&#249; les &#233;quipements de t&#233;l&#233;communication mobile monolingue int&#232;grent ce type de
dispositif), nous ont motiv&#233;s pour &#233;tudier, mod&#233;liser, et prototyper un ensemble de ressources
g&#233;n&#233;riques et de plates-formes orient&#233;es vers les aides &#224; la communication orale multilingue et
multimodale sur le web, en contribution &#233;galement &#224; certaines attentes de l'ing&#233;nierie linguicielle.
</p>
<p>Cet article rappelle d'abord nos premiers travaux dans cette orientation, puis pr&#233;sente la
famille des plates-formes ERIM (Environnement R&#233;seau pour l&#8217;Interpr&#233;tariat Multimodal) en
pr&#233;cisant leurs motivations, leurs caract&#233;ristiques de conception, et leur &#233;tat actuel. Il rend compte
ensuite des premi&#232;res utilisations en collecte de dialogues parl&#233;s spontan&#233;s fran&#231;ais-chinois en
domaine finalis&#233; (projet ChinFaDial), et aborde les d&#233;veloppements en cours et &#224; venir, en vue
d'une int&#233;gration de ces composants sur une plate-forme unique.
</p>
<p>1 Aider la communication multilingue sur r&#233;seau
</p>
<p>1.1 Situation, enjeux
</p>
<p>Les motivations de cette recherche sont multiples : elles sont n&#233;es de l'observation des
conditions de l'int&#233;gration du fran&#231;ais aux projets de TAP C-STAR II puis NESPOLE!, et du
constat de l'absence de grands corpus de parole spontan&#233;e en dialogues bilingues interpr&#233;t&#233;s,
essentiels pour la production de mod&#232;les linguistiques des langues parl&#233;es, tr&#232;s diff&#233;rents de
ceux des dialogues monolingues et des textes &#233;crits. Il est, pour chaque langue, de multiples
variantes en langue parl&#233;e spontan&#233;e, tant y sont fr&#233;quents les variations de style, de traits
syntaxiques particuliers (anaphores, style indirect&#8230;), les ph&#233;nom&#232;nes d&#8217;&#233;locution (faux d&#233;parts,
interruptions et reprises, raccourcis&#8230;), les tournures idiomatiques ou usuelles orales.
L&#8217;incidence de ces traits de parole spontan&#233;e s&#8217;av&#232;re de plus diff&#233;rente en situation multilingue.
</p>
<p>Avec pour finalit&#233; une aide &#224; l'ing&#233;nierie linguicielle, nous souhaitions aussi faciliter une
exp&#233;rimentation fine de composants de TAP (de reconnaissance, traduction, synth&#232;se), et celle de
ressources multimodales dans un cadre de traduction de parole bilingue &#8212;donc, cr&#233;er une plate-
forme g&#233;n&#233;rique, ouverte &#224; l'int&#233;gration (plug-in) de composants, facilitant la capture de donn&#233;es.
</p>
<p>Nous voulons de plus proposer aux interpr&#232;tes humains des sc&#233;narios innovants et de
nouvelles modalit&#233;s d'intervention sur le web, permettant le travail &#224; distance, par exemple pour
l'insertion professionnelle des handicap&#233;s, et facilitant les interventions ponctuelles &#224; la demande.
</p>
<p>Enfin, nous mettrons &#224; disposition &#224; terme certains des logiciels d&#233;velopp&#233;s, en acc&#232;s libre
sur le web, pour favoriser un volontariat de production de ressources partageables au sein de la
communaut&#233; des chercheurs en TA de Parole.
</p>
<p>1.2 Un premier environnement : Sim*, simulateur de traduction avec
Magicien d&#8217;Oz, pour la collecte de dialogues spontan&#233;s
</p>
<p>Motivation. &#192; la suite de travaux sur des plates-formes multimodales &#224; magicien d&#8217;Oz
(architecture multimagiciens monolingues de NEIMO [4], ou, &#224; ATR-ITL Kyoto, EMMI [7, 5] &#224;
magicien unique bilingue, dans un contexte d&#8217;&#233;tude de la d&#233;sambiguisation interactive
multimodale), nous avons pens&#233; utile, pour faciliter la construction de syst&#232;mes de TAP,
d'acqu&#233;rir d'abord une exp&#233;rience et de rassembler des donn&#233;es, en prototypant Sim*
(prononcer Sim-star), environnement de simulation de TAP con&#231;u parall&#232;lement &#224; C-STAR II.
</p>
<p>Conception. L'architecture de Sim* est celle d'un environnement multiposte avec</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Interpr&#233;tariat &#224; distance et collecte de dialogues spontan&#233;s bilingues
</p>
<p>interpr&#232;te magicien d&#8217;Oz [6], ce dernier entendant et voyant les locuteurs gr&#226;ce &#224; leur webcam, et
n&#8217;&#233;tant ni vu, ni entendu (du moins comme un humain) par eux. Sur Sim*, les locuteurs peuvent
s&#8217;entendre et se voir, et disposent de ressources multimodales de base : &#233;change de textes courts,
&quot;tableau blanc&quot; pour le partage de documents visuels et d&#8217;annotations graphiques libres. Nous
visions une observation de comportements d&#8217;utilisateurs plac&#233;s en situation future de TA
multimodale, en m&#234;me temps que la collecte de donn&#233;es (parole et textes courts dans un premier
temps) permettant la mod&#233;lisation de la langue spontan&#233;e parl&#233;e (par exemple pour C-STAR II).
</p>
<p>Pour ce premier syst&#232;me, la conversation sur r&#233;seau est g&#233;r&#233;e par un serveur de
communication de type client-serveur programm&#233; en Tcl/Tk, et l&#8217;interaction multimodale utilise
des applications MBone. Impl&#233;ment&#233; sur stations Unix, Sim* a &#233;t&#233; utilis&#233; sur l'intranet du
laboratoire, bien qu'&#233;crit pour tourner sur Internet. Les tests ont &#233;t&#233; effectu&#233;s en anglais-fran&#231;ais.
</p>
<p>Situation actuelle. La r&#233;alisation d&#8217;un &quot;magicien d&#8217;Oz Interpr&#232;te&quot; cr&#233;dible, non
reconnu comme humain par les locuteurs, donc utile pour l&#8217;observation de ces derniers, s&#8217;est
av&#233;r&#233;e difficile m&#234;me en utilisant des vocodeurs pour d&#233;former la voix de l&#8217;interpr&#232;te. Nous
l&#8217;avons donc &#233;cart&#233;e, et avons choisi, pour les situations de collecte comme d'exp&#233;rimentation
multimodale, que l&#8217;interpr&#232;te soit per&#231;u comme tel &#8212;un &quot;warm body&quot;, ou &quot;ange gardien&quot;. Ceci
nous permet d'explorer directement des situations r&#233;alistes d'usage de syst&#232;mes de TAP futurs,
tels que nous les concevons : m&#233;diatis&#233;s et synergiques, c&#8217;est &#224; dire int&#233;grant des ressources de
traduction &quot;par la machine&quot; (cf. 2.3) et &quot;aid&#233;e par l&#8217;utilisateur&quot; (cf. 2.1), ce dernier disposant
d&#8217;aides en ligne (cf. 2.4). Mais la collecte de corpus spontan&#233;s restait l&#8217;enjeu premier.
</p>
<p>Cette conception a &#233;t&#233; d&#233;velopp&#233;e lors du prototypage par &#233;tapes d&#8217;une famille de
composants cibl&#233;s, qui constituent le syst&#232;me ERIM, et sont pr&#233;sent&#233;s dans la section suivante.
</p>
<p>2 Les composants d'ERIM, pour l&#8217;aide &#224; la communication orale
multilingue
</p>
<p>La famille des plates-formes ERIM comprend, actuellement : ERIM-Interpr&#232;te pour
l'interpr&#233;tariat multimodal &#224; distance (et base des autres composants), ERIM-Collecte pour la
collecte de corpus de dialogues parl&#233;s spontan&#233;s bilingues traduits, ERIM-TA (vers un service
de Traduction partiellement Automatique de Parole aid&#233;e par le locuteur, et banc d&#8217;essai de
composants de TAP) et ERIM-Aides (vers des aides en ligne &#224; la communication multilingue sur
r&#233;seau). Elle int&#233;grera ERIM-Formation pour l'e-training &#224; distance en interpr&#233;tariat bilingue.
</p>
<p>2.1 ERIM-Interpr&#232;te, pour l&#8217;interpr&#233;tariat multimodal &#224; distance
</p>
<p>Motivation. Il existe, sur le march&#233;, des environnements &quot;propri&#233;taires&quot; fonctionnant
sur r&#233;seau, de type cabine d&#8217;interpr&#232;te, analogues aux environnements de traduction fixes
destin&#233;s aux grandes conf&#233;rences multilingues (ONU, Communaut&#233; Europ&#233;enne). Mais leur
code n&#8217;est pas accessible, pour des d&#233;veloppements orient&#233;s vers la recherche.
</p>
<p>De plus, nous envisageons 2 sc&#233;narios, diff&#233;rents de ceux de l&#8217;interpr&#233;tariat classique :
&#8226; t&#233;l&#233;conf&#233;rence (&quot;conference call&quot;) : les interlocuteurs prennent un rendez-vous avec un
</p>
<p>interpr&#232;te pour un cr&#233;neau de dur&#233;e donn&#233;e,
&#8226; &quot;interpr&#233;tariat intermittent &#224; la demande&quot; : les locuteurs essaient de converser en utilisant
</p>
<p>la connaissance qu&#8217;ils ont de la langue de leur interlocuteur, ou dans une langue
v&#233;hiculaire, ou connue des deux. Lorsque cette communication s&#8217;av&#232;re impraticable, ou
pour des s&#233;quences &quot;sensibles&quot; de leur &#233;change, ils font appel momentan&#233;ment aux
services d'un interpr&#232;te disponible sur le web, qui peut les aider.
</p>
<p>Parall&#232;lement &#224; la mod&#233;lisation et au prototypage de ressources orient&#233;es vers des
services d'interpr&#233;tariat &#224; distance, une autre motivation pour ces plates-formes est l&#8217;&#233;tude
exp&#233;rimentale de l&#8217;incidence de diverses combinaisons de ressources multimodales, sur les
dialogues bilingues ou multilingues. Cette approche exp&#233;rimentale requiert des fonctionnalit&#233;s
de capture et d&#8217;enregistrement de donn&#233;es, &#224; l'origine aussi d'ERIM-Collecte.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G. Fafiotte
</p>
<p>Conception. La plate-forme ERIM-Interpr&#232;te est le socle de l&#8217;environnement ERIM, et g&#232;re la
communication entre interlocuteurs. L&#8217;architecture g&#233;n&#233;rique, commune avec celle d&#8217;ERIM-
Collecte, est pr&#233;sent&#233;e sur la figure 2 : elle comprend un serveur de communication, deux
stations locuteurs, une station interpr&#232;te. Un serveur de multimodalit&#233; la compl&#232;te pour la
communication vid&#233;o et par tableau blanc partag&#233;. Les locuteurs s&#8217;adressent le plus souvent &#224;
l&#8217;interpr&#232;te, mais peuvent se parler directement s'ils le souhaitent. En multimodalit&#233;, sont
possibles l'&#233;change de textes courts, le partage sur un tableau blanc de documents textuels et
graphiques avec pointages, marquages et soulignements libres, et la vision du correspondant.
</p>
<p>Situation actuelle. L&#8217;impl&#233;mentation en Tcl/Tk est multiplate-forme (ind&#233;pendante
des syst&#232;mes d&#8217;accueil, Windows, MacOS, ult&#233;rieurement Linux) et g&#233;n&#233;rique. Elle permet des
configurations &#233;volutives : le serveur de communication sur station s&#233;par&#233;e (ou non), 2 stations
locuteurs (ou plus) distantes, 1 station interpr&#232;te distante (ou plusieurs) ; 2 processus interpr&#232;tes
sont possibles sur une m&#234;me station, par exemple en situation de bilinguisme avec traductions
&quot;sym&#233;triques&quot; ; 2 processus locuteurs &#233;galement, en situation de &quot;visite&quot; d'un locuteur &#224; l'autre.
Nous adoptons un sch&#233;ma de type &quot;pousser/parler&quot; (push to talk) pour discipliner les &#233;changes.
</p>
<p>Les premiers tests ont &#233;t&#233; faits &#224; moyenne distance (Grenoble-Valence) :
</p>
<p>Exemple d'exp&#233;rimentation
(110 km,     &#224; 100 Mbits),
avec  cotation  de  0  &#224;  5
</p>
<p>Texte
court
</p>
<p>Voix  RtS :
Record-then-Send
</p>
<p>Voix  S&amp;R :
Send &amp; Record
</p>
<p>(streaming)
</p>
<p>Voix S&amp;R   +
recouvrement de
tours de parole
</p>
<p>Streaming non non oui oui
</p>
<p>Qualit&#233; de r&#233;ception 5 5 3 1
</p>
<p>Rythme des &#233;changes 5 2 4 5
</p>
<p>Fiabilit&#233; de transmission 5 5 4 1
</p>
<p>Ph&#233;nom&#232;nes particuliers utilisateur h&#233;sitant,
dialogue perturb&#233;
</p>
<p>(trop lent)
</p>
<p>quelques micro-
coupures, bonne
qualit&#233; g&#233;n&#233;rale
</p>
<p>inutilisable (alors
qu'acceptable sur
</p>
<p>un intranet)
</p>
<p>Fig. 1 :  Communication orale sur le web
</p>
<p>La mise au point initiale a &#233;t&#233; faite sur l&#8217;intranet du laboratoire. Sur Internet l&#8217;&#233;change de
messages textuels courts est g&#233;r&#233; classiquement, mais pour la transmission de la voix deux
modes peuvent &#234;tre choisis (cf. Fig. 1) : soit &quot;enregistrer-puis-envoyer&quot; (Record-then-Send,
enregistrement local puis transmission du fichier enregistr&#233;), tr&#232;s fiable mais qui cr&#233;e des temps
d'attente parfois contraignants, soit &quot;envoyer-et-enregistrer&quot; (Send &amp; Record, avec transmission
en flux &#8212;streaming), qui assure un rythme d'&#233;changes satisfaisant et dont la qualit&#233; est bonne
(malgr&#233; quelques microcoupures) pour autant que les locuteurs se parlent sans recouvrement
(deux locuteurs ne s'adressant pas en m&#234;me temps &#224; l'interpr&#232;te, par exemple).
</p>
<p>Des validations &#224; longue distance sont pr&#233;vues, avec &#233;tude des performances en fonction
des liaisons utilis&#233;es.
</p>
<p>2.2 ERIM-Collecte, pour la collecte sur r&#233;seau de dialogues spontan&#233;s
bilingues traduits
</p>
<p>Motivation. L'importance de grands corpus r&#233;alistes est essentielle pour la
construction de syst&#232;mes de TA de Parole. Ces syst&#232;mes requi&#232;rent des corpus acoustiques
maintenant largement produits &#224; partir de communications sur le web. Il est besoin &#233;galement,
pour &#233;tablir des mod&#232;les de langues parl&#233;es en situations r&#233;elles, de corpus parall&#232;les d'&#233;nonc&#233;s
transcrits align&#233;s. Peu de ressources de ce type sont produites, ou librement disponibles.
</p>
<p>De m&#234;me, de grands corpus de dialogues spontan&#233;s bilingues sont n&#233;cessaires pour
d&#233;velopper et valider les syst&#232;mes de TAP, mais il en existe tr&#232;s peu (NEC, ATR, ELRA et</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Interpr&#233;tariat &#224; distance et collecte de dialogues spontan&#233;s bilingues
</p>
<p>quelques autres), et aucun n'est en acc&#232;s libre. Pourquoi sont-ils &quot;propri&#233;taires&quot; ? Parce qu'ils
sont co&#251;teux &#224; collecter, et encore plus &#224; transcrire et annoter : les rendre disponibles
gratuitement semble d&#233;raisonnable si on les a beaucoup travaill&#233;s.
</p>
<p>Face &#224; cette situation, nous avons d&#233;velopp&#233; ERIM-Collecte (cf. Fig 2), pour
&#8226; collecter des donn&#233;es &quot;brutes&quot; (que d&#8217;autres &#233;quipes traiteront ensuite), les plus
</p>
<p>multimodales qu'il est possible, et &#224; partir de dialogues r&#233;els,
&#8226; proposer &#224; des volontaires de produire gratuitement ces donn&#233;es &#8230;en l'&#233;change d'un
</p>
<p>acc&#232;s libre aux plates-formes ERIM n&#233;cessaires et aux services qu'elles proposent.
</p>
<p>Conception. ERIM-Collecte est une extension d'ERIM-Interpr&#232;te, avec enregistrement
syst&#233;matique des actes et donn&#233;es de l'interaction pour tous les participants (deux locuteurs ou
plus, un interpr&#232;te ou plus). L'enregistrement est fait localement lors de la conversation, sur
fichiers son au format PCM 16kHz-16bit mono. En fin de dialogue, les descripteurs et fichiers
produits localement sont transmis &#224; un serveur de collecte, o&#249; ils sont regroup&#233;s et structur&#233;s.
</p>
<p>Fig. 2 :  ERIM-Collecte, en configuration l locuteurs et i interpr&#232;tes (ici l=2, i=1)
</p>
<p>Dans la situation que pr&#233;sente le sch&#233;ma, (1) l&#8217;interlocuteur fran&#231;ais parle (tour de parole
en un ou plusieurs &#233;nonc&#233;s), avec enregistrement local (1a), et transmission au &quot;CommSwitch&quot;
qui les diffuse vers un salon virtuel &#233;tabli pour le dialogue (1b). L&#8217;interpr&#232;te &#233;coute ce tour de
parole, le traduit en chinois (2). La traduction est enregistr&#233;e localement (2a), en m&#234;me temps que
diffus&#233;e (2b). L&#8217;interlocuteur chinois &#233;coute la traduction (3), puis r&#233;pond (4). De nouveau, son
tour de parole est enregistr&#233; localement (4a) et diffus&#233; (4b). En (5), l&#8217;interpr&#232;te le traduit en
fran&#231;ais, la traduction &#233;tant enregistr&#233;e localement (5a), et transmise(5b) au destinataire (6).
</p>
<p>Situation actuelle. Sur la version actuelle ERIM/3-Collecte, sont enregistr&#233;s les tours
de parole et textes courts (bimodalit&#233;). La capture des &#233;v&#232;nements du tableau blanc, et des objets
impliqu&#233;s (fichiers visuels partag&#233;s, trac&#233;s libres, url&#8230;) est en cours d'int&#233;gration, comme celle
de la vid&#233;o, si elle est souhait&#233;e (par exemple pour des &#233;tudes ult&#233;rieures d'expressions faciales).
</p>
<p>ERIM-Collecte est &#233;galement r&#233;alis&#233;e en Tcl/Tlk, qui favorise l'utilisation multiplate-
forme (PC, Macintosh, stations Unix/Linux) sur les stations de travail usuelles des utilisateurs.
La figure 3 pr&#233;sente l'interface actuelle de la plate-forme, pour un locuteur.
</p>
<p>Une ressource de r&#233;&#233;coute (le module Replay) permet de reconstituer tout ou partie du
dialogue, chronologiquement ou avec extraction de versions monolingues. Elle facilite un suivi
visuel de l'&#233;change (cf. Fig. 4). Elle fonctionne maintenant en version bimodale (tours de parole,
&#233;change de textes courts &#8211; extension en cours au tableau blanc), et sera accessible sur le site web
DistribDial d'acc&#232;s aux corpus produits, pour des utilisateurs de la communaut&#233; scientifique.
</p>
<p>Par contre, ERIM-Collecte, destin&#233;e par choix initial &#224; la constitution de corpus de
donn&#233;es brutes (fichiers descripteurs de session et tours de parole) ne propose pas de ressource
particuli&#232;re d'aide int&#233;gr&#233;e &#224; la transcription, ni &#224; l'annotation. Elles sont r&#233;alisables hors ERIM.
</p>
<p>L'architecture ouverte de la plate-forme g&#233;n&#233;rique facilitera d'&#233;ventuels d&#233;veloppements
futurs. Nous pr&#233;voyons d&#8217;utiliser par exemple les reconnaissances vocales int&#233;gr&#233;es d&#8217;ERIM-
TA (cf. 2.3) pour produire des premi&#232;res versions instantan&#233;es de transcriptions.
</p>
<p>5b
</p>
<p>5a
</p>
<p>a2
</p>
<p>3
</p>
<p>1a
</p>
<p> Locuteur 1 
</p>
<p>Tableau Blanc
</p>
<p>tour
chinois
traduit
</p>
<p>1b
</p>
<p>tour de parole
fran&#231;ais  Traduction 
</p>
<p>4b
</p>
<p>6
</p>
<p>tour de parole
chinois
</p>
<p>Traduction
</p>
<p>2b
</p>
<p>Serveur de
</p>
<p>Communication
</p>
<p>Interpr&#232;te
+
</p>
<p>Locuteur 2
</p>
<p>4a
</p>
<p>Tableau Blanc
</p>
<p>tour
fran&#231;ais
traduit</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2004, F&#232;s, 19-21 avril 2004
</p>
<p>Fig. 3 : &#201;cran Locuteur   Fig. 4 : R&#233;&#233;coute des &#233;nonc&#233;s Locuteurs, et Interpr&#232;te (au centre)
</p>
<p>Les versions successives d'ERIM-Collecte ont &#233;t&#233; utilis&#233;es pour les enregistrements, &#224;
Grenoble et &#224; P&#233;kin, d'un premier corpus de dialogues spontan&#233;s traduits (r&#233;servation h&#244;teli&#232;re).
</p>
<p>2.3 ERIM-TA, vers un service de Traduction partiellement Automatique
de Parole (TpAP), aid&#233;e par le locuteur
</p>
<p>Motivation. Pour cette variante l&#8217;objectif &#233;tait l'int&#233;gration g&#233;n&#233;rique, par plug-in, de
s&#233;ries de composants de TAP (Reconnaissance, Traduction, Synth&#232;se), pour leur mise au point
en &#233;valuation comparative, contrastive, avec la production &quot;humaine&quot; d'un Magicien d'Oz.
</p>
<p>S'y est joint, en partenariat avec la start-up Spoken Translation Inc. (STI, Berkeley), le
maquettage d'une plate-forme produit que STI souhaite d&#233;velopper. Enfin, nous souhaitions un
outil g&#233;n&#233;rique permettant d'exp&#233;rimenter des techniques de D&#233;sambigu&#239;sation Interactive
d&#233;riv&#233;es du projet LIDIA [1, 2] et de conduire des exp&#233;rimentations d'utilisabilit&#233; sur ce th&#232;me.
</p>
<p>L&#8217;enjeu global est pour nous une &quot;Traduction partiellement Automatique de qualit&#233;&quot;, de
parole (&quot;tchat&quot;) et de texte (SMS), sans recours &#224; un interpr&#232;te ou traducteur humain, mais en
introduisant un niveau ad&#233;quat de contr&#244;le par l&#8217;utilisateur (syst&#232;mes synergiques de TAP).
</p>
<p>De tels syst&#232;mes devront &#234;tre utilisables sur tous supports (PC, PDA, t&#233;l&#233;phones ou
futures microstations mobiles). Leurs Reconnaissance Vocale (RV), Traduction Automatique
(TA), Synth&#232;se Vocale (SV) et D&#233;sambigu&#239;sation Interactive (DI) doivent de plus, au moins pour
les &#233;quipements mobiles, tourner sur un serveur. L&#224; encore, une g&#233;n&#233;ricit&#233; des services int&#233;gr&#233;s
est essentielle. L&#8217;architecture ouverte et l&#8217;int&#233;gration diff&#233;rentielle par plug-in y contribueront.
</p>
<p>Conception. Pour que les couvertures lexicale et grammaticale soient assez larges, nous
avons choisi d'int&#233;grer des composants commerciaux (de reconnaissance de parole, de
traduction, et de synth&#232;se de parole) tous disponibles sur serveur. Ce sont, dans le premier
prototype, des produits disponibles respectivement chez Philips, Linguatec, et ScanSoft, (avec
SDKs, environnements ou kits de d&#233;veloppement). Le composant de TA doit pouvoir &#234;tre coupl&#233;
ult&#233;rieurement avec un module de DI.
</p>
<p>Pour la reconnaissance, nous souhaitions une RV de type &quot;dict&#233;e vocale&quot;, interactive.
IBM proposait un SDK pour son composant de RV, offrant une reconnaissance interactive pour
des domaines finalis&#233;s, et un syst&#232;me de dict&#233;e (&quot;transcription&quot;) non interactive &#224; large
couverture, mais pas de dict&#233;e vocale interactive. L'offre de Philips semble &#224; ce jour &#234;tre la seule
permettant une dict&#233;e vocale interactive sur serveur, mais l&#8217;&#233;volution du domaine est rapide.
</p>
<p>Situation actuelle. L'&#233;tude d'un banc d'essai monostation &#8212;le &quot;rack&quot; d'int&#233;gration&#8212;
a &#233;t&#233; conduite, avec plug-in des composants externes. Ce prototype a &#233;t&#233; r&#233;alis&#233; en Tcl/Tk (pour
ses facilit&#233;s d'int&#233;gration de ressources externes et d'interop&#233;rabilit&#233;), puis test&#233;. L'int&#233;gration
finale &#224; un dispositif multistation, de type ERIM-Interpr&#232;te, est en cours.
</p>
<p>Actuellement, le locuteur &#233;met un &#233;nonc&#233; de parole en langue source, et l'&#233;nonc&#233; textuel
&quot;reconnu&quot; lui est soumis pour validation ; si n&#233;cessaire, il peut r&#233;entrer son &#233;nonc&#233; vocalement</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Interpr&#233;tariat &#224; distance et collecte de dialogues spontan&#233;s bilingues
</p>
<p>(ou s'il pr&#233;f&#232;re, modifier au clavier l'&#233;nonc&#233; textuel propos&#233;). Apr&#232;s validation, le composant de
traduction produit un texte en langue cible, synth&#233;tis&#233; par le composant de synth&#232;se vocale.
</p>
<p>Dans certains cas (locuteur &#233;metteur partiellement bilingue) cette traduction &#233;crite peut lui
&#234;tre renvoy&#233;e ; une r&#233;trotraduction peut aussi lui &#234;tre soumise, pour validation ; elle pourra jouer
un r&#244;le d'indicateur, certes assez imparfait, d'une non-pertinence de la traduction. En cas de r&#233;elle
difficult&#233;, le locuteur peut reformuler oralement (voire au clavier) son &#233;nonc&#233; en langue-source,
pour contourner une possible inaptitude de la TA. Une validation provoquera la synth&#232;se vocale.
</p>
<p>Il est pr&#233;vu qu'ERIM-TA effectue l'enregistrement de toutes les productions (de
reconnaissance, de traduction et r&#233;trotraduction, et de synth&#232;se), et de toute reformulation. Les
descripteurs correspondants et la base de fichiers d'une session sont en cours d'impl&#233;mentation.
</p>
<p>Une mod&#233;lisation de la d&#233;sambigu&#239;sation interactive, fond&#233;e sur les techniques LIDIA [1,
2], est pr&#233;vue en partenariat avec Spoken T. Inc. ; elle sera prototyp&#233;e, puis int&#233;gr&#233;e et
exp&#233;riment&#233;e sur la plate-forme ERIM-TA. Nous pr&#233;voyons d'effectuer une pr&#233;-exp&#233;rimentation
sur les modalit&#233;s de ces interactions et leur pertinence, dans diff&#233;rentes situations d'utilisation, en
collaboration avec MultiCom (qui est une composante du CLIPS, &#233;quipe-ressource d'&#233;tude de
l'utilisabilit&#233; et de l'ergonomie des logiciels), avec observation des comportements d&#8217;utilisateurs .
</p>
<p>Le paradigme d'une TA de Parole &quot;aid&#233;e par l'utilisateur&quot; semble a priori se pr&#234;ter &#224; des
utilisations de &quot;tchat&quot; oral multilingue de qualit&#233;, qui int&#233;resse d&#8217;abord notre partenaire, et plus
globalement de communication multilingue avec traduction de qualit&#233;, notre objectif final.
</p>
<p>2.4 ERIM-Aides, vers des aides en ligne &#224; la communication multilingue
sur r&#233;seau
</p>
<p>Motivation. Dans notre sc&#233;nario d'interpr&#233;tariat intermittent &quot;&#224; la demande&quot;, il est
propos&#233; aux interpr&#232;tes de passer d'une conversation &#224; une autre et d'un sujet &#224; un autre (&#224; la
mani&#232;re des interpr&#232;tes &quot;de cocktail&quot;). C'est une activit&#233; difficile, et il peut en r&#233;sulter un &quot;stress
lexical&quot;. Des aides automatiques en ligne, br&#232;ves &#8212;par exemple pour une &quot;mini-immersion
lexicale&quot; avant intervention, selon la sp&#233;cificit&#233; du domaine concern&#233;&#8212;, seraient bienvenues.
</p>
<p>On devrait &#233;galement disposer d'aides automatiques pour les locuteurs (par exemple
&quot;faiblement&quot; ou partiellement bilingues, ce qui concr&#232;tement est parfois le cas), pour les aider &#224;
&quot;se d&#233;brouiller sans interpr&#232;te&quot;, en cas de n&#233;cessit&#233;.
</p>
<p>Conception. Les &quot;aides &#224; la communication&quot; comprennent, entre autres, des ressources
&#8226; pour se voir en se parlant (locuteurs, interpr&#232;te),
&#8226; pour partager des donn&#233;es, &#233;ventuellement modifiables, pointables, marquables (tableau
</p>
<p>blanc, visuels partag&#233;s&#8230;), consultables a posteriori&#8230;
&#8226; pour planifier et g&#233;rer des rendez-vous sur un agenda (accessible sur un site serveur).
</p>
<p>Des &quot;aides linguistiques&quot; peuvent inclure :
&#8226; l'acc&#232;s &#224; des fiches terminologiques th&#233;matiques bilingues, &#224; des dictionnaires
</p>
<p>&#233;lectroniques &#224; saisie au clavier ou &#224; entr&#233;e vocale, par exemple par d&#233;tection de mots
automatique (word-spotting) suivi d'un filtrage, d'une recherche en dictionnaire, et
pr&#233;sentation de synth&#232;se sur fen&#234;tre unique,
</p>
<p>&#8226; en l'absence d'interpr&#232;te, une reconnaissance de parole att&#233;nuant les difficult&#233;s de
compr&#233;hension orale et produisant une trace ou un historique de la conversation, que
peut &#233;galement consulter l'interpr&#232;te avant intervention,
</p>
<p>&#8226; de la TA de Parole partiellement (ou compl&#232;tement) automatique.
</p>
<p>Situation actuelle. Les aides de communication sont prototyp&#233;es. L'agenda est global
sur un site d'acc&#232;s ERIM, chaque utilisateur y acc&#233;dant via une vue personnalis&#233;e.
</p>
<p>Les premi&#232;res aides linguistiques vont &#234;tre introduites, en interfa&#231;ant des ressources
dictionnairiques existantes, en acc&#232;s libre sur le site Papillon [14]. Une ressource de
reconnaissance vocale (Philips) a d&#233;j&#224; &#233;t&#233; interfac&#233;e avec ERIM-TA, et sera int&#233;gr&#233;e.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G. Fafiotte
</p>
<p>2.5 ERIM-Formation, pour l&#8217;e-training &#224; distance en interpr&#233;tariat
bilingue
</p>
<p>En projet actuellement (m&#234;me si l'architecture g&#233;n&#233;rique des plates-formes actuelles
permet de simuler d&#233;j&#224; son fonctionnement), cette variante permettra de proposer, &#224; des &#233;tudiants
en interpr&#233;tariat bilingue, diff&#233;rents modes de formation &#224; distance (FAD) sur le web de type
e&#8211;training, pour une activit&#233; &quot;live&quot; (en direct), ou &quot;de doublage&quot;.
</p>
<p>Nous pr&#233;voyons un dispositif de type &quot;laboratoire de langues sur le web, pour
interpr&#232;tes&quot;, avec par exemple un interpr&#232;te professionnel (et/ou professeur) assurant la
continuit&#233; et la fluidit&#233; du dialogue bilingue entre deux locuteurs monolingues sur le r&#233;seau, et
un cercle d'interpr&#232;tes &quot;juniors&quot; qui peuvent (sans entendre les traductions du professionnel)
s'exercer &#224; distance, ou &#233;ventuellement intervenir chacun &#224; son tour sur proposition d'un
m&#233;diateur de traduction. Toute intervention &#233;tant enregistr&#233;e (avec l'accord des intervenants) et
consultable, un travail p&#233;dagogique int&#233;ressant peut s'ensuivre.
</p>
<p>Cette ressource rejoint de fait l'approche collaborative que privil&#233;gie le projet ERIM, car il
est probable que des &#233;tudiants avanc&#233;s en interpr&#233;tariat ou des interpr&#232;tes en perfectionnement
seront volontaires pour coop&#233;rer &#224; l&#8217;activit&#233; collaborative sur ce type d'outil &quot;d'apprentissage &#224;
distance par la pratique&quot;, contribuant &#224; la cr&#233;ation de corpus de dialogues spontan&#233;s (cf. 3.2).
</p>
<p>Il est possible &#233;galement d'envisager des situations d'utilisation plus institutionnelles, o&#249;
des &#233;tudiants &quot;seniors&quot; en interpr&#233;tariat accepteraient d'assurer des traductions bilingues dans le
cadre d'un service multilingue d'interpr&#233;tariat &quot;grand public&quot;, b&#233;n&#233;volement ou en &#233;change d'une
validation acad&#233;mique de cette activit&#233; (par exemple lors de Jeux Olympiques, Beijing 2008).
</p>
<p>3 Application &#224; la collecte de corpus de dialogues oraux bilingues
</p>
<p>3.1 ChinFaDial, un premier corpus de dialogues spontan&#233;s traduits
</p>
<p>ERIM-Collecte a &#233;t&#233; utilis&#233; dans le cadre du projet LIAMA &quot;ChinFaDial&quot;, en partenariat
avec le NLPR (Institut d'Automatique de l'Acad&#233;mie des Sciences de Chine, &#224; P&#233;kin), pour la
collecte de dialogues parl&#233;s bilingues fran&#231;ais-chinois spontan&#233;s et traduits, entre deux locuteurs
monolingues (cf. Fig. 5). La transcription ult&#233;rieure est ici manuelle.
</p>
<p>Fig. 5 :  Dialogue fran&#231;ais-chinois (extrait), entre h&#244;telier fran&#231;ais et client chinois
</p>
<p>Ces collectes utilisent pour le moment, localement, les intranets des laboratoires
partenaires, avec trois participants dans le m&#234;me b&#226;timent (ou dans deux b&#226;timents proches). La
collecte &#224; longue distance est en cours de validation.
</p>
<p>Les situations sont r&#233;elles (r&#233;servation h&#244;teli&#232;re), en dialogue spontan&#233;. Une douzaine
d'heures de dialogues oraux ont &#233;t&#233; enregistr&#233;es lors de quelques sessions &#224; Grenoble et &#224; P&#233;kin,
et constituent un premier corpus de donn&#233;es brutes, non transcrites. Les collectes se poursuivent.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Interpr&#233;tariat &#224; distance et collecte de dialogues spontan&#233;s bilingues
</p>
<p>L'AUF (Agence Universitaire de la Francophonie) finance actuellement le projet VTH-
Fra.Dial, une action de collecte de dialogues parl&#233;s spontan&#233;s bilingues entre le fran&#231;ais d'une
part, et le vietnamien, le tamoul, et l'hindi, dans des r&#233;gions francophones des pays concern&#233;s.
</p>
<p>3.2 Un sch&#233;ma de cr&#233;ation collaborative de ressources pour la TAP
</p>
<p>Nous souhaitons contribuer &#224; promouvoir un sch&#233;ma de mutualisation de ressources
pour l'ing&#233;nierie de la TA de Parole : corpus parall&#232;les de dialogues parl&#233;s spontan&#233;s, &#224; collecter,
puis &#224; transcrire et annoter, en participation collaborative.
</p>
<p>Une &#233;tape premi&#232;re sera la mise en acc&#232;s libre au printemps 2004, sur site web, des
donn&#233;es d&#233;j&#224; collect&#233;es en fran&#231;ais-chinois, sous une forme &quot;rejouable&quot; avec le module Replay,
et, pour chaque conversation, un descripteur des param&#232;tres d&#8217;intervenants (anonymes) et de
session, la liste des tours de parole horodat&#233;s par locuteur, les pointeurs sur les fichiers son.
</p>
<p>Ce site et son environnement DistribDial devront faciliter l'enrichissement libre des
corpus par d'autres chercheurs, par ajout de transcriptions et/ou d'annotations en fichiers
parall&#232;les (selon un format homog&#232;ne) &#8212;&#224; rendre accessibles &#233;galement sur le web.
</p>
<p>Une contribution suivante sera de proposer la plate-forme ERIM-Collecte elle-m&#234;me, en
acc&#232;s libre (GPL) sur le web, apr&#232;s de nouveaux tests de robustesse, de performance &#224; distance,
et quelques d&#233;veloppements d'utilisabilit&#233;.
</p>
<p>4 D&#233;veloppements en cours, prospective
</p>
<p>L'environnement ERIM s'est construit par prototypage exploratoire puis d&#233;veloppement
incr&#233;mentiel de plusieurs classes de ressources compl&#233;mentaires, en coh&#233;rence fonctionnelle. La
recherche sur et avec ces plates-formes, apr&#232;s cadrage en tranches fonctionnelles, se poursuit par
</p>
<p>&#8226; de nouvelles collectes dans de nouvelles langues,
&#8226; l'enrichissement fonctionnel du serveur de multimodalit&#233; d'ERIM-Interpr&#232;te, puis le
</p>
<p>d&#233;veloppement de la capture de donn&#233;es multimodales par ERIM-Collecte, enregistrant
les &#233;v&#232;nements multimodaux et leur horodatage, avec un Replay Multimodal associ&#233;,
</p>
<p>&#8226; la consolidation de DistribDial, le site d&#8217;acc&#232;s aux corpus collect&#233;s,
&#8226; un site d&#8217;acc&#232;s &#224; la plate-forme ERIM-Collecte pour la collecte collaborative,
&#8226; quelques extensions fonctionnelles conduisant &#224; une plate-forme &quot;laboratoire&quot;, facilitant
</p>
<p>le plug-in de composants pour la TAP ou la &quot;TAP de qualit&#233; aid&#233;e par l'utilisateur&quot;, et
leur exp&#233;rimentation &#8212;que ces composants proviennent de r&#233;alisations acad&#233;miques, de
versions &#224; tester ou &#224; r&#233;gler (&quot;tuning&quot;), ou qu'ils soient des produits logiciels du march&#233; ;
plusieurs produits ou versions de modules de TA en cours de prototypage, d'une m&#234;me
classe fonctionnelle (RV, TA, SV, ou DI) pourront &#234;tre test&#233;s et compar&#233;s en parall&#232;le
avec enregistrement complet ; des &#233;tudes contrastives avec des productions humaines
d'interpr&#232;tes magiciens d'Oz, enregistr&#233;es en parall&#232;le, seront possibles,
</p>
<p>&#8226; le prototypage et l'&#233;valuation exp&#233;rimentale de solutions de d&#233;sambigu&#239;sation interactive,
pour ERIM-TA.
</p>
<p>Nous souhaitons, parall&#232;lement &#224; la diffusion d'une plate-forme &#224; usage cibl&#233; (pour la
collecte de donn&#233;es brutes, puis leurs enrichissements contributifs), entreprendre &#233;galement
l'unification et l'int&#233;gration des diff&#233;rents composants d'ERIM ici pr&#233;sent&#233;s en une plate-forme
unique ERIMM, Environnement R&#233;seau pour l'Interpr&#233;tariat Multimodal Multilingue, regroupant
un ensemble d&#8217;aides &#224; la communication multilingue et multimodale sur r&#233;seau.
</p>
<p>Conclusion
</p>
<p>Nous avons pr&#233;sent&#233; 3 plates-formes d&#233;j&#224; op&#233;rationnelles (l'une d&#8217;elle en finition),
permettant d'aider la communication bilingue sur le web, pour des dialogues spontan&#233;s non
finalis&#233;s : ERIM-Interpr&#232;te, pour l'interpr&#233;tariat humain sur r&#233;seau, ERIM-Collecte, qui r&#233;duit le</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G. Fafiotte
</p>
<p>manque de donn&#233;es utiles pour d&#233;velopper de meilleurs syst&#232;mes de TA de Parole, et ERIM-TA
ressource g&#233;n&#233;rique destin&#233;e &#224; la Traduction partiellement Automatique de Parole (TpAP), de
qualit&#233;, utilisant des produits logiciels de reconnaissance, traduction et synth&#232;se &#224; couverture
large et disponibles sur serveurs, avec contr&#244;le par l'utilisateur (feedback, validation directe,
d&#233;sambigu&#239;sation interactive). ERIM-TA assiste aussi l&#8217;ing&#233;nierie des syst&#232;mes de TAP, et
constitue un banc d&#8217;essai g&#233;n&#233;rique en situation r&#233;elle, ou de r&#233;glage, pour leurs composants.
</p>
<p>Une autre plate-forme ERIM-Aides proposant aux interpr&#232;tes et locuteurs des aides en
ligne (aides de communication, aides lexicales), est partiellement r&#233;alis&#233;e.
</p>
<p>Les dialogues spontan&#233;s bilingues d&#233;j&#224; collect&#233;s (fran&#231;ais-chinois) seront prochainement
disponibles en acc&#232;s libre sur le web, ainsi que les plates-formes Interpr&#232;te et de Collecte.
</p>
<p>Cette recherche se poursuit par la collecte et la distribution de donn&#233;es concernant
d'autres langues, par l'enrichissement fonctionnel des quatre premi&#232;res plates-formes, puis leur
unification en un environnement unique ERIMM, base d'exp&#233;rimentation et d'aide &#224; l'ing&#233;nierie
de syst&#232;mes de TpAP multilingue et multimodale, et enfin par le d&#233;veloppement d'un &quot;labo de
langue sur le web pour l'interpr&#233;tariat&quot;, ERIMM-Formation, qui pourrait &#233;galement contribuer
aux collectes.
</p>
<p>Remerciements
</p>
<p>Ces travaux ont &#233;t&#233; soutenus par le CLIPS-IMAG (Universit&#233; Joseph Fourier
Grenoble&#8211;1, INPG, CNRS), par la R&#233;gion Rh&#244;ne-Alpes (projet ERIM), et par le laboratoire
franco-chinois LIAMA (projet ChinFaDial). Zhai JianShe (Universit&#233; de Nankin) en r&#233;sidence
au CLIPS, puis Julien Lamboley (&#201;l&#232;ve-Ing&#233;nieur INSA Lyon) ont contribu&#233; au d&#233;veloppement
des plates-formes. L'auteur les remercie, ainsi que les membres du CLIPS, de MultiCom (&#224;
Grenoble) et du NLPR (CAS-IA, &#224; P&#233;kin) qui ont particip&#233; aux collectes et exp&#233;rimentations.
</p>
<p>R&#233;f&#233;rences
</p>
<p>[1] Blanchon H. (1994) Perspectives of DBMT for monolingual authors on the basis of
LIDIA-1, an implemented mockup. Proc. 15th International Conference on Computational
Linguistics, COLING-94, Y. Wilks ed., vol. 1/2, pp. 115&#8212;119.
[2] Boitet C., Blanchon H. (1994) Multilingual Dialogue-Based MT for Monolingual
Authors: the LIDIA Project and a First Mockup. Machine Translation 9/2 1994, pp. 99&#8212;132.
[3] Brown R. D., Nirenburg S. (1990) Human-Computer Interaction for Semantic
Disambiguation. Proc. COLING-90, ACL, H. Karlgren ed., vol. 3/3, pp. 42-47.
[4] Coutaz J., Salber D., Carraux E., Portolan N. (1996) NEIMO, a Multiwork station
Usability Lab for Observing and Analyzing Multimodal Interaction. Proc. CHI&#8217;96 companion.
[5] Fafiotte G., Boitet C. (1994) Report on first EMMI Experiments for the MIDDIM project
in the context of Interpreting Telecommunications. MIDDIM report TR-IT-0074 GETA-IMAG
&amp; ATR-ITL, Aug. 1994, 11 p.
[6] Fafiotte G., Zhai J.-S. (1999) A Network-based Simulator for Speech Translation. Proc.
NPLRS&#8217;99, Beijing, 5-7/11/99, B. Yuan, T. Huang &amp; X. Tang ed., pp. 511-514.
[7] Loken-Kim K.-H., Yato F., Morimoto T. (1994) A Simulation Environment for
Multimodal Interpreting Telecommunications. Proc. IPSJ-AV workshop, March 1994, 5 p.
[8] Morimoto T., Takezawa T., Yato F., Sagayama S., Tashiro T., Nagata M. &amp; al. (1993)
ATR's Speech Translation System: ASURA. Proc. EuroSpeech'93, Berlin, 21-23/9/83, 4 p.
[9] Nyberg E. H., Mitamura T. (1992) The KANT system: Fast, Accurate, High-Quality
Translation in Practical Domains. Proc. COLING-92, ACL, vol. 3/4, pp. 1069&#8212;1073.
[10] &lt;url&gt; site web C-STAR: http://www.c-star.org
[11] &lt;url&gt; site web DARPA: http://www.darpa.mil/ito/research/com/index.html
</p>
<p>http://fofoca.mitre.org/doc.html
[12] &lt;url&gt; GALAXY architecture site: http://www.sls.lcs.mit.edu/sls/whatwedo/architecture.html
[13] &lt;url&gt; site web NESPOLE! : http://nespole.itc.it
[14] &lt;url&gt; site web PAPILLON: http://www.papillon-dictionary.org
[15] &lt;url&gt; site web VERBMOBIL: http://verbmobil.dfki.de</p>

</div></div>
</body></html>