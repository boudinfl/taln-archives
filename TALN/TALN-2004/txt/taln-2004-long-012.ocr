TALN 2004, F és, 19-21 avril 2004

Interprétariat a distance et collecte de dialogues spontanés
bilingues, sur une plate-forme générique multifonctionnelle

Georges Fafiotte

GETA, CLIPS—IMAG (UJF — Université Grenoble 1)
385, rue de la Bibliotheque, BP 53, F-38041 GRENOBLE Cedex 9 (France)
georges.fafiotte@imag.fr

Résumé — Abstract

Parallelement a l’inte’gration du frangais en TA de Parole multilingue (projets C—STAR,
NESPOLE!), nous avons de’veloppe’ plusieurs plates—forrnes, dans le cadre des projets ERIM
(Environnement Réseau pour l’Interpre’tariat Multimodal) et ChinFaDial (collecte de dialogues
parlés spontane’s frangais—chinois), pour traiter différents aspects de la communication orale
spontane’e bilingue non finalise’e sur le web: interpre’tariat humain a distance, collecte de
données, intégration d’aides automatiques (serveur de TA de Parole utilisant des composants du
marche’, interaction multimodale entre interlocuteurs, et prochainement aides en ligne aux
intervenants, locuteurs ou interpretes). Les corpus collecte’s devraient étre disponibles sur un site
DistribDial au printemps 2004. Ces plates—forrnes sont en cours d’inte’gration, en un systeme
générique multifonctionnel unique ERIMM d’aide a la communication multilingue multimodale,
dont une Variante s’étendra également a la formation a distance (e—training) a l’interpre’tariat.

In parallel with integrating the French language into multilingual Speech Machine Translation
(within the C—STAR and NESPOLE! projects), we have developed in recent years several
platforms, in the framework of projects ERIM (Network—based Environment for Multimodal
Interpreting) and ChinFaDial (collecting French—Chinese spontaneously spoken dialogues),
allowing to handle various aspects of spontaneous, general—purpose bilingual spoken dialogues
on the web: distant human interpreting, data collection, integration of machine aids including
server—based speech translation based on commercial products, multimodal user interaction, and
next, online aids to speakers and/or interpreters. Collected data should be available on the web
(DistribDial) in spring 2004. All platforms are being integrated into one single multifunctional
ERIMM generic system, which should then be extended to distant e—training in interpreting.

Mots-clés — Keywords

Interpre’tariat a distance sur réseau, collecte de corpus oraux bilingues, dialogues spontane’s,
communication multilingue, mutualisation de ressources.

Web—based interpreting, bilingual spoken corpora collection, spontaneous dialogues, multilingual
communication, resource mutualization.

Introduction

Les progres de la TA de Parole (TAP) ont éte’ sensibles dans la derniere décennie,
particulierement en spontane’ite’ du style et en multilinguisme. La premiere de’monstration fut
effectuée par NEC (septembre 1992) dans le domaine du tourisme, mais les recherches les plus
connues sur ces themes peuvent étre créditées a des actions tres coordonne’es, entre autres les

G. F aﬁotte

projets C—STAR (international Consortium for Speech Translation Advanced Research) [8, 10],
en Europe les projets NESPOLE! IST [13] et l'allemand Verbmobil [15] et aux USA le DARPA
Communicator project [11] avec le Galaxy Communicator Software Infrastructure [12]. Ces
projets ont produit des plates—formes de traitement de la parole spontane’e en communication
multilingue personne—personne ou personne—systeme, toujours dans des domaines cible’s.

Le manque notoire de grands corpus de dialogues parlés bilingues en acces libre
(ressources essentielles au développement de systemes de TAP spontane’e), d'une part, et d'autre
part l'impo1tance de l'étude de l'impact de la multimodalite’ sur la communication multilingue (a
l'heure ou les équipements de télécommunication mobile monolingue integrent ce type de
dispositif), nous ont motivés pour étudier, modéliser, et prototyper un ensemble de ressources
géne’riques et de plates—formes oriente’es vers les aides a la communication orale multilingue et
multimodale sur le web, en contribution également a certaines attentes de l'ingénierie linguicielle.

Cet article rappelle d'abord nos premiers travaux dans cette orientation, puis pre’sente la
famille des plates—formes ERIM (Environnement Réseau pour l’Interpre’tariat Multimodal) en
précisant leurs motivations, leurs caracte’ristiques de conception, et leur état actuel. ll rend compte
ensuite des premieres utilisations en collecte de dialogues parlés spontane’s frangais—chinois en
domaine finalise’ (projet ChinFaDial), et aborde les de’veloppements en cours et a venir, en vue
d'une intégration de ces composants sur une plate—forrne unique.

1 Aider la communication multilingue sur réseau

1.1 Situation, enjeux

Les motivations de cette recherche sont multiples: elles sont nées de l'observation des
conditions de l'intégration du francais aux projets de TAP C—STAR II puis NESPOLE!, et du
constat de l'absence de grands corpus de parole spontane’e en dialogues bilingues interpre’te’s,
essentiels pour la production de modeles linguistiques des langues parlées, tres diffe’rents de
ceux des dialogues monolingues et des textes écrits. Il est, pour chaque langue, de multiples
variantes en langue parle’e spontanée, tant y sont frequents les variations de style, de traits
syntaxiques particuliers (anaphores, style indirect. ..), les phe’nomenes d’élocution (faux departs,
interruptions et reprises, raccourcis. ..), les tournures idiomatiques ou usuelles orales.
L’incidence de ces traits de parole spontane’e s’avere de plus différente en situation multilingue.

Avec pour finalite’ une aide a l'inge’nierie linguicielle, nous souhaitions aussi faciliter une
experimentation fine de composants de TAP (de reconnaissance, traduction, synthese), et celle de
ressources multimodales dans un cadre de traduction de parole bilingue —donc, cre’er une plate-
forrne générique, ouverte a l'intégration (plug—in) de composants, facilitant la capture de données.

Nous voulons de plus proposer aux interpretes humains des sce’narios innovants et de
nouvelles modalités d'intervention sur le web, perrnettant le travail a distance, par exemple pour
l'inse1tion professionnelle des handicape’s, et facilitant les interventions ponctuelles a la demande.

Enfin, nous mettrons a disposition a terme certains des logiciels développe’s, en acces libre
sur le web, pour favoriser un volontariat de production de ressources partageables au sein de la
communaute’ des chercheurs en TA de Parole.

1.2 Un premier environnement : Sim*, simulateur de traduction avec
Magicien d’Oz, pour la collecte de dialogues spontanés

Motivation. A la suite de travaux sur des plates—formes multimodales a magicien d’Oz
(architecture multimagiciens monolingues de NEIMO [4], ou, a ATR—ITL Kyoto, EMMI [7, 5] a
magicien unique bilingue, dans un contexte d’étude de la désambiguisation interactive
multimodale), nous avons pensé utile, pour faciliter la construction de systemes de TAP,
d'acque’rir d'abord une expe’rience et de rassembler des données, en prototypant Sim*
(prononcer Sim—star), environnement de simulation de TAP concu parallelement a C—STAR II.

Conception. L'architecture de Sim* est celle d'un environnement multiposte avec

Interprétariat [1 distance et collecte de dialogues spontanés bilingues

interprete magicien d’Oz [6], ce dernier entendant et voyant les locuteurs grace a leur webcam, et
n’etant ni vu, ni entendu (du moins comme un humain) par eux. Sur Sim*, les locuteurs peuvent
s’entendre et se voir, et disposent de ressources multimodales de base : echange de textes courts,
"tableau blanc" pour le partage de documents visuels et d’annotations graphiques libres. Nous
visions une observation de comportements d’utilisateurs places en situation future de TA
multimodale, en meme temps que la collecte de donnees (parole et textes courts dans un premier
temps) permettant la modelisation de la langue spontanee parlee (par exemple pour C—STAR II).
Pour ce premier systeme, la conversation sur reseau est geree par un serveur de
communication de type client—serveur programme en Tcl/Tk, et l’interaction multimodale utilise
des applications MBone. Implemente sur stations Unix, Sim* a ete utilise sur l'intranet du
laboratoire, bien qu'ecrit pour tourner sur Internet. Les tests ont ete effectues en anglais—frangais.

Situation actuelle. La realisation d’un "magicien d’Oz Interprete" credible, non
reconnu comme humain par les locuteurs, donc utile pour l’observation de ces derniers, s’est
averee difficile meme en utilisant des vocodeurs pour deformer la voix de l’interprete. Nous
l’avons donc ecartee, et avons choisi, pour les situations de collecte comme d'experimentation
multimodale, que l’interprete soit pergu comme tel —un "warm body", ou "ange gardien". Ceci
nous permet d'explorer directement des situations realistes d'usage de systemes de TAP futurs,
tels que nous les concevons : mediatises et synergiques, c’est a dire integrant des ressources de
traduction "par la machine" (cf. 2.3) et "aidee par l’utilisateur" (cf. 2.1), ce dernier disposant
d’aides en ligne (cf. 2.4). Mais la collecte de corpus spontanes restait l’enjeu premier.

Cette conception a ete developpee lors du prototypage par etapes d’une famille de
composants cibles, qui constituent le systeme ERIM, et sont presentes dans la section suivante.

2 Les composants d'ERIM, pour l’aide a la communication orale
multilingue

La famille des plates—formes ERIM comprend, actuellement: ERIM—Interprete pour
l'interpretariat multimodal a distance (et base des autres composants), ERIM—Collecte pour la
collecte de corpus de dialogues parles spontanes bilingues traduits, ERIM—TA (vers un service
de Traduction partiellement Automatique de Parole aidee par le locuteur, et banc d’essai de
composants de TAP) et ERIM—Aides (vers des aides en ligne a la communication multilingue sur
reseau). Elle integrera ERIM—Formation pour l'e—training a distance en interpretariat bilingue.

2.1 ERIM-Interpréte, pour l’interprétariat multimodal in distance

Motivation. Il existe, sur le marche, des environnements "proprietaires" fonctionnant
sur reseau, de type cabine d’interprete, analogues aux environnements de traduction fixes
destines aux grandes conferences multilingues (ONU, Communaute Europeenne). Mais leur
code n’est pas accessible, pour des developpements orientes vers la recherche.

De plus, nous envisageons 2 scenarios, differents de ceux de l’interpretariat classique :

° teleconference ("conference call"): les interlocuteurs prennent un rendez—vous avec un
interprete pour un creneau de duree donnee,

° "interpretariat intermittent a la demande" : les locuteurs essaient de converser en utilisant
la connaissance qu’ils ont de la langue de leur interlocuteur, ou dans une langue
vehiculaire, ou connue des deux. Lorsque cette communication s’avere impraticable, ou
pour des sequences "sensibles" de leur echange, ils font appel momentanement aux
services d'un interprete disponible sur le web, qui peut les aider.

Parallelement a la modelisation et au prototypage de ressources orientees vers des
services d'interpretariat a distance, une autre motivation pour ces plates—formes est l’etude
experimentale de l’incidence de diverses combinaisons de ressources multimodales, sur les
dialogues bilingues ou multilingues. Cette approche experimentale requiert des fonctionnalites
de capture et d’enregistrement de donnees, a l'origine aussi d'ERIM—Collecte.

G. F aﬁotte

Conception. La plate—forrne ERIM—Interprete est le socle de l’enVironnement ERIM, et gere la
communication entre interlocuteurs. L’architecture générique, commune avec celle d’ERIM—
Collecte, est présentée sur la figure 2: elle comprend un serveur de communication, deux
stations locuteurs, une station interprete. Un serveur de multimodalite’ la complete pour la
communication Video et par tableau blanc partagé. Les locuteurs s’adressent le plus souvent a
l’interprete, mais peuvent se parler directement s'ils le souhaitent. En multimodalite’, sont
possibles l'e’change de textes courts, le partage sur un tableau blanc de documents textuels et
graphiques avec pointages, marquages et soulignements libres, et la Vision du correspondant.

Situation actuelle. L’imple’mentation en Tcl/T k est multiplate—forrne (indépendante
des systemes d’accueil, Windows, MacOS, ultérieurement Linux) et générique. Elle perrnet des
configurations évolutives : le serveur de communication sur station séparée (ou non), 2 stations
locuteurs (ou plus) distantes, 1 station interprete distante (ou plusieurs) ; 2 processus interpretes
sont possibles sur une meme station, par exemple en situation de bilinguisme avec traductions
"symétriques" ; 2 processus locuteurs également, en situation de "Visite" d'un locuteur a l'autre.
Nous adoptons un sche’ma de type "pousser/parler" (push to talk) pour discipliner les échanges.

Les premiers tests ont été faits a moyenne distance (Grenoble—Valence) :

Exemple d'eXpérimentation Texte Voix RtS : Voix S&R: Voix S&R +
(110 km, a 100 Mbits), court Record—then—Send Send & Record recouvrement de
avec cotation de 0 a 5 (streaming) tours de parole
Streaming non non oui oui
Qualite’ de reception 5 5 3 1
Rythme des échanges 5 2 4 5
Fiabilite’ de transmission 5 5 4 1
Phénomenes particuliers utilisateur hesitant, quelques n1icro— inutilisable (alors
dialogue perturbe’ coupures, bonne qu'acceptable sur
(trop lent) qualite’ ge’ne’rale un intranet)

Fig. 1 : Communication orale sur le web

La mise au point initiale a été faite sur l’intranet du laboratoire. Sur Internet l’échange de
messages textuels courts est gére’ classiquement, mais pour la transmission de la Voix deux
modes peuvent etre choisis (cf. Fig. 1): soit "enregistrer—puis—enVoyer" (Record—then—Send,
enregistrement local puis transmission du fichier enregistre’), tres fiable mais qui cre’e des temps
d'attente parfois contraignants, soit "enVoyer—et—enregistrer" (Send & Record, avec transmission
en ﬂux —strean1ing), qui assure un rythme d'échanges satisfaisant et dont la qualite’ est bonne
(malgré quelques microcoupures) pour autant que les locuteurs se parlent sans recouvrement
(deux locuteurs ne s'adressant pas en meme temps a l'interprete, par exemple).

Des validations a longue distance sont pre’Vues, avec etude des performances en fonction
des liaisons utilise’es.

2.2 ERIM-Collecte, pour la collecte sur réseau de dialogues spontanés
bilingues traduits

Motivation. L'impo1tance de grands corpus re’alistes est essentielle pour la
construction de systemes de TA de Parole. Ces systemes requierent des corpus acoustiques
maintenant largement produits a partir de communications sur le web. 11 est besoin également,
pour e’tablir des modeles de langues parlées en situations réelles, de corpus paralleles d'e’nonce’s
transcrits aligne’s. Peu de ressources de ce type sont produites, ou librement disponibles.

De meme, de grands corpus de dialogues spontane’s bilingues sont nécessaires pour
développer et Valider les systemes de TAP, mais il en existe tres peu (NEC, ATR, ELRA et

Interprétariat [1 distance et collecte de dialogues spontanés bilingues

quelques autres), et aucun n'est en acces libre. Pourquoi sont—ils "propriétaires" ? Parce qu'ils
sont coﬁteux a collecter, et encore plus a transcrire et annoter : les rendre disponibles
gratuitement semble déraisonnable si on les a beaucoup travaille’s.
Face a cette situation, nous avons développe’ ERIM—Collecte (cf. Fig 2), pour
° collecter des données "brutes" (que d’autres e’quipes traiteront ensuite), les plus
multimodales qu'il est possible, eta partir de dialogues réels,
° proposer a des volontaires de produire gratuitement ces données ...en l'échange d'un

acces libre aux plates—forrnes ERIM nécessaires et aux services qu'elles proposent.

Conception. ERIM—Collecte est une extension d'ERIM—Interprete, avec enregistrement
syste’matique des actes et données de l'interaction pour tous les participants (deux locuteurs ou
plus, un interprete ou plus). L'enregistrement est fait localement lors de la conversation, sur
fichiers son au format PCM l6kHz—l6bit mono. En fin de dialogue, les descripteurs et fichiers
produits localement sont transmis a un serveur de collecte, ou ils sont regroupe’s et structures.

3 ,
*3
, Tabluu Blane Tabluu Blane
T 4
gr. .

mg “.""'.
Q6) :.’.r';.:'.-':I I

\ ocuteur 1

I;’©'
 5 “Wm,

       

tour de para
ﬁun '

T.}‘......m...| |
x@ x
Q

ea

Fig. 2 : ERIM—Collecte, en configuration I locuteurs et  interpretes (ici I22, i=1)

  

Dans la situation que présente le schema, (1) l’interlocuteur frangais parle (tour de parole
en un ou plusieurs e’noncés), avec enregistrement local (la), et transmission au "CommSwitch"
qui les diffuse vers un salon virtuel e’tabli pour le dialogue (lb). L’interprete e’coute ce tour de
parole, le traduit en chinois (2). La traduction est enregistrée localement (2a), en meme temps que
diffusée (2b). L’interlocuteur chinois écoute la traduction (3), puis répond (4). De nouveau, son
tour de parole est enregistre’ localement (4a) et diffusé (4b). En (5), l’interprete le traduit en
frangais, la traduction étant enregistre’e localement (5a), et transmise(5b) au destinataire (6).

Situation actuelle. Sur la version actuelle ERIM/3—Collecte, sont enregistre’s les tours
de parole et textes courts (bimodalite’). La capture des e’venements du tableau blanc, et des objets
implique’s (fichiers visuels partage’s, trace’s libres, url. ..) est en cours d'intégration, comme celle
de la vide’o, si elle est souhaite’e (par exemple pour des études ultérieures d'expressions faciales).

ERIM—Collecte est également réalise’e en Tcl/Tlk, qui favorise l'utilisation multiplate—
forrne (PC, Macintosh, stations Unix/Linux) sur les stations de travail usuelles des utilisateurs.
La figure 3 pre’sente l'interface actuelle de la plate—forme, pour un locuteur.

Une ressource de réécoute (le module Replay) permet de reconstituer tout ou partie du
dialogue, chronologiquement ou avec extraction de versions monolingues. Elle facilite un suivi
visuel de l'e’change (cf. Fig. 4). Elle fonctionne maintenant en version bimodale (tours de parole,
e’change de textes courts — extension en cours au tableau blanc), et sera accessible sur le site web
DistribDial d'acces aux corpus produits, pour des utilisateurs de la communaute’ scientifique.

Par contre, ERIM—Collecte, destinée par choix initial a la constitution de corpus de
données brutes (fichiers descripteurs de session et tours de parole) ne propose pas de ressource
particuliere d'aide intégre’e a la transcription, ni a l'annotation. Elles sont re’alisables hors ERIM.

L'architecture ouverte de la plate—forme générique facilitera d'éventuels développements
futurs. Nous prévoyons d’utiliser par exemple les reconnaissances vocales intégre’es d’ERIM—
TA (cf. 2.3) pour produire des premieres versions instantane’es de transcriptions.

TALN 2004, F és, 19-21 avril 2004

   

| ERIM rlienunqenr '

' Elle gmngme lnnls Langages gpuen ﬂelp

 
  
   

:1 . . ' . Dileclnly ml agenl:

Em! Mode Reemd \A/Enavd Agenda Replay

C /GB|aI'Fleiuuer/'spEECl1_CllEnt C.fGe|afFl aiuuer.«‘spee:h_interpva|ar C fﬁE|a/Flaiuuer/spEeEh_agEnt

Subduectary :

E_I3 F_testl L
E_G F_test2
C_G F_test3

File in the sulzclirecloly

:| speechlwav 3.

Message its salsls la texleé awn}/av lbl, pm; is chums men cnrvaspnndant jplevla Sand

-lienri and reeewed text

peue cam est un lexleénus Dal plane 5 _
paul eee ext un |e:<|e que "El émis W D‘ “W W “E WE WE

mteuerene cam est un lexleénus pal lmlevpréle Spgak .; We

Di»:-N‘?
SW lnterpréte

    

speech2.wav
speeclﬂ wav
speechti wav
speechiwav
speechliwav
speechlwav
speechﬂwav

 

 -1 El" mum "Ll
Fig. 3 : Ecran Locuteur Fig. 4 : Réécoute des énonce’s Locuteurs, et Interprete (au centre)

Les versions successives d'ERIM—Collecte ont éte’ utilisées pour les enregistrements, a
Grenoble eta Pe’kin, d'un premier corpus de dialogues spontane’s traduits (réservation hoteliere).

2.3 ERIM-TA, vers un service de Traduction partiellement Automatique
de Parole (TpAP), aidée par le locuteur

Motivation. Pour cette variante l’objectif e’tait l'intégration générique, par plug—in, de
séries de composants de TAP (Reconnaissance, Traduction, Synthese), pour leur mise au point
en évaluation comparative, contrastive, avec la production "humaine" d'un Magicien d'Oz.

S'y est joint, en partenariat avec la start—up Spoken Translation Inc. (STI, Berkeley), le
maquettage d'une plate—forrne produit que STI souhaite développer. Enfin, nous souhaitions un
outil générique permettant d'eXpérimenter des techniques de Désambigu'1'sation Interactive
dérivées du projet LIDIA [1, 2] et de conduire des expérimentations d'utilisabilité sur ce theme.

L’enjeu global est pour nous une "Traduction partiellement Automatique de qualite"', de
parole ("tchat") et de texte (SMS), sans recours a un interprete ou traducteur humain, mais en
introduisant un niveau adéquat de controle par l’utilisateur (systemes synergiques de TAP).

De tels systemes devront étre utilisables sur tous supports (PC, PDA, téléphones ou
futures rnicrostations mobiles). Leurs Reconnaissance Vocale (RV), Traduction Automatique
(TA), Synthese Vocale (SV) et Désambigu'1'sation Interactive (DI) doivent de plus, au moins pour
les équipements mobiles, tourner sur un serveur. La encore, une généricite’ des services intégrés
est essentielle. L’architecture ouverte et l’inte’gration différentielle par plug—in y contribueront.

Conception. Pour que les couvertures lexicale et grammaticale soient assez larges, nous
avons choisi d'inte’grer des composants commerciaux (de reconnaissance de parole, de
traduction, et de synthese de parole) tous disponibles sur serveur. Ce sont, dans le premier
prototype, des produits disponibles respectivement chez Philips, Linguatec, et ScanSoft, (avec
SDKs, environnements ou kits de développement). Le composant de TA doit pouvoir étre couple’
ultérieurement avec un module de DI.

Pour la reconnaissance, nous souhaitions une RV de type "dicte’e Vocale", interactive.
IBM proposait un SDK pour son composant de RV, offrant une reconnaissance interactive pour
des domaines finalise’s, et un systeme de dictée ("transcription") non interactive a large
couverture, mais pas de dicte’e vocale interactive. L'offre de Philips semble a ce jour étre la seule
permettant une dicte’e vocale interactive sur serveur, mais l’évolution du domaine est rapide.

Situation actuelle. L'étude d'un banc d'essai monostation —le "rack" d'intégration—
a été conduite, avec plug—in des composants extemes. Ce prototype a éte’ re’alisé en Tcl/T k (pour
ses facilités d'intégration de ressources extemes et d'interope’rabilité), puis testé. L'inte’gration
finale a un dispositif multistation, de type ERIM—Interprete, est en cours.

Actuellement, le locuteur émet un e’noncé de parole en langue source, et l'e’noncé textuel
"reconnu" lui est soumis pour validation ; si ne’cessaire, il peut réentrer son e’noncé vocalement

Interprétariat [1 distance et collecte de dialogues spontanés bilingues

(ou s'il préfere, modifier au clavier l'e’nonce’ textuel propose’). Apres validation, le composant de
traduction produit un texte en langue cible, synthe’tise’ par le composant de synthese vocale.

Dans certains cas (locuteur émetteur partiellement bilingue) cette traduction écrite peut lui
étre renvoye’e ; une rétrotraduction peut aussi lui étre soumise, pour validation ; elle pourra jouer
un role d'indicateur, certes assez imparfait, d'une non—pertinence de la traduction. En cas de réelle
difficulté, le locuteur peut reformuler oralement (voire au clavier) son e’noncé en langue—source,
pour contoumer une possible inaptitude de la TA. Une validation provoquera la synthese vocale.

Il est prévu qu'ERIM—TA effectue l'enregistrement de toutes les productions (de
reconnaissance, de traduction et re’trotraduction, et de synthese), et de toute reformulation. Les
descripteurs correspondants et la base de fichiers d'une session sont en cours d'imple’mentation.

Une modélisation de la désambigu'1'sation interactive, fondée sur les techniques LIDIA [1,
2], est prévue en partenariat avec Spoken T. Inc. ; elle sera prototype’e, puis intégre’e et
eXpérimente’e sur la plate—forrne ERIM—TA. Nous prévoyons d'effectuer une pré—eXpérimentation
sur les modalite’s de ces interactions et leur pertinence, dans diffe’rentes situations d'utilisation, en
collaboration avec MultiCom (qui est une composante du CLIPS, équipe—ressource d'étude de
l'utilisabilité et de l'ergonomie des logiciels), avec observation des comportements d’utilisateurs .
Le paradigme d'une TA de Parole "aide’e par l'utilisateur" semble a priori se préter a des
utilisations de "tchat" oral multilingue de qualite’, qui inte’resse d’abord notre partenaire, et plus
globalement de communication multilingue avec traduction de qualite’, notre objectif final.

2.4 ERIM-Aides, vers des aides en ligne in la communication multilingue
sur réseau

Motivation. Dans notre scenario d'interpre’tariat intermittent "a la demande", il est
propose’ aux interpretes de passer d'une conversation a une autre et d'un sujet a un autre (a la
maniere des interpretes "de cocktail"). C'est une activite’ difficile, et il peut en re’sulter un "stress
lexical". Des aides automatiques en ligne, breves —par exemple pour une "mini—immersion
lexicale" avant intervention, selon la spécificité du domaine concemé—, seraient bienvenues.

On devrait également disposer d'aides automatiques pour les locuteurs (par exemple
"faiblement" ou partiellement bilingues, ce qui concretement est parfois le cas), pour les aider a
"se débrouiller sans interprete", en cas de nécessite’.

Conception. Les "aides a la communication" comprennent, entre autres, des ressources
° pour se voir en se parlant (locuteurs, interprete),
° pour partager des données, éventuellement modifiables, pointables, marquables (tableau

blanc, visuels partagés. . . ), consultables a posteriori. ..
° pour planifier et gérer des rendez—vous sur un agenda (accessible sur un site serveur).

Des "aides linguistiques" peuvent inclure :

° l'acces a des fiches terminologiques thématiques bilingues, a des dictionnaires
électroniques a saisie au clavier ou a entre’e vocale, par exemple par de’tection de mots
automatique (word—spotting) suivi d'un filtrage, d'une recherche en dictionnaire, et
présentation de synthese sur fenétre unique,

° en l'absence d'interprete, une reconnaissance de parole atténuant les difficultés de
comprehension orale et produisant une trace ou un historique de la conversation, que
peut également consulter l'interprete avant intervention,

° de la TA de Parole partiellement (ou completement) automatique.

Situation actuelle. Les aides de communication sont prototypées. L'agenda est global
sur un site d'acces ERIM, chaque utilisateur y accédant via une vue personnalise’e.

Les premieres aides linguistiques vont étre introduites, en interfagant des ressources
dictionnairiques existantes, en acces libre sur le site Papillon [14]. Une ressource de

I'\ /

reconnaissance vocale (Philips) a deja eté interface’e avec ERIM—TA, et sera intégre’e.

G. F aﬁotte

2.5 ERIM-Formation, pour l’e-training in distance en interprétariat
bilingue

En projet actuellement (meme si l'architecture générique des plates—forrnes actuelles
perrnet de simuler de’ja son fonctionnement), cette variante perrnettra de proposer, a des étudiants
en interpre’tariat bilingue, diffe’rents modes de formation a distance (FAD) sur le web de type
e—training, pour une activite’ "live" (en direct), ou "de doublage".

Nous prévoyons un dispositif de type "laboratoire de langues sur le web, pour
interpretes", avec par exemple un interprete professionnel (et/ou professeur) assurant la
continuité et la ﬂuidite’ du dialogue bilingue entre deux locuteurs monolingues sur le réseau, et
un cercle d'interpretes "juniors" qui peuvent (sans entendre les traductions du professionnel)
s'eXercer a distance, ou éventuellement intervenir chacun a son tour sur proposition d'un
médiateur de traduction. Toute intervention étant enregistrée (avec l'accord des intervenants) et
consultable, un travail pédagogique intéressant peut s'ensuivre.

Cette ressource rejoint de fait l'approche collaborative que privilégie le projet ERIM, car il
est probable que des étudiants avancés en interpre’tariat ou des interpretes en perfectionnement
seront volontaires pour coope’rer a l’activite’ collaborative sur ce type d'outil "d'apprentissage a
distance par la pratique", contribuant a la création de corpus de dialogues spontane’s (cf. 3.2).

11 est possible également d'envisager des situations d'utilisation plus institutionnelles, ou
des étudiants "seniors" en interpre’tariat accepteraient d'assurer des traductions bilingues dans le
cadre d'un service multilingue d'interpre’tariat "grand public", bénévolement ou en échange d'une
validation académique de cette activite’ (par exemple lors de Jeux Olympiques, Beijing 2008).

3 Application :21 la collecte de corpus de dialogues oraux bilingues

3.1 ChinFaDial, un premier corpus de dialogues spontanés traduits

ERIM—Collecte a été utilise’ dans le cadre du projet LIAMA "ChinFaDial", en partenariat
avec le NLPR (Institut d'Automatique de l'Acade’mie des Sciences de Chine, a Pékin), pour la
collecte de dialogues parle’s bilingues frangais—chinois spontane’s et traduits, entre deux locuteurs
monolingues (cf. Fig. 5). La transcription ultérieure est ici manuelle.

Eﬁfclientm
EEXEE: :Jc$ia5§1.-’i'fr]J3EtEZ=9£:'_Ei5nIFm. :1; Li?

{Je suis 2': la gare. je ne sais pas cumlnent me renclra a l‘i1cI-tel a partir de la gare.}

Agentffliillr '[?}
Alurs fest extreme-rnenl simp-1e,en sartant de la gate vous 1-Jurnez 3 dr-mite at (rest a 80 miaires en
face the I’autI'e cote de la place.

Hlifé-‘TEE. lI!lJ§E{$l'J*l’I":J:L$i:.*.?l-?JL.|'ﬁ|‘tﬂJE$r¥. 133.3%.-IE'£|J3ﬂiIt;¥-:45. ﬁl:%ﬂ{ﬂI?I*]HEtE'. J

Ei$F.v'C!|ient{E}
ie¥i.Hiﬁ3fBE1t—§.-JLHI.

{Merci bian. alors a tout -.1 |‘heure}

Agentfftﬂ {8}
Merci, bansoir Monsieuna tout a I'heure_

Iiﬁiﬁ‘---iﬁiﬁ. $12.. E5‘:---—§;‘.5I'.l

Fig. 5 : Dialogue frangais—chinois (extrait), entre hotelier frangais et client chinois

Ces collectes utilisent pour le moment, localement, les intranets des laboratoires
partenaires, avec trois participants dans le méme batiment (ou dans deux batiments proches). La
collecte a longue distance est en cours de validation.

Les situations sont réelles (réservation hoteliere), en dialogue spontane’. Une douzaine
d'heures de dialogues oraux ont été enregistre’es lors de quelques sessions a Grenoble et a Pékin,
et constituent un premier corpus de données brutes, non transcrites. Les collectes se poursuivent.

Interprétariat it distance et collecte de dialogues spontanés bilingues

L'AUF (Agence Universitaire de la Francophonie) finance actuellement le projet VTH—
Fra.Dial, une action de collecte de dialogues parlés spontane’s bilingues entre le frangais d'une
part, et le vietnamien, le tamoul, et l'hindi, dans des régions francophones des pays concernés.

3.2 Un schéma de création collaborative de ressources pour la TAP

Nous souhaitons contribuer a promouvoir un sche’ma de mutualisation de ressources
pour l'ingénierie de la TA de Parole : corpus paralleles de dialogues parle’s spontane’s, a collecter,
puis a transcrire et annoter, en participation collaborative.

Une étape premiere sera la mise en acces libre au printemps 2004, sur site web, des
données de’ja collecte’es en frangais—chinois, sous une forme "rejouable" avec le module Replay,
et, pour chaque conversation, un descripteur des parametres d’intervenants (anonymes) et de
session, la liste des tours de parole horodate’s par locuteur, les pointeurs sur les fichiers son.

Ce site et son environnement DistribDial devront faciliter l'enrichissement libre des
corpus par d'autres chercheurs, par ajout de transcriptions et/ou d'annotations en fichiers
paralleles (selon un format homogene) —a rendre accessibles également sur le web.

Une contribution suivante sera de proposer la plate—forme ERIM—Collecte elle—méme, en
acces libre (GPL) sur le web, apres de nouveaux tests de robustesse, de performance a distance,
et quelques développements d'utilisabilité.

4 Développements en cours, prospective

L'environnement ERIM s'est construit par prototypage exploratoire puis développement
incrémentiel de plusieurs classes de ressources complémentaires, en cohe’rence fonctionnelle. La
recherche sur et avec ces plates—formes, apres cadrage en tranches fonctionnelles, se poursuit par

° de nouvelles collectes dans de nouvelles langues,

° l'enrichissement fonctionnel du serveur de multimodalite’ d'ERIM—Interprete, puis le
développement de la capture de données multimodales par ERIM—Collecte, enregistrant
les évenements multimodaux et leur horodatage, avec un Replay Multimodal associe’,

° la consolidation de DistribDial, le site d’acces aux corpus collecte’s,

° un site d’acces a la plate—forme ERIM—Collecte pour la collecte collaborative,

° quelques extensions fonctionnelles conduisant a une plate—forme "laboratoire", facilitant
le plug—in de composants pour la TAP ou la "TAP de qualite’ aide’e par l'utilisateur", et
leur experimentation —que ces composants proviennent de réalisations académiques, de
versions a tester ou a régler ("tuning"), ou qu'ils soient des produits logiciels du marche’ ;
plusieurs produits ou versions de modules de TA en cours de prototypage, d'une meme
classe fonctionnelle (RV, TA, SV, ou DI) pourront étre teste’s et comparés en parallele
avec enregistrement complet ; des études contrastives avec des productions humaines
d'interpretes magiciens d'Oz, enregistre’es en parallele, seront possibles,

° le prototypage et l'évaluation expérimentale de solutions de désambigu'1'sation interactive,
pour ERIM—TA.

Nous souhaitons, parallelement a la diffusion d'une plate—forme a usage ciblé (pour la
collecte de données brutes, puis leurs enrichissements contributifs), entreprendre également
l'unification et l'intégration des diffe’rents composants d'ERIM ici présente’s en une plate—forme
unique ERIMM, Environnement Réseau pour l'Interpre’tariat Multimodal Multilingue, regroupant
un ensemble d’aides a la communication multilingue et multimodale sur réseau.

Conclusion

Nous avons présente’ 3 plates—formes déja opérationnelles (l'une d’elle en finition),
permettant d'aider la communication bilingue sur le web, pour des dialogues spontane’s non
finalise’s : ERIM—Interprete, pour l'interpre’tariat humain sur réseau, ERIM—Collecte, qui réduit le

G. F aﬁotte

manque de données utiles pour développer de meilleurs systemes de TA de Parole, et ERIM—TA
ressource générique destine’e a la Traduction partiellement Automatique de Parole (TpAP), de
qualite’, utilisant des produits logiciels de reconnaissance, traduction et synthese a couverture
large et disponibles sur serveurs, avec controle par l'utilisateur (feedback, validation directe,
désambigu'1'sation interactive). ERIM—TA assiste aussi l’ingénierie des systemes de TAP, et
constitue un banc d’essai générique en situation réelle, ou de réglage, pour leurs composants.

Une autre plate—forrne ERIM—Aides proposant aux interpretes et locuteurs des aides en
ligne (aides de communication, aides lexicales), est partiellement réalise’e.

Les dialogues spontane’s bilingues déja collecte’s (frangais—chinois) seront prochainement
disponibles en acces libre sur le web, ainsi que les plates—formes Interprete et de Collecte.

Cette recherche se poursuit par la collecte et la distribution de données concemant
d'autres langues, par l'enrichissement fonctionnel des quatre premieres plates—formes, puis leur
unification en un environnement unique ERIMM, base d'expérimentation et d'aide a l'ingénierie
de systemes de TpAP multilingue et multimodale, et enfin par le développement d'un "labo de
langue sur le web pour l'interpre’tariat", ERIMM—Formation, qui pourrait également contribuer
aux collectes.

Remerciements

Ces travaux ont éte’ soutenus par le CLIPS—IMAG (Université Joseph Fourier
Grenoble—1, INPG, CNRS), par la Region Rhone—Alpes (projet ERIM), et par le laboratoire
franco—chinois LIAMA (projet ChinFaDial). Zhai .IianShe (Université de Nankin) en résidence
au CLIPS, puis Julien Lamboley (Eleve—Inge’nieur INSA Lyon) ont contribué au développement
des plates—formes. L'auteur les remercie, ainsi que les membres du CLIPS, de MultiCom (a
Grenoble) et du NLPR (CAS—IA, a Pékin) qui ont participé aux collectes et expérimentations.

Références

[1] Blanchon H. (1994) Perspectives of DBMT for monolingual authors on the basis of
LIDIA—1, an implemented mockup. Proc. 15th International Conference on Computational
Linguistics, COLING—94, Y. Wilks ed., vol. 1/2, pp. 115—119.

[2] Boitet C., Blanchon H. (1994) Multilingual Dialogue—Based MT for Monolingual
Authors: the LIDIA Project and a First Mockup. Machine Translation 9/2 1994, pp. 99— 132.
[3] Brown R. D., Nirenburg S. (1990) Human—Computer Interaction for Semantic
Disambiguation. Proc. COLING—90, ACL, H. Karlgren ed., vol. 3/3, pp. 42-47.

[4] Coutaz J ., Salber D., Carraux E., Portolan N. (1996) NEIMO, a Multiwork station
Usability Lab for Observing and Analyzing Multimodal Interaction. Proc. CHI ’96 companion.
[5] Fafiotte G., Boitet C. (1994) Report on first EMMI Experiments for the MIDDIM project
in the context of Interpreting Telecommunications. MIDDIM report TR—IT—0074 GETA—IMAG
& ATR—ITL, Aug. 1994, 11 p.

[6] Fafiotte G., Zhai J .—S. (1999) A Network—based Simulator for Speech Translation. Proc.
NPLRS’99, Beijing, 5-7/II/99, B. Yuan, T. Huang & X. Tang ed., pp. 511-514.

[7] Loken—Kim K.—H., Yato F., Morimoto T. (1994) A Simulation Environment for
Multimodal Interpreting Telecommunications. Proc. IPSJ—AV workshop, March 1994, 5 p.

[8] Morimoto T., Takezawa T., Yato F., Sagayama S., Tashiro T., Nagata M. & al. (1993)
ATR's Speech Translation System: ASURA. Proc. EuroSpeech'93, Berlin, 21-23/9/83, 4 p.

[9] Nyberg E. H., Mitamura T. (1992) The KANT system: Fast, Accurate, High—Quality
Translation in Practical Domains. Proc. COLING—92, ACL, vol. 3/4, pp. 1069— 1073.

[10] <url> site web C—STAR: http://www.c—star.org

[1 1] <url> site web DARPA: http://www.darpa.n1il/ito/ research/ con1/ index.htn1l

http://fofoca.mitre.org/doc.html

[12] <url> GALAXY architecture site: http://www.sls.lcs.rnit.edu/sls/whatwedo/architecture.html
[13] <url> site web NESPOLE! : http://nespole.itc.it

[14] <url> site web PAPILLON: http://www.papillon—dictionary.org

[15] <url> site web VERBMOBIL: http://verbmobil.dfki.de

