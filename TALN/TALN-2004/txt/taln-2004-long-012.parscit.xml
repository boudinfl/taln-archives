<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>Ces travaux ont été soutenus par le CLIPS-IMAG (Université Joseph Fourier Grenoble–1, INPG, CNRS), par la Région Rhône-Alpes (projet ERIM), et par le laboratoire franco-chinois LIAMA (projet ChinFaDial). Zhai JianShe (Université de Nankin) en résidence au CLIPS, puis Julien Lamboley (Élève-Ingénieur INSA Lyon) ont contribué au développement des plates-formes. L&apos;auteur les remercie, ainsi que les membres du CLIPS, de MultiCom (à Grenoble) et du NLPR (CAS-IA, à Pékin) qui ont participé aux collectes et expérimentations. Références</title>
<marker></marker>
<rawString> Ces travaux ont été soutenus par le CLIPS-IMAG (Université Joseph Fourier Grenoble–1, INPG, CNRS), par la Région Rhône-Alpes (projet ERIM), et par le laboratoire franco-chinois LIAMA (projet ChinFaDial). Zhai JianShe (Université de Nankin) en résidence au CLIPS, puis Julien Lamboley (Élève-Ingénieur INSA Lyon) ont contribué au développement des plates-formes. L&apos;auteur les remercie, ainsi que les membres du CLIPS, de MultiCom (à Grenoble) et du NLPR (CAS-IA, à Pékin) qui ont participé aux collectes et expérimentations. Références</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Blanchon</author>
</authors>
<title>Perspectives of DBMT for monolingual authors on the basis of LIDIA-1, an implemented mockup.</title>
<date>1994</date>
<booktitle>Proc. 15th International Conference on Computational Linguistics, COLING-94,</booktitle>
<volume>1</volume>
<pages>115--119</pages>
<editor>Y. Wilks ed.,</editor>
<contexts>
<context position="19787" citStr="[1, 2]" startWordPosition="2791" endWordPosition="2792"> (TpAP), aidée par le locuteur Motivation. Pour cette variante l’objectif était l&apos;intégration générique, par plug-in, de séries de composants de TAP (Reconnaissance, Traduction, Synthèse), pour leur mise au point en évaluation comparative, contrastive, avec la production &amp;quot;humaine&amp;quot; d&apos;un Magicien d&apos;Oz. S&apos;y est joint, en partenariat avec la start-up Spoken Translation Inc. (STI, Berkeley), le maquettage d&apos;une plate-forme produit que STI souhaite développer. Enfin, nous souhaitions un outil générique permettant d&apos;expérimenter des techniques de Désambiguïsation Interactive dérivées du projet LIDIA [1, 2] et de conduire des expérimentations d&apos;utilisabilité sur ce thème. L’enjeu global est pour nous une &amp;quot;Traduction partiellement Automatique de qualité&amp;quot;, de parole (&amp;quot;tchat&amp;quot;) et de texte (SMS), sans recours à un interprète ou traducteur humain, mais en introduisant un niveau adéquat de contrôle par l’utilisateur (systèmes synergiques de TAP). De tels systèmes devront être utilisables sur tous supports (PC, PDA, téléphones ou futures microstations mobiles). Leurs Reconnaissance Vocale (RV), Traduction Automatique (TA), Synthèse Vocale (SV) et Désambiguïsation Interactive (DI) doivent de plus, au mo</context>
<context position="23209" citStr="[1, 2]" startWordPosition="3273" endWordPosition="3274">pertinence de la traduction. En cas de réelle difficulté, le locuteur peut reformuler oralement (voire au clavier) son énoncé en langue-source, pour contourner une possible inaptitude de la TA. Une validation provoquera la synthèse vocale. Il est prévu qu&apos;ERIM-TA effectue l&apos;enregistrement de toutes les productions (de reconnaissance, de traduction et rétrotraduction, et de synthèse), et de toute reformulation. Les descripteurs correspondants et la base de fichiers d&apos;une session sont en cours d&apos;implémentation. Une modélisation de la désambiguïsation interactive, fondée sur les techniques LIDIA [1, 2], est prévue en partenariat avec Spoken T. Inc. ; elle sera prototypée, puis intégrée et expérimentée sur la plate-forme ERIM-TA. Nous prévoyons d&apos;effectuer une pré-expérimentation sur les modalités de ces interactions et leur pertinence, dans différentes situations d&apos;utilisation, en collaboration avec MultiCom (qui est une composante du CLIPS, équipe-ressource d&apos;étude de l&apos;utilisabilité et de l&apos;ergonomie des logiciels), avec observation des comportements d’utilisateurs . Le paradigme d&apos;une TA de Parole &amp;quot;aidée par l&apos;utilisateur&amp;quot; semble a priori se prêter à des utilisations de &amp;quot;tchat&amp;quot; oral mult</context>
</contexts>
<marker>[1]</marker>
<rawString>Blanchon H. (1994) Perspectives of DBMT for monolingual authors on the basis of LIDIA-1, an implemented mockup. Proc. 15th International Conference on Computational Linguistics, COLING-94, Y. Wilks ed., vol. 1/2, pp. 115—119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Boitet</author>
<author>H Blanchon</author>
</authors>
<title>Multilingual Dialogue-Based MT for Monolingual Authors: the LIDIA Project and a First Mockup.</title>
<date>1994</date>
<journal>Machine Translation</journal>
<volume>9</volume>
<pages>99--132</pages>
<contexts>
<context position="19787" citStr="[1, 2]" startWordPosition="2791" endWordPosition="2792"> (TpAP), aidée par le locuteur Motivation. Pour cette variante l’objectif était l&apos;intégration générique, par plug-in, de séries de composants de TAP (Reconnaissance, Traduction, Synthèse), pour leur mise au point en évaluation comparative, contrastive, avec la production &amp;quot;humaine&amp;quot; d&apos;un Magicien d&apos;Oz. S&apos;y est joint, en partenariat avec la start-up Spoken Translation Inc. (STI, Berkeley), le maquettage d&apos;une plate-forme produit que STI souhaite développer. Enfin, nous souhaitions un outil générique permettant d&apos;expérimenter des techniques de Désambiguïsation Interactive dérivées du projet LIDIA [1, 2] et de conduire des expérimentations d&apos;utilisabilité sur ce thème. L’enjeu global est pour nous une &amp;quot;Traduction partiellement Automatique de qualité&amp;quot;, de parole (&amp;quot;tchat&amp;quot;) et de texte (SMS), sans recours à un interprète ou traducteur humain, mais en introduisant un niveau adéquat de contrôle par l’utilisateur (systèmes synergiques de TAP). De tels systèmes devront être utilisables sur tous supports (PC, PDA, téléphones ou futures microstations mobiles). Leurs Reconnaissance Vocale (RV), Traduction Automatique (TA), Synthèse Vocale (SV) et Désambiguïsation Interactive (DI) doivent de plus, au mo</context>
<context position="23209" citStr="[1, 2]" startWordPosition="3273" endWordPosition="3274">pertinence de la traduction. En cas de réelle difficulté, le locuteur peut reformuler oralement (voire au clavier) son énoncé en langue-source, pour contourner une possible inaptitude de la TA. Une validation provoquera la synthèse vocale. Il est prévu qu&apos;ERIM-TA effectue l&apos;enregistrement de toutes les productions (de reconnaissance, de traduction et rétrotraduction, et de synthèse), et de toute reformulation. Les descripteurs correspondants et la base de fichiers d&apos;une session sont en cours d&apos;implémentation. Une modélisation de la désambiguïsation interactive, fondée sur les techniques LIDIA [1, 2], est prévue en partenariat avec Spoken T. Inc. ; elle sera prototypée, puis intégrée et expérimentée sur la plate-forme ERIM-TA. Nous prévoyons d&apos;effectuer une pré-expérimentation sur les modalités de ces interactions et leur pertinence, dans différentes situations d&apos;utilisation, en collaboration avec MultiCom (qui est une composante du CLIPS, équipe-ressource d&apos;étude de l&apos;utilisabilité et de l&apos;ergonomie des logiciels), avec observation des comportements d’utilisateurs . Le paradigme d&apos;une TA de Parole &amp;quot;aidée par l&apos;utilisateur&amp;quot; semble a priori se prêter à des utilisations de &amp;quot;tchat&amp;quot; oral mult</context>
</contexts>
<marker>[2]</marker>
<rawString>Boitet C., Blanchon H. (1994) Multilingual Dialogue-Based MT for Monolingual Authors: the LIDIA Project and a First Mockup. Machine Translation 9/2 1994, pp. 99—132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R D Brown</author>
<author>S Nirenburg</author>
</authors>
<title>Human-Computer Interaction for Semantic Disambiguation.</title>
<date>1990</date>
<booktitle>Proc. COLING-90,</booktitle>
<volume>3</volume>
<pages>42--47</pages>
<editor>ACL, H. Karlgren ed.,</editor>
<marker>[3]</marker>
<rawString>Brown R. D., Nirenburg S. (1990) Human-Computer Interaction for Semantic Disambiguation. Proc. COLING-90, ACL, H. Karlgren ed., vol. 3/3, pp. 42-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Coutaz</author>
<author>D Salber</author>
<author>E Carraux</author>
<author>N Portolan</author>
</authors>
<title>NEIMO, a Multiwork station Usability Lab for Observing and Analyzing Multimodal Interaction.</title>
<date>1996</date>
<booktitle>Proc. CHI’96 companion.</booktitle>
<contexts>
<context position="6686" citStr="[4]" startWordPosition="908" endWordPosition="908">le pour l&apos;insertion professionnelle des handicapés, et facilitant les interventions ponctuelles à la demande. Enfin, nous mettrons à disposition à terme certains des logiciels développés, en accès libre sur le web, pour favoriser un volontariat de production de ressources partageables au sein de la communauté des chercheurs en TA de Parole. 1.2 Un premier environnement : Sim*, simulateur de traduction avec Magicien d’Oz, pour la collecte de dialogues spontanés Motivation. À la suite de travaux sur des plates-formes multimodales à magicien d’Oz (architecture multimagiciens monolingues de NEIMO [4], ou, à ATR-ITL Kyoto, EMMI [7, 5] à magicien unique bilingue, dans un contexte d’étude de la désambiguisation interactive multimodale), nous avons pensé utile, pour faciliter la construction de systèmes de TAP, d&apos;acquérir d&apos;abord une expérience et de rassembler des données, en prototypant Sim* (prononcer Sim-star), environnement de simulation de TAP conçu parallèlement à C-STAR II. Conception. L&apos;architecture de Sim* est celle d&apos;un environnement multiposte avec Interprétariat à distance et collecte de dialogues spontanés bilingues interprète magicien d’Oz [6], ce dernier entendant et voyant le</context>
</contexts>
<marker>[4]</marker>
<rawString>Coutaz J., Salber D., Carraux E., Portolan N. (1996) NEIMO, a Multiwork station Usability Lab for Observing and Analyzing Multimodal Interaction. Proc. CHI’96 companion.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Fafiotte</author>
<author>C Boitet</author>
</authors>
<title>Report on first EMMI Experiments for the MIDDIM project in the context of Interpreting Telecommunications.</title>
<date>1994</date>
<booktitle>MIDDIM report TR-IT-0074 GETA-IMAG &amp; ATR-ITL,</booktitle>
<pages>11</pages>
<contexts>
<context position="6720" citStr="[7, 5]" startWordPosition="914" endWordPosition="915">elle des handicapés, et facilitant les interventions ponctuelles à la demande. Enfin, nous mettrons à disposition à terme certains des logiciels développés, en accès libre sur le web, pour favoriser un volontariat de production de ressources partageables au sein de la communauté des chercheurs en TA de Parole. 1.2 Un premier environnement : Sim*, simulateur de traduction avec Magicien d’Oz, pour la collecte de dialogues spontanés Motivation. À la suite de travaux sur des plates-formes multimodales à magicien d’Oz (architecture multimagiciens monolingues de NEIMO [4], ou, à ATR-ITL Kyoto, EMMI [7, 5] à magicien unique bilingue, dans un contexte d’étude de la désambiguisation interactive multimodale), nous avons pensé utile, pour faciliter la construction de systèmes de TAP, d&apos;acquérir d&apos;abord une expérience et de rassembler des données, en prototypant Sim* (prononcer Sim-star), environnement de simulation de TAP conçu parallèlement à C-STAR II. Conception. L&apos;architecture de Sim* est celle d&apos;un environnement multiposte avec Interprétariat à distance et collecte de dialogues spontanés bilingues interprète magicien d’Oz [6], ce dernier entendant et voyant les locuteurs grâce à leur webcam, e</context>
</contexts>
<marker>[5]</marker>
<rawString>Fafiotte G., Boitet C. (1994) Report on first EMMI Experiments for the MIDDIM project in the context of Interpreting Telecommunications. MIDDIM report TR-IT-0074 GETA-IMAG &amp; ATR-ITL, Aug. 1994, 11 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Fafiotte</author>
<author>J-S Zhai</author>
</authors>
<title>A Network-based Simulator for Speech Translation.</title>
<date>1999</date>
<booktitle>Proc. NPLRS’99, Beijing,</booktitle>
<pages>5--7</pages>
<editor>B. Yuan, T. Huang &amp; X. Tang ed.,</editor>
<contexts>
<context position="7251" citStr="[6]" startWordPosition="987" endWordPosition="987">ultimagiciens monolingues de NEIMO [4], ou, à ATR-ITL Kyoto, EMMI [7, 5] à magicien unique bilingue, dans un contexte d’étude de la désambiguisation interactive multimodale), nous avons pensé utile, pour faciliter la construction de systèmes de TAP, d&apos;acquérir d&apos;abord une expérience et de rassembler des données, en prototypant Sim* (prononcer Sim-star), environnement de simulation de TAP conçu parallèlement à C-STAR II. Conception. L&apos;architecture de Sim* est celle d&apos;un environnement multiposte avec Interprétariat à distance et collecte de dialogues spontanés bilingues interprète magicien d’Oz [6], ce dernier entendant et voyant les locuteurs grâce à leur webcam, et n’étant ni vu, ni entendu (du moins comme un humain) par eux. Sur Sim*, les locuteurs peuvent s’entendre et se voir, et disposent de ressources multimodales de base : échange de textes courts, &amp;quot;tableau blanc&amp;quot; pour le partage de documents visuels et d’annotations graphiques libres. Nous visions une observation de comportements d’utilisateurs placés en situation future de TA multimodale, en même temps que la collecte de données (parole et textes courts dans un premier temps) permettant la modélisation de la langue spontanée p</context>
</contexts>
<marker>[6]</marker>
<rawString>Fafiotte G., Zhai J.-S. (1999) A Network-based Simulator for Speech Translation. Proc. NPLRS’99, Beijing, 5-7/11/99, B. Yuan, T. Huang &amp; X. Tang ed., pp. 511-514.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K-H Loken-Kim</author>
<author>F Yato</author>
<author>T Morimoto</author>
</authors>
<title>A Simulation Environment for Multimodal Interpreting Telecommunications.</title>
<date>1994</date>
<booktitle>Proc. IPSJ-AV workshop,</booktitle>
<pages>5</pages>
<contexts>
<context position="6720" citStr="[7, 5]" startWordPosition="914" endWordPosition="915">elle des handicapés, et facilitant les interventions ponctuelles à la demande. Enfin, nous mettrons à disposition à terme certains des logiciels développés, en accès libre sur le web, pour favoriser un volontariat de production de ressources partageables au sein de la communauté des chercheurs en TA de Parole. 1.2 Un premier environnement : Sim*, simulateur de traduction avec Magicien d’Oz, pour la collecte de dialogues spontanés Motivation. À la suite de travaux sur des plates-formes multimodales à magicien d’Oz (architecture multimagiciens monolingues de NEIMO [4], ou, à ATR-ITL Kyoto, EMMI [7, 5] à magicien unique bilingue, dans un contexte d’étude de la désambiguisation interactive multimodale), nous avons pensé utile, pour faciliter la construction de systèmes de TAP, d&apos;acquérir d&apos;abord une expérience et de rassembler des données, en prototypant Sim* (prononcer Sim-star), environnement de simulation de TAP conçu parallèlement à C-STAR II. Conception. L&apos;architecture de Sim* est celle d&apos;un environnement multiposte avec Interprétariat à distance et collecte de dialogues spontanés bilingues interprète magicien d’Oz [6], ce dernier entendant et voyant les locuteurs grâce à leur webcam, e</context>
</contexts>
<marker>[7]</marker>
<rawString>Loken-Kim K.-H., Yato F., Morimoto T. (1994) A Simulation Environment for Multimodal Interpreting Telecommunications. Proc. IPSJ-AV workshop, March 1994, 5 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Morimoto</author>
<author>T Takezawa</author>
<author>F Yato</author>
<author>S Sagayama</author>
<author>T Tashiro</author>
<author>M Nagata</author>
<author>al</author>
</authors>
<title>ATR&apos;s Speech Translation System: ASURA.</title>
<date>1993</date>
<booktitle>Proc. EuroSpeech&apos;93,</booktitle>
<volume>21</volume>
<pages>p.</pages>
<location>Berlin,</location>
<contexts>
<context position="3061" citStr="[8, 10]" startWordPosition="398" endWordPosition="399">ed interpreting, bilingual spoken corpora collection, spontaneous dialogues, multilingual communication, resource mutualization. Introduction Les progrès de la TA de Parole (TAP) ont été sensibles dans la dernière décennie, particulièrement en spontanéité du style et en multilinguisme. La première démonstration fut effectuée par NEC (septembre 1992) dans le domaine du tourisme, mais les recherches les plus connues sur ces thèmes peuvent être créditées à des actions très coordonnées, entre autres les G. Fafiotte projets C-STAR (international Consortium for Speech Translation Advanced Research) [8, 10], en Europe les projets NESPOLE! IST [13] et l&apos;allemand Verbmobil [15] et aux USA le DARPA Communicator project [11] avec le Galaxy Communicator Software Infrastructure [12]. Ces projets ont produit des plates-formes de traitement de la parole spontanée en communication multilingue personne-personne ou personne-système, toujours dans des domaines ciblés. Le manque notoire de grands corpus de dialogues parlés bilingues en accès libre (ressources essentielles au développement de systèmes de TAP spontanée), d&apos;une part, et d&apos;autre part l&apos;importance de l&apos;étude de l&apos;impact de la multimodalité sur la</context>
</contexts>
<marker>[8]</marker>
<rawString>Morimoto T., Takezawa T., Yato F., Sagayama S., Tashiro T., Nagata M. &amp; al. (1993) ATR&apos;s Speech Translation System: ASURA. Proc. EuroSpeech&apos;93, Berlin, 21-23/9/83, 4 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Nyberg</author>
<author>T Mitamura</author>
</authors>
<title>The KANT system: Fast, Accurate, High-Quality Translation in Practical Domains.</title>
<date>1992</date>
<booktitle>Proc. COLING-92, ACL,</booktitle>
<volume>3</volume>
<pages>1069--1073</pages>
<marker>[9]</marker>
<rawString>Nyberg E. H., Mitamura T. (1992) The KANT system: Fast, Accurate, High-Quality Translation in Practical Domains. Proc. COLING-92, ACL, vol. 3/4, pp. 1069—1073.</rawString>
</citation>
<citation valid="false">
<note>site web C-STAR: http://www.c-star.org</note>
<contexts>
<context position="3061" citStr="[8, 10]" startWordPosition="398" endWordPosition="399">ed interpreting, bilingual spoken corpora collection, spontaneous dialogues, multilingual communication, resource mutualization. Introduction Les progrès de la TA de Parole (TAP) ont été sensibles dans la dernière décennie, particulièrement en spontanéité du style et en multilinguisme. La première démonstration fut effectuée par NEC (septembre 1992) dans le domaine du tourisme, mais les recherches les plus connues sur ces thèmes peuvent être créditées à des actions très coordonnées, entre autres les G. Fafiotte projets C-STAR (international Consortium for Speech Translation Advanced Research) [8, 10], en Europe les projets NESPOLE! IST [13] et l&apos;allemand Verbmobil [15] et aux USA le DARPA Communicator project [11] avec le Galaxy Communicator Software Infrastructure [12]. Ces projets ont produit des plates-formes de traitement de la parole spontanée en communication multilingue personne-personne ou personne-système, toujours dans des domaines ciblés. Le manque notoire de grands corpus de dialogues parlés bilingues en accès libre (ressources essentielles au développement de systèmes de TAP spontanée), d&apos;une part, et d&apos;autre part l&apos;importance de l&apos;étude de l&apos;impact de la multimodalité sur la</context>
</contexts>
<marker>[10]</marker>
<rawString>&lt;url&gt; site web C-STAR: http://www.c-star.org</rawString>
</citation>
<citation valid="false">
<title>site web DARPA:</title>
<note>http://www.darpa.mil/ito/research/com/index.html http://fofoca.mitre.org/doc.html</note>
<contexts>
<context position="3177" citStr="[11]" startWordPosition="418" endWordPosition="418">lization. Introduction Les progrès de la TA de Parole (TAP) ont été sensibles dans la dernière décennie, particulièrement en spontanéité du style et en multilinguisme. La première démonstration fut effectuée par NEC (septembre 1992) dans le domaine du tourisme, mais les recherches les plus connues sur ces thèmes peuvent être créditées à des actions très coordonnées, entre autres les G. Fafiotte projets C-STAR (international Consortium for Speech Translation Advanced Research) [8, 10], en Europe les projets NESPOLE! IST [13] et l&apos;allemand Verbmobil [15] et aux USA le DARPA Communicator project [11] avec le Galaxy Communicator Software Infrastructure [12]. Ces projets ont produit des plates-formes de traitement de la parole spontanée en communication multilingue personne-personne ou personne-système, toujours dans des domaines ciblés. Le manque notoire de grands corpus de dialogues parlés bilingues en accès libre (ressources essentielles au développement de systèmes de TAP spontanée), d&apos;une part, et d&apos;autre part l&apos;importance de l&apos;étude de l&apos;impact de la multimodalité sur la communication multilingue (à l&apos;heure où les équipements de télécommunication mobile monolingue intègrent ce type de</context>
</contexts>
<marker>[11]</marker>
<rawString>&lt;url&gt; site web DARPA: http://www.darpa.mil/ito/research/com/index.html http://fofoca.mitre.org/doc.html</rawString>
</citation>
<citation valid="false">
<note>GALAXY architecture site: http://www.sls.lcs.mit.edu/sls/whatwedo/architecture.html</note>
<contexts>
<context position="3234" citStr="[12]" startWordPosition="425" endWordPosition="425">P) ont été sensibles dans la dernière décennie, particulièrement en spontanéité du style et en multilinguisme. La première démonstration fut effectuée par NEC (septembre 1992) dans le domaine du tourisme, mais les recherches les plus connues sur ces thèmes peuvent être créditées à des actions très coordonnées, entre autres les G. Fafiotte projets C-STAR (international Consortium for Speech Translation Advanced Research) [8, 10], en Europe les projets NESPOLE! IST [13] et l&apos;allemand Verbmobil [15] et aux USA le DARPA Communicator project [11] avec le Galaxy Communicator Software Infrastructure [12]. Ces projets ont produit des plates-formes de traitement de la parole spontanée en communication multilingue personne-personne ou personne-système, toujours dans des domaines ciblés. Le manque notoire de grands corpus de dialogues parlés bilingues en accès libre (ressources essentielles au développement de systèmes de TAP spontanée), d&apos;une part, et d&apos;autre part l&apos;importance de l&apos;étude de l&apos;impact de la multimodalité sur la communication multilingue (à l&apos;heure où les équipements de télécommunication mobile monolingue intègrent ce type de dispositif), nous ont motivés pour étudier, modéliser, e</context>
</contexts>
<marker>[12]</marker>
<rawString>&lt;url&gt; GALAXY architecture site: http://www.sls.lcs.mit.edu/sls/whatwedo/architecture.html</rawString>
</citation>
<citation valid="false">
<authors>
<author>site web NESPOLE</author>
</authors>
<note>http://nespole.itc.it</note>
<contexts>
<context position="3102" citStr="[13]" startWordPosition="406" endWordPosition="406">llection, spontaneous dialogues, multilingual communication, resource mutualization. Introduction Les progrès de la TA de Parole (TAP) ont été sensibles dans la dernière décennie, particulièrement en spontanéité du style et en multilinguisme. La première démonstration fut effectuée par NEC (septembre 1992) dans le domaine du tourisme, mais les recherches les plus connues sur ces thèmes peuvent être créditées à des actions très coordonnées, entre autres les G. Fafiotte projets C-STAR (international Consortium for Speech Translation Advanced Research) [8, 10], en Europe les projets NESPOLE! IST [13] et l&apos;allemand Verbmobil [15] et aux USA le DARPA Communicator project [11] avec le Galaxy Communicator Software Infrastructure [12]. Ces projets ont produit des plates-formes de traitement de la parole spontanée en communication multilingue personne-personne ou personne-système, toujours dans des domaines ciblés. Le manque notoire de grands corpus de dialogues parlés bilingues en accès libre (ressources essentielles au développement de systèmes de TAP spontanée), d&apos;une part, et d&apos;autre part l&apos;importance de l&apos;étude de l&apos;impact de la multimodalité sur la communication multilingue (à l&apos;heure où </context>
</contexts>
<marker>[13]</marker>
<rawString>&lt;url&gt; site web NESPOLE! : http://nespole.itc.it</rawString>
</citation>
<citation valid="false">
<note>site web PAPILLON: http://www.papillon-dictionary.org</note>
<contexts>
<context position="26094" citStr="[14]" startWordPosition="3678" endWordPosition="3678">&apos;interprète, une reconnaissance de parole atténuant les difficultés de compréhension orale et produisant une trace ou un historique de la conversation, que peut également consulter l&apos;interprète avant intervention, • de la TA de Parole partiellement (ou complètement) automatique. Situation actuelle. Les aides de communication sont prototypées. L&apos;agenda est global sur un site d&apos;accès ERIM, chaque utilisateur y accédant via une vue personnalisée. Les premières aides linguistiques vont être introduites, en interfaçant des ressources dictionnairiques existantes, en accès libre sur le site Papillon [14]. Une ressource de reconnaissance vocale (Philips) a déjà été interfacée avec ERIM-TA, et sera intégrée. G. Fafiotte 2.5 ERIM-Formation, pour l’e-training à distance en interprétariat bilingue En projet actuellement (même si l&apos;architecture générique des plates-formes actuelles permet de simuler déjà son fonctionnement), cette variante permettra de proposer, à des étudiants en interprétariat bilingue, différents modes de formation à distance (FAD) sur le web de type e–training, pour une activité &amp;quot;live&amp;quot; (en direct), ou &amp;quot;de doublage&amp;quot;. Nous prévoyons un dispositif de type &amp;quot;laboratoire de langues s</context>
</contexts>
<marker>[14]</marker>
<rawString>&lt;url&gt; site web PAPILLON: http://www.papillon-dictionary.org</rawString>
</citation>
<citation valid="false">
<note>site web VERBMOBIL: http://verbmobil.dfki.de</note>
<contexts>
<context position="3131" citStr="[15]" startWordPosition="410" endWordPosition="410">es, multilingual communication, resource mutualization. Introduction Les progrès de la TA de Parole (TAP) ont été sensibles dans la dernière décennie, particulièrement en spontanéité du style et en multilinguisme. La première démonstration fut effectuée par NEC (septembre 1992) dans le domaine du tourisme, mais les recherches les plus connues sur ces thèmes peuvent être créditées à des actions très coordonnées, entre autres les G. Fafiotte projets C-STAR (international Consortium for Speech Translation Advanced Research) [8, 10], en Europe les projets NESPOLE! IST [13] et l&apos;allemand Verbmobil [15] et aux USA le DARPA Communicator project [11] avec le Galaxy Communicator Software Infrastructure [12]. Ces projets ont produit des plates-formes de traitement de la parole spontanée en communication multilingue personne-personne ou personne-système, toujours dans des domaines ciblés. Le manque notoire de grands corpus de dialogues parlés bilingues en accès libre (ressources essentielles au développement de systèmes de TAP spontanée), d&apos;une part, et d&apos;autre part l&apos;importance de l&apos;étude de l&apos;impact de la multimodalité sur la communication multilingue (à l&apos;heure où les équipements de télécommun</context>
</contexts>
<marker>[15]</marker>
<rawString>&lt;url&gt; site web VERBMOBIL: http://verbmobil.dfki.de</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>