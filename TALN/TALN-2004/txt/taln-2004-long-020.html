<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>D&#233;sambigu&#239;sation de corpus monolingues par des approches de type Lesk</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2004, F&#232;s, 19&#8211;21 avril 2004
</p>
<p>D&#233;sambigu&#239;sation de corpus monolingues
par des approches de type Lesk
</p>
<p>Florentina Vasilescu, Philippe Langlais
</p>
<p>RALI/IRO, Universit&#233; de Montr&#233;al
CP. 6128, succursale Centre-ville
</p>
<p>Montr&#233;al, Qu&#233;bec, H3C CJ7 Canada
{vasilesf,felipe}@iro.umontreal.ca
</p>
<p>R&#233;sum&#233; - Abstract
</p>
<p>Cet article pr&#233;sente une analyse d&#233;taill&#233;e des facteurs qui d&#233;terminent les performances des
approches de d&#233;sambigu&#239;sation d&#233;riv&#233;es de la m&#233;thode de Lesk (1986). Notre &#233;tude porte sur
une s&#233;rie d&#8217;exp&#233;riences concernant la m&#233;thode originelle de Lesk et des variantes que nous
avons adapt&#233;es aux caract&#233;ristiques de WORDNET. Les variantes impl&#233;ment&#233;es ont &#233;t&#233; &#233;valu&#233;es
sur le corpus de test de SENSEVAL2, English All Words, ainsi que sur des extraits du corpus
SEMCOR. Notre &#233;valuation se base d&#8217;un c&#244;t&#233;, sur le calcul de la pr&#233;cision et du rappel, selon
le mod&#232;le de SENSEVAL, et d&#8217;un autre c&#244;t&#233;, sur une taxonomie des r&#233;ponses qui permet de
mesurer la prise de risque d&#8217;un d&#233;cideur par rapport &#224; un syst&#232;me de r&#233;f&#233;rence.
</p>
<p>This paper deals with a detailed analysis of the factors determining the performances of Lesk-
based WSD methods. Our study consists in a series of experiments on the original Lesk algo-
rithm and on its variants that we adapted to WORDNET. These methods were evaluated on the
test corpus from SENSEVAL2, English All Words, and on excerpts from SEMCOR. The evalua-
tion metrics are based on precision and recall, as in SENSEVAL exercises, and on a new method
estimating the risk taken by each variant.
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>D&#233;sambigu&#239;sation s&#233;mantique, algorithme de Lesk, naive Bayes, WORDNET
Word sense desambiguation, Lesk&#8217;s algorithm, naive Bayes, WORDNET</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florentina Vasilescu, Philippe Langlais
</p>
<p>1 Introduction
</p>
<p>La d&#233;sambigu&#239;sation s&#233;mantique d&#8217;un texte consiste &#224; d&#233;terminer le sens correct des mots de ce
texte. Des campagnes d&#8217;&#233;valuation comme SENSEVAL sont la preuve du grand int&#233;r&#234;t port&#233; au
sein de notre communaut&#233; &#224; cette t&#226;che (90 &#233;quipes ont mentionn&#233; leur int&#233;r&#234;t &#224; participer &#224; la
prochaine campagne SENSEVAL3).
</p>
<p>Cet int&#233;r&#234;t se traduit par un foisonnement de m&#233;thodes et de ressources utilis&#233;es, comme par
exemple les dictionnaires, les th&#233;saurus ou les lexiques s&#233;mantiques &#233;lectroniques (Lesk, 1986;
Banerjee &amp; Pedersen, 2003), les corpus annot&#233;s, comportant des &#233;tiquettes de sens (voir par
exemple (Crestan et al., 2003)), les corpus non annot&#233;s (Yarowsky, 1995; Sch&#252;tze, 1998) ou
une combinaison de ces ressources (Stevenson &amp; Wilks, 2001).
</p>
<p>Malgr&#233; tous ces travaux, nous ne connaissons pas d&#8217;application r&#233;elle qui tire r&#233;ellement profit
de la d&#233;sambigu&#239;sation. C&#8217;est certes intuitivement une t&#226;che indispensable &#224; la bonne r&#233;alisation
de toutes les applications qui n&#233;cessitent un niveau de compr&#233;hension du message d&#8217;entr&#233;e (la
traduction automatique en t&#234;te), mais force est de constater que c&#8217;est une t&#226;che difficile que
nous ne ma&#238;trisons pas compl&#232;tement.
</p>
<p>L&#8217;absence de ressources &#233;tiquet&#233;es de qualit&#233; et en grande quantit&#233; est une explication souvent
avanc&#233;e pour rendre compte de cet &#233;chec. D&#8217;autres (e.g. (V&#233;ronis, 2001)) soulignent que la t&#226;che
sur laquelle les diff&#233;rents syst&#232;mes se comparent est mal d&#233;finie. Ils mentionnent en particulier
que le niveau de granularit&#233; de WORDNET, la ressource utilis&#233;e dans la campagne d&#8217;&#233;valuation
pass&#233;e, est souvent trop fine pour que m&#234;me des humains s&#8217;accordent sur la bonne &#233;tiquette &#224;
donner &#224; un mot.
</p>
<p>Dans ce contexte, nous avons d&#233;cid&#233; d&#8217;impl&#233;menter un algorithme de d&#233;sambigu&#239;sation simple
et tent&#233; de comprendre ses limites autrement qu&#8217;en analysant ses performances brutes en terme
de pr&#233;cision et de rappel. Le candidat qui nous a sembl&#233; le plus int&#233;ressant dans cette optique
exploratoire est l&#8217;algorithme propos&#233; par Lesk (1986) qui consiste &#224; compter le nombre de mots
communs entre les d&#233;finitions d&#8217;un mot (g&#233;n&#233;ralement trouv&#233;es dans un dictionnaire &#233;lectro-
nique) et les d&#233;finitions des mots de son contexte. Le sens retenu correspondant &#224; la d&#233;finition
pour laquelle on compte le plus grand nombre de mots communs avec le contexte. Cette id&#233;e
simple s&#8217;est av&#233;r&#233;e meilleure que bon nombre de techniques plus &#233;volu&#233;es dans le cadre de la
campagne SENSEVAL1.
</p>
<p>Nous avons test&#233; de nombreuses variantes de l&#8217;algorithme de Lesk adapt&#233;es &#224; WORDNET. Les
r&#233;sultats de ces variantes ont &#233;t&#233; compar&#233;s avec ceux d&#8217;une version Naive Bayes (qui peut elle-
m&#234;me &#234;tre d&#233;crite comme une variante de l&#8217;algorithme de Lesk). Nous r&#233;sumons en section 2
les variantes et les facteurs les plus saillants que nous avons &#233;tudi&#233;s.
</p>
<p>La performance obtenue par chaque variante n&#8217;&#233;tant pas l&#8217;objet principal de notre &#233;tude, nous
avons mis au point une taxonomie des r&#233;ponses que peuvent faire nos d&#233;cideurs et qui aide &#224;
mieux comprendre leur performance. Nous d&#233;crivons cette taxonomie en section 3 et d&#233;finissons
la notion de risque associ&#233;e &#224; un algorithme de d&#233;sambigu&#239;sation.
</p>
<p>Nous d&#233;crivons ensuite en 4 notre protocole exp&#233;rimental et analysons les performances de
chaque variante d&#233;crite. Nous discutons finalement nos r&#233;sultats en section 5.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;sambigu&#239;sation de corpus monolingues par des approches de type Lesk
</p>
<p>2 Algorithmes &#233;tudi&#233;s
</p>
<p>Les algorithmes que nous avons impl&#233;ment&#233;s s&#8217;appuient tous sur un mod&#232;le extr&#234;mement
simple d&#233;crit en pseudo-code en figure 1. Ce mod&#232;le prend en entr&#233;e un mot &#224; d&#233;sambigu&#239;ser
t ainsi qu&#8217;une liste (tri&#233;e en ordre d&#233;croissant de fr&#233;quence) de ses sens candidats et produit en
sortie le sens s&#233;lectionn&#233;. Toutes les variantes test&#233;es ici diff&#232;rent seulement par le choix associ&#233;
aux fonctions Score, Description et Contexte d&#233;crites dans les sections suivantes.
</p>
<p>Entr&#233;e:
t, un mot &#224; d&#233;sambigu&#239;ser
S = {s1, . . . , sN}, les sens candidats ordonn&#233;s en ordre d&#233;croissant de fr&#233;quence
</p>
<p>Sortie:
sens, l&#8217;indice dans S du sens retenu
</p>
<p>score &#8592; &#8722;&#8734;
sens &#8592; 1 //choix par d&#233;faut du sens le plus fr&#233;quent
C &#8592; Contexte(t) //contexte du mot cible
for all i &#8712; [1,N] do
D &#8592; Description(si) //description de si extraite de WORDNET
sup &#8592; 0
for all w &#8712; C do
W &#8592; Description(w) //description de w extraite de WORDNET
sup &#8592; sup + Score(D,W) //cumul des superpositions entre D et W
</p>
<p>if sup &gt; score then
score &#8592; sup
sens &#8592; i //on retient le sens de plus haut score
</p>
<p>FIG. 1 &#8211; Canevas des variantes &#233;tudi&#233;es. Les trois fonctions dont d&#233;pend ce mod&#232;le sont d&#233;crites
&#224; m&#234;me le texte.
</p>
<p>2.1 D&#233;finition du contexte
</p>
<p>La premi&#232;re des fonctions dont d&#233;pend le mod&#232;le de la figure 1 &#8212; Contexte(t) &#8212; d&#233;finit
l&#8217;ensemble des mots qui vont servir &#224; la d&#233;sambigu&#239;sation de t. Nous avons test&#233; deux impl&#233;-
mentations de cette fonction. La premi&#232;re &#8212; celle utilis&#233;e par d&#233;faut &#8212; consiste &#224; retourner
l&#8217;ensemble des mots pleins centr&#233;s autour du mot t. Nous rapportons les r&#233;sultats de nos va-
riantes en section 4 pour des longueurs de contexte de &#177;2 (les deux mots pleins directement
&#224; gauche et &#224; droite de t), &#177;3, &#177;8, &#177;10 et &#177;25 mots. Notons qu&#8217;Audibert (2003) sugg&#232;re
que choisir un contexte sym&#233;trique n&#8217;est pas optimal dans le cas des verbes. Il montre en effet
que l&#8217;information servant &#224; les d&#233;sambigu&#239;ser a tendance &#224; se trouver dans les compl&#233;ments
d&#8217;objets, et donc plut&#244;t &#224; droite des verbes. L&#8217;auteur sugg&#232;re pour cela d&#8217;utiliser un contexte
&lt; &#8722;2,+4 &gt;. Dans les m&#234;mes actes, Crestan et al. (2003) montrent qu&#8217;il est b&#233;n&#233;fique &#8212; du
moins pour certaines classes syntaxiques de mots &#8212; de mettre en &#339;uvre une proc&#233;dure auto-
matique de s&#233;lection du contexte.
</p>
<p>La seconde impl&#233;mentation de cette fonction, d&#233;not&#233;e CL, consiste &#224; extraire du contexte d&#8217;oc-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florentina Vasilescu, Philippe Langlais
</p>
<p>currence de t les mots constitutifs de ce que nous appelons apr&#232;s Hirst et St-Onge (1998) sa
cha&#238;ne lexicale. Dans une &#233;tude sur la correction des malapropismes (confusion de deux mots
comportant la m&#234;me prononciation ou des formes orthographiques tr&#232;s semblables mais des
sens diff&#233;rents), les auteurs s&#8217;appuient sur l&#8217;id&#233;e que pour rendre un discours coh&#233;rent, les mots
cooccurrant dans un m&#234;me contexte sont reli&#233;s entre eux par des relations de coh&#233;sion, formant
des encha&#238;nements logiques qu&#8217;ils baptisent cha&#238;nes lexicales.
</p>
<p>Nous avons adapt&#233; cette id&#233;e &#224; la d&#233;sambigu&#239;sation s&#233;mantique, en consid&#233;rant que la lev&#233;e de
l&#8217;ambigu&#239;t&#233; d&#8217;un mot peut se faire en d&#233;terminant la cha&#238;ne lexicale de ce mot. Seuls les mots
de cette cha&#238;ne sont alors retenus dans le contexte. Notre impl&#233;mentation utilise les relations
de synonymie et d&#8217;hyperonymie de WORDNET ainsi qu&#8217;une mesure de similarit&#233; entre deux
ensembles (nous avons utilis&#233; la formule de Jaccard) pour tester l&#8217;appartenance d&#8217;un mot du
contexte de t &#224; sa cha&#238;ne lexicale. Son principe consiste &#224; associer &#224; chaque mot w du contexte
l&#8217;ensemble E(w) des mots des synsets rencontr&#233;s en suivant les liens (jusqu&#8217;&#224; la racine) d&#8217;hy-
peronymie et de synonymie d&#233;finis dans WORDNET pour chaque sens de w. On d&#233;cide alors
que w appartient &#224; la cha&#238;ne lexicale de t si le score de Jaccard pour les deux ensembles E(w)
et E(t) est sup&#233;rieur &#224; un seuil fix&#233; empiriquement. Le r&#233;sultat de ce processus est illustr&#233; en
figure 2.
</p>
<p>Committee approval of Gov._Price_Daniel&#8217;s &#8220;abandoned property&#8221; act seemed cer-
tain Thursday despite the adamant protests of Texas bankers. Daniel perso-
nally led the fight for the measure, which he had watered_down considerably
since its rejection by two previous Legislatures, in a public hearing before the
House_Committee_on_Revenue_and_Taxation. Under committee rules, it went auto-
matically to a subcommittee for one week.
</p>
<p>&#8211; E(committee) = {committee, commission, citizens, administrative-unit, administrative-
body, organization, social-group, group, grouping}
</p>
<p>&#8211; E(legislature) = {legislature, legislative-assembly, general-assembly, law-makers, assem-
bly, gathering, assemblage, social-group, group, grouping}
</p>
<p>FIG. 2 &#8211; Illustration d&#8217;une cha&#238;ne lexicale. Les mots en gras forment la cha&#238;ne lexicale du mot
committee. E(committee) et E(legislature) sont les ensembles de mots obtenus en suivant les
relations de synonymie et d&#8217;hyperonymie dans WORDNET.
</p>
<p>2.2 Description associ&#233;e &#224; un mot
</p>
<p>L&#8217;algorithme de la figure 1 applique une fonction de score &#224; la repr&#233;sentation Description(w)
d&#8217;un mot w du contexte de t ainsi qu&#8217;&#224; celle d&#8217;un sens particulier st de t: Description(st). Dans
tous nos tests, l&#8217;entit&#233; descriptive d&#8217;un sens est repr&#233;sent&#233;e par un sac de mots, c&#8217;est-&#224;-dire un
ensemble de mots dont l&#8217;ordre et la d&#233;pendance sont ignor&#233;s. Cet ensemble contient seulement
des mots pleins (noms, verbes, adjectifs ou adverbes) dans leur forme canonique (lemme) et
l&#8217;entit&#233; descriptive associ&#233;e &#224; un mot est l&#8217;union des entit&#233;s descriptives de chacun des sens de
ce mot (Description(w) =
</p>
<p>&#8899;
s&#8712;Sens(w) Description(s) ; o&#249; Sens(w) est l&#8217;ensemble
</p>
<p>des sens de w selon WORDNET).
</p>
<p>Nous avons &#233;tudi&#233; trois variantes de la repr&#233;sentation d&#8217;un sens. La premi&#232;re, d&#233;not&#233;e DEF,</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;sambigu&#239;sation de corpus monolingues par des approches de type Lesk
</p>
<p>consiste &#224; ne conserver que les mots pleins de la d&#233;finition associ&#233;e au sens selon WORDNET1.
La deuxi&#232;me, not&#233;e REL, consiste &#224; regrouper les mots des synsets parcourus en suivant dans
WORDNET les relations de synonymie et d&#8217;hyperonymie (c&#8217;est comme cela qu&#8217;a &#233;t&#233; obtenue la
repr&#233;sentation E(committee) dans l&#8217;exemple de la figure 2). Une troisi&#232;me variante, DEF+REL,
consiste &#224; faire l&#8217;union des deux repr&#233;sentations pr&#233;c&#233;dentes.
</p>
<p>Une autre variante de la fonction Description permet d&#8217;impl&#233;menter la variante simplifi&#233;e
de Lesk propos&#233;e par Kilgarriff et Rosenzweig (2000). Cette variante consiste &#224; comptabiliser
les intersections entre l&#8217;entit&#233; descriptive d&#8217;un sens candidat et les mots du contexte de t (et
non plus leur d&#233;finition). Dans ce cas, la description associ&#233;e &#224; un mot du contexte est tr&#232;s
simple (Description(w) = {w}) ; la description d&#8217;un sens candidat n&#8217;est quant &#224; elle pas
chang&#233;e (DEF, REL, ou DEF+REL).
</p>
<p>2.3 Fonction de score
</p>
<p>Nous avons test&#233; de nombreuses variantes de la fonction de score Score(E1,E2) entre deux
entit&#233;s descriptives E1 et E2 dont les d&#233;tails et les performances peuvent &#234;tre lus dans (Vasi-
lescu, 2003). Nous d&#233;crivons ici les classes de variantes les plus saillantes qui sont toutes des
fonctions cumulatives du score de chaque intersection entre E1 et E2.
</p>
<p>La variante la plus simple, d&#233;sign&#233;e par LESK dans la suite, consiste &#224; donner &#224; chaque inter-
section le score unitaire. C&#8217;est le score qui correspond &#224; l&#8217;algorithme de Lesk.
</p>
<p>Une deuxi&#232;me classe de variantes d&#233;nomm&#233;e POND&#201;R&#201; suit la suggestion faite par (Lesk, 1986)
que le score devrait tenir compte de la taille de l&#8217;entr&#233;e du dictionnaire pour un sens donn&#233;
afin d&#8217;&#233;viter que les descriptions trop longues ne dominent le processus de prise de d&#233;cision
(plus une description est longue et plus les intersections sont probables). Le score associ&#233; &#224;
une intersection entre deux mots est donc normalis&#233; par l&#8217;inverse du logarithme de la taille
(compt&#233;e en mots) de la description du sens candidat. Nous avons &#233;tudi&#233; d&#8217;autres m&#233;canismes
de pond&#233;ration tenant par exemple compte de la distance du mot du contexte au mot cible, ou
encore de la fr&#233;quence d&#8217;occurrence dans la langue du mot du contexte sans obtenir de gain lors
de la d&#233;sambigu&#239;sation.
</p>
<p>La troisi&#232;me fonction de score utilis&#233;e, d&#233;sign&#233;e par BAYES, est sp&#233;cifique &#224; notre impl&#233;men-
tation naive Bayes qui s&#8217;inscrit &#233;galement dans le canevas de la figure 1. Une telle approche
s&#233;lectionne en effet parmi les sens candidats s du mot cible celui qui maximise la quantit&#233;
p(s|Contexte(t)) en faisant comme hypoth&#232;se que tous les mots du contexte sont ind&#233;pendants.
Pr&#233;cis&#233;ment, notre fonction de score est:
</p>
<p>log p(s) +
&#8721;
</p>
<p>w&#8712;Contexte(t)
log (&#955;p(w|s) + (1&#8722; &#955;)p(w))
</p>
<p>o&#249; les trois distributions p(s), p(w|s) et p(w) sont d&#233;termin&#233;es par fr&#233;quence relative &#224; partir
du corpus SEMCOR d&#233;crit bri&#232;vement dans la section 4.1. Le lissage de p(w|s) par un mod&#232;le
unigramme p(w) est ici n&#233;cessaire compte tenu de la forme tr&#232;s piqu&#233;e des distributions condi-
tionnelles (comme nous l&#8217;avons mentionn&#233; en introduction, les corpus &#233;tiquet&#233;s sont de petite
taille). Ce lissage est contr&#244;l&#233; par un unique param&#232;tre &#955; fix&#233; &#224; 0.95 dans nos exp&#233;riences.
</p>
<p>1Cette d&#233;finition peut contenir &#233;galement des exemples d&#8217;usage.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florentina Vasilescu, Philippe Langlais
</p>
<p>3 M&#233;triques d&#8217;&#233;valuation
</p>
<p>&#192; l&#8217;instar des campagnes SENSEVAL, nous mesurons les performances de nos diff&#233;rents d&#233;ci-
deurs &#224; l&#8217;aide des mesures classiques de pr&#233;cision et de rappel. La pr&#233;cision (resp. le rappel)
est le ratio du nombre de r&#233;ponses correctes fournies par le syst&#232;me sur le nombre de d&#233;ci-
sions faites (resp. &#224; prendre). Ces mesures ne permettent qu&#8217;indirectement d&#8217;appr&#233;cier le m&#233;rite
de chaque d&#233;cideur (au del&#224; du fait qu&#8217;un bon d&#233;cideur est celui pour lequel on mesure une
pr&#233;cision et un rappel &#233;lev&#233;). Aussi proposons-nous une taxonomie des r&#233;ponses faites par nos
algorithmes qui permet de comparer un d&#233;cideur &#224; un syst&#232;me de r&#233;f&#233;rence: ici le syst&#232;me BASE
qui retourne toujours le sens candidat le plus fr&#233;quent selon WORDNET.
</p>
<p>Cette taxonomie fait intervenir deux caract&#233;ristiques propres &#224; une r&#233;ponse, &#224; savoir sa cor-
rection (C=correcte, C = incorrecte) et son effectivit&#233; (E=effective, E = non effective) ainsi
que deux caract&#233;ristiques suppl&#233;mentaires li&#233;es &#224; la r&#233;ponse du syst&#232;me de r&#233;f&#233;rence (BASE)
qui peut &#234;tre juste (B) ou fausse (B) tout en &#233;tant &#233;gale (=) ou pas (&#4;=) &#224; la r&#233;ponse faite par le
syst&#232;me test&#233;. Nous qualifions une r&#233;ponse d&#8217;effective lorsqu&#8217;au moins une intersection a &#233;t&#233; ob-
serv&#233;e entre les repr&#233;sentations du contexte et la repr&#233;sentation du sens choisi (nous rappelons
qu&#8217;en cas de non d&#233;cision, le sens le plus fr&#233;quent selon WORDNET est toujours s&#233;lectionn&#233;).
En prenant comme syst&#232;me de r&#233;f&#233;rence le syst&#232;me BASE, nous obtenons une combinaison de
7 classes qui sont repr&#233;sent&#233;es en figure 3. Nous pouvons alors d&#233;finir deux types de risques.
</p>
<p>decision correcte ?
</p>
<p>BASE correcte ?
</p>
<p>oui non
</p>
<p>nonoui
</p>
<p>oui non oui oui non
</p>
<p>ovlps != 0 ? ovlps != 0 ?
</p>
<p>== BASE ? == BASE ? == BASE ? == BASE ?
</p>
<p>CE != B CE != B
</p>
<p>CE == BCE == BCE == B CE != B,B CE == B
</p>
<p>(C) (C)
</p>
<p>nonoui(E) (E)(E)(E)
</p>
<p>nonoui
(B) (B)
</p>
<p>R&#8722;
</p>
<p>R+
</p>
<p>oui
</p>
<p>FIG. 3 &#8211; Taxonomie des r&#233;ponses faites par un d&#233;cideur. La classe CE = B caract&#233;rise par
exemple les r&#233;ponses effectives correctes qui sont identiques au syst&#232;me de r&#233;f&#233;rence ; alors
que la classe CE &#4;= B d&#233;signe les r&#233;ponses effectives correctes diff&#233;rentes de la r&#233;ponse du
syst&#232;me de base qui elle est fausse. ovlps d&#233;signe le nombre de superpositions consid&#233;r&#233;es lors
de la prise de d&#233;cision.
</p>
<p>Le risque positif (R+) est donn&#233; par le nombre (CE &#4;= B,B) de d&#233;cisions effectives correctes,
diff&#233;rentes des d&#233;cisions de BASE. Le risque n&#233;gatif (R&#8722;) est le nombre (CE &#4;= B) de d&#233;ci-
sions effectives incorrectes, pour lesquelles le syst&#232;me de r&#233;f&#233;rence &#233;tait quant &#224; lui correct. Ces
deux quantit&#233;s sont normalis&#233;es par le nombre total de d&#233;cisions faites. La diff&#233;rence entre ces
deux mesures d&#233;termine ce que nous appelons le gain par rapport aux performances du syst&#232;me
de r&#233;f&#233;rence.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;sambigu&#239;sation de corpus monolingues par des approches de type Lesk
</p>
<p>4 Exp&#233;riences
</p>
<p>4.1 Protocole
</p>
<p>Nous avons utilis&#233; la version 1.7.1 de WORDNET pour obtenir les diff&#233;rents sens possibles de
chaque mot ainsi que les d&#233;finitions et les relations associ&#233;es &#224; chaque sens. Les mots &#224; d&#233;-
sambigu&#239;ser qui n&#8217;&#233;taient pas pr&#233;sents dans WORDNET (0.8% des instances) sont comptabilis&#233;s
comme des erreurs du d&#233;cideur test&#233;. C&#8217;est &#233;galement les informations fournies par WORDNET
qui nous permettent de classer les diff&#233;rents sens candidats entre eux (nous nous basons sur les
champs sense_number et tag_cnt de la table d&#8217;index de WORDNET).
</p>
<p>Nous avons de plus utilis&#233; la version 1.7.1 du corpus SEMCOR pour entra&#238;ner nos versions naive
Bayes. Dans le but de v&#233;rifier la stabilit&#233; de nos observations, nous avons test&#233; nos d&#233;cideurs
sur le corpus de test de la campagne SENSEVAL2 ainsi que sur diff&#233;rents jeux de test que nous
avons cr&#233;&#233;s &#224; partir du corpus SEMCOR (les approches naive Bayes entra&#238;n&#233;es sur ce m&#234;me
corpus n&#8217;ont cependant pas &#233;t&#233; test&#233;es sur ces jeux de test SEMCOR). Les r&#233;sultats que nous
rapportons ici sont ceux obtenus sur le premier corpus (nous laissons le soin au lecteur int&#233;ress&#233;
de lire les diff&#233;rences inter-corpus dans (Vasilescu, 2003)), car c&#8217;est le corpus qui sert de point de
comparaison dans la plupart des &#233;tudes en d&#233;sambigu&#239;sation (2473 mots cibles). Nous veillons
cependant dans notre discussion &#224; ne d&#233;gager que les tendances observ&#233;es sur l&#8217;ensemble de
nos jeux de test.
</p>
<p>Chaque d&#233;cideur avait &#224; charge de d&#233;sambigu&#239;ser l&#8217;ensemble des mots pleins du texte d&#8217;entr&#233;e
(les mots &#233;tiquet&#233;s head dans le corpus SENSEVAL2), ce que l&#8217;on d&#233;signe habituellement par la
piste English All Words.
</p>
<p>4.2 Performances
</p>
<p>4.2.1 Comparaison des diff&#233;rents d&#233;cideurs
</p>
<p>Le tableau 1 pr&#233;sente la pr&#233;cision et le rappel des d&#233;cideurs d&#233;crits dans la section 2 dans leur
version DEF. Plusieurs tendances se d&#233;gagent de ce tableau. En premier lieu, il convient de
noter que l&#8217;algorithme de Lesk dans sa formulation originelle (LESK) donne les moins bons
r&#233;sultats. En fait, les r&#233;sultats de ce d&#233;cideur sont de loin inf&#233;rieurs &#224; ceux obtenus en prenant
le sens le plus fr&#233;quent. Cette observation est cependant coh&#233;rente avec celles de Litkowski
(2002) o&#249; l&#8217;auteur analyse les diff&#233;rents facteurs responsables des performances de son syst&#232;me
&#224; SENSEVAL2 (CL Research - DIMAP, 29.3% de pr&#233;cision et rappel English lexical sample2). Il
fait en particulier l&#8217;observation que seulement 30% des instances &#224; d&#233;sambigu&#239;ser tiraient profit
de l&#8217;information de type Lesk (d&#233;finitions + exemples).
</p>
<p>Il est &#233;galement clair que la version simplifi&#233;e (SLESK) de cet algorithme donne de meilleurs
r&#233;sultats. Rappelons que la version simplifi&#233;e consiste a compter les intersections entre la des-
cription associ&#233;e &#224; chaque sens candidat et les mots du contexte eux-m&#234;me (et non leur descrip-
tion).
</p>
<p>Nous constatons que de pond&#233;rer le score par l&#8217;inverse de la longueur de la description, tel
que le sugg&#233;rait Lesk (1986) ne s&#8217;av&#232;re pas une strat&#233;gie payante, et ce aussi bien pour les
</p>
<p>2Voir le site www.cs.unt.edu/~rada/senseval.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florentina Vasilescu, Philippe Langlais
</p>
<p>P &#177;2 R P &#177;3 R P &#177;8 R P &#177;10 R P &#177;25 R
LESK 42.64 42.26 42.96 42.58 43.21 42.82 43.29 42.90 42.39 42.01
+ POND&#201;R&#201; 39.29 38.94 39.41 39.06 41.21 40.84 40.76 40.40 41.49 41.12
+ CL 58.38 57.86 58.22 57.70 56.18 55.68 55.65 55.16 53.90 53.42
</p>
<p>P &#177;2 R P &#177;3 R P &#177;8 R P &#177;10 R P &#177;25 R
SLESK 58.18 57.66 57.20 56.69 54.67 54.19 53.28 52.81 50.47 50.02
+ POND&#201;R&#201; 56.67 56.17 55.49 54.99 51.08 50.63 49.25 48.81 44.39 44.00
+ CL 59.08 58.55 59.12 58.59 58.43 57.91 58.26 57.74 57.41 56.89
</p>
<p>P &#177;2 R P &#177;3 R P &#177;8 R P &#177;10 R P &#177;25 R
BAYES 57.60 57.30 58.00 57.70 56.80 56.60 57.60 57.30 58.50 58.30
</p>
<p>TAB. 1 &#8211; Pr&#233;cision et rappel des diff&#233;rents d&#233;cideurs d&#233;crits dans leur variante DEF en fonction
de la taille du contexte. Le syst&#232;me BASE obtient une pr&#233;cision de 57.99 et un rappel de 57.62
(performance qui ne d&#233;pend d&#8217;aucun param&#232;tre).
</p>
<p>variantes LESK que SLESK. En revanche, le filtrage du contexte &#224; l&#8217;aide des cha&#238;nes lexicales
permet d&#8217;augmenter les performances de toutes les variantes test&#233;es. Ceci semble attester qu&#8217;il
n&#8217;est pas souhaitable de consid&#233;rer tous les mots lors d&#8217;une prise de d&#233;cision. Les am&#233;liorations
apport&#233;es par le filtre CL aux variantes LESK sont particuli&#232;rement marqu&#233;es. Il est toutefois
surprenant qu&#8217;un tel filtre porte ses fruits dans des contextes tr&#232;s resserr&#233;s autour du mot cible
(&#177;2). L&#8217;analyse que nous fournissons plus loin propose une explication des performances de
cette variante.
</p>
<p>Nous pouvons &#233;galement observer qu&#8217;&#224; l&#8217;exception des variantes LESK et BAYES, augmenter la
taille du contexte entra&#238;ne une d&#233;croissance des performances, ce qui appuie l&#8217;importance de la
s&#233;lection d&#8217;un bon contexte de d&#233;sambigu&#239;sation. Notons enfin que la meilleure des variantes
test&#233;es ici ne d&#233;passe pas de fa&#231;on tr&#232;s marqu&#233;e le syst&#232;me BASE.
</p>
<p>4.2.2 Choix de la description associ&#233;e &#224; un sens
</p>
<p>Il est difficile de d&#233;gager des conclusions claires quant &#224; l&#8217;influence du choix de la fonction
Description. Cependant la tendance la plus marqu&#233;e (et ce pour toutes les configurations
test&#233;es) est que pour un contexte tr&#232;s court (&#177;2), il est pr&#233;f&#233;rable de consid&#233;rer les mots de la
d&#233;finition des sens (DEF) que les relations (REL). Pour des contextes plus grands, il semble en
revanche que les relations donnent de meilleurs r&#233;sultats. Il est cependant difficile d&#8217;interpr&#233;ter
cette observation sans recourir &#224; une analyse plus pouss&#233;e.
</p>
<p>4.2.3 Analyse des r&#233;ponses
</p>
<p>La taxonomie que nous avons pr&#233;sent&#233;e en section 3 nous permet de comprendre davantage
les diff&#233;rentes variantes test&#233;es. Le tableau 2 reporte le risque positif (CE &#4;= B,B) et n&#233;gatif
(CE &#4;= B) des diff&#233;rentes variantes SLESK &#233;tudi&#233;es. Nous pouvons observer que, &#224; l&#8217;exception
des variantes CL, les d&#233;cideurs prennent plus de risque n&#233;gatif que positif, et ce d&#8217;autant plus
que le contexte est grand.
</p>
<p>Pour toutes les variantes test&#233;es, le taux des r&#233;ponses correctes diff&#233;rentes de BASE est tr&#232;s petit.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;sambigu&#239;sation de corpus monolingues par des approches de type Lesk
</p>
<p>&#177;2 &#177;3 &#177;8 &#177;10 &#177;25
R+ R- R+ R- R+ R- R+ R- R+ R-
</p>
<p>SLESK 3.5 3.3 3.9 4.7 6.0 9.3 6.5 11.2 7.8 15.3
+ POND&#201;R&#201; 3.5 4.8 3.9 6.4 5.9 12.8 6.4 15.2 7.8 21.3
+ CL 1.1 0.2 1.2 0.2 1.7 1.3 1.7 1.5 1.9 2.5
</p>
<p>TAB. 2 &#8211; Risque positif (R+) et n&#233;gatif (R-) des diff&#233;rentes variantes SLESK. Les mesures
rapport&#233;es en italique indiquent des gains n&#233;gatifs par rapport au syst&#232;me BASE.
</p>
<p>La majorit&#233; des r&#233;ponses correctes co&#239;ncide en fait avec les r&#233;ponses correctes de BASE ; soit
qu&#8217;elles sont prises par d&#233;faut en l&#8217;absence de superposition (CE = B, le cas le plus fr&#233;quent),
soit qu&#8217;elles sont produites par des d&#233;cisions effectives (CE = B). Dans le cas des variantes
CL, les r&#233;ponses correctes sont majoritairement des r&#233;ponses non effectives: cette variante doit
ses performances &#224; une strat&#233;gie silencieuse (quelques d&#233;cisions effectives prises &#224; bon escient,
la plupart &#233;tant des d&#233;cisions non effectives). Les autres variantes prennent quant &#224; elles plus
de risque et la proportion de bonnes r&#233;ponses effectives est donc plus grande. Elles co&#239;ncident
cependant majoritairement avec le choix du sens le plus fr&#233;quent.
</p>
<p>4.2.4 Filtrage par &#233;tiquetage morpho-syntaxique
</p>
<p>Nous avons &#233;tudi&#233; l&#8217;impact du filtrage des sens candidats &#224; l&#8217;aide de l&#8217;&#233;tiquette morpho-syntaxi-
que connue (APOS) ou estim&#233;e (RALI) du mot cible. Dans le second cas, nous avons fait usage
d&#8217;un &#233;tiqueteur d&#233;velopp&#233; au RALI ; un mod&#232;le markovien d&#8217;ordre 3 entra&#238;n&#233; sur le corpus
des d&#233;bats parlementaires canadiens. Soulignons que ce corpus est par nature tr&#232;s diff&#233;rent
du corpus de test de SENSEVAL2. L&#8217;&#233;tiquette &#233;tait utilis&#233;e comme filtre. Par exemple selon
WORDNET, le mot anglais house contient 12 sens en tant que nom et seulement 2 sens en tant
que verbe. Le fait de savoir (APOS) ou de croire (RALI) qu&#8217;on est par exemple en pr&#233;sence d&#8217;un
verbe permet de ne consid&#233;rer que 2 sens candidats. Les performances de cette approche sont
rapport&#233;es dans le tableau 3. Comme on peut le constater, la prise en compte de l&#8217;information
morpho-syntaxique (estim&#233;e ou connue) am&#233;liore les performances de l&#8217;approche de base (sens
le plus fr&#233;quent). Nous n&#8217;observons cependant pas de gain lorsque l&#8217;approche de base b&#233;n&#233;ficie
&#233;galement de cette information.
</p>
<p>APOS P R RALI P R P R
SLESK+ CL 61.9 61.3 60.5 59.9 59.1 58.6
BASE 61.9 61.3 60.4 59.9 57.9 57.6
</p>
<p>TAB. 3 &#8211; Pr&#233;cision et rappel de la meilleure variante test&#233;e lorsque la cat&#233;gorie morpho-
syntaxique du mot &#224; d&#233;sambigu&#239;ser est connue (APOS) ou estim&#233;e (RALI). La derni&#232;re colonne
rappelle les performances obtenues sans ce filtrage.
</p>
<p>5 Conclusion
</p>
<p>Nous avons fait l&#8217;&#233;tude de diff&#233;rentes variantes de l&#8217;algorithme de Lesk et tent&#233; d&#8217;analyser
leur performance gr&#226;ce &#224; une taxonomie des r&#233;ponses que nous avons d&#233;crite. Nos exp&#233;riences</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florentina Vasilescu, Philippe Langlais
</p>
<p>ont montr&#233; qu&#8217;en g&#233;n&#233;ral les performances diminuent avec l&#8217;&#233;largissement du contexte, les
meilleures performances &#233;tant enregistr&#233;es par des fen&#234;tres de 4 &#224; 6 mots pleins autour du mot
cible. Nous avons observ&#233; que filtrer les mots du contexte (ici par les cha&#238;nes lexicales) &#233;tait
b&#233;n&#233;fique (le d&#233;cideur prend moins de risque n&#233;gatif).
</p>
<p>La cat&#233;gorie grammaticale peut de plus agir comme un filtre qui r&#233;duit le nombre de sens
candidats possibles d&#8217;un mot cible. Les performances obtenues en se servant d&#8217;une &#233;tiquette
morpho-syntaxique estim&#233;e permettent de d&#233;passer le meilleur des d&#233;cideurs qui n&#8217;utilise pas
cette information. Rappelons que dans le cadre de SENSEVAL2 (English All Words), le meilleur
syst&#232;me supervis&#233; a obtenu une performance (pr&#233;cision et rappel) de 69% alors que le meilleur
syst&#232;me non supervis&#233; obtenait une pr&#233;cision de 57.5% et un rappel de 56.9%.
</p>
<p>Les tentatives ici d&#233;crites sugg&#232;rent que les mots des d&#233;finitions, des exemples d&#8217;usage et des
relations ne sont pas suffisants pour une bonne d&#233;sambigu&#239;sation. Ceci rejoint les observations
de V&#233;ronis (2001) qui souligne que les d&#233;finitions de WORDNET (et des dictionnaires en g&#233;n&#233;-
ral) ne fournissent pas toujours l&#8217;information n&#233;cessaire &#224; la d&#233;sambigu&#239;sation. L&#8217;ajout d&#8217;une
information de type syntaxique ou pragmatique reli&#233;e &#224; l&#8217;usage des mots dans des contextes
r&#233;els semble n&#233;cessaire &#224; ce type de t&#226;che.
</p>
<p>R&#233;f&#233;rences
</p>
<p>AUDIBERT L. (2003). &#201;tude des crit&#232;res de d&#233;sambig&#239;sation s&#233;mantique automatique: r&#233;sultats sur les
cooccurrences. In 10e conf&#233;rence TALN, p. 35&#8211;44, Batz-sur-mer, France.
</p>
<p>BANERJEE S. &amp; PEDERSEN T. (2003). Extended gloss overlaps as a measure of semantic related-
ness. In Eighteenth International Conference on Artificial Intelligence (IJCAI-03), p. 805&#8211;810, Aca-
pulco, Mexico.
</p>
<p>CRESTAN E., EL-B&#200;ZE M. &amp; DE LOUPY C. (2003). Peut-on trouver la taille de contexte optimale en
d&#233;sambigu&#239;sation s&#233;mantique ? In 10e conf&#233;rence TALN, p. 85&#8211;94, Batz-sur-mer, France.
</p>
<p>HIRST G. &amp; ST-ONGE D. (1998). Lexical chains as representation of context for the detection and
correction of malapropisms. In C. FELLBAUM, Ed., WordNet: An electronic lexical database and some
of its applications, p. 305&#8211;331. Cambrige, MA: The MIT Press.
</p>
<p>KILGARRIFF A. &amp; ROSENZWEIG J. (2000). Framework and results for English SENSEVAL. In Com-
puters and the Humanities, volume 34, p. 15&#8211;48. Kluwer.
</p>
<p>LESK M. (1986). Automatic sense disambiguation using machine readable dictionaries: How to tell a
pine cone from an ice cream cone. In The Fifth International Conference on Systems Documentation,
ACM SIGDOC.
</p>
<p>LITKOWSKI K. (2002). Sense information for disambiguation: Confluence of supervised and unsuper-
vised methods. In SIGLEX/Senseval Workshop on Word Sense Disambiguation: Recent Successes and
Future Directions, Philadelphia.
</p>
<p>SCH&#220;TZE H. (1998). Automatic word sense discrimination. Computational Linguistics, 24(1), 97&#8211;123.
</p>
<p>STEVENSON M. &amp; WILKS Y. (2001). The interaction of knowledge sources in word sense disambigua-
tion. Computational Linguistics, 27(3), 321&#8211;351.
</p>
<p>VASILESCU F. (2003). D&#233;sambigu&#239;sation de corpus monolingues par des approches de type Lesk. Mas-
ter&#8217;s thesis, Universit&#233; de Montr&#233;al.
</p>
<p>V&#201;RONIS J. (2001). Sense tagging: does it make sense ? In The Corpus Linguistics Conference, Lan-
caster, UK.
</p>
<p>YAROWSKY D. (1995). Unsupervised word sense disambiguation rivaling supervised methods. In 33rd
Meeting of the Association for Computational Linguistics, p. 189&#8211;196.</p>

</div></div>
</body></html>