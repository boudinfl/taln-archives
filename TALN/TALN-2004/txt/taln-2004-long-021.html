<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Densit&#233; d'information syntaxique et gradient de grammaticalit&#233;</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2004, F&#232;s, 19-21 avril 2004 
</p>
<p>Densit&#233; d'information syntaxique et gradient de grammaticalit&#233; 
</p>
<p>Philippe Blache 
</p>
<p>Laboratoire Parole et Langage 
CNRS &#8211; Universit&#233; de Provence 
</p>
<p>29, Avenue Robert Schuman 
13621 Aix-en-Provence 
</p>
<p>pb@lpl.univ-aix.fr 
</p>
<p>R&#233;sum&#233; &#8211; Abstract 
</p>
<p>Cet article propose l'introduction d'une notion de densit&#233; syntaxique permettant de caract&#233;riser la 
complexit&#233; d'un &#233;nonc&#233; et au-del&#224; d'introduire la sp&#233;cification d'un gradient de grammaticalit&#233;. Un tel 
gradient s'av&#232;re utile dans plusieurs cas : quantification de la difficult&#233; d'interpr&#233;tation d'une phrase, 
gradation de la quantit&#233; d'information syntaxique contenue dans un &#233;nonc&#233;, explication de la 
variabilit&#233; et la d&#233;pendances entre les domaines linguistiques, etc. Cette notion exploite la possibilit&#233; 
de caract&#233;risation fine de l'information syntaxique en termes de contraintes : la densit&#233; est fonction des 
contraintes satisfaites par une r&#233;alisation pour une grammaire donn&#233;e. Les r&#233;sultats de l'application de 
cette notion &#224; quelques corpus sont analys&#233;s. 
 
This paper introduces the notion of syntactic density that makes it possible to characterize the 
complexity of an utterance and to specify a gradient of grammaticality. Such a gradient is useful in 
several cases: quantification of the difficulty of interpreting an utterance, quantification of syntactic 
information of an utterance, description of variability and linguistic domains interaction, etc. This 
notion exploits the possibility of fine syntactic characterization in terms of constraints: density if 
function of satisfied constraints by an utterance for a given grammar. Some results are presented and 
analyzed. 
</p>
<p>Keywords &#8211; Mots Cl&#233;s 
</p>
<p>Syntaxe, analyse, robustesse, contraintes, information linguistique, complexit&#233; syntaxique. 
Syntax, parsing, robustness, constraints, linguistic information, syntactic complexity. 
 
</p>
<p>1 Introduction 
</p>
<p>Certains ph&#233;nom&#232;nes linguistiques, certaines constructions sont caract&#233;ris&#233;es par des 
propri&#233;t&#233;s tr&#232;s marqu&#233;es, facilement identifiables. C'est le cas par exemple de la syntaxe pour 
laquelle des propri&#233;t&#233;s de forme, d'ordre ou de rection permettent de caract&#233;riser des 
constructions comme les cliv&#233;es. Il est alors possible de d&#233;crire avec une grande pr&#233;cision de 
telles constructions, mais &#233;galement de les interpr&#233;ter facilement. Les cliv&#233;es sont en effet 
souvent simples &#224; interpr&#233;ter m&#234;me si leur repr&#233;sentation formelle et leur analyse automatique 
est complexe. Il n'y a en g&#233;n&#233;ral que peu d'ambigu&#239;t&#233; pour ce type de construction. A </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Blache 
</p>
<p>l'inverse, il existe d'autres types de constructions, comme les dislocations qui, m&#234;me si elles 
sont identifiables, pr&#233;sentent quelquefois plus de probl&#232;mes pour leur interpr&#233;tation. 
 
Il est tr&#232;s difficile de fournir une explication &#224; cette diff&#233;rence de fonctionnement si l'on s'en 
tient au niveau global de la construction. Il n'est en effet pas possible de dire que les cliv&#233;es 
sont plus faciles &#224; interpr&#233;ter que les disloqu&#233;es, d'une fa&#231;on g&#233;n&#233;rale, sans en fournir de 
raison. La liste des constituants de chacune de ces constructions pas plus que leur position 
dans la structure syntaxique ne nous fournit d'indication sur cette difficult&#233; d'interpr&#233;tation ou 
la potentialit&#233; d'ambigu&#239;t&#233;. La notion de complexit&#233; en syntaxe ou de difficult&#233; d'analyse reste 
encore aujourd'hui un probl&#232;me difficile &#224; d&#233;crire. Certains travaux en psycholinguistique &#224; ce 
sujet tentent de fournir des explications en termes de distance (cf. en particulier [Gibson00]), 
mais sans rendre compte des diff&#233;rences tr&#232;s importantes &#224; l'int&#233;rieur d'une m&#234;me 
construction. Or, &#224; un niveau d'analyse fin, il est possible d'identifier des diff&#233;rences ou du 
moins de fournir quelques caract&#233;ristiques plus r&#233;guli&#232;res pouvant servir d'&#233;l&#233;ment de r&#233;ponse 
&#224; ce probl&#232;me. Il faut pour cela dissocier l'information syntaxique et tenter d'en caract&#233;riser 
plus finement ses propri&#233;t&#233;s. Il devient ainsi possible non seulement d'indiquer quelles sont 
les propri&#233;t&#233;s d'ordre purement syntaxique de la construction (par exemple l'ordre, la 
restriction de cooccurrence ou l'accord), mais &#233;galement d'indiquer des caract&#233;ristiques 
g&#233;n&#233;rales concernant notamment la quantit&#233; d'information syntaxique, son importance, sa 
fiabilit&#233;, etc. Dans certains cas, l'analyse permet de fournir un grand nombre d'informations 
sur les objets linguistiques (par exemple les cat&#233;gories) formant une construction. Dans 
d'autres, ces informations sont au contraire plus rares. Il est alors possible de penser que dans 
les cas o&#249; l'information est rare ou peu &quot;importante&quot;, l'interpr&#233;tation de la construction sera 
plus difficile que dans ceux o&#249; l'information est abondante et fiable. Cette question est au 
coeur de certaines approches comme les grammaires de construction (cf. [Fillmore93] ou 
[Goldberg95]) qui proposent une description exploitant en m&#234;me temps diff&#233;rentes 
informations provenant de diff&#233;rents domaines linguistiques. Nous proposons dans cet article 
d'introduire dans la description une notion de densit&#233; d'information. Celle-ci ne tient pas 
compte du contenu informationnel port&#233; par la syntaxe mais de sa forme. Il est ainsi possible 
de fournir un &#233;l&#233;ment d'information quantifi&#233;e propre &#224; une construction et donnant des 
indications sur son interpr&#233;tabilit&#233;. Les constructions &#224; forte densit&#233; syntaxique seraient ainsi 
plus faciles &#224; interpr&#233;ter que celles &#224; faible densit&#233;. L'id&#233;e que la quantit&#233; d'information 
facilite l'analyse au lieu de la complexifier est d&#233;crite par exemple dans [Vasishth03]. Nous 
proposons ici de quantifier cette donn&#233;e. 
 
Ce type d'approche pr&#233;sente un triple int&#233;r&#234;t descriptif, cognitif et computationnel. Il devient 
en effet possible de fournir des indications sur la complexit&#233; syntaxique d'une construction 
non plus par les seules relations syntaxiques entrant en jeu, mais &#233;galement par une &#233;valuation 
de leur importance, notamment du point de vue quantitatif. De plus, la densit&#233; permet de 
fournir un &#233;l&#233;ment de r&#233;ponse &#224; des questions d'ordre psycholinguistique comme les 
pr&#233;f&#233;rences ou les difficult&#233;s d'interpr&#233;tation. Enfin, du point de vue du traitement 
automatique, la densit&#233; constitue un crit&#232;re pr&#233;cieux pour identifier des zones o&#249; la quantit&#233; 
d'information est plus abondante et plus riche. Ce type de crit&#232;re peut &#234;tre utile par exemple 
dans la recherche d'information, le typage de document ou l'analyse de sa structure discursive. 
Inversement, le rep&#233;rage d'une faible densit&#233; permet, par exemple dans le cas de syst&#232;mes de 
traitement de langue parl&#233;e, d'identifier les cas o&#249; des heuristiques particuli&#232;res devront &#234;tre 
appliqu&#233;es pour permettre l'interpr&#233;tation. 
 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Densit&#233; syntaxique &amp; gradient de grammaticalit&#233; 
</p>
<p>2 La nature de l'information syntaxique 
</p>
<p> 
Plusieurs approches en syntaxe tentent aujourd'hui de se d&#233;marquer du cadre g&#233;n&#233;ratif pour 
proposer une vision de l'analyse plus souple et permettant de s'adapter &#224; la r&#233;alit&#233; des donn&#233;es 
langagi&#232;res. La forme des &#233;nonc&#233;s que nous sommes amen&#233;s &#224; traiter ainsi que les processus 
d'&#233;laboration du contenu informatif montrent en effet que l'information linguistique est 
dispers&#233;e et instable. Dans cette perspective, la vision propos&#233;e par les th&#233;ories g&#233;n&#233;ratives 
stipulant que la langue est un ensemble et la grammaire un processus permettant 
l'&#233;num&#233;ration de cet ensemble n'est pas adapt&#233;e : la question fondamentale n'est en effet pas 
de savoir si un &#233;nonc&#233; appartient ou non &#224; une langue mais bien d'extraire l'information de cet 
&#233;nonc&#233;, quelle que soit sa forme. Dans certains cas, il est ainsi possible d'associer &#224; l'&#233;nonc&#233; 
analys&#233; une structure syntaxique le d&#233;crivant en totalit&#233;. Cependant, dans de tr&#232;s nombreux 
cas, une telle structure n'est pas calculable. De plus la granularit&#233; de l'information obtenue 
dans ce type de d&#233;marche est homog&#232;ne: tous les composants de la structure sont de m&#234;me 
niveau. Or, dans de nombreux cas, seules des informations tr&#232;s partielles peuvent &#234;tre 
obtenues. C'est le cas de l'exemple (1), tir&#233; de [Mertens93], dans lequel seules quelques 
indications sont accessibles : 
 
</p>
<p>(1) lundi lavage mardi repassage mercredi repos 
 
Cet exemple illustre une construction courante, pas seulement en langue parl&#233;e, dans laquelle 
la relation entre les &#233;l&#233;ments est fournie notamment par la r&#233;p&#233;tition d'un sch&#233;ma. La prosodie 
sera dans ce cas d'une grande importance, nous y reviendrons. Pour ce qui concerne le seul 
niveau syntaxique, nous avons donc une r&#233;p&#233;tition de la s&#233;quence N1[temporel] &lt; 
N2[action]. La morphologie et l'ordre lin&#233;aire sont les seules caract&#233;ristiques de cette 
construction. Une analyse syntaxique &#224; proprement parler n'est pas possible dans la mesure o&#249; 
aucune relation particuli&#232;re en dehors de la lin&#233;arit&#233; ne relie les objets de l'&#233;nonc&#233;. Il est en 
revanche indispensable de sp&#233;cifier les informations accessibles de fa&#231;on &#224; permettre 
l'interpr&#233;tation. Dans l'exemple (2), nous retrouvons un probl&#232;me similaire, m&#234;me si plus 
d'informations syntaxiques sont accessibles. 
 
</p>
<p>(2) Marie, je la supporte pas 
 
Dans ce cas, l'&#233;nonc&#233; n'est pas interpr&#233;table sur la base des seules informations syntaxiques 
dans la mesure o&#249; la relation entre le premier nom et le reste de l'&#233;nonc&#233; n'est pas sp&#233;cifi&#233;e. 
Plus pr&#233;cis&#233;ment, deux interpr&#233;tations sont possibles : la premi&#232;re en disloqu&#233;e, avec une 
cor&#233;f&#233;rence entre le nom et le clitique, et la seconde en vocatif, sans cor&#233;f&#233;rence. La prosodie 
dans ce cas jouera un r&#244;le d&#233;terminant (cf. [Blache03]). Cet exemple illustre le cas o&#249; le 
domaine syntaxique n'apporte pas suffisamment d'information permettant &#224; lui seul 
l'interpr&#233;tation. 
 
D'une fa&#231;on g&#233;n&#233;rale, ces exemples illustrent d'une part la n&#233;cessit&#233; de repr&#233;senter tout type 
d'information syntaxique, y compris en l'absence de v&#233;ritable relation, et d'autre part l'int&#233;r&#234;t 
de tenter de quantifier cette information. Dans certains cas, l'information syntaxique est en 
effet plus marqu&#233;e, plus forte, plus dense que dans d'autres. Nous proposons dans le reste de 
cet article une d&#233;finition de cette notion de densit&#233; s'appuyant sur une repr&#233;sentation 
d&#233;centralis&#233;e de l'information. Dans la prochaine section, nous rappellerons rapidement les 
principales caract&#233;ristiques des Grammaires de Propri&#233;t&#233;s permettant une repr&#233;sentation de </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Blache 
</p>
<p>l'information syntaxique &#224; granularit&#233; variable. Nous proposerons ensuite une sp&#233;cification de 
la densit&#233; en fournissant des exemples tir&#233;s de corpus. 
 
</p>
<p>3 Une repr&#233;sentation d&#233;centralis&#233;e de l'information : les 
Grammaires de Propri&#233;t&#233;s 
</p>
<p> 
Une approche permettant la repr&#233;sentation de l'information linguistique telle que nous l'avons 
d&#233;crite, &#224; savoir instable et dispers&#233;e, doit s'appuyer sur une conception non holistique de 
cette information (cf. [Pullum03]). En d'autres termes chaque type d'information doit &#234;tre 
repr&#233;sent&#233; s&#233;par&#233;ment et surtout pouvoir &#234;tre &#233;valu&#233;e s&#233;par&#233;ment. A la diff&#233;rence des r&#232;gles 
syntagmatiques dans les approches g&#233;n&#233;ratives qui n'ont de valeur que situ&#233;es dans un 
processus de d&#233;rivation g&#233;n&#233;ral (donc dans une structure g&#233;n&#233;rale), &#224; la diff&#233;rence &#233;galement 
de la th&#233;orie de l'optimalit&#233; (cf. [Prince93]) dans laquelle une contrainte n'a de signification 
que par rapport aux autres, les propri&#233;t&#233;s syntaxiques doivent pouvoir &#234;tre interpr&#233;t&#233;es 
ind&#233;pendamment des autres propri&#233;t&#233;s. 
 
C'est sur ce principe que reposent les Grammaires de Propri&#233;t&#233;s (cf. [Blache01]). Celles-ci 
distinguent plusieurs types de propri&#233;t&#233;s syntaxiques, sans relation hi&#233;rarchique : aucun ordre 
d'&#233;valuation n'est impos&#233; et chaque propri&#233;t&#233; repr&#233;sente une information homog&#232;ne. La 
description de la structure syntaxique d'un &#233;nonc&#233; est constitu&#233;e par l'ensemble des propri&#233;t&#233;s 
qui peuvent &#234;tre &#233;valu&#233;es. Le tableau suivant r&#233;capitule les types de propri&#233;t&#233;s syntaxiques 
actuellement utilis&#233;es dans les grammaires de propri&#233;t&#233;s, de nouvelles propri&#233;t&#233;s pouvant 
&#233;ventuellement &#234;tre ajout&#233;es (il se peut par exemple qu'une propri&#233;t&#233; de contigu&#239;t&#233; soit utile).  
 
</p>
<p>Propri&#233;t&#233; Definition 
Lin&#233;arit&#233; (&lt;) Contraintes de pr&#233;c&#233;dence lin&#233;aire 
</p>
<p>D&#233;pendance (o) Relations de d&#233;pendance 
Obligation (Oblig) Ensemble des cat&#233;gories obligatoires. Une de ces cat&#233;gories et une seule 
</p>
<p>doit &#234;tre r&#233;alis&#233;e dans un syntagme 
</p>
<p>Exclusion (&#143;) Restriction de cooccurrence entre ensembles de cat&#233;gories 
Exigence (&#159;) Obligation de cooccurrence entre ensembles de cat&#233;gories 
Unicit&#233; (Unic) Cat&#233;gories ne pouvant &#234;tre r&#233;p&#233;t&#233;es dans un syntagme 
</p>
<p> 
</p>
<p>Une propri&#233;t&#233; est une contrainte repr&#233;sentant une information sp&#233;cifique d'une cat&#233;gorie. La 
grammaire est un ensemble de contraintes de ce type et chaque cat&#233;gorie de la grammaire est 
d&#233;crite par un sous-ensemble de ces contraintes. Certaines de ces contraintes sont 
caract&#233;ristiques d'une cat&#233;gorie et permettront pendant l'analyse de l'instancier. Une analyse 
consiste, pour un &#233;nonc&#233; donn&#233;, &#224; &#233;valuer l'ensemble des contraintes. A chaque cat&#233;gorie sera 
associ&#233; l'ensemble des contraintes que sa r&#233;alisation satisfait ainsi que celles qu'elle ne 
satisfait pas. Ces deux ensembles forment la caract&#233;risation de la cat&#233;gorie. Une telle 
approche permet donc d'associer une caract&#233;risation &#224; une cat&#233;gorie, quelle que soit la forme 
de sa r&#233;alisation. Dans les cas o&#249; toutes les contraintes sont satisfaites, la cat&#233;gorie est 
grammaticale, mais ceci ne lui conf&#232;re aucun statut particulier. Le fait que des contraintes ne 
soient pas satisfaites n'emp&#234;che en effet pas l'utilisation de la cat&#233;gorie correspondante. De 
plus, nous disposons alors d'une approche permettant de sp&#233;cifier un gradient de 
grammaticalit&#233;. 
 
Plusieurs analyseurs de grammaire de propri&#233;t&#233;s ont &#233;t&#233; d&#233;velopp&#233;s (cf. [Blache02]). Nous 
pr&#233;sentons rapidement les caract&#233;ristiques principales de l'analyseur utilis&#233; pour les 
exp&#233;rimentations d&#233;crites plus loin. Le sch&#233;ma g&#233;n&#233;ral de l'analyse en GP consiste, pour un </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Densit&#233; syntaxique &amp; gradient de grammaticalit&#233; 
</p>
<p>ensemble donn&#233; de cat&#233;gories (on parle d'affectation) &#224; d&#233;terminer sa caract&#233;risation. Pour 
cela, l'ensemble des contraintes de la grammaire est activ&#233;, un sous-ensemble d'entre elles 
sont &#233;valuables et permettent de commencer &#224; construire une caract&#233;risation. Celle-ci, form&#233;e 
de contraintes satisfaites et non satisfaites, est analys&#233;e et en cas de pr&#233;sence de contraintes 
caract&#233;ristiques, la cat&#233;gorie correspondante est instanci&#233;e. Chaque nouvelle cat&#233;gorie 
instanci&#233;e est alors disponible pour participer &#224; une nouvelle affectation qui sera &#224; son tour 
&#233;valu&#233;e. Le syst&#232;me construit donc de fa&#231;on incr&#233;mentale les affectations (ces ensembles de 
cat&#233;gories) qui servent de base &#224; la construction des caract&#233;risations. Le sch&#233;ma g&#233;n&#233;ral de 
l'analyse se pr&#233;sente comme suit : 
 
</p>
<p>1. Construction d'une affectation A (choix d'un ensemble de cat&#233;gories) 
2. Evaluation de la satisfaisabilit&#233; de A parmi l'ensemble total de contraintes 
3. Analyse de la caract&#233;risation de A, instanciation de la cat&#233;gorie syntagmatique 
</p>
<p>correspondante 
 
</p>
<p>La caract&#233;risation, au coeur de l'analyse en GP, est un m&#233;canisme de satisfaction de 
contraintes. Il est possible d'en r&#233;gler le niveau de relaxation en autorisant ou non la violation 
de contrainte. Dans le cas o&#249; toutes les contraintes doivent &#234;tre satisfaites, seules des 
cat&#233;gories grammaticales sont construites. Cependant, une telle approche n'est pas adapt&#233;e &#224; 
la r&#233;alit&#233;, en particulier pour de l'analyse de textes tout-venant. Dans l'analyseur utilis&#233; ici, 
nous avons choisi de rel&#226;cher la satisfaisabilit&#233; des contraintes de d&#233;pendance, d'exigence et 
d'obligation, ces propri&#233;t&#233;s &#233;tant d'une part les moins filtrantes et d'autre part celles dont la 
satisfaisabilit&#233; peut varier en compl&#233;tant l'affectation initiale (cf. [Dahl04]). Cette strat&#233;gie 
permet de d&#233;velopper un analyseur d&#233;terministe mais tol&#233;rant. 
 
L'exemple suivant montre la caract&#233;risation d'une cat&#233;gorie (la relative &quot;qu'ils chassaient &#224; 
cheval&quot;) comportant l'indication de ses bornes dans l'&#233;nonc&#233; analys&#233;, son statut de 
grammaticalit&#233;, son affectation et sa caract&#233;risation &#224; proprement parler. Celle-ci indique par 
exemple le respect des propri&#233;t&#233;s de lin&#233;arit&#233;, de l'obligation de r&#233;alisation d'un SV avec un 
relatif sujet ou encore l'unicit&#233; de ses constituants.  
 
</p>
<p>Cat&#233;gorie Gauche Droite Affectation Caract&#233;risation 
Rel 53 57 ProR:qu; SN:sujet; SV ProR&lt;SN; ProR&lt;SV; SN&lt;SV  
</p>
<p>ProR[suj]=&gt;SV;  
</p>
<p>SN-&gt;SV; SV-&gt;ProR  
</p>
<p>Oblig:ProR  
</p>
<p>Unic = {ProR, SN, SV} 
</p>
<p> 
</p>
<p>4 La densit&#233; d'information 
</p>
<p>Nous avons vu dans la section pr&#233;c&#233;dente comment caract&#233;riser une cat&#233;gorie par l'ensemble 
des propri&#233;t&#233;s &#233;valuables parmi celles qui la d&#233;crivent potentiellement. Le nombre de 
propri&#233;t&#233;s &#233;valu&#233;es par rapport aux propri&#233;t&#233;s d&#233;crivant la cat&#233;gorie est int&#233;ressant et 
constitue un premier indice de la &quot;qualit&#233;&quot; de l'information. Plus pr&#233;cis&#233;ment, le nombre de 
propri&#233;t&#233;s satisfaites par rapport au nombre total de propri&#233;t&#233;s d&#233;crivant cette cat&#233;gorie dans 
la grammaire (not&#233; dens_sat) nous fournit une indication brute sur la quantit&#233; d'information 
syntaxique contenue dans la cat&#233;gorie. L'hypoth&#232;se &#233;mise est que plus nous disposons 
d'informations au niveau syntaxique, plus la cat&#233;gorie construite est fiable. Dans les cas o&#249; 
dens_sat est faible, dans la mesure o&#249; peu de propri&#233;t&#233;s ont &#233;t&#233; satisfaites, la cat&#233;gorie 
caract&#233;ris&#233;e le sera de fa&#231;on moins fiable que pour une cat&#233;gorie ayant un rapport &#233;lev&#233;. La </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Blache 
</p>
<p>fiabilit&#233; constitue donc un outil permettant de classer des r&#233;alisations de cat&#233;gories : les 
cat&#233;gories tr&#232;s fiables satisfont plus de contraintes que celles qui le sont moins. En d'autres 
termes, ce rapport repr&#233;sente un &#233;l&#233;ment d'information sur la grammaticalit&#233; de la cat&#233;gorie. 
Si nous disposons simultan&#233;ment de l'&#233;valuation des propri&#233;t&#233;s satisfaites et des propri&#233;t&#233;s 
non satisfaites par rapport au nombre total de propri&#233;t&#233;s, ce degr&#233; de grammaticalit&#233; devient 
alors tr&#232;s pr&#233;cis. De plus, nous pensons que la fiabilit&#233; syntaxique constitue &#233;galement une 
facilitation pour l'interpr&#233;tation. Une cat&#233;gorie tr&#232;s fiable sera plus facilement interpr&#233;table &#224; 
l'aide des seules informations syntaxiques qu'une cat&#233;gorie non fiable. 
 
Dans la version de l'analyseur GP pr&#233;sent&#233;e plus haut, l'information de fiabilit&#233;, ou indication 
de densit&#233;, est associ&#233;e &#224; toute cat&#233;gorie construite. Cet analyseur &#233;tant d&#233;terministe, le seuil 
de tol&#233;rance de non satisfaction de propri&#233;t&#233; est tr&#232;s bas. Le rapport des propri&#233;t&#233;s non 
satisfaites sur le nombre de propri&#233;t&#233;, malgr&#233; son importance, n'est donc pas retenu ici. Seule 
la densit&#233; des propri&#233;t&#233;s satisfaites est utilis&#233;e. Cette information est malgr&#233; tout int&#233;ressante 
et permet de distinguer plusieurs types de constructions. L'exemple suivant fournit le type 
d'indications caract&#233;risant une cat&#233;gorie. En plus des informations donn&#233;es plus haut, nous 
trouvons donc les indications de densit&#233; sous la forme des deux rapports suivants : 
 
</p>
<p>x dens_sat = nb propri&#233;t&#233;s satisfaites / nb total de propri&#233;t&#233;s  
x dens_unsat = nb propri&#233;t&#233;s non satisfaites / nb total de propri&#233;t&#233;s 
</p>
<p> 
</p>
<p>Rappelons que parmi toutes les propri&#233;t&#233;s d&#233;crivant une cat&#233;gorie dans la grammaire, pour 
une r&#233;alisation donn&#233;e, seul un sous-ensemble des ces propri&#233;t&#233;s est &#233;valuable. Par exemple, 
pour un SN form&#233; de /Det N/, toutes les propri&#233;t&#233;s mettant en jeu d'autres cat&#233;gories ne sont 
pas &#233;valuables. La somme des deux densit&#233;s n'est donc pas &#233;gale &#224; 1, ce qui justifie 
l'utilisation de ces deux rapports.  
 
</p>
<p>Cat&#233;gorie Gauche Droite Statut Dens_Sat Dens_Unsat Affectation 
</p>
<p>P 0 24 Vrai 0,375 0,125 SP; SN 
</p>
<p> 
</p>
<p>Dans cet exemple, la cat&#233;gorie P est form&#233;e d'un SP et d'un SN. La grammaire utilis&#233;e stipule 
une relation de d&#233;pendance entre un SN et un SV, expliquant la pr&#233;sence d'une densit&#233; non 
nulle pour les propri&#233;t&#233;s non satisfaites. La densit&#233; relativement faible de propri&#233;t&#233;s satisfaites 
s'explique par le fait qu'une proportion importante des propri&#233;t&#233;s d&#233;crivant la cat&#233;gorie P met 
en jeu le SV. 
 
Un des enjeux des approches formelles de la syntaxe est la capacit&#233; &#224; prendre en compte tout 
type d'&#233;nonc&#233;. Il est cependant n&#233;cessaire de distinguer un gradient de grammaticalit&#233; 
permettant d'indiquer en quelque sorte le niveau de bonne formation d'un &#233;nonc&#233; relativement 
&#224; une grammaire. Une telle approche permet de n'exclure a priori aucune production et offre 
l'avantage de fournir une caract&#233;risation, quelle que soit la forme de l'&#233;nonc&#233; analys&#233;. La 
question de la grammaticalit&#233; n'est ainsi plus un probl&#232;me de d&#233;cision (oui ou non l'&#233;nonc&#233; 
appartient-il &#224; la langue) mais un probl&#232;me de description pur. La densit&#233; joue alors 
parfaitement ce r&#244;le d'indicateur pour le gradient de grammaticalit&#233;. La notion de gradient 
prend toute son importance lorsqu'on aborde la question de l'interaction entre les diff&#233;rents 
domaines de l'information linguistique. Il est en effet n&#233;cessaire d'une part d'expliquer 
comment ces domaines interagissent entre eux, mais &#233;galement de tenter de comprendre 
pourquoi, dans certains cas, l'interaction est n&#233;cessaire plus que dans d'autres. L'hypoth&#232;se 
que nous avons expos&#233;e dans [Blache02] et [Blache03], est qu'il existe un seuil d'information 
n&#233;cessaire au-del&#224; duquel l'interpr&#233;tation d'un &#233;nonc&#233; devient possible. Ce seuil est atteint par 
le cumul des informations provenant des diff&#233;rents domaines. Un domaine peut &#224; lui seul </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Densit&#233; syntaxique &amp; gradient de grammaticalit&#233; 
</p>
<p>contenir suffisamment d'information et dans ce cas, les autres domaines deviennent en 
quelque sorte moins importants. Nous expliquons de cette fa&#231;on la variabilit&#233; plus ou moins 
grande de tel ou tel domaine en fonction du type de construction. Par exemple, si les 
informations morpho-syntaxiques sont suffisamment importantes, la prosodie aura une 
possibilit&#233; de variabilit&#233; plus grande. Inversement, lorsque la prosodie est caract&#233;ristique 
d'une construction (par exemple un contour ascendant caract&#233;ristique de l'interrogation), la 
syntaxe sera plus variable, ce qui explique la possibilit&#233; en fran&#231;ais de construire une tournure 
interrogative avec une forme syntaxique de surface affirmative. De m&#234;me, dans l'exemple (1) 
cit&#233; plus haut, la densit&#233; des relations syntaxiques est faible et l'interpr&#233;tation est rendue 
possible par l'identification de la r&#233;p&#233;tition d'un sch&#233;ma lexical renforc&#233; par la structure 
prosodique. Plus g&#233;n&#233;ralement, dans le cas d'une construction &#224; densit&#233; syntaxique faible, le 
recours &#224; des informations provenant d'autres domaines est probable. 
</p>
<p>5 Exp&#233;rimentation 
</p>
<p>Cette section pr&#233;sente une investigation un peu plus pr&#233;cise portant sur trois corpus limit&#233;s : 
un corpus de langue &#233;crite (extrait du journal Le Monde) de 15.420 mots et deux corpus de 
langue parl&#233;e transcrite (entretiens non supervis&#233;s, langue spontan&#233;e). Ces derniers, compte 
tenu des difficult&#233;s d'analyse, sont beaucoup plus r&#233;duits et comportent 523 et 1.923 mots. Il 
est tr&#232;s difficile d'adopter pour ce qui concerne l'analyse automatique de la langue parl&#233;e, une 
position rendant pr&#233;cis&#233;ment compte de la production r&#233;alis&#233;e. La transcription a donc &#233;t&#233; 
filtr&#233;e de fa&#231;on &#224; &#233;liminer toutes les informations d'ordre non lexical, en particulier les mots 
incomplets. En revanche, toutes les r&#233;p&#233;titions sont maintenues. Il faut par ailleurs pr&#233;ciser 
qu'il ne s'agit pas dans cette exp&#233;rience d'&#233;valuer les performances de l'analyseur, mais de 
comparer des indications syntaxiques construites par un analyseur donn&#233; pour une grammaire 
donn&#233;e. Chaque cat&#233;gorie, lorsqu'elle est construite (et dans la mesure o&#249; l'analyseur est 
d&#233;terministe) satisfait les principales contraintes qui la caract&#233;risent. Plus pr&#233;cis&#233;ment, la 
strat&#233;gie utilis&#233;e impose la satisfaction des propri&#233;t&#233;s de lin&#233;arit&#233;, d'exclusion et d'unicit&#233;. 
Une cat&#233;gorie construite par l'analyseur est donc globalement grammaticale et dans la plupart 
des cas, elle poss&#232;de une densit&#233; de propri&#233;t&#233;s non satisfaites nulle. Il est important de 
pr&#233;ciser que la cat&#233;gorie ainsi construite ce correspond pas toujours &#224; la bonne r&#233;ponse (erreur 
d'&#233;tiquetage, grammaire partielle, etc.). Cependant, une comparaison brute des r&#233;sultats sur 
des corpus diff&#233;rents, si elle ne constitue pas une &#233;valuation des performances de l'analyseur, 
fournit cependant des &#233;l&#233;ments d'information int&#233;ressants sur l'approche g&#233;n&#233;rale. 
 
Nous nous appuyons donc dans ce qui suit les seules indications de densit&#233; de propri&#233;t&#233;s 
satisfaites. Celle-ci permet notamment comparer la fiabilit&#233; de la caract&#233;risation et plus 
g&#233;n&#233;ralement de l'information syntaxique contenue : une densit&#233; &#233;lev&#233;e est en effet r&#233;v&#233;latrice 
d'une quantit&#233; d'information importante. Le tableau de la figure 3 pr&#233;sente quelques exemples 
de r&#233;alisation du SN pris dans le Corpus A et comportant des densit&#233;s contrast&#233;es : 
 
</p>
<p>Densit&#233; Constituants  Densit&#233; Constituants 
</p>
<p>0,034483 ProP  0,310345 Det SA SP 
</p>
<p>0,068966 Clit  0,379310 Det N Rel 
</p>
<p>0,103448 N  0,413793 Det SA N 
</p>
<p>0,1724138 ProP SA  0,413793 Det N SP 
</p>
<p>0,206897 Det SA  0,517241 Det N Rel SP 
</p>
<p>0,241379 Det SP Rel  0,551724 Det N SA SP 
</p>
<p>0,275862 Det N  0,655172 Det N SP SA Rel 
</p>
<p>Figure 3 : Densit&#233;s croissantes du SN (Corpus A) </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Blache 
</p>
<p> 
On constate dans ce tableau des situations diff&#233;rentes selon le type de r&#233;alisation. En effet, la 
densit&#233; ne cro&#238;t pas syst&#233;matiquement avec le degr&#233; de grammaticalit&#233;. Les deux densit&#233;s les 
plus basses (pronom personnel et clitique) correspondent &#224; des constructions grammaticales 
dans la grammaire utilis&#233;e. Ce ph&#233;nom&#232;ne vient du fait qu'une seule cat&#233;gorie fait partie de la 
liste des constituants et que seul un petit nombre de contraintes de la grammaire est donc 
&#233;valuable. Cette m&#234;me explication est valable pour expliquer la diff&#233;rence de densit&#233; entre la 
construction /Det N/ et /Det N SP/ qui est plus dense. De m&#234;me une r&#233;alisation moins 
grammaticale comme /Det SA SP/ pourra se voir attribuer une densit&#233; plus forte. Le filtrage 
de ce type d'effet pourrait se faire par la prise en compte de la densit&#233; de contraintes non 
satisfaites. Ce param&#232;tre &#233;tant sp&#233;cifi&#233;, la progression de densit&#233; correspond bien &#224; une 
croissance de la quantit&#233; d'information, notamment en termes de d&#233;pendance s&#233;mantique. Les 
densit&#233;s les plus &#233;lev&#233;es correspondent en effet toutes &#224; des constructions grammaticales et 
complexes. 
 
Il est par ailleurs int&#233;ressant d'examiner les r&#233;sultats obtenus sur les trois corpus, donn&#233;s dans 
la figure 4. Dans ce tableau sont indiqu&#233;s pour chaque corpus le nombre de mots qu'il 
contient, le nombre de cat&#233;gories syntagmatiques construites par l'analyseur, le nombre 
d'occurrence de chacune de ces cat&#233;gories, sa proportion dans le corpus et la densit&#233; moyenne 
de ses propri&#233;t&#233;s satisfaites. La taille des corpus &#233;tant limit&#233;e, il n'est bien entendu pas 
question de g&#233;n&#233;raliser trop rapidement les observations. On constate en particulier que le 
corpus B, tr&#232;s petit, a des &#233;carts relativement importants avec les autres &#224; la fois sur les 
fr&#233;quences, ce qui est normal, mais &#233;galement sur la densit&#233;. Cependant, la moyenne des deux 
corpus de langue parl&#233;e (donn&#233;e en figure 5a) se rapproche aussi bien pour la fr&#233;quence que la 
densit&#233; du corpus de langue &#233;crite. Il est donc possible d'en tirer quelques informations 
g&#233;n&#233;rales. 
 
</p>
<p>  Corpus A Corpus B Corpus C 
</p>
<p>  Nombre Fr&#233;quence Dens_sat Nombre Fr&#233;quence Dens_sat Nombre Fr&#233;quence Dens_sat 
</p>
<p>Mots   15 420      523      1 923     
</p>
<p>Cat. synt.  10 487      110      728     
</p>
<p>P  660 0,062935 0,571860  11 0,100000 0,386363  29 0,039835 0,560344
</p>
<p>SA  1 273 0,121388 0,565121  11 0,100000 0,381818  85 0,116758 0,435294
</p>
<p>Sadv  314 0,029942 1,000000  5 0,045455 1,000000  37 0,050824 1,000000
</p>
<p>SN  3 080 0,293697 0,314140  32 0,290909 0,191810  228 0,313187 0,217332
</p>
<p>SP  2 153 0,205302 0,351266  10 0,090909 0,273148  80 0,109890 0,353472
</p>
<p>SV  1 912 0,182321 0,391635  24 0,218182 0,333333  160 0,219780 0,350657
</p>
<p>Circ  241 0,022981 0,682157  6 0,054545 0,733333  54 0,074176 0,703703
</p>
<p>Coord  628 0,059884 0,306187  11 0,100000 0,428571  32 0,043956 0,535714
</p>
<p>Rel  226 0,021550 0,750000  0 0,000000 0,000000  23 0,031593 0,708695
</p>
<p>Figure 4 : R&#233;sultat d'analyse des 3 corpus 
 
Sans entrer dans les d&#233;tails d'une analyse compar&#233;e, on constate dans ces tableaux que 
certaines cat&#233;gories ont une densit&#233; moyenne tr&#232;s &#233;lev&#233;e, voire maximale (c'est le cas du 
SAdv). Les cat&#233;gories de ce type sont g&#233;n&#233;ralement caract&#233;ris&#233;es par un petit nombre de 
constituants possibles et un petit nombre de propri&#233;t&#233;s dans la grammaire. Il s'agit de 
cat&#233;gories relativement stables dans le sens o&#249; elles sont peu variables. A l'oppos&#233;, la 
cat&#233;gorie ayant la plus faible densit&#233; moyenne est le SN, dans tous les corpus. Cette cat&#233;gorie 
est potentiellement grande, elle est surtout tr&#232;s variable dans ses possibilit&#233;s de construction et </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Densit&#233; syntaxique &amp; gradient de grammaticalit&#233; 
</p>
<p>se d&#233;crit donc par un grand nombre de propri&#233;t&#233;s. Par ailleurs, il est int&#233;ressant d'examiner la 
corr&#233;lation entre la fr&#233;quence et la densit&#233;, comme indiqu&#233; dans la figure 5b suivante : 
</p>
<p> 
</p>
<p>Cat Fr&#233;quence Densit&#233; 
</p>
<p> 
</p>
<p>      
</p>
<p>P 0,069917582 0,4733535     
</p>
<p>SA 0,108379121 0,408556     
</p>
<p>Sadv 0,048139361 1     
</p>
<p>SN 0,302047952 0,204571     
</p>
<p>SP 0,1003996 0,31331     
</p>
<p>SV 0,218981019 0,341995     
</p>
<p>Circ 0,064360639 0,718518     
</p>
<p>Coord 0,071978022 0,4821425     
</p>
<p>Rel 0,015796703 0,3543475     
</p>
<p>Fig. 5a: Moyennes    Fig. 5b : Corr&#233;lation densit&#233;/fr&#233;quence 
 
On constate dans cette figure une tendance pour les cat&#233;gories les plus fr&#233;quentes &#224; &#234;tre 
associ&#233;es aux densit&#233;s les plus basses : les trois cat&#233;gories les plus fr&#233;quentes (SN, SV et SP) 
sont aussi celles ayant les plus faibles densit&#233;s tandis que les moins fr&#233;quentes (Circ, SAdv et 
Coord) sont celles de densit&#233; plus forte. Les &#233;l&#233;ments d'explication donn&#233;s plus haut 
concernant le nombre de constituants, de propri&#233;t&#233;s et la combinatoire (donc la variabilit&#233;) qui 
en d&#233;coule s'appliquent ici. Il est donc possible de dire &#233;galement que les cat&#233;gories les plus 
fr&#233;quentes sont celles qui sont d&#233;crites par le plus de propri&#233;t&#233;s. Il est donc n&#233;cessaire de 
pond&#233;rer la densit&#233; de satisfaction brute d&#233;crite pr&#233;c&#233;demment par la densit&#233; moyenne de la 
cat&#233;gorie concern&#233;e. Le calcul de la densit&#233; est ainsi ramen&#233; pour chaque cat&#233;gorie &#224; une 
&#233;chelle permettant d'&#233;valuer l'importance de la densit&#233; d'une construction donn&#233;e en montrant 
les fluctuations au del&#224; ou en de&#231;&#224; des densit&#233;s moyennes. 
</p>
<p>6 Conclusion 
</p>
<p>La repr&#233;sentation de l'information syntaxique sous forme de contraintes et la notion de 
caract&#233;risation, d&#233;crivant les propri&#233;t&#233;s syntaxiques d'un &#233;nonc&#233; sous la forme d'ensembles de 
propri&#233;t&#233;s satisfaites et non satisfaites, qu'on peut en tirer permettent d'introduire la notion de 
densit&#233; d'information. Certaines constructions pr&#233;sentent des densit&#233;s syntaxiques plus 
&#233;lev&#233;es que d'autres. Il s'agit d'une part de l'indication d'une quantit&#233; d'information variable et 
d'autre part d'une sp&#233;cification de la qualit&#233; de l'information syntaxique: une densit&#233; faible 
r&#233;v&#232;le soit une faible quantit&#233; d'information, soit une proportion importante de contraintes non 
satisfaites. La densit&#233; constitue donc un outil permettant &#233;galement la d&#233;finition d'un gradient 
de grammaticalit&#233; utile dans l'analyse de textes tout-venant. Bien entendu, la densit&#233; ne peut 
&#234;tre d&#233;finie que pour un ensemble de propri&#233;t&#233;s donn&#233;. Elle n'a donc de valeur comparative 
que pour cette grammaire. Il est cependant utile de remarquer que les types de propri&#233;t&#233;s sont 
g&#233;n&#233;raux et qu'il est sans doute possible (cela reste &#224; d&#233;montrer) de repr&#233;senter &#224; l'aide de 
propri&#233;t&#233;s les informations repr&#233;sent&#233;es sous un autre formalisme comme les grammaires de 
d&#233;pendance ou les grammaires de construction (voir [Blache04]). 
 
Il s'agit aussi d'un &#233;l&#233;ment d'identification de la complexit&#233; syntaxique et, parall&#232;lement, de la 
difficult&#233; d'interpr&#233;tation d'un &#233;nonc&#233; : une densit&#233; faible est associ&#233;e &#224; une plus grande 
difficult&#233; d'interpr&#233;tation. Enfin, la densit&#233; permettant de quantifier l'information, elle est un 
&#233;l&#233;ment quantitatif d'explication de la variabilit&#233; : une densit&#233; d'information faible est associ&#233;e 
&#224; une variabilit&#233; plus grande. Cette notion peut donc &#234;tre exploit&#233;e &#224; la fois d'un point de vue </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Blache 
</p>
<p>th&#233;orique pour identifier les cas o&#249; l'interaction entre les domaines linguistiques est n&#233;cessaire 
pour compenser un &quot;d&#233;faut&quot; d'information, du point de vue computationnel pour indiquer de 
fa&#231;on explicite un seuil de fiabilit&#233; de la description construite et du point de vue cognitif en 
fournissant un &#233;l&#233;ment d'explication de la difficult&#233; d'interpr&#233;tation. 
 
</p>
<p>R&#233;f&#233;rences 
</p>
<p>BALFOURIER J.-M., P. BLACHE &amp; T. VAN RULLEN (2002), &quot;From Shallow to Deep Parsing 
Using Constraint Satisfaction&quot;, in proceedings of COLING-2002 
</p>
<p>BLACHE P. (2001) Les Grammaires de Propri&#233;t&#233;s : des contraintes pour le traitement 
automatique des langues naturelles, Herm&#232;s Sciences. 
</p>
<p>BLACHE P. &amp; A. DI CRISTO (2002), &quot;Variabilit&#233; et d&#233;pendances des composants 
linguistiques&quot;, in actes de TALN-2002. 
</p>
<p>BLACHE P. (2003), &quot;Vers une th&#233;orie cognitive de la langue bas&#233;e sur les contraintes&quot;, in actes 
de TALN-03 
</p>
<p>BLACHE P. (soumis), &quot;Constraints: an operational framework for Construction Grammars&quot; 
CROFT W. &amp; D. CRUSE (2003), Cognitive Linguistics, Cambridge University Press. 
DAHL V. &amp; P. BLACHE (2004), &quot;Directly executable constraint-based grammars&quot;, soumis 
FILLMORE C. &amp; P. KAY (1993), Construction Grammars (ms), UC Berkeley 
GOLDBERG A. (1995) Construcions: A Construction grammar approach to argument 
</p>
<p>structure, University of Chicago Press 
GIBSON T. (2000) &quot;Dependency locality theory: a distance-based theory of linguistic 
</p>
<p>complexity&quot;, in Marantz &amp; al. (eds), Image, Language and Brain , MIT Press. 
LANGACKER R. (1999), Grammar and Conceptualization, Walter de Gruyter. 
MERTENS P. (1993) &quot;Accentuation, intonation et morphosyntaxe&quot;, in Travaux de Linguistique 
</p>
<p>26 
PRINCE A. &amp; SMOLENSKY P. (1993), Optimality Theory: Constraint Interaction in Generative 
</p>
<p>Grammars, Technical Report RUCCS TR-2, Rutgers Center for Cognitive Science. 
PULLUM G. &amp; B. SCHOLZ (2003), Model-Theoretic Syntax Foundations &#8211; Linguistic Aspects, 
</p>
<p>ESSLLI lecture notes, Vienna University of Technology. 
VASISHTH S. (2003) &quot;Quantifying Processing Difficulty in Human Sentence Parsing&quot;, in 
</p>
<p>procedings of Eurocogsci-2003 
 </p>

</div></div>
</body></html>