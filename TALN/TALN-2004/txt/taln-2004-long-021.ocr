TALN 2004, Fés, 19-21 avril 2004

Densité d'information syntaxique et gradient de grammaticalité

Philippe Blache

Laboratoire Parole et Langage
CNRS — Université de Provence
29, Avenue Robert Schuman
13621 Aix-en-Provence

pb@lpl.univ-aix.ﬁ*

Résumé — Abstract

Cet article propose l'introduction d'une notion de densité syntaxique permettant de caractériser la
complexité d'un énoncé et au-dela d'introduire la spéciﬁcation d'un gradient de grammaticalité. Un tel
gradient s'avére utile dans plusieurs cas : quantiﬁcation de la difﬁculté d'interprétation d'une phrase,
gradation de la quantité d'information syntaxique contenue dans un énoncé, explication de la
variabilité et la dépendances entre les domaines linguistiques, etc. Cette notion exploite la possibilité
de caractérisation ﬁne de l'information syntaxique en termes de contraintes : la densité est fonction des
contraintes satisfaites par une réalisation pour une grammaire donnée. Les résultats de l'application de
cette notion a quelques corpus sont analysés.

This paper introduces the notion of syntactic density that makes it possible to characterize the
complexity of an utterance and to speciﬁz a gradient of grammaticality. Such a gradient is useful in
several cases: quantiﬁcation of the diﬂiculty of interpreting an utterance, quantiﬁcation of syntactic
information of an utterance, description of variability and linguistic domains interaction, etc. This
notion exploits the possibility of fine syntactic characterization in terms of constraints: density if
function of satisﬁed constraints by an utterance for a given grammar. Some results are presented and
analyzed.

Keywords — Mots Clés

Syntaxe, analyse, robustesse, contraintes, information linguistique, complexité syntaxique.
Syntax, parsing, robustness, constraints, linguistic information, syntactic complexity.

1 Introduction

Certains phénomenes linguistiques, certaines constructions sont caractérisées par des
propriétés tres marquées, facilement identiﬁables. C'est le cas par exemple de la syntaxe pour
laquelle des propriétés de forme, d'ordre ou de rection permettent de caractériser des
constructions comme les clivées. Il est alors possible de décrire avec une grande précision de
telles constructions, mais également de les interpréter facilement. Les clivées sont en effet
souvent simples a interpréter méme si leur representation formelle et leur analyse automatique
est complexe. Il n'y a en général que peu d'ambigu'1'té pour ce type de construction. A

Philippe Blache

l'inVerse, il existe d'autres types de constructions, comme les dislocations qui, méme si elles
sont identiﬁables, présentent quelquefois plus de problemes pour leur interprétation.

Il est tres difﬁcile de fournir une explication a cette différence de fonctionnement si l'on s'en
tient au niveau global de la construction. Il n'est en effet pas possible de dire que les clivées
sont plus faciles a interpréter que les disloquées, d'une facon générale, sans en fournir de
raison. La liste des constituants de chacune de ces constructions pas plus que leur position
dans la structure syntaxique ne nous fournit d'indication sur cette difﬁculté d'interprétation ou
la potentialité d'ambigu'1'té. La notion de complexité en syntaxe ou de difﬁculté d'analyse reste
encore aujourd'hui un probleme difﬁcile a décrire. Certains travaux en psycholinguistique a ce
sujet tentent de fournir des explications en termes de distance (cf. en particulier [Gibson00]),
mais sans rendre compte des différences tres importantes a l'intérieur d'une méme
construction. Or, a un niveau d'analyse ﬁn, il est possible d'identiﬁer des différences ou du
moins de fournir quelques caractéristiques plus régulieres pouvant servir d'élément de réponse
a ce probleme. Il faut pour cela dissocier l'information syntaxique et tenter d'en caractériser
plus ﬁnement ses propriétés. Il devient ainsi possible non seulement d'indiquer quelles sont
les propriétés d'ordre purement syntaxique de la construction (par exemple l'ordre, la
restriction de cooccurrence ou l'accord), mais également d'indiquer des caractéristiques
générales concernant notamment la quantité d'information syntaxique, son importance, sa
ﬁabilité, etc. Dans certains cas, l'analyse permet de fournir un grand nombre d'informations
sur les objets linguistiques (par exemple les catégories) formant une construction. Dans
d'autres, ces informations sont au contraire plus rares. Il est alors possible de penser que dans
les cas o1‘1 l'information est rare ou peu "importante", l'interprétation de la construction sera
plus difﬁcile que dans ceux o1‘1 l'information est abondante et ﬁable. Cette question est au
coeur de certaines approches comme les grammaires de construction (cf. [Fillmore93] ou
[Goldberg95]) qui proposent une description exploitant en méme temps différentes
informations provenant de différents domaines linguistiques. Nous proposons dans cet article
d'introduire dans la description une notion de densité d'information. Celle-ci ne tient pas
compte du contenu informationnel porté par la syntaxe mais de sa forme. Il est ainsi possible
de fournir un élément d'information quantiﬁée propre a une construction et donnant des
indications sur son interprétabilité. Les constructions a forte densité syntaxique seraient ainsi
plus faciles a interpréter que celles a faible densité. L'idée que la quantité d'information
facilite l'analyse au lieu de la complexiﬁer est décrite par exemple dans [Vasishth03]. Nous
proposons ici de quantiﬁer cette donnée.

Ce type d'approche présente un triple intérét descriptif, cognitif et computationnel. Il devient
en effet possible de fournir des indications sur la complexité syntaxique d'une construction
non plus par les seules relations syntaxiques entrant en jeu, mais également par une évaluation
de leur importance, notamment du point de Vue quantitatif. De plus, la densité permet de
fournir un élément de réponse a des questions d'ordre psycholinguistique comme les
préférences ou les difﬁcultés d'interprétation. Enﬁn, du point de Vue du traitement
automatique, la densité constitue un critere précieux pour identiﬁer des zones ou la quantité
d'information est plus abondante et plus riche. Ce type de critere peut étre utile par exemple
dans la recherche d'information, le typage de document ou l'analyse de sa structure discursive.
Inversement, le repérage d'une faible densité permet, par exemple dans le cas de systemes de
traitement de langue parlée, d'identiﬁer les cas ou des heuristiques particulieres devront étre
appliquées pour permettre l'interprétation.

Densité syntaxique & gradient de grammaticalité

2 La nature de l'information syntaxique

Plusieurs approches en syntaxe tentent aujourd'hui de se démarquer du cadre génératif pour
proposer une Vision de l'analyse plus souple et permettant de s'adapter a la réalité des données
langagieres. La forme des énoncés que nous sommes amenés a traiter ainsi que les processus
d'élaboration du contenu informatif montrent en effet que l'information linguistique est
dispersée et instable. Dans cette perspective, la Vision proposée par les théories génératives
stipulant que la langue est un ensemble et la grammaire un processus permettant
l'énumération de cet ensemble n'est pas adaptée : la question fondamentale n'est en effet pas
de savoir si un énoncé appartient ou non a une langue mais bien d'extraire l'information de cet
énoncé, quelle que soit sa forme. Dans certains cas, il est ainsi possible d'associer a l'énoncé
analysé une structure syntaxique le décrivant en totalité. Cependant, dans de tres nombreux
cas, une telle structure n'est pas calculable. De plus la granularité de l'information obtenue
dans ce type de démarche est homogene: tous les composants de la structure sont de méme
niveau. Or, dans de nombreux cas, seules des informations tres partielles peuvent étre
obtenues. C'est le cas de l'exemple (1), tiré de [Mertens93], dans lequel seules quelques
indications sont accessibles :

(1) lundi lavage mardi repassage mercredi repos

Cet exemple illustre une construction courante, pas seulement en langue parlée, dans laquelle
la relation entre les éléments est fournie notamment par la répétition d'un schéma. La prosodie
sera dans ce cas d'une grande importance, nous y reviendrons. Pour ce qui conceme le seul
niveau syntaxique, nous avons donc une répétition de la séquence N1 [temporel] <
N2 [action]. La morphologie et l'ordre linéaire sont les seules caractéristiques de cette
construction. Une analyse syntaxique a proprement parler n'est pas possible dans la mesure ou
aucune relation particuliere en dehors de la linéarité ne relie les objets de l'énoncé. Il est en
revanche indispensable de spéciﬁer les informations accessibles de facon a permettre
l'interprétation. Dans l'exemple (2), nous retrouvons un probleme similaire, méme si plus
d'informations syntaxiques sont accessibles.

(2) Marie, je la supporte pas

Dans ce cas, l'énoncé n'est pas interprétable sur la base des seules informations syntaxiques
dans la mesure ou la relation entre le premier nom et le reste de l'énoncé n'est pas spéciﬁée.
Plus précisément, deux interprétations sont possibles : la premiere en disloquée, avec une
coréférence entre le nom et le clitique, et la seconde en Vocatif, sans coréférence. La prosodie
dans ce cas jouera un role déterminant (cf. [Blache03]). Cet exemple illustre le cas ou le
domaine syntaxique n'apporte pas sufﬁsamment d'information permettant a lui seul
l'interprétation.

D'une facon générale, ces exemples illustrent d'une part la nécessité de représenter tout type
d'information syntaxique, y compris en l'absence de Véritable relation, et d'autre part l'intérét
de tenter de quantiﬁer cette information. Dans certains cas, l'information syntaxique est en
effet plus marquée, plus forte, plus dense que dans d'autres. Nous proposons dans le reste de
cet article une déﬁnition de cette notion de densité s'appuyant sur une représentation
décentralisée de l'information. Dans la prochaine section, nous rappellerons rapidement les
principales caractéristiques des Grammaires de Propriétés permettant une représentation de

Philippe Blache

l'inforrnation syntaxique a granularité Variable. Nous proposerons ensuite une spécification de
la densité en foumissant des exemples tirés de corpus.

3 Une représentation décentralisée de l'information : les
Grammaires de Propriétés

Une approche permettant la représentation de l'inforrnation linguistique telle que nous l'aVons
décrite, a savoir instable et dispersée, doit s'appuyer sur une conception non holistique de
cette information (cf. [Pullum03]). En d'autres terrnes chaque type d'inforrnation doit étre
représenté séparément et surtout pouvoir étre évaluée séparément. A la différence des regles
syntagmatiques dans les approches génératives qui n'ont de Valeur que situées dans un
processus de dérivation général (donc dans une structure générale), a la différence également
de la théorie de l'optimalité (cf. [Prince93]) dans laquelle une contrainte n'a de signiﬁcation
que par rapport aux autres, les propriétés syntaxiques doivent pouvoir étre interprétées
indépendamment des autres propriétés.

C'est sur ce principe que reposent les Grammaires de Propriétés (cf. [Blache01]). Celles-ci
distinguent plusieurs types de propriétés syntaxiques, sans relation hiérarchique : aucun ordre
d'éValuation n'est imposé et chaque propriété représente une information homogene. La
description de la structure syntaxique d'un énoncé est constituée par l'ensemble des propriétés
qui peuvent étre évaluées. Le tableau suivant récapitule les types de propriétés syntaxiques
actuellement utilisées dans les grammaires de propriétés, de nouvelles propriétés pouvant
éventuellement étre ajoutées (il se peut par exemple qu'une propriété de contiguité soit utile).

Propriété Deﬁnition
Linéarité (<) Contraintes de précédence Iinéaire
Dépendance (—;) Relations de dépendance
Obligation (ObIig) Ensemble des catégories obligatoires. Une de ces catégories et une seule
doit étre réalisée dans un syntagme

Exclusion (¢) Restriction de cooccurrence entre ensembles de catégories
Exigence (:>) Obligation de cooccurrence entre ensembles de catégories
Unicité (Unic) Catégories ne pouvant étre répétées dans un syntagme

Une propriété est une contrainte représentant une information spéciﬁque d'une catégorie. La
grammaire est un ensemble de contraintes de ce type et chaque catégorie de la grammaire est
décrite par un sous-ensemble de ces contraintes. Certaines de ces contraintes sont
caractéristiques d'une catégorie et permettront pendant l'analyse de l'instancier. Une analyse
consiste, pour un énoncé donné, a évaluer l'ensemble des contraintes. A chaque catégorie sera
associé l'ensemble des contraintes que sa réalisation satisfait ainsi que celles qu'elle ne
satisfait pas. Ces deux ensembles forment la caractérisation de la catégorie. Une telle
approche permet donc d'associer une caractérisation a une catégorie, quelle que soit la forme
de sa réalisation. Dans les cas ou toutes les contraintes sont satisfaites, la catégorie est
grammaticale, mais ceci ne lui confere aucun statut particulier. Le fait que des contraintes ne
soient pas satisfaites n'empéche en effet pas l'utilisation de la catégorie correspondante. De
plus, nous disposons alors d'une approche permettant de spécifier un gradient de
grammaticalité.

Plusieurs analyseurs de grammaire de propriétés ont été développés (cf. [Blache02]). Nous
présentons rapidement les caractéristiques principales de l'analyseur utilisé pour les
expérimentations décrites plus loin. Le schéma général de l'analyse en GP consiste, pour un

Densité syntaxique & gradient de grammaticalité

ensemble donné de catégories (on parle d'aﬂectatz'on) a déterminer sa caractérisation. Pour
cela, l'ensemble des contraintes de la grammaire est activé, un sous-ensemble d'entre elles
sont évaluables et permettent de commencer a construire une caractérisation. Celle-ci, formée
de contraintes satisfaites et non satisfaites, est analysée et en cas de présence de contraintes
caractéristiques, la catégorie correspondante est instanciée. Chaque nouvelle catégorie
instanciée est alors disponible pour participer a une nouvelle affectation qui sera a son tour
évaluée. Le systeme construit donc de facon incrémentale les affectations (ces ensembles de
catégories) qui servent de base a la construction des caractérisations. Le schéma general de
l'analyse se présente comme suit :

1. Construction d 'une aﬂectation /'4 (choix d 'un ensemble de catégories)

2. Evaluation de la satz'sfaz'sabz'lz'té de ﬂparmi I 'ensemble total de contraintes

3. Analyse de la caractérisation de ,1, instanciation de la catégorie syntagmatique
correspondante

La caractérisation, au coeur de l'analyse en GP, est un mécanisme de satisfaction de
contraintes. Il est possible d'en régler le niveau de relaxation en autorisant ou non la Violation
de contrainte. Dans le cas o1‘1 toutes les contraintes doivent étre satisfaites, seules des
catégories grammaticales sont construites. Cependant, une telle approche n'est pas adaptée a
la réalité, en particulier pour de l'analyse de textes tout-Venant. Dans l'analyseur utilisé ici,
nous avons choisi de relacher la satisfaisabilité des contraintes de dépendance, d'eXigence et
d'obligation, ces propriétés étant d'une part les moins ﬁltrantes et d'autre part celles dont la
satisfaisabilité peut Varier en complétant l'affectation initiale (cf. [Dahl04]). Cette stratégie
permet de développer un analyseur déterministe mais tolérant.

L'eXemple suivant montre la caractérisation d'une catégorie (la relative "qu'z'ls chassaient a
cheval") comportant l'indication de ses bornes dans l'énoncé analysé, son statut de
grammaticalité, son affectation et sa caractérisation a proprement parler. Celle-ci indique par
exemple le respect des propriétés de linéarité, de l'obligation de réalisation d'un SV avec un
relatif sujet ou encore l'unicité de ses constituants.

Catégorie Gauche Droite Affectation Caractérisation

Rel 53 57 ProR:qu; SN:sujet; SV ProR<SN; ProR<SV; SN<SV
ProR[suj]=>SV;

SN->SV; SV->ProR
Ob|ig:ProR

Unic = {ProR, SN, SV}

4 La densité d'information

Nous avons Vu dans la section précédente comment caractériser une catégorie par l'ensemble
des propriétés évaluables parmi celles qui la décrivent potentiellement. Le nombre de
propriétés évaluées par rapport aux propriétés décrivant la catégorie est intéressant et
constitue un premier indice de la "qualité" de l'information. Plus précisément, le nombre de
propriétés satisfaites par rapport au nombre total de propriétés décrivant cette catégorie dans
la grammaire (noté dens_sat) nous foumit une indication brute sur la quantité d'information
syntaxique contenue dans la catégorie. L'hypothese émise est que plus nous disposons
d'informations au niveau syntaxique, plus la catégorie construite est ﬁable. Dans les cas o1‘1
dens_sat est faible, dans la mesure o1‘1 peu de propriétés ont été satisfaites, la catégorie
caractérisée le sera de facon moins ﬁable que pour une catégorie ayant un rapport élevé. La

Philippe Blache

fiabilité constitue donc un outil permettant de classer des réalisations de catégories : les
catégories tres ﬁables satisfont plus de contraintes que celles qui le sont moins. En d'autres
termes, ce rapport représente un élément d'information sur la grammaticalité de la catégorie.
Si nous disposons simultanément de l'éValuation des propriétés satisfaites et des propriétés
non satisfaites par rapport au nombre total de propriétés, ce degré de grammaticalité devient
alors tres précis. De plus, nous pensons que la ﬁabilité syntaxique constitue également une
facilitation pour l'interprétation. Une catégorie tres ﬁable sera plus facilement interprétable a
l'aide des seules informations syntaxiques qu'une catégorie non ﬁable.

Dans la Version de l'analyseur GP présentée plus haut, l'information de ﬁabilité, ou indication
de densité, est associée a toute catégorie construite. Cet analyseur étant déterrniniste, le seuil
de tolérance de non satisfaction de propriété est tres bas. Le rapport des propriétés non
satisfaites sur le nombre de propriété, malgré son importance, n'est donc pas retenu ici. Seule
la densité des propriétés satisfaites est utilisée. Cette information est malgré tout intéressante
et permet de distinguer plusieurs types de constructions. L'eXemple suivant fournit le type
d'indications caractérisant une catégorie. En plus des informations données plus haut, nous
trouvons donc les indications de densité sous la forme des deux rapports suivants :

o dens_sat = nb propriétés satisfaites / nb total de propriétés
o dens_unsat = nb propriétés non satisfaites / nb total de propriétés

Rappelons que parrni toutes les propriétés décrivant une catégorie dans la grammaire, pour
une réalisation donnée, seul un sous-ensemble des ces propriétés est évaluable. Par exemple,
pour un SN forme de /Det N/, toutes les propriétés mettant en jeu d'autres catégories ne sont
pas évaluables. La somme des deux densités n'est donc pas égale a 1, ce qui justiﬁe
l'utilisation de ces deux rapports.

Catégorie Gauche Droite Statut Dens_Sat Dens_Unsat Affectation
P 0 24 Vmi Q375 0J25 SP;SN

Dans cet exemple, la catégorie P est forrnée d'un SP et d'un SN. La grammaire utilisée stipule
une relation de dépendance er1tre un SN et un Sv, expliquant la présence d'une densité non
nulle pour les propriétés non satisfaites. La densité relativement faible de propriétés satisfaites
s'explique par le fait qu'une proportion importante des propriétés décrivant la catégorie P met
en jeu le Sv.

Un des enjeux des approches forrnelles de la syntaxe est la capacité a prendre en compte tout
type d'énoncé. Il est cependant nécessaire de distinguer un gradient de grammaticalité
permettant d'indiquer en quelque sorte le niveau de bonne formation d'un énoncé relativement
a une grammaire. Une telle approche permet de n'eXclure a priori aucune production et offre
l'aVantage de fournir une caractérisation, quelle que soit la forme de l'énoncé analysé. La
question de la grammaticalité n'est ainsi plus un probleme de décision (oui ou non l'énoncé
appartient-il a la langue) mais un probleme de description pur. La densité joue alors
parfaitement ce role d'indicateur pour le gradient de grammaticalité. La notion de gradient
prend toute son importance lorsqu'on aborde la question de l'interaction er1tre les différents
domaines de l'information linguistique. Il est en effet nécessaire d'une part d'eXpliquer
comment ces domaines interagissent entre eux, mais également de tenter de comprendre
pourquoi, dans certains cas, l'interaction est nécessaire plus que dans d'autres. L'hypothese
que nous avons exposée dans [Blache02] et [Blache03], est qu'il existe un seuil d'information
nécessaire au-dela duquel l'interprétation d'un énoncé devient possible. Ce seuil est atteint par
le cumul des informations provenant des différents domaines. Un domaine peut a lui seul

Densité syntaxique & gradient de grammaticalité

contenir suffisamment d'information et dans ce cas, les autres domaines deviennent en
quelque sorte moins importants. Nous expliquons de cette facon la variabilité plus ou moins
grande de tel ou tel domaine en fonction du type de construction. Par exemple, si les
informations morpho-syntaxiques sont suffisamment importantes, la prosodie aura une
possibilité de variabilité plus grande. Inversement, lorsque la prosodie est caractéristique
d'une construction (par exemple un contour ascendant caractéristique de l'interrogation), la
syntaxe sera plus Variable, ce qui explique la possibilité en francais de construire une tournure
interrogative avec une forme syntaxique de surface affirmative. De méme, dans l'exemple (1)
cité plus haut, la densité des relations syntaxiques est faible et l'interprétation est rendue
possible par l'identiﬁcation de la répétition d'un schéma lexical renforcé par la structure
prosodique. Plus généralement, dans le cas d'une construction a densité syntaxique faible, le
recours a des informations provenant d'autres domaines est probable.

5 Expérimentation

Cette section présente une investigation un peu plus précise portant sur trois corpus limités :
un corpus de langue écrite (extrait du journal Le Monde) de 15.420 mots et deux corpus de
langue parlée transcrite (entretiens non supervisés, langue spontanée). Ces derniers, compte
tenu des difﬁcultés d'analyse, sont beaucoup plus réduits et comportent 523 et 1.923 mots. Il
est tres difﬁcile d'adopter pour ce qui concerne l'analyse automatique de la langue parlée, une
position rendant précisément compte de la production réalisée. La transcription a donc été
ﬁltrée de facon a éliminer toutes les informations d'ordre non lexical, en particulier les mots
incomplets. En revanche, toutes les répétitions sont maintenues. Il faut par ailleurs préciser
qu'il ne s'agit pas dans cette expérience d'éValuer les performances de l'analyseur, mais de
comparer des indications syntaxiques construites par un analyseur donné pour une grammaire
donnée. Chaque catégorie, lorsqu'elle est construite (et dans la mesure ou l'analyseur est
déterministe) satisfait les principales contraintes qui la caractérisent. Plus précisément, la
stratégie utilisée impose la satisfaction des propriétés de linéarité, d'exclusz'on et d'um'cz'té.
Une catégorie construite par l'analyseur est donc globalement grammaticale et dans la plupart
des cas, elle possede une densité de propriétés non satisfaites nulle. Il est important de
préciser que la catégorie ainsi construite ce correspond pas toujours a la bonne réponse (erreur
d'étiquetage, grammaire partielle, etc.). Cependant, une comparaison brute des résultats sur
des corpus différents, si elle ne constitue pas une évaluation des performances de l'analyseur,
foumit cependant des éléments d'information intéressants sur l'approche générale.

Nous nous appuyons donc dans ce qui suit les seules indications de densité de propriétés
satisfaites. Celle-ci permet notamment comparer la fiabilité de la caractérisation et plus
généralement de l'information syntaxique contenue : une densité élevée est en effet révélatrice
d'une quantité d'information importante. Le tableau de la ﬁgure 3 présente quelques exemples
de réalisation du SN pris dans le Corpus A et comportant des densités contrastées :

Densité Constituants Densité Constituants
0 0.310345 Det SA SP
0 0.379310 Det N Rel
0 1 0,413793 Det SA N
0 17241 SA 0,413793 Det N SP
SA 0,517241 Det N Rel SP
SP Rel 0,551724 Det N SA SP
N 0,655172 Det N SP SA Rel
Figure 3 : Densités croissantes du SN (Corpus A)

 

Philippe Blache

On constate dans ce tableau des situations différentes selon le type de réalisation. En effet, la
densité ne croit pas systématiquement avec le degré de grammaticalité. Les deux densités les
plus basses (pronom personnel et clitique) correspondent a des constructions grammaticales
dans la grammaire utilisée. Ce phénomene Vient du fait qu'une seule catégorie fait partie de la
liste des constituants et que seul un petit nombre de contraintes de la grammaire est donc
évaluable. Cette méme explication est Valable pour expliquer la différence de densité er1tre la
construction /Det N/ et /Det N SP/ qui est plus dense. De méme une réalisation moins
grammaticale comme /Det SA SP/ pourra se Voir attribuer une densité plus forte. Le ﬁltrage
de ce type d'effet pourrait se faire par la prise en compte de la densité de contraintes non
satisfaites. Ce parametre étant spéciﬁé, la progression de densité correspond bien a une
croissance de la quantité d'inforrnation, notamment en terrnes de dépendance sémantique. Les
densités les plus élevées correspondent en effet toutes a des constructions grammaticales et
complexes.

Il est par ailleurs intéressant d'examiner les résultats obtenus sur les trois corpus, donnés dans
la ﬁgure 4. Dans ce tableau sont indiqués pour chaque corpus le nombre de mots qu'il
contient, le nombre de catégories syntagmatiques construites par l'analyseur, le nombre
d'occurrence de chacune de ces catégories, sa proportion dans le corpus et la densité moyenne
de ses propriétés satisfaites. La taille des corpus étant limitée, il n'est bien entendu pas
question de généraliser trop rapidement les observations. On constate en particulier que le
corpus B, tres petit, a des écarts relativement importants avec les autres a la fois sur les
fréquences, ce qui est normal, mais également sur la densité. Cependant, la moyenne des deux
corpus de langue parlée (donnée en ﬁgure 5a) se rapproche aussi bien pour la fréquence que la
densité du corpus de langue écrite. Il est donc possible d'en tirer quelques informations
générales.

Dens sat Nombre Dens sat

1

Nombre Dens sat
1 5

1
121

0 141

0 351
0 182321 0 391
0 022981 0 6821
0 0 3061

0 021 0
Figure 4 : Résultat d 'analyse des 3 corpus

0
0
0
11 0 428571

0
0
1
0
0
0
0
0
0 0

       

Sans entrer dans les détails d'une analyse comparée, on constate dans ces tableaux que
certaines catégories ont une densité moyenne tres élevée, Voire maximale (c'est le cas du
sAdv). Les catégories de ce type sont généralement caractérisées par un petit nombre de
constituants possibles et un petit nombre de propriétés dans la grammaire. Il s'agit de
catégories relativement stables dans le sens o1‘1 elles sont peu Variables. A l'opposé, la
catégorie ayant la plus faible densité moyenne est le SN, dans tous les corpus. Cette catégorie
est potentiellement grande, elle est surtout tres Variable dans ses possibilités de construction et

Densité syntaxique & gradient de grammaticalité

se décrit donc par un grand nombre de propriétés. Par ailleurs, il est intéressant d'examiner la
corrélation er1tre la fréquence et la densité, comme indiqué dans la ﬁgure 5b suivante :

 

Cat Fréquence Densité
P 0069917582 04733535
SA 0,108379121 0,408556 ,
Sadv 0048139361 1 
SN 0,302047952 0.204571 "‘
SP 0,1003996 0,313.31
sv 0,218981019 0.341995
Circ 0,064360639 0,718518 °-W °-=* °-=° W W °--'= °-=° °-==
Coord 0071978022 04821425 
Rel 0015796703 03543475
Fig. 5a: Moyermes Fig. 5b : Corrélation densité/fréquence

On constate dans cette ﬁgure une tendance pour les catégories les plus fréquentes a étre
associées aux densités les plus basses : les trois catégories les plus fréquentes (SN, sv et SP)
sont aussi celles ayant les plus faibles densités tandis que les moins fréquentes (Circ, sAdv et
Coord) sont celles de densité plus forte. Les éléments d'eXplication donnés plus haut
concernant le nombre de constituants, de propriétés et la combinatoire (donc la Variabilité) qui
en découle s'appliquent ici. Il est donc possible de dire également que les catégories les plus
fréquentes sont celles qui sont décrites par le plus de propriétés. Il est donc nécessaire de
pondérer la densité de satisfaction brute décrite précédemment par la densité moyenne de la
catégorie concernée. Le calcul de la densité est ainsi rarnené pour chaque catégorie a une
échelle permettant d'éValuer l'importance de la densité d'une construction donnée en montrant
les ﬂuctuations au dela ou en deca des densités moyennes.

6 Conclusion

La représentation de l'information syntaxique sous forme de contraintes et la notion de
caractérisation, décrivant les propriétés syntaxiques d'un énoncé sous la forme d'ensembles de
propriétés satisfaites et non satisfaites, qu'on peut en tirer perrnettent d'introduire la notion de
densité d'inforrnation. Certaines constructions présentent des densités syntaxiques plus
élevées que d'autres. Il s'agit d'une part de l'indication d'une quantité d'inforrnation Variable et
d'autre part d'une spéciﬁcation de la qualité de l'information syntaxique: une densité faible
révele soit une faible quantité d'inforrnation, soit une proportion importante de contraintes non
satisfaites. La densité constitue donc un outil perrnettant également la déﬁnition d'un gradient
de grarnmaticalité utile dans l'analyse de textes tout-Venant. Bien entendu, la densité ne peut
étre déﬁnie que pour un ensemble de propriétés donné. Elle n'a donc de Valeur comparative
que pour cette grammaire. Il est cependant utile de remarquer que les types de propriétés sont
généraux et qu'il est sans doute possible (cela reste a démontrer) de représenter a l'aide de
propriétés les inforrnations représentées sous un autre forrnalisme comme les grammaires de
dépendance ou les grammaires de construction (Voir [Blache04]).

Il s'agit aussi d'un élément d'identiﬁcation de la complexité syntaxique et, parallelement, de la
difﬁculté d'interprétation d'un énoncé : une densité faible est associée a une plus grande
difﬁculté d'interprétation. Enﬁn, la densité permettant de quantiﬁer l'inforrnation, elle est un
élément quantitatif d'explication de la Variabilité : une densité d'inforrnation faible est associée
a une Variabilité plus grande. Cette notion peut donc étre exploitée a la fois d'un point de Vue

Philippe Blache

théorique pour identiﬁer les cas o1‘1l'interaction er1tre les domaines linguistiques est nécessaire
pour compenser un "défaut" d'information, du point de vue computationnel pour indiquer de
facon explicite un seuil de fiabilité de la description construite et du point de vue cognitif en
foumissant un élément d'eXplication de la difﬁculté d'interprétation.

Références

BALFOURIER J .-M., P. BLACHE & T. VAN RULLEN (2002), "From Shallow to Deep Parsing
Using Constraint Satisfaction", in proceedings of COLING-2002

BLACHE P. (2001) Les Grammaires de Propriétés .' des contraintes pour le traitement
automatique des langues naturelles, Hermes Sciences.

BLACHE P. & A. DI CRISTO (2002), "Variabilité et dépendances des composants
linguistiques", in actes de TALN-2002.

BLACHE P. (2003), "Vers une théorie cognitive de la langue basée sur les contraintes", in actes
de TALN-03

BLACHE P. (soumis), "Constraints: an operational framework for Construction Grammars"

CROFT W. & D. CRUSE (2003), Cognitive Linguistics, Cambridge University Press.

DAHL V. & P. BLACHE (2004), "Directly executable constraint-based grammars", soumis

FILLMORE C. & P. KAY (1993), Construction Grammars (ms), UC Berkeley

GOLDBERG A. (1995) Construcions: A Construction grammar approach to argument
structure, University of Chicago Press

GIBSON T. (2000) "Dependency locality theory: a distance-based theory of linguistic
complexity", in Marantz & al. (eds), Image, Language and Brain , MIT Press.

LANGACKER R. (1999), Grammar and Conceptualization, Walter de Gruyter.

MERTENS P. (1993) "Accentuation, intonation et morphosyntaxe", in T ravaux de Linguistique
26

PRINCE A. & SMOLENSKY P. (1993), Optimality Theory: Constraint Interaction in Generative
Grammars, Technical Report RUCCS TR-2, Rutgers Center for Cognitive Science.

PULLUM G. & B. SCHOLZ (2003), Model-Theoretic Syntax Foundations — Linguistic Aspects,
ESSLLI lecture notes, Vienna University of Technology.

VASISHTH S. (2003) "Quantifying Processing Difﬁculty in Human Sentence Parsing", in
procedings of Eurocogsci-2003

