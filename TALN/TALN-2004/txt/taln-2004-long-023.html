<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Grammaires d'unification polaris&#233;es</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2004, F&#232;s, 19-21 avril 2004
</p>
<p>Grammaires d'unification polaris&#233;es
</p>
<p>Sylvain Kahane
</p>
<p>Lattice, Universit&#233; Paris 7
Modyco, Universit&#233; Paris 10
</p>
<p>sk@ccr.jussieu.fr
</p>
<p>R&#233;sum&#233; &#8211; Abstract
Cet article propose un formalisme math&#233;matique g&#233;n&#233;rique pour la combinaison de structures.
Le contr&#244;le de la saturation des structures finales est r&#233;alis&#233; par une polarisation des objets des
structures &#233;l&#233;mentaires. Ce formalisme permet de mettre en &#233;vidence et de formaliser les
m&#233;canismes proc&#233;duraux masqu&#233;s de nombreux formalismes, dont les grammaires de r&#233;&#233;criture,
les grammaires de d&#233;pendance, TAG, HPSG et LFG.
</p>
<p>This paper proposes a generic mathematical formalism for the combination of structures. The
control of saturation of the final structures is realized by a polarization of the objects of the
elementary structures. This formalism allows us to bring to the fore and to formalize the hidden
procedural mechanisms of numerous formalisms, including rewriting systems, dependency
grammars, TAG, HPSG and LFG.
</p>
<p>Mots Cl&#233;s &#8211;Keywords
Grammaire formelle, unification, polarisation, grammaire de r&#233;&#233;criture, grammaire de
d&#233;pendance, TAG, HPSG, LFG, graphe, arbre, dag.
Formal grammar, unification, polarization, rewriting system, dependency grammar, TAG, HPSG,
LFG, graph, tree, dag.
</p>
<p>1 Introduction
Notre objectif est de donner un cadre g&#233;n&#233;ral &#224; la plupart des formalismes &#224; base de r&#232;gles
utilis&#233;es en linguistique. Les productions langagi&#232;res sont fortement structur&#233;es et par ailleurs la
langue est compositionnelle, c'est-&#224;-dire que la structure1 d'unit&#233;s langagi&#232;res complexes peut
                                                
</p>
<p>1 La question de savoir si une production langagi&#232;re, par exemple une phrase, a une ou des structures est une
question qui d&#233;pend du point de vue. D'une part, il est clair qu'on peut associer &#224; une phrase diff&#233;rentes
structures selon que l'on consid&#232;re le point de vue s&#233;mantique, syntaxique, morphologique ou phonologique.
D'autre part, les diff&#233;rentes structures d'une phrase ne sont pas ind&#233;pendantes les unes des autres et m&#234;me si ce
ne sont pas des structures sur les m&#234;mes objets (par exemple les n&#339;uds de la structure s&#233;mantique ne
correspondent pas un &#224; un aux n&#339;uds de la structure syntaxique, qui eux correspondent aux mots), il existe des
liens entre les diff&#233;rents objets de ces structures. En d'autres termes, en consid&#233;rant de fa&#231;on dissoci&#233;e les
diff&#233;rentes structures simples de la phrase, on ne rend pas compte de la structure compl&#232;te de la phrase,
puisqu'on perd les interrelations entre les structures simples.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Sylvain Kahane
</p>
<p>&#234;tre obtenue par composition de structures &#233;l&#233;mentaires associ&#233;es aux unit&#233;s &#233;l&#233;mentaires. Le
plus simple des modes de composition de deux structures A et B est l'unification, &#224; savoir la
construction d'une structure C en superposant partiellement A et B, c'est-&#224;-dire en identifiant une
partie des objets de A avec ceux de B. Cette id&#233;e rejoint une id&#233;e ancienne, d&#233;j&#224; pr&#233;sente chez
Jespersen 1924, Tesni&#232;re 1934 ou Ajduckiewicz 1935, que la phrase serait comme une mol&#233;cule
dont les mots seraient les atomes, chaque mot &#233;tant dot&#233; d'une certaine valence (terme
explicitement emprunt&#233; par la linguistique &#224; la chimie) qui l'oblige ou lui permet de s'assembler &#224;
un certain nombre d'autres mots. N&#233;anmoins, les grammaires d'unification (o&#249; l'unification est
prise au sens strict du terme) sont incapables de rendre compte du fait que la structure de
certaines unit&#233;s linguistiques est insatur&#233;e et que celles-ci doivent obligatoirement se combiner
avec d'autres unit&#233;s pour former une unit&#233; stable. Par exemple, la forme verbale voulait ne peut
former &#224; elle seule une phrase et appelle un sujet et un compl&#233;ment. La plupart des formalismes
&#224; base de r&#232;gles ne traitent pas directement dans le formalisme des r&#232;gles la question de la
saturation des structures g&#233;n&#233;r&#233;es. Par exemple, dans une grammaire de r&#233;&#233;criture, ce ne sont pas
les r&#232;gles de la grammaire qui assurent qu'une suite g&#233;n&#233;r&#233;e par la grammaire soit uniquement
compos&#233;e de symboles terminaux, mais une condition s&#233;par&#233;e, v&#233;rifi&#233;e ind&#233;pendamment et
compliquant par cons&#233;quent la proc&#233;dure de d&#233;rivation. En HPSG, la saturation est assur&#233;e par
des conditions obligeant certains traits &#224; avoir pour valeur une liste vide. L'utilisation de polarit&#233;s
permet d'incorporer le traitement de la saturation dans le formalisme des r&#232;gles. Le processus de
saturation va ainsi guider la composition des structures tout au long du processus de g&#233;n&#233;ration.
</p>
<p>Dans cet article, nous pr&#233;sentons une nouvelle famille de formalismes, les grammaires
d'unification polaris&#233;es (GUP). Les GUP prolongent les grammaires d'unification en proposant
un contr&#244;le tr&#232;s explicite de la saturation des structures par l'attribution &#224; chaque objet d'une
polarit&#233;. Certaines polarit&#233;s sont neutres, d'autres non, mais une structure finale doit
obligatoirement &#234;tre compl&#232;tement neutre. Deux objets non neutres peuvent s'unifier (c'est-&#224;-dire
en fait s'identifier) en formant un objet neutre, c'est-&#224;-dire en se neutralisant. L'unification
proprement dite ne permet rien d'&#233;quivalent. Le formalisme de Nasr (1995) est l'un des premiers
&#224; utiliser explicitement une polarisation des structures et Duchier &amp; Thater 1999 est la premi&#232;re
&#233;tude &#224; ma connaissance &#224; mettre en avant la question de la polarit&#233; (et &#224; introduire les termes
polarit&#233; et neutralisation), tandis que Perrier 2002 est le premier &#224; proposer un formalisme, les
grammaires d'interaction, enti&#232;rement bas&#233; sur ces id&#233;es.
</p>
<p>Dans la Partie 2, nous pr&#233;senterons le cadre g&#233;n&#233;ral des GUP et notamment le syst&#232;me des
polarit&#233;s. La Partie 3 proposera plusieurs exemples de GUP et tout particuli&#232;rement la traduction
en GUP de formalismes classiques comme les grammaires de r&#233;&#233;criture, TAG, HPSG ou LFG.
</p>
<p>2 Unification et polarit&#233;s
2.1 Grammaires d'unification polaris&#233;es
Les grammaires d'unification polaris&#233;es sont des grammaires permettant de g&#233;n&#233;rer des
ensembles de structures finies. Tous les types de structures sont a priori envisageables, mais
dans cet article nous ne consid&#233;rerons que des graphes orient&#233;s et notamment les cas particuliers
des dags2 et des arbres. Nous consid&#233;rerons &#233;galement des structures complexes obtenues en
combinant plusieurs structures sur les m&#234;mes objets.
</p>
<p>Une structure repose sur des objets. Par exemple, pour un graphe (orient&#233;), les objets sont les
n&#339;uds et les arcs. Ces deux types d'objets sont li&#233;s entre eux, ce qui fournit la structure
proprement dite : si X est l'ensemble des n&#339;uds et U l'ensemble des arcs, le graphe est d&#233;fini par
deux fonctions p1 et p2 de U dans X qui associent respectivement &#224; un arc sa source et sa cible.
                                                
</p>
<p>2 On appelle dag un graphe orient&#233; acyclique (angl. directed acyclic graph).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Grammaires d'unification polaris&#233;es
</p>
<p>Une structure polaris&#233;e est une structure dont les objets sont polaris&#233;s, c'est-&#224;-dire &#233;tiquet&#233;s par
une valeur appartenant &#224; un ensemble fini P de polarit&#233;s. L'ensemble P est muni d'une op&#233;ration
not&#233;e &quot;.&quot;, appel&#233;e produit. Le produit est commutatif et g&#233;n&#233;ralement associatif : (P,.) est appel&#233;
le syst&#232;me des polarit&#233;s. Un sous-ensemble N de P contient les polarit&#233;s dites neutres. Une
structure polaris&#233;e est dite neutre si tous les objets de cette structure sont neutres.
</p>
<p>Les structures peuvent &#234;tre combin&#233;es par unification. L'unification de deux structures A et B
donne une nouvelle structure A&#8853;B obtenue en &#171; collant &#187; ensemble ces structures par
l'identification d'une partie des objets de la premi&#232;re structure avec ceux de la deuxi&#232;me. Lorsque
deux structures  polaris&#233;es A et B sont unifi&#233;es, la polarit&#233; d'un objet de A&#8853;B obtenu par
identification de deux objets de A et B est le produit de leurs polarit&#233;s.
</p>
<p>Une grammaire d'unification polaris&#233;e (GUP) est d&#233;finie par une famille finie F de types
d'objets (avec des fonctions attach&#233;es aux diff&#233;rents types d'objets), un syst&#232;me (P,.) de polarit&#233;s,
un sous-ensemble N de P de polarit&#233;s neutres, et un ensemble fini de structures &#233;l&#233;mentaires
polaris&#233;es, dont les objets sont d&#233;crits par F et dont une est marqu&#233;e comme la structure initiale.
Les structures g&#233;n&#233;r&#233;es par la grammaire sont les structures neutres obtenues par combinaison
de la structure initiale et d'un nombre fini de structures &#233;l&#233;mentaires. Les polarit&#233;s sont
uniquement utilis&#233;es pour contr&#244;ler la saturation au cours du calcul et ne sont pas consid&#233;r&#233;es
lorsqu'on &#233;value la capacit&#233; g&#233;n&#233;rative de la grammaire. Bien que donn&#233;es sous une forme
d&#233;clarative, les polarit&#233;s jouent en fait un r&#244;le essentiellement proc&#233;dural.
</p>
<p>2.2 Le syst&#232;me des polarit&#233;s
Nous allons pr&#233;senter un syst&#232;me des polarit&#233;s P qui sera ensuite utilis&#233; dans tous nos
exemples. L'&#233;l&#233;ment neutre (au sens math&#233;matique du terme) de P est not&#233; &#8226; et appel&#233; gris
(&quot;x&#338;P, &#8226;.x=x). Le symbole &#8226; est une polarit&#233; neutre (&#8226;&#338;N) et peut &#234;tre interpr&#233;t&#233; comme un
contexte facultatif. Un contexte obligatoire est repr&#233;sent&#233; par la symbole &#162; appel&#233; blanc. Il s'agit
d'une polarit&#233; non neutre (&#162;&#339;N) qui se comporte comme un &#233;l&#233;ment neutre sauf avec &#8226; (&quot;x&#8800;&#8226;,
&#162;.x=x). Le symbole ^ repr&#233;sente l'&#233;chec et est par cons&#233;quent l'&#233;l&#233;ment absorbant de P (&quot;x&#338;P,
^.x=^). Evidemment, ^ n'est pas neutre et par l'impossibilit&#233; de le neutraliser, l'apparition de ^
bloque tout espoir de produire une structure neutre. Le symbole l, appel&#233; noir, repr&#233;sente la
saturation&quot;: il s'agit d'une polarit&#233; neutre qui ne peut &#234;tre combin&#233;e avec aucune autre polarit&#233;
que les deux pr&#233;c&#233;dentes (&quot;x&#8800;&#8226;/&#162;, l.x=^). Les symboles + et &#8211; repr&#233;sentent les polarit&#233;s
positive et n&#233;gative&quot;: ce sont des polarit&#233;s non neutres qui, combin&#233;es entre elles, donnent la
saturation et qui ne peuvent &#234;tre combin&#233;es avec elles-m&#234;mes ou avec la saturation (+.&#8211;=l,
+.+=^, +.l=^, &#8211;.&#8211;=^ et &#8211;.l=^). Le symbole &#8211; peut &#234;tre vu comme un besoin et + comme la
ressource correspondante.
</p>
<p>Le syst&#232;me {&#162;,l,^} est utilis&#233; par Nasr 1995, tandis que le syst&#232;me {&#8226;,l,&#8211;,+,^} est consid&#233;r&#233;
par Bonfante et al. 20033, qui montrent les avantages des polarit&#233;s n&#233;gatives et positives dans le
pr&#233;filtrage des objets en analyse syntaxique (une famille de structures comportant des polarit&#233;s
n&#233;gatives et positives ne pourront se combiner en une structure neutre que si la somme des
polarit&#233;s n&#233;gatives de chaque type d'objet est &#233;gale &#224; la somme des polarit&#233;s positives).
</p>
<p>Le syst&#232;me (P,.) que nous venons de pr&#233;senter est commutatif et associatif. La commutativit&#233; est
essentielle pour que la combinaison de deux structures ne soit pas proc&#233;duralement orient&#233;e.
L'associativit&#233; permet de rendre la combinaison des objets &#233;galement associative, c'est-&#224;-dire que
si un objet B doit se combiner avec A et C, il n'y a pas d'ordre de pr&#233;c&#233;dence entre la
combinaison de A et B et celle de B et C : A&#8853;(B&#8853;C) = (A&#8853;B)&#8853;C.
</p>
<p>                                                
</p>
<p>3 Ceux-ci utilisent les notations {=,&#180;,&#168;,&#198;,^}.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Sylvain Kahane
</p>
<p>Bien d'autres polarit&#233;s peuvent encore &#234;tre utiles. Par exemple, un besoin facultatif, not&#233; ?, aura
les m&#234;mes propri&#233;t&#233;s que la polarit&#233; n&#233;gative &#8211; (+.?=l, ?.?=^ et ?.l=^), mais sera neutre. Ou
encore, l'instanciation, au sens des structures de traits, not&#233;e ::, aura les m&#234;mes propri&#233;t&#233;s que la
saturation, mais pourra se combiner avec elle-m&#234;me (::.::=::). Dans la suite, nous utiliserons un
syst&#232;me avec deux polarit&#233;s neutres (&#8226;, l) et quatre polarit&#233;s non neutres (&#162;, +, &#8211;, ^).
</p>
<p>2.3 Monotonie
Tel que pr&#233;sent&#233; jusqu'&#224; maintenant, le formalisme des GUP est monotone aux polarit&#233;s pr&#232;s : le
r&#233;sultat A&#8853;B de la combinaison de deux structures A et B par une GUP contient A et B comme
sous-structures. On peut ajouter un ordre (partiel) sur P pour rendre le formalisme
compl&#232;tement monotone4. Notons &#8804; cet ordre. Pour que le formalisme soit monotone, &#8804; doit
v&#233;rifier la propri&#233;t&#233; de monotonie suivante : &quot;x,y&#338;P x.y &#8805; x&#8260;y, o&#249; x&#8260;y est le maximum de x et y.
Ceci nous impose d'avoir  &#8226; &lt; &#162; &lt; +/&#8211;/? &lt; l &lt; ^ et &#162; &lt; :: &lt; ^. Une GUP construite sur un
syst&#232;me ordonn&#233; (P,.,&#8804;) v&#233;rifiant la propri&#233;t&#233; de monotonie est monotone. Ceci induit de bonnes
propri&#233;t&#233;s computationnelles et permet par exemple de traduire l'analyse en GUP en un
probl&#232;me de r&#233;solution de contraintes (Duchier &amp; Thater 1999).
</p>
<p>3 Des exemples de GUP
3.1 Les grammaires d'arbres
Les premi&#232;res grammaires d'arbre rentrant dans le paradigme des GUP ont, &#224; ma connaissance,
&#233;t&#233; propos&#233;es par Nasr 1995. La grammaire G1 suivante permet de g&#233;n&#233;rer tous les arbres finis
(un arbre est un graphe orient&#233; connexe dont tous les n&#339;uds sont la cible d'au plus un arc) : les
objets sont des n&#339;uds et des arcs ; la structure initiale (plac&#233; dans le cadre de gauche) est r&#233;duite
&#224; un n&#339;ud noir ; la grammaire poss&#232;de une seule structure &#233;l&#233;mentaire qui est compos&#233;e d'un arc
noir reliant un n&#339;ud blanc &#224; un n&#339;ud noir. Chaque n&#339;ud blanc devra s'unifier avec un n&#339;ud
noir pour &#234;tre neutralis&#233; et un n&#339;ud noir pourra s'unifier avec un nombre quelconque de n&#339;uds
blancs. On v&#233;rifie ais&#233;ment que les structures g&#233;n&#233;r&#233;es par la grammaire sont bien des arbres,
puisque tout n&#339;ud aura un et un seul gouverneur &#224; l'exception du n&#339;ud introduit par la structure
initiale qui sera la racine de l'arbre. Dans nos figures, la double barre s&#233;pare la structure initiale
des autres structures &#233;l&#233;mentaires.
</p>
<p>G1 G2   G3
</p>
<p>La grammaire G1 ne permet pas de contr&#244;ler le nombre de fils de chaque n&#339;ud. Une grammaire
du type de G2 permet de contr&#244;ler la valence de chaque n&#339;ud, mais elle n'assure pas que les
structures g&#233;n&#233;r&#233;es sont des arbres puisque deux n&#339;uds blancs peuvent s'unifier et un n&#339;ud
peut donc avoir deux gouverneurs5. La grammaire G3 r&#233;sout le probl&#232;me en ne g&#233;n&#233;rant que des
                                                
</p>
<p>4 Cette id&#233;e m'a &#233;t&#233; sugg&#233;r&#233;e par Guy Perrier.
</p>
<p>5 Nasr 1995 propose une grammaire de ce type pour g&#233;n&#233;rer des arbres. Ceci est assur&#233; par une clause
proc&#233;durale qui oblige, lors de la combinaison de deux structures, la racine d'une des structures &#224; se combiner
avec un n&#339;ud de l'autre.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Grammaires d'unification polaris&#233;es
</p>
<p>S
</p>
<p>a
</p>
<p>a b c
</p>
<p>arbres. En fait, on peut voir G3 comme la superposition de G1 et G2. En effet, si P0 = {&#162;,l},
P1 &quot;= {&#162;,+,&#8211;,l} &#8801; P0&#165;P0, avec +=(&#162;,l) et &#8211;=(l,&#162;). La premi&#232;re polarit&#233; contr&#244;le la structure
d'arbre comme dans G1, tandis que la deuxi&#232;me contr&#244;le la valence comme dans G2.
</p>
<p>Avec les m&#234;mes principes, on peut construire une grammaire de d&#233;pendance g&#233;n&#233;rant les arbres
de d&#233;pendance syntaxique d'un fragmet de langue. La grammaire G4, directement inspir&#233;e de
Nasr 1995, propose un fragment de grammaire pour l'anglais permettant de g&#233;n&#233;rer l'arbre
syntaxique de Peter eats red beans. Les n&#339;uds de cette grammaire sont &#233;tiquet&#233;s par des
structures de traits qui devront s'unifier. Les traits et les valeurs des structures de traits sont
&#233;galements des objets qui peuvent (et doivent dans une GUP) &#234;tre polaris&#233;s (cf. plus loin la
repr&#233;sentation des structures de traits d'HPSG sous forme de dags). En attribuant des polarit&#233;s
positives et n&#233;gatives aux traits /cat/ plut&#244;t qu'aux n&#339;uds, on obtient une grammaire dans l'esprit
de Perrier 2002.
</p>
<p>G4 (Grammaire de d&#233;pendance pour l'anglais)
</p>
<p>3.2 Grammaires de r&#233;&#233;criture et arbres ordonn&#233;s
N'importe quelle grammaire de r&#233;&#233;criture peut &#234;tre simul&#233;e par une GUP. Nous reprenons ici
des id&#233;es d&#233;velopp&#233;es par Burroni 1993. Les GUP ont donc la capacit&#233; g&#233;n&#233;rative faible des
machines de Turing. Une suite abc est repr&#233;sent&#233;e par une cha&#238;ne d'arcs &#233;tiquet&#233;s a, b et c :
</p>
<p>La cat&#233;gorie initiale S de la grammaire donne la structure initiale :
</p>
<p>Une r&#232;gle de r&#233;criture ABC &#198; DE donne
la structure &#233;l&#233;mentaire :
</p>
<p>Cette structure &#233;l&#233;mentaire est une &#171;&quot;cellule&quot;&#187; dont le bord sup&#233;rieur est une cha&#238;ne d'arcs
positifs correspondant &#224; la partie gauche de la r&#232;gle, tandis que le bord inf&#233;rieur est une cha&#238;ne
d'arcs n&#233;gatifs correspondant &#224; la partie droite de la r&#232;gle. Chaque arc positif doit s'unifier avec
un arc n&#233;gatif et vice-versa pour donner un arc noir. Les n&#339;uds sont gris, c'est-&#224;-dire qu'ils sont
neutres et peuvent s'unifier entre eux.
</p>
<p>Un symbole terminal a correspond &#224; un arc positif :
</p>
<p>Les cellules vont venir s'unifier les unes aux autres pour donner une structure finale qui
repr&#233;sente la structure de d&#233;rivation d'une suite, la suite elle-m&#234;me &#233;tant le bord inf&#233;rieur de cette
structure. Nous donnons ci-apr&#232;s la structure de d&#233;rivation de la suite Peter eats red beans avec
une grammaire syntagmatique classique, que le lecteur reconstituera de lui-m&#234;me. Dans une telle
repr&#233;sentation, les arcs repr&#233;sentent des syntagmes et correspondent &#224; des intervalles de
d&#233;coupage de la suite et les n&#339;uds aux bornes de ces intervalles.
</p>
<p>A B C
</p>
<p>D E
</p>
<p>subj dobj
</p>
<p>cat: V
lex: eatcat: V
</p>
<p>cat: N
</p>
<p>cat: Adj
lex: red
</p>
<p>cat: N cat: N
</p>
<p>cat: N
lex: Peter
</p>
<p>modcat: N
lex: beans</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Sylvain Kahane
</p>
<p>Pour une grammaire de r&#233;&#233;criture hors-contexte, la grammaire g&#233;n&#232;re en fait l'arbre de
d&#233;rivation , que l'on peut repr&#233;senter de mani&#232;re traditionnelle en ajoutant les branches de l'arbre.
Les n&#339;uds de l'arbre de d&#233;rivation seront les arcs des cellules et une r&#232;gle du type A&quot;&#198; BCD
donnera la structure :
</p>
<p>Rappelons qu'un arbre de d&#233;rivation pour une grammaire de r&#233;&#233;criture hors-contexte est un arbre
ordonn&#233;. Un arbre ordonn&#233; combine deux structures sur un m&#234;me ensemble de n&#339;ud : une
structure d'arbre proprement dite et une relation de pr&#233;c&#233;dence sur les n&#339;uds de l'arbre. Ici la
relation de pr&#233;c&#233;dence est repr&#233;sent&#233;e de mani&#232;re explicite (un &#171;&quot;n&#339;ud&quot;&#187; de l'arbre pr&#233;c&#232;de un
autre &#171;&quot;n&#339;ud&quot;&#187; si la cible du premier est la source du deuxi&#232;me). Il n'est pas possible, avec une
GUP, de g&#233;n&#233;rer l'arbre de d&#233;rivation, relation de pr&#233;c&#233;dence comprise, de fa&#231;on plus simple6.
Notons que la repr&#233;sentation usuelle des arbres ordonn&#233;s (o&#249; la relation de pr&#233;c&#233;dence n'est pas
explicite, mais seulement d&#233;ductible de la plan&#233;it&#233; de la repr&#233;sentation) est fort trompeuse d'un
point de vue computationnel. En calculant la relation de pr&#233;c&#233;dence, les analyseurs syntaxiques
(du type CKY par exemple) calculent en fait une structure de donn&#233;es comme celle que nous
pr&#233;sentons ici, dont les n&#339;uds sont les d&#233;buts et les fins des syntagmes.
</p>
<p>3.3 TAG (Grammaire d'adjonction d'arbres)
Les GUP doivent beaucoup aux grammaires TAG qui sont les premi&#232;res grammaires de
combinaisons de structures &#224; avoir &#233;t&#233; &#233;tudi&#233;es en d&#233;tail. On pr&#233;sente g&#233;n&#233;ralement les
grammaires TAG comme des grammaires de combinaison d'arbres (ordonn&#233;s). En fait, en tant
que grammaires d'arbres, les TAG ne sont pas monotones et ne peuvent donc &#234;tre simul&#233;es par
une GUP. Comme l'a montr&#233; Vijay-Shanker 1992, il faut pour obtenir un formalisme monotone
consid&#233;rer TAG comme une grammaire de combinaison de quasi-arbres. Intuitivement, un
quasi-arbre est un arbre dont les n&#339;uds sont scind&#233;s en deux et poss&#232;dent donc une partie
sup&#233;rieure et une partie inf&#233;rieure, entre lesquelles peut venir s'intercaler un autre quasi-arbre
(c'est la fameuse op&#233;ration d'adjonction de TAG). Formellement, un quasi-arbre est un arbre
dont les branches sont de deux types : des relations de d&#233;pendance et des relations de dominance
(respectivement not&#233;s par un trait plein et un trait pointill&#233;). Deux n&#339;uds reli&#233;s par une relation
de dominance sont consid&#233;r&#233;s comme &#233;tant potentiellement les deux parties d'un m&#234;me n&#339;ud ;
</p>
<p>                                                
</p>
<p>6 L'id&#233;e la plus naturelle serait d'encoder une r&#232;gle de r&#233;&#233;criture par un arbre de profondeur 1 et la relation de
pr&#233;c&#233;dence par des arcs allant d'un n&#339;ud &#224; son successeur. La difficult&#233; est ensuite de propager la relation
d'ordre aux descendants de deux fr&#232;res lorsqu'on leur applique une r&#232;gle de r&#233;&#233;criture par substitution d'un arbre
de profondeur 1. La solution la plus simple est incontestablement celle pr&#233;sent&#233;e ici, consistant &#224; un
introduire des objets repr&#233;sentant les d&#233;buts et fins des syntagmes (nos n&#339;uds gris) et d'indiquer les relations
entre un syntagme, son d&#233;but et sa fin en repr&#233;sentant le syntagme par un arc allant de son d&#233;but &#224; sa fin.
</p>
<p>S
</p>
<p>NP
VP
</p>
<p>NPeter
</p>
<p>eats red
</p>
<p>Adj
beans
</p>
<p>NP
V
</p>
<p>A
</p>
<p>B
C
</p>
<p>D</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Grammaires d'unification polaris&#233;es
</p>
<p>seule la partie inf&#233;rieure peut avoir plusieurs fils. La figure ci-dessous donne un arbre a (= &#224;
substituer) et un arbre b (= &#224; adjoindre) avec les structures de la GUP correspondante7.
</p>
<p>Un arbre a et sa traduction GUP Un arbre b et sa traduction GUP
</p>
<p>Un n&#339;ud de substitution (comme D&#216;) donne un n&#339;ud n&#233;gatif, qui devra s'unifier avec la racine
d'un arbre a. Un arbre b poss&#232;de une racine et un n&#339;ud pied blancs qui devront s'unifier avec la
partie haute et la partie basse d'un n&#339;ud scind&#233;. Pour cette raison, la racine et le n&#339;ud pied sont
reli&#233;s par un lien de dominance positif qui devra s'unifier avec le lien de dominance n&#233;gatif
reliant les deux parties du site d'adjonction. A la fin de la d&#233;rivation, la structure doit &#234;tre un arbre
et tous les n&#339;uds doivent &#234;tre reconstitu&#233;s : pour cela nous introduisons la r&#232;gle suivante, qui
pr&#233;sente un lien de dominance positif reliant un n&#339;ud &#224; lui m&#234;me et qui en s'unifiant avec un lien
de dominance n&#233;gatif assurera la saturation de celui-ci et forcera l'unification de ses deux
extr&#233;mit&#233;s.
</p>
<p>Cette derni&#232;re r&#232;gle montre encore une fois l'avantage d'une GUP : la r&#233;unification des n&#339;uds
qui dans la pr&#233;sentation de Vijay-Shanker 1992 est donn&#233;e sous forme proc&#233;durale est ici
assur&#233;e par une r&#232;gle d&#233;clarative.
</p>
<p>3.4 HPSG (Grammaire syntagmatique guid&#233;e par les t&#234;tes)
Il est bien connu que les structures de traits (ST) peuvent &#234;tre vues comme des dags dont les arcs
repr&#233;sentent les traits et les n&#339;uds les valeurs (cf., par exemple, Kesper et M&#246;nnich 2003). Les
grammaires HPSG s'&#233;crivent donc simplement dans le formalisme des GUP. Il est important de
souligner au pr&#233;alable une diff&#233;rence essentielle entre l'unification de ST et l'unification de
structures dans les GUP : on consid&#232;re g&#233;n&#233;ralement qu'une ST poss&#232;de au plus un trait de
chaque sorte et, par cons&#233;quent, lors de l'unification de deux ST, les traits de m&#234;me sorte des
deux ST doivent &#234;tre identifi&#233;s et leurs valeurs unifi&#233;es. Il n'y a rien de tel pour les GUP : un
n&#339;ud d'un dag peut tr&#232;s bien &#234;tre la source de plusieurs arcs de m&#234;me &#233;tiquette et seule la
n&#233;cessit&#233; de neutraliser deux objets peut inciter &#224; les identifier (il y a aussi des identifications qui
r&#233;sultent de contraintes structurelles : l'identification de deux arcs entra&#238;ne l'identification de leurs
extr&#233;mit&#233;s).
</p>
<p>                                                
</p>
<p>7 Par souci de simplicit&#233;, nous laissons de c&#244;t&#233; dans notre pr&#233;sentation des grammaires TAG, l'encodage de la
relation de pr&#233;c&#233;dence sur les fils d'un m&#234;me n&#339;ud. Celle-ci devra &#234;tre encod&#233;e, comme nous l'avons fait pour
les grammaires de r&#233;&#233;criture hors-contexte, en mod&#233;lisant les semi-n&#339;uds des arbres TAG par des arcs. Ceci ne
pose aucune difficult&#233; particuli&#232;re, mais pourrait rendre les structures difficiles &#224; comprendre.
</p>
<p>A
</p>
<p>B
C
</p>
<p>D&#216;
</p>
<p>A
</p>
<p>B C
</p>
<p>C
</p>
<p>A
</p>
<p>B
</p>
<p>D
</p>
<p>A
</p>
<p>A* C
</p>
<p>D&#216;
</p>
<p>A
</p>
<p>C
</p>
<p>C
</p>
<p>A
</p>
<p>A
</p>
<p>D</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Sylvain Kahane
</p>
<p>Voyons donc comment traduire l'unification de ST en GUP. Consid&#233;rons le sch&#233;ma de base de
HPSG, &#224; savoir le sch&#233;ma head-daughter-phrase de combinaison d'un constituant t&#234;te avec un
sous-constituant fille sous-cat&#233;goris&#233;8 :
</p>
<p>HEAD:  1
SUBCAT:  3
HDTR: HEAD:  1
</p>
<p>SUBCAT: &#183;  2  &#210; &#8853;   3
NHDTR: HEAD:  2
</p>
<p>SUBCAT : elist
</p>
<p>Cette structure de traits donne le dag suivant, o&#249; une liste est repr&#233;sent&#233;e r&#233;cursivement en deux
morceaux : sa t&#234;te (valeur de H) et sa queue (valeur de Q). Nous pla&#231;ons &#224; la droite de ce dag
l'entr&#233;e lexicale pour eat indiquant que eat est un V dont la SUBCAT contient deux constituants
de cat&#233;gorie N (nous traitons le sujet comme un compl&#233;ment sous-cat&#233;goris&#233;).
</p>
<p>Comme nous l'avons dit, l'identification de deux arcs de m&#234;me &#233;tiquette et de m&#234;me source n'est
plus imm&#233;diate comme avec les ST. Elle est ici contr&#244;l&#233;e par la polarisation : une partie du dag
est une ressource (noir/gras ou positif) et une partie est un besoin (blanc/fin ou n&#233;gatif) qui
devra &#234;tre neutralis&#233;. En plus d'assurer l'unification compl&#232;te des ST, la polarisation permet
&#233;galement de forcer l'instanciation des listes SUBCAT (et par cons&#233;quent de contr&#244;ler la
saturation de la valence), ce qui n'est pas directement assur&#233; par le formalisme habituel des r&#232;gles
en HPSG. Notons que le fragment de grammaire HPSG donn&#233; ici est &#233;quivalent &#224; celui de G4 et
inutilement plus compliqu&#233;. Remarquons qu'&#224; la diff&#233;rence des arbres, on n'a pas de GUP qui
g&#233;n&#232;re tous les dags (on ne peut pas d&#233;celer des cycles de longueur potentiellement illimit&#233;e).
N&#233;anmoins, on peut assurer qu'une GUP ne g&#233;n&#232;re que des dags, notamment en obligeant
comme ici &#224; respecter une structure d'arbre sous-jacente : cela signifie qu'un n&#339;ud ne pourra
avoir deux gouverneurs dans une structure finale que si cela a &#233;t&#233; sp&#233;cifi&#233; par une structure
&#233;l&#233;mentaire.
</p>
<p>3.5 LFG (Grammaire lexicale fonctionnelle) et grammaires synchrones
Le formalisme de LFG permet de synchroniser une grammaire syntagmatique hors-contexte
avec une grammaire de d&#233;pendance. La grammaire de d&#233;pendance ne g&#233;n&#232;re pas des arbres, mais
des structures de traits r&#233;entrantes, appel&#233;es structures fonctionnelles, que nous repr&#233;sentons par
                                                
</p>
<p>8 Les num&#233;ros dans les bo&#238;tes indiquent des valeurs partag&#233;es par plusieurs traits. La valeur de SUBCAT est une
liste (la liste des constituants sous-cat&#233;goris&#233;s). Le constituant fille (NHDTR) doit &#234;tre satur&#233; et avoir donc
une liste SUBCAT vide (elist). La liste SUBCAT du sous-constituant t&#234;te (HDTR) est la concat&#233;nation,
not&#233;e &#8853;, de deux listes : une liste &#224; un &#233;l&#233;ment constitu&#233;e de la description du sous-constituant fille et la liste
SUBCAT du constituant complet. Le reste de la description de ce constituant (valeur de HEAD) est &#233;gal &#224;
celle de son sous-constituant t&#234;te.
</p>
<p>SC
HD
</p>
<p>H
</p>
<p>Q
SC
</p>
<p>HD
</p>
<p>SC
HD
</p>
<p>elist
</p>
<p>NHDTR
</p>
<p>HDTR
</p>
<p>eat
V
</p>
<p>Q
</p>
<p>H
cat
</p>
<p>lex
</p>
<p>Q elist
</p>
<p>SC
</p>
<p>HD
</p>
<p>HD cat N
H HD cat N</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Grammaires d'unification polaris&#233;es
</p>
<p>des dags, comme nous l'avons fait pour HPSG. Consid&#233;rons une premi&#232;re r&#232;gle LFG et sa
traduction GUP :
</p>
<p>   S &#198; NP VP
&#216; = &#8593;Subj &#216; =
</p>
<p>Les &#233;quations sous les cat&#233;gories assurent la synchronisation de la structure syntagmatique avec
la structure fonctionnelle. Chaque n&#339;ud syntagmatique est synchronis&#233; avec un n&#339;ud
&#171;&quot;fonctionnel&quot;&#187;. Les expressions &#216; et &#8593; renvoient respectivement au n&#339;ud fonctionnel
synchronis&#233; avec le n&#339;ud syntagmatique courant et &#224; celui synchronis&#233; avec le n&#339;ud
syntagmatique p&#232;re (ici S). L'&#233;quation &#216;=&#8593; signifie donc que le n&#339;ud syntagmatique courant et
son p&#232;re sont synchronis&#233;s avec le m&#234;me n&#339;ud fonctionnel. L'expression &#8593;Subj d&#233;signe le
n&#339;ud fonctionnel d&#233;pendant de &#8593; par la relation Subj. Dans la traduction, seul le lien de
synchronisation vers le n&#339;ud syntagmatique p&#232;re est satur&#233;. La structure fonctionnelle est
totalement blanche et elle sera satur&#233;e par une r&#232;gle lexicale comme :
</p>
<p>   V &#198; veut
&#8593;Pred = &#8216;vouloir&#183;Subj,VComp&#210;&#8217;
&#8593;Subj = &#8593;VCompSubj
</p>
<p>On notera que la r&#232;gle lexicale est enti&#232;rement traduite par des &#233;l&#233;ments satur&#233;s, &#224; l'exception des
&#233;l&#233;ments de la valence et des &#233;l&#233;ments introduits par une &#233;quation fonctionnelle, comme ici la
relation Subj entre les deux &#233;l&#233;ments de la valence introduite par &#8593;Subj = &#8593;VCompSubj.
</p>
<p>Donnons encore la traduction d'une r&#232;gle pour le traitement d'une interrogative indirecte avec
extraction de l'objet. Notons que la distinction entre &#233;quation contrainte (f =c v) et non contrainte
(f = v) est facilement prise en compte par les polarit&#233;s. La propagation de Comp* (qui
correspond, comme son nom l'indique, &#224; une s&#233;quence de d&#233;pendance Comp) est assur&#233;e par la
r&#232;gle en bas &#224; gauche et l'arr&#234;t de cette propagation par la r&#232;gle voisine.
</p>
<p>   S' &#198; NP S
&#216; = &#8593;Comp*Obj &#8593;Int = +
&#216;Wh =c +
</p>
<p>Encore une fois la traduction en GUP permet de mettre en &#233;vidence certaines composantes
fondamentales des r&#232;gles (comme les liens de synchronisation) et des m&#233;canismes non explicit&#233;s
comme la propagation de Comp* ou le fait qu'une &#233;quation lexicale comme &#8593;Pred =
&#8216;vouloir&#183;Subj,VComp&#210;&#8217; introduit &#224; la fois des ressources et des besoins.
</p>
<p>4 Conclusion
L'introduction de la polarisation des objets dans une grammaire d'unification permet de contr&#244;ler
la saturation des structures de mani&#232;re explicite. Proc&#233;duralement, le formalisme des GUP est
</p>
<p>S
</p>
<p>NP
Subj
</p>
<p>VP
</p>
<p>V
</p>
<p>veut
</p>
<p>Subj
</p>
<p>Pred
mp
</p>
<p>VComp
</p>
<p>Subj
</p>
<p>&#8216;vouloir&#8217;
</p>
<p>S'
</p>
<p>+
</p>
<p>S
</p>
<p>Comp*
</p>
<p>Obj
Wh +
</p>
<p>Int
</p>
<p>Comp*
</p>
<p>Comp
Comp*
</p>
<p>Comp*
</p>
<p>NP</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Sylvain Kahane
</p>
<p>extr&#234;mement simple : il impose seulement que la combinaison de deux structures mette en jeu
l'unification d'au moins un objet. L'obligation ou l'interdiction de combiner davantage d'objets est
ensuite enti&#232;rement contr&#244;l&#233;e par la polarisation des objets. La polarisation va donc guider la
proc&#233;dure de combinaison des structures &#233;l&#233;mentaires. Malgr&#233; sa simplicit&#233;, le formalisme des
GUP est suffisamment puissant pour simuler &#233;l&#233;gamment la quasi-totalit&#233; des formalismes
utilis&#233;s en linguistique formelle et en TAL9. Cela permet &#224; la fois d'obtenir un &#233;clairage nouveau
sur ces formalismes, de mettre en &#233;vidence la nature exacte des structures qu'ils manipulent et
d'extraire certains m&#233;canismes proc&#233;duraux masqu&#233;s par le formalisme. Mais surtout, le
formalisme des GUP permet d'&#233;crire s&#233;par&#233;ment divers modules de la grammaire manipulant des
structures diff&#233;rentes et de les coupler ensuite en un m&#234;me formalisme, comme cela est par
exemple fait en GUST (Kahane 2002). Les GUP fournissent ainsi une alternative aux
formalismes d'unification bas&#233;s sur les structures de traits en permettant une plus grande
diversit&#233; des structures g&#233;om&#233;triques et un meilleur contr&#244;le des ressources. Les propri&#233;t&#233;s
computationnelles des GUP restent &#224; &#233;tudier et notamment les restrictions qui permettent d'avoir
une analyse en temps polynomial.
</p>
<p>Remerciements
Je remercie Beno&#238;t Crabb&#233;, Kim Gerdes, Piet Mertens, Guy Perrier, Alain Polgu&#232;re et Beno&#238;t
Sagot pour leurs nombreuses remarques et leurs commentaires &#233;clairants.
</p>
<p>R&#233;f&#233;rences
AJDUKIEWICZ K. (1935), Die syntaktische Konnexit&#228;t, Studia Philosophica, Vol. 1, 1-27.
BONFANTE G., GUILLAUME B., PERRIER G. (2003), Analyse syntaxique &#233;lectrostatique, TAL.
BURRONI A. (1993), Higher-dimensional word problems with applications to equational logic,
Theoretical Computer Sciences, Vol. 115, 43-62.
DUCHIER D., THATER S., 1999, Parsing with tree descriptions: a constraint-based approach,
NLULP 1999 (Natural Language Understanding and Logic Programming), Las Cruces, NM.
KAHANE S. (2002), Grammaire d'Unification Sens-Texte : vers un mod&#232;le math&#233;matique
articul&#233; de la langue, Habilitation &#224; diriger les recherches, Universit&#233; Paris 7, 82 p.
KESPER S., M&#214;NNICH U. (2003), Graph properties of HPSG feature structures, Formal
Grammar 2003, 115-124.
NASR A. (1995), A formalism and a parser for lexicalised dependency grammars, 4th Int.
Workshop on Parsing Tecnologies, State Univ. of NY Press.
PERRIER G. (2002), Descriptions d'arbres avec polarit&#233;s : les Grammaires d'Interaction, TALN
2002, Nancy.
ROGERS J., VIJAY-SHANKER K. (1992), Reasoning with descriptions of trees, ACL 1992, 72-80.
TESNIERE Lucien, 1934, Comment construire une syntaxe, Bulletin de la Facult&#233; des Lettres de
Strasbourg,Vol. 7, 12&#232;me ann&#233;e, 219-229.
VIJAY-SHANKER K. (1992), Using description of trees in a Tree Adjoining Grammar,
Computational Linguistics, Vol. 18, n&#176;4, 481-517.
</p>
<p>                                                
</p>
<p>9 Aux formalismes pr&#233;sent&#233;s ici, nous pouvons ajouter une partie des grammaires cat&#233;gorielles, traduites en
GUP par Perrier 2002 sous le nom de grammaires d'interaction. Rappelons encore une fois que la pr&#233;sente
contribution doit beaucoup &#224; ce travail pr&#233;curseur.</p>

</div></div>
</body></html>