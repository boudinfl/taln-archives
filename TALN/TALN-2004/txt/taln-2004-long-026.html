<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Approche statistique pour le rep&#233;rage de mots informatifs dans les textes oraux</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2004, F&#232;s, 19&#8211;21 avril 2004
</p>
<p>Approche statistique pour le rep&#233;rage de mots informatifs
dans les textes oraux
</p>
<p>Narj&#232;s Boufaden (1), Yoshua Bengio (2), Guy Lapalme (1)
(1) Laboratoire RALI - Universit&#233; de Montr&#233;al
</p>
<p>Qu&#233;bec, Canada
boufaden@iro.umontreal.ca, lapalme@iro.umontreal.ca
</p>
<p>(2) Laboratoire LISA - Universit&#233; de Montr&#233;al
Qu&#233;bec, Canada
</p>
<p>bengioy@iro.umontreal.ca
</p>
<p>R&#233;sum&#233; - Abstract
</p>
<p>Nous pr&#233;sentons les r&#233;sultats de l&#8217;approche statistique que nous avons d&#233;velopp&#233;e pour le rep&#233;-
rage de mots informatifs &#224; partir de textes oraux. Ce travail fait partie d&#8217;un projet lanc&#233; par le
d&#233;partement de la d&#233;fense canadienne pour le d&#233;veloppement d&#8217;un syst&#232;me d&#8217;extraction d&#8217;in-
formation dans le domaine de la Recherche et Sauvetage maritime (SAR). Il s&#8217;agit de trouver
et annoter les mots pertinents avec des &#233;tiquettes s&#233;mantiques qui sont les concepts d&#8217;une on-
tologie du domaine (SAR). Notre m&#233;thode combine deux types d&#8217;information : les vecteurs
de similarit&#233; g&#233;n&#233;r&#233;s gr&#226;ce &#224; l&#8217;ontologie du domaine et le dictionnaire-th&#233;saurus Wordsmyth ;
le contexte d&#8217;&#233;nonciation repr&#233;sent&#233; par le th&#232;me. L&#8217;&#233;valuation est effectu&#233;e en comparant la
sortie du syst&#232;me avec les r&#233;ponses de formulaires d&#8217;extraction d&#8217;information pr&#233;d&#233;finis. Les
r&#233;sultats obtenus sur les textes oraux sont comparables &#224; ceux obtenus dans le cadre de MUC7
pour des textes &#233;crits .
</p>
<p>We present results of a statistical method we developped for the detection of informative words
from manually transcribed conversations. This work is part of an ongoing project for an infor-
mation extraction system in the field of maritime Search And Rescue (SAR). Our purpose is
to automatically detect relevant words and annotate them with concepts from a SAR ontology.
Our approach combines similarity score vectors and topical information. Similarity vectors are
generated using a SAR ontology and the Wordsmyth dictionary-thesaurus. Evaluation is carried
out by comparing the output of the system with key answers of predefined extraction templates.
Results on speech transcriptions are comparable to those on written texts in MUC7.
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>&#201;tiquetage s&#233;mantique, extraction d&#8217;information
Semantic tagging, information extraction</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Narj&#232;s Boufaden, Yoshua Bengio, Guy Lapalme
</p>
<p>1 Introduction
</p>
<p>Le rep&#233;rage de mots informatifs consiste &#224; d&#233;tecter des mots qui apportent de l&#8217;information
pertinente1 relativement &#224; un domaine particulier. Cette t&#226;che est une &#233;tape charni&#232;re pour
beaucoup d&#8217;applications du Traitement Automatique de la Langue (TAL) telles que l&#8217;extrac-
tion d&#8217;information et la g&#233;n&#233;ration automatique de r&#233;sum&#233;. Dans cet article nous &#233;tudions le
rep&#233;rage de mots informatifs pour l&#8217;extraction d&#8217;information (EI) &#224; partir de textes oraux.
</p>
<p>L&#8217;extraction d&#8217;information (EI) a pour but la collecte d&#8217;informations pertinentes dans un do-
maine d&#8217;application particulier. Les approches d&#8217;EI pour les textes &#233;crits se basent en g&#233;n&#233;ral
sur le contexte imm&#233;diat (partie de phrase) des mots informatifs pour les d&#233;tecter (Appelt et al.,
1993; Aberdeen et al., 1996). Les approches symboliques utilisant des patrons d&#8217;extraction ainsi
que les approches d&#8217;apprentissage bas&#233;es sur les HMM (Leek, 1997; McCallum et al., 2000) ou
les r&#232;gles d&#8217;induction (Riloff, 1998; Soderland et al., 1995) sont des exemples classiques utili-
sant le contexte imm&#233;diat. Toutes ces approches reposent sur l&#8217;hypoth&#232;se de la grammaticalit&#233;
des textes et de ce fait sont inad&#233;quates pour les textes oraux.
</p>
<p>L&#8217;approche que nous pr&#233;sentons diff&#232;re des approches classiques d&#8217;EI con&#231;ues pour les textes
&#233;crits notamment par sa robustesse aux extra-grammaticalit&#233;s pr&#233;sentent dans les textes oraux.
Nous utilisons le contenu du mot et le contexte d&#8217;&#233;nonciation repr&#233;sent&#233; par le th&#232;me de l&#8217;&#233;nonc&#233;
pour rep&#233;rer les mots informatifs. les mots potentiellement pertinents sont identifi&#233;s gr&#226;ce &#224;
leur contenu (par opposition au contexte syntaxique d&#233;finit par une partie de phrase). Cela
contourne les probl&#232;mes des irr&#233;gularit&#233;s grammaticales caus&#233;es par les r&#233;p&#233;titions ou omis-
sions, par exemple, tr&#232;s pr&#233;sentes dans les textes oraux. De plus, le th&#232;me que l&#8217;on associe &#224; un
&#233;nonc&#233; d&#233;finit un contexte de nature s&#233;mantique moins vuln&#233;rable aux extra-grammaticalit&#233;s et
permet de s&#233;lectionner les mots informatifs parmi ceux qui sont potentiellement pertinents. De
fait, le th&#232;me joue un r&#244;le de d&#233;sambiguisation.
</p>
<p>Dans ce qui suit nous d&#233;crivons d&#8217;abord le corpus utilis&#233; pour ce projet (section 2), puis, les
diff&#233;rentes parties du syst&#232;me d&#8217;EI (section 3). Ensuite, nous explicitons le mod&#232;le utilis&#233; pour
le rep&#233;rage de mots informatifs (section 4) et pr&#233;sentons les r&#233;sultats de nos exp&#233;riences (section
5). Enfin, nous comparons nos r&#233;sultats &#224; ceux de travaux existants (section 6).
</p>
<p>2 Cadre de projet et description du corpus
</p>
<p>Ce travail fait partie d&#8217;un projet qui a pour but d&#8217;impl&#233;menter un syst&#232;me d&#8217;EI pour rep&#233;rer
des informations ayant un lien avec les missions de recherche et sauvetage maritimes (domaine
SAR) tels que la nature de l&#8217;incident, l&#8217;endroit de l&#8217;incident, les ressources allou&#233;es pour la
recherche et les conditions m&#233;t&#233;orologiques pendant la mission de recherche. Le projet a &#233;t&#233;
men&#233; par le Centre de Recherche de la D&#233;fense Valcartier (CRDV) afin de d&#233;velopper un outil
d&#8217;aide &#224; la g&#233;n&#233;ration de plan de SAR &#224; partir de conversations t&#233;l&#233;phoniques manuellement
transcrites.
</p>
<p>Le corpus est une collection de 95 conversations t&#233;l&#233;phoniques transcrites manuellement (39.000
mots). Dans la plupart des cas ce sont des conversations impliquant deux locuteurs (l&#8217;appelant
Caller et un op&#233;rateur Operator) qui discutent des conditions et circonstances entourant un in-
</p>
<p>1Dans la suite de l&#8217;article, nous utilisons par abus de langage le mot &#8217;pertinent&#8217; pour signifier &#8217;pertinent par
rapport au domaine de la Recherche et Sauvetage&#8217;.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Approche statistique pour le rep&#233;rage de mots informatifs dans les textes oraux
</p>
<p>1-O :Hi, it&#8217;s Mr. Joe Blue
&#65080; &#65079;&#65079; &#65080;
</p>
<p>.
</p>
<p>PERSON
</p>
<p>&#8212;&#8212;&#8212;&#8212;&#8212;&#8211; OTHER&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-
3-O :We get an overdue boat
</p>
<p>&#65080; &#65079;&#65079; &#65080;
, missing boat
</p>
<p>&#65080; &#65079;&#65079; &#65080;
</p>
<p>on the South Coast of Newfoundland
&#65080; &#65079;&#65079; &#65080;
</p>
<p>...
</p>
<p>VESSEL VESSEL LOCATION
</p>
<p>&#8212;&#8212;&#8212;&#8212;&#8212;&#8211; INCIDENT&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-
4-O :They did a radar search
</p>
<p>&#65080; &#65079;&#65079; &#65080;
for us in the area
</p>
<p>&#65080; &#65079;&#65079; &#65080;
.
</p>
<p>DETECTION LOCATION
</p>
<p>5-C :Hum, hum.
&#8212;&#8212;&#8212;&#8212;&#8212;&#8211; MISSION&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-
8-O :And I am wondering
</p>
<p>&#65080; &#65079;&#65079; &#65080;
</p>
<p>about the possibility
&#65080; &#65079;&#65079; &#65080;
</p>
<p>of outputting
&#65080; &#65079;&#65079; &#65080;
</p>
<p>an Aurora
&#65080; &#65079;&#65079; &#65080;
</p>
<p>in there for radar search
&#65080; &#65079;&#65079; &#65080;
</p>
<p>.
</p>
<p>STATUS STATUS TASK SAR-AIRCRAFT DETECTION
&#8212;&#8212;&#8212;&#8212;&#8212;&#8211; SEARCH UNIT&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-
</p>
<p>11-O :They got a South East
&#65080; &#65079;&#65079; &#65080;
</p>
<p>to be flowing
&#65080; &#65079;&#65079; &#65080;
</p>
<p>there and it&#8217;s just gonna
&#65080; &#65079;&#65079; &#65080;
</p>
<p>be black thicker fog
&#65080; &#65079;&#65079; &#65080;
</p>
<p>the whole,
</p>
<p>STATUS DIRECTION STATUS WEATHER
</p>
<p>12-C :OK.
&#8212;&#8212;&#8212;&#8212;&#8212;&#8211; MISSION&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-
</p>
<p>FIG. 1 &#8211; Exemple d&#8217;une conversation indiquant un incident :an overdue boat, une requ&#234;te pour
allouer des avions SAR pour la recherche : Aurora. Les mots en gras italiques sont reconnus
par l&#8217;&#233;tiqueteur s&#233;mantique (section 3.3). Tandis que les mots en gras uniquement sont des
candidats pour le rep&#233;rages de mots informatifs (section 4) . Les &#233;tiquettes sous les groupes de
mots en gras sont des concepts de l&#8217;ontologie. Les lignes horizontales sont les fronti&#232;res des
th&#232;mes (MISSION, INCIDENT, SEARCH UNIT, OTHER) ajout&#233;s manuellement.
</p>
<p>cident ou une mission de recherche et sauvetage. Les conversations sont : (1) des rapports
d&#8217;incidents survenus tels qu&#8217;une personne port&#233;e disparue ou un bateau en retard, (2) l&#8217;&#233;labo-
ration d&#8217;un plan de sauvetage tels que l&#8217;allocation d&#8217;avions et de bateaux pour les besoins de la
recherche, (3) le compte rendu d&#8217;une mission de sauvetage et les r&#233;sultats de cette mission ou
une combinaison des ces trois cas. La Figure 1 donne un extrait de ces conversations.
</p>
<p>Le corpus est particuli&#232;rement bruit&#233; et certaines parties d&#8217;&#233;nonc&#233;s sont remplac&#233;es par le mot
&#8220;INAUDIBLE&#8221; pour indiquer que l&#8217;enregistrement est incompr&#233;hensible. Plus de la moiti&#233; des
&#233;nonc&#233;s contiennent au moins une extra-grammaticalit&#233; (Shriberg, 1994) telles que les r&#233;p&#233;ti-
tions (Ha, do, is there, is there . . .) , les omissions et interruptions (we&#8217;ve been, _ actually had a
. . .). Enfin, nous avons comptabilis&#233; 3% d&#8217;erreurs de transcriptions qui apparaissent en majorit&#233;
dans les mots informatifs comme c&#8217;est le cas dans l&#8217;&#233;nonc&#233; 11-O o&#249; le mot flowing devrait
&#234;tre blowing (Figure 1).
</p>
<p>3 Architecture du syst&#232;me d&#8217;extraction d&#8217;information
</p>
<p>L&#8217;extraction d&#8217;information s&#8217;&#233;labore en quatre &#233;tapes. L&#8217;&#233;tape I est l&#8217;analyse syntaxique et la
d&#233;tection des groupes de mots candidats &#224; l&#8217;extraction. Ce sont essentiellement les groupes
nominaux, verbaux, adverbiaux et adjectivaux. L&#8217;&#233;tape II, l&#8217;&#233;tiquetage s&#233;mantique, annote les</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Narj&#232;s Boufaden, Yoshua Bengio, Guy Lapalme
</p>
<p>groupes de mots avec les concepts qu&#8217;il reconna&#238;t gr&#226;ce &#224; l&#8217;ontologie du domaine que nous
avons construie. L&#8217;&#233;tape III, permet le rep&#233;rage et l&#8217;&#233;tiquetage s&#233;mantique de groupes de mots
informatifs qui ne font pas partie de l&#8217;ontologie du domaine et par cons&#233;quent qui n&#8217;ont pu &#234;tre
&#233;tiquet&#233;s &#224; l&#8217;&#233;tape pr&#233;c&#233;dente. Enfin, les groupes de mots extraits sont utilis&#233;s dans le processus
de r&#233;solution de cor&#233;f&#233;rence pour, ensuite, remplir les formulaires d&#8217;extraction. La Figure 2
illustre l&#8217;architecture du syst&#232;me d&#8217;extraction d&#8217;information.
</p>
<p>Dans la prochaine section, nous d&#233;crivons de mani&#232;re concise les trois premi&#232;res &#233;tapes, la
conception de l&#8217;ontologie du domaine SAR et la segmentation en th&#232;mes. (Boufaden, 2003;
Boufaden et al., 2002; Boufaden et al., 2001) pr&#233;sentent une description d&#233;taill&#233;e de ces mo-
dules. La r&#233;solution de cor&#233;f&#233;rence et le remplissage de formulaires d&#8217;extraction sont laiss&#233;s
pour des travaux futurs. Le rep&#233;rage des groupes de mots informatifs qui fait l&#8217;objet de cet
article est d&#233;taill&#233; dans la section 4.
</p>
<p>Conversation
transcrite
</p>
<p>&#1;&#1;
&#233;tape I :Analyse syntaxique . . .. . .. . .. . .. . .
</p>
<p>Extraction
des groupes de mots
</p>
<p>&#1;&#1;
&#233;tape II :&#201;tiquetage s&#233;mantique . . .. . .. . .. . .. . .
</p>
<p>&#201;tiquetage
s&#233;mantique
</p>
<p>&#1;&#1;
</p>
<p>Ontologie
SAR
</p>
<p>&#2;&#2;
</p>
<p>&#3;&#3;&#1;&#1;&#1;
&#1;&#1;&#1;
</p>
<p>&#1;&#1;&#1;
&#1;&#1;&#1;
</p>
<p>&#1;&#1;&#1;
&#1;&#1;&#1;
</p>
<p>Stage III :Rep&#233;rage des
mots informatifs
</p>
<p>. . .. . .. . .. . .. . .
</p>
<p>Calcul des vecteurs
de similarit&#233;
</p>
<p>&#1;&#1;
</p>
<p>Dictionnaire
th&#233;saurus
</p>
<p>Wordsmyth
&#2;&#2;
</p>
<p>Mod&#232;le statistique
</p>
<p>&#1;&#1;
</p>
<p>Annotation
de th&#232;mes
</p>
<p>&#2;&#2;
</p>
<p>&#233;tape IV :Remplissage
des formulaires
</p>
<p>. . .. . .. . .. . .. . . Segmentation
en th&#232;mes
</p>
<p>&#4;&#4;
</p>
<p>&#5;&#5;&#2;&#2;&#2;&#2;
&#2;&#2;
</p>
<p>R&#233;solution de cor&#233;f&#233;rence
et
</p>
<p>g&#233;n&#233;ration des formulaires d&#8217;EI
</p>
<p>FIG. 2 &#8211; Cette figure pr&#233;sente les principales composantes du syst&#232;me d&#8217;EI. Les rectangles
simples repr&#233;sentent les modules qui ont d&#233;j&#224; &#233;t&#233; d&#233;velopp&#233;s et sont d&#233;crits bri&#232;vement dans
les sections 3.1, 3.2 et 3.3. Le rectangle en gras est le module qui fait l&#8217;objet de cet article. Les
rectangles en pointill&#233;s sont des modules laiss&#233;s pour des travaux futurs.
</p>
<p>3.1 Segmentation en th&#232;mes
</p>
<p>Le mot th&#232;me utilis&#233; dans plusieurs travaux (Carbonell et al., 1999; Hearst, 1994) ne jouit pas
d&#8217;une d&#233;finition formelle. Selon l&#8217;application cible, le th&#232;me peut varier du sujet d&#8217;un texte au
propos d&#8217;une partie d&#8217;un texte. (Hearst, 1994; Brown &amp; Beorge, 1983) s&#8217;accordent pour dire
que la notion de th&#232;me dans un contexte de segmentation de textes implique que les phrases</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Approche statistique pour le rep&#233;rage de mots informatifs dans les textes oraux
</p>
<p>sont regroup&#233;es naturellement selon leur &#8217;propos&#8217;2. Dans le cadre de notre application, nous
avons d&#233;velopp&#233; un module de segmentation en th&#232;mes qui permet de regrouper les &#233;nonc&#233;s
adjacents qui portent sur un aspect de la mission, tels que l&#8217;annonce d&#8217;un incident (&#233;nonc&#233; 3-O
Figure 1) ou le r&#233;sultat d&#8217;une mission de recherche et sauvetage. Dans (Boufaden et al., 2001;
Boufaden et al., 2002), nous montrons qu&#8217;en utilisant des connaissances pragmatiques, s&#233;man-
tiques, syntaxiques et lexicales, il est possible moyennant un mod&#232;le de Markov de g&#233;n&#233;rer les
changements de th&#232;mes3 avec un rappel de 61,4% et une pr&#233;cision de 67,3%.
</p>
<p>3.2 Ontologie du domaine
</p>
<p>L&#8217;ontologie du domaine est une composante fondamentale dans notre approche de rep&#233;rage
des mots informatifs. Elle est utilis&#233;e lors de l&#8217;&#233;tiquetage s&#233;mantique (section 3.3) et pour la
g&#233;n&#233;ration des vecteurs de similarit&#233; (Boufaden, 2003). L&#8217;ontologie du domaine est utilis&#233;e pour
quantifier la pertinence d&#8217;un mot par rapport au domaine. Dans la section 4.2, nous montrons
que la probabilit&#233; qu&#8217;un mot soit informatif est une fonction du degr&#233; de similarit&#233; de ce mot
par rapport aux concepts du domaine SAR.
</p>
<p>L&#8217;ontologie a &#233;t&#233; construite &#224; partir de manuels fournis par le Secr&#233;tariat de la Recherche et
Sauvetage Nationale et d&#8217;un &#233;chantillon de 10 conversations choisies au hasard. Elle est consti-
tu&#233;e de mots ou groupes de mots informatifs tels que radar search, diving pour les
moyens de d&#233;tections, drifting, overdue pour les incidents et wind, rain, fog pour les
conditions m&#233;t&#233;orologiques. Ces mots sont des exemples de r&#233;ponses pour les champs des for-
mulaires d&#8217;EI. Ils sont regroup&#233;s en 24 classes et organis&#233;es en une hi&#233;rarchie IS-A et une autre
PART-OF. Les classes de l&#8217;ontologie forment les concepts pertinents du domaine SAR. Ils sont
utilis&#233;s pour &#233;tiqueter les mots informatifs comme nous l&#8217;expliquons dans la section 4. Enfin,
chaque entr&#233;e de l&#8217;ontologie contient un mot informatif, une liste exhaustive de synonymes ex-
traite de Wordsmyth4 et leur d&#233;finitions textuelles aussi extraites du dictionnaire-th&#233;saurus. La
Figure 3 est un exemple des entr&#233;es de Wordsmyth que nous avons utilis&#233; pour la construction
de l&#8217;ontologie.
</p>
<p>3.3 &#201;tiquetage s&#233;mantique
</p>
<p>L&#8217;&#233;tiqueteur s&#233;mantique est similaire &#224; un module d&#8217;extraction d&#8217;entit&#233;s nomm&#233;es (MUC, 1998).
Il reconna&#238;t des entit&#233;s nomm&#233;es telles que les lieux, les personnes, les organisations, les noms
d&#8217;avions, de bateaux et de mat&#233;riel de d&#233;tection. Il est bas&#233; sur un automate &#224; &#233;tats finis qui
effectue l&#8217;&#233;tiquetage en deux &#233;tapes illustr&#233;es dans la Figure 4. La premi&#232;re &#233;tape recherche
un appariement entre la t&#234;te du syntagme analys&#233; et les instances des concepts de l&#8217;ontologie.
Lorsque un appariement r&#233;ussit, le t&#234;te est annot&#233;e par le concept dont le mot est une instance.
La deuxi&#232;me &#233;tape sert &#224; propager l&#8217;&#233;tiquette s&#233;mantique de la t&#234;te du syntagme vers tout le
syntagme. La sortie de l&#8217;&#233;tiqueteur s&#233;mantique est repr&#233;sent&#233;e par les mots en gras italique
dans la Figure 1. Dans (Boufaden, 2003), nous montrons que l&#8217;&#233;tiqueteur s&#233;mantique attribue
</p>
<p>2Ce terme est la traduction de &#8217;aboutness&#8217; selon le glossaire fran&#231;ais-anglais de terminologie linguistique SIL
http ://www.sil.org/linguistics/
</p>
<p>3Les changements de th&#232;mes sont repr&#233;sent&#233;s par une &#233;tiquette. Quatre autres sont utilis&#233;es pour distinguer les
&#233;nonces qui font partie d&#8217;un segment de th&#232;me de celles qui clos le segment de th&#232;me, qui initient une conversation
ou qui indiquent la fin d&#8217;une conversation
</p>
<p>4URL http ://www.wordsmyth.net/.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Narj&#232;s Boufaden, Yoshua Bengio, Guy Lapalme
</p>
<p>ENT: wonder
SYL: won-der
PRO: wuhn dEr
POS: intransitive verb
INF: wondered, wondering, wonders
DEF: 1. to experience a sensation of admiration or amazement (of-
ten fol. by at):
EXA: She wondered at his bravery in combat.
SYN: marvel
SIM: gape, stare, gawk
DEF: 2. to be curious or skeptical about something:
EXA: I wonder about his truthfulness.
SYN: speculate (1)
SIM: deliberate, ponder, think, reflect, puzzle, conjecture
...
</p>
<p>FIG. 3 &#8211; Description d&#8217;une entr&#233;e du dictionnaire-th&#233;saurus Wordsmyth pour le verbe wonder
qui est un verbe g&#233;n&#233;ralement utilis&#233; pour formuler une requ&#234;te pour allouer du mat&#233;riel de re-
cherche. Ce verbe a pour &#233;tiquette le concept STATUS (8-O Figure 1). Les acronymes ENT, SYL,
PRO, POS, INF, DEF, EXA, SYN, SIM sont respectivement l&#8217;entr&#233;e, la syllabe, la prononciation,
la cat&#233;gorie syntaxique, les formes fl&#233;chies, la d&#233;finition textuelle, un exemple, les mots syno-
nymes et les mots similaires. Pour construire notre ontologie nous avons utilis&#233; les informations
contenues dans les champs ENT, DEF, SYN et SIM.
</p>
<p>les concepts avec un rappel de 85,3% et une pr&#233;cision de 94,8%.
</p>
<p>&#201;tape 1 : . . .SN : black thicker fog
&#65080;&#65079;&#65079;&#65080;
</p>
<p>. . .
</p>
<p>WEATHER-TYPE
&#8592; Propagation
</p>
<p>&#201;tape 2 : . . .SN : black thicker fog
&#65080; &#65079;&#65079; &#65080;
</p>
<p>. . .
</p>
<p>WEATHER-TYPE
</p>
<p>FIG. 4 &#8211; Le syntagme nominal SN : black thicker fog est &#233;tiquet&#233; avec le concept WEATHER
(&#233;nonce 11-O). La premi&#232;re &#233;tape de l&#8217;analyse s&#233;mantique reconna&#238;t la t&#234;te fog comme un type
de conditions climatiques. La deuxi&#232;me &#233;tape propage le concept &#224; tout le syntagme nominal.
</p>
<p>4 Rep&#233;rage des mots informatifs
</p>
<p>Le rep&#233;rage de mots informatifs est une fonction du contexte d&#8217;&#233;nonciation repr&#233;sent&#233; par le
th&#232;me T et de la pertinence du mot par rapport aux concepts Ck de l&#8217;ontologie. Pour calculer
la pertinence, nous utilisons le contenu du mot w repr&#233;sent&#233; par sa d&#233;finition textuelle Dw,
la mesure de similarit&#233; OC5 (Manning &amp; Schutze, 2001) (section 4.2) et l&#8217;ontologie. Chaque
mot est repr&#233;sent&#233; par un vecteur de similarit&#233; qui contient les scores de similarit&#233; sim(w,Ck)
obtenus pour chaque concept Ck de l&#8217;ontologie. Le th&#232;me permet d&#8217;&#233;carter les faux positifs
qui sont les mots w tel que w proche (selon la mesure de similarit&#233; ) d&#8217;un concept Ck et Ck
</p>
<p>5Overlap Coefficient.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Approche statistique pour le rep&#233;rage de mots informatifs dans les textes oraux
</p>
<p>est rarement observ&#233; dans le contexte d&#8217;&#233;nonciation ayant pour th&#232;me T . Dans ce qui suit,
nous pr&#233;sentons le mod&#232;le de rep&#233;rage. La section 4.2 d&#233;crit la mod&#233;lisation de la distribution
des concepts sachant les mots. Ce mod&#232;le permet de calculer P (Ck|wt) &#224; partir des scores de
similarit&#233; sim(wt, Ck) (&#201;quation 2). La section 4.3 explicite la mod&#233;lisation de la distribution
des concepts Ck &#233;tant donn&#233; les th&#232;mes Tt.
</p>
<p>4.1 Mod&#232;le
</p>
<p>Une formulation de notre probl&#233;matique est : chercher le concept Ck qui maximise la similarit&#233;
pour un mot wt et Ck fr&#233;quemment observ&#233; &#233;tant donn&#233; le th&#232;me Tt. Cela se traduit par un
produit d&#8217;experts. Un expert, P (Ct|wt), mod&#233;lise la distribution des concepts sachant le mot ;
l&#8217;autre, P (Ct|Tt), mod&#233;lise la distribution des concepts sachant le th&#232;me. Les coefficients &#946;1 et
&#946;2 sont des poids qui refl&#232;tent la contribution de chacun des experts dans le mod&#232;le de rep&#233;rage.
</p>
<p>Lorsque les deux experts P (Ct|Tt) et P (Ct|wt) s&#8217;entendent sur le concept qui maximise ces
deux probabilit&#233;s, il est facile de conclure que wt est informatif. Le cas non trivial est lorsque
les experts ne s&#8217;entendent pas sur le concept. Dans ce cas la d&#233;cision repose sur un seuil de
confiance &#948; d&#233;termin&#233; de mani&#232;re empirique (&#201;quation 1). Un mot wt est consid&#233;r&#233; informatif
lorsque P (C&#8727;|wt, Tt) est sup&#233;rieur &#224; &#948;. L&#8217;&#233;quation 1 d&#233;crit le mod&#232;le P (C&#8727;|wt, Tt).
</p>
<p>P (Ct = k|wt, Tt) = P (Ct = k|wt)
&#946;1P (Ct = k|Tt)&#946;2
</p>
<p>&#931;Kl=1P (Ct = l|w&#946;1t P (Ct = l|Tt)&#946;2
(1)
</p>
<p>et
</p>
<p>C&#8727; = argmax
Ct
</p>
<p>P (Ct|wt, Tt), P (C&#8727;|wt, Tt) &gt; &#948;
k est un des K concepts de l&#8217;ontologie, logP (Ct = k|wt) repr&#233;sente la log probabilit&#233;
d&#8217;observer le concept k &#233;tant donn&#233; le mot wt et logP (Ct = k|Tt) est la log probabilit&#233;
d&#8217;observer le concept k &#233;tant donn&#233; le th&#232;me Tt.
</p>
<p>4.2 Distribution des concepts par rapport &#224; un mot
</p>
<p>La pertinence d&#8217;un mot est quantifi&#233;e en utilisant la mesure de similarit&#233; OC. Cette mesure
correspond &#224; la proportion de mots en commun, contenus dans la d&#233;finition textuelle du mot et
celle d&#8217;un concept (&#201;quation 2). Un mot est jug&#233; proche du domaine lorsqu&#8217;un des scores de
similarit&#233; est &#233;lev&#233; pour un concept donn&#233;. (Boufaden, 2003) pr&#233;sente l&#8217;algorithme qui permet
de calculer les scores de similarit&#233;s et de g&#233;n&#233;rer les vecteurs de similarit&#233;.
</p>
<p>sim(w(l), Ck) =
| Dw(l) | &#8745; | DCk |
</p>
<p>min(| Dw(l) |, | DCk |)
(2)
</p>
<p>w(l) repr&#233;sente un sens particulier l du mot w et Ck un concept de l&#8217;ontologie du domaine.
Dw(l) et DCk sont respectivement les ensembles de mots lemmatis&#233;s extraits des d&#233;finitions
textuelles de w(l) et Ck. Les d&#233;finitions textuelles sont extraites &#224; partir de Wordsmyth.
</p>
<p>La distribution d&#8217;un concept par rapport &#224; un mot P (Ck|wt) s&#8217;exprime en fonction de la proba-
bilit&#233; d&#8217;observer un concept Ck &#233;tant donn&#233; un sens particulier w(l) du mot w et la probabilit&#233;
d&#8217;observer un sens particulier w(l) sachant w. P (Ck|w(l)) est obtenue par une redistribution</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Narj&#232;s Boufaden, Yoshua Bengio, Guy Lapalme
</p>
<p>des scores du vecteur de similarit&#233; afin d&#8217;attribuer une probabilit&#233; tr&#232;s faible aux scores nuls.
Aussi, pour simplifier nos calculs nous supposons que les sens d&#8217;un mot sont &#233;quiprobables
(&#201;quation 3).
</p>
<p>P (Ck|w) =
&#8721;
</p>
<p>w(l)&#8712;S(w)
P (Ck|w(l))P (w(l)|w), (3)
</p>
<p>P (w(l)|w) = 1| S(w) |
Avec w(l) &#8712; S(w) sont les diff&#233;rents sens du mot w, P (Ck|w(l)) est le score de similarit&#233;
normalis&#233; entre le concept Ck &#233;tant donn&#233; un sens w(l) de w et P (w(l)|w) est la probabilit&#233;
d&#8217;observer le sens w(l) &#233;tant donn&#233; le mot w.
</p>
<p>4.3 Distribution des concepts par rapport &#224; un th&#232;me
</p>
<p>Selon le d&#233;coupage effectu&#233; &#224; l&#8217;&#233;tape de segmentation (section 3.1), un segment est compos&#233;
d&#8217;&#233;nonc&#233;s dont le th&#232;me peut &#234;tre class&#233; en cinq cat&#233;gories :(1)MISSING_OBJECT qui englobe
toutes les informations faisant r&#233;f&#233;rence &#224; l&#8217;objet impliqu&#233; dans un incident ; (2)INCIDENT qui
d&#233;crit l&#8217;incident, sa cause et l&#8217;endroit o&#249; il s&#8217;est produit ; (3)SEARCH_UNIT qui rapporte les faits
et actes des &#233;quipes de recherches ; (4)MISSION qui d&#233;crit les conditions m&#233;t&#233;orologiques lors
de la mission, l&#8217;endroit o&#249; sont effectu&#233;es les recherches ; (5)OTHER qui contient toutes autres
informations qui n&#8217;a pas de lien directe avec le type d&#8217;information recherch&#233;e (section 2). La
probabilit&#233; P (Ct|Tt) est d&#233;finie par l&#8217;&#233;quation :
</p>
<p>P (Ct|Tt) = &#945;P0(Ct) + (1&#8722; &#945;)P1(Ct|Tt) (4)
</p>
<p>CT est la s&#233;quence des concepts observ&#233;s, TT la s&#233;quence des th&#232;mes observ&#233;s. &#945; est le
param&#232;tre libre de notre mod&#232;le. P0(Ct) est la fr&#233;quence relative des concepts dans le
corpus d&#8217;entra&#238;nement et P1(Ct|Tt) la fr&#233;quence relative des concepts sachant le th&#232;me.
</p>
<p>5 Exp&#233;riences et r&#233;sultats
</p>
<p>Le corpus d&#8217;entra&#238;nement est constitu&#233; de 1850 mots, soit 65% des 64 conversations anno-
t&#233;es manuellement avec les concepts de l&#8217;ontologie et les th&#232;mes. Les r&#233;sultats sont obtenus
en comparant les concepts g&#233;n&#233;r&#233;s par le mod&#232;le de rep&#233;rage aux r&#233;ponses des formulaires
pr&#233;alablement annot&#233;es avec les concepts de l&#8217;ontologie. Le Tableau 1 donne le rappel et la
pr&#233;cision obtenus pour le seuil &#948; = 0.35. Ce seuil est calcul&#233; de mani&#232;re empirique sur le cor-
pus de test. Afin de comparer le mod&#232;le bas&#233; sur la similarit&#233; et le mod&#232;le exponentiel nous
avons consid&#233;r&#233; uniquement les P (Ct|wt) &gt; 0.02. Pour des rappels &#233;quivalents (38, 5% pour
P (Ct|wt) et 36, 8% pour P (Ct|wt, Tt)) le mod&#232;le exponentiel performe mieux que la mod&#232;le
bas&#233; uniquement sur la similarit&#233;. Bien que le mod&#232;le bas&#233; sur les th&#232;mes ait une faible perfor-
mance, celui-ci a permis d&#8217;augmenter la pr&#233;cision du rep&#233;rage de mots informatifs de 16,2 %.
La moyenne performance du mod&#232;le bas&#233; sur la similarit&#233; est probablement due &#224; l&#8217;approxi-
mation faite pour passer du vecteur de scores de similarit&#233; vers P (Ct|wt). Une am&#233;lioration
possible est de repr&#233;senter P (Ct|wt) comme une mixture de gaussiennes o&#249; chaque gaussienne
est une fonction de la similarit&#233; par rapport &#224; un concept donn&#233;. Le r&#233;sultat modeste du mod&#232;le
de rep&#233;rage de mots informatifs est en partie d&#251; aux erreurs d&#8217;&#233;tiquetage syntaxique caus&#233;es
par les extra-grammaticalit&#233;s qui engendrent un score de similarit&#233; erron&#233;. Par ailleurs, &#224; cause</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Approche statistique pour le rep&#233;rage de mots informatifs dans les textes oraux
</p>
<p>P (Ct|Tt) P (Ct|wt) P (Ct|Tt, wt)
Mots Pr&#233;cision Rappel Pr&#233;cision Rappel Pr&#233;cision Rappel
Tous 37,4% 44% 73,33% 76,1% 61,45% 55%
Informatifs 34,6% 21,8% 64,7% 38,5% 75,2% 36,8%
</p>
<p>TAB. 1 &#8211; Classification des mots wt par rapports aux 24 concepts Ct de l&#8217;ontologie. Les mots
informatifs sont les r&#233;ponses des champs des formulaires d&#8217;extraction. Les r&#233;sultats du mod&#232;le
P (Ct|wt) sont obtenus en ne consid&#233;rant que les probabilit&#233;s P (Ct|wt) &gt; 0.02. Le r&#233;sultat du
mod&#232;le P (Ct|Tt, wt) est obtenu pour le seuil de confiance optimale &#948; = 0.35
</p>
<p>de la taille modeste de notre corpus d&#8217;entra&#238;nement, nous avons opt&#233; pour des param&#232;tres &#946;1 et
&#946;2 ind&#233;pendants du concept. Cependant, la disparit&#233; de la distribution des concepts (le concept
STATUS &#224; lui seul repr&#233;sente 29,5% du corpus d&#8217;entra&#238;nement) dans le corpus d&#8217;entra&#238;nement
fait que les coefficients &#946;1 et &#946;2 sont influenc&#233;s de mani&#232;re &#224; favoriser une meilleure classi-
fication du concept pr&#233;dominant. Le passage vers un mod&#232;le o&#249; les param&#232;tres d&#233;pendent du
concept permettrait une meilleure performance.
</p>
<p>6 Conclusion
</p>
<p>Le rep&#233;rage de mots informatifs est une t&#226;che fondamentale pour plusieurs applications de TAL
tels que l&#8217;extraction d&#8217;information. La plupart des approches &#233;labor&#233;es pour les textes &#233;crits
se basent sur l&#8217;utilisation de patrons formul&#233;s par des r&#232;gles ou par des mod&#232;les stochastiques
(Leek, 1997; Riloff, 1998). Dans les deux cas, la structure des phrases pertinentes constitue une
partie importante des connaissances a priori prises en compte dans la d&#233;finition de la d&#233;marche
d&#8217;extraction. Ces approches performantes pour les textes &#233;crits sont inad&#233;quates pour les textes
oraux qui ne pr&#233;sentent pas de structures phrastiques r&#233;guli&#232;res. Pour pallier ce probl&#232;me, nous
avons d&#233;velopp&#233; une approche bas&#233;e sur le contenu des mots et sur le th&#232;me associ&#233; au contexte
d&#8217;&#233;nonciation.
</p>
<p>Afin d&#8217;&#233;valuer la performance du syst&#232;me, nous avons compar&#233; nos r&#233;sultats avec ceux obtenus
lors de MUC7 pour la t&#226;che d&#8217;extraction des objets6 &#8217;Template Object&#8217; &#224; partir de textes &#233;crits
(MUC, 1998). Le F-score7 obtenu pour les mots informatifs est de 74.65% alors que le meilleur
r&#233;sultat obtenu lors de MUC7 est de 80%.
</p>
<p>Enfin, bien que l&#8217;approche pr&#233;sent&#233;e soit con&#231;ue pour les textes oraux, celle-ci pr&#233;sente des
avantages int&#233;ressant pour les textes &#233;crits. En particulier, une approche bas&#233;e sur le contenu
des mots permet un raisonnement sur le sens des mots plut&#244;t que sur le mot en tant qu&#8217;unit&#233;
lexicale. Une telle approche est un atout pour rem&#233;dier aux variations langagi&#232;res tr&#232;s pr&#233;sentes
dans les textes &#233;crits. De plus, l&#8217;absence d&#8217;extra-grammaticalit&#233;s dans les textes &#233;crits permet
d&#8217;envisager un meilleur r&#233;sultat pour les textes &#233;crits.
</p>
<p>6Cela correspond &#224; l&#8217;extraction des objets qui participent aux &#233;v&#232;nements. Dans notre cas les &#233;v&#232;nements sont
les incidents
</p>
<p>7Le F-score utilis&#233; pour MUC7 est F = (&#946;+1)P.R&#946;2.P+R et &#946; = 0.5</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Narj&#232;s Boufaden, Yoshua Bengio, Guy Lapalme
</p>
<p>Remerciements
</p>
<p>Nous remercions Robert Parks pour nous avoir donn&#233; acc&#232;s &#224; la version &#233;lectronique de Word-
smyth ainsi que le Secr&#233;tariat National de la Recherche et Sauvetage pour les manuels de SAR.
</p>
<p>R&#233;f&#233;rences
</p>
<p>MUC(1998). Proceedings of the seventh Message Understanding Conference (MUC-7). Morgan Kauff-
man.
</p>
<p>ABERDEEN J., BURGER J., DAY D., HIRSCHMAN L., PALMER D., ROBINSON P. &amp; VILAIN M.
(1996). MITRE :Description of the Alembic System as Used in MET. In Proceedings of the TIPSTER
24-Months Workshop.
</p>
<p>APPELT E., HOBBS J., BEAR J., ISRAEL D. &amp; TYSON M. (1993). FASTUS : A Finite-state Processor
for Information Extraction from Real-world Text. In Proceedings of IJCAI, p. 1172&#8211;1178.
</p>
<p>BOUFADEN N. (2003). An Ontology-based Semantic Tagger for IE System. In 41st. Annual Meeting of
the Association for Computational Linguistics(ACL) : Student Workshop, p. 7&#8211;14, Sapporo, Japon.
</p>
<p>BOUFADEN N., LAPALME G. &amp; BENGIO Y. (2001). Topic Segmentation : A First Stage to Dialog-based
Information Extraction. In Natural Language Processing Rim Symposium, NLPRS&#8217;01, p. 273&#8211;280.
</p>
<p>BOUFADEN N., LAPALME G. &amp; BENGIO Y. (2002). D&#233;coupage th&#233;matique des conversations : un outil
d&#8217;aide &#224; l&#8217;extraction. In Actes de Traitement Automatique de la Langue, volume I, p. 377&#8211;382, Nancy,
France.
</p>
<p>BROWN G. &amp; BEORGE Y. (1983). Discourse Analysis. Cambridge Textbooks in Linguistics Series.
Canbridge University Press.
</p>
<p>CARBONELL J., YIMMING Y., LAFERTY J., R.D B., PIERCE T. &amp; LIU X. (1999). CMU Report on
TDT-2 : Segmentation, Detection and Tracking. In DARPA Broadcast News Workshop.
</p>
<p>HEARST M. (1994). Multi-paragraph Segmentation of Expository Text. In 32nd. Annual Meeting of the
Association for Computational Linguistics (ACL), p. 9&#8211;16, New Mexico State University, Las Cruces,
New Mexico.
</p>
<p>LEEK T. (1997). Information Extraction Using Hidden Markov Model. Master&#8217;s thesis, University of
California, San Diego, CA.
</p>
<p>MANNING C. D. &amp; SCHUTZE H. (2001). Foundations of Statistical Natural Language Processing,
chapter Word Sense Disambiguiation, p. 294&#8211;303. The MIT Press Cambridge, Massachussets London
England.
</p>
<p>MCCALLUM A., FREITAG D. &amp; PEREIRA F. (2000). Maximum Entropy Markov Models for Informa-
tion Extraction and Segmentation. In Prroceedings of ICML-2000.
</p>
<p>RILOFF E. (1998). Automatically Generating Extraction Patterns from Untagged Text. In Proceedings
of the Thirteenth National Conference on Artificial Intelligence (AAAI-96), p. 1044&#8211;1049.
</p>
<p>SHRIBERG E. (1994). Preliminaries to a Theory of Speech Disfluencies. PhD thesis, University of
California at Berkeley.
</p>
<p>SODERLAND S., FISHER D., ASELTINE J. &amp; W. L. (1995). Crystal : Inducing a Conceptual Dictionary.
In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (IJCAI-95), p.
1314&#8211;1319, Menlo Park.</p>

</div></div>
</body></html>