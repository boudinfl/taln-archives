TALN 2004, Fés, 19-21 avril 2004

Approche statistique pour le repérage de mots informatifs
dans les textes oraux

Narjes Boufaden (1), Yoshua Bengio (2), Guy Lapalme (1)
(1) Laboratoire RALI — Université de Montréal
Québec, Canada
boufaden@iro.umontreal.ca, lapalme@iro.umontreal.ca
(2) Laboratoire LISA — Université de Montréal
Québec, Canada
bengioy@iro.umontreal.ca

Résumé - Abstract

Nous présentons les résultats de l’approche statistique que nous avons développée pour le repe-
rage de mots informatifs a partir de textes oraux. Ce travail fait partie d’un projet lance’ par le
département de la défense canadienne pour le développement d’un systeme d’extraction d’in—
formation dans le domaine de la Recherche et Sauvetage maritime (SAR). ll s’agit de trouver
et annoter les mots pertinents avec des étiquettes se’mantiques qui sont les concepts d’une on-
tologie du domaine (SAR). Notre méthode combine deux types d’information : les vecteurs
de similarite’ génére’s grace a l’ontologie du domaine et le dictionnaire—the’saurus Wordsmyth;
le contexte d’énonciation représenté par le theme. L’évaluation est effectuée en comparant la
sortie du systeme avec les réponses de formulaires d’extraction d’information prédéﬁnis. Les
résultats obtenus sur les textes oraux sont comparables a ceux obtenus dans le cadre de MUC7
pour des textes écrits .

We present results of a statistical method we developped for the detection of informative words
from manually transcribed conversations. This work is part of an ongoing project for an infor-
mation extraction system in the ﬁeld of maritime Search And Rescue (SAR). Our purpose is
to automatically detect relevant words and annotate them with concepts from a SAR ontology.
Our approach combines similarity score vectors and topical information. Similarity vectors are
generated using a SAR ontology and the Wordsmyth dictionary—thesaurus. Evaluation is carried
out by comparing the output of the system with key answers of predeﬁned extraction templates.
Results on speech transcriptions are comparable to those on written texts in MUC7.

Mots-clefs — Keywords

Etiquetage sémantique, extraction d’information
Semantic tagging, information extraction

Narjes Boufaden, Yoshua Bengio, Guy Lapalme

1 Introduction

Le reperage de mots informatifs consiste a detecter des mots qui apportent de l’information
pertinentel relativement a un domaine particulier. Cette tache est une etape charniere pour
beaucoup d’applications du Traitement Automatique de la Langue (TAL) telles que l’extrac—
tion d’information et la generation automatique de resume. Dans cet article nous etudions le
reperage de mots informatifs pour l’extraction d’information (El) a partir de textes oraux.

L’extraction d’information (El) a pour but la collecte d’informations pertinentes dans un do-
maine d’application particulier. Les approches d’EI pour les textes ecrits se basent en general
sur le contexte immediat (partie de phrase) des mots informatifs pour les detecter (Appelt et al.,
1993; Aberdeen et al., 1996). Les approches symboliques utilisant des patrons d’extraction ainsi
que les approches d’apprentissage basees sur les HMM (Leek, 1997; McCallum et al., 2000) ou
les regles d’induction (Riloff, 1998; Soderland et al., 1995) sont des exemples classiques utili-
sant le contexte immediat. Toutes ces approches reposent sur l’hypothese de la grammaticalite
des textes et de ce fait sont inadequates pour les textes oraux.

L’approche que nous presentons differe des approches classiques d’EI congues pour les textes
ecrits notamment par sa robustesse aux extra—grammaticalites presentent dans les textes oraux.
Nous utilisons le contenu du mot et le contexte d’enonciation represente par le theme de l’enonce
pour reperer les mots informatifs. les mots potentiellement pertinents sont identiﬁes grace a
leur contenu (par opposition au contexte syntaxique deﬁnit par une partie de phrase). Cela
contourne les problemes des irregularites grammaticales causees par les repetitions ou omis-
sions, par exemple, tres presentes dans les textes oraux. De plus, le theme que l’on associe a un
enonce deﬁnit un contexte de nature semantique moins vulnerable aux extra—grammaticalites et
permet de selectionner les mots informatifs parmi ceux qui sont potentiellement pertinents. De
fait, le theme joue un role de desambiguisation.

Dans ce qui suit nous decrivons d’abord le corpus utilise pour ce projet (section 2), puis, les
differentes parties du systeme d’EI (section 3). Ensuite, nous explicitons le modele utilise pour
le reperage de mots informatifs (section 4) et presentons les resultats de nos experiences (section
5). Enﬁn, nous comparons nos resultats a ceux de travaux existants (section 6).

2 Cadre de projet et description du corpus

Ce travail fait partie d’un projet qui a pour but d’implementer un systeme d’EI pour reperer
des informations ayant un lien avec les missions de recherche et sauvetage maritimes (domaine
SAR) tels que la nature de l’incident, l’endroit de l’incident, les ressources alloue’es pour la
recherche et les conditions me’te’orologiques pendant la mission de recherche. Le projet a ete
mene par le Centre de Recherche de la Defense Valcartier (CRDV) aﬁn de developper un outil
d’aide a la generation de plan de SAR a partir de conversations telephoniques manuellement
transcrites.

Le corpus est une collection de 95 conversations telephoniques transcrites manuellement (39.000
mots). Dans la plupart des cas ce sont des conversations impliquant deux locuteurs (l’appelant
Caller et un operateur Operator) qui discutent des conditions et circonstances entourant un in-

1Dans la suite de Particle, nous utilisons par abus de langage le mot ’pertinent’ pour signiﬁer ’perI:inent par
rapport au domaine de la Recherche et Sauvetage’.

Approche statistique pour le repérage de mots informatifs dans les textes oraux

1—O :Hi, it’s Mr. Joe Blue.
L4

PERSON
———— —— OTHER————————
3—O :We get an overdue boat, missing boat on the South Coast of Newfoundland...
mm \ 1 x V 1

V

VESSEL VESSEL LOCATION

———— —— INCIDENT— — — — — — ——
4—O :They did a radar search for us in the area.

ma +,_4

DETECTION LOCATION
5—C :Hum, hum.
———— —— MISSION— — — — — — ——
8—O :And I am wondering about the possibilitx of putputting an Aurora in there for radar search.

STATUS STATUS TASKV SAR—AIRCRAFT DETECTION
———— —— SEARCH UNIT— — — — — — ——

11—O :They got a South East to be ﬂowing there and it’s just gonna be black thicker fog the whole,
T +,_4 »V_a C

STATUS DIRECTION STATUS WEATHER
12—C :OK.
———— —— MISSION— — — — — — ——

FIG. 1 — Exemple d’une conversation indiquant un incident :an overdue boat, une requéte pour
allouer des avions SAR pour la recherche : Aurora. Les mots en gras italiques sont reconnus
par l’étiqueteur sémantique (section 3.3). Tandis que les mots en gras uniquement sont des
candidats pour le repérages de mots informatifs (section 4) . Les étiquettes sous les groupes de
mots en gras sont des concepts de l’ontologie. Les lignes horizontales sont les frontiéres des
themes (MISSION, INCIDENT, SEARCH UNIT, OTHER) ajoutés manuellement.

cident ou une mission de recherche et sauvetage. Les conversations sont : (1) des rapports
d’incidents survenus tels qu’une personne portée disparue ou un bateau en retard, (2) l’élabo—
ration d’un plan de sauvetage tels que l’allocation d’aVions et de bateaux pour les besoins de la
recherche, (3) le compte rendu d’une mission de sauvetage et les résultats de cette mission ou
une combinaison des ces trois cas. La Figure 1 donne un extrait de ces conversations.

Le corpus est particulierement bruité et certaines parties d’énonce’s sont remplacées par le mot
“INAUDIBLE” pour indiquer que l’enregistrement est incompréhensible. Plus de la moitié des
énoncés contiennent au moins une eXtra—grammaticalite’ (Shriberg, 1994) telles que les répe’ti—
tions (Ha, do, is there, is there . . .) , les omissions et interruptions (we’Ve been, _ actually had a
. . .). Enﬁn, nous avons comptabilise’ 3% d’erreurs de transcriptions qui apparaissent en majorite’
dans les mots informatifs comme c’est le cas dans l’énoncé 11-0 ou le mot flowing devrait
étre blowing (Figure 1).

3 Architecture du systéme d’extr'action d’inf0r'mati0n

L’eXtraction d’information s’élabore en quatre étapes. L’étape I est l’analyse syntaxique et la
détection des groupes de mots candidats 51 l’eXtraction. Ce sont essentiellement les groupes
nominaux, Verbaux, adverbiaux et adjectivaux. L’étape II, l’e’tiquetage sémantique, annote les

Narjés Boufaden, Yoshua Bengio, Guy Lapalme

groupes de mots avec les concepts qu’il reconnait grace a l’ontologie du domaine que nous
avons construie. L’étape III, permet le repérage et l’e’tiquetage sémantique de groupes de mots
informatifs qui ne font pas partie de l’ontologie du domaine et par consequent qui n’ont pu étre
étiquetés a l’étape précédente. Enﬁn, les groupes de mots extraits sont utilisés dans le processus
de résolution de coréférence pour, ensuite, remplir les formulaires d’eXtraction. La Figure 2
illustre l’architecture du systeme d’eXtraction d’information.

Dans la prochaine section, nous décrivons de maniere concise les trois premieres étapes, la
conception de l’ontologie du domaine SAR et la segmentation en themes. (Boufaden, 2003;
Boufaden et al., 2002; Boufaden et al., 2001) présentent une description détaille’e de ces mo-
dules. La résolution de coréférence et le remplissage de formulaires d’eXtraction sont laissés
pour des travaux futurs. Le repérage des groupes de mots informatifs qui fait l’objet de cet
article est détaille’ dans la section 4.

Conversation
trans cnte

étape I :Analyse syntaxique

Extraction
des groupes de mots

étape II :Etiquetage sémantique

Etiquetage Ontologie

 

 

sémantique SAR
Stage III :Repérage des
mots infomiatifs

Calcul des vecteurs Dtlﬁélggllﬁﬁlsre

de similarité Wordsmyth

~ - - §'A'iiii¢£:;{tik$h'

Modele statistique E de thémes E

A
étape IV :Remplissage __ __ _ __ __ _ __ __ Segmentation
des formulaires en themes
4/.
Resolution de coréférence '

et 
génération des formulaires d’EI 

FIG. 2 — Cette ﬁgure présente les principales composantes du systeme d’EI. Les rectangles
simples représentent les modules qui ont de’ja e’té de’Veloppe’s et sont décrits brievement dans
les sections 3.1, 3.2 et 3.3. Le rectangle en gras est le module qui fait l’objet de cet article. Les
rectangles en pointillés sont des modules laissés pour des travaux futurs.

3.1 Segmentation en thémes

Le mot théme utilise’ dans plusieurs travaux (Carbonell et al., 1999; Hearst, 1994) ne jouit pas
d’une deﬁnition formelle. Selon l’application cible, le théme peut Varier du sujet d’un texte au
propos d’une partie d’un texte. (Hearst, 1994; Brown & Beorge, 1983) s’accordent pour dire
que la notion de théme dans un contexte de segmentation de textes implique que les phrases

Approche statistique pour le repérage de mots informatifs dans les textes oraux

sont regroupées naturellement selon leur ’propos’2. Dans le cadre de notre application, nous
avons développe’ un module de segmentation en themes qui perrnet de regrouper les énonce’s
adjacents qui portent sur un aspect de la mission, tels que l’annonce d’un incident (énonce’ 3-0
Figure 1) ou le re’sultat d’une mission de recherche et sauvetage. Dans (Boufaden et al., 2001;
Boufaden et al., 2002), nous montrons qu’en utilisant des connaissances pragmatiques, séman-
tiques, syntaxiques et lexicales, il est possible moyennant un modele de Markov de géne’rer les
changements de themes3 avec un rappel de 61,4% et une précision de 67,3%.

3.2 Ontologie du domaine

L’ontologie du domaine est une composante fondamentale dans notre approche de repérage
des mots informatifs. Elle est utilise’e lors de l’étiquetage sémantique (section 3.3) et pour la
ge’nération des vecteurs de similarite’ (Boufaden, 2003). L’ ontologie du domaine est utilise’e pour
quantiﬁer la pertinence d’un mot par rapport au domaine. Dans la section 4.2, nous montrons
que la probabilite’ qu’un mot soit informatif est une fonction du degre’ de similarite’ de ce mot
par rapport aux concepts du domaine SAR.

L’ontologie a été construite a partir de manuels fournis par le Secretariat de la Recherche et
Sauvetage Nationale et d’un échantillon de 10 conversations choisies au hasard. Elle est consti-
tue’e de mots ou groupes de mots informatifs tels que radar search, diving pour les
moyens de détections, drifting, overdue pour les incidents et wind, rain, fog pour les
conditions me’téorologiques. Ces mots sont des exemples de réponses pour les champs des for-
mulaires d’EI. Ils sont regroupe’s en 24 classes et organisées en une hiérarchie IS—A et une autre
PART—OF. Les classes de l’ontologie forment les concepts pertinents du domaine SAR. Ils sont
utilisés pour étiqueter les mots informatifs comme nous l’eXpliquons dans la section 4. Enﬁn,
chaque entre’e de l’ontologie contient un mot informatif, une liste exhaustive de synonymes ex-
traite de Wordsmyth4 et leur de’ﬁnitions textuelles aussi extraites du dictionnaire—the’saurus. La
Figure 3 est un exemple des entrées de Wordsmyth que nous avons utilise’ pour la construction
de l’ontologie.

3.3 Etiquetage sémantique

L’ étiqueteur sémantique est similaire a un module d’eXtraction d’entite’s nomme’es (MUC, 1998).
ll reconnait des entités nomrne’es telles que les lieux, les personnes, les organisations, les noms
d’avions, de bateaux et de mate’riel de détection. Il est base’ sur un automate a états ﬁnis qui
effectue l’e’tiquetage en deux étapes illustre’es dans la Figure 4. La premiere étape recherche
un appariement entre la téte du syntagme analyse et les instances des concepts de l’ontologie.
Lorsque un appariement réussit, le téte est annote’e par le concept dont le mot est une instance.
La deuxieme étape sert a propager l’étiquette sémantique de la téte du syntagme vers tout le
syntagme. La sortie de l’étiqueteur sémantique est représentée par les mots en gras italique
dans la Figure 1. Dans (Boufaden, 2003), nous montrons que l’étiqueteur sémantique attribue

2Ce terme est la traduction de ’aboutness’ selon le glossaire francais-anglais de terminologie linguistique SIL
http ://www.sil.org/linguisl:ics/
3 \ , , , . . . , . .

Les changements de themes sont representes par une euquette. Quatre autres sont uulisees pour distmguer les
énonces qui font partie d’un segment de theme de celles qui clos le segment de theme, qui initient une conversation
ou qui indiquent la ﬁn d’une conversation

4URL http 2/ / www.wordsmyth.net/ .

Narjés Boufaden, Yoshua Bengio, Guy Lapalme

ENT: wonder

SYL: won—der

PRO: wuhn dEr

POS: intransitive verb

INF: wondered, wondering, wonders

DEF: 1. to experience a sensation of admiration or amazement (of-
ten fol. by at):

EXA: She wondered at his bravery in combat.

SYN: marvel

SIM: gape, stare, gawk

DEF: 2. to be curious or skeptical about something:

EXA: I wonder about his truthfulness.

SYN: speculate (1)

SIM: deliberate, ponder, think, reflect, puzzle, conjecture

FIG. 3 — Description d’une entree du dictionnaire—thesaurus Wordsmyth pour le Verbe wonder
qui est un Verbe generalement utilise’ pour formuler une requete pour allouer du materiel de re-
cherche. Ce Verbe a pour etiquette le concept STATUS (8 -0 Figure 1). Les acronymes ENT, SYL,
PRO, POS, INF, DEF, EXA, SYN, SIM sont respectivement l’entree, la syllabe, la prononciation,
la categorie syntaxique, les formes ﬂechies, la deﬁnition textuelle, un exemple, les mots syno-
nymes et les mots similaires. Pour construire notre ontologie nous avons utilise les informations
contenues dans les champs ENT, DEF, SYN et SIM.

les concepts avec un rappel de 85,3% et une precision de 94,8%.

Etape 1 : . . .SN : black thicker fog . ..
\/-’

WEATHER—TYPE
e—Propagation
Etape 2 : . . .SN : black thicker fog . . .
 /

WEATHER—TYPE

FIG. 4 — Le syntagme nominal SN : black thicker fog est etiquete avec le concept WEATHER
(enonce 11-0). La premiere etape de l’analyse semantique reconnait la tete fog comme un type
de conditions climatiques. La deuxieme etape propage le concept a tout le syntagme nominal.

4 Reperage des mots informatifs

Le reperage de mots informatifs est une fonction du contexte d’enonciation represente par le
theme T et de la pertinence du mot par rapport aux concepts Ck de l’ontologie. Pour calculer
la pertinence, nous utilisons le contenu du mot w represente par sa deﬁnition textuelle Dw,
la mesure de similarite OC5 (Manning & Schutze, 2001) (section 4.2) et l’ontologie. Chaque
mot est represente par un Vecteur de similarite qui contient les scores de similarite sz'm(w, Ck)
obtenus pour chaque concept Ck de l’ontologie. Le theme permet d’ecarter les faux positifs
qui sont les mots w tel que w proche (selon la mesure de similarite ) d’un concept Ck et Ck

5Overlap Coefﬁcient.

Approche statistique pour le repérage de mots informatifs dans les textes oraux

est rarement observe’ dans le contexte d’énonciation ayant pour theme T. Dans ce qui suit,
nous présentons le modele de repérage. La section 4.2 décrit la mode’lisation de la distribution
des concepts sachant les mots. Ce modele permet de calculer P(Ck|w,;) a partir des scores de
similarite’ s2'm(wt, Ck) (Equation 2). La section 4.3 explicite la modélisation de la distribution
des concepts Ck étant donne’ les themes Tt.

4.1 Modéle

Une formulation de notre problématique est : chercher le concept Ck qui maximise la similarite’
pour un mot wt et Ck fréquemment observe’ étant donne’ le theme Tt. Cela se traduit par un
produit d’experts. Un expert, P(C,;|w,;), mode’lise la distribution des concepts sachant le mot;
l’autre, P(C,;|T,;), mode’lise la distribution des concepts sachant le theme. Les coefﬁcients 31 et
B2 sont des poids qui reﬂetent la contribution de chacun des experts dans le modele de repérage.

Lorsque les deux experts P(Ct|T,;) et P(Ct|wt) s’entendent sur le concept qui maximise ces
deux probabilités, il est facile de conclure que wt est informatif. Le cas non trivial est lorsque
les experts ne s’entendent pas sur le concept. Dans ce cas la décision repose sur un seuil de
conﬁance 6 determine’ de maniere empirique (Equation 1). Un mot wt est considére’ informatif
lorsque P(C*|wt, Tt) est supérieur a 6. L’équation 1 décrit le modele P(C*|wt, 

P(Ct = k|wt)'31P(Ct = k|Tt)'82
::{;1P(0. = z|wf1P(0. = l|Tt)52
et
0* = 3«1"ggf13»XP(Ct|wt,7ir)>P(C*|wt,7i:)> 5

P(Ct = k|wtaTt) = (1)

k est un des K concepts de l’ontologie, log P(Ck = k|wt) représente la log probabilite’
d’obserVer le concept It étant donne’ le mot wt et log P(Ck = k|Tt) est la log probabilite’

d’obserVer le concept It étant donne’ le theme Tt.

4.2 Distribution des concepts par rapport £1 un mot

La pertinence d’un mot est quantiﬁe’e en utilisant la mesure de similarite’ OC. Cette mesure
correspond a la proportion de mots en commun, contenus dans la deﬁnition textuelle du mot et
celle d’un concept (Equation 2). Un mot est jugé proche du domaine lorsqu’un des scores de
similarite’ est e’leVé pour un concept donné. (Boufaden, 2003) présente l’algorithme qui permet
de calculer les scores de similarite’s et de générer les Vecteurs de similarite’.

|Dw(z) I n I Do,.| (2)
 Dw(l) lal DC)c 
w(l) représente un sens particulier l du mot w et Ck un concept de l’ontologie du domaine.

Dwa) et Dck sont respectivement les ensembles de mots lemmatise’s extraits des de’ﬁnitions
textuelles de w(l) et Ck. Les de’ﬁnitions textuelles sont extraites a partir de Wordsmyth.

s2'm(w(l), Ck) =

La distribution d’un concept par rapport a un mot P (Ck |w,;) s’exprime en fonction de la proba-
bilité d’obserVer un concept Ck étant donne’ un sens particulier w(l) du mot w et la probabilite’
d’obserVer un sens particulier w(l) sachant w. P(Ck|w(l)) est obtenue par une redistribution

Narjés Boufaden, Yoshua Bengio, Guy Lapalme

des scores du vecteur de similarite’ aﬁn d’attribuer une probabilite’ tres faible aux scores nuls.
Aussi, pour simpliﬁer nos calculs nous supposons que les sens d’un mot sont équiprobables
(Equation 3).

P(Ck|w)= Z P(Ck|w(l))P(w(l)|w), <3)
w(l)€S(w)
P(w(l)|w)=%

Avec w(l) E S’ (w) sont les différents sens du mot w, P(C'k|w(l)) est le score de similarite’
normalisé entre le concept Ck étant donne’ un sens w(l) de w et P(w(l) |w) est la probabilite’
d’observer le sens w(l) étant donne’ le mot w.

4.3 Distribution des concepts par rapport £1 un theme

Selon le découpage effectué a l’étape de segmentation (section 3.1), un segment est compose’
d’énonce’s dont le theme peut etre classe’ en cinq categories :(1)MISSING_OBJECT qui englobe
toutes les informations faisant reference a l’objet implique’ dans un incident; (2)INCIDENT qui
décrit l’incident, sa cause etl’endroito1‘1il s’est produit ; (3)SEARCH_UNIT qui rapporte les faits
et actes des équipes de recherches; (4)MISSION qui décrit les conditions météorologiques lors
de la mission, l’endroit ou sont effectuées les recherches ; (5)OTHER qui contient toutes autres
informations qui n’a pas de lien directe avec le type d’information recherchée (section 2). La
probabilite’ P(C't|Tt) est déﬁnie par l’équation :

P(Ct|Tt) = 04P0(Ct) + (1 — 04)P1(Ct|Tt) (4)

CT est la séquence des concepts observe’s, TT la sequence des themes observés. 04 est le
parametre libre de notre modele. P0(C',;) est la fréquence relative des concepts dans le
corpus d’entrainement et P1(C',;|T,;) la fréquence relative des concepts sachant le theme.

5 Experiences et résultats

Le corpus d’entrainement est constitue’ de 1850 mots, soit 65% des 64 conversations anno-
tées manuellement avec les concepts de l’ontologie et les themes. Les résultats sont obtenus
en comparant les concepts générés par le modele de repérage aux réponses des formulaires
préalablement annotées avec les concepts de l’ontologie. Le Tableau 1 donne le rappel et la
précision obtenus pour le seuil 6 = 0.35. Ce seuil est calculé de maniere empirique sur le cor-
pus de test. Aﬁn de comparer le modele base’ sur la similarite’ et le modele exponentiel nous
avons considére’ uniquement les P(C',;|w,g) > 0.02. Four des rappels équivalents (38, 5% pour
P(C',;|w,;) et 36, 8% pour P(C't|wt, Tt)) le modele exponentiel performe mieux que la modele
base’ uniquement sur la similarite’. Bien que le modele base’ sur les themes ait une faible perfor-
mance, celui—ci a permis d’augmenter la précision du repérage de mots informatifs de 16,2 %.
La moyenne performance du modele base’ sur la similarite’ est probablement due a l’approxi—
mation faite pour passer du vecteur de scores de similarite’ vers P(C',;|w,;). Une amélioration
possible est de représenter P(C',;|w,;) comme une mixture de gaussiennes ou chaque gaussienne
est une fonction de la similarite’ par rapport a un concept donné. Le re’sultat modeste du modele
de repérage de mots informatifs est en partie dﬁ aux erreurs d’étiquetage syntaxique causées
par les extra—grammaticalite’s qui engendrent un score de similarite’ errone’. Par ailleurs, a cause

Approche statistique pour le repérage de mots informatifs dans les textes oraux

| | P(Ct|Tt) | P(Ct|wt) | P(Ct|Tt;wt) |
Mots Precision Rappel Precision Rappel Precision Rappel
Tous 37,4% 44% 73,33% 76,1% 61,45% 55%

Informatifs 34,6% 21,8% 64,7% 38,5% 75,2% 36,8%

TAB. 1 — Classiﬁcation des mots wt par rapports aux 24 concepts Ct de l’ontologie. Les mots
informatifs sont les réponses des champs des formulaires d’extraction. Les résultats du modele
P(C't|wt) sont obtenus en ne conside’rant que les probabilite’s P(C',;|w,;) > 0.02. Le re’sultat du
modele P(C',;|T,;, wt) est obtenu pour le seuil de conﬁance optimale 6 = 0.35

de la taille modeste de notre corpus d’entrainement, nous avons opte’ pour des parametres B1 et
B2 indépendants du concept. Cependant, la disparité de la distribution des concepts (le concept
STATUS a lui seul représente 29,5% du corpus d’entrainement) dans le corpus d’entrainement
fait que les coefﬁcients B1 et B2 sont inﬂuence’s de maniere a favoriser une meilleure classi-
ﬁcation du concept prédominant. Le passage Vers un modele ou les parametres dépendent du
concept permettrait une meilleure performance.

6 Conclusion

Le repérage de mots informatifs est une tache fondamentale pour plusieurs applications de TAL
tels que l’extraction d’information. La plupart des approches élabore’es pour les textes écrits
se basent sur l’utilisation de patrons formulés par des regles ou par des modeles stochastiques
(Leek, 1997; Riloff, 1998). Dans les deux cas, la structure des phrases pertinentes constitue une
partie importante des connaissances a priori prises en compte dans la déﬁnition de la démarche
d’extraction. Ces approches performantes pour les textes écrits sont inadéquates pour les textes
oraux qui ne présentent pas de structures phrastiques re’gulieres. Pour pallier ce probleme, nous
avons développe’ une approche base’e sur le contenu des mots et sur le theme associe’ au contexte
d’énonciation.

Aﬁn d’éValuer la performance du systeme, nous avons comparé nos résultats avec ceux obtenus
lors de MUC7 pour la tache d’extraction des objets6 ’Template Object’ a partir de textes écrits
(MUC, 1998). Le F—score7 obtenu pour les mots informatifs est de 74.65% alors que le meilleur
résultat obtenu lors de MUC7 est de 80%.

Enﬁn, bien que l’approche présente’e soit congue pour les textes oraux, celle—ci présente des
avantages intéressant pour les textes écrits. En particulier, une approche base’e sur le contenu
des mots permet un raisonnement sur le sens des mots plutot que sur le mot en tant qu’unite’
lexicale. Une telle approche est un atout pour reme’dier aux Variations langagieres tres présentes
dans les textes e’crits. De plus, l’absence d’extra—grammaticalite’s dans les textes écrits permet
d’enVisager un meilleur re’sultat pour les textes écrits.

6Cela correspond a l’extraction des objets qui participent aux événements. Dans notre cas les événements sont
les incidents

7Le F-score utilisé pour MUC7 est F = %'li11,)_f}§ et B = 0.5

Narjés Boufaden, Yoshua Bengio, Guy Lapalme

Remerciements

Nous remercions Robert Parks pour nous avoir donne’ acces a la version électronique de Word-
smyth ainsi que le Secretariat National de la Recherche et Sauvetage pour les manuels de SAR.

Références

MUC(1998). Proceedings of the seventh Message Understanding Conference (M UC—7). Morgan Kauff—
man.

ABERDEEN .I., BURGER .I., DAY D., HIRSCHMAN L., PALMER D., ROBINSON P. & VILAIN M.
(1996). MITRE :Description of the Alembic System as Used in MET. In Proceedings of the T IPST ER
24—Months Workshop.

APPELT E., HOBBS J., BEAR J., ISRAEL D. & TYSON M. (1993). FASTUS : A Finite—state Processor
for Information Extraction from Real—world Text. In Proceedings of IJCAI , p. 1172-1178.

BOUFADEN N. (2003). An Ontology—based Semantic Tagger for IE System. In 41 st. Annual Meeting of
the Association for Computational Linguistics(ACL) .' Student Workshop, p. 7-14, Sapporo, J apon.

BOUFADEN N., LAPALME G. & BENGIO Y. (2001). Topic Segmentation : A First Stage to Dialog—based
Infomiation Extraction. In Natural Language Processing Rim Symposium, NLPRS ’0I , p. 273-280.

BOUFADEN N., LAPALME G. & BENGIO Y. (2002). Découpage thématique des conversations : un outil
d’aide a l’extraction. In Actes de T raitement Automatique de la Langue, volume I, p. 377-382, Nancy,
France.

BROWN G. & BEORGE Y. (1983). Discourse Analysis. Cambridge Textbooks in Linguistics Series.
Canbridge University Press.

CARBONELL J ., YIMMING Y., LAFERTY J ., R.D B., PIERCE T. & LIU X. (1999). CMU Report on
TDT—2 : Segmentation, Detection and Tracking. In DARPA Broadcast News Workshop.

HEARST M. (1994). Multi—paragraph Segmentation of Expository Text. In 32nd. Annual Meeting of the
Association for Computational Linguistics (ACL), p. 9-16, New Mexico State University, Las Cruces,
New Mexico.

LEEK T. (1997). Information Extraction Using Hidden Markov Model. Master’s thesis, University of
California, San Diego, CA.

MANNING C. D. & SCHUTZE H. (2001). Foundations of Statistical Natural Language Processing,
chapter Word Sense Disambiguiation, p. 294-303. The MIT Press Cambridge, Massachussets London
England.

MCCALLUM A., FREITAG D. & PEREIRA F. (2000). Maximum Entropy Markov Models for Inforn1a—
tion Extraction and Segmentation. In Prroceedings of ICML—2000.

RILOFF E. (1998). Automatically Generating Extraction Patterns from Untagged Text. In Proceedings
of the Thirteenth National Conference on Artiﬁcial Intelligence (AAAI—96), p. 1044-1049.

SHRIBERG E. (1994). Preliminaries to a Theory of Speech Disﬂuencies. PhD thesis, University of
California at Berkeley.

SODERLAND S ., FISHER D., ASELTINE J. & W. L. (1995). Crystal : Inducing a Conceptual Dictionary.
In Proceedings of the Fourteenth International Joint Conference on Artiﬁcial Intelligence (IJCAI—95), p.
1314-1319, Menlo Park.

