<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Fiabilit&#233; de la r&#233;f&#233;rence humaine dans la d&#233;tection de th&#232;me</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2004, F&#232;s, 19&#8211;21 avril 2004
</p>
<p>Fiabilit&#233; de la r&#233;f&#233;rence humaine dans la d&#233;tection de th&#232;me
</p>
<p>Armelle Brun, Kamel Sma&#239;li
LORIA - Universit&#233; Nancy2
</p>
<p>Campus Scientifique - BP 239
54506 VANDOEUVRE-l&#232;s-NANCY
</p>
<p>{brun,smaili}@loria.fr
</p>
<p>R&#233;sum&#233; - Abstract
</p>
<p>Dans cet article, nous nous int&#233;ressons &#224; la t&#226;che de d&#233;tection de th&#232;me dans le cadre de la
reconnaissance automatique de la parole. La combinaison de plusieurs m&#233;thodes de d&#233;tection
montre ses limites, avec des performances de 93.1 %. Ces performances nous m&#232;nent &#224; remett-
tre en cause le th&#232;me de r&#233;f&#233;rence des paragraphes de notre corpus. Nous avons ainsi effectu&#233;
une &#233;tude sur la fiabilit&#233; de ces r&#233;f&#233;rences, en utilisant notamment les mesures Kappa et er-
reur de Bayes. Nous avons ainsi pu montrer que les &#233;tiquettes th&#233;matiques des paragraphes du
corpus de test comportaient vraisemblablement des erreurs, les performances de d&#233;tection de
th&#232;me obtenues doivent donc &#234;tres exploit&#233;es prudemment.
</p>
<p>In this paper, topic detection is studied in the frame of automatic speech recognition. Topic
detection methods combination reaches 93.1% correct detection. This rate makes us throw the
reference labeling back into question. We have then studied the reliability of the topic labeling
of our test corpus, by using the Kappa statistics and the Bayes error. With these measures, we
show the topic label of some paragraphs may be wrong, then performance of topic detection
may be carefully exploited.
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>D&#233;tection de th&#232;me, Etiquetage th&#233;matique, statistique Kappa, erreur de Bayes
Topic detection, topic assignment, Kappa statistics, Bayes error</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>A. Brun, K. Sma&#239;li
</p>
<p>1 Introduction
</p>
<p>Dans le cadre de la reconnaissance automatique de la parole, il a &#233;t&#233; montr&#233; que l&#8217;adaptation
des mod&#232;les au signal en cours de traitement permettait une am&#233;lioration des performances.
Plus concr&#232;tement, les mod&#232;les que nous &#233;voquons ici sont tout d&#8217;abord le mod&#232;le acoustique
dont l&#8217;objectif est le traitement du signal per&#231;u. Le second mod&#232;le, quant &#224; lui, est le mod&#232;le de
langage, il repr&#233;sente la composante langagi&#232;re d&#8217;un syst&#232;me de reconnaissance de la parole.
</p>
<p>Notons A le signal acoutique per&#231;u par le syst&#232;me de reconnaissance de la parole, la s&#233;quence
de mots W&#770; reconnue par ce dernier sera celle correspondant &#224; l&#8217;&#233;quation suivante :
</p>
<p>W&#770; = argmax P (W | A)
W
</p>
<p>(1)
</p>
<p>O&#249; P (W | A) est la probabilit&#233; que la suite de motsW soit reconnue sachant que A a &#233;t&#233; per&#231;u.
En utilisant la r&#232;gle de Bayes, nous pouvons obtenir :
</p>
<p>P (W | A) = P (A |W ) &#183; P (W )
P (A)
</p>
<p>(2)
</p>
<p>O&#249; P (A | W ) est la probabilit&#233; que le signal A soit per&#231;u sachant que la suite de mots W a
&#233;t&#233; prononc&#233;e, elle est &#233;valu&#233;e par le module acoustique (Haton et al., 1991; Calliope, 1989).
P (W ), quant &#224; lui, repr&#233;sente la probabilit&#233; de la suite de mots composant W , elle est &#233;valu&#233;e
par le mod&#232;le de langage.
</p>
<p>Le mod&#232;le auquel nous nous int&#233;ressons ici est le mod&#232;le de langage et plus particuli&#232;rement son
adaptation au signal en cours de reconnaissance. De nombreux travaux ont port&#233; sur l&#8217;adaptation
des mod&#232;les de langage, montrant &#224; la fois un gain en perplexit&#233; des mod&#232;les de langage mais
&#233;galement en taux de reconnaissance (Kuhn &amp; De Mori, 1990; Seymore &amp; Rosenfeld, 1997).
Nous nous penchons ici sur un cas particulier de l&#8217;adaptation des mod&#232;les de langage, celui de
l&#8217;adaptation au th&#232;me de la s&#233;quence en cours de reconnaissance. Cette phase d&#8217;adaptation au
th&#232;me doit passer par une &#233;tape pr&#233;alable de d&#233;tection dudit th&#232;me.
</p>
<p>La seconde section de cet article pr&#233;sente le domaine de la d&#233;tection de th&#232;me : m&#233;thodes de d&#233;-
tection et d&#8217;&#233;valuation des performances sur des corpus textuels, puis d&#233;taille les performances
effectives sur nos donn&#233;es. La troisi&#232;me partie s&#8217;int&#233;resse &#224; la remise en cause de l&#8217;&#233;tiquette
de r&#233;f&#233;rence des documents textuels sur lesquels se sont faits les tests de performance. La qua-
tri&#232;me partie pr&#233;sente le gain effectif de perplexit&#233; atteint gr&#226;ce &#224; l&#8217;adaptation des mod&#232;les de
langage. Une conclusion et des perspectives &#224; ce travail sont pr&#233;sent&#233;es dans la derni&#232;re section.
</p>
<p>2 La d&#233;tection de th&#232;me
</p>
<p>La d&#233;tection de th&#232;me consiste, sachant un ensemble pr&#233;d&#233;fini de th&#232;mes et un document donn&#233;,
&#224; assigner une &#233;tiquette th&#233;matique au document. Un th&#232;me dans notre cas est consid&#233;r&#233; comme
&#233;tant le sujet trait&#233; par un ensemble documents. Pour permettre l&#8217;exploitation de ces th&#232;mes,
nous utilisons un corpus, compos&#233; de documents traitant des th&#232;mes auxquels nous nous in-
t&#233;ressons.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Fiabilit&#233; de la r&#233;f&#233;rence humaine dans la d&#233;tection de th&#232;me
</p>
<p>2.1 Les corpus
</p>
<p>Le corpus que nous utilisons dans notre &#233;tude est issu du journal Le Monde des ann&#233;es 1987 &#224;
1991. Les donn&#233;es, pr&#233;sent&#233;es sous forme d&#8217;articles, nous sont fournies d&#233;j&#224; class&#233;es. Chacune
de ces classes repr&#233;sente un secteur de r&#233;daction du journal, et les th&#232;mes que nous &#233;tudions
seront ces m&#234;mes secteurs de r&#233;daction.
</p>
<p>De ce corpus, nous devons extraire un corpus de test. Nous choisissons volontairement de ne
traiter que des articles relatant d&#8217;un seul th&#232;me. Etant donn&#233; qu&#8217;il est plus probable qu&#8217;un
article entier traite de plusieurs th&#232;mes, nous choisissons de travailler au niveau du paragraphe
que nous jugeons &#234;tre plus probable de ne traiter que d&#8217;un seul th&#232;me.
Le corpus de test que nous avons s&#233;lectionn&#233; est donc compos&#233; de 835 paragraphes. Pour
l&#8217;&#233;tiquetage des paragraphes composant ce corpus, nous avons demand&#233; &#224; un humain d&#8217;affecter
une &#233;tiquette th&#233;matique &#224; ces paragraphes. Ce r&#233;&#233;tiquetage des paragraphes pourra ajouter un
biais &#224; notre exp&#233;rience (que nous jugeons cependant faible), les paragraphes d&#8217;apprentissage
n&#8217;&#233;tant pas r&#233;&#233;tiquet&#233;s par les humains.
</p>
<p>Le corpus d&#8217;apprentissage est compos&#233; des paragraphes ne participant pas au test.
</p>
<p>2.2 M&#233;thodes et performances en d&#233;tection de th&#232;me
</p>
<p>Pour pouvoir d&#233;tecter le th&#232;me d&#8217;un document donn&#233;, nous devons tout d&#8217;abord &#8220;apprendre&#8221;
les caract&#233;ristiques de chacun des th&#232;mes pour ensuite les rep&#233;rer dans un nouveau document.
Pour cela, nous repr&#233;sentons chaque th&#232;me par un vecteur (Salton, 1991), o&#249; chaque dimen-
sion caract&#233;rise un mot, sa valeur repr&#233;sentant la plupart du temps sa fr&#233;quence dans le cor-
pus d&#8217;apprentissage. Pour d&#233;tecter le th&#232;me d&#8217;un document donn&#233; il est indispensable de le
repr&#233;senter &#233;galement vectoriellement pour pouvoir le comparer.
</p>
<p>L&#8217;&#233;tape suivante consiste alors &#224; comparer la repr&#233;sentation vectorielle du document de test
avec chacune des repr&#233;sentations vectorielles des th&#232;mes. Il existe deux grandes approches pour
d&#233;tecter le th&#232;me d&#8217;un document sachant les repr&#233;sentations vectorielles, l&#8217;approche statistique
et l&#8217;approche machine learning, nous pr&#233;sentons maintenant les principes de quelques unes des
m&#233;thodes de d&#233;tection de th&#232;me.
</p>
<p>&#8226; L&#8217;approche statistique exploite la probabilit&#233; d&#8217;apparition des mots dans les th&#232;mes et
dans le document de test. Nous pouvons par exemple citer le classifieur de Bayes ou
mod&#232;le unigramme (McDonough et al., 1994) qui &#233;value la probabilit&#233; de chaque th&#232;me
sachant le document de test (en exploitant la distribution de probabilit&#233; des mots dans les
th&#232;mes et le document de test). Un autre exemple de m&#233;thode probabiliste est le classi-
fieur TFIDF (Salton, 1991) qui &#233;value la similarit&#233; existant entre le vecteur du document
de test et l&#8217;ensemble des vecteurs de th&#232;me.
</p>
<p>&#8226; L&#8217;approche machine learning se fonde sur l&#8217;apprentissage automatique. Les mod&#232;les
les plus courants sont les r&#233;seaux de neurones (Wiener et al., 1995) et les Machines &#224;
Vecteurs Supports (SVMs) (Vapnik, 1995), qui recherchent le s&#233;parateur optimal entre
les diff&#233;rents th&#232;mes.
</p>
<p>L&#8217;&#233;valuation des performances d&#8217;une m&#233;thode de d&#233;tection de th&#232;me s&#8217;effectue sur le corpus
de test. Nous comparons le th&#232;me propos&#233; par la m&#233;thode &#233;tudi&#233;e avec le th&#232;me effectif du</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>A. Brun, K. Sma&#239;li
</p>
<p>Table 1: Performances en d&#233;tection de th&#232;me
</p>
<p>TFIDF Class. Bayes R&#233;s. neur. SVM
Performances (%) 74.3 83.1 76.2 78.3
</p>
<p>paragraphe (celui propos&#233; par l&#8217;humain). Nos exp&#233;rimentations on conduit aux performances
maximales donn&#233;es dans le tableau 1.
</p>
<p>2.3 Combinaison de m&#233;thodes de d&#233;tection de th&#232;me
</p>
<p>Les m&#233;thodes pr&#233;sent&#233;es ci-dessus ont &#233;t&#233; optimis&#233;es au maximum, le seul moyen d&#8217;am&#233;liorer
les performances obtenues est alors de combiner les diff&#233;rentes m&#233;thodes. Il existe plusieurs
m&#233;thodes de combinaison : combinaison lin&#233;aire, r&#233;seaux de neurones et SVM. La combinaison
&#224; l&#8217;aide des SVM nous a permis d&#8217;obtenir les plus hautes performances : celles-ci atteignent
93.1%, le gain en performances est plus que significatif (environ 10% en absolu) (Brun et al.,
2003).
Cependant, il reste 7% des paragraphes dont le th&#232;me n&#8217;est pas correctement d&#233;tect&#233;. Nous
nous sommes alors demand&#233;s la raison pour laquelle le th&#232;me de ces paragraphes n&#8217;&#233;tait pas
correctement reconnu. Pour cela, nous nous sommes pench&#233;s sur l&#8217;&#233;tiquetage de r&#233;f&#233;rence des
paragraphes de test.
</p>
<p>3 Remise en cause de l&#8217;&#233;tiquetage de r&#233;f&#233;rence
</p>
<p>Les remarques avanc&#233;es pr&#233;c&#233;demment nous laissent penser que potentiellement l&#8217;&#233;tiquette de
r&#233;f&#233;rence des paragraphes utilis&#233;e n&#8217;est pas fiable et peut &#234;tre remise en cause. En effet, la phase
d&#8217;&#233;tiquetage des paragraphes de test a &#233;t&#233; effectu&#233;e par un humain, source potentielle d&#8217;erreurs
et l&#8217;on ne peut donc pas conna&#238;tre a priori le degr&#233; de fiabilit&#233; des &#233;tiquettes affect&#233;es aux textes.
L&#8217;&#233;tude que nous pr&#233;sentons dans la suite a pour but de conna&#238;tre le taux de confiance que nous
pouvons accorder &#224; l&#8217;&#233;tiquetage humain.
</p>
<p>3.1 L&#8217;exp&#233;rience men&#233;e
</p>
<p>Pour &#233;valuer le taux de confiance que nous pouvons accorder &#224; une &#233;tiquette fournie par un hu-
main, nous d&#233;cidons d&#8217;&#233;tudier l&#8217;homog&#233;n&#233;it&#233; de l&#8217;&#233;tiquetage fourni par un ensemble d&#8217;humains
sur des paragraphes. Pour ce faire, il nous faut, pour chaque paragraphe &#233;tudi&#233;, un ensemble
d&#8217;&#233;tiquettes, fournies par diff&#233;rents &#233;tiqueteurs (humains).
L&#8217;ensemble de paragraphes utilis&#233; est celui que nous avons d&#233;j&#224; trait&#233; ici : les 835 paragraphes
&#233;tiquet&#233;s manuellement. Il nous faut alors recueillir plusieurs jeux d&#8217;&#233;tiquetages pour chacun de
ces 835 paragraphes. Ce nombre nous a sembl&#233; trop &#233;lev&#233; pour trouver des personnes acceptant
d&#8217;&#233;tiqueter cet ensemble important de paragraphes. C&#8217;est pour cette raison que nous avons
choisi de ne travailler que sur un sous-ensemble de ce dernier. Nous avons ainsi extrait, de</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Fiabilit&#233; de la r&#233;f&#233;rence humaine dans la d&#233;tection de th&#232;me
</p>
<p>fa&#231;on al&#233;atoire, environ 15% des 835 paragraphes. Ensuite, pour chacun d&#8217;eux, nous avons du
r&#233;colter un ensemble d&#8217;&#233;tiquetages pour pouvoir &#233;tudier l&#8217;homog&#233;n&#233;it&#233; des &#233;tiquettes.
</p>
<p>Pour collecter ces &#233;tiquetages, nous avons fait appel &#224; un ensemble de personnes b&#233;n&#233;voles.
Nous leur avons tout d&#8217;abord fourni un bref descriptif de l&#8217;&#233;tude que nous menions, o&#249; nous
expliquions notre objectif. Puis nous leur avons expliqu&#233; ce que nous attendions des &#233;tique-
teurs : &#224; chacun des paragraphes fournis ils devaient donner 1 ou 2 &#233;tiquettes parmi un ensemble
d&#8217;&#233;tiquettes possibles. La premi&#232;re &#233;tiquette est obligatoire, la seconde, quant &#224; elle, est option-
nelle. Ces &#233;tiquettes correspondent aux th&#232;mes sur lesquels nous travaillons. Un descriptif de
ce que repr&#233;sente chacune des &#233;tiquettes (th&#232;mes) leur a &#233;galement &#233;t&#233; fourni.
Nous avons ensuite donn&#233; &#224; chaque &#233;tiqueteur, une ou plusieurs s&#233;ries de 10 paragraphes,
auxquels ils devaient affecter au moins une &#233;tiquette.
</p>
<p>Afin de nous situer dans le cadre d&#8217;une seule &#233;tiquette par paragraphe, nous ne retenons que les
paragraphes pour lesquels une seule &#233;tiquette a &#233;t&#233; donn&#233;e. A la fin de l&#8217;exp&#233;rience, nous avons
obtenu un ensemble de 12 &#233;tiquetages pour chacun des 89 paragraphes &#233;tudi&#233;s. Nous avons, par
la suite, cherch&#233; &#224; analyser le degr&#233; de coh&#233;sion entre les &#233;tiqueteurs afin d&#8217;en d&#233;river le degr&#233;
de confiance que l&#8217;on peut accorder aux &#233;tiquettes des 835 paragraphes.
</p>
<p>3.2 La mesure Kappa
</p>
<p>La statistique Kappa (Cohen, 1960), r&#233;cemment exploit&#233;e par Carletta (Carletta, 1996) comme
une mesure d&#8217;accord pour l&#8217;analyse de documents/discours, est un test applicable dans le cas
o&#249; plusieurs sujets doivent assigner une &#233;tiquette parmi n &#224; un texte.
Le calcul du coefficient K d&#8217;accord entre les &#233;tiqueteurs tient compte de la chance a priori
que les &#233;tiqueteurs soient d&#8217;accord. K est ind&#233;pendant du nombre d&#8217;&#233;tiqueteurs, du nombre
d&#8217;&#233;l&#233;ments &#224; classer, ainsi que du nombre d&#8217;&#233;tiquettes &#224; affecter aux &#233;l&#233;ments.
</p>
<p>Le coefficient K d&#8217;accord entre les &#233;tiqueteurs est d&#233;fini comme suit:
</p>
<p>K =
P (A)&#8722; P (E)
1&#8722; P (E) (3)
</p>
<p>o&#249; P (A) est la proportion d&#8217;&#233;tiqueteurs qui sont d&#8217;accord (proposant la m&#234;me &#233;tiquette) et
P (E) est la proportion a priori que les &#233;tiqueteurs soient d&#8217;accord (proportion d&#251;e &#224; la chance
uniquement). Lorsque les &#233;tiqueteurs sont compl&#232;tement d&#8217;accord, K = 1 et &#224; l&#8217;inverse si les
&#233;tiqueteurs ne sont pas plus d&#8217;accord que par chance, alors K = 0.
</p>
<p>Selon Krippendorff (Krippendorff, 1980), une valeur de K &gt; 0.8 est synonyme d&#8217;une bonne
coh&#233;rence entre les annotateurs. Une valeur 0.68 &lt; K &lt; 0.8 ne permet pas de rendre de
d&#233;cision et une valeur K &lt; 0.68 montre une non coh&#233;rence entre les &#233;tiqueteurs.
</p>
<p>3.2.1 Aper&#231;u de l&#8217;&#233;tiquetage manuel
</p>
<p>Le tableau TAB. 2 pr&#233;sente un sous-ensemble des &#233;tiquetages fournis sur les 89 paragraphes.
La valeur de chaque case (ni,j) correspond au nombre d&#8217;&#233;tiqueteurs ayant donn&#233; le th&#232;me Tj au
paragraphe Pi.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>A. Brun, K. Sma&#239;li
</p>
<p>Table 2: Exemple d&#8217;&#233;tiquetage de paragraphes
</p>
<p>Paragraphe T1 T2 T3 T4 T5 T6 T7 S
Culture Economie Etranger Histoire Politique Sciences Sports
</p>
<p>P1 0 1 6 0 1 2 2 0.26
P2 0 0 0 0 0 12 0 1
P3 0 0 0 1 0 0 11 0.83
P4 7 3 2 0 0 0 0 0.38
... ... ...
</p>
<p>P87 0 0 0 0 0 0 12 1
P88 1 0 0 0 0 11 0 0.83
P89 0 0 0 0 0 12 0 1
N = 89 T1=145 T2=56 T3=138 T4=33 T5=175 T6=271 T7=217 Z=67.0
</p>
<p>La derni&#232;re colonne contient les valeurs Si, qui correspondent &#224; l&#8217;accord entre les &#233;tiqueteurs
pour le paragraphe i. Si a une valeur de 1 lorsque tous les &#233;tiqueteurs sont d&#8217;accord et une
valeur de 0 lorsqu&#8217;ils ne sont pas du tout d&#8217;accord. Si est calcul&#233; de la mani&#232;re suivante:
</p>
<p>Si =
1
</p>
<p>C(C &#8722; 1) &#8727;
m&#8721;
</p>
<p>j=1
</p>
<p>nij(nij &#8722; 1) (4)
</p>
<p>Avec
m le nombre de th&#232;mes, dans notre cas m = 7
C le nombre d&#8217;&#233;tiqueteurs, ici C = 12 &#233;tiqueteurs
</p>
<p>La valeur de K (formule 3) n&#233;cessite la connaissance de P (A) et P (E). P (A) repr&#233;sente le
taux d&#8217;accord entre les &#233;tiqueteurs et est calcul&#233; de la mani&#232;re suivante :
</p>
<p>P (A) =
Z
</p>
<p>N
(5)
</p>
<p>Avec
</p>
<p>&#8226; N le nombre de paragraphes trait&#233;s, ici N = 89 paragraphes
</p>
<p>&#8226; Z = &#8721;Ni=1 Si est la valeur correspondant &#224; l&#8217;accord entre les &#233;tiqueteurs, tous paragraphes
confondus
</p>
<p>P (E), la proportion a priori d&#8217;&#233;tiqueteurs d&#8217;accord sur la m&#234;me &#233;tiquette, est calcul&#233;e ainsi :
</p>
<p>P (E) =
1
</p>
<p>NC2
</p>
<p>n&#8721;
i=1
</p>
<p>Ti
2 (6)
</p>
<p>Avec</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Fiabilit&#233; de la r&#233;f&#233;rence humaine dans la d&#233;tection de th&#232;me
</p>
<p>&#8226; n, le nombre de th&#232;mes
</p>
<p>&#8226; NC, le nombre total d&#8217;&#233;tiquetages (= N &#8727; C = 89*12)
</p>
<p>&#8226; T1, T2, . . . , T7 les valeurs correspondant au nombre d&#8217;&#233;tiquettes donn&#233;es pour chaque
th&#232;me Tj .
</p>
<p>3.2.2 R&#233;sultats
</p>
<p>La valeurK obtenue sur les 89 paragraphes de test est de 0.52, cette valeur nous indique que les
&#233;tiqueteurs ne sont pas d&#8217;accord sur les &#233;tiquettes des paragraphes. Vu les diff&#233;rences au niveau
de l&#8217;&#233;tiquetage entre les &#233;tiqueteurs, nous pouvons en d&#233;duire que les &#233;tiquettes que nous avons
fournies &#224; la main aux 835 paragraphes comportent probablement des erreurs.
</p>
<p>Par cons&#233;quent, les &#233;tiquettes de r&#233;f&#233;rence que nous utilisons ne sont pas forc&#233;ment les bonnes
&#233;tiquettes. Le taux d&#8217;&#233;tiquetage correct de 93.3% s&#8217;explique donc et dans une certaine mesure
repr&#233;sente un excellent r&#233;sultat &#233;tant donn&#233;e la qualit&#233; de l&#8217;&#233;tiquetage de r&#233;f&#233;rence.
</p>
<p>3.3 L&#8217;erreur de Bayes
</p>
<p>3.3.1 Th&#233;orie
</p>
<p>La statistique Kappa que nous venons d&#8217;&#233;tudier, ne nous permet pas de quantifier le taux de
d&#233;saccord entre les &#233;tiqueteurs. L&#8217;erreur de Bayes, que nous pr&#233;sentons maintenant va nous
permettre d&#8217;estimer le pourcentage d&#8217;erreur d&#8217;&#233;tiquetage sur les 89 paragraphes.
</p>
<p>Nous faisons l&#8217;hypoth&#232;se que les donn&#233;es (d&#8217;&#233;tiquetage) r&#233;sultent d&#8217;une exp&#233;rience al&#233;atoire
lanc&#233;e de fa&#231;on it&#233;rative. Soit &#8486; = {&#969;} l&#8217;ensemble fondamental de l&#8217;exp&#233;rience (l&#8217;ensemble
des valeurs que peut prendre le r&#233;sultat de l&#8217;exp&#233;rience) et Z = (X, Y ) la variable al&#233;atoire telle
queX(&#8486;) est l&#8217;ensemble des textes et Y (&#8486;) l&#8217;ensemble des cat&#233;gories (th&#232;mes). Chaque couple
texte/th&#232;me correspond alors &#224; un couple (x, y) dans X(&#8486;)&#215;Y (&#8486;), associ&#233; &#224; &#969; (i.e. x = X(&#969;)
et y = Y (&#969;)). Ces notations &#233;tant pos&#233;es, on peut prendre en consid&#233;ration les restrictions
pr&#233;cit&#233;es concernant l&#8217;universalit&#233; de l&#8217;&#233;tiquetage en faisant l&#8217;hypoth&#232;se qu&#8217;il n&#8217;existe pas de
d&#233;pendance fonctionnelle entre x et y mais seulement une loi de probabilit&#233; jointe sur (X, Y ).
Dans ce cadre, il est bien connu que le classifieur ayant le plus petit taux d&#8217;erreur est celui qui
impl&#233;mente la r&#232;gle de d&#233;cision de Bayes ((Fukunaga, 1990)). Ce taux d&#8217;erreur est donn&#233; par
la formule suivante :
</p>
<p>RBayes = 1&#8722;
&#8747;
X(&#8486;)
</p>
<p>P (y0 | x)dP (x) (7)
</p>
<p>o&#249; y0 = arg maxyP (y | x). Elle constitue une borne inf&#233;rieure sur le taux d&#8217;erreur que l&#8217;on
peut esp&#233;rer atteindre. L&#8217;impl&#233;mentation de la r&#232;gle de d&#233;cision de Bayes revient &#224; choisir, pour
chaque texte, la cat&#233;gorie correspondant au plus grand nombre de votes. L&#8217;erreur peut ainsi &#234;tre
calcul&#233;e de la fa&#231;on suivante :
</p>
<p>R&#770;Bayes = 1&#8722; 1
m
</p>
<p>m&#8721;
i=1
</p>
<p>maxyf(y | xi) (8)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>A. Brun, K. Sma&#239;li
</p>
<p>o&#249; f(y | xi) est le nombre d&#8217;&#233;tiqueteurs affectant le th&#232;me y au texte xi et m est le nombre de
paragraphes. Prenons par exemple un paragraphe ayant re&#231;u l&#8217;&#233;tiquetage suivant :
Culture : 2, Economie : 0, Etranger : 0, Histoire : 1, Politique : 1, Sciences : 8, Sports : 0. La
valeur de maxyf(y | xi) sera alors &#233;gale &#224; 8/12.
</p>
<p>3.3.2 R&#233;sultats
</p>
<p>Sur l&#8217;ensemble des 89 paragraphes &#233;tudi&#233;s, l&#8217;erreur de Bayes est de 15.7%. Cela signifie que
l&#8217;on peut supposer que quasiment 16% des paragraphes peuvent avoir une &#233;tiquette fausse.
Cependant, cette valeur doit &#234;tre nuanc&#233;e. En effet, bien qu&#8217;un descriptif ait &#233;t&#233; fourni aux
&#233;tiqueteurs avant les &#233;tiquetages, certains d&#233;tails peuvent ne pas leur avoir &#233;t&#233; pr&#233;cis&#233;s, et un
biais peut avoir &#233;t&#233; introduit dans leur &#233;tiquetage.
</p>
<p>Ces r&#233;sultats nous m&#232;nent de nouveau &#224; penser que le fait que les performances de d&#233;tection
de th&#232;me ne d&#233;passent pas 93.3% est probablement d&#251; &#224; la limite des performances humaines
elles-m&#234;mes.
</p>
<p>Les r&#233;sultats pr&#233;c&#233;dents nous indiquent donc que nous ne pouvons pas &#233;valuer de fa&#231;on fiable les
performances des m&#233;thodes de d&#233;tection de th&#232;me &#233;tudi&#233;es. En effet, les &#233;tiquettes de r&#233;f&#233;rence
pouvant &#234;tre remises en doute, nous n&#8217;avons aucun r&#233;f&#233;rentiel fiable.
</p>
<p>Par cons&#233;quent, il nous faut trouver une alternative &#224; l&#8217;&#233;valuation des m&#233;thodes de d&#233;tection de
th&#232;me. Nous pouvons rappeler ici que nous effectuons la t&#226;che de d&#233;tection de th&#232;me dans le
but d&#8217;effectuer une adaptation des mod&#232;les de langage dans les syst&#232;mes de reconnaissance de
la parole. Ainsi, l&#8217;efficacit&#233; de nos m&#233;thodes de d&#233;tection de th&#232;me devra &#234;tre &#233;valu&#233;e un pas
plus en avant dans le processus, c&#8217;est-&#224;-dire au niveau de l&#8217;adaptation des mod&#232;les de langage.
</p>
<p>Plus concr&#232;tement, si nos exp&#233;riences montrent que l&#8217;adaptation des mod&#232;les de langage au
th&#232;me d&#233;tect&#233; n&#8217;engendre pas une am&#233;lioration des performances de reconnaissance de la pa-
role (ou encore de perplexit&#233;), cela signifiera les m&#233;thodes de d&#233;tection de th&#232;me ne sont pas
efficaces. A l&#8217;oppos&#233;, si les performances s&#8217;am&#233;liorent, cela signifiera que nos m&#233;thodes sont
performantes. Nous chercherons dans ce cas &#224; maximiser le gain (en perplexit&#233; ou en reconnais-
sance) obtenu. Lewis, dans (Lewis, 1991), a &#233;galement &#233;nonc&#233; le probl&#232;me de la non fiabilit&#233;
de l&#8217;&#233;tiquetage de r&#233;f&#233;rence humain. Pour y faire face, il propose &#233;galement d&#8217;&#233;valuer ces
performances durant une &#233;tape plus en avant dans le processus.
</p>
<p>3.3.3 Etude plus approfondie des r&#233;sultats
</p>
<p>Nous allons maintenant &#233;tudier les performances, sur l&#8217;ensemble des 89 paragraphes, des dif-
f&#233;rentes m&#233;thodes pr&#233;sent&#233;es dans ce document. Plus pr&#233;cis&#233;ment, nous allons comparer les
performances obtenues par nos m&#233;thodes en fonction de celles des humains (i.e. du degr&#233;
d&#8217;accord entre les &#233;tiqueteurs). Les m&#233;thodes &#233;tudi&#233;es sont celles qui ont permis d&#8217;obtenir les
meilleures performances d&#8217;&#233;tiquetage.
</p>
<p>Le tableau TAB. 3 pr&#233;sente les r&#233;sultats de cette &#233;tude. Nous divisons l&#8217;ensemble des 89 para-
graphes en sous-ensembles, en fonction du degr&#233; d&#8217;accord des humains sur les paragraphes.
</p>
<p>La premi&#232;re colonne montre parmi l&#8217;ensemble des 89 paragraphes, le nombre de paragraphes
de chaque sous-ensemble &#233;tudi&#233;. Les autres colonnes montrent soit le degr&#233; d&#8217;accord, soit les
performances des m&#233;thodes sur chaque ensemble.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Fiabilit&#233; de la r&#233;f&#233;rence humaine dans la d&#233;tection de th&#232;me
</p>
<p>Table 3: Comparaison du taux d&#8217;homog&#233;n&#233;it&#233; des &#233;tiquettes humaines et des performances des
m&#233;thodes de d&#233;tection de th&#232;me &#233;tudi&#233;es
</p>
<p>Nb paragraphes Taux d&#8217;accord Perfs Unigramme Perfs RN Perfs TFIDF Perfs SVM
humain (Classif. Bayes)
</p>
<p>39 12/12 37/39 38/39 38/39 38/39
15 11/12 14/15 14/15 12/15 14/15
8 10/12 6/8 7/8 6/8 7/8
10 9/12 9/10 8/10 9/10 8/10
3 8/12 2/3 2/3 2/3 2/3
2 7/12 2/2 2/2 1/2 1/2
6 6/12 4/6 4/6 3/6 4/6
6 5/12 2/6 1/6 2/6 2/6
</p>
<p>Il est &#233;vident que le nombre de paragraphes par th&#232;me est trop petit pour parler de pourcentage,
mais nous pouvons tout de m&#234;me donner quelques impressions g&#233;n&#233;rales sur la tendance des
performances. Nous pouvons tout d&#8217;abord remarquer que sur les ensembles de paragraphes pour
lesquels les humains ont tendance &#224; &#234;tre d&#8217;accord (11/12 et 12/12), les m&#233;thodes de d&#233;tection
de th&#232;me sont tr&#232;s performantes. A l&#8217;oppos&#233;, sur les paragraphes o&#249; les humains ne sont pas
d&#8217;accord (doute sur le th&#232;me, taux d&#8217;accord &lt; 8/12), les m&#233;thodes ont tendance &#224; &#234;tre moins
performantes.
</p>
<p>La figure FIG. 1 montre l&#8217;&#233;volution de l&#8217;erreur en d&#233;tection de th&#232;me en fonction de l&#8217;erreur de
Bayes moyenne du corpus de test. A nouveau, nous pouvons constater que moins les &#233;tiqueteurs
sont d&#8217;accord sur l&#8217;&#233;tiquette &#224; assigner aux paragraphes, plus l&#8217;erreur de d&#233;tection de th&#232;me
augmente.
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>8
</p>
<p>10
</p>
<p>12
</p>
<p>14
</p>
<p>16
</p>
<p>18
</p>
<p>20
</p>
<p>0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.1
</p>
<p>Er
re
</p>
<p>ur
 d
</p>
<p>e 
d&#233;
</p>
<p>te
ct
</p>
<p>io
n 
</p>
<p>de
 th
</p>
<p>&#232;m
e 
</p>
<p>(%
)
</p>
<p>Estimation de l erreur de Bayes
</p>
<p>L&#233;gende:
Unigramme
</p>
<p>Cache
Perplexit&#233;
</p>
<p>WSIM
</p>
<p>Figure 1: Evolution du taux d&#8217;erreur de d&#233;tection de th&#232;me en fonction de l&#8217;erreur de Bayes du
corpus de test</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>A. Brun, K. Sma&#239;li
</p>
<p>4 Conclusion et perspectives
</p>
<p>Dans cet article, nous nous sommes int&#233;ress&#233;s &#224; la t&#226;che de d&#233;tection de th&#232;me. Les perfor-
mances, sur notre corpus, de plusieurs m&#233;thodes ont &#233;t&#233; pr&#233;sent&#233;es. Apr&#232;s avoir combin&#233; les
diff&#233;rentes m&#233;thodes de d&#233;tection de th&#232;me dans un but d&#8217;am&#233;liorer les performances, nous
nous sommes rendus compte que le th&#232;me de certains paragraphes n&#8217;&#233;tait pas correctement re-
connu. Nous avons alors &#233;tudi&#233; les raisons de ce mauvais &#233;tiquetage, et plus particuli&#232;rement
nous nous sommes pench&#233;s sur le th&#232;me de r&#233;f&#233;rence accord&#233; aux paragraphes de test.
</p>
<p>L&#8217;&#233;tude que nous avons ainsi men&#233;e s&#8217;int&#233;resse &#224; l&#8217;homog&#233;n&#233;it&#233; des &#233;tiquettes th&#233;matiques ac-
cord&#233;es par plusieurs humains sur des paragraphes de test. Cette &#233;tude montre que les diff&#233;rents
&#233;tiqueteurs (humains) sont r&#233;guli&#232;rement d&#8217;accord sur l&#8217;&#233;tiquette &#224; assigner aux paragraphes.
Cependant sur certains, leur avis divergent. Nous avons ainsi &#233;tudi&#233; dans quelle proportion
les avis des &#233;tiqueteurs divergaient en exploitant notamment la statistique Kappa et l&#8217;erreur de
Bayes. Nous en avons ainsi d&#233;riv&#233; le taux d&#8217;erreur sur notre corpus de test (15.7%) et nous
avons pu conclure qu&#8217;une partie des erreurs d&#8217;&#233;tiquetage &#233;tait probablement due aux &#233;tiquettes
de r&#233;f&#233;rence du corpus de texte.
</p>
<p>R&#233;f&#233;rences
BRUN A., SMA&#207;LI K. &amp; HATON J. (2003). Nouvelle approche de la s&#233;lection de vocabulaire pour la
d&#233;tection de th&#232;me. In Traitement Automatique des Langues Naturelles (TALN2003), p. 45&#8211;54, Nantes,
France.
</p>
<p>CALLIOPE (1989). La parole et son traitement automatique. Masson.
CARLETTA J. (1996). Assessing agreement on classification tasks: the kappa statistics. Computational
linguistics, 22(2), 249&#8211;254.
COHEN J. (1960). A coefficient of agreement for nominal scales. PSychological easurements.
FUKUNAGA K. (1990). Introduction to Statistical Pattern Recognition. Academic Press, 2nd edition.
HATON J., PIERREL J., PERENNOU G., CAELEN J. &amp; GAUVAIN J. (1991). Reconnaissance automa-
tique de la parole. DUNOD Informatique.
KRIPPENDORFF K. (1980). Content Analysis: An introduction to its methodology. Sage Publications.
KUHN R. &amp; DE MORI R. (1990). A cache-based natural language model for speech recognition. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 12(6), 570&#8211;582.
LEWIS D. (1991). Evaluating Text Categorization. In Speech and Natural Language Workshop, p.
312&#8211;318, Asilomar.
MCDONOUGH J., NG K., JEANRENAUD P., GISH H. &amp; ROHLICEK J. (1994). Approaches to Topic
Identification On The Switchboard Corpus. In IEEE Transactions on Acoustics, Speech, and Signal
Processing, p. 385&#8211;388.
SALTON G. (1991). Developments in Automatic Text Retrieval. Science, 253, 974&#8211;979.
SEYMORE K. &amp; ROSENFELD R. (1997). Using Story Topics for Language Model Adaptation. In
Proceeding of the European Conference on Speech Communication and Technology.
VAPNIK V. (1995). The Nature of Statistical Learning Theory. Spinger, New York.
WIENER E., PEDERSEN J. &amp; WEIGEND A. (1995). A neural network approach to topic spotting. In
Fourth Annual Symposium on Document Analysis and Information Retrieval, SDAIR-95, p. 317&#8211;332,
University of Nevada, Las Vegas.</p>

</div></div>
</body></html>