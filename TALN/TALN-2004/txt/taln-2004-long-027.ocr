TALN 2004, Fés, 19-21 aV11'1 2004

Fiabilité de la référence humaine dans la détection de théme

Armelle Brun, Kamel Sma'ili
LORIA - Université Nancy2
Campus Scientiﬁque - BP 239
54506 VAN DOEUVRE-les-NANCY
{brun,smaili} @loria.fr

Résumé - Abstract

Dans cet article, nous nous intéressons a la tache de détection de theme dans le cadre de la
reconnaissance automatique de la parole. La combinaison de plusieurs méthodes de détection
montre ses limites, avec des performances de 93.1 %. Ces performances nous menent a remett-
tre en cause le theme de référence des paragraphes de notre corpus. Nous avons ainsi effectué
une étude sur la ﬁabilité de ces références, en utilisant notamment les mesures Kappa et er-
reur de Bayes. Nous avons ainsi pu montrer que les étiquettes thématiques des paragraphes du
corpus de test comportaient vraisemblablement des erreurs, les performances de détection de
theme obtenues doivent donc étres exploitées prudemment.

In this paper, topic detection is studied in the frame of automatic speech recognition. Topic
detection methods combination reaches 93.1% correct detection. This rate makes us throw the
reference labeling back into question. We have then studied the reliability of the topic labeling
of our test corpus, by using the Kappa statistics and the Bayes error. With these measures, we
show the topic label of some paragraphs may be wrong, then performance of topic detection
may be carefully exploited.

Mots-clefs — Keywords

Détection de theme, Etiquetage thématique, statistique Kappa, erreur de Bayes
Topic detection, topic assignment, Kappa statistics, Bayes error

A. Brun, K. Smafli

1 Introduction

Dans le cadre de la reconnaissance automatique de la parole, il a été montré que l’adaptation
des modeles au signal en cours de traitement permettait une amelioration des performances.
Plus concretement, les modeles que nous évoquons ici sont tout d’abord le modele acoustique
dont l’objectif est le traitement du signal pergu. Le second modele, quanta lui, est le modele de
langage, il représente la composante langagiere d’un systeme de reconnaissance de la parole.

Notons A le signal acoutique pergu par le systeme de reconnaissance de la parole, la séquence
de mots W reconnue par ce dernier sera celle correspondant a l’équation suivante :

W = argmaa: P(W | A) (1)

W
011 P(W | A) est la probabilité que la suite de mots W soit reconnue sachant que A a été pergu.
En utilisant la regle de Bayes, nous pouvons obtenir :

P(A 1 W) . P(W)

P(W 1 A) = P(A)

(2)

011 P(A | W) est la probabilité que le signal A soit pergu sachant que la suite de mots W a
été prononcée, elle est évaluée par le module acoustique (Haton et al., 1991; Calliope, 1989).
P(W), quant a lui, représente la probabilité de la suite de mots composant W, elle est évaluée
par le modele de langage.

Le modele auquel nous nous intéressons ici est le modele de langage et plus particulierement son
adaptation au signal en cours de reconnaissance. De nombreux travaux ont porté sur l’adaptation
des modeles de langage, montrant a la fois un gain en perplexité des modeles de langage mais
également en taux de reconnaissance (Kuhn & De Mori, 1990; Seymore & Rosenfeld, 1997).
Nous nous penchons ici sur un cas particulier de l’adaptation des modeles de langage, celui de
l’adaptation au theme de la séquence en cours de reconnaissance. Cette phase d’adaptation au
theme doit passer par une étape préalable de détection dudit theme.

La seconde section de cet article présente le domaine de la détection de theme : méthodes de de-
tection et d’évaluation des performances sur des corpus textuels, puis détaille les performances
effectives sur nos données. La troisieme partie s’intéresse a la remise en cause de l’étiquette
de référence des documents textuels sur lesquels se sont faits les tests de performance. La qua-
trieme partie présente le gain effectif de perplexité atteint grace a l’adaptation des modeles de
langage. Une conclusion et des perspectives a ce travail sont présentées dans la derniere section.

2 La détection de théme

La détection de theme consiste, sachant un ensemble prédéﬁni de themes et un document donné,
a assigner une etiquette thématique au document. Un theme dans notre cas est considéré comme
étant le sujet traité par un ensemble documents. Pour permettre l’eXploitation de ces themes,
nous utilisons un corpus, composé de documents traitant des themes auxquels nous nous in-
téressons.

Fiabilite’ de la référence humaine dans la détection de théme

2.1 Les corpus

Le corpus que nous utilisons dans notre etude est issu du journal Le Monde des annees 1987 a
1991. Les donnees, presentees sous forme d’articles, nous sont fournies deja classees. Chacune
de ces classes represente un secteur de redaction du journal, et les themes que nous etudions
seront ces memes secteurs de redaction.

De ce corpus, nous devons extraire un corpus de test. Nous choisissons volontairement de ne
traiter que des articles relatant d’un seul theme. Etant donne qu’il est plus probable qu’un
article entier traite de plusieurs themes, nous choisissons de travailler au niveau du paragraphe
que nous jugeons étre plus probable de ne traiter que d’un seul theme.

Le corpus de test que nous avons selectionne est donc compose de 835 paragraphes. Pour
l’etiquetage des paragraphes composant ce corpus, nous avons demande a un humain d’affecter
une etiquette thematique a ces paragraphes. Ce reetiquetage des paragraphes po11rra ajouter un
biais a notre experience (que nous jugeons cependant faible), les paragraphes d’apprentissage
n’etant pas reetiquetes par les humains.

Le corpus d’apprentissage est compose des paragraphes ne participant pas au test.

2.2 Méthodes et performances en détection de theme

Pour pouvoir detecter le theme d’un document donne, nous devons tout d’abord “apprendre”
les caracteristiques de chacun des themes pour ensuite les reperer dans un nouveau document.
Pour cela, nous representons chaque theme par un vecteur (Salton, 1991), 011 chaque dimen-
sion caracterise un mot, sa valeur representant la plupart du temps sa frequence dans le cor-
pus d’apprentissage. Pour detecter le theme d’un document donne il est indispensable de le
representer egalement vectoriellement pour pouvoir le comparer.

L’etape suivante consiste alors a comparer la representation vectorielle du document de test
avec chacune des representations vectorielles des themes. Il existe deux grandes approches pour
detecter le theme d’un document sachant les representations vectorielles, l’approche statistique
et l’approche machine learning, nous presentons maintenant les principes de quelques unes des
methodes de detection de theme.

0 L’approche statistique exploite la probabilite d’apparition des mots dans les themes et
dans le document de test. Nous pouvons par exemple citer le classiﬁeur de Bayes ou
modele unigramme (McDonough et al., 1994) qui evalue la probabilite de chaque theme
sachant le document de test (en exploitant la distribution de probabilite des mots dans les
themes et le document de test). Un autre exemple de methode probabiliste est le classi-
ﬁeur TFIDF (Salton, 1991) qui evalue la similarite existant entre le vecteur du document
de test et l’ensemble des vecteurs de theme.

0 L’approche machine learning se fonde sur l’apprentissage automatique. Les modeles
les plus courants sont les reseaux de neurones (Wiener et al., 1995) et les Machines a
Vecteurs Supports (SVMs) (Vapnik, 1995), qui recherchent le separateur optimal entre
les differents themes.

L’evaluation des performances d’une methode de detection de theme s’effectue sur le corpus
de test. Nous comparons le theme propose par la methode etudiee avec le theme effectif du

A. Brun, K. Smafli

Table 1: Performances en détection de theme

TFIDF Class. Bayes Rés. neur. SVM
Performances (%) 74.3 83.1 76.2 78.3

paragraphe (celui proposé par l’humain). Nos expérimentations on conduit aux performances
maximales données dans le tableau 1.

2.3 Combinaison de méthodes de détection de théme

Les méthodes présentées ci-dessus ont été optimisées au maximum, le seul moyen d’améliorer
les performances obtenues est alors de combiner les différentes méthodes. I1 existe plusieurs
méthodes de combinaison : combinaison linéaire, réseaux de neurones et SVM. La combinaison
a l’aide des SVM nous a permis d’obtenir les plus hautes performances : celles-ci atteignent
93.1%, le gain en performances est plus que signiﬁcatif (environ 10% en absolu) (Brun et al.,
2003).

Cependant, il reste 7% des paragraphes dont le theme n’est pas correctement détecté. Nous
nous sommes alors demandés la raison pour laquelle le theme de ces paragraphes n’était pas
correctement reconnu. Pour cela, nous nous sommes penchés sur l’étiquetage de référence des
paragraphes detest.

3 Remise en cause de l’étiquetage de référence

Les remarques avancées précédemment nous laissent penser que potentiellement l’étiquette de
référence des paragraphes utilisée n’est pas ﬁable et peut étre reInise en cause. En effet, la phase
d’étiquetage des paragraphes de test a été effectuée par un humain, source potentielle d’erreurs
et l’on ne peut donc pas connaitre a priori le degré de ﬁabilité des étiquettes affectées aux textes.
L’ étude que nous présentons dans la suite a pour but de connaitre le taux de conﬁance que nous
pouvons accorder a l’étiquetage humain.

3.1 L’expérience menée

Pour évaluer le taux de conﬁance que nous pouvons accorder a une étiquette fournie par un hu-
main, nous décidons d’étudier l’homogénéité de l’étiquetage fourni par un ensemble d’humains
sur des paragraphes. Pour ce faire, il nous faut, pour chaque paragraphe étudié, un ensemble
d’étiquettes, fournies par différents étiqueteurs (humains).

L’ ensemble de paragraphes utilisé est celui que nous avons déja traité ici : les 835 paragraphes
étiquetés manuellement. I1 nous faut alors recueillir plusieurs jeux d’étiquetages pour chacun de
ces 835 paragraphes. Ce nombre nous a semblé trop élevé pour trouver des personnes acceptant
d’étiqueter cet ensemble important de paragraphes. C’est pour cette raison que nous avons
choisi de ne travailler que sur un sous-ensemble de ce demier. Nous avons ainsi extrait, de

Fiabilite’ de la référence humaine dans la détection de théme

facon aléatoire, environ 15% des 835 paragraphes. Ensuite, pour chacun d’eux, nous avons du
récolter un ensemble d’étiquetages pour pouvoir étudier l’homogénéité des étiquettes.

Pour collecter ces étiquetages, nous avons fait appel a un ensemble de personnes bénévoles.
Nous leur avons tout d’abord foumi un bref descriptif de l’étude que nous menions, ou nous
expliquions notre objectif. Puis nous leur avons expliqué ce que nous attendions des étique-
teurs : a chacun des paragraphes fournis ils devaient donner 1 ou 2 étiquettes parmi un ensemble
d’étiquettes possibles. La premiere étiquette est obligatoire, la seconde, quanta elle, est option-
nelle. Ces étiquettes correspondent aux themes sur lesquels nous travaillons. Un descriptif de
ce que représente chacune des étiquettes (themes) leur a également été fourni.

Nous avons ensuite donné a chaque étiqueteur, une ou plusieurs séries de 10 paragraphes,
auxquels ils devaient affecter au moins une étiquette.

Aﬁn de nous situer dans le cadre d’une seule étiquette par paragraphe, nous ne retenons que les
paragraphes pour lesquels une seule étiquette a été donnée. A la ﬁn de l’expérience, nous avons
obtenu un ensemble de 12 étiquetages pour chacun des 89 paragraphes étudiés. Nous avons, par
la suite, cherché a analyser le degré de cohésion entre les étiqueteurs aﬁn d’en dériver le degré
de conﬁance que l’on peut accorder aux étiquettes des 835 paragraphes.

3.2 La mesure Kappa

La statistique Kappa (Cohen, 1960), récemment exploitée par Carletta (Carletta, 1996) comme
une mesure d’accord pour l’analyse de documents/discours, est un test applicable dans le cas
o1‘1 plusieurs sujets doivent assigner une étiquette parIr1i n a un texte.

Le calcul du coefﬁcient K d’accord entre les étiqueteurs tient compte de la chance a priori
que les étiqueteurs soient d’accord. K est indépendant du nombre d’étiqueteurs, du nombre
d’éléments a classer, ainsi que du nombre d’étiquettes a affecter aux éléments.

Le coefﬁcient K d’accord entre les étiqueteurs est déﬁni comme suit:

P(A) — P(E)
K = T 3
1 — P(E) ( )
ou P(A) est la proportion d’étiqueteurs qui sont d’accord (proposant la méme étiquette) et
P(E) est la proportion a priori que les étiqueteurs soient d’accord (proportion due a la chance
uniquement). Lorsque les étiqueteurs sont completement d’accord, K = 1 et a l’inverse si les
étiqueteurs ne sont pas plus d’accord que par chance, alors K = 0.

Selon Krippendorff (Krippendorff, 1980), une valeur de K > 0.8 est synonyme d’une bonne
cohérence entre les annotateurs. Une valeur 0.68 < K < 0.8 ne permet pas de rendre de
décision et une valeur K < 0.68 montre une non cohérence entre les étiqueteurs.

3.2.1 Apergu de l’étiquetage manuel

Le tableau TAB. 2 présente un sous-ensemble des étiquetages fournis sur les 89 paragraphes.
La valeur de chaque case (Tlm) correspond au nombre d’étiqueteurs ayant donné le theme Tj au
paragraphe P,-.

A. Brun, K. Smafli

Table 2: Exemple d’étiquetage de paragraphes

La derniere colonne contient les valeurs Si, qui correspondent £1 1’accord entre les étiqueteurs
pour le paragraphe 1'. Si a une valeur de 1 lorsque tous les étiqueteurs sont d’accord et une
valeur de 0 1orsqu’i1s ne sont pas du tout d’accord. Si est calculé de la maniere suivante:

Avec

m le nombre de themes, dans notre cas m = 7
0 1e nombre d’étiqueteurs, ici C = 12 étiqueteurs

La valeur de K (formule 3) nécessite la connaissance de P(A) et  P(A) représente 1e
taux d’accord entre les étiqueteurs et est calculé de la maniere suivante :

P(A) = (5)

ZIN

Avec

o N 1e nombre de paragraphes traités, ici N = 89 paragraphes

0 Z = 2?; Si est la valeur correspondanté1’accord entre les étiqueteurs, tous paragraphes
confondus

P(E), la proportion a priori d’étiqueteurs d’accord sur la meme étiquette, est calculée ainsi :

P(E) t N102  (6)

Avec

Para graphe T1 T2 T3 T4 T5 T6 T7 S
Culture Economie Etranger Histoire Politique Sciences Sports

P1 0 1 6 0 1 2 2 0.26

P2 0 0 0 0 0 12 0 1

P3 0 0 0 1 0 0 11 0.83
P4 7 3 2 0 0 0 0 0.38
P87 0 0 0 0 0 0 12 1

P88 1 0 0 0 0 11 0 0.83
P89 0 0 0 0 0 12 0 1

N = 89 T1=145 T2=56 T3=138 T4=33 T5=175 T6=271 T7=217 Z=67.0

Fiabilite’ de la référence humaine dans la détection de théme

o n, le nombre de themes
0 N 0, le nombre total d’étiquetages (= N >:< C = 89*12)

0 T1, T2, . . . , T7 les valeurs correspondant au nombre d’étiquettes données pour chaque
theme Tj.

3.2.2 Résultats

La valeur K obtenue sur les 89 paragraphes de test est de 0.52, cette valeur nous indique que les
étiqueteurs ne sont pas d’accord sur les étiquettes des paragraphes. Vu les différences au niveau
de l’étiquetage entre les étiqueteurs, nous pouvons en déduire que les étiquettes que nous avons
fournies a la main aux 835 paragraphes comportent probablement des erreurs.

Par conséquent, les étiquettes de référence que nous utilisons ne sont pas forcément les bonnes
étiquettes. Le taux d’étiquetage correct de 93.3% s’eXplique donc et dans une certaine mesure
représente un excellent résultat étant donnée la qualité de l’étiquetage de référence.

3.3 L’erreur de Bayes

3.3.1 Théorie

La statistique Kappa que nous venons d’étudier, ne nous permet pas de quantiﬁer le taux de
désaccord entre les étiqueteurs. L’ erreur de Bayes, que nous présentons maintenant Va nous
permettre d’estimer le pourcentage d’erreur d’étiquetage sur les 89 paragraphes.

Nous faisons l’hypothese que les données (d’étiquetage) résultent d’une expérience aléatoire
lancée de facon itérative. Soit Q = {w} l’ensemble fondamental de l’expérience (l’ensemble
des valeurs que peut prendre le résultat de l’eXpérience) et Z = (X, Y) la variable aléatoire telle
que X est l’ensemble des textes et I/((2) l’ensemble des catégories (themes). Chaque couple
texte/theme correspond alors a un couple (av, y) dans X X I/(Q), associé a w (i.e. 1: = X (cu)
et y = Y(w)). Ces notations étant posées, on peut prendre en considération les restrictions
précitées concernant l’universalité de l’étiquetage en faisant l’hypothese qu’il n’existe pas de
dépendance fonctionnelle entre 1: et y mais seulement une loi de probabilité jointe sur (X, Y).
Dans ce cadre, il est bien connu que le classiﬁeur ayant le plus petit taux d’erreur est celui qui
implémente la regle de décision de Bayes ((Fukunaga, 1990)). Ce taux d’erreur est donné par
la formule suivante :

RBayes : 1 _ Z

W Pay. 1 a:>dP<a:> <7)

ou yo = arg maxyP(y |  Elle constitue une borne inférieure sur le taux d’erreur que l’on
peut espérer atteindre. L’ implementation de la regle de décision de Bayes revient a choisir, pour
chaque texte, la catégorie correspondant au plus grand nombre de votes. L’ erreur peut ainsi étre
calculée de la facon suivante :

/\ 1 m
RBayes : 1 _ E :maxyf(y |  

i=1

A. Brun, K. Smafli

o1‘1 f (y |  est le nombre d’étiqueteurs affectant le theme y au texte 1:, et m est le nombre de
paragraphes. Prenons par exemple un paragraphe ayant recu l’étiquetage suivant :

Culture : 2, Economie : 0, Etranger : 0, Histoire : 1, Politique : 1, Sciences : 8, Sports : 0. La
valeur de maxy f (y |  sera alors égale a 8/ 12.

3.3.2 Résultats

Sur l’ensemble des 89 paragraphes étudiés, l’erreur de Bayes est de 15.7%. Cela signiﬁe que
l’on peut supposer que quasiment 16% des paragraphes peuvent avoir une étiquette fausse.
Cependant, cette valeur doit étre nuancée. En effet, bien qu’un descriptif ait été foumi aux
étiqueteurs avant les étiquetages, certains détails peuvent ne pas leur avoir été précisés, et un
biais peut avoir été introduit dans leur étiquetage.

Ces résultats nous menent de nouveau a penser que le fait que les performances de détection
de theme ne dépassent pas 93.3% est probablement dﬁ a la limite des performances humaines
elles-mémes.

Les résultats précédents nous indiquent donc que nous ne pouvons pas évaluer de facon ﬁable les
performances des méthodes de détection de theme étudiées. En effet, les étiquettes de référence
pouvant étre remises en doute, nous n’avons aucun référentiel ﬁable.

Par conséquent, il nous faut trouver une alternative a l’évaluation des méthodes de détection de
theme. Nous pouvons rappeler ici que nous effectuons la tache de détection de theme dans le
but d’effectuer une adaptation des modeles de langage dans les systemes de reconnaissance de
la parole. Ainsi, l’efﬁcacité de nos méthodes de détection de theme devra étre évaluée un pas
plus en avant dans le processus, c’est-a-dire au niveau de l’adaptation des modeles de langage.

Plus concretement, si nos expériences montrent que l’adaptation des modeles de langage au
theme détecté n’engendre pas une amélioration des performances de reconnaissance de la pa-
role (ou encore de perplexité), cela signiﬁera les méthodes de détection de theme ne sont pas
efﬁcaces. A l’opposé, si les performances s’améliorent, cela signiﬁera que nos méthodes sont
performantes. Nous chercherons dans ce cas a maximiser le gain (en perplexité ou en reconnais-
sance) obtenu. Lewis, dans (Lewis, 1991), a également énoncé le probleme de la non ﬁabilité
de l’étiquetage de référence humain. Pour y faire face, il propose également d’évaluer ces
performances durant une étape plus en avant dans le processus.

3.3.3 Etude plus approfondie des résultats

Nous allons maintenant étudier les performances, sur l’ensemble des 89 paragraphes, des dif-
férentes méthodes présentées dans ce document. Plus précisément, nous allons comparer les
performances obtenues par nos méthodes en fonction de celles des humains (i.e. du degré
d’accord entre les étiqueteurs). Les méthodes étudiées sont celles qui ont permis d’obtenir les
meilleures performances d’étiquetage.

Le tableau TAB. 3 présente les résultats de cette étude. Nous divisons l’ensemble des 89 para-
graphes en sous-ensembles, en fonction du degré d’accord des humains sur les paragraphes.

La premiere colonne montre parmi l’ensemble des 89 paragraphes, le nombre de paragraphes
de chaque sous-ensemble étudié. Les autres colonnes montrent soit le degré d’accord, soit les
performances des méthodes sur chaque ensemble.

Fiabilite’ de la référence humaine dans la détection de théme

Table 3: Comparaison du taux d’homogénéité des étiquettes humaines et des performances des
méthodes de détection de theme étudiées

Nb paragraphes Taux d’accord Perfs Unigramme Perfs RN Perfs TFIDF Perfs SVM
humain (Classif. Bayes)

39 12/12 37/39 38/39 38/39 38/39

15 11/12 14/15 14/15 12/15 14/15

8 10/12 6/8 7/8 6/8 7/8

10 9/12 9/10 8/10 9/10 8/10

3 8/12 2/3 2/3 2/3 2/3

2 7/12 2/2 2/2 1/2 1/2

6 6/12 4/6 4/6 3/6 4/6

6 5/12 2/6 1/6 2/6 2/6

Il est évident que le nombre de paragraphes par theme est trop petit pour parler de pourcentage,
mais nous pouvons tout de meme donner quelques impressions générales sur la tendance des
performances. Nous pouvons tout d’abord remarquer que sur les ensembles de paragraphes pour
lesquels les humains ont tendance a étre d’accord (1 1/ 12 et 12/12), les méthodes de détection
de theme sont tres performantes. A l’opposé, sur les paragraphes ou les humains ne sont pas
d’accord (doute sur le theme, taux d’accord < 8/ 12), les méthodes ont tendance a étre moins

performantes.

La ﬁgure FIG. 1 montre l’évolution de l’erreur en détection de theme en fonction de l’erreur de
Bayes moyenne du corpus de test. A nouveau, nous pouvons constater que moins les étiqueteurs
sont d’accord sur l’étiquette a assigner aux paragraphes, plus l’erreur de détection de theme

augmente.

Erreur dc détection dc theme (%)

20 I

 

0.06
Estimation de 1 erreur de Bayes

0.08

0.1

0.12

Figure 1: Evolution du taux d’erreur de détection de theme en fonction de l’erreur de Bayes du

corpus de test

A. Brun, K. Smaili

4 Conclusion et perspectives

Dans cet article, nous nous sommes interesses a la tache de detection de theme. Les perfor-
mances, sur notre corpus, de plusieurs methodes ont ete presentees. Apres avoir combine les
differentes methodes de detection de theme dans un but d’ameliorer les performances, nous
nous sommes rendus compte que le theme de certains paragraphes n’etait pas correctement re-
connu. Nous avons alors etudie les raisons de ce mauvais etiquetage, et plus particulierement
nous nous sommes penches sur le theme de reference accorde aux paragraphes de test.

L’ etude que nous avons ainsi menee s’interesse a l’homogeneite des etiquettes thematiques ac-
cordees par plusieurs humains sur des paragraphes detest. Cette etude montre que les differents
etiqueteurs (humains) sont regulierement d’accord sur l’etiquette a assigner aux paragraphes.
Cependant sur certains, leur avis divergent. Nous avons ainsi etudie dans quelle proportion
les avis des etiqueteurs divergaient en exploitant notamment la statistique Kappa et l’erreur de
Bayes. Nous en avons ainsi derive le taux d’erreur sur notre corpus de test (15.7%) et nous
avons pu conclure qu’une partie des erreurs d’etiquetage etait probablement due aux etiquettes
de reference du corpus de texte.

References

BRUN A., SMAILI K. & HATON J. (2003). Nouvelle approche de la selection de Vocabulaire pour la
detection de theme. In Traitement Automatique des Langues Naturelles (TALN2003), p. 45-54, Nantes,
France.

CALLIOPE (1989). La parole et son traitement automatique. Masson.

CARLETTA J. (1996). Assessing agreement on classiﬁcation tasks: the kappa statistics. Computational
linguistics, 22(2), 249-254.

COHEN J . (1960). A coefﬁcient of agreement for nominal scales. PSychological easurements.
FUKUNAGA K. (1990). Introduction to Statistical Pattern Recognition. Academic Press, 2nd edition.

HATON J ., PIERREL J ., PERENNOU G., CAELEN J . & GAUVAIN J . (1991). Reconnaissance automa-
tique de la parole. DUNOD Informatique.

KRIPPENDORFF K. (1980). Content Analysis: An introduction to its methodology. Sage Publications.

KUHN R. & DE MORI R. (1990). A cache-based natural language model for speech recognition. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 12(6), 570-582.

LEWIS D. (1991). Evaluating Text Categorization. In Speech and Natural Language Workshop, p.
312-318, Asilomar.

MCDONOUGH J ., NG K., JEANRENAUD P., GISH H. & ROHLICEK J . (1994). Approaches to Topic
Identiﬁcation On The Switchboard Corpus. In IEEE Transactions on Acoustics, Speech, and Signal
Processing, p. 385-388.

SALTON G. (1991). Developments in Automatic Text Retrieval. Science, 253, 974-979.

SEYMORE K. & ROSENFELD R. (1997). Using Story Topics for Language Model Adaptation. In
Proceeding of the European Conference on Speech Communication and Technology.

VAPNIK V. (1995). The Nature of Statistical Learning Theory. Spinger, New York.

WIENER E., PEDERSEN J . & WEIGEND A. (1995). A neural network approach to topic spotting. In
Fourth Annual Symposium on Document Analysis and Information Retrieval, SDAIR-95, p. 317-332,
University of Nevada, Las Vegas.

