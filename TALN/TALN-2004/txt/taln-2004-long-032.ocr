TALN 2004, Fés, 19-21 avril 2004

Annoter en constituants pour évaluer
des analyseurs syntaxiques

Anne Vilnat( 1 ), Laura Monceaux(2), Patrick Paroubek( 1 ), Isabelle Robba( 1 ),
Véronique Gendner(1), Gabriel Illouz(1), Michele Jardino( 1)

(1) LIMSI — CNRS
Université d’Orsay, BP 133
91403 Orsay CEDEX
{prénom.nom}@limsi.fr
(2) LINA
2 rue de la Houssiniere, BP 92208
44322 Nantes CEDEX O3
{prénom.nom}@lina.univ—nantes.fr

Résumé - Abstract

Cet article présente l’annotation en constituants mene’e dans le cadre d’un protocole d’évaluation
des analyseurs syntaxiques (mis au point dans le pré—projet PEAS, puis dans le projet EASY).
Le choix des constituants est décrit en détail et une premiere e’valuation effectue’e a partir des
résultats de deux analyseurs est donnée.

This paper focuses on constituent annotation in a syntactic parsers evaluation protocol (which
was elaborated in PEAS pre—project and EASY project). The choice of the constituents is
described in details, and the results of a ﬁrst evaluation between two parsers are given.

Mots-clefs — Keywords

annotation en constituants, e’valuation, analyseurs syntaxiques
constituent annotation, evaluation, syntactic parser

1 Introduction

Avec le développement d’Internet, l’acces a de grandes quantite’s de données textuelles est de-
venu possible ; les analyseurs syntaxiques qui, en amont d’autres outils linguistiques, traitent
ces données ont alors dﬁ se ﬁxer de nouveaux objectifs. ll doivent ainsi étre capables de traiter

A. Vilnat, L. Monceaux, P Paroubek, I. Robba, V Gendner, G. I11ouz, M. Jardino

ces grandes quantite’s en des temps raisonnables et surtout ils doivent faire face a des données
tres Variées dans leur forme et leur nature. C’est dans ce contexte que les analyseurs robustes ou
les analyseurs partiels ont été mis au point. Dans le meme temps, les analyseurs complets ont
continué d’étre étudiés, améliore’s et plus récemment des approches mixtes ont été élabore’es.
Ces dernieres retournent une analyse partielle de la phrase mais dont les éléments sont analyse’s
en profondeur quand cela est possible (Frank et al., 2003), (A'1't—Mokthar et al., 2002).

L’ e’Valuation des analyseurs permet d’une part a ceux qui les utilisent de connaitre leurs forces et
leurs faiblesses, et d’autre part a ceux qui les développent de disposer d’une reference a laquelle
ils peuvent se confronter. Cependant, comme le soulignent (Blache et Morin, 2003) ou (Briscoe
et al., 2002), l’éValuation des analyseurs syntaxiques n’est en rien une tache facile et ce pour
diverses raisons : les sorties des analyseurs Varient dans leur forme et leur nature d’un anal-
yseur a l’autre, et meme en parvenant a un accord sur ces sorties, des métriques équitables et
representatives ne sont pas actuellement disponibles. Conscients de ces difﬁcultés, nous avons
malgré tout mis au point un protocole complet d’évaluation des analyseurs syntaxiques, bap-
tisé PEAS, et dont la Volonté était de n’écarter la participation d’aucun analyseur. Ce protocole
PEAS (Gendner et al. , 2003) a servi de pré—proj et au projet EASY1 qui rassemble 5 fournisseurs
de corpus et 14 analyseurs participants. La campagne d’évaluation mene’e par EASY au print-
emps 2004 sera, dans la mesure du possible, reproductible et donc reconduite autant d’anne’es
que nécessaire. Apres une pre’sentation du protocole EASY, nous détaillons les principes adop-
tés pour l’annotation, nous exposons les premiers résultats d’évaluation comparative entre deux
analyseurs obtenus dans le cadre de PEAS et enﬁn nous évoquons quelques travaux connexes.

2 Présentation du protocole d’évaluation

Le protocole mis au point dans PEAS puis EASY est articulé autour des modules suivants :

1. La constitution d’un corpus d’1 million de mots, compose’ de textes hétérogenes en genre :
des articles de journaux, des extraits de romans, des recueils de questions, des transcrip-
tions de l’oral, des extraits de sites Internet. Et son formatage : normalisation, t0kem'sa—
tion et découpage en phrases.

2. L’annotation d’un sous—ensemble de 20 000 mots. Elle est effectuée a l’aide d’un éditeur
HTML et les résultats sont transcrits dans un format XML.

3. L’analyse par les participants et la transcription des sorties de leur analyseur dans un
format XML commun.

4. L’éValuation, prévue actuellement comme un calcul du rappel et de la précision sur les
constituants et les relations, est toujours ouverte a de nouvelles propositions.

Les décisions concernant le formalisme d’annotation ont été l’objet de nombreuses discussions
avec les fournisseurs de corpus d’une part (ils annotent de fagon semi—automatique ou manuelle
les corpus et doivent donc, dans la mesure du possible, étre en accord avec les choix portant
sur l’annotation) avec les participants d’autre part (qui doivent pouvoir disposer d’un format
dans lequel il leur sera possible de transcrire les résultats de leur analyseur). Par ailleurs, le

1Le projet EASY fait partie de la campagne d’évaluation EVALDA du programme Technolangue, qui est a
l’initiative du rninistére délégué a la Recherche et aux Nouvelles Technologies ; il a débuté en janvier 2003.

Annoter en constituants pour évaluer des analyseurs syntaxiques

formalisme doit permettre une couverture la plus large possible des phe’nomenes syntaxiques
de la langue. Notre but est aussi de constituer un corpus arboré, utilisable pour d’autres ap-
plications, constitue’ a la fois d’une partie annote’e manuellement, et d’une partie issue de la
combinaison des résultats des diffe’rents analyseurs participant a l’éValuation. Nous ne develop-
perons pas ce point ici, pour des raisons de place. Nous avons fait le choix d’annoter deux types
d’information : les constituants, avec leur catégorie et leur étendue et les relations syntaxiques
ou fonctionnelles, avec les éléments en relation, qui peuvent étre des mots ou des constituants.

3 L’ann0tati0n en constituants

3.1 Principe général

L’annotation que nous allons de’tailler dans cet article concerne les constituants, en supposant
que le découpage en phrases et le découpage en mots ont été préalablement e’tablis. Ces deux
découpages sont souvent conside’rés comme des problemes plus simples et quasiment reso-
lus, mais nous avons pu constater que lorsque l’on s’intéresse a des textes réels, ce n’était pas
toujours le cas ! Nous ne détaillerons pas cet aspect ici, mais nous donnerons quelques exem-
ples. Pour le découpage en phrases, le probleme est évidemment rendu plus difﬁcile quand les
textes analyse’s sont des transcriptions d’oral, spontane’ ou meme lu. La pre’sence de ponctua—
tions fortes telles que le point est alors soit restituée lors de la transcription, soit completement
absente. ll faut alors se fonder sur des criteres tels que la dure’e des pauses pour essayer de
re’—introduire la coupure en phrases. Les textes écrits posent également un certain nombre de
cas difﬁciles a résoudre : par exemple lorsque le texte présente de nombreuses énumérations,
sous forme de “listes a puces”, ou du discours rapporte’, comme illustré ci—dessous.

1. Pour brancher l’appareil, vous devez .'

0 vériﬁer votre installation électriqne. Si vous ne respectez pas les normes, votre
garantie ne fera plus eﬂet.

o relier le cordon d ’alimentation a votre appareil...

2. Le directeur aﬁirma .'“Je ne penx pas accepter une telle situation.”, devant le conseil
d ’administration de son établissement.

Nous avons choisi de conside’rer la phrase la plus longue possible, pour e’Viter des découpages
qui risqueraient de séparer des constituants, ou d’établir des relations en franchissant la frontiere
de phrase, comme dans l’eXemple 2 ou la ﬁn de la phrase se rapporte a la toute premiere partie,
avant le discours rapporte’.

Pour le découpage en mots, nous nous sommes inspiree’s du travail realise’ dans le cadre de
Grace (Adda et al., 1999) pour constituer une liste de mots compose’s ou de locutions qui ne
formeront qu’un seul mot lors de l’annotation en constituants. En revanche aucun étiquetage
morphosyntaxique de ces mots n’est fait au préalable (ni impose’ ou fourni aux systemes partic-
ipants a l’éValuation). Par exemple dans : Dés que le soleil se léve, les coqs chantent., Dés_que
ne forme qu’un seul mot.

Ces deux découpages étant faits, le découpage en constituants peut alors avoir lieu. Le probleme
se pose de déterminer le nombre et la taille de ces constituants. Le principe general que nous

A. Vilnat, L. Monceaux, P Paroubek, I. Robba, V Gendner, G. I11ouz, M. Jardino

avons adopte’ consiste a annoter des constituants minimaux, non discontinus et non récursifs.
Ce choix est dicte’ par le fait que nous souhaitons proposer un cadre qui permette d’éValuer
des analyseurs ayant des caractéristiques diverses, en essayant d’étre le plus equitable possible
envers chacun d’eux. Prenons un exemple simple : Le chat de la voisine. On peut analyser cette
phrase comme un groupe nominal complexe, constitue’ d’un groupe nominal (le chat) et d’un
groupe prépositionnel (de la voisine), extension (comple’ment de nom) du premier. On peut
aussi n’annoter que les deux constituants simples, le rattachement du groupe prépositionnel au
groupe nominal étant alors note’ par une relation modiﬁeur du nom. C’est cette solution que
nous avons adopte’e. Elle nous permet de ne pas rejeter les analyseurs qui ne relevent que les
constituants simples et de mieux noter les analyseurs plus précis ou ces deux informations sont
retrouvées. Ce parti pris nous permet e’galement de simpliﬁer la tache d’annotation.

3.2 Quels constituants retenir ?

Partant d’exemples réels et de la littérature sur le domaine ((Abeille’ et Blache 2000), (Marcus et
al., 1993)...), nous avons de’termine’ une liste de six constituants. Nous en donnons une premiere
deﬁnition, que nous illustrons sur des exemples simples 2. La délimitation d’un constituant GX
est donne’e dans une notation a la XML :<GX> le constituant GX </GX>.

0 le groupe nominal (GN) : il est constitue’ d’un nom éventuellement préce’de’ d’un determi-
nant (<GN> la porte </GN>) et/ou d’un adj ectif antépose’ accompagne’ de ses modiﬁeurs
(<GN> la lTe’s grande porte </GN>), d’un nom propre (<GN> Rouletabille </GN>) ou
d’un pronom NON clitique (<GN> eux </GN>, <GN> qui </GN>).

0 le groupe prépositionnel (GP) : il est constitue’ d’une préposition et du GN qu’elle intro-
duit (<GP> de la chambre </GP>) ou d’un déterminant et d’une préposition contracte’s
(du, aux, des) avec le GN introduit (<GP> du pavillon </GP>) ou d’une préposition
suivie d’un adverbe (<GP> de la </GP>), ou de pronoms qui remplacent des GP (<GP>
dont </GP>, <GP> on </GP>).

0 le noyau Verbal (NV) : il regroupe un Verbe, les pronoms clitiques plus éventuellement les
particules euphoniques (—t— et l’), ainsi que la particule ne qui lui sont rattache’s (<NV>
j’entendais </NV>, <NV> on ne l’entendait </NV> plus. Un noyau Verbal peut étre
a différents modes : temps conjugué mais aussi participe présent (<NV> désobéissant
</NV> a leurs parents), participe passe’ (<NV> fermée </NV> a clef) et inﬁnitif (<NV>
ne veut </NV> pas <NV> venir </NV>). En cas de temps compose’, nous identiﬁons un
NV distinct pour chaque Verbe (<NV> ils n’e’taient </NV> pas <NV> fermés </NV>).

0 le groupe adjectival (GA) : il contient un adjectif lorsqu’il n’est pas épithete antépose’
au nom (les barreaux <GA> intacts </GA>) ou un participe passe’ (la solution <GA>
retenue </GA> jut...) ou présent (les enfants <GA> de’sobe’issants </GA>) employé
comme adj ectif.

0 le groupe adverbial (GR) : il contient un adverbe, a l’exception du ne qui fait partie du
NV (<GR> aussi </GR>, <GR> encore </GR> ,vous n’auriez <GR> pas </GR>).

0 le groupe Verbal introduit par une préposition (PV) : il correspond a un noyau Verbal dont
le Verbe n’est pas conjugué (inﬁnitif, participe présent, ...) et introduit par une préposition

2Plusieurs extraits sont issus du Mystére de la chambrejaune, de Gaston Leroux.

Annoter en constituants pour évaluer des analyseurs syntaxiques

(<PV> d ’e’branler </PV>). ll peut contenir aussi des modiﬁeurs de ce Verbe, comme des
adverbes (<PV> de vraiment banger </PV>).

3.3 Quelques problémes

Le découpage décrit ci—dessus, semble simple a respecter, pourtant lors de l’annotation, nous
avons constate’ que meme pour les constituants comme le groupe nominal, ce n’est pas tou-
jours si facile. Nous allons illustrer quelques—uns des problemes lies a l’annotation du groupe
nominal, du groupe prépositionnel et du noyau Verbal. Cette pre’sentation ne prétend pas étre ex-
haustive mais illustrer a la fois les problemes rencontre’s et les solutions qu’a permis d’apporter
le choix de nos constituants minimaux.

3.3.1 Le groupe nominal GN

Pour le groupe nominal, nous détaillerons le cas du glissement d’usage d’un adjectif en nom,
et l’annotation des groupes nominaux désignant des personnes. Beaucoup d’adjectifs peuvent
jouer le role de nom et se construire de la meme fagon, a savoir étre sujet d’une phrase et se
construire avec un déterminant seul. La question est alors de savoir si on fait glisser la catégorie
du mot d’adjectif en nom, ou si on considere qu’il est possible d’aVoir un groupe nominal
sans nom, ou encore d’aVoir un groupe adjectival comme sujet. Nous n’aVons pas retenu cette
derniere possibilité, conside’rant que la fonction (sujet) et la construction avec un déterminant
sont des arguments sufﬁsamment forts pour faire de ces constituants des groupes nominaux. ll
reste a trancher entre les deux autres possibilite’s. Ainsi dans l’eXemple suivant :

<GN> La plus belle </GN> de la collection est <GN> la verte </GN>.

faut—il conside’rer que belle et verte deviennent des noms, ou qu’il est possible de délimiter un
groupe nominal constitue’ d’un déterminant et d’un adjectif ? Nous avons pre’fe’re’ ne pas forcer
la transcatégorisation des mots, qui n’a pas de réelle justiﬁcation, et donc accepter qu’un groupe
nominal puisse étre considére’ comme bien forme’, meme s’il ne comporte aucun nom.

Une autre question s’est posée quand nous avons eu a annoter une phrase telle que :

Le pre’sident Xavier Chapuisat est pre’sent.

Doit—il y avoir un seul, deux (< GN> Le pre’sident </GN> <GN> Xavier Chapuisat </GN>) ou
trois groupes nominaux (<GN> Le pre’sident </GN> <GN> Xavier </GN> <GN> Chapuisat
</GN>) ? Nous avons decide’ de conside’rer que lorsque plusieurs noms propres se succedent
sans déterminant ni preposition, ils forment un seul GN, dans les autres cas, nous en formons
plusieurs, qui seront lie’s par des relations de de’pendance. D’o1‘1 les annotations suivantes :
<GN> Le pre’sident </GN> <GN> Xavier Chapuisat </GN> est pre’sent.

<GN> Le de’pute’ </GN> <GN> PS </GN> est pre’sent.

<GN> Le pre’sident </GN> <GP> de l ’Universite’ Paris—Sud </GP > est pre’sent.

3.3.2 Le groupe prépositionnel GP

11 est important de noter que cette annotation en constituant GP n’est qu’un raccourci qui permet
de noter a la fois l’étiquette du constituant et la relation entre le premier élément (la preposi-
tion) et ce qui suit (le GN introduit). Elle est possible dans la plupart des cas de GP, car la
préposition n’est que rarement détache’e du GN qu’elle introduit. C’est pourquoi nous l’aVons

A. Vilnat, L. Monceaux, P Paroubek, I. Robba, V Gendner, G. I11ouz, M. Jardino

retenu. Cependant, on peut rencontrer des cas d’incises par exemple ou il y a separation entre
ces elements. 11 faut alors revenir a l’annotation "complete", a savoir : annoter le GN comme
tel, laisser la preposition non annote’e et traduire la relation de dépendance entre la preposition
et le GN par une relation de type comple’menteur. Par exemple :

Il arrive <GP> en retard <GP> , avec , <GP> dans sa poche <GP> , <GN> an petit discours
</GN> e’crit qu’ il est oblige’ de garder.

en retard et dans sa poche sont annote’s simplement comme des GP. En revanche, la relation
entre avec et un petit discours sera elle annote’e a l’aide d’une relation de dépendance. ll faudra
lors de l’éValuation conside’rer que ces annotations sont équivalentes.

On trouve un cas un peu similaire lors de coordinations ou la preposition est "factorisée" pour
deux GN.

<GN> lesjeimesﬁlles </GN> arboraient donc <GN> imﬁchu </GN> e’troitement noue’ <GP>
sous le menton </GP> <GP> dans les couloirs </GP> et <GN> la cour </GN> <GP> de
recreation </GP>

La relation entre dans et la cour sera annote’e elle aussi comme une dépendance.

3.3.3 Le noyau verbal NV

Nous allons de’tailler ici deux points : l’annotation des négations, et la distinction entre par-
ticipes conside’rés comme noyau Verbal et ceux conside’rés comme adjectifs. La particule de
négation ne est incluse dans le NV auquel elle se rattache. Les autres adverbes de négation
forment un GR car ils peuvent se trouver a distance du Verbe auquel ils se rattachent. Dans la
forme ne...que, que est adverbe et forme un GR, ne reste rattache’ au Verbe (dans le NV corre-
spondant). Avec un inﬁnitif, les adverbes de négation sont place’s avant le Verbe; dans ce cas ils
sont inclus dans le NV ou le PV : ma ﬁlle avaitjure’ <PV> de ne jamais me quitter </PV>.

La distinction entre noyau Verbal et groupe adjectival n’est pas forcément claire quand il s’agit
d’annoter des participes présents ou passés.

Dans le cas de temps compose’s, les participes passe’s qui suivent un auxiliaire , comme par
exemple : le coq <NV> a </NV> <NV> chante’ <NV> forment un noyau Verbal. Un noyau
Verbal est également identiﬁe’ quand on reconnait une proposition participiale :

leurs enfants <NV> e’leve’s <NV>, les parents entreprennent un grand voyage

ces prescriptions<NV> ame’liorant </NV> son e’tat, le me’decin poursuivit le traitement

Enﬁn, les participes sont conside’rés comme Verbes quand ils sont modiﬁe’s par un complément,
comme dans :

La porte de la chambre <NV> ferme’e </NV> a clef a l ’inte’rieur.

Les coteaux <NV> environnant </NV> la ville sont tres verts.

Dans les autres cas, ils sont notés comme des adjectifs.

3.4 Quel bénéﬁce ?

Pour conclure cette pre’sentation, plusieurs questions se posent. La premiere est de savoir si
l’annotation manuelle d’un gros corpus en suivant ces principes est possible. Pour répondre a
cette question, nous avons d’abord annote’ un premier corpus, ce qui nous a permis de Veriﬁer le
bien fonde’ de notre approche. Cette annotation a concerne’ aussi bien les constituants que nous
avons présente’ ici que les relations (non de’taille’es dans cet article), qui traduisent a la fois les

Annoter en constituants pour évaluer des analyseurs syntaxiques

imbrications des groupes simples dans des groupes plus complexes comme nous l’avons montre’
plus haut, que les relations syntaxiques comme la relation sujet pour n’évoquer que celle—ci.
Nous avons pour cela développe’ des outils d’annotation simples, ne nécessitant que l’usage
d’un éditeur HTML standard. Cette étude ne nous a pas permis de détecter tous les problemes,
mais de lancer la campagne d’annotation du projet EASY, sur un corpus beaucoup plus gros.
Les problemes rencontre’s par les annotateurs nous ont alors permis d’afﬁner nos de’ﬁnitions,
sans remettre en cause le cadre géne’ral. On peut aussi se demander si cette annotation qui
parait simple permet de mettre en évidence des différences entre les analyseurs, meme si nous
souhaitons a terme procéder a une e’valuation globale qui regroupe constituants et relations.
C’est le but de l’étude que nous allons présenter ci—dessous.

4 Premiers résultats de l’évaluati0n menée dans PEAS

Dans le protocole d’évaluation PEAS, nous comparons les sorties des différents analyseurs a un
corpus annote’ de référence en calculant les mesures de précision et de rappel pour les différents
constituants et pour chaque type de constituant présent dans le corpus de re’férence. Nous avons
en effet élabore’ un corpus de référence compose’ de diffe’rents types de texte : corpus journalis-
tiques (note’ dans les ﬁgures : LeMonde.num), des extraits de roman (ABU.num et L782.num),
des questions et des corpus oraux (111997.num et SECODIP.num), aﬁn de permettre une eval-
uation cible’e sur les phe’nomenes linguistiques propres a un type de texte particulier. Pour
pouvoir comparer les sorties des analyseurs avec notre corpus de référence, elles devront étre
projete’es dans le formalisme PEAS présente’ section 3. Cette projection passe par l’application
de regles de réécriture plus ou moins complexes. Dans la projection des deux analyseurs eval-
ués, certaines informations ne sont pas représente’es par le meme type d’information (adverbe
représenté par une étiquette morpho—syntaxique et non par un constituant) (Monceaux 2002).

Une fois la projection réalise’e, la concordance de la segmentation en e’nonce’s et en formes en-
tre la référence et les sorties des analyseurs doit étre vériﬁe’e, car les analyseurs syntaxiques
n’effectuent pas nécessairement des segmentations identiques a celles de la re’férence. Une
étape de réalignement est donc nécessaire. Notons que le décompte des erreurs se fait selon
la segmentation de la référence ce qui peut parfois entrainer une variation artiﬁcielle du nom-
bre de formes (et potentiellement d’erreurs) certaines formes n’étant pas réaligne’es ou bien
faisant l’objet d’une expansion en plusieurs tokens ; mais jusqu’a présent ce biais (variation
des distances entre les points représentatifs des performances des systemes) n’a jamais remis en
cause les résultats globaux de l’évaluation, ni les différences relatives de performance entre les
différents systemes.

Dans les résultats des ﬁgures 1 et 2, on constate que l’analyseur p2 retourne plus d’informations
précises et en plus grand nombre que l’analyseur pl, sauf pour le constituant PV. Mais si l’on
regarde de plus pres les mesures effectue’es, pour chaque constituant, par type de corpus, on
peut constater que dans certains cas la précision de l’analyseur pl est légérement plus e’levée
que celle de p2, comme par exemple pour le sous—corpus de questions, ou la précision globale
de tous les constituants est sensiblement meilleure pour l’analyseur pl.

D’apres les mesures effectue’es, la tache de segmentation en constituants ne semble pas étre aussi
simple qu’il parait, puisque globalement l’analyseur p2 renvoie environ 20% d’informations
errone’es et ne de’tecte pas environ 20% des constituants. Dans cette evaluation, on note aussi
que le constituant GA semble étre le constituant posant le plus de problemes : pour les deux

A. Vilnat, L. Monceaux, P Paroubek, I. Robba, V Gendner, G. I11ouz, M. Jardino

P99999999
oumuammummu

P99999999
oumuammummu

Figure 2: Re’sultats compare’s en rappel

analyseurs, la précision et le rappel sont beaucoup plus faibles.

L’éValuation propose’e par PEAS présente les comparaisons de performance en fonction du
type de composant et de texte, ce qui permet d’effectuer des comparaisons ﬁnes entre les sys-
temes ou de calibrer au mieux les performances d’un analyseur en fonction des spéciﬁcités de
l’application pour laquelle il sera utilise’.

5 Travaux en évaluation des analyseurs syntaxiques

A notre connaissance, pour les analyseurs du frangais, la premiere publication sur l’éValuation
des analyseurs syntaxiques est (Abeille’, 1991) qui relate l’éValuation par un comité d’eXperts de
plusieurs analyseurs du francais. Cette e’Valuation portait sur le nombre d’analyses retournées
et sur leur Validite’. Le projet TSNLP (Oepen et al., 1996) a tente’ de capitaliser les connais-
sances linguistiques sous forme de jeux de tests. 11 offre pour plusieurs langues européennes
dont le francais, des phrases de test avec des exemples positifs et négatifs, pour les principaux
phe’nomenes syntaxiques. Les corpus arbore’s offrent l’aVantage d’étre plus représentatifs de
la distribution des phe’nomenes linguistiques dans la langue, le premier et le plus célebre est
certainement le PennTreeBank (Marcus et al., 1993), qui contient des annotations base’es sur les
constituants et qui a inspire’ d’autres développements, par exemple (Brants et al., 2002) ou pour
le frangais (Abeille’ et Blache 2000).

Annoter en constituants pour évaluer des analyseurs syntaxiques

La premiere campagne d’éValuation comparative selon une méthodologie boite noire est (Black
et al., 1991) qui attaque le probleme par le biais des mesures d’éValuation et propose de com-
parer les systemes sur les frontieres de constituants au moyen du taux de croisement (nombre de
frontieres de constituants produits par l’analyseur, qui croisent une frontiere de constituant de la
référence) et le taux de rappel (nombre de frontieres de constituants produits par l’analyseur qui
existent dans la référence). On a par la suite aj oute’ la précision a ces deux mesures pour former
ce que l’on appelle le GEIG7 scheme (Srinivas et al., 1996) ou mesures PARSEVAL (Carroll et
al., 2003). Malheureusement ces mesures ne sont applicables pratiquement que sur des consti-
tuants non étiquetés (dépourvus de catégorie), les sorties des analyseurs étant trop diffe’rentes
pour essayer d’incorporer cette information dans le processus d’e’Valuation. 11 en résulte une
e’Valuation ne tenant compte que d’une partie des informations produites par les analyseurs et
qui de plus s’applique plus facilement aux formalismes produisant une analyse en constituants.

Pour essayer d’ouVrir l’éValuation Vers diffe’rents types d’analyseurs de nouvelles approches
oriente’es sur les dépendances (Lin, 1998) ou meme sur les relations grammaticales sont ap-
parues (Carroll et al., 1998) (Briscoe et al., 2002) (Carroll et al., 2003). C’est l’approche que
nous suivons dans EASY (Vilnat et al., 2003).

6 Conclusion

Les travaux initie’s dans PEAS et en cours de développement dans la campagne EVALDA—
EASY du programme TECHNOLANGUE ont permis de Valider comme support d’éValuation,
un formalisme d’annotation syntaxique pour le frangais, a la fois sur les phénomenes linguis-
tiques effectivement rencontre’s en corpus et Vis—a—Vis de la communaute’ des développeurs de
systemes. Ce résultat est concre’tise’ dans le guide d’annotation3, décrivant comment utiliser
le formalisme. Nous avons aussi présente’ un premier ensemble de mesures de précision et de
rappel sur les frontieres de constituants, realise’ sur le corpus PEAS avec le concours de deux
participants te’moins. Bien que les differences de performance observées soient relativement
faibles, le calcul des résultats par type de constitutant et de corpus permet d’aVoir une perception
ﬁne des differences de comportement entre les deux systemes. Ces résultats seront compléte’s
dans un avenir tres proche par une comparaison avec un algorithme de simple identiﬁcation
des constituants, une étude de pertinence statistique des différences observées, et une étude de
l’effet sur les résultats d’un relachement de contraintes sur les frontieres de constituants. Bien
entendu, les résultats prendont toute leur signiﬁcation lorsque les mesures auront e’té effectue’es
dans la campagne EASY, sur un corpus de taille plus importante, avec plus de participants, et
surtout accompagne’es de mesures sur les dépendances.

Remerciements

Nous tenons ici a remercier les membres de ELDA qui participent a l’organisation de EASY :
Khalid Choukri et Kevin Mc Tait ; ainsi que les premiers annotateurs, Remy Bonnet et Pierre
Zweigenbaum, et l’équipe de Jean Véronis (LPL a Aix) qui nous ont permis par leurs questions
pertinentes et précises de compléter d’eXemples et d’eXplications notre guide d’annotation.

3http://wwW.limsi.fr/Recherche/CORVAL/easy/

A. Vilnat, L. Monceaux, P Paroubek, I. Robba, V Gendner, G. I11ouz, M. Jardino

Références

ABEILLE A. (1991), Analyseurs syntaxiques du frangais, Bulletin Semestriel de l ’ATALA (Association
pour le T raitement Automatique des Langues), Vol. 32, No. 21, pp. 107-120.

ABEILLE A., BLACHE P. (2000), Gramrnaires et Analyseurs syntaxiques, Inge’nierie des Langues sous
la direction de J.-M. Pierrel, Ch. 2, pp. 51-76, Hermes, Paris.

ADDA G., MARIANI J ., PAROUBEK P., RAJMAN M., LECOMTE J .(1999) L’action GRACE

d’évaluation de l’assignation de parties du discours pour le frangais, Langues, Vol. 2, No. 2, pp 119-
129.

AIT-MOKTHAR S., CHANOD J., ROUX C. (2002), Robustness beyond shallowness : incremental deep
parsing, Journal ofNatural Language Engineering, Vol. 8, No. 3-2.

BLACHE P., MORIN J.-Y. (2003), Une grille d’évaluation pour les analyseurs syntaxiques, Atelier sur
l ’e’valuation des analyseurs syntaxiques - T ALN, pp 77-86

BLACK E., ABNEY S., FLICKENGER D., GDANIEC C., GRISHMAN R., HARISON P., HINDLE D.,
INGRIA R., JELINECK F., KLAVANS J ., LIBERMAN M., MARCUS M., ROUKOS S., SANTORINI B.,
STRZALKOZSKI T. (1991), A Procedure for Quantitatively Comparing the Syntactic Coverage of English
Grammars, 4th DARPA Speech and Natural Language Workshop, Morgan Kaufman, pp. 306-311.

BRANTS T., DIPPER S., HANSEN S., LEZIUS W., SMITH G. (2002), The TIGER Treebank, Irst Work-
shop on T reebanks and Linguistic Theories ( T LT ), Sozopol, Bulgaria.

BRISCOE E, CARROLL J., GRAHAM J., COPESTAKE A. (2002), Relational evaluation schemes, Work-
shop Beyond PARSEVAL - Toward improved evaluation measures for parsing systems, 3rd LREC, Las
Palmas, Gran Canaria.

CARROLL J., BRISCOE T., SANFILIPO A. (1998), Parser Evaluation: a Survey and a New Proposal, 1 st
LREC, Granada, vol. 1 pp. 447-454

CARROLL J., MINNEN G., BRISCOE E. (2003) Parser evaluation using a grammatical relation annota-
tion scheme, In A. Abeillé (ed.), Treebanks: Building and Using Parsed Corpora, Dordrecht Kluwer, pp.
299-3 16

FRANK A., BECKER M., CRYSMANN B., KIEFER B., SCHAFER U. (2003) Integrated shallow and
deep parsing : TopP meets HPSG , 41 st ACL, pp. 104-111, 2003

GENDNER V., ILLOUZ G., JARDINO M., PAROUBEK P., MONCEAUX L., ROBBA I., VILNAT A.
(2003), Proposition de protocole d’évaluation des analyseurs syntaxiques, Atelier sur l ’e’valuation des
analyseurs syntaxiques de la confe’rence T ALN , pp 87-94

LIN D. (1998), Dependency-B ased Evaluation of MINIPAR Workshop on Evaluation ofParsing Systems,
1st LREC, Granada.

MARCUS M., SANTORINI B., MARCINKIEWICZ M. (1993), Building a large annotated corpus of En-
glish : The Penn treebank, Computational Linguistics, 19.1313-330

MONCEAUX L. (2002), Adaptation du niveau d ’analyse des interventions dans un dialogue. Application
a un systeme de question-re’ponse. These de l’université Paris 11, Décembre 2002.

OEPEN S., NETTER N., KLEIN J. (1996), Test Suites for Natural Language Processing, Linguistic
Databases, Nerbonne J. editor, Center for the Study of Language and Information, CSLI Lecture Notes.

SRIVINAS B., DORAN C., HOCKEY B.A., JOSHI A.K. (1996), An approach to Robust Partial Parsing
and Evaluation Metrics,Workshop on Robust Parsing, ESSLI, Prague.

VILNAT A. , PAROUBEK P. , MONCEAUX L. , ROBBA I. , GENDNER V. , ILLOUZ G. , JARDINO M.
(2003), EASY or How Difﬁcult Can It Be to Deﬁne a Reference Treebank for French, 2nd Workshop on
T reebanks and Linguistic Theories ( T LT ) , Vaxjo, Sweden.

