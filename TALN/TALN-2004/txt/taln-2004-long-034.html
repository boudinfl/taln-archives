<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Apprentissage partiel de grammaires cat&#233;gorielles</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2004, F&#232;s, 19&#8211;21 avril 2004
</p>
<p>Apprentissage partiel de grammaires cat&#233;gorielles
</p>
<p>Erwan Moreau
LINA - Universit&#233; de Nantes
</p>
<p>2 rue de la Houssini&#232;re - BP 92208 - 44322 Nantes cedex 3
Erwan.Moreau@irin.univ-nantes.fr
</p>
<p>R&#233;sum&#233; - Abstract
</p>
<p>Cet article traite de l&#8217;apprentissage symbolique de r&#232;gles syntaxiques dans le mod&#232;le de Gold.
Kanazawa a montr&#233; que certaines classes de grammaires cat&#233;gorielles sont apprenables dans ce
mod&#232;le. L&#8217;algorithme qu&#8217;il propose n&#233;cessite une grande quantit&#233; d&#8217;information en entr&#233;e pour
&#234;tre efficace. En changeant la nature des informations en entr&#233;e, nous proposons un algorithme
d&#8217;apprentissage de grammaires cat&#233;gorielles plus r&#233;aliste dans la perspective d&#8217;applications au
langage naturel.
</p>
<p>This article deals with symbolic learning of syntactic rules in Gold&#8217;s model. Kanazawa showed
that some classes of categorial grammars are learnable in this model. But the algorithm needs a
high amount of information as input to be efficient. By changing the kind of information taken
as input, we propose a learning algorithm for categorial grammars which is more realistic in the
perspective of applications to natural language.
</p>
<p>Mots-clefs &#8211; Keywords
</p>
<p>Apprentissage partiel, inf&#233;rence grammaticale, grammaire cat&#233;gorielles.
Partial learning, grammatical inference, categorial grammars.
</p>
<p>1 Introduction
</p>
<p>Malgr&#233; la facilit&#233; presque surprenante avec laquelle un enfant est capable d&#8217;acqu&#233;rir sa langue
maternelle, la r&#233;alisation d&#8217;un tel processus par la machine est un probl&#232;me tr&#232;s difficile. Ce
probl&#232;me de l&#8217;apprentissage automatique de grammaires consiste &#224; d&#233;couvrir les r&#232;gles (syn-
taxiques) de formation des phrases d&#8217;un langage particulier. Plusieurs mod&#232;les de formalisation
de ce processus existent. Le mod&#232;le de Gold (Gold, 1967) est celui que nous utilisons dans
cet article, et plus sp&#233;cifiquement la m&#233;thode propos&#233;e par Buszkowski (Buszkowski &amp; Penn,
1989) et g&#233;n&#233;ralis&#233;e par Kanazawa (Kanazawa, 1998) dans ce mod&#232;le.
</p>
<p>Le mod&#232;le d&#8217;apprentissage propos&#233; par Gold est tr&#232;s restrictif, c&#8217;est pourquoi les premiers r&#233;-
sultats obtenus avec ce mod&#232;le ont &#233;t&#233; n&#233;gatifs. Cependant Kanazawa a montr&#233; que certaines
classes de langages non triviales sont apprenables, en se servant de l&#8217;algorithme propos&#233; par</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Erwan Moreau
</p>
<p>Buszkoswki pour les grammaires cat&#233;gorielles. Le m&#233;canisme d&#8217;apprentissage propos&#233; est en-
ti&#232;rement symbolique, c&#8217;est-&#224;-dire qu&#8217;aucun traitement statistique n&#8217;est utilis&#233; : cela implique
que le risque d&#8217;erreur est r&#233;duit &#224; z&#233;ro, mais aussi que le bon fonctionnement de l&#8217;algorithme
d&#8217;apprentissage doit satisfaire des contraintes importantes.
</p>
<p>L&#8217;une de ces contraintes qui font obstacle &#224; l&#8217;application de cette m&#233;thode au langage naturel
concerne la nature des donn&#233;es dont l&#8217;algorithme a besoin en entr&#233;e : il ne s&#8217;agit pas seulement
de phrases simples mais de structures particuli&#232;res, ce qui permet &#224; l&#8217;algorithme d&#8217;&#234;tre d&#233;ter-
ministe et efficace. Ces structures sont une forme &#8220;d&#8217;arbre de d&#233;rivation appauvri&#8221; des phrases
consid&#233;r&#233;es, dans le formalisme des grammaires cat&#233;gorielles. La disponibilit&#233; de telles struc-
tures dans des cas r&#233;els (i.e. pas seulement sur des exemples jouets) est loin d&#8217;&#234;tre assur&#233;e
pour deux raisons : d&#8217;une part le formalisme des grammaires cat&#233;gorielles est tr&#232;s peu utilis&#233;
(en grande partie du fait de sa faible expressivit&#233;); d&#8217;autre part la connaissance de la gram-
maire sous-jacente est quasiment indispensable &#224; la construction de ces structures, ce qui est un
handicap majeur puisque l&#8217;objectif est pr&#233;cis&#233;ment de d&#233;duire cette grammaire.
</p>
<p>Nous proposons ici un compromis, bas&#233; sur la m&#233;thode de Kanazawa, qui conserve les avan-
tages de l&#8217;apprentissage symbolique tout en &#233;liminant cette contrainte sur les structures. En
contrepartie, on consid&#233;rera qu&#8217;une partie de la grammaire est d&#233;j&#224; connue, de mani&#232;re &#224; rem-
placer l&#8217;information apport&#233;e par les structures par celle apport&#233;e par la grammaire initiale.
Cette hypoth&#232;se est r&#233;aliste dans la perspective de l&#8217;application aux cas r&#233;els, du fait notamment
de la lexicalisation totale des grammaires cat&#233;gorielles. L&#8217;inconv&#233;nient &#233;tant que l&#8217;efficacit&#233; de
l&#8217;apprentissage d&#233;pend d&#233;sormais beaucoup de la grammaire initiale.
</p>
<p>2 Apprentissage de grammaires cat&#233;gorielles
</p>
<p>2.1 Grammaires AB
</p>
<p>Les grammaires cat&#233;gorielles classiques, nomm&#233;es aussi grammaires AB, ont &#233;t&#233; introduites
dans (Bar-Hillel et al., 1960). Ces grammaires sont totalement lexicalis&#233;es : cela signifie
qu&#8217;une grammaire est d&#233;crite uniquement par son lexique, le lexique &#233;tant l&#8217;association d&#8217;une
ou plusieurs cat&#233;gories &#224; chaque mot du vocabulaire. Les r&#232;gles utilis&#233;es dans les d&#233;rivations
sont donc universelles. Ces r&#232;gles sont :
</p>
<p>A/B, B &#8594; A FA (Forward Application)
B, B\A &#8594; A BA (Backward Application)
</p>
<p>Les cat&#233;gories sont des termes utilisant les op&#233;rateurs binaires / et\. Intuitivement, une expres-
sion est de type A/B (resp. B\A) si cette expression est de type A lorsqu&#8217;elle est suivie (resp.
pr&#233;c&#233;d&#233;e) par une expression de type B. Une phrase est correcte s&#8217;il est possible d&#8217;associer
&#224; chaque mot l&#8217;une de ses cat&#233;gories, de telle sorte que les r&#232;gles universelles permettent de
transformer cette s&#233;quence de cat&#233;gories en la cat&#233;gorie sp&#233;ciale S.
</p>
<p>Exemple : Soit G la grammaire constitu&#233;e du lexique suivant :
</p>
<p>{ Pierre, Marie, Paul : SN ; aime, d&#233;teste : (SN \S)/SN ; qui : (SN \SN)/(SN \S) }.
La phrase &#8220;Pierre, qui aime Marie, d&#233;teste Paul&#8221; appartient au langage de cette grammaire,
comme le montre la d&#233;rivation suivante :</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Apprentissage partiel de grammaires cat&#233;gorielles
</p>
<p>SN, (SN\SN)/(SN\S), (SN\S)/SN, SN, (SN\S)/SN, SN &#8658; SN, (SN\SN)/(SN\
S), (SN \S)/SN, SN, SN \S &#8658; SN, (SN \SN)/(SN \S), SN \S, SN \S &#8658; SN, SN \
SN, SN \S &#8658; SN, SN \S &#8658; S
Une grammaire AB est rigide si chaque mot n&#8217;est d&#233;fini que par une seul cat&#233;gorie. De m&#234;me,
une grammaire est dite k-valu&#233;e si chaque mot est d&#233;fini par au plus k cat&#233;gories.
</p>
<p>On peut d&#233;crire une d&#233;rivation &#224; l&#8217;aide d&#8217;un arbre de mani&#232;re classique, en &#233;tiquetant les n&#339;uds
par la cat&#233;gorie du constituant qu&#8217;ils repr&#233;sentent. De plus, la forme des r&#232;gles permet aussi
de repr&#233;senter un arbre de d&#233;rivation en &#233;tiquetant les n&#339;uds seulement par l&#8217;identifiant de la
r&#232;gle utilis&#233;e (FA ou BA). Une telle structure dans laquelle les feuilles ne sont &#233;tiquet&#233;es que
par un mot est appell&#233;e FA-structure (pour Functor-Argument structure). Cette repr&#233;sention est
unique pour un arbre de d&#233;rivation donn&#233; (voir figure 1). En revanche une FA-structure donn&#233;e
peut repr&#233;senter un nombre infini d&#8217;arbres de d&#233;rivations : dans la figure 1, on peut par exemple
remplacer tous les SN par des (X1/X2)/.../Xn et la FA-structure reste identique.
</p>
<p>Pierre qui aime Marie d&#233;teste Paul
</p>
<p>S
</p>
<p>SN SNSN (SN \S)/SN(SN \S)/SN(SN \SN)/(SN \S)
</p>
<p>SN \S
</p>
<p>SN \SN
</p>
<p>SN
</p>
<p>SN \S 1&#8594;
</p>
<p>&#8734;&#8592;
</p>
<p>Pierre qui aime Marie d&#233;teste Paul
</p>
<p>FA FA
</p>
<p>FA
</p>
<p>BA
</p>
<p>BA
</p>
<p>Figure 1: Arbre de d&#233;rivation
</p>
<p>2.2 L&#8217;algorithme RG
</p>
<p>L&#8217;algorithme RG (pour Rigid Grammars), propos&#233; par Buszkowski (Buszkowski &amp; Penn, 1989),
apprend la classe des grammaires AB rigides &#224; partir de FA-structures dans le mod&#232;le de Gold
(Gold, 1967). Dans ce mod&#232;le, l&#8217;algorithme d&#8217;apprentissage doit d&#233;duire la grammaire &#224; partir
d&#8217;une suite infinie de phrases appartenant au langage g&#233;n&#233;r&#233; par celle-ci (exemples positifs).
Apr&#232;s chaque exemple, l&#8217;algorithme effectue une hypoth&#232;se, en proposant une grammaire. Si
l&#8217;algorithme ne change plus d&#8217;hypoth&#232;se &#224; partir d&#8217;une certaine &#233;tape, alors celui-ci converge.
La grammaire-cible est correctement apprise si l&#8217;algorithme converge vers cette grammaire (ou
une qui lui soit &#233;quivalente). Une classe de grammaires est apprenable s&#8217;il existe un algorithme
qui, pour toute &#233;num&#233;ration du langage engendr&#233; par une grammaire de cette classe, converge
vers cette derni&#232;re.
</p>
<p>2.2.1 Algorithme
</p>
<p>L&#8217;algorithme RG comporte deux &#233;tapes. La premi&#232;re consiste &#224; construire une grammaire
g&#233;n&#233;rale &#224; partir de la s&#233;quence de FA-structures fournies comme exemples :
</p>
<p>Soit D = &#12296;T1, .., Tn&#12297; la s&#233;quence de FA-structures en entr&#233;e.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Erwan Moreau
</p>
<p>1. Etiquetage d&#8217;une structure Ti :
</p>
<p>(a) la racine de Ti est &#233;tiquet&#233;e par le type S (le type primitif qui caract&#233;rise les phrases
correctes).
</p>
<p>(b) en allant de la racine vers les feuilles, les fils de chaque n&#339;ud t sont &#233;tiquet&#233;s de la
mani&#232;re suivante : une nouvelle variable x est cr&#233;&#233;e, avec laquelle le n&#339;ud argument
est &#233;tiquet&#233;. L&#8217;autre n&#339;ud est &#233;tiquet&#233; t/x ou x\ t selon qu&#8217;il s&#8217;agit d&#8217;un n&#339;ud FA
ou BA. Le n&#339;ud argument est celui de la branche droite s&#8217;il s&#8217;agit d&#8217;un n&#339;ud FA,
gauche si c&#8217;est un n&#339;ud BA.
</p>
<p>2. Soit &#12296;P1..Pn&#12297; l&#8217;ensemble des arbres de d&#233;rivations construits par &#233;tiquetage des FA-
structures &#12296;T1..Tn&#12297;. Pour chaque arbre Pi et chaque feuille de cet arbre, une r&#232;gle w &#6;&#8594; t
est cr&#233;&#233;e, o&#249; w est le mot correspondant &#224; cette feuille et t le type obtenu apr&#232;s &#233;tiquetage
pour cette feuille. La grammaire ainsi obtenue est la grammaire g&#233;n&#233;rale GF (D).
</p>
<p>La grammaire ainsi construite g&#233;n&#232;re bien l&#8217;ensemble des FA-structures donn&#233; en entr&#233;e, et
donc aussi les phrases d&#233;crites par ces structures. Cependant il est &#233;vident que cette seule &#233;tape
ne suffit pas &#224; apprendre le langage d&#233;crit, puisque la taille de la grammaire va augmenter
ind&#233;finiment, avec chaque nouvel exemple fourni &#224; l&#8217;algorithme. C&#8217;est la raison pour laquelle
la seconde &#233;tape d&#8217;unification doit transformer GF (D) en une grammaire rigide :
</p>
<p>1. Pour chaque mot w d&#233;fini dans GF (D), soit Aw l&#8217;ensemble des types associ&#233;s au mot w.
SoitA l&#8217;union de tous lesAw. Soit &#963;u l&#8217;unifieur le plus g&#233;n&#233;ral (MGU) deA : un unifieur
de A est une substitution &#963; telle que pour tout couple de types (t1, t2) de tout ensemble
Aw on a &#963;(t1) = &#963;(t2). Un unifieur &#963;u est le plus g&#233;n&#233;ral si pour tout autre unifieur &#963; il
existe une substition &#964; qui permet de passer de &#963;u &#224; &#963;, i.e. &#963; = &#964; &#9702; &#963;u (voir par exemple
(Knight, 1989)).
</p>
<p>2. On d&#233;finit la grammaire RG(D) par RG(D) = &#963;u[GF (D)] : toute r&#232;gle w &#6;&#8594; t de
GF (D) est remplac&#233;e par w &#6;&#8594; &#963;u(t) dans RG(D). Comme tous les types d&#8217;un m&#234;me
mot ont &#233;t&#233; unifi&#233;s, la grammaire obtenue est rigide.
</p>
<p>Cet algorithme a quelques qualit&#233;s int&#233;ressantes : il est tout d&#8217;abord efficace, puisque sa com-
plexit&#233; (en fonction de la taille des exemples) est seulement quadratique. Il peut &#234;tre utilis&#233;
de mani&#232;re incr&#233;mentale, ainsi il n&#8217;est pas n&#233;cessaire de recalculer la grammaire &#224; partir de
l&#8217;ensemble des phrases &#224; chaque nouvel exemple. Enfin il produit une unique grammaire solu-
tion (la plus g&#233;n&#233;rale) quel que soit l&#8217;ensemble d&#8217;exemples propos&#233;s.
</p>
<p>2.2.2 Exemple
</p>
<p>On consid&#232;re l&#8217;ensemble D de FA-structures repr&#233;sent&#233;es (apr&#232;s &#233;tiquetage des n&#339;uds) sur la
figure 2. La phase d&#8217;&#233;tiquetage permet d&#8217;obtenir la grammaire g&#233;n&#233;rale GF (D) suivante :
</p>
<p>GF (D) =
</p>
<p>&#9127;
&#9130;&#9130;&#9130;&#9130;&#9130;&#9130;&#9130;&#9130;&#9128;
</p>
<p>&#9130;&#9130;&#9130;&#9130;&#9130;&#9130;
&#9130;&#9129;
</p>
<p>Pierre &#6;&#8594; X1, X4, X9
Marie &#6;&#8594; X3, X8
Paul &#6;&#8594; X2, X6
aime &#6;&#8594; (X3\S)/X4, X7/X8
d&#233;teste &#6;&#8594; (X1\S)/X2, (X5\S)/X9
qui &#6;&#8594; (X6\X5)/X7</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Apprentissage partiel de grammaires cat&#233;gorielles
</p>
<p>Pierre
</p>
<p>S
</p>
<p>BA
</p>
<p>d&#233;teste Paul
</p>
<p>FA
</p>
<p>X1\S
</p>
<p>(X1\S)/X2 X2X1
</p>
<p>S
</p>
<p>BA
</p>
<p>FA
</p>
<p>Marie aime Pierre
X3
</p>
<p>X3\S
</p>
<p>(X3\S)/X4 X4
</p>
<p>qui aime Marie d&#233;teste
</p>
<p>BA
</p>
<p>FA
</p>
<p>FA FA
</p>
<p>BA
</p>
<p>S
</p>
<p>X5
</p>
<p>X5\S
</p>
<p>X6
</p>
<p>X6\X5
</p>
<p>X7
</p>
<p>(X6\X5)/X7 X7/X8 X8 (X5\S)/X9 X9
Paul Pierre
</p>
<p>Figure 2: FA-structures apr&#232;s &#233;tiquetage
</p>
<p>Le calcul du MGU unifie les types suivants : X1 = X4 = X9, X3 = X8, X2 = X6, X7 =
(X3\S), X4 = X8, X1 = X5, X2 = X9, ce qui donne : X1 = X2 = X3 = X4 = X5 = X6 =
X8 = X9 et X7 = X1\S. Donc la grammaire RG(D) est :
</p>
<p>RG(D) =
</p>
<p>&#9127;
&#9130;
&#9130;&#9130;&#9130;&#9130;&#9130;&#9130;&#9128;
</p>
<p>&#9130;&#9130;&#9130;&#9130;&#9130;&#9130;&#9130;&#9130;&#9129;
</p>
<p>Pierre &#6;&#8594; X1
Marie &#6;&#8594; X1
Paul &#6;&#8594; X1
aime &#6;&#8594; (X1\S)/X1
d&#233;teste &#6;&#8594; (X1\S)/X1
qui &#6;&#8594; (X1\X1)/(X1\S)
</p>
<p>2.3 Apprentissage &#224; partir de phrases plates
</p>
<p>L&#8217;algorithme RG pr&#233;sente peu d&#8217;int&#233;r&#234;t, d&#8217;une part &#224; cause de la nature des informations qu&#8217;il
n&#233;cessite, et d&#8217;autre part &#224; cause de la faible expressivit&#233; des grammaires rigides. Mais Kanazawa
a aussi montr&#233; que la classe des grammaires AB k-valu&#233;es est apprenable (au sens de Gold)
&#224; partir de &#8220;phrases plates&#8221; (flat strings, i.e. phrases sans FA-structure) (Kanazawa, 1998).
L&#8217;algorithme qu&#8217;il propose consiste en une r&#233;duction au cas de l&#8217;apprentissage de grammaires
rigides &#224; partir de FA-structures. En effet, pour une phrase donn&#233;e de longueur n, le nombre
de FA-structures possibles est born&#233; (mais grand !), puisqu&#8217;il s&#8217;agit d&#8217;arbres binaires de n 1
n&#339;uds, chaque n&#339;ud &#233;tant &#233;tiquet&#233; soit par FA soit par BA. De mani&#232;re similaire, le nombre
de grammaires k-valu&#233;es possibles est born&#233; pour une grammaire GF (D) donn&#233;e (on consid&#232;re
tous les unifieurs k-partiels au lieu de l&#8217;unique MGU).
</p>
<p>Dans ce cas, l&#8217;ensemble des solutions est calculable mais la complexit&#233; de l&#8217;algorithme devient
exponentielle. Costa-Flor&#234;ncio montre que le probl&#232;me qui consiste &#224; apprendre la classe des
grammaires k-valu&#233;es (pour k &gt; 1) &#224; partir de FA-structures ainsi que celui qui consiste &#224;
apprendre la classe des grammaires rigides &#224; partir de phrases plates sont des probl&#232;mes NP-durs
(Costa Flor&#234;ncio, 2001), (Costa Flor&#234;ncio, 2002). Nicolas a impl&#233;ment&#233; et test&#233; l&#8217;algorithme de
Kanazawa pour ce cas, et obtient par exemple 126775 grammaires solutions en fixant seulement
la valeur 2 &#224; k, pour de petits exemples (Nicolas, 1999).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Erwan Moreau
</p>
<p>3 Apprentissage partiel de grammaires rigides
</p>
<p>L&#8217;application des algorithmes d&#8217;apprentissage de grammaires cat&#233;gorielles rigides se heurte
donc au probl&#232;me classique du rapport entre quantit&#233; d&#8217;information en entr&#233;e et efficacit&#233; de
l&#8217;algorithme : soit l&#8217;algorithme est polyn&#244;mial mais n&#233;cessite des FA-structures trop complexes,
soit l&#8217;algorithme n&#8217;utilise que des phrases plates mais est alors exponentiel, donc tout aussi peu
utilisable dans des applications r&#233;elles.
</p>
<p>3.1 M&#233;thode
</p>
<p>Nous proposons ici un compromis dans lequel les informations que constituent les FA-structures
sont remplac&#233;es par celles fournies par une grammaire initiale, de mani&#232;re &#224; maintenir un
niveau acceptable d&#8217;efficacit&#233;. Comme les grammaires cat&#233;gorielles sont totalement lexical-
is&#233;es, l&#8217;hypoth&#232;se qu&#8217;une partie de la grammaire &#224; apprendre soit connue au d&#233;part est r&#233;aliste
: en effet, cette partie est simplement constitu&#233;e d&#8217;un ensemble de mots auxquels sont associ&#233;s
un ensemble de types.
</p>
<p>Le programme Prolog ci-contre est &#224; la
fois un parser de grammaires AB, un al-
gorithme d&#8217;apprentissage de grammaires
rigides et un algorithme d&#8217;apprentissage
partiel. Cet algorithme na&#239;f, qui repose
enti&#232;rement sur le moteur Prolog pour la
recherche d&#8217;une d&#233;rivation et/ou le calcul
des types inconnus du lexique, illustre bien
l&#8217;importance de l&#8217;unification dans le pro-
cessus de d&#233;rivation des grammaires cat&#233;-
gorielles.
On peut noter que cet algorithme termine
toujours, car le nombre de parenth&#233;sages
d&#8217;une phrase en constituants (non vides)
est born&#233;. Cependant il est tr&#232;s peu effi-
cace, surtout dans le cas o&#249; un grand nom-
bre de mots sont d&#233;finis dans le lexique :
tous les parenth&#233;sages sont test&#233;s jusqu&#8217;&#224;
ce que celui qui correspond &#224; la forme des
types soit trouv&#233;.
</p>
<p>:-op(400,xfx,/).
:-op(400,xfx,\).
</p>
<p>regle(A/B,B,A). % Forward Application (FA)
regle(B,B\A,A). % Backward Application (BA)
</p>
<p>couper_liste(Part1, Part2, Liste) :-
append(Part1, Part2, Liste),
Part1 \= [],
Part2 \= [].
</p>
<p>deriv(Lexique, [Mot], T) :-
member(def(Mot,T), Lexique).
</p>
<p>deriv(Lexique, Constituant, T) :-
couper_liste(C1, C2, Constituant),
deriv(Lexique, C1, T1),
deriv(Lexique, C2, T2),
regle(T1,T2,T).
</p>
<p>exemple(X) :- % &#8217;Marie&#8217; de type inconnu :
Lex = [ % renvoie X = sn
</p>
<p>def(&#8217;Pierre&#8217;, sn),
def(&#8217;aime&#8217;, (sn\s)/sn),
def(&#8217;Marie&#8217;, X)
],
</p>
<p>deriv(Lex, [ &#8217;Pierre&#8217;, &#8217;aime&#8217;, &#8217;Marie&#8217; ], s),
deriv(Lex, [ &#8217;Marie&#8217;, &#8217;aime&#8217;, &#8217;Pierre&#8217; ], s).
</p>
<p>Afin d&#8217;optimiser l&#8217;utilisation des informations fournie dans la grammaire initiale, on peut proc&#233;der
de la m&#234;me mani&#232;re que pour l&#8217;analyse syntaxique (parsing) : chercher tous les types possibles
pour tous les constituants complets (i.e. ne contenant aucun mot inconnu). Selon la proportion
de mots inconnus dans la phrase et leur r&#233;partition, cela permet de limiter l&#8217;explosion combi-
natoire d&#251;e aux diff&#233;rentes structures possibles. L&#8217;algorithme propos&#233; ci-dessous utilise une
m&#233;thode de parsing incr&#233;mental de type CYK, de mani&#232;re &#224; guider la construction de l&#8217;arbre de
d&#233;rivation par les types fournis dans la grammaire initiale.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Apprentissage partiel de grammaires cat&#233;gorielles
</p>
<p>3.2 Algorithme
</p>
<p>L&#8217;algorithme RGPL (Rigid Grammars Partial Learning) prend en entr&#233;e une phrase w1, .., wn et
une grammaire initiale G0, compos&#233;e de r&#232;gles associant un type &#224; un mot, de la forme w &#6;&#8594; t.
Il renvoie l&#8217;ensemble des grammaires rigides solutions, c&#8217;est-&#224;-dire celles contenant les r&#232;gles
de la grammaire initiale et acceptant cette phrase.
</p>
<p>RGPL(G0, [w1, w2, .., wn])
Lex &#8592; {(W,T ) | (W &#2;&#8594; T ) &#8712; G0} % Initialisation
cr&#233;er une matrice vide M [1..n, 1..n]
pour i &#8592; 1 &#224; n faire
</p>
<p>si &#8707;T tel que (wi, T ) &#8712; Lex alors
M [i, i] &#8592; {(T, Id)}
</p>
<p>sinon
cr&#233;er une nouvelle variable V
Lex &#8592; Lex &#8746; {(wi, V )}
M [i, i] &#8592; {(V, Id)}
</p>
<p>fin si
fin pour
pour i &#8592; 2 &#224; n faire % Processus de d&#233;rivation/apprentissage partiel
</p>
<p>pour j &#8592; i 1 &#224; 1 faire
pour k &#8592; j &#224; i 1 faire
</p>
<p>pour chaque (Tl, &#963;l) &#8712; M [j, k] faire
pour chaque (Tr, &#963;r) &#8712; M [k + 1, i] faire
</p>
<p>si &#8707;&#963;u = mgu(&#963;l, &#963;r) alors
cr&#233;er deux nouvelles variables A, B
si &#8707;&#963;FA = mgu({{&#963;u(Tl), A/B}, {&#963;u(Tr), B}}) alors
</p>
<p>M [j, i] &#8592; M [j, i] &#8746; {(&#963;FA(A), &#963;FA &#9702; &#963;u &#9702; &#963;1}
fin si
cr&#233;er deux nouvelles variables A&#8242;, B&#8242;
</p>
<p>si &#8707;&#963;BA = mgu({{&#963;u(Tl), B&#8242;}, {&#963;u(Tr), B&#8242;\A&#8242;}}) alors
M [j, i] &#8592; M [j, i] &#8746; {(&#963;BA(A&#8242;), &#963;BA &#9702; &#963;u &#9702; &#963;1}
</p>
<p>fin si
fin si
</p>
<p>fin pour
fin pour
</p>
<p>fin pour
fin pour
</p>
<p>fin pour
Res &#8592; &#8709; % Application des substitutions compatibles
pour chaque (T, &#963;) &#8712; M [1, n] faire
</p>
<p>si &#8707;&#964; tel que &#964;(T ) = S alors
Res &#8592; Res &#8746; {(&#964; &#9702; &#963;)(Lex)}
</p>
<p>fin si
fin pour
renvoyer Res
</p>
<p>Fin RGPL
</p>
<p>Remarques: Id d&#233;signe la substitution identit&#233;, et (&#963;u &#9702;&#963;1) = (&#963;u &#9702;&#963;2) car &#963;u est d&#233;fini comme
le MGU de &#963;1 et &#963;2.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Erwan Moreau
</p>
<p>Cet algorithme ne d&#233;crit le fonctionnement que pour une phrase : le processus d&#8217;apprentissage
sur un ensemble de phrases consiste &#224; appliquer RGPL sur chaque phrase puis calculer le MGU
(s&#8217;il existe) sur chaque ensemble de solutions, comme dans l&#8217;algorithme de Kanazawa.
</p>
<p>De m&#234;me que dans l&#8217;algorithme d&#8217;apprentissage &#224; partir de FA-structures, cet algorithme utilise
des termes qui peuvent contenir des variables. Ces variables sont progressivement instanci&#233;es
selon les contraintes impos&#233;es par les r&#232;gles universelles, en particulier dans le cas o&#249; le type
est combin&#233; avec un type sans variable. Chaque type &#8220;r&#233;alisable&#8221; par un constituant est ac-
compagn&#233; de la substitution qui permet de l&#8217;obtenir. Cette substitution porte sur les variables
associ&#233;es aux mots inconnus de ce constituant, afin de v&#233;rifier lors de chaque combinaison de
types que leurs substitutions sont compatibles (par calcul du MGU).
</p>
<p>Il est important de noter que malgr&#233; son fonctionnement &#8220;de type CYK&#8221; la complexit&#233; de cet
algorithme n&#8217;est pas polyn&#244;miale en g&#233;n&#233;ral. En effet, le nombre de couples (T, &#963;) dans chaque
case de la matrice M peut cro&#238;tre de mani&#232;re exponentielle. C&#8217;est notamment le cas lorsque
tous les mots sont inconnus (la grammaire initiale est vide) : on se trouve alors dans le cas
pr&#233;c&#233;dent d&#8217;apprentissage &#224; partir de phrases plates, et l&#8217;algorithme doit calculer l&#8217;ensemble
des FA-structures possibles.
</p>
<p>3.3 Exemple
</p>
<p>Soit G0 la grammaire initiale d&#233;finie par le lexique suivant1
</p>
<p>{ un &#6;&#8594; SN/N, homme &#6;&#8594; N, poisson &#6;&#8594; N, nage &#6;&#8594; SN\S, vite &#6;&#8594; (SN\S)\(SN\S) }
Soit &#8220;un homme court&#8221; la phrase donn&#233;e comme entr&#233;e &#224; l&#8217;algorithme, o&#249; &#8220;court&#8221; est un mot
inconnu.
</p>
<p>1. Initialisation :
M [1, 1] &#8592; (SN/N, &#8709;)
M [2, 2] &#8592; (N, &#8709;)
M [3, 3] &#8592; (x1, &#8709;) et Lex &#8592; Lex &#8746; {(court, x1)}
</p>
<p>2. D&#233;rivation :
</p>
<p>i = 2, j = 1, k = 1: M [1, 2] &#8592; (SN, &#8709;) (FA)
i = 3, j = 2, k = 2: M [2, 3] &#8592; (x2, {x1 &#6;&#8594; N \x2}) (BA)
i = 3, j = 1, k = 1: M [1, 3] &#8592; (SN, {x1 &#6;&#8594; N \N}) (FA)
i = 3, j = 1, k = 1: M [1, 3] &#8592; (x3, {x1 &#6;&#8594; N \((SN/N)\x3)}) (BA)
i = 3, j = 1, k = 2: M [1, 3] &#8592; (x4, {x1 &#6;&#8594; SN \x4)}) (BA)
</p>
<p>3. Substitutions compatibles avec S :
&#964;(SN) = S ? impossible
&#964;(x3) = S ? {x1 &#6;&#8594; N \((SN/N)\S)}
&#964;(x4) = S ? {x1 &#6;&#8594; SN \S}
</p>
<p>Apr&#232;s cet exemple, il y a deux grammaires dans l&#8217;ensemble des solutions : l&#8217;une d&#233;finit &#8220;court&#8221;
par le type N \((SN/N)\S), l&#8217;autre par le type SN \S. Si l&#8217;exemple &#8220;un homme court vite&#8221;
appara&#238;t plus tard dans la s&#233;quence d&#8217;exemples, la premi&#232;re solution sera &#233;limin&#233;e, car il n&#8217;existe
pas de substitution sur les r&#232;gles universelles permettant de combiner N \((SN/N)\S) avec le
type de l&#8217;adverbe vite, (SN \S)\(SN \S).
</p>
<p>1On peut noter dans cette grammaire que le type des noms N est un argument du type du d&#233;terminant SN/N ,
et non l&#8217;inverse : il s&#8217;agit de la notation classique dans les grammaires cat&#233;gorielles.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Apprentissage partiel de grammaires cat&#233;gorielles
</p>
<p>3.4 Discussion et perspectives
</p>
<p>La contrainte de rigidit&#233;
</p>
<p>L&#8217;algorithme RGPL pr&#233;sent&#233; ci-dessus apprend uniquement des grammaires rigides. Plus ex-
actement, les mots d&#233;finis dans la grammaire initiale peuvent avoir plusieurs cat&#233;gories, mais
l&#8217;algorithme unifie tous les types d&#8217;un m&#234;me mot inconnu. Il ne serait bien s&#251;r pas difficile
de g&#233;rer des grammaires k-valu&#233;es en calculant toutes les possibilit&#233;s d&#8217;unification, mais cela
serait contraire &#224; l&#8217;objectif puisque l&#8217;algorithme deviendrait rapidement inexploitable. On peut
par contre envisager pour pallier ce probl&#232;me que des classes de mots soit d&#233;finies dans la gram-
maire initiale : chaque mot inconnu devrait alors appartenir &#224; l&#8217;une des classes pr&#233;d&#233;finies, ce
qui limite fortement les combinaisons de types. Le regroupemement par classes est fr&#233;quem-
ment utilis&#233; (par exemple dans (Brill, 1993)), mais suppose que les classes pr&#233;d&#233;finies cou-
vrent l&#8217;ensemble des combinaisons syntaxiques suceptibles d&#8217;appara&#238;tre dans les exemples, et
ne causent pas de surg&#233;n&#233;ration.
</p>
<p>Formalisme
</p>
<p>L&#8217;&#233;tude r&#233;alis&#233;e dans cet article porte uniquement sur les grammaires AB, la forme la plus sim-
ple de grammaires cat&#233;gorielles. Ce formalisme est plut&#244;t pauvre en termes de repr&#233;sentation
des ph&#233;nom&#232;nes linguistiques, c&#8217;est pourquoi il est souhaitable d&#8217;&#233;tendre la m&#233;thode propos&#233;e
&#224; des cadres plus adapt&#233;s au langage naturel. Il existe diff&#233;rents travaux qui tendent &#224; mon-
trer que le type d&#8217;apprentissage propos&#233; par Kanazawa est g&#233;n&#233;ralisable, notamment &#224; d&#8217;autres
formes de grammaires cat&#233;gorielles telles les grammaires de Lambek et minimalistes (Bonato
&amp; Retor&#233;, 2001) (m&#234;me si cela pose d&#8217;autres probl&#232;mes de complexit&#233;, voir (Pentus, 2003)).
D&#8217;autres formalismes, comme les grammaires de liens (Sleator &amp; Temperley, 1991), sont aussi
suceptibles de permettre ce type d&#8217;apprentissage.
</p>
<p>La grammaire initiale
</p>
<p>L&#8217;int&#233;r&#234;t de la m&#233;thode d&#8217;apprentissage que nous proposons repose enti&#232;rement sur l&#8217;existence
d&#8217;une grammaire initiale. Celle-ci doit &#234;tre suffisamment compl&#232;te pour qu&#8217;un nombre signi-
ficatif de mots soient connus dans les phrases de la s&#233;quence &#224; apprendre. Dans ce cadre, on
peut tirer profit de la &#8220;loi de Zipf&#8221;, utilis&#233;e notamment par l&#8217;&#233;tiqueteur de Brill (Brill, 1993).
Celle-ci garantit que, sur l&#8217;ensemble des mots d&#8217;un texte, une faible proportion des mots suffit
&#224; repr&#233;senter une grande partie du texte (en nombre d&#8217;occurences). Or pr&#233;cis&#233;ment ce sont les
mots les plus fr&#233;quents d&#8217;un langage qui sont le plus facile &#224; r&#233;pertorier et d&#233;finir (mots gram-
maticaux tels que d&#233;terminants, pronoms, pr&#233;positions, conjonctions, etc.), soit manuellement
soit par conversion de dictionnaires existants dans d&#8217;autres formalismes.
</p>
<p>4 Conclusion
</p>
<p>Dans le domaine de l&#8217;inf&#233;rence grammaticale, l&#8217;apprenabilit&#233; des classes de langages est sou-
vent &#233;tudi&#233;e ind&#233;pendamment d&#8217;une &#233;ventuelle mise en pratique de cet apprentissage. Du strict</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Erwan Moreau
</p>
<p>point de vue de l&#8217;apprenabilit&#233; dans le mod&#232;le de Gold, aucune distinction n&#8217;est n&#233;cessaire en-
tre les cas d&#8217;apprentissage de grammaires rigides &#224; partir de FA-structures et de grammaires
k-valu&#233;es &#224; partir de phrases plates, m&#234;me si le premier est peu utile et le second quasiment
irr&#233;alisable.
</p>
<p>Dans la perspective d&#8217;applications &#8220;r&#233;elles&#8221;, nous avons propos&#233; une adaptation des algorithmes
d&#8217;apprentissage de grammaires cat&#233;gorielles. L&#8217;approche &#233;tudi&#233;e est moins contraignante sur
la forme des entr&#233;es de l&#8217;algorithme, tout en restant relativement r&#233;aliste du point de vue de
l&#8217;efficacit&#233;. N&#233;anmoins il reste plusieurs questions &#224; r&#233;soudre avant de pouvoir appliquer des al-
gorithmes d&#8217;apprentissage symbolique de r&#232;gles syntaxiques au langage naturel : l&#8217;expressivit&#233;
des classes de langages apprenables ainsi que le formalisme utilis&#233; pour les repr&#233;senter doivent
&#234;tre am&#233;lior&#233;s (les pronoms, par exemple, sont difficilement repr&#233;sentables dans les grammaires
AB), et il reste &#224; d&#233;terminer comment et selon quels crit&#232;res constituer la grammaire initiale.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BAR-HILLEL Y., GAIFMAN C. &amp; SHAMIR E. (1960). On categorial and phrase structure grammars.
</p>
<p>BONATO R. &amp; RETOR&#201; C. (2001). Learning rigid lambek grammars and minimalist grammars from
structured sentences. In L. POPEL&#205;NSK&#221; &amp; M. NEPIL, Eds., Proceedings of the 3d Workshop on Learn-
ing Language in Logic, p. 23&#8211;34, Strasbourg, France.
</p>
<p>BRILL E. (1993). A Corpus-Based Approach to Language Learning. PhD thesis, Computer and Infor-
mation Science, University of Pennsylvania.
</p>
<p>BUSZKOWSKI W. &amp; PENN G. (1989). Categorial grammars determined from linguistic data by unifi-
cation. Rapport interne TR-89-05, Department of Computer Science, University of Chicago.
</p>
<p>COSTA FLOR&#202;NCIO C. (2001). Consistent Identification in the Limit of the Class k-valued is NP-hard.
In P. DE GROOTE, G. MORRILL &amp; C. RETOR&#201;, Eds., Logical Aspects of Computational Linguistics,
4th International Conference, LACL 2001, Le Croisic, France, June 27-29, 2001, Proceedings, volume
2099 of Lecture Notes in Computer Science, p. 125&#8211;138: Springer-Verlag.
</p>
<p>COSTA FLOR&#202;NCIO C. (2002). Consistent Identification in the Limit of Rigid Grammars from Strings is
NP-hard. In P. ADRIAANS, H. FERNAU &amp; M. VAN ZAANEN, Eds., Grammatical Inference: Algorithms
and Applications 6th International Colloquium: ICGI 2002, volume 2484 of Lecture Notes in Artificial
Intelligence, p. 49&#8211;62: Springer-Verlag.
</p>
<p>GOLD E. (1967). Language identification in the limit. Information and control, 10, 447&#8211;474.
</p>
<p>KANAZAWA M. (1998). Learnable classes of categorial grammars. Cambridge University Press.
</p>
<p>KNIGHT K. (1989). Unification: A multidisciplinary survey. ACM Computing Surveys, 21(1), 93&#8211;124.
</p>
<p>NICOLAS J. (1999). Grammatical inference as unification . Rapport interne 3632, INRIA. &#233;galement
rapport IRISA PI1265.
</p>
<p>PENTUS M. (2003). Lambek calculus is NP-complete. Rapport interne TR-2003005, CUNY Ph.D.
Program in Computer Science.
</p>
<p>SLEATOR D. D. K. &amp; TEMPERLEY D. (1991). Parsing English with a Link Grammar. Rapport interne
CMU-CS-TR-91-126, Carnegie Mellon University, Pittsburgh, PA.</p>

</div></div>
</body></html>