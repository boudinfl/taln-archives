TALN 2004, Fés, 19-21 avril 2004

La sémantique dans les grammaires d’interacti0n

Guy Perrier
LORIA — Université Nancy 2
BP 239 — 54506 Vandoeuvre—les—Nancy cedex
perrier@loria.fr

Résumé - Abstract

Nous proposons d’intégrer la sémantique dans les grammaires d’interaction, formalisme qui a
été concu pour représenter la syntaxe des langues. Pour cela, nous ajoutons au formalisme un
niveau supplémentaire qui s’appuie sur les memes principes fondamentaux que le niveau syn-
taxique : controle de la composition par un systeme de polarite’s et utilisation de la notion de
description de structure pour exprimer la sous—spe’ciﬁcation. A la différence du niveau syntax-
ique, les structures sont des graphes acycliques oriente’s et non des arbres localement ordonne’s.
L’interface entre les deux niveaux est assure’e de facon souple par une fonction de liage qui
associe a tout nmud syntaxique au plus un nteud sémantique.

We propose an integration of semantics into Interaction Grammars, a formalism that was de-
signed for representing the syntax of natural languages. It consists in the addition of a new level
to the formalism and this level is based on the same fundamental principles as the syntactical
level: the control of composition with a system of polarities and the use of the notion of struc-
ture description for expressing underspeciﬁcation. Unlike the syntactical level, structures are
directed acyclic graphs and not locally ordered trees. The interface between the two levels is
performed in a ﬂexible way by a linking function which maps every syntactical node to at most
one semantical node.

Mots-clefs — Keywords

formalisme grammatical, interface syntaxe—sémantique, sous—spéciﬁcation, polarite’s.
grammatical formalism, syntax—semantics interface, underspeciﬁcation, polarities.

Introduction

Initialement, les grammaires d’interaction (IG en abre’ge’ pour Interaction Grammars) ont été
congues pour modéliser la syntaxe des langues (Perrier, 2002) a partir de deux traditions dif-
férentes des grammaires formelles : les grammaires catégorielles (CG en abre’ge’ pour Categorial
Grammars) et les grammaires d’arbres adjoints (TAG).

Des CG, les IG retiennent l’idée que les syntagmes sont vus comme des ressources consommables
et qu’il y a une dualite’ entre celles—ci qui s’exprime dans le mécanisme de composition syntax-
ique : certaines ressources, munies de polarite’s negatives, sont attendues alors que d’autres,
munies de polarite’s positives, sont disponibles si bien que les premieres vont chercher a ren-
contrer les secondes et c’est ce principe de neutralisation des polarités opposées qui va guider
la composition syntaxique.

Guy Perrier

La plupart des formalismes linguistiques tiennent compte de la sensibilite’ aux ressources des
langues mais en géne’ral ils le font de fagon externe a l’aide de principes de bonne formation
qui sont Veriﬁes apres coup sur les structures engendre’es. Seules les CG en font un principe
incorpore’ dans le formalisme lui—méme, qui s’applique dans le processus de composition lui—
meme et permet de le controler. Les IG peuvent étre Vues comme un rafﬁnement des CG
en ce sens que la notion de polarite’ est descendue du niveau des syntagmes au niveau des
traits grammaticaux utilisés pour les décrire (parties du discours, fonctions syntaxiques ...).
Le principe de composition syntaxique reste fondamentalement le meme, prenant seulement la
forme de la neutralisation de traits duattx.

En meme temps qu’un rafﬁnement des CG, les IG introduisent un assouplissement consid-
érable dans le formalisme en ayant recours a la notion de description d ’arbre. Utilise’e par
Vijay—Shanker (1992) pour exprimer l’adjonction des TAG sous forme d’une opération mono-
tone, elle s’inscrit dans une nouvelle approche de la formalisation des langues qui considere les
grammaires comme des systemes de contraintes plutot que comme des systemes dérivationnels.
Les e’nonce’s des langues sont alors Vus comme des instanciations de ces systemes de con-
traintes dont la résolution produit les analyses. Une bonne illustration de cette approche nous
est donne’e par les grammaires de proprie’tés de Blache (2001). L’inte’rét d’une telle approche
est qu’elle permet une grande souplesse de composition et une expression économique de la
sous—spéciﬁcation. La notion de description d’arbre n’est que l’application de cette approche a
la représentation des structures syntaxiques a l’aide de contraintes de domination et de prece-
dence portant sur des nceuds représentant des syntagmes. L’originalite’ des IG est d’étiqueter
ces nceuds par des structures de traits polarisés et d’ajouter aux contraintes précédentes des
contraintes de neutralite’ sur les polarite’s.

Dans les langues, la syntaxe n’est qu’un moyen pour accéder a la sémantique. Un formalisme
ne peut donc se préoccuper de la premiere en ignorant la seconde. ll ne peut conside’rer non plus
que la sémantique est une simple projection de la syntaxe et il est plus conforme a la réalite’ de
Voir leur rapports en termes d’interactions qu’en termes de dépendance passive de la premiere
relativement a la seconde.

Malheureusement, parmi les formalismes distinguant le niveau sémantique du niveau syn-
taxique, beaucoup ne présentent le premier que comme une déduction passive du second.
Cela a comme consequence soit de ne pas pouvoir rendre compte de phe’nomenes se’mantiques
lorsqu’ils ne sont pas le re’sultat me’canique de phe’nomenes syntaxiques, soit de compliquer ar-
tiﬁciellement la syntaxe pour en rendre compte et d’une certaine fagon d’inclure la sémantique
de maniere détourne’e dans la syntaxe.

Une bonne illustration de notre propos nous est fournie par les CG dont sont justement issues
les IG. Classiquement, la sémantique y est intégrée sous forme de la sémantique de Montague
(Montague, 1970). Le cadre utilise’ est celui d’une logique d’ordre supérieur exprime’e a l’aide
d’un lambda—calcul type’ (Carpenter, 1998). Chaque phrase est représente’e par une formule
logique qui est une fonction de la représentation sémantique de chacun des mots de la phrase.
Cette fonction est représente’e sous forme d’un lambda—terme qui est une stricte projection de
la structure syntaxique de la phrase. Cette projection consiste a oublier l’ordre des mots eta ne
conserver que les dépendances syntaxiques.

Prenons par exemple la phrase Jean aime Marie. Sa structure syntaxique dans les CG s’exprime
sous forme de l’application de la fonction }\:L'GN )4/GN .(y*aime>s<x)p a deux arguments de type
groupe nominal (GN) Marie et Jean qui Vont instancier respectivement 3: et y. L’opérateur
“*” est l’opérateur de concate’nation et la Valeur retourne’e par la fonction est de type phrase
(P) : c’est la phrase Jean aime Marie. La représentation sémantique s’obtient par projection de
chaque type syntaxique en un type sémantique et par oubli de l’ordre des mots dans l’expression
du re’sultat de la fonction précédente. Si on considere que les types GN et P se projettent se’—
mantiquement selon les types entite’ (e ) et b00le’en (b), la représentation sémantique de la phrase
s’obtient comme application de la fonction Me Ave .aimer(v, u);, aux entités correspondant a

La sémantique dans les grammaires d’interaction

Marie et Jean qui Vont instancier respectiVement u et 1).

Maintenant, Voyons comment analyser la phrase tous aiment quelqu’un. Syntaxiquement, elle
se présente comme Jean aime Marie mais si nous reprenons la meme analyse syntaxique que
celle qui Vient d’etre effectuée, par projection, on obtiendra la meme representation seman-
tique et on aura completement ignore la pre’sence et le role des deux quantiﬁcateurs dans la
phrase. Compte tenu des relations de portée entre les deux quantiﬁcateurs pre’sents, il y a deux
representations se’mantiques possibles de la phrase d’o1‘1 nécessite’ de deux structures syntax-
iques correspondantes : dans l’une, tous est représente’ par une fonction qui s’applique a aiment
quelqu’un et dans l’autre, c’est quelqu’un qui est représente’ par une fonction s’appliquant a
tous aiment. Des que l’on Va augmenter le nombre quantiﬁcateurs, l’analyse syntaxique Va Vite
deVenir tres complique’e. On peut perceVoir ainsi les limites d’une telle conception de l’interface
syntaXe—sémantique.

L’objet du propos qui Va suiVre est d’ajouter un niVeau sémantique aux IG de facon a aVoir un
formalisme linguistique qui couVre a la fois la syntaxe et la sémantique des langues. On Vient
d’entreVoir les limites d’une interface syntaXe—sémantique trop rigide comme celle qui existe
pour les CG. Les IG évitent cet écueil en gardant un niVeau syntaxique autonome. Le me’can—
isme de liage entre les deux niveaux est aussi peu contraignant que possible puisqu’il consiste
en une simple fonction partielle qui associe a un syntagme au plus un objet sémantique. On
ne demande aucune proprie’te’ particuliere a cette fonction. La representation sémantique, quant
a elle, est fondée sur les memes notions de polarite’ et de description s0us—spe’ciﬁe’e que la
representation syntaxique aVec le meme mécanisme de composition guide par le principe de
neulralisation des polarités. 11 y a cependant une difference : au niVeau syntaxique, nous ma-
nipulons des arbres localement ordonne’s et donc des descriptions d’arbres localement ordonne’s
mais, au niVeau sémantique, nous cherchons a exprimer des dépendances sémantiques entre
entités sous forme de relations prédicat—arguments et nous utilisons pour cela des graphes acy-
cliques oriente’s (DAG en abre’ge’ pour Directed Acyclic Graph) donc des descriptions de DAG.
Dans les sections 1 et 2, nous présenterons sépare’ment les niveaux syntaxique et sémantique
des IG puis dans la section 3, nous montrerons comment ils interagissent dans le processus
d’analyse. Nous terminerons dans la section 4 par une comparaison aVec d’autres formalismes.

1 Le niveau syntaxique et les descriptions d’arbres polarisées

Une description d’arbre syntaxique est un ensemble de nceuds et de relations de domination
immediate, de domination large et de precedence entre ces nceuds. Les nceuds représentent
des syntagmes et les relations les dépendances entre ces syntagmes. Le proprie’tés morpho-
syntaxiques de ces syntagmes sont eXprime’es par des structures de traits attache’es aux nceuds.
La ﬁgure 1, dans sa partie infe’rieure, montre un exemple simpliﬁé de description d’arbre, D syn,
qui est associe’e par un lexique a la phrase tous aiment quelqu’un. Les nceuds y sont représente’s
par des rectangles aVec pour entete leur nom et pour corps la structure de traits attache’e. Les re-
lations de domination immediate sont représente’es par des traits continus, celles de precedence
par des ﬂeches et les relations de domination large par des traits discontinus. Ces dernieres,
qui Vont permettre d’eXprimer aussi bien les possibilite’s d’appliquer des modiﬁeurs a certains
syntagmes et les dépendances syntaxiques non borne’es, peuVent etre contraintes par des struc-
tures de traits. Ainsi, la relation de domination v—max§v—min est contrainte par le trait cat =v.
Le nteud v—min représente l’ancre1 de la description, c’est—a—dire la position du Verbe associe’
aiment dans la description. A ce Verbe peuVent éventuellement s’adjoindre une negation, des
clitiques ou des adVerbes pour former sa projection maximale v—max. La contrainte cat =v sur
la relation de domination v—max$v—min exprime exactement cela puisque elle signiﬁe que tout
nteud qui domine strictement v—min et qui est domine au sens large par v—max doit etre por-

1Les ancres sont représentées par des rectangles colorés.

Guy Perrier

 preI‘l—rndne 
Dsm  ’ a type <- pred 
.—-"’ , ‘
I
I 
‘K ’ .“ .
poIIr—Iunt I II-exam
I
type —> quant , M39 -> ltuam
com = pou,._u,m I , cont = i|—exist£
I I '1 nnner I I
1 1 3 ' type —> Iex ‘ ‘ 1 2 3
, cont = aimer \
. , . I I I \ I I . I
restrictionl Pm”; I ‘\ resiricﬁmi poﬂeel
. I I 1 \ _
type = Ioglque ‘we <_ pred I ‘ WP9 - '9)‘ type <— pred
cont = vrai __ | \ cont = humain _
' ' I gent pnthnl “ , ,
I
X ‘ type <— ent type <— ent ‘
\ I I I I I I ‘ 3
‘V99 '> 9"‘ \ ” \ “ type —> ent
°°"' = X “ I “ I com = y
I l I ,\ ‘ | I I I
I I \ I
I I \ ‘ ' I
l I s ‘ ' .
I I s ‘ \ l I
I I \ phrnse I‘ ‘I |
| " cat <— p , , I
‘I I 1 ‘ ' l.
' ' .r ., ‘l I’ |
I‘ :  In-up ‘ ‘ , I
‘ l  cat —> p ,1 ‘I
\ I  mode = ind  I
D I I  temps = pres I i.‘ I
syn \ I  I I I 
I  « I ~ '.
\ ,'
\  ‘I ,' ' '
‘  “lie! v—mnx I ' I‘
‘\  03' <' 9" cat <— v ob!‘ '
\  tonct —> suj :> _ :> oat <— gn .‘ I
\  "b = Pl mode = Ind tonct —> ob] ‘
\  pars = 3 temps = pres ',
\  
\ I 3 I 
\ can: v gnz
gnl 1
‘ v—min cat —> gn
‘cat :> 9'; cat —> v tenet <— ‘.7
:,::n:_..,'ouS.. phon = aim... Dhonf "que|qu’un"
nb : pl mode : ind 
gen : m temps : pres , ,
I I I I
=-mt

Figure 1: Description syntaXico—se’mantique associe’e a la phrase tous aiment quelqu’tm par le
lexique d’une IG.

teur d’un trait pouvant s’uniﬁer avec le trait cat=v. Lorsque le rectangle représentant un nmud
est muni a son pied d’un crochet tourne’ Vers le bas, cela signiﬁe que l’ensemble des ﬁls du
nteud a sa cardinalite’ ﬁXe’e. Par exemple, le crochet associe’ au nteud prop représente la relation
pr0p>{sujet, v—max, objet} qui signiﬁe que prop a exactement trois ﬁls distincts : sujet, v—max,
objet.

L’ ori ginalité des IG est que le traits morpho—syntaXiques associe’s aux syntagmes sont polarise’s.
Habituellement, un trait est associe’ a une Valeur dans un couple (trait, valeur). Dans les IG, un
trait est associe’ a une polarite’ eta une Valeur dans un triplet (trait, polarite’, valeur). Une polarite’
peut étre <—, —), = et <—>pour dire qu’un trait est négatif, positif, neutre ordinaire ou sature’.
Un trait négatif f <—v représente une ressource attendue, un trait positif f —>v une ressource
disponible et un trait neutre ordinaire f =v une proprie’te’ qui ne se comporte pas comme une
ressource consommable. Un trait sature’ f (—>v est un trait neutre particulier qui provient de la
neutralisation d’un trait ne’gatif par un trait positif. Contrairement a un trait neutre ordinaire, il
ne peut pas s’uniﬁer avec un trait positif ou négatif.

Une description d’arbre peut étre considére’e comme un ensemble de contraintes déﬁnissant un
ensemble d’arbres syntaxiques et chacun de ces arbres peut étre Vu comme un modele de la
description correspondante. Les polarite’s déﬁnissent des contraintes spéciﬁques de neutralite’
sur les modeles : dans tout modele Valide, tout trait positif doit avoir e’té neutralisé exactement
par un trait négatif correspondant et réciproquement. Pour une deﬁnition formelle de cette

La sémantique dans les grammaires d’interaction

notion de modele, le lecteur pourra se reporter a (Perrier, 2002).
S’il est nécessaire de de’ﬁnir rigoureusement cette notion de modele, il est important ensuite de
pouvoir calculer les modeles d’une description donne’e. C’est l’ope’ration de neutralisation de
traits qui nous en donne les moyens. Cette opération consiste dans une description a identiﬁer
deux nceuds porteurs de traits duaux, c’est—a—dire qui ont le meme nom mais des polarite’s op-
pose’es. Par exemple, sur la ﬁgure 1, les nceuds syntaxiques gnlet sujet de Day” portent les traits
duaux cat —)gn et cat <—gn. La fusion des deux nreuds Va permettre de neutraliser les deux
traits qui Vont s’uniﬁer en un trait cat (—>gn. 11 se trouve qu’ici, incidemment, on obtient une
deuxieme neutralisation : celle des traits fonct <—?2 etfonct —>suj qui Vont s’uniﬁer dans fonct
<—>suj. Le nteud qui résulte de la fusion de gnlet sujet est le nreud gnI.sujet que l’on peut Voir
sur la ﬁgure 2.

En itérant l’ope’ration de neutralisation de traits, nous allons pouvoir spe’ciﬁer pas a pas une
description initiale et construire progressivement un modele neutre de celle—ci. Dans notre
exemple, apres 4 neutralisations de traits effectue’s sur Day“, on obtient l’arbre syntaxique com-
pletement spéciﬁe’ de la ﬁgure 2. Cette fagon proce’durale d’obtenir un modele est équivalente

 

iI—exi5Ie

 

poIIr—InII1 I
1 Iype —> quam
WP9 ‘> qua” ’ nom = iI—exis1s
com = pour—IouI I’ , ,
I z 3
I 1
Z 3 I
I 1 u u u :
mﬁmml ' ‘ml ' I ulna‘ - - puma
D I e — I i ue 1” I. 'V"° '> '°" Ivpe = Iex Ivpe <- pred
sern yp ‘ °9_q qype <_ pred I cum = aimer _
cam = vral | ' ' I cum = humaln .
. 4
u
. I 1 I I
1 .
I '1 ,.
I I
I I
I’ .
1‘ y. pman ‘
x. lgenl  I’ l‘ Iype <—> em 
lype <—> em ‘I ‘ 1‘-0"“ = V
_ I \ I
I DOM — X I \ \
I | ' \ \
I I \ \
I \ \
I I’ \ \
I I ‘ \
I pmp . phnae \
I I \
‘ I cal <—> p \
. \
\ “ mode = Ind ‘
\ ‘ lamps = pres \
‘ . . \
D ‘ ‘\ ‘
\
syn ‘ , \‘
\ \
\ \ \‘
\ \
\ 1 _ at \ _ _ .
‘...fl'....S.'l’. ,,,,, .. ' ' “'“" ““" g-Lobjet
cat<—> gn cat <—> v cat<_>gn
funct <—> suj phon = "aimem fonct <_> obj
Dhorl = "tous" mode = Ind phon = "que|qu’un"
num = pl temps = pres num = 39
P95 = 3 ' ' gen = m
gen = m I I
I‘ ‘I

Figure 2: Description syntaXico—se’mantique a la ﬁn de l’analyse syntaxique de la phrase tous

aiment quelqu ’un.

a la fagon declarative de le de’ﬁnir (Perrier, 2003). Il est a noter que l’ope’ration de neutralisa-
tion de traits qui permet de composer les descriptions entre elles est beaucoup plus riche que
les operations de composition d’arbres utilisées par les formalismes fondés sur les arbres tels
que les TAG. Elle permet de superposer partiellement des arbres et s’apparente beaucoup plus
a l’uniﬁcation de structures de traits d’HPSG mais avec le controle par les polarite’s en plus.

2Le symbole “?” représente ici la valeur indéterminée, c’est-a-dire, comme les valeurs sont des disjonctions
d’atomes, la disjonctions de tous les atomes du domaine correspondant au trait, fonct en l’occurrence.

Guy Perrier

2 Le niveau sémantique et les descriptions de DAG polarisées

Nous ne proposons pas de formaliser une théorie sémantique particuliere mais plutet de fournir
un cadre pour représenter diffe’rentes se’mantiques objets. Pour illuster notre propos, nous
choisirons comme sémantique objet le calcul des predicats mais nous aurions tres bien pu pren-
dre les graphes se’mantiques de la théorie Sens—Texte (Mel’cuk, 1988). Certes, le choix n’est pas
totalement arbitraire car le calcul des prédicats permet d’eXprimer la notion de portée, notion
qui pose des problemes d’eXplosion combinatoire quand on cherche a calculer une representa-
tion sémantique. Ce n’est pas un hasard si c’est en sémantique informatique, dans le domaine de
la traduction, qu’ont Vu le jour depuis une dizaine d’anne’es une série de langages de represen-
tation sémantique qui Visent a re’soudre ce probleme en utilisant l’idée de sous—spe’ciﬁcation
(Reyle, 1993; Bos, 1995; Egg et al., 1998; Copestake et al., 1999).

Nous proposons de reprendre au niveau sémantique les deux idées—forces qui sont au cceur
de notre representation de la syntaxe : l’utilisation de la notion de description de structure
pour exprimer la sous—spe’ciﬁcation et celle de polarite’ pour contreler la composition d’une
structure completement spéciﬁe’e. La difference avec le niveau syntaxique est que nous al-
lons chercher a représenter des dépendances sémantiques entre objets sous forme de relations
prédicat—arguments donc les structures sémantiques completement spéciﬁe’es seront des DAG
et non des arbres localement ordonne’s : en effet, la precedence entre nceuds n’a plus de sens
et un objet sémantique peut etre argument de plusieurs predicats a la fois. De fagon analogue
au niveau syntaxique, une description de DAG sémantique permettra de representer un ensem-
ble de DAG qui seront ses modeles. Si nous choisissons comme sémantique objet le calcul
des prédicats, un DAG sera la representation géométrique d’une formule logique et ses nceuds
seront soit des prédicats, soit des individus. Les seules relations qui Om du sens entre les nceuds
d’une description de DAG sont les relations prédicat—arguments qui sont représente’es par des
relations de domination immediate et les relations de portée qui sont représente’es par des re-
lations de domination large. Comme au niveau syntaxique, les nceuds sont étiquetés par des
structures de traits polarisés qui expriment cette fois des proprie’tés sémantiques. La notion de
modele neutre d’une description de DAG sémantique se déﬁnit de la meme fagon qu’au niveau
syntaxique et la meme operation de neutralisation de traits nous fournit une méthode de con-
struction pas a pas de ces modeles. Pour une deﬁnition formelle complete, le lecteur peut se
réfe’rer a (Perrier, 2003).

La ﬁgure 1, dans sa partie supérieure, nous montre un exemple de description de DAG seman-
tique, Dsem. Dans cet exemple, nous nous contentons d’utiliser deux traits type et cont. Le
premier indique le type sémantique du nteud, prédicat lexical (lex), opérateur logique (logique)
ou quantiﬁcateur (quant) 3, et le second son contenu. Les deux quantiﬁcateurs associés a tous
et quelqu’un sont représentés a l’aide de prédicats a 3 arguments : la variable quantiﬁe’e, sa
restriction qui permet de caracte’riser logiquement l’entite’ représenter par cette Variable et la
porte’e du quantiﬁcateur. Dans notre exemple, la restriction correspondant a tous est Vide d’o1‘1
la Valeur vrai de son trait cont alors que celle correspondant a quelqu’un est le prédicat humain.
Comme au niveau syntaxique, des contraintes permettent de ﬁxer la cardinalite’ de l’ensemble
des ﬁls d’un nteud et elles sont aussi représente’es graphiquement par des crochets tourne’s Vers
le bas. Par exemple, la contrainte pour—tout > [x, restriction], porteeI] exprime le fait que
pour—tout a exactement trois ﬁls x, restriction], porteel mais a la difference de la syntaxe, pour
distinguer leurs reles dans le prédicat, ils sont ordonne’s dans une liste et leur rang est note’ sur
l’arc représentant leur rele dans le prédicat. Comme un meme nteud peut avoir plusieurs peres,
nous avons aussi des contraintes ﬁxant la cardinalite’ de l’ensemble des peres d’un nceud. Par
exemple, dans Dsem, la contrainte { }> pred—racine exprime que le nteud pred—racine a son
ensemble de peres qui est Vide donc que c’est une racine. Enﬁn, les relations de portée peuvent

3La Valeur pred est une abréviation de la disjonction lea: V logique V quant, étant donné que les valeurs de
traits sont des disjonctions ﬁnies d’atomes.

La sémantique dans les grammaires d’interaction

étre contraintes de la meme facon que les relations de domination large au niveau syntaxique
avec des structures de traits neutres les étiquetant.

La description Dsem a exactement deux modeles neutres au sens ou nous le déﬁnissons dans
(Perrier, 2003) sous forme de deux DAG qui peuvent étre obtenus par 3 neutralisations de
polarite’s (le lecteur pourra lui—méme effectuer le calcul). Pour ensuite interpréter ces deux
DAG obtenus sous forme de formules logiques, il est nécessaire de disposer d’une traduction
logique de chacun de leurs nceuds. On peut le faire a l’aide du lambda—calcul en associant un
lambda—terme a chaque nteud et en interprétant chaque relation pere—ﬁls comme une applica-
tion du lambda—terme associe’ au nteud pere a ceux qui sont associe’s a ses ﬁls. Si on associe
aux nceuds p0ur—t0ut et il—existe les lambda—termes respectifs Ax R P.‘v’ac((Ra:) =>  et
Ax R P.E|x((Ra:) A (P:I:)), ou :L', R et P correspondent a la Variable quantiﬁe’e, la restriction et
la portée, le lecteur en déduira facilement l’interpre’tation des deux DAG par les deux formules
logiques \7’:L'(E|y (h/umain(y) A az'mer($,  et E|y(humain(y) A \7’:c az'me7'(a:, y)) correspon-
dant aux deux lectures possibles de la phrase tous aiment quelqu’un.

La proposition que nous faisons ici se distingue de la plupart des langages donnés en référence
au debut de la section par le fait qu’elle fournit un moyen de controler la saturation des struc-
tures sémantiques sous—spe’ciﬁe’es grace au mécanisme des polarite’s. Il est un langage qui s’en
rapproche, c’est la Hole Semantics (Bos, 1995) : les nceuds des descriptions y sont soit des
constantes, soit des trous et c’est le mécanisme d’identiﬁcation un a un des trous par des con-
stantes qui fournit le moyen de réduire la sous—spe’ciﬁcation et de produire les modeles d’une
description donnée. Dans l’eXemple du calcul des prédicats choisi comme sémantique objet,
nous nous distinguons aussi de ce qui se fait dans la plupart des langages précédemment cite’s
qui n’identiﬁent les nceuds qu’aVec des prédicats. Les nceuds de nos descriptions peuvent étre
soit des prédicats, soit des individus. Cette uniformisation de la représentation présente deux
avantages : elle permet d’aller plus loin dans la sous—spéciﬁcation en laissant indétermine’ le
type de l’argument d’un prédicat, individu ou prédicat lui—méme. La deuxieme raison est que
cela simpliﬁe beaucoup l’interface avec la syntaxe, les syntagmes pouvant correspondre aussi
bien a des individus qu’a des prédicats.

3 L’interaction entre syntaxe et sémantique dans le processus
d’analyse

Nous Venons de décrire sépare’ment les niveaux syntaxique et sémantique. Leur liage s’effectue
par une simple fonction qui projette tout nteud syntaxique sur au plus un nteud sémantique.
La ﬁgure 1 nous en fournit un exemple; la fonction de liage y est représentée a l’aide de traits
pointillés. On y constate que certains nceuds syntaxiques n’ont aucune image sémantique et,
dans l’autre sens, certains nceuds sémantiques, tels que les prédicats représentant les quantiﬁca-
teurs, n’ont aucun ante’ce’dent syntaxique.

Les IG sont lexicalisées. Une entre’e lexicale associe un mot a une description syntaxique et
une description sémantique couplées par la fonction de liage. Dans la description syntaxique,
un nteud y joue le role privilégie’ d’ancre, c’est—a—dire que c’est lui qui représente la position du
mot dans l’arbre syntaxique correspondant a la description.

Analyser une phrase avec les IG consiste tout d’abord a sélectionner une entre’e dans le lexique
pour chacun des mots de la phrase. En juxtaposant toutes les descriptions d’arbres syntaxiques
sélectionne’es, on obtient une unique description qui doit étr comple’tée par des relations de
précédence entre les ancres exprimant l’ordre des mots dans la phrase et par un nteud racine,
ici le nreud phrase, représentant la phrase attendue comme but de l’analyse. 11 en résulte une
description Dsyn, telle celle que l’on peut Voir a la ﬁgure 1, qui constitue le point de départ de
l’analyse. De facon analogue, on réunit les descriptions de DAG sémantiques sélectionne’es du
lexique en une unique description Dam couple’e avec Dsyn, comme on l’obserVe sur la ﬁgure

Guy Perrier

1. On aj oute une racine pred—racine a Dsem lie’e a la racine syntaxique phrase pour exprimer le
but de l’analyse au niveau semantique.

Le processus d’analyse est dirigé par la syntaxe, c’est—a—dire qu’il s’effectue en itérant les neu-
tralisations de traits dans Dsyn, jusqu’a que l’on obtienne un arbre syntaxique completement
spéciﬁe’ ou tous les traits sont neutres. Dans ce processus, la fonction de liage joue deux reles :

0 Elle contribue a speciﬁer progressivement Dsem car chaque fusion de deux nceuds syn-
taxiques entraine la fusion des nceuds sémantiques qui sont leurs images, si elles existent.

0 Le meme mécanisme peut entrainer une re’action du niveau sémantique sur le niveau
syntaxique. Certaines neutralisations au niveau syntaxique vont échouer parce que les
neutralisations qu’elles entrainent au niveau sémantique échouent aussi.

A la ﬁn d’une analyse syntaxique qui réussit, la description sémantique Dsem peut rester sous-
spéciﬁe’e comme c’est le cas dans notre exemple et comme le montre la ﬁgure 2. Si l’on souhaite
obtenir tous les modeles de Dsem, il faut continuer le processus de neutralisation de traits mais
au niveau sémantique cette fois. Si nous le faisons dans notre exemple, nous allons, apres 3
neutralisations, obtenir les deux DAG sémantiques attendus correspondant aux deux relations
de portée possibles entre les deux quantiﬁcateurs. Cet exemple est tres simple mais le lecteur
trouvera des exemples de mode’lisation de phe’nomenes linguistiques plus complexes dans (Per-
rier, 2003) (propositions relatives appositives et restrictives, verbes a montée et a contrele du
sujet, etc.).

D’un point de vue théorique, un tel processus d’analyse est extremement coﬁteux mais, comme
nous le montrons dans (Bonfante et al., 2003), les polarite’s nous fournissent des méthodes orig-
inales d’analyse qui permettent en pratique d’eviter l’explosion combinatoire. Ces méthodes
ont été implémentées dans l’analyseur syntaxique LEOPAR qui integre la sémantique et qui est

téléchargeable librement avec une grammaire et un lexique jouets du frangais4.

4 Autres approches de l’interface syntaxe-sémantique

Les IG présentent certaines similarite’s avec les TAG synchrones (Shieber & Schabes, 1990;
Shieber, 1994). Les deux formalismes visent a lier deux niveaux de representation qui utilisent
le meme principe de composition : neutralisation de polarite’s pour les IG et adjonction pour
les TAG. Néanmoins, les deux formalismes ont de profondes differences. De’ja les TAG sont
limite’es par l’adjonction qui ne permet pas de faire de la superposition de structures mais en
outre l’interface syntaxe-sémantique y est tres rigide : toute adjonction au niveau sémantique
doit etre couple’e avec une adjonction au niveau syntaxique, si bien que les arbres de de’rivation
syntaxique et sémantique sont isomporphes. Cet isomorphisme est un facteur maj eur de rigidite’
meme s’il peut etre un peu assoupli (Rambow & Satta, 1996).

L’autre approche de la sémantique dans les TAG qui s’appuie sur les arbres de de’rivation syn-
taxique est aussi tres rigide. La representation sémantique issue de l’arbre de de’rivation est
parfois en contradiction avec la representation souhaite’e (Candito & Kahane, 1998), ce qui a
d’ailleurs amene’ a l’introduction de nouveaux formalismes (Rambow et al. , 1995). D’autre part,
elle se prete mal a la representation de phe’nomenes comme la quantiﬁcation qui ne découlent
pas mécaniquement de la syntaxe.

Gardent et Kallmeyer (2003) proposent une nouvelle approche qui s’appuie sur les arbres syn-
taxiques derives. Chaque arbre derive est couple’ avec une formule logique sous—spe’ciﬁe’e dans
le cadre de la Hole Semantics (Bos, 1995). L’interface syntaxe-sémantique utilise en plus des
traits associés aux nceuds des arbres syntaxiques derives et qui indiquent avec quels individus

4L’adresse oil le logiciel peut etre téléchargé est 2 www.loriafr/equipes/calligramme/leopar.

La sémantique dans les grammaires d’interaction

ou predicats sémantiques ils sont en correspondance. Compte tenu du fait que la Hole Seman-
tics est tres proche de la representation sémantique dans les IG, on a une approche semblable,
la principale difference restant la representation du niveau syntaxique.

Du cete’ des CG, de Groote (2001) et Muskens (2003) ont des propositions Voisines l’une de
l’autre qui Visent a assouplir et a généraliser les CG. Ils proposent un formalisme a plusieurs
niveaux paramétrables. L’ un de ces niveaux peut etre instancie’ par la syntaxe et un autre par la
sémantique. A chaque niveau, c’est le fragment implicatif de la logique linéaire intuitionniste
qui est utilise’ pour gerer la composition des structures, ce qui présente certaines limites dans
le pouvoir d’eXpression. En outre, tous les niveaux sont isomorphes en un certain sens : toute
operation a un niveau qui est une operation de deduction logique elementaire (application ou
abstraction) doit etre couple’e avec une operation du meme type a l’autre niveau. Cet isompor—
phisme ne conduit pas a la meme rigidite’ que les TAG synchrones du fait la latitude qui est
offerte quant au langage d’instanciation de chaque niveau.

On trouve aussi une grande souplesse dans la representation de l’interface syntaXe—sémantique
du cete’ des grammaires de dépendance dans le formalisme propose’ par Kahane (2002), les
Grammaires d ’Uniﬁcati0n Sens—7?3xte (GUST). Suivant la the’orie Sens—Texte (Mel’cuk, 1988),
celui—ci comporte 3 niveaux : sémantique, syntaxique et phonologique. Les structures represen-
tees au niveau sémantique et syntaxique sont respectivement des DAG et des arbres et le liage
entre les deux se fait par ensembles de nceuds car, au niveau syntaxique, les nceuds représentent
des mots et non des syntagmes. Le fait que la quantiﬁcation et les relations de portée ne soient
pas traite’es au niveau sémantique et que les nceuds représentent des mots ne rend pas neces-
saire la representation de la sous—spéciﬁcation comme dans une approche syntagmatique car les
dépendances non borne’es sont traite’es de la meme fagon que les de’pendances locales. Dans sa
pre’sentation originelle, les GUST utilisaient l’uniﬁcation comme mécanisme de composition
des structures sans systeme de contrele de la saturation de ces structures. Cette faiblesse est
maintenant corrige’e de la meme fagon que dans les IG avec un systeme de polarite’s (Kahane,
2004).

L’intégration de la Minimal Recursion Semantics dans HPSG (Copestake et al., 1999) four-
nit un autre exemple de souplesse de l’interface syntaXe—sémantique qui est assurée par la co-
indexation dans des structures de traits codant en meme temps le niveau syntaxique et le niveau
sémantique. L’uniﬁcation sert de principe de composition de structures et elle peut etre Vue
comme une ge’néralisation de la superposition partielle de DAG, telle qu’elle se presente dans
les IG. Lui manque un mécanisme de contrele de la saturation des structures qui est garantie a
posteriori par des principes de bonne formation.

Conclusion

L’intégration de la sémantique dans les IG que nous proposons se Veut avant tout un cadre formel
pour exprimer la representation sémantique d’un enonce’ et l’interface avec sa representation
syntaxique. Elle ne préjuge en rien des choix linguistiques qui en permettent la re’alisation. Ce
cadre formel se caractérise par trois proprie’tés importantes : la notion de description permet
d’eXprimer la sous—spe’ciﬁcation aux deux niveaux, le mécanisme de composition des structures
completement spéciﬁe’es tant au niveau sémantique que syntaxique est guide par un systeme de
polarite’s et l’interface syntaXe—sémantique est souple et simple.

Remerciements

Merci a Benoit Crabbe’ et Sylvain Kahane pour la relecture de cet article et leurs commentaires
pertinents.

Guy Perrier

Références

BLACHE P. (2001), Les Grammaires de Proprie’te’s .' des contraintes pour le traitement automatique des
langues naturelles, Hermes Sciences.

BONFANTE G., GUILLAUME B., PERRIER G. (2003), Analyse syntaxique électrostatique, T raitement
Automatique des Langues, Vol. , A paraitre.

BOS J. (1995), Predicate logic unplugged, dans P. DEKKER & M. STOKHOF, Eds., 10th Amsterdam
Colloquium, p. 133-142.

CANDITO M.—H., KAHANE S. (1998), Can the derivation tree represent a semantic graph? an answer
in the light of Meaning—Text Theory, T AG+ 4, Philadelphia, p. 21-24.

CARPENTER B. (1998), T ype—logical Semantics, Cambridge, Massachusetts, MIT Press.

COPESTAKE A., FLICKINGER D., SAG I. (1999), Minimal Recursion Semantics — an Introduction,
Draft.

DE GROOTE P. (2001), Towards Abstract Categorial Grammars, Association for Computational Linguis-
tics, 39th Annual Meeting and 10th Conference of the European Chapter, Toulouse, France, p. 148-155.

EGG M., NIEHREN J ., RUHRBERG P., XU F. (1998), Constraints over lambda structures in semantic un-
derspeciﬁcation., I 7th International Conference on Computational Linguistics and 36th Annual Meeting
of the Association for Computational Linguistics (COLING/ACL’98), Montreal, Quebec, Canada.

GARDENT C., KALLMEYER L. (2003), Semantic construction in FTAG, EACL’2003, Budapest, Hun-
gary.

KAHANE S. (2002), Grammaire d ’Uniﬁcation Sens—Texte — Vers un modele mathe’matique articule’ de la
langue, Habilitation a diriger des recherches, Université Paris 7.

KAHANE S. (2004), Gramrnaires d’uniﬁcation polarisées, I I ieme Confe’rence annuelle sur le T raite—
ment Automatique des Langues Naturelles (TALN’04), F es, Maroc, France,, Soumis.

MEL’CUK I. (1988), Dependency Syntax: Theory and Practice, Albany, N.Y.: The SUNY Press.

MONTAGUE R. (1970), Universal grammar, T heoria, Vol. 36, 373-398, Reprinted in R. Thomason,
editor, Formal Philosophy, 188-221, New Haven: Yale University Press.

MUSKENS R. (2003), Lambda Grammars, Prospects and Advances in the Syntax/Semantics Interface,
Lorraine—Saarland Workshop Series, Nancy, p. 29-32.

PERRIER G. (2002), Descriptions d’arbres avec polarités : les grammaires d’interaction, 9ieme Con-
ference annuelle sur le T raitement Automatique des Langues Naturelles ( T ALN ’02 ), Nancy, F rance, 2002.

PERRIER G. (2003), Les grammaires d ’interaction, Habilitation a diriger des recherches, Université
Nancy2, Film de la soutenance visible a l’URL: http://www.inria.fr/multimedia/Didactheque—fra.html.

RAMBOW O., SATTA G. (1996), Synchronous Models of Language, ACL’96, Santa Cruz.

RAMBOW O., VIJAY—SHANKER K., WEIR D. (1995), D—tree grammars, ACL’95, Cambridge, USA, p.
151-158.

REYLE U. (1993), Dealing with ambiguities by underspeciﬁcation: Constrcution, Representation and
Deduction, Journal of Semantics, Vol. 10, 123-179.

SHIEBER S. (1994), Restricting the Weak—Generative Capacity of Synchronous Tree—Adjoining Gram-
mars, ComputationalIntelligence, Vol. 10(4), 371-385.

SHIEBER S., SCHABES Y. (1990), Synchronous Tree—Adjoining Grammars, CoLing’90, Helsinki,
volume 3, p. 1-6.

VIJAY—SHANKAR K. (1992), Using description of trees in a tree adjoining grammar, Computational
Linguistics, Vol. 18(4), 481-517.

