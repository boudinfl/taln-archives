TALN 2004, Session Poster, Fes, 19-21 avn'12004

Mots composes dans les modeles de langue pour la recherche
d’inf0rmati0n

Carmen Alvarez, Philippe Langlais et J ian—Yun Nie
RALI/IRO, Universite de Montreal
CP. 6128, succursale Centre—ville
Montreal, Quebec, H3C 3J7 Canada
{bissettc,felipe,nie}@iro.umontreal.ca

Resume - Abstract

Une approche classique en recherche d’information (RI) consiste a batir une representation des
documents et des requetes basee sur les mots simples les constituant. L’utilisation de mode-
les bigrammes a ete etudiee, mais les contraintes sur l’ordre et l’adjacence des mots dans ces
travaux ne sont pas toujours justiﬁees pour la recherche d’information. Nous proposons une
nouvelle approche basee sur les modeles de langue qui incorporent des aﬁinités lexicales (ALS),
c’est a dire des paires non ordonnees de mots qui se trouvent proches dans un texte. Nous
decrivons ce modele et le comparons aux plus traditionnels modeles uni grammes et bi grammes
ainsi qu’au modele Vectoriel.

Previous language modeling approaches to information retrieval have focused primarily on sin-
gle terms. The use of bigram models has been studied, but the restriction on word order and
adjacency may not be justiﬁed for information retrieval. We propose a new language modeling
approach to information retrieval that incorporates lexical afﬁnities (LAS), or pairs of words that
occur near each other, without a constraint on word order. We explore the use of LAS in a lan-
guage modeling approach, and compare our results with the vector space model, and unigram
and bi gram language model approaches.

Mots-clefs — Keywords

Modeles de langue, recherche d’information, mots composes
Language models, information retrieval, compound terms, word pairs

Carmen Alvarez, Philippe Langlais, et J1'an- Yun N1'e

1 Introduction

L’utilisation des modeles de langue en RI a été introduite par Ponte et Croft (1998). Chaque
document est considére’ comme un échantillon d’un langage particulier, et un modele de langue
est entrainé pour chaque document. Pour une requéte donne’e, les documents sont trie’s par ordre
décroissant de la probabilite’ que le modele du document génere la requéte. Cette approche
donne des performances comparables, Voire supérieures, au modele Vectoriel.

Représenter un document par un modele de langue représente un certain nombre de désaVan—
tages dont le principal est le probleme ici aigu de la sous—repre’sentation des données d’entrai—
nement. Entrainer un modele de langue (meme un simple unigramme) sur des documents qui
contiennent quelques centaines de mots représente en effet un certain déﬁ. Ainsi, Song et Croft
(1999) e’tudient diffe’rentes techniques de lissage connues comme le lissage Good—Turing ou
la combinaison linéaire de plusieurs modeles n—grammes d’ordres diffe’rents. Hiemstra (2002)
propose une technique d’interpolation o1‘1 un modele uni gramme du document et un modele de
corpus sont combine’s. Lavrenko et Croft (2001) font également usage d’une combinaison de
modeles de documents et d’un modele de corpus pour estimer un modele de pertinence (prob-
abilite’ qu’un mot soit pertinent pour une requéte), sans nécessiter de données d’entrainement
spéciﬁques.

Nous proposons une approche base’e sur l’entrainement de modeles de langues qui incorporent
des paires de mots non déﬁnies par des contraintes d’adjacence ou d’ordonnancement: les
afﬁnite’s lexicales (ALs). Nous commencons par présenter en section 2 le modele uni gramme
que nous utilisons a des ﬁns comparatives dans nos experiences. Nous décrivons ensuite en
section 3 une procédure initialement propose’e par Maarek et al. (1991) qui permet d’obtenir
les ALs d’un document et présentons en section 4 un modele de langue faisant usage de ces
afﬁnite’s. Nous décrivons ensuite en section 5 le cadre eXpe’rimental qui nous a permis d’étudier
le comportement des différents modeles décrits et discutons nos résultats dans la section 6. Nous
montrons en particulier qu’un modele de langue uni gramme lisse’ rivalise avec l’approche clas-
sique du modele Vectoriel et que la prise en compte des afﬁnite’s lexicales améliore de maniere
sensible les performances.

2 Modéles n-gramme sur les mots simples

Le score de pertinence d’un document d pour une requéte de N mots q = w{‘7 = wl, . . . , w N est
donne’ par la probabilite’ que le modele du document génere la requéte. Dans le cas d’un modele
n—gramme pnd, cette pertinence s’eXprime simplement par l’équation 1 o1‘1 n représente l’ordre
du modele:

N
score(d, q) = Hpn.(wiIw::;+1 (1)
i=1

Réaliser un systeme de RI a l’aide de modeles de langue peut se résumer dans sa forme la plus
simple a entrainer autant de modeles que de documents. La probabilité qu’un mot w d’une
requéte soit géne’re’ par le modele de langue d’un document peut alors étre estime’e par le max-
imum de Vraisemblance (MLE), ce qui revient dans le cas unigramme a calculer la fréquence
relative de w dans le document d.

Mots composes dans les modeles de Iangue pour la recherche d’1'nformat1'on

L’estimateur a maximum de Vraisemblance directement injecte’ dans l’équation 1 s’aVere en
pratique tres peu utile: les documents qui ne contiennent pas l’ensemble des mots de la requéte
se Voient attribuer un score de pertinence nul. Ce probleme bien connu en mode’lisation de
la langue (le lissage) est ici particulierement épineux puisque les documents que nous traitons
contiennent environ 200 a 400 mots.

La problématique du lissage a été et continue a étre un objet d’inVestigation scientiﬁque et de
nombreuses techniques ont été proposées pour l’entrainement de modeles de langue a partir de
grands corpus de textes (Goodman, 2001). Nous étudions dans Alvarez et al. (2003) diffe’rentes
techniques de lissage spéciﬁques a l’entrainement de modeles de langue pour la RI et rapportons
ici les conﬁgurations pour lesquelles nous avons observe’ les meilleurs résultats. ll convient de
noter que les documents ainsi que les requétes sont soumis a un pré—traitement qui consiste en
une lemmatisation et en la suppression de mots apparaissant dans une stoplistel.

Dans le cas d’un modele de langue unigramme, nous combinons linéairement le modele MLE
avec un modele de corpus selon l’équation 2. Ce dernier est un modele uni gramme MLE sur
l’ensemble des documents de la collection. Dans le cas d’un modele bi gramme, nous combinons
linéairement le modele MLE du document avec le modele uni gramme selon l’équation 3:

punid  = )\1pMLEd  ‘l‘  — )\1)pwrpus(w) 

pbid (wz'|wz'—1) = )\2pMLEd (wz'|wz'—1) + (1 — )\2)pum'd  (3)

3 Afﬁnités lexicales

L’hypothese d’indépendance entre mots, faite par le modele uni gramme, ainsi qu’une grande
partie des approches a la RI, n’est pas toujours justiﬁe’e. Les modeles bigramme (et a fortiori
les modeles d’ordre supérieur) tentent en effet de rendre compte des dépendances entre termes;
tout en supposant que l’ordre des mots est important. Tandis que cette derniere hypothese
semble raisonnable pour des applications comme la reconnaissance de parole, elle ne s’applique
pas nécessairement a la RI. Par exemple, pour une requéte “apartment rentals”, un document
contenant les termes “rent an apartment” ne doit pas étre a priori moins bien classe’ qu’un autre
document contant les termes “apartments for rent”. Notre réponse a ce probleme consiste a
baser notre mode’lisation sur une unite’ lexicale n’imposant aucune restriction sur l’ordre de ses
mots et peu de contrainte sur leur adjacence: l’afﬁnité lexicale.

Selon Martin et al. (1983), 98% des relations lexicales dans un texte mettent en jeu des mots
dans une fenétre de 5 mots. Nous adoptons cette proprie’te’ pour identiﬁer les unités (paires de
mots) sur lesquelles batir nos modeles de langue. Par ailleurs, Maarek et al. (1991) introduisent
le concept de pouvoir de résolution d’une paire de mots. A l’instar des facteurs tf et idf utilisés
dans le modele Vectoriel, l’idée principale derriere le pouvoir de résolution est que les paires de
mots qui caracte’risent le mieux un document sont celles qui ont en meme temps une fréquence
élevée dans le document et une fréquence relativement basse dans la collection. Les auteurs
suggerent de calculer le pouvoir de résolution d’une paire < u, ’U > pour un document d selon
l’équation 4; ou cd(< u, ’U >) est la fréquence de la paire dans le document d. Le terme logarith-

1Une liste de 571 mots anglais f ournie avec le systéme SMART a été utilisée.

Carmen Alvarez, Philippe Langlais, et J1'an- Yun N1'e

mique dans cette e’quation peut étre Vu comme une approximation de la quantité d’information
Véhicule’e par la paire, comparable au facteur idf.

pd(< “av >) = —Cd(< U’/U >) X 10g(pco7‘pus(u) X pco7‘pus(v)) 

Le pouvoir de résolution de toutes les paires de mots distants d’au plus cinq mots (pleins) dans
un document est calcule’. Il est important de noter que les paires < u, ‘U > sont stocke’es par
ordre lexicographique (la paire “traduction automatique” Vue dans un texte est traitée comme
“automatique,traduction”). La table 1 montre les cinq meilleurs afﬁnite’s lexicales de deux
documents de notre collection.

AP900302—1O AP900427—3

AL (< u,v >) fréquence pd AL (< u, ’U >) fréquence pd

court supreme 7 43,6 union Violence 6 37,7
court property 6 38,3 greyhound Violence 5 37,5
public sidewalk 4 30,5 greyhound union 5 34,6
court night 5 29,7 member union 6 34,2
court justice 4 24,6 condone Violence 4 33,4

Table 1: Les 5 meilleures ALs selon le pouvoir de résolution pour deux documents de la collec-
tion TREC AP90: le document AP900302—1O traitant du 200e anniversaire de la cour supreme
des Etats—Unis et le document AP900427—3 traitant des syndicats de la société Greyhound.

4 M L A: Un modéle de langue basé sur les afﬁnités lexicales

Notre modele M L A est un modele unigramme qui estime les probabilite’s des mots simples et
des paires de termes du document. Pour ce faire, on introduit les comptes décrits en equation 5;
desquels on obtient la probabilite’ de chaque événement p(w’) (w’ étant un mot ou une paire) en
les normalisant par la constante D = Zwed cd(w)+Z<u,,,>€d ﬂpd(< u, ‘U >). Cette approche est
conceptuellement équivalente a l’ajout dans chaque document du compte fractionnaire (controle’
par ﬁd, ﬁxe pour l’ensemble des documents) des afﬁnite’s lexicales du document.

* , _ cd(w) si w’ est un mot simple w
Cd(w) _ { ﬂdpd(< u,v >) sinon (5)

Ce modele est a son tour lisse’ par le modele de corpus décrit dans la section 2, ou les probabilités

[ [ A I
pcorpus (w ) se basent sur les comptes cj0Tpus(w ), controles par un facteur ﬂwrpus.

0* (w’)
D

PMLA (wl) = )‘MLA + (1 — )\MLA)pCOTPu3 (U/)) (6)

Si le meme traitement est appliqué a la requéte q (en controlant les comptes fractionnaires par
un coefﬁcient ﬁg, ﬁxe pour toutes les requétes), le score de pertinence est alors:

score<d,q> = H pM.,,<w'>c3<'“’> <7)

w’€q

Mots composes dans les modeles de Iangue pour la recherche d’1'nformat1'on

5 Expériences

Nous avons étudie’ le comportement des diffe’rents modeles présente’s sur la collection TREC
AP90, qui contient 78 321 documents en anglais de l’Associated Press newswire de 1990. 53
requétes étiquetées manuellement pour les pistes translinguistiques des campagnes TREC—6
et TREC—7 constituaient notre corpus de test (une moyenne de 22 documents pertinents sont
associés a chaque requéte). Chaque requéte comporte un champ titre de 1 a 5 mots (2.5 en
moyenne) ainsi qu’un champ description contenant de 3 a 19 mots (7 en moyenne).

Chaque experience comprend deux tests. L’ un dénote’ TITRE consiste a n’utiliser que le champ
titre d’une requéte, l’autre dénote’ DESC utilise les champs titre et description. La tache du
systeme consiste a classer par ordre décroissant de pertinence les documents de la collection
pour chaque requéte. La métrique d’éValuation que nous utilisons est la précision moyenne
habituellement utilise’e dans ce type de tache et qui mesure la moyenne de précision obtenue
sur plusieurs points de rappel (Salton & McGill, 1983), pour les 1000 premiers documents
retrouVe’s par le systeme. Aﬁn de comparer nos diffe’rents modeles a un systeme e’prouVé, nous
avons utilise’ le systeme SMART qui implémente le modele Vectoriel classique (Buckley, 1985).

La table 2 montre les performances du modele M L ,4. Les précisions indique’es en gras corre-
spondent a des Variantes dont les performances mesurées dépassent le modele uni gramme et
le systeme SMART. Notre modele de’passe le modele uni gramme pour plusieurs combinaisons
de ﬂd et ﬂq. Pour les requétes TITRE, le gain relatif mesure’ le plus important est de 2.0%. La
meilleure précision moyenne obtenue avec les requétes DESC (43.20) est supe’rieure au modele
unigramme (42.75), soit un gain relatif de 1.0%.

AMLA 0.1 0.2 0.4 0.5 0.6 Smart 1—gram 2—gram
/6d:/Bqa/6C0Tp'U.s

TITRE .01,.01,.01 39.20 40.77 40.87 41.43 41.13 33.49 40.71 40.72
.01,.01,.0001 39.39 40.92 40.95 41.54 41.39 33.49 40.71 40.72

DESC .01,.005,.01 41.18 43.20 42.66 42.29 41.96 34.98 42.75 42.77

.04,.005,.0001 40.95 43.14 42.74 42.39 42.00 34.98 42.75 42.77

Table 2: Precision moyenne obtenue par le modele M L ,4 en fonction des méta—parametres AMLA
et ﬁd pour le document, ﬂq pour la requéte et ﬂwrpus pour le modele de corpus. Les résultats qui
sont signiﬁcatifs, selon le test de Wilcoxon des rangs signe’s avec un intervalle de conﬁance de
95%, sont indique’s en italique.

6 Discussion

11 existe plusieurs travaux qui tentent d’améliorer les performances d’un systeme de recherche
d’information base’ sur les mots simples. En particulier, Nie et Dufoit (2002) e’tudient l’ajout
de termes compose’s comme de nouveaux indices dans le modele Vectoriel. Ils montrent que
l’adjonction de termes en provenance des bases terminologiques (Termiumz et la Banque de
terminologie du Québec3) permet d’améliorer les performances d’une tache de RI si ces termes

Zhttp://www.termium.com
3http://www.olf.gouv.qc.ca/ressources/bibliotheque/dictionnaires/Intemet/Index/

Carmen Alvarez, Philippe Langlais, et J1'an- Yun N1'e

sont incorporés de maniere ade’quate.

Dans cette étude, nous montrons qu’il est possible d’améliorer (certes de maniere modeste)
les performances d’un modele de langue s’il fait usage d’afﬁnités lexicales. Ce type d’unite’
est intuitivement attirant en RI car il ne possede pas la rigidite’ des séquences de mots. Nous
observons que l’augmentation en performance due aux ALs est plus marquée pour les requétes
courtes (TITRE). Les requétes plus longues (DES C) contiennent en moyenne 18 paires. Bien que
n’ayant pas mer1e’ d’analyse systématique, nous pensons que dans le cas de requétes longues,
plusieurs ALs ne sont pas pertinentes.

Les perspectives que cette étude suggere sont multiples. Les modeles que nous proposons
sont régis par plusieurs parametres (A1, A2, AMLA, ﬂd) que nous avons ﬁxe’s empiriquement.
Une approche plus systématique nous permettrait d’ajuster ces parametres et d’en augmenter
le nombre. Il est en effet intuitif de penser que le poids donne’ a un modele donne’ devrait
a tout le moins étre conditionne’ par la taille du document traite’. Nous souhaitons également
étudier l’impact de differentes techniques de ﬁltrage des ALs, notamment grace a un étiqueteur
morpho—syntaxique.

Références

ALVAREZ C., LANGLAIS P. & J .Y—NIE (2003). Word Pairs in Language Modeling for Information
Retrieval. Rapport inteme, RALI.

BUCKLEY C. (1985). Implementation of the SMART information retrieval system. Rapport inteme,
Cornell University. Technical report 35-686.

GOODMAN J. (2001). A bit of progress in language modeling. Computer Speech and Language, p.
403-434.

HIEMSTRA D. (2002). Terrn—speciﬁc smoothing for the language modeling approach to information
retrieval: the importance of a query term. In 25th annual international ACM SIGIR conference on
Research and Development in Information Retrieval, p. 35-41, Tampere, Finland.

LAVRENKO V. & CROFT W. B. (2001). Relevance—based language models. In 24th annual international
ACM SI GIR conference on Research and Development in Information Retrieval, p. 120-127.

MAAREK Y., BERRY D. & KAISER G. (1991). An information retrieval approach for automatically
constructing software libraries. IEEE transactions on software engineering, p. 800-813.

MARTIN W., AL B. & VAN STERKENBURG P. (1983). On the processing of a text corpus: From textual
data to lexicographical information. In E. R.R.K. HARTMANN, Ed., Lexicography: Principles and
Practice, Applied Language Studies Series. Academic Press, London.

NIE J .—Y. & DUFORT J. (2002). Combining words and compound terms for monolingual and cross-
language information retrieval. In Information 2002.

PONTE J. M. & CROFT W. B. (1998). A language modeling approach to information retrieval. In 21 st
annual international ACM SIGIR conference on Research and Development in Information Retrieval, p.
275-281, Melbourne, Australia.

SALTON G. & MCGILL M. J. (1983). Introduction to Modern Information Retrieval. New York:
McGraw Hill.

SONG F. & CROFT W. B. (1999). A general language model for information retrieval. In 22nd annual
international ACM SIGIR conference on Research and Development in Information Retrieval, p. 279-
280.

