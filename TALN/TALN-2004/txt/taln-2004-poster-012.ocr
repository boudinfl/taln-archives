Classiﬁcation automatique de deﬁnitions en sens

Fabien J alabert (1 & 2), Mathieu Lafourcade (2)
fabien.jalabert@ema.fr , mathieu.lafourcade@lirmm.fr

(1) LGI2P — Ecole des Mines d’Ales
Parc Scientiﬁque Georges Besse
30 035 — N'1'mes Cedex 1
www.lgi2p.ema.fr

(2) LIRMM — Universite Montpellier II
34 392 — Montpellier Cedex 5
www.lirmm.fr

Mots-clefs — Keywords

Traitement automatique des langues naturelles, classiﬁcation automatique, desambigu'1'sation
semantique lexicale
Natural language processing, unsupervised clustering, word sense disambiguation

Resume - Abstract

Dans le cadre de la recherche en semantique lexicale, l’equipe TAL du LIRMM developpe
actuellement un systeme d’analyse des aspects thematiques des textes et de desambiguisation
lexicale base sur les vecteurs conceptuels. Pour la construction des vecteurs, les deﬁnitions
provenant de sources lexicales differentes (dictionnaires a usage humain, listes de synonymes,
deﬁnitions de thesaurus, . . .) sont analysees. Aucun decoupage du sens n’est present dans la re-
presentation : un vecteur conceptuel est associe a chaque deﬁnition et un autre pour representer
le sens global du mot. Nous souhaitons effectuer une categorisation aﬁn que chaque element ne
soit plus une deﬁnition mais un sens. Cette amelioration concerne bien sur directement les ap-
plications courantes (desambigu'1'sation, transfert lexical, . . .) mais a aussi pour objectif majeur
d’ameliorer l’apprentissage de la base.

In the framework of research in meaning representation in NLP, we focus our attention on the-
matic aspects and conceptual vectors. A Vectorial base is built upon a morphosyntactic analysis
of several lexical resources to reduce isolated problems. A conceptual vector is associated with
each deﬁnition and another one with the global meaning of a word. There is no effective mea-
ning division and representation the the knowledge base. We study in the article a clustering
method that merge deﬁnitions into senses. This applies on common problems (word sense di-
sambiguation, word translation, . . .) and mainly to improve knowledge base learning.

Fabien Jalabert, Mathieu Lafourcade

Introduction

Dans le cadre de la recherche en semantique lexicale, l’equipe TAL du LIRMM developpe
actuellement un systeme d’analyse des aspects thematiques des textes et de desambigu'1'sation
lexicale base sur les Vecteurs conceptuels (Lafourcade et al., 2002). Les Vecteurs representent
les idees associees a tout segment textuel (mots, expressions, textes, ...) Via l’actiVation de
concepts. Pour la construction des Vecteurs, nous avons pris notamment l’hypothese d’un ap-
prentissage multi—source aﬁn de pallier le bruit deﬁnitoire (par exemple les problemes dus au
metalangage comme dans la deﬁnition d’<aboyer> : crier en parlant du chien).

L’utilisation de multiples sources fait disparaitre la notion d’atomicite du sens. Un Vecteur est
associe globalement a un mot et plus ﬁnement a chaque deﬁnition. Mais aucun decoupage des
sens n’apparait reellement a ce stade. Nous proposons dans cet article d’effectuer une classiﬁ-
cation non—superVisee (categorisation) aﬁn de regrouper les deﬁnitions similaires en sens. Les
methodes de categorisation sont nombreuses et beneﬁcient de nombreux travaux mais ne sont
pas directement adaptees pour traiter des deﬁnitions de dictionnaires.

L’etude suivante decrit la speciﬁcite de ce probleme ainsi que les choix proposes en reponse
avant de presenter en detail la procedure mise en ceuvre.

1 Categorisation des deﬁnitions

Les methodes de classiﬁcation automatique sont nombreuses (Alpert, Kahng, 1995), (Berkhin,
2002) mais ne sont cependant pas directement applicables dans le cadre de cette etude, car
la categorisation et la classiﬁcation dans ces domaines traitent un grand nombre de donnees
a repartir dans un faible nombre de classes en un processus unique. Dans notre cas, la masse
de donnees est importante (actuellement pour 110 000 termes, plus de 430 000 deﬁnitions et
Vecteurs conceptuels), mais la categorisation porte sur les deﬁnitions d’un seul terme (environ
5 deﬁnitions en moyennes par source, certains termes fortement polysemiques peuvent en avoir
plus de 50).

Cependant, dans notre cas, une categorisation ne s’applique qu’a quelques dizaines de deﬁni-
tions tout au plus. Les algorithmes du domaine de la fouille de donnees recherchent une efﬁ—
cacite globale dans un grand ensemble de donnees. Notre approche du probleme se distingue
donc par une importance moindre du coﬁt calculatoire et s’appuie sur une profondeur d’analyse
superieure.

1.1 Choix de l’algorithme

Le choix de l’algorithme repose de differents constats :

Le volume de la donnée est faible. Le probleme est donc moins restrictif concernant le choix
des methodes d’analyses et de l’algorithme. Cependant, il est impossible d’enVisager un
entrainement sur lequel repose certains algorithmes dont les Support Vector Machine
(SVM) par exemple (Vapnik, Chervonenkis, 1964), (Burges, 1998).

Les dictionnaires sont supposes ﬁables et par consequent deux deﬁnitions d’un meme diction-
naire ne peuvent appartenir a une meme classe resultat.

L’aspect hiérarchique n’est pas preponderant dans les sens. Si une relation partielle d’hyper—
onymie est presente en semantique, il est frequemment impossible de generaliser deux
sens car leur decoupage ne repose pas exclusivement sur une hierarchie (mais sur une
analogie par exemple).

Le nombre de classes est inconnu a priori. Cependant, l’hypothese de ﬁabilite des dictionnaires
decrite ci—dessus implique que le nombre de sens d’un terme donne est superieur ou egal au

Classiﬁcation automatique de deﬁnitions en sens

nombre maximum de deﬁnitions presentes dans une des sources. Nous avons donc opte pour
l’algorithme des k—m0yennes. Les centro'1'des sont initialises avec les deﬁnitions du dictionnaire
qui en a le plus grand nombre. Puis, de fagon iterative pour chaque dictionnaire, et de fagon
gloutonne, chaque deﬁnition est affectee aux differentes classes et les centro'1'des sont recalcules.

Il faut noter que l’hypothese precedente n’est pas vraie. Certains dictionnaires divisent deux
sens la ou certains n’en proposent qu’un plus general. Lorsque cela se produit simultanement
pour deux sens differents, deux dictionnaires possedant chaque sens peuvent en realite signiﬁer
5 sens feuilles et deux sens hyperonymiques. Ce probleme s’avere cependant isole et dans le
cas de termes a tres forte polysemie, ces termes sont peu nombreux mais en revanchent sont
frequents en usage. Nous recherchons actuellement des solutions face a cette difﬁculte.

2 Principe general de l’alg0rithme

2.1 Deroulement general

L’algorithme utilise suit le principe des k—m0yennes. A l’initialisation, soit D l’ensemble des
sources lexicales d,- et dmaw le dictionnaire comportant le plus grand nombre nmw de deﬁnitions.
Alors on construit nmw classes et a chacune est affectee une deﬁnition de dmaw. Soit C l’en—
semble des classes c,- obtenues. L’algorithme a pour objectif de rechercher un partitionnement

optimal pour la fonction d’evaluation globale (Eval) suivante : Eval (C) = : 
i=1 12. Ta. 1

avec D Inter la distance entre les categories c,- E C :
_ 1 n n p
D1m;eT(C) — W Z2-;1,J-=2-+1 DA(c,-, cj) avec C,-, cj E C

et avec D [mm la distance interne a une categorie c E C :

D1mm(c) =  Z-"=1 DA(d,-,m)p avec d,- E C

ELSE 

et avec m =
ICI

centro'1'de de la categorie

L’ al gorithme itere pour chaque source et procece a l’affectation de valeur minimum entre les de-
ﬁnitions de la source et les differentes classes. Etant donne le faible nombre de sources lexicales,
il est necessaire que toutes les sources soit affectees sur un ensemble de centro'1'des deja amorce.
L’algorithme effectue ainsi au minimum 1: = 2 X |{s0m'ces}| iterations. Quand une source
a deja ete affectee, ses elements sont supprimes des classes avant d’etre a nouveau reaffectes.
L’algorithme se termine lorsqu’il y a convergence. En pratique, il est rare que la convergence
ne soit pas obtenue apres k iterations.

2.2 Probléme de l’affectati0n de coﬁt minimal

A chaque etape de l’iteration, l’algorithme possede une matrice de distances entre les categories
et les deﬁnitions qui doivent etre affectees. 11 se pose donc le probleme de trouver l’affectation
de coﬁt minimal : ce probleme est equivalent au probleme couplage maximum de valeur mi-
nimum dans un graphe biparti, ou encore a un probleme de combinaison lineaire. La methode
Hongroise (Kuhn, 1955) (algorithme de complexite O(n3), ou n est la cardinalite de la plus
grande des deux partitions du graphe) est un cas particulier de (Ford, Fulkerson, 1956) qui
considere de probleme dans le cas plus general d’un graphe.

Fabien Jalabert, Mathieu Lafourcade

3 Profondeur d’analyse et aspect multicritére

Le dernier aspect de cet algorithme et la me’thode d’analyse qui permet d’obtenir les distances.
Nous l’aVons Vu, les impe’ratifs de complexite’ sont moins restrictifs que ceux géne’ralement
présent dans la fouille de donne’e. Ainsi nous avons fait le choix d’une approche multicritere
aﬁn de pallier statistiquement les de’fauts isole’s inhérents a chaque type d’analyse du sens.

3.1 Types de critéres

Chaque critere est sollicite’ a deux étapes diffe’rentes de l’algorithme pour fournir une mesure
de distance. A chaque itération de l’algorithme, ils doivent d’une part proposer une matrice de
distance pour l’affectation des déﬁnitions d’une sources dans les différentes categories, puis
d’autre part a la ﬁn de l’ite’ration permettre d’éValuer les distances inter et intra—catégories.
Les criteres sont ponde’re’s entre eux et suivant le type de source lexicale utilise’. Ces criteres
s’articulent autour de trois axes principaux :

Le critére de distance angulaire est simplement base’ sur l’utilisation de l’angle entre deux
Vecteurs. Ce critere est particulierement important dans le cas des <de’ﬁm'tz'ons manuelles>,
qui sont tres succintes, et qui sont géne’ralement insérées dans la base pour corriger et
ﬁxer des sens.

Le critére d’analyse ad-hoc extrait le contenu lexical des de’ﬁnitions en recherchant des lo-
cutions ad—h0c. Ils recherchent par exemple des informations de domaine (<me’cam'que>,
<bi0l0gz'e> . . .), d’e'tymologie (<du latin  qui sigmﬁe  >), d’usage (<ancz'en>, <arg0t>, . .  ll
ne s’agit pas de proposer une mesure de distance mais de proposer un bonus ou un malus
ponde’ré en fonction de chaque cas. Ce critere recherche aussi d’autres motifs dans le cas
de dictionnaire semi—structurés (a l’aide de XML ou SGML par exemple).

Le critére d’analyse de contenu lexical extrait les similitudes entre les contenus lexicaux des
diffe’rentes déﬁnitions. ll peut étre parame’tre’ avec des fonctions de fréquence et de co-
occurence de termes qui permettent apres un apprentissage en corpus de reﬂéter l’usage
des termes. Ce critere est plus amplement détaille’ dans le paragraphe suivant.

3.2 Critére d’analyse de contenu lexical

Ce critere compare les de’ﬁnitions par la pre’sence simultanée de termes. La cooccurence obtenue
est ponde’rée par la position et les informations morphosyntaxiques de chaque de’ﬁnition. En ef-
fet, la plupart des de’ﬁnitions sont de’crites en genre et diﬂérence, c’est a dire par un hyperonyme
suivi de la description souvent ordonne’e des caractéristiques propres. Cependant, l’apposition
d’un complément (place’ en début de déﬁnition, avant le Verbe et le sujet) est fréquente dans les
déﬁnitions et constitue souvent une forte participation au sens.

Le déroulement de cette e’Valuation est le suivant :

— A l’aide d’une analyse morphosyntaxique (Chauche’, 1984), nous supprimons les termes ap-
partenant au méta—langage, les de’terminants, pronoms, pre’positions et plus géne’ralement les
termes qui ne participent pas fortement a la thématique de la de’ﬁnition. Puis en fonction de
l’arbre morphosyntaxique, nous réordonnons tous les termes restants en traitant par exemple
les appositions de compléments, mais aussi en placant les gouverneurs avant les adjointsl) . . .

1Par exemple dans <v0ile £1 bateaw on donne plus d’importance £1 <v0ile> qui est 1e 1e gouvemeur (ou téte)
qu’a <bateau> qui est son adjoint, tandis que dans <bateau £1 v0z'le>, <bateau> est favorisé

Classiﬁcation automatique de deﬁnitions en sens

Enﬁn, une fois cette liste de termes dont l’ordre est sense’ reﬂéter la participation de’croissante
a la thématique, nous indigonsz tous ces termes.

— Ensuite nous appliquons une fonction de’croissante de 1 a 0 en fonction de la Valeur de cette
indice ind : f = kl — k2.l0g(ind) ou kl et kg sont des constantes réelles.

— Pour les termes qui ont plusieurs occurences dans une deﬁnition (dans le cas ou on compare
deux de’ﬁnitions entre elles) ou dans un ensemble de de’ﬁnitions (dans le cas ou on compare
une deﬁnition avec une classe de deﬁnitions), on remplace les occurences multiples par une
seule dont la Valeur est la somme des pre’cédentes. Soient ind1..indj les indices occurences
du mots m dans une déﬁnition, alors ces occurences sont remplace’es par Zia f

— Enﬁn, on mesure une proximite’ entre documents sources par une fonction qui effectue la
somme des produits des indices ponde’re’s pour chaque terme present dans les deux de’ﬁnitions

ou groupes de déﬁnitions compare’s : pr0acd1,d2 = Ztqdmdg) ( f ( incited, ) . f ( incited, 
Remarques :
— Notons que cette fonction n’est pas une mesure de similarite’ ni de distance. Elle ne respecte
notamment pas la propriété de minimalité : pr0ac(ac, as) 75 0
— d,- est une déﬁnition et cj est une catégorie, on les considere tous deux comme des ensembles
de termes indice’s, les indices commengant a 1 a chaque début de de’ﬁnition.
— On peut proposer plusieurs Variantes en fonction des choix suivants :
— La position d’un terme peut étre brute c’est a dire directement dans la deﬁnition, ou peut
étre calcule’e dans l’arbre morphosyntaxique.
— Il est possible de comptabiliser ou non plusieurs fois un terme qui possede de multiples
occurences dans une meme deﬁnition ou classe de de’ﬁnition.
— Enﬁn, pour comptabiliser ces occurence multiples, on peut conside’rer l’indice minimum
ou encore effectuer la somme des Valeurs obtenues en appliquant f aux indices.

3.3 Pondération distributionnelle
Enﬁn, les résultats précédents peuvent étre ponde’re’s en ajoutant des criteres de fréquence ou de
cooccurence dans les corpus :

— Plus un terme est rare dans la totalite’ des dictionnaires ou du corpus, plus il est discre-

minant. On peut donc choisir de ponde’rer la fonction de proximité de la fagon suivante :
_ f(i ) - f(i )
P"°””freq(d1> 42) - Xtetdmda  , . .
— La cooccurence permet de ponderer le resu tat o tenu par les deﬁn1t1ons en tenant compte de

l’usage de la langue dans les corpus. Plusieurs méthode d’application sont possibles :

— La premiere consiste a ponde’rer l’importance des termes en Valorisant ceux pre’sents qui
sont corre’le’s avec le mot que l’on souhaite déﬁnir. Ainsi, soit m un terme, d1 et d2 deux
de’ﬁnitions de ce terme que l’on souhaite comparer et tk les termes présents dans ces deﬁ-

nitions : pro-’Ecoocc1(d17d2) = Zt€(d1ﬂd2) (.f(it€d1) ' .f(it€d2) ' C00CC(t7 

— On peut d’autre part étendre la comparaison en comparant tous les termes des de’ﬁnitions et
en ponde’rant par la cooccurence. La similarite’ ne dépend plus alors de la présence simul-
tane’e d’un meme terme dans les deux déﬁnitions mais de la présence dans les de’ﬁnitions
de termes sémantiquement proches :

proacwoccg (d1, d2) = Zt1€d1,t2ed2)(f(it1) . f(i,;2) . c00cc(t1, m) . c00cc(t2, 
— Enﬁn il est possible de conjuguer les deux criteres par une pondération supplémentaire de
la seconde formule avec m, par exemple :

pr0acwocc3 (d1, d2) = Zt1€d1,t2€d2)(f(it1) . f(i,;2) . c00cc(t1,m) . c00cc(t2,m) . c00cc(t1,t2))

2Par ordre croissant en commencant 51 1.

Fabien Jalabert, Mathieu Lafourcade

Ces criteres présentes des résultats encourageants, mais une étude comparative serait neces-
saire aﬁn de determiner les parametres ade’quats et les méthodes les plus performantes ou
complémentaires.

Résultats et conclusion

Nous avons présente’ dans cet article une nouvelle méthode permettant de cate’goriser les deﬁ-
nitions provenant de multiples sources lexicales aﬁn d’obtenir des sens. Les résultats obtenus
sont assez encourageants, et plus particulierement, la méthode d’analyse ponde’rée par la cooc—
curence de termes. Cependant de nombreux travaux restent encore nécessaires : la classiﬁcation
est efﬁcace pour une bonne proportion du lexique, mais s’averent moins pertinente pour des
termes possédant un grand nombre de sens, qui sont moins nombreux mais tres frequents (les
sens sont trop nombreux et insufﬁsamment démarque’s). L’observation des erreurs commises
montre que les interversions relevent souvent de cliques de sens et notre réponse a ce probleme
s’oriente donc actuellement a réduire le nombre de sens et fusionner les multiples classes.

Mais ceci pose de nouveaux problemes : avant tout, réduire le nombre de sens implique que
plusieurs deﬁnitions d’une meme source peuvent étre affecte’es a une meme classe, dont les
conse’quences peuvent étre un perte d’efﬁcacite’ globale. Enﬁn, les méthodes na'1'ves statistiques
que nous avons mises en jeu pour détecter et choisir le nombre de sens n’offrent pas de résultats
satisfaisants. Cependant, malgré toutes ces difﬁcultés, l’obtention de sens si imparfaite qu’elle
est actuellement s’avere bénéﬁque pour l’apprentissage de la base vectorielle. L’amélioration
de cette derniere laisse prévoir réciproquement un impact positif sur la cate’gorisation.

Références

C.J. Alpert, A.B. Kahng Recent Directions in Netlist Partitioning .' A Survey Integration : VLSI
J., vol. 19, 1995, 93 pp.

P. Berkhin Survey of clustering data mining techniques Accrue Software Research Paper, 56
PP-

C.J.C. Burges A Tutorial on Support Vector Machines for Pattern Recognition Journal : Data
Mining and Knowledge Discovery, vol. 2, number 2, pp. 121-167, 1998.

J. Chauché Un outil multidimensionnel de l’analyse du discours Coling’84, Stanford, July
1984

L.R. Ford, D.R. Fulkerson Maximal Flow through a Network Candidan Journal of Mathema-
tics,p. 399, 1956.

H.W Kuhn The hungarian method for the assignment problem Naval Res. Logist. Quart.,
pages 83-98, 1955.

M. Lafourcade, V. Prince, D. Schwab Vecteurs conceptuels et structuration e’mergente de ter-
minologies Revue TAL Volume 43 — n 1/2002, pages 43 a 72

V. Vapnik, A. Chervonenkis A note on one class of perceptrons Journal Automatic and Remote
Control, vol. 25, 1964.

