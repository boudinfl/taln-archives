TALN 2004, Session Poster, Fes, 19-21 avr1'12004

NLP Applications Based on Weighted Multi-Tape Automata

André Kempe
Xerox Research Centre Europe — Grenoble Laboratory
6 chemin de Maupertuis — 38240 Meylan — France
andre.kempe@xrce.xerox.com — www.xrce.xerox.com/people/kempe/

Abstract

This article describes two practical applications of weighted multi—tape automata (WMTAS) in
Natural Language Processing, that demonstrate the augmented descriptive power of WMTAS
compared to weighted 1—tape and 2—tape automata. The two examples concern the preserva-
tion of intermediate results in transduction cascades and the search for similar words in two
languages. As a basis for these applications, the article proposes a number of operations on
WMTAS. Among others, it (re—)deﬁnes multi—tape intersection, where a number of tapes of
one WMTA are intersected with the same number of tapes of another WMTA. In the proposed
approach, multi—tape intersection is not an atomic operation but rather a sequence of more ele-
mentary ones, which facilitates its implementation.

Keywords

ﬁnite—state automaton, weighted multi—tape automaton, transduction cascade, lexicon

1 Introduction

Finite state automata (FSAS) and weighted ﬁnite state automata (WFSAS) are widely used in
language and speech processing (Kaplan & Kay, 1981; Mohri, 1997; Beesley & Karttunen,
2003). They permit, among others, the fast processing of input strings and can be easily modi-
ﬁed and combined by well deﬁned operations. Most systems and applications deal with I—tape
and 2—tape automata, also called acceptors and transducers, respectively. Multi—tape automata
(MTAs) (Elgot & Mezei, 1965) offer additional advantages such as storing different types of
information on different tapes. MTAs have been implemented and used, e.g., in the morpholog-
ical analysis of Semitic languages, where the vowels, consonants, pattern, and surface form of
words have been represented on different tapes (Kay, 1987; Kiraz & Grimley—Evans, 1998).

This article describes two practical applications of weighted multi—tape automata (WMTAS)
and MTAs in Natural Language Processing (NLP). The ﬁrst example shows how intermediate
results can be preserved in transduction cascades so that they can be accessed by any of the
following transductions (Sec. 4.1). The second one deals with the search for words that are
similar in two languages, and in particular in French and Spanish (Sec. 4.2). To support these
applications, the article deﬁnes WMTAS (Sec. 2) and some WMTA operations (Sec. 3). Efﬁcient
algorithms for the these operations have been implemented in the WFSC toolkit (Kempe et al.,
2003) and will be presented in future publications.

Andre’ Kempe

2 Weighted Multi-Tape Automata

In the following we build on basic deﬁnitions of a monoid, a semiring, a weighted automaton,
and a multi—tape automaton (Elgot & Mezei, 1965; Eilenberg, 1974; Kuich & Salomaa, 1986;
Mohri et al., 1998) which we do not recall for reasons of space.

A weighted multi—tape automaton (WMTA), A(") , also called weighted n—tape automaton, over
a semiring IC is deﬁned as a siX—tuple

 =def <27Q7I7F7E(n)7IC> 

with 2 being a ﬁnite alphabet, Q the ﬁnite set of states, I Q Q the set of initial states, F Q Q the
set of ﬁnal states, n the arity, i.e., the number of tapes in A("), E(") Q (Q X (Z*)" X K x Q)
the ﬁnite set of n—tape transitions, and IC = (K, 63, ®, 0, 1) the semiring of weights. For any
state q E Q, we denote by )\(q) E IC its initial weight and by g(q) E IC its ﬁnal weight. For
any transition e(") E E("), e(") = (p, E("),w, n), we denote by p(e(")) E Q its source state, by
w(e(")) E IC its weight, by n(e(")) E Q its target state, and by E(e(")) its label which is an n—tuple
of strings, E : E(") —> (Z]*)". A path 7r(") of length 7' = |7r(")| is a sequence of transitions
e[")eg") - - - e[") such that n(e[")) = p(e[:)1), Vi E [[1, r— 1]]. A path is said to be successful iff
p(e[")) E I and n(e[")) E F. Its label €(7r(")) is an n—tuple of strings and equals the concatenation
of the labels of its transitions:

E(7r(")) = W = (s1,s2,...,sn) = e(e§">).e(eg">) ...e(eg">) (2)
Its weight w(7r(")) is
w<vr<">> = A<p<e§")>>® ® w(€§-"’) ®g<n(e£">>) <3)
j=[l1uT][

We denote by H(A(")) the set of successful paths of AW and by R(") = R(A(")) the n—tape
relation of AW. It is the set of n—tuples of strings s(") having successful paths in AW:

R(A(")) = { s(") [ E|7r(") EH(A(")) /\ €(7r("))=s(") } (4)

The weight of any s(") E R(A(")) is the semiring sum of the weights of all paths labeled with
(n) :

5 w<s<">> = ® w<vr<">> <5)

71'('”) [ £(7'r('"r) ) =s('”)

3 Operations
Pairing and Concatenation: We deﬁne the pairing of two string tuples, s(") :v("‘) = u("+"‘), as
(31, . . . ,3”) : (v1,...,vm) =def (31, . ..,sn,v1,...,vm) (6)
w( (s1,...,sn) : (v1,...,vm)) =def w( (s1,...,sn))®w( (v1,...,vm)) (7)
The concatenation of two string tuples of equal arity, s(")v(") = u("), is deﬁned as
(31, . . . , sn)(v1, . . . ,vn) =def (31111, . . . , snvn) (8)

w( (s1,...,sn)(v1,...,vn)) =def w( (s1,...,sn) )®w( (v1,...,vn)) (9)

Projection and Complementary Projection: Projection, 79,-,;€,___(s(")), of a string tuple is
defined as 79,-,,,,___( (31, . . .,sn) ) Zdef (.3,-,.s,,, . . .) (10)

It retains only those strings (i.e., tapes) of the tuple that are speciﬁed by the indices j , k, . . . E
[[1, n][, and places them in the speciﬁed order. The weight of the tuple is not modiﬁed (if we

NLP Applications Based on Weighted Mu1ti—T ape Automata

consider it not as a member of a relation). The projection of an n—tape relation is the projection
of all its string tuples:

7>,-,;t,...(72<">) =def {W I 3s‘")eR‘")A7>j,k,...(s‘"))=v‘"”} (11)

The weight of each 110”) E 73,-,;€,___(R(")) is the semiring sum of the weights of each s(") E R(")
leading, when projected, to UV”):

w(v‘m>) =def EB w(s‘"’) <12)

30‘) [Pj,k,... (3("))=V('")

Complementary projection, R,-,k,___(s(")), removes those strings of the tuple s(") that are speciﬁed
by the indices j, k, . .. E [[1, It is deﬁned as

Pj,k,___( <81, . . . ,3n>) =def  . . ,8j_1, 8j_[_1, . . . , 8k_1, 8k_[_1, . .  
fj,k,...(R(n)) =def { “(W [ 33W ERW /\ fj,k,...(5(")) =”(m) } (14)
w(v‘"”) =def EB w(s‘"’) <15)

3(")|$j,Ie,...(3("))=V('")
Cross-Product: The cross—product of two n—tape relations is based on pairing and is deﬁned
as W W n m n W m m
R[)><R£) =def {s():v()|s()ER[),v()ERg)} (16)

Auto-Intersection: We deﬁne the auto—intersection of a relation, I“ (R(")), on the tapes j and
k as the subset of R(") that contains all s(") with equal sj and sk:

$j,k(73(")) =def {SW ERW I 3j = Sic} (17)

The weight of any s(") EI,-,k(R(")) is not modiﬁed. For example (Figure 1)
R?) = (we) <b,y, a>* <5, 2, b) = {<ab’“,acy’“z, a’“b> I keN} <18)
I1s(RE3)) = {<ab1,acy1z, a1b>} <19)

A(3)

(b) (0) a:x:e ® b:y:a @ e:z:b ®

Figure 1: (a) A WMTA A[3) and (b) its auto—intersection A(3) = I1,3(A[3)). (Weights omitted)

 

Single-Tape and Multi-Tape Intersection: Multi—tape intersection of two relations, R[") and

RS”) , uses 7' tapes in each relation, and intersects them pair—wise. We (re—)deﬁne it as
RE")  Rt“) =aef mi.,...,n+i. (I3-.,n+;c.( - - - Ij.,n+k.( RE") >< RS") > - - - > ) <20)
.7"r-‘y-I-91‘

The operation pairs each s(") E R[") with each 110") E R3") iff 33-1 = vkl until 33-, = vkr. We
speak about single—tape intersection if only one tape is used in each relation (r = 1). All tapes
k,- of RS”) that are used in the intersection are afterwards equal to the tapes _7',- of R("), and are
removed. The operation is conceptually similar to composition of two relations, except that the
tapes j,- are preserved and hence can be (re—)used in subsequent operations. The result is

R("+"‘_T) = { u("+"‘_T) | E|s(") E R[") /\ E|v("‘) €723") /\ 33-1. =vk1., Vi E [[1, r']]
/\ U("+m_T) :fW«+k71:---:"+k7'(3(n):v(m)) } (21)

w(u‘"+"”)) = w(s‘"))®w(v‘"”) <22)

Andre’ Kempe

Although single—tape and multi—tape intersection include complementary projection, Eq. 22 is
not in conﬂict with Eq. 15 because any two u("+"‘) = s("):v("‘) that differ in vki, differ also in
33-1. , and hence cannot become equal when the Uk, are removed.

Two well—known special cases are the intersection of two acceptors leading to an acceptor, and
the composition of two transducers leading to a transducer:

A§1)nA§1) = A§1)1n1Ag1> = f2(I1,2(A§1)xAg1))) (23)
A?) <>Ag2> = f2(A§2)p1Ag2)) = f2,3(I2,3(A§2)><A§2))) (24)

4 Applications

4.1 Preserving Intermediate Transduction Results

Transduction cascades are frequently used in language and speech processing. In a (classical)

weighted transduction cascade, Tlm . . . T52), a set of weighted input strings, encoded as a

) )

weighted acceptor, L0 , is composed with the ﬁrst transducer, T(2 , on its input tape (Figure 2).

The output projection of this composition is the ﬁrst intermediate result, LE1), of the cascade.

It is further composed with the second transducer, Tm, which leads to the second intermediate

result, Lu), etc. The output projection of the last transducer is the ﬁnal result, Lg) :

Lg” = 7>2( LE9, <> Ti“) ) for 2' e [[1, 7']] (25)
At any point in the cascade, previous results cannot be accessed.
(2) (2) (2)
T T T
L((1)) 1 Lq) 2 Lqjl I Lq)

D//W D//D
/ 

Figure 2: Weighted transduction cascade (classical)

In a weighted transduction cascade, Ag“) . . . AV’), that uses WMTAs and multi—tape inter-
section, intermediate results can be preserved and (re—)used by all subsequent transductions.

Suppose, we want to use the two previous results at each point in the cascade (except in the ﬁrst
(2)

transduction) which requires all intermediate results, Li , to have two tapes (Figure 3) :

L?’ = LSKQAE” (26)

L?) = 792,3(L§E)1 1n1A§3)) for re [[2,7'—1]] (27)
2:2

L5?) = 7>3( LE1 lnl AS”) (28)

2,2

This augmented descriptive power is also available if the whole cascade is intersected into a sin-
gle WMTA, Am (although Am has only two tapes in our example). Each of the “incorporated”
multi—tape sub—relations in Am (except the ﬁrst one) will still refer to its two predecessors:

AR = 7>1,n—1,n(AETf‘.%-1,f31A§3)) for 2'e[[2,r]],me{2,3} (29)

71,2

Am = P1,n( A1-..) (30)

NLP Applications Based on Weighted Mu1ti—T ape Automata

(2) Ag) (2) A(r3)
L1 Lr—1

/D/ D/

/rtapel /,tape2/'..... /rtapez

D /D / D 3 /D

tape 2 tape 3

(2)
A
L((1)) 1

Figure 3: Weighted transduction cascade using multi—tape intersection

4.2 Extracting Similar Words in French and Spanish

To extract, in general, from a relation RE") all string tuples s(") whose strings 33-1 to 33-, are
similar to its strings ski to skr, respectively, we can compare each pair of tapes, j,- and k,-,
independently from all other pairs. Hence the task can be reduced to comparing two tapes, j
and k. This can be done by means of a weighted 2—tape relation, 72(2), that describes the required
similarity between tape j and k of RE"):

72$") = 72$") n R? (31)

J31
k,2

For example, if we have an French—Spanish 3—tape lexicon, F7"Es(3), with entries of the form
3(3) = (French Word, Spanish Word, Pos Tag), and want to ﬁnd all words that are similar in
the two languages, we create a 2—tape automaton, Sm, describing this similarity. For that
we compile a WMTA G?) that encodes various synchronic consonant correspondences, G182)
and Gggn that describe alternations between sequences of vowels, and G512) that admits any
diacritization (insertion of accents, cedille, tilde, etc.) :

G?) = {bzv}U{ph:f}U{ch:c}U{qu:c}U  (32)
09> = A§}>+ >< A§}>+ with A9) = {a} u {e} u {1} u {0} u {u} u {y} (33)
e533, = AW‘ x A,(})* (34)
G512) = {a:?a}U{a:é}U  {e:é}U{e:é}U  {n:f’1}U{c:g}U  (35)

From these sub—relations we compile Sm describing the relation between any (hypothetical)
French word and its potential Spanish formzl

s<2> = ((053))-1u?,?)+o((Gg2>uG;2>u?,?)+G§,1,) <>(c;ff)u?,?)+ (36)

To extract similar words with equal meaning from F7"Es(3), we intersect it on the tapes of French

and Spanish with Sm: (3)

FrEs = FrEs(3> n 5(2) (37)
1,1

2,2
For better illustration, we explain this approach on a tiny example: a French—Spanish lexicon

containing only the four entries

sim

R(F7"Es(3)) = {(chanter, cantar, VB), (manger, comer, VB), (piquer, mangar, VB), (piquer, picar, VB)}

With the above approach (Eq. 37), we can extract a sub—lexicon of similar words with equal

meaning: (3)

R(F7"Es ) = {(chanter,cantar,VB),(piquer,picar,VB)}

sim

Classical composition cannot accomplish this task, even if we had only a 2—tape lexicon F7"Es(2).

1Here ? means any symbol, i.e., ? E {a,b,c,...}, and ‘.5 is an identity pairing such that (?'.,-?) E
{a:a,b:b,c:c,...},whereas (?:?)E{a:a.,a:b,b:a,...}.

Andre’ Kempe

F0‘ example of” 791(FrEs(2)) <> 5(2) <> 732(FrEs(2)) (38)

R(D)2)) = {(cha11ter, cantar), (manger, mangar), (piquer, picar)}

From a full—size French—Spanish lexicon with 45,578 entries, generated from lexical data from
ELRA, we extracted 5,624 similar entries, containing among others

(b1a.nche,b1a.nca, S) (cheval, caballo, S) (oeuvre, obra, S)
(brusque, brus co, ADJ) (grumeau, grumo, S) (ouvrier, obrero, S)
(approuver, aprobar, V) (nid, nido, S) (poire, pera, S)
(chaleur, calor, S) (noeud, nudo, S) (pont, puente, S)
(chanter, cantar, V) (oeil, oj o, S) (trois, tres, NUM)

5 Conclusion

We have described two practical applications of WMTAs and MTAs in NLP, demonstrating
their augmented descriptive power compared to 1—tape and 2—tape automata, namely the preser-
vation of intermediate results in transduction cascades and the search for similar words in two
languages. None of these tasks can be accomplished with 1—tape or 2—tape automata, in general.

We recalled some basic operations for WMTAs and MTAs and proposed some others such as
auto—intersection of one WMTA and multi—tape intersection of two WMTAs. In our approach,
multi—tape intersection is not an atomic operation but rather a sequence of more elementary
ones, which facilitates its implementation.

Acknowledgments I wish to thank Kenneth R. Beesley, .Iean—Marc Champarnaud,
Franck Guingne, and Florent Nicart for their help.

References

BEESLEY K. R. & KARTTUNEN L. (2003). Finite State Morphology. Palo Alto, CA, USA: CSLI
Publications.

EILENBERG S. (1974). Automata, Languages, and Machines, volume A. San Diego, CA, USA: Aca-
demic Press.

ELGOT C. C. & MEZEI J. E. (1965). On relations deﬁned by generalized ﬁnite automata. IBM Journal
of Research and Development, 9, 47-68.

KAPLAN R. M. & KAY M. (1981). Phonological rules and ﬁnite state transducers. In Winter Meeting
of the Linguistic Society ofAmerica, New York, NY, USA.

KAY M. (1987). Nonconcatenative ﬁnite—state morphology. In Proc. 3rd Int. Conf. EACL, p. 2-10.
KEMPE A., BAEIJS C., GAAL T., GUINGNE F. & NICART F. (2003). WFSC - A new weighted ﬁnite
state compiler. In 0. H. IBARRA & Z. DANG, Eds., Proc. 8th Int. Conf. CIAA, volume 2759 of Lecture
Notes in Computer Science, p. 108-119, Santa Barbara, CA, USA: Springer Verlag.

KIRAZ G. A. & GRIMLEY—EVANS E. (1998). Multi—tape automata for speech and language systems:
A prolog implementation. In D. WOODS & S. YU, Eds., Automata Implementation, number 1436 in
Lecture Notes in Computer Science. Springer Verlag.

KUICH W. & SALOMAA A. (1986). Semirings, Automata, Languages. Number 5 in EATCS Mono-
graphs on Theoretical Computer Science. Springer Verlag.

MOHRI M. (1997). Finite—state transducers in language and speech processing. Computational Linguis-
tics, 23(2), 269-312.

MOHRI M., PEREIRA F. C. N. & RILEY M. (1998). A rational design for a weighted ﬁnite—state
transducer library. Lecture Notes in Computer Science, 1436, 144-158.

