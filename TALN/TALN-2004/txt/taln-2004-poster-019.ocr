T ALN 2004, Session Poster, F és, I9-21 avril 2004

Résolution automatique d’anaphores inﬁdéles en francais :
Quelles ressources pour quels apports ?

Susanne Salmon-Alt

ATILF — CNRS (UMR 7118)
44, Avenue de la Liberation, B.P. 30687, 54063 Nancy Cedex
Susanne.Salmon-Alt@atilf.fr

Résumé — Abstract

La performance d’une résolution automatique d’anaphores inﬁdéles pour le francais pourrait
atteindre une F-mesure de 30%. Ce résultat repose toutefois sur une ressource équivalente a
un bon dictionnaire de la langue francaise, une analyse syntaxique de qualité satisfaisante et
un traitement performant des entités nommées. En l’absence de telles ressources, les meilleurs
résultats plafonnent autour d’une F-mesure de 15%.

A system for solving indirect anaphora in French seems to be able to achieve a F-measure of
30%. However, this result supposes a high quality lexical database (equivalent to a classical
dictionary), a good parser and a high precision named entity recognition. In case such
resources are not available, the best results are obtained by using simple heuristics and are
limited to a F-measure of 15%.

Mots Clés — Keywords
anaphore inﬁdéle, ressource sémantique, résolution d’anaphore, corpus annoté multiniveau

indirect anaphor, lexical database, anaphora resolution, multi-level corpus annotation

1 Problématique

Par anaphore << inﬁdéle », nous entendons, dans la lignée de la linguistique descriptive
francaise, un groupe nominal anaphorique (dont l’interprétation dépend d’une expression
nominale du contexte précédent) et coréférentiel (dont le référent est identique a celui de
l’antécédent), caractérisé par une téte nominale différente de celle de l’antécédent (le deﬁcit
en pluie — la sécheresse). Ces reprises partagent la coréférentialité avec d’autres types
d’anaphores (pronominales, nominales << ﬁdéles »), mais leur compréhension s’appuie sur des
connaissances sémantiques et pragmatiques au-dela des mécanismes mis en jeu lors de
l’interprétation des pronoms personnels et reprises directes. S’il a été montré pour différentes
langues (anglais, portugais, francais) que les défmis en anaphore inﬁdéle foumissent en
moyenne 25 a 50% des descriptions déﬁnies coréférentielles (Poesio et Vieira, 1998;

Susanne Salmon-Alt

Salmon-Alt et Vieira, 2002), au maximum un tiers parmi eux peuvent étre résolus (Poesio et
al., 2002), méme dans les meilleures conﬁgurations s’appuyant sur les ressources et outils a la
fois accessibles et correspondant a l’état de l’art anglo-saxon. L’objectif de ce travail est
d’éValuer les performances que l’on peut obtenir pour la résolution automatique des
anaphores inﬁdeles en comparant trois types des ressources sémantiques différentes.

2 Corpus detest

Les experiences ont été conduites sur un extrait du corpus Le Monde (~ 9000 mots, 276
phrases). En préparation l’annotation manuelle des anaphores, ce corpus a été étiqueté et
normalisé au niveau structurel, morphologique (Schmid, 1994) et syntaxique (Bick, 2003). Du
corpus résultant ont été extraits automatiquement les antécédents potentiels (tous les groupes
nominaux : 1924) et les anaphoriques potentiels (groupes nominaux défmies : 741).

Les 741 groupes nominaux déﬁnis restants ont été soumis, par l’intermédiaire d’un outil a
interface graphique (Miiller et Strube, 2001) a deux annotateurs pour l’annotation des
relations coréférentielles. Sur le total des défmis en entrée, respectivement 256 et 247 ont été
considérés comme coréférentiels. Ce taux (autour de 30%) est comparable a celui de travaux
antérieurs (Poesio et Vieira, 1998 ; Salmon-Alt et Vieira, 2002). En revanche, la répartition
entre reprises ﬁdeles VS. inﬁdeles Variait de 23 points entre les deux annotateurs. En raison de
cette disparité importante, nous avons décidé de retenir uniquement l’intersection des
descriptions défmies inﬁdeles, soit 78 descriptions défmies. Ce nombre, bien que ne
représentant plus 10,5% des 741 déﬁnis en entrée, constitue donc un noyau sﬁr de
descriptions déﬁnies a reprise coréférentielle inﬁdele : 85,9% se sont d’ailleurs Vu attribuer le
méme antécédent par les deux annotateurs. Le Tableau 1 propose une synthese des principales
caractéristiques des anaphores retenues : une part importante d’antécédents sous forme de
noms propres (plus d’un tiers), l’absence de régularité sur l’accord en nombre et genre entre
antécédent et reprise et une distance entre antécédent et anaphore Variant entre 0 et 27
phrases.

tete de 1’antecedent accord distance phrastique
annotateur . . .
nom commun nom propre autre nombre genre minimale maximale
Al 55,1 % (43) 37,2 % (29) 7,7 % (6) 57,7 % (45) 34,6 % (27) 0 17
A2 53,8 % (42) 39,7 % (31) 6,4 % (5) 57,7 % (45) 30,8 % (24) 0 27

Tableau 1 : Caractéristique des couples antécédent — anaphore infidéle

3 Ressources : Présentation et rendement en situation hors bruit

Ensuite, nous avons testé l’utilité de trois types de ressources lexicales pour la résolution
automatique des anaphores inﬁdeles en calculant le nombre de paires antécédent — anaphore
ﬁgurant dans au moins un des lexiques. Menée hors contexte applicatif (donc hors bruit),
cette experience nous a permis d’évaluer le plafond du rappel et de ﬁxer les Valeurs limites
des parametres en entrée du résolveur.

La premiere des ressources testées est une ressource acquise de facon automatique a partir
d’un corpus analysé syntaxiquement. Il s’agit d’une liste dite de << similarité sémantique »,
obtenue par des techniques basées sur des propriétés distributionnelles d’unités linguistiques
en corpus (Grefenstette, 1994 ; Gasperin et al., 2001). En appliquant cette méthode sur un
extrait de 90.000 mots du corpus Le Monde (comprenant les corpus de test), nous avons

Résolution automatique d ’anaph0res inﬁdéles en frangais

obtenu 572 entrees avec 3322 terrnes proches (moyenne de 5,8 par entree). Le deuxieme
lexique a été produit a partir du Euro WordNet francais dont nous avons extrait 7856 synsets
comprenant en moyenne 2,3 terrnes. La troisieme ressource est issue d’un dictionnaire
<< classique ». Il s’agit d’une liste des synonymes extraits manuellement du Grand Robert
donnant 32.484 entrees avec une moyenne de 4,7 synonymes par entree.

Le rendement de ces ressources a été testé sur les 78 paires antécédent-reprise. L’entrée
était fournie par les tétes non ﬂéchies de l’antécédent (TA) de la reprise (TR). Dans 11 cas, TR
était ambigu er1tre deux expressions, puisque les deux annotateurs avaient choisi des
antécédents différents, comme dans les peines reprenant, pour un annotateur, sa
condamnation a quatre ans de camp de travail et pour l’autre quatre ans de camp de travail,
avec T A 1 = condamnation, T A2 = an et TR = peine. Pour chaque paire (T A,T R) ainsi que les listes
de synonymes associés a la téte de l’antécédent STA et celle de l’anaphore STR, nous avons
considéré que la ressource aide a la resolution de l’anaphore si et seulement si : TA e STR ou
TR e STA ou TA e SR3TR.

Ressource SimLists WordNet Robert Cumul ressources
SimLists 2 0 3 5
WordNet 0 0 2 + 2

Robert 3 2 8 + 8
Total ressources 5 2 13 15
% (avec NP) 6,4 2,5 16,7 19,2
% (sans NP) 8,5 4,3 27,7 29,8

Tableau 2 : Rendement des ressources

Téte de l’antécédent Accord Distance hrastique
Ressource . . . . .
nom commun nom propre ad] ectlf nombre genre m1n1male maxlmale

SimLists 80 % 20 % 0 % 100 % 80 % 0 3

WordNet 100 % 0 % 0 % 100 % 50 % 0 3
Robert 92,3% 0 % 7,7 % 92,3 % 46,2 % 0 5

Tableau 3 : Caractéristiques des couples antécédent — anaphore infidéle présent dans les ressources

Les résultats, pour chacune des ressources isolées, les ressources croisées et les ressources
cumulées, sont domes dans le Tableau 2. Il apparait que l’ensemble des ressources ne
contient que 15 des paires recherchées, soit un rappel plafonné a l9,2% avec et a 29,8% sans
les antécédents sous forme de noms propres, l’apport de EuroWordNet étant entierement
neutralise par le Robert. En Vue de la déterrnination des parametres du calcul automatique,
nous avons analyse certaines propriétés linguistiques (accord en nombre et genre, distance
phrastique, nature de la téte de l’antécédent) des cas couverts (Tableau 3).

4 Rendement des ressources en résolution automatique

4.1 Stratégie etparamétres

Aﬁn d’éValuer l’apport des différentes ressources lexicales pour la resolution d’anaphores
nominales inﬁdeles en situation réelle (contrairement a une situation hors bruit telle que
supposée dans la section 3), nous avons implémenté un systeme de resolution automatique. Il
prend en entrée les descriptions déﬁnies classiﬁées comme anaphores inﬁdeles par les deux
annotateurs ainsi que des connaissances associées (identiﬁants de la phrase et de l’article

Susanne Salmon-Alt

<< hote », fonction syntaxique, téte du groupe syntaxique, déterminant, nombre, genre). La
stratégie de résolution consiste a chercher, pour chacune d’entre elles, un antécédent
correspondant a la premiere expression en amont remplissant un certain nombre de

contraintes, défmies en fonction des caractéristiques mises en lumiere dans le Tableau 3 :

L’irnposition d’un accord en genre er1tre antécédent et anaphore semble peu adéquate
(mois que 50% pour les paires trouvées dans le Robert). En contrepartie, l’effet d’un accord
en nombre AN pourrait s’aVérer intéressant pour augmenter la précision et fera l’objet de
Variation systématique. Dans tous les cas, la fenétre de recherche pour l’antécédent peut étre
limitée a cinq phrases en amont. Sachant par ailleurs que 93,3% des antécédents se trouvent a
une distance phrastique inférieure a quatre phrases et que seulement 6,6% se trouvent dans la
méme phrase, on fera Varier les contours de cette fenétre afm de trouver le meilleur rapport
entre rappel et précision : W,,,,,x= {S_5, S_3} ; W,,,,-,, = {S_g, S_1}. Enfm, la nature de la téte de
l’antécédent peut étre restreinte a un nom commun, un nom propre ou un adjectif. Toutefois,
les reprises de noms propres pourraient étre traitées plus avantageusement par des outils de
reconnaissance d’entités nommées, atteignant un taux de reconnaissance supérieur a 90%.
(Fourour, 2002). Au Vu de la quasi-absence de nom propres dans les ressources, ces cas
risquent fort de pénaliser la précision. Pour cette raison, nous ferons également Varier les
contraintes sur la nature de la téte de l’antécédent (T A = +/-nom propre).

Pour toutes les combinaisons de ces parametres, les sorties du systeme ont été évaluées
dans 4 conﬁgurations de ressources lexicales (RL) — absence de ressource (0), liste de
sirnilarité (S), Euro WordNet (WN), Robert (R) — par le calcul du rappel, de la précision et de
la F-mesure.

4.2 Résultats

Le point de comparaison pour évaluer l’utilité des ressources lexicales est l’application
des heuristiques sans prise en compte des lexiques. Nous avons donc retenu comme réponse
le premier groupe nominal remplissant toutes les contraintes spécifiées en 4.1. Le tableau 4
montre que les meilleurs résultats — 15% a 20% — s’obtiennent en imposant l’accord en
nombre. Par ailleurs, l’espace de recherche peut étre réduit aux trois phrases précédentes pour
un gain en temps de calcul.

L’apport des listes de similarité a été testé dans les mémes circonstances, en réduisant les
réponses aux groupes pour lesquels les tétes (T A,T R) remplissant les contraintes introduites
dans la section 3. Come le montre le Tableau 4, on constate, méme pour les meilleurs
résultats, une baisse de performance de plus de 10 points par rapport a la conﬁguration de
base. Cette baisse s’explique a la fois par un rappel inférieur (le systeme trouve moins de
bonnes réponses) et une précision inférieure (la part des fausses réponses augmente).
L’inclusion des anaphores ayant des noms propres comme antécédents creuse encore cet
écart. Si les résultats doivent étre interprétés prudemment en raison des faibles effectifs, ils
remettent tout de méme en question l’acquisition automatique de listes de similarité
sémantique pour la résolution anaphorique : en l’absence de ressources syntaxiques
disponibles et d’une taille largement supérieure a la taille des corpus utilisés ici, cette solution
présente un déséquilibre important er1tre efforts (preparation des corpus, annotation
syntaxique, transfert de formats, implementation des calculs de similarité) et effets (résultats
largement moins bons que sans ressources).

Les résultats des mémes experiences conduites sur la base de EuroWordNet
montrent qu’il n’y a pas de changement en ce qui conceme le taux de rappel tres bas. En
revanche, la F-mesure est légerement supérieure, et ceci en raison d’une précision élevée.

Résolution automatique d ’anaph0res inﬁdéles en ﬂangais

Notons toutefois que cette precision est essentiellement due a la couverture insufﬁsante de la
ressource. Le principal constat reste donc une perte de performance de 10 points par rapport
aux heuristiques sans ressources.

+ noms propres - noms propres
RL A” W'""" WW R | P | F R | P | F
non 0 5/3 0,077 0,106
0 non 1 5/3 0,090 0,106
oui 0 5/3 0,141 0,191
oui 1 5/3 0,141 0,149
non 0/1 5/3 0,013 0,033 0,019 0,021 0,063 0,032
oui 0 5 0,013 0,038 0,019 0,021 0,083 0,034
S oui 1 5 0,026 0,077 0,038 0,043 0,167 0,068
oui 0 3 0,013 0,048 0,020 0,021 0,091 0,034
oui 1 3 0,026 0,010 0,040 0,043 0,182 0,069
non 0 5/3 0,026 0,050 0,049 0,043 0,500 0,078
WN non 1 5/3 0,013 0,050 0,025 0,013 0,500 0,041
oui 0 5/3 0,026 0,666 0,049 0,043 0 ,666 0,080
oui 1 5/3 0,013 1,000 0,025 0,021 1,000 0,042
non 0 5 0,128 0,263 0,172 0,213 0,385 0,274
non 1 5 0,115 0,243 0,157 0,191 0,360 0,250
non 0 3 0,115 0,281 0,167 0,191 0,409 0,261
R non 1 3 0,103 0,258 0,147 0,170 0,381 0,235
oui 0 5 0,128 0,333 0,185 0,213 0,500 0,299
oui 1 5 0,115 0,310 0,168 0,191 0,474 0,273
oui 0 3 0,115 0,391 0,178 0,191 0,563 0,286
oui 1 3 0,103 0,364 0,160 0,170 0,533 0,258

Tableau 4 : F-mesure pour la résolution d’anaphores inﬁdéles selon différentes ressources lexicales

De facon peu surprenante, l’utilisation des synonymes du Robert permet d’obtenir des
résultats plus intéressants : dans la meilleure conﬁguration (accord en nombre, mais fenétre
de recherche large), l’amélioration par rapport a la stratégie de base Varie de 5 a 10 points.
Elle est essentiellement due a une meilleure precision (forte diminution des fausses réponses),
allant jusqu’a une bonne réponse sur deux. Par ailleurs, l’amélioration est plus irnportante
pour la Version excluant les noms propres ce qui est coherent puisque ce type d’information
n’y ﬁgure pas. Le taux de succes reste néanmoins intéressant pour la Version avec noms
propres (+ 4 points). C’est un point important car le ﬁltrage a priori des anaphores ayant des
noms propres comme antecedents demande des outils supplémentaires pour la reconnaissance
des entités nommées et n’est pas entierement automatisable.

La meilleure performance globale du systeme (F-mesure de 0.319) s’obtient par une
conﬁguration en cascade : utilisation du Robert (fenétre phrastique 0 a 5), puis des listes de
similarité (fenétre phrastique l a 3), puis des heuristiques de récence (fenétre phrastique 0 a
3), le tout en excluant les noms propres et en imposant un accord en genre. Ce résultat se
rapproche de ceux obtenus pour l’anglais par Poesio et al. (2002) en combinant un thesaurus
acquis sur grand corpus avec WordNet 1.6.

Susanne Salmon-Alt

5 Discussion

Au ﬁnal, seuls les synonymes extraits du Grand Robert, c’est-a-dire d’une ressource
lexicographique générale, concue par et pour des humains, apportent un gain de performance
signiﬁcatif pour la résolution automatique des anaphores inﬁdeles en francais. En l’absence
de ressources de qualité et couverture comparables, la meilleure stratégie reste encore la plus
simple : l’association du principe de récence a des contraintes morpho-syntaxiques
élémentaires permet d’obtenir une F-mesure de l’ordre de 0,15%. L’absence de publications
sur la méme tachel ne nous permet pas de confronter ce taux a d’autres experiences sur le
francais. Néamnoins, l’écart de seulement 8 points entre notre meilleur rappel (ressources en
cascade) et celui obtenu par Poesio et al. (2002) pour l’anglais peut étre considéré comme
encourageant. Toujours est-il que ce taux est pour l’instant largement insufﬁsant pour des
applications en grandeur réelle et souligne la distance a parcourir pour rendre Vraiment
opérationnels des travaux sur l’interprétation et la génération automatique d’expressions
référentielles, supposant en général l’existence de ressources sémantiques de bonne qualité
sur lesquelles Viennent se greffer des mécanismes d’inférence élaborés (Danlos, 1999 ;
Salmon-Alt, 2001). Ce constat devra donc encourager a explorer différentes pistes :
reconnaissance des entités nommées, prise en compte d’autres relations sémantiques, prise en
compte non seulement de la téte, mais des modiﬁeurs des groupes nominaux et integration
d’une analyse morphologique dérivationnelle.

Références

BICK E. (2003). A CG & PSG Hybrid Approach to Automatic Corpus Annotation. In: Kiril Simow & Petya
Osenova: Proc. of SProLaC2003, pp. 1-12. Corpus Linguistics 2003, Lancaster.

DANLOS L. (1999). Event Coreference between two sentences. Proc. of International Workshop on
Computational Semantics. Tildburg.

FOUROUR N. (2002). Némésis, un systeme de reconnaissance incrémentielle d’entités nommées pour le
francais. Actes TALN 2002, Nancy.

GASPERIN C., GAMALLO P., AGUSTINI A., LOPES G., LIMA V. (2001). Using syntactic contexts for
measuring word similarity. Proc. of the Workshop on Semantic Knowledge Acquisition and Categorisation.
ESSLLI 2001, Helsinki, Finland.

GREFENSTETTE G. (1994). Explorations in Automatic Thesaurus Discovery. Kluwer Academic Publishers,
USA.

MULLER C., STRUBE M. (2001). MMAX: A Tool for the Annotation of Multi—modal Corpora. Proc. of the
2nd IJCAI Workshop on Knowledge and Reasoning in Practical Dialogue Systems. Seattle, Wash., 45-50.
POESIO M., ISHIKAWA T., SCHULTE 1M WALDE S., VIEIRA R. (2002). Aquiring Lexical Knowledge for
Anaphora Resolution. Proc. of LRE C 2002. Las Palmas, Spain.

POESIO M., VIEIRA R. (1998). A corpus—based investigation of definite description use. Computational
Linguistics, 24, n° 2.

POPESCU-BELIS A. (1999). Modélisation multi-agent des échanges langagiers .' application au proble‘me
de la reference et son évaluation. These d'université, Université de Paris XI (Paris—Sud).

SALMON—ALT S. (2001). Reference Resolution within the Framework of Cognitive Grammar. Proc. of
International Colloquium on Cognitive Science. San Sebastian, Spain, May 2001.

SALMON—ALT S., VIEIRA R. (2002). Nominal expressions in multilingual corpora : deﬁnites and
demonstratives. Proc. of LREC 2002. Las Palmas, Spain.

SCHMID H. (1994). Probabilistic Part—of—Speech Tagging Using Decision Trees. In Proc. of International
Conference on New Methods in Language Processing. September 1994. Manchester, UK.

1 Le seul systéme de résolution d’anaphores nominales du francais évalué ﬁnement est celui de Popescu-Belis
(1999). Toutefois, il n’y a pas d’évaluation consacrée exclusivement aux reprises inﬁdéles.

