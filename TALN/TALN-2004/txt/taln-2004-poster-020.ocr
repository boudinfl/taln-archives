T ALN 2004, Session Poster, F és, I9-21 avril 2004

SibyMot : Modélisation stochastique du langage
intégrant la notion de chunks’

Igor Schadle, J ean-Yves Antoine, Brigitte Le Pévédic, Franck Poirier
Laboratoire VALORIA, Université de Bretagne Sud (EA 2593)
(igor.schadle@univ-ubs.fr)

Résumé — Abstract

Cet article présente le modéle de langage développé pour le systéme Sibylle, un systéme
d’aide a la communication pour les personnes handicapées. L’utilisation d’un modéle de
langage perrnet d’améliorer la pertinence des mots proposés en tenant compte du contexte
gauche de la saisie en cours. L’originalité de notre modéle se situe dans l’intégration de la
notion de chunks aﬁn d’élargir la taille du contexte pris en compte pour l’estirnation de la
probabilité d’apparition des mots.

We present in this article the language model of Sibyl, a new Alternative and Augmentative
Communication (AAC) system. The use of language modeling improves the relevance of
displayed words by taking into account the left context of the current sentence. The originality
of our model is to introduce chunking. This enlarges the context taken into account to estimate
the words probability.

Mots Clés — Keywords
Aide a la communication, modélisation stochastique du langage, n-gramme, chunks.

AAC, stochastic language modeling, n-gram, chunks.

1 Handicap et communication

On appelle systéme d’aide a la communication tout systéme visant a suppléer ou restaurer, ne
serait-ce que partiellement, la fonction de communication d’une personne handicapée. Dans le
cas d’un handicap physique lourd (troubles de la parole et facultés motrices réduites), les
modalités de communication sont limitées. Sur ordinateur, une solution consiste a composer
les messages a l’aide d’un clavier simulé (clavier présenté a l’écran) via une interface adaptée.
Lorsque l’interface d’accés n’autorise que l’équivalent du simple clic, comme le bouton
poussoir, la saisie sur clavier simulé est réalisée par un systéme de déﬁlement automatique.

1 Activités de recherche fmancées par le Conseil Régional de Bretagne

Schadle, Antoine, Le Pévédic, Poirier

Un curseur met en évidence les lettres une a une, a intervalle régulier, et l’utilisateur n’a plus
qu’a Valider lorsque le curseur pointe sur la lettre désirée. L’inconVénient majeur de ces aides
est l’eXtréme lenteur d’écriture. La ou la communication orale permet un débit de l’ordre de
150 mots a la minute, ces aides ne permettent qu’une écriture autour de 5 mots a la minute.
Pour accroitre cette Vitesse, le systeme Sibylle, développé au laboratoire VALORIA de
l’UniVersité de Bretagne Sud, propose deux aides complémentaires. La premiere, SibyLettre
est un systeme de prédiction de lettre qui permet une sélection plus rapide des lettres (Schadle
et al., 2001). La deuxieme, SibyMot, est un systeme de prédiction de mot. Le systeme afﬁche
une liste de mots, mots considérés comme les plus probables en fonction du contexte gauche
de la phrase. En sélectionnant les mots dans la liste, l’utilisateur évite leur saisie complete.
Comme d’autres systemes de communication issus de la recherche, HandiAS (Maurel, Le
Pévédic, 2001) ou VITIPI (Boissiere, 2000), le systeme Sibylle utilise un modele de langage
avancé pour établir une liste de mots pertinente. Ce modele est le sujet de ce present article.

2 Idées et principes

2.1 Modélisation n-gramme

Le point de départ de notre modele est le modele statistique n-gramme gramme utilisé dans le
cadre de la modélisation probabiliste du langage et issu de la théorie de l’information (J elinek,
1976). Dans l’objectif de prédire des mots, le probleme principal de ce modele est de ne tenir
compte que des demiers mots. De nombreuses Variations ont été proposées pour améliorer
l’utilisation de ce contexte. Cependant, malgré ces améliorations, le contexte reste a tres
courte distance, de l’ordre de deux a trois mots. Pour accroitre la taille du contexte et capter de
maniere plus efﬁcace les dépendances a plus longue distance, le modele présenté, et c’est son
originalité, propose d’intégrer la notion de chunks.

2.2 Analyse en chunks

L’analyse en chunks consiste a décomposer une phrase en syntagmes minimaux non récursifs.
Par rapport a l’analyse syntaxique, l’analyse en chunks se distingue par le fait qu’elle ne
cherche ni a donner les fonctions syntaxiques des syntagmes, ni a en établir les dépendances.
(Abney, 1991) a utilisé les chunks comme étape préliminaire a l’analyse syntaxique. Depuis,
la notion de chunks a largement été réutilisée en linguistique informatique : pour la
reconnaissance de la parole, l’analyse syntaxique, la compréhension de la parole, etc. Dans le
cadre de notre modele, nous utilisons les chunks pour l’estimation du mot a Venir. Ici, l’intérét
de cette analyse est de structurer le contexte gauche du mot a prédire. En particulier, avec les
tétes des chunks (leur mot principal), elle permet de mettre en avant des mots pertinents pour
la prédiction. Ainsi, au contexte des n-I demiers mots, nous associons un contexte des n-I
demieres tétes de chunks. Sur l’eXemple du début de phrase : << [I ’année*] [du dragon *] [a 
(commencé) », le contexte tri-gramme pour le mot << commencé » est << dragon a», tandis que
le contexte considérant les deux demieres tétes de chunks est << année dragon». Ce demier
fait apparaitre le mot << année », un bon prédicteur pour le mot << commencé ». Les chunks
permettent donc de capter des dépendances a plus longue distance que le modele n-gramme,
tout en restant dans le cadre de la modélisation robuste du langage.

SibyMot .' Modélisation stochastique du langage intégrant la notion de chunks

2.3 Les lemmes

Une autre des difﬁcultes du modele n-gramme est liee a l’espace des parametres a estimer. Si
Vest la taille du Vocabulaire, alors le nombre de parametres est de l’ordre de VN. Relativement
a l’anglais, ce probleme est accru en francais par sa richesse ﬂexionnelle. (Cerf Danon, El-
Beze, 1991) donnent un rapport formes ﬂechies/lemme de 2 en anglais contre 7 en francais.
Nous avons donc privilegie le lemme comme unite lexicale, la probabilite d’une forme ﬂechie
etant exprimee comme la probabilite combinee du lemme et de la ﬂexion.

3 Modélisation

Apres avoir expose les idees principales de notre modele, nous allons maintenant decrire de
maniere plus detaillee son fonctionnement. Pour permettre une prediction fondee sur les
chunks, SibyMot est compose de deux modules : un analyseur charge de construire une
representation de la phrase en chunks et un prédicteur qui delivre la probabilite d’apparition
des mots du lexique. Rappelons que dans le cadre de l’application Sibylle, le modele est
utilise en mot a mot. Les deux etapes analyse et prediction sont independantes et, en
particulier, l’analyseur peut étre utilise seul pour des taches d’etiquetage et de segmentation.

3.1 Partie analyse

En ce qui conceme l’analyseur, la segmentation d’un enonce en chunks correspond en TAL a
une analyse de surface (shallow parsing). Dans notre systeme, l’analyse est chargee de
determiner pour chaque mot son lemme et son etiquette grammaticale. De plus, au niveau du
chunk, elle delivre l’etiquette associee au chunk (sa categorie grammaticale) ainsi qu’une
ﬂexion qui correspond a celle de la téte. L’analyse en elle-meme est decomposee en deux
etapes : une etape d’etiquetage des mots puis une etape de segmentation (ﬁgure 1).

1’année du dragon a

Etiquetage
1’/1’/det année/année/nom du/du/pre dragon/dragon/nom a/avoir/aux

Segmentation

GN:fs[1’/1’/det/fs année/année/nom/fs]
GP:1ns[du/du/pre/ms dragon/dragon/nom/ms]
GV:3s-indpre[a/avoir/aux/3s-indpre

Figure 1 : Les etapes successives de l’analyseur

1) Etiquetage. Dans le cadre de la modelisation probabiliste, le processus d’etiquetage revient
a aligner une sequence de mots W = w1,...,wN et une autre de tags T = t1, ...,TN, et a rechercher
la sequence d’etiquettes T qui maximise la probabilite conditionnelle d’association. Dans
SibyMot, nous avons utilise le modele n-POS, avec n = 3. SibyMot travaillant sur les lemmes,
le modele n-POS a ete adapte pour estimer non plus la probabilite d’apparition d’un mot mais
celle d’un lemme. Par rapport au jeu d’etiquettes de l’action GRACE (Rajman et al., 1997),

Schadle, Antoine, Le Pévédic, Poirier

notre jeu d’étiquettes est plus réduit (une centaine d’étiquettes). En particulier, les étiquettes
ne contiennent pas d’informations ﬂexionnelles, ce qui facilite la tache de l’étiqueteur.
L’éValuation de l’analyseur a ainsi donné un taux de 97,9 % de mots correctement étiquetés
sur un extrait du journal Le Monde d’enViron 50 000 mots.

2) Segmentation. Pour réaliser la segmentation, nous proposons une solution originale qui
s’inspire du modele n-POS. Dans la modélisation adoptée, la phrase est Vue non plus comme
une séquence de mots, mais comme une sequence de chunks C = c1, ..., cN. Chaque chunk Cj
contient un ou plusieurs mots représentés par leur etiquette grammaticale. Par analogie au
modele n-POS, la liste des parties du discours est identiﬁée a la liste des différentes classes de
chunk (GN, GV, etc.) et l’ensemble des éléments d’une classe est constitué par les sequences
de tags appartenant a cette classe (par exemple, det_nom, det_nom_aah',  pour le groupe
nominal). La liste des sequences est donnée par une grammaire des chunks, qui contient plus
de 200 000 séquences et est créée de maniere automatique a partir d’une base de 200 regles
sous forme d’eXpressions régulieres. Pour la segmentation, l’éValuation a donné un taux de
93,9 % de taux de rappel sur le méme corpus que précédemment.

3.2 Partie prédiction

Au sortir de l’analyseur, nous disposons d’une segmentation de la phrase en chunks et d’un
étiquetage en classes grammaticales. Cette structure est ensuite utilisée par le module de
prédiction pour établir une probabilité des mots du lexique. Sans entrer dans les détails de la
réalisation (Schadle, 2003), le processus de prediction est réalisé en cinq étapes (ﬁgure 2).

1) Prédiction des chunks

l

2) Prédiction des relations
I
‘l’ ‘l’

3) Prédictiorli des lemmes 4) Prédictiorli des ﬂexions
\l/

5) Prédiction des mots

Figure 2 : Etapes de la prediction

1) Prediction des chunks. La premiere étape de la prédiction est chargée de foumir l’ensemble
des segmentations possibles pour le mot a Venir. Elle s’appuie sur la méme grammaire des
chunks que l’analyseur et donne une estimation de la probabilité de chacune d’elles. Les
segmentations produites foumissent les étiquettes grammaticales du mot et du chunk. Par
exemple, apres la sequence << GN[l’année] », cette étape determine les probabilités de
<< GN[l’année <adjectif cardinal> », << GN[l’année] GV[<Verbe conjugué> », etc.

2) Prediction des relations. L’objectif de cette étape est de mettre en relation le demier chunk
avec les n-I chunks précédents. Le but implicite est de capter les relations entre syntagmes.
Cette mise en relation est également probabilisée et utilise uniquement l’étiquette attribuée
aux chunks. Sur l’eXemple << GN[l’année] GP[du dragon] GV[a <participe passé> », une forte
probabilité sera ainsi attribuée a la relation entre le GV et le GN.

SibyMot .' Modélisation stochastique du langage intégrant la notion de chunks

3) Prediction des lemmes. A ce stade, la prediction dispose de toutes les inforrnations
nécessaires pour estimer les probabilités des lemmes. L’estimation combine une probabilité
tri-lemme (a l’image du n-gramme) et une probabilité fondée sur les tétes de chunks. C’est
cette demiere qui sur l’eXemple << GN[l’année] GP[du dragon] GV[a <participe passé> » et la
relation GV-GN, permet d’obtenir une forte probabilité pour << commence ».

4, 5) Parallelement a l’estimation des lemmes, l’étape de prediction des ﬂexions délivre une
estimation pour chaque ﬂexion. Grace aux relations établies en 2) un mécanisme d’accords
entre chunks est rendu possible. Au ﬁnal, a partir des estimations des lemmes et des ﬂexions,
ces probabilités sont combinées pour calculer la probabilité des mots du lexique de SibyMot.

4 Apprentissage

Pour l’acquisition des parametres du modele, le corpus d’apprentissage doit étre annoté. A
chaque mot doit correspondre son lemme, sa catégorie grammaticale, sa ﬂexion. Les phrases
doivent étre segrnentées et les segments mis en relation. Nous ne disposons malheureusement
pas d’un tel corpus, l’apprentissage a donc été réalisé sur un corpus non annoté manuellement.
Le corpus utilise contient pres de deux millions de mots (un mois du journal Le Monde). Pour
l’étiqueteur, l’apprentissage a été réalisé sur un étiquetage produit par l’analyseur Cordial.
L’acquisition des parametres des modules supérieurs a été obtenue par apprentissage non
supervise. Nous reviendrons sur cet apprentissage sous-optimal lors des résultats de
l’éValuation. Quant au lexique il est extrait de ceux de l’ABU et de Lexique (accessibles sur
l’intemet), enrichis des données d’apprentissage et contient plus de 50 000 lemmes.

5 Evaluation

L’éValuation adoptée est proche de celle proposée dans (Bimbot et al., 1997) qui permet de
comparer des modeles probabilistes a des modeles non probabilistes. Il s’agit d’une adaptation
du j eu de Shannon qui consiste a proposer a partir d’un contexte, une liste de mots candidats.
Chacun des mots candidats étant affecté d’un poids, la qualité du modele est évaluée a partir
de la moyenne géométrique des poids accordés a la solution correcte pour chaque contexte.
Notre métrique se rapproche de cette demiere et est plus adaptée a l’éValuation des systemes
d’aide a la communication. Apres chaque lettre tapée par l’utilisateur pour composer son
message, le systeme afﬁche une liste d’un certain nombre de mots (ici 5). Si le mot souhaité
apparait dans la liste, les lettres non tapées sont considérées comme économisées, sinon
l’utilisateur tape la lettre suivante et le systeme établit une nouvelle liste de propositions. On
mesure ainsi le nombre de lettres économisées par rapport au nombre de lettres du message.
Lors de cette evaluation nous avons compare notre systeme au modele n-gramme (ordres de 1
a 3). Le corpus d’apprentissage est le méme pour les différents modeles compares. Le corpus
de test contient 50 889 mots. Les résultats obtenus sont domes dans le tableau ci-dessous.

Modele 1- gramme 2- gramme 3- gramme SibyMot

% économisés 43,9 % 51,2 % 55,8 % 57,1 %

Tableau 1 : Evaluation comparée du modele SibyMot

Schadle, Antoine, Le Pévédic, Poirier

Les résultats montrent que notre modele obtient des performances supérieures a l’uni-gramme
(+ 13,2 %), au bi-gramme (+ 5,9 %) et au tri-gramme (+ 1,3 %). Cette demiere comparaison
montre que notre modele avec des connaissances syntaxiques obtient de meilleurs résultats
qu’un modele n-gramme simple. De plus, nous pensons que l’apprentissage a été réalisée de
maniere sous optimale et que le modele dispose ainsi d’une certaine marge de progression.

6 Conclusion

Nous avons présenté dans cet article les principes du modele de langage utilisé par le systeme
Sibylle. Dans le cadre de la modélisation probabiliste du langage, nous proposons d’améliorer
les capacités prédictives du modele n-gramme en captant des dépendances a plus longue
distance avec des chunks. Les résultats obtenus montrent ainsi que les capacités de notre
modele sont supérieures a celle du modele n-gramme. Ce modele appelé SibyMot est
actuellement intégré dans l’application Sibylle, un systeme d’aide a la communication pour
les personnes handicapées. Cette application est utilisée au CMRRF de Kerpape par des
Infirmes Moteurs Cérébraux. Le module SibyMot Va étre également commercialise dans un
autre systeme d’aide a la communication par la société Microvocal. Enﬁn, notons que le
modele SibyMot, dans sa partie analyseur, participe a la campagne d’éValuation EASY des
analyseurs syntaxiques du francais, dans le cadre de l’action Technolangue.

Références

ABNEY S. (1991), Parsing by chunks. In R. Berwick, S. Abney, and C. Tenny (Eds.), Principle
based parsing, Kluwer Academic.

BIMBOT F., EL-B1‘-ZZE M., JARDINO M. (1997), An alternative scheme for perplexity estimation.
Proc. of the International Conference on Acoustics, Speech and Signal Processing, Munich.

BOISSIERE P. (2000) VITIPI : Un systeme d’aide a l’écriture basé sur un principe d’auto-
apprentissage et adapté a tous les handicaps moteurs. Actes de Handicap ’00, pp 81-86, Paris.

CERF-DANON H., EL-B1‘-ZZE M. (1991), Three different probabilistic language models:
Comparison and combination. In Proceeding of ICASSP-91 , pp 297-300, Toronto, Canada.

JELINEK F. (1976), Continuous speech recognition by statistical models. Proc. of the IEEE.

MAUREL D., LE PEVEDIC B. (2001), The syntactic prediction with Token Automata:
Application to HandiAS system. Theoretical Computer Science, vol. 267, pp 121-129.

RAJMAN M., LECOMTE J ., PAROUBEK P. (1997), Format de description lexicale pour le
francais. Partie 2 : Description morpho-syntaxique, réf GRACE GT R-3-2.1.

SCHADLE 1., LE PEVEDIC B., ANTOINE J .—Y., POIRIER F. (2001), SibyLettre : prédiction de
lettre pour l’aide a la saisie de texte. Actes de TALN’200I, vol. 2, pp 233-242, Tours, France.

SCHADLE I. (2003), Sibylle: Systeme linguistique d’aide a la communication pour les
personnes handicapées. These de doctorat, Université de Bretagne Sud.

