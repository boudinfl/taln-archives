<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Mod&#232;le de langage s&#233;mantique pour la reconnaissance automatique de parole dans un contexte de traduction</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Mod&#232;le de langage s&#233;mantique pour la reconnaissance automatique de
parole dans un contexte de traduction
</p>
<p>Quang Vu-minh, Laurent Besacier, Herv&#233; Blanchon, Brigitte Bigi
</p>
<p>quang.vu-minh@imag.fr,laurent.besacier@imag.fr,
herve.blanchon@imag.fr,brigitte.bigi@imag.fr
</p>
<p>CLIPS-IMAG Lab. UJF, BP53, 38041 Grenoble cedex 9, France
</p>
<p>R&#233;sum&#233;-Abstract
</p>
<p>Le travail pr&#233;sent&#233; dans cet article a &#233;t&#233; r&#233;alis&#233; dans le cadre d'un projet global de traduction automatique de la
parole. L&#8217;approche de traduction est fond&#233;e sur un langage pivot ou Interchange Format (IF), qui repr&#233;sente le
sens de la phrase ind&#233;pendamment de la langue. Nous proposons une m&#233;thode qui int&#232;gre des informations
s&#233;mantiques dans le mod&#232;le statistique de langage du syst&#232;me de Reconnaissance Automatique de Parole. Le
principe consiste a utiliser certaines classes d&#233;finies dans l'IF comme des classes s&#233;mantiques dans le mod&#232;le
de langage. Ceci permet au syst&#232;me de reconnaissance de la parole d'analyser partiellement en IF les tours de
parole. Les exp&#233;rimentations realis&#233;es montrent qu&#8217;avec cette approche, le syst&#232;me de reconnaissance peut
analyser directement en IF  une partie des donn&#233;es de dialogues de notre application, sans faire appel au
syst&#232;me de traduction (35% des mots ; 58% des tours de parole), tout en maintenant le m&#234;me niveau de
performance du syst&#232;me global.
</p>
<p>This paper relates a methodology to include some semantic information early in the statistical language model
for Automatic Speech Recognition (ASR). This work is done in the framework of a global speech-to-speech
translation project. An Interchange Format (IF) based approach, representing the meaning of phrases
independently of languages, is adopted. The methodology consists in introducing semantic information by
using a class-based statistical language model for which classes directly correspond to IF entries. With this
new Language Model, the ASR module can analyze into IF part of dialogue data: 35% dialogue words; 58%
speaker turns, without degrading the overall system performance.
</p>
<p>Mots cl&#233;s-Key words
</p>
<p>Traduction de parole, mod&#232;les de langage, repr&#233;sentation pivot
Speech-to-speech translation, language modeling, interchange format
</p>
<p>1 Introduction
Dans un syst&#232;me de traduction ou compr&#233;hension automatique de parole,  le r&#244;le du module de reconnaissance
automatique de la parole (RAP) est d&#8217;obtenir une hypoth&#232;se textuelle &#224; partir du signal tandis que,
g&#233;n&#233;ralement, cette hypoth&#232;se est ensuite trait&#233;e s&#233;par&#233;ment par un autre module de compr&#233;hension ou
d&#8217;analyse qui transforme le texte en une repr&#233;sentation s&#233;mantique. Tous ces modules utilisent des ressources
linguistiques comme des dictionnaires, mod&#232;les de langage et/ou grammaires, mais ils sont souvent
ind&#233;pendants l&#8217;un de l&#8217;autre. Bien qu&#8217;il y ait quelques travaux (voir Vermobil [1] ou SLT [2])  qui proposent
une utilisation intelligente des ressources communes entre module de RAP et module  d&#8217;analyse, &#224; notre
connaissance, tr&#232;s peu de travaux exp&#233;rimentaux proposent d&#8217;introduire des informations s&#233;mantiques
directement dans un module de RAP pour une meilleure int&#233;gration du syst&#232;me complet.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Quang VU-MINH     Laurent BESACIER     Herve BLANCHON     Brigitte BIGI
</p>
<p>Cet article pr&#233;sente une m&#233;thode pour int&#233;grer des informations s&#233;mantiques dans le mod&#232;le de langage
statistique du syst&#232;me de reconnaissance. Ce travail a &#233;t&#233; r&#233;alis&#233; dans le cadre d&#8217;un projet global de traduction
de parole intitul&#233; NESPOLE1 [3]. Au sein du projet,  une approche de traduction fond&#233;e sur un langage pivot
(appel&#233; IF pour Interchange Format), qui repr&#233;sente le sens de la phrase ind&#233;pendamment de la langue, est
utilis&#233;e. L&#8217;architecture de ce syst&#232;me de traduction utilisant l&#8217;approche pivot est d&#233;crite dans la figure 1.
</p>
<p>texte langue source
</p>
<p>Reconnaissance de la parole
</p>
<p>G&#233;n&#233;ration
</p>
<p>texte langue cible
</p>
<p>Synth&#232;se de la parole
</p>
<p>site qui parle
</p>
<p>site qui entend
 la traduction
</p>
<p>texte pivot (IF)
Analyse vers pivot
</p>
<p>Figure 1: Interaction entre les modules de traduction de parole dans l&#8217;architecture IF.
</p>
<p>L&#8217;avantage le plus &#233;vident de l&#8217;approche par pivot est la r&#233;duction du nombre de modules &#224; r&#233;aliser. Si n
langues sont impliqu&#233;es, deux modules, d&#8217;analyse et de g&#233;n&#233;ration vers/depuis l&#8217;IF, pour chaque langue
permettent la traduction pour toutes les paires de langues possibles. Si une nouvelle langue vient s&#8217;ajouter au
projet, il suffit alors de d&#233;velopper les modules d&#8217;analyse et de g&#233;n&#233;ration vers/depuis l&#8217;IF pour cette langue
afin qu'elle puisse &#234;tre int&#233;gr&#233;e avec les n autres. Le d&#233;faut de cette approche r&#233;side dans la difficult&#233; &#224; d&#233;finir
le langage pivot, les concepts qui sont couverts, ainsi que sa syntaxe. Cela est vrai m&#234;me lorsque le domaine
est limit&#233; &#224; une t&#226;che particuli&#232;re comme l&#8217;information touristique.
</p>
<p>L'IF [4] est fond&#233; sur de actes de dialogue (DA) qui sont constitu&#233;s d'un acte de parole (SA) &#233;ventuellement
compl&#233;t&#233; par des concepts. L'acte de parole exprime ce que veut ou ce que fait celui qui parle. Les concepts
sont sub-divis&#233;s en attitudes, pr&#233;dicats principaux et participants du pr&#233;dicat. Ils expriment le focus
informationnel de ce qui est dit. Actes de parole et concepts peuvent admettre des arguments qui instancient
les variables du discours. Les arguments admis par les actes de parole et les concepts sont des arguments
sup&#233;rieurs (top-level arguments). Il existe aussi des arguments domin&#233;s (embedded arguments) qui raffinent
les arguments sup&#233;rieurs.
</p>
<p>Pour une phrase signifiant &quot;et je voudrais une chambre simple &#224; 100 euros &#224; Cavalese du 10 au 15 septembre&quot;
prononc&#233;e par un client, l'IF est par exemple (pour plus de d&#233;tails voir [4] :
</p>
<p>giveinformation+disposition+price+room(conjunction=discourse,disposition=(desire,
who=i),room-spec=(identifiability=no,single_room),
price=(quantity=100,currency=euro), location=name-cavalese,
time=(start-time=(md=10),end-time=(md=15, month=9)))
</p>
<p>Le travail pr&#233;sent&#233; ici se situe &#224; l&#8217;interface entre le module de reconnaissance et le module d&#8217;analyse en IF
(voir figure 1). Plus pr&#233;cis&#233;ment, le module de reconnaissance de la parole a &#233;t&#233; adapt&#233; afin d&#8217;&#234;tre capable de
d&#233;livrer une cha&#238;ne partiellement ou compl&#232;tement analys&#233;e en IF. Cela a &#233;t&#233; achev&#233; par l&#8217;usage d&#8217;un mod&#232;le
de langage utilisant des classes qui correspondent directement &#224; des concepts de l&#8217;IF. La m&#233;thodologie utilis&#233;e
pour obtenir ce mod&#232;le de langage &#171; s&#233;mantique &#187; est d&#233;taill&#233;e dans la section 2. La section 3 pr&#233;sente
quelques r&#233;sultats exp&#233;rimentaux obtenus tandis que la section 4 propose une premi&#232;re conclusion &#224; ce travail.
</p>
<p>                                                      
1 http://nespole.itc.it/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mod&#232;le de langage s&#233;mantique pour le RAP dans un contexte de traduction
</p>
<p>2 Construction du mod&#232;le de langage
Le mod&#232;le de langage statistique constitue un &#233;l&#233;ment important dans un syst&#232;me de Reconnaissance
Automatique de la Parole. Il a pour but de d&#233;finir une distribution  de probabilit&#233; sur des ensembles de
s&#233;quences de mots (suites de trois mots dans le cas du mod&#232;le trigramme). Pendant l&#8217;apprentissage du mod&#232;le,
certains mots peuvent &#234;tre regroup&#233;s en classes. Si on consid&#232;re que chaque mot, &#224; l&#8217;int&#233;rieur d&#8217;une classe, a
la m&#234;me probabilit&#233; d&#8217;occurence, dans ce cas une classe peut se r&#233;duire &#224; une liste de mots. Lorsqu&#8217;on a
d&#233;finit des classes, on peut alors directement remplacer les mots du corpus d&#8217;apprentissage par leur classe
avant l&#8217;apprentissage du mod&#232;le de langage.
</p>
<p>Afin d'introduire des connaissances s&#233;mantiques dans le ML, nous proposons de regrouper certains mots dans
des classes correspondant a des entit&#233;s s&#233;mantiques de l'IF. Par exemple, les mots &#171; bien &#187;, &#171; d'accord &#187; et &#171;
okay &#187; seront des &#233;l&#233;ments de la classe &#171; c:acknowledgment &#187; tel que le sp&#233;cifie l'IF. Plusieurs articles [5,6]
ont montr&#233; l&#8217;int&#233;r&#234;t de l&#8217;utilisation de classes dans diverses t&#226;ches de Traitement Automatique de Langue
Naturelle. La plupart des m&#233;thodes pour constituer automatiquement des classes utilisent des crit&#232;res
statistiques permettant, par exemple, de diminuer la perplexit&#233; d&#8217;un mod&#232;le de langage. Dans notre cas, notre
crit&#232;re de choix de classes est guid&#233; par la d&#233;finition du langage pivot et par les concepts les plus utilis&#233;s dans
l&#8217;IF. Notre approche consiste en deux &#233;tapes : (1) la s&#233;lection des IFs les plus fr&#233;quentes &#224; int&#233;grer comme
classes dans le nouveau mod&#232;le de langage (2) la calcul du mod&#232;le de langage proprement dit. Ces &#233;tapes
toutes automatiques sont d&#233;taill&#233;es dans le paragraphe suivant.
</p>
<p>2.1 S&#233;lection des classes-IF les plus fr&#233;quentes
Utiliser toutes les unit&#233;s s&#233;mantiques pr&#233;sentes dans la d&#233;finition de l&#8217;IF comme classes dans notre mod&#232;le de
langage conduirait &#224; un mod&#232;le inutilisable pour la reconnaissance automatique de la parole. En effet, le
nombre de classes doit &#234;tre limit&#233; et surtout, le nombre d&#8217;occurrences de mots d&#8217;une m&#234;me classe doit &#234;tre
suffisamment important pour que l&#8217;estimation des probabilit&#233;s soit de bonne qualit&#233;. Nous avons donc choisi
de nous limiter &#224; la s&#233;lection de classes-IF les plus fr&#233;quemment rencontr&#233;es dans les dialogues du projet
NESPOLE, correspondant &#224; la t&#226;che que nous voulons traiter. Dans cette &#233;tape, nous identifions donc ces IFs
les plus fr&#233;quentes et les regroupons dans des classes. Une classe correspond alors &#224; un ensemble de mots
conduisant &#224; une m&#234;me repr&#233;sentation IF (on trouve par exemple dans ces classes des actes de dialogue tels
que acknowledge, affirm, negate &#8230;). La figure 2 illustre comment cette s&#233;lection des IFs les plus fr&#233;quentes
est r&#233;alis&#233;e automatiquement &#224; partir d&#8217;un corpus textuel brut non annot&#233; manuellement en IF.
</p>
<p>Dialogues 
NESPOLE 
</p>
<p>d&#233;lissasses 1  
croquantes 42 
emm&#232;nerais 9 
emm&#232;nerait 
26 
badg&#233; 19 
badge 3439 
faillirent 52 
pentateuque 
309 
tablo&#239;de 17 
tablo&#239;ds 117 
attendriraient 
</p>
<p>Selection Ifs 
les plus freq. 
</p>
<p>Analyse auto. en IF 
</p>
<p>{c:affirm} oui, ouais, euh oui, &#8230; 
{c:acknowledge} okay, d&#8217;accord, &#8230; 
{c:thank} merci, merci beaucoup,  &#8230; 
&#8230; 
</p>
<p>Figure 2: S&#233;lection des IFs les plus fr&#233;quentes
</p>
<p>L&#8217;analyseur automatique en IF du CLIPS [7] a &#233;t&#233; utilis&#233; pour analyser un corpus qui comprend  46
transcriptions de dialogues collect&#233;s lors du projet NESPOLE [8]. Ce corpus repr&#233;sente des dialogues
possibles entre un client et un agent de voyage concernant l&#8217;organisation de vacances, la r&#233;servation d&#8217;h&#244;tels
et les activit&#233;s sportives ou culturelles, dans la r&#233;gion de Trente en Italie. L&#8217;analyseur transforme
automatiquement tous ces dialogues en une repr&#233;sentation de langage IF. Nous avons par cons&#233;quent un</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Quang VU-MINH     Laurent BESACIER     Herve BLANCHON     Brigitte BIGI
</p>
<p>corpus align&#233; fran&#231;ais-IF. Bien s&#251;r, ce corpus n&#8217;est pas parfait car l&#8217;analyseur fait &#233;ventuellement des erreurs,
mais nous supposons que, malgr&#233; ces erreurs, la distribution des diff&#233;rentes IFs est correctement repr&#233;sent&#233;e.
Ensuite, nous regroupons ces donn&#233;es align&#233;es par IF et listons toutes les unit&#233;s s&#233;mantiques de dialogue
correspondant &#224; une m&#234;me IF, et obtenons enfin nos classes &#171; s&#233;mantiques &#187; dont certaines sont pr&#233;sent&#233;es
dans la table 1. Par exemple, la classe la plus fr&#233;quente affirm contient les variantes repr&#233;sentant le m&#234;me sens
(affirmer) en fran&#231;ais.
</p>
<p>Le nombre de classes s&#233;mantiques obtenues de cette fa&#231;on &#233;tant important, nous avons retenu seulement 41
classes en tenant compte de la taille (le nombre de mots ou variantes dans une m&#234;me classe) et de la fr&#233;quence
d&#8217;apparition dans les dialogues des classes.
</p>
<p>CLASSES IFs
Variantes d&#8217;unit&#233;s s&#233;mantiques
</p>
<p>associ&#233;es
Pourcentage dans
</p>
<p>un total de 3194 unit&#233;s
{c:affirm} Oui, ouais, mouais&#8230; 22%
{c:acknowledge} d'accord, entendu, ok&#8230; 19%
{c:exclamation (exclamation=oh)} Oh, ah, ha&#8230;. 4%
</p>
<p>Table 1: Exemples de  classes IF obtenues automatiquement
</p>
<p>2.2 Calcul du mod&#232;le de langage
Apr&#232;s avoir obtenu la liste des classes s&#233;mantiques, comme illustr&#233; dans la figure 2, nous nous en servons en
combinaison avec les donn&#233;es de l&#8217;apprentissage du mod&#232;le de langage afin de construire notre nouveau
mod&#232;le &#171; s&#233;mantique &#187;. Ce processus est illustr&#233; dans la figure 3.
</p>
<p>Figure 3: M&#233;thode d&#8217;apprentissage du mod&#232;le de langage utilisant les classes issues de l&#8217;IF
</p>
<p>Dans le corpus d&#8217;apprentissage du ML qui comprend les transcriptions des 46 dialogues NESPOLE, nous
rempla&#231;ons tous les mots (ou s&#233;quences de mots) qui sont &#233;l&#233;ments de nos nouvelles classes s&#233;mantiques, par
le nom de la classe. Il en r&#233;sulte alors un corpus &#8220;pr&#233;par&#233;&#8221; qui contient &#224; la fois des mots fran&#231;ais et des IF.
Enfin, nous utilisons la bo&#238;te &#224; outils SRILM [9] pour apprendre le ML incluant les classes-IF, en utilisant la
methode Kneser-Ney pour le lissage. Apr&#232;s avoir obtenu le nouveau ML proprement construit, nous l&#8217;avons
int&#233;gr&#233; et test&#233; dans le syst&#232;me de reconnaissance. La section suivante pr&#233;sente quelques r&#233;sultats
exp&#233;rimentaux.
</p>
<p>Donn&#233;es
</p>
<p>apprentissage ML
</p>
<p>d&#233;lissa
sses 1
</p>
<p>croqua
ntes
42
</p>
<p>emm&#232;
i
</p>
<p>Liste d&#8217;IFs (&#233;tape
</p>
<p>Rempla
-cer
mots
par IF
</p>
<p>Il mordait en ce
moment de fort bon
app&#233; t i t  dans  un
morceau de pain.
</p>
<p>Il en arracha un peu de
mie pour faire une
boulette
</p>
<p>Corpus
Pr&#233;par&#233;
</p>
<p>Outils de
calcul du
</p>
<p>ML
</p>
<p>d&#233;lissa
sses 1
</p>
<p>croqua
ntes
42
</p>
<p>emm&#232;
nerais
9
</p>
<p>emm&#232;
nerait
</p>
<p>Mod&#232;le
langage
s&#233;manti</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mod&#232;le de langage s&#233;mantique pour le RAP dans un contexte de traduction
</p>
<p>3 R&#233;sultats exp&#233;rimentaux
</p>
<p>3.1 Description du syst&#232;me de RAP
Notre syst&#232;me RAPHAEL de reconnaissance de parole continue utilise la bo&#238;te &#224; outils Janus-III du CMU
[10]. Le mod&#232;le acoustique d&#233;pendant du contexte a &#233;t&#233; appris sur un corpus qui contient 12 heures de parole
continue prononc&#233;e par 72 locuteurs, issues de la base BREF80. Le vocabulaire contient approximativement
20000 formes lexicales parmi lesquelles quelques-unes sont sp&#233;cifiques au domaine de la r&#233;servation
touristique. Plus de d&#233;tail sur le syst&#232;me RAP du fran&#231;ais utilis&#233; dans NESPOLE se trouvent dans [3].
</p>
<p>Un test contradictoire a donc &#233;t&#233; conduit pour comparer un m&#234;me syst&#232;me de RAP utilisant d&#8217;une part
l&#8217;ancien mod&#232;le de langage, et d&#8217;autre part le nouveau mod&#232;le de langage &#171; s&#233;mantique &#187; obtenu par la
m&#233;thodologie pr&#233;sent&#233;e dans la section 2.
</p>
<p>3.2 Corpus de test
Les signaux de test sont 216 tours de parole extraits du corpus de dialogues du projet NESPOLE. La table 2
illustre quelques exemples de ces tours de parole de test. Dans la deuxi&#232;me colonne sont pr&#233;sent&#233;es les
hypoth&#232;ses textuelles obtenues  &#224; la sortie du module de RAP utilisant  notre mod&#232;le de langage s&#233;mantique.
Nous remarquons que des tours de parole simples sont d&#233;j&#224; compl&#232;tement analys&#233;s en IF. D&#8217;autres tours de
parole plus complexes sont, eux aussi, analys&#233;s partiellement ou compl&#232;tement en IF.
</p>
<p>Phrases de r&#233;f&#233;rence Sortie de RAP avec nouveau ML
oui je vous entends c:affirm c:dialog-hear(who=i, to-whom=you)
euh je vous entends pas tr&#232;s fort mais
c&#8217;est correct
</p>
<p>euh c:dialog-hear(who=i, to-whom=you) pas tr&#232;s forme ce_qu
on est
</p>
<p>oh oui c&#8217;est bon c:exclamation (exclamation=wow) c:affirm c:acknowledge
Oui c:affirm
d&#8217;accord c:acknowledge
</p>
<p>Table 2: Exemple d&#8217;hypoth&#232;ses obtenues &#224; la sortie du syst&#232;me de RAP avec notre nouveau ML s&#233;mantique
</p>
<p>3.3 Analyse des r&#233;sultats
</p>
<p>3.3.1 Comparaison de taux d&#8217;erreur
</p>
<p>Cette comparaison a pour seul but de v&#233;rifier que ces changements dans le mod&#232;le de langage, permettant une
analyse partielle en IF, ne d&#233;gradent pas la performance intrins&#232;que du syst&#232;me de reconnaissance initial. Pour
cela, nous avons compar&#233; le taux d&#8217;erreur du syst&#232;me initial avec celui de notre nouveau syst&#232;me. Le taux
d&#8217;erreur de mots (Word Error Rate -WER) du syst&#232;me initial qui utilise des classes construites manuellement
est de 31.9% alors que le taux d&#8217;erreur du syst&#232;me utilisant le nouveau mod&#232;le, apr&#232;s avoir reconstitu&#233; les
mots fran&#231;ais &#224; partir de la classe IF, est 32.9%. Ainsi, nous pouvons constater que le nouveau mod&#232;le
n&#8217;impose pas une d&#233;gradation tr&#232;s importante de la performance du syst&#232;me initial.
</p>
<p>3.3.2 Premi&#232;res statistiques sur l&#8217;analyse partielle en IF lors de la phase de reconnaissance
</p>
<p>Les 216 tours de parole de test comprennent 915 mots. Parmi ces 915 mots, 35% ont &#233;t&#233; analys&#233;s directement
en IF d&#232;s la phase de reconnaissance. Au niveau des tours de parole, 125 tours sur un total de 216 (58%) ont
&#233;t&#233; analys&#233;s directement en IF, aussi, d&#232;s la phase de reconnaissance. Bien s&#251;r, ce sont surtout les tours de
parole courts qui sont totalement analys&#233;s en IF, mais ce r&#233;sultat reste encourageant car, d&#233;sormais, une partie
du travail du module d&#8217;analyse peut &#234;tre r&#233;alis&#233; directement par l&#8217;usage d&#8217;un module de reconnaissance
utilisant un mod&#232;le de langage s&#233;mantique.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Quang VU-MINH     Laurent BESACIER     Herve BLANCHON     Brigitte BIGI
</p>
<p>Par ailleurs, sur les 58% de tours directement analys&#233;s, 84% sont proprement analys&#233;s sans erreur. Les 16%
d&#8217;erreur restant sur cette partie du corpus de test, correspondent essentiellement aux erreurs de reconnaissance
faites par le syst&#232;me, avec ou sans mod&#232;le s&#233;mantique, et qui ne seront jamais r&#233;cup&#233;r&#233;es par le module
d&#8217;analyse.
</p>
<p>4 Conclusion
Nous avons pr&#233;sent&#233; une nouvelle m&#233;thodologie pour introduire des classes s&#233;mantiques dans le mod&#232;le de
langage statistique d&#8217;un syst&#232;me de reconnaissance, dans un contexte de traduction de parole. Ce mod&#232;le
&#171; s&#233;mantique &#187; a &#233;t&#233; test&#233; dans le cadre du projet de traduction de parole NESPOLE. Avec notre nouveau
mod&#232;le de langage, le module de reconnaissance peut r&#233;aliser directement une partie du travail d&#8217;analyse vers
la repr&#233;sentation s&#233;mantique (IF) : 35% des mots du dialogue test ; 58% des tours de parole du dialogue test.
Parmi ces 58% tours analys&#233;s directement, 84% sont proprement analys&#233;s. Evidemment, la principale
limitation de notre approche est que ce sont majoritairement les tours de parole les plus courts, et donc les plus
faciles &#224; analyser, qui sont trait&#233;s d&#232;s la phase de reconnaissance. Par ailleurs, le module d&#8217;analyse devra &#234;tre
l&#233;g&#232;rement adapt&#233; afin de pouvoir traiter en entr&#233;e un m&#233;lange de mots fran&#231;ais et d&#8217;IF. N&#233;anmoins, cette
modification reste relativement facile &#224; impl&#233;menter.
</p>
<p>5 R&#233;f&#233;rences
[1] Wahlster, W. &#8220;Verbmobil : Foundations of Speech-to-Speech Translation&#8221;, Springer-Verlag. Berlin. 677
</p>
<p>p. (2000).
</p>
<p>[2] Rayner, M., Carter, D., Bouillon, P., Digalakis, V., Wir&#233;n, M., &#8220;Spoken Language Translation&#8221;
Cambridge University Press, (2000).
</p>
<p>[3] Besacier, L. &amp; al. &quot;Speech Translation for French in the NESPOLE! European Project&quot;, Eurospeech 2001,
Aalborg, Denmark, September (2001).
</p>
<p>[4] Levin L. &amp; al. &#8220;An Interlingua Based on Domain Actions for Machine Translation of Task-Oriented
Dialogues&#8221;. Proc. ICSLP'98, 30th November - 4th December 1998, Sydney, Australia, vol.4/7, pp.1155-
1158. (1998).
</p>
<p>[5] Brown, P.F., &amp; al. &#8220;Class-based n-gram Models of Natural Language&#8221;. Computational Linguistics 18(4):
467-479. (1992).
</p>
<p>[6] Kneser W., Ney, H., &#8220;Improved Clustering Techniques for class-based Statistical Language Modelling&#8221;.
In proceeding of the 3rd European Conference on Speech Communication and Technology, 973-976.
(1993).
</p>
<p>[7] Blanchon, H. (2002). &#8220;A Pattern-Based Analyzer for French in the Context of Spoken Language
Translation: First Prototype and Evaluation&#8221;. Proc. COLING. Taipei, Taiwan. Vol. 1/2: pp 92-98. 24
August - 1 September, (2002).
</p>
<p>[8] Burger, S. &amp; al &quot;The NESPOLE! VoIP Dialogue Database&quot;, Eurospeech 2001, Aalborg, Danemark,
September (2001).
</p>
<p>[9] Stolcke, A., &#8220;SRILM -- An Extensible Language Modeling Toolkit&#8221;. Proc. Intl. Conf. on Spoken
Language Processing, vol. 2, pp. 901-904, Denver, USA, (2002).
</p>
<p>[10] Zeppenfeld, T., &amp; al. &#8220;Recognition of conversational telephone speech using the Janus speech engine&#8221;
IEEE International Conference on Acoustics, Speech and Signal Processing, Munich, (1997).</p>

</div></div>
</body></html>