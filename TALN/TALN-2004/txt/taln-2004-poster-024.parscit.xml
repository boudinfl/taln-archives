<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>W Wahlster</author>
</authors>
<title>Verbmobil : Foundations of Speech-to-Speech Translation”,</title>
<date>2000</date>
<journal>Springer-Verlag. Berlin.</journal>
<volume>677</volume>
<pages>p.</pages>
<contexts>
<context position="2792" citStr="[1]" startWordPosition="395" endWordPosition="395">ction Dans un système de traduction ou compréhension automatique de parole, le rôle du module de reconnaissance automatique de la parole (RAP) est d’obtenir une hypothèse textuelle à partir du signal tandis que, généralement, cette hypothèse est ensuite traitée séparément par un autre module de compréhension ou d’analyse qui transforme le texte en une représentation sémantique. Tous ces modules utilisent des ressources linguistiques comme des dictionnaires, modèles de langage et/ou grammaires, mais ils sont souvent indépendants l’un de l’autre. Bien qu’il y ait quelques travaux (voir Vermobil [1] ou SLT [2]) qui proposent une utilisation intelligente des ressources communes entre module de RAP et module d’analyse, à notre connaissance, très peu de travaux expérimentaux proposent d’introduire des informations sémantiques directement dans un module de RAP pour une meilleure intégration du système complet. Quang VU-MINH Laurent BESACIER Herve BLANCHON Brigitte BIGI Cet article présente une méthode pour intégrer des informations sémantiques dans le modèle de langage statistique du système de reconnaissance. Ce travail a été réalisé dans le cadre d’un projet global de traduction de parole </context>
</contexts>
<marker>[1]</marker>
<rawString>Wahlster, W. “Verbmobil : Foundations of Speech-to-Speech Translation”, Springer-Verlag. Berlin. 677 p. (2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>D Carter</author>
<author>P Bouillon</author>
<author>V Digalakis</author>
<author>M Wirén</author>
</authors>
<title>Spoken Language Translation”</title>
<date>2000</date>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="2803" citStr="[2]" startWordPosition="398" endWordPosition="398">un système de traduction ou compréhension automatique de parole, le rôle du module de reconnaissance automatique de la parole (RAP) est d’obtenir une hypothèse textuelle à partir du signal tandis que, généralement, cette hypothèse est ensuite traitée séparément par un autre module de compréhension ou d’analyse qui transforme le texte en une représentation sémantique. Tous ces modules utilisent des ressources linguistiques comme des dictionnaires, modèles de langage et/ou grammaires, mais ils sont souvent indépendants l’un de l’autre. Bien qu’il y ait quelques travaux (voir Vermobil [1] ou SLT [2]) qui proposent une utilisation intelligente des ressources communes entre module de RAP et module d’analyse, à notre connaissance, très peu de travaux expérimentaux proposent d’introduire des informations sémantiques directement dans un module de RAP pour une meilleure intégration du système complet. Quang VU-MINH Laurent BESACIER Herve BLANCHON Brigitte BIGI Cet article présente une méthode pour intégrer des informations sémantiques dans le modèle de langage statistique du système de reconnaissance. Ce travail a été réalisé dans le cadre d’un projet global de traduction de parole intitulé NE</context>
</contexts>
<marker>[2]</marker>
<rawString>Rayner, M., Carter, D., Bouillon, P., Digalakis, V., Wirén, M., “Spoken Language Translation” Cambridge University Press, (2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Besacier</author>
<author>al</author>
</authors>
<title>Speech Translation for French in the NESPOLE! European Project&amp;quot;,</title>
<date>2001</date>
<location>Eurospeech</location>
<contexts>
<context position="3413" citStr="[3]" startWordPosition="485" endWordPosition="485">roposent une utilisation intelligente des ressources communes entre module de RAP et module d’analyse, à notre connaissance, très peu de travaux expérimentaux proposent d’introduire des informations sémantiques directement dans un module de RAP pour une meilleure intégration du système complet. Quang VU-MINH Laurent BESACIER Herve BLANCHON Brigitte BIGI Cet article présente une méthode pour intégrer des informations sémantiques dans le modèle de langage statistique du système de reconnaissance. Ce travail a été réalisé dans le cadre d’un projet global de traduction de parole intitulé NESPOLE1 [3]. Au sein du projet, une approche de traduction fondée sur un langage pivot (appelé IF pour Interchange Format), qui représente le sens de la phrase indépendamment de la langue, est utilisée. L’architecture de ce système de traduction utilisant l’approche pivot est décrite dans la figure 1. Reconnaissance de la parole texte langue source Analyse vers pivot site qui parle texte pivot (IF) site qui entend Génération la traduction texte langue cible Synthèse de la parole Figure 1: Interaction entre les modules de traduction de parole dans l’architecture IF. L’avantage le plus évident de l’approch</context>
<context position="13539" citStr="[3]" startWordPosition="2046" endWordPosition="2046"> un contexte de traduction 3 Résultats expérimentaux 3.1 Description du système de RAP Notre système RAPHAEL de reconnaissance de parole continue utilise la boîte à outils Janus-III du CMU [10]. Le modèle acoustique dépendant du contexte a été appris sur un corpus qui contient 12 heures de parole continue prononcée par 72 locuteurs, issues de la base BREF80. Le vocabulaire contient approximativement 20000 formes lexicales parmi lesquelles quelques-unes sont spécifiques au domaine de la réservation touristique. Plus de détail sur le système RAP du français utilisé dans NESPOLE se trouvent dans [3]. Un test contradictoire a donc été conduit pour comparer un même système de RAP utilisant d’une part l’ancien modèle de langage, et d’autre part le nouveau modèle de langage « sémantique » obtenu par la méthodologie présentée dans la section 2. 3.2 Corpus de test Les signaux de test sont 216 tours de parole extraits du corpus de dialogues du projet NESPOLE. La table 2 illustre quelques exemples de ces tours de parole de test. Dans la deuxième colonne sont présentées les hypothèses textuelles obtenues à la sortie du module de RAP utilisant notre modèle de langage sémantique. Nous remarquons qu</context>
</contexts>
<marker>[3]</marker>
<rawString>Besacier, L. &amp; al. &amp;quot;Speech Translation for French in the NESPOLE! European Project&amp;quot;, Eurospeech 2001, Aalborg, Denmark, September (2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Levin</author>
<author>al</author>
</authors>
<title>An Interlingua Based on Domain Actions for Machine Translation of Task-Oriented Dialogues”.</title>
<date>1998</date>
<booktitle>Proc. ICSLP&apos;98, 30th November - 4th</booktitle>
<volume>4</volume>
<pages>1155--1158</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="4711" citStr="[4]" startWordPosition="690" endWordPosition="690">x modules, d’analyse et de génération vers/depuis l’IF, pour chaque langue permettent la traduction pour toutes les paires de langues possibles. Si une nouvelle langue vient s’ajouter au projet, il suffit alors de développer les modules d’analyse et de génération vers/depuis l’IF pour cette langue afin qu&apos;elle puisse être intégrée avec les n autres. Le défaut de cette approche réside dans la difficulté à définir le langage pivot, les concepts qui sont couverts, ainsi que sa syntaxe. Cela est vrai même lorsque le domaine est limité à une tâche particulière comme l’information touristique. L&apos;IF [4] est fondé sur de actes de dialogue (DA) qui sont constitués d&apos;un acte de parole (SA) éventuellement complété par des concepts. L&apos;acte de parole exprime ce que veut ou ce que fait celui qui parle. Les concepts sont sub-divisés en attitudes, prédicats principaux et participants du prédicat. Ils expriment le focus informationnel de ce qui est dit. Actes de parole et concepts peuvent admettre des arguments qui instancient les variables du discours. Les arguments admis par les actes de parole et les concepts sont des arguments supérieurs (top-level arguments). Il existe aussi des arguments dominés</context>
</contexts>
<marker>[4]</marker>
<rawString>Levin L. &amp; al. “An Interlingua Based on Domain Actions for Machine Translation of Task-Oriented Dialogues”. Proc. ICSLP&apos;98, 30th November - 4th December 1998, Sydney, Australia, vol.4/7, pp.1155-1158. (1998).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>al</author>
</authors>
<title>Class-based n-gram Models of Natural Language”.</title>
<date>1992</date>
<journal>Computational Linguistics</journal>
<volume>18</volume>
<issue>4</issue>
<pages>467--479</pages>
<contexts>
<context position="7604" citStr="[5,6]" startWordPosition="1122" endWordPosition="1122">ur d’une classe, a la même probabilité d’occurence, dans ce cas une classe peut se réduire à une liste de mots. Lorsqu’on a définit des classes, on peut alors directement remplacer les mots du corpus d’apprentissage par leur classe avant l’apprentissage du modèle de langage. Afin d&apos;introduire des connaissances sémantiques dans le ML, nous proposons de regrouper certains mots dans des classes correspondant a des entités sémantiques de l&apos;IF. Par exemple, les mots « bien », « d&apos;accord » et « okay » seront des éléments de la classe « c:acknowledgment » tel que le spécifie l&apos;IF. Plusieurs articles [5,6] ont montré l’intérêt de l’utilisation de classes dans diverses tâches de Traitement Automatique de Langue Naturelle. La plupart des méthodes pour constituer automatiquement des classes utilisent des critères statistiques permettant, par exemple, de diminuer la perplexité d’un modèle de langage. Dans notre cas, notre critère de choix de classes est guidé par la définition du langage pivot et par les concepts les plus utilisés dans l’IF. Notre approche consiste en deux étapes : (1) la sélection des IFs les plus fréquentes à intégrer comme classes dans le nouveau modèle de langage (2) la calcul </context>
</contexts>
<marker>[5]</marker>
<rawString>Brown, P.F., &amp; al. “Class-based n-gram Models of Natural Language”. Computational Linguistics 18(4): 467-479. (1992).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Kneser</author>
<author>H Ney</author>
</authors>
<title>Improved Clustering Techniques for class-based Statistical Language Modelling”.</title>
<date>1993</date>
<booktitle>In proceeding of the 3rd European Conference on Speech Communication and Technology,</booktitle>
<pages>973--976</pages>
<contexts>
<context position="7604" citStr="[5,6]" startWordPosition="1122" endWordPosition="1122">ur d’une classe, a la même probabilité d’occurence, dans ce cas une classe peut se réduire à une liste de mots. Lorsqu’on a définit des classes, on peut alors directement remplacer les mots du corpus d’apprentissage par leur classe avant l’apprentissage du modèle de langage. Afin d&apos;introduire des connaissances sémantiques dans le ML, nous proposons de regrouper certains mots dans des classes correspondant a des entités sémantiques de l&apos;IF. Par exemple, les mots « bien », « d&apos;accord » et « okay » seront des éléments de la classe « c:acknowledgment » tel que le spécifie l&apos;IF. Plusieurs articles [5,6] ont montré l’intérêt de l’utilisation de classes dans diverses tâches de Traitement Automatique de Langue Naturelle. La plupart des méthodes pour constituer automatiquement des classes utilisent des critères statistiques permettant, par exemple, de diminuer la perplexité d’un modèle de langage. Dans notre cas, notre critère de choix de classes est guidé par la définition du langage pivot et par les concepts les plus utilisés dans l’IF. Notre approche consiste en deux étapes : (1) la sélection des IFs les plus fréquentes à intégrer comme classes dans le nouveau modèle de langage (2) la calcul </context>
</contexts>
<marker>[6]</marker>
<rawString>Kneser W., Ney, H., “Improved Clustering Techniques for class-based Statistical Language Modelling”. In proceeding of the 3rd European Conference on Speech Communication and Technology, 973-976. (1993).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Blanchon</author>
</authors>
<title>A Pattern-Based Analyzer for French in the Context of Spoken Language Translation: First Prototype and Evaluation”.</title>
<date>2002</date>
<booktitle>Proc. COLING.</booktitle>
<volume>1</volume>
<pages>92--98</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="9844" citStr="[7]" startWordPosition="1468" endWordPosition="1468"> affirm, negate ...). La figure 2 illustre comment cette sélection des IFs les plus fréquentes est réalisée automatiquement à partir d’un corpus textuel brut non annoté manuellement en IF. délissasses 1 croquantes 42 Dialogues Analyse auto. en IF emmènerais 9 emmènerait 26 NESPOLE Selecbadgté i19o badge 3439 n Ifs faillirent 52 pentateuque les p3l09u tabloïdes 17 freq. tabloïds 117 attendriraient {c:affirm} oui, ouais, euh oui, ... {c:acknowledge} okay, d’accord, ... {c:thank} merci, merci beaucoup, ... ... Figure 2: Sélection des IFs les plus fréquentes L’analyseur automatique en IF du CLIPS [7] a été utilisé pour analyser un corpus qui comprend 46 transcriptions de dialogues collectés lors du projet NESPOLE [8]. Ce corpus représente des dialogues possibles entre un client et un agent de voyage concernant l’organisation de vacances, la réservation d’hôtels et les activités sportives ou culturelles, dans la région de Trente en Italie. L’analyseur transforme automatiquement tous ces dialogues en une représentation de langage IF. Nous avons par conséquent un Quang VU-MINH Laurent BESACIER Herve BLANCHON Brigitte BIGI corpus aligné français-IF. Bien sûr, ce corpus n’est pas parfait car l</context>
</contexts>
<marker>[7]</marker>
<rawString>Blanchon, H. (2002). “A Pattern-Based Analyzer for French in the Context of Spoken Language Translation: First Prototype and Evaluation”. Proc. COLING. Taipei, Taiwan. Vol. 1/2: pp 92-98. 24 August - 1 September, (2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Burger</author>
</authors>
<title>al &amp;quot;The NESPOLE! VoIP Dialogue Database&amp;quot;,</title>
<date>2001</date>
<location>Eurospeech</location>
<contexts>
<context position="9963" citStr="[8]" startWordPosition="1487" endWordPosition="1487">ment à partir d’un corpus textuel brut non annoté manuellement en IF. délissasses 1 croquantes 42 Dialogues Analyse auto. en IF emmènerais 9 emmènerait 26 NESPOLE Selecbadgté i19o badge 3439 n Ifs faillirent 52 pentateuque les p3l09u tabloïdes 17 freq. tabloïds 117 attendriraient {c:affirm} oui, ouais, euh oui, ... {c:acknowledge} okay, d’accord, ... {c:thank} merci, merci beaucoup, ... ... Figure 2: Sélection des IFs les plus fréquentes L’analyseur automatique en IF du CLIPS [7] a été utilisé pour analyser un corpus qui comprend 46 transcriptions de dialogues collectés lors du projet NESPOLE [8]. Ce corpus représente des dialogues possibles entre un client et un agent de voyage concernant l’organisation de vacances, la réservation d’hôtels et les activités sportives ou culturelles, dans la région de Trente en Italie. L’analyseur transforme automatiquement tous ces dialogues en une représentation de langage IF. Nous avons par conséquent un Quang VU-MINH Laurent BESACIER Herve BLANCHON Brigitte BIGI corpus aligné français-IF. Bien sûr, ce corpus n’est pas parfait car l’analyseur fait éventuellement des erreurs, mais nous supposons que, malgré ces erreurs, la distribution des différente</context>
</contexts>
<marker>[8]</marker>
<rawString>Burger, S. &amp; al &amp;quot;The NESPOLE! VoIP Dialogue Database&amp;quot;, Eurospeech 2001, Aalborg, Danemark, September (2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM -- An Extensible Language Modeling Toolkit”.</title>
<date>2002</date>
<booktitle>Proc. Intl. Conf. on Spoken Language Processing,</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<location>Denver, USA,</location>
<contexts>
<context position="12609" citStr="[9]" startWordPosition="1906" endWordPosition="1906">ire une apprentissage ML par IF boulette délissa sses 1 Outils de Modcroèquantes le 42 calcul du langage emmè ML sémanernais9 ti emmè nerait Figure 3: Méthode d’apprentissage du modèle de langage utilisant les classes issues de l’IF Dans le corpus d’apprentissage du ML qui comprend les transcriptions des 46 dialogues NESPOLE, nous remplaçons tous les mots (ou séquences de mots) qui sont éléments de nos nouvelles classes sémantiques, par le nom de la classe. Il en résulte alors un corpus “préparé” qui contient à la fois des mots français et des IF. Enfin, nous utilisons la boîte à outils SRILM [9] pour apprendre le ML incluant les classes-IF, en utilisant la methode Kneser-Ney pour le lissage. Après avoir obtenu le nouveau ML proprement construit, nous l’avons intégré et testé dans le système de reconnaissance. La section suivante présente quelques résultats expérimentaux. Modèle de langage sémantique pour le RAP dans un contexte de traduction 3 Résultats expérimentaux 3.1 Description du système de RAP Notre système RAPHAEL de reconnaissance de parole continue utilise la boîte à outils Janus-III du CMU [10]. Le modèle acoustique dépendant du contexte a été appris sur un corpus qui cont</context>
</contexts>
<marker>[9]</marker>
<rawString>Stolcke, A., “SRILM -- An Extensible Language Modeling Toolkit”. Proc. Intl. Conf. on Spoken Language Processing, vol. 2, pp. 901-904, Denver, USA, (2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Zeppenfeld</author>
<author>al</author>
</authors>
<title>Recognition of conversational telephone speech using the Janus speech engine”</title>
<date>1997</date>
<booktitle>IEEE International Conference on Acoustics, Speech and Signal Processing,</booktitle>
<location>Munich,</location>
<contexts>
<context position="13129" citStr="[10]" startWordPosition="1984" endWordPosition="1984"> fois des mots français et des IF. Enfin, nous utilisons la boîte à outils SRILM [9] pour apprendre le ML incluant les classes-IF, en utilisant la methode Kneser-Ney pour le lissage. Après avoir obtenu le nouveau ML proprement construit, nous l’avons intégré et testé dans le système de reconnaissance. La section suivante présente quelques résultats expérimentaux. Modèle de langage sémantique pour le RAP dans un contexte de traduction 3 Résultats expérimentaux 3.1 Description du système de RAP Notre système RAPHAEL de reconnaissance de parole continue utilise la boîte à outils Janus-III du CMU [10]. Le modèle acoustique dépendant du contexte a été appris sur un corpus qui contient 12 heures de parole continue prononcée par 72 locuteurs, issues de la base BREF80. Le vocabulaire contient approximativement 20000 formes lexicales parmi lesquelles quelques-unes sont spécifiques au domaine de la réservation touristique. Plus de détail sur le système RAP du français utilisé dans NESPOLE se trouvent dans [3]. Un test contradictoire a donc été conduit pour comparer un même système de RAP utilisant d’une part l’ancien modèle de langage, et d’autre part le nouveau modèle de langage « sémantique » </context>
</contexts>
<marker>[10]</marker>
<rawString>Zeppenfeld, T., &amp; al. “Recognition of conversational telephone speech using the Janus speech engine” IEEE International Conference on Acoustics, Speech and Signal Processing, Munich, (1997).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>