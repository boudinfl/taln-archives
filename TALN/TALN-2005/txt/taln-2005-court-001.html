<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Induction de r&#232;gles de correction pour l'&#233;tiquetage morphosyntaxique de la litt&#233;rature de biologie en utilisant l'apprentissage actif</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2005, Dourdan, 6-10 juin 2005 
</p>
<p>Induction de r&#232;gles de correction pour l&#8217;&#233;tiquetage 
morphosyntaxique de la litt&#233;rature de biologie en utilisant 
</p>
<p>l&#8217;apprentissage actif 
</p>
<p>Ahmed Amrani (1), Yves Kodratoff (2) et Oriane Matte-Tailliez (2) 
</p>
<p>(1) ESIEA Recherche, 9 rue V&#233;sale, 75005 Paris, France.                
amrani@esiea.fr                                                                                         
</p>
<p>(2) LRI, UMR CNRS 8623, B&#226;t. 490, Universit&#233; Paris 11,  91405 Orsay.                                                                         
{yk, oriane}@lri 
</p>
<p>Mots-cl&#233;s : Etiquetage morphosyntaxique, Apprentissage de r&#232;gles, Apprentissage actif, 
fouille de textes. 
Keywords: Part-of-speech tagging, rule learning, active learning, text-mining. 
</p>
<p>R&#233;sum&#233; Dans le contexte de l&#8217;&#233;tiquetage morphosyntaxique des corpus de sp&#233;cialit&#233;, nous 
proposons une approche inductive pour r&#233;duire les erreurs les plus difficiles et qui persistent 
apr&#232;s &#233;tiquetage par le syst&#232;me de Brill. Nous avons appliqu&#233; notre syst&#232;me sur deux types de 
confusions. La premi&#232;re confusion concerne un mot qui peut avoir les &#233;tiquettes &#8216;verbe au 
participe pass&#233;&#8217;, &#8216;verbe au pass&#233;&#8217; ou &#8216;adjectif&#8217;. La deuxi&#232;me confusion se produit entre un 
nom commun au pluriel et un verbe au pr&#233;sent, &#224; la 3&#0;&#1; &#2; personne du singulier. A l&#8217;aide 
d&#8217;interface conviviale, l&#8217;expert corrige l&#8217;&#233;tiquette du mot ambigu. A partir des exemples 
annot&#233;s, nous induisons des r&#232;gles de correction. Afin de r&#233;duire le co&#251;t d&#8217;annotation, nous 
avons utilis&#233; l&#8217;apprentissage actif. La validation exp&#233;rimentale a montr&#233; une am&#233;lioration de 
la pr&#233;cision de l&#8217;&#233;tiquetage. De plus, &#224; partir de l&#8217;annotation du tiers du nombre d&#8217;exemples, 
le niveau de pr&#233;cision r&#233;alis&#233; est &#233;quivalent &#224; celui obtenu en annotant tous les exemples.  
</p>
<p>Abstract In the context of Part-of-Speech (PoS)-tagging of specialized corpora, we 
proposed an approach focusing on the most &#8216;important&#8217; PoS-tags because mistaking them can 
lead to a total misunderstanding of the text. After tagging a biological corpus by Brill&#8217;s tagger, 
we noted persistent errors that are very hard to deal with. As an application, we studied two 
cases of different nature: first, confusion between past participle, adjective and preterit; 
second, confusion between plural nouns and verbs, 3&#3;&#4; person singular present. With a friendly 
user interface, the expert corrected the examples. Then, from these well-annotated examples, 
we induced rules. In order to reduce the cost of annotation, we used active learning. The 
experimental validation showed improvement in tagging precision and that on the basis of the 
annotation of one third of the examples we obtain a level of precision equivalent to the one 
reached by annotating all the examples. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Amrani A, Kodratoff Y et Matte-Tailliez O 
</p>
<p>1 Introduction 
L&#8217;&#233;tiquetage morphosyntaxique est une &#233;tape importante pour la t&#226;che d&#8217;extraction 
d&#8217;informations &#224; partir de textes bruts et sp&#233;cialis&#233;s. Cette &#233;tape consiste &#224; associer &#224; chaque 
mot son &#233;tiquette grammaticale en fonction de sa morphologie et de son contexte. Les 
&#233;tiqueteurs morphosyntaxiques actuels atteignent des performances tr&#232;s satisfaisantes en 
pr&#233;cision (plus de 95%) (Paroubek, Rajman, 2000). Ces bons r&#233;sultats s&#8217;expliquent par le fait 
que les travaux en question se situent dans le domaine de l&#8217;apprentissage supervis&#233; o&#249; le 
corpus de test est de m&#234;me nature que le corpus d&#8217;apprentissage. Un pr&#233;-requis pour la 
construction d&#8217;un &#233;tiqueteur est la disponibilit&#233; d&#8217;un corpus annot&#233; de taille importante. 
L&#8217;acquisition d&#8217;un tel corpus est co&#251;teuse. D&#8217;autre part, les syst&#232;mes d&#8217;&#233;tiquetage ont tous des 
difficult&#233;s sur les cas difficiles. Les d&#233;cisions sont le plus souvent fond&#233;es sur l&#8217;examen des 
contextes locaux (tels que les trigrammes de mots), qui r&#233;solvent mal les cas qui 
demanderaient une analyse plus globale et approfondie (Valli, Veronis, 1999). 
Il existe deux approches principales pour l&#8217;apprentissage de r&#232;gles : la cr&#233;ation de r&#232;gles &#224; 
partir d&#8217;arbres de d&#233;cision (Quinlan, 1993) et la technique d&#8217;apprentissage directe de r&#232;gles 
comme dans l&#8217;algorithme RIPPER (Cohen, 1995). L&#8217;algorithme d&#8217;apprentissage de r&#232;gles 
propositionnelles, PART (Frank, Witten, 1998), combine les deux approches pr&#233;c&#233;dentes. 
Chaque r&#232;gle induite par PART a la forme d&#8217;une conjonction de conditions : Si T&#0; et T&#1; et ... 
T&#2; alors la classe est C&#3; . (Si T&#0; et T&#1; et ... T&#2;) est appel&#233; le corps de la r&#232;gle et (Cx) est la classe 
cible &#224; apprendre. Chaque condition T&#4; teste une valeur particuli&#232;re d&#8217;un attribut. La condition 
a la forme suivante : A&#4; = v, o&#249; A&#4; est un attribut symbolique et v est une valeur possible de A&#4;. 
L&#8217;apprentissage actif est une technique qui permet de r&#233;duire le nombre d&#8217;exemples &#224; annoter. 
Cette technique consiste &#224; s&#233;lectionner les exemples les plus instructifs, pour lesquels le 
mod&#232;le courant est le plus incertain. L'apprentissage actif est de plus en plus utilis&#233; dans des 
applications de traitement du langage naturel telles que l'&#233;tiquetage morphosyntaxique 
(Engelson, Dagan, 1999), le parsage stochastique (Tang et al, 2002) et la reconnaissance 
d&#8217;entit&#233;s nomm&#233;es (Shen et al, 2004).  
Dans cet article, nous proposons une m&#233;thodologie bas&#233;e sur l&#8217;apprentissage de r&#232;gles de 
correction. Ces r&#232;gles sont employ&#233;es pour r&#233;soudre les erreurs d&#8217;&#233;tiquetage qui persistent 
apr&#232;s l&#8217;application de l&#8217;&#233;tiqueteur de Brill (Brill, 1994) et d&#8217;E&#5;&#6;&#7; (Amrani et al, 2004). 
</p>
<p>2 M&#233;thodologie d&#8217;Etiquetage morphosyntaxique 
L&#8217;approche propos&#233;e consiste &#224; adapter un &#233;tiqueteur induit &#224; partir d'un corpus g&#233;n&#233;raliste &#224; 
un corpus de sp&#233;cialit&#233;. Notre syst&#232;me est bas&#233; sur l'&#233;tiqueteur de Brill (Brill, 1994). Cet 
&#233;tiqueteur utilise un apprentissage supervis&#233; &#224; base de transformations pour engendrer deux 
listes ordonn&#233;es de r&#232;gles : r&#232;gles lexicales et r&#232;gles contextuelles. E&#8;&#9;&#10;
</p>
<p>&#11;(Amrani et al, 2004), 
l&#8217;&#233;tiqueteur que nous avons con&#231;u, permet &#224; l&#8217;expert de d&#233;tecter les erreurs de l&#8217;&#233;tiqueteur de 
Brill, produites sur les corpus de sp&#233;cialit&#233;. A l&#8217;aide d&#8217;E&#8;&#9;&#10;, l&#8217;expert visualise le r&#233;sultat de 
l&#8217;&#233;tiquetage de Brill; il peut faire des requ&#234;tes lexicales ou contextuelles pour visualiser des 
                                                 
&#12; &#13;&#14;&#14;&#15; &#16;
</p>
<p>&#17;&#17;&#18;&#18; &#19;&#20;&#21; &#22; &#19;&#23;&#21;&#17;&#22;&#24;&#17;&#25;&#26;fffifl &#22;ffi&#31;&#17; &#19;  !&#20;!ffi
</p>
<p>&#13;
</p>
<p>&#24;&#21;&#25;&#26;fl &#26;ff
</p>
<p>&#14; &quot; #
</p>
<p>$
</p>
<p>ff&#26; %&#26;&#21;&#31;&#22;fiff
</p>
<p>&quot;
</p>
<p>&#26;
</p>
<p>&quot;
</p>
<p>!fl fiff &#31;
</p>
<p>&#14;
</p>
<p>&#21;&#24;
</p>
<p>&#14;
</p>
<p>&#22;fiff
</p>
<p>&quot;
</p>
<p>$
</p>
<p>&#20;fi&#25;&#22;ffi&#22;&#26;&#20; &amp; '( &#19;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Induction de r&#232;gles de correction pour l&#8217;&#233;tiquetage morphosyntaxique 
</p>
<p>groupes de mots (et leurs &#233;tiquettes) ayant des caract&#233;ristiques morphologiques ou 
contextuelles similaires. En fonction des erreurs d&#233;tect&#233;es, l'expert ins&#232;re des r&#232;gles lexicales 
et contextuelles pour les corriger. 
Apr&#232;s l&#8217;application de l&#8217;&#233;tiqueteur de Brill et d&#8217;E&#0;&#1;&#2; (Amrani et al, 2004; Amrani et al, 2005), 
nous avons remarqu&#233;, &#224; l&#8217;aide du logiciel E&#0;&#1;&#2;, que certaines confusions sp&#233;cifiques et 
difficiles &#224; r&#233;soudre persistent. Voici les confusions les plus s&#233;rieuses : (1) JJ (adjectif) et NN 
(nom commun, singulier) pour quelques mots tr&#232;s fr&#233;quents comme complex. (2) VBN (verbe 
participe pass&#233;), JJ et VBD (verbe au pass&#233;) comme transformed. (3) VBZ (verbe au pr&#233;sent, 
troisi&#232;me personne du singulier) et NNS (nom commun, pluriel) comme functions et contacts.  
L&#8217;expert annote les exemples correspondant aux confusions identifi&#233;es. Il corrige ou il 
confirme l&#8217;&#233;tiquette du mot cible de chaque exemple. Afin de r&#233;duire le nombre d&#8217;exemples &#224; 
annoter, nous utilisons l&#8217;apprentissage actif. Pour &#233;tudier l&#8217;impact de la repr&#233;sentation des 
exemples sur la performance, nous avons fait varier la taille des contextes aussi bien que les 
attributs utilis&#233;s pour repr&#233;senter les exemples. Ces exemples servent &#224; apprendre 
automatiquement des r&#232;gles qui corrigent l&#8217;&#233;tiquette du mot en fonction de son contexte. Ces 
r&#232;gles sont appliqu&#233;es &#224; la suite des r&#232;gles contextuelles existantes. 
</p>
<p>2.1 Apprentissage actif  
Nous calculons une mesure de distance entre chaque couple d&#8217;exemples. Puis, un ensemble 
initial d'exemples est s&#233;lectionn&#233; puis annot&#233;. A partir de cet ensemble, nous apprenons un 
mod&#232;le. A chaque it&#233;ration, un nouvel ensemble d&#8217;exemples pertinents est s&#233;lectionn&#233; puis 
annot&#233;. La strat&#233;gie de s&#233;lection est bas&#233;e sur la confiance et la diversit&#233;. Chaque &#233;tape est 
d&#233;taill&#233;e dans les sections suivantes. 
</p>
<p>2.1.1 Mesure de distance entre deux exemples 
Chaque exemple est repr&#233;sent&#233; comme suit: le mot cible est pris dans une fen&#234;tre de n mots de 
chaque c&#244;t&#233;. Chaque mot est repr&#233;sent&#233; par un ensemble d&#8217;attributs correspondant &#224; son 
&#233;tiquette morphosyntaxique et &#224; ses caract&#233;ristiques morphologiques. Soit l&#8217;exemple x 
repr&#233;sent&#233; comme suit, o&#249; (m =2n+1) est le nombre d&#8217;attributs et V&#3; &#4;&#5;  est la valeur de l&#8217;attribut 
qui est &#224; la position y de l&#8217;exemple x. 
</p>
<p>&#6;&#7; &#8;&#9;
</p>
<p>&#10; &#11;
</p>
<p>&#8; &#7; &#12; &#13; &#14;
</p>
<p>&#15; &#16;&#17;&#18;
</p>
<p>&#14;
</p>
<p>&#15; &#16; &#17; &#19;&#18; &#17;&#20;
</p>
<p>&#21; &#22;
</p>
<p>&#14;
</p>
<p>&#15; &#16;&#23;
</p>
<p>&#22;
</p>
<p>&#14;
</p>
<p>&#15; &#16;&#19;&#18; &#17;&#20;
</p>
<p>&#21;
</p>
<p>&#14;
</p>
<p>&#15; &#16;&#18;
</p>
<p>&#24;
</p>
<p>La mesure globale de distance entre deux exemples A et B (G_dist(ex&#25; ,ex&#26;)) est bas&#233;e sur les 
distances ((L_dist(V&#25; fffi,V&#26; fffi))) entre les valeurs de chaque attribut. Pour chaque attribut (k), 
nous comparons ses valeurs (V&#25; fffi and V&#26; fffi) dans les exemples: si les valeurs sont &#233;gales alors 
la distance est de 0; si les valeurs sont diff&#233;rentes alors la distance est de 1. 
</p>
<p>fl ffi &#31;
</p>
<p>&#14;
</p>
<p> 
</p>
<p>&#16;! &quot;
</p>
<p>&#14;
</p>
<p>#
</p>
<p>&#16;!
</p>
<p>$ % &amp;'() *+, -) . /0
</p>
<p>1 234
</p>
<p>0
</p>
<p>5
</p>
<p>23
</p>
<p>$ 6 7
</p>
<p>4
</p>
<p>) - /0
</p>
<p>1 23
</p>
<p>6 0
</p>
<p>5
</p>
<p>23
</p>
<p>$ % &amp;'() *+, -) . /0
</p>
<p>1 234
</p>
<p>0
</p>
<p>5
</p>
<p>23
</p>
<p>$ 6 8
</p>
<p>La mesure globale de distance (G_dist) entre deux exemples A (ex9 ) et B (ex:) est calcul&#233;e 
comme suit, o&#249; W; sont les poids donn&#233;s aux attributs de sorte que les attributs des mots les 
plus pr&#232;s du mot central soient les plus importants dans la mesure:  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Amrani A, Kodratoff Y et Matte-Tailliez O 
</p>
<p>&#8721;
&#8721;
</p>
<p>&#8722;=
</p>
<p>&#8722;=
</p>
<p>= &#0;
</p>
<p>&#0;
</p>
<p>&#1;
</p>
<p>&#1;
</p>
<p>&#0;
</p>
<p>&#0;
</p>
<p>&#1;
</p>
<p>&#1;
</p>
<p>&#2;
</p>
<p>&#1;&#3;&#1;
</p>
<p>&#2;
</p>
<p>&#3;
</p>
<p>W
</p>
<p>VVdistLW
exexdistG
</p>
<p>),(_*
),(_
</p>
<p>&#4;&#4;
</p>
<p>. 
</p>
<p>2.1.2 Strat&#233;gie de s&#233;lection des exemples 
Tout d&#8217;abord, nous s&#233;lectionnons un &#233;chantillon initial repr&#233;sentatif de tous les exemples. 
Pour ce faire, nous utilisons l&#8217;algorithme des k-moyennes (Jain et al, 1999; Tang et al., 2002). 
Cet algorithme est bas&#233; sur la mesure de distance d&#233;finie pr&#233;c&#233;demment. Nous obtenons un 
ensemble compos&#233; de nbc groupes. Chaque groupe contient des exemples similaires. 
L&#8217;&#233;chantillon initial est constitu&#233; &#224; partir d&#8217;une s&#233;lection al&#233;atoire d&#8217;un pourcentage &#945; 
d&#8217;exemples de chaque groupe. Cet &#233;chantillon nous sert &#224; apprendre un mod&#232;le initial. 
Ensuite, les autres exemples sont s&#233;lectionn&#233;s de mani&#232;re it&#233;rative. A chaque it&#233;ration, nous 
utilisons deux crit&#232;res pour la s&#233;lection : la confiance et la diversit&#233;. 
L&#8217;utilisation du crit&#232;re de la  confiance consiste &#224; choisir les exemples pour lesquels le mod&#232;le 
courant n'est pas satisfaisant. L'incertitude du mod&#232;le au sujet d'un exemple peut &#234;tre due au 
fait que les exemples semblables sont sous-repr&#233;sent&#233;s dans l'ensemble d&#8217;apprentissage, ou 
bien que les exemples semblables sont intrins&#232;quement complexes. Nous tirons profit de la 
disponibilit&#233; de la confiance en classification du mod&#232;le courant. L'algorithme d'apprentissage 
de r&#232;gles (par exemple PART (Frank, Witten, 1998)) assigne un degr&#233; de confiance &#224; chaque 
r&#232;gle induite. Pour chaque exemple non annot&#233;, nous affectons le degr&#233; de confiance de la 
r&#232;gle de laquelle il v&#233;rifie les conditions. 
Le but du crit&#232;re de la diversit&#233; (Shen et al., 2004) est de maximiser l&#8217;utilit&#233; inductive d&#8217;un 
ensemble d&#8217;exemples. Nous pr&#233;f&#233;rons les ensembles d&#8217;exemples h&#233;t&#233;rog&#232;nes. En choisissant 
un nouvel exemple non annot&#233;, nous le comparons avec tous les exemples pr&#233;c&#233;demment 
choisis dans l&#8217;ensemble courant. Si la similitude entre eux est au dessus d&#8217;un seuil &#946;, 
l&#8217;exemple n&#8217;est pas ajout&#233; dans l&#8217;ensemble. De cette fa&#231;on, nous &#233;vitons de choisir les 
exemples trop semblables (valeur de similitude &#8805; &#946;) dans un ensemble. 
La strat&#233;gie globale de s&#233;lection des exemples est d&#233;crite comme suit : les exemples non-
annot&#233;s sont ordonn&#233;s selon la confiance. A chaque it&#233;ration, nous choisissons un ensemble 
de nb exemples de la mani&#232;re suivante: D&#8217;abord, nous s&#233;lectionnons un exemple candidat
(Exemple&#5;) avec une valeur de confiance minimale. Ensuite, nous &#233;valuons le crit&#232;re de 
diversit&#233; et nous ajoutons l&#8217;exemple candidat Exemple&#5; &#224; l&#8217;ensemble si seulement Exemple&#5; est 
assez diff&#233;rent de n&#8217;importe quel exemple pr&#233;c&#233;demment ins&#233;r&#233; dans l&#8217;ensemble. Le seuil &#946; 
est fix&#233; &#224; une valeur comprise entre la valeur maximale de similitude et la moyenne des 
similitudes par paires dans l&#8217;ensemble des exemples non annot&#233;s. 
</p>
<p>3 Validation exp&#233;rimentale 
Pour les exp&#233;rimentations, nous avons utilis&#233; un corpus de 600 r&#233;sum&#233;s d&#8217;articles MEDLINE 
(Amrani et al, 2004) de biologie mol&#233;culaire. Ce corpus a &#233;t&#233; &#233;tiquet&#233; par l&#8217;&#233;tiqueteur de Brill, 
puis par E&#6;&#7;&#8;. A partir de ce corpus, nous avons pr&#233;sent&#233; &#224; l&#8217;annotateur 4133 exemples o&#249; le </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Induction de r&#232;gles de correction pour l&#8217;&#233;tiquetage morphosyntaxique 
</p>
<p>mot cible est &#233;tiquet&#233; VBN et 3298 exemples o&#249; le mot cible est &#233;tiquet&#233; NNS. Le nombre 
total d&#8217;exemples NNS &#233;tait de 7708 dont 4410 sont des mots non-ambigus. L&#8217;annotateur a 
class&#233; les mots cibles en VBN, JJ ou VBD pour le premier jeu d&#8217;exemples et  NNS ou VBZ 
pour le deuxi&#232;me jeu. Pour am&#233;liorer la pr&#233;cision, nous avons repr&#233;sent&#233; les exemples comme 
suit : pour le cas des VBN,  le mot cible est pris dans une fen&#234;tre de 10 mots (5 mots &#224; gauche 
et 5 mots &#224; droite) et chaque mot du contexte est repr&#233;sent&#233; par : son &#233;tiquette 
morphosyntaxique, le groupe auquel appartient son &#233;tiquette (verbal, nominal ou autre) et le 
mot est un verbe auxiliaire ou non. Pour le cas des NNS, le mot cible est pris dans une fen&#234;tre 
de 6 mots : 3 mots &#224; droite et 3 mots &#224; gauche. En plus des attributs utilis&#233;s pour repr&#233;senter 
les exemples des VBN, nous avons utilis&#233; les suffixes et les pr&#233;fixes les plus fr&#233;quents des 
mots. A partir de ces exemples, nous avons induit des r&#232;gles avec les algorithmes PART (pour 
les VBN) et RIPPER (pour les NNS). Nous avons calcul&#233; les pr&#233;cisions de l&#8217;&#233;tiqueteur de 
Brill, d&#8217;E&#0;&#1;&#2; et d&#8217;E&#0;&#1;&#2; enrichi par les r&#232;gles induites (voir Figure 1). La pr&#233;cision des r&#232;gles 
induites a &#233;t&#233; calcul&#233;e par la m&#233;thode &#171;validation crois&#233;e 10 fois&#187;.  
</p>
<p>Confusion  /  %de pr&#233;cision Brill Brill+ E&#0;&#1;&#2; Brill+ E&#0;&#1;&#2;+R&#232;gles induites 
VBN&#1;VBN-VBD-JJ (P&#3;&#4;&#0;)  54 76 94 
NNS&#1;NNS-VBZ (R&#1;&#5;&#5;&#6;&#4;) 92 96 97,5 
</p>
<p>Figure 1 : Pr&#233;cisions obtenues sur deux jeux d&#8217;exemples de confusions d&#8217;&#233;tiquettes. 
Nous avons appliqu&#233; la strat&#233;gie de l&#8217;apprentissage actif aux exemples correspondent &#224; 
l&#8217;ambigu&#239;t&#233; VBN-VBD-JJ. Parmi les 4133 exemples disponibles, nous avons pris 3100 
exemples pour l&#8217;apprentissage actif, et 1033 exemples pour le test. Le mod&#232;le initial a &#233;t&#233; 
construit &#224; partir de 423 exemples. A chaque it&#233;ration, nous avons s&#233;lectionn&#233; 100 exemples. 
L&#8217;exp&#233;rience a &#233;t&#233; r&#233;p&#233;t&#233;e 5 fois. La courbe (figure 2) repr&#233;sente les valeurs moyennes 
obtenues. La pr&#233;cision obtenue avec tous les exemples (3100) est de 93,5. 
</p>
<p>87
88
89
90
91
92
93
94
</p>
<p>443 543 643 743 843 943 1043 1143 1243 1343 1443
Nombre d&#8217;exemples s&#233;lectionn&#233;s 
</p>
<p>Pr
&#233;c
</p>
<p>is
io
</p>
<p>n
 
</p>
<p>(%
)
</p>
<p>Apprentissage actif S&#233;lection al&#233;atoire Apprentissage supervis&#233;
</p>
<p> 
Figure 2 : Apprentissage actif versus s&#233;lection al&#233;atoire. 
</p>
<p>4 Conclusions et perspectives 
Dans le cadre d&#8217;une m&#233;thodologie globale pour l&#8217;&#233;tiquetage morphosyntaxique des corpus de 
sp&#233;cialit&#233;, nous avons compl&#233;t&#233; notre approche pour traiter efficacement les probl&#232;mes </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Amrani A, Kodratoff Y et Matte-Tailliez O 
</p>
<p>d&#8217;&#233;tiquetage pointus. Apr&#232;s la d&#233;tection des contextes ambigus et particuliers, les mots cibles 
sont annot&#233;s (exemples). A partir de ces exemples, nous avons induit des r&#232;gles de correction. 
Nous avons obtenu une nette am&#233;lioration de la pr&#233;cision d&#8217;&#233;tiquetage. Pour r&#233;duire le 
nombre d&#8217;exemples &#224; annoter, nous avons utilis&#233; l&#8217;apprentissage actif avec une strat&#233;gie de 
s&#233;lection bas&#233;e sur la confiance et la diversit&#233;. En annotant seulement un tiers des exemples, 
nous obtenons des performances &#233;quivalentes &#224; celles obtenues en annotant tous les exemples. 
Nous &#233;tendrons cette approche &#224; d&#8217;autres classes d&#8217;ambigu&#239;t&#233;s. Nous envisageons &#233;galement 
de consid&#233;rer d&#8217;autres m&#233;thodes d&#8217;apprentissage, par exemple : la Programmation Logique 
Inductive. La combinaison optimale des r&#232;gles obtenues par diff&#233;rents algorithmes pourrait 
am&#233;liorer les performances. Le crit&#232;re de diversit&#233;, utilis&#233; pour l&#8217;apprentissage actif, peut &#234;tre 
am&#233;lior&#233; en utilisant une valeur de similitudes (&#946;) optimale. 
</p>
<p>R&#233;f&#233;rences 
A&#0;&#1;&#2;&#3; &#4;, A., A&#5;&#6;, J., K&#7;&#8;&#9;&#10;&#11;&#7;&#12;&#12;, Y. (2005) ETIQ: Logiciel d'aide &#224; l'&#233;tiquetage morpho-
syntaxique de textes de sp&#233;cialit&#233;. Dans la revue RNTI, num&#233;ro sp&#233;cial EGC'2005. 
A&#13;&#9;&#10;&#14; &#15;, A., K&#7;&#8;&#9;&#10;&#11;&#7;&#12;&#12;, Y., M&#10;&#11;&#11;&#16;-T&#10; &#15;&#17;&#17;&#15;&#16;&#18;, O. (2004) A Semi-automatic System for 
Tagging Specialized Corpora,  PAKDD 2004, Sydney, LNAI, Vol. 3056, pp 670-681. 
B&#9; &#15;&#17;&#17;, E. (1994) Some Advances in Transformation-Based Part of Speech Tagging, AAAI, 
Vol. 1, pp 722-727. 
C&#7;&#19;&#16;&#14; , W. (1995) Fast Effective Rule Induction, Proceedings of the 12&#20;&#21; International 
Conference on Machine Learning. 
E&#22;&#23;&#24;&#25;&#26;ff&#22; , S.A., Dfi&#23;fi&#22; , I. (1999) Committee-Based Sample Selection for Probabilistic 
Classifiers. Journal of Artifical Intel-ligence Research. 
Fflfi&#22;ffi , E., W&#31;  &#24;&#22; , I.H. (1998) Generating Accurate Rule Sets Without Global Optimization, 
Shavlik, J. Eds., Proceedings of the 15&#20;&#21; ICML, Madison, Wisconsin, pp 144-151. 
Jfi &#31;&#22; , A. K., M!&quot;#$ , M. N., %&amp;' F($&amp;&amp; , P. J. Data clustering: a review. ACM Computing 
Surveys, 31(3):264-323. 
P%&quot;)!*+, , P., R%-.%&amp; , M. (2000) Chapitre 5: Etiquetage morpho-syntaxique, Ing&#233;nierie des 
Langues, sous la direction de Jean-Marie Pierrel, Collection &quot;Information Commande 
Communication&quot;, aux Editions Hermes Science, 2000 pp 131-148. 
Q!/&amp;(%&amp; , J.R (1993) C4.5: Programs for Machine Learning, Morgan Kaufmann San Mateo. 
S0+&amp; , D., Z0%&amp;1, J., S! , J., Z0)! , G., T%&amp; , C-L. (2004) Multi-Criteria-based Active 
Learning for Named Entity Recognition. Proceedings of ACL 2004. 
T%&amp;1, M., L!), X., R)!,)2, S., 2002. Active Learning for Statistical Natural Language 
Parsing. In Proceedings of the ACL 2002. 
V%((/, A., &amp; V+&quot;)&amp; /2, J. (1999). Etiquetage grammatical de corpus oraux: probl&#232;mes et 
perspectives. Revue Fran&#231;aise de Linguistique Appliqu&#233;e, IV(2), 113-133. </p>

</div></div>
</body></html>