TALN 2005, Dourdan, 6-10juz'n 2005

Induction de regles de correction pour l’étiquetage
morphosyntaxique de la littérature de biologie en utilisant
l’apprentissage actif

Ahmed Arnrani (1), Yves Kodratoff (2) et Oriane Matte-Tailliez (2)

(1)ESIEA Recherche, 9 rue Vésale, 75005 Paris, France.
arnrani@esiea.fr
(2) LRI, UlVlR CNRS 8623, Bat. 490, Université Paris 11, 91405 Orsay.
{yk, oriane}@lri

Mots-clés I Etiquetage morphosyntaxique, Apprentissage de regles, Apprentissage actif,
fouille de textes.

Keywords: Part-of-speech tagging, rule learning, active learning, text-mining.

Résumé Dans le contexte de l’e'tiquetage morphosyntaxique des corpus de spécialité, nous
proposons une approche inductive pour réduire les erreurs les plus diffrciles et qui persistent
apres étiquetage par le systeme de Brill. Nous avons applique’ notre systeme sur deux types de
confusions. La premiere confusion concerne un mot qui peut avoir les étiquettes ‘Verbe au
participe passé’, ‘Verbe au passé’ ou ‘adjectif’. La deuxieme confusion se produit entre un
nom commun au pluriel et un Verbe au présent, a la 36"“ personne du singulier. A l’aide
d’interface conviviale, l’expert corrige l’étiquette du mot ambigu. A partir des exemples
armotés, nous induisons des regles de correction. Aﬁn de réduire le coﬁt d’armotation, nous
avons utilise’ l’apprentissage actif. La validation expérimentale a montré une amelioration de
la précision de l’étiquetage. De plus, a partir de l’armotation du tiers du nombre d’exemples,
le niveau de précision réalisé est équivalent a celui obtenu en armotant tous les exemples.

Abstract In the context of Part-of-Speech (PoS)-tagging of specialized corpora, we
proposed an approach focusing on the most ‘important’ PoS-tags because mistaking them can
lead to a total misunderstanding of the text. After tagging a biological corpus by Brill’s tagger,
we noted persistent errors that are very hard to deal with. As an application, we studied two
cases of different nature: ﬁrst, confusion between past participle, adjective and preterit;
second, confusion between plural nouns and verbs, 3rd person singular present. With a friendly
user interface, the expert corrected the examples. Then, from these well-armotated examples,
we induced rules. In order to reduce the cost of armotation, we used active learning. The
experimental validation showed improvement in tagging precision and that on the basis of the
armotation of one third of the examples we obtain a level of precision equivalent to the one
reached by armotating all the examples.

Amrani A, Kodratoﬂ Y et Matte-T ailliez O

1 Introduction

L’étiquetage morphosyntaxique est une étape importante pour la tache d’extraction
d’informations a partir de textes bruts et spécialisés. Cette étape consiste a associer a chaque
mot son étiquette grammaticale en fonction de sa morphologie et de son contexte. Les
étiqueteurs morphosyntaxiques actuels atteignent des performances tres satisfaisantes en
précision (plus de 95%) (Paroubek, Rajman, 2000). Ces bons résultats s’expliquent par le fait
que les travaux en question se situent dans le domaine de l’apprentissage supervise ou le
corpus de test est de meme nature que le corpus d’apprentissage. Un pré-requis pour la
construction d’un étiqueteur est la disponibilité d’un corpus armoté de taille importante.
L’acquisition d’un tel corpus est coﬁteuse. D’autre part, les systemes d’étiquetage ont tous des
difﬁcultés sur les cas difﬁciles. Les décisions sont le plus souvent fondées sur l’examen des
contextes locaux (tels que les trigrammes de mots), qui résolvent mal les cas qui
demanderaient une analyse plus globale et approfondie (Valli, Veronis, 1999).

Il existe deux approches principales pour l’apprentissage de regles 2 la création de regles a
partir d’arbres de décision (Quinlan, 1993) et la technique d’apprentissage directe de regles
comme dans l’algorithme RIPPER (Cohen, 1995). L’algorithme d’apprentissage de regles
propositionnelles, PART (Frank, Witten, 1998), combine les deux approches précédentes.
Chaque regle induite par PART a la forme d’une conjonction de conditions 2 Si T; et T 2 et 
T ,, alors la classe est Cx. (Si T1 et T 2 et  T ,,) est appelé le corps de la regle et (Cx) est la classe
cible a apprendre. Chaque condition T ,~ teste une Valeur particuliere d’un attribut. La condition
a la forme suivante 2 A ,- = v, ou A,~ est un attribut symbolique et v est une Valeur possible de A ,-.

L’apprentissage actif est une technique qui permet de réduire le nombre d’exemples a armoter.
Cette technique consiste a sélectionner les exemples les plus instructifs, pour lesquels le
modele courant est le plus incertain. L'apprentissage actif est de plus en plus utilisé dans des
applications de traitement du langage naturel telles que l'étiquetage morphosyntaxique
(Engelson, Dagan, 1999), le parsage stochastique (Tang et al, 2002) et la reconnaissance
d’entités nommées (Shen et al, 2004).

Dans cet article, nous proposons une méthodologie basée sur l’apprentissage de regles de
correction. Ces regles sont employées pour résoudre les erreurs d’étiquetage qui persistent
apres l’application de l’étiqueteur de Brill (Brill, 1994) et d’ETIQ (Amrani et al, 2004).

2 Méthodologie d’Etiquetage morphosyntaxique

L’approche proposée consiste a adapter un étiqueteur induit a partir d'un corpus généraliste a
un corpus de spécialité. Notre systeme est basé sur l'étiqueteur de Brill (Brill, 1994). Cet
étiqueteur utilise un apprentissage supervise a base de transformations pour engendrer deux
listes ordonnées de regles 2 regles lexicales et regles contextuelles. ETIQ1(Amrani et al, 2004),
l’étiqueteur que nous avons concu, permet a l’expert de détecter les erreurs de l’étiqueteur de
Brill, produites sur les corpus de spécialité. A l’aide d’ETIQ, l’expert visualise le résultat de
l’étiquetage de Brill; il peut faire des requétes lexicales ou contextuelles pour Visualiser des

1 httpz//ww.1n'.fr/ia/genomics/. Téléchargement d’une version de démonstration du logiciel ETIQ.

Induction de regles de correction pour l’étiquetage morphosyntaxique

groupes de mots (et leurs étiquettes) ayant des caractéristiques morphologiques ou
contextuelles similaires. En fonction des erreurs détectées, l'expert insere des regles lexicales
et contextuelles pour les corriger.

Apres l’application de l’étiqueteur de Brill et d’ETIQ (Amrani et al, 2004; Amrani et al, 2005),
nous avons remarqué, £1 l’aide du logiciel ETIQ, que certaines confusions spéciﬁques et
difﬁciles £1 résoudre persistent. Voici les confusions les plus sérieuses : (1) JJ (adjectif) et NN
(nom commun, singulier) pour quelques mots tres frequents comme complex. (2) VBN (Verbe
participe passé), JJ et VBD (Verbe au passé) comme transformed. (3) VBZ (Verbe au présent,
troisieme personne du singulier) et NNS (nom commun, pluriel) comme functions et contacts.

L’expert armote les exemples correspondant aux confusions identiﬁées. Il corrige ou il
conﬁrrne l’étiquette du mot cible de chaque exemple. Aﬁn de réduire le nombre d’exemples £1
armoter, nous utilisons l’apprentissage actif. Pour étudier l’impact de la representation des
exemples sur la performance, nous avons fait Varier la taille des contextes aussi bien que les
attributs utilisés pour représenter les exemples. Ces exemples servent £1 apprendre
automatiquement des regles qui corrigent l’étiquette du mot en fonction de son contexte. Ces
regles sont appliquées £1 la suite des regles contextuelles existantes.

2.1 Apprentissage actif

Nous calculons une mesure de distance entre chaque couple d’exemples. Puis, un ensemble
initial d'exemples est sélectionné puis armoté. A partir de cet ensemble, nous apprenons un
modele. A chaque itération, un nouvel ensemble d’exemples pertinents est sélectionné puis
armoté. La stratégie de sélection est basée sur la conﬁance et la diversité. Chaque étape est
détaillée dans les sections suivantes.

2.1.1 Mesure de distance entre deux exemples

Chaque exemple est représenté comme suit: le mot cible est pris dans une fenétre de n mots de
chaque cote. Chaque mot est représenté par un ensemble d’attributs correspondant £1 son
etiquette morphosyntaxique et £1 ses caractéristiques morphologiques. Soit l’exemple x
représenté comme suit, ou (m =2n+1) est le nombre d’attributs et Vxhy est la Valeur de l’attribut
qui est £1 la position y de l’exemple x.

Exemple .X3.' [Vxrn  _(n_1)  Vx_0  Vx’(,,_1) 

La mesure globale de distance entre deux exemples A et B (G_dist(exA,exB)) est basée sur les
distances ((L_dist(VA,k,VB,k))) entre les Valeurs de chaque attribut. Pour chaque attribut (k),
nous comparons ses Valeurs (V A,k and VB,k) dans les exemples: si les Valeurs sont égales alors
la distance est de 0; si les Valeurs sont différentes alors la distance est de 1.

si (VA,k = V31) alors L_dist(V,,,,,, V”) = 0, si (V/1,1: = V31.) alors L_dz'st(V,,,,,, VB,k) = 1

La mesure globale de distance (G_dist) entre deux exemples A (ex,4) et B (exg) est calculée
comme suit, ou Wk sont les poids donnés aux attributs de sorte que les attributs des mots les
plus pres du mot central soient les plus importants dans la mesure:

Amrani A, Kodratoﬂ Y et Matte-T ailliez O

n

Zwk * L_ dist(VA)k, V3,)
G_ dist(exA ,exB) = k=’" n
2%
k=—n

2.1.2 Stratégie de sélection des exemples

Tout d’abord, nous sélectionnons un échantillon initial représentatif de tous les exemples.
Pour ce faire, nous utilisons l’algorithme des k-moyennes (Jain et al, 1999; Tang et al., 2002).
Cet algorithme est basé sur la mesure de distance déﬁnie précédemment. Nous obtenons un
ensemble composé de nbc groupes. Chaque groupe contient des exemples similaires.
L’échantillon initial est constitué a partir d’une sélection aléatoire d’un pourcentage 0!
d’exemples de chaque groupe. Cet échantillon nous sert a apprendre un modele initial.
Ensuite, les autres exemples sont sélectionnés de maniere itérative. A chaque itération, nous
utilisons deux criteres pour la sélection : la conﬁance et la diversité.

L’utilisation du critere de la conﬁance consiste a choisir les exemples pour lesquels le modele
courant n'est pas satisfaisant. L'incertitude du modele au sujet d'un exemple peut étre due au
fait que les exemples semblables sont sous-représentés dans l'ensemble d’apprentissage, ou
bien que les exemples semblables sont intrinsequement complexes. Nous tirons proﬁt de la
disponibilité de la conﬁance en classiﬁcation du modele courant. L'algorithme d'apprentissage
de regles (par exemple PART (Frank, Witten, 1998)) assigne un degré de conﬁance a chaque
regle induite. Pour chaque exemple non armoté, nous affectons le degré de conﬁance de la
regle de laquelle il Vériﬁe les conditions.

Le but du critere de la diversité (Shen et al., 2004) est de maximiser l’utilité inductive d’un
ensemble d’exemples. Nous préférons les ensembles d’exemples hétérogenes. En choisissant
un nouvel exemple non armoté, nous le comparons avec tous les exemples précédemment
choisis dans l’ensemble courant. Si la similitude entre eux est au dessus d’un seuil [3,
l’exemple n’est pas ajouté dans l’ensemble. De cette facon, nous évitons de choisir les
exemples trop semblables (Valeur de similitude 2 B) dans un ensemble.

La stratégie globale de sélection des exemples est décrite comme suit: les exemples non-
armotés sont ordonnés selon la conﬁance. A chaque itération, nous choisissons un ensemble
de nb exemples de la maniere suivante: D’abord, nous sélectionnons un exemple candidat
(Exemple,-) avec une Valeur de conﬁance minimale. Ensuite, nous évaluons le critere de
diversité et nous aj outons l’exemple candidat Exemplei a l’ensemble si seulement Exemple; est
assez different de n’importe quel exemple précédemment inséré dans l’ensemble. Le seuil B
est ﬁxé a une Valeur comprise entre la Valeur maximale de similitude et la moyenne des
similitudes par paires dans l’ensemble des exemples non armotés.

3 Validation expérimentale
Pour les expérimentations, nous avons utilisé un corpus de 600 résumés d’articles MEDLINE

(Amrani et al, 2004) de biologie moléculaire. Ce corpus a été étiqueté par l’étiqueteur de Brill,
puis par ETIQ. A partir de ce corpus, nous avons présenté a l’armotateur 4133 exemples ou le

Induction de régles de correction pour l’étz'quetage morphosyntaxique

mot cible est étiqueté VBN et 3298 exemples ou le mot cible est étiqueté NNS. Le nombre
total d’exemples NNS était de 7708 dont 4410 sont des mots non-ambigus. L’armotateur a
classé les mots cibles en VBN, JJ ou VBD pour le premier jeu d’exemples et NNS ou VBZ
pour le deuxieme jeu. Pour améliorer la précision, nous avons représenté les exemples comme
suit 2 pour le cas des VBN, le mot cible est pris dans une fenétre de 10 mots (5 mots a gauche
et 5 mots a droite) et chaque mot du contexte est représenté par 2 son étiquette
morphosyntaxique, le groupe auquel appartient son étiquette (Verbal, nominal ou autre) et le
mot est un Verbe auxiliaire ou non. Pour le cas des NNS, le mot cible est pris dans une fenétre
de 6 mots 2 3 mots a droite et 3 mots a gauche. En plus des attributs utilisés pour représenter
les exemples des VBN, nous avons utilisé les sufﬁxes et les preﬁxes les plus frequents des
mots. A partir de ces exemples, nous avons induit des regles avec les algorithmes PART (pour
les VBN) et RIPPER (pour les NNS). Nous avons calculé les précisions de l’étiqueteur de
Brill, d’ETIQ et d’ETIQ enrichi par les regles induites (Voir Figure 1). La précision des regles
induites a été calculée par la méthode «Validation croisée 10 fois».

Confusion / %de précision Brill Brill+ ETIQ Brill+ ETIQ+Regles induites

VBN9VBN-VBD-J J (PART) 54 76 94

NNS9NNS-VBZ (RIPPER) 92 96 97,5

Figure 1 2 Précisions obtenues sur deux jeux d’exemples de confusions d’étiquettes.

Nous avons appliqué la stratégie de l’apprentissage actif aux exemples correspondent a
l’ambigu'1'té VBN-VBD-JJ. Parmi les 4133 exemples disponibles, nous avons pris 3100
exemples pour l’apprentissage actif, et 1033 exemples pour le test. Le modele initial a été
construit a partir de 423 exemples. A chaque itération, nous avons sélectionné 100 exemples.
L’expérience a été répétée 5 fois. La courbe (ﬁgure 2) représente les Valeurs moyennes
obtenues. La précision obtenue avec tous les exemples (3100) est de 93,5.

‘—I—Apprentissage actif —A—Sé|ection aléatoire - - -X- - -Apprentissage supervisé 1

 

Précision (%
(O
O

443 543 643 743 843 943 1043 1143 1243 1343 1443
Nombre d’exemples sélectionnés

Figure 2 2 Apprentissage actif versus sélection aléatoire.

4 Conclusions et perspectives

Dans le cadre d’une méthodologie globale pour l’étiquetage morphosyntaxique des corpus de
spécialité, nous avons complété notre approche pour traiter efﬁcacement les problemes

Amrani A, Kodratoﬂ Y et Matte-T ailliez O

d’étiquetage pointus. Apres la détection des contextes ambigus et particuliers, les mots cibles
sont armotés (exemples). A partir de ces exemples, nous avons induit des regles de correction.
Nous avons obtenu une nette amélioration de la précision d’étiquetage. Pour réduire le
nombre d’exemples a armoter, nous avons utilisé l’apprentissage actif avec une stratégie de
sélection basée sur la conﬁance et la diversité. En armotant seulement un tiers des exemples,
nous obtenons des performances équivalentes a celles obtenues en armotant tous les exemples.
Nous étendrons cette approche a d’autres classes d’ambigui'tés. Nous envisageons également
de considérer d’autres méthodes d’apprentissage, par exemple : la Programmation Logique
Inductive. La combinaison optimale des regles obtenues par différents algorithmes pourrait
améliorer les performances. Le critere de diversité, utilisé pour l’apprentissage actif, peut étre
amélioré en utilisant une valeur de similitudes (B) optimale.

Références

AMRAN1, A., AZE, J., KODRATOFF, Y. (2005) ETIQ: Logiciel d'aide a l'étiquetage morpho-
syntaxique de textes de spécialité. Dans la revue RN T I, numéro spécial EGC’2005.

AMRAN1, A., KODRATOFF, Y., MATTE-TAILLIEZ, O. (2004) A Semi-automatic System for
Tagging Specialized Corpora, PAKDD 2004, Sydney, LNAI, Vol. 3056, pp 670-681.

BRILL, E. (1994) Some Advances in Transformation-Based Part of Speech Tagging, AAAI,
Vol. 1, pp 722-727.

COHEN, W. (1995) Fast Effective Rule Induction, Proceedings of the 12"’ International
Conference on Machine Learning.

ENGELSON, S.A., DAGAN, I. (1999) Committee-Based Sample Selection for Probabilistic
Classiﬁers. Journal of Artiﬁcal Intel-ligence Research.

FRANK, E., WITTEN, I.H. (1998) Generating Accurate Rule Sets Without Global Optimization,
Shavlik, J. Eds., Proceedings of the 15"’ ICML, Madison, Wisconsin, pp 144-151.

JAIN, A. K., MURTY, M. N., AND FLYNN, P. J. Data clustering: a review. ACM Computing
Surveys, 31(3):264-323.

PAROUBEK, P., RAJMAN, M. (2000) Chapitre 5: Etiquetage morpho-syntaxique, Ingénierie des
Langues, sous la direction de Jean-Marie Pierrel, Collection "Information Commande
Communication", aux Editions Hermes Science, 2000 pp 131-148.

QUINLAN, J .R (1993) C45’ Programs for Machine Learning, Morgan Kaufmarm San Mateo.

SHEN, D., ZHANG, J., SU, J., ZHoU, G., TAN, C-L. (2004) Multi-Criteria-based Active
Learning for Named Entity Recognition. Proceedings of A CL 2004.

TANG, M., LUO, X., ROUKOS, S., 2002. Active Learning for Statistical Natural Language
Parsing. In Proceedings of the ACL 2002.

VALLI, A., & VERONIS, J . (1999). Etiquetage grammatical de corpus oraux: problemes et
perspectives. Revue Francaise de Linguistique Appliquée, IV(2), 113-133.

