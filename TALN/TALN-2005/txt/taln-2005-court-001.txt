TALN 2005, Dourdan, 6-I0juz'n 2005

Induction de regles de correction pour l’étiquetage
morphosyntaxique de la littérature de biologie en utilisant
Papprentissage actif

Ahmed Amrani (1), Yves Kodratoff (2) et Oriane Matte-Tailliez (2)

(l)ESIEA Recherche, 9 rue Vésale, 75005 Paris, France.
amrani@esiea.fr
(2) LRI, Ul\/[R CNRS 8623, Bat. 490, Université Paris 1 1, 91405 Orsay.
{yk, oriane}@lri

Mots-clés 2 Etiquetage morphosyntaxique, Apprentissage de regles, Apprentissage actif,
fouille de textes.

Keywords: Part-of-speech tagging, rule learning, active learning, text-mining.

Résumé Dans le contexte de l’e’tiquetage morphosyntaxique des corpus de spécialité, nous
proposons une approche inductive pour réduire les erreurs les plus difficiles et qui persistent
apres étiquetage par le systeme de Brill. Nous avons applique’ notre systeme sur deux types de
confusions. La premiere confusion concerne un mot qui peut avoir les étiquettes ‘verbe au
participe passe”, ‘verbe au passe” ou ‘adjectif’. La deuxieme confusion se produit entre un
nom commun au pluriel et un verbe au présent, a la 36"” personne du singulier. A l’aide
d’interface conviviale, l’expert corrige l’e'tiquette du mot ambigu. A partir des exemples
annotés, nous induisons des regles de correction. Afin de réduire le coﬁt d’annotation, nous
avons utilise’ l’apprentissage actif La validation expérimentale a montré une amélioration de
la précision de l’e'tiquetage. De plus, a partir de l’annotation du tiers du nombre d’exemples,
le niveau de précision réalisé est équivalent a celui obtenu en annotant tous les exemples.

Abstract In the context of Part-of-Speech (PoS)-tagging of specialized corpora, we
proposed an approach focusing on the most ‘important’ PoS-tags because mistaking them can
lead to a total misunderstanding of the text. After tagging a biological corpus by Brill’s tagger,
we noted persistent errors that are very hard to deal with. As an application, we studied two
cases of different nature: first, confusion between past participle, adjective and preterit;
second, confusion between plural nouns and verbs, 3"‘ person singular present. With a friendly
user interface, the expert corrected the examples. Then, from these well-annotated examples,
we induced rules. In order to reduce the cost of annotation, we used active learning. The
experimental validation showed improvement in tagging precision and that on the basis of the
annotation of one third of the examples we obtain a level of precision equivalent to the one
reached by annotating all the examples.

385

386

Amrani A, Kodratoﬁ’ Y et Matte-Tailliez O

1 Introduction

L’e'tiquetage morphosyntaxique est une e'tape importante pour la tache d’eXtraction
d’informations a partir de textes bruts et specialises. Cette e'tape consiste a associer a chaque
mot son etiquette grammaticale en fonction de sa morphologie et de son contexte. Les
e'tiqueteurs morphosyntaxiques actuels atteignent des performances tres satisfaisantes en
precision (plus de 95%) (Paroubek, Rajman, 2000). Ces bons re'sultats s’eXpliquent par le fait
que les traVauX en question se situent dans le domaine de l’apprentissage supervise oil le
corpus de test est de meme nature que le corpus d’apprentissage. Un pre’-requis pour la
construction d’un e'tiqueteur est la disponibilité d’un corpus annote' de taille importante.
L’acquisition d’un tel corpus est coﬁteuse. D’autre part, les systemes d’e'tiquetage ont tous des
difﬁcultés sur les cas difﬁciles. Les decisions sont le plus souvent fonde'es sur l’eXamen des
contextes locaux (tels que les trigrammes de mots), qui re’solVent mal les cas qui
demanderaient une analyse plus globale et approfondie Walli, Veronis, 1999).

Il existe deux approches principales pour l’apprentissage de regles 2 la creation de regles a
partir d’arbres de decision (Quinlan, 1993) et la technique d’apprentissage directe de regles
comme dans l’algorithme RIPPER (Cohen, 1995). L’algorithme d’apprentissage de regles
propositionnelles, PART (Frank, Witten, 1998), combine les deux approches pre'ce'dentes.
Chaque regle induite par PART a la forme d’une conjonction de conditions 2 Si T; et T 2 et 
T ,, alors la classe est Cx. (Si T; et T 2 et  T ,1) est appele' le corps de la regle et (Cx) est la classe
cible a apprendre. Chaque condition T ,< teste une Valeur particuliere d’un attribut. La condition
a la forme suivante 2 A,< = v, oil A; est un attribut symbolique et v est une Valeur possible de A,<.

L’apprentissage actif est une technique qui permet de re’duire le nombre d’eXemples a annoter.
Cette technique consiste a sélectionner les exemples les plus instructifs, pour lesquels le
modele courant est le plus incertain. L'apprentissage actif est de plus en plus utilise dans des
applications de traitement du langage naturel telles que l'e’tiquetage morphosyntaxique
(Engelson, Dagan, 1999), le parsage stochastique (Tang et al, 2002) et la reconnaissance
d’entite's nomme'es (Shen et al, 2004).

Dans cet article, nous proposons une méthodologie base'e sur l’apprentissage de regles de
correction. Ces regles sont employe'es pour re'soudre les erreurs d’e'tiquetage qui persistent
apres l’application de l’e’tiqueteur de Brill (Brill, 1994) et d’ETIQ (Armani et al, 2004).

2 Méthodologie d’Etiquetage morphosyntaxique

L’approche propose'e consiste a adapter un e'tiqueteur induit a partir d'un corpus ge’ne'raliste a
un corpus de spe'cialite'. Notre systeme est base’ sur l'e’tiqueteur de Brill (Brill, 1994). Cet
e’tiqueteur utilise un apprentissage supervise a base de transformations pour engendrer deux
listes ordonne'es de regles 2 regles lexicales et regles contextuelles. ETIQ1(Amrani et al, 2004),
l’e'tiqueteur que nous aVons concu, permet a l’eXpert de de’tecter les erreurs de l’e'tiqueteur de
Brill, produites sur les corpus de spe'cialite'. A l’aide d’ETIQ, l’eXpert Visualise le re'sultat de
l’e'tiquetage de Brill; il peut faire des requétes lexicales ou contextuelles pour Visualiser des

1 http://ww.]ri.fr/ia/genomics/. Téléchargement d’une version de démonstration du logiciel ETIQ.

Induction de regles de correction pour I ’étiquetage morphosyntaxique

groupes de mots (et leurs e'tiquettes) ayant des caracte’ristiques morphologiques ou
contextuelles similaires. En fonction des erreurs de'tecte'es, l'eXpert insere des regles lexicales
et contextuelles pour les corriger.

Apres l’application de l’e’tiqueteur de Brill et d’ETIQ (Armani et al, 2004; Armani et al, 2005),
nous aVons remarque', a l’aide du logiciel ETIQ, que certaines confusions spe'ciﬁques et
difﬁciles a re’soudre persistent. Voici les confusions les plus se’rieuses 2 (1) J J (adjectif) et NN
(nom commun, singulier) pour quelques mots tres frequents comme complex. (2) VBN (Verbe
participe passe’), JJ et VBD (Verbe au passe’) comme transformed. (3) VBZ (Verbe au pre’sent,
troisieme personne du singulier) et NNS (nom commun, pluriel) comme functions et contacts.

L’eXpert annote les exemples correspondant aux confusions identiﬁe'es. Il corrige ou il
conﬁrme l’e’tiquette du mot cible de chaque exemple. Aﬁn de re’duire le nombre d’eXemples a
annoter, nous utilisons l’apprentissage actif. Pour e'tudier l’impact de la repre'sentation des
exemples sur la performance, nous aVons fait Varier la taille des contextes aussi bien que les
attributs utilise's pour repre’senter les exemples. Ces exemples serVent a apprendre
automatiquement des regles qui corrigent l’e’tiquette du mot en fonction de son contexte. Ces
regles sont applique'es a la suite des regles contextuelles existantes.

2.1 Apprentissage actif

Nous calculons une mesure de distance entre chaque couple d’eXemples. Puis, un ensemble
initial d'eXemples est se'lectionne' puis annote'. A partir de cet ensemble, nous apprenons un
modele. A chaque ite'ration, un nouVel ensemble d’eXemples pertinents est se'lectionne' puis
annote'. La strate'gie de se'lection est base'e sur la conﬁance et la diVersite'. Chaque e'tape est
de'taille'e dans les sections suiVantes.

2.1.1 Mesure de distance entre deux exemples

Chaque exemple est repre'sente' comme suit: le mot cible est pris dans une fenétre de n mots de
chaque cote’. Chaque mot est repre’sente' par un ensemble d’attributs correspondant a son
e'tiquette morphosyntaxique et a ses caracte’ristiques morphologiques. Soit l’eXemple x
repre'sente' comme suit, ou (in =2n+I) est le nombre d’attributs et VW est la Valeur de l’attribut
qui est a la position y de l’eXemple x.

Exemple XI [Vxrn  _(n_1)  Vx,0  Vx,(n_1) 

La mesure globale de distance entre deux exemples A et B (G_dlSt(CXA,CX]3)) est base'e sur les
distances ((L_distWA,k,VB,k))) entre les Valeurs de chaque attribut. Pour chaque attribut (k),
nous comparons ses Valeurs WA,k and VB,k) dans les exemples: si les Valeurs sont e'gales alors
la distance est de 0; si les Valeurs sont diffe'rentes alors la distance est de I.

si (VA,k = Vgk) alors L_dz'st(V,,Yk, Vgyk) = 0, Si (V/11.: = Vgyk) alors L_dz'st(V,,Yk, Vgyk) = 1

La mesure globale de distance (G_dist) entre deux exemples A (ex,4) et B (exg) est calcule'e
comme suit, ou Wk sont les poids donne's aux attributs de sorte que les attributs des mots les
plus pres du mot central soient les plus importants dans la mesure:

387

388

Amrani A, Kodratoﬁ’ Y et Matte-Tailliez O

n

ZW, * L _ dz'st(VA)k, V3,)
G _ dist(exA , exB) = "=‘"

2.1.2 Stratégie de sélection des exemples

Tout d’abord, nous se'lectionnons un e’chantillon initial repre’sentatif de tous les exemples.
Pour ce faire, nous utilisons l’algorithme des k-moyennes (Jain et al, 1999; Tang et al., 2002).
Cet algorithme est base’ sur la mesure de distance de’ﬁnie pre’ce'demment. Nous obtenons un
ensemble compose’ de nbc groupes. Chaque groupe contient des exemples similaires.
L’e’chantillon initial est constitue' a partir d’une se'lection ale'atoire d’un pourcentage a
d’eXemples de chaque groupe. Cet e’chantillon nous sert a apprendre un modele initial.
Ensuite, les autres exemples sont se’lectionne's de maniere ite'ratiVe. A chaque ite'ration, nous
utilisons deux criteres pour la selection 2 la conﬁance et la diVersite'.

L’utilisation du critere de la conﬁance consiste a choisir les exemples pour lesquels le modele
courant n'est pas satisfaisant. L'incertitude du modele au sujet d'un exemple peut étre due au
fait que les exemples semblables sont sous-repre'sente's dans l'ensemble d’apprentissage, ou
bien que les exemples semblables sont intrinsequement complexes. Nous tirons proﬁt de la
disponibilite' de la conﬁance en classiﬁcation du modele courant. L'algorithme d'apprentissage
de regles (par exemple PART (Frank, Witten, 1998)) assigne un degre' de conﬁance a chaque
regle induite. Pour chaque exemple non annote', nous affectons le degre' de conﬁance de la
regle de laquelle il Ve’riﬁe les conditions.

Le but du critere de la diVersite' (Shen et al., 2004) est de maximiser l’utilite' inductive d’un
ensemble d’eXemples. Nous pre'fe'rons les ensembles d’eXemples he’te’rogenes. En choisissant
un nouVel exemple non annote', nous le comparons aVec tous les exemples pre’ce'demment
choisis dans l’ensemble courant. Si la similitude entre eux est au dessus d’un seuil B,
l’eXemple n’est pas ajoute' dans l’ensemble. De cette facon, nous e'Vitons de choisir les
exemples trop semblables (Valeur de similitude 2 B) dans un ensemble.

La strate'gie globale de se'lection des exemples est de'crite comme suit: les exemples non-
annote's sont ordonne's selon la conﬁance. A chaque ite'ration, nous choisissons un ensemble
de nb exemples de la maniere suiVante: D’abord, nous se'lectionnons un exemple candidat
(Exemplei) aVec une Valeur de conﬁance minimale. Ensuite, nous e'Valuons le critere de
diVersite' et nous aj outons l’eXemple candidat Exemplei a l’ensemble si seulement Exemple; est
assez different de n’importe quel exemple pre'ce'demment inse're' dans l’ensemble. Le seuil [3
est ﬁXe' a une Valeur comprise entre la Valeur maximale de similitude et la moyenne des
similitudes par paires dans l’ensemble des exemples non annote's.

3 Validation expérimentale
Pour les eXpe’rimentations, nous aVons utilise’ un corpus de 600 resumes d’articles MEDLINE

(Armani et al, 2004) de biologie mole'culaire. Ce corpus a été e'tiquete' par l’e'tiqueteur de Brill,
puis par ETIQ. A partir de ce corpus, nous aVons pre'sente' a l’annotateur 4133 exemples ou le

Induction de régles de correction pour I ’étiquetage morphosyntaxique

mot cible est e'tiquete' VBN et 3298 exemples ou le mot cible est e'tiquete' NNS. Le nombre
total d’exemples NNS e'tait de 7708 dont 4410 sont des mots non-ambigus. L’annotateur a
classe' les mots cibles en VBN, JJ ou VBD pour le premier jeu d’exemples et NNS ou VBZ
pour le deuxieme jeu. Pour ame’liorer la pre’cision, nous aVons repre'sente' les exemples comme
suit 2 pour le cas des VBN, le mot cible est pris dans une fenétre de 10 mots (5 mots a gauche
et 5 mots a droite) et chaque mot du contexte est repre’sente' par 2 son e'tiquette
morphosyntaxique, le groupe auquel appartient son e’tiquette (Verbal, nominal ou autre) et le
mot est un Verbe auxiliaire ou non. Pour le cas des NNS, le mot cible est pris dans une fenétre
de 6 mots 2 3 mots a droite et 3 mots a gauche. En plus des attributs utilise's pour repre'senter
les exemples des VBN, nous aVons utilise’ les suffixes et les preﬁxes les plus frequents des
mots. A partir de ces exemples, nous aVons induit des regles aVec les algorithmes PART (pour
les VBN) et RIPPER (pour les NNS). Nous aVons calcule' les pre’cisions de l’e'tiqueteur de
Brill, d’ETIQ et d’ETIQ enrichi par les regles induites (Voir Figure 1). La pre'cision des regles
induites a été calcule'e par la me'thode <<Validation croise'e 10 fois>>.

Confusion / %de pre'cision Brill Brill+ ETIQ Brill+ ETIQ+Regles induites
VBN9VBN-VBD-JJ (PART) 54 76 94
NNS9NNS-VBZ (RIPPER) 92 96 97,5

Figure 1 2 Pre’cisions obtenues sur deux jeux d’exemples de confusions d’e'tiquettes.

Nous aVons applique’ la strate'gie de l’apprentissage actif aux exemples correspondent a
l’ambigu'1'te’ VBN-VBD-JJ. Parmi les 4133 exemples disponibles, nous aVons pris 3100
exemples pour l’apprentissage actif, et 1033 exemples pour le test. Le modele initial a été
construit a partir de 423 exemples. A chaque ite'ration, nous aVons se'lectionne' 100 exemples.
L’expe'rience a été re'pe'te'e 5 fois. La courbe (figure 2) repre’sente les Valeurs moyennes
obtenues. La pre'cision obtenue aVec tous les exemples (3100) est de 93,5.

1—I—Apprentissage actif —A—Sé|ection aléatoire - - -X- - -Apprentissage supervisé 1

Précision (%)

 

443 543 643 743 843 943 1043 1 143 1243 1343 1443

Nombre d’exemp|es sélectionnés

Figure 2 2 Apprentissage actif versus se'lection ale’atoire.

4 Conclusions et perspectives

Dans le cadre d’une me’thodologie globale pour l’e’tiquetage morphosyntaxique des corpus de
spe'cialite', nous aVons complete notre approche pour traiter efficacement les problemes

389

390

Amrani A, Kodratoﬁ’ Y et Matte-Tailliez O

d’e'tiquetage pointus. Apres la de'tection des contextes ambigus et particuliers, les mots cibles
sont annote's (exemples). A partir de ces exemples, nous avons induit des regles de correction.
Nous avons obtenu une nette ame'lioration de la pre'cision d’e’tiquetage. Pour re'duire le
nombre d’eXemples a annoter, nous avons utilise’ l’apprentissage actif avec une strate'gie de
se'lection base'e sur la confiance et la diversite'. En annotant seulement un tiers des exemples,
nous obtenons des performances e'quivalentes a celles obtenues en annotant tous les exemples.
Nous e'tendrons cette approche a d’autres classes d’ambigu'1'te's. Nous envisageons e'galement
de conside'rer d’autres me’thodes d’apprentissage, par exemplez la Programmation Logique
Inductive. La combinaison optimale des regles obtenues par diffe’rents algorithmes pourrait
ame’liorer les performances. Le critere de diversite', utilise’ pour l’apprentissage actif, peut étre
ame’liore' en utilisant une valeur de similitudes ([3) optimale.

Références

AMRAN1, A., AZE, J., KODRATOFF, Y. (2005) ETIQ: Logiciel d'aide a l'e’tiquetage morpho-
syntaxique de textes de spe’cialite'. Dans la revue RN T I, numéro spécial EGC’2005.

AMRANI, A., KODRATOFF, Y., MATTE-TAILLIEZ, O. (2004) A Semi-automatic System for
Tagging Specialized Corpora, PAKDD 2004, Sydney, LNAI, Vol. 3056, pp 670-681.

BRILL, E. (1994) Some Advances in Transformation-Based Part of Speech Tagging, AAAI,
Vol. 1, pp 722-727.

COHEN, W. (1995) Fast Effective Rule Induction, Proceedings of the 12”’ International
Conference on Machine Learning.

ENGELSON, S.A., DAGAN, I. (1999) Committee-Based Sample Selection for Probabilistic
Classifiers. Journal of Artifical Intel-ligence Research.

FRANK, E., WITTEN, I.H. (1998) Generating Accurate Rule Sets Without Global Optimization,
Shavlik, J . Eds., Proceedings of the 15”’ ICML, Madison, Wisconsin, pp 144-151.

JAIN, A. K., MURTY, M. N., AND FLYNN, P. J. Data clustering: a review. ACM Computing
Surveys, 31(3):264-323.

PAROUBEK, P., RAJMAN, M. (2000) Chapitre 5: Etiquetage morpho-syntaxique, Inge’nierie des
Langues, sous la direction de Jean-Marie Pierrel, Collection "Information Commande
Communication", aux Editions Hermes Science, 2000 pp 131-148.

QUINLAN, J .R (1993) C4.5.' Programs for Machine Learning, Morgan Kaufmann San Mateo.

SHEN, D., ZHANG, J ., SU, J., ZHoU, G., TAN, C-L. (2004) Multi-Criteria-based Active
Learning for Named Entity Recognition. Proceedings of ACL 2004.

TANG, M., LUO, X., ROUKOS, S., 2002. Active Learning for Statistical Natural Language
Parsing. In Proceedings of the ACL 2002.

VALLI, A., & VERONIS, J . (1999). Etiquetage grammatical de corpus orauxz problemes et
perspectives. Revue Francaise de Linguistique Appliquée, IV(2), 113-133.

