<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Apprentissage de relations pr&#233;dicat-argument pour l'extraction d'information &#224; partir de textes conversationnels</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2005, Dourdan, 6&#8211;10 juin 2005
</p>
<p>Apprentissage de relations pr&#233;dicat-argument pour
l&#8217;extraction d&#8217;information &#224; partir de textes conversationnels
</p>
<p>Narj&#232;s Boufaden (1), Guy Lapalme (1)
(1) RALI - Universit&#233; de Montr&#233;al
</p>
<p>D&#233;partement d&#8217;Informatique et de Recherche Op&#233;rationnelle
Universit&#233; de Montr&#233;al
</p>
<p>C.P. 6128, succ. Centre-Ville
Montr&#233;al, Qu&#233;bec, H3C 3J7 Canada
</p>
<p>{boufaden,lapalme}@iro.umontreal.ca
</p>
<p>Mots-clefs : Apprentissage de relations pr&#233;dicat-argument, extraction d&#8217;information
Keywords: Learning predicat-argument relations, information extraction
</p>
<p>R&#233;sum&#233; Nous pr&#233;sentons les r&#233;sultats de notre approche d&#8217;apprentissage de relations
pr&#233;dicat-argument dans le but de g&#233;n&#233;rer des patrons d&#8217;extraction pour des textes conversation-
nels. Notre approche s&#8217;effectue en trois &#233;tapes incluant la segmentation linguistique des textes
pour d&#233;finir des unit&#233;s linguistiques &#224; l&#8217;instar de la phrase pour les textes bien form&#233;s tels que
les d&#233;p&#234;ches journalistiques. Cette &#233;tape prend en consid&#233;ration la dimension discursive impor-
tante dans ces types de textes. La deuxi&#232;me &#233;tape effectue la r&#233;solution des anaphores pronom-
inales en position de sujet. Cela tient compte d&#8217;une particularit&#233; importante des textes conver-
sationnels : la pronominalisation du th&#232;me. Nous montrons que la r&#233;solution d&#8217;un sous ensem-
ble d&#8217;anaphores pronominales am&#233;liore l&#8217;apprentissage des patrons d&#8217;extraction. La troisi&#232;me
utilise des mod&#232;les de Markov pour mod&#233;liser les s&#233;quences de classes de mots et leurs r&#244;les
pour un ensemble de relations donn&#233;es. Notre approche exp&#233;riment&#233;e sur des transcriptions de
conversations t&#233;l&#233;phoniques dans le domaine de la recherche et sauvetage identifie les patrons
d&#8217;extraction avec un F-score moyen de 73,75 %.
</p>
<p>Abstract We present the results of our approach for the learning of patterns for infor-
mation extraction from conversational texts. Our three step approach is based on a linguistic
segmentation stage that defines units suitable for the pattern learning process. Anaphora res-
olution helps to identify more relevant relations hidden by the pronominalization of the topic.
This stage precedes the pattern learning stage, which is based on Markov models that include
wild card states designed to handle edited words and null transitions to handle omissions. We
tested our approach on manually transcribed telephone conversations in the domain of maritime
search and rescue, and succeeded in identifying extraction patterns with an F-score of 73.75 %.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Narj&#232;s Boufaden, Guy Lapalme
</p>
<p>1 Introduction
</p>
<p>Nous pr&#233;sentons notre approche d&#8217;apprentissage de patrons dans le contexte de l&#8217;extraction
d&#8217;information &#224; partir de textes conversationnels sp&#233;cialis&#233;s. Cette &#233;tape est la derni&#232;re de
notre approche propos&#233;e pour l&#8217;extraction d&#8217;information &#224; partir de ces textes que nous avons
pr&#233;sent&#233;e dans nos travaux pr&#233;c&#233;dents (Boufaden et al., 2002; Boufaden et al., 2005). Nous pro-
posons une mod&#233;lisation utilisant des mod&#232;les de Markov pour apprendre des relations pr&#233;dicat-
argument (s&#233;quences de classes s&#233;mantiques &#233;tiquetant le verbe et ses arguments) et les r&#244;les1
des arguments &#224; partir de textes &#233;tiquet&#233;s s&#233;mantiquement. Ces textes sont des transcriptions2
manuelles de conversations t&#233;l&#233;phoniques portant sur des incidents survenus en mer. Ce sont des
compte rendus o&#249; les locuteurs se communiquent des informations sur un incident, par exemple
un bateau en difficult&#233;, sur les conditions m&#233;t&#233;orologiques lors d&#8217;une mission de recherche ou
sur le lieu de l&#8217;incident. Un exemple de conversation est donn&#233; au tableau 1.
</p>
<p>Le syst&#232;me repose sur trois &#233;tapes et prend en entr&#233;e des s&#233;quences de classes s&#233;mantiques &#233;ti-
quetant les mots cl&#233; des &#233;nonc&#233;s o&#249; les &#233;tiquettes sont d&#233;finies dans une ontologie du domaine.
La premi&#232;re &#233;tape segmente les conversations en unit&#233;s linguistiques &#224; l&#8217;instar de la phrase pour
les textes bien form&#233;s tels que les d&#233;p&#234;ches journalistiques (section 2.1). Cette &#233;tape prend en
consid&#233;ration la dimension discursive tr&#232;s importante dans ce types de textes (Levelt, 1989). La
deuxi&#232;me effectue la r&#233;solution des anaphores pronominales en position de sujet (section 2.2).
Cette &#233;tape tient compte d&#8217;une particularit&#233; des textes conversationnels : la pronominalisation
du th&#232;me. Nous montrons que la r&#233;solution d&#8217;un sous ensemble des anaphores pronominales
am&#233;liore l&#8217;apprentissage des patrons d&#8217;extraction. La troisi&#232;me utilise les mod&#232;les de Markov
pour mod&#233;liser les s&#233;quences de classes de mots et leurs r&#244;les pour un ensemble de relations
donn&#233;es (section 3). La comparaison de notre approche avec celles d&#233;velopp&#233;es pour les textes
bien form&#233;s montrent la pertinence de notre approche (section 4).
</p>
<p>2 Probl&#233;matique de l&#8217;apprentissage des patrons d&#8217;extraction
</p>
<p>Un patron d&#8217;extraction est une structure qui permet le rep&#233;rage des informations que nous
voulons extraire et &#233;tablit une relation entre ces &#233;l&#233;ments d&#8217;information. Il se caract&#233;rise par
des contraintes syntaxiques (position des arguments dans une relation sujet-verbe-objet) et s&#233;-
mantiques (type de classes s&#233;mantiques) permettant le filtrage d&#8217;un sous-ensemble d&#8217;&#233;nonc&#233;s
qui contiennent des informations pertinentes au domaine d&#8217;application. Parmi les principales
difficult&#233;s de l&#8217;apprentissage des patrons d&#8217;extraction &#224; partir de textes bien form&#233;s mentionn&#233;s
dans la litt&#233;rature (Grishman, 1998; Surdeanu et al., 2003), nous retenons: (1) la diversit&#233; des
constructions phrastiques contenant l&#8217;information pertinente et (2) l&#8217;association de nouveaux
&#233;l&#233;ments d&#8217;information &#224; des objets r&#233;f&#233;renc&#233;s par une anaphore.
Dans le contexte des textes conversationnels, ces difficult&#233;s sont amplifi&#233;es. D&#8217;une part, les ir-
r&#233;gularit&#233;s langagi&#232;res telles que les r&#233;p&#233;titions et les reprises modifient la structure syntaxique
des &#233;nonc&#233;s, tandis que l&#8217;aspect conversationnel a pour effet de r&#233;partir l&#8217;information sur plus
d&#8217;un &#233;nonc&#233;, par exemple lors d&#8217;&#233;changes de type question-r&#233;ponse. D&#8217;autre part, la pr&#233;sence
importante de pronoms notamment &#224; l&#8217;int&#233;rieur des unit&#233;s th&#233;matiques augmente le nombre de
</p>
<p>1Un r&#244;le est un nom de champ d&#233;fini dans un formulaire.
2Ces textes ont &#233;t&#233; fournis par le Centre de Recherche de la d&#233;fense Canadienne. Ils ne sont pas annot&#233;s
</p>
<p>prosodiquement et nous n&#8217;avions pas les enregistrements originaux pour reconstituer la prosodie.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Apprentissage de relations pr&#233;dicat-argument
</p>
<p>No Loc &#201;nonc&#233;
4 b: ha, Ha, I don&#8217;t know if I was handled over
</p>
<p>to you at all, but we&#8217;ve got an overdue boat
VESSEL
</p>
<p>on the South Coast of Newfoundland
LOCATION
</p>
<p>, just in
the area quite between Fortune Bay and Trepassey
</p>
<p>LOCATION
</p>
<p>.
</p>
<p>...................................Incident ...................................
5 b: it&#8217;s on the south east coast of Newfoundland
</p>
<p>LOCATION
.
</p>
<p>...................................Incident ...................................
6 b: this is been going on for, for 24 hours
</p>
<p>TIME
that the case has,
</p>
<p>or almost anyway, and we had an DFO King Air
AIRCRAFT
</p>
<p>up flying
STATUS
</p>
<p>this morning
TIME
</p>
<p>.
</p>
<p>.................................Search-unit .................................
7 b: they did
</p>
<p>STATUS
a radar search
MEANSOFDETECTION
</p>
<p>for us in that area
LOCATION
</p>
<p>.
</p>
<p>8 a: yes.
.................................Search-unit .................................
</p>
<p>Table 1: Exemple de conversation dans le domaine de Recherche et sauvetage. Les mots
soulign&#233;s sont les informations que nous voulons extraire. Les &#233;tiquettes sous les barres en
soulign&#233;s sont des classes de mots importants. Les pointill&#233;s sont les fronti&#232;res des unit&#233;s lin-
guistiques que nous d&#233;tectons dans la section (2.1). Incident et Search-unit sont des exemples
de relations que nous voulons mod&#233;liser par des mod&#232;les de Markov.
</p>
<p>relations partielles (par opposition &#224; une relation compl&#232;te o&#249; tous les arguments sont d&#233;finis).
L&#8217;approche que nous proposons tient compte de ses difficult&#233;s. Tout d&#8217;abord, nous effectuons
une segmentation en paires d&#8217;adjacence3 qui d&#233;tecte, par exemple, les paires de type question-
r&#233;ponse pour repgrouper dans une seule unit&#233; linguistique les &#233;l&#233;ments d&#8217;information pr&#233;sents
dans une question et sa r&#233;ponse. Ensuite, nous proc&#233;dons &#224; la r&#233;solution des anaphores pronomi-
nales en position de sujet pour diminuer le nombre des relations partielles. Enfin, nous relaxons
la contrainte de contiguit&#233; des arguments de la relation &#8220;sujet-verbe-objet&#8221;, en apprenant les
patrons &#224; partir de s&#233;quences d&#8217;&#233;tiquettes s&#233;mantiques de longueur variable.
</p>
<p>2.1 Segmentation en unit&#233;s linguistiques
</p>
<p>&#192; l&#8217;instar des travaux en segmentation linguistique de conversations (Stolcke, 1997), nous avons
utilis&#233; un mod&#232;le de Markov d&#8217;ordre 1 pour mod&#233;liser des s&#233;quences de traits compos&#233;s de mar-
ques lexicales telles que ok, well et ? caract&#233;ristiques des paires d&#8217;adjacence, mais aussi la
longueur d&#8217;un &#233;nonc&#233; ainsi que l&#8217;identit&#233; de locuteur. Contrairement aux approches propos&#233;es,
nous n&#8217;avons pas utilis&#233; la prosodie car celle-ci est absente de nos textes. Le mod&#232;le con-
tient deux &#233;tats repr&#233;sentant la classe des &#233;nonc&#233;s ind&#233;pendants (E) et la classe des &#233;nonc&#233;s
compl&#233;tant une paire d&#8217;adjacence (PA). Nous avons valid&#233; notre mod&#232;le en effectuant 10 vali-
dations crois&#233;es sur notre corpus contenant 64 conversations (3481 &#233;nonc&#233;s) avec 80 % r&#233;serv&#233;
</p>
<p>3Les paires d&#8217;adjacence sont deux tours de parole, chacun venant d&#8217;un locuteur distinct o&#249; le premier
tour n&#233;cessite un second tour de parole d&#8217;un certain type (source http://www.sil.org/linguistics/
GlossaryOfLinguisticTerms/).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Narj&#232;s Boufaden, Guy Lapalme
</p>
<p>&#224; l&#8217;entra&#238;nement. La moyenne des erreurs de classification obtenue &#224; partir des 10 validations
crois&#233;es est de 15,9 %. L&#8217;analyse des erreurs de classification a montr&#233; que la source princi-
pale des erreurs est due &#224; l&#8217;absence de marques lexicales pour certains &#233;nonc&#233;s de la classe PA.
Dans ces cas, l&#8217;information prosodique absente dans nos transcriptions permettrait de combler
le manque d&#8217;information lexicale.
</p>
<p>2.2 R&#233;solution des anaphores pronominales
</p>
<p>Nous nous int&#233;ressons aux anaphores pronominales they, we, she, he et it en position
de sujet4. Notre approche se base sur la structure th&#233;matique des conversations et sur une
liste des &#233;tiquettes s&#233;mantiques5 extraites &#224; partir de chaque &#233;nonc&#233; d&#8217;une unit&#233; th&#233;matique.
L&#8217;importance de la structure th&#233;matique a d&#233;j&#224; &#233;t&#233; soulign&#233;e pour la r&#233;solution des cor&#233;f&#233;rences
dans les conversations (Grosz et al., 1995).
Le choix d&#8217;un ant&#233;c&#233;dent est dirig&#233; par deux contraintes de compatibilit&#233;: s&#233;mantique et th&#233;-
matique. La premi&#232;re fixe des associations possibles entre les &#233;tiquettes s&#233;mantiques et les
pronoms. Tandis que la seconde fournie un ant&#233;c&#233;dent par d&#233;faut, lorsqu&#8217;aucun ant&#233;c&#233;dent
compatible avec l&#8217;anaphore n&#8217;a &#233;t&#233; d&#233;tect&#233; dans les &#233;nonc&#233;s pr&#233;c&#233;dents de l&#8217;unit&#233; th&#233;matique
courante ou de la pr&#233;c&#233;dente portant sur le m&#234;me th&#232;me. Les valeurs par d&#233;faut sont les &#233;ti-
quettes les plus fr&#233;quentes calcul&#233;es sur 31 conversations du corpus.
</p>
<p>L&#8217;&#233;valuation de notre approche a &#233;t&#233; effectu&#233;e sur 31 conversations de notre corpus, soit 161
anaphores pronominales en position de sujet. Le taux moyen d&#8217;erreurs de r&#233;solution obtenu
est de 79,5 %. Bien que le r&#233;sultat soit encourageant, certains choix de notre approche ont
contribu&#233; &#224; augmenter le taux d&#8217;erreurs, en particulier, le choix d&#8217;une approche lin&#233;aire (non
hi&#233;rarchique) de segmentation en unit&#233;s th&#233;matiques (Boufaden et al., 2002) dans la segmenta-
tion automatique et la simplicit&#233; de notre approche dans le calcul des ant&#233;c&#233;dents par d&#233;faut qui
se base sur les fr&#233;quences obtenues sur le corpus.
</p>
<p>3 Apprentissage des patrons d&#8217;extraction
</p>
<p>Le but de cette &#233;tape est d&#8217;exploiter les associations entre les &#233;tiquettes s&#233;mantiques afin d&#8217;apprendre
des patrons d&#8217;extraction qui expriment une relation pr&#233;dicat-argument o&#249; les arguments ont un
r&#244;le sp&#233;cifique pour une relation donn&#233;e. Des exemples d&#8217;&#233;tiquettes s&#233;mantiques utilis&#233;es sont
pr&#233;sent&#233;es dans l&#8217;extrait de conversation du tableau 1.
</p>
<p>3.1 Approche
</p>
<p>Nous avons consid&#233;r&#233; cinq relations dans nos exp&#233;riences:
</p>
<p>1. Missing-object qui d&#233;crit Le bateau en difficult&#233;, c&#8217;est-&#224;-dire sa description, le nom de
son propri&#233;taire.
</p>
<p>2. Incident qui d&#233;crit le type d&#8217;incident, la cause, le type d&#8217;appel de d&#233;tresse.
4Levelt (Levelt, 1989), montre que les pronoms position de sujet sont souvent le r&#233;sultat de la pronominalisation
</p>
<p>du th&#232;me d&#8217;une unit&#233; th&#233;matique.
5La structure th&#233;matique et les &#233;tiquettes s&#233;mantiques sont g&#233;n&#233;r&#233;es de mani&#232;re automatique par des syst&#232;mes
</p>
<p>d&#233;velopp&#233;s dans nos travaux pr&#233;c&#233;dents (Boufaden et al., 2005).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Apprentissage de relations pr&#233;dicat-argument
</p>
<p>Sch&#233;mas d&#8217;extraction Mod&#232;le de Markov Rappel Pr&#233;cision F-score
Incident (62
&#233;nonc&#233;s)
</p>
<p>Ordre 1 59,0 % 79,6 %
Ordre 2 63,8 % 85,0 % 72,9 %
</p>
<p>Search-mission (27
&#233;nonc&#233;s)
</p>
<p>Ordre 1 79,0 % 89,5 % 83,9 %
Ordre 2 70,7 % 81,4 %
</p>
<p>Search-unit (93
&#233;nonc&#233;s)
</p>
<p>Ordre 1 53,3 % 75,2 %
Ordre 2 52,9 % 76,9 % 62.7 %
</p>
<p>Missing-object (38
&#233;nonc&#233;s)
</p>
<p>Ordre 1 54,4 % 71,7 %
Ordre 2 70,8 % 80,8 % 75,5 %
</p>
<p>Table 2: Rappel, pr&#233;cision et F-score de l&#8217;apprentissage des patrons d&#8217;extraction pour les for-
mulaires Incident, Mission, Search-unit et Missing-object. Le rappel et la pr&#233;cision sont obtenus
par la m&#233;thode de validation crois&#233;e &#8220;Leaving one out&#8221; pour les deux mod&#232;les de Markov. Le
F-score est la moyenne des F-scores du meilleur mod&#232;le.
</p>
<p>3. Search-unit qui parle de la ressource utilis&#233;e dans une mission de recherche.
</p>
<p>4. Mission qui d&#233;crit le lieu de la mission, les conditions m&#233;t&#233;orologiques, la date.
</p>
<p>Pour chaque type de relation, nous avons mod&#233;lis&#233; les s&#233;quences des &#233;tiquettes avec un mod&#232;le
de Markov. Nous avons entra&#238;n&#233; chaque mod&#232;le sur un sous-ensemble du corpus qui contient
des exemples positifs du type de relation cibl&#233;e.
</p>
<p>3.2 Exp&#233;riences et r&#233;sultats
</p>
<p>Nous avons effectu&#233; deux exp&#233;riences afin de d&#233;terminer l&#8217;ordre du mod&#232;le de Markov qui
donne les meilleures performances pour chaque patron d&#8217;extraction. Nous avons test&#233; un mod-
&#232;le de Markov d&#8217;ordre 1 et un mod&#232;le d&#8217;ordre 2. &#201;tant donn&#233; la taille modeste des corpus
d&#8217;entra&#238;nement (&lt;100) pour les diff&#233;rents patrons d&#8217;extraction, nous avons opt&#233; pour une val-
idation crois&#233;e avec l&#8217;approche &#8220;Leaving one out&#8221;. Les rappels6, pr&#233;cisions et F-scores des
meilleures performances sont indiqu&#233;es au tableau 2.
</p>
<p>Nous constatons que le patron d&#8217;extraction associ&#233; &#224; la relation Search-mission pr&#233;sente une
meilleure performance avec le mod&#232;le de Markov d&#8217;ordre 1, tandis que les autres patrons
d&#8217;extraction Missing-object, Incident et Search-unit montrent de meilleurs r&#233;sultats avec les
mod&#232;les d&#8217;ordre 2.
</p>
<p>Le choix de l&#8217;ordre du mod&#232;le d&#233;pend du taux des &#233;tiquettes s&#233;mantiques ayant plusieurs
r&#244;les possibles. Par exemple, dans l&#8217;unit&#233; th&#233;matique Mission, l&#8217;&#233;tiquette la plus fr&#233;quente est
WEATHER-CONDITIONS avec une fr&#233;quence relative de 37,7 %. Cette derni&#232;re a un seul r&#244;le
dans la relation Mission, contrairement &#224; l&#8217;&#233;tiquette NUMBER qui peut avoir le r&#244;le d&#8217;une date
ou d&#8217;une position g&#233;ographique (en degr&#233; par exemple). Le choix de l&#8217;ordre d&#233;pend &#233;galement
du bruit introduit par les irr&#233;gularit&#233;s langagi&#232;res, notamment les reprises, agrandit la taille du
contexte n&#233;cessaire pour d&#233;sambigu&#239;ser un r&#244;le.
</p>
<p>6Le rappel correspond au nombre de r&#244;les corrects g&#233;n&#233;r&#233;s par le syst&#232;me sur le nombre de r&#244;les dans le corpus
de test, tandis que la pr&#233;cision est le nombre de r&#244;les corrects g&#233;n&#233;r&#233;s par le syst&#232;me sur le nombre de r&#244;les qu&#8217;il
fournit.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Narj&#232;s Boufaden, Guy Lapalme
</p>
<p>4 Conclusion
</p>
<p>Nous avons analys&#233; la probl&#233;matique de l&#8217;apprentissage des patrons d&#8217;extraction pour des textes
complexes peu &#233;tudi&#233;s en EI: les transcriptions de conversations. Nous avons mod&#233;lis&#233; les
patrons d&#8217;extraction par des mod&#232;les de Markov qui associent des r&#244;les aux arguments des
pr&#233;dicats avec un F-score de 73,75 %. Bien que les mod&#232;les de Markov aient &#233;t&#233; utilis&#233;s pour
l&#8217;apprentissage de patrons (Seymore et al., 1999), peu de travaux les ont utilis&#233;s pour apprendre
les r&#244;les s&#233;mantiques. De ces travaux, nous retenons ceux de Gildea (Gildea &amp; Palmer, 2002)
effectu&#233;s sur des textes journalistiques avec un F-score de 82 %. D&#8217;autres approches ont &#233;t&#233;
utilis&#233;es, notamment les arbres de d&#233;cisions sur des textes bien form&#233;s avec un F-score de
83,7 % (Surdeanu et al., 2003). Cependant, cette approche ne permet pas de tenir compte des
s&#233;quences de longueurs variables que l&#8217;on retrouve avec les textes conversationnels.
</p>
<p>Nous avons ajout&#233; une &#233;tape de r&#233;solution des anaphores pronominales en amont de l&#8217;&#233;tape
d&#8217;apprentissage de patrons. Notre approche a permis un taux de r&#233;solution des anaphores de
79,5 % am&#233;liorant ainsi le F-score moyen pour l&#8217;apprentissage de patrons de 68,6 %. Quelques
travaux Surdeanu (Surdeanu &amp; Harabagiu, 2002) ont utilis&#233; une approche similaire pour am&#233;liorer
l&#8217;extraction des informations en r&#233;solvant les cor&#233;f&#233;rences aux entit&#233;s nomm&#233;es.
</p>
<p>R&#233;f&#233;rences
BOUFADEN N., LAPALME G. &amp; BENGIO Y. (2002). D&#233;coupage th&#233;matique des conversations: un outil
d&#8217;aide &#224; l&#8217;extraction. In Actes de la 9 e conf&#233;rence annuelle sur le traitement automatique des langues
naturelles (TALN 2002), volume I, p. 377&#8211;382, Nancy, France.
BOUFADEN N., LAPALME G. &amp; BENGIO Y. (2005). Rep&#233;rage de mots informatifs &#224; partir de textes
conversationnels. Traitement Automatique de la Langue, 45(3).
GILDEA D. &amp; PALMER M. (2002). The necessity of syntactic parsing for predicate argument recog-
nition. In Proceedings of the 40th Annual Conference of the Association for Computational Linguistics
(ACL 2002), p. 239&#8211;246, Philadelphie, Pennsylvanie.
GRISHMAN R. (1998). Information extraction and speech recognition. In Proceedings of the DARPA
Broadcast Transcription and Understanding Workshop, Lansdowne, Virginie: Morgan Kaufmann Pub-
lishers.
GROSZ B., JOSHI A. &amp; WEINSTEIN S. (1995). Centering: A Framework for Modeling the local Co-
herence of Discourse. Computational Linguistics, 21(2), 203&#8211;225.
LEVELT W. J. M. (1989). Speaking: From Intention to Articulation. ACL-MIT Press Series in Natural
Language Processing. MIT Press.
SEYMORE K., MCCALLUM A. &amp; ROSENFELD R. (1999). Learning hidden Markov structure for in-
formation extraction. In Proceedings of the AAAI-99 Workshop on Machine Learning for Information
Extraction, p. 37&#8211;42, Orlando, Floride.
STOLCKE A. (1997). Modeling linguistic segment and turn boundaries for n-best rescoring of sponta-
neous speech. In Proceedings of EUROSPEECH 1997, volume 5, p. 2779&#8211;2782, Rhodes, Gr&#232;ce.
SURDEANU M., HARABAGIU S., WILLIAMS J. &amp; AARSETH P. (2003). Using predicate-argument
structures for information extraction. In E. HINRICHS &amp; D. ROTH, Eds., Proceedings of ACL 2003, p.
8&#8211;15.
SURDEANU M. &amp; HARABAGIU S. M. (2002). Infrastructure for Open-Domain Information Extraction.
In M. MITCHELL, Ed., Proceedings of HLT 2002, p. 325&#8211;330, San Diego, Californie.</p>

</div></div>
</body></html>