TALN 2005, Dourdan, 6-10 juin 2005

Apprentissage de relations predicat-argument pour
l’extraction d’information a partir de textes conversationnels

Narjes Boufaden (1), Guy Lapalme (1)

(1) RALI — Universite de Montreal
Departement d’Informatique et de Recherche Operationnelle
Universite de Montreal
C.P. 6128, succ. Centre—Ville
Montreal, Quebec, H3C 3J7 Canada
{boufaden,lapalme} @ iro.umontreal.ca

Mots-clefs :

Apprentissage de relations predicat—argument, extraction d’information

K€yWOFdS2 Learning predicat—argument relations, information extraction

Resume Nous presentons les resultats de notre approche d’apprentissage de relations
predicat—argument dans le but de generer des patrons d’extraction pour des textes conversation-
nels. Notre approche s’effectue en trois etapes incluant la segmentation linguistique des textes
pour deﬁnir des unites linguistiques a l’instar de la phrase pour les textes bien formes tels que
les depéches joumalistiques. Cette etape prend en consideration la dimension discursive impor-
tante dans ces types de textes. La deuxieme etape effectue la resolution des anaphores pronom—
inales en position de sujet. Cela tient compte d’une particularite importante des textes conver-
sationnels : la pronominalisation du theme. Nous montrons que la resolution d’un sous ensem-
ble d’anaphores pronominales ameliore l’apprentissage des patrons d’extraction. La troisieme
utilise des modeles de Markov pour modeliser les sequences de classes de mots et leurs roles
pour un ensemble de relations donnees. Notre approche experimentee sur des transcriptions de
conversations telephoniques dans le domaine de la recherche et sauvetage identiﬁe les patrons
d’extraction avec un F—score moyen de 73,75 %.

AbStI‘.‘:lCt We present the results of our approach for the learning of patterns for infor-
mation extraction from conversational texts. Our three step approach is based on a linguistic
segmentation stage that deﬁnes units suitable for the pattern learning process. Anaphora res-
olution helps to identify more relevant relations hidden by the pronominalization of the topic.
This stage precedes the pattern learning stage, which is based on Markov models that include
wild card states designed to handle edited words and null transitions to handle omissions. We
tested our approach on manually transcribed telephone conversations in the domain of maritime
search and rescue, and succeeded in identifying extraction patterns with an F—score of 73.75 %.

397

398

Narjes Boufaden, Guy Lapalme

1 Introduction

Nous presentons notre approche d’apprentissage de patrons dans le contexte de l’extraction
d’information a partir de textes conversationnels specialises. Cette etape est la demiere de
notre approche proposee pour l’extraction d’information a partir de ces textes que nous avons
presentee dans nos travaux precedents (Boufaden er al., 2002; Boufaden er al., 2005). Nous pro-
posons une modelisation utilisant des modeles de Markov pour apprendre des relations predicat-
argument (sequences de classes semantiques etiquetant le verbe et ses arguments) et les rolesl
des arguments a partir de textes etiquetes semantiquement. Ces textes sont des transcriptionsz
manuelles de conversations telephoniques portant sur des incidents survenus en mer. Ce sont des
compte rendus ou les locuteurs se communiquent des informations sur un incident, par exemple
un bateau en difﬁculte, sur les conditions meteorologiques lors d’une mission de recherche ou
sur le lieu de l’incident. Un exemple de conversation est donne au tableau 1.

Le systeme repose sur trois etapes et prend en entree des sequences de classes semantiques eti-
quetant les mots cle des enonces ou les etiquettes sont deﬁnies dans une ontologie du domaine.
La premiere etape segmente les conversations en unites linguistiques a l’instar de la phrase pour
les textes bien formes tels que les depéches journalistiques (section 2.1). Cette etape prend en
consideration la dimension discursive tres importante dans ce types de textes (Levelt, 1989). La
deuxieme effectue la resolution des anaphores pronominales en position de sujet (section 2.2).
Cette etape tient compte d’une particularite des textes conversationnels : la pronominalisation
du theme. Nous montrons que la resolution d’un sous ensemble des anaphores pronominales
arneliore l’apprentissage des patrons d’extraction. La troisieme utilise les modeles de Markov
pour modeliser les sequences de classes de mots et leurs roles pour un ensemble de relations
donnees (section 3). La comparaison de notre approche avec celles developpees pour les textes
bien formes montrent la pertinence de notre approche (section 4).

2 Problématique de l’apprentissage des patrons d’eXtracti0n

Un patron d’extraction est une structure qui permet le reperage des informations que nous
voulons extraire et etablit une relation entre ces elements d’information. Il se caracterise par
des contraintes syntaxiques (position des arguments dans une relation sujet—verbe—objet) et se-
mantiques (type de classes semantiques) permettant le ﬁltrage d’un sous—ensemble d’enonces
qui contiennent des informations pertinentes au domaine d’application. Parmi les principales
difﬁcultes de l’apprentissage des patrons d’extraction a partir de textes bien formes mentionnes
dans la litterature (Grishman, 1998; Surdeanu er al., 2003), nous retenons: (1) la diversite des
constructions phrastiques contenant l’information pertinente et (2) l’association de nouveaux
elements d’information a des objets references par une anaphore.

Dans le contexte des textes conversationnels, ces difﬁcultes sont ampliﬁees. D’une part, les ir-
regularites langagieres telles que les repetitions et les reprises modiﬁent la structure syntaxique
des enonces, tandis que l’aspect conversationnel a pour effet de repartir l’information sur plus
d’un enonce, par exemple lors d’echanges de type question—reponse. D’autre part, la presence
importante de pronoms notamment a l’interieur des unites thematiques augmente le nombre de

1Un role est un nom de champ deﬁ ni dans un formulaire.
2Ces textes ont ete foumis par le Centre de Recherche de la defense Canadienne. Ils ne sont pas annotes
prosodiquement et nous n’avions pas les enregistrements originaux pour reconstituer la prosodie.

Apprentissage de relations predicat—argument

|NoLocEnonce

4 lo: ha, Ha, I don't know if I was handled over

to you at all, but we've got an overdue boat
VESSEL
on the South Coast of Newfoundland, just in
LOCATION
the area quite between Fortune Bay and Trepassey.
LOCATION

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ..Incident .n..H..n..”..H..H..H..H..n

5 b: it's on the south east coast of Newfoundland.
LOCATION

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ..Incident .n..H..n..”..H..H..H..H..n

6 b: this is been going on for, for 24 hours that the case has,
TIME
or almost anyway, and we had an DFO King Air up flying

AIRCRAFT

STATUS
this morning.
TIME
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ..Search—unit .”..H..n..H..H..H..n..n..
7 lo: they did a radar search for us in that area.
STATUS MEANSOFDETECTION LOCATION
8 a: yes.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ..Search—unit .”..H..n..H..H..H..n..n..

Table 1: Exemple de conversation dans le domaine de Recherche et sauvetage. Les mots
soulignes sont les informations que nous voulons extraire. Les etiquettes sous les barres en
soulignes sont des classes de mots importants. Les pointilles sont les frontieres des unites lin-
guistiques que nous detectons dans la section (2.1). Incident et Search—um't sont des exemples
de relations que nous voulons modeliser par des modeles de Markov.

relations partielles (par opposition a une relation complete on tous les arguments sont deﬁnis).
L’ approche que nous proposons tient compte de ses difﬁcultes. Tout d’abord, nous effectuons
une segmentation en paires d’adjacence3 qui detecte, par exemple, les paires de type question-
reponse pour repgrouper dans une seule unite linguistique les elements d’information presents
dans une question et sa reponse. Ensuite, nous procedons a la resolution des anaphores pronomi—
nales en position de sujet pour diminuer le nombre des relations partielles. Enﬁn, nous relaxons
la contrainte de contiguite des arguments de la relation “sujet—verbe—objet”, en apprenant les
patrons a partir de sequences d’etiquettes semantiques de longueur variable.

2.1 Segmentation en unités linguistiques

A l’instar des travaux en segmentation linguistique de conversations (Stolcke, 1997), nous avons
utilise un modele de Markov d’ordre 1 pour modeliser des sequences de traits composes de mar-
ques lexicales telles que ok, well et ? caracteristiques des paires d’adjacence, mais aussi la
longueur d’un enonce ainsi que l’identite de locuteur. Contrairement aux approches proposees,
nous n’avons pas utilise la prosodie car celle—ci est absente de nos textes. Le modele con-
tient deux etats representant la classe des enonces independants (E) et la classe des enonces
completant une paire d’adjacence (PA). Nous avons valide notre modele en effectuant 10 vali-
dations croisees sur notre corpus contenant 64 conversations (3481 enonces) avec 80 % reserve

3Les paires d’adjacence sont deux tours de parole, chacun venant d’un locuteur distinct on le premier
wurnammneunsmmndumrdepmob(Yuncmumiwpeaomcehttp://www.sil.org/linguistics/
GlossaryOfLinguisticTerms/)

399

Narjes Boufaden, Guy Lapalme

a l’entrainement. La moyenne des erreurs de classiﬁcation obtenue a partir des 10 validations
croisees est de 15,9 %. L’analyse des erreurs de classiﬁcation a montre que la source princi-
pale des erreurs est due a l’absence de marques lexicales pour certains enonces de la classe PA.
Dans ces cas, l’information prosodique absente dans nos transcriptions permettrait de combler
le manque d’information lexicale.

2.2 Resolution des anaphores pronominales

Nous nous interessons aux anaphores pronominales they, we, she, he et it en position
de sujet4. Notre approche se base sur la structure thematique des conversations et sur une
liste des etiquettes semantiques5 extraites a partir de chaque enonce d’une unite thematique.
L’ importance de la structure thematique a deja ete soulignee pour la resolution des coreferences
dans les conversations (Grosz er al., 1995).

Le choix d’un antecedent est dirige par deux contraintes de compatibilite: sémantique et the-
matique. La premiere ﬁxe des associations possibles entre les etiquettes semantiques et les
pronoms. Tandis que la seconde fournie un antecedent par defaut, lorsqu’aucun antecedent
compatible avec l’anaphore n’a ete detecte dans les enonces precedents de l’unite thematique
courante ou de la precedente portant sur le meme theme. Les valeurs par defaut sont les eti-
quettes les plus frequentes calculees sur 31 conversations du corpus.

L’ evaluation de notre approche a ete effectuee sur 31 conversations de notre corpus, soit 161
anaphores pronominales en position de sujet. Le taux moyen d’erreurs de resolution obtenu
est de 79,5 %. Bien que le resultat soit encourageant, certains choix de notre approche ont
contribue a augmenter le taux d’erreurs, en particulier, le choix d’une approche lineaire (non
hierarchique) de segmentation en unites thematiques (Boufaden er al., 2002) dans la segmenta-
tion automatique et la simplicite de notre approche dans le calcul des antecedents par defaut qui
se base sur les frequences obtenues sur le corpus.

3 Apprentissage des patrons d’extracti0n

Le but de cette etape est d’exploiter les associations entre les etiquettes semantiques aﬁn d’ apprendre
des patrons d’extraction qui expriment une relation predicat—argument ou les arguments ont un
role speciﬁque pour une relation donnee. Des exemples d’etiquettes semantiques utilisees sont
presentees dans l’extrait de conversation du tableau 1.

3.1 Approche

Nous avons considere cinq relations dans nos experiences:

1. Missing—0bject qui decrit Le bateau en difﬁculte, c’est—a—dire sa description, le nom de
son proprietaire.

2. Incident qui decrit le type d’incident, la cause, le type d’appel de detresse.

“Leve1t(Leve1t, 1989), montre que les pronoms position de suj et sont souvent 1e resultat de la pronominalisation
du theme d’une unite thematique.

5La structure thematique et les etiquettes semantiques sont generees de maniere automatique par des systemes
developpes dans nos travaux precedents (Boufaden et al., 2005).

400

Apprentissage de relations predicat—argument

Schemas d’extraction | Modele de Markov | Rappel | Precision | F—score |

Incident (62 Ordre 1 59,0 % 79,6 %
enonces) Ordre 2 63,8 % 85,0 % 72,9 %
Search—mission (27 Ordre 1 79,0 % 89,5 % 83,9 %
enonces) Ordre 2 70,7 % 81,4 %
Search—nnit (93 Ordre 1 53,3 % 75,2 %
enonces) Ordre 2 52,9 % 76,9 % 62.7 %
Missing—object (38 Ordre 1 54,4 % 71,7 %
enonces) Ordre 2 70,8 % 80,8 % 75,5 %

Table 2: Rappel, precision et F—score de l’apprentissage des patrons d’extraction pour les for-
mulaires Incident, Mission, Search—unit et Missing—object. Le rappel et la precision sont obtenus
par la methode de validation croisee “Leaving one out” pour les deux modeles de Markov. Le
F—score est la moyenne des F—scores du meilleur modele.

3. Search—unit qui parle de la ressource utilisee dans une mission de recherche.

4. Mission qui decrit le lieu de la mission, les conditions meteorologiques, la date.

Pour chaque type de relation, nous avons modelise les sequences des etiquettes avec un modele
de Markov. Nous avons entraine chaque modele sur un sous—ensemble du corpus qui contient
des exemples positifs du type de relation ciblee.

3.2 Experiences et resultats

Nous avons effectue deux experiences aﬁn de determiner l’ordre du modele de Markov qui
donne les meilleures performances pour chaque patron d’extraction. Nous avons teste un mod-
ele de Markov d’ordre 1 et un modele d’ordre 2. Etant donne la taille modeste des corpus
d’entrainement (<100) pour les differents patrons d’extraction, nous avons opte pour une val-
idation croisee avec l’approche “Leaving one out”. Les rappels6, precisions et F—scores des
meilleures performances sont indiquees au tableau 2.

Nous constatons que le patron d’extraction associe a la relation Search—mission presente une
meilleure performance avec le modele de Markov d’ordre 1, tandis que les autres patrons
d’extraction Missing—object, Incident et Search—unit montrent de meilleurs resultats avec les
modeles d’ordre 2.

Le choix de l’ordre du modele depend du taux des etiquettes semantiques ayant plusieurs
roles possibles. Par exemple, dans l’unite thematique Mission, l’etiquette la plus frequente est
WEATHER—COND1TIONS avec une frequence relative de 37,7 %. Cette derniere a un seul role
dans la relation Mission, contrairement a l’etiquette NUMBER qui peut avoir le role d’une date
ou d’une position geographique (en degre par exemple). Le choix de l’ordre depend egalement
du bruit introduit par les irregularites langagieres, notamment les reprises, agrandit la taille du
contexte necessaire pour desambiguiser un role.

6Le rappel correspond au nombre de roles corrects generes par le systeme sur le nombre de roles dans le corpus
de test, tandis que la precision est le nombre de roles corrects generes par le systeme sur le nombre de roles qu’i1
foumit.

401

Narjes Boufaden, Guy Lapalme

4 Conclusion

Nous avons analyse la problematique de l’apprentissage des patrons d’extraction pour des textes
complexes peu etudies en EI: les transcriptions de conversations. Nous avons modelise les
patrons d’extraction par des modeles de Markov qui associent des roles aux arguments des
predicats avec un F—score de 73,75 %. Bien que les modeles de Markov aient ete utilises pour
l’apprentissage de patrons (Seymore et al., 1999), peu de travaux les ont utilises pour apprendre
les roles semantiques. De ces travaux, nous retenons ceux de Gildea (Gildea & Palmer, 2002)
effectues sur des textes journalistiques avec un F—score de 82 %. D’autres approches ont ete
utilisees, notamment les arbres de decisions sur des textes bien formes avec un F—score de
83,7 % (Surdeanu et al., 2003). Cependant, cette approche ne permet pas de tenir compte des
sequences de longueurs variables que l’on retrouve avec les textes conversationnels.

Nous avons ajoute une etape de resolution des anaphores pronominales en amont de l’etape
d’ apprentissage de patrons. Notre approche a permis un taux de resolution des anaphores de
79,5 % ameliorant ainsi le F—score moyen pour l’apprentissage de patrons de 68,6 %. Quelques
travaux Surdeanu (Surdeanu & Harabagiu, 2002) ont utilise une approche similaire pour ameliorer
l’extraction des informations en resolvant les coreferences aux entites nommees.

Références

BOUFADEN N., LAPALME G. & BENGIO Y. (2002). Decoupage thématique des conversations: un outil

d’aide a l’extraction. In Actes de la 96 conference annuelle sur le traitement automatique des langues
naturelles (TALN 2002), volume I, p. 377-382, Nancy, France.

BOUFADEN N., LAPALME G. & BENGIO Y. (2005). Repérage de mots inforrnatifs a partir de textes
conversationnels. T raitement Automatique de la Langue, 45(3).

GILDEA D. & PALMER M. (2002). The necessity of syntactic parsing for predicate argument recog-
nition. In Proceedings of the 40th Annual Conference of the Association for Computational Linguistics
(ACL 2002 ), p. 239-246, Philadelphie, Pennsylvanie.

GRISHMAN R. (1998). Information extraction and speech recognition. In Proceedings of the DARPA
Broadcast Transcription and Understanding Workshop, Lansdowne, Virginie: Morgan Kaufmann Pub-
lishers.

GROSZ B., J OSHI A. & WEINSTEIN S. (1995). Centering: A Framework for Modeling the local Co-
herence of Discourse. Computational Linguistics, 21(2), 203-225.

LEVELT W. J . M. (1989). Speaking.‘ From Intention to Articulation. ACL—MIT Press Series in Natural
Language Processing. MIT Press.

SEYMORE K., MCCALLUM A. & ROSENFELD R. (1999). Learning hidden Markov structure for in-
formation extraction. In Proceedings of the AAAI—99 Workshop on Machine Learning for Information
Extraction, p. 37-42, Orlando, Floride.

STOLCKE A. (1997). Modeling linguistic segment and turn boundaries for n—best rescoring of sponta-
neous speech. In Proceedings of E UROSPEECH 1997, volume 5, p. 2779-2782, Rhodes, Grece.

SURDEANU M., HARABAGIU S., WILLIAMS J . & AARSETH P. (2003). Using predicate—argument
structures for information extraction. In E. HINRICHS & D. ROTH, Eds., Proceedings of ACL 2003, p.
8-15.

SURDEANU M. & HARABAGIU S. M. (2002). Infrastructure for Open—Domain Information Extraction.
In M. MITCHELL, Ed., Proceedings of HLT 2002, p. 325-330, San Diego, Californie.

402

