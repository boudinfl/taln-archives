IALN ZUUD, Uourdan, 0-1 U _]l11I1 ZUUD

Un analyseur LFG efﬁcace : SXLFG

Pierre Boullier, Benoit Sagot, Lionel Clement
INRIA - Proj et Atoll
Domaine de Voluceau, B.P. 105, 78153 Le Chesnay Cedex, France
{pierre.boullier, benoit.sagot}@inria.fr,
lionel.clement@lefff.net

Mots-clefs I syntaxe, analyseur, LFG, désambiguisation, forét partagée

Keywords: syntax, parser, LFG, disambiguation, shared forest

Résumé Dans cet article, nous proposons un nouvel analyseur syntaxique, qui repose
sur une variante du modele Lexical-Functional Grammars (Grammaires Lexicales Fonction-
nelles) ou LF G. Cet analyseur LFG accepte en entrée un treillis de mots et calcule ses structures
fonctionnelles sur une forét partagée. Nous présentons également les différentes techniques de
rattrapage d’erreurs que nous avons Inises en oeuvre. Puis nous évaluons cet analyseur sur une
grammaire a large couverture du francais dans le cadre d’une utilisation a grande échelle sur
corpus variés. Nous montrons que cet analyseur est a la fois efﬁcace et robuste.

Abstract In this paper, we introduce a new parser based on the Lexical-Functional Gram-
mars formalism (LF G). This LFG parser accepts as input word lattices and computes functional
structures on a shared forest. We also present various error recovery techniques we have im-
plemented. Afterwards, we evaluate this parser on a large-coverage grammar for French in the
framework of a large-scale use on various corpus. We show that our parser is both efﬁcient and
robust.

1 . 1J\}bl111\/1, JJ. >J(l.s\}L \/L 1.4. \./1\/111\/11L

1 Introduction

Pour pallier les difﬁcultés algorithmiques des analyseurs syntaxiques sur du texte tout venant,
il est aujourd’hui habituel d’appliquer un mode opératoire robuste (méthodes markoviennes,
automates ﬁnis, etc.). Ces méthodes sont tres satisfaisantes pour un grand nombre d’applications
qui ne dépendent pas d’une representation complexe de la phrase, mais la ﬁnesse d’analyse en
patit tellement qu’il est illusoire d’avoir une representation du syntagme ou des dépendances
non locales qui satisfassent une déﬁnition linguistique sérieuse. C’est pour cette raison que
nous proposons de batir un analyseur syntaxique qui soit a la fois compatible avec une théorie
linguistique (ici LFG) et qui soit robuste face a la variabilité des productions langagieres.

Le développement d’un nouvel analyseur syntaxique pour le formalisme LFG (Lexical-Functi0-
nal Grammars, cf. p. ex. (Kaplan, 1989)) n’est pas en soi tres original. 11 en existe déja un
certain nombre, comme ceux de (Kaplan & Maxwell, 1994), (Andrews, 1990), ou (Briffault
et al., 1997). Toutefois, ils n’utilisent pas toujours de la maniere la plus complete possible
les différentes techniques algorithmiques de partage de calcul et de représentation compacte de
l’information qui permettent d’ écrire un analyseur efﬁcace bien que le formalisme LFG, comme
de nombreux formalismes qui reposent sur l’uniﬁcation, soit NP-complet.

Pour utiliser au maximum ces techniques, il nous a donc fallu adapter LFG sans pour autant
diminuer son pouvoir d’expression. Associée a un analyseur non-contextuel (CF) tabulaire,
cette variante de LFG nous permet d’effectuer efﬁcacement l’analyse d’énoncés complexes.
La construction des structures de constituance ne pose théoriquementl pas de probleme particu-
lier, car elles sont décrites par des grammaires non-contextuelles (CFG) sous-jacentes aux LFG
et appelées ici grammaires support. Mais la construction efﬁcace des structures fonctionnelles
est beaucoup plus problématique. Nous avons développé un module de calcul de ces structures
qui partage les sous-structures communes a plusieurs analyses. De plus, des mécanismes de rat-
trapage d’erreur a tous les niveaux en font un analyseur robuste. Cet analyseur, appelé SXLFG,
est décrit ci-dessous puis évalué avec une grammaire du francais sur des corpus variés.

2 L’analyseur SXLFG : analyse standard

2.1 L’analyseur Earley

Le moteur de SXLFG est un analyseur CF général qui traite la grammaire support de la LFG.
L’ ensemble des analyses qu’il produit est représenté sous la forme d’une forét partagéez. L’ éva-
luation fonctionnelle se fait dans une seconde phase au cours d’un parcours bas-haut de cette
forét3. L’entrée de l’analyseur est un treillis de mots transformé par le lexeur en un treillis de
lexemes (terminaux de la CFG et structures fonctionnelles sous-spéciﬁées associées). Un post-
traitement (facultatif) permet alors de désambiguiser.

L’ analyse de la grammaire support est réalisée par une évolution de l’analyseur Earley décrit
dans (Boullier, 2003) : il prend en entrée des treillis de mots et permet de récupérer les erreurs
syntaxiques (cf. section 3.1). Traiter un treillis en entrée ne nécessite pas, d’un point de vue
théorique, des changements considérables a l’algorithme Earley, meme aidé d’un guide régulier.

1Méme si, en pratique, la disponibilité d’un bon analyseur est déja plus délicate.

2Rappelons que cette structure permet de représenter en une taille polynomiale en n, nombre de mots du source,
l’ensemble potentiellement non borné des arbres d’analyse.

3Ce parcours assure que si un symbole se trouve en partie droite d’une production reconnue, toutes les structures
fonctionnelles associées a ce symbole ont déja été calculées (nos foréts partagées sont non cycliques).

lJll u.uu.1_y D\/LIL 1.41 \J \/11l\/(l.\/\/. >.J1\J._41'\J

2.2 Calcul des structures fonctionnelles

Disposant d’une forét partagée en sortie de l’analyse CFG, nous devons maintenant calculer les
structures fonctionnelles. Bien entendu, la méthode qui consiste a déplier la forét pour en ex-
traire chaque arbre sur lequel on évalue les structures fonctionnelles est impratiquable en termes
de temps de calcul. En revanche, l’autre possibilité, une évaluation des structures fonctionnelles
directement sur la forét partagée, est toujours un sujet de recherche. Le probleme se simpli-
ﬁe cependant si l’on suppose, comme c’est le cas dans SXLFG, que l’évaluation des équations
fonctionnelles associées a une production CFG ne modiﬁe pas les structures fonctionnelles as-
sociées aux symboles de sa partie droite. Cette légere restriction dans l’écriture des équations
fonctionnelles ne diminue pas pour autant le pouvoir d’expression.

La conséquence directe de cette évaluation bottom-up des structures fonctionnelles est que toute
sous-forét n’est évaluée qu’une seule fois et son calcul partagé entre tous ses parents. L’autre
conséquence est qu’a chaque noeud de la forét est associée non pas une structure fonctionnelle
unique mais une disjonction de structures fonctionnelles. Tres souvent, le résultat de cette éva-
luation est donc un grand nombre de structures fonctionnelles associées a la racine de la forét.

2.3 Désambiguisation

La sortie de l’étape précédente (sauf échec, voir partie suivante) est une forét partagée de struc-
tures de constituants associée a un ensemble de structures fonctionnelles avec partage de struc-
tures communes. Ces informations peuvent étre la description d’une ou de plusieurs analyses.
11 faut donc pouvoir désambiguiser, c’est-a-dire choisir parmi ces analyses celle qui est la plus
vraisemblable. Deux familles de techniques sont envisageables : les techniques probabilistes et
les techniques a regles. Suivant sur ce point (Clément & Kinyon, 2001), nous utilisons un en-
semble de regles qui est une refonte et une extension des trois principes simples qu’ils énoncent
et qui s’applique sur les structures fonctionnelles4. Chacune de nos regles est appliquée suc-
cessivement (on peut en changer l’ordre, voire ne pas toutes les appliquer). L’ application d’une
regle consiste a éliminer les analyses qui ne sont pas optimales au sens de cette regle5.

A l’issue de ce mécanisme de désambiguisation sur les structures fonctionnelles, la forét d’ana-
lyse (qui représente les structures en constituants) est ﬁltrée aﬁn qu’elle corresponde exacte-
ment aux structures fonctionnelles retenues. En particulier, si la désambiguisation est complete,
ce ﬁltrage rend en général une structure en constituants unique (un arbre).

4Cf. (Kinyon, 2000) pour une argumentation sur l’i1nportance de désainbiguisation en se fondant sur des struc-
tures comme les arbres de derivation TAG ou les structures fonctionnelles LFG et non sur celles en constituants.
5Nos regles, dans leur ordre d’application par défaut, sont :

régle 1 : Pre’fe’rer les analyses maximisant la somme des poids des lexemes utilise’s ; parmi les entrees lexicales de
poids supérieur a la moyenne se trouvent les multi-mots, qui sont ainsi favorisés.

régle 2 : Pre’fe’rer les noms communs avec de’terminant.

régle 3 : Pre’fe’rer les arguments aux modiﬁeurs, et les relations auxiliaire—participe aux arguments (le calcul se
fait récursivement sur toutes les (sous—)structures).

régle 4 : Pre’fe’rer les arguments les plus proches (meme remarque).

régle 5 : Pre’fe’rer les structures les plus enchassées.

régle 6 : Trier les structures selon le mode des verbes (on préfere récursivement les structures a l’indicatif a celles
au subjonctif, et ainsi de suite).

régle 7 : Trier selon les cate’gories des gouverneurs d ’adverbes.

régle 8 : Choisir une analyse au hasard (pour garantir qu’on rende une analyse et une seule).

1 . 1J\}bl111\/1, JJ. >J(l.s\}L \/L 1.4. \./1\/111\/11L

3 Mécanismes pour l’analyse robuste

3.1 Rattrapage d’erreur pendant l’analyse

La détection d’une erreur dans l’analyseur Earley peut étre la manifestation de deux phéno-
menes : la CFG support n’est pas assez couvrante ou l’énoncé n’est pas du francais. Bien
entendu, méme si l’analyseur ne distingue pas ces deux situations, le concepteur de la gram-
maire doit y réagir différemment. Le traitement des erreurs dans les analyseurs est un sujet de
recherche qui a surtout été abordé dans le cas déterministe et tres peu dans le cas des analyseurs
CF généraux. Pour des raisons de place, nous ne pouvons décrire ici le mécanisme general de
rattrapage CFG que nous avons développé. I1 fera l’objet d’une publication ultérieure.

Le calcul des structures fonctionnelles échoue si et seulement si aucune structure fonctionnelle
n’est associée a la racine de la forét partagée. Cette situation d’erreur provient du fait que les
contraintes (d’uniﬁcation) spéciﬁées par les équations fonctionnelles n’ont pas pu toutes étre
vériﬁées ou que les structures fonctionnelles résultantes sont incohérentes.

Un premier échec déclenche une deuxieme évaluation des structures fonctionnelles sur la fo-
rét partagée, au cours de laquelle les vériﬁcations de cohérence sont supprimées. En cas de
succes, on obtient a la racine un certain nombre de structures fonctionnelles incohérentes. Si
cette seconde tentative échoue, on recherche dans la forét partagée tous les noeuds maximaux
qui ont des structures fonctionnelles et dont aucun des peres n’a de structure fonctionnelle. Ils
correspondent donc a des analyses partielles disjointes éventuellement incohérentes6.

3.2 Sur-segmentation des énoncés inanalysables

Malgré les mécanismes exposés précédemment, il arrive que l’analyseur SXLFG ne rende au-
cune analyse. Ceci peut étre dﬁ a l’expiration d’un délai maximum que l’on peut donner en
parametre (time-out), ou au fait que le rattrapage d’erreur de l’analyseur Earley n’a pas été ca-
pable de produire une analyse raisonnable. La cause peut en étre l’insufﬁsance de la couverture
de la grammaire ou un énoncé d’entrée par trop déraisonnable.

Pour cette raison, nous avons réalisé une surcouche a SXLFG qui permet une sur-segmentation
des énoncés agrammaticaux. L’idée est qu’il arrive fréquemment que des portions de l’énoncé
d’entrée soient analysables en tant que phrases, alors méme que l’énoncé d’entrée dans son en-
semble ne l’est pas. Nous découpons donc en segments les énoncés inanalysables (découpage
de niveau 1), puis, le cas échéant, redécoupons en segments les segments de niveau 1 inana-
lysables7 (découpage de niveau 2) et ainsi de suite. Les niveaux de découpage correspondent
successivement aux frontieres probables de phrases, aux ponctuations fortes, aux ponctuations
faibles, aux coordonnants, et enﬁn aux frontieres de mots.

La qualité de l’analyse décroit évidemment avec le niveau de découpage. Si le découpage de
niveau 1 ne pose aucun probleme, des difﬁcultés apparaissent au niveau 2. Les niveaux 3 et 4
sont véritablement du rattrapage. Et le niveau 5 n’est la que pour analyser toutes les phrases
possibles, et en particulier celles dont on sait analyser certains morceaux de niveau 1 ou 2.

5Le processus de désarnbiguisation présenté a la section 2.3 s’applique alors a tous les noeuds maximaux.
7Un énoncé peut etre découpé en deux segments de niveau 1 dont le premier est analysable. Seul le second sera
alors sur—segmenté au niveau 2. Et seuls les segments de niveau 2 inanalysables seront sur—segmentés, etc.

lJll u.uu.1_yo\/u1 1.41 \J \/11l\/(l.\/\/. >.J1\J._41'\J

4 Mise en aeuvre et évaluation

4.1 Mise en aeuvre

Nous avons utilisé SXLFG a grande échelle pendant la campagne EASy d’évaluation des ana-
lyseurs syntaxiques. Nous l’avons couplé avec une grammaire LFG développée pour XLFG
(Clement & Kinyon, 2001), étendue et adaptée aux contraintes liées a ce que SXLFG calcule
de maniere bottom-up les structures fonctionnelles sur la forét d’analyse CFG. Le lexique et la
chaine de traitement pré-syntaxique Inis en oeuvre sont décrits dans (Boullier et al., 2005).

4.2 Evaluation

Dans cette section, nous n’évaluerons pas la qualité d’une analyse qui dépend pour l’essentiel
de la grammaire et qui nécessiterait de disposer d’un corpus de référence annoté manuellements.
Nous nous concentrons ici sur l’efﬁcacité de notre systeme en présentant les résultats obtenus
pendant la campagne EASy et sur les corpus EUROTRA et TSNLP.

Corpus #phrases couverture (sans couverture (avec temps d’ analyse

Vérif. de coh.) Vérif. de coh.) moy. méd. 2 0.1s 2 1s
EUROTRA 334 94.61% 84.43% 0.33s 0.02s 22.2% 6.0%
TSNLP 1661 98.50% 79.12% 0.03s 0.00s 2.8% 0.6%
EASy 40859 66.62% 41.95% n.d.1°

TAB. 1 — Evaluation de SXLFG, avec un time-out de 15 secondes9.

Corpus complet Phrases valides pour la CFG support
Analyse CFG Analyse CFG | Analyse complete

Données #phrases 40859 35756
sur les nmoy / nmax 20.95 / 541 19.06/ 173
corpus“ UWm0y / UWWH, 0.79 / 97 0.75 / 65

moy 0.05s 0.01s 3.35s
Temps med 0.00s 0.00s 0.03s
d’analyse < 0.1s 98.2% 98.8% 57.8%

< 1s 99.8% 99.9% 71.0%

max 3.1073 5.1052 112
Nombre med 32 028 29 582 1
d’analyses 2 10° 36.13% 35.28% 0%

2 1012 8.86% 7.84% 0%

TAB. 2 — Données sur le EASy corpus, les temps et les nombres d’analyses, avant application
de l’heuristique de sur-segmentation (time-out de 15 secondes9).

8Cette qualité depend aussi des heuristiques de désarnbiguisation utilisées et du traitement de la robustesse.
9Un time-out plus élevé aurait augmenté les taux de couverture mais également les temps d’analyse.
1°Nous n’avons pas conserve les infonnations pennettant de donner les résultats sur l’ensemble du corpus.
Toutefois, la table 2 donne les temps d’analyse pour les 87.51% de phrases reconnues par la CFG support.
1112 désigne un nombre de mots, et U W un nombre de mots inconnus.
12Dans 14.34% des cas, aucune analyse n’a été trouvée en moins de 15s. C’est dans ces cas—la que sont alors
appliquées les heuristiques de sur—segmentation.

1 . 1J\}bl111\/1, JJ. >J(l.s\}L \/L 1.4. \./1\/111\/11L

5 Conclusion

Dans cet article, nous avons introduit l’analyseur SXLFG. A notre connaissance, c’est la pre-
miere fois qu’un systeme d’analyse fondé sur le modele LFG traite du texte tout venant de
fagon efﬁcace et robuste sans que le pouvoir expressif du formalisme ne soit dégradé. Il est en
outre possible de décrire des phénomenes complexes dans SXLFG en accord avec les nombreux
travaux linguistiques qui s’y rapportent.

Les experiences relatées utilisent une grammaire du frangais et un lexique morpho-syntaxique
que nous avons également réalisés. Les résultats extrémement encourageants obtenus ne doivent
bien entendu pas masquer qu’il s’agit d’une premiere tentative qui doit se poursuivre et qui peut
étre améliorée. Les perfectionnements possibles concernent le formalisme, la grammaire du
frangais et l’analyseur SXLFG lui-méme.

Nous avons quelques idées pour étendre notre variante de LFG qui pourraient faciliter certains
traitements, en particulier celui des coordonnées. La grammaire doit étre étendue et amelio-
rée. En effet, certaines constructions comme les clivées, les comparatives, les coordinations a
ellipse, et d’autres, ne sont pas couvertes. D’autre part, la grammaire support (CFG) doit étre
afﬁnée car son ambiguité actuelle est déraisonnable (voir section 4.2). Meme si notre analy-
seur Earley y est relativement peu sensible, elle peut rendre prohibitif le temps d’évaluation
des structures fonctionnelles associées. Les autres pistes de recherche sur l’analyseur propre-
ment dit concernent essentiellement l’amélioration de la robustesse et du temps de calcul des
structures fonctionnelles.

Références

ANDREWS A. (1990). Functional closure in LF G. Rapport inteme, The Australian National University.

BOULLIER P. (2003). Guided Earley parsing. In Proceedings of the 8th International Workshop on
Parsing Technologies (IWPT’03), p. 43-54, Nancy, France.

BOULLIER P., CLEMENT L., SAGOT B. & ERIC VILLEMONTE DE LA CLERGERIE (2005). Chaines

de traitement syntaxique. In Actes de TALN 05, Dourdan, France.

BRIFFAULT X., CHIBOUT K., SABAH G. & VAPILLON J. (1997). An object-oriented linguistic en-

gineering environment using LFG (Lexical-Functional Grammar) and CG (Conceptual Graphs). In
Proceedings of Computational Environments for Grammar Development and Linguistic Engineering,

ACL’97 Workshop.

CLEMENT L. & KINYON A. (2001). XLFG — an LFG parsing scheme for French. In Proceedings of
LFG’0I, Hong Kong.

KAPLAN R. (1989). The formal architecture of lexical functionnal grammar. Journal of Informations

Science and Engineering.

KAPLAN R. M. & MAXWELL J. T. (1994). Grammar Writer’s Workbench, Version 2.0. Rapport
inteme, Xerox Corporation.

KINYON A. (2000). Are structural principles useful for automatic disambiguation ? In Proceedings of
in COGSCI’00, Philadelphia, Pennsylvania, United States.

