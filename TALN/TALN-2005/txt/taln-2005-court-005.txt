TALN 2005, Dourdan, 6-10 juin 2005

Etiquetage morpho-syntaxique du francais 51 base
d’apprentissage supervise

Julien Bourdaillet, Jean—Gabriel Ganascia
LIP6 — Univesite Paris VI
8 rue du capitaine Scott — 75015 Paris
{J ulien.Bourdaillet, J ean—Gabriel.Ganascia} @ lip6.fr

M0tS-Cl€fS I etiquetage morpho—syntaXique, apprentissage supervise, modele de Markov
cache, evaluation, homo graphes

part—of—speech tagging, supervised learning, hidden Markov model, eval-

Keywords:

uation, homographs

Resume Nous presentons un etiqueteur morpho—syntaXique du francais. Celui—ci utilise
l’ apprentis sage supervise a travers un modele de Markov cache. Le modele de langage est appris
a partir d’un corpus etiquete. Nous decrivons son fonctionnement et la methode d’ apprentissage.
L’etiqueteur atteint un score de precision de 89 % avec un jeu d’etiquettes tres riche. Nous
presentons ensuite des resultats detailles pour chaque classe grammaticale et etudions en parti-
culier la reconnaissance des homographes.

AbStI‘.‘:lCt A french part—of—speech tagger is described. It is based on supervised learning:
hidden Markov model and trained using a corpus of tagged text. We describe the way the model
is learnt. A 89 % precision rate is achieved with a rich tagset. Detailed results are presented for
each grammatical class. We specially pay attention to homographs recognition.

1 Introduction

L’etiquetage morpho—syntaxique consiste a assigner la bonne classe grammaticale, deﬁnie sui-
vant un certain niveau de granularite, a chaque mot d’un texte en entree. Nous presentons ici
un etiqueteur (ou tagger) du francais base sur un modele d’apprentissage supervise. Celui—ci est
une adaptation du tagger de l’analyseur syntaxique RASP de la langue anglaise. Cet etiqueteur
apprend un modele de langage a partir d’un corpus prealablement etiquete.

Plusieurs approches ont ete presentees pour l’etiquetage morpho—syntaxique du francais. Le
Brill Tagger (Brill, 92) apprend des regles a partir d’un corpus etiquete et a ete adapte pour le
francais avec WinBrill. (Giguet, 97) et (Chanod, 95) se basent sur des proprietes de la langue
comme les mots noyaux ou des methodes a base de contraintes. (Chanod, 95) presente un
autre etiqueteur a base d’apprentissage non—supervise, qui apprend un modele de langage a par-
tir d’un corpus non—etiquete via une variante de l’algorithme Estimation—Maximisation (EM).

409

410

Julien Bourdaillet, Jean—Gabriel Ganascia

(Chanod, 95) presente les limites de ce modele qui est fortement dependant des conditions
initiales et peut rester bloque sur un optimum local. (Stein, 95) presente une adapatation au
francais du TreeTagger. Celui—ci est base sur un modele de Markov cache (Hidden Markov
Model ou HMM) modelise par un arbre de decisions. Nous nous situons dans la lignee de ces
deux derniers travaux et utilisons egalement un HMM. Toutefois puisqu’il a ete prouve dans
(Elworthy, 94) que l’apprentissage d’un modele a partir d’un corpus manuellement etiquete
produit de meilleurs resultats que la procedure d’apprentissage d’EM et que nous disposions
d’un tel corpus, nous avons choisi cette alternative.

2 Presentation de l’etiqueteur

Nous utilisons l’etiqueteur morpho—syntaxique de l’anglais du projet RASP (Briscoe, 02). Cet
etiqueteur, detaille dans (Elworthy, 94), est base sur HMM du premier ordre (bigramme). Celui—
ci est represente par un lexique des formes ﬂechies qui associe a chaque mot ses tags potentiels
et par une matrice de transition entre etats. Nous l’avons adapte au traitement de la langue
francaise.

Nous avons utilise le corpus GRACE qui est annote morpho—syntaxiquement. Il comporte env-
iron 800.000 mots et est constitue pour moitie d’articles du Monde et pour moitie d’oeuvres
et d’essais litteraires. Ce corpus est etiquete avec un jeu de 312 etiquettes qui correspon-
dent a un etiquetage tres ﬁn. Les mots sont tout d’abord regroupes en 12 grandes classes tres
generales : adjectif, conjonction, determinant, mot—phrase, nom, pronom, adverbe, preposition,
verbe, residu, ponctuation et extra—lexical. Ces classes sont ensuite afﬁnees, comme par exem-
ple conjonction en conjonction de coordination et conjonction de subordination, verbe en verbe
auxiliaire et verbe principal. On aboutit ainsi a un jeu de 36 etiquettes. Enﬁn, ont ete adjoints
a ces classes grammaticales des traits proprement morphologiques, tels que le genre, le nom-
bre, la personne, le mode ou encore le temps qui donnent le jeu de 312 etiquettes. Nous avons
ajoute, pour des facilites d’implementation et sans denaturer la coherence de l’ensemble, huit
etiquettes composees (qui existaient dans le corpus sous la forme d’une composition de deux
etiquettes) et sommes ainsi arrives a un jeu de 320 etiquettes.

Nous avons choisi d’effectuer l’apprentissage sur le corpus GRACE avec le jeu de 320 eti-
quettes. En effet, l’interet de ce jeu est que les classes tres ﬁnes apportent beaucoup d’informa—
tions sur les mots et permettent de se passer d’analyseur morphologique en vue d’une etape
ulterieure d’analyse en constituants.

Ainsi la procedure d’apprentis sage permet d’ apprendre un HMM base sur 320 etats. Nous avons
garde la majeure partie du corpus comme donnees d’ apprentissage et utilise le reste comme
donnees de test, soit environ 26.000 mots. L’entrainement du modele a permis d’obtenir un
dictionnaire d’environ 44.000 formes ﬂechies.

Nous avons modiﬁe l’algorithme d’etiquetage proprement dit pour que celui—ci prenne en compte
les locutions. Pour cela, nous avons applique l’heuristique du motif le plus long. Au moment de
lire le texte en entree, l’etiqueteur va chercher, grace au lexique, si la combinaison du mot sui-
vant au mot courant forme une locution. Si tel est le cas, on applique ce principe iterativement
avec le mot suivant jusqu’a ce que l’application ne soit plus possible, auquel cas, on garde la
demiere locution trouvee. L’etiquetage de la phrase par Viterbi est ensuite effectue avec celle—ci.

Etiquetage morpho—syntaxique du francais a base d’apprentissage supervise

3 Evaluation

Pour evaluer notre travail, nous utilisons la precision (proportion d’etiquetages corrects parrni
les etiquetages stricts) et la decision (proportion d’etiquetages stricts parrni l’ensemble de tous
les etiquetages). Dans un premier temps, nous avons developpe un script Perl charge de cette
evaluation, qui sera appele par la suite EVAL. Dans un second temps nous avons reutilise la
boite a outils d’evaluation des analyseurs du projet ELSE1. Notons que EVAL comporte 150
lignes de code alors que l’evaluateur ELSE en comporte plusieurs milliers, meme si ce dernier
se veut plus ambitieux et traite, par exemple, divers formats de ﬁchiers en entree.

3.1 Résultats

Lors de tous nos tests, notre analyseur atteint un score de decision de 100% et ceci pour
deux raisons. Tout d’ abord, il ne renvoie qu’une seule etiquette par mot, ce qui ne genere
pas d’etiquetage ambigu. Et ensuite, notre jeu d’etiquettes est identique a celui de GRACE.
Il n’y a donc pas de problemes de projection d’un jeu dans l’autre (phenomene qui entraine
des regroupements de plusieurs etiquettes en une seule ou inversement) lors de l’utilisation de
l’ evaluateur ELSE.

Nous avons effectue des tests avec trois niveaux de granularite de l’etiquetage. Le premier
niveau correspond au jeu complet des 320 etiquettes. Le second est ce meme jeu mais sans les
traits morphologiques, ce qui donne 36 etiquettes. Le demier niveau est l’etiquetage le plus
general en 12 grandes classes grammaticales. Dans le tableau 1 nous presentons les scores
de precision dans differents cas. La premiere colonne correspond a l’etiquetage du corpus de
test produit par notre analyseur morpho—syntaxique avec EVAL. La deuxieme fait reference au
meme etiquetage mais avec l’evaluateur ELSE. Et la demiere presente l’evaluation par ELSE
de ce meme corpus de test mais etiquete par l’analyseur Cordial. En effet, ce demier cas nous
a semble interessant comme element de comparaison puisque Cordial semble actuellement etre
le meilleur analyseur du francais.

A partir de ces chiffres nous pouvons

tirer plusieurs constations. Tout d’ab— I I EVAL | ELSE l ELSE / C0Tdia1 l
ord remarquons qu’entre l’evaluation 320 tags 87.65 % 89.07 % 94.44 %
de notre analyseur avec EVAL et celle 36 tags 92.24 % 93.52 % 94.63 %
avec ELSE, on a pour les trois niveaux 12 tags 94.39 % 95.69 % 97.52 %

environ 1.5 point d’ecart. Ceci vient

de la difference des methodes de seg— Table 11 SC0f6S (16 pfe/CiSi0I1

mentation utilisees. Avec ELSE, l’alignement entre la sortie de l’etiqueteur et le corpus cor-
rectement etiquete n’est pas tres bon car ELSE utilise un segmenteur generique et non un seg-
menteur adapte a l’analyseur comme EVAL. Ainsi plus de tokens ne sont pas correctement
realignes avec ELSE, comme certains mots composes ou contenant une apostrophe. Ceux—ci ne
sont donc pas soumis a evaluation, ce qui tend a ameliorer mecaniquement la precision. D’autre
part, cela souligne l’importance de la question de la segmentation et la difﬁculte d’y apporter
une reponse qui soit valide a travers plusieurs formalismes. Avec EVAL, les tokens incorrecte—
ment realignes sont des mots contenant des tirets, des mots composes et des expressions non
presentes dans le dictionnaire. On en compte environ 0.8 % du nombre de tokens contenus dans
le corpus detest.

1http://www.limsi.fr/TLP/ELSE

411

412

Julien Bourdaillet, Jean—Gabriel Ganascia

Ensuite, avec le jeu d’etiquettes complet (320 tags) et l’evaluateur ELSE, notre analyseur est
moins performant que Cordial. Cependant si l’on compare ce score avec ceux presentes dans
(Adda, 99), nous nous situons dans la moyenne des analyseurs évalues qui obtiennent de 82
a 96 % de precision. De plus, notons que lors de cette campagne les meilleurs resultats ont
éte obtenus non par des etiqueteurs mais par des analyseurs syntaxiques complets. Ceux—ci
ayant un avantage certain sur les premiers pour desambiguiser les cas les plus difﬁciles. En
effet, leur resolution peut étre reportee au niveau syntaxique, ce qui ameliore de quelques (mais
precieux) points la precision. Au vu de nos resultats et du fait que nous nous limitons au niveau
de l’etiquetage, notre approche est interessante vis—a—vis des autres.

Enﬁn, nous avons effectue l’evaluation avec des jeux d’etiquettes plus concis. En effet, ceux—ci
se rapprochant plus des jeux utilises par les analyseurs de l’anglais, la comparaison est rendue
possible. Notre score se situe egalement dans la moyenne de ceux présentes dans la littera—
ture. Notons que dans (Briscoe, 02), donc pour RASP sur l’anglais, les auteurs atteignent
une precision de 97 %. Nous nous situons en dessous, ce qui laisse entrevoir des possibilites
d’ amelioration. Toutefois un tel score semble difﬁcilement atteignable par un etiqueteur seul
pour le francais. En effet, du fait de sa plus grande richesse morphologique, le francais est plus
dur a etiqueter que l’anglais. Ceci est conﬁrme, au vu de la littérature, par le fait que globale—
ment les scores des etiqueteurs de l’anglais sont plus eleves, de quelques (et toujours precieux)
points, que ceux du francais.

3.2 Evaluation par classes

Nous cherchons dans cette partie a évaluer les points forts et les points faibles de notre étiqueteur
de facon plus precise. Dans un premier temps, nous presentons dans cette section les resultats
pour chaque classe grammaticale. Dans un second temps, nous presentons dans la section
suivante le taux de reconnaissance des homo graphes.

Dans le tableau 2, nous presentons pour chaque classe grammaticale, le nombre d’occurrences
dans le corpus de test, le pourcentage d’etiquetage correct et les trois types d’erreurs les plus
frequentes par ordre decroissant.

| | Occurrences | % Correct | Erreurl | Erreur 2 | Erreur 3 |
Nom 6506 95.2 % Adj /2 % V / 0.8 % D / 0.7 %
Verbe 3184 96 % Adj / 2.4 % N/1.1 % Prep/0.3 %
Verbe auxiliaire 669 78.5 % Vp / 21 % N / 0.1 % Adv / 0.1 %
Verbe principal 2515 92.8 % Adj / 3 % Va / 2.3 % N/ 1.3 %
Adjectif 1773 85.4 % V / 6.6 % N / 5.1 % Adv/ 1.2 %
Pronom 1456 89.3 % C/4.5 % D / 2 % Adv/ 1.7 %
Determinant 3162 94.0 % Prep / 1.8 % Pron/ 1.7 % N/ 1.6 %
Adverbe 1170 94.9 % C / 2.3 % Prep/ 1 % N / 0.8 %
Conjonction 856 97.9 % Adv/ 1% Prep/ 1 % Pron / 0.6 %
Preposition 3863 81.8 % D/ 16.4 % Pron / 0.6 % N / 0.3 %
Ponctuation 3424 98.8 % Adv / 0.8 % Pron / 0.3 % N / 0.1 %

Table 2: Scores et types d’erreurs par classes

Nous considerons que les classes presentant un taux supérieur a 94 % sont bien reconnues et
que les efforts d’amelioration de l’etiqueteur devraient plutot se porter sur la reconnaissance

Etiquetage morpho—syntaxique du francais a base d’apprentissage supervise

des autre classes. En etudiant en particulier les deux composantes de la classe Verbe (auxiliaire
et principal), on constate que les auxiliaires sont les plus mal reconnus. Neanmoins le tagger
hesite essentiellement entre Verbe auxiliaire et Verbe principal, ce qui est satisfaisant pour une
etape ulterieure d’ analyse syntaxique. La ponctuation presente un score eleve mais toutefois
insufﬁsant, ce qui est dﬁ aux points de suspension mal etiquetes.

Les prepositions semblent particulierement mal reconnues. En analysant les erreurs, on constate
que ce sont les mots du type “de la, de l’, des” qui posent la plupart des problemes, c’est—a—dire
les mots homographes qui sont soit des articles partitifs, soit des prepositions contractees. Cette
difﬁculte est due a la forte ambiguite entre les deux cas, element caracteristique de la grammaire
francaise. De plus, les adjectifs et les pronoms sont un point faible de notre etiqueteur.

3.3 Evaluation des homographes

En nous inspirant de (Vergne, 99) qui presente differents types d’homographes du francais, nous
avons cherche a afﬁner ces resultats. Le tableau 3 presente ci—dessous les taux de reconnais-
sance de differents types d’homographes. Dans la premiere colonne (H1) sont presentes les
homographes determinant/pronom (le, 1’, la, les); en H2, les homographes preposition contrac-
tee/article partitif (de, d’, du, des); en H3, les homographes conjonction/pronom relatif (que,
qu’); en H4, les homographes auxiliaire/nom (est, étre, avoir); en H5, les homographes ad-
Verbe/nom (bien, mal, moins, plus, pas, point...); en H6, les homographes nom/adjectif et en
H7, les homo graphes norn/Verbe principal. La premiere ligne presente le nombre d’occurrences
dans le corpus de test de la classe majoritaire (en effet, pour les cas d’homographes, une classe
est largement majoritaire par rapport a l’autre, de l’ordre de 70 a 95 % des cas); la seconde,
le nombre d’occurrences de la classe minoritaire; la troisieme, le taux de reconnaissance de la
classe maj oritaire, et la derniere le taux de reconnaissance de la classe minoritaire.

H1 H2 H3 H4 H5 H6 H7
Occ. Maj D: 1767 Prep: 1601 C: 200 Aux: 267 Adv: 223 Adj: 290 N: 141
Occ. min Pro: 59 Part: 132 Pro: 47 N: 6 N: 27 N: 171 VP: 96
% OK Maj 97.7 % 82.5 % 98 % 99.2 % 97.3 % 91.7 % 92.9 %
% OK min 69.5 % 62.1 % 17 % 85.7 % 85.2 % 87.7 % 83.3 %

Table 3: Reconnaissance des homographes

Au Vu de ces resultats, nous constatons que les classes majoritaires sont bien reconnues (sauf
en H2, ou on retrouve la difﬁculte precedente). Pour les classes minoritaires, les resultats sont
reellement encourageants pour H4, H5, H6 et H7, or ce sont ces cas qui sont les plus interessants
pour l’etape ulterieure d’analyse syntaxique. En effet, nous pensons que discriminer un nom
d’un Verbe (H7) apporte plus d’information qu’une preposition d’un partitif (H2), meme si cela
semble difﬁcilement quantiﬁable. Nous avons deja discute de la difﬁculte du cas H2. Pour
ce qui est de H1 et H3, dans les deux cas, la classe minoritaire est le pronom. Nous pensons
atteindre ici certaines limites de l’etiquetage pour ce qui est de la reconnaissance des pronoms.
En effet, celle—ci serait probablement plus pertinente au niveau de l’analyse en constituants .

413

414

Julien Bourdaillet, Jean—Gabn'el Ganascia

4 Conclusion

A travers ce travail, nous avons cherche a developper un etiqueteur morpho—syntaxique du
frangais se fondant sur une methode d’ apprentissage supervise. Pour ce faire, en nous basant sur
un tagger de l’anglais, nous avons adapte la procedure d’apprentissage aux exigences du traite—
ment automatique du frangais. Nous obtenons un score de precision de 89 %, score inferieur a
ceux des meilleurs etiqueteurs mais comme, d’une part ceux—ci sont des analyseurs syntaxiques
complets et d’autre part nous n’avons effectue aucune optimisation sur notre etiqueteur, ce re-
sultat est interessant. Apres avoir analyse en detail les erreurs d’etiquetage, il ressort que les
points faibles se situent au niveau des adjectifs, pronoms et prepositions et en particulier sur
ceux qui sont homographes avec une autre classe. Toutefois nous avons identiﬁe certains cas
d’homographes comme etant les plus interessants et ceux—ci s’averent bien reconnus.

Dans une perspective de poursuite de ce travail, nous avons effectue des tests prospectifs avec
le dictionnaire appris a partir de tout le corpus (mais avec les memes transitions), la precision
s’est amelioree de 1.5 a 2 points pour les trois niveaux. Cela laisse a penser que l’augmentation
de la taille du dictionnaire presenterait des gains signiﬁcatifs de precision et, plus generalement,
l’acquisition d’un modele de langage a partir d’un corpus plus consequent. D’autre part, nous
avons reutilise tel quel le guesser qui est optimise pour l’anglais. Puisqu’il repose sur des regles
statistiques, il fonctionne egalement ici mais meriterait d’étre etudie plus en detail et adapte.

Remerciements

Nous tenons a remercier John Carroll pour son concours et Emmanuel Giguet pour ses com-
mentaires sur ce travail.

Références

Adda G., Mariani J ., Paroubek P., Rajman M., Lecomte J . (1999), Métrique et premiers résultats de
l’évaluation GILACE des étiqueteurs morphosyntaxiques pour le frangais, Actes de la Sixieme Con-
ference sur le T raitement Automatique des Langues Naturelles.

Brill E. (1992), A simple rule—based part of speech tagger, Actes de Third Conference of Applied Natural
Language Processing.

Briscoe T., Carroll J (2002), Robust accurate statistical annotation of general text. Actes de Third Inter-
national Conference on Language Resources and Evaluation. p. 1499-1504.

Chanod J—P., Tapanainen P. (1995), Tagging French — comparing a statistical and a constraint—based
method, Actes de Seventh Conference of the European Chapter of the ACL.

Elworthy D. (1994), Does Baum—Welch re—estimation help taggers ‘.7, Actes de Fourth ACL Conference
on Applied NLP.

Giguet E., Vergne J . (1997), From part of speech tagging to memory—based deep syntactic analysis, Actes
de Fifth Iternational Workshop on Parsing Technologies.

Stein A., Schmid H. (1995), Etiquetage morphologique de textes frangais avec un arbre de decisions,
Revue TA.L, Vol. 36.

Vergne J . (1999), Habilitation a diriger des recherches, p. 36.

