<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Approches en corpus pour la traduction : le cas M&#201;T&#201;O</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2005, Dourdan, 6&#8211;10 juin 2005
</p>
<p>Approches en corpus pour la traduction: le cas M&#201;T&#201;O
</p>
<p>Philippe Langlais, Thomas Leplus
Simona Gandrabur et Guy Lapalme
</p>
<p>RALI
Universit&#233; de Montr&#233;al
</p>
<p>http://rali.iro.umontreal.ca/
</p>
<p>Mots-clefs : M&#233;moire de traduction, traduction probabiliste, alignements multiples, r&#233;-
ordonnancement &#224; post&#233;riori
</p>
<p>Keywords: Memory-based translation, statistical translation, multiple alignment, rescor-
ing
</p>
<p>R&#233;sum&#233; La traduction automatique (TA) attire depuis plusieurs ann&#233;es l&#8217;int&#233;r&#234;t d&#8217;un nom-
bre grandissant de chercheurs. De nombreuses approches sont propos&#233;es et plusieurs cam-
pagnes d&#8217;&#233;valuation rythment les avanc&#233;es faites. La t&#226;che de traduction &#224; laquelle les par-
ticipants de ces campagnes se pr&#234;tent consiste presque invariablement &#224; traduire des articles
journalistiques d&#8217;une langue &#233;trang&#232;re vers l&#8217;anglais; t&#226;che qui peut sembler artificielle. Dans
cette &#233;tude, nous nous int&#233;ressons &#224; savoir ce que diff&#233;rentes approches bas&#233;es sur les corpus
peuvent faire sur une t&#226;che r&#233;elle. Nous avons reconstruit &#224; cet effet l&#8217;un des plus grands succ&#232;s
de la TA: le syst&#232;me M&#201;T&#201;O. Nous montrons qu&#8217;une combinaison de m&#233;moire de traduc-
tion et d&#8217;approches statistiques permet d&#8217;obtenir des r&#233;sultats comparables &#224; celles du syst&#232;me
M&#201;T&#201;O, tout en offrant un cycle de d&#233;veloppement plus court et de plus grandes possibilit&#233;s
d&#8217;ajustements.
</p>
<p>Abstract Machine Translation (MT) is the focus of extensive scientific investigations
driven by regular evaluation campaigns, but which are mostly oriented towards a somewhat
artificial task: translating news articles into English. In this paper, we investigate how well cur-
rent MT approaches deal with a real-world task. We have rationally reconstructed one of the
only MT systems in daily production use: the METEO system. We show how a combination
of a sentence-based memory approach, a phrase-based statistical engine and a neural-network
rescorer can give results comparable to those of the current system while offering a faster de-
velopment cycle and better customization possibilities.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Langlais, Leplus, Gandrabur et Lapalme
</p>
<p>1 Introduction
</p>
<p>Depuis la reprise des campagnes d&#8217;&#233;valuation NIST1 la traduction automatique (TA) rev&#234;t un
caract&#232;re de plus en plus comp&#233;titif. La t&#226;che partag&#233;e &#224; laquelle se pr&#234;tent les &quot;comp&#233;titeurs&quot;
de ces campagnes d&#8217;&#233;valuation consiste &#224; traduire vers l&#8217;anglais des textes journalistiques. S&#8217;il
est clair que cette t&#226;che r&#233;pond en partie &#224; des pr&#233;occupations concr&#232;tes du pays organisateur,
il n&#8217;est cependant pas imm&#233;diat d&#8217;imaginer des applications r&#233;elles de la technologie &#233;valu&#233;e.
</p>
<p>Des t&#226;ches de traduction plus sp&#233;cifiques existent cependant. Lors du workshop IWSLT (Akiba
et al., 2004) dont l&#8217;objectif premier &#233;tait de proposer un protocole d&#8217;&#233;valuation adapt&#233; &#224; la
traduction de corpus oralis&#233;s, la t&#226;che partag&#233;e consistait &#224; traduire des phrases du corpus BTEC
(Basic Travel Expression Corpus). Ce corpus regroupe des phrases susceptibles d&#8217;&#234;tre utiles
&#224; un touriste &#224; l&#8217;&#233;tranger. Une autre t&#226;che de traduction plus cibl&#233;e et qui a fait l&#8217;objet de
nombreuses &#233;tudes est la t&#226;che Verbmobil (Wahlster, 2000) qui consiste &#224; traduire des dialogues
de t&#226;ches pr&#233;cises (comme la prise de rendez-vous) pour la paire de langue anglais/allemand.
Dans cette &#233;tude, nous nous int&#233;ressons &#224; une t&#226;che encore plus pr&#233;cise et dont l&#8217;applicabilit&#233; ne
fait cette fois-ci aucun doute puisqu&#8217;elle est reconnue comme l&#8217;un des plus grand succ&#232;s de la
traduction automatique: la traduction de l&#8217;anglais vers le fran&#231;ais de bulletins m&#233;t&#233;orologiques
&#233;mis par Environnement Canada (EC)2. Nous baptisons cette t&#226;che M&#201;T&#201;O.
R&#233;cemment, Leplus et al. (2004) montraient qu&#8217;&#224; l&#8217;aide d&#8217;une m&#233;moire de traduction phrastique
peupl&#233;e de bulletins m&#233;t&#233;orologiques d&#233;j&#224; traduits, il &#233;tait possible d&#8217;obtenir des traductions de
bonne qualit&#233;. Ils expliquaient leur succ&#232;s par un fort taux de r&#233;p&#233;titivit&#233; des phrases que le
syst&#232;me M&#201;T&#201;O traduit. Dans ce travail, nous &#233;tudions la pertinence de plusieurs approches
bas&#233;es sur les corpus &#224; traduire les bulletins m&#233;t&#233;orologiques.
</p>
<p>2 Protocole
</p>
<p>Nous avons utilis&#233; dans ce travail le bitexte d&#233;crit dans (Leplus et al., 2004). Nous avons repris
le m&#234;me d&#233;coupage en trois partie de ce bitexte: TRAIN pour l&#8217;entra&#238;nement des syst&#232;mes,
BLANC pour leur ajustement et TEST pour tester les diff&#233;rentes approches. Ce d&#233;coupage avait
&#233;t&#233; choisi de mani&#232;re &#224; ce que les textes soient d&#8217;une p&#233;riode disjointe et que la tranche de test
soit d&#8217;une p&#233;riode post&#233;rieure &#224; celle de l&#8217;entra&#238;nement; ceci afin de simuler autant que faire se
peut les conditions r&#233;elles d&#8217;utilisation du syst&#232;me.
</p>
<p>Pour &#233;valuer nos diff&#233;rentes approches, nous utilisons des m&#233;triques automatiques qui bien que
discutables n&#8217;en sont pas moins largement utilis&#233;es: deux taux d&#8217;erreurs &#8212; WER au niveau
des mots et SER au niveau des phrases &#8212; que l&#8217;on cherchera &#224; minimiser et deux mesures de
couverture n-gramme &#8212; NIST et 100&#215;BLEU &#8212; que l&#8217;on voudra maximiser, toutes les deux
calcul&#233;es par le script mteval (version 11a) disponible depuis le site de NIST.
</p>
<p>1Consulter http://www.nist.gov/speech/tests/mt/ pour plus d&#8217;information.
2Le bulletin en cours peut &#234;tre consult&#233; &#224; l&#8217;adresse http://meteo.ec.gc.ca/forecast/
</p>
<p>textforecast_f.html</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Approches en corpus pour la traduction: le cas M&#201;T&#201;O
</p>
<p>3 M&#233;moire de traduction phrastique
</p>
<p>Nous avons mesur&#233; que 83% des phrases du corpus BLANC sont pr&#233;sentes verbatim dans le
corpus TRAIN. Cette couverture atteint 87% si nous introduisons quelques classes de mots
comme les jours, les mois ou encore les num&#233;ros de t&#233;l&#233;phones. Nous avons donc commenc&#233;
par reproduire l&#8217;approche m&#233;moire de traduction phrastique propos&#233;e par Leplus et al. (2004).
Nous avons construit une m&#233;moire en gardant de chaque phrase source de TRAIN, un maxi-
mum de 5 traductions. En pratique, 89% des phrases anglaises de TRAIN n&#8217;ont qu&#8217;une seule
traduction, probablement en raison du fait que la plupart des phrases ont &#233;t&#233; produites automa-
tiquement (nous reviendrons sur ce point dans la section 7).
Pour une nouvelle phrase &#224; traduire, nous recherchons les phrases sources les plus proches (en
terme de distance d&#8217;&#233;dition) dans la m&#233;moire et trions les traductions associ&#233;es selon un score
dont le d&#233;tail est d&#233;crit dans (Langlais et al., 2005). Dans cette exp&#233;rience, la premi&#232;re phrase
cible retourn&#233;e est la traduction retenue.
</p>
<p>m&#233;moire Leplus et al.
WER% SER% NIST BLEU WER% SER% NIST BLEU
</p>
<p>8.42 23.43 10.9571 87.68 9.18 23.56 10.8983 86.95
</p>
<p>Table 1: &#201;valuation de l&#8217;approche m&#233;moire phrastique sur le corpus TEST et comparaison avec
l&#8217;approche Leplus et al. (2004).
</p>
<p>Les scores sont tr&#232;s bons si on les compare avec ceux observ&#233;s dans d&#8217;autres t&#226;ches de tra-
duction. Nous r&#233;f&#233;rons le lecteur &#224; l&#8217;&#233;tude de Zens et Ney (2004) pour des performances &#233;tat
de l&#8217;art sur trois t&#226;ches de traduction incluant Verbmobil. Nos performances sont &#233;galement
l&#233;g&#232;rement sup&#233;rieures &#224; celles mentionn&#233;es par (Leplus et al., 2004). Il n&#8217;en reste cependant
pas moins que le taux d&#8217;erreur au niveau des phrases (c&#8217;est-&#224;-dire le pourcentage de traductions
produites non identiques &#224; la traduction de r&#233;f&#233;rence) n&#8217;est pas particuli&#232;rement bas.
</p>
<p>4 Approche probabiliste
</p>
<p>Nous avons test&#233; dans un deuxi&#232;me temps une approche &#233;tat de l&#8217;art en traduction statistique
(Koehn et al., 2003). Elle s&#8217;appuie sur un mod&#232;le de la distribution conditionnelle d&#8217;une
s&#233;quence de mots dans une langue &#233;tant donn&#233;e une s&#233;quence dans l&#8217;autre langue. Les d&#233;-
tails de l&#8217;obtention des mod&#232;les probabilistes sous-jacents sont donn&#233;s dans (Langlais et al.,
2005). Nous avons fait usage du d&#233;codeur PHARAOH (Koehn, 2004) disponible gratuitement
pour des fins de recherche.
</p>
<p>Les performances du syst&#232;me probabiliste sont pr&#233;sent&#233;es en table 2. Une comparaison directe
avec les r&#233;sultats mesur&#233;s avec l&#8217;approche m&#233;moire milite en faveur de la m&#233;moire, surtout
si l&#8217;on observe le taux d&#8217;erreur au niveau des phrases. Cependant, nous remarquons que la
performance du traducteur probabiliste lorsque mesur&#233;e sur les phrases &#224; traduire qui n&#8217;ont pas
&#233;t&#233; vues verbatim dans le corpus TRAIN sont de loin sup&#233;rieures &#224; celles obtenues par l&#8217;approche
m&#233;moire. Nous reviendrons sur la compl&#233;mentarit&#233; de ces deux approches en section 7.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Langlais, Leplus, Gandrabur et Lapalme
</p>
<p>WER% SER% NIST BLEU
7.46 32.01 10.8725 84.03
</p>
<p>Table 2: &#201;valuation de l&#8217;approche statistique sur TEST.
</p>
<p>5 Approche consensuelle
</p>
<p>Bangalore et al. (2002) ont montr&#233; qu&#8217;il &#233;tait possible de combiner des traductions produites
par diff&#233;rents moteurs de traduction afin de g&#233;n&#233;rer des traductions d&#8217;une qualit&#233; sup&#233;rieure &#224;
celles produites par un seul des moteurs. L&#8217;id&#233;e sous-jacente &#224; cette approche (bootstrapping)
est l&#8217;alignement de plusieurs traductions candidates afin d&#8217;isoler des &#238;lots de confiance capables
de diriger la g&#233;n&#233;ration d&#8217;une traduction dite consensuelle. Nous retrouvons cette id&#233;e dans
certains syst&#232;mes d&#8217;acquisition et de g&#233;n&#233;ration de paraphrases.
</p>
<p>Nous avons reproduit cette approche et avons pour cela adapt&#233; &#224; nos besoins le programme
CLUSTALW (Thompson et al., 1994) &#233;crit pour aligner entre-elles plusieurs s&#233;quences de pro-
t&#233;ines. &#192; partir d&#8217;un alignement multiple de traduction (dont le lecteur trouvera les d&#233;tails
dans (Langlais et al., 2005)), nous pouvons construire un treillis qui permet de produire en
sus des traductions align&#233;es de nouvelles phrases que l&#8217;on esp&#232;re plus robustes. Nous utilisons
le package CARMEL (Knight &amp; Al-Onaizan, 1999) pour trouver dans un treillis la traduction
consensuelle; c&#8217;est-&#224;-dire le chemin de plus faible co&#251;t dans le treillis.
</p>
<p>Les r&#233;sultats de cette approche sont pr&#233;sent&#233;s en table 3 pour les seules phrases de BLANC
non rencontr&#233;es verbatim dans le corpus ayant servi &#224; cr&#233;er la m&#233;moire. Nous observons que
la traduction par consensus am&#233;liore la qualit&#233; (telle que mesur&#233;e) des traductions produites.
Le taux d&#8217;erreur au niveau des phrases est en particulier r&#233;duit de 9 points (en absolu), ce qui
constitue une am&#233;lioration notable.
</p>
<p>m&#233;moire m&#233;moire + consensus
WER% SER% NIST BLEU WER% SER% NIST BLEU
18.69 94.82 9.7853 66.56 18.97 85.53 9.9314 68.86
</p>
<p>Table 3: Performance de l&#8217;approche consensuelle sur la sortie de la m&#233;moire de traduction pour
les 13 010 phrases de BLANC non rencontr&#233;es dans le corpus TRAIN.
</p>
<p>6 R&#233;-ordonnancement par apprentissage neuronal
</p>
<p>Dans notre cadre, le rescoring consiste &#224; r&#233;-ordonner une liste d&#8217;alternatives produites par un
syst&#232;me (dit natif) avec l&#8217;espoir que des informations suppl&#233;mentaires, ou diff&#233;rentes fa&#231;ons de
les utiliser, permettent de produire un ordonnancement plus pertinent. Le rescoring a fait l&#8217;objet
d&#8217;&#233;tudes r&#233;centes en traduction probabiliste (Blatz et al., 2004).
Dans notre contexte, cela consiste &#224; reclasser la liste des meilleures traductions g&#233;n&#233;r&#233;es par
PHARAOH (Koehn, 2004) pour une phrase donn&#233;e. Chaque alternative de traduction tj est
repr&#233;sent&#233;e par un vecteur de traits vj et est &#233;tiquet&#233;e comme correcte si elle est identique &#224; la
traduction de r&#233;f&#233;rence et incorrecte sinon. Nous avons utilis&#233; le package TORCH (Collobert</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Approches en corpus pour la traduction: le cas M&#201;T&#201;O
</p>
<p>et al., 2002) pour entra&#238;ner un r&#233;seau perceptron multi-couche &#224; estimer p(&#8853;|vj), la probabilit&#233;
conditionnelle de la correctitude d&#8217;une alternative tj .
</p>
<p>Nous avons test&#233; diff&#233;rentes configurations de la couche cach&#233;e du r&#233;seau et avons consid&#233;r&#233; de
nombreux traits pour repr&#233;senter nos alternatives, chacun encodant des caract&#233;ristiques partic-
uli&#232;res. Les plus utiles &#233;taient a) le ratio des longueurs de la phrase source et de la traduction
candidate, b) la probabilit&#233; a posteriori de l&#8217;alternative et c) les scores p(tj|s) calcul&#233;s par les
mod&#232;les IBM 1 et 2 (Brown et al., 1993). De plus amples informations sur cette approche sont
disponibles dans (Langlais et al., 2005).
Nous pr&#233;sentons en table 4 les performances mesur&#233;es par l&#8217;&#233;tape de rescoring.
</p>
<p>smt smt + rescoring
WER% SER% NIST BLEU WER% SER% NIST BLEU
7.46 32.01 10.8725 84.03 5.73 25.03 10.9828 87.40
</p>
<p>Table 4: Comparaison des performances du moteur probabiliste (smt) seul et des traductions
produites par reclassement (smt + rescoring) sur TEST.
</p>
<p>7 Discussion
</p>
<p>La diversit&#233; des approches que nous avons impl&#233;ment&#233;es nous donne la souplesse de pouvoir
les combiner. Pour illustrer ce point, nous avons &#233;valu&#233; une combinaison tr&#232;s simple o&#249; la
m&#233;moire seule est consult&#233;e lorsque la phrase &#224; traduire est d&#233;j&#224; dans la m&#233;moire, et o&#249; le
moteur de traduction probabiliste rescor&#233; est consult&#233; sinon. Les performances ainsi mesur&#233;es
(voir la table 5) sont meilleures que celles de chaque approche prise isol&#233;ment.
</p>
<p>WER% SER% NIST BLEU
4.85 20.80 11.3021 89.59
</p>
<p>Table 5: Performance sur TEST de la combinaison de la m&#233;moire et du moteur de traduction
probabiliste reclass&#233;.
</p>
<p>Il est cependant appropri&#233; de s&#8217;interroger quant &#224; la performance v&#233;ritable d&#8217;un tel syst&#232;me. Il
est en particulier int&#233;ressant de contraster ces r&#233;sultats avec ceux mesur&#233;s par le bureau de
la traduction du Canada (BTC) qui est en charge de produire les traductions des bulletins
m&#233;t&#233;orologiques produits par Environnement Canada (EC). Le BTC utilise en effet le syst&#232;me
M&#201;T&#201;O pour traduire automatiquement les bulletins anglais, mais a la responsabilit&#233; de r&#233;viser
tout ou partie des traductions ainsi produites.
</p>
<p>(Macklovitch, 1985) d&#233;crit une &#233;valuation du syst&#232;me M&#201;T&#201;O-II conduite par le BTC. L&#8217;auteur
a s&#233;lectionn&#233; 1257 phrases fran&#231;aises publi&#233;es sur une p&#233;riode de 24 heures par EC et a compt&#233;
le nombre de fois o&#249; le syst&#232;me produisait exactement la m&#234;me traduction que celle qui a &#233;t&#233;
publi&#233;e. Les erreurs dues &#224; des fautes flagrantes non imputables au syst&#232;me &#233;taient cependant
&#233;cart&#233;es (typos, erreur de transmission, etc.). Il rapporte que seulement 11% des phrases test&#233;es
&#233;taient diff&#233;rentes de celles publi&#233;es.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Langlais, Leplus, Gandrabur et Lapalme
</p>
<p>Ce protocole d&#8217;&#233;valuation correspond grossi&#232;rement au n&#244;tre lorsque nous mesurons un taux
d&#8217;erreur au niveau des phrases. Les approches que nous avons impl&#233;ment&#233;es ne montrent pas un
tel niveau de performance. Cependant, une comparaison directe des deux protocoles n&#8217;est pas
ad&#233;quate. Premi&#232;rement, nous &#233;valuons nos approches sur un corpus bien plus grand (36 228
phrases). Deuxi&#232;mement, nous avons mesur&#233; un bruit d&#8217;environ 7% dans notre r&#233;f&#233;rence.
Troisi&#232;mement, une &#233;valuation informelle d&#8217;un &#233;chantillon de 1000 traductions (choisies al&#233;a-
toirement) diff&#233;rentes de celles de notre r&#233;f&#233;rence, nous a r&#233;v&#233;l&#233; que 77% d&#8217;entre-elles &#233;taient
des traductions correctes.
</p>
<p>R&#233;f&#233;rences
AKIBA Y., FEDERICO M., KANDO N., NAKAIWA H., PAUL M. &amp; TSUJII J. (2004). Overview of
the IWSLT04 evaluation campaign. In Proceedings of the International Workshop on Spoken Language
Translation, p. 1&#8211;12, Kyoto.
</p>
<p>BANGALORE S., MURDOCK V. &amp; RICCARDI G. (2002). Bootstrapping bilingual data using consensus
translation for a multilingual instant messaging system. In Proceedings of COLING, p. 50&#8211;56, Taipei.
BLATZ, J., FITZGERALD, E., FOSTER, G., GANDRABUR, S., GOUTTE, C., KULESZA, A., SANCHIS,
A., UEFFING &amp; N. (2004). Confidence estimation for machine translation. In Proceedings of COLING,
p. 315&#8211;321, Geneva.
BROWN P., PIETRA S. D., PIETRA V. D. &amp; MERCER R. (1993). The mathematics of statistical machine
translation: Parameter estimation. Computational Linguistics, 19(2), 263&#8211;311.
COLLOBERT R., BENGIO S. &amp; MARI&#201;THOZ. J. (2002). Torch: a modular machine learning software
library. Rapport interne IDIAP-RR 02-46, IDIAP.
KNIGHT K. &amp; AL-ONAIZAN Y. (1999). A Primer on Finite-State Software for Natural Language
Processing. http://www.isi.edu/licensed-sw/carmel/carmel-tutorial2.pdf.
</p>
<p>KOEHN P. (2004). Pharaoh: a beam search decoder for phrase-based smt. In Proceedings of AMTA, p.
115&#8211;124, Washington.
KOEHN P., OCH F. &amp; MARCU D. (2003). Statistical phrase-based translation. In Proceedings of HLT,
p. 127&#8211;133, Edmonton.
</p>
<p>LANGLAIS P., LEPLUS T., GANDRABUR S. &amp; LAPALME G. (2005). From the real world to real words:
The meteo case. In in 10th Annual Conference of the European Association for Machine Translation,
Budapest, Hungary.
</p>
<p>LEPLUS T., LANGLAIS P. &amp; LAPALME G. (2004). Weather report translation using a translation mem-
ory. In Proceedings of AMTA, p. 154&#8211;163, Washington.
MACKLOVITCH E. (1985). A Linguistic Performance Evaluation of METEO 2. Rapport interne, Cana-
dian Translation Bureau.
</p>
<p>THOMPSON J., HIGGINS D. &amp; GIBSON T. (1994). CLUSTAL W: Improving the sensitivity of pro-
gressive multiple sequence alignment through sequence weighting, position-specific gap penalties and
weight matrix choice. Nucleic Acids Research, 22(22), 4673&#8211;4680.
WAHLSTER, Ed. (2000). Verbmobil: Foundations of speech-to-speech translations. Berlin, Germany:
Springer Verlag.
</p>
<p>ZENS R. &amp; NEY H. (2004). Improvements in phrase-based statistical machine translation. In Proceed-
ings of HLT/NAACL, p. 257&#8211;264, Boston.</p>

</div></div>
</body></html>