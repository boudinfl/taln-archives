TALN 2005, Dourdan, 6-10 juin 2005

Approches en corpus pour la traduction: le cas METEO

Philippe Langlais, Thomas Leplus
Simona Gandrabur et Guy Lapalme
RALI
Université de Montreal
http://rali.iro.umontreal.ca/

Mots-clefs I Mémoire de traduction, traduction probabiliste, alignements multiples, ré-
ordonnancement a postériori

Keywords: Memory-based translation, statistical translation, multiple alignment, rescor-
ing

Résumé La traduction automatique (TA) attire depuis plusieurs années l’intérét d’un nom-
bre grandissant de chercheurs. De nombreuses approches sont proposées et plusieurs cam-
pagnes d’évaluation rythment les avancées faites. La tache de traduction a laquelle les par-
ticipants de ces campagnes se prétent consiste presque invariablement a traduire des articles
journalistiques d’une langue étrangere vers l’anglais; tache qui peut sembler artiﬁcielle. Dans
cette étude, nous nous intéressons a savoir ce que différentes approches basées sur les corpus
peuvent faire sur une tache réelle. Nous avons reconstruit a cet effet l’un des plus grands succes
de la TA: le systeme METEO. Nous montrons qu’une combinaison de mémoire de traduc-
tion et d’approches statistiques permet d’obtenir des résultats comparables a celles du systeme
METEO, tout en offrant un cycle de développement plus court et de plus grandes possibilités
d’ ajustements.

Abstract Machine Translation (MT) is the focus of extensive scientiﬁc investigations
driven by regular evaluation campaigns, but which are mostly oriented towards a somewhat
artiﬁcial task: translating news articles into English. In this paper, we investigate how well cur-
rent MT approaches deal with a real-world task. We have rationally reconstructed one of the
only MT systems in daily production use: the METEO system. We show how a combination
of a sentence-based memory approach, a phrase-based statistical engine and a neural-network
rescorer can give results comparable to those of the current system while offering a faster de-
velopment cycle and better customization possibilities.

Langlais, Leplus, Gandrabur et Lapalme

1 Introduction

Depuis la reprise des campagnes d’évaluation NIST1 la traduction automatique (TA) revét un
caractere de plus en plus compétitif. La tache partagée a laquelle se prétent les "compétiteurs"
de ces campagnes d’évaluation consiste a traduire vers l’anglais des textes joumalistiques. S’il
est clair que cette tache répond en partie a des préoccupations concretes du pays organisateur,
il n’est cependant pas immédiat d’imaginer des applications réelles de la technologie évaluée.

Des taches de traduction plus spéciﬁques existent cependant. Lors du workshop IWSLT (Akiba
et al., 2004) dont l’objectif premier était de proposer un protocole d’évaluation adapté a la
traduction de corpus oralisés, la tache partagée consistait a traduire des phrases du corpus BTEC
(Basic Travel Expression Corpus). Ce corpus regroupe des phrases susceptibles d’étre utiles
a un touriste a l’étranger. Une autre tache de traduction plus ciblée et qui a fait l’objet de
nombreuses études est la tache Verbmobil (Wahlster, 2000) qui consiste a traduire des dialogues
de taches précises (comme la prise de rendez-vous) pour la paire de langue anglais/allemand.

Dans cette étude, nous nous intéressons a une tache encore plus précise et dont l’applicabilité ne
fait cette fois-ci aucun doute puisqu’elle est reconnue comme l’un des plus grand succes de la
traduction automatique: la traduction de l’anglais vers le frangais de bulletins météorologiques
émis par Environnement Canada (EC)2. Nous baptisons cette tache METEO.

Récemment, Leplus et al. (2004) montraient qu’a l’aide d’une mémoire de traduction phrastique
peuplée de bulletins météorologiques déja traduits, il était possible d’obtenir des traductions de
bonne qualité. Ils expliquaient leur succes par un fort taux de répétitivité des phrases que le
systeme METEO traduit. Dans ce travail, nous étudions la pertinence de plusieurs approches
basées sur les corpus a traduire les bulletins météorologiques.

2 Protocole

Nous avons utilisé dans ce travail le bitexte décrit dans (Leplus et al., 2004). Nous avons repris
le méme découpage en trois partie de ce bitexte: TRAIN pour l’entrainement des systemes,
BLANC pour leur ajustement et TEST pour tester les différentes approches. Ce découpage avait
été choisi de maniere a ce que les textes soient d’une période disjointe et que la tranche de test
soit d’une période postérieure a celle de l’entrainement; ceci aﬁn de simuler autant que faire se
peut les conditions réelles d’utilisation du systeme.

Pour évaluer nos différentes approches, nous utilisons des métriques automatiques qui bien que
discutables n’en sont pas moins largement utilisées: deux taux d’erreurs — WER au niveau
des mots et SER au niveau des phrases — que l’on cherchera a Ininimiser et deux mesures de
couverture n-gramme — NIST et 100><BLEU — que l’on voudra maximiser, toutes les deux
calculées par le script mt eval (version 11a) disponible depuis le site de NIST.

1Consulter http: / /www . ni st . gov/ speech/test s /mt/ pour plus d’infonnation.

2Le bulletin en cours peut étre consulté a l’adresse http://meteo.ec.gc.ca/forecast/
text forecast_f . html

Approches en corpus pour la traduction: le cas METEO

3 Mémoire de traduction phrastique

Nous avons mesuré que 83% des phrases du corpus BLANC sont présentes verbatim dans le
corpus TRAIN. Cette couverture atteint 87% si nous introduisons quelques classes de mots
comme les jours, les mois ou encore les numéros de téléphones. Nous avons donc commencé
par reproduire l’approche mémoire de traduction phrastique proposée par Leplus et al. (2004).

Nous avons construit une mémoire en gardant de chaque phrase source de TRAIN, un maxi-
mum de 5 traductions. En pratique, 89% des phrases anglaises de TRAIN n’ont qu’une seule
traduction, probablement en raison du fait que la plupart des phrases ont été produites automa-
tiquement (nous reviendrons sur ce point dans la section 7).

Pour une nouvelle phrase a traduire, nous recherchons les phrases sources les plus proches (en
terme de distance d’édition) dans la mémoire et trions les traductions associées selon un score
dont le détail est décrit dans (Langlais et al., 2005). Dans cette experience, la premiere phrase
cible retournée est la traduction retenue.

mémoire Leplus et al.
WER% SER% NIST BLEU WER% SER% NIST BLEU
8.42 23.43 10.9571 87.68 9.18 23.56 10.8983 86.95

Table 1: Evaluation de l’approche mémoire phrastique sur le corpus TEST et comparaison avec
l’approche Leplus et al. (2004).

Les scores sont tres bons si on les compare avec ceux observés dans d’autres taches de tra-
duction. Nous référons le lecteur a l’étude de Zens et Ney (2004) pour des performances état
de l’art sur trois taches de traduction incluant Verbmobil. Nos performances sont également
légerement supérieures a celles mentionnées par (Leplus et al., 2004). I1 n’en reste cependant
pas moins que le taux d’erreur au niveau des phrases (c’est-a-dire le pourcentage de traductions
produites non identiques a la traduction de référence) n’est pas particulierement bas.

4 Approche probabiliste

Nous avons testé dans un deuxieme temps une approche état de l’art en traduction statistique
(Koehn et al., 2003). Elle s’appuie sur un modele de la distribution conditionnelle d’une
séquence de mots dans une langue étant donnée une séquence dans l’autre langue. Les de-
tails de l’obtention des modeles probabilistes sous-jacents sont donnés dans (Langlais et al.,
2005). Nous avons fait usage du décodeur PHARAOH (Koehn, 2004) disponible gratuitement
pour des ﬁns de recherche.

Les performances du systeme probabiliste sont présentées en table 2. Une comparaison directe
avec les résultats mesurés avec l’approche mémoire milite en faveur de la mémoire, surtout
si l’on observe le taux d’erreur au niveau des phrases. Cependant, nous remarquons que la
performance du traducteur probabiliste lorsque mesurée sur les phrases a traduire qui n’ont pas
été vues verbatim dans le corpus TRAIN sont de loin supérieures a celles obtenues par l’approche
mémoire. Nous reviendrons sur la complémentarité de ces deux approches en section 7.

Langlais, Leplus, Gandrabur et Lapalme

WER% SER% NIST BLEU
7.46 32.01 10.8725 84.03

Table 2: Evaluation de l’approche statistique sur TEST.

5 Approche consensuelle

Bangalore et al. (2002) ont montré qu’il était possible de combiner des traductions produites
par différents moteurs de traduction aﬁn de générer des traductions d’une qualité supérieure a
celles produites par un seul des moteurs. L’idée sous-jacente a cette approche (bootstrapping)
est l’alignement de plusieurs traductions candidates aﬁn d’isoler des ilots de conﬁance capables
de diriger la génération d’une traduction dite consensuelle. Nous retrouvons cette idée dans
certains systemes d’acquisition et de génération de paraphrases.

Nous avons reproduit cette approche et avons pour cela adapté a nos besoins le programme
CLUSTALW (Thompson et al., 1994) écrit pour aligner entre-elles plusieurs séquences de pro-
téines. A partir d’un alignement multiple de traduction (dont le lecteur trouvera les détails
dans (Langlais et al., 2005)), nous pouvons construire un treillis qui permet de produire en
sus des traductions alignées de nouvelles phrases que l’on espere plus robustes. Nous utilisons
le package CARMEL (Knight & Al-Onaizan, 1999) pour trouver dans un treillis la traduction
consensuelle; c’est-a-dire le chemin de plus faible coﬁt dans le treillis.

Les résultats de cette approche sont présentés en table 3 pour les seules phrases de BLANC
non rencontrées verbatim dans le corpus ayant servi a créer la mémoire. Nous observons que
la traduction par consensus améliore la qualité (telle que mesurée) des traductions produites.
Le taux d’erreur au niveau des phrases est en particulier réduit de 9 points (en absolu), ce qui
constitue une amélioration notable.

mémoire mémoire + consensus
WER% SER% NIST BLEU WER% SER% NIST BLEU
18.69 94.82 9.7853 66.56 18.97 85.53 9.9314 68.86

Table 3: Performance de l’approche consensuelle sur la sortie de la mémoire de traduction pour
les 13 010 phrases de BLANC non rencontrées dans le corpus TRAIN.

6 Ré-ordonnancement par apprentissage neuronal

Dans notre cadre, le rescoring consiste a ré-ordonner une liste d’altematives produites par un
systeme (dit natif) avec l’espoir que des informations supplémentaires, ou différentes facons de
les utiliser, permettent de produire un ordonnancement plus pertinent. Le rescoring a fait l’obj et
d’études récentes en traduction probabiliste (Blatz et al., 2004).

Dans notre contexte, cela consiste a reclasser la liste des meilleures traductions générées par
PHARAOH (Koehn, 2004) pour une phrase donnée. Chaque alternative de traduction tj est
représentée par un vecteur de traits 11]‘ et est étiquetée comme correcte si elle est identique a la
traduction de référence et incorrecte sinon. Nous avons utilisé le package TORCH (Collobert

Approches en corpus pour la traduction: le cas METEO

et al., 2002) pour entrainer un réseau perceptron multi-couche a estimer p(€B |vj), la probabilité
conditionnelle de la correctitude d’une alternative tj.

Nous avons testé différentes conﬁgurations de la couche cachée du réseau et avons considéré de
nombreux traits pour représenter nos alternatives, chacun encodant des caractéristiques partic-
ulieres. Les plus utiles étaient a) le ratio des longueurs de la phrase source et de la traduction
candidate, b) la probabilité a posteriori de l’alternative et c) les scores p(tj |s) calculés par les
modeles IBM 1 et 2 (Brown et al., 1993). De plus amples informations sur cette approche sont
disponibles dans (Langlais et al., 2005).

Nous présentons en table 4 les performances mesurées par l’étape de rescoring.

smt smt + rescoring
WER% SER% NIST BLEU WER% SER% NIST BLEU
7.46 32.01 10.8725 84.03 5.73 25.03 10.9828 87.40

Table 4: Comparaison des performances du moteur probabiliste (smt) seul et des traductions
produites par reclassement (smt + rescoring) sur TEST.

7 Discussion

La diversité des approches que nous avons implémentées nous donne la souplesse de pouvoir
les combiner. Pour illustrer ce point, nous avons évalué une combinaison tres simple ou la
mémoire seule est consultée lorsque la phrase a traduire est déja dans la mémoire, et ou le
moteur de traduction probabiliste rescore’ est consulté sinon. Les performances ainsi mesurées
(voir la table 5) sont meilleures que celles de chaque approche prise isolément.

WER% SER% NIST BLEU
4.85 20.80 11.3021 89.59

Table 5: Performance sur TEST de la combinaison de la mémoire et du moteur de traduction
probabiliste reclassé.

Il est cependant approprié de s’interroger quant a la performance véritable d’un tel systeme. Il
est en particulier intéressant de contraster ces résultats avec ceux mesurés par le bureau de
la traduction du Canada (BTC) qui est en charge de produire les traductions des bulletins
météorologiques produits par Environnement Canada (EC). Le BTC utilise en effet le systeme
METEO pour traduire automatiquement les bulletins anglais, mais a la responsabilité de réviser
tout ou partie des traductions ainsi produites.

(Macklovitch, 1985) décrit une évaluation du systeme METEO-II conduite par le BTC. L’ auteur
a sélectionné 1257 phrases francaises publiées sur une période de 24 heures par EC eta compté
le nombre de fois ou le systeme produisait exactement la méme traduction que celle qui a été
publiée. Les erreurs dues a des fautes ﬂagrantes non imputables au systeme étaient cependant
écartées (typos, erreur de transmission, etc.). Il rapporte que seulement 11% des phrases testées
étaient différentes de celles publiées.

Langlais, Leplus, Gandrabur et Lapalme

Ce protocole d’évaluation correspond grossierement au notre lorsque nous mesurons un taux
d’erreur au niveau des phrases. Les approches que nous avons implémentées ne montrent pas un
tel niveau de performance. Cependant, une comparaison directe des deux protocoles n’est pas
adéquate. Premierement, nous évaluons nos approches sur un corpus bien plus grand (36 228
phrases). Deuxiemement, nous avons mesuré un bruit d’environ 7% dans notre référence.
Troisiemement, une évaluation informelle d’un échantillon de 1000 traductions (choisies aléa-
toirement) différentes de celles de notre référence, nous a révélé que 77% d’entre-elles étaient
des traductions correctes.

Références

AKIBA Y., FEDERICO M., KANDO N., NAKAIWA H., PAUL M. & TSUJII J. (2004). Overview of
the IWSLT04 evaluation campaign. In Proceedings of the International Workshop on Spoken Language
Translation, p. 1-12, Kyoto.

BANGALORE S., MURDOCK V. & RICCARDI G. (2002). Bootstrapping bilingual data using consensus
translation for a multilingual instant messaging system. In Proceedings of COLING, p. 50-56, Taipei.

BLATZ, J ., FITZGERALD, E., FOSTER, G., GANDRABUR, S., GOUTTE, C., KULESZA, A., SANCHIS,
A., UEFFING & N. (2004). Conﬁdence estimation for machine translation. In Proceedings of COLING,
p. 315-321, Geneva.

BROWN P., PIETRA S. D., PIETRA V. D. & MERCER R. (1993). The mathematics of statistical machine
translation: Parameter estimation. Computational Linguistics, 19(2), 263-311.

COLLOBERT R., BENGIO S. & MARIETHOZ. J . (2002). Torch: a modular machine learning software
library. Rapport inteme IDIAP-RR 02-46, IDIAP.

KNIGHT K. & AL-ONAIZAN Y. (1999). A Primer on Finite-State Software for Natural Language
Processing. http://www.isi.edu/1icensed-sw/carmel/carmel-tutorial2.pdf.

KOEHN P. (2004). Pharaoh: a beam search decoder for phrase-based smt. In Proceedings of AMTA, p.
115-124, Washington.

KOEHN P., OCH F. & MARCU D. (2003). Statistical phrase-based translation. In Proceedings of HLT,
p. 127-133, Edmonton.

LANGLAIS P., LEPLUS T., GANDRABUR S. & LAPALME G. (2005). From the real world to real words:
The meteo case. In in 10th Annual Conference of the European Association for Machine Translation,
Budapest, Hungary.

LEPLUS T., LANGLAIS P. & LAPALME G. (2004). Weather report translation using a translation mem-
ory. In Proceedings of AMTA, p. 154-163, Washington.

MACKLOVITCH E. (1985). A Linguistic Performance Evaluation of METEO 2. Rapport inteme, Cana-
dian Translation Bureau.

THOMPSON J ., HIGGINS D. & GIBSON T. (1994). CLUSTAL W: Improving the sensitivity of pro-
gressive multiple sequence alignment through sequence weighting, position-speciﬁc gap penalties and
weight matrix choice. Nucleic Acids Research, 22(22), 4673-4680.

WAHLSTER, Ed. (2000). Verbmobil: Foundations of speech-to-speech translations. Berlin, Germany:
Springer Verlag.

ZENS R. & NEY H. (2004). Improvements in phrase-based statistical machine translation. In Proceed-
ings of HLTﬂVAACL, p. 257-264, Boston.

