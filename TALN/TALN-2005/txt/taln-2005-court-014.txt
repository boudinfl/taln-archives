TALN 2005, Dourdan, 6-10 juin 2005

Approches en corpus pour la traduction: le cas METEO

Philippe Langlais, Thomas Leplus
Simona Gandrabur et Guy Lapalme
RALI
Université de Montreal
http://rali.iro.umontreal.ca/

M0tS-Cl€fS I Mémoire de traduction, traduction probabiliste, alignements multiples, re-
ordonnancement a postériori

K€yWOFdS2 Memory—based translation, statistical translation, multiple alignment, rescor-
ing

Résumé La traduction automatique (TA) attire depuis plusieurs années l’intérét d’un nom-
bre grandissant de chercheurs. De nombreuses approches sont proposées et plusieurs cam-
pagnes d’évaluation rythment les avancées faites. La tache de traduction a laquelle les par-
ticipants de ces campagnes se prétent consiste presque invariablement a traduire des articles
journalistiques d’une langue étrangere vers l’anglais; tache qui peut sembler artiﬁcielle. Dans
cette etude, nous nous intéressons a savoir ce que différentes approches basées sur les corpus
peuvent faire sur une tache réelle. Nous avons reconstruit a cet effet l’un des plus grands succes
de la TA: le systeme METEO. Nous montrons qu’une combinaison de mémoire de traduc-
tion et d’approches statistiques permet d’obtenir des résultats comparables a celles du systeme
METEO, tout en offrant un cycle de développement plus court et de plus grandes possibilités
d’ajustements.

Abstract Machine Translation (MT) is the focus of extensive scientiﬁc investigations
driven by regular evaluation campaigns, but which are mostly oriented towards a somewhat
artiﬁcial task: translating news articles into English. In this paper, we investigate how well cur-
rent MT approaches deal with a real—world task. We have rationally reconstructed one of the
only MT systems in daily production use: the METEO system. We show how a combination
of a sentence—based memory approach, a phrase—based statistical engine and a neural—network
rescorer can give results comparable to those of the current system while offering a faster de-
velopment cycle and better customization possibilities.

463

464

Langlais, Leplus, Gandrabur et Lapalme

1 Introduction

Depuis la reprise des campagnes d’evaluation NIST1 la traduction automatique (TA) revét un
caractere de plus en plus competitif. La tache partagee a laquelle se prétent les "competiteurs"
de ces campagnes d’evaluation consiste a traduire vers l’anglais des textes journalistiques. S’il
est clair que cette tache repond en partie a des preoccupations concretes du pays organisateur,
il n’est cependant pas immediat d’imaginer des applications reelles de la technologie evaluee.

Des taches de traduction plus speciﬁques existent cependant. Lors du workshop IWSLT (Akiba
er al., 2004) dont l’objectif premier etait de proposer un protocole d’evaluation adapte a la
traduction de corpus oralises, la tache partagee consistait a traduire des phrases du corpus BTEC
(Basic Travel Expression Corpus). Ce corpus regroupe des phrases susceptibles d’étre utiles
a un touriste a l’étranger. Une autre tache de traduction plus ciblee et qui a fait l’objet de
nombreuses etudes est la tache Verbmobil (Wahlster, 2000) qui consiste a traduire des dialogues
de taches precises (comme la prise de rendez—vous) pour la paire de langue anglais/allemand.

Dans cette etude, nous nous interessons a une tache encore plus precise et dont l’applicabilite ne
fait cette fois—ci aucun doute puisqu’elle est reconnue comme l’un des plus grand succes de la
traduction automatique: la traduction de l’anglais vers le francais de bulletins meteorologiques
émis par Envirormement Canada (EC)2. Nous baptisons cette tache METEO.

Recemment, Leplus et al. (2004) montraient qu’a l’ aide d’une memoire de traduction phrastique
peuplee de bulletins meteorologiques deja traduits, il était possible d’obtenir des traductions de
bonne qualite. Ils expliquaient leur succes par un fort taux de repetitivite des phrases que le
systeme METEO traduit. Dans ce travail, nous etudions la pertinence de plusieurs approches
basees sur les corpus a traduire les bulletins metéorologiques.

2 Protocole

Nous avons utilise dans ce travail le bitexte decrit dans (Leplus er al., 2004). Nous avons repris
le meme decoupage en trois partie de ce bitexte: TRAIN pour l’entrainement des systemes,
BLANC pour leur ajustement et TEST pour tester les differentes approches. Ce decoupage avait
éte choisi de maniere a ce que les textes soient d’une periode disjointe et que la tranche de test
soit d’une periode posterieure a celle de l’entrainement; ceci aﬁn de simuler autant que faire se
peut les conditions reelles d’utilisation du systeme.

Pour evaluer nos differentes approches, nous utilisons des métriques automatiques qui bien que
discutables n’en sont pas moins largement utilisees: deux taux d’erreurs — WER au niveau
des mots et SER au niveau des phrases — que l’on cherchera a minirniser et deux mesures de
couverture n—gramme — NIST et l00><BLEU — que l’on voudra maximiser, toutes les deux
calculees par le script mt eval (version lla) disponible depuis le site de NIST.

1Consulter http: / /www . r1i st . gov/ speech/tests/mt/ pour plus d’information.

2Le bulletin en cours peut étre consulté a l’adresse http://meteo.ec.gc.ca/forecast/
textforecast_f . html

Approches en corpus pour la traduction: le cas METEO

3 Mémoire de traduction phrastique

Nous avons mesure que 83% des phrases du corpus BLANC sont presentes verbatim dans le
corpus TRAIN. Cette couverture atteint 87% si nous introduisons quelques classes de mots
comme les jours, les mois ou encore les numeros de telephones. Nous avons donc commence
par reproduire l’approche memoire de traduction phrastique proposee par Leplus et al. (2004).

Nous avons construit une memoire en gardant de chaque phrase source de TRAIN, un maxi-
mum de 5 traductions. En pratique, 89% des phrases anglaises de TRAIN n’ont qu’une seule
traduction, probablement en raison du fait que la plupart des phrases ont ete produites automa-
tiquement (nous reviendrons sur ce point dans la section 7).

Pour une nouvelle phrase a traduire, nous recherchons les phrases sources les plus proches (en
terme de distance d’edition) dans la memoire et trions les traductions associees selon un score
dont le detail est decrit dans (Langlais er al., 2005). Dans cette experience, la premiere phrase
cible retournee est la traduction retenue.

memoire Leplus et al.
WER% SER% NIST BLEU WER% SER% NIST BLEU
8.42 23.43 10.9571 87.68 9.18 23.56 10.8983 86.95

Table 1: Evaluation de l’approche memoire phrastique sur le corpus TEST et comparaison avec
l’approche Leplus et al. (2004).

Les scores sont tres bons si on les compare avec ceux observes dans d’autres taches de tra-
duction. Nous referons le lecteur a l’etude de Zens et Ney (2004) pour des performances etat
de l’art sur trois taches de traduction incluant Verbmobil. Nos performances sont egalement
legerement superieures a celles mentionnees par (Leplus er al., 2004). Il n’en reste cependant
pas moins que le taux d’erreur au niveau des phrases (c’est—a—dire le pourcentage de traductions
produites non identiques a la traduction de reference) n’est pas particulierement bas.

4 Approche probabiliste

Nous avons teste dans un deuxieme temps une approche etat de l’art en traduction statistique
(Koehn er al., 2003). Elle s’appuie sur un modele de la distribution conditionnelle d’une
sequence de mots dans une langue etant donnee une sequence dans l’autre langue. Les de-
tails de l’obtention des modeles probabilistes sous—jacents sont donnes dans (Langlais er al.,
2005). Nous avons fait usage du decodeur PHARAOH (Koehn, 2004) disponible gratuitement
pour des ﬁns de recherche.

Les performances du systeme probabiliste sont presentees en table 2. Une comparaison directe
avec les resultats mesures avec l’approche memoire milite en faveur de la memoire, surtout
si l’on observe le taux d’erreur au niveau des phrases. Cependant, nous remarquons que la
performance du traducteur probabiliste lorsque mesuree sur les phrases a traduire qui n’ont pas
ete vues verbatim dans le corpus TRAIN sont de loin superieures a celles obtenues par l’approche
memoire. Nous reviendrons sur la complementarite de ces deux approches en section 7.

465

466

Langlais, Leplus, Gandrabur et Lapalme

NIST BLEU
10.8725 84.03

WER% SER%
7.46 32.01

Table 2: Evaluation de l’approche statistique sur TEST.

5 Approche consensuelle

Bangalore et al. (2002) ont montre qu’il était possible de combiner des traductions produites
par differents moteurs de traduction aﬁn de génerer des traductions d’une qualite superieure a
celles produites par un seul des moteurs. L’ idee sous—jacente a cette approche (bootstrapping)
est l’alignement de plusieurs traductions candidates aﬁn d’isoler des ilots de conﬁance capables
de diriger la generation d’une traduction dite consensuelle. Nous retrouvons cette idee dans
certains systemes d’acquisition et de generation de paraphrases.

Nous avons reproduit cette approche et avons pour cela adapte a nos besoins le programme
CLUSTALW (Thompson et al., 1994) ecrit pour aligner entre—elles plusieurs sequences de pro-
teines. A partir d’un alignement multiple de traduction (dont le lecteur trouvera les details
dans (Langlais et al., 2005)), nous pouvons construire un treillis qui permet de produire en
sus des traductions alignees de nouvelles phrases que l’on espere plus robustes. Nous utilisons
le package CARMEL (Knight & Al—Onaizan, 1999) pour trouver dans un treillis la traduction
consensuelle; c’est—a—dire le chemin de plus faible coﬁt dans le treillis.

Les resultats de cette approche sont présentes en table 3 pour les seules phrases de BLANC
non rencontrées verbatim dans le corpus ayant servi a creer la memoire. Nous observons que
la traduction par consensus ameliore la qualite (telle que mesurée) des traductions produites.
Le taux d’erreur au niveau des phrases est en particulier reduit de 9 points (en absolu), ce qui
constitue une amelioration notable.

memoire + consensus
WER% SER% NIST BLEU
18.97 85.53 9.9314 68.86

mémoire
WER% SER% NIST BLEU
18.69 94.82 9.7853 66.56

Table 3: Performance de l’approche consensuelle sur la sortie de la memoire de traduction pour
les 13 010 phrases de BLANC non rencontrees dans le corpus TRAIN.

6 Ré-ordonnancement par apprentissage neuronal

Dans notre cadre, le rescoring consiste a re—ordonner une liste d’altematiVes produites par un
systeme (dit natif) avec l’espoir que des informations supplementaires, ou differentes facons de
les utiliser, permettent de produire un ordonnancement plus pertinent. Le rescoring a fait l’objet
d’études recentes en traduction probabiliste (Blatz et al., 2004).

Dans notre contexte, cela consiste a reclasser la liste des meilleures traductions genérees par
PHARAOH (Koehn, 2004) pour une phrase donnée. Chaque alternative de traduction tj est
representee par un Vecteur de traits vj et est etiquetee comme correcte si elle est identique a la
traduction de reference et incorrecte sinon. Nous avons utilise le package TORCH (Collobert

Approches en corpus pour la traduction: le cas METEO

er al., 2002) pour entrainer un reseau perceptron multi—couche a estimer p(@3 |vj), la probabilite
conditionnelle de la correctitude d’une alternative tj.

Nous avons teste differentes conﬁgurations de la couche cachee du reseau et avons considere de
nombreux traits pour representer nos alternatives, chacun encodant des caracteristiques partic-
ulieres. Les plus utiles etaient a) le ratio des longueurs de la phrase source et de la traduction
candidate, b) la probabilite a posteriori de l’alternative et c) les scores p(tj |s) calcules par les
modeles IBM 1 et 2 (Brown et al., 1993). De plus amples informations sur cette approche sont
disponibles dans (Langlais er al., 2005).

Nous presentons en table 4 les performances mesurees par l’etape de rescoring.

smt smt + rescoring
WER% SER% NIST BLEU WER% SER% NIST BLEU
7.46 32.01 10.8725 84.03 5.73 25.03 10.9828 87.40

Table 4: Comparaison des performances du moteur probabiliste (smt) seul et des traductions
produites par reclassement (smt + rescoring) sur TEST.

7 Discussion

La diversite des approches que nous avons implementees nous donne la souplesse de pouvoir
les combiner. Pour illustrer ce point, nous avons evalue une combinaison tres simple ou la
memoire seule est consultee lorsque la phrase a traduire est deja dans la memoire, et ou le
moteur de traduction probabiliste rescoré est consulte sinon. Les performances ainsi mesurees
(voir la table 5) sont meilleures que celles de chaque approche prise isolement.

WER% SER% NIST
4.85 20.80 11.3021

BLEU
89.59

Table 5: Performance sur TEST de la combinaison de la memoire et du moteur de traduction
probabiliste reclasse.

Il est cependant approprie de s’interroger quant a la performance veritable d’un tel systeme. Il
est en particulier interessant de contraster ces resultats avec ceux mesures par le bureau de
la traduction da Canada (BTC) qui est en charge de produire les traductions des bulletins
meteorologiques produits par Environnement Canada (EC). Le BTC utilise en effet le systeme
METEO pour traduire automatiquement les bulletins anglais, mais a la responsabilite de reviser
tout ou partie des traductions ainsi produites.

(Macklovitch, 1985) decrit une evaluation du systeme METEO—II conduite par le BTC. L’ auteur
a selectionne 1257 phrases francaises publiees sur une periode de 24 heures par EC eta compte
le nombre de fois ou le systeme produisait exactement la meme traduction que celle qui a ete
publiee. Les erreurs dues a des fautes ﬂagrantes non imputables au systeme etaient cependant
écartees (typos, erreur de transmission, etc.). Il rapporte que seulement 11% des phrases testees
etaient differentes de celles publiees.

467

468

Langlais, Leplus, Gandrabur et Lapalme

Ce protocole d’evaluation correspond grossierement au notre lorsque nous mesurons un taux
d’erreur au niveau des phrases. Les approches que nous avons implementees ne montrent pas un
tel niveau de performance. Cependant, une comparaison directe des deux protocoles n’est pas
adequate. Premierement, nous evaluons nos approches sur un corpus bien plus grand (36 228
phrases). Deuxiemement, nous avons mesure un bruit d’environ 7% dans notre reference.
Troisiemement, une evaluation informelle d’un echantillon de 1000 traductions (choisies alea—
toirement) differentes de celles de notre reference, nous a revele que 77% d’entre—elles etaient
des traductions correctes.

Références

AKIBA Y., FEDERICO M., KANDO N., NAKAIWA H., PAUL M. & TSUJII J. (2004). Overview of
the IWSLT04 evaluation campaign. In Proceedings of the International Workshop on Spoken Language
Translation, p. 1-12, Kyoto.

BANGALORE S., MURDOCK V. & RICCARDI G. (2002). Bootstrapping bilingual data using consensus
translation for a multilingual instant messaging system. In Proceedings of COLING, p. 50-56, Taipei.

BLATZ, J., FITZGERALD, E., FOSTER, G., GANDRABUR, S., GOUTTE, C., KULESZA, A., SANCHIS,
A., UEFFING & N. (2004). Conﬁdence estimation for machine translation. In Proceedings of COLING,
p. 315-321, Geneva.

BROWN P., PIETRA S. D., PIETRA V. D. & MERCER R. (1993). The mathematics of statistical machine
translation: Parameter estimation. Computational Linguistics, 19(2), 263-311.

COLLOBERT R., BENGIO S. & MARIETHOZ. J . (2002). Torch.‘ a modular machine learning software
library. Rapport interne IDLAP—RR 02-46, IDLAP.

KNIGHT K. & AL—ONAIZAN Y. (1999). A Primer on Finite—State Software for Natural Language
Processing. http://www.isi.edu/licensed-sw/carrnel/carmel—tutorial2.pdf.

KOEHN P. (2004). Pharaoh: a beam search decoder for phrase—based smt. In Proceedings of AMTA, p.
115-124, Washington.

KOEHN P., OCH F. & MARCU D. (2003). Statistical phrase—based translation. In Proceedings of HLT ,
p. 127-133, Edmonton.

LANGLAIS P., LEPLUS T., GANDRABUR S. & LAPALME G. (2005). From the real world to real words:
The meteo case. In in 10th Annual Conference of the European Association for Machine Translation,
Budapest, Hungary.

LEPLUS T., LAN GLAIS P. & LAPALME G. (2004). Weather report translation using a translation mem-
ory. In Proceedings of AMTA, p. 154-163, Washington.

MACKLOVITCH E. (1985). A Linguistic Performance Evaluation of MET E0 2. Rapport interne, Cana-
dian Translation Bureau.

THOMPSON J ., HIGGINS D. & GIBSON T. (1994). CLUSTAL W: Improving the sensitivity of pro-
gressive multiple sequence alignment through sequence weighting, position—speciﬁc gap penalties and
weight matrix choice. Nucleic Acids Research, 22(22), 4673-4680.

WAHLSTER, Ed. (2000). Verbmobil: Foundations of speech—to—speech translations. Berlin, Germany:
Springer Verlag.

ZENS R. & NEY H. (2004). Improvements in phrase—based statistical machine translation. In Proceed-
ings of HLT/NAACL, p. 257-264, Boston.

