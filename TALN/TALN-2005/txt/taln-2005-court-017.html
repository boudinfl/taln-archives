<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>R&#233;seau bayesien pour un mod&#232;le d'utilisateur et un module de compr&#233;hension pour l'optimisation des syst&#232;mes de dialogues</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2005, Dourdan, 6-10 juin 2005 
</p>
<p>R&#233;seau bay&#233;sien pour un mod&#232;le d&#8217;utilisateur et un module de 
compr&#233;hension pour l&#8217;optimisation des syst&#232;mes de dialogues 
</p>
<p>Olivier Pietquin 
</p>
<p>Sup&#233;lec, Campus de Metz &#8211; Equipe STS 
2 rue Edouard Belin &#8211; F-57070 Metz 
</p>
<p>olivier.pietquin@supelec.fr 
</p>
<p>Mots-cl&#233;s :   Syst&#232;mes de dialogue, simulation de dialogues, mod&#232;le d&#8217;utilisateur, 
optimisation.  
Keywords:   Spoken dialog systems, dialog simulation, user modeling, optimization 
R&#233;sum&#233; Dans cet article, un environnement modulaire pour la simulation automatique de 
dialogues homme-machine est propos&#233;. Cet environnement comprend notamment un mod&#232;le 
d&#8217;utilisateur consistant dirig&#233; par le but et un module de simulation de compr&#233;hension de parole. Un 
r&#233;seau bay&#233;sien est &#224; la base de ces deux mod&#232;les et selon les param&#232;tres utilis&#233;s, il peut g&#233;n&#233;rer un 
comportement d&#8217;utilisateur coh&#233;rent ou servir de classificateur de concepts. L&#8217;environnement a &#233;t&#233; 
utilis&#233; dans le contexte de l&#8217;optimisation de strat&#233;gies de dialogue sur une t&#226;che simple de remplissage 
de formulaire et les r&#233;sultats montrent qu&#8217;il est alors possible d&#8217;identifier certains dialogues 
probl&#233;matiques du point de vue de la compr&#233;hension.  
 
Abstract In this paper we present a modular environment for simulating human-machine 
dialogues by computer means. This environment includes a consistent goal-directed user model and a 
natural language understanding system model. Both models rely on a special Bayesian network used 
with different parameters in such a way that it can generate a consistent user behaviour according to a 
goal and the history of the interaction, and been used as a concept classifier. This environment was 
tested in the framework of optimal strategy learning for the simple form-filling task. The results show 
that the environment allows pointing out problematic dialogues that may occur because of 
misunderstanding between the user and the system. 
</p>
<p>1 Introduction 
Dans cet article, nous traitons essentiellement de simulation de dialogues homme-machine. 
Initialement, les syst&#232;mes de simulation &#233;taient destin&#233;s essentiellement &#224; la validation de mod&#232;les du 
discours (Power, 1979). Avec l'apparition des interfaces vocales sont aussi arriv&#233;s les probl&#232;mes de 
conception. La conception de ces interfaces est un processus cyclique dans lequel interviennent 
successivement des phases de d&#233;veloppement, de tests, d&#8217;&#233;valuations et d&#8217;am&#233;liorations. La phase la 
plus sujette aux contraintes de temps et d&#8217;argent et bien souvent celle de l&#8217;&#233;valuation et de test. Pour 
cette raison, la simulation en vue de l&#8217;&#233;valuation automatique des interfaces s&#8217;est r&#233;pandue depuis la 
fin des ann&#233;es 1990 (Eckert et al., 1998). De cette combinaison de la simulation et de l&#8217;automatisation 
de l&#8217;&#233;valuation a assez vite d&#233;coul&#233; une nouvelle application : l&#8217;apprentissage automatique de 
strat&#233;gies optimales (Levin, Pieraccini, 1997) (Singh et al., 1999). Dans cet article, un environnement 
de simulation de dialogues est propos&#233; dans le cadre de cette derni&#232;re application. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier Pietquin 
</p>
<p>De tels environnements existent donc d&#233;j&#224;. Certains utilisent des mod&#232;les statistiques de transitions 
entre &#233;tats obtenus d&#8217;apr&#232;s observation de dialogues r&#233;els, (Singh et al., 1999). D&#8217;autres utilisent un 
mod&#232;le d&#8217;utilisateur sans m&#233;moire (Levin, Pieraccini, 1997) et n&#8217;incluent pas de mod&#233;lisation de 
l&#8217;erreur. Ici, nous d&#233;crivons un environnement de simulation comprenant un mod&#232;le d&#8217;utilisateur 
consistant &#233;tant donn&#233; l&#8217;historique de l&#8217;interaction (avec m&#233;moire) et un but. Cet environnement 
comprend aussi un mod&#232;le de syst&#232;me de reconnaissance vocale ainsi qu&#8217;un module simulant la 
compr&#233;hension du langage naturel. En incluant ces modules dans l&#8217;environnement, nous esp&#233;rons que 
les strat&#233;gies apprises tiendront comptes de leurs lacunes.    
</p>
<p>2 Un mod&#232;le formel pour le dialogue vocal homme-machine 
De mani&#232;re formelle et comme le d&#233;crit la Figure 1, un dialogue vocal homme-machine peut &#234;tre 
consid&#233;r&#233; comme un processus s&#233;quentiel dans lequel un utilisateur humain et un syst&#232;me de gestion 
de dialogue (DM : Dialogue Manager) communiquent gr&#226;ce &#224; la parole au travers d&#8217;un canal de 
transmission. Ce canal est compos&#233; de diff&#233;rents modules qui manipulent chacun l&#8217;information pour 
lui faire prendre une forme utilisable par le ou les modules suivants. Le but d&#8217;un syst&#232;me de dialogue 
&#233;tant souvent de fournir de l&#8217;information &#224; l&#8217;utilisateur, le syst&#232;me de gestion de dialogues peut donc 
</p>
<p>acc&#233;der &#224; une base de connaissance.  
</p>
<p>Le processus &#233;tant s&#233;quentiel, il peut &#234;tre 
discr&#233;tis&#233; en tours t. A chaque tour, le 
gestionnaire de dialogue g&#233;n&#232;re un 
ensemble d&#8217;actes de communication at 
sur base de son &#233;tat interne st pouvant se 
mat&#233;rialiser en une invite, une question, 
une aide, une demande de confirmation, 
la fermeture du dialogue etc. Afin d&#8217;&#234;tre 
compris par l&#8217;utilisateur, cet ensemble est 
transform&#233; en un signal de parole syst par 
les syst&#232;mes de g&#233;n&#233;ration de sorties 
vocales. En fonction de ce qu&#8217;il a pu 
comprendre de ce signal, de sa 
</p>
<p>connaissance au moment t (kt) et du but qu&#8217;il poursuit en communiquant avec le syst&#232;me (gt), 
l&#8217;utilisateur produit &#224; son tour un signal de parole ut. Dans le cas particulier des syst&#232;mes de dialogue, 
le terme  &#8216;connaissance&#8217; peut faire r&#233;f&#233;rence &#224; la connaissance de l&#8217;utilisateur concernant l&#8217;historique 
de l&#8217;interaction, la t&#226;che, le syst&#232;me lui-m&#234;me ou le monde en g&#233;n&#233;ral. Les deux signaux vocaux ut et 
syst sont entach&#233;s par le bruit ambiant nt au moment de leur production. Le syst&#232;me de reconnaissance 
vocale (ASR) traite alors le signal ut et le transforme en un ensemble de mots wt. Au passage, le 
module ASR produit une mesure CLASR indiquant le degr&#233; de confiance qu&#8217;il accorde &#224; son r&#233;sultat. 
L&#8217;ensemble wt est ensuite pass&#233; au syst&#232;me de compr&#233;hension de parole (NLU) qui doit en retirer une 
repr&#233;sentation s&#233;mantique que nous supposerons mise sous la forme d&#8217;un ensemble de concepts ct. Le 
module NLU produit lui-aussi une mesure de confiance CLNLU associ&#233;e &#224; l&#8217;ensemble ct. L&#8217;ensemble 
{ct, CLASR, CLNLU} compose une observation ot qui est utilis&#233;e pour r&#233;aliser une mise &#224; jour de son &#233;tat 
interne.  D&#8217;un point de vue probabiliste, le comportement de l&#8217;utilisateur peut &#234;tre r&#233;sum&#233; par la 
probabilit&#233; conjointe suivante :  
</p>
<p>( ) ( ) ( ) ( )
( ) ( ) ( )44 344 213214434421
</p>
<p>444 3444 21444 344 2144 344 21
</p>
<p>rutilisateu Sortiebutdu on Modificaticeconnaissan de MAJ
</p>
<p>rutilisateu Sortiebutdu on Modificaticeconnaissan de MAJ
</p>
<p>,,,|  |,,|
</p>
<p>,,,,,|  ,,,,|,,,|,,,,,
</p>
<p>nsyskguPkgPnssyskP
</p>
<p>nsasyskguPnsasyskgPnsasyskPnsasyskguP
</p>
<p>&#8901;&#8901;=
</p>
<p>&#8901;&#8901;=
 (1) 
</p>
<p>Les simplifications dans (1) tiennent compte de plusieurs faits, notamment on peut raisonnablement 
admettre que la connaissance de l&#8217;utilisateur n&#8217;est pas modifi&#233;e par l&#8217;acte a puisque l&#8217;utilisateur n&#8217;a 
pas acc&#232;s directement &#224; cette valeur. De m&#234;me, sa r&#233;ponse ne d&#233;pend ni de l&#8217;acte a qu&#8217;il ne connait 
</p>
<p>Traitement des
sorties vocales
</p>
<p>NLUASR
wt
</p>
<p>CLASR
CLNLU
</p>
<p>ct
</p>
<p>G&#233;n&#233;ration
des sorties
</p>
<p>vocales
(NLG + TTS)
</p>
<p>d&#12;
Utilisateur
</p>
<p>gt,kt DM
</p>
<p>st+1
</p>
<p>st
</p>
<p>B
as
</p>
<p>e
de
</p>
<p> c
on
</p>
<p>na
is
</p>
<p>sa
nc
</p>
<p>es
</p>
<p>B
ru
</p>
<p>it
 
</p>
<p>n t
</p>
<p>+
</p>
<p>;syst
</p>
<p>ut
</p>
<p>ot
</p>
<p>at
</p>
<p>Figure 1 : Mod&#232;le de dialogue vocal homme-machine </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;seau Bay&#233;sien pour un mod&#232;le d&#8217;utilisateur et un module de compr&#233;hension pour l&#8217;optimisation des 
syst&#232;mes de dialogues 
</p>
<p>Figure 2 : R&#233;seau bay&#233;sien dynamique 
</p>
<p>pas, ni de l&#8217;&#233;tat s qu&#8217;il a du int&#233;grer dans sa connaissance de l&#8217;historique de l&#8217;interaction. Enfin, une 
modification du but de l&#8217;utilisateur doit passer par une modification de sa connaissance uniquement. 
Les trois termes de (1) mettent en &#233;vidence les relations &#233;troites qui existent entre le processus de 
production de parole et le couple {but, connaissance}. N&#233;anmoins, la modification de la connaissance 
est un processus incr&#233;mental (mise &#224; jour) et se base donc aussi sur la connaissance pr&#233;alable de 
l&#8217;utilisateur :  
</p>
<p>( ) ( ) ( )
( ) ( ) |,,|
</p>
<p> ,,|,,,|,,|
</p>
<p>&#8721;
&#8721;
</p>
<p>&#8722;
</p>
<p>&#8722;
</p>
<p>&#8722;&#8722;
</p>
<p>&#8722;&#8722;
</p>
<p>&#8901;=
&#8901;=
</p>
<p>k
</p>
<p>k
</p>
<p>skPnsyskkP
</p>
<p>nssyskPnssyskkPnssyskP
 (2) 
</p>
<p>Ici, k- repr&#233;sente la variable kt-1. La simplification du second facteur de la somme provient du fait 
&#233;vident que la connaissance de l&#8217;utilisateur au temps t-1 ne peut pas d&#233;pendre des signaux de parole ou 
de bruit au temps t.  
</p>
<p>3 Le mod&#232;le d&#8217;utilisateur 
</p>
<p>3.1 Un r&#233;seau bay&#233;sien dynamique 
Les &#233;quations (1) et (2) permettent de dire 
qu&#8217;un r&#233;seau bay&#233;sien dynamique (DBN : 
Dynamic Bayesian Network) pourrait 
encoder la factorisation particuli&#232;re des 
probabilit&#233;s associ&#233;es &#224; l&#8217;utilisateur 
(Pearl, 1988). Les n&#339;uds du r&#233;seau sont 
donn&#233;s par les variables pr&#233;sentes dans les 
&#233;quations (sys, n, k, g, u) et les arcs sont 
donn&#233;s par les probabilit&#233;s 
conditionnelles. La consistance de tour en 
tour est assur&#233;e par la d&#233;pendance dans le 
temps de la variable k. Le r&#233;seau 
dynamique obtenu est montr&#233; sur la 
Figure 2. Les variables sys et n sont des 
variables ext&#233;rieures &#224; l&#8217;utilisateur 
</p>
<p>(cercles vides), les variables k et g sont des variables internes (cercles gris-clair) et la variable u est une 
variable de sortie (cercles gris-fonc&#233;). 
</p>
<p> 
3.2 Utilisation du Mod&#232;le 
Le DBN de la Figure 2 para&#238;t relativement simple, n&#233;anmoins la d&#233;finition des variables qu&#8217;il fait 
intervenir est plus ou moins floue. Ici, nous avons choisi une repr&#233;sentation des variables en paires 
&#171; attribut-valeur &#187; (paires AV) d&#233;riv&#233;es de la description en &#171; Matrice attribut-valeur &#187; de la t&#226;che. 
Dans ce cadre, chaque acte de communication est consid&#233;r&#233; comme un ensemble de paires AV. Dans 
ce qui suit, Le signal de parole sys &#233;mis par le syst&#232;me est alors mod&#233;lis&#233; par un ensemble de pairs AV 
dont l&#8217;ensemble des attributs, not&#233; S={s&#963;}, contient des &#233;l&#233;ments qui peuvent prendre des valeurs 
bool&#233;ennes indiquant si oui ou non l&#8217;attribut associ&#233; est pr&#233;sent dans sys. Un attribut sp&#233;cial non 
bool&#233;en AS sera inclus &#224; S et sa valeur d&#233;finira le type d&#8217;acte de communication associ&#233; &#224; sys. Les 
types accept&#233;s peuvent &#234;tre &#8216;invite&#8217;, &#8216;question&#8217;, &#8216;demande de relaxation&#8217;, &#8216;proposition&#8217;, &#8216;demande de 
confirmation&#8217;, &#8216;fermeture du dialogue&#8217;, &#8230; Une question directe sera alors caract&#233;ris&#233;e par un attribut 
AS &#233;gal &#224; &#8216;question&#8217; et un seul attribut s&#963;  dont la valeur sera vraie. La r&#233;ponse u de l&#8217;utilisateur sera 
mod&#233;lis&#233;e par une autre paire AV dans laquelle les attributs appartiennent &#224; U = {u&#965;} et l&#8217;ensemble 
des valeurs possibles pour chaque attribut u&#965; sera note V = { &#965;iv }. Un attribut sp&#233;cial CU est ajout&#233; &#224; U 
et sa valeur bool&#233;enne indique si l&#8217;utilisateur a d&#233;cid&#233; de clore le dialogue dans sa r&#233;ponse. Le but et la 
</p>
<p>u
</p>
<p>k
</p>
<p>sys
</p>
<p>g
</p>
<p>t t-1
</p>
<p>n
</p>
<p>u
</p>
<p>k
</p>
<p>sys
</p>
<p>g
</p>
<p>n</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier Pietquin 
</p>
<p>connaissance de l&#8217;utilisateur seront repr&#233;sent&#233;es respectivement 
par les paires G = {[g&#947;, &#947;igv ]} et K = {[k&#954;, &#954;ikv ]} ou g&#947; et k&#954; sont 
des attributs et &#947;igv  et &#954;ikv sont les valeurs possibles. En fonction 
de ces nouvelles notations, le r&#233;seau de la Figure 2 devient celui 
de la Figure 3 ou la d&#233;pendance dans le temps a &#233;t&#233; 
volontairement omise pour plus de clart&#233; ainsi que le bruit dont 
la mod&#233;lisation est trop complexe. Chaque valeur ou &#233;tat 
possible pour chaque variable de ce r&#233;seau est une combinaison 
des attributs et des valeurs, ce qui signifie que les &#233;tats sont 
discrets et en nombre fini. On peut donc d&#233;finir une version 
factoris&#233;e de ce r&#233;seau dans laquelle figureraient les variables 
AS, s&#963;, &#963;iv , u&#965;, &#965;iv , g&#947;, &#947;igv , k&#954;, &#954;ikv et UC. 
</p>
<p>Consid&#233;rons une t&#226;che simple consistant &#224; remplir un formulaire compos&#233; de deux entr&#233;es : S = {s1, 
s2}. Le syst&#232;me peut utiliser 4 types d&#8217;actes de communication : &#8216;invite&#8217;, &#8216;question directe&#8217;, &#8216;demande 
de confirmation&#8217; et &#8216;fermeture&#8217;. Pour simplifier, consid&#233;rons que la connaissance de l&#8217;utilisateur se 
compose de simples compteurs, chacun associ&#233; &#224; un &#233;l&#233;ment de S, initialis&#233;s &#224; 0 et qui sont 
incr&#233;ment&#233;s &#224; chaque fois que le syst&#232;me pose une question ou demande une confirmation sur l&#8217;entr&#233;e 
associ&#233;e. Ceci est suffisant pour permettre au mod&#232;le d&#8217;utilisateur de rester consistant par rapport &#224; 
l&#8217;historique de l&#8217;interaction et de r&#233;agir &#224; un comportement insatisfaisant du syst&#232;me (en r&#233;agissant 
lorsqu&#8217;une entr&#233;e a &#233;t&#233; demand&#233;e plusieurs fois). Le but de l&#8217;utilisateur est alors de transmettre au 
syst&#232;me les valeurs correctes pour les attributs repr&#233;sent&#233;s par les entr&#233;es du formulaire (Figure 4).  
</p>
<p>Goal Know. 
Att. Val. Count 
g1 gv1 k1 
g2 gv2 k2 
</p>
<p>Figure 4 : But et connaissance de l&#8217;utilisateur 
</p>
<p>L&#8217;utilisateur peut donc inclure dans ses r&#233;ponses u les deux attributs u1 et u2 (il y a autant d&#8217;attributs 
dans U que dans S). Afin de simuler la r&#233;ponse de l&#8217;utilisateur &#224; l&#8217;invite, il suffit alors d&#8217;entrer 
l&#8217;&#233;vidence suivante dans le moteur d&#8217;inf&#233;rence :  
</p>
<p>AS k1 k2 g1 g2 gv1 gv2 
invite 0 0 1 1 gv1 gv2 
</p>
<p>Figure 5 : Evidence pour une r&#233;ponse &#224; l&#8217;invite 
</p>
<p>Les valeurs 1 associ&#233;es aux variables gi signifient que les attributs gi sont bien pr&#233;sents dans le but. 
Gr&#226;ce &#224; cette &#233;vidence, le moteur d&#8217;inf&#233;rence produira les probabilit&#233;s P(u1=1), P(u2=1), P(UC=1) et 
leurs compl&#233;ments. Tout d&#8217;abord, le mod&#232;le choisit de mani&#232;re al&#233;atoire un nombre r&#233;el entre 0 et 1, si 
ce nombre est inf&#233;rieur &#224; P(UC=1), le dialogue est clos. Dans le cas contraire, le m&#234;me processus est 
r&#233;p&#233;t&#233; pour choisir les attributs pr&#233;sents dans la r&#233;ponse de l&#8217;utilisateur. En supposant que u1 est 
s&#233;lectionn&#233;e pour &#234;tre pr&#233;sente dans la r&#233;ponse de l&#8217;utilisateur, l&#8217;&#233;vidence suivante est alors entr&#233;e 
dans le moteur d&#8217;inf&#233;rence :  
</p>
<p>u1 u2 gv1 gv2 
1 0 gv1 gv2 
</p>
<p>Figure 6 : Inf&#233;rence pour une valeur de r&#233;ponse 
</p>
<p>4 Simulation de la compr&#233;hension de parole 
La simulation de NLU peut se faire en utilisant le r&#233;seau bay&#233;sien d&#233;crit plus haut comme 
classificateur. Pour ce faire, nous consid&#232;rerons que les erreurs de reconnaissances vocales n&#8217;affectent 
que les valeurs des paires AV alors que les erreurs d&#8217;associations attribut-valeur sont dues au module 
</p>
<p>U
</p>
<p>K
</p>
<p>S
</p>
<p>UC
</p>
<p>As
</p>
<p>V
</p>
<p>G
</p>
<p>Figure 3 : R&#233;seau bay&#233;sien bas&#233; 
sur les paires AV </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;seau Bay&#233;sien pour un mod&#232;le d&#8217;utilisateur et un module de compr&#233;hension pour l&#8217;optimisation des 
syst&#232;mes de dialogues 
</p>
<p>de compr&#233;hension. En consid&#233;rant que le processus de reconnaissance vocale a transform&#233; les valeurs 
V = { &#965;iv } g&#233;n&#233;r&#233;es dans sa r&#233;ponse u par le mod&#232;le d&#8217;utilisateur en un ensemble de valeur W = {wj} et 
en reprenant l&#8217;exemple simple du remplissage de formulaire expliqu&#233; dans la section pr&#233;c&#233;dente, les 
&#233;vidences suivantes peuvent &#234;tre introduites dans le moteur d&#8217;inf&#233;rence pour simuler la compr&#233;hension 
de la r&#233;ponse &#224; l&#8217;invite :  
</p>
<p>AS s1 s2 with v11 or V12 
invite 0 0  wj  wj 
</p>
<p>Figure 7 : Evidence pour la compr&#233;hension de la r&#233;ponse &#224; l&#8217;invite 
</p>
<p>A moins que wj ne soit pas une valeur acceptable pour un des attributs test&#233;s, ces deux diff&#233;rentes 
&#233;vidences vont fournir des valeurs pour les probabilit&#233;s P(u1 | AS = greet, v11 = wj) and P(u2|AS = greet, 
v12 = wj). Le syst&#232;me de simulation de compr&#233;hension va alors affecter la valeur wj &#224; l&#8217;attribut ui ayant 
produit la probabilit&#233; la plus haute. Des situations plus complexes peuvent &#233;videmment &#234;tre 
rencontr&#233;es mais il est toujours possible de les transformer en &#233;vidence utilisable par le moteur 
d&#8217;inf&#233;rence. Cette m&#233;thode peut aussi produire une sorte de niveau de confiance de compr&#233;hension. 
Dans le cas de la classification d&#8217;une seule valeur, le niveau de confiance de compr&#233;hension est 
simplement la probabilit&#233; fournie par le moteur d&#8217;inf&#233;rence. Lorsque plusieurs valeurs ont du &#234;tre 
associ&#233;e &#224; des attributs par le module de compr&#233;hension, une mesure de confiance peut &#234;tre affect&#233;e &#224; 
chaque paire ou une mesure globale peut &#234;tre donn&#233;e en multipliant toutes les valeurs.  
</p>
<p>5 Apprentissage de strat&#233;gies optimales par simulation 
Le mod&#232;le d&#233;crit ci-dessus a &#233;t&#233; d&#233;velopp&#233; dans le but de l&#8217;apprentissage automatique de strat&#233;gies de 
dialogue homme-machine optimales. Nous avons donc mis notre environnement en pr&#233;sence d&#8217;un 
agent d&#8217;apprentissage par renforcement comme propos&#233; dans (Levin, Pieraccini, 1997). Pour se faire, 
il faut d&#233;finir un crit&#232;re d&#8217;optimisation. On peut en trouver plusieurs dans la litt&#233;rature n&#233;anmoins, 
l&#8217;hypoth&#232;se selon laquelle la contribution de chaque acte &#224; la satisfaction de l&#8217;utilisateur est une bonne 
mesure de l&#8217;&#233;valuation d&#8217;une strat&#233;gie est retenue ici. Selon (Singh et al, 1999) une fonction de co&#251;t 
bas&#233;e sur une mesure de la compl&#233;tion de la t&#226;che, les performances de reconnaissance et de 
compr&#233;hension et la dur&#233;e en tours du dialogue serait satisfaisante. Dans notre exp&#233;rience, les 
utilisateurs sont invit&#233;s &#224; fournir des informations &#224; propos d&#8217;un voyage en train. Les attributs sont 
donc une ville de d&#233;part, une ville de destination, une heure de d&#233;part, une heure d&#8217;arriv&#233;e d&#233;sir&#233;e et la 
classe. Il y a 50 valeurs possibles pour les villes (les m&#234;mes pour le d&#233;part et l&#8217;arriv&#233;e) et les heures 
possibles sont les heures plaines (de 0 &#224; 24). Les types d&#8217;actes de communications possibles sont 
&#8216;invite&#8217;, &#8216;question directe&#8217;, &#8216;question ouverte&#8217;, &#8216;confirmation explicite&#8217; et &#8216;fermeture du dialogue&#8217;. 
Nous r&#233;alisons plusieurs exp&#233;riences diff&#233;rentes dans lesquelles l&#8217;agent d&#8217;apprentissage &#233;volue dans 
un espace d&#8217;&#233;tat construit sur base de l&#8217;historique de l&#8217;interaction et d&#8217;une valeur binaire indiquant si 
le niveau de confiance de la derni&#232;re interaction est haut ou bas. Les exp&#233;riences varient entre autre 
par la d&#233;finition du niveau de confiance qui peut &#234;tre uniquement CLASR (espace d&#8217;&#233;tats S1 dans la 
suite) et CLASR*CLNLU (espace d&#8217;&#233;tats S2 dans la suite). De m&#234;me la fonction de co&#251;t int&#232;gre l&#8217;une ou 
l&#8217;autre mesure de confiance. Au d&#233;but de chaque dialogue, un but d&#8217;utilisateur est construit assignant 
des valeurs aux 5 attributs. La mesure de compl&#233;tion de la t&#226;che est alors d&#233;finie comme le rapport 
entre le nombre d&#8217;attributs dont la valeur a &#233;t&#233; correctement assign&#233;e au nombre d&#8217;attributs en tout (5 
ici). On d&#233;finit aussi deux environnements de simulation. Le premier (Sim1) int&#232;gre le mod&#232;le 
d&#8217;utilisateur et un module de simulation de reconnaissance vocale introduisant des erreurs et une 
mesure de confiance de reconnaissance. Le second environnement (Sim2) int&#232;gre, en plus, le module 
de compr&#233;hension. Nous avons r&#233;alis&#233; trois exp&#233;riences diff&#233;rentes en combinant diff&#233;remment les 
espaces d&#8217;&#233;tats et les environnements de simulation. Les r&#233;sultats de l&#8217;apprentissage sont montr&#233;s dans 
les tableaux de la Figure 8. Dans le tableau de gauche sont indiqu&#233;s les r&#233;sultats des mesures 
objectives pouvant &#234;tre obtenues lors d&#8217;un dialogue moyen suivant la strat&#233;gie apprise (mesures 
obtenues en calculant la moyenne des mesures faites sur 10 000 dialogues simul&#233;s). Dans le tableau de 
droite sont indiqu&#233;es les fr&#233;quences moyennes d&#8217;occurrences de chaque type d&#8217;acte de 
communication. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier Pietquin 
</p>
<p> N TC  invite constQ openQ expC Close 
Sim1, S1 5.39 0.81 Sim1, S1 1.0 0.85 1.23 1.31 1.0 
Sim2, S1 7.03 0.74 Sim2, S1 1.0 1.25 1.18 2.60 1.0 
Sim2, S2 5.82 0.79 
</p>
<p> 
</p>
<p>Sim2, S2 1.0 1.05 1.18 1.58 1.0 
</p>
<p>Figure 8 : R&#233;sultats de l&#8217;exp&#233;rience 
</p>
<p>Gr&#226;ce aux tableaux de la Figure 8, nous pouvons conclure que lors de la premi&#232;re exp&#233;rience (sans 
erreur de compr&#233;hension), il y a plus de question ouvertes que de questions directes. Les erreurs de 
reconnaissances &#233;tant prises en compte par l&#8217;introduction de CLASR dans S1 et Sim1, il y a souvent des 
demandes de confirmations. Dans la deuxi&#232;me exp&#233;rience, des erreurs de compr&#233;hensions sont 
introduites mais elles ne peuvent pas &#234;tre d&#233;tect&#233;es par les mesures de confiance. On observe une 
augmentation du nombre de confirmations puisque le syst&#232;me ne peut jamais &#234;tre certain que les 
valeurs sont bien assign&#233;es. La longueur moyenne du dialogue s&#8217;en trouve augment&#233;e et la compl&#233;tion 
de la t&#226;che diminue. En ajoutant CLNLU dans S2, les performances s&#8217;am&#233;liorent et on retrouve presque 
les r&#233;sultats de la premi&#232;re exp&#233;rience. Ceci est du au fait que certaines questions ouvertes sont &#233;vit&#233;es 
parce qu&#8217;elles r&#233;sultent en une tr&#232;s mauvaises mesure de confiance. En effet la strat&#233;gie est modifi&#233;e et 
les questions ouvertes concernant les deux villes en m&#234;me temps sont tr&#232;s peu probables car elles 
induisent des confusions et des niveaux de confiance plus faibles.  
</p>
<p>6 Conclusions et perspectives 
Dans cet article, un environnement de simulation de dialogues dans lequel ont &#233;t&#233; introduit un mod&#232;le 
d&#8217;utilisateur consistant et un module de simulation de compr&#233;hension de parole a &#233;t&#233; d&#233;crit. Cet 
environnement a &#233;t&#233; d&#233;velopp&#233; dans le but d&#8217;un &#8217;apprentissage de strat&#233;gies de dialogues optimales et 
il a pu &#234;tre d&#233;montr&#233; par exp&#233;rience que cet environnement permettait de mettre en &#233;vidence des 
probl&#232;mes &#233;ventuels de compr&#233;hension et d&#8217;adapter la strat&#233;gie automatiquement en cons&#233;quence. 
Quelques particularit&#233;s de l&#8217;environnement n&#8217;ont pas &#233;t&#233; exploit&#233;es dans ce travail et il serait 
probablement int&#233;ressant de s&#8217;y atteler dans le futur. Par exemple, la relation avec le fonctionnement 
parall&#232;le de l&#8217;utilisateur et le gestionnaire de dialogue et le ph&#233;nom&#232;ne de grounding intervenant dans 
les dialogues homme-homme a &#233;t&#233; bri&#232;vement mentionn&#233; dans la section 2 mais n&#8217;a pas vraiment &#233;t&#233; 
exploit&#233;e. Le besoin d&#8217;introduire des sous-dialogues permettant la mise en phase des connaissances 
suppos&#233;es de l&#8217;utilisateur et de l&#8217;&#233;tat r&#233;el du gestionnaire pourrait &#234;tre d&#233;tect&#233; par la l&#8217;inconsistance 
entre l&#8217;&#233;tat du syst&#232;me et des valeurs inf&#233;r&#233;es de la connaissance de l&#8217;utilisateur.  
</p>
<p>R&#233;f&#233;rences 
ECKERT W., LEVIN E., PIERACCINI R. (1998) Automatic Evaluation of Spoken Dialogue Systems, 
Technical Report TR98.9.1, AT&amp;T Labs Research. 
</p>
<p>LEVIN E., PIERACCINI R. (1997), A Stochastic Model of Computer-Human Interaction for Learning 
Dialogue Strategies, Proc. Eurospeech&#8217;97, Rhodes, Greece, pp. 1883-1886. 
</p>
<p>PEARL J. (1988) Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, 
Morgan Kaufmann Publishers, Inc. San Francisco, California. 
</p>
<p>PIETQUIN O., DUTOIT T. (2002) Mod&#233;lisation d'un Syst&#232;me de Reconnaissance dans le Cadre de 
l'Evaluation et l'Optimisation Automatique des Syst&#232;mes de Dialogue, Actes des Journ&#233;es d'Etude de 
la Parole, JEP 2002, Nancy (France). 
</p>
<p>POWER R. (1979) The Organization of Purposeful Dialogues, Linguistics 17, pp. 107-152. 
</p>
<p>SINGH S., KEARNS M., LITMAN D., WALKER M., (1999) Reinforcement Learning for Spoken Dialogue 
Systems, Proc. NIPS&#8217;99, Denver, USA. </p>

</div></div>
</body></html>