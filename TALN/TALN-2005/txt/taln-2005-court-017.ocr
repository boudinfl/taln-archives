TALN 2005, Dourdan, 6-I0juin 2005

Réseau bayésien pour un modele d’utilisateur et un module de
compréhension pour l’optimisation des systemes de dialogues

Olivier Pietquin

Supélec, Campus de Metz — Equipe STS
2 rue Edouard Belin — F-57070 Metz
olivier.pietquin @ supelec.fr

Mots-clés Z Systémes de dialogue, simulation de dialogues, modéle d’utilisateur,
optimisation.

Keywords: Spoken dialog systems, dialog simulation, user modeling, optimization

Résumé Dans cet article, un environnement modulaire pour la simulation automatique de
dialogues homme—machine est proposé. Cet environnement comprend notarmnent un modéle
d’utilisateur consistant dirigé par le but et un module de simulation de compréhension de parole. Un
réseau bayésien est a la base de ces deux modéles et selon les paramétres utilisés, il peut générer un
comportement d’utilisateur cohérent ou servir de classiﬁcateur de concepts. L’environnement a été
utilisé dans le contexte de l’optin1isation de stratégies de dialogue sur une tache simple de remplissage
de formulaire et les résultats montrent qu’il est alors possible d’identiﬁer certains dialogues
problématiques du point de vue de la compréhension.

Abstract In this paper we present a modular enviromnent for simulating human—machine
dialogues by computer means. This enviromnent includes a consistent goal—directed user model and a
natural language understanding system model. Both models rely on a special Bayesian network used
with different parameters in such a way that it can generate a consistent user behaviour according to a
goal and the history of the interaction, and been used as a concept classifier. This enviromnent was
tested in the framework of optimal strategy learning for the simple form—ﬁl1ing task. The results show
that the enviromnent allows pointing out problematic dialogues that may occur because of
misunderstanding between the user and the system.

1 Introduction

Dans cet article, nous traitons essentiellement de simulation de dialogues homme—machine.
Initialement, les systémes de simulation étaient destinés essentiellement a la validation de modéles du
discours (Power, 1979). Avec l'apparition des interfaces vocales sont aussi arrivés les problémes de
conception. La conception de ces interfaces est un processus cyclique dans lequel interviennent
successivement des phases de développement, de tests, d’évaluations et d’améliorations. La phase la
plus sujette aux contraintes de temps et d’argent et bien souvent celle de l’évaluation et de test. Pour
cette raison, la simulation en vue de l’évaluation automatique des interfaces s’est répandue depuis la
ﬁn des armées 1990 (Eckert et al., 1998). De cette combinaison de la simulation et de l’automatisation
de l’évaluation a assez Vite découlé une nouvelle application : l’apprentissage automatique de
stratégies optimales (Levin, Pieraccini, 1997) (Singh et al., 1999). Dans cet article, un environnement
de simulation de dialogues est proposé dans le cadre de cette derniére application.

Olivier Pietquin

De tels environnements existent donc déja. Certains utilisent des modeles statistiques de transitions
entre états obtenus d’apres observation de dialogues réels, (Singh et al., 1999). D’autres utilisent un
modele d’utilisateur sans mémoire (Levin, Pieraccini, 1997) et n’incluent pas de modélisation de
l’erreur. Ici, nous décrivons un environnement de simulation comprenant un modele d’utilisateur
consistant étant donné l’historique de l’interaction (avec mémoire) et un but. Cet environnement
comprend aussi un modele de systeme de reconnaissance vocale ainsi qu’un module simulant la
compréhension du langage naturel. En incluant ces modules dans l’environnement, nous espérons que
les stratégies apprises tiendront comptes de leurs lacunes.

2 Un modéle formel pour le dialogue vocal homme-machine

De maniere formelle et comme le décrit la Figure 1, un dialogue vocal homme-machine peut étre
considéré comme un processus séquentiel dans lequel un utilisateur humain et un systeme de gestion
de dialogue (DM: Dialogue Manager) communiquent grace a la parole au travers d’un canal de
transmission. Ce canal est composé de différents modules qui manipulent chacun l’info1mation pour
lui faire prendre une forme utilisable par le ou les modules suivants. Le but d’un systeme de dialogue
étant souvent de fournir de l’infor1nation a l’utilisateur, le systeme de gestion de dialogues peut donc
accéder a une base de connaissance.

Tranemem des Le processus étant séquentiel, il peut étre
5°'“°“’°°a'°3 discrétisé en tours t. A chaque tour, le
wt ‘ gestionnaire de dialogue génere un
ensemble d’actes de communication a,
sur base de son e’tat inteme st pouvant se
matérialiser en une invite, une question,
une aide, une demande de conﬁrmation,
Génération ..: la fermeture du dialogue etc. Afin d’étre
des Sorties compris par l’utilisateur, cet ensemble est

vocales , .
(NLG ., 1-Ts, transforme en un signal de parole sys, par

     

 _ ASR
L L

‘A A
u, '
Utlllsateur
39,‘: W
.-....k
4' -4

i

CLASR ""-

(

I
I
.
I
I
.

Base
de connaussances

   

  
   

les systemes de génération de sorties
Figure 1 : Modele de dialogue vocal homme-machine vocales. En fonction de ce qu’il a pu
comprendre de ce signal, de sa
connaissance au moment t (k,) et du but qu’il poursuit en communiquant avec le systeme (gt),
l’utilisateur produit a son tour un signal de parole ut. Dans le cas particulier des systemes de dialogue,
le terme ‘connaissance’ peut faire reference a la connaissance de l’utilisateur concernant l’historique
de l’interaction, la tache, le systeme lui—méme ou le monde en général. Les deux signaux vocaux u, et
sys, sont entachés par le bruit ambiant n, au moment de leur production. Le systeme de reconnaissance
vocale (ASR) traite alors le signal u, et le transforme en un ensemble de mots wt. Au passage, le
module ASR produit une mesure CLASR indiquant le degré de conﬁance qu’il accorde a son résultat.
L’ ensemble w, est ensuite passé au systeme de compréhension de parole (NLU) qui doit en retirer une
representation sémantique que nous supposerons mise sous la forme d’un ensemble de concepts ct. Le
module NLU produit lui—aussi une mesure de conﬁance CLNLU associée a l’ensemble c,. L’ensemble
{c,, CLASR, CLNLU} compose une observation 0, qui est utilisée pour réaliser une mise a jour de son état
interne. D’un point de vue probabiliste, le comportement de l’utilisateur peut étre résumé par la
probabilité conjointe suivante :

P(u,g,k

sys,a,s,n)= l”(k I sys,a,s, l”(g I k,sys,a,s,n)-  I g,k,sys,a,s,n)
MAJ de cdrnnaissance Modiﬁcaltiron du but Sortie ul:l]isateur ( 1 )
= P(k I sys,s,n)- P(g Ik) - P(u I g,k,sys,n)

MAJ de connaissance Modiﬁcation du but Sortie utilisateur

Les simpliﬁcations dans (1) tiennent compte de plusieurs faits, notamment on peut raisonnablement
admettre que la connaissance de l’utilisateur n’est pas modiﬁée par l’acte a puisque l’utilisateur n’a
pas acces directement a cette valeur. De méme, sa réponse ne dépend ni de l’acte a qu’il ne connait

Réseau Bayésien pour un modéle d’utilisateur et un module de compréhension pour l’optimisation des
systémes de dialogues

pas, ni de l’état s qu’il a du intégrer dans sa connaissance de l’historique de l’interaction. Enﬁn, une
modification du but de l’utilisateur doit passer par une modiﬁcation de sa connaissance uniquement.
Les trois termes de (1) mettent en évidence les relations étroites qui existent entre le processus de
production de parole et le couple {but, connaissance}. Néanmoins, la modification de la connaissance
est un processus incrémental (mise a jour) et se base donc aussi sur la connaissance préalable de
l’utilisateur :

P(k I sys, s, n) = Zk_ P(k I k", sys, s,  P(k' I sys, s, n)
= Zk_ P(k I k',sys,n)- P(k' I s)

Ici, k" représente la variable k,_1. La simpliﬁcation du second facteur de la somme provient du fait
évident que la connaissance de l’utilisateur au temps t—l ne peut pas dépendre des signaux de parole ou
de bruit au temps t.

(2)

3 Le modéle d’utilisateur

3.1 Un réseau bayésien dynamique

Les equations (1) et (2) permettent de dire
qu’un réseau bayésien dynamique (DBN :
Dynamic Bayesian Network) pourrait
encoder la factorisation particuliere des
probabilités associées a l’utilisateur
(Pearl, 1988). Les noeuds du réseau sont
donnés par les variables présentes dans les
équations (sys, n, k, g, u) et les arcs sont
donnés par les probabilités
conditionnelles. La consistance de tour en
tour est assurée par la dépendance dans le
temps de la variable k. Le réseau
* dynamique obtenu est montré sur la
Figure 2 : Réseau bayésien dynamique Figure 2. Les variables sys et 11 sont des
variables extérieures a l’utilisateur
(cercles vides), les variables k et g sont des variables intemes (cercles gris—clair) et la variable u est une
variable de sortie (cercles gris—foncé).

I I-1

    

3.2 Utilisation du Modéle

Le DBN de la Figure 2 parait relativement simple, néanmoins la déﬁnition des variables qu’il fait
intervenir est plus ou moins ﬂoue. Ici, nous avons choisi une représentation des variables en paires
« attribut-valeur » (paires AV) dérivées de la description en « Matrice attribut-valeur » de la tache.
Dans ce cadre, chaque acte de communication est considéré comme un ensemble de paires AV. Dans
ce qui suit, Le signal de parole sys émis par le systeme est alors modélisé par un ensemble de pairs AV
dont l’ensemble des attributs, noté S ={s"}, contient des éléments qui peuvent prendre des valeurs
booléennes indiquant si oui ou non l’attribut associé est présent dans sys. Un attribut spécial non
booléen As sera inclus a S et sa valeur déﬁnira le type d’acte de communication associé a sys. Les
types acceptés peuvent étre ‘invite’, ‘question’, ‘demande de relaxation’, ‘proposition’, ‘demande de
conﬁrmation’, ‘fermeture du dialogue’,  Une question directe sera alors caractérisée par un attribut
As égal a ‘question’ et un seul attribut s“ dont la valeur sera vraie. La réponse u de l’utilisateur sera
modélisée par une autre paire AV dans laquelle les attributs appartiennent a U = {u"} et l’ensemble
des valeurs possibles pour chaque attribut u” sera note V = {v}’ }. Un attribut spécial Cy est ajouté a U

et sa valeur booléenne indique si l’utilisateur a décidé de clore le dialogue dans sa réponse. Le but et la

Olivier Pietquin

connaissance de l’utilisateur seront représentées respectivement
par les paires G = {[g", gv,-7]} et K = {[k", kv,-"]} ou g7 et k" sont
des attributs et gv,-7 et kv,-" sont les valeurs possibles. En fonction

de ces nouvelles notations, le réseau de la Figure 2 devient celui
de la Figure 3 ou la dépendance dans le temps a été
volontairement omise pour plus de clarté ainsi que le bruit dont
la modélisation est trop complexe. Chaque valeur ou état
possible pour chaque variable de ce réseau est une combinaison
des attributs et des valeurs, ce qui signiﬁe que les états sont
discrets et en nombre fini. On peut donc déﬁnir une version
factorisée de ce réseau dans laquelle ﬁgureraient les variables

As, s0,v-0 , u",v,l’ , gr, gv,-7, kk,  et U5.

1

 

Figure 3 : Réseau bayésien basé
sur les paires AV

Considérons une tache simple consistant a remplir un formulaire composé de deux entrées : S = {s1,
s2}. Le systeme peut utiliser 4 types d’actes de communication : ‘invite’, ‘question directe’, ‘demande
de conﬁrmation’ et ‘fermeture’. Pour simplifier, considérons que la connaissance de l’utilisateur se
compose de simples compteurs, chacun associé a un élément de S, initialisés a 0 et qui sont
incrémentés a chaque fois que le systeme pose une question ou demande une conﬁrmation sur l’entrée
associée. Ceci est suffisant pour permettre au modele d’utilisateur de rester consistant par rapport a
l’historique de l’interaction et de réagir a un comportement insatisfaisant du systeme (en réagissant
lorsqu’une entrée a été demandée plusieurs fois). Le but de l’utilisateur est alors de transmettre au
systeme les valeurs correctes pour les attributs représentés par les entrées du formulaire (Figure 4).

Goal Know.
Att. Val. Count
8; gV1 kg
8 gV2 k

Figure 4 : But et connaissance de l’utilisateur

L’utilisateur peut donc inclure dans ses réponses u les deux attributs 111 et u2 (il y a autant d’attributs
dans U que dans S). Aﬁn de simuler la réponse de l’utilisateur a l’invite, il sufﬁt alors d’entrer
l’évidence suivante dans le moteur d’inférence :

AS k1 k2 g1 g2 gvl gvz

invite 0 0 1 1 gvl gvg

Figure 5 : Evidence pour une réponse a l’invite

Les valeurs l associées aux variables gi signiﬁent que les attributs gi sont bien présents dans le but.
Grace a cette évidence, le moteur d’inférence produira les probabilités P(u1=l), P(u2=l), P(Uc=l) et
leurs compléments. Tout d’abord, le modele choisit de maniere aléatoire un nombre réel entre 0 et I, si
ce nombre est inférieur a P(Uc=l), le dialogue est clos. Dans le cas contraire, le méme processus est
répété pour choisir les attributs présents dans la réponse de l’utilisateur. En supposant que 111 est
sélectionnée pour étre présente dans la réponse de l’utilisateur, l’évidence suivante est alors entrée
dans le moteur d’inférence :

1 0 gvi gvz

Figure 6 : Inférence pour une valeur de réponse

4 Simulation de la compréhension de parole

La simulation de NLU peut se faire en utilisant le réseau bayésien décrit plus haut comme
classificateur. Pour ce faire, nous considererons que les erreurs de reconnaissances vocales n’affectent
que les valeurs des paires AV alors que les erreurs d’associations attribut—valeur sont dues au module

Réseau Bayésien pour un modéle d’utilisateur et un module de compréhension pour l’optimisation des
systémes de dialogues

de comprehension. En considerant que le processus de reconnaissance vocale a transforme les valeurs
V = { vﬁ’ } generees dans sa reponse u par le modele d’utilisateur en un ensemble de valeur W = {Wj} et
en reprenant l’exemple simple du remplissage de formulaire explique dans la section precedente, les

evidences suivantes peuvent étre introduites dans le moteur d’inference pour simuler la comprehension
de la reponse a l’invite :

 

Figure 7 : Evidence pour la comprehension de la reponse a l’invite

A moins que wj ne soit pas une valeur acceptable pour un des attributs testes, ces deux differentes
evidences vont fournir des valeurs pour les probabilites P(u‘ I AS = greet, V11 = wj) and P(u2lAS = greet,
V12 = wj). Le systeme de simulation de comprehension va alors affecter la valeur wj a l’attribut ui ayant
produit la probabilite la plus haute. Des situations plus complexes peuvent evidemment étre
rencontrees mais il est toujours possible de les transformer en evidence utilisable par le moteur
d’ inference. Cette methode peut aussi produire une sorte de niveau de conﬁance de comprehension.
Dans le cas de la classiﬁcation d’une seule valeur, le niveau de conﬁance de comprehension est
simplement la probabilite foumie par le moteur d’inference. Lorsque plusieurs valeurs ont du étre
associee a des attributs par le module de comprehension, une mesure de confiance peut étre affectee a
chaque paire ou une mesure globale peut étre donnee en multipliant toutes les valeurs.

5 Apprentissage de stratégies optimales par simulation

Le modele decrit ci—dessus a ete developpe dans le but de l’apprentissage automatique de strategies de
dialogue homme—machine optimales. Nous avons donc mis notre environnement en presence d’un
agent d’apprentissage par renforcement comme propose dans (Levin, Pieraccini, 1997). Pour se faire,
il faut deﬁnir un critere d’optin1isation. On peut en trouver plusieurs dans la litterature neanmoins,
l’hypothese selon laquelle la contribution de chaque acte a la satisfaction de l’utilisateur est une bonne
mesure de l’evaluation d’une strategie est retenue ici. Selon (Singh et al, 1999) une fonction de coﬁt
basee sur une mesure de la completion de la tache, les performances de reconnaissance et de
comprehension et la duree en tours du dialogue serait satisfaisante. Dans notre experience, les
utilisateurs sont invites a fournir des informations a propos d’un voyage en train. Les attributs sont
donc une ville de depart, une ville de destination, une heure de depart, une heure d’ arrivee desiree et la
classe. Il y a 50 valeurs possibles pour les villes (les memes pour le depart et l’arrivee) et les heures
possibles sont les heures plaines (de 0 a 24). Les types d’actes de communications possibles sont
‘invite’, ‘question directe’, ‘question ouverte’, ‘conﬁrmation explicite’ et ‘fermeture du dialogue’.
Nous realisons plusieurs experiences differentes dans lesquelles l’agent d’apprentissage evolue dans
un espace d’etat construit sur base de l’historique de l’interaction et d’une valeur binaire indiquant si
le niveau de conﬁance de la derniere interaction est haut ou bas. Les experiences varient entre autre
par la definition du niveau de conﬁance qui peut étre uniquement CLASR (espace d’etats S1 dans la
suite) et CLAsR*CLNLU (espace d’etats S2 dans la suite). De meme la fonction de coﬁt integre l’une ou
l’autre mesure de conﬁance. Au debut de chaque dialogue, un but d’utilisateur est construit assignant
des valeurs aux 5 attributs. La mesure de completion de la tache est alors deﬁnie comme le rapport
e11tre le nombre d’attributs dont la valeur a ete correctement assignee au nombre d’attributs en tout (5
ici). On deﬁnit aussi deux environnements de simulation. Le premier (Siml) integre le modele
d’utilisateur et un module de simulation de reconnaissance vocale introduisant des erreurs et une
mesure de conﬁance de reconnaissance. Le second environnement (Simz) integre, en plus, le module
de comprehension. Nous avons realise trois experiences differentes en combinant differemment les
espaces d’ etats et les environnements de simulation. Les resultats de l’apprentissage sont montres dans
les tableaux de la Figure 8. Dans le tableau de gauche sont indiques les resultats des mesures
objectives pouvant étre obtenues lors d’un dialogue moyen suivant la strategie apprise (mesures
obtenues en calculant la moyenne des mesures faites sur 10 000 dialogues simules). Dans le tableau de
droite sont indiquees les frequences moyennes d’occurrences de chaque type d’acte de
communication.

Olivier Pietquin

Sim S 5.39 0.81 Sim S 1.0 0.85 1.23 1.31 1.0

Sim S 7.03 0.74 Sim S 1.0 1.25 1.18 2.60 1.0
Sim S 5.82 0.79 Sim S 1.0 1.05 1.18 1.58 1.0

 

Figure 8 : Résultats de l’eXpérience

Grace aux tableaux de la Figure 8, nous pouvons conclure que lors de la premiere expérience (sans
erreur de compréhension), il y a plus de question ouvertes que de questions directes. Les erreurs de
reconnaissances étant prises en compte par l’introduction de CLASR dans S1 etSim1, il y a souvent des
demandes de confirmations. Dans la deuxieme expérience, des erreurs de compréhensions sont
introduites mais elles ne peuvent pas étre détectées par les mesures de conﬁance. On observe une
augmentation du nombre de conﬁrmations puisque le systeme ne peut jamais étre certain que les
valeurs sont bien assignées. La longueur moyenne du dialogue s’en trouve augmentée et la complétion
de la tache dimiI1ue. En ajoutant CLNLU dans S2, les performances s’améliorent et on retrouve presque
les résultats de la premiere expérience. Ceci est du au fait que certaines questions ouvertes sont évitées
parce qu’elles résultent en une tres mauvaises mesure de conﬁance. En effet la stratégie est modiﬁée et
les questions ouvertes concemant les deux villes en méme temps sont tres peu probables car elles
induisent des confusions et des niveaux de conﬁance plus faibles.

6 Conclusions et perspectives

Dans cet article, un environnement de simulation de dialogues dans lequel ont été introduit un modele
d’utilisateur consistant et un module de simulation de compréhension de parole a été décrit. Cet
environnement a été développé dans le but d’un ’apprentissage de stratégies de dialogues optimales et
il a pu étre démontré par expérience que cet environnement permettait de mettre en évidence des
problemes éventuels de compréhension et d’adapter la stratégie automatiquement en conséquence.
Quelques particularités de l’environnement n’ont pas été exploitées dans ce travail et il serait
probablement intéressant de s’y atteler dans le futur. Par exemple, la relation avec le fonctionnement
parallele de l’utilisateur et le gestionnaire de dialogue et le phénomene de grounding intervenant dans
les dialogues homme—homme a été brievement mentionné dans la section 2 mais n’a pas vraiment été
exploitée. Le besoin d’introduire des sous—dialogues permettant la mise en phase des connaissances
supposées de l’utilisateur et de l’état réel du gestionnaire pourrait étre détecté par la l’inconsistance
entre l’état du systeme et des valeurs inférées de la connaissance de l’utilisateur.

Références

ECKERT W., LEVIN E., PIERACCINI R. (1998) Automatic Evaluation of Spoken Dialogue Systems,
Technical Report TR98.9.I, AT&T Labs Research.

LEVIN E., PIERACCINI R. (1997), A Stochastic Model of Computer—Human Interaction for Learning
Dialogue Strategies, Proc. Eurospeech’97, Rhodes, Greece, pp. 1883-1886.

PEARL J. (1988) Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference,
Morgan Kaufmarm Publishers, Inc. San Francisco, California.

PIETQUIN 0., DUTOII‘ T. (2002) Modélisation d’un Systeme de Reconnaissance dans le Cadre de
l'Evaluation et l'Optin1isation Automatique des Systemes de Dialogue, Actes des Journe’es d'Etude de
la Parole, JEP 2002, Nancy (France).

POWER R. (1979) The Organization of Purposeful Dialogues, Linguistics 1 7, pp. 107-152.

SINGH S., KEARNS M., LIFMAN D., WALKER M., (1999) Reinforcement Learning for Spoken Dialogue
Systems, Proc. NIPS’99, Denver, USA.

