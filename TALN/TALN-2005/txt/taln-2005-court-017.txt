TALN 2005, Dourdan, 6—10juin 2005

Reseau bayesien pour un modele d’utilisateur et un module de
compr ehension pour l’optimisation des systemes de dialogues

Olivier Pietquin

Supelec, Campus de Metz — Equipe STS
2 rue Edouard Belin — F-57070 Metz
olivier.pietquin @ supelec.fr

Mots—cles I Systemes de dialogue, simulation de dialogues, modele d’utilisateur,
optimisation.
K€yWO1‘ ds: Spoken dialog systems, dialog simulation, user modeling, optimization

Resume Dans cet article, un environnement modulaire pour la simulation automatique de
dialogues homme—machine est propose. Cet environnement comprend notamment un modele
d’utilisateur consistant dirige par le but et un module de simulation de comprehension de parole. Un
reseau bayesien est a la base de ces deux modeles et selon les parametres utilises, il peut generer un
comportement d’utilisateur coherent ou servir de classificateur de concepts. L’environnement a ete
utilise dans le contexte de l’optimisation de strategies de dialogue sur une tache simple de remplissage
de forrnulaire et les resultats montrent qu’il est alors possible d’identifier certains dialogues
problematiques du point de vue de la comprehension.

AbSt1' act In this paper we present a modular environment for simulating human—machine
dialogues by computer means. This environment includes a consistent goal—directed user model and a
natural language understanding system model. Both models rely on a special Bayesian network used
with different parameters in such a way that it can generate a consistent user behaviour according to a
goal and the history of the interaction, and been used as a concept classifier. This environment was
tested in the framework of optimal strategy learning for the simple forrn—f1lling task. The results show
that the environment allows pointing out problematic dialogues that may occur because of
misunderstanding between the user and the system.

1 Introduction

Dans cet article, nous traitons essentiellement de simulation de dialogues homme—machine.
Initialement, les systemes de simulation etaient destines essentiellement a la validation de modeles du
discours (Power, 1979). Avec l'apparition des interfaces vocales sont aussi arrives les problemes de
conception. La conception de ces interfaces est un processus cyclique dans lequel interviennent
successivement des phases de developpement, de tests, d’evaluations et d’ameliorations. La phase la
plus sujette aux contraintes de temps et d’argent et bien souvent celle de l’evaluation et de test. Pour
cette raison, la simulation en vue de l’evaluation automatique des interfaces s’est repandue depuis la
fin des annees 1990 (Eckert et al., 1998). De cette combinaison de la simulation et de l’automatisation
de l’evaluation a assez Vite decoule une nouvelle application : l’apprentissage automatique de
strategies optimales (Levin, Pieraccini, 1997) (Singh et al., 1999). Dans cet article, un environnement
de simulation de dialogues est propose dans le cadre de cette derniere application.

481

482

Olivier Pietquin

De tels environnements existent donc deja. Certains utilisent des modeles statistiques de transitions
entre etats obtenus d’apres observation de dialogues reels, (Singh et al., 1999). D’autres utilisent un
modele d’utilisateur sans memoire (Levin, Pieraccini, 1997) et n’incluent pas de modelisation de
l’erreur. Ici, nous decrivons un environnement de simulation comprenant un modele d’utilisateur
consistant etant donne l’historique de l’interaction (avec memoire) et un but. Cet environnement
comprend aussi un modele de systeme de reconnaissance vocale ainsi qu’un module simulant la
comprehension du langage naturel. En incluant ces modules dans l’environnement, nous esperons que
les strategies apprises tiendront comptes de leurs lacunes.

2 Un modele formel pour le dialogue vocal homme—machine

De maniere forrnelle et comme le decrit la Figure 1, un dialogue vocal homme—machine peut etre
considere comme un processus sequentiel dans lequel un utilisateur humain et un systeme de gestion
de dialogue (DM: Dialogue Manager) communiquent grace a la parole au travers d’un canal de
transmission. Ce canal est compose de differents modules qui manipulent chacun l’inforrnation pour
lui faire prendre une forme utilisable par le ou les modules suivants. Le but d’un systeme de dialogue
etant souvent de foumir de l’inforrnation a l’utilisateur, le systeme de gestion de dialogues peut donc
acceder a une base de connaissance.

Le processus etant sequentiel, il peut etre
discretise en tours t. A chaque tour, le
w, ‘ gestionnaire de dialogue genere un
ensemble d’actes de communication a,
sur base de son etat inteme s, pouvant se
materialiser en une invite, une question,
une aide, une demande de confirmation,
la ferrneture du dialogue etc. Aﬁn d’etre
compris par l’utilisateur, cet ensemble est
transforrne en un signal de parole sys, par

Traitem em des
sorties vocales

 

ASR

M,  i 7-’ _ Cl-‘Ask

Utilisateur  
k 9 .
gr 2 t

 

de connaissance:

Généraiion ““ "
des sorties
vocales

(NLG + TTS)

    

     

les systemes de generation de sorties
vocales. En fonction de ce qu’il a pu
comprendre de ce signal, de sa
connaissance au moment t (k,) et du but qu’il poursuit en communiquant avec le systeme (g,),
l’utilisateur produit a son tour un signal de parole u,. Dans le cas particulier des systemes de dialogue,
le terrne ‘connaissance’ peut faire reference a la connaissance de l’utilisateur concemant l’historique
de l’interaction, la tache, le systeme lui—meme ou le monde en general. Les deux signaux vocaux u, et
sys, sont entaches par le bruit ambiant n, au moment de leur production. Le systeme de reconnaissance
vocale (ASR) traite alors le signal u, et le transforrne en un ensemble de mots w,. Au passage, le
module ASR produit une mesure CLASR indiquant le degre de conﬁance qu’il accorde a son resultat.
L’ensemble w, est ensuite passe au systeme de comprehension de parole (NLU) qui doit en retirer une
representation semantique que nous supposerons mise sous la forme d’un ensemble de concepts c,. Le
module NLU produit lui—aussi une mesure de conﬁance CLNLU associee a l’ensemble c,. L’ensemble
{c,, CLASR, CLNLU} compose une observation o, qui est utilisee pour realiser une mise a jour de son etat
interne. D’un point de vue probabiliste, le comportement de l’utilisateur peut etre resume par la
probabilite conjointe suivante :

Figure l : Modele de dialogue vocal homme—machine

P(u, g,k sys,a,s,n)= P(k I sys, a, s,n)- P(g I k,sys,a,s,n)- P(u I g,k, sys, a, s,n)
MAJ de coiinaissance Modification du but Sortie utilisateur 
= P(k I sys, s, n)- P(g I k) - P(u I g, k, sys,n)

MAJ de connaissance Modification du but Sortie utilisateur

Les simpliﬁcations dans (1) tiennent compte de plusieurs faits, notamment on peut raisonnablement
admettre que la connaissance de l’utilisateur n’est pas modiﬁee par l’acte a puisque l’utilisateur n’a
pas acces directement a cette valeur. De meme, sa réponse ne depend ni de l’acte a qu’il ne connait

Résecm Bayésien pour mt modéle d’utilisateur et mt module de compréhension pour l’0ptimisati0n des
systémes de dialogues

pas, ni de l’etat s qu’il a du integrer dans sa connaissance de l’historique de l’interaction. Enﬁn, une
modification du but de l’utilisateur doit passer par une modiﬁcation de sa connaissance uniquement.
Les trois terrnes de (1) mettent en evidence les relations etroites qui existent entre le processus de
production de parole et le couple {but, connaissance}. Neanmoins, la modification de la connaissance
est un processus incremental (mise a jour) et se base donc aussi sur la connaissance prealable de
l’utilisateur :

P(k I sys, s, 11): Zk_ P(k I k", sys, s, I1)-P(k‘ I sys, s, I1)
= Zr P(k I k‘, sys, I1)-P(k' I s)

Ici, k" represente la Variable k,_1. La simpliﬁcation du second facteur de la somme provient du fait
evident que la connaissance de l’utilisateur au temps t—l ne peut pas dependre des signaux de parole ou
de bruit au temps t.

(2)

3 Le modele d’utilisateur

3.1 Un reseau bayesien dynamique

Les equations (1) et (2) perrnettent de dire
qu’un reseau bayesien dynamique (DBN :
Dynamic Bayesian Network) pourrait
encoder la factorisation particuliere des
probabilites associees a l’utilisateur
(Pearl, 1988). Les noeuds du reseau sont
donnes par les Variables presentes dans les
equations (sys, n, k, g, u) et les arcs sont
donnes par les probabilites
conditionnelles. La consistance de tour en
tour est assuree par la dependance dans le
temps de la Variable k. Le reseau
dynamique obtenu est montre sur la
Figure 2. Les Variables sys et 11 sont des
Variables ‘ l’utilisateur

t t-1

 

Figure 2 : Reseau bayesien dynamique

exterieures a
(cercles Vides), les Variables k et g sont des Variables intemes (cercles gris—clair) et la Variable u est une
Variable de sortie (cercles gris—fonce).

3.2 Utilisation du Modele

Le DBN de la Figure 2 parait relativement simple, neanmoins la deﬁnition des Variables qu’il fait
intervenir est plus ou moins ﬂoue. Ici, nous avons choisi une representation des Variables en paires
« attribut—valeur » (paires AV) derivees de la description en « Matrice attribut—valeur » de la tache.
Dans ce cadre, chaque acte de communication est considere comme un ensemble de paires AV. Dans
ce qui suit, Le signal de parole sys emis par le systeme est alors modelise par un ensemble de pairs AV
dont l’ensemble des attributs, note S={s"}, contient des elements qui peuvent prendre des Valeurs
booleennes indiquant si oui ou non l’attribut associe est present dans sys. Un attribut special non
booleen AS sera inclus a S et sa Valeur deﬁnira le type d’acte de communication associe a sys. Les
types acceptes peuvent etre ‘invite’, ‘question’, ‘demande de relaxation’, ‘proposition’, ‘demande de
conﬁrmation’, ‘ferrneture du dialogue’,  Une question directe sera alors caracterisee par un attribut
A5 egal a ‘question’ et un seul attribut s" dont la Valeur sera vraie. La reponse u de l’utilisateur sera
modelisee par une autre paire AV dans laquelle les attributs appartiennent a U = {u”} et l’ensemble
des Valeurs possibles pour chaque attribut u” sera note V = { vf’ }. Un attribut special CU est ajoute a U

et sa Valeur booleenne indique si l’utilisateur a decide de clore le dialogue dans sa reponse. Le but et la

483

484

Olivier Pietquin

connaissance de l’utilisateur seront representees respectivement
par les paires G = {[g7, gv,7]} et K = {[k", kv{‘]} ou g7 et k" sont
des attributs et gv,7 et kvf‘ sont les valeurs possibles. En fonction

de ces nouvelles notations, le réseau de la Figure 2 devient celui

de la Figure 3 ou la dependance dans le temps a ete l
volontairement omise pour plus de clarté ainsi que le bruit dont

la modelisation est trop complexe. Chaque valeur ou état U

possible pour chaque variable de ce reseau est une combinaison l
des attributs et des valeurs, ce qui signiﬁe que les etats sont
discrets et en nombre fini. On peut donc deﬁnir une version
factorisee de ce reseau dans laquelle ﬁgureraient les variables

A5, S”, v97 , Lt", vf’ , g7, gv,7, k", kvf et Uc.

l

Figure 3 : Reseau bayesien base
sur les paires AV

Considerons une tache simple consistant a remplir un formulaire compose de deux entrees : S = {s1,
s2 . Le s steme eut utiliser 4 es d’actes de communication: ‘invite’, ‘ uestion directe’, ‘demande
3’
de conﬁrmation’ et ‘ferrneture’. Pour simplifier, considerons que la connaissance de l’utilisateur se
compose de simples compteurs, chacun associe a un element de S, initialises a 0 et qui sont
incrementes a chaque fois que le systeme pose une question ou demande une conﬁrmation sur l’entree
associee. Ceci est suffisant pour perrnettre au modele d’utilisateur de rester consistant par rapport a
l’historique de l’interaction et de reagir a un comportement insatisfaisant du systeme (en reagissant
lorsqu’une entree a ete demandee plusieurs fois). Le but de l’utilisateur est alors de transmettre au
s steme les valeurs correctes our les attributs re resentes ar les entrees du forrnulaire (Fi ure 4).
Y

Att. Val. Count
g1 gvi k1
g2 gvz k2

Figure 4 : But et connaissance de l’utilisateur

L’utilisateur peut donc inclure dans ses reponses u les deux attributs ul et uz (il y a autant d’attributs
dans U que dans S). Aﬁn de simuler la reponse de l’utilisateur a l’invite, il sufﬁt alors d’entrer
l’evidence suivante dans le moteur d’inference :

invite 0 0 l 1

gV1
Figure 5 : Evidence pour une reponse a l’invite

gV2

Les valeurs l associees aux variables gi signiﬁent que les attributs gi sont bien presents dans le but.
Grace a cette evidence, le moteur d’inference produira les probabilites P(u1=l), P(u2=l), P(UC=l) et
leurs complements. Tout d’ abord, le modele choisit de maniere aleatoire un nombre reel entre 0 et 1, si
ce nombre est inferieur a P( UC=l), le dialogue est clos. Dans le cas contraire, le meme processus est
repete pour choisir les attributs presents dans la reponse de l’utilisateur. En supposant que ul est
selectionnee pour etre presente dans la reponse de l’utilisateur, l’evidence suivante est alors entree
dans le moteur d’inference :

1 0 gV1

Figure 6 : Inference pour une valeur de reponse

gV2

4 Simulation de la comprehension de parole

La simulation de NLU peut se faire en utilisant le reseau bayesien decrit plus haut comme
classificateur. Pour ce faire, nous considererons que les erreurs de reconnaissances vocales n’affectent
que les valeurs des paires AV alors que les erreurs d’associations attribut—valeur sont dues au module

Résecm Bayésien pour mt modéle d’utilisateur et mt module de compréhension pour l’0ptimisati0n des
systémes de dialogues

de comprehension. En considerant que le processus de reconnaissance vocale a transforme les valeurs
V = { vf’ } génerees dans sa reponse u par le modele d’utilisateur en un ensemble de valeur W = {Wj} et
en reprenant l’exemple simple du remplissage de forrnulaire explique dans la section precédente, les

evidences suivantes peuvent etre introduites dans le moteur d’inference pour simuler la comprehension
de la reponse a l’invite :

with or
invite 0 0 W1 W1

Figure 7 : Evidence pour la comprehension de la reponse a l’invite

A moins que Wj ne soit pas une valeur acceptable pour un des attributs testes, ces deux différentes
evidences vont fournir des valeurs pour les probabilites P(u1 I A S = greet, v11 = Wj) and P(u2|AS = greet,
v12 = Wj). Le systeme de simulation de comprehension va alors affecter la valeur Wj a l’attribut ui ayant
produit la probabilite la plus haute. Des situations plus complexes peuvent evidemment etre
rencontrees mais il est toujours possible de les transformer en evidence utilisable par le moteur
d’ inference. Cette methode peut aussi produire une sorte de niveau de confiance de comprehension.
Dans le cas de la classification d’une seule valeur, le niveau de confiance de comprehension est
simplement la probabilite foumie par le moteur d’inference. Lorsque plusieurs valeurs ont du etre
associee a des attributs par le module de comprehension, une mesure de confiance peut etre affectee a
chaque paire ou une mesure globale peut etre donnee en multipliant toutes les valeurs.

5 Appr entissage de str atégies optimales par simulation

Le modele decrit ci—dessus a ete developpe dans le but de l’apprentissage automatique de strategies de
dialogue homme—machine optimales. Nous avons donc mis notre environnement en presence d’un
agent d’apprentissage par renforcement comme propose dans (Levin, Pieraccini, 1997). Pour se faire,
il faut definir un critere d’optimisation. On peut en trouver plusieurs dans la litterature neanmoins,
l’hypothese selon laquelle la contribution de chaque acte a la satisfaction de l’utilisateur est une bonne
mesure de l’evaluation d’une strategie est retenue ici. Selon (Singh et al, 1999) une fonction de coﬁt
basee sur une mesure de la completion de la tache, les performances de reconnaissance et de
comprehension et la durée en tours du dialogue serait satisfaisante. Dans notre experience, les
utilisateurs sont invites a fournir des inforrnations a propos d’un voyage en train. Les attributs sont
donc une ville de depart, une ville de destination, une heure de depart, une heure d’ arrivee desiree et la
classe. 11 y a 50 valeurs possibles pour les villes (les memes pour le depart et l’arrivee) et les heures
possibles sont les heures plaines (de 0 a 24). Les types d’actes de communications possibles sont
‘invite’, ‘question directe’, ‘question ouverte’, ‘confirmation explicite’ et ‘ferrneture du dialogue’.
Nous realisons plusieurs experiences differentes dans lesquelles l’agent d’apprentissage evolue dans
un espace d’état construit sur base de l’historique de l’interaction et d’une valeur binaire indiquant si
le niveau de confiance de la demiere interaction est ham ou bas. Les experiences varient entre autre
par la deﬁnition du niveau de confiance qui peut etre uniquement CLASR (espace d’etats S1 dans la
suite) et CLASR*CLNLU (espace d’etats S2 dans la suite). De meme la fonction de coﬁt integre l’une ou
l’autre mesure de confiance. Au debut de chaque dialogue, un but d’utilisateur est construit assignant
des valeurs aux 5 attributs. La mesure de completion de la tache est alors definie comme le rapport
entre le nombre d’attributs dont la valeur a éte correctement assignee au nombre d’attributs en tout (5
ici). On definit aussi deux environnements de simulation. Le premier (Siml) integre le modele
d’utilisateur et un module de simulation de reconnaissance vocale introduisant des erreurs et une
mesure de confiance de reconnaissance. Le second environnement (Simz) integre, en plus, le module
de comprehension. Nous avons realise trois experiences differentes en combinant différemment les
espaces d’ états et les environnements de simulation. Les resultats de l’apprentissage sont montrés dans
les tableaux de la Figure 8. Dans le tableau de gauche sont indiques les resultats des mesures
objectives pouvant etre obtenues lors d’un dialogue moyen suivant la strategie apprise (mesures
obtenues en calculant la moyenne des mesures faites sur 10 000 dialogues simules). Dans le tableau de
droite sont indiquees les fréquences moyennes d’occurrences de chaque type d’acte de
communication.

485

486

Olivier Pietqnin

 

Sim], S; 5.39 0.81 Sim S 1.0 0.85 1.23 1.31 1.0
Sim2, S; 7.03 0.74 Sim S 1.0 1.25 1.18 2.60 1.0
Simg, S2 5.82 0.79 Sim 1.0 1.05 1.18 1.58 1.0

Figure 8 : Resultats de l’experience

Grace aux tableaux de la Figure 8, nous pouvons conclure que lors de la premiere experience (sans
erreur de comprehension), il y a plus de question ouvertes que de questions directes. Les erreurs de
reconnaissances etant prises en compte par l’introduction de CLASR dans S1 et Siml, il y a souvent des
demandes de confirmations. Dans la deuxieme experience, des erreurs de comprehensions sont
introduites mais elles ne peuvent pas etre detectees par les mesures de confiance. On observe une
augmentation du nombre de confirmations puisque le systeme ne peut jamais etre certain que les
valeurs sont bien assignees. La longueur moyenne du dialogue s’en trouve augmentee et la completion
de la tache diminue. En ajoutant CLNLU dans S2, les performances s’ameliorent et on retrouve presque
les resultats de la premiere experience. Ceci est du au fait que certaines questions ouvertes sont évitees
parce qu’elles resultent en une tres mauvaises mesure de confiance. En effet la strategie est modifiee et
les questions ouvertes concemant les deux villes en meme temps sont tres peu probables car elles
induisent des confusions et des niveaux de confiance plus faibles.

6 Conclusions et perspectives

Dans cet article, un environnement de simulation de dialogues dans lequel ont ete introduit un modele
d’utilisateur consistant et un module de simulation de comprehension de parole a ete décrit. Cet
environnement a éte developpe dans le but d’un ’apprentissage de strategies de dialogues optimales et
il a pu etre démontre par experience que cet environnement permettait de mettre en evidence des
problemes eventuels de comprehension et d’adapter la strategie automatiquement en consequence.
Quelques particularites de l’environnement n’ont pas ete exploitees dans ce travail et il serait
probablement interessant de s’y atteler dans le futur. Par exemple, la relation avec le fonctionnement
parallele de l’utilisateur et le gestionnaire de dialogue et le phenomene de grounding intervenant dans
les dialogues homme—homme a ete brievement mentionne dans la section 2 mais n’a pas vraiment éte
exploitee. Le besoin d’introduire des sous—dialogues permettant la mise en phase des connaissances
supposees de l’utilisateur et de l’etat reel du gestionnaire pourrait etre detecte par la l’inconsistance
entre l’etat du systeme et des valeurs inferees de la connaissance de l’utilisateur.

Refer en ces

ECKERT W., LEVIN E., PIERACCINI R. (1998) Automatic Evaluation of Spoken Dialogue Systems,
Technical Report TR98.9.I, AT&T Labs Research.

LEVIN E., PIERACCINI R. (1997), A Stochastic Model of Computer—Human Interaction for Learning
Dialogue Strategies, Proc. Enrospeech’97, Rhodes, Greece, pp. 1883-1886.

PEARL J. (1988) Probabilistic Reasoning in Intelligent Systems: Networks of Plansible Inference,
Morgan Kaufmann Publishers, Inc. San Francisco, California.

PIETQUIN O., DUTOIT T. (2002) Modelisation d’un Systeme de Reconnaissance dans le Cadre de
l'Evaluation et l'Optimisation Automatique des Systemes de Dialogue, Actes des Jonrnees d’Etnde de
la Parole, JEP 2002, Nancy (France).

POWER R. (1979) The Organization of Purposeful Dialogues, Linguistics 1 7, pp. 107-152.

SINGH S., KEARNS M., LITMAN D., WALKER M., (1999) Reinforcement Learning for Spoken Dialogue
Systems, Proc. NIPS’99, Denver, USA.

