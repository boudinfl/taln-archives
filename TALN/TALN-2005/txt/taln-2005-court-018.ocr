TALN 2005, Dourdan, 6-10 juin 2005

Correction automatique en temps réel
Contraintes, méthodes et voies de recherche

Roger Rainero

Société Diagonal
1, Traverse des Brucs — Valbonne — Sophia Antipolis
roger.r@prolexis.com

Mots-clés :

Correction automatique, temps réel, analyse syntaxique, grammaire de contraintes.

Résumé

Cet article expose un cas concret d’utilisation d’une grammaire de contraintes. Le produit qui les
applique a été commercialisé en 2003 pour corriger automatiquement et en temps réel les fautes
d’accord présentes dans les sous—titres des retransmissions en direct des débats du Sénat du
Canada. Avant la mise en place du systeme, le taux moyen de fautes était de l’ordre de 7 pour
100 mots. Depuis la mise en service, le taux d’erreurs a chuté a 1,7 %.

Nous expliquons dans ce qui suit les principaux atouts des grammaires de contraintes dans le

cas particulier des traitements temps réel, et plus généralement pour toutes les applications qui
nécessitent une analyse au fur eta mesure du discours (c.—a—d. sans attendre la fin des phrases).

Keywords:

Automatic correction, real—time, syntactic analysis, grammar of constraints.

Abstract

This article sets out a concrete use case of a grammar of constraints. The product which applies
them was commercialised in 2003 to automatically correct in real time the errors of agreement
present in the sub—titles of live televised debates from the Senate of Canada.

Before the introduction of this system, the average rate of mistakes was in the order of 7 per 100
words. With the introduction of this system, the rate of errors has fallen to 1.7%.

In the following section, we explain the main advantages of a grammar of constraints in the
specific case of real—time processing, and more generally for all applications which require an
analysis during the speech (that is, without waiting until the end of sentences).

Roger Rainero

1. Exposé du probléme

Le Sénat du Canada diffuse certains de ses débats en direct sur une chaine de télévision
spécialisée. Chaque sénateur pouvant s’exprimer dans sa langue matemelle (francais ou anglais),
les interventions se succedent indifféremment dans ces deux langues. Les téléspectateurs ont la
possibilité d’afficher des sous—titres, soit en francais, soit en anglais, mais lorsqu’une langue est
choisie, la totalité des débats est transcrite dans cette langue (fonction légale pour les
malentendants).

Les sous—titrages francais sont obtenus par retranscription sténotypée soit directe (locuteur
francais) soit indirecte (locuteur anglais traduit simultanément en francais, la sténotypiste
enregistrant alors la traduction). Les sténotypistes francophones et anglophones utilisent la
meme méthode de saisie mise au point en Amérique du Nord, tres perforrnante pour les langues
globalement phonétiques (ou la majorité des lettres se prononcent). Cette méthode donne ainsi
d’eXcellents résultats en anglais. Mais pour le francais qui comporte de nombreuses syllabes
finales muettes, les ajustements ont été longs et fastidieux, et la mise en ondes a été maintes fois
repoussée, a la recherche d’un taux acceptable de transcription exacte. Les résultats ont
régulierement progressé jusqu’en 2002, ou ce taux a plafonné aux alentours de 93 %. (sur 100
mots, seuls 93 étaient corrects).

Bien que ce taux paraisse tres élevé, il génere un nombre d’incidents de lecture tres au—dela de ce
qui est acceptable. 11 suffit, pour s’en convaincre, de constater qu’il correspond a 8 fautes par
minute de lecture. Le Sénat du Canada a alors fait un appel d’offres international dans le but de
trouver une solution automatique susceptible d’améliorer cette situation. La solution proposée
devait permettre de corriger automatiquement le plus grand nombre de fautes résiduelles
possibles, sans ajouter de fautes la ou il n’y en a pas. Par ailleurs, l’automate devait s’intercaler
dans le processus d’acquisition du texte sténotypé (logiciel Eclipse déja installé) sans le ralentir
de facon notable.

La société Diagonal a soumissionné en proposant une adaptation spécifique de ses moteurs
d’analyse déja utilisés dans les logiciels de correction ProLexis et Myriade. Cette solution
retenue par le Sénat a été livrée en octobre 2003.

2. Exigences dynamiques de la correction automatique des sous-
titrages en temps réel

Le systeme demandé par le Sénat imposait de faire les corrections au fur eta mesure de la saisie,
c’est—a—dire sans que l’on puisse attendre la fin des phrases. Cette obligation Vient
essentiellement du direct: les sous—titres suivent a peu pres les paroles des orateurs. En théorie
donc, les corrections doivent étre faites quasi immédiatement apres les fautes.

En pratique, nous disposions des souplesses suivantes :

0 les diffusions sont en léger différé d’une a deux secondes,
0 les sous—titres sont découpés en lignes qui ne partent a l’antenne que lorsqu’elles sont pleines.

Exemple avec la phrase : « Les ﬁlles jouent aux billes, les garcons jouent au ballon. »
Voici ce que saisit la sténotypiste par tranche de 0,5 seconde (avec les fautes) :

0,5 s Les

1,0 s Les ﬁlle

1,5 s Les ﬁlle joue

2,0 s Les ﬁlle joue au

2,5 s Les ﬁlle joue au bille,

Correction automatique en temps re'el : contraintes, methodes et voies de recherche

3,0 s Les ﬁlle joue au bille, les

3,5 s Les ﬁlle joue au bille, les garcon

4,0 s Les ﬁlle joue au bille, les garconjoue

4,5 s Les ﬁlle joue au bille, les garconjoue au

5,0 s Les ﬁlle joue au bille, les garconjoue au ballon.

Et Voici ce que doit Voir le telespectateur (entre parentheses, les corrections a faire) :

0 s (rien)
3 s LES FILLE(S) JOUE(NT) AU(X) BILLE(S),
6 s LES GARCON(S) JOUE(NT) AU BALLON.

L’automate doit coniger les fautes de la lre ligne au plus tard au temps 5,0 (temps reel 3,0 + 2
secondes de differe), c’est—a—dire lorsque le 4e mot de la ligne suivante Vient d’arriVer. Pour la
premiere faute (fille), il dispose d’un retard de 7 mots, mais pour la demiere faute (bille), il ne
beneficie plus que d’un retard de 4 mots. L’automate ignorant totalement a quel moment les
lignes sont declarees « pleines >>, il est oblige de s’astreindre a faire toutes ses corrections avec
un maximum de quatre mots de retard !

C’etait bien la la plus grande difficulte a laquelle nous allions etre confrontes.

3. Les atouts des systémes d’analyse basés sur les contraintes

Ce qui a rendu la chose possible avec ProLeXis tient dans le fait essentiel que notre moteur
exploite un principe de propagation de contraintes.

Comme dans les principaux systemes bases sur la satisfaction de contraintes (cf. (BlacheOO)),
notre approche ne Vise pas a construire un arbre syntaxique de la phrase, mais plutot a optimiser,
dans un reseau de contraintes, le chemin menant du premier au demier mot de la phrase :

    

 :))/V . mgtg  o mot3 (a)  ‘ o etc.
o (c) 0 m (c) 0 mot4 (c)
0 mot1(d)

Sur ce schema, les contraintes ne sont pas figurees. Elles ne se manifestent qu’au travers du
choix du chemin affiche qui est cense satisfaire le maximum d’entre elles.

Chaque nouveau mot apporte son lot de Variantes possibles, mais aussi son lot de contraintes
potentielles pour toutes les Variantes etablies depuis le debut de la phrase :

-) Appliquer une contrainte revient a calculer son coefficient de satisfaction (son << poids >>) dans
toutes les Variantes etablies.

-) Propager une contrainte revient a reconsiderer l’application des contraintes deja appliquees,
comme consequence de l’aniVee du nouveau jeu de contraintes.

Notre systeme ne construit donc pas un arbre, mais il pondere un reseau. A la fin de la phrase,
un algorithme simple peut restituer l’arborescence de la structure syntaxique, si le besoin s’en
fait sentir, mais cela n’est pas necessaire pour diagnostiquer les erreurs et les corriger.

La ponderation est souple, dans la mesure ou une contrainte mal satisfaite n’est qu’une
indication d’un ecart par rapport a la norme formalisee par cette contrainte. En ce sens, elle
produit des analyses robustes qui s’accommodent de deviances parfois fortes par rapport aux
usages ou meme de l’absence de certains mots.

Roger Rainero

Tout cela est bien connu et caractérise les grammaires basées sur les contraintes, mais n’est pas
determinant dans le cas qui nous intéresse.

Le plus gros avantage de notre grammaire, dans le cadre de la correction automatique en temps
réel, provient de sa capacité a délivrer une analyse pondérée des Variantes apres chaque mot. Bien
sﬁr, l’analyse est réputée optimale lorsque tous les mots de la phrase sont connus, mais cette
analyse est néanmoins disponible en phase intermédiaire apres chaque mot.

Enfin, le mécanisme de propagation apres chaque mot présente un autre avantage de taille dans le
cas de notre application << temps réel >> : il permet, par un choix judicieux des coefficients de
pondération, de marginaliser assez Vite certaines Variantes isolées et de limiter a un niveau
raisonnable le nombre de Variantes concurrentes que le logiciel évalue en parallele a chaque
iteration.

Ce mécanisme peut meme s’autoréguler en détruisant systématiquement les Variantes les moins
probables a chaque passe, de telle sorte que leur nombre total reste en dessous d’un seuil
critique pour le temps d’exécution.

Evidemment, toutes ces actions aveugles sont préjudiciables a la qualité de l’analyse in ﬁne.
Toute la question était de quantifier leur inﬂuence réelle sur la fiabilité des corrections attendues.

4. Tests de fiabilité des résultats intermédiaires a « mot + 4 »

Jusqu’a présent, nous n’aVions jamais testé la fiabilité des résultats intermédiaires avant la fin de
la phrase. 11 nous fallait donc Verifier que dans le contexte du Sénat, nous disposions
effectivement de suffisamment d’indices pour décider des corrections au maximum a mot + 4.

En théorie, en effet, tout nouveau mot dans une phrase peut changer totalement son analyse.
C’est un exercice bien connu auquel se livrent Volontiers les professionnels de l’analyse
syntaxique. Et c’est aussi avec de tels exemples que l’on peut démontrer que ce que nous avons
fait est impossible. En Voici quelques—uns :

Debut : Le chien regarde le chat et la souris. ..

Suite 1 : Le chien regarde le chat et la souris mais. ..

Suite 2 : Le chien regarde le chat et la souris prise. ..

Suite 2a : Le chien regarde le chat et la souris prise. .. (au piege ?)
Suite 2b : Le chien regarde le chat et la souris prise. .. (du tabac ?)

Mais quelle est la portée statistique réelle d’un tel phénomene et quelle est son inﬂuence sur la
fiabilité d’un systeme de correction automatique apres quatre mots ?

Pour l’estimer, nous avons fabriqué un prototype du produit fini simulant le comportement de
l’outil d’acquisition Eclipse. Ce logiciel lisait un extrait des débats du Sénat obtenu par
sténotypie et l’enVoyait signe a signe a l’automate qui gardait trace dans un fichier de sortie de
toutes les corrections faites et du moment ou elles pouvaient étre faites.

Le tableau suivant montre un extrait de ce fichier de sortie, concemant un début de phrase telle

\

qu’elle est délivrée par Eclipse, fautes comprises (colonne de gauche). A droite, les fautes
corrigées sont intercalées apres le mot qui les rend possibles :

Correction automatique en temps reel : contraintes, methodes et voies de recherche

Apres la saisie de. .. Les corrections suivantes sont faites. ..
Ilfaut egalement des solution pratique qui. .. solution 9 solutions
pratique 9 pratiques
soit sense... soit 9 soient
pour. .. sense -) sensees
ceux qui travaille sur. .. travaille 9 travajllent

On constate que les deux premieres erreurs << solution >> et « pratique >> sont corrigees des la
saisie de « qui », donc respectivement a mot + 2 et mot + 1.

Regardons de plus pres les analyses qui sont faites a ce stade : le mot << pratique >> est ambigu :
ce peut etre un nom, un adjectif ou un Verbe. Toutes ces formes generent potentiellement autant
de Variantes. Les Vaiiantes Verbales paraissent improbables, mais, comme toujours en pareil cas,
une petite reﬂexion permet d’en decouvrir certaines formes legitimes :

« Ilfaut egalement des solutions, pratique ce sport et tu verras ! »
« Ilfaut egalement des solutions(, ) explique Cesar... »

Bien sur, la Virgule semble cruciale, mais la ponderation de son absence n’est pas suffisante ici.
En revanche, l’aniVee du mot suivant << qui >> est determinante, elle rend la ﬂexion Verbale pour le
mot « pratique >> quasiment impossible. En theorie, la ﬂexion Verbale ne peut étre totalement
exclue, car l’hypothese d’oubli d’un mot peut toujours la justifier. Mais les reglages actuels de
nos seuils de probabilites pour des textes de provenance stenotypee font qu’elle est rej etee ici.

La suite est comprehensible : determine nominal, le groupe precedent est fautif sur l’accord GN.
Deux formes correctes sont possibles : << une solution pratique >> et « des solutions pratiques >>.
C’est la qu’interViennent des automates specialises dans la correction automatique specifique du
Senat du Canada : ces automates choisissent de fagon probabiliste la correction au pluriel.

Applique au texte de reference de 2 000 mots fourni par le Senat, contenant 149 fautes et
correspondant a un debat reel de 20 minutes, le prototype a donne les resultats suivants :

Nombre de fautes corri gees : ...aVec un retard de :
89 1 mot
17 2 mots
3 3 mots
1 4 mots

La faible incidence des situations ambigues sur les corrections automatiques envisagees pour les
debats du Senat du Canada paraissait donc confirmee, au moins sur le texte etudie. Et la
propagation de contraintes montrait la une capacite tout a fait etonnante a resoudre le probleme
pose. Restaient a demontrer son efficacite et sa stabilite a grande echelle.

Roger Rainero

5. Méthode d’évaluation a grande échelle.

L’inconvénient des systemes probabilistes est que leur comportement ne peut étre totalement
déduit de tests a petite échelle. Typiquement, dans le cas du Sénat, la nature meme des débats
influe grandement sur le vocabulaire, les intervenants et donc sur les types de phrases
prononcées. Nul doute qu’un simple échantillon de 2 000 mots ne pouvait représenter
correctement la totalité des situations auxquelles devrait faire face l’automate apres sa mise en
service.

Apres avoir été choisis par le Sénat du Canada pour exécuter le marché, nous avons donc lancé
en parallele les deux réalisations suivantes : d’une part, le logiciel lui—méme (bien entendu), et
d’autre part, l’étalonnage d’un corpus de 50 000 mots destiné a valider les tests d’usine du
logiciel, avant sa livraison chez le client.

Ce corpus a été extrait des transcriptions sténotypées de débats récents représentant un peu plus
de 10 heures d’antenne réparties sur une période de deux mois. On ne s’est limité a cette taille
que pour des contraintes de temps. Deux personnes ont travaillé pendant un mois pour
sélectionner les textes, éliminer les passages en double, détecter les fautes et les baliser dans le
texte. Quelque 3 500 fautes y ont été repérées.

L’application de l’automate sur ce corpus a corrigé plus de 2 500 fautes sur 3 500, établissant
un taux de reconnaissance a grande échelle stable a 98,31 %. Sur ce meme corpus, l’automate
n’a introduit que 23 fautes, soit un taux moyen de surcorrection de 1/2100.

6. Perspectives et voies de recherche

ll faut se méfier de l’idée fausse qui consiste a penser que le temps d’eXécution n’est pas un
probleme majeur pour les algorithmes d’analyse automatique. On entend souvent dire : << de
toute maniere, les machines iront de plus en plus Vite et un jour viendra ou les algorithmes lents
s’exécuteront Vite ! >>.

Tout cela est vrai, sauf pour les applications << temps réel >>. La correction automatique des sous-
titrages est un exemple, mais il y en a bien d’autres. La reconnaissance vocale multilocuteur et la
traduction simultanée sont deux domaines qui pointent déja a l’horizon et qui n’attendent que
l’émergence de nouvelles technologies linguistiques pour se déployer a grande échelle.

Le découpage du mécanisme d’analyse en strates successives ou le controle intégré du nombre

de variantes concurrentes que permettent aujourd’hui les grammaires guidées par la satisfaction
de contraintes semble étre un atout de poids dans les applications temps réels.

Références

Blache P. (2000) Le role des contraintes dans les théories linguistiques et leur intérét pour
l’analyse automatique, Actes de TALN 2000.

Blache P. (2000) Constraints, Linguistic Theories and Natural Language Processing, Lecture
Notes in Artiﬁcial Intelligence, Springer—Verlag.

Harper M. P., Helzerman R. A. (1995). Extensions to constraint dependency parsing for spoken
language processing. Computer Speech and Language, Vol. 9 (3), pp 187-234.

Maruyama, H. (1990). Constraint dependency grammar and its weak generative capacity.
Computer Software.

