TALN 2005, Dourdan, 6-10 juin 2005

Une plateforme pour l’acquisiti0n, la maintenance et la
validation de ressources lexicales

VanRullen T. , Blache P. , Portes C. , Rauzy S. , Maeyhieux J .—F. , Guénot
M.—L. ,Balfourier J .—M. , Bellengier E.
Laboratoire Parole et Langage — CNRS — Université de Provence
29, Avenue Robert Schuman — 13100 Aix—en—Provence
{tristan,pb}@lpl.univ—aix.fr

Mots-clefs :

dictionnaire, lexique, lexique noyau

K€yWOFdS2 dictionary, lexicon, kernel lexicon

Résumé Nous présentons une plateforme de développement de lexique offrant une base
lexicale accompagnée d’un certain nombre d’outils de maintenance et d’utilisation. Cette base,
qui comporte auj ourd’hui 440.000 formes du Frangais contemporain, est destinée a étre diffusée
et remise a jour régulierement. Nous exposons d’abord les outils et les techniques employees
pour sa constitution et son enrichissement, notamment la technique de calcul des fréquences
lexicales par catégorie morphosyntaxique. Nous décrivons ensuite différentes approches pour
constituer un sous—lexique de taille réduite, dont la particularité est de couvrir plus de 90% de
l’usage. Un tel lexique noyau offre en outre la possibilité d’étre réellement complété manuelle—
ment avec des informations sémantiques, de valence, pragmatiques etc.

AbStI‘.‘:lCt We present a lexical development platform which comprises a lexical database
of 440.000 lemmatized words of contemporary French, plus a set of maintenance tools. The
lexical database is intended to be distributed and updated regularly. We present in this paper
tools and techniques applied for the lexicon constitution and its enrichment, in particular the
computation of lexical frequencies by morphosyntactic category. Then we describe various
approaches to build an under—lexicon of reduced size, whose characteristic is to cover more
than 90% of the use. Such a kernel lexicon makes it moreover possible to be really enriched by
hand with semantic, valence, pragmatic information, etc.

511

512

VanRullen T., Blache P., Portes C., Rauzy S., Maeyhieux J .—F., Guenot M.—L. ,
Balfourier J .—M., Bellengier E.

1 Introduction

L’elaboration d’un lexique electronique peut sembler une tache obsolete, de nombreux lex-
iques du francais etant references. Cependant, force est de constater que cette affirmation doit
étre modulee. La premiere constatation est que seul un petit nombre d’entre eux est effec-
tivement accessible. Il faut de ce point de vue souligner le role considerable joue par Bdlex
(cf. [de Calmes98]) qui, dans le cadre des activites du GdR—PRC Communication Homme—
Machine, a longtemps ete le lexique le plus largement diffuse en contribuant ainsi puissamment
a l’evolution du domaine en France. Le mode de diffusion constitue evidemment un aspect
critique 1. Un rapide survol des ressources lexicales libres d’acces pour le francais permet d’en
identiﬁer deux :

—Lexique: il s’agit d’un lexique comportant 130.000 formes et comportant des
informations morphosyntaxiques, phonologiques et des indications de
frequence (cf. [New01], http : //www . lexique . org/).

— ABU : contient 300.000 formes avec indications morphosyntaxiques (cf. [ABU],

http://abu.cnam.fr/)

On peut par ailleurs trouver quelques ressources verbales, par exemple :

— Leﬁﬁ’ : il contient 200.000 formes verbales, avec les informations de base (temps,
nombre, personne) (cf. [Clement04], http : / / www . le f f f . net / );
— Litote : c’est une base contenant les formes conjuguees de 6.500 verbes.

(http://www.loria.fr/equipes/calligramme/litote/)

Par ailleurs, il faut egalement signaler la demarche initiee par le Loria dans le cadre du pro-
jet Morphalou (cf. [Romary04], http: / /loreley . loria . fr/morphalou/). Ce projet
foumira egalement a terme un lexique morphologique de 540.000 formes. Son interét tient
d’une part au fait qu’il est collaboratif mais egalement qu’il s’inscrit dans le cadre du projet
LMF (Lexical Markup Framework), proposant la normalisation du codage des informations
linguistiques.

Il reste donc un travail important pour parvenir a un lexique de qualite. Pour cela, une base
lexicale doit avant tout étre nettoyee de facon a proposer une couverture adequate du francais. Il
ne sert a rien de constituer une res source de 400 ou 500.000 formes si la plupart d’entre elles ne
sont pas attestees. Le second aspect concerne le type d’informations contenu dans le lexique. Il
est en effet necessaire qu’un lexique contienne pour une meme entree autant d’informations que
possible concernant ses proprietes morphologiques, syntaxiques, bien entendu, mais egalement
semantiques, phonetiques ou phonologiques. La forme phonetisee de l’entree, la syllabation ou
la frequence sont par exemple autant d’informations precieuses pour la description.

Nous decrivons dans cet article la base lexicale developpee au LPL. Cette base, construite au-
tour d’un lexique morphologique, presente la particularite d’étre couvrante, de contenir des
information variees et d’avoir ete validee sur corpus. Cette base est associee a une veritable
plateforme de developpement lexical, munie de divers outils de maintenance et d’acces. Apres
une presentation des principales caracteristiques de cette plateforme, nous en proposons une
evaluation se fondant sur differents corpus. Nous decrivons de plus l’exploitation de cette base
dans la perspective d’une etude lexicale du francais contemporain.

1Nous nous associons de ce point de vue a la démarche aujourd’hui proposée par le projetMorpha1ou et nos
ressources seront distribuées dans ce cadre

Une plateforme pour l’acquisition, la maintenance et la validation de ressources
lexicales

2 Le lexique complet

Le lexique que nous avons mis au point a fait l’objet de beaucoup d’etudes et de travaux
d’ amelioration. Nous aboutissons actuellement a un lexique defactorise de plus de 444.000
entrees correspondant a environ 320.000 formes orthographiques differentes. Ce lexique est
associe a un ensemble d’outils permettant sa maintenance, sa securisation et son interrogation.
Ce projet est la base nécessaire a des applications du TALN qui auront besoin d’une ressource
ﬁable, c’est pourquoi l’accent a éte mis sur la maintenabilité de la ressource.

Les entrees du lexique Dic0LPL sont basees sur des ressources libres et une acquisition semi-
automatique. Comme le montre la ﬁgure 1, nous avons au depart recense et incorporé des
lexiques libres, tels ABU ou Lexiqaeorg. Le formatage de notre lexique a nécessite un travail
de transformation, de categorisation, de phonétisation etc., aﬁn de faire correspondre les entrées
acquises. L’etape importante que constitue le calcul des frequences lexicales est aborde dans la
prochaine section.

RGSSOUFCES

-Ressources Iibres:
‘ABU
‘Lexique.org
‘Autres (divers)

'Ressources acquises
‘Manuellement

-Automatiq uement
(corpus)

Spécification des champs
‘Mot,
-Majuscule,

‘Phonétisation,
3? E ‘Lemme’
Filtrage

-Catégorie
Nettoyage

Syntaxique,
Défactorisation 'Fréq uence, etc...

 
       

Lexique:
444 266
entrées

 

Figure 1: Conception du dictionnaire

Figure 2: Extrait du lexique

Le format du lexique, son codage, et son stockage ont éte penses aﬁn d’accélérer son charge-
ment dans les applications qui le requierent. Ce lexique est en effet actuellement embarque dans
des applications de communication sur des machines ayant de petites capacites. D’autre part,
il s’agit de permettre avec le meme stockage un développement et des modiﬁcations manuels.
C’est pourquoi un format ASCII, structure en CSV tabule classique a éte choisi, plutot qu’un
standard XML ou qu’une forme binaire de type base de dormees. Ce choix a repondu a nos
attentes et permet une transformation rapide dans d’autres formats tels que le XML répondant
aux normes ISO (TC37/SC4) utilisees par le projet MORPHALOU par exemple.

Notre lexique se structure sous une forme defactorisee (une ligne par quadruplet [M0t, Phoneti-
sation, Categorie, Lemme] par opposition a d’autres lexiques pour lesquels une seule ligne est
reservée pour chaque forme orthographique.

L’ extrait de lexique donne dans la table 2 met en evidence les caractéristiques de son format.
On y observe la defactorisation du mot deambalais.

Certaines colonnes ont éte reservees pour un usage ulterieur; les mots acceptes dans ce lex-
ique ne doivent pas étre des afﬁxes, mais toujours des mots (simples ou composes) du langage
courant. Ainsi, les preﬁxes et sufﬁxes tels que anti, hecto, isme ou able en sont rejetés.

Le codage des champs du lexique est lui aussi contraint: les frequences correspondent au nom-
bre d’occurences de chaque entree mesuree sur les corpus d’apprentissage. Les valeurs sont des
entiers et ne representent pas des pourcentages. Les valeurs de traits des categories de chaque
entree sont formatees selon un codage derive de Multext et de Grace. La forme phonetisee est
exprimee a l’aide de l’alphabet standard Sampa, qui permet un codage phonetique en texte brut
sans faire appel a des polices de caracteres speciﬁques.

513

514

VanRullen T., Blache P., Portes C., Rauzy S., Maeyhieux J .—F., Guenot M.—L. ,
Balfourier J .—M., Bellengier E.

3 Plateforme d’enrichissement du lexique

Le lexique Dic0LPL est une res source en evolution. Nous presentons ici quelques uns des outils
qui permettent son enrichissement.

Deux outils — un segmenteur et un etiqueteur— met-
tent en relation les mots d’un texte fourni en en-
tree avec les mots du lexique. La ﬁgure 3 illus-
tre leur usage. Le segmenteur, base sur des au-
tomates simples, effectue un decoupage du texte
en tokens. C’est a partir de ces informations
que l’etiqueteur effectuera la desambiguisation en
contexte des categories a attribuer a chaque token.

texte >Segmenteur Etiqueteur some XML
" "

Figure 3: segmenteur et etiqueteur

La technique de desambiguisation que nous utilisons s’inspire des techniques stochastiques ex-
istantes. Nous avons cependant prefere developper notre propre étiqueteur aﬁn de correspondre
au mieux avec la precision des traits morphosyntaxiques que nous employons. Une premiere
evaluation de l’etiqueteur sur le corpus du projet Multitag (cf. [ParoubekOO]) a donne des re-
sultats par categorie Variant de 60% a 99%. Le score moyen calcule sur le corpus de reference
Multitag est de 95%.

Aﬁn d’enrichir le lexique et de calculer au besoin
les frequences lexicales speciﬁques a un ensem-
ble de corpus, nous avons developpe un outil de
frequencage. Comme l’indique la ﬁgure 4, cet
outil fait appel aux resultats de l’etiquetage pour
en deduire les frequences des entrees du lexique,
pour chaque couple (mot, catégorie). A partir
d’un lexique initial, etant donne un ensemble de
textes, nous obtenons en sortie du frequenceur un
lexique des mots inconnus, un lexique des noms—
propres et une nouvelle Version du lexique initial,
dont les champs fréquence sont mis a jour.

     

Ensemble de textes
étiquetés
%_f
+

fréquences

F .
Ensemble de requencage

textes

 
    

Lexique initial
m
Lexique fréquencé

     
     
   

Fusion

  

Mots inconnus
§——j_—J
Noms propres

Figure 4: calcul des frequences lexicales

La Version actuelle de Dic0LPL dispose des frequences acquises sur 153 millions de mots tires
du journal Le Monde, de ressources litteraires gratuites, de transcriptions de corpus oraux et des
textes speciﬁques (domaine medical, corpus de mails etc.).

D’autre part, la forme phonetisee des entrees est obtenue grace a un phonetiseur inspire du
projet Syntaix (cf. [Di CristoOl]) pour la conception d’un systeme de synthese Vocale. D’autres
champs (semantique, Valence Verbale etc.) necessitent touj ours une Validation manuelle.

L’ evaluation des outils et du lexique est realisee avec les techniques suiVantes: Nous pouvons
mesurer la couverture du lexique pour un corpus donne (calculer le quotient nombre de mots
recomms / nombre total de mots). La couverture actuelle du lexique represente 96% des corpus
analyses (153 millions de mots). Lorsque nous souhaitons une information plus ﬁne concernant
l’etiquetage, il faut alors disposer d’un corpus de reference, pour lequel chaque mot est associe a
une catégorie morphosyntaxique certiﬁee. Il est alors possible de mesurer les scores de rappel
et précision pour chaque categorie. C’est dans ce cadre que nous avons pu calculer un score de
95% sur le corpus de reference Multitag.

Une plateforme pour l’acquisition, la maintenance et la Validation de ressources
lexicales

4 Un lexique noyau du frangais contemporain

Une fois le lexique constitue, il est necessaire de Veriﬁer sa couverture. Par ailleurs, l’analyse
des corpus décrits plus haut permet de fournir des indications pour la constitution d’un dic-
tionnaire minimal (ou lexique noyau) du francais ayant une couverture maximale (un tel sous-
lexique est toujours speciﬁque a un ensemble de corpus). Cette ressource est d’une grande
importance pour le futur: Il n’est pas possible d’enrichir un grand lexique manuellement. Or,
nombre d’informations ne peuvent aujourd’hui étre acquises totalement automatiquement, no-
tamment les informations sémantiques. Un lexique noyau permet d’identiﬁer un nombre limite
d’entrées lexicales qu’il est possible d’enrichir y compris manuellement. L’ objectif est a terme
de disposer d’une ressource lexicale tres complete, comportant des informations syntaxiques,
semantiques, Voire pragmatiques. Un lexique limite aux 10.000 formes les plus frequentes
couvre en moyenne 90% du francais. Il s’aVere donc intéressant de selectionner un lexique
noyau du Francais contemporain avoisinant cette taille. La qualite de l’information concernant
la fréquence de chacune des entrees du lexique complet permet de concevoir un lexique noyau
(dorenavant LN) des mots les plus frequents. C’est aussi l’occasion d’eValuer diachroniquement
l’eVolution du lexique de base du francais depuis "Le Francais Fondamental" (cf. [Gougen—
heim64] et [Blache05]). Nous avons selectionne les formes pertinentes du LN grace a une
methode simple utilisant une fréquence seuil (une autre méthode basée sur une réﬂexion a pro-
pos des types de categories a conserver independamment de leur fréquence s’est revelee moins
efﬁcace et a éte abandonnee). Ainsi, pour obtenir un dictionnaire de 10.000 formes (LN10)
avons nous selectionne les 10.000 entrees les plus frequentes du lexique general DicoLPL, c’est—
a—dire toutes les formes dont la fréquence est superieure a 1091. Différentes Versions de LN de
taille croissante ont été produites suivant la meme méthode : LN15 (frequence>613, 15.017
formes), LN20 (frequence>389,l9.990 formes) et LN30 (fréquence>l93, 30.018 formes) aﬁn
de comparer leurs couvertures et choisir le meilleur rendement taille/couverture.

Nous avons soumis les differentes Versions du

DicoNoyau Corpus écrit Corpus oral  .21 1111 tCSt d6 COUVCITUTC SUI dCU.X ll)/PCS 
LN10(f>1091) 33,631/U 91,56% / , / -

LN15(f>613) 91,07% 93,60% ferents delcorpus, un corpus ecrit (500000
LN20(f>389) 92,5o% 94,60% mots extraits d articles publ1es dans le Journal
LN30 (f>193) 94,0s% 96,46%

DicoLPL 9 6,21% 99,02% Le Monde) et un corpus oral (435.000 mots

et regroupe le Bristol Corpus, un ensemble de
95 entretiens enregistres et transcrits par Kate
Beeching (1988-1990), ainsi que des corpus de
parole recueillis au LPL).

Figure 5: couvertures par taille de lexique
et par type de corpus

Les résultats présentés dans la ﬁgure 5 appellent plusieurs commentaires: nous constatons
d’ abord que la couverture du lexique general DicoLPL (demiere ligne) n’est pas totale et qu’elle
est meilleure pour le corpus oral que pour le corpus ecrit, remarque qui Vaut aussi pour les
autres dictionnaires. Ceci s’explique selon nous par le fait que l’ecrit utilise un Vocabulaire
beaucoup plus étendu et Varie que l’oral. On constate aussi que les performances de couverture
s’améliorent régulierement au fur et a mesure que le LN contient plus de formes, ce qui est bien
sur attendu. Il faut neanmoins noter qu’il existe un saut qualitatif plus important entre LN10
et LN15 qu’entre LN15 et LN20 ou LN20 et LN30 alors meme que l’écart de taille entre ces
deux derniers est plus important. Le dictionnaire noyau de 15000 formes apparait donc comme
la Version optimale pour obtenir la plus grande couverture avec un nombre réduit de formes.

515

516

VanRullen T., Blache P., Portes C., Rauzy S., Maeyhieux J .—F., Guenot M.—L. ,
Balfourier J .—M., Bellengier E.

5 Conclusion

La plateforme de developpement de lexique de’cn'te dans cet article repond a un certain nombre
de besoins a la fois en termes de richesse d’informations, mais egalement de developpements
de lexiques specialises en produisant des frequences speciﬁques. Notre approche permet de
rationaliser le choix des entrees sur lesquelles travailler en proposant la construction d’un lex-
ique noyau elabore sur la base d’une veritable analyse de la langue. L’enrichissement manuel
de petits lexiques avec des informations semantiques, pragmatiques etc. s’en trouve facilite.
C’est pourquoi nous defendons la demarche qui consiste a concentrer les efforts sur un sous-
lexique dont la couverture a ete Veriﬁee sur corpus. D’autre part, un lexique de petite taille offre
de nombreuses possibilites d’etudes sur l’usage avec notamment les réseaux sémantiques, les
petits mondes etc. (Voir a ce propos [FerrerO1]).

Le fait de disposer d’un grand lexique de formes n’en reste pas moins un atout, puisque c’est
a partir d’une telle ressource que peuvent étre extraits des sous—lexiques ad hoc couvrant des
types de texte de domaines divers que le fréquengage permet d’isoler.

Enﬁn, la tache de constituer une telle ressource est immense. Nous souhaitons la Voir s’ ameliorer
avec le temps, ce qui suppose sa diffusion, sa confrontation a l’usage et un retour de la com-
munaute. La plateforme de’cn'te ici comportant une se’n'e d’outils de maintenance, il est ainsi
possible d’enVisager une mise a jour reguliere des informations. Au total, notre contribution
Viendrait s’inscire dans le mouvement de mise a disposition de ressources du frangais initie par
les differents projets signales plus haut.

Références

Association des Bibliophiles Universels, “ABU. Dictionnaire des mots communs”, in La Bibliotheque
Universelle, http://abu.cnam.fr/DICO/mots—communs.html. CNAM.

Blache P., M.—L. Guénot & C. Portes (2005), “Outils et ressources pour la mise a jour du Frangais
Fondamental”, in Proceedings of Frangais Fondamental: 50 ans de travaux et d’enjeux.

Clement L., B. Sagot & B. Lang (2004), “Morphology—Based Automatic Acquisition”, in proceedings of
LREC—04.

de Calmes M. & G. Pérennou (1998), “BDLEX : a Lexicon for Spoken and Written French”, in proceed-
ings of LREC—98

Di Cristo & P. Di Cristo (2001), “Syntaix : une approche métrique—autosegmentale de la prosodie”, in
revue TAL, 42:1

Ferrer R., Cancho I. & Sole R. (2001), “The small—world of human language”, Proceedings of the Royal
Society of London, B 268, 2261- 2266 url = "citeseer.ist.psu.edu/ferrer01small.html"

Gougenheim, G. ; Rivenc, P ; Michéa, R. & Sauvageot, A. (1964), “L’élaboration du Frangais Fonda-
mental”, ler degré, Didier : New B.

Pallier C., L. Ferrand & R.Matos (2001), “Une base de données lexicales du Frangais contemporain sur
Internet : Lexique ”, in L’Année Pschologique, 101

Paroubek P. & M. Rajman (2000), “MULTITAG, une ressource linguistique produit du paradigme
d’évaluation”, in Actes de la conference TALN—2000

Romary L., S. Salmon—Alt & G. Francopoulo (2004), “Standards going concrete: from LMF to Mor-
phalou”, in Workshop on Electronic Dictionaries, COLING—04.

