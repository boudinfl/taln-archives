TALN 2005, Dourdan, 6-10 juin 2005

La plate-forme Linguastream :
un outil d’expl0rati0n linguistique sur corpus

WIDLOCHER Antoine, BILHAUT Frederik
GREYC — CNRS UMR 6072 — Université de Caen
Campus 11, Sciences 3, B.P. 5186, 14032 Caen Cedex, France
{awidloch,fbilhaut} @ info.unicaen.fr

Mots-clefs :

K€yWOFdS2 Corpus linguistics, NLP, software framework

Linguistique de corpus, TAL, plate—forme logicielle

Résumé A travers la présentation de la plate—forme LinguaStream, nous présentons cer-
tains principes méthodologiques et différents modéles d’analyse pouvant permettre l’articula—
tion de traitements sur corpus. Nous envisageons en particulier les besoins nés de perspectives
émergentes en TAL telles que l’analyse du discours.

Abstract By presenting the LinguaStream platform, we introduce different methodologi-
cal principles and analysis models, which make it possible to articulate corpus processing tasks.
More especially, we consider emerging approaches in NLP, such as discourse analysis.

1 Introduction

Par dela la diversité des domaines d’investigation et des objets d’étude, un certain nombre de
tendances communes se conﬁrment peu a peu au sein de la communauté TAL. Se manifeste
tout d’abord, désormais distinctement, la généralisation du travail sur corpus, mouvement qui
constitue d’ailleurs un point de convergence fécond entre les travaux spéciﬁquement dédiés au
TAL et les démarches plus immédiatemment linguistiques. Les modéles théoriques proposés
doivent désormais trouver leur justiﬁcation et prouver leur validité « en corpus », et leur per-
tinence sera jugée, tantét sur leur capacité a rendre compte de la diversité dudit corpus (dans
une perspective descriptive), tantét a la lumiére de leur capacité a l’explorer « efﬁcacement »
(dans une perspective d’ingénierie documentaire). Se pose alors inévitablement la question de
la méthode et des outils a adopter pour travailler ainsi « sur corpus ».

Il devient en effet difﬁcilement envisageable de considérer celui—ci comme une matiére brute a
laquelle devraient se référer immédiatement les différents modéles et traitements. Au contraire,
la multiplication des points de me sur le corpus, qu’ils soient morphologiques, syntaxiques, sé—
mantiques, rhétoriques ou pragmatiques, qu’ils ne visent que l’une de ces dimensions ou qu’ils
les croisent, rend pressante la question des interdépendances entre ces vues possibles, interdé—
pendances qui seront d’autant plus nombreuses que des résultats satisfaisants seront obtenus
par chacune des approches. Une récente J oumée d’Etude de l’ATALA a d’ailleurs permis de
poser trés frontalement la question désormais centrale de l’articulation des traitements sur cor-
pus. Or, si l’articulation des traitements rend indispensable une réﬂexion sur leur modularité,
elle conduit également a réinterroger l’ensemble de leur processus d’élaboration, de la prise en

517

518

WIDLOCHER Antoine, BILHAUT Frederik

charge du corpus, jusqu’a l’evaluati0n des resulats, en imposant que soient repensees les no-
tions méme d’0bservati0n et d’experimentati0n, a travers, en particulier, une reﬂexion sur les
cycles devaluation/validation puis d’ajustement des methodes d’analyse.

Enﬁn, de nouvelles perspectives en TAL conﬁrment ces nouveaux besoins. Si nous considerons
l’interet recent accorde a l’analyse automatique de l’organisation discursive, par exemple en
termes thématiques (Bilhaut, 2004) ou rhétoriques (Widlocher, 2004), il apparait clairement
que ces investigations sont rendues possibles par la preexistence de resultats satisfaisants aux
niveaux de granularite inferieurs, en matiere d’analyse morpho—syntaxique et semantique, aux
niveaux lexicaux et syntagmatiques. Ces travaux se trouvent consubstantiellement lies a des
strategies d’empilement de traitements successifs permettant Yenrichissement incremental des
vues sur le corpus et l’abstraction progressive des formes de surface par l’utilisation des analyses
prealables. A travers la presentation de LinguaStream1, nous envisageons ici differents elements
methodologiques et techniques pouvant permettre d’as sumer ces nouvelles orientations.

2 La plate-forme LinguaStream

LinguaStream (Bilhaut & Widlocher, 2005) a pour principale ambition de faciliter la realisa-
tion d’experiences sur corpus non triviales en TAL, ainsi que le cycle d’evaluation/ajustement
qui en decoule. Sans outil adapte, le coﬁt de developpement induit par chaque nouvelle ex-
perience devient en effet un frein considerable a l’approche experimentale. Pour repondre a
ce probleme, LinguaStream facilite la mise en oeuvre de procedes complexes tout en reque-
rant des competences informatiques minimales. Plate—forme generique fondee sur le principe
d’enrichissement incremental des documents electroniques, elle facilite la conception et l’eva—
luation de chaines de traitements complexes, par assemblage visuel de modules d’analyse de
types et de niveaux varies : morphologique, syntaxique, semantique, discursif... Chaque palier
de la chaine de traitement se traduit par la decouverte et le marquage de nouvelles informations,
sur lesquelles pourront s’appuyer les analyseurs subsequents.

Un environnement de developpement integre permet de construire visuellement ces chaines de
traitement, a partir d’une « palette >> de composants (une cinquantaine est integree en standard)
facilement extensible grace une AP1 Java, un systeme de macro—composants, et des templates.
Certains sont speciﬁquement dedies au TAL, et d’autres permettent de resoudre differents pro-
blemes lies a la gestion des documents electroniques (traitements XML en particulier). D’autres
peuvent étre utilises pour effectuer des calculs sur les annotations produites par les analyseurs,
ou encore generer des diagrammes. Chacun dispose d’un ou plusieurs points d’entree et/ou de
sortie que l’on relie pour obtenir la chaine voulue, celle—ci etant representee par un graphe ou les
divers composants apparaissent sous forme de « boites >> reliees entre elles. Chaque composant
propose un nombre variable de parametres permettant d’adapter leur comportement. Les mar-
quages produits sur un meme document sont organises en couches independantes, supportant
enchas sements et chevauchements. La plate—forme se base systematiquement sur les standards
et outils XML, et peut traiter tout ﬁchier de ce type en preservant sa structure orginelle. A l’exe—
cution, elle se charge de l’ordonnancement des sous—taches, et differents outils permettent in
ﬁne de visualiser les documents analyses et leurs annotations.

Principes fondamentaux

En premier lieu, la plate—forme recourt systematiquement a des representations déclaratives
pour speciﬁer les differents traitements, ainsi que leur enchainement sous forme de graphe.
Les differents formalismes disponibles permettent ainsi de transcrire directement l’expertise

1On trouvera une presentation complete de la p1ate—forme a1’adresse http : / / www . l inguastre am . org.

La plate—forme LinguaStream

linguistique a mettre en oeuvre, l’appareil procedural qui en resulte etant pris en charge par
la plate—forme. Les regles donnees ont donc une valeur tant descriptive, en tant que repre-
sentations formelles d’un phenomene linguistique, que prescriptive, en tant qu’instructions de
traitement foumies a un processus informatique.

De plus, la plate—forme exploite la complémentarité des modeles d’analyse, plutot que de pri-
vilegier un hypothetique modele « omnipotent » capable d’exprimer efﬁcacement tout type de
contrainte. Nous faisons en effet l’hypothese qu’un analyseur complexe doit adopter successi-
vement plusieurs regards sur le meme materiau linguistique, auxquels repondront des forma-
lismes distincts. On pourra combiner, au sein d’un meme traitement, des expressions regulieres
au niveau morphologique, une grammaire locale au niveau syntagmatique, un transducteur au
niveau phrastique et une grammaire DSDL (cf. infra) au niveau discursif. L’interoperabilite des
differents modeles d’analyse proposes est garantie par l’usage d’une représentation uniﬁée des
marquages et des annotations. Ces dernieres sont uniformement representees par des structures
de traits, modele communement utilise en TAL et en linguistique, et permettant de represen-
ter des annotations riches et structurees. Tout composant d’analyse pourra produire son propre
marquage en s’appuyant sur les analyses précedentes : les formalismes proposes permettent de
speciﬁer des contraintes sur les annotations existantes par uniﬁcation. La plate—forme favorise
ainsi l’abstraction progressive des formes de surface. Chaque palier d’ analyse pouvant acce-
der simultanement aux annotations produites par tous les paliers antérieurs, les analyseurs de
plus haut niveau sont generalement conduits a s’abstraire progressivement du matériau textuel
pour ne plus reposer que sur des representations symboliques anterieurement calculees.

Un autre aspect important conceme la variabilité du grain d’analyse au cours du traitement.
De nombreux modeles d’analyse imposent la deﬁnition d’un grain d’analyse minimal, dit « je-
ton >> ou token. C’est par exemple le cas de toute grammaire ou transducteur : ces formalismes
supposent l’existence d’une unite textuelle (comme le caractere ou le mot) a laquelle s’ap—
pliquent les patrons. Quand la deﬁnition de ce grain minimal est necessaire au fonctionnement
d’un composant, la plate—forme permet de speciﬁer localement le ou les types d’unites a consi-
derer comme jetons. Toute unite prealablement délimitee peut jouer ce role : il pourra s’agir
du decoupage habituel en mots, mais aussi de toute autre unite ayant éte prealablement mar-
quee : syntagmes, phrases, cadres du discours, etc. Le grain minimal peut donc étre different
pour chaque palier de l’analyse, ce qui augmente considerablement la portee des differents mo-
deles d’analyses utilisables dans la plate—forme. D’autre part, chaque module d’analyse speciﬁe
les marquages ante’n'eurs auxquels il souhaite faire reference, pouvant ainsi ne tenir compte
que des marquages qu’il estime pertinents, et donc s’affranchir partiellement de la linearite du
texte. La combinaison de ces fonctionnalites permet d’adopter un point de vue sur le document
speciﬁque a chaque etape d’une chaine de traitement.

La modularité des chaines de traitements favorise quant a elle la réutilisabilité des compo-
sants dans des contextes differents : un module d’analyse développe au sein d’une premiere
chaine pourra étre reutilise dans d’autres chaines. De fagon similaire, toute chaine pourra étre
reutilisee en tant que constituant d’une chaine de plus haut niveau, sous forme de « macro-
composant >>. Reciproquement, pour une chaine donnee, on pourra substituer a un composant
tout autre composant fonctionnellement équivalent. Pour une sous—tache donnee, un prototype
rudimentaire pourra étre remplace in ﬁne par un equivalent pleinement operationnel. Ceci rend
possible la mise en comparaison des traitements, en soumettant ces derniers a des contextes
rigoureusement identiques, condition sine qua non d’une comparaison pertinente.

Modeles d’analyse

Nous avons évoque plus haut quelques—uns des composants susceptibles de prendre part a une
chaine de traitement. Parmi ceux speciﬁquement dedies au TAL, on peut distinguer deux fa-
milles. La premiere regroupe les analyseurs « préts a l’emploi », dedies a une tache precise.

519

520

WIDLOCHER Antoine, BILHAUT Frederik

Il s’agira par exemple de l’etiquetage morpho—syntaxique, une interface avec TreeTagger etant
integree par defaut. Ces composants sont parametrables, mais il n’est pas possible de modiﬁer
fondamentalement leur fonctionnement. D’autres au contraire proposent un modele d’analyse,
c’est—a—dire un formalisme de representation de contraintes linguistiques, eventuellement as so-
cie a un modele operatoire, par lequel l’utilisateur peut speciﬁer integralement le traitement a
operer. Ils permettent d’exprimer des contraintes tant sur les formes de surface que sur les an-
notations inserees par les analyseurs precedents. Toutes les annotations sont representees sous
forme de structures de traits, et les contraintes sont systematiquement speciﬁees par uniﬁcation
sur ces structures. Quelques—uns des systemes proposes sont :

— Un systeme appele EDCG (pour Extended—DCG), permettant de decrire des grammaires lo-
cales d’uniﬁcati0n en se basant sur la syntaxe DCG (Deﬁnite Clause Grammars) de Prolog.
Une telle grammaire peut étre decrite dans le plus pur style declaratif, bien que les speciﬁcites
du langage lo gique restent accessibles aux utilisateurs experimentes.

— Un systeme, nomme MRE (pour Macro—Regular—Expressi0ns), permettant de decrire des pa-
trons par transducteurs, s’appliquant aussi bien aux formes de surface qu’aux annotations
prealablement calculees. Sa syntaxe est sirnilaire a celle des expressions regulieres commu-
nement utilisees en TAL et en linguistique sur corpus. Mais a la difference de ces dernieres,
ce formalisme ne s’applique pas speciﬁquement aux caracteres ni aux mots, et peut porter sur
toute unite textuelle prealablement analysee.

— Un formalisme d’expression de contraintes au niveau discursif. En cours d’elaboration,
DSDL (Discourse Structure Description Language), que nous decrirons plus loin, permet
l’exploration des organisations discursives par l’expression et la satisfaction de contraintes,
pouvant etre non sequentielles exprimees a l’aide d’un ensemble de fonctions discursives pri-
mitives (presence/absence, coherence semantique...), et pouvant porter en particulier sur les
annotations produites en amont et sur des relations entre ces demieres.

— Un systeme d’annotation a partir de lexiques sémantiques, un systeme de tokenisation base
sur des expressions regulieres (au niveau caractere), un systeme permettant de delimiter des
objets linguistiques en se basant sur le balisage XML du document, etc.

3 Analyse du discours

Voyons quels avantages l’analyse automatique du discours peut tirer des principes proposes.
Un premier apport signiﬁcatif resulte de l’approche par enrichissement incremental et par abs-
traction progressive des formes de surface. S’il est naturel d’operer au niveau de ces dernieres
pour une analyse par exemple morphologique ou syntaxique, il Va sans dire que l’analyse dis-
cursive ne peut s’accomoder de la diversite combinatoire apparaissant a ce niveau, et qu’un
ﬁltrage s’impose. En plus de la possibilite d’operer la pure et simple occultation d’elements peu
pertinents pour tel ou tel besoin interpretatif, la plate—forme permet d’operer ladite abstraction
de deux manieres complementaires. En premier lieu, l’unicite du modele de marquage et d’an—
notation donne a chaque etape d’analyse l’acces aux representations symboliques produites en
amont, et permet ainsi de ramener la diversite combinatoire de surface a celle des Valeurs in-
terpretees, generalement moins nombreuses. En second lieu, le principe de Variabilite du grain
d’ analyse deja evoque permet d’exploiter au niveau discursif des modeles d’analyse habituel—
lement dedies a des niveaux de granularite inferieurs. Par exemple, des regles EDCG pourront
aussi bien decrire des patrons syntagmatiques qu’une grammaire textuelle, selon le grain choisi.

Par ailleurs, la plate—forme propose des modeles d’analyse speciﬁquement adaptes au niveau
discursif. Le langage DSDL en particulier, s’ecarte des paradigmes generalement adoptes par
les autres formalismes (y compris MRE ou EDCG), qui reposent fondamentalement sur des prin-
cipes de linearite (on tient compte de tous les elements successifs) et de sequentialite (un ordre
est impose), principes souvent inadaptes au niveau discursif. En permettant l’expression de

La plate—forme LinguaStream

contraintes non séquentielles et non linéaires, le formalisme DSDL autorise l’expression et la
detection de motifs pouvant porter sur des elements distants dans le texte, sans faire d’hypothese
sur leur ordre, ce qui s’aVere particulierement adapte a l’analyse du discours.

Aﬁn de donner une idee plus concrete des principes methodologiques presentes, envisageons a
present une conﬁguration linguistique particuliere, assez representative des problemes poses par
l’analyse discursive, en abordant le probleme de l’encadrement du discours (Charolles, 1997),
et plus particulierement de la detection automatique des cadres temporels. Rappelons que cette
theorie qualiﬁe ainsi des segments textuels homogenes du point de Vue d’un critere d’interpre—
tation ﬁxe dans une expression en position détachee en debut de phrase, dite introducteur de
cadre. L’ operationnalisation en TAL de ce modele psycho—linguistique impose la resolution de
deux problemes principaux : detection des introducteurs, puis evaluation de leur portée, c’est—
a—dire determination de la borne droite du cadre introduit. Bien que cette derniere tache soit
tres problematique dans la mesure ou les criteres formels de cloture des cadres sont difﬁciles a
etablir, un certain nombre d’indices ont toutefois pu étre degages dans le cas precis des cadres
temporels (Bilhaut er al., 2003), que nous evoquerons ci—apres.

Le probleme de la detection des introducteurs temporels se decline lui—méme en deux sous-
problemes : l’analyse des expressions temporelles, et celle des introducteurs s’appuyant sur
elles. Les principes de modularite evoques trouvent ici leur justiﬁcation, puisque nous souhai—
terons generalement traiter ces problemes independamment. L’ analyse semantique des expres-
sions temporelles fait l’objet d’une grammaire EDCG, exprimant des contraintes sur les resultats
d’une analyse morpho—syntaxique preliminaire, et associant aux expressions reconnues une re-
presentation de leur « sens » sous forme de structures de traits. Sur cette base, la detection
des introducteurs peut étre mise en place a l’aide de criteres essentiellement positionnels. Les
contraintes exprimees sont fondamentalement sequentielles : nous recherchons des zones de
texte Veriﬁant des motifs imposant la presence, dans un ordre ﬁxe, d’elements immediatement
successifs. Ces regles sont donc simplement exprimables a l’aide du formalisme MRE (outre
les expressions temporelles, nous exploitons ici le marquage des phrases et des connecteurs de
discours) :

{type : phrase, anchor :
<introducteur>

{type : connecteur}? {tag :
</introducteur> /sem {axe :

start}

pre} {type : temporel} /as $t
temps, valeur : $t} ","

Les contraintes sur les structures de traits produites en amont (ici en gras), ainsi que sur les
formes de surface (ici, la Virgule en ﬁn de motif) permettent de delimiter l’introducteur. Nous
recherchons les elements precedes d’un debut de phrase et composes, d’un eventuel connecteur
de discours, d’une preposition et d’une expression temporelle. Le reste de l’expression corres-
pond au marquage et a l’annotation produits en sortie. L’element reconnu aura le type << intro-
ducteur >> et sera associe a l’annotation semantique qui lui fait suite. Precisons que la Variable
$t permet de faire « remonter » l’information contenue dans la structure de traits associee a
l’expression temporelle, pour un usage ulterieur.

Pour la determination de la portee de l’introducteur, la méthode presentee dans (Bilhaut er al.,
2003) s’appuie sur des criteres enonciatifs tels que la cohesion des temps Verbaux, sur la struc-
turation en paragraphes, et sur des calculs semantiques de coherence entre l’introducteur et les
autres expressions temporelles. La nature de ces contraintes differe radicalement des prece-
dentes. D’une part, nous pouvons desormais nous abstraire de la linearite du texte : contraire—
ment at une approche par expressions regulieres, nous pouvons ici ignorer un certain nombre
d’elements du ﬂot textuel. D’autre part, s’il existe bien des contraintes interpretatives entre
l’introducteur et certains elements de la zone introduite, il n’est pas souhaitable de concevoir
ces contraintes comme imposant un ordre strict entre ces elements. Pour l’expression de telles
contraintes a la fois non linéaires et non séquentielles, nous disposons du formalisme DSDL

521

522

WIDLOCHER Antoine, BILHAUT Frederik

et pouvons formuler la « grammaire » ci—dessous. Nous recherchons une unite textuelle com-
posée de phrases completes, commencant par un element identiﬁé comme introducteur et ne
comportant pas d’autre élément de ce type, dont tous le Verbes sont au méme temps, et au sein
de laquelle les expressions temporelles portent sur une plage comprise dans l’interValle ﬁxé par
l’introducteur, en ne retenant que le plus long des candidats partageant un meme introducteur.

Rule {type : "cadre"} :
start({type : "introducteur"})
end({type : "phrase"})
homogeneity(comparator : portée)
not presence(pattern : {type 2 "intro"}, amount : 2)

size(mode : #LONGEST)

Comparator portée ({type : "verbe"} as $vl, {type : "verbe"} as $v2)
$vl/temps : $v2/temps

Comparator portée ({type : "intro"} as $1, {type : "tempo"} as $t)

($t/debut >: $1/debut) and ($t/fin <: $1/fin)

Il est ainsi possible, a l’aide des principes méthodologiques promus par la plate—forme, et en
nous appuyant sur la complémentarité des modeles d’analyse, de mettre en place un analyseur
de cadres temporels, certes encore imparfait, mais ne faisant usage que de formalismes pure-
ment déclaratifs propices a la capitalisation de l’expertise linguistique mise en oeuvre.

4 Conclusion

Initialement développée dans le cadre du projet GeoSem2, la plate—forme évolue maintenant
indépendamment. Elle est aujourd’hui utilisée dans le cadre d’un projet TCAN3, de différents
travaux de recherche en TAL, notamment en analyse sémantique du discours : organisation
thématique (Bilhaut, 2004), ou rhétorique (Widlocher, 2004). Le logiciel est également utilise a
des ﬁns pédagogiques au GREYC et a l’ERSS, eta été mis a la disposition de laboratoires tels que
LIUPPA ou LATTICE. La plate—forme reste en elle—méme indépendante des modeles d’analyse
utilises, pour peu qu’ils partagent le méme systeme de marquage et d’annotation, et il est donc
envisageable d’intégrer des modules exploitant d’autres modeles d’analyse.

Références

BILHAUT F. (2004). Analyse automatique de la structure thématique du discours pour la navigation
documentaire. In J0urne’e ATALA « M0de’liser et decrire l ’0rgam'sau'0/1 discursive 61 l ’heure du document
numerique ».

BILHAUT F., HO-DAC M., BORILLO A., CHARNOIS T., ENJALBERT P., DRAOULEC A. L., MATHET
Y., MIGUET H., PERY-WOODLEY M.—P. & SARDA L. (2003). Indexation discursive pour la navi-
gation intradocumentaire : cadres temporels et spatiaux dans l’inforrnation géographique. In Actes de
Traiteme/1tAut0matique du Lcmgage Naturel (TALN), Batz—sur—Mer, France.

BILHAUT F. & WIDLOCHER A. (2005). La plate—forrne LinguaStream. In J0ume’e ATALA « Architec-
tures logicielles pour articuler les traitements sur corpus ».

CHAROLLES M. (1997). L’encadrement du discours : Univers, champs, domaines et espaces. Cahier de
Recherche Linguistique no 6. Université de Nancy 2.

WIDLOCHER A. (2004). Analyse macro—sémantique : vers une analyse rhétorique du discours. In Actes
de RECITAL 2004, p. 183-188, Fes, Maroc.

2« Traitement sémantique de1’information géographique », programme CN RS « Société de1’informati0n ».
3« Intervalles temporels et applications a la linguistique textuelle », projet interdisciplinaire du CN RS.

