TALN 2005, Dourdan, 6-1 0 juin 2005

QRISTAL, systéme de Questions-Réponses

Dominique Laurent, Patrick Séguéla

Synapse Développement
33 rue Maynard,
31000 Toulouse, France
{dlaurent, p.seguela} @synapse-fr.com

Mots-clés 2 Systeme de questions-réponses, recherche d'information, évaluation des
systemes de questions-réponses, extraction de réponse, recherche sur le Web, QRISTAL.

Keywords: Question Answering system, information retrieval, Question Answering
evaluation, answer extraction, Web search strategy, QRISTAL.

Résumé

QRISTAL1 (Questions-Réponses Intégrant un Systeme de Traitement Automatique des
Langues) est un systeme de questions-réponses utilisant massivement le TAL, tant pour
l'indexation des documents que pour l'extraction des réponses. Ce systeme s’est récemment
classé premier lors de l’évaluation EQueR (Evalda, Technolanguez). Apres une description
fonctionnelle du systeme, ses performances sont détaillées. Ces résultats et des tests
complémentaires permettent de mieux situer l'apport des différents modules de TAL. Les
réactions des premiers utilisateurs incitent enf1n a une réﬂexion sur l'ergonomie et les
contraintes des systemes de questions-réponses, face aux outils de recherche sur le Web.

Abstract

QRISTAL1 is a question answering system which makes intensive use of natural language
processing techniques, for indexing documents as well as for extracting answers. This system
recently ranked first in the EQueR evaluation exercise (Evalda, Technolangue2). After a
functional description of the system, its results in the EQueR exercise are detailed. These
results and some additional tests allow to evaluate the contribution of each NLP component.
The feedback of the first QRISTAL users encourage further thoughts about the ergonomics
and the constraints of question answering systems, faced with the Web search engines.

1 développé avec le soutien de l'ANVAR et de la Commission Européenne (TRUST, IST-1999-56416), cf.
Amaral (2004), Laurent (2004).

2 http://www.technolangue.net

Dominique Laurent, Patrick Séguéla

1 Introduction

QRISTAL est un systeme de questions-réponses multilingue (francais, anglais, italien,
portugais, polonais) concu pour extraire des réponses de documents placés sur un disque dur,
ou pour extraire des réponses a partir du Web sur la base des pages ou passages retournés par
des moteurs Web classiques (Google, MSN, AOL, etc.)

Le systeme reconnait un grand nombre de formats (.html, .xml, .txt, .doc, .dbx, .hlp, .pdf, .ps,
etc.), autorisant ainsi l'indexation de l'immense majorité des textes mais également des e-mails
ou encore des ﬁchiers d'aide.

Commercialisé depuis novembre 2004 pour la plate-forme Windows, ce systeme est destiné
au grand public. Cependant, il est en cours d'intégration dans des applications professionnelles
de recherche d'information. Chacun peut le tester sur le site www.qristal.fr, le corpus de test
étant constitué du manuel de grammaire en ligne disponible sur http://www. synapse-
fr.com/grammaire/GTM_0.htm

Notre systeme est fondé sur la technologie Cordial d'analyse syntaxique et sémantique du
texte. 11 se caractérise par une utilisation intensive des outils de TAL, entre autres l'analyse
syntaxique, la désambigu'1'sation sémantique, la recherche des référents des anaphores, la
détection des métaphores, la prise en compte des converses, le repérage des entités nommées
ou encore l'analyse conceptuelle et thématique. L'utilisation professionnelle ou grand public a
nécessité une optimisation constante des différents modules aﬁn que le logiciel reste
extrémement rapide, l'utilisateur étant maintenant habitué a obtenir ce qui ressemble a des
réponses dans un délai tres court.

2 Architecture

L'architecture du systeme est modulaire. Le schéma général est décrit par la figure 1.
Module.
Linguistique
frangais

Moteur d’extraction de
blocs de texte
Moteur d’indexation
D.o=cum:ein't.s.

Figure 1. Architecture générale du systeme

QRISTAL, systéme de Questi0ns—Rép0nses

Ce systeme est donc un moteur complet d'indexation et d'extraction de réponses. Toutefois
l'indexation n'est effectuée que pour les documents "statiques", la recherche sur le Web se
faisant a l'aide d'un métamoteur, par conséquent sans indexation préalable des pages.

2.1 Indexation multicritéres
Au-dela du schéma general de fonctionnement du systeme, la ﬁgure 2 décrit le processus

d'analyse linguistique effectué lors de l'indexation, lors de l'analyse de la question et lors de
l'extraction de la réponse.

@  Réponse(s)

lndeation Traitemet Question Extraction reponse
Decoupage des blocs  :I:Correction"orthographe  I Extraction réponsqs)
,-=*-x |Correction'orthographeI I Analyse syntaxique I I Cohérence’ justification
Ontologie  Analyse syntaxique  I Analyse conceptuelle I I -I-ri des phrases
générale ' ' I ‘ _ "' , ’
\_H___J, “I Analyse conceptuelle I  ExtractIon'n1ots-cles I I Séiection phrasqs)
/_,__.,H\ IRéso|ution'anaphores  I Type de laquestion I r « ‘

‘  Ilndex entités nomméesk ITraduction si mu|ti|ingueI i. éte°ti°" des métaphmes

df;>rririIi1ée:=s ‘K index tétes dérivation ’ I Resolution des anaphores
*~———e/ Index des concepts I Recherche ans Index A Mots-cles du bloc
® I index des domaines I ISynonymes'-II- conversesI Type de  reponse

O,“l°‘1°*5ie’  Index mots-clés blocs I‘ SéIe°ti°" des bI°°5 I
g1_e_s_t'_y‘p.:es

I V .'.
.E'i'i-i»eSii§,—,'i-s:\! index des types de iI Ordonnancement blocs I
\“‘‘—'’J questions-réponses
I

II Extraction'cles blocs I
Figure 2. Processus d’analyse linguistique lors de l’indexation
Analyse conceptuelle
7 an
Correctioniorthographe

Analyse syntaxique
Les textes sont convertis en Unicode puis découpés en blocs de longueur ﬁxe, actuellement un
kilo-octet. Cette découpe perrnet de réduire la taille de l'index car seul le nombre
d'occurrences d'un lemme donné par bloc est sauvé dans l'index, ce nombre constituant par
ailleurs un indice précieux de la pertinence de chaque bloc lors de la recherche d'un lemme
donné dans l'index. En fait le mot "lemme" est ici fautif car sont indexées des tétes de
dérivation. Par exemple "symétriques", "asymétrie", "dissymétriques", "symétriseraient" ou
"symétrisable" seront indexés dans la méme entrée "symétrie", réduisant de fait encore la taille
de l'index sur disque.

Chacun des blocs de texte est analysé syntaxiquement et sémantiquement. A partir des
inforrnations issues de cette analyse, plusieurs index sont constitués :

0 index des tétes de dérivation (les tétes pouvant étre des sens de mots comme
"symétrie"),

0 index des noms propres (si ces noms propres figurent dans nos dictionnaires),

Dominique Laurent, Patrick Séguéla

0 index des expressions (connues de nos dictionnaires d'expressions d'environ 50 000
entrées, comme "frein moteur", "prendre l'air", "par inadVertance"...),

0 index des entités nomrnées (repérées dans le texte, comme "George W. Bush" ou
"Société Nationale des Chemins de fer Francais"),

0 index des concepts (sur deux niveaux de l'ontologie générale : 256 categories, comme
la Visibilité et 3 387 sous-catégories, comme l'éclairage ou la transparence),

0 index des domaines (186 domaines, comme l'aéronautique, l'agriculture, etc.),
0 index des types de questions-réponses (distance, Vitesse, deﬁnition, causalité...),

0 index des mots-clés du texte.

Le processus d'indexation est similaire pour chacune des langues, ce qui permet de disposer de
données indépendantes de la langue (numéros de concepts dans l'ontologie, numéro de
domaine, type de question-réponse) qui fournissent des bases intéressantes pour retrouver
dans une langue des réponses a des questions posées dans une autre langue.

En francais, le taux de désambigu'1'sation grammaticale correcte (distinction nom-Verbe-
adjectif-adverbe) est supérieur a 99%, 1e taux de désambigu'1'sation sémantique est d'environ
90% pour 9 000 mots polysémiques et environ 30 000 sens pour ces mots (nombre de sens
nettement inférieur a celui du Larousse par exemple, les dictionnaires d'expressions couvrant
déja un grand nombre de sens idiomatiques). La Vitesse d'indexation Varie entre 200 et 400
Mo par heure avec un Pentium 3 GHz, selon la taille et le nombre des fichiers a indexer.

L'indexation des types de questions est sans doute l'un des aspects les plus originaux de notre
systeme. Lors de l'analyse des blocs a indexer, les réponses éventuelles sont repérées, par
exemple un nom de fonction pour une personne ("boulanger", "ministre", "directeur de
cabinet"...) une date de naissance ("né le 28 avril 1958"), un lien de causalité ("dﬁ a
l'accumulation de neige", "en raison du gel"...) ou de conséquence ("entrainant de graves
perturbations", "facilitant la gestion du trafic"...), et le bloc est alors indexé comme pouvant
foumir une réponse du type repéré.

La typologie comprend actuellement 86 types, dont des types factuels (dimension, surface,
poids, Vitesse, pourcentage, température, prix, nombre d'habitants, nom d'oeuVre, etc.) mais
aussi de nombreux types non factuels (forrne, possession, jugement, but, causalité, opinion,
comparaison, classification, etc.). Lors de l'éValuation EQueR (Voir §3), 492 questions sur 500
ont été classées selon cette typologie avec seulement 6 erreurs (exemple d'erreur, sur la
question 391, "Quels sont les cinq nouveaux membres non-permanents du Conseil de Sécurité
de l'ONU ?", le type repéré est "noms de personnes" au lieu de "noms de pays").

L'index des mots-clés du texte est également une originalité de notre systeme. Il est rendu
nécessaire par la découpe des textes en blocs. Du fait de cette découpe, des blocs spécifiques
peuvent ne pas contenir les sujets du texte bien que les phrases de ces blocs portent sur ces
sujets. L'index des mots-clés permet d'aj outer une plus-Value aux textes portant a priori sur le
sujet recherché, lequel sujet peut étre une notion, une personne, un événement, etc.

2.2 Extraction de réponse

Lorsque l'utilisateur pose sa question, celle-ci est analysée, syntaxiquement et sémantique-
ment. Le type de question-réponse est déterrniné. Relevons cependant ici que l'analyse

QRISTAL, systéme de Questions-Réponses

sémantique de la question est plus complete que l'analyse effectuée sur les textes car l'énoncé
est généralement court. De ce fait, la désambigu'1'sation sémantique est plus incertaine, par
manque de contexte. Si l'utilisateur a la possibilité de "forcer" tel ou tel sens de mot, cette
option reste peu utilisée. Aussi calculons-nous un poids pour chaque sens possible et ce poids
entre en compte dans la recherche dans l'index (exemple : sens 1 a 20%, sens 2 a 65%, sens 3
a 5% de probabilité). Ainsi les erreurs éventuelles de désambigu'1'sation sémantique sont
tempérées par ces coefficients qui perrnettent de "remonter" des blocs correspondant a d'autres
sens mais ayant d'autres caractéristiques recherchées, par exemple des réponses potentielles au
type de la question, un nom propre identique, un méme theme, etc.

Apres analyse de la question, si le corpus Visé est sur disque, les différents index sont
consultés et les blocs les mieux placés pour ces index sont réanalysés. Sur le Web, des
requétes sont générées Vers les moteurs Web classiques. Dans les pages de résultats retoumées
par les moteurs, les bribes ("snippets") ou les pages indiquées par les liens (pour les questions
non factuelles) sont analysées.

Comme indiqué ﬁgure 2, l'analyse des blocs sélectionnés est similaire a l'analyse effectuée
lors de l'indexation ou lors de l'analyse de la question avec, par exemple, une
désambigu'1'sation sémantique des mots polysémiques. Toutefois cette analyse se double d'un
calcul de poids pour chacune des phrases, le poids étant fonction du nombre de mots et entités
nommées trouvés dans cette phrase, de la présence ou non du type de réponse correspondant a
la question, de l'accord entre les themes et domaines. C'est ce poids qui permettra ensuite le
classement des réponses.

Apres analyse, les phrases ou paragraphes semblant répondre a la question sont triés et une
analyse complémentaire extrait les entités nommées ou les groupes de mots (parfois des
propositions ou des listes) qui correspondent le mieux aux réponses. Cette extraction se fait en
fonction des caractéristiques des entités nommées ou sur la base de nature syntaxique des
groupes ou propositions.

Pour une question sur un corpus ferrné, le temps de réponse est d'enViron 3 secondes avec un
Pentium 3 GHz. Sur le Web, les premieres réponses sont généralement foumies au bout de 2
secondes, un afﬁnage progressif ayant lieu et pouvant durer jusqu'a une quinzaine de
secondes, selon le paramétrage utilisateur (nombre de moteurs, nombre de pages analysées,
etc.)

3 Evaluation EQueR

QRISTAL a été évalué dans le cadre d'EQueR, campagne d’éValuation des systemes de
Questions-Réponses du projet EVALDA (voir GRAU 2004). Le projet EVALDA et, plus
généralement, les projets Technolangue, ont été initiés par les Ministeres francais de
l’Industrie, de la Recherche et de la Culture.

La campagne EQueR a été organisée par l’ELDA (Evaluations and Language resources
Distribution Agency, www.elda.org) entre janvier 2003 et décembre 2004. Tres similaire dans
ses principes aux campagnes TREC-QA (USA) ou NTCIR (Japon), elle a pris la forme de
deux tests distincts :

Dominique Laurent, Patrick Séguéla

0 500 questions générales, principalement factuelles, sur un corpus journalistique et
administratif de 1,5 Go.

0 200 questions, souvent non factuelles, sur un corpus médical d’articles scientiﬁques
et de pages Web d’enViron 50 Mo.

Les 500 questions générales se décomposaient en :

0 407 questions factuelles simples (ex: Comment s'appelle leﬁls de Juliette Binoche .7)

0 31 questions dont la réponse est une liste (ex.: Quels sont les trois pays qui bordent
la Bosnie-Herzégovine .7)

0 32 questions dont la réponse est une définition (ex.: Qu ’est-ce que la NSA ?)

0 30 questions binaires, a réponse oui ou non (ex.: La carte d’identité existe-t-elle au
Royaume-Uni .7)

La métrique utilisée pour noter les résultats était le MRR (Mean Reciprocal Rank, voir
http://trec.nist.goV/data/qa.html), c’est-a-dire 1 pour une réponse exacte en premiere position,
1/2 pour une réponse exacte en seconde position, 1/3 pour une réponse exacte en troisieme
position, etc. Seules 5 réponses étaient prises en compte, sauf pour les questions binaires ou
une seule réponse justifiée était acceptée. Pour les questions dont la réponse était une liste, la
métrique utilisée était le NLAP (Non Interpolated Average Precision, voir MONZ, 2003).

Chaque participant pouvait foumir deux fichiers de résultats avec deux grilles d'éValuation : le
mode "passages" dans lequel, sur un passage d'au maximum 200 caracteres, la réponse était
jugée juste si elle était contenue dans ce passage; le mode "réponses exactes" ou il fallait
donner la réponse exacte et uniquement celle-ci.

Notre systeme de Questions-Réponses évalué pour EQUER était une Version béta de
QRISTAL, et Synapse Développement participait la a sa premiere campagne d’éValuation de

moteurs de questions-réponses.

Sur la tache générale (500 questions), les résultats des sept participants ont été les suivants :

Résultats de la tiche générale (500 questions)

33 EIF'assages

IF:'éponses exactes

:   :kk

1 2 3 4 5 QFIISTAL 7
Participants

Figure 3. Résultats de la tache générale

QRISTAL, systéme de Questi0ns—Rép0nses

Sur la tache specialisee (200 questions sur un corpus medical), les resultats des cinq
participants ont ete les suivants :

Résultats de la tache spécialisée (200 questions)

o,9— — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — ——
O,8— — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — ——
0,7 — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — ——

MRR

|:| Passages
I Réponses exactes
1 2 3 4 QRISTAL
Participants

Figure 4. Resultats de la tache specialisee

Ces deux graphiques mettent en evidence 1e bon niveau de performance de QRISTAL, qui
obtient les meilleurs resultats parmi les sept systemes en competition, sur les deux taches. Son
niveau de performance assez Voisin de celui du meilleur moteur americain de TREC (MRR de
0,58 contre 0,68, voir Harabagiu, 2002 et Voorhees, 2003) ou du meilleur moteur japonais de
NTCIR (MRR de 0,58 contre 0,61) sur la tache generale.

Si 1'on considere les differentes categories de questions, QRISTAL presente des resultats
homogenes selon les categories, contrairement aux autres participants (figure 5).

Résultats par type de question
(téche générale : réponses exactes)

I:i Factueiles

I Definitions

I] Elinainas (uuifnnn)
El Listes
1 2 3 4 5 QRISTAL 7

Figure 5. Resultats par type de question

Dominique Laurent, Patrick Séguéla

Ces résultats correspondent au meilleur run foumi, celui correspondant a une passe complete
d'indexation et d'extraction de réponse dans QRISTAL. Nous avions fourni un autre fichier de
résultats dans lequel les textes analysés pour extraction de réponse étaient les textes retoumés
par un indexeur classique de recherche d'inforrnations. Dans ce second fichier de résultats, les
MRR du moteur de Synapse étaient de 0,64 (contre 0,70) pour les passages et de 0,48 (contre
0,58) pour les réponses exactes. Cette différence, significative statistiquement, indique que
notre processus d'indexation multicriteres est payant, car il permet de remonter de meilleurs
textes a de meilleures positions qu'un moteur de recherche d'information classique.

Nous avons par ailleurs effectué un autre test afin d'éValuer l'impact de notre typologie de
questions-réponses. En forcant a "inconnu" le type de toutes les questions analysées et en ne
prenant pas en compte l'index des types de questions-réponses, nous avons alors obtenu un
MRR de 0,46 contre 0,70 pour les passages, démontrant ainsi la pertinence de ce type de
variable d'indexation et d'analyse, d'ailleurs déja largement utilisé en questions-réponses, en
particulier par les participants de TREC-QA.

4 Utilisation de QRISTAL

Les réactions des premiers utilisateurs de QRISTAL (quelques centaines apres deux mois de
commercialisation) permettent de tirer nombre d'enseignements sur la perception des systemes
de questions-réponses, les attentes et les illusions tant sur ces outils que sur les moteurs
classiques de recherche sur le Web.

En matiere de recherche sur disque dur, les réactions sont assez rares et tres souvent positives.
La Vitesse de recherche est bonne et le fait que le moteur trouve des dérivés ou des synonymes
des mots de la question améliore nettement le taux de documents retrouvés. Ainsi, sur un
corpus de dépéches d'un mois de l'AFP, les moteurs classiques se révelent incapables de
retrouver le nom du président du Pérou sur l'interrogation "président Pérou" alors que
QRISTAL retrouve "Alejandro Toledo" dans "le chef de l'état péruvien, Alejandro Toledo"
par un double processus de synonymie et de dérivation.

Compte tenu du tres grand nombre de pages indexées sur le Web, ce type d'absence de
réponse ne se pose qu'aVec de petits corpus, pas sur le Web, sauf pour des questions moins
générales, ou peu de pages contiennent la réponse. Dans ces cas-la, l'utilisateur conclura en
général qu"'il n'y a pas de réponses sur le Web", ne percevant pas que ce silence résulte
souvent de l'absence de traitement linguistique des moteurs classiques !

En matiere de recherche sur le Web, les moteurs existants donnent le sentiment a l'utilisateur
qu'ils disposent de la réponse quasi instantanément. En fait, ces moteurs foumissent des bribes
de texte et des liens Vers des pages, en aucun cas la réponse exacte a la question posée. Il faut
au mieux lire quelques fragments, au pire ouvrir quelques pages, pour espérer obtenir une
réponse. Ce processus demande touj ours plusieurs secondes, d'autant que la découpe de bribes
par les moteurs associe parfois des données issues de phrases différentes (ainsi une demande
associant "surface" et un nom de pays donnera rarement la superficie du pays mais plut6t des
tailles d'appartements situés dans ce pays). Et ceci n'est Valable que pour des questions
factuelles ou portant sur des personnes, les questions du type "pourquoi" ou "comment" étant
habituellement hors de portée des moteurs de recherche du Web.

QRISTAL, systéme de Questi0ns—Rép0nses

Utiliser les moteurs de recherche sur le Web suppose par ailleurs la maitrise de la syntaxe de
ces moteurs (rarement identique). Or cette maitrise est peu commune. Certes, la plupart des
utilisateurs de Google savent qu'il Vaut mieux ne saisir que quelques mots, si possible des
noms, mais peu connaissent l'usage des guillemets. Pour ces tres nombreux utilisateurs, la
saisie de questions en langage naturel est un atout de poids.

Reste que de nombreux traitements pouvant permettre d'améliorer la qualité des résultats
finaux sont inenvisageables, tout simplement parce que l'utilisateur ne supporte pas d'attendre
une réponse plus de trois a quatre secondes. Ainsi nous avions implémenté un dispositif de
validation de la réponse en allant interroger a nouveau les moteurs avec les mots de la
question et les mots de chacune des différentes réponses possibles (Magnini, 2002). Ce
dispositif perrnettait d'obtenir une amélioration nette : le nombre de bonnes réponses foumies
en premiere position passait de 47% a 58%. Mais le processus de Validation demandait six a
dix secondes supplémentaires eta donc dﬁ étre désactivé.

Améliorer un systeme de questions-réponses suppose donc une gestion extrémement serrée du
temps machine requis pour chacun des traitements. De sorte qu'il faut choisir avant tout les
traitements offrant le meilleur rapport amélioration des résultats/temps machine utilisé.

5 Conclusion

QRISTAL est le premier moteur de questions-réponses commercialisé, aupres du grand public
comme des professionnels. Ses résultats lors de l'éValuation EQUER montrent que l'usage
intensif de technologies TAL pour l'analyse de la question et des textes indexés, ainsi que
pour l'extraction de la réponse, donne de bons résultats, puisque le systeme se classe premier
parmi les sept systemes évalués.

Ces résultats, méme s'ils sont du niveau des meilleurs prototypes intemationaux, peuvent
toutefois étre encore considérés comme insuffisants, particulierement lors de recherches sur le
Web ou l'absence d'indexation, l'utilisation d'un métamoteur (donc des résultats renvoyés par
les moteurs) et des impératifs de rapidité, rendent plus incertaine l'extraction de réponses
correctes dans de nombreux cas.

Méme s'il parait tres Vraisemblable que, dans quelques années, les moteurs booléens actuels
seront remplacés par des moteurs en langage naturel, démontrer les avantages de ce type
d'outil et renverser quelques illusions sur les moteurs de recherche actuels demandera du
temps, ne serait-ce que parce que les prescripteurs sont souvent des experts en recherche
booléenne !

Remerciements

Les auteurs remercient Vivement Bruno Wieckowski et l'ensemble des ingénieurs et linguistes
ayant participé au développement de QRISTAL

Dominique Laurent, Patrick Séguéla

Références

AMARAL C., LAURENT D., MARTINS A., MENDES A., PINTO C. (2004), Design &
Implementation of a Semantic Search Engine for Portuguese, Proceedings of the Fourth
Conference on Language Resources and Evaluation.

CLARKE C. L. A., CORMACK G. V., LYNAM T. R. (2001), Exploiting Redundancy in Question
Answering, Proceedings of 24th Annual International ACM SIGIR Conference (SIGIR 2001),
p. 358-365.

GRAU B.. (2004), L'évaluation des systemes de question-réponse, Evaluation des syste‘mes de
traitement de l 'information, TSTI, p. 77-98, éd. Lavoisier.

HARABAGIU S., MOLDOVAN D., CLARK C., BOWDEN M., WILLIAMS J., BENSLEY J. (2002),
Answer Mining by Combining Extraction Techniques with Abductive Reasoning,
Proceedings of The Twelfth Text Retrieval Conference (TREC 2003).

LAURENT D., VARONE M., AMARAL C., FUGLEWICZ P. (2004), Multilingual Semantic and
Cognitive Search Engine for Text Retrieval Using Semantic Technologies, First International
Workshop on Prooﬁng Tools and Language Technologies, Patras, Gréce.

MAGNINI B., NEGRI M., PREVETE R., TANEV H. (2002), Is It the Right Answer? Exploiting
Web Redundancy for Answer Validation, Proceedings of the 40th Annual Meeting of the
ACL, p. 425-432

MONZ C. (2003), From Document Retrieval to Question Answering, ILLC Dissertation
Series 2003-4, HLC, Amsterdam.

VOORHEES E. M.. (2003), Overview of the TREC 2003 Question Answering Track, NIST,
54-68 (http://trec.nist.gov/pubs/trec12/tl2 proceedings.html).
