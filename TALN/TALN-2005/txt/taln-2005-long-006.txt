TALN 2005, Dourdan, 6-I0juz'n 2005

QRISTAL, systéme de Questions-Réponses

Dominique Laurent, Patrick Séguéla

Synapse Développement
33 rue Maynard,
31000 Toulouse, France

{dlaurent, p.seguela} @synapse-fr.com

Mots-clés 2 Systéme de questions-réponses, recherche d'information, évaluation des
systémes de questions-réponses, extraction de réponse, recherche sur le Web, QRISTAL.

Keywords: Question Answering system, information retrieval, Question Answering
evaluation, answer extraction, Web search strategy, QRISTAL.

Résumé

QRISTAL1 (Questions-Réponses Intégrant un Systéme de Traitement Automatique des
Langues) est un systéme de questions-réponses utilisant massivement le TAL, tant pour
l'indexation des documents que pour l'extraction des réponses. Ce systéme s’est récemment
classé premier lors de l’évaluation EQueR (Evalda, Technolanguez). Aprés une description
fonctionnelle du systéme, ses performances sont détaillées. Ces résultats et des tests
complémentaires permettent de mieux situer l'apport des différents modules de TAL. Les
réactions des premiers utilisateurs incitent enﬁn a une réﬂexion sur l'ergonomie et les
contraintes des systémes de questions-réponses, face aux outils de recherche sur le Web.

Abstract

QRISTAL1 is a question answering system which makes intensive use of natural language
processing techniques, for indexing documents as well as for extracting answers. This system
recently ranked ﬁrst in the EQueR evaluation exercise (Evalda, Technolanguez). After a
ﬁmctional description of the system, its results in the EQueR exercise are detailed. These
results and some additional tests allow to evaluate the contribution of each NLP component.
The feedback of the ﬁrst QRISTAL users encourage ﬁirther thoughts about the ergonomics
and the constraints of question answering systems, faced with the Web search engines.

1 développé avec le soutien de 1'ANVAR et de la Commission Européenne (TRUST, IST-1999-56416), cf.
Amaral (2004), Laurent (2004).

2 http://www.techno1angue.net

53

54

Dominique Laurent, Patrick Séguéla

1 Introduction

QRISTAL est un systeme de questions-réponses multilingue (ﬁancais, anglais, italien,
portugais, polonais) concu pour extraire des réponses de documents placés sur un disque dur,
ou pour extraire des réponses a partir du Web sur la base des pages ou passages retoumés par
des moteurs Web classiques (Google, MSN, AOL, etc.)

Le systeme reconnait un grand nombre de formats (.html, .xml, .txt, .doc, .dbx, .hlp, .pdf, .ps,
etc.), autorisant ainsi l'indexation de l'immense majorité des textes mais également des e-mails
ou encore des ﬁchiers d'aide.

Commercialisé depuis novembre 2004 pour la plate-forme Windows, ce systeme est destiné
au grand public. Cependant, il est en cours d'intégration dans des applications professionnelles
de recherche d'information. Chacun peut le tester sur le site www.qristal.fr, le corpus de test
étant constitué du manuel de grammaire en ligne disponible sur http://www.synapse-
fr.com/grammaire/GTM_O.htm

Notre systeme est fondé sur la technologie Cordial d'analyse syntaxique et sémantique du
texte. 11 se caractérise par une utilisation intensive des outils de TAL, entre autres l'analyse
syntaxique, la désambigu'1'sation sémantique, la recherche des référents des anaphores, la
détection des métaphores, la prise en compte des converses, le repérage des entités nommées
ou encore l'analyse conceptuelle et thématique. L'utilisation professionnelle ou grand public a
nécessité une optimisation constante des différents modules aﬁn que le logiciel reste
extrémement rapide, l'utilisateur étant maintenant habitué a obtenir ce qui ressemble a des
réponses dans un délai tres court.

2 Architecture

L'architecture du systeme est modulaire. Le schéma général est décrit par la ﬁgure 1.

'li}1_od._u'l'.’e;:
.:;L_.i_‘ri1§.LgI;II"°.'-*;Iif:1'i1"..I'.”.ie.‘.>:‘:

 
  
   

Moteur .d7’extraction de
-b:|ot‘:s deg texte

    

  

Moteur d’in_dexation.

   
 

?o"eIL:rm7e“:nfs:

Figure 1. Architecture générale du systeme

QRISTAL, systéme de Questions-Réponses

Ce systeme est donc un moteur complet d'indexation et d'extraction de reponses. Toutefois
l'indexation n'est effectuee que pour les documents "statiques", la recherche sur le Web se
faisant a l'aide d'un metamoteur, par consequent sans indexation prealable des pages.

2.1 Indexation multicritéres

Au-dela du schema general de fonctionnement du systeme, la ﬁgure 2 decrit le processus
d'analyse linguistique effectue lors de l'indexation, lors de l'analyse de la question et lors de

l'extraction de la reponse.
I Reponse(s) |

Extraction réponse A

Traitemet Question

 
    

    

Indexation

 

 

   
    
  
  

  

  

iJ‘i:Découpage des blocs   V_Correction"c'arthographe  1 Extraction réponsqs) '
,«e——-x iiicorrectlon orthographelii  Analyse syntaxlque  i Cohérence’ justification
oggﬁaélfaie  Analyse s‘yntaxIque   Analyse conceptuelle  i Tr; des phrases ’
\______F/  Analyse conceptuelle ]ii  Extraction'n1ots-clés  My Séiection phrasqs)
r_,.__H  Résolution anaphores   Type de la question   
1 ‘ Ir lil - . I" 7 i . - .
33$: iﬂlndex entités nomméesiii f||Traduction si multilingue  ‘;|___De_t°_°t'°” d°§m9taPh°T9$
formes ‘K’ index téte; dérivation ‘I ' ’ ’ Ll Résolution des anaphores .
d‘ ' ' ;_  |.— I -‘
‘E3  Index des concepts i Recherche dans Index ii Mots-clés du bloc l.
' -1 _. Q I» I - -'
$  index des domaines lg’ ‘_i“|$ynonymes '+ converses|;  Type de  réponse 
 Index mots-clés blocs    3é|ection'des blocs   Analyse conceptuelle 
 , index des types de ii .|FOrdonnancement blocs   Analyse syntaxlque |_.
V  questions-réponses  Extraction des blocs   Correction orthographe 
, in __ I . ~‘ |7  .

  
   

Figure 2. Processus d’analyse linguistique lors de l’indexation

Les textes sont convertis en Unicode puis decoupes en blocs de longueur ﬁxe, actuellement un
kilo-octet. Cette decoupe pennet de reduire la taille de l'index car seul le nombre
d'occurrences d'un lemme donne par bloc est sauve dans l'index, ce nombre constituant par
ailleurs un indice precieux de la pertinence de chaque bloc lors de la recherche d'un lemme
donne dans l'index. En fait le mot "lemme" est ici fautif car sont indexees des tetes de
derivation. Par exemple "symetriques", "asymetrie", "dissymetriques", "symetriseraient" ou
"symetrisable" seront indexes dans la meme entree "symetrie", reduisant de fait encore la taille
de l'index sur disque.

Chacun des blocs de texte est analyse syntaxiquement et semantiquement. A partir des
informations issues de cette analyse, plusieurs index sont constitues :

0 index des tetes de derivation (les tetes pouvant etre des sens de mots comme
"symetrie"),
0 index des noms propres (si ces noms propres ﬁgurent dans nos dictionnaires),

55

56

Dominique Laurent, Patrick Séguéla

0 index des expressions (connues de nos dictionnaires d'expressions d'environ 50 000
entrees, comme "frein moteur", "prendre l'air", "par inadvertance"...),

0 index des entites nommees (reperees dans le texte, comme "George W. Bush" ou
"Societe Nationale des Chemins de fer Francais"),

0 index des concepts (sur deux niveaux de l'ontologie generale : 256 categories, comme
la visibilite et 3 387 sous-categories, comme l'eclairage ou la transparence),

0 index des domaines (186 domaines, comme l'aeronautique, l'agriculture, etc.),
0 index des types de questions-reponses (distance, vitesse, deﬁnition, causalite...),
0 index des mots-cles du texte.

Le processus d'indexation est similaire pour chacune des langues, ce qui permet de disposer de
donnees independantes de la langue (numeros de concepts dans l'ontologie, numero de
domaine, type de question-reponse) qui fournissent des bases interessantes pour retrouver
dans une langue des reponses a des questions posees dans une autre langue.

En francais, le taux de desambigu'1'sation gramrnaticale correcte (distinction nom-verbe-
adjectif-adverbe) est superieur a 99%, 1e taux de desambigu'1'sation semantique est d'environ
90% pour 9 000 mots polysemiques et environ 30 000 sens pour ces mots (nombre de sens
nettement inferieur a celui du Larousse par exemple, les dictionnaires d'expressions couvrant
deja un grand nombre de sens idiomatiques). La vitesse d'indexation varie entre 200 et 400
Mo par heure avec un Pentium 3 GHz, selon la taille et le nombre des ﬁchiers a indexer.

L'indexation des types de questions est sans doute l'un des aspects les plus originaux de notre
systeme. Lors de l'analyse des blocs a indexer, les reponses eventuelles sont reperees, par
exemple un nom de fonction pour une personne ("boulanger", "ministre", "directeur de
cabinet"...) une date de naissance ("ne le 28 avril 1958"), un lien de causalite ("dﬁ a
l'accumulation de neige", "en raison du gel"...) ou de consequence ("entrainant de graves
perturbations", "facilitant la gestion du traﬁc"...), et le bloc est alors indexe comme pouvant
fournir une reponse du type repere.

La typologie comprend actuellement 86 types, dont des types factuels (dimension, surface,
poids, vitesse, pourcentage, temperature, prix, nombre d'habitants, nom d'oeuvre, etc.) mais
aussi de nombreux types non factuels (forme, possession, jugement, but, causalite, opinion,
comparaison, classiﬁcation, etc.). Lors de l'evaluation EQueR (voir §3), 492 questions sur 500
ont ete classees selon cette typologie avec seulement 6 erreurs (exemple d'erreur, sur la
question 391, "Quels sont les cinq nouveaux membres non-permanents du Conseil de Securite
de l'ONU ?", le type repere est "noms de personnes" au lieu de "noms de pays").

L'index des mots-cles du texte est egalement une originalite de notre systeme. Il est rendu
necessaire par la decoupe des textes en blocs. Du fait de cette decoupe, des blocs speciﬁques
peuvent ne pas contenir les sujets du texte bien que les phrases de ces blocs portent sur ces
sujets. L'index des mots-cles permet d'ajouter une plus-value aux textes portant a priori sur le
suj et recherche, lequel suj et peut etre une notion, une personne, un evenement, etc.

2.2 Extraction de réponse

Lorsque l'utilisateur pose sa question, celle-ci est analysee, syntaxiquement et semantique-
ment. Le type de question-reponse est determine. Relevons cependant ici que l'analyse

QRISTAL, systéme de Questions-Réponses

sémantique de la question est plus complete que l'analyse effectuée sur les textes car l'énoncé
est généralement court. De ce fait, la désambigu'1'sation sémantique est plus incertaine, par
manque de contexte. Si l'utilisateur a la possibilité de "forcer" tel ou tel sens de mot, cette
option reste peu utilisée. Aussi calculons-nous un poids pour chaque sens possible et ce poids
entre en compte dans la recherche dans l'index (exemple : sens 1 a 20%, sens 2 a 65%, sens 3
a 5% de probabilité). Ainsi les erreurs éventuelles de désambigu'1'sation sémantique sont
tempérées par ces coefﬁcients qui permettent de "remonter" des blocs correspondant a d'autres
sens mais ayant d'autres caractéristiques recherchées, par exemple des réponses potentielles au
type de la question, un nom propre identique, un meme theme, etc.

Apres analyse de la question, si le corpus visé est sur disque, les différents index sont
consultés et les blocs les mieux placés pour ces index sont réanalysés. Sur le Web, des
requétes sont générées vers les moteurs Web classiques. Dans les pages de résultats retoumées
par les moteurs, les bribes ("snippets") ou les pages indiquées par les liens (pour les questions
non factuelles) sont analysées.

Comme indiqué ﬁgure 2, l'analyse des blocs sélectionnés est similaire a l'analyse effectuée
lors de l'indexation ou lors de l'analyse de la question avec, par exemple, une
désambigu'1'sation sémantique des mots polysémiques. Toutefois cette analyse se double d'un
calcul de poids pour chacune des phrases, le poids étant fonction du nombre de mots et entités
nommées trouvés dans cette phrase, de la présence ou non du type de réponse correspondant a
la question, de l'accord entre les themes et domaines. C'est ce poids qui permettra ensuite le
classement des réponses.

Apres analyse, les phrases ou paragraphes semblant répondre a la question sont triés et une
analyse complémentaire extrait les entités nommées ou les groupes de mots (parfois des
propositions ou des listes) qui correspondent le mieux aux réponses. Cette extraction se fait en
fonction des caractéristiques des entités nommées ou sur la base de nature syntaxique des
groupes ou propositions.

Pour une question sur un corpus fenné, le temps de réponse est d'environ 3 secondes avec un
Pentium 3 GHz. Sur le Web, les premieres réponses sont généralement foumies au bout de 2
secondes, un afﬁnage progressif ayant lieu et pouvant durer jusqu'a une quinzaine de
secondes, selon le paramétrage utilisateur (nombre de moteurs, nombre de pages analysées,
etc.)

3 Evaluation EQueR

QRISTAL a été évalué dans le cadre d'EQueR, campagne d’évaluation des systemes de
Questions-Réponses du projet EVALDA (voir GRAU 2004). Le projet EVALDA et, plus
généralement, les projets Technolangue, ont été initiés par les Ministeres francais de
l’Industrie, de la Recherche et de la Culture.

La campagne EQueR a été organisée par l’ELDA (Evaluations and Language resources
Distribution Agency, wvvw.elda.org) entre janvier 2003 et décembre 2004. Tres similaire dans
ses principes aux campagnes TREC-QA (USA) ou NTCIR (Japon), elle a pris la forme de
deux tests distincts :

57

58

Dominique Laurent, Patrick Séguéla

0 500 questions générales, principalement factuelles, sur un corpus joumalistique et
administratif de 1,5 Go.

0 200 questions, souvent non factuelles, sur un corpus médical d’articles scientiﬁques
et de pages Web d’environ 50 Mo.

Les 500 questions générales se décomposaient en :

0 407 questions factuelles simples (ex: Comment s’appelle lefils de Juliette Binoche ?)

0 31 questions dont la réponse est une liste (ex.: Quels sont les trois pays qui bordent
la Bosnie-Herzégovine ?)

0 32 questions dont la réponse est une deﬁnition (ex.: Qu ’est-ce que la NSA ?)

0 30 questions binaires, a réponse oui ou non (ex.: La carte d’identité existe-t-elle au
Royaume- Uni ?)

La métrique utilisée pour noter les résultats était le MRR (Mean Reciprocal Rank, voir
http://trec.nist.gov/data/qa.html), c’est-a-dire 1 pour une réponse exacte en premiere position,
1/2 pour une réponse exacte en seconde position, 1/3 pour une réponse exacte en troisieme
position, etc. Seules 5 réponses étaient prises en compte, sauf pour les questions binaires ou
une seule réponse justiﬁée était acceptée. Pour les questions dont la réponse était une liste, la
métrique utilisée était le NIAP (Non Interpolated Average Precision, voir MONZ, 2003).

Chaque participant pouvait fournir deux ﬁchiers de résultats avec deux grilles d'évaluation : le
mode "passages" dans lequel, sur un passage d'au maximum 200 caracteres, la réponse était
jugée juste si elle était contenue dans ce passage; le mode "réponses exactes" ou il fallait
donner la réponse exacte et uniquement celle-ci.

Notre systeme de Questions-Réponses évalué pour EQUER était une version beta de
QRISTAL, et Synapse Développement participait la a sa premiere campagne d’évaluation de
moteurs de questions-réponses.

Sur la tache générale (500 questions), les résultats des sept participants ont été les suivants :

Résultats de la tiche générale (500 questions)

53 I:IF'assages

lF:'éponses exactes

 

 

.
1 2 3 4 5 QFIISTAL 7
Participants

Figure 3. Résultats de la tache générale

QRISTAL, systéme de Questions-Réponses

Sur la tache specialisee (200 questions sur un corpus medical), les resultats des cinq
participants ont ete les suivants :

Résultats de la tache spécialisée (200 questions)

0,9 — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — ——
0,8 — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — ——
0,7 — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — ——

|:| Passages
I Réponses exactes

MRR

 

3 4 QRISTAL

Participants

Figure 4. Resultats de la tache specialisee

Ces deux graphiques mettent en evidence 1e bon niveau de performance de QRISTAL, qui
obtient les meilleurs resultats parmi les sept systemes en competition, sur les deux taches. Son
niveau de performance assez voisin de celui du meilleur moteur americain de TREC (MRR de
0,58 contre 0,68, voir Harabagiu, 2002 et Voorhees, 2003) ou du meilleur moteur japonais de
NTCIR (MRR de 0,58 contre 0,61) sur la tache generale.

Si 1'on considere les differentes categories de questions, QRISTAL presente des resultats
homogenes selon les categories, contrairement aux autres participants (ﬁgure 5).

Résultats par type de question
(téche générale : réponses exactes)

El Factueiles

I Definitions

I] Elinainas (uuifnnn)
El Listes

 

1 2 3 4 5 QRISTAL 7

Figure 5. Resultats par type de question

59

60

Dominique Laurent, Patrick Séguéla

Ces résultats correspondent au meilleur run foumi, celui correspondant a une passe complete
d'indexation et d'extraction de réponse dans QRISTAL. Nous avions foumi un autre ﬁchier de
résultats dans lequel les textes analysés pour extraction de réponse étaient les textes retournés
par un indexeur classique de recherche d'inforrnations. Dans ce second ﬁchier de résultats, les
MRR du moteur de Synapse étaient de 0,64 (contre 0,70) pour les passages et de 0,48 (contre
0,58) pour les réponses exactes. Cette difference, signiﬁcative statistiquement, indique que
notre processus d'indexation multicriteres est payant, car il perrnet de remonter de meilleurs
textes a de meilleures positions qu'un moteur de recherche d'inforrnation classique.

Nous avons par ailleurs effectué un autre test aﬁn d'évaluer l'impact de notre typologie de
questions-réponses. En forcant a "inconnu" le type de toutes les questions analysées et en ne
prenant pas en compte l'index des types de questions-réponses, nous avons alors obtenu un
MRR de 0,46 contre 0,70 pour les passages, démontrant ainsi la pertinence de ce type de
variable d'indexation et d'analyse, d'ailleurs déja largement utilisé en questions-réponses, en
particulier par les participants de TREC-QA.

4 Utilisation de QRISTAL

Les reactions des premiers utilisateurs de QRISTAL (quelques centaines apres deux mois de
commercialisation) permettent de tirer nombre d'enseignements sur la perception des systemes
de questions-réponses, les attentes et les illusions tant sur ces outils que sur les moteurs
classiques de recherche sur le Web.

En matiere de recherche sur disque dur, les réactions sont assez rares et tres souvent positives.
La vitesse de recherche est bonne et le fait que le moteur trouve des dérivés ou des synonymes
des mots de la question améliore nettement le taux de documents retrouvés. Ainsi, sur un
corpus de dépéches d'un mois de l'AFP, les moteurs classiques se révelent incapables de
retrouver le nom du président du Pérou sur l'interrogation "président Pérou" alors que
QRISTAL retrouve "Alejandro Toledo" dans "le chef de l'état péruvien, Alejandro Toledo"
par un double processus de synonymie et de dérivation.

Compte tenu du tres grand nombre de pages indexées sur le Web, ce type d'absence de
réponse ne se pose qu'avec de petits corpus, pas sur le Web, sauf pour des questions moins
générales, ou peu de pages contiennent la réponse. Dans ces cas-la, l'utilisateur conclura en
général qu"'il n'y a pas de réponses sur le Web", ne percevant pas que ce silence résulte
souvent de l'absence de traitement linguistique des moteurs classiques !

En matiere de recherche sur le Web, les moteurs existants donnent le sentiment a l'utilisateur
qu'ils disposent de la réponse quasi instantanément. En fait, ces moteurs foumissent des bribes
de texte et des liens vers des pages, en aucun cas la réponse exacte a la question posée. Il faut
au mieux lire quelques fragments, au pire ouvrir quelques pages, pour espérer obtenir une
réponse. Ce processus demande toujours plusieurs secondes, d'autant que la découpe de bribes
par les moteurs associe parfois des données issues de phrases différentes (ainsi une demande
associant "surface" et un nom de pays donnera rarement la superﬁcie du pays mais plutot des
tailles d'appartements situés dans ce pays). Et ceci n'est valable que pour des questions
factuelles ou portant sur des personnes, les questions du type "pourquoi" ou "comment" étant
habituellement hors de portée des moteurs de recherche du Web.

QRISTAL, systéme de Questions-Réponses

Utiliser les moteurs de recherche sur le Web suppose par ailleurs la maitrise de la syntaxe de
ces moteurs (rarement identique). Or cette maitrise est peu commune. Certes, la plupart des
utilisateurs de Google savent qu'il vaut mieux ne saisir que quelques mots, si possible des
noms, mais peu connaissent l'usage des guillemets. Pour ces tres nombreux utilisateurs, la
saisie de questions en langage naturel est un atout de poids.

Reste que de nombreux traitements pouvant permettre d'ameliorer la qualite des resultats
ﬁnaux sont inenvisageables, tout simplement parce que l'utilisateur ne supporte pas d'attendre
une reponse plus de trois a quatre secondes. Ainsi nous avions implemente un dispositif de
validation de la reponse en allant interroger a nouveau les moteurs avec les mots de la
question et les mots de chacune des differentes reponses possibles (Magnini, 2002). Ce
dispositif permettait d'obtenir une amelioration nette : le nombre de bonnes reponses foumies
en premiere position passait de 47% a 58%. Mais le processus de validation demandait six at
dix secondes supplementaires eta donc dﬁ etre desactive.

Ameliorer un systeme de questions-reponses suppose donc une gestion extremement serree du
temps machine requis pour chacun des traitements. De sorte qu'il faut choisir avant tout les
traitements offrant le meilleur rapport amelioration des resultats/temps machine utilise.

5 Conclusion

QRISTAL est le premier moteur de questions-reponses commercialise, aupres du grand public
comme des professionnels. Ses resultats lors de l'evaluation EQUER montrent que l'usage
intensif de technologies TAL pour l'analyse de la question et des textes indexes, ainsi que
pour l'extraction de la reponse, donne de bons resultats, puisque le systeme se classe premier
parmi les sept systemes evalues.

Ces resultats, meme s'ils sont du niveau des meilleurs prototypes intemationaux, peuvent
toutefois etre encore consideres comme insufﬁsants, particulierement lors de recherches sur le
Web ou l'absence d'indexation, l'utilisation d'un metamoteur (donc des resultats renvoyes par
les moteurs) et des imperatifs de rapidite, rendent plus incertaine l'extraction de reponses
correctes dans de nombreux cas.

Meme s'il parait tres vraisemblable que, dans quelques armees, les moteurs booleens actuels
seront remplaces par des moteurs en langage naturel, demontrer les avantages de ce type
d'outil et renverser quelques illusions sur les moteurs de recherche actuels demandera du
temps, ne serait-ce que parce que les prescripteurs sont souvent des experts en recherche
booleenne !

Remerciements

Les auteurs remercient vivement Bruno Wieckowski et l'ensemble des ingenieurs et linguistes
ayant participe au developpement de QRISTAL

61

62

Dominique Laurent, Patrick Séguéla

Références

AMARALC., LAURENT D., MARTINS A., MENDES A., PINTO C. (2004), Design &
Implementation of a Semantic Search Engine for Portuguese, Proceedings of the Fourth
Conference on Language Resources and Evaluation.

CLARKE C. L. A., CORMACK G. V., LYNAM T. R. (2001), Exploiting Redundancy in Question
Answering, Proceedings of 24th Annual International ACM SIGIR Conference (SIGIR 2001),
p. 358-365.

GRAU B.. (2004), L'évaluation des systémes de question-réponse, Evaluation des syste‘mes de
traitement de l’information, TSTI, p. 77-98, éd. Lavoisier.

HARABAGIU S., MOLDOVAN D., CLARK C., BOWDEN M., WILLIAMS J., BENSLEY J. (2002),
Answer Mining by Combining Extraction Techniques with Abductive Reasoning,
Proceedings of T he Twelfth Text Retrieval Conference (TREC 2003).

LAURENT D., VARONE M., AMARAL C., FUGLEWICZ P. (2004), Multilingual Semantic and
Cognitive Search Engine for Text Retrieval Using Semantic Technologies, First International
Workshop on Proofing Tools and Language Technologies, Patras, Gréce.

MAGNINI B., NEGRI M., PREVETE R., TANEV H. (2002), Is It the Right Answer? Exploiting
Web Redundancy for Answer Validation, Proceedings of the 40th Annual Meeting of the
ACL, p. 425-432

MONZ C. (2003), From Document Retrieval to Question Answering, ILLC Dissertation
Series 2003-4, ILLC, Amsterdam.

VOORHEES E. M.. (2003), Overview of the TREC 2003 Question Answering Track, NIST,
54-68 (http://trec.nist.gov/pubs/trec12/t12 proceedings.html).

