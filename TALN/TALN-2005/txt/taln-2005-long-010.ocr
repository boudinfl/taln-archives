TALN 2005, Dourdan, 6-10 juin 2005

Combiner analyse superﬁcielle et profonde : bilan et
perspectives

Philippe Blache
Laboratoire Parole et Langage
CNRS & Université de Provence
pb@lpl.univ—aix.fr

Mots-clefs I Analyse syntaxique, analyse superﬁcielle, analyse profonde

Keywords: Parsing, shallow and deep parsing

Résumé L’ analyse syntaxique reste un probleme complexe au point que nombre d’applications
n’ont recours qu’a des analyseurs superﬁciels. Nous faisons dans cet article le point sur les
notions d’analyse superﬁcielles et profondes en proposant une premiere caractérisation de la
notion de complexité opérationnelle pour l’analyse syntaxique automatique permettant de dis-
tinguer objets et relations plus ou moins difﬁciles a identiﬁer. Sur cette base, nous proposons

un bilan des différentes techniques permettant de caractériser et combiner analyse superﬁcielle

et profonde.

Abstract Deep parsing remains a problem for NLP so that many applications has to
use shallow parsers. We propose in this paper a presentation of the different characteristics
of shallow and deep parsing techniques relying on the notion of operational complexity. We
present different approaches combining these techniques and propose a new approach making
it possible to use the output of a shallow parser as the input of a deep one.

1 Introduction

Le probleme de l’analyse syntaxique reste une question complexe a la fois du point de vue
théorique et computationnel. La solution généralement adoptée pour traiter des masses de don-
nées volumineuses ou des entrées non standard consiste a recourir a des analyseurs superﬁciels,
robustes et efﬁcaces, mais ne construisant que des informations partielles. I1 existe un certain
nombre d’études proposant de combiner les techniques d’analyse superﬁcielle profonde perme-
ttant soit d’améliorer l’efﬁcacité des analyseurs profonds en leur offrant un meilleur controle
des processus, soit de proposer une approche permettant de choisir le type d’analyse désiré en
fonction des besoins. Cet article dresse un bilan de ces différentes techniques en caractérisant
les notions d’analyse profonde et superﬁcielle. Ces caractéristiques sont données non seule-
ment d’un point de vue opérationnel, mais également en introduisant la notion de complexité
des phénomenes syntaxiques a analyser. I1 s’agit d’une premiere tentative de classiﬁcation dis-
tinguant les phénomenes faciles a analyser de ceux plus complexes.

Philippe Blache

On distingue généralement analyse de surface et analyse profonde en fonction de la précision de
l’information linguistique construite par un analyseur. Les techniques utilisées sont habituelle-
ment différentes : on retrouve plutot les techniques probabilistes du cote des analyseurs su-
perﬁciels tandis que les analyseurs profonds utilisent plutot des approches symboliques. Cette
caractérisation doit étre complétée par la prise en compte de la ﬁnalité de l’application util-
isant l’analyseur. I1 convient pour cela d’identiﬁer précisément les besoins en termes morpho-
syntaxiques ou sémantiques pour identiﬁer le niveau d’analyse requis (chunks pour les sys-
temes de synthese de la parole, repérage d’objets nominaux pour les applications de recherche
d’information, etc.). Cependant, certaines applications nécessitent, meme ponctuellement, des
informations plus détaillées concernant les relations syntaxiques ou les effets de sens pour une
construction donnée. Nous avons ainsi d’une part une distinction en termes d’efﬁcacité (les
analyseurs superﬁciels sont plus rapides et plus robustes que les analyseurs profonds) et de
l’autre une distinction de ﬁnalité.

La question du déterminisme est a prendre en compte de facon distincte. Si les analyseurs su-
perﬁciels sont déterministes, les analyseurs profonds traitent quant a eux l’ambigu'1'té : toutes
les possibilités sont prises en compte pendant l’analyse et le systeme fournit plusieurs solu-
tions lorsque l’ambigu'1'té ne peut étre levée. Une facon de réduire la complexité d’un analyseur
profond sans le ramener a un analyseur superﬁciel consiste a le rendre déterministe. A un pre-
mier niveau, l’entrée elle-méme peut étre déterminisée par l’utilisation d’un étiqueteur désam-
bigu'1'sant. La déterminisation de l’analyse consiste alors a éliminer des constructions en cours.
Les propriétés de coupure utilisées peuvent étre de type tres différents : probabilistes (par ex-
emple en utilisant des informations syntaxiques associées a des poids), topologiques (propriétés
formelles des structures construites, par exemple profondeur des arbres, taille des constituants,
etc.), ou encore cognitives (préférences de categorisation, de rattachement, etc.). Ces techniques
permettent de prendre des décisions de facon incrémentale en cours d’analyse. Elles peuvent
étre associées a des techniques de retardement consistant a repousser certains choix et maintenir
plusieurs solutions en parallele, par exemple en les factorisant. On peut donc a ce stade donner
quelques criteres distinctifs entre les deux approches :

o analyseur superﬁciel : rapide et robuste, il fournit une structuration simple en termes
d’unités non récursives ainsi que des relations portant sur ces unités

o analyseur profond : fournit une description couvrante des constructions de la langue en
indiquant les relations syntaxiques ou syntactico-sémantiques entre ses constituants.

I1 existe plusieurs approches permettant de combiner ces approches, la section suivante en pro-
pose une présentation. Nous reviendrons ensuite sur une caractérisation de la complexité des
phénomenes a analyser avant de décrire, dans la demiere partie, une technique hybride permet-
tant a un analyseur profond de tirer parti d’une analyse superﬁcielle.

2 Approches combinant analyse superﬁcielle et analyse pro-
fonde

I1 existe un certain nombre de travaux proposant d’utiliser simultanément les techniques d’ analyse
superﬁcielle et profonde. Un workshop a été récemment consacré a l’étude de ce probleme (cf.
[Hinrichs04]) et a permis de faire un tour d’horizon de la situation. Dans la plupart des cas,
la technique consiste a utiliser l’analyse superﬁcielle en tant que pre’-traitemem,‘ d’une analyse

Combiner analyse superﬁcielle et profonde

profonde. Par analyse superﬁcielle, on entend surtout ici forrnatage de l’entrée visant la désam-
bigu'1'sation de l’e’tiquetage morpho-syntaxique, le traitement des mots inconnus et pouvant aller
jusqu’a l’analyse d’unités entieres comme les entités nommées par exemple a l’aide de gram-
maires locales. Ce type d’approche peut s’avérer tres efﬁcace et offre l’avantage de réutiliser
voire d’adapter des composants différents : on trouve par exemple dans [Grover01] une descrip-
tion de la réutilisation d’outils originellement prévus pour l’analyse en GPSG. Dans ce type
d’approche, le controle de l’analyse profonde se fait donc en lirnitant l’espace de recherche
de l’analyseur grace a une réduction du nombre d’étiquettes a prendre en compte. De plus,
des parties entieres peuvent étre pré-analysées, ce qui réduit d’autant le nombre de structures a
construire. L’intérét majeur de ce type d’approche réside dans le fait l’analyseur n’a pas a étre
modiﬁé : il est donc possible de traiter avec le meme systeme une entrée brute ou pré-traitée.

Un second type d’approche, relativement peu répandu, consiste a utiliser les résultats d’un
analyseur syntaxique superﬁciel. L’ entrée de l’analyseur profond est la sortie de l’analyseur su-
perﬁciel, ce qui nécessite l’adaptation de l’analyseur profond. Une premiere technique consiste
a modiﬁer (on emploie également le terrne de lifter) les informations construites par l’analyseur
superﬁciel. Cela concerne les unités lexicales comme les groupes syntaxiques. Dans le premier
cas, il s’agit de transformer une unité simple en une structure enrichie adaptée au format de
l’analyseur profond, par exemple par des patterns de ﬁltrage (cf. [Blache95]). Les chunks ou
les unités syntaxiques construites peuvent également étre transforrnés a l’aide de regles adaptées
utilisant la encore des patterns. Une telle approche est décrite dans [Marimon02] qui transforme
ainsi les unités lexicales et les chunks en structures attribut-valeurs du type HPSG comme décrit
dans l’exemple suivant :

[LEMME -|

MORPH MORPHEMEI
rule( SYNSEM LOCAL L f I , [Pos=’Ncfs—’, Lemma ],).
AGR em, sing

CAT | HEAD [NCLASS common]

On trouve dans la meme perspective une technique consistant a enrichir directement la structure
construite a l’aide de techniques spéciﬁques. C’est le cas de [J ohnson02]) qui décrit comment,
a partir d’arbres syntaxiques simples, créer des arbres complexes a noeud vide. Il s’agit dans
ce cas d’une opération d’adjonction qui s’appuie sur des schémas d’arbre spéciﬁant les en-
droits ou ces noeuds peuvent étre insérés et la valeur des arguments qu’ils doivent prendre. Le
controle du processus se fait grace a une hiérarchisation de ces schémas. Un troisieme type
d’approche, défendu dans [Uszkoreit02], propose l’utilisation en parallele d’une analyse super-
ﬁcielle et d’une analyse profonde. Cette approche (cf. [Crysmann02] ou [Frank03]) consiste
a exploiter les informations de l’analyseur superﬁciel pour controler l’analyseur profond et ré-
duire son espace de recherche. Les informations de controle fournies par l’analyseur superﬁciel
portent dans cet exemple sur la structure topologique de la phrase en allemand. L’idée est de
repérer les champs topologiques par différentes techniques (cf. [Neumann00]) et guider ainsi la
construction de la structure par l’analyseur profond. Le dernier type d’approche repose sur la
possibilité de régler la ﬁnesse de l’analyse en fonction des objectifs. On peut distinguer deux cas
selon que les ressources utilisées sont identiques ou pas. Un premier type d’approche consiste
simplement a faire varier la grammaire en entrée. L’utilisation d’une grammaire simple, peu
ambigue et n’utilisant que des constituants de forte granularité permettra d’obtenir une analyse
grossiere d’un énoncé. Dans ce cas, nous pouvons parler de superﬁcialisation d’un analyseur
profond par l’utilisation d’une grammaire superﬁcielle (cf. [Puver04]). Mais il est également

Philippe Blache

Type Caractéristiques Exemple

Pre—traitement Etiqueteur desambigu'1'sant, grammaires locales [GroVer01]

Pre—analyse Analyse superﬁcielle = input de l’analyseur profond [Marimon02],[Johnson02]
Contrele L’ana1yseur profond est guide par l’analyseur superﬁciel [Crysma1m02], [Frank03]
Granularite Variable Meme analyseur, le type de sortie est une option [B1ache02]

Figure 1: Differentes techniques de combinaison d’analyseurs

possible de proposer des techniques permettant d’eXploiter des ressources identiques en termes
de lexique et de grammaire. Ce type d’approche necessite la possibilite pour l’analyseur de
construire des structures partielles, limitees a un certain type de constituant (par exemple les
SN dans le cas de systemes de recherche d’information). De meme, ce type de systeme doit
pouvoir construire une segmentation de l’input (par exemple sous la forme de chunks). Mais
le meme analyseur doit pouvoir a l’autre bout de la chaine construire egalement une structure
detaillee. Un exemple de ce type d’approche est decrit dans [Blache02]. I1 s’appuie sur une
representation decentralisee de l’information sous la forme de contraintes. Le reglage de la
granularite d’analyse s’opere en faisant varier la tolerance de l’analyseur par un seuil de con-
traintes qu’il est possible de relacher. Le choix de la structure construite en sortie se fait quant
a lui en speciﬁant le type de contraintes a satisfaire.

3 Les difﬁcultes syntaxiques

Une analyse precise des difﬁcultes rencontrees par les analyseurs syntaxiques, en dehors des
problemes purement computationnels, reste a etablir. I1 serait en effet tres utile de distinguer
les phenomenes faciles a analyser de ceux qui ne le sont pas et d’en expliquer les raisons. I1
s’agit d’un exercice difﬁcile, ce probleme ne recoupant pas toujours la notion de complexite
linguistique : certaines constructions peuvent etre facilement interpretables, mais presenter des
difﬁcultes en termes d’implantation. C’est le cas par exemple des phenomenes d’extraction
qui ne presentent que peu d’ambigu'1'te d’interpretation mais pour lesquels les systemes ont des
difﬁcultes d’analyse. Reciproquement, les enchassements de syntagmes peuvent etre complexes
mais ne presentent pas en soi de difﬁcultes pour un analyseur. Il est interessant de proposer une
ensemble de constructions ou phenomenes qu’un analyseur doit pouvoir traiter. L’article de
synthese [Abeille00] en foumit une premiere liste etablie de fagon tout a fait empirique sur la
base d’une analyse des capacites des analyseurs existants au moment de la redaction de l’article
(voici 5 ans, ce domaine a bien entendu beaucoup evolue depuis) :

o dependances locales: accord, sous-categorisation des predicats, expressions semi-ﬁgees,
restrictions modiﬁeur-modiﬁe, clitiques, etc.

dependances moyennes : pronominalisation, contrele des inﬁnitives, association negative,
quantiﬁeurs ﬂottants, etc.

dependances a distance : questions, relatives, constructions disloquees, etc.
altemances syntaxiques : passif, impersonnel, causatives, etc.
o phenomenes de coordination et de comparaison

Cette liste comporte des phenomenes varies et dont la complexite de traitement depend de la
ﬁnesse de l’analyse qu’on veut en donner, ainsi que du type de representation de l’information
choisi. Les phenomenes d’accord par exemple sont generalement faciles a traiter pour le
frangais ou l’anglais a condition de disposer dans la grammaire ou le lexique d’un codage

Combiner analyse superﬁcielle et profonde

explicite de l’information. Pour ce qui concerne les dépendances a distance, on observe des
situations tres différentes. Les relatives font partie des constructions souvent faciles a traiter,
y compris du point de vue de la structure sémantique. Les constructions disloquées posent en
revanche plus de problemes. Elles sont assez faciles a repérer, mais la relation sémantique entre
l’élément disloqué et le reste de l’énoncé est assez complexe a traiter, meme en presence d’un
pronom résomptif. Il convient dans ce cas tout d’abord d’identiﬁer ce pronom, celui-ci pouvant
apparaitre dans des positions tres variées, de veriﬁer les compatibilités morpho-syntaxiques en-
tre l’antécédent et le pronom, mais aussi les compatibilités sémantiques entre l’antécédent et
la structure régissant le pronom. Les constructions clivées présentent le meme type de prob-
leme : elles sont en francais faciles a identiﬁer, mais le repérage de leur site d’attachement est
généralement complexe. Il faut souligner que cette complexité de traitement ne se traduit pas
par une difﬁculté d’interprétation par un humain : les clivées sont au contraire dans la plupart
des cas tres facile a interpreter (ce type de probleme est signalé dans [Puver04]). Pour une meme
construction, certaines informations sont donc plus complexes a obtenir que d’autres. Si l’on
prend en compte le critere de facilité d’analyse pour caractériser un analyseur superﬁciel, on
peut alors dire que l’identiﬁcation de la presence d’une dépendance a distance peut etre obtenue
facilement notamment grace a des marques morphologiques fortes.

Par ailleurs, il faut distinguer d’un cote la structure elle-meme (la hiérarchie des objets) et de
l’autre les relations existant entre ces objets. Dans le cas d’une approche syntagmatique par
exemple, un analyseur devra produire un arbre, mais également indiquer les relations syntax-
iques ou sémantiques existant entre les constituants. Un certain nombre de propositions ont
été faites pour cela dans le cadre de l’évaluation des analyseurs syntaxiques (cf. [Carroll01],
[Briscoe02] ou [Carroll03]). Ce paradigme propose de recenser un certain nombre de relations
servant de base a la comparaison et l’évaluation des analyseurs syntaxique. L’ ensemble des
relations (adapté aux besoins du francais par rapport a la proposition de [Carroll01]) est décrit
dans la ﬁgure 3 et s’organise selon la hiérarchie suivante :

dépendance /lr\
mod arg—mod arg aux conj Subj Comp
mod XX /\

/¥\ ncsubj csubj b_ I I
o _] causa
/\ /\

ncmod cmod detmod dobj I-obj xcomp ccomp

On propose dans le tableau suivant une repartition entre relations faciles et difﬁciles a identiﬁer.
Ce jugement est ici établi sur une base empirique. On essaie de donner quelques arguments
justiﬁant ce classement, mais il conviendrait d’en faire une description plus systématique.

Philippe Blache

Nom Description

dépendance Relation de dependance generique entre une tete et un dependant

mod Relation entre une tete et son modiﬁeur. Le type est le mot introduisant la dependance
ncmod Modiﬁcateur lexical (non propositionnel)

cmod Modiﬁcateurs propositionnels

detmod Relation determinants / noms

Relation tete/argument, celu1—c1 etant realise comme un mod1ﬁeur (par exemple un SP
arg—mod ,
complement du Verbe)

arg Relation generique tete/argument (plutot de type complement)

subj Relation predicat/suj et

ncsubj Suj et lexical (non propositionnel)

csubj Suj ets propositionnels (par exemple inﬁnitive suj et)

comp Relation tete/complement

obj Relation tete/obj et

dobj Relation predicat/obj et direct (premier complement non propositionnel)

iobj Relation predicat/complement non propositionnel introduit par une preposition
clausal Relation tete/complement propositionnel

xcomp la proposition complement n’a pas de suj et realise

ccomp la proposition complement a un suj et realise

Figure 2: Description des relations
Faciles Difﬁciles
Relation Caractéristique Relation Caractéristique
Ncmod Ji::,;eI1):tS1::Ss ad]/n’ Sp/n’ Sp/V’ Sa/n sont n/sp separe par d’autres elements
marque morphologrque et generale— arnbrguite de rattachement (p. ex. spN
Cmod rel . Cmod
ment adjacence Vs. sp/n)
Detmod Hnéaﬁté, adj acence Arg_m0d dort tenrr compte de la forme Verbale et

de la semantique du mod
reperage de la proposition, complexrte

Ncsubj ordre, marque morpho (accord) Csubj potentielle, identiﬁcation du Verbe tete

de la prop sujet, de la tete de la phrase.
reperage de la subordonnee, identiﬁca-

marques morphologrques et ordre (eg

X . . . . , , C .
comp attrrbut, rnﬁmtrf antepose, etc.) comp non des tetes verbales
1011113 (111 C0111P1e111e11t 0101101311531), 0f- difﬁculte de distinguer les conjonctions
Dobj dre (premier) et adj acence avec le Verbe Conj simples (coordonnes de meme type)
Iobj mais arnbiguite rattachement des autres
Cette relation n’est pas exprrmee d1-
. . A rectement mais par doublement de la
Aux marque morphologrque, ad] acence Commie

relation subj. Depend du type du Verbe
et du type du complement

Cette observation rapide permet de degager quelques elements de caracterisation de la com-
plexite operationnelle (et non pas theorique) de l’analyse syntaxique. D’une fagon generale en
effet, les relations les plus faciles a analyser sont celles proﬁtant d’une conjonction de plusieurs
sources d’information stables : faible taux d’ambigu'1'te des constituants entrant en jeu dans la
relation (par exemple seule la relation Detmod peut relier un determinant et un nom), marque
morphologique reguliere (pronom relatif, conjonctions, construction “c’est  que”, etc.), or-
dre lineaire strict, etc. De plus, le niveau de la relation dans la hierarchie inﬂue egalement sur
sa complexite : une relation generique sera plus facile a reperer qu’un de ses sous-type (par

exemple la relation Comp est plus facile a indiquer que Ccomp).

A l’inverse, les relations complexes sont celles necessitant d’acceder a des informations lo-
cales speciﬁques (par exemple des traits lexicaux), dependant de la forme des constituants non
lexicaux relies (par exemple type du Verbe ou de la preposition dans le SV ou le SP) ou en-
core reposant sur des phenomenes semantiques de restriction. Le niveau semantique presente

Combiner analyse superﬁcielle et profonde

d’ailleurs des caractéristiques similaires : il est par exemple plus facile de traiter le role d’un
modiﬁeur que la portée de la quantiﬁcation.

Il n’est donc pas possible de distinguer simplement, comme nous l’avons vu en premiere partie,
un analyseur superﬁciel d’un analyseur profond sur de simples criteres d’efﬁcacité. Mais il ne
semble pas non plus pertinent de distinguer les deux approches sur la base du type d’information
construit en sortie. Le parenthésage d’un énoncé est une tache globalement facile si on se con-
tente de constituants non récursifs. Elle devient nettement plus difﬁcile si l’on cherche a décrire
le niveau propositionnel ou les dispositifs complexes. De meme, comme nous venons de le
voir, certaines relations syntaxiques peuvent étre plus faciles a identiﬁer que d’autres. Il est
donc intéressant d’introduire deux nouveaux criteres pour la distinction entre types d’analyse :
niveau opérationnel (un analyseur profond est non déterministe) et niveauformel (un analyseur
superﬁciel ne constr11it que des informations simples). Les criteres de déterminisme et de type
d’information peuvent bien entendu étre combinés. On po11rra par exemple trouver des analy-
seurs déterministes pouvant construire des informations complexes. Il est possible dans ce cas
de parler d’analyseurs intermédiaires.

4 Une stratégie d’analyse hybride

Ainsi que nous venons de le voir, l’analyse profonde a fréquemment recours a des techniques
d’analyse superﬁcielle, notaInInent grace a une désambigu'1'sation de l’entrée. Par ailleurs, les
résultats obtenus pour la construction d’une analyse superﬁcielle par un analyseur superﬁciel et
un analyseur profond ne sont pas tres différents, quelque soit la forme de l’input. La compara-
ison des résultats obtenus par deux analyseurs sur un meme ensemble de corpus dans le cadre
de la campagne Easy (ces résultats seront présentés lors du workshop Easy associé a TALN)
montre en effet une forte convergence, aussi bien pour le traitement de corpus de langue écrite
que de langue parlée.

Nous avons donc un certain nombre d’arguments qui Inilitent en faveur de systemes mixtes per-
mettant de fournir comme résultat, en fonction des besoins,aussi bien une analyse superﬁcielle
qu’approfondie. Plus précisément, nous proposons une architecture a deux niveaux permettant
de réutiliser une analyse superﬁcielle comme entrée d’un analyseur profond. Il ne s’agit pas de
modiﬁer la structure superﬁcielle construite (a la différence de l’approche proposée par [John-
son02]), mais bien de construire une représentation plus riche utilisant les objets construits par
la superﬁcielle pour construire des objets plus complexes. Il est pour cela nécessaire de déﬁnir
les objets “superﬁciels” comme pouvant étre des constituants pour l’analyse détaillée. Un par-
enthésage classique sous forme de chunks ne serait pas pertinente dans cette approche, un chunk
ne pouvant étre une unité constitutive d’un groupe syntaxique de niveau supérieur.

L’ objectif d’une telle approche est tout d’abord de combiner des outils différents, en ne déclen-
chant éventuellement une analyse détaillée qu’en fonction des besoins. Mais elle permet égale-
ment d’envisager l’analyse superﬁcielle comme outil de controle de l’analyse détaillée. Dans
ce cas, toutes les informations construites par l’analyseur superﬁciel sont susceptibles d’étre
utilisées par l’analyseur profond. Ces informations sont de deux types : il s’agit d’une part
de groupes de mots (donc des informations de parenthésage) et d’autre part des relations entre
des formes ou des groupes. Il convient donc de proposer la construction de groupes qui soient
a la fois pertinents pour une analyse superﬁcielle, mais également utilisables par un analyseur
détaillé. Ces groupes sont nécessairement de premier niveau (i.e. sans constituants emboités),

Philippe Blache

ils ne contiennent que des elements lexicaux. L’objectif est de deﬁnir des groupements tres
simples et peu ambigus. La grammaire suivante donne une idee du type de groupes pouvant
etre construits :

GV ::= [Adv[neg]] (Clit) [Aux] (Adv) V

GN ::= Det [Adv] [Adj] N[c] | [Det] N[p] | [Det] [Adj] N[p] |Pro[p]

GP = Prep Det [Adv] [Adj] N[c] | Prep N[p] | Prep V[ppres] | Prep V[inf]
GA ::= [Adv] Adj | [Adv] V[ppas]

Gadv ::= Adv*

Bien entendu, cette grammaire est largement incomplete, et de nombreuses categories ne sont
pas prises en compte, ce qui ne perturbe pas le comportement d’un analyseur superﬁciel. De
meme, d’autres regles completant la description de ce qu’on peut considerer comme etant des
syntagmes noyaux peuvent etre ajoutees. Enﬁn, une representation sous forme syntagmatique
ne prejuge pas non plus du formalisme choisi. On peut par exemple decrire cette meme infor-
mation sous forme de dependances ou de contraintes. Signalons qu’une gramInaire de ce type
a ete utilisee lors de la campagne d’evaluation Easy (cf. [Vilnat04]). De leur cote, les relations
pouvant etre etablies par un analyseur superﬁciel sont relativement generales et determinees
sur la base d’informations simples, en particulier l’ordre lineaire. Le tableau suivant propose
quelques relations avec leur semantique operationnelle. Chaque relation est caracterisee par des
proprietes qu’il est possible d’extraire de la liste des groupes precedemment construite. Nous
utiliserons dans ce qui suit les notations suivantes : GX+ pour indiquer que le groupe GX fait
deja partie d’une relation et X pour indiquer une suite quelconque d’objets.

Sujet (GN < x < GV) /\ (E GN+ e x)

Aux (Aux -< X -< V[ppas]) /\ (E V E X)
Objet (GV < x < GN) /\ (E GN+ e x)

Conj (GX < X < Conj < GX) /\ (E GX E X)

Les relations telles qu’elles sont deﬁnies ne permettent de speciﬁer qu’une partie des relations.
Par exemple, la relation sujet ne prend pas en compte les inversions, de meme que la relation
de coordination ne permet que les coordinations simples. Le probleme essentiel de ce type de
relation est la surgeneration. Il est cependant possible d’ajouter un niveau de contrele speci-
ﬁque, notamment concernant le type de relation possible pour une categorie donnee ou encore
en ayant recours a des informations lexicales. Une analyse intermediaire ou detaillee tirant
parti d’une analyse superﬁcielle de ce type vise donc la construction de groupes syntaxiques
de niveau superieur ainsi que de relations complexes. Le principe consiste a utiliser en entree
les objets construits par l’analyseur superﬁciel. Les constituants des unites syntaxiques detail-
lees sont donc soit des groupes soit des categories lexicales. Dans les deux cas, l’analyseur
superﬁciel peut associer a ces groupes et categories des indications en termes de probabilites
permettant ainsi de contreler le processus d’analyse profonde en reduisant l’espace de recherche
de l’analyseur. Il est possible de deﬁnir les bases d’une analyse intermediaire. Les regles de la
grammaire correspondante utilisent les groupes et les relations construits par l’analyseur super-
ﬁciel, ce qui permet de preciser ou d’exclure certains constituants en fonction de leur proprietes
syntaxiques. Ces relations sont indiquees entre chevrons. Nous obtenons ainsi des regles de la
forme :

SN ::= GN [GA] [Rel] [GP] <,E mod(GP,GV)>
SV ::= GV [GN] [GP] <,E mod(GN, GV)>
Rel ::= Pro[rel] [GN1] GV [GN2] <,E suj(GN2,GV)>

Combiner analyse superﬁcielle et profonde

SX +— pile_synt[en_cours]
si GC 6 SX
ajouter(GC, SX)
finsi sinon
répéter
fermer(SX);
en_cours—;
tant que ((GC ¢ pile_synt[en_cours]) et (ouvert(pile_synt[en_cours]))
et (en_cours 2 0))
si en_cours # 0
ajouter(GC, pile_synt[en_cours])
finsi
pile_synt[top++] +— GC

Figure 3: Algorithme intermédiaire

SN_clivé SV_SNclivé
FORM [SEM [FOCUS GN1-SEM]-l lARG_S [COMP1 SN_c1ivé1.GN.sYNT] 
SYNT

SEM [1>RED_s[REc SN_c1ivé1.GN.SEM]:|

FORM
Const = {Pro[ce], GV[étre], ProR[qu-), GN1}

PROPS Pro 4 GV, GV 4 GN1, GN1 < PIOR
pro => GV PROPS Const ={SN_c1ivé1 }
Uniq = {GN1} GV 75> GN

 

Figure 4: Description du SN clivé en GP

Un algorithme simple (cf. ﬁgure 3) consiste pour chaque groupe a veriﬁer s’il peut appartenir
a un syntagme. On utilise pour cela une pile des syntagmes (notée pile_synt) construits et
deux pointeurs : l’un pointant sur le sommet de la pile (noté top), l’autre sur le syntagme
en cours (noté en_c0urs). On indique par GC le groupe courant, on se dote d’une fonc-
tion aj0uter_c0nstituant(Const, SX) permettant d’ajouter const la liste des constituants de SX
ainsi que d’une fonction fermer(SX) cloturant la liste de constituants de SX et d’une fonction
booléenne 0uvert(SX) indiquant si SX est ouvert ou fermé.

Il est donc possible d’obtenir a faible coﬁt un analyseur intermédiaire construisant des objets
dont les constituants sont des groupes fournis par l’analyse superﬁcielle. La ﬁgure (4) présente
l’exemple d’une description du clivage du SN dans le formalisme des grammaires de propriétés
(cf. [Blache05]). Cette analyse s’appuie sur deux constructions : la premiere décrivant le site de
l’extraction, et la seconde les relations avec le site duquel l’élément a été extrait. On y constate,
de la méme facon que pour l’analyseur intermédiaire, l’utilisation des groupes et des relations en
tant que source d’information élémentaire, tout en la complétant avec des informations propres
au formalisme choisi.

5 Conclusion

L’ analyse syntaxique est un probleme dont les facteurs de complexité doivent étre précisés. Il
est pour cela nécessaire de distinguer précisément les différents types d’analyse (superﬁcielle ou
profonde) avant de proposer une caractérisation des phénomenes inﬂuant sur cette complexité.

Philippe Blache

Nous proposons dans cet article une premiere approche de ce probleme qui permet d’envisager
une coopération entre ces différentes approches. La technique proposée permet a l’analyse
détaillée de s’appuyer sur les résultats de la superﬁcielle, ce qui permet de réduire l’espace
de recherche en fournissant en entrée non plus des objets atomiques, mais des informations
complexes.

Références

Abeillé A. & P. Blache. (2000). “Grammaires et analyseurs syntaxiques”, Traité IC2, Volume Ingénierie
des langues, Hermes.

Blache P. & M. Delpui (1995) “Outil d’intégration de bases de connaissances lexicales aux analyseurs
syntaxiques”, in actes des J oumées “Lexicomatique et Dictionnairique”.

Blache P., J .-M. Balfourier & T. van Rullen (2002), “From Shallow to Deep Parsing Using Constraint
Satisfaction”, in proceedings of COLING-2002

Blache P. (2005) “Property Grammars: A Fully Constraint-Based Theory”, in Constraint Satisfaction
and Language Processing, H. Christiansen & al. (eds), Springer-Verlag LNAI 3438.

Briscoe, E., J . Carroll, J . Graham & A. Copestake (2002) “Relational evaluation schemes”, in proceed-
ings of the Beyond PARSEVAL Workshop, LREC-02.

Carroll J . & T. Briscoe (2001) “High Precision Extraction of Grammatical Relations”, in proceedings of
IWPT-01.

Carroll J ., G. Minnen & T. Briscoe (2003) “Parser Evaluation. Using a Grammatical Relation Annotation
Scheme”, in A. Abeillé (ed) Treebanks: Building and Using Syntactically Annotated Corpora, Kluwer.

Crysmarm B. A. Frank, B. Kiefer, S. Muller, G. Neumann, J . Piskorski, U. Schafer, M. Siegel, H. Uszkor-
eit, F. Xu, M. Becker & H. Krieger (2002) “An Integrated Architecture for Shallow and Deep Processing”,
in proceedings of ACL-02.

Frank A., M. Becker, B. Crysmann, B. Kiefer & U. Schafer (2003) “Integrated Shallow and Deep Parsing:
TopP meets HPSG”, in proceedings of ACL-03.

Grover C. & A. Lascarides (2001) “XML-Based Data Prepartion for Robust Deep Parsing”, in proceed-
ings of ACUEACL-01 .

Hinrichs E. & K. Simov eds.(2004) Proceedings of the Workshop “Combining Shallow and Deep
Processing for NLP”, ESSLLI-04.

Johnson M. (2002) “A Simple Pattern-Matching Algorithm for Recovering Empty Nodes and their An-
tecedents”, in proceedings of ACL-02.

Marimon M. (2002) “Integrating Shallow Linguistic Processing into a Uniﬁcation-Based Spanish Gram-
mar”, in proceedings of COLING-02.

Neumann G., C. Braun & J . Piskorski (1999) “A Divide and Conquer Strategy for Shallow Parsing of
German Free Texts”, in proceedings of ANLP-00.

Puver M. & R. Kempson (2004) “Incremental Parsing or Incremental Grammar? ”, in proceedings of the
workshop Incremental Parsing: Bringing Engineering and Cognition Together; ACL-04.

Uszkoreit H. (2002) “New Chances for Deep Linguistic Processing”, in proceedings of COLING-02.

Vilnat A., L. Monceaux, P. Paroubek, I. Robba, V. Gendner, G. Illouz & M. J ardino (2004) “Annoter en
constituants pour évlauer des analyseurs syntaxiques”, in actes de TALN-04.

