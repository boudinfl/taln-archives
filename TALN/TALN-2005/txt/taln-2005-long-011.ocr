IALN ZUUD, Uourdan, 0-1 U _]l11I1 ZUUD

Chaines de traitement syntaxique

Pierre Boullier, Lionel Clément, Benoit Sagot, Eric Villemonte de La Clergerie
INRIA - Proj et Atoll
Domaine de Voluceau, Rocquencourt, B.P. 105 ,78l53 Le Chesnay (France)
{Benoit.Sagot,Eric.De_La_Clergerie}@inria.fr
Lionel.Clement@lefff.net

Mots-clefs I Analyse syntaxique, évaluation

Keywords: Parsing, Evaluation

Résumé Cet article expose l’ensemble des outils que nous avons Ir1is en oeuvre pour
la campagne EASy d’évaluation d’analyse syntaxique. Nous commencons par un apercu du
lexique morphologique et syntaxique utilisé. Puis nous décrivons brievement les propriétés de
notre chaine de traitement pré-syntaxique qui permet de gérer des corpus tout-venant. Nous
présentons alors les deux systemes d’analyse que nous avons utilisés, un analyseur TAG issu
d’une méta-grammaire et un analyseur LFG. Nous comparons ces deux systemes en indiquant
leurs points communs, comme l’utilisation intensive du partage de calcul et des représentations
compactes de l’information, mais également leurs différences, au niveau des formalismes, des
grammaires et des analyseurs. Nous décrivons ensuite le processus de post-traitement, qui nous
a permis d’extraire de nos analyses les informations demandées par la campagne EASy. Nous
terminons par une évaluation quantitative de nos architectures.

Abstract This paper presents the set of tools we used for the EASy parsing evaluation
campaign. We begin with an overview of the morphologic and syntactic lexicon we used. Then
we brieﬂy describe the properties of our pre-syntactic processing that allows us to deal with
real-life corpus. Afterwards, we introduce the two parsers we used, namely a TAG parser based
on a meta-grammar and an LFG parser. We compare these parsers, showing their common
points, e.g., the extensive use of tabulation and compact representation techniques, but also
their differences, concerning formalisms, grammars and parsers. We then describe the post-
processing that allowed us to extract from our analyses the data required by the EASy campaign.
We conclude with a quantitative evaluation of our architectures.

1 . lJULl111U1, 1.4. \./1Ul11UllL, 1). QGEUL, L2. UU 1a 916156115

1 Introduction

L’objectif pour les participants de la campagne nationale EASy pour l’I-/Evaluation des Ana-
lyseurs Syntaxiques etait d’analyser, automatiquement et en moins d’une semaine, environ
35000 phrases. Les analyses devaient etre rendues dans le format deﬁni dans le Guide d’an-
notation (Gendner & Vilnat, 2004). Ce format regroupe une annotation (obligatoire) en consti-
tuants et une annotation (faculative) en dependances syntaxiques, que l’on pouvait rendre sous
une forme ambigue ou desambigu'1'see. Bien que nos analyseurs soient non-deterministes, nous
avons choisi de foumir a la fois des constituants et des dependances desambigu'1'sees.

Les corpus a analyser etaient des corpus reels, non retravailles, mais segmentes en tokens et
en phrases, principalement a des ﬁns d’alignement des resultats des participants. Ils couvraient
differents styles, avec environ 6000 phrases de corpus generaux (journalistiques, legislatifs),
8 000 phrases de corpus litteraires, pres de 8 000 phrases de corpus de courrier electronique
(avec tout le bruit que l’on peut imaginer dans un tel corpus), plus de 2 000 phrases de corpus
medicaux, 7 000 phrases de corpus de transcription d’oral (avec les marques speciﬁques a de
tels corpus, comme les hesitations, les reprises, les repetitions, etc.), et 3 500 phrases de corpus
de questions (issus de concours de questions-reponses).

Il nous a done fallu developper un certain nombre d’outils permettant de transformer ces cor-
pus en entrees acceptables par nos analyseurs. Par ailleurs, nous avons developpe un lexique
morphologique et syntaxique a large couverture, une meta-grammaire TAG et une grammaire
LFG, et des mecanismes permettant de desambigu'1'ser nos analyses et d’en extraire les consti-
tuants et dependances deﬁnis par le guide d’annotation. Ces composants ont dﬁ etre articules
harmonieusement, construisant ainsi deux chaines completes d’analyse syntaxique.

2 Lexique

Le lexique que nous avons utilise est en cours de developpement au sein de l’equipe (Sagot
et al. , 2005). Il s’agit d’un lexique morphologique et syntaxique a large couverture, dont l’archi-
tecture repose sur une structure hierarchique avec heritage. En effet, le lexique morphologique
et syntaxique est construit en deux phases a partir d’informations elementaires factorisees. La
premiere phase, morphologique, construit un ﬁchier de formes ﬂechies associees a leur lemme
et leur etiquette morphologique a partir d’un ﬁchier de lemmes, d’un ﬁchier decrivant les diffe-
rentes ﬂexions, et d’un ﬁchier d’exceptions. La seconde phase, syntaxique, construit le lexique
ﬁnal a partir du ﬁchier de formes ﬂechies, d’un ﬁchier associant les lemmes a des patrons syn-
taxiques et d’un ﬁchier decrivant ces patrons au sein d’une structure d’heritage.

Le lexique comporte aujourd’hui 404 366 formes ﬂechies distinctes representant 600 909 en-
trees dont certaines sont factorisees. Le developpement de ce lexique met en oeuvre differentes
technique d’acquisition, de completion et de correction. Outre la recuperation de ressources
libres de droits, des techniques d’apprentissage automatique de lexiques morphologiques ont
ete utilisees. Elles ont donne naissance a la premiere version du Leﬁj‘ (Clement et al., 2004;
Clement & Sagot, 2004), qui est un lexique des verbes frangais presents dans un gros corpus
joumalistique. Par ailleurs, un des points faibles des lexiques est souvent le manque de couver-
ture pour les multi-mots (tels que pomme de terre ou un peu). Nous avons donc experimente
des techniques d’acquisition de multi-mots (cf. (Sagot et al., 2005)).

\./1l€I.1llUD UU L1€I.1LU111Ul1L by l1L€I.A1\iLlU

Notre lexique est encore recent et comporte un certain nombre d’erreurs et de manques. Pour le
completer et le corriger, d’autres techniques ont ete employees (cf. (Sagot et al., 2005)). Notre
module de correction orthographique permet de detecter automatiquement les mots pour les-
quels il n’existe pas de correction a faible coﬁt. Il s’agit le plus souvent de mots manquants a
raj outer manuellement. Nous avons egalement applique des methodes de detection automatique
des entrees syntaxiquement incorrectes. L’ idee est qu’un mot apparaissant principalement dans
des phrases non-analysables a des chances d’etre syntaxiquement incomplet ou errone dans le
lexique. Enﬁn, certaines informations speciﬁques (associations verbe-preposition, verbes sup-
ports et leurs noms predicatifs, ...) peuvent etre acquises seIr1i-automatiquement moyennant
des techniques statistiques simples sur gros corpus. D’autres methodes sont aujourd’hui envisa-
geables, par exemple des methodes stochastiques sur des sorties d’analyse syntaxique de corpus
avec des grammaires robustes sur-generatrices (cadres de sous-categorisation tres souples, etc.).

3 Traitements pré-syntaxiques

3.1 Description

Nous avons eu a traiter des corpus bruts et donc bruites, bien loin des phrases de linguistes ou
des jeux de tests, impliquant le traitement de divers types d’entites nommeesl (Maynard et al.,
2001), des adresses aux « smileys », la correction de fautes d’orthographe, la delimitation des
phrases et des mots, et la gestion des particularites de certains corpus oraux ou de transcriptions
de sites internet. La segmentation des corpus en phrases et tokens foumie par les organisa-
teurs etait parfois soit partielle soit incompatible avec nos outils. Cette segmentation devant
etre celle des resultats rendus, notre chaine de traitement pre-syntaxique (decrite plus en detail
dans (Sagot & Boullier, 2005)) a ete adaptee pour garder en permanence un lien entre une unite
morphosyntaxique manipulee par nos outils (unite que nous appelerons mot) et le ou les tokens
d’entree (issus de la segmentation foumie) qui lui correspondent. Ainsi, pendant tout le pro-
cessus, les tokens d’entree sont conserves dans des commentaires (entre accolades et completes
par leur position dans la chaine d’entree) qui sont immediatement suivis du mot associez. Par
exemple3,

contactez—moi__,auH 1Hav.u Foch,u 750 16_ Paris,__,ouHparH e—mailH a‘_,my.name@my-emai/.com.
deviendra, si on laisse de cote les ambigu'1'tes4

{contactez0__1} contactez {—moi1__2} moi {au2__3} a‘ {au2__3} le {1 av. Foch, 75016 Paris3__9}

_ADDRESs {,9..10} : {0U10..11} 0“ {P3F11.12} P3’ {9'm3I'/12..13} 9'"73” {$13.14} 3

{my.name@my-emai/.com14_J5} _EMAIL {.15__16} . {.15__16} _SENT_BOUND.

1Nous utilisons ce tenne dans un sens legerement plus large, en y incluant toutes les sequences de tokens de ce
type, y compris celles qui ne sont generalement pas considerees comme des entites nominees (p.ex. les nombres).

2Nous utilisons les conventions suivantes : un mot artiﬁciel (par exemple un identiﬁant d’entite nominee) com-
mence par un <<_»; dans le corpus, les caracteres <<_», << { » et << }» sont remplaces par les mots artiﬁciels _UN—
DEHSCOHE, _O_BRACE et _C_BRACE, qui sont donc des mots du lexique. Ainsi, ces trois caracteres sont disponibles
comme meta—caracteres.

3Dans cet article, le symbole << __ » represente de maniere plus visible un espace, et donc une frontiere de tokens
ou de mots.

4On notera que le meme token peut etre utilise plusieurs fois de suite, pour gerer les agglutinees (ainsi au2__3).
Par ailleurs, le token special _SENT_BOUND indique une frontiere de phrase.

1 . lJULl111U1, 1.4. \./1Ul11UllL, 1). QGEUL, L2. UU 1a \./IULEULIU

Par ailleurs, pour pouvoir prendre en compte certaines ambiguités, le résultat de notre chaine
de traitement pré-syntaxique, et donc l’entrée de nos analyseurs n’est pas une séquence de mots
mais un treillis (DAG) de mots.

L’ architecture de notre chaine de traitement pré-syntaxique est la suivante :

Grammaires locales sur texte brut : reconnaissance d’un certain nombre d’entités nommées
(et autres expressions apparentées) avant la phase de correction orthographique (adresses
électroniques, URL, dates, numéros de téléphone, horaires, adresses, nombres en chiffres,
smileys, mots entre guillemets, ponctuations et artefacts de transcription de l’oral),

Segmentation en phrases et identiﬁcation des tokens inconnus :regroupement de deux phra-
ses (au sens de la segmentation EASy) en une seule phrase, ou a l’inverse découpage
d’une phrase en plusieurs (nous avons adapté pour cela notre segmenteur, qui étend les
idées simples proposées p. ex. par (Grefenstette & Tapanainen, 1994)) ; puis identiﬁcation
des tokens non analysables comme mots du lexique ou combinaison de mots du lexique5,

Grammaires locales concemant les tokens inconnus : reconnaissance d’entités nommées met-
tant en jeu des tokens inconnus a l’aide des résultats de la phase précédente : acronymes

avec leur expansion, noms propres avec titres, séquences en langues étrangeres6,

Correction orthographique et segmentation : transformation de tout token inconnu (c.-a-d.
ne faisant pas partie d’une entité nommée reconnue) en un ou plusieurs mots du lexique
par correction orthographique7, segmentation des tokens et regroupement de tokens adj a-
cents, a l’aide du correcteur orthographique SXSPELL (Sagot & Boullier, 2005),

Grammaires locales sur mots connus : entités nommées composées de mots du1exique(nom-
bres, y compris les ordinaux, et dates écrits en toutes lettres),

Traitement non-déterministe : cette phase, qui produit un treillis de mots du lexique, permet
de reconnaitre les multi-mots (comme pomme de terre) et les agglutinées (comme au)
tout en préservant toutes les ambiguités possibles, mais aussi de représenter différentes
alternatives pour gérer les erreurs d’accentuation ou de majuscule initiales.

A titre d’illustration, la ﬁgure 1 montre la sortie de cette chaine pour la phrase unique Jean__,
abite__,en__,0utre,_,au,_,I,_,,__,rue,_,de,_,la,_,P0mpe, ou une espace correspond a une frontiere de to-

kens au sens de la segmentation fournie par EASy. Les notations y sont allégées, et seuls les cas
o1‘1iln’y a pas correspondance exacte entre un token et un mot sont indiqués : le ou les tokens

5Par combinaison de mots du lexique nous entendons des tokens tels que parle—m’en ou anti—Bush—ne’.

5Ces grammaires reposent sur la méthode suivante. Soit w1 . . . wn une phrase dont les mots sont les w,-. Nous
déﬁnissons une fonction d’étiquetage t qui associe (grace a des expressions régulieres) une etiquette ti = t(w,-) a
chaque mot w,-, ou les ti sont pris dans un petit ensemble ﬁni d’étiquettes possibles (respectivement 9 et 12 pour les
deux grammaires locales concernées). Ainsi, une sequence d’étiquettes t1 . . .25” est associée a 1121 . . .wn. Ensuite,
un (gros) ensemble de transducteurs ﬁnis transforme t1 . . .25” en une nouvelle sequence d’étiquettes t’1 . . . 25'”. Si
dans cette demiere la sous—séquence tg . . . 253- correspond a un certain patron, la sequence de mots correspondante
w,- . . . wj est considérée comme reconnue par la grammaire locale.

Soit par exemple l’énoncé Peu__,aprés,_,,__,Ie__,Center__,for__,irish__,Studies__,pubIiait . . ., ou Center, irish et Studies ont été
identiﬁes comme mots inconnus. On associe a cet énoncé les étiquettes suivantes : cnpNEEucn. . .(c correspond a
initiale en majuscule, n a pmbablementfrangais (cas par défaut), p a ponctuation, N a cormu commefrangais, E a
cormu comme étranger et u a inconnu). Ces étiquettes sont transformées en la nouvelle sequence cnpNeeeen. . .,
011 e correspond a étranger : Center__,for__,irish__,Studies est reconnu comme une sequence en langue étrangere.

7Si la correction orthographique est impossible ou trop coﬁteuse, deux mots du lexique représentant les mots
inconnus sont utilises, l’un correspondant aux mots a initiale majuscule, l’autre a ceux a initiale minuscule.

8Nous essayons aussi de corriger les composants de multi-mots qui n’existent pas isolément mais qui ne
prennent pas part a leur multi—mot. Par exemple, brac n’existe que comme composant du multi—mot bric__,a‘1,_,brac.
Ainsi, un__,brac n’a pas été corrigé précédemment, mais est corrigé en un__,bras.

\./1l€I.1llUD UU L1€I.1LU111Ul1L by l1L€I.A1\iLlU

sont alors entre accolades, le mot associe etant indique derriere. On notera que Jean, en tant que
premier mot, peut aussi designer une categorie de pantalon, que la faute d’orthographe sur abite
est corrigee, la reconnaissance de l’adresse et le traitement du multi-mot et de l’agglutinee.

Jean {abite} habite en outre {au} ti {au} le {I , rue de la Pompe} _ADRESSE

ojo 9&3)» 9 e 0

{Jean} jean {en outre} en_outre

FIG. 1 — DAG associe a Jean abite en outre au 1 , rue de la Pompe.

Nos experiences montrent l’importance cruciale pour l’analyse syntaxique d’une telle chaine de
traitement pre-syntaxique, en particulier pour ceux des corpus d’EASy qui sont les plus eloignes
du francais ecrit standard : les corpus de courrier electronique et de transcriptions d’oral.

3.2 Evaluation

L’ evaluation d’une telle chaine est difﬁcile car nous ne disposons pas d’un corpus de reference
approprie. Cependant, on peut en avoir un apercu grace a des tests prealablement menes sur un
corpus journalistique de 1,1 million de mots. Tout le processus prend 13 minutes 01 seconde,
soit environ 1400 tokens/sec9. Le tableau 1 indique les taux de detection de quelques categories
d’entites nommees manuellement validees.

| Classe d’entités nommees | Occurrences | Precision | Rappel |
URL 174 100% 100%
adresses (physiques) 35 100% 100%
Expressions en langue etrangerelo 42 83% 88%

TAB. 1 — Evaluation partielle de la reconnaissance d’entites nommees.

L’ evaluation de la segmentation en phrases necessite une annotation manuelle. Nous l’avons
effectuee sur les 400 premieres phrases du corpus, ce qui donne un taux de precision de 100%
et un taux de rappel de 100%. C’est tres satisfaisant, compte tenu du fait que ce corpus jour-
nalistique est rempli de citations, de notes de bas de page, de references bibliographiques et de
meta-informations qui rendent la detection des frontieres de phrases assez difﬁcile.

L’ evaluation du correcteur orthographique est delicate. La phase de correction orthographique et
de segmentation en mots etant realisee par un composant qui fait appel au correcteur SXSPELL
tout en gerant les phenomenes de segmentation et de majuscules, il y a deux sous-composants a
evaluer : le correcteur SXSPELL et le segmenteur-correcteur qui l’utilise. De plus, il faut isoler
leurs performances des qualites du lexique et du corpus consideres. Pour ce faire, nous avons
identiﬁe automatiquement parIr1i les 1,1 million de tokens tous ceux qui ne sont pas reconnus
par le correcteur-segmenteur comme mots connus ou combinaisons valides de mots connus.
Nous avons alors identiﬁe parIr1i ces tokens inconnus ceux qui devraient etre corriges en des

9Le test a ete realise sur une architecture AMD Athlon? XP 2100+ (1.7 GHz) et les resultats peuvent pa-
raitre lents, compare, par exemple, aux quelques milliers de mots par seconde que l’on peut obtenir en faisant
de l’ana1yse syntaxique de surface. Mais la phase de correction orthographique est algoritlnniquement tres cou-
teuse (impliquant, pour chaque mot, des intersections dynamiques d’automates a plusieurs millions d’etats). Les
performances que nous obtenons sont donc excellentes.

1°Test realise seulement sur 2000 phrases, car une annotation manuelle est necessaire.

1 . lJULl111U1, 1.4. \./1Ul11UllL, 1). QGEUL, L2. UU 1a \./IULEULIU

mots ou combinaisons de mots présents dans le lexique, et nous les avons corrigés manuelle-
ment (en tenant compte de leur contexte). Puis nous avons comparé cette correction manuelle a
celle fournie par notre systeme. 91% des 150 tokens concernés sont corrigés (et éventuellement
segmentés) correctement. Quelques exemples sont indiqués dans le tableau 2.

Token d’entrée arisienne barriére Finterventgionnisme n’aspire-til plrrase
Correction parisienne barriére /Linterventionnisme nf_,aspire__,-t-il phrase

TAB. 2 — Exemples de corrections réussies effectuées par le correcteur-segmenteur.

Par ailleurs, 1846 tokens sont analysés comme combinaison de mots du lexique avec (au moins)
un préﬁxe (1712 cas) ou un sufﬁxe (54 cas, seuls -né, -clef et leurs variantes étant concer-
nés) connu. Ainsi, quasi-parti,_,unique_chrétien-/ibéral-conservateur est transformée en quasi-
__parti_ unique_chrétien—__Iibéra/-__conservateur, ou « -_ » est, par convention, la marque des
préﬁxes. Il nous faut préciser a ce stade deux faits. Tout d’abord, le corpus considéré est de tres
bonne qualité (150 mots du francais standard mal orthographiés parIr1i 1,1 million de mots).
D’autre part, cette évaluation du correcteur-segmenteur nous a permis de réaliser l’incomplé-
tude du lexique, en particulier en ce qui concerne les mots d’emprunt a des langues étrangeres.

4 Analyseurs syntaxiques

Nous avons développé deux analyseurs utilisant des formalismes, des architectures et des gram-
maires différents. Le premier, SXLFG, est un analyseur LFG a deux passes. Le second, FRMG,
est un analyseur TAG a une passe utilisant une grammaire qui est la représentation compacte
d’une TAG avec structures de traits et qui est obtenue par compilation d’une méta-grammaire.

4.1 Analyseur SXLFG

Le systeme SXLFG (Boullier et al., 2005) permet de construire des analyseurs a partir de gram-
maires écrites dans une variante du formalisme LFG (Lexical-Functional Grammars). Les gram-
maires sont donc des grammaires non-contextuelles (CFG) dites grammaires support dont les
regles dont décorées par des équationsfonctionnelles dont la résolution repose sur l’uniﬁcation.
Lors d’une analyse, les équations fonctionnelles sont calculées sur une représentation compacte
des arbres d’analyse provenant de la grammaire support appelée forét par1age’e.En cas d’ambi-
gui'té, elle partage les sous-structures communes entre plusieurs analyses.

Pour obtenir un analyseur efﬁcace, nous effectuons les calculs d’équations fonctionnelles direc-
tement sur la forét partagée, et non sur chaque arbre d’analyse CFG. Ceci induit la spéciﬁcité
de notre variante de LFG : toute information calculée dans les structures fonctionnelles ne peut
l’étre que de maniere bottom-up. En effet, puisque l’on effectue ces calculs sur la forét d’analyse
sans la modiﬁer, la structure fonctionnelle associée a la racine d’un sous-arbre ne peut dépendre
que des structures associées a ses ﬁls. Dans le cas général, le résultat de ces calculs est un en-
semble de structures fonctionnelles associées a la racine de la forét. Si cet ensemble contient
plus d’un element, on peut par la suite appliquer des heuristiques de désambigui'sation.

Notre analyseur est un analyseur robuste, et ce a plusieurs titres. Tout d’abord, l’analyseur CFG
dispose de mécanismes de rattrapage d’erreurs, permettant de traiter les cas ou la phrase d’en-
trée est agrammaticale pour la grammaire support (on parle de phrases non-valides pour la CF G

\./1l€I.1llUD UU L1€I.1LU111Ul1L by l1L€I.A1\iLlU

support). Ensuite, en cas d’échec du calcul des équations fonctionnelles, ces équations peuvent
étre assouplies et donner lieu a des résultats ayant divers degrés d’imperfection. Par exemple, on
peut obtenir une structure pour toute la phrase d’entrée mais qui ne respecte pas nécessairement
certaines contraintes comme les cadres de sous-categorisation (on parle d’analyse sans ve’rzﬁca-
tion de cohérence, par opposition a une analyse qui se déroule correctement jusqu’au bout, dite
avec vériﬁcation de cohérence). En cas d’échec de cet essai, des structures fonctionnelles cou-
vrant des portions disjointes de la phrase sont produites, qui sont appelées structures partielles.
Au pire, la phrase d’entrée peut étre sur-segmentée, c’est-a-dire découpée en sous-phrases (avec
5 niveaux de découpage possibles) pour essayer d’en analyser des portions correctes.

Pour la campagne d’évaluation EASy, nous sommes partis d’une grammaire LFG du francais
développée pour le systeme XLFG (Clément & Kinyon, 2001), que nous avons modiﬁée et com-
plétée. Sa couverture et le degré d’ambigui'té de sa grammaire support sont encore améliorables,
mais elle traite correctement un nombre respectable de phénomenes syntaxiques complexes.

4.2 Analyseur FRMG

L’ analyseur FRMG s’appuie sur une grammaire d’arbres adj oints (TAG) avec décorations engen-
drée a partir d’un niveau plus abstrait de description, une méta-grammaire (MG) (Candito, 1999;
Thomasset & de la Clergerie, 2005). La grammaire obtenue est tres compacte avec seulement
133 arbres, car elle s’appuie sur des arbresfactorisés utilisant des disjonctions entre noeuds, des
répétitions de noeuds et, surtout, des noeuds optionnels controlés par des gardes. L’ ancrage des
arbres par les entrées lexicales se fait par uniﬁcation de structures de traits appelées hypertags.

Un analyseur syntaxique hybride TAGfI‘IG“ a été compile a partir de la grammaire. Il peut
prendre en entrée les treillis produits par la chaine d’entrée (section 3) modulo quelques conver-
sions pour construire les hypertags. Au démarrage de l’analyse, les arbres sont ﬁltrés par rapport
aux mots du treillis d’entrée, pour ne garder que ceux dont les noeuds d’ancrages et les noeuds
lexicaux sont compatibles avec ces mots. L’ analyseur utilise une stratégie d’analyse tabulaire
descendante gauche-droite en une seule passe : le traitement des décorations des noeuds n’est
pas repoussé dans une seconde passe, contrairement a la stratégie SXLFG. Néanmoins, les dé-
corations ne sont pas prises en compte pour les prédictions descendantes mais seulement dans
les propagations de réponses. Le parcours des arbres factorisés se fait sans expansion de ceux-ci
assurant une bonne efﬁcacité. L’ analyseur retourne soit une analyse complete du treillis d’en-
trée, soit, en mode robuste, un ensemble d’analyses partielles couvrant au mieux ce treillis. Les
analyses sont émises sous formes de foréts partagées de dérivations TAG indiquant les diverses
opérations effectuées (substitution, adjonction, ancrage,. . .) et ensuite converties en foréts par-
tagées de dépendances (ﬁgure 2) servant de base pour les traitements post-syntaxiques.

ElF5l:u E1F6l1E1Wl,E1FXlrue ElF9\de 131111011; ElFlllPompe
PP E1F3\en

vrep=2

N7.
EIFN
W "“"° N2
ElFllIun I ElF2l:bne “:46 plepmo -
119:5!) mlw v:111 V F I
' ‘ PP
Vm°d IVM0d:90l N2 

FIG. 2 — Forét de dépendances (FRMG)

“Les TIG (Tree Insertion Grammars) sont une variantes des TAG faiblement équivalentes aux CFG.

1 . lJULl111U1, 1.4. \./1Ul11UllL, 1). QGEUL, L2. UU 1a 916156115

5 Traitement post-syntaxique

Le format et la nature des informations attendus par les organisateurs de la campagne EASy
(Gendner & Vilnat, 2004) ne correspondent pas nécessairement a nos propres formats et choix
linguistiques (cf. ﬁgure 3). D’autre part, les techniques tabulaires de partage de calculs Inises
en oeuvre dans nos analyseurs sont en partie motivées par le souci d’obtenir l’ensemble des
analyses pour une phrase, alors que la piste d’évaluation de base pour EASy concerne des
analyses syntaxiques non ambigues. Il a donc été nécessaire de mettre en place des algorithmes
de désambigu'1'sation et de conversion travaillant sur les structures partagées produites par nos
analyseurs. Ces travaux ont été l’occasion d’explorer ce type d’algorithmes avec des approches
assez différentes dans les cas de SXLFG et de FRMG. Nous avons également dﬁ explorer diverses
regles heuristiques de désambigu'1'sation et comprendre comment les exprimer.

GN 1 NV 2 GR 3 GP 4
Jean abite en outre au 1 , rue de la Pompe
F1 F2 F3 F4 F5 F6 F7 F8 F9 F10 F11

sujet verbe complément verbe modiﬁeur verbe
GN1 NV2 GP4 NV2 GR3 NV2

FIG. 3 — Sortie EASy foumie par SXLFG et FRMG pour la meme phrase que précédemment

Dans le cas de FRMG, la désambigu'1'sation et la conversion s’appuient sur les forets partagées
de dépendances (section 4.2). Les arcs de dépendance se pretent bien a l’expression d’heuris-
tiques de désambigu'1'sation : chaque arc se voit attribuer un poids donné par la somme des poids
élémentaires associés aux contraintes satisfaites par l’arc, avec, par exemple, un poids élevé
pour une dépendance entre un verbe et un argument et moindre entre un verbe et un modiﬁeur.
Au niveau global, l’algorithme retient un ensemble d’arcs maximisant la somme de leurs poids
et tels que tout noeud soit accessible par un et un seul chemin. Néanmoins, pour des raisons
d’efﬁcacité, l’algorithme a été (tardivement) complété par une notion de coﬁt régional associé
a un sous-ensemble d’arcs atteignables a partir d’un noeud. Une selection bomée des meilleurs
coﬁts régionaux est effectuée pour progressivement calculer un coﬁt global qui n’est plus néces-
sairement optimal. Quoique bien plus efﬁcace, l’algorithme reste encore trop lent dans certains
cas. Une analyse plus poussée du probleme (en partie aidée par l’approche suivie pour SXLFG)
suggere que trop d’informations sont perdues lors de la conversion des derivations en dépen-
dances”. En particulier, le format actuel n’indique pas si deux dépendances issues d’un meme
mot appartiennent ou non a une meme analyse, ce qui nécessite l’ajout de regles coﬁteuses fa-
vorisant les bonnes conﬁgurations. Nous prévoyons donc de faire évoluer notre notion de foret
partagée de dépendances. Malgré ces problemes, nous avons pu constater l’adéquation des arcs
de dépendance pour exprimer des regles de désambigu'1'sation ou de conversion.

Dans le systeme SXLFG, la phase de désambigu'1'sation se fait par l’application successive d’un
certain nombre de regles sur les structures fonctionnelles associées a la racine de la foret d’ana-
lyse produite par la grammaire support. Chaque regle met en oeuvre un critere pour éliminer les
structures fonctionnelles non optimales au sens de ce critere. La demiere regle choisit au hasard
une analyse parmi celles qui restent. La foret d’analyse est alors élaguée pour n’y laisser que
1’ arbre13 support correspondant a la structure fonctionnelle choisie. L’ extraction des constituants

12Ceci est dﬁ au fait que nos forets de dépendances ont initialement ete congues pour une visualisation simpliﬁee
d’un ensemble important d’analyses.
“En toute rigueur, plusieurs arbres peuvent subsister s’ils correspondent a une structure fonctionnelle identique.

\./1l€I.1llUD UU L1€I.1LU111Ul1L by l1L€I.A1\iLlU

et des dependances demandes par EASy se fait alors en parcourant la structure fonctionnelle et
son arbre associe, a la recherche de motifs correspondant aux speciﬁcations de la campagne.
Cette phase est facilitee par le fait que l’analyse unique issue de la phase de desambiguisation a
ete prealablement extraite, a l’inverse de ce qui se passe dans le systeme FRMG.

6 Misc en aeuvre et résultats expérimentaux

Le volume de donnees a analyser pour EASy, le nombre d’essais que nous voulions effectuer et
la complexite de la tache etaient sufﬁsamment consequents pour que nous decidions de ventiler
les analyses sur plusieurs machines, formant ainsi un cluster pour chaque systeme.

Les tableaux 3 a 5 presentent divers resultats concernant EASy mais aussi les corpus EUROTRA
et TSNLP. Les nombres de phrases different selon le systeme, en raison d’heuristiques diffe-
rentes de segmentation en phrases. Par ailleurs, le taux d ’ambigu'i'te’ moyen par mot n’est dispo-
nible que pour FRMG, car dans SXLFG les heuristiques de desambigu'1'sation sont incorporees
dans l’analyseur. Ce taux est deﬁni comme le nombre moyen d’arcs de dependance atteignant
un mot moins un”.

Corpus #phrases % couv. temps d’ analyse amb.
moy. med. 2 1s 2 10s
EUROTRA 334 95.80% 1.81s 1.27s 61.68% 1.55% 0.7
TSNLP 1661 93.38% 0.72s 0.56s 22.03% 0.00% 0.4
EASy 34438 42.45% 5.55s 1.61s 64.41% 9.32% 0.6

TAB. 3 — Resultats pour FRMG, avec un timeout de 100 secondes15

Corpus #phrases couverture (sans couverture (avec temps d’ analyse

Verif. de coh.16) Verif. de coh.) moy. med. 2 0.1s 2 1s
EUROTRA 334 94.61% 84.43% 0.33s 0.02s 22.2% 6.0%
TSNLP 1661 98.50% 79.12% 0.03s 0.00s 2.8% 0.6%
EASy 40859 66.62% 41.95% n.d.17

TAB. 4 — Resultats pour SXLFG, avec un timeout de 15 secondes15.

7 Conclusion

La campagne d’evaluation EASy nous a perInis de mettre en evidence la difference considerable
qu’il y a entre le developpement d’un analyseur syntaxique et le developpement d’une chaine
complete d’analyse syntaxique. En effet, outre l’importance de la qualite de la grammaire et
de l’analyseur, cette campagne a montre le role non moins determinant de la couverture et de
la richesse du lexique, de la qualite de la chaine de traitement, de la precision des methodes
d’eXploitation des sorties des analyseurs, ainsi que la tres forte interaction entre les differents
composants, et en particulier entre le lexique et la grammaire.

“Pour une phrase non-ambigue, chaque mot (sauf la << tete » de la phrase) est atteint par un seul arc, d’o1‘1 un taux
d’ambigu'1'te nul. Le nombre maximal d’ana1yses pour un taux 04 et une phrase de longueur 11 est en O((1 + 04)").

15On notera qu’un timeout plus eleve aurait augmente les taux de couverture mais egalement les temps d’ analyse.

“Nous n’aVons pas conserve les infonnations pennettant de donner les temps sur le corpus EASy. Toutefois,
(Boullier et al., 2005) donne les temps d’analyse pour les 87.51% de phrases reconnues par la CFG support.

1 . lJULl111U1, 1.4. \./1Ul11UllL, 1). QGEUL, L2. UU 1a \./IULEULIU

Corpus complet Phrases Valides pour la CFG support
Analyse CFG Analyse CFG | Analyse complete
#phrases 40859 35756
nmoy - nmam 20.95 - 541 19.06 - 173
UWm0y - UWWW 0.79 - 97 0.75 - 65
Nombre med - max 32028 - 3.1073 29 582 - 5.1052 1 - 1
d’analyses 2 1012 8.86% 7.84% 0%

TAB. 5 — Données sur les corpusls et nombres d’analyses pour SXLFG, avant application de
l’heuristique de sur-segmentation.

Cette forte complémentarité entre les différentes phases des chaines d’analyse syntaxique a
inévitablement élargi le champ de la campagne EASy. Ce n’est pas seulement l’analyse syn-
taxique elle-méme qui a été évaluée lors de cette campagne, mais la capacité a mettre en place
des chaines d’analyse syntaxique completes”. Nous comptons exploiter le fait que nous avons
déployé deux chaines de traitement que tout sépare sauf le lexique et la chaine pré-syntaxique.
Ceci nous permettra d’effectuer des comparaisons et d’améliorer ainsi grammaires et analyseurs
(en étudiant les différences entre nos résultats), mais aussi le lexique et la chaine de traitement
pré-syntaxique (en étudiant les erreurs communes).

Références

BOULLIER P., SAGOT B. & CLEMENT L. (2005). Un analyseur LFG efﬁcace 2 SXLFG. In Actes de
TALN’05, Dourdan, France.

CANDITO M.-H. (1999). Organisation modulaire et paramétrable de grammaires électroniques lexica-
lise’es. PhD thesis, Université Paris 7.

CLEMENT L. & KINYON A. (2001). XLFG-an LFG parsing scheme for French. In Proc. of LF G’0I.
CLEMENT L. & SAGOT B. (2004). Site intemet du Lefff (Lexique des Formes Fléchies du Francais).
www . lefff . net.

CLEMENT L., SAGOT B. & LANG B. (2004). Morphology Based Automatic Acquisition of Large-
coverage Lexica. In Proceedings of LREC ’04, p. 1841-1844.

GENDNER V. & VILNAT A. (2004). Les armotations syntaxiques de référence PEAS. En ligne sur
www . limsi . fr/Recherche/CORVAL/easy/PEAS_reference_annotations_v1 . 6 . html.
GREFENSTETTE G. & TAPANAINEN P. (1994). What is a word, what is a sentence ? Problems of
tokenization. In Proceedings of the 3rd CCLTR, Budapest, Hungary.

MAYNARD D., TABLAN V., URSU C., CUNNINGHAM H. & WILKS Y. (2001). Named entity recogni-
tion from diverse text types. In Proceedings of RANLP 2001, Tzigov Chark, Bulgaria.

SAGOT B. & BOULLIER P. (2005). From raw corpus to word lattices 2 robust pre-parsing processing. In
Actes de L&TC 2005, Poznan, Pologne.

SAGOT B., CLEMENT L., ERIC VILLEMONTE DE LA CLERGERIE & BOULLIER P. (2005). Vers un
méta-lexique pour le francais 2 architecture, acquisition, utilisation. In Joumée ATALA sur l’interface
lexique-grammaire. http 2 //www . atala . org/article . php3 ?id_article=2 4 0.

THOMASSET F. & DE LA CLERGERIE E. V. (2005). Comment obtenir plus des méta-grammaires. In
Actes de TALN’05, Dourdan, France.

18Pour les données sur les corpus, n désigne un nombre de mots, et U W un nombre de mots inconnus.
19En outre, l’harmonisation des résultats des différents participants passe par une segmentation commune en
phrases et en mots, différente de celle produite et utilisée par nos outils, qui a dﬁ étre conservée en permanence.

