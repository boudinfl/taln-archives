TALN 2005, Dourdan, 6-10 juin 2005

Chaines de traitement syntaxique

Pierre Boullier, Lionel Clement, Benoit Sagot, Eric Villemonte de La Clergerie
INRIA — Projet Atoll
Domaine de Voluceau, Rocquencourt, B.P. 105 ,78l5 3 Le Chesnay (France)
{Benoit.Sagot,Eric.De_La_Clergerie}@inria.fr
Lionel.Clement@lefff.net

Mots-clefs :

Analyse syntaxique, evaluation

K€yWOFdS2 Parsing, Evaluation

Resume Cet article expose l’ensemble des outils que nous avons mis en oeuvre pour
la campagne EASy d’evaluation d’analyse syntaxique. Nous commengons par un apergu du
lexique morphologique et syntaxique utilise. Puis nous decrivons brievement les proprietes de
notre chaine de traitement pre—syntaxique qui permet de gerer des corpus tout—venant. Nous
presentons alors les deux systemes d’analyse que nous avons utilises, un analyseur TAG issu
d’une meta—grammaire et un analyseur LFG. Nous comparons ces deux systemes en indiquant
leurs points communs, comme l’utilisation intensive du partage de calcul et des representations
compactes de l’information, mais egalement leurs differences, au niveau des formalismes, des
grammaires et des analyseurs. Nous decrivons ensuite le processus de post—traitement, qui nous
a permis d’extraire de nos analyses les informations demandees par la campagne EASy. Nous
terminons par une evaluation quantitative de nos architectures.

Abstract This paper presents the set of tools we used for the EASy parsing evaluation
campaign. We begin with an overview of the morphologic and syntactic lexicon we used. Then
we brieﬂy describe the properties of our pre—syntactic processing that allows us to deal with
real—life corpus. Afterwards, we introduce the two parsers we used, namely a TAG parser based
on a meta—grammar and an LFG parser. We compare these parsers, showing their common
points, e.g., the extensive use of tabulation and compact representation techniques, but also
their differences, concerning formalisms, grammars and parsers. We then describe the post-
processing that allowed us to extract from our analyses the data required by the EASy campaign.
We conclude with a quantitative evaluation of our architectures.

103

104

P. Boullier, L. Clement, B. Sagot, E. de la Clergerie

1 Introduction

L’objectif pour les participants de la campagne nationale EASy pour l’Evaluation des Ana-
lyseurs Syntaxiques était d’analyser, automatiquement et en moins d’une semaine, environ
35000 phrases. Les analyses devaient étre rendues dans le format déﬁni dans le Guide d’an—
notation (Gendner & Vilnat, 2004). Ce format regroupe une annotation (obligatoire) en consti-
tuants et une annotation (faculative) en dépendances syntaxiques, que l’on pouvait rendre sous
une forme ambigue ou désambiguisée. Bien que nos analyseurs soient non—deterministes, nous
avons choisi de fournir a la fois des constituants et des dépendances desambiguisées.

Les corpus a analyser étaient des corpus reels, non retravaillés, mais segmentés en tokens et
en phrases, principalement a des ﬁns d’alignement des résultats des participants. Ils couvraient
différents styles, avec environ 6000 phrases de corpus généraux (journalistiques, législatifs),
8000 phrases de corpus litteraires, pres de 8 000 phrases de corpus de courrier électronique
(avec tout le bruit que l’on peut imaginer dans un tel corpus), plus de 2 000 phrases de corpus
médicaux, 7 000 phrases de corpus de transcription d’oral (avec les marques spéciﬁques a de
tels corpus, comme les hésitations, les reprises, les repetitions, etc.), et 3 500 phrases de corpus
de questions (issus de concours de questions—réponses).

Il nous a donc fallu développer un certain nombre d’outils permettant de transformer ces cor-
pus en entrees acceptables par nos analyseurs. Par ailleurs, nous avons développé un lexique
morphologique et syntaxique a large couverture, une méta—grammaire TAG et une grammaire
LFG, et des mécanismes permettant de désambiguiser nos analyses et d’en extraire les consti-
tuants et dépendances déﬁnis par le guide d’annotation. Ces composants ont dﬁ étre articulés
harmonieusement, construisant ainsi deux chaines completes d’ analyse syntaxique.

2 Lexique

Le lexique que nous avons utilise est en cours de développement au sein de l’équipe (Sagot
er al., 2005). Il s’ agit d’un lexique morphologique et syntaxique a large couverture, dont l’ archi-
tecture repose sur une structure hierarchique avec heritage. En effet, le lexique morphologique
et syntaxique est construit en deux phases a partir d’informations élémentaires factorisées. La
premiere phase, morphologique, construit un ﬁchier de formes ﬂechies associees a leur lemme
et leur etiquette morphologique a partir d’un ﬁchier de lemmes, d’un ﬁchier décrivant les diffe-
rentes ﬂexions, et d’un ﬁchier d’exceptions. La seconde phase, syntaxique, construit le lexique
ﬁnal a partir du ﬁchier de formes ﬂéchies, d’un ﬁchier associant les lemmes a des patrons syn-
taxiques et d’un ﬁchier décrivant ces patrons au sein d’une structure d’héritage.

Le lexique comporte aujourd’hui 404 366 formes ﬂéchies distinctes représentant 600 909 en-
trees dont certaines sont factorisées. Le développement de ce lexique met en oeuvre différentes
technique d’acquisition, de completion et de correction. Outre la recuperation de ressources
libres de droits, des techniques d’apprentissage automatique de lexiques morphologiques ont
été utilisées. Elles ont donné naissance a la premiere version du Leﬁj‘ (Clement er al., 2004;
Clement & Sagot, 2004), qui est un lexique des verbes francais presents dans un gros corpus
journalistique. Par ailleurs, un des points faibles des lexiques est souvent le manque de couver-
ture pour les multi—mots (tels que pomme de terre ou un peu). Nous avons donc expérimenté
des techniques d’acquisition de multi—mots (cf. (Sagot et al., 2005)).

Chaines de traitement syntaxique

Notre lexique est encore recent et comporte un certain nombre d’erreurs et de manques. Pour le
completer et le corriger, d’autres techniques ont ete employees (cf. (Sagot er al., 2005)). Notre
module de correction orthographique permet de detecter automatiquement les mots pour les-
quels il n’existe pas de correction at faible coﬁt. Il s’agit le plus souvent de mots manquants a
raj outer manuellement. Nous avons egalement applique des methodes de detection automatique
des entrees syntaxiquement incorrectes. L’ idee est qu’un mot apparaissant principalement dans
des phrases non—analysables a des chances d’étre syntaxiquement incomplet ou errone dans le
lexique. Enﬁn, certaines informations speciﬁques (associations verbe—preposition, verbes sup-
ports et leurs noms predicatifs, ...) peuvent étre acquises semi—automatiquement moyennant
des techniques statistiques simples sur gros corpus. D’autres methodes sont aujourd’hui envisa-
geables, par exemple des methodes stochastiques sur des sorties d’analyse syntaxique de corpus
avec des grammaires robustes sur—generatrices (cadres de sous—categorisation tres souples, etc.).

3 Traitements pré-syntaxiques

3.1 Description

Nous avons eu a traiter des corpus bruts et donc bruites, bien loin des phrases de linguistes ou
des jeux de tests, impliquant le traitement de divers types d’entites nomme’es1 (Maynard er al.,
2001), des adresses aux « smileys >>, la correction de fautes d’orthographe, la delimitation des
phrases et des mots, et la gestion des particularites de certains corpus oraux ou de transcriptions
de sites internet. La segmentation des corpus en phrases et tokens foumie par les organisa-
teurs etait parfois soit partielle soit incompatible avec nos outils. Cette segmentation devant
étre celle des resultats rendus, notre chaine de traitement pre—syntaxique (decrite plus en detail
dans (S agot & Boullier, 2005)) a ete adaptee pour garder en permanence un lien entre une unite
morphosyntaxique manipulee par nos outils (unite que nous appelerons mot) et le ou les tokens
d’entree (issus de la segmentation fournie) qui lui correspondent. Ainsi, pendant tout le pro-
cessus, les tokens d’entree sont conserves dans des commentaires (entre accolades et completes
par leur position dans la chaine d’entree) qui sont immediatement suivis du mot associe’2. Par
exemple3,

contactez-moi__,auH 1 Havh Foch,u 75016_ Paris,__,ouHparH e-mai/H é1_,my.name@my-emai/.com.
deviendra, si on laisse de cote les ambiguite’s4

{contactezm} contactez {'n70I.1N2} moi {QUQN3} é {QUQN3} le {1 av. Foch, 75016 Parisgug}

_ADDREss 159.10} , {0U10..11} 0” l(P3F11.12} P3’ {9'm3I'/12.13} 9'”73” {$13.14} 3

{my.name@my-emai/.com14..15} _EMAIL {.1546} . {.15..16}_SENT_BOUND.

1Nous utilisons ce terme dans un sens legerement plus large, en y incluant toutes les sequences de tokens de ce
type, y compris celles qui ne sont generalement pas considerees comme des entites nommees (p.eX. les nombres).

2Nous utilisons les conventions suivantes : un mot artiﬁciel (par exemple un identiﬁant d’entite nommee) com-
mence par un «_ »; dans le corpus, les caracteres «_ », « {» et « }» sont remplaces par les mots artiﬁciels _UN—
DERSCORE, _O_BRACE et_C_BRACE, qui sont donc des mots du lexique. Ainsi, ces trois caracteres sont disponibles
comme meta—caracteres.

3Dans cet article, le symbole « _ » represente de maniere plus visible un espace, et donc une frontiere de tokens
ou de mots.

“On notera que le meme token peut etre utilise plusieurs fois de suite, pour gerer les agglutinees (ainsi aU2H3).
Par ailleurs, le token special _sENT_BOUND indique une frontiere de phrase.

105

P. Boullier, L. Clement, B. Sagot, E. de la Clergerie

Par ailleurs, pour pouvoir prendre en compte certaines ambiguités, le résultat de notre chaine
de traitement pré—syntaxique, et donc l’entrée de nos analyseurs n’est pas une sequence de mots
mais un treillis (DAG) de mots.

L’ architecture de notre chaine de traitement pré—syntaxique est la suivante :

Grammaires locales sur texte brut : reconnaissance d’un certain nombre d’entités nommées
(et autres expressions apparentées) avant la phase de correction orthographique (adresses
électroniques, URL, dates, numéros de téléphone, horaires, adresses, nombres en chiffres,
smileys, mots entre guillemets, ponctuations et artefacts de transcription de l’oral),

Segmentation en phrases et identiﬁcation des tokens inconnus zregroupement de deux phra-
ses (au sens de la segmentation EASy) en une seule phrase, ou a l’inVerse découpage
d’une phrase en plusieurs (nous avons adapté pour cela notre segmenteur, qui étend les
idées simples proposées p. ex. par (Grefenstette & Tapanainen, 1994)) ; puis identiﬁcation
des tokens non analysables comme mots du lexique ou combinaison de mots du lexique5,

Grammaires locales concernant les tokens inconnus : reconnaissance d’entités nommées met-
tant en jeu des tokens inconnus a l’aide des résultats de la phase précédente : acronymes
avec leur expansion, noms propres avec titres, sequences en langues e’trangeres6,

Correction orthographique et segmentation : transformation de tout token inconnu (c.—a—d.
ne faisant pas partie d’une entité nommée reconnue) en un ou plusieurs mots du lexique
par correction orthographique7, segmentation des tokens et regroupement de tokens adj a-
cents, a l’aide du correcteur orthographique SXSPELL (S agot & Boullier, 2005),

Grammaires locales sur mots connus : entités nommées composées de mots du lexique (nom-
bres, y compris les ordinaux, et dates écrits en toutes lettres),

Traitement non-déterministe : cette phase, qui produit un treillis de mots du lexique, permet
de reconnaitre les multi—mots (comme pomme de terre) et les agglutinées (comme au)
tout en préservant toutes les ambiguités possibles, mais aussi de représenter différentes
alternatives pour gérer les erreurs d’accentuation ou de majuscule initialeg.

A titre d’illustration, la ﬁgure 1 montre la sortie de cette chaine pour la phrase unique Jecm__,
abite__,en__,0utre,_,au,_,1,_,,__,rue,_,de,_,la,_,P0mpe, ou une espace correspond a une frontiere de to-

kens au sens de la segmentation fournie par EASy. Les notations y sont allégées, et seuls les cas
ou il n’y a pas correspondance exacte entre un token et un mot sont indiqués : le ou les tokens

5Par combinaison de mots du lexique nous entendons des tokens tels que parle—m’en ou ami—Bush—né.

6Ces grammaires reposent sur la methode suivante. Soit wl . . . wn une phrase dont les mots sont les w,. Nous
deﬁnissons une fonction d’etiquetage t qui associe (grace a des expressions regulieres) une etiquette t, = t(w,) a
chaque mot w,, ou les 26, sont pris dans un petit ensemble ﬁni d’etiquettes possibles (respectivement 9 et 12 pour les
deux grammaires locales concemees). Ainsi, une sequence d’etiquettes t1 . . .26” est associee a 101 . . .w,,. Ensuite,
un (gros) ensemble de transducteurs ﬁnis transforme t1 . . .26” en une nouvelle sequence d’etiquettes t’1 . . . 261,. Si
dans cette demiere la sous—sequence 26; . . . 2&3. correspond a un certain patron, la sequence de mots correspondante
w, . . . 7.Uj est consideree comme reconnue par la grammaire locale.

Soit par exemple l’enonce Peu,_,apres__,,__,le__,Center__,for__,irish__,Studies__,publiait..., Oil Center, irish et Studies ont été
identiﬁes comme mots inconnus. On associe a cet enonce les etiquettes suivantes : cr1pNEEucr1. . .(c correspond a
initiale en majuscule, n a probablememfrangrais (cas par defaut), p a ponctuation, N a comm commefrangrais, E a
comm comme étranger et u a inconnu). Ces etiquettes sont transformees en la nouvelle sequence cr1pNeeeer1. . .,
ou e correspond a étranger : Center,_,for,_,irish__,studies est reconnu comme une sequence en langue etrangere.

7Si la correction orthographique est impossible ou trop coﬁteuse, deux mots du lexique representant les mots
inconnus sont utilises, l’un correspondant aux mots a initiale majuscule, l’autre a ceux a initiale minuscule.

8Nous essayons aussi de corriger les composants de multi—mots qui n’existent pas isolement mais qui ne
prennent pas part a leur multi—mot. Par exemple, brac n’existe que comme composant du multi—mot bric_é__,brac.
Ainsi, un__,brac n’a pas ete corrige precedemment, mais est corrige en un_bras.

106

Chaines de traitement syntaxique

sont alors entre accolades, le mot as socie etant indique derriere. On notera que Jean, en tant que
premier mot, peut aussi designer une categorie de pantalon, que la faute d’orthographe sur abite
est corrigee, la reconnaissance de l’adresse et le traitement du multi—mot et de l’agglutinee.

Jean fabite} habite en ontre {an} a {an} le [1 , rue de la Pompe} _ADRESSE

ajo 9(9)» 6 e 0

{Jean} jean [ en 0ntre} en_0ntre

FIG. 1 — DAG associe a Jean abite en ontre an I , rue de la Pompe.

Nos experiences montrent l’importance cruciale pour l’analyse syntaxique d’une telle chaine de
traitement pre—syntaxique, en particulier pour ceux des corpus d’EASy qui sont les plus eloignes
du francais ecrit standard : les corpus de courrier electronique et de transcriptions d’oral.

3.2 Evaluation

L’evaluation d’une telle chaine est difﬁcile car nous ne disposons pas d’un corpus de reference
approprie. Cependant, on peut en avoir un apercu grace a des tests prealablement menes sur un
corpus journalistique de 1,1 million de mots. Tout le processus prend 13 minutes 01 seconde,
soit environ 1400 tokens/sec9. Le tableau 1 indique les taux de detection de quelques categories
d’entites nommees manuellement validees.

| Classe d’entites nommees | Occurrences | Precision | Rappel |

URL 174 100% 100%
adresses (physiques) 35 100% 100%
Expressions en langue etrangerelo 42 83% 88%

TAB. 1 — Evaluation partielle de la reconnaissance d’entites nommees.

L’evaluation de la segmentation en phrases necessite une annotation manuelle. Nous l’avons
effectuee sur les 400 premieres phrases du corpus, ce qui donne un taux de precision de 100%
et un taux de rappel de 100%. C’est tres satisfaisant, compte tenu du fait que ce corpus jour-
nalistique est rempli de citations, de notes de bas de page, de references bibliographiques et de
meta—informations qui rendent la detection des frontieres de phrases as sez difﬁcile.

L’ evaluation du correcteur orthographique est delicate. La phase de correction orthographique et
de segmentation en mots etant realisee par un composant qui fait appel au correcteur SXSPELL
tout en gerant les phenomenes de segmentation et de majuscules, il y a deux sous—composants a
evaluer : le correcteur SXSPELL et le segmenteur—correcteur qui l’utilise. De plus, il faut isoler
leurs performances des qualites du lexique et du corpus consideres. Pour ce faire, nous avons
identiﬁe automatiquement parmi les 1,1 million de tokens tous ceux qui ne sont pas reconnus
par le correcteur—segmenteur comme mots connus ou combinaisons valides de mots connus.
Nous avons alors identiﬁe parmi ces tokens inconnus ceux qui devraient etre corriges en des

9Le test a ete realise sur une architecture AMD Athlon ‘.7 XP 2100+ (1.7 GHz) et les resultats peuvent pa-
raitre lents, compare, par exemple, aux quelques milliers de mots par seconde que l’on peut obtenir en faisant
de l’analyse syntaxique de surface. Mais la phase de correction orthographique est algorithmiquement tres cou-
teuse (impliquant, pour chaque mot, des intersections dynamiques d’automates a plusieurs millions d’etats). Les
performances que nous obtenons sont donc excellentes.

1°Test realise seulement sur 2000 phrases, car une annotation manuelle est necessaire.

107

108

P. Boullier, L. Clement, B. Sagot, E. de la Clergerie

mots ou combinaisons de mots presents dans le lexique, et nous les avons corriges manuelle—
ment (en tenant compte de leur contexte). Puis nous avons compare cette correction manuelle a
celle fournie par notre systeme. 91% des 150 tokens concernes sont corriges (et éventuellement
segmentes) correctement. Quelques exemples sont indiques dans le tableau 2.

barriére
barriére

arisienne
parisienne

Token d’entree
Correction

/’inz‘ervenz‘Hionnisme
/Linterventionnisme

n’aspire-til
n’_aspire__,-t-i/

plrrase
phrase

TAB. 2 — Exemples de corrections reussies effectuees par le correcteur—segmenteur.

Par ailleurs, 1846 tokens sont analyses comme combinaison de mots du lexique avec (au moins)
un preﬁxe (1712 cas) ou un sufﬁxe (54 cas, seuls -né, -clef et leurs Variantes etant concer-
nés) connu. Ainsi, quasi-parz‘i,_,unique_chrétien-libéra/-conservateur est transformée en quasi-
_,_,parti,_,unique_chrétien-__/ibéral-__conservateur, ou « -_ » est, par convention, la marque des
preﬁxes. Il nous faut preciser a ce stade deux faits. Tout d’abord, le corpus considere est de tres
bonne qualite (150 mots du francais standard mal orthographies parmi 1,1 million de mots).
D’autre part, cette evaluation du correcteur—segmenteur nous a perrnis de realiser l’incomple—
tude du lexique, en particulier en ce qui concerne les mots d’emprunt a des langues etrangeres.

4 Analyseurs syntaxiques

Nous avons developpe deux analyseurs utilisant des forrnalismes, des architectures et des gram-
maires differents. Le premier, SXLFG, est un analyseur LFG a deux passes. Le second, FRMG,
est un analyseur TAG a une passe utilisant une grammaire qui est la representation compacte
d’une TAG avec structures de traits et qui est obtenue par compilation d’une meta—grammaire.

4.1 Analyseur SXLFG

Le systeme SXLFG (Boullier er al., 2005) permet de construire des analyseurs a partir de gram-
maires écrites dans une Variante du forrnalisme LFG (Lexical—Functional Grammars). Les gram-
maires sont donc des grammaires non—contextuelles (CFG) dites grammaires support dont les
regles dont decorees par des équationsfonctiormelles dont la resolution repose sur l’uniﬁcation.
Lors d’une analyse, les equations fonctionnelles sont calculees sur une representation compacte
des arbres d’analyse provenant de la grammaire support appelee forét partagée.En cas d’ambi—
guite, elle partage les sous—structures communes entre plusieurs analyses.

Pour obtenir un analyseur efﬁcace, nous effectuons les calculs d’equations fonctionnelles direc-
tement sur la forét partagee, et non sur chaque arbre d’analyse CFG. Ceci induit la speciﬁcite
de notre Variante de LFG : toute information calculee dans les structures fonctionnelles ne peut
l’étre que de maniere b0tt0m—up. En effet, puisque l’on effectue ces calculs sur la forét d’analyse
sans la modiﬁer, la structure fonctionnelle associee a la racine d’un sous—arbre ne peut dependre
que des structures associees a ses ﬁls. Dans le cas general, le resultat de ces calculs est un en-
semble de structures fonctionnelles associees a la racine de la forét. Si cet ensemble contient
plus d’un element, on peut par la suite appliquer des heuristiques de desambiguisation.

Notre analyseur est un analyseur robuste, et ce a plusieurs titres. Tout d’abord, l’analyseur CFG
dispose de mecanismes de rattrapage d’erreurs, perrnettant de traiter les cas ou la phrase d’en—
tree est agrammaticale pour la grammaire support (on parle de phrases n0n—valides pour la CF G

Chaines de traitement syntaxique

support). Ensuite, en cas d’echec du calcul des equations fonctionnelles, ces equations peuvent
étre as souplies et donner lieu a des resultats ayant divers degres d’imperfection. Par exemple, on
peut obtenir une structure pour toute la phrase d’entree mais qui ne respecte pas necessairement
certaines contraintes comme les cadres de sous—categorisation (on parle d’analyse sans veriﬁca-
tion de coherence, par opposition a une analyse qui se deroule correctement jusqu’au bout, dite
avec veriﬁcation de coherence). En cas d’echec de cet essai, des structures fonctionnelles cou-
vrant des portions disjointes de la phrase sont produites, qui sont appelees structures partielles.
Au pire, la phrase d’entree peut étre sur—segmentée, c’est—a—dire decoupee en sous—phrases (avec
5 niveaux de decoupage possibles) pour essayer d’en analyser des portions correctes.

Pour la campagne d’evaluation EASy, nous sommes partis d’une grammaire LFG du francais
developpee pour le systeme XLFG (Clement & Kinyon, 2001), que nous avons modiﬁee et com-
pletee. Sa couverture et le degre d’ambiguite de sa grammaire support sont encore ameliorables,
mais elle traite correctement un nombre respectable de phenomenes syntaxiques complexes.

4.2 Analyseur FRMG

L’ analyseur FRMG s’appuie sur une grammaire d’arbres adj oints (TAG) avec decorations engen-
dree a partir d’un niveau plus abstrait de description, une métmgrammaire (MG) (Candito, 1999;
Thomasset & de la Clergerie, 2005). La grammaire obtenue est tres compacte avec seulement
133 arbres, car elle s’appuie sur des arbresfactorisés utilisant des disjonctions entre noeuds, des
repetitions de noeuds et, surtout, des noeuds optionnels controles par des gardes. L’ancrage des
arbres par les entrees lexicales se fait par uniﬁcation de structures de traits appelees hypertags.

Un analyseur syntaxique hybride TAG/TIG“ a ete compile a partir de la grammaire. Il peut
prendre en entree les treillis produits par la chaine d’entree (section 3) modulo quelques conver-
sions pour construire les hypertags. Au demarrage de l’analyse, les arbres sont ﬁltres par rapport
aux mots du treillis d’entree, pour ne garder que ceux dont les noeuds d’ancrages et les noeuds
lexicaux sont compatibles avec ces mots. L’ analyseur utilise une strategie d’analyse tabulaire
descendante gauche—droite en une seule passe : le traitement des decorations des noeuds n’est
pas repousse dans une seconde passe, contrairement a la strategie SXLFG. Neanmoins, les de-
corations ne sont pas prises en compte pour les predictions descendantes mais seulement dans
les propagations de reponses. Le parcours des arbres factorises se fait sans expansion de ceux—ci
assurant une bonne efﬁcacite. L’ analyseur retourne soit une analyse complete du treillis d’en—
tree, soit, en mode robuste, un ensemble d’analyses partielles couvrant au mieux ce treillis. Les
analyses sont emises sous formes de foréts partagees de derivations TAG indiquant les diverses
operations effectuees (substitution, adjonction, ancrage,. . .) et ensuite converties en foréts par-
tagees de dependances (ﬁgure 2) servant de base pour les traitements post—syntaxiques.

ElF5l:m EIFSU E11771, E F8lme ElF9lde ElFl0H:1 ElFl llPm'npe

mi W=9° ‘’P |
El P‘°P32 N2 4’
mad :1dv:88
ElFllJe:1n ElF2lnbite “:46 N1 Pmpm ®
V

subject

np:50 V2 1 11

FIG. 2 — Forét de dependances (FRMG)

“Les TIG (Tree Insertion Grammars) sont une variantes des TAG faiblement équivalentes aux CFG.

109

110

P. Boullier, L. Clement, B. Sagot, E. de la Clergerie

5 Traitement post-syntaxique

Le format et la nature des informations attendus par les organisateurs de la campagne EASy
(Gendner & Vilnat, 2004) ne correspondent pas necessairement a nos propres formats et choix
linguistiques (cf. ﬁgure 3). D’autre part, les techniques tabulaires de partage de calculs mises
en oeuvre dans nos analyseurs sont en partie motivees par le souci d’obtenir l’ensemble des
analyses pour une phrase, alors que la piste d’evaluation de base pour EASy concerne des
analyses syntaxiques non ambigues. Il a donc ete necessaire de mettre en place des algorithmes
de desambiguisation et de conversion travaillant sur les structures partagees produites par nos
analyseurs. Ces travaux ont ete l’occasion d’explorer ce type d’algorithmes avec des approches
assez differentes dans les cas de SXLFG et de FRMG. Nous avons egalement dﬁ explorer diverses
regles heuristiques de desambiguisation et comprendre comment les exprimer.

GN 1 NV 2 GR 3 GP 4
Jean abite en outre au 1 , rue de la Pompe
F1 F2 F3 F4 F5 F6 F7 F8 F9 F10 F1 1
sujet Verbe complement Verbe modiﬁeur Verbe
GN1 NV2 GP4 NV2 GR3 NV2

FIG. 3 — Sortie EASy foumie par SXLFG et FRMG pour la meme phrase que precedemment

Dans le cas de FRMG, la desambiguisation et la conversion s’appuient sur les forets partagees
de dependances (section 4.2). Les arcs de dependance se pretent bien a l’expression d’heuris—
tiques de desambiguisation : chaque arc se voit attribuer un poids donne par la somme des poids
elementaires associes aux contraintes satisfaites par l’arc, avec, par exemple, un poids eleve
pour une dependance entre un verbe et un argument et moindre entre un verbe et un modiﬁeur.
Au niveau global, l’algorithme retient un ensemble d’arcs maximisant la somme de leurs poids
et tels que tout noeud soit accessible par un et un seul chemin. Neanmoins, pour des raisons
d’efﬁcacite, l’algorithme a ete (tardivement) complete par une notion de coﬁt régional associe
a un sous—ensemble d’arcs atteignables a partir d’un noeud. Une selection bomee des meilleurs
coﬁts regionaux est effectuee pour pro gressivement calculer un coﬁt global qui n’est plus neces-
sairement optimal. Quoique bien plus efﬁcace, l’algorithme reste encore trop lent dans certains
cas. Une analyse plus poussee du probleme (en partie aidee par l’approche suivie pour SXLFG)
suggere que trop d’informations sont perdues lors de la conversion des derivations en depen-
danceslz. En particulier, le format actuel n’indique pas si deux dependances issues d’un meme
mot appartiennent ou non a une meme analyse, ce qui necessite l’ajout de regles coﬁteuses fa-
vorisant les bonnes conﬁgurations. Nous prevoyons donc de faire evoluer notre notion de foret
partagee de dependances. Malgre ces problemes, nous avons pu constater l’adequation des arcs
de dependance pour exprimer des regles de desambiguisation ou de conversion.

Dans le systeme SXLFG, la phase de desambiguisation se fait par l’application successive d’un
certain nombre de regles sur les structures fonctionnelles associees a la racine de la foret d’ana—
lyse produite par la grammaire support. Chaque regle met en oeuvre un critere pour eliminer les
structures fonctionnelles non optimales au sens de ce critere. La derniere regle choisit au hasard
une analyse parmi celles qui restent. La foret d’analyse est alors elaguee pour n’y laisser que
1’ arbre” support correspondant a la structure fonctionnelle choisie. L’ extraction des constituants

12Ceci est dﬁ au fait que nos forets de dependances ont initialement ete congues pour une visualisation simpliﬁee
d’ un ensemble important d’ana1yses.
“En toute rigueur, plusieurs arbres peuvent subsister s’i1s correspondent a une structure fonctionnelle identique.

Chaines de traitement syntaxique

et des dependances demandes par EASy se fait alors en parcourant la structure fonctionnelle et
son arbre associe, a la recherche de motifs correspondant aux speciﬁcations de la campagne.
Cette phase est facilitee par le fait que l’analyse unique issue de la phase de desambiguisation a
ete prealablement extraite, a l’inverse de ce qui se passe dans le systeme FRMG.

6 Mise en aeuvre et resultats experimentaux

Le volume de donnees a analyser pour EASy, le nombre d’essais que nous voulions effectuer et
la complexite de la tache etaient sufﬁsamment consequents pour que nous decidions de ventiler
les analyses sur plusieurs machines, formant ainsi un cluster pour chaque systeme.

Les tableaux 3 a 5 presentent divers resultats concemant EASy mais aussi les corpus EUROTRA
et TSNLP. Les nombres de phrases different selon le systeme, en raison d’heuristiques diffe-
rentes de segmentation en phrases. Par ailleurs, le taux d ’ambigu'i'té moyen par mot n’est dispo-
nible que pour FRMG, car dans SXLFG les heuristiques de desambiguisation sont incorporees
dans l’analyseur. Ce taux est deﬁni comme le nombre moyen d’arcs de dependance atteignant
un mot moins un”.

Corpus #phrases % couv. temps d’ analyse amb.
moy. med. 2 1s 2 10s
EUROTRA 334 95.80% 1.81s 1.27s 61.68% 1.55% 0.7
TSNLP 1661 93.38% 0.72s 0.56s 22.03% 0.00% 0.4
EASy 34438 42.45% 5.55s 1.61s 64.41% 9.32% 0.6

TAB. 3 — Resultats pour FRMG, avec un timeout de 100 secondes15

Corpus #phrases couverture (sans couverture (avec temps d’analyse

verif. de coh.16) verif. de coh.) moy. med. 2 0.1s 2 1s
EUROTRA 334 94.61% 84.43% 0.33s 0.02s 22.2% 6.0%
TSNLP 1661 98.50% 79.12% 0.03s 0.00s 2.8% 0.6%
EASy 40859 66.62% 41.95% n.d.17

TAB. 4 — Resultats pour SXLFG, avec un timeout de 15 secondes15.

7 Conclusion

La campagne d’evaluation EASy nous a permis de mettre en evidence la difference considerable
qu’il y a entre le developpement d’un analyseur syntaxique et le developpement d’une chaine
complete d’analyse syntaxique. En effet, outre l’importance de la qualite de la grammaire et
de l’analyseur, cette campagne a montre le role non moins determinant de la couverture et de
la richesse du lexique, de la qualite de la chaine de traitement, de la precision des methodes
d’exploitation des sorties des analyseurs, ainsi que la tres forte interaction entre les differents
composants, et en particulier entre le lexique et la grammaire.

“Pour une phrase non—ambigue, chaque mot (sauf la « tete >> de la phrase) est atteint par un seul arc, d’ou un taux
d’ambigu'1‘te nul. Le nombre maximal d’ana1yses pour un taux 04 et une phrase de longueur n est en O((1 + 04)”).

16 On notera qu’un timeout plus eleve aurait augmente les taux de couverture mais egalement les temps d’analyse.

“Nous n’avons pas conserve les informations permettant de donner les temps sur le corpus EASy. Toutefois,
(Boullier et al., 2005) donne les temps d’analyse pour les 87.51% de phrases reconnues par la CFG support.

111

112

P. Boullier, L. Clement, B. Sagot, B. de la Clergerie

Corpus complet Phrases valides pour la CFG support
Analyse CFG Analyse CFG | Analyse complete
#phrases 40859 35756
nmoy — nmm 20.95 — 541 19.06 — 173
U Wmoy — U Wm” 0.79 — 97 0.75 — 65
Nombre med — max 32 028 — 3.1073 29 582 — 5.1052 1 — 1
d’analyses 2 1012 8.86% 7.84% 0%

TAB. 5 — Donnees sur les corpus“ et nombres d’analyses pour SXLFG, avant application de
l’heuristique de sur—segmentation.

Cette forte complementarite entre les differentes phases des chaines d’analyse syntaxique a
inevitablement elargi le champ de la campagne EASy. Ce n’est pas seulement l’analyse syn-
taxique elle—méme qui a ete evaluee lors de cette campagne, mais la capacite a mettre en place
des chaines d’analyse syntaxique completes”. Nous comptons exploiter le fait que nous avons
deploye deux chaines de traitement que tout separe sauf le lexique et la chaine pre—syntaxique.
Ceci nous permettra d’effectuer des comparaisons et d’ ameliorer ainsi grammaires et analyseurs
(en etudiant les differences entre nos resultats), mais aussi le lexique et la chaine de traitement
pre—syntaxique (en etudiant les erreurs communes).

References

BOULLIER P., SAGOT B. & CLEMENT L. (2005). Un analyseur LFG efﬁcace : SXLFG. In Actes de
TALN’05, Dourdan, France.

CANDITO M.—H. (1999). Organisation modulaire et parametrable de grammaires e’lectroniques lexica-
lise’es. PhD thesis, Universite Paris 7.

CLEMENT L. & KINYON A. (2001). XLFG—an LFG parsing scheme for French. In Proc. of LF G’0I .
CLEMENT L. & SAGOT B. (2004). Site internet du Lefff (Lexique des Forrnes Flechies du Frangais).
www. lefff . net.

CLEMENT L., SAGOT B. & LANG B. (2004). Morphology Based Automatic Acquisition of Large-
coverage Lexica. In Proceedings of LREC’04, p. 1841-1844.

GENDNER V. & VILNAT A. (2004). Les annotations syntaxiques de reference PEAS. En ligne sur
www . limsi . fr/Recherche/CORVAL/easy/PEAS_referer1ce_ar1r1otatior1s_vl . 6 . html.
GREFENSTETTE G. & TAPANAINEN P. (1994). What is a word, what is a sentence ‘.7 Problems of
tokenization. In Proceedings of the 3rd CCLT R, Budapest, Hungary.

MAYNARD D., TABLAN V., URSU C., CUNNINGHAM H. & WILKS Y. (2001). Named entity recogni-
tion from diverse text types. In Proceedings of RANLP 2001, Tzigov Chark, Bulgaria.

SAGOT B. & BOULLIER P. (2005). From raw corpus to word lattices : robust pre—parsing processing. In
Actes de L&T C 2005, Poznan, Pologne.

SAGOT B., CLEMENT L., ERIC VILLEMONTE DE LA CLERGERIE & BOULLIER P. (2005). Vers un
meta—lexique pour le frangais : architecture, acquisition, utilisation. In Joiirnee ATALA sur l’interface
lexique—grammaire. http ://www . atala . org/article . php3 ?icl_article=24 0.

THOMASSET F. & DE LA CLERGERIE E. V. (2005). Comment obtenir plus des meta—grammaires. In
Actes de TALN’05, Dourdan, France.

“Pour les donnees sur les corpus, n designe un nombre de mots, et UW un nombre de mots inconnus.
19En outre, 1’harmonisation des resultats des differents participants passe par une segmentation commune en
phrases et en mots, differente de celle produite et utilisee par nos outils, qui a dﬁ etre conservee en permanence.

