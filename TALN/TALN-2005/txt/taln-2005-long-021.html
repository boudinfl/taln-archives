<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Am&#233;lioration de la segmentation automatique des textes gr&#226;ce aux connaissances acquises par l'analyse s&#233;mantique latente</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2005, Dourdan, 6-10 juin 2005 
</p>
<p>Am&#233;lioration de la segmentation automatique des textes gr&#226;ce aux 
connaissances acquises par l'analyse s&#233;mantique latente. 
</p>
<p>Yves Bestgen 
</p>
<p>Centre pour l'&#233;tude du texte et du discours &#8211; PSOR - Universit&#233; catholique de Louvain 
</p>
<p>Place du Cardinal Mercier, 10 - B1348 Louvain-la-Neuve Belgique 
</p>
<p>yves.bestgen@psp.ucl.ac.be 
</p>
<p>Mots-cl&#233;s :   Segmentation automatique de textes, Analyse s&#233;mantique latente (ASL) 
Keywords:   Automatic text segmentation, Latent semantic analysis (LSA) 
</p>
<p>R&#233;sum&#233; Choi, Wiemer-Hastings et Moore (2001) ont propos&#233; d'employer l'analyse 
s&#233;mantique latente (ASL) pour extraire des connaissances s&#233;mantiques &#224; partir de corpus afin 
d'am&#233;liorer l'efficacit&#233; d'un algorithme de segmentation des textes. En comparant l'efficacit&#233; 
du m&#234;me algorithme selon qu'il prend en compte des connaissances s&#233;mantiques 
compl&#233;mentaires ou non, ils ont pu montrer les b&#233;n&#233;fices apport&#233;s par ces connaissances. 
Dans leurs exp&#233;riences cependant, les connaissances s&#233;mantiques avaient &#233;t&#233; extraites d'un 
corpus qui contenait les textes &#224; segmenter dans la phase de test. Si cette hypersp&#233;cificit&#233; du 
corpus d'apprentissage explique la plus grande partie de l'avantage observ&#233;, on peut se 
demander s'il est possible d'employer l'ASL pour extraire des connaissances s&#233;mantiques 
g&#233;n&#233;riques pouvant &#234;tre employ&#233;es pour segmenter de nouveaux textes. Les deux exp&#233;riences 
pr&#233;sent&#233;es ici montrent que la pr&#233;sence dans le corpus d'apprentissage du mat&#233;riel de test a un 
effet important, mais &#233;galement que les connaissances s&#233;mantiques g&#233;n&#233;riques d&#233;riv&#233;es de 
grands corpus am&#233;liorent l'efficacit&#233; de la segmentation. 
</p>
<p>Abstract Choi, Wiemer-Hastings and Moore (2001) proposed to use latent Semantic 
Analysis to extract semantic knowledge from corpora in order to improve the accuracy of a 
text segmentation algorithm. By comparing the accuracy of the very same algorithm 
depending on whether or not it takes into account complementary semantic knowledge, they 
were able to show the benefit derived from such knowledge. In their experiments, semantic 
knowledge was, however, acquired from a corpus containing the texts to be segmented in the 
test phase. If this hyper-specificity of the training corpus explains the largest part of the 
benefit, one may wonder  if it is possible to use LSA to acquire generic semantic knowledge 
that can be used to segment new texts. The two experiments reported here show that the 
presence of the test materials in the training corpus has an important effect, but also that the 
generic semantic knowledge derived from large corpora clearly improves the segmentation 
accuracy. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Yves Bestgen 
</p>
<p>1 Am&#233;liorer la segmentation des textes par l'adjonction de 
connaissances s&#233;mantiques compl&#233;mentaires? 
</p>
<p>Pendant les dix derni&#232;res ann&#233;es, de nombreuses m&#233;thodes ont &#233;t&#233; propos&#233;es pour segmenter 
automatiquement des textes en fonction des th&#232;mes qui les composent sur la base de la 
coh&#233;sion lexicale. La distinction principale entre ces m&#233;thodes r&#233;side dans le contraste entre 
les approches bas&#233;es exclusivement sur l'information contenue dans le texte &#224; segmenter 
comme la coh&#233;sion lexicale (par exemple, Choi, 2000 ; Hearst, 1997 ; Heinonen, 1998 ; 
Kehagias, Pavlina, Petridis, 2003 ; Utiyama, Isahara, 2001), et celles qui reposent sur des 
connaissances s&#233;mantiques compl&#233;mentaires extraites de dictionnaires et de thesaurus (par 
exemple, Kozima 1993 ; Lin, Nunamaker, Chau, Chen, 2004 ; Morris, Hirst, 1991), ou des 
collocations observ&#233;es dans de grands corpus (Bolshakov, Gelbukh 2001 ; Choi et al., 2001 ; 
Ferret, 2002 ; Kaufmann, 1999 ; Ponte, Croft, 1997). Selon leurs auteurs, les m&#233;thodes qui 
utilisent des connaissances suppl&#233;mentaires apportent une r&#233;ponse aux probl&#232;mes pos&#233;s par 
les phrases qui rel&#232;vent du m&#234;me th&#232;me tout en ne partageant aucun mot commun ou par la 
pr&#233;sence de synonymes et d'hyperonymes. Des arguments empiriques en faveur de ces 
m&#233;thodes ont &#233;t&#233; r&#233;cemment pr&#233;sent&#233;s par Choi et al. (2001) dans une &#233;tude bas&#233;e sur 
l'analyse s&#233;mantique latente (ASL : Latent semantic analysis, Latent semantic indexing, 
Deerwester et al., 1990), une technique statistique d'extraction d'espaces s&#233;mantiques &#224; partir 
de corpus qui permet l'estimation de la similarit&#233; s&#233;mantique entre des mots, des phrases ou 
des paragraphes. En comparant l'efficacit&#233; du m&#234;me algorithme selon qu'il prend en compte 
ou non ces connaissances s&#233;mantiques compl&#233;mentaires, Choi et al. (2001) ont mis en 
&#233;vidence l'avantage d&#233;riv&#233; de telles connaissances.  
</p>
<p>Toutefois, les implications de l'&#233;tude de Choi et al. pour la segmentation des textes et, plus 
g&#233;n&#233;ralement, pour l'utilisation de l'ASL dans le traitement automatique du langage sont 
rendues peu claires en raison de la m&#233;thodologie qu'ils ont employ&#233;e. Dans leurs exp&#233;riences, 
les connaissances s&#233;mantiques ont &#233;t&#233; extraites d'un corpus qui contenait les textes qui ont &#233;t&#233; 
segment&#233;s dans la phase de test. On peut donc se demander si la plus grande partie des 
b&#233;n&#233;fices obtenus par l'ajout de connaissances s&#233;mantiques n'est pas due &#224; cette 
hypersp&#233;cificit&#233; du corpus d'apprentissage (c.-&#224;-d. inclure le mat&#233;riel de test). Si c'est le cas, 
cela met en question la possibilit&#233; d'employer l'ASL pour extraire des connaissances 
s&#233;mantiques g&#233;n&#233;riques pouvant &#234;tre utilis&#233;es pour segmenter de nouveaux textes. A priori, le 
probl&#232;me ne semble pas tr&#232;s important, parce que Choi et al. ont utilis&#233; un grand nombre de 
petits &#233;chantillons de test pour &#233;valuer leur algorithme, chaque &#233;chantillon ne repr&#233;sentant en 
moyenne que 0.15% du corpus d'apprentissage. La pr&#233;sente &#233;tude montre, toutefois, que la 
pr&#233;sence du mat&#233;riel de test dans le corpus d'apprentissage a un effet important, mais 
&#233;galement que les connaissances s&#233;mantiques g&#233;n&#233;riques d&#233;riv&#233;es de grands corpus 
am&#233;liorent nettement l'efficacit&#233; de l'algorithme de segmentation. Cette conclusion est issue 
de deux exp&#233;riences dans lesquelles la pr&#233;sence ou l'absence du mat&#233;riel de test dans le 
corpus d'apprentissage pour l'ASL est manipul&#233;e. La premi&#232;re exp&#233;rience est bas&#233;e sur le 
mat&#233;riel employ&#233; par Choi et al., un petit corpus de 1.000.000 de mots. La deuxi&#232;me 
exp&#233;rience est bas&#233;e sur un corpus beaucoup plus grand (25.000.000 mots). Avant de 
pr&#233;senter ces exp&#233;riences, l'algorithme et l'utilisation par Choi et al. de l'ASL dans ce cadre 
sont d&#233;crits. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Am&#233;lioration de la segmentation automatique des textes 
</p>
<p>2  Les deux versions de l'algorithme de Choi 
L'algorithme de segmentation propos&#233; par Choi (2000) se compose des trois &#233;tapes 
habituellement pr&#233;sentes dans les proc&#233;dures de segmentation bas&#233;es sur la coh&#233;sion lexicale. 
Premi&#232;rement, le document &#224; segmenter est divis&#233; en unit&#233;s textuelles minimales, 
habituellement les phrases. Ensuite, un indice de similarit&#233; entre chaque paire d'unit&#233;s prises 
deux par deux est calcul&#233;. Chaque valeur brute de similarit&#233; est r&#233;exprim&#233;e sous une forme 
ordinale en prenant la proportion de valeurs voisines qui sont plus petites qu'elle. Pour finir, le 
document est segment&#233; r&#233;p&#233;titivement selon les fronti&#232;res entre les unit&#233;s qui maximisent la 
somme des similarit&#233;s moyennes &#224; l'int&#233;rieur des segments ainsi constitu&#233;s.  
</p>
<p>L'&#233;tape la plus int&#233;ressante pour la pr&#233;sente &#233;tude est celle qui calcule les similarit&#233;s 
interphrases. La proc&#233;dure initialement propos&#233;e par Choi (2000), C99, reposait 
exclusivement sur l'information contenue dans le texte &#224; segmenter. Chaque phrase est 
repr&#233;sent&#233;e par un vecteur construit selon le mod&#232;le vectoriel classique (Manning, Sch&#252;tze, 
1999, pp. 539ff) et la similarit&#233; entre deux phrases est calcul&#233;e au moyen de la mesure de 
cosinus entre les vecteurs correspondants. Dans une premi&#232;re &#233;valuation bas&#233;e sur la 
proc&#233;dure d&#233;crite ci-dessous, Choi a montr&#233; que son algorithme &#233;tait plus efficace que 
plusieurs autres approches telles que TextTilling (Hearst, 1994), Segmenter (Kan, Klavans, 
McKeown, 1998) et le Maximum-probability segmentation algorithm de Utiyama et Isahara 
(2001).  
</p>
<p>Choi et al. (2001) ont propos&#233; d'am&#233;liorer la mesure de similarit&#233; inter-phrases en prenant en 
compte les proximit&#233;s s&#233;mantiques entre les mots estim&#233;es sur la base de l'analyse s&#233;mantique 
latente (ASL). Bri&#232;vement, l'ASL s'appuie sur la th&#232;se qu'il est possible d'estimer la similarit&#233; 
s&#233;mantique entre des mots en analysant les contextes dans lesquels ces mots apparaissent 
(Deerwester et al. 1990 ; Degand, Spooren, Bestgen, 2004 ; Landauer, Dumais 1997). La 
premi&#232;re &#233;tape d'une analyse s&#233;mantique latente consiste en la construction d'un tableau 
lexical contenant les fr&#233;quences d'occurrence de chaque mot dans chacun des documents, un 
document pouvant &#234;tre une phrase, un paragraphe, un texte, ... Pour extraire les dimensions 
s&#233;mantiques, ce tableau lexical subit une d&#233;composition en valeurs singuli&#232;res, une sorte 
d'analyse factorielle qui extrait les dimensions orthogonales les plus importantes. Apr&#232;s cette 
&#233;tape, chaque mot est repr&#233;sent&#233; par un vecteur de poids indiquant sa force d'association avec 
chacune des dimensions. Ceci permet de mesurer la proximit&#233; s&#233;mantique entre deux mots 
quelconques en utilisant, par exemple, la mesure de cosinus entre les vecteurs correspondants. 
La proximit&#233; entre deux phrases (ou toutes autres unit&#233;s textuelles), m&#234;me lorsque ces phrases 
ne font pas partir du corpus initial, peut &#234;tre estim&#233;e en calculant un vecteur pour chacune de 
ces phrases -- correspondant &#224; la somme pond&#233;r&#233;e des vecteurs des mots qui les composent -- 
et puis en calculant le cosinus entre ces vecteurs (Deerwester et al. 1990). Choi et al. (2001) 
ont montr&#233; que l'utilisation de cette proc&#233;dure pour calculer les similarit&#233;s inter-phrases 
produit des performances sup&#233;rieures &#224; celles enregistr&#233;es au moyen de la version pr&#233;c&#233;dente 
de l'algorithme (bas&#233; seulement sur la r&#233;p&#233;tition de mots).  
</p>
<p>3 Exp&#233;rience 1 
Le but de cette exp&#233;rience est de d&#233;terminer l'impact de la pr&#233;sence du mat&#233;riel de test dans le 
corpus d'apprentissage de l'ASL sur les r&#233;sultats obtenus par Choi et al. (2001). Est-ce que les 
connaissances s&#233;mantiques extraites d'un corpus qui n'inclut pas le mat&#233;riel de test am&#233;liorent 
&#233;galement l'efficacit&#233; de la segmentation ?  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Yves Bestgen 
</p>
<p>3.1 M&#233;thode 
</p>
<p>Cette exp&#233;rience est bas&#233;e sur la m&#233;thodologie d&#233;velopp&#233;e par Choi (2000). Cette 
m&#233;thodologie a &#233;t&#233; &#233;galement employ&#233;e par plusieurs auteurs pour &#233;valuer l'efficacit&#233; de leur 
syst&#232;me de segmentation (Brants, Chen, Tsochantaridis, 2002 ; Ferret, 2002 ; Kehagias et al., 
2003 ; Utiyama, Isahara, 2001). La t&#226;che consiste &#224; retrouver les fronti&#232;res entre des textes 
concat&#233;n&#233;s. Chaque &#233;chantillon de test est une concat&#233;nation de dix segments de textes. 
Chaque segment est compos&#233; des n premi&#232;res phrases d'un texte al&#233;atoirement choisi dans 
deux sous-sections du corpus de Brown. Pour l'exp&#233;rience, j'ai utilis&#233; le mat&#233;riel de test le 
plus g&#233;n&#233;ral propos&#233; par Choi (2000) dans lequel la taille des segments dans chaque 
&#233;chantillon varie al&#233;atoirement de 3 &#224; 11 phrases. Il est compos&#233; de 400 &#233;chantillons.  
</p>
<p>L'exp&#233;rience vise &#224; comparer l'efficacit&#233; de l'algorithme selon que le mat&#233;riel de test est inclus 
dans le corpus d'apprentissage de l'ASL (condition non autonome) ou qu'il ne l'est pas 
(condition autonome). Un espace s&#233;mantique non autonome, correspondant &#224; celui utilis&#233; par 
Choi et al., a &#233;t&#233; construit en utilisant l'enti&#232;ret&#233; du corpus de Brown comme corpus 
d'apprentissage. Quatre cents espaces autonomes diff&#233;rents ont &#233;t&#233; construits, un pour chaque 
&#233;chantillon de test, en retirant &#224; chaque fois du corpus de Brown uniquement les phrases qui 
composent cet &#233;chantillon.  
</p>
<p>Pour extraire l'espace s&#233;mantique par l'ASL et pour appliquer l'algorithme de segmentation, 
une s&#233;rie de param&#232;tres ont d&#251; &#234;tre fix&#233;s. Tout d'abord, les paragraphes ont &#233;t&#233; utilis&#233;s comme 
documents pour construire le tableau lexical parce que Choi et al. ont observ&#233; que de telles 
unit&#233;s de taille moyenne &#233;taient plus efficaces que des unit&#233;s plus courtes comme les phrases. 
Les mots repris dans la liste de mots-outils (stoplist) de Choi ont &#233;t&#233; supprim&#233;s, ainsi que 
ceux qui n'apparaissaient qu'une seule fois dans l'ensemble du corpus. Les mots n'ont pas &#233;t&#233; 
tronqu&#233;s en fonction de leur racine (stemming), suivant en cela la proc&#233;dure de Choi et al. 
(2001). Pour &#233;tablir l'espace s&#233;mantique, la d&#233;composition en valeurs singuli&#232;res a &#233;t&#233; r&#233;alis&#233;e 
par le programme SVDPACKC (Berry, 1992 ; Berry et al., 1993), et les 300 premiers 
vecteurs singuliers ont &#233;t&#233; conserv&#233;s. En ce qui concerne l'algorithme de segmentation, j'ai 
utilis&#233; la version dans laquelle le nombre de fronti&#232;res &#224; trouver est impos&#233; et fix&#233; ici &#224; neuf. 
Un masque de 11 x 11 a &#233;t&#233; employ&#233; pour la transformation ordinale, comme recommand&#233; 
par Choi (2000).  
</p>
<p>3.2 R&#233;sultats 
</p>
<p>L'efficacit&#233; de la segmentation a &#233;t&#233; &#233;valu&#233;e au moyen de l'indice utilis&#233; par Choi et al. 
(2001) : le taux Pk d'erreur de segmentation (Beeferman, Berger, Lafferty, 1999) qui indique 
la proportion de phrases qui sont incorrectement class&#233;es comme appartenant au m&#234;me 
segment ou incorrectement class&#233;es comme appartenant &#224; des segments diff&#233;rents.  
</p>
<p>Les r&#233;sultats1 sont pr&#233;sent&#233;s dans la Figure 1. Les espaces autonomes donnent lieu &#224; des 
performances plus faibles que l'espace non autonome, comme le confirme le test t pour 
&#233;chantillon appareill&#233; (chaque &#233;chantillon de test &#233;tant utilis&#233; comme une observation) qui est 
                                                 
1  Ce taux d'erreur est en fait l&#233;g&#232;rement meilleur que celui obtenu par Choi et al. (2001), la diff&#233;rence pouvant 
</p>
<p>&#234;tre due &#224; plusieurs facteurs tels que le pr&#233;traitement du corpus de Brown (identification des mots et des 
paragraphes) ou la fonction de pond&#233;ration appliqu&#233;e aux fr&#233;quences brutes, qui &#233;tait ici la formule de 
pond&#233;ration d&#233;crite dans Landauer, Foltz, et Laham (1998). </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Am&#233;lioration de la segmentation automatique des textes 
</p>
<p>significatif pour un alpha plus petit que 0.0001. L'algorithme C99, qui n'utilise pas l'ASL pour 
estimer les similarit&#233;s entre les phrases, produit un Pk de 0.13 (Choi et al., 2001, tableau 3, 
ligne 3 : no stemming). Il s'av&#232;re donc que, si la condition autonome est meilleure que C99, 
l'avantage est tr&#232;s faible.  
</p>
<p> Pk 
</p>
<p>Non autonome 0.084  (0.005) 
</p>
<p>Autonome 0.120  (0.006) 
</p>
<p>Figure 1 : Taux d'erreur et variance (entre parenth&#232;ses) pour les conditions non autonome et 
autonome.  
</p>
<p>Avant de conclure que la pr&#233;sence du mat&#233;riel de test dans le corpus d'apprentissage de l'ASL 
a fortement modifi&#233; l'espace s&#233;mantique, une explication alternative doit &#234;tre consid&#233;r&#233;e. La 
perte d'efficacit&#233; en condition autonome pourrait &#234;tre due au fait qu'il y a syst&#233;matiquement 
l&#233;g&#232;rement moins de mots index&#233;s dans les espaces s&#233;mantiques autonomes que dans l'espace 
non autonome. La suppression de chaque &#233;chantillon de test a entra&#238;n&#233; la perte en moyenne de 
23 mots diff&#233;rents sur un total de 25.847 mots qui sont index&#233;s dans l'espace non autonome. 
Dans les espaces autonomes, ces mots ne sont pas disponibles pour estimer la similarit&#233; entre 
les phrases, tandis qu'ils sont utilis&#233;s dans l'espace non autonome. Afin de d&#233;terminer si ce 
facteur peut expliquer la diff&#233;rence d'efficacit&#233;, une analyse compl&#233;mentaire a &#233;t&#233; effectu&#233;e 
sur l'espace non autonome dans laquelle, pour chaque &#233;chantillon de test, uniquement les mots 
pr&#233;sents dans l'espace autonome correspondant ont &#233;t&#233; pris en compte. De cette mani&#232;re, 
seules les relations s&#233;mantiques peuvent jouer. Compar&#233; &#224; l'espace non autonome complet, je 
n'ai observ&#233; presque aucune diminution d'efficacit&#233;, le taux d'erreur Pk passant de 0.084 &#224; 
0.085 dans la nouvelle analyse. Ce r&#233;sultat indique que ce ne sont pas les mots choisis pour le 
calcul des proximit&#233;s qui importent, mais les relations s&#233;mantiques dans les espaces.  
</p>
<p>4 Exp&#233;rience 2 
L'exp&#233;rience 1 a &#233;t&#233; men&#233;e sur le corpus d'apprentissage de Choi et al. (2001), un corpus de 
1.000.000 de mots issus de textes de genres et de th&#232;mes tr&#232;s diff&#233;rents. La petite taille du 
corpus et la diversit&#233; des textes pourraient avoir affect&#233; les r&#233;sultats de deux mani&#232;res. 
D'abord, l'impact de la pr&#233;sence du mat&#233;riel de test dans le corpus d&#233;pend probablement de 
ces caract&#233;ristiques du corpus. Retirer les premi&#232;res phrases d'un texte devrait avoir moins 
d'effet si le corpus contient beaucoup de textes sur des th&#232;mes similaires. En second lieu, un 
corpus plus volumineux permettrait probablement l'extraction d'un espace s&#233;mantique plus 
stable et plus efficace. Ceci pourrait produire une plus grande diff&#233;rence entre la version 
&quot;ASL&quot; de l'algorithme et celle qui n'utilise pas de connaissances s&#233;mantiques suppl&#233;mentaires 
(C99). Pour ces raisons, une deuxi&#232;me exp&#233;rience a &#233;t&#233; men&#233;e sur la base d'un corpus 
beaucoup plus volumineux, comprenant les articles parus durant les ann&#233;es 1997 et 1998 dans 
le journal de langue fran&#231;aise belge Le Soir (approximativement 52.000 articles et 26.000.000 
mots). Dans ce corpus, chaque &#233;chantillon du mat&#233;riel de test correspond en moyenne &#224; 
0.0066% du corpus complet. Cette deuxi&#232;me exp&#233;rience a &#233;galement permis de comparer les 
conditions non autonome et autonome &#224; une condition ant&#233;rieure bas&#233;e sur les articles parus 
dans le m&#234;me journal, mais pendant les ann&#233;es 1995 et 1996 (approximativement 50.000 
articles et plus de 22.000.000 mots). Cette condition nous informera &#224; propos de la possibilit&#233; </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Yves Bestgen 
</p>
<p>d'employer l'ASL pour extraire des connaissances s&#233;mantiques plus g&#233;n&#233;riques, puisque le 
corpus d'apprentissage de l'ASL est ant&#233;rieur aux textes &#224; segmenter. Il faut toutefois noter 
que ces connaissances &#233;tant extraites de la m&#234;me source journalistique, les qualifier 
d'ind&#233;pendantes seraient nettement excessifs. 
</p>
<p>4.1 M&#233;thode 
</p>
<p>Le mat&#233;riel de test a &#233;t&#233; extrait du corpus 1997-1998 suivant les directives donn&#233;es dans Choi 
(2000). Il se compose de 100 &#233;chantillons de dix segments, dont la longueur varie 
al&#233;atoirement de 3 &#224; 11 phrases. Trois types d'espace d'apprentissage pour l'ASL ont &#233;t&#233; 
construits. L'espace non autonome est bas&#233; sur l'enti&#232;ret&#233; du corpus 1997-1998. Cent espaces 
autonomes diff&#233;rents ont &#233;t&#233; construits comme d&#233;crit dans l'exp&#233;rience 1. Enfin, un espace 
ant&#233;rieur a &#233;t&#233; &#233;tabli &#224; partir du corpus 1995-1996. Les param&#232;tres utilis&#233;s pour extraire les 
espaces s&#233;mantiques sont identiques &#224; ceux employ&#233;s dans l'exp&#233;rience 1 sauf que, pour 
r&#233;duire la taille des tableaux lexicaux. les articles, et non les paragraphes, ont &#233;t&#233; utilis&#233;s 
comme documents et les mots ont &#233;t&#233; lemmatis&#233;s au moyen de TreeTagger (Schmid 1994).  
</p>
<p>4.2 R&#233;sultats 
</p>
<p>Globalement, les r&#233;sultats sont similaires &#224; ceux obtenus lors de la premi&#232;re exp&#233;rience. 
Comme le montre la Figure 2, les espaces autonomes donnent lieu &#224; des performances plus 
faibles que l'espace non autonome et, comme attendu, l'espace ant&#233;rieur donne lieu &#224; des 
performances encore plus faibles.  
</p>
<p> Pk 
</p>
<p>Non autonome 0.074   (0.004) 
</p>
<p>Autonome 0.084   (0.005) 
</p>
<p>Ant&#233;rieure 0.098   (0.005) 
</p>
<p>Figure 2 : Taux d'erreur et variance (entre parenth&#232;ses) pour les conditions non autonome, 
autonome et ant&#233;rieure. 
</p>
<p>Toutefois, il est important de noter que l'algorithme C99, qui n'est pas bas&#233; sur l'analyse 
s&#233;mantique latente, produit un taux d'erreur Pk de 0.155, soit une valeur nettement plus 
mauvaise que celles obtenues avec les espaces autonomes (0.084) et avec l'espace ant&#233;rieur 
(0.098). Ceci confirme l'utilit&#233; des connaissances s&#233;mantiques extraites de grands corpus pour 
estimer les similarit&#233;s interphrases. 
</p>
<p>Par rapport &#224; la premi&#232;re exp&#233;rience, l'&#233;cart entre les conditions non autonome et autonome 
est beaucoup plus faible, passant de 0.036 pour l'exp&#233;rience 1 &#224; 0.01 pour l'exp&#233;rience 2. Cet 
&#233;cart demeure n&#233;anmoins statistiquement significatif (t(99) = 3.17; p = 0.002). Bien que plus 
grand, l'&#233;cart entre les conditions autonome et ant&#233;rieure (0.014), est statistiquement juste 
significatif (t(99) = 2.04; p = 0.045). La Figure 3 montre que la condition autonome surpasse 
la condition ant&#233;rieure dans 46 &#233;chantillons, alors que l'inverse se produit dans 35 
&#233;chantillons, les 19 &#233;chantillons restants ne montrant aucune diff&#233;rence entre ces deux 
conditions.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Am&#233;lioration de la segmentation automatique des textes 
</p>
<p> 
</p>
<p>Figure 3 : Distribution des diff&#233;rences en Pk entre les conditions Autonome et Ant&#233;rieure 
</p>
<p>On voit donc que l'avantage de la condition autonome sur la condition ant&#233;rieure est 
principalement d&#251; &#224; quelques &#233;chantillons de test pour lesquels la condition autonome est 
nettement plus efficace. Rappelons &#233;galement que la condition ant&#233;rieure donne lieu &#224; des 
r&#233;sultats nettement meilleurs que ceux obtenus lorsque la segmentation s'effectue sans le 
recours &#224; des connaissances s&#233;mantiques compl&#233;mentaires. 
</p>
<p>5 Conclusion 
Les deux exp&#233;riences rapport&#233;es ici montrent que la pr&#233;sence du mat&#233;riel de test dans le 
corpus d'apprentissage de l'ASL augmente l'efficacit&#233; de l'algorithme de segmentation m&#234;me 
lorsqu'un corpus de plus de 25.000.000 mots est utilis&#233;. Elles montrent &#233;galement que 
l'utilisation de connaissances s&#233;mantiques ind&#233;pendantes am&#233;liore l'efficacit&#233; de la 
segmentation et que ceci s'observe m&#234;me lorsque ces connaissances sont extraites d'ann&#233;es 
ant&#233;rieures de la m&#234;me source. Cette observation souligne la possibilit&#233; de constituer par 
analyse s&#233;mantique latente des connaissances s&#233;mantiques plus ou moins g&#233;n&#233;riques, c'est-&#224;-
dire, des connaissances qui peuvent &#234;tre utilis&#233;es pour traiter de nouvelles donn&#233;es, comme 
cela a &#233;t&#233; r&#233;cemment propos&#233; dans la recherche de l'ant&#233;c&#233;dent d'une anaphore, dans un 
syst&#232;me de reconnaissance de la parole ou en traduction automatique (Bellegarda, 2000 ; 
Klebanov, Wiemer-Hastings, 2002 ; Kim, Chang, Zhang, 2003). Une question &#224; laquelle la 
pr&#233;sente &#233;tude ne r&#233;pond pas concerne la possibilit&#233; d'utiliser un corpus tir&#233; d'une autre 
source, telle qu'un autre journal. Bellegarda (2000) a observ&#233;, en reconnaissance automatique 
de la parole, qu'un tel espace s&#233;mantique est moins efficace. Cependant, &#233;valuer la proximit&#233; 
s&#233;mantique entre deux phrases est probablement moins affect&#233; par la source du corpus que de 
pr&#233;dire le prochain mot d'un &#233;nonc&#233;.  
</p>
<p>R&#233;cemment, plusieurs auteurs ont propos&#233; des algorithmes de segmentation, bas&#233;s 
principalement sur la programmation dynamique, qui &#233;galent ou m&#234;me surpassent les r&#233;sultats 
de Choi (Ji, Zha, 2003, Kehagias et al., 2003 ; Utiyama, Isahara, 2001). Ces algorithmes ne 
s'appuient pas sur des connaissances s&#233;mantiques suppl&#233;mentaires. Les r&#233;sultats de la pr&#233;sente 
&#233;tude sugg&#232;rent que leur efficacit&#233; pourrait encore &#234;tre am&#233;lior&#233;e en prenant en compte de 
telles connaissances. Enfin, d'autres techniques que l'ASL ont &#233;t&#233; propos&#233;es pour extraire des 
connaissances s&#233;mantiques &#224; partir de grands corpus tel pASL (Brants et al., 2002). L'analyse 
s&#233;mantique latente &#233;tant relativement simple &#224; mettre en pratique gr&#226;ce &#224; la disponibilit&#233; de </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Yves Bestgen 
</p>
<p>programmes tr&#232;s puissants tel que SVDPACKC (Berry et al., 1993), son avantage principal 
est qu'elle est employ&#233;e par une communaut&#233; de plus en plus large de chercheurs.  
</p>
<p>Une limitation importante de ce travail r&#233;side dans la t&#226;che employ&#233;e pour &#233;valuer l'efficacit&#233; 
de l'algorithme de segmentation. Identifier les fronti&#232;res entre des textes concat&#233;n&#233;s est une 
t&#226;che artificielle et certainement moins complexe que de localiser les changements de th&#232;mes 
&#224; l'int&#233;rieur de textes. Le fait que la proc&#233;dure et le mat&#233;riel con&#231;u par Choi soient devenus 
une sorte de &quot;standard&quot; employ&#233; par une s&#233;rie de chercheurs pour &#233;valuer leur algorithme ne 
suffit pas &#224; la l&#233;gitimer. Il serait donc utile de confirmer les conclusions de la pr&#233;sente &#233;tude 
dans une t&#226;che de segmentation intratexte. 
</p>
<p> 
</p>
<p>Remerciements 
Y. Bestgen est chercheur qualifi&#233; du Fonds National de la Recherche (FNRS).  Cette 
recherche est financ&#233;e par le projet FRFC n&#176; 2.4535.02 et par une &#8220;Action de Recherche 
concert&#233;e&#8221; du Gouvernement de la Communaut&#233; fran&#231;aise de Belgique. 
</p>
<p>R&#233;f&#233;rences 
BEEFERMAN D., BERGER A., LAFFERTY J. (1999). Statistical models for text segmentation, 
Machine Learning, Vol. 34, pp. 177&#8211;210. 
</p>
<p>BELLEGARDA J. (2000). Large vocabulary speech recognition with multispan statistical 
language models. IEEE Transactions on Speech and Audio Processing, Vol. 8, pp. 78-84. 
</p>
<p>BERRY M. (1992). Large scale singular value computation. International jornal of 
Supercomputer Application, Vol. 6, 13-49. 
</p>
<p>BERRY M., DO T., O'BRIEN G., KRISHNA V., VARADHAN S. (1993). SVDPACKC: Version 1.0 
user's guide, Tech. Rep. CS-93-194, University of Tennessee, Knoxville, TN, October 1993. 
</p>
<p>BOLSHAKOV I., GELBUKH A. (2001). Text segmentation into paragraphs based on local text 
cohesion. In Proceedings of Text, Speech and Dialogue (TSD-2001), 158&#8211;166. 
</p>
<p>BRANTS T., CHEN, F., TSOCHANTARIDIS I. (2002). Topic-based document segmentation with 
probabilistic latent semantic analysis. In Proceedings of CIKM&#8217;02, 211-218 
</p>
<p>CHOI F. (2000). Advances in domain independent linear text segmentation, In Proceedings of 
NAACL-00, 26&#8211;33. 
</p>
<p>CHOI F., WIEMER-HASTINGS P., MOORE J. (2001) Latent semantic analysis for text 
segmentation, In Proceedings of NAACL&#8217;01, 109&#8211;117. 
</p>
<p>DEERWESTER S., DUMAIS S., FURNAS G., LANDAUER T., HARSHMAN R. (1990). Indexing by 
latent semantic analysis. Journal of the American Society for Information Science, Vol. 41, 
pp. 391-407. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Am&#233;lioration de la segmentation automatique des textes 
</p>
<p>DEGAND L., SPOOREN W., BESTGEN Y. (2004). On the use of automatic tools for large scale 
semantic analyses of causal connectives. In Proceedings of ACL 2004 Workshop on 
Discourse Annotation, 25-32. 
</p>
<p>FERRET O. (2002). Using collocations for topic segmentation and link detection. In 
Proceedings of COLING 2002, 260-266. 
</p>
<p>HEARST M. (1997). TextTiling: Segmenting text into multi-paragraph subtopic passages. 
Computational Linguistics, Vol. 23, pp. 33&#8211;64.  
</p>
<p>HEINONEN O. (1998). Optimal multi-paragraph text segmentation by dynamic programming. 
In Proceedings of 17th International Conference on Computational Linguistics (COLING-
ACL&#8217;98), 1484-1486. 
</p>
<p>JI X., ZHA H. (2003). Domain-independent text segmentation using anisotropic diffusion and 
dynamic programming. In Proceedings of SIGIR 2003, 322-329. 
</p>
<p>KAN M., KLAVANS J., MCKEOWN K. (1998). Linear segmentation and segment significance. 
In Proceedings of the 6th International Workshop of Very Large Corpora, 197-205. 
</p>
<p>KAUFMANN, S. (1999). Cohesion and collocation: using context vectors in text segmentation. 
In Proceedings of ACL&#8217;99, 591&#8211;595. 
</p>
<p>KEHAGIAS A., PAVLINA F., PETRIDIS V. (2003). Linear text segmentation using a dynamic 
programming algorithm. In Proceedings of the 10th Conference of the European Chapter of 
the Association for Computational Linguistics, 171-178 
</p>
<p>KIM Y., CHANG J., ZHANG B. (2003). An empirical study on dimensionality optimization in 
text mining for linguistic. Knowledge Acquisition. In Proceedings of PAKDD 2003, 111&#8211;116. 
</p>
<p>KLEBANOV B., WIEMER-HASTINGS P. (2002). Using ASL for pronominal anaphora resolution. 
In Proceedings of the Third International Conference on Computational Linguistics and 
Intelligent Text Processing, 197-199.  
</p>
<p>KOZIMA H. (1993). Text segmentation based on similarity between words. In Proceedings of 
the 31st Annual Meeting of the Association for Computational Linguistics, 286-288.  
</p>
<p>LANDAUER T., DUMAIS S. (1997). A solution to Plato&#8217;s problem : the latent semantic analysis 
theory of acquisition, induction and representation of knowledge, Psychological Review, Vol. 
104, pp. 211&#8211;240. 
</p>
<p>LANDAUER T., FOLTZ P., LAHAM D. (1998). An Introduction to latent semantic analysis. 
Discourse Processes, Vol. 25, pp. 259-284. 
</p>
<p>LIN M., NUNAMAKER J., CHAU, M., CHEN H. (2004). Segmentation of lecture videos based on 
text: A method combining multiple linguistic features. In Proceedings of the 37th Hawaii 
International Conference on System Sciences. 
</p>
<p>MANNING C., SCH&#220;TZE H. (1999). Foundations of Statistical Natural Language Processing. 
Cambridge: MIT Press. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Yves Bestgen 
</p>
<p>MORRIS J., HIRST G. (1991). Lexical cohesion computed by thesaural relations as an indicator 
of the structure of text. Computational Linguistics, 17: 21-42. 
</p>
<p>PEVZNER L., HEARST M. (2002). A Critique and improvement of an evaluation metric for text 
segmentation, Computational Linguistics, Vol 28, pp. 19-36 
</p>
<p>PONTE J., CROFT W. (1997). Text segmentation by topic. Proceedings of the 1st European 
Conference on Research and Advanced Technology for Digital Libraries, 120-129. 
</p>
<p>SCHMID H. (1994). Probabilistic Part-of-speech tagging using decision trees. Proceedings of 
International Conference on New Methods in Language Processing . 
</p>
<p>UTIYAMA M., ISAHARA H. (2001). A Statistical model for domain-independent text 
segmentation. Proceedings of ACL&#8217;2001, 491&#8211;498. </p>

</div></div>
</body></html>