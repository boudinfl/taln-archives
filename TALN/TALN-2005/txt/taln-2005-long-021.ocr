TALN 2005, Dourdan, 6-I0juin 2005

Amélioration de la segmentation automatique des textes grace aux
connaissances acquises par l'analyse sémantique latente.

Yves Bestgen

Centre pour l'étude du texte et du discours — PSOR — Université catholique de Louvain
Place du Cardinal Mercier, 10 — B1348 Louvain—la—Neuve Belgique
yves.bestgen@psp.ucl.ac.be

lV[0tS-Clés Z Segmentation automatique de textes, Analyse semantique latente (ASL)
Keywords: Automatic text segmentation, Latent semantic analysis (LSA)

Réslllné Choi, Wiemer-Hastings et Moore (2001) ont propose d'employer l'analyse
semantique latente (ASL) pour extraire des connaissances semantiques a partir de corpus aﬁn
d'ameliorer l'efﬁcacite d'un algorithme de segmentation des textes. En comparant l'efficacite
du meme algorithme selon qu'il prend en compte des connaissances semantiques
complementaires ou non, ils ont pu montrer les benefices apportes par ces connaissances.
Dans leurs experiences cependant, les connaissances semantiques avaient ete extraites d'un
corpus qui contenait les textes a segmenter dans la phase de test. Si cette hyperspecificite du
corpus d'apprentissage explique la plus grande partie de l'avantage observe, on peut se
demander s'il est possible d'employer l'ASL pour extraire des connaissances semantiques
generiques pouvant etre employees pour segmenter de nouveaux textes. Les deux experiences
presentees ici montrent que la presence dans le corpus d'apprentissage du materiel de test a un
effet important, mais egalement que les connaissances semantiques generiques derivees de
grands corpus ameliorent l'efficacite de la segmentation.

Abstract Choi, Wiemer-Hastings and Moore (2001) proposed to use latent Semantic
Analysis to extract semantic knowledge from corpora in order to improve the accuracy of a
text segmentation algorithm. By comparing the accuracy of the very same algorithm
depending on whether or not it takes into account complementary semantic knowledge, they
were able to show the benefit derived from such knowledge. In their experiments, semantic
knowledge was, however, acquired from a corpus containing the texts to be segmented in the
test phase. If this hyper-speciﬁcity of the training corpus explains the largest part of the
benefit, one may wonder if it is possible to use LSA to acquire generic semantic knowledge
that can be used to segment new texts. The two experiments reported here show that the
presence of the test materials in the training corpus has an important effect, but also that the
generic semantic knowledge derived from large corpora clearly improves the segmentation
accuracy.

Yves Bestgen

1 Améliorer la segmentation des textes par l'adjonction de
connaissances sémantiques complémentaires?

Pendant les dix dernieres années, de nombreuses méthodes ont été proposées pour segmenter
automatiquement des textes en fonction des themes qui les composent sur la base de la
cohésion lexicale. La distinction principale entre ces méthodes réside dans le contraste entre
les approches basées exclusivement sur l'information contenue dans le texte a segmenter
comme la cohésion lexicale (par exemple, Choi, 2000; Hearst, 1997; Heinonen, 1998;
Kehagias, Pavlina, Petridis, 2003 ; Utiyama, Isahara, 2001), et celles qui reposent sur des
connaissances sémantiques complémentaires extraites de dictionnaires et de thesaurus (par
exemple, Kozima 1993 ; Lin, Nunamaker, Chau, Chen, 2004; Morris, Hirst, 1991), ou des
collocations observées dans de grands corpus (Bolshakov, Gelbukh 2001 ; Choi et al., 2001 ;
Ferret, 2002; Kaufmann, 1999 ; Ponte, Croft, 1997). Selon leurs auteurs, les méthodes qui
utilisent des connaissances supplémentaires apportent une réponse aux problemes posés par
les phrases qui relevent du meme theme tout en ne partageant aucun mot commun ou par la
présence de synonymes et d'hyperonymes. Des arguments empiriques en faveur de ces
méthodes ont été récemment présentés par Choi et al. (2001) dans une étude basée sur
l'analyse sémantique latente (ASL : Latent semantic analysis, Latent semantic indexing,
Deerwester et al., 1990), une technique statistique d'extraction d'espaces sémantiques a partir
de corpus qui permet l'estimation de la similarité sémantique entre des mots, des phrases ou
des paragraphes. En comparant l'efficacité du meme algorithme selon qu'il prend en compte
ou non ces connaissances sémantiques complémentaires, Choi et al. (2001) ont mis en
évidence l'avantage dérivé de telles connaissances.

Toutefois, les implications de l'étude de Choi et al. pour la segmentation des textes et, plus
généralement, pour l'utilisation de l'ASL dans le traitement automatique du langage sont
rendues peu claires en raison de la méthodologie qu'ils ont employée. Dans leurs expériences,
les connaissances sémantiques ont été extraites d'un corpus qui contenait les textes qui ont été
segmentés dans la phase de test. On peut donc se demander si la plus grande partie des
bénéfices obtenus par l'ajout de connaissances sémantiques n'est pas due a cette
hyperspécificité du corpus d'apprentissage (c.-a-d. inclure le materiel de test). Si c'est le cas,
cela met en question la possibilité d'employer l'ASL pour extraire des connaissances
sémantiques génériques pouvant étre utilisées pour segmenter de nouveaux textes. A priori, le
probleme ne semble pas tres important, parce que Choi et al. ont utilisé un grand nombre de
petits échantillons de test pour évaluer leur algorithme, chaque échantillon ne représentant en
moyenne que 0.15% du corpus d'apprentissage. La présente étude montre, toutefois, que la
présence du materiel de test dans le corpus d'apprentissage a un effet important, mais
également que les connaissances sémantiques génériques dérivées de grands corpus
améliorent nettement l'efﬁcacité de l'algorithme de segmentation. Cette conclusion est issue
de deux expériences dans lesquelles la présence ou l'absence du materiel de test dans le
corpus d'apprentissage pour l'ASL est manipulée. La premiere expérience est basée sur le
materiel employé par Choi et al., un petit corpus de 1.000.000 de mots. La deuxieme
expérience est basée sur un corpus beaucoup plus grand (25.000.000 mots). Avant de
présenter ces expériences, l'algorith1ne et l'utilisation par Choi et al. de l'ASL dans ce cadre
sont décrits.

Amélioration de la segmentation automatique des textes

2 Les deux versions de l'algorithme de Choi

L'algorithme de segmentation proposé par Choi (2000) se compose des trois étapes
habituellement présentes dans les procédures de segmentation basées sur la cohésion lexicale.
Premierement, le document a segmenter est divisé en unités textuelles minimales,
habituellement les phrases. Ensuite, un indice de similarité entre chaque paire d'unités prises
deux par deux est calculé. Chaque valeur brute de similarité est réexprimée sous une forme
ordinale en prenant la proportion de valeurs voisines qui sont plus petites qu'elle. Pour ﬁnir, le
document est segmenté répétitivement selon les frontieres entre les unités qui maximisent la
somme des similarités moyennes a l'intérieur des segments ainsi constitués.

L'étape la plus intéressante pour la présente étude est celle qui calcule les similarités
interphrases. La procédure initialement proposée par Choi (2000), C99, reposait
exclusivement sur l'information contenue dans le texte a segmenter. Chaque phrase est
représentée par un vecteur construit selon le modele vectoriel classique (Manning, Schiitze,
1999, pp. 539ff) et la similarité entre deux phrases est calculée au moyen de la mesure de
cosinus entre les vecteurs correspondants. Dans une premiere évaluation basée sur la
procédure décrite ci-dessous, Choi a montré que son algorithme était plus efﬁcace que
plusieurs autres approches telles que TextTilling (Hearst, 1994), Segmenter (Kan, Klavans,
McKeown, 1998) et le Maximum-probability segmentation algorithm de Utiyama et Isahara
(2001).

Choi et al. (2001) ont proposé d'améliorer la mesure de similarité inter-phrases en prenant en
compte les proximités sémantiques entre les mots estimées sur la base de l'analyse sémantique
latente (ASL). Brievement, l'ASL s'appuie sur la these qu'il est possible d'estimer la similarité
sémantique entre des mots en analysant les contextes dans lesquels ces mots apparaissent
(Deerwester et al. 1990 ; Degand, Spooren, Bestgen, 2004 ; Landauer, Dumais 1997). La
premiere étape d'une analyse sémantique latente consiste en la construction d'un tableau
lexical contenant les fréquences d'occurrence de chaque mot dans chacun des documents, un
document pouvant étre une phrase, un paragraphe, un texte,  Pour extraire les dimensions
sémantiques, ce tableau lexical subit une décomposition en valeurs singulieres, une sorte
d'analyse factorielle qui extrait les dimensions orthogonales les plus importantes. Apres cette
étape, chaque mot est représenté par un vecteur de poids indiquant sa force d'association avec
chacune des dimensions. Ceci permet de mesurer la proximité sémantique entre deux mots
quelconques en utilisant, par exemple, la mesure de cosinus entre les vecteurs correspondants.
La proximité entre deux phrases (ou toutes autres unités textuelles), meme lorsque ces phrases
ne font pas partir du corpus initial, peut étre estimée en calculant un vecteur pour chacune de
ces phrases -- correspondant a la somme pondérée des vecteurs des mots qui les composent --
et puis en calculant le cosinus entre ces vecteurs (Deerwester et al. 1990). Choi et al. (2001)
ont montré que l'utilisation de cette procédure pour calculer les similarités inter-phrases
produit des performances supérieures a celles enregistrées au moyen de la version précédente
de l'algorithme (basé seulement sur la répétition de mots).

3 Expérience 1

Le but de cette expérience est de déterminer l'impact de la présence du matériel de test dans le
corpus d'apprentissage de l'ASL sur les résultats obtenus par Choi et al. (2001). Est-ce que les
connaissances sémantiques extraites d'un corpus qui n'inclut pas le matériel de test améliorent
également l'efficacité de la segmentation ?

Yves Bestgen

3.1 Méthode

Cette expérience est basée sur la méthodologie développée par Choi (2000). Cette
méthodologie a été également employée par plusieurs auteurs pour évaluer l'efficacité de leur
systeme de segmentation (Brants, Chen, Tsochantaridis, 2002 ; Ferret, 2002 ; Kehagias et al.,
2003 ; Utiyama, Isahara, 2001). La tache consiste a retrouver les frontieres entre des textes
concaténés. Chaque échantillon de test est une concaténation de dix segments de textes.
Chaque segment est composé des 11 premieres phrases d'un texte aléatoirement choisi dans
deux sous-sections du corpus de Brown. Pour l'eXpérience, j'ai utilisé le matériel de test le
plus général proposé par Choi (2000) dans lequel la taille des segments dans chaque
échantillon varie aléatoirement de 3 a 11 phrases. Il est composé de 400 échantillons.

L'expérience vise a comparer l'efficacité de l'algorithme selon que le matériel de test est inclus
dans le corpus d'apprentissage de l'ASL (condition non autonome) ou qu'il ne l'est pas
(condition autonome). Un espace sémantique non autonome, correspondant a celui utilisé par
Choi et al., a été construit en utilisant l'entiereté du corpus de Brown comme corpus
d'apprentissage. Quatre cents espaces autonomes différents ont été construits, un pour chaque
échantillon de test, en retirant a chaque fois du corpus de Brown uniquement les phrases qui
composent cet échantillon.

Pour extraire l'espace sémantique par l'ASL et pour appliquer l'algorithme de segmentation,
une série de parametres ont dﬁ étre fixés. Tout d'abord, les paragraphes ont été utilisés comme
documents pour construire le tableau lexical parce que Choi et al. ont observé que de telles
unités de taille moyenne étaient plus efﬁcaces que des unités plus courtes comme les phrases.
Les mots repris dans la liste de mots-outils (stoplist) de Choi ont été supprimés, ainsi que
ceux qui n'apparaissaient qu'une seule fois dans l'ensemble du corpus. Les mots n'ont pas été
tronqués en fonction de leur racine (stemming), suivant en cela la procédure de Choi et al.
(2001). Pour établir l'espace sémantique, la décomposition en valeurs singulieres a été réalisée
par le programme SVDPACKC (Berry, 1992 ; Berry et al., 1993), et les 300 premiers
vecteurs singuliers ont été conservés. En ce qui concerne l'algorithme de segmentation, j'ai
utilisé la version dans laquelle le nombre de frontieres a trouver est imposé et fixé ici a neuf.
Un masque de 11 X 11 a été employé pour la transformation ordinale, comme recommandé
par Choi (2000).

3.2 Résultats

L'efﬁcacité de la segmentation a été évaluée au moyen de l'indice utilisé par Choi et al.
(2001) : le taux Pk d'erreur de segmentation (Beeferman, Berger, Lafferty, 1999) qui indique
la proportion de phrases qui sont incorrectement classées comme appartenant au méme
segment ou incorrectement classées comme appartenant a des segments différents.

Les résultatsl sont présentés dans la Figure 1. Les espaces autonomes donnent lieu a des
performances plus faibles que l'espace non autonome, comme le conﬁrme le test 2,‘ pour
échantillon appareillé (chaque échantillon de test étant utilisé comme une observation) qui est

Ce taux d'erreur est en fait légérement meilleur que celui obtenu par Choi et al. (2001), la différence pouvant
étre due a plusieurs facteurs tels que le prétraitement du corpus de Brown (identiﬁcation des mots et des
paragraphes) ou la fonction de pondération appliquée aux fréquences brutes, qui était ici la formule de
pondération décrite dans Landauer, Foltz, et Laham (1998).

Ame’li0rati0n de la segmentation automatique des textes

signiﬁcatif pour un alpha plus petit que 0.0001. L'algorithme C99, qui n'utilise pas l'ASL pour
estimer les similarités entre les phrases, produit un Pk de 0.13 (Choi et al., 2001, tableau 3,
ligne 3 : no stemming). Il s'avere donc que, si la condition autonome est meilleure que C99,
l'avantage est tres faible.

Pk
Non autonome 0.084 (0.005)
Autonome 0.120 (0.006)

Figure 1 : Taux d'erreur et variance (entre parentheses) pour les conditions non autonome et
autonome.

Avant de conclure que la présence du matériel de test dans le corpus d'apprentissage de l'ASL
a fortement modifié l'espace sémantique, une explication alternative doit étre considérée. La
perte d'efficacité en condition autonome pourrait étre due au fait qu'il y a systématiquement
légerement moins de mots indexés dans les espaces sémantiques autonomes que dans l'espace
non autonome. La suppression de chaque échantillon de test a entrainé la perte en moyenne de
23 mots différents sur un total de 25.847 mots qui sont indexés dans l'espace non autonome.
Dans les espaces autonomes, ces mots ne sont pas disponibles pour estimer la similarité entre
les phrases, tandis qu'ils sont utilisés dans l'espace non autonome. Aﬁn de déterminer si ce
facteur peut expliquer la différence d'efficacité, une analyse complémentaire a été effectuée
sur l'espace non autonome dans laquelle, pour chaque échantillon detest, uniquement les mots
présents dans l'espace autonome correspondant ont été pris en compte. De cette maniere,
seules les relations sémantiques peuvent jouer. Compare a l'espace non autonome complet, je
n'ai observé presque aucune diminution d'efﬁcacité, le taux d'erreur Pk passant de 0.084 a
0.085 dans la nouvelle analyse. Ce résultat indique que ce ne sont pas les mots choisis pour le
calcul des proximités qui importent, mais les relations sémantiques dans les espaces.

4 Expérience 2

L'expérience 1 a été menée sur le corpus d'apprentissage de Choi et al. (2001), un corpus de
1.000.000 de mots issus de textes de genres et de themes tres différents. La petite taille du
corpus et la diversité des textes pourraient avoir affecté les résultats de deux manieres.
D'abord, l'impact de la présence du matériel de test dans le corpus dépend probablement de
ces caractéristiques du corpus. Retirer les premieres phrases d'un texte devrait avoir moins
d'effet si le corpus contient beaucoup de textes sur des themes similaires. En second lieu, un
corpus plus volumineux permettrait probablement l'extraction d'un espace sémantique plus
stable et plus efficace. Ceci pourrait produire une plus grande différence entre la version
"ASL" de l'algorithme et celle qui n'utilise pas de connaissances sémantiques supplémentaires
(C99). Pour ces raisons, une deuxieme experience a été menée sur la base d'un corpus
beaucoup plus volumineux, comprenant les articles parus durant les années 1997 et 1998 dans
le journal de langue francaise belge Le Soir (approximativement 52.000 articles et 26.000.000
mots). Dans ce corpus, chaque échantillon du matériel de test correspond en moyenne a
0.0066% du corpus complet. Cette deuxieme experience a également permis de comparer les
conditions non autonome et autonome a une condition antérieure basée sur les articles parus
dans le meme journal, mais pendant les années 1995 et 1996 (approximativement 50.000
articles et plus de 22.000.000 mots). Cette condition nous informera a propos de la possibilité

Yves Bestgen

d'employer l'ASL pour extraire des connaissances sémantiques plus génériques, puisque le
corpus d'apprentissage de l'ASL est antérieur aux textes a segmenter. I1 faut toutefois noter
que ces connaissances étant extraites de la méme source joumalistique, les qualiﬁer
d'indépendantes seraient nettement excessifs.

4.1 Méthode

Le matériel de test a été extrait du corpus 1997-1998 suivant les directives données dans Choi
(2000). 11 se compose de 100 échantillons de dix segments, dont la longueur varie
aléatoirement de 3 a 11 phrases. Trois types d'espace d'apprentissage pour l'ASL ont été
construits. L'espace non autonome est basé sur l'entiereté du corpus 1997-1998. Cent espaces
autonomes différents ont été construits comme décrit dans l'expérience 1. Enﬁn, un espace
antérieur a été établi a partir du corpus 1995-1996. Les parametres utilisés pour extraire les
espaces sémantiques sont identiques a ceux employés dans l'expérience 1 sauf que, pour
réduire la taille des tableaux lexicaux. les articles, et non les paragraphes, ont été utilisés
comme documents et les mots ont été lemmatisés au moyen de TreeTagger (Schmid 1994).

4.2 Résultats

Globalement, les résultats sont similaires a ceux obtenus lors de la premiere expérience.
Comme le montre la Figure 2, les espaces autonomes donnent lieu a des performances plus
faibles que l'espace non autonome et, comme attendu, l'espace antérieur donne lieu a des
performances encore plus faibles.

Pk
Non autonome 0.074 (0.004)
Autonome 0.084 (0.005)
Antérieure 0.098 (0.005)

Figure 2 : Taux d'erreur et variance (entre parentheses) pour les conditions non autonome,
autonome et antérieure.

Toutefois, il est important de noter que l'algorithme C99, qui n'est pas basé sur l'analyse
sémantique latente, produit un taux d'erreur Pk de 0.155, soit une valeur nettement plus
mauvaise que celles obtenues avec les espaces autonomes (0.084) et avec l'espace antérieur
(0.098). Ceci conﬁrme l'utilité des connaissances sémantiques extraites de grands corpus pour
estimer les similarités interphrases.

Par rapport a la premiere expérience, l'écart entre les conditions non autonome et autonome
est beaucoup plus faible, passant de 0.036 pour l'expérience 1 a 0.01 pour l'eXpérience 2. Cet
écart demeure néanmoins statistiquement signiﬁcatif (t(99) = 3.17; p = 0.002). Bien que plus
grand, l'écart entre les conditions autonome et antérieure (0.014), est statistiquement juste
significatif (t(99) = 2.04; p = 0.045). La Figure 3 montre que la condition autonome surpasse
la condition antérieure dans 46 échantillons, alors que l'inverse se produit dans 35
échantillons, les 19 échantillons restants ne montrant aucune différence entre ces deux
conditions.

Amélioration de la segmentation automatique des textes

F 2:2:

2315

*1

U 1:2:

[I

r1 5

: @ ﬁﬁﬁmﬁ

-3.13 -EH55 E|.¢:u’Z' ELE5 E|.lH' E|.15 $3.22?
]Ji1'I'ért*I1L*c unln: les; P]-; [A1:rm1r.r;:m: A1*:a'rJr'ic.r.r:'.:'j:

Figure 3 : Distribution des différences en Pk entre les conditions Autonome et Antérieure

On voit donc que l'avantage de la condition autonome sur la condition antérieure est
principalement dﬁ a quelques échantillons de test pour lesquels la condition autonome est
nettement plus efficace. Rappelons également que la condition antérieure donne lieu a des
résultats nettement meilleurs que ceux obtenus lorsque la segmentation s'effectue sans le
recours a des connaissances sémantiques complémentaires.

5 Conclusion

Les deux expériences rapportées ici montrent que la présence du matériel de test dans le
corpus d'apprentissage de l'ASL augmente l'efficacité de l'algorithme de segmentation méme
lorsqu'un corpus de plus de 25.000.000 mots est utilisé. Elles montrent également que
l'utilisation de connaissances sémantiques indépendantes améliore l'efﬁcacité de la
segmentation et que ceci s'observe méme lorsque ces connaissances sont extraites d'années
antérieures de la méme source. Cette observation souligne la possibilité de constituer par
analyse sémantique latente des connaissances sémantiques plus ou moins génériques, c'est-a-
dire, des connaissances qui peuvent étre utilisées pour traiter de nouvelles données, comme
cela a été récemment proposé dans la recherche de l'antécédent d'une anaphore, dans un
systeme de reconnaissance de la parole ou en traduction automatique (Bellegarda, 2000;
Klebanov, Wiemer-Hastings, 2002 ; Kim, Chang, Zhang, 2003). Une question a laquelle la
présente étude ne répond pas concerne la possibilité d'utiliser un corpus tiré d'une autre
source, telle qu'un autre journal. Bellegarda (2000) a observé, en reconnaissance automatique
de la parole, qu'un tel espace sémantique est moins efficace. Cependant, évaluer la proximité
sémantique entre deux phrases est probablement moins affecté par la source du corpus que de
prédire le prochain mot d'un énoncé.

Récemment, plusieurs auteurs ont proposé des algorithmes de segmentation, basés
principalement sur la programmation dynamique, qui égalent ou méme surpassent les résultats
de Choi (Ji, Zha, 2003, Kehagias et al., 2003 ; Utiyama, Isahara, 2001). Ces algorithmes ne
s'appuient pas sur des connaissances sémantiques supplémentaires. Les résultats de la présente
étude suggerent que leur efﬁcacité pourrait encore étre améliorée en prenant en compte de
telles connaissances. Enfin, d'autres techniques que l'ASL ont été proposées pour extraire des
connaissances sémantiques a partir de grands corpus tel pASL (Brants et al., 2002). L'analyse
sémantique latente étant relativement simple a mettre en pratique grace a la disponibilité de

Yves Bestgen

programmes tres puissants tel que SVDPACKC (Berry et al., 1993), son avantage principal
est qu'elle est employée par une communauté de plus en plus large de chercheurs.

Une limitation importante de ce travail réside dans la tache employée pour évaluer l'efficacité
de l'algorithme de segmentation. Identiﬁer les frontieres entre des textes concaténés est une
tache artificielle et certainement moins complexe que de localiser les changements de themes
a l'intérieur de textes. Le fait que la procédure et le matériel concu par Choi soient devenus
une sorte de "standard" employé par une série de chercheurs pour évaluer leur algorithme ne
sufﬁt pas a la légitimer. Il serait donc utile de confirmer les conclusions de la présente étude
dans une tache de segmentation intratexte.

Remerciements

Y. Bestgen est chercheur qualifié du Fonds National de la Recherche (FNRS). Cette
recherche est financée par le projet FRFC n° 2.4535.02 et par une “Action de Recherche
concertée” du Gouvemement de la Communauté francaise de Belgique.

Références

BEEFERMAN D., BERGER A., LAFFERTY J. (1999). Statistical models for text segmentation,
Machine Learning, Vol. 34, pp. 177-210.

BELLEGARDA J. (2000). Large vocabulary speech recognition with multispan statistical
language models. IEEE Transactions on Speech and Audio Processing, Vol. 8, pp. 78-84.

BERRY M. (1992). Large scale singular value computation. International jomal of
Supercomputer Application, Vol. 6, 13-49.

BERRY M., D0 T ., O'BRIEN G., KRISHNA V., VARADHAN S. (1993). SVDPACKC: Version 1.0
user's guide, Tech. Rep. CS-93-194, University of Tennessee, Knoxville, TN, October 1993.

BOLSHAKOV I., GELBUKH A. (2001). Text segmentation into paragraphs based on local text
cohesion. In Proceedings of Text, Speech and Dialogue (TSD-2001), 158-166.

BRANTS T ., CHEN, F., TSOCHANTARIDIS I. (2002). Topic-based document segmentation with
probabilistic latent semantic analysis. In Proceedings of CIKM’02, 211-218

CHOI F. (2000). Advances in domain independent linear text segmentation, In Proceedings of
NAACL-00, 26-33.

CHOI F., WIEMER-HASTINGS P., MOORE J. (2001) Latent semantic analysis for text
segmentation, In Proceedings of NAA CL’0I , 109-117.

DEERWESTER S., DUMAIS S., FURNAS G., LANDAUER T., HARSHMAN R. (1990). Indexing by
latent semantic analysis. Journal of the American Society for Information Science, Vol. 41,
pp. 391-407.

Ame’lioration de la segmentation automatique des textes

DEGAND L., SPOOREN W., BESTGEN Y. (2004). On the use of automatic tools for large scale
semantic analyses of causal connectives. In Proceedings of ACL 2004 Workshop on
Discourse Annotation, 25-32.

FERRET O. (2002). Using collocations for topic segmentation and link detection. In
Proceedings of C OLING 2002, 260-266.

HEARST M. (1997). TextTiling: Segmenting text into multi-paragraph subtopic passages.
Computational Linguistics, Vol. 23, pp. 33-64.

HEINONEN O. (1998). Optimal multi-paragraph text segmentation by dynamic programming.
In Proceedings of I 7th International Conference on Computational Linguistics (COLING-
ACL’98), 1484-1486.

JI X., ZHA H. (2003). Domain-independent text segmentation using anisotropic diffusion and
dynamic programming. In Proceedings ofSIGIR 2003 , 322-329.

KAN M., KLAVANS J ., MCKEOWN K. (1998). Linear segmentation and segment significance.
In Proceedings of the 6th International Workshop of Very Large Corpora, 197-205.

KAUFMANN, S. (1999). Cohesion and collocation: using context vectors in text segmentation.
In Proceedings of ACL’99, 591-595.

KEHAGIAS A., PAVLINA F., PETRIDIS V. (2003). Linear text segmentation using a dynamic
programming algorithm. In Proceedings of the I 0th Conference of the European Chapter of
the Association for Computational Linguistics, 171-178

KIM Y., CHANG J ., ZHANG B. (2003). An empirical study on dimensionality optimization in
text mining for linguistic. Knowledge Acquisition. In Proceedings of PAKDD 2003, 111-116.

KLEBANOV B., WIEMER-HASTINGS P. (2002). Using ASL for pronominal anaphora resolution.
In Proceedings of the Third International Conference on Computational Linguistics and
Intelligent Text Processing, 197-199.

KOZIMA H. (1993). Text segmentation based on similarity between words. In Proceedings of
the 31 st Annual Meeting of the Association for Computational Linguistics, 286-288.

LANDAUER T., DUMAIS S. (1997). A solution to Plato’s problem : the latent semantic analysis
theory of acquisition, induction and representation of knowledge, Psychological Review, Vol.
104, pp. 211-240.

LANDAUER T ., FOLTZ P., LAHAM D. (1998). An Introduction to latent semantic analysis.
Discourse Processes, Vol. 25, pp. 259-284.

LIN M., NUNAMAKER J ., CHAU, M., CHEN H. (2004). Segmentation of lecture videos based on
text: A method combining multiple linguistic features. In Proceedings of the 37th Hawaii
International Conference on System Sciences.

MANNING C., SCHUTZE H. (1999). Foundations of Statistical Natural Language Processing.
Cambridge: MIT Press.

Yves Bestgen

MORRIS J ., HIRST G. (1991). Lexical cohesion computed by thesaural relations as an indicator
of the structure of text. Computational Linguistics, 17: 21-42.

PEVZNER L., HEARST M. (2002). A Critique and improvement of an evaluation metric for text
segmentation, Computational Linguistics, Vol 28, pp. 19-36

PONTE J ., CROFT W. (1997). Text segmentation by topic. Proceedings of the 1st European
Conference on Research and Advanced Technology for Digital Libraries, 120-129.

SCHMID H. (1994). Probabilistic Part-of-speech tagging using decision trees. Proceedings of
International Conference on New Methods in Language Processing .

UTIYAMA M., ISAHARA H. (2001). A Statistical model for domain-independent text
segmentation. Proceedings of A CL ’200I , 491-498.

