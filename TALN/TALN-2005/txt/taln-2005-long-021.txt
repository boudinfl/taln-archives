TALN 2005, Dourdan, 6-I0juz'n 2005

Amélioration de la segmentation automatique des textes grace aux
connaissances acquises par l'analyse sémantique latente.

Yves Bestgen

Centre pour l'étude du texte et du discours — PSOR - Université catholique de Louvain
Place du Cardinal Mercier, 10 - B1348 Louvain-la-Neuve Belgique
yves.bestgen@psp.ucl.ac.be

Mots-clés :
Keywords: Automatic text segmentation, Latent semantic analysis (LSA)

Segmentation automatique de textes, Analyse sémantique latente (ASL)

Résumé Choi, Wiemer-Hastings et Moore (2001) ont proposé d'employer l'analyse
sémantique latente (ASL) pour extraire des connaissances sémantiques a partir de corpus aﬁn
d'améliorer l'efﬁcacité d'un algorithme de segmentation des textes. En comparant l'efﬁcacité du
méme algorithme selon qu'il prend en compte des connaissances sémantiques complémentaires
ou non, ils ont pu montrer les bénéﬁces apportés par ces connaissances. Dans leurs expériences
cependant, les connaissances sémantiques avaient été extraites d'un corpus qui contenait les
textes a segmenter dans la phase de test. Si cette hyperspéciﬁcité du corpus d'apprentissage
explique la plus grande partie de l'avantage observé, on peut se demander s'il est possible
d'employer l'ASL pour extraire des connaissances sémantiques génériques pouvant étre
employées pour segmenter de nouveaux textes. Les deux expériences présentées ici montrent que
la présence dans le corpus d'apprentissage du matériel de test a un effet important, mais
également que les connaissances sémantiques génériques dérivées de grands corpus améliorent
l'efﬁcacité de la segmentation.

Abstract Choi, Wiemer-Hastings and Moore (2001) proposed to use latent Semantic Analysis
to extract semantic knowledge from corpora in order to improve the accuracy of a text
segmentation algorithm. By comparing the accuracy of the very same algorithm depending on
whether or not it takes into account complementary semantic knowledge, they were able to show
the beneﬁt derived from such knowledge. In their experiments, semantic knowledge was,
however, acquired ﬁom a corpus containing the texts to be segmented in the test phase. If this
hyper-speciﬁcity of the training corpus explains the largest part of the beneﬁt, one may wonder
if it is possible to use LSA to acquire generic semantic knowledge that can be used to segment
new texts. The two experiments reported here show that the presence of the test materials in the
training corpus has an important effect, but also that the generic semantic knowledge derived
from large corpora clearly improves the segmentation accuracy.

203

204

Yves Bestgen

1 Améliorer la segmentation des textes par l'adjonction de
connaissances sémantiques complémentaires?

Pendant les dix demieres armees, de nombreuses methodes ont ete proposees pour segmenter
automatiquement des textes en fonction des themes qui les composent sur la base de la cohesion
lexicale. La distinction principale entre ces methodes reside dans le contraste entre les approches
basees exclusivement sur l'information contenue dans le texte a segmenter comme la cohesion
lexicale (par exemple, Choi, 2000 ; Hearst, 1997 ; Heinonen, 1998 ; Kehagias, Pavlina, Petridis,
2003; Utiyama, Isahara, 2001), et celles qui reposent sur des connaissances semantiques
complementaires extraites de dictionnaires et de thesaurus (par exemple, Kozima 1993 ; Lin,
Nunamaker, Chau, Chen, 2004; Morris, Hirst, 1991), ou des collocations observees dans de
grands corpus (Bolshakov, Gelbukh 2001 ; Choi et al., 2001 ; Ferret, 2002; Kaufmarm, 1999;
Ponte, Croft, 1997). Selon leurs auteurs, les methodes qui utilisent des connaissances
supplementaires apportent une reponse aux problemes poses par les phrases qui relevent du
meme theme tout en ne partageant aucun mot commun ou par la presence de synonymes et
d'hyperonymes. Des arguments empiriques en faveur de ces methodes ont ete recemment
presentes par Choi et al. (2001) dans une etude basee sur l'analyse semantique latente (ASL :
Latent semantic analysis, Latent semantic indexing, Deerwester et al., 1990), une technique
statistique d'extraction d'espaces semantiques a partir de corpus qui permet l'estimation de la
similarite semantique entre des mots, des phrases ou des paragraphes. En comparant l'efﬁcacite
du meme algorithme selon qu'il prend en compte ou non ces connaissances semantiques
complementaires, Choi et al. (2001) ont mis en evidence l'avantage derive de telles
connaissances.

Toutefois, les implications de l'etude de Choi et al. pour la segmentation des textes et, plus
generalement, pour l'utilisation de l'ASL dans le traitement automatique du langage sont rendues
peu claires en raison de la methodologie qu'ils ont employee. Dans leurs experiences, les
connaissances semantiques ont ete extraites d'un corpus qui contenait les textes qui ont ete
segmentes dans la phase de test. On peut donc se demander si la plus grande partie des beneﬁces
obtenus par l'ajout de connaissances semantiques n'est pas due a cette hyperspeciﬁcite du corpus
d'apprentissage (c.-a-d. inclure le materiel de test). Si c'est le cas, cela met en question la
possibilite d'employer l'ASL pour extraire des connaissances semantiques generiques pouvant
etre utilisees pour segmenter de nouveaux textes. A priori, le probleme ne semble pas tres
important, parce que Choi et al. ont utilise un grand nombre de petits echantillons de test pour
evaluer leur algorithme, chaque echantillon ne representant en moyenne que 0.15% du corpus
d'apprentissage. La presente etude montre, toutefois, que la presence du materiel de test dans le
corpus d'apprentissage a un effet important, mais egalement que les connaissances semantiques
generiques derivees de grands corpus ameliorent nettement l'efﬁcacite de l'algorithme de
segmentation. Cette conclusion est issue de deux experiences dans lesquelles la presence ou
l'absence du materiel de test dans le corpus d'apprentissage pour l'ASL est manipulee. La
premiere experience est basee sur le materiel employe par Choi et al., un petit corpus de
1.000.000 de mots. La deuxieme experience est basee sur un corpus beaucoup plus grand
(25.000.000 mots). Avant de presenter ces experiences, l'algorithme et l'utilisation par Choi et al.
de l'ASL dans ce cadre sont decrits.

Amélioration de la segmentation automatique des textes

2 Les deux versions de l'algorithme de Choi

L'algorithme de segmentation propose par Choi (2000) se compose des trois etapes
habituellement presentes dans les procedures de segmentation basees sur la cohesion lexicale.
Premierement, le document a segmenter est divise en unites textuelles minimales, habituellement
les phrases. Ensuite, un indice de similarite entre chaque paire d'unites prises deux par deux est
calcule. Chaque valeur brute de similarite est reexprimee sous une forme ordinale en prenant la
proportion de valeurs voisines qui sont plus petites qu'elle. Pour ﬁnir, le document est segmente
repetitivement selon les frontieres entre les unites qui maximisent la somme des similarites
moyennes a l'interieur des segments ainsi constitues.

L'etape la plus interessante pour la presente etude est celle qui calcule les similarites interphrases.
La procedure initialement proposee par Choi (2000), C99, reposait exclusivement sur
l'information contenue dans le texte a segmenter. Chaque phrase est representee par un vecteur
construit selon le modele vectoriel classique (Manning, Schiitze, 1999, pp. 539ff) et la similarite
entre deux phrases est calculee au moyen de la mesure de cosinus er1tre les vecteurs
correspondants. Dans une premiere evaluation basee sur la procedure decrite ci-dessous, Choi a
montre que son algorithme etait plus efﬁcace que plusieurs autres approches telles que
TextTilling (Hearst, 1994), Segmenter (Kan, Klavans, McKeown, 1998) et le Maximum-
probability segmentation algorithm de Utiyama et Isahara (2001).

Choi et al. (2001) ont propose d'ameliorer la mesure de similarite inter-phrases en prenant en
compte les proximites semantiques entre les mots estimees sur la base de l'analyse semantique
latente (ASL). Brievement, l'ASL s'appuie sur la these qu'il est possible d'estimer la similarite
semantique entre des mots en analysant les contextes dans lesquels ces mots apparaissent
(Deerwester et al. 1990 ; Degand, Spooren, Bestgen, 2004 ; Landauer, Dumais 1997). La
premiere etape d'une analyse semantique latente consiste en la construction d'un tableau lexical
contenant les frequences d'occurrence de chaque mot dans chacun des documents, un document
pouvant etre une phrase, un paragraphe, un texte,  Pour extraire les dimensions semantiques, ce
tableau lexical subit une decomposition en valeurs singulieres, une sorte d'analyse factorielle qui
extrait les dimensions orthogonales les plus importantes. Apres cette etape, chaque mot est
represente par un vecteur de poids indiquant sa force d'association avec chacune des dimensions.
Ceci permet de mesurer la proximite semantique entre deux mots quelconques en utilisant, par
exemple, la mesure de cosinus entre les vecteurs correspondants. La proximite entre deux phrases
(ou toutes autres unites textuelles), meme lorsque ces phrases ne font pas partir du corpus initial,
peut etre estimee en calculant un vecteur pour chacune de ces phrases -- correspondant a la
somme ponderee des vecteurs des mots qui les composent -- et puis en calculant le cosinus entre
ces vecteurs (Deerwester et al. 1990). Choi et al. (2001) ont montre que l'utilisation de cette
procedure pour calculer les similarites inter-phrases produit des performances superieures a celles
enregistrees au moyen de la version precedente de l'algorithme (base seulement sur la repetition
de mots).

3 Experience 1

Le but de cette experience est de determiner l'impact de la presence du materiel de test dans le
corpus d'apprentissage de l'ASL sur les resultats obtenus par Choi et al. (2001). Est-ce que les

205

206

Yves Bestgen

connaissances semantiques extraites d'un corpus qui n'inclut pas le materiel de test ameliorent
egalement l'efﬁcacite de la segmentation ?

3.1 Méthode

Cette experience est basee sur la methodologie developpee par Choi (2000). Cette methodologie
a ete egalement employee par plusieurs auteurs pour evaluer l'efﬁcacite de leur systeme de
segmentation (Brants, Chen, Tsochantaridis, 2002 ; Ferret, 2002 ; Kehagias et al., 2003 ;
Utiyama, Isahara, 2001). La tache consiste a retrouver les frontieres entre des textes concatenes.
Chaque echantillon de test est une concatenation de dix segments de textes. Chaque segment est
compose des n premieres phrases d'un texte aleatoirement choisi dans deux sous-sections du
corpus de Brown. Pour l'experience, j'ai utilise le materiel de test le plus general propose par Choi
(2000) dans lequel la taille des segments dans chaque echantillon varie aleatoirement de 3 a 11
phrases. 11 est compose de 400 echantillons.

L'experience vise a comparer l'efﬁcacite de l'algorithme selon que le materiel de test est inclus
dans le corpus d'apprentissage de l'ASL (condition non autonome) ou qu'il ne l'est pas (condition
autonome). Un espace semantique non autonome, correspondant a celui utilise par Choi et al., a
ete construit en utilisant l'entierete du corpus de Brown comme corpus d'apprentissage. Quatre
cents espaces autonomes differents ont ete construits, un pour chaque echantillon de test, en
retirant a chaque fois du corpus de Brown uniquement les phrases qui composent cet echantillon.

Pour extraire l'espace semantique par l'ASL et pour appliquer l'algorithme de segmentation, une
serie de parametres ont dﬁ etre ﬁxes. Tout d'abord, les paragraphes ont ete utilises comme
documents pour construire le tableau lexical parce que Choi et al. ont observe que de telles unites
de taille moyenne etaient plus efﬁcaces que des unites plus courtes comme les phrases. Les mots
repris dans la liste de mots-outils (stoplist) de Choi ont ete supprimes, ainsi que ceux qui
n'apparaissaient qu'une seule fois dans l'ensemble du corpus. Les mots n'ont pas ete tronques en
fonction de leur racine (stemming), suivant en cela la procedure de Choi et al. (2001). Pour etablir
l'espace semantique, la decomposition en valeurs singulieres a ete realisee par le programme
SVDPACKC (Berry, 1992 ; Berry et al., 1993), et les 300 premiers vecteurs singuliers ont ete
conserves. En ce qui conceme l'algorithme de segmentation, j'ai utilise la version dans laquelle le
nombre de ﬁontieres a trouver est impose et ﬁxe ici a neuf. Un masque de 11 x 11 a ete employe
pour la transformation ordinale, comme recommande par Choi (2000).

3.2 Résultats

L'efﬁcacite de la segmentation a ete evaluee au moyen de l'indice utilise par Choi et al. (2001) :
le taux Pk d'erreur de segmentation (Beeferman, Berger, Lafferty, 1999) qui indique la proportion
de phrases qui sont incorrectement classees comme appartenant au meme segment ou
incorrectement classees comme appartenant a des segments differents.

Amélioration de la segmentation automatique des textes

Les resultatsl sont presentes dans la Figure 1. Les espaces autonomes donnent lieu a des
performances plus faibles que l'espace non autonome, comme le conﬁrme le test If pour
echantillon appareille (chaque echantillon de test etant utilise comme une observation) qui est
signiﬁcatif pour un alpha plus petit que 0.0001. L'algorithme C99, qui n'utilise pas l'ASL pour
estimer les similarites entre les phrases, produit un Pk de 0.13 (Choi et al., 2001, tableau 3, ligne
3 : no stemming). Il s'avere donc que, si la condition autonome est meilleure que C99, l'avantage
est tres faible.

Pk
Non autonome 0.084 (0.005)
Autonome 0.120 (0.006)

Figure 1 : Taux d'erreur et variance (entre parentheses) pour les conditions non autonome et
autonome.

Avant de conclure que la presence du materiel de test dans le corpus d'apprentissage de l'ASL a
fortement modiﬁe l'espace semantique, une explication alternative doit etre consideree. La perte
d'eff1cacite en condition autonome pourrait etre due au fait qu'il y a systematiquement legerement
moins de mots indexes dans les espaces semantiques autonomes que dans l'espace non autonome.
La suppression de chaque echantillon de test a entraine la perte en moyenne de 23 mots differents
sur un total de 25.847 mots qui sont indexes dans l'espace non autonome. Dans les espaces
autonomes, ces mots ne sont pas disponibles pour estimer la similarite entre les phrases, tandis
qu'ils sont utilises dans l'espace non autonome. Aﬁn de determiner si ce facteur peut expliquer la
difference d'eff1cacite, une analyse complementaire a ete effectuee sur l'espace non autonome
dans laquelle, pour chaque echantillon de test, uniquement les mots presents dans l'espace
autonome correspondant ont ete pris en compte. De cette maniere, seules les relations
semantiques peuvent jouer. Compare a l'espace non autonome complet, je n'ai observe presque
aucune diminution d'eff1cacite, le taux d'erreur Pk passant de 0.084 a 0.085 dans la nouvelle
analyse. Ce resultat indique que ce ne sont pas les mots choisis pour le calcul des proximites qui
importent, mais les relations semantiques dans les espaces.

4 Experience 2

L'experience 1 a ete menee sur le corpus d'apprentissage de Choi et al. (2001), un corpus de
1.000.000 de mots issus de textes de genres et de themes tres differents. La petite taille du corpus
et la diversite des textes pourraient avoir affecte les resultats de deux manieres. D'abord, l'impact
de la presence du materiel de test dans le corpus depend probablement de ces caracteristiques du
corpus. Retirer les premieres phrases d'un texte devrait avoir moins d'effet si le corpus contient

1 Ce taux d'erreur est en fait legerement meilleur que celui obtenu par Choi et al. (2001), la difference pouvant étre

due a plusieurs facteurs tels que le pretraitement du corpus de Brown (identiﬁcation des mots et des paragraphes)
ou la fonction de ponderation appliquee aux frequences brutes, qui etait ici la formule de ponderation decrite dans
Landauer, Foltz, et Laham (1998).

207

208

Yves Bestgen

beaucoup de textes sur des themes similaires. En second lieu, un corpus plus volumineux
permettrait probablement l'extraction d'un espace semantique plus stable et plus efficace. Ceci
pourrait produire une plus grande difference entre la version "ASL" de l'algorithme et celle qui
n'utilise pas de connaissances semantiques supplementaires (C99). Pour ces raisons, une
deuxieme experience a ete menee sur la base d'un corpus beaucoup plus volumineux, comprenant
les articles parus durant les annees 1997 et 1998 dans le journal de langue ﬁancaise belge Le Soir
(approximativement 52.000 articles et 26.000.000 mots). Dans ce corpus, chaque echantillon du
materiel de test correspond en moyenne a 0.0066% du corpus complet. Cette deuxieme
experience a egalement permis de comparer les conditions non autonome et autonome a une
condition antérieure basee sur les articles parus dans le meme journal, mais pendant les armees
1995 et 1996 (approximativement 50.000 articles et plus de 22.000.000 mots). Cette condition
nous informera a propos de la possibilite d'employer l'ASL pour extraire des connaissances
semantiques plus generiques, puisque le corpus d'apprentissage de l'ASL est anterieur aux textes
a segmenter. Il faut toutefois noter que ces connaissances etant extraites de la meme source
joumalistique, les qualiﬁer d'independantes seraient nettement excessifs.

4.1 Methode

Le materiel de test a ete extrait du corpus 1997-1998 suivant les directives donnees dans Choi
(2000). 11 se compose de 100 echantillons de dix segments, dont la longueur varie aleatoirement
de 3 a 11 phrases. Trois types d'espace d'apprentissage pour l'ASL ont ete construits. L'espace
non autonome est base sur l'entierete du corpus 1997-1998. Cent espaces autonomes differents
ont ete construits comme decrit dans l'experience 1. Enﬁn, un espace antérieur a ete etabli a
partir du corpus 1995-1996. Les parametres utilises pour extraire les espaces semantiques sont
identiques a ceux employes dans l'experience 1 sauf que, pour reduire la taille des tableaux
lexicaux. les articles, et non les paragraphes, ont ete utilises comme documents et les mots ont ete
lemmatises au moyen de TreeTagger (Schmid 1994).

4.2 Resultats

Globalement, les resultats sont similaires a ceux obtenus lors de la premiere experience. Comme
le montre la Figure 2, les espaces autonomes donnent lieu a des performances plus faibles que
l'espace non autonome et, comme attendu, l'espace anterieur donne lieu a des performances
encore plus faibles.

Pk

Non autonome 0.074 (0.004)

Autonome 0.084 (0.005)

Anterieure

0.098 (0.005)

Figure 2 : Taux d'erreur et variance (entre parentheses) pour les conditions non autonome,
autonome et anterieure.

Amélioration de la segmentation automatique des textes

Toutefois, il est important de noter que l'algorithme C99, qui n'est pas base sur l'analyse
semantique latente, produit un taux d'erreur Pk de 0.155, soit une valeur nettement plus mauvaise
que celles obtenues avec les espaces autonomes (0.084) et avec l'espace antérieur (0.098). Ceci
conﬁrme l'utilite des connaissances semantiques extraites de grands corpus pour estimer les
similarites interphrases.

Par rapport a la premiere experience, l'ecart entre les conditions non autonome et autonome est
beaucoup plus faible, passant de 0.036 pour l'experience 1 a 0.01 pour l'experience 2. Cet ecart
demeure neanmoins statistiquement signiﬁcatif (t(99) = 3.17; p = 0.002). Bien que plus grand,
l'ecart entre les conditions autonome et antérieure (0.014), est statistiquement juste signiﬁcatif
(t(99) = 2.04; p = 0.045). La Figure 3 montre que la condition autonome surpasse la condition
antérieure dans 46 echantillons, alors que l'inverse se produit dans 35 echantillons, les 19
echantillons restants ne montrant aucune difference entre ces deux conditions.

'1':

2:3:
1.
I5 15
‘-1
U 1:2:
[:3
ll 5
‘” @ ﬁﬁﬁmw

E

0.10 0.15 0.20

.4nr¢5rEe:L:1'c‘ 1"

-0.10 -0.05 0.00 0.05
Diflﬁrcnntc unite les. PL. {A1:mn:m:ra¢ -

Figure 3 : Distribution des differences en Pk entre les conditions Autonome et Antérieure

On voit donc que l'avantage de la condition autonome sur la condition antérieure est
principalement dﬁ a quelques echantillons de test pour lesquels la condition autonome est
nettement plus efficace. Rappelons egalement que la condition antérieure donne lieu a des
resultats nettement meilleurs que ceux obtenus lorsque la segmentation s'effectue sans le recours
a des connaissances semantiques complementaires.

5 Conclusion

Les deux experiences rapportees ici montrent que la presence du materiel de test dans le corpus
d'apprentissage de l'ASL augmente l'efﬁcacite de l'algorithme de segmentation meme lorsqu'un
corpus de plus de 25.000.000 mots est utilise. Elles montrent egalement que l'utilisation de
connaissances semantiques independantes ameliore l'efﬁcacite de la segmentation et que ceci
s'observe meme lorsque ces connaissances sont extraites d'annees anterieures de la meme source.
Cette observation souligne la possibilite de constituer par analyse semantique latente des
connaissances semantiques plus ou moins generiques, c'est-a-dire, des connaissances qui peuvent
etre utilisees pour traiter de nouvelles donnees, comme cela a ete recemment propose dans la
recherche de l'antecedent d'une anaphore, dans un systeme de reconnaissance de la parole ou en

209

210

Yves Bestgen

traduction automatique (Bellegarda, 2000; Klebanov, Wiemer-Hastings, 2002; Kim, Chang,
Zhang, 2003). Une question a laquelle la présente étude ne répond pas conceme la possibilité
d'utiliser un corpus tiré d'une autre source, telle qu'un autre journal. Bellegarda (2000) a observé,
en reconnaissance automatique de la parole, qu'un tel espace sémantique est moins efﬁcace.
Cependant, évaluer la proximité sémantique entre deux phrases est probablement moins affecté
par la source du corpus que de prédire le prochain mot d'un énoncé.

Récemment, plusieurs auteurs ont proposé des algorithmes de segmentation, basés
principalement sur la programrnation dynamique, qui égalent ou méme surpassent les résultats de
Choi (Ji, Zha, 2003, Kehagias et al., 2003; Utiyama, Isahara, 2001). Ces algorithmes ne
s'appuient pas sur des connaissances sémantiques supplémentaires. Les résultats de la présente
étude suggerent que leur efﬁcacité pourrait encore étre améliorée en prenant en compte de telles
connaissances. Enﬁn, d'autres techniques que l'ASL ont été proposées pour extraire des
connaissances sémantiques a partir de grands corpus tel pASL (Brants et al., 2002). L'analyse
sémantique latente étant relativement simple a mettre en pratique grace a la disponibilité de
programmes tres puissants tel que SVDPACKC (Berry et al., 1993), son avantage principal est
qu'elle est employée par une communauté de plus en plus large de chercheurs.

Une limitation importante de ce travail réside dans la tache employée pour évaluer l'efﬁcacité de
l'algorithme de segmentation. Identiﬁer les frontieres entre des textes concaténés est une tache
artiﬁcielle et certainement moins complexe que de localiser les changements de themes a
l'intérieur de textes. Le fait que la procédure et le matériel concu par Choi soient devenus une
sorte de "standard" employé par une série de chercheurs pour évaluer leur algorithme ne sufﬁt
pas a la légitimer. Il serait donc utile de conﬁnner les conclusions de la présente étude dans une
tache de segmentation intratexte.

Remerciements

Y. Bestgen est chercheur qualiﬁé du Fonds National de la Recherche (FNRS). Cette recherche
est ﬁnancée par le projet FRFC n° 2.4535.02 et par une “Action de Recherche concertée” du
Gouvemement de la Communauté francaise de Belgique.

Références

BEEFERMAN D., BERGER A., LAFFERTY J. (1999). Statistical models for text segmentation,
Machine Learning, Vol. 34, pp. 177-210.

BELLEGARDA J. (2000). Large vocabulary speech recognition with multispan statistical language
models. IEEE Transactions on Speech and Audio Processing, Vol. 8, pp. 78-84.

BERRY M. (1992). Large scale singular value computation. International jomal of Supercomputer
Application, Vol. 6, 13-49.

Amélioration de la segmentation automatique des textes

BERRY M., Do T., O'BRIEN G., KRISHNA V., VARADHAN S. (1993). SVDPACKC: Version 1.0
user's guide, Tech. Rep. CS-93-194, University of Tennessee, Knoxville, TN, October 1993.

BOLSHAKOV I., GELBUKH A. (2001). Text segmentation into paragraphs based on local text
cohesion. In Proceedings of T ext, Speech and Dialogue (T SD-2001 ), 158-166.

BRANTS T., CHEN, F., TSOCHANTARIDIS I. (2002). Topic-based document segmentation with
probabilistic latent semantic analysis. In Proceedings of CIKM ’02, 211-218

CHOI F. (2000). Advances in domain independent linear text segmentation, In Proceedings of
NAACL-00, 26-33.

CHOI F., WIEMER-HASTINGS P., MOORE J. (2001) Latent semantic analysis for text segmentation,
In Proceedings of NAACL ’0I , 109-1 17.

DEERWESTER S., DUMAIS S., FURNAS G., LANDAUER T., HARSHMAN R. (1990). Indexing by
latent semantic analysis. Journal of the American Society for Information Science, Vol. 41, pp.
391-407.

DEGAND L., SPOOREN W., BESTGEN Y. (2004). On the use of automatic tools for large scale
semantic analyses of causal connectives. In Proceedings of ACL 2004 Workshop on Discourse
Annotation, 25-32.

FERRET O. (2002). Using collocations for topic segmentation and link detection. In Proceedings
of COLING 2002, 260-266.

HEARST M. (1997). TextTiling: Segmenting text into multi-paragraph subtopic passages.
Computational Linguistics, Vol. 23, pp. 33-64.

HEINONEN O. (1998). Optimal multi-paragraph text segmentation by dynamic programming. In
Proceedings of] 7th International Conference on Computational Linguistics (COLING-ACL ’98),
1484-1486.

JI X., ZHA H. (2003). Domain-independent text segmentation using anisotropic diffusion and
dynamic programming. In Proceedings of SIGIR 2003, 322-329.

KAN M., KLAVANS J ., MCKEOWN K. (1998). Linear segmentation and segment signiﬁcance. In
Proceedings of the 6th International Workshop of Very Large Corpora, 197-205.

KAUFMANN, S. (1999). Cohesion and collocation: using context vectors in text segmentation. In
Proceedings of ACL ’99, 591-595.

KEHAGMS A., PAVLINA F., PETRIDIS V. (2003). Linear text segmentation using a dynamic
programming algorithm. In Proceedings of the 10th Conference of the European Chapter of the
Association for Computational Linguistics, 171-178

211

212

Yves Bestgen

KIM Y., CHANG J ., ZHANG B. (2003). An empirical study on dimensionality optimization in text
mining for linguistic. Knowledge Acquisition. In Proceedings of PAKDD 2003, 1 1 1-1 16.

KLEBANOV B., WIEMER-HASTINGS P. (2002). Using ASL for pronominal anaphora resolution. In
Proceedings of the Third International Conference on Computational Linguistics and Intelligent
Text Processing, 197-199.

KOZIMA H. (1993). Text segmentation based on similarity between words. In Proceedings of the
31st Annual Meeting of the Association for Computational Linguistics, 286-288.

LANDAUER T., DUMAIS S. (1997). A solution to Plato’s problem: the latent semantic analysis
theory of acquisition, induction and representation of knowledge, Psychological Review, Vol.
104, pp. 211-240.

LANDAUER T., FOLTZ P., LAHAM D. (1998). An Introduction to latent semantic analysis.
Discourse Processes, Vol. 25, pp. 259-284.

LIN M., NUNAMAKER J ., CHAU, M., CHEN H. (2004). Segmentation of lecture videos based on
text: A method combining multiple linguistic features. In Proceedings of the 37th Hawaii
International Conference on System Sciences.

MANNING C., SCHUTZE H. (1999). Foundations of Statistical Natural Language Processing.
Cambridge: MIT Press.

MORRIS J ., HIRST G. (1991). Lexical cohesion computed by thesaural relations as an indicator of
the structure of text. Computational Linguistics, 17: 21-42.

PEVZNER L., HEARST M. (2002). A Critique and improvement of an evaluation metric for text
segmentation, Computational Linguistics, Vol 28, pp. 19-36

PONTE J ., CROFT W. (1997). Text segmentation by topic. Proceedings of the 1st European
Conference on Research and Advanced Technology for Digital Libraries, 120-129.

SCHMID H. (1994). Probabilistic Part-of-speech tagging using decision trees. Proceedings of
International Conference on New Methods in Language Processing .

UTIYAMA M., ISAHARA H. (2001). A Statistical model for domain-independent text segmentation.
Proceedings of ACL ’200I, 491-498.

