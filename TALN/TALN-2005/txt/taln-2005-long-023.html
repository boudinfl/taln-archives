<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Paradocs: un syst&#232;me d'identification automatique de documents parall&#232;les</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2005, Dourdan, 6&#8211;10 juin 2005
</p>
<p>Paradocs : un syst&#232;me d&#8217;identification automatique de
documents parall&#232;les
</p>
<p>Alexandre Patry et Philippe Langlais
Laboratoire de Recherche Appliqu&#233;e en Linguistique Informatique
</p>
<p>D&#233;partement d&#8217;Informatique et de Recherche Op&#233;rationnelle
Universit&#233; de Montr&#233;al
</p>
<p>C.P. 6128, succursale Centre-ville
H3C 3J7, Montr&#233;al, Qu&#233;bec, Canada
</p>
<p>{patryale,felipe}@iro.umontreal.ca
</p>
<p>Mots-clefs : Corpus parall&#232;les, apprentissage automatique, traduction automatique
Keywords: Parallel documents, machine learning, machine translation
</p>
<p>R&#233;sum&#233; Les corpus parall&#232;les sont d&#8217;une importance capitale pour les applications mul-
tilingues de traitement automatique des langues. Malheureusement, leur raret&#233; est le maillon
faible de plusieurs applications d&#8217;int&#233;r&#234;t. Extraire de tels corpus du Web est une solution viable,
mais elle introduit une nouvelle probl&#233;matique : il n&#8217;est pas toujours trivial d&#8217;identifier les do-
cuments parall&#232;les parmi tous ceux qui ont &#233;t&#233; extraits. Dans cet article, nous nous int&#233;ressons
&#224; l&#8217;identification automatique des paires de documents parall&#232;les contenues dans un corpus
bilingue. Nous montrons que cette t&#226;che peut &#234;tre accomplie avec pr&#233;cision en utilisant un en-
semble restreint d&#8217;invariants lexicaux. Nous &#233;valuons &#233;galement notre approche sur une t&#226;che
de traduction automatique et montrons qu&#8217;elle obtient des r&#233;sultats sup&#233;rieurs &#224; un syst&#232;me de
r&#233;f&#233;rence faisant usage d&#8217;un lexique bilingue.
</p>
<p>Abstract Parallel corpora are playing a crucial role in multilingual natural language pro-
cessing. Unfortunately, the availability of such a resource is the bottleneck in most applications
of interest. Mining the web for such a resource is a viable solution that comes at a price : it is
not always easy to identify parallel documents among the crawled material. In this study we
address the problem of automatically identifying the pairs of texts that are translation of each
other in a set of documents. We show that it is possible to automatically build particularly ef-
ficient content-based methods that make use of very little lexical knowledge. We also evaluate
our approach toward a front-end translation task and demonstrate that our parallel text classifier
yields better performances than another approach based on a rich lexicon.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre Patry et Philippe Langlais
</p>
<p>1 Introduction
</p>
<p>De nos jours, les corpus de documents parall&#232;les (ensemble de documents exprimant le m&#234;me
contenu dans le m&#234;me ordre) jouent un r&#244;le crucial dans les applications multilingues de traite-
ment automatique des langues (V&#233;ronis, 2000). Align&#233; au niveau des phrases, une t&#226;che pouvant
&#234;tre accomplie avec fiabilit&#233; (Langlais et al., 1998), un corpus parall&#232;le s&#8217;av&#232;re tr&#232;s utile aux
concordanciers bilingues (Macklovitch et al., 2000) et est la pierre angulaire de la plupart des
syst&#232;mes commerciaux de m&#233;moire de traduction. Align&#233; au niveau des mots, une t&#226;che mainte-
nant bien ma&#238;tris&#233;e (Brown et al., 1993), un corpus parall&#232;le peut servir &#224; plusieurs applications
telles que la traduction automatique, la d&#233;sambigu&#239;sation de mots ou l&#8217;extraction d&#8217;information
translinguistique.
</p>
<p>Malheureusement, il existe assez peu de corpus parall&#232;les (ensemble de documents parall&#232;les)
riches et bien organis&#233;s comme le sont par exemple les Hansards canadiens (anglais/fran&#231;ais),
les d&#233;bats parlementaires de Hongkong (anglais/chinois), les transcriptions des d&#233;bats du par-
lement europ&#233;en1 (EUROPARL, disponibles en onze langues) ou encore les transcriptions des
d&#233;bats parlementaires du Nunavut (anglais/inuktitut)2.
S&#8217;il existe &#233;galement des ressources telles que la Bible qui sont traduites dans de nombreuses
langues (mais pas n&#233;cessairement organis&#233;es en corpus parall&#232;le), il n&#8217;en reste pas moins que
la raret&#233; des corpus parall&#232;les demeure le goulot d&#8217;&#233;tranglement pour plusieurs applications
d&#8217;int&#233;r&#234;t. Plusieurs solutions ont &#233;t&#233; propos&#233;es pour palier leur absence. Il est par exemple pos-
sible d&#8217;extraire automatiquement des corpus parall&#232;les &#224; partir du Web (Ma &amp; Liberman, 1999;
Kraaij et al., 2003; Resnik &amp; Smith, 2003). Il est &#233;galement possible de tirer profit de corpus
comparables (corpus traitant du m&#234;me sujet sans n&#233;cessairement &#234;tre parall&#232;les) (Munteanu
et al., 2004), voire m&#234;me d&#8217;utiliser des corpus n&#8217;ayant aucune affinit&#233; (Rapp, 1999). D&#8217;autres
misent &#224; plus long terme sur des outils informatiques simplifiant la gestion des donn&#233;es paral-
l&#232;les (Hajlaoui &amp; Boitet, 2004).
Dans cet article, nous nous int&#233;ressons &#224; la d&#233;tection des documents parall&#232;les dans un corpus
bilingue (par exemple extrait d&#8217;un site Web) &#224; l&#8217;aide d&#8217;invariants lexicaux (par exemple donn&#233;es
chiffr&#233;es, entit&#233;s nomm&#233;es, ponctuations). Cette id&#233;e &#233;tait &#224; la base d&#8217;un algorithme d&#8217;aligne-
ment bilingue de phrases d&#233;crit par Simard et al. (1993) ; nous montrons ici qu&#8217;elle s&#8217;applique
&#224; notre probl&#232;me.
</p>
<p>Nous d&#233;crivons en section 2 notre m&#233;thodologie et pr&#233;sentons les diff&#233;rentes m&#233;triques utili-
s&#233;es. Nous montrons en section 3 que notre approche permet d&#8217;identifier sans faute les paires
parall&#232;les d&#8217;une partie du corpus EUROPARL. Nous &#233;valuons &#233;galement notre approche &#224; travers
une t&#226;che de traduction automatique et mesurons des performances sup&#233;rieures &#224; celles d&#8217;une
approche faisant usage d&#8217;un lexique bilingue riche (section 4). Nous discutons en section 5 de
travaux connexes et pr&#233;sentons en section 6 nos conclusions.
</p>
<p>2 M&#233;thodologie
</p>
<p>Nous consid&#233;rons dans cette &#233;tude que nous disposons de deux ensembles de documents: un
ensemble S contenant les documents d&#8217;une langue source et un ensemble T contenant ceux
</p>
<p>1http://www.europarl.eu.int/home/default_fr.htm
2http://www.inuktitutcomputing.ca/NunavutHansards/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Paradocs: un syst&#232;me d&#8217;identification automatique de documents parall&#232;les
</p>
<p>d&#8217;une langue cible. Ces documents peuvent par exemple provenir du Web (Kraaij et al., 2003) et
leur langue peut avoir &#233;t&#233; identifi&#233;e automatiquement, comme ce sera le cas dans les exp&#233;riences
de la section 4.
</p>
<p>Le probl&#232;me que nous r&#233;solvons consiste &#224; d&#233;terminer le sous-ensemble du produit Cart&#233;sien
S &#215; T qui contient les paires de documents parall&#232;les. Nous ne faisons pas usage dans cette
&#233;tude d&#8217;informations externes aux documents comme leur nom ou leurs balises structurelles,
ce qui exclut l&#8217;usage d&#8217;heuristiques bas&#233;es sur les noms de fichiers comme celles d&#233;crites dans
(Resnik &amp; Smith, 2003). Cette contrainte ne d&#233;coule pas d&#8217;une pens&#233;e puriste, mais correspond
&#224; notre volont&#233; d&#8217;&#233;valuer objectivement diff&#233;rentes m&#233;triques n&#8217;utilisant que le contenu des
documents. Ces caract&#233;ristiques externes pourraient cependant &#234;tre incorpor&#233;es facilement &#224;
notre approche.
</p>
<p>L&#8217;identification des paires de documents parall&#232;les est r&#233;alis&#233;e en deux &#233;tapes: le pointage de
toutes les paires du produit Cart&#233;sien S &#215; T et la classification de chacune d&#8217;elles comme
parall&#232;le ou non. Les diff&#233;rents pointages utilis&#233;s sont d&#233;crits dans la section 2.1 et l&#8217;algorithme
de classification dans la section 2.2.
</p>
<p>2.1 M&#233;triques
</p>
<p>Trois diff&#233;rentes familles de m&#233;triques sont utilis&#233;es pour mesurer le parall&#233;lisme de deux do-
cuments. La mesure de cosinus et la distance d&#8217;&#233;dition normalis&#233;e utilisent certaines des unit&#233;s
lexicales des documents: les s&#233;quences de chiffres (NOMBRE), certaines ponctuations (PUNCT)
et les entit&#233;s nomm&#233;es (ENTIT&#201;). Les ponctuations que nous avons consid&#233;r&#233;es sont les paren-
th&#232;ses, les crochets et les guillemets. De plus, nous avons consid&#233;r&#233; comme une entit&#233; nomm&#233;e
tout mot commen&#231;ant par une lettre majuscule mais ne d&#233;butant pas une phrase. Ces types
d&#8217;unit&#233;s lexicales sont relativement ind&#233;pendants des langues consid&#233;r&#233;es. La troisi&#232;me famille
de m&#233;triques utilise la sortie d&#8217;un aligneur de textes au niveau des phrases pour juger du paral-
l&#233;lisme de deux documents.
</p>
<p>Mesure de cosinus (COS) Nous avons repris l&#8217;id&#233;e propos&#233;e par Nadeau et Foster (2004) et
repr&#233;sent&#233; un document par diff&#233;rents vecteurs o&#249; chaque dimension correspond &#224; une unit&#233;
lexicale et chaque coordonn&#233;e &#224; la fr&#233;quence de cette unit&#233; dans le document. Dans nos ex-
p&#233;riences, chaque document est repr&#233;sent&#233; par trois vecteurs: un pour les nombres, un pour les
ponctuations et un pour les entit&#233;s nomm&#233;es. Un exemple d&#8217;une telle repr&#233;sentation est pr&#233;sent&#233;
en figure 1. La similarit&#233; entre deux documents est mesur&#233;e par la mesure de cosinus entre leur
repr&#233;sentation vectorielle, mesure populaire en extraction d&#8217;information.
</p>
<p>Distance d&#8217;&#233;dition normalis&#233;e (EDIT) La repr&#233;sentation vectorielle ne tient pas compte de
l&#8217;ordre des unit&#233;s lexicales dans le document, information qui peut &#234;tre pertinente ici. Nous pro-
posons de repr&#233;senter un document par trois s&#233;quences d&#8217;unit&#233;s lexicales (NOMBRE, PUNCT,
ENTIT&#201;). Le parall&#233;lisme de deux documents peut ainsi &#234;tre mesur&#233; en comparant leurs s&#233;-
quences (voir la figure 1).
Pour mesurer la similarit&#233; de deux s&#233;quences, nous utilisons la distance d&#8217;&#233;dition (Levenshtein,
1966), qui compte le nombre minimal d&#8217;op&#233;rations n&#233;cessaires pour transformer la premi&#232;re s&#233;-
quence en la seconde (les op&#233;rations permises sont l&#8217;insertion, la suppression ou la substitution</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre Patry et Philippe Langlais
</p>
<p>d&#8217;une unit&#233; lexicale). Nous la normalisons ensuite par la longueur de la plus longue des deux
s&#233;quences.
</p>
<p>Approximately 60% very roughly, 60% to 40%, when the 60% is paid by the
tenant and 40% is approximately paid by the Government subsidy.
</p>
<p>apiqqutiqaqqaujunga akunialuk, angiqqaugaluarakku $60 milian kaivainnaqtuq
kiinaujaqarvingmut, kisianittauq tusaqtitauvalliaqqaugama, takuvallialiqtugu $39
milian 807 tausan ammalu taanna angiqtauguni taikkuali amiakkujut $60 milianut
tikillugu kisumut atuqtaugajaqpat ?
</p>
<p>FIG. 1 &#8211; Si nous devions comparer les nombres dans les deux documents ci-haut (extraits an-
glais et inuktitut tir&#233;s des d&#233;bats parlementaires du Nunavut), les repr&#233;sentations vectorielles
utilis&#233;es pour la mesure de cosinus seraient (039, 240, 360, 0807) et (139, 040, 260, 1807). Alors
que les repr&#233;sentations s&#233;quentielles pour mesurer la distance d&#8217;&#233;dition normalis&#233;e seraient
&lt;60, 60, 40, 60, 40&gt; et &lt;60, 39, 807, 60&gt;.
</p>
<p>Scores d&#8217;alignements Une autre source d&#8217;information permettant de mesurer le parall&#233;lisme
de deux documents est la sortie d&#8217;un aligneur de textes au niveau des phrases. Nous avons
utilis&#233; l&#8217;aligneur JAPA (Langlais et al., 1998) qui produit une s&#233;quence d&#8217;alignements et un
score global mesurant le co&#251;t de l&#8217;alignement produit. Les alignements qu&#8217;il produit sont de
type m-n (m,n &#8712; {0, 1, 2}) o&#249; m et n sont respectivement le nombre de phrases sources et le
nombre de phrases cibles impliqu&#233;es dans l&#8217;alignement.
</p>
<p>Nous retenons cinq pointages: le ratio d&#8217;alignements 1-0 ou 0-1, le ratio d&#8217;alignements 1-1, le
ratio d&#8217;alignements 1-2 ou 2-1, le ratio d&#8217;alignements 2-2 et le score global d&#8217;alignement. Nous
nommerons dor&#233;navant les quatre ratios M-N et le score global CO&#219;T. Intuitivement, le r&#233;sultat
de l&#8217;aligneur sur deux documents parall&#232;les devrait contenir plusieurs alignements de type 1-1
et devrait &#234;tre de faible co&#251;t.
</p>
<p>2.2 Identification des paires parall&#232;les
</p>
<p>Chaque paire de documents est d&#233;crite par un ensemble de pointages. Une premi&#232;re approche
pour identifier celles qui sont parall&#232;les consiste &#224; ajuster manuellement des seuils sur ces poin-
tages, une t&#226;che d&#233;licate ne se g&#233;n&#233;ralisant pas n&#233;cessairement bien. Nous avons plut&#244;t utilis&#233;
AdaBoost (Y.Freund &amp; Schapire, 1999), un algorithme d&#8217;apprentissage. Cet algorithme prend
en entr&#233;e un ensemble de paires de documents, leurs pointages et leur &#233;tiquette (parall&#232;le ou
non) et produit &#224; partir de cet ensemble d&#8217;entra&#238;nement une fonction classant une paire comme
parall&#232;le ou non &#224; partir de ses pointages.
</p>
<p>AdaBoost est un algorithme d&#8217;apprentissage it&#233;ratif combinant plusieurs classificateurs faibles
(classificateur juste plus d&#8217;une fois sur deux) en un classificateur plus robuste. &#192; chaque it&#233;-
ration, un classificateur faible est entra&#238;n&#233; &#224; reconna&#238;tre l&#8217;&#233;tiquette de toutes les paires de do-
cuments (&#224; partir des pointages) en accordant plus d&#8217;importance &#224; celles qui ont &#233;t&#233; moins
bien &#233;tiquet&#233;es par les classificateurs faibles pr&#233;c&#233;dents. Les it&#233;rations se poursuivent jusqu&#8217;&#224;
ce qu&#8217;un classificateur faible ait un ratio d&#8217;erreur sup&#233;rieur ou &#233;gal &#224; 50% ou jusqu&#8217;&#224; ce qu&#8217;un
nombre maximal (fix&#233; &#224; l&#8217;avance) d&#8217;it&#233;rations ait &#233;t&#233; atteint. Le classificateur retourn&#233; par Ada-
Boost fait voter les diff&#233;rents classificateurs faibles afin de d&#233;terminer si une paire est parall&#232;le</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Paradocs: un syst&#232;me d&#8217;identification automatique de documents parall&#232;les
</p>
<p>ou non.
</p>
<p>Dans nos exp&#233;riences, nos classificateurs faibles &#233;taient des r&#233;seaux neuronaux (Bishop, 1996)
&#224; une couche cach&#233;e de cinq neurones et apr&#232;s quelques exp&#233;riences informelles, nous avons
d&#233;cid&#233; de borner le nombre d&#8217;it&#233;rations d&#8217;AdaBoost &#224; 75. L&#8217;entra&#238;nement et les tests ont &#233;t&#233;
r&#233;alis&#233;s &#224; l&#8217;aide du logiciel PLEARN 3.
</p>
<p>3 Exp&#233;rience contr&#244;l&#233;e
</p>
<p>EUROPARL est un corpus parall&#232;le tir&#233; de la transcription des d&#233;bats parlementaires europ&#233;ens
s&#8217;&#233;tant tenus entre avril 1996 et septembre 2003 (Koehn, 2002). Les d&#233;bats parlementaires eu-
rop&#233;ens sont traduits en onze langues, mais nous nous sommes concentr&#233;s sur les traductions
anglaises et espagnoles. Notre corpus &#233;tait compos&#233; de 487 textes anglais et de 487 textes espa-
gnols ayant en moyenne environ 2800 phrases chacun.
</p>
<p>3.1 Protocole d&#8217;&#233;valuation
</p>
<p>Parce que les paires de documents parall&#232;les sont bien identifi&#233;es dans EUROPARL, les diff&#233;-
rentes configurations ont &#233;t&#233; compar&#233;es sur la base de leur pr&#233;cision, de leur rappel et de leur
f-mesure (moyenne harmonique de la pr&#233;cision et du rappel). La pr&#233;cision (resp. rappel) est le
ratio du nombre de paires vraiment parall&#232;les que le classificateur a identifi&#233;es sur le nombre
total de paires que le classificateur a identifi&#233;es (resp. sur le nombre total de paires parall&#232;les
dans le corpus). La pr&#233;cision indique la qualit&#233; de l&#8217;ensemble des paires trouv&#233;es et le rappel sa
couverture.
</p>
<p>Les diff&#233;rentes configurations ont &#233;t&#233; &#233;valu&#233;es &#224; l&#8217;aide d&#8217;une validation crois&#233;e en cinq &#233;tapes.
Le produit cart&#233;sien S &#215; T a &#233;t&#233; partitionn&#233; al&#233;atoirement en cinq sous-ensembles de m&#234;me
taille. Ensuite, cinq exp&#233;riences ont &#233;t&#233; lanc&#233;es en testant chaque fois sur un sous-ensemble
diff&#233;rent et en entra&#238;nant avec les paires ne faisant pas partie de ce sous-ensemble de test.
</p>
<p>3.2 Syst&#232;me de r&#233;f&#233;rence (LEXIQUE)
</p>
<p>Pour mettre en contexte les performances de nos diff&#233;rents classificateurs, un syst&#232;me de r&#233;-
f&#233;rence utilisant un lexique bilingue a &#233;t&#233; mis au point. Le lexique bilingue qui a &#233;t&#233; utilis&#233;
contient plus de 70 000 entr&#233;es et provient du projet PYTHO&#209;OL4, qui vise &#224; aider les locuteurs
anglais &#224; apprendre l&#8217;espagnol.
</p>
<p>Un document est repr&#233;sent&#233; par l&#8217;ensemble de ses mots rares (dans le cadre de ce projet, les
mots rares sont ceux n&#8217;apparaissant qu&#8217;une seule fois dans le document) pr&#233;sents dans le lexique
bilingue. Chaque document source est ensuite appari&#233; avec le document cible partageant avec
lui le plus grand nombre de mots rares.
</p>
<p>3http://plearn.sourceforge.net
4http://sourceforge.net/projects/pythonol/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre Patry et Philippe Langlais
</p>
<p>Configuration Performances (%)
COS EDIT NOMBRE PUNCT ENTIT&#201; CO&#219;T M-N pr&#233;cision rappel f-mesure&#8730; &#8730; &#8730; &#8730;
</p>
<p>100 100 100&#8730; &#8730; &#8730; &#8730; &#8730; &#8730; &#8730;
99.8 99.8 99.8&#8730; &#8730;
98.3 99.8 99.0&#8730; &#8730; &#8730;
96.6 99.8 98.1&#8730;
85.8 99.8 92.1&#8730;
65.6 99.4 77.1&#8730; &#8730;
49.3 99.4 62.7&#8730; &#8730; &#8730; &#8730;
24.6 99.2 38.7&#8730; &#8730;
12.4 98.9 21.8
</p>
<p>TAB. 1 &#8211; Pr&#233;cision, rappel et f-mesure de diff&#233;rentes configurations d&#8217;entra&#238;nement du classi-
ficateur. Notez que valeurs rapport&#233;es sont des moyennes sur les cinq &#233;tapes de la validation
crois&#233;e.
</p>
<p>3.3 R&#233;sultats
</p>
<p>Nous avons entra&#238;n&#233; des classificateurs sur plusieurs combinaisons des pointages d&#233;crits dans
la section 2.1. Leurs performances sont pr&#233;sent&#233;es dans la Table 1. La meilleure de nos confi-
gurations et le syst&#232;me de r&#233;f&#233;rence ont tous deux obtenus des r&#233;sultats parfaits.
</p>
<p>Les meilleurs performances des m&#233;triques bas&#233;es sur la distance d&#8217;&#233;dition semblent confirmer
l&#8217;hypoth&#232;se selon laquelle l&#8217;ordre des unit&#233;s lexicales est importante pour l&#8217;identification des
documents parall&#232;les. Il est &#224; noter que le seul usage de la distance d&#8217;&#233;dition sur les nombres
am&#232;ne une f-mesure de 99%, ce qui sugg&#232;re que les nombres sont de tr&#232;s bons indices de
parall&#233;lisme pour ce genre de corpus. En effet, les d&#233;bats parlementaires contiennent plusieurs
nombres stables comme des dates, des num&#233;ros de lois ou encore les comptes de votes.
</p>
<p>On observe &#233;galement que les configurations utilisant les pointages d&#8217;alignements n&#8217;am&#232;nent
pas de bons r&#233;sultats. L&#8217;usage des ratios de types d&#8217;alignements donne en particulier une f-
mesure moyenne inf&#233;rieure d&#8217;au moins 20% aux meilleures configurations et ont &#233;t&#233; instables
dans les diff&#233;rentes &#233;tapes de la validation crois&#233;e.
</p>
<p>4 T&#226;che r&#233;elle
</p>
<p>Nous avons montr&#233; dans la section pr&#233;c&#233;dente qu&#8217;il &#233;tait possible d&#8217;identifier parfaitement les
paires parall&#232;les d&#8217;un corpus bilingue comme EUROPARL. Nous voulons maintenant mesurer
si des performances satisfaisantes peuvent &#234;tre obtenues dans un contexte d&#8217;utilisation plus
repr&#233;sentatif. Nous avons pour cela aspir&#233; le site Web de la Pan American Health Organiza-
tion5. Bien qu&#8217;en principe simple, cette t&#226;che s&#8217;est av&#233;r&#233;e particuli&#232;rement d&#233;licate (nombreux
formats propri&#233;taires, absence d&#8217;une nomenclature pour nommer et identifier les diff&#233;rentes
ressources bilingues).
Le corpus r&#233;sultant, PAHO, totalise 6878 documents dont 2523 ont &#233;t&#233; identifi&#233;s comme &#233;tant
anglais (et 4355 comme espagnols) par SILC6, l&#8217;outil que nous avons utilis&#233; pour identifier la
</p>
<p>5http://www.paho.org.
6http://rali.iro.umontreal.ca.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Paradocs: un syst&#232;me d&#8217;identification automatique de documents parall&#232;les
</p>
<p>langue de chaque document. Au total, ce corpus compte plus de 10 millions de paires poten-
tielles. Chaque document contient en moyenne environ 180 phrases. Une inspection informelle
du corpus a r&#233;v&#233;l&#233; que plusieurs de ces documents sont identiques ou tr&#232;s similaires et que
certains sont bilingues.
</p>
<p>4.1 Protocole d&#8217;&#233;valuation
</p>
<p>Pour cette exp&#233;rience, nous avons mesur&#233; l&#8217;impact de nos diff&#233;rents extracteurs de paires pa-
rall&#232;les sur une t&#226;che de traduction automatique (TA) de l&#8217;espagnol vers l&#8217;anglais. Deux rai-
sons majeures ont men&#233; &#224; ce choix. Premi&#232;rement, l&#8217;identification de documents parall&#232;les n&#8217;a
d&#8217;int&#233;r&#234;t que dans un cadre applicatif donn&#233; ; la traduction &#233;tant l&#8217;application bilingue par ex-
cellence. Deuxi&#232;mement, nous ne connaissons pas les documents parall&#232;les du corpus PAHO ce
qui complique les calculs de pr&#233;cision et de rappel.
</p>
<p>Le moteur de traduction que nous utilisons ici est un moteur probabiliste &#233;tat de l&#8217;art (Koehn
et al., 2003). L&#8217;avantage d&#8217;un tel choix r&#233;side dans le fait que l&#8217;obtention d&#8217;un tel syst&#232;me est
enti&#232;rement automatique une fois un corpus parall&#232;le identifi&#233;.
</p>
<p>Afin d&#8217;&#233;valuer les traductions produites, nous avons t&#233;l&#233;charg&#233; 520 nouvelles phrases du site
de la Pan American Health Organization avec leur traduction. Pour les m&#234;mes raisons d&#8217;auto-
maticit&#233;, nous mesurons la qualit&#233; de nos traductions &#224; l&#8217;aide de quatre m&#233;triques couramment
utilis&#233;es en TA: deux taux d&#8217;erreurs au niveau des phrases (SER) et des mots (WER) et deux
mesures de pr&#233;cision n-grammes (BLEU et NIST) calcul&#233;es par le script mteval7.
Les deux premi&#232;res m&#233;triques varient entre 0 et 100 o&#249; 0 repr&#233;sente une traduction parfaite.
SER (pour Sentence-Error-Rate) est le ratio des phrases produites par le moteur de TA qui sont
diff&#233;rentes de la r&#233;f&#233;rence. WER (pour Word-Error-Rate) calcule la distance d&#8217;&#233;dition normali-
s&#233;e entre les mots de la traduction produite et ceux de la traduction de r&#233;f&#233;rence. BLEU et NIST
comptent le nombre de s&#233;quences partag&#233;es entre la traduction automatique et la traduction de
r&#233;f&#233;rence en donnant plus d&#8217;importance aux s&#233;quences plus longues. Le score BLEU varie entre
0 et 1 (o&#249; 1 est le score de la r&#233;f&#233;rence) alors que le score NIST n&#8217;est pas normalis&#233;8.
En plus de l&#8217;&#233;valuation &#224; l&#8217;aide d&#8217;un moteur de TA, la pr&#233;cision (voir la section 3.1) de chaque
configuration a &#233;t&#233; calcul&#233;e manuellement.
</p>
<p>4.2 R&#233;sultats
</p>
<p>Nous avons compar&#233; les performances de notre moteur de TA lorsqu&#8217;il est entra&#238;n&#233; sur quatre
corpus parall&#232;les diff&#233;rents. Le corpus COS-TOUS a &#233;t&#233; g&#233;n&#233;r&#233; &#224; l&#8217;aide de la mesure de cosi-
nus sur les nombres, sur les ponctuations et sur les entit&#233;s nomm&#233;es (ligne 8 de la Table 1).
Le corpus EDIT-TOUS a &#233;t&#233; obtenu &#224; l&#8217;aide de la configuration ayant obtenue les meilleurs r&#233;-
sultats sur EUROPARL, la distance d&#8217;&#233;dition normalis&#233;e sur les nombres, sur les ponctuations
et sur les entit&#233;s nomm&#233;es (ligne 1 de la Table 1). Le corpus LEXIQUE a &#233;t&#233; produit &#224; l&#8217;aide
du syst&#232;me de r&#233;f&#233;rence (bas&#233; sur l&#8217;utilisation d&#8217;un lexique bilingue). Finalement, le corpus
COS-TOUS &#8746; EDIT-TOUS est l&#8217;union de COS-TOUS et de EDIT-TOUS. Une inspection de ces
deux corpus nous a en effet r&#233;v&#233;l&#233; qu&#8217;ils ne partagent que 229 paires de documents.
</p>
<p>7Disponible &#224; l&#8217;adresse http://www.nist.gov/speech/tests/mt/mt2001/resource.
8Son calcul sur la r&#233;f&#233;rence produit dans notre cas une valeur de 13.11.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre Patry et Philippe Langlais
</p>
<p>Corpus parall&#232;le N SER WER NIST BLEU pr&#233;cision
COS-TOUS &#8746; EDIT-TOUS 494 99.42 60.02 5.3125 0.2435 99.0
LEXIQUE 529 99.42 61.67 5.1989 0.2304 89.2
EDIT-TOUS 390 99.42 61.53 5.1342 0.2290 99.0
COS-TOUS 333 99.23 62.23 5.1629 0.2256 99.7
</p>
<p>TAB. 2 &#8211; Performances de notre moteur de TA lorsque entra&#238;n&#233; sur les corpus parall&#232;les re-
tourn&#233;es par diff&#233;rentes configurations o&#249; N est le nombre de paires identifi&#233;es comme &#233;tant
parall&#232;les.
</p>
<p>Les classificateurs identifiant les paires parall&#232;les ont &#233;t&#233; entra&#238;n&#233;s sur les paires du corpus
EUROPARL. Pour chaque configuration, les paires partageant un document ont &#233;t&#233; rejet&#233;es (ce
sont les paires les plus incertaines). Les performances de traduction des moteurs probabilistes
correspondant sont pr&#233;sent&#233;es en Table 2.
</p>
<p>Contrairement &#224; nos exp&#233;riences sur EUROPARL, la mesure de cosinus et la distance d&#8217;&#233;dition
ont des performances comparables. Cela pourrait s&#8217;expliquer par la plus petite taille des do-
cuments de PAHO (rendant l&#8217;ordre des caract&#233;ristiques moins important) et par l&#8217;&#233;tape de sup-
pression des paires partageant un document. Nous observons que les performances du moteur
entra&#238;n&#233; sur le corpus COS-TOUS &#8746; EDIT-TOUS sont meilleures que celles du moteur entra&#238;n&#233;
sur le corpus LEXIQUE, et ce m&#234;me si ce dernier contient plus de paires. Ce r&#233;sultat est particu-
li&#232;rement int&#233;ressant puisqu&#8217;il montre qu&#8217;il n&#8217;est pas n&#233;cessaire de r&#233;unir un lexique bilingue.
Un autre r&#233;sultat encourageant est la forte pr&#233;cision de tous nos classificateurs (99% ou plus).
</p>
<p>5 Travaux connexes
</p>
<p>Ce travail a &#233;t&#233; inspir&#233; de celui de Nadeau et Foster (2004). Les auteurs ont propos&#233; l&#8217;utilisation
de la mesure de cosinus sur les nombres, les ponctuations, les entit&#233;s nomm&#233;es et le nombre de
paragraphes pour d&#233;tecter les paires de documents parall&#232;les d&#8217;un corpus bilingue de commu-
niqu&#233;s. Ils ont montr&#233; qu&#8217;&#224; l&#8217;aide d&#8217;un filtre sur les dates de publication, ils pouvaient identifier
les documents parall&#232;les du Groupe Canada NewsWire9 avec une grande pr&#233;cision.
</p>
<p>Nous avons &#233;tendu cette id&#233;e de trois fa&#231;ons. Premi&#232;rement nous avons valid&#233; l&#8217;utilisation d&#8217;uni-
t&#233;s lexicales invariantes sur des corpus de natures diff&#233;rentes. Deuxi&#232;mement, nous avons mon-
tr&#233; que l&#8217;ordre de ces caract&#233;ristiques est porteur d&#8217;information. Finalement, nous avons test&#233;
l&#8217;impact de cette approche sur une t&#226;che concr&#232;te: la traduction automatique.
</p>
<p>Notre travail, m&#234;me si men&#233; de fa&#231;on ind&#233;pendante, partage des points communs avec celui de
Munteanu et al. (2004). Les auteurs ont montr&#233; qu&#8217;un moteur de traduction pouvait b&#233;n&#233;ficier
d&#8217;un corpus parall&#232;le extrait automatiquement de corpus comparables. L&#8217;approche qu&#8217;ils ont
propos&#233;e est analogue &#224; la n&#244;tre: ils entra&#238;nent un classificateur (dans leur cas par une approche
de maximum entropie) pour identifier les paires de phrases en relation de traduction (alors que
nous travaillons au niveau du document). Ils font cependant l&#8217;hypoth&#232;se qu&#8217;un corpus parall&#232;le
est disponible afin d&#8217;entra&#238;ner un mod&#232;le de traduction qu&#8217;ils utiliseront ensuite pour aligner les
phrases au niveau des mots. Nous pensons que cette approche est compl&#233;mentaire &#224; la n&#244;tre.
Notre approche serait plus adapt&#233;e pour les corpus o&#249; nous savons &#224; priori qu&#8217;ils contiennent
</p>
<p>9http://www.newswire.ca</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Paradocs: un syst&#232;me d&#8217;identification automatique de documents parall&#232;les
</p>
<p>plusieurs documents parall&#232;les.
</p>
<p>6 Conclusions et travaux futurs
</p>
<p>Nous avons pr&#233;sent&#233; une approche compl&#232;tement automatique permettant d&#8217;identifier les paires
de documents parall&#232;les d&#8217;un corpus bilingue et ce, &#224; l&#8217;aide d&#8217;un nombre restreint d&#8217;infor-
mations lexicales. Nous avons plus pr&#233;cis&#233;ment &#233;tudi&#233; l&#8217;usage de certains invariants lexicaux
comme les nombres, certaines ponctuations et les entit&#233;s nomm&#233;es. Nous avons montr&#233; que
cette approche amenait des r&#233;sultats comparables (voire sup&#233;rieurs) &#224; une approche de r&#233;f&#233;-
rence faisant usage d&#8217;un lexique bilingue riche.
</p>
<p>L&#8217;un des avantages majeurs de notre approche est sa souplesse que nous devons &#224; l&#8217;utilisation
d&#8217;un algorithme d&#8217;apprentissage &#224; la fois simple &#224; mettre en place et efficace. Il est donc tout &#224;
fait possible d&#8217;&#233;tendre la liste des traits (pointages) que nous avons utilis&#233;s pour repr&#233;senter nos
documents. Ajouter comme trait le nombre d&#8217;entr&#233;es d&#8217;un lexique bilingue que partagent deux
documents serait par exemple particuli&#232;rement ais&#233;.
</p>
<p>Nous travaillons actuellement sur l&#8217;am&#233;lioration de deux limitations du syst&#232;me propos&#233;. Pre-
mi&#232;rement, nous avons consid&#233;r&#233; syst&#233;matiquement dans cette &#233;tude toutes les paires du produit
cart&#233;sien entre l&#8217;ensemble des documents sources et cibles. Cela impose des temps de traitement
qui peuvent vite devenir prohibitifs. Certaines heuristiques conservatrices peuvent &#234;tre appli-
qu&#233;es pour limiter l&#8217;espace de recherche des paires de documents parall&#232;les. Nous pouvons par
exemple &#233;liminer les paires de documents dont le rapport de longueur est anormalement grand
ou faible (Kraaij et al., 2003).
Deuxi&#232;mement, nous aimerions v&#233;rifier l&#8217;efficacit&#233; de l&#8217;approche si seulement une partie de
chaque document est inspect&#233;e (par exemple les premi&#232;res phrases). Cela diminuerait le temps
de calcul des pointages et par le fait m&#234;me acc&#233;l&#233;rerait le processus au complet.
</p>
<p>Remerciements
</p>
<p>Nous voudrions remercier Leila Arras et Marie Ouimet pour avoir mis &#224; notre disposition le
corpus PAHO.
</p>
<p>R&#233;f&#233;rences
BISHOP C. M. (1996). Neural networks for pattern recognition. Oxford University Press.
BROWN P. F., PIETRA S. A. D., PIETRA V. J. D. &amp; MERCER R. L. (1993). The mathematics of
statistical machine translation: Parameter estimation. Computational Linguistics, 19(2), 263&#8211;311.
HAJLAOUI N. &amp; BOITET C. (2004). PolyphraZ : a tool for the quantitative and subjective evaluation of
parallel corpora. In Proc. of the International Workshop on Spoken LanguageTranslation, p. 123&#8211;129,
Kyoto, Japan.
KOEHN P. (2002). Europarl: A multilingual corpus for evaluation of machine translation. Draft.
KOEHN P., OCH F. J. &amp; MARCU D. (2003). Statistical phrase-based translation. In Proceedings of the
Second Conference on Human Language Technology Reasearch (HLT), p. 127&#8211;133, Edmonton, Alberta,</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre Patry et Philippe Langlais
</p>
<p>Canada.
KRAAIJ W., NIE J.-Y. &amp; SIMARD M. (2003). Embedding web-based statistical translation models in
cross-language information retrieval. Computational Linguistics, 29(3), 381&#8211;419.
LANGLAIS P., SIMARD M. &amp; VERONIS J. (1998). Methods and practical issues in evaluating alignment
techniques. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics
(ACL), p. 711&#8211;717, Montr&#233;al, Quebec, Canada.
LEVENSHTEIN V. I. (1966). Binary codes capable of correcting deletions, insertions and reversals. Sov.
Phys. Dokl., 6, 707&#8211;710.
MA X. &amp; LIBERMAN M. (1999). Bits: A method for bilingual text search over the web. In Machine
Translation Summit VII, Kent Ridge Digital Labs, National University of Singapore.
MACKLOVITCH E., SIMARD M. &amp; LANGLAIS P. (2000). Transsearch: A free translation memory
on the world wide web. In Second International Conference On Language Resources and Evaluation
(LREC), volume 3, p. 1201&#8211;1208, Athens Greece.
MUNTEANU D. S., FRASER A. &amp; MARCU D. (2004). Improved machine translation performance via
parallel sentence extraction from comparable corpora. In HLT-NAACL, p. 265&#8211;272.
NADEAU D. &amp; FOSTER G. (2004). Real-time identification of parallel texts from bilingual news feed.
In CLINE 2004, p. 21&#8211;36: Computational Linguistics in the North East.
RAPP R. (1999). Automatic identification of word translations from unrelated english and german cor-
pora. In Proceedings of the 37th conference on Association for Computational Linguistics, p. 519&#8211;526:
Association for Computational Linguistics.
RESNIK P. &amp; SMITH N. A. (2003). The web as a parallel corpus. Computational Linguistics, 29,
349&#8211;380. Special Issue on the Web as a Corpus.
SIMARD M., FOSTER G. F. &amp; ISABELLE P. (1993). Using cognates to align sentences in bilingual
corpora. In CASCON &#8217;93: Proceedings of the 1993 conference of the Centre for Advanced Studies on
Collaborative research, p. 1071&#8211;1082: IBM Press.
J. V&#201;RONIS, Ed. (2000). Parallel Text Processing, Alignment and Use of Translation Corpora. Kluwer
Academic.
Y.FREUND &amp; SCHAPIRE R. (1999). A short introduction to boosting. Journal of Japanese Society for
Artificial Intelligence, 14(5), 771&#8211;780. Appearing in Japanese, translation by Naoki Abe.</p>

</div></div>
</body></html>