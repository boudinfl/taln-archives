TALN 2005, Dourdan, 6-10 juin 2005

Paradocs : un systeme d’identiﬁcation automatique de
documents paralleles

Alexandre Patry et Philippe Langlais
Laboratoire de Recherche Appliquée en Linguistique Informatique
Département d’Informatique et de Recherche Opérationnelle
Université de Montréal
C.P 6128, succursale Centre-ville
H3C 3J7, Montréal, Québec, Canada
{patryale,felipe}@iro.umontreal.ca

Mots-clefs 2 Corpus paralleles, apprentissage automatique, traduction automatique

Keywords: Parallel documents, machine learning, machine translation

Résumé Les corpus paralleles sont d’une importance capitale pour les applications mul-
tilingues de traitement automatique des langues. Malheureusement, leur rareté est le maillon
faible de plusieurs applications d’intérét. Extraire de tels corpus du Web est une solution viable,
mais elle introduit une nouvelle problématique : il n’est pas toujours trivial d’identiﬁer les do-
cuments paralleles parmi tous ceux qui ont été extraits. Dans cet article, nous nous intéressons
a l’identiﬁcation automatique des paires de documents paralleles contenues dans un corpus
bilingue. Nous montrons que cette tache peut étre accomplie avec precision en utilisant un en-
semble restreint d’invariants lexicaux. Nous évaluons également notre approche sur une tache
de traduction automatique et montrons qu’elle obtient des résultats supérieurs a un systeme de
référence faisant usage d’un lexique bilingue.

Abstract Parallel corpora are playing a crucial role in multilingual natural language pro-
cessing. Unfortunately, the availability of such a resource is the bottleneck in most applications
of interest. Mining the web for such a resource is a viable solution that comes at a price : it is
not always easy to identify parallel documents among the crawled material. In this study we
address the problem of automatically identifying the pairs of texts that are translation of each
other in a set of documents. We show that it is possible to automatically build particularly ef-
ﬁcient content-based methods that make use of very little lexical knowledge. We also evaluate
our approach toward a front-end translation task and demonstrate that our parallel text classiﬁer
yields better performances than another approach based on a rich lexicon.

Alexandre Patry et Philippe Langlais

1 Introduction

De nos jours, les corpus de documents paralléles (ensemble de documents exprimant le meme
contenu dans le meme ordre) jouent un rele crucial dans les applications multilingues de traite-
ment automatique des langues (Véronis, 2000). Aligné au niveau des phrases, une tache pouvant
etre accomplie avec ﬁabilité (Langlais et al., 1998), un corpus parallele s’avere tres utile aux
concordanciers bilingues (Macklovitch et al., 2000) et est la pierre angulaire de la plupart des
systemes commerciaux de mémoire de traduction. Aligné au niveau des mots, une tache mainte-
nant bien maitrisée (Brown et al. , 1993), un corpus parallele peut servir a plusieurs applications
telles que la traduction automatique, la désambiguisation de mots ou l’eXtraction d’information
translinguistique.

Malheureusement, il existe assez peu de corpus paralléles (ensemble de documents paralleles)
riches et bien organises comme le sont par exemple les Hansards canadiens (anglais/frangais),
les débats parlementaires de Hongkong (anglais/chinois), les transcriptions des débats du par-
lement européenl (EUROPARL, disponibles en onze langues) ou encore les transcriptions des
débats parlementaires du Nunavut (anglais/inuktitut)2.

S’il existe également des ressources telles que la Bible qui sont traduites dans de nombreuses
langues (mais pas nécessairement organisées en corpus parallele), il n’en reste pas moins que
la rareté des corpus paralleles demeure le goulot d’étranglement pour plusieurs applications
d’intéret. Plusieurs solutions ont été proposées pour palier leur absence. Il est par exemple pos-
sible d’extraire automatiquement des corpus paralleles a partir du Web (Ma & Liberman, 1999;
Kraaij et al., 2003; Resnik & Smith, 2003). Il est également possible de tirer proﬁt de corpus
comparables (corpus traitant du meme sujet sans nécessairement etre paralleles) (Munteanu
et al., 2004), voire meme d’utiliser des corpus n’ayant aucune afﬁnité (Rapp, 1999). D’autres
misent a plus long terme sur des outils informatiques simpliﬁant la gestion des données paral-
leles (Hajlaoui & Boitet, 2004).

Dans cet article, nous nous intéressons a la detection des documents paralleles dans un corpus
bilingue (par exemple extrait d’un site Web) a l’aide d’invariants lexicaux (par exemple données
chiffrées, entités nommées, ponctuations). Cette idée était a la base d’un algorithme d’aligne-
ment bilingue de phrases décrit par Simard et al. (1993); nous montrons ici qu’elle s’applique
a notre probleme.

Nous décrivons en section 2 notre méthodologie et présentons les différentes métriques utili-
sées. Nous montrons en section 3 que notre approche permet d’identiﬁer sans faute les paires
paralleles d’une partie du corpus EUROPARL. Nous évaluons également notre approche a travers
une tache de traduction automatique et mesurons des performances supérieures a celles d’une
approche faisant usage d’un lexique bilingue riche (section 4). Nous discutons en section 5 de
travaux connexes et présentons en section 6 nos conclusions.

2 Méthodologie

Nous considérons dans cette etude que nous disposons de deux ensembles de documents: un
ensemble 8 contenant les documents d’une langue source et un ensemble T contenant ceux

lhttpz//www.europarl.eu.int/home/default_fr.htm
Zhttp://www.inuktitutcomputing.ca/NunavutHansards/

Paradocs: un systeme d’identiﬁcation automatique de documents paralleles

d’une langue cible. Ces documents peuvent par exemple provenir du Web (Kraaij et al. , 2003) et
leur langue peut avoir été identiﬁée automatiquement, comme ce sera le cas dans les expériences
de la section 4.

Le probleme que nous résolvons consiste a déterminer le sous-ensemble du produit Cartésien
8 X T qui contient les paires de documents paralleles. Nous ne faisons pas usage dans cette
étude d’informations extemes aux documents comme leur nom ou leurs balises structurelles,
ce qui exclut l’usage d’heuristiques basées sur les noms de ﬁchiers comme celles décrites dans
(Resnik & Smith, 2003). Cette contrainte ne découle pas d’une pensée puriste, mais correspond
a notre volonté d’évaluer objectivement différentes métriques n’uti1isant que le contenu des
documents. Ces caractéristiques extemes pourraient cependant étre incorporées facilement a
notre approche.

L’identiﬁcation des paires de documents paralleles est réalisée en deux étapes: le pointage de
toutes les paires du produit Cartésien 8 X T et la classiﬁcation de chacune d’elles comme
parallele ou non. Les différents pointages utilisés sont décrits dans la section 2.1 et l’algorithme
de classiﬁcation dans la section 2.2.

2.1 Métriques

Trois différentes familles de métriques sont utilisées pour mesurer le parallélisme de deux do-
cuments. La mesure de cosinus et la distance d’édition normalisée utilisent certaines des unités
lexicales des documents: les séquences de chiffres (NOMBRE), certaines ponctuations (PUNCT)
et les entités nommées (ENTITE). Les ponctuations que nous avons considérées sont les paren-
theses, les crochets et les guillemets. De plus, nous avons considéré comme une entité nommée
tout mot commencant par une lettre majuscule mais ne débutant pas une phrase. Ces types
d’unités lexicales sont relativement indépendants des langues considérées. La troisieme famille
de métriques utilise la sortie d’un aligneur de textes au niveau des phrases pour juger du paral-
lélisme de deux documents.

Mesure de cosinus (COS) Nous avons repris l’idée proposée par Nadeau et Foster (2004) et
représenté un document par différents vecteurs ou chaque dimension correspond a une unité
lexicale et chaque coordonnée a la fréquence de cette unité dans le document. Dans nos ex-
périences, chaque document est représenté par trois vecteurs: un pour les nombres, un pour les
ponctuations et un pour les entités nommées. Un exemple d’une telle représentation est présenté
en ﬁgure 1. La sirnilarité entre deux documents est mesurée par la mesure de cosinus entre leur
représentation vectorielle, mesure populaire en extraction d’information.

Distance d’édition norrnalisée (EDIT) La représentation vectorielle ne tient pas compte de
l’ordre des unités lexicales dans le document, information qui peut étre pertinente ici. Nous pro-
posons de représenter un document par trois séquences d’unités lexicales (NOMBRE, PUNCT,
ENTITE). Le parallélisme de deux documents peut ainsi étre mesuré en comparant leurs se-
quences (voir la ﬁgure 1).

Pour mesurer la sirnilarité de deux séquences, nous utilisons la distance d’édition (Levenshtein,
1966), qui compte le nombre minimal d’opérations nécessaires pour transformer la premiere se-
quence en la seconde (les opérations perrnises sont l’insertion, la suppression ou la substitution

Alexandre Patry et Philippe Langlais

d’une unité lexicale). Nous la normalisons ensuite par la longueur de la plus longue des deux
séquences.

Approximately 60% very roughly, 60% to 40%, when the 60% is paid by the
tenant and 40% is approximately paid by the Government subsidy.

apiqqutiqaqqaujunga akunialuk, angiqqaugaluarakku $60 milian kaivainnaqtuq
kiinaujaqarvingmut, kisianittauq tusaqtitauvalliaqqaugama, takuvallialiqtugu $39
milian 807 tausan aInmalu taanna angiqtauguni taikkuali amiakkujut $60 milianut
tikillugu kisumut atuqtaugaj aqpat ?

FIG. 1 — Si nous devions comparer les nombres dans les deux documents ci-haut (extraits an-
glais et inuktitut tirés des débats parlementaires du Nunavut), les représentations vectorielles
utilisées pour la mesure de cosinus seraient (039, 240, 360, 0807) et (139,040,260,1807). Alors
que les représentations séquentielles pour mesurer la distance d’édition normalisée seraient
< 60, 60, 40, 60, 40 > et < 60,39, 807, 60 >.

Scores d’alignements Une autre source d’information permettant de mesurer le parallélisme
de deux documents est la sortie d’un aligneur de textes au niveau des phrases. Nous avons
utilisé l’aligneur JAPA (Langlais et al., 1998) qui produit une séquence d’alignements et un
score global mesurant le com‘ de l’alignement produit. Les alignements qu’il produit sont de
type m-n (m, n E «[0, 1, 2}) ou m et n sont respectivement le nombre de phrases sources et le
nombre de phrases cibles impliquées dans l’alignement.

Nous retenons cinq pointages: le ratio d’alignements I-0 ou 0-], le ratio d’a1ignements 1-], le
ratio d’alignements I -2 ou 2-], le ratio d’alignements 2-2 et le score global d’alignement. Nous
nommerons dorénavant les quatre ratios M-N et le score global COUT. Intuitivement, le résultat
de l’a1igneur sur deux documents paralleles devrait contenir plusieurs alignements de type I -I
et devrait étre de faible coﬁt.

2.2 Identiﬁcation des paires paralléles

Chaque paire de documents est décrite par un ensemble de pointages. Une premiere approche
pour identiﬁer celles qui sont paralleles consiste a ajuster manuellement des seuils sur ces poin-
tages, une tache délicate ne se généralisant pas nécessairement bien. Nous avons plutot utilisé
AdaBoost (Y.Freund & Schapire, 1999), un algorithme d’apprentissage. Cet algorithme prend
en entrée un ensemble de paires de documents, leurs pointages et leur étiquette (parallele ou
non) et produit a partir de cet ensemble d’entrainement une fonction classant une paire comme
parallele ou non a partir de ses pointages.

AdaBoost est un algorithme d’apprentissage itératif combinant plusieurs classiﬁcateursfaibles
(classiﬁcateur juste plus d’une fois sur deux) en un classiﬁcateur plus robuste. A chaque ité-
ration, un classiﬁcateur faible est entrainé a reconnaitre l’étiquette de toutes les paires de do-
cuments (a partir des pointages) en accordant plus d’importance a celles qui ont été moins
bien étiquetées par les classiﬁcateurs faibles précédents. Les itérations se poursuivent jusqu’a
ce qu’un classiﬁcateur faible ait un ratio d’erreur supérieur ou égal a 50% ou jusqu’a ce qu’un
nombre maximal (ﬁxé a l’avance) d’itérations ait été atteint. Le classiﬁcateur retourné par Ada-
Boost fait voter les différents classiﬁcateurs faibles aﬁn de déterminer si une paire est parallele

Paradocs: un systeme d’identiﬁcation automatique de documents paralleles

O11 I1OI1.

Dans nos expériences, nos classiﬁcateurs faibles étaient des réseaux neuronaux (Bishop, 1996)
a une couche cachée de cinq neurones et apres quelques expériences informelles, nous avons
décidé de borner 1e nombre d’itérations d’AdaBoost a 75. L’ entrainement et les tests ont été
réalisés a 1’aide du logiciel PLEARN 3.

3 Expérience contrﬁlée

EUROPARL est un corpus parallele tiré de la transcription des débats parlementaires européens
s’étant tenus entre avril 1996 et septembre 2003 (Koehn, 2002). Les débats parlementaires eu-
ropéens sont traduits en onze langues, mais nous nous sommes concentrés sur les traductions
anglaises et espagnoles. Notre corpus était composé de 487 textes anglais et de 487 textes espa-
gnols ayant en moyenne environ 2800 phrases chacun.

3.1 Protocole d’évaluation

Parce que les paires de documents paralleles sont bien identiﬁées dans EUROPARL, les diffé-
rentes conﬁgurations ont été comparées sur la base de leur précision, de leur rappel et de leur
f-mesure (moyenne harmonique de la précision et du rappel). La précision (resp. rappel) est le
ratio du nombre de paires vraiment paralleles que le classiﬁcateur a identiﬁées sur le nombre
total de paires que le classiﬁcateur a identiﬁées (resp. sur le nombre total de paires paralleles
dans le corpus). La précision indique la qualité de 1’ensemb1e des paires trouvées et le rappel sa
couverture.

Les différentes conﬁgurations ont été évaluées a 1’aide d’une validation croisée en cinq étapes.
Le produit cartésien 8 X T a été partitionné aléatoirement en cinq sous-ensembles de méme
taille. Ensuite, cinq expériences ont été lancées en testant chaque fois sur un sous-ensemble
différent et en entrainant avec les paires ne faisant pas partie de ce sous-ensemble de test.

3.2 Systéme de référence (LEXIQUE)

Pour mettre en contexte les performances de nos différents classiﬁcateurs, un systeme de ré-
férence utilisant un lexique bilingue a été Inis au point. Le lexique bilingue qui a été utilisé
contient plus de 70 000 entrées et provient du projet PYTHONOL4, qui vise a aider les locuteurs
anglais a apprendre 1’espagno1.

Un document est représenté par 1’ensemble de ses mots rares (dans le cadre de ce projet, les
mots rares sont ceux n’apparaissant qu’une seule fois dans le document) presents dans le lexique
bilingue. Chaque document source est ensuite apparié avec le document cible partageant avec
lui le plus grand nombre de mots rares.

3http://plearn.sourceforge.net
4http://sourceforge.net/projects/pythonol/

Alexandre Patry et Philippe Langlais

Conﬁguration Performances (%)
COS EDIT NOMBRE PUNCT ENTITE COUT M-N précision rappel f—mesure

\/ \/ \/ \/ 100 100 100

\/ \/ \/ \/ \/ \/ \/ 99.8 99.8 99.8
\/ \/ 98.3 99.8 99.0

\/ \/ \/ 96.6 99.8 98.1

\/ 85.8 99.8 92.1

\/ 65.6 99.4 77.1

\/ \/ 49.3 99.4 62.7

\/ \/ \/ \/ 24.6 99.2 38.7
\/ \/ 12.4 98.9 21.8

TAB. 1 — Précision, rappel et f—mesure de différentes conﬁgurations d’entrainement du classi-
ﬁcateur. Notez que valeurs rapportées sont des moyennes sur les cinq étapes de la validation
croisée.

3.3 Résultats

Nous avons entrainé des classiﬁcateurs sur plusieurs combinaisons des pointages décrits dans
la section 2.1. Leurs performances sont présentées dans la Table 1. La meilleure de nos conﬁ-
gurations et le systeme de référence ont tous deux obtenus des résultats parfaits.

Les meilleurs performances des métriques basées sur la distance d’édition semblent conﬁrmer
l’hypothese selon laquelle l’ordre des unités lexicales est importante pour l’identiﬁcation des
documents paralleles. Il est a noter que le seul usage de la distance d’édition sur les nombres
amene une f—mesure de 99%, ce qui suggere que les nombres sont de tres bons indices de
parallélisme pour ce genre de corpus. En effet, les débats parlementaires contiennent plusieurs
nombres stables comme des dates, des numéros de lois ou encore les comptes de votes.

On observe également que les conﬁgurations utilisant les pointages d’alignements n’amenent
pas de bons résultats. L’usage des ratios de types d’a1ignements donne en particulier une f-
mesure moyenne inférieure d’au moins 20% aux meilleures conﬁgurations et ont été instables
dans les différentes étapes de la validation croisée.

4 Téiche réelle

Nous avons montré dans la section précédente qu’il était possible d’identiﬁer parfaitement les
paires paralleles d’un corpus bilingue comme EUROPARL. Nous voulons maintenant mesurer
si des performances satisfaisantes peuvent étre obtenues dans un contexte d’utilisation plus
représentatif. Nous avons pour cela aspiré le site Web de la Pan American Health Organiza-
ti0n5. Bien qu’en principe simple, cette tache s’est avérée particulierement délicate (nombreux
formats propriétaires, absence d’une nomenclature pour nommer et identiﬁer les différentes
ressources bilingues).

Le corpus résultant, PAHO, totalise 6878 documents dont 2523 ont été identiﬁés comme étant
anglais (et 4355 comme espagnols) par SILC6, l’outil que nous avons utilisé pour identiﬁer la

Shttp : //www . paho . org.
éhttp : //rali . iro .umontreal . ca.

Paradocs: un systeme d’identiﬁcation automatique de documents paralleles

langue de chaque document. Au total, ce corpus compte plus de 10 millions de paires poten-
tielles. Chaque document contient en moyenne environ 180 phrases. Une inspection informelle
du corpus a révélé que plusieurs de ces documents sont identiques ou tres similaires et que
certains sont bilingues.

4.1 Protocole d’évaluation

Pour cette expérience, nous avons mesuré l’impact de nos différents extracteurs de paires pa-
ralleles sur une tache de traduction automatique (TA) de l’espagnol vers l’anglais. Deux rai-
sons majeures ont mené a ce choix. Premierement, l’identiﬁcation de documents paralleles n’a
d’intérét que dans un cadre applicatif donné; la traduction étant l’application bilingue par ex-
cellence. Deuxiemement, nous ne connaissons pas les documents paralleles du corpus PAHO ce
qui complique les calculs de précision et de rappel.

Le moteur de traduction que nous utilisons ici est un moteur probabiliste état de l’art (Koehn
et al., 2003). L’ avantage d’un tel choix réside dans le fait que l’obtention d’un tel systeme est
entierement automatique une fois un corpus parallele identiﬁé.

Aﬁn d’évaluer les traductions produites, nous avons téléchargé 520 nouvelles phrases du site
de la Pan American Health Organization avec leur traduction. Pour les memes raisons d’auto-
maticité, nous mesurons la qualité de nos traductions a l’aide de quatre métriques couraInment
utilisées en TA: deux taux d’erreurs au niveau des phrases (SER) et des mots (WER) et deux
mesures de précision n-grammes (BLEU et NIST) calculées par le script mt eva 17.

Les deux premieres métriques varient entre 0 et 100 ou 0 représente une traduction parfaite.
SER (pour Sentence-Error-Rate) est le ratio des phrases produites par le moteur de TA qui sont
différentes de la référence. WER (pour Word-Error-Rate) calcule la distance d’édition normali-
sée entre les mots de la traduction produite et ceux de la traduction de référence. BLEU et NIST
comptent le nombre de séquences partagées entre la traduction automatique et la traduction de
référence en donnant plus d’importance aux séquences plus longues. Le score BLEU varie entre
0 et 1 (ou 1 est le score de la référence) alors que le score NIST n’est pas normalisés.

En plus de l’évaluation a l’aide d’un moteur de TA, la précision (voir la section 3.1) de chaque
conﬁguration a été calculée manuellement.

4.2 Résultats

Nous avons comparé les performances de notre moteur de TA lorsqu’il est entrainé sur quatre
corpus paralleles différents. Le corpus COS-TOUS a été généré a l’aide de la mesure de cosi-
nus sur les nombres, sur les ponctuations et sur les entités nommées (ligne 8 de la Table 1).
Le corpus EDIT-TOUS a été obtenu a l’aide de la conﬁguration ayant obtenue les meilleurs re-
sultats sur EUROPARL, la distance d’édition normalisée sur les nombres, sur les ponctuations
et sur les entités nommées (ligne 1 de la Table 1). Le corpus LEXIQUE a été produit a l’aide
du systeme de référence (basé sur l’utilisation d’un lexique bilingue). Finalement, le corpus
COS-TOUS U EDIT-TOUS est l’union de COS-TOUS et de EDIT-TOUS. Une inspection de ces
deux corpus nous a en effet révélé qu’ils ne partagent que 229 paires de documents.

7Disponible a l’adresse http : / /www . ni st . gov/ speech/test s /mt /mt2 00 1 /resource.
8Son calcul sur la référence produit dans notre cas une Valeur de 13.11.

Alexandre Patry et Philippe Langlais

Corpus parallele N SER WER NIST BLEU precision
COS-TOUS U EDIT-TOUS 494 99.42 60.02 5.3125 0.2435 99.0
LEXIQUE 529 99.42 61.67 5.1989 0.2304 89.2
EDIT-TOUS 390 99.42 61.53 5.1342 0.2290 99.0
COS-TOUS 333 99.23 62.23 5.1629 0.2256 99.7

TAB. 2 — Performances de notre moteur de TA lorsque entraine sur les corpus paralleles re-
tournees par différentes conﬁgurations 011 N est le nombre de paires identiﬁées comme étant
paralleles.

Les classiﬁcateurs identiﬁant les paires paralleles ont ete entraines sur les paires du corpus
EUROPARL. Pour chaque conﬁguration, les paires partageant un document ont ete rejetées (ce
sont les paires les plus incertaines). Les performances de traduction des moteurs probabilistes
correspondant sont présentées en Table 2.

Contrairement a nos experiences sur EUROPARL, la mesure de cosinus et la distance d’édition
ont des performances comparables. Cela pourrait s’expliquer par la plus petite taille des do-
cuments de PAHO (rendant l’ordre des caractéristiques moins important) et par l’étape de sup-
pression des paires partageant un document. Nous observons que les performances du moteur
entraine sur le corpus COS-TOUS U EDIT-TOUS sont meilleures que celles du moteur entraine
sur le corpus LEXIQUE, et ce meme si ce dernier contient plus de paires. Ce résultat est particu-
lierement interessant puisqu’il montre qu’il n’est pas nécessaire de réunir un lexique bilingue.
Un autre résultat encourageant est la forte precision de tous nos classiﬁcateurs (99% ou plus).

5 Travaux connexes

Ce travail a ete inspire de celui de Nadeau et Foster (2004). Les auteurs ont propose l’utilisation
de la mesure de cosinus sur les nombres, les ponctuations, les entites nommees et le nombre de
paragraphes pour detecter les paires de documents paralleles d’un corpus bilingue de commu-
niques. Ils ont montre qu’a l’aide d’un ﬁltre sur les dates de publication, ils pouvaient identiﬁer
les documents paralleles du Groupe Canada NewsWire9 avec une grande precision.

Nous avons étendu cette idee de trois fagons. Premierement nous avons valide l’utilisation d’uni-
tes lexicales invariantes sur des corpus de natures différentes. Deuxiemement, nous avons mon-
tre que l’ordre de ces caractéristiques est porteur d’information. Finalement, nous avons teste
l’impact de cette approche sur une tache concrete: la traduction automatique.

Notre travail, meme si mene de fagon independante, partage des points communs avec celui de
Munteanu et al. (2004). Les auteurs ont montre qu’un moteur de traduction pouvait beneﬁcier
d’un corpus parallele extrait automatiquement de corpus comparables. L’approche qu’ils ont
proposée est analogue a la notre: ils entrainent un classiﬁcateur (dans leur cas par une approche
de maximum entropie) pour identiﬁer les paires de phrases en relation de traduction (alors que
nous travaillons au niveau du document). Ils font cependant l’hypothese qu’un corpus parallele
est disponible aﬁn d’entrainer un modele de traduction qu’ils utiliseront ensuite pour aligner les
phrases au niveau des mots. Nous pensons que cette approche est complementaire a la notre.
Notre approche serait plus adaptee pour les corpus o1‘1 nous savons a priori qu’ils contiennent

9http://www.newswire.ca

Paradocs: un systeme d’identiﬁcation automatique de documents paralleles

plusieurs documents paralleles.

6 Conclusions et travaux futurs

Nous avons présenté une approche completement automatique permettant d’identiﬁer les paires
de documents paralleles d’un corpus bilingue et ce, a l’aide d’un nombre restreint d’infor-
mations lexicales. Nous avons plus précisément étudié l’usage de certains invariants lexicaux
comme les nombres, certaines ponctuations et les entités nommées. Nous avons montré que
cette approche amenait des résultats comparables (voire supérieurs) a une approche de réfé-
rence faisant usage d’un lexique bilingue riche.

L’un des avantages majeurs de notre approche est sa souplesse que nous devons a l’utilisation
d’un algorithme d’apprentissage a la fois simple a mettre en place et efﬁcace. Il est donc tout a
fait possible d’étendre la liste des traits (pointages) que nous avons utilisés pour représenter nos
documents. Ajouter comme trait le nombre d’entrées d’un lexique bilingue que partagent deux
documents serait par exemple particulierement aisé.

Nous travaillons actuellement sur l’amélioration de deux limitations du systeme proposé. Pre-
mierement, nous avons considéré systématiquement dans cette étude toutes les paires du produit
cartésien entre l’ensemble des documents sources et cibles. Cela impose des temps de traitement
qui peuvent vite devenir prohibitifs. Certaines heuristiques conservatrices peuvent étre appli-
quées pour limiter l’espace de recherche des paires de documents paralleles. Nous pouvons par
exemple éliminer les paires de documents dont le rapport de longueur est anormalement grand
ou faible (Kraaij et al., 2003).

Deuxiemement, nous aimerions vériﬁer l’efﬁcacité de l’approche si seulement une partie de
chaque document est inspectée (par exemple les premieres phrases). Cela diminuerait le temps
de calcul des pointages et par le fait meme accélérerait le processus au complet.

Remerciements

Nous voudrions remercier Leila Arras et Marie Ouimet pour avoir mis a notre disposition le
corpus PAHO.

Références

BISHOP C. M. (1996). Neural networks for pattern recognition. Oxford University Press.
BROWN P. F., PIETRA S. A. D., PIETRA V. J. D. & MERCER R. L. (1993). The mathematics of
statistical machine translation: Parameter estimation. Computational Linguistics, 19(2), 263-311.

HAJLAOUI N. & BOITET C. (2004). Po1yphraZ 2 a tool for the quantitative and subjective evaluation of
parallel corpora. In Proc. of the International Workshop on Spoken LanguageTranslation, p. 123-129,
Kyoto, Japan.

KOEHN P. (2002). Europarlz A multilingual corpus for evaluation of machine translation. Draft.

KOEHN P., OCH F. J. & MARCU D. (2003). Statistical phrase-based translation. In Proceedings of the
Second Conference on Human Language Technology Reasearch (HLT), p. 127-133, Edmonton, Alberta,

Alexandre Patry et Philippe Langlais

Canada.

KRAAIJ W., NIE J .-Y. & SIMARD M. (2003). Embedding web-based statistical translation models in
cross-language information retrieval. Computational Linguistics, 29(3), 381-419.

LANGLAIS P., SIMARD M. & VERONIS J . (1998). Methods and practical issues in evaluating alignment
techniques. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics
(ACL), p. 711-717, Montréal, Quebec, Canada.

LEVENSHTEIN V. I. (1966). Binary codes capable of correcting deletions, insertions and reversals. Sov.
Phys. Dokl., 6, 707-710.

MA X. & LIBERMAN M. (1999). Bits: A method for bilingual text search over the web. In Machine
Translation Summit VII, Kent Ridge Digital Labs, National University of Singapore.

MACKLOVITCH E., SIMARD M. & LANGLAIS P. (2000). Transsearch: A free translation memory
on the world wide web. In Second International Conference On Language Resources and Evaluation
(LREC), volume 3, p. 1201-1208, Athens Greece.

MUNTEANU D. S., FRASER A. & MARCU D. (2004). Improved machine translation performance via
parallel sentence extraction from comparable corpora. In HLT-NAACL, p. 265-272.

NADEAU D. & FOSTER G. (2004). Real-time identiﬁcation of parallel texts from bilingual news feed.
In CLINE 2004, p. 21-36: Computational Linguistics in the North East.

RAPP R. (1999). Automatic identiﬁcation of word translations from unrelated english and german cor-
pora. In Proceedings of the 37th conference on Association for Computational Linguistics, p. 519-526:
Association for Computational Linguistics.

RESNIK P. & SMITH N. A. (2003). The web as a parallel corpus. Computational Linguistics, 29,
349-380. Special Issue on the Web as a Corpus.

SIMARD M., FOSTER G. F. & ISABELLE P. (1993). Using cognates to align sentences in bilingual
corpora. In CASCON ’93: Proceedings of the 1993 conference of the Centre for Advanced Studies on
Collaborative research, p. 1071-1082: IBM Press.

J . VERONIS, Ed. (2000). Parallel Text Processing, Alignment and Use of Translation Corpora. Kluwer
Academic.

Y.FREUND & SCHAPIRE R. (1999). A short introduction to boosting. Journal of Japanese Society for
Artificial Intelligence, 14(5), 771-780. Appearing in Japanese, translation by Naoki Abe.

