<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Alignement de mots par apprentissage de r&#232;gles de propagation syntaxique en corpus de taille restreinte</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2005, Dourdan, 6&#8211;10 juin 2005
</p>
<p>Alignement de mots par apprentissage artificiel de r&#232;gles de
propagation syntaxique en corpus de taille restreinte
</p>
<p>Sylwia Ozdowska (1), Vincent Claveau (2)
(1) ERSS - Universit&#233; de Toulouse le Mirail
</p>
<p>5 all&#233;es Antonio Machado
31058 Toulouse Cedex 1
ozdowska@univ-tlse2.fr
</p>
<p>(2) OLST - Universit&#233; de Montr&#233;al
CP 6128 succ. Centre-Ville
</p>
<p>Montr&#233;al, QC, H3C 3J7, Canada
vincent.claveau@umontreal.ca
</p>
<p>Mots-clefs : alignement de mots, corpus align&#233;s, apprentissage artificiel, programma-
tion logique inductive, analyse syntaxique
</p>
<p>Keywords: word alignment, aligned corpus, machine learning, inductive logic
programming, syntactic analysis
</p>
<p>R&#233;sum&#233; Cet article pr&#233;sente et &#233;value une approche originale et efficace permettant
d&#8217;aligner automatiquement un bitexte au niveau des mots. Pour cela, cette approche tire parti
d&#8217;une analyse syntaxique en d&#233;pendances des bitextes effectu&#233;e par les outils SYNTEX et utilise
une technique d&#8217;apprentissage artificiel, la programmation logique inductive, pour apprendre
automatiquement des r&#232;gles dites de propagation. Celles-ci se basent sur les informations syn-
taxiques connues pour ensuite aligner les mots avec une grande pr&#233;cision. La m&#233;thode est
enti&#232;rement automatique, et les r&#233;sultats &#233;valu&#233;s sur les donn&#233;es de la campagne d&#8217;alignement
HLT montrent qu&#8217;elle se compare aux meilleures techniques existantes. De plus, alors que
ces derni&#232;res n&#233;cessitent plusieurs millions de phrases pour s&#8217;entra&#238;ner, notre approche n&#8217;en
requiert que quelques centaines. Enfin, l&#8217;examen des r&#232;gles de propagation inf&#233;r&#233;es permet
d&#8217;identifier facilement les cas d&#8217;isomorphismes et de non-isomorphismes syntaxiques entre les
deux langues trait&#233;es.
</p>
<p>Abstract This paper presents and evaluates an effective yet original approach to automat-
ically align bitexts at the word level. This approach relies on a syntactic dependency analysis of
the texts provided by the tools SYNTEX and uses a machine-learning technique, namely induc-
tive logic programming, to automatically infer rules called propagation rules. These rules make
the most of the syntactic information to precisely align words. This approach is entirely auto-
matic, and results obtained on the data of the HLT evaluation campaign rival the ones of the best
existing alignment systems. Moreover, our system uses very few training data: only hundreds of
sentences compared to millions for the existing systems. Furthermore, syntactic isomorphisms
between the two spotted languages are easily identified through a linguistic examination of the
inferred propagation rules.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Sylwia Ozdowska et Vincent Claveau
</p>
<p>1 Introduction
</p>
<p>L&#8217;enjeu que repr&#233;sente l&#8217;alignement des corpus parall&#232;les au niveau des mots n&#8217;est plus &#224; d&#233;-
montrer : ce dernier trouve ses applications dans des t&#226;ches telles que la traduction automatique
ou encore la construction de ressources lexicales bi ou multilingues (V&#233;ronis, 2000). Il existe
principalement deux types d&#8217;approches pour aligner des mots : celles &#224; dominante statistique qui
s&#8217;appuient notamment sur les mod&#232;les IBM (Brown et al., 1993), et celles qui tendent &#224; com-
biner calculs statistiques simples et diff&#233;rentes sources d&#8217;information linguistique (Ahrenberg
et al., 2000 ; Barbu, 2004). Destin&#233;s principalement &#224; la traduction automatique, les syst&#232;mes
purement statistiques se sont progressivement enrichis en incorporant des donn&#233;es linguistiques
issues de l&#8217;analyse syntaxique (Lin &amp; Cherry, 2003 ; Ding &amp; Palmer, 2004) et ce afin de mieux
prendre en compte les variations syst&#233;matiques entre les langues impliqu&#233;es dans le processus
de traduction (Dorr, 1994 ; Fox, 2002). L&#8217;alignement sur des bases purement syntaxiques a &#233;ga-
lement fait l&#8217;objet de travaux : D. Wu (2000) a par exemple propos&#233; une m&#233;thode bas&#233;e sur
une analyse en constituants ; S. Ozdowska (2004), dont nous reprenons le cadre exp&#233;rimental,
utilise quant &#224; elle une analyse en d&#233;pendances dans le but de proposer une &#233;tude contrastive
fine des divergences syntaxiques entre le fran&#231;ais et l&#8217;anglais. Sa d&#233;marche a consist&#233; &#224; d&#233;fi-
nir manuellement des r&#232;gles d&#8217;alignement, dites de propagation, qui exploitent les relations de
d&#233;pendance mises en &#233;vidence dans chaque partie d&#8217;un corpus parall&#232;le.
</p>
<p>Cet article pr&#233;sente une technique d&#8217;alignement proche de cette derni&#232;re. Cependant, l&#8217;origi-
nalit&#233; de notre d&#233;marche r&#233;side dans le fait que les r&#232;gles de propagation sont acquises de
mani&#232;re automatique en corpus par une technique d&#8217;apprentissage artificiel, la programmation
logique inductive. Ces r&#232;gles de propagation, exploitant des informations syntaxiques issues des
analyseurs SYNTEX, sont automatiquement inf&#233;r&#233;es &#224; partir d&#8217;exemples d&#8217;alignements valides.
L&#8217;objectif de cet article est d&#8217;une part de montrer que, contrairement aux approches statistiques,
notre technique ne n&#233;cessite que tr&#232;s peu de donn&#233;es d&#8217;apprentissage. D&#8217;autre part, on se pro-
pose de v&#233;rifier si les r&#232;gles obtenues et les alignements qu&#8217;elles produisent varient en fonction
du type de corpus d&#8217;apprentissage.
</p>
<p>Pour ce faire, nous exposons tout d&#8217;abord le cadre m&#233;thodologique dans lequel nous avons
men&#233; nos travaux. Puis, nous d&#233;crivons la technique d&#8217;apprentissage automatique des r&#232;gles de
propagation en section 3. Enfin, nous pr&#233;sentons et discutons les r&#233;sultats obtenus en section 4
avant d&#8217;indiquer les perspectives de poursuite de ce travail.
</p>
<p>2 Contexte d&#8217;exp&#233;rimentation
</p>
<p>2.1 Alignement de mots par propagation syntaxique
</p>
<p>L&#8217;utilisation de r&#232;gles de propagation pour aligner des bitextes au niveau des mots a d&#233;j&#224;
fait l&#8217;objet de plusieurs travaux. Ainsi, S. Ozdowska (2004) exploite les relations de d&#233;pen-
dance syntaxique dans le processus d&#8217;alignement. Elle utilise des r&#232;gles de propagation syn-
taxique d&#233;finies &#224; la main qui, &#233;tant donn&#233;s deux mots en relation d&#8217;&#233;quivalence dans un couple
de phrases align&#233;es, appel&#233;s couple amorce, permettent de propager le lien d&#8217;alignement &#224;
d&#8217;autres mots en suivant les relations de d&#233;pendance syntaxique connues. Dans l&#8217;exemple sui-
vant, il est ainsi possible d&#8217;aligner ban et interdire en exploitant la relation sujet portant sur
le couple amorce. Dans cet exemple et les suivants, les couples amorces sont not&#233;s en gras.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alignement de mots dans un bitexte par apprentissage artificiel
</p>
<p>The Community banned imports of ivory
</p>
<p>La Communaut&#216; a interdit l&#8217;importation d&#8217;ivoire
</p>
<p>SUJ
</p>
<p>SUJ
</p>
<p>Chaque r&#232;gle de propagation est donc d&#233;crite en fonction de la relation syntaxique qui sert de
base &#224; la propagation et de la direction dans laquelle s&#8217;effectue la propagation (et &#233;ventuelle-
ment des restrictions portant sur les parties du discours des mots concern&#233;s). Si nous reprenons
l&#8217;exemple pr&#233;c&#233;dent, la r&#232;gle de propagation anglais/fran&#231;ais utilis&#233;e est :
V SUJ&#8722;&#8594; Nom / V SUJ&#8722;&#8594; Nom
Elle indique que la propagation se fait &#224; partir d&#8217;un couple amorce de noms r&#233;gis (Community /
Communaut&#233;) vers un couple de verbes recteurs (ban / interdire) par la relation sujet. Une autre
r&#232;gle de propagation possible est celle qui va du couple amorce de noms r&#233;gis (ivory / ivoire)
au couple de recteurs (imports / importation) par la relation de pr&#233;position :
Nom PREP&#8722;&#8594; Nom / Nom PREP&#8722;&#8594; Nom
La plupart des r&#232;gles utilis&#233;es dans ce type d&#8217;approche ont &#233;t&#233; d&#233;finies en accord avec l&#8217;hypo-
th&#232;se d&#8217;isomorphisme direct entre les langues selon laquelle les structures syntaxiques seraient
conserv&#233;es lors de la traduction, comme dans l&#8217;exemple pr&#233;c&#233;dent (Hwa et al., 2002). Cepen-
dant quelques unes traitent des cas de non-isomorphisme, comme l&#8217;alignement de tax et fiscales
dans la biphrase : tax expenditures have been (...) / les d&#233;penses fiscales demeurent (...). Si l&#8217;on
part du couple amorce de noms recteurs (expenditures / d&#233;penses), les structures syntaxiques
qui se correspondent dans les deux langues sont (NN repr&#233;sente la d&#233;pendance entre deux noms
et MOD la d&#233;pendance g&#233;n&#233;rique t&#234;te-modifieur, ici nom-adjectif) :
Nom NN&#8722;&#8594; Nom/Nom MOD&#8722;&#8594; Adj
Ce type d&#8217;approche permet d&#8217;obtenir des alignements qui offrent en g&#233;n&#233;ral une bonne pr&#233;ci-
sion, le rappel se r&#233;v&#233;lant cependant de moins bonne qualit&#233;. En effet, le principe d&#8217;isomor-
phisme permet de g&#233;n&#233;rer des alignements corrects dans la plupart des cas o&#249; il s&#8217;applique
mais il semble, dans certains cas, trop contraignant. Par ailleurs, ces approches n&#233;cessitent une
expertise humaine pour &#233;crire ces r&#232;gles de propagation, ce qui peut se r&#233;v&#233;ler co&#251;teux. C&#8217;est
ce dernier point que nous proposons de contourner en utilisant une technique d&#8217;apprentissage
artificiel pour inf&#233;rer automatiquement des r&#232;gles de propagation.
</p>
<p>2.2 Donn&#233;es d&#8217;apprentissage et d&#8217;&#233;valuation
</p>
<p>Nous avons choisi comme donn&#233;es de r&#233;f&#233;rence celles mises &#224; disposition dans le cadre d&#8217;une
campagne d&#8217;&#233;valuation des syst&#232;mes d&#8217;alignement au niveau des mots notamment pour les
paires de langues anglais/fran&#231;ais (Mihalcea &amp; Pederson, 2003). En voici la description (Och
&amp; Ney, 2000) :
&#8211; corpus d&#8217;entra&#238;nement anglais/fran&#231;ais, issu du HANSARD (d&#233;bats parlementaires), comptant
</p>
<p>1.3 million de biphrases. Pour les exp&#233;riences que nous reportons en section 4, nous n&#8217;avons
utilis&#233; qu&#8217;une portion variant de 10 &#224; 1000 couples de phrases align&#233;es de ce corpus.
</p>
<p>&#8211; corpus de test constitu&#233; de 447 phrases align&#233;es extraites d&#8217;une partie diff&#233;rente du HAN-
SARD.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Sylwia Ozdowska et Vincent Claveau
</p>
<p>&#8211; le jeu de r&#233;f&#233;rence contient les alignements effectu&#233;s par deux annotateurs sur le corpus de
test. Chaque lien d&#8217;appariement &#233;tabli s&#8217;est vu attribuer la valeur S, s&#8217;il s&#8217;agissait d&#8217;un lien
consid&#233;r&#233; comme non ambigu, ou P dans le cas contraire. La valeur P est choisie en pr&#233;sence
d&#8217;expressions fig&#233;es ou de traductions libres. Dans le jeu de r&#233;f&#233;rence final, la valeur S est
conserv&#233;e pour les alignements pour lesquels il y a accord inter-annotateurs ; la valeur P
est attribu&#233;e dans tous les autres cas. La figure 1 pr&#233;sente un exemple de phrase annot&#233;e ;
les alignements S sont en traits pleins et les P en pointill&#233;s. Dans un premier temps, pour
&#233;valuer notre approche, nous nous focalisons sur les alignements 1-1 entre mots lexicaux ;
les exp&#233;rimentations d&#233;crites en section 4 ne portent donc que sur les annotations S entre
mots lexicaux.
</p>
<p>the rules are complicated and changing all the time .
</p>
<p>les r&#216;glements sont compliqu&#216;s et on les modifie sans cesse .
</p>
<p>FIG. 1 &#8211; Annotation pour la campagne d&#8217;alignement HLT
</p>
<p>Comme nous l&#8217;avons dit pr&#233;c&#233;demment, en plus du HANSARD, les exp&#233;riences d&#8217;inf&#233;rence de
r&#232;gles de propagation que nous pr&#233;sentons en section 4 sont effectu&#233;es sur deux autres corpus.
Le premier est un extrait du corpus INRA1. Il s&#8217;agit d&#8217;un corpus sp&#233;cialis&#233; anglais/fran&#231;ais du
domaine de la recherche agronomique de 1000 biphrases. Le second est un corpus fourni dans
le cadre de la campagne d&#8217;&#233;valuation ARCADE (V&#233;ronis &amp; Langlais, 2000). Il est constitu&#233; de
questions-r&#233;ponses trait&#233;es &#224; la Commission Europ&#233;enne. L&#224; encore, nous n&#8217;avons retenu que
1000 biphrases.
</p>
<p>Le rep&#233;rage des relations de d&#233;pendance syntaxique dans les trois corpus d&#8217;entrainement est
effectu&#233; ind&#233;pendamment pour chacune des deux langues par les analyseurs SYNTEX fran&#231;ais
et anglais (Bourigault &amp; Fabre, 2000). Ces derniers prennent en entr&#233;e un texte &#233;tiquet&#233; et iden-
tifient, pour chaque phrase, des relations telles que sujet, objet direct et indirect, modifieur...
Les deux outils sont con&#231;us suivant la m&#234;me architecture et mettent en oeuvre les m&#234;mes pro-
c&#233;dures de rep&#233;rage des relations de d&#233;pendance. Par ailleurs, les relations identifi&#233;es ainsi que
leur repr&#233;sentation sont globalement les m&#234;mes d&#8217;une langue &#224; l&#8217;autre.
</p>
<p>3 Alignement par apprentissage artificiel
</p>
<p>Comme nous l&#8217;avons d&#233;j&#224; dit, l&#8217;originalit&#233; de notre approche tient au fait que contrairement aux
travaux pr&#233;c&#233;demment expos&#233;s (Ozdowska, 2004), les r&#232;gles de propagation ne sont pas don-
n&#233;es manuellement mais inf&#233;r&#233;es automatiquement. Les deux sous-sections suivantes pr&#233;sentent
la technique d&#8217;apprentissage artificiel et son utilisation pour inf&#233;rer ces r&#232;gles. La technique
d&#8217;amor&#231;age fournissant automatiquement les exemples n&#233;cessaires &#224; cette technique supervis&#233;e
est d&#233;crite en sous-section 3.3.
</p>
<p>1Nous remercions A. Lacombe, INRA, de nous avoir permis d&#8217;utiliser ce corpus.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alignement de mots dans un bitexte par apprentissage artificiel
</p>
<p>3.1 Programmation logique inductive
</p>
<p>Le principe de notre approche est le suivant : &#224; partir d&#8217;exemples de propagations valides au
sein de deux phrases align&#233;es, on tente d&#8217;apprendre des r&#232;gles qui les d&#233;finissent. Pour ce faire,
nous utilisons une technique d&#8217;apprentissage artificiel supervis&#233;e, la programmation logique in-
ductive (PLI). Une pr&#233;sentation approfondie de cette m&#233;thode d&#8217;apprentissage peut &#234;tre trouv&#233;e
dans (Muggleton &amp; De Raedt, 1994), nous n&#8217;en donnons ici que les grandes lignes. La PLI per-
met d&#8217;inf&#233;rer des r&#232;gles g&#233;n&#233;rales (des clauses de Horn) d&#233;crivant un concept &#224; partir d&#8217;un jeu
d&#8217;exemples de ce concept E+ (avec &#233;ventuellement des contre-exemples E&#8722;) et un ensemble
d&#8217;informations externes B, appel&#233;es Background Knowledge. L&#8217;ensemble de r&#232;gles inf&#233;r&#233;es,
appel&#233; classifieur et not&#233; H par la suite, est obtenu en g&#233;n&#233;ralisant les exemples en fonction de
B.
</p>
<p>Quelques conditions impos&#233;es &#224; cette t&#226;che d&#8217;apprentissage forment le cadre logique de la PLI
(2 signifie faux et |= repr&#233;sente l&#8217;implication logique) :
&#8211; la consistance a posteriori impose qu&#8217;aucune contradiction n&#8217;existe entre B, H et E+ : B &#8743;
H &#8743; E+ 6|= 2 ;
</p>
<p>&#8211; la compl&#233;tude assure que tous les exemples positifs sont expliqu&#233;s avec H et les informations
du Background Knowledge, soit B &#8743;H |= E+.
</p>
<p>En pratique, les r&#232;gles composant H sont recherch&#233;es &#224; travers un espace d&#8217;hypoth&#232;ses regrou-
pant toutes les r&#232;gles possibles. Cet espace est organis&#233; hi&#233;rarchiquement, ce qui permet de le
parcourir efficacement. Une r&#232;gle de cet espace est retenue si elle maximise un score, g&#233;n&#233;rale-
ment d&#233;fini en fonction du nombre d&#8217;exemples (et &#233;ventuellement de contre-exemples) qu&#8217;elle
couvre. La PLI, de par son expressivit&#233; (exemples et r&#232;gles sont exprim&#233;s en logique des pr&#233;di-
cats), a &#233;t&#233; utilis&#233;e pour de nombreuses t&#226;ches d&#8217;apprentissage, et notamment en TAL (Cussens
&amp; D&#382;eroski, 2000).
</p>
<p>3.2 Apprentissage de r&#232;gles de propagation
</p>
<p>Dans notre cas, les r&#232;gles recherch&#233;es sont des propagations et les exemples que nous utilisons
sont des phrases align&#233;es comportant des alignements valides ; nous n&#8217;utilisons pas de contre-
exemples. L&#8217;algorithme de PLI que nous utilisons est ALEPH2. Dans B sont stock&#233;es toutes les
informations concernant les d&#233;pendances syntaxiques entre mots des phrases exemples et les
couples amorces connus. Le formalisme logique de la PLI permet d&#8217;encoder facilement ces in-
formations relationnelles. Ainsi, si l&#8217;on sait que companies/entreprises peuvent &#234;tre align&#233;s dans
l&#8217;extrait de biphrase suivant (l&#8217;identifiant de chaque mot est not&#233; apr&#232;s les barres obliques) :
... private/id_1_en sector/id_2_en companies/id_3_en
... les/id_1_fr entreprises/id_2_fr du/id_3_fr secteur/id_4_fr priv&#233;/id_5_fr
on ajoute &#224; E+ : alignement(id_3_en,id_2_fr). et &#224; B (le nom du pr&#233;dicat repr&#233;sente le nom
de la relation syntaxique, le premier argument repr&#233;sente le recteur et le second le r&#233;gi) :
determinant(id_2_fr,id_1_fr). prep_de(id_2_fr,id_3_fr). adjectif(id_2_en,id_1_en).
preposition(id_3_fr,id_4_fr). adjectif(id_4_fr,id_5_fr). nom_nom(id_3_en,id_2_en).
amorce(id_2_en,id_4_fr).
</p>
<p>Une r&#232;gle qui peut &#234;tre inf&#233;r&#233;e &#224; partir de cet exemple est :
alignement(M_Ang,M_Fr) :- nom_nom(M_Ang,A1), prep_de(M_Fr,F1), preposition(F1,F2),
</p>
<p>2ALEPH est d&#233;velopp&#233; par A. Srinivasan et disponible &#224; http://web.comlab.ox.ac.uk/oucl/research/areas/
machlearn/Aleph.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Sylwia Ozdowska et Vincent Claveau
</p>
<p>amorce(A1,F2).
Avec les notations pr&#233;c&#233;dentes, cette r&#232;gle s&#8217;&#233;crit :
M_Ang NN&#8722;&#8594; A1 / M_Fr PREP_DE&#8722;&#8594; F1 PREP&#8722;&#8594; F2.
Elle souligne l&#8217;&#233;quivalence des structures Nom-Nom en anglais avec Nom de Nom en fran-
&#231;ais ; tout couple apparaissant dans une biphrase avec cette structure peut ainsi &#234;tre align&#233;.
</p>
<p>3.3 Amor&#231;age
</p>
<p>Des exemples d&#8217;alignements valides sont n&#233;cessaires &#224; notre technique d&#8217;apprentissage. Cette
phase de supervision, p&#233;nible si elle &#233;tait conduite manuellement, est dans notre cas automatis&#233;e
par une technique dite d&#8217;amor&#231;age. Notre approche d&#8217;inf&#233;rence de r&#232;gles de propagation ne
requiert donc finalement aucune intervention humaine ; elle est dite semi-supervis&#233;e.
</p>
<p>Pour g&#233;n&#233;rer ces alignements exemples, ou couples amorces, nous utilisons deux approches
compl&#233;mentaires. Il s&#8217;agit d&#8217;une part d&#8217;une technique statistique classique et d&#8217;autre part d&#8217;une
recherche de cognats. En ce qui concerne la m&#233;thode statistique, nous consid&#233;rons comme
couples amorces les paires de mots (anglais/fran&#231;ais) apparaissant ensemble dans des phrases
align&#233;es de mani&#232;re statistiquement significative (Ahrenberg et al., 2000) ; la force du lien entre
deux mots est calcul&#233;e par un Jaccard sur les fr&#233;quences d&#8217;apparition conjointe des deux mots
(Ozdowska, 2004). Pour le rep&#233;rage de cognats, c&#8217;est-&#224;-dire de cha&#238;nes de caract&#232;res identiques
ou proches dans les deux langues, la m&#233;thode mise au point est similaire &#224; celle d&#233;crite dans
(Fluhr et al., 2000). Elle consiste &#224; identifier la sous-cha&#238;ne maximale commune &#224; deux mots
qui cooccurrent dans un couple de phrases align&#233;es.
</p>
<p>Par la conjonction de ces deux m&#233;thodes, ce sont ainsi en moyenne entre 4 et 6 couples amorces
(selon les corpus) par phrase qui sont d&#233;tect&#233;s. Environ 5% des couples amorces se r&#233;v&#232;lent
erron&#233;s (i.e. mots ne devant pas &#234;tre align&#233;s) ; ce faible taux ne devrait donc pas g&#234;ner le pro-
cessus d&#8217;apprentissage. Chaque couple amorce, alli&#233; aux deux phrases align&#233;es dont il est tir&#233;,
peut ainsi servir d&#8217;exemple pour notre technique d&#8217;apprentissage de r&#232;gles de propagation. Une
phrase permet donc de produire autant d&#8217;exemples qu&#8217;elle comporte de couples amorces.
</p>
<p>&#192; partir des exemples obtenus par cette technique, il nous est donc possible d&#8217;inf&#233;rer des r&#232;gles
de propagation &#224; partir de nos trois corpus d&#8217;entra&#238;nement. Ces r&#232;gles peuvent ensuite &#234;tre
appliqu&#233;es &#224; de nouvelles donn&#233;es dans lesquelles on aura pr&#233;alablement rep&#233;r&#233; des couples
amorces.
</p>
<p>4 R&#233;sultats
</p>
<p>Cette section pr&#233;sente tout d&#8217;abord les r&#233;sultats obtenus par notre approche sur le jeu d&#8217;&#233;va-
luation HLT. Nous d&#233;crivons ensuite quelques causes d&#8217;erreurs r&#233;currentes et examinons enfin
certaines des r&#232;gles inf&#233;r&#233;es.
</p>
<p>4.1 Performances d&#8217;alignement
</p>
<p>Les trois syst&#232;mes d&#8217;alignement (i.e. les trois ensembles de r&#232;gles inf&#233;r&#233;es &#224; partir de nos cor-
pus) sont &#233;valu&#233;s &#224; l&#8217;aide des donn&#233;es de la campagne HLT. Leurs performances sont pr&#233;sent&#233;es</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alignement de mots dans un bitexte par apprentissage artificiel
</p>
<p>de mani&#232;re classique en termes de taux de rappel, taux de pr&#233;cision et f-mesure.
</p>
<p>La table 1 pr&#233;sente les r&#233;sultats des trois syst&#232;mes. Pour ces exp&#233;riences, la phase d&#8217;apprentis-
sage a &#233;t&#233; men&#233;e sur 1000 phrases de chaque corpus. &#192; des fins de comparaison, nous indiquons
les r&#233;sultats obtenus par les meilleurs syst&#232;mes d&#8217;alignement &#8211; en terme de f-mesure &#8211; ayant
particip&#233; &#224; la comp&#233;tition HLT ; il s&#8217;agit de Ralign (Simard &amp; Langlais, 2003), XRCE (bas&#233; sur
GIZA++) (Dejean et al., 2003) et BiBr (Simard &amp; Vogel, 2003), tous les trois utilisant principale-
ment des approches statistiques. Nous indiquons aussi les r&#233;sultats du syst&#232;me de S. Ozdowska
(2004) dans lequel les r&#232;gles de propagation sont d&#233;finies manuellement.
</p>
<p>Syst&#232;me HANSARD ARCADE INRA Ozdowska Ralign XRCE BiBr
Pr&#233;cision 88.51% 82.65% 86.15% 81.59% 72.54% 55.54% 63.03%
Rappel 60.03% 60.25% 60.73% 58.43% 80.61% 93.46% 74.59%
F-mesure 71.54% 69.69% 71.24% 68.10% 76.36% 69.68% 68.32%
</p>
<p>TAB. 1 &#8211; Performances des syst&#232;mes d&#8217;alignement sur les donn&#233;es HLT
</p>
<p>&#192; l&#8217;examen de ce tableau, on remarque que les r&#233;sultats de nos syst&#232;mes varient peu en fonction
du corpus d&#8217;entra&#238;nement. D&#8217;autre part, les performances de nos trois syst&#232;mes sont de niveau
comparable &#224; celles des autres. Ils se classent en effet deuxi&#232;me derri&#232;re le syst&#232;me Ralign en
terme de f-mesure. Ils jouissent par ailleurs d&#8217;une pr&#233;cision tr&#232;s sup&#233;rieure aux autres syst&#232;mes,
mais d&#8217;un rappel relativement plus bas. Ce rappel s&#8217;explique en partie par l&#8217;insuffisance de
couples amorces et la couverture imparfaite de l&#8217;&#233;tiquetage syntaxique, ce qui rend certains
couples inaccessibles &#224; nos r&#232;gles de propagation.
</p>
<p>On s&#8217;int&#233;resse dans un second temps &#224; l&#8217;&#233;volution des performances selon la taille des corpus
d&#8217;entra&#238;nement. Pour cela, on fait varier le nombre de phrases servant &#224; produire les exemples
pour l&#8217;apprentissage. La figure 2 pr&#233;sente les taux de rappel, de pr&#233;cision et la f-mesure obtenus
selon le nombre de phrases &#224; partir du corpus HANSARD. Les r&#233;sultats sont tr&#232;s &#233;loquents : il n&#8217;y
</p>
<p> 0
</p>
<p> 20
</p>
<p> 40
</p>
<p> 60
</p>
<p> 80
</p>
<p> 100
</p>
<p> 0  200  400  600  800  1000
</p>
<p>Po
ur
</p>
<p>ce
nt
</p>
<p>ag
e
</p>
<p>Nombre de phrases
</p>
<p>f&#8722;mesure
rappel
</p>
<p>precision
</p>
<p>FIG. 2 &#8211; Variation des performances selon le nombre de phrases utilis&#233;es &#224; l&#8217;apprentissage
</p>
<p>a quasiment aucune variation de rappel et de pr&#233;cision de 300 &#224; 1000 phrases. En dessous de 300
phrases, la pr&#233;cision augmente sensiblement alors que le rappel d&#233;cro&#238;t. Cela s&#8217;explique par le</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Sylwia Ozdowska et Vincent Claveau
</p>
<p>fait que seules quelques r&#232;gles de propagation, parmi les plus s&#251;res, sont trouv&#233;es. On remarque
enfin qu&#8217;avec 10 phrases seulement, notre algorithme d&#8217;apprentissage est capable d&#8217;inf&#233;rer des
r&#232;gles suffisamment pertinentes pour mener &#224; une f-mesure de 65%. Ces r&#233;sultats sont donc
tr&#232;s positifs, notamment en regard des tailles tr&#232;s restreintes de nos corpus d&#8217;entra&#238;nement. &#192;
titre de comparaison, les syst&#232;mes Ralign, XRCE et BiBr utilisent 1.3 million de phrases pour
s&#8217;entra&#238;ner.
</p>
<p>4.2 Examen des r&#233;sultats
</p>
<p>Les erreurs d&#8217;alignement les plus courantes faites par nos syst&#232;mes peuvent se classer en plu-
sieurs grandes cat&#233;gories. Comme nous l&#8217;avons dit pr&#233;c&#233;demment, une grande part des faux
n&#233;gatifs (i.e. des alignements non d&#233;tect&#233;s) est due &#224; une trop faible densit&#233; de couples amorces
en plus d&#8217;absences de d&#233;pendances au sein de certaines phrases.
</p>
<p>En ce qui concerne les faux positifs (i.e. des alignements d&#233;tect&#233;s &#224; tort), certains viennent
simplement d&#8217;erreurs d&#8217;&#233;tiquetage de SYNTEX (elles-m&#234;mes parfois caus&#233;es par des erreurs de
l&#8217;&#233;tiqueteur cat&#233;goriel utilis&#233; en amont). Par exemple, dans la biphrase federal government car-
penters get $ 6.42/Les menuisiers du gouvernement f&#233;d&#233;ral touchent $ 6.42, l&#8217;adjectif federal a
incorrectement &#233;t&#233; rattach&#233; &#224; carpenters, ce qui a provoqu&#233; l&#8217;alignement incorrect de carpen-
ter/gouvernement, tous deux not&#233;s recteurs du couple amorce federal/f&#233;d&#233;ral. D&#8217;autres erreurs
de ce type sont caus&#233;es par certaines des r&#232;gles inf&#233;r&#233;es qui ne sont pas assez sp&#233;cifiques pour
&#233;viter de ramener du bruit. C&#8217;est notamment le cas des r&#232;gles manipulant les d&#233;pendances ob-
jet ou sujet qui, &#224; cause du manque d&#8217;informations dont dispose l&#8217;algorithme d&#8217;apprentissage,
ne font pas de diff&#233;rence entre les voix actives et passives. Ainsi, &#224; partir du couple amorce
bring/apporter dans la biphrase good legislation has been brought in by Liberal governments /
les gouvernements lib&#233;raux ont apport&#233; de bonnes mesures l&#233;gislatives, gouvernement et legis-
lation ont &#233;t&#233; align&#233;s &#224; tort. Enfin, des ph&#233;nom&#232;nes de reformulations plus ou moins fid&#232;les lors
de la traduction perturbent parfois nos tentatives d&#8217;alignement. Ainsi, dans la phrase the Go-
vernment must implement the recommendations of the Commissioner of Official Languages/le
gouvernement se doit de respecter les recommandations du Commissaire aux langues officielles,
implement et respecter ont &#233;t&#233; align&#233;s alors que ce couple n&#8217;est pas not&#233; valide dans le jeu de
test HLT.
</p>
<p>4.3 R&#232;gles obtenues
</p>
<p>Environ une trentaine de r&#232;gles de propagation sont obtenues pour chacun des corpus d&#8217;entra&#238;-
nement avec 1000 phrases. Il y a peu de diff&#233;rences entre ces r&#232;gles dans les trois corpus, ce
qui explique la proximit&#233; des performances observ&#233;e en section 4.1. Elles sont, pour leur quasi
totalit&#233;, tr&#232;s similaires &#224; celles propos&#233;es par S. Ozdowska. Notons cependant que des r&#232;gles,
non retenues par S. Ozdowska, comme celles exploitant la coordination ou la relation attribut, se
r&#233;v&#232;lent en pratique tr&#232;s productives et expliquent la diff&#233;rence de r&#233;sultats avec notre approche
par apprentissage.
</p>
<p>La plupart des r&#232;gles mettent donc en exergue des isomorphismes connus entre la syntaxe
anglaise et fran&#231;aise, comme l&#8217;alignement des adjectifs modifiant deux noms align&#233;s, ou
l&#8217;alignement des compl&#233;ments d&#8217;objet direct de deux verbes align&#233;s :
alignement(M_Ang,M_Fr) :- adjectif(C,M_Ang), adjectif(D,M_Fr), amorce(C,D).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alignement de mots dans un bitexte par apprentissage artificiel
</p>
<p>alignement(M_Ang,M_Fr) :- objet(C,M_Ang), objet(D,M_Fr), amorce(C,D).
Ces cas d&#8217;isomorphismes parfaits repr&#233;sentent pr&#232;s de 50% des r&#232;gles de propagation. Certains
cas de non-isomorphisme syntaxique sont &#233;galement trouv&#233;s, comme par exemple la construc-
tion standard des syntagmes nominaux Nom Nom en anglais et Nom de Nom en fran&#231;ais
(cf. section 3.2). D&#8217;autres types de non-isomorphismes peuvent m&#234;me mener &#224; l&#8217;alignement de
mots ayant des parties du discours diff&#233;rentes, comme par exemple des noms et des adjectifs :
alignement(M_Ang,M_Fr) :- nom_nom(C,M_Ang), adjective(D,M_Fr), amorce(C,D).
</p>
<p>D&#8217;une mani&#232;re g&#233;n&#233;rale, il ressort de l&#8217;examen de ces r&#232;gles que la plupart d&#8217;entre elles sont
des r&#232;gles de propagation que l&#8217;on peut qualifier de g&#233;n&#233;riques. Elles sont effectivement pour
une grande partie similaires &#224; celles trouv&#233;es manuellement par S. Ozdowska (2004), ce qui
confirme la validit&#233; de notre processus d&#8217;apprentissage. Cependant quelques r&#232;gles inf&#233;r&#233;es
sont plus inattendues &#8211; et leur validit&#233; peut-&#234;tre discut&#233;e &#8211; comme par exemple :
alignement(M_Ang,M_Fr) :- adjectif(M_Fr,C), nom_nom(D,M_Ang), adjectif(D,E), amorce(E,C).
qui permet d&#8217;aligner bargaining et n&#233;gociation dans la biphrase ... to have some hang-up with
regard to the collective bargaining process/... &#233;prouver certains complexes &#224; l&#8217;&#233;gard de la n&#233;-
gociation collective.
</p>
<p>5 Conclusion et perspectives
</p>
<p>Nous avons pr&#233;sent&#233; une m&#233;thode originale d&#8217;alignement de mots bas&#233;e sur la syntaxe et sur
une technique d&#8217;apprentissage semi-supervis&#233;e. Celle-ci permet d&#8217;apprendre automatiquement
des r&#232;gles de propagation &#224; partir d&#8217;exemples de couples de mots align&#233;s. Ces exemples sont
par ailleurs fournis &#224; l&#8217;aide d&#8217;une proc&#233;dure d&#8217;amor&#231;age qui conf&#232;re &#224; notre approche une com-
pl&#232;te autonomie. Les r&#233;sultats d&#8217;alignement obtenus sont bons et comparables aux meilleurs
syst&#232;mes d&#8217;alignement actuels. De plus, et c&#8217;est l&#8217;originalit&#233; de ce travail, contrairement aux
syst&#232;mes existants, tr&#232;s peu de donn&#233;es sont n&#233;cessaires pour entra&#238;ner notre syst&#232;me. On a
montr&#233; &#233;galement que les r&#232;gles de propagation sont relativement g&#233;n&#233;riques et changent peu
d&#8217;un bitexte &#224; un autre.
</p>
<p>Plusieurs perspectives sont ouvertes par ce travail. Concernant la technique d&#8217;apprentissage,
nous pr&#233;voyons d&#8217;int&#233;grer les informations cat&#233;gorielles pour permettre d&#8217;inf&#233;rer des r&#232;gles
ne portant plus seulement sur les d&#233;pendances syntaxiques mais aussi sur les parties du dis-
cours. Cela permettra d&#8217;&#233;viter certaines fausses d&#233;tections report&#233;es pr&#233;c&#233;demment. L&#8217;utilisa-
tion d&#8217;exemples n&#233;gatifs, qui permettraient d&#8217;emp&#234;cher des g&#233;n&#233;ralisations excessives et donc
des r&#232;gles de propagation pas assez pr&#233;cises, est &#233;galement &#224; l&#8217;&#233;tude. D&#8217;un point de vue appli-
catif, notre m&#233;thode &#233;tant enti&#232;rement automatique, elle peut ais&#233;ment &#234;tre adapt&#233;e &#224; d&#8217;autres
paires de langues, pourvu que celles-ci soient suffisamment proches d&#8217;un point de vue syn-
taxique et qu&#8217;un analyseur en d&#233;pendances existe pour chacune d&#8217;elles. Des exp&#233;riences dans
ce sens permettraient d&#8217;int&#233;ressantes &#233;tudes des cas d&#8217;isomorphismes et de non-isomorphismes
syntaxiques dans les phrases align&#233;es &#224; travers l&#8217;&#233;tude des r&#232;gles de propagation inf&#233;r&#233;es.
</p>
<p>R&#233;f&#233;rences
AHRENBERG L., ANDERSSON M. &amp; MERKEL M. (2000). A knowledge-lite approach to word ali-
gnment, In Parallel Text Processing: Alignment and Use of Translatin Corpora, chapitre 5, p. 97&#8211;138.
Kluwer Academic Publishers : Dordrecht.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Sylwia Ozdowska et Vincent Claveau
</p>
<p>BARBU A. M. (2004). Simple linguistic methods for improving a word alignment algorithm. In 7th
International Conference on the Statistical Analysis of Textual Data, JADT&#8217;04, Louvain-la-Neuve, Bel-
gique.
BOURIGAULT D. &amp; FABRE C. (2000). Approche linguistique pour l&#8217;analyse syntaxique de corpus.
Cahiers de Grammaire, 25, 131&#8211;151. Universit&#233; Toulouse le Mirail.
BROWN P. F., PIETRA S. A. D., PIETRA V. J. D. &amp; MERCER R. L. (1993). The mathematics of
statistical machine translation: parameter estimation. Computational Linguistics, 19(2), 263&#8211;311.
J. CUSSENS &amp; S. D&#381;EROSKI, Eds. (2000). Learning Language in Logic. Lecture Notes in Artificial
Intelligence. Sringer Verlag.
DEJEAN H., GAUSSIER E., GOUTTE C. &amp; YAMADA K. (2003). Reducing parameter space for word
alignment. In HLT-NAACL 2003 Workshop: Building and Using Parallel Texts: Data Driven Machine
Translation and Beyond, Edmonton, Alberta, Canada.
DING Y. &amp; PALMER M. (2004). Automatic learning of parallel dependency treelet pairs. In 1st Inter-
national Joint Conference on Natural Language Processing, Sanya City, Chine.
DORR B. (1994). Machine translation divergences: A formal description and proposed solution. Com-
putational Linguistics, 20(4), 597&#8211;633.
FLUHR C., BISSON F. &amp; ELKATEB F. (2000). Parallel Text Alignment Using Crosslingual Information
Retrieval Techniques, chapitre 9. In (V&#233;ronis, 2000).
FOX H. J. (2002). Phrasal cohesion and statistical machine translation. In Empirical Methods in Natural
Language Processing, EMNLP&#8217;02, Philadelphia, PA, &#201;tats-Unis.
HWA R., RESNIK P., WEINBERG A. &amp; KOLAK O. (2002). Evaluating translational correspondence
using annotation projection. In 40th Annual Conference of the Association for Computational Linguis-
tics, Philadelphia, PA, &#201;tats-Unis.
LIN D. &amp; CHERRY C. (2003). Proalign: Shared task system description. In HLT-NAACL 2003 Work-
shop: Building and Using Parallel Texts: Data Driven Machine Translation and Beyond, Edmonton,
Alberta, Canada.
MIHALCEA R. &amp; PEDERSON T. (2003). An evaluation exercise for word alignment. In HLT-NAACL
2003 Workshop: Building and Using Parallel Texts: Data Driven Machine Translation and Beyond, Ed-
monton, Alberta, Canada.
MUGGLETON S. &amp; DE RAEDT L. (1994). Inductive Logic Programming: Theory and Methods. Journal
of Logic Programming, 19-20, 629&#8211;679.
OCH F. J. &amp; NEY H. (2000). Improved statistical alignment models. In 38th Annual Conference of the
Association for Computational Linguistics, Hong Kong.
OZDOWSKA S. (2004). Appariement bilingue de mots par propagation syntaxique &#224; partir de corpus
fran&#231;ais/anglais align&#233;s. In conf&#233;rence RECITAL&#8217;04, F&#232;s, Maroc.
SIMARD B. &amp; VOGEL S. (2003). Word alignment based on bilingual bracketing. In HLT-NAACL 2003
Workshop: Building and Using Parallel Texts: Data Driven Machine Translation and Beyond, Edmonton,
Alberta, Canada.
SIMARD M. &amp; LANGLAIS P. (2003). Statistical translation alignment with compositionality constraints.
In HLT-NAACL 2003 Workshop: Building and Using Parallel Texts: Data Driven Machine Translation
and Beyond, Edmonton, Alberta, Canada.
J. V&#201;RONIS, Ed. (2000). Parallel Text Processing : Alignment and Use of Translation Corpora. Dor-
drecht : Kluwer Academic Publishers.
V&#201;RONIS J. &amp; LANGLAIS P. (2000). Evaluation of Parallel Text Alignment Systems. The ARCADE
Project, chapitre 19. In (V&#233;ronis, 2000).
WU D. (2000). Bracketing and Aligning Words and Constituents in Parallel Text using Stochastic
Inversion Transduction Grammars, chapitre 7. In (V&#233;ronis, 2000).</p>

</div></div>
</body></html>