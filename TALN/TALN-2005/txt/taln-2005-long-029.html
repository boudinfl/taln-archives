<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>D&#233;tection automatique d'actes de dialogue par l'utilisation d'indices multiniveaux</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2005, Dourdan, 6&#8211;10 juin 2005
</p>
<p>D&#233;tection automatique d&#8217;actes de dialogues par l&#8217;utilisation
d&#8217;indices multi-niveaux
</p>
<p>Sophie Rosset, Delphine Tribout
LIMSI - CNRS
</p>
<p>F-91403 Orsay Cedex
{rosset, tribout}@limsi.fr
</p>
<p>Mots-clefs : actes de dialogue, dialogue homme homme, d&#233;tection automatique, indices
multiniveaux
</p>
<p>Keywords: dialog acts, human human dialog, automatic detection of dialog acts, mulilevel
information
</p>
<p>R&#233;sum&#233; Ces derni&#232;res ann&#233;es, il y a eu de nombreux travaux portant sur l&#8217;utilisation d&#8217;actes
de dialogue pour caract&#233;riser les dialogues homme-homme ou homme-machine. Cet article fait
&#233;tat de nos travaux sur la d&#233;tection automatique d&#8217;actes de dialogue dans des corpus r&#233;els de
dialogue homme-homme. Notre travail est fond&#233; essentiellement sur deux hypoth&#232;ses . (i) la
position des mots et la classe s&#233;mantique du mot sont plus importants que les mots eux-m&#234;mes
pour identifier l&#8217;acte de dialogue et (ii) il y a une forte pr&#233;dictivit&#233; dans la succession des actes de
dialogues port&#233;s sur un m&#234;me segment dialogique. Une approche de type Memory Based Learning
a &#233;t&#233; utilis&#233;e pour la d&#233;tection automatique des actes de dialogue. Le premier mod&#232;le n&#8217;utilise pas
d&#8217;autres informations que celles contenus dans le tour de parole. Dans lex exp&#233;riences suivantes,
des historiques dialogiques de taille variables sont utilis&#233;s. Le taux d&#8217;erreur de d&#233;tection d&#8217;actes
de dialogue est d&#8217;environ 16% avec le premier mod&#232;le est descend avec une utilisation plus large
de l&#8217;historique du dialogue &#224; environ 14%.
</p>
<p>Abstract Recently there has been growing interest in using dialog acts to characterize human-
human and human-machine dialogs. This paper reports on our experience in the annotation and the
automatic detection of dialog acts in human-human spoken dialog corpora. Our work is based on
two hypotheses: first, word position is more important than the exact word in identifying the dialog
act; and second, there is a strong grammar constraining the sequence of dialog acts. A memory
based learning approach has been used to detect dialog acts. In a first set of experiments only the
information contained in each turn is used and in a second set, different histories of the dialogue
are used. A dialog act error rate of about 16 % is obtained for the simplest model. Using other
informations, such as history of the dialog, the results grow up to 14%.
</p>
<p>1 Introduction
</p>
<p>Afin de saisir la complexit&#233; de dialogues homme-homme collect&#233;s dans des services d&#8217;appels,
il semble int&#233;ressant d&#8217;explorer et de corr&#233;ler diff&#233;rents types d&#8217;information, disponibles sous</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>S. Rosset, D. Tribout
</p>
<p>la forme d&#8217;annotations faites &#224; diff&#233;rents niveaux : lexical, s&#233;mantique et fonctionnel. D&#8217;autre
part, il peut &#234;tre utile de mod&#233;liser la structure du dialogue afin d&#8217;utiliser cette information dans
des syst&#232;mes de dialogue. Une analyse souvent effectu&#233;e sur les dialogues concerne les actes
de dialogue. Les actes de dialogues sont en quelque sorte des unit&#233;s fonctionnelles abstraites
qui d&#233;crivent les actions des locuteurs tout en g&#233;n&#233;ralisant les variations de forme et de contenu
des &#233;nonc&#233;s. Par exemple, on consid&#232;re que les assertions (assert), les demandes d&#8217;informations
(information-request), les marques d&#8217;accord (acknowledgement) sont des actes de dialogue qui
permettent d&#8217;approcher ce que les locuteurs souhaitent accomplir par leur parole. &#192; la base
de ce courant, on trouve l&#8217;id&#233;e selon laquelle dire c&#8217;est faire1, c&#8217;est-&#224;-dire selon laquelle tout
acte d&#8217;&#233;nonciation serait la r&#233;alisation d&#8217;un acte social. Cette conception de la parole vient de
philosophes du langage ((Austin J. L., 1962),(Searle J. R., 1969)) qui consid&#232;rent le dialogue
comme un lieu d&#8217;interaction sociale et la parole comme un moyen d&#8217;(inter)action. Austin consi-
d&#232;re ainsi qu&#8217;une &#233;nonciation, outre un contenu explicite, permet &#233;galement d&#8217;accomplir un acte
et a donc &#224; ce titre une fonction pragmatique. L&#8217;id&#233;e d&#8217;Austin est en outre que ces fonctions des
&#233;nonc&#233;s peuvent &#234;tre &#233;tudi&#233;es ind&#233;pendamment de leur structure syntaxique mais selon un certain
contexte. Plusieurs travaux r&#233;cents sont fond&#233;s sur l&#8217;id&#233;e que les actes de dialogue sont une bonne
fa&#231;on de caract&#233;riser les dialogues, tant dans les interactions homme-homme que homme-machine.
Pour exemple, nous pouvons citer les travaux de (Cattoni R. et al., 2001), de (Di Eugenio B. et al.,
1998) ou encore ceux de (Isard A., Carletta J. C., 1995). De nombreuses taxonomies d&#8217;actes de di-
alogue ont donc &#233;t&#233; &#233;tablies (Traum D., 2000). Pour ce qui concerne les syst&#232;mes de dialogue et les
annotations de corpus de dialogue homme-homme et homme-machine, une taxonomie fr&#233;quem-
ment utilis&#233;e et largement r&#233;pandue est celle de DAMSL 2. Quant aux approches pour l&#8217;annotation
automatique en actes dialogiques, il en existe plusieurs qui diff&#232;rent l&#233;g&#232;rement. Par exemple,
ayant observ&#233; dans plusieurs corpus que les diff&#233;rents actes de dialogue sont fortement corr&#233;l&#233;s &#224;
des suite de mots pr&#233;cis (appel&#233;s cue-phrases), (Hirschberg J. et Litman D. J., 1993) se fondent sur
ces indices pour les d&#233;tecter. Le probl&#232;me de cette approche est toutefois que ces suites de mots
sont fortement d&#233;pendantes de la t&#226;che et du domaine. Afin de pallier ce probl&#232;me, (Reithinger
N. et Klesen M., 1997) proposent l&#8217;utilisation de n-gramme de mots. (Samuel K. et al., 1998),
quant &#224; eux, se situent &#224; l&#8217;intersection de ces deux approches et utilisent les suites de mots et un
sous-ensemble d&#8217;indices dialogiques mod&#233;lis&#233;s par des n-gramme de mots. Il est toutefois difficile
de ne pas constater que, en r&#232;gle g&#233;n&#233;rale, la relation entre les actes de dialogue et les mots n&#8217;est
pas univoque. Par exemple, un simple mot comme oui peut correspondre &#224; diff&#233;rents actes de
dialogue comme une r&#233;ponse &#224; une question, la confirmation d&#8217;une information, un backchannel...
D&#8217;un autre c&#244;t&#233;, un acte de dialogue comme une assertion peut correspondre &#224; plusieurs mots ou
suites de mots comme ma date de naissance est le 31/08/70 ou 68 euros 50... Afin de r&#233;duire
autant que possible la d&#233;pendance &#224; la t&#226;che tout en g&#233;rant ces correspondances multiples, nous
avons cherch&#233; &#224; &#233;laborer une m&#233;thode de d&#233;tection des actes de dialogue sans utilisation explicite
du lexique, notre hyoth&#232;se &#233;tant que cette information n&#8217;est pas strictement indispensable.
</p>
<p>Dans cet article nous pr&#233;sentons donc notre m&#233;thodologie pour la d&#233;tection automatique des actes
de dialogue. Puis nous pr&#233;sentons les diff&#233;rentes exp&#233;riences que nous avons men&#233;es et qui nous
ont permis d&#8217;am&#233;liorer la d&#233;tection automatique des actes de dialogue gr&#226;ce &#224; la prise en compte
et l&#8217;int&#233;gration d&#8217;indices dialogiques suppl&#233;mentaires.
</p>
<p>1Ceci fait r&#233;f&#233;rence au titre de la version fran&#231;aise de (Austin J. L., 1962).
2Cette taxonomie a &#233;t&#233; utilis&#233;e et adapt&#233;e dans nombre de projets. Le projet europ&#233;en et am&#233;ricain AMITI&#201;S
</p>
<p>(Automated Multilingual Interaction with Information and Services) par exemple s&#8217;est fond&#233;e sur elle pour proposer
une m&#233;thode d&#8217;annotation des dialogues sur diff&#233;rents niveaux</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;tection automatique d&#8217;actes de dialogue
</p>
<p>nombre de dialogues 134
nombre de tours 4273
nombre moyen de tours/dialogue 32
nombre de segments dialogiques 5623
nombre moyen de segments dialogiques/dialogue 42
nombre moyen de segments dialogiques/tour 1.3
nombre de mots distincts 1976
nombre total de mots 40494
</p>
<p>Table 1: Descriptif du corpus GE_fr
</p>
<p>2 Corpus et m&#233;thodologie
</p>
<p>2.1 Corpus utilis&#233;
</p>
<p>Dans ce travail, le corpus utilis&#233; (cf. tableau 1) consiste en une s&#233;rie de dialogues homme-homme
en fran&#231;ais, enregistr&#233;s dans un centre d&#8217;appel d&#8217;un service de pr&#234;ts bancaires (GE_fr). Ces dia-
logues couvrent une grande vari&#233;t&#233; de th&#232;mes comme la demande d&#8217;informations (limites de cr&#233;dits
possibles, informations sur le disponible), le passage d&#8217;ordres (modification des limites de cr&#233;dits,
changement des mensualites...), la gestion de compte (ouverture et fermeture, modification des
informations personnelles)... Le corpus au complet est constitu&#233; de 134 dialogues. Ces dialogues
sont transcrits avec l&#8217;outil d&#8217;alignement transcription/signal Transcriber. Ce corpus a &#233;t&#233; divis&#233; en
trois partie pour l&#8217;apprentissage (94 dialogues, 2923 tours de parole et 3912 segments dialogiques),
le d&#233;veloppement (22 dialogues, 687 tours de parole et 884 segments dialogiques) et le test (18
dialogues, 663 tours de parole et 827 segments dialogiques). Ce corpus a par ailleurs &#233;t&#233; tagu&#233; en
entit&#233;s sp&#233;cifiques : entit&#233;s nomm&#233;es (personne, lieu, date etc.), entit&#233;s d&#233;pendantes de la t&#226;che (i.e.
entit&#233;s nomm&#233;es faisant appel &#224; une connaissance sp&#233;cifique du domaine ; par exemple num&#233;ro de
compte, adresse, montant disponible sur un compte etc.).
</p>
<p>2.2 Principes d&#8217;annotation
</p>
<p>Ce corpus a &#233;t&#233; annot&#233; avec le sch&#233;ma d&#8217;annotation dialogique propos&#233; dans le cadre du projet
AMITI&#201;S et fond&#233; sur la taxonomie de DAMSL (Hardy H. et al., 2002). Les annotations devant
permettre de d&#233;crire et r&#233;sumer l&#8217;intention du locuteur, huit classes ont &#233;t&#233; &#233;tablies afin d&#8217;obtenir
une annotation fine et sur diff&#233;rents niveaux. La taxonomie obtenue est la suivante :
</p>
<p>&#8226; Classe 1 Information Level : permet d&#8217;annoter un &#233;nonc&#233; dans son rapport &#224; la r&#233;alisation
de la t&#226;che. Les tags possibles sont : Communication-mgt, Out-of-topic, Task, Task-manage-
ment-Completion, Task-management-Order, Task-management-Summary, Task-management-
System-Capabilities.
</p>
<p>&#8226; Classe 2 Statement : permet d&#8217;annoter les &#233;nonc&#233;s d&#233;claratifs ayant un contenu informatif
explicite. Les tags possibles sont : Assert, Commit, Explanation, Expression, ReExplanation,
Reassert.
</p>
<p>&#8226; Classe 3 Conventional : permet de noter les aspects conventionnels d&#8217;un dialogue homme-
homme, comme les ouvertures et fermetures. Les tags possibles sont : Closing, Opening.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>S. Rosset, D. Tribout
</p>
<p>C1 C2 C3 C4 C5 C6 C7 C8
</p>
<p>seuil=200,Utt.=51%
</p>
<p>CM19%
</p>
<p>26%
</p>
<p>Task
</p>
<p>16%
</p>
<p>14%
</p>
<p>12%
</p>
<p>10%
</p>
<p>Exp
</p>
<p>19%
26%
</p>
<p>-
</p>
<p>26%
</p>
<p>Cl19%
</p>
<p>-
</p>
<p>26%
</p>
<p>16%
</p>
<p>10%
</p>
<p>Ad
</p>
<p>14%
</p>
<p>EIr
</p>
<p>12%
-
</p>
<p>26%
</p>
<p>19%
</p>
<p>16%
</p>
<p>Acc
</p>
<p>10%
</p>
<p>-
</p>
<p>26%
</p>
<p>19%
16%
14%
12%
</p>
<p>Bc
</p>
<p>26%
</p>
<p>-
</p>
<p>19%
</p>
<p>16%
14%
12%
</p>
<p>-
</p>
<p>26%
</p>
<p>19%
</p>
<p>19%
16%
14%
12%
</p>
<p>10%
</p>
<p>Ass
</p>
<p>16%
</p>
<p>10%
</p>
<p>-
</p>
<p>14%
</p>
<p>12%
</p>
<p>16%
</p>
<p>10%
</p>
<p>14%
12%
</p>
<p>14%
</p>
<p>12%
</p>
<p>RT10%
</p>
<p>10%
</p>
<p>Figure 1: Les successions les plus fr&#233;quentes d&#8217;ADs
</p>
<p>&#8226; Classe 4 Influence on Listener : permet de rendre compte de l&#8217;intention du locuteur en tant
qu&#8217;agissant sur le dr&#769;oulement du dialogue. Les tags possibles sont : Action-directive, Ex-
plicit-Confirm-request, Explicit-Info-request, Implicit-Confirm-request, Implicit-Info-request,
Offer, Open-Option, Re-Action-directive, Re-Confirm-request, Re-Info-request, Re-Offer.
</p>
<p>&#8226; Classe 5 Agreement : permet de sp&#233;cifier l&#8217;accord ou le d&#233;saccord du locuteur avec ce qui
pr&#233;c&#232;de. Les tags possibles sont : Accept, Accept-part, Maybe, Reject, Reject-part.
</p>
<p>&#8226; Classe 6 Answer : permet de pr&#233;ciser si l&#8217;&#233;nonce en question constitue une r&#233;ponse &#224; un
&#233;nonc&#233; pr&#233;c&#233;dent. Le tag utilis&#233; est alors : True.
</p>
<p>&#8226; Classe 7 Understanding : permet de noter les degr&#233;s de compr&#233;hension du locuteur. Les
tags possibles sont : Backchannel, Completion, Correction, Non-understanding, Repeat-
rephrase.
</p>
<p>&#8226; Classe 8 Communicative Status : permet d&#8217;annoter les apart&#233;s les interruptions, les change-
ment de sujet... Les tags possibles sont : AbandStyle, AbandTrans, AbandChangeMind,
AbandlossIdeas, Interrupted, Self-talk.
</p>
<p>Les actes de dialogue couvrant diff&#233;rents aspects conversationnels, un m&#234;me segment dialogique
peut contenir plusieurs actes de dialogue. Par cons&#233;quent plusieurs de ces classes peuvent &#234;tre
s&#233;lectionn&#233;es pour d&#233;crire un m&#234;me segment dialogique. Chaque segment dialogique peut en ef-
fet &#234;tre cat&#233;goris&#233; selon son niveau informationnel ainsi que selon son aspect conventionnel, son
influence sur la suite du dialogue... Ceci implique qu&#8217;un segment dialogique peut potentielle-
ment recevoir une &#233;tiquette de chacune de ces classes. Par exemple, le segment dialogique A for
Alpha est annot&#233; avec l&#8217;&#233;tiquette Explicit-Confirm-request de la classe Influence on Listener et
Non-understanding de la classe Understanding.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;tection automatique d&#8217;actes de dialogue
</p>
<p>ADj(Di+1)
</p>
<p>ADj(SDi)
</p>
<p>ADj+1(SDi)
</p>
<p>sortieentr&#233;e
</p>
<p>Model(AD)
</p>
<p>traits
Extraction de Classification
</p>
<p>Figure 2: Raisonnement fond&#233; sur la similarit&#233; et utilisation des hypoth&#232;ses pr&#233;c&#233;dentes
</p>
<p>2.3 M&#233;thodologie pour l&#8217;annotation automatique
</p>
<p>Pour effectuer l&#8217;annotation automatique nous avons repr&#233;sent&#233; chaque enonc&#233; du corpus d&#8217;ap-
prentistisage et du corpus de developpement par un vecteur puis effectu&#233; des comparaisons. Pour
cela nous avons choisi une approche de type Memory Based Learning car elle fonctionne bien
sur de petites quantit&#233;s de donn&#233;es. En outre, diff&#233;rentes &#233;tudes (van den Bosch A. et al., 2001;
Daelemans W. et al., 1999) ont montr&#233; qu&#8217;elle &#233;tait particuli&#232;rement bien adapt&#233; au traitement au-
tomatique de la langue. Nous avons utilis&#233; l&#8217;impl&#233;mentation IB1-IG du logiciel Timbl (Daelemans
W. et al. 2003) avec une distance de manhatan. Dans cette m&#233;trique, la distance entre deux ob-
jets est simplement la somme de la diff&#233;rence entre les diff&#233;rents traits de ces objets. Le principe
de cette approche est relativement simple : il s&#8217;agit de comparer le vecteur entrant &#224; l&#8217;ensemble
des vecteurs du mod&#232;le et d&#8217;assigner &#224; celui-ci la classe du vecteur du mod&#232;le dont il est le plus
proche. Le corpus d&#8217;apprentissage a servi de mod&#232;le de vecteurs et le corpus de developpement
a constitu&#233; l&#8217;ensemble des vecteurs &#224; classer. Les traits choisis pour la construction des vecteurs
sont l&#8217;identit&#233; du locuteur (Client ou Agent), le nombre de segments dialogiques dans le tour con-
sid&#233;r&#233;, les premiers mots du segment annot&#233; et les tags des huit classes d&#233;finies. Pour ce qui est
de l&#8217;utilisation des mots comme traits, notre hypoth&#232;se &#233;tant que les premiers mots sont plus im-
portants que l&#8217;ensemble des mots, seuls les premiers mots de chaque segment dialogique ont &#233;t&#233;
utilis&#233;s. Quant aux tags, si aucune &#233;tiquette d&#8217;une classe consid&#233;r&#233;e n&#8217;est pertinente pour le seg-
ment alors la classe est repr&#233;sent&#233;e par le tag &quot;NA&quot; (not applicable) de mani&#232;re &#224; avoir toujours le
m&#234;me nombre de traits dans un vecteur. Ainsi, les &#233;nonc&#233;s du corpus d&#8217;apprentissage constituant
le mod&#232;le de vecteurs ont &#233;t&#233; repr&#233;sent&#233;s de la fa&#231;on suivante (pour un nombre de mots &#233;gal &#224; 4) :
pour un &#233;nonc&#233; tel que
Agent: donnez moi votre num&#233;ro de compte
</p>
<p>ayant pour annotation les &#233;tiquettes :
</p>
<p>DAs: information-level=Task ; influence-on-listener=Action-directive
le vecteur correspondant est :
</p>
<p>Agent 1 donnez moi votre num&#233;ro Task NA NA Action-directive NA NA NA NA
</p>
<p>De la m&#234;me fa&#231;on, l&#8217;enonc&#233;
</p>
<p>Client : alors [numerique] [numerique] [numerique] [numerique] [numerique] [numerique]
ayant pour annotation les &#233;tiquettes :</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>S. Rosset, D. Tribout
</p>
<p>DAs: information-level=Task ; statement=Assert ; agreement=Accept ; answer=true
est repr&#233;sent&#233; par le vecteur :
</p>
<p>Client 1 alors [numerique] [numerique] [numerique] Task Assert NA NA Accept true NA NA
Alors qu&#8217;a priori la combinatoire des tags est relativement importante, seulement 197 combi-
naisons diff&#233;rentes sont retrouv&#233;es dans le corpus d&#8217;entra&#238;nement. Il y a donc un facteur de pr&#233;-
dictivit&#233; relativement important dans la succession des classes et des &#233;tiquettes s&#233;lectionn&#233;es. Ceci
est illustr&#233; par la figure 1 qui peut &#234;tre vue comme une grammaire de succession d&#8217;&#233;tiquettes dia-
logiques. Sur cette figure, les six successions les plus fr&#233;quentes d&#8217;&#233;tiquettes dialogiques sont
repr&#233;sent&#233;es. Elles couvrent 51% des s&#233;quences du corpus d&#8217;entra&#238;nement. Ainsi, si Task est
s&#233;lectionn&#233; pour la classe 1 (52%) alors la classe 2 recevra soit NA (26%) soit Assert (26%) et
la classe 3 NA. Ceci montre qu&#8217;il semble y avoir un facteur de pr&#233;dictivit&#233; relativement impor-
tant dans la succession des classes et des &#233;tiquettes s&#233;lectionn&#233;es. C&#8217;est pourquoi l&#8217;annotation des
segments dialogiques du corpus &#224; annoter est r&#233;alis&#233;e en huit &#233;tapes : une pour chacune des huit
classes d&#8217;annotation. A chaque &#233;tape un tag est affect&#233; &#224; la classe correspondante et celui-ci est
ajout&#233; au vecteur lors de l&#8217;&#233;tape suivante. En outre, l&#8217;annotation dialogique est effectu&#233;e en tenant
compte de l&#8217;ensemble du tour de parole et dans l&#8217;ordre des segments composant un tour. C&#8217;est-
&#224;-dire que pour chaque tour de parole, le premier segment dialogique est d&#8217;abord annot&#233; en huit
&#233;tapes, puis le second segment est ajout&#233; au premier et annot&#233; &#224; son tour en huit &#233;tapes. La m&#233;-
thode consiste donc pour le syst&#232;me &#224; extraire du tour de parole donn&#233; en entr&#233;e les traits retenus
(identit&#233; du locuteur, nombre de segments dialogiques, N premiers mots) et &#224; les placer dans un
vecteur (SD1(ADi)=[SpkrId, #Utt., w_1,w_2,ADi&#8722;1]). L&#8217;assignation d&#8217;une &#233;tiquette dialogique &#224;
ce vecteur (la classification) est faite en comparant ce vecteur &#224; l&#8217;ensemble des vecteurs du mod-
&#232;le, et ceci &#224; huit reprises (une pour chacune des classes d&#8217;annotation) en ajoutant &#224; chaque &#233;tape
de la classification l&#8217;&#233;tiquette d&#233;termin&#233;e &#224; l&#8217;&#233;tape pr&#233;c&#233;dente. D&#232;s que le premier segment di-
alogique de l&#8217;&#233;nonc&#233; en cours de traitement est annot&#233;, si cet &#233;nonc&#233; comporte un ou plusieurs
autres segments dialogiques, les N premiers mots du segment suivant sont ajout&#233;s au vecteur
initial et la classification s&#8217;effectue de la m&#234;me fa&#231;on. Ainsi le nouveau vecteur est compos&#233;
de : SDi(SDi&#8722;1 +ADi+w1SDi ,w2SDi ,). Cette m&#233;thode utilis&#233;e pour annoter automatiquement les
&#233;nonc&#233;s est repr&#233;sent&#233;e par la figure 2.
</p>
<p>3 Exp&#233;riences et r&#233;sultats
</p>
<p>3.1 Premi&#232;re exp&#233;rience : mod&#232;le de base
</p>
<p>La premi&#232;re exp&#233;rience, effectu&#233;e sur le corpus d&#8217;apprentissage, a consist&#233; &#224; faire varier le nombre
de mots donn&#233;s en entr&#233;e : (1) les 4 premiers mots du premier segment dialogique, (2) les 4
premiers mots du premier segment dialogique et les 2 premiers mots du segment pour les segments
dialogiques suivants, (3) les 2 premiers mots du premier segment dialogique et les 2 premiers mots
du segment pour les segments dialogiques suivants. Les r&#233;sultats sont pr&#233;sent&#233;s dans le tableau 2.
Par ailleurs, un examen des poids attribu&#233;s par TiMBL &#224; chaque trait des vecteurs montre que les
mots sont dot&#233;s d&#8217;un faible poids, ce qui indique qu&#8217;ils ne constituent pas le crit&#232;re le plus pertinent
pour cat&#233;goriser les vecteurs entrant. Cette observation va bien dans le sens de notre hypoth&#232;se
lexicale. Toutefois, un examen plus attentif des r&#233;sultats montrent que certains actes de dialogues
sont plus d&#233;pendants du lexique que d&#8217;autres. Le tableau 3 permet de mettre cette constatation en
&#233;vidence.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;tection automatique d&#8217;actes de dialogue
</p>
<p>Data # dial #seg. dial. #tour %erreur exp.
GE_fr dev 22 884 687 14.0 4words
</p>
<p>13.2 4+2words
13.0 2+2words
</p>
<p>GE_fr Test 18 827 663 16.5 4words
16.2 4+2words
17.2 2+2words
</p>
<p>Table 2: Taux d&#8217;erreur de d&#233;tection d&#8217;actes de dialogues sur corpus developpement et test.
</p>
<p>DA GE_fr dev
Response-To 52% (148)
Backchannel 12.5% (161)
Accept 46.9% (147)
Assert 25.9% (243)
Expression 7.9% (378)
Comm-mgt 8.3% (420)
Task 12.4% (427)
</p>
<p>Table 3: Taux d&#8217;erreur sur les 7 tags les plus fr&#233;quents.
</p>
<p>3.2 R&#233;duction de la variation lexicale
</p>
<p>Un pr&#233;traitement des &#233;nonc&#233;s a ensuite &#233;t&#233; effectu&#233; pour tenter de r&#233;duire la variation de cer-
tains &#233;nonc&#233;s jug&#233;s &#233;quivalents au niveau s&#233;mantique et fonctionnel. L&#8217;hypoth&#232;se sous-jacente &#224;
cette tentative est que l&#8217;annotation automatique g&#234;n&#233;e par certaines variations formelles d&#8217;&#233;nonc&#233;s
pourtant &#233;quivalents du point de vue du sens pourrait &#234;tre am&#233;lior&#233;e si ces variations &#233;taient neu-
tralis&#233;es. Ainsi pour la conjugaison des verbes la variation en temps g&#234;ne souvent l&#8217;annotation.
Les formes &#8220;je voudrais&#8221;, &#8220;je voulais&#8221;, &#8220;j&#8217;aurais voulu&#8221;, par exemple sont &#224; peu pr&#232;s &#233;quivalentes
dans le contexte de demande d&#8217;information. Nous avons donc d&#233;cid&#233; de r&#233;duire ces variations
&#224; une m&#234;me forme neutralis&#233;e &#8220;*vouloir&#8221;, que nous distingons de l&#8217;infinitif avec le signe &#8220;*&#8221;.
Les neutralisations concernent &#233;galement certains morceaux d&#8217;&#233;nonc&#233;s r&#233;currents que nous avons
jug&#233;s &#233;quivalents comme &#8220;je vous &#233;coute&#8221;, &#8220;c&#8217; est &#224; quel propos&#8221;, &#8220;c &#8217;est pourquoi&#8221;, &#8220;c&#8217; est &#224; quel
sujet&#8221;... qui sont tous une fa&#231;on pour l&#8217;agent d&#8217;inviter le client &#224; exposer le sujet de son appel,
et que nous avons donc neutralis&#233;s en *invite. Ces &#233;nonc&#233;s neutralis&#233;s ont &#233;t&#233; d&#233;termin&#233;s apr&#232;s
l&#8217;&#233;tude des dialogues du corpus d&#8217;apprentissage et concernent notamment les diff&#233;rentes fa&#231;ons de
remercier (&#8220;je vous remercie&#8221;, &#8220;c&#8217; est moi qui vous remercie&#8221;, &#8220;merci beaucoup&#8221;, &#8220;merci bien&#8221;...),
de demander (&#8220;vous pouvez me donner&#8221;, &#8220;vous pouvez me rappeler&#8221;, &#8220;donnez-moi&#8221;, &#8220;rappelez-
moi&#8221;...) d&#8217;ouvrir la conversation (&#8220;bonjour&#8221;, &#8220;bonsoir&#8221;, &#8220;allo&#8221;)... La r&#233;duction de ces variations
lexicales a &#233;t&#233; effectu&#233;e automatiquement sur l&#8217;ensemble du corpus en utilisant l&#8217;outil de d&#233;tection
en entit&#233;s nomm&#233;es qui a &#233;t&#233; &#233;tendu. Cette &#233;tape a permis de faire passer la taille du lexique de
1976 mots &#224; 1649 mots. Les m&#234;mes exp&#233;riences que pr&#233;c&#233;demment ont ensuite &#233;t&#233; men&#233;es sur ce
corpus et les r&#233;sultats obtenus dans ces conditions montrent que la r&#233;duction de la variation lexi-
cale am&#233;liore l&#8217;annotation automatique. Le tableau 4 donne les r&#233;sultats obtenus avec ce second
mod&#232;le.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>S. Rosset, D. Tribout
</p>
<p>Exp. %erreur Dev %erreur Test.
4words 14.0 16.4
4+2words 12.9 16.2
2+2words 12.7 16.7
</p>
<p>Table 4: Taux d&#8217;erreur de d&#233;tection d&#8217;actes de dialogues sur corpus d&#233;veloppement et test apr&#232;s
r&#233;duction de la variation
</p>
<p># Seg. Dial %erreur Dev. %erreur Test
1 SD 13.2 16.8
2 SD 9.2 16.0
3 SD 22.4 19.2
</p>
<p>Table 5: Taux d&#8217;erreur de d&#233;tection d&#8217;actes de dialogues sur corpus d&#233;veloppement et test par
segment dialogique
</p>
<p>3.3 Utilisation des historiques
</p>
<p>Des exp&#233;riences suppl&#233;mentaires ont ensuite &#233;t&#233; men&#233;es en jouant sur l&#8217;historique du dialogue
afin de voir si cela am&#233;liorait la d&#233;tection automatique des actes de dialogue. Partant des r&#233;sultats
pr&#233;c&#233;demment obtenus, deux hypoth&#232;ses ont servi de base &#224; ces exp&#233;riences. La premi&#232;re est que
s&#8217;il existe plusieurs segments dialogiques au sein d&#8217;un tour, ceux-ci entretiennent des relations en-
tre eux et sont organis&#233;s selon certains principes. La seconde est que le dialogue constituant une
alternance de tours de parole se r&#233;pondant les uns aux autres, les actes de dialogue d&#8217;un tour sont
en partie conditionn&#233;s par les actes de dialogue du tour pr&#233;c&#233;dent. Les exp&#233;riences suivantes ont
donc &#233;t&#233; r&#233;alis&#233;es afin de voir si ces deux hypoth&#232;ses se v&#233;rifiaient.
En ce qui concerne la premi&#232;re hypoth&#232;se, nous avons constat&#233; &#224; partir des exp&#233;riences pr&#233;c&#233;dentes
qu&#8217;au sein d&#8217;un tour de parole les r&#233;sultats de l&#8217;annotation automatique &#233;taient syst&#233;matiquement
meilleurs pour le deuxi&#232;me segment dialogique que pour le premier, et tout aussi syst&#233;matique-
ment, nettement moins bons pour le troisi&#232;me segment3 ainsi que le montre le tableau 5. Le
premier segment dialogique, qui est ajout&#233; au vecteur lorsqu&#8217;on annote le suivant, semble donc
aider &#224; d&#233;terminer le second. Celui-ci serait donc &#233;troitement li&#233; au premier et constituerait une
sorte de prolongement ou de compl&#233;ment du premier. En revanche, pour le troisi&#232;me segment les
segments pr&#233;c&#233;dents qui sont eux aussi ajout&#233;s au vecteur ne semblent pas aider &#224; sa d&#233;tection. De
cette constatation nous avons &#233;mis l&#8217;hypoth&#232;se que si le second segment dialogique d&#8217;un tour de
parole est dans la continuit&#233; du premier, le troisi&#232;me semble au contraire &#234;tre en rupture avec eux.
Nous avons donc essay&#233; d&#8217;annoter automatiquement les segments dialogiques sans tenir compte
des deux premiers segments pour annoter le troisi&#232;me, c&#8217;est-&#224;-dire sans mettre les deux premiers
segments dans le vecteur du troisi&#232;me. Avec cette m&#233;thode les r&#233;sultats du troisi&#232;me segment sont
nettement meilleurs comme le montre le tableau 6 (exp. 1). Ceci semble donc confirmer notre hy-
poth&#232;se de d&#233;part selon laquelle les segments dialogiques d&#8217;un tour de parole entretiennent entre
eux des relations qui ne sont pas toutes de la m&#234;me nature.
En ce qui concerne la seconde hypoth&#232;se, les tours de parole se r&#233;pondant les uns les autres, il
nous a sembl&#233; int&#233;ressant de prendre en compte les informations contenues dans le tour pr&#233;c&#233;dent
pour d&#233;terminer les segments dialogiques d&#8217;un tour donn&#233;. Toutefois, compte tenu de ce qui vient
</p>
<p>3les tours de parole comprenant plus de trois segments dialogiques n&#8217;&#233;tant pas assez nombreux pour pouvoir
&#233;mettre une hypoth&#232;se &#224; leur sujet l&#8217;&#233;tude s&#8217;est born&#233;e aux trois premiers segments.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;tection automatique d&#8217;actes de dialogue
</p>
<p>Exp. Dev. %erreur Test %erreur Seg. Dial
Exp. 1 13.2 16.8 1
</p>
<p>9.2 16.5 2
19.7 12.5 3
</p>
<p>Exp. 2 10.4 13.7 1
10.4 15.6 2
25 14.2 3
</p>
<p>Exp. 3 10.4 13.7 1
10.4 15.6 2
15.8 13.3 3
</p>
<p>Table 6: Taux d&#8217;erreur de d&#233;tection d&#8217;actes de dialogues sur corpus developpement et test avec
variation sur les historiques
</p>
<p>d&#8217;&#234;tre expos&#233; sur les relations que semblent entretenir les segments dialogiques au sein d&#8217;un m&#234;me
tour de parole, il nous a sembl&#233; que toutes les informations du tour pr&#233;c&#233;dent n&#8217;&#233;taient sans doute
pas pertinentes et que seules les informations relatives au dernier segment dialogique devait avoir
une influence sur les segments dialogiques du tour suivant. Nous avons donc ajout&#233; au vecteur
les annotations du dernier segment du tour pr&#233;c&#233;dent. Les r&#233;sultats concernant le premier et le
deuxi&#232;me segments ont ainsi &#233;t&#233; am&#233;lior&#233;s, mais pas ceux du troisi&#232;me qui se sont plut&#244;t d&#233;grad&#233;s
(cf. tableau 6 (exp. 2)).
Compte tenu de ces r&#233;sultats et de ceux obtenus par l&#8217;exp&#233;rience pr&#233;c&#233;dente, nous avons essay&#233; de
m&#234;ler les deux m&#233;thodes afin d&#8217;am&#233;liorer encore l&#8217;annotation automatique. Ainsi, pour le premier
et le deuxi&#232;me segments d&#8217;un tour de parole les annotations du dernier segment dialogique du tour
pr&#233;c&#233;dent ont &#233;t&#233; ajout&#233;es au vecteur, tandis que pour le troisi&#232;me segment ni les deux segments
pr&#233;c&#233;dents ni le dernier segment du tour pr&#233;c&#233;dent n&#8217;ont &#233;t&#233; pris en compte. Avec cette m&#233;thode
&quot;mixte&quot;, les r&#233;sultats ont ainsi &#233;t&#233; am&#233;lior&#233;s pour tous les segments (cf. tableau 6 (exp. 3)).
</p>
<p>4 Conclusion et Perspectives
</p>
<p>Ces travaux r&#233;alis&#233;s dans le cadre de l&#8217;annotation dialogique automatique ont permis de mettre
en avant le fait que les tours de parole ne sont pas des suites d&#8217;&#233;nonc&#233;s anarchiques mais sont
au contraire structur&#233;s selon certains principes. La succession des segments dialogiques qui les
composent semble en effet organis&#233;e : le premier segment dialogique d&#8217;un tour de parole semble
&#234;tre li&#233; au dernier segment du tour pr&#233;c&#233;dent, le deuxi&#232;me segment d&#8217;un tour semble li&#233; au premier,
tandis que le troisi&#232;me semble ind&#233;pendant des pr&#233;c&#233;dents. En outre, l&#8217;&#233;tude des dialogues dans
leur entier a &#233;galement fait ressortir une certaine structure du dialogue.
</p>
<p>En ce qui concerne l&#8217;annotation automatique d&#8217;actes de dialogue, les diff&#233;rentes exp&#233;riences men&#233;es
ont contribu&#233; &#224; son am&#233;lioration. Toutefois, celle-ci peut encore &#234;tre am&#233;lior&#233;e davantage et
d&#8217;autres m&#233;thodes sont &#224; envisager. Nous envisageons notamment d&#8217;utiliser des informations
s&#233;mantiques, disponibles actuellement sous la forme d&#8217;annotations appliqu&#233;es aux m&#234;mes don-
n&#233;es, afin de voir si elles ne permettraient pas une meilleure d&#233;tection des actes de dialogue.
Une autre m&#233;thode que nous envisageons est d&#8217;effectuer une classification des &#233;nonc&#233;s du corpus
d&#8217;apprentissage et de faire pour chacune classes d&#233;gag&#233;es des mod&#232;les propres. Ceux-ci seraient</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>S. Rosset, D. Tribout
</p>
<p>ainsi plus sp&#233;cificques et les nouveaux &#233;nonc&#233;s pourraient alors &#234;tre annot&#233;s en fonction du mod&#232;le
qui leur correspond le mieux. Enfin, les r&#233;sultats pr&#233;sent&#233;s font tous l&#8217;assomption que le nombre
de segments dialogiques par tour de parole est connu ainsi que les fronti&#232;res elles-m&#234;mes. Il est
bien entendu que dans le cadre d&#8217;un syst&#232;me automatique, ces informations doivent &#234;tre estim&#233;es.
Une &#233;tude pr&#233;c&#233;dente (Rosset S. et Lamel L., 2004) avait montr&#233; qu&#8217;il &#233;tait possible de pr&#233;dire
de mani&#232;re raisonnable le nombre de segment dialogique dans un &#233;nonc&#233;. Des taux d&#8217;&#233;rreurs sur
cette t&#226;che de l&#8217;ordre de 12% ont &#233;t&#233; rapport&#233;s. Environ 5 &#224; 7% des tour de parole pr&#233;sentaient une
insertion ou une suppression de fronti&#232;re. Ces mod&#232;les pour la d&#233;tection de fronti&#232;res de segments
dialogiques doivent donc &#233;galement &#234;tre int&#233;gr&#233;s au syst&#232;me de d&#233;tection d&#8217;actes de dialogue pour
avoir un syst&#232;me enti&#232;rement automatique.
</p>
<p>R&#233;f&#233;rences
J. L. Austin (1962), How to do thing with words, Oxford: Clarendon Press.
R. Cattoni, M. Danieli, A. Panizza, V. Sandrini, C. Soria (2001), Building a corpus of annotated dialogues:
the ADAM experience, Corpus Linguistics 2001.
</p>
<p>W. Daelemans, J. Zavrel, K. van der Sloot, A. van den Bosch (2003), TiMBL: Tilburg Memory Based
Learner, v5.0, Reference Guide, ILK Technical Report ILK-03-10, (http://ilk.kub.nl/software.html#timbl)
W. Daelemans, A. van den Bosch, J. Zavrel (1999), Forgetting exceptions is harmful in language learning,
Machine Learning Vol 34:11-43.
</p>
<p>B. Di Eugenio, P. W. Jordan, J. D. Moore, R. H. Thomason (1998) An empirical investigation of collabora-
tive dialogues, Actes de ACL, COLING.
</p>
<p>H. Hardy, K. Baker, H. Bonneau-Maynard, L. Devillers, S. Rosset, T. Strzalkowski (2002), Semantic and
Dialogic annotation for Automated Multilingual Customer Service, Actes de ISLE workshop.
</p>
<p>J. Hirschberg, D.J. Litman (1993), Empirical Studies on the Disambiguation of Cue Phrases, Computational
Linguistics Vol. 19(3):501-530.
A. Isard, J.C. Carletta (1995), Replicability of transaction and action coding in the map task corpus, Actes
de AAAI Spring Symposium: Empirical Methods in Discourse Interpretation and Generation.
</p>
<p>N. Reithinger, M. Klesen. (1997), Dialogue act classification using language models, Actes de
Eurospeech&#8217;97
S. Rosset et L. Lamel (2004), Automatic Detection of Dialog Acts Based on Multi-level Information, Actes
de ICSLP&#8217;04
</p>
<p>K. Samuel, S. Carberry, K. Vijay-Shanker (1998), Dialogue act tagging with transformation-based learning,
Actes de COLING-ACL
</p>
<p>J. R. Searle (1969), Speech acts, Cambridge University Press.
D. Traum (2000), 20 Questions on Dialog Act taxonomies, Journal of Semantics, Vol. 17(1):7-30.
A. van den Bosch, E. Krahmer, M. Swerts (2001), Detecting problematic turns in human-machine interac-
tions: Rule-induction versus memory-based learning approaches, Actes de ACL&#8217;01</p>

</div></div>
</body></html>