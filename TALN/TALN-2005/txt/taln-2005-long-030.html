<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Comment mesurer la couverture d'une ressource terminologique pour un corpus ?</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2005, Dourdan, 6-10 juin 2005
</p>
<p>Comment mesurer la couverture d'une ressource terminologique
pour un corpus ?
</p>
<p>Goritsa Ninova (1), Adeline Nazarenko (2),
Thierry Hamon (2), Sylvie Szulman (2)
</p>
<p>LIPN UMR 7030
Universit&#233; Paris 13 &amp; CNRS
</p>
<p>99, av. J.-B. Cl&#233;ment
93430 Villetaneuse
</p>
<p>(1) cylvago@yahoo.fr
(2){pr&#233;nom.nom}@lipn.univ-paris13.fr
</p>
<p>Mots-cl&#233;s : couverture lexicale, terminologie, statistique lexicale
Keywords : lexical coverage, terminology, lexical statistics
</p>
<p>R&#233;sum&#233; Cet article propose une d&#233;finition formelle de la notion de couverture lexicale. Celle-
ci repose sur un ensemble de quatre m&#233;triques qui donnent une vue globale de l'ad&#233;quation d'une
ressource lexicale &#224; un corpus et permettent ainsi de guider le choix d'une ressource en fonction
d'un corpus donn&#233;. Les m&#233;triques propos&#233;es sont test&#233;es dans le contexte de l'analyse de corpus
sp&#233;cialis&#233;s en g&#233;nomique : 5 terminologies diff&#233;rentes sont confront&#233;es &#224; 4 corpus. La
combinaison des valeurs obtenues permet de discerner diff&#233;rents types de relations entre
ressources et corpus.
</p>
<p>Abstract This paper proposes a formal definition of the notion of lexical coverage. This
definition is based on four metrics that give a global view over a lexical resource to corpus
relationship, thus helping the choice of a relevant resource with respect to a given corpus. These
metrics have been experimented in the context of specialised corpus analysis in genomics. 5
terminologies have been confronted to 4 different corpora. The combination of resulting figures
reflects various types of corpus vs . resource relationships.
</p>
<p>1 Introduction
On parle couramment de &#171; couverture lexicale &#187; sans d&#233;finir clairement ce qu&#8217;on entend par l&#224;.
Diff&#233;rents auteurs mettent sous ce terme diff&#233;rentes notions et mesures. Le probl&#232;me est d'autant
plus complexe que les ressources utilis&#233;es comportent souvent des expressions polylexicales
dont la projection en corpus peut se faire de diff&#233;rentes mani&#232;res. Le pr&#233;sent article propose de
d&#233;finir un ensemble de m&#233;triques pour cerner cette notion de couverture dans le cas g&#233;n&#233;ral
d'une ressource constitu&#233;e d'une liste de termes mono- et polylexicaux. Ces mesures sont test&#233;es</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ninova G., Nazarenko A., Hamon T. et Szulman S.
</p>
<p>pour diff&#233;rents couples ressource/corpus. Les premiers r&#233;sultats obtenus sont encourageants. Ils
montrent qu'on peut en effet documenter le comportement d'une ressource pour un corpus
donn&#233; en pr&#233;alable &#224; tout traitement, et ainsi guider le choix de la ressource.
</p>
<p>Apr&#232;s avoir soulign&#233; les enjeux de cette probl&#233;matique et les questions qu&#8217;elle soul&#232;ve (section
2), nous pr&#233;sentons dans la section 3 un ensemble de m&#233;triques. Celles-ci sont exploit&#233;es dans
la perspective du traitement automatique de corpus de g&#233;nomique. Les r&#233;sultats de ces
exp&#233;riences sont pr&#233;sent&#233;s et discut&#233;s dans la section 4 de cet article.
</p>
<p>2 Probl&#233;matique
2.1 Enjeux
Le traitement de corpus sp&#233;cialis&#233; fait appel &#224; des ressources s&#233;mantiques qu'on appelle
g&#233;n&#233;ralement sp&#233;cialis&#233;es parce qu'elles d&#233;crivent un domaine particulier d'activit&#233;. Ces
ressources peuvent &#234;tre de diff&#233;rents types selon les traitements envisag&#233;s, mais elles doivent
comporter une dimension lexicale d&#232;s lors qu'elles sont destin&#233;es &#224; l'analyse et l'interpr&#233;tation de
donn&#233;es textuelles.
</p>
<p>Les ontologies du web s&#233;mantique doivent ainsi &#234;tre ancr&#233;es lexicalement (avec des items
lexicaux associ&#233;s aux noeuds de l'ontologie) si elles doivent servir &#224; indexer des textes. Les
techniques d'acc&#232;s au contenu des documents textuels sont diverses (extraction d'information,
question-r&#233;ponse, outils de navigation ou de r&#233;sum&#233;) mais elles reposent toutes sur une analyse
s&#233;mantique partielle des documents, qui implique la reconnaissance de certains &#233;l&#233;ments du
discours (entit&#233;s nomm&#233;es et termes du domaine, notamment), leur typage s&#233;mantique et leur
mise en relation (Nazarenko, 2005). De ce fait, ces techniques reposent &#233;galement sur des
lexiques, terminologies ou thesaurus sp&#233;cialis&#233;s pour identifier le vocabulaire de sp&#233;cialit&#233;. Les
cat&#233;gories s&#233;mantiques et les relations lexicales sont utilis&#233;es (quand elles existent) pour
d&#233;sambigu&#239;ser les textes et en guider l'interpr&#233;tation.
</p>
<p>D&#232;s lors que les applications de traitement automatique des langues (TAL), y compris au niveau
s&#233;mantique, sont de plus en plus guid&#233;es par le lexique, la question du choix des ressources &#224;
exploiter prend de l&#8217;importance. La situation rel&#232;ve souvent &#224; la fois de la pl&#233;thore et de la
p&#233;nurie. D'un c&#244;t&#233;, il existe de nombreuses ressources terminologiques, surtout dans des
domaines comme la biologie ou la m&#233;decine o&#249; l'effort d'organisation des connaissances est
ancien1. Mais d'un autre c&#244;t&#233;, les &#171; bonnes ressources &#187; sont rares : le degr&#233; de sp&#233;cialisation ou
le point de vue repr&#233;sent&#233; par la ressource est g&#233;n&#233;ralement diff&#233;rent de celui du texte que l'on
cherche &#224; analyser. Ce constat a &#233;t&#233; fait par (Charlet et al., 1996), toujours dans le domaine de la
m&#233;decine pourtant reconnu pour la richesse de ses bases de connaissances. Dans la pratique,
comme on ne peut ni se passer de ressource, ni en reconstruire de nouvelles pour chaque
nouvelle application, on fait souvent avec ce qu'on a. Dans certains cas, on peut sp&#233;cialiser la
ressource et l'adapter en fonction du domaine et de la t&#226;che vis&#233;s (probl&#233;matique de l'adaptation
lexicale ou &#171; lexical tuning &#187; (Basili et al., 1998)) mais cela suppose n&#233;anmoins une ressource
initiale.
</p>
<p>Une question se pose alors : parmi l'ensemble des ressources qui paraissent recouvrir en partie
et a priori le domaine du corpus &#224; traiter, laquelle ou lesquelles choisir et sur quels crit&#232;res ?
Cette question est d'autant plus importante qu'on doit souvent limiter le nombre de ces
ressources pour r&#233;duire l'in&#233;vitable travail de pr&#233;paration des donn&#233;es et pour &#233;viter les
probl&#232;mes d'incoh&#233;rence. Il est en g&#233;n&#233;ral trop co&#251;teux d&#8217;exploiter en parall&#232;le diff&#233;rentes
ressources pour les tester en les comparant au regard de l&#8217;application vis&#233;e. Les experts du
domaine ne sont pas toujours d'un grand secours non plus. M&#234;me s'ils sont capables de d&#233;crire
</p>
<p>                                                
</p>
<p>1 Voir par exemple, UMLS (Unified Medical Language System, http://www.nlm.nih.gov/research/umls/).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mesurer la couverture d&#8217;une ressource terminologique
</p>
<p>le sous-domaine couvert par une ressource et le point de vue qui y est repr&#233;sent&#233;, ils sont
d&#8217;ordinaire peu &#224; m&#234;me de mesurer son ad&#233;quation proprement lexicale.
</p>
<p>Ce probl&#232;me du choix des ressources est souvent r&#233;solu de mani&#232;re tr&#232;s empirique, ce qui ne
permet pas de capitaliser d'une exp&#233;rience &#224; l&#8217;autre. Il est donc important de se doter de crit&#232;res
formels permettant de d&#233;crire le comportement d'une ressource par rapport &#224; un corpus donn&#233; et
d&#8217;en guider le choix. C'est l'objet de ce travail : nous proposons un premier ensemble de
m&#233;triques pour appr&#233;cier la couverture d'un corpus par une ressource terminologique.
</p>
<p>2.2 Difficult&#233;s
Pour des dictionnaires traditionnels, on exprime l'ad&#233;quation &#224; un corpus en termes de
couverture et on l'appr&#233;cie &#224; partir du nombre d'occurrences de mots du corpus qui se rattachent
&#224; des entr&#233;es du dictionnaire. La couverture est plus difficile &#224; d&#233;finir pour des ressources
terminologiques.
</p>
<p>La premi&#232;re difficult&#233; tient &#224; la diversit&#233; des ressources terminologiques qui rend probl&#233;matique
leur comparaison. La nature de l&#8217;information diff&#232;re d&#8217;une ressource &#224; l&#8217;autre. Au-del&#224; des
listes de termes, les termes eux-m&#234;mes peuvent &#234;tre typ&#233;s et les types peuvent &#234;tre organis&#233;s en
hi&#233;rarchie (thesaurus). Dans les ressources les plus riches, les termes sont de surcro&#238;t li&#233;s entre
eux par des liens s&#233;mantiques. Les ressources ont par ailleurs des degr&#233;s de sp&#233;cialisation
divers. Il est difficile de comparer un lexique de 10 000 unit&#233;s qui comporterait de nombreuses
unit&#233;s &#233;galement pr&#233;sentes dans des dictionnaires g&#233;n&#233;ralistes et un lexique de 500 unit&#233;s dont
tr&#232;s peu figurent dans des dictionnaires classiques. Les ressources s'opposent enfin par leur
degr&#233; de lexicalisation : certaines se contentent de lister des &#233;tiquettes de concepts ; d'autres
consid&#232;rent ces &#233;tiquettes dans leur dimension lexicale et linguistique. Ces derni&#232;res rendent
compte des diff&#233;rentes formes sous lesquelles ces unit&#233;s s&#233;mantiques peuvent se r&#233;aliser en
corpus, jusqu&#8217;&#224; associer des r&#232;gles de d&#233;sambigu&#239;sation contextuelles aux unit&#233;s polys&#233;miques
(N&#233;dellec, Nazarenko, 2005).
</p>
<p>La deuxi&#232;me difficult&#233; tient au fait qu'on cherche &#224; confronter deux objets qui ne sont pas de
m&#234;me nature. La ressource et le corpus s'opposent comme la langue s'oppose au discours : il
faut comparer un ensemble d'&#233;l&#233;ments de lexique (la ressource) avec un ensemble d'occurrences
(le corpus). Par voie de cons&#233;quence, il faut aussi comparer des unit&#233;s potentiellement
polylexicales avec des occurrences observ&#233;es en corpus, n&#233;cessairement monolexicales. Comme
il s&#8217;agit d&#8217;appr&#233;cier a priori l&#8217;ad&#233;quation des ressources aux corpus, nous ne pr&#233;supposons en
effet aucune &#233;tape de reconnaissance  terminologique pr&#233;alable.
</p>
<p>Dans ce premier travail, nous focalisons l'&#233;tude sur les ressources terminologiques consid&#233;r&#233;es
comme des listes de termes, sans exploiter les &#233;ventuelles informations qu'elles contiennent
concernant leurs r&#232;gles de variation, leur typage s&#233;mantique ou les relations s&#233;mantiques qu'ils
entretiennent. Les premiers &#233;l&#233;ments &#233;tant pos&#233;s, il est &#233;videmment n&#233;cessaire de poursuivre, par
exemple, en prenant en compte la d&#233;sambigu&#239;sation des termes polys&#233;miques, les liens de
variations entre termes et la structure s&#233;mantique. Ces points ne sont pas abord&#233;s ici.
</p>
<p>2.3 &#201;tat de l'art
La question de la s&#233;lection des ontologies pour une application prend de l'importance avec
l'augmentation du nombre des ontologies disponibles et la standardisation de leurs formats.
Cette pr&#233;occupation est au coeur de la probl&#233;matique du web s&#233;mantique. (Buitelaar et al., 2004)
montre que la cr&#233;ation d&#8217;une biblioth&#232;que d'ontologies (OntoSelect) suppose de d&#233;finir des
crit&#232;res permettant de s&#233;lectionner une ontologie particuli&#232;re. Trois crit&#232;res sont propos&#233;s : les
degr&#233;s de structuration et de connectivit&#233; sont des mesures proprement ontologiques, mais le
crit&#232;re de couverture est &#233;tabli relativement &#224; une collection de documents. Ce dernier crit&#232;re est</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ninova G., Nazarenko A., Hamon T. et Szulman S.
</p>
<p>cependant d&#233;fini de mani&#232;re assez fruste2 : il ne prend qu'imparfaitement en compte la
dimension proprement linguistique des &#171; &#233;tiquettes  de concepts &#187;.
</p>
<p>Brewster et al. (2004) vont plus loin. Ils proposent d'&#233;valuer les ontologies relativement &#224; un
corpus donn&#233;. La notion de couverture qu'ils proposent est plus riche que la pr&#233;c&#233;dente. Elle
repose sur le nombre de termes en corpus qui correspondent &#224; des concepts de l'ontologie, une
fois effectu&#233;s un calcul de variation pour reconna&#238;tre des formes de termes non canoniques et
une expansion s&#233;mantique pour autoriser une ad&#233;quation &#224; diff&#233;rents niveaux de g&#233;n&#233;ralit&#233;. &#192;
partir de l&#224;, une ontologie est &#233;valu&#233;e en fonction du nombre de concepts qui trouvent leur
contrepartie en corpus. Ce deuxi&#232;me travail prend davantage en compte la nature linguistique des
r&#233;alisations lexicales des concepts en corpus (notion de variation, quasisynonymie entre un
hyperonyme et son hyponyme) mais il est centr&#233; sur l'&#233;valuation et la coh&#233;rence interne d'une
ontologie alors que notre objectif est plut&#244;t de guider le choix d'une ressource pour un corpus
donn&#233;, ce qui conf&#232;re un autre r&#244;le &#224; la notion de couverture et impose de la d&#233;finir plus
pr&#233;cis&#233;ment.
</p>
<p>Sur le plan lexical, la question de la couverture n'a gu&#232;re &#233;t&#233; &#233;tudi&#233;e3. De mani&#232;re intuitive, on
tend &#224; pr&#233;f&#233;rer des ressources de grande taille (en nombre d'entr&#233;es), avec l'id&#233;e qu'elles sont soit
plus compl&#232;tes sur un domaine restreint soit plus g&#233;n&#233;riques et moins li&#233;es &#224; un domaine
particulier. (Nirenburg et al., 1996) critique ce pr&#233;suppos&#233; en soulignant que la taille de la
ressource donne une vue tr&#232;s partielle de sa couverture. Dans ce travail, les auteurs cherchent
cependant &#224; appr&#233;cier la qualit&#233; intrins&#232;que de la ressource alors que nous d&#233;fendons l'id&#233;e
qu'une ressource n'a pas de valeur propre et qu&#8217;elle n'a de valeur que par les utilisations qui
peuvent en &#234;tre faites. Au total, la question du choix de la ressource &#233;tant donn&#233; un corpus a
moins retenu l'attention que la question ult&#233;rieure : une fois cette ressource choisie, comment
l'adapter &#224; ce corpus (Basili et al., 1998) ?
</p>
<p>La statistique lexicale a soulign&#233; depuis ses d&#233;buts (Muller, 1977 ; Manning, Sch&#252;tze, 1999)
qu'il existe une relation fonctionnelle entre une ressource (un vocabulaire) et un corpus mais elle
n'a pas abord&#233; le probl&#232;me des unit&#233;s polylexicales que contiennent les terminologies.
</p>
<p>3 Proposition de m&#233;triques
Afin d'appr&#233;cier l'ad&#233;quation d'une ressource &#224; un corpus, nous proposons diff&#233;rentes mesures.
Il s&#8217;agit de caract&#233;riser la couverture de la ressource ainsi que son degr&#233; de sp&#233;cialisation.
</p>
<p>3.1 Remarques terminologiques
Nous posons les d&#233;finitions suivantes :
</p>
<p>&#8226; Le texte T du corpus est un ensemble ordonn&#233; de mots4. Les mots sont d&#233;finis par leur
forme graphique et rep&#233;r&#233;s par leur position dans le texte.
</p>
<p>                                                
</p>
<p>2 &#171;Coverage is measured by the number of labels for classes and properties that can be matched in the
document&#187;.
</p>
<p>3 La notion de couverture lexicale n&#8217;est pas d&#233;finie dans les ouvrages de statistique linguistique (Oakes, 1998).
Quand la question est abord&#233;e (Manning, Sch&#252;tze, 1999, p. 130), c&#8217;est uniquement pour appr&#233;cier le nombre
de mots inconnus dans un texte.
</p>
<p>4 La notion de &#171; mot &#187; est difficile &#224; d&#233;finir. Nous consid&#233;rons ici comme mots les unit&#233;s r&#233;sultant d'une
segmentation du texte, &#233;tant donn&#233; un algorithme de segmentation clairement d&#233;fini. Dans les exemples
pr&#233;sent&#233;s ici, tous les caract&#232;res d&#8217;espacement et de ponctuation sont consid&#233;r&#233;s comme s&#233;parateurs de mots.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mesurer la couverture d&#8217;une ressource terminologique
</p>
<p>&#8226; Le vocabulaire V du corpus est l'ensemble des vocables, i.e. l'ensemble des mots diff&#233;rents
du corpus. Les vocables sont des unit&#233;s monolexicales.
</p>
<p>&#8226; Le lexique L de la ressource est l'ensemble des lexies ou entr&#233;es lexicales de la ressource5,
qu'elles soient compos&#233;es de un ou plusieurs mots, sp&#233;cialis&#233;es ou non.
</p>
<p>Les vocables du corpus et les lexies &#233;tant de natures diff&#233;rentes, on ne peut pas comparer
directement le vocabulaire et le lexique. Pour &#233;tablir cette comparaison, nous consid&#233;rons la
&#171; partie utile &#187; de la ressource et sa &#171; d&#233;composition &#187;, ainsi que leurs compl&#233;mentaires, d&#233;finis
de la mani&#232;re suivante (fig. 1) :
</p>
<p>ESPACE DE LEXIES
</p>
<p>ESPACE DE VOCABLE
</p>
<p>ESPACE DE MOTS T
</p>
<p>PUD
</p>
<p>PU
</p>
<p>PR
</p>
<p>Abstraction : les mots sont des occurrences de vocables
</p>
<p>D&#233;composition des lexies par segmentation 
</p>
<p>Projection de la ressource sur le texte
</p>
<p>L = PU U PNU
</p>
<p>V = PR U PNR
</p>
<p>Figure 1 : Construction des ensembles de r&#233;f&#233;rence
</p>
<p>&#8226; La partie utile de la ressource PU est l'ensemble des lexies de la ressource qui apparaissent
dans le corpus. C'est un sous-ensemble de L.
</p>
<p>&#8226; La partie utile d&#233;compos&#233;e PUD est l'ensemble de tous les vocables des lexies de PU. Elle
est obtenue par d&#233;composition en vocables &#233;l&#233;mentaires des lexies de PU. En supposant que
cette d&#233;composition est faite selon les m&#234;mes r&#232;gles qui ont permis de segmenter le corpus,
cet ensemble de vocables PUD correspond aussi &#224; la partie du vocabulaire du corpus qui est
reconnue (PR) par la ressource. On a donc PUD=PR, o&#249; PR est un sous-ensemble de V.
</p>
<p>&#8226; La partie inutile de la ressource PNU est l'ensemble des lexies qui n'ont pas d'occurrence
dans le corpus. C'est le compl&#233;mentaire de PU par rapport &#224; L.
</p>
<p>&#8226; La partie inconnue du vocabulaire du corpus PNR est l'ensemble des vocables de V non
reconnus par la ressource. C'est le compl&#233;mentaire de PN par rapport &#224; V.
</p>
<p>3.2 Mesures
Les m&#233;triques que nous proposons pour appr&#233;cier l'ad&#233;quation d'une ressource terminologique &#224;
un corpus sont d&#233;finies comme des rapports entre les diff&#233;rents ensembles d&#233;finis ci-dessus. On
peut distinguer les mesures qui portent sur les formes et celles qui portent sur les occurrences.
</p>
<p>La premi&#232;re mesure permet d'appr&#233;cier le degr&#233; de sp&#233;cialit&#233; de la ressource par rapport &#224; un
corpus. La contribution (Contr) est la proportion de lexies du lexique qui figurent en corpus.
Elle est d&#233;finie par la formule ci-dessous. Nous d&#233;signons par surplus (Surpl) la proportion de
lexies &#171; inutiles &#187;. On retrouve ici la notion d'exc&#232;s de ressource introduite par (Brewster et al.,
2004). La contribution est forte si beaucoup des lexies de la ressource se retrouvent en corpus et
donc si le domaine de sp&#233;cialit&#233; de la ressource correspond bien &#224; celui du corpus. &#192; l'inverse,
                                               
</p>
<p>5 Comme nous l'avons soulign&#233; plus haut, nous ne consid&#233;rons pas &#224; ce stade les autres informations
s&#233;mantiques apport&#233;es par la ressource.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ninova G., Nazarenko A., Hamon T. et Szulman S.
</p>
<p>un surplus &#233;lev&#233; indique que la ressource est relativement g&#233;n&#233;rique et donc potentiellement utile
pour des corpus vari&#233;s. Ces mesures &#233;tant ind&#233;pendantes de la taille de la ressource, on peut
comparer les contributions de ressources tr&#232;s diff&#233;rentes.
</p>
<p>Contr = |PU| / |L|  Surpl = 1 &#8211; Contr = |PNU| / |L| o&#249; |X| repr&#233;sente le cardinal de X
</p>
<p>Une autre mesure permet d'appr&#233;cier dans quelle mesure la ressource &#171; couvre &#187; le vocabulaire
du corpus. Pour avoir des ensembles comparables, il faut comparer la partie reconnue du
vocabulaire et le vocabulaire dans son ensemble. Les deux mesures duales de la reconnaissance
(Rec) et de l'ignorance (Ign) sont d&#233;finies ci-dessous. La reconnaissance est la proportion des
lexies d&#233;compos&#233;es reconnues en corpus par rapport au nombre total de vocables du corpus. La
reconnaissance augmente 1) si on trouve dans le lexique les termes sp&#233;cialis&#233;s employ&#233;s dans le
corpus mais aussi 2) quand la ressource comporte beaucoup de mots de la langue g&#233;n&#233;rale
comme par exemple les mots grammaticaux. Seule la confrontation des diff&#233;rentes mesures
permet de se faire une id&#233;e plus pr&#233;cise du comportement d'une ressource. Dans le cas 2, la forte
reconnaissance tend &#224; &#234;tre associ&#233;e &#224; un surplus important. Une forte reconnaissance combin&#233;e
&#224; une contribution &#233;lev&#233;e indique une ressource sp&#233;cifique bien adapt&#233;e au corpus consid&#233;r&#233;.
</p>
<p>Re c = |PR| / |V| = |PUD| / |V|  Ign = 1 &#8211; Re c = |PNR| / |V|
</p>
<p>Parler de &#171; couverture &#187; &#233;voque l'id&#233;e d'un corpus tout ou partiellement &#171; couvert &#187; par la
ressource. La couverture est donc calcul&#233;e relativement au corpus plut&#244;t qu'&#224; son vocabulaire.
Nous d&#233;finissons la couverture (Couv) comme la proportion d'occurrences de mots
correspondant &#224; des vocables entrant dans les lexies de la partie utile de la ressource. Dans la
formule ci-dessous, freqi repr&#233;sente le nombre d&#8217;occurrences d&#8217;une lexie i de PU non incluses
dans une occurrence d&#8217;une autre lexie plus large et longueuri  est la longueur de la lexie en
nombre de mots. Dans le cas de termes ench&#226;ss&#233;s (p. ex. syst&#232;me et syst&#232;me de fichiers), seule
l&#8217;occurrence du terme le plus large entre dans la mesure de fr&#233;quence. Cette mesure de
couverture est ind&#233;pendante de la taille du corpus, ce qui rend les mesures de couverture d'une
ressource comparables m&#234;me sur des corpus de taille diff&#233;rente.
</p>
<p>La derni&#232;re mesure compl&#232;te la mesure de couverture. C'est la densit&#233; (Dens), d&#233;finie par la
formule ci-dessous, o&#249; fPUD est la fr&#233;quence moyenne des lexies de PU dans le corpus et fV est la
fr&#233;quence moyenne des vocables dans le corpus. C'est une mesure normalis&#233;e de la fr&#233;quence
des lexies utiles en corpus. Pour avoir une mesure ind&#233;pendante de la taille du corpus, la
fr&#233;quence moyenne des lexies de PU est pond&#233;r&#233;e par la fr&#233;quence moyenne des vocables dans
le corpus.
</p>
<p>&#8364; 
</p>
<p>Couv =
i=1
</p>
<p>PU&#8721; freqi x longeuri / |T| Dens=fPUD/fV
</p>
<p>3.3 Exemple
&#192; titre d&#8217;exemple, consid&#233;rons la ressource et le texte suivants :
</p>
<p>&#8226; L={syst&#232;me, syst&#232;me de fichiers}
</p>
<p>&#8226; T=&#171; Il a r&#233;par&#233; le syst&#232;me de fichiers &#187;
</p>
<p>On a |L|=2 et |T|=7. Dans ce cas particulier, on a |V|=|T|=7. Toutes les unit&#233;s du lexique se
retrouvant en corpus, on a par ailleurs PU=L et PUD=PR={syst&#232;me, de, fichiers}.
</p>
<p>On obtient donc les mesures suivantes : Contr=1, Rec=3/7, Couv=3/7. Notons que l&#8217;occurrence
de la lexie syst&#232;me qui entre dans l&#8217;occurrence plus large de la lexie syst&#232;me de fichier n&#8217;est pas
comptabilis&#233;e en tant que telle dans la couverture.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mesurer la couverture d&#8217;une ressource terminologique
</p>
<p>4 R&#233;sultats
4.1 Protocole exp&#233;rimental
Nous avons test&#233; ces m&#233;triques dans le cadre de projets de recherche et d&#8217;extraction
d'information dans le domaine de la g&#233;nomique. Ce type d'application sp&#233;cialis&#233;e requiert en
effet d'exploiter des ressources et le choix de/des ressource(s) &#224; exploiter s'av&#232;re souvent d&#233;licat.
Nous avons consid&#233;r&#233; diff&#233;rents corpus de g&#233;nomique et diff&#233;rentes ressources terminologiques
a priori assez bien adapt&#233;es au domaine d'application (Hamon, 2005). &#192; des fins d'&#233;valuation,
nous avons compl&#233;t&#233; ces donn&#233;es exp&#233;rimentales par un autre corpus qui porte sur les plantes
carnivores et qui rel&#232;ve d'un domaine un peu diff&#233;rent. Il faudra &#233;largir cette exp&#233;rimentation en
prenant en compte un autre corpus ext&#233;rieur au champ de la biologie et une ressource dite de
&#171; langue g&#233;n&#233;rale &#187;.
</p>
<p>Nous avons travaill&#233; sur quatre corpus, tous du domaine de la biologie, mais diff&#233;rant les uns
des autres par leur style et leurs caract&#233;ristiques lexicographiques (tableau 1). Le premier corpus
(Transcript) est constitu&#233; de 2 209 r&#233;sum&#233;s d'articles scientifiques issus de la base Medline6 &#224;
partir de la requ&#234;te &#171; Bacillus subtilis transcription &#187;. Le second corpus (Transcript-932 ou
932) a &#233;t&#233; construit &#224; partir du premier, en s&#233;lectionnant 932 phrases dans lesquelles
apparaissent deux noms de g&#232;nes. Le troisi&#232;me corpus (Drosophile-1199 ou 1199-droso)
(Pillet, 2000) est similaire au second. Il s'agit de 1 199 phrases extraites des r&#233;sum&#233;s de
Flybase7, qui contiennent deux noms de g&#232;nes. Le quatri&#232;me corpus regroupe diff&#233;rents
documents issus du web se rapportant aux plantes carnivores (Carnivore).
</p>
<p>Vocabulaire V Taille T Fr&#233;quence moyenne
Transcript 18 720 405 423 21,66
Transcript-932 3 305 29 848 9,03
Drosophile-1199 3 232 22 691 7,02
Carnivore 27 201 273 605 10,06
</p>
<p>Le tableau 1. Caract&#233;ristiques lexicographiques des corpus
</p>
<p>Pour &#233;tudier la couverture des ressources terminologiques, nous avons s&#233;lectionn&#233; cinq
ressources sp&#233;cialis&#233;es publiquement disponibles8 : 1) les mots cl&#233;s SwissProt (keywlist)
utilis&#233;s pour indexer la base de s&#233;quen&#231;age des prot&#233;ines, 2) Gene Ontology (GO) qui porte sur
les diff&#233;rents types d'organismes vivants, 3) le MeSH qui est d&#233;di&#233; &#224; l'indexation de la base de
donn&#233;es Medline et rassemble des termes tr&#232;s divers utilis&#233;s dans le domaine m&#233;dical. Nous
avons &#233;galement retenu deux glossaires proposant une grande vari&#233;t&#233; de termes : 4) le glossaire
de biochimie et de biologie mol&#233;culaire (GlossBioch) qui comporte des termes courants et 5) le
glossaire de terminologie de biologie mol&#233;culaire (GoMBT).
</p>
<p>                                                
</p>
<p>6 www.ncbi.nlm.nih.gov
</p>
<p>7 Flybase est une base de donn&#233;es structur&#233;es et bibliographiques sur la drosophile :
http://flybase.bio.indiana.edu/
</p>
<p>8 Ces ressources sont disponibles aux adresses suivantes :
keylist : ftp://ftp.expasy.org/databases/swiss-prot/release/keywlist.txt
GO : http://www.geneontology.org/, version t&#233;l&#233;charg&#233;e en septembre 2002
MeSH : http://www.nlm.nih.gov/mesh/meshhome.html (Medical subject headings, Library of Medicine)
GlossBioch : http://www.portlandpress.com/pcs/books/prod_det.dfm?product=1855780887
GoMBT : http://www.asheducationbook.org/cgi/content/full/2002/1/490</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ninova G., Nazarenko A., Hamon T. et Szulman S.
</p>
<p>Ressources MeSH GO keywlist GlossBioch GoBMT
Taille en nombre de lexies 89 949 16 736 2934 836 263
</p>
<p>Tableau 2. Tailles compar&#233;es des diff&#233;rentes ressources
</p>
<p>4.2 Analyse des r&#233;sultats
Les calculs des diff&#233;rentes m&#233;triques pour les 5 ressources et les 4 corpus ci-dessus sont
synth&#233;tis&#233;s dans les graphiques des figures 2 et 3.
</p>
<p>Couverture du corpus par des ressources
</p>
<p>0
</p>
<p>0.02
</p>
<p>0.04
</p>
<p>0.06
</p>
<p>0.08
</p>
<p>0.1
</p>
<p>0.12
</p>
<p>0.14
</p>
<p>0.16
</p>
<p>0.18
</p>
<p>Transcript 1199-droso 932- Carnivores
</p>
<p>GlossBIoch
GO
GoBMT
keywlist
MeSH
</p>
<p> 
</p>
<p>Densit&#233; des ressources
</p>
<p>0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>5
</p>
<p>6
</p>
<p>7
</p>
<p>8
</p>
<p>9
</p>
<p>10
</p>
<p>Transcript 1199-droso 932- Carnivores
</p>
<p>GlossBIoch
GO
GoBMT
keywlist
MeSH
</p>
<p>Figure 2. Mesures d'ad&#233;quation de diff&#233;rentes ressources &#224; diff&#233;rents corpus :
couverture  et densit&#233;
</p>
<p>Les mesures gomment l'effet de taille aussi bien sur les corpus que sur les ressources. Le
glossaire GlossBioch a une couverture similaire &#224; celle de MeSH qui comporte pourtant 50 fois
plus de termes (fig. 2). Le comportement des ressources est comparable pour le corpus
Transcript et son sous-corpus Transcript-932 (fig. 3). On peut donc envisager de s&#233;lectionner
une ressource &#224; partir d'un sous-corpus sans chercher &#224; projeter la ressource sur l'int&#233;gralit&#233; du
corpus, ce qui facilite les exp&#233;rimentations.
</p>
<p>La contribution fait exception cependant. Elle est &#224; la fois sensible &#224; la taille de la ressource et &#224;
celle du corpus&#160;: on remarque qu&#8217;elle est moindre pour un petit corpus (GloBioch pour
transcript-932) et pour les ressources volumineuses (MESH pour Transcript). Malgr&#233; cette
sensibilit&#233; aux effets de taille, c&#8217;est une mesure int&#233;ressante : une forte contribution pour une
petite ressource est un bon indicateur de pertinence (cf. GoBMT et keywlist pour Transcript).
</p>
<p>La troisi&#232;me remarque concerne les deux mesures de reconnaissance et de couverture qui
paraissent assez bien corr&#233;l&#233;es. On note une grande stabilit&#233; dans le sens et l'ampleur de leur
&#233;cart : un corpus est d&#8217;autant mieux couvert que son vocabulaire est reconnu. C&#8217;est donc
l&#8217;absence de corr&#233;lation qui est significative. Nos exp&#233;riences montrent par exemple que le
glossaire GlossBioch a une couverture nettement sup&#233;rieure &#224; celle de GO sur Transcript, pour
une reconnaissance similaire. C&#8217;est le signe que GlossBioch refl&#232;te mieux la langue de sp&#233;cialit&#233;
du corpus Transcript, en d&#233;pit de sa taille modeste (fig. 3), et la preuve que la taille des
ressources n&#8217;est pas un crit&#232;re suffisant. Dans ce cas particulier, les mesures font appara&#238;tre un
comportement des ressources contraire aux intuitions initiales des biologistes qui
recommandaient &#224; tort d&#8217;utiliser GO.
</p>
<p>Le dernier point porte sur la densit&#233;. Elle permet d'appr&#233;cier la fr&#233;quence des lexies en corpus.
De mani&#232;re surprenante, la plus forte densit&#233; s'observe pour une petite ressource tr&#232;s sp&#233;cialis&#233;e
(glossaire GoBMT, fig. 2) et pour le corpus le plus diff&#233;rent th&#233;matiquement (Carnivore). Seule
l'analyse d&#233;taill&#233;e des lexies de la partie utile du glossaire permet de comprendre ce r&#233;sultat
contre-intuitif. Moins de 10% des lexies figurent dans le corpus mais ces lexies ont de fortes
fr&#233;quences. On trouve notamment can (676 occ.), fish (121 occ.) tel (8 occ), tous les trois d&#233;crits
dans la ressource comme des noms de g&#232;nes. Ce sont des mots ambigus reconnus &#224; tort comme</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mesurer la couverture d&#8217;une ressource terminologique
</p>
<p>noms de g&#232;nes dans le corpus Carnivore. Une forte densit&#233; peut ainsi aussi bien refl&#233;ter une
bonne ad&#233;quation de la ressource en termes de sp&#233;cialisation que des ph&#233;nom&#232;nes d'ambigu&#239;t&#233;.
Une simple mesure de fr&#233;quence pond&#233;r&#233;e n&#8217;appara&#238;t donc pas suffisamment &#233;clairante. Il
faudrait sans doute consid&#233;rer le profil lexical des lexies de la partie utile de la ressource par
rapport &#224; l'ensemble des vocables du corpus pour pouvoir pr&#233;dire la nature s&#233;mantique de la
couverture. Ce profil devrait permettre d'appr&#233;cier la dispersion des fr&#233;quences et donc de mieux
rep&#233;rer des correspondances artificielles entre certains termes sp&#233;cialis&#233;s et des occurrences de
mots courants.
</p>
<p>Transcript
</p>
<p>0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
</p>
<p>0.25
</p>
<p>0.3
</p>
<p>0.35
</p>
<p>GlossBIoch GO GoBMT keywlist MeSH
</p>
<p>Contribution
Couverture
Reconnaissance
</p>
<p> 
</p>
<p>932
</p>
<p>0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
</p>
<p>0.25
</p>
<p>0.3
</p>
<p>0.35
</p>
<p>GlossBIoch GO GoBMT keywlist MeSH
</p>
<p>Contribution
Couverture
Reconnaissance
</p>
<p>1199 - droso
</p>
<p>0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
</p>
<p>0.25
</p>
<p>0.3
</p>
<p>0.35
</p>
<p>GlossBIoch GO GoBMT keywlist MeSH
</p>
<p>Contribution
Couverture
Reconnaissance
</p>
<p> 
</p>
<p>Carnivores
</p>
<p>0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
</p>
<p>0.25
</p>
<p>0.3
</p>
<p>0.35
</p>
<p>GlossBioch GO GoBMT keywlist MeSH
</p>
<p>Contribution
Couverture
Reconnaissance
</p>
<p>Figure 3. Mesures de contribution, couverture et reconnaissance de 5 ressources sur 4 corpus :
Transcript, Transcript-932 (932), Drosophile (1199-droso) et Carnivore
</p>
<p>5 Conclusion et perspectives
Pour permettre de caract&#233;riser avec une certaine fiabilit&#233; et une certaine reproductibilit&#233; le
comportement d'une ressource lexicale pour un corpus donn&#233;, nous avons d&#233;fini et test&#233; un
ensemble de m&#233;triques qui donne une id&#233;e de la &#171; couverture &#187;, notion vague mais tr&#232;s
couramment utilis&#233;e qui prend de l'importance avec l'augmentation du nombre de ressources
disponibles. Ces m&#233;triques ne peuvent pr&#233;tendre suppl&#233;er une analyse pr&#233;cise de l&#8217;apport d&#8217;une
ressource : elles visent &#224; &#233;clairer le choix des ressources et des traitements &#224; mettre en &#339;uvre.
Les exp&#233;riences que nous avons men&#233;es montrent l'int&#233;r&#234;t de ce type de m&#233;triques mais nous
avons &#233;galement  soulign&#233; les limites des mesures propos&#233;es. Il faudrait d&#233;finir une mesure de
densit&#233; plus riche que nous ne l'avons fait et, pour compl&#233;ter l'image globale de couverture que
nous cherchons &#224; construire, tenir compte de la r&#233;partition des occurrences des lexies de la
ressource. La notion de couverture lexicale telle qu&#8217;elle est d&#233;finie ici doit par ailleurs &#234;tre
&#233;tendue pour prendre en compte les variantes de lexies, leurs types s&#233;mantiques et m&#234;me leurs
relations s&#233;mantiques.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ninova G., Nazarenko A., Hamon T. et Szulman S.
</p>
<p>R&#233;f&#233;rences
BUITELAAR P., EIGNER T., DECLERCK T. (2004), OntoSelect: A Dynamic Ontology Library with
Support for Ontology Selection, In Proc. of the Demo Session at the Int. Semantic Web Conf.,
Hiroshima, Japan, Nov. 2004.
</p>
<p>BREWSTER, C., Alani, H., DASMAHAPATRA, S. and WILKS, Y. (2004), Data Driven Ontology
Evaluation. In Proc. Of the Int. Conf. on Language Resources and Evaluation (LREC 2004),
Lisbon, Portugal.
</p>
<p>BASILI R., PAZIENZA M.T., STVENSON M., VELARDI P., VINDIGNI M., WILKS Y. (1998), An
Empirical Approach to lexical Tuning, In Proc. of the Workshop on Adaptating Lexical and
Corpus Ressources to Sublanguages and Applications (First Int. Conf. on Language
Resources and Evaluation LREC 1998), P. VELARDI (ed.), May, Grenada.
</p>
<p>CHARLET J., BACHIMONT  B., BOUAUD J., ZWEIGENBAUM P. (1996), Ontologie et r&#233;utilisabilit&#233; :
exp&#233;rience et discussion, in Acquisition et Ing&#233;nierie des Connaissance, N. Aussenac , P.
Laublet and C. Reynaud (&#233;d.), pp. 69-87, C&#233;padu&#232;s-Editions, Toulouse.
</p>
<p>HAMON H. (2005), Indexing specialized documents : are terminological resources sufficient ?, in
Actes des 6&#232;mes journ&#233;es Terminologie et Intelligence Artificielle (TIA 2005), pp. 71-82, Rouen.
</p>
<p>HOVY E. (2001), Comparing sets of semantic relations in ontologies. In Semantics of
Relationships, R. GREEN, C.A. BEAN and S.H. MYAENG (eds.), chapter 6, Kluwer , Dordrecht,
NL.
</p>
<p>PILLET V. (2000), M&#233;thodologie d'extraction automatique d'information &#224; partir de la
litt&#233;rature en science en vue d'alimenter un nouveau syst&#232;me d'information. Application &#224; la
g&#233;n&#233;tique mol&#233;culaire pour l'extraction de donn&#233;es sur les interactions. Th&#232;se doctorat, Aix-
Marseille III.
</p>
<p>MANNING C., SCH&#220;TZE H. (1999). Foundations of Statistical Natural Language Processing, The
MIT Press.
</p>
<p>MULLER C. (1977), Principes et m&#233;thodes de statistique lexicale, Hachette Universit&#233;, Paris.
</p>
<p>NAZARENKO A. (2005). Sur quelle s&#233;mantique reposent les m&#233;thodes automatiquesd&#8217;acc&#232;s au
contenu textuel ? S&#233;mantique et corpus, A. CONDAMINES (coord.), ch. 6, pp. 211-244,
Herm&#232;s/Lavoisier.
</p>
<p>NEDELLEC C., NAZARENKO A. (2005), Ontology and Information Extraction : a necessary
symbiosis, in Ontology Learning and Population, P. Buitelaar, P. Cimiano, B. Magnini (eds),
IOS (to appear).
</p>
<p>NIRENBURG S., MAHESH K. and BEALE S. (1996), Measuring semantic coverage, in Proc. of the
16th Conf. on Computational Linguistics (COLING&#8217;96), Copenhagen Denmark, ACL, pp. 83-
88.</p>

</div></div>
</body></html>