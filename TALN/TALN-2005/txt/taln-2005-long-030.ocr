TALN 2005, Dourdan, 6-10 juin 2005

Comment mesurer la couverture d'une ressource terminologique
pour un corpus ?

Goritsa Ninova (1), Adeline Nazarenko (2),
Thierry Hamon (2), Sylvie Szulman (2)

LIPN UMR 7030
Université Paris 13 & CNRS
99, av. J .—B. Clément
93430 Villetaneuse
(1) cylvago@yahoo.fr
(2){prénom.nom}@lipn.univ—paris13.fr

Mots-clés 2 couverture lexicale, terrninologie, statistique lexicale
Keywords 2 lexical coverage, terminology, lexical statistics

Résumé Cet article propose une définition forrnelle de la notion de couverture lexicale. Celle—
ci repose sur un ensemble de quatre métriques qui donnent une vue globale de l'adéquation d'une
ressource lexicale a un corpus et perrnettent ainsi de guider le choix d'une ressource en fonction
d'un corpus donné. Les métriques proposées sont testées dans le contexte de l'analyse de corpus
spécialisés en génomique : 5 terminologies différentes sont confrontées a 4 corpus. la
combinaison des valeurs obtenues permet de discerner différents types de relations entre
ressources et corpus.

Abstract This paper proposes a formal definition of the notion of lexical coverage. This
definition is based on four metrics that give a global view over a lexical resource to corpus
relationship, thus helping the choice of a relevant resource with respect to a given corpus. These
metrics have been experimented in the context of specialised corpus analysis in genomics. 5
terminologies have been confronted to 4 different corpora. The combination of resulting figures
reﬂects various types of corpus vs . resource relationships.

1 Introduction

On parle couramment de << couverture lexicale >> sans définir clairement ce qu’on entend par la.
Différents auteurs mettent sous ce terrne différentes notions et mesures. Le probleme est d'autant
plus complexe que les ressources utilisées comportent souvent des expressions polylexicales
dont la projection en corpus peut se faire de différentes manieres. Le présent article propose de
définir un ensemble de métriques pour cemer cette notion de couverture dans le cas général
d'une ressource constituée d'une liste de terrnes mono— et polylexicaux. Ces mesures sont testées

Ninova G., Nazarenko A., Hamon T. et Szulman S.

pour différents couples ressource/corpus. Les premiers résultats obtenus sont encourageants. Ils
montrent qu'on peut en effet documenter le comportement d'une ressource pour un corpus
donné en préalable a tout traitement, et ainsi guider le choix de la ressource.

Apres avoir souligné les enjeux de cette problématique et les questions qu’elle souleve (section
2), nous présentons dans la section 3 un ensemble de métriques. Celles—ci sont exploitées dans
la perspective du traitement automatique de corpus de génomique. Les résultats de ces
experiences sont présentés et discutés dans la section 4 de cet article.

2 Problématique

2.1 Enjeux

Le traitement de corpus spécialisé fait appel a des ressources sémantiques qu'on appelle
généralement spécialisées parce qu'elles décrivent un domaine particulier d'activité. Ces
ressources peuvent étre de différents types selon les traitements envisages, mais elles doivent
comporter une dimension lexicale des lors qu'elles sont destinées a l'analyse et l'interprétation de
données textuelles.

Les ontologies du web sémantique doivent ainsi étre ancrées lexicalement (avec des items
lexicaux associés aux noeuds de l'ontologie) si elles doivent servir a indexer des textes. Les
techniques d'acces au contenu des documents textuels sont diverses (extraction d'inforrnation,
question—réponse, outils de navigation ou de résumé) mais elles reposent toutes sur une analyse
sémantique partielle des documents, qui implique la reconnaissance de certains éléments du
discours (entités nommées et termes du domaine, notamment), leur typage sémantique et leur
mise en relation (Nazarenko, 2005). De ce fait, ces techniques reposent également sur des
lexiques, terminologies ou thesaurus spécialisés pour identifier le vocabulaire de spécialité. Les
categories sémantiques et les relations lexicales sont utilisées (quand elles existent) pour
désambigu'1'ser les textes et en guider l'interprétation.

Des lors que les applications de traitement automatique des langues (TAL), y compris au niveau
sémantique, sont de plus en plus guidées par le lexique, la question du choix des ressources a
exploiter prend de l’importance. La situation releve souvent a la fois de la pléthore et de la
pénurie. D'un cote, il existe de nombreuses ressources terminologiques, surtout dans des
domaines comme la biologie ou la médecine ou l'effort d'organisation des connaissances est
ancienl. Mais d'un autre cote, les << bonnes ressources >> sont rares : le degré de specialisation ou
le point de vue représenté par la ressource est généralement different de celui du texte que l'on
cherche a analyser. Ce constat a été fait par (Charlet et al., 1996), touj ours dans le domaine de la
médecine pourtant reconnu pour la richesse de ses bases de connaissances. Dans la pratique,
comme on ne peut ni se passer de ressource, ni en reconstruire de nouvelles pour chaque
nouvelle application, on fait souvent avec ce qu'on a. Dans certains cas, on peut spécialiser la
ressource et l'adapter en fonction du domaine et de la tache visés (problématique de l'adaptation
lexicale ou << lexical tuning >> (Basili et al., 1998)) mais cela suppose néanmoins une ressource
initiale.

Une question se pose alors : parmi l'ensemble des ressources qui paraissent recouvrir en partie
et a priori le domaine du corpus a traiter, laquelle ou lesquelles choisir et sur quels criteres ?
Cette question est d'autant plus importante qu'on doit souvent limiter le nombre de ces
ressources pour réduire l'inévitable travail de preparation des données et pour éviter les
problemes d'incohérence. Il est en général trop coﬁteux d’exploiter en parallele différentes
ressources pour les tester en les comparant au regard de l’application visée. Les experts du
domaine ne sont pas toujours d'un grand secours non plus. Meme s'ils sont capables de décrire

1 Voir par exemple, UMLS (Unified Medical Language System, http://www.nlm.nih.gov/research/umls/).

Mesurer la couverture d ’1me ressource terminologique

le sous—domaine couvert par une ressource et le point de Vue qui y est represente, ils sont
d’ordinaire peu a meme de mesurer son adequation proprement lexicale.

Ce probleme du choix des ressources est souvent resolu de maniere tres empirique, ce qui ne
perrnet pas de capitaliser d'une experience a l’autre. Il est donc important de se doter de criteres
formels permettant de decrire le comportement d'une ressource par rapport a un corpus donne et
d’en guider le choix. C'est l'objet de ce travail : nous proposons un premier ensemble de
metriques pour apprecier la couverture d'un corpus par une ressource terminologique.

2.2 Difficultés

Pour des dictionnaires traditionnels, on exprime l'adequation a un corpus en termes de
couverture et on l'apprecie a partir du nombre d'occurrences de mots du corpus qui se rattachent
a des entrees du dictionnaire. La couverture est plus difficile a definir pour des ressources
terrninologiques.

La premiere difficulte tient a la diversite des ressources terrninologiques qui rend problematique
leur comparaison. La nature de l’information differe d’une ressource a l’autre. Au—dela des
listes de termes, les termes euX—memes peuvent etre types et les types peuvent etre organises en
hierarchie (thesaurus). Dans les ressources les plus riches, les termes sont de surcroit lies entre
eux par des liens semantiques. Les ressources ont par ailleurs des degrés de spécialisation
divers. Il est difficile de comparer un lexique de 10 000 unites qui comporterait de nombreuses
unites egalement presentes dans des dictionnaires generalistes et un lexique de 500 unites dont
tres peu figurent dans des dictionnaires classiques. Les ressources s'opposent enfin par leur
degré de lexicalisationz certaines se contentent de lister des etiquettes de concepts ; d'autres
considerent ces etiquettes dans leur dimension lexicale et linguistique. Ces dernieres rendent
compte des differentes formes sous lesquelles ces unites semantiques peuvent se realiser en
corpus, jusqu’a associer des regles de desambigu'1'sation contextuelles aux unites polysemiques
(Nedellec, Nazarenko, 2005).

La deuxieme difficulte tient au fait qu'on cherche a confronter deux objets qui ne sont pas de
meme nature. La ressource et le corpus s'opposent comme la langue s'oppose au discours : il
faut comparer un ensemble d'elements de lexique (la ressource) avec un ensemble d'occurrences
(le corpus). Par Voie de consequence, il faut aussi comparer des unites potentiellement
polylexicales avec des occurrences observees en corpus, necessairement monolexicales. Comme
il s’agit d’apprecier a priori l’adequation des ressources aux corpus, nous ne presupposons en
effet aucune etape de reconnaissance terminologique prealable.

Dans ce premier travail, nous focalisons l'etude sur les ressources terrninologiques considerees
comme des listes de termes, sans exploiter les eventuelles inforrnations qu'elles contiennent
concernant leurs regles de Variation, leur typage semantique ou les relations semantiques qu'ils
entretiennent. Les premiers elements etant poses, il est evidemment necessaire de poursuivre, par
exemple, en prenant en compte la desambigu'1'sation des termes polysemiques, les liens de
Variations entre termes et la structure semantique. Ces points ne sont pas abordes ici.

2.3 Etat de l'art

La question de la selection des ontologies pour une application prend de l'importance avec
l'augmentation du nombre des ontologies disponibles et la standardisation de leurs formats.
Cette preoccupation est au coeur de la problematique du web semantique. (Buitelaar et al., 2004)
montre que la creation d’une bibliotheque d'ontologies (OntoSelect) suppose de definir des
criteres permettant de selectionner une ontologie particuliere. Trois criteres sont proposes : les
degres de structuration et de connectivite sont des mesures proprement ontologiques, mais le
critere de couverture est etabli relativement a une collection de documents. Ce demier critere est

Ninova G., Nazarenko A., Hamon T. et Szulman S.

cependant défini de maniere assez frustez : il ne prend qu'imparfaitement en compte la
dimension proprement linguistique des << étiquettes de concepts >>.

Brewster et al. (2004) vont plus loin. Ils proposent d'évaluer les ontologies relativement a un
corpus donne. La notion de couverture qu'ils proposent est plus riche que la précédente. Elle
repose sur le nombre de terrnes en corpus qui correspondent a des concepts de l'ontologie, une
fois effectués un calcul de variation pour reconnaitre des formes de terrnes non canoniques et
une expansion sémantique pour autoriser une adéquation a différents niveaux de généralité. A
partir de la, une ontologie est évaluée en fonction du nombre de concepts qui trouvent leur
contrepartie en corpus. Ce deuxieme travail prend davantage en compte la nature linguistique des
réalisations lexicales des concepts en corpus (notion de variation, quasisynonymie entre un
hyperonyme et son hyponyme) mais il est centre sur l'évaluation et la cohérence interne d'une
ontologie alors que notre objectif est plutot de guider le choix d'une ressource pour un corpus
donne, ce qui confere un autre role a la notion de couverture et impose de la définir plus
précisément.

Sur le plan lexical, la question de la couverture n'a guere été étudiée3. De maniere intuitive, on
tend a préférer des ressources de grande taille (en nombre d'entrées), avec l'idée qu'elles sont soit
plus completes sur un domaine restreint soit plus génériques et moins liées a un domaine
particulier. (Nirenburg et al., 1996) critique ce présupposé en soulignant que la taille de la
ressource donne une vue tres partielle de sa couverture. Dans ce travail, les auteurs cherchent
cependant a apprécier la qualité intrinseque de la ressource alors que nous défendons l'idée
qu'une ressource n'a pas de valeur propre et qu’elle n'a de valeur que par les utilisations qui
peuvent en étre faites. Au total, la question du choix de la ressource étant donné un corpus a
moins retenu l'attention que la question ultérieure : une fois cette ressource choisie, comment
l'adapter a ce corpus (Basili et al., 1998) ?

La statistique lexicale a souligné depuis ses débuts (Muller, 1977 ; Manning, Schiitze, _1999)

qu'il existe une relation fonctionnelle entre une ressource (un vocabulaire) et un corpus mais elle
n'a pas abordé le probleme des unités polylexicales que contiennent les terminologies.

3 Proposition de métriques

Afin d'apprécier l'adéquation d'une ressource a un corpus, nous proposons différentes mesures.
Il s’agit de caractériser la couverture de la ressource ainsi que son degré de spécialisation.

3.1 Remarques terminologiques
Nous posons les definitions suivantes :

0 Le texte T du corpus est un ensemble ordonné de mots4. Les mots sont définis par leur
forme graphique et repérés par leur position dans le texte.

2 «Coverage is measured by the number of labels for classes and properties that can be matched in the
document».

3 La notion de couverture lexicale n’est pas définie dans les ouvrages de statistique linguistique (Oakes, 1998).
Quand la question est abordée (Manning, Schiitze, 1999, p. 130), c’est uniquement pour apprécier le nombre
de mots inconnus dans un texte.

4 La notion de « mot » est difficile a définir. Nous considérons ici comme mots les unités résultant d'une
segmentation du texte, étant donné un algorithme de segmentation clairement défini. Dans les exemples
présentés ici, tous les caractéres d’espacement et de ponctuation sont considérés comme séparateurs de mots.

Mesurer la couverture d ’1me ressource terminologique

0 Le vocabulaire V du corpus est l'ensemble des Vocables, i.e. l'ensemble des mots différents
du corpus. Les Vocables sont des unites monolexicales.

0 Le lexique L de la ressource est l'ensemble des lexies ou entrées lexicales de la ressource5,
qu'elles soient composées de un ou plusieurs mots, spécialisées ou non.

Les Vocables du corpus et les lexies étant de natures différentes, on ne peut pas comparer
directement le Vocabulaire et le lexique. Pour établir cette comparaison, nous considérons la
« partie utile >> de la ressource et sa << décomposition », ainsi que leurs complémentaires, définis
de la maniere suivante (fig. 1) :

ESPACE DE LEXIES

   

ESPACE DE MOTS

ESPACE DE VOCABLE

Figure 1 : Construction des ensembles de reference

0 La partie utile de la ressource PU est l'ensemble des lexies de la ressource qui apparaissent
dans le corpus. C'est un sous—ensemble de L.

0 La partie utile décomposée PUD est l'ensemble de tous les Vocables des lexies de PU. Elle
est obtenue par décomposition en Vocables élémentaires des lexies de PU. En supposant que
cette décomposition est faite selon les memes regles qui ont permis de segmenter le corpus,
cet ensemble de Vocables PUD correspond aussi a la partie du Vocabulaire du corpus qui est
reconnue (PR) par la ressource. On a donc PUD=PR, ou PR est un sous—ensemble de V.

0 La partie inutile de la ressource PNU est l'ensemble des lexies qui n'ont pas d'occurrence
dans le corpus. C'est le complémentaire de PU par rapport a L.

0 La partie inconnue du Vocabulaire du corpus PNR est l'ensemble des Vocables de V non
reconnus par la ressource. C'est le complémentaire de PN par rapport a V.

3.2 Mesures

Les métriques que nous proposons pour apprécier l'adéquation d'une ressource terminologique a
un corpus sont définies comme des rapports entre les différents ensembles définis ci—dessus. On
peut distinguer les mesures qui portent sur les formes et celles qui portent sur les occurrences.

La premiere mesure permet d'apprécier le degré de spécialité de la ressource par rapport a un
corpus. La contribution (Contr) est la proportion de lexies du lexique qui figurent en corpus.
Elle est définie par la formule ci—dessous. Nous désignons par surplus (Surpl) la proportion de
lexies << inutiles >>. On retrouve ici la notion d'exces de ressource introduite par (Brewster et al.,
2004). La contribution est forte si beaucoup des lexies de la ressource se retrouvent en corpus et

\

donc si le domaine de spécialité de la ressource correspond bien a celui du corpus. A l'inVerse,

5 Comme nous l'avons souligné plus haut, nous ne considérons pas a ce stade les autres informations
sémantiques apportées par la ressource.

Ninova G., Nazarenko A., Hamon T. et Szulman S.

un surplus élevé indique que la ressource est relativement générique et donc potentiellement utile
pour des corpus Variés. Ces mesures étant indépendantes de la taille de la ressource, on peut
comparer les contributions de ressources tres différentes.

Contr = |PU| / |L| Surpl = I — Contr = |PNU| / |L| ou IX] représente le cardinal deX

Une autre mesure perrnet d'apprécier dans quelle mesure la ressource << couvre >> le Vocabulaire
du corpus. Pour avoir des ensembles comparables, il faut comparer la partie reconnue du
Vocabulaire et le Vocabulaire dans son ensemble. Les deux mesures duales de la reconnaissance
(Rec) et de l'ign0rance (Ign) sont définies ci—dessous. La reconnaissance est la proportion des
lexies décomposées reconnues en corpus par rapport au nombre total de Vocables du corpus. la
reconnaissance augmente 1) si on trouve dans le lexique les termes spécialisés employés dans le
corpus mais aussi 2) quand la ressource comporte beaucoup de mots de la langue générale
comme par exemple les mots grammaticaux. Seule la confrontation des différentes mesures
perrnet de se faire une idée plus précise du comportement d'une ressource. Dans le cas 2, la forte
reconnaissance tend a étre associée a un surplus important. Une forte reconnaissance combinée
a une contribution élevée indique une ressource spécifique bien adaptée au corpus considéré.

Rec=|PR|/|Vl =|PUD|/|V| Ign=1—Rec=|PNR|/|V|

Parler de << couverture >> évoque l'idée d'un corpus tout ou partiellement << couvert >> par la
ressource. La couverture est donc calculée relativement au corpus plutot qu'a son Vocabulaire.
Nous définissons la couverture (Couv) comme la proportion d'occurrences de mots
correspondant a des Vocables entrant dans les lexies de la partie utile de la ressource. Dans la
formule ci—dessous,freqt. représente le nombre d’occurrences d’une lexie i de PU non incluses
dans une occurrence d’une autre lexie plus large et longueurl. est la longueur de la lexie en
nombre de mots. Dans le cas de termes enchassés (p. ex. systéme et systéme de ﬁchiers), seule
l’occurrence du terme le plus large entre dans la mesure de fréquence. Cette mesure de
couverture est indépendante de la taille du corpus, ce qui rend les mesures de couverture d'une
ressource comparables meme sur des corpus de taille différente.

La derniere mesure complete la mesure de couverture. C'est la densité (Dens), définie par la
formule ci—dessous, oufm, est la fréquence moyenne des lexies de PU dans le corpus et fv est la
fréquence moyenne des Vocables dans le corpus. C'est une mesure normalisée de la fréquence
des lexies utiles en corpus. Pour avoir une mesure indépendante de la taille du corpus, la

fréquence moyenne des lexies de PU est pondérée par la fréquence moyenne des Vocables dans
le corpus.

PU
Couv = EH freqix l0ngeurl./ ITI Dens=fPUD/fv

3.3 Exemple

A titre d’exemple, considérons la ressource et le texte suivants :
° L={systéme, systéme de ﬁchiers}

° T:« 11 a réparé le systeme de fichiers >>

On a |L|=2 et |T| =7. Dans ce cas particulier, on a |V|=|T|=7. Toutes les unités du lexique se
retrouvant en corpus, on a par ailleurs PU=L et PUD=PR={systéme, de, ﬁchiers}.

On obtient donc les mesures suivantes : C0ntr=1, Rec=3/7, C0uv=3/7. Notons que l’occurrence
de la lexie systéme qui entre dans l’occurrence plus large de la lexie systéme de ﬁchier n’est pas
comptabilisée en tar1t que telle dans la couverture.

Mesurer la couverture d’une ressource terminologique

4 Résultats

4.1 Protocole expérimental

Nous avons teste ces metriques dans le cadre de projets de recherche et d’extraction
d'inforrnation dans le domaine de la genomique. Ce type d'application specialisee requiert en
effet d'exploiter des ressources et le choix de/des ressource(s) a exploiter s'avere souvent delicat.
Nous avons considere differents corpus de genomique et differentes ressources terrninologiques
a priori assez bien adaptees au domaine d'application (Hamon, 2005). A des fins d'evaluation,
nous avons complete ces donnees experimentales par un autre corpus qui porte sur les plantes
carnivores et qui releve d'un domaine un peu different. 11 faudra elargir cette experimentation en
prenant en compte un autre corpus exterieur au champ de la biologie et une ressource dite de
« langue generale >>.

Nous avons travaille sur quatre corpus, tous du domaine de la biologie, mais differant les uns
des autres par leur style et leurs caracteristiques lexicographiques (tableau 1). Le premier corpus
(Transcript) est constitue de 2 209 resumes d'articles scientifiques issus de la base Medlineé a
partir de la requete « Bacillus subtilis transcription >>. Le second corpus (Transcript—932 ou
932) a ete construit a partir du premier, en selectionnant 932 phrases dans lesquelles
apparaissent deux noms de genes. Le troisieme corpus (Dr0s0phile—1199 ou 1199—dr0s0)
(Pillet, 2000) est similaire au second. 11 s'agit de 1 199 phrases extraites des resumes de
Flybase7, qui contiennent deux noms de genes. Le quatrieme corpus regroupe differents

documents issus du web se rapportant aux plantes carnivores (Carnivore).

e ce moyenne
Transcript 18 720 423 21,66
anscript— ,
oso —

Carnivore 27 201 273 605 10,06

Le tableau 1. Caracteristiques lexicographiques des corpus

 

Pour etudier la couverture des ressources terminologiques, nous avons selectionne cinq
ressources specialisees publiquement disponibless : 1) les mots cles SwissProt (keywlist)
utilises pour indexer la base de sequencage des proteines, 2) Gene Ontology (GO) qui porte sur
les differents types d'organismes vivants, 3) le MeSH qui est dedie a l'indexation de la base de
donnees Medline et rassemble des termes tres divers utilises dans le domaine medical. Nous
avons egalement retenu deux glossaires proposant une grande variete de termes : 4) le glossaire
de biochimie et de biologie moleculaire (GlossBioch) qui comporte des termes courants et 5) le
glossaire de terminologie de biologie moleculaire (GoMBT).

6 www.ncbi.nlm.nih.gov
7 Flybase est une base de donnees structurees et bibliographiques sur la drosophile
http://ﬂybase.bio.indiana.edu/

8 Ces ressources sont disponibles aux adresses suivantes :

keylist : ftp://ftp.expasy.org/databases/swiss—prot/release/keywlist.txt

GO : http://www.geneontology.org/, version telechargee en septembre 2002

MeSH : http://www.nlm.nih.gov/mesh/meshhome.html (Medical subject headings, Library of Medicine)
GlossBioch : http://www.portlandpress.com/pcs/books/prod_det.dfm?product: 1855780887

GoMBT : http://www.asheducationbook.org/cgi/content/full/2002/ 1/490

Ninova G., Nazarenko A., Hamon T. et Szulman S.

Ressources MeSH GO keywlist GlossBioch GoBMT
Taille en nombre delexies 89 949 16 736 2934 836 263

Tableau 2. Tailles comparées des différentes ressources

4.2 Analyse des résultats

Les calculs des différentes métriques pour les 5 ressources et les 4 corpus ci—dessus sont
synthétisés dans les graphiques des figures 2 et 3.

  
 
 
  

Couverture du corpus par des ressources Densité des ressources
0.18 10
0.1 6 D GlossBioch ‘ 9 D GlossBioch
GO
0_1 A - GO , 8 '
T E. GOBMT 7 u GOBMT
O_1 2‘ D keywlist D keywlist
0 1_ - MeSH 6 ' M65“
5
0.08—
4
0.06—
3
0.04- 2
0.02— 1
0 ’ 0

 

Transcript 1 199—droso 932- Carnivores Transcript ll99'dr0S0 932' C3miV0reS

Figure 2. Mesures d'adéquation de différentes ressources a différents corpus :
couverture et densité

Les mesures gomment l'effet de taille aussi bien sur les corpus que sur les ressources. he
glossaire GlossBioch a une couverture similaire a celle de MeSH qui comporte pourtant 50 fois
plus de termes (fig. 2). Le comportement des ressources est comparable pour le corpus
Transcript et son sous—corpus Transcript—932 (fig. 3). On peut donc envisager de sélectionner
une ressource a partir d'un sous—corpus sans chercher a projeter la ressource sur l'intégralité du
corpus, ce qui facilite les expérimentations.

La contribution fait exception cependant. Elle est a la fois sensible a la taille de la ressource et a
celle du corpus : on remarque qu’elle est moindre pour un petit corpus (GloBioch pour
transcript—932) et pour les ressources Volumineuses (MESH pour Transcript). Malgré cette
sensibilité aux effets de taille, c’est une mesure intéressante : une forte contribution pour une
petite ressource est un bon indicateur de pertinence (cf. GoBMT et keywlist pour Transcript).

La troisieme remarque concerne les deux mesures de reconnaissance et de couverture qui
paraissent assez bien corrélées. On note une grande stabilité dans le sens et l'ampleur de leur
écart : un corpus est d’autant mieux couvert que son Vocabulaire est reconnu. C’est donc
l’absence de correlation qui est significative. Nos experiences montrent par exemple que le
glossaire GlossBioch a une couverture nettement supérieure a celle de GO sur Transcript, pour
une reconnaissance similaire. C’est le signe que GlossBioch reﬂete mieux la langue de spécialite
du corpus Transcript, en dépit de sa taille modeste (fig. 3), et la preuve que la taille des
ressources n’est pas un critere suffisant. Dans ce cas particulier, les mesures font apparaitre un
comportement des ressources contraire aux intuitions initiales des biologistes qui
recommandaient a tort d’utiliser GO.

Le demier point porte sur la densité. Elle permet d'apprécier la fréquence des lexies en corpus.
De maniere surprenante, la plus forte densité s'obserVe pour une petite ressource tres spécialisée
(glossaire GoBMT, fig. 2) et pour le corpus le plus different thématiquement (Carnivore). Seule
l'analyse détaillée des lexies de la partie utile du glossaire permet de comprendre ce résultat
contre—intuitif. Moins de 10% des lexies figurent dans le corpus mais ces lexies ont de fortes
fréquences. On trouve notamment can (676 occ.), ﬁsh (121 occ.) tel (8 occ), tous les trois décrits
dans la ressource comme des noms de genes. Ce sont des mots ambigus reconnus a tort comme

Mesurer la Couverture d ’1me ressource terminologique

noms de genes dans le corpus Carnivore. Une forte densité peut ainsi aussi bien reﬂéter une
bonne adéquation de la ressource en terrnes de specialisation que des phénomenes d'ambigu'1'té.
Une simple mesure de fréquence pondérée n’apparait donc pas suffisamment éclairante. ll
faudrait sans doute considérer le profil lexical des lexies de la partie utile de la ressource par
rapport a l'ensemble des Vocables du corpus pour pouvoir prédire la nature sémantique de la
couverture. Ce profil devrait permettre d'apprécier la dispersion des fréquences et donc de mieux
repérer des correspondances artificielles entre certains terrnes spécialisés et des occurrences de
mots courants.

Transcript 932

0.35 035

0.3 L D C°"trib“ti°" - 03 U Contribution c

7 ' C°UVertUre I Couverture

025 T D Reconnaissance 025 1:1 Reconnai55ancg__

0.2 ’ 0.2

0.15 0.15

0-1 0.1 - _
 F  L is
0 , 1 L 1 Io ‘ 0 -*1
G|ossB|och GO GOBMT keywlist MeSH G|ossB|och GO GOBMT keywlist MeSH
1199 - droso carnivores

0 35 0.3 5

0-3 B Contribution * O_ 3 U Contribution —

I Couverture I Couverture

0.25 D Reconnaissance; O_ 2 5 D Reconnaissance?

0.2 0. Z

0.15 O. 1 E

0.1 O. 1
0.05 T 0.0 5
0 r J y L y E y O  . em .
G|°SSB|0Ch G0 GOBMT keywlist MeSH G|ossBioch GO GOBMT keywlist MeSH

Figure 3. Mesures de contribution, couverture et reconnaissance de 5 ressources sur 4 corpus :
Transcript, Transcript—932 (932), Drosophile (1199—dr0s0) et Carnivore

5 Conclusion et perspectives

Pour permettre de caractériser avec une certaine fiabilité et une certaine reproductibilité le
comportement d'une ressource lexicale pour un corpus donne, nous avons défini et testé un
ensemble de métriques qui donne une idée de la << couverture », notion Vague mais tres
couramment utilisée qui prend de l'importance avec l'augmentation du nombre de ressources
disponibles. Ces métriques ne peuvent prétendre suppléer une analyse precise de l’apport d’une
ressource : elles Visent a éclairer le choix des ressources et des traitements a mettre en oeuvre.
Les experiences que nous avons menées montrent l'intérét de ce type de métriques mais nous
avons également souligné les limites des mesures proposées. ll faudrait définir une mesure de
densité plus riche que nous ne l'aVons fait et, pour compléter l'image globale de couverture que
nous cherchons a construire, tenir compte de la répartition des occurrences des lexies de la
ressource. La notion de couverture lexicale telle qu’elle est définie ici doit par ailleurs étre
étendue pour prendre en compte les Variantes de lexies, leurs types sémantiques et meme leurs
relations sémantiques.

Ninova G., Nazarenko A., Hamon T. et Szulman S.

Références

BUITELAAR P., EIGNER T., DECLERCK T. (2004), OntoSelect: A Dynamic Ontology Library with
Support for Ontology Selection, In Proc. of the Demo Session at the Int. Semantic Web Conf,
Hiroshima, Japan, Nov. 2004.

BREWSTER, C., Alani, H., DASMAHAPATRA, S. and WILKS, Y. (2004), Data Driven Ontology
Evaluation. In Proc. Of the Int. Conf. on Language Resources and Evaluation (LREC 2004),
Lisbon, Portugal.

BASILI R., PAZIENZA M.T., STvENsoN M., VELARDI P., VINDIGNI M., WILKS Y. (1998), An
Empirical Approach to lexical Tuning, In Proc. of the Workshop on Adaptating Lexical and
Corpus Ressources to Sublanguages and Applications (First Int. Conf. on Language

Resources and Evaluation LREC 1998), P. VELARDI (ed.), May, Grenada.

CHARLET J ., BAcH1MoNT B., BOUAUD J ., ZWEIGENBAUM P. (1996), Ontologie et réutilisabilité :
expérience et discussion, in Acquisition et Inge'nierie des Connaissance, N. Aussenac , P.
Laublet and C. Reynaud (ed.), pp. 69-87, Cépadues—Editions, Toulouse.

HAMON H. (2005), Indexing specialized documents : are terminological resources sufficient ?, in
Actes des 6emes journe'es Terminologie et Intelligence Artiﬁcielle (TIA 2005), pp. 71-82, Rouen.

HOVY E. (2001), Comparing sets of semantic relations in ontologies. In Semantics of

Relationships, R. GREEN, C.A. BEAN and S.H. MYAENG (eds.), chapter 6, Kluwer , Dordrecht,
NL.

PILLET V. (2000), Me'thodologie d'extraction automatique d'information a partir de la
litte'rature en science en vue d'alimenter un nouveau systeme d'information. Application a la
ge'ne'tique mole'culaire pour l ‘extraction de donne'es sur les interactions. These doctorat, Aix—
Marseille III.

MANNING C., SCHUTZE H. (1999). Foundations of Statistical Natural Language Processing, The
MIT Press.

MULLER C. (1977), Principes et me'thodes de statistique lexicale, Hachette Université, Paris.

NAZARENKO A. (2005). Sur quelle sémantique reposent les méthodes automatiquesd’acces au

contenu textuel ? Se'mantique et corpus, A. CONDAMINES (coord.), ch. 6, pp. 211-244,
Hermes/Lavoisier.

NEDELLEC C., NAZARENKO A. (2005), Ontology and Information Extraction : a necessary
symbiosis, in Ontology Learning and Population, P. Buitelaar, P. Cimiano, B. Magnini (eds),
IOS (to appear).

NIRENBURG S., MAHESH K. and BEALE S. (1996), Measuring semantic coverage, in Proc. of the
16th Conf. on Computational Linguistics (COLING’96), Copenhagen Denmark, ACL, pp. 83-
88.

