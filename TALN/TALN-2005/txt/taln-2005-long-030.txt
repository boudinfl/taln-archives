T ALN 2005, Dourdan, 6-10 juin 2005

Comment mesurer la couverture d'une ressource terminologique
pour un corpus ?

Goritsa Ninova (1), Adeline Nazarenko (2),
Thierry Hamon (2), Sylvie Szulman (2)

LIPN UMR 7030
Université Paris 13 & CNRS
99, av. J .—B. Clément
93430 Villetaneuse
(1) cylvago@yahoo.fr
(2){prénom.nom}@lipn.univ—parisl3.fr

Mots-clés 2 couverture lexicale, terminologie, statistique lexicale
Keywords : lexical coverage, terminology, lexical statistics

Résumé Cet article propose une définition formelle de la notion de couverture lexicale. Celle-
ci repose sur un ensemble de quatre métriques qui donnent une vue globale de l'adéquation d'une
ressource lexicale a un corpus et permettent ainsi de guider le choix d'une ressource en fonction
d'un corpus donné. Les métriques proposées sont testées dans le contexte de l'analyse de corpus
spécialisés en génomique : 5 terminologies différentes sont confrontées a 4 corpus. La
combinaison des valeurs obtenues permet de discerner différents types de relations eI1tre
ressources et corpus.

Abstract This paper proposes a formal definition of the notion of lexical coverage. This
definition is based on four metrics that give a global view over a lexical resource to corpus
relationship, thus helping the choice of a relevant resource with respect to a given corpus. These
metrics have been experimented in the context of specialised corpus analysis in genomics. 5
terminologies have been confronted to 4 different corpora. The combination of resulting ﬁgures
reﬂects various types of corpus vs . resource relationships.

1 Introduction

On parle couramment de << couverture lexicale » sans définir clairement ce qu’on entend par la.
Différents auteurs mettent sous ce terme différentes notions et mesures. Le probleme est d'autant
plus complexe que les ressources utilisées comportent souvent des expressions polylexicales
dont la projection en corpus peut se faire de différentes manieres. Le présent article propose de
définir un ensemble de métriques pour cemer cette notion de couverture dans le cas général
d'une ressource constituée d'une liste de termes mono- et polylexicaux. Ces mesures sont testées

293

294

Ninova G., Nazarenko A., Hamon T. et Szulman S.

pour différents couples ressource/corpus. Les premiers résultats obtenus sont encourageants. Ils
montrent qu'on peut en effet documenter le comportement d'une ressource pour un corpus
donné en préalable a tout traitement, et ainsi guider le choix de la ressource.

Apres avoir souligné les enjeux de cette problématique et les questions qu’elle souleve (section
2), nous présentons dans la section 3 un ensemble de métriques. Celles-ci sont exploitées dans
la perspective du traitement automatique de corpus de génomique. Les résultats de ces
experiences sont présentés et discutés dans la section 4 de cet article.

2 Problématique
2.1 Enjeux

Le traitement de corpus specialise fait appel a des ressources sémantiques qu'on appelle
généralement spécialisées parce qu'elles décrivent un domaine particulier d'activité. Ces
ressources peuvent étre de différents types selon les traitements envisages, mais elles doivent
comporter une dimension lexicale des lors qu'elles sont destinées a l'analyse et l'interprétation de
données textuelles.

Les ontologies du web sémantique doivent ainsi étre ancrées lexicalement (avec des items
lexicaux associés aux noeuds de l'ontologie) si elles doivent servir a indexer des textes. Les
techniques d'acces au contenu des documents textuels sont diverses (extraction d'inforrnation,
question-réponse, outils de navigation ou de resume) mais elles reposent toutes sur une analyse
sémantique partielle des documents, qui implique la reconnaissance de certains elements du
discours (entités nommées et termes du domaine, notamment), leur typage sémantique et leur
mise en relation (Nazarenko, 2005). De ce fait, ces techniques reposent également sur des
lexiques, terminologies ou thesaurus specialises pour identiﬁer le vocabulaire de spécialité. Les
categories sémantiques et les relations lexicales sont utilisées (quand elles existent) pour
désambigu'1'ser les textes et en guider l'interprétation.

Des lors que les applications de traitement automatique des langues (T AL), y compris au niveau
sémantique, sont de plus en plus guidées par le lexique, la question du choix des ressources a
exploiter prend de l’importance. La situation releve souvent a la fois de la pléthore et de la
pénurie. D'un cote, il existe de nombreuses ressources terminologiques, surtout dans des
domaines comme la biologie ou la médecine ou l'effort d'organisation des connaissances est
ancienl. Mais d'un autre cote, les << bonnes ressources » sont rares : le degré de specialisation ou
le point de vue représenté par la ressource est généralement different de celui du texte que l'on
cherche a analyser. Ce constat a été fait par (Charlet et al., 1996), toujours dans le domaine de la
médecine pourtant reconnu pour la richesse de ses bases de connaissances. Dans la pratique,
come on ne peut ni se passer de ressource, ni en reconstruire de nouvelles pour chaque
nouvelle application, on fait souvent avec ce qu'on a. Dans certains cas, on peut spécialiser la
ressource et l'adapter en fonction du domaine et de la tache visés (problématique de l'adaptation
lexicale ou « lexical tuning » (Basili et al., 1998)) mais cela suppose néanmoins une ressource
initiale.

Une question se pose alors : parmi l'ensemble des ressources qui paraissent recouvrir en partie
eta priori le domaine du corpus a traiter, laquelle ou lesquelles choisir et sur quels criteres ?
Cette question est d'autant plus importante qu'on doit souvent limiter le nombre de ces
ressources pour réduire l'inévitable travail de preparation des données et pour éviter les
problemes d'incohérence. Il est en general trop coﬁteux d’exploiter en parallele différentes
ressources pour les tester en les comparant au regard de l’application visée. Les experts du
domaine ne sont pas toujours d'un grand secours non plus. Meme s'ils sont capables de décrire

1 Voir par exemple, UMLS (Unified Medical Language System, http://www.n1m.njh.gov/research/umls/).

Mesurer la couverture d ’z/me ressource terminologique

le sous-domaine couvert par une ressource et le point de vue qui y est représenté, ils sont
d’ordinaire peu a meme de mesurer son adéquation proprement lexicale.

Ce probleme du choix des ressources est souvent résolu de maniere tres empirique, ce qui ne
permet pas de capitaliser d'une experience a1’autre. Il est donc important de se doter de criteres
formels permettant de décrire le comportement d'une ressource par rapport a un corpus donné et
d’en guider le choix. C'est l'objet de ce travail : nous proposons un premier ensemble de
métriques pour apprécier la couverture d'un corpus par une ressource terminologique.

2.2 Difﬁcultés

Pour des dictionnaires traditionnels, on exprime l'adéquation a un corpus en termes de
couverture et on 1'apprécie a partir du nombre d'occurrences de mots du corpus qui se rattachent
a des entrees du dictionnaire. La couverture est plus difficile a définir pour des ressources
terminologiques.

La premiere difﬁculté tient a la diversité des ressources terminologiques qui rend problématique
leur comparaison. La nature de l’information differe d’une ressource a l’autre. Au-dela des
listes de termes, les termes eux-memes peuvent étre types et les types peuvent étre organises en
hiérarchie (thesaurus). Dans les ressources les plus riches, les termes sont de surcroit lies entre
eux par des liens sémantiques. Les ressources ont par ailleurs des degrés de spécialisation
divers. Il est difﬁcile de comparer un lexique de 10 000 unites qui comporterait de nombreuses
unites également présentes dans des dictionnaires généralistes et un lexique de 500 unites dont
tres peu figurent dans des dictionnaires classiques. Les ressources s'opposent enfin par leur
degre’ de lexicalisation : certaines se contentent de lister des étiquettes de concepts ; d'autres
considerent ces étiquettes dans leur dimension lexicale et linguistique. Ces dernieres rendent
compte des différentes formes sous lesquelles ces unites sémantiques peuvent se réaliser en
corpus, jusqu’a associer des regles de désambigu'1'sation contextuelles aux unites polysémiques
(Nédellec, Nazarenko, 2005).

La deuxieme difficulté tient au fait qu'on cherche a confronter deux objets qui ne sont pas de
meme nature. La ressource et le corpus s'opposent comme la langue s'oppose au discours : il
faut comparer un ensemble d'é1éments de lexique (la ressource) avec un ensemble d'occurrences
(le corpus). Par voie de consequence, il faut aussi comparer des unites potentiellement
polylexicales avec des occurrences observées en corpus, nécessairement monolexicales. Comme
il s’agit d’apprécier a priori 1’adéquation des ressources aux corpus, nous ne présupposons en
effet aucune étape de reconnaissance terminologique préalable.

Dans ce premier travail, nous focalisons 1'étude sur les ressources terminologiques considérées
comme des listes de termes, sans exploiter les éventuelles informations qu'el1es contiennent
concernant leurs regles de variation, leur typage sémantique ou les relations sémantiques qu'ils
entretiennent. Les premiers éléments étant poses, il est évidemment nécessaire de poursuivre, par
exemple, en prenant en compte la désambigu'1'sation des termes polysémiques, les liens de
variations entre termes et la structure sémantique. Ces points ne sont pas abordés ici.

2.3 Etat de l'art

La question de la sélection des ontologies pour une application prend de l'importance avec
1'augmentation du nombre des ontologies disponibles et la standardisation de leurs formats.
Cette preoccupation est au coeur de la problématique du web sémantique. (Buitelaar et al., 2004)
montre que la creation d’une bibliotheque d'ontologies (OntoSelect) suppose de définir des
criteres permettant de sélectionner une ontologie particuliere. Trois criteres sont proposes : les
degrés de structuration et de connectivité sont des mesures proprement ontologiques, mais le
critere de couverture est établi relativement a une collection de documents. Ce dernier critere est

295

296

Ninova G., Nazarenko A., Hamon T. et Szulman S.

cependant défini de maniere assez frustez : il ne prend qu'imparfaitement en compte la
dimension proprement linguistique des << étiquettes de concepts ».

Brewster et al. (2004) vont plus loin. Ils proposent d'évaluer les ontologies relativement a un
corpus donne. La notion de couverture qu'ils proposent est plus riche que la précédente. Elle
repose sur le nombre de termes en corpus qui correspondent a des concepts de 1'ontologie, une
fois effectués un calcul de variation pour reconnaitre des formes de termes non canoniques et
une expansion sémantique pour autoriser une adéquation a différents niveaux de généralité. A
partir de la, une ontologie est évaluée en fonction du nombre de concepts qui trouvent leur
contrepartie en corpus. Ce deuxieme travail prend davantage en compte la nature linguistique des
réalisations lexicales des concepts en corpus (notion de variation, quasisynonymie entre un
hyperonyme et son hyponyme) mais il est centre sur l'évaluation et la coherence interne d'une
ontologie alors que notre objectif est plutot de guider le choix d'une ressource pour un corpus
donne, ce qui confere un autre role a la notion de couverture et impose de la définir plus
précisément.

Sur le plan lexical, la question de la couverture n'a guere été étudiée3. De maniere intuitive, on
tend a préférer des ressources de grande taille (en nombre d'entrées), avec 1'idée qu'elles sont soit
plus completes sur un domaine restreint soit plus génériques et moins liées a un domaine
particulier. (Nirenburg et al., 1996) critique ce presuppose en soulignant que la taille de la
ressource donne une vue tres partielle de sa couverture. Dans ce travail, les auteurs cherchent
cependant a apprécier la qualité intrinseque de la ressource alors que nous défendons 1'idée
qu'une ressource n'a pas de valeur propre et qu’elle n'a de valeur que par les utilisations qui
peuvent en étre faites. Au total, la question du choix de la ressource étant donne un corpus a
moins retenu l'attention que la question ultérieure : une fois cette ressource choisie, comment
1'adapter a ce corpus (Basili et al., 1998) ?

La statistique lexicale a souligné depuis ses debuts (Muller, 1977 ; Manning, Schiitze, 1999)

qu'il existe une relation fonctionnelle eI1tre une ressource (un vocabulaire) et un corpus mais elle
n'a pas abordé le probleme des unites polylexicales que contiennent les terminologies.

3 Proposition de métriques

Afin d'apprécier 1'adéquation d'une ressource a un corpus, nous proposons différentes mesures.
I1 s’agit de caractériser la couverture de la ressource ainsi que son degré de specialisation.

3.1 Remarques terminologiques

Nous posons les deﬁnitions suivantes :

° Le texte T du corpus est un ensemble ordonné de mots4. Les mots sont définis par leur
forme graphique et repérés par leur position dans le texte.

2 «Coverage is measured by the number of labels for classes and properties that can be matched in the
document».

3 La notion de couverture lexicale n’est pas définie dans les ouvrages de statistique linguistique (Oakes, 1998).
Quand la question est abordée (Manning, Schijtze, 1999, p. 130), c’est uniquement pour apprécier le nombre
de mots inconnus dans un texte.

4 La notion de « mot » est difficile a définir. Nous considérons ici comme mots les unites resultant d'une
segmentation du texte, étant donne un algorithme de segmentation clairement défini. Dans les exemples
présentés ici, tous les caracteres d’espacement et de ponctuation sont considérés comme séparateurs de mots.

Mesurer la couverture d ’une ressource terminologique

° Le vocabulaire V du corpus est l'ensemble des Vocables, i.e. l'ensemble des mots différents
du corpus. Les Vocables sont des unites monolexicales.

° Le lexique L de la ressource est l'ensemble des lexies ou entrees lexicales de la ressources,
qu'e1les soient composées de un ou plusieurs mots, spécialisées ou non.

Les Vocables du corpus et les lexies étant de natures différentes, on ne peut pas comparer
directement le Vocabulaire et le lexique. Pour établir cette comparaison, nous considérons la
« partie utile » de la ressource et sa « decomposition », ainsi que leurs complémentaires, définis
de la maniere suivante (ﬁg. 1) :

ESPACE DE LEXIES

  
  

ESPACE DE MOTS ! r T

ESPACE DE VOCABLE

Figure 1 : Construction des ensembles de reference

° La partie utile de la ressource PU est l'ensemble des lexies de la ressource qui apparaissent
dans le corpus. C'est un sous-ensemble de L.

° La partie utile décomposée PUD est l'ensemble de tous les Vocables des lexies de PU. Elle
est obtenue par decomposition en Vocables élémentaires des lexies de PU. En supposant que
cette decomposition est faite selon les memes regles qui ont permis de segmenter le corpus,
cet ensemble de Vocables PUD correspond aussi a la partie du Vocabulaire du corpus qui est
reconnue (PR) par la ressource. On a donc PUD=PR, ou PR est un sous-ensemble de V.

° La partie inutile de la ressource PN U est l'ensemble des lexies qui n'ont pas d'occurrence
dans le corpus. C'est le complémentaire de PU par rapport a L.

° La partie inconnue du vocabulaire du corpus PNR est l'ensemble des Vocables de V non
reconnus par la ressource. C'est le complémentaire de PN par rapport a V.

3.2 Mesures

Les métriques que nous proposons pour apprécier1'adéquation d'une ressource terminologique a
un corpus sont déﬁnies comme des rapports entre les différents ensembles déﬁnis ci-dessus. On
peut distinguer les mesures qui portent sur les formes et celles qui portent sur les occurrences.

La premiere mesure permet d'apprécier le degré de spécialité de la ressource par rapport a un
corpus. La contribution (Contr) est la proportion de lexies du lexique qui figurent en corpus.
Elle est déﬁnie par la formule ci-dessous. Nous désignons par surplus (Surpl) la proportion de
lexies « inutiles ». On retrouve ici la notion d'exces de ressource introduite par (Brewster et al.,
2004). La contribution est forte si beaucoup des lexies de la ressource se retrouvent en corpus et
donc si le domaine de spécialité de la ressource correspond bien a celui du corpus. A 1'inVerse,

5 Comme nous l'avons souligné plus haut, nous ne considérons pas :2. cc stade les autres informations
sémantiques apportées par la ressource.

297

298

Ninova G., Nazarenko A., Hamon T. et Szulman S.

un surplus élevé indique que la ressource est relativement générique et donc potentiellement utile
pour des corpus Varies. Ces mesures étant indépendantes de la taille de la ressource, on peut
comparer les contributions de ressources tres différentes.

Contr = IPU I / ILI Surpl = I — Contr = IPN U I / ILI ou IX] représente le cardinal de X
Une autre mesure permet d'apprécier dans quelle mesure la ressource « couvre » 1e Vocabulaire
du corpus. Pour avoir des ensembles comparables, il faut comparer la partie reconnue du
Vocabulaire et le Vocabulaire dans son ensemble. Les deux mesures duales de la reconnaissance
(Rec) et de 1'ignorance (Ign) sont déﬁnies ci-dessous. La reconnaissance est la proportion des
lexies décomposées reconnues en corpus par rapport au nombre total de Vocables du corpus. La
reconnaissance augmente 1) si on trouve dans le lexique les termes specialises employés dans le
corpus mais aussi 2) quand la ressource comporte beaucoup de mots de la langue générale
comme par exemple les mots grammaticaux. Seule la confrontation des différentes mesures
permet de se faire une idée plus precise du comportement d'une ressource. Dans le cas 2, la forte
reconnaissance tend a étre associée a un surplus important. Une forte reconnaissance combinée
a une contribution élevée indique une ressource spéciﬁque bien adaptée au corpus considéré.

Rec=|PR|/|V|=|PUD|/|V| Ign=1—Rec=|PNR|/|V|

Parler de << couverture » évoque l'idée d'un corpus tout ou partiellement « couVert » par la
ressource. La couverture est donc calculée relativement au corpus plutot qu'a son Vocabulaire.
Nous définissons la couverture (Couv) comme la proportion d'occurrences de mots
correspondant a des Vocables entrant dans les lexies de la partie utile de la ressource. Dans la
formule ci-dessous,freq,. représente le nombre d’occurrences d’une lexie 1' de PU non incluses
dans une occurrence d’une autre lexie plus large et longueur, est la longueur de la lexie en
nombre de mots. Dans le cas de termes enchassés (p. ex. systéme et systéme de ﬁchiers), seule
l’occurrence du terme le plus large entre dans la mesure de fréquence. Cette mesure de
couverture est indépendante de la taille du corpus, ce qui rend les mesures de couverture d'une
ressource comparables meme sur des corpus de taille différente.

La derniere mesure complete la mesure de couverture. C'est la densite’ (Dens), définie par la
formule ci-dessous, oufm, est la fréquence moyenne des lexies de PU dans le corpus et fv est la
fréquence moyenne des Vocables dans le corpus. C'est une mesure normalisée de la fréquence
des lexies utiles en corpus. Pour avoir une mesure indépendante de la taille du corpus, la
fréquence moyenne des lexies de PU est pondérée par la fréquence moyenne des Vocables dans
le corpus.

Couv =  freqix longeur,./ ITI Dens=fPUD/fV

3.3 Exemple

A titre d’exemp1e, considérons la ressource et le texte suivants :
° L={syste‘me, systéme deﬁchiers}

0 T=<< I] a réparé le systeme de ﬁchiers »

On a |L|=2 et |T|=7. Dans ce cas particulier, on a |V|=|T|=7. Toutes les unites du lexique se
retrouvant en corpus, on a par ailleurs PU=L et PUD=PR={syste‘me, de, ﬁchiers}.

On obtient donc les mesures suivantes : Contr=1, Rec=3/7, C01/zv=3/7. Notons que l’occurrence
de la lexie systéme qui entre dans l’occurrence plus large de la lexie systéme de ﬁchier n’est pas
comptabilisée en tant que telle dans la couverture.

Mesurer la couverture d ’z/me ressource terminologique

4 Résultats

4.1 Protocole experimental

Nous avons teste ces metriques dans le cadre de projets de recherche et d’extraction
d'information dans le domaine de la genornique. Ce type d'application specialisee requiert en
effet d'exploiter des ressources et le choix de/des ressource(s) a exploiter s'avere souvent delicat.
Nous avons considere differents corpus de genornique et differentes ressources terrninologiques
a priori assez bien adaptees au domaine d'app1ication (Hamon, 2005). A des fins d'evaluation,
nous avons complete ces donnees experimentales par un autre corpus qui porte sur les plantes
carnivores et qui releve d'un domaine un peu different. I1 faudra elargir cette experimentation en
prenant en compte un autre corpus exterieur au champ de la biologie et une ressource dite de
<< langue generale ».

Nous avons travaille sur quatre corpus, tous du domaine de la biologie, mais differant les uns
des autres par leur style et leurs caracteristiques lexicographiques (tableau 1). Le premier corpus
(Transcript) est constitue de 2 209 resumes d'articles scientiﬁques issus de la base Medline“ a
partir de la requete << Bacillus subtilis transcription ». Le second corpus (Transcript-932 ou
932) a ete construit a partir du premier, en selectionnant 932 phrases dans lesquelles
apparaissent deux noms de genes. Le troisieme corpus (Drosophile-1199 ou 1199-droso)
(Pillet, 2000) est similaire au second. 11 s'agit de 1 199 phrases extraites des resumes de
Flybase7, qui contiennent deux noms de genes. Le quatrieme corpus regroupe differents

documents issus du web se rapportant aux plantes carnivores (Carnivore).

moyenne
9
t-

e 27 201 273 605

10,06

Le tableau 1. Caracteristiques lexicographiques des corpus

 

Pour etudier la couverture des ressources terminologiques, nous avons selectionne cinq
ressources specialisees publiquement disponibless : 1) les mots cles SwissProt (keywlist)
utilises pour indexer la base de sequencage des proteines, 2) Gene Ontology (GO) qui porte sur
les differents types d'organismes vivants, 3) le MeSH qui est dedie a l'indexation de la base de
donnees Medline et rassemble des termes tres divers utilises dans le domaine medical. Nous
avons egalement retenu deux glossaires proposant une grande variete de termes : 4) le glossaire
de biochimie et de biologie moleculaire (GlossBioch) qui comporte des termes courants et 5) le
glossaire de terminologie de biologie moleculaire (GoMBT).

6 www.ncbi.nlm.nih.gov

7 Flybase est une base de donnees structurees et bibliographiques sur la
http://ﬂybase.bio.indiana.edu/

drosophile :

3 Ces ressources sont disponibles aux adresses suivantes :

keylist : ftp://ftp.expasy.org/databases/swiss—prot/release/keywlist.txt

GO : http://www.geneontology.org/, version telechargee en septembre 2002

MeSH : http://www.n1m.njh.gov/mesh/meshhome.htm1 (Medical subject headings, Library of Medicine)
GlossBioch : http://www.portlandpress.com/pcs/books/prod_det.dfm?product=18557 80887

GoMBT : http://www.asheducationbook.org/cgi/content/fu]l/2002/ 1/490

299

300

Ninova G., Nazarenko A., Hamon T. et Szulman S.

GoBMT
263

Ressources
Taille en nombre de lexies

MeSH GO keywlist GlossBioch
8994916736 2934 836

Tableau 2. Tailles comparées des différentes ressources

4.2 Analyse des résultats

Les calculs des différentes métriques pour les 5 ressources et les 4 corpus ci-dessus sont
synthétisés dans les graphiques des figures 2 et 3.

Couverture du corpus par des ressources Densité des ressources

o
_.
on
5

U G|ossB|och
I GO

U GoBMT

D keywlist

I MeSH

D G|ossB|och 7
I GO _
D GoBMT
D keywlist _
I MeSH

  
 
 
   

 

O_.l'\JV.AJ-bu-rO')\]CO1O

1 199—droso 9 32- carnivores Transcript 1199—droso 932- Carnivores

Transcript

Figure 2. Mesures d'adéquation de différentes ressources a différents corpus :
couverture et densité

Les mesures gomment l'effet de taille aussi bien sur les corpus que sur les ressources. Le
glossaire GlossBioch a une couverture similaire a celle de MeSH qui comporte pourtant 50 fois
plus de terrnes (fig. 2). Le comportement des ressources est comparable pour le corpus
Transcript et son sous-corpus Transcript-932 (fig. 3). On peut donc envisager de sélectionner
une ressource a partir d'un sous-corpus sans chercher a projeter la ressource sur l'intégralité du
corpus, ce qui facilite les expérimentations.

La contribution fait exception cependant. Elle est a la fois sensible a la taille de la ressource et a
celle du corpus : on remarque qu’elle est moindre pour un petit corpus (GloBioch pour
transcript-932) et pour les ressources Volurnineuses (MESH pour Transcript). Malgré cette
sensibilité aux effets de taille, c’est une mesure intéressante : une forte contribution pour une
petite ressource est un bon indicateur de pertinence (cf. GoBMT et keywlist pour Transcript).

La troisieme remarque concerne les deux mesures de reconnaissance et de couverture qui
paraissent assez bien corrélées. On note une grande stabilité dans le sens et l'ampleur de leur
écart : un corpus est d’autant mieux couvert que son Vocabulaire est reconnu. C’est donc
l’absence de correlation qui est significative. Nos experiences montrent par exemple que le
glossaire GlossBioch a une couverture nettement supérieure a celle de GO sur Transcript, pour
une reconnaissance sirnilaire. C’est le signe que GlossBioch reﬂete mieux la langue de spécialité
du corpus Transcript, en dépit de sa taille modeste (fig. 3), et la preuve que la taille des
ressources n’est pas un critere sufﬁsant. Dans ce cas particulier, les mesures font apparaitre un
comportement des ressources contraire aux intuitions initiales des biologistes qui
recommandaient a tort d’utiliser GO.

Le dernier point porte sur la densite. Elle perrnet d'apprécier la fréquence des lexies en corpus.
De maniere surprenante, la plus forte densité s'obserVe pour une petite ressource tres spécialisée
(glossaire GoBMT, ﬁg. 2) et pour le corpus le plus different thématiquement (Carnivore). Seule
l'analyse détaillée des lexies de la partie utile du glossaire perrnet de comprendre ce résultat
contre-intuitif. Moins de 10% des lexies figurent dans le corpus mais ces lexies ont de fortes
fréquences. On trouve notamment can (676 occ.), ﬁsh (121 occ.) tel (8 occ), tous les trois décrits
dans la ressource comme des noms de genes. Ce sont des mots ambigus reconnus a tort comme

Mesurer la couverture d ’z/me ressource terminologique

noms de genes dans le corpus Carnivore. Une forte densité peut ainsi aussi bien reﬂéter une
bonne adéquation de la ressource en termes de specialisation que des phénomenes d'ambigu'1'té.
Une simple mesure de fréquence pondérée n’apparait donc pas suffisamment éclairante. I1
faudrait sans doute considérer le profil lexical des lexies de la partie utile de la ressource par
rapport a l'ensemble des Vocables du corpus pour pouvoir prédire la nature sémantique de la
couverture. Ce profil devrait permettre d'apprécier la dispersion des fréquences et donc de mieux
repérer des correspondances artificielles entre certains termes specialises et des occurrences de
mots courants.

Transcript 932

0.35 035

0.3 L 5‘ C°“mbUti°“ — 03 U Contribution n

7 ' C°UVe|'t'-We I Couverture

025 T D Reconnaissance; 025 u Reconnaissancgﬁ

0.2 — 0.2
0-15 0.15

0-1 0.1 - _
 F  L E

0 , y L y In t 0 -*1
G|ossB|och G0 GoBMT keywlist MeSH G|ossB|och GO GoBMT keywlist MeSH
1199 - droso carnivores

0 35 0.3 5

0-3 B Contribution * 0.3 U Contribution —

I Couverture I Couverture

0.25 U Reconnaissance; 0.25 D Reconnaissancek

0.2 0.2
0.15 0.1 E

0.1 0.1
o_o5 T 0.05:!

0 y r—' ‘ L—i ‘ HT ‘ 0 — . '_‘—ﬁ .
G|ossB|och G0 GoBMT keywlist MeSH G|ossBioch GI) GoBMT keywlist MeSH

Figure 3. Mesures de contribution, couverture et reconnaissance de 5 ressources sur 4 corpus :
Transcript, Transcript-932 (932), Drosophile (1199-droso) et Carnivore

5 Conclusion et perspectives

Pour permettre de caractériser avec une certaine fiabilité et une certaine reproductibilité le
comportement d'une ressource lexicale pour un corpus donné, nous avons défini et testé un
ensemble de métriques qui donne une idée de la << couverture », notion Vague mais tres
couramment utilisée qui prend de l'importance avec l'augmentation du nombre de ressources
disponibles. Ces métriques ne peuvent prétendre suppléer une analyse precise de l’apport d’une
ressource : elles Visent a éclairer le choix des ressources et des traitements a mettre en oeuvre.
Les experiences que nous avons menées montrent l'intérét de ce type de métriques mais nous
avons également souligné les limites des mesures proposées. I1 faudrait défmir une mesure de
densité plus riche que nous ne l'aVons fait et, pour compléter l'image globale de couverture que
nous cherchons a construire, tenir compte de la repartition des occurrences des lexies de la
ressource. La notion de couverture lexicale telle qu’elle est définie ici doit par ailleurs étre
étendue pour prendre en compte les Variantes de lexies, leurs types sémantiques et meme leurs
relations sémantiques.

301

302

Ninova G., Nazarenko A., Hamon T. et Szulman S.

Références

BUITELAAR P., EIGNER T., DECLERCK T. (2004), OntoSelect: A Dynamic Ontology Library with
Support for Ontology Selection, In Proc. of the Demo Session at the Int. Semantic Web Conf,
Hiroshima, Japan, Nov. 2004.

BREWSTER, C., Alani, H., DASMAHAPATRA, S. and WILKS, Y. (2004), Data Driven Ontology
Evaluation. In Proc. Of the Int. Conf. on Language Resources and Evaluation (LREC 2004),
Lisbon, Portugal.

BASILI R., PAZIENZA M.T., STvENs0N M., VELARDI P., VINDIGNI M., WILKS Y. (1998), An
Empirical Approach to lexical Tuning, In Proc. of the Workshop on Adaptating Lexical and
Corpus Ressources to Sublanguages and Applications (First Int. Conf. on Language

Resources and Evaluation LREC 1998), P. VELARDI (ed.), May, Grenada.

CHARLET J.,BAcH1MoNr B., BOUAUD J ., ZWEIGENBAUM P. (1996), Ontologie et réutilisabilité :
experience et discussion, in Acquisition et Inge’nierie des Connaissance, N. Aussenac , P.
Laublet and C. Reynaud (ed.), pp. 69-87, Cépadues-Editions, Toulouse.

HAMON H. (2005), Indexing specialized documents : are terminological resources sufﬁcient ?, in
Actes des 6emes journe’es Terminologie et Intelligence Artiﬁcielle (TIA 2005), pp. 71-82, Rouen.

HOVY E. (2001), Comparing sets of semantic relations in ontologies. In Semantics of
Relationships, R. GREEN, C.A. BEAN and S.H. MYAENG (eds.), chapter 6, Kluwer , Dordrecht,
NL.

PILLET V. (2000), Me’thodologie d'extraction automatique d'information a partir de la
litte’rature en science en vue d'alimenter un nouveau systeme d ‘information. Application a la
ge’ne’tique mole’culaire pour l ‘extraction de donne’es sur les interactions. These doctorat, Aix-
Marseille I[[.

MANNING C., SCHCTTZE H. (1999). Foundations of Statistical Natural Language Processing, The
MIT Press.

MULLER C. (1977), Principes et me’thodes de statistique lexicale, Hachette Université, Paris.

NAZARENKO A. (2005). Sur quelle sémantique reposent les méthodes automatiquesd’acces au

contenu textuel ? Se’mantique et corpus, A. CONDAMINES (coord.), ch. 6, pp. 211-244,
Hermes/Lavoisier.

NEDELLEC C., NAZARENKO A. (2005), Ontology and Information Extraction .' a necessary
symbiosis, in Ontology Learning and Population, P. Buitelaar, P. Cimiano, B. Magnini (eds),
IOS (to appear).

NIRENBURG S., MAHESH K. and BEALE S. (1996), Measuring semantic coverage, in Proc. of the
16th Conf. on Computational Linguistics (COLING’96), Copenhagen Denmark, ACL, pp. 83-
88.

