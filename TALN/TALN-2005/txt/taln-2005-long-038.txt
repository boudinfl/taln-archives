TALN 2005, Dourdcm, 6-I0 juin 2005

Acquisition et évaluation sur corpus
de propriétés de sous-categorisation syntaxique

Didier Bourigault et Cecile Frerot

ERSS — CNRS & Universite Toulouse le Mirail
5, allees Antonio Machado
31 058 Toulouse Cedex 1
{didier.bourigault,cecile.frerot} @uniV—tlse2.fr

Mots-clés 2 analyse syntaxique, ambiguite de rattachement prepositionnel, sous-
categorisation syntaxique

Keywords: syntactic parsing, PP attachment disambiguation, subcategorization lexicon

Résumé

Cette etude est menee dans le cadre du developpement de l’analyseur syntaxique de corpus
Syntex et porte sur la tache de desambiguisation des rattachements prepositionnels. Les
donnees de sous-categorisation syntaxique exploitees par Syntex pour la desambiguisation se
presentent sous la forme de probabilites de sous-categorisation (que telle unite lexicale -
Verbe, nom ou adjectif - se construise avec telle preposition). Elles sont acquises
automatiquement a partir d’un corpus de 200 millions de mots, etiquete et partiellement
analyse syntaxiquement. Pour evaluer ces donnees, nous utilisons 4 corpus de test de genres
Varies, sur lesquels nous avons annote a la main plusieurs centaines de cas de rattachement
prepositionnels ambigus. Nous testons plusieurs strategies de desambiguisation, une strategie
de base, une strategie endogéne qui exploite des proprietes de sous-categorisation specifiques
acquises a partir du corpus en cours de traitement, une strategie exogéne qui exploite des
proprietes de sous-categorisation generiques acquises a partir du corpus de 200 millions de
mots, et enfin une strategie mixte qui utilisent les deux types de ressources. L’analyse des
resultats montre que la strategie mixte est la meilleure, et que les performances de l’analyseur
sur la tache de desambiguisation des rattachements prepositionnels Varient selon les corpus de
79.4 % a 87.2 %.

Abstract

We carry out an experiment aimed at using subcategorization information into a syntactic
parser for PP attachment disambiguation. The subcategorization lexicon consists of
probabilities between a word (Verb, noun, adjective) and a preposition. The lexicon is
acquired automatically from a 200 million word corpus, that is partially tagged and parsed. In
order to assess the lexicon, we use 4 different corpora in terms of genre and domain. We

373

374

D. Bonrigaalt, C. Fre’rot

assess Various methods for PP attachment disambiguation : an exogeous method relies on the
sub-categorization lexicon whereas an endogenous method relies on the corpus specific
ressource only and an hybrid method makes use of both. The hybrid method proves to be the
best and the results Vary from 79.4 % to 87.2 %.

1 Introduction

Les nombreux travaux sur le developpement de parseurs statistiques concement la langue
anglaise et tendent a utiliser comme corpus d’apprentissage et comme corpus de test des
portions de la section du Wall Street Journal du Penn TreeBank (Charniak, 1997). Outre
qu’elle permet d’eViter la tache l aborieuse de construction de corpus annotes, cette demarche
presente l’immense avantage de po uvoir comparer les parseurs entre eux (Ratnaparkhi et al.,
1994 ; Pantel et Lin, 1998). Cette exploitation mono-corpus pose cependant la question de la
stabilite des performances en fonction du type de corpus, comme le mentionnent Kilgarrif et
Grefenstette (2003 :341) : « there is little work on assessing how well one language model
fares when applied to a text type that is diﬁerent from that of the training corpus ». Par
ailleurs, il est maintenant bien connu que, dans tout corpus, certaines unites lexicales ont des
proprietes syntaxiques de sous-categorisation specifiques, qui peuvent donc Varier d’un
domaine a l’autre (Roland, J urafsky, 1998 ; Basili et al., 1999). Or peu de travaux relatent des
experiences sur la Variation des performances de l’analyseur en fonction du type de corpus a
traiter, sur le probleme de la possible Variation inter-corpus et sur celui de la necessaire
adaptation des regles de l’analyseur a un corpus donne. On peut neanmoins citer (Sekine,
1997 ; Gildea, 2001 ; Slocum, 1986).

Dans cet article, nous nous interessons a l’acquisition et a l’eValuation sur corpus de donnees

de sous-categorisation syntaxique. Cette etude est menee dans le cadre du developpement de
l’analyseur syntaxique de corpus Syntex et porte sur la tache de desambiguisation des
rattachements prepositionnelsl (section 2). Les donnees de sous-categorisation syntaxique
exploitees par Syntex pour la desambiguisation se presentent sous la forme de probabilites de
sous-categorisation (que telle unite lexicale - Verbe, nom ou adjectif — se construise aVec telle
preposition). Dans la section 3, nous decrivons comment elles sont acquises automatiquement
a partir d’un corpus de 200 millions de mot s, etiquete et partiellement analyse
syntaxiquement. La section4 est consacree a l’eValuation sur des donnees acquises sur 4
corpus de test de genres Varies, sur lesquels nous aVons annote a la main plusieurs centaines
de cas de rattachement prepositionnels ambigus. Dans la section 5, nous presentons plusieurs
strategies de desambiguisation : une strategie de base, une strategie endogene qui exploite des
proprietes de sous-categorisation specifiques, acquises a partir du corpus en cours de
traitement, une strategie exogene qui exploite des proprietes de sous-categorisation
generiques, acquises a partir du corpus de 200 millions de mots, et enfin une strategie mixte
qui utilise les deux types de ressources. L’analyse des resultats (section 6) montre que la
strategie mixte est la plus performante, et que les performances de l’analyseur sur la tache de
desambiguisation des rattachements prepositionnels Varient selon les corpus.

' Nous nous intéressons dans cet article aux prépositions autres que de. Le traitement de la preposition de repose
sur les memes principes, mais est sensiblement plus complexe (Frérot et al., 2003).

Acquisition er évaluation sur corpus 

2 Syntex, un analyseur syntaxique de corpus

Cette experience est menee dans le cadre du developpement de l’analyseur syntaxique de
corpus Syntex (Bourigault, Fabre, 2000). Syntex est un analyseur en dependance qui prend en
entree un corpus de phrases etiqueteesz, et calcule pour chaque phrase les relations de
dependance syntaxique entre les mots. C’est un analyseur en couches (A’1’t-Moktar et al.,
2002) : le corpus est analyse en plusieurs passes, differents modules prenant successivement
en charge une relation syntaxique de dependance donnee, et les sorties d’un module
constituant les entrees du module suivant. Chaque module est constitue d’un ensemble de
regles construites « a la main ».

Syntex est un analyseur semi-lexicalise. Le module qui effectue les rattachements
prepositionnels exploite des donnees lexico-syntaxiques de sous-categorisation, exprimees
sous la forme de probabilites qu’une unite lexicale donnee (Verbe, nom, adjectif) se construise
aVec telle ou telle preposition. Le rattachement des prepositions a leur recteur s’effectue en
deux passes : (1) recherche des candidats recteurs, (2) choix d’un recteur. Un premier module
(rechercher-candidats) traite l’ensemble des phrases du corpus, et recherche pour chaque
preposition, le ou les mots susceptibles de regir cette preposition. Ce module est constitue de
regles qui reconnaissent un certain nombre de configurations lineaires de mots et de categories
morphosyntaxiques a gauche de la preposition au sein desquelles sont identifies des mots
susceptibles de regir la preposition. Ces regles s’appuient sur les relations de dependance
placees par les modules anterieurs, et sont capables d’aller chercher des candidats recteurs
dans des configurations relativement complexes, incluant par exemple des structures
coordonnees ou des incises. Les configurations d’ambigu’1’tes, definies comme la succession
des categories grammaticales des candidats recteurs, sont tres Variees. Sur les 4 corpus de test
presentes dans la section 4, la configuration ‘V N’, ou seuls un Verbe et un nom sont en
competition - configuration traitee dans beaucoup de travaux dont ceux, fondateurs, de Hindle
et Rooth (1993) -, ne represente que 50 % des cas dans le corpus litteraire, environ 35 % dans
le corpus joumalistique et 15 % dans le corpus juridique et le corpus technique.

Au cours de la seconde etape du traitement des ambiguites prepositionnelles, le second
module (choisir-ccmdidat) revient sur chaque cas ambigu et choisit le recteur de la preposition
parmi les candidats. Pour ce faire, ce module exploite des informations de sous-categorisation
associees aux couples (candidat, preposition). Depuis l’origine de nos travaux sur l’analyse

syntaxique, ces informations sont acquises de facon endogene sur le corpus en cours de
traitement (Bourigault, 1993). En effet, l’analyseur est utilise dans differents conte xtes
applicatifs, et principalement dans des applications de construction de terminologies ou
d’ontologies specialisees a partir de textes. Il traite des corpus specialises, thematiques, de
taille moyenne (quelques centaines de milliers de mots, sur des domaines techniques,
juridiques, medicaux). Les experiences menees sur de nombreux corpus ont montre que ces
corpus renferment des specificites lexicales, en particulier que certains mots, frequents dans le
corpus, manifestent des comportements syntaxiques specifiques et impredictibles. C’est
pourquoi, nous avons porte nos efforts depuis une dizaine d’annees sur le developpement de
procedures d’apprentissage endogene sur corpus qui permettent a l’analyseur d’acquerir lui -

2 Nous utilisons actuellement les Versions francaise et anglaise du Treetager (http2//www.ims.uni—stuttgart.de)

375

376

D. Bourigault, C. Frérot

meme, par analyse du corpus a traiter, des informations de sous-categorisation specifiques a
ce corpus, acquises a partir des cas non ambigus reperes par le module rechercher-candidats.

Devant les limites inherentes a l’eXploitation d’informations de sous -categorisation acquises
exclusivement sur le corpus en cours de traitement, nous travaillons a l’elaboration de
ressources generales, susceptibles d’étre exploitees pour tout corpus (Frerot er al., 2003).
Nous aVons experimente l’utilisation d’un lexique de sous -categorisation construit a partir des
tables du Lexique Grammaire (Frerot, a paraitre). Nous presentons dans ce travail une
experience d’acquisition de probabilites de sous -categorisation a partir d’un corpus de 200
millions de mots.

3 Acquisition de propriétés de sous-catégorisation 51 partir d’un
corpus de 200 millions de mots

Les methodes d’acquisition de propriétés de sous -categorisation exploitent classiquement des
corpus etiquetes de grande taille (Basili, Vindigni, 1998). Le Web est aussi considere comme
source potentielle d’acquisiti on (Gala Pavia, 2003). Dans notre etude, nous utilisons comme
base d’apprentissage un corpus de 200 millions de mots, constitue des articles du journal Le
Monde, des annees 1991 a 2000 (corpus LMl03). Nous ne pretendons pas que ce corpus soit
representatif de la « langue generale », mais nous considerons que sa taille et sa diversite
thematique en font un corpus referentiellement et linguistiquement peu marque, a partir
duquel il est possible d’acquerir des do nnees de sous-categorisation relativement generiques.
La procedure d’acquisition est adaptee des methodes d’apprentissage endogene integrees dans

Syntex. La methode de calcul des probabilites de sous-categorisation s’appuie sur un
ensemble de triplets (recteur, preposition, regi) extraits d’une analyse syntaxique du corpus
LMl0 effectuee par Syntex. La procedure d’acquisition se deroule en deux etapes, au cours
desquelles la meme methode de calcul de probabilites est lancee successivement sur deux
ensembles differents de triplets : une etape d’amorgage et une etape de consolidation.

Au cours de l’etape d’amorgage, le module rechercher-ccmdidats traite l’ensemble du corpus
LM10, qui a ete analyse par les modules anterieurs de Syntex, et construit, a partir des cas
non-ambigus, c’est-a-dire ceux pour lesquels il n’a identifie qu’un seul candidat recteur pour
la preposition, un ensemble de triplets (w,p,w’), ou w est le recteur de la preposition p, et w’ le
mot (nom, ou Verbe a l’infinitif) regi par la preposition. Le module rechercher-candidats
compte aussi pour chaque mot w le nombre d’occurrences dans le corpus ou ce mot n’est
candidat d’aucLme preposition. A l’issue du traitement de l’ensemble du corpus, on dispose

des donnees de frequence suivantes :

0 F(w,0): nombre d’o ccurrences non ambigues ou le mot w ne regit aucune
preposition ;

3 Ce corpus a été prepare, a partir de fichiers obtenus aupres de l’agence Elra, par Benoit Habert (LIMSI), qui a
effectué les taches de nettoyage, de balisage et de signalisation nécessaires pour transformer les fichiers
initiaux en un corpus effectivement « traitable » par des outils de Traitement Automatique des Langues.
Nous remercions Benoit Habert et le LIMSI de nous avoir permis de bénéficier de cette ressource.

Acquisition er évaluation sur corpus 

0 F(w,p,w’): nombre d’occurrences non ambigues ou le mot w regit la
preposition p, qui elle-meme regit le mot w ’.

A partir de ces donnees, un premier ensemble de probabilites de sous-categorisation P(w,p)
est calcule, selon la methode decrite plus loin dans la presente section.

Au cours de l’etape de consolidation, le module choisir-candidat exploite ce premier lexique
et traite a son tour l’ensemble du corpus LM10, analyse par le module rechercher-candidats.
Il revient sur les cas ambigus et choisit le candidat recteur dont la probabilite de construction
avec la preposition, foumie dans le premier lexique, est la plus importante. A partir de ces
nouvelles annotations, un nouvel ensemble de triplets est constitue, qui inclut le precedent et
auquel s’ajoutent les triplets (w,p,w’) issus des cas ambigus resolus. De nouvelles donnees de
frequence F(w,p,w’) et F(w,0) sont alors constituees, a partir desquelles un second ensemble
de probabilites de sous-categorisation est calcule, selon la methode decrite ci-dessous. C’est le
lexique construit a l’issue de cette etape de consolidation qui est utilise dans Syntex.

La methode de calcul des probabilites est simple. La probabilite est calculee comme une
frequence relative ponderee4. Soit T, l’ensemble des triplets (w,p,w’), obtenu a l’issue de
l’etape d’amorgage ou a celle de consolidation. Pour un couple (w,p), on definit Ewsp comme
l’ensemble des mots w’ tels que la frequence F(w,p,w’) est superieure a 0. On definit la
productivite’ du couple (w,p), Prod(w,p), comme le cardinal de l’ensemble Ewsp, c’est-a-dire
comme le nombre de mots diﬁérents que regit la preposition p quand elle-meme est regie par
le mot w. Nous utilisons ce coefficient pour ponderer la frequence totale du couple (w,p). A
frequence egale, plus le couple (w,p) a ete repere avec des contextes w’ differents, plus grande
est estimee la propension du mot w a regir la preposition p. L’eXperience montre que, dans des
corpus thematiques, la tres haute frequence de certains syntagmes tres repetitifs incluant le
triplet (w,p,w’) Vient biaiser la probabilite d’association lexicale entre w et p. La ponderation
proposee ci-dessus Vise a limiter une telle surestimation et a accorder un poids non seulement
a la frequence de l’association, mais aussi a sa diversite. La formule de calcul de la probabil ite
ponderee est donnee dans le tableau 1 : F(w,p) est la frequence totale du couple (w,p), F(w) est
la frequence totale du mot w, et 0 est un coefficient de normalisation, choisi de telle sorte que
la somme des probabilites associees a un mot donne soit egale a 1.

4 Nous n’aVons pour le moment pas testé d’autres méthode de filtrage, comme celle de la distribution
polynomiale (Manning, 1993).

377

378

D. Bourigault, C. Frérot

T = { (w,p,w’) / F( w,p,w’) > 0 }, ensemble de triplets

F(w,p,w ’) : nombre de cas ou le mot w regit la preposition p, elle-
meme regissant le mot w’

F(w,0) : nombre de cas ou le mot w ne regit aucune preposition
Ewsp = { W’ / F( w,p,w’) > 0 }, le contexte du couple (w,p)
Prod(w,p) = Card(Ewsp), la productivite du couple (w,p)

F(W,p) = ° w’oEw,p F(W,p,W’)

F(w)=F(w,0)+ 0p F(w,p)

P(w,0) = F(w,0)/F(w)

P(w,p)=F(w,p) /F(w)*log(1 + Prod(w,p))/ 0

Tableau 1. Methode de calcul des probabilites de sous-categorisation

Le nombre total d’occurrences de triplets (w,p,w’) a partir desquels les probabilites sont
calculees est de l’ordre de 6,7 millions a l’issue de l’etape d’amorgage, et de 12 millions a
l’issue de l’etape de consolidation. Le nombre total d’occurrences de mots ne regissant pas de
preposition est d’enViron 87 millions a l’issue de l’etape d’amorgage , et de 95 millions a
l’issue de l’etape de consolidation. Les probabilites ne sont calculees que pour les couples
(w,p) tels que la frequence totale du mot w est superieure a 20. Un couple n’est retenu dans le
lexique de desambiguisation que si la probabilite depasse le seuil de 0.01. Le lexique final
compte 6 693 Verbes differents (chacun pouvant etre present avec plusieurs prepositions),
11 528 noms et 698 adjectifs.

4 Annotation

De fagon generale, le developpement d’un analyseur sy ntaxique robuste exige une methode de
travail qui assume la tres grande Variabilite des corpus sur le plan syntaxique. Les strategies et
regles des differents modules de Syntex sont a chaque experimentation elaborees a partir de
tests effectues sur plusieurs corpus, aussi diversifies que possible, pour limiter les biais
d’implementation que pourrait introduire une approche mono-corpus. A la Variabilite inter-
corpus, il faut ajouter la Variabilite intra-corpus. Pour eviter d’elaborer des regles trop
dependantes de telle ou telle configuration syntaxique ou unite lexicale, il faut sur chaque
corpus annoter a la main un tres grand nombre de cas. Dans le cadre de cette etude, nous
aVons eValue le lexique de sous-categorisation sur 4 corpus de test, de genres Varies, dans
lesquels nous aVons Valide a la main plusieurs centaines de cas :

0 BAL. Le roman « Splendeurs et miseres des courtisanes », d’Honore de Balzac
(199 789 mots) : 672 cas Valides

0 LMO. Un extrait du journal Le Monde (673 187 mots) : 1 238 cas Valides

Acquisition er évaluation sur corpus 

0 REA. Un corpus de comptes-rendus d’hospitalisation dans le domaine de la
reanimation chirurgicale (377 967 mots) : 646 cas Valides

0 TRA. Le Code du travail de la legislation francaise (509124 mots): 1 150 cas
Valides

Les regles d’annotation sont les suivantes : (1) ne pas Valider de cas ou il y a des erreurs
d’analyse des modules anterieurs, en particulier des erreurs d’etiquetage, autrement dit on
evalue le module de rattachement prepositionnel dans des contextes ou les informations sur
lesquelles il s’appuie sont justes ; (2) se donner la possibilite de retenir comme Valides deux
recteurs pour une preposition donnee, en particulier pour les constructions a Verbe support
(apporter une aide a) ; (3) ne pas Valider certains cas trop repetitifs, afin de ne pas sur
representer un cas trop specifique au corpus, comme par exemple dans le corpus CTRA, ou les
cas de rattachement des participes passes a la preposition sont massifs (ex: définir les
modalités visées a l’article) ; (4) Valider de maniere indifferenciee des groupes
prepositionnels arguments ou circonstants. Ce demier point est important, et peut préter a
controverse, si on ne replace pas la tache d’annotation dans le contexte de l’eValuation des

performances d’un analyseur syntaxique. La distinction argument/circonstant, ou complement
essentiel/complement circonstanciel, ne fait pas l’objet d’un consensus dans la communaute

linguistique. En dehors des cas trivaux, choisis en general soigneusement pour illustrer cette
distinction, la confrontation aVec des enonces reels met a mal la clarte de cette distinction
(Fabre, Frerot, 2002). Dans ces conditions, la tache essentielle devolue a l’analyseur est
d’abord de choisir le bon recteur parmi un ensemble de recteurs possibles, et ensuite
seulement, et eventuellement, de distinguer le type de complement.

5 Méthode de désambiguisation

L’algorithme de desambiguisation mis en oeuvre dans le module choisir-candidat est simple.
Nous comparons 4 strategies differentes, selon le type des donnees de sous-categorisation
qu’elles exploitent.

0 Mode base. En mode base, le module choisir-candidat se contente de choisir comme
recteur le premier candidat dans l’ordre lineaire de phrase, c’est -a-dire le plus eloigne
de la prepositions.

0 Mode exogéne. En mode exogene, le module choisir-candidat exploite le lexique de
sous-categorisation construit a partir du corpus LMl0 (section 3). Il choisit le
candidat dont la probabilite est la plus elevee. On distingue exogene 1 et exogene 2,
selon que le lexique utilise est obtenu apres la phase d’amorcage ou apres la phase de
consolidation.

0 Mode endogéne. En mode endogene, le module choisir-candidat exploite le lexique
de sous-categorisation construit a partir du corpus en cours d’analyse6. Avant

5 Globalement - sur 1’ensemble des corpus et sur 1’ensemble des configurations d’ambigu‘1‘té —, cette stratégie est
meilleure que celle qui choisirait le candidat le plus proche.

6 Selon la méthode décrite dans la section 3, sans 1’étape de consolidation.

379

380

D. Bourigault, C. Frérot

d’eXploiter les probabilites de sous -categorisation, il exploite la liste des frequences
des triplets (w,p,w’) construite par le module rechercher-candidats : si p est la
preposition et w’ le mot qu’elle regit, le module choisit le candidat wt. pour lequel la
frequence F(wl.,p,w’) est la plus elevee. Sinon, il choisit le candidat dont la probabilite
endogene est la plus elevee.

0 Mode mixte. Le mode mixte est analogue au mode endogene, a ceci pres que le
module choisir-candidat choisit le candidat qui a la probabilite endogene ou la
probabilite exogene la plus elevee.

Dans tous ces modes, la regle par defaut est celle de la strategie de base, a savoir le choix du
premier candidat.

BAL LMO REA TRA

base 83.0 70.3 59.9 65.5
endogene 83.5 80.1 78.0 82.3
exogene 1 85.7 85.5 65.3 85.9
exogene 2 86.9 86.6 66.3 86.3
mixte 86.6 85.9 78.3 87.3

Tableau 2. Taux de precision (%) des differentes strategies de desambiguisation
sur les 4 corpus de test

6 Résultats et discussion

Le tableau 2 donne les taux de precision des differentes strategies de desambiguisation
sur les 4 corpus de test. On peut rapprocher ces resultats de ceux, recapitules dans (Pantel et
Lin, 1998), obtenus sur 3 000 cas ambigus extraits de la partie Wall Street Journal du Penn
TreeBank par differentes methodes : 8l,6% aVec une methode supervisee utilisant un modele
d’entro pie maximale (Ratnaparkhi er al., 1994), 88,1% aVec une methode supervisee utilisant
un dictionnaire semantique (Stetina, Nagao, 1997) et 84.3% aVec une methode non supervisee
utilisant des mots distributionnellement proches (Pantel, Lin, 0p.cit.). Etant donne que les
langues, le type de corpus de test et les conventions d’annotations sont differentes, il est
delicat de comparer ces chiffres aVec ceux que nous presentons dans le tableau 4. Ceux-ci
doivent étre analyses de facon autonome et contrastive. Notons d’abord que les resultats des
strategies exogenes 1 et 2 justifient l’interét d’acquerir les informations de sous -categorisation
en 2 etapes (amorcage et consolidation, section 3). Le corpus medical (REA), qui est le plus
specialise des 4 corpus de test, presente un comportement particulier. Sur ce corpus, les
performances des differentes strategies sont globalement moins bonnes que sur les 3 autres
corpus, ce qui illustre le point que nous aVons evoque au debut de cet article, a propos de la
sensibilite des resultats des analyseurs aux genres des textes. Par ailleurs, la strategie de base
donne de tres mauvais resultats sur ce corpus, alors qu’ils sont particulierement bons sur le
corpus litteraire. C’est uniquement sur le corpus medical qu’apparait, de facon nette, la

Acquisition et e’valuation sur corpus 

necessite d’exploiter des probabilites de sous -categorisation specifiques au corpus
(apprentissage endogene). Sur ce corpus, la strategie endogene donne de meilleurs resultats
que la strategie exogene, et la strategie mixte est tres legerement superieure a la strategie
endogene. Sur les corpus litteraire et journaliste, la strategie exogene est meilleure que la
strategie mixte.

Les ressources de sous-categorisation syntaxique construites a partir du corpus LM10 sont
exploitees par l’analyseur sans avoir ete Validees manuellement, et les resultats montrent
qu’elles sont performantes pour cette tache. Il convient de preciser que, sur le plan
linguistique, ces proprietes de sous-categorisation ne sont pas comparables aux descriptions
que l’on peut trouver dans des lexiques construits a la main, comme le Lexique Grammaire,
dans les dictionnaires de langue ou dans les etudes de psycholinguistique. C’est
particulierement Vrai pour les Verbes. La probabilite qu’a un Verbe de sous -categoriser telle
preposition est calculee a partir de toutes les occurrences (lemmatisees) de ce Verbe, sans
distinction des differentes acceptions du Verbe, alors que l’on sait qu’un meme Verbe peut
avoir des cadres de sous-categorisation differents selon ses differents sens. Dans le contexte
du developpement d’un analyseur syntaxique « tout terrain », l’approximation a laquelle
conduit ce lissage des sens est un mal necessaire.

Références

AiT-MOKTAR S., CHANOD J .-P, ROUX C. (2002), Robustness beyond shallowness
incremental deep parsing, Natural Language Engineering Journal, 8(2/3): 121-147

BASILI R., PAZIENZA M.-T., VINDIGNI M. (1999), Adaptative Parsing and Lexical Learning,
Proceedings of VEXTAL ’99 , Venise

BASILI R., VINDIGNI M. (1998), Adapting a Subcategorization Lexicon to a Domain,
Proceedings of the ECML98 Workshop TANLPS, Chemnitz, Germany

BOURIGAULT D. (1993), An endogenous Corpus Based Method for Structural Noun Phrase
Disambiguation, In Proceedings of the 6;}. Conference of the European Chapter of ACL
(EACL), pp. 81-86, Utrecht, The Netherlands

BOURIGAULT D., FABRE C. (2000), Approche linguistique pour l’analyse syntaxique de
corpus, Cahiers de Grammaire, 25, Universite Toulouse le Mirail, pp. 131-151

CHARNIAK E. (1997), Statistical Parsing with a Contexte-Free Grammar and Word Statistics.
Proceedings of the AAAI97 Conference, Browne University, Rhode Island, pp.598-603

FABRE C., FREROT C (2002), Groupes prepositionnels arguments ou circonstants: Vers un
reperage automatique en corpus. Actes de la Conference TALN, pp. 215-224.

FREROT C. (2005), Etude en corpus varie’s sur l’inte’gration de ressources linguistiques
ge’ne’rales dans un analyseur syntaxique, These en sciences du langage de l’UniVersite
Toulouse le Mirail

381

382

D. Bourigault, C. Fre’rot

FREROT C., BOURIGAULT D., FABRE C. (2003), Marier apprentissage endogene et ressources
exogenes dans un analyseur syntaxique de corpus. Le cas du rattachement Verbal a distance de
la preposition « de », in Revue t.a.l., 44-3

GALA PAVIA N. (2003), Un modele d ’analyseur syntaxique robuste base’ sur la modularite’ et
la lexicalisation de ses grammaires, PhD, University of Paris XI, Orsay

GILDEA D. (2001), Corpus Variation and Parser Performance. In Lillian Lee and Donna
Harma, editors, in Proceedings of the 200] Conference on Empirical Methods in Natural
Language Processing, pp. 167-202

HINDLE D., ROOTH M. (1993), Structural Ambiguity and Lexical Relations. Computational
Linguistics, 19(1):103-120

KILGARRIFF A., GREFENSTETTE G. (2003), Introduction to the special issue of Web as
Corpus. Computational Linguistics, 29:3, pp. 333-338

MANNING C. (1993), Automatic Acquisition of Large Subcategorization Dictionary from
Corpora, Proceedings of the 315; Meeting of the Association for Computational Linguistics,
Columbus

PANTEL P., LIN D. (2000), An unsupervised approach to prepositional phrase attachment
using contextually similar words. In K. VijayShanker and Chang-Ning Huang, editors,
Proceedings of the 38th Meeting of the Association for Computational Linguistics, pp. 101-
108, Hong Kong

RATNAPARKH1 A., REYNAR J ., ROUKOS S. (1994), A Maximum Entropy Model for
Prepositional Phrase Attachment. Proceedings of the ARPA Workshop on Human Language
Technology, Morgan Kaufmann

ROLAND D., J URAFSKY, D. (1998). How Verb Subcategorization Frequencies Are Affected By
Corpus Choice. Proceedings of Coling-ACL, pp. 1122-1128

SEKINE S. (1997), The domain dependence of parsing. Proceedings of the F ith Conference on
Applied Natural Language Processing, pp. 96-102

SLOCUM J. (1986), How one might Automatically Identify and Adapt to a Sublanguage: An
Initial Exploration, in Grishman R. and Kittredge R., eds., Analyzing Language in Restricted
Domains: Sublanguage Description and Processing. Lawrence Erlbaum Associates,
Hillsdale, N.J., 1986, pp. 195-210

STETINA J., NAGAO M. (1997), Corpus-based PP attachment ambiguity resolution with a
semantic dictionary. In J. Zhou and K. Church editors, Proceedings of the 5;». Workshop on
Very Large Corpora, Beijing and Hongkong.

