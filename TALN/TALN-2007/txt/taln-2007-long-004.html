<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Identifier les pronoms anaphoriques et trouver leurs ant&#233;c&#233;dents : l&#8217;int&#233;r&#234;t de la classification bay&#233;sienne</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2007, Toulouse, 5&#8211;8 juin 2007
</p>
<p>Identifier les pronoms anaphoriques et trouver leurs
ant&#233;c&#233;dents : l&#8217;int&#233;r&#234;t de la classification bay&#233;sienne
</p>
<p>Davy WEISSENBACHER, Adeline NAZARENKO
Universit&#233; Paris-Nord, LIPN, 99 av. J-B. Cl&#233;ment, F-93430 Villetaneuse
</p>
<p>{dw,nazarenko}@lipn.univ-paris13.fr
</p>
<p>R&#233;sum&#233;. On oppose souvent en TAL les syst&#232;mes &#224; base de connaissances linguistiques
et ceux qui reposent sur des indices de surface. Chaque approche a ses limites et ses avantages.
Nous proposons dans cet article une nouvelle approche qui repose sur les r&#233;seaux bay&#233;siens
et qui permet de combiner au sein d&#8217;une m&#234;me repr&#233;sentation ces deux types d&#8217;informations
h&#233;t&#233;rog&#232;nes et compl&#233;mentaires. Nous justifions l&#8217;int&#233;r&#234;t de notre approche en comparant les
performances du r&#233;seau bay&#233;sien &#224; celles des syst&#232;mes de l&#8217;&#233;tat de l&#8217;art, sur un probl&#232;me diffi-
cile du TAL, celui de la r&#233;solution d&#8217;anaphore.
Abstract. In NLP, a traditional distinction opposes linguistically-based systems and know-
ledge-poor ones, which mainly rely on surface clues. Each approach has its drawbacks and its
advantages. In this paper, we propose a new approach based on Bayes Networks that allows to
combine both types of information. As a case study, we focus on the anaphora resolution which
is known as a difficult NLP problem. We show that our bayesain system performs better than a
state-of-the art one for this task.
Mots-cl&#233;s : r&#233;seaux bay&#233;siens, r&#233;solution des anaphores, connaissance linguistique, in-
dice de surface.
</p>
<p>Keywords: bayesian network, anaphora resolution, linguistic knowledge, surface clue.
</p>
<p>1 Introduction
On oppose souvent en TAL les syst&#232;mes qui exploitent des connaissances linguistiques et ceux
qui reposent sur des indices de surface. Les premiers syst&#232;mes ne sont pas toujours fiables parce
qu&#8217;ils exploitent des connaissances complexes qui peuvent &#234;tre erron&#233;es lorsqu&#8217;elles sont cal-
cul&#233;es automatiquement ou incompl&#232;tes lorsqu&#8217;elles sont produites manuellement. Les seconds
syst&#232;mes s&#8217;appuient g&#233;n&#233;ralement sur des m&#233;thodes d&#8217;apprentissage automatique et sur des in-
dices de surface qui sont plus faciles &#224; obtenir mais qui ne permettent de traiter que les cas
simples ou les plus courants de la t&#226;che d&#233;volue au syst&#232;me.
Dans cet article nous proposons une nouvelle approche qui permet de d&#233;passer cette opposition
entre syst&#232;mes &#171;pauvres&#187; et syst&#232;me &#171;riches&#187; en connaissances. Cette approche repose sur le
formalisme des r&#233;seaux bay&#233;siens. Ce formalisme est encore peu exploit&#233; en TALmais il repose
sur un mod&#232;le probabiliste con&#231;u pour raisonner sur des informations incertaines, partielles et
manquantes.
</p>
<p>47</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Davy WEISSENBACHER, Adeline NAZARENKO
</p>
<p>Nous validons notre approche sur la t&#226;che de la r&#233;solution automatique des anaphores o&#249;, en
raison de la complexit&#233; et du nombre de connaissances n&#233;cessaires, l&#8217;opposition des syst&#232;mes &#224;
base de connaissances linguistiques et d&#8217;indices de surface est tr&#232;s marqu&#233;e. Apr&#232;s avoir valid&#233;
l&#8217;approche en d&#233;veloppant un premier classifieur bay&#233;sien qui permet de distinguer pronoms
impersonnels et pronoms anaphoriques, nous analysons les performances d&#8217;un second classi-
fieur qui trouve l&#8217;ant&#233;c&#233;dent des pronoms anaphoriques.
La section suivante revient sur les raisons de l&#8217;opposition pr&#233;c&#233;dente dans le cadre de la r&#233;so-
lution des anaphores pronominales. La section 3 d&#233;crit le mod&#232;le des r&#233;seaux bay&#233;siens et son
int&#233;r&#234;t pour le TAL. Dans la section 4 nous validons notre approche en comparant les perfor-
mances de diff&#233;rents syst&#232;mes pour la distinction des pronoms impersonnels et anaphoriques.
Enfin, la derni&#232;re section pr&#233;sente un classifieur pour la t&#226;che compl&#232;te de la r&#233;solution des
anaphores et compare ses r&#233;sultats par rapport &#224; l&#8217;&#233;tat de l&#8217;art.
</p>
<p>2 La compl&#233;mentarit&#233; des connaissances linguistiques et des
indices de surface
</p>
<p>2.1 Le choix des indices de surface
L&#8217;anaphore est une relation linguistique entre deux entit&#233;s textuelles d&#233;finie lorsqu&#8217;une entit&#233;
textuelle (l&#8217;anaphore) renvoie &#224; une autre entit&#233; du texte (l&#8217;ant&#233;c&#233;dent). Comme la pr&#233;sence
d&#8217;anaphores d&#233;grade consid&#233;rablement les performances des syst&#232;mes de TAL, la question de
leur r&#233;solution est &#233;tudi&#233;e depuis longtemps. Ce travail se limite &#224; la r&#233;solution de l&#8217;anaphore
du pronom it dans les textes anglais, l&#8217;anaphore la mieux connue et la plus facile &#224; r&#233;soudre.
L&#8217;approche classique pour sa r&#233;solution automatique distingue trois &#233;tapes : la distinction des
pronoms anaphoriques et impersonnels (it is known that... vs it produced...), la s&#233;lection des
candidats possibles &#224; l&#8217;ant&#233;c&#233;dence et le choix de l&#8217;ant&#233;c&#233;dent. Pour chaque &#233;tape, les premiers
syst&#232;mes propos&#233;s dans la litt&#233;rature exploitaient des connaissances linguistiques complexes
traduisant les contraintes syntaxiques et s&#233;mantiques qui r&#233;gissent l&#8217;anaphore. Comme le calcul
automatique de ces connaissances &#233;tait consid&#233;r&#233; comme impossible ou trop peu fiable pour &#234;tre
utilisable, ces connaissances linguistiques &#233;taient produites manuellement, ce qui pr&#233;supposait
un important travail d&#8217;analyse pr&#233;alable des textes.
Durant les ann&#233;es 1990, devant le besoin de syst&#232;mes de r&#233;solution robustes et peu co&#251;teux &#224;
mettre en place, un nombre important de syst&#232;mes &#224; bases d&#8217;indices de surface ont &#233;t&#233; propo-
s&#233;s (Mitkov, 2002). Ces syst&#232;mes abandonnent les connaissances linguistiques complexes des
premiers syst&#232;mes. Ils approchent les connaissances n&#233;cessaires par des indices plus simples &#224;
calculer et que l&#8217;on suppose plus fiables.
Pour la distinction des pronoms anaphoriques, (Husk &amp; Paice, 1987) a ainsi propos&#233; un en-
semble d&#8217;automates encodant des connaissances linguistiques et permettant de reconna&#238;tre les
s&#233;quences contenant des pronoms impersonnels. Jugeant que ces automates avaient une couver-
ture trop faible, (Evans, 2001) propose une voie alternative reposant sur l&#8217;apprentissage auto-
matique des indices de surface pour reconna&#238;tre les s&#233;quences caract&#233;ristiques. Pour le choix de
l&#8217;ant&#233;c&#233;dent, les connaissances syntaxico-s&#233;mantiques sont approch&#233;es de la m&#234;me mani&#232;re par
des m&#233;thodes robustes. On sait que les sch&#233;mas pr&#233;dicat-argument am&#233;liorent les r&#233;sultats du
filtrage (Ponzetto &amp; Strube, 2006), mais comme ces ressources ne sont pas toujours disponibles,
</p>
<p>48</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L&#8217;int&#233;r&#234;t de la classification bay&#233;sienne
</p>
<p>on a cherch&#233; &#224; les approcher par un calcul fr&#233;quentiel : les r&#233;gularit&#233;s des coocurrences entre
les sujets, les compl&#233;ments et les verbes dessinent les contours des classes s&#233;mantiques. Les
auteurs de (Dagan &amp; Itai, 1990) montrent que les contraintes obtenues peuvent partiellement
remplacer les connaissances s&#233;mantiques.
</p>
<p>2.2 Les limites des indices de surface
Si les indices approch&#233;s propos&#233;s lors des ann&#233;es 1990 ont permis l&#8217;impl&#233;mentation de sys-
t&#232;mes robustes (Mitkov, 2002), leur apport et leurs limites &#233;taient mal connus. Des travaux
r&#233;cents commencent &#224; en mesurer les limites. L&#8217;&#233;tude de (Kehler et al., 2001) montre ainsi que
les fr&#233;quences de (Dagan &amp; Itai, 1990) n&#8217;am&#233;liorent pas les performances d&#8217;un syst&#232;me qui
exploite d&#233;j&#224; des informations morpho-syntaxiques. Les auteurs en concluent que l&#8217;apport des
fr&#233;quences tient davantage du hasard que d&#8217;une v&#233;ritable capture du sens s&#233;mantique.
Les limites rencontr&#233;es par les syst&#232;mes &#224; base d&#8217;indices de surface nous renvoient au pro-
bl&#232;me initial. Nous avons besoin de connaissances s&#233;mantiques et syntaxiques complexes pour
la r&#233;solution de l&#8217;anaphore pronominale. Ces connaissances linguistiques, lorsqu&#8217;elles sont dis-
ponibles, ne sont pas fiables. On peut chercher &#224; les remplacer par des indices de surface dont le
calcul est toujours r&#233;alisable et plus fiable mais ces indices peuvent ne pas exprimer, ou seule-
ment de mani&#232;re impr&#233;cise, les connaissances n&#233;cessaires &#224; la r&#233;solution, ce qui produit des
erreurs.
Nous proposons une mod&#233;lisation reposant sur les R&#233;seaux Bay&#233;siens (RB), con&#231;u pour raison-
ner sur des donn&#233;es incertaines et incompl&#232;tes. Cette approche probabiliste offre la possibilit&#233;
d&#8217;unifier dans une unique repr&#233;sentation connaissances linguistiques et indices de surface. Cette
unification permet de corroborer les connaissances linguistiques gr&#226;ce aux indices de surface
qui sont observ&#233;s en corpus. A l&#8217;inverse, l&#8217;exploitation de connaissances linguistiques permet
de corriger certaines des erreurs des syst&#232;mes &#224; base d&#8217;indices de surface.
</p>
<p>3 Une approche int&#233;gr&#233;e : le mod&#232;le bay&#233;sien
</p>
<p>3.1 Des probl&#232;mes de classification
La distinction des pronoms impersonnels comme le choix de l&#8217;ant&#233;c&#233;dent sont des t&#226;ches qui,
comme de nombreuses t&#226;ches du TAL, se reformulent facilement en probl&#232;mes de classification.
Consid&#233;rons par exemple la classification des pronoms impersonnels et anaphoriques : soit Cor-
pus un ensemble de textes d&#8217;un m&#234;me domaine, Corpus_entra&#238;nement et Corpus_test deux
sous-ensembles stricts disjoints de Corpus, C1 et C2 les classes des occurrences des pronoms
impersonnels et anaphoriques pr&#233;sents dans Corpus. e est une occurrence d&#8217;un pronom pr&#233;sent
dans Corpus d&#233;crit par un vecteur a = v1, ...va d&#8217;attributs &#224; valeurs dans R. Pour les occur-
rences de Corpus_entra&#238;nement, les valeurs des attributs vi sont obtenues &#224; partir d&#8217;une analyse
humaine du corpus : elles repr&#233;sentent selon les cas des connaissances linguistiques ou des
indices de surface.
Le th&#233;or&#232;me de Bayes dit comment pr&#233;dire la meilleure classe d&#8217;appartenance pour une occur-
rence d&#8217;un pronom inconnu de Corpus_test sur la base d&#8217;observations faites sur les occurrences
</p>
<p>49</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Davy WEISSENBACHER, Adeline NAZARENKO
</p>
<p>de Corpus_entrainement. La classe s&#233;lectionn&#233;e doit maximiser la probabilit&#233;
</p>
<p>P (Ci|E) =
P (E|Ci)&#8727;P (Ci)
</p>
<p>P (E)
</p>
<p>o&#249; Ci&#8712;{C1, C2}, E une occurrence du corpus de test et P (Ci|E) la probabilit&#233; conditionnelle
que E appartienne &#224; la classe Ci sachant la valeur des attributs de E, une probabilit&#233; estim&#233;e &#224;
partir des donn&#233;es d&#8217;entra&#238;nement. Si nous imposons la contrainte d&#8217;ind&#233;pendance des attributs,
le classifieur est un &#171;classifieur bay&#233;sien na&#239;f&#187;. Les attributs &#233;tant ind&#233;pendants, la probabilit&#233;
P (E|Ci) se d&#233;compose en P (v1|Ci) &#8727; ... &#8727; P (va|Ci) et la probabilit&#233; &#224; maximiser se reformule
en
</p>
<p>P (Ci|E) =
P (Ci)
P (E)
</p>
<p>a
</p>
<p>&#928;j=1 P (vj|Ci)
</p>
<p>Pour tout E de Corpus_test, un classifieur bay&#233;sien attribue la classe C1 &#224; l&#8217;exemple E si
P(Pronom=Impersonnel|E)&#8805;P(Pronom=Anaphorique|E) et la classe C2 sinon.
</p>
<p>3.1.1 Le choix des attributs pour la classification
</p>
<p>L&#8217;un des premiers syst&#232;mes distinguant les pronoms it impersonnels et anaphoriques (Husk &amp;
Paice, 1987) s&#8217;appuie sur un ensemble de r&#232;gles de logique du 1er ordre pour reconna&#238;tre les
s&#233;quences qui contiennent une occurrence du pronom impersonnel. Les s&#233;quences qui intro-
duisent les it impersonnels partagent une forme remarquable : elles commencent par un it et se
terminent par un d&#233;limiteur comme to, that, whether.... Les r&#232;gles varient selon le d&#233;limiteur.
Les tests r&#233;alis&#233;s par Paice montrent que ces r&#232;gles r&#233;alisent un bon score avec 91,4%Acc 1 sur
un corpus technique. Cependant les performances sont d&#233;grad&#233;es si on applique les r&#232;gles &#224; des
corpus de nature diff&#233;rente. Le nombre de faux positifs (FP) augmente : certains attributs sont
discriminants sur les corpus techniques mais ne le sont plus sur des corpus de nature diff&#233;rente.
Afin d&#8217;&#233;viter cet &#233;cueil, (Lappin &amp; Leass, 1994) d&#233;crit enti&#232;rement les s&#233;quences au moyen
d&#8217;automates &#224; &#233;tats finis de la forme It is not/may be&lt;Modaladj&gt; ; It is &lt;Cogv-ed&gt; that
&lt;Subject&gt; o&#249; &lt;Modaladj&gt; et &lt;Cogv&gt; d&#233;notent des classes d&#8217;adjectifs modaux et de verbes
cognitifs connus pour introduire des it impersonnels (par exemple necessary, possible et recom-
mend, think). Ce syst&#232;me a une bonne pr&#233;cision (il produit peu de FP), mais il a un mauvais
rappel (il produit beaucoup de FN) : seules les s&#233;quences exactes sont reconnues et il est tou-
jours difficile d&#8217;obtenir des classes d&#8217;adjectifs et de verbes exhaustives.
(Evans, 2001) renonce &#224; exploiter des connaissances linguistiques aussi complexes et se concentre
sur des attributs plus fiables, les indices de surface. Evans consid&#232;re 35 indices syntaxiques et
contextuels (ex. la position du pronom dans la phrase, le lemme du verbe suivant...). Un syst&#232;me
d&#8217;apprentissage, utilisant la m&#233;thode des K plus proches voisins, d&#233;termine le poids des attri-
buts discriminants pour le domaine du corpus et classe les occurrences inconnues. Les premiers
essais r&#233;alisent un score de 71,31%Acc satisfaisant sur un corpus de langue g&#233;n&#233;rale. (Litran
et al., 2004) reproduit un essai identique avec une Machine &#224; Support de Vecteur (SVM) sur un
corpus de g&#233;nomique et obtient un score de 92,71%Acc.
</p>
<p>1L&#8217;exactitude, en anglais Accuracy : Acc= V P+V N
V P+V N+FP+FN
</p>
<p>, o&#249; les faux positifs (FP) correspondent aux oc-
currences d&#8217;un pronom anaphorique &#233;tiquet&#233;es impersonnelles, les faux n&#233;gatifs (FN) les occurrences de pronoms
impersonnels &#233;tiquet&#233;es anaphoriques, les vrais positifs (VP) et les vrais n&#233;gatifs (VN) correctement &#233;tiquet&#233;es
comme impersonnels et anaphoriques, respectivement.
</p>
<p>50</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L&#8217;int&#233;r&#234;t de la classification bay&#233;sienne
</p>
<p>95.0 90.0 15.0 15.0
10.05.0 85.0 85.0
</p>
<p>85.0
99.515.0
0.5
</p>
<p>I A
</p>
<p>45.0   65.0
55.0    35.0
</p>
<p>30.0
70.0
</p>
<p>Start_Sentence
</p>
<p>Pronun=Anaphoric
</p>
<p>Pronoun Lappin_Rules
</p>
<p>Paice_Rules
Pronoun
</p>
<p>I A
Pronoun
</p>
<p>Pronoun, Start_Sentence
</p>
<p>Lappin_Rules=Match
Lappin_Rules=No_Match
</p>
<p>Paice_Rules=Match
Paice_Rules=No_MatchStart_Sentence=No_Start
</p>
<p>Start_Sentence=Start
I,S I,N A,S A,N
</p>
<p>Pronoun=Impersonal
</p>
<p>FIG. 1 &#8211; Exemple d&#8217;un classifieur bay&#233;sien mod&#233;lis&#233; par un r&#233;seau bay&#233;sien
</p>
<p>Ces deux derniers syst&#232;mes d&#8217;apprentissage reposent donc uniquement sur des indices de sur-
face. Constatant que les connaissances linguistiques sont peu fiables ou incompl&#232;tes, les au-
teurs renoncent &#224; les utiliser comme attributs. Ce choix nous para&#238;t trop radical : d&#232;s lors que
ces connaissances linguistiques sont pertinentes pour notre t&#226;che, il faut les int&#233;grer dans la
d&#233;cision sous la forme d&#8217;attributs mais en se donnant les moyens de raisonner sur des attributs
h&#233;t&#233;rog&#232;nes et de qualit&#233; variable.
</p>
<p>3.1.2 L&#8217;inf&#233;rence sur des attributs imparfaits
</p>
<p>Le RB est un mod&#232;le con&#231;u pour raisonner sur des attributs incertains et incomplets. Il est
compos&#233; d&#8217;une description qualitative de leurs d&#233;pendances, un graphe orient&#233; sans circuits, et
d&#8217;une description quantitative, un ensemble de probabilit&#233;s conditionnelles o&#249; chaque Variable
Al&#233;atoire (VA) est associ&#233;e &#224; un noeud du graphe. Une 1er &#233;tape de param&#233;trage permet de
repr&#233;senter les connaissances a priori pour chaque VA sous la forme d&#8217;une table de probabilit&#233;s
conditionnelles. L&#8217;&#233;tape suivante, l&#8217;&#233;tape d&#8217;inf&#233;rence, consiste &#224; r&#233;viser certaines probabilit&#233;s
a priori pour obtenir des probabilit&#233;s a posteriori et &#224; modifier en cons&#233;quence les valeurs
des VA correspondantes &#224; partir d&#8217;observations faites en corpus. Ces nouvelles informations
sont propag&#233;es au travers du r&#233;seau et permettent de r&#233;viser les valeurs a priori m&#234;me pour les
variables non-observ&#233;es.
Expliquons sur un exemple tr&#232;s simplifi&#233; le m&#233;canisme d&#8217;inf&#233;rence du r&#233;seau de la figure 1,
un r&#233;seau destin&#233; &#224; la classification des pronoms it. La 1er &#233;tape de param&#233;trage du r&#233;seau,
permet de calculer les valeurs a priori des probabilit&#233;s. Sur l&#8217;analyse des fr&#233;quences d&#8217;un cor-
pus d&#8217;entra&#238;nement ou &#224; partir de l&#8217;estimation d&#8217;un expert, nous &#233;tablissons a priori qu&#8217;en-
viron un tiers des pronoms it du corpus sont impersonnels, P(Pronoun=Impersonal)=0,3. Un
lien d&#8217;influence relie les variables Pronom et Lappin_Rules, indiquant qu&#8217;un it a d&#8217;autant
plus de chance d&#8217;&#234;tre reconnu par une r&#232;gle de (Lappin &amp; Leass, 1994) qu&#8217;il est impersonnel.
De m&#234;me, les liens entre les variables Pronoun et Paice_Rules d&#8217;une part, Pronoun et
Start_Sentence d&#8217;autre part indiquent respectivement qu&#8217;un it a d&#8217;autant plus de chance
d&#8217;&#234;tre reconnu par une r&#232;gle de (Husk &amp; Paice, 1987) et d&#8217;&#234;tre en d&#233;but de phrase qu&#8217;il est im-
personnel. L&#8217;arc (Start_Sentence,Paice_Rules) unit les deux variables, car, toujours
au regard du corpus d&#8217;entra&#238;nement ou de l&#8217;estimation de l&#8217;expert, elles ne sont pas ind&#233;pen-
dantes. La fiabilit&#233; de la r&#232;gle de (Husk &amp; Paice, 1987) reconnaissant une s&#233;quence est aug-
ment&#233;e si la s&#233;quence est situ&#233;e en d&#233;but de phrase. Cette influence est mesur&#233;e par la table de
probabilit&#233;s conditionnelles associ&#233;e au noeud Paice_Rules de la figure 1.
Une fois l&#8217;ensemble des probabilit&#233;s conditionnelles d&#233;termin&#233;, l&#8217;&#233;tape d&#8217;inf&#233;rence d&#233;bute.
</p>
<p>51</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Davy WEISSENBACHER, Adeline NAZARENKO
</p>
<p>Anaphorique
Impersonnel
Pronom
</p>
<p>Inconnu
Connu
</p>
<p>Un
Deux
Trois
Plus
</p>
<p>Mot_inconnu
</p>
<p>Longueur_Pronom_Delimiteur
</p>
<p>Non_debut
Debut
</p>
<p>Debut
Non!debut
</p>
<p>Inconnu
Connu
</p>
<p>Reconnu
Non_reconnu
</p>
<p>Regle_Lappin
</p>
<p>...
Inferieur_trois
</p>
<p>trois
Superieur!onze
</p>
<p>Pronom_Role_Grammatical
</p>
<p>Objet
Sujet
</p>
<p>Autre
Preposition
</p>
<p>Non_reconnu
Reconnu
Regle_Paice
</p>
<p>Non_Preposition
Preposition
</p>
<p>Mot_Precedent_Pronom
</p>
<p>To
That
</p>
<p>Whether!if
Which!Who
</p>
<p>Other
</p>
<p>Delimiteur
</p>
<p>Mot
Virgule
Point
</p>
<p>Sequence_Contient_Verbe
</p>
<p>Pronom_Debut_Resume
</p>
<p>Pronom_Debut_Phrase
Sequence_Contient_Nom
</p>
<p>Sequence_Contient_Adjectif
</p>
<p>Inconnu
Connu
</p>
<p>Pronom_Debut_Proposition
</p>
<p>FIG. 2 &#8211; Un R&#233;seau Bay&#233;sien pour la classification des pronoms it impersonnels
</p>
<p>Consid&#233;rons par exemple la phrase It is well documented that treatment of serum-grown....
Nous appliquons les r&#232;gles de (Lappin &amp; Leass, 1994) et les r&#232;gles de (Husk &amp; Paice, 1987)
sur cette s&#233;quence. Aucune r&#232;gle de (Lappin &amp; Leass, 1994) ne reconna&#238;t la s&#233;quence, nous
posons P(Lappin_Rules = No_Match)=1. Une r&#232;gle de (Husk &amp; Paice, 1987) la reconna&#238;t, nous
posons P(Paice_Rules = Match)=1 et comme la s&#233;quence se situe en d&#233;but de phrase nous po-
sons aussi P(Start_Sentence = Start)=1. En repr&#233;sentant graphiquement l&#8217;ind&#233;pendance condi-
tionnelle des VA, le RB permet de compacter la loi jointe globale. A l&#8217;aide des probabilit&#233;s
conditionnelles fournies en param&#232;tres nous pouvons inf&#233;rer la probabilit&#233; qui nous int&#233;resse :
P(Pronoun=Impersonal|Lappin_Rules=No_Match, Start_Sentence=Start, Paice_Rules=Match)
Du fait qu&#8217;une r&#232;gle de (Husk &amp; Paice, 1987) a reconnu la s&#233;quence et que l&#8217;occurrence se
trouve en d&#233;but de phrase, le r&#233;seau inf&#232;re une probabilit&#233; de 38,9% pour l&#8217;occurrence d&#8217;&#234;tre im-
personnelle. Nous pouvons modifier cette conclusion en ajoutant d&#8217;autres variables au r&#233;seau ou
en raisonnant avec des observations incertaines ou manquantes. On peut par exemple indiquer
que la fiabilit&#233; de l&#8217;observation est inf&#233;rieure &#224; 100% et poser P(Lappin_Rules=No_Match)=0,9
pour tenir compte de l&#8217;incompl&#233;tude des r&#232;gles de (Lappin &amp; Leass, 1994).
</p>
<p>4 1re exp&#233;rience : l&#8217;identification des pronoms impersonnels
</p>
<p>4.1 Le protocole exp&#233;rimental
</p>
<p>L&#8217;objectif de cette premi&#232;re exp&#233;rience est de valider notre mod&#232;le (on trouvera dans (Weissen-
bacher &amp; Nazarenko, 2007) une description pr&#233;cise du syst&#232;me d&#233;velopp&#233; et une analyse plus
compl&#232;te des r&#233;sultats obtenus). Nous avons mesur&#233; les performances du Classifieur Bay&#233;sien
(CB) de la figure 22, ainsi que celles du classifieur bay&#233;sien na&#239;f (CBN) associ&#233;3, puis nous les
avons compar&#233;es avec celles des syst&#232;mes de l&#8217;&#233;tat de l&#8217;art.
</p>
<p>2Les attributs repr&#233;sentant le fait qu&#8217;une r&#232;gle de (Lappin &amp; Leass, 1994) ait reconnu une s&#233;quence sont color&#233;s
en gris, en blanc ceux qui correspondent aux r&#232;gles de (Husk &amp; Paice, 1987), enfin en noir les attributs de (Litran
et al., 2004) et (Evans, 2001). Le noeud de pr&#233;diction est le noeud Pronom, au centre. Il estime la probabilit&#233; pour
une occurrence donn&#233;e de pronom d&#8217;&#234;tre impersonnel ou anaphorique.
</p>
<p>3Le classifieur bay&#233;sien na&#239;f poss&#232;de les m&#234;mes attributs mais sa structure est diff&#233;rente : le noeud Pronom est
li&#233; &#224; tous les noeuds et ces derniers ne sont li&#233;s &#224; aucun autre.
</p>
<p>52</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L&#8217;int&#233;r&#234;t de la classification bay&#233;sienne
</p>
<p>M&#233;thode R&#233;sultats
R&#232;gles De (Lappin &amp; Leass, 1994) 88,11% 12,8 169,1
R&#232;gles De (Husk &amp; Paice, 1987) 88,88% 123,6 24,2
Machine &#224; Vecteurs de Support 92,71% - -
Classifieur Bay&#233;sien na&#239;f 92,58% 74,1 19,5
Classifieur Bay&#233;sien 95,91% 21,0 38,2
</p>
<p>TAB. 1 &#8211; R&#233;sultats des pr&#233;dictions (Exactitude/Faux Positifs/Faux N&#233;gatifs)
</p>
<p>Nous avons travaill&#233; sur un corpus de r&#233;sum&#233; d&#8217;articles de g&#233;nomique construit &#224; partir de
la base Medline interrog&#233;e avec les mots cl&#233;s bacillus subtilis, transcription factors, Human,
blood cells, gene and fusion. Nous en avons extrait 11 966 r&#233;sum&#233;s (environ 5 millions de mots)
o&#249; nous avons identifi&#233; 3347 occurrences du pronom it. Deux annotateurs humains ont class&#233;
chaque occurrence du pronom soit comme anaphorique soit comme impersonnelle. L&#8217;accord
des annotateurs fut entier apr&#232;s discussion.
Notre corpus &#233;tant de taille moyenne, nous avons proc&#233;d&#233; &#224; une validation crois&#233;e pour valider
nos r&#233;sultats. Nous s&#233;lectionnons al&#233;atoirement 2/3 du corpus pour calculer les probabilit&#233;s
conditionnelles a priori. Nous appliquons ensuite notre CB, ainsi que le CBN, param&#233;tr&#233;s gr&#226;ce
&#224; ces probabilit&#233;s sur le tiers restant. Nous r&#233;it&#233;rons 20 fois ces op&#233;rations pour obtenir une
moyenne des performances de chaque syst&#232;me sur le corpus.
</p>
<p>4.2 R&#233;sultats
</p>
<p>Le tableau 1 r&#233;sume les moyennes des r&#233;sultats (en exactitude) obtenus par les syst&#232;mes de
l&#8217;&#233;tat de l&#8217;art d&#233;crits plus haut4 et celles des deux classifieurs. Ces r&#233;sultats montrent que le
CB produit une meilleure classification que les autres syst&#232;mes, notamment les syst&#232;mes &#224; base
de r&#232;gles. Ces r&#233;sultats valident notre mod&#232;le : le CB exploite tous les attributs pertinents et
corrige le bruit d&#8217;un attribut par la fiabilit&#233; des autres. Priv&#233; des relations de d&#233;pendance entre
les attributs, le CBN ne b&#233;n&#233;ficie pas du m&#233;canisme de correction et surestime leurs fiabilit&#233;s.
Les syst&#232;mes &#224; base de r&#232;gles sont quant &#224; eux enti&#232;rement assujettis &#224; la fiabilit&#233; des attributs.
Les r&#233;sultats confirment les craintes soulev&#233;es dans la section 3.1.1 : on obtient un faible rappel
pour les r&#232;gles de (Lappin &amp; Leass, 1994) et une mauvaise pr&#233;cision pour celles de (Husk &amp;
Paice, 1987).
</p>
<p>5 2nde exp&#233;rience : la r&#233;solution des anaphores
</p>
<p>Assur&#233;s des bonnes performances de notre mod&#232;le sur la distinction des pronoms impersonnels,
nous proposons un classifieur bay&#233;sien pour la r&#233;solution d&#8217;anaphore.
</p>
<p>4Nous avons ajout&#233; le score du SVM obtenu par (Litran et al., 2004) sur un corpus de g&#233;nomique similaire pour
comparer leurs r&#233;sultats aux n&#244;tres. Les attributs utilis&#233;s par les SVM sont ceux d&#233;fini par les auteurs. Les valeurs
FP et les FN n&#8217;ont pas &#233;t&#233; publi&#233;es.
</p>
<p>53</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Davy WEISSENBACHER, Adeline NAZARENKO
</p>
<p>Impersonal_Filter
Impersonal
Anaphoric
</p>
<p>First_NP
First
</p>
<p>NotFirst
</p>
<p>Prepositional
NotPrepositional
</p>
<p>Prepositional_NP
</p>
<p>Same_SentencePrevious_SentenceBefore_Previous_SentenceOther_Sentence
</p>
<p>Distance
</p>
<p>AnaphoricPronoun
NotPronoun
</p>
<p>Pronoun_NP Heading
NotHeading
</p>
<p>Candidate_Heading
</p>
<p>DefiniteIndefiniteDemonstrativePossessive
</p>
<p>Definite_NP
ZeroOneMore
</p>
<p>Repeated_NP Term
Term
</p>
<p>Not_Term
ProperName
</p>
<p>NotProperName
</p>
<p>Proper_Name
</p>
<p>Candidate
Antecedent
</p>
<p>NotAntecedent
</p>
<p>SubjectComplementDifferentUnknown
</p>
<p>Syntactic_ParallalismCollocation_Sunject_Verb_Pattern
ZeroLess_FiveLess_TenMore_Ten
</p>
<p>Collocation_Verb_NP_Pattern
ZeroLess_FiveLess_TenMore_Ten
</p>
<p>Collocation_Verb_Complement_Pattern
ZeroLess_FiveLess_TenMore_Ten
</p>
<p>SubjectComplementUnknown
</p>
<p>Subject_NP
</p>
<p>ZeroLess_FiveLess_TenMore_Ten
</p>
<p>Collocation_NP_Verb_Pattern
</p>
<p>Incompatible
Compatible
Gender_Filter
</p>
<p>Singular
Number_Filter
</p>
<p>Plural
Indicating
</p>
<p>NotIndicating
</p>
<p>Indicating_Verb
Appositive
</p>
<p>NotAppositive
</p>
<p>Appositive_NP Noued de pr&#233;diction
Attributs du syst&#232;me MARS
Attributs  Compl&#233;mentaires
</p>
<p>Gene
Species
Person
</p>
<p>Location
Unknown
</p>
<p>Semantic_Class
CoherenteNotCoherent
</p>
<p>Semantic_Coherence
</p>
<p>Unknown
</p>
<p>FIG. 3 &#8211; Un r&#233;seau Bay&#233;sien pour la classification des ant&#233;c&#233;dents
</p>
<p>5.1 Un classifieur bay&#233;sien pour la r&#233;solution des anaphores
Nous avons utilis&#233; le syst&#232;me MARS (Mitkov, 2002) comme syst&#232;me de r&#233;f&#233;rence pour notre
&#233;valuation. Ce syst&#232;me repose sur des indices de surface pour trouver l&#8217;&#233;l&#233;ment le plus saillant
dans le discours qui pr&#233;c&#232;de une occurrence donn&#233;e de pronom. Cet &#233;l&#233;ment est celui qui a
la plus forte probabilit&#233; d&#8217;&#234;tre l&#8217;ant&#233;c&#233;dent du pronom. Nous avons r&#233;-impl&#233;ment&#233; le syst&#232;me
en utilisant le m&#234;me pr&#233;traitement des textes que dans notre syst&#232;me bay&#233;sien5 de mani&#232;re &#224;
comparer uniquement les algorithmes des deux syst&#232;mes (choix des attributs et m&#233;canisme de
prise de d&#233;cision).
Pour r&#233;aliser notre classifieur bay&#233;sien (voir figure 36), nous avons conserv&#233; tous les indices
approch&#233;s de MARS (noeuds colori&#233;s en noir sur la figure) mais nous avons ajout&#233; une s&#233;rie
d&#8217;autres indices (en gris sur la figure) qui sont &#233;galement pertinents pour le calcul de la saillance
et qui sont propos&#233;s par plusieurs travaux de l&#8217;&#233;tat de l&#8217;art. De notre point de vue, il est en
effet utile d&#8217;avoir &#224; la fois les indices et les connaissances linguistiques qu&#8217;ils approchent. Par
exemple, le sujet d&#8217;une phrase est souvent l&#8217;&#233;l&#233;ment saillant mais comme le calcul du r&#244;le
grammatical peut &#234;tre erron&#233;, il est int&#233;ressant d&#8217;exploiter en parall&#232;le l&#8217;information concernant
un indice de surface (First_NP : le premier GN de la phrase est tr&#232;s souvent le sujet du verbe)
qui peut confirmer ou infirmer l&#8217;hypoth&#232;se du r&#244;le grammatical.
En suivant un protocole exp&#233;rimental identique &#224; celui de la section pr&#233;c&#233;dente sur le m&#234;me
corpus, nous avons r&#233;alis&#233; la r&#233;solution avec 4 syst&#232;mes diff&#233;rents. Trois syst&#232;mes servent de
comparaison : le syst&#232;me Al&#233;atoire qui choisit un ant&#233;c&#233;dent au hasard dans la liste des candi-
dats, le syst&#232;me Premier GN qui s&#233;lectionne toujours le premier GN de la phrase pr&#233;c&#233;dant le
pronom comme ant&#233;c&#233;dent et le syst&#232;me MARS. Le dernier syst&#232;me est le classifieur bay&#233;sien
(CB) que nous cherchons &#224; &#233;valuer.
Pour les trois derniers syst&#232;mes, nous donnons deux mesures diff&#233;rentes des performances, un
taux de succ&#232;s strict et partiel7. Le taux de succ&#232;s est strict lorsque l&#8217;ant&#233;cedent exact a &#233;t&#233;
</p>
<p>5Nous avons utilis&#233; dans les deux cas les analyses produites par la plate-forme d&#8217;annotation OGMIOS (Derivi&#232;re
et al., 2006).
</p>
<p>6Le noeud de pr&#233;diction est le noeud Candidat, au centre. Il estime la probabilit&#233; pour une occurrence d&#8217;un
candidat d&#8217;&#234;tre l&#8217;ant&#233;c&#233;dent d&#8217;un pronom donn&#233;. Ce noeud Candidate est li&#233; &#224; tous les noeuds du r&#233;seau.
</p>
<p>7Strict Success rate = Anaphorecorrectementrsolue
Touteslesanaphores
</p>
<p>Partial Succes rate = Anaphorecorrectementetpartiellementrsolue
Touteslesanaphores
</p>
<p>54</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L&#8217;int&#233;r&#234;t de la classification bay&#233;sienne
</p>
<p>annot&#233; par le syst&#232;me et partiel lorsque seule une partie de l&#8217;ant&#233;c&#233;dent &#224; &#233;t&#233; annot&#233;e. En raison
des erreurs de l&#8217;analyse syntaxique en constituants sur laquelle la liste des candidats est calcul&#233;e,
certains GN candidats ne sont identifi&#233;s que partiellement ou font d&#233;faut. Les performances
de nos syst&#232;mes ne peuvent atteindre 100%, la derni&#232;re colonne donne les scores maximum
possibles pour la r&#233;solution.
</p>
<p>System Results
Strict Partial
</p>
<p>Al&#233;atoire 6% -
Premier GN 36.3% 51%
</p>
<p>MARS 26.7% 43%
Classifieur Bay&#233;sien 44.0% 61%
</p>
<p>MAX 93.3% 97.8%
</p>
<p>TAB. 2 &#8211; Comparaison des r&#233;sultats (taux de Succ&#232;s)
</p>
<p>La comparaison des scores des syst&#232;mes MARS et CB permet d&#8217;&#233;tablir l&#8217;apport des connais-
sances linguistiques complexes dans la r&#233;solution en d&#233;pit de leur qualit&#233; imparfaite. Ces connais-
sances suppl&#233;mentaires rendent possible la d&#233;sambiguisation entre diff&#233;rents candidats. Consi-
d&#233;rons les phrases [A grpE heat-shock gene]1 was found by sequencing in [the genome of the
methanogenic archaeon Methanosarcina mazei S-6]2. [It]1 is the first example of grpE from
the phylogenetic domain Archaea. Le syst&#232;me MARS attribue des scores identiques pour les
candidats 1 et 2 et ne les d&#233;partage que gr&#226;ce &#224; l&#8217;heuristique du candidat le plus r&#233;cent, ce qui
le conduit &#224; choisir le candidat 2. Le classifieur CB &#233;vite cette erreur. La connaissance du sujet
et du type s&#233;mantique g&#232;ne du candidat 1 augmente &#224; 0.73 sa probabilit&#233; d&#8217;&#234;tre l&#8217;ant&#233;c&#233;dent du
pronom et l&#232;ve l&#8217;ambiguit&#233;.
Une analyse d&#233;taill&#233;e des erreurs du CB montre les limites de notre analyse de la saillance.
47% des erreurs sont dues &#224; un calcul erron&#233; de l&#8217;&#233;l&#233;ment saillant : le syst&#232;me ne retrouve pas
ce que l&#8217;annotateur humain juge &#171;intuitivement&#187; &#234;tre l&#8217;&#233;l&#233;ment saillant parce qu&#8217;un nombre
plus important d&#8217;indices favorisent un candidat diff&#233;rent de l&#8217;&#233;l&#233;ment saillant auquel le classi-
fieur associe la plus grande probabilit&#233; d&#8217;ant&#233;c&#233;dence. Dans 21% des cas, le syst&#232;mes trouve
bien l&#8217;&#233;l&#233;ment qui para&#238;t saillant &#224; l&#8217;annotateur humain mais cet &#233;l&#233;ment n&#8217;est pas l&#8217;ant&#233;c&#233;-
dent, ce qui met en cause soit notre d&#233;finition de la saillance soit son r&#244;le dans la r&#233;solution de
l&#8217;anaphore. Dans l&#8217;exemple suivant [Amino acid sequence analysis]1 of [the 33-kDa protein]2
revealed that it is a sigma factor, sigma E. l&#8217;&#233;l&#233;ment le plus saillant est le candidat 1 et il est
choisi comme ant&#233;c&#233;dent par le syst&#232;me, une d&#233;cision qui viole les connaissances du domaine,
un facteur sigma est une prot&#233;ine, des connaissances qu&#8217;il faut prendre en compte pour choisir
le candidat 2 comme ant&#233;c&#233;dent. Les erreurs restantes proviennent des imperfections des pr&#233;-
traitements linguistiques : principalement des erreurs de segmentation en phrase et de l&#8217;analyse
syntaxique incorrecte qui ne permet pas de rep&#233;rer tout les GN candidats.
</p>
<p>6 Conclusion
Les r&#233;seaux bay&#233;siens pr&#233;sentent un v&#233;ritable int&#233;r&#234;t pour les nombreuses t&#226;ches de classifi-
cation du TAL. Ce mod&#232;le permet de d&#233;passer l&#8217;opposition historique des syst&#232;mes &#224; base de
connaissances linguistiques et d&#8217;indices de surface. De fait, cette opposition appara&#238;t infond&#233;e :
</p>
<p>55</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Davy WEISSENBACHER, Adeline NAZARENKO
</p>
<p>les connaissances linguistiques sont n&#233;cessaires mais souvent indisponibles et peu fiables ; les
indices de surface sont g&#233;n&#233;ralement calculables et de bonne qualit&#233; mais il reste des probl&#232;mes
d&#8217;ambigu&#239;t&#233;. En unifiant ce deux types de connaissances au sein d&#8217;une unique repr&#233;sentation, le
mod&#232;le offre un m&#233;canisme de raisonnement dont nous nous servons pour corriger et suppl&#233;er
les connaissances linguistiques en les compl&#233;tant des indices de surface. Tout l&#8217;enjeu consiste
selon nous &#224; raisonner sur l&#8217;ensemble des connaissances et indices disponibles &#224; un moment
donn&#233; mais en tenant compte de leur relative fiabilit&#233; dans le processus de d&#233;cision.
Nous avons ensuite valid&#233; notre mod&#232;le sur le probl&#232;me de la r&#233;solution des anaphores en pro-
posant deux classifieurs, le premier pour distinguer les pronoms impersonnels et anaphoriques,
le second pour le choix de l&#8217;ant&#233;c&#233;dent. Les r&#233;sultats de nos classifieurs sont sup&#233;rieurs &#224; ceux
des syst&#232;mes de l&#8217;&#233;tat de l&#8217;art.
Actuellement seule une expertise linguistique rend compte de la structure des deux classifeurs
que nous avons pr&#233;sent&#233;s. Nous envisageons de tester les m&#233;canismes permettant d&#8217;apprendre
la structure m&#234;me du r&#233;seau. Comparer notre structure avec une structure apprise automatique-
ment devrait permettre de v&#233;rifier et d&#8217;enrichir la structure du CB actuelle.
</p>
<p>R&#233;f&#233;rences
DAGAN I. &amp; ITAI A. (1990). Automatic processing of large corpora for the resolution of
anaphora references. In Proceedings of COLING&#8217;90, p. 3 :330&#8211;332.
DERIVI&#200;RE J., HAMON T. &amp; NAZARENKO. A. (2006). A scalable and distributed nlp ar-
chitecture for web document annotation. In Advances in Natural Language Processing (5th
International Conference on NLP, FinTAL 2006), p. 56&#8211;67.
EVANS R. (2001). Applying machine learning toward an automatic classification of it. Literary
and linguistic computing, 16, 45&#8211;57.
HUSK G. &amp; PAICE C. (1987). Towards the automatic recognition of anaphoric features in
english text : the impersonal pronoun it. Computer Speech and Language, 2, 109&#8211;132.
KEHLER A., APPELT D., TAYLOR L. &amp; SIMMA A. (2001). The (non)utility of predicate-
argument frequencies for pronoun interpretation. In Proceedings of the Human Language
Technology Conference, p. 289&#8211;296.
LAPPIN S. &amp; LEASS H. (1994). An algorithm for pronominal anaphora resolution. Compu-
tational Linguistics, 20(4), 535&#8211;561.
LITRAN J. C., SATOU K. &amp; TORISAWA K. (2004). Improving the identification of non-
anaphoric it using support vector machines. In Actes d&#8217;International Joint Workshop on Natu-
ral Language Processing in Biomedicine and its Applications, p. 58&#8211;61.
MITKOV R. (2002). Anaphora Resolution. Longman Pub Group.
PONZETTO S. &amp; STRUBE M. (2006). Semantic role labeling for coreference resolution. In
Companion Volume of the Proceedings of EACL&#8217;06., p. 143&#8211;146.
WEISSENBACHER D. &amp; NAZARENKO A. (2007). A bayesian classifier for the recognition of
the impersonal occurrences of the it pronoun. In Proceedings of DAARC&#8217;07.
</p>
<p>56</p>

</div></div>
</body></html>