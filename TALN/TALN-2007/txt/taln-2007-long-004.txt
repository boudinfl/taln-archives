TALN 2007, Toulouse, 5-8 juin 2007

Identiﬁer les pronoms anaphoriques et trouver leurs
antécédents : l’intérét de la classiﬁcation bayésienne

Davy WEISSENBACHER, Adeline NAZARENKO
Université Paris-Nord, LIPN, 99 av. J-B. Clément, F-93430 Villetaneuse
{dw, nazarenko}@lipn . univ—parisl3 . fr

Résumé. On oppose souvent en TAL les systemes a base de connaissances linguistiques
et ceux qui reposent s11r des indices de surface. Chaque approche a ses limites et ses avantages.
Nous proposons dans cet article une nouvelle approche qui repose s11r les réseaux bayésiens
et qui permet de combiner au sein d’une méme representation ces deux types d’informations
hétérogenes et complémentaires. Nous justiﬁons l’intérét de notre approche en comparant les
performances du réseau bayésien a celles des systemes de l’état de l’art, sur un probleme difﬁ-
cile du TAL, celui de la résolution d’anaphore.

Abstract. In NLP, a traditional distinction opposes linguistically-based systems and know-
ledge-poor ones, which mainly rely on surface clues. Each approach has its drawbacks and its
advantages. In this paper, we propose a new approach based on Bayes Networks that allows to
combine both types of information. As a case study, we focus on the anaphora resolution which
is known as a difﬁcult NLP problem. We show that o11r bayesain system performs better than a
state-of-the art one for this task.

Mots-clés 2 réseaux bayésiens, résolution des anaphores, connaissance linguistique, in-
dice de surface.

Keywords: bayesian network, anaphora resolution, linguistic knowledge, surface clue.

I Introduction

On oppose souvent en TAL les systemes qui exploitent des connaissances linguistiques et ceux
qui reposent s11r des indices de surface. Les premiers systemes ne sont pas toujours ﬁables parce
qu’ils exploitent des connaissances complexes qui peuvent étre erronées lorsqu’elles sont cal-
culées automatiquement ou incompletes lorsqu’elles sont produites manuellement. Les seconds
systemes s’appuient généralement s11r des méthodes d’apprentissage automatique et s11r des in-
dices de surface qui sont plus faciles a obtenir mais qui ne permettent de traiter que les cas
simples ou les plus courants de la tache dévolue au systeme.

Dans cet article nous proposons une nouvelle approche qui permet de dépasser cette opposition
entre systemes «pauvres» et systeme «riches» en connaissances. Cette approche repose s11r le
formalisme des réseaux bayésiens. Ce formalisme est encore peu exploité en TAL mais il repose
s11r un modele probabiliste concu pour raisonner sur des informations incertaines, partielles et
manquantes.

47

Davy WEISSENBACHER, Adeline NAZARENKO

Nous validons notre approche s11r la tache de la résolution automatique des anaphores ou, en
raison de la complexité et du nombre de connaissances nécessaires, l’opposition des systemes a
base de connaissances linguistiques et d’indices de surface est tres marquée. Apres avoir validé
l’approche en développant un premier classiﬁe11r bayésien qui permet de distinguer pronoms
impersonnels et pronoms anaphoiiques, nous analysons les performances d’un second classi-
ﬁeur qui t1ouvel’antécédentdes pronoms anaphoiiques.

La section suivante revient sur les raisons de l’opposition précédente dans le cadre de la réso-
lution des anaphores pronominales. La section 3 déciit le modele des réseaux bayésiens et son
intérét po11r le TAL. Dans la section 4 nous validons notre approche en comparant les perfor-
mances de différents systemes po11r la distinction des pronoms impersonnels et anaphoiiques.
Enﬁn, la demiere section présente un classiﬁeur pour la téche complete de la résolution des
anaphores et compare ses résultats par rapport a l’état de l’art.

2 La complémentarité des connaissances linguistiques et des
indices de surface

2.1 Le choix des indices de surface

L’anaphore est une relation linguistique entre deux entités textuelles déﬁnie lorsqu’une entité
text11elle (l’anaph0re) renvoie a une autre entité du texte (l’antécédent). Comme la présence
d’anaphores dégrade considérablement les performances des systemes de TAL, la question de
le11r résolution est étudiée depuis longtemps. Ce travail se limite a la résolution de l’anaphore
du pronom it dans les textes anglais, l’anaphore la mieux connue et la plus facile a résoudre.

L’approche classique pour sa résolution automatique distingue trois étapes : la distinction des
pronoms anaphoiiques et impersonnels (it is known that... vs it produced...), la sélection des
candidats possibles a l’antécédence et le choix de l’antécédent. Pour chaque étape, les premiers
systemes proposés dans la littérature exploitaient des connaissances linguistiques complexes
traduisant les contraintes syntaxiques et sémantiques qui régissent l’anaphore. Comme le calcul
automatique de ces connaissances était considéré comme impossible ou trop peu ﬁable po11r étre
utilisable, ces connaissances linguistiques étaient produites manuellement, ce qui présupposait
un important travail d’analyse préalable des textes.

Durant les années 1990, devant le besoin de systemes de résolution robustes et peu coﬁteux a
mettre en place, un nombre important de systemes 51 bases d’indices de surface ont été propo-
sés (l\/Iitkov, 2002). Ces systemes abandonnent les connaissances linguistiques complexes des
premiers systemes. Ils approchent les connaissances nécessaires par des indices plus simples a
calculer et que l’on suppose plus ﬁables.

Pour la distinction des pronoms anaphoiiques, (Husk & Paice, 1987) a ainsi proposé un en-
semble d’automates encodant des connaissances linguistiques et permettant de reconnaitre les
séquences contenant des pronoms impersonnels. J ugeant que ces automates avaient une couver-
ture trop faible, (Evans, 2001) propose une voie alternative reposant s11r l’apprentissage auto-
matique des indices de surface pour reconnaitre les séquences caractéiistiques. Po11r le choix de
l’antécédent, les connaissances syntaxico-sémantiques sont approchées de la méme maniere par
des méthodes robustes. On sait que les schémas prédicat-argument améliorent les résultats du
ﬁltrage (Ponzetto & Strube, 2006), mais comme ces ressources ne sont pas to11jo11rs disponibles,

48

L’intérét de la classiﬁcation bayésienne

on a cherché a les approcher par un calcul fréquentiel : les régulalités des coocurrences entre
les s11jets, les compléments et les verbes dessinent les contours des classes sémantiques. Les
aute11rs de (Dagan & Itai, 1990) montrent que les contraintes obtenues peuvent partiellement
remplacer les connaissances sémantiques.

2.2 Les limites des indices de surface

Si les indices approchés proposés lors des années 1990 ont permis l’implémentation de sys-
temes robustes (1\/Iitkov, 2002), leur apport et le11rs limites étaient mal connus. Des travaux
récents commencent 51 en mesurer les limites. L’étude de (Kehler et al., 2001) montre ainsi que
les fréquences de (Dagan & Itai, 1990) n’améliorent pas les performances d’un systeme qui
exploite déja des informations morpho-syntaxiques. Les aute11rs en concluent que l’apport des
fréquences tient davantage du hasard que d’une véritable capture du sens sémantique.

Les limites rencontrées par les systemes a base d’indices de surface nous renvoient au pro-
bleme initial. Nous avons besoin de connaissances sémantiques et syntaxiques complexes pour
la résolution de l’anaphore pronominale. Ces connaissances linguistiques, lorsqu’elles sont dis-
ponibles, ne sont pas ﬁables. On peut chercher ales remplacer par des indices de surface dont le
calcul est to11jours réalisable et plus ﬁable mais ces indices peuvent ne pas exprimer, ou seule-
ment de maniere imprécise, les connaissances nécessaires a la résolution, ce qui produit des
erreurs.

Nous proposons une modélisation reposant s11r les Réseaux Bayésiens (RB), concu po11r raison-
ner s11r des données incertaines et incompletes. Cette approche probabiliste offre la possibilité
d’uniﬁer dans une unique représentation connaissances linguistiques et indices de surface. Cette
uniﬁcation permet de corroborer les connaissances linguistiques grace aux indices de surface
qui sont observés en corpus. A l’inverse, l’exploitation de connaissances linguistiques permet
de corriger certaines des e1re11rs des systemes a base d’indices de surface.

3 Une approche intégrée : le modéle bayésien

3.1 Des problémes de classiﬁcation

La distinction des pronoms impersonnels comme le choix de l’antécédent sont des taches qui,
comme de nombreuses taches du TAL, se reformulent facilement en problemes de classiﬁcation.

Considérons par exemple la classiﬁcation des pronoms impersonnels et anaphoiiques : soit Cor-
pus un ensemble de textes d’un méme domaine, Corpus_entraz‘nement et Corpus_test deux
sous-ensembles stricts disjoints de Corpus, C1 et C2 les classes des occurrences des pronoms
impersonnels et anaphoiiques présents dans Corpus. e est une occurrence d’un pronom présent
dans Corpus déciit par un vecteur a = 121, ...'u,, d’att1ibuts a valeurs dans R. Pour les occur-
rences de Corpus_entra1‘nement, les valeurs des attiibuts vi sont obtenues a partir d’une analyse
humaine du corpus : elles représentent selon les cas des connaissances linguistiques ou des
indices de surface.

Le théoreme de Bayes dit comment prédire la meille11re classe d’appartenance pour une occur-
rence d’un pronom inconnu de Corpus_test sur la base d’observations faites sur les occurrences

49

Davy WEISSENBACHER, Adeline NAZARENKO

de C0rpus_entrainement. La classe sélectionnée doit maximiser la probabilité
_ ( lC'z')* (Oi)
P (CEIE) — %

ou C,<E{C1, C2}, E une occurrence du corpus de test et P(C,«|E) la probabilité conditionnelle
que E appartienne a la classe C, sachant la valeur des attributs de E, une probabilité estimée a
partir des données d’entrainement. Si nous imposons la contrainte d’indépendance des attributs,
le classiﬁe11r est un «classiﬁeur bayésien naif». Les attributs étant indépendants, la probabilité
P(E se décompose en P('u1  >1:  >1: P('u,,|C,«) et la probabilité a maximiser se refonnule
en

P<o.«|E> = “;

I (I
p( 3) Hj=1 P('Uj|Cz‘)
Pour tout E de C0rpus_test, un classiﬁeur bayésien attribue la classe C1 51 l’exemple E si

P(Pronom=Impersonnel|E) 2P(Pronom=Anapho1ique|E) et la classe C2 sinon.

3.1.1 Le choix des attributs pour la classiﬁcation

L’un des premiers systemes distinguant les pronoms it impersonnels et anaphoriques (Husk &
Paice, 1987) s’appuie s11r un ensemble de regles de logique du 1" ordre po11r reconnaitre les
séquences qui contiennent une occurrence du pronom impersonnel. Les séquences qui intro-
duisent les it impersonnels partagent une forme remarquable : elles commencent par un it et se
tenninent par un délimiteur comme to, that, whether.... Les regles varient selon le délimiteur.
Les tests réalisés par Paice montrent que ces regles réalisent un bon score avec 91,4%Acc 1 sur
un corpus technique. Cependant les performances sont dégradées si on applique les regles a des
corpus de nature différente. Le nombre de faux positifs (FP) augmente : certains attributs sont
discriminants s11r les corpus techniques mais ne le sont plus sur des corpus de nature différente.

Aﬁn d’éviter cet écueil, (Lappin & Leass, 1994) décrit entierement les séquences au moyen
d’automates a états ﬁnis de la forme It is not/may be<M0daIadj>; It is <C0gv-ed> that
<Subject> ou <M0daladj> et <C0gv> dénotent des classes d’adjectifs modaux et de verbes
cognitifs connus po11r introduire des it impersonnels (par exemple necessary, possible et recom-
mend, think). Ce systeme a une bonne précision (il produit peu de FP), mais il a un mauvais
rappel (il produit beaucoup de FN) : seules les séquences exactes sont reconnues et il est tou-
jo11rs difﬁcile d’obtenir des classes d’adjectifs et de verbes exhaustives.

(Evans, 2001) renonce a exploiter des connaissances linguistiques aussi complexes et se concentre
s11r des attributs plus ﬁables, les indices de surface. Evans considere 35 indices syntaxiques et
contextuels (ex. la position du pronom dans la phrase, le lemme du verbe suivant. ..). Un systeme
d’apprentissage, utilisant la méthode des K plus proches voisins, détermine le poids des attri-
buts discriminants po11r le domaine du corpus et classe les occurrences inconnues. Les premiers
essais réalisent un score de 71,31%Acc satisfaisant s11r un corpus de langue générale. (Litran
et al., 2004) reproduit un essai identique avec une Machine 51 Support de Vecteur (SVM) s11r un
corpus de génomique et obtient un score de 92,71%Acc.

1L’exactitude, en anglais Accuracy : Acc=  , o1‘11es faux positifs (FP) correspondent aux oc-

currences d’un pronom anaphorique étiquetées impersom1e11es,1es faux négatifs (FN) les occurrences de pronoms
impersonnels étiquetées anaphoriques, les vrais positifs (V P) et les vrais négatifs (VN) cuuectement étiquetées
comme impersonnels et anaphoriques, respectivement.

50

L’intérét de la classiﬁcation bayésienne

‘n Ru.Ies:Mn|nh 5.0 0.5
‘n Ru.Iea:N0 Much 15.0 99.5

      

pm,,,,_, Pmnmm.Sm1_SmImce

1 A LS LN As AN
smismmﬁsm 550 350 Pnice_Ru.les:Mn|nh 95.0 90.0150 15.0
sm,smm;pNo,sm 45.0 55.0 Pnice_Ru.les:N0_Mnmh 5_() 1()_() g5_g g5_g

FIG. 1 — Exemple d’un classiﬁeur bayésien modélisé par un réseau bayésien

Ces deux demiers systemes d’apprentissage reposent donc uniquement sur des indices de sur-
face. Constatant que les connaissances linguistiques sont peu ﬁables ou incompletes, les au-
te11rs renoncent a les utiliser comme attributs. Ce choix nous parait trop radical : des lors que
ces connaissances linguistiques sont pertinentes po11r notre tache, il faut les intégrer dans la
décision sous la forme d’attributs mais en se donnant les moyens de raisonner sur des attributs
hétérogenes et de qualité variable.

3.1.2 L’inférence sur des attributs imparfaits

Le RB est un modele concu po11r raisonner sur des attributs incertains et incomplets. Il est
composé d’une description qualitative de le11rs dépendances, un graphe orienté sans circuits, et
d’une description quantitative, un ensemble de probabilités conditionnelles ou chaque Variable
Aléatoire (VA) est associée a un noeud du graphe. Une 1" étape de paramétrage permet de
représenter les connaissances a priori pour chaque VA sous la forme d’une table de probabilités
conditionnelles. L’étape suivante, l’étape d’inférence, consiste a réviser certaines probabilités
a priori po11r obtenir des probabilités a posteriori et a modiﬁer en conséquence les valeurs
des VA correspondantes a partir d’observations faites en corpus. Ces nouvelles informations
sont propagées au travers du réseau et permettent de réviser les vale11rs a priori méme pour les
variables non-observées.

Expliquons s11r un exemple tres simpliﬁé le mécanisme d’inférence du réseau de la ﬁgure 1,
un réseau destiné a la classiﬁcation des pronoms it. La 1" étape de paramétrage du réseau,
permet de calculer les valeurs a priori des probabilités. S11r l’analyse des fréquences d’un cor-
pus d’entrainement ou a partir de l’estimation d’un expert, nous établissons a priori qu’en-
viron un tiers des pronoms it du corpus sont impersonnels, P(Pronoun=Impersonal)=0,3. Un
lien d’inﬂuence relie les variables Pronom et Lappin_Ru1es, indiquant qu’un it a d’autant
plus de chance d’étre reconnu par une regle de (Lappin & Leass, 1994) qu’il est impersonnel.
De méme, les liens e11tre les variables Pronoun et Paice_Ru1es d’une part, Pronoun et
Start_Sentence d’autre part indiquent respectivement qu’un it a d’autant plus de chance
d’étre reconnu par une regle de (Husk & Paice, 1987) et d’étre en début de phrase qu’il est im-
personnel. L’arc (Start_Sentence , Paice_Rules) unit les deux variables, car, to11jo11rs
au regard du corpus d’entrainement ou de l’estimation de l’expert, elles ne sont pas indepen-
dantes. La ﬁabilité de la regle de (Husk & Paice, 1987) reconnaissant une séquence est aug-
mentée si la séquence est située en début de phrase. Cette inﬂuence est mesurée par la table de
probabilités conditionnelles associée au noeud Paice_Ru1 es de la ﬁgure 1.

Une fois l’ensemble des probabilités conditionnelles déterminé, l’étape d’inférence débute.

51

Davy WEISSENBACHER, Adeline NAZARENKO

 

FIG. 2 — Un Réseau Bayésien po11r la classiﬁcation des pronoms it impersonnels

Considérons par exemple la phrase It is well documented that treatment of serum-gr0wn....
Nous appliquons les regles de (Lappin & Leass, 1994) et les regles de (Husk & Paice, 1987)
s11r cette séquence. Aucune regle de (Lappin & Leass, 1994) ne reconnait la séquence, nous
posons P(Lappin_Rules = No_Match)=1. Une regle de (Husk & Paice, 1987) la reconnait, nous
posons P(Paice_Rules = Match)=1 et comme la séquence se situe en début de phrase nous po-
sons aussi P(Start_Sentence = Start)=1. En représentant graphiquement l’indépendance condi-
tionnelle des VA, le RB permet de compacter la loi jointe globale. A l’aide des probabilités
conditionnelles foumies en parametres nous pouvons inférer la probabilité qui nous intéresse :
P(Pronoun=Impersonal|Lappin_Rules=No_Match, Start_Sentence=Start, Paice_Rules=Match)

Du fait qu’une regle de (Husk & Paice, 1987) a reconnu la séquence et que l’occurrence se
trouve en début de phrase, le réseau infere une probabilité de 38,9% pour l’occurrence d’étre im-
personnelle. Nous pouvons modiﬁer cette conclusion en ajoutant d’autres variables au réseau ou
en raisonnant avec des observations incertaines ou manquantes. On peut par exemple indiquer
que la ﬁabilité de l’observation est inférieure a 100% et poser P(Lappin_Rules=No_Match)=0,9
pour tenir compte de l’incomplétude des regles de (Lappin & Leass, 1994).

4 1” expérience : l’identiﬁcation des pronoms impersonnels

4.1 Le protocole expérimental

L’objectif de cette premiere expérience est de valider notre modele (on trouvera dans (Weissen-
bacher & Nazarenko, 2007) une description précise du systeme développé et une analyse plus
complete des résultats obtenus). Nous avons mesuré les performances du Classiﬁeur Bayésien
(CB) de la ﬁgure 22, ainsi que celles du classiﬁeur bayésien na'1'f (CBN) associé3, puis nous les
avons comparées avec celles des systemes de l’état de l’art.

2Les attributs représentant 1e fait qu’une regle de (Lappin & Leass, 1994) ait reconnu une séquence sont colorés
en gris, en blanc ceux q11i correspondent aux regles de (Husk & Paice, 1987), enﬁn en noir les attributs de (Litran
et al., 2004) et (Evans, 2001). Le noeud de prediction est le noeud Pronom, au centre. 11 estime la probabilité pour
une occurrence donnée de pronom d’étre impersonnel ou anaphorique.

3Le c1assiﬁe11r bayésien na‘1'f possede les memes attributs mais sa structure est différente : 1e noeud Pronom est
lie 5 tous les noeuds et ces derniers ne sont lies 5 aucun autre.

52

L’intérét de la classiﬁcation bayésienne

Méthode Résultats
Regles De (Lappin & Leass, 1994) 88,11% 12,8 169,1
Regles De (Husk & Paice, 1987) 88,88% 123,6 24,2
Machine 51 Vecte11rs de Support 92,71% - -
Classiﬁe11r Bayésien na'1'f 92,58% 74,1 19,5
Classiﬁeur Bayésien 95,91 % 21,0 38,2

TAB. 1 — Résultats des predictions (Exactitude/Faux Positifs/Faux Négatifs)

Nous avons tiavaillé s11r un corpus de résumé d’articles de génomique construit a partir de
la base Medline inteirogée avec les mots clés bacillus subtilis, transcription factors, Human,
blood cells, gene and fusion. Nous en avons extrait 11 966 résumés (environ 5 millions de mots)
ou nous avons identiﬁé 3347 occurrences du pronom it. Deux annotateurs humains ont classé
chaque occurrence du pronom soit comme anaphorique soit comme impersonnelle. L’accord
des annotateurs fut entier apres discussion.

;;\

Notre corpus étant de taille moyenne, nous avons procede a une validation croisée pour valider
nos résultats. Nous sélectionnons aléatoirement 2/3 du corpus po11r calculer les probabilités
conditionnelles a priori. Nous appliquons ensuite notre CB , ainsi que le CBN, paramétrés grace
a ces probabilités sur le tiers restant. Nous réitérons 20 fois ces opérations po11r obtenir une
moyenne des performances de chaque systeme sur le corpus.

4.2 Résultats

Le tableau 1 résume les moyennes des résultats (en exactitude) obtenus par les systemes de
l’état de l’art décrits plus haut4 et celles des deux classiﬁeurs. Ces résultats montrent que le
CB produit une meilleure classiﬁcation que les autres systemes, notamment les systemes a base
de regles. Ces résultats valident notre modele : le CB exploite tous les attributs pertinents et
corrige le bruit d’un attribut par la ﬁabilité des autres. Privé des relations de dépendance entre
les attributs, le CBN ne bénéﬁcie pas du mécanisme de correction et surestime le11rs ﬁabilités.
Les systemes a base de regles sont quant a eux entierement assujettis a la ﬁabilité des attributs.
Les résultats conﬁrment les craintes soulevées dans la section 3.1.1 : on obtient un faible rappel
pour les regles de (Lappin & Leass, 1994) et une mauvaise précision pour celles de (Husk &
Paice, 1987).

5 2”de expérience : la résolution des anaphores

Ass11rés des bonnes performances de notre modele sur la distinction des pronoms impersonnels,
nous proposons un classiﬁeur bayésien pour la résolution d’anaphore.

4Nous avons ajouté le score du SVM obtenu par (Litran et al., 2004) sur un corpus de génomique similaire pour
comparer leurs résultats aux nétres. Les attributs utilisés par les SVM sont ceux déﬁni par les auteurs. Les valeurs
FP et les FN n’ont pas été publiées.

53

Davy WEISSENBACHER, Adeline NAZARENKO

El Nomad dc plﬁicfnll
V ° ' “""‘”“"’ “"“"i“"“ — Amilmu dn syxlhme MARS
Flnnl Nmlnﬁuling Nmmmmve

— Amibnu Cmnpldinenhinns

  
 
  

FIG. 3 — Un réseau Bayésien po11r la classiﬁcation des antécédents

5.1 Un classiﬁeur bayésien pour la résolution des anaphores

Nous avons utilisé le systeme MARS (l\/Iitkov, 2002) comme systeme de référence po11r notre
évaluation. Ce systeme repose sur des indices de surface po11r trouver l’élément le plus saillant
dans le disco11rs qui précede une occurrence donnée de pronom. Cet élément est celui qui a
la plus forte probabilité d’étre l’antécédent du pronom. Nous avons ré-implémenté le systeme
en utilisant le méme prétraitement des textes que dans notre systeme bayésiens de maniere a
comparer uniquement les algorithmes des deux systemes (choix des attributs et mécanisme de
prise de décision).

Pour réaliser notre classiﬁeur bayésien (voir ﬁgure 36), nous avons conservé tous les indices
approchés de MARS (noeuds coloriés en noir s11r la ﬁgure) mais nous avons ajouté une série
d’autres indices (en gris s11r la ﬁgure) qui sont également pertinents pour le calcul de la saillance
et qui sont proposés par plusie11rs travaux de l’état de l’art. De notre point de vue, il est en
effet utile d’avoir a la fois les indices et les connaissances linguistiques qu’ils approchent. Par
exemple, le sujet d’une phrase est souvent l’élément saillant mais comme le calcul du role
grammatical peut étre erroné, il est intéressant d’exploiter en parallele l’information concemant
un indice de surface (First_NP : le premier GN de la phrase est tres souvent le s11jet du verbe)
qui peut conﬁrmer ou inﬁrmer l’hypothese du role grammatical.

En suivant un protocole experimental identique a celui de la section précédente sur le méme
corpus, nous avons réalisé la résolution avec 4 systemes différents. Trois systemes servent de
comparaison : le systeme Aléatoire qui choisit un antécédent au hasard dans la liste des candi-
dats, le systeme Premier GN qui sélectionne toujo11rs le premier GN de la phrase précédant le
pronom comme antécédent et le systeme MARS. Le demier systeme est le classiﬁeur bayésien
(CB) que nous cherchons a évaluer.

Pour les trois demiers systemes, nous donnons deux mes11res différentes des performances, un
taux de succes strict et partiel7. Le taux de succes est strict lorsque l’antécedent exact a été

5Nous avons utilise dans les deux cas les analyses produites par la plate—forme d’annotation OGMIOS (Deriviere
et al., 2006).
6Le noeud de prediction est le noeud Candidat, au centre. 11 estime la probabilité pour une occurrence d’un

candidat d’étre l’antécédent d’un pronom donné. Ce noeud Candidate est lie in tous les noeuds du réseau.

7Stﬁct Success rate = Anaphu: ecarrectementrsaluc
Tauteslesanaphares
- _ Anaphu: Cour : ectementetpaviiellementrsuluc
Partial Succes rate _ Tauteslesanaphares

54

L’intérét de la classiﬁcation bayésienne

annoté par le systeme et partiel lorsque seule une partie de l’antécédent a été annotée. En raison
des erreurs de l’analyse syntaxique en constituants sur laquelle la liste des candidats est calculée,
certains GN candidats ne sont identiﬁés que partiellement ou font défaut. Les performances
de nos systemes ne peuvent atteindre 100%, la derniere colonne donne les scores maximum
possibles po11r la résolution.

System Results
Strict Partial
Aléatoire 6% -
Premier GN 36.3% 51%
MARS 26.7% 43%
Classiﬁeur Bayésien 44.0% 6 1 %
MAX 93.3% 97.8%

TAB. 2 — Comparaison des résultats (taux de Succes)

La comparaison des scores des systemes MARS et CB permet d’établir l’apport des connais-
sances linguistiques complexes dans la résolution en dépit de le11r qualité imparfaite. Ces connais-
sances supplémentaires rendent possible la désambiguisation entre différents candidats. Consi-
dérons les phrases [A grpE heat-shock gene ]1 was found by sequencing in [the genome of the
methanogenic archaeon Methanosarcina mazei S-6]2. [It]1 is the first example of grpE from
the phylogenetic domain Archaea. Le systeme MARS attribue des scores identiques pour les
candidats 1 et 2 et ne les départage que grace a l’heuristique du candidat le plus récent, ce qui
le conduit 51 choisir le candidat 2. Le classiﬁeur CB évite cette erreur. La connaissance du s11jet
et du type sémantique gene du candidat 1 augmente a 0.73 sa probabilité d’étre l’antécédent du
pronom et leve l’ambiguité.

Une analyse détaillée des erreurs du CB montre les limites de notre analyse de la saillance.
47% des erreurs sont dues a un calcul erroné de l’élément saillant : le systeme ne retrouve pas
ce que l’annotateur humain juge «intuitivement» étre l’élément saillant parce qu’un nombre
plus important d’indices favorisent un candidat différent de l’élément saillant auquel le classi-
ﬁeur associe la plus grande probabilité d’antécédence. Dans 21% des cas, le systemes trouve
bien l’élément qui parait saillant a l’annotateur humain mais cet élément n’est pas l’antécé-
dent, ce qui met en cause soit notre déﬁnition de la saillance soit son role dans la résolution de
l’anaphore. Dans l’exemple suivant [Amino acid sequence analysis ]1 of [the 33-kDa protein ]2
revealed that it is a sigma factor, sigma E. l’élément le plus saillant est le candidat 1 et il est
choisi comme antécédent par le systeme, une décision qui viole les connaissances du domaine,
un facte11r sigma est une protéine, des connaissances qu’il faut prendre en compte pour choisir
le candidat 2 comme antécédent. Les erre11rs restantes proviennent des imperfections des pre-
traitements linguistiques : principalement des erreurs de segmentation en phrase et de l’analyse
syntaxique incorrecte qui ne permet pas de repérer tout les GN candidats.

6 Conclusion

Les réseaux bayésiens présentent un véritable intérét po11r les nombreuses taches de classiﬁ-
cation du TAL. Ce modele permet de dépasser l’opposition historique des systemes a base de
connaissances linguistiques et d’indices de surface. De fait, cette opposition apparait infondée :

55

Davy WEISSENBACHER, Adeline NAZARENKO

les connaissances linguistiques sont nécessaires mais souvent indisponibles et peu ﬁables ; les
indices de surface sont généralement calculables et de bonne qualité mais il reste des problemes
d’ambiguité. En uniﬁant ce deux types de connaissances au sein d’une unique représentation, le
modele offre un mécanisme de raisonnement dont nous nous servons pour corriger et suppléer
les connaissances linguistiques en les complétant des indices de surface. Tout l’enjeu consiste
selon nous a raisonner sur l’ensemble des connaissances et indices disponibles a un moment
donné mais en tenant compte de le11r relative ﬁabilité dans le processus de décision.

Nous avons ensuite validé notre modele sur le probleme de la résolution des anaphores en pro-
posant deux classiﬁeurs, le premier pour distinguer les pronoms impersonnels et anaphoriques,
le second po11r le choix de l’antécédent. Les résultats de nos classiﬁeurs sont supérieurs a ceux
des systemes de l’état de l’art.

Actuellement seule une expertise linguistique rend compte de la structure des deux classifeurs
que nous avons présentés. Nous envisageons de tester les mécanismes permettant d’apprendre
la structure méme du réseau. Comparer notre structure avec une structure apprise automatique-
ment devrait permettre de vériﬁer et d’enrichir la structure du CB actuelle.

Références

DAGAN I. & ITAI A. (1990). Automatic processing of large corpora for the resolution of
anaphora references. In Proceedings of COLING ’90, p. 3 2330-332.

DERIVIERE J ., HAMON T. & NAZARENKO. A. (2006). A scalable and distributed nlp ar-
chitecture for web document annotation. In Advances in Natural Language Processing (5th
International Conference on NLP, FinTAL 2006), p. 56-67.

EVANS R. (2001). Applying machine learning toward an automatic classiﬁcation of it. Literary
and linguistic computing, 16, 45-57.

HUSK G. & PAICE C. (1987). Towards the automatic recognition of anaphoric features in
english text : the impersonal pronoun it. Computer Speech and Language, 2, 109- 132.

KEHLER A., APPELT D., TAYLOR L. & SIMMA A. (2001). The (non)utility of predicate-
argument frequencies for pronoun interpretation. In Proceedings of the Human Language
Technology Conference, p. 289-296.

LAPPIN S. & LEASS H. (1994). An algorithm for pronominal anaphora resolution. Compu-
tational Linguistics, 20(4), 535-561.

LITRAN J . C., SATOU K. & TORISAWA K. (2004). Improving the identiﬁcation of non-
anaphoric it using support vector machines. In Actes d ’International Joint Workshop on Natu-
ral Language Processing in Biomedicine and its Applications, p. 58-61.

MITKOV R. (2002). Anaphora Resolution. Longman Pub Group.

PONZETTO S. & STRUBE M. (2006). Semantic role labeling for coreference resolution. In
Companion Volume of the Proceedings of EACL’06., p. 143-146.

WEISSENBACHER D. & NAZARENKO A. (2007). A bayesian classiﬁer for the recognition of
the impersonal occurrences of the it pronoun. In Proceedings of DAARC ’07.

56

