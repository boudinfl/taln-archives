<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Aides &#224; la navigation dans un corpus de transcriptions d&#8217;oral</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2007, Toulouse, 5&#8211;8 juin 2007 
</p>
<p>Aides &#224; la navigation dans un corpus de transcriptions d&#8217;oral 
</p>
<p>Frederik CAILLIAU1, 2, Claude DE LOUPY3
1 LIPN &#8211; Institut Galil&#233;e &#8211; Universit&#233; Paris-Nord,
</p>
<p>99, avenue Jean-Baptiste Cl&#233;ment, 93430 Villetaneuse 
2 Sinequa Labs &#8211; 51 rue Ledru-Rollin, 94200 Ivry-sur-Seine 
</p>
<p>3 Syllabs &#8211; 3 rue Castex, c/o Agoranov, 75004 Paris 
cailliau@sinequa.com, loupy@syllabs.com 
</p>
<p>R&#233;sum&#233;. Dans cet article, nous &#233;valuons les performances de fonctionnalit&#233;s d&#8217;aide &#224; la 
navigation dans un contexte de recherche dans un corpus audio. Nous montrons que les 
particularit&#233;s de la transcription et, en particulier les erreurs, conduisent &#224; une d&#233;gradation 
parfois importante des performances des outils d&#8217;analyse. Si la navigation par concepts reste 
dans des niveaux d&#8217;erreur acceptables, la reconnaissance des entit&#233;s nomm&#233;es, utilis&#233;e pour 
l&#8217;aide &#224; la lecture, voit ses performances fortement baisser. Notre remise en doute de la 
portabilit&#233; de ces fonctions &#224; un corpus oral est n&#233;anmoins att&#233;nu&#233;e par la nature m&#234;me du 
corpus qui incite &#224; consid&#233;rer que toute m&#233;thodes permettant de r&#233;duire le temps d&#8217;acc&#232;s &#224; 
l&#8217;information est pertinente, m&#234;me si les outils utilis&#233;s sont imparfaits.  
</p>
<p>Abstract. In this paper we evaluate the performances of navigation facilities within the 
context of information retrieval performed on an audio corpus. We show that the issues about 
transcription, especially the errors, lead to a sometimes important deterioration of the 
performances of the analysing tools. While the navigation by concepts remains within an 
acceptable error rate, the recognition of named entities used in fast reading undergo a 
performance drop. Our caution to the portability of these functions to a speech corpus is 
attenuated by the nature of the corpus: access time to a speech corpus can be very long, and 
therefore all methods that reduce access time are good to take. 
</p>
<p>Mots-cl&#233;s : &#233;valuation, moteur de recherche, corpus oral. 
</p>
<p>Keywords: evaluation, search engine, speech corpus. 
</p>
<p>1 Introduction
Les corpus oraux font de plus en plus partie de notre quotidien, aussi bien &#224; travers le web 
que dans notre environnement professionnel. Leur taille est dans une phase de tr&#232;s forte 
croissance du fait de la g&#233;n&#233;ralisation des podcasts. Face &#224; la masse grandissante de donn&#233;es 
disponibles et les grands progr&#232;s constat&#233;s dans les technologies de transcription depuis les 15 
derni&#232;res ann&#233;es, la recherche &#224; l&#8217;int&#233;rieur de ces enregistrements s&#8217;impose. En particulier, les 
techniques d&#8217;aide &#224; la navigation appliqu&#233;es aux corpus &#233;crits devraient &#234;tre particuli&#232;rement 
utiles du fait du temps n&#233;cessaire &#224; l&#8217;&#233;coute d&#8217;une &#233;mission enti&#232;re. Il a &#233;t&#233; montr&#233; que les 
performances des outils de transcriptions ont une influence relativement faible sur les 
</p>
<p>143</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Frederik CAILLIAU, Claude DE LOUPY
</p>
<p>performances des moteurs de recherche sur l&#8217;audio [Allen, 2002]. Mais ces performaces de 
transcriptions ont-elles un impact important sur les aides &#224; la navigation ? 
</p>
<p>Cette &#233;valuation s&#8217;inscrit dans une s&#233;rie de travaux men&#233;s depuis les ann&#233;es 90 comme la 
BNN (Merlino et al., 1997), Speechbot (Van Thong et al., 2002), SCAN (Choi et al., 1999). 
Des outils d&#8217;aide &#224; la navigation pour l&#8217;audio ont d&#233;j&#224; &#233;t&#233; test&#233;s (Anick &amp; Tipirneni, 1999) 
mais concernent des fonctionnalit&#233;s moins &#233;volu&#233;es que ce qui est actuellement utilis&#233; pour 
l&#8217;&#233;crit.
</p>
<p>Le pr&#233;sent article se place dans le cadre et &#224; la suite du projet AudioSurf1 dont le but &#233;tait de 
cr&#233;er une plate-forme d&#8217;indexation de l&#8217;audio et, en particulier, un moteur de recherche sur 
l&#8217;audio ayant les m&#234;mes fonctionnalit&#233;s qu&#8217;un moteur de recherche sur le texte. Les moteurs 
de recherche sur les textes &#233;crits ont fait de grands progr&#232;s depuis quelques ann&#233;es en incluant 
des fonctionnalit&#233;s d&#8217;aide &#224; la navigation qui permettent de donner des informations 
compl&#233;mentaires &#224; l&#8217;utilisateur, de lui permettre de sp&#233;cifier sa requ&#234;te et d&#8217;interagir avec le 
syst&#232;me.  
</p>
<p>Nous pr&#233;sentons ici une application du moteur Intuition de Sinequa &#224; l&#8217;indexation de corpus 
oraux transcrits &#224; l&#8217;aide de l&#8217;outil du LIMSI et de Vecsys (Gauvain et al., 2000) et les 
cons&#233;quences des particularit&#233;s de tels corpus sur les fonctionnalit&#233;s d&#8217;aide &#224; la navigation. 
En section 2, nous d&#233;crivons le moteur de recherche Intuition, le principe des aides &#224; la 
navigation ainsi que l&#8217;&#233;valuation de leur apport. La section 3 d&#233;crit le corpus de 
transcriptions, ses particularit&#233;s ainsi que les implications de ces particularit&#233;s sur les 
performances de l&#8217;outil. Enfin, en section 4, nous pr&#233;sentons les r&#233;sultats des &#233;valuations que 
nous avons men&#233;es.  
</p>
<p>2 La plateforme Intuition 
</p>
<p>2.1 Pr&#233;sentation
</p>
<p>Intuition est une plateforme de recherche d&#8217;information d&#233;velopp&#233;e par Sinequa2, constitu&#233;e 
d&#8217;un moteur de recherche et d&#8217;interfaces de navigation. Elle repose sur des traitements 
linguistiques, statistiques et s&#233;mantiques qui augmentent la pertinence des documents trouv&#233;s 
et acc&#233;l&#232;rent la recherche des utilisateurs (cf. section 2.2).
</p>
<p>La figure 1 pr&#233;sente l&#8217;interface du moteur de recherche telle qu&#8217;elle a &#233;t&#233; con&#231;ue pour le 
corpus audio. Globalement, cette interface est similaire &#224; celle sur les textes &#233;crits. Certains 
&#233;l&#233;ments ont cependant &#233;t&#233; ajout&#233;s comme l&#8217;acc&#232;s direct &#224; l&#8217;&#233;coute du passage, sa dur&#233;e, etc.  
</p>
<p>1  Le projet AudioSurf a &#233;t&#233; financ&#233; dans le cadre du R&#233;seau National des Technologies Logicielles (appel 
RNTL 2002). Il avait comme partenaire Sinequa1 (leader), la soci&#233;t&#233; Vecsys1, le LIMSI1 et le partenaire 
valideur Radio France. 
</p>
<p>2  Pour plus d&#8217;informations : http://www.sinequa.com/ 
</p>
<p>144</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Aides &#224; la navigation dans un corpus oral 
</p>
<p>Sur le volet de gauche, apparaissent des listes de concepts3, d&#8217;entit&#233;s (noms de lieux, 
d&#8217;organisations et de personnes). Ces &#233;l&#233;ments sont contextuels par rapport &#224; la requ&#234;te 
(Crestan &amp; Loupy, 2004) et permettent &#224; l&#8217;utilisateur de la pr&#233;ciser. Un simple clic sur une 
des entit&#233;s permet de relancer une requ&#234;te demandant des documents r&#233;pondant &#224; la requ&#234;te 
pr&#233;c&#233;dente et contenant le terme choisi. L&#8217;extraction des entit&#233;s, en combinaison avec un 
&#233;quilibrage statistique, se transforme alors en g&#233;n&#233;rateur de filtres &#224; la vol&#233;e qui permet de 
restreindre rapidement le nombre de documents de la liste des r&#233;ponses. 
</p>
<p>L&#8217;extraction des entit&#233;s est faite &#224; partir de grammaires locales &#233;crites sous forme de 
transducteurs, qui prennent en compte les r&#233;sultats d&#8217;un &#233;tiquetage morphosyntaxique et 
d&#8217;une lemmatisation. Plus d&#8217;informations sur les ressources linguistiques utilis&#233;es dans ces 
traitements peuvent &#234;tre retrouv&#233;es dans Cailliau (2006).  
</p>
<p>Figure 1 : Interface du moteur de recherche sur le corpus audio 
</p>
<p>L&#8217;aide &#224; la lecture est une deuxi&#232;me application des entit&#233;s visible pour l&#8217;utilisateur. Elle 
consiste &#224; mettre en couleur les diff&#233;rentes entit&#233;s nomm&#233;es qui ont &#233;t&#233; identifi&#233;es &#224; 
l&#8217;int&#233;rieur d&#8217;un document afin de favoriser une lecture rapide par le rep&#233;rage des passages 
importants. Par exemple, les personnes seront visualis&#233;es en rouge, les lieux en bleu, etc. Il 
est ainsi possible de rep&#233;rer tr&#232;s vite ce dont parle le document. Pour l&#8217;&#233;valuation, nous nous 
concentrerons sur le rappel et la pr&#233;cision en reconnaissance des personnes par le syst&#232;me. 
</p>
<p>Les interfaces d&#233;crites se compl&#232;tent par un autre type de navigation, qui ne sera pas &#233;valu&#233; 
dans cet article : la fonction des documents similaires. Elle permet de retrouver des 
documents s&#233;mantiquement proches de celui que l&#8217;utilisateur vient de regarder.  
</p>
<p>3  Appel&#233;s parfois aussi termes associ&#233;s.
</p>
<p>145</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Frederik CAILLIAU, Claude DE LOUPY
</p>
<p>Nous &#233;valuerons l&#8217;impact, sur ces fonctionnalit&#233;s d&#8217;aide &#224; la navigation, du passage &#224; des 
corpus oraux dans la section 4.
</p>
<p>2.2 &#201;valuation du principe de navigation 
</p>
<p>Le principe de navigation utilis&#233; ici a &#233;t&#233; valid&#233; sur l&#8217;&#233;crit [Crestan &amp; Loupy, 2004]. Nous 
avons effectu&#233; une analyse mettant en jeu : 
</p>
<p>&#8211; 775 000 articles issus du journal Le Monde (ann&#233;es 1989 &#224; 2002) ; 
&#8211; 6 interfaces diff&#233;rentes utilisant l&#8217;une ou l&#8217;autre des fonctions de navigation ; 
&#8211; 18 requ&#234;tes dont 12 de type recherche documentaire (traductions de requ&#234;tes 
</p>
<p>provenant de TREC-6, ad&#8217;hoc [Voorhees &amp; Harman, 1997]) et 6 requ&#234;tes factuelles 
(traductions de requ&#234;tes provenant de TREC-11, question/answering [Voorhees, 
2003]) ; 
</p>
<p>&#8211; 6 personnes de formation et int&#233;r&#234;ts diff&#233;rents ayant pour instruction de passer 
exactement 10 mn par requ&#234;te pour retrouver le maximum de documents pertinents. 
Chaque document visualis&#233; devait &#234;tre class&#233; pertinent ou non pertinent par 
l&#8217;utilisateur.
</p>
<p>Les r&#233;sultats ont &#233;t&#233; tr&#232;s satisfaisants puisque l&#8217;interface donnant acc&#232;s &#224; toutes les aides &#224; la 
navigation a permis :  
</p>
<p>&#8211; de diminuer le temps d&#8217;acc&#232;s au premier document pertinent par deux en moyenne 
(248 s &#198; 122 s) ; 
</p>
<p>&#8211; d&#8217;augmenter presque par deux en moyenne le nombre de documents pertinents 
retrouv&#233;s (3,83 &#198; 6,56) ; 
</p>
<p>&#8211; de diminuer tr&#232;s significativement le nombre de documents non pertinents visualis&#233;s 
(7,17&#198; 4,28). 
</p>
<p>0
</p>
<p>0,05
</p>
<p>0,1
</p>
<p>0,15
</p>
<p>0,2
</p>
<p>0,25
</p>
<p>0,3
</p>
<p>0,35
</p>
<p>0,4
</p>
<p>0,45
</p>
<p>0,5
</p>
<p>0 20 40 60 80 10
0
</p>
<p>12
0
</p>
<p>14
0
</p>
<p>16
0
</p>
<p>18
0
</p>
<p>20
0
</p>
<p>22
0
</p>
<p>24
0
</p>
<p>26
0
</p>
<p>28
0
</p>
<p>30
0
</p>
<p>32
0
</p>
<p>34
0
</p>
<p>36
0
</p>
<p>38
0
</p>
<p>40
0
</p>
<p>42
0
</p>
<p>44
0
</p>
<p>46
0
</p>
<p>48
0
</p>
<p>50
0
</p>
<p>52
0
</p>
<p>54
0
</p>
<p>56
0
</p>
<p>58
0
</p>
<p>60
0
</p>
<p>Time (in s)
</p>
<p>Av
er
</p>
<p>ag
e 
</p>
<p>re
ca
</p>
<p>ll
</p>
<p>I1
I2
I3
I4
I5
I6
</p>
<p>Figure 1 : &#201;valuation de l&#8217;apport des aides &#224; la navigation en prenant compte du temps 
</p>
<p>La courbe pr&#233;c&#233;dente montre la progression du nombre de documents pertinents r&#233;cup&#233;r&#233;s en 
utilisant les diff&#233;rentes interfaces. La courbe I6 (interface utilisant toutes les fonctionnalit&#233;s 
d&#8217;aide &#224; la navigation) obtient des r&#233;sultats tr&#232;s au-dessus de la courbe I1 (interface basique). 
</p>
<p>146</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Aides &#224; la navigation dans un corpus oral 
</p>
<p>Ces exp&#233;riences ont donc montr&#233; l&#8217;int&#233;r&#234;t de ces aides &#224; la navigation sur un corpus &#233;crit. Un 
corpus oral pr&#233;sente en revanche des difficult&#233;s pouvant r&#233;duire l&#8217;utilit&#233; de telles 
fonctionnalit&#233;s.
</p>
<p>3 Difficult&#233;s apport&#233;es par la transcription 
Le corpus est constitu&#233; de 1048 fichiers au format xml, repr&#233;sentant chacun une heure de 
transcription automatique. Ils couvrent l&#8217;ensemble des &#233;missions radio de France Culture et 
de France Inter dans la p&#233;riode du 6/2/05 au 28/2/05. L&#8217;unit&#233; habituelle d&#8217;indexation dans un 
contexte de corpus &#233;crit est le fichier, qui correspond dans la majorit&#233; des cas aussi &#224; une 
unit&#233; th&#233;matique. La notion de document a donc d&#251; &#234;tre red&#233;finie puisque plusieurs &#233;missions 
sont pr&#233;sentes dans une heure de radio.
</p>
<p>La transcription issue de l&#8217;outil de Vecsys et du LIMSI (Gauvain et al., 2000) n&#8217;est pas un 
texte conforme &#224; ceux habituellement trait&#233;s &#224; Sinequa. La Figure 2 montre un passage 
transcrit par cet outil.
</p>
<p>Figure 2 : Exemple de transcription (les mots en gras sont ceux pr&#233;sents dans la requ&#234;te d&#8217;origine) 
</p>
<p>Nous voyons ici, des caract&#233;ristiques classiques d&#8217;une transcription automatique :  
</p>
<p>&#8211; Chaque fichier xml est structur&#233; par les tours de parole. Ceux-ci ne repr&#233;sentent pas 
forc&#233;ment une unit&#233; th&#233;matique, mais ils ont &#233;t&#233; index&#233;s comme des documents faute 
d&#8217;un meilleur d&#233;coupage. Les balises des tours de parole comportent des attributs avec 
l&#8217;heure de d&#233;but et de fin du tour de parole. Ces informations sont exploit&#233;es dans la 
maquette pour retrouver la partie du fichier audio qui y correspond. D&#8217;autres attributs 
non exploit&#233;s sont l&#8217;identifiant de la personne qui parle et son sexe. Un flux de parole 
n&#8217;est pas aussi propre qu&#8217;un article de journal. Les locuteurs peuvent se couper la 
parole, parler en m&#234;me temps ce qui rend la transcription tr&#232;s al&#233;atoire. La qualit&#233; de 
transcription peut &#234;tre tr&#232;s diff&#233;rente d&#8217;un locuteur &#224; un autre selon la fa&#231;on 
d&#8217;articuler, l&#8217;accent ou le fait que le journaliste peut &#234;tre sur son plateau de radio alors 
que l&#8217;interview&#233; est au t&#233;l&#233;phone (d&#8217;o&#249; une qualit&#233; de son tr&#232;s mauvaise).  
</p>
<p>147</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Frederik CAILLIAU, Claude DE LOUPY
</p>
<p>&#8211; Le texte ne comporte aucune ponctuation. Les seules ponctuations pr&#233;sentes sont les 
deux traits qui indiquent une pause, une respiration, mais auxquels on ne peut attribuer 
de s&#233;mantique ou de syntaxe significative pour nos traitements. Les majuscules de 
d&#233;but de phrase ne sont pas non plus donn&#233;es. L&#8217;unit&#233; phrastique est donc 
compl&#232;tement absente et c&#232;de sa place au tour de parole. Nous avons tent&#233; d&#8217;effectuer 
des adaptations de nos mod&#232;les statistiques pour prendre en compte ce ph&#233;nom&#232;ne, 
mais il aurait fallu un &#233;tiquetage de corpus pour pouvoir l&#8217;effectuer de mani&#232;re 
correcte. Du fait de l&#8217;absence d&#8217;un tel corpus &#233;tiquet&#233;, les exp&#233;riences, utilisant des 
corpus normaux transform&#233;s pour ressembler &#224; du corpus oral n&#8217;ont pas &#233;t&#233; probantes. 
A cause de l&#8217;absence de ponctuation et du fait de la syntaxe propre &#224; l&#8217;oral, les 
transcriptions, m&#234;me si elles sont de tr&#232;s bonne qualit&#233;, sont souvent difficilement 
lisibles. L&#8217;&#233;coute des morceaux s&#233;lectionn&#233;s s&#8217;impose pour une bonne compr&#233;hension. 
Un tour de parole dans un journal se termine par exemple souvent par le nom de la 
personne qui va prendre la parole juste apr&#232;s dans la suite du bulletin sans aucune 
transition : &#171; [&#8230;] une gauche &#224; r&#233;unifier dans un bel ensemble Fr&#233;d&#233;ric Pommier &#187;.
</p>
<p>&#8211; La transcription comporte l&#8217;ensemble des disfluences, h&#233;sitations, r&#233;p&#233;titions, faux 
d&#233;parts, etc.  propres &#224; l&#8217;oral et pr&#233;sente donc souvent des diff&#233;rences importantes par 
rapport &#224; un texte &#233;crit.
</p>
<p>&#8211; Il y a des erreurs de transcription. La transcription de la Figure 2 est excellente mais 
comporte malgr&#233; tout quelques erreurs. Ainsi, &#224; la 9&#232;me ligne, le logiciel de 
transcription a &#233;crit &#171; avoue Anne &#187; au lieu de &#171; &#224; Wuhan &#187; (ville n&#8217;&#233;tant pas pr&#233;sente 
dans le lexique du syst&#232;me). Les transcriptions sont en g&#233;n&#233;ral de tr&#232;s bonne qualit&#233; : 
le Word Error Rate (WER) sur les &#233;missions radio a &#233;t&#233; &#233;valu&#233; en 2001 &#224; 20% sur le 
type de corpus qui nous int&#233;resse ici (Gauvain et al., 2001) mais les mod&#232;les ont &#233;t&#233; 
am&#233;lior&#233;s depuis et ont &#233;t&#233; &#233;valu&#233;s &#224; 11,9% de WER pendnat la campagne ESTER 
(Galliano et al., 2005). D&#8217;apr&#232;s nos observations, les erreurs relev&#233;es dans le corpus 
donn&#233; sont dues &#224; la pr&#233;sence d&#8217;un bruit ou d&#8217;une musique de fond, &#224; des lacunes 
lexicales ou au non-branchement de la d&#233;tection de la langue. Pour ce dernier cas, il 
arrive qu&#8217;une personne parle en anglais et qu&#8217;un interpr&#232;te effectue alors la traduction. 
Un grand nombre d&#8217;erreurs est alors g&#233;n&#233;r&#233;. Dans un esprit un peu diff&#233;rent, les 
chiffres peuvent &#234;tre transcrits en lettres, ce qui est le cas pour certaines ann&#233;es ou 
dans l&#8217;exemple suivant : &#171; [&#8230;] une petite baisse de z&#233;ro z&#233;ro neuf pour-cent &#224; quatre 
mille cinq points [&#8230;] &#187;. Il est bien s&#251;r possible de traiter facilement ce dernier point 
mais des particularit&#233;s de ce type impliquent des ajouts de modules.  
</p>
<p>L&#8217;ensemble de ces points conduit &#224; un certain nombre d&#8217;erreurs et de probl&#232;mes pour les 
fonctionnalit&#233;s qui suivent, en particulier les traitements linguistiques.  
</p>
<p>4 &#201;valuation
Nous avons mis en place la plate-forme Intuition avec un corpus oral sans aucune adaptation 
des traitements d&#233;crits dans 2. Nous mesurerons leurs performance et robustesse sur un 
corpus oral &#224; travers deux fonctions principales d&#8217;Intuition : la navigation par les concepts et 
les entit&#233;s nomm&#233;es d&#8217;une part et l&#8217;extraction des entit&#233;s dans les documents qui servent &#224; 
l&#8217;aide &#224; la lecture d&#8217;autre part. Ce qui est &#233;valu&#233; ici n&#8217;est pas le WER de la transcription mais 
son impact sur l&#8217;aide &#224; la navigation. 
</p>
<p>148</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Aides &#224; la navigation dans un corpus oral 
</p>
<p>4.1 &#201;valuation de la navigation 
</p>
<p>4.1.1 Navigation par concepts 
</p>
<p>A partir d&#8217;un jeu de requ&#234;tes existant issues de logs d&#8217;un client de Sinequa, 40 requ&#234;tes ont 
&#233;t&#233; s&#233;lectionn&#233;es auxquelles au moins 50 documents dans le corpus r&#233;pondent. Ces requ&#234;tes, 
de un &#224; quatre mots, n&#8217;ont subies aucune modification (casse, orthographe, etc.). Elles posent 
des questions sur des noms de personnes (saddam ; mahmoud abbas ; &#8230;), des questions sur 
des noms de personnes en association avec un concept (sistani irak ; sharon rice paix ; &#8230;), 
des questions th&#233;matiques (fatah ; armes nucl&#233;aires ; &#8230;) ou factuelles pour obtenir une 
information pr&#233;cise (chiites &#233;lections irak ; tgv Paris strasbourg ; &#8230;). Le jeu complet est 
pr&#233;sent&#233; en annexe.
</p>
<p>Afin de pouvoir comparer les r&#233;sultats de l&#8217;&#233;valuation sur le corpus oral aux performances 
pos&#233;es sur l&#8217;&#233;crit, nous avons fait les m&#234;mes tests sur un corpus &#233;crit de type presse, compos&#233; 
de 21984 fichiers xml pour une totalit&#233; de 81,1 Mo. Le corpus oral est donc celui pr&#233;sent&#233; en 
section 3.
</p>
<p>Nous avons &#233;valu&#233; les concepts qui sont extraits en fonction d&#8217;une requ&#234;te. Cette &#233;valuation 
est bas&#233;e sur leur structure, c'est-&#224;-dire que nous avons cherch&#233; &#224; savoir s&#8217;ils &#233;taient bien 
form&#233;s. Le but de cet article &#233;tant d&#8217;analyser l&#8217;impact des particularit&#233;s de la transcription, la 
pertinence des concepts par rapport &#224; la requ&#234;te n&#8217;est pas &#233;valu&#233;e.
</p>
<p>L&#8217;&#233;valuation elle-m&#234;me porte sur les 40 premiers concepts rapport&#233;s par le syst&#232;me. Elle a &#233;t&#233; 
effectu&#233;e par 3 personnes ayant une comp&#233;tence en linguistique. Pour chaque concept 
pr&#233;sent&#233;, il &#233;tait demand&#233; de noter s&#8217;il &#233;tait ou non bien form&#233;. La figure suivante montre 
l&#8217;&#233;volution des erreurs dans les concepts extraits.
</p>
<p>0,82
</p>
<p>0,84
</p>
<p>0,86
</p>
<p>0,88
</p>
<p>0,9
</p>
<p>0,92
</p>
<p>0,94
</p>
<p>0,96
</p>
<p>1 4 7 10 13 16 19 22 25 28 31 34 37
</p>
<p>20 mn
AudioSurf
</p>
<p>Figure 3 : &#201;valuation du nombre de concepts bien form&#233;s extraits d&#8217;un corpus audio (AudioSurf) et 
d&#8217;un corpus &#233;crit (20 mn) 
</p>
<p>On peut voir que les concepts mal form&#233;s sont plus nombreux sur les transcriptions que sur 
des textes normaux comme nous pouvions nous y attendre. Le taux d&#8217;erreur moyen sur le 
texte est de 5% et de 10% sur les transcriptions.
</p>
<p>149</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Frederik CAILLIAU, Claude DE LOUPY
</p>
<p>Le ph&#233;nom&#232;ne de forte d&#233;croissance en d&#233;but de courbe est d&#251; &#224; de mauvaises analyses des 
concepts et non &#224; une mauvaise transcription (on peut voir qu&#8217;elle appara&#238;t aussi sur le texte). 
Il s&#8217;agit de noms de lieux ou de personnes du Moyen Orient pour lesquels les transducteurs ne 
sont pas assez robustes. 16 requ&#234;tes sur 40 portent sur cette r&#233;gion du monde et des concepts 
comme Char el (au lieu de Charm el Cheikh) sont fr&#233;quemment extraits et se trouvent en t&#234;te 
de liste car le concept complet est tr&#232;s pertinent.  
</p>
<p>La croissance du nombre d&#8217;erreurs est assez forte (5 points) lorsque l&#8217;on passe aux 
transcriptions. Cette d&#233;croissance provient d&#8217;erreurs comme &#171; sa patte h&#233;ros &#187; au lieu de 
Zapatero, &#171; Traque Tommy &#187; pour trach&#233;otomie ou &#171; Langeais Luce &#187; &#224; la place de 
&#171; l&#8217;Ang&#233;lus &#187;. N&#233;anmoins, nous restons dans un ordre d&#8217;erreurs acceptable (un concept sur 10 
mal form&#233;), c&#8217;est-&#224;-dire qu&#8217;il est visible et bien pr&#233;sent mais non pr&#233;judiciable &#224; la 
navigation.
</p>
<p>4.1.2 Navigation par entit&#233;s nomm&#233;es 
</p>
<p>L&#8217;&#233;valuation de la navigation par entit&#233;s nomm&#233;es n&#8217;&#233;tait pas pertinente dans le contexte 
pr&#233;sent. Les lieux et les entreprises sont extraits par listes (avec quelques contextes 
restrictifs). Sur les entreprises, seules des choses correctes sont renvoy&#233;es et les manques 
viennent plut&#244;t de l&#8217;incompl&#233;tude des listes utilis&#233;es. Pour la g&#233;ographie, le rappel et la 
pr&#233;cision sont tr&#232;s bons mais certaines erreurs r&#233;currentes apparaissent avec &#171; France deux &#187; 
et &#171; France inter &#187; dont le premier terme est reconnu comme le pays. 
</p>
<p>4.2 &#201;valuation de l&#8217;aide &#224; la lecture 
</p>
<p>Cette &#233;valuation est semblable &#224; l&#8217;&#233;tude qu&#8217;ont faite Kubala et al. (1998). Les &#233;missions de 
France Culture comportant peu d&#8217;entit&#233;s nomm&#233;es, nous avons choisi comme &#233;chantillon 
deux heures d&#8217;&#233;mission de France Inter. L&#8217;&#233;tude a port&#233; sur la premi&#232;re demi-heure de 
chacune de ces &#233;missions, car c&#8217;est la partie qui est la plus dense en entit&#233;s nomm&#233;es.  
</p>
<p>L&#8217;identification des entit&#233;s nomm&#233;es est fortement li&#233;e &#224; la pr&#233;sence de ces entit&#233;s dans les 
lexiques utilis&#233;s pour la reconnaissance de la parole. Si le nom propre est inconnu de ces 
lexiques, les mots en question sont remplac&#233;s par des mots communs, ce qui rend impossible 
toute d&#233;tection par les grammaires d&#8217;extraction. 
</p>
<p>Le tableau suivant pr&#233;sente une &#233;valuation du rappel et de la pr&#233;cision de la reconnaissance 
des personnes dans 3 contextes : 
</p>
<p>&#8211; La transcription automatique c'est-&#224;-dire sans se pr&#233;occuper des mauvaises 
transcriptions. Ainsi, si une personne est cit&#233;e &#224; l&#8217;oral mais que la transcription en la 
fait pas appara&#238;tre (elle se trompe), elle n&#8217;est pas prise en compte dans le calcul.  
</p>
<p>&#8211; La confrontation &#224; l&#8217;oral : si une entit&#233; est mal transcrite, elle sera comptabilis&#233;e 
quand m&#234;me, ce qui fait chuter le rappel. Nous avons donc corrig&#233; la transcription 
automatique pour effectuer cette &#233;valuation. 
</p>
<p>&#8211; La transcription manuelle : afin d&#8217;&#233;valuer l&#8217;impact des erreurs de transcription, nous 
avons corrig&#233; manuellement celle-ci et repass&#233; l&#8217;extraction des entit&#233;s afin de 
r&#233;&#233;valuer la pr&#233;cision et le rappel sur une transcription jug&#233;e sans erreur par le 
transcripteur humain.  
</p>
<p>150</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Aides &#224; la navigation dans un corpus oral 
</p>
<p>transcription automatique confrontation &#224; 
l&#8217;oral
</p>
<p>transcription manuelle 
</p>
<p>Pr&#233;cision 0,90 0,90 0,91
Rappel 0,73 0,65 0,80
</p>
<p>Les erreurs de transcription mises en cause concernent des entit&#233;s comme Mahmoud Abbas 
qui sont reconnues sous un autre nom (&#171; le dirigeant palestinien Marc Mbouda basses 
annoncent &#187;), des configurations diff&#233;rentes d&#8217;&#233;criture comme pour &#171; Jean Paul deux &#187; o&#249; ce 
cas d&#8217;&#233;criture n&#8217;a pas &#233;t&#233; pr&#233;vu dans les transducteurs, etc. 
</p>
<p>On constate que les erreurs de transcription ont pour cons&#233;quence une chute du rappel de 15 
points par rapport &#224; une transcription manuelle. Ce chiffre est tr&#232;s important et nous conduit &#224; 
penser que l&#8217;utilisation de cette fonctionnalit&#233; sur un corpus oral n&#8217;est peut-&#234;tre pas 
pertinente. N&#233;anmoins, les transcriptions ne sont pas faites pour &#234;tre lues mais plut&#244;t pour 
d&#233;terminer de quoi parle un texte et si l&#8217;on veut aller plus loin en &#233;coutant l&#8217;&#233;mission ou non. 
Tous les &#233;l&#233;ments permettant d&#8217;aider l&#8217;utilisateur &#224; appr&#233;hender plus vite l&#8217;int&#233;r&#234;t d&#8217;une 
&#233;mission sont int&#233;ressants dans ce contexte. Il faudrait une &#233;valuation de navigation avec 
utilisateur comme celle pr&#233;sent&#233;e en section 2.2 pour pouvoir conclure.
</p>
<p>5 Conclusion et perspectives 
Le but de notre &#233;tude &#233;tait d&#8217;&#233;valuer la portabilit&#233; sur du corpus oral des traitements faits 
habituellement sur l&#8217;&#233;crit. En ce qui concerne la navigation par concepts, nous avons constat&#233; 
une d&#233;gradation significative mais tout &#224; fait acceptable au per&#231;u des utilisateurs. Les 
performances de l&#8217;extraction des entit&#233;s nomm&#233;es sur les documents du corpus oral sont bien 
faibles en rappel, mais la pr&#233;cision et le rappel sont en m&#234;me temps d&#233;j&#224; un apport pour la 
fonctionnalit&#233; vis&#233;e. Dans les syst&#232;mes qui traitent de l&#8217;oral, toute am&#233;lioration qui r&#233;duit le 
temps d&#8217;acc&#232;s &#224; un morceau pr&#233;cis est un gain pour l&#8217;utilisateur. D&#8217;autres exp&#233;riences qui 
mettent l&#8217;utilisateur au centre de l&#8217;&#233;valuation sont &#224; mener, justement pour mesurer si l&#8217;apport 
en efficacit&#233; est comparable &#224; celui constat&#233; sur le texte. 
</p>
<p>Remerciements
Les auteurs tiennent &#224; remercier M&#233;lodie Soufflard pour son travail d&#8217;analyse et d&#8217;&#233;tiquetage.  
</p>
<p>R&#233;f&#233;rences
ALLEN J. (2002). Perspectives on Information Retrieval and Speech. In Information Retrieval 
Techniques for Speech Applications, Coden, Brown, and Srinivasan (Eds.).. 
</p>
<p>ANICK, P.G., TIPIRNENI, S. (1999). The paraphrase search assistant: terminological feedback 
for iterative information seeking. Proceedings of the 22nd Annual international ACM SIGIR 
Conference on Research and Development in information Retrieval. SIGIR '99. ACM Press, 
New York, NY, pp. 153-159. 
</p>
<p>CAILLIAU F. (2006). Un mod&#232;le pour unifier la gestion de ressources linguistiques en contexte 
multilingue. Actes de TALN 2006. 
</p>
<p>151</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Frederik CAILLIAU, Claude DE LOUPY
</p>
<p>Choi J., Hindle D., Pereira F., Singhal A., Whittaker S. (1999). Spoken content-based audio 
navigation (SCAN). Proceedings of the ICPhS-99. 
</p>
<p>GALLIANO S., GEOFFROIS E., MOSTEFA D., CHOUKRI K., BONASTRE J.-F., GRAVIER G. (2005). 
The ESTER Phase II Evaluation Campaign for the Rich Transcription of French Broadcast 
News. Proceedings of the European Conf. on Speech Communication and Technology. 
</p>
<p>GAUVAIN J.L., LAMEL L., ADDA G., ADDA-DECKER M., BARRAS C., CHEN L., KERCADIO Y. 
DE (2001). Processing Broadcast Audio for Information Access'. ACL 39th annual meeting, 
pp. 2-9. 
</p>
<p>GAUVAIN J.L., LORI L., ADDA G. (2000). Transcribing broadcast news for audio and video 
indexing. Communications of the ACM, vol. 43, n&#176; 2, pp. 64-70. 
</p>
<p>KUBALA F., SCHWARTZ R., STONE R., WEISCHEDEL R. (1998). Named entity extraction from 
speech. Proceedings of DARPA Broadcast News Transcription and Understanding.    
Workshop, Lansdowne, VA. 
</p>
<p>LOUPY C. DE, CRESTAN E. (2004). Browsing Help for Faster Document Retrieval. Actes de
Coling.
</p>
<p>MERLINO, A., MOREY, D., MAYBURY, M. (1997). Broadcast news navigation using story 
segmentation. Proceedings of the Fifth ACM international Conference on Multimedia,
MULTIMEDIA '97. ACM Press, New York, NY, pp. 381-391. 
</p>
<p>VAN THONG J.M., MORENO P.J., LOGAN B., FIDLER B., MAFFEY K., MOORES, M. (2002).
SpeechBot: An Experimental Speech-based Search Engine for Multimedia Content on the 
Web. IEEE Transactions on Multimedia, Vol 4, Nr. 1. 
</p>
<p>Annexe : liste des requ&#234;tes 
1 nucl&#233;aire iran 15 Paris 29 tgv Paris strasbourg 
2 chiites irak 16 Californie 30 chiites &#233;lections irak 
3 russie gaz 17 Irlande 31 mur palestine 
4 explosions de gaz 
</p>
<p>Paris 
18 Irak 32 cessez le feu intifada 
</p>
<p>5 attentat madrid 19 ONU 33 vote constitution 
europ&#233;enne
</p>
<p>6 mahmoud abbas 20 OTAN 34 fatah
7 aubenas 21 chirac en chine 35 forum mondial 
8 Saddam 22 bush syrie 36 kyoto
9 Hussein 23 Poutine Rice 37 djihad
</p>
<p>10 Chirac 24 assassinat hariri 38 armes nucl&#233;aires 
11 Bush 25 moubarak et 
</p>
<p>abdallah
39 chomage
</p>
<p>12 jean paul deux 26 sida new york 40 grippe pape 
13 &#201;yad&#233;ma 27 sistani irak 
14 Jean-Pierre Raffarin 28 sharon rice paix 
</p>
<p>152</p>

</div></div>
</body></html>