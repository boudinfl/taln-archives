<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Architecture compositionnelle pour les d&#233;pendances crois&#233;es</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2007, Toulouse, 5&#8211;8 juin 2007
</p>
<p>Architecture compositionnelle pour les d&#233;pendances crois&#233;es
</p>
<p>Alexandre DIKOVSKY
LINA-FRE CNRS 2729, Universit&#233; de Nantes
</p>
<p>Alexandre.Dikovsky@univ-nantes.fr
</p>
<p>R&#233;sum&#233;. L&#8217;article pr&#233;sente les principes g&#233;n&#233;raux sous-jacent aux grammaires cat&#233;go-
rielles de d&#233;pendances : une classe de grammaires de types r&#233;cemment propos&#233;e pour une des-
cription compositionnelle et uniforme des d&#233;pendances continues et discontinues. Ces gram-
maires tr&#232;s expressives et analys&#233;es en temps polynomial, adoptent naturellement l&#8217;architecture
multimodale et expriment les d&#233;pendances crois&#233;es illimit&#233;es.
Abstract. This article presents the general principles underlying the categorial depen-
dency grammars : a class of type logical grammars recently introduced as a compositional and
uniform definition of continuous and discontinuous dependences. These grammars are very
expressive, are parsed in a reasonable polynomial time, naturally adopt the multimodal archi-
tecture and explain unlimited cross-serial dependencies.
Mots-cl&#233;s : grammaires cat&#233;gorielles de d&#233;pendances, grammaires multimodales, ana-
lyseur syntaxique.
</p>
<p>Keywords: categorial dependency grammars, multimodal grammars, syntactic parser.
</p>
<p>1 Introduction
L&#8217;int&#233;r&#234;t principal des grammaires de types logiques dont les grammaires cat&#233;gorielles (GC) est
leur lien direct et transparent avec la s&#233;mantique formelle compositionnelle. Ce lien est &#233;tabli
pour une phrase g&#233;n&#233;r&#233;e &#224; travers l&#8217;isomorphisme entre une preuve de correction du choix des
types pour les mots dans la phrase et l&#8217;expession s&#233;mantique extraite de cette preuve. Les rela-
tions syntaxiques entre les mots d&#233;finies par les types sont formalise&#233;s par un calcul logique de
types qui n&#8217;est pas sp&#233;cifique &#224; une grammaire mais &#224; une classe de grammaires. On construit
ainsi des interfaces simples et &#233;l&#233;gantes entre la syntaxe et la s&#233;mantique &#224; la base de principes
plus ou moins universels. Tant que les relations entre les mots (d&#233;pendances) s&#8217;accordent bien
avec les relations de pr&#233;c&#233;dence (ordre des mots), &#224; savoir lorsqu&#8217;elles ne d&#233;passent jamais
les limites des domaines syntaxiques l ocaux des mots (d&#233;pendances projectives), les preuves
de correction sont isomorphes aux syst&#232;mes de constituents des phrases. A ce niveau de re-
pr&#233;sentation syntaxique il est en principe possible de d&#233;finir les types directement en termes de
d&#233;pendances. En fait, les premi&#232;res d&#233;finitions des grammaires de d&#233;pendances (GD) (Gaifman,
1961) ont &#233;t&#233; similaires &#224; celle des GC classiques (Bar-Hillel, 1953) 1. Cependant, il existe dans
</p>
<p>1Or, m&#234;me &#224; ce niveau, on peut remarquer qu&#8217;&#224; la diff&#233;rence des grammaires de types logiques, les GD traitent
les modifieurs comme adjoints.
</p>
<p>165</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre DIKOVSKY
</p>
<p>toute langue des d&#233;pendances non born&#233;es par les domaines locaux (d&#233;pendances non projec-
tives). Elles sont dues aux formes et aux mots fonctionnels discontinus (comme les particules
n&#233;gatives, les pronoms comparatifs, etc.), ou &#224; l&#8217;interf&#233;rence des &#233;l&#233;ments des structures extra-
syntaxiques telles que la structure communicative (cf. la topicalisation), la co-r&#233;f&#233;rence, les
relations de port&#233;e, etc. ou, au contraire, sont dues au manque en surface, des membres des
relations s&#233;mantiques (comme c&#8217;est le cas de la relativisation ou de l&#8217;extraction au cours de
la coordination). Pour y faire face les calculs logiques sont compl&#233;t&#233;s par des r&#232;gles qui, d&#8217;un
c&#244;t&#233;, rendent les preuves plus flexibles au d&#233;triment du lien direct avec les constituents, e.g. en
montant les types (Lambek, 1961; Steedman, 1996), et d&#8217;un autre c&#244;t&#233;, les rendent plus s&#233;lec-
tives, e.g. en choisissant les r&#232;gles structurelles sp&#233;cifiques en foncion de connecteurs diff&#233;rents
(r&#232;gles multimodales dues &#224; Oehrle, Morrill, Moortgat et Hepple (Morrill, 1994; Moortgat,
1997)). Avec ces moyens on peut exprimer les d&#233;pendances non born&#233;es tout en gardant l&#8217;in-
terpr&#233;tation s&#233;mantique compositionnelle. En m&#234;me temps, &#224; cause de l&#8217;expressivit&#233; accrue, la
complexit&#233; des preuves devient exponentielle, voire pire.
Dans l&#8217;article (Dikovsky, 2004), nous avons propos&#233; une nouvelle architecture compositionnelle
de types invariables de d&#233;pendances (sans mont&#233;e des types). Elle est &#233;tablie sur la base de la
distinction faite entre les types neutres des d&#233;pendances projectives, qui sont formalis&#233;s par la
r&#232;gle classique d&#8217;&#233;limination d&#8217;arguments, et les types des d&#233;pendances non born&#233;es (valences)
dot&#233;s de polarisation et d&#8217;orientation, qui sont formalis&#233;s par une r&#232;gle appel&#233;e FA (first avai-
lable) de saturation (appariement) des valences. La base psycholinguistique de cette r&#232;gle est
l&#8217;hypoth&#232;se que les d&#233;pendances non born&#233;es sont g&#233;r&#233;es par les piles dans la m&#233;moire dyna-
mique d&#8217;analyse. FA s&#233;lectionne la plus proche valence polaris&#233;e duale dans la direction indi-
qu&#233;e. Elle est conforme avec la majorit&#233; des d&#233;pendances non projectives dans maintes langues.
On a &#233;labor&#233; diff&#233;rents calculs de d&#233;pendances avec la r&#232;gle FA (Dekhtyar &amp; Dikovsky, 2004;
Dekhtyar &amp; Dikovsky, 2007). Les Grammaires Cat&#233;gorielles de D&#233;pendances (CDG) corres-
pondantes s&#8217;av&#232;rent expressives. En m&#234;me temps, elles disposent d&#8217;algorithmes d&#8217;analyse en
temps polynomial. Tout de m&#234;me, la r&#232;gle FA n&#8217;est pas universelle. Par exemple, elle n&#8217;est pas
adapt&#233;e aux d&#233;pendances crois&#233;es illimit&#233;es du hollandais expos&#233;es dans (Bresnan et al., 1982).
C&#8217;est pourquoi, dans cet article nous explorons une autre r&#232;gle d&#8217;appariement FC (first cross)
qui s&#233;lectionne la premi&#232;re valence polaris&#233;e duale crois&#233;e dans la direction indiqu&#233;e. Ainsi, la
structure dynamique de m&#233;moire qui correspond &#224; cette r&#232;gle est la file d&#8217;attente. FC explique
les d&#233;pendances crois&#233;es illimit&#233;es en termes d&#8217;un langage simple de structures de d&#233;pendances
et non en termes du langage de copies, comme d&#8217;habitude. A l&#8217;instar de grammaires multimo-
dales de types, nous d&#233;finissons les CDG multimodales (mmCDG) o&#249; les r&#232;gles d&#8217;appariement
sont consid&#233;r&#233;es comme les modes de compositionnalit&#233; propres aux d&#233;pendances non projec-
tives. Nous montrons que la r&#232;gle FC est aussi efficace que la r&#232;gle FA et nous pr&#233;sentons un
algorithme d&#8217;analyse syntaxique de ces grammaires en temps polynomial.
</p>
<p>2 Grammaires cat&#233;gorielles de d&#233;pendances
Les CDG sont des grammaires cat&#233;gorielles (GC) qui, &#224; la diff&#233;rence des GC classiques, d&#233;-
finissent explicitement les relations de d&#233;pendance entre les mots dans la phrase et non les
relations de dominance entre les constituants. Elles peuvent d&#233;terminer les structures de d&#233;-
pendances (SD) plus g&#233;n&#233;rales que les arbres de d&#233;pendances (AD). Une SD d&#8217;une phrase
w = w1 . . . wn est un graphe orient&#233; dont les n&#339;ux sont les mots w1, . . . , wn ordonn&#233;s par
l&#8217;ordre dans w, avec un n&#339;ux s&#233;lectionn&#233; (la t&#234;te) et dont les arcs sont &#233;tiquet&#233;s par les noms
</p>
<p>166</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Architecture compositionnelle pour les d&#233;pendances crois&#233;es
</p>
<p>Figure 1
</p>
<p>des d&#233;pendances. E.g., la SD en figure 1 est un AD dont la t&#234;te (sa racine) est le mot &#233;tait.
Comme toutes les GC, les CDG n&#8217;ont pas de r&#232;gles. Une CDG peut &#234;tre vue comme un lexique
qui affecte &#224; chaque mot un ensemble de types de d&#233;pendances. La particularit&#233; essentielle des
types des CDG est la distinction faite entre les types de d&#233;pendances projectives qui relient le
gouverneur &#224; ses subordonn&#233;s appartenants &#224; son domaine local, et les types de d&#233;pendances
non projectives (non born&#233;es) qui le relient aux subordonn&#233;s d&#233;plac&#233;s vers les domaines des
autres mots. Les premiers sont d&#233;finis par les sous types arguments des types du gouverneur,
tandis que les derniers sont d&#233;finis par les valences dot&#233;es d&#8217;une polarisation et d&#8217;une orienta-
tion (gauche / droite) dont l&#8217;ensemble constitue pour chaque type son potentiel. Formellement,
les types de d&#233;pendances sont construits &#224; partir d&#8217;un ensemble C de types primitifs et d&#8217;un
ensemble V (C) de valences polaris&#233;es. Les &#233;l&#233;ments de C sont les noms des relations de
d&#233;pendance, dont un type s&#233;lectionn&#233; S (l&#8217;axiome). Les valences dans V (C) sont orient&#233;es :
V (C) = V l(C) &#8746; V r(C), o&#249; V l(C) consiste des valences gauches&#8601;d (n&#233;gative),&#8599;d (posi-
tive) et V r(C) consiste des valences droites&#8598;d (positive),&#8600;d (n&#233;gative) o&#249; d &#8712; C.
Un type (de d&#233;pendance) est une expression &#945;P , o&#249; &#945; est un type basique et P est un potentiel.
gCat(C) va noter l&#8217;ensemble des types sur C. Les types basiques B(C) sur C sont les types
fonctionnels traditionnels du 1r ordre destin&#233;s &#224; d&#233;finir les d&#233;pendances projectives :
</p>
<p>1. C &#8834; B(C). 2. Si &#945; &#8712; C et &#946; &#8712; B(C), alors [&#945;\&#946;], [&#945;&#8727; \&#946;], [&#946;/&#945;&#8727;], [&#946;/&#945;] &#8712; B(C). !
Les constructeurs \, / &#233;tant suppos&#233;s associatifs, tout type basique peut &#234;tre repr&#233;sent&#233; sous la
forme [alm\...\al1\f/ar1/.../arn]. Intuitivement, f est la d&#233;pendance du gouverneur et ali, arj
correspondent aux d&#233;pendances des subordonn&#233;s gauches et droites. d&#8727; correspond &#224; la d&#233;pen-
dance d it&#233;r&#233;e. f = S est le type des SD correctes. Les potentiels sont les suites de valences
polaris&#233;es. Ils sont destin&#233;s &#224; d&#233;finir les d&#233;pendances non projectives. Dans le cas de d&#233;pen-
dances projectives, ils sont vides. Les types avec le potentiel vide sont neutres. Par exemple,
l&#8217;AD projectif en figure 1 est d&#233;fini par les types neutres suivants :
</p>
<p>au )&#8594; [c&#8722;copul/prepos&#8722;a] commencement )&#8594; [prepos&#8722;a] le )&#8594; [det]
&#233;tait )&#8594; [c&#8722;copul\S/pred] Verbe )&#8594; [det\pred]
</p>
<p>Les valences &#8601; d et &#8599; d, d &#8712; C, peuvent &#234;tre vues comme les parenth&#232;ses gauches. Res-
pectivement, &#8598; d et &#8600; d sont les parenth&#232;ses droites. Pour une valence gauche, e.g. &#8601;d, la
valence correspondante (duale) droite,&#8598;d, est not&#233;e &#8601;&#774;d =&#8598;d. Ensemble ces valences duales
appari&#233;es d&#233;finissent la d&#233;pendance non projective d. L&#8217;adjacence est exprim&#233;e en utilisant les
types primitifs d&#8217;ancrage : pour ancrer une valence n&#233;gative v &#8712; {&#8601;d,&#8600;d | d &#8712; C} (la fin
d&#8217;une d&#233;pendance non projective), c&#8217;est-&#224;-dire la placer aupr&#232;s d&#8217;un mot d&#8217;appui, sont utilis&#233;s
les types primitifs particuliers d&#8217;ancrage :#(v) dont l&#8217;&#233;limination signifie l&#8217;adjacence des mots
et ne cr&#233;e aucune d&#233;pendance. E.g., l&#8217;AD non projectif en figure 2 est d&#233;fini par
</p>
<p>Figure 2
167</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre DIKOVSKY
</p>
<p>les types qui ancrent les clitiques la, lui sur l&#8217;auxiliaire a :
elle !&#8594; [pred] a !&#8594; [#(&#8601;clit&#8722;iobj)\#(&#8601;clit&#8722;dobj)\pred\S/aux]
la !&#8594; [#(&#8601;clit&#8722;dobj)]&#8601;clit&#8722;dobj lui !&#8594; [#(&#8601;clit&#8722;iobj)]&#8601;clit&#8722;iobj
donn&#233;e !&#8594; [aux]&#8598;clit&#8722;iobj&#8598;clit&#8722;dobj
</p>
<p>Le sens exact des types est d&#233;fini par le calcul de d&#233;pendances suivant 2 :
Ll. CP1 [C\&#946;]P2 % [&#946;]P1P2
</p>
<p>Il. CP1 [C&#8727;\&#946;]P2 % [C&#8727;\&#946;]P1P2
</p>
<p>&#8486;l. [C&#8727;\&#946;]P % [&#946;]P
</p>
<p>DlM. &#945;
P1(&#8601;C)P (&#8598;C)P2 % &#945;P1PP2 , si P1(&#8601;C)P (&#8598;C)P2 satisfait la r&#232;gle d&#8217;appariementM.
</p>
<p>Ll est la r&#232;gle classique d&#8217;&#233;limination. En &#233;liminant le sous-type argument C '= #(&#945;), elle cr&#233;e
la d&#233;pendance projective C et concat&#232;ne les potentiels. C = #(&#945;) ne cr&#233;e aucune d&#233;pendance.
Il cr&#233;e k &gt; 0 exemplaires de C. &#8486;l sert pour le cas k = 0 et pour &#233;liminer le sous-type it&#233;r&#233;.
DlM apparie et &#233;limine deux valences duales&#8601;C et&#8598;C selon la r&#232;gle d&#8217;appariementM et cr&#233;e
la d&#233;pendance non projective C. Voici deux r&#232;gles importantes d&#8217;appariement :
FAl : P n&#8217;a pas d&#8217;occurrence de&#8601;C,&#8598;C (apparier &#224; la plus proche valence duale disponible).
FCl : P1 et P n&#8217;ont pas d&#8217;occurrences, respectivement, de&#8601;C et de&#8598;C (apparier &#224; la premiere
valence duale crois&#233;e, c&#8217;est-&#224;-dire &#224; la plus lointaine disponible).
On voit que les valences ressamblent aux traits Slash des GPSG, HPSG, mais &#224; la place de r&#232;gles
complexes de &#171; propagation &#187;des traits Slash les CDG utilisent les r&#232;gles simples d&#8217;appariement
FA et FC. En admettant que toute d&#233;pendance non projective C peut avoir sa propre r&#232;gle
d&#8217;appariementMC nous consid&#233;rons cette r&#232;gle comme un mode de compositionnalit&#233; &#224; travers
C. Nous obtenons ainsi par analogie avec l&#8217;architecture multimodale pour les grammaires de
Lambek (Morrill, 1994; Moortgat, 1997) la notion suivante de grammaire.
D&#233;finition 1 Une grammaire cat&#233;gorielle multimodale de d&#233;pendances (mmCDG) est une
structure G = (W,C, S, &#948;, &#181;), o&#249; W est un vocabulaire, &#948; (le lexique) est une fonction qui
affecte &#224; chaque mot dansW un sous ensemble fini de types dans gCat(C) et &#181; est une fonction
qui affecte une r&#232;gle d&#8217;appariement &#224; toute d&#233;pendance non projective dans C.
Le calcul de d&#233;pendances d&#233;termine la relation de prouvabilit&#233; correspondante %&#181; sur les suites
de types. La prouvabilit&#233; sans r&#232;gles D (c&#8217;est-&#224;-dire, au cas de d&#233;pendances projectives) est
not&#233;e %c . Pour une SDD et une phrase w, la relationG(D,w) signifie : &#171;D est cr&#233;&#233;e au cours
d&#8217;une preuve &#915; %&#181; S pour une suite de types &#915; &#8712; &#948;(w) &#187;.
Le langage et le langage des SD g&#233;n&#233;r&#233;s parG sont respectivement les ensembles L(G)=df {w |
&#8707;D G(D,w)} et &#8710;(G)=df {D | &#8707;w G(D,w)}. mmCDG&#181; et L(mmCDG&#181;) sont respective-
ment la famille des grammaires et des langages correspondants.
</p>
<p>3 Expressivit&#233; des mmCDG
Les mmCDG sont tr&#232;s expressives. Avec la r&#232;gle FA elles g&#233;n&#232;rent tous les langages non
contextuels (alg&#233;briques), mais aussi maints langages contextuels dont {anbncn | n &gt; 0}, les
langages L(m) = {an1an2 ...anm | n &#8805; 1} (Dikovsky, 2004) qui sont faiblement contextuels mais
non-TAG &#224; partir de m &gt; 4, le langage MIX, qui contient toutes permutations des motifs
anbncn, n &gt; 0, MIX = {w &#8712; {a, b, c}+ | |w|a = |w|b = |w|c}. Or, selon l&#8217;hypoth&#232;se de E.
</p>
<p>2Nous exposons les r&#232;gles gauches. Les r&#232;gles droites sont sym&#233;triques.
168</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Architecture compositionnelle pour les d&#233;pendances crois&#233;es
</p>
<p>Bach, MIX n&#8217;est pas faiblement contextuel, ainsi il ne serait pas g&#233;n&#233;r&#233; par une grammaire
minimaliste, ou multi-TAG, etc. Dans (Dekhtyar &amp; Dikovsky, 2007) on peut trouver d&#8217;autres
exemples et une preuve du fait que L(mmCDGFA) est une famille abstraite de langages (AFL).
D&#8217;un autre c&#244;t&#233;, nous croyons (Dikovsky, 2004; Dekhtyar &amp; Dikovsky, 2004) que le langage de
copies Lcopy = {ww |w &#8712; {a, b}+}, qui est g&#233;n&#233;r&#233; par une grammaire TAG, n&#8217;appartient pas
&#224; la famille L(mmCDGFA,FC). Ce langage est d&#8217;un int&#233;r&#234;t particulier parce qu&#8217;on croit qu&#8217;il
est un mod&#232;le de la construction en n&#233;erlandais dite des &#171; d&#233;pendances crois&#233;es illimit&#233;es &#187;.
Il s&#8217;agit des phrases n1n2 . . . nmnm+1v1v(inf)2 . . . v(inf)m, dont un exemple est en figure 3, o&#249;
il y a une d&#233;pendance pr&#233;dicative n1 pred&#8592;&#8722; v1 entre le verbe v1 en forme finie et le nom n1,
les d&#233;pendances pr&#233;dicatives ni pred&#8592;&#8722; v(inf)i entre les verbes v(inf)i &#224; l&#8217;infinitif et les noms ni,
pour tout 2 &#8804; i &#8804; m, et &#233;ventuellement, une d&#233;pendance d&#8217;objet direct nm+1 dobj&#8592;&#8722; v(inf)m si le
verbe v(inf)m est transitif et le nom nm+1 est pr&#233;sent (c&#8217;est-&#224;-dire, nm+1 %= &#949;).
</p>
<p>!
!&quot;
</p>
<p>!
!&quot;
</p>
<p>!
!&quot;#$!
</p>
<p>%&amp;
</p>
<p>!
</p>
<p>%&amp;
</p>
<p>!
</p>
<p>%&amp;
</p>
<p>!
</p>
<p>%&amp;
</p>
<p>!
Jan Piet Marie de kinderen zag helpen laten zwemmen
</p>
<p>det
</p>
<p>pred
</p>
<p>pred
</p>
<p>pred
</p>
<p>inf&#8722;dobj inf&#8722;dobj inf&#8722;dobj
</p>
<p>inf&#8722;dobj
</p>
<p>&#8727;Jan Piet Marie les enfants a vu aider faire nager
Figure 3.
</p>
<p>Par ailleurs, une analyse plus approfondie de cette construction (Pulman &amp; Ritchie, 1985)
montre que l&#8217;accord des formes existe seulement entre n1 et v1. Sinon, la forme du nom su-
bordonn&#233; est d&#233;termin&#233;e seulement par le verbe transitif v(inf)m et son argument nm+1. Cela
implique que le vrai mod&#232;le de cette construction n&#8217;est point le langage Lcopy, mais le langage
des SD &#8710;cross = {D(m) |m &gt; 0} surW = N &#8746; V, o&#249; N &#8745; V = &#8709;, D(m) est la SD en figure 4
et nil &#8712; N, vjr &#8712; V. En m&#234;me temps, le langage correspondant est alg&#233;brique (voire lin&#233;aire).
</p>
<p>!
'(
</p>
<p>!
'(
</p>
<p>%&amp;
</p>
<p>!
</p>
<p>%&amp;
</p>
<p>!
</p>
<p>%&amp;
</p>
<p>!
ni1 ni2 nim vj2vj1. . . vjm
</p>
<p>R R
. . .
</p>
<p>. . .
</p>
<p>L
</p>
<p>L
</p>
<p>D(m) =
</p>
<p>L
</p>
<p>Figure 4. AD D(m)
</p>
<p>Le langage &#8710;cross est g&#233;n&#233;r&#233; par lammCDGFC suivante :
</p>
<p>Gcross =
</p>
<p>{
n )&#8594; [#(L)]&#8601;L, [#(L)\#(L)]&#8601;L, pour n &#8712; N
v )&#8594; [#(L)\S/R]&#8598;L, [R/R]&#8598;L, [R]&#8598;L, pour v &#8712; V
</p>
<p>E.g., une preuve de D(3) &#8712; &#8710;cross est montr&#233;e en figure 5.
[#(L)]&#8601;L[#(L)\#(L)]&#8601;L
</p>
<p>(Ll)
[#(L)]&#8601;L&#8601;L [#(L)\#(L)]&#8601;L
</p>
<p>(Ll)
[#(L)]&#8601;L&#8601;L&#8601;L
</p>
<p>[#(L)\S/R]&#8598;L
[R/R]&#8598;L[R]&#8598;L
</p>
<p>(Lr)
[R]&#8598;L&#8598;L
</p>
<p>(Lr)
[#(L)\S]&#8598;L&#8598;L&#8598;L
</p>
<p>(Ll)
[S]&#8601;L&#8601;L&#8601;L&#8598;L&#8598;L&#8598;L
</p>
<p>(DlFC &#215; 3)
[S]
</p>
<p>Figure 5.
169</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre DIKOVSKY
</p>
<p>4 Fondements th&#233;oriques
Notre solution du probl&#232;me des d&#233;pendances crois&#233;es repose sur l&#8217;ind&#233;pendance des types ba-
siques et des valences polaris&#233;es dans les preuves du calcul de d&#233;pendances. Cette propri&#233;t&#233; est
exprim&#233;e en termes de projections et de suites de cat&#233;gories bien appari&#233;es.
Pour une suite de cat&#233;gories &#947; &#8712; gCat(C)&#8727; ses projections locale &#8214;&#947;&#8214;l et de valences &#8214;&#947;&#8214;v sont
d&#233;finies ainsi : pour tous &#945; &#8712; gCat(C), &#947; &#8712; gCat(C)&#8727; et CP &#8712; gCAT (C),
1. &#8214;&#949;&#8214;l = &#8214;&#949;&#8214;v = &#949;; &#8214;&#945;&#947;&#8214;l = &#8214;&#945;&#8214;l&#8214;&#947;&#8214;l et &#8214;&#945;&#947;&#8214;v = &#8214;&#945;&#8214;v&#8214;&#947;&#8214;v
2. &#8214;CP&#8214;l = C et &#8214;CP&#8214;v = P.
Pour un potentiel P, sa projection &#8214;P&#8214;d sur une paire de valences duales vd, v&#774;d est d&#233;finie
comme h(P ) pour l&#8217;homomorphisme h(&#945;) = &#945; si &#945; &#8712; {vd, v&#774;d} et h(&#945;) = &#949; sinon. P est dit
&#233;quilibr&#233; si toute projection &#8214;P&#8214;d est bien appari&#233;e au sens habituel.
Soit |P |x le nombre d&#8217;occurrences de x dans P. Alors l&#8217;&#233;quilibre d&#8217;un potentiel P est incr&#233;men-
talement v&#233;rifiable en utilisant les quantit&#233;s suivantes pour toute &#945; &#8712; V l(C) et &#945;&#774; &#8712; V r(C) :
</p>
<p>&#8710;&#945;(P ) = max{|P &#8242;|&#945; &#8722; |P &#8242;|&#945;&#774; | P &#8242; est un suffixe de P},
&#8710;&#945;&#774;(P ) = max{|P &#8242;|&#945;&#774; &#8722; |P &#8242;|&#945; | P &#8242; est un pre&#769;fixe de P}.
</p>
<p>Elles expriment respectivement le d&#233;ficit des &#945;&#8722;parenth&#232;ses droites et gauches dans P (c&#8217;est-
&#224;-dire, le nombre de parenth&#232;ses droites (gauches) qu&#8217;il faut rajouter &#224; P de droite (de gauche)
pour qu&#8217;il devienne &#233;quilibr&#233;. Les propri&#233;t&#233;s suivantes sont v&#233;rifi&#233;es (Dekhtyar &amp; Dikovsky,
2004; Dekhtyar &amp; Dikovsky, 2007) :
</p>
<p>Lemme 1 1. Quels que soient des potentiels P1, P2 et des valences &#945; &#8712; V l(C), &#945;&#774; &#8712; V r(C),
&#8710;&#945;(P1P2) = &#8710;&#945;(P2) +max{&#8710;&#945;(P1)&#8722;&#8710;&#945;&#774;(P2), 0},
&#8710;&#945;&#774;(P1P2) = &#8710;&#945;&#774;(P1) +max{&#8710;&#945;&#774;(P2)&#8722;&#8710;&#945;(P1), 0}.
</p>
<p>2. Un potentiel P est &#233;quilibr&#233; ssi &#8721;
&#945;&#8712;V (C)
</p>
<p>&#8710;&#945;(P ) = 0.
</p>
<p>La propri&#233;t&#233; suivante d&#8217;ind&#233;pendance des projections (Dekhtyar &amp; Dikovsky, 2004; Dekhtyar
&amp; Dikovsky, 2007) garantit l&#8217;existence d&#8217;un algorithme polynomial d&#8217;analyse demmCDGFA.
</p>
<p>Th&#233;or&#232;me 1 Pour une mmCDG G = (W,C, S, &#948;, &#181;) avec le mode FA et x &#8712; W+, x &#8712; L(G)
ssi il y a une suite &#915; &#8712; &#948;(x) telle que &#8214;&#915;&#8214;l $c S et &#8214;&#915;&#8214;v est &#233;quilibr&#233;.
</p>
<p>Le seul point de sa preuve sensible aux modes est la proposition suivante vraie pour FA :
</p>
<p>Lemme 2 Un potentiel P est &#233;quilibr&#233; ssi pour toute cat&#233;gorie &#945;P il y a une preuve &#945;P $ &#945;
utilisant exclusivement les r&#232;glesDlM etDrM.
</p>
<p>Pour garantir l&#8217;ind&#233;pendance des projections (et par cons&#233;quent, une analyse polynomiale) pour
une mmCDGM , il faut prouver ce lemme pour tout modeM &#8712; M. En prouvant le lemme 2
pour FC, nous avons &#233;tendu le th&#233;or&#232;me 1 aux mmCDG avec les modes FA,FC :
</p>
<p>Th&#233;or&#232;me 2 Pour x &#8712; W+ et pour une mmCDGM G = (W,C, S, &#948;, &#181;) avec M = {FA},
ouM = {FC} ouM = {FA,FC}, x &#8712; L(G) ssi il y a une suite &#915; &#8712; &#948;(x) telle que &#8214;&#915;&#8214;l $c S
et &#8214;&#915;&#8214;v est &#233;quilibr&#233;.
</p>
<p>Corollaire 1 L(mmCDGFA) = L(mmCDGFC) = L(mmCDGFA,FC).
170</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Architecture compositionnelle pour les d&#233;pendances crois&#233;es
</p>
<p>5 Analyse syntaxique, complexit&#233;
Dans l&#8217;article (Dekhtyar &amp; Dikovsky, 2004) un algorithme d&#8217;analyse en temps polynomial a &#233;t&#233;
d&#233;crit pour une version sous commutative du calcul de d&#233;pendances 3. Dans l&#8217;article (Dekhtyar
&amp; Dikovsky, 2007) cet algorithme a &#233;t&#233; &#233;tendu aux mmCDGFA. Ce m&#234;me algorithme &#224; un
d&#233;tail pr&#232;s s&#8217;applique aussi auxmmCDGFA,FC. Nous l&#8217;exposons en figure 6.
Fonctions d&#8217;&#233;chec. Soit une mmCDGM G = (W,C, S, &#948;, &#181;) avec les valences polaris&#233;es
gauches V l(C) = {v1, . . . , vp} et droites V r(C) = {v&#774;1, . . . , v&#774;p}. Nous allons d&#8217;abord d&#233;finir
deux fonctions d&#8217;&#233;chec qui vont servir pour une optimisation de l&#8217;analyse. Soit w = w1w2...wn
&#8712; W+. Alors, pour 1 &#8804; i &#8804; n, &#945; &#8712; V l(C) et &#946; &#8712; V r(C),
</p>
<p>piL(&#945;, i) = max{&#8710;&#945;(&#8214;&#915;&#8214;v) | &#915; &#8712; &#948;(w1...wi)},
piR(&#946;, i) = max{&#8710;&#946;(&#8214;&#915;&#8214;v) | &#915; &#8712; &#948;(wn&#8722;i+1...wn)}
</p>
<p>sont les fonction d&#8217;&#233;chec gauche et droite. On suppose que piL(&#945;, 0) = piR(&#946;, 0) = 0.
Algorithme d&#8217;analyse syntaxique. mmCdgPars est un algorithme typique de &#171; program-
mation dynamique &#187;. Il s&#8217;applique &#224; une mmCDGM et &#224; une phrase w = w1w2...wn &#8712; W+ et
remplit une matrice triangulaireM dont la dimension est n&#215;n. L&#8217;&#233;l&#233;mentM [i, j], i &#8804; j, deM
correspond &#224; l&#8217;intervalle wi...wj de la phrase et repr&#233;sente un ensemble fini d&#8217;&#171; items &#187;. Un item
est une expression I = &#12296;C,&#8710;L,&#8710;R, I l, Ir&#12297; qui code une cat&#233;gorie CP , o&#249; C est une cat&#233;gorie
basique (C &#8712; B(C)), &#8710;L = (&#8710;v1 , . . . ,&#8710;vp) et &#8710;R = (&#8710;v&#774;1 , . . . , &#8710;v&#774;p) sont les vecteurs entiers
dont chaque composante i correspond &#224; la valence vi, respectivement v&#774;i, et vaut le d&#233;ficit cor-
respondant des vi-parenth&#232;ses droites (gauches) dans le potentiel P. Finalement, I l, Ir sont les
identificateurs des items dans les angles gauches et droites deM &#224; partir desquelles est calcul&#233;
l&#8217;item I (pour tout I &#8712;M [i, i] I l = Ir = &#8709;).
Complexit&#233;. Pour unemmCDGM G = (W,C, S, &#948;, &#181;), soit lG = |&#948;| le nombre d&#8217;affectations
des cat&#233;gories aux mots dans le lexique, soit aG = max{k | &#8707;x &#8712; W ([&#945;k\...\&#945;1\C/&#946;]P &#8712;
&#948;(x) &#8744; [&#946;\C/&#945;1/.../&#945;k]P &#8712; &#948;(x))} le nombre maximal de sous types arguments dans les
cat&#233;gories affect&#233;es, soit pG = |V l(C)| = |V r(C)| le nombre de valences polaris&#233;es et &#8710;G =
max{&#8710;&#945;(P ) | &#8707;x &#8712;W (CP &#8712; &#948;(x) &#8744; &#945; &#8712; V (C))} le d&#233;ficit maximal des valences parenth&#232;ses
dans les cat&#233;gories affect&#233;es. Finalement, soit n la longueur de la phrase analys&#233;e.
Th&#233;or&#232;me 3 L&#8217;algorithmemmCdgPars a une complexit&#233; en tempsO(lG &#183;a2G &#183;(&#8710;G &#183;n)2pG &#183;n3).
</p>
<p>Remarque 1 1. Pour une grammaire fix&#233;e G, les valeurs lG, aG, pG et &#8710;G sont constantes. Si
G varie, alors le probl&#232;me d&#8217;appartenance devient NP -compl&#232;t (Dekhtyar &amp; Dikovsky, 2004).
2. Si G est sans valence polaris&#233;e, alors la complexit&#233; est O(n3).
3. Soit le d&#233;ficit maximal de valences &#963;G(n) des potentiels survenants dans les preuves des
phrases dont la longueur est limit&#233;e par n. Si &#963;G(n) est born&#233;e par une constante c, alors G
peut &#234;tre transform&#233;e en une mmCDGG&#8242; sans valence polaris&#233;e dont le langage est alg&#233;brique
(Dikovsky, 2001). Or, la taille deG&#8242; est exponentielle par rapport &#224;G. Si, de plus, le nombre des
d&#233;pendances non born&#233;es dans une SD engendr&#233;e par G n&#8217;est jamais sup&#233;rieur &#224; une borne
constante uniforme (ce qui est typique pour maintes langues), alors la complexit&#233; est O(n3)
pour la m&#234;me grammaire G.
4. D&#8217;un autre c&#244;t&#233;, m&#234;me si toute d&#233;pendance de G (sauf S) &#233;tait d&#233;finie par une valence
polaris&#233;e, la complexit&#233; serait toujours polynomiale. Cette remarque explique que les mmCDG
sont bien adapt&#233;es aux langages avec l&#8217;ordre flexible. Les limites de cet article ne nous laissent
pas faire une analyse plus d&#233;taill&#233;e de ce cas important.
</p>
<p>3L&#8217;algorithme a &#233;t&#233; r&#233;alis&#233; en LISP par Darin et Hristian Todorov et en en C# par Ilya Zaytsev.
171</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre DIKOVSKY
</p>
<p>AlgorithmemmCdgPars
//Entr&#233;e : mmCDG G, phrase w = w1...wn
//Sortie : &#12296;&#8220;succe&#768;s&#8221;, DS D&#12297; ssi w &#8712; L(G)
{
CalcFailFuncL() ;
CalcFailFuncR() ;
for (k = 1, . . . , n)
{
</p>
<p>Propose( k )
}
for (l = 2, . . . , n)
{
</p>
<p>for (i = 1, . . . , n&#8722; l)
{
</p>
<p>j := i+ l &#8722; 1;
for (k = i, . . . , j &#8722; l)
{
</p>
<p>SubordinateL(i, k, j) ;
SubordinateR(i, k, j) ;
</p>
<p>}
}
</p>
<p>}
if (I = &#12296;S, (0, 0, . . . , 0), (0, 0, . . . , 0), I l, Ir&#12297; &#8712;M [1, n])
</p>
<p>return &#12296;&#8220;succe&#768;s&#8221;, Expand(I)&#12297; ;
//procedure Expand( I ) calcule la SD de sortie.
//Elle seule est sensible aux r&#232;gles d&#8217;appariement
//FA,FC. Elle est technique et n&#8217;est pas incluse
else
</p>
<p>return &#12296;&#8220;e&#769;chec&#8221;, &#8709;&#12297; ;
}
</p>
<p>//For 1 &#8804; i &#8804; n
Propose( i )
{
(loop) foreach (CP &#8712; &#948;(wi)
{
</p>
<p>foreach (v &#8712; V l(C))
{
</p>
<p>&#8710;L[v] := &#8710;v(P ) ;
if (&#8710;L[v] &gt; piR[v&#774;, n&#8722; j]) next (loop) ;
&#8710;R[v&#774;] := &#8710;v&#774;(P ) ;
if (&#8710;R[v&#774;] &gt; piL[v, i&#8722; 1]) next (loop) ;
</p>
<p>}
AddItem( M [i, i], &#12296;C,&#8710;L,&#8710;R, &#8709;, &#8709;&#12297; ) ;
</p>
<p>}
}
</p>
<p>AddItem( M [i, j], &#12296;C,&#8710;L,&#8710;R, I l, Ir&#12297; )
{
M [i, j] := M [i, j] &#8746; {&#12296;C,&#8710;L,&#8710;R, I l, Ir&#12297;} ;
if (C = [C &#8242; &#8727; \&#946;])
{
</p>
<p>AddItem( M [i, j], &#12296;[&#946;],&#8710;L,&#8710;R, I l, Ir&#12297; ) ;
}
if (C = [&#946;/C &#8242;&#8727;])
{
</p>
<p>AddItem( M [i, j], &#12296;[&#946;],&#8710;L,&#8710;R, I l, Ir&#12297; ) ;
}
</p>
<p>}
</p>
<p>CalcFailFuncL()
{
foreach (v &#8712; V l(C))
{
</p>
<p>piL[v, 0] := 0;
for (i = 1, . . . , n)
{
</p>
<p>pimax := 0;
foreach (CP &#8712; &#948;(wi))
{
</p>
<p>pimax := max{pimax,&#8710;v(P )+
max{piL[v, i&#8722; 1]&#8722;&#8710;v&#774;(P ), 0}};
</p>
<p>}
piL[v, i] := pimax;
</p>
<p>}
}
</p>
<p>}
</p>
<p>CalcFailFuncR() est similaire.
</p>
<p>//For 1 &#8804; i &#8804; k &#8804; j &#8804; n
SubordinateL( i, k, j )
{
(loop) foreach (I1 = &#12296;&#945;1,&#8710;L1 ,&#8710;R1 , I l1, Ir1&#12297; &#8712;M [i, k],
</p>
<p>I2 = &#12296;&#945;2,&#8710;L2 ,&#8710;
R
2 , I
</p>
<p>l
2, I
</p>
<p>r
2&#12297; &#8712;M [k + 1, j])
</p>
<p>{
foreach (v &#8712; V l(C))
{
</p>
<p>&#8710;L[v] := &#8710;L2 (v) +max{&#8710;
L
1 (v)&#8722;&#8710;
</p>
<p>R
2 (v), 0} ;
</p>
<p>if (&#8710;L[v] &gt; piR[v&#774;, n&#8722; j]) next (loop) ;
&#8710;R[v&#774;] := &#8710;R1 (v&#774;) +max{&#8710;
</p>
<p>R
2 (v&#774;)&#8722;&#8710;
</p>
<p>L
1 (v&#774;), 0} ;
</p>
<p>if (&#8710;R[v&#774;] &gt; piL[v, i&#8722; 1]) next (loop) ;
}
if ( &#945;1 = C and &#945;2 = [C\&#946;] )
{
</p>
<p>AddItem( M [i, j], &#12296;[&#946;],&#8710;L,&#8710;R, I1, I2&#12297; ) ;
}
elseif ( (&#945;1 = C and &#945;2 = [C &#8727; \&#946;]) or &#945;1 = [&#949;] )
{
</p>
<p>AddItem( M [i, j], &#12296;&#945;2,&#8710;L,&#8710;R, I1, I2&#12297; ) ;
}
</p>
<p>}
}
</p>
<p>SubordinateR( i, k, j ) est similaire.
</p>
<p>Figure 6. AlgorithmemmCdgPars
</p>
<p>172</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Architecture compositionnelle pour les d&#233;pendances crois&#233;es
</p>
<p>6 Comparaison, discussion
Certes, il y a des grammaires o&#249; l&#8217;expression des d&#233;pendances non born&#233;es ne pose pas pro-
bl&#232;me, e.g. HPSG (Pollard &amp; Sag, 1988), les extensions multimodales des grammaires de Lam-
bek (Morrill, 1994; Moortgat, 1997), dont certaines visent notamment les d&#233;pendances (Kruijff,
2001) et leur fournissent une interface compositionnelle avec la s&#233;mantique. Or, l&#8217;analyse avec
ces formalismes expressifs est tr&#232;s complexe et parfois n&#233;cessite l&#8217;utilisation des syst&#232;mes de
d&#233;monstration des th&#233;or&#232;mes. C&#8217;est aussi le cas des grammaires qui repr&#233;sentent PTIME,
dont RCG (Boullier, 2003). A la diff&#233;rence de mmCDG, ces grammaires n&#8217;ont pas d&#8217;algo-
rithme universel d&#8217;analyse en temps O(nk), o&#249; k d&#233;pend de l&#8217;alphabet. Cela concerne aussi les
grammaires bas&#233;es sur l&#8217;unification et les contraintes, e.g. (Duchier, 1999). Contrairement &#224; ces
formalismes, les mmCDG n&#8217;utilisent que les moyens primitifs d&#8217;une complexit&#233; faible. E.g.,
les Grammaires Topologiques de D&#233;pendances (Duchier &amp; Debusmann, 2001) (voir aussi (Br&#246;-
ker, 1998; Duchier et al., 2004)) utilisent les hierarchies des domaines de l&#8217;ordre des mots
(WO-domains) qui, en cas de discontinuit&#233;, servent &#224; exprimer les contraintes de contigu&#239;t&#233;,
de distance entre un gouverneur et son modifieur etc. Dans beaucoup des cas, ces contraintes
sont exprim&#233;es dans mmCDG par le moyen de sous types d&#8217;ancrage plac&#233;s dans les positions
correspondantes d&#8217;un type du gouverneur.
Les mmCDG repr&#233;sentent une alternative int&#233;ressante aux TAG (et &#233;quivalentes : CCG, HG
(Vijay-Shanker &amp; Weir, 1994)) et aux grammaires faiblement contextuelles (Joshi et al., 1991),
telles multi-TAG, non contextuelles multi-composantes, minimalistes, etc. Tout comme ces der-
ni&#232;res, les mmCDG disposent d&#8217;une analyse syntaxique en temps polynomial. On peut m&#234;me
constater, qu&#8217;en pratique l&#8217;algorithmemmCdgPars va avoir une complexit&#233;O(n3). Leur avan-
tage d&#233;cisif est l&#8217;architecture compositionnelle de d&#233;pendances o&#249; toutes les d&#233;pendances, pro-
jectives comme non born&#233;es, sont d&#233;finies par les types fonctionnels, ce qui cr&#233;e la base n&#233;-
cessaire pour une s&#233;mantique fonctionnelle de d&#233;pendances. En m&#234;me temps, cette architecture
adopte naturellement la multimodalit&#233; des d&#233;pendances non born&#233;es correspondant aux r&#232;gles
de saturation des valences sp&#233;cifiques aux diff&#233;rentes langues. Il est important de noter que cette
flexibilit&#233; syntaxique est atteinte sans explosion du co&#251;t de l&#8217;analyse syntaxique (par contraste
avec les grammaires de Lambek). Malgr&#233; leur simplicit&#233;, les mmCDG sont tr&#232;s expressives.
On a vu que pour exprimer les d&#233;pendances crois&#233;es illimit&#233;es on n&#8217;a pas besoin du langage de
copies, mais d&#8217;un langage des SD facilement exprim&#233; par les mmCDG. Et le fait queMIX est
un langage mmCDGFA montre que ces grammaires sont adapt&#233;es aux langues naturelles avec
l&#8217;ordre des mots flexible.
Enfin, il est difficile de comparer les mmCDG par l&#8217;expressivit&#233; avec les autres GD qui traitent
les d&#233;pendances non born&#233;es et qui les analysent en temps polynomial, e.g. (Kahane et al.,
1998; Br&#246;ker, 2000). Le pouvoir de ces grammaires n&#8217;est pas d&#233;termin&#233;e. Leurs d&#233;finitions
sont op&#233;rationnelles (cf. le &#171; lifting &#187;). L&#8217;avantage des mmCDG est leur transparence et leur
architecture compositionnelle de d&#233;pendances.
</p>
<p>R&#233;f&#233;rences
BAR-HILLEL Y. (1953). A quasi-arithmetical notation for syntactic description. Language,
29(1), 47&#8211;58.
BOULLIER P. (2003). Counting with range concatenation grammars. Theoretical Computer
Science, 293, 391&#8211;416.
</p>
<p>173</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre DIKOVSKY
</p>
<p>BRESNAN J., KAPLAN R., PETERS S. &amp; ZAENEN A. (1982). Cross-serial dependencies in
dutch. Linguistic Inquiry, 13(4), 613&#8211;635.
BR&#214;KER N. (1998). Separating surface order and syntactic relations in a dependency gram-
mar. In Proc. COLING-ACL, p. 174&#8211;180, Montreal.
BR&#214;KER N. (2000). Unordered and non-projective dependency grammars. Traitement Auto-
matique des Langues (TAL), 41(1), 245&#8211;272.
DEKHTYAR M. &amp; DIKOVSKY A. (2004). Categorial dependency grammars. In M. MOORT-
GAT &amp; V. PRINCE, Eds., Proc. of Intern. Conf. on Categorial Grammars, p. 76&#8211;91.
DEKHTYAR M. &amp; DIKOVSKY A. (2007). Generalized categorial dependency gram-
mars. In submission, www.sciences.univ-nantes.fr/info/perso/permanents/
dikovsky/.
DIKOVSKY A. (2001). Polarized non-projective dependency grammars. In P. DE GROOTE, G. MORILL
&amp; C. RETOR&#201;, Eds., Proc. of the Fourth Intern. Conf. on Logical Aspects of Computational Linguistics,
volume 2099 of LNAI, p. 139&#8211;157 : Springer.
DIKOVSKY A. (2004). Dependencies as categories. In &#8220;Recent Advances in Dependency Grammars&quot;.
COLING&#8217;04 Workshop, p. 90&#8211;97.
DUCHIER D. (1999). Axiomatizing dependency parsing using set constraints. In Sixth Meeting on
Mathematics of Language (MOL-6), p. 115&#8211;126, Orlando, Florida.
DUCHIER D. &amp; DEBUSMANN R. (2001). Topological dependency trees : A constraint-based account
of linear precedence. In Proc. of the Intern. Conf. ACL&#8217;2001, p. 180&#8211;187 : ACL &amp; Morgan Kaufman.
DUCHIER D., DEBUSMANN R. &amp; KRUIJFF G.-J. M. (2004). Extensible dependency grammar : A
new methodology. In COLING&#8217;04 Workshop, p. 78&#8211;84, Geneva.
GAIFMAN H. (1961). Dependency systems and phrase structure systems. Report p-2315, RAND Corp.
Santa Monica (CA). Published in Information and Control, 1965, v. 8, n &#9702; 3, pp. 304-337.
JOSHI A. K., SHANKER V. K. &amp; WEIR D. J. (1991). The convergence of mildly context-sensitive
grammar formalisms. In P. SELLS, S. SHIEBER &amp; T. WASOW, Eds., Foundational issues in natural
language processing, p. 31&#8211;81, Cambridge, MA : MIT Press.
KAHANE S., NASR A. &amp; RAMBOW O. (1998). Pseudo-projectivity : A polynomially parsable non-
projective dependency grammar. In Proc. COLING-ACL, p. 646&#8211;652, Montreal.
KRUIJFF G.-J. M. (2001). A Categorial-Modal Logical Architecture of Informativity : Dependency
Grammar Logic &amp; Information Structure. PhD thesis, Charles University, Prague.
LAMBEK J. (1961). On the calculus of syntactic types. In R. JAKOBSON, Ed., Structure of languages
and its mathematical aspects, p. 166&#8211;178. Providence RI : American Mathematical Society.
MOORTGAT M. (1997). Categorial type logics. In J. VAN BENTHEM &amp; A. TER MEULEN, Eds.,
Handbook of Logic and Language, chapter 2, p. 93&#8211;177. Elsevier, The MIT Press.
MORRILL G. V. (1994). Type Logical Grammar. Categorial Logic of Signs. Kluwer.
POLLARD C. &amp; SAG I. (1988). An Information Based Approach to Syntax and Semantics, Part I.
Stanford, California : CSLI.
PULMAN S. &amp; RITCHIE G. (1985). Indexed grammars and interesting dependencies. UEA Papers in
Linguistics, 23, 21&#8211;38.
M. STEEDMAN, Ed. (1996). Surface Structure and Interpretation. The MIT Press.
VIJAY-SHANKER K. &amp; WEIR D. (1994). The equivalence of four extensions of context-free grammars.
Mathematical Systems Theory, 27, 511&#8211;545.
</p>
<p>174</p>

</div></div>
</body></html>