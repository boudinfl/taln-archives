TALN 2007, Toulouse, 5-8 juiu 2007

Architecture compositionnelle pour les dépendances croisées

Alexandre DIKOVSKY
LINA—FRE CNRS 2729, Université de Nantes
Alexandre . Dikovsky@univ— nantes . fr

Résumé. L’article présente les principes généraux sous-jacent aux grammaires catego-
rielles de dépendances : une classe de grammaires de types récemment proposée po11r une des-
cription compositionnelle et uniforme des dépendances continues et discontinues. Ces gram-
maires tres expressives et analysées en temps polynomial, adoptent naturellement l’architecture
multimodale et expriment les dépendances croisées illimitées.

Abstract. This article presents the general principles underlying the categorial depen-
dency grammars : a class of type logical grammars recently introduced as a compositional and
uniform deﬁnition of continuous and discontinuous dependences. These grammars are very
expressive, are paxsed in a reasonable polynomial time, naturally adopt the multimodal archi-
tecture and explain unlimited cross-serial dependencies.

Mots-clés 2 grammaires catégorielles de dépendances, grammaires multimodales, ana-
lyse11r syntaxique.

Keywords: categorial dependency grammars, multimodal grammars, syntactic parser.

1 Introduction

L’intérét principal des grammaires de types logiques dont les grammaires catégorielles (GC) est
le11r lien direct et tlansparent avec la sémantique formelle compositionnelle. Ce lien est établi
pour une phrase générée a tlavers l’isomorphisme entre une preuve de correction du choix des
types po11r les mots dans la phrase et l’expession sémantique extlaite de cette preuve. Les rela-
tions syntaxiques entre les mots déﬁnies par les types sont formaliseés par un calcul logique de
types qui n’est pas spéciﬁque a une grammaire mais a une classe de grammaires. On construit
ainsi des interfaces simples et élégantes entre la syntaxe et la sémantique a la base de principes
plus ou moins universels. Tant que les relations entre les mots (dépendances) s’accordent bien
avec les relations de précédence (ordre des mots), a savoir lorsqu’elles ne dépassent jamais
les limites des domaines syntaxiques l ocaux des mots (dépendances projectives), les preuves
de correction sont isomorphes aux systemes de constituents des phrases. A ce niveau de re-
presentation syntaxique il est en principe possible de déﬁnir les types directement en termes de
dépendances. En fait, les premieres deﬁnitions des grammaires de dépendances (GD) (Gaifman,
1961) ont été similaires a celle des GC classiques (Bar-Hillel, 1953) 1. Cependant, il existe dans

‘Or, méme an ce niveau, on peut remarquer qu’a la différence des grammaires de types logiques, les GD traitent
les modiﬁeurs comn1e adjoints.

165

Alexandre DIKOVSKY

toute langue des dépendances non bornées par les domaines locaux (dépendances non projec-
tives). Elles sont dues aux formes et aux mots fonctionnels discontinus (comme les particules
négatives, les pronoms comparatifs, etc.), ou a l’interférence des éléments des structures extra-
syntaxiques telles que la structure communicative (cf. la topicalisation), la co-référence, les
relations de portée, etc. ou, au contraire, sont dues au manque en surface, des membres des
relations sémantiques (comme c’est le cas de la relativisation ou de l’extraction au co11rs de
la coordination). Po11r y faire face les calculs logiques sont complétés par des regles qui, d’un
coté, rendent les preuves plus ﬂexibles au détriment du lien direct avec les constituents, e. g. en
montant les types (Lambek, 1961; Steedman, 1996), et d’un autre coté, les rendent plus sélec-
tives, e. g. en choisissant les regles structurelles spéciﬁques en foncion de connecte11rs différents
(regles multimodales dues a Oehrle, Morrill, Moortgat et Hepple (Morrill, 1994; Moortgat,
1997)). Avec ces moyens on peut exprimer les dépendances non bomées tout en gardant l’in-
terprétation sémantique compositionnelle. En méme temps, a cause de l’expressivité accrue, la
complexité des preuves devient exponentielle, voire pire.

Dans l’article (Dikovsky, 2004), nous avons proposé une nouvelle architecture compositionnelle
de types invariables de dépendances (sans montée des types). Elle est établie s11r la base de la
distinction faite entre les types neutres des dépendances projectives, qui sont formalisés par la
regle classique d’élimination d’arguments, et les types des dépendances non bomées (valences)
dotés de polarisation et d’0rientaIi0n, qui sont formalisés par une regle appelée FA (ﬁrst avai-
lable) de saturation (appariement) des valences. La base psycholinguistique de cette regle est
l’hypothese que les dépendances non bomées sont gérées par les piles dans la mémoire dyna-
mique d’analyse. FA sélectionne la plus proche valence polarisée duale dans la direction indi-
quée. Elle est conforme avec la majorité des dépendances non projectives dans maintes langues.
On a élaboré différents calculs de dépendances avec la regle FA (Dekhtyar & Dikovsky, 2004;
Dekhtyar & Dikovsky, 2007). Les Grammaires Catégorielles de Dépendances (CDG) corres-
pondantes s’averent expressives. En méme temps, elles disposent d’algorithmes d’analyse en
temps polynomial. Tout de méme, la regle FA n’est pas universelle. Par exemple, elle n’est pas
adaptée aux dépendances croisées illimitées du hollandais exposées dans (Bresnan et al., 1982).
C’est pourquoi, dans cet article nous explorons une autre regle d’appariement FC (ﬁrst cross)
qui sélectionne la premiere valence polarisée duale croisée dans la direction indiquée. Ainsi, la
structure dynamique de mémoire qui correspond a cette regle est la ﬁle d’attente. FC explique
les dépendances croisées illimitées en termes d’un langage simple de structures de dépendances
et non en termes du langage de copies, comme d’habitude. A l’instar de grammaires multimo-
dales de types, nous déﬁnissons les CDG multimodales (mmCDG) ou les regles d’appariement
sont considérées comme les modes de compositionnalité propres aux dépendances non projec-
tives. Nous montrons que la regle FC est aussi efﬁcace que la regle FA et nous présentons un
algorithme d’analyse syntaxique de ces grammaires en temps polynomial.

2 Grammaires catégorielles de dépendances

Les CDG sont des grammaires catégorielles (GC) qui, a la différence des GC classiques, dé-
ﬁnissent explicitement les relations de dépendance entre les mots dans la phrase et non les
relations de dominance entre les constituants. Elles peuvent déterminer les structures de dé-
pendances (SD) plus générales que les arbres de dépendances (AD). Une SD d’une phrase
11; = wl . . . wn est un graphe orienté dont les noeux sont les mots w1,.. . , wn ordonnés par
l’ordre dans w, avec un noeux sélectionné (la téte) et dont les arcs sont étiquetés par les noms

166

Architecture compositionnelle pour les dépendances croisées

C-co ul red

VT

au commencement était Ie Verbe
Figurcl

des dépendances. E. g., la SD en ﬁgure 1 est un AD dont la téte (sa racine) est le mot était.
Comme toutes les GC, les CDG n’ont pas de régles. Une CDG peut étre vue comme un lexique
qui affecte a chaque mot un ensemble de t)y)es de dépendances. La particularité essentielle des
types des CDG est la distinction faite entre les types de dépendances projectives qui relient le
gouvemeur a ses subordonnés appartenants a son domaine local, et les types de dépendances
non projectives (non bomées) qui le relient aux subordonnés déplacés vers les domaines des
autres mots. Les premiers sont déﬁnis par les sous types arguments des types du gouvemeur,
tandis que les demiers sont déﬁnis par les valences dotées d’une polarisation et d’une orienta-
tion (gauche / droite) dont l’ensemble constitue pour chaque type son potentiel. Formellement,
les types de dépendances sont construits a partir d’un ensemble C de types primitﬁ et d’un
ensemble V(C) de valences polarisées. Les éléments de C sont les noms des relations de
dépendance, dont un type sélectionné S (l’axi0me). Les valences dans V(C) sont orientées :
V(C) = Vl(C) U V’(C), ofl Vl(C) consiste des valences gauches / d (négative), /‘d (posi-
tive) et V’ (C) consiste des valences droites ’\ d (positive), \,d (négative) ofl d E C.

Un t)y)e (de dépendance) est une expression 0/’ , oil at est un type basique et P est un potentiel.
gCat(C) va noter l’ensemble des types sur C. Les t)y)es basiques B(C) s11r C sont les types
fonctionnels traditionnels du 1’ ordre destinés a déﬁnir les dépendances projectives :

1. C C B(C). 2. Sia E C et,8 E B(C), alors [oz\,8], [Out \,8], [,3/01*], [,3/oz] E B(C). El
Les constructeurs \, / étant supposés associatifs, tout type basique peut étre représenté sous la
forme [alm\...\al1\f/arl / /am]. Intuitivement, f est la dépendance du gouvemeur et ah, am-
correspondent aux dépendances des subordonnés gauches et droites. d* correspond a la dépen-
dance d itérée. f = S est le type des SD correctes. Les potentiels sont les suites de valences
polarisées. Ils sont destinés a déﬁnir les dépendances non projectives. Dans le cas de dépen-
dances projectives, ils sont vides. Les types avec le potentiel vide sont neutres. Par exemple,
l’AD projectif en ﬁgure 1 est déﬁni par les types neutres suivants :

cm »—> [c—copul/prepos—a] commencement »—> [prepos—a] le »—> [det]

était »—> [c—copul\S/pred] Verbe »—> [det\pred]
Les valences / d et /‘ d, d E C, peuvent étre vues comme les parenthéses gauches. Res-
pectivement, ’\ d et \, d sont les parenthéses droites. Pour une valence gauche, e.g. / d, la
valence correspondante (duale) droite, ’\ d , est notée / d =’\d. Ensemble ces valences duales
appariées déﬁnissent la dépendance non projective d. L’adjacence est exprimée en utilisant les
types primitifs d ’ancrage : pour ancrer une valence négative 1) E {/ d, \,d I d E C} (la ﬁn
d’une dépendance non projective), c’est-a-dire la placer auprés d’un mot d ’appui, sont utilisés
les types primitif s particuliers d ’ancrage : #(v) dont l’élimination signiﬁe l’adjacence des mots
et ne crée aucune dépendance. E. g., l’AD non projectif en ﬁgure 2 est déﬁni par

red l2ll_t:d_OiJj
lg’ C“-..g|it_—igI§J‘-.\
‘___- ._

aux" ‘T,-.
C

If-

elle Ia lui a donnée

Figure 2
167

Alexandre DIKOVSKY

les types qui ancrent les clitiques la, lui s11r l’auxiliaire a :
elle »—> bred] a »—> [#(,/ clit—iobj)\#(,/ clit—dobj)\pred\S/aux]

la |—> [#(/ clit —dobj)]/climb!‘ lui |—> [#(/ clit—iobj)]/°”“‘°b"
dorme/e ._) [aux]\clit—iobj\clit—dobj

Le sens exact des types est déﬁni par le calcul de dépendances suivant 2 :

L1. CPI [o\,a1*’2 F L6]‘’‘’’“

11. oP1[o*\,a1P2 F [o*\,a1*’1P2

91. [O*\ﬁ]" F L81"

Dbl. aP1(/O)P(\C)P’ |- (IPIPP2, si P1(,/C)P(’\C)P2 satisfait la regle d’appariement M.

L1 est la regle classique d’élimination. En éliminant le sous-type argument C 75 #(a), elle crée
la dépendance projective C et concatene les potentiels. C = #(a) ne crée aucune dépendance.
I1 crée k: > 0 exemplaires de C. Q1 sert pour le cas k: = 0 et po11r éliminer le sous-type itéré.
Dbl apparie et élimine deux valences duales / C et ’\C selon la regle d’appa1iement M et crée
la dépendance non projective C. Voici deux regles importantes d’appariement :

FAl : P n’a pas d’occurrence de / C , ’\C (apparier a la plus proche valence duale disponible).

FCl : P1 et P n’ont pas d’occu1rences, respectivement, de / C et de ’\C (apparier a la premiere
valence duale croisée, c’est-a-dire a la plus lointaine disponible).

On voit que les valences ressamblent aux traits Slash des GPSG, HPSG, mais a la place de regles
complexes de « propagation »des traits Slash les CDG utilisent les regles simples d’appariement
FA et FC. En admettant que toute dépendance non projective C peut avoir sa propre regle
d’appariement Mg nous considérons cette regle comme un mode de compositionnalité a travers
C. Nous obtenons ainsi par analogie avec l’architecture multimodale pour les grammaires de
Lambek(Mor1ill, 1994; Moortgat, 1997) la notion suivante de grammaire.

Déﬁnition 1 Une grammaire catégorielle multimodale de dépendances (mmCDG) est une
structure G = (IV, C, S, 6, ft), ou W est un vocabulaire, 6 (le lexique) est une fonction qui
aﬂecte d chaque mot dans W un sous ensemble ﬁni de tjpes dans gCat( C ) et [1, est unefonction
qui aﬂecte une regle d ’appariement d toute dépendance non projective dans C.

Le calcul de dépendances détermine la relation de prouvabilité correspondante I-It sur les suites
de types. La prouvabilité sans regles D (c’est-d-dire, au cas de dépendances projectives) est
notée I-C . Pour une SD D et une phrase w, la relation G(D, w) signiﬁe : « D est créée au cours
d’unepreuve F I-ﬂ Spour une suite de types I‘ E 5(w) ».

Le langage et le langage des SD ge’ne’re’s par G sont respectivernent les ensembles L(G) =,,‘, {w |
EID G(D,  et A(G)=d, {D | Elw G(D,  mmCDG“ et L',(mmCDG“) sont respective-
ment la famille des grammaires et des langages correspondants.

3 Expressivité des mmCDG

Les mmCDG sont tres expressives. Avec la regle FA elles génerent tous les langages non
contextuels (algébriques), mais aussi maints langages contextuels dont {a"b"c" | n > 0}, les
langages L9”) = {a{‘a§‘...a’,f1 | n 2 1} (Dikovsky, 2004) qui sont faiblement contextuels mais
non-TAG a partir de m > 4, le langage M I X , qui contient toutes permutations des motifs
a"b"c",n > 0, MIX = {w E {(1, b, c}+ I |w|,, = |w|b =  Or, selon l’hypothese deE.

2Nous exposons les régles gauches. Les régles droitcs sont symétriques.
1 68

Architecture compositionnelle pour les dépendances croisées

Bach, MIX n’est pas faiblement contextuel, ainsi il ne serait pas généré par une grammaire
minimaliste, ou multi-TAG, etc. Dans (Dekhtyar & Dikovsky, 2007) on peut trouver d’autres
exemples et une preuve du fait que L‘, (mmCDGFA) est une famille abstiaite de langages (AFL).

D’un autre coté, nous croyons (Dikovsky, 2004; Dekhtyar & Dikovsky, 2004) que le langage de
copies Lem, = {ww I w E {(1, b}‘''}, qui est généré par une grammaire TAG, n’appartient pas
a la famille L',(mmCDGFA’FC). Ce langage est d’un intérét particulier parce qu’on croit qu’il
est un modéle de la construction en néerlandais dite des « dépendances croisées illimitées ».
I1 s’agit des phrases 711712 . . . n,,,n,,,+1v1v(,,,f)2 . . .v(,,,f),,,, dont un exemple est en ﬁgure 3, oil
il y a une dépendance prédicative n1 1331 211 e11tre le verbe 221 en forme ﬁnie et le nom n1,

. . d . . .
les dépendances prédicatives 71,, 1:: v(,<,,f),« entre les verbes v(,,,f), a l’1nﬁn1t1f et les noms m,

. . . d b ' .
pour tout 2 3 2 3 777,, et éventuellement, une dépendance d’ob_]etd1rect n,,,_,_1 <o—J v(,,,f),,, s1le
verbe v(,,,f),,, est transitif et le nom n,,,+1 est présent (c’est-a-dire, n,,,_,.1 76 5).

 

inf—dobj
pred
med
/ prei

K I M \inf—dobj inf—dobj inf—dobj

VF I I I
Jan Piet Marie de kimieren mg helpen laten zwemmen

*Jan Piet Marie les enfants a vu aiderfaire nager
Figure 3.

Par aille11rs, une analyse plus approfondie de cette construction (Pulman & Ritchie, 1985)
montre que l’accord des formes existe seulement entre 711 et U1. Sinon, la forme du nom su-
bordonné est déterminée seulement par le verbe transitif v(,,,f),,, et son argument n,,,_,.1. Cela
implique que le vrai modéle de cette construction n’est point le langage Lem, mais le langage
des SDAs,,,ss = {D(’”) Im > 0} surW = NU V,o1‘1N ﬂV = 0, D9”) estlaSDenﬁgure4
et 71,, E N , vj, E V. En méme temps, le langage correspondant est algébrique (voire linéaire).

Figure 4. AD D9”)

Le langage Across est généré par la mmCDGFC suivante :

G ={ n '-> [#(L)]/L,[#(L)\#(L)]/L, POIIWEN
°"’‘” 11 '-> [#(L)\3/R]\‘,[R/R]“,[R]‘L, p011rv€V

E.g., une preuve de D(3) E Across est montrée en ﬁgure 5.

[#(L)]/L[#(L)\#(L)]’L L, [R/R]\L[R]\‘ (U)
[#(L)]’L” [#(L)\#(L)]’L L, [#(L)\5/R1“ [RJKLV (U)
[#(L)]/L/L” [#(L)\5]\‘\“‘ L,
[5]/I1/I«/I«\L’\I«\L (D1 3) ( )
FM "X
Figure 5.

169

Alexandre DIKOVSKY

4 Fondements théoriques

Notre solution du probleme des dependances croisees repose s11r l’independance des types ba-
siques et des valences polarisees dans les preuves du calcul de dependances. Cette propriete est
exprimee en termes de projections et de suites de categories bien appariees.

Pour une suite de categories 7 E gCat(C)* ses projections locale ||'y||l et de valences ||'y||v sont
deﬁnies ainsi 2 pour tous at E gCat(C), 7 E gCat(C)* et CF 6 gCAT(C),

1. nan; = llellu = e; llavllz = llallzllvllz er llowllu = llallullvllu
2. ||O"||z = 0 er ||C"||v = P.

Pour un potentiel P, sa projection ||P||d s11r une paire de valences duales vd, vvd est deﬁnie
comme h(P) po11r l’homomorphisme h(a) = oz si at 6 {'ud, vd} et h(a) = 5 sinon. P est dit
équilibré si toute projection ||P||d est bien appariee au sens habit11el.

Soit |P|, le nombre d’occu1rences de m dans P. Alors l’equilibre d’un potentiel P est incremen-
talement veriﬁable en utilisant les quantites suivantes po11r toute at E Vl(C) et (3 E V’ (C) :

Aa(P) = max{|P’|a — |P’ a | P’ est un suffixe de P},

Aa(P) = max{|P’ at — |P’|a | P’ est un préfixe de P}.
Elles expriment respectivement le deficit des a—parentheses droites et gauches dans P (c’est-
a-dire, le nombre de parentheses droites (gauches) qu’il faut ra_jouter a P de droite (de gauche)
pour qu’il devienne equilibre. Les proprietes suivantes sont veriﬁees (Dekhtyar & Dikovsky,
2004; Dekhtyar & Dikovsky, 2007) :

Lemme 1 I . Quels que soient des potentiels P1, P2 et des valences at E Vl(C), (52 E V’(C),
Aa(P1P2) = Aa(P2) Jr max{A,,,(P1) — Aa(P2), 0},
A5;(P1P2) = Aa(P1) + 7'TL(11I{Aa(P2) — Aa(P1), 
2. Un potentiel P est équilibré ssi Z Aa(P) = 0.
aEV(C)

La propriete suivante d’indépendance des projections (Dekhtyar & Dikovsky, 2004; Dekhtyar
& Dikovsky, 2007) garantit l’existence d’un algorithme polynomial d’analyse de mmCDGFA.

Théoreme 1 Pour une mmCDG G = (W, C, S, 6, [.L) avec le mode FA et .z‘ 6 W1’, .1‘ E L(G)
ssi ily a une suite F E 5(.z‘) telle que ||l"||l I-C S et ||l"||v estéquilibré.

Le seul point de sa preuve sensible aux modes est la proposition suivante vraie po11r FA :

Lemme 2 Un potentiel P est équilibré ssi pour toute catégorie 0/’ il )7 a une preuve 0/’ |- at
utilisant exclusivement les regles Did et Dfvl.

Pour garantir l’independance des projections (et par consequent, une analyse polynomiale) pour
une mmCDGM, il faut prouver ce lemme pour tout mode M E M. En prouvant le lemme 2
pour FC, nous avons etendu le theoreme 1 aux mmCDG avec les modes FA, FC :

Théoreme2 Pour .z' 6 W1’ etpour une mmCDGM G = (IV, C, S, 5, ].L) avec M = {FA},
ouM = {FC} ouM = {FA, FC}, .z‘ E L(G) ssi ilyaune suitel‘ E 5(.z‘) telleque ||l"||l I-C S
et ||FHz; est équilibré.

Corollaire 1 £(mmCDGFA) = £(mmCDGFC) = £(mmCDGFA=FC).

170

Architecture compositionnelle pour les dépendances croisées

5 Analyse syntaxique, complexité

Dans l’article (Dekhtyar & Dikovsky, 2004) un algorithme d’analyse en temps polynomial a été
décrit pour une version sous commutative du calcul de dépendances 3. Dans l’article (Dekhtyar
& Dikovsky, 2007) cet algorithme a été étendu aux mmCDGFA. Ce méme algorithme a un
détail pres s’applique aussi aux mmCDGFA’FC. Nous l’exposons en ﬁgure 6.

Fonctions d’échec. Soit une mmCDGM G = (IV, C, S, 6, [.L) avec les valences polaiisées
gauches Vl(C) = {'01, . . . yup} et droites V’(C) = {'51, . . . ﬂip}. Nous allons d’abord déﬁnir
deux fonctions d’échec qui vont servir pour une optimisation de l’analyse. Soit w = w1w2...w,,
E W‘''. Alors,pour 1 3 i 3 71,01 6 Vl(C) et,3 E V’(C),
7TL(0t, i) = ma${Aa(||F||u) IT 6 5(w1---w¢)},
7rR(,8,i) = max{A,3(||1"||,,)|1" E 6(w,,_,<+1...w,,)}
sont lesfonction d ’échec gauche et droite. On suppose que 7rL (oz, 0) = 7rR(,3, 0) = 0.

Algorithme d’analyse syntaxique. mmCdgPa1s est un algorithme typique de « program-
mation dynamique ». Il s’applique a une mmCDGM eta une phrase w = w1w2...w,, E W‘'' et
remplit une matrice triangulaire M dont la dimension est n X n. L’élément M [i, j], i 3 j , de M
correspond a l’intervalle w, . . .wj de la phrase et représente un ensemble ﬁni d’<< items ». Un item
est une expression I = (C, AL, AR, I’, I’) qui code une catégorie GP, on C est une catégorie
basique (C E B(C)), AL = (Am, . . . ,Avp) et AR = (A151,. . . , A510) sont les vecteurs entiers
dont chaque composante 2' correspond a la valence 1),, respectivement iii, et vaut le déﬁcit cor-
respondant des vi-parentheses droites (gauches) dans le potentiel P. Finalement, I l, I T sont les
identiﬁcateurs des items dans les angles gauches et droites de M a partir desquelles est calculé
l’item I (pourtout I E  I’ = I’ = (D).

Complexité. Pour une mmCDGM G = (W, C, S, 6, [.L), soit lg = |6| le nombre d’affectations
des catégories aux mots dans le lexique, soit ag = ma.z‘{k: I Elm E W ([ozk\...\oz1\C/,3]P E
5(.z‘) V [,3\C/011/.../ozk]P E  le nombre maximal de sous types arguments dans les
catégories affectées, soit pg = |Vl(C)| = |V’  le nombre de valences polarisées et Ag =
max{Aa(P) | Elm E W(CP E 6(x) V at E V(C))} le déﬁcit maximal des valences parentheses
dans les catégories affectées. Finalement, soit 71 la longue11r de la phrase analysée.

Théoréme 3 L’algorithme mmCdgPars a une complexité en temps O(|(; -aé - (AG - n)2"° -n3).

Remarque 1 I . Pour une grammaireﬁxée G , les valeurs lg, ag, pg et Ag sont constantes. Si
G varie, alors le probleme d ’appartenance devient N P-complét ( Dekhtyar & Dikovsky, 2004).
2. Si G est sans valence polarisée, alors la complexité est O(n3).

3. Soit le déﬁcit maximal de valences ag  des potentiels survenants dans les preuves des
phrases dont la longueur est limitée par 71. Si ag(n) est bornée par une constante c, alors G
peut étre transforme’e en une mmCDG G’ sans valence polarisée dont le langage est algébrique
(Dikovsky, 2001). Or, la taille de G’ est exponentielle par rapport a G. Si, de plus, le nombre des
dépendances non borne’es dans une SD engendrée par G n ’est jamais supérieur a une borne
constante uniforme (ce qui est t)pique pour maintes langues), alors la complexité est O(n3)
pour la méme grammaire G.

4. D’un autre co"te’, méme si toute dépendance de G (sauf S) était de’ﬁnie par une valence
polarisée, la complexité serait toujours polynomiale. Cette remarque explique que les mmCDG
sont bien adaptées aux langages avec l ’ordre ﬂexible. Les limites de cet article ne nous laissent
pas faire une analyse plus détaillée de ce cas important.

3L’a1gorithme a été réalisé en LISP par Darin et Hristian Todorov et en en C'# par llya Zaytsev.
171

Algortthme mmCdgPars
//Entree : mmCDG G, phrase w : w1...w,,
//Sortie : (“suocés”, DS D) ssi w E L(G)

Ca|cFai|FuncL() ;
Ca|cFai|FuncFt() ;
for (k:1,...,n)

Propose( k )

for(l:2,...,n)

{
f0l‘(i:1,...,n—l)
{

j::i-l-l—1;
for(k:i,...,j—l)
{

SubordinateL(z', k, j) ;
SubordinateFt(z', k, j) ;

}

}

if (I 2 (S, (0, 0, . . .,0), (0,0, . . . ,0),I‘,I') e M[1,n,])
return (“suocés” , E'zpam,d(I ;

//procedure Expand( I ) calcule la SD de sortie.

//Elle seule est sensible aux regles d’appariement

//FA,FC. Elle est technique et n’est pas incluse

else
return (“éched’ , 9)) ;

Ca|cFai| FuncL()
foreach (v 6 V‘(C))

7rL[v,0]:: 0;
f0l‘(i:1,...,n)
{

777mm 5: 0;
foreach (OP 6 5(w,-))
{
NM, :: maz{7r,,,.,_,, A,,(P)—l-
Wl${7rLlv,i - 1] - Av(P): 0}};

7rLlv,i] == mm;
}
}
}

Ca|cFai|FuncFt() est similaire.

Alexandre DIKOVSKY

//For 1 5 i 5 n
Propose( i)

({|oop) foreach (CP 6 5(w,-)

foreach (v 6 V‘(C))

{
AL[v] :: A,,(P) ;
if (AL[v] > ¢rR[1‘;,n — j]) next (loop);
AR[1‘;] :: A,~,(P) ;
if (AR[l‘;] > 7rL[v,i — 1]) next (loop);

}
Addltem( M[i,i], (C, AL, AR, 0, 0) );

Addltem( M[i,j], (C, AL, AR, 11, 1') )

Mli,J'] == Mli,J'] U {(C,AL,ARJ’J’)}3
i{f(C = lC’* \ﬂ])

Add|lem( Mliyjly (lﬂLAL,AR, I51’) );
}
iE(C = lﬂ/C’*])

Add|lem( M[i7j]7 (lﬂ],AL,AR, 1'11’) ):

//Forlgisksjgn
SubordinateL( i, k,j )

(loop) foreach (I1 : (a1,Af,A{*, I{,I{) e M[i,k],
I2 = <a2,A%,A£*,Ié,I§) 6 Mlk + 1,J'])

foreach (v 6 V‘(C))

{
AL[v] :: A£‘(v) + maz{A{‘(v) — A§(v), 0};
if (AL[v] > ¢rR[1‘;, n — j]) next (loop);
AR[1”;] :: A{"(1")) + maz{Af(1”;) — A{‘(1”;), 0};
if (AR[l‘;] > 7rL[v,i — 1]) next (loop);

}

if ( a1 : C and a2 : [C\,B])

} Add“em( Mliyjly (l/3]:AL,AR, 11,12) );

elseif ((111 : C and a2 : [Car  or 521 2 [e])
Add|tem( M[i,j], (522, AL, AR, I1, I2) );

}
}

SubordinateFt( i, k,j ) est similaire.

Figure 6. Algorithme mmCdgPars

172

Architecture compositionnelle pour les dépendances croisées

6 Comparaison, discussion

Certes, il y a des grammaires ou l’expression des dépendances non bomées ne pose pas pro-
bléme, e. g. HPSG (Pollard & Sag, 1988), les extensions multimodales des grammaires de Lam-
bek (Morrill, 1994; Moortgat, 1997), dont certaines visent notamment les dépendances (Kruijff,
2001) et le11r fournissent une interface compositionnelle avec la sémantique. Or, l’analyse avec
ces formalismes expressifs est trés complexe et parfois nécessite l’utilisation des systémes de
démonstration des théorémes. C’est aussi le cas des grammaires qui représentent PTI M E,
dont RCG (Boullier, 2003). A la différence de mmCDG, ces grammaires n’ont pas d’algo-
rithme universel d’analyse en temps O(nk), on k: dépend de l’alphabet. Cela conceme aussi les
grammaires basées sur l’uniﬁcation et les contraintes, e. g. (Duchier, 1999). Contrairement a ces
formalismes, les mmCDG n’utilisent que les moyens primitifs d’une complexité faible. E.g.,
les Grammaires Topologiques de Dépendances (Duchier & Debusmann, 2001) (voir aussi (Bro-
ker, 1998; Duchier et al., 2004)) utilisent les hierarchies des domaines de l’ordre des mots
(W O-domains) qui, en cas de discontinuité, servent a exprimer les contraintes de contiguité,
de distance entre un gouvemeur et son modiﬁeur etc. Dans beaucoup des cas, ces contraintes
sont exprimées dans mmCDG par le moyen de sous types d’ancrage placés dans les positions
correspondantes d’un type du gouvemeur.

Les mmCDG représentent une alternative intéressante aux TAG (et équivalentes : CCG, HG
(Vijay-Shanker & Weir, 1994)) et aux grammaires faiblement contextuelles (Joshi et al., 1991),
telles multi-TAG, non contextuelles multi-composantes, minimalistes, etc. Tout comme ces der-
niéres, les mmCDG disposent d’une analyse syntaxique en temps polynomial. On peut méme
constater, qu’en pratique l’algorithme mmCdgPa1s va avoir une complexité O(n3). Leur avan-
tage décisif est l’architecture compositionnelle de dépendances ou toutes les dépendances, pro-
jectives comme non bomées, sont déﬁnies par les types fonctionnels, ce qui crée la base né-
cessaire po11r une sémantique f onctionnelle de dépendances. En méme temps, cette architecture
adopte naturellement la multimodalité des dépendances non bornées correspondant aux régles
de saturation des valences spéciﬁques aux différentes langues. Il est important de noter que cette
ﬂexibilité syntaxique est atteinte sans explosion du coﬁt de l’analyse syntaxique (par contraste
avec les grammaires de Lambek). Malgré le11r simplicité, les mmCDG sont trés expressives.
On a vu que pour exprimer les dépendances croisées illimitées on n’a pas besoin du langage de
copies, mais d’un langage des SD facilement exprimé par les mmCDG. Et le fait que MIX est
un langage mmCDGFA montre que ces grammaires sont adaptées aux langues naturelles avec
l’ordre des mots ﬂexible.

Enﬁn, il est difﬁcile de comparer les mmCDG par l’expressivité avec les autres GD qui traitent
les dépendances non bornées et qui les analysent en temps polynomial, e.g. (Kahane et al.,
1998; Broker, 2000). Le pouvoir de ces grammaires n’est pas déterminée. Leurs déﬁnitions
sont opérationnelles (cf. le « lifting »). L’avantage des mmCDG est leur transparence et leur
architecture compositionnelle de dépendances.

Références
BAR-HILLEL Y. (1953). A quasi-arithmetical notation for syntactic description. Language,
29(1), 47-58.

BOULLIER P. (2003). Counting with range concatenation grammars. Theoretical Computer
Science, 293, 391-416.

173

Alexandre DIKOVSKY

BRESNAN J ., KAPLAN R., PETERS S. & ZAENEN A. (1982). Cross-serial dependencies in
dutch. Linguistic Inquiry, 13(4), 613-635.

BROKER N. (1998). Separating surface order and syntactic relations in a dependency gram-
mar. In Proc. COLING-ACL, p. 174-180, Montreal.

BROKER N. (2000). Unordered and non-projective dependency grammars. Traitement Auto-
matique des Langues (TAL), 41(1), 245-272.

DEKHTYAR M. & DIKOVSKY A. (2004). Categorial dependency grammars. In M. MOORT-
GAT & V. PRINCE, Eds., Proc. of Intern. Conf. on Categorial Grammars, p. 76-91.

DEKHTYAR M. & DIKOVSKY A. (2007). Generalized categorial dependency gram-
mars. In submission, www.sciences.univ—nantes.fr/info/perso/permanents/
dikovsky/.

DIKOV SKY A. (2001). Polarized non—projecl:ive dependency grammars. In P. DE GROOTE, G. MORILL
& C. RETORE, Eds., Proc. of the Fourth Intern. Conf. on Logical Aspects of Computational Linguistics,
vol11me 2099 of LNAI, p. 139-157 : Springer.

DIKOV SKY A. (2004). Dependencies as categories. In “Recent Advances in Dependency Grammars".
COLING’04 Workshop, p. 90-97.

DUCHIER D. (1999). Axiomatizing dependency parsing using set constraints. In Sixth Meeting on
Mathematics of Language (MOL—6), p. 115-126, Orlando, Florida.

DUCHIER D. & DEBUSMANN R. (2001). Topological dependency trees : A consl:raint—based account
of linear precedence. In Proc. of the Intern. Conf. ACL’200I , p. 180-187 : ACL & Morgan Kaufman.

DUCHIER D., DEBUSMANN R. & KRUIJFF G.—J. M. (2004). Extensible dependency grammar : A
new methodology. In COLING’04 Workshop, p. 78-84, Geneva.

GAIFMAN H. (1961). Dependency systems and phrase structure systems. Report p—2315, RAND Corp.
Santa Monica (CA). Published in Information and Control, 1965, v. 8, 11 ° 3, pp. 304-337.

JOSHI A. K., SHANKER V. K. & WEIR D. J . (1991). The convergence of mildly context—sensitive
grammar fomralisms. In P. SELLS, S. SHIEBER & T. WASOW, Eds., Foundational issues in natural
language processing, p. 31-81, Cambridge, MA : MIT Press.

KAHANE S., NASR A. & RAMBOW O. (1998). Pseudo—projec1ivity : A polynomially parsable non-
projective dependency grammar. In Proc. COLING—ACL, p. 646-652, Montreal.

KRUIJFF G.—J. M. (2001). A Categorial—Modal Logical Architecture of Informativity : Dependency
Grammar Logic & Information Structure. PhD thesis, Charles University, Prague.

LAMBEK J . (1961). On the calculus of syntactic types. In R. JAKOBSON, Ed., Structure of languages
and its mathematical aspects, p. 166-178. Providence RI : American Mathematical Society.

MOORTGAT M. (1997). Categorial type logics. In J . VAN BENTHEM & A. TER MEULEN, Eds.,
Handbook ofLogic and Language, chapter 2, p. 93-177. Elsevier, The MIT Press.

MORRILL G. V. (1994). Type Logical Grammar. Categorial logic of Signs. Kluwer.

POLLARD C. & SAG I. (1988). An Information Based Approach to Syntax and Semantics, Part I.
Stanford, California : CSLI.

PULMAN S. & RITCHIE G. (1985). Indexed grammars and interesting dependencies. UEA Papers in
Linguistics, 23, 21-38.

M. STEEDMAN, Ed. (1996). Surface Structure and Interpretation. The MIT Press.

VIJAY—SHANKER K. & WEIR D. (1994). The equivalence of fo11r extensions of context—free grammars.
Mathematical Systems Theory, 27, 511-545.

174

