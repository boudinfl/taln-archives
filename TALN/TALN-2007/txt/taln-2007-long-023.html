<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Un analyseur hybride pour la d&#233;tection et la correction des erreurs cach&#233;es s&#233;mantiques en langue arabe</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2007, Toulouse, 5&#8211;8 juin 2007 
</p>
<p>Un analyseur hybride pour la d&#233;tection et la correction 
des erreurs cach&#233;es s&#233;mantiques en langue arabe
</p>
<p> Chiraz BEN OTHMANE ZRIBI, Han&#232;ne MEJRI , Mohamed BEN AHMED
Laboratoire de recherche RIADI, Universit&#233; La Manouba 
</p>
<p> ENSI, La Manouba, Tunisie 
Chiraz.benothmane@riadi.rnu.tn, Hanene.mejri@riadi.rnu.tn,
</p>
<p>Mohamed.benahmed@riadi.rnu.tn
</p>
<p>R&#233;sum&#233;. Cet article s&#8217;int&#233;resse au probl&#232;me de la  d&#233;tection et de la correction des erreurs 
cach&#233;es s&#233;mantiques dans les textes arabes. Ce sont des erreurs orthographiques produisant 
des mots lexicalement valides mais invalides s&#233;mantiquement. Nous commen&#231;ons par d&#233;crire 
le type d&#8217;erreur s&#233;mantique auquel nous nous int&#233;ressons. Nous exposons par la suite 
l&#8217;approche adopt&#233;e qui se base sur la combinaison de plusieurs m&#233;thodes, tout en d&#233;crivant 
chacune de ces m&#233;thodes. Puis, nous &#233;voquons le contexte du travail qui nous a men&#233; au 
choix de l&#8217;architecture multi-agent pour l&#8217;impl&#233;mentation de notre syst&#232;me. Nous pr&#233;sentons 
et commentons vers la fin les r&#233;sultats de l&#8217;&#233;valuation dudit syst&#232;me. 
</p>
<p>Abstract. In this paper, we address the problem of detecting and correcting hidden 
semantic spelling errors in Arabic texts. Hidden semantic spelling errors are morphologically 
valid words causing invalid semantic irregularities. After the description of this type of errors, 
we propose and argue the combined method that we adopted in this work to realize a hybrid 
spell checker for detecting and correcting hidden spelling errors. Afterward, we present the 
context of this work and show the multi-agent architecture of our system. Finally, we expose 
and comment the obtained results.  
</p>
<p>Mots-cl&#233;s : erreur cach&#233;e, erreur s&#233;mantique, d&#233;tection, correction, syst&#232;me multi-agent, 
langue arabe. 
</p>
<p>Keywords: hidden error, semantic error, detection, correction, multi-agent system, 
Arabic language.
</p>
<p>1 Introduction
Les erreurs cach&#233;es sont des erreurs orthographiques produisant des mots valides 
lexicalement et causant des d&#233;r&#232;glements de haut niveau : syntaxique, s&#233;mantique, voire 
m&#234;me pragmatique. Les erreurs cach&#233;es surviennent lorsqu&#8217;une ou plusieurs modifications 
sur un mot le transforme en un autre mot de la langue. Dans ce cas, l&#8217;erreur, est dans la 
plupart du temps, une graphie semblable au mot que l&#8217;utilisateur avait l&#8217;intention d&#8217;&#233;crire.  
</p>
<p>Le jardinier utilise le g&#226;teau (r&#226;teau) pour b&#234;cher la terre
</p>
<p>251</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Chiraz BEN OTHMANE ZRIBI, Han&#232;ne MEJRI , Mohamed BEN AHMED
</p>
<p>Dans cet exemple, le mot &#171; g&#226;teau &#187; est introduit dans un contexte qui ne lui est pas 
appropri&#233;. Cette faute de frappe peut &#234;tre corrig&#233;e en r&#233;tablissant le mot correct &#171; r&#226;teau &#187;. 
Dans (Verberne, 2002) on lit que les statistiques r&#233;alis&#233;es pour la langue anglaise par 
(Eastman, Oakman, 1991) affirment que les erreurs cach&#233;es repr&#233;sentent 25% parmi toutes les 
erreurs orthographiques commises et contenues dans leur corpus de r&#233;f&#233;rence. (Mitton, 1987) 
cit&#233; par le m&#234;me auteur, leur attribue une valeur plus grande &#224; savoir : 40% parmi toutes les 
erreurs orthographiques &#233;tudi&#233;es. Ces deux valeurs assez importantes ont rendu l&#8217;&#233;tude de ce 
genre d&#8217;erreurs une n&#233;cessit&#233; en soi. Plusieurs recherches ont &#233;t&#233; entreprises dans le but de 
rem&#233;dier &#224; ce probl&#232;me. Nous pouvons citer par exemple les recherches de  Golding qui a 
&#233;tudi&#233; ce genre d&#8217;erreurs pour la langue anglaise. Il a ainsi propos&#233; diff&#233;rentes m&#233;thodes 
comme la m&#233;thode de Bayes (Golding, 1995), la m&#233;thode des trigrammes des parties du 
discours (Golding, Schabes, 1996) et la m&#233;thode &#224; base de r&#233;seaux neuronaux dite Winnow
(Golding, Roth, 1999). Le chinois a &#233;t&#233; aussi trait&#233; avec les deux chercheurs (Xiaolong, 
Jianhua, 2001). Le su&#233;dois a &#233;galement fait l&#8217;objet d&#8217;une recherche avec (Bigert, Knutsson, 
2002).
En ce qui concerne la langue arabe, aucun autre travail n&#8217;a concern&#233; le traitement des erreurs 
cach&#233;es malgr&#233; l&#8217;importance de l&#8217;entreprise d&#8217;une telle recherche. La langue arabe pr&#233;sente, 
en effet, des sp&#233;cificit&#233;s dont nous citons principalement : l&#8217;agglutination, l&#8217;ambigu&#239;t&#233; 
grammaticale et la proximit&#233; lexicale. Toutes ces caract&#233;ristiques rendent le risque de 
commettre une erreur cach&#233;e plus important que pour les autres langues notamment latines.  
Nous nous sommes donc int&#233;ress&#233;s &#224; ce probl&#232;me en construisant un syst&#232;me permettant &#224; la 
fois de d&#233;tecter et de corriger ce type d&#8217;erreurs pouvant survenir dans des textes arabes. Dans 
un premier temps ce syst&#232;me a concern&#233; uniquement les anomalies syntaxiques (Ben 
Othmane et al., 2005). Nous l&#8217;avons amend&#233; par la suite pour qu&#8217;il puisse traiter l&#8217;ensemble 
des anomalies  (syntaxiques et s&#233;mantiques). 
D&#251; &#224; la complexit&#233; de ce travail, nous avons &#233;t&#233; amen&#233;s &#224; &#233;mettre certaines hypoth&#232;ses pour 
restreindre les champs de nos investigations. Nous avons consid&#233;r&#233; alors l&#8217;arabe non voyell&#233; 
et ce pour une raison capitale. C&#8217;est que malgr&#233; l&#8217;importance des voyelles1 dans la 
compr&#233;hension du discours arabe, elles n&#8217;apparaissent que tr&#232;s rarement dans les textes. 
Ainsi, &#224; part quelques ouvrages po&#233;tiques ou litt&#233;raires didactiques, les &#233;crits arabes sont 
g&#233;n&#233;ralement d&#233;pourvus de voyelles, et c&#8217;est le cas des textes fr&#233;quemment rencontr&#233;s dans 
les journaux, les revues, les romans, etc. Aussi, nous &#233;mettons l&#8217;hypoth&#232;se de l&#8217;existence 
d&#8217;une seule erreur par phrase et par mot. Cette erreur consisterait en une seule faute 
typographique du type : ajout d&#8217;un caract&#232;re, omission d&#8217;un caract&#232;re, substitution d&#8217;un 
caract&#232;re par un autre ou interversion de deux caract&#232;res adjacents. Des statistiques ont en 
effet montr&#233; que l'une (seulement) de ces op&#233;rations est &#224; l'origine d&#8217;une erreur 
orthographique dans 90% des cas (Ben Hamadou, 1993).  
Dans ce qui suit, nous d&#233;crivons dans la premi&#232;re section le type d&#8217;erreurs s&#233;mantiques 
auquel nous nous sommes int&#233;ress&#233;s et formant ce qu&#8217;on appelle des erreurs cach&#233;es 
s&#233;mantiques. Dans la deuxi&#232;me section, nous pr&#233;sentons l&#8217;approche propos&#233;e pour la 
conception de notre syst&#232;me de d&#233;tection&#8211;correction erreurs cach&#233;es s&#233;mantiques. Dans la 
troisi&#232;me section de l&#8217;article, nous abordons le contexte de notre travail, ainsi, que 
l&#8217;architecture d&#8217;impl&#233;mentation adopt&#233;e pour la r&#233;alisation de notre syst&#232;me. La quatri&#232;me et 
derni&#232;re section est consacr&#233;e, quant &#224; elle,  &#224; la description des r&#233;sultats de l&#8217;&#233;valuation du 
syst&#232;me mis en place. 
</p>
<p>1 Signes diacritiques ajout&#233;es aux lettres arabes pour permettre leur lecture 
</p>
<p>252</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Un analyseur hybride pour la d&#233;tection et la correction des erreurs cach&#233;es s&#233;mantiques en arabe 
</p>
<p>2 Les erreurs cach&#233;es s&#233;mantiques 
Nous entendons par &#171; erreur cach&#233;e s&#233;mantique &#187; tout mot ressemblant typographiquement &#224; 
un caract&#232;re pr&#232;s au mot correct qu&#8217;il remplace mais invalide s&#233;mantiquement dans le 
contexte o&#249; il se trouve. Les d&#233;r&#232;glements s&#233;mantiques caus&#233;es par ce type d&#8217;erreurs peuvent 
&#234;tre r&#233;parties en deux cat&#233;gories: les incompatibilit&#233;s s&#233;mantiques et les incompl&#233;tudes
s&#233;mantiques. Quand l&#8217;erreur cause des contresens ou encore rend la phrase d&#233;pourvue de 
sens, nous parlons dans ce cas d&#8217;incompatibilit&#233; s&#233;mantique. Quand &#224; l&#8217;incompl&#233;tude 
s&#233;mantique, elle concerne principalement  l&#8217;oubli de mots, de syntagmes ou d&#8217;outils de 
coordination n&#233;cessaires &#224; l&#8217;interpr&#233;tation de la phrase.
Nous nous int&#233;ressons ici qu&#8217;aux anomalies mettant en cause le sens. Les erreurs 
d&#8217;incompl&#233;tude sont plus difficiles &#224; d&#233;celer.  
</p>
<p>(&#915;&#942;&#1012;&#924;&#987;) &#915;&#942;&#1012;&#914;&#987; &#1019;&#909;&#1006;&#995;&#899; &#1002;&#1012;&#992;&#971; &#997;&#1006;&#959;&#942;&#972;&#1011;
Ils lui proposent de grandes (beaucoup) d&#8217;argent 
</p>
<p>Dans cette phrase erron&#233;e, l&#8217;adjectif &quot;&#915;&#942;&#1012;&#914;&#987;&quot; (grandes) est utilis&#233; au lieu de l&#8217;adjectif &quot;&#915;&#942;&#1012;&#924;&#987;&quot;
(beaucoup) et il se trouve dans un contexte inappropri&#233; par la substitution de la lettre &#911; par la 
lettre &#921;.
</p>
<p>3 D&#233;tection des anomalies s&#233;mantiques 
Pour que la machine puisse traiter la s&#233;mantique des mots, elle doit disposer, par analogie &#224; 
l&#8217;&#234;tre humain, des connaissances &#224; propos du sens des mots et des diff&#233;rents contextes dans 
lesquels ils apparaissent. Ces connaissances peuvent &#234;tre obtenues &#224; partir de plusieurs 
ressources informatiques telles que les dictionnaires s&#233;mantiques, les th&#233;saurus, les r&#233;seaux 
s&#233;mantiques, les ontologies ou les corpus textuels.  
Dans le cadre de ce travail, nous optons pour une solution bas&#233;e sur l&#8217;apprentissage du sens 
des mots &#224; partir des corpus textuels. Cette orientation repose sur un principe de la 
linguistique distributionnelle qui dit que : &quot;le sens d&#8217;un mot peut &#234;tre d&#233;fini statistiquement, &#224; 
partir de l&#8217;ensemble des contextes (i.e., paragraphes, phrases, textes) dans lesquels ce mot 
appara&#238;t&quot; (Landauer et al., 1998). Par exemple, le mot avion appara&#238;t souvent conjointement 
avec des mots comme d&#233;coller, aile, a&#233;roport, et rarement conjointement avec des mots 
comme lion ou for&#234;t.
Pour d&#233;tecter les erreurs cach&#233;es s&#233;mantiques, nous proposons une approche  qui se base sur 
l&#8217;&#233;tude de la validit&#233; s&#233;mantique de chaque mot du texte &#224; analyser dans son contexte et ceci 
par la combinaison de plusieurs m&#233;thodes permettant de repr&#233;senter chaque mot en fonction 
du contexte proche et lointain dans lequel il appara&#238;t et de comparer cette repr&#233;sentation aux 
repr&#233;sentations ant&#233;rieures obtenues lors de l&#8217;apprentissage.
Nous faisons ainsi appel &#224; quatre m&#233;thodes, de nature statistique ou mixte (linguistique et 
statistique), responsables chacune de v&#233;rifier la validit&#233; s&#233;mantique d&#8217;une phrase donn&#233;e. 
L&#8217;id&#233;e derri&#232;re cette combinaison est d&#8217;obtenir un analyseur d&#8217;erreurs cach&#233;es s&#233;mantiques 
capable de tirer profit des avantages de toutes les m&#233;thodes d&#8217;analyses s&#233;mantiques 
propos&#233;es.  Ceci implique la construction de plusieurs syst&#232;mes de traitement d&#8217;erreurs 
cach&#233;es qui seront mis en confrontation quant &#224; la s&#233;lection d&#8217;une erreur cach&#233;e s&#233;mantique 
dans une phrase. Cette confrontation est r&#233;alis&#233;e suite &#224; l&#8217;application d&#8217;une proc&#233;dure de vote 
qui prendra en consid&#233;ration tous les r&#233;sultats issus de l&#8217;application des m&#233;thodes d&#8217;analyses 
s&#233;mantiques propos&#233;es et proc&#232;dera &#224; un vote pour l&#8217;identification de l&#8217;erreur la plus probable 
garantissant ainsi une meilleure qualit&#233; d&#8217;analyse.  
</p>
<p>253</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Chiraz BEN OTHMANE ZRIBI, Han&#232;ne MEJRI , Mohamed BEN AHMED
</p>
<p>Pendant la phase d&#8217;apprentissage, sont r&#233;colt&#233;es &#224; partir d&#8217;un corpus dit d&#8217;entra&#238;nement trait&#233; 
au pr&#233;alable2 toutes les connaissances n&#233;cessaires aux diff&#233;rentes m&#233;thodes propos&#233;es et 
formant leurs entr&#233;es. Ce corpus3 comporte 30 textes de type &#233;conomique, et compte environ 
30 000 mots, 1827 phrases et 4029 lemmes. Les connaissances extraites se pr&#233;sentent sous 
forme de donn&#233;es linguistiques et statistiques et varient selon les besoins de chaque m&#233;thode 
d&#8217;analyse utilis&#233;e. 
</p>
<p>3.1 M&#233;thode Coocurrence-Collocation 
</p>
<p>Cette m&#233;thode v&#233;rifie la validit&#233; contextuelle d&#8217;un mot en se basant sur sa probabilit&#233; 
contextuelle d&#233;duite du calcul des trois mesures suivantes : 
</p>
<p>x Probabilit&#233; de cooccurrence : Cette probabilit&#233; est calcul&#233;e pour chaque mot mi de
la phrase &#224; analyser pour une fen&#234;tre de 10 mots4. Elle est exprim&#233;e par la formule 
de probabilit&#233; conditionnelle de Bayes suivante :
</p>
<p>),......cc,,......cP(c
))P(mm,......cc,,......cP(c
</p>
<p>),......cc,,......ccP(m)CP(m
k1-1k
</p>
<p>iik1-1k
k1-1kii   
</p>
<p> O&#249; mi repr&#233;sente le mot &#224; analyser, ci les mots voisins du contexte proche et P(mi) la 
probabilit&#233; d&#8217;apparition du mot mi dans le corpus d&#8217;apprentissage.
</p>
<p>x Coefficient de collocation : Une collocation est une expression ayant une structure 
morphosyntaxique pr&#233;cise et une fr&#233;quence d&#8217;apparition importante dans le corpus 
d&#8217;apprentissage, exemple : &#916;&#1000;&#1011;&#938;&#996;&#991;&#909; &#969;&#941;&#909;&#1006;&#951; (les rues de la ville). Pour calculer ce 
coefficient nous proc&#233;dons d&#8217;abord &#224; l&#8217;identification des collocations existantes dans 
une phrase en se basant sur une liste de collocations obtenue lors de la phase 
d&#8217;apprentissage. Pour se faire, nous avons utilis&#233; et adopt&#233; une partie du syst&#232;me 
r&#233;alis&#233; par (Mlayeh, 2004). Lorsque une collocation est identifi&#233;e dans une phrase, 
un coefficient collocationnel est attribu&#233; &#224; chaque mot de cette expression. Ce 
coefficient n&#8217;est autre que la mesure de Kulczinsky, qui est un crit&#232;re d&#8217;association 
permettant d&#8217;identifier le degr&#233; de corr&#233;lation de deux lemmes li et lj. calcul&#233;e &#224; l&#8217;aide 
de la formule suivante :
</p>
<p>)c+a
1
</p>
<p>+b+a
1
</p>
<p>(2
a
</p>
<p>=KUC
</p>
<p> O&#249; : a : le nombre d&#8217;occurrences du couple (li, lj)
   b : le nombre d&#8217;occurrences des couples o&#249; li appara&#238;t non suivi de lj
   c : le nombre d&#8217;occurrences des couples o&#249; lj est non pr&#233;c&#232;de d&#233; li
 La  valeur de ce coefficient varie entre 0 et 1 et il est &#233;gal &#224; 0,5 quand li est toujours 
</p>
<p>observ&#233; avec lj. Une expression est consid&#233;r&#233;e comme collocation si son coefficient 
de KUC est sup&#233;rieur &#224; 0,5. 
</p>
<p>x Probabilit&#233; de r&#233;p&#233;tition: &quot;les mots ou plus pr&#233;cis&#233;ment les lemmes des mots d&#8217;un 
texte ont tendance &#224; se r&#233;p&#233;ter dans le texte lui-m&#234;me&quot;. Cette hypoth&#232;se est d&#233;duite 
des comptages r&#233;alis&#233;s par (Ben Othmane, Ben Ahmed, 2003) sur un corpus textuel 
en langue arabe appartenant &#224; un domaine particulier qui montrent qu&#8217;une forme 
</p>
<p>2 Analys&#233; morpho-syntaxiquement, d&#233;coup&#233; en phrases et en syntagmes nominaux et verbaux. 
3 Ces textes proviennent &#224; l&#8217;origine du corpus de l&#8217;arabe contemporain collect&#233; par Al-Sulaiti L. 
</p>
<p>http://www.comp.leeds.ac.uk/eric/latifa/arabic-corpora.htm. Ils ont &#233;t&#233; choisis par ce qu&#8217;ils sont relatifs &#224; un 
m&#234;me domaine. 
</p>
<p>4  La taille de la fen&#234;tre est param&#233;trable et peut &#234;tre facilement ajust&#233;e. 
</p>
<p>254</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Un analyseur hybride pour la d&#233;tection et la correction des erreurs cach&#233;es s&#233;mantiques en arabe 
</p>
<p>textuelle appara&#238;t en moyenne 5,6 fois dans un m&#234;me texte alors qu&#8217;un lemme 
appara&#238;t en moyenne 6,3 fois et ce dans le m&#234;me texte. Subs&#233;quemment, si le lemme 
d&#8217;un mot se r&#233;p&#232;te tr&#232;s peu dans le texte, le mot en question peut correspondre &#224; une 
erreur cach&#233;e. Cette probabilit&#233; concerne donc le taux d&#8217;apparition de chaque lemme 
des mots de la phrase, objet de v&#233;rification,  dans le corpus de test. Ce taux est 
calcul&#233; par la formule suivante : 
</p>
<p>lemmesdetotalnombre
l de occurencesd' nombre
</p>
<p>=)P(l ii
</p>
<p>La combinaison de ces trois mesures en vue de l&#8217;obtention de la probabilit&#233; contextuelle P(mi)
de chaque mot de la phrase se fait selon la formule lin&#233;aire suivante : 
</p>
<p>)iP(l*&#303;+)iKUC(m*&#533;+)CiP(m*&#302;=)iP(m
</p>
<p>O&#249; P(mi\C) est la probabilit&#233; de cooccurrence du mot mi, KUC(mi) est le coefficient 
collocationelle attribu&#233; &#224; un mot mi, P(li) est la probabilit&#233; de r&#233;p&#233;tition pour un lemme li du 
mot mi. &#302;, &#533;, et &#303; sont des poids attribu&#233;s aux diff&#233;rentes probabilit&#233;s afin de mettre en 
&#233;vidence la contribution de chaque probabilit&#233;. Il est &#224; noter que ces valeurs ne sont pas 
connues &#224; l&#8217;avance et sont d&#233;termin&#233;es lors des exp&#233;rimentations5. Toutefois, nous estimons 
que la valeur de &#302; doit &#234;tre plus importante que celles de  &#533;, et &#303;  vu que le contexte voisin est 
plus d&#233;terminant pour le sens du mot &#224; analyser que son contexte lointain. 
Une fois les probabilit&#233;s relatives &#224; tous les mots de la phrase en question sont calcul&#233;es, elles 
seront compar&#233;es &#224; une valeur seuil d&#233;termin&#233; lors des exp&#233;rimentations. Le ou les vocables 
ayant une probabilit&#233; inf&#233;rieure &#224; ce seuil forment une liste d&#8217;erreurs cach&#233;es &#233;ventuelles.  
</p>
<p>3.2 M&#233;thode Vecteur-Contexte
</p>
<p>Cette m&#233;thode consiste &#224; repr&#233;senter chaque mot de la phrase par un vecteur en fonction du 
contexte dans lequel il appara&#238;t. De ce fait, un vecteur mot Vmi n&#8217;est autre qu&#8217;une 
repr&#233;sentation vectorielle de la probabilit&#233; de cooccurrence de ce mot avec chaque mot de la 
phrase. Consid&#233;rons par exemple, la phrase suivante :  
</p>
<p>(&#910;&#947;&#900;&#987;)&#910;&#914;&#992;&#987; &#990;&#927;&#942;&#991;&#909; &#911;&#942;&#951;
L&#8217;homme a bu un chien (un verre) 
</p>
<p>La matrice ci-dessus illustre la probabilit&#233; de cooccurrence de chaque mot mi de la phrase 
avec les mots voisins de ce m&#234;me contexte. Les colonnes de la matrice repr&#233;sentent les mots 
mi et les lignes repr&#233;sentent les composantes du vecteur Vmi. Ainsi, une cellule contient la 
probabilit&#233; de cooccurrence du mot mi avec le mot mj, calcul&#233;e selon la formule suivante: 
</p>
<p>j
</p>
<p>ji
ji m de occurrenced' nombre
</p>
<p>cooccurent met  mo&#249;  fois de nombre
=)m P(m
</p>
<p>&#910;&#914;&#992;&#987; &#990;&#927;&#942;&#991;&#909; &#942;&#951;&#911;
</p>
<p>&#911;&#942;&#951; 0,3 0,6 
&#990;&#927;&#942;&#991;&#909; 0,1 0,6 
&#910;&#914;&#992;&#987; 0,1 0,3 
</p>
<p>Tableau 1 : Matrice de cooccurrence des mots d&#8217;une phrase  
</p>
<p>V&#910;&#914;&#992;&#987;
</p>
<p>5 Pour nos exp&#233;rimentations nous avons choisi: &#302;=2, &#533;=1 et &#303; =0,5. 
</p>
<p>255</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Chiraz BEN OTHMANE ZRIBI, Han&#232;ne MEJRI , Mohamed BEN AHMED
</p>
<p>Pour repr&#233;senter le degr&#233; de corr&#233;lation de chaque mot mi avec tous les autres mots mj de la 
phrase, nous proposons de calculer la norme de chaque vecteur Vmi  exprim&#233;e comme suit : 
</p>
<p>&#8225;&#8221;
n
</p>
<p>1=j
</p>
<p>2
ji c=Vm
</p>
<p>O&#249; cj est la probabilit&#233; de cooccurrence du mot mi avec le mot mj de la phrase. Dans 
l&#8217;exemple pr&#233;c&#233;dent, les normes des vecteurs des mots &#911;&#942;&#951;, &#990;&#927;&#942;&#991;&#909; ,&#910;&#914;&#992;&#987; sont respectivement 
&#233;gales &#224; 0,67 ; 0,6  et 0,31. Le mot ayant la norme la moins &#233;lev&#233;e est &#910;&#914;&#992;&#987;, est soup&#231;onn&#233; d&#8217;une 
erreur cach&#233;e. D&#8217;une mani&#232;re g&#233;n&#233;rale, nous &#233;valuons la norme de chaque vecteur mot Vmi &#224;
une valeur seuil. Le ou les mots ayant une norme inf&#233;rieure au seuil sont ajout&#233;s &#224; la liste des 
mots suspect&#233;s.  
</p>
<p>3.3 M&#233;thode Vecteur-Vocabulaire
</p>
<p>Le vocabulaire (termes repr&#233;sentatifs) d&#8217;un texte ou d&#8217;un domaine en question est un  &#233;l&#233;ment 
caract&#233;ristique de ce dernier et un bon indicateur de la coh&#233;rence de ce texte. Nous pouvons, 
par cons&#233;quent et en adoptant le principe de repr&#233;sentation vectorielle pr&#233;c&#233;demment cit&#233;, 
&#233;tudier la validit&#233; s&#233;mantique d&#8217;une phrase en repr&#233;sentant chaque mot lui appartenant par un 
vecteur en fonction de sa probabilit&#233; de cooccurrence avec le vocabulaire. Pour &#233;valuer la 
proximit&#233; entre deux vecteurs, nous utilisons la m&#233;trique de distance angulaire exprim&#233;e 
comme suit : 
</p>
<p>))Vm,(Vmarccos(Sim=)Vm,Dist(Vm jiji
</p>
<p>&#8225;&#8221; &#8225;&#8221;
</p>
<p>&#8225;&#8221;
k
</p>
<p>1=t
k
</p>
<p>1=l
2
jl
</p>
<p>2
it
</p>
<p>k
1=t tjti
</p>
<p>ji
</p>
<p>ji
jiji
</p>
<p>VmVm
</p>
<p>VmVm
=
</p>
<p>Vm*Vm
</p>
<p>VmVm
=)Vm,cos(Vm=)Vm,Sim(Vm
</p>
<p>Le calcul de la distance angulaire se fait pour chaque vecteur mot mi par rapport &#224; tous les 
autres vecteurs mot mj de la phrase. Le vecteur le plus &#233;loign&#233; du contexte correspond au mot 
qui appara&#238;t le moins avec les mots du vocabulaire en corr&#233;lation avec le contexte courant. 
Pour s&#233;lectionner ce vecteur, la somme des distances angulaires de chaque vecteur mot mi est
calcul&#233;e puis compar&#233;e &#224; une valeur seuil. Le ou les mots qui correspondent  &#224; la somme des 
distances la plus &#233;lev&#233;e et sup&#233;rieur au seuil sont soup&#231;onn&#233;s d&#8217;erreurs cach&#233;es.
</p>
<p>3.4 M&#233;thode LSA 
</p>
<p>&quot;LSA (Latent semantic Analysis : Analyse s&#233;mantique latente) est une m&#233;thode permettant 
l&#8217;acquisition des connaissances  &#224; partir de l&#8217;analyse enti&#232;rement automatique de grands 
corpus textuels&quot; (Landauer et al., 1998). Plus pr&#233;cis&#233;ment, cette m&#233;thode permet d&#8217;identifier 
la similarit&#233; s&#233;mantique entre deux mots, deux segments textuels ou la combinaison des deux 
m&#234;me si ces mots ou segments textuels ne sont pas co-occurrents.  
Le principe de la m&#233;thode LSA consiste &#224; repr&#233;senter les mots dits unit&#233;s lexicales et les 
segments textuels (phrases, paragraphes, textes) dits unit&#233;s textuelles par des vecteurs dans un 
espace vectoriel de dimensions r&#233;duites par rapport &#224; l&#8217;espace d&#8217;origine et le mieux 
repr&#233;sentatif de ce dernier. L&#8217;espace d&#8217;origine est repr&#233;sent&#233; par une matrice de cooccurrence 
initiale X(m, n) repr&#233;sentative du corpus d&#8217;apprentissage o&#249; les m lignes correspondent aux 
unit&#233;s lexicales, et les n colonnes aux unit&#233;s textuelles. Une cellule contient le nombre 
d&#8217;occurrences d&#8217;une unit&#233; lexicale dans une unit&#233; textuelle. Cette matrice est d&#233;compos&#233;e en 
produits de trois matrices T(m,t), S(t,t) et D(t,n) gr&#226;ce &#224; une forme d&#8217;analyse factorielle 
appel&#233;e d&#233;composition en valeurs singuli&#232;res. La matrice T est une matrice orthogonale de 
m&#215;t dimensions, D est une matrice orthogonale de t&#215;n dimensions  et S est une matrice 
</p>
<p>256</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Un analyseur hybride pour la d&#233;tection et la correction des erreurs cach&#233;es s&#233;mantiques en arabe 
</p>
<p>diagonale de t&#215;t dimensions dite aussi matrice de valeurs singuli&#232;res. Les valeurs de cette 
derni&#232;re repr&#233;sentent les dimensions de l&#8217;espace d&#8217;origine. 
Dans notre cas, la matrice X a &#233;t&#233; construite durant la phase d&#8217;apprentissage. Les lignes 
correspondent aux lemmes dudit corpus, et ils sont au nombre de 4029, les colonnes 
repr&#233;sentent les phrases dont le nombre est 1827. La r&#233;duction des dimensions consiste &#224; 
choisir parmi les n dimensions les k dimensions les plus pertinentes et les plus repr&#233;sentatives 
de l&#8217;espace d&#8217;origine &#224; partir de la matrice diagonale S tri&#233;e selon l&#8217;ordre de ses valeurs 
singuli&#232;res. Ainsi, nous obtenons trois matrices T (m,k), S(k,k) et D(k,n) de dimensions 
r&#233;duites (k=300 valeur choisie apr&#232;s plusieurs tests). Le produit scalaire de ces matrices 
g&#233;n&#232;re la matrice X&#8217;(m,n) repr&#233;sentative de l&#8217;espace r&#233;sultat.
La variante de la m&#233;thode LSA que nous proposons &#233;tudie la validit&#233; s&#233;mantique des mots 
d&#8217;une phrase donn&#233;e en comparant leurs vecteurs s&#233;mantiques extraits de la matrice de 
cooccurrence transform&#233;e et obtenue lors de la phase d&#8217;apprentissage. Pour mesurer la 
proximit&#233; s&#233;mantique entre les vecteurs issus de la matrice obtenue, nous utilisons, comme le 
cas de la m&#233;thode Vecteur-Vocabulaire, la m&#233;trique de distance angulaire. Ainsi, chaque 
vecteur s&#233;mantique Vmi du mot mi est compar&#233; &#224; tous les vecteurs Vmj des mots mj du 
contexte en fonction de la distance angulaire. La somme de ces distances est ensuite calcul&#233;e 
pour chaque mot mi et compar&#233;e &#224; une valeur seuil. Si cette valeur est sup&#233;rieure au seuil, le 
mot correspondant est soup&#231;onn&#233; d&#8217;une erreur cach&#233;e. 
</p>
<p>3.5 Proc&#233;dure de vote 
</p>
<p>&#201;tant donn&#233; que notre syst&#232;me global de d&#233;tection d&#8217;erreurs cach&#233;es se base sur l&#8217;hypoth&#232;se 
stipulant une erreur au plus par phrase et que les pr&#233;tendues erreurs sont toujours class&#233;es par 
ordre de probabilit&#233; d&#233;croissante, nous avons choisi un vote de type uninominal par 
classement (les candidats sont tri&#233;s et un seul parmi eux sera &#233;lu). Nous pr&#233;sentons dans ce 
qui suit le principe de la m&#233;thode que nous avons adopt&#233;e par notre proc&#233;dure de vote.  
</p>
<p>1. Compter le nombre d&#8217;occurrences des diff&#233;rentes erreurs propos&#233;es par toutes les 
m&#233;thodes d&#8217;analyses s&#233;mantiques pr&#233;sentes dans chaque liste et se trouvant au 
premier rang. 
</p>
<p>2. S&#233;lectionner les erreurs qui ont recueilli le plus grand nombre d&#8217;occurrences. Si une 
seule erreur obtient la majorit&#233; absolue du nombre d&#8217;occurrences, elle est &#233;lue 
comme &#233;tant l&#8217;erreur la plus probable dans la phrase. Sinon, on calcule une nouvelle 
valeur d&#8217;occurrences des erreurs retenues au rang suivant. 
</p>
<p>3. Ce processus se r&#233;p&#232;te autant de fois jusqu'&#224; ce qu&#8217;une seule erreur ayant la majorit&#233; 
absolue d&#8217;occurrences soit retenue. 
</p>
<p>Toutefois, la m&#233;thode de vote propos&#233;e peut conduire parfois &#224; une situation de blocage o&#249; le 
nombre d&#8217;occurrence de deux ou plusieurs erreurs s&#233;lectionn&#233;es en premier rang reste 
toujours invariant. Dans ce cas, nous nous r&#233;f&#233;rons au degr&#233; de confiance attribu&#233; &#224; chaque 
m&#233;thode afin de s&#233;lectionner, parmi la liste des erreurs retenues, celle d&#233;tect&#233;e par la m&#233;thode 
du plus grand degr&#233; de confiance. 
</p>
<p>4 Correction  des erreurs cach&#233;es s&#233;mantiques 
Pour corriger les erreurs cach&#233;es, nous proc&#233;dons &#224; la g&#233;n&#233;ration de toutes les formes proches 
de la forme erron&#233;e, &#224; un caract&#232;re d&#8217;&#233;dition pr&#232;s pour former ainsi une liste contenant les 
</p>
<p>257</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Chiraz BEN OTHMANE ZRIBI, Han&#232;ne MEJRI , Mohamed BEN AHMED
</p>
<p>candidats &#224; la correction. Nous avons utilis&#233; et adapt&#233; &#224; cet effet un correcteur orthographique 
d&#233;velopp&#233; par (Ben Othmane, 1998).   
Comme nous nous attendons &#224; avoir un grand nombre de propositions, d&#251; &#224; la proximit&#233; 
lexicale de la langue arabe, nous avons pens&#233; r&#233;duire cette liste. L&#8217;id&#233;e &#233;tant de substituer la 
forme erron&#233;e par chacune des formes propos&#233;es et former ainsi un ensemble de phrases 
candidates. Ces derni&#232;res seront soumises &#224; notre d&#233;tecteur d&#8217;erreur s&#233;mantique. Celles qui 
produisent des d&#233;r&#232;glements dans la phrase seront &#233;limin&#233;es et c&#8217;est le m&#234;me sort que 
subissent leurs propositions respectives. La liste des propositions restantes est par la suite 
tri&#233;e par ordre de pertinence et pr&#233;sent&#233;e &#224; l&#8217;utilisateur. 
</p>
<p>5 Contexte de travail 
Ce travail vient compl&#233;ter nos recherches pr&#233;c&#233;dentes (Ben Othmane et al., 2005) qui ont 
concern&#233; le probl&#232;me d&#8217;erreurs cach&#233;es (syntaxiques et s&#233;mantiques) pouvant se produire 
dans un texte en langue arabe. Le syst&#232;me qui a &#233;t&#233; propos&#233; pour le traitement de ces erreurs 
est &#224; base d&#8217;agents. Ce syst&#232;me (SMA) se compose principalement d&#8217;un agent pour la 
correction et de deux groupes d&#8217;agents pour la d&#233;tection : un groupe d&#8217;agents syntaxiques 
permettant de traiter les anomalies syntaxiques pouvant se produire dans une phrase donn&#233;e et 
un groupe d&#8217;agents s&#233;mantiques permettant de traiter les incoh&#233;rences s&#233;mantiques. Seul 
l&#8217;agent correction et le groupe d&#8217;agents syntaxiques ont &#233;t&#233; bien &#233;tudi&#233;s et impl&#233;ment&#233;s, nous 
venons donc compl&#233;ter par notre travail la partie s&#233;mantique.  La figure 1 illustre 
l&#8217;architecture globale du syst&#232;me de traitement des erreurs cach&#233;es. 
</p>
<p>Liste tri&#233;e de 
propositions
de correction 
</p>
<p>Phrase 
Texte analys&#233; 
</p>
<p>morpho-
syntactiquemen
t(Format XML)
</p>
<p>Groupe 
syntaxique  
</p>
<p>d&#8217;agents 
</p>
<p>Propositions
de correction 
</p>
<p>Liste r&#233;duite 
de
</p>
<p>propositions
de correction
</p>
<p>Mot suspect
</p>
<p>1
</p>
<p>46
</p>
<p>Groupe 
s&#233;mantique
</p>
<p>d&#8217;agents 
</p>
<p>Agent
Correction  
</p>
<p>1
</p>
<p>8
</p>
<p>8
</p>
<p>12
</p>
<p>13
</p>
<p>414
</p>
<p>15
16
</p>
<p>18 7
</p>
<p>19
</p>
<p>Figure 1 : Architecture du syst&#232;me global de d&#233;tection et correction des erreurs cach&#233;es 
</p>
<p>Nous avons ainsi impl&#233;ment&#233; notre v&#233;rificateur s&#233;mantique sous forme d&#8217;un groupe d&#8217;agents 
s&#233;mantiques, o&#249; chaque m&#233;thode propos&#233;e est appliqu&#233;e par un agent sp&#233;cifique. En plus, un 
agent Superviseur du groupe est charg&#233; de l&#8217;activation des diff&#233;rents sous agents s&#233;mantiques 
responsables d&#8217;analyser la phrase en cours et de d&#233;tecter les incoh&#233;rences s&#233;mantiques qu&#8217;elle 
peut renfermer. Les agents s&#233;mantiques travaillent en parall&#232;le et communiquent leurs 
r&#233;sultats &#224; l&#8217;agent Superviseur qui joue en plus, dans ce cas, le r&#244;le de d&#233;cideur en 
s&#233;lectionnant l&#8217;erreur la plus probable parmi l&#8217;ensemble des listes d&#8217;erreurs d&#233;tect&#233;es par les 
diff&#233;rents agents en appliquant la proc&#233;dure de vote.
</p>
<p>258</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Un analyseur hybride pour la d&#233;tection et la correction des erreurs cach&#233;es s&#233;mantiques en arabe 
</p>
<p>6 Exp&#233;rimentations et r&#233;sultats
Pour l&#8217;&#233;valuation de notre syst&#232;me, nous avons choisi un texte de test de m&#234;me type et 
appartenant au m&#234;me domaine que le corpus d&#8217;apprentissage utilis&#233;. Il  compte 1 564 mots, 
100 phrases dont 50 contiennent une erreur cach&#233;e.
La figure suivante illustre les performances de chaque agent, ainsi, que du syst&#232;me global de 
d&#233;tection des erreurs cach&#233;es s&#233;mantiques en terme de pr&#233;cision. 
</p>
<p>97,05%
82,92% 77,50%
</p>
<p>50,94%
</p>
<p>89,18%
</p>
<p>0%
20%
40%
60%
80%
</p>
<p>100%
120%
</p>
<p>Syst&#232;me global Agent Co-occurrence-
Collocation
</p>
<p>Agent LSA Agent
Vecteur_Contexte
</p>
<p>Agent Vecteur-
Vocabulaire
</p>
<p>Pr
&#233;c
</p>
<p>isi
on
</p>
<p> (%
)
</p>
<p>Figure  2 : Performances du syst&#232;me de d&#233;tection des erreurs cach&#233;es s&#233;mantiques
</p>
<p>Le taux de pr&#233;cision le plus &#233;lev&#233; pour l&#8217;ensemble des agents s&#233;mantiques est celui de l&#8217;agent 
Cooccurrence-Collocation avec une valeur de 89,18%. Cette performance s&#8217;explique par la 
compl&#233;mentarit&#233; des ph&#233;nom&#232;nes de cooccurrence, de collocation et de r&#233;p&#233;tition. Contre 
toute attente, le taux fourni  par l&#8217;agent LSA (82,92%) s&#8217;av&#232;re plus faible ; ceci est d&#251; sans 
doute &#224; la modestie de nos donn&#233;es d&#8217;apprentissage qui cause un taux &#233;lev&#233; de sur-d&#233;tection 
d&#8217;erreurs. Toutefois, la m&#233;thode LSA reste toujours prometteuse par rapport aux m&#233;thodes 
bas&#233;es uniquement sur les cooccurrences des mots.  En effet, le taux de pr&#233;cision de l&#8217;agent 
Vecteur-Contexte, est relativement faible (77,5%) et  celui de l&#8217;agent Vecteur_Vocabulaire 
n&#8217;est pas bon (50,94%). L&#8217;am&#233;lioration des r&#233;sultats de ces derniers n&#233;cessiterait &#224; notre avis 
un grand corpus d&#8217;apprentissage, une strat&#233;gie d&#8217;extraction du vocabulaire du domaine plus 
fiable et une s&#233;lection fine et bien &#233;tudi&#233;e des textes formant le corpus d&#8217;apprentissage.  Pour 
ce qui est du  r&#233;sultat de l&#8217;&#233;valuation du syst&#232;me global, nous pouvons dire que le taux de 
pr&#233;cision qui est &#233;gal &#224; 97,05% est tr&#232;s satisfaisant. La performance du syst&#232;me de vote et 
son apport quant &#224; la s&#233;lection de l&#8217;erreur la plus probable dans la phrase se confirment donc.
Quant &#224; la phase de correction, elle a &#233;t&#233; test&#233;e &#224; deux niveaux ; d&#8217;abord apr&#232;s l&#8217;obtention de 
toutes les propositions de correction, ensuite apr&#232;s la minimisation de la liste de ces 
propositions. Les r&#233;sultats obtenus sont illustr&#233;s dans le tableau ci-apr&#232;s. 
</p>
<p>Couverture Pr&#233;cision Ambigu&#239;t&#233; Proposition Position 
   Initialement 100% 100% 100% 46,67 13,82 
</p>
<p>Minimisation 100% 80% 80% 5,98 3,43 
</p>
<p>Tableau 2 : Performance du syst&#232;me de correction des erreurs cach&#233;es s&#233;mantiques 
</p>
<p>Nous remarquons que notre m&#233;thode de minimisation de la liste des propositions a permis de 
r&#233;duire, consid&#233;rablement (98%), le nombre moyen des propositions (46,67 &#224; 5,98 
propositions en moyenne). Cette diminution, bien qu&#8217;elle ait r&#233;duit l&#8217;ambigu&#239;t&#233; de notre 
correcteur de 20%, ne s&#8217;est pas pass&#233;e sans d&#233;g&#226;t. Elle s&#8217;est faite au d&#233;pend de la pr&#233;cision 
(diminution de 20%). 
</p>
<p>259</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Chiraz BEN OTHMANE ZRIBI, Han&#232;ne MEJRI , Mohamed BEN AHMED
</p>
<p>7 Conclusion
</p>
<p>Notre syst&#232;me de d&#233;tection d&#8217;erreurs cach&#233;es s&#233;mantiques a donn&#233; des r&#233;sultats satisfaisants 
(taux de pr&#233;cision de 97,05%) en d&#233;pit des contraintes et des restrictions li&#233;es &#224; la taille ainsi 
qu&#8217;&#224; la non diversit&#233; de nos donn&#233;es d&#8217;apprentissage. Nous signalons, aussi, l&#8217;apport de la 
d&#233;marche suivie pour la correction de la forme erron&#233;e qui a permis de minimiser la liste des 
propositions de correction de 98% et d&#8217;avancer la forme correcte aux premiers rangs. 
Cependant, nous estimons que les r&#233;sultats obtenus peuvent &#234;tre encore am&#233;lior&#233;s d&#8217;abord par 
l&#8217;utilisation d&#8217;un bon corpus d&#8217;apprentissage de nature plus vari&#233; et de taille plus importante. 
D&#8217;autres perspectives proches sont &#233;galement en vue, nous pensons effectivement int&#233;grer les 
deux groupes d&#8217;agents syntaxiques et s&#233;mantiques ensemble afin de former le syst&#232;me global 
de traitement des erreurs cach&#233;es en langue arabe.  
</p>
<p>R&#233;f&#233;rences
BEN HAMADOU A. (1993). V&#233;rification et correction automatique par analyse affixale des textes &#233;crits 
</p>
<p>en langue naturelle : le cas de l&#8217;arabe non voyell&#233;. Th&#232;se d&#8217;&#233;tat en informatique, Facult&#233; des 
Sciences de Tunis.
</p>
<p>BEN OTHMANE Z. C. (1998). De la synth&#232;se lexicographique &#224; la d&#233;tection et la correction des graphie 
fautives arabes. Th&#232;se de doctorat, Universit&#233; de Paris XI, Orsay.  
</p>
<p>BEN OTHMANE Z. C., BEN AHMED M. (2003). Le contexte au service des graphies fautives arabes. 
TALN&#8217;03, Batz-sur-Mer. 
</p>
<p>BEN OTHMANE Z. C., BEN FRAJ F., BEN AHMED M. (2005). Un syst&#232;me multi-agent pour le 
traitement des erreurs cach&#233;es en langue arabe. Actes de la 12&#232;me Conf&#233;rence sur le Traitement 
Automatique des langues naturelles TALN'05, Dourdan, vol. 1, p. 143-153. 
</p>
<p>BIGERT J., KNUTSSON O. (2002). Robust Error Detection : A Hybrid Approach Combining 
Unsupervised Error Detection and Linguistic Knowledge. In Proceedings of Robust Methods in 
Analysis of Natural Language Data (ROMAND&#8217;02), Frascati, Italie. 
</p>
<p>GOLDING A. (1995). A Bayesian hybrid method for context-sensitive spelling correction. In 
Proceedings of the third Workshop On Very Large Corpora, Cambridge, Massachuses, USA, 
(1995), 39-53. 
</p>
<p>GOLDING A., SCHABES Y. (1996). Combining trigram based and feature based methods for context 
sensitive spelling correction. In Proceedings of the 34th Annual Meeting of the Association for 
Computational Linguistics, Santa Cruz, 71-78. 
</p>
<p>GOLDING A., ROTH D. (1999). A winnow-based approach to context-sensitive spelling correction. 
Machine Learning, 34(1-3), 107-130. 
</p>
<p>LANDAUER T.K., Foltz P.W., Laham D. (1998). An introduction to Latent Semantic Analysis. 
Discourse Processes, Vol. 25, 259-284. 
</p>
<p>MLAYEH I. (2004). Extraction de collocations &#224; partir de corpus textuels en langue arabe. M&#233;moire de 
mast&#232;re, Ecole nationale des sciences informatiques, Universit&#233; de la Manouba.  
</p>
<p>VERBERNE S. (2002). Context sensitive spell checking based on word trigram probabilities. Master 
thesis Taal, Spraak &amp; Informatica, University of Nijmegen. 
</p>
<p>XIAOLONG W., JIANHUA L. (2001). Combine trigram and automatic weight distribution in Chinese 
spelling error correction. Journal of computer Science and Technology, Volume 17 Issue 6, 
Province, China.
</p>
<p>260</p>

</div></div>
</body></html>