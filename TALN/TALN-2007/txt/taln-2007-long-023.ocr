TALN 2007, Toulouse, 5—8juin 2007

Un analyseur hybride pour la détection et la correction
des erreurs cachées sémantiques en langue arabe

Chiraz BEN OTHMANE ZRIBI, Hanene MEJRI , Mohamed BEN AHMED
Laboratoire de recherche RIADI, Université La Manouba
ENSI, La Manouba, Tunisie
Chiraz.benothmane@riadi.rnu.tn, Hanene.mejri@riadi.rnu.tn,
Mohamed.benahmed@riadi.rnu.tn

Résumé. Cet article s’intéresse au probleme de la detection et de la correction des erreurs
cachées sémantiques dans les textes arabes. Ce sont des erreurs orthographiques produisant
des mots lexicalement valides mais invalides sémantiquement. Nous commencons par décrire
le type d’erreur sémantique auquel nous nous intéressons. Nous exposons par la suite
l’approche adoptée qui se base sur la combinaison de plusieurs méthodes, tout en décrivant
chacune de ces méthodes. Puis, nous évoquons le contexte du travail qui nous a mené au
choix de l’architecture multi-agent pour l’implémentation de notre systeme. Nous présentons
et commentons vers la ﬁn les résultats de l’évaluation dudit systeme.

Abstract. In this paper, we address the problem of detecting and correcting hidden
semantic spelling errors in Arabic texts. Hidden semantic spelling errors are morphologically
valid words causing invalid semantic irregularities. After the description of this type of errors,
we propose and argue the combined method that we adopted in this work to realize a hybrid
spell checker for detecting and correcting hidden spelling errors. Afterward, we present the
context of this work and show the multi-agent architecture of our system. Finally, we expose
and comment the obtained results.

Mots-clés 2 erreur cachée, erreur sémantique, détection, correction, systeme multi-agent,
langue arabe.

Ke 0I‘dS: hidden error, semantic error, detection, correction, multi-agent system,
Ara ic language.

1 Introduction

Les erreurs cachées sont des erreurs orthographiques produisant des mots valides
lexicalement et causant des déreglements de haut niveau: syntaxique, sémantique, voire
méme pragmatique. Les erreurs cachées surviennent lorsqu’une ou plusieurs modiﬁcations
sur un mot le transforme en un autre mot de la langue. Dans ce cas, l’erreur, est dans la
plupart du temps, une graphie semblable au mot que l’utilisateur avait l’intention d’écrire.

Le jardinier utilise le gﬁteau (rdteau) pour bécher la terre

251

Chiraz BEN OTHMANE ZRIBI, Hanene MEJRI , Mohamed BEN AHMED

Dans cet exemple, le mot « gdteau » est introduit dans un contexte qui ne lui est pas
approprie. Cette faute de frappe peut étre corrigee en retablissant le mot correct « rdteau ».

Dans (Verbeme, 2002) on lit que les statistiques realisees pour la langue anglaise par
(Eastman, Oakman, 1991) afﬁrment que les erreurs cachees representent 25% parmi toutes les
erreurs orthographiques commises et contenues dans leur corpus de reference. (Mitton, 1987)
cite par le méme auteur, leur attribue une valeur plus grande a savoir : 40% parmi toutes les
erreurs orthographiques etudiees. Ces deux valeurs assez importantes ont rendu l’etude de ce
genre d’erreurs une necessite en soi. Plusieurs recherches ont ete entreprises dans le but de
remedier a ce probleme. Nous pouvons citer par exemple les recherches de Golding qui a
etudie ce genre d’erreurs pour la langue anglaise. 11 a ainsi propose differentes methodes
comme la methode de Bayes (Golding, 1995), la methode des trigrammes des parties du
discours (Golding, Schabes, 1996) et la methode a base de reseaux neuronaux dite Winnow
(Golding, Roth, 1999). Le chinois a ete aussi traite avec les deux chercheurs (Xiaolong,
Jianhua, 2001). Le suedois a egalement fait l’objet d’une recherche avec (Bigert, Knutsson,
2002).

En ce qui concerne la langue arabe, aucun autre travail n’a concerne le traitement des erreurs
cachees malgre l’importance de l’entreprise d’une telle recherche. La langue arabe presente,
en effet, des speciﬁcites dont nous citons principalement : l’agglutination, l’ambigu’1’te
grammaticale et la proximite lexicale. Toutes ces caracteristiques rendent le risque de
commettre une erreur cachee plus important que pour les autres langues notamment latines.

Nous nous sommes donc interesses a ce probleme en construisant un systeme permettant a la
fois de detecter et de corriger ce type d’erreurs pouvant survenir dans des textes arabes. Dans
un premier temps ce systeme a concerne uniquement les anomalies syntaxiques (Ben
Othmane et al., 2005). Nous l’avons amende par la suite pour qu’il puisse traiter l’ensemble
des anomalies (syntaxiques et semantiques).

Dﬁ a la complexite de ce travail, nous avons ete amenes a emettre certaines hypotheses pour
restreindre les champs de nos investigations. Nous avons considere alors l’arabe non voyelle
et ce pour une raison capitale. C’est que malgre l’importance des voyellesl dans la
comprehension du discours arabe, elles n’apparaissent que tres rarement dans les textes.
Ainsi, a part quelques ouvrages poetiques ou litteraires didactiques, les ecrits arabes sont
generalement depourvus de voyelles, et c’est le cas des textes frequemment rencontres dans
les journaux, les revues, les romans, etc. Aussi, nous emettons l’hypothese de l’existence
d’une seule erreur par phrase et par mot. Cette erreur consisterait en une seule faute
typographique du type: ajout d’un caractere, omission d’un caractere, substitution d’un
caractere par un autre ou interversion de deux caracteres adjacents. Des statistiques ont en
effet montre que l'une (seulement) de ces operations est a l'origine d’une erreur
orthographique dans 90% des cas (Ben Hamadou, 1993).

Dans ce qui suit, nous decrivons dans la premiere section le type d’erreurs semantiques
auquel nous nous sommes interesses et formant ce qu’on appelle des erreurs cachees
semantiques. Dans la deuxieme section, nous presentons l’approche proposee pour la
conception de notre systeme de detection—correction erreurs cachees semantiques. Dans la
troisieme section de l’article, nous abordons le contexte de notre travail, ainsi, que
l’architecture d’implementation adoptee pour la realisation de notre systeme. La quatrieme et
derniere section est consacree, quant a elle, a la description des resultats de l’evaluation du
systeme mis en place.

1 Signes diacritiques ajoutées aux lettres arabes pour permettre leur lecture

252

Un analyseur hybride pour la detection et la correction des erreurs cachees semantiques en axabe

2 Les erreurs cachees sémantiques

Nous entendons par « erreur cachee semantique » tout mot ressemblant typographiquement a
un caractere pres au mot correct qu’il remplace mais invalide semantiquement dans le
contexte ou il se trouve. Les dereglements semantiques causees par ce type d’erreurs peuvent
étre reparties en deux categories: les incompatibilités sémantiques et les incomplétudes
sémantiques. Quand l’erreur cause des contresens ou encore rend la phrase depourvue de
sens, nous parlons dans ce cas d’incompatz'bilité sémantique. Quand a l’incompletude
semantique, elle concerne principalement l’oubli de mots, de syntagmes ou d’outils de
coordination necessaires a l’inte1pretation de la phrase.

Nous nous interessons ici qu’aux anomalies mettant en cause le sens. Les erreurs
d’incompletude sont plus djfﬁciles a deceler.

(M55)  Yb-l4-.~1= cu-'4)-2
Ils luiproposent de gandes (beaucoup) d ’argent

Dans cette phrase erronee, l’adjectif "bees" (grandes) est utilise au lieu de l’adjectif "U255"
(beaucoup) et il se trouve dans un contexte inapproprie par la substitution de la lettre «a par la
lettre ¢-.

3 Detection des anomalies sémantiques

Pour que la machine puisse traiter la semantique des mots, elle doit disposer, par analogie a
l’étre humain, des connaissances a propos du sens des mots et des djfferents contextes dans
lesquels ils apparaissent. Ces connaissances peuvent étre obtenues a partir de plusieurs
ressources informatiques telles que les djctionnaires semantiques, les thesaurus, les reseaux
semantiques, les ontologies ou les corpus textuels.

Dans le cadre de ce travail, nous optons pour une solution basee sur l’apprentissage du sens
des mots a partir des corpus textuels. Cette orientation repose sur un principe de la
linguistique distributionnelle qui dit que : "le sens d ’un motpeut étre défini statistiquement, £1
partir de l’ensemble des contextes (i.e., paragraphes, phrases, textes) dans lesquels ce mot
apparait" (Landauer et al., 1998). Par exemple, le mot avian apparait souvent conjointement
avec des mots comme décoller, aile, aéroport, et rarement conjointement avec des mots
comme lion ouforét.

Pour detecter les erreurs cachees semantiques, nous proposons une approche qui se base sur
l’etude de la validite semantique de chaque mot du texte a analyser dans son contexte et ceci
par la combinaison de plusieurs methodes permettant de representer chaque mot en fonction
du contexte proche et lointain dans lequel il apparait et de comparer cette representation aux
representations anterieures obtenues lors de l’apprentissage.

Nous faisons ainsi appel a quatre methodes, de nature statistique ou mixte (linguistique et
statistique), responsables chacune de veriﬁer la validite semantique d’une phrase donnee.
L’idee derriere cette combinaison est d’obtenir un analyseur d’erreurs cachees semantiques
capable de tirer proﬁt des avantages de toutes les methodes d’analyses semantiques
proposees. Ceci implique la construction de plusieurs systemes de traitement d’erreurs
cachees qui seront mis en confrontation quant a la selection d’une erreur cachee semantique
dans une phrase. Cette confrontation est realisee suite a l’application d’une procedure de vote
qui prendra en consideration tous les resultats issus de l’application des methodes d’analyses
semantiques proposees et procedera a un vote pour l’identiﬁcation de l’erreur la plus probable
garantissant ainsi une meilleure qualite d’analyse.

253

Chiraz BEN OTHMANE ZRIBI, Hanene MEJRI , Mohamed BEN AHMED

Pendant la phase d’apprentissage, sont récoltées a partir d’un corpus dit d’entrainement traité
au préalablez toutes les connaissances nécessaires aux différentes méthodes proposées et
formant leurs entrées. Ce corpus3 comporte 30 textes de type économique, et compte environ
30 000 mots, I827 phrases et 4029 lemmes. Les connaissances extraites se présentent sous
forme de données linguistiques et statistiques et varient selon les besoins de chaque méthode
d’analyse utilisée.

3.1 Méthode Coocurrence-Collocation

Cette méthode vériﬁe la validite contextuelle d’un mot en se basant sur sa probabilité
contextuelle déduite du calcul des trois mesures suivantes :

2

Probabilité de cooccurrence : Cette probabilité est calculée pour chaque mot m,- de
la phrase a analyser pour une fenétre de 10 mots4. Elle est exprimée par la formule
de probabilité conditionnelle de Bayes suivante :

|m.)P(-n .)

.... ..c ,)

_ P(c K, .... ..c _l,cl,......c
P(c,, .... ..c _,,c,,

  

P(m ,|C) = P(m ,|ck,......c _l,cl,......c K)

Ou m,-représente le mot a analyser, c,- les mots voisins du contexte proche et P(m,-) la
probabilité d’apparition du mot m,- dans le corpus d’apprentissage.

Coefficient de collocation : Une collocation est une expression ayant une structure
morphosyntaxique précise et une fréquence d’apparition importante dans le corpus
d’apprentissage, exemple : 1-in-5| tgbﬁ (les rues de la ville). Pour calculer ce
coefﬁcient nous procédons d’abord a l’identiﬁcation des collocations existantes dans
une phrase en se basant sur une liste de collocations obtenue lors de la phase
d’apprentissage. Pour se faire, nous avons utilisé et adopté une partie du systeme
réalisé par (Mlayeh, 2004). Lorsque une collocation est identiﬁée dans une phrase,
un coefﬁcient collocationnel est attribué a chaque mot de cette expression. Ce
coefﬁcient n’est autre que la mesure de Kulczinsky, qui est un critere d’association
permettant d’identiﬁer le degré de correlation de deux lemmes I,- et I,-.calculée a l’aide
de la formule suivante :

1 )

a
K =_ A
U0 (a+b+a+c

2

Ou : a : le nombre d’occurrences du couple (Ii, lj)
b : le nombre d’occurrences des couples ou li apparait non suivi de l,-
c : le nombre d’occurrences des couples ou lj est non precede dé Ii

La valeur de ce coefﬁcient varie entre 0 et 1 et il est égal a 0,5 quand li est toujours
observé avec lj. Une expression est considérée comme collocation si son coefﬁcient
de KUC est supérieur a 0,5.

Probabilité de répéﬁtion: "les mots ou plus précisément les lemmes des mots d ’un
texte ant tendance 21 se répéter dans le texte lui-méme". Cette hypothése est déduite
des comptages réalisés par (Ben Othmane, Ben Ahmed, 2003) sur un corpus textuel
en langue arabe appartenant a un domaine particulier qui montrent qu’une forme

Analyse’ morpho-syntaxiquement, de’coupé en phrases et en syntagmes nominaux et verbaux.

3 Ces textes proviennent £1 l’origine du corpus de 1’arabe contemporain collecte’ par A1-Sulaiti L.
hm;://www.comp.1eeds.ac.uk/eric/latifa/arabic-co;pora.htm. Ils ont été choisis par ce qu’ils sont relatifs £1 un

meme domaine.

4

La taille de la fenétre est parame'trable et peut étre facilement ajuste’e.

254

Un analyseur hybride pour la detection et la correction des erreurs cachees sernantiques en arabe

textuelle apparait en moyenne 5,6 fois dans un meme texte alors qu’un lemme
apparait en moyenne 6,3 fois et ce dans le meme texte. Subsequemment, si le lemme
d’un mot se repete tres peu dans le texte, le mot en question peut correspondre a une
erreur cachee. Cette probabilite conceme donc le taux d’apparition de chaque lemme
des mots de la phrase, objet de veriﬁcation, dans le corpus de test. Ce taux est
calcule par la formule suivante :

nombre d'occurences del,
uombre total de lemmes

Pa .) =
La combinaison de ces trois mesures en vue de l’obtention de la probabilite contextuelle P(m,-)
de chaque mot de la phrase se fait selon la formule lineaire suivante :

P(mi) = u*P(mi|C)+p*KUC(mi)+5*P(1i)

Ou P(m,-\C) est la probabilite de cooccurrence du mot m,-, KUC(m,-) est le coefﬁcient
collocationelle attribue a un mot m,-, P(ll-) est la probabilite de repetition pour un lemme l,- du
mot m,-. a, ,8, et 6 sont des poids attribues aux djfferentes probabilites aﬁn de mettre en
evidence la contribution de chaque probabilite. Il est a noter que ces valeurs ne sont pas
connues a l’avance et sont determinees lors des experimentations5. Toutefois, nous estimons
que la valeur de a doit étre plus importante que celles de ,8, et 6 vu que le contexte voisin est
plus determinant pour le sens du mot a analyser que son contexte lointain.

Une fois les probabilites relatives 51 tous les mots de la phrase en question sont calculees, elles
seront comparees a une valeur seuil determine lors des experimentations. Le ou les vocables
ayant une probabilite inferieure a ce seuil forment une liste d’erreurs cachees eventuelles.

3.2 Méthode Vecteur-Contexte

Cette methode consiste a representer chaque mot de la phrase par un vecteur en fonction du
contexte dans lequel il apparait. De ce fait, un vecteur mot Vm,- n’est autre qu’une
representation vectorielle de la probabilite de cooccurrence de ce mot avec chaque mot de la
phrase. Considerons par exemple, la phrase suivante :

(ha-l5)_,\-§d.>J5‘ +05
L ’homme a bu un chien (un verre)

La matrice ci-dessus illustre la probabilite de cooccurrence de chaque mot m,- de la phrase
avec les mots voisins de ce meme contexte. Les colonnes de la matrice representent les mots
m,- et les lignes representent les composantes du vecteur Vm,-. Ainsi, une cellule contient la
probabilite de cooccurrence du mot m,- avec le mot mj, calculee selon la formule suivante:
nombre de fois on m, et rn , cooocurent

P :
(m ‘ l m’) nombre d'oocurrence de In’

‘7'

Vans

 

Tableau 1 : Matrice de cooccurrence des mots d’une phrase

5 Pour nos expérimentations nous avons choisi: oL=2, [i=1 et 8 =0,5.

255

Chiraz BEN OTHMANE ZRIBI, Hanene MEJRI , Mohamed BEN AHMED

Pour representer le degre de correlation de chaque mot m,- avec tous les autres mots m,- de la
phrase, nous proposons de calculer la norme de chaque vecteur Vm,- exprimee comme suit :

||Vm.|| = ,/,i‘,’c?

Ou c,- est la probabilite de cooccurrence du mot m,- avec le mot m,- de la phrase. Dans
l’exemple precedent, les normes des vecteurs des mots «Tu-3, J9)“ ,\-.45 sont respectivement
egales a 0,67 ; 0,6 et 0,31. Le mot ayant la norme la moins elevee est l-.45, est soupconne d’une
erreur cachee. D’une maniere generale, nous evaluons la norme de chaque vecteur mot Vm,- a
une valeur seuil. Le ou les mots ayant une norme inferieure au seuil sont ajoutes a la liste des
mots suspectes.

3.3 Méthode Vecteur-Vocabulaire

Le vocabulaire (termes representatifs) d’un texte ou d’un domaine en question est un element
caracteristique de ce demier et un bon indicateur de la coherence de ce texte. Nous pouvons,
par consequent et en adoptant le principe de representation vectorielle precedemment cite,
etudier la validite semantique d’une phrase en representant chaque mot lui appartenant par un
vecteur en fonction de sa probabilite de cooccurrence avec le vocabulaire. Pour evaluer la
proximite entre deux vecteurs, nous utilisons la metrique de distance angulaire exprimee
comme suit :

Dist(Vm ,,Vm].) = a1ccos(Sim (Vm,,Vm].))

V111 ‘V111: 1"l=.Vm "Vin H

“V111 ,||« "Vin ,|| = ,/’:*::.7 ; r:.Tn ;,

Le calcul de la distance angulaire se fait pour chaque vecteur mot m,- par rapport a tous les
autres vecteurs mot m,- de la phrase. Le vecteur le plus eloigne du contexte correspond au mot
qui apparait le moins avec les mots du vocabulaire en correlation avec le contexte courant.
Pour selectionner ce vecteur, la somme des distances angulaires de chaque vecteur mot m,- est
calculee puis comparee a une valeur seuil. Le ou les mots qui correspondent a la somme des
distances la plus elevee et superieur au seuil sont soupconnes d’erreurs cachees.

Sim(Vm ‘,Vm J)= oos(Vm ‘,Vm J) =

3.4 Méthode LSA

"LSA (Latent semantic Analysis : Analyse semantique latente) est une methode permettant
l’acquisition des connaissances a partir de l’analyse entierement automatique de grands
corpus textuels" (Landauer et al., 1998). Plus precisement, cette methode permet d’identiﬁer
la similarite semantique entre deux mots, deux segments textuels ou la combinaison des deux
meme si ces mots ou segments textuels ne sont pas co-occurrents.

Le principe de la methode LSA consiste a representer les mots dits unites lexicales et les
segments textuels (phrases, paragraphes, textes) dits unites textuelles par des vecteurs dans un
espace vectoriel de dimensions reduites par rapport a l’espace d’origine et le mieux
representatif de ce dernier. L’espace d’origine est represente par une matrice de cooccurrence
initiale X(m, 11) representative du corpus d’apprentissage ou les m lignes correspondent aux
unites lexicales, et les n colonnes aux unites textuelles. Une cellule contient le nombre
d’occurrences d’une unite lexicale dans une unite textuelle. Cette matrice est decomposee en
produits de trois matrices T(m,t), S(t,t) et D(t,n) grace a une forme d’analyse factorielle
appelee decomposition en valeurs singulieres. La matrice T est une matrice orthogonale de
m><t dimensions, D est une matrice orthogonale de t><n dimensions et S est une matrice

256

Un analyseur hybride pour la detection et la correction des erreurs cachees semantiques en aiabe

diagonale de t><t dimensions dite aussi matrice de valeurs singulieres. Les valeurs de cette
demiere representent les dimensions de l’espace d’origine.

Dans notre cas, la matrice X a ete construite durant la phase d’apprentissage. Les lignes
correspondent aux lemmes dudit corpus, et ils sont au nombre de 4029, les colonnes
representent les phrases dont le nombre est 1827. La reduction des dimensions consiste a
choisir parmi les n dimensions les k dimensions les plus pertinentes et les plus representatives
de l’espace d’origine a partir de la matrice diagonale S triee selon l’ordre de ses valeurs
singulieres. Ainsi, nous obtenons trois matrices T (m,k), S(k,k) et D(k,n) de dimensions
reduites (k=300 valeur choisie apres plusieurs tests). Le produit scalaire de ces matrices
genere la matrice X ’(m, 11) representative de l’espace resultat.

La variante de la methode LSA que nous proposons etudie la validite semantique des mots
d’une phrase donnee en comparant leurs vecteurs semantiques extraits de la matrice de
cooccurrence transformee et obtenue lors de la phase d’apprentissage. Pour mesurer la
proximite semantique entre les vecteurs issus de la matrice obtenue, nous utilisons, comme le
cas de la methode Vecteur-Vocabulaire, la metrique de distance angulaire. Ainsi, chaque
vecteur semantique Vm,- du mot m,- est compare a tous les vecteurs Vm,- des mots m,- du
contexte en fonction de la distance angulaire. La somme de ces distances est ensuite calculee
pour chaque mot m,- et comparee a une valeur seuil. Si cette valeur est superieure au seuil, le
mot correspondant est soupconne d’une erreur cachee.

3.5 Procedure de vote

Etant donne que notre systeme global de detection d’erreurs cachees se base sur l’hypothese
stipulant une erreur au plus par phrase et que les pretendues erreurs sont toujours classees par
ordre de probabilite decroissante, nous avons choisi un vote de type uninominal par
classement (les candidats sont tries et un seul parmi eux sera elu). Nous presentons dans ce
qui suit le principe de la methode que nous avons adoptee par notre procedure de vote.

1. Compter le nombre d’occurrences des differentes erreurs proposees par toutes les
methodes d’analyses semantiques presentes dans chaque liste et se trouvant au
premier rang.

2. Selectionner les erreurs qui ont recueilli le plus grand nombre d’occurrences. Si une
seule erreur obtient la majorite absolue du nombre d’occurrences, elle est elue
comme etant l’erreur la plus probable dans la phrase. Sinon, on calcule une nouvelle
valeur d’occurrences des erreurs retenues au rang suivant.

3. Ce processus se repete autant de fois jusqu'a ce qu’une seule erreur ayant la majorite
absolue d’occurrences soit retenue.

Toutefois, la methode de vote proposee peut conduire parfois a une situation de blocage ou le
nombre d’occurrence de deux ou plusieurs erreurs selectionnees en premier rang reste
toujours invariant. Dans ce cas, nous nous referons au degré de conﬁance attribue a chaque
methode aﬁn de selectionner, parmi la liste des erreurs retenues, celle detectee par la methode
du plus grand degre de conﬁance.

4 Correction des erreurs cachées sémantiques

Pour corriger les erreurs cachees, nous procedons a la generation de toutes les formes proches
de la forme erronee, a un caractere d’edition pres pour former ainsi une liste contenant les

257

Chiraz BEN OTHMANE ZRIBI, Hanene MEJRI , Mohamed BEN AHMED

candidats a la correction. Nous avons utilisé et adapté a cet effet un correcteur orthographique
développé par (Ben Othmane, 1998).

Comme nous nous attendons a avoir un grand nombre de propositions, dﬁ a la proximité
lexicale de la langue arabe, nous avons pensé réduire cette liste. L’idée étant de substituer la
forme erronée par chacune des formes proposées et former ainsi un ensemble de phrases
candidates. Ces dernieres seront soumises a notre détecteur d’erreur sémantique. Celles qui
produisent des déreglements dans la phrase seront éliminées et c’est le méme sort que
subissent leurs propositions respectives. La liste des propositions restantes est par la suite
triée par ordre de pertinence et présentée a l’utilisateur.

5 Contexte de travail

Ce travail vient compléter nos recherches précédentes (Ben Othmane et al., 2005) qui ont
concerné le probleme d’erreurs cachées (syntaxiques et sémantiques) pouvant se produire
dans un texte en langue arabe. Le systeme qui a été proposé pour le traitement de ces erreurs
est a base d’agents. Ce systeme (SMA) se compose principalement d’un agent pour la
correction et de deux groupes d’agents pour la détection: un groupe d’agents syntaxiques
permettant de traiter les anomalies syntaxiques pouvant se produire dans une phrase donnée et
un groupe d’agents sémantiques permettant de traiter les incohérences sémantiques. Seul
l’agent correction et le groupe d’agents syntaxiques ont été bien étudiés et implémentés, nous
venons donc compléter par notre travail la partie sémantique. La ﬁgure 1 illustre
l’architecture globale du systeme de traitement des erreurs cachées.

     
   

 

Texte analysé 0
morpho- Phrase .' .'
syntactiquemen W {:> f
t(Format XML) y
Groupe Groupe
T’ Synmxilllle sémanﬁque
ol d’agents d’agents
I

| 6 Mot suspect °

 
       
     

. . .-
P1'°P°51t1°D5 Liste réduite
Liste triée de de correction de.t.

- - ro OS1 ions
pmposmo-us ° 0 cllje clorrection
de correction Agent

Correction

 

Figure 1 : Architecture du systerne global de detection et correction des erreurs cachées

Nous avons ainsi implémenté notre vériﬁcateur sémantique sous forme d’un groupe d’agents
sémantiques, ou chaque méthode proposée est appliquée par un agent spéciﬁque. En plus, un
agent Superviseur du groupe est chargé de l’activation des différents sous agents sémantiques
responsables d’analyser la phrase en cours et de détecter les incohérences sémantiques qu’elle
peut renfermer. Les agents sémantiques travaillent en parallele et communiquent leurs
résultats a l’agent Superviseur qui joue en plus, dans ce cas, le role de décideur en
sélectionnant l’erreur la plus probable parmi l’ensemble des listes d’erreurs détectées par les
différents agents en appliquant la procédure de vote.

258

Un analyseur hybride pour la detection et la correction des erreurs cachees sémantiques en axabe

6 Expérimentations et résultats

Pour l’evaluation de notre systeme, nous avons choisi un texte de test de méme type et
appartenant au meme domaine que le corpus d’apprentissage utilise. I1 compte 1 564 mots,
100 phrases dont 50 contiennent une erreur cachee.

La ﬁgure suivante illustre les performances de chaque agent, ainsi, que du systeme global de
detection des erreurs cachees semantiques en terme de precision.

120% - 97 050/
Q 100% V 89il8% '9 " 77 5o°/
ﬁg: 80?’ -i  so,94°/..
_ .7 T 1-}
 60%:
E 40% -7 T
20% '
0%
Syllélneglabal Aga.IlCo—occurra.1c& AganLsA Ayn Aynvecccup
Collncalicll Veclu.|r_CaJI=x1c Vucalrulaire

Figure 2 : Performances du systeme de detection des erreurs cachees sémantiques

Le taux de precision le plus eleve pour l’ensemble des agents semantiques est celui de l’agent
Cooccurrence-Collocation avec une valeur de 89,18%. Cette perfonnance s’explique par la
complementarite des phenomenes de cooccurrence, de collocation et de repetition. Contre
toute attente, le taux fourni par l’agent LSA (82,92%) s’avere plus faible ; ceci est dﬁ sans
doute a la modestie de nos donnees d’apprentissage qui cause un taux eleve de sur-detection
d’erreurs. Toutefois, la methode LSA reste toujours prometteuse par rapport aux methodes
basees uniquement sur les cooccurrences des mots. En effet, le taux de precision de l’agent
Vecteur-Contexte, est relativement faible (77,S%) et celui de l’agent Vecteur_Vocabulaire
n’est pas bon (50,94%). L’amelioration des resultats de ces derniers necessiterait a notre avis
un grand corpus d’apprentissage, une strategie d’extraction du vocabulaire du domaine plus
ﬁable et une selection ﬁne et bien etudiee des textes formant le corpus d’apprentissage. Pour
ce qui est du resultat de l’evaluation du systeme global, nous pouvons dire que le taux de
precision qui est egal 51 97,05% est tres satisfaisant. La performance du systeme de vote et
son apport quant a la selection de l’erreur la plus probable dans la phrase se conﬁnnent donc.

Quant a la phase de correction, elle a ete testee a deux niveaux ; d’abord apres l’obtention de
toutes les propositions de correction, ensuite apres la minimisation de la liste de ces
propositions. Les resultats obtenus sont illustres dans le tableau ci-apres.

Cauverture Précisian A ' " ' Prapasitiun Pusitian
Initialement 100% 100% 100% 46,67 13,82
Minimisation 100% 80% 80% 5,98 3,43

Tableau 2 : Performance du systerne de correction des erreurs cachees sémantiques

Nous remarquons que notre methode de minimisation de la liste des propositions a permis de
reduire, considerablement (98%), 1e nombre moyen des propositions (46,67 51 5,98
propositions en moyenne). Cette diminution, bien qu’elle ait reduit l’ambigu’1’te de notre
correcteur de 20%, ne s’est pas passee sans degat. Elle s’est faite au depend de la precision
(diminution de 20%).

259

Chiraz BEN OTHMANE ZRIBI, Hanene MEJRI , Mohamed BEN AHMED

7 Conclusion

Notre systeme de détection d’erreurs cachées sémantiques a donné des résultats satisfaisants
(taux de precision de 97,0S%) en dépit des contraintes et des restrictions liées a la taille ainsi
qu’a la non diversite de nos données d’apprentissage. Nous signalons, aussi, l’apport de la
démarche suivie pour la correction de la forme erronée qui a permis de minimiser la liste des
propositions de correction de 98% et d’avancer la forme correcte aux premiers rangs.
Cependant, nous estimons que les résultats obtenus peuvent étre encore améliorés d’abord par
l’utilisation d’un bon corpus d’apprentissage de nature plus varié et de taille plus importante.
D’autres perspectives proches sont également en vue, nous pensons effectivement integrer les
deux groupes d’agents syntaxiques et sémantiques ensemble aﬁn de former le systeme global
de traitement des erreurs cachées en langue arabe.

Références

BEN HAMADOU A. (1993). Veriﬁcation et correction automatique par analyse afﬁxale des textes écrits
en langue naturelle: le cas de l’arabe non voyellé. These d’état en inforrnatique, Faculté des
Sciences de Tunis.

BEN OTHMANE Z. C. (1998). De la synthese lexicographique a la détection et la correction des graphie
fautives arabes. These de doctorat, Université de Paris XI, Orsay.

BEN OTHMANE Z. C., BEN AHMED M. (2003). Le contexte au service des graphies fautives arabes.
TALN’03, Batz-sur-Mer.

BEN OTHMANE Z. C., BEN FRAJ F., BEN AHMED M. (2005). Un systeme multi-agent pour le
traitement des erreurs cachées en langue arabe. Actes de la 12 "3 Conference sur le Traiternent
Automatique des langues naturelles TALN'05, Dourdan, vol. 1, p. 143-153.

BIGERT J., KNUTSSON O. (2002). Robust Error Detection: A Hybrid Approach Combining

Unsupervised Error Detection and Linguistic Knowledge. In Proceedings of Robust Methods ir1
Analysis of Natural Language Data (ROMAND’02), Frascati, Italie.

GOLDING A. (1995). A Bayesian hybrid method for context-sensitive spelling correction. In
Proceedings of the third Workshop On Very Large Corpora, Cambridge, Massachuses, USA,
(1995), 39-53.

GOLDING A., SCHABES Y. (1996). Combining trigrarn based and feature based methods for context
sensitive spelling correction. In Proceedings of the 34th Armual Meeting of the Association for
Computational Linguistics, Santa Cruz, 71-78.

GOLDING A., ROTH D. (1999). A winnow-based approach to context-sensitive spelling correction.
Machine Learning, 34(1-3), 107-130.

LANDAUER T.K., Foltz P.W., Laham D. (1998). An introduction to Latent Semantic Analysis.
Discourse Processes, Vol. 25, 259-284.

MLAYEH I. (2004). Extraction de collocations a partir de corpus textuels en langue arabe. Mémoire de
mastere, Ecole nationale des sciences inforrnatiques, Université de la Manouba.

VERBERNE S. (2002). Context sensitive spell checking based on word trigram probabilities. Master
thesis Taal, Spraak & Informatica, University of Nijmegen.

XIAOLONG W., JIANHUA L. (2001). Combine trigram and automatic weight distribution ir1 Chinese
spelling error correction. Journal of computer Science and Technology, Volume 17 Issue 6,
Province, China.

260

