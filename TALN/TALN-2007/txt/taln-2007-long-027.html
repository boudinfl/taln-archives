<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Les vecteurs conceptuels, un outil compl&#233;mentaire aux r&#233;seaux lexicaux</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2007, Toulouse, 5&#8211;8 juin 2007
</p>
<p>Les vecteurs conceptuels, un outil compl&#233;mentaire
aux r&#233;seaux lexicaux
</p>
<p>Didier SCHWAB1, Lim LIAN TZE1, Mathieu LAFOURCADE2
1 Computer-Aided Translation Unit (UTMK)
</p>
<p>School of Computer Sciences, Universiti Sains Malaysia
Penang, Malaysia
</p>
<p>2 TAL-LIRMM, Universit&#233; Montpellier II &#8211; CNRS
161 rue ada, 34392 Montpellier Cedex 5, France
</p>
<p>{didier,liantze}@cs.usm.my, lafourcade@lirmm.fr
</p>
<p>R&#233;sum&#233;. Fr&#233;quemment utilis&#233;s dans le Traitement Automatique des Langues Naturelles,
les r&#233;seaux lexicaux font aujourd&#8217;hui l&#8217;objet de nombreuses recherches. La plupart d&#8217;entre eux,
et en particulier le plus c&#233;l&#232;bre WordNet, souffrent du manque d&#8217;informations syntagmatiques
mais aussi d&#8217;informations th&#233;matiques (&#171; probl&#232;me du tennis &#187;). Cet article pr&#233;sente les vec-
teurs conceptuels qui permettent de repr&#233;senter les id&#233;es contenues dans un segment textuel
quelconque et permettent d&#8217;obtenir une vision continue des th&#233;matiques utilis&#233;es gr&#226;ce aux
distances calculables entre eux. Nous montrons leurs caract&#233;ristiques et en quoi ils sont com-
pl&#233;mentaires des r&#233;seaux lexico-s&#233;mantiques. Nous illustrons ce propos par l&#8217;enrichissement
des donn&#233;es de WordNet par des vecteurs conceptuels construits par &#233;mergence.
</p>
<p>Abstract. There is currently much research in natural language processing focusing on
lexical networks. Most of them, in particular the most famous,WordNet, lack syntagmatic infor-
mation and but also thematic information (&#171;Tennis Problem &#187;). This article describes conceptual
vectors that allows the representation of ideas in any textual segment and offers a continuous
vision of related thematics, based on the distances between these thematics. We show the cha-
racteristics of conceptual vectors and explain how they complement lexico-semantic networks.
We illustrate this purpose by adding conceptual vectors to WordNet by emergence.
</p>
<p>Mots-cl&#233;s : WordNet, vecteurs conceptuels, informations lexicales, informations th&#233;ma-
tiques.
</p>
<p>Keywords: WordNet, conceptual vectors, lexical information, thematic information.
</p>
<p>1 Introduction
</p>
<p>Originellement issus des travaux de Ross Quillian sur la psycholinguistique &#224; la fin des ann&#233;es
60 (Quillian, 1968), les r&#233;seaux lexicaux sont toujours aujourd&#8217;hui au centre des recherches en
Traitement Automatique des Langues Naturelles. Ils sont utilis&#233;s dans de nombreuses t&#226;ches
(d&#233;sambiguisation lexicale (Mihalcea et al., 2004)) ou applications du domaine (traduction au-
tomatique avec les r&#233;seaux multilingues comme Papillon (Mangeot-Lerebours et al., 2003) ou
</p>
<p>293</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Didier SCHWAB, Lim LIAN TZE, Mathieu LAFOURCADE
</p>
<p>(Knight &amp; Luk, 1994), recherche d&#8217;informations ou classification de textes (Harabagiu &amp; Chai,
1998)). La plupart de ces r&#233;seaux, et sp&#233;cifiquement le plus c&#233;l&#232;bre d&#8217;entre eux WordNet (Fell-
baum, 1988), souffrent du manque d&#8217;informations syntagmatiques mais aussi d&#8217;informations
concernant le domaine d&#8217;usage des termes ou du moins les termes th&#233;matiquement associ&#233;s.
Il n&#8217;y a ainsi aucune relation directe entre des termes comme &#8618;teacher&#8617;-&#8618;student&#8617; (&#8618;enseignant&#8617;-
&#8618;&#233;tudiant&#8617;) et &#8618;boat&#8617;-&#8618;port&#8617; (&#8618;bateau&#8617;-&#8618;port&#8617;). Ce ph&#233;nom&#232;ne a &#233;t&#233; nomm&#233; &#171; Probl&#232;me du tennis &#187;
[(Fellbaum, 1988), p. 10] lorsqu&#8217;il a &#233;t&#233; remarqu&#233; qu&#8217;il fallait chercher les &#233;quivalents de &#8618;balle&#8617;,
&#8618;raquette&#8617; et &#8618;court&#8617; &#224; diff&#233;rents endroits de la hi&#233;rarchie.
</p>
<p>Depuis quelques ann&#233;es, l&#8217;&#233;quipe de traitement automatique des langues (TAL) du LIRMM
(Laboratoire d&#8217;Informatique, de Robotique et de Micro&#233;lectronique de Montpellier) travaille
sur une formalisation de la projection de la notion linguistique de champ s&#233;mantique dans un
espace vectoriel, les vecteurs conceptuels. Ils permettent de repr&#233;senter les id&#233;es contenues dans
un segment textuel quelconque et permettent d&#8217;obtenir une vision continue des th&#233;matiques
utilis&#233;es gr&#226;ce aux distances calculables entre eux.
</p>
<p>Dans cet article, nous pr&#233;sentons les vecteurs conceptuels et en particulier leur version &#233;mer-
gente. Nous montrons leurs caract&#233;ristiques et en quoi ils sont compl&#233;mentaires des r&#233;seaux
lexico-s&#233;mantiques. Nous illustrons ce propos par une exp&#233;rience men&#233;e &#224; Penang en Malaisie
qui a consist&#233; &#224; enrichir les donn&#233;es de WordNet de vecteurs conceptuels par &#233;mergence.
</p>
<p>2 R&#233;seaux lexico-s&#233;mantique : l&#8217;exemple deWordNet
</p>
<p>Principe et lacunes. WordNet est une base de donn&#233;es lexicale pour l&#8217;anglais d&#233;velopp&#233;e sous
la direction de George Armitage Miller par le Cognitive Science Laboratory de l&#8217;universit&#233; de
Princeton (&#201;tats-Unis d&#8217;Am&#233;rique). Il se veut repr&#233;sentatif du fonctionnement de l&#8217;acc&#232;s au
lexique mental humain.
</p>
<p>WordNet est organis&#233; en ensembles de synonymes appel&#233;s synsets. &#192; chaque synset correspond
un concept. Le sens des termes est d&#233;crit dans WordNet par trois moyens : (1) leur d&#233;finition ;
(2) le synset auquel ce sens est rattach&#233; ; (3) les relations lexicales qui unissent entre eux les
synsets. On trouve parmi ces relations, l&#8217;hyperonymie, la m&#233;ronymie et l&#8217;antonymie.
</p>
<p>La version 2 de WordNet compte 152059 termes ce qui constitue une couverture relativement
large de la langue anglaise. Dans les premi&#232;res versions de WordNet, les relations lexicales ne
connectent que les termes de m&#234;me morphologie. Il y a donc une hi&#233;rarchie pour les noms, une
pour les adjectifs, une pour les verbes et enfin une derni&#232;re pour les adverbes.
</p>
<p>Dans (Harabagiu et al., 1999), les auteurs de WordNet (alors &#224; sa version 1.6) rel&#232;vent six
faiblesses dans la construction de leur r&#233;seau : (1) le manque de liens entre les hi&#233;rarchies ;
(2) le nombre limit&#233; de relations entre termes traitant du m&#234;me sujet ; (3) le manque de relations
morphologiques ; (4) l&#8217;absence de relations th&#233;matiques ; (5) l&#8217;absence de certains sens de mots ;
(6) le manque d&#8217;uniformisation et de coh&#233;rence dans les d&#233;finitions. Si les points 3, 5 et 6 ne
nous int&#233;ressent pas dans cet article, nous allons montrer l&#8217;apport des vecteurs conceptuels pour
la r&#233;solution des autres, tous trois formant le probl&#232;me du tennis.
</p>
<p>Exp&#233;riences cherchant &#224; r&#233;soudre le probl&#232;me du tennis. Dans cet article, nous nous int&#233;-
resserons uniquement &#224; la version 2.1 de WordNet qui &#233;tait la derni&#232;re disponible au moment
</p>
<p>294</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Compl&#233;mentarit&#233; des r&#233;seaux lexicaux et des vecteurs conceptuels
</p>
<p>o&#249; nous avons r&#233;alis&#233; nos exp&#233;riences. Une nouvelle version (3.0) est sortie en D&#233;cembre 2006
mais elle ne semble pas comporter de r&#233;elles am&#233;liorations par rapport &#224; la version pr&#233;c&#233;dente
pour ce qui nous int&#233;resse ici.
</p>
<p>Depuis la version 2, des relations comme derivationally related form (formes d&#233;rivationnelles)
permettent de lier des adjectifs &#224; des verbes ou des adjectifs &#224; des noms. De m&#234;me, les syn-
sets peuvent se voir attribuer un domaine d&#8217;usage. Toutefois, ces donn&#233;es semblent encore
en nombre trop restreint pour &#234;tre suffisamment pertinentes. Des relations typiques comme
&#8618;teacher&#8617;-&#8618;student&#8617; (&#8618;enseignant&#8617;-&#8618;&#233;tudiant&#8617;) &#8618;boat&#8617;-&#8618;port&#8617; (&#8618;bateau&#8617;-&#8618;port&#8617;) ou &#8618;doctor&#8617;-&#8618;hospital&#8617; (&#8618;doc-
teur&#8617;-&#8618;h&#244;pital&#8617;), pourtant souvent indispensables &#224; une t&#226;che de d&#233;sambigu&#239;sation lexicale, ne s&#8217;y
trouvent toujours pas et le nombre restreint d&#8217;indications th&#233;matiques comme l&#8217;est le domaine
ne permet pas de compenser ce d&#233;faut. Plusieurs solutions ont &#233;t&#233; propos&#233;es pour r&#233;soudre tout
ou partie de ce probl&#232;me.
</p>
<p>Avec eXtended WordNet, (Harabagiu et al., 1999) propose de d&#233;sambigu&#239;ser l&#8217;ensemble des
d&#233;finitions de WordNet de fa&#231;on semi-automatique. L&#8217;id&#233;e est, pour chaque d&#233;finition, de dire
quel est le sens utilis&#233; pour chacun des termes. On peut ensuite comparer deux synsets et &#233;valuer
leur similarit&#233;. Nous verrons que nous utilisons ces informations pour fabriquer les vecteurs
conceptuels de cette exp&#233;rience. D&#8217;autres eux aussi rajoutent des informations aux synsets.
Ainsi, (Agirre et al., 2001) ajoutent des signatures lexicales issues de corpus tagg&#233;s ou du Web.
En revanche, d&#8217;autres cherchent plut&#244;t &#224; augmenter le nombre d&#8217;arcs existants. (Stevenson,
2002), par exemple, combine diff&#233;rentes m&#233;triques pour cr&#233;er des arcs entre synsets &#224; partir de
leur d&#233;finition et d&#8217;un th&#233;saurus. (Ferret &amp; Zock, 2006) utilisent eux un r&#233;seau de coocurrences
pour extraire des relations typiques comme celles pr&#233;sent&#233;es dans un paragraphe pr&#233;c&#233;dent.
</p>
<p>On le voit, toutes ses propositions ont en commun d&#8217;appartenir en particulier au domaine du
discret. La n&#244;tre est d&#8217;introduire une repr&#233;sentation continue des id&#233;es contenues dans le r&#233;seau,
les vecteurs conceptuels.
</p>
<p>3 Les vecteurs Conceptuels
</p>
<p>Nous pr&#233;sentons ici les points fondamentaux &#224; comprendre sur les vecteurs conceptuels. Nous
revenons sur le mode de construction classique des vecteurs conceptuels, c&#8217;est-&#224;-dire tels qu&#8217;ils
ont &#233;t&#233; &#233;tudi&#233;s au LIRMM depuis 19971, &#224; partir d&#8217;un ensemble de concepts choisis a priori.
Nous expliquons dans cette partie certaines notions de base qui nous seront utiles pour pr&#233;senter
ensuite la construction par &#233;mergence, c&#8217;est &#224; dire sans concepts pr&#233;d&#233;finis.
</p>
<p>Principe G&#233;n&#233;raux. Nous repr&#233;sentons les aspects th&#233;matiques des segments textuels (do-
cuments, paragraphes, syntagmes, etc.) par des vecteurs conceptuels, une formalisation de la
projection de la notion linguistique de champ s&#233;mantique dans un espace vectoriel. &#192; partir
d&#8217;un ensemble de notions &#233;l&#233;mentaires dont nous faisons l&#8217;hypoth&#232;se, les concepts2, il est pos-
sible de construire des vecteurs dont chaque composante correspond &#224; un concept et est positive.
Par exemple, le vecteur de l&#8217;item lexical &#8618;vie&#8617;, qui fusionne tous les sens de &#8618;vie&#8617;, peut &#234;tre pro-
jet&#233; sur les concepts suivants (les CONCEPT!intensit&#233;&quot; sont ordonn&#233;s par valeurs d&#233;croissantes de
l&#8217;intensit&#233;) : V &#8618;vie&#8617; = (VIE!0.7&quot;, NAISSANCE!0.48&quot;, ENFANCE! 0.46&quot;, MORT!0.43&quot;, VIEILLESSE!0.41&quot;, . . .).
</p>
<p>1Voir les articles de l&#8217;&#233;quipe dans les pr&#233;c&#233;dentes &#233;ditions de cette conf&#233;rence ou (Schwab, 2005).
2Dans notre exp&#233;rimentation sur le fran&#231;ais nous utilisons (Larousse, 1992) qui d&#233;fini 873 concepts.
</p>
<p>295</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Didier SCHWAB, Lim LIAN TZE, Mathieu LAFOURCADE
</p>
<p>La construction des vecteurs conceptuels se fait &#224; partir de d&#233;finitions extraites de diverses
sources (dictionnaires, listes de synonymes, indexations manuelles, ...). Cette m&#233;thode d&#8217;ana-
lyse construit, &#224; partir de vecteurs conceptuels d&#233;j&#224; existants et de nouvelles d&#233;finitions, de
nouveaux vecteurs.
</p>
<p>Distance angulaire. La comparaison entre deux vecteurs se fait gr&#226;ce &#224; la distance angulaire
DA. Pour deux vecteurs conceptuels A et B, DA(A,B) = arccos(Sim(A,B)) o&#249; Sim est
Sim(X, Y ) = cos(X&#770;, Y ) = X&#183;Y&#8214;X&#8214;&#215;&#8214;Y &#8214; . Intuitivement, cette fonction constitue une &#233;valuation de
la proximit&#233; th&#233;matique et en pratique la mesure de l&#8217;angle entre les deux vecteurs. Empirique-
ment, nous estimons que pour une distance DA(X, Y ) &#8804; pi4 (45&#9702;), X et Y sont th&#233;matiquement
proches et partagent plusieurs concepts. PourDA(X,Y ) &#8805; pi4 , la proximit&#233; th&#233;matique est consi-
d&#233;r&#233;e comme faible et aux alentours de pi2 (90
</p>
<p>&#9702;), X et Y n&#8217;ont aucune relation. Nous obtenons,
par exemple, les angles suivants :
DA(V(&#8618;fourmilier&#8617;), V(&#8618;fourmilier&#8617;))=0 (0&#9702;) DA(V(&#8618;fourmilier&#8617;), V(&#8618;mammif&#232;re&#8617;))=0.36 (21&#9702;)
DA(V(&#8618;fourmilier&#8617;), V(&#8618;animal&#8617;))=0.45 (26&#9702;) DA(V(&#8618;fourmilier&#8617;), V(&#8618;quadrup&#232;de&#8617;))=0,42 (24&#9702;)
DA(V(&#8618;fourmilier&#8617;), V(&#8618;train&#8617;))=1.18 (68&#9702;) DA(V(&#8618;fourmilier&#8617;), V(&#8618;fourmi&#8617;))=0,26 (15&#9702;)
</p>
<p>Le premier r&#233;sultat a une interpr&#233;tation directe, &#8618;fourmilier&#8617; ne peut &#234;tre plus proche d&#8217;autre
chose que de lui m&#234;me. Le fait qu&#8217;un &#8618;fourmilier&#8617; soit un &#8618;mammif&#232;re&#8617; explique le deuxi&#232;me
r&#233;sultat. Un &#8618;fourmilier&#8617; n&#8217;a que peu de rapport avec un &#8618;train&#8617; ce qui explique l&#8217;angle plus im-
portant. Dans le dernier exemple, l&#8217;angle peu important entre &#8618;fourmilier&#8617; et &#8618;fourmi&#8617; se comprend
si on se rappelle queDA est une distance th&#233;matique et non une distance ontologique. L&#8217;examen
de la d&#233;finition de fourmilier, &#171;mammif&#232;re qui se nourrit de fourmis &#187;, explique le r&#233;sultat.
</p>
<p>Le voisinage th&#233;matique, une vision continue de la th&#233;matique. La fonction de voisinage
th&#233;matique permet de conna&#238;tre les items lexicaux voisins d&#8217;un item lexical donn&#233;. On d&#233;finit V
la fonction de voisinage qui renvoie les k items les plus proches en termes de distance angulaire
DA d&#8217;un texte Z dans une base vectorielle. Soit
|V(DA, Z, k)| = k &#8704;X &#8712; V(DA, Z, k), &#8704;Y /&#8712; V(DA, Z, k), DA(X, Z) &#8804; DA(Y, Z)
Par exemple, les 7 termes proches et ordonn&#233;s par distance th&#233;matique croissante du nom &#8618;mort&#8617;
peuvent &#234;tre :
</p>
<p>V(DA, &#8618;mort&#8617;, 7) = (&#8618;mort&#8617; 0) (&#8618;meurtre&#8617; 0.367) (&#8618;tueur&#8617; 0.377) (&#8618;&#226;ge de la vie&#8617; 0.481) (&#8618;tyrannicide&#8617;
0.516) (&#8618;tuer&#8617; 0.579) (&#8618;mort :adj&#8617; 0.582)
</p>
<p>La m&#233;thode de voisinage peut &#234;tre utilis&#233;e lors de l&#8217;apprentissage des vecteurs conceptuels pour
v&#233;rifier la coh&#233;rence globale de la base ou en phase d&#8217;exploitation pour trouver le meilleur mot
&#224; utiliser dans un &#233;nonc&#233;. Ainsi, elle constitue un nouvel outil pour acc&#233;der aux mots et &#224; leur
sens, compl&#233;mentaire &#224; ceux d&#233;crits dans (Zock, 2002) comme la forme, la morphologie ou la
navigation dans un grand r&#233;seau lexical. La fonction de voisinage permet ainsi une navigation
dans le domaine du continu contrairement aux r&#233;seaux s&#233;mantiques qui ne permettent qu&#8217;une
navigation discr&#232;te.
</p>
<p>Somme vectorielle. SoientX et Y deux vecteurs, leur somme vectorielle norm&#233;eV est d&#233;finie
par : &#977;2 &#8594; &#977; : V = X &#8853; Y | Vi = Xi+Yi&#8214;X+Y &#8214; o&#249; &#977; est l&#8217;ensemble des vecteurs conceptuels,
Vi (resp Xi, Yi) repr&#233;sente la i-&#232;me composante du vecteur V (resp. X, Y).
</p>
<p>La somme vectorielle norm&#233;e de deux vecteurs donne un vecteur &#233;quidistant en termes d&#8217;angle
des deux premiers vecteurs. Il s&#8217;agit en fait d&#8217;une moyenne des vecteurs somm&#233;s. En tant
</p>
<p>296</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Compl&#233;mentarit&#233; des r&#233;seaux lexicaux et des vecteurs conceptuels
</p>
<p>qu&#8217;op&#233;ration sur les vecteurs conceptuels, on peut donc voir la somme vectorielle norm&#233;e
comme l&#8217;union des id&#233;es contenues dans les termes.
</p>
<p>Soient X et Y deux vecteurs, leur produit terme &#224; terme normalis&#233; V est d&#233;fini par : &#977;2 &#8594;
&#977; : V = X &#8855; Y | vi = &#8730;xiyi L&#8217;op&#233;rateur &#8855; peut &#234;tre interpr&#233;t&#233; comme un op&#233;rateur
d&#8217;intersection entre vecteurs. Si l&#8217;intersection entre deux vecteurs est le vecteur nul, alors ils
n&#8217;ont rien en commun. Du point de vue des vecteurs conceptuels, cette op&#233;ration permet donc
de s&#233;lectionner les id&#233;es communes &#224; un ensemble de termes.
</p>
<p>Construction des vecteurs par &#233;mergence. L&#8217;approche par &#233;mergence s&#8217;affranchit de tout
th&#233;saurus et vecteurs de concept comme base de d&#233;part. Seule d la taille du vecteur est fix&#233;e
a priori. Le mode de construction des vecteurs est identique au mod&#232;le classique &#224; la diff&#233;-
rence que si un des vecteurs entrant dans la somme est inexistant, car non encore calcul&#233;, alors
ce vecteur est tir&#233; au hasard. Le processus de calcul est it&#233;r&#233; jusqu&#8217;&#224; convergence de chaque
vecteur.
</p>
<p>Comme nous le montrons de fa&#231;on plus d&#233;taill&#233;e dans (Lafourcade, 2006), il y a un certain
nombre d&#8217;avantages &#224; utiliser ce mod&#232;le. Le premier d&#8217;entre eux est de pouvoir choisir libre-
ment la quantit&#233; de ressources que l&#8217;on souhaite utiliser en choisissant la taille des vecteurs de
fa&#231;on appropri&#233;e. Pour donner une id&#233;e de l&#8217;importance de ce choix, une base de 500000 vec-
teurs de dimension 1000 fait environ 2Go, de taille 2000, 4Go, . . . Comme il ne serait pas alors
ni raisonnable ni facile de d&#233;finir une jeu de concept de la taille choisie, autant chercher une ap-
proche nous permettant de nous en passer. De plus, ce qui peut sembler un pis-aller ou au mieux
un compromis, s&#8217;av&#232;re un avantage car la densit&#233; lexicale dans l&#8217;espace des mots calcul&#233;s par
&#233;mergence est bien plus constante que dans un espace o&#249; les concepts sont pr&#233;calcul&#233;s. En effet,
les ressources (les dimensions de l&#8217;espace) ont tendance &#224; &#234;tre harmonieusement distribu&#233;es en
fonction de la richesse lexicale.
</p>
<p>4 Mod&#233;lisation hybride du sens : vecteurs conceptuels et r&#233;-
seaux lexicaux
</p>
<p>4.1 Apport des r&#233;seaux lexicaux aux vecteurs conceptuels
</p>
<p>Les distances utilis&#233;es sur les vecteurs, comme le montre (Besan&#231;on, 2001), mettent en exergue
les composantes communes et/ou les composantes distinctes. Si nous utilisons en particulier
la distance angulaire, c&#8217;est que ses caract&#233;ristiques math&#233;matiques, sa simplicit&#233; &#224; comprendre
et &#224; interpr&#233;ter linguistiquement ainsi que son efficacit&#233; en termes de temps de calcul en font
un bon outil. Quelle que soit la distance choisie, utilis&#233;e sur ce type de vecteur (repr&#233;sentant
des id&#233;es, des concepts plut&#244;t que des termes cooccurrents), elle est d&#8217;autant plus faible que les
vecteurs des objets lexicaux qui en sont les arguments sont dans un champ s&#233;mantique proche
(en isotopie selon la terminologie de Rastier (Rastier, 1985)).
</p>
<p>Dans le cadre d&#8217;une analyse s&#233;mantique comme celle qui nous int&#233;resse ici, nous l&#8217;utilisons
pour tirer profit des informations mutuelles contenues dans les vecteurs conceptuels pour faire
de la d&#233;sambigu&#239;sation lexicale sur des mots qui ont des sens situ&#233;s dans un champ s&#233;mantique
proche. Ainsi, &#171; Zidane a marqu&#233; un but &#187; peut &#234;tre d&#233;sambigu&#239;s&#233;e gr&#226;ce aux id&#233;es communes
concernant le sport tandis que &#171; L&#8217;avocat a plaid&#233; &#224; la cour &#187; peut l&#8217;&#234;tre gr&#226;ce &#224; celles concer-
</p>
<p>297</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Didier SCHWAB, Lim LIAN TZE, Mathieu LAFOURCADE
</p>
<p>nant la justice. De m&#234;me, en ce qui concerne les rattachements pr&#233;positionnels, les vecteurs
peuvent permettre dans &#171; Il voit la fille avec un t&#233;lescope. &#187; de rattacher &#171; avec un t&#233;lescope &#187;
au verbe &#8618;voir&#8617; gr&#226;ce aux id&#233;es communes sur la vision.
</p>
<p>En revanche, les vecteurs conceptuels ne peuvent pas aider &#224; r&#233;soudre des cas o&#249; les termes
mis en jeu sont dans des champs s&#233;mantiques diff&#233;rents. On remarquera m&#234;me qu&#8217;une ana-
lyse ne reposant que sur eux peut conduire &#224; de gros contre-sens. Par exemple, dans la phrase
&#171; L&#8217;avocat a mang&#233; un fruit &#187;, &#8618;avocat&#8617; ne peut &#234;tre interpr&#233;t&#233; que comme le fruit et non comme
l&#8217;auxiliaire de justice. Ces limites des vecteurs conceptuels ont &#233;t&#233; exp&#233;rimentalement montr&#233;es
pour l&#8217;analyse s&#233;mantique sur des algorithmes &#224; fourmis dans (Lafourcade &amp; Guinand, 2006).
</p>
<p>Il aurait fallu que des connaissances comme &#171; un avocat est un &#234;tre humain &#187; et &#171; un &#234;tre hu-
main mange &#187; puissent &#234;tre identifi&#233;es, ce qui n&#8217;est donc pas possible avec des vecteurs concep-
tuels seuls. Les vecteurs conceptuels seuls ne sont ainsi pas suffisants pour exploiter certaines
instances de fonctions lexicales dans les textes et un r&#233;seau lexical peut donc aider &#224; pallier
ces manques. Des publications ant&#233;rieures ont montr&#233; la n&#233;cessit&#233; de cette approche hybride :
(Schwab et al., 2002) pour les antonymies, (Lafourcade &amp; Prince, 2003) pour les g&#233;n&#233;riques et
les hyperonymes. (Schwab, 2005) &#233;tend cette constatation &#224; toute relation susceptible d&#8217;aider &#224;
la r&#233;solution d&#8217;une analyse s&#233;mantique.
</p>
<p>4.2 Apport des vecteurs conceptuels aux r&#233;seaux lexicaux
</p>
<p>S&#8217;ils b&#233;n&#233;ficient d&#8217;une pr&#233;cision certaine, le rappel des r&#233;seaux est bien moins fort. Il est, en
effet, difficile de penser que l&#8217;on pourrait repr&#233;senter toutes les relations entre les termes. En
effet, comment consid&#233;rer deux termes qui sont dans le m&#234;me champ s&#233;mantique ? Ils peuvent
tr&#232;s bien ne pas se trouver dans le r&#233;seau car ils ne seraient pas forc&#233;ment reli&#233;s par un des arcs
&#8220;classiques&#8221;. Envisager l&#8217;introduction d&#8217;arcs de type champ s&#233;mantique, poserait &#224; nos yeux
deux probl&#232;mes dus au caract&#232;re flou et flexible de cette relation :
&#8211; le premier est li&#233; &#224; l&#8217;id&#233;e de la relation que se fait le concepteur de la base, &#224; quel moment
consid&#232;re-t&#8217;il que deux synsets sont dans le m&#234;me champ s&#233;mantique ? Dans un cas d&#233;favo-
rable, on aurait tr&#232;s peu de ces arcs tandis que dans un cas oppos&#233;, on pourrait se trouver avec
une explosion combinatoire du nombre d&#8217;arc ;
</p>
<p>&#8211; le second probl&#232;me, plus fondamental, est li&#233; &#224; la repr&#233;sentation elle m&#234;me. Comment envi-
sager de repr&#233;senter par un &#233;l&#233;ment discret une relation floue donc du domaine du continu ?
</p>
<p>Ainsi, le domaine du continu offert par les vecteurs conceptuels offre des flexibilit&#233;s que le
domaine du discret offert par les r&#233;seaux ne peut donner. Il permet de pouvoir rapprocher des
mots sur des id&#233;es peu importantes mais pourtant communes &#224; deux objets.
</p>
<p>Avec cette approche hybride - vecteurs conceptuels, r&#233;seau lexical - nous proposons de com-
biner des informations de nature compl&#233;mentaire. Les vecteurs conceptuels et l&#8217;op&#233;ration de
distance th&#233;matique par leur nature peuvent pallier le faible rappel intrins&#232;que aux r&#233;seaux
lexicaux tandis que ces derniers peuvent permettre de d&#233;sambigu&#239;ser les cas qui sont dans un
champs s&#233;mantique diff&#233;rent contrairement aux vecteurs conceptuels. Les d&#233;fauts des uns sont
ainsi compens&#233;s par les qualit&#233;s des autres ce qui fait des vecteurs conceptuels et des r&#233;seaux
lexicaux des outils compl&#233;mentaires.
</p>
<p>298</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Compl&#233;mentarit&#233; des r&#233;seaux lexicaux et des vecteurs conceptuels
</p>
<p>5 Exp&#233;rience sur WordNet : utilisation des donn&#233;es
</p>
<p>5.1 Exploitation des d&#233;finitions
</p>
<p>Le projet eXtended WordNet (Mihalcea &amp; Moldovan, 2001) est men&#233; &#224; la Southern Methodist
University de Dallas au Texas et vise deux objectifs : (1) d&#233;sambigu&#239;ser l&#8217;ensemble des termes
utilis&#233;s dans les d&#233;finitions des synsets, c&#8217;est-&#224;-dire indiquer quels sont les synsets employ&#233;s
dans la d&#233;finition ; (2) Transformer ces d&#233;finitions en forme logique pour permettre plus facile-
ment les calculs.
</p>
<p>Ces donn&#233;es ont &#233;t&#233; r&#233;alis&#233;es de fa&#231;on semi-automatique en utilisant les informations du r&#233;-
seau3, des distances entre d&#233;finitions ou bien les informations sur le domaine. Ces donn&#233;es sont
en partie contr&#244;l&#233;es &#224; la main et le taux de pr&#233;cision de plus de 90%.
</p>
<p>Pour les vecteurs conceptuels, nous avons utilis&#233; ces donn&#233;es sous forme logique car elles per-
mettent de rep&#233;rer les &#233;l&#233;ments les plus importants de la d&#233;finition, en particulier le genre. Le
calcul se fait ainsi sur un arbre en d&#233;pendances fabriqu&#233; &#224; partir de cette d&#233;finition pr&#233;trait&#233;e
pour enlever le m&#233;talangage difficilement exploitable pour une analyse th&#233;matique. Dans nos
explications, nous allons prendre pour exemple la forme logique de la d&#233;finition de fourmi.
</p>
<p>ant :NN(x1) -&gt; social :JJ(x1) insect :NN(x1) live :VB(e1, x1, x3) in :IN(e1, x2) organized :JJ(x2) colony :NN(x2)
</p>
<p>Elle est organis&#233;e en 3 ensembles : x1 = {social, insect}, x2 = {organised, colony} et e1 =
{live}. Ce dernier ainsi que in permettent de hi&#233;rarchiser les ensembles. Le vecteur de chacun
des ensembles est calcul&#233; en faisant la somme vectorielle de l&#8217;&#233;l&#233;ment le plus porteur de sens
de cet ensemble (verbes, VB ; noms, NN ) et de la moiti&#233; des adjoints (adverbes, RB ; adjectifs,
JJ). Le calcul du vecteur global se fait ensuite par somme vectorielle pond&#233;r&#233;e des diff&#233;rents
ensembles dans l&#8217;arbre en commen&#231;ant par la partie la plus basse. Ce mode de calcul permet
de consid&#233;rer de fa&#231;on pr&#233;pond&#233;rante le genre sur les autres termes de la d&#233;finition et de fa&#231;on
plus g&#233;n&#233;rale les t&#234;tes sur leurs d&#233;pendants syntaxiques. La figure 1 synth&#233;tise ce calcul. Aucun
pr&#233;dicat n&#8217;&#233;tant dans l&#8217;ensemble x3, il n&#8217;appara&#238;t pas sur le sch&#233;ma.
</p>
<p>!&quot;#$%&amp;'((
</p>
<p>$)!*#+',,
</p>
<p>&amp;$-*'./*0
</p>
<p>#&quot;&amp;&quot;)1',,
</p>
<p>&quot;23%)$!*4'((
56
</p>
<p>$)'7,
</p>
<p>.8569:;:.8#&quot;&amp;&quot;)19:&#8853;:0&lt;6:.8&quot;23%)$!*49
</p>
<p>.8509:;:.8$)!*#+9:&#8853;:0&lt;6:.8!&quot;#$%&amp;9
</p>
<p>.8*09:;:.8&amp;$-*9
</p>
<p>&#8853;
</p>
<p>&#8853;
</p>
<p>FIG. 1 &#8211; Construction du vecteur conceptuel de la d&#233;finition de fourmi
</p>
<p>3Par exemple, pour une d&#233;finition aristot&#233;licienne (en genre et diff&#233;rences), si le genre a un sens qui est aussi
un hyperonyme du synset d&#233;fini, on consid&#232;re que ce sens est celui utilis&#233; dans la d&#233;finition.
</p>
<p>299</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Didier SCHWAB, Lim LIAN TZE, Mathieu LAFOURCADE
</p>
<p>5.2 Exploitation des relations
</p>
<p>L&#8217;exploitation des relations se fait &#224; deux niveaux : (1) pour la construction des vecteurs,
elles permettent de fabriquer de mani&#232;re compl&#233;mentaire aux d&#233;finitions le vecteur d&#8217;un syn-
set ; (2) pour &#233;viter les ph&#233;nom&#232;nes de regroupement d&#8217;ensembles distincts.
</p>
<p>5.2.1 Construction des vecteurs
</p>
<p>La construction d&#8217;un vecteur conceptuel est effectu&#233;e pour chaque n&#339;ud du r&#233;seau par simple
somme pond&#233;r&#233;e des vecteurs des n&#339;uds reli&#233;s. Soit un n&#339;ud N reli&#233; a k n&#339;uds N1 . . . Nk, le
vecteur de N , V (N) sera &#233;gal &#224; p1V (N1) + p2V (N2) + . . . + pkV (Nk) o&#249; pi est le poids du
i-&#232;me n&#339;ud. Le vecteur somme est ensuite normalis&#233;.
</p>
<p>Cette approche entra&#238;ne naturellement une agglom&#233;ration des vecteurs. Il est donc n&#233;cessaire
d&#8217;augmenter le contraste d&#8217;un vecteur &#224; la suite de son calcul. Pour ce faire, on calcule le co-
efficient de variation4 de V. Si ce dernier ne se situe pas a 10% du CV moyen alors le vecteur
subit une op&#233;ration non lin&#233;aire d&#8217;amplification (la mise &#224; une puissance n de chaque compo-
sante puis normalisation), et ce de fa&#231;on it&#233;r&#233;e jusqu&#8217;&#224; l&#8217;obtention d&#8217;un coefficient de variation
dans la fourchette acceptable. Cette derni&#232;re a &#233;t&#233; estim&#233;e &#224; partir des valeurs obtenues dans les
exp&#233;riences avec concepts pr&#233;d&#233;finis.
</p>
<p>5.2.2 Probl&#232;me du regroupement d&#8217;ensembles distincts
</p>
<p>Un dernier probl&#232;me potentiel est que les vecteurs de deux ensembles distincts (&#224; la fois au sens
du r&#233;seau lexical et de la th&#233;matique) de termes peuvent occuper la m&#234;me r&#233;gion de l&#8217;espace.
L&#8217;approche du calcul se faisant par activation et les vecteurs &#233;tant tir&#233;s au hasard &#224; l&#8217;initialisation
rien n&#8217;emp&#234;che que cela se produise par accident. Il est donc n&#233;cessaire de &quot;s&#233;parer&quot; les vecteurs
proches mais correspondant pourtant &#224; des parties tr&#232;s diff&#233;rentes du r&#233;seau lexical et de la
th&#233;matique.
</p>
<p>La d&#233;tection de ce ph&#233;nom&#232;ne se fait par scrutation du voisinage d&#8217;un vecteur conceptuel. Si
parmi ses n premiers voisins, la densit&#233; de mots n&#8217;ayant rien &#224; voir avec le mot &#233;tudi&#233; est
importante alors une action de s&#233;paration doit &#234;tre entreprise.
</p>
<p>Cette action de s&#233;paration consiste &#224; plonger l&#8217;ensemble du r&#233;seau dans un champs o&#249; les n&#339;uds
ont tendance &#224; se repousser. En s&#8217;inspirant directement de la physique, une force de r&#233;pulsion
en 1/d2 est calcul&#233;e it&#233;rativement entre les n&#339;uds. Pour un n&#339;ud donn&#233;, on peut ainsi calculer
un vecteur d&#233;placement qui va l&#8217;&#233;loigner des n&#339;uds dont il se trouve trop pr&#232;s. Les n&#339;uds ne se
rapprochant pas par voisinage th&#233;matique (lors de la premi&#232;re phase du calcul) mais se trouvant
proches &#8220;par accident&#8221; finissent ainsi naturellement par se s&#233;parer.
</p>
<p>4Le coefficient de variation CV est donn&#233; par la formule EC(V )&#181;(V ) avec EC(V) l&#8217;&#233;cart type du vecteur V et &#181;(V )
la moyenne arithm&#233;tique des composantes de V.
</p>
<p>300</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Compl&#233;mentarit&#233; des r&#233;seaux lexicaux et des vecteurs conceptuels
</p>
<p>6 Conclusion
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; les vecteurs conceptuels construits par &#233;mergence. Nous
avons montr&#233; en quoi ils peuvent aider &#224; r&#233;soudre le &#171; probl&#232;me du tennis &#187; de par leur carac-
t&#232;re compl&#233;mentaire aux r&#233;seaux lexico-s&#233;mantiques dont l&#8217;exemple le plus courant dans les
recherches actuelles est WordNet. En effet, le rappel des r&#233;seaux est faible, ils ne permettent
pas facilement de repr&#233;senter le champs s&#233;mantique contrairement aux vecteurs tandis que ces
derniers ne sont pas suffisants pour repr&#233;senter des relations comme l&#8217;hyperonymie ou la m&#233;ro-
nymie.
</p>
<p>Notre proposition est de tirer profit de cette compl&#233;mentarit&#233; en ajoutant &#224;WordNet des vecteurs
conceptuels construits &#224; partir des d&#233;finitions et des relations contenues dans cette base. La
m&#233;thode propos&#233;e ici tient du domaine du continu contrairement &#224; l&#8217;ensemble des m&#233;thodes
que nous avons &#233;tudi&#233;es dans la litt&#233;rature qui, elles, font partie du domaine du discret (ajout
d&#8217;arcs pour les relations, de symboles sur le domaine, etc.).
</p>
<p>Nous avons conscience que cette m&#233;thode ne permet seulement que de r&#233;soudre une partie du
&#171; probl&#232;me du tennis &#187;. En effet, les vecteurs conceptuels ne permettent pas d&#8217;exhiber les rap-
ports collocationnels non-th&#233;matiques entre items. Il s&#8217;agit essentiellement des relations qu&#8217;Igor
Mel&#8217;c&#780;uk mod&#233;lise avec ses fonctions lexicales syntagmatiques (Mel&#8217;c&#780;uk et al., 1995) comme
l&#8217;intensification (&#171; peur bleue &#187; ;Magn (&#8618;peur&#8617;) = &#8618;bleue&#8617;)), la d&#233;gradation (&#171; lait tourne &#187; ;
Degrad (&#8618;lait&#8617;) = &#8618;tourner&#8617;) ou bien encore le confirmateur (&#171; argument valable &#187; ; Ver (&#8618;ar-
gument&#8617;) = &#8618;valable&#8617;). Comme le remarque (Ferret &amp; Zock, 2006), ces relations font partie de
celles qu&#8217;il faudrait vraisemblablement avoir dans une base lexicale. Nous partageons ce point
de vue, certaines pistes ont &#233;t&#233; explor&#233;es dans (Schwab, 2005) et continuent &#224; l&#8217;&#234;tre actuelle-
ment.
</p>
<p>R&#233;f&#233;rences
E. AGIRRE, O. ANSA, D. MARTINEZ, et E. HOVY. &#171; Enriching WordNet concepts with topic
signatures &#187;. Dans les actes de NAACL worshop on WordNet and Other Lexical Resources :
Applications, Extensions and Customizations, Pittsburg, USA, 2001.
</p>
<p>Romaric BESAN&#199;ON. &#171; Int&#233;gration de connaissances syntaxiques et s&#233;mantiques dans les
repr&#233;sentations vectorielles de texte &#187;. Th&#232;se de doctorat, &#201;cole Polytechnique F&#233;d&#233;rale de
Lausanne, Laboratoire d&#8217;Intelligence Artificielle, 2001.
</p>
<p>Christiane FELLBAUM, . WordNet : An Electronic Lexical Database. The MIT Press, 1988.
</p>
<p>Olivier FERRET et Michael ZOCK. &#171; Enhancing Electronic Dictionaries with an Index Based
on Associations &#187;. Dans les actes de Proceedings of the 21st International Conference on
Computational Linguistics, pp 281&#8211;288, 2006. Association for Computational Linguistics.
</p>
<p>Sanda HARABAGIU et Joyce Yue CHAI, . Usage of WordNet in Natural Language Processing
Systems, Universit&#233; de Montr&#233;al, Montr&#233;al, Canada, 1998.
</p>
<p>Sanda M. HARABAGIU, George Armitage MILLER, et Dan I. MOLDOVAN. &#171; WordNet 2
- A Morphologically and Semantically Enhanced Resource &#187;. Dans les actes de Workshop
SIGLEX&#8217;99 : Standardizing Lexical Resources, pp 1&#8211;8, 1999.
</p>
<p>Kevin KNIGHT et Steeve LUK. &#171; Building a Large-Scale Knowledge Base for Machine Trans-
lation &#187;. Dans les actes de AAAI&#8217;1994 : National Conference on Artificial Intelligence, 1994.
</p>
<p>301</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Didier SCHWAB, Lim LIAN TZE, Mathieu LAFOURCADE
</p>
<p>Mathieu LAFOURCADE et Fr&#233;d&#233;ric GUINAND. &#171; Ants for Natural Language Processing &#187;.
International Journal of Computational Intelligence Research, 2006. &#192; para&#238;tre.
Mathieu LAFOURCADE et Violaine PRINCE. &#171; Mixing Semantic Networks and Conceptual
Vectors : the Case of Hyperonymy &#187;. Dans les actes de ICCI-2003 (2nd IEEE International
Conference on Cognitive Informatics), pp 121&#8211;128, 2003.
Mathieu LAFOURCADE. &#171; Conceptual Vector Learning - Comparing Bootstrapping from a
Thesaurus or Induction by Emergence &#187;. Dans les actes de LREC&#8217;2006, 2006.
LAROUSSE, . Th&#233;saurus Larousse - des id&#233;es aux mots, des mots aux id&#233;es. Larousse, 1992.
Mathieu MANGEOT-LEREBOURS, Gilles S&#201;RASSET, et Mathieu LAFOURCADE. &#171; Construc-
tion collaborative d&#8217;une base lexicale multilingue : Le projet Papillon &#187;. TAL (Traitement
Automatique des langues) : Les dictionnaires &#233;lectroniques, pp 151&#8211;176, 2003.
Igor MEL&#8217;C&#780;UK, Andr&#233; CLAS, et Alain POLGU&#200;RE. Introduction &#224; la lexicologie explicative
et combinatoire. Duculot, 1995.
Rada MIHALCEA et Dan MOLDOVAN. &#171; eXtended Wordnet : progress report &#187;. Dans les
actes de NAACL 2001 - Workshop on WordNet and Other Lexical Resources, Pittsburgh, USA,
2001.
Rada MIHALCEA, Paul TARAU, et Elizabeth FIGA. &#171; PageRank on Semantic Networks, with
Application toWord Sense Disambiguation &#187;. Dans les actes de COLING&#8217;2004 : 20th Inter-
national Conference on Computational Linguistics, pp 1126&#8211;1132, 2004.
Ross QUILLIAN. &#171; Semantic Informatic processing &#187;, Chapitre Semantic memory, pp 227&#8211;
270. MIT Press, 1968.
Fran&#231;ois RASTIER. &#171; L&#8217;isotopie s&#233;mantique, du mot au texte &#187;. Th&#232;se de doctorat d&#8217;&#201;tat,
Universit&#233; de Paris-Sorbonne, 1985.
Didier SCHWAB. &#171; Approche hybride - lexicale et th&#233;matique - pour la mod&#233;lisation, la d&#233;tec-
tion et l&#8217;exploitation des fonctions lexicales en vue de l&#8217;analyse s&#233;mantique de texte. &#187;. Th&#232;se
de doctorat, Universit&#233; Montpellier 2, 2005.
Didier SCHWAB, Mathieu LAFOURCADE, et Violaine PRINCE. &#171; Vers l&#8217;apprentissage automa-
tique, pour et par les vecteurs conceptuels, de fonctions lexicales. L&#8217;exemple de l&#8217;antonymie
&#187;. Dans les actes de TALN 2002, volume 1, pp 125&#8211;134, 2002.
Mark STEVENSON. &#171; Augmenting Noun Taxonomies by Combining Lexical Similarity Me-
trics &#187;. Dans les actes de COLING&#8217;2002 : 19th International Conference on Computational
Linguistics, volume 2/2, pp 953&#8211;959, 2002.
Michael ZOCK. &#171; Sorry, What Was Your Name Again, Or How to Overcome The Tip-Of-The
Tongue with the help of a computer ? &#187;. Dans les actes de SemaNet&#8217;02 : Building and Using
Semantic Networks, Taipei, Taiwan, 2002.
</p>
<p>302</p>

</div></div>
</body></html>