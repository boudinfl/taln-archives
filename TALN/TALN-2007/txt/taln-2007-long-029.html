<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Confondre le coupable : corrections d&#8217;un lexique sugg&#233;r&#233;es par une grammaire</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2007, Toulouse, 5&#8211;8 juin 2007
</p>
<p>Confondre le coupable :
corrections d&#8217;un lexique sugg&#233;r&#233;es par une grammaire
</p>
<p>Lionel NICOLAS1, Jacques FARR&#201;1, &#201;ric VILLEMONTE DE LA CLERGERIE2
1 Laboratoire I3S, Universit&#233; de Nice-Sophia Antipolis, CNRS
</p>
<p>2000 route des Lucioles, B.P. 121, 06903 Sophia Antipolis Cedex, France
2 Projet ATOLL - INRIA
</p>
<p>Domaine de Voluceau, B.P. 105, 78153 Le Chesnay Cedex, France
{lnicolas,jf}@i3s.unice.fr,
</p>
<p>Eric.De_La_Clergerie@inria.fr
</p>
<p>R&#233;sum&#233;. Le succ&#232;s de l&#8217;analyse syntaxique d&#8217;une phrase d&#233;pend de la qualit&#233; de la gram-
maire sous-jacente mais aussi de celle du lexique utilis&#233;. Une premi&#232;re &#233;tape dans l&#8217;am&#233;lioration
des lexiques consiste &#224; identifier les entr&#233;es lexicales potentiellement erron&#233;es, par exemple en
utilisant des techniques de fouilles d&#8217;erreurs sur corpus (Sagot &amp; Villemonte de La Clergerie,
2006). Nous explorons ici l&#8217;&#233;tape suivante : la suggestion de corrections pour les entr&#233;es iden-
tifi&#233;es. Cet objectif est atteint au travers de r&#233;analyses des phrases rejet&#233;es &#224; l&#8217;&#233;tape pr&#233;c&#233;dente,
apr&#232;s modification des informations port&#233;es par les entr&#233;es suspect&#233;es. Un calcul statistique sur
les nouveaux r&#233;sultats permet ensuite de mettre en valeur les corrections les plus pertinentes.
</p>
<p>Abstract. Successful parsing depends on the quality of the underlying grammar but also
on the quality of the lexicon. A first step towards the improvement of lexica consists in iden-
tifying potentially erroneous lexical entries, for instance by using error mining techniques on
corpora (Sagot &amp; Villemonte de La Clergerie, 2006). we explores the next step, namely the
suggestion of corrections for those entries. This is achieved by parsing the sentences rejected at
the previous step anew, after modifying the information carried by the suspected entries. After-
wards, a statistical computation on the parsing results exhibits the most relevant corrections.
</p>
<p>Mots-cl&#233;s : analyse syntaxique, lexique, apprentissage, correction .
Keywords: parsing, lexicon, machine learning, correction .
</p>
<p>1 Introduction
</p>
<p>L&#8217;analyse syntaxique d&#8217;une langue repose sur l&#8217;utilisation de ressources linguistiques les plus
pr&#233;cises et correctes possibles. Obtenir des ressources poss&#233;dant une si large couverture est une
t&#226;che ardue de longue haleine qu&#8217;il est souhaitable d&#8217;all&#233;ger par le biais de techniques qui en
automatisent l&#8217;&#233;laboration et la correction. Nous pr&#233;sentons ici une technique de g&#233;n&#233;ration au-
tomatique de suggestions de corrections pour les entr&#233;es potentiellement erron&#233;es d&#8217;un lexique.
Nous nous int&#233;ressons aux moyens de r&#233;duire l&#8217;inexactitude et l&#8217;incompl&#233;tude d&#8217;un lexique
&#224; partir d&#8217;un recensement de formes lexicales suspect&#233;es d&#8217;&#234;tre incorrectement ou seulement
</p>
<p>315</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Lionel NICOLAS, Jacques FARR&#201;, &#201;ric VILLEMONTE DE LA CLERGERIE
</p>
<p>partiellement d&#233;crites dans un lexique. Nous nous situons ainsi dans le prolongement direct de
la technique de fouille d&#8217;erreurs sur des corpus de grande taille originalement propos&#233;e par (van
Noord, 2004), et am&#233;lior&#233;e par (Sagot &amp; Villemonte de La Clergerie, 2006). La pertinence de
cette derni&#232;re s&#8217;observe notamment &#224; travers nos r&#233;sultats.
Cette technique repose sur l&#8217;id&#233;e suivante : &#233;tant donn&#233; un large corpus de phrases attest&#233;es, plus
une forme (et indirectement les lemmes associ&#233;s) appara&#238;t ou n&#8217;appara&#238;t pas dans des phrases
dont les analyses &#233;chouent, plus nous avons des raisons de douter ou de ne pas douter des en-
tr&#233;es lexicales qui lui sont associ&#233;es. Cependant le contexte des formes importe : une forme est
d&#8217;autant plus suspecte qu&#8217;elle appara&#238;t dans des phrases non analysables mais en co-occurrence
avec des formes qui tendent &#224; appara&#238;tre dans des phrases analysables.
L&#8217;impl&#233;mentation de la technique de fouilles d&#8217;erreurs nous a fourni une liste de 5344 formes
suspectes avec, pour chaque forme f , un taux de suspicion et une liste de phrases non analy-
sables (56089 au total) o&#249; f est suspect&#233;e d&#8217;&#234;tre &#224; l&#8217;origine de l&#8217;&#233;chec des analyses. Si une
forme est effectivement responsable de ces &#233;checs, et non la grammaire1, c&#8217;est donc que les
informations lexicales qui lui sont associ&#233;es sont incompl&#232;tes ou inexactes (voir inexistantes).
En rel&#226;chant les contraintes sur les informations port&#233;es par une forme suspecte ou en les mo-
difiant (notamment la cat&#233;gorie syntaxique), de nouvelles analyses des phrases associ&#233;es vont
aboutir. Les repr&#233;sentations des phrases alors produites repr&#233;sentent les conditions dans les-
quelles l&#8217;analyse a r&#233;ussi, c.a.d. les informations sur la forme suspecte rendant possible l&#8217;ana-
lyse. En examinant ces informations sur un ensemble de phrases, il est alors possible de d&#233;gager
des hypoth&#232;ses de correction utiles.
La technique pr&#233;sent&#233;e est ind&#233;pendante du langage &#233;tudi&#233;.
Travaux relatifs. L&#8217;acquisition de connaissances linguistiques depuis des corpus bruts (i.e.
non annot&#233;s) par le biais de connaissances grammaticales a &#233;t&#233; initialement &#233;tudi&#233;e par (Brent,
1993) afin d&#8217;identifier les cadres syntaxiques des verbes en anglais. (Horiguchi et al., 1995)
utilisent les r&#233;sultats d&#8217;analyse fournis par un syst&#232;me HPSG afin d&#8217;acqu&#233;rir des entr&#233;es lexi-
cales de mots japonais inconnus. Enfin, mentionnons la reconstitution d&#8217;informations lexicales
manquantes en vue d&#8217;analyses robustes (Grover &amp; Lascarides, 2001), (Crysmann et al., 2002).
Nous commen&#231;ons par expliquer comment g&#233;n&#233;rer des hypoth&#232;ses de correction (Sect. 2) et
comment les trier (Sect. 3). Nous introduisons ensuite la notion de synchronisation entre un
lexique et une grammaire (Sect. 4), juste avant d&#8217;exposer les r&#233;sultats obtenus (Sect. 5) et les
d&#233;veloppements futurs (Sect. 6).
</p>
<p>2 G&#233;n&#233;ration d&#8217;hypoth&#232;ses
</p>
<p>Le principal but d&#8217;un analyseur syntaxique est de v&#233;rifier la validit&#233; syntaxique d&#8217;une phrase et
d&#8217;en produire une ou plusieurs repr&#233;sentations. On souhaite en g&#233;n&#233;ral &#233;viter la surg&#233;n&#233;ration
des repr&#233;sentations issues d&#8217;une analyse en produisant le moins possible de repr&#233;sentations.
Une phrase est qualifi&#233;e d&#8217;ambigu&#235; pour un analyseur lorsque celui-ci lui associe plusieurs
interpr&#233;tations. Ceci arrive principalement lorsque la phrase est intrins&#232;quement ambigu&#235;, i.e.
d&#8217;autres informations (tel que le contexte s&#233;mantique) sont n&#233;cessaires afin de filtrer les inter-
</p>
<p>1Nous supposons que les erreurs dues &#224; un traitement incorrect en amont du processus d&#8217;analyse proprement
dit (segmentation, ponctuation, d&#233;tection d&#8217;entit&#233;s nomm&#233;es, . . .) ont &#233;t&#233; identifi&#233;es. Les formes erron&#233;es et leurs
phrases associ&#233;es qui r&#233;sulteraient de telles erreurs sont donc exclues de celles qui nous int&#233;ressent ici.
</p>
<p>316</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Confondre le coupable : corrections d&#8217;un lexique sugg&#233;r&#233;es par une grammaire
</p>
<p>pr&#233;tations, ou lorsque les ressources utilis&#233;es (lexique, grammaire . . .) ne sont pas assez restric-
tives et acceptent un langage plus large.
</p>
<p>Afin de rejeter les phrases n&#8217;appartenant pas &#224; la langue, on souhaite disposer d&#8217;un lexique le
plus pr&#233;cis et d&#233;taill&#233; possible. En effet, plus une forme lexicale est sp&#233;cifi&#233;e, moins elle se
combine avec les autres constituants de la phrase, et par cons&#233;quent, moins elle permet d&#8217;inter-
pr&#233;tations incorrectes.
</p>
<p>2.1 Causes d&#8217;&#233;chec d&#8217;une analyse
</p>
<p>Chaque forme poss&#232;de, &#224; travers ses lemmes, diff&#233;rentes informations pouvant &#234;tre regroup&#233;es
en deux ensembles : d&#8217;une part la cat&#233;gorie syntaxique (nom, verbe, adjectif, . . .), d&#8217;autre part
les informations morphologiques (nombre, genre, personne, temps, mode, . . .) et syntaxiques
(valence, facultativit&#233; des arguments, r&#233;flexivit&#233;, passivation, . . .). L&#8217;&#233;chec d&#8217;une analyse &#224; cause
d&#8217;une forme est la cons&#233;quence d&#8217;un probl&#232;me touchant &#224; au moins un de ces ensembles.
</p>
<p>2.1.1 D&#233;faut de cat&#233;gorisation
</p>
<p>Une forme peut &#234;tre associ&#233;e &#224; plusieurs lemmes (homonymes) avec des cat&#233;gories syntaxiques
distinctes. Le traitement de telles formes ambigu&#235;s au sein d&#8217;une phrase se g&#232;re par le passage
d&#8217;un treillis de mots (ou DAG) &#224; l&#8217;analyseur syntaxique (Sagot &amp; Boullier, 2005). Une analyse
syntaxique r&#233;ussie valide au moins un chemin possible de lecture dans ce treillis.
Cependant, un lexique peut ne pas recenser tous les homonymes d&#8217;une forme et induire ainsi
des &#233;checs d&#8217;analyse. Par exemple, la forme &#171; fiche &#187; d&#233;note un nom commun et une flexion du
verbe &#171; ficher &#187; . S&#8217;il n&#8217;existe aucun lemme associ&#233; de cat&#233;gorie nom-commun, la phrase &#171; Ma
fiche contient une erreur. &#187; sera repr&#233;sent&#233;e par une seule s&#233;quence de cat&#233;gories ma/pronom-
possessif fiche/verbe contient/verbe une/det erreur/nom-commun. &#192; moins qu&#8217;une production
grammaticale n&#8217;accepte une telle construction, son analyse devrait aboutir &#224; un &#233;chec.
</p>
<p>2.1.2 Sur-sp&#233;cification
</p>
<p>En g&#233;n&#233;ral, on associe aux r&#232;gles de grammaire des d&#233;corations, exprim&#233;es sous formes de
structures de traits et charg&#233;es de compl&#233;ter les v&#233;rifications amorc&#233;es par le squelette syn-
taxique d&#8217;une production grammaticale (Abeill&#233;, 1993). Par exemple, un squelette v&#233;rifie la
pr&#233;sence d&#8217;un groupe nominal sujet et d&#8217;un verbe dans une phrase l&#224; ou les d&#233;corations en
v&#233;rifient l&#8217;accord (m&#234;me personne, nombre, et &#233;ventuellement genre).
Comme nous l&#8217;avons expliqu&#233;, il est souhaitable que les formes lexicales soient les plus sp&#233;ci-
fi&#233;es possible afin de r&#233;duire les ambigu&#239;t&#233;s. En revanche, si ces derni&#232;res sont trop restrictives
(autrement dit sur-sp&#233;cifi&#233;es), certaines analyses &#233;chouent &#224; cause du m&#233;canisme d&#8217;unification
des d&#233;corations de la grammaire et des restrictions d&#8217;utilisation des entr&#233;es lexicales.
Il est par exemple tr&#232;s difficile de renseigner un verbe sur l&#8217;ensemble de ses emplois pos-
sibles, du fait de la polys&#233;mie, de la facultativit&#233; de certains arguments, de possibles alternations
(&#171; acheter qchose &#187; donnant &#171; qchose s&#8217;ach&#232;te &#187; ), et de multiples r&#233;alisations des arguments
(&#171; aimer qchose &#187; , &#171; aimer que + S &#187; , &#171; aimer Sinf &#187; ). Il arrive donc que l&#8217;on consid&#232;re comme
obligatoires des aspects qui ne sont que facultatifs dans certains cas. Ce constat s&#8217;&#233;tend aux
autres cat&#233;gories syntaxiques d&#232;s lors qu&#8217;on leur attache des cadres de cat&#233;gorisation.
</p>
<p>317</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Lionel NICOLAS, Jacques FARR&#201;, &#201;ric VILLEMONTE DE LA CLERGERIE
</p>
<p>2.2 R&#233;analyser en sous-sp&#233;cifiant
</p>
<p>Puisque seules les phrases dont l&#8217;analyse a &#233;chou&#233; sont conserv&#233;es durant l&#8217;&#233;tape de fouille
d&#8217;erreurs, leur taux d&#8217;analyse est nul. Si une modification des informations lexicales port&#233;es par
une forme suspecte f permet d&#8217;augmenter sensiblement le taux de r&#233;analyse des phrases qui
lui sont associ&#233;es, il est raisonnable de penser que le probl&#232;me est bien li&#233; &#224; f . La difficult&#233;
est alors de trouver quelles modifications permettent des augmentations sensibles. Plut&#244;t que
de tester toutes les combinaisons de modifications possibles, ce qui est exponentiel, nous nous
reposons sur la capacit&#233; de notre analyseur &#224; pouvoir g&#233;rer des formes sous-sp&#233;cifi&#233;es.
Une fois obtenus de nouveaux r&#233;sultats d&#8217;analyse, nous sommes en mesure d&#8217;en extraire des
hypoth&#232;ses de correction (voir Sect. 2.2.2).
</p>
<p>2.2.1 G&#233;n&#233;ration et utilisation de jokers
</p>
<p>Afin de rendre analysables des phrases qui ne l&#8217;&#233;taient initialement pas, nous introduisons &#224;
la place des formes lexicales suspectes des formes sous-sp&#233;cifi&#233;es appel&#233;es jokers. Dans l&#8217;ap-
proche actuelle (qui demande &#224; &#234;tre affin&#233;e), elles ne poss&#232;dent qu&#8217;une cat&#233;gorie syntaxique
(parmi les cat&#233;gories &#171; ouvertes &#187; : verbe, nom commun, adjectif ou adverbe). Elles n&#8217;ont donc
aucune information morphologique ou syntaxique fixe et remplissent toujours les conditions
fix&#233;es par les d&#233;corations des productions grammaticales. Puisque leur utilisation ne soul&#232;ve
aucun conflit lors des analyses (except&#233; pour la cat&#233;gorie syntaxique), les substituer &#224; une forme
suspecte dans une phrase rejet&#233;e favorise la r&#233;ussite de son analyse. Cependant, cela peut intro-
duire une certaine ambigu&#239;t&#233; car il n&#8217;y a plus de filtrage au niveau des d&#233;corations.
&#201;tant donn&#233; que nous ne pouvons savoir a priori quel type d&#8217;erreur (sur-sp&#233;cification ou d&#233;faut
de cat&#233;gorisation) est responsable des &#233;checs d&#8217;analyse, nous consid&#233;rons les deux simultan&#233;-
ment au moment de g&#233;n&#233;rer les jokers.
Pour envisager une sur-sp&#233;cification, nous rempla&#231;ons une forme de cat&#233;gorie X par un joker
de m&#234;me cat&#233;gorie X . Les caract&#233;ristiques permettent alors d&#8217;explorer les m&#234;mes productions
grammaticales que pour la phrase initiale, sans pour autant &#234;tre arr&#234;t&#233; par les d&#233;corations.
Pour faire face &#224; un d&#233;faut de cat&#233;gorisation d&#8217;une forme f , nous cr&#233;ons des jokers avec des
cat&#233;gories syntaxiques diff&#233;rentes de celles initialement recens&#233;es pour f . En proc&#233;dant ainsi,
les r&#233;analyses exploreront d&#8217;autres productions. Ces jokers sont g&#233;n&#233;r&#233;s &#224; partir des informa-
tions fournies par un lemmatiseur (stemmer) ou par un tagger probabiliste tel que TREETAGGER
(Schmid, 1999).
Nous aurions pu utiliser un joker unique ne poss&#233;dant m&#234;me pas de cat&#233;gorie syntaxique et
permettant de couvrir &#224; lui seul l&#8217;ensemble des situations d&#233;crites ci-dessus. Cependant, un
tel joker introduit une tr&#232;s forte ambigu&#239;t&#233;, aboutissant soit &#224; un &#233;chec des analyses par limite
de temps ou de m&#233;moire, soit &#224; la surg&#233;n&#233;ration de repr&#233;sentations pour une phrase. Dans le
premier cas, nous ne collectons aucune donn&#233;e, dans le second cas, le volume de donn&#233;es est
trop important pour &#234;tre correctement tri&#233; et valoris&#233;. Notre approche permet (en grande partie)
d&#8217;&#233;carter ces probl&#232;mes tout en &#233;vitant de multiplier le nombre de jokers par forme suspecte.
Nous avons test&#233; une moyenne de 2.05 jokers par forme suspecte (10978 au total), donnant lieu
&#224; 117655 nouvelles analyses.
</p>
<p>318</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Confondre le coupable : corrections d&#8217;un lexique sugg&#233;r&#233;es par une grammaire
</p>
<p>det
N
</p>
<p>Nc2
_ :comp
</p>
<p>N2
La
</p>
<p>la :det est :nc
subject
</p>
<p>comp
</p>
<p>vie est :adj
</p>
<p>&#234;tre :v beau :adj
</p>
<p>belle :nc
</p>
<p>est belle
</p>
<p>comp
N
</p>
<p>vie :nc
</p>
<p>FIG. 1 &#8211; Extrait de la repr&#233;sentation graphique d&#8217;une for&#234;t partag&#233;es de d&#233;pendances
</p>
<p>2.2.2 Extraction de signatures syntaxiques
</p>
<p>Si une forme suspecte a &#233;t&#233; correctement identifi&#233;e, son remplacement par des jokers dans les
phrases qui lui sont associ&#233;es permet &#224; certaines analyses de r&#233;ussir. Dans les faits, on observe
une relation nette entre le taux de succ&#232;s de l&#8217;analyse des phrases modifi&#233;es et le taux de suspi-
cion de la forme concern&#233;e.
Notre analyseur renvoie l&#8217;ensemble des interpr&#233;tations possibles d&#8217;une phrase sous la forme
d&#8217;une for&#234;t partag&#233;e de d&#233;pendances (Fig. 1) o&#249; les n&#339;uds repr&#233;sentent les lemmes et les arcs
les d&#233;pendances syntaxiques entre les lemmes. Chaque n&#339;ud poss&#232;de des informations relatives
au lemme et &#224; la production grammaticale ancr&#233;e (dans le cadre d&#8217;une grammaire lexicalis&#233;e).
Chaque d&#233;pendance est caract&#233;ris&#233;e par un n&#339;ud gouverneur source, un n&#339;ud gouvern&#233; cible,
une nature et un label qui d&#233;pend de la grammaire. Ce label d&#233;note souvent (mais malheu-
reusement pas toujours) la fonction syntaxique de la cible (sujet, objet, . . .). Afin de g&#233;rer les
ambigu&#239;t&#233;s, des informations compl&#233;mentaires locales au n&#339;ud gouverneur lient les lemmes et
les d&#233;pendances &#224; une ou plusieurs interpr&#233;tations. Ainsi, la repr&#233;sentation issue de l&#8217;analyse
de la phrase pour &#171; La vie est belle &#187; (Fig. 1) donne lieu &#224; quatre lectures possibles, du fait (a)
de l&#8217;ambigu&#239;t&#233; de &#171; est &#187; comme verbe &#224; copule, nom commun (en apposition de &#171; vie &#187; ) et
adjectif ainsi que (b) de l&#8217;ambigu&#239;t&#233; de &#171; belle &#187; entre adjectif et nom.
Sans aucune information suppl&#233;mentaire, les deux interpr&#233;tations comme nom et adjectif de
&#171; est &#187; auraient d&#251; &#234;tre rejet&#233;es car introduisant une apposition rare et/ou construisant une
phrase sans verbe.
Les for&#234;ts contiennent donc les d&#233;pendances entrantes et sortantes depuis et vers un joker. Nous
appelons d&#233;sormais signature syntaxique l&#8217;ensemble de d&#233;pendances autour d&#8217;un joker dans
une interpr&#233;tation particuli&#232;re et groupe de signatures l&#8217;ensemble des signatures syntaxiques
possibles extraites des interpr&#233;tations obtenues par l&#8217;analyse r&#233;ussie d&#8217;une phrase.
Ces signatures repr&#233;sentent les conditions dans lesquelles l&#8217;analyse a pu aboutir, i.e. les donn&#233;es
que la grammaire aurait accept&#233; pour la forme suspecte. Du fait de l&#8217;ambigu&#239;t&#233; cons&#233;cutive &#224;
l&#8217;introduction d&#8217;un joker, un analyseur peut produire plusieurs interpr&#233;tations et donc plusieurs
signatures. Parmi ces interpr&#233;tations, une est plus proche du sens r&#233;el de la phrase que les autres.
La signature qu&#8217;elle contient poss&#232;de alors les donn&#233;es les plus pertinentes et int&#233;ressantes,
celles que nous recherchons afin de d&#233;terminer les corrections &#224; appliquer au lexique.
</p>
<p>3 Identifier les meilleures signatures
</p>
<p>En se pla&#231;ant au niveau d&#8217;un seul groupe de signatures (produit &#224; partir d&#8217;une seule phrase),
nous sommes incapables de diff&#233;rencier les signatures pertinentes de celles qui ne sont qu&#8217;une
</p>
<p>319</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Lionel NICOLAS, Jacques FARR&#201;, &#201;ric VILLEMONTE DE LA CLERGERIE
</p>
<p>cons&#233;quence de l&#8217;ambigu&#239;t&#233; introduite par le joker.
La variabilit&#233; de contexte induite par plusieurs groupes de signatures (produits &#224; partir de plu-
sieurs phrases) nous apporte une solution &#224; ce probl&#232;me. En effet, elle implique la diversification
des signatures &#171; parasites &#187; qui contraste avec la stabilit&#233; des signatures pertinentes repr&#233;sentant
le(s) sens r&#233;el(s) de la forme.
Une r&#233;p&#233;tition bien marqu&#233;e de certaines signatures sur l&#8217;ensemble des phrases sugg&#232;re alors un
sch&#233;ma d&#8217;utilisation attendu par la grammaire pour la forme. Afin de pouvoir l&#8217;observer, nous
valorisons/d&#233;valorisons les signatures par le biais d&#8217;un calcul statistique simple en deux &#233;tapes.
Premi&#232;re &#233;tape : distribution locale des poids entre signatures. L&#8217;int&#233;r&#234;t que nous portons
&#224; un groupe de signatures d&#233;pend de sa taille : plus il contient de signatures moins il pr&#233;sente
d&#8217;int&#233;r&#234;t. En effet, il est vraisemblable que plusieurs squelettes syntaxiques &#171; permissifs &#187; lui
correspondent, &#224; l&#8217;image de ceux permettant les diverses interpr&#233;tations illustr&#233;es par la figure 1.
Pour chaque groupe g, nous calculons donc un poids P = cn avec c une constante incluse dans
]0, 1[ (par exemple 0, 95) et n la taille du groupe.
Au niveau d&#8217;un groupe, toutes les signatures sont d&#8217;&#233;gale importance, nous r&#233;partissons donc de
mani&#232;re &#233;quitable les poids attribu&#233;s au groupe : chacune signature re&#231;oit un poids pg = Pn =
</p>
<p>cn
</p>
<p>n
qui d&#233;pend donc doublement de la taille du groupe.
</p>
<p>Seconde &#233;tape : calcul global des poids. Une fois l&#8217;&#233;tape pr&#233;c&#233;dente r&#233;alis&#233;e, nous addition-
nons les poids obtenus par une m&#234;me signature &#963; dans les diff&#233;rents groupes o&#249; elle appara&#238;t
pour calculer son score s&#963; = &#931;gpg.
</p>
<p>Les meilleures signatures, &#224; savoir celles qui se trouvent dans plusieurs groupes et dans des
groupes de petite taille, re&#231;oivent alors un score s&#963; plus &#233;lev&#233;.
</p>
<p>4 Synchronisation lexique-grammaire
</p>
<p>Cette technique permet &#224; une grammaire d&#8217;exprimer ses attentes pour les formes suspectes. Si
elle n&#8217;est pas parfaite, les repr&#233;sentations qu&#8217;elle produit ainsi que les signatures que l&#8217;on en
extrait ne le sont pas non plus. En fait, dans le cas o&#249; la grammaire est parfaite, nous pouvons
qualifier les suggestions faites par cette technique comme permettant une correction du lexique.
Dans le cas inverse, il s&#8217;agit alors d&#8217;une technique permettant de diminuer le nombre de conflits
entre une grammaire et un lexique, i.e. permettant une meilleure &#171; synchronisation &#187; entre le
lexique et la grammaire.
</p>
<p>Il est &#224; noter qu&#8217;un ensemble de signatures incorrectes repr&#233;sente une source d&#8217;informations
int&#233;ressante sur les manques et incorrections d&#8217;une grammaire.
</p>
<p>5 R&#233;sultats
</p>
<p>Le travail pr&#233;sent&#233; ici, tout comme la technique de fouille d&#8217;erreurs, est un m&#233;canisme de re-
tour sur erreurs. Ce terme d&#233;signe des m&#233;canismes r&#233;utilisant les erreurs produites par un pro-
gramme afin d&#8217;am&#233;liorer automatiquement ou semi-automatiquement sa qualit&#233;. De mani&#232;re &#224;
garantir que l&#8217;origine des erreurs produites est effectivement le programme, les donn&#233;es ana-
</p>
<p>320</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Confondre le coupable : corrections d&#8217;un lexique sugg&#233;r&#233;es par une grammaire
</p>
<p>lys&#233;es doivent &#234;tre fiables. Dans le cas pr&#233;sent, les erreurs sur lesquelles nous travaillons sont
issues d&#8217;une campagne d&#8217;analyse d&#8217;un corpus MD de 331 000 phrases extraites du Monde diplo-
matique r&#233;alis&#233;e durant la validation de la technique de fouille d&#8217;erreurs (Sagot &amp; Villemonte
de La Clergerie, 2006).
Le lexique que nous cherchons &#224; am&#233;liorer est le Lefff (Lexique des formes fl&#233;chies du fran&#231;ais)
(Sagot et al., 2006). En partie acquis automatiquement, ce lexique morpho-syntaxique &#224; large
couverture du fran&#231;ais est en constant d&#233;veloppement et poss&#232;de, &#224; l&#8217;heure actuelle, plus de
520 000 entr&#233;es. La grammaire FRMG (Thomasset &amp; Villemonte de La Clergerie, 2005) que
nous utilisons est une grammaire hybride TAG/TIG avec d&#233;corations. Elle est construite &#224; par-
tir d&#8217;une m&#233;ta-grammaire plus abstraite qui produit un ensemble de 134 arbres tr&#232;s factoris&#233;s.
Malgr&#233; son tr&#232;s faible nombre d&#8217;arbres, sa factorisation lui permet de couvrir un grand nombre
de cadres de cat&#233;gorisation pour les verbes, la passivation, les extractions (relatives, interro-
gatives, cliv&#233;es), certaines inversions du sujet, certaines constructions &#224; verbe support (&#171; faire
attention &#224; &#187; ). N&#233;anmoins, nombre de ph&#233;nom&#232;nes ne sont pas encore trait&#233;s (comme la sous-
cat&#233;gorisation sur les adjectifs et les noms). La grammaire FRMG coupl&#233;e &#224; Lefff assurait en
2005 une couverture de l&#8217;ordre de 41% sur le corpus MD.
</p>
<p> 5
</p>
<p> 10
</p>
<p> 15
</p>
<p> 20
</p>
<p> 25
</p>
<p> 30
</p>
<p> 35
</p>
<p> 40
</p>
<p> 45
</p>
<p> 50
</p>
<p> 55
</p>
<p> 0  10  20  30  40  50  60  70  80
</p>
<p>FIG. 2 &#8211; Taux de r&#233;ussite des r&#233;analyses (axe Y) en fonction des taux de suspicion (axe X)
</p>
<p>5.1 Exactitude de la d&#233;tection automatique des formes suspectes
</p>
<p>La courbe de la figure 2 nous permet d&#8217;observer une corr&#233;lation tr&#232;s nette entre les taux de r&#233;us-
site des r&#233;analyses et les taux de suspicion des formes. Cela atteste la validit&#233; des informations
produites par l&#8217;&#233;tape pr&#233;c&#233;dente de fouille d&#8217;erreurs.
Les valeurs pr&#233;sent&#233;es par cette courbe sont en r&#233;alit&#233; des moyennes calcul&#233;es apr&#232;s un regrou-
pement des formes suspectes par intervalle de taux de suspicion. Sans cela, la courbe pr&#233;sente
des variations rendant difficile son observation.
Ces variations s&#8217;expliquent principalement par le fait que certaines formes ont &#233;t&#233; suspect&#233;es &#224;
la place de la grammaire ce qui explique que leur &#233;change avec des jokers n&#8217;ait rien apport&#233;. En
effet, certaines formes ont une affinit&#233; marqu&#233;e pour des constructions sp&#233;cifiques ; par exemple
une inversion du sujet en pr&#233;sence de l&#8217;adjectif &#8217;rare&#8217; comme dans &#171; Rares sont ceux qui tentent
</p>
<p>321</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Lionel NICOLAS, Jacques FARR&#201;, &#201;ric VILLEMONTE DE LA CLERGERIE
</p>
<p>d&#8217;en sortir. &#187; ou &#8217;nombreux&#8217; dans &#171; Nombreux sont ceux qui refusent. &#187; 2. Ces formes ont alors
pay&#233; cette affinit&#233; par une suspicion injustement &#233;lev&#233;e &#224; leur &#233;gard.
Une autre raison moins importante expliquant ces variations est que l&#8217;utilisation de jokers aug-
mente sensiblement le taux de timeout pour les phrases, et cela m&#234;me en ayant impos&#233; une
limite de 40 mots sur la longueur des phrases analys&#233;es.
Puisque ces deux ph&#233;nom&#232;nes s&#8217;observent &#224; tous les niveaux de taux de suspicion, le regroupe-
ment des valeurs par intervalle a permis d&#8217;en diminuer l&#8217;influence sur la courbe de la figure 2.
Toujours dans une optique de retour sur erreurs, notons qu&#8217;il est tentant de voir les phrases des
suspects forts avec de faibles taux de r&#233;analyse comme indiquant des manques de la grammaire.
Il serait alors int&#233;ressant de les analyser au moyen d&#8217;un syst&#232;me d&#8217;inf&#233;rence grammaticale.
</p>
<p>5.2 &#201;valuation de la qualit&#233; des signatures
Afin d&#8217;&#233;valuer la qualit&#233; des signatures produites, nous avons ordonn&#233; les formes suspectes en
accord avec le calcul suivant : Mf = Sf .ln(NSf ), Sf &#233;tant le taux de suspicion d&#8217;une forme
et NSf le nombre de phrases associ&#233;es3. Nous avons ensuite examin&#233; nombre d&#8217;entre elles
&#224; travers une interface Web (Fig. 3) nous permettant d&#8217;acc&#233;der, pour chaque forme, aux jokers
test&#233;s, aux taux de r&#233;analyses obtenus, aux phrases test&#233;es et aux meilleures signatures retenues.
De m&#234;me, elle nous permet de laisser des commentaires et de soumettre des requ&#234;tes au lexique
et &#224; l&#8217;analyseur. &#192; terme, cette interface a vocation &#224; &#234;tre utilis&#233;e par des linguistes.
</p>
<p>FIG. 3 &#8211; Interface d&#8217;exploration des signatures
</p>
<p>Lors de l&#8217;&#233;tude des meilleures signatures, certains doutes ont &#233;t&#233; confirm&#233;s : notre technique
manque de maturit&#233;. Nous avons identifi&#233; un certain nombre de ph&#233;nom&#232;nes nous emp&#234;chant
de correctement quantifier la qualit&#233; des signatures. Cependant, nous savons d&#233;j&#224; comment faire
face &#224; la plupart (voir Sect 6).
</p>
<p>2Ces exemples refl&#232;tent aussi le style recherch&#233; du corpus journalistique &#233;tudi&#233; !
3Un fort taux de r&#233;analyse sur un nombre r&#233;duit de phrases est peu significatif.
</p>
<p>322</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Confondre le coupable : corrections d&#8217;un lexique sugg&#233;r&#233;es par une grammaire
</p>
<p>Toutefois, dans bien des cas, nous avons obtenu des r&#233;sultats pertinents et instructifs qui nous
ont permis d&#8217;am&#233;liorer nos outils (et pas seulement notre lexique). Par exemple, on retrouve
la bonne signature comme dans le cas de &#171; prosp&#232;res &#187; o&#249; l&#8217;on retrouve un usage d&#8217;adjectif
&#233;pith&#232;te (joker + signature), alors qu&#8217;il n&#8217;existe que comme verbe dans Lefff. Pour la forme
verbale &#171; r&#233;v&#233;ler &#187; , les hypoth&#232;ses font ressortir qu&#8217;elle attend bien un argument attributif (&#171; ce
choix pourrait se r&#233;v&#233;ler catastrophique. &#187; ) mais qu&#8217;il lui manque le c&#244;t&#233; r&#233;flexif, &#224; cause de
constructions pr&#233;positionnelles comme &#171; contraint de r&#233;v&#233;ler X &#187; ou &#171; penser &#224; r&#233;v&#233;ler X &#187; .
Bien que devant encore m&#251;rir, notre approche s&#8217;est montr&#233;e viable. Nous continuerons &#224; la d&#233;ve-
lopper afin d&#8217;obtenir un outil pleinement fonctionnel. L&#8217;ach&#232;vement de certaines am&#233;liorations
donnera notamment lieu &#224; de nouvelles campagnes de calcul.
</p>
<p>6 D&#233;veloppements futurs
</p>
<p>Durant nos exp&#233;riences, nous avons pu &#233;tablir une liste de probl&#232;mes &#224; traiter et des solutions
pour les r&#233;soudre :
&#8211; Il est tr&#232;s fr&#233;quent de pouvoir appliquer plusieurs productions grammaticales &#224; une suite de
</p>
<p>formes, surtout si la cat&#233;gorie syntaxique d&#8217;une de ces formes varie (comme pour les jokers).
Cependant, ces productions n&#8217;ont pas les m&#234;mes fr&#233;quences d&#8217;utilisations et par cons&#233;quent,
les signatures qui en r&#233;sultent ne repr&#233;sentent pas la m&#234;me quantit&#233; d&#8217;information utile. De
telles donn&#233;es sur les fr&#233;quences d&#8217;utilisation nous seraient utiles afin de pond&#233;rer les signa-
tures et de diminuer l&#8217;ing&#233;rence de signatures &#171; parasites &#187; dans les r&#233;sultats.
</p>
<p>&#8211; Les signatures doivent &#234;tre nettoy&#233;es pour &#233;liminer l&#8217;adjonction de certains adjoints (gouver-
n&#233;s par les suspects) qui ne sont pas primordiaux pour caract&#233;riser ceux-ci. Cela nous permet-
trait de consolider des signatures actuellement s&#233;par&#233;es par des adjoints inutiles. N&#233;anmoins,
&#224; ce stade, il n&#8217;est pas toujours &#233;vident de juger de l&#8217;importance d&#8217;un adjoint.
</p>
<p>&#8211; Il nous faut regrouper les formes par famille de lemmes sous-jacents de mani&#232;re &#224; augmenter
la variabilit&#233; des contextes test&#233;s et ainsi cerner ce qu&#8217;ils ont en commun. N&#233;anmoins, il
faut garder &#224; l&#8217;esprit que certains probl&#232;mes ne se manifestent que pour quelques formes, par
exemple une mauvaise attribution de l&#8217;auxiliaire &#224; utiliser pour des participes pass&#233;s (exemple
de &#171; larv&#233; &#187; faussement list&#233; dans Lefff comme utilisant l&#8217;auxiliaire &#171; avoir &#187; ). Nous avons
aussi mentionn&#233; que, parfois, le probl&#232;me r&#233;sulte du manque dans le lexique d&#8217;un des lemmes
possibles pour une forme suspecte.
</p>
<p>&#8211; Il nous faut regrouper les signatures qui traduisent en fait un m&#234;me ph&#233;nom&#232;ne syntaxique
sous des aspects diff&#233;rents ; comme par exemple : le sujet et autres arguments verbaux ont
diverses r&#233;alisations (nominales, cliticis&#233;es, pronoms relatifs, pronoms interrogatifs), ou en-
core un verbe avec objet sous forme active et passive. Le regroupement des formes par lemme
est susceptible d&#8217;aider.
</p>
<p>&#8211; Certaines formes suspectes donnent des signatures &#233;quivalentes aux informations syntaxiques
d&#233;j&#224; pr&#233;sentes dans le lexique. Ce genre de cas implique que les signatures sont incompl&#232;tes.
&#192; l&#8217;heure actuelle, elles manquent principalement d&#8217;informations morphologiques. L&#8217;int&#233;-
gration de ces informations d&#233;j&#224; pr&#233;sentes dans les for&#234;ts de d&#233;pendances, mais non encore
exploit&#233;es, repr&#233;sente donc la prochaine &#233;tape dans l&#8217;am&#233;lioration du mod&#232;le des signatures.
</p>
<p>&#8211; Certaines formes ont &#233;t&#233; injustement suspect&#233;es &#224; cause de leur affinit&#233; avec des constructions
syntaxiques non g&#233;r&#233;es par la grammaire. L&#8217;utilisation de plusieurs analyseurs syntaxiques
avec des grammaires diff&#233;rentes durant l&#8217;&#233;tape pr&#233;alable de fouille d&#8217;erreurs permettraient
&#233;ventuellement de filtrer une partie des formes suspectes.
</p>
<p>323</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Lionel NICOLAS, Jacques FARR&#201;, &#201;ric VILLEMONTE DE LA CLERGERIE
</p>
<p>&#8211; Les signatures sont compos&#233;es d&#8217;un ensemble de d&#233;pendances syntaxiques entre les mots
et le joker dans les repr&#233;sentations g&#233;n&#233;r&#233;es d&#8217;une phrase. Ces signatures d&#233;pendent direc-
tement de la grammaire utilis&#233;e et peuvent &#234;tre difficiles &#224; comprendre pour une personne
non famili&#232;re avec ce formalisme. Un effort doit donc &#234;tre r&#233;alis&#233; pour les traduire vers une
repr&#233;sentation ind&#233;pendante de la grammaire et plus humainement compr&#233;hensible.
</p>
<p>7 Conclusion
</p>
<p>Les exp&#233;riences pr&#233;sent&#233;es confirment en premier lieu la capacit&#233; de la technique de fouille
d&#8217;erreurs &#224; identifier de bonnes formes suspectes. Leur transformation en jokers augmente le
taux de r&#233;analyses r&#233;ussies de mani&#232;re coordonn&#233;e avec le taux de suspicion d&#8217;une forme.
En second lieu, elles valident la faisabilit&#233; d&#8217;un m&#233;canisme automatique de suggestion de cor-
rections lexicales sur les formes suspectes (i.e. sur les lemmes sous-jacents). Elles montrent
qu&#8217;il est &#233;galement possible d&#8217;obtenir du retour d&#8217;information sur des manques grammaticaux.
N&#233;anmoins, un travail reste encore &#224; faire pour affiner la qualit&#233; des corrections sugg&#233;r&#233;es en
distinguant mieux l&#8217;essentiel de l&#8217;accessoire dans les signatures, notamment &#224; travers des am&#233;-
liorations introduites pr&#233;c&#233;demment.
</p>
<p>R&#233;f&#233;rences
ABEILL&#201; A. (1993). Les nouvelles syntaxes, grammaire d&#8217;unification et analyse du fran&#231;ais.
Armand Colin.
BRENT M. R. (1993). From grammar to lexicon : unsupervised learning of lexical syntax.
Computational Linguistic, 19(2), 243&#8211;262.
CRYSMANN B., FRANK A., KIEFER B., KRIEGER H.-U., M&#220;LLER S., NEUMANN G., PIS-
KORSKI J., SCH&#196;FER U., SIEGEL M., USZKOREIT H. &amp; XU F. (2002). An integrated ar-
chitecture for shallow and deep processing. In Proceedings of the 40th Annual Meeting of the
ACL, p. 441&#8211;448.
GROVER C. &amp; LASCARIDES A. (2001). XML-based data preparation for robust deep parsing.
In Meeting of the Association for Computational Linguistics, p. 252&#8211;259.
HORIGUCHI K., TORISAWA K. &amp; TSUJII J. (1995). Automatic acquisition of content words
using an HPSG-based parser. In Proceedings of NLPRS&#8217;95.
SAGOT B. &amp; BOULLIER P. (2005). From raw corpus to word lattices : robust pre-parsing
processing. In Proceedings of L&amp;TC, Poznan, Pologne.
SAGOT B., CL&#201;MENT L., VILLEMONTE DE LA CLERGERIE &#201;. &amp; BOULLIER P. (2006). The
Lefff 2 syntactic lexicon for french : architecture, acquisition, use. In Proceedings of LREC&#8217;06.
SAGOT B. &amp; VILLEMONTE DE LA CLERGERIE &#201;. (2006). Trouver le coupable : Fouille
d&#8217;erreurs sur des sorties d&#8217;analyseurs syntaxiques. In Proceedings of TALN&#8217;06, p. 287&#8211;296.
SCHMID H. (1999). Probabilistic part-of-speech tagging using decision trees. IMS-CL.
THOMASSET F. &amp; VILLEMONTE DE LA CLERGERIE &#201;. (2005). Comment obtenir plus des
m&#233;ta-grammaires. In Proceedings of TALN&#8217;05, Dourdan, France : ATALA.
VAN NOORD G. (2004). Error mining for wide-coverage grammar engineering. In Procee-
dings of ACL 2004, Barcelone, Espagne.
</p>
<p>324</p>

</div></div>
</body></html>