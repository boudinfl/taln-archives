TALN 2007, Toulouse, 5-8 juin 2007

Confondre le coupable :
corrections d’un lexique suggérées par une grammaire

Lionel NICOLAS1, Jacques FARRE1, Eric VILLEMONTE DE LA CLERGERIE2
1 Laboratoire I3S, Université de Nice—Sophia Antipolis, CNRS
2000 route des Lucioles, B.P. 121, 06903 Sophia Antipolis Cedex, France
2 Projet ATOLL — INRIA
Domaine de Voluceau, B.P. 105, 78153 Le Chesnay Cedex, France
{lnicolas , j f} @i3s .unice . fr,
Eric . De_La_Clergerie@inria . fr

Résumé. Le succés de l’analyse syntaxique d’une phrase dépend de la qualité de la gram-
maire sous-j acente mais aussi de celle du lexique utilisé. Une premiere étape dans l’amélioration
des lexiques consiste a identiﬁer les entrées lexicales potentiellement erronées, par exemple en
utilisant des techniques de fouilles d’ erreurs sur corpus (Sagot & Villemonte de La Clergerie,
2006). Nous explorons ici l’étape suivante 2 la suggestion de corrections pour les entrées iden-
tiﬁées. Cet objectif est atteint au travers de réanalyses des phrases rej etées a l’étape précédente,
aprés modiﬁcation des informations portées par les entrées suspectées. Un calcul statistique sur
les nouveaux résultats permet ensuite de mettre en valeur les corrections les plus pertinentes.

Abstract. Successful parsing depends on the quality of the underlying grarmnar but also
on the quality of the lexicon. A ﬁrst step towards the improvement of lexica consists in iden-
tifying potentially erroneous lexical entries, for instance by using error mining techniques on
corpora (Sagot & Villemonte de La Clergerie, 2006). we explores the next step, namely the
suggestion of corrections for those entries. This is achieved by parsing the sentences rejected at
the previous step anew, after modifying the information carried by the suspected entries. After-
wards, a statistical computation on the parsing results exhibits the most relevant corrections.

Mots-clés 2 analyse syntaxique, lexique, apprentissage, correction.

Keywords: parsing, lexicon, machine learning, correction .

1 Introduction

L’ analyse symtaxique d’une langue repose sur l’utilisation de ressources linguistiques les plus
précises et correctes possibles. Obtenir des ressources possédant une si large couverture est une
tache ardue de longue haleine qu’il est souhaitable d’ alléger par le biais de techniques qui en
automatisent l’élaboration et la correction. Nous présentons ici une technique de génération au-
tomatique de suggestions de corrections pour les entrées potentiellement erronées d’un lexique.

Nous nous intéressons aux moyens de réduire l’inexactitude et l’incomplétude d’un lexique
a partir d’un recensement de formes lexicales suspectées d’étre incorrectement ou seulement

315

Lionel NICOLAS, Jacques FARRE, Eric VILLEMONTE DE LA CLERGERIE

partiellement décrites dans un lexique. Nous nous situons ainsi dans le prolongement direct de
la technique de fouille d’ erreurs sur des corpus de grande taille originalement proposée par (Van
Noord, 2004), et arnéliorée par (Sagot & Villemonte de La Clergerie, 2006). La pertinence de
cette demiére s’observe notarrrrnent a travers nos résultats.

Cette technique repose sur l’idée suivante 2 étant donné un large corpus de phrases attestées, plus
une forme (et indirectement les lemmes associés) apparait ou n’appara’1‘t pas dans des phrases
dont les analyses échouent, plus nous avons des raisons de douter ou de ne pas douter des en-
trées lexicales qui lui sont associées. Cependant le contexte des formes importe 2 une forme est
d’autar1t plus suspecte qu’elle apparait dans des phrases non analysables mais en co-occurrence
avec des formes qui tendent a appara1"tre dans des phrases analysables.

L’implémentation de la technique de fouilles d’ erreurs nous a fourni une liste de 5344 formes
suspectes avec, pour chaque forme f, un taux de suspicion et une liste de phrases non ar1aly-
sables (56089 au total) 011 f est suspectée d’étre a l’origir1e de l’échec des analyses. Si une
forme est effectivement responsable de ces échecs, et non la grammairel, c’est donc que les
informations lexicales qui lui sont associées sont incomplétes ou inexactes (Voir inexistantes).

En relachant les contraintes sur les irrforrrrations portées par une forme suspecte ou en les mo-
diﬁant (notarrrrnent la catégorie syurtaxique), de nouvelles analyses des phrases associées Vont
aboutir. Les représentations des phrases alors produites représentent les conditions dans les-
quelles l’analyse a réussi, c.a.d. les informations sur la forme suspecte rendant possible l’ana-
lyse. En examinant ces irrforrrrations sur un ensemble de phrases, il est alors possible de dégager
des hypotheses de correction utiles.

La technique présentée est irrdépendante du langage étudié.

'I1'avaux relatifs. L’ acquisition de connaissances linguistiques depuis des corpus bruts (i.e.
non armotés) par le biais de connaissances grammaticales a été initialement étudiée par (Brent,
1993) aﬁn d’identiﬁer les cadres syntaxiques des Verbes en anglais. (Horiguchi er al., 1995)
utilisent les résultats d’ analyse foumis par un systéme HPSG aﬁn d’acquérir des entrées lexi-
cales de mots japonais inconnus. Enﬁn, mentionnons la reconstitution d’informations lexicales
manquantes en Vue d’analyses robustes (Grover & Lascarides, 2001), (Crysmann er al., 2002).

Nous commencons par expliquer comment générer des hypotheses de correction (Sect. 2) et
comment les trier (Sect. 3). Nous introduisons ensuite la notion de symchronisation entre un
lexique et une grammaire (Sect. 4), juste avant d’ exposer les résultats obtenus (Sect. 5) et les
développements futurs (Sect. 6).

2 Génération d’hyp0théses

Le principal but d’un analyseur symtaxique est de Vériﬁer la Validité symtaxique d’une phrase et
d’en produire une ou plusieurs représentations. On souhaite en général éviter la surgénération
des représentations issues d’une analyse en produisant le moins possible de représentations.

Une phrase est qualiﬁée d’ambigué' pour un analyseur lorsque celui-ci lui associe plusieurs
interprétations. Ceci arrive principalement lorsque la phrase est intrinséquement ambigué, i.e.
d’autres informations (tel que le contexte sémantique) sont nécessaires aﬁn de ﬁltrer les inter-

1Nous supposons que les erreurs dues A un traitement incorrect en arnont du processus d‘ analyse proprement
dit (segmentation, ponctuation, detection d‘entités nommées, . . .) ont été identiﬁées. Les formes erronées et leurs
phrases associées qui résulteraient de telles erreurs sont donc exclues de celles qui nous intéressent ici.

316

Confondre le coupable 2 corrections d’un lexique suggerees par une grarmnaire

pretations, ou lorsque les ressources utilisees (lexique, grammaire ...) ne sont pas assez restric-
tives et acceptent un langage plus large.

Aﬁn de rejeter les phrases n’appartenant pas a la langue, on souhaite disposer d’un lexique le
plus precis et detaille possible. En effet, plus une forme lexicale est speciﬁee, moins elle se
combine avec les autres constituants de la phrase, et par consequent, moins elle permet d’inter-
pretations incorrectes.

2.1 Causes d’échec d’une analyse

Chaque forme possede, a travers ses lemmes, differentes informations pouvant etre regroupees
en deux ensembles 2 d’une par: la categorie symtaxique (nom, Verbe, adjectif, ...), d’ autre part
les informations morphologiques (nombre, genre, personne, temps, mode, ...) et syntaxiques
(Valence, fac11ltatiVite des arguments, reﬂexivite, passivation, . . .). L’ echec d’ une analyse a cause
d’une forme est la consequence d’ un probleme touchant a au moins un de ces ensembles.

2.1.1 Défaut de categorisation

Une forme peut etre associee a plusieurs lemmes (homonymes) avec des categories syntaxiques
distinctes. Le traitement de telles formes ambigues au sein d’une phrase se gere par le passage
d’un treillis de mots (ou DAG) a l’analyseur syntaxique (Sagot & Boullier, 2005). Une analyse
symtaxique reussie Valide au moins un chemin possible de lecture dans ce treillis.

Cependant, un lexique peut ne pas recenser tous les homonymes d’une forme et induire ainsi
des echecs d’ analyse. Par exemple, la forme « ﬁche » denote un nom commun et une ﬂexion du
Verbe « ﬁcher » . S’il n’existe aucun lemme associe de categorie nom-commun, la phrase « Ma
ﬁche contient une erreur. » sera representee par une seule sequence de categories ma/pronom-
possessifﬁche/verbe contient/verbe une/det erreur/nom-commun. A moins qu’une production
grannnaticale n’accepte une telle construction, son analyse devrait aboutir a un echec.

2.1.2 Sur-speciﬁcation

En general, on associe aux regles de grarmnaire des decorations, exprimees sous formes de
structures de traits et chargees de completer les veriﬁcations amorcees par le squelette sym-
taxique d’une production grammaticale (Abeille, 1993). Par exemple, un squelette Veriﬁe la
presence d’un groupe nominal sujet et d’un Verbe dans une phrase la ou les decorations en
veriﬁent l’accord (meme personne, nombre, et eventuellement genre).

Comme nous l’aVons explique, il est souhaitable que les formes lexicales soient les plus speci-
ﬁees possible aﬁn de reduire les ambigu'1‘tes. En revanche, si ces demieres sont trop restrictives
(autrement dit sur-speciﬁees), certaines analyses echouent a cause du mecanisme d’uniﬁcation
des decorations de la grarmnaire et des restrictions d’utilisation des entrees lexicales.

Il est par exemple tres difﬁcile de renseigner un Verbe sur l’ensemble de ses emplois pos-
sibles, du fait de la polysemie, de la facultativite de certains arguments, de possibles alternations
(« acheter qchose » donnant « qchose s’achete » ), et de multiples realisations des arguments
(« aimer qchose » , « aimer que + S » , « aimer Sinf » ). I] arrive donc que 1’ on considere comme
obligatoires des aspects qui ne sont que facultatifs dans certains cas. Ce constat s’etend aux
autres categories symtaxiques des lors qu’on leur attache des cadres de categorisation.

317

Lionel NICOLAS, Jacques FARRE, Eric VILLEMONTE DE LA CLERGERIE

2.2 Réanalyser en sous-spéciﬁant

Puisque seules les phrases dont l’analyse a échoué sont conservées durant l’étape de fouille
d’erreurs, leur taux d’ analyse est nul. Si une modiﬁcation des informations lexicales portées par
une forme suspecte f permet d’augmenter sensiblement le taux de réanalyse des phrases qui
lui sont associées, il est raisonnable de penser que le probléme est bien lié a f. La difﬁculté
est alors de trouver quelles modiﬁcations perrnettent des augmentations sensibles. Plutét que
de tester toutes les combinaisons de modiﬁcations possibles, ce qui est exponentiel, nous nous
reposons sur la capacité de notre analyseur a pouvoir gérer des formes sous-spéciﬁées.

Une fois obtenus de nouveaux résultats d’analyse, nous sommes en mesure d’en extraire des
hypotheses de correction (Voir Sect. 2.2.2).

2.2.1 Génération et utilisation de jokers

Aﬁn de rendre analysables des phrases qui ne l’étaient initialement pas, nous introduisons a
la place des formes lexicales suspectes des formes sous-spéciﬁées appelées jokers. Dans l’ap-
proche actuelle (qui demande a étre afﬁnée), elles ne possédent qu’une catégorie syntaxique
(parmi les catégories « ouvertes » 2 verbe, nom commun, adj ectif ou adverbe). Elles n’ont donc
aucune information morphologique ou symtaxique ﬁxe et remplissent toujours les conditions
ﬁxées par les décorations des productions grammaticales. Puisque leur utilisation ne souléve
aucun conﬂit lors des analyses (excepté pour la catégorie syntaxique), les substituer a une forme
suspecte dans une phrase rej etée favorise la réussite de son analyse. Cependant, cela peut intro-
duire une certaine ambigu'1‘té car il n’y a plus de ﬁltrage au niveau des décorations.

Etant donné que nous ne pouvons savoir a priori quel type d’ erreur (sur-spéciﬁcation ou défaut
de catégorisation) est responsable des échecs d’ analyse, nous considérons les deux sim111tané-
ment au moment de générer les jokers.

Pour envisager une sur-spéciﬁcation, nous remplacons une forme de catégorie X par un joker
de méme catégorie X. Les caractéristiques perrnettent alors d’explorer les mémes productions
grammaticales que pour la phrase initiale, sans pour autant étre arrété par les décorations.

Pour faire face a un défaut de catégorisation d’une forme f, nous créons des jokers avec des
catégories syntaxiques différentes de celles initialement recensées pour f. En procédant ainsi,
les réanalyses exploreront d’ autres productions. Ces jokers sont générés a partir des informa-
tions fournies par un lermnatiseur (stemmer) ou par un tagger probabiliste tel que TREETAGGER
(Schmid, 1999).

Nous aurions pu utiliser un joker unique ne possédant méme pas de catégorie syntaxique et
permettant de couvrir a lui seul l’ensemble des situations décrites ci-dessus. Cependant, un
tel joker introduit une trés forte ambiguité, aboutissant soit a un échec des analyses par lirnite
de temps ou de mémoire, soit a la surgénération de représentations pour une phrase. Dans le
premier cas, nous ne collectons aucune donnée, dans le second cas, le Volume de données est
trop important pour étre correctement trié et Valorisé. Notre approche permet (en grande partie)
d’écarter ces problémes tout en évitant de multiplier le nombre de jokers par forme suspecte.

Nous avons testé une moyenne de 2.05 jokers par forme suspecte (10978 au total), donnant lieu
a 117655 nouvelles analyses.

318

Confondre le coupable 2 corrections d’un lexique suggérées par une grarmnaire

La vie

de


mg
/m
ec '

9
5:5
0
(Si)
‘3
E

FIG. 1 — Extrait de la représentation graphique d’une forét partagées de dépendances

2.2.2 Extraction de signatures syntaxiques

Si une forme suspecte a été correctement identiﬁée, son remplacement par des jokers dans les
phrases qui lui sont associées permet a certaines analyses de réussir. Dans les faits, on observe
une relation nette entre le taux de succés de l’analyse des phrases modiﬁées et le taux de suspi-
cion de la forme concemée.

Notre analyseur renvoie l’ensemble des inteiprétations possibles d’une phrase sous la forme
d’une forét partagée de dépendances (Fig. 1) ou les noeuds représentent les lemmes et les arcs
les dépendances syntaxiques entre les lemmes. Chaque noeud posséde des informations relatives
au lemme et a la production grammaticale ancrée (dans le cadre d’une grammaire lexicalisée).
Chaque dépendance est caractérisée par un noeud gouvemeur source, un noeud gouvemé cible,
une nature et un label qui dépend de la graimnaire. Ce label dénote souvent (mais malheu-
reusement pas toujours) la fonction switaxique de la cible (sujet, objet, ...). Aﬁn de gérer les
ambigu'1‘tés, des informations complémentaires locales au noeud gouvemeur lient les lemmes et
les dépendances a une ou plusieurs interprétations. Ainsi, la représentation issue de l’analyse
de la phrase pour « La vie est belle » (Fig. 1) donne lieu a quatre lectures possibles, du fait (a)
de l’ambigu'1‘té de « est» comme Verbe a copule, nom commun (en apposition de « vie » ) et
adjectif ainsi que (b) de 1’ ambigu'1‘té de « belle » entre adjectif et nom.

Sans aucune information supplémentaire, les deux interprétations comme nom et adjectif de
« est» auraient dﬁ étre rejetées car introduisant une apposition rare et/ou construisant une
phrase sans Verbe.

Les foréts contiennent donc les dépendances entrantes et sortantes depuis et Vers un joker. Nous
appelons désormais signature syntaxique l’ensemble de dépendances autour d’un joker dans
une inteiprétation particuliére et groupe de signatures l’ensemble des signatures syntaxiques
possibles extraites des interprétations obtenues par 1’ analyse réussie d’une phrase.

Ces signatures représentent les conditions dans lesquelles l’analyse a pu aboutir, i.e. les données
que la grammaire aurait accepté pour la forme suspecte. Du fait de l’ambigu'1‘té consécutive a
l’introduction d’un joker, un analyseur peut produire plusieurs interprétations et donc plusieurs
signatures. Parmi ces interprétations, une est plus proche du sens réel de la phrase que les autres.
La signature qu’elle contient posséde alors les données les plus pertinentes et intéressantes,
celles que nous recherchons aﬁn de déterminer les corrections a appliquer au lexique.

3 Identiﬁer les meilleures signatures

En se placant au niveau d’un seul groupe de signatures (produit a partir d’une seule phrase),
nous sommes incapables de différencier les signatures pertinentes de celles qui ne sont qu’une

319

Lionel NICOLAS, Jacques FARRE, Eric VILLEMONTE DE LA CLERGERIE

conséquence de l’ambigu'1‘té introduite par le joker.

La variabilité de contexte induite par plusieurs groupes de signatures (produits a partir de plu-
sieurs phrases) nous apporte une solution a ce probléme. En effet, elle implique la diversiﬁcation
des signatures « parasites » qui contraste avec la stabilité des signatures pertinentes représentant
le(s) sens réel(s) de la forme.

Une répétition bien marquée de certaines signatures sur l’ensemble des phrases suggére alors un
schéma d’utilisation attendu par la grammaire pour la forme. Aﬁn de pouvoir l’observer, nous
valorisons/dévalorisons les signatures par le biais d’un calcul statistique simple en deux étapes.

Premiére étape : distribution locale des poids entre signatures. L’intérét que nous portons
a un groupe de signatures dépend de sa taille 2 plus il contient de signatures moins il présente
d’intérét. En effet, il est Vraisemblable que plusieurs squelettes switaxiques « permissifs » lui
correspondent, a l’image de ceux permettant les diverses interprétations illustrées par la ﬁgure 1.
Pour chaque groupe g, nous calculons donc un poids P = c" avec c une constante incluse dans
]0, 1[ (par exemple 0, 95) et 11 la taille du groupe.

Au niveau d’un groupe, toutes les signatures sont d’ égale importance, nous répartissons donc de
maniére équitable les poids attribués au groupe 2 chacune signature recoit un poids pg = § = %
qui dépend donc doublement de la taille du groupe.

Seconde étape : calcul global des poids. Une fois l’étape précédente réalisée, nous addition-
nons les poids obtenus par une méme signature 0' dans les différents groupes o1‘1 elle appara’1‘t
pour calculer son score .9, = Egpg.

Les meilleures signatures, a savoir celles qui se trouvent dans plusieurs groupes et dans des
groupes de petite taille, recoivent alors un score 5, plus élevé.

4 Synchronisation lexique-grammaire

Cette technique perrnet a une grarmnaire d’expr'imer ses attentes pour les formes suspectes. Si
elle 11’ est pas parfaite, les représentations qu’elle produit ainsi que les signatures que 1’ on en
extrait ne le sont pas non plus. En fait, dans le cas ou la grarmnaire est parfaite, nous pouvons
qualiﬁer les suggestions faites par cette technique comme permettant une correction du lexique.
Dans le cas inverse, il s’agit alors d’une technique permettant de dirninuer le nombre de conﬂits
entre une grarnmaire et un lexique, i.e. perrnettant une meilleure « synchronisation » entre le
lexique et la grarnmaire.

Il est a noter qu’un ensemble de signatures incorrectes représente une source d’informations
intéressante sur les manques et incorrections d’une grarnmaire.

5 Résultats

Le travail présenté ici, tout comme la technique de fouille d’erreurs, est un mécanisme de re-
tour sur erreurs. Ce terme désigne des mécanismes réutilisant les erreurs produites par un pro-
gramme aﬁn d’ arnéliorer automatiquement ou serni-autornatiquement sa qualité. De maniére a
garantir que l’or'igine des erreurs produites est effectivement le programme, les données ana-

320

Confondre le coupable 2 corrections d’un lexique suggerees par une grarmnaire

lysees doivent etre ﬁables. Dans le cas present, les erreurs sur lesquelles nous travaillons sont
issues d’une carnpagne d’ analyse d’un corpus MD de 331 000 phrases extraites du Monde diplo-
matique realisee durant la validation de la technique de fouille d’ erreurs (Sagot & Villemonte
de La Clergerie, 2006).

Le lexique que nous cherchons a arneliorer est le Leﬁ (Lexique desformesﬂéchies dufrangais)
(Sagot et al., 2006). En partie acquis automatiquement, ce lexique morpho-syntaxique a large
couverture du francais est en constant developpement et possede, a l’heure actuelle, plus de
520000 entrees. La grarnmaire FRMG (Thomasset & Villemonte de La Clergerie, 2005) que
nous utilisons est une gramrnaire hybride TAG/'I‘IG avec decorations. Elle est construite a par-
tir d’une méta-grammaire plus abstraite qui produit un ensemble de 134 arbres tres factorises.
Malgre son tres faible nombre d’ arbres, sa factorisation lui pennet de couvrir un grand nombre
de cadres de categorisation pour les verbes, la passivation, les extractions (relatives, interro-
gatives, clivees), certaines inversions du sujet, certaines constructions a verbe support (« faire
attention a » ). Neanmoins, nombre de phenomenes ne sont pas encore traites (comme la sous-
categorisation sur les adjectifs et les r1on1s). La grarnmaire FRMG couplee a Leﬂf assurait en
2005 une couverture de l’ordre de 41% sur le corpus MD.

55

50- -

45- —

40- -

35- -

30- -

25- -

20- —

0 1 0 20 30 40 50 50 70 00

FIG. 2 — Taux de reussite des reanalyses (axe Y) en fonction des taux de suspicion (axe X)

5.1 Exactitude de la détection automatique des formes suspectes

La courbe de la ﬁgure 2 nous perrnet d’ observer une correlation tres nette entre les taux de reus-
site des reanalyses et les taux de suspicion des fonnes. Cela atteste la Validite des infonnations
produites par l’etape precedente de fouille d’erreurs.

Les Valeurs presentees par cette courbe sont en realite des moyennes calculees apres un regrou-
pement des forrnes suspectes par intervalle de taux de suspicion. Sans cela, la courbe presente
des variations rendant difﬁcile son observation.

Ces variations s’expliquent principalement par le fait que certaines forrnes ont ete suspectees a
la place de la grarmnaire ce qui explique que leur echange avec des jokers n’ait rien apporte. En
effet, certaines fonnes ont une afﬁnite marquee pour des constructions speciﬁques ; par exemple
une inversion du suj et en presence de l’adj ectif ’rare’ comme dans « Rares sont ceux qui tentent

321

Lionel NICOLAS, Jacques FARRE,E1ic VILLEMONTE DE LA CLERGERIE

d’en sortir. » ou ’nombreux’ dans « Nombreux sont ceux qui refusent. » 2. Ces formes ont alors
payé cette afﬁnité par une suspicion injustement élevée a leur égard.

Une autre raison moins importante expliquant ces variations est que l’utilisation de jokers aug-
mente sensiblement le taux de timeout pour les phrases, et cela méme en ayant imposé une
limite de 40 mots sur la longueur des phrases analysées.

Puisque ces deux phénoménes s’observent a tous les niveaux de taux de suspicion, le regroupe-
ment des Valeurs par intervalle a permis d’en diminuer l’inﬂuence sur la courbe de la ﬁgure 2.

Toujours dans une optique de retour sur erreurs, notons qu’il est tentant de Voir les phrases des
suspects forts avec de faibles taux de réanalyse comme indiquant des manques de la grammaire.
I1 serait alors intéressant de les analyser au moyen d’un systéme d’inférence grammaticale.

5.2 Evaluation de la qualité des signatures

Aﬁn d’éValuer la qualité des signatures produites, nous avons ordonné les formes suspectes en
accord avec le calcul suivant 2 M f = Sf.ln(NSf), Sf étant le taux de suspicion d’une forme
et N Sf le nombre de phrases associées3. Nous avons ensuite examiné nombre d’entre elles
a travers une interface Web (Fig. 3) nous permettant d’accéder, pour chaque forme, aux jokers
testés, aux taux de réanalyses obtenus, aux phrases testées et aux meilleures signatures retenues.
De méme, elle nous permet de laisser des commentaires et de soumettre des requétes au lexique
et a l’analyseur. A tenne, cette interface a vocation a étre utilisée par des linguistes.

Analyzing correction suggestions

3ntel'lf(:>l rank) 245 l::245ranl«.:29

EE|tC0

1%

 

 

info on 246: prospéres /prospéres

i—] Key/Lax => priisaéreslprosnéres Original Results => 0 Lanes, :9 failures, ii nn.so.s Best new results => :4

  

status DONE Results 14lsuccess,5fai.lul"es,Dtlmeuuls iyps detected

. 27; cat as, Points 2.243332532330257

Relations v :> suspect ioonuo
. 57) cat ao_ Paints 5495551143454 Graph Dev: 1311 1553

Relations no :> so aspect :> prep [edﬂ

' c43aecu73o4e Graph Dep: 37 87 27

I}

 

    

. an cat ad_
Relations no :> slime
. 1653) Cal: sol
Relations no :> slime
. 47027) Cal: an Points:
Relations v k
. 1311) Cat sq Point-
Relations no :> slime
. 11) Cat ad_ Paints
Relations ad_ :> sll5p3:t[N)
~[+ _el'Tur7nc status: DO\E Results tvsucoess, l2fallures,0llmenuls 1ype:delected

71BE§lS25"E GraphDep: 1653
slspect :> a:_ ladj)

 
  
   
 
   
 
 

(edfl suspect :> adJ(E:1J)
2: oeti susosol :> sou (N)

prep [edﬂ suspect :> coo(a:1JF]
2916328218

 

 

°t1’m/ Hw

FIG. 3 — Interface d’ exploration des signatures

Lors de 1’ étude des meilleures signatures, certains doutes ont été conﬁrmés 2 notre technique
manque de maturité. Nous avons identiﬁé un certain nombre de phénoménes nous empéchant
de correctement quantiﬁer la qualité des signatures. Cependant, nous savons déja comment faire
face a la plupart (Voir Sect 6).

2Ces exemples reﬂétent aussi le style recherché du corpus joumalistiquc étudié !
3Un fort taux de réanalyse sur un nombre réduit dc phrases est peu signiﬁcatif.

322

Confondre le coupable 2 corrections d’un lexique suggérées par une grarmnaire

Toutefois, dans bien des cas, nous avons obtenu des résultats pe11'.inents et instructifs qui nous
ont permis d’ améliorer nos outils (et pas seulement notre lexique). Par exemple, on retrouve
la bonne signature comme dans le cas de « prosperes » ou l’on retrouve un usage d’ adjectif
épithete (joker + signature), alors qu’il n’existe que comme verbe dans Leﬁ‘. Pour la forme
verbale « révéler » , les hypotheses font ressortir qu’elle attend bien un argument attributif (« ce
choix pourrait se révéler catastrophique. » ) mais qu’il lui manque le coté réﬂexif, a cause de
constructions prépositionnelles comme « contraint de révéler X » ou « penser a révéler X » .

Bien que devant encore mﬁrir, notre approche s’ est montrée viable. Nous continuerons a la deve-
lopper aﬁn d’ obtenir un outil pleinement fonctionnel. L’ achevement de certaines améliorations
donnera notan1ment lieu a de nouvelles campagnes de calcul.

6 Développements futurs

Durant nos experiences, nous avons pu établir une liste de problemes a traiter et des solutions

pour les résoudre 2

— Il est tres fréquent de pouvoir appliquer plusieurs productions grannnaticales a une suite de
formes, surtout si la catégorie syntaxique d’une de ces formes varie (comme pour les jokers).
Cependant, ces productions n’ont pas les memes fréquences d’utilisations et par conséquent,
les signatures qui en rés11ltent ne représentent pas la méme quantité d’information utile. De
telles données sur les fréquences d’utilisation nous seraient utiles aﬁn de pondérer les signa-
tures et de diminuer l’ingérence de signatures « parasites » dans les résultats.

— Les signatures doivent étre nettoyées pour éliminer l’adj onction de certains adj oints (gouver-
nés par les suspects) qui ne sont pas primordiaux pour caractériser ceux-ci. Cela nous permet-
trait de consolider des signatures actuellement séparées par des adj oints inutiles. Néanmoins,
a ce stade, il n’est pas toujours évident de juger de l’impo1tance d’un adjoint.

— Il nous faut regrouper les formes par famille de lemmes sous-j acents de maniere a augmenter
la vatiabilité des contextes testés et ainsi cemer ce qu’ils ont en commun. Néanmoins, il
faut garder al’esp1itque certains problemes ne se manifestent que pour quelques formes, par
exemple une mauvaise attribution de l’auXiliaire a utiliser pour des participes passés (exemple
de « larvé » faussement listé dans Leﬁf comme utilisant l’auxiliaire « avoir » ). Nous avons
aussi mentionné que, parfois, le probleme résulte du manque dans le lexique d’un des lemmes
possibles pour une forme suspecte.

— Il nous faut regrouper les signatures qui traduisent en fait un méme phénomene syntaxique
sous des aspects différents; comme par exemple 2 le sujet et autres arguments verbaux ont
diverses réalisations (nominales, cliticisées, pronon1s relatifs, pronon1s interrogatifs), ou en-
core un verbe avec objet sous forme active et passive. Le regroupement des formes par lemme
est susceptible d’ aider.

— Certaines formes suspectes donnent des signatures équivalentes aux informations syntaxiques
déja présentes dans le lexique. Ce genre de cas implique que les signatures sont incompletes.
A l’heure actuelle, elles manquent principalement d’informations morphologiques. L’inté-
gration de ces informations déja présentes dans les foréts de dépendances, mais non encore
exploitées, représente donc la prochaine étape dans l’amélioration du modele des signatures.

— Certaines formes ont été injustement suspectées a cause de leur afﬁnité avec des constructions
switaxiques non gérées par la grammaire. L’utilisation de plusieurs analyseurs syntaxiques
avec des grarmnaires différentes durant l’étape préalable de fouille d’ erreurs permettraient
éventuellement de ﬁltrer une partie des formes suspectes.

323

Lionel NICOLAS, Jacques FARRE, Eric VILLEMONTE DE LA CLERGERIE

— Les signatures sont composées d’un ensemble de dépendances syntaxiques entre les mots
et le joker dans les représentations générées d’une phrase. Ces signatures dépendent direc-
tement de la grarnmaire utilisée et peuvent étre difﬁciles a comprendre pour une personne
non familiére avec ce formalisme. Un effort doit donc étre réalisé pour les traduire Vers une
représentation indépendante de la grarnmaire et plus hurnainement compréhensible.

7 Conclusion

Les expériences présentées conﬁrment en premier lieu la capacité de la technique de fouille
d’erreurs a identiﬁer de bonnes formes suspectes. Leur transformation en jokers augmente le
taux de réanalyses réussies de maniére coordonnée avec le taux de suspicion d’une forme.

En second lieu, elles valident la faisabilité d’un mécanisme automatique de suggestion de cor-
rections lexicales sur les formes suspectes (i.e. sur les lemmes sous-jacents). Elles montrent
qu’il est également possible d’obtenir du retour d’information sur des manques gramrnaticaux.

Néanmoins, un travail reste encore a faire pour afﬁner la qualité des corrections suggérées en
distinguant rnieux l’essentiel de l’accessoire dans les signatures, notamment a travers des arné-
liorations introduites précédemment.

Références

ABEILLE A. (1993). Les nouvelles syntaxes, grammaire d ’uniﬁcation et analyse dufrangais.
Armand Colin.

BRENT M. R. (1993). From grammar to lexicon 2 unsupervised learning of lexical swrtax.
Computational Linguistic, 19(2), 243-262.

CRYSMANN B., FRANK A., KIEFER B., KRIEGER H.-U., MULLER S., NEUMANN G., PIS-
KORSKI J ., SCHAFER U., SIEGEL M., USZKOREIT H. & XU F. (2002). An integrated ar-
chitecture for shallow and deep processing. In Proceedings of the 40th Annual Meeting of the
ACL, p. 441-448.

GROVER C. & LASCARIDES A. (2001). XML-based data preparation for robust deep parsing.
In Meeting of the Association for Computational Linguistics, p. 252-259.

HORIGUCHI K., TORISAWA K. & TSUJII J. (1995). Automatic acquisition of content words
using an HPSG-based parser. In Proceedings of NLPRS ’95.

SAGOT B. & BOULLIER P. (2005). From raw corpus to word lattices 2 robust pre-parsing
processing. In Proceedings of L&TC, Poznan, Pologne.

SAGOT B., CLEMENT L., VILLEMONTE DE LA CLERGERIE E. & BOULLIER P. (2006). The
Lefff 2 syntactic lexicon for french 2 architecture, acquisition, use. In Proceedings of LRE C’06.
SAGOT B. & VILLEMONTE DE LA CLERGERIE E. (2006). Trouver 1e coupable 2 Fouille
d’ erreurs sur des sorties d’ analyseurs swrtaxiques. In Proceedings of TALN’06, p. 287-296.
SCHMID H. (1999). Probabilistic part-of-speech tagging using decision trees. IMS-CL.
THOMAssET F. & VILLEMONTE DE LA CLERGERIE E. (2005). Comment obtenir plus des
méta-grarmnaires. In Proceedings of TALN’05, Dourdan, France 2 ATALA.

VAN NOORD G. (2004). Error mining for wide-coverage grarmnar engineering. In Procee-
dings ofACL 2004, Barcelone, Espagne.

324

