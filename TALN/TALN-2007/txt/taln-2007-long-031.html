<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>&#201;valuer SYNLEX</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2007, Toulouse, 5&#8211;8 juin 2007
</p>
<p>&#201;valuer SYNLEX
</p>
<p>Ingrid FALK1, Gil FRANCOPOULO2, Claire GARDENT3
1 CNRS/ATILF, Nancy
2 INRIA/LORIA, Nancy
3 CNRS/LORIA, Nancy
</p>
<p>{Ingrid.Falk,Claire.Gardent}@loria.fr,
Gil.Francopoulo@wanadoo.fr
</p>
<p>R&#233;sum&#233;. SYNLEX est un lexique syntaxique extrait semi-automatiquement des tables du
LADL. Comme les autres lexiques syntaxiques du fran&#231;ais disponibles et utilisables pour le
TAL (LEFFF, DICOVALENCE), il est incomplet et n&#8217;a pas fait l&#8217;objet d&#8217;une &#233;valuation permet-
tant de d&#233;terminer son rappel et sa pr&#233;cision par rapport &#224; un lexique de r&#233;f&#233;rence. Nous pr&#233;-
sentons une approche qui permet de combler au moins partiellement ces lacunes. L&#8217;approche
s&#8217;appuie sur les m&#233;thodes mises au point en acquisition automatique de lexique. Un lexique
syntaxique distinct de SYNLEX est acquis &#224; partir d&#8217;un corpus de 82 millions de mots puis uti-
lis&#233; pour valider et compl&#233;ter SYNLEX. Le rappel et la pr&#233;cision de cette version am&#233;lior&#233;e de
SYNLEX sont ensuite calcul&#233;s par rapport &#224; un lexique de r&#233;f&#233;rence extrait de DICOVALENCE.
</p>
<p>Abstract. SYNLEX is a syntactic lexicon extracted semi-automatically from the LADL
tables. Like the other syntactic lexicons for French which are both available and usable for NLP
(LEFFF, DICOVALENCE), it is incomplete and its recall and precision wrt a gold standard are
unknown. We present an approach which goes some way towards adressing these shortcomings.
The approach draws on methods used for the automatic acquisition of syntactic lexicons. First,
a new syntactic lexicon is acquired from an 82 million words corpus. This lexicon is then used
to validate and extend SYNLEX. Finally, the recall and precision of the extended version of
SYNLEX is computed based on a gold standard extracted from DICOVALENCE.
</p>
<p>Mots-cl&#233;s : lexique syntaxique, &#233;valuation.
Keywords: syntactic lexicon, evaluation.
</p>
<p>1 Introduction
</p>
<p>Un lexique syntaxique d&#233;crit les propri&#233;t&#233;s syntaxiques des mots d&#8217;une langue. En particulier,
un lexique syntaxique associe &#224; chaque foncteur syntaxique un cadre de sous-cat&#233;gorisation
sp&#233;cifiant le nombre et le type (cat&#233;gorie syntaxique, marqueur introductif, mode, etc.) de ses
arguments.
</p>
<p>Comme l&#8217;ont montr&#233; (Carroll &amp; Fang, 2004), un lexique syntaxique exhaustif et d&#233;taill&#233; per-
met d&#8217;am&#233;liorer les performances des analyseurs syntaxiques. Un tel lexique est &#233;galement une
composante essentielle de tout r&#233;alisateur de surface puisqu&#8217;il permet de r&#233;aliser un contenu
</p>
<p>335</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ingrid FALK, Gil FRANCOPOULO, Claire GARDENT
</p>
<p>s&#233;mantique donn&#233; par une phrase bien form&#233;e et en particulier, une phrase o&#249; chaque foncteur
syntaxique a le nombre et le type d&#8217;arguments requis par son r&#233;gime. Plus g&#233;n&#233;ralement, un
lexique syntaxique est une composante de base pour tout syst&#232;me faisant intervenir soit l&#8217;ana-
lyse, soit la r&#233;alisation.
</p>
<p>Pour le francais, il existe &#224; l&#8217;heure actuelle trois lexiques syntaxiques disponibles librement
et utilisables par des syst&#232;mes de traitement automatique des langues : Proton r&#233;cemment re-
nomm&#233; DicoValence, (van den Eynde &amp; Mertens, 2003), Lefff (Cl&#233;ment et al., 2004) et SYN-
LEX (Gardent et al., 2006). N&#233;anmoins aucun de ces lexiques n&#8217;est enti&#232;rement satisfaisant
pour deux raisons.
</p>
<p>Premi&#232;rement, aucun de ces lexiques ne couvre l&#8217;ensemble des verbes du fran&#231;ais. Ainsi pour
8 790 verbes identifi&#233;s pour le fran&#231;ais dans Morphalou (Romary et al., 2004), DicoValence
inclut 3 700 verbes, Lefff 6 798 et SYNLEX 5244.
</p>
<p>Deuxi&#232;mement, la qualit&#233; de leur contenu et plus pr&#233;cis&#233;ment, leur rappel et leur pr&#233;cision
restent inconnus : Pour l&#8217;ensemble des entr&#233;es contenues dans chacun de ses dictionnaires,
on ne connait ni quelle proportion des entr&#233;es correctes est pr&#233;sente (rappel) ni quelle est la
proportion d&#8217;entr&#233;es incorrectes (pr&#233;cision).
</p>
<p>Dans cet article, nous consid&#233;rons SYNLEX et pr&#233;sentons une approche qui vise &#224; pallier ces
lacunes. L&#8217;approche s&#8217;appuie sur les m&#233;thodes mises au point en acquisition automatique de
lexique. Un lexique syntaxique (CORLEX) distinct de SYNLEX est acquis &#224; partir d&#8217;un corpus
de 82 millions de mots. Ce lexique est ensuite utilis&#233; pour valider et compl&#233;ter SYNLEX. Le
rappel et la pr&#233;cision de SYNLEX, de la version am&#233;lior&#233;e de SYNLEX et de CORLEX sont
ensuite calcul&#233;s par rapport &#224; un lexique de r&#233;f&#233;rence extrait de DICOVALENCE.
</p>
<p>L&#8217;article est structur&#233; comme suit. La section 2 d&#233;crit le processus de cr&#233;ation de SYNLEX et
pr&#233;sente son format et son contenu. La section 3 pr&#233;sente les travaux visant &#224; valider et &#224; &#233;tendre
SYNLEX puis commente les r&#233;sultats obtenus. La section 4 conclut en indiquant les directions
de recherche futures.
</p>
<p>2 Synlex
</p>
<p>Synlex est un lexique cr&#233;&#233; &#224; partir des tables du LADL (Gross, 1975; Guillet &amp; Lecl&#232;re, 1992;
Boons et al., 1976). Le processus de cr&#233;ation a &#233;t&#233; d&#233;crit dans (Gardent et al., 2005b; Gardent
et al., 2006; Gardent et al., 2005a) et peut &#234;tre r&#233;sum&#233; comme suit :
</p>
<p>1. une repr&#233;sentation du contenu des colonnes des tables et de leurs interd&#233;pendance est
cr&#233;&#233;e manuellement sous la forme d&#8217;un graphe et/ou dont les noeuds contiennent &#224; la fois
des conditions et des pointeurs vers le contenu des colonnes
</p>
<p>2. ce graphe et/ou est ensuite utilis&#233; en conjonction avec les tables pour produire de facon
automatique un lexique syntaxique repr&#233;sentant leur contenu
</p>
<p>3. ce lexique est ensuite simplifi&#233; pour ne contenir que le type d&#8217;information habituellement
pr&#233;sente dans un lexique syntaxique (i.e., nombre et types de syntagmes sous-cat&#233;goris&#233;s
par les verbes)
</p>
<p>Le format des entr&#233;es de SYNLEX est sp&#233;cifi&#233; dans la figure 1 et peut &#234;tre d&#233;crit comme suit.
Une entr&#233;e se compose d&#8217;un verbe, d&#8217;une liste d&#8217;arguments syntaxiques ayant un r&#244;le s&#233;man-
</p>
<p>336</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;valuer SYNLEX
</p>
<p>tique, d&#8217;une liste optionnelle d&#8217;associ&#233;s c-&#224;-d, d&#8217;arguments r&#233;gis par le verbe mais ne remplis-
sant pas de r&#244;le s&#233;mantique (e.g., l&#8217;expl&#233;tive il dans il pleut) et d&#8217;une liste de macros donnant
des informations suppl&#233;mentaires sur les propri&#233;t&#233;s syntaxiques du verbes (e.g., contr&#244;le, pas-
sivisation). Les associ&#233;s et les macros sont des listes finies d&#8217;atomes. Un argument en revanche
est d&#233;fini par un triplet de la forme F :M-C o&#249; F est une fonction grammaticale, M un mar-
queur optionnel (une pr&#233;position ou un clitique indiquant la cliticisation d&#8217;un argument en cas
d&#8217;ambiguit&#233; comme par exemple les arguments en &#224; qui peuvent se cliticiser soit en y, soit en
lui) et C est une cat&#233;gorie syntaxique.
</p>
<p>Entree ::= Verb : &#12296;Arg+&#12297;, Associe&#8727;,Macro&#8727; (1)
Arg ::= Fonction : Marqueur &#8722; Categorie (2)
</p>
<p>Fonction ::= suj | obj | obja | objde | obl | attr (3)
Marqueur ::= Prep | Clitic | Compl (4)
Categorie ::= sn | pinf | pcompl | qcompl (5)
Associe ::= ilimp | cln | cla | cld | clg | pron (6)
Macro ::= CtrlArgXArgY | passivable | nonPassivable (7)
</p>
<p>FIG. 1 &#8211; SynLex Format
</p>
<p>Seules 60% des tables du LADL &#233;tant disponibles, nous avons compl&#233;t&#233; manuellement le
lexique extrait des tables disponibles avec environ 2 000 verbes et leurs cadres de base. Le
lexique SYNLEX r&#233;sultant contient 5244 verbes et 19127 entr&#233;es (paires verbe - cadre) fai-
sant intervenir 726 cadres de sous-cat&#233;gorisation en consid&#233;rant les associ&#233;s et 538 cadres de
sous-cat&#233;gorisation sans associ&#233;s.
</p>
<p>3 Evaluation
</p>
<p>Comme nous l&#8217;avons mentionn&#233;, SYNLEX est produit &#224; partir des tables du LADL par un
processus de conversion faisant intervenir une repr&#233;sentation interm&#233;diaire. Or l&#8217;information
contenue dans les tables peut &#234;tre inexacte et la conversion dans le format SYNLEX peut intro-
duire des erreurs. Enfin, le lexique produit ne couvre ni l&#8217;ensemble des verbes du fran&#231;ais, ni
n&#233;cessairement, l&#8217;ensemble des entr&#233;es d&#8217;un verbe. Il est donc n&#233;cessaire &#224; la fois de valider et
de compl&#233;ter le lexique obtenu.
</p>
<p>Au cours des 15 derni&#232;res ann&#233;es, des travaux (Brent, 1991; Briscoe &amp; Carroll, 1997; Manning,
1993) ont montr&#233; qu&#8217;il est possible d&#8217;extraire un lexique syntaxique d&#8217;un corpus en utilisant
d&#8217;abord un analyseur puis un filtre statistique. L&#8217;id&#233;e est la suivante. Dans un premier temps,
un analyseur d&#233;terministe est utilis&#233; pour produire &#224; partir d&#8217;un corpus des hypoth&#232;ses sur les
cadres de sous-cat&#233;gorisation des verbes pr&#233;sents dans ce corpus. Plus pr&#233;cis&#233;ment, l&#8217;analyse
produite pour chaque proposition par l&#8217;analyseur est utilis&#233;e pour associer au verbe de la propo-
sition une description des syntagmes maximaux (groupe nominal, groupe pr&#233;positionnel, pro-
position infinitive, etc.) apparaissant avec ce verbe. Dans un deuxi&#232;me temps, les hypoth&#232;ses
sont soumises &#224; un calcul statistique et seules sont conserv&#233;es les hypoth&#232;ses pour lesquelles la
probabilit&#233; d&#8217;erreur est suffisament basse. Le lexique ainsi obtenu est ensuite &#233;valu&#233; (rappel et
pr&#233;cision) par rapport &#224; un lexique de r&#233;f&#233;rence valid&#233; manuellement.
</p>
<p>337</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ingrid FALK, Gil FRANCOPOULO, Claire GARDENT
</p>
<p>Nous utilisons ici les id&#233;es issues de ces travaux pour &#233;valuer la qualit&#233; de SYNLEX. D&#8217;une
part, nous montrons comment un lexique extrait d&#8217;un corpus (CORLEX) peut &#234;tre utilis&#233; pour
valider SYNLEX et l&#8217;enrichir. Le lexique r&#233;sultant est appel&#233; XSYNLEX. D&#8217;autre part, nous
comparons les trois lexiques ainsi cr&#233;&#233;s (SYNLEX, XSYNLEX et CORLEX) avec un corpus de
r&#233;f&#233;rence (REFLEX) extrait de DICOVALENCE.
</p>
<p>3.1 Comparaison et fusion avec un lexique acquis &#224; partir de corpus
</p>
<p>Afin d&#8217;&#233;valuer la pr&#233;cision et la couverture de SYNLEX, nous commen&#231;ons par le comparer
avec un lexique acquis automatiquement &#224; partir d&#8217;un corpus. Ce lexique (CORLEX) est acquis
selon la m&#233;thodologie d&#233;crite ci-dessus : un corpus et un analyseur sont d&#8217;abord utilis&#233;s pour
&#233;mettre des hypoth&#232;ses sur les entr&#233;es lexicales (association verbe - cadre) possibles. Ensuite,
ces hypoth&#232;ses sont soumises &#224; un calcul statistique permettant de classifier les hypoth&#232;ses en
hypoth&#232;ses plausibles et hypoth&#232;ses non plausibles. Dans ce qui suit, nous d&#233;taillons chacun de
ces proc&#233;d&#233;s.
</p>
<p>Cr&#233;ation des hypoth&#232;ses. Le corpus exploit&#233; est un corpus de 82 millions de mots avec 65%
d&#8217;articles de presse, 30 % de compte rendus de d&#233;bats parlementaires et 5% de textes litt&#233;raires.
</p>
<p>L&#8217;analyseur (TAGPARSER) est un analyseur robuste ascendant qui exploite des connaissances
tr&#232;s fines sur la combinaison des mots grammaticaux classifi&#233;s en 300 classes de mots simples
ou compos&#233;s (Francopoulo, 2005). Dans la version actuelle (version 1), mise &#224; part, une cat&#233;go-
risation binaire des adjectifs et l&#8217;indication comme quoi le verbe accepte ou non, une compl&#233;-
tive, l&#8217;analyseur n&#8217;utilise pas d&#8217;information portant sur la sous-cat&#233;gorisation des verbes et des
noms pr&#233;dicatifs. La technologie mise en oeuvre combine un automate et une matrice statistique
induite &#224; partir d&#8217;un corpus de 77 000 mots annot&#233;s en syntaxe de surface.
</p>
<p>Enfin notons que pour cette premi&#232;re exp&#233;rience, nous nous sommes limit&#233;s aux cadres qui sont
relativement faciles &#224; d&#233;tecter pendant l&#8217;analyse syntaxique i.e., les cadres ne faisant intervenir
ni la fonction oblique, ni la fonction attribut. En outre, les associ&#233;s (e.g., reflexif intrins&#232;que,
clitique fig&#233;) et les macros qui concernent des propri&#233;t&#233;s syntaxiques non d&#233;tectables par un ana-
lyseur (e.g.,ph&#233;nom&#232;nes de contr&#244;le, acceptation ou non pour les verbes transitifs de la forme
passive, etc.) ne sont pas pris en compte.
</p>
<p>L&#8217;analyse du corpus par TAGPARSER permet d&#8217;extraire 38 550 hypoth&#232;ses o&#249; chaque hypoth&#232;se
est l&#8217;association d&#8217;un verbe, d&#8217;un cadre et d&#8217;une fr&#233;quence d&#8217;apparition de cette association dans
le corpus.
</p>
<p>Filtrage des hypoth&#232;ses. Afin d&#8217;&#233;valuer la plausibilit&#233; des hypoth&#232;ses &#233;mises, nous utilisons
un test souvent mis en oeuvre (Brent, 1991; Briscoe &amp; Carroll, 1997; Manning, 1993) par
les approches portant sur l&#8217;acquisition automatique de lexiques &#224; savoir le test binomial sur les
hypoth&#232;ses (BHT). Ce test calcule la probabilit&#233; quem occurrences du cadre c apparaissent avec
un verbe v n&#8217;acceptant pas ce cadre, &#233;tant donn&#233; n occurrence de ce verbe. Plus la probabilit&#233;
est basse, plus l&#8217;hypoth&#232;se est douteuse et par cons&#233;quent, plus il est probable que c est un cadre
valide de v.
</p>
<p>En pratique, nous fixons &#224; 0.05% le seuil utilis&#233; pour d&#233;terminer si ou non une association verbe-
cadre apparait suffisament peu fr&#233;quemment pour &#234;tre une erreur. En d&#8217;autres termes, toutes les
</p>
<p>338</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;valuer SYNLEX
</p>
<p>FIG. 2 &#8211; R&#233;sultats
</p>
<p>hypoth&#232;ses pour lesquelles la probabilit&#233; d&#8217;erreur donn&#233;e par le test BHT est en dessous de
0.05% sont accept&#233;es comme valides &#8211; les autres sont rejet&#233;es. Pour calculer la probabilit&#233; d&#8217;er-
reur des hypoth&#232;ses &#233;mises, nous utilisons le UCS toolkit (http://www.collocations.
de/). Apr&#232;s filtrage, le lexique syntaxique obtenu (CORLEX) comporte 8 742 entr&#233;es.
</p>
<p>Comparaison et fusion des deux lexiques (SYNLEX et CORLEX). La figure 2 donne une
analyse d&#233;taill&#233;e des r&#233;sultats obtenus &#224; partir de l&#8217;analyse de corpus. Plus g&#233;n&#233;ralement, on
peut diviser et classifier les donn&#233;es suivant les crit&#232;res suivants1 :
</p>
<p>CONFIRM&#201; : les entr&#233;es pr&#233;sentes dans SYNLEX et dans CORLEX et pour lesquelles la pro-
babilit&#233; d&#8217;erreur est inf&#233;rieure &#224; 0.05% .
</p>
<p>INFIRM&#201; : les entr&#233;es pr&#233;sentes dans SYNLEX et dans CORLEX et pour lesquelles la probabi-
lit&#233; d&#8217;erreur est sup&#233;rieure &#224; 0.05% .
</p>
<p>AJOUT&#201; : les entr&#233;es absentes dans SYNLEX qui sont pr&#233;sentes dans CORLEX et pour les-
quelles la probabilit&#233; d&#8217;erreur est inf&#233;rieure &#224; 0.05% .
</p>
<p>1Les pourcentages sont donn&#233;s par rapport &#224; l&#8217;union de CORLEX et SYNLEX.
</p>
<p>339</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ingrid FALK, Gil FRANCOPOULO, Claire GARDENT
</p>
<p>JET&#201; : les entr&#233;es absentes dans SYNLEX qui sont pr&#233;sentes dans CORLEX et pour lesquelles
la probabilit&#233; d&#8217;erreur est sup&#233;rieure &#224; 0.05% .
</p>
<p>IMPROBABLE : les entr&#233;es pr&#233;sentes dans SYNLEX absentes dans CORLEX et pour lesquels
le verbe impliqu&#233; apparait plus de 5 000 fois dans le corpus.
</p>
<p>PEUTETREPAS : les entr&#233;es pr&#233;sentes dans SYNLEX absentes dans CORLEX et pour lesquels
le verbe impliqu&#233; apparait moins de 5 000 fois dans le corpus.
</p>
<p>La classe CONFIRM&#201; permet de valider la partie de SYNLEX trouv&#233;e en corpus et valid&#233;e par
les statistiques. Inversement, la classe INFIRM&#201; permet de d&#233;tecter les entr&#233;es de SYNLEX
qui sont sans doute incorrectes. Les donn&#233;es montrent en particulier, que sur la base de cette
analyse, plus de la moiti&#233; des entr&#233;es de SYNLEX sont jug&#233;es incorrectes.
</p>
<p>Par ailleurs, la classe AJOUT&#201; permet d&#8217;&#233;tendre SYNLEX avec les entr&#233;es jug&#233;es fiables par
l&#8217;analyse de corpus mais non contenues par SYNLEX. Ceci permet d&#8217;augmenter le nombre
d&#8217;entr&#233;es de SYNLEX de 34.56%.
</p>
<p>Enfin, les classes IMPROBABLE et PEUTETREPAS regroupent les entr&#233;es de SYNLEX qui n&#8217;ap-
paraissent pas dans les donn&#233;es extraites du corpus. Les IMPROBABLE sont des cas o&#249; le verbe
consid&#233;r&#233; appara&#238;t plus de 5 000 fois dans le corpus mais jamais avec le cadre prescrit par SYN-
LEX. Ils sont &#233;limin&#233;s de SYNLEX. Si le verbe apparait moins de 5 000 fois dans le corpus,
l&#8217;entr&#233;e est conserv&#233;e mais &#233;tiquett&#233;e comme peu fiable (PEUTETREPAS).
</p>
<p>En r&#233;sum&#233;, la fusion XSYNLEX de SYNLEX avec CORLEX peut &#234;tre d&#233;finie par l&#8217;union de
CONFIRM&#201; avec AJOUT&#201; :
</p>
<p>XSYNLEX = CONFIRM&#201; &#8746; AJOUT&#201; &#8746; PEUTETREPAS
</p>
<p>Cependant, cette fusion ne garantit pas un lexique parfait. En effet, la validation statistique
reste imparfaite. Par exemple, les meilleurs lexiques extraits pour l&#8217;anglais avec des m&#233;thodes
similaires &#224; celle utilis&#233;e ici ont une F-mesure maximum tournant autour de 80 % . La deuxi&#232;me
&#233;tape a donc consist&#233; &#224; &#233;valuer les diff&#233;rents lexiques (SYNLEX, CORLEX et XSYNLEX) en
mesurant leur rappel et pr&#233;cision par rapport &#224; un lexique de r&#233;f&#233;rence REFLEX. L&#8217;objectif
est de d&#233;terminer si l&#8217;extension de SYNLEX par les donn&#233;es issues de CORLEX accroit non
seulement le nombre d&#8217;entr&#233;es mais &#233;galement la qualit&#233; du lexique r&#233;sultant.
</p>
<p>3.2 &#201;valuation de SYNLEX sur un lexique de r&#233;f&#233;rence
</p>
<p>Une fa&#231;on de d&#233;terminer la qualit&#233; d&#8217;un lexique consiste &#224; calculer son rappel et sa pr&#233;cision
par rapport &#224; un lexique de r&#233;f&#233;rence. Soit Acquis le contenu du lexique &#224; &#233;valuer et Ref celui
du lexique de r&#233;f&#233;rence, pr&#233;cision et rappel sont d&#233;finis de la fa&#231;on suivante :
</p>
<p>Pr&#233;cision
P =
</p>
<p>Acquis &#8745;Ref
Acquis
</p>
<p>La pr&#233;cision indique la proportion d&#8217;entr&#233;es correctes dans le lexique acquis (combien
d&#8217;entr&#233;es sont correctes ?)
</p>
<p>340</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;valuer SYNLEX
</p>
<p>Rappel
R =
</p>
<p>Acquis &#8745;Ref
Ref
</p>
<p>Le rappel indique la proportion entre entr&#233;es correctes pr&#233;sentes dans le lexique acquis
et entr&#233;es pr&#233;sentes dans le lexique de r&#233;f&#233;rence (combien d&#8217;entr&#233;es correctes ont &#233;t&#233;
trouv&#233;es ?).
</p>
<p>Calcul du rappel et de la pr&#233;cision. Pour l&#8217;&#233;valuation, nous avons s&#233;lectionn&#233; 100 verbes
pr&#233;sents dans tous les lexiques (i.e., SYNLEX, XSYNLEX, DICOVALENCE et CORLEX) et
distribu&#233;s de fa&#231;on r&#233;guli&#232;re sur l&#8217;&#233;chelle du nombre d&#8217;apparition dans le corpus.
</p>
<p>Pour chacun de ces 100 verbes, nous avons cr&#233;&#233; un lexique de r&#233;f&#233;rence REFLEX &#224; partir de
DICOVALENCE. Les entr&#233;es de ces verbes ont &#233;t&#233; &#233;pur&#233;es des entr&#233;es non prises en compte
dans CORLEX (c-&#224;-d, les entr&#233;es faisant intervenir des arguments obliques ou attributifs) puis
traduites dans le format SYNLEX (cf. Figure 1) afin de permettre une comparaison automatique
avec SYNLEX, XSYNLEX et CORLEX.
</p>
<p>Les performances des statistiques ont &#233;t&#233; &#233;valu&#233;es sur ces 100 verbes &#224; travers quatre exp&#233;-
riences visant &#224; mesurer l&#8217;impact de la fr&#233;quence d&#8217;un cadre sur ces performances.
</p>
<p>Etant donn&#233; C le nombre total d&#8217;entr&#233;es pr&#233;sentes dans CORLEX, la fr&#233;quence fc d&#8217;un cadre
c est dite HAUTE si c apparait dans plus de 1% des entr&#233;es de CORLEX (fc &#8805; 0.01 &#215; C) ;
MOYENNE si 0.001&#215; C &#8804; fc &#8804; 0.01&#215; C ; et BASSE si fc &#8804; 0.0001&#215; C .
Pour chaque lexique (SYNLEX, XSYNLEX et REFLEX), quatre (sous-)lexiques sont cr&#233;&#233;s : un
premier contenant toutes les entr&#233;es du lexique (TOUT) et trois autres contenant uniquement les
entr&#233;es faisant intervenir des cadres de haute (HF), moyenne (MF) et basse (BF) fr&#233;quence. La
r&#233;f&#233;rence minimum (baseline) est fix&#233;e comme &#233;tant le lexique acquis &#224; partir du corpus sans
filtrage statistique (toutes les entr&#233;es trouv&#233;es par TAGPARSER sont prises en compte).
</p>
<p>Le rappel et la pr&#233;cision pour chacun des 5 cas consid&#233;r&#233;s sont donn&#233;s dans la Figure 3.
</p>
<p>Discussion. Ces premiers r&#233;sultats montrent que pour l&#8217;&#233;chantillon de cadres consid&#233;r&#233;s (les
cadres ne faisant pas intervenir d&#8217;obliques ou d&#8217;attributs), la couverture et la pr&#233;cision de SYN-
LEX sont relativement bas. La couverture faible n&#8217;est pas surprenante et s&#8217;explique du fait de
l&#8217;incompl&#233;tude inh&#233;rente aux tables du LADL puisque seules 60% des tables sont disponibles.
</p>
<p>La mauvaise pr&#233;cision est en revanche plus surprenante mais peut, peut &#234;tre, &#234;tre expliqu&#233;e par
la relative permissivit&#233; des tables du LADL : si une construction est possible pour un verbe
donn&#233;, elle sera marqu&#233;e comme telle m&#234;me si elle est tr&#232;s rare.
</p>
<p>Un autre facteur contribuant &#224; diminuer la pr&#233;cision concerne la d&#233;cision de ne pas prendre
en compte les associ&#233;s c-&#224;-d, les arguments r&#233;gis par le verbe mais ne remplissant pas de r&#244;le
s&#233;mantique. Or parmi ces associ&#233;s, on trouve le clitique r&#233;fl&#233;chi intrins&#232;que (e.g., se dans s&#8217;&#233;va-
nouir). En cons&#233;quence, toutes les entr&#233;es faisant intervenir un clitique intrins&#232;que (l&#8217;associ&#233;
CLR) sont trait&#233;es de fa&#231;on incorrecte comme des entr&#233;es sans ce clitique.
</p>
<p>Malgr&#233; tout, un examen plus approfondi des cas fautifs reste &#224; faire pour d&#233;terminer les causes
pr&#233;cises de ce manque de pr&#233;cision et &#233;ventuellement, y rem&#233;dier.
</p>
<p>Le rappel et la pr&#233;cision de XSYNLEX , le lexique enrichi &#224; partir du corpus, sont relativement
</p>
<p>341</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ingrid FALK, Gil FRANCOPOULO, Claire GARDENT
</p>
<p>TOUT HF MF LF
</p>
<p>SYNLEX P 0.30 0.63 0.16 0.02
R 0.44 0.45 0.47 0.3
F 0.37 0.54 0.31 0.16
</p>
<p>XSYNLEX P 0.58 0.69 0.23 0.29
R 0.63 0.66 0.56 0.5
F 0.59 0.67 0.4 0.4
</p>
<p>XSYNLEX + INFIRM&#201; P 0.49 0.61 0.21 0.27
R 0.76 0.78 0.67 0.5
F 0.62 0.70 0.44 0.38
</p>
<p>BASELINE P 0.22 0.29 0.07 0.15
R 0.89 0.95 0.70 0.5
F 0.56 0.62 0.39 0.32
</p>
<p>FIG. 3 &#8211; Pr&#233;cision et rappel
</p>
<p>bas mais proches de certains r&#233;sultats obtenus dans la lit&#233;rature pour des langues autres que
l&#8217;anglais. (Fast &amp; Przepi&#243;rkowski, 2005) par exemple, cite un rappel de 47% et une pr&#233;cision de
49% pour une exp&#233;rience similaire sur le polonais. Pour ce lexique, le rappel et la pr&#233;cision sont
meilleurs que pour SYNLEX. En d&#8217;autres termes, le lexique extrait du corpus permet de valider
et d&#8217;&#233;tendre la partie de SYNLEX faisant intervenir les cadres consid&#233;r&#233;s pour l&#8217;acquisition
automatique.
</p>
<p>Enfin, les donn&#233;es concernant XSYNLEX+ INFIRM&#201; montrent qu&#8217;ignorer la plausibilit&#233; statis-
tique des hypoth&#232;ses (i.e., conserver les entr&#233;es de SYNLEX qui sont infirm&#233;es par les statis-
tiques) permet d&#8217;am&#233;liorer le rappel (0.76 contre 0.63 dans XSYNLEX) au d&#233;triment bien s&#251;r
de la pr&#233;cision (0.49 contre 0.58 dans XSYNLEX).
</p>
<p>4 Conclusion et perspectives
</p>
<p>Comme nous l&#8217;avons mentionn&#233; dans l&#8217;introduction, trois lexiques syntaxiques sont actuelle-
ment disponibles et utilisables dans le domaine du traitement automatique des langues. Cepen-
dant, ils sont tous incomplets et leur contenu n&#8217;a pas fait l&#8217;objet d&#8217;une &#233;valuation permettant de
d&#233;terminer rappel et pr&#233;cision.
</p>
<p>Le travail pr&#233;sent&#233; dans cet article est un premier pas vers la d&#233;finition d&#8217;une proc&#233;dure d&#8217;&#233;va-
luation et de fusion de ces lexiques.
</p>
<p>Il montre en particulier que DICOVALENCE peut servir de base &#224; la cr&#233;ation d&#8217;un lexique de
r&#233;f&#233;rence permettant ainsi de calculer le rappel et la pr&#233;cision de lexiques cr&#233;&#233;s de fa&#231;on auto-
matique ou semi-automatique.
</p>
<p>Il montre &#233;galement, qu&#8217;un lexique acquis &#224; partir d&#8217;un corpus peut permettre d&#8217;am&#233;liorer la
</p>
<p>342</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;valuer SYNLEX
</p>
<p>couverture et la pr&#233;cision d&#8217;un lexique existant ; et plus g&#233;n&#233;ralement, que la comparaison et
la fusion de plusieurs lexiques pourrait permettre &#224; relativement court terme de produire un
lexique syntaxique du fran&#231;ais complet et de bonne qualit&#233;.
</p>
<p>N&#233;anmoins, plusieurs aspects m&#233;ritent d&#8217;&#234;tre approfondis.
</p>
<p>Tout d&#8217;abord, notons que l&#8217;&#233;valuation de SYNLEX pr&#233;sent&#233;e ici est tr&#232;s partielle puisqu&#8217;elle ne
porte que sur 33 des 726 cadres pr&#233;sents dans SYNLEX. Une &#233;valuation plus extensive prenant
en compte les obliques et les attributs est donc n&#233;cessaire.
</p>
<p>Un second point concerne la proc&#233;dure d&#8217;acquisition automatique. En effet, l&#8217;approche pr&#233;sen-
t&#233;e ici est une approche pr&#233;liminaire qui peut &#234;tre am&#233;lior&#233;e sur au moins deux points &#224; savoir,
la qualit&#233; des hypoth&#232;ses &#233;mises d&#8217;une part et la qualit&#233; du filtre statistique d&#8217;autre part.
</p>
<p>Les hypoth&#232;ses &#233;mises peuvent &#234;tre affin&#233;es par l&#8217;emploi d&#8217;un analyseur plus performant &#8211; par
exemple, en utilisant une information de sous-cat&#233;gorisation pour informer l&#8217;analyseur ou en-
core en utilisant un analyseur profond plut&#244;t que local. Une autre possibilit&#233; que nous entendons
explorer prochainement, est d&#8217;utiliser plusieurs analyseurs en parall&#232;le et de comparer/fusionner
leurs r&#233;sultats par un syst&#232;me de vote.
</p>
<p>Les travaux fait sur l&#8217;anglais sugg&#232;rent en outre que le filtre statistique peut &#234;tre am&#233;lior&#233; de
deux fa&#231;ons. Ainsi (Briscoe &amp; Carroll, 1997) montre que le seuil permettant de d&#233;terminer
l&#8217;acceptabilit&#233; d&#8217;une hypoth&#232;se doit &#234;tre fix&#233; diff&#233;remment suivant le type de cadre consid&#233;r&#233;
plut&#244;t que de fa&#231;on uniforme pour l&#8217;ensemble des hypoth&#232;ses comme nous l&#8217;avons fait ici. Et
(Korhonen, 2002) montre que l&#8217;utilisation de techniques de lissages inform&#233;es par les classes
s&#233;mantiques de verbes permet d&#8217;am&#233;liorer les r&#233;sultats. L&#8217;exploitation de ces r&#233;sultats devrait
permettre d&#8217;am&#233;liorer la qualit&#233; du lexique extrait.
</p>
<p>Une troisi&#232;me point, plus ouvert celui-l&#224;, concerne l&#8217;&#233;largissement des m&#233;thodes explor&#233;es &#224;
l&#8217;ensemble du lexique et en particulier au traitement des macros. Comme nous l&#8217;avons vu,
SYNLEX, LEFFF et DICOVALENCE contiennent outre des informations portant sur la valence
(arguments r&#233;gis par le verbe remplissant ou non un r&#244;le s&#233;mantique), des informations portant
sur les ph&#233;nom&#232;nes de contr&#244;le, la passivation, la possibilit&#233; pour un verbe d&#8217;&#234;tre utilis&#233; dans
une tournure impersonnelle, etc. Si elles sont utiles pour le traitement automatique des langues
et en particulier, pour l&#8217;analyse et la r&#233;alisation de surface, ces informations ne peuvent pas &#234;tre
extraites &#224; partir des corpus par les techniques utilis&#233;es en acquisition automatique de lexique.
Elles sont en revanche partiellement pr&#233;sentes dans les lexiques existants (LEFFF, DICOVA-
LENCE et SYNLEX). Une question int&#233;ressante est donc de savoir comment cette information
peut &#234;tre utilis&#233;e pour informer la compl&#233;tion d&#8217;un lexique partiellement sous-sp&#233;cifi&#233; dans
cette dimension. Ou en d&#8217;autres termes, comment un lexique acquis &#224; partir de corpus peut &#234;tre
fusionn&#233; avec un ou des lexiques acquis par des m&#233;thodes &#171;symboliques&#187; (LEFFF, SYNLEX)
de fa&#231;on &#224; enrichir la partie acquise statistiquement avec l&#8217;information additionnelle contenue
dans les lexiques symboliques.
</p>
<p>Dans tous les cas, la pr&#233;cision relativement basse des lexiques produits sugg&#232;re qu&#8217;une phase de
validation manuelle est n&#233;cessaire. Dans cette optique, une approche qui consiste &#224; privil&#233;gier
(dans une juste mesure) le rappel plut&#244;t que la pr&#233;cision est sans doute pr&#233;f&#233;rable (il est plus
facile d&#8217;&#233;liminer que d&#8217;ajouter). Ce qui sugg&#232;re en particulier, que XSYNLEX+ INFIRM&#201; est
pr&#233;f&#233;rable &#224; XSYNLEX et plus sp&#233;cifiquement, que l&#8217;extraction de SYNLEX &#224; partir des tables
est utile.
</p>
<p>343</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ingrid FALK, Gil FRANCOPOULO, Claire GARDENT
</p>
<p>R&#233;f&#233;rences
BOONS J.-P., GUILLET A. &amp; LECL&#200;RE C. (1976). La structure des phrases simples en
fran&#231;ais. I : Constructions intransitives. Droz, Gen&#232;ve.
BRENT M. (1991). Automatic acquisition of subcategorisation frames from untagged text. In
Proceedings of the 29th Meeting of the ACL, p. 209&#8211;214, Berkeley.
BRISCOE T. &amp; CARROLL J. (1997). Automatic extraction of subcategorisation from corpora.
In Proceedings of the 5th ANLP conference, p. 356&#8211;363.
CARROLL J. &amp; FANG A. (2004). The automatic acquisition of verb subcategorisations and
their impact on the performance of an HPSG parser. In Proceedings of the 1st International
Joint Conference on Natural Language Processing (IJCNLP), p. 107&#8211;114, Sanya City, China.
CL&#201;MENT L., SAGOT B. &amp; LANG B. (2004). Morphology based automatic acquisition of
large-coverage lexica. In Proceedings of LREC&#8217;04, Lisbonne.
FAST J. &amp; PRZEPI&#211;RKOWSKI A. (2005). Automatic extraction of polish verb subcategorisa-
tion. an evaluation of common statistics. In Proceedings of the 2nd Language and Technology
conference, p. 191&#8211;195.
FRANCOPOULO G. (2005). Tagparser et technolangue-easy. In Actes de l&#8217;atelier Easy, TALN.
GARDENT C., GUILLAUME B., PERRIER G. &amp; FALK I. (2005a). Extracting subcategori-
sation information from Maurice Gross&#8217; Grammar Lexicon. Archives of Control Sciences,
15(LI), 253&#8211;264.
GARDENT C., GUILLAUME B., PERRIER G. &amp; FALK I. (2005b). Maurice gross&#8217; grammar
lexicon and natural language processing. In Proceedings of the 2nd Language and Technology
Conference, Poznan, Poland.
GARDENT C., GUILLAUME B., PERRIER G. &amp; FALK I. (2006). Extraction d&#8217;information de
sous-cat&#233;gorisation &#224; partir des tables du ladl. In Actes de La 13&#232;me &#233;dition de la conf&#233;rence
sur le Traitement Automatique des Langues Naturelles (TALN 2006).
GROSS M. (1975). M&#233;thodes en syntaxe. Hermann.
GUILLET A. &amp; LECL&#200;RE C. (1992). La structure des phrases simples en fran&#231;ais. Construc-
tions transitives locatives. Droz, Gen&#232;ve.
KORHONEN A. (2002). Subcategorization Acquisition. PhD thesis, University of Cambridge.
MANNING C. (1993). Automatic acquisition of a large subcategorisation dictionary from
corpora. In Proceedings of the 31st Meeting of the ACL.
ROMARY L., SALMON-ALT S. &amp; FRANCOPOULO G. (2004). Standards going concrete :
from LMF to morphalou. In Workshop on Electronic Dictionaries, Geneva, Switzerland.
VAN DEN EYNDE K. &amp; MERTENS P. (2003). La valence : l&#8217;approche pronominale et son
application au lexique verbal. Journal of French Language Studies 13, 63-104.
</p>
<p>344</p>

</div></div>
</body></html>