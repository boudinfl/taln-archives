TALN 2007, Toulouse, 5-8 juin 2007

Evaluer SYNLEX

Ingrid FALK1, Gil FRANCOPOULO2, Claire GARDENT3
1 CNRS/ATILF, Nancy
2 INRIA/LORIA, Nancy
3 CNRS/LORIA, Nancy
{Ingrid.Falk,Claire.Gardent}@loria.fL
Gil.Francopoulo@wanadoo.fr

Résumé. SYNLEX est un lexique syntaxique extrait semi—automatiquement des tables du
LADL. Comme les autres lexiques syntaxiques du francais disponibles et utilisables pour le
TAL (LEFFF, DICOVALENCE), il est incomplet et n’a pas fait l’objet d’une évaluation permet-
tant de déterminer son rappel et sa précision par rapport a un lexique de référence. Nous pre-
sentons une approche qui permet de combler au moins partiellement ces lacunes. L’approche
s’appuie sur les méthodes mises au point en acquisition automatique de lexique. Un lexique
syntaxique distinct de SYNLEX est acquis a partir d’un corpus de 82 millions de mots puis uti-
lisé pour valider et compléter SYNLEX. Le rappel et la précision de cette version améliorée de
SYNLEX sont ensuite calculés par rapport a un lexique de référence extrait de DICOVALENCE.

Abstract. SYNLEX is a syntactic lexicon extracted semi—automatically from the LADL
tables. Like the other syntactic lexicons for French which are both available and usable for NLP
(LEFFF, DICOVALENCE), it is incomplete and its recall and precision wrt a gold standard are
unknown. We present an approach which goes some way towards adressing these shortcomings.
The approach draws on methods used for the automatic acquisition of syntactic lexicons. First,
a new syntactic lexicon is acquired from an 82 million words corpus. This lexicon is then used
to validate and extend SYNLEX. Finally, the recall and precision of the extended version of
SYNLEX is computed based on a gold standard extracted from DICOVALENCE.

Mots-clés I lexique syntaxique, évaluation.

Keywords: syntactic lexicon, evaluation.

1 Introduction

Un lexique syntaxique décrit les propriétés syntaxiques des mots d’une langue. En particulier,
un lexique syntaxique associe a chaque foncteur syntaxique un cadre de s0us—cate’g0risati0n
spéciﬁant le nombre et le type (catégorie syntaxique, marqueur introductif, mode, etc.) de ses
arguments.

Comme l’ont montré (Carroll & Fang, 2004), un lexique syntaxique exhaustif et détaillé per-
met d’améliorer les performances des analyseurs syntaxiques. Un tel lexique est également une
composante essentielle de tout réalisateur de surface puisqu’il permet de réaliser un contenu

335

Ingrid FALK, Gil FRANCOPOULO, Claire GARDENT

semantique donne par une phrase bien formee et en particulier, une phrase ou chaque foncteur
syntaxique a le nombre et le type d’arguments requis par son regime. Plus generalement, un
lexique syntaxique est une composante de base pour tout systeme faisant intervenir soit l’ana—
lyse, soit la realisation.

Pour le francais, il existe a l’heure actuelle trois lexiques syntaxiques disponibles librement
et utilisables par des systemes de traitement automatique des langues : Proton recemment re-
nomme DicoValence, (van den Eynde & Mertens, 2003), Lefff (Clement et al., 2004) et SYN-
LEX (Gardent et al., 2006). Neanmoins aucun de ces lexiques n’est entierement satisfaisant
pour deux raisons.

Premierement, aucun de ces lexiques ne couvre l’ensemble des verbes du francais. Ainsi pour
8 790 verbes identiﬁes pour le francais dans Morphalou (Romary et al., 2004), DicoValence
inclut 3 700 verbes, Lefff6 798 et SYNLEX 5244.

Deuxiemement, la qualite de leur contenu et plus precisement, leur rappel et leur precision
restent inconnus : Pour l’ensemble des entrees contenues dans chacun de ses dictionnaires,
on ne connait ni quelle proportion des entrees correctes est presente (rappel) ni quelle est la
proportion d’entrees incorrectes (precision).

Dans cet article, nous considerons SYNLEX et presentons une approche qui vise a pallier ces
lacunes. L’approche s’appuie sur les methodes mises au point en acquisition automatique de
lexique. Un lexique syntaxique (CORLEX) distinct de SYNLEX est acquis a partir d’un corpus
de 82 millions de mots. Ce lexique est ensuite utilise pour valider et completer SYNLEX. Le
rappel et la precision de SYNLEX, de la version amelioree de SYNLEX et de CORLEX sont
ensuite calcules par rapport a un lexique de reference extrait de DICOVALENCE.

L’article est structure comme suit. La section 2 decrit le processus de creation de SYNLEX et
presente son format et son contenu. La section 3 presente les travaux visant a valider et a etendre
SYNLEX puis commente les resultats obtenus. La section 4 conclut en indiquant les directions
de recherche futures.

2 Synlex

Synlex est un lexique cree a partir des tables du LADL (Gross, 1975; Guillet & Leclere, 1992;
Boons et al., 1976). Le processus de creation a ete decrit dans (Gardent et al., 2005b; Gardent
et al., 2006; Gardent et al., 2005a) et peut etre resume comme suit :

l. une representation du contenu des colonnes des tables et de leurs interdependance est
creee manuellement sous la forme d’un graphe et/014 dont les noeuds contiennent a la fois
des conditions et des pointeurs vers le contenu des colonnes

2. ce graphe et/014 est ensuite utilise en conjonction avec les tables pour produire de facon
automatique un lexique syntaxique representant leur contenu

3. ce lexique est ensuite simpliﬁe pour ne contenir que le type d’information habituellement
presente dans un lexique syntaxique (i.e., nombre et types de syntagmes sous—categorises
par les verbes)

Le format des entrees de SYNLEX est speciﬁe dans la ﬁgure 1 et peut etre decrit comme suit.
Une entree se compose d’un verbe, d’une liste d’arguments syntaxiques ayant un role seman-

336

Evaluer SYNLEX

tique, d’une liste optionnelle d’associe’s c—a—d, d’arguments régis par le verbe mais ne remplis—
sant pas de role sémantique (e.g., l’explétive il dans il pleut) et d’une liste de macros donnant
des informations supplémentaires sur les propriétés syntaxiques du verbes (e.g., controle, pas-
sivisation). Les associe’s et les macros sont des listes ﬁnies d’atomes. Un argument en revanche
est déﬁni par un triplet de la forme F :M—C ou F est une fonction grammaticale, M un mar-
queur optionnel (une préposition ou un clitique indiquant la cliticisation d’un argument en cas
d’ambiguité comme par exemple les arguments en a qui peuvent se cliticiser soit en 3/, soit en
lui) et C est une catégorie syntaxique.

Entree ::: Verb: (Arg+), Associe*,Macro* (l)
Arg ': Fonction :Marqueur — Categorie (2)
Fonction ': suj | obj | obja | objde | obl | attr (3)
Marqueur ': Prep | Clitic | Compl (4)
Categorie ': sn | pinf | pcompl | qcompl (5)
Associe ::: ilimp | cln | cla | cld | clg | pron (6)
Macro ::: CtrlArgXArgY | passivable | nonPassivable (7)

FIG. 1 — SynLex Format

Seules 60% des tables du LADL étant disponibles, nous avons complété manuellement le
lexique extrait des tables disponibles avec environ 2 000 verbes et leurs cadres de base. Le
lexique SYNLEX résultant contient 5244 verbes et 19127 entrées (paires verbe — cadre) fai-
sant intervenir 726 cadres de sous—catégorisation en considérant les associés et 538 cadres de
sous—catégorisation sans associés.

3 Evaluation

Comme nous l’avons mentionné, SYNLEX est produit a partir des tables du LADL par un
processus de conversion faisant intervenir une representation intermédiaire. Or l’information
contenue dans les tables peut étre inexacte et la conversion dans le format SYNLEX peut intro-
duire des erreurs. Enﬁn, le lexique produit ne couvre ni l’ensemble des verbes du francais, ni
nécessairement, l’ensemble des entrées d’un verbe. Il est donc nécessaire a la fois de valider et
de compléter le lexique obtenu.

Au cours des 15 dernieres années, des travaux (Brent, 1991; Briscoe & Carroll, 1997; Manning,
1993) ont montré qu’il est possible d’extraire un lexique syntaxique d’un corpus en utilisant
d’abord un analyseur puis un ﬁltre statistique. L’idée est la suivante. Dans un premier temps,
un analyseur déterministe est utilisé pour produire a partir d’un corpus des hypotheses sur les
cadres de sous—catégorisation des verbes présents dans ce corpus. Plus précisément, l’analyse
produite pour chaque proposition par l’analyseur est utilisée pour associer au verbe de la propo-
sition une description des syntagmes maximaux (groupe nominal, groupe prépositionnel, pro-
position inﬁnitive, etc.) apparaissant avec ce verbe. Dans un deuxieme temps, les hypotheses
sont soumises a un calcul statistique et seules sont conservées les hypotheses pour lesquelles la
probabilité d’erreur est sufﬁsament basse. Le lexique ainsi obtenu est ensuite évalué (rappel et
précision) par rapport a un lexique de référence validé manuellement.

337

Ingrid FALK, Gil FRANCOPOULO, Claire GARDENT

Nous utilisons ici les idees issues de ces travaux pour evaluer la qualite de SYNLEX. D’une
part, nous montrons comment un lexique extrait d’un corpus (CORLEX) peut etre utilise pour
valider SYNLEX et l’enrichir. Le lexique resultant est appele XSYNLEX. D’autre part, nous
comparons les trois lexiques ainsi crees (S YNLEX, XSYNLEX et CORLEX) avec un corpus de
reference (REFLEX) extrait de DICOVALENCE.

3.1 Comparaison et fusion avec un lexique acquis it partir de corpus

Aﬁn d’evaluer la precision et la couverture de SYNLEX, nous commencons par le comparer
avec un lexique acquis automatiquement a partir d’un corpus. Ce lexique (CORLEX) est acquis
selon la methodologie decrite ci—dessus : un corpus et un analyseur sont d’abord utilises pour
emettre des hypotheses sur les entrees lexicales (association verbe — cadre) possibles. Ensuite,
ces hypotheses sont soumises a un calcul statistique permettant de classiﬁer les hypotheses en
hypotheses plausibles et hypotheses non plausibles. Dans ce qui suit, nous detaillons chacun de
ces procedes.

Creation des hypotheses. Le corpus exploite est un corpus de 82 millions de mots avec 65%
d’articles de presse, 30 % de compte rendus de debats parlementaires et 5% de textes litteraires.

L’analyseur (TAGPARSER) est un analyseur robuste ascendant qui exploite des connaissances
tres ﬁnes sur la combinaison des mots grammaticaux classiﬁes en 300 classes de mots simples
ou composes (Francopoulo, 2005). Dans la version actuelle (version 1), mise a part, une catego-
risation binaire des adjectifs et l’indication comme quoi le verbe accepte ou non, une comple-
tive, l’analyseur n’utilise pas d’information portant sur la sous—categorisation des verbes et des
noms predicatifs. La technologie mise en oeuvre combine un automate et une matrice statistique
induite a partir d’un corpus de 77 000 mots annotes en syntaxe de surface.

Enﬁn notons que pour cette premiere experience, nous nous sommes limites aux cadres qui sont
relativement faciles a detecter pendant l’analyse syntaxique i.e., les cadres ne faisant intervenir
ni la fonction oblique, ni la fonction attribut. En outre, les associes (e.g., reﬂexif intrinseque,
clitique ﬁge) et les macros qui concernent des proprietes syntaxiques non detectables par un ana-
lyseur (e.g.,phenomenes de controle, acceptation ou non pour les verbes transitifs de la forme
passive, etc.) ne sont pas pris en compte.

L’ analyse du corpus par TAGPARSER permet d’extraire 38 550 hypotheses ou chaque hypothese
est l’association d’un verbe, d’un cadre et d’une frequence d’apparition de cette association dans
le corpus.

F iltrage des hypotheses. Aﬁn d’evaluer la plausibilite des hypotheses emises, nous utilisons
un test souvent mis en oeuvre (Brent, 1991; Briscoe & Carroll, 1997; Manning, 1993) par
les approches portant sur l’acquisition automatique de lexiques a savoir le test binomial sur les
hypotheses (BHT). Ce test calcule la probabilite que m occurrences du cadre c apparaissent avec
un verbe 11 n’acceptant pas ce cadre, etant donne n occurrence de ce verbe. Plus la probabilite
est basse, plus l’hypothese est douteuse et par consequent, plus il est probable que c est un cadre
valide de 11.

En pratique, nous ﬁxons a 0.05% le seuil utilise pour determiner si ou non une association verbe-
cadre apparait sufﬁsament peu frequemment pour etre une erreur. En d’autres termes, toutes les

338

Evaluer SYNLEX

  

PEUTETREPFIS 525

IMPRDBFIBLE oz JETE 532

I’—‘IJ|I|UTE 163

CIIINFIRHE

FIG. 2 — Résultats

hypotheses pour lesquelles la probabilité d’erreur donnée par le test BHT est en dessous de
0.05% sont acceptées comme valides — les autres sont rejetées. Pour calculer la probabilité d’er—
reur des hypotheses émises, nous utilisons le UCS toolkit (http : / /www . collocations .
de /). Apres ﬁltrage, le lexique syntaxique obtenu (CORLEX) comporte 8 742 entrées.

Comparaison et fusion des deux lexiques (SYNLEX et CORLEX). La ﬁgure 2 donne une
analyse détaillée des résultats obtenus :21 partir de l’analyse de corpus. Plus généralement, on
peut diviser et classiﬁer les données suivant les criteres suivantsl :

CONFIRME : les entrées présentes dans SYNLEX et dans CORLEX et pour lesquelles la pro-
babilité d’erreur est inférieure :21 0.05% .

INFIRME : les entrées présentes dans SYNLEX et dans CORLEX et pour lesquelles la probabi-
lité d’erreur est supérieure 51 0.05% .

AJOUTE : les entrées absentes dans SYNLEX qui sont présentes dans CORLEX et pour les-
quelles la probabilité d’erreur est inférieure :21 0.05% .

1Les pourcentages sont donnés par rapport é11’union de CORLEX et SYNLEX.

339

Ingrid FALK, Gil FRANCOPOULO, Claire GARDENT

J ETE : les entrées absentes dans SYNLEX qui sont présentes dans CORLEX et pour lesquelles
la probabilité d’erreur est supérieure a 0.05% .

IMPROBABLE : les entrées présentes dans SYNLEX absentes dans CORLEX et pour lesquels
le verbe impliqué apparait plus de 5 000 fois dans le corpus.

PEUTETREPAS : les entrées présentes dans SYNLEX absentes dans CORLEX et pour lesquels
le verbe impliqué apparait moins de 5 000 fois dans le corpus.

La classe CONFIRME permet de valider la partie de SYNLEX trouvée en corpus et validée par
les statistiques. Inversement, la classe INFIRME permet de détecter les entrées de SYNLEX
qui sont sans doute incorrectes. Les données montrent en particulier, que sur la base de cette
analyse, plus de la moitié des entrées de SYNLEX sont jugées incorrectes.

Par ailleurs, la classe AJOUTE permet d’étendre SYNLEX avec les entrées jugées ﬁables par
l’analyse de corpus mais non contenues par SYNLEX. Ceci permet d’augmenter le nombre
d’entrées de SYNLEX de 34.56%.

Enﬁn, les classes IMPROBABLE et PEUTETREPAS regroupent les entrées de SYNLEX qui n’ap—
paraissent pas dans les données extraites du corpus. Les IMPROBABLE sont des cas ou le verbe
considéré apparait plus de 5 000 fois dans le corpus mais jamais avec le cadre prescrit par SYN-
LEX. Ils sont éliminés de SYNLEX. Si le verbe apparait moins de 5 000 fois dans le corpus,
l’entrée est conservée mais étiquettée comme peu ﬁable (PEUTETREPAS).

En résumé, la fusion XSYNLEX de SYNLEX avec CORLEX peut étre déﬁnie par l’union de
CONFIRME avec AJOUTE :

XSYNLEX = CONFIRME U AJOUTE U PEUTETREPAS

Cependant, cette fusion ne garantit pas un lexique parfait. En effet, la validation statistique
reste imparfaite. Par exemple, les meilleurs lexiques extraits pour l’anglais avec des méthodes
similaires a celle utilisée ici ont une F—mesure maximum toumant autour de 80 % . La deuxieme
étape a done consisté a évaluer les différents lexiques (S YNLEX, CORLEX et XSYNLEX) en
mesurant leur rappel et précision par rapport a un lexique de référence REFLEX. L’objectif
est de déterminer si l’extension de SYNLEX par les données issues de CORLEX accroit non
seulement le nombre d’entrées mais également la qualité du lexique résultant.

3.2 Evaluation de SYN LEX sur un lexique de référence

Une fagon de déterminer la qualité d’un lexique consiste a calculer son rappel et sa précision
par rapport a un lexique de référence. Soit Acqmls le contenu du lexique a évaluer et Re f celui
du lexique de référence, précision et rappel sont déﬁnis de la fagon suivante :

Précision ’
_ Acqms {'1 Re f

P
Acqmls

La précision indique la proportion d’entrées correctes dans le lexique acquis (combien
d’entrées sont correctes ?)

340

Evaluer SYNLEX

Rappel
R _ Acqmls {'1 Re f

Ref

Le rappel indique la proportion entre entrées correctes présentes dans le lexique acquis
et entrées présentes dans le lexique de référence (combien d’entrées correctes ont été
trouvées ?).

Calcul du rappel et de la précision. Pour l’évaluation, nous avons sélectionné 100 verbes
présents dans tous les lexiques (i.e., SYNLEX, XSYNLEX, DICOVALENCE et CORLEX) et
distribués de facon réguliere sur l’échelle du nombre d’apparition dans le corpus.

Pour chacun de ces 100 verbes, nous avons créé un lexique de référence REFLEX a partir de
DICOVALENCE. Les entrées de ces verbes ont été épurées des entrées non prises en compte
dans CORLEX (c—a—d, les entrées faisant intervenir des arguments obliques ou attributifs) puis
traduites dans le format SYNLEX (cf. Figure l) aﬁn de permettre une comparaison automatique
avec SYNLEX, XSYNLEX et CORLEX.

Les performances des statistiques ont été évaluées sur ces 100 verbes a travers quatre expe-
riences visant a mesurer l’impact de la fréquence d’un cadre sur ces performances.

Etant donné C le nombre total d’entrées présentes dans CORLEX, la fréquence fa d’un cadre
c est dite HAUTE si c apparait dans plus de 1% des entrées de CORLEX (ft 2 0.01 X C);
MOYENNE si0.001 X C 3 fa 3 0.01 X C;et BASSE si fa S 00001 x 0.

Pour chaque lexique (SYNLEX, XS YNLEX et REFLEX), quatre (sous—)lexiques sont créés : un
premier contenant toutes les entrées du lexique (TOUT) et trois autres contenant uniquement les
entrées faisant intervenir des cadres de haute (HF), moyenne (MF) et basse (BF) fréquence. La
référence minimum (baseline) est ﬁxée comme étant le lexique acquis a partir du corpus sans
ﬁltrage statistique (toutes les entrées trouvées par TAGPARSER sont prises en compte).

Le rappel et la précision pour chacun des 5 cas considérés sont donnés dans la Figure 3.

Discussion. Ces premiers résultats montrent que pour l’échantillon de cadres considérés (les
cadres ne faisant pas intervenir d’obliques ou d’attributs), la couverture et la précision de SYN-
LEX sont relativement bas. La couverture faible n’est pas surprenante et s’explique du fait de
l’incomplétude inhérente aux tables du LADL puisque seules 60% des tables sont disponibles.

La mauvaise précision est en revanche plus surprenante mais peut, peut étre, étre expliquée par
la relative permissivité des tables du LADL : si une construction est possible pour un verbe
donné, elle sera marquée comme telle meme si elle est tres rare.

Un autre facteur contribuant a diminuer la précision concerne la décision de ne pas prendre
en compte les associés c—a—d, les arguments régis par le verbe mais ne remplissant pas de role
sémantique. Or parmi ces associés, on trouve le clitique réﬂéchi intrinseque (e.g., se dans s ’éva—
nouir). En conséquence, toutes les entrées faisant intervenir un clitique intrinseque (l’associé
CLR) sont traitées de facon incorrecte comme des entrées sans ce clitique.

Malgré tout, un examen plus approfondi des cas fautifs reste a faire pour déterminer les causes
précises de ce manque de précision et éventuellement, y remédier.

Le rappel et la précision de XS YNLEX , le lexique enrichi a partir du corpus, sont relativement

341

Ingrid FALK, Gil FRANCOPOULO, Claire GARDENT

TOUT HF MF LF

SYNLEX P 0.30 0.63 0.16 0.02
R 0.44 0.45 0.47 0.3
F 0.37 0.54 0.31 0.16

XSYNLEX P 0.58 0.69 0.23 0.29
R 0.63 0.66 0.56 0.5
F 0.59 0.67 0.4 0.4

XSYNLEX + INFIRME P 0.49 0.61 0.21 0.27
R 0.76 0.78 0.67 0.5
F 0.62 0.70 0.44 0.38

BASELINE P 0.22 0.29 0.07 0.15
R 0.89 0.95 0.70 0.5
F

0.56 0.62 0.39 0.32

FIG. 3 — Precision et rappel

bas mais proches de certains resultats obtenus dans la literature pour des langues autres que
l’anglais. (Fast & Przepiorkowski, 2005) par exemple, cite un rappel de 47% et une precision de
49% pour une experience similaire sur le polonais. Pour ce lexique, le rappel et la precision sont
meilleurs que pour SYNLEX. En d’autres termes, le lexique extrait du corpus permet de valider
et d’etendre la partie de SYNLEX faisant intervenir les cadres consideres pour l’acquisition
automatique.

Enﬁn, les donnees concernant XSYNLEX+ INFIRME montrent qu’ignorer la plausibilite statis-
tique des hypotheses (i.e., conserver les entrees de SYNLEX qui sont inﬁrmees par les statis-
tiques) permet d’ameliorer le rappel (0.76 contre 0.63 dans XSYNLEX) au detriment bien sﬁr
de la precision (0.49 contre 0.58 dans XS YNLEX).

4 Conclusion et perspectives

Comme nous l’avons mentionne dans l’introduction, trois lexiques syntaxiques sont actuelle—
ment disponibles et utilisables dans le domaine du traitement automatique des langues. Cepen—
dant, ils sont tous incomplets et leur contenu n’a pas fait l’objet d’une evaluation permettant de
determiner rappel et precision.

Le travail presente dans cet article est un premier pas vers la deﬁnition d’une procedure d’eva—
luation et de fusion de ces lexiques.

Il montre en particulier que DICOVALENCE peut servir de base a la creation d’un lexique de
reference permettant ainsi de calculer le rappel et la precision de lexiques crees de facon auto-
matique ou semi—automatique.

Il montre egalement, qu’un lexique acquis a partir d’un corpus peut permettre d’ameliorer la

342

Evaluer SYNLEX

couverture et la precision d’un lexique existant; et plus generalement, que la comparaison et
la fusion de plusieurs lexiques pourrait permettre a relativement court terme de produire un
lexique syntaxique du francais complet et de bonne qualite.

Neanmoins, plusieurs aspects meritent d’etre approfondis.

Tout d’abord, notons que l’evaluation de SYNLEX presentee ici est tres partielle puisqu’elle ne
porte que sur 33 des 726 cadres presents dans SYNLEX. Une evaluation plus extensive prenant
en compte les obliques et les attributs est donc necessaire.

Un second point concerne la procedure d’acquisition automatique. En effet, l’approche presen-
tee ici est une approche preliminaire qui peut etre amelioree sur au moins deux points a savoir,
la qualite des hypotheses emises d’une part et la qualite du ﬁltre statistique d’autre part.

Les hypotheses emises peuvent etre afﬁnees par l’emploi d’un analyseur plus performant — par
exemple, en utilisant une information de sous—categorisation pour informer l’analyseur ou en-
core en utilisant un analyseur profond plutot que local. Une autre possibilite que nous entendons
explorer prochainement, est d’utiliser plusieurs analyseurs en parallele et de comparer/fusionner
leurs resultats par un systeme de vote.

Les travaux fait sur l’anglais suggerent en outre que le ﬁltre statistique peut etre ameliore de
deux facons. Ainsi (Briscoe & Carroll, 1997) montre que le seuil permettant de determiner
l’acceptabilite d’une hypothese doit etre ﬁxe differemment suivant le type de cadre considere
plutot que de facon uniforme pour l’ensemble des hypotheses comme nous l’avons fait ici. Et
(Korhonen, 2002) montre que l’utilisation de techniques de lissages informees par les classes
semantiques de verbes permet d’ameliorer les resultats. L’exploitation de ces resultats devrait
permettre d’ameliorer la qualite du lexique extrait.

Une troisieme point, plus ouvert celui—la, concerne l’elargissement des methodes explorees a
l’ensemble du lexique et en particulier au traitement des macros. Comme nous l’avons vu,
SYNLEX, LEFFF et DICOVALENCE contiennent outre des informations portant sur la valence
(arguments regis par le verbe remplissant ou non un role semantique), des informations portant
sur les phenomenes de controle, la passivation, la possibilite pour un verbe d’etre utilise dans
une tournure impersonnelle, etc. Si elles sont utiles pour le traitement automatique des langues
et en particulier, pour l’analyse et la realisation de surface, ces informations ne peuvent pas etre
extraites a partir des corpus par les techniques utilisees en acquisition automatique de lexique.
Elles sont en revanche partiellement presentes dans les lexiques existants (LEFFF, DICOVA-
LENCE et SYNLEX). Une question interessante est donc de savoir comment cette information
peut etre utilisee pour infonner la completion d’un lexique partiellement sous—speciﬁe dans
cette dimension. Ou en d’autres termes, comment un lexique acquis a partir de corpus peut etre
fusionne avec un ou des lexiques acquis par des methodes «symboliques» (LEFFF, SYNLEX)
de facon a enrichir la partie acquise statistiquement avec l’information additionnelle contenue
dans les lexiques symboliques.

Dans tous les cas, la precision relativement basse des lexiques produits suggere qu’une phase de
validation manuelle est necessaire. Dans cette optique, une approche qui consiste a privilegier
(dans une juste mesure) le rappel plutot que la precision est sans doute preferable (il est plus
facile d’eliminer que d’ajouter). Ce qui suggere en particulier, que XS YNLEX+ INFIRME est
preferable a XSYNLEX et plus speciﬁquement, que l’extraction de SYNLEX a partir des tables
est utile.

343

Ingrid FALK, Gil FRANCOPOULO, Claire GARDENT

Références

BOONS J.—P., GUILLET A. & LECLERE C. (1976). La structure des phrases simples en
francais. I : Constructions intransitives. Droz, Geneve.

BRENT M. (1991). Automatic acquisition of subcategorisation frames from untagged text. In
Proceedings of the 29th Meeting of the ACL, p. 209-214, Berkeley.

BRISCOE T. & CARROLL J. (1997). Automatic extraction of subcategorisation from corpora.
In Proceedings of the 5th ANLP conference, p. 356-363.

CARROLL J. & FANG A. (2004). The automatic acquisition of verb subcategorisations and
their impact on the performance of an HPSG parser. In Proceedings of the 1 st International
Joint Conference on Natural Language Processing (IJCNLP), p. 107-1 14, Sanya City, China.
CLEMENT L., SAGOT B. & LANG B. (2004). Morphology based automatic acquisition of
large—coverage lexica. In Proceedings of LREC ‘O4, Lisbonne.

FAST J. & PRZEPIORKOWSKI A. (2005). Automatic extraction of polish verb subcategorisa-
tion. an evaluation of common statistics. In Proceedings of the 2nd Language and Technology
conference, p. 191-195.

FRANCOPOULO G. (2005). Tagparser et technolangue—easy. In Actes de l ‘atelier Easy, TALN.

GARDENT C., GUILLAUME B., PERRIER G. & FALK I. (2005a). Extracting subcategori-
sation information from Maurice Gross’ Grammar Lexicon. Archives of Control Sciences,
l5(LI), 253-264.

GARDENT C., GUILLAUME B., PERRIER G. & FALK I. (2005b). Maurice gross’ grammar
lexicon and natural language processing. In Proceedings of the 2nd Language and Technology
Conference, Poznan, Poland.

GARDENT C., GUILLAUME B., PERRIER G. & FALK I. (2006). Extraction d’information de
sous—catégorisation a partir des tables du ladl. In Actes de La I3eme edition de la conference
sur le Traitement Automatique des Langues Naturelles (TALN 2006 ).

GROSS M. (1975). Me’thodes en syntaxe. Hermann.

GUILLET A. & LECLERE C. (1992). La structure des phrases simples en francais. Construc-
tions transitives locatives. Droz, Geneve.

KORHONEN A. (2002). Subcategorization Acquisition. PhD thesis, University of Cambridge.

MANNING C. (1993). Automatic acquisition of a large subcategorisation dictionary from
corpora. In Proceedings of the 31st Meeting of the ACL.

ROMARY L., SALMON—ALT S. & FRANCOPOULO G. (2004). Standards going concrete :
from LMF to morphalou. In Workshop on Electronic Dictionaries, Geneva, Switzerland.

VAN DEN EYNDE K. & MERTENS P. (2003). La valence : l’approche pronominale et son
application au lexique verbal. Journal of French Language Studies 13, 63-104.

344

