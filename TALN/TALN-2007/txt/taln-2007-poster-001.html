<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>D&#233;sambigu&#239;sation lexicale automatique : s&#233;lection automatique d&#8217;indices</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2007, Toulouse, 5&#8211;8 juin 2007
</p>
<p>D&#233;sambigu&#239;sation lexicale automatique :
s&#233;lection automatique d&#8217;indices
</p>
<p>Laurent AUDIBERT
Laboratoire d&#8217;Informatique de l&#8217;universit&#233; Paris-Nord (LIPN)
99, avenue Jean-Baptiste Cl&#233;ment &#8211; 93430 Villetaneuse, France
</p>
<p>laurent.audibert@lipn.univ-paris13.fr
</p>
<p>R&#233;sum&#233;. Nous exposons dans cet article une exp&#233;rience de s&#233;lection automatique des in-
dices du contexte pour la d&#233;sambigu&#239;sation lexicale automatique. Notre point de vue est qu&#8217;il
est plus judicieux de privil&#233;gier la pertinence des indices du contexte plut&#244;t que la sophistica-
tion des algorithmes de d&#233;sambigu&#239;sation utilis&#233;s. La s&#233;lection automatique des indices par le
biais d&#8217;un algorithme g&#233;n&#233;tique am&#233;liore significativement les r&#233;sultats obtenus dans nos exp&#233;-
riences pr&#233;c&#233;dentes tout en confortant des observations que nous avions faites sur la nature et
la r&#233;partition des indices les plus pertinents.
</p>
<p>Abstract. This article describes an experiment on automatic features selection for word
sense disambiguation. Our point of view is that word sense disambiguation success is more
dependent on the features used to represent the context in which an ambiguous word occurs
than on the sophistication of the learning techniques used. Automatic features selection using
a genetic algorithm improves significantly our last experiment bests results and is consistent
with the observations we have made on the nature and space distribution of the most reliable
features.
</p>
<p>Mots-cl&#233;s : d&#233;sambigu&#239;sation lexicale automatique, corpus s&#233;mantiquement &#233;tiquet&#233;,
cooccurrences, s&#233;lection d&#8217;indices, algorithmes g&#233;n&#233;tiques.
</p>
<p>Keywords: word sense disambiguation, sense tagged corpora, cooccurrences, features
selection, genetic algorithms.
</p>
<p>1 Introduction
</p>
<p>La plupart des mots ont plusieurs significations. La d&#233;sambigu&#239;sation lexicale consiste &#224; choi-
sir la bonne signification d&#8217;un mot polys&#233;mique dans un contexte donn&#233;. Cette op&#233;ration est
utile ou indispensable pour la plupart des applications de traitement automatique des langues :
recherche d&#8217;information, traduction automatique, reconnaissance de la parole, etc. (Ide &amp; V&#233;-
ronis, 1998). La campagne d&#8217;&#233;valuation trisannuel SensEval (Edmonds, 2002) atteste de l&#8217;im-
portance de cette t&#226;che.
</p>
<p>La d&#233;sambigu&#239;sation lexicale s&#8217;effectue toujours en utilisant l&#8217;information pr&#233;sente dans le
contexte du mot &#224; d&#233;sambigu&#239;ser. Cette information peut &#234;tre enrichie par un certain nombre
d&#8217;annotations (&#233;tiquette morphosyntaxique, lemmatisation, etc.). Il n&#8217;est cependant pas pos-
</p>
<p>13</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Laurent AUDIBERT
</p>
<p>sible d&#8217;utiliser toute l&#8217;information disponible car elle est bien trop importante et bruit&#233;e. Il faut
donc se focaliser sur un certain nombre d&#8217;indices. Le choix de ces indices, d&#233;termin&#233; par ce que
nous appelons des crit&#232;res de d&#233;sambigu&#239;sation lexicale, est primordial et constitue un enjeu
important dans le domaine de la d&#233;sambigu&#239;sation lexicale automatique (Bruce et al., 1996; Ng
&amp; Zelle, 1997; Pedersen, 2001b).
</p>
<p>Notre approche s&#8217;inscrit dans celles qui utilisent des techniques de classification supervis&#233;e sur
un corpus lexicalement d&#233;sambigu&#239;s&#233;. Dans ce type d&#8217;approche, de nombreux travaux cherchent
&#224; am&#233;liorer la pr&#233;cision de la d&#233;sambigu&#239;sation en am&#233;liorant les techniques de classification.
Le choix des indices utilis&#233;s est g&#233;n&#233;ralement d&#233;termin&#233; plus ou moins arbitrairement par la
connaissance, l&#8217;exp&#233;rience et l&#8217;intuition du chercheur. Peu de travaux avaient &#233;tudi&#233; syst&#233;ma-
tiquement l&#8217;impact du choix des indices utilis&#233;s sur la pr&#233;cision de la d&#233;sambigu&#239;sation. Pour
cette raison, nous avons pr&#233;sent&#233; une &#233;tude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique auto-
matique (Audibert, 2003a) bas&#233;s sur les unigrammes (i.e. cooccurrences de mots isol&#233;s). Nous
avons compl&#233;t&#233; cette &#233;tude en explorant des indices bas&#233;s sur des bigrammes et des trigrammes
(Audibert, 2004). Dans ces travaux, les crit&#232;res &#233;tudi&#233;s &#233;taient homog&#232;nes dans le sens o&#249; ils
&#233;taient constitu&#233;s d&#8217;indices de m&#234;me nature : par exemple, soit des lemmes, soit des &#233;tiquettes
morphosyntaxiques, mais pas une combinaison des deux.
</p>
<p>Dans le pr&#233;sent article, nous pr&#233;sentons, dans un premier temps, une petite &#233;tude comparative
de diff&#233;rents algorithmes de classification. Nous nous int&#233;ressons ensuite &#224; la s&#233;lection auto-
matique des meilleurs indices du contexte pour former des crit&#232;res de d&#233;sambigu&#239;sation h&#233;t&#233;-
rog&#232;nes sur lesquels un algorithme de classification peut s&#8217;appuyer efficacement pour effectuer
de la d&#233;sambigu&#239;sation lexicale. Ce travail s&#8217;appuie toujours sur les 60 mots cibles (20 noms,
20 adjectifs et 20 verbes) des travaux pr&#233;c&#233;dents (Audibert, 2003a; Audibert, 2004).
</p>
<p>2 Corpus, indices et crit&#232;res
</p>
<p>2.1 Corpus
</p>
<p>Notre corpus de travail est compos&#233; de textes de genres vari&#233;s et comporte 6 468 522 mots. Il a
&#233;t&#233; constitu&#233; dans le cadre du projet SyntSem qui vise &#224; produire un corpus fran&#231;ais d&#8217;amor&#231;age
&#233;tiquet&#233; au niveau morphosyntaxique, lemmatis&#233; et comportant un &#233;tiquetage syntaxique peu
profond ainsi qu&#8217;un &#233;tiquetage lexical de 60 mots-cibles s&#233;lectionn&#233;s pour leur caract&#232;re forte-
ment polys&#233;mique (V&#233;ronis, 1998). Ces 60 mots-cibles, qui totalisent 53796 occurrences dans
le corpus, sont &#233;galement r&#233;partis en 20 noms, 20 adjectifs et 20 verbes et sont d&#233;taill&#233;s dans le
tableau 1.
</p>
<p>L&#8217;une des difficult&#233;s majeures de l&#8217;&#233;tiquetage s&#233;mantique automatique r&#233;side dans l&#8217;inad&#233;qua-
tion des dictionnaires traditionnels (V&#233;ronis, 2001) ou d&#233;di&#233;s (Palmer, 1998) pour cette t&#226;che.
Pour rem&#233;dier &#224; ce probl&#232;me, l&#8217;&#233;quipe DELIC 1 a entrepris la construction d&#8217;un dictionnaire
distributionnel en se basant sur un ensemble de crit&#232;res diff&#233;rentiels stricts (Reymond, 2001).
C&#8217;est ce dictionnaire qui a &#233;t&#233; utilis&#233; pour &#233;tiqueter les occurrences des 60mots-cibles du projet
SyntSem. Dans ce dictionnaire, le nombre de lexies par vocable est important car il inclut les
locutions fig&#233;es ou compos&#233;es comme mettre sur pied, mettre &#224; pied, pied de nez, etc.
</p>
<p>Un consensus semble &#233;merger selon lequel l&#8217;&#233;tiquetage morphosyntaxique, et plus particuli&#232;-
</p>
<p>1&#201;quipe DELIC, Universit&#233; de Provence, 29 Avenue Robert SCHUMAN, 13621 Aix-en-Provence Cedex 1.
</p>
<p>14</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;sambigu&#239;sation lexicale automatique : s&#233;lection automatique d&#8217;indices
</p>
<p>Noms Adjectifs Verbes
Vocable freq lex H Vocable freq lex H Vocable freq lex H
barrage 92 5 1, 18 correct 116 5 1, 81 couvrir 518 21 3, 25
</p>
<p>restauration 104 5 1, 85 sain 129 10 2, 45 importer 576 8 2, 57
suspension 110 5 1, 50 courant 168 4 0, 63 parvenir 653 8 2, 31
d&#233;tention 112 2 0, 85 r&#233;gulier 181 11 2, 54 exercer 698 8 1, 52
lancement 138 5 0, 99 frais 182 18 3, 10 conclure 727 16 2, 36
</p>
<p>concentration 246 6 1, 98 secondaire 195 5 1, 69 arr&#234;ter 913 15 2, 97
station 266 8 2, 58 strict 220 9 2, 23 ouvrir 919 41 3, 80
vol 278 10 2, 20 exceptionnel 226 3 1, 45 poursuivre 978 16 2, 71
</p>
<p>organe 366 6 2, 24 utile 359 9 2, 39 tirer 1001 47 3, 88
compagnie 412 12 1, 62 vaste 368 6 2, 08 conduire 1082 15 2, 28
constitution 422 6 1, 64 sensible 425 11 2, 63 entrer 1210 38 3, 65
</p>
<p>degr&#233; 507 18 2, 47 traditionnel 447 2 0, 49 conna&#238;tre 1635 16 2, 24
observation 572 3 0, 68 populaire 457 5 2, 02 rendre 1985 27 2, 88
passage 601 19 2, 70 biologique 475 4 0, 55 comprendre 2136 13 2, 76
solution 880 4 0, 44 clair 556 20 3, 10 pr&#233;senter 2140 18 2, 56
&#233;conomie 930 10 2, 16 historique 620 3 0, 67 porter 2328 59 4, 01
</p>
<p>pied 960 62 3, 55 s&#251;r 645 14 2, 61 r&#233;pondre 2529 9 0, 99
chef 1133 11 1, 47 plein 844 35 3, 99 passer 2547 83 4, 49
</p>
<p>formation 1528 9 1, 66 haut 1016 29 3, 46 venir 3788 33 3, 21
communication 1703 13 2, 44 simple 1051 14 2, 14 mettre 5095 140 3, 65
</p>
<p>Moyenne 568 14, 2 1, 9 Moyenne 434, 4 14, 1 2, 3 Moyenne 1687, 6 47, 4 3, 1
</p>
<p>TAB. 1 &#8211; Fr&#233;quence moyenne des occurrences des vocables (freq), nombre moyen de lexies
(lex) et entropie de la r&#233;partition des occurrences sur les lexies (H).
</p>
<p>rement la lev&#233;e de l&#8217;ambigu&#239;t&#233; sur la cat&#233;gorie grammaticale des vocables, n&#8217;est pas du ressort
de la d&#233;sambigu&#239;sation lexicale (Kilgarriff, 1997; Ng &amp; Zelle, 1997). Nous avons confi&#233; l&#8217;&#233;ti-
quetage morphosyntaxique de notre corpus au logiciel Cordial Analyseur (d&#233;velopp&#233; par la so-
ci&#233;t&#233; Synapse D&#233;veloppement), qui offre une lemmatisation et un &#233;tiquetage morphosyntaxique
d&#8217;une exactitude satisfaisante (Valli &amp; V&#233;ronis, 1999).
</p>
<p>jeton lemme ems smallems lexie
pouvait pouvoir VINDI3S VCON
mettre mettre VINF VINF 1.12.7
fin fin NCFS NCOM
&#224; &#224; PREP PREP
la le DETDFS DET
</p>
<p>pratique pratique NCFS NCOM
des de DETDPIG DET
</p>
<p>d&#233;tentions d&#233;tention NCFP NCOM 1
</p>
<p>TAB. 2 &#8211; Extrait du corpus SyntSem
</p>
<p>Le Tableau 2 pr&#233;sente un extrait du corpus SyntSem. Il permet de visualiser l&#8217;ensemble des
&#233;tiquettes que poss&#232;de un mot. C&#8217;est l&#8217;information de ces &#233;tiquettes que nous utilisons dans nos
crit&#232;res de d&#233;sambigu&#239;sation lexicale.
</p>
<p>15</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Laurent AUDIBERT
</p>
<p>2.2 Indices et crit&#232;res
</p>
<p>Nous d&#233;signons par le terme d&#8217;indice une source potentielle d&#8217;information pouvant participer &#224;
la lev&#233;e de l&#8217;ambigu&#239;t&#233; d&#8217;un mot cible dont nous cherchons la bonne lexie. Un indice peut &#234;tre
le lemme du mot qui pr&#233;c&#232;de par exemple. Un crit&#232;re est simplement la donn&#233;e d&#8217;un ensemble
d&#8217;indices.
</p>
<p>Nous avons &#233;tudi&#233; une grande vari&#233;t&#233; de crit&#232;res dans (Audibert, 2004). Les noms de ces cri-
t&#232;res pr&#233;cisent leur nature et sont de la forme [P1|P2|P3|P4]. Le param&#232;tre P1 indique si
le crit&#232;re consid&#232;re des unigrammes (P1=1gr), des bigrammes (P1=2gr) ou des trigrammes
(P1=3gr) ; un n-gramme &#233;tant la juxtaposition de n mots. Le param&#232;tre P2 indique si l&#8217;on
regarde la forme brute des mots (P2=jeton), leur lemme (P2=lemme), leur &#233;tiquette mor-
phosyntaxique (P2=ems) ou leur &#233;tiquette morphosyntaxique simplifi&#233;e (P2=smallems). Le
param&#232;tre P3 indique si les mots consid&#233;r&#233;s sont diff&#233;renci&#233;s par leur position (P3=ordonne),
diff&#233;renci&#233;s suivant qu&#8217;ils appartiennent au contexte droit ou gauche (P3=differencie), ou
non diff&#233;renci&#233;s (P3=non-ordonne). Enfin, le param&#232;tre P4 indique si le crit&#232;re consid&#232;re
tous les mots (P4=mot) ou seulement les mots pleins (P4=mot-plein). Nous qualifions
ces crit&#232;res de crit&#232;res homog&#232;nes dans la mesure o&#249; l&#8217;ensemble des indices de d&#233;sambigu&#239;-
sation sont de la m&#234;me nature puisque enti&#232;rement d&#233;termin&#233;s par l&#8217;instanciation des quatre
param&#232;tres.
</p>
<p>3 Comparaison de diff&#233;rents algorithmes de d&#233;sambigu&#239;sa-
tion
</p>
<p>Dans cette exp&#233;rience, nous comparons diff&#233;rents algorithmes de classification supervis&#233;e en
utilisant un crit&#232;re assez standard constitu&#233; du lemme des mots en tenant compte de leur posi-
tion (i.e. [1gr|lemme|ordonne|mot]) dans une fen&#234;tre de &#177;3 mots. Les algorithmes de
classification &#233;valu&#233;s sont les suivants :
MAJ est un classifieur qui retourne toujours la lexie la plus fr&#233;quente ; nous l&#8217;utilisons comme
</p>
<p>borne inf&#233;rieure &#224; la pr&#233;cision de la d&#233;sambigu&#239;sation ;
PCM est un algorithme bas&#233; sur une liste de d&#233;cisions, proche de celui utilis&#233; par (Yarowsky,
</p>
<p>1994) et d&#233;taill&#233; dans (Audibert, 2003a) ;
NB est notre impl&#233;mentation du classifieur Na&#239;f de Bayes ;
KPPV est une impl&#233;mentation &#233;l&#233;mentaire d&#8217;un classifieur du type k plus proches voisins ;
PEBLS est classifieur du type k plus proches voisins poss&#233;dant une m&#233;trique bien plus sophis-
</p>
<p>tiqu&#233; que celle de KPPV ;
NBW est l&#8217;impl&#233;mentation du projet Weka du classifieur Na&#239;f de Bayes ;
C45W est l&#8217;impl&#233;mentation du projet Weka du classifieur C45.
Le tableau 3 montre les r&#233;sultats de cette exp&#233;rience comparative. Dans toutes les exp&#233;riences
de d&#233;sambigu&#239;sation de cet article, toutes les occurrences re&#231;oivent une classification. Le rappel
&#233;tant &#233;gal &#224; la pr&#233;cision dans ce cas, nous ne mentionnons que la pr&#233;cision obtenue.
</p>
<p>Les temps d&#8217;ex&#233;cution des deux algorithmes du projet Weka que nous avons utilis&#233;s (NBW et
C45W) sont r&#233;dhibitoires pour nos exp&#233;riences. Les raisons de ces temps d&#8217;ex&#233;cution sont, ou
peuvent &#234;tre, la non optimisation de l&#8217;impl&#233;mentation, l&#8217;utilisation du langage java et le format,
</p>
<p>16</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;sambigu&#239;sation lexicale automatique : s&#233;lection automatique d&#8217;indices
</p>
<p>MAJ PCM NB KPPV PEBLS NBW C45W
Pr&#233;cision 42, 9% 72, 3% 74, 5% 65, 5% 70, 9% 58, 2% 74, 6%
</p>
<p>Intervalle de confiance &#177;0, 38% &#177;0, 37% &#177;0, 40% &#177;0, 38% &#177;0, 42% &#177;0, 37%
Temps 3s 3s 5s 26mn 2h33mn 1h47mn 35h43mn
</p>
<p>TAB. 3 &#8211; Comparaison de la pr&#233;cision, avec intervalle de confiance de l&#8217;estimation &#224; 95%, et
des temps d&#8217;ex&#233;cution de diff&#233;rents algorithmes de classification.
</p>
<p>peu adapt&#233; au probl&#232;me, de la repr&#233;sentation des donn&#233;es d&#8217;apprentissage. Le temps d&#8217;ex&#233;cution
du classifieur PEBLS est &#233;galement bien trop important et est une cons&#233;quence de la complexit&#233;
de la m&#233;trique utilis&#233;e.
</p>
<p>Les classifieurs NB et PCM, n&#233;cessitent tous deux des estimations de probabilit&#233;s. En raison
des observations souvent rares et parfois nulles qui interviennent dans ces estimations, nous
utilisons la m-estimation (Cussens, 1993) plut&#244;t que l&#8217;estimation classique des probabilit&#233;s.
Cette diff&#233;rence explique certainement l&#8217;&#233;cart de performance des classifieurs NB et NBW.
</p>
<p>Nous pouvons tirer deux enseignements de cette exp&#233;rience. La premier est qu&#8217;il est souvent
difficile et parfois pr&#233;judiciable d&#8217;utiliser un algorithme de classification comme une bo&#238;te noire
(cf. la comparaison entre NB et NBW). Le second est que la complexit&#233; et la sophistication des
algorithmes de classification n&#8217;apportent pas forc&#233;ment un gain important pour notre t&#226;che (cf.
la comparaison entre NB, PEBLS et C45). Actuellement, des gains bien plus importants sont &#224;
attendre des indices fournis aux classifieurs plut&#244;t que des classifieurs eux-m&#234;mes.
</p>
<p>4 S&#233;lection automatique des indices
</p>
<p>4.1 M&#233;thodologie
</p>
<p>En prenant tous les indices g&#233;n&#233;r&#233;s par tous les crit&#232;res homog&#232;nes [P1|P2|P3|P4] cor-
respondants aux diff&#233;rentes instanciations possibles des quatre param&#232;tres P1 &#224; P4, et en
consid&#233;rant une fen&#234;tre de &#177;12 mots, nous obtenons 3 (1gr, 2gr ou 3gr) &#215;4 (jeton,
lemme, ems ou smallems) &#215;3 (ordonne, differentie ou non-ordonne) &#215;2 (mot
ou mot-plein) &#215;24 (contexte de &#177;12 mots2) soit 1728 indices diff&#233;rents.
En r&#233;duisant la taille du contexte consid&#233;r&#233;, nous avons g&#233;n&#233;r&#233; un deuxi&#232;me jeu d&#8217;indices r&#233;duit
&#224; 888 indices. Dans ce jeu d&#8217;indices, la taille du contexte pour les crit&#232;res bas&#233;s sur les &#233;tiquettes
lemme et jeton et compos&#233;s d&#8217;unigrammes (respectivement de bigrammes et trigrammes)
est de &#177;6 mots (respectivement &#177;8 et &#177;10), et pour les crit&#232;res bas&#233;s sur les &#233;tiquettes ems
et smallems et compos&#233;s d&#8217;unigrammes (respectivement de bigrammes et trigrammes) est de
&#177;4 mots (respectivement &#177;5 et &#177;6).
La question est de savoir quels indices retenir, parmi les 1728 du premier jeu d&#8217;indices ou parmi
les 888 du second, pour former un crit&#232;re h&#233;t&#233;rog&#232;ne efficace pour la lev&#233;e de l&#8217;ambigu&#239;t&#233;. Pour
repr&#233;senter un crit&#232;re nous utilisons une cha&#238;ne de bits, appel&#233;e un g&#233;nome, compos&#233;e de 1728
</p>
<p>2 Le calcul est ici simplifi&#233;, en r&#233;alit&#233;, le nombre d&#8217;indices consid&#233;r&#233;s sans sortir du contexte de &#177;12 mots est
de 12 + 1 + 12 = 25 pour les unigrammes, 12 + 1 + 11 = 24 pour les bigrammes et 12 + 1 + 10 = 23 pour les
trigrammes ce qui fait bien 24 en moyenne.
</p>
<p>17</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Laurent AUDIBERT
</p>
<p>bits pour le premier jeu et de 888 bits pour le second. La valeur de chaque bit permet de pr&#233;ci-
ser si l&#8217;indice associ&#233; est retenu ou pas. Un g&#233;nome caract&#233;rise donc un crit&#232;re (une s&#233;lection
d&#8217;indices) h&#233;t&#233;rog&#232;ne (tous les indices ne sont pas forc&#233;ment de la m&#234;me nature). En raison de
la complexit&#233; combinatoire de notre probl&#232;me d&#8217;optimisation de s&#233;lection d&#8217;indices, il n&#8217;existe
pas de m&#233;thode exacte pour le r&#233;soudre en un temps raisonnable. Il faut donc se contenter de
solutions approch&#233;es que nous obtenons en utilisant deux techniques classiques d&#8217;optimisation :
les algorithmes gloutons et les algorithmes g&#233;n&#233;tiques3. Le principe de l&#8217;algorithme glouton est
de rechercher le meilleur indice pris individuellement, puis de chercher quel indice lui associer
pour am&#233;liorer au maximum la pr&#233;cision, et ainsi de suite jusqu&#8217;&#224; ne plus obtenir d&#8217;am&#233;lio-
ration. Les algorithmes g&#233;n&#233;tiques, quant &#224; eux, tentent de mettre en &#339;uvre le principe de la
s&#233;lection naturelle (croisements et mutations) sur des populations de solutions potentielles (i.e
des g&#233;nomes) et se rapprochent de la solution au cours de g&#233;n&#233;rations successives.
</p>
<p>Pour mettre en &#339;uvre ces techniques, le corpus de d&#233;part est scind&#233; en deux sous-corpus. Le
premier sous-corpus contient 60% des exemples d&#8217;apprentissage. Il est utilis&#233; dans un premier
temps pour effectuer la s&#233;lection des indices en utilisant l&#8217;algorithme glouton ou l&#8217;algorithme
g&#233;n&#233;tique. Cette s&#233;lection se fait en g&#233;n&#233;rant une famille de g&#233;nomes en suivant les r&#232;gles
propres &#224; l&#8217;algorithme glouton ou g&#233;n&#233;tique. L&#8217;&#233;valuation de la performance de chacun des g&#233;-
nomes (i.e. sous-ensemble d&#8217;indices) est r&#233;alis&#233;e par l&#8217;estimation de la pr&#233;cision obtenue par le
classifieur NB en utilisant une m&#233;thode d&#8217;&#233;valuation crois&#233;e k fois (avec k = 10) toujours sur
ce m&#234;me sous-corpus. Cette m&#233;thode est co&#251;teuse en temps de calcul, mais permet l&#8217;&#233;valuation
des crit&#232;res (i.e. des g&#233;nomes) sur la totalit&#233; du sous-corpus. Une nouvelle g&#233;n&#233;ration de g&#233;-
nomes est ensuite calcul&#233;e en fonction de la g&#233;n&#233;ration pr&#233;c&#233;dente et des r&#232;gles de l&#8217;algorithme
glouton ou g&#233;n&#233;tique. L&#8217;exp&#233;rience est r&#233;p&#233;t&#233;e tant que des g&#233;nomes plus performants &#233;mergent
des g&#233;n&#233;rations successives.
</p>
<p>Les indices s&#233;lectionn&#233;s par le g&#233;nome obtenant la meilleure performance constituent un crit&#232;re
h&#233;t&#233;rog&#232;ne utilis&#233; pour l&#8217;apprentissage du classifieur NB sur la totalit&#233; du sous-corpus contenant
60% des exemples. Le deuxi&#232;me sous-corpus, qui contient 40% des exemples d&#8217;apprentissage,
est enfin utilis&#233; pour estimer la pr&#233;cision de d&#233;sambigu&#239;sation obtenue par le classifieur NB
pr&#233;c&#233;demment entra&#238;n&#233;.
</p>
<p>Cette exp&#233;rience a &#233;t&#233; conduite d&#8217;un c&#244;t&#233; sur chacun des vocables ind&#233;pendamment (i.e. un
g&#233;nome est s&#233;lectionn&#233; pour chacun des vocables) et d&#8217;un autre c&#244;t&#233; par cat&#233;gorie grammaticale
(i.e. un unique g&#233;nome est s&#233;lectionn&#233; pour les 20 vocables d&#8217;une cat&#233;gorie). L&#8217;exp&#233;rience par
cat&#233;gorie grammaticale n&#8217;a pas &#233;t&#233; men&#233;e pour le jeu contenant 1728 indices en raisons des
temps de calcul d&#233;j&#224; de l&#8217;ordre de la dizaine de jours pour le jeu contenant 888 indices. Le
tableau 4 rend compte des r&#233;sultats de notre exp&#233;rience.
</p>
<p>4.2 R&#233;sultats des diff&#233;rentes exp&#233;riences de s&#233;lection
</p>
<p>La lecture du tableau 4 permet d&#8217;observer imm&#233;diatement que chacune des exp&#233;riences de s&#233;-
lection automatique des indices &#224; permis de surpasser la pr&#233;cision obtenue par le meilleur crit&#232;re
homog&#232;ne identifi&#233; dans (Audibert, 2004).
</p>
<p>Nous avons syst&#233;matiquement obtenu de meilleurs r&#233;sultats en s&#233;lectionnant les indices avec
l&#8217;algorithme g&#233;n&#233;tique plut&#244;t qu&#8217;avec l&#8217;algorithme glouton qui est incapable de se sortir d&#8217;un
</p>
<p>3 Ce type d&#8217;approche n&#8217;est pas original, par exemple (Daelemans et al., 2003) montrent comment obtenir une
am&#233;lioration significative des performances en r&#233;alisant une optimisation simultan&#233;e des param&#232;tres de l&#8217;algo-
rithme d&#8217;apprentissage et de la s&#233;lection des indices en utilisant justement des algorithmes g&#233;n&#233;tiques.
</p>
<p>18</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;sambigu&#239;sation lexicale automatique : s&#233;lection automatique d&#8217;indices
</p>
<p>Noms Adjectifs Verbes Moyenne
P (%) Am. ICA P (%) Am. ICA P (%) Am. ICA P (%) Am. ICA
</p>
<p>Baseline (MAJ) 57, 2 46, 3 37, 2 42, 9
Crit&#232;re homog&#232;ne 81, 4 0, 0 75, 1 0, 0 72, 3 0, 0 74, 7 0, 0
Glou/Voc (1728) 82, 5 1, 0 &#177;1, 6 75, 7 0, 5 &#177;2, 0 74, 3 2, 0 &#177;1, 1 76, 3 1, 6 &#177;0, 8
G&#233;n&#233;/Voc (1728) 83, 5 2, 1 &#177;1, 6 75, 9 0, 7 &#177;2, 0 75, 1 2, 8 &#177;1, 0 77, 0 2, 3 &#177;0, 8
Glou/Voc (888) 82, 9 1, 5 &#177;1, 6 75, 7 0, 6 &#177;2, 0 75, 0 2, 7 &#177;1, 0 76, 8 2, 1 &#177;0, 8
G&#233;n&#233;/Voc (888) 85, 3 3, 9 &#177;1, 5 77, 3 2, 2 &#177;2, 0 77, 3 5, 0 &#177;1, 0 79, 0 4, 3 &#177;0, 8
Glou/Cat (888) 83, 7 2, 3 &#177;1, 6 75, 9 0, 7 &#177;2, 0 76, 8 4, 5 &#177;1, 0 78, 1 3, 4 &#177;0, 8
G&#233;n&#233;/Cat (888) 85, 9 4, 4 &#177;1, 5 78, 2 3, 1 &#177;2, 0 77, 7 5, 4 &#177;1, 0 79, 5 4, 8 &#177;0, 8
</p>
<p>TAB. 4 &#8211; Pr&#233;cision d&#8217;un crit&#232;re h&#233;t&#233;rog&#232;ne constitu&#233; par s&#233;lection automatique des indices. La
ligne Baseline (MAJ) donne la pr&#233;cision obtenue par l&#8217;algorithme retournant syst&#233;matiquement
la lexie majoritaire. La ligne Crit&#232;re homog&#232;ne donne la pr&#233;cision obtenue par le meilleur cri-
t&#232;re homog&#232;ne, c&#8217;est-&#224;-dire le crit&#232;re [2gr|lemme|differencie|mot]) avec une taille
de fen&#234;tre de &#177;4 mots pour les noms et les verbes et &#177;3 mots pour les adjectifs. Dans les lignes
suivantes, Glou signifie que la technique de s&#233;lection d&#8217;indices utilis&#233;e est de type algorithme
glouton tandis que G&#233;n&#233; signifie que la technique utilis&#233;e est de type algorithme g&#233;n&#233;tique. Voc
signifie que la s&#233;lection d&#8217;indices est ind&#233;pendante pour chacun des vocables et Cat qu&#8217;elle est
commune aux 20 vocables de la cat&#233;gorie grammaticale. (1728) et (888) pr&#233;cisent la taille du
jeux d&#8217;indices de l&#8217;exp&#233;rience. La colonne P (%) donne la pr&#233;cision obtenue en pourcentage,
Am. l&#8217;am&#233;lioration r&#233;alis&#233;e par rapport &#224; la pr&#233;cision du meilleur crit&#232;re homog&#232;ne (ligne Cri-
t&#232;re homog&#232;ne) et ICA l&#8217;intervalle de confiance &#224; 95% de l&#8217;am&#233;lioration r&#233;alis&#233;e (l&#8217;intervalle de
confiance de la pr&#233;cision &#233;tant bien inf&#233;rieur).
</p>
<p>minimum local. Dans nos exp&#233;riences, l&#8217;algorithme glouton s&#233;lectionne environ 20 indices.
D&#8217;un autre c&#244;t&#233;, un algorithme g&#233;n&#233;tique est capable, par d&#233;finition, de se sortir d&#8217;un minimum
local. Cependant, il ne garantit pas que tous les indices s&#233;lectionn&#233;s sont utiles et il s&#233;lectionne,
dans nos exp&#233;riences, environ 180 indices.
</p>
<p>Un autre ph&#233;nom&#232;ne qui ressort de la lecture de ces r&#233;sultats est que le jeu d&#8217;indices qui n&#8217;en
contient que 888 permet d&#8217;aboutir &#224; de meilleurs r&#233;sultats que le jeu d&#8217;indices en contenant
1728. Les deux raisons de ce comportement sont la taille du corpus d&#8217;apprentissage, probable-
ment trop faible pour une telle quantit&#233; d&#8217;indices, et le pi&#232;ge du surapprentissage sensible dans
notre approche.
</p>
<p>De mani&#232;re surprenante, nous obtenons de meilleurs r&#233;sultats en op&#233;rant la s&#233;lection sur l&#8217;en-
semble d&#8217;une cat&#233;gorie grammaticale plut&#244;t que sur chacun des vocables pris individuellement.
Op&#233;rer la s&#233;lection sur l&#8217;ensemble d&#8217;une cat&#233;gorie grammaticale permet de limiter le ph&#233;no-
m&#232;ne de surapprentissage et d&#8217;augmenter le nombre d&#8217;exemples sur lesquels se fait la s&#233;lec-
tion. Le gain obtenu par la limitation du ph&#233;nom&#232;ne de surapprentissage et l&#8217;augmentation du
nombre d&#8217;exemples est ici sup&#233;rieur &#224; celui obtenu par l&#8217;ajustement de la s&#233;lection des indices
individuellement pour chaque vocable.
</p>
<p>L&#8217;accord entre plusieurs annotateurs (ITA pour InTer-annotator Agreement en anglais) a &#233;t&#233; es-
tim&#233; &#224; 96.4% (Audibert, 2003b) sur notre corpus. La pr&#233;cision moyenne de 79, 5% obtenue en
effectuant une s&#233;lection automatique des indices permet de gagner 4, 8pt (avec un intervalle de
confiance de &#177;0, 8) sur la pr&#233;cision obtenue par le meilleur crit&#232;re homog&#232;ne, ce qui corres-
pond &#224; 22% de l&#8217;&#233;cart avec la borne maximale estim&#233;e. Il s&#8217;agit donc d&#8217;une am&#233;lioration tr&#232;s
substantielle.
</p>
<p>19</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Laurent AUDIBERT
</p>
<p>4.3 Forme et r&#233;partition des indices s&#233;lectionn&#233;s
</p>
<p>FIG. 1 &#8211; Forme et r&#233;partition spatiale des indices s&#233;lectionn&#233;s par l&#8217;algorithme g&#233;n&#233;tique
appliqu&#233; par cat&#233;gorie grammaticale sur le jeu de 888 indices. Les graphiques de gauche
montrent : les proportions d&#8217;indices constitu&#233;s des &#233;tiquettes jeton (J), lemme (L), ems
(E) ou smalems (S) ; les proportions d&#8217;indices diff&#233;renci&#233;s par leur position (O), diff&#233;renci&#233;s
suivant qu&#8217;ils appartiennent au contexte droit ou gauche (D), ou non diff&#233;renci&#233;s (N) ; les pro-
portions d&#8217;indices constitu&#233;s de mots sans distinction (M) ou seulement de mots pleins (Mp) ;
et enfin les proportions d&#8217;indices constitu&#233;s d&#8217;unigrammes (1), de bigrammes (2) ou de tri-
grammes (3). Les graphiques de droite montrent o&#249; se situent les indices (en prenant la position
m&#233;diane pour les bigrammes et trigrammes) par rapport au mot &#224; d&#233;sambigu&#239;ser.
</p>
<p>Nous avons cherch&#233; &#224; en savoir plus sur les indices s&#233;lectionn&#233;s par l&#8217;algorithme g&#233;n&#233;tique
appliqu&#233; par cat&#233;gorie grammaticale sur le jeu de 888 indices, c&#8217;est-&#224;-dire par la s&#233;lection qui
obtient les meilleurs r&#233;sultat et qui correspond &#224; la derni&#232;re ligne du tableau 4. La figure 1
r&#233;sume ces observations pour chacune des cat&#233;gories grammaticales.
</p>
<p>Les graphiques de gauche permettent de remarquer que les &#233;tiquettes jeton et lemme sont
bien plus utilis&#233;es que les &#233;tiquettes ems et smallems ce qui para&#238;t logique et coh&#233;rent avec
la litt&#233;rature. Ils permettent &#233;galement d&#8217;observer que les indices s&#233;lectionn&#233;s sont constitu&#233;s
en proportions comparables d&#8217;unigrammes, de bigrammes et de trigrammes. Cette observation
conforte celle que nous avions faite dans (Audibert, 2004), &#224; savoir que les bigrammes4 et les
trigrammes v&#233;hiculent une information importante qui ne se retrouve pas dans les unigrammes.
Ces graphiques permettent enfin d&#8217;observer que la s&#233;lection op&#233;r&#233;e par l&#8217;algorithme g&#233;n&#233;tique
ne privil&#233;gie pas les indices constitu&#233;s uniquement de mots pleins. Comme nous l&#8217;avions remar-
qu&#233; dans (Audibert, 2004), le filtrage consistant &#224; supprimer les mots grammaticaux n&#8217;appara&#238;t
absolument pas pertinent.
</p>
<p>4 cf. &#233;galement (Pedersen, 2001a) concernant l&#8217;utilisation des bigrammes.
</p>
<p>20</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;sambigu&#239;sation lexicale automatique : s&#233;lection automatique d&#8217;indices
</p>
<p>Les graphiques de droite de la figure 1 montrent que la r&#233;partition spatiale des indices s&#233;lection-
n&#233;s par l&#8217;algorithme g&#233;n&#233;tique diff&#232;re suivant la cat&#233;gorie grammaticale du mot &#224; d&#233;sambigu&#239;-
ser. Concernant les noms, la r&#233;partition des indices est grossi&#232;rement sym&#233;trique par rapport au
mots &#224; d&#233;sambigu&#239;ser et les indices les plus proches sont privil&#233;gi&#233;s. La r&#233;partition des indices
pour la d&#233;sambigu&#239;sation des adjectifs est bien plus aplatie que pour les deux autres cat&#233;gories
grammaticales. De plus, ce sont les adjectifs qui b&#233;n&#233;ficient le moins de l&#8217;am&#233;lioration de la
pr&#233;cision apport&#233;e par la s&#233;lection automatique des indices : 3, 1pt contre 4, 4pt pour les noms
et 5, 4pt pour les verbes. Comme nous l&#8217;avions d&#233;j&#224; observ&#233; dans (Audibert, 2004), la r&#233;parti-
tion des indices pour la d&#233;sambigu&#239;sation des verbes est fortement dissym&#233;trique probablement
parce que la d&#233;sambigu&#239;sation des verbes se fait plus en fonction de leur objet que de leur sujet,
la forme sujet-verbe-compl&#233;ment &#233;tant la plus fr&#233;quente.
</p>
<p>5 Conclusion et perspectives
</p>
<p>Comme (Mohammad &amp; Pedersen, 2004; Ng &amp; Lee, 2002; Pedersen, 2001a), entre autres, nous
pensons que les performance d&#8217;un algorithmes de d&#233;sambigu&#239;sation d&#233;pendent principalement
de la qualit&#233; des indices du contexte consid&#233;r&#233; plut&#244;t que de la sophistication des algorithmes
de d&#233;sambigu&#239;sation utilis&#233;s. Dans cet article, nous avons expos&#233; une exp&#233;rience consistant &#224;
automatiser une s&#233;lection d&#8217;indices de natures diff&#233;rentes. Ainsi, en r&#233;alisant une s&#233;lection au-
tomatique bas&#233;e sur un algorithme g&#233;n&#233;tique, nous sommes parvenus &#224; une pr&#233;cision de d&#233;sam-
bigu&#239;sation, sur les 60 vocables de notre &#233;tude, de 79.5%, soit 4, 8pt de plus que la pr&#233;cision
obtenue par le meilleur crit&#232;re homog&#232;ne identifi&#233; lors de notre &#233;tude syst&#233;matique pr&#233;c&#233;dente
(Audibert, 2004).
</p>
<p>Cette am&#233;lioration est importante, mais d&#8217;autres espoirs d&#8217;am&#233;liorations sont &#224; attendre de l&#8217;en-
richissement des indices disponibles en utilisant, par exemple :
&#8211; des indices issus de relations syntaxiques binaires (nom-nom, nom-verbe, adjectif-nom, etc.) ;
&#8211; des th&#233;saurus ou des ontologies pour effectuer des g&#233;n&#233;ralisations sur les mots du contexte
du mot &#224; d&#233;sambigu&#239;ser ;
</p>
<p>&#8211; des informations sur le th&#232;me du texte.
</p>
<p>R&#233;f&#233;rences
</p>
<p>AUDIBERT L. (2003a). Etude des crit&#232;res de d&#233;sambigu&#239;sation s&#233;mantique automatique : r&#233;-
sultats sur les cooccurrences. In 10&#232;me conf&#233;rence sur le Traitement Automatique des Langues
Naturelles (TALN-2003), p. 35&#8211;44, Batz-sur-Mer.
</p>
<p>AUDIBERT L. (2003b). Outils d&#8217;exploration de corpus et d&#233;sambigu&#239;sation lexicale automa-
tique. PhD thesis, Universit&#233; de Provence.
</p>
<p>AUDIBERT L. (2004). Word sense disambiguation criteria : a systematic study. In 20th Inter-
national Conference on Computational Linguistics (COLING-2004), p. 910&#8211;916, Geneva.
</p>
<p>BRUCE R., WIEBE J. &amp; PERDERSEN T. (1996). The measure of a model. In E. BRILL &amp;
K. W. CHURCH, Eds., 1st Conference on Empirical Methods in Natural Language Processing
(EMNLP-1996), p. 101&#8211;112, Somerset, New Jersey : Association for Computational Linguis-
tics.
</p>
<p>21</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Laurent AUDIBERT
</p>
<p>CUSSENS J. (1993). Bayes and pseudo-bayes estimates of conditional probability and their
reliability. In P. B. BRAZDIL, Ed., 6th European Conference on Machine Learning (ECML-
1993), p. 136&#8211;152, Springer-Verlag, Berlin.
DAELEMANS W., HOSTE V., MEULDER F. D. &amp; NAUDTS B. (2003). Combined optimization
of feature selection and algorithm parameter interaction in machine learning of language. In
14th European Conference on Machine Learning (ECML-2003), Cavtat-Dubrovnik, Croatia.
EDMONDS P. (2002). Introduction to senseval. In ELRA Newsletter.
IDE N. &amp; V&#201;RONIS J. (1998). Word sense disambiguation : The state of the art. In Computa-
tional Linguistics : Special Issue on Word Sense Disambiguation, volume 24, p. 1&#8211;40.
KILGARRIFF A. (1997). Evaluating word sense disambiguation programs : Progress report.
In Speech and Language Technology (SALT-1997) Workshop on Evaluation in Speech and
Language Technology, p. 114&#8211;120, Sheffield University, United Kingdom.
MOHAMMAD S. &amp; PEDERSEN T. (2004). Combining lexical and syntactic features for su-
pervised word sense disambiguation. In Proceedings of CoNLL-2004, p. 25&#8211;32, Boston, MA,
USA.
NG H. T. &amp; LEE Y. K. (2002). An empirical evaluation of knowledge sources and learning
algorithms for word sense disambiguation. In 7th Conference on Empirical Methods in Natural
Language Processing (EMNLP-2002), p. 41&#8211;48, Philadelphia, Pennsylvania, USA.
NG H. T. &amp; ZELLE J. (1997). Corpus-based approaches to semantic interpretation in natural
language processing. In Artificial Intelligence Magazine - Special Issue on Natural Language
Processing, volume 18, p. 45&#8211;64.
PALMER M. (1998). Are WordNet sense distinctions appropriate for computational lexicons.
In Association for Computational Linguistics Special Interest Group on the Lexicon (ACL-
SIGLEX-1998) : SENSEVAL, Herstmonceux, Sussex, UK.
PEDERSEN T. (2001a). A decision tree of bigrams is an accurate predictor of word sense. In
Second Annual Meeting of the North American Chapter of the Association for Computational
Linguistics, p. 79 ?&#8211;86, Pittsburgh.
PEDERSEN T. (2001b). Machine learning with lexical features : The duluth approach to
senseval-2. In 2nd International Workshop on Evaluating Word Sense Disambiguation Sys-
tems (SENSEVAL-2), p. 139&#8211;142.
REYMOND D. (2001). Dictionnaires distributionnels et &#233;tiquetage lexical de corpus. In 5&#232;me
Rencontre des &#201;tudiants Chercheurs en Informatique pour le Traitement Automatique des
Langues (RECITAL-2002), volume 1, p. 479&#8211;488, Tours.
VALLI A. &amp; V&#201;RONIS J. (1999). Etiquetage grammatical de corpus oraux : Probl&#232;mes et
perpectives. In Revue Fran&#231;aise de Linguistique Appliqu&#233;e, volume IV, p. 113&#8211;133. Champs-
sur-Marne : Association pour le traitement informatique des langues (ASSTRIL).
V&#201;RONIS J. (1998). A study of polysemy judgements and inter-annotator agreement. In
Programme and Advanced Papers of the Senseval Workshop, Herstmonceux Castle, England.
V&#201;RONIS J. (2001). Sense tagging : Does it makes sense. In Corpus Linguistics, Lancaster,
U.K.
YAROWSKY D. (1994). A comparision of corpus-based techniques for restoring accents in
spanish and french text. In 2nd Annual Workshop on Very Large Text Corpora, p. 19&#8211;32, Las
Cruces.
</p>
<p>22</p>

</div></div>
</body></html>