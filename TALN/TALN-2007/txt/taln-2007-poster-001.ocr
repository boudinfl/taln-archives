TALN 2007, Toulouse, 5-8 juin 2007

Désarnbiguisation lexicale automatique :
sélection automatique d’indices

Laurent AUDIBERT
Laboratoire d’Informatique de l’universite Paris—Nord (LIPN)
99, avenue Jean—Baptiste Clement — 93430 Villetaneuse, France
laurent . audibert@lipn . univ—parisl3 . fr

Résumé. Nous exposons dans cet article une experience de selection automatique des in-
dices du contexte pour la desambigu'1'sation lexicale automatique. Notre point de vue est qu’il
est plus judicieux de privilegier la pertinence des indices du contexte plutot que la sophistica-
tion des algorithmes de desambiguisation utilises. La selection automatique des indices par le
biais d’un algorithme genetique arneliore signiﬁcativement les resultats obtenus dans nos expe-
riences precedentes tout en confortant des observations que nous avions faites sur la nature et
la repartition des indices les plus pertinents.

Abstract. This article describes an experiment on automatic features selection for word
sense disambiguation. Our point of View is that word sense disambiguation success is more
dependent on the features used to represent the context in which an ambiguous word occurs
than on the sophistication of the learning techniques used. Automatic features selection using
a genetic algorithm improves signiﬁcantly our last experiment bests results and is consistent
with the observations we have made on the nature and space distribution of the most reliable
features.

Mots-clés 2 desarnbiguisation lexicale automatique, corpus semantiquement etiquete,
cooccurrences, selection d’indices, algorithmes genetiques.

Keywords: word sense disambiguation, sense tagged corpora, cooccurrences, features
selection, genetic algorithms.

1 Introduction

La plupart des mots ont plusieurs signiﬁcations. La désambiguisation lexicale consiste a choi-
sir la bonne signiﬁcation d’un mot polysemique dans un contexte donne. Cette operation est
utile ou indispensable pour la plupart des applications de traitement automatique des langues 2
recherche d’inforrnation, traduction automatique, reconnaissance de la parole, etc. (Ide & Ve-
ronis, 1998). La carnpagne d’ evaluation trisannuel SensEval (Edrnonds, 2002) atteste de l’im-
portance de cette téiche.

La desambigu'1'sation lexicale s’effectue toujours en utilisant l’inforrnation presente dans le
contexte du mot a desarnbigu'1'ser. Cette information peut etre enrichie par un certain nombre
d’a.nnotations (etiquette morphosyntaxique, lemrnatisation, etc.). 11 n’est cependant pas pos-

13

Laurent AUDIBERT

sible d’utiliser toute l’information disponible car elle est bien trop importante et bruitée. Il faut
donc se focaliser sur un certain nombre d’indices. Le choix de ces indices, déterminé par ce que
nous appelons des criteres de désambiguisation lexicale, est primordial et constitue un enjeu
important dans le domaine de la désambiguisation lexicale automatique (Bruce et al., 1996; Ng
& Zelle, 1997; Pedersen, 2001b).

Notre approche s’inscrit dans celles qui utilisent des techniques de classiﬁcation supervisée sur
un corpus lexicalement désambiguisé. Dans ce type d’approche, de nombreux travaux cherchent
a arnéliorer la précision de la désambigu'1'sation en arnéliorant les techniques de classiﬁcation.
Le choix des indices utilisés est généralement déterminé plus ou moins arbitrairement par la
connaissance, l’expérience et l’intuition du chercheur. Peu de travaux avaient étudié systéma-
tiquement l’impact du choix des indices utilisés sur la précision de la désambigu'1'sation. Pour
cette raison, nous avons présenté une étude des criteres de désambigu'1'sation sémantique auto-
rnatique (Audibert, 2003a) basés sur les unigrarmnes (i. e. cooccurrences de mots isolés). Nous
avons complété cette étude en explorant des indices basés sur des bigrammes et des trigrammes
(Audibert, 2004). Dans ces travaux, les criteres étudiés étaient homogenes dans le sens o1‘1 ils
étaient constitués d’indices de méme nature 2 par exemple, soit des lemmes, soit des étiquettes
morphosyntaxiques, mais pas une combinaison des deux.

Dans le présent article, nous présentons, dans un premier temps, une petite étude comparative
de différents algorithmes de classiﬁcation. Nous nous intéressons ensuite a la sélection auto-
rnatique des meilleurs indices du contexte pour former des criteres de désambiguisation hété-
rogenes sur lesquels un algorithme de classiﬁcation peut s’appuyer efﬁcacement pour effectuer
de la désambiguisation lexicale. Ce travail s’appuie toujours sur les 60 mots cibles (20 noms,
20 adjectifs et 20 verbes) des travaux précédents (Audibert, 2003a; Audibert, 2004).

2 Corpus, indices et critéres

2.1 Corpus

Notre corpus de travail est composé de textes de genres variés et comporte 6 468 522 mots. 11 a
été constitué dans le cadre du proj et SyntSem qui vise a produire un corpus francais d’amorcage
étiqueté au niveau morphosyntaxique, lermnatisé et comportant un étiquetage syntaxique peu
profond ainsi qu’un étiquetage lexical de 60 mots-cibles sélectionnés pour leur caractere forte-
ment polysérnique (Véronis, 1998). Ces 60 mots-cibles, qui totalisent 53796 occurrences dans
le corpus, sont également répartis en 20 noms, 20 adjectifs et 20 verbes et sont détaillés dans le
tableau 1.

L’une des difﬁcultés majeures de l’étiquetage sémantique automatique réside dans l’inadéqua-
tion des dictionnaires traditionnels (Véronis, 2001) ou dédiés (Palmer, 1998) pour cette tache.
Pour remédier a ce probleme, l’équipe DELIC 1 a entrepris la construction d’un dictionnaire
distributionnel en se basant sur un ensemble de criteres différentiels stricts (Reymond, 2001).
C’est ce dictionnaire qui a été utilisé pour étiqueter les occurrences des 60 mots-cibles du proj et
SyntSem. Dans ce dictionnaire, le nombre de lexies par vocable est important car il inclut les
locutions ﬁgées ou composées comme mettre sur pied, mettre £1 pied, pied de nez, etc.

Un consensus semble émerger selon lequel l’étiquetage morphosymtaxique, et plus parLiculie-

1Equipe DELIC, Université de Provence, 29 Avenue Robert SCHUMAN, 13621 Aix-en-Provence Cedex 1.

14

Désambiguisation lexicale automatique 2 selection automatique d’indices

TAB. 1 — Fréquence moyenne des occurrences des vocables (freq), nombre moyen de lexies

(lex) et entropie de la repartition des occurrences sur les lexies (H).

rement la levée de l’ambigu'1'té sur la catégoiie grammaticale des vocables, n’ est pas du ressort
de la désambiguisation lexicale (Kilganiff, 1997; Ng & Zelle, 1997). Nous avons conﬁé l’éti-
quetage morphoswitaxique de notre corpus au logiciel Cordial Analyseur (développé par la so-
ciété Swiapse Développement), qui offre une lennnatisation et un étiquetage morphosyntaxique

d’une exactitude satisfaisante (Valli & Véronis, 1999).

Le Tableau 2 présente un extrait du corpus SyntSem. I1 permet de Visualiser l’ensemble des
étiquettes que possede un mot. C’ est l’information de ces étiquettes que nous utilisons dans nos

jeton lemme ems smallems lexie
pouvait pouvoir VINDI3S VCON
mettre mettre VINF VINF 1.12.7
ﬁn ﬁn NCFS NCOM
51 51 PREP PREP
la le DETDFS DET
pratique pratique NCFS NCOM
des de DETDPIG DET
détentions détention NCFP NCOM 1

TAB. 2 — Extrait du corpus SyntSem

criteres de désambiguisation lexicale.

15

Noms Adjectifs Verbes
Vocable freq lex H Vocable freq lex H Vocable freq lex H
barrage 92 5 1, 18 correct 116 5 1, 81 couvrir 518 21 3, 25
restauration 104 5 1, 85 sain 129 10 2, 45 importer 576 8 2, 57
suspension 110 5 1, 50 courant 168 4 0, 63 parvenir 653 8 2, 31
détention 112 2 0,85 régulier 181 11 2,54 exercer 698 8 1,52
lancement 138 5 0, 99 frais 182 18 3, 10 conclure 727 16 2, 36
concentration 246 6 1, 98 secondaire 195 5 1, 69 airéter 913 15 2, 97
station 266 8 2, 58 strict 220 9 2, 23 ouvrir 919 41 3, 80
vol 278 10 2,20 exceptionnel 226 3 1,45 poursuivre 978 16 2,71
organe 366 6 2, 24 utile 359 9 2, 39 tirer 1001 47 3, 88
compagnie 412 12 1, 62 vaste 368 6 2, 08 conduire 1082 15 2, 28
constitution 422 6 1, 64 sensible 425 11 2, 63 entrer 1210 38 3, 65
degré 507 18 2, 47 traditionnel 447 2 0, 49 connaitre 1635 16 2, 24
observation 572 3 0, 68 populaire 457 5 2, 02 rendre 1985 27 2, 88
passage 601 19 2,70 biologique 475 4 0,55 comprendre 2136 13 2,76
solution 880 4 0, 44 clair 556 20 3, 10 presenter 2140 18 2, 56
économie 930 10 2, 16 historique 620 3 0, 67 porter 2328 59 4, 01
pied 960 62 3, 55 sﬂr 645 14 2, 61 répondre 2529 9 0, 99
chef 1133 11 1, 47 plein 844 35 3, 99 passer 2547 83 4, 49
fonnation 1528 9 1, 66 haut 1016 29 3, 46 venir 3788 33 3, 21
communication 1703 13 2,44 simple 1051 14 2,14 mettre 5095 140 3,65
Moyenne 568 14, 2 1, 9 Moyenne 434, 4 14, 1 2, 3 Moyenne 1687, 6 47, 4 3, 1

Laurent AUDIBERT

2.2 Indices et critéres

Nous désignons par le terme d’indice une source potentielle d’ir1formation pouvant participer a
la levée de l’ambigu'1'té d’un mot cible dont nous cherchons la bonne lexie. Un indice peut étre
le lemme du mot qui précede par exemple. Un critére est simplement la donnée d’un ensemble
d’indices.

Nous avons étudié une grande variété de criteres dans (Audibert, 2004). Les noms de ces cri-
teres précisent leur nature et sont de la forme [P 1 I P 2 I P3 I P4] . Le parametre P 1 indique si
le critere considere des unigrarmnes (P 1=1gr), des bigrammes (P 1=2 gr) ou des trigrammes
(P 1=3gr); un n-grarmne étant la juxtaposition de 11 mots. Le parametre P2 indique si l’on
regarde la forme brute des mots (P2=jeton), leur lemme (P2=lemme), leur étiquette mor-
phosyntaxique (P 2 =ems) ou leur étiquette morphosyntaxique sirnpliﬁée (P 2 =sma l l ems). Le
parametre P 3 indique si les mots considérés sont différenciés par leur position (P 3=ordonne),
différenciés suivant qu’ils appartiennent au contexte droit ou gauche (P 3=di f f erencie), ou
non différenciés (P3=non—ordonne). Enﬁn, le parametre P4 indique si le critere considere
tous les mots (P4=mot) ou seulement les mots pleins (P4=mot—plein). Nous qualiﬁons
ces critéres de critéres homogénes dans la mesure oh 1’ ensemble des indices de désambigu'1'-
sation sont de la méme nature puisque entierement déterminés par l’instar1ciation des quatre
paramétres.

3 Comparaison de différents algorithmes de désambigu'1'sa-
tion

Dans cette expérience, nous comparons différents algorithmes de classiﬁcation supervisée en
utilisant un critere assez standard constitué du lemme des mots en tenant compte de leur posi-
tion (i.e. [1gr I lemme I ordonne |mot]) dans une fenétre de :|:3 mots. Les algorithmes de
classiﬁcation évalués sont les suivants 2

MAJ est un classiﬁeur qui retoume touj ours la lexie la plus fréquente ; nous l’utilisons comme
borne inférieure a la précision de la désambigu'1'sation;

PCM est un algorithme basé sur une liste de décisions, proche de celui utilisé par (Yarowsky,
1994) et détaillé dans (Audibert, 2003a) ;

NB est notre implémentation du classiﬁeur Na'1'f de Bayes;
KPPV est une implémentation élémentaire d’un classiﬁeur du type k plus proches voisins;

PEBLS est classiﬁeur du type k plus proches voisins possédant une métrique bien plus sophis-
tiqué que celle de KPPV;

NBW est l’implémentation du proj et Weka du classiﬁeur Na'1'f de Bayes ;
C45W est l’implémentation du proj et Weka du classiﬁeur C45.

Le tableau 3 montre les rés11ltats de cette expérience comparative. Dans toutes les expériences
de désambiguisation de cet article, toutes les occurrences recoivent une classiﬁcation. Le rappel
étant égal a la précision dans ce cas, nous ne mentionnons que la précision obtenue.

Les temps d’exécution des deux algorithmes du projet Weka que nous avons utilisés (NBW et
C4 5W) sont rédhibitoires pour nos expériences. Les raisons de ces temps d’exécution sont, ou
peuvent étre, la non optimisation de l’implémentation, l’utilisation du langage java et le format,

16

Desambigu'1'sation lexicale automatique 2 selection automatique d’indices

MAJ PCM NB KPPV PEBLS NBW C45W

Precision 42,9% 72, 3% 74, 5% 65, 5% 7o,9% 58, 2% 74, 6%
Intervalle de conﬁance :|:0,38% :|:0, 37% :|:0,40% :|:0, 38% :|:0,42% :|:0,37%
Temps 3s 3s 5s 261Im 2h33nm 1h47mn 35h43mn

TAB. 3 — Comparaison de la precision, avec intervalle de conﬁance de l’estimation a 95%, et
des temps d’ execution de differents algorithmes de classiﬁcation.

peu adapte au probleme, de la representation des donnees d’ apprentissage. Le temps d’ execution
du classiﬁeur PEBLS est egalement bien trop important et est une consequence de la complexite
de la metrique utilisee.

Les classiﬁeurs NB et PCM, necessitent tous deux des estimations de probabilites. En raison
des observations souvent rares et parfois n11lles qui interviennent dans ces estimations, nous
utilisons la m-estimation (Cussens, 1993) plut6t que l’estimation classique des probabilites.
Cette difference explique certainement l’ecart de performance des classiﬁeurs NB et NBW.

Nous pouvons tirer deux enseignements de cette experience. La premier est qu’il est souvent
difﬁcile et parfois prejudiciable d’ utiliser un algorithme de classiﬁcation comme une bo’1‘te noire
(cf. la comparaison entre NB et NBW). Le second est que la complexite et la sophistication des
algorithmes de classiﬁcation n’apportent pas forcement un gain important pour notre tache (cf.
la comparaison entre NB, PEBLS et C4 5). Actuellement, des gains bien plus importants sont a
attendre des indices foumis aux classiﬁeurs plut6t que des classiﬁeurs eux-memes.

4 Selection automatique des indices

4.1 Méthodologie

En prenant tous les indices generes par tous les criteres homogenes [P1 IP2 IP3 | P4] cor-
respondants aux differentes instanciations possibles des quatre parametres P1 a P4, et en
considerant une fenetre de :|:12 mots, nous obtenons 3 (lgr, 2gr ou 3gr) ><4 (jeton,
lemme, ems ou smallems) ><3 (ordonne, differentie ou non—ordonne) ><2 (mot
ou mot—plein) ><24 (contexte de :|:12 motsz) soit 1728 indices differents.

En reduisant la taille du contexte considere, nous avons genere un deuxieme jeu d’ indices reduit
a 888 indices. Dans ce jeu d’ indices, la taille du contexte pour les criteres bases sur les etiquettes
lemme et jeton et composes d’unigrammes (respectivement de bigrammes et trigrammes)
est de :|:6 mots (respectivement :|:8 et :|:l0), et pour les criteres bases sur les etiquettes ems
et smal lems et composes d’unigrammes (respectivement de bigrammes et trigrammes) est de
:|:4 mots (respectivement :|:5 et :|:6).

La question est de savoir quels indices retenir, parmi les 1728 du premier jeu d’indices ou parmi
les 888 du second, pour former un critere heterogene efﬁcace pour la levee de l’ambigu'1'te. Pour
representer un critere nous utilisons une cha’1‘ne de bits, appelee un genome, composee de 1728

2 Le calcul est ici simpliﬁé, en réalite, le nombre d‘indices considérés sans sortir du contexte de 21:12 mots est
de 12 + 1 + 12 = 25 pour les unigrammes, 12 + 1 + 11 = 24 pour les bigrammes et 12 + 1 + 10 = 23 pour les
trigrammes ce qui fait bien 24 en moyenne.

17

Laurent AUDIBERT

bits pour le premier jeu et de 888 bits pour le second. La valeur de chaque bit permet de préci-
ser si l’indice associé est retenu ou pas. Un génome caractérise donc un critere (une sélection
d’indices) hétérogene (tous les indices ne sont pas forcément de la méme nature). En raison de
la complexité combinatoire de rrotre probleme d’optimisation de sélection d’indices, il n’existe
pas de méthode exacte pour le résoudre en un temps raisonnable. Il faut donc se contenter de
solutions approchées que nous obtenons en utilisant deux techniques classiques d’ optimisation 2
les algorithmes gloutons et les algorithmes génétiques3. Le principe de l’algorithme glouton est
de rechercher le meilleur indice pris individuellement, puis de chercher quel indice lui associer
pour arnéliorer au maximum la précision, et ainsi de suite jusqu’a ne plus obtenir d’amélio-
ration. Les algorithmes génétiques, quant a eux, tentent de mettre en oeuvre le principe de la
sélection naturelle (croisements et mutations) sur des populations de solutions potentielles (i.e
des génomes) et se rapprochent de la solution au cours de générations successives.

Pour mettre en oeuvre ces techniques, le corpus de départ est scindé en deux sous-corpus. Le
premier sous-corpus contient 60% des exemples d’apprentissage. Il est utilisé dans un premier
temps pour effectuer la sélection des indices en utilisant l’algorithme glouton ou l’algorithme
génétique. Cette sélection se fait en générant une famille de génomes en suivant les regles
propres a l’algorithme glouton ou génétique. L’ évaluation de la performance de chacun des gé-
nomes (i. e. sous-ensemble d’ir1dices) est réalisée par l’estimation de la précision obtenue par le
classiﬁeur NB en utilisant une méthode d’évaluation croisée kt fois (avec k2 = 10) toujours sur
ce méme sous-corpus. Cette méthode est coﬁteuse en temps de calcul, mais permet l’évaluation
des criteres (i. e. des génomes) sur la totalité du sous-corpus. Une nouvelle génération de gé-
nomes est ensuite calculée en fonction de la génération précédente et des regles de l’algorithme
glouton ou génétique. L’ expérience est répétée tant que des génomes plus performants émergent
des générations successives.

Les indices sélectionnés par le génome obtenant la meilleure performance constituent un critere
hétérogene utilisé pour l’apprentissage du classiﬁeur NB sur la totalité du sous-corpus contenant
60% des exemples. Le deuxieme sous-corpus, qui contient 40% des exemples d’apprentissage,
est enﬁn utilisé pour estimer la précision de désambigu'1'sation obtenue par le classiﬁeur NB
précédemment entrainé.

Cette expérience a été conduite d’un coté sur chacun des vocables irrdépendamment (i.e. un
génome est sélectionné pour chacun des vocables) et d’un autre coté par catégorie grarnmaticale
(i.e. un unique génome est sélectionné pour les 20 vocables d’une catégorie). L’ expérience par
catégorie grammaticale n’a pas été menée pour le jeu contenant 1728 indices en raisons des
temps de calcul déja de l’ordre de la dizaine de jours pour le jeu contenant 888 indices. Le
tableau 4 rend compte des résultats de notre expérience.

4.2 Résultats des différentes expériences de sélection

La lecture du tableau 4 permet d’observer irnmédiatement que chacune des expériences de sé-
lection automatique des indices 51 permis de surpasser la précision obtenue par le meilleur critere
homogene identiﬁé dans (Audibert, 2004).

Nous avons systématiquement obtenu de meilleurs résultats en sélectionnant les indices avec
l’algorithme génétique plutot qu’avec l’algorithme glouton qui est incapable de se sortir d’un

3 Ce type d‘approche n‘est pas original, par exemple (Daelemans et al., 2003) montrent comment obtenir une
amélioration signiﬁcative des performances en réalisant une optimisation simultanée des parametres de 1‘algo-
rithme d‘apprentissage et de la sélection des indices en utilisant justement des algorithmes génétiques.

18

Desambigu'1'sation lexicale automatique 2 selection automatique d’indices

Noms Adjectifs Verbes Moyenne
P(%) Am. ICA P(%) Am. ICA P(%) Am. ICA P(%) Am. ICA
Baseline (MAJ) 57,2 46,3 37,2 42,9
Criterehomogene 81,4 0,0 75,1 0,0 72,3 0,0 74,7 0,0

GlouNoc (1728) 82,5 1,0 i1,6 75,7 0,5 i2,0 74,3 2,0 11,1 76,3 1,6 i0,8
GeneNoc(1728) 83,5 2,1 i1,6 75,9 0,7 i2,0 75,1 2,8 i1,0 77,0 2,3 i0,8
GlouNoc(888) 82,9 1,5 i1,6 75,7 0,6 i2,0 75,0 2,7 i1,0 76,8 2,1 i0,8
GeneNoc(888) 85,3 3,9 i1,5 77,3 2,2 i2,0 77,3 5,0 i1,0 79,0 4,3 i0,8
Glou/Cat(888) 83,7 2,3 i1,6 75,9 0,7 i2,0 76,8 4,5 i1,0 78,1 3,4 i0,8
Gene/Cat(888) 85,9 4,4 i1,5 78,2 3,1 i2,0 77,7 5,4 i1,0 79,5 4,8 i0,8

TAB. 4 — Precision d’un critere heterogene constitue par selection automatique des indices. La
ligne Baseline (MAJ) donne la precision obtenue par l’algorithme retoumant systematiquement
la lexie majoritaire. La ligne Critere homogene donne la precision obtenue par le meilleur cri-
tere homogene, c’est-a-dire le critere [2 gr I lemme I di fferencie I mot] ) avec une taille
de fenetre de :|:4 mots pour les r1on1s et les verbes et :|:3 mots pour les adjectifs. Dans les lignes
suivantes, Glou signiﬁe que la technique de selection d’indices utilisee est de type algorithme
glouton tandis que Gene signiﬁe que la technique utilisee est de type algorithme genetique. Vac
signiﬁe que la selection d’indices est independante pour chacun des vocables et Cat qu’elle est
commune aux 20 vocables de la categorie grammaticale. (1728) et (888) precisent la taille du
jeux d’indices de l’experience. La colonne P (%) donne la precision obtenue en pourcentage,
Am. l’amelioration realisee par rapport a la precision du meilleur critere homogene (ligne Cri-
tere homogene) et I CA l’intervalle de conﬁance a 95% de l’ame1ioration realisee (l’intervalle de
conﬁance de la precision etant bien inferieur).

minimum local. Dans nos experiences, l’algorithme glouton selectionne environ 20 indices.
D’un autre cote, un algorithme genetique est capable, par deﬁnition, de se sortir d’un minimum
local. Cependant, il ne garantit pas que tous les indices selectionnes sont utiles et il selectionne,
dans nos experiences, environ 180 indices.

Un autre phenomene qui ressort de la lecture de ces resultats est que le jeu d’indices qui n’en
contient que 888 permet d’aboutir a de meilleurs res11ltats que le jeu d’indices en contenant
1728. Les deux raisons de ce comportement sont la taille du corpus d’apprentissage, probable-
ment trop faible pour une telle quantite d’indices, et le piege du surapprentissage sensible dans
notre approche.

De maniere surprenante, nous obtenons de meilleurs resultats en operant la selection sur l’en-
semble d’une categorie grammaticale plutot que sur chacun des vocables pris individuellement.
Operer la selection sur l’ensemble d’une categorie grammaticale permet de limiter le pheno-
mene de surapprentissage et d’augmenter le nombre d’exemples sur lesquels se fait la selec-
tion. Le gain obtenu par la limitation du phenomene de surapprentissage et l’augmentation du
nombre d’exemples est ici superieur a celui obtenu par l’ajustement de la selection des indices
individuellement pour chaque vocable.

L’ accord entre plusieurs annotateurs (1 TA pour InTer-annotator Agreement en anglais) a ete es-
time a 96.4% (Audibert, 2003b) sur notre corpus. La precision moyenne de 79, 5% obtenue en
effectuant une selection automatique des indices permet de gagner 4, 81215 (avec un intervalle de
conﬁance de :|:0, 8) sur la precision obtenue par le meilleur critere homogene, ce qui corres-
pond a 22% de l’ecart avec la borne maximale estimee. ll s’agit donc d’une amelioration tres
substantielle.

19

Laurent AUDIBERT

4.3 Forme et répartition des indices sélectionnés

Norma

 
 
  

 

 

(JLES)lODN)lMMp)l1Z3l —lo—9—a—7—6—5—4—3r2—lo12345673910

Adleciiifs l ‘ ‘

   

 

ULESl(0DN)(MMp)ll23l —1o—9—a—7—6—5—4r3—2—1u12345675910

 

U L E5)l0DN)[MMp)(12 3|

FIG. 1 — Forme et répartition spatiale des indices sélectionnés par l’algorithme génétique
appliqué par catégorie grarnmaticale sur le jeu de 888 indices. Les graphiques de gauche
montrent : les proportions d’indices constitués des étiquettes jeton (J), lemme (L), ems
(E) ou smalems (S); les proportions d’indices différenciés par leur position (0), différenciés
suivant qu’ils appartiennent au contexte droit ou gauche (D), ou non différenciés (N); les pro-
portions d’indices constitués de mots sans distinction (M) ou seulement de mots pleins (Mp);
et enﬁn les proportions d’indices constitués d’unigrarnrnes (1), de bigrarmnes (2) ou de tri-
grarmnes (3). Les graphiques de droite montrent o1‘1 se situent les indices (en prenant la position
médiane pour les bigrammes et trigrammes) par rapport au mot a désarnbiguiser.

Nous avons cherché 51 en savoir plus sur les indices sélectionnés par l’algorithme génétique
appliqué par catégorie grarnmaticale sur le jeu de 888 indices, c’est-a-dire par la sélection qui
obtient les meilleurs résultat et qui correspond a la demiére ligne du tableau 4. La ﬁgure 1
résume ces observations pour chacune des catégories grarnmaticales.

Les graphiques de gauche permettent de remarquer que les étiquettes jeton et lemme sont
bien plus utilisées que les étiquettes ems et smallems ce qui parait logique et cohérent avec
la littérature. Ils permettent également d’ observer que les indices sélectionnés sont constitués
en proportions comparables d’unigrammes, de bigrammes et de trigrarnmes. Cette observation
conforte celle que nous avions faite dans (Audibert, 2004), a savoir que les bigrammes4 et les
trigrarnrnes véhiculent une information importante qui ne se retrouve pas dans les unigrarnrnes.
Ces graphiques permettent enﬁn d’ observer que la sélection opérée par l’algorithme génétique
ne privilégie pas les indices constitués uniquement de mots pleins. Comme nous l’avions remar-
qué dans (Audibert, 2004), le ﬁltrage consistant a supprimer les mots grarnmaticaux n’appara’1‘t
absolument pas pertinent.

4 cf. également (Pedersen, 2001a) concemant l‘uti]isation des bigrammes.

20

Desambigu'1'sation lexicale automatique 2 selection automatique d’indices

Les graphiques de droite de la ﬁgure 1 montrent que la repartition spatiale des indices selection-
nes par l’algorithme genetique differe suivant la categorie grammaticale du mot a desambigu'1'-
ser. Concemant les r1on1s, la repartition des indices est grossierement syrnetrique par rapport au
mots a desambigu'1'ser et les indices les plus proches sont privilegies. La repartition des indices
pour la desambiguisation des adjectifs est bien plus aplatie que pour les deux autres categories
grammaticales. De plus, ce sont les adjectifs qui beneﬁcient le moins de l’amelioration de la
precision apportee par la selection automatique des indices 2 3, lpt contre 4, 41215 pour les r1on1s
et 5, 41215 pour les verbes. Comme nous l’avions deja observe dans (Audibert, 2004), la reparti-
tion des indices pour la desambigu'1'sation des verbes est fortement dissymetrique probablement
parce que la desambigu'1'sation des verbes se fait plus en fonction de leur obj et que de leur suj et,
la forme suj et-verbe-complement etant la plus frequente.

5 Conclusion et perspectives

Comme (Mohammad & Pedersen, 2004; Ng & Lee, 2002; Pedersen, 2001a), entre autres, nous
pensons que les performance d’un algorithmes de desambigu'1'sation dependent principalement
de la qualite des indices du contexte considere plut6t que de la sophistication des algorithmes
de desambiguisation utilises. Dans cet article, nous avons expose une experience consistant a
automatiser une selection d’indices de natures differentes. Ainsi, en realisant une selection au-
tomatique basee sur un algorithme genetique, nous sommes parvenus a une precision de desarn-
biguisation, sur les 60 vocables de notre etude, de 79.5%, soit 4, 81275 de plus que la precision
obtenue par le meilleur critere homogene identiﬁe lors de notre etude systematique precedente
(Audibert, 2004).

Cette amelioration est importante, mais d’autres espoirs d’ arneliorations sont a attendre de 1’ en-
richissement des indices disponibles en utilisant, par exemple 2

— des indices issus de relations symtaxiques binaires (nom-nom, nom-verbe, adj ectif-nom, etc.) ;
— des thesaurus ou des ontologies pour effectuer des generalisations sur les mots du contexte

du mot a desambiguiser;
— des inforrnations sur le theme du texte.

Références

AUDIBERT L. (2003a). Etude des criteres de desambiguisation semantique automatique 2 re-
sultats sur les cooccurrences. In I 0”“ conference sur le Traitement Automatique des Iangues
Naturelles (TALN-2003), p. 35-44, Batz-sur-Mer.

AUDIBERT L. (2003b). Outils d’exploration de corpus et desambiguisation lexicale automa-
tique. PhD thesis, Universite de Provence.

AUDIBERT L. (2004). Word sense disambiguation criteria 2 a systematic study. In 20"‘ Inter-
national Conference on Computational Linguistics (COLING-2004), p. 910-916, Geneva.

BRUCE R., WIEBE J. & PERDERSEN T. (1996). The measure of a model. In E. BRILL &
K. W. CHURCH, Eds., I 5’ Conference on Empirical Methods in Natural Language Processing
(EMNLP-I996), p. 101-112, Somerset, New Jersey 2 Association for Computational Linguis-
tics.

21

Laurent AUDIBERT

CUSSENS J. (1993). Bayes and pseudo-bayes estimates of conditional probability and their
reliability. In P. B. BRAZDIL, Ed., 6"‘ European Conference on Machine Learning (ECML-
I 993), p. 136-152, Springer-Verlag, Berlin.

DAELEMANS W., HOSTE V., MEULDER F. D. & NAUDTS B. (2003). Combined optimization
of feature selection and algorithm parameter interaction in machine learning of language. In
14"‘ European Conference on Machine Learning (ECML-2003), Cavtat-Dubrowrik, Croatia.

EDMONDS P. (2002). Introduction to senseval. In ELRA Newsletter.

IDE N. & VERONIS J. (1998). Word sense disambiguation 2 The state of the art. In Computa-
tional Linguistics : Special Issue on Word Sense Disambiguation, volume 24, p. 1-40.

KILGARRIFF A. (1997). Evaluating word sense disambiguation programs 2 Progress report.
In Speech and Language Technology (SALT-I997) Workshop on Evaluation in Speech and
Language Technology, p. 114-120, Shefﬁeld University, United Kingdom.

MOHAMMAD S. & PEDERSEN T. (2004). Combining lexical and syntactic features for su-
pervised word sense disambiguation. In Proceedings of CoNLL-2004, p. 25-32, Boston, MA,
USA.

NG H. T. & LEE Y. K. (2002). An empirical evaluation of knowledge sources and learning
algorithms for word sense disambiguation. In 7"‘ Conference on Empirical Methods in Natural
Language Processing (EMNLP-2002), p. 41-48, Philadelphia, Pennsylvania, USA.

NG H. T. & ZELLE J. (1997). Corpus-based approaches to semantic interpretation in natural
language processing. In Artificial Intelligence Magazine - Special Issue on Natural Language
Processing, volume 18, p. 45-64.

PALMER M. (1998). Are WordNet sense distinctions appropriate for computational lexicons.
In Association for Computational Linguistics Special Interest Group on the Lexicon (ACL-
SIGLEX-I998) .' SENSEVAL, Herstrnonceux, Sussex, UK.

PEDERSEN T. (2001a). A decision tree of bigrarns is an accurate predictor of word sense. In
Second Annual Meeting of the North American Chapter of the Association for Computational
Linguistics, p. 79 ?-86, Pittsburgh.

PEDERSEN T. (2001b). Machine learning with lexical features 2 The duluth approach to
senseval-2. In 2"” International Workshop on Evaluating Word Sense Disambiguation Sys-
tems (SENSEVAL-2), p. 139-142.

REYMOND D. (2001). Dictionnaires distributionnels et étiquetage lexical de corpus. In 5”“
Rencontre des Etudiants Chercheurs en Informatique pour le Traitement Automatique des
Langues (RECITAL-2002), volume 1, p. 479-488, Tours.

VALLI A. & VERONIS J. (1999). Etiquetage grammatical de corpus oraux 2 Problemes et
perpectives. In Revue Francaise de Linguistique Applique’e, volume IV, p. 113-133. Champs-
sur-Mame 2 Association pour le traitement informatique des langues (ASSTRIL).

VERONIS J. (1998). A study of polysemy judgements and inter-annotator agreement. In
Programme and Advanced Papers of the Senseval Workshop, Herstrnonceux Castle, England.

VERONIS J. (2001). Sense tagging 2 Does it makes sense. In Corpus Linguistics, Lancaster,
U.K.

YAROWSKY D. (1994). A comparision of corpus-based techniques for restoring accents in
spanish and french text. In 2'” Annual Workshop on Very Large Text Corpora, p. 19-32, Las
Cruces.

22

