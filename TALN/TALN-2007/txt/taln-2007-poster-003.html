<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Segmentation en super-chunks</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2007, Toulouse, 5&#8211;8 juin 2007
</p>
<p>Segmentation en super-chunks
</p>
<p>Olivier BLANC, Matthieu CONSTANT, Patrick WATRIN
IGM, Universit&#233; de Marne-la-Vall&#233;e &amp; CNRS
</p>
<p>{oblanc,mconstan,watrin}@univ-mlv.fr
</p>
<p>R&#233;sum&#233;. Depuis l&#8217;analyseur d&#233;velopp&#233; par Harris &#224; la fin des ann&#233;es 50, les unit&#233;s poly-
lexicales ont peu &#224; peu &#233;t&#233; int&#233;gr&#233;es aux analyseurs syntaxiques. Cependant, pour la plupart,
elles sont encore restreintes aux mots compos&#233;s qui sont plus stables et moins nombreux. Tou-
tefois, la langue est remplie d&#8217;expressions semi-fig&#233;es qui forment &#233;galement des unit&#233;s s&#233;man-
tiques : les expressions adverbiales et les collocations. De m&#234;me que pour les mots compos&#233;s
traditionnels, l&#8217;identification de ces structures limite la complexit&#233; combinatoire induite par
l&#8217;ambigu&#239;t&#233; lexicale. Dans cet article, nous d&#233;taillons une exp&#233;rience qui int&#232;gre ces notions
dans un processus de segmentation en super-chunks, pr&#233;alable &#224; l&#8217;analyse syntaxique. Nous
montrons que notre chunker, d&#233;velopp&#233; pour le fran&#231;ais, atteint une pr&#233;cision et un rappel de
92,9 % et 98,7 %, respectivement. Par ailleurs, les unit&#233;s polylexicales r&#233;alisent 36,6 % des
attachements internes aux constituants nominaux et pr&#233;positionnels.
</p>
<p>Abstract. Since Harris&#8217; parser in the late 50&#8217;s, multiword units have been progressively
integrated in parsers. Nevertheless, in the most part, they are still restricted to compound words,
that are more stable and less numerous. Actually, language is full of semi-frozen expressions
that also form basic semantic units : semi-frozen adverbial expressions (e.g. time), collocations.
Like compounds, the identification of these structures limits the combinatorial complexity in-
duced by lexical ambiguity. In this paper, we detail an experiment that largely integrates these
notions in a procedure of segmentation into super-chunks, preliminary to a parser. We show
that the chunker, developped for French, reaches 92.9% precision and 98.7% recall. Moreover,
multiword units realize 36.6% of the attachments within nominal and prepositional phrases.
</p>
<p>Mots-cl&#233;s : chunker, super-chunks, analyse syntaxique, patrons lexico-syntaxiques.
Keywords: chunker, super-chunks, syntactic analysis, lexico-syntactic patterns.
</p>
<p>1 Introduction
</p>
<p>Depuis l&#8217;analyseur syntaxique &#233;labor&#233; par l&#8217;&#233;quipe d&#8217;Harris &#224; la fin des ann&#233;es 50 (Joshi &amp; Ho-
pely, 1997), les unit&#233;s polylexicales ont progressivement &#233;t&#233; int&#233;gr&#233;es au processus d&#8217;analyse
(Nivre &amp; Nilsson, 2004). Cependant, dans la plupart des cas, elles sont restreintes aux mots com-
pos&#233;s, plus stables et moins nombreux. La langue regorge pourtant d&#8217;expressions moins fig&#233;es
qui peuvent &#233;galement &#234;tre consid&#233;r&#233;es comme des unit&#233;s s&#233;mantiques de base : les expressions
adverbiales semi-fig&#233;es et les collocations. De m&#234;me que pour les compos&#233;s, l&#8217;identification de
ces structures facilite l&#8217;analyse syntaxique en limitant consid&#233;rablement la combinatoire induite
par l&#8217;ambigu&#239;t&#233; lexicale.
</p>
<p>33</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier BLANC, Matthieu CONSTANT, Patrick WATRIN
</p>
<p>Pour &#233;tudier ce ph&#233;nom&#232;ne, nous avons impl&#233;ment&#233; un chunker1 reposant sur la notion de
super-chunk. Ces structures diff&#232;rent de la notion commun&#233;ment associ&#233;e aux chunks (Abney,
1996; Karlsson et al., 1995; Federici et al., 1996; Ait-Mokhtar &amp; Chanod, 1997) en ce qu&#8217;elles
peuvent int&#233;grer des attachements adjectivaux et/ou pr&#233;positionnels. Le super-chunk est donc
une unit&#233; non r&#233;cursive qui s&#8217;arr&#234;te &#224; un &#233;l&#233;ment lexical des classes N , V , A, Adv, ou &#224; un
&#233;l&#233;ment complexe (MWU) appartenant &#224; ces m&#234;mes classes. Ainsi, par exemple, les s&#233;quences
chiffres d&#8217;affaires brut et marge d&#8217;exploitation, &#233;tiquet&#233;es N (nom) lors de l&#8217;analyse lexicale,
seront tra&#238;t&#233;es comme des mots simples durant la phase de segmentation2. Dans ce cas, la r&#233;-
duction de l&#8217;ambigu&#239;t&#233; est &#233;vidente. Appr&#233;hend&#233;e de mani&#232;re compositionnelle, la s&#233;quence
chiffres d&#8217;affaires brut conduit &#224; 24 analyses que nous lin&#233;arisons compl&#232;tement si l&#8217;on envi-
sage la collocation dans son ensemble. Par ailleurs, cette seule entr&#233;e lexicale nous permet de
r&#233;soudre un double attachement (pr&#233;positionnel et adjectival), facilitant ainsi l&#8217;indentification
des constituants.
</p>
<p>Notre chunker s&#8217;inscrit dans un projet plus large visant l&#8217;analyse syntaxique du fran&#231;ais. Telle
que nous la concevons, cette analyse op&#232;re en trois phases de rafinement successifs : (1) la
segmentation lexicale du texte en unit&#233;s simples et complexes ; (2) la reconnaissance et l&#8217;&#233;ti-
quetage des super-chunks ; (3) l&#8217;attachement en constituants. Une illustration de cette proc&#233;dure
incr&#233;mentale est donn&#233;e au sein du tableau 1. Dans cet expos&#233;, nous ne d&#233;taillerons pas plus
en profondeur les caract&#233;ristiques de l&#8217;analyseur et limiterons notre propos &#224; la segmentation
en super-chunks. Nous nous concentrerons tout d&#8217;abord sur le module de segmentation lexicale
en pr&#233;sentant les ressources utilis&#233;es. Nous montrerons comment une partie d&#8217;entre elles a &#233;t&#233;
apprise automatiquement et comment nous les appliquons aux textes. Nous d&#233;crirons ensuite le
module de segmentation en super-chunks inspir&#233; par (Abney, 1996), et d&#233;taillerons la proc&#233;dure
de d&#233;sambigu&#239;sation. Enfin, nous &#233;valuerons les performances de notre chunker et montrerons
son int&#233;r&#234;t pour la r&#233;solution d&#8217;attachements lexicaux.
</p>
<p>NIVEAU EXEMPLE
</p>
<p>Text Le groupe de t&#233;l&#233;communications n&#233;erlandais KPN a annonc&#233;e avoir acquis une partici-
pation de 77,5 % dans le troisi&#232;me op&#233;rateur allemand de t&#233;l&#233;phonie mobile E-Plus.
</p>
<p>Lexique Le [N groupe de t&#233;l&#233;communications ] n&#233;erlandais KPN a annonc&#233; avoir acquis une par-
ticipation de 77,5 % dans le troisi&#232;me [N op&#233;rateur allemand de t&#233;l&#233;phonie mobile ]
E-Plus.
</p>
<p>Super-Chunk
Le [N groupe de t&#233;l&#233;communications ] [XA n&#233;erlandais ] KPN a annonc&#233; [XV I avoir
acquis ] une participation de 77,5 % dans le [XA troisi&#232;me ] [N op&#233;rateur allemand de
t&#233;l&#233;phonie mobile ] E-Plus.
[XN Le groupe de t&#233;l&#233;communications ] [XA n&#233;erlandais ] [XN KPN ] a annonc&#233;
[XV I avoir acquis ] [XN une participation ] de [XN 77,5 % ] dans [XN le troisi&#232;me
op&#233;rateur allemand de t&#233;l&#233;phonie mobile E-Plus ].
[XN Le groupe de t&#233;l&#233;communications ] [XA n&#233;erlandais ] [XN KPN ] [XV a annonc&#233;
avoir acquis ] [XN une participation ] [XP de 77,5 % ] [XP dans le troisi&#232;me op&#233;rateur
allemand de t&#233;l&#233;phonie mobile E-Plus ].
</p>
<p>Syntagme [N0 Le groupe de t&#233;l&#233;communications n&#233;erlandais KPN ] [V a annonc&#233; avoir acquis ]
[N1 une participation de 77,5 % dans le troisi&#232;me op&#233;rateur allemand de t&#233;l&#233;phonie mo-
bile E-Plus ].
</p>
<p>TAB. 1 &#8211; Processus global
</p>
<p>1Les d&#233;veloppements informatiques pr&#233;sent&#233;s dans ce travail reposent, en grande partie, sur la plate-forme
logicielle Outilex (Blanc &amp; Constant, 2006), d&#233;velopp&#233;e &#224; l&#8217;Universit&#233; de Marne-la-Vall&#233;e (IGM).
</p>
<p>2Notons que les informations morpho-syntaxiques sont h&#233;rit&#233;es de la t&#234;te lexicale de l&#8217;unit&#233; complexe (i.e.
marge et chiffre). De plus, nous associons &#224; ces informations la structure interne de l&#8217;unit&#233; complexe (i.e. nom-
pr&#233;position-nom-adjectif et nom-pr&#233;position-nom) afin de permettre une &#233;ventuelle d&#233;compression du tout (dans
le but d&#8217;un &#233;tiquetage, par exemple).
</p>
<p>34</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmentation en super-chunks
</p>
<p>2 Segmentation lexicale
</p>
<p>Le processus de segmentation lexicale constitue la part fondamentale de notre chunker. Nous
d&#233;taillons, dans cette section, les ressources utilis&#233;es de m&#234;me que leur mode d&#8217;application.
</p>
<p>Les ressources lexicales responsables de la segmentation se pr&#233;sentent sous deux formes : un
ensemble de dictionnaires morpho-syntaxiques et une biblioth&#232;que de grammaires locales. Ces
ressources sont soit d&#233;velopp&#233;es manuellement soit acquises automatiquement &#224; partir de textes
bruts.
</p>
<p>2.1 Ressources lexicales construites manuellement
</p>
<p>Les ressources lexicales d&#233;velopp&#233;es manuellement s&#8217;organisent en un dictionnaire de formes
fl&#233;chies (Courtois, 1990; Courtois et al., 1997) et un r&#233;seau de 190 graphes ou grammaires
locales3.
</p>
<p>Le dictionnaire compte 746 198 formes simples et 249 929 formes complexes (dont 245 436
noms4). Chaque entr&#233;e lexicale s&#8217;organise autour d&#8217;une forme fl&#233;chie, d&#8217;un lemme, d&#8217;une partie
du discours, d&#8217;informations morphologiques (e.g. genre et nombre), d&#8217;informations syntaxiques
(e.g. la structure interne des mots compos&#233;s) et d&#8217;informations s&#233;mantiques (e.g. trait humain).
La biblioth&#232;que de grammaires locales lexicalis&#233;es d&#233;crit un ensemble d&#8217;unit&#233;s polylexicales5.
Un exemple de grammaire locale est donn&#233;e &#224; la figure 1. Cette grammaire d&#233;crit des adverbes
de date et reconna&#238;t des s&#233;quences comme en mars 2007 et cinq minutes plus tard. Les cha&#238;nes
entre &lt; et &gt; d&#233;finissent des masques lexicaux6 (i.e. les symboles terminaux). &lt;minute&gt;, par
exemple, d&#233;signe les formes fl&#233;chies dont le lemme est minute (i.e. minute et minutes). Les
sommets gris&#233;s sont, quant &#224; eux, des r&#233;f&#233;rences &#224; d&#8217;autres graphes (i.e. les symboles non ter-
minaux).
Notons que le graphe de la figure 1 d&#233;finit un transducteur dont la sortie permet le balisage
des s&#233;quences reconnues. Chaque adverbe de temps d&#233;crit par cette grammaire sera d&#232;s lors
augment&#233; de l&#8217;&#233;tiquette ADV+time.
</p>
<p>2.2 Collocations nominales et apprentissage
</p>
<p>Outre les ressources lexicales d&#233;velopp&#233;es manuellement, notre analyseur lexical int&#232;gre un en-
semble de collocations nominales (i.e. des s&#233;quences de mots qui cooccurrent plus souvent qu&#8217;&#224;
la normale) apprises automatiquement. De cette mani&#232;re, nous souhaitons favoriser la modula-
rit&#233; de notre approche afin de la rendre viable dans un contexte applicatif r&#233;el tel que l&#8217;extraction
d&#8217;information.
</p>
<p>3Les grammaires locales sont des r&#233;seaux de transitions r&#233;cursifs repr&#233;sent&#233;s sous la forme de graphes re-
connaissant des langages alg&#233;briques (Gross, 1997; Woods, 1970). Elles permettent une repr&#233;sentation ais&#233;e des
contraintes lexico-syntaxiques dans un contexte local.
</p>
<p>4En marge des noms (e.g. pomme de terre, faux t&#233;moignage), il contient un ensemble de pr&#233;positions (e.g. au
milieu de, &#224; cause de), d&#8217;adverbes (e.g. par ailleurs, en pratique) et de conjonctions (e.g. bien que, pendant que)
</p>
<p>5Des noms (e.g. ministre anglais de l&#8217;Agriculture), des pr&#233;positions (e.g. &#224; dix kilom&#232;tres au nord de), des
d&#233;terminants num&#233;riques (e.g. vingt-sept) et nominaux (e.g. dix grammes de) et des adverbes (e.g. en octobre
2006)
</p>
<p>6Un masque lexical est une entr&#233;e lexicale sous-sp&#233;cifi&#233;e &#233;quivalente &#224; une structure de traits.
</p>
<p>35</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier BLANC, Matthieu CONSTANT, Patrick WATRIN
</p>
<p>FIG. 1 &#8211; Une grammaire locale d&#8217;adverbes de date
</p>
<p>Pour extraire les collocations, nous avons appliqu&#233; la m&#233;thode d&#233;velopp&#233;e dans (Watrin, 2006) &#224;
un corpus de d&#233;p&#234;ches journalistiques d&#8217;un million de mots. Cette m&#233;thode, inspir&#233;e par (Daille,
1995), op&#232;re en trois &#233;tapes. Dans un premier temps, le corpus d&#8217;apprentissage est &#233;tiquet&#233;,
afin d&#8217;&#233;vacuer toute ambigu&#239;t&#233; (principale source de bruit en extraction) et lemmatis&#233;, pour
permettre la g&#233;n&#233;ralisation des r&#233;sultats. Ensuite, un ensemble de patrons syntaxiques, forma-
lisant les structures de collocations, est appliqu&#233; au texte afin d&#8217;extraire les candidats termes.
Finalement, les s&#233;quences identifi&#233;es sont &#233;valu&#233;es statistiquement &#224; l&#8217;aide du log-likelihood :
(Dunning, 1993), pour les bigrammes et (Seretan et al., 2003), pour les trigrammes.
</p>
<p>FIG. 2 &#8211; Collocation : augmentation de capital
</p>
<p>Le processus d&#8217;extraction associe &#224; chaque collocation sa structure interne. Cette structure nous
permet de g&#233;n&#233;rer automatiquement les grammaires locales qui seront utilis&#233;es par le module
de segmentation lexicale. Notons que ces grammaires locales prennent en compte d&#8217;&#233;ventuels
modifieurs. Ainsi, par exemple, la grammaire associ&#233;e &#224; la collocation augmentation de capital
(cf. FIG. 2) reconna&#238;tra la s&#233;quence augmentations exceptionnelles de capital.
L&#8217;extraction men&#233;e dans le cadre de cette exp&#233;rience nous a permis d&#8217;isoler 1 953 formes ca-
noniques (1 330 bigrammes et 163 trigrammes). Le nombre de collocations extraites pourrait
para&#238;tre l&#233;ger mais se justifie pleinement. Nous souhaitons automatiser au maximum le proces-
sus d&#8217;apprentissage tout en minimisant autant que possible le taux d&#8217;erreur. Par cons&#233;quent,
nous utilisons des contraintes statistiques tr&#232;s fortes qui, si elles r&#233;duisent consid&#233;rablement le
nombre de collocation, assure la pertinence des r&#233;sultats.
</p>
<p>D&#8217;un point de vue pratique, nous avons observ&#233; que 69,1 % des bigrammes et 86,5 % des
trigrammes extraits pr&#233;sentent une structure en pr&#233;position-nom. Ce constat appuie, selon nous,
notre hypoth&#232;se d&#8217;un attachement au niveau lexical et justifie le rep&#233;rage et l&#8217;&#233;tiquetage des
collocations.
</p>
<p>2.3 Application des ressources lexicales
</p>
<p>Le module de segmentation lexicale se divise en deux &#233;tapes : (1) consultation du dictionnaire et
(2) application des grammaires locales lexicalis&#233;es. Le programme de consultation du diction-
</p>
<p>36</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmentation en super-chunks
</p>
<p>naire permet d&#8217;associer &#224; chaque token toutes les &#233;tiquettes linguistiques potentielles et permet
&#233;galement de reconna&#238;tre et &#233;tiqueter les mots compos&#233;s. La sortie de ce processus est un auto-
mate acyclique dans lequel chaque transition correspond &#224; une entr&#233;e lexicale. De cette mani&#232;re,
nous pouvons conserver la totalit&#233; de l&#8217;ambigu&#239;t&#233;. Les grammaires locales sont ensuite appli-
qu&#233;es &#224; cet automate, qui est alors augment&#233; des &#233;tiquettes associ&#233;es aux unit&#233;s polylexicales
identifi&#233;es.
</p>
<p>Bien que nous cherchions &#224; conserver l&#8217;ambigu&#239;t&#233; le plus loin possible dans notre cha&#238;ne de
traitement, notre analyseur permet d&#8217;&#233;viter certaines ambigu&#239;t&#233;s artificielles en supprimant les
analyses tr&#232;s rares du dictionnaire. Ainsi, par exemple, les analyses de a et par comme nom
sont enlev&#233;es. Pour &#233;viter le silence que peut provoquer la suppression de ces analyses, nous
recourrons &#224; un jeu des grammaires locales sp&#233;cialis&#233;es formalisant de mani&#232;re tr&#232;s pr&#233;cises
leurs contextes d&#8217;apparition. D&#232;s lors, la forme par sera toujours &#233;tiquet&#233;e pr&#233;position, sauf
dans le cas o&#249; elle se trouve dans un contexte lexical particulier tel que 16 au-dessous du par
ou faire le par. Dans ce cas, elle sera &#233;galement analys&#233;e comme nom.
</p>
<p>3 Segmentation en super-chunks
</p>
<p>La segmentation en super-chunks est &#233;galement incr&#233;mentale. Elle consiste en une cascade de
transducteurs appliqu&#233;s &#224; l&#8217;automate du texte. L&#8217;automate est ainsi augment&#233; &#224; chaque &#233;tape
des super-chunks identifi&#233;s. La cascade comporte huit &#233;tapes et utilise un r&#233;seau de 18 graphes
reconnaissant successivement :
</p>
<p>&#8211; les chunks adverbiaux (XADV) : les suites d&#8217;adverbes simples et les expressions adverbiales
reconnues durant l&#8217;analyse lexicale ;
</p>
<p>&#8211; les chunks adjectivaux (XA) : les suites d&#8217;adjectifs simples pouvant &#234;tre pr&#233;c&#233;d&#233;es par un
adverbe ;
</p>
<p>&#8211; les chunks nominaux (XN) : les groupes nominaux simples, les entit&#233;s nomm&#233;es et certains
types de pronoms ;
</p>
<p>&#8211; les chunks pr&#233;positionnels (XP) : les XN pr&#233;c&#233;d&#233;s d&#8217;une pr&#233;position ;
&#8211; les chunks verbaux (cascade de 4 FSTs) : les voix actives et passives des infinitifs, participes
</p>
<p>pass&#233;s, g&#233;rondifs et verbes conjugu&#233;s (not&#233;s respectivement XVI &#8211; XVIP ; XVK &#8211; XVKP ;
XVG &#8211; XVGP ; XV &#8211; XVP) ;
</p>
<p>Les super-chunks h&#233;ritent des propri&#233;t&#233;s morpho-syntaxiques de leur t&#234;te comme le montre
la figure 3 qui repr&#233;sente un XP. XP h&#233;rite du lemme, du genre, du nombre et de la sous-
cat&#233;gorisation de sa t&#234;te (&#710;lemma, &#710;gender, &#710;number et &#710;subcat). Par ailleurs, nous
conservons l&#8217;information li&#233;e &#224; la pr&#233;position (prep=$$.lemma).
A la suite du processus de segmentation, l&#8217;automate du texte est nettoy&#233;. La proc&#233;dure de net-
toyage consiste, d&#8217;une part, &#224; supprimer les transitions dont les &#233;tiquettes n&#8217;appartiennent pas
au niveau des super-chunks7 (e.g. noms, verbes, adjectifs, ...) et, d&#8217;autre part, &#224; conserver uni-
quement les chemins qui partent de l&#8217;&#233;tat initial (d&#233;but de phrase) et arrivent &#224; l&#8217;&#233;tat final (fin
de phrase).
La proc&#233;dure de segmentation en super-chunks appliqu&#233;e &#224; la s&#233;quence au sujet d&#8217;un attentat
terroriste produit l&#8217;automate du texte donn&#233; &#224; la figure 4.
</p>
<p>7Notons toutefois que certaines entr&#233;es lexicales ne sont int&#233;gr&#233;es &#224; aucun chunk (i.e. les conjonctions et les
pronoms relatifs). Ces entr&#233;es sont conserv&#233;es au m&#234;me titre que les super-chunks.
</p>
<p>37</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier BLANC, Matthieu CONSTANT, Patrick WATRIN
</p>
<p>FIG. 3 &#8211; Chunk pr&#233;positionnel
</p>
<p>FIG. 4 &#8211; Automate du texte apr&#232;s segmentation
</p>
<p>4 Lev&#233;e d&#8217;ambigu&#239;te incr&#233;mentale
</p>
<p>La proc&#233;dure de segmentation en super-chunks produit un ensemble d&#8217;analyses. Afin de r&#233;duire
ou m&#234;me de supprimer l&#8217;ambigu&#239;t&#233;, le chunker inclut un module de lev&#233;e d&#8217;ambigu&#239;t&#233; compos&#233;e
de trois phases optionnelles : l&#8217;heuristique du plus court chemin, un jeu de r&#232;gles et un module
de d&#233;cision statistique.
</p>
<p>4.1 Application de l&#8217;heuristique du plus court chemin (SPH)
L&#8217;heuristique du plus court chemin consiste &#224; ne garder, dans l&#8217;automate du texte, que les che-
mins les plus courts. Cette heuristique, ind&#233;pendante de la langue, peut para&#238;tre simple et na&#239;ve
au premier abord. Mais, en pratique, elle est tr&#232;s efficace. Elle privil&#233;gie en effet les analyses
int&#233;grant une ou plusieurs unit&#233;s polylexicales au d&#233;triment des analyses compositionnelles.
L&#8217;algorithme SPH est une adaptation de l&#8217;algorithme de Dijkstra (Dijkstra, 1959) qui garde
l&#8217;ensemble des plus courts chemins d&#8217;un graphe au lieu d&#8217;un seul.
</p>
<p>L&#8217;application de cette heuristique sur l&#8217;automate de la figure 4 du texte produit un automate
totalement lin&#233;aris&#233; : &lt;au sujet d&#8217;un attentat terroriste.XP&gt;.
</p>
<p>4.2 Application de r&#232;gles &#233;crites manuellement
</p>
<p>La plupart des ambigu&#239;t&#233;s lexicales peuvent se r&#233;soudre efficacement en consid&#233;rant leur
contexte d&#8217;apparition. Dans cette perspective, nous avons d&#233;velopp&#233; un formalisme simple :
les r&#232;gles Lub&#233;ron. Une r&#232;gle se compose de trois &#233;l&#233;ments : deux contextes (gauche et droit),
&#233;ventuellement vides (EMPTY), repr&#233;sent&#233;s sous la forme de grammaires locales et une partie
centrale listant une suite d&#8217;analyses ambigu&#235;s. Chaque r&#232;gle d&#233;crit donc une ambigu&#239;t&#233; poten-
tielle8. Si cette derni&#232;re s&#8217;observe au sein de l&#8217;automate du texte, nous conservons uniquement
la premi&#232;re analyse de la liste des &#233;l&#233;ments ambigus. Les autres analyses sont alors supprim&#233;es
de l&#8217;automate.
</p>
<p>XN.wrtn
</p>
<p>8Le chunker contient actuellement 26 r&#232;gles de ce type.
</p>
<p>38</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmentation en super-chunks
</p>
<p>&lt;XP&gt; &lt;XN&gt;
EMPTY
</p>
<p>La r&#232;gle propos&#233;e ci-dessus exprime la contrainte suivante : dans le cas d&#8217;une ambigu&#239;t&#233; XN
&#8211; XP, l&#8217;analyse XP sera pr&#233;f&#233;r&#233;e si le contexte gauche (d&#233;fini au sein du graphe XN.wrtn)
pr&#233;sente un XN. Appliqu&#233;e &#224; l&#8217;automate de la figure 5, cette r&#232;gle nous permet de supprimer
l&#8217;analyse XN pour la s&#233;quence de lutte contre le terrorisme.
</p>
<p>FIG. 5 &#8211; Ambigu&#239;t&#233; des analyses en super-chunks
</p>
<p>4.3 Application de r&#232;gles statistiques simples
</p>
<p>Certaines ambigu&#239;t&#233;s ne peuvent &#234;tre r&#233;solues efficacement par &#233;tude des contextes directs
gauche ou droit. Un exemple prototypique est l&#8217;ambigu&#239;t&#233; XV &#8211; XN (e.g. le mot avions, V (avoir)
ou N (avion)). Dans ce cas, nous utilisons des r&#232;gles de priorit&#233;s statistiques apprises automa-
tiquement au d&#233;part d&#8217;un corpus9. &#201;tant donn&#233; un mot ambigu, l&#8217;analyse hors contexte la plus
fr&#233;quente est choisie. Pour la forme avions, par exemple, nous retiendrons l&#8217;analyse N (probabi-
lit&#233; de 0, 6) et supprimerons l&#8217;analyse V (probabilit&#233; de 0, 4). Si une forme ambigu&#235; est absente
de notre liste de d&#233;cision, nous retenons, en dernier recours, la cat&#233;gorie de (super-)chunk la
plus fr&#233;quente.
</p>
<p>Notons que toutes les phases de lev&#233;e d&#8217;ambigu&#239;t&#233; sont optionnelles. En effet, dans l&#8217;optique
d&#8217;une analyse syntaxique, il peut &#234;tre pr&#233;f&#233;rable de conserver une partie de cette ambigu&#239;t&#233;, sa
r&#233;solution pouvant entra&#238;ner des erreurs. L&#8217;ambigu&#239;t&#233; XV &#8211; XN constitue, selon nous, une situa-
tion caract&#233;ristique qu&#8217;il est pr&#233;f&#233;rable de r&#233;soudre au niveau de l&#8217;attachement syntagmatique
surtout si celui-ci est bas&#233; sur des r&#232;gles lexicales.
</p>
<p>5 &#201;valuation et discussion
La notion de super-chunk compatible avec notre d&#233;finition n&#8217;existant dans aucun corpus annot&#233;
de r&#233;f&#233;rence, l&#8217;&#233;valuation a d&#251; &#234;tre r&#233;alis&#233;e manuellement.
</p>
<p>Notre proc&#233;dure d&#8217;&#233;valuation a port&#233; sur un corpus compos&#233; de d&#233;p&#234;ches journalistiques ex-
traites du site yahoo.fr. Ce corpus de 13 493 mots (i.e. 6 901 chunks), auxquels nous avons
appliqu&#233; notre chunker &#224; l&#8217;aide des donn&#233;es lexicales d&#233;crites dans les sections pr&#233;c&#233;dentes. La
sortie est un texte annot&#233; ne contenant plus aucune ambigu&#239;t&#233;. Les r&#233;sultats de l&#8217;&#233;valuation sont
donn&#233;s dans la table 2.
</p>
<p>De mani&#232;re g&#233;n&#233;rale, nous avons observ&#233; que la plupart des erreurs sont dues &#224; l&#8217;incompl&#233;tude
de nos ressources lexico-syntaxiques. Ceci implique que de nombreuses am&#233;liorations peuvent
&#234;tre apport&#233;es facilement et le seront tr&#232;s prochainement. Dans cette &#233;valuation, nous distin-
guons les erreurs de pr&#233;cision et de rappel.
</p>
<p>9Notre corpus comprend un an d&#8217;articles du journal Le Monde et a &#233;t&#233; &#233;tiquet&#233; avec TreeTagger (Schmid,
1994).
</p>
<p>39</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier BLANC, Matthieu CONSTANT, Patrick WATRIN
</p>
<p>PR&#201;CISION RAPPEL F MESURE
92,91 % 98,69 % 95.71%
</p>
<p>TAB. 2 &#8211; R&#233;sultats
</p>
<p>Les erreurs de rappel sont uniquement dues &#224; la couverture de notre dictionnaire et de nos gram-
maires locales lexicalis&#233;es. D&#8217;un point de vue lexical, certains mots grammaticaux compos&#233;s
sont absents du dictionnaire (e.g. tandis que, au-dessous de). D&#8217;un point de vue plus gramma-
ticale, les erreurs sont principalement imputables &#224; la formalisation des entit&#233;s nomm&#233;es. La
s&#233;quence Nouri al Maliki, par exemple, n&#8217;a pu &#234;tre reconnue : la forme al est inconnue et n&#8217;a
pas &#233;t&#233; int&#233;gr&#233; dans la grammaire comme un pr&#233;fixe de nom de famille. Par ailleurs, quelques
expressions semi-fig&#233;es ont &#233;t&#233; oubli&#233;es (e.g. vers 8h45) de m&#234;me que certaines structures pro-
nominales complexes (e.g. au cours de laquelle).
Les erreurs de pr&#233;cision peuvent &#234;tre divis&#233;es en quatre classes.
</p>
<p>1. Erreurs li&#233;es &#224; SPH
</p>
<p>L&#8217;ambigu&#239;t&#233; lexicale peut conduire a une mauvaise limitation des chunks apr&#232;s application de
l&#8217;heuristique des plus courts chemins. Par exemple, dans la s&#233;quence apr&#232;s l&#8217;affirmation du
quotidien espagnol El Pais, il existe deux analyses possibles :
</p>
<p>&#8211; [apr&#232;s l&#8217;affirmation XP] [du quotidien espagnol XP] [El Pais XN] ;
&#8211; [apr&#232;s l&#8217;affirmation XP] [du quotidien XP] [espagnol XA] [El Pais XN].
Comme quotidien et espagnol peuvent &#234;tre tous deux soit adjectif soit nom, l&#8217;algorithme SPH
va pr&#233;f&#233;rer l&#8217;analyse [Prep XA N] au lieu de [Prep N] [XA].
</p>
<p>2. Erreurs dues aux r&#232;gles statistiques
</p>
<p>Dans la s&#233;quence La c&#244;te Est et les villes de New York ..., deux analyses sont attribu&#233;es au
chunk Est : il s&#8217;agit soit d&#8217;un XV (&#234;tre), soit d&#8217;un XA (direction est). Bien qu&#8217;Est soit XA dans
ce contexte, le module statistique va pr&#233;f&#233;rer l&#8217;analyse XV (probabilit&#233; de 0, 9 contre 0, 1 pour
l&#8217;analyse XA).
</p>
<p>3. Erreurs caus&#233;es par l&#8217;application des r&#232;gles Luberon
</p>
<p>Ces erreurs sont heureusement tr&#232;s rares. Elles concernent principalement l&#8217;ambigu&#239;t&#233; XP&#8211;XN
due &#224; la forme de qui peut &#234;tre d&#233;terminant et pr&#233;position. Dans la s&#233;quence qui n&#8217;a pas fourni
de plus amples d&#233;tails, par exemple, le chunk de plus amples d&#233;tails aurait d&#251; &#234;tre &#233;tiquet&#233; XN.
</p>
<p>4. Erreurs imputables &#224; la couverture lexicale
</p>
<p>Quelques structures compos&#233;es absentes dans le dictionnaire provoque des erreurs. Par exemple,
en outre est un adverbe compos&#233; mais est absent de notre dictionnaire. Ainsi, l&#8217;analyse compo-
sitionnelle est choisie dans la phrase ils ont en outre pris plusieurs centaines de personnes en
otage. Elle est segment&#233;e en super-chunks de la mani&#232;re suivante :
</p>
<p>&#8211; [ils XN] [ont XV] [en outre pris plusieurs centaines XP] [de personnes XP] [en otage XP]
au lieu de,
</p>
<p>40</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmentation en super-chunks
</p>
<p>&#8211; [ils XN] [ont en outre pris XV] [plusieurs centaines XN] [de personnes XP] [en otage XP]
</p>
<p>o&#249; en outre est un adverbe ins&#233;r&#233; dans un chunk verbal.
</p>
<p>En plus de l&#8217;&#233;valuation en rappel et pr&#233;cision, nous avons aussi estim&#233; l&#8217;impact des unit&#233;s po-
lylexicales pour l&#8217;attachement lexical. Notre proc&#233;dure permet la r&#233;alisation correcte de 36,6 %
des attachements lexicaux int&#233;rieurs aux groupes nominaux et pr&#233;positionnels, soit environ
13 % des attachements internes et externes aux syntagmes.
</p>
<p>Malgr&#233; ces quelques erreurs, notre &#233;valuation montre, selon nous, l&#8217;int&#233;r&#234;t d&#8217;une segmentation
en super-chunks, tant du point de vue de l&#8217;attachement que du point de vue de la r&#233;duction
globale de l&#8217;ambigu&#239;t&#233;.
</p>
<p>6 Conclusion et perspectives
</p>
<p>Dans cette article, nous avons pr&#233;sent&#233; une technique de chunking reposant sur une augmenta-
tion significative du niveau lexical. En introduisant la notion de super-chunks, nous cherchions,
d&#8217;une part, &#224; optimiser le processus de d&#233;sambigu&#239;sation et, d&#8217;autre part, &#224; r&#233;soudre une part de
l&#8217;attachement lexical au sein des constituants pr&#233;positionnels et nominaux.
</p>
<p>Afin d&#8217;&#233;valuer la pertinence et l&#8217;efficacit&#233; de notre hypoth&#232;se, nous avons confront&#233; notre chun-
ker &#224; un corpus de d&#233;p&#234;ches journalistiques. Cette exp&#233;rience nous a permis de d&#233;gager une
double conclusion.
</p>
<p>&#8211; Notre proc&#233;dure affiche une pr&#233;cision et un rappel excellents sans n&#233;cessiter le recours &#224; un
&#233;tiqueteur.
</p>
<p>&#8211; La prise en compte des unit&#233;s polylexicales nous permet d&#8217;&#233;vacuer efficacement (i.e. sans en-
tra&#238;ner d&#8217;erreurs) une part cons&#233;quente des attachements internes aux constituants nominaux
et pr&#233;positionnels.
</p>
<p>Cette exp&#233;rience nous a &#233;galement permis de pr&#233;ciser un certain nombre de perspectives orga-
nisant notre travail futur. Ces perspectives s&#8217;articulent autour de deux points principaux : (1)
l&#8217;augmentation des ressources lexicales (principal facteur de succ&#232;s de notre application) et (2)
l&#8217;am&#233;lioration du module de d&#233;sambigu&#239;sation statistique (en ce sens, l&#8217;int&#233;gration des HMM
nous semble &#234;tre une solution int&#233;ressante).
</p>
<p>R&#233;f&#233;rences
ABNEY S. P. (1996). Partial parsing via finite-state cascades. Natural Language Engineering,
2(4), 337&#8211;344.
AIT-MOKHTAR S. &amp; CHANOD J.-P. (1997). Incremental finite-state parsing. In Proceedings
of the fifth Conference on Applied Natural Language Processing ANLP&#8217;97.
BLANC O. &amp; CONSTANT M. (2006). Outilex, a linguistic platform for text processing. In
Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, p. 73&#8211;76.
COURTOIS B. (1990). Un syst&#232;me de dictionnaires &#233;lectroniques pour les mots simples du
fran&#231;ais. Langue Fran&#231;aise, 87, 11&#8211;22.
</p>
<p>41</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier BLANC, Matthieu CONSTANT, Patrick WATRIN
</p>
<p>COURTOIS B., GARRIGUES M., GROSS G., GROSS M., JUNG R., MATHIEU-COLAS M.,
MONCEAUX A., PONCET-MONTANGE A., SILBERZTEIN M. &amp; VIV&#200;S R. (1997). Diction-
naire &#233;lectronique DELAC : les mots compos&#233;s binaires. Rapport interne, LADL (Paris 7).
DAILLE B. (1995). Combined approach for terminology extraction : lexical statistics and
linguistic filtering. Rapport interne, Lancaster University.
DIJKSTRA E. W. (1959). A note on two problems in connexion with graphs. Numerische
Mathematik, 1, 269&#8211;271.
DUNNING T. (1993). Accurate methods for the statistics of surprise and coincidence. Com-
putational Linguistics, 19(1), 61&#8211;74.
FEDERICI S., MONTEMAGNI S. &amp; PIRELLI V. (1996). Shallow parsing and text chunking :
A view on underspecification in syntax. In Proceedings of the ESSLLI&#8217;96 Workshop on Robust
Parsing.
GROSS M. (1997). The construction of local grammars, p. 329&#8211;352. MIT Press : Cambridge.
JOSHI A. &amp; HOPELY P. (1997). A parser from antiquity : an early application of finite state
transducers to natural language parsing. Natural Language Engineering, 2(4), 6&#8211;15.
KARLSSON F., VOUTILAINEN A., HEIKKILA J. &amp; ANTTILA A. (1995). Constraint Gram-
mar : A language-independent system for parsing unrestricted text, volume 4 of Natural Lan-
guage Processing. Mouton de Gruyter.
NIVRE J. &amp; NILSSON J. (2004). Multiword units in syntactic parsing. In Workshop on Me-
thodologies and Evaluation of Multiword Units in Real-World Applications, p. 39&#8211;46, Lisbon.
SCHMID H. (1994). Probabilistic part-of-speech tagging using decision trees. In International
Conference on New Methods in Language Processing, Manchester, UK.
SERETAN V., NERIMA L. &amp; WEHRLI E. (2003). Extraction of multi-word collocations using
syntactic bigram composition. In Proceedings of th 4th International Conference on Recent
Advances in NLP (RANLP-2003), p. 424&#8211;431.
WATRIN P. (2006). Une approche hybride de l&#8217;extraction d&#8217;information : sous-langages et
lexique-grammaire. PhD thesis, Universit&#233; catholique de Louvain.
WOODS W. A. (1970). Transition network grammars for natural language analysis. Commu-
nications of the ACM, 13(10).
</p>
<p>42</p>

</div></div>
</body></html>