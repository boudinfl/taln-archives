TALN 2007, Toulouse, 5-8 juin 2007

Segmentation en super-chunks

Olivier BLANC, Matthieu CONSTANT, Patrick WATRIN
IGM, Université de Mame—la—Vallée & CNRS
{oblanc , mconstan , watrin} @univ—mlv . fr

Résumé. Depuis l’analyseur développé par Harris a la ﬁn des armées 50, les unités poly-
lexicales ont peu a peu été irrtégrées aux analyseurs symtaxiques. Cependant, pour la plupart,
elles sont encore restreintes aux mots composés qui sont plus stables et moins nombreux. Tou-
tefois, la langue est remplie d’expressions serrri-ﬁgées qui forment également des unités séman-
tiques 2 les expressions adverbiales et les collocations. De méme que pour les mots composés
traditionnels, l’identiﬁcation de ces structures lirrrite la complexité combinatoire induite par
l’ambigu'1‘té lexicale. Dans cet article, nous détaillons une expérience qui intégre ces notions
dans un processus de segmentation en super-chunks, préalable a l’analyse syntaxique. Nous
montrons que notre chunker, développé pour le francais, atteint une précision et un rappel de
92,9 % et 98,7 %, respectivement. Par ailleurs, les unités polylexicales réalisent 36,6 % des
attachements intemes aux constituants norrrinaux et prépositionnels.

Abstract. Since Harris’ parser in the late 50’s, multiword units have been progressively
integrated in parsers. Nevertheless, in the most part, they are still restricted to compound words,
that are more stable and less numerous. Actually, language is full of serrri-frozen expressions
that also form basic semantic units 2 serrri-frozen adverbial expressions (e. g. time), collocations.
Like compounds, the identiﬁcation of these structures lirrrits the combinatorial complexity irr-
duced by lexical ambiguity. In this paper, we detail an experiment that largely integrates these
notions in a procedure of segmentation into super-chunks, preliminary to a parser. We show
that the chunker, developped for French, reaches 92.9% precision and 98.7% recall. Moreover,
multiword units realize 36.6% of the attachments within nominal and prepositional phrases.

Mots-clés 2 chunker, super-chunks, analyse symtaxique, patrons lexico-syntaxiques.

Keywords: chunker, super-chunks, syntactic analysis, lexico-syntactic patterns.

1 Introduction

Depuis l’analyseur symtaxique élaboré par l’équipe d’Har'ris a la ﬁn des armées 50 (Joshi & Ho-
pely, 1997), les unités polylexicales ont progressivement été intégrées au processus d’analyse
(Nivre & Nilsson, 2004). Cependant, dans la plupart des cas, elles sont restreintes aux mots com-
posés, plus stables et moins nombreux. La langue regorge pourtant d’expressions moins ﬁgées
qui peuvent également étre considérées comme des unités sémantiques de base 2 les expressions
adverbiales serrri-ﬁgées et les collocations. De méme que pour les composés, l’identiﬁcation de
ces structures facilite l’analyse symtaxique en lirnitant considérablement la combinatoire induite
par l’ambigu'1‘té lexicale.

33

Olivier BLANC, Matthieu CONSTANT, Patrick WATRIN

Pour étudier ce phénomene, nous avons implémenté un chunkerl reposant sur la notion de
super-chunk. Ces structures different de la notion communément associée aux chunks (Abney,
1996; Karlsson er al., 1995; Federici et al., 1996; Ait-Mokhtar & Chanod, 1997) en ce qu’elles
peuvent intégrer des attachements adjectivaux et/ou prépositionnels. Le super-chunk est donc
une unité non recursive qui s’arréte a un élément lexical des classes N, V, A, Adv, ou a un
élément complexe (MWU) appartenant a ces memes classes. Ainsi, par exemple, les séquences
chifres d’aﬁ‘aires brut et marge d ’exploitation, étiquetées N (nom) lors de l’analyse lexicale,
seront tra’1‘tées comme des mots simples durant la phase de segmentationz. Dans ce cas, la re-
duction de l’ambigu'1‘té est évidente. Appréhendée de maniere compositionnelle, la sequence
chzﬂres d ’aﬁ‘aires brut conduit a 24 analyses que nous linéarisons completement si l’on envi-
sage la collocation dans son ensemble. Par ailleurs, cette seule entrée lexicale nous permet de
résoudre un double attachement (prépositionnel et adjectival), facilitant ainsi l’indentiﬁcation
des constituants.

Notre chunker s’insc1it dans un projet plus large Visant l’analyse syntaxique du francais. Telle
que nous la concevons, cette analyse opere en trois phases de raﬁnement successifs : (1) la
segmentation lexicale du texte en unités simples et complexes; (2) la reconnaissance et l’éti-
quetage des super-chunks ; (3) l’attachement en constituants. Une illustration de cette procédure
incrémentale est donnée au sein du tableau 1. Dans cet exposé, nous ne détaillerons pas plus
en profondeur les caractéristiques de l’analyseur et lin1iterons notre propos a la segmentation
en super-chunks. Nous nous concentrerons tout d’ abord sur le module de segmentation lexicale
en présentant les ressources utilisées. Nous montrerons comment une partie d’ entre elles a été
apprise automatiquement et comment nous les appliquons aux textes. Nous décrirons ensuite le
module de segmentation en super-chunks inspiré par (Abney, 1996), et détaillerons la procédure
de désambigu'1‘sation. Enﬁn, nous évaluerons les performances de notre chunker et montrerons
son intérét pour la résolution d’ attachements lexicaux.

| NIVEAU | EXEMPLE |

Text Le groupe de télécommunications néerlandais KPN a annoncée avoir acquis une partici-
pation de 775 %dansle ' " ,’ “ ‘ de "’ ' ' mobile E-Plus.

Lexique Le [N groupe de télécommunication ] néerlandais KPN a annoncé avoir acquis une par-
ticipation de 77,5 % dans le troisiéme [N opérateur allemand de téléphonie mobile ]
E-Plus.

Le [N gmupe de télécommunication ] [XA néerlandajs ] KPN a annoncé [XV1 avoir

Super—Chunk acquis ] une par 'cipation de 775 % dans le [XA troisiéme ] [N opérateur allemand de
"’ ' ' mobile]E-Plus.

[XN Le groupe de télécommunic ion ] [XA néerlandajs ] [XN KPN ] a annoncé

[XV1 avoir acquis] [XN une participation] de [XN 77,5 % ] dans [XN le oisiéme
,’ “ ’de  ' ' mobileE-Plus].

[XN Le groupe de telecommunications] [XA néerlandais ] [XN KPN] [xv a annoncé

avoir acquis] [XN une participation] [xp de 77,5 % ] [Xp dans le troisiéme opérateur
“ ‘ " ' ' ‘ mobile E-Plus ].

Syntagme [Nu Le groupe de télécommunicatiun néerlandais KPN ] [V a annoncé avoir acquis ]
[N1 une participation de 77,5 % dans le troisiéme opérateur allemand de téléphonie mo-
bile E-Plus ].

TAB. 1 — Processus global

1Les développements informatiques présentés dans ce travail reposent, en grande partie, sur la plate-forme
logicielle Outilex (Blanc & Constant, 2006), développée a l‘Université dc Mame-la-Vallée (IGM).

2Notons que les informations morpho-syntaxiques sont héritées de la téte lexicale de l‘unité complexe (i. e.
marge et chzﬂre). De plus, nous associons a ces informations la structure inteme de 1‘unité complexe (i.e. nom-
prépaxition-nam—adjectzf et nom-prépoxition-nom) aﬁn dc permettre une éventuelle decompression du tout (dans
le but d‘un étiquetage, par exemple).

34

Segmentation en super-chunks

2 Segmentation lexicale

Le processus de segmentation lexicale constitue la part fondamentale de notre chunker. Nous
detaillons, dans cette section, les ressources utilisees de meme que leur mode d’ application.

Les ressources lexicales responsables de la segmentation se presentent sous deux formes 2 un
ensemble de dictionnaires morpho-switaxiques et une bibliotheque de grarmnaires locales. Ces
ressources sont soit developpees manuellement soit acquises automatiquement a partir de textes
bruts.

2.1 Ressources lexicales construites manuellement

Les ressources lexicales developpees manuellement s’organisent en un dictionnaire de formes
ﬂechies (Courtois, 1990; Courtois er al., 1997) et un reseau de 190 graphes ou grarmnaires
locales3.

Le dictionnaire compte 746 198 formes simples et 249 929 formes complexes (dont 245 436
noms4). Chaque entree lexicale s’ organise autour d’une forme ﬂechie, d’un lemme, d’une partie
du discours, d’informations morphologiques (e.g. genre et nombre), d’inforn1ations syntaxiques
(e.g. la structure inteme des mots composes) et d’informations semantiques (e.g. trait humain).

La bibliotheque de grannnaires locales lexicalisees decrit un ensemble d’unites polylexicales5.
Un exemple de grannnaire locale est donnee a la ﬁgure 1. Cette grannnaire decrit des adverbes
de date et reconna’1‘t des sequences comme en mars 2007 et cinq minutes plus tard. Les chaines
entre < et > deﬁnissent des masques lexicauxé (i. e. les symboles terminaux). <minute>, par
exemple, designe les formes ﬂechies dont le lemme est minute (i.e. minute et minutes). Les
sommets grises sont, quant a eux, des references a d’autres graphes (i.e. les symboles non ter-
minaux).

Notons que le graphe de la ﬁgure 1 deﬁnit un transducteur dont la so11'.ie permet le balisage
des sequences reconnues. Chaque adverbe de temps decrit par cette grannnaire sera des lors
augmente de l’etiquette ADV+time.

2.2 Collocations nominales et apprentissage

Outre les ressources lexicales developpees manuellement, notre analyseur lexical integre un en-
semble de collocations nominales (i. e. des sequences de mots qui cooccurrent plus souvent qu’a
la normale) apprises automatiquement. De cette maniere, nous souhaitons favoriser la modula-
rite de notre approche aﬁn de la rendre Viable dans un contexte applicatif reel tel que 1’ extraction
d’inforn1ation.

3Les grannnaires locales sont des reseaux de transitions recursifs representes sous la forme de graphes re-
connaissant des langages algebriques (Gross, 1997; Woods, 1970). Elles permettent une representation aisee des
contraintes lexico-syntaxiques dans un contexte local.

4En marge des noms (e.g. pomme de terre, faux témoignage), il contient un ensemble de prepositions (e.g. au
milieu de, a cause de), d‘adverbes (e.g. par ailleurx, en pratique) et de conjonctions (e.g. bien que, pendant que)

5Des noms (e.g. minixtre anglaix de l’Agriculture), des prepositions (eg. a dix kilometres au nard de), des
determinants numeriques (e.g. vingt-xept) et nominaux (e.g. dix grammes de) et des adverbes (e.g. en octobre
2006)

6Un masque lexical est une entree lexicale sous-speciﬁee equivalente a une structure de traits.

35

Olivier BLANC, Matthieu CONSTANT, Patrick WATRIN

<rrunute>

<sec<>nde>
card

Dnum <an> plus tat
(Jaw
mois
year
an month
dermer D
procham
- 1
[ADV+tI e 3'“ ‘E E
12 WeekDay “V < >
<E>
mﬂhn
"""kDaV aprés—midi
sou’

FIG. 1 — Une grannnaire locale d’ adverbes de date

Pour extraire les collocations, nous avons appliqué la méthode développée dans (Wattin, 2006) a
un corpus de dépéches journalistiques d’un million de mots. Cette méthode, inspirée par (Daille,
1995), opere en trois étapes. Dans un premier temps, le corpus d’apprentissage est étiqueté,
aﬁn d’éVacuer toute ambigu'1‘té (principale source de bruit en extraction) et lemmatisé, pour
permettre la généralisation des résultats. Ensuite, un ensemble de patrons switaxiques, forma-
lisant les structures de collocations, est appliqué au texte aﬁn d’extraire les candidats termes.
Finalement, les séquences identiﬁées sont évaluées statistiquement a l’aide du log-likelihood 2
(Dunning, 1993), pour les bigrammes et (Seretan et al., 2003), pour les ttigrammes.
A A ’ A IT. ’

[T4 .
V V A», V V <ae..... , V <cap|lal.N> Hi)
[N+<omP+“gender+"number I

FIG. 2 — Collocation 2 augmentation de capital

Le processus d’ extraction associe a chaque collocation sa structure inteme. Cette structure nous
permet de générer automatiquement les grarmnaires locales qui seront utilisées par le module
de segmentation lexicale. Notons que ces grammaires locales prennent en compte d’ éventuels
modiﬁeurs. Ainsi, par exemple, la grannnaire associée a la collocation augmentation de capital
(cf FIG. 2) reconnaitra la séquence augmentations exceptionnelles de capital.

L’ extraction menée dans le cadre de cette expérience nous a permis d’isoler 1 953 fonnes ca-
noniques (1 330 bigrammes et 163 trigrammes). Le nombre de collocations extraites pourrait
para1"tre léger mais se justiﬁe pleinement. Nous souhaitons automatiser au maximum le proces-
sus d’ apprentissage tout en n1ir1in1isant autant que possible le taux d’ erreur. Par conséquent,
nous utilisons des contraintes statistiques tres fortes qui, si elles réduisent considérablement le
nombre de collocation, assure la pertinence des résultats.

D’un point de Vue pratique, nous avons observé que 69,1 % des bigrammes et 86,5 % des
trigrammes extraits présentent une structure en préposition-nom. Ce constat appuie, selon nous,
notre hypothese d’un attachement au r1iVeau lexical et justiﬁe le repérage et l’étiquetage des
collocations.

2.3 Application des ressources lexicales

Le module de segmentation lexicale se divise en deux étapes 2 (1) consultation du dictionnaire et
(2) application des grannnaires locales lexicalisées. Le programme de consultation du diction-

36

Segmentation en super-chunks

naire permet d’ associer a chaque token toutes les étiquettes linguistiques potentielles et permet
également de reconna1"tre et étiqueter les mots composés. La sortie de ce processus est un auto-
mate acyclique dans lequel chaque transition correspond a une entrée lexicale. De cette maniere,
nous pouvons conserver la totalité de l’ambigu'1‘té. Les grarmnaires locales sont ensuite appli-
quées a cet automate, qui est alors augmenté des étiquettes associées aux unités polylexicales
identiﬁées.

Bien que nous chercl1ions a conserver l’ambigu'1‘té le plus loin possible dans notre cha’1‘ne de
traitement, notre analyseur permet d’éviter certaines ambigu'1‘tés artiﬁcielles en supprimant les
analyses tres rares du dictionnaire. Ainsi, par exemple, les analyses de a et par comme nom
sont er1leVées. Pour éviter le silence que peut provoquer la suppression de ces analyses, nous
recourrons a un jeu des grannnaires locales spécialisées formalisant de maniere tres précises
leurs contextes d’ apparition. Des lors, la forme par sera toujours étiquetée préposition, sauf
dans le cas ou elle se trouve dans un contexte lexical particulier tel que I6 au-dessous du par
oufaire le par. Dans ce cas, elle sera également analysée comme nom.

3 Segmentation en super-chunks

La segmentation en super-chunks est également incrémentale. Elle consiste en une cascade de
transducteurs appliqués a l’ automate du texte. L’ auton1ate est ainsi augmenté a chaque étape
des super-chunks identiﬁés. La cascade comporte huit étapes et utilise un réseau de 18 graphes
reconnaissant successivement 2

— les chunks adverbiaux (XADV) 2 les suites d’ adverbes simples et les expressions adverbiales
reconnues durant l’ analyse lexicale ;

— les chunks adjectivaux (XA) 2 les suites d’adjectifs simples pouvant étre précédées par un
adverbe;

— les chunks nominaux (XN) 2 les groupes nominaux simples, les entités nommées et certains
types de pronon1s ;

— les chunks prépositionnels (XP) 2 les XN précédés d’une préposition;

— les chunks Verbaux (cascade de 4 FSTs) 2 les Voix actives et passives des inﬁnitifs, participes
passés, gérondifs et Verbes conjugués (notés respectivement XVI — XVIP; XVK — XVKP;
XVG — XVGP ; xv — XVP) ;

Les super-chunks héritent des propriétés morpho-syntaxiques de leur téte comme le montre
la ﬁgure 3 qui représente un XP. XP hérite du lemme, du genre, du nombre et de la sous-
catégorisation de sa téte ("lemma, “gender, “number et "subcat). Par ailleurs, nous
conservons l’information liée a la préposition (prep=$ $ . 1 emma).

A la suite du processus de segmentation, l’automate du texte est nettoyé. La procédure de net-
toyage consiste, d’une part, a supprimer les transitions dont les étiquettes n’appartiennent pas
au r1iVeau des super-chunks7 (e. g. r1on1s, Verbes, adjectifs, ...) et, d’ autre part, a conserver uni-
quement les chen1ins qui partent de l’état initial (début de phrase) et arrivent a l’état ﬁnal (ﬁn
de phrase).

La procédure de segmentation en super-chunks appliquée a la séquence au sujet d ’un attentat
terroriste produit l’automate du texte donné a la ﬁgure 4.

7Notons toutefois que certaines entrées lexicales ne sont intégrées A aucun chunk (i. e. les conjonctions et les
pronoms relatifs). Ces entrées sont conservées au méme titre que les super-chunks.

37

Olivier BLANC, Matthieu CONSTANT, Patrick WATRIN

   

 
 

>

+"|emmI+"§ender+"number-r - 7.

<XA> .. }

<E>
+“|lmmI+"DIndur+‘numbun-"IzlIsnn+"iuII:at

  
   
        

+nren=$s.Iemmn

FIG. 3 — Chunk prépositionnel

    
   

<au sujﬁl d‘ un atlenmt termriste,au su]elde.XP+3+n1+s> >

<au sIIjel,au.XP+3+1n+s>

<d‘ un attenIal,de,XP+3+m+s> <tenonsIe.IerronsIe.XN+3+f+s> )
(an sujcl 11' ml allentagau sujel de.XP+3+m+s> <v,ermriste,tzrmrisle xA+r+.~> [)/

FIG. 4 — Automate du texte apres segmentation

  

<d‘ un attenlat Ierroriste,de.X1>+3+m+s> }

        
 

4 Levée d’ambigu'1'te incrémentale

La procédure de segmentation en super-chunks produit un ensemble d’analyses. Aﬁn de réduire
ou meme de supprimer l’ ambigu'1‘té, le chunker inclut un module de levée d’ ambigu'1‘té composée
de trois phases optionnelles 2 l’heu1istique du plus court chemin, un jeu de regles et un module
de décision statistique.

4.1 Application de l’heuristique du plus court chemin (SPH)

L’heu1istique du plus court chemin consiste a ne garder, dans l’automate du texte, que les che-
mins les plus courts. Cette heuristique, indépendante de la langue, peut paraitre simple et na'1‘Ve
au premier abord. Mais, en pratique, elle est tres efﬁcace. Elle privilégie en effet les analyses
intégrant une ou plusieurs unités polylexicales au détriment des analyses compositionnelles.
L’algo1ithme SPH est une adaptation de l’algo1itl1me de Dijkstra (Dijkstra, 1959) qui garde
l’ensemble des plus courts chemins d’un graphe au lieu d’un seul.

L’ application de cette heuristique sur l’automate de la ﬁgure 4 du texte produit un automate
totalement linéatisé 2 <au sujet d ’un attentat terroriste.XP>.

4.2 Application de régles écrites manuellement

La plupart des ambigu'1‘tés lexicales peuvent se résoudre efﬁcacement en considérant leur
contexte d’appa1ition. Dans cette perspective, nous avons développé un formalisme simple 2
les regles Lubéron. Une regle se compose de trois elements 2 deux contextes (gauche et droit),
éventuellement vides (EMPTY), représentés sous la forme de grarmnaires locales et une partie
centrale listant une suite d’ analyses ambigues. Chaque regle décrit donc une ambigu'1‘té poten-
tielles. Si cette derniere s’observe au sein de l’ auton1ate du texte, nous conservons uniquement
la premiere analyse de la liste des éléments ambigus. Les autres analyses sont alors supprimées
de l’automate.

XN.wrtn

8Le chunker contient actuellement 26 régles de ce type.

38

Segmentation en super-chunks

<XP> <XN>
EMPTY

La regle proposée ci-dessus exprime la contrainte suivante 2 dans le cas d’une ambigu'1‘té XN
— XP, l’ar1alyse XP sera préférée si le contexte gauche (déﬁni au sein du graphe XN .wrtn)
présente un XN. Appliquée a l’automate de la ﬁgure 5, cette regle nous permet de supprimer
l’ar1alyse XN pour la séquence de lutte contre le terrorisme.

<de I-me centre 1: Ierronsme,de XP+3+f+s> >
> >
<.1:1unc conlre lc IcrmrIsme,luIlc conlrc 1e Icrmr|sme.XN+3+f+s> D

FIG. 5 — Ambigu'1‘té des analyses en super-chunks

4.3 Application de régles statistiques simples

Certaines ambigu'1‘tés ne peuvent étre résolues efﬁcacement par étude des contextes directs
gauche ou droit. Un exemple prototypique est l’ambigu'1‘té XV — XN (e. g. le mot avions, V (avoir)
ou N (avion)). Dans ce cas, nous utilisons des regles de priorités statistiques apprises automa-
tiquement au dépatt d’un corpus9. Etant donné un mot ambigu, l’ analyse hors contexte la plus
fréquente est choisie. Pour la forme avions, par exemple, nous retiendrons l’analyse N (probabi-
lité de 0, 6) et supprimerons l’analyse V (probabilité de 0, 4). Si une forme ambigue est absente
de notre liste de décision, nous retenons, en demier recours, la catégorie de (super-)chunk la
plus fréquente.

Notons que toutes les phases de levée d’ambigu'1‘té sont optionnelles. En effet, dans l’optique
d’une analyse syntaxique, il peut étre préférable de conserver une partie de cette ambigu'1‘té, sa
résolution pouvant entrainer des erreurs. L’ambigu'1‘té XV — XN constitue, selon nous, une situa-
tion caractéristique qu’il est préférable de résoudre au niveau de l’attachement syntagmatique
surtout si celui-ci est basé sur des regles lexicales.

5 Evaluation et discussion

La notion de super-chunk compatible avec notre déﬁnition n’eXistant dans aucun corpus annoté
de référence, l’éValuation a dﬁ étre réalisée manuellement.

Notre procédure d’ evaluation a porté sur un corpus composé de dépéches journalistiques ex-
traites du site yahoo. fr. Ce corpus de 13 493 mots (i.e. 6 901 chunks), auxquels nous avons
appliqué notre chunker a l’aide des données lexicales décrites dans les sections précédentes. La
sortie est un texte armoté ne contenant plus aucune ambigu'1‘té. Les résultats de l’éValuation sont
donnés dans la table 2.

De maniere générale, nous avons observé que la plupatt des erreurs sont dues a l’incomplétude
de nos ressources lexico-switaxiques. Ceci implique que de nombreuses améliorations peuvent
étre apportées facilement et le seront tres prochainement. Dans cette évaluation, nous distin-
guons les erreurs de précision et de rappel.

9No1:re corpus comprend un an d‘ar1:icles du joumal Le Monde et a été étiqueté avec TreeTagger (Schmid,
1994).

39

Olivier BLANC, Matthieu CONSTANT, Patrick WATRIN

PRECISION RAPPEL FMESURE
92,91% 98,69% 95.71%

TAB. 2 — Résultats

Les erreurs de rappel sont uniquement dues a la couverture de notre dictionnaire et de nos gram-
maires locales lexicalisées. D’un point de Vue lexical, certains mots grammaticaux composés
sont absents du dictionnaire (e. g. tandis que, au-dessous de). D’un point de Vue plus gramma-
ticale, les erreurs sont principalement imputables a la formalisation des entités nommées. La
séquence Nouri al Maliki, par exemple, n’a pu étre reconnue 2 la forme al est inconnue et n’a
pas été intégré dans la grammaire comme un préﬁxe de nom de famille. Par ailleurs, quelques
expressions semi-ﬁgées ont été oubliées (e. g. vers 8h45) de méme que certaines structures pro-
nominales complexes (e. g. au cours de laquelle).

Les erreurs de précision peuvent étre divisées en quatre classes.
1. Erreurs liées a SPH

L’ambigu'1‘té lexicale peut conduire a une mauvaise limitation des chunks apres application de
l’heu1istique des plus courts chen1ins. Par exemple, dans la séquence aprés l Qzﬂirmation du
quotidien espagnol El Pais, il existe deux analyses possibles 2

— [aprés l ’aﬁ'im1ation XP] [du quotidien espagnol XP] [El Pais XN] ;

— [aprés l ’aﬂim1ation XP] [du quotidien XP] [espagnol XA] [El Pais XN].

Comme quotidien et espagnol peuvent étre tous deux soit adjectif soit nom, l’algo1ithme SPH
Va préférer l’analyse [Prep XA N] au lieu de [Prep N] [XA] .

2. Erreurs dues aux regles statistiques

Dans la séquence La céte Est et les villes de New York ..., deux analyses sont atttibuées au
chunk Est 2 il s’agit soit d’un XV (étre), soit d’un XA (direction est). Bien qu’Est soit XA dans
ce contexte, le module statistique Va préférer l’analyse XV (probabilité de 0, 9 contre 0, 1 pour
l’analyse XA).

3. Erreurs causées par l’application des regles Luberon

Ces erreurs sont heureusement tres rares. Elles concement principalement l’ambigu'1‘té XP—XN
due a la forme de qui peut étre déterminant et préposition. Dans la séquence qui n’a pas foumi
de plus amples détails, par exemple, le chunk de plus amples détails aurait dﬁ étre étiqueté XN.

4. Erreurs imputables a la couverture lexicale

Quelques structures composées absentes dans le dictionnaire provoque des erreurs. Par exemple,
en outre est un adverbe composé mais est absent de notre dictionnaire. Ainsi, l’analyse compo-
sitionnelle est choisie dans la phrase ils ont en outre pris plusieurs centaines de personnes en
otage. Elle est segmentée en super-chunks de la maniere suivante 2

— [ils XN] [ont XV] [en outre pris plusieurs centaines XP] [de personnes XP] [en otage XP]

au lieu de,

40

Segmentation en super-chunks

— [ils XN] [ont en outre pris XV] [plusieurs centaines XN] [de personnes XP] [en otage XP]

ou en outre est un adverbe insere dans un chunk verbal.

En plus de l’evaluation en rappel et precision, nous avons aussi estime l’impact des ur1ites po-
lylexicales pour l’attachement lexical. Notre procedure permet la realisation correcte de 36,6 %
des attachements lexicaux interieurs aux groupes nominaux et prepositionnels, soit environ
13 % des attachements intemes et extemes aux symtagmes.

Malgre ces quelques erreurs, notre evaluation montre, selon nous, l’interet d’une segmentation
en super-chunks, tant du point de vue de l’attachement que du point de vue de la reduction
globale de l’ambigu'1‘te.

6 Conclusion et perspectives

Dans cette article, nous avons presente une technique de chunking reposant sur une augmenta-
tion signiﬁcative du r1iveau lexical. En introduisant la notion de super-chunks, nous chercl1ions,
d’une part, a optimiser le processus de desambigu'1‘sation et, d’ autre part, a resoudre une part de
l’attachement lexical au sein des constituants prepositionnels et nominaux.

Aﬁn d’ evaluer la pertinence et l’efﬁcacite de notre hypothese, nous avons confronte notre chun-
ker a un corpus de depeches joumalistiques. Cette experience nous a permis de degager une
double conclusion.

— Notre procedure afﬁche une precision et un rappel excellents sans necessiter le recours a un
etiqueteur.

- La prise en compte des unites polylexicales nous permet d’ evacuer efﬁcacement (i. e. sans en-
trainer d’ erreurs) une part consequente des attachements intemes aux constituants nominaux
et prepositionnels.

Cette experience nous a egalement permis de preciser un certain nombre de perspectives orga-
nisant notre travail futur. Ces perspectives s’a1ticulent autour de deux points principaux 2 (1)
l’augrnentation des ressources lexicales (principal facteur de succes de notre application) et (2)
l’amelioration du module de desambigu'1‘sation statistique (en ce sens, l’integration des I-IIVJM
nous semble etre une solution interessante).

References

ABNEY S. P. (1996). Partial parsing via ﬁnite-state cascades. Natural Language Engineering,
2(4), 337-344.

AIT-MOKHTAR S. & CHANOD J.-P. (1997). Incremental ﬁnite-state parsing. In Proceedings
of the ﬁfth Conference on Applied Natural Language Processing ANLP’97.

BLANC O. & CONSTANT M. (2006). Outilex, a linguistic platform for text processing. In
Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, p. 73-76.

COURTOIS B. (1990). Un systeme de dictionnaires electroniques pour les mots simples du
francais. langue Francaise, 87, 11-22.

41

Olivier BLANC, Matthieu CONSTANT, Patrick WATRIN

COURTOIS B., GARRIGUES M., GROSS G., GROSS M., JUNG R., MATHIEU-COLAS M.,
MONCEAUX A., PONCET-MONTANGE A., SILBERZTEIN M. & VIVES R. (1997). Diction-
naire e’lectronique DEIAC .' les mots compose’s binaires. Rapport inteme, LADL (Paris 7).
DAILLE B. (1995). Combined approach for terminology extraction .' lexical statistics and
linguistic ﬁltering. Rapport inteme, Lancaster University.

DIJKSTRA E. W. (1959). A note on two problems in connexion with graphs. Numerische
Mathematik, 1, 269-271.

DUNNING T. (1993). Accurate methods for the statistics of surprise and coincidence. Com-
putational Linguistics, 19(1), 61-74.

FEDERICI S., MONTEMAGNI S. & PIRELLI V. (1996). Shallow parsing and text chunking :
A view on underspeciﬁcation in syntax. In Proceedings of the ESSLLI’96 Workshop on Robust
Parsing.

GROSS M. (1997). The construction of local grammars, p. 329-352. MIT Press 2 Cambridge.
JOSHI A. & HOPELY P. (1997). A parser from antiquity 2 an early application of ﬁnite state
transducers to natural language parsing. Natural Language Engineering, 2(4), 6-15.
KARLSSON F., VOUTILAINEN A., HEIKKILA J. & ANTTILA A. (1995). Constraint Gram-
mar : A language-independent system for parsing unrestricted text, Volume 4 of Natural Lan-
guage Processing. Mouton de Gruyter.

NIVRE J. & NILSSON J. (2004). Multiword units in syntactic parsing. In Workshop on Me-
thodologies and Evaluation of Multiword Units in Real-World Applications, p. 39-46, Lisbon.
SCHMID H. (1994). Probabilistic part-of-speech tagging using decision trees. In International
Conference on New Methods in Language Processing, Manchester, UK.

SERETAN V., NERIMA L. & WEHRLI E. (2003). Extraction of multi-word collocations using
syntactic bigrarn composition. In Proceedings of th 4”‘ International Conference on Recent
Advances in NLP (RANLP-2003), p. 424-431.

WATRIN P. (2006). Une approche hybride de l’extraction d ’infom1ation : sous-langages et
lexique-grammaire. PhD thesis, Université catholique de Louvain.

WOODS W. A. (1970). Transition network grammars for natural language analysis. Commu-
nications of the ACM, 13(10).

42

