IALN ZUU'/, '1'ou1ouse, 3-8 _]l11I1 ZUU'/

Détection et prédiction de la satisfaction des usagers dans les
dialogues Personne-Machine

Narjes Boufaden, Truong Le Hoang, Pierre Dumouchel
Ecole de Technologie Supérieure et Centre de Recherche Inforrnatique de
Montreal
{Narj es.Boufaden,LeHoang.Truong,Pierre.Dumouchel} @crim.ca

Résumé. Nous étudions le role des entités nommées et marques discursives de rétroac-
tion pour la tache de classiﬁcation et prédiction de la satisfaction usager a partir de dialogues.
Les expériences menées sur 1027 dialogues Personne-Machine dans le domaine des agences
de voyage montrent que les entités nommées et les marques discursives n’améliorent pas de
maniere signiﬁcative le taux de classiﬁcation des dialogues. Par contre, elles permettent une
meilleure prédiction de la satisfaction usager a partir des premiers tours de parole usager.

Abstract. We study the usefulness of named entities and acknowldgment words for user
satisfaction classiﬁcation and prediction from Human-Computer dialogs. We show that named
entities and acknowledgment words do not enhance baseline classiﬁcation performance. Howe-
ver, they allow a better prediction of user satisfaction in the beginning of the dialogue.

M0tS-CléS I prédiction de la satisfaction usager, classiﬁcation des dialogues Personne-
Machine.

Keywords: prediction of user satisfaction, Human-Computer dialog classiﬁcation.

11 .1Juu1uu\/11, 1.4.11 11uU11s, 1 .1J bl111\lbl\/11L/1

1 Introduction

La progression des systemes de dialogue Personne-Machine dans le marche du service a la
clientele cree des attentes grandissantes tant sur le plan de la gestion des donnees generees par
ces systemes que sur leur exploitation a des ﬁns d’evaluation.

La classiﬁcation, l’indexation et l’extraction d’information sont autant d’exemples d’applica-
tions peu ou pas encore explorees en gestion des dialogues Personne-Machine. La majeure
partie de la recherche dans ce domaine est encore consacree a l’evaluation de ces systemes.

Dans cet article, nous explorons la classiﬁcation des dialogues Personne-Machine dans le but
de detecter les dialogues problematiques dans lesquels l’usager montre une insatisfaction par
rapport au systeme. Nous explorons l’utilisation des entites nommes et des marques discursives
de retroaction pour la tache de prediction de la satisfaction usager durant et apres le deroulement
du dialogue.

Ces travaux s’inserent dans le cadre d’un projet en cours avec une compagnie de telecommu-
nication dans le but d’evaluer leur systeme de dialogue et analyser les dialogues qu’il genere.
Comme premiere etape de ce projet, nous etudions la problematique de detection et prediction
de la satisfaction usager sur un corpus public : DARPA Communicator.

Dans la section 2, nous presentons l’etat de l’art en evaluation des systemes de dialogues
Personne-Machine, en detection des dialogues problematiques et presentons le cadre theorique
PARADISE. Dans la section 3, nous presentons le corpus DARPA Communicator avec lequel
nous effectuons nos experiences. La section 4 decrit notre approche basee du cadre theorique
PARADISE. La section 5 presente trois experiences de classiﬁcation dans lesquelles nous expe-
rimentons differentes combinaisons des attributs proposes pour detecter la satisfaction usager a
partir du dialogue. Dans la section 6, nous etudions le role des entites nommees et des marques
discursives dans la prediction de la satisfaction usager en debut de dialogue. Enﬁn, la section 7
presente une synthese de nos resultats ainsi que les prochaines etapes de ce projet.

2 Etat de l’art

L’ evaluation des systemes de dialogue occupe depuis la ﬁn des annees 90 une place de plus en
plus importante en recherche. Par exemple, (Eckert et al., 1998) ont utilise un modele stochas-
tique pour modeliser le comportement de differentes classes d’usager dans le but de collecter
des statistiques sur les differents scenarii de dialogues. En particulier, ils ont montre que la
longueur du dialogue en termes du nombre de tours de parole est un bon predicteur des perfor-
mances d’un systeme.

Dans une perspective plus generale, (Walker et al., 1997) proposaient le cadre theorique PARA-
DISE actuellement le plus utilise pour l’evaluation des systemes de dialogues. Ce cadre theo-
rique s’inspire de la theorie de decision et pose comme hypothese que la performance d’un
systeme de dialogues est correlee avec le degre de convivialite. Dans le cadre de notre applica-
tion (le service a la clientele), la convivialite se mesure en termes de satisfaction de l’usager.

PARADISE met en avant la maximisation de la satisfaction usager en maximisant les chances de
reussir la tache ou but du dialogue tout en minimisant les coﬁts associes a sa realisation. Ces
coﬁts sont deﬁnis en termes d’efﬁcacite (i.e. nombre de tours de parole systeme et usager) et

\/L\/\/L1\Jl1 \/L tIL\/\al1\/L1\Jl1 \aI\/ Lu DCILLDLCIN/L1\Jl1 \al\/D DIDCISK/LL) blﬂlllt) 1\/D \al1£l1\Jslal\/D L \/LD\J1111\/_J.V1(l\/1L111\/

qualité du systeme (i.e. temps de réponse du systeme). La Figure 1 illustre le cadre théorique
PARADISE.

Maximiser la satisfaction de l ’usager

Minimiser les colit associés a la
réalisation de la tache

Maximiser la réalisation de la tache

Mesure de l’eﬁ‘icacite de la tache Mesure de la qualité de la tache

FIG. 1 — Cadre théorique PARADISE

Le cadre PARADISE a été utilisé dans plusieurs travaux (Walker et al., 2000), (Lamel & Rosset,
2000), (Devillers & Rosset, 2000), notamment dans le but de choisir les stratégies de dialogues
qui maximisent la satisfaction de l’usager (Walker & Passonneau, 2001), pour déterminer les
composantes (reconnaissance de la parole, stratégie de dialogue) ayant le plus d’impact sur la
performance d’un systeme ou encore pour détecter les dialogues problématiques (Hastie et al.,
2002)

En particulier, (Hastie et al., 2002) ont proposé une approche pour la détection des dialogues
problématiques utilisant 16 attributs représentant différentes mesures reliées aux trois dimen-
sions déﬁnies dans PARADISE, a savoir :

Mesure du succés de la téiche Evaluation de l’usager indiquant la réalisation de la tache.

Mesure de l’efﬁcacité du systéme Traits extraits des traces du systeme de dialogue.

— Manuellement : Taux d’erreur de reconnaissance de la parole calculé a partir des trans-
criptions manuelles des dialogues et le taux d’erreur phrastique.

— Automatiquement : la durée de la tache, le nombre de tours de parole durant la tache,
nombre de chevauchement de tours de parole systeme et usager, la moyenne des temps
des tours de parole usager, la moyenne des mots par tour de parole usager, la moyenne
des temps des tours de parole systeme, la moyenne des mots par tour de parole systeme
et le type de téléphone (cellulaire ou ﬁxe).

Mesure de la qualité du systéme Actes de dialogue associés aux tours de parole du systeme.

Dans une premiere expérience, les auteurs ont utilisé tous les traits : extraits automatiquement
ainsi que ceux annotés manuellement. En utilisant un arbre de décision, ils ont obtenu un taux
de classiﬁcation de 54%. Toutefois, pour éviter l’utilisation des attributs annotés manuellement,
ils ont entrainé un arbre de décision aﬁn de prédire le succés de la téiche et les actes de dialogues
des tours de parole systeme. Avec un taux de prédiction du succés de la téiche de 92% et un
taux de prédiction des actes de dialogues de 98%, les auteurs ont obtenu un taux de classiﬁcation
similaire.

(Walker et al. , 2002) ont testé la détection des dialogues problématiques en utilisant des attributs
entierement extraits de maniere automatique. Ils ont utilisé aussi des mesures de l’efﬁcacité

11 .1Juu1uu\/11, 1.4.11 11uU11s, 1 .1J bl111\lbl\/11L/1

modélisé avec l’algorithme RIPPER (Cohen, 1995) : un algorithme de classiﬁcation a base de
regles. Sur le corpus généré par le systeme de AT&T How May I Help You, les auteurs ont
obtenu un taux de classiﬁcation de 70,1% a partir du premier tour de parole usager, 78,4% a
partir des deux premiers tours de parole et de 83% sur tout le dialogue.

Les travaux que nous présentons se basent sur le cadre théorique PARADISE et s’inspirent des
travaux de (Hastie et al., 2002) réalisés sur le corpus DARPA Communicator.

3 Corpus DARPA Communicator

Le corpus DARPA Communicator (version 2001) est un corpus public distribué par le Linguistic
Data Consortium (LDC). C’est le résultat d’une expérience menée sur plusieurs sites incluant
huit systemes de dialogue Personne-Machine dans le but de développer des approches robustes
de reconnaissance de la parole et de gestion de dialogues pour l’acces interactif a l’informa-
tion (Robust Recognition and Dialog Tracking for Interactive Information Access). Le domaine
d’application choisi est celui des agences de voyages.

Un des déﬁs de cette expérience était de collecter un corpus de dialogues Personne-Machine
proche de la réalité. Pour ce faire, les scénarii des dialogues étaient en majorité prédéﬁnis (sept
des neuf scénarii) puisque chaque participant savait l’origine et la destination de son voyage
ainsi que les dates et la compagnie aérienne a choisir. Tandis que deux des scénarii étaient
laissés au choix des participants. La version 2001 du corpus contient une sélection de plus de
1242 dialogues annotés avec la degré de satisfaction de l’usager. Les dialogues sont en moyenne
composés de 51 tours de parole avec en moyenne 25,4 tours de parole usager et une longueur
moyenne d’un tour de parole usager est de 64,6 mots.

Dans la version 2001 du corpus que nous utilisons dans nos expériences, chaque dialogue est

accompagné de deux ﬁchiers :

— Un ﬁchier qui contient la transcription du dialogue (partie du haut de la Figure 2).

— Un ﬁchier récapitulatif contenant les scores attribués par l’usager pour l’évaluation de la
convivialité du systeme (partie du bas de la Figure 2). En allant de gauche a droite la ligne
contient le nom du systeme (CMU pour Carnegie Melon University), l’index du site (le chiffre
27), le temps de début du dialogue (14 :25), la date du dialogue (2000/07/06), la complétion
de la tache et le reste des données sont respectivement les réponses a des questions portant
sur la convivialité du systeme. Chaque question était notée sur une échelle de 1 a 5 avec la
valeur 1 indiquant que l’usager est en parfait accord avec 1’ afﬁrmation et le score 5 indiquant
un total désaccord.

4 Approche

Nous proposons d’utiliser PARADISE pour détecter les dialogues problématiques et prédire la
satisfaction usager durant et apres le déroulement du dialogue.

Dans notre approche nous tenons compte de deux contraintes liées a notre projet :

— Minimiser la quantité d’information a annoter manuellement. Le but de ces expériences étant
de concevoir une application réelle pour la détection des dialogues problématiques, nous
voulons obtenir un systeme entierement automatisé.

\/L\/\/L1\Jl1 \/L tIL\/\al1\/L1\Jl1 \aI\/ Lu DCILLDLCIN/L1\Jl1 \al\/D DIDCISK/LL) blﬂlllt) 1\/D \al1£l1\Jslal\/D L \/LD\J1111\/_J.V1(l\/1L111\/

Thu Jul 6 2000 at 15 :15 238.51 2 Task-speciﬁc portion started.

Thu Jul 6 2000 at 15 :17 201.44 2 Overall task started.

Task completion status 2 not completed.

Thu Jul 6 2000 at 15 215 224.85 to Thu Jul 6 2000 at 15 215 225.01 2 New system turn
began.

Thu Jul 6 2000 at 15 215 224.94 2 System started speaking.

Thu Jul 6 2000 at 15 215 236.22 2 System ﬁnished speaking.

System said 2 . Hello. Welcome to the C M U Communicator. Please speak your 4-digit
ID number using the phrase, . My ID number is

Thu Jul 6 2000 at 15 215 238.51 2 New user turn began.

Thu Jul 6 2000 at 15 215 238.51 2 User started speaking.

Thu Jul 6 2000 at 15 215 243.53 2 User ﬁnished speaking.

Recognizer heard 2 MY I D NUMBER IS . ?THAT ?. . ?WONDER ?. ZERO EIGHT SE-
VEN

User said 2 my i. d. number is one zero eight seven [h#]

1087_02_27_03_20000706

CMU 27 14 225 EDT 2000/07/06 Alive No 4 1 4 3 4

(no comments provided)

FIG. 2 — Exemple de traces du systeme extrait du corpus DARPA Communicator.

— Minimiser la quantité d’information dépendante du domaine. Notre systeme étant voué a
étre appliqué sur un corpus différent du DARPA Communicator, nous voulons minimiser
l’information dépendante du domaine des agences de voyages.

Nous proposons de partir des mesures d’efﬁcacité proposées par (Hastie et al., 2002). Plus pre-

cisément, nous partons des mesures extraites automatiquement et étudions deux nouveaux traits

indépendants du domaine 2 les entités nommées contenue dans un dialogue et les marques
discursives de rétroaction. Nous proposons d’uti1iser les entités nommées comme indica-
teur de la densité d’information que nous corrélons avec la qualité du dialogue. Nous pensons
qu’une densité d’information faible (interruption du dialogue) ou trop importante (plusieurs ré-
pétitions) pourrait indiquer un probleme de communication entre l’usager et le systeme. Les
marques discursives de rétroaction sont utilisées dans la détection des actes de dialogues

notamment d’acquiescement ou de conﬁrmation, tous les deux correlés avec la satisfaction de
l’usager (Colineau & Caelen, 1996).

4.1 Les entités nommées

Les entités nommées sont des noms propres ou chiffres référant a des noms de personnes, de
lieux ou des noms de compagnies. L’ apport des entités nommées pour les applications de com-
préhension du langage naturel a été largement démontré aussi bien en extraction d’information
qu’en résumé automatique ou en traduction automatique. Leur intérét réside dans la valeur
sémantique de l’information qu’ils véhiculent. Dans le cadre de notre application, nous nous
intéressons a la correlation existant entre les entités nommées et la densité d’information.

Nous proposons d’utiliser le compte des entités nommées comme indicateur de la densité d’in-
formation contenue dans un dialogue. Par ailleurs et dans la mesure o1‘1 notre corpus n’est pas de
taille importante, nous regroupons le compte de toutes les catégories d’entités nommées pour

11 .1Juu1uu\/11, 1.4.11 11uU11s, 1 .1J bl111\lbl\/11L/1

réduire la dimension des vecteurs des données foumies comme données d’entrainement.

4.2 les marques discursives de rétroaction

Les marques discursives de rétroaction telles que ok, yes et no sont des marques lexicales
utilisées pour détecter les actes de dialogues d’acquiescement ou d’opposition (Colineau &
Caelen, 1996), (Jurafsky et al., 1998). Ce sont des unités lexicales qui, dans le contexte des
dialogues Personne-Machine, donnent une mesure qualitative sur le déroulement du dialogue.

Par ailleurs, les stratégies dialogiques des systemes de dialogues Personne-Machine étant en
grande partie composées de questions a base de choix binaires (Yes/N o questions) ou de choix
multiples, nous sommes assurés d’observer ces marques de maniere signiﬁcative dans les dia-
logues. Dans notre approche, nous ne faisons aucune distinction entre les marques de rétro-
actions indiquant un acquiescement yes, ok, correct ou yep de celles indiquant une op-
position no, wrong ou erase puisque nous ne tenons pas compte du contexte précédent le
tour de parole. Aussi, ce choix nous permet de réduire la dimension des vecteurs des données
d’entrainement.

Dans ce qui suit, nous testons différentes combinaisons des attributs décrits dans notre approche
pour la tache de classiﬁcation des dialogues et la prédiction de la satisfaction usager durant le
déroulement du dialogue.

5 Expérience 1 : Détection des dialogues problématiques

Notre premiere experience a pour but de classer des dialogues dans une des classes suivantes :
— Positive : L’usager a attribué un score de satisfaction < 12. Ce score est obtenu en cumulant
tous les scores des cinq questions évaluant la convivialité du systeme. Le seuil de 12 est aligné
sur celui proposé dans les travaux de (Hastie et al., 2002) aﬁn de permettre la comparaison
de nos résultats.
— Négative : L’usager a attribué un score 2 12.
Aﬁn d’évaluer notre approche, nous comparons nos résultats avec ceux de (Hastie et al., 2002)
en utilisant que les mesures d’efﬁcacité (indépendantes du domaine) extraites de maniere auto-
matique et les actes de dialogues (dépendants du domaine) pour classer les dialogues.

Nous présentons quatre expériences combinant nos différents attributs :

Eff. composé uniquement des mesures de l’efﬁcacité extraites automatiquent a partir des traces
du systeme de dialogue.

Eff.+NE composé des mesures de l’efﬁcacité et du compte des entités nommées toutes catego-
ries confondues.

Eff.+ACK composé des mesures de l’efﬁcacité et du compte des marques discursives de rétro-
action.

Eff.+EN+ACK composé de tous les attributs.

Nous testons ces combinaisons avec trois algorithmes de classiﬁcation : Support Vector Ma-
chine (SVM), k-Nearest-Neighbour (kNN) et un arbre de décision (DT). Le corpus utilisé est
constitué de 1027 dialogues tirés du corpus DARPA Communicator 2001. A la base le cor-
pus contenait une distribution de quatre dialogues de la classe positive pour un dialogue de la

\/L\/\/L1\Jl1 \/L tIL\/\al1\/L1\Jl1 \aI\/ Lu DCILLDLCIN/L1\Jl1 \al\/D DIDCISK/LL) blﬂlllt) 1\/D \al1£l1\Jslal\/D L \/LD\J1111\/_J.V1(l\/1L111\/

classe negative. Les premiers resultats sur ce corpus avec une distribution tres biaisee en faveur
des dialogues positifs se rapprochaient sensiblement du baseline de 80%. Aﬁn de remedier a
ce biais, nous avons constitue un nouveau corpus a partir du corpus original en dupliquant de
maniere aleatoire les statistiques de dialogues de la classe negative et en retirant de maniere
aleatoire les statistiques de dialogues de la classe positive jusqu’a obtention d’une distribution
uniforme (re-echantillonage avec duplication) avec 50% des donnees par classes.

Les resultats que nous presentons sont obtenus sur ce nouveau corpus. Ce sont les moyennes
des resultats de 10 validations croisees.

Modele Baseline Eff. Eff.+NE Eff.+ACK Eff.+NE+ACK (Hastie et al., 2002)

SVM 50% 6l,26% 62,9% 62,83% 63,5l% -

kNN 50% 91,41% 91,12% 9l,6% 9l,8% -

DT 50% 85,75% 84,68% 87,41 % 87,26% 54%

TAB. 1 — Performance des differents classiﬁcateurs en termes de taux de classiﬁcation pour les
differentes combinaisons d’attributs.

Contrairement a notre intuition quanta l’ apport des entites nommees et des marques discursives,
aucune amelioration signiﬁcative est observee pour les differents modeles. Les resultats pour le
modeles kNN est sensiblement le meme pour toutes les combinaisons d’attributs. Tandis qu’une
petite amelioration est observee pour l’arbre de decision (DT) et le SVM. Cependant, le resultat
obtenu pour le kNN avec la combinaison de tous les attributs est superieur aux resultats obtenus
par (Hastie et al., 2002). Toutefois, rappelons que la distribution des classes n’etant pas la meme
ont ne peut etablir une comparaison directe entre nos resultats et les leurs.

Enﬁn, bien que nous n’ayons pas ameliore le resultat de la classiﬁcation obtenu avec les mesures
d’efﬁcacite, nous avons obtenu un meilleur taux de classiﬁcation de 9l,8% avec le modele kNN.

6 Experience 2 : Prédiction de la satisfaction de l’usager

Malgre le peu d’amelioration des resultats obtenus sur la classiﬁcation des dialogues en com-
binant toutes les marques, nous voulions tester l’apport des entites nommes et des marques
discursives pour la prediction de la satisfaction usager durant le deroulement du dialogue. Nous
avons conduit neuf experiences dans lesquelles nous testons successivement les differentes com-
binaisons des attributs du Tableau 1 avec des donnees issues uniquement d’un nombre variable
de tours de parole usager. Chacune des combinaisons est testee sur des parties d’un dialogue
comprenant respectivement 1 tour de parole de l’usager, 2 tours de parole et ce jusqu’a 8 tours
de parole et enﬁn sur tout le dialogue (soit 25,4 tours de parole).

Nous avons dresse des courbes illustrant la progression du taux de classiﬁcation dumat le dia-
logue en augmentant le nombre des tours de parole de l’usager a chaque nouvelle experience.
Nous avons utilise le meme corpus que celui utilise dans la premiere experience et les resultats
obtenus sont la moyenne de 10 validations croisees.

Les courbes obtenues sont montrees dans les Figures 3, 4 et 5. La premiere ﬁgure represente
l’evolution du taux de classiﬁcation en fonction du nombre de tours de parole usager et ce
pour differentes combinaisons des attributs modelises par un SVM. La deuxieme ﬁgure montre
la progression modelisee avec l’algorithme kNN et la demiere ﬁgure montre la progression
modelisee avec un arbre de decision.

64

62

60

58

56

54

52

50

J. V .1J\Jlal1(l\al\/

11, 1.4.11 11uU11s,

 

0

20

1 . JJ u111U bl\/11\/1

FIG. 3 — Courbes illustrant la progression du taux de classiﬁcation durant le dialogue pour le

modele SVM.

95

90

85

80

75

70

65

60

55

50

 

EHAMEQ--—-a--4—

JACK -
Eff.+NE+ACK ---

0

20

FIG. 4 — Courbes illustrant la progression du taux de classiﬁcation durant le dialogue pour le

modele kNN.

95

85-
80-

80
75
75
70
70

65
65

60-
60-

50

 

0

16 18

20

FIG. 5 — Courbes illustrant la progression du taux de classiﬁcation durant le dialogue pour le

modele DT.

\/L\/\/L1\Jl1 \/L tIL\/\al1\/L1\Jl1 \aI\/ Lu DCILLDLCIN/L1\Jl1 \al\/D DIDCISK/LL) blﬂlllt) 1\/D \al1£l1\Jslal\/D L \/LD\J1111\/_J.V1(l\/1L111\/

Nous remarquons sur les différents graphiques que pendant les trois premiers tours de parole
usager, la combinaison de tous les attributs donne une meilleure prédiction de la satisfaction
usager.

Aussi, nous remarquons que le meilleur résultat est en majorité obtenu pour la combinaison
Eff.+ACK. Les marques discursives combinées aux mesures d’efﬁcacité améliorent grande-
ment le taux de classiﬁcation pendant les premiers tours de parole et ce pour tous les modeles.
I1 semble que l’ajout des entités nommées introduit du bruit car le résultat obtenu pour la com-
binaison Eff.+EN+ACK est moins bon.

Par ailleurs, la meilleure performance est obtenue avec l’algorithme kNN qui se base sur la dis-
tance euclidienne pour classer les dialogues. Cela s’eXplique par le fait que les données d’entrai-
nement sont des valeurs réelles qui représentent des fréquences et que la distance euclidienne
est une fonction qui permet de représenter efﬁcacement la similarité en termes de proximité.

Le Tableau 2 montre les performances du modele kNN qui a donné le meilleur résultat de
classiﬁcation avec les différentes combinaisons d’attributs.

Nb tours de parole Eff. Eff.+EN Eff.+ACK Eff.+EN+ACK
1 80,49% 81,78% 87,07% 87,26%

2 81,47% 83,44% 87,65% 87,26%

3 87,80% 88,29% 88,48% 88,39%

tous 91,41% 91,12% 91,6% 91,8%

TAB. 2 — Progression du taux de classiﬁcation sur les trois premiers tours de parole usager pour
le modele kNN.

7 Conclusion

Nous avons testé la combinaison des mesures de l’efﬁcacité proposées par (Hastie et al., 2002)
avec deux nouveaux attributs : les entités nommés et les marques discursives de rétroaction pour
la classiﬁcation des dialogues et la prédiction de la satisfaction usager. Bien que ces deux attri-
buts n’aient pas amélioré de maniere signiﬁcative les résultats de la classiﬁcation des dialogues,
ils ont permis une meilleure prédiction de la satisfaction usager durant les premiers tours de
parole de l’usager.

En particulier, le compte des marques discursives a permis d’obtenir les meilleurs taux de pre-
diction en début de dialogue. Ce résultat a un intérét particulier puisque moyennant cet attribut
facilement calculable et non dépendant du domaine d’application, nous avons amélioré le taux
de prédiction de la satisfaction usager de 6,6% pour le premier et second tour de parole par
rapport a celui obtenu avec le modele utilisant un arbre de décision.

Dans les prochaines étapes, nous exploiterons d’avantage les marques discursives de rétroaction
en tenant compte de l’information prosodique extraites de l’audio de ces unités lexicales. L’ aj out
de la prosodie permettra de distinguer ces marques en leur as sociant un contenu émotionnel pour
une meilleur prédiction de la satisfaction usager.

11 .1Juu1uu\/11, 1.4.11 11uU11s, 1 .1J bl111\lbl\/11L/1

Remerciement

Ce proj et est rendu possible grace au support de Patrimoine Canada.

Références

COHEN W. (1995). Fast Effective rule induction. In Proceedings of the 12th Conference on
Machine Learning.

COLINEAU N. & CAELEN J. (1996). Une approche lexicale pour la reconnaissance d’actes de
dialogue. In Séminaire lexique en traitement automatique de la parole, p. 137-145, Toulouse,
France.

DEVILLERS B.-M. H. L. & ROSSET S. (2000). Predictive performance of dialog systems. In
Int. Conf on Language ResourcesandEvaluation,LREC2000.

ECKERT W., LEVIN E. & PIERACCINI R. (1998). Automatic evaluation of spoken dialogue
systems. TWLTI3 .' Formal semantics and pragmatics of dialogue.

HASTIE H., PRASAD R. & WALKER M. (2002). What’s the Trouble : Automatically Identi-
fying Problematic Dialogues in DARPA Communicator Dialogue Systems. In Proceedings of
the ACL 2002.

J URAFSKY D., E. S., B. F. & CURL T. (1998). Lexical, prosodic, and syntactic cues for dialog
acts. In Proceedings of ACI/COLING 98 Workshop on Discourse Relations and Discourse
Markers.

LAMEL L. & ROSSET S. (2000). Considerations in the design and evaluation of spoken
language dialog systems. In ICSLP, 2000.

WALKER M., LITMAN D. J ., KAMM C. A. & ABELLA A. (1997). Interactive Spoken Dialog
Systems .' Bridging Speech and NLP Together in Real Applications, chapter Evaluating Inter-
active Dialogue Systems : Extending Component Evaluation to Integrated System Evaluation.
Association for Computational Linguistics : New Brunswick, New Jersey.

WALKER M. A., LANGKILDE 1., WRIGHT J ., GoRIN A. & LITMAN D. (2000). Learning to
predict problematic situations in a spoken dialogue system : Experiments with how may i help
you ? In North American Meeting of the Association of Computational Linguistics.

WALKER M. A., LANGKILDE-GEARY I., HASTIE H. W., WRIGHT J . & GoRIN A. (2002).
Automatically Training A Problematic Dialog Predictor for the HMOHY Spoken Dialog Sys-
tem. Journal ofArtiﬁcial Intelligence Research, 16, 293-319.

WALKER M. A. & PASSONNEAU R. (2001). Date : A dialogue act tagging scheme for evalua-
tion of spoken dialogue systems. In In Proceedings of Human Language Technology Confe-
rence, San Diego.

