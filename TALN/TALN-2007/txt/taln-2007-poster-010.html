<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>OGMIOS : une plate-forme d&#8217;annotation linguistique de collection de documents issus du Web</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2007, Toulouse, 5&#8211;8 juin 2007
</p>
<p>OGMIOS : une plate-forme d&#8217;annotation linguistique
de collection de documents issus du Web
</p>
<p>Thierry HAMON, Julien DERIVI&#200;RE, Adeline NAZARENKO
LIPN &#8211; UMR CNRS 7030
</p>
<p>99 av. J.B. Cl&#233;ment, F-93430 Villetaneuse, FRANCE
{Thierry.Hamon,Julien.Derivi&#232;re,Adeline.Nazarenko}
</p>
<p>@lipn.univ-paris13.fr
</p>
<p>R&#233;sum&#233;. L&#8217;un des objectifs du projet ALVIS est d&#8217;int&#233;grer des informations linguistiques
dans des moteurs de recherche sp&#233;cialis&#233;s. Dans ce contexte, nous avons con&#231;u une plate-forme
d&#8217;enrichissement linguistique de documents issus du Web, OGMIOS, exploitant des outils de
TAL existants. Les documents peuvent &#234;tre en fran&#231;ais ou en anglais. Cette architecture est
distribu&#233;e, afin de r&#233;pondre aux contraintes li&#233;es aux traitements de gros volumes de textes, et
adaptable, pour permettre l&#8217;analyse de sous-langages. La plate-forme est d&#233;velopp&#233;e en Perl
et disponible sous forme de modules CPAN. C&#8217;est une structure modulaire dans lequel il est
possible d&#8217;int&#233;grer de nouvelles ressources ou de nouveaux outils de TAL. On peut ainsi d&#233;finir
des configuration diff&#233;rentes pour diff&#233;rents domaines et types de collections. Cette plateforme
robuste permet d&#8217;analyser en masse des donn&#233;es issus du web qui sont par essence tr&#232;s h&#233;-
t&#233;rog&#232;nes. Nous avons &#233;valu&#233; les performances de la plateforme sur plusieurs collections de
documents. En distribuant les traitements sur vingt machines, une collection de 55 329 docu-
ments du domaine de la biologie (106 millions de mots) a &#233;t&#233; annot&#233;e en 35 heures tandis qu&#8217;une
collection de 48 422 d&#233;p&#234;ches relatives aux moteurs de recherche (14 millions de mots) a &#233;t&#233;
annot&#233;e en 3 heures et 15 minutes.
</p>
<p>Abstract. In the context of the ALVIS project, which aims at integrating linguistic in-
formation in topic-specific search engines, we developed an NLP architecture, OGMIOS, to
linguistically annotate large collections of web documents with existing NLP tools. Documents
can be written in French or English. The distributed architecture allows us to take into account
constraints related to the scalability problem of Natural Language Processing and the domain
specific tuning of the linguistic analysis. The platform is developed in Perl and is available as
CPAN modules. It is a modularized framework where new resources or NLP tools can be in-
tegrated. Then, various configurations are easy to define for various domains and collections.
This platform is robust to massively analyse web document collections which are heterogeneous
in essence. We carried out experiments on two different collections of web documents on 20
computers. A 55,329 web documents collection dealing with biology (106 millions of words)
has been annotated in 35 hours, whereas a 48,422 search engine news collection (14 millions of
word) has been annotated in 3 hours and 15 minutes.
</p>
<p>Mots-cl&#233;s : plateforme d&#8217;annotation linguistique, passage &#224; l&#8217;&#233;chelle, robustesse.
Keywords: linguistic annotation, NLP platform, process scability, robustess.
</p>
<p>103</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Thierry HAMON, Julien DERIVI&#200;RE, Adeline NAZARENKO
</p>
<p>1 Introduction
</p>
<p>Si les moteurs de recherche actuels sont suffisants pour r&#233;pondre aux requ&#234;tes les plus courantes
sur Internet, il n&#8217;existe pas actuellement d&#8217;outils permettant la formulation de requ&#234;tes s&#8217;ap-
puyant sur des techniques de recherche avanc&#233;es (filtrage sur le sens, &#233;limination d&#8217;ambigu&#239;t&#233;s,
exclusion des sites marchands, etc.) et sp&#233;cialis&#233;es exploitant des connaissances du domaine.
Par exemple, la plupart des publications dans le domaine de la biologie et de la bio-m&#233;decine
sont enregistr&#233;es dans de grandes bases de donn&#233;es textuelles, plus ou moins sp&#233;cialis&#233;es (Fly-
base pour l&#8217;esp&#232;ce Drosophilia Menogaster, Medline pour la biologie et la m&#233;decine). Ce type
de bases documentaire est aujourd&#8217;hui essentiel au travail des scientifiques mais ceux-ci sont
confront&#233;s &#224; la masse de textes, sans pouvoir y faire face. Les outils disponibles sont trop g&#233;n&#233;-
raux, ils renvoient des centaines ou des milliers d&#8217;articles pour la moindre requ&#234;te. Pour juger
de la pertinence d&#8217;un document dans ce contexte, il faut en analyser le contenu (reconnaissance
des entit&#233;s, reconnaissance des termes techniques).
</p>
<p>Le projet ALVIS1 vise &#224; d&#233;velopper un moteur de recherche open source incluant des techniques
de recherche avanc&#233;es et d&#8217;analyse du contenu textuel, notamment du point de vue s&#233;mantique.
Par rapport aux moteurs de recherche actuels, ALVIS cherche &#224; prendre en compte &#224; la fois
le th&#232;me et le contexte de la recherche pour affiner l&#8217;analyse de la requ&#234;te et du document.
Le projet s&#8217;appuie sur une architecture peer-to-peer. Le syst&#232;me est constitu&#233; d&#8217;un r&#233;seau de
&#171; n&#339;uds &#187; assurant l&#8217;infrastructure de recherche globale, auxquels sont adjoints des n&#339;uds
sp&#233;cialis&#233;s pour un domaine donn&#233;. Les n&#339;uds sp&#233;cialis&#233;s proposent une v&#233;ritable analyse du
contenu textuel pour am&#233;liorer l&#8217;acc&#232;s au document. A terme, des t&#226;ches d&#8217;extraction d&#8217;infor-
mations structur&#233;es et leur fusion avec des informations d&#233;j&#224; enregistr&#233;es au sein de bases de
donn&#233;es devraient pouvoir &#234;tre prises en charge par ce type de moteur sp&#233;cialis&#233;.
</p>
<p>L&#8217;acc&#232;s au contenu s&#233;mantique des documents issus du web ou de grandes bases documentaires
n&#233;cessite une premi&#232;re phase d&#8217;enrichissement linguistique des documents en un temps suffi-
samment court. Il s&#8217;agit ici de r&#233;duire le goulet d&#8217;&#233;tranglement que constituent g&#233;n&#233;ralement
les outils de TAL lorsqu&#8217;ils sont int&#233;gr&#233;s dans des applications de recherche d&#8217;information.
L&#8217;architecture logicielle que nous avons d&#233;velopp&#233; permet de satisfaire cette contrainte. Cette
plate-forme, OGMIOS, est &#224; la fois g&#233;n&#233;rique et sp&#233;cialisable. Elle est con&#231;ue pour analyser de
mani&#232;re robuste des collections de taille vari&#233;es et h&#233;t&#233;rog&#232;nes du point de vue de la langue
(pour l&#8217;instant le fran&#231;ais et l&#8217;anglais2), de la longueur et du type de leurs documents . Elle peut
aussi &#234;tre sp&#233;cialis&#233;e pour un domaine particulier. Dans le cadre du projet ALVIS, les exp&#233;-
riences ont port&#233; en priorit&#233; sur le domaine de la biologie, mais nous avons &#233;galement pu tester
la plate-forme sur un corpus de d&#233;p&#234;ches relatives aux moteurs de recherche.
</p>
<p>Cet article pr&#233;sente notre approche permettant de r&#233;pondre aux contraintes de performances,
de g&#233;n&#233;ricit&#233; et d&#8217;adaptabilit&#233; &#224; un domaine de sp&#233;cialit&#233;, qu&#8217;impose l&#8217;utilisation du TAL dans
une application de recherche d&#8217;information (RI) sp&#233;cialis&#233;e. Dans la section 2, nous donnons un
aper&#231;u de l&#8217;&#233;tat de l&#8217;art des plates-formes d&#8217;annotation de documents. La plate-forme est d&#233;crite
dans la section 3 avec les modules de traitement qu&#8217;elle int&#232;gre. L&#8217;&#233;valuation des performances
de la plateforme est pr&#233;sent&#233;e &#224; la section 4.
</p>
<p>1ALVIS Superpeer semantic Search Engine, projet IST / STREP n&#730; 002068, voir http://www.alvis.
info/alvis.
</p>
<p>2Des versions slov&#232;ne et chinoise ont &#233;galement &#233;t&#233; d&#233;velopp&#233;es dans le cadre du projet mais avec une ambition
moindre pour le slov&#232;ne et avec une architecture un peu diff&#233;rente pour le chinois.
</p>
<p>104</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>OGMIOS : une plate-forme d&#8217;annotation linguistique
</p>
<p>2 &#201;tat de l&#8217;art
</p>
<p>Lors de cette derni&#232;re d&#233;cennie, plusieurs architectures d&#8217;ing&#233;nierie du texte ont &#233;t&#233; d&#233;velopp&#233;es
pour articuler les traitements linguistiques (Cunningham et al., 2000) sans toutefois se placer
dans un contexte de recherche d&#8217;information. Ainsi, les architectures GATE (Bontcheva et al.,
2004), UIMA (Ferrucci &amp; Lally, 2004) ou de Textpresso (M&#252;ller et al., 2004) visent g&#233;n&#233;ra-
lement l&#8217;annotation linguistique et l&#8217;exploration de corpus de taille moyenne pour l&#8217;extraction
d&#8217;information. LinguaStream (Widl&#246;cher &amp; Bilhaut, 2005), quant &#224; elle, est con&#231;ue comme un
outil de d&#233;pouillement de corpus et d&#8217;exp&#233;rimentation, qui formalise des traitements complexes.
</p>
<p>Ces plates-formes appuient leur analyse des documents sur des outils de Traitement Automa-
tique des Langues existants. Ceux-ci sont r&#233;utilis&#233;s dans des modules qui les encapsulent et qui
assurent la conformit&#233; des entr&#233;es/sorties. La d&#233;finition d&#8217;un format d&#8217;&#233;change et d&#8217;annotation
suffisamment g&#233;n&#233;rique est &#233;galement un point crucial pour les plates-formes d&#8217;annotation. Il
s&#8217;agit d&#8217;assurer une communication correcte des informations entre les modules, mais aussi une
r&#233;utilisation des annotations produites dans des applications externes. Ont ainsi &#233;t&#233; propos&#233;s dif-
f&#233;rents formats d&#8217;&#233;change et d&#8217;annotation qui reposaient g&#233;n&#233;ralement sur SGML puis XML.
Le format d&#8217;&#233;change et d&#8217;annotation de GATE, CPSL (Common Pattern Specific Language) et
d&#8217;UIMA, CAS (Common Analysis Structure) sont inspir&#233;s du format d&#8217;annotation TIPSTER
(Grishman, 1997). Afin de pr&#233;server une certaine flexibilit&#233;, les annotations y sont d&#233;port&#233;es.
</p>
<p>Au regard de nos contraintes (g&#233;n&#233;ricit&#233;, performances et adaptabilit&#233; &#224; un domaine de sp&#233;cia-
lit&#233;), les plates-formes d&#8217;annotation existantes ne paraissent pas adapt&#233;es &#224; la recherche d&#8217;in-
formation sp&#233;cialis&#233;e. Si les plates-formes GATE et UIMA sont plut&#244;t con&#231;ues comme des
solutions g&#233;n&#233;riques, le syst&#232;me Textpresso (M&#252;ller et al., 2004) poursuit un objectif similaire
au n&#244;tre : proposer une architecture g&#233;n&#233;rique capable de traiter des corpus de documents issus
d&#8217;un domaine sp&#233;cialis&#233;. Cette plate-forme a &#233;t&#233; con&#231;ue pour la fouille des documents traitant
de biologie, aussi bien des r&#233;sum&#233;s que des articles complets. Son &#233;valuation a port&#233; sur un
corpus relativement petit : 16 000 r&#233;sum&#233;s et 3 000 articles en texte brut.
</p>
<p>En r&#232;gle g&#233;n&#233;rale, on dispose de tr&#232;s peu d&#8217;informations pour d&#8217;&#233;valuer les performances de ces
syst&#232;mes sur un corpus de documents. Un premier test nous a montr&#233; que GATE ne convient pas
au traitement de gros corpus de documents : seuls de petits volumes de documents pouvaient
&#234;tre trait&#233;s sans rencontrer des probl&#232;mes. Ceci s&#8217;explique par le fait que GATE ait &#233;t&#233; con&#231;ue
comme un environnement puissant de d&#233;veloppement et de conception d&#8217;applications de TAL
dans le cadre de l&#8217;extraction d&#8217;information. Le passage &#224; l&#8217;&#233;chelle n&#8217;&#233;tait pas un objectif cen-
tral. La m&#233;ta-plate-forme KIM (Popov et al., 2004), qui s&#8217;appuie sur GATE, tente cependant
de satisfaire cette contrainte dans le cadre de projets d&#8217;annotation s&#233;mantique massive SWAN3
et SEKT4. L&#8217;architecture est d&#233;di&#233;e &#224; l&#8217;enrichissement d&#8217;ontologies, l&#8217;indexation s&#233;mantique et
la recherche d&#8217;information. Bien que les auteurs identifient le passage &#224; l&#8217;&#233;chelle comme un
param&#232;tre critique, aucune performance en terme de temps de calcul et de volume de docu-
ments trait&#233;s, n&#8217;est fournie. Le traitement de grande collections de documents est cependant,
envisageable avec UIMA, les temps de calcul et l&#8217;adaptabilit&#233; des traitements restant &#224; &#233;valuer.
Celle-ci offre en effet la possibilit&#233; de traiter les documents les uns apr&#232;s les autres ou sous
forme d&#8217;une collection. Le Collection Processing Engine (CPE) g&#232;re alors la parall&#233;lisation et
surveille les performances.
</p>
<p>3http ://deri.ie/projects/swan
4http ://sekt.semanticweb.org
</p>
<p>105</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Thierry HAMON, Julien DERIVI&#200;RE, Adeline NAZARENKO
</p>
<p>Les plates-formes existantes r&#233;pondent donc partiellement aux contraintes de l&#8217;int&#233;gration d&#8217;in-
formations linguistiques dans un moteur de recherche sp&#233;cialis&#233;. Il s&#8217;agit g&#233;n&#233;ralement plus
d&#8217;environnements de d&#233;pouillement que d&#8217;architectures d&#8217;annotation de gros volumes de don-
n&#233;es pouvant &#234;tre utilis&#233;es pour la recherche d&#8217;information sp&#233;cialis&#233;e. Nous avons donc d&#233;ve-
lopp&#233; une plate-forme capable de g&#233;rer d&#8217;importants volumes de documents en mettant l&#8217;accent
sur l&#8217;efficacit&#233; et la robustesse des traitements effectu&#233;s.
</p>
<p>3 Une plate-forme modulaire et adaptable
</p>
<p>Nous avons choisi de d&#233;velopper une plate-forme d&#8217;annotation linguistique exploitant des outils
de TAL existants plut&#244;t que d&#8217;en d&#233;velopper de nouveaux5. Nous avons ainsi pu mettre l&#8217;accent
sur la robustesse des traitements et la rapidit&#233; de l&#8217;annotation de grandes quantit&#233;s de documents
sp&#233;cialis&#233;s, en proposant une architecture modulaire et distribu&#233;e. De plus, l&#8217;adaptation des trai-
tements n&#233;cessaires &#224; l&#8217;analyse de textes sp&#233;cialis&#233;s est r&#233;alis&#233;e par l&#8217;int&#233;gration de ressources
sp&#233;cifiques au domaine ou l&#8217;utilisation d&#8217;outils sp&#233;cialis&#233;s pour un domaine.
</p>
<p>3.1 Contraintes sp&#233;cifiques
</p>
<p>Le fait de r&#233;utiliser des outils existants et d&#8217;autoriser le remplacement de certains outils par
d&#8217;autres imposent des contraintes sp&#233;cifiques. Il faut notamment g&#233;rer l&#8217;h&#233;t&#233;rog&#233;n&#233;it&#233; des for-
mats d&#8217;entr&#233;es/sorties des outils utilis&#233;s dans la plate-forme. Chaque outil ayant g&#233;n&#233;ralement
ses formats propres, il est donc crucial de d&#233;finir un format d&#8217;&#233;change permettant d&#8217;intercon-
necter librement des outils ensemble et de distribuer correctement les traitements.
</p>
<p>Le d&#233;veloppement d&#8217;une plate-forme d&#8217;annotation des textes sp&#233;cialis&#233;s int&#232;gre &#233;galement des
contraintes sp&#233;cifiques au TAL, comme la disponibilit&#233; de ressources lexicales, terminologiques
et ontologiques, ou la n&#233;cessit&#233; d&#8217;adapter des outils au domaine afin d&#8217;am&#233;liorer certains traite-
ments, comme l&#8217;&#233;tiquetage morpho-syntaxique ou l&#8217;analyse syntaxique, sur des sous-langages
particuliers. De plus, toutes les &#233;tapes de traitement n&#8217;&#233;tant pas &#233;galement pertinentes pour
toutes les applications, nous avons pr&#233;serv&#233; au maximum l&#8217;approche modulaire.
</p>
<p>3.2 Architecture g&#233;n&#233;rale
</p>
<p>Les diff&#233;rentes &#233;tapes de traitement sont traditionnellement prises en charge par un ensemble de
modules (Bontcheva et al., 2004). Chaque module est d&#233;di&#233; &#224; un type de traitement : reconnais-
sance d&#8217;entit&#233;s nomm&#233;es, segmentation en mots, &#233;tiquetage morpho-syntaxique, analyse syn-
taxique, etc. Un module encapsule l&#8217;outil effectuant une analyse linguistique donn&#233;e et assure
la conformit&#233; du format des entr&#233;es/sorties avec la d&#233;finition de type de documents (dor&#233;navant
DTD). Les annotations sont enregistr&#233;es dans un format XML d&#233;port&#233; afin de pouvoir mieux
g&#233;rer l&#8217;h&#233;t&#233;rog&#233;n&#233;it&#233; des entr&#233;es/sorties des outils de TAL. La DTD est d&#233;crite dans (Taylor,
2006; Nazarenko et al., 2006). La modularit&#233; de l&#8217;architecture facilite la substitution d&#8217;un outil
par un autre, car le remplacement d&#8217;un outil n&#8217;a aucun impact sur l&#8217;ensemble de l&#8217;architecture.
</p>
<p>5Nous avons toutefois d&#233;velopp&#233; des outils lorsqu&#8217;aucun outil r&#233;pondant &#224; nos besoin n&#8217;&#233;tait disponible ou
nous convenait. Nous avons, de plus, choisi de pr&#233;f&#233;rence des logiciels sous licence GPL ou libre/gratuit pour un
usage non commercial.
</p>
<p>106</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>OGMIOS : une plate-forme d&#8217;annotation linguistique
</p>
<p>La sp&#233;cialisation de la plate-forme pour un domaine sp&#233;cifique est assur&#233;e par les ressources de
chacun des modules. Par exemple, une liste d&#8217;esp&#232;ces ou de g&#232;nes peut &#234;tre ajout&#233;e au module
de rep&#233;rage d&#8217;entit&#233;s nomm&#233;es sp&#233;cifiques &#224; la biologie, afin de traiter des r&#233;sum&#233;s de Medline.
L&#8217;adaptabilit&#233; des traitements peut aussi se faire par l&#8217;int&#233;gration d&#8217;outils sp&#233;cialis&#233;s.
</p>
<p>La figure 1 pr&#233;sente l&#8217;architecture de la plate-forme dans son &#233;tat actuel. D&#8217;autres modules tels
que l&#8217;&#233;tiquetage s&#233;mantique et la r&#233;solution d&#8217;anaphores seront prochainement int&#233;gr&#233;s. Les
bo&#238;tes repr&#233;sentent les diff&#233;rents modules composant la cha&#238;ne de traitements linguistiques. Ces
modules sont d&#233;crits dans la section 3.3. Les fl&#232;ches en traits pleins repr&#233;sentent le flux de
donn&#233;es lors du traitement tandis que les fl&#232;ches en pointill&#233;s repr&#233;sentent les ressources qui
peuvent &#234;tre utilis&#233;es dans la plate-forme.
</p>
<p>!&quot;#$%&amp; '()&quot;**+,&amp;&amp;+*)(
-.(*/,/0&amp;1*&quot;220(&amp;
</p>
<p>3(42(*/+/,&quot;*1(*12&quot;/&amp;
</p>
<p>3(42(*/+/,&quot;*1(*1$5#+&amp;(&amp;
</p>
<p>6(22+/,&amp;+/,&quot;*
</p>
<p>7/,8%(/+4(1/(#2,*&quot;9&quot;4,8%(
</p>
<p>:&quot;;(*,&amp;+/,&quot;*
</p>
<p>7/,8%(/+4(12&quot;#$5&quot;&#358;&amp;&lt;*/+=,8%(
</p>
<p>#(&amp;&amp;&quot;%#)(
&gt;-,)/,&quot;**+,#(?
</p>
<p>#(&amp;&amp;&quot;%#)(
&gt;9(22(&amp;?#(&amp;&amp;&quot;%#)(
</p>
<p>&gt;/(#2,*&quot;9&quot;4,(?
</p>
<p>+**&quot;/0
!&quot;#$%&amp;
</p>
<p>#(&amp;&amp;&quot;%#)(
&gt;(*/,/0&amp;1*&quot;220(&amp;?
</p>
<p>#(&amp;&amp;&quot;%#)(
&gt;#@49(&amp;1-.+*+9&lt;&amp;(?
</p>
<p>A*+9&lt;&amp;(1&amp;&lt;*/+=,8%(
</p>
<p>FIG. 1 &#8211; Architecture de la cha&#238;ne de traitement
</p>
<p>Nous partons du principe que les documents Web donn&#233;s en entr&#233;e ont d&#233;j&#224; &#233;t&#233; t&#233;l&#233;charg&#233;s, net-
toy&#233;s, cod&#233;s en UTF-8 et convertis au format XML (Taylor, 2006). Les documents sont d&#8217;abord
tokenis&#233;s, ce qui permet de d&#233;finir des offsets (indices d&#233;limitant une s&#233;quence, en nombre de
caract&#232;res par rapport au d&#233;but du document) pour garantir l&#8217;homog&#233;n&#233;it&#233; des diff&#233;rentes anno-
tations. Les tokens seront utilis&#233;s par les modules suivants. Les documents sont ensuite trait&#233;s
par divers modules : rep&#233;rage d&#8217;entit&#233;s nomm&#233;es, segmentation en mots et en phrases, lemma-
tisation, &#233;tiquetage morpho-syntaxique, &#233;tiquetage terminologique et analyse syntaxique.
</p>
<p>Cette architecture est assez traditionnelle mais certains points m&#233;ritent d&#8217;&#234;tre soulign&#233;s :
</p>
<p>&#8211; La tokenisation constitue la premi&#232;re &#233;tape de la cha&#238;ne. Elle proc&#232;de &#224; une premi&#232;re segmen-
tation, non linguistique, utilis&#233;e par la suite par les autres outils. Le token est donc l&#8217;unit&#233; tex-
tuelle de base dans la cha&#238;ne de traitements, et n&#8217;est qu&#8217;un point de d&#233;part pour les autres an-
notations. Ce niveau d&#8217;annotation suit les recommandations du groupe TC37SC4/TEI, m&#234;me
si nous employons le terme d&#8217;offset de caract&#232;re plut&#244;t que celui de pointeur d&#8217;&#233;l&#233;ment pour
d&#233;signer les fronti&#232;res de chaque token. Pour simplifier les traitements suivants, nous distin-
guons quatre types de tokens : alphab&#233;tiques, num&#233;riques, s&#233;parateurs et symboliques.
</p>
<p>107</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Thierry HAMON, Julien DERIVI&#200;RE, Adeline NAZARENKO
</p>
<p>&#8211; L&#8217;&#233;tiquetage des entit&#233;s nomm&#233;es se produit tr&#232;s t&#244;t dans la cha&#238;ne de traitement car l&#8217;identi-
fication des entit&#233;s nomm&#233;es facilite la d&#233;sambigu&#239;sation d&#8217;un certain nombre de marques de
ponctuation lors de la segmentation en mots ou en phrases.
</p>
<p>&#8211; L&#8217;&#233;tiquetage terminologique est utilis&#233; tel quel mais peut &#233;galement &#234;tre consid&#233;r&#233; comme
un pr&#233;alable &#224; l&#8217;analyse syntaxique. Cette derni&#232;re demandant beaucoup de temps de cal-
cul, nous exploitons le fait qu&#8217;une analyse terminologique r&#233;duit le nombre d&#8217;analyses syn-
taxiques possibles (Aubin et al., 2005).
</p>
<p>3.3 Description des modules disponibles
</p>
<p>Les modules sont appel&#233;s de mani&#232;re s&#233;quentielle pour chaque document. Les sorties (annota-
tions) sont stock&#233;es en m&#233;moire jusqu&#8217;&#224; la fin du traitement du document en cours, puis enre-
gistr&#233;es dans un format XML.
</p>
<p>Cette section d&#233;crit les diff&#233;rents modules int&#233;gr&#233;s &#224; l&#8217;heure actuelle au sein de la cha&#238;ne de
traitement. Il s&#8217;agit d&#8217;une description des modules par d&#233;faut de la plate-forme pour le traite-
ment de l&#8217;anglais. Des outils similaires sont &#233;galement int&#233;gr&#233;s pour le fran&#231;ais (&#224; l&#8217;exception
de l&#8217;analyse syntaxique). De plus, la conception et l&#8217;impl&#233;mentation de la plate-forme permet
ais&#233;ment une substitution d&#8217;un outil par un autre.
</p>
<p>Etiquetage d&#8217;entit&#233;s nomm&#233;es. Le module assurant la reconnaissance des entit&#233;s nomm&#233;es
identifie les s&#233;quences textuelles qui renvoient &#224; une entit&#233;, leur associe un type s&#233;mantique
(d&#233;pendant du domaine &#8211; pour la biologie, les &#233;tiquettes gene et species, par exemple) et,
le cas &#233;ch&#233;ant, normalise cette s&#233;quence. Dans la suite des traitements, une entit&#233; nomm&#233;e est
consid&#233;r&#233;e comme une seule unit&#233; et assimil&#233;e &#224; un mot. En les reconnaissant &#224; un stade tr&#232;s
pr&#233;liminaire dans l&#8217;analyse, on &#233;vite des ambigu&#239;t&#233;s ult&#233;rieures. Le module encapsule TagEN
(Berroyer, 2004), qui repose essentiellement sur des dictionnaires et l&#8217;application de r&#232;gles
d&#233;crites sous formes de transducteurs.
</p>
<p>Segmentation en mots et en phrases. Ce module identifie les phrases et les mots. Il exploite
un ensemble d&#8217;expressions r&#233;guli&#232;res reprenant l&#8217;algorithme propos&#233; dans (Grefenstette &amp; Ta-
panainen, 1994). Une partie de la segmentation est effectu&#233;e par le module de reconnaissance
des entit&#233;s nomm&#233;es dans la mesure o&#249; celui-ci r&#233;sout un grand nombre des probl&#232;mes li&#233;s &#224;
la ponctuation. C&#8217;est par exemple le module traitant les entit&#233;s nomm&#233;es qui permet de recon-
na&#238;tre la s&#233;quence &#171; B. subtilis &#187; , et qui met en rapport l&#8217;abr&#233;viation &#171; B. &#187; avec la forme
&#233;tendue &#171; Bacillus &#187; . Le point pr&#233;sent dans la s&#233;quence &#171; B. subtilis &#187; n&#8217;a plus &#224; &#234;tre pris en
compte au niveau de la segmentation en phrases.
</p>
<p>&#201;tiquetage morpho-syntaxique. Ce module associe une &#233;tiquette morpho-syntaxique &#224;
chaque mot du texte. Il repose sur la segmentation effectu&#233;e &#224; l&#8217;&#233;tape pr&#233;c&#233;dente. Nous uti-
lisons &#224; l&#8217;heure actuelle le TreeTagger (Schmid, 1997). Nous avons aussi test&#233; l&#8217;int&#233;gration de
l&#8217;&#233;tiqueteur GeniaTagger (Tsuruoka et al., 2005) qui est sp&#233;cialis&#233; pour le biologie, m&#234;me si on
observe que le gain en qualit&#233; de l&#8217;&#233;tiquetage se fait au d&#233;triment des performances.
</p>
<p>108</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>OGMIOS : une plate-forme d&#8217;annotation linguistique
</p>
<p>Lemmatisation. Ce module associe un lemme &#224; chaque mot du texte. Si le mot ne peut pas
&#234;tre lemmatis&#233; (nombres, mots &#233;trangers, mots inconnus), aucune information n&#8217;est associ&#233;e
&#224; la forme. Ce module suppose que l&#8217;analyse morpho-syntaxique a pr&#233;alablement &#233;t&#233; effec-
tu&#233;e. Dans notre impl&#233;mentation, la lemmatisation est effectu&#233;e en m&#234;me temps que l&#8217;analyse
morpho-syntaxique par le TreeTagger mais quand on utilise un &#233;tiqueteur qui ne fournit pas de
lemmes, comme l&#8217;analyseur de Brill (Brill, 1995), il faut faire appel &#224; un module sp&#233;cifique
pour la lemmatisation.
</p>
<p>&#201;tiquetage terminologique. Ce module vise &#224; rep&#233;rer les expressions du domaine qui ne
sont pas des entit&#233;s nomm&#233;es, comme gene expression ou spore coat cell dans le domaine de la
biologie. L&#8217;analyse peut &#234;tre r&#233;alis&#233;e en projetant les termes fournis en entr&#233;e. Ceux-ci peuvent
&#234;tre issus de ressources terminologiques comme Gene Ontology (GO Consortium, 2001), le
MeSH (MeSH, 1998) ou UMLS (UMLS, 2003) ou d&#8217;une ressource construite &#224; l&#8217;aide d&#8217;un
extracteur de termes. L&#8217;analyse morpho-syntaxique et la lemmatisation du texte sont n&#233;cessaires
pour proc&#233;der &#224; l&#8217;analyse terminologique.
</p>
<p>Analyse syntaxique. L&#8217;analyse syntaxique vise &#224; produire, pour chaque phrase du texte, un
graphe refl&#233;tant les d&#233;pendances entre mots au sein de la phrase. L&#8217;analyse repose sur les sor-
ties de l&#8217;analyse morpho-syntaxique. La plupart des analyseurs n&#8217;exigent pas une analyse ter-
minologique pr&#233;alable mais celle-ci permet de faire d&#233;cro&#238;tre largement l&#8217;ambigu&#239;t&#233; et donc la
complexit&#233; de l&#8217;analyse (Aubin et al., 2005).
</p>
<p>L&#8217;analyse syntaxique demande encore aujourd&#8217;hui des temps de calcul beaucoup plus impor-
tants que les autres &#233;tapes d&#8217;analyse, dans la mesure o&#249; elle op&#232;re sur un espace de recherche
tr&#232;s vaste (tous les mots de la phrase sont potentiellement li&#233;s deux &#224; deux). Nous avons choisi
d&#8217;int&#233;grer le Link Grammar Parser (Sleator &amp; Temperley, 1993), qui repose sur des grammaires
de d&#233;pendance, comme traitement par d&#233;faut. Pour le traitement de textes biom&#233;dicaux, l&#8217;adap-
tation de cet outil au domaine de la biologie BIOLG (Pyysalo et al., 2006) est utilis&#233;e.
</p>
<p>3.4 Impl&#233;mentation
</p>
<p>La plate-forme est impl&#233;ment&#233;e en Perl et est disponible sous forme de modules CPAN (http:
//search.cpan.org/~thhamon/Alvis-NLPPlatform-0.3/). Nous avons utilis&#233;
un mod&#232;le client/serveur, mais la plateforme peut &#233;galement traiter s&#233;quentiellement et de
mani&#232;re autonome une collection de documents. Dans le contexte d&#8217;utilisation client/serveur,
chaque client r&#233;cup&#232;re aupr&#232;s du serveur les documents &#224; traiter les uns apr&#232;s les autres et les
analyse. Les documents annot&#233;s sont ensuite renvoy&#233;s au serveur qui, dans l&#8217;ensemble de la
cha&#238;ne de traitement de recherche d&#8217;information d&#8217;ALVIS, les envoie au moteur d&#8217;indexation.
</p>
<p>4 Analyse des performances
</p>
<p>La plate-forme que nous avons d&#233;velopp&#233;e vise &#224; analyser des textes provenant du web pour des
moteurs sp&#233;cialis&#233;s dans des domaines techniques. Bien qu&#8217;il ne s&#8217;agisse pas d&#8217;analyse en temps
r&#233;el, les performances doivent &#234;tre acceptables. On vise ainsi l&#8217;analyse de plusieurs giga-octets
de donn&#233;es par jour. Ce type de performances implique une architecture distribu&#233;e, qui est par
</p>
<p>109</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Thierry HAMON, Julien DERIVI&#200;RE, Adeline NAZARENKO
</p>
<p>d&#233;finition robuste dans la mesure o&#249; l&#8217;on peut ajouter de nouvelles machines en fonction de la
charge. Au-del&#224; des performances, le syst&#232;me doit &#233;galement &#234;tre robuste face aux documents
fournis en entr&#233;e, qui peuvent &#234;tre tr&#232;s variables quant &#224; leur taille ou leur contenu, notamment
quand il s&#8217;agit de documents issus du web.
</p>
<p>Nous avons men&#233; une exp&#233;rience d&#8217;annotation de deux collections de documents issus du Web.
La premi&#232;re collection regroupe 55 329 documents biom&#233;dicaux (d&#233;sormais BIO). La plupart
des documents XML ont une taille comprise entre 1 kilo-octet et 100 kilo-octets. La taille du
plus grand document est 5,7 m&#233;ga-octets. La seconde collection comporte 48 422 d&#233;p&#234;ches
relatives aux moteurs de recherche (d&#233;sormais SEN). La taille des documents varie entre 1 et
150 kilo-octets.
</p>
<p>Nous nous sommes plac&#233;s dans le contexte d&#8217;annotation d&#8217;un flux de documents venant du
Web. Ainsi, nous avons r&#233;alis&#233; l&#8217;ensemble des traitements jusqu&#8217;&#224; l&#8217;&#233;tiquetage terminologique.
Pour l&#8217;annotation de la collection BIO, nous avons exploit&#233; une liste de 375 000 termes issus du
MeSH et de Gene Ontology, Sur la collection SEN, la liste comportait 17 341 termes extraits
automatiquement. Nous avons utilis&#233; une liste d&#8217;environ 400 000 entit&#233;s nomm&#233;es, incluant des
noms d&#8217;esp&#232;ce et de g&#232;nes sur le corpus BIO, ou des noms de personne, de logiciel et de soci&#233;t&#233;
sur le corpus SEN.
</p>
<p>L&#8217;annotation des documents a &#233;t&#233; distribu&#233;e sur vingt ordinateurs. La plupart sont des ordi-
nateurs classiques (de type PC) avec 1 giga-octet de m&#233;moire vive (RAM) et un processeur
cadenc&#233; &#224; 2,9 ou 3,1 GHz. Nous avons &#233;galement utilis&#233; un ordinateur avec 8 giga-octets de
RAM et deux processeurs Xeon cadenc&#233;s &#224; 2,8 GHz (processeur Xeon dual core). Le syst&#232;me
d&#8217;exploitation utilis&#233; est Linux (Debian ou Mandrake). Le serveur et trois clients &#233;taient h&#233;-
berg&#233;s sur la machine bi-processeur Xeon. Chaque ordinateur personnel abritait un seul client
r&#233;alisant l&#8217;ensemble de la cha&#238;ne de traitement.
</p>
<p>Les performances obtenues donnent une bonne id&#233;e des performances globales de la plate-
forme (une &#233;valuation compl&#232;te aurait demand&#233; des s&#233;ries plus importantes de test). Le temps
d&#8217;ex&#233;cution de chaque module a &#233;t&#233; enregistr&#233; &#224; l&#8217;aide du module Perl Time::Hires. Les
temps d&#8217;analyse sont inscrits dans le fichier XML produit en sortie.
</p>
<p>L&#8217;annotation de la collection, &#224; l&#8217;exception de deux documents, a &#233;t&#233; effectu&#233;e en 35 heures.
Le corpus est compos&#233; de 106 millions de mots et 4,72 millions de phrases. 147 documents ne
contenaient aucun mot, ils n&#8217;ont donc pas &#233;t&#233; analys&#233;s au-del&#224; de l&#8217;&#233;tape de tokenisation. Un
des clients a analys&#233; un document compos&#233; de 414 995 mots.
</p>
<p>Les documents du corpus BIO sont analys&#233;s en moyenne en 35 secondes. La g&#233;n&#233;ration du
fichier XML prend en moyenne 2 secondes suppl&#233;mentaires. Les &#233;tapes les plus co&#251;teuses en
temps de traitement sont celles qui demandent le plus de ressources, &#224; savoir la reconnaissance
des termes (56 % du temps de traitement global) et la reconnaissance des entit&#233;s nomm&#233;es
(16 % du total).
</p>
<p>Lors ces deux exp&#233;riences, l&#8217;ensemble des documents a &#233;t&#233; trait&#233; sans rencontrer de probl&#232;me.
Les performances obtenues montrent que la plate-forme d&#233;velopp&#233;e est robuste, et qu&#8217;elle peut
traiter des grandes masses de textes dans des temps raisonnables. Celles-ci pourraient &#234;tre en-
core am&#233;lior&#233;es par une optimisation du code, et un travail approfondi sur le module d&#8217;&#233;tique-
tage terminologique. Le processus permet une indexation pr&#233;cise de documents sp&#233;cialis&#233;s.
</p>
<p>110</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>OGMIOS : une plate-forme d&#8217;annotation linguistique
</p>
<p>5 Conclusion
</p>
<p>Nous avons pr&#233;sent&#233; une plate-forme, OGMIOS, destin&#233;e &#224; enrichir des documents issus de do-
maines sp&#233;cialis&#233;s avec des annotations linguistiques. Les exp&#233;riences pr&#233;sent&#233;es ont port&#233; sur
des collections de documents issus du web. Nous avons montr&#233; que l&#8217;architecture et les modules
int&#233;gr&#233;s &#224; la plate-forme sont adapt&#233;s au traitement de textes de langue de sp&#233;cialit&#233;. L&#8217;archi-
tecture est en outre suffisamment g&#233;n&#233;rique pour permettre l&#8217;adaptation &#224; d&#8217;autres domaines.
La plate-forme est actuellement utilis&#233;e par d&#8217;autres partenaires du projet ALVIS et notamment
pour l&#8217;annotation de documents issus de biblioth&#232;ques num&#233;riques en biom&#233;decine.
</p>
<p>La strat&#233;gie adopt&#233;e consiste &#224; r&#233;utiliser des modules existants et &#224; les adapter au domaine
vis&#233;. Ceux-ci peuvent bien &#233;videmment &#234;tre remplac&#233;s par d&#8217;autres et les traitements peuvent
&#234;tre encha&#238;n&#233;s de diff&#233;rentes fa&#231;ons en fonction du r&#233;sultat vis&#233;. Les modules int&#233;gr&#233;s sont
pour l&#8217;instant : la reconnaissance des entit&#233;s nomm&#233;es, la segmentation en phrases et en mots,
l&#8217;analyse morpho-syntaxique et la lemmatisation, la reconnaissance des termes et l&#8217;analyse syn-
taxique. Un module de r&#233;solution d&#8217;anaphore ainsi que d&#8217;autres outils terminologiques seront
prochainement int&#233;gr&#233;s.
</p>
<p>Les performances sont le point cl&#233; de ce type d&#8217;application. Nous avons d&#233;crit une impl&#233;men-
tation distribu&#233;e de la plate-forme permettant le traitement de la collection de documents sur
plusieurs machines. Les temps de calcul obtenus sont acceptables pour une t&#226;che de RI.
</p>
<p>Remerciements
</p>
<p>Ce travail a &#233;t&#233; r&#233;alis&#233;, pour l&#8217;essentiel, dans le cadre du projet ALVIS (projet europ&#233;en IST du
6&#232;me programme cadre &#8211; Partenaires : HIIT (Helsinki, Finlande), MIG-INRA (Jouy en Josas,
France), LSIR-EPFL (Lausanne, Suisse), ULUND (Lund, Su&#232;de), DTU (Copenhague, Dane-
mark), LIPN (Paris, France), JSI (Liubliana, Slov&#233;nie), DCSTH (Tsinghua, Chine), IndexData
(Copenhague, Danemark), Exalead (France), ALMA Bioinformatica (Madrid, Espagne)). Les
donn&#233;es et les exemples fournis ont &#233;t&#233; obtenus en interaction avec les partenaires du projet.
La conception de cette plateforme a b&#233;n&#233;fici&#233; d&#8217;une collaboration de plusieurs ann&#233;es avec le
groupe MIG de l&#8217;INRA qui a notamment d&#233;fini le cadre des exp&#233;riences en biologie.
</p>
<p>R&#233;f&#233;rences
</p>
<p>AUBIN S., NAZARENKO A. &amp; N&#201;DELLEC C. (2005). Adapting a general parser to a su-
blanguage. In Proceedings of the International Conference on Recent Advances in Natural
Language Processing (RANLP&#8217;05), p. 89&#8211;93, Borovets, Bulgaria.
</p>
<p>BERROYER J.-F. (2004). Tagen, un analyseur d&quot;entit&#233;s nomm&#233;es : conception, d&#233;veloppement
et &#233;valuation. M&#233;moire de D.E.A. d&#8217;intelligence artificielle, Universit&#233; Paris-Nord.
</p>
<p>BONTCHEVA K., TABLAN V., MAYNARD D. &amp; CUNNINGHAM H. (2004). Evolving GATE
to meet new challenges in language engineering. Natural Language Engineering, 10(3-4),
349&#8211;374.
</p>
<p>BRILL E. (1995). Transformation-based error-driven learning and natural language profes-
sing : A case study in part-of-speech tagging. Computational Linguistics, 21(4), 543&#8211;565.
</p>
<p>111</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Thierry HAMON, Julien DERIVI&#200;RE, Adeline NAZARENKO
</p>
<p>CUNNINGHAM H., BONTCHEVA K., TABLAN V. &amp; WILKS Y. (2000). Software infrastruc-
ture for language resources : a taxonomy of previous work and a requirements analysis. In Pro-
ceedings of the 2nd International Conference on Language Resources and Evaluation (LREC-
2), Athens.
FERRUCCI D. &amp; LALLY A. (2004). UIMA : an architecture approach to unstructured informa-
tion processing in a corporate research environment. Natural Language Engineering, 10(3-4),
327&#8211;348.
GO CONSORTIUM (2001). Creating the Gene Ontology Resource : Design and Implementa-
tion. Genome Res., 11(8), 1425&#8211;1433.
GREFENSTETTE G. &amp; TAPANAINEN P. (1994). What is a word, what is a sentence ? problems
of tokenization. In The 3rd International Conference on Computational Lexicography, p. 79&#8211;
87, Budapest.
GRISHMAN R. (1997). Tipster architecture design document version 2.3. Rapport interne,
DARPA.
MESH (1998). Medical subject headings. Library of Medicine, Bethesda, Maryland, WWW
page http ://www.nlm.nih.gov/mesh/meshhome.html,.
M&#220;LLER H.-M., KENNY E. E. &amp; STERNBERG P. W. (2004). Textpresso : an ontology-
based information retrieval and extraction system for biological literature. PLoS Biology,
2(11), 1984&#8211;1998.
NAZARENKO A., ALPHONSE E., DERIVI&#200;RE J., HAMON T., VAUVERT G. &amp; WEISSENBA-
CHER D. (2006). The ALVIS format for linguistically annotated documents. In Proceedings
of LREC 2006.
POPOV B., KIRYAKOV A., OGNYANOFF D., MANOV D. &amp; KIRILOV A. (2004). Kim &#8211; a
semantic platform for information extraction and retrieval. Natural Language Engineering,
10(3-4), 375&#8211;392.
PYYSALO S., SALAKOSKI T., AUBIN S. &amp; NAZARENKO A. (2006). Lexical adaptation of
link grammar to the biomedical sublanguage : a comparative evaluation of three approaches.
In J. F. SOPHIA ANANIADOU, Ed., Proceedings of the Second International Symposium on
Semantic Mining in Biomedicine (SMBM 2006), p. 60&#8211;67, Jena, Germany.
SCHMID H. (1997). Probabilistic part-of-speech tagging using decision trees. In D. JONES &amp;
H. SOMERS, Eds., New Methods in Language Processing Studies in Computational Linguis-
tics.
SLEATOR D. D. &amp; TEMPERLEY D. (1993). Parsing English with a link grammar. In Third
International Workshop on Parsing Technologies.
TAYLOR M. (2006). Report on metadata frameworks, including concrete representations, for
network nodes and semantic document analyses. ALVIS Deliverable 3.1.
TSURUOKA Y., TATEISHI Y., KIM J.-D., OHTA T., MCNAUGHT J., ANANIADOU S. &amp;
TSUJII J. (2005). Developing a robust part-of-speech tagger for biomedical text. In Procee-
dings of Advances in Informatics - 10th Panhellenic Conference on Informatics, LNCS 3746,
p. 382&#8211;392.
UMLS (2003). UMLS knowledge source. National Library of Medicine.
WIDL&#214;CHER A. &amp; BILHAUT F. (2005). La plate-forme linguastream : un outil d&#8217;exploration
linguistique sur corpus. In Actes de la conf&#233;rence TALN 2005, p. 517&#8211;522, Dourdan, France.
</p>
<p>112</p>

</div></div>
</body></html>