TALN 2007, Toulouse, 5-8 juin 2007

OGMIOS : une plate-forme d’annotation linguistique
de collection de documents issus du Web

Thierry HAMON, Julien DERIVIERE, Adeline NAZARENKO
LIPN — UMR CNRS 7030
99 av. J .B. Clément, F-93430 Villetaneuse, FRANCE
{Thierry . Hamon, Julien . Deriviére , Adeline . Nazarenko}
@lipn . univ—paris 13 . fr

Résumé. L’ un des obj ectifs du proj et ALVIS est d’intégrer des informations linguistiques
dans des moteurs de recherche spécialisés. Dans ce contexte, nous avons concu une plate-forme
d’enrichissement linguistique de documents issus du Web, OGMIOS, exploitant des outils de
TAL existants. Les documents peuvent étre en francais ou en anglais. Cette architecture est
distribuée, aﬁn de répondre aux contraintes liées aux traitements de gros volumes de textes, et
adaptable, pour permettre l’analyse de sous-langages. La plate-forme est développée en Perl
et disponible sous forme de modules CPAN. C’est une structure modulaire dans lequel il est
possible d’intégrer de nouvelles ressources ou de nouveaux outils de TAL. On peut ainsi déﬁnir
des conﬁguration différentes pour différents domaines et types de collections. Cette plateforme
robuste permet d’analyser en masse des données issus du web qui sont par essence trés hé-
térogénes. Nous avons évalué les performances de la plateforme sur plusieurs collections de
documents. En distribuant les traitements sur vingt machines, une collection de 55 329 docu-
ments du domaine de la biologie (106 millions de mots) a été annotée en 35 heures tandis qu’une
collection de 48 422 dépéches relatives aux moteurs de recherche (14 millions de mots) a été
annotée en 3 heures et 15 minutes.

Abstract. In the context of the ALVIS project, which aims at integrating linguistic in-
formation in topic-speciﬁc search engines, we developed an NLP architecture, OGMIOS, to
linguistically annotate large collections of web documents witl1 existing NLP tools. Documents
can be written in French or English. The distributed architecture allows us to take into account
constraints related to the scalability problem of Natural Language Processing and the domain
speciﬁc tuning of the linguistic analysis. The platform is developed in Perl and is available as
CPAN modules. It is a modularized framework where new resources or NLP tools can be in-
tegrated. Then, various conﬁgurations are easy to deﬁne for various domains and collections.
This platform is robust to massively analyse web document collections which are heterogeneous
in essence. We carried out experiments on two different collections of web documents on 20
computers. A 55,329 web documents collection dealing with biology (106 millions of words)
has been annotated in 35 hours, whereas a 48,422 search engine news collection (14 millions of
word) has been annotated in 3 hours and 15 minutes.

Mots-clés 2 plateforme d’ annotation linguistique, passage 51 l’échelle, robustesse.
Keywords: linguistic annotation, NLP platform, process scability, robustess.

103

Thierry HAMON, Julien DERIVIERE, Adeline NAZARENKO

1 Introduction

Si les moteurs de recherche actuels sont sufﬁsants pour répondre aux requétes les plus courantes
sur Intemet, il n’existe pas actuellement d’outils permettant la formulation de requétes s’ ap-
puyant sur des techniques de recherche avancées (ﬁltrage sur le sens, élimination d’ambigu'1'tés,
exclusion des sites marchands, etc.) et spécialisées exploitant des connaissances du domaine.
Par exemple, la plupart des publications dans le domaine de la biologie et de la bio-médecine
sont enregistrées dans de grandes bases de données textuelles, plus ou moins spécialisées (Fly-
base pour l’espéce Drosophilia Menogaster, Medline pour la biologie et la médecine). Ce type
de bases documentaire est aujourd’hui essentiel au travail des scientiﬁques mais ceux-ci sont
confrontés a la masse de textes, sans pouvoir y faire face. Les outils disponibles sont trop géné-
raux, ils renvoient des centaines ou des rnilliers d’ articles pour la moindre requéte. Pour juger
de la pertinence d’ un document dans ce contexte, il faut en analyser le contenu (reconnaissance
des entités, reconnaissance des termes techniques).

Le proj et ALVIS1 vise a développer un moteur de recherche open source incluant des techniques
de recherche avancées et d’ analyse du contenu textuel, notarrunent du point de vue sémantique.
Par rapport aux moteurs de recherche actuels, ALVIS cherche a prendre en compte a la fois
le theme et le contexte de la recherche pour afﬁner l’ analyse de la requéte et du document.
Le projet s’ appuie sur une architecture peer-to-peer. Le systéme est constitué d’un réseau de
« noeuds » assurant l’infrastructure de recherche globale, auxquels sont adjoints des noeuds
spécialisés pour un domaine donné. Les noeuds spécialisés proposent une véritable analyse du
contenu textuel pour arnéliorer l’accés au document. A terme, des taches d’extraction d’infor-
mations structurées et leur fusion avec des informations déja enregistrées au sein de bases de
données devraient pouvoir étre prises en charge par ce type de moteur spécialisé.

L’ accés au contenu sémantique des documents issus du web ou de grandes bases documentaires
nécessite une premiere phase d’ enrichissement linguistique des documents en un temps sufﬁ-
sarmnent court. ll s’ agit ici de réduire le goulet d’étranglement que constituent généralement
les outils de TAL lorsqu’ils sont intégrés dans des applications de recherche d’information.
L’ architecture logicielle que nous avons développé permet de satisfaire cette contrainte. Cette
plate-forme, OGMIOS, est a la fois générique et spécialisable. Elle est concue pour analyser de
maniére robuste des collections de taille variées et hétérogénes du point de vue de la langue
(pour l’instant le francais et l’anglais2), de la longueur et du type de leurs documents . Elle peut
aussi étre spécialisée pour un domaine particulier. Dans le cadre du projet ALVIS, les expé-
riences ont porté en priorité sur le domaine de la biologie, mais nous avons également pu tester
la plate-forme sur un corpus de dépéches relatives aux moteurs de recherche.

Cet article présente notre approche perrnettant de répondre aux contraintes de performances,
de généricité et d’adaptabilité a un domaine de spécialité, qu’impose l’utilisation du TAL dans
une application de recherche d’information (RI) spécialisée. Dans la section 2, nous donnons un
apercu de l’état de l’art des plates-formes d’ annotation de documents. La plate-forme est décrite
dans la section 3 avec les modules de traitement qu’elle intégre. L’ évaluation des performances
de la plateforme est présentée a la section 4.

1ALVIS Superpeer semantic Search Engine, projet IST / STREP n" 002068, voir ht tp : / /www . alvi s .
i n f o / alvi s .

2Des versions slovene et chinoise ont également été développées dans le cadre du projet mais avec une ambition
moindre pour le slovene et avec une architecture un peu différente pour le chinois.

104

OGMIOS 2 une plate-forrne d’ armotation linguistique

2 Etat de l’art

Lors de cette demiere decennie, plusieurs architectures d’ingenierie du texte ont ete developpees
pour articuler les traitements linguistiques (Cunningham et al., 2000) sans toutefois se placer
dans un contexte de recherche d’information. Ainsi, les architectures GATE (Bontcheva et al.,
2004), UllVIA (Ferrucci & Lally, 2004) ou de Textpresso (Muller et al., 2004) visent genera-
lement l’armotation linguistique et 1’ exploration de corpus de taille moyenne pour l’ extraction
d’inforrr1ation. LirrguaStrearn (Wid1ocher & Bilhaut, 2005), quant a elle, est concue comme un
outil de depouillement de corpus et d’ experimentation, qui formalise des traitements complexes.

Ces plates-formes appuient leur analyse des documents sur des outils de Traitement Automa-
tique des Langues existants. Ceux-ci sont reutilises dans des modules qui les encapsulent et qui
assurent la conforrnite des entrees/sorties. La deﬁnition d’un format d’ echange et d’ annotation
sufﬁsanrrnent generique est egalement un point crucial pour les plates-formes d’ annotation. ll
s’agit d’ assurer une communication correcte des informations entre les modules, mais aussi une
reutilisation des annotations produites dans des applications extemes. Ont ainsi ete proposes dif-
ferents formats d’ echange et d’ annotation qui reposaient generalement sur SGML puis XML.
Le format d’ echange et d’ annotation de GATE, CPSL (Common Pattern Speciﬁc Language) et
d’UlMA, CAS (Common Analysis Structure) sont inspires du format d’ annotation TIPSTER
(Grishman, 1997). Aﬁn de preserver une certaine ﬂexibilite, les annotations y sont deportees.

Au regard de nos contraintes (genericite, performances et adaptabilite a un domaine de specia-
lite), les plates-formes d’armotation existantes ne paraissent pas adaptees a la recherche d’in-
formation specialisee. Si les plates-formes GATE et UIMA sont plut6t concues comme des
solutions generiques, le systeme Textpresso (Muller et al., 2004) poursuit un objectif similaire
au notre 2 proposer une architecture generique capable de traiter des corpus de documents issus
d’un domaine specialise. Cette plate-forrne a ete concue pour la fouille des documents traitant
de biologie, aussi bien des resumes que des articles complets. Son evaluation a porte sur un
corpus relativement petit 2 16 000 resumes et 3 000 articles en texte brut.

En regle generale, on dispose de tres peu d’informations pour d’ evaluer les perfonnances de ces
systemes sur un corpus de documents. Un premier test nous a montre que GATE ne convient pas
au traitement de gros corpus de documents 2 seuls de petits volumes de documents pouvaient
etre traites sans rencontrer des problemes. Ceci s’ explique par le fait que GATE ait ete concue
comme un environnement puissant de developpement et de conception d’ applications de TAL
dans le cadre de l’extraction d’irrforrr1ation. Le passage a1’eche11e n’etait pas un objectif cen-
tral. La méta-plate-forme KIM (Popov et al., 2004), qui s’appuie sur GATE, tente cependant
de satisfaire cette contrainte dans le cadre de projets d’armotation semantique massive SWAN 3
et SEKT4. L’ architecture est dediee a l’enrichissement d’ ontologies, l’indexation semantique et
la recherche d’inforrr1ation. Bien que les auteurs identiﬁent le passage 51 l’echelle comme un
parametre critique, aucune performance en terrne de temps de calcul et de volume de docu-
ments traites, n’ est fournie. Le traitement de grande collections de documents est cependant,
envisageable avec UIMA, les temps de calcul et l’adaptabilite des traitements restant a evaluer.
Celle-ci offre en effet la possibilite de traiter les documents les uns apres les autres ou sous
forme d’une collection. Le Collection Processing Engine (CPE) gere alors la parallelisation et
surveille les performances.

3http 2 //deri . ie/projects/swan
4http ://sekt . semanticweb . org

105

Thierry HAMON, Julien DERIVIERE, Adeline NAZARENKO

Les plates-formes existantes répondent donc partiellement aux contraintes de l’intégration d’ in-
formations linguistiques dans un moteur de recherche spécialisé. ll s’agit généralement plus
d’environnements de dépouillement que d’ architectures d’annotation de gros volumes de don-
nées pouvant étre utilisées pour la recherche d’information spécialisée. Nous avons donc déve-
loppé une plate-forme capable de gérer d’importants volumes de documents en mettant l’ accent
sur l’efﬁcacité et la robustesse des traitements effectués.

3 Une plate-forme modulaire et adaptable

Nous avons choisi de développer une plate-forme d’armotation linguistique exploitant des outils
de TAL existants plutot que d’ en développer de nouveaux5. Nous avons ainsi pu mettre l’accent
sur la robustesse des traitements et la rapidité de l’annotation de grandes quantités de documents
spécialisés, en proposant une architecture modulaire et distribuée. De plus, l’adaptation des trai-
tements nécessaires a l’analyse de textes spécialisés est réalisée par l’intégration de ressources
spéciﬁques au domaine ou l’utilisation d’outils spécialisés pour un domaine.

3.1 Contraintes spéciﬁques

Le fait de réutiliser des outils existants et d’autoriser le remplacement de certains outils par
d’autres imposent des contraintes spéciﬁques. Il faut notamment gérer Phétérogénéité des for-
mats d’entrées/sorties des outils utilisés dans la plate-forme. Chaque outil ayant généralement
ses formats propres, il est donc crucial de déﬁnir un format d’échange permettant d’intercon-
necter librement des outils ensemble et de distribuer correctement les traitements.

Le développement d’une plate-forme d’armotation des textes spécialisés intégre également des
contraintes spéciﬁques au TAL, comme la disponibilité de ressources lexicales, terminologiques
et ontologiques, ou la nécessité d’ adapter des outils au domaine aﬁn d’améliorer certains traite-
ments, comme l’étiquetage morpho-symtaxique ou l’ analyse symtaxique, sur des sous-langages
particuliers. De plus, toutes les étapes de traitement n’étant pas également pertinentes pour
toutes les applications, nous avons préservé au maximum l’approche modulaire.

3.2 Architecture générale

Les différentes étapes de traitement sont traditionnellement prises en charge par un ensemble de
modules (Bontcheva et al., 2004). Chaque module est dédié a un type de traitement 2 reconnais-
sance d’entités nommées, segmentation en mots, étiquetage morpho-syntaxique, analyse syn-
taxique, etc. Un module encapsule l’outil effectuant une analyse linguistique donnée et assure
la conformité du format des entrées/sorties avec la déﬁnition de type de documents (dorénavant
DTD). Les armotations sont enregistrées dans un format XML déporté aﬁn de pouvoir mieux
gérer l’hétérogénéité des entrées/sorties des outils de TAL. La DTD est décrite dans (Taylor,
2006; Nazarenko et al., 2006). La modularité de 1’ architecture facilite la substitution d’un outil
par un autre, car le remplacement d’un outil n’a aucun impact sur l’ensemble de l’architecture.

5Nous avons toutefois développé des outils lorsqu‘aucun outil répondant 5 nos besoin n‘était disponible ou
nous convenait. Nous avons, de plus, choisi de préférence des logiciels sous licence GPL ou libre/gratuit pour un
usage non commercial.

106

OGMIOS 2 une plate-forme d’ armotation linguistique

La specialisation de la plate-forme pour un domaine spéciﬁque est assurée par les ressources de
chacun des modules. Par exemple, une liste d’ especes ou de genes peut étre ajoutée au module
de repérage d’entités nommées spéciﬁques a la biologie, aﬁn de traiter des résumés de Medline.
L’ adaptabilité des traitements peut aussi se faire par l’intégration d’ outils spécialisés.

La ﬁgure 1 présente l’architecture de la plate-forme dans son état actuel. D’autres modules tels
que l’étiquetage sémantique et la résolution d’anaphores seront prochainement intégrés. Les
bo’1‘tes représentent les différents modules composant la cha’1‘ne de traitements linguistiques. Ces
modules sont décrits dans la section 3.3. Les ﬂeches en traits pleins représentent le ﬂux de
données lors du traitement tandis que les ﬂeches en pointillés représentent les ressources qui
peuvent étre utilisées dans la plate-forme.

Tokenisation 1 r Reconnaissance ‘ ’ ressmrce
d’entités nommées (“ms “°m&s)
Segmentation en mots
Segmentation en phrases

  
 

 
 

Iessounce
(diam _ ) rasource

(terminologie)

‘ Etiquetage terminologique

l

E‘ """ ">‘ Analyse syntaxique  $2:

ressource
(régls d'amalyse)

FIG. 1 — Architecture de la cha’1‘ne de traitement

/-\ ;

Nous partons du principe que les documents Web donnés en entrée ont de_]a eté téléchargés, net-
toyés, codés en UTF-8 et convertis au format XML (Taylor, 2006). Les documents sont d’ abord
tokenisés, ce qui permet de déﬁnir des offsets (indices délimitant une séquence, en nombre de
caracteres par rapport au début du document) pour garantir l’homogénéité des différentes armo-
tations. Les tokens seront utilisés par les modules suivants. Les documents sont ensuite traités
par divers modules 2 repérage d’ entités nommées, segmentation en mots et en phrases, lemma-
tisation, étiquetage morpho-symtaxique, étiquetage terminologique et analyse symtaxique.

Cette architecture est assez traditionnelle mais certains points méritent d’ étre soulignés 2

— La tokenisation constitue la premiere étape de la cha’1‘ne. Elle procede a une premiere segmen-
tation, non linguistique, utilisée par la suite par les autres outils. Le token est donc l’unité tex-
tuelle de base dans la cha’1‘ne de traitements, et n’est qu’un point de depart pour les autres an-
notations. Ce niveau d’ annotation suit les recomrnandations du groupe TC37SC4/TEI, meme
si nous employons le tenne d’ oﬁset de caractére plutot que celui de pointeur d’élément pour
désigner les frontieres de chaque token. Pour simpliﬁer les traitements suivants, nous distin-
guons quatre types de tokens 2 alphabétiques, nurnériques, séparateurs et symboliques.

107

Thierry HAMON, Julien DERIVIERE, Adeline NAZARENKO

— L’ étiquetage des entités nommées se produit trés tot dans la chaine de traitement car l’identi-
ﬁcation des entités nommées facilite la désambigu'1'sation d’un certain nombre de marques de
ponctuation lors de la segmentation en mots ou en phrases.

— L’ étiquetage terrninologique est utilisé tel quel mais peut également étre considéré comme
un préalable a l’analyse syntaxique. Cette derniére demandant beaucoup de temps de cal-
cul, nous exploitons le fait qu’une analyse terrninologique réduit le nombre d’analyses syn-
taxiques possibles (Aubin et al., 2005).

3.3 Description des modules disponibles

Les modules sont appelés de maniére séquentielle pour chaque document. Les sorties (annota-
tions) sont stockées en mémoire jusqu’a la ﬁn du traitement du document en cours, puis ente-
gistrées dans un format XML.

Cette section décrit les différents modules intégrés a l’heure actuelle au sein de la cha’1‘ne de
traitement. Il s’agit d’une description des modules par défaut de la plate-forme pour le traite-
ment de l’anglais. Des outils similaires sont également intégrés pour le francais (a l’ exception
de l’ analyse syntaxique). De plus, la conception et l’implémentation de la plate-forme permet
aisément une substitution d’un outil par un autre.

Etiquetage d’entités nommées. Le module assurant la reconnaissance des entités nommées
identiﬁe les séquences textuelles qui renvoient a une entité, leur associe un type sémantique
(dépendant du domaine — pour la biologie, les étiquettes gene et species, par exemple) et,
le cas échéant, normalise cette séquence. Dans la suite des traitements, une entité nommée est
considérée comme une seule unité et assimilée a un mot. En les reconnaissant a un stade trés
préliminaire dans l’analyse, on évite des arnbigu'1'tés ultérieures. Le module encapsule TagEN
(Berroyer, 2004), qui repose essentiellement sur des dictionnaires et l’application de regles
décrites sous formes de transducteurs.

Segmentation en mots et en phrases. Ce module identiﬁe les phrases et les mots. I1 exploite
un ensemble d’ expressions réguliéres reprenant l’algor'ithme proposé dans (Grefenstette & Ta-
panainen, 1994). Une partie de la segmentation est effectuée par le module de reconnaissance
des entités nommées dans la mesure ou celui-ci résout un grand nombre des problémes liés a
la ponctuation. C’est par exemple le module traitant les entités nommées qui permet de recon-
na1"tre la séquence « B. subtilis » , et qui met en rapport l’abréviation « B. » avec la forme
étendue « Bacillus » . Le point présent dans la séquence « B. subtilis » n’a plus a étre pris en
compte au niveau de la segmentation en phrases.

Eﬁquetage morpho-syntaxique. Ce module associe une étiquette morpho-symtaxique a
chaque mot du texte. Il repose sur la segmentation effectuée a l’étape précédente. Nous uti-
lisons a l’heure actuelle le TreeTagger (Sch1nid, 1997). Nous avons aussi testé l’intégration de
l’étiqueteur GeniaTagger (T suruoka et al., 2005) qui est spécialisé pour le biologie, méme si on
observe que le gain en qualité de l’étiquetage se fait au détriment des performances.

108

OGMIOS 2 une plate-forme d’a1motation linguistique

Lemmatisation. Ce module associe un lemme a chaque mot du texte. Si le mot ne peut pas
étre lemmatisé (nombres, mots étrangers, mots inconnus), aucune information n’est associée
a la forme. Ce module suppose que 1’ analyse morpho-symtaxique a préalablement été effec-
tuée. Dans notre implementation, la lenunatisation est effectuée en meme temps que l’analyse
morpho-symtaxique par le TreeTagger mais quand on utilise un étiqueteur qui ne foumit pas de
lemmes, comme l’analyseur de Brill (Brill, 1995), i1 faut faire appel a un module spéciﬁque
pour la lennnatisation.

Etiquetage terminologique. Ce module vise a repérer les expressions du domaine qui ne
sont pas des entités nommées, comme gene expression ou spore coat cell dans le domaine de la
biologie. L’ analyse peut étre réalisée en projetant les termes foumis en entrée. Ceux-ci peuvent
étre issus de ressources terminologiques comme Gene Ontology (GO Consortium, 2001), le
MeSH (MeSH, 1998) ou UMLS (UMLS, 2003) ou d’une ressource construite a l’ aide d’un
extracteur de termes. L’ analyse morpho-syntaxique et la lemmatisation du texte sont nécessaires
pour procéder a l’analyse terminologique.

Analyse syntaxique. L’analyse syntaxique vise a produire, pour chaque phrase du texte, un
graphe reﬂétant les dépendances entre mots au sein de la phrase. L’analyse repose sur les sor-
ties de l’analyse morpho-syntaxique. La plupart des analyseurs n’exigent pas une analyse ter-
minologique préalable mais celle-ci pennet de faire décroitre largement l’ambigu'1'té et donc la
complexité de l’analyse (Aubin et al., 2005).

L’ analyse syntaxique demande encore aujourd’hui des temps de calcul beaucoup plus impor-
tants que les autres étapes d’analyse, dans la mesure ou elle opere sur un espace de recherche
tres vaste (tous les mots de la phrase sont potentiellement liés deux a deux). Nous avons choisi
d’intégrer le Link Grarmnar Parser (Sleator & Temperley, 1993), qui repose sur des grarmnaires
de dépendance, comme traitement par défaut. Pour le traitement de textes biomédicaux, l’adap-
tation de cet outil au domaine de la biologie BIOLG (Pyysalo et al., 2006) est utilisée.

3.4 Implémentation

La plate-forme est implémentée en Perl et est disponible sous forme de modules CPAN (http :
/ /search. cpan . org/~thhamon/Alvis—NLPPlatform— 0 . 3/). Nous avons utilisé
un modele client/serveur, mais la plateforme peut également traiter séquentiellement et de
maniere autonome une collection de documents. Dans le contexte d’utilisation client/serveur,
chaque client récupere aupres du serveur les documents a traiter les uns apres les autres et les
analyse. Les documents annotés sont ensuite renvoyés au serveur qui, dans l’ensemble de la
cha’1‘ne de traitement de recherche d’information d’ALVIS, les envoie au moteur d’indexation.

4 Analyse des performances

La plate-forme que nous avons développée vise a analyser des textes provenant du web pour des
moteurs spécialisés dans des domaines techniques. Bien qu’il ne s’agisse pas d’ analyse en temps
réel, les performances doivent étre acceptables. On vise ainsi l’ analyse de plusieurs giga-octets
de données par jour. Ce type de performances implique une architecture disttibuée, qui est par

109

Thierry HAMON, Julien DERIVIERE, Adeline NAZARENKO

déﬁrrition robuste dans la mesure oil 1’ on peut ajouter de nouvelles machines en fonction de la
charge. Au-dela des performances, le systeme doit également étre robuste face aux documents
foumis en entrée, qui peuvent étre tres variables quant a leur taille ou leur contenu, notarrrrnent
quand il s’agit de documents issus du web.

Nous avons mené une expérience d’ annotation de deux collections de documents issus du Web.
La prerrriere collection regroupe 55 329 documents biomédicaux (désormais BIO). La plupart
des documents XML ont une taille comprise entre 1 kilo-octet et 100 kilo-octets. La taille du
plus grand document est 5,7 méga-octets. La seconde collection comporte 48 422 dépéches
relatives aux moteurs de recherche (désorrrrais SEN). La taille des documents varie entre 1 et
150 kilo-octets.

Nous nous sommes placés dans le contexte d’annotation d’un ﬂux de documents venant du
Web. Ainsi, nous avons réalisé l’ensemble des traitements jusqu’a l’étiquetage terminologique.
Pour l’annotation de la collection BIO, nous avons exploité une liste de 375 000 termes issus du
MeSH et de Gene Ontology, Sur la collection SEN, la liste comportait 17 341 termes extraits
automatiquement. Nous avons utilisé une liste d’ environ 400 000 entités nommées, incluant des
noms d’espece et de genes sur le corpus BIO, ou des noms de personne, de logiciel et de société
sur le corpus SEN.

L’a1motation des documents a été distribuée sur vingt ordinateurs. La plupart sont des ordi-
nateurs classiques (de type PC) avec 1 giga-octet de mémoire vive (RAM) et un processeur
cadencé a 2,9 ou 3,1 GHz. Nous avons également utilisé un ordinateur avec 8 giga-octets de
RAM et deux processeurs Xeon cadencés a 2,8 GHz (processeur Xeon dual core). Le systeme
d’exploitation utilisé est Linux (Debian ou Mandrake). Le serveur et trois clients étaient hé-
bergés sur la machine bi-processeur Xeon. Chaque ordinateur personnel abritait un seul client
réalisant l’ensemble de la cha’1‘ne de traitement.

Les performances obtenues donnent une bonne idée des performances globales de la plate-
forme (une évaluation complete aurait demandé des séries plus importantes de test). Le temps
d’exécution de chaque module a été enregistré a l’aide du module Perl Time: :Hires. Les
temps d’ analyse sont inscrits dans le ﬁchier XML produit en sortie.

L’a1motation de la collection, a 1’ exception de deux documents, a été effectuée en 35 heures.
Le corpus est composé de 106 millions de mots et 4,72 millions de phrases. 147 documents ne
contenaient aucun mot, ils r1’ ont donc pas été analysés au-dela de 1’ étape de tokenisation. Un
des clients a analysé un document composé de 414 995 mots.

Les documents du corpus BIO sont analysés en moyenne en 35 secondes. La génération du
ﬁchier XML prend en moyenne 2 secondes supplémentaires. Les étapes les plus coﬁteuses en
temps de traitement sont celles qui demandent le plus de ressources, a savoir la reconnaissance
des termes (56 % du temps de traitement global) et la reconnaissance des entités nommées
(16 % du total).

Lors ces deux expériences, l’ensemble des documents a été traité sans rencontrer de probleme.
Les performances obtenues montrent que la plate-forrne développée est robuste, et qu’elle peut
traiter des grandes masses de textes dans des temps raisonnables. Celles-ci pourraient étre en-
core améliorées par une optimisation du code, et un travail approfondi sur le module d’étique-
tage terminologique. Le processus permet une indexation précise de documents spécialisés.

110

OGMIOS 2 une plate-forme d’ armotation linguistique

5 Conclusion

Nous avons presente une plate-forme, OGMIOS, destinee a enrichir des documents issus de do-
maines specialises avec des annotations linguistiques. Les experiences presentees ont porte sur
des collections de documents issus du web. Nous avons montre que l’architecture et les modules
integres a la plate-forme sont adaptes au traitement de textes de langue de specialite. L’ arcin-
tecture est en outre sufﬁsamment generique pour permettre 1’ adaptation a d’ autres domaines.
La plate-forme est actuellement utilisee par d’autres partenaires du proj et ALVIS et notarrunent
pour l’annotation de documents issus de bibliotheques nurneriques en biomedecine.

La strategie adoptee consiste a reutiliser des modules existants et a les adapter au domaine
vise. Ceux-ci peuvent bien evidemment etre remplaces par d’ autres et les traitements peuvent
etre enchaines de differentes facons en fonction du resultat vise. Les modules integres sont
pour l’instant 2 la reconnaissance des entites nommees, la segmentation en phrases et en mots,
l’analyse morpho-symtaxique et la lemmatisation, la reconnaissance des termes et l’analyse syn-
taxique. Un module de resolution d’ anaphore ainsi que d’ autres outils terminologiques seront
prochainement integres.

Les performances sont le point cle de ce type d’ application. Nous avons decrit une implemen-
tation distribuee de la plate-forme permettant le traitement de la collection de documents sur
plusieurs machines. Les temps de calcul obtenus sont acceptables pour une tache de RI.

Remerciements

Ce travail a ete realise, pour l’essentiel, dans le cadre du projet ALVIS (projet europeen IST du
6eme programme cadre - Partenaires 2 I-IIIT (Helsinki, Finlande), MIG-INRA (J ouy en Josas,
France), LSIR-EPFL (Lausanne, Suisse), ULUND (Lund, Suede), DTU (Copenhague, Dane-
mark), LIPN (Paris, France), J SI (Liubliana, Slovenie), DCSTH (Tsinghua, Chine), IndexData
(Copenhague, Danemark), Exalead (France), ALMA Bioinformatica (Madrid, Espagne)). Les
donnees et les exemples fournis ont ete obtenus en interaction avec les partenaires du projet.
La conception de cette plateforme a beneﬁcie d’une collaboration de plusieurs annees avec le
groupe MIG de l’lNRA qui a notarmnent deﬁni le cadre des experiences en biologie.

Références

AUBIN S., NAZARENKO A. & NEDELLEC C. (2005). Adapting a general parser to a su-
blanguage. In Proceedings of the International Conference on Recent Advances in Natural
Language Processing (RANLP’05), p. 89-93, Borovets, Bulgaria.

BERROYER J .-F. (2004). Tagen, un analyseur d"entites r1ommees 2 conception, developpement
et evaluation. Memoire de D.E.A. d’intelligence artiﬁcielle,Ur1iversite Paris-Nord.

BONTCHEVA K., TABLAN V., MAYNARD D. & CUNNINGHAM H. (2004). Evolving GATE
to meet new challenges in language engineering. Natural Language Engineering, 10(3-4),
349-374.

BRILL E. (1995). Transformation-based error-driven learning and natural language profes-
sing 2 A case study in part-of-speech tagging. Computational Linguistics, 21(4), 543-565.

111

Thierry HAMON, Julien DERIVIERE, Adeline NAZARENKO

CUNNINGHAM H., BONTCHEVA K., TABLAN V. & WILKS Y. (2000). Software infrastruc-
ture for language resources 2 a taxonomy of previous work and a requirements analysis. In Pro-
ceedings of the 2nd International Conference on Language Resources and Evaluation (LRE C-
2), Athens.

FERRUCCI D. & LALLY A. (2004). UIIVIA 2 an architecture approach to unstructured informa-
tion processing in a corporate research environment. Natural Language Engineering, 10(3-4),
327-348.

GO CONSORTIUM (2001). Creating the Gene Ontology Resource 2 Design and Implementa-
tion. Genome Res., 11(8), 1425-1433.

GREFENSTETTE G. & TAPANAINEN P. (1994). What is a word, what is a sentence ? problems
of tokenization. In The 3rd International Conference on Computational Lexicography, p. 79-
87, Budapest.

GRISHMAN R. (1997). Tipster architecture design document version 2.3. Rapport inteme,
DARPA.

MESH (1998). Medical subject headings. Library of Medicine, Bethesda, Maryland, WWW
page http :/ /www . nlm . nih . gov/mesh/meshhome . html,.

MULLER H.-M., KENNY E. E. & STERNBERG P. W. (2004). Textpresso 2 an ontology-
based information retrieval and extraction system for biological literature. PLoS Biology,
2(11), 1984-1998.

NAZARENKO A., ALPHONSE E., DERIVIERE J ., HAMON T., VAUVERT G. & WEISSENBA-
CHER D. (2006). The ALVIS format for linguistically annotated documents. In Proceedings
of LREC 2006.

POPOV B., KIRYAKOV A., OGNYANOFF D., MANOV D. & KIRILOV A. (2004). Kim - a
semantic platform for information extraction and retrieval. Natural Language Engineering,
10(3-4), 375-392.

PYYSALO S., SALAKOSKI T., AUBIN S. & NAZARENKO A. (2006). Lexical adaptation of
link grammar to the biomedical sublarrguage 2 a comparative evaluation of three approaches.
In J. F. SOPHIA ANANIADOU, Ed., Proceedings of the Second International Symposium on
Semantic Mining in Biomedicine (SMBM 2006), p. 60-67, Jena, Germany.

SCHMID H. (1997). Probabilistic part-of-speech tagging using decision trees. In D. JONES &
H. SOMERS, Eds., New Methods in Language Processing Studies in Computational Linguis-
tics.

SLEATOR D. D. & TEMPERLEY D. (1993). Parsing English with a link grarmnar. In Third
International Workshop on Parsing Technologies.

TAYLOR M. (2006). Report on metadata frameworks, including concrete representations, for
network nodes and semantic document analyses. ALVIS Deliverable 3.1.

TSURUOKA Y., TATEISHI Y., KIM J .-D., OHTA T., MCNAUGHT J., ANANIADOU S. &
TSUJII J . (2005). Developing a robust part-of-speech tagger for biomedical text. In Procee-
dings of Advances in Informatics - I 0th Panhellenic Conference on Informatics, LNCS 3746,
p. 382-392.

UMLS (2003). UMLS knowledge source. National Library of Medicine.

WIDLOCHER A. & BILHAUT F. (2005). La plate-forme linguastream 2 un outil d’exploration
linguistique sur corpus. In Actes de la confe’rence TALN 2005, p. 517-522, Dourdan, France.

112

