TALN 2007, Toulouse, 5—8ju1'n 2007

Modéles statistiques enrichis par la syntaxe pour la
traduction automatique

Holger SCHWENK, Daniel DECHELOTTE
Hélene BONNEAU—l\/IAYNARD, Alexandre ALLAUZEN
LIMSLCNRS, B.P. 133, 91403 Orsay cedex
{schwenk , dechelot , hbm, a11auzen}@1imsi . fr

Résumé. La traduction automatique statistique par séquences de mots est une
voie prometteuse. Nous présentons dans cet article deux évolutions complémentaires. La
premiere permet une modélisation de la langue cible dans un espace continu. La seconde
integre des catégories morpho-syntaxiques aux unités manipulées par le modele de tra-
duction. Ces deux approches sont évaluées sur la tache TC-STAR. Les résultats les plus
intéressants sont obtenus par la combinaison de ces deux méthodes.

Abstract. Statistical phrase-based translation models are very eﬁlcient. In this
paper, we present two complementary methods. The ﬁrst one consists in a a statistical
language model that is based on a continuous representation of the words in the vocabu-
lary. By these means we expect to take better advantage of the limited amount of training
data. In the second method, morpho-syntactic information is incorporated into the trans-
lation model in order to obtain lexical disambiguation. Both approaches are evaluated on
the TC-STAR task. Most promising results are obtained by combining both methods.

Mots-clés 2 traduction automatique, approche statistique, modélisation linguis-
tique dans un espace continu, analyse morpho-syntaxique, désambigu‘1‘sation lexicale.

Keywords: statistical machine translation, continuous space language model,
POS tagging, lexical disambiguation.

1 Introduction

La traduction automatique est un theme de recherche depuis plusieurs décennies et dif-
férentes approches ont été proposées, telles que la traduction par regles, la traduction a
base d’exemples ou la traduction statistique. Les travaux récents en traduction statistique
conﬁrment que les modeles fondés sur des séquences de mots (Och et al., 1999; Koehn
et al., 2003) obtiennent des performances signiﬁcativement meilleures que ceux fondés
sur des mots (Brown et al., 1993). En utilisant des séquences de mots, les systemes de
traduction parviennent a préserver certaines contraintes locales sur l’ordre des mots. L’en-
trainement d’un tel modele nécessite l’alignement d’un corpus parallele. Les régularités
du langage naturel comme celles de la syntaxe, ou, encore a un niveau supérieur, celles de
la sémantique sont ainsi, en principe, implicitement capturées par les modeles.

253

H. SCHWENK, D. DFJCHELOTTE, H. BONNEAU-MAYNARD, A. ALLAUZEN

Depuis les débuts de l’approche statistique en traduction automatique, les efforts de mo-
délisation se sont principalement concentrés sur les modeles de traduction et d’alignement,
comme en témoignent les nombreuses publications sur ces sujets. Dans cet article, nous
explorons deux pistes complémentaires pour l’amélioration des modeles de traduction
statistique : d’une part, l’exploration d’une modélisation statistique du langage dans un
espace continu, et d’autre part l’intégration d’informations syntaxiques dans le modele de
traduction.

Traditionnellement, les systemes de traduction statistiques utilisent des modeles de lan-
gage trigramme a repli. Dans ces modeles classiques, les mots sont représentés par un
indice dans un espace discret, le vocabulaire. Ceci ne permet pas de faire de véritables
interpolations des probabilités d’un 71,-gramme non observé puisqu’un changement dans
l’espace des mots peut entrainer un changement arbitraire de la probabilité. Nous propo-
sons ici d’appréhender dans un domaine continu le probleme de l’estimation d’un modele
linguistique. L’idée consiste a pro jeter les indices des mots dans une représentation conti-
nue (un espace vectoriel) et d’estimer les probabilités dans cet espace (Bengio et al., 2003).
Actuellement, un réseau de neurones multi-couches completement connecté est utilisé pour
apprendre conjointement la projection des mots sur un espace continu et l’estimation des
probabilités n-grammes.

La lecture humaine des sorties d’un systeme statistique de traduction, meme basé sur
des séquences de mots, nécessite parfois un diﬁlcile exercice de réordonnancement et de
restructuration syntaxique pour restituer le sens de l’énoncé d’origine. La modélisation
du langage comme une source markovienne (modele de langage 11,-gramme), avec comme
unité le mot ou la séquence de mots, ne permet pas de prendre en compte les contraintes
syntaxiques ou les dépendances a long terme entre les mots. Il apparait donc néces-
saire d’utiliser des méthodes dans lesquelles les propriétés structurelles des langues sont
explicitement représentées. Plusieurs tentatives sur l’utilisation d’informations morpho-
syntaxiques dans la traduction statistique ont déja été menées. (Och et al., 2004) ont
exploré de nombreuses fonctions caractéristiques, dont certaines d’ordre syntaxique. La
réévaluation des 11 meilleures hypotheses avec des étiquettes morpho-syntaxiques a égale-
ment été étudiée par (Hasan et al., 2006). Dans (Kirchhoff & Yang, 2005), un modele de
langage factorisé quadrigramme utilisant des informations syntaxiques n’a pas montré des
performances meilleures qu’un modele n-gramme de mots. Les modeles de langage fondés
sur la syntaxe ont enﬁn été explorés par (Charniak et al., 2003). Tous ces travaux ont en
commun d’utiliser des séquences de mots comme unités du systeme de traduction et de
n’introduire les catégories morpho-syntaxiques que dans une seconde passe de traitement.

Dans ce travail, nous proposons d’intégrer les informations syntaxiques dans le modele
de traduction lui-meme. De plus, nous proposons de combiner cette approche avec les
méthodes classiques de réévaluation de listes de 11 meilleures hypotheses. A notre connais-
sance, cette approche n’a pas été évaluée sur une large tache (elle a été appliquée par
(Hwang et al., 2007) a la tache BTEC (Basic Travel Expression Corpus) beaucoup plus
réduite). Nous présentons ici des résultats sur la tache TC-STAR (traduction des trans-
criptions des sessions plénieres du Parlement européen).

Cet article est organisé comme suit. Dans la section suivante, nous présentons d’abord la
structure du systeme de traduction automatique et ses différentes extensions. Les résultats
expérimentaux sont résumés et discutés dans la section 3. La derniere section conclue cet
article et suggere des extensions et travaux futurs.

254

Modeles statistiques enrichis par la syntaxe pour la traduction automatique

2 Description du systéme

L’objectif d’un systeme de traduction automatique est de proposer pour une phrase f en
langue << source >> sa traduction en une phrase e dans la langue << cible ». L’approche
statistique consiste a choisir, parmi les phrases possibles, la plus probable. Le probleme
se décompose de la maniere suivante :

e* = argmeaxPr(e|f) = argmeaxPr(f|e) Pr(e),

ou la probabilité Pr(f|e) est estimée par le modele de traduction et Pr(e) par le mo-
dele de langage de la langue cible. Cette équation résume l’approche source/canal his-
torique (Brown et al., 1993) qui considere le mot comme unité et la phrase comme une
séquence de mots. Le modele de traduction peut etre estimé automatiquement a partir de
textes paralleles alignés au niveau de la phrase. Ce calcul est effectué par le logiciel libre
GIZA-l-+.

Ces dernieres années, les travaux en traduction statistique ont étendu avec succes l’unité
qu’était le mot a la séquence de mots (Och et al., 1999; Koehn et al., 2003). Cette nouvelle
unité se déﬁnit alors comme un groupe de mots successifs i' de la langue source. Sa
traduction est également une séquence de mots é dans la phrase cible. Les séquences
de mots peuvent etre extraites automatiquement a partir de données bilingues alignées
au niveau du mot dans les deux sens. L’utilisation du principe du maximum d’entropie
permet de décomposer le probleme de la maniere suivante (Och & Ney, 2002) :

e* = argmaxp(e|f) = arg meax{expX:)\,<h,<(e,f)} (1)

ou chaque fonction hi quantiﬁe l’adéquation des phrases f et el. Les coeﬁlcients A1 pon-
derent l’importance relative de ces fonctions.

2.1 Décodeur Moses

Moses2 est un systeme de traduction automatique a base de séquences de mots a l’état de
l’art. Il est distribué librement avec les scripts nécessaires a l’entrainement d’un systeme
de traduction complet, ainsi qu’une mise en oeuvre eﬁlcace d’un algorithme de recherche
de type recherche en faisceau pour produire les traductions. Le décodeur Moses peut
également générer une liste des 11 hypotheses envisagées les plus probables. Cette liste
des 11 meilleures hypotheses contient en général plusieurs fois la méme phrase, avec des
probabilités différentes, puisque plusieurs segmentations de la phrase source en séquences
de mots peuvent aboutir a une meme phrase cible. Comme effectué dans les expériences
ci-dessous, il est possible de contraindre le décodeur pour que cette liste contienne n
hypotheses distinctes.

Dans sa version standard, Moses utilise huit fonctions caractéristiques modélisant le pro-
cessus de traduction. Ces fonctions permettent d’intégrer a la recherche de la phrase cible
les contraintes suivantes : les probabilités de traduction des séquences de mots dans les

1Cette « adéquation » est 5. prendre au sens large, puisqu’un systéme de traduction inclut toujours un
modéle de langage cible hm-(e, f) = p(e).
Qhttp : //www . statmt . org/moses/

255

H. SCHWENK, D. DFJCHELOTTE, H. BONNEAU-MAYNARD, A. ALLAUZEN

deux sens, les probabilités de traduction des mots dans les deux sens, une mesure de
distorsion, deux pénalités d’insertion de mots et de séquences de mots, et la probabilité
calculée par le modele de langage de la langue cible.

L’approche couramment employée pour optimiser les poids A, des fonctions caractéris-
tiques est la maximisation sur un corpus de développement de la mesure BLEU (Papineni
et al., 2002). Pour cela, l’outil d’optimisation numérique Condor (Berghen & Bersini,
2005) est intégré a l’algorithme itératif suivant :

1. Partant d’un jeu de poids initial, les listes des 11 = 1000 meilleures hypotheses sont
générées avec Moses (une liste par phrase source).

2. Ces listes sont réévaluées en utilisant le jeu de poids courant.
3. Les meilleures hypotheses sont extraites et évaluées.

4. A partir du score BLEU aisni calculé, Condor calcule un nouveau jeu de poids
(l’algorithme retourne alors a l’étape 2), sauf si un maximum local est détecté ce
qui met ﬁn a l’algorithme.

Le jeu de poids solution est en général trouvé apres une centaine d’itérations. Remarquons
que les listes des 1000 meilleures hypotheses sont générées une seule fois lors de l’initiali-
sation et que les itérations réévaluent les listes des 1000 meilleures hypotheses en fonction
des poids proposés par Condor.

2.2 Désambiguisation lexicale par catégories syntaxiques

D’une langue a l’autre, les structures et les propriétés syntaxiques difFerent, par exemple
l’espagnol est une langue fortement ﬂéchie alors que l’anglais l’est peu. Or ces structures
syntaxiques induisent des ambiguités lexicales qui ne sont pas explicitement prises en
compte par la modélisation statistique du processus de traduction décrit dans la section
ci-dessus.

Il est toujours possible d’utiliser des modeles de langage n-grammes de catégories morpho-
syntaxiques pour réévaluer les listes des 11 meilleures hypotheses de mots générées par un
systeme de traduction. Ce processus nécessite alors d’étiqueter les hypotheses contenues
dans les listes. Cependant, les étiqueteurs morpho-syntaxiques ont été appris sur des énon-
cés correctement formés, ce qui n’est pas toujours le cas des hypotheses provenant d’un
systeme de traduction automatique. Cette étape peut ainsi etre une source d’erreurs qui
limite les performances de la réévaluation. Nous proposons donc d’intégrer les catégories
morpho-syntaxiques au caem" du modele de traduction, ce qui permet d’éviter cet écueil.
L’étiqueteur est alors utilisé sur des énoncés syntaxiquement corrects (en tout cas, des
énoncés réellement produits), ici sur les corpus paralleles. Par ailleurs, utiliser lors de
l’apprentissage des corpus étiquetés morpho-syntaxiquement dans les deux langues per-
met de prendre en compte les spéciﬁcités syntaxiques des deux langues et leur interaction,
alors que dans le cas de la réévaluation des listes de meilleures hypotheses, seules les
spéciﬁcités de la langue cible interviennent.

Nous proposons d’utiliser dans le modele de traduction des unités enrichies constituées
des formes de surface des mots, auxquelles sont agglutinées leurs catégories morpho-
syntaxiques respectives. Cette méthode permet une désambiguisation des mots tenant

256

Modeles statistiques enrichis par la syntaxe pour la traduction automatique

compte de leurs roles et de leurs contextes grammaticaux. Un exemple d’énoncé, avec les
unités enrichies, est donné a la Figure 1 en anglais et en espagnol.

Anglais : Ipp declarevvp resumed‘/VD theDT sessionNN ofm theDT
EuropeanNp Parliament Np

Espagnol : deClaI'0VLf»;»,,, reanudadoVL,,,1,- elART periodoNg depREp sesionesNg
delpDEL ParlamentoNg EuropeoADJ

FIG. 1 — Exemple d’un texte parallele composé d’unités enrichies utilisé pour entrainer le
modele de traduction.

Lorsque les modeles de traduction et de langage sont fondés sur les unités enrichies, le
systeme de traduction attend en entrée et produit en sortie des séquences d’unités enri-
chies. Ainsi les phrases a traduire doivent etre préalablement étiquetées. Réciproquement,
si une traduction classique est requise en sortie, il est nécessaire de retirer les catégories
morpho-syntaxiques de l’hypothese proposée.

Par ailleurs, il devient possible, sur la base des 11 meilleures hypotheses enrichies, d’effec-
tuer une réévaluation en utilisant un modele n-gramme de catégories morpho-syntaxiques,
sans avoir a utiliser a posteriori un étiqueteur sur ces hypotheses.

Pour les expériences présentées dans cet article, nous avons utilisé Wee Tagger (Schmid,
1994), un étiqueteur markovien utilisant des arbres de décision pour estimer les probabi-
lités trigramme de transition. Ce logiciel est librement disponible pour les deux langues
considérées dans cet article. La version anglaise a été entrainée sur le corpus PENN tree-
bank3, et la version espagnole sur le corpus CRATER4. Le nombre de catégories est assez
restreint : 59 pour l’anglais et 69 pour l’espagnol. Notons que les catégories espagnoles ne
contiennent pas de distinction en genre et en nombre.

2.3 Modéle de langage neuronal

L’architecture du modele de langage neuronal est résumée a la Figure 2. Un réseau de
neurones multi-couches completement connecté est utilisé pour apprendre conjointement
la projection des mots dans un espace continu et l’estimation des probabilités n-grammes.

Les entrées du réseau sont les n—1 mots précédents du vocabulaire et les sorties sont les
probabilités a-posteriori pour tous les mots du vocabulaire :

P(wj =i|wj—n+1:---:wj~2=wj—1) = P(wj = ilhjl Vi€l1:Nl (2)

ou N est la taille du vocabulaire et hj le contexte w,-_,,+1, ...,w,--1. Ces entrées sont
projetées sur un espace continu (couche P dans la Figure 2). Les autres couches servent
a l’estimation non-linéaire des probabilités. La valeur de la 2'-eme sortie correspond a la
probabilité du n-gramme P(wj =z'|hj). Le réseau calcule donc directement les probabilités
de tous les mots du vocabulaire pour le meme contexte. L’apprentissage se fait par rétro-
propagation du gradient, en utilisant la cross-entropie comme fonction d’erreur.

ahttp : //www . cis .upenn . edu/"treebank
4http : //www . comp . lancs . ac .uk/1inguistics/crater/corpus .html

257

H. SCHWENK, D. DFJCHELOTTE, H. BONNEAU-MAYNARD, A. ALLAUZEN

Réseau de Neurones
r - — - - — - - - - - - - - N
. . . . couch: ¢k
I 5"‘-'5‘ estlmatlon tbs probalxlnés mm: |

   
  

'"'“'”: ;%ch=.d=  p}1’(n=uj=1|hj) FIG. 2 : Architecture du
N ‘ pi: modele de langage neuro-
 P(wj=i|hj) nal. hj dénomme le contexte
wj-_,,+1,...,wj_1. P est la

et N correspondent a la di-

_ mv = mension de la couche cachée
.‘ ’: 1>(.u,-=N|r.,-) _ _
----------------------- -- et de sortie, respectivement.

reirésentationz représentation: Lrobalililés
dis re ccminue pour tous les rmts
indioes dans le vocab. vecteurs de dim P

I
 taille d’une projection, et H
I
I

Dans ce modele, la complexité est dominée par la taille importante de la couche de sortie.
Ainsi, nous proposons de limiter l’estimation des probabilités aux 8 192 mots les plus fre-
quents, les autres mots étant traités par le modele a repli standard. Dans nos expériences,
environ 90% des requetes de probabilités sont traitées par le réseau de neurones. Il est
important de noter que tous les mots du vocabulaire sont considérés a l’entrée du réseau.

Ce modele de langage a été utilisé avec succes dans un systeme de reconnaissance de la
parole a grand vocabulaire (Schwenk, 2007), et dans un systeme de traduction statistique
pour la tache BTEC avec un nombre tres limité de données d’apprentissage (Schwenk et al.,
2006). Cet article décrit la premiere application du modele de langage neuronal dans un
systeme de traduction statistique avec plusieurs milliers d’exemples d’apprentissage.

3 Résultats expérimentaux

Les expériences décrites dans cet article ont été effectuées dans le cadre des évaluations
internationales organisées par le projet européen TC-STAR5. L’objectif de ce projet est de
motiver, fédérer, et promouvoir les recherches sur la traduction automatique de la parole.
La tache principale de ce projet est la traduction des transcriptions des sessions plénieres
du Parlement européen (SPPE). La communauté européenne met a disposition les minutes
de ces sessions en plusieurs langues, aussi connues sous le nom << Editions du texte ﬁnal >>
(ETF). Ces textes, alignés au niveau des phrases, sont utilisés pour apprendre les modeles
statistiques. Nous disposons également d’environ 100 heures d’enregistrement des sessions
plénieres du Parlement européen. Ces données audio ont été transcrites manuellement et
servent principalement au développement des systemes de reconnaissance de la parole,
mais elles sont aussi utilisées pour entrainer les modeles de langage cible dans le systeme
de traduction.

Trois conditions sont considérées dans les évaluations TC-STAR : la traduction des mi-
nutes ETF (texte), la traduction des transcriptions des données acoustiques (verbatim)
et la traduction des hypotheses du systeme de reconnaissance de la parole (parole). Dans
ce travail, nous ne considérons que la condition verbatim, pour la paire de langues espa-
gnol/anglais. Nous donnons des résultats sur les données de développement et de test de

5http : //www .tc-star . org/

258

Modeles statistiques enrichis par la syntaxe pour la traduction automatique

l’évaluation organisée en 2007. Deux traductions de référence sont disponibles pour les
deux jeux de test. Plusieurs étapes de normalisation ont été appliquées aux minutes des
sessions plénieres aﬁn d’approcher la condition verbatim ou parole, notamment la trans-
formation en mots des nombres. Les modeles de traduction sont estimés sur les données
SPPE qui représentent 1,2M de phrases paralleles, soit environ 35M de mots en anglais.

3.1 Apprentissage des modéles de langage

Pour l’apprentissage des modeles de langage, nous avons utilisé la partie monolingue des
données paralleles SPPE ainsi que les transcriptions des données acoustiques. Des données
extérieures ont également été utilisées pour une estimation plus robuste des modeles : deux
corpus de textes provenant des parlements espagnol (49M mots) et britannique (55M
mots). Ainsi, pour chaque langue, nous disposons de trois sources de texte donnant lieu
a l’estimation de trois modeles indépendants. Ces trois modeles sont in ﬁne interpolés
linéairement pour créer un modele de la langue cible. Les coeﬁlcients d’interpolation sont
estimés via l’algorithme E.M. de maniere a minimiser la perplexité sur les données de
développement. Les coeﬁlcients obtenus sont 0,81 pour le modele SPPE, 0,12 pour le
modele estimé sur les données additionnelles du parlement et 0,07 pour celui utilisant les
transcriptions acoustiques.

Tous les modeles de langage n-grammes utilisés, hormis le modele neuronal, sont des
modeles classiques avec repli utilisant le lissage de Kneser-Ney modiﬁé. Le SR1 LM-toolkit
(Stolcke, 2002) a été utilisé pour leur construction.

Les caractéristiques des données et les perplexités des modeles de langage sont résumées
dans le Tableau 1. Les modeles trigrammes interviennent pendant le décodage, alors que les
modeles quadrigrammes sont utilisés pour réévaluer les listes de 11 meilleures hypotheses.
Le modele de langage neuronal obtient une réduction de la perplexité de 15% environ. Il est
a noter que les données de développement en anglais, donc la traduction de l’espagnol vers
l’anglais, proviennent de deux sources différentes (parlements européen et espagnol). Cette
difference explique les perplexités relativement élevées. Les perplexités sur les données
du Parlement européen uniquement sont plus basses : 85.0, 77.8 et 64.3 pour le tri-,
quadrigramme a repli et le quadrigramme neuronal respectivement.

Anglais Espagnol
Textes du Parlement européen 35,3M 36,6M
Textes parlementaires supplémentaires 55,1M 48,9M
Transcriptions acoustiques 1,5M 777k
Vocabulaire 82,6k 132,5k
Perplexité trigramme 134,5 69,7
Quadrigramme a repli 123,4 64,0
Quadrigramme neuronal 102,8 54,6

TAB. 1 — Données d’apprentissage (en nombre de mots) utilisées pour l’estimation des
modeles de langage et perplexités obtenues sur les données de développement.

259

H. SCHWENK, D. DFJCHELOTTE, H. BONNEAU-MAYNARD, A. ALLAUZEN

3.2 Résultats sur les données de développement

Nous avons effectué de nombreuses études comparatives sur les données de développement
pour évaluer les apports des différentes techniques. Les résultats principaux sont résumés
dans le Tableau 2. En ce qui concerne la désambiguisation lexicale, seul le sens de tra-
duction de l’anglais vers l’espagnol (vers la langue la plus inﬂéchie) a été évalué a ce jour.
Pour chaque sens de traduction, le score BLEU du modele de base avec un trigramme est
donné, ainsi qu’apres la réévaluation avec un quadrigramme a repli et neuronal.

L’utilisation d’un quadrigramme permet d’augmenter le score BLEU d’environ 0,4 points
pour la traduction vers l’anglais et de 0,6 points vers l’espagnol. Nous avons également
essayé de réévaluer les 11 meilleures hypotheses avec des modeles de langage 11,-grammes
de catégories morpho-syntaxiques, mais sans effet sur les performances du systeme. L’uti-
lisation du modele de langage neuronal, par ailleurs, produit une amélioration du score
BLEU de plus de 0,6 points pour les deux directions.

Espagnol —> anglais Anglais —> espagnol
Sans désambiguisation Sans désambiguisation Avec désambiguisation
base 4-gram NNLM base 4—gram NNLM base 4-gram NNLM
BLEU 47,20 47,64 48,26 48,78 49,39 50,15 48,92 49,45 50,30

TAB. 2 — Scores BLEU sur les données de développement. NNLM dénomme le modele de
langage neuronal.

Les gains apportés par la désambiguisation lexicale par categories syntaxiques sont relati-
vement faibles lorsqu’on considere les systemes avec un tri- ou quadrigramme a repli. La
encore, une réévaluation avec des modeles n-grammes de catégories syntaxique n’est pas
eﬁlcace. Cependant, les résultats sont intéressants lorsqu’on combine la modélisation de
langage neuronal et la désambiguisation lexicale : le score BLEU passe de 49,39 a 50,30.
Ceci montre bien l’intérét de travailler conjointement sur une amélioration des techniques
statistiques et sur l’incorporation de connaissances lexicales ou syntaxiques. En effet, la
réévaluation des 11 meilleures hypotheses avec un modele de langage semble etre plus
eﬁlcace si les mots proposés par le modele de traduction sont mieux choisis.

3.3 Résultats sur les données de test

Les performances sur les données de test de l’évaluation TC-STAR 2007 sont résumées dans
le Tableau 3. Les coeﬁlcients A, des fonctions caractéristiques sont les memes que ceux du
systeme optimisé sur les données de développement. Le systeme n’a donc pas été adapté
sur les données de test. Sept centres de recherche publiques et industriels ont participé
a l’évaluation qui s’est déroulée en février 2007. Les scores BLEU varient entre 42.95
et 49.60 (espagnol/anglais) et entre 37.39 et 51.04 (anglais/espagnol). Les performances
du systeme avec désambiguisation lexicale sont tres légerement au-dessous du systeme de
base, dans le cas de l’utilisation d’un modele de langage a repli. Cependant la combinaison
avec un modele de langage neuronal donne de bons résultats, sans pour autant pouvoir
dépasser le systeme sans désambiguisation.

260

Modeles statistiques enrichis par la syntaxe pour la traduction automatique

Espagnol —> anglais Anglais —> espagnol
Sans désambigu'1'sation Sans désambigu'1'sation Avec désambigu'1'sation
base 4-gram NNLM base 4—gram NNLM base 4-gram NNLM

BLEU 48,42 48,67 49,19 49,19 50,17 51,04 49,13 49,91 51,04

TAB. 3 — Scores BLEU sur les données de test.
4 Conclusion

Nous avons présenté et évalué deux évolutions d’un systeme de traduction statistique.
L’une propose une modélisation linguistique dans un espace continu et la seconde integre
les catégories morpho-syntaxiques des mots dans le modele de traduction. La combinaison
des deux méthodes donne des résultats intéressants. Notre systeme a obtenu de tres bons
résultats a l’évaluation TC-STAR organisée début 2007.

Nous étudions aussi l’application des memes techniques a la traduction automatique
d’autres paires de langues, notamment la traduction entre l’anglais et le frangais. Pour
cela le corpus Europarl est utilisé (Koehn, 2006). Nous sommes en train de produire une
deuxieme référence de traduction qui sera librement disponible pour d’autres laboratoires
de recherche intéressés dans la traduction automatique du frangaisﬁ.

Plusieurs extensions du systeme décrit dans cet article sont actuellement a l’étude. Nous
travaillons sur une meilleure incorporation des connaissances linguistiques, notamment
sur l’utilisation d’étiqueteurs prenant en compte le genre et le nombre, voire le sens des
mots, aﬁn d’améliorer la désambigu'1'sation dans le modele de traduction. Un logiciel de
visualisation des erreurs de traduction est en cours de développement aﬁn de permettre
une analyse qualitative des erreurs pour aﬁiner le choix des étiquettes, notamment pour le
frangais. En ce qui concerne l’amélioration des techniques statistiques, nous sommes tres
intéressés par une représentation factorisée des mots, incluant notamment des informations
morpho-syntaxiques et linguistiques, aussi bien pour le modele de traduction que pour le
modele de la langue cible.

Remerciements

Ces recherches ont été partiellement ﬁnancées par le projet européen TC-STAR et par le
projet ANR Instar, J CJ C06_143038.

Références

BENGIO Y., DUCHARME R., VINCENT P. & JAUVIN C. (2003). A neural probabilistic
language model. Journal of Machine Learning Research, 3(2), 1137—1155.

BERGHEN F. V. & BERSINI H. (2005). CONDOR, a new parallel, constrained extension
of powell’s UOBYQA algorithm : Experimental results and comparison with the DFO
algorithm. Journal of Computational and Applied Mathematics, 181, 157—175.

5Données disponibles 53. partir de la. page internet http://instar.1imsi.fr

261

H. SCHWENK, D. DECHELOTTE, H. BONNEAU-MAYNARD, A. ALLAUZEN

BROWN P., DELLA PIETRA S., DELLA PIETRA V. J. & MERCER R. (1993). The
mathematics of statistical machine translation. Computational Linguistics, 19(2), 263—
311.

CHARNIAK E., KNIGHT K. & YAMADA K. (2003). Syntax-based language models for
machine translation. In MT Summit.

HASAN S., BENDER O. & NEY H. (2006). Reranking translation hypothesis using
structural properties. In EA CL Workshop on Learning Structured Information in Natural
Language Applications.

HWANG Y., FINCH A. & SASAKI Y. (2007). Improving statistical machine translation
using shallow linguistic knowledge. Computer Speech 63 Language, 21(2), 350—372.
KIRCHHOFF K. & YANG M. (2005). Improved language modeling for statistical machine
translation. In ACL’05 workshop on Building and Using Parallel Text, p. 125—128.
KOEHN P. (2006). Europarl : A parallel corpus for statistical machine translation. In
MT Summit.

KOEHN P., OCH F. J. & MARCU D. (2003). Statistical phrased-based machine trans-
lation. In Joint Conference on Human Language Technology and of the North American
Chapter of the Asociation for Computational Lingustics, p. 127—133.

OCH F.-J., GILDEA D., KHUDANPUR S., SARKAR A., YAMADA K., FRASER A.,
KUMAR S., SHEN L., SMITH D., ENG K., JAIN V., JIN Z. & RADEV D. (2004). A
smorgasbord of features for statistical machine translation. In Proceedings of the North
American Chapter of the Asociation for Computational Lingustics, p. 161—168.

OCH F. J . & NEY H. (2002). Discriminative training and maximum entropy models
for statistical machine translation. In Proceedings of ACL, p. 295—302.

OCH F. J ., TILLMANN C. & NEY H. (1999). Improved alignment models for statistical
machine translation. In Joint SIGDAT Conference on Empirical Methods in Natural
Language Processing and Very Large Copora, p. 20—28.

PAPINENI K., RoUKos S., WARD T. & ZHU W. (2002). BLEU : a method for auto-
matic evaluation of machine translation. In Proceedings of ACL, p. 311—318.

SCHMID H. (1994). Probabilistic part-of-speech tagging using decision trees. In Procee-
dings of International Conference on New Methods in Language Processing.

SCHWENK H. (2007). Continuous space language models. Computer Speech and Lan-
guage, 21, 492—518.

SCHWENK H., CosTA-JUssA M. R. & FoNoLLosA J . A. R. (2006). Continuous
space language models for the IWSLT 2006 task. In International Workshop on Spoken
Language Translation, p. 166—173.

STOLCKE A. (2002). SRILM - an extensible language modeling toolkit. In International
Conference on Speech and Language Processing, p. II : 901—904.

262

