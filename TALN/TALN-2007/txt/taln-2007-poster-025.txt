TALN 2007, Toulouse, 5Ğ8 juin 2007
Mode`les statistiques enrichis par la syntaxe pour la
traduction automatique
Holger Schwenk, Daniel De«chelotte
He«le`ne Bonneau-Maynard, Alexandre Allauzen
LIMSI-CNRS, B.P. 133, 91403 Orsay cedex
{schwenk,dechelot,hbm,allauzen}@limsi.fr
Re«sume«. La traduction automatique statistique par se«quences de mots est une
voie prometteuse. Nous pre«sentons dans cet article deux e«volutions comple«mentaires. La
premie`re permet une mode«lisation de la langue cible dans un espace continu. La seconde
inte`gre des cate«gories morpho-syntaxiques aux unite«s manipule«es par le mode`le de tra-
duction. Ces deux approches sont e«value«es sur la taöche Tc-Star. Les re«sultats les plus
inte«ressants sont obtenus par la combinaison de ces deux me«thodes.
Abstract. Statistical phrase-based translation models are very efficient. In this
paper, we present two complementary methods. The first one consists in a a statistical
language model that is based on a continuous representation of the words in the vocabu-
lary. By these means we expect to take better advantage of the limited amount of training
data. In the second method, morpho-syntactic information is incorporated into the trans-
lation model in order to obtain lexical disambiguation. Both approaches are evaluated on
the Tc-Star task. Most promising results are obtained by combining both methods.
Mots-cle«s : traduction automatique, approche statistique, mode«lisation linguis-
tique dans un espace continu, analyse morpho-syntaxique, de«sambigu¬õsation lexicale.
Keywords: statistical machine translation, continuous space language model,
POS tagging, lexical disambiguation.
1 Introduction
La traduction automatique est un the`me de recherche depuis plusieurs de«cennies et dif-
fe«rentes approches ont e«te« propose«es, telles que la traduction par re`gles, la traduction a`
base dÕexemples ou la traduction statistique. Les travaux re«cents en traduction statistique
confirment que les mode`les fonde«s sur des se«quences de mots (Och et al., 1999; Koehn
et al., 2003) obtiennent des performances significativement meilleures que ceux fonde«s
sur des mots (Brown et al., 1993). En utilisant des se«quences de mots, les syste`mes de
traduction parviennent a` pre«server certaines contraintes locales sur lÕordre des mots. LÕen-
traöõnement dÕun tel mode`le ne«cessite lÕalignement dÕun corpus paralle`le. Les re«gularite«s
du langage naturel comme celles de la syntaxe, ou, encore a` un niveau supe«rieur, celles de
la se«mantique sont ainsi, en principe, implicitement capture«es par les mode`les.
253
H. Schwenk, D. De«chelotte, H. Bonneau-Maynard, A. Allauzen
Depuis les de«buts de lÕapproche statistique en traduction automatique, les efforts de mo-
de«lisation se sont principalement concentre«s sur les mode`les de traduction et dÕalignement,
comme en te«moignent les nombreuses publications sur ces sujets. Dans cet article, nous
explorons deux pistes comple«mentaires pour lÕame«lioration des mode`les de traduction
statistique : dÕune part, lÕexploration dÕune mode«lisation statistique du langage dans un
espace continu, et dÕautre part lÕinte«gration dÕinformations syntaxiques dans le mode`le de
traduction.
Traditionnellement, les syste`mes de traduction statistiques utilisent des mode`les de lan-
gage trigramme a` repli. Dans ces mode`les classiques, les mots sont repre«sente«s par un
indice dans un espace discret, le vocabulaire. Ceci ne permet pas de faire de ve«ritables
interpolations des probabilite«s dÕun n-gramme non observe« puisquÕun changement dans
lÕespace des mots peut entraöõner un changement arbitraire de la probabilite«. Nous propo-
sons ici dÕappre«hender dans un domaine continu le proble`me de lÕestimation dÕun mode`le
linguistique. LÕide«e consiste a` projeter les indices des mots dans une repre«sentation conti-
nue (un espace vectoriel) et dÕestimer les probabilite«s dans cet espace (Bengio et al., 2003).
Actuellement, un re«seau de neuronesmulti-couches comple`tement connecte« est utilise« pour
apprendre conjointement la projection des mots sur un espace continu et lÕestimation des
probabilite«s n-grammes.
La lecture humaine des sorties dÕun syste`me statistique de traduction, meöme base« sur
des se«quences de mots, ne«cessite parfois un difficile exercice de re«ordonnancement et de
restructuration syntaxique pour restituer le sens de lÕe«nonce« dÕorigine. La mode«lisation
du langage comme une source markovienne (mode`le de langage n-gramme), avec comme
unite« le mot ou la se«quence de mots, ne permet pas de prendre en compte les contraintes
syntaxiques ou les de«pendances a` long terme entre les mots. Il apparaöõt donc ne«ces-
saire dÕutiliser des me«thodes dans lesquelles les proprie«te«s structurelles des langues sont
explicitement repre«sente«es. Plusieurs tentatives sur lÕutilisation dÕinformations morpho-
syntaxiques dans la traduction statistique ont de«ja` e«te« mene«es. (Och et al., 2004) ont
explore« de nombreuses fonctions caracte«ristiques, dont certaines dÕordre syntaxique. La
re«e«valuation des n meilleures hypothe`ses avec des e«tiquettes morpho-syntaxiques a e«gale-
ment e«te« e«tudie«e par (Hasan et al., 2006). Dans (Kirchhoff & Yang, 2005), un mode`le de
langage factorise« quadrigramme utilisant des informations syntaxiques nÕa pas montre« des
performances meilleures quÕun mode`le n-gramme de mots. Les mode`les de langage fonde«s
sur la syntaxe ont enfin e«te« explore«s par (Charniak et al., 2003). Tous ces travaux ont en
commun dÕutiliser des se«quences de mots comme unite«s du syste`me de traduction et de
nÕintroduire les cate«gories morpho-syntaxiques que dans une seconde passe de traitement.
Dans ce travail, nous proposons dÕinte«grer les informations syntaxiques dans le mode`le
de traduction lui-meöme. De plus, nous proposons de combiner cette approche avec les
me«thodes classiques de re«e«valuation de listes de n meilleures hypothe`ses. A` notre connais-
sance, cette approche nÕa pas e«te« e«value«e sur une large taöche (elle a e«te« applique«e par
(Hwang et al., 2007) a` la taöche BTEC (Basic Travel Expression Corpus) beaucoup plus
re«duite). Nous pre«sentons ici des re«sultats sur la taöche Tc-Star (traduction des trans-
criptions des sessions ple«nie`res du Parlement europe«en).
Cet article est organise« comme suit. Dans la section suivante, nous pre«sentons dÕabord la
structure du syste`me de traduction automatique et ses diffe«rentes extensions. Les re«sultats
expe«rimentaux sont re«sume«s et discute«s dans la section 3. La dernie`re section conclue cet
article et sugge`re des extensions et travaux futurs.
254
Mode`les statistiques enrichis par la syntaxe pour la traduction automatique
2 Description du syste`me
LÕobjectif dÕun syste`me de traduction automatique est de proposer pour une phrase f en
langue Ç source È sa traduction en une phrase e dans la langue Ç cible È. LÕapproche
statistique consiste a` choisir, parmi les phrases possibles, la plus probable. Le proble`me
se de«compose de la manie`re suivante :
e? = argmax
e
Pr(e|f) = argmax
e
Pr(f |e) Pr(e),
ou` la probabilite« Pr(f |e) est estime«e par le mode`le de traduction et Pr(e) par le mo-
de`le de langage de la langue cible. Cette e«quation re«sume lÕapproche source/canal his-
torique (Brown et al., 1993) qui conside`re le mot comme unite« et la phrase comme une
se«quence de mots. Le mode`le de traduction peut eötre estime« automatiquement a` partir de
textes paralle`les aligne«s au niveau de la phrase. Ce calcul est effectue« par le logiciel libre
GIZA++.
Ces dernie`res anne«es, les travaux en traduction statistique ont e«tendu avec succe`s lÕunite«
quÕe«tait le mot a` la se«quence de mots (Och et al., 1999; Koehn et al., 2003). Cette nouvelle
unite« se de«finit alors comme un groupe de mots successifs f÷ de la langue source. Sa
traduction est e«galement une se«quence de mots e÷ dans la phrase cible. Les se«quences
de mots peuvent eötre extraites automatiquement a` partir de donne«es bilingues aligne«es
au niveau du mot dans les deux sens. LÕutilisation du principe du maximum dÕentropie
permet de de«composer le proble`me de la manie`re suivante (Och & Ney, 2002) :
e? = argmax p(e|f) = argmax
e
{exp
·
i
?ihi(e, f)} (1)
ou` chaque fonction hi quantifie lÕade«quation des phrases f et e1. Les coefficients ?i pon-
de`rent lÕimportance relative de ces fonctions.
2.1 De«codeur Moses
Moses2 est un syste`me de traduction automatique a` base de se«quences de mots a` lÕe«tat de
lÕart. Il est distribue« librement avec les scripts ne«cessaires a` lÕentraöõnement dÕun syste`me
de traduction complet, ainsi quÕune mise en Ïuvre efficace dÕun algorithme de recherche
de type recherche en faisceau pour produire les traductions. Le de«codeur Moses peut
e«galement ge«ne«rer une liste des n hypothe`ses envisage«es les plus probables. Cette liste
des n meilleures hypothe`ses contient en ge«ne«ral plusieurs fois la meöme phrase, avec des
probabilite«s diffe«rentes, puisque plusieurs segmentations de la phrase source en se«quences
de mots peuvent aboutir a` une meöme phrase cible. Comme effectue« dans les expe«riences
ci-dessous, il est possible de contraindre le de«codeur pour que cette liste contienne n
hypothe`ses distinctes.
Dans sa version standard, Moses utilise huit fonctions caracte«ristiques mode«lisant le pro-
cessus de traduction. Ces fonctions permettent dÕinte«grer a` la recherche de la phrase cible
les contraintes suivantes : les probabilite«s de traduction des se«quences de mots dans les
1Cette Ç ade«quation È est a` prendre au sens large, puisquÕun syste`me de traduction inclut toujours un
mode`le de langage cible hi(e, f) = p(e).
2http://www.statmt.org/moses/
255
H. Schwenk, D. De«chelotte, H. Bonneau-Maynard, A. Allauzen
deux sens, les probabilite«s de traduction des mots dans les deux sens, une mesure de
distorsion, deux pe«nalite«s dÕinsertion de mots et de se«quences de mots, et la probabilite«
calcule«e par le mode`le de langage de la langue cible.
LÕapproche couramment employe«e pour optimiser les poids ?i des fonctions caracte«ris-
tiques est la maximisation sur un corpus de de«veloppement de la mesure BLEU (Papineni
et al., 2002). Pour cela, lÕoutil dÕoptimisation nume«rique Condor (Berghen & Bersini,
2005) est inte«gre« a` lÕalgorithme ite«ratif suivant :
1. Partant dÕun jeu de poids initial, les listes des n = 1000 meilleures hypothe`ses sont
ge«ne«re«es avec Moses (une liste par phrase source).
2. Ces listes sont re«e«value«es en utilisant le jeu de poids courant.
3. Les meilleures hypothe`ses sont extraites et e«value«es.
4. A` partir du score BLEU aisni calcule«, Condor calcule un nouveau jeu de poids
(lÕalgorithme retourne alors a` lÕe«tape 2), sauf si un maximum local est de«tecte« ce
qui met fin a` lÕalgorithme.
Le jeu de poids solution est en ge«ne«ral trouve« apre`s une centaine dÕite«rations. Remarquons
que les listes des 1000 meilleures hypothe`ses sont ge«ne«re«es une seule fois lors de lÕinitiali-
sation et que les ite«rations re«e«valuent les listes des 1000 meilleures hypothe`ses en fonction
des poids propose«s par Condor.
2.2 De«sambigu¬õsation lexicale par cate«gories syntaxiques
DÕune langue a` lÕautre, les structures et les proprie«te«s syntaxiques diffe`rent, par exemple
lÕespagnol est une langue fortement fle«chie alors que lÕanglais lÕest peu. Or ces structures
syntaxiques induisent des ambigu¬õte«s lexicales qui ne sont pas explicitement prises en
compte par la mode«lisation statistique du processus de traduction de«crit dans la section
ci-dessus.
Il est toujours possible dÕutiliser des mode`les de langage n-grammes de cate«gories morpho-
syntaxiques pour re«e«valuer les listes des n meilleures hypothe`ses de mots ge«ne«re«es par un
syste`me de traduction. Ce processus ne«cessite alors dÕe«tiqueter les hypothe`ses contenues
dans les listes. Cependant, les e«tiqueteursmorpho-syntaxiques ont e«te« appris sur des e«non-
ce«s correctement forme«s, ce qui nÕest pas toujours le cas des hypothe`ses provenant dÕun
syste`me de traduction automatique. Cette e«tape peut ainsi eötre une source dÕerreurs qui
limite les performances de la re«e«valuation. Nous proposons donc dÕinte«grer les cate«gories
morpho-syntaxiques au cÏur du mode`le de traduction, ce qui permet dÕe«viter cet e«cueil.
LÕe«tiqueteur est alors utilise« sur des e«nonce«s syntaxiquement corrects (en tout cas, des
e«nonce«s re«ellement produits), ici sur les corpus paralle`les. Par ailleurs, utiliser lors de
lÕapprentissage des corpus e«tiquete«s morpho-syntaxiquement dans les deux langues per-
met de prendre en compte les spe«cificite«s syntaxiques des deux langues et leur interaction,
alors que dans le cas de la re«e«valuation des listes de meilleures hypothe`ses, seules les
spe«cificite«s de la langue cible interviennent.
Nous proposons dÕutiliser dans le mode`le de traduction des unite«s enrichies constitue«es
des formes de surface des mots, auxquelles sont agglutine«es leurs cate«gories morpho-
syntaxiques respectives. Cette me«thode permet une de«sambigu¬õsation des mots tenant
256
Mode`les statistiques enrichis par la syntaxe pour la traduction automatique
compte de leurs roöles et de leurs contextes grammaticaux. Un exemple dÕe«nonce«, avec les
unite«s enrichies, est donne« a` la Figure 1 en anglais et en espagnol.
Anglais : IPP declareV V P resumedV V D theDT sessionNN ofIN theDT
EuropeanNP ParliamentNP
Espagnol : declaroV Lfin reanudadoV Ladj elART per«õodoNC dePREP sesionesNC
delPDEL ParlamentoNC EuropeoADJ
Fig. 1 Ğ Exemple dÕun texte paralle`le compose« dÕunite«s enrichies utilise« pour entraöõner le
mode`le de traduction.
Lorsque les mode`les de traduction et de langage sont fonde«s sur les unite«s enrichies, le
syste`me de traduction attend en entre«e et produit en sortie des se«quences dÕunite«s enri-
chies. Ainsi les phrases a` traduire doivent eötre pre«alablement e«tiquete«es. Re«ciproquement,
si une traduction classique est requise en sortie, il est ne«cessaire de retirer les cate«gories
morpho-syntaxiques de lÕhypothe`se propose«e.
Par ailleurs, il devient possible, sur la base des n meilleures hypothe`ses enrichies, dÕeffec-
tuer une re«e«valuation en utilisant un mode`le n-gramme de cate«gories morpho-syntaxiques,
sans avoir a` utiliser a posteriori un e«tiqueteur sur ces hypothe`ses.
Pour les expe«riences pre«sente«es dans cet article, nous avons utilise« TreeTagger (Schmid,
1994), un e«tiqueteur markovien utilisant des arbres de de«cision pour estimer les probabi-
lite«s trigramme de transition. Ce logiciel est librement disponible pour les deux langues
conside«re«es dans cet article. La version anglaise a e«te« entraöõne«e sur le corpus PENN tree-
bank 3, et la version espagnole sur le corpus CRATER4. Le nombre de cate«gories est assez
restreint : 59 pour lÕanglais et 69 pour lÕespagnol. Notons que les cate«gories espagnoles ne
contiennent pas de distinction en genre et en nombre.
2.3 Mode`le de langage neuronal
LÕarchitecture du mode`le de langage neuronal est re«sume«e a` la Figure 2. Un re«seau de
neurones multi-couches comple`tement connecte« est utilise« pour apprendre conjointement
la projection des mots dans un espace continu et lÕestimation des probabilite«s n-grammes.
Les entre«es du re«seau sont les n?1 mots pre«ce«dents du vocabulaire et les sorties sont les
probabilite«s a-posteriori pour tous les mots du vocabulaire :
P (wj = i|wj?n+1, ..., wj?2, wj?1) = P (wj = i|hj) ?i ? [1, N ] (2)
ou` N est la taille du vocabulaire et hj le contexte wj?n+1, ..., wj?1. Ces entre«es sont
projete«es sur un espace continu (couche P dans la Figure 2). Les autres couches servent
a` lÕestimation non-line«aire des probabilite«s. La valeur de la i-e`me sortie correspond a` la
probabilite« du n-gramme P (wj= i|hj). Le re«seau calcule donc directement les probabilite«s
de tous les mots du vocabulaire pour le meöme contexte. LÕapprentissage se fait par re«tro-
propagation du gradient, en utilisant la cross-entropie comme fonction dÕerreur.
3http://www.cis.upenn.edu/~treebank
4http://www.comp.lancs.ac.uk/linguistics/crater/corpus.html
257
H. Schwenk, D. De«chelotte, H. Bonneau-Maynard, A. Allauzen
couche de
projection couche
cache
couche de
sortie
entre
partages
projections
probabilits
pour tous les mots
Rseau de Neurones
reprsentation:
discrte
indices dans le vocab.
reprsentation:
continue
vecteurs de dim. P
estimation des probabilits 
N
wj?1 P
H
N
P (wj=1|hj)
wj?n+1
wj?n+2
P (wj=i|hj)
P (wj=N|hj)
cl
oiM
Vdj
p1 =
pN =
pi =
Fig. 2 : Architecture du
mode`le de langage neuro-
nal. hj de«nomme le contexte
wj?n+1, . . . , wj?1. P est la
taille dÕune projection, et H
et N correspondent a` la di-
mension de la couche cache«e
et de sortie, respectivement.
Dans ce mode`le, la complexite« est domine«e par la taille importante de la couche de sortie.
Ainsi, nous proposons de limiter lÕestimation des probabilite«s aux 8 192 mots les plus fre«-
quents, les autres mots e«tant traite«s par le mode`le a` repli standard. Dans nos expe«riences,
environ 90% des requeötes de probabilite«s sont traite«es par le re«seau de neurones. Il est
important de noter que tous les mots du vocabulaire sont conside«re«s a` lÕentre«e du re«seau.
Ce mode`le de langage a e«te« utilise« avec succe`s dans un syste`me de reconnaissance de la
parole a` grand vocabulaire (Schwenk, 2007), et dans un syste`me de traduction statistique
pour la taöcheBtec avec un nombre tre`s limite« de donne«es dÕapprentissage (Schwenk et al.,
2006). Cet article de«crit la premie`re application du mode`le de langage neuronal dans un
syste`me de traduction statistique avec plusieurs milliers dÕexemples dÕapprentissage.
3 Re«sultats expe«rimentaux
Les expe«riences de«crites dans cet article ont e«te« effectue«es dans le cadre des e«valuations
internationales organise«es par le projet europe«en Tc-Star5. LÕobjectif de ce projet est de
motiver, fe«de«rer, et promouvoir les recherches sur la traduction automatique de la parole.
La taöche principale de ce projet est la traduction des transcriptions des sessions ple«nie`res
du Parlement europe«en (SPPE). La communaute« europe«ennemet a` disposition lesminutes
de ces sessions en plusieurs langues, aussi connues sous le nom Ç E«ditions du texte final È
(ETF). Ces textes, aligne«s au niveau des phrases, sont utilise«s pour apprendre les mode`les
statistiques. Nous disposons e«galement dÕenviron 100 heures dÕenregistrement des sessions
ple«nie`res du Parlement europe«en. Ces donne«es audio ont e«te« transcrites manuellement et
servent principalement au de«veloppement des syste`mes de reconnaissance de la parole,
mais elles sont aussi utilise«es pour entraöõner les mode`les de langage cible dans le syste`me
de traduction.
Trois conditions sont conside«re«es dans les e«valuations Tc-Star : la traduction des mi-
nutes ETF (texte), la traduction des transcriptions des donne«es acoustiques (verbatim)
et la traduction des hypothe`ses du syste`me de reconnaissance de la parole (parole). Dans
ce travail, nous ne conside«rons que la condition verbatim, pour la paire de langues espa-
gnol/anglais. Nous donnons des re«sultats sur les donne«es de de«veloppement et de test de
5http://www.tc-star.org/
258
Mode`les statistiques enrichis par la syntaxe pour la traduction automatique
lÕe«valuation organise«e en 2007. Deux traductions de re«fe«rence sont disponibles pour les
deux jeux de test. Plusieurs e«tapes de normalisation ont e«te« applique«es aux minutes des
sessions ple«nie`res afin dÕapprocher la condition verbatim ou parole, notamment la trans-
formation en mots des nombres. Les mode`les de traduction sont estime«s sur les donne«es
SPPE qui repre«sentent 1,2M de phrases paralle`les, soit environ 35M de mots en anglais.
3.1 Apprentissage des mode`les de langage
Pour lÕapprentissage des mode`les de langage, nous avons utilise« la partie monolingue des
donne«es paralle`les SPPE ainsi que les transcriptions des donne«es acoustiques. Des donne«es
exte«rieures ont e«galement e«te« utilise«es pour une estimation plus robuste desmode`les : deux
corpus de textes provenant des parlements espagnol (49M mots) et britannique (55M
mots). Ainsi, pour chaque langue, nous disposons de trois sources de texte donnant lieu
a` lÕestimation de trois mode`les inde«pendants. Ces trois mode`les sont in fine interpole«s
line«airement pour cre«er un mode`le de la langue cible. Les coefficients dÕinterpolation sont
estime«s via lÕalgorithme E.M. de manie`re a` minimiser la perplexite« sur les donne«es de
de«veloppement. Les coefficients obtenus sont 0,81 pour le mode`le SPPE, 0,12 pour le
mode`le estime« sur les donne«es additionnelles du parlement et 0,07 pour celui utilisant les
transcriptions acoustiques.
Tous les mode`les de langage n-grammes utilise«s, hormis le mode`le neuronal, sont des
mode`les classiques avec repli utilisant le lissage de Kneser-Ney modifie«. Le SRI LM-toolkit
(Stolcke, 2002) a e«te« utilise« pour leur construction.
Les caracte«ristiques des donne«es et les perplexite«s des mode`les de langage sont re«sume«es
dans le Tableau 1. Lesmode`les trigrammes interviennent pendant le de«codage, alors que les
mode`les quadrigrammes sont utilise«s pour re«e«valuer les listes de n meilleures hypothe`ses.
Lemode`le de langage neuronal obtient une re«duction de la perplexite« de 15% environ. Il est
a` noter que les donne«es de de«veloppement en anglais, donc la traduction de lÕespagnol vers
lÕanglais, proviennent de deux sources diffe«rentes (parlements europe«en et espagnol). Cette
diffe«rence explique les perplexite«s relativement e«leve«es. Les perplexite«s sur les donne«es
du Parlement europe«en uniquement sont plus basses : 85.0, 77.8 et 64.3 pour le tri-,
quadrigramme a` repli et le quadrigramme neuronal respectivement.
Anglais Espagnol
Textes du Parlement europe«en 35,3M 36,6M
Textes parlementaires supple«mentaires 55,1M 48,9M
Transcriptions acoustiques 1,5M 777k
Vocabulaire 82,6k 132,5k
Perplexite« trigramme 134,5 69,7
Quadrigramme a` repli 123,4 64,0
Quadrigramme neuronal 102,8 54,6
Tab. 1 Ğ Donne«es dÕapprentissage (en nombre de mots) utilise«es pour lÕestimation des
mode`les de langage et perplexite«s obtenues sur les donne«es de de«veloppement.
259
H. Schwenk, D. De«chelotte, H. Bonneau-Maynard, A. Allauzen
3.2 Re«sultats sur les donne«es de de«veloppement
Nous avons effectue« de nombreuses e«tudes comparatives sur les donne«es de de«veloppement
pour e«valuer les apports des diffe«rentes techniques. Les re«sultats principaux sont re«sume«s
dans le Tableau 2. En ce qui concerne la de«sambigu¬õsation lexicale, seul le sens de tra-
duction de lÕanglais vers lÕespagnol (vers la langue la plus infle«chie) a e«te« e«value« a` ce jour.
Pour chaque sens de traduction, le score Bleu du mode`le de base avec un trigramme est
donne«, ainsi quÕapre`s la re«e«valuation avec un quadrigramme a` repli et neuronal.
LÕutilisation dÕun quadrigramme permet dÕaugmenter le score Bleu dÕenviron 0,4 points
pour la traduction vers lÕanglais et de 0,6 points vers lÕespagnol. Nous avons e«galement
essaye« de re«e«valuer les n meilleures hypothe`ses avec des mode`les de langage n-grammes
de cate«gories morpho-syntaxiques, mais sans effet sur les performances du syste`me. LÕuti-
lisation du mode`le de langage neuronal, par ailleurs, produit une ame«lioration du score
BLEU de plus de 0,6 points pour les deux directions.
Espagnol ? anglais Anglais ? espagnol
Sans de«sambigu¬õsation Sans de«sambigu¬õsation Avec de«sambigu¬õsation
base 4-gram NNLM base 4-gram NNLM base 4-gram NNLM
BLEU 47,20 47,64 48,26 48,78 49,39 50,15 48,92 49,45 50,30
Tab. 2 Ğ Scores BLEU sur les donne«es de de«veloppement. NNLM de«nomme le mode`le de
langage neuronal.
Les gains apporte«s par la de«sambigu¬õsation lexicale par cate«gories syntaxiques sont relati-
vement faibles lorsquÕon conside`re les syste`mes avec un tri- ou quadrigramme a` repli. La`
encore, une re«e«valuation avec des mode`les n-grammes de cate«gories syntaxique nÕest pas
efficace. Cependant, les re«sultats sont inte«ressants lorsquÕon combine la mode«lisation de
langage neuronal et la de«sambigu¬õsation lexicale : le score Bleu passe de 49,39 a` 50,30.
Ceci montre bien lÕinte«reöt de travailler conjointement sur une ame«lioration des techniques
statistiques et sur lÕincorporation de connaissances lexicales ou syntaxiques. En effet, la
re«e«valuation des n meilleures hypothe`ses avec un mode`le de langage semble eötre plus
efficace si les mots propose«s par le mode`le de traduction sont mieux choisis.
3.3 Re«sultats sur les donne«es de test
Les performances sur les donne«es de test de lÕe«valuationTc-Star 2007 sont re«sume«es dans
le Tableau 3. Les coefficients ?i des fonctions caracte«ristiques sont les meömes que ceux du
syste`me optimise« sur les donne«es de de«veloppement. Le syste`me nÕa donc pas e«te« adapte«
sur les donne«es de test. Sept centres de recherche publiques et industriels ont participe«
a` lÕe«valuation qui sÕest de«roule«e en fe«vrier 2007. Les scores BLEU varient entre 42.95
et 49.60 (espagnol/anglais) et entre 37.39 et 51.04 (anglais/espagnol). Les performances
du syste`me avec de«sambigu¬õsation lexicale sont tre`s le«ge`rement au-dessous du syste`me de
base, dans le cas de lÕutilisation dÕun mode`le de langage a` repli. Cependant la combinaison
avec un mode`le de langage neuronal donne de bons re«sultats, sans pour autant pouvoir
de«passer le syste`me sans de«sambigu¬õsation.
260
Mode`les statistiques enrichis par la syntaxe pour la traduction automatique
Espagnol ? anglais Anglais ? espagnol
Sans de«sambigu¬õsation Sans de«sambigu¬õsation Avec de«sambigu¬õsation
base 4-gram NNLM base 4-gram NNLM base 4-gram NNLM
BLEU 48,42 48,67 49,19 49,19 50,17 51,04 49,13 49,91 51,04
Tab. 3 Ğ Scores BLEU sur les donne«es de test.
4 Conclusion
Nous avons pre«sente« et e«value« deux e«volutions dÕun syste`me de traduction statistique.
LÕune propose une mode«lisation linguistique dans un espace continu et la seconde inte`gre
les cate«gories morpho-syntaxiques des mots dans le mode`le de traduction. La combinaison
des deux me«thodes donne des re«sultats inte«ressants. Notre syste`me a obtenu de tre`s bons
re«sultats a` lÕe«valuation Tc-Star organise«e de«but 2007.
Nous e«tudions aussi lÕapplication des meömes techniques a` la traduction automatique
dÕautres paires de langues, notamment la traduction entre lÕanglais et le francüais. Pour
cela le corpus Europarl est utilise« (Koehn, 2006). Nous sommes en train de produire une
deuxie`me re«fe«rence de traduction qui sera librement disponible pour dÕautres laboratoires
de recherche inte«resse«s dans la traduction automatique du francüais6.
Plusieurs extensions du syste`me de«crit dans cet article sont actuellement a` lÕe«tude. Nous
travaillons sur une meilleure incorporation des connaissances linguistiques, notamment
sur lÕutilisation dÕe«tiqueteurs prenant en compte le genre et le nombre, voire le sens des
mots, afin dÕame«liorer la de«sambigu¬õsation dans le mode`le de traduction. Un logiciel de
visualisation des erreurs de traduction est en cours de de«veloppement afin de permettre
une analyse qualitative des erreurs pour affiner le choix des e«tiquettes, notamment pour le
francüais. En ce qui concerne lÕame«lioration des techniques statistiques, nous sommes tre`s
inte«resse«s par une repre«sentation factorise«e desmots, incluant notamment des informations
morpho-syntaxiques et linguistiques, aussi bien pour le mode`le de traduction que pour le
mode`le de la langue cible.
Remerciements
Ces recherches ont e«te« partiellement finance«es par le projet europe«en Tc-Star et par le
projet Anr Instar, JCJC06 143038.
Re«fe«rences
Bengio Y., Ducharme R., Vincent P. & Jauvin C. (2003). A neural probabilistic
language model. Journal of Machine Learning Research, 3(2), 1137Ğ1155.
Berghen F. V. & Bersini H. (2005). CONDOR, a new parallel, constrained extension
of powellÕs UOBYQA algorithm : Experimental results and comparison with the DFO
algorithm. Journal of Computational and Applied Mathematics, 181, 157Ğ175.
6Donne«es disponibles a` partir de la page internet http://instar.limsi.fr
261
H. Schwenk, D. De«chelotte, H. Bonneau-Maynard, A. Allauzen
Brown P., Della Pietra S., Della Pietra V. J. & Mercer R. (1993). The
mathematics of statistical machine translation. Computational Linguistics, 19(2), 263Ğ
311.
Charniak E., Knight K. & Yamada K. (2003). Syntax-based language models for
machine translation. In MT Summit.
Hasan S., Bender O. & Ney H. (2006). Reranking translation hypothesis using
structural properties. In EACL Workshop on Learning Structured Information in Natural
Language Applications.
Hwang Y., Finch A. & Sasaki Y. (2007). Improving statistical machine translation
using shallow linguistic knowledge. Computer Speech & Language, 21(2), 350Ğ372.
Kirchhoff K. & Yang M. (2005). Improved languagemodeling for statisticalmachine
translation. In ACLÕ05 workshop on Building and Using Parallel Text, p. 125Ğ128.
Koehn P. (2006). Europarl : A parallel corpus for statistical machine translation. In
MT Summit.
Koehn P., Och F. J. & Marcu D. (2003). Statistical phrased-based machine trans-
lation. In Joint Conference on Human Language Technology and of the North American
Chapter of the Asociation for Computational Lingustics, p. 127Ğ133.
Och F.-J., Gildea D., Khudanpur S., Sarkar A., Yamada K., Fraser A.,
Kumar S., Shen L., Smith D., Eng K., Jain V., Jin Z. & Radev D. (2004). A
smorgasbord of features for statistical machine translation. In Proceedings of the North
American Chapter of the Asociation for Computational Lingustics, p. 161Ğ168.
Och F. J. & Ney H. (2002). Discriminative training and maximum entropy models
for statistical machine translation. In Proceedings of ACL, p. 295Ğ302.
Och F. J., Tillmann C. & Ney H. (1999). Improved alignment models for statistical
machine translation. In Joint SIGDAT Conference on Empirical Methods in Natural
Language Processing and Very Large Copora, p. 20Ğ28.
Papineni K., Roukos S., Ward T. & Zhu W. (2002). BLEU : a method for auto-
matic evaluation of machine translation. In Proceedings of ACL, p. 311Ğ318.
Schmid H. (1994). Probabilistic part-of-speech tagging using decision trees. In Procee-
dings of International Conference on New Methods in Language Processing.
Schwenk H. (2007). Continuous space language models. Computer Speech and Lan-
guage, 21, 492Ğ518.
Schwenk H., Costa-jussa` M. R. & Fonollosa J. A. R. (2006). Continuous
space language models for the IWSLT 2006 task. In International Workshop on Spoken
Language Translation, p. 166Ğ173.
Stolcke A. (2002). SRILM - an extensible language modeling toolkit. In International
Conference on Speech and Language Processing, p. II : 901Ğ904.
262
