TALN 2007, Toulouse, 5—8juin 2007

Evaluation des performances d’un modele de langage
stochastique pour la comprehension de la parole arabe spontanée

Anis ZOUAGHI1, Mounir ZRIGUI1, Mohamed BEN AHMED2

1 Labo RIADI (Unite de Monastir)
Universite de Monastir, Faculte des sciences de Monastir
2 Labo RIADI — Universite de la Marmouba,
Ecole nationale des sciences de 1’informatique

Anis.Zouaghi@riadi.rnu.tn, Mounir.Zrigui@fsm.rnu.tn,
Mohamed.Benahmed@riadi.rnu.tn

Résumé. Les modeles de Markov caches (HMM : Hidden Markov Models) (Baum et al.,
1970), sont tres utilises en reconnaissance de la parole et depuis quelques annees en
comprehension de la parole spontanee latine telle que le francais ou l’anglais. Dans cet article,
nous proposons d’utiliser et d’evaluer la performance de ce type de modele pour
l’interprétation semantique de la parole arabe spontanee. Les resultats obtenus sont
satisfaisants, nous avons atteint un taux d’erreur de l’ordre de 9,9% en employant un I-IMM a
un seul niveau, avec des probabilites tri_grammes de transitions.

Abstract. The HMM (Hidden Markov Models) (Baum et al., 1970), are frequently used in
speech recognition and in the comprehension of foreign spontaneous speech such us the
french or the english. In this article, we propose using and evaluating the performance of this
model type for the semantic interpretation of the spontaneous arabic speech. The obtained
results are satisfying; we have achieved an error score equal to 9.9%, by using HMM with tri-
grams probabilities transitions.

Mots-clefs 2 analyse semantique, modele de langage stochastique, contexte pertinent,
information mutuelle moyenne, parole arabe spontanée.

Keywords: semantic analysis, stochastic language model, pertinent context, overage
mutual information, spontaneous arabic speech.

1 Introduction

On distingue deux grands courants d'approches pour la comprehension de la parole: les
approches symboliques linguistiques (ou par regles), et les approches stochastiques. Le
premier type d’approches se base sur une representation prealable de la grammaire. Pour
decrire cette grammaire, on utilise generalement l’un des formalismes existants tels que:
HPSG, les grammaires lexicales fonctionnelles (LFG), etc. Quand au deuxieme type

303

Anis ZOUAGHI, Mounir ZRIGUI, Mohamed BEN AHMED

d’approche, les regles sont de'duites directement a partir d’un corpus d’apprentissage. Depuis
quelques annees, la tendance est Vers l’utilisation des modeles de langages stochastiques dans
le domaine de la comprehension de la parole spontanee (Schwartz et al., 1996), (Minker,
1999), (Bousquet, 2002), etc. Cette tendance s’explique par le faite que les approches
stochastiques offrent une alternative efficace aux approches par regles, concernant le coﬁt
global de de'Veloppement du modele, et la portabilite Vers d’autres domaines. De plus, du fait
que le locuteur parle d’une maniere spontane'e, les fautes de syntaxe ou de grammaire sont
beaucoup plus fre'quentes a l’oral qu'a l'e'crit. C’est pour cela, qu’une analyse portant
uniquement sur la syntaxe n’est souvent pas efficace. Ainsi, certains proposent pour faire face
a ce probleme, une analyse plus ﬁne des phe'nomenes linguistiques de l’oral tels que (Van
Noord et al., 1999) et (Antoine et al., 2003), ou une combinaison d'une analyse syntaxique et
semantique tels que (Villaneau et al., 2001), (Seneff, 1992), etc. Contrairement a la langue
latine, la comprehension automatique de la parole arabe spontanee reste encore tres peu
abordee au niveau de la recherche scientiﬁque. Durant les deux dernieres de'cennies les efforts
ont e'te plutot concentres sur la re'alisation des analyseurs morphologiques et syntaxiques pour
l’arabe tel que (Ouersighni, 2001). Malgre l’importance de la representation et de l’analyse
se'mantique pour la realisation de n’importe quel systeme de comprehension, il n’existe que
quelques travaux qui s’interessent a ce domaine en Vue du traitement automatique de la
langue arabe e'crite et non pas parlee tels que (Haddad et al., 2005), (Meftouh et al., 2001),
etc. Dans cet article, nous pre'sentons le modele de langage stochastique employe' pour
l’analyse se'mantique de la parole arabe spontane'e dans le cadre d’une application f1nalise'e,
ainsi que les re'sultats d’e'Valuation obtenus.

2 L’applicati0n ﬁnalisée considérée

2.1 Le domaine de Papplication

Pour tester et estimer les parametres du modele de langage stochastique, nous avons utilise’ un
corpus repre'sentant le domaine des renseignements ferroviaires. La principale raison de ce
choix est la taille statistiquement representative du corpus d’apprentissage dont nous
disposons (Voir tables 1 et 2). Ce corpus a e'te collecte' en demandant a cent personnes
differentes de formuler des enonces relatifs aux renseignements ferroviaires. Donc c’est un
corpus simule et non pas re'el.

l_')-r.m1nin:: 'l21‘Jll<: (,\'1¢‘!1 Ntrlnlwics 1'-luI11hrc dc: IN nmhre: dz:
d llwzmccs; l1"It>I!~'- 1ocu(cLIrs:
Rcns-:cig.I'JcI11<:I1ts; tbI'L'cw1':aIrL=s; .3‘. ..E Iéffffféf <‘1’5E1fJ'f.' .?FJ'FJ'€}

Table 1 : Caracteristiques du corpus de point de Vue Volume.

Nature dc la téicln: l<’.u:|1s<.:igm:n1u:nts sur les: R¢5<:1'\'ati0|1s autrcs

’['uLIx do 53 |]0|'ui1'<:s; trzijcts tarifs durécs 10.41 "0 —/(1.6-£‘%;
rep1'és<:|1tati0|1

2b’.''‘’/» 9._?"% 16.66% 3.12%

Table 2 : Caracteristiques du corpus de point de Vue contenu.

304

Evaluation des performances d’un modele de langage stochastique

2.2 Le corpus d’apprentissage

Le modele de langage va servir a attribuer a chaque mot de l’enonce transcrit par le module
de reconnaissance de la parole un couple de traits semantiques note TS. Chaque couple TS est
constitue de deux traits elementaires : TS = (classe semantique TSC, trait micro semantique
TSM). Le premier trait sert a determiner la classe semantique a laquelle appartient le mot a
interpreter. Par exemple, toutes les villes du reseau ferroviaire sont representees par la classe
semantique ‘\-‘e-M "medina "(ville). Pour l’application consideree, nous avons utilise en tout
12 classes semantiques differentes (voir table 3 ci-dessous).

Classes semantiques TCS Exernples d'instanciations
3?}

)3 etc.

J=_)-3_‘»- (Indice_rnouvernent) (&)- ;>'- (vers)- J.‘ (51 travers)- 9- (de)- etc.

etc.
etc.
.9» (sousse)- u-3.93 (Tunis)- etc.
J (et)- etc.
as 7 2 g;

an (bruit) ' (que)- (joume'e)- etc.

= 1.95 (type_bi11et)

=4: (nombre)

 

Table 3 : Les classes semantiques considerees.

La methode d’identiﬁcation ou d’extraction de ces classes est presentee dans le paragraphe
suivant (2.3). En ce qui concerne le deuxieme trait du couple TS, c’est un trait micro
semantique qui permet de differencier le sens des mots appartenant a une meme classe
semantique. Par exemple, ce trait permet de distinguer une ville de depart d’une ville de
destination dans un enonce donne. Nous signalons que les mots synonymiques ou possedant
un meme r6le semantique possedent le meme couple de traits TS. Le nombre total des traits
micro semantiques TMS utilises est 20 traits, soit presque le double des TCS. Ces traits sont
les suivants: An _ ~.-U= (demande_generale) - o-5 _ e-IL (demande_prix) — 425:3 _ e.-IL
(demande_horaire) — 34+; (destination) — é>\-‘ail (depart) — J35‘ (correspondance) — U?->|
(moment) — in-la (heure) — 5-.9‘-'« (date) — us (jour) — 3-ma (classe) — etc. Ainsi, pour estimer
les parametres du modele de langage stochastique, nous avons cree un corpus d’apprentissage
(voir ﬁgure 1). Ce corpus a ete obtenu en etiquetant au debut manuellement une quantite
(500) des enonces du corpus collecte par un expert humain. Le principe d’etiquetage est
d’attribuer a chaque mot signiﬁcatif pour l’application un couple TS tel que deﬁni ci haut.
Les mots non signiﬁcatifs ou vides sont elimines lors de la phase du pretraitement du corpus

305

Anis ZOUAGHI, Mounir ZRIGUI, Mohamed BEN AHMED

initial, et certains mots sont regroupés en une seule entrée. L’élimination des mots vides nous
a permis de simpliﬁer la complexité et réduire la taille du modele. Ensuite, nous avons
appliqué ce modele pour l’étiquetage sémantique des 9000 énoncés restants, et ce par groupes
de 500. Entre chaque étape d’étiquetage automatique, nous avons procédé a une veriﬁcation
des résultats obtenus et une correction des parametres a été établie chaque fois qu’il y a une
détection d’erreurs. Enfn, les 500 énoncés restants nous ont servi pour l’évaluation de la
performance du modele. Ainsi, 95% du corpus a été consacré £1 l’apprentissage et 5% aux
tests.

     
 
    

Corpus repre'sematif de
l’application ﬁ11alise'e

      
   

Expert humaiu

Corpus
prétra ite'

     
 

   

Estimation des Ensembles des
, ......... .. couples TS

parametres __________________ "

Corpus """"" '-

e'tiquete'

"""" -- Reconnaissance de la arole
laugage .... _.   V
 $ parole MW
Analyse
se'1na11tique

Figure 1 : Principe de l’estimation des parametres du modele de langage.

Les ﬂeches en pointillés dans la ﬁgure 1, correspondent aux informations qui dépendent du
domaine de l’application a modéliser.

2.3 L’extraction des classes sémantiques

Pour extraire les classes sémantiques de l’application, nous avons appliqué l’algorithme des
K-means proposé par (McQueen, 1967), en utilisant l’information mutuelle moyenne IMm de
(Rosenfeld, 1994) au lieu de la distance euclidienne pour mesurer la distance sémantique
entre les différents mots du vocabulaire de l’application ﬁnalisée. Ceci, nous a amené £1
remplacer dans l’algorithme le critere d’évaluation arg min,-= 1, Wk d2(m,-, cgy) par arg max,-= 1,
Wk d(m,-, cgj) (voir ﬁgure 2). A part que cet algorithme, permet de faciliter la tache
d’identiﬁcation des classes sémantiques, il a l’avantage d’étre :

- Rapide face a des données de taille importante, puisqu’il converge a une vitesse linéaire de
l’ordre de O(n.k.t); ou n, k et t désignent respectivement le nombre des mots a classer, le
nombre des classes sémantiques et le nombre d’itérations maximales.
- Et simple 51 implémenter.

Presentation de l’algorithme des k-means : -
Choisir d’une maniere arbitraire les centres de gravite’ (cgl, cg2, cg3, ..., cgk) des k classes sémantiques
(cs1, cs2, cs3, ..., csk).

De'but

- Etiquette :

Pour tout mot mi de ml 51 mn faire
Chercher la classe csk du mot mi en question :
csk = arg maXj=1, ...;. d(m,, cgj);
0111, d (mi, cgj) = IMm(mi, cgj) = P(mi, cgj)x Log [P(mi / cgj) / P(mi).P(cgj)] + P(n'u', @)x Lo_g
[P(n—1i / cgj) / P(1T1).P(cgj)] +_P(mi, cE)x Log [P(n1i / cﬁ) / P(mi).P(c-gj)] + P(n1i,

306

Evaluation des performances d’un modele de langage stochastique

cgj)x Log [P(n1i / cgj) / P(mi).P(cgj)]

Recalculer 1e centre de gravite' de la classe csk :

cgk = 1/Nk Zmiwk mi ; oil Nk de'signe dans cet algorithme 1e nombre de mots dans la classe csk.
Fin Pour.
- Arret du traitement si les centres de gravite’ sont inchanges.
- Retoumer £1 Etiquette sinon.
Fin

Figure 2 : l’algorithme des k-means en utilisant l’IMm comme metrique.

Cependant, le probleme principal de cette methode est la dependance du resultat du
classement ﬁnal des informations donnees en entree (les k centres de gravite des k classes
semantiques a determiner sont choisis d’une maniere totalement arbitraire). Cette limite ne
pose pas de problemes pour nous, puisque nous avons utilise cette methode rien que pour
aider et donner une idee a l’utilisateur (surtout si cet utilisateur n’est pas un expert du
domaine) sur la classiﬁcation possible des mots de l’application d’un point de vue
semantique. Cependant les cartes auto organisatrices de (kohonen, 1989) oﬂ-‘rent une
alternative efﬁcace, pour ceux qui cherchent des meilleurs resultats de partitionnement
(J amoussi, 2004).

3 Modélisation stochastique

3.1 Description du systéme de comprehension

Le systeme de comprehension concu permet de construire la representation semantique d’un
enonce, sous la forme d’un ensemble d’associations attributs/valeurs (ou formulaire), comme
le montre l’exemple suivant : Enonce transcrit : .9»-U3 El ~.M55‘ J94“-.' J54 in -‘eul "ouridou
hajza makan bilqitar athaheb ila tuwnis" -) I e veux reserver une place dans le train allant a
Tunis.

Representation semantique : 1+-—;3('Iype) = 3.» +41: (demande de reservation)

:.§3\-‘=3‘_3-‘*a¢- (ville_ depart) = &Vil1ecouIante

:33‘-‘=3‘_ we (jour_ depart) = ‘.7

:33‘-‘=3‘_ ‘sh (heuIe_ depart) = ‘.7

31+; _3-‘HM (ville_ destination) = mini (Tunis)

Juli-_A== (nombre_places) = 1
La ﬁgure 3 ci-dessous, presente l’architecture generale du systeme de comprehension. On
remarque bien que la deduction du sens d’un enonce par ce systeme est le resultat de
l’accomplissement des traitements successifs suivants :
- La segmentation de l’enonce transcrit par le module de reconnaissance de la parole : ce
traitement permet d’identiﬁer les mots ainsi que les differentes phrases du message du
locuteur. Un meme message peut étre constitue d’un ou plusieurs requétes a la fois. D’ou, il
est necessaire que le systeme puisse identiﬁer les differentes requétes du message, aﬁn qu’il
puisse interpreter la demande de l’utilisateur dans toute son integralite.
- Le pretraitement de l’enonce : ce pretraitement consiste comme pour le pretraitement du
corpus collecte a eliminer par exemple les mots vides, a regrouper certains mots en une seule
entree, etc. Ce modele permet de simpliﬁer la complexite de la tache de comprehension.
- Le decodage semantique de l’enonce : c'est-a-dire l’etiquetage de chaque mot de l’enonce
pretraite avec les couples TS correspondants.
- La construction du sens de l’enonce, cette etape correspond a la phase de generation de

307

Anis ZOUAGHI, Mounir ZRIGUI, Mohamed BEN AHMED

l’ensemble des paires attribut/valeur (ou formulaire).

Le décodage sémantique des énoncés prétraités repose sur un modele de langage stochastique
qui permet d’encoder les regles de la grammaire (voir paragraphe suivant) et sur un lexique
sémantique décrit dans un ﬁchier et contient tous les mots du vocabulaire de l’application. Ce
lexique est un ensemble d’associations de la forme : Mot M / TS décrivant le sens du mot +
P(W/ TSC, TSM) qui est la probabilité d’utilisation de TS = (TSC, TSM) pour la description
du sens du mot M.

Emmmg Enoncc

Prétrailcmcnt dc Fénoncé prémiilé Décodagc sémamiquc déwdé
Emma; - ._ V _
scgmcmé Modglc dc langagc Lcxiquc scmanuquc
slochasliquc

      
  

 
  

   

Enoncé rcconnu Construction du sens de

1‘énoncé

l

lmcrprcunion dc Fcnoncc sous
la formc d’un formulairc.

    
 

  
       

    

Segmentation

Figure 3 : Architecture du systéme de comprehension

3.2 Le modéle de langage

3.2.1 Le principe du décodage

Le modele de langage que nous présentons ici, permet d’attribuer a chaque mot signiﬁcatif un
couple TS permettant de décrire sons sens. Comme nous l’avons signalé auparavant, nous
avons choisi de représenter ce modele a l’aide d’un modele de Markov caché. Le principe du
décodage sémantique est le suivant :
Nous considérons un énoncé constitué d’une suite de n mots : W = wl w2  wn
Cette suite de n mots est réduite a une suite de m mots apres la phase du prétraitement de
l’énoncé (élimination et regroupement de certains mots), ou m S n: W = wl w2  wm
Supposons que cette suite a été décodée via la suite de in couples de traits sémantiques
suivante:TS=TS1TS2...TSm, ou encore TS= (TSC1,TSM1)(TSC2,TSM2). . .(TSCm, TSMm).
Le but est alors de trouver les meilleures suites TS‘ connaissant W. Cette probabilité est
calculée grace au critere du maximum a posteriori : P(TS’ / W‘) = Max Ts P(TS / W) =
Max TSCXTSM  TSM / W)
Ce qui donne en appliquant la formule de Bayes : P(TSC, TSM / W) = P(W / TSC, TSM) x
P(TSC, TSM) / P(W)
Nous avons ensuite utilisé l’algorithme de Viterbi (Rabiner et al., 1986), pour réaliser ce
décodage.

3.2.2 La topologie du modéle

Nous avons considéré un modele de Markov caché (H1VlM) a un seul niveau pour réaliser
notre décodeur (voir ﬁgure 4). Chaque état du modele markovien représente un couple TS et

308

Evaluation des performances d’un modele de langage stochastique

les probabilites de transitions representent les probabilites de passage d’un TS vers un autre.
L’interpretation d’un mot depend du contexte de l’enonce, c’est-a-dire des relations de
dependances qu’il entretient avec les autres mots de l’enonce. Comme ll montre la ﬁgure 4
suivante, nous avons considere un HMM avec des probabilites tri-grammes de transitions
entre les couples de traits semantiques TSi des mots. Ce modele contribue ainsi a la prediction
d’un couple de traits semantiques TSi a partir des deux couples precedents TSi-1 et TSi-2.

 

Figure 4 : Exemple de modélisation £31 1’aide d’un modéle de Markov cache
:31 un niveau avec des probabilités tri-grammes de transitions entre les TSi

La realisation de ce modele necessite principalement deux types d’informations :

- La maniere d’agencement des couples TSi entre eux, sous la forme de probabilites tri-
grammes de transitions entre les TSi :

P(TSi / TSi-1, TSi-2) = N (TSi, TSi-1, TSi-2) /N (TSi-1, TSi-2) ; o1‘1N (TSi, TSi-1,TSi-2)
(resp. N (TSi-1, TSi-2)) est le nombre d’occurrence de TSi, TSi-1 et TSi-2 (resp. TSi-1 et
TSi-2) ensemble.

- Et la probabilite d’emission de chaque mot du vocabulaire de l’application par chacun des
couples TS deﬁnis. Un mot peut étre decrit semantiquement par plusieurs couples TS.

P (W/ TS) = N (W, TS) /N (TS) ; ou N (W, TS) est le nombre fois de description de W par
TS et N (TS) est le nombre total d’utilisation de TS.

3.2.3 Amélioration du modéle

En remarquant que ce n’est pas obligatoirement les mots precedant immediatement le mot a
interpreter qui ont une inﬂuence semantique sur ce dernier, nous avons decide d’employer
lors de la phase de decodage du sens d’un mot que les TS des deux mots possedant la plus
grande affnite semantique avec celui-ci. Pour atteindre cet objectif, nous nous sommes bases
sur la notion d’information mutuelle moyenne (Rosenfeld, 1994) qui permet de calculer le
degre de correlation ou de co-occurrence de deux mots donnes. Cette methode nous a permis
de ne plus utiliser systematiquement les TS des deux mots qui precedent immediatement le
mot a decoder.

309

Anis ZOUAGHI, Mounir ZRIGUI, Mohamed BEN AHMED

4 Application du modéle et résultats

Pour tester la performance du modele stochastique déﬁni, nous avons utilisé les 500 énoncés
du corpus collecté qui n’ont pas été employés lors de la phase d’estimation des paramétres du
modele de langage stochastique (voirparagraphes 2.1 et 2.2). Nous avons utilisé comme
mesures de performances : - -
Le nombre total de mauvaises interpretations Nf déﬁni comme suit : Nf = Ncs + NMS, ou Ncs
et NMS sont respectivement 1e nombre de TSC et le nombre de TSM incorrectement attribués
par le systeme aux mots de 1’énoncé.

- Le taux d’erreur du décodage sémantique : Tauxmu, = Nf/ N ; ou N est le nombre total de
traits TSC et TSM attribués a 1’énoncé a interpréter.

- Le taux de précision est : Tauxprécision = Nc /N ; ou Nc est le nombre des traits TSC et TSM
correctement attribués.

La ﬁgure 5 suivante, présente les taux d’erreur et de précision trouvés. Ces taux sont répartis
selon le type de renseignement demandé par 1’uti1isateur : demande de réservation (DR), ou
de renseignements sur le traj et (DT), 1’horaire (DH), 1e prix (DP), ou la durée du voyage
(DD). On peut toujours aussi relever 1e taux d’erreurs des énoncés incorrectement décodés
sémantiquement, en considérant 1e rapport entre les énoncés mal interprétés et le nombres
total d’énoncés considérés dans le test (ici 500).

'1EIEI‘M-. 01%
9 .
3 5.4% 37%

    

Figure 5 : Taux d’erreur et de précision selon le type de la demande de 1’uti1isateur
et le nombre d’én0ncés appris.
Le taux d’erreur réellement trouvé lors de la mesure de la performance de notre systéme est
de 1’ordre de 21,1%. En analysant davantage les résultats, nous avons conclu qu’un mauvais
décodage est obtenu chaque fois qu’i1 y a un manque de données d’apprentissage. La ﬁgure 5
ci-dessus illustre bien ceci. En effet, d’apres cette ﬁgure, nous remarquons que les résultats de
décodage sont bons dans presque tous les types de renseignements demandés par 1’uti1isateur
(DT, DR, DP et DH). Le plus mauvais décodage correspond aux énoncés de type DD. Ceci
est dﬁ au fait, que le nombre des énoncés DD considérés (3,12% du corpus) lors de la phase
d’apprentissage du modele de langage est insufﬁsant. En effet, nous avons constaté que
seulement a partir de 1000 énoncés appris que notre systéme devienne performant. A partir de
ce seuil, 1e taux d’erreur est inférieur a 11%. Au dessous de la barre de 500 énoncés, les
résultats deviennent inacceptables. Le taux d’erreurs atteint 36,7% pour 296 énoncés appris,
alors qu’i1 se restreint a 9,9% pour 2726 énoncés appris (voir ﬁgure 5). Donc, une mauvaise
interpretation par notre systéme est due essentiellement a un manque de données
d’apprentissage, et non pas au type ou a la topologie du modele de langage utilisé. Nous
avons aussi comparé ce modele de langage employé par rapport a un modéle de langage avec
des probabilités bi-grammes de transitions entre les TSi (1) et un modele de langage avec des
probabilités tri-grammes de transitions sans amélioration (2) (c-a-d sans considération des TS

310

Evaluation des performances d’un modele de langage stochastique

des 2 mots inﬂuant semantiquement sur le mot a interpreter). Nous avons trouve que modele
(1) est efﬁcace seulement lorsque le corpus d’apprentissage n’est pas assez volumineux (voir
ﬁgure 6). En effet, plus l’ordre n d’un modele n-grammes est petit, moins on a besoin de
donnees d’apprentissage. Donc le modele (1) peut étre une alternative efﬁcace au modele
utilise (avec tri-grammes de transitions ameliore), dans le cas ou on ne dispose pas de corpus
assez volumineux representatif du domaine de l’application a modeliser. Mais nous avons
constate que des qu’il y a occurrence d’hesitations ou de mots inconnus precedant le mot a
interpreter les modeles (1) et (2) deviennent aussi inefﬁcaces.
tau>< d'erreur

39.4%

32%

28%

 

nomhre
200 400 500 300 1000 1200 1400 1600 1800 2000 d-énoncég
. Modele de Markov avec bi—gramme de transitions entre les TS

Z-j Modele de Markov a\rectri—grarnmes de transitions et avec consideration du contexte pertinent.

fa: modele de Markov a\:ectri—grammes de transitions sans consideration du contexte pertinent.

Figure 6: Resultats de decodage obtenus en utilisant des modeles de Markov avec bi-
grammes et tri-grammes de transitions avec et sans consideration du contexte pertinent.

5 Conclusion

Nous avons presente dans cet article le modele de langage stochastique que nous avons
employe pour le decodage semantique de la parole arabe spontanee. Pour cela, nous avons
utilise un modele de Markov cache a un seul niveau, avec des probabilites tri-grammes de
transitions entre les couples de traits semantiques TS. L’evaluation du modele, en l’appliquant
dans le domaine des renseignements ferroviaires a montre son efﬁcacite. Nous avons atteint
un taux de precision de l’ordre de 90,1% avec 2726 enonces appris de type demandes
d’horaires. Nous avons montre qu’en cas de manque de donnees d’apprentissage, un modele
de Markov cache a un seul niveau, avec des probabilites bi-grammes de transitions entre les
TS est plus puissant. Ceci est vrai malheureusement que dans le cas d’enonces non spontanes,
c'est-a-dire ne contenant ni des hesitations ni des mots inconnus. Pour identiﬁer les couples
TS a employer pour l’interpretation des mots de l’enonce, nous avons employe l’information
mutuelle moyenne IMm de (Rosenfeld, 1994). Pour faciliter la tache d’extraction des traits
TSC d’une application, nous avons utilise l’algorithme de partitionnement des K-means
propose par (McQueen, 1967). Cependant comme nous l’avons deja signale, nous avons
utilise cette methode rien que pour aider et donner une idee a l’utilisateur sur la classiﬁcation
possible des mots de l’application d’un point de vue semantique. Cependant les cartes auto
organisatrices de (kohonen, 1989) offrent une alternative efﬁcace, pour ceux qui cherchent
des meilleurs resultats de partitionnement (J amoussi, 2004).

311

Anis ZOUAGHI, Mounir ZRIGUI, Mohamed BEN AHMED

Références

ANTOINE J-Y., GOULIAN J., VILLANEAU J. (2003), Quand le TAL robuste s’attaque au langage
parlé: analyse incrémentale pour la compréhension de la parole spontanée, Actes de TALN.

Baum L.E., Petrie T., Soules G., Weiss N. (1970), A maximisation technique occurring in
statistical analysis of probabilistic functions in Markov chains, The Annals of Mathematical
Statistics.

BOUSQUET-VERNHETTES C. (2002), Comprehension robuste de la parole spontanée dans le
dialogue oral homme-machine — Décodage conceptuel stochastique, These de doctorat de
l ’universite' de Toulouse III.

HADDAD B., YASEEN M. (2005), A Compositional Approach Towards Semantic
Representation and Construction of ARABIC, Actes de LACL.

JAMOUSSI S. (2004), Méthodes statistiques pour la compréhension automatique de la parole,
These de doctorat de l’universite’ Henri Poincare’.

Kohonen T. (1998), Self-organisation and associative memory. Berlin, Spring-Verlag.

McQueen J. (1967), Some methods for classiﬁcation and analysis of multivariate
observations, Actes de the Berkeley Symposium on Mathematical Statistics and Probability.

MEFTOUH K., LASKRI M.T. (2001), Generation of the Sense of a Sentence in Arabic
Language with a Connectionist Approach, Actes de AICCSA.

MINKER W. (1999), Comprehension automatique de la parole spontanée, Paris, L’Harmattan.

OUERSIGHNI R. (2001), A major offshoot of the Dinar-MBC project: AraParse, a
morphosyntactic analyzer for unvowelled Arabic texts, Actes de ACL/EA CL.

Rabiner L.R., J uang B.H. (1986), Introduction to Hidden Markov Models, IEEE Transactions
on Acoustics, Speech and Signal processing.

ROSENFELD R. (1994), Adaptive statistical language modelling: A maximum entropy
approach., These de doctorat de l ’université de Carnegie Mellon.

Schwartz R., Miller S., Stallard D., Makhoul J. (1996), Language Understanding Using
Hidden Understanding Models, Actes de ICSLP.

SENEFF S. (1992), Robust parsing for spoken language systems, Actes de ICASSP, 189-192.

Van Noord G., Bouma G., Koeling R., Nederhof M.J. (1999), Robust grammatical analysis
for spoken dialogue systems, Natural Language Engineering 5(1).

Villaneau J ., Antoine J .Y., Ridoux O. (2001), Combining Syntax and Pragmatic Knowledge
for the Understanding of Spontaneous Spoken Sentences, Actes de LACL ’0I.

312

