<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Comparaison de m&#233;thodes lexicales et syntaxico-s&#233;mantiques dans la segmentation th&#233;matique de texte non supervis&#233;e</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2008, Avignon, 9&#8211;13 juin 2008
</p>
<p>Comparaison de m&#233;thodes lexicales et syntaxico-s&#233;mantiques
dans la segmentation th&#233;matique de texte non supervis&#233;e
</p>
<p>Alexandre Labadi&#233;1 Violaine Prince1
</p>
<p>(1) LIRMM, 161 rue ADA, 34392 Montpellier cedex
labadie@lirmm.fr, prince@lirmm.fr
</p>
<p>R&#233;sum&#233;. Cet article pr&#233;sente une m&#233;thode bas&#233;e sur des calculs de distance et une analyse
s&#233;mantique et syntaxique pour la segmentation th&#233;matique de texte. Pour &#233;valuer cette m&#233;thode
nous la comparons &#224; un un algorithme lexical tr&#232;s connu : c99. Nous testons les deux m&#233;thodes
sur un corpus de discours politique fran&#231;ais et comparons les r&#233;sultats. Les deux conclusions qui
ressortent de notre exp&#233;rience sont que les approches sont compl&#233;mentaires et que les protocoles
d&#8217;&#233;valuation actuels sont inadapt&#233;s.
</p>
<p>Abstract. This paper present a semantic and syntactic distance based method in topic
text segmentation and compare it to a very well known text segmentation algorithm : c99. To
do so we ran the two algorithms on a corpus of twenty two French political discourses and
compared their results. Our two conclusions are that the two approaches are complementary
and that evaluation methods in this domain should be revised.
</p>
<p>Mots-cl&#233;s : Methodes d&#8217;&#233;valuation, segmentation de texte, segmentation th&#233;matique.
</p>
<p>Keywords: Evaluation methods, text segmentation, topic segmentation.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre Labadi&#233;, Violaine Prince
</p>
<p>Introduction
</p>
<p>Il existe beaucoup de t&#226;ches dites de &#171;segmentation de texte&#187;. Par exemple, la recherche et
l&#8217;extraction de textes dans des documents multim&#233;dia, o&#249; le texte est m&#233;lang&#233; &#224; de la vid&#233;o
et de l&#8217;image, sont des t&#226;ches assimil&#233;es &#224; la &#171;segmentation de texte&#187; (Karatzas, 2003). Re-
grouper des mots en morph&#232;mes, ou en unit&#233;s linguistiques plus importantes, est aussi nomm&#233;
segmentation de texte (par exemple, dans le traitement des langues asiatiques, qui utilisent des
id&#233;ogrammes, les fronti&#232;res des mots sont difficiles &#224; d&#233;terminer(Wu &amp; Tseng, 1993), (Yang &amp;
Li, 2005)). Dans cet article, nous nous int&#233;ressons &#224; la &#171;segmentation th&#233;matique de texte&#187;,
c&#8217;est &#224; dire &#224; l&#8217;op&#233;ration qui a pour but de trouver la structure th&#233;matique (Hearst &amp; Plaunt,
1993) d&#8217;un texte et d&#8217;en proposer une d&#233;composition par th&#232;me (Ponte &amp; Croft, 1997). Si la
plupart des textes traitent d&#8217;un sujet unique, ils abordent en g&#233;n&#233;ral plusieurs th&#232;mes en leur
sein. Plus le texte est volumineux, plus il est probable que ses th&#232;mes, ou sous-th&#232;mes d&#8217;un su-
jet donn&#233;, soient nombreux. Fondamentalement, la segmentation th&#233;matique de texte recherche,
au sein d&#8217;un texte, le d&#233;but et la fin des th&#232;mes. Pour des raisons pratiques, nous utiliserons pour
le reste de cet article le terme &#171;segmentation th&#233;matique&#187; plut&#244;t que segmentation th&#233;matique
de texte.
Si l&#8217;on consid&#232;re que la segmentation th&#233;matique doit diviser le document en plusieurs seg-
ments coh&#233;rents et distincts sur le plan th&#233;matique, alors chaque segment ne doit id&#233;alement
traiter que d&#8217;un seul th&#232;me. Mais un th&#232;me est une unit&#233; complexe sur le plan rh&#233;torique, qui
n&#233;cessite souvent des digressions, des exemples et des argumentations.
Ce qui nous am&#232;ne &#224; nous poser la question de la d&#233;finition de la notion de th&#232;me. Dans la litt&#233;-
rature, nous en trouvons plusieurs d&#233;finitions. En g&#233;n&#233;ral, un th&#232;me est : le sujet d&#8217;une conver-
sation ou d&#8217;une discussion (d&#233;finition du dictionnaire). En linguistique, on le d&#233;finit comme :
l&#8217;&#233;l&#233;ment d&#8217;un &#233;nonc&#233; qui est r&#233;put&#233; connu par les participants &#224; la communication (on l&#8217;op-
pose souvent au rh&#232;me qui est l&#8217;information nouvelle apport&#233;e par l&#8217;&#233;nonc&#233;). Nous admettrons
ici que le th&#232;me d&#8217;un segment de texte est ce dont il parle. La segmentation th&#233;matique doit
donc diviser le texte en portions dont chacune des phrases &#171;parle&#187; de la m&#234;me chose que les
autres.
Dans cet article nous comparons Transeg, notre m&#233;thode de segmentation th&#233;matique bas&#233;e
sur des calculs de distance et une analyse s&#233;mantique et syntaxique a priori, &#224; c99, un algo-
rithme de r&#233;f&#233;rence &#224; l&#8217;heure actuelle dans le domaine. Nous voulons d&#233;terminer l&#8217;importance
des informations d&#8217;ordre s&#233;mantique et syntaxique port&#233;es par les phrases, qui sont les &#233;l&#233;ments
constitutif du texte, dans le cadre de la segmentation th&#233;matique. Notre m&#233;thode tient compte de
cette information, alors que c99 est essentiellement de granularit&#233; lexicale. Nous pr&#233;senterons
les deux approches test&#233;es ici dans une premi&#232;re partie, pour examiner en d&#233;tail leur r&#233;sultats
respectifs sur notre corpus de discours politiques. Nous conclurons sur la validit&#233; des m&#233;thodes
d&#8217;&#233;valuation de segmentation th&#233;matique et les possibilit&#233;s d&#8217;&#233;volution de Transeg.
</p>
<p>1 Pr&#233;sentation des m&#233;thodes compar&#233;es.
</p>
<p>1.1 C99
</p>
<p>D&#233;velopp&#233; par Choi (Choi, 2000), c99 est un algorithme de segmentation th&#233;matique s&#8217;appuyant
fortement sur la notion de coh&#233;sion lexicale (Morris &amp; Hirst, 1991). C&#8217;est un des algorithmes
donnant les meilleurs r&#233;sultats dans le domaine de la segmentation th&#233;matique (Bestgen &amp; Pi&#233;-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Comparaison de m&#233;thodes lexicale et syntaxico-s&#233;mantique dans la segmentation th&#233;matique
non supervis&#233;e
</p>
<p>rard, 2006).
C99 s&#8217;appuie sur une matrice de similarit&#233; entre les phrases du texte. D&#8217;abord projet&#233;es dans
l&#8217;espace des mots du texte, les phrases sont ensuite compar&#233;es deux &#224; deux &#224; l&#8217;aide d&#8217;une me-
sure de similarit&#233; (en g&#233;n&#233;ral le cosinus) pour former une matrice de similarit&#233;. Plus r&#233;cemment,
Choi &#224; am&#233;lior&#233; c99 en y adjoignant une analyse s&#233;mantique latente (LSA), afin de r&#233;duire l&#8217;es-
pace des mots &#224; un espace de &#171;concepts&#187; (Choi et al., 2001).
L&#8217;originalit&#233; de Choi est de ne pas travailler directement sur la matrice de similarit&#233;, mais sur
une matrice de classement locaux. Chaque case de la matrice est compar&#233;e aux cases environ-
nantes (leur nombre d&#233;pendant de la taille du masque appliqu&#233;, qui est param&#233;trable), et obtient
un score en fonction du nombre de cases ayant un score de similarit&#233; inf&#233;rieur. Evidmement ces
rangs, ainsi nomm&#233;s par Choi, sont normalis&#233;s par le nombre de cases effectivement comprises
dans le masque pour &#233;viter les effets de bord.
La recherche des fronti&#232;res de th&#232;me se fait en optimisant la densit&#233; de sous-matrices le long
de la diagonale de la matrice de rang, de mani&#232;re r&#233;cursive. L&#8217;algorithme s&#8217;arr&#234;te lorsque la
fronti&#232;re id&#233;ale d&#233;sign&#233;e par l&#8217;algorithme est la derni&#232;re phrase de la matrice courante ou, si
l&#8217;utilisateur fournit un maximum en param&#232;tre &#224; l&#8217;algorithme, quand le nombre maximum de
fronti&#232;res est atteint.
La plupart des approches bas&#233;es sur la coh&#233;sion lexicale n&#8217;utilisent que peu (voir pas) d&#8217;infor-
mation syntaxique ou s&#233;mantique. C99 ne fait pas exception. L&#8217;ajout d&#8217;une LSA en pr&#233;traite-
ment du texte introduit certes un peu de s&#233;mantique, mais cela reste au niveau lexical, et ne
gomme que partiellement ce d&#233;faut d&#8217;informations s&#233;mantiques. Les informations syntaxiques
sont ignor&#233;es.
</p>
<p>1.2 Transeg
</p>
<p>Nous avons d&#233;velopp&#233; une m&#233;thode de segmentation th&#233;matique, appel&#233;e Transeg, que nous
avons voulu la plus sensible possible aux variations th&#233;matiques intra-textuelles. Elle part de
l&#8217;hypoth&#232;se que le texte est constitu&#233; par des phrases, qui &#224; leur tour, ne sont pas jet&#233;es en
vrac, mais produites et ordonn&#233;es selon une intention discursive. D&#232;s lors, les informations
de position et de construction de ces derni&#232;res sont importantes pour la reconnaissance des
fronti&#232;res, aussi bien que de la structure des th&#232;mes qui jalonnent le document.
Les travaux pr&#233;liminaires qui ont servi &#224; l&#8217;&#233;laboration de Transeg ont &#233;t&#233; &#233;valu&#233;s lors de du d&#233;fi
DEFT&#8217;06 (Az&#233; et al., 2006). Bien qu&#8217;encore incompl&#232;te, la m&#233;thode Transeg a &#233;t&#233; class&#233;e en
milieu de tableau face aux diff&#233;rentes autres approches &#233;valu&#233;es.
</p>
<p>1.2.1 Repr&#233;sentation du texte
</p>
<p>La premi&#232;re &#233;tape de notre approche est de convertir chaque phrase du texte en un vecteur
s&#233;mantique. Ce vecteur est obtenu gr&#226;ce &#224; l&#8217;analyseur morpho-syntaxique de la langue fran&#231;aise
SYGFRAN (Chauch&#233;, 1984). Ces vecteurs sont des vecteurs s&#233;mantiques &#224; la Roget (Roget,
1852), mais se basant sur le th&#233;saurus Larousse (Larousse, 1992) comme r&#233;f&#233;rence. Le vecteur
de chaque phrase est calcul&#233; de mani&#232;re r&#233;cursive en combinant lin&#233;airement les vecteurs des
constituants de la phrase, eux m&#234;me obtenus par combinaison lin&#233;aire des vecteurs de mots. Le
poids de chaque constituant d&#233;pend du r&#233;sultat d&#8217;une analyse morpho-syntaxique en constituant
et en d&#233;pendance1.
</p>
<p>1La formule est donn&#233;e par (Chauch&#233; &amp; Prince, 2007)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre Labadi&#233;, Violaine Prince
</p>
<p>1.2.2 Segmentation du texte
</p>
<p>En nous appuyant sur cette repr&#233;sentation de la phrase, nous avons cherch&#233; &#224; identifier ce que
nous nommons les &#171;zones de transition&#187; &#224; l&#8217;int&#233;rieur du texte. La notion de zone de transition
vient de l&#8217;hypoth&#232;se selon laquelle la fronti&#232;re entre deux th&#232;mes au sein d&#8217;un texte n&#8217;est pas
une phrase unique, mais probablement une courte succession de phrases (2 ou 3). Pour retrou-
ver ces zones de transition nous faisons glisser une fen&#234;tre le long du texte. Cette fen&#234;tre, d&#8217;une
largeur fixe de 20 phrases (sa taille reste param&#233;trable), repr&#233;sente un encha&#238;nement suppos&#233; de
deux segments th&#233;matiques. Chaque moiti&#233; de la fen&#234;tre est donc consid&#233;r&#233;e comme un seg-
ment th&#233;matique potentiel. On calcule alors un centro&#239;de pour chacun d&#8217;entre eux. Ce centro&#239;de
est un barycentre pond&#233;r&#233;, ce qui nous permet d&#8217;incorporer un peu d&#8217;information stylistique.
En effet, les premi&#232;res phrases et les introductions comportent tr&#232;s souvent plus d&#8217;informations
pertinentes que les autres phrases (Labadi&#233; &amp; Chauch&#233;, 2006), (Lelu et al., 2006). Les poids
de chaque phrase sont donc calcul&#233;s selon une r&#233;gression lin&#233;aire donnant plus d&#8217;importance
aux premi&#232;res phrases d&#8217;un segment comparativement aux derni&#232;res. Finalement, nous calcu-
lons une distance (que nous nommons distance th&#233;matique) entre ces deux barycentres. Cette
distance est attribu&#233;e comme score de transition &#224; la phrase du milieu de la fen&#234;tre (la fronti&#232;re
potentielle donc, voir figure 1). Le choix d&#8217;une fen&#234;tre de 20 phrases se base sur l&#8217;observation
empirique de la taille moyenne d&#8217;un segment sur les diff&#233;rents corpus fournis lors de l&#8217;&#233;valua-
tion DEFT&#8217;06 (Az&#233; et al., 2006), qui est d&#8217;environ 10 phrases (10, 12). On notera que le masque
utilis&#233; par Choi dans son algorithme est par d&#233;faut de 11 phrases, les deux m&#233;thodes envisagent
donc une taille moyenne du segment th&#233;matique proche de 10 phrases.
Les zones de transition sont donc des phrases successives avec un score de transition sup&#233;rieur &#224;
un seuil d&#233;termin&#233;. Ce seuil est le r&#233;sultat d&#8217;une observation d&#233;taill&#233;e du corpus de discours po-
litiques fourni lors de l&#8217;&#233;valuation DEFT&#8217;06 (Az&#233; et al., 2006). Nous avons calcul&#233; les distances
qui s&#233;parent des segments th&#233;matique de bon nombre de discours (plus de 100000 phrases au
total) et nous avons trouv&#233; une distance moyenne de 0.45 pour un &#233;cart type de 0.08. Une fois
les zones de transition identifi&#233;es, on s&#233;lectionne les phrases fronti&#232;res en leur sein. Une des-
cription plus d&#233;taill&#233;e de notre approche est disponible dans (Prince &amp; Labadi&#233;, 2007). Dans
notre premi&#232;re mise en &#339;uvre de la m&#233;thode, nous utilisions la distance angulaire pour le calcul
du score de transition. Dans cet article, nous utilisons une version modifi&#233;e de la distance de
concordance propos&#233;e par (Chauch&#233; et al., 2003).
</p>
<p>1.2.3 La distance de concordance
</p>
<p>Les vecteurs s&#233;mantiques issus de l&#8217;analyse par SYGFRAN ont 873 composantes, et la grande
majorit&#233; de ces derni&#232;res ne sont pas activ&#233;es pour une phrase donn&#233;e. Avec autant de valeurs
nulles, la distances angulaire n&#8217;est pas assez discriminante. La distance de concordance a pour
objectif d&#8217;&#234;tre plus discriminante en se concentrant sur les composantes les plus activ&#233;es et leur
classement relatif.
Consid&#233;rons deux vecteurs ~A et ~B, nous classons leurs composantes de la plus activ&#233;e &#224; la
moins activ&#233;e et ne conservons que les premi&#232;res valeurs (1
</p>
<p>3
de la taille initiale du vecteur). ~Atr
</p>
<p>et ~Btr sont les versions tri&#233;es et r&#233;duites de respectivement ~A et ~B. Comme nous ne conservons
que les composantes les plus fortes de chaque vecteur, ~Atr et ~Btr peuvent tr&#232;s bien ne pas avoir
de composantes en commun (dans ce cas la distance qui les s&#233;pare sera de 1). Dans le cas o&#249;
~Atr et ~Btr ont au moins une composante en commun nous pouvons calculer deux diff&#233;rences :
La diff&#233;rence de rang : Si i est le rang de Ct une composante de ~Atr et &#961;(i) le rang de la m&#234;me</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Comparaison de m&#233;thodes lexicale et syntaxico-s&#233;mantique dans la segmentation th&#233;matique
non supervis&#233;e
</p>
<p>FIG. 1 &#8211; Attribution d&#8217;un score de transition
</p>
<p>composante dans ~Btr, alors nous avons la diff&#233;rence de rang :
</p>
<p>Ei,&#961;(i) =
(i&#8722; &#961;(i))2
</p>
<p>Nb2 + (1 + i2)
(1)
</p>
<p>O&#249; Nb est le nombre de composantes conserv&#233;es.
La diff&#233;rence d&#8217;intensit&#233; : Il nous faut &#233;galement comparer la diff&#233;rence d&#8217;intensit&#233; des dif-
f&#233;rente composantes communes. Pour cela nous consid&#233;rons ai l&#8217;intensit&#233; de la composante de
rang i dans ~Atr et b&#961;(i) l&#8217;intensit&#233; de la m&#234;me composante dans ~Btr (et dont le rang est &#961;(i)),
alors nous avons la diff&#233;rence d&#8217;intensit&#233; :
</p>
<p>Ii,&#961;(i) =
</p>
<p>&#8741;&#8741;&#8741;ai &#8722; b&#961;(i)&#8741;&#8741;&#8741;
Nb2 + (1+i2 )
</p>
<p>(2)
</p>
<p>Ces deux diff&#233;rences nous permettent de calculer la concordance :
</p>
<p>P ( ~Atr, ~Btr) = (
</p>
<p>&#8721;Nb&#8722;1
i=0
</p>
<p>1
1+Ei,&#961;(i)&#8727;Ii,&#961;(i)
Nb
</p>
<p>)2 (3)
</p>
<p>Toutefois, la concordance P se concentre sur l&#8217;intensit&#233; et le rang des composantes et n&#8217;a
pas la notion de direction que poss&#232;de la distance angulaire. Nous introduisons donc la notion
de direction en combinant la concordance avec la distance angulaire. Ainsi si &#948;( ~A, ~B) est la
distance angulaire entre ~A et ~B, nous avons :
</p>
<p>&#8710;( ~Atr, ~Btr) =
P ( ~Atr, ~Btr) &#8727; &#948;( ~A, ~B)
</p>
<p>&#946; &#8727; P ( ~Atr, ~Btr) + (1 &#8722; &#946;) &#8727; &#948;( ~A, ~B)
(4)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre Labadi&#233;, Violaine Prince
</p>
<p>O&#249; &#946; est un coefficient donnant plus ou moins de poids &#224; P . Il est ais&#233; de prouver que
&#8710;( ~Atr, ~Btr) n&#8217;est pas sym&#233;trique.
&#8710;( ~Atr, ~Btr) a &#233;t&#233; con&#231;u au d&#233;part dans un contexte de classification, afin de comparer des vec-
teurs de textes &#224; des vecteurs de classes. Comme seule la proximit&#233; entre le texte et la classe
&#233;tait importante la sym&#233;trie n&#8217;&#233;tait pas n&#233;cessaire. Dans notre contexte de segmentation de texte,
o&#249; un segment n&#8217;est pas plus important que celui qui le pr&#233;c&#232;de ou lui succ&#232;de, la sym&#233;trie est
indispensable. Ainsi la distance de concordance sym&#233;trique vaut :
</p>
<p>D( ~A, ~B) =
&#8710;( ~Atr, ~Btr) + &#8710;( ~Btr, ~Atr)
</p>
<p>2
(5)
</p>
<p>2 Exp&#233;rience : segmentation th&#233;matique de vingt deux dis-
cours politiques fran&#231;ais.
</p>
<p>Afin de mesurer l&#8217;efficacit&#233; de Transeg nous l&#8217;avons compar&#233; &#224; un algorithme reconnu et
&#233;prouv&#233;, c99 de (Choi et al., 2001). Les deux algorithmes sont non supervis&#233;s et donc ind&#233;pen-
dants des donn&#233;es (ils n&#8217;effectuent ni apprentissage, ni adaptation aux donn&#233;es et donc l&#8217;usage
r&#233;p&#233;t&#233; d&#8217;un m&#234;me corpus n&#8217;aura pas d&#8217;influence sur les r&#233;sultats). Les tests ont &#233;t&#233; effectu&#233;s
sur un corpus de vingt deux discours politiques extrait du corpus d&#8217;apprentissage fourni lors
de l&#8217;atelier DEFT&#8217;06 (Az&#233; et al., 2006). Nous d&#233;crivons dans cette section la pr&#233;paration des
donn&#233;es, les conditions de l&#8217;exp&#233;rience et nous commentons les r&#233;sultats.
</p>
<p>2.1 Pr&#233;sentation des donn&#233;es : Un corpus de vingt deux discours poli-
tiques fran&#231;ais
</p>
<p>Notre choix s&#8217;est port&#233; sur le corpus de discours politiques fourni par l&#8217;atelier DEFT&#8217;06 pour
deux raisons principales :
&#8211; Les fronti&#232;res th&#233;matiques au sein des discours ont &#233;t&#233; identifi&#233;es par des personnes pouvant
</p>
<p>&#234;tre consid&#233;r&#233;es comme &#171;expertes&#187; dans le domaine (le personnel travaillant &#224; la r&#233;daction
et &#224; la mise en ligne des discours pr&#233;sidentiels). Ainsi ces fronti&#232;res th&#233;matiques paraissent
moins artificielles que des d&#233;buts de texte concat&#233;n&#233;s ou des d&#233;buts de paragraphe, comme
c&#8217;est le cas en g&#233;n&#233;ral quand on essaie d&#8217;&#233;valuer des m&#233;thodes de segmentation.
</p>
<p>&#8211; En tant que textes argumentatifs par excellence, les discours politiques offrent, en g&#233;n&#233;ral,
une structure th&#233;matique claire.
</p>
<p>En d&#8217;autres termes, ce corpus est tout &#224; fait appropri&#233; pour une r&#233;elle &#233;valuation de la seg-
mentation th&#233;matique de textes. Malheureusement, le corpus initial propos&#233; par DEFT&#8217;06 &#233;tait
extr&#234;mement bruit&#233;. Certains discours &#233;taient uniquement en lettres capitales par exemple (ce
qui est pr&#233;judiciable dans une langue comme le fran&#231;ais qui utilise beaucoup d&#8217;accents et s&#8217;en
sert pour la reconnaissance lexicale), d&#8217;autres sont en fait des interviews. Il a donc &#233;t&#233; n&#233;cessaire
de s&#233;lectionner et de nettoyer manuellement vingt deux discours dans un ensemble de plusieurs
centaines de textes concat&#233;n&#233;s.
Sur un corpus initial de plus de 300000 phrases (de qualit&#233; douteuse) nous avons donc extrait 22
discours totalisant 1895 phrases et 54551 mots. Nous ne disposions d&#8217;aucune information quant
au d&#233;but des discours au sein de cet ensemble (en dehors des d&#233;but de segments th&#233;matiques</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Comparaison de m&#233;thodes lexicale et syntaxico-s&#233;mantique dans la segmentation th&#233;matique
non supervis&#233;e
</p>
<p>qui pouvaient &#234;tre indiff&#233;remment des d&#233;buts de discours, comme de simples fronti&#232;res th&#233;-
matiques). L&#8217;op&#233;ration a donc pris beaucoup de temps et a consid&#233;rablement r&#233;duit la masse de
donn&#233;es sur laquelle nous avons men&#233; l&#8217;exp&#233;rience, mais c&#8217;&#233;tait n&#233;cessaire afin de disposer d&#8217;un
jeu de donn&#233;es propre, et d&#8217;&#233;viter les biais exp&#233;rimentaux qui pourraient entacher l&#8217;objectivit&#233;
des r&#233;sultats.
</p>
<p>2.2 Pr&#233;sentation de l&#8217;exp&#233;rience : Comparaison des m&#233;thodes
</p>
<p>Nous avons donc compar&#233; Transeg et c99 sur ce jeu de donn&#233;es. Afin d&#8217;&#234;tre s&#251;r de ne pas faire
d&#8217;erreur de programmation, nous avons utilis&#233; la version 1.3 de c99 fournie par Choi lui m&#234;me
(http://www.lingware.co.uk/homepage/freddy.choi/software/software.htm). Cette version
de c99 b&#233;n&#233;ficie de l&#8217;am&#233;lioration LSA pr&#233;sent&#233;e dans (Choi et al., 2001).
Nous avons lanc&#233; les deux algorithmes sur les 22 textes, sans jamais les concat&#233;ner. En effet,
consid&#233;rer la reconnaissance d&#8217;un texte comme la reconnaissance d&#8217;un th&#232;me ne nous para&#238;t pas
&#234;tre de nature &#224; rendre compte de la variation th&#233;matique intratextuelle. Or malheureusement,
dans la majorit&#233; des campagnes d&#8217;&#233;valuation, on ne fait pas de diff&#233;rence entre les deux cas. En
s&#233;parant bien les textes, c&#8217;est vraiment la segmentation intra-textuelle que nous avons isol&#233;e et
test&#233;e, &#233;vitant ainsi des biais exp&#233;rimentaux.
Pour comparer les r&#233;sultats, nous avons utilis&#233; le rappel et la pr&#233;cision avec fen&#234;tre de tol&#233;rance
pr&#233;sent&#233;s dans (Az&#233; et al., 2006). Ils comptent comme correctes des phrases que les algorithmes
ram&#232;neraient et qui seraient juste avant ou juste apr&#232;s la phrase identifi&#233;e par l&#8217;expert comme
&#233;tant la fronti&#232;re. Dans le cadre de l&#8217;exp&#233;rience, la fen&#234;tre &#233;tait de deux phrases avant ou apr&#232;s.
L&#8217;&#233;quipe de DEFT&#8217;06 a constat&#233; que l&#8217;usage de ces mesures ne changeait pas le classement des
m&#233;thodes pr&#233;sent&#233;es par rapport &#224; un rappel et une pr&#233;cision stricts. Cette tol&#233;rance permet de
ne pas sanctionner un algorithme qui s&#233;lectionne comme fronti&#232;re possible une phrase juste &#224;
cot&#233; de la fronti&#232;re identifi&#233;e par l&#8217;expert.
A partir de ce rappel et de cette pr&#233;cision nous calculons un FScore selon la formule bien
connue :
</p>
<p>FScore =
(&#946;2 + 1) &#8727; rappel &#8727; precision
&#946;2 &#8727; precision+ rappel (6)
</p>
<p>Avec &#946; = 1.
On notera tout de m&#234;me que c99 comme Transeg consid&#232;re toujours la premi&#232;re phrase d&#8217;un
texte comme une fronti&#232;re th&#233;matique, et que lors de notre &#233;valuation nous consid&#233;rons cette
r&#233;ponse comme correcte. Aussi pour chaque texte les deux m&#233;thodes ont au moins un retour
correct.
</p>
<p>2.3 R&#233;sultats : avantage Transeg
</p>
<p>Le premier constat que nous faisons &#224; la vue des r&#233;sultats, est qu&#8217;ils sont plut&#244;t d&#233;cevants en
terme de FScore quelle que soit la m&#233;thode utilis&#233;e. Le FScore est une mesure tr&#232;s stricte,
et m&#234;me en utilisant un rappel et une pr&#233;cision tol&#233;rante nous obtenons au mieux un FScore
de 42.86 (pour Transeg sur le texte 9 ; nous donnons ici les valeurs sous forme de pourcentage,
pour des raisons de lisibilit&#233;). Cela nous permet de constater que la marge de progression dans
le domaine de la segmentation th&#233;matique demeure importante.
Plus en d&#233;tail, nous constatons que Transeg a un meilleur FScore sur 16 des 22 textes consi-
d&#233;r&#233;s. Sur ces 16 textes, Transeg a toujours un rappel sup&#233;rieur ou &#233;gal &#224; celui de c99, et son
FScore est au minimum sup&#233;rieur de 20% &#224; celui de c99 (texte 1) pour aller &#224; plus de 4 fois
sup&#233;rieur (texte 9). On notera &#233;galement que Transeg poss&#232;de &#233;galement le meilleur r&#233;sultat sur</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre Labadi&#233;, Violaine Prince
</p>
<p>l&#8217;ensemble des textes.
C99 d&#233;passe Transeg dans 6 textes, mais avec un FScore au maximum deux fois sup&#233;rieur &#224; ce-
lui de Transeg. Toutefois on notera que c99 est en g&#233;n&#233;ral toujours performant en terme de pr&#233;-
cision comparativement &#224; Transeg. Ce r&#233;sultat s&#8217;explique facilement en &#233;tudiant les conditions
de l&#8217;exp&#233;rience. En effet les deux m&#233;thodes ram&#232;nent toujours au moins la premi&#232;re phrase,
qui est toujours comptabilis&#233;e comme correcte. C99 ram&#232;ne beaucoup moins de phrases que
Transeg, avec au moins une phrase de juste. Le calcul de la pr&#233;cision lui est donc favorable (les
textes o&#249; c99 a une pr&#233;cision de 100 correspondent &#224; des textes o&#249; l&#8217;algorithme n&#8217;a ramen&#233; que
la premi&#232;re phrase).
Transeg est une m&#233;thode d&#233;velopp&#233;e pour d&#233;tecter les faibles variations intra-textuelles. Logi-
quement elle obtient, en g&#233;n&#233;ral, un fort rappel et sa pr&#233;cision en p&#226;tit quelque peu. Parfois trop
sensible, Transeg a tendance &#224; sur-segmenter. A l&#8217;oppos&#233;, c99 est un algorithme qui favorise la
pr&#233;cision en ramenant peu de phrases et donc sous-segmente. On peut imputer cette tendance au
fait que bon nombre de m&#233;thodes de segmentation th&#233;matique sont d&#233;velopp&#233;es et test&#233;es sur
des corpus tr&#232;s artificiels o&#249; le but est de retrouver des d&#233;buts de paragraphes, voir des d&#233;buts de
textes courts dans un ensemble de textes concat&#233;n&#233;s. C&#8217;est encore plus &#233;vident si l&#8217;on regarde
en d&#233;tail les 6 textes o&#249; c99 a de meilleurs r&#233;sultats. Ce sont soit des textes tr&#232;s courts, avec
tr&#232;s peu de fronti&#232;res th&#233;matiques identifi&#233;es, soit des &#233;num&#233;rations sans r&#233;elle structure. Par
exemple le texte 6 est un discours du porte-parole du gouvernement &#224; l&#8217;issue d&#8217;un conseil des
ministres. Ce discours n&#8217;est que l&#8217;&#233;num&#233;ration des diff&#233;rents sujets trait&#233;s durant le conseil. Les
mots sont tr&#232;s diff&#233;rents, et les sujets sont courts, ce qui est dans le domaine de comp&#233;tence de
c99.
</p>
<p>3 Conclusion
</p>
<p>D&#8217;apr&#232;s l&#8217;exp&#233;rience d&#233;crite dans cet article, et que nous avons voulu la plus objective possible,
Transeg semble plus performant que c99 lorsqu&#8217;il s&#8217;agit de retrouver les fronti&#232;res th&#233;matiques
intra-textuelles. Nous pouvons donc en d&#233;duire que l&#8217;usage d&#8217;informations s&#233;mantiques et syn-
taxiques a un effet appr&#233;ciable sur la qualit&#233; de segmentation th&#233;matique d&#8217;un texte, lorsque
celui-ci a une certaine taille, et qu&#8217;il est construit (avec des qualit&#233;s stylistiques et rh&#233;toriques).
En revanche, ces informations peuvent parfois &#234;tre trop sensibles et nous amener &#224; une surseg-
mentation par rapport aux fronti&#232;res donn&#233;es en r&#233;f&#233;rence. Ce qui nous am&#232;ne l&#233;gitimement &#224;
nous poser les questions suivantes : Les fronti&#232;res th&#233;matiques ont &#233;t&#233; identifi&#233;es par des per-
sonnes pouvant raisonnablement &#234;tre consid&#233;r&#233;es comme des experts du domaine, mais toutes
les fronti&#232;res sont elles bonnes ? En faudrait il plus ? Ou moins ? Ou m&#234;me, une question peut-
&#234;tre plus pertinente, leur solution est-elle l&#8217;unique solution ?
Le fait m&#234;me de n&#8217;avoir aucune certitude sur le sujet pourrait remettre en cause la validit&#233; de
l&#8217;&#233;valuation absolue, celle qui se fait automatiquement, ou quasi-automatiquement, en rapport
avec &#171;une valeur de r&#233;f&#233;rence&#187;. La segmentation th&#233;matique est, par essence, subjective, et l&#8217;on
peut dire la m&#234;me chose d&#8217;autres domaines du traitement automatique de la langue. S&#8217;il faut
&#233;valuer, il serait plus appropri&#233; de proposer une proc&#233;dure plus relative. Nous envisageons, &#224;
l&#8217;heure actuelle, d&#8217;autre mani&#232;res d&#8217;&#233;valuer nos r&#233;sultats, en se basant, par exemple sur des avis
&#224; posteriori (faire &#171;noter&#187; nos r&#233;sultats par des experts ou m&#234;me des utilisateurs). Plut&#244;t que
d&#8217;affirmer la sup&#233;riorit&#233; intrins&#232;que de tel ou tel outil, il serait plus ad&#233;quat d&#8217;en constater la
plus grande adaptation, la plus grande souplesse, la plus grande satisfaction d&#8217;usage, etc.
Pour terminer, on pourrait remarquer que, toutes choses &#233;tant &#233;gales par ailleurs, c99 et Tran-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Comparaison de m&#233;thodes lexicale et syntaxico-s&#233;mantique dans la segmentation th&#233;matique
non supervis&#233;e
</p>
<p>Nb. mots Nb. phrases Transeg c99
Pr&#233;cision Rappel FScore Pr&#233;cision Rappel FScore
</p>
<p>Text 1 617 22 50 33.33 20 33.33 33.33 16.67
Text 2 3042 100 33.33 37.5 17.65 50 12.5 10
Text 3 2767 92 42.86 85.71 28.57 20 14.29 8.33
Text 4 1028 40 33.33 33.33 16.67 20 33.33 12.5
Text 5 4532 157 12.5 18.18 7.41 16.67 9.09 5.88
Text 6 5348 212 8.7 18.18 5.88 20 18.18 9.52
Text 7 1841 47 100 42.86 30 100 14.29 12.5
Text 8 1927 74 60 33.33 21.43 100 11.11 10
Text 9 1789 53 75 100 42.86 25 16.67 10
Text 10 1389 31 33.33 20 12.5 100 20 16.67
Text 11 2309 81 30 50 18.75 33.33 16.67 11.11
Text 12 7193 211 15.38 6.25 4.44 33.33 3.13 2.86
Text 13 6097 305 20.59 33.33 12.73 17.65 14.29 7.89
Text 14 1417 57 40 33.33 18.18 100 16.67 14.29
Text 15 3195 79 40 8 6.67 66.67 8 7.14
Text 16 1995 60 66.67 28.57 20 57.14 57.14 28.57
Text 17 558 16 33.33 33.33 16.67 50 66.67 28.57
Text 18 696 25 100 37.5 27.27 40 25 15.38
Text 19 678 26 33.33 33.33 16.67 50 66.67 28.57
Text 20 1388 57 50 66.67 28.57 100 16.67 14.29
Text 21 3127 110 62.5 25 17.86 40 10 8
Text 22 1618 40 60 75 33.33 100 25 20
</p>
<p>TAB. 1 &#8211; Comparaison transeg / c99
</p>
<p>seg font montre de propri&#233;t&#233;s compl&#233;mentaires. A eux deux, ils couvrent (avec des am&#233;liora-
tions futures &#224; envisager) les possibilit&#233;s de segmentation. Une fusion imm&#233;diate entre les deux
m&#233;thodes &#233;tant paradigmatiquement et techniquement peu envisageable, une piste int&#233;ressante
pourrait &#234;tre celle d&#8217;un logiciel qui permettrait de d&#233;celer automatiquement lequel des deux al-
gorithmes lancer en fonction des propri&#233;t&#233;s des textes &#224; segmenter. C&#8217;est une &#233;tude qui reste &#224;
faire, et qui permettrait aussi d&#8217;examiner les am&#233;liorations en termes de performances &#224; apporter
aux deux algorithmes.
</p>
<p>R&#233;f&#233;rences
</p>
<p>AZ&#201; J., HEITZ T., MELA A., MEZAOUR A., PEINL P. &amp; ROCHE M. (2006). Pr&#233;sentation
de deft&#8217;06 (defi fouille de textes). Proceedings of DEFT&#8217;06, 1, 3&#8211;12.
</p>
<p>BESTGEN Y. &amp; PI&#201;RARD S. (2006). Comment &#233;valuer les algorithmes de segmentation auto-
matiques ? essai de construction d&#8217;un mat&#233;riel de r&#233;f&#233;rence. Proceedings of TALN&#8217;06.
</p>
<p>CHAUCH&#201; J. (1984). Un outil multidimensionnel de l&#8217;analyse du discours. Proceedings of
Coling&#8217;84, 1, 11&#8211;15.
</p>
<p>CHAUCH&#201; J. &amp; PRINCE V. (2007). Classifying texts through natural language parsing and
semantic filtering. In Proceedings of LTC&#8217;03.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Alexandre Labadi&#233;, Violaine Prince
</p>
<p>CHAUCH&#201; J., PRINCE V., JAILLET S. &amp; TEISSEIRE M. (2003). Classification automatique
de textes &#224; partir de leur analyse syntaxico-s&#233;mantique. Proceedings of TALN&#8217;03, p. 55&#8211;65.
</p>
<p>CHOI F. Y. Y. (2000). Advances in domain independent linear text segmentation. Proceedings
of NAACL-00, p. 26&#8211;33.
</p>
<p>CHOI F. Y. Y., WIEMER-HASTINGS P. &amp; MOORE J. (2001). Latent semantic analysis for
text segmentation. Proceedings of EMNLP, p. 109&#8211;117.
</p>
<p>HEARST M. A. &amp; PLAUNT C. (1993). Subtopic structuring for full-length document access.
Proceedings of the ACM SIGIR-93 International Conference On Research and Development
in Information Retrieval, p. 59&#8211;68.
</p>
<p>KARATZAS D. (2003). Text Segmentation in Web Images Using Color Perception and Topo-
logical Features. UK : ECS Publications.
</p>
<p>LABADI&#201; A. &amp; CHAUCH&#201; (2006). Segmentation th&#233;matique par calcul de distance s&#233;man-
tique. Proceedings of DEFT&#8217;06, 1, 45&#8211;59.
LAROUSSE (1992). Th&#233;saurus Larousse - des id&#233;es aux mots, des mots aux id&#233;es. Paris :
Larousse.
</p>
<p>LELU A., M. C. &amp; AUBAIN S. (2006). Coop&#233;ration multiniveau d&#8217;approches non-supervis&#233;es
et supervis&#233;es pour la detection des ruptures th&#233;matiques dans les discours pr&#233;sidentiels fran-
&#231;ais. In Proceedings of DEFT&#8217;06.
</p>
<p>MORRIS J. &amp; HIRST G. (1991). Lexical cohesion computed by thesaural relations as an
indicator of the structure of text. Computational Linguistics, 17, 20&#8211;48.
PONTE J. M. &amp; CROFT W. B. (1997). Text segmentation by topic. European Conference on
Digital Libraries, p. 113&#8211;125.
</p>
<p>PRINCE V. &amp; LABADI&#201; A. (2007). Text segmentation based on document understanding for
information retrieval. In Proceedings of NLDB&#8217;07, p. 295&#8211;304.
</p>
<p>ROGET P. (1852). Thesaurus of English Words and Phrases. London : Longman.
</p>
<p>WU Z. &amp; TSENG G. (1993). Chinese text segmentation for text retrieval : Achievements and
problems. Journal of the American Society for Information Science, 44, 532&#8211;542.
YANG C. C. &amp; LI K. W. (2005). A heuristic method based on a statistical approach for chinese
text segmentation. Journal of the American Society for Information Science and Technology,
56, 1438&#8211;1447.</p>

</div></div>
</body></html>