TALN 2008, Avignon, 9-13 juin 2008

Comparaison de méthodes lexicales et syntaxico-sémantiques
dans la segmentation thématique de texte non supervisée

Alexandre Labadiél Violaine Prince1
(1) LIRMM, 161 rue ADA, 34392 Montpellier cedex
labadie@lirmm.fr, prince @lirmm.fr

Résumé. Cet article présente une méthode basée sur des calculs de distance et une analyse
sémantique et syntaxique pour la segmentation thématique de texte. Pour évaluer cette méthode
nous la comparons a un un algorithme lexical tres connu : c99. Nous testons les deux méthodes
sur un corpus de discours politique francais et comparons les résultats. Les deux conclusions qui
ressortent de notre experience sont que les approches sont complémentaires et que les protocoles
d’évaluation actuels sont inadaptés.

Abstract. This paper present a semantic and syntactic distance based method in topic
text segmentation and compare it to a very well known text segmentation algorithm : c99. To
do so we ran the two algorithms on a corpus of twenty two French political discourses and
compared their results. Our two conclusions are that the two approaches are complementary
and that evaluation methods in this domain should be revised.

M0tS-CléS I Methodes d’évaluation, segmentation de texte, segmentation thématique.

Keywords: Evaluation methods, text segmentation, topic segmentation.

Alexandre Labadie, Violaine Prince

Introduction

Il existe beaucoup de taches dites de «segmentation de texte». Par exemple, la recherche et
l’eXtraction de textes dans des documents multimedia, ou le texte est melange a de la video
et de l’image, sont des taches assimilees a la «segmentation de texte» (Karatzas, 2003). Re-
grouper des mots en morphemes, ou en unites linguistiques plus importantes, est aussi nomme
segmentation de texte (par exemple, dans le traitement des langues asiatiques, qui utilisent des
ideogrammes, les frontieres des mots sont difﬁciles a deterIr1iner(Wu & Tseng, 1993), (Yang &
Li, 2005)). Dans cet article, nous nous interessons a la «segmentation thématique de texte»,
c’est a dire a l’operation qui a pour but de trouver la structure thematique (Hearst & Plaunt,
1993) d’un texte et d’en proposer une decomposition par theme (Ponte & Croft, 1997). Si la
plupart des textes traitent d’un sujet unique, ils abordent en general plusieurs themes en leur
sein. Plus le texte est volumineux, plus il est probable que ses themes, ou sous-themes d’un su-
jet donne, soient nombreux. Fondamentalement, la segmentation thematique de texte recherche,
au sein d’un texte, le debut et la ﬁn des themes. Pour des raisons pratiques, nous utiliserons pour
le reste de cet article le terme «segmentation thematique» plut6t que segmentation thematique
de texte.

Si l’on considere que la segmentation thematique doit diviser le document en plusieurs seg-
ments coherents et distincts sur le plan thematique, alors chaque segment ne doit idealement
traiter que d’un seul theme. Mais un theme est une unite complexe sur le plan rhetorique, qui
necessite souvent des digressions, des exemples et des argumentations.

Ce qui nous amene a nous poser la question de la deﬁnition de la notion de theme. Dans la litte-
rature, nous en trouvons plusieurs deﬁnitions. En general, un theme est : le sujet d ’une conver-
sation on d ’une discussion (deﬁnition du dictionnaire). En linguistique, on le deﬁnit comme :
l’e’le’ment d ’un énoncé qui est répute’ connu par les participants a la communication (on l’op-
pose souvent au rheme qui est l’information nouvelle apportee par l’enonce). Nous admettrons
ici que le theme d’un segment de texte est ce dont il parle. La segmentation thematique doit
donc diviser le texte en portions dont chacune des phrases «parle» de la meme chose que les
autres.

Dans cet article nous comparons Transeg, notre methode de segmentation thematique basee
sur des calculs de distance et une analyse semantique et syntaxique a priori, a c99, un algo-
rithme de reference a l’heure actuelle dans le domaine. Nous voulons determiner l’importance
des informations d’ordre semantique et syntaxique portees par les phrases, qui sont les elements
constitutif du texte, dans le cadre de la segmentation thematique. Notre methode tient compte de
cette information, alors que c99 est essentiellement de granularite lexicale. Nous presenterons
les deux approches testees ici dans une premiere partie, pour examiner en detail leur resultats
respectifs sur notre corpus de discours politiques. Nous conclurons sur la validite des methodes
d’evaluation de segmentation thematique et les possibilites d’evolution de Transeg.

1 Presentation des méthodes comparées.

1.1 C99

Developpe par Choi (Choi, 2000), c99 est un algorithme de segmentation thematique s’appuyant
fortement sur la notion de cohesion lexicale (Morris & Hirst, 1991). C’est un des algorithmes
donnant les meilleurs resultats dans le domaine de la segmentation thematique (Bestgen & Pie-

Comparaison de méthodes lexicale et syntaxico-sémantique dans la segmentation thématique
non supervisée

rard, 2006).

C99 s’appuie sur une matrice de similarité entre les phrases du texte. D’abord projetées dans
l’espace des mots du texte, les phrases sont ensuite comparées deux a deux a l’aide d’une me-
sure de similarité (en général le cosinus) pour former une matrice de similarité. Plus récemment,
Choi a amélioré c99 en y adjoignant une analyse sémantique latente (LSA), aﬁn de réduire l’es-
pace des mots a un espace de «concepts» (Choi et al., 2001).

L’ originalité de Choi est de ne pas travailler directement sur la matrice de similarité, mais sur
une matrice de classement locaux. Chaque case de la matrice est comparée aux cases environ-
nantes (leur nombre dépendant de la taille du masque appliqué, qui est paramétrable), et obtient
un score en fonction du nombre de cases ayant un score de similarité inférieur. Evidmement ces
rangs, ainsi nommés par Choi, sont normalisés par le nombre de cases effectivement comprises
dans le masque pour éviter les effets de bord.

La recherche des frontieres de theme se fait en optimisant la densité de sous-matrices le long
de la diagonale de la matrice de rang, de maniere récursive. L’algorithme s’arréte lorsque la
frontiere idéale désignée par l’algorithme est la demiere phrase de la matrice courante ou, si
l’utilisateur foumit un maximum en parametre a l’algorithme, quand le nombre maximum de
frontieres est atteint.

La plupart des approches basées sur la cohésion lexicale n’utilisent que peu (voir pas) d’infor-
mation syntaxique ou sémantique. C99 ne fait pas exception. L’ ajout d’une LSA en prétraite-
ment du texte introduit certes un peu de sémantique, mais cela reste au niveau lexical, et ne
gomme que partiellement ce défaut d’informations sémantiques. Les informations syntaxiques
sont ignorées.

1.2 Transeg

Nous avons développé une méthode de segmentation thématique, appelée Transeg, que nous
avons voulu la plus sensible possible aux variations thématiques intra-textuelles. Elle part de
l’hypothese que le texte est constitué par des phrases, qui a leur tour, ne sont pas jetées en
vrac, mais produites et ordonnées selon une intention discursive. Des lors, les informations
de position et de construction de ces dernieres sont importantes pour la reconnaissance des
frontieres, aussi bien que de la structure des themes qui jalonnent le document.

Les travaux préliminaires qui ont servi a l’élaboration de Transeg ont été évalués lors de du déﬁ
DEFT’06 (Azé et al., 2006). Bien qu’encore incomplete, la méthode Transeg a été classée en
milieu de tableau face aux différentes autres approches évaluées.

1.2.1 Représentation du texte

La premiere étape de notre approche est de convertir chaque phrase du texte en un vecteur
sémantique. Ce vecteur est obtenu grace a l’analyseur morpho-syntaxique de la langue francaise
SYGFRAN (Chauché, 1984). Ces vecteurs sont des vecteurs sémantiques a la Roget (Roget,
1852), mais se basant sur le thésaurus Larousse (Larousse, 1992) comme référence. Le vecteur
de chaque phrase est calculé de maniere récursive en combinant linéairement les vecteurs des
constituants de la phrase, eux méme obtenus par combinaison linéaire des vecteurs de mots. Le
poids de chaque constituant dépend du résultat d’une analyse morpho-syntaxique en constituant
et en dépendancel.

1La fonnule est donnée par (Chauché & Prince, 2007)

Alexandre Labadié, Violaine Prince

1.2.2 Segmentation du texte

En nous appuyant sur cette représentation de la phrase, nous avons cherché a identiﬁer ce que
nous nommons les «zones de transition» a l’intérieur du texte. La notion de zone de transition
vient de l’hypothese selon laquelle la frontiere entre deux themes au sein d’un texte n’est pas
une phrase unique, mais probablement une courte succession de phrases (2 ou 3). Pour retrou-
ver ces zones de transition nous faisons glisser une fenétre le long du texte. Cette fenétre, d’une
largeur ﬁxe de 20 phrases (sa taille reste paramétrable), représente un enchainement supposé de
deux segments thématiques. Chaque moitié de la fenétre est donc considérée comme un seg-
ment thématique potentiel. On calcule alors un centro'1'de pour chacun d’entre eux. Ce centroi'de
est un barycentre pondéré, ce qui nous permet d’incorporer un peu d’information stylistique.
En effet, les premieres phrases et les introductions comportent tres souvent plus d’informations
pertinentes que les autres phrases (Labadié & Chauché, 2006), (Lelu et al., 2006). Les poids
de chaque phrase sont donc calculés selon une régression linéaire donnant plus d’importance
aux premieres phrases d’un segment comparativement aux dernieres. Finalement, nous calcu-
lons une distance (que nous nommons distance thématique) entre ces deux barycentres. Cette
distance est attribuée comme score de transition a la phrase du milieu de la fenétre (la frontiere
potentielle donc, voir ﬁgure 1). Le choix d’une fenétre de 20 phrases se base sur l’observation
empirique de la taille moyenne d’un segment sur les différents corpus fournis lors de l’évalua-
tion DEFT’06 (Azé et al., 2006), qui est d’environ 10 phrases (10, 12). On notera que le masque
utilisé par Choi dans son algorithme est par défaut de 11 phrases, les deux méthodes envisagent
donc une taille moyenne du segment thématique proche de 10 phrases.

Les zones de transition sont donc des phrases successives avec un score de transition supérieur a
un seuil déterminé. Ce seuil est le résultat d’une observation détaillée du corpus de discours po-
litiques fourni lors de l’évaluation DEFT’06 (Azé et al. , 2006). Nous avons calculé les distances
qui séparent des segments thématique de bon nombre de discours (plus de 100000 phrases au
total) et nous avons trouvé une distance moyenne de 0.45 pour un écart type de 0.08. Une fois
les zones de transition identiﬁées, on sélectionne les phrases frontieres en leur sein. Une des-
cription plus détaillée de notre approche est disponible dans (Prince & Labadié, 2007). Dans
notre premiere Inise en oeuvre de la méthode, nous utilisions la distance angulaire pour le calcul
du score de transition. Dans cet article, nous utilisons une version modiﬁée de la distance de
concordance proposée par (Chauché et al., 2003).

1.2.3 La distance de concordance

Les vecteurs sémantiques issus de l’analyse par SYGFRAN ont 873 composantes, et la grande
majorité de ces dernieres ne sont pas activées pour une phrase donnée. Avec autant de valeurs
nulles, la distances angulaire n’est pas assez discriminante. La distance de concordance a pour
objectif d’étre plus discriminante en se concentrant sur les composantes les plus activées et leur
classement relatif. _’ _’

Considérons deux vecteurs A et B, nous classons leurs composantes de la plus activée a la
moins activée et ne conservons que les premieres valeurs (é de la taille initiale du vecteur). A:,
et B1, sont les versions triées et réduites de respectivement A et B. Comme nous ne conservons
que les composantes les plus fortes de chaque vecteur, A:, et B1, peuvent tres bien ne pas avoir
de composantes en commun (dans ce cas la distance qui les sépare sera de 1). Dans le cas ou
A,;, et B1, ont au moins une composante en commun nous pouvons calculer deux différences :
La différence de rang : Si 1' est le rang de 0,; une composante de A,;, et  le rang de la meme

Comparaison de méthodes lexicale et syntaxico-sémantique dans la segmentation thématique
non supervisée

Fenétre

Vecteurs conceptuels
-)(-

Centro'|'de 1 CentroTde 2

\ /

Distance thématique

Valeurs attribuées

* : phrase observée

FIG. 1 — Attribution d’un score de transition

composante dans Btr, alors nous avons la différence de rang :

E1. (1.) =  (1)
”’ Nb? + (1 + 5)
on Nb est le nombre de composantes conservées.
La différence d’intensité : I1 nous faut également comparer la différence d’intensité des dif-
férente composantes communes. Pour cela nous considérons ai 1’intensité de la composante de
rang i dans A; et b,,(,-) 1’intensité de la méme composante dans B_,;, (et dont 1e rang est p(i)),
alors nous avons la différence d’intensité :

l “i ‘ bp(i)
W =  ‘Z’
Ces deux différences nous permettent de calculer la concordance :
_. _. Z1-3-1 
P(AtT’BtT) = ( 1 0 1+Ez,P(z)*Iz,/7(1) )2 

Nb

Toutefois, la concordance P se concentre sur 1’intensité et le rang des composantes et n’a
pas la notion de direction que possede la distance angulaire. Nous introduisons donc la notion
de direction en combinant la concordance avec la distance angulaire. Ainsi si 6(ff,  est la
distance angulaire entre K et E, nous avons :

P(A;, 3;) * 5(A’, 3

Am} 31): 4 ) -9 —»
” ’ 3 * P(A:,,B,;,) + (1 — 3) * 6(A,B)

(4)

Alexandre Labadié, Violaine Prince

on B est un coefﬁcient donnant plus ou moins de poids a P. 11 est aisé de prouver que
A(A_,;,, B1.) n’est pas symétrique.
A(A_,;,, B_,;,) a été concu au départ dans un contexte de classiﬁcation, aﬁn de comparer des vec-
teurs de textes a des vecteurs de classes. Comme seule la proximité entre le texte et la classe
était importante la symétrie n’ était pas nécessaire. Dans notre contexte de segmentation de texte,
ou un segment n’est pas plus important que celui qui le précede ou lui succede, la symétrie est
indispensable. Ainsi la distance de concordance symétrique vaut :

A<AZ., B2.) + A<B;, A1.)

D(A’,§) = 2

(5)

2 Expérience : segmentation thématique de vingt deux dis-
cours politiques frangais.

Aﬁn de mesurer l’efﬁcacité de Transeg nous l’avons compare a un algorithme reconnu et
éprouvé, c99 de (Choi et al., 2001). Les deux algorithmes sont non supervisés et donc indepen-
dants des données (ils n’effectuent ni apprentissage, ni adaptation aux données et donc l’usage
répété d’un méme corpus n’aura pas d’inﬂuence sur les résultats). Les tests ont été effectués
sur un corpus de vingt deux discours politiques extrait du corpus d’apprentissage fourni lors
de l’atelier DEFT’06 (Azé et al., 2006). Nous décrivons dans cette section la préparation des
données, les conditions de l’eXpérience et nous commentons les résultats.

2.1 Présentation des données : Un corpus de vingt deux discours poli-
tiques francais

Notre choix s’est porté sur le corpus de discours politiques fourni par l’atelier DEFT’06 pour

deux raisons principales :

— Les frontieres thématiques au sein des discours ont été identiﬁées par des personnes pouvant
étre considérées comme «expertes» dans le domaine (le personnel travaillant a la rédaction
et a la mise en ligne des discours présidentiels). Ainsi ces frontieres thématiques paraissent
moins artiﬁcielles que des débuts de texte concaténés ou des débuts de paragraphe, comme
c’est le cas en général quand on essaie d’évaluer des méthodes de segmentation.

— En tant que textes argumentatifs par excellence, les discours politiques offrent, en général,
une structure thématique claire.

En d’autres termes, ce corpus est tout a fait approprié pour une réelle évaluation de la seg-
mentation thématique de textes. Malheureusement, le corpus initial proposé par DEFT’06 était
extrémement bruité. Certains discours étaient uniquement en lettres capitales par exemple (ce
qui est préjudiciable dans une langue comme le francais qui utilise beaucoup d’accents et s’en
sert pour la reconnaissance lexicale), d’autres sont en fait des interviews. 11 a donc été nécessaire
de sélectionner et de nettoyer manuellement vingt deux discours dans un ensemble de plusieurs
centaines de textes concaténés.

Sur un corpus initial de plus de 300000 phrases (de qualité douteuse) nous avons donc extrait 22

discours totalisant 1895 phrases et 54551 mots. Nous ne disposions d’aucune information quant

au début des discours au sein de cet ensemble (en dehors des début de segments thématiques

Comparaison de méthodes lexicale et syntaxico-sémantique dans la segmentation thématique
non supervisée

qui pouvaient etre indifféremment des débuts de discours, comme de simples frontieres thé-
matiques). L’ operation a donc pris beaucoup de temps et a considérablement réduit la masse de
données sur laquelle nous avons mené l’eXpérience, mais c’était nécessaire aﬁn de disposer d’un
jeu de données propre, et d’éviter les biais expérimentaux qui pourraient entacher l’objectivité
des résultats.

2.2 Présentation de l’expérience : Comparaison des méthodes

Nous avons donc compare Transeg et c99 sur ce jeu de données. Aﬁn d’etre sﬁr de ne pas faire
d’erreur de programmation, nous avons utilise la version 1.3 de c99 foumie par Choi lui meme
(http://wvvw.Iingware.co.uk/homepage/freddy.choi/software/software.htm). Cette Version
de c99 bénéﬁcie de l’amélioration LSA présentée dans (Choi et al., 2001).

Nous avons lancé les deux algorithmes sur les 22 textes, sans jamais les concaténer. En effet,
considérer la reconnaissance d’un texte comme la reconnaissance d’un theme ne nous parait pas
etre de nature a rendre compte de la variation thématique intratextuelle. Or malheureusement,
dans la majorité des campagnes d’évaluation, on ne fait pas de difference entre les deux cas. En
séparant bien les textes, c’est vraiment la segmentation intra-textuelle que nous avons isolée et
testée, évitant ainsi des biais expérimentaux.

Pour comparer les résultats, nous avons utilise le rappel et la precision avec fenetre de tolerance
présentés dans (Azé et al., 2006). Ils comptent comme correctes des phrases que les algorithmes
rameneraient et qui seraient juste avant ou juste apres la phrase identiﬁée par l’expert comme
étant la frontiere. Dans le cadre de l’eXpérience, la fenetre était de deux phrases avant ou apres.
L’ équipe de DEFT’06 a constaté que l’usage de ces mesures ne changeait pas le classement des
méthodes présentées par rapport a un rappel et une precision stricts. Cette tolerance permet de
ne pas sanctionner un algorithme qui sélectionne comme frontiere possible une phrase juste a
coté de la frontiere identiﬁée par l’expert.

A partir de ce rappel et de cette precision nous calculons un FSc0re selon la formule bien

Connue 3
(ﬂ2 + 1) >«< rappel >«<precisi0n

FSc0re = (6)

ﬂ? >«< precision + rappel
Avec B = 1.
On notera tout de meme que c99 comme Transeg considere toujours la premiere phrase d’un
texte comme une frontiere thématique, et que lors de notre evaluation nous considérons cette
réponse comme correcte. Aussi pour chaque texte les deux méthodes ont au moins un retour
correct.

2.3 Résultats : avantage Transeg

Le premier constat que nous faisons a la vue des résultats, est qu’ils sont plutet décevants en
terme de FSc0re quelle que soit la méthode utilisée. Le FSc0re est une mesure tres stricte,
et meme en utilisant un rappel et une precision tolérante nous obtenons au mieux un FSc0re
de 42.86 (pour Transeg sur le texte 9; nous donnons ici les valeurs sous forme de pourcentage,
pour des raisons de lisibilité). Cela nous permet de constater que la marge de progression dans
le domaine de la segmentation thématique demeure importante.

Plus en detail, nous constatons que Transeg a un meilleur FSc0re sur 16 des 22 textes consi-
dérés. Sur ces 16 textes, Transeg a toujours un rappel supérieur ou égal a celui de c99, et son
FSc0re est au minimum supérieur de 20% a celui de c99 (texte 1) pour aller a plus de 4 fois
supérieur (texte 9). On notera également que Transeg possede également le meilleur résultat sur

Alexandre Labadié, Violaine Prince

l’ensemble des textes.

C99 dépasse Transeg dans 6 textes, mais avec un FSc0re au maximum deux fois supérieur a ce-
lui de Transeg. Toutefois on notera que c99 est en général touj ours performant en terme de pre-
cision comparativement a Transeg. Ce résultat s’explique facilement en étudiant les conditions
de l’expérience. En effet les deux méthodes ramenent toujours au moins la premiere phrase,
qui est toujours comptabilisée comme correcte. C99 ramene beaucoup moins de phrases que
Transeg, avec au moins une phrase de juste. Le calcul de la précision lui est donc favorable (les
textes o1‘1 c99 a une précision de 100 correspondent a des textes ou l’algorithme n’a ramené que
la premiere phrase).

Transeg est une méthode développée pour détecter les faibles variations intra-textuelles. Logi-
quement elle obtient, en général, un fort rappel et sa précision en patit quelque peu. Parfois trop
sensible, Transeg a tendance a sur-segmenter. A l’opposé, c99 est un algorithme qui favorise la
précision en ramenant peu de phrases et donc sous-segmente. On peut imputer cette tendance au
fait que bon nombre de méthodes de segmentation thématique sont développées et testées sur
des corpus tres artiﬁciels o1‘1le but est de retrouver des débuts de paragraphes, voir des débuts de
textes courts dans un ensemble de textes concaténés. C’est encore plus évident si l’on regarde
en détail les 6 textes ou c99 a de meilleurs résultats. Ce sont soit des textes tres courts, avec
tres peu de frontieres thématiques identiﬁées, soit des énumérations sans réelle structure. Par
exemple le texte 6 est un discours du porte-parole du gouvemement a l’issue d’un conseil des
Ininistres. Ce discours n’est que l’énumération des différents sujets traités durant le conseil. Les
mots sont tres différents, et les sujets sont courts, ce qui est dans le domaine de compétence de
c99.

3 Conclusion

D’apres l’expérience décrite dans cet article, et que nous avons voulu la plus objective possible,
Transeg semble plus performant que c99 lorsqu’il s’agit de retrouver les frontieres thématiques
intra-textuelles. Nous pouvons donc en déduire que l’usage d’informations sémantiques et syn-
taxiques a un effet appréciable sur la qualité de segmentation thématique d’un texte, lorsque
celui-ci a une certaine taille, et qu’il est construit (avec des qualités stylistiques et rhétoriques).
En revanche, ces informations peuvent parfois étre trop sensibles et nous amener a une surseg-
mentation par rapport aux frontieres données en référence. Ce qui nous amene légitimement a
nous poser les questions suivantes : Les frontieres thématiques ont été identiﬁées par des per-
sonnes pouvant raisonnablement étre considérées comme des experts du domaine, mais toutes
les frontieres sont elles bonnes ? En faudrait il plus ? Ou moins ? Ou méme, une question peut-
étre plus pertinente, leur solution est-elle l’unique solution ?

Le fait méme de n’avoir aucune certitude sur le sujet pourrait remettre en cause la validité de
l’évaluation absolue, celle qui se fait automatiquement, ou quasi-automatiquement, en rapport
avec «une valeur de référence». La segmentation thématique est, par essence, subjective, et l’on
peut dire la méme chose d’autres domaines du traitement automatique de la langue. S’il faut
évaluer, il serait plus approprié de proposer une procédure plus relative. Nous envisageons, a
l’heure actuelle, d’autre manieres d’évaluer nos résultats, en se basant, par exemple sur des avis
a posteriori (faire «noter» nos résultats par des experts ou méme des utilisateurs). Plutot que
d’afﬁrmer la supériorité intrinseque de tel ou tel outil, il serait plus adéquat d’en constater la
plus grande adaptation, la plus grande souplesse, la plus grande satisfaction d’usage, etc.

Pour terminer, on pourrait remarquer que, toutes choses étant égales par ailleurs, c99 et Tran-

Comparaison de méthodes lexicale et syntaxico-sémantique dans la segmentation thématique
non supervisée

Nb. mots Nb. phrases Transeg c99
Précision Rappel FScore Précision Rappel FScore

Text 1 617 22 50 33.33 20 33.33 33.33 16.67
Text 2 3042 100 33.33 37.5 17.65 50 12.5 10
Text 3 2767 92 42.86 85.71 28.57 20 14.29 8.33
Text 4 1028 40 33.33 33.33 16.67 20 33.33 12.5
Text 5 4532 157 12.5 18.18 7.41 16.67 9.09 5.88
Text 6 5348 212 8.7 18.18 5.88 20 18.18 9.52
Text 7 1841 47 100 42.86 30 100 14.29 12.5
Text 8 1927 74 60 33.33 21.43 100 11.11 10
Text 9 1789 53 75 100 42.86 25 16.67 10
Text 10 1389 31 33.33 20 12.5 100 20 16.67
Text 11 2309 81 30 50 18.75 33.33 16.67 11.11
Text 12 7193 211 15.38 6.25 4.44 33.33 3.13 2.86
Text 13 6097 305 20.59 33.33 12.73 17.65 14.29 7.89
Text 14 1417 57 40 33.33 18.18 100 16.67 14.29
Text 15 3195 79 40 8 6.67 66.67 8 7.14
Text 16 1995 60 66.67 28.57 20 57.14 57.14 28.57
Text 17 558 16 33.33 33.33 16.67 50 66.67 28.57
Text 18 696 25 100 37.5 27.27 40 25 15.38
Text 19 678 26 33.33 33.33 16.67 50 66.67 28.57
Text 20 1388 57 50 66.67 28.57 100 16.67 14.29
Text 21 3127 110 62.5 25 17.86 40 10 8
Text 22 1618 40 60 75 33.33 100 25 20

TAB. 1 — Comparaison transeg / c99

seg font montre de propriétés complémentaires. A eux deux, ils couvrent (avec des améliora-
tions futures a envisager) les possibilités de segmentation. Une fusion immédiate entre les deux
méthodes étant paradigmatiquement et techniquement peu envisageable, une piste intéressante
pourrait étre celle d’un logiciel qui permettrait de déceler automatiquement lequel des deux al-
gorithmes lancer en fonction des propriétés des textes a segmenter. C’est une étude qui reste a
faire, et qui permettrait aussi d’ examiner les améliorations en termes de performances a apporter
aux deux algorithmes.

Références

A211: J ., HEITZ T., MELA A., MEZAOUR A., PEINL P. & ROCHE M. (2006). Presentation
de deft’06 (deﬁ fouille de textes). Proceedings of DEF T’06, 1, 3-12.

BESTGEN Y. & PIERARD S. (2006). Comment évaluer les algorithmes de segmentation auto-
matiques ? essai de construction d’un matériel de référence. Proceedings of TALN’06.

CHAUCHE J. (1984). Un outil multidimensionnel de l’analyse du discours. Proceedings of
Coling’84, 1, 11-15.

CHAUCHE J. & PRINCE V. (2007). Classifying texts through natural language parsing and
semantic ﬁltering. In Proceedings of LTC ’03 .

Alexandre Labadié, Violaine Prince

CHAUCHE J ., PRINCE V., JAILLET S. & TEISSEIRE M. (2003). Classiﬁcation automatique
de textes a partir de leur analyse syntaxico-sémantique. Proceedings of TALN’03, p. 55-65.

CHOI F. Y. Y. (2000). Advances in domain independent linear text segmentation. Proceedings
of NAACL-00, p. 26-33.

CHOI F. Y. Y., WIEMER-HASTINGS P. & MOORE J . (2001). Latent semantic analysis for
text segmentation. Proceedings of EMNLP, p. 109-117.

HEARST M. A. & PLAUNT C. (1993). Subtopic structuring for full-length document access.
Proceedings of the ACM SIGIR-93 International Conference On Research and Development
in Information Retrieval, p. 59-68.

KARATZAS D. (2003). Text Segmentation in Web Images Using Color Perception and Topo-
logical Features. UK : ECS Publications.

LABADIE A. & CHAUCHE (2006). Segmentation thématique par calcul de distance seman-
tique. Proceedings of DEF T’06, 1, 45-59.

LAROUSSE (1992). Thesaurus Larousse - des idées aux mots, des mots aux ide’es. Paris :
Larousse.

LELU A., M. C. & AUBAIN S. (2006). Coopération multiniveau d’approches non-supervisées
et supervisées pour la detection des ruptures thématiques dans les discours présidentiels fran-
cais. In Proceedings of DEF T’06.

MORRIS J . & HIRST G. (1991). Lexical cohesion computed by thesaural relations as an
indicator of the structure of text. Computational Linguistics, 17, 20-48.

PONTE J . M. & CROFT W. B. (1997). Text segmentation by topic. European Conference on
Digital Libraries, p. 113-125.

PRINCE V. & LABADIE A. (2007). Text segmentation based on document understanding for
information retrieval. In Proceedings of NLDB ’07, p. 295-304.

ROGET P. (1852). Thesaurus of English Words and Phrases. London : Longman.

WU Z. & TSENG G. (1993). Chinese text segmentation for text retrieval : Achievements and
problems. Journal of the American Society for Information Science, 44, 532-542.

YANG C. C. & LI K. W. (2005). A heuristic method based on a statistical approach for chinese
text segmentation. Journal of the American Society for Information Science and Technology,
56, 1438-1447.

