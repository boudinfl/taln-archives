La Grammaire Semantique Reversible

Un modéle de langage pour le DHM :
la Grammaire Sémantique Reversible

Jerome Lehuen

LIUM — Universite du Maine
Avenue Laennec, 72085 Le Mans Cedex 9
Jerome.Lehuen@lium.uniV—lemans.fr

Resume Cet article propose un modele de langage dedie au dialogue homme—machine, ain-
si que des algorithmes d’analyse et de generation. L’originalite de notre approche est de faire
reposer l’analyse et la generation sur les memes connaissances, essentiellement semantiques.
Celles—ci sont structurees sous la forme d’une bibliotheque de concepts, et de formes d’usage
associees aux concepts. Les algorithmes, quant a eux, sont fondes sur un double principe de
correspondance entre des offres et des attentes, et d’un calcul heuristique de score.

Abstract In this paper we present a language model for man—machine dialogue, as well as
algorithms for analysis and text generation. The originality of our approach is to base analysis
and generation on the same knowledge. These one is structured like a library of concepts and
syntactic patterns. The algorithms are based on a principle of correspondence between offers
and expectations, and calculation of a heuristic scoring.

Mots-clés 2 Grammaire Semantique, Reversibilite, Analyse, Generation, Dialogue.
Keywords 2 Semantic Grammar, Reversibility, Analysis, Generation, Dialogue.

1 Introduction

La finalite de la recherche en dialogue homme—machine (DHM) est de permettre aux systemes
informatiques d’interagir avec leurs utilisateurs selon des modalites proches de celles utilisees
dans les interactions humaines, en particulier la modalite Verbale. Dans cette optique, les theo-
ries et modeles en TAL sont convoques car ils ont pour Vocation de decrire la structure et la
fonction des productions langagieres. Or, il se trouve que le TAL s’est longtemps focalise sur
l’analyse de textes, selon une approche essentiellement monologique, tant du cote des niveaux
de traitements (morphologie, syntaxe, semantique, pragmatique), que des applications Visees
(correction, indexation, resume, traduction). Anne Nicolle ecrit dans (Nicolle, 2006) que la
diﬂ"iculte'principale du DHM vient du monologisme de l ’interface [. . .] avec une vision du dia-
logue comme succession d ’e'nonce's autosuﬁisants, sur le modele de l ’e'crit. Daniel Luzzati
constate dans (Luzzati, 2006) l ’inade'quation des grammaires actuelles construites a partir de
donne'es sans rapport avec les productions dialogiques. D’un cote’, on trouve des descriptions
qui ne correspondent que rarement a des exemples de langue en interaction. De l ’autre cote’,
on a des the'ories de l ’interaction, fortement descendantes, qui ne rencontrent que rarement la
parole. De plus, la morphosyntaxe du dialogue est approximative. Meme le concept de phrase
est remis en question : en dialogue, on produit des e'nonce's dont la comple'tude ne peut se me-

JEROME LEHUEN

surer qu’en termes d’eﬂ“icacite' interactive (Luzzati, 2006). Ils comportent des bruits, des hesi-
tations, des disﬂuences, des inattendus structurels. C’est une langue par essence difficile,
voire impossible a decrire de facon exhaustive, qui se definit par sa spontaneite et par sa va-
riabilite. Par ailleurs, les systemes de DHM dissocient souvent les aspects interpretation et
generation. Cette dichotomie n’est pas redhibitoire : la generation des enonces de la machine
est moins problematique que l’analyse des enonces de l’usager, puisqu’on peut determiner un
champ lexical et des formes d’usage en fonction d’une application visee. Cela dit, comme a
d’autres auteurs (Gertjan, 1993) (Dymetman, 1994), il nous est apparu interessant de mutuali-
ser les connaissances de l’analyse et de la generation, le systeme etant en mesure de dire ce
qu’il comprend et de comprendre ce qu’il dit. Cette capacite n’est pas neutre. Tout d’abord,
elle permet des citations et reformulations des enonces de l’usager par la machine. Ensuite,
elle rend possible une forme de reﬂexivite de l’activite langagiere de la machine, ce qui lui
permet potentiellement de s’autocontroler au cours des phases de generation. Enfin, elle per-
met d’envisager des evolutions conjointes de ces deux competences des lors que les connais-
sances evoluent, par intervention exterieure ou par apprentissage automatique.

Partant de ces considerations, nous developpons actuellement le moteur de dialogue YADE,
construit autour d’un modele de langage adapte a la problematique du DHM. Ce modele
« oriente connaissances >> associe une semantique lexicale et des bibliotheques de formes
d’usage utilisables en analyse comme en generation. Les algorithmes d’analyse et de genera-
tion fonctionnent de facon opportuniste. Ils ne sont pas fondes sur des principes d’unification
et de contraintes mais sur des principes de dependances et de score. L’utilisation conjointe
d’une syntaxe partielle/relachee et d’une semantique lexicale a deja ete exploree, notamment
par (Goulian, Antoine, 2001). La specificite de notre approche tient essentiellement dans la
réversibilité, laquelle conditionne le modele des connaissances et les algorithmes. La mise en
oeuvre d’une grammaire reversible en generation est egalement exploree dans (Gardent, Kow,
2007) : le generateur GENI combine un algorithme non—deterministe et un mecanisme de se-
lection des paraphrases. La difference avec notre proposition reside dans le modele de langage
et dans les criteres de déterminisation. GENI exploite une grammaire d’arbres adjoints, basee
sur l’unification, alors que YADE utilise une grammaire essentiellement semantique.

Le moteur de dialogue YADE est architecture selon quatre niveaux (cf. Fig. 1) dont les trois
premiers (langage, dialogue et tache interactive) communiquent via une memoire de travail
commune, un peu a la facon des architectures de type << tableau noir >>. Cet article se focalise
sur le niveau langagier qui implemente la Grammaire Semantique Reversible (GSR). La pre-
miere partie decrit le modele de langage (representations et connaissances), la seconde partie
presente les algorithmes d’analyse et de generation, ainsi que quelques exemples.

Niveau langagier (GSHJ

Niveaiu dialogique

Nliveau de ta téche interactive
Niveau applicatiif

Figure 1 : Architecture du moteur de dialogue YADE

  

Connaissances et prccédures

our |'ana| se et la énération
p Y 9 Aspects relevants de la langue

   

Procedures dialogiques
ge ner iq ues (tacti q u es)

       

Aspects relevants du dialogue
Bibliothéque d'enchainements
interactionnels {sequences}

  

. Aspects relex-rants de la téche
Connaissances et

procedures metier

La Grammaire Sémantique Reversible

2 Le modéle de langage de la GSR

Cette partie présente d’abord le modele de représentation des énoncés (de l’usager et de la
machine), puis le forrnalisme << orienté connaissances >> qui permet de passer d’une chaine de
caracteres a une représentation exploitable par le moteur de dialogue et inversement. Ces
représentations sont centrales dans notre proposition car elles sont communes aux modules

d’analyse, de génération, et de dialogue.

2.1 Représentation des énoncés

En DHM, il s’agit d’obtenir, a partir d’énoncés relativement courts, des représentations qui
permettent de déclencher des mécanismes cognitifs, en rapport avec une tache donnée ou avec
le dialogue lui—méme. A moins d’étre une étape nécessaire, une représentation syntagmatique
n’est d’aucune utilité. Enfin, nous souhaitions pouvoir passer d’un énoncé a sa représentation
et inversement sans avoir a convoquer des modélisations morphosyntaxiques subtiles. Partant
de ces objectifs et contraintes, nous avons opté pour un formalisme fortement inspiré des
grammaires de dépendance (Tesniere, 1959) mais résolument orienté Vers la sémantique. La
représentation d’un énoncé consiste en un graphe de relations qui couvre les mots ou expres-
sions significatives par rapport au contexte applicatif et/ou dialogique. Les nceuds du graphe
(appelés granules) sont des concepts instanciés dans le double contexte de l’énoncé et du dia-
logue. Les granules sont identifiés par leur concept, une catégorie sémantique ou pragmatique
indiquant son role dans la structure ou dans l’interaction, et un numéro d’instanciation.

Par exemple, l’analyse de l’énoncé « Bonjour, je voudrais une baguette bien cuite s’il vous
plaft » produit trois granules—racines: ouVerture:SALUER#1, demande:DEMANDER#6 et
politesse:SVP#4 (cf. Fig. 2). Le choix des concepts et des catégories ne dépend pas du mo-
dele : il releve d’un travail d’ingénierie des connaissances a partir d’un domaine d’application
et éventuellement d’un corpus de dialogue.

Granules racines

(ouverture) (demande) (polite-sse)
SALUER#‘i DEMANDEFW6 SVP#4

      
   
 

(ouverture) (demande) (politesse) {obieg
1« 1 BAGUETTE#5
Bonjour, je voudrais une baguette bien cuite s‘il vous plait.
W9) (quamé) [ (quantité) J [ (qualité) J
(Objet) UN#2 CU|TE#3

Figure 2 : Structure de dépendances produite par la GSR

2.2 Représentation des connaissances

Le modele des connaissances est construit autour de la notion de concept. Un concept repre-
sente un objet, une action, la Valeur d’un attribut, etc. 11 possede des propriétés qui permettent,
d’une part de le distinguer des autres concepts, d’autre part de le relier a d’autres concepts
dans le cadre de l’application Visée. Un concept est caractérisé par des offres, des attentes, et
des formes d’usage (cf. Fig. 3).

Jfﬂu)Nﬂ3lJﬂ{UE%J

 
 
   
 

_, ------------- 4- analyse ------------- ._
I‘ {X Z} . , . i‘.
of-fres \ =V* _, ...... -- generation -—-—--..\ ;
. I _1 I.
' ¢IIIIIb- «
‘V I
concept ''bla bla bla"
aﬁentes

I I
{e1,e2} {e3}

Figure 3 : Modele de concept de Valence 2

Les descripteurs des oﬂres sont des catégories ou des traits sémantiques (Katz, Fodor, 1963).
Le modele ne présuppose pas la facon dont les traits sont déterminés : soit a partir de condi-
tions nécessaires et suffisantes (et nous obtenons une collection de concepts autosuﬂisants),
soit a partir de différences entre concepts (et nous obtenons une structure relationnelle de
concepts). Cette distinction, explorée dans (Nicolle et al., 2001), ne fait pas l’objet de cet arti-
cle. Les attentes, qui sont décrites dans les mémes termes que les offres, caractérisent des ac-
tants, des circonstants, des modifieurs, des attributs. Les attentes ne sont pas obligatoires, elles
participent a la description du concept en décrivant les liaisons potentielles entre granules.
Enfin, un concept est associé a un catalogue de formes d’usage. Les formes d’usage sont des
structures de surface composées de mots et de références aux attentes du concept. Elles sont
associées a des traits pragmatiques et/ou morphologiques qui permettent de caractériser fine-
ment les formulations de l’usager pour un méme acte de langage (type de langage, politesse,
force illocutoire, etc.). La multiplication des formes d’usage engendre une certaine Variabilité
en interpretation ou pour la génération des énoncés de la machine. Nous avons choisi
d’intégrer les Variations morphologiques (genre et nombre) dans les formes (codage ﬁ4ll—f0rm)
pour faire l’économie de traitements morphologiques en analyse, et surtout en génération.
C’est la raison pour laquelle des traits morphologiques sont combinés aux traits pragmatiques.

<concept nom="DEMANDER" offres="action demande">

<attente code="Al" catégories="demandable"
description="l'objet de la demande"
question="que désirez—vous ?"/>

<syntaxe traits="familier">file—moi Al</syntaxe>

<syntaxe traits="normal">je voudrais Al</syntaxe>

<syntaxe traits="normal">avez—vous Al</syntaxe>

<syntaxe traits="soutenu">puis—je avoir Al</syntaxe>

<syntaxe traits="assertion rpv">vous désirez Al</syntaxe>

<syntaxe traits="vérification rpv">c’est bien A1 que vous désirez ?</syntaxe>

</concept>

<concept nom="BAGUETTE" offres="objet demandable">

<attente code="Al" catégories="quantité"

description="la quantité"

question="combien de baguettes désirez—vous ?"/>
<attente code="A2" catégories="cuisson"

description="la cuisson"

question="quelle cuisson souhaitez—vous ?"/>

<syntaxe traits="féminin singulier">Al baguette A2</syntaxe>
<syntaxe traits="féminin pluriel">Al baguettes A2</syntaxe>
</concept>

Tableau 1 : Fragment d’une base de connaissances codée en XML

La Grammaire Sémantique Reversible

La constitution d’une base de connaissances dédiée représente un important travail, meme s’il
est envisageable de réutiliser des << connaissances générales >> d’une application a l’autre, que
ce soit au niveau de l’ontologie (contribution de l’ingénierie des connaissances) ou au niveau
des formes d’usage (contribution de la linguistique). Parallelement a notre démarche, et non
sans rapports avec celle—ci, a été développée la Grammaire Interactive (cf. § 2.3). Cette der-
niere peut constituer une réponse au probleme de la systématisation de la constitution des
formes d’usage de la GSR, avec un point de vue linguistique et dialogique.

2.3 GSR et Grammaire Interactive

L’objectif de la Grammaire Interactive (Luzzati, 2007) est d’aborder la morphosyntaxe avec
un point de vue résolument dialogique: la morphosyntaxe d’une question se justiﬁe par
l’existence d’une re'ponse pre'suppose'e ou escompte'e, ci laquelle les interactants adherent ou
dont ils se de'marquent. Le principe consiste a faire varier une formulation prototypique selon
des paradigmes qui dependent ou non du type et du theme de l’énoncé. La combinatoire des
criteres identifies génere une table a n dimensions qu’il s’agit de remplir. Par exemple, pour
les questions quantificatrices, on fait varier la formulation « Combien coute X ? » selon deux
dimensions: une dimension propre a la quantification, et une dimension généralisable a
l’interrogation (cf. Tableau 2). Cette etude s’est focalisée pour l’instant sur les questions
quantificatrices et locatives du corpus Ritel (Rosset, Petel, 2006).

uestion adverbiale numérale determinative nominale propositionnelle
. . A Combien d ’euros . A A A .
simple Combzen coute X .7 Come X 7 Quelpnx couteX .7 Que coute X .7 X coute—t—zl 5 euros .7
. A . X coute combien A . A .
tomque X coute combzen .7 , X coute quelprzx .7 X coute quot .7
d 7
euros .
renfor A Combien est—ce que Combien d’euros est— Quel prix est—ce que Qu’est—ce que coute Est—ce que X coute 5
coute X .7 ce que coute X .7 coute X .7 X .7 euros .7
. . J e voudrais savoir . . Je voudrais savoir . . .
A . . Je voudrazs savozr , , Je voudrazs savozr , Je voudrazs savozr sz X
periphrastique , A combzen d euros , A qu est—ce que X A
combzen X coute A quel pnx coute X A coute 5 euros
coute X coute

assertive X coute 5 euros .7 X coute 5 en euros .7 Leprix de X est de 5 X Come quelque

euros .7 chose .7

Tableau 2 : Variabilité de la question « Combien coute X ? » (Luzzati, 2007)

Pour élargir la couverture morphosyntaxique, il suffit d’ajouter des criteres de variabilité. Par
exemple, la prise en compte de l’adverbe « bien » augmente la combinatoire. Apres avoir fait
le meme travail pour les réponses associées, il s’agit de dégager les structures syntaxiques, et
de les coder en tant que formes d’usage.

La Grammaire Interactive repose sur l’identification de structures de surface, a partir d’une
combinaison de criteres morphosyntaxiques et pragmatiques. Elle est moins générique que
des grammaires qui reposent sur des connaissances de granularité plus fine. Ceci dit, nous
formulons l’hypothese que la subtilité linguistique permise par la GI, la finesse dans la forrnu—
lation des réponses, peuvent compenser ce manque de généricité. C’est la raison pour laquelle
nous nous inspirons de la GI pour développer la GSR.

JEROME LEHUEN

3 Analyse et génération des énoncés

L’adéquation des représentations proposées au §2 pour le dialogue dépend des processus qui
Vont les utiliser. En situation de dialogue, en compréhension comme en génération, un résultat
erroné ou approximatif est préférable a une absence de résultat qui entraverait l’interaction.
Ceci est Vrai a condition de pouvoir corriger ou compléter ce résultat. C’est pour cette raison
que : premiérement, nous avons privilégié des algorithmes non—déterministes, deuxiemement,
les représentations produites par l’analyseur sont partagées avec le dialogueur et manipulables
par celui—ci. Les sous—sections suivantes décrivent les algorithmes d’analyse des énoncés de
l’usager, puis de génération de ceux de la machine.

3.1 Algorithme d’analyse

L’analyse part d’un énoncé sous forme de chaine de caracteres et produit une représentation
construite suivant le modele présenté au §2.1. L’algorithme d’analyse procéde en cinq étapes
au cours desquelles il s’agit d’instancier et de relier des << granules >> en se fondant sur un cri-
tére syntaxique (reconnaissance de leurs formes d’usage) et/ou sur un critére sémantique (cor-
respondance entre leurs offres et leurs attentes). Ces deux critéres sont soit combinés, soit uti-
lisés indépendamment l’un de l’autre, afin de générer des hypotheses. Les cinq étapes de
l’analyse sont les suivantes :

1. Noyautage = instanciation de certains types de granules terminaux (comme les dates)
a l’aide d’eXpressions réguliéres ou de grammaires locales ;

2. Segmentation = identification des portions de texte susceptibles de contenir un gra-
nule—fils a l’aide des formes d’usage et des attentes. L’objectif est de générer des hy-
potheses sur des mots ou expressions non répertoriées (granules hypothétiques) ;

3. Construction = instanciation des granules et de leurs liaisons a l’aide des formes
d’usage et des attentes. L’algorithme repose sur le remplissage d’un tableau de granu-
les (lexicalisés ou hypothétiques), et sur une fonction d’éValuation ;

4. Résolution = suppression des conflits de position entre granules. Les granules faibles
sont supprimés au profit des granules forts (cf. fonction d’éValuation) ;

5. Sauvetage = rattachement hypothétique des << granules orphelins >> sur des critéres de
correspondance entre offres et attentes, et de proximité.

La méthode choisie pour progresser dans l’analyse sans avoir a effectuer d’incessants retours
arrieres est l’analyse tabulaire ou chart parsing (Kay, 1980) dont le principe est de poursuivre
en paralléle des analyses concurrentes, a chaque niveau de granularité permis par le modele
de langage. Dans notre cas, il s’agit de mémoriser les granules (hypothétiques ou non) dans
une sorte de tableau—agenda avec leur position, leurs dépendances, et leur score. A la fin de la
cinquiéme étape, ne restent que les structures fortes ou de méme poids. En cas d’ambigu'1'té,
une reformulation est proposée et c’est le dialogue qui devra permettre de trancher.

Un granule est caractérisé par une position, une couverture (nombre de mots), et une disper-
sion (nombre de mots non pris en compte). De plus, il est éventuellement relié a des granules-
fils Gi. Le score d’une liaison Ai correspond au nombre d’éléments en commun entre les en-
sembles de traits offerts et attendus. Le score d’un granule G est donné par la formule :

La Grammaire Sémantique Reversible

111."
.h'i'r:|'c(Cl = i'm:1‘c*J‘mI‘cll"}] - rff.s';)r’1‘.x'frJ:i{f}'J + E (1 U )4 .\'r'rJI'c(.-‘"1,-} X .\'r'rI|'c((§,-])

i‘:

Par exemple, le score du granule BAGUETTE de l’énoncé : « Je voudrais une baguette trés
bien cuite » est de 5—1+10+20=34 (cf. Fig. 4). Tout granule en conflit de position avec celui—
ci, et ayant un score inférieur a 34, sera supprimé du chart, avec des suppressions en chaine
sur les liaisons et granules dependants.

oftres = { objei, demandaole}
forme = "A1 baguette A2"
texte = "une baguette tres bien ouite"
objet:BAGUE1TE position = 4

score : 34 couverture = 5
dispersion =1

 

attentes = { quantité } attentes ={ qualité }

oﬁres = { quantite} 5'00"?“ = 1 Scorefa = 1 oftres = { qualité, cuisson }

forme = "une" forme ="bien cuite"
“‘-"‘°="“”°" ( quanlilé:UN J [ qua|ité:CU|TE J ‘W’-="b“’“°““°"

position = 4 Score = 1 Score : 2 position = 7'
couverture = 1 couverture = 2
dispersion = 0 dispersion = 0

Figure 4 : Calcul du score du granule BAGUETTE

3.2 Quelques cas particuliers d’analyse

Cette section donne des exemples qui illustrent des performances particulieres (identification
des questions toniques/périphrastiques, resolution d’ambigu'1'tés homonymiques, resolution de
conjonctions de coordination), ainsi que la capacité qu’a l’analyse de générer des hypotheses
(hypotheses de rattachement ou hypotheses lexicales).

0 Le premier exemple illustre la difference d’analyse entre une question tonique et une ques-
tion périphrastique. Le type des questions non—périphrastiques est note comme traits d’un
granule, alors que les questions périphrastiques génerent un concept supplémentaire :

a) Le s2 il commence quand ?
=> (DATE-DE interrogation tonigue A1 :(événement:S2))

b) Je voudrais savoir ci quelle date commence le s2
=> (QUESTIONNER A1 :(information:DATE-DE A1 :(événement:S2)))

0 Le deuxieme exemple montre comment l’analyseur résout naturellement les rares (et artifi-
ciels) cas d’ambigu'1'té homonymiques si le contexte le lui permet. Ici, le Vocable << avocat >>
est désambigu'1'sé par son adjectif :

C) Je voudrais un avocat bien mlir
=> (DEMANDER A1 :(demandab|e:AVOCAT-FRUIT A1 :(quantité:UN) A2:(avancement:MUR)))

d) Je voudrais un avocat compétent
=> (DEMANDER A1 :(demandab|e:AVOCAT-PERS A1 :(quantité:UN) A2:(qua|iﬁcatif:COMPETENT)))

JEROME LEHUEN

0 La conjonction de coordination << et >> est construite en fonction des categories ou des traits
des granules situés a gauche et a droite de la conjonction, qui déterminent sa portée. La
catégorie du concept ET est donnée par ses arguments :

e ) Je voudrais une baguette et avez~v0us deux croissants ?
=> (demande:ET A1 :(demande:DEMANDER A1 :(demandab|e:BAGUETTE A1 :(quantité:UN)))
A2:(demande:DEMANDER A1 :(demandab|e:CRO|SSANT A1 :(quantité:DEUX))))

f) Je voudrais une baguette et deux croissants
=> (DEMANDER A1 :(demandable:ET A1 :(demandab|e:BAGUETTE A1 :(quantité:UN))
A2:(demandab|e:CRO|SSANT A1 :(quantité:DEUX))))

° L’étape de sauvetage permet d’analyser des énoncés disloqués qui produisent des granules
orphelins. Lorsque les offres et les attentes sémantiques le permettent, l’analyseur tente des
rattachements hypothétiques (indiqués ci—dessous par un point d’interrogation) :

g ) Le semestre 2 je voudrais savoir la date
=> (QUESTIONNER A1 :(information:DATE-DE ?A1:(événement:S2)))

h) Le semestre 2 la date je voudrais savoir
=> (QUESTIONNER ?A1:(information:DATE-DE ?A1:(événement:S2)))

° Enfin, grace a l’étape de segmentation, l’analyseur est capable de faire des hypotheses sur
des mots inconnus. Les segments [le truc] et [le bidule] ont été générés a partir de la forme
d’usage << ranger [objet] dans [rangement] >>. Au dialogueur de gérer ces hypotheses :

i ) Ranger le truc dans le bidule
=> (RANGER A1: ?ob'et:"le truc" A2: ?ran ement:"le bidule" )

3.3 Algorithme de génération

Le principe est de reconstruire un texte a partir d’une structure de granules en activant les
formes d’usage les plus intéressantes et en les composant. Comme pour l’analyse, il s’agit
d’étre opportuniste, c’est—a—dire de faire pour le mieux avec ce dont on dispose, en fonction
d’indices et non pas de contraintes. L’algorithme de génération procede de la facon suivante.
Un but de génération est propagé de la racine de la structure Vers ses feuilles, en Véhiculant un
ensemble Tg de modifieurs globaux (cf. Fig. 5). Un score est calculé, pour chaque Verbalisa—
tion et pour chaque noeud, en fonction d’un critere global (adéquation avec Tg), et d’un critere
local (score des fils et nombre de traits communs entre peres et fils). L’énoncé final est obtenu
en combinant les Verbalisations de meilleurs scores. Soit c0te(V) la cote d’une Verbalisation,
Tp(V) ses traits propres, et Tp( Vi ) les traits propres des Verbalisations << filles », le score d’une
Verbalisation Vest alors donné par la forrnule :

1'14.‘
.w'rJ|‘c[1x’l = cntc*[l=") + 1m‘..u"{'.1';rJ{lr"] 1"“ 'f'_::1le':.I"J']I + Z [10 X .x'r'rJ1‘1:{‘lv"f‘J + :'m‘nl['f',r){"L-‘E11 Fl '1' 'pI[i‘l—"_])J

Par exemple, le score de la Verbalisation « une baguette bien cuite » est de 1+O+12+12=25,
tandis que le score de la Verbalisation « un baguette bien cuit » est de 1+O+11+11=23. Avec
Tg = {familier}, le score de la Verbalisation « je voudrais une baguette bien cuite » est de
1+O+250=251, tandis que le score de la Verbalisation « ﬁle—m0i une baguette bien cuite » est
de 1+1+250=252. Cette Verbalisation est gagnante. Si l’eXpression «ﬁle—m0i... » n’aVait pas
été connue du systeme, « je voudrais... » serait restée. En cas de ballottage, on applique une

La Grammaire Sémantique Reversible

fonction aléatoire. La cote d’une verbalisation (par défaut = 1) permet de faire évoluer les
« habitudes >> du générateur en fonction de criteres extérieurs au processus de generation,
comme la fréquence d’usage constatée en analyse, par exemple.

BUT
lexle : "file-moi une baguette bien cuite"

T9 ﬁfamilier} score : 1 -1- 1 + 250 : 252

lorme = "fi|e-moi A1 "

Tp : { familier}

T9 = 1  i“$".::a2t°;‘f 2:” 
lorme = "A1 baguette A2"
Tp = { fern, sing}

texte A2 = “bien cuite"
score A2 = 1

[granule DEMANDEFIJ

  

granule ‘BAG U ETTE

  
    
  

Tg ={1ami|ier}

lorme = "bien cuite"

lorme = “une" [
Tp : { fém. sing}

Tp = { fém‘ Sing} granule UN J [ granule CUIT J

Figure 5 : Exemple de processus de generation

Les algorithmes d’analyse et de generation ont été testes sur des jeux d’énoncés, a l’aide d’un
script de << double traduction >>, chaque énoncé étant analyse puis régénéré dans la foulée. La
representation inteme de l’énoncé est alors utilisée comme un << langage pivot >>. Nous avons
ainsi pu comparer les énoncés d’origines et leurs regénérations. Bien que notre problématique
n’ait a priori aucun rapport avec la traduction automatique, nous avons tenté de fournir au
systeme des formes d’usage anglophones et spécifié un Tg = {anglais}. 11 a été intéressant de
constater que le générateur produisait des traductions correctes et que, lorsqu’une forme
d’usage anglophone venait a manquer, l’algorithme utilisait une forme d’usage francophone.
Le mélange d’anglais et de francais qui en résulte illustre bien le principe opportuniste.

4 Conclusion

La finalité de notre modele n’est pas de représenter la phrase ou l’énoncé. Elle est de fournir a
un moteur de dialogue finalise les elements qui lui permettront de répondre a un énoncé, dans
le contexte d’une application donnée. Ainsi, les representations produites sont ni absolues, ni
forcément utilisables hors d’un contexte dialogique. De plus, elles sont tres dépendantes des
connaissances fournies, lesquelles sont tres dépendantes de l’application visée. En revanche,
nous proposons un forrnalisme << reversible >> puisque utilisable en analyse comme en genera-
tion, et des algorithmes indépendants des applications. Parce qu’il tolere bruits, dislocations et
incomplétudes, et parce qu’il peut faire certaines hypotheses, l’analyseur vise la robustesse.
Le modele de langage est non—normatif car les structures syntaxiques décrites sont davantage
proposées qu’imposées. Nous l’avons également souhaité extensible: il suffit d’ajouter une
forme d’usage pour augmenter son potentiel, en analyse comme en generation. La multiplica-
tion des formes d’usage permet d’interagir en prenant en compte la variabilité et les subtilités
langagieres décrites dans la grammaire interactive. Le modele de langage et les algorithmes
présentés sont implémentés en CLIPS (http://clipsrules.sourceforge.net) et opérationnels.
Nous disposons également d’un éditeur dédié permettant d’éditer une ontologie de concepts
selon le modele ANADIA (Beust, 1998) (Nicolle et al. 2001), ainsi que sa GSR associée. La
plate—forme de dialogue est en cours de développement. Elle integrera un module de recon-
naissance de la parole et un module de synthese vocale. Afin de positionner notre approche
par rapport a d’autres, nous avons engage une evaluation en nous fondant sur le corpus utilise
pour la campagne Evalda—Media (Bonneau—Maynard et al. 2006).

JEROME LEHUEN

References

BEUST P. (1998). Contribution a un modele interactionniste du sens. These de doctorat
d’informatique de l’Universite de Caen.

BONNEAU—MAYNARD, H., AYACHE, C., BECHET, F., DENIS, A., KUHN, A., LEFEVRE, F., Mos-
TEFA, D., QUIGNARD, M., ROSSET, S., SEVRAN, C., VILLANEAU, J. (2006). Results of the
french evalda—media evaluation campaign for literal understanding. In: Proceedings of LREC
2006, Genoa, 2054-2059.

DYMETMAN M. (1994). Inherently reversible grammars. In: Tomek Strzalkowski (ed.), Rever-
sible Grammar in Natural Language Processing, Kluwer, 33-57.

GARDENT C., KOW E. (2007). A symbolic approach to near—deterministic surface realisation
using tree adjoining grammar. In: Proceeding of ACL 2007, Prague, 328-335.

GERTJAN VON NOORD (1993). Reversibility in Natural Language Processing. Dissertation.
University of Utrecht. http://www.let.rug.nl/~vannoord/papers/diss/diss.html

GOULIAN J ., ANTOINE J .—Y. (2001). Comprehension Automatique de la Parole combinant syn-
taxe locale et semantique globale pour une CHM portant sur des taches relativement com-
pleXes., In: Proceeding of TALN 2001, Tours, 203-212.

GREIMAS A.J. (1966). Semantique Structurale. PUF : Paris.

KATZ J.J., FODOR J.A. (1963). The Structure of a Semantic Theory. In: Rosenberg and Travis
(1971), Language n°34 (2). 170-210.

KAY M. (1980). Algorithm shemata and data structures in syntactic processing. Rapport
CSL—80—12. Xerox Corporation.

LUZZATI D. (2006). Dialogue et apprentissage. In: Comprehension des langues et interaction,
Gerard Sahab (ed.), Hermes—Lavoisier, 337-356.

LUZZATI D. (2007). Essai de description interactive des questions quantificatrices. In: Actes
du colloque La Quantiﬁcation. Strasbourg. Presses Universitaires de Caen. (a paraitre)

NICOLLE P., BEUST P., PERLERIN V. (2001). Un analogue de la memoire pour un agent logi-
ciel interactif. In: Revue In Cognito n°21. 37-66.

NICOLLE P. (2006). Comprehension et interaction. In: Comprehension des langues et interac-
tion, Gerard Sahab (ed.), Hermes—Lavoisier, 141-170.

ROSSET S., PETEL. S. (2006). The Ritel Corpus - An annotated Human—Machine open—domain
question answering spoken dialog corpus. In: Proceedings of International Conference on
Language Resources and Evaluation. Genes. 1640-1643.

TESNIERE L. (1959). Elements de syntaxe structurale, Paris, Klincksiek.

