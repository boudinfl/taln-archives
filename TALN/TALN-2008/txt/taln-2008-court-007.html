<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>E-Gen : Profilage automatique de candidatures</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2008, Avignon, 9&#8211;13 juin 2008
</p>
<p>E-Gen : Profilage automatique de candidatures
</p>
<p>R&#233;my Kessler1,2 Juan Manuel Torres-Moreno1 Marc El-B&#232;ze1
(1) LIA / Universit&#233; d&#8217;Avignon, 339 chemin des Meinajari&#232;s, 84911 Avignon
</p>
<p>(2) AKTOR 12, all&#233;e Ir&#232;ne Joliot Curie 69800 Saint Priest
{remy.kessler, juan-manuel.torres, marc.elbeze}@univ-avignon.fr
</p>
<p>R&#233;sum&#233;. La croissance exponentielle de l&#8217;Internet a permis le d&#233;veloppement de sites
d&#8217;offres d&#8217;emploi en ligne. Le syst&#232;me E-Gen (Traitement automatique d&#8217;offres d&#8217;emploi) a
pour but de permettre l&#8217;analyse et la cat&#233;gorisation d&#8217;offres d&#8217;emploi ainsi qu&#8217;une analyse et
classification des r&#233;ponses des candidats (Lettre de motivation et CV). Nous pr&#233;sentons les
travaux r&#233;alis&#233;s afin de r&#233;soudre la seconde partie : on utilise une repr&#233;sentation vectorielle de
texte pour effectuer une classification des pi&#232;ces jointes contenus dans le mail &#224; l&#8217;aide de SVM.
Par la suite, une &#233;valuation de la candidature est effectu&#233;e &#224; l&#8217;aide de diff&#233;rents classifieurs
(SVM et n-grammes de mots).
Abstract. The exponential growth of the Internet has allowed the development of a mar-
ket of on-line job search sites. This paper presents the E-Gen system (Automatic Job Offer
Processing system for Human Resources). E-Gen will perform two complex tasks : an analysis
and categorisation of job postings, which are unstructured text documents, an analysis and a
relevance ranking of the candidate answers (cover letter and curriculum vitae). Here we present
the work related to the second task : we use vectorial representation before generating a classi-
fication with SVM to determine the type of the attachment. In the next step, we try to classify
the candidate answers with different classifiers (SVM and ngrams of words).
Mots-cl&#233;s : Classification de textes, Mod&#232;le probabiliste, Ressources humaines, Offres
d&#8217;emploi.
</p>
<p>Keywords: Text Classification, Probabilistic Model, Human Ressources, Job Offer.
</p>
<p>1 Introduction
</p>
<p>La croissance exponentielle de l&#8217;Internet a permis un grand d&#233;veloppement de jobboards (Bizer
&amp; Rainer, 2005; Rafter et al., 2000). Cependant, les r&#233;ponses des candidats repr&#233;sentent une
grande quantit&#233; d&#8217;information difficile &#224; g&#233;rer rapidement et efficacement pour les entreprises
(Bourse et al., 2004; Morin, 2004; Rafter et al., ). En cons&#233;quence, il est n&#233;cessaire de la traiter
d&#8217;une mani&#232;re automatique ou assist&#233;e. Le LIA et Aktor Interactive, agence de communica-
tion fran&#231;aise sp&#233;cialis&#233;e dans l&#8217;e-recruiting, d&#233;veloppent le syst&#232;me E-Gen pour r&#233;soudre ce
probl&#232;me. Le syst&#232;me E-Gen se compose de deux modules principaux :
</p>
<p>1. Un module d&#8217;extraction de l&#8217;information &#224; partir de corpus des courriels provenant d&#8217;offres
d&#8217;emplois extraites de la base de donn&#233;es d&#8217;Aktor.
</p>
<p>2. Un module pour analyser et calculer un classement de pertinence du profil du candidat
(lettre de motivation et curriculum vitae).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Kessler, Torres-Moreno and El-B&#232;ze.
</p>
<p>Nos pr&#233;c&#233;dents travaux (Kessler et al., 2007; Kessler &amp; El-B&#232;ze, 2008) pr&#233;sentaient le premier
module, l&#8217;identification des diff&#233;rentes parties d&#8217;une offre d&#8217;emploi et l&#8217;extraction d&#8217;informa-
tions pertinentes (contrat, salaire, localisation, etc.). Lors de la mise en ligne d&#8217;une annonce,
Aktor g&#233;n&#232;re une adresse &#233;lectronique de &quot;r&#233;ponse&quot; pour chacune de ces offres. Chaque cour-
rier &#233;lectronique de candidature est par la suite redirig&#233; vers le logiciel de Ressources Humaines,
Gestmax1, afin de pouvoir &#234;tre trait&#233;. Cependant le flux de r&#233;ponses &#224; une offre d&#8217;emploi en-
tra&#238;ne un long travail de lecture des candidatures par les recruteurs. Afin de faciliter cette t&#226;che,
nous souhaitons mettre en place un syst&#232;me capable de fournir une premi&#232;re &#233;valuation auto-
matis&#233;e des candidatures selon divers crit&#232;res. Nous pr&#233;sentons les premiers travaux concernant
le second module du syst&#232;me E-Gen. On pr&#233;sente en section 2 l&#8217;architecture globale d&#8217;E-Gen
et la strat&#233;gie pour identifier chaque document de la candidature. Nous pr&#233;sentons en section 3
la m&#233;thode utilis&#233; afin d&#8217;effectuer un tri entre les pi&#232;ces jointes avant de pr&#233;senter en section 4
les travaux concernant l&#8217;&#233;valuation d&#8217;un curriculum vitae (abr&#233;g&#233; CV) d&#8217;une candidature avant
de d&#233;tailler les diff&#233;rents r&#233;sultats obtenus dans la section finale.
</p>
<p>2 Vue d&#8217;ensemble du syst&#232;me
</p>
<p>Nous avons choisi de d&#233;velopper un syst&#232;me r&#233;pondant aussi rapidement et judicieusement
que possible au besoin d&#8217;Aktor, et donc aux contraintes du march&#233; de recrutement en ligne.
(Kessler &amp; El-B&#232;ze, 2008) d&#233;taillent la strat&#233;gie mise en place afin de r&#233;soudre la t&#226;che 1. Ici,
nous pr&#233;senterons principalement la seconde t&#226;che ainsi que les premiers travaux concernant la
t&#226;che 3 (voir figure 1), l&#8217;&#233;valuation de la candidature. Lors de la r&#233;ception d&#8217;une candidature
par courrier &#233;lectronique, le syst&#232;me extrait le corps du message, ainsi que les diff&#233;rentes pi&#232;ces
jointes et les transforme au format XML (wvWare2 traite les documents MS-Word et produit
une version texte du document d&#233;coup&#233; en segments, pdftotext3extrait le contenu texte d&#8217;un
document pdf). Diff&#233;rents processus de filtrage et racinisation permettent au syst&#232;me d&#8217;identifier
&#224; l&#8217;aide de machines &#224; support vectoriel (cf section 3) le contenu de la candidature (compos&#233;e
d&#8217;un CV et/ou d&#8217;une lettre de motivation pr&#233;sente dans le corps du mail ou dans les pi&#232;ces
jointes). Une fois le CV et la lettre de motivation identifi&#233;, le syst&#232;me E-Gen effectuera une
premi&#232;re &#233;valuation automatis&#233;e de cette candidature selon divers crit&#232;res tels que la richesse
du vocabulaire, le nombre de fautes d&#8217;orthographe, la correspondance entre la candidature et
l&#8217;offre d&#8217;emploi (T&#226;che 1) ainsi qu&#8217;une &#233;valuation par des m&#233;thodes d&#8217;apprentissage de cette
candidature(cf section 4). La figure 1 pr&#233;sente une vue d&#8217;ensemble du syst&#232;me E-Gen.
</p>
<p>2.1 Corpus et exemple de candidatures
</p>
<p>Un sous-ensemble de donn&#233;es a &#233;t&#233; s&#233;lectionn&#233; &#224; partir de la base de donn&#233;es d&#8217;Aktor. Ce cor-
pus regroupe plusieurs missions4 d&#8217;Aktor Sourcing&amp;Selection5 ainsi que les diverses r&#233;ponses
&#224; ces offres d&#8217;emplois class&#233;es en diff&#233;rentes bo&#238;tes6. Afin de simplifier le probl&#232;me nous avons
</p>
<p>1http ://www.gestmax.fr
2http ://wvware.sourceforge.net. La segmentation de textes MS-Word &#233;tant difficile, on a opt&#233; pour un outil
</p>
<p>existant. Dans la majorit&#233; des cas, il sectionne en paragraphes le document.
3http ://www.bluem.net/downloads/pdftotext_en
4Mission d&#233;signe la pr&#233;-s&#233;lection effectu&#233;e par le cabinet de recrutement pour une offre d&#8217;emploi.
5http ://www.aktor-selection.fr
6Gestmax permet au recruteur de classer une candidature : non lu, oui, non, peut-&#234;tre, Entretien etc..</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>E-Gen: Profilage automatique de candidatures
</p>
<p>FIG. 1 &#8211; Vue d&#8217;ensemble du syst&#232;me E-Gen.
</p>
<p>ramen&#233; chacune de ces bo&#238;tes &#224; 3 cat&#233;gories diff&#233;rentes : OUI, NON ou PEUT-ETRE (PT par
la suite). Apr&#232;s consultation du recruteur ayant effectu&#233; l&#8217;&#233;tiquetage des CV, nous avons d&#233;cid&#233;
de regrouper en une seule cat&#233;gorie les CV appartenant &#224; la classe OUI et &#224; la classe PT. En
effet, d&#8217;un point de vue ressource humaine, une candidature class&#233;e PT est une bonne candida-
ture mais ne correspondant pas forc&#233;ment &#224; la mission, ou une bonne candidature mais pas la
meilleure. Ce regroupement nous a permis d&#8217;&#233;quilibrer un peu le corpus, celui-ci &#233;tant majori-
tairement compos&#233; de candidatures &#233;tiquet&#233;es NON 2. Les missions peuvent &#234;tre r&#233;dig&#233;es en
diff&#233;rentes langues, mais notre &#233;tude porte sur les offres et les r&#233;ponses en fran&#231;ais (le march&#233;
fran&#231;ais repr&#233;sente l&#8217;activit&#233; principale d&#8217;Aktor). Ce sous-ensemble, nomm&#233; Corpus de r&#233;f&#233;-
rence a donc permis d&#8217;obtenir un corpus de r&#233;ponses class&#233;es en fonction de la mission ainsi
que du jugement d&#8217;un recruteur sur les candidatures. Le tableau 1 pr&#233;sente quelques statistiques
du corpus.
</p>
<p>Nombre de Missions Total 41
Nombre de Mission avec moins de 10 r&#233;ponses 8
NB Mission avec plus de 10 r&#233;ponses 13
NB Mission avec plus de 50 r&#233;ponses 9
NB Mission avec plus de 100 r&#233;ponses 11
Nombre de candidatures Total 3078
</p>
<p>TAB. 1 &#8211; Statistisques du Corpus de r&#233;f&#233;rence.
</p>
<p>CV Total CV not&#233; OUI CV not&#233; NON CV not&#233; PT
2755 414 2128 213
</p>
<p>LM Total LM not&#233; OUI LM not&#233; NON LM not&#233; PT
2473 407 1882 184
</p>
<p>TAB. 2 &#8211; Statistisques du Corpus de r&#233;f&#233;rence en fonction de l&#8217;&#233;tiquetage.
</p>
<p>La figure 2 pr&#233;sente un exemple de CV extrait du corpus de r&#233;f&#233;rence et la figure 3 un exemple
de lettre de motivation (abr&#233;g&#233;e en LM par la suite). Les documents ont &#233;t&#233; pr&#233;alablement ano-
nymis&#233;s. De fa&#231;on &#233;vidente le style de chaque document est diff&#233;rent, la lettre de motivation se
pr&#233;sentant comme un texte complet alors que le CV r&#233;sume le parcours professionnel de la per-
sonne de fa&#231;on concise. On observe par ailleurs que les CV, malgr&#233; un format libre, pr&#233;sentent
des similarit&#233;s entre eux du point de vue de leur contenu : On retrouve g&#233;n&#233;ralement les sec-
tions &quot;Exp&#233;rience professionnelle&quot;,&quot;Exp&#233;rience personnelle&quot;, &quot;Formation&quot;, &quot;Divers&quot; ou encore</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Kessler, Torres-Moreno and El-B&#232;ze.
</p>
<p>&quot;Loisirs&quot;) ainsi que certaines collocations pertinentes (&quot;assistante commercial&quot;, &quot;baccalaur&#233;at
scientifique&quot; etc.) comme d&#233;crit dans (Roche &amp; Prince, 2008) et d&#8217;un point de vue pr&#233;sentation
(Texte en gras ou en italique afin de d&#233;finir chaque partie, indentation etc..), m&#234;me si les dif-
f&#233;rents outils que nous utilisons afin d&#8217;extraire le texte ne nous permettent pas de r&#233;cup&#233;rer la
structure du document (cf section 2).
</p>
<p>R&#233;my BOUDIN
</p>
<p>38123 LE VERDON 
</p>
<p>remy@gomail.com
</p>
<p>N&#233; le 14 mai 1960,  37 ans
</p>
<p>DIRECTEUR D&#8217;EXPLOITATION
</p>
<p>D&#8217;EQUIPEMENTS TOURISTIQUES
</p>
<p>SITUATION ACTUELLE :
</p>
<p>Depuis 2004 : CCE SNCF Directeur d&#8217;un village de vacances de 700 lits (h&#244;tel, bungalows, camping
</p>
<p>am&#233;nag&#233;), 50 salari&#233;s en saison :
</p>
<p>- gestion humaine, administrative et financi&#232;re
</p>
<p>- gestion du patrimoine
</p>
<p>- d&#233;veloppement de projets et de nouveaux produits 
</p>
<p>EXPERIENCES PROFFESSIONNELLES ANTERIEURES :
</p>
<p>De 1995 &#224; 2004 : CCE SNCF  Directeur de villages de vacances d&#8217;une capacit&#233; de 150 &#224; 500 lits.
</p>
<p>De 1992 &#224; 1995 : Directeur d&#8217;un camping d&#8217;une capacit&#233; de 1200 campeurs
</p>
<p>De 1989 &#224; 1992 Agent r&#233;ceptif de tours op&#233;rateurs en Gr&#232;ce, Yougoslavie, Bal&#233;ares.
</p>
<p>De 1986 &#224; 1987 GO relation publique
</p>
<p>De 1982 &#224; 1986 Responsable d&#8217;animation en village de vacances l&#8217;&#233;t&#233;
</p>
<p>Moniteur de ski l&#8217;hiver
</p>
<p>FORMATION :
</p>
<p>1988 : Cadre de direction des &#233;quipements du tourisme (ma&#238;trise)
</p>
<p>DIVERS :
</p>
<p>Informatique : pratique des outils bureautiques, gestion de r&#233;seaux
</p>
<p>Anglais Espagnol : usage conversationnel
</p>
<p>De nombreux voyages sur les cinq continents.
</p>
<p>FIG. 2 &#8211; Exemple de CV.
</p>
<p>Nom : LADET
</p>
<p>prenom : Marc
</p>
<p>Monsieur,
</p>
<p>Votre annonce en r&#233;f&#233;rence a retenue toute mon attention, vous trouverez donc ci-joint mon curriculum vitae. Vous constaterez &#224; la lecture
de mon CV une bonne exp&#233;rience de structures touristiques dont j&#8217;assume les directions depuis 15 ans. Je me suis toujours impliqu&#233; dans les
installations que je dirigeais, aussi bien au niveau de la gestion des hommes, que financi&#232;re, et je suis particuli&#232;rement attach&#233; &#224; la pr&#233;servation
du patrimoine et au respect des conditions de vente.
</p>
<p>Disponible pour vous rencontrer &#224; la date qui vous conviendra, veuillez agr&#233;er, monsieur, mes salutations distingu&#233;es.
</p>
<p>FIG. 3 &#8211; Exemple de lettre de motivation.
</p>
<p>3 Classification de CV/Lettre de motivation par SVM
</p>
<p>Nous avons choisi les SVM(Vapnik, 1995) pour cette t&#226;che car cet algorithme d&#8217;apprentissage
a &#233;t&#233; utilis&#233; avec succ&#232;s dans plusieurs t&#226;ches de cat&#233;gorisation de texte auparavant (Joachims,
2008; Pham &amp; Do, 2003). Nous avons tent&#233; &#233;videmment une classification simpliste en se ba-
sant uniquement sur les noms des fichiers. Cependant ceci s&#8217;est av&#233;r&#233; insuffisant7 en raison de
</p>
<p>7Le syst&#232;me constituait un corpus tronqu&#233; &#224; 1725 CV et 910 LM</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>E-Gen: Profilage automatique de candidatures
</p>
<p>la diversit&#233; des noms de fichiers8. De m&#234;me, diff&#233;rents tests &#224; base de classifieurs na&#239;fs tels que
la longueur moyenne des phrases ou le nombre de mot dans le document ont montr&#233; leur limite
comme nous le verrons dans la section 5. Nous effectuons donc une premi&#232;re &#233;tape de filtrage9
et de racinisation (Heitz, 2008) 10, nous utilisons la repr&#233;sentation vectorielle de chaque docu-
ment afin de lui attribuer une &#233;tiquette (CV ou LM) &#224; l&#8217;aide des SVM. Les SVM permettent de
construire un classifieur &#224; valeurs r&#233;elles qui d&#233;coupe le probl&#232;me de classification en deux sous
probl&#232;mes : transformation non-lin&#233;aire des entr&#233;es et choix d&#8217;une s&#233;paration lin&#233;aire optimale.
Les donn&#233;es sont projet&#233;es dans un espace de grande dimension muni d&#8217;un produit scalaire o&#249;
elles sont lin&#233;airement s&#233;parables selon une transformation bas&#233;e sur un noyau lin&#233;aire, polyno-
mial ou gaussien. Puis dans cet espace transform&#233;, les classes sont s&#233;par&#233;es par des classifieurs
lin&#233;aires qui d&#233;terminent un hyperplan s&#233;parant correctement toutes les donn&#233;es et maximisant
la marge. Elles offrent, en particulier, une bonne approximation du principe de minimisation
du risque structurel (c&#8217;est-&#224;-dire, trouver une hypoth&#232;se h pour laquelle la probabilit&#233; que h
soit fausse sur un exemple non-vu et extrait al&#233;atoirement du corpus de test soit minimale).
Nous utilisons l&#8217;impl&#233;mentation LibSVM (Fan et al., 2005) qui a prouv&#233; sa robustesse dans de
pr&#233;c&#233;dent travaux (Kessler &amp; El-B&#232;ze, 2008).
</p>
<p>4 Classification du CV d&#8217;une candidature
</p>
<p>Nous avons d&#233;cid&#233; dans un premier temps d&#8217;effectuer une classification du CV uniquement, en
vue d&#8217;un profilage de la candidature (CV, offre d&#8217;emploi ainsi que LM) par la suite. Le CV est
un document textuel singulier : structure particuli&#232;re, informations &#233;parses, contenu fortement
symbolique, etc. d&#8217;o&#249; la difficult&#233; de traitement de ces documents (Zighed, 2003). Nous avons
pris en consid&#233;ration le genre donn&#233; par le Corpus de r&#233;f&#233;rence (CV ou LM) afin de ne garder
que les documents &#233;tiquet&#233;s comme CV. Apr&#232;s le pr&#233;-traitement, nous avons effectu&#233; un premier
apprentissage par les SVM. Les premiers r&#233;sultats mitig&#233;s (voir section 5.2) nous ont conduit &#224;
envisager une classification par n-gramme. Un n-gramme de mots est une s&#233;quence de n mots
cons&#233;cutifs. Pour un document donn&#233;, on peut g&#233;n&#233;rer l&#8217;ensemble des n-grammes (n = 1, 2,
3,...) en d&#233;pla&#231;ant une fen&#234;tre glissante de n cases sur le corpus. &#192; chaque n-gramme, on associe
une fr&#233;quence. Nos pr&#233;c&#233;dents travaux (Kessler &amp; El-B&#232;ze, 2008) ainsi que d&#8217;autres dans la
litt&#233;rature (Damashek, 1995; El-B&#232;ze et al., 2005) ont montr&#233; l&#8217;efficacit&#233; de cette approche
comme m&#233;thode de repr&#233;sentation des textes pour des t&#226;ches de classification. Nous avons
construit les uni-grammes et les bi-grammes &#224; chaque classe (OUI/NON) avec leur probabilit&#233;
P puis nous calculons pour obtenir le score t&#771; des n-grammes pour un document D :
</p>
<p>t&#771; = ArgMaxtP (t|W ) = ArgMaxt
P (W |t)P (t)
</p>
<p>P (W )
= ArgMaxtP (W |t)P (t) (1)
</p>
<p>Les deux derni&#232;res &#233;galit&#233;s proviennent de l&#8217;application du th&#233;or&#232;me de Bayes. En prenant
comme hypoth&#232;se, compte tenu de la sous-repr&#233;sentation de la classe OUI :
</p>
<p>P (t) = 1 &#8704; t (2)
8par exemple PierreDurand.doc, Durand.pdf, Aktor.doc, 13042007.doc, V3.doc etc.
9Pour r&#233;duire la complexit&#233; du texte, diff&#233;rents filtrages du lexique sont effectu&#233;s : la suppression des verbes et
</p>
<p>des mots fonctionnels, des expressions courantes, de chiffres (num&#233;riques et/ou textuelles) et des symboles.
10La racinisation simple trouve la racine des verbes fl&#233;chis et &#224; ram&#232;ne les mots pluriels et/ou f&#233;minins au
</p>
<p>masculin singulier.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Kessler, Torres-Moreno and El-B&#232;ze.
</p>
<p>on obtient :
</p>
<p>t&#771; &#8776; ArgMaxtP (W |t) = ArgMaxt
</p>
<p>|D|&#8719;
</p>
<p>i=1
</p>
<p>Pt(Wi|W
i&#8722;1
1
</p>
<p>) (3)
</p>
<p>avec comme seconde hypoth&#232;se, pour obtenir des estimations fiables, malgr&#233; la faible taille des
corpus disponibles :
</p>
<p>Pt(Wi|W
i&#8722;1
1 ) &#8776; &#955;Pt(Wi|Wi&#8722;1) + (1&#8722; &#955;)Pt(Wi) (4)
</p>
<p>Nous travaillons actuellement a l&#8217;int&#233;gration des tri-grammes dans notre mod&#232;le ainsi qu&#8217;un
lissage des &#233;v&#233;nement non vus (Beaufort et al., 2002) afin de compenser la faible taille de nos
corpus ainsi que le manque d&#8217;&#233;tiquetage grammatical de ceux-ci. Cependant, les r&#233;sultats tr&#232;s
proches de chacun des classifieurs (voir section 5.2) nous ont permis d&#8217;envisager une combinai-
son des deux classifieurs (Grilheres et al., 2004; Planti&#233; M., 2007) sur la base d&#8217;un vote simple
dans un premier temps afin d&#8217;am&#233;liorer les performances globales du syst&#232;me.
</p>
<p>5 R&#233;sultats et discussion
</p>
<p>Afin de r&#233;gler les param&#232;tres et tester nos m&#233;thodes, nous avons scind&#233; le Corpus de r&#233;f&#233;-
rence en cinq sous-ensembles approximativement de la m&#234;me taille, respectivement A1, A2,
A3, A4 et A5, avec une r&#233;partition al&#233;atoire mais &#233;quilibr&#233;e des candidatures dans chacun des
sous-corpus. Le protocole exp&#233;rimental a &#233;t&#233; le suivant : nous avons concat&#233;n&#233; quatre des cinq
sous-ensembles comme ensemble d&#8217;apprentissage et gard&#233; le cinqui&#232;me pour le test (ex A2 a
pour ensemble d&#8217;apprentissage les sous ensembles 1,3,4,5 et pour validation le sous ensemble
2). Cinq exp&#233;riences ont &#233;t&#233; ainsi effectu&#233;es &#224; tour de r&#244;le. Nous avons choisi d&#8217;effectuer ce
d&#233;coupage afin d&#8217;&#233;viter de r&#233;gler les algorithmes sur un seul ensemble d&#8217;apprentissage (et un
autre seul de test), ce qui pourrait conduire &#224; deux travers, le biais exp&#233;rimental et/ou le ph&#233;no-
m&#232;ne de sur-apprentissage (Torres-Moreno et al., 2007). Les algorithmes ont &#233;t&#233; &#233;valu&#233;s sur des
corpus de test en utilisant la mesure Fscore (5) des documents bien class&#233;s, moyenn&#233;e sur toutes
les classes (avec &#946; = 1 afin de ne privil&#233;gier ni la pr&#233;cision ni le rappel)(Goutte &amp; Gaussier,
2005).
</p>
<p>Fscore(&#946;) =
(&#946;2 + 1)&#215; &#12296;Pr&#233;cision&#12297; &#215; &#12296;Rappel&#12297;
</p>
<p>&#946;2 &#215; &#12296;Pr&#233;cision&#12297; + &#12296;Rappel&#12297; (5)
</p>
<p>5.1 Classification CV vs. Lettre de motivation
</p>
<p>Le tableau 4 pr&#233;sente les diff&#233;rentes statistiques qui ont permis de construire les classifieurs
na&#239;fs. Le premier classifieur choisit la classe en fonction de la longueur moyenne des phrases
dans le document tandis que le second d&#8217;apr&#232;s le nombre de mots rencontr&#233;s. On remarque que
malgr&#233; un nombre de documents identiques et une diff&#233;rence importante dans leur nombre, la
moyenne des phrases est a peu pr&#232;s identique entre les deux documents, ce qui explique les
r&#233;sultats du tableau 4 (l&#8217;ensemble des documents ont &#233;t&#233; class&#233;s LM pour le classifieur na&#239;f
sur la longueur de phrase), ainsi que le peu de &quot;.&quot; pr&#233;sent dans un CV, contrairement au LM.
Malgr&#233; une diff&#233;rence significative entre les moyennes de mots contenus dans chaque document
(425 pour les CV et 190 pour les LM), le second classifieur se heurte &#224; l&#8217;h&#233;t&#233;rog&#233;n&#233;it&#233; des
documents dans leur style et leur longueur. Le tableau 5 pr&#233;sente une moyenne de la pr&#233;cision
rappel ainsi que le Fscore obtenu pour la t&#226;che de classification de CV/Lettre de motivation</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>E-Gen: Profilage automatique de candidatures
</p>
<p>CV LM
Nombre de documents 2165 2165
Nombre de phrase total 45655 20658
Longueur moyenne des phrases 17.07 18.97
Nombre de Mots total 922103 412008
Moyenne de mots par documents 425.91 190.30
</p>
<p>TAB. 3 &#8211; Statitistiques &#224; la base des classifieurs na&#239;fs.
</p>
<p>Classifieur Pr&#233;cision Rappel Fscore
Longueur moyenne des phrases 1 0.50 0.66
Nombre de mots 0.35 0.26 0.30
</p>
<p>TAB. 4 &#8211; Pr&#233;cision, Rappel, Fscore obtenus par les deux classifieurs na&#239;fs.
</p>
<p>sur chacun des sous-corpus par les SVM. Le tableau 6 montre la matrice de confusion. Une
analyse des CV/Lettre de motivation mal &#233;tiquet&#233;s montre que les CV mal class&#233;s sont de deux
types : l&#8217;exemple 7 montre le cas d&#8217;un mauvais &#233;tiquetage dans le Corpus de r&#233;f&#233;rence, puisque
le document contient plus vraisemblablement une lettre de motivation et un lien vers le CV.
L&#8217;exemple 8, &#233;tiquet&#233; LM, est un message g&#233;n&#233;r&#233; automatiquement par des sites d&#8217;emploi,
ceux-ci contenant des versions tr&#232;s courtes du CV avec un lien vers une version compl&#232;te.
</p>
<p>5.2 Classification selon le CV d&#8217;une candidature
</p>
<p>Afin d&#8217;&#233;valuer nos m&#233;thodes de classification d&#8217;une candidature, et plus particuli&#232;rement les
CV, nous avons effectu&#233; une scission du Corpus de r&#233;f&#233;rence en plusieurs sous-corpus : un
sous-corpus contenant les CV class&#233;s en fonction d&#8217;une &#233;valuation OUI/NON (d&#233;sign&#233; comme
Corpus OUI/NON) ainsi que deux sous-corpus th&#233;matiques, afin de tester l&#8217;influence du m&#233;tier
sur les caract&#233;ristiques de la candidature (c&#8217;est &#224; dire, les CV sont-ils ind&#233;pendants du m&#233;tier ?).
Ceux ci contiennent l&#8217;ensemble des CV r&#233;pondant &#224; des missions de type &quot;commercial&quot; (nomm&#233;
corpus commercial, avec 715 CV) et &quot;comptable&quot; (corpus comptable, avec 1546 CV). Le ta-
bleau 9 pr&#233;sente les r&#233;sultats obtenus par les diff&#233;rents noyaux sur le Corpus OUI/NON ainsi
qu&#8217;un test sans racinisation. Le CV &#233;tant g&#233;n&#233;ralement compos&#233; de mots simples et avec peu
d&#8217;ambigu&#239;t&#233;. Le tableau 10 pr&#233;sente les r&#233;sultats obtenus par les SVM et le calcul de probabilit&#233;
des n-grammes. Le tableau 11 montre la r&#233;partition des erreurs pour chacun des classifieurs.
L&#8217;observation de ces r&#233;sultats nous a pouss&#233; &#224; envisager un combinaison de classifieurs, les
SVM ayant de meilleurs performances sur la classe NON (375 documents bien class&#233;s contre
115 pour la m&#233;thode probabiliste) alors que les n-grammes classent mieux la classe OUI (107
documents bien class&#233;s contre 38 pour les SVM). Le tableau 12 pr&#233;sente le r&#233;sultat d&#8217;un mixage
simple entre les SVM et les n-grammes sur la base d&#8217;un vote. On observe une tr&#232;s l&#233;g&#232;re am&#233;-
lioration des performances globales (Fscore de 0,66 pour le mixage contre 0,62 pour les SVM
et 0,61 pour la m&#233;thode probabiliste).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Kessler, Torres-Moreno and El-B&#232;ze.
</p>
<p>A1 A2 A3 A4 A5 Total
Pr&#233;cision 0,98 0,98 0,97 0,98 0,99 0,98
Rappel 0,95 0,95 0,97 0,95 0,97 0,96
Fscore 0,97 0,97 0,97 0,97 0,98 0,98
</p>
<p>TAB. 5 &#8211; Pr&#233;cision, Rappel, Fscore obtenu par les SVM pour la classification de CV/LM.
</p>
<p>Documents type CV Documents type LM
Documents class&#233;s CV 421 12
Documents class&#233;s LM 6 428
</p>
<p>TAB. 6 &#8211; Matrice de confusion SVM.
</p>
<p>6 Conclusion et perspectives
</p>
<p>Le traitement des offres d&#8217;emploi est une t&#226;che difficile car l&#8217;information est en format libre
malgr&#233; une structure conventionnelle. Ces travaux ont mis en avant le module de traitement des
r&#233;ponses &#224; des offres d&#8217;emplois, second module du projet E-Gen, syst&#232;me pour le traitement
automatique des offres d&#8217;emploi sur Internet. Apr&#232;s diff&#233;rentes &#233;tapes de filtrage et de racini-
sation et de production d&#8217;une repr&#233;sentation vectorielle, nous effectuons une classification sur
les diff&#233;rentes pi&#232;ces de la candidature (CV/ Lettre de motivation). Les r&#233;sultats obtenus sur
la t&#226;che de classification de CV/Lettre de motivation par les SVM sont de tr&#232;s bonne qualit&#233;
(Fscore moyen de 0,98) nous ont permis de commencer les travaux sur la cat&#233;gorisation du CV
d&#8217;une candidature. Les r&#233;sultats mitig&#233;s obtenus par les diff&#233;rents classifieurs pour cette t&#226;che
nous a fait envisager la mise en place d&#8217;une solution mixe utilisant un simple vote. Nous avons
observ&#233; une tr&#232;s l&#233;g&#232;re am&#233;lioration des performances du syst&#232;me mais nous envisageons d&#8217;af-
finer prochainement celui-ci ainsi que de tester d&#8217;autres outils tels que boostexter (Schapire &amp;
Singer, 2000). Nous pr&#233;voyons par ailleurs d&#8217;augmenter la taille de notre mod&#232;le n-grammes
ainsi qu&#8217;un lissage pour g&#233;rer le probl&#232;me des &#233;v&#233;nement non vus. De plus, la classification
de CV ne repr&#233;sente qu&#8217;une partie de l&#8217;&#233;valuation globale de la candidature puisque nous sou-
haitons la coupler avec les informations de la lettre de motivation et du profil du poste. Nous
envisageons cependant la mise en place d&#8217;un syst&#232;me d&#8217;&#233;valuation de CV sur le portail emploi
jobmanager11 Les prochaines &#233;tapes consisteront donc &#224; &#233;valuer les lettres de motivations et
la candidature de fa&#231;on globale en tenant compte de divers param&#232;tres tels que la richesse du
vocabulaire, l&#8217;orthographe ainsi que sa correspondance avec l&#8217;offre d&#8217;emploi (premier module
du syst&#232;me).
</p>
<p>11http ://www.jobmanager.fr
</p>
<p>Mr ARVAUX Pierre
</p>
<p>45 rue DE CHANTECLAIR 69440 VANNES. T&#233;l 06.06.06.06.06
</p>
<p>A la recherche d&#8217;un autre emploi, je me permets de vous adresser ma candidature pour le poste de Directeur d&#8217;h&#244;tel car je pense correspondre
au profil souhait&#233;.En effet j&#8217;ai acquis une solide exp&#233;rience en ma qualit&#233; de Responsable de Centre de Profit ainsi que Directeur de Caf&#233;t&#233;ria.
reconnu,homme de terrain, j&#8217;ai un sens du commerce tr&#233;s prononc&#233;, j&#8217;ai manag&#233; jusqu&#8217;&#224; 5O collarateurs.Je vous laisse le soin d&#8217;&#233;tudier ma
candidature et me tiens &#224; votre disposition pour de plus amples renseignements.
</p>
<p>Le CV du candidat est consultable &#224; l&#8217;adresse suivante :http : ///CV ?code = 3D &#8722; 178903129619543181
</p>
<p>TAB. 7 &#8211; 1er exemple de CV mal class&#233;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>E-Gen: Profilage automatique de candidatures
</p>
<p>M. Zidounet Albert 4 rue de la Corniere 42490 Fraisage
</p>
<p>akzeddoun@yahoo.fr Portable : 0606060606
</p>
<p>Salaire souhait&#233; : 21,000.00 EUR par an
</p>
<p>Type d&#8217;emploi :Temps Plein Mobile g&#233;ographiquement : non
</p>
<p>Niveau d&#8217;&#233;tudes : Ma&#238;trise, IEP, IUP, Bac + 4
</p>
<p>Derni&#232;re exp&#233;rience professionelle : 2002 &#224; 2004 : Cabinet d&#8217;Expertise Comptable &quot;Cofis&quot; - Assistant en comptabilit&#233;
</p>
<p>Le CV du candidat est consultable &#224; l&#8217;adresse suivante :http : ///CV ?code = 130493543
</p>
<p>TAB. 8 &#8211; 2&#232;me exemple de CV mal class&#233;
</p>
<p>Noyau SVM Pr&#233;cision Rappel Fscore
Lin&#233;aire 0.60 0.61 0.61
</p>
<p>Polynomial 0.57 0.57 0.57
Radial 0.57 0.55 0.56
</p>
<p>Sigmoidal 0.54 0.54 0.55
lin&#233;aire sans racinisation 0.57 0.58 0.58
</p>
<p>TAB. 9 &#8211; Pr&#233;cision, Rappel, Fscore obtenus par les SVM en fonction du noyau.
</p>
<p>Pr&#233;cision Rappel Fscore
Classifieur SVM n-grammes SVM n-grammes SVM n-grammes
Corpus OUI/NON 0,62 0,62 0,62 0,59 0,61 0,61
corpus commercial 0,66 0,62 0,64 0,57 0,58 0,58
corpus comptable 0,57 0,61 0,59 0,63 0,64 0,64
</p>
<p>TAB. 10 &#8211; Pr&#233;cision, Rappel, Fscore obtenu sur chaque corpus.
</p>
<p>Documents de type OUI Documents de type NON
SVM n-grammes SVM n-grammes
</p>
<p>Documents class&#233;s OUI 38 50 107 309
Documents class&#233;s NON 85 375 19 115
</p>
<p>TAB. 11 &#8211; Matrice de confusion.
</p>
<p>Classification par Mixage (OUI) (NON) (Toutes classes)
Pr&#233;cision 0,53 0,83 0,68
Rappel 0,38 0,90 0,64
Fscore 0,44 0,90 0,66
</p>
<p>TAB. 12 &#8211; Pr&#233;cision, Rappel, Fscore obtenu par mixage des SVM et n-grammes.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Kessler, Torres-Moreno and El-B&#232;ze.
</p>
<p>R&#233;f&#233;rences
BEAUFORT R., DUTOIT T., PAGEL V. &amp; MONS M. (2002). Analyse syntaxique du fran&#231;ais.
Pond&#233;ration par trigrammes liss&#233;s et classes d&#8217;ambigu&#239;t&#233; lexicales. TALN 2002.
BIZER R. H. &amp; RAINER E. (2005). Impact of Semantic web on the job recruitment Process.
International Conference Wirtschaftsinformatik.
BOURSE M., LECL&#200;RE M., MORIN E. &amp; TRICHET F. (2004). Human resource management
and semantic web technologies. ICTTA.
DAMASHEK M. (1995). A gauging similarity with n-grams : Language independent categori-
zation of text. Science 267, p. 843&#8211;848.
EL-B&#200;ZE M., TORRES-MORENO J. &amp; B&#201;CHET F. (2005). Un duel probabiliste pour d&#233;par-
tager deux Pr&#233;sidents. RNTI.
FAN R.-E., CHEN P.-H. &amp; LIN C.-J. (2005). Towards a Hybrid Abstract Generation System,
Working set selection using the second order information for training SVM. NIPS 2005, p.
1889&#8211;1918.
GOUTTE C. &amp; GAUSSIER E. (2005). A Probabilistic Interpretation of Precision, Recall and
F-Score, with Implication for Evaluation. ECIR 2005, p. 345&#8211;359.
GRILHERES B., BRUNESSAUX S. &amp; LERAY P. (2004). Combining classifiers for harmful
document filtering. RIAO, p. 173&#8211;185.
HEITZ T. (2008). Mod&#233;lisation du pr&#233;traitement des textes . JADT2006.
JOACHIMS T. (2008). Text categorization with Support Vector Machines : Learning with
many relevant features . European Conference on Machine Learning, p. 137&#8211;142.
KESSLER R. &amp; EL-B&#200;ZE M. (2008). E-Gen : traitement automatique des offres d&#8217;emploi.
JADT2008, p. 591&#8211;601.
KESSLER R., TORRES-MORENO J. M. &amp; EL-B&#200;ZE M. (2007). E-Gen : Automatic Job Offer
Processing system for Human Ressources. MICAI.
MORIN, EMMANUEL ET LECL&#200;RE M. E. T. F. (2004). The semantic web in e-recruitment
(2004). The First European Symposium of Semantic Web ESWS.
PHAM N.-K. &amp; DO T.-N. (2003). Fouille de textes &#224; l&#8217;aide de ProximalSVM. 9th national
conference in computer science Vietnam.
PLANTI&#201; M., DRAY G. R. M. (2007). Comparaison d&#8217;approches pour la classification de
textes d&#8217;opinion. 3&#232;me d&#233;fi fouille de textes DEFT 2007, p. 55&#8211;68.
RAFTER R., BRADLEY K. &amp; SMYT B. (2000). Automated Collaborative Filtering Applica-
tions for Online Recruitment Services. RIAO, p. 363&#8211;368.
RAFTER R., SMYTH B. &amp; BRADLEY K. Inferring Relevance Feedback from Server Logs :
A Case Study in Online Recruitment.
ROCHE M. &amp; PRINCE V. (2008). Evaluation et d&#233;termination de la pertinence pour des
syntagmes candidats &#224; la collocation . JADT2008, p. 1009&#8211;1020.
SCHAPIRE R. E. &amp; SINGER Y. (2000). BoosTexter : A boosting-based system for text cate-
gorization. Machine Learning, 39(2/3), 135&#8211;168.
TORRES-MORENO J., EL-B&#200;ZE M., B&#201;CHET F. &amp; N C. (2007). Comment faire pour que
l&#8217;opinion forg&#233; &#224; la sortie des urnes soient la bonne ? Actes DEFT2007.
VAPNIK V. (1995). The Nature of Statistical Learning Theory. Springer-Verlag.
ZIGHED, D. A. E. C. J. (2003). Data Mining et analyse des CV : une exp&#233;rience et des
perspectives. Journ&#233;es sur l&#8217;Extraction et la Gestion des Connaissances, Lyon EGC 2003.</p>

</div></div>
</body></html>