TALN 2008, Avignon, 9-I3juin 2008

Vers l’évaluation de systémes de dialogue homme-machine :
de l’oral au multimodal

Frédéric Landragin

CNRS — Laboratoire LaTTICe (UMR 8094)
1 rue Maurice Amoux — 92120 Montrouge
frederic.landragin@linguist.jussieu.fr

Résumé L’évaluation pour le dialogue homme-machine ne se caractérise pas par
l’efficacité, l’objectivité et le consensus que l’on observe dans d’autres domaines du
traitement automatique des langues. Les systemes de dialogue oraux et multimodaux restent
cantonnés a des domaines applicatifs restreints, ce qui rend difﬁciles les évaluations
comparatives ou normées. De plus, les avancées technologiques constantes rendent vite
obsoletes les paradigmes d’évaluation et ont pour conséquence une multiplication de ceux-ci.
Des solutions restent ainsi a trouver pour améliorer les méthodes existantes et permettre des
diagnostics plus automatisés des systemes. Cet article se veut un ensemble de réﬂexions
autour de l’évaluation de la multimodalité dans les systemes a forte composante linguistique.
Des extensions des paradigmes existants sont proposées, en particulier DQR/DCR, sachant
que certains sont Inieux adaptés que d’autres au dialogue multimodal. Des conclusions et
perspectives sont tirées sur l’avenir de l’évaluation pour le dialogue homme-machine.

Abstract Evaluating human-machine dialogue systems is not so efficient, objective, and
consensual than evaluating other natural language processing systems. Oral and multimodal
dialogue systems are still working within reduced applicative domains. Comparative and
normative evaluations are then difﬁcult. Moreover, the continuous technological progress
makes obsolete and numerous the evaluating paradigms. Some solutions are still to be
identified to improve existing methods and to allow a more automatic diagnosis of systems.
The aim of this paper is to provide a set of remarks dealing with the evaluation of multimodal
spoken language dialogue systems. Some extensions of existing paradigms are presented, in
particular DQR/DCR, considering that some paradigms fit better multimodal issues than
others. Some conclusions and perspectives are then drawn on the future of the evaluation of
human-machine dialogue systems.

Mots-clés 2 Dialogue ﬁnalisé, multimodalité, évaluation pour le dialogue homme-
machine, paradigme d’évaluation, test utilisateur, diagnostic, paraphrase multimodale

Keywords: Task-driven dialogue, multimodality, evaluating human-machine dialogue,
evaluation paradigm, user test, diagnosis

F rédéric Landragin

1 Introduction

La communauté intemationale voit paraitre un nombre grandissant d’articles sur l’évaluation
des systemes de dialogue oraux et multimodaux. Outre les livres de référence en dialogue
homme-machine qui incluent désormais systématiquement un chapitre sur l’évaluation
(Gibbon et al., 2000; puis Lopez-Cozar, Araki, 2005), on trouve un grand nombre de
propositions ciblées sur le dialogue oral ou sur une modalité particuliere d’un systeme
multimodal. Des paradigmes d’évaluation sont proposés, de plus en plus larges et complexes,
regroupant entre autres des ensembles de métriques, des tests utilisateurs et des méthodes
d’analyse de questionnaires remplis par des sujets apres leur utilisation du systeme a évaluer.
Dans la communauté francaise, les propositions se cantonnent pour le moment a l’oral ou a
certains aspects du dialogue multimodal comme le comportement d’agents animés, et il n’y a
pas encore de chapitre sur l’évaluation de la multimodalité dans des ouvrages tels que
(Chaudiron, 2004) ou (Caelen, Xuereb, 2007). Ces efforts sont pertinents et louables, mais ne
doivent pas faire oublier plusieurs constats récurrents qui restent particulierement valables.

Premier constat : contrairement aux systemes de recherche d’information, de reconnaissance
de la parole ou d’analyse syntaxique, les systemes de dialogue homme-machine restent
toujours au niveau de prototypes de recherche difficiles a réaliser et a faire fonctionner, ainsi
que tres sensibles au comportement des utilisateurs. A part quelques exemples marginaux,
ludiques par exemple, il n’existe a l’heure actuelle aucun systeme fiable commercialisé et
utilisé de maniere proﬁtable par une population de taille importante. Autrement dit, le passage
a l’échelle reste un probleme majeur en dialogue homme-machine et les évaluations réalisées
s’en tiennent a des prototypes de recherche ou a des systemes professionnels tellement
ﬁnalisés (militaires par exemple) qu’ils ne s’adressent qu’a un nombre extrémement réduit
d’utilisateurs. Ce qui est valable pour les systemes oraux l’est encore plus pour les systemes
multimodaux. L’évaluation pour le dialogue homme-machine se cantonne donc a un périmetre
limité qui, sans remettre en cause son utilité, nuance quelque peu sa portée.

Deuxieme constat: il risque d’exister bientot autant de méthodologies d’évaluation que de
systemes proprement dits. Ce n’est pas un probleme en soi, mais cela souleve des
interrogations. En particulier, on peut s’interroger sur le bien-fondé d’une méthode
d’évaluation proposée par les concepteurs d’un systeme dans le but d’évaluer ce seul systeme,
la méthode étant elle-méme évaluée par son application au systeme en question. Cette
description peut sembler caricaturale, elle reﬂete pourtant une certaine réalité, ou en tout cas
elle s’en approche. Cette situation est tout a fait normale et inévitable, compte tenu du nombre
réduit de systemes et, face aux avancées de chaque systeme, de la nécessité de prendre en
compte des aspects qui ne sont pas traités par les méthodologies d’évaluation existantes.
Ainsi, on en vient a proposer ou a étendre une méthodologie d’évaluation en vue de pouvoir
évaluer les avancées d’un nouveau systeme. Les avancées technologiques rapides ne font
qu’augmenter ce phénomene. L’évaluation pour le dialogue homme-machine semble ainsi
perpétuellement en retard par rapport a son objectif.

Troisieme constat: l’évaluation sert non seulement a améliorer le développement d’un
systeme particulier (en passant par des mesures, des diagnostics et des questionnaires de
satisfaction), mais aussi a comparer des systemes les uns par rapport aux autres. Plusieurs
campagnes ont été lancées, et ce qu’il en ressort ﬁnalement, c’est qu’il est tres difficile de
comparer plusieurs systemes de dialogue, méme s’ils ont été réalisés pour des contextes
applicatifs comparables, par exemple le renseignement ferroviaire ou hotelier pour ne citer
que ces deux applications largement exploitées. Pour cet aspect, le domaine du dialogue

Vers Z ’e’valuati0n des systémes de dialogue multimodaux

homme-machine semble poser un probleme plus délicat que les autres domaines du TAL, et
contribue a l’image de fragilité attachée a son évaluation.

Face a ces constats, on peut s’interroger sur la faisabilité de l’évaluation pour le dialogue
homme-machine. Dans ce but, la section 2 passera en revue les principaux problemes et
quelques méthodologies qui nous semblent prometteuses. La question de la faisabilité nous
semble constituer un probleme de fond qui n’est pas assez discuté et pour lequel nous
essaierons d’apporter quelques pistes de réﬂexion. Les critiques que nous venons de porter
avec les constats précédents ne nous empécheront pas, dans un second temps, de proposer des
pistes pour une meilleure prise en compte de la multimodalité dans des paradigmes existants.
La section 3 s’attachera ainsi a faire un point sur les possibilités d’extension a la
multimodalité des méthodologies prévues pour l’oral, en particulier les méthodes DQR et
DCR, et sur la prise en compte de phénomenes pour l’instant ignorés dans les méthodologies
déja prévues pour la multimodalité. A défaut d’évaluer nos propositions sur des systemes
existants ou sur de nouveaux systemes (c’est l’une des perspectives de ce travail), nous les
expliciterons sur des exemples typiques tels que le classique « mets ca ici » (Bolt, 1980).

2 Méthodologies existantes

Dans le contexte du dialogue homme-machine oral, beaucoup de méthodologies ont été
proposées (Antoine, Caelen, 1999 ; Bonneau-Maynard et al., 2006 ; Devillers et al., 2004 ;
Dybkjaer et al., 1998 ; Eckert et al., 1998 ; Litman, Pan, 1999 ; Moller et al., 2007). Elles
constituent une sorte de cadre de référence comprenant des recommandations pour mettre en
oeuvre des tests d’interaction avec des utilisateurs, des méthodes pour analyser
automatiquement ou seIr1i-automatiquementles traces d’interaction obtenues, des reperes pour
déterminer des métriques d’évaluation, ou encore des principes pour constituer et analyser des
questionnaires remplis a posteriori par les utilisateurs. Chaque évaluateur peut ainsi piocher
dans ce stock pour déterminer la ou les méthodes qu’il va appliquer. En fait, un seul test
semble insuffisant et une véritable évaluation semble devoir grouper plusieurs types de test.
Les campagnes d’évaluation (EVALDA/MEDIA), les groupes de travail (groupe MADCOW,
groupe « compréhension de parole » du GdR 13) et les divers consortiums de projets
européens exploitent largement ce principe. Lorsque plusieurs systemes sont en jeu et que
l’évaluation est comparative, des regles de fonctionnement peuvent étre définies de maniere a
mieux controler la qualité de l’évaluation. La campagne d’évaluation par déﬁ avec sa gestion
croisée des roles des concepteurs des systemes en jeu (Antoine, 2003) en est un exemple.

Les principales propositions de méthodologie s’accompagnent chacune d’une idée originale
qui vient simplifier la mise en oeuvre d’un type de test en lui apportant un moyen d’étre
opérationnalisé dans un contexte déterminé. Le paradigme du groupe MADCOW (Hirschman,
1992) apporte ainsi la notion de gabarit qui caractérise les solutions Ininimales et maximales a
une requéte et rend ainsi son évaluation plus rigoureuse. Le paradigme PARADISE —
PARAdigm for DIalogue System Evaluation (Walker et al., 2001) se focalise sur la
maximisation de la satisfaction de l’utilisateur et propose de prendre la satisfaction de la tache
comme référence. Autre exemple d’idée originale, (Lopez-Cozar et al., 2003) propose
d’évaluer un systeme en générant automatiquement des énoncés utilisateurs de test, c’est-a-
dire en modélisant le comportement de l’utilisateur, y compris ses erreurs. En France, la
méthodologie DQR — Donnée—Question—Réponse (Zeiliger et al., 1997) introduit le principe
de questionner le systeme sur le point a évaluer, avec l’avantage de déplacer ainsi l’objet de
l’évaluation de la donnée vers la question, et donc ni sur les réponses ou réactions du systeme
(méthode « boite noire », qui ne nécessite pas d’explorer les structures internes au systeme,
mais qui manque de précision), ni sur les structures sémantiques du systeme (méthode « boite

F rédéric Landragin

transparente », précise et conduisant facilement a un diagnostic, mais qui nécessite de disposer
de représentations sémantiques de référence). Encore faut-il que le systeme soit capable de
répondre aux questions Q de DQR. Le paradigme adapté DCR — Demande—Contr6le—
Réponse/Résultat/Référence (Antoine, Caelen, 1999) minimise ce probleme en remplacant la
question par un controle qui est une simpliﬁcation ou une reformulation de la demande
utilisateur initiale. Pour sa part, le paradigme PEACE — Paradigme d’Evaluation Automatique
de ComprEhension (Devillers et al., 2002) apporte l’idée originale de modéliser l’historique
du dialogue par une paraphrase, ce qui permet de rester dans le mode « boite noire » tout en
permettant une évaluation de la compréhension en contexte.

Dans le contexte du dialogue homme-machine multimodal, les propositions sont loin d’étre
aussi pertinentes. Le paradigme PROMISE — PROcedure for Multimodal Interactive System
Evaluation (Beringer et al., 2002) est présenté comme une extension de PARADISE a la
multimodalité, avec des principes pour affecter des scores aux entrées et sorties multimodales.
La proposition reste en fait a un niveau tres approximatif, bien en deca de la variété des
phénomenes multimodaux. Les aspects intéressants de l’article concernent le dialogue oral,
avec des considérations sur le niveau de complétude de la tache et le niveau de coopération de
l’utilisateur. Les travaux de Bernsen et Dybkj zer, qui font pourtant référence dans le milieu du
dialogue multimodal, sont plutot décevants en ce qui conceme l’évaluation. (Bernsen,
Dybkjzer, 2004) présente ainsi une méthodologie prévue pour un systeme, avec une
focalisation sur la méthode du questionnaire rempli a posteriori par les utilisateurs (la raison
donnée est d’ailleurs que les autres méthodes ne sont pas encore bien établies).
Malheureusement, les questions du questionnaire restent a un niveau tres superﬁciel pour ce
qui concerne la multimodalité : « avez-vous utilisé la souris ou avez-vous pointé sur
l’écran ? », « quelles étaient vos impressions en produisant un geste ? », et « auriez-vous aimé
en faire plus avec le geste ? si oui, pour faire quoi ? ». Les réponses qui ont été fournies par
les utilisateurs semblent également tres pauvres, d’autant plus qu’une des conclusions des
auteurs est que les utilisateurs ont préféré parler plutot qu’exploiter les possibilités
multimodales. .. Pour sa part, (Dybkj zer et al., 2004) est plus une revue de méthodologies et de
projets qu’une proposition de nouvelle méthodologie pour la multimodalité : le propos reste
au niveau de recommandations tres générales. Par ailleurs, une des remarques finales de
l’article rejoint notre point de vue : « The field is moving rapidly beyond the standard task-
oriented, speech-only SLDS [Spoken Language Dialogue System] towards multimodal
SLDSs, mobile systems, situation-aware systems, location-aware systems, internet access
systems, educational systems, entertainment systems, etc. In fact, technology development
may appear to speed further ahead of the knowledge we already have on evaluation, usability
and standards, increasing the proportion of what we do not know compared with what we do
know. ». Dans un autre registre, (Vuurpijl et al., 2004) présente un outil, appelé « ueval »,
pour la transcription des données multimodales et l’évaluation d’un systeme. Or l’évaluation
ne conceme que les tours de dialogue et ne traite pas les phénomenes multimodaux. Enﬁn,
(Walker et al., 2004), malgré son titre, se focalise sur les modeles utilisateur et les stratégies
de dialogue (oral) mais quasiment pas sur les aspects multimodaux. D’une maniere générale
pour l’évaluation des systemes multimodaux, on ne retrouve donc pas les principes appliqués
dans les campagnes d’évaluation des systemes oraux. C’est ce que nous allons contribuer a
faire en nous focalisant sur les méthodologies qui nous semblent les plus prometteuses.

3 Extension au dialogue multimodal
(Zeiliger et al., 2000) ont retenu une méthodologie de type « boite noire » permettant de faire

un diagnostic du systeme, méthodologie qui repose sur des tests génériques pour l’évaluation
de la compréhension d’un énoncé isolé. Les aspects contextuels ont été négligés (nous y

Vers Z ’e’valuati0n des systémes de dialogue multimodaux

reviendrons avec PEACE), mais c’etait le priX a payer pour obtenir une methodologie simple
et bien delimitee. Le principe est de proceder a des evaluations ponctuelles, chacune d’entre
elles etant centree sur un phenomene particulier. Ainsi, dans la materialisation DQR,
l’evaluation ponctuelle prend la forme d’une question Q adressee au systeme et permet de
veriﬁer sa bonne comprehension de la demande initiale D. Un des eXemples donnes concerne
la resolution des anaphores, avec la demande, la question et la reponse suivantes :

0 D = « Vous prenez la rue a droite et vous la suivez sur 300 metres » (enonce initial,
tel qu’il a ete adresse au systeme dans le but de faire avancer la tache) ;

0 Q = « Suivre rue a droite ? » (question adressee au systeme juste apres l’enonce D et
destinee a evaluer la bonne comprehension de D) ;

0 R = « oui » (reponse du systeme montrant que l’anaphore a ete bien comprise et
rendant l’evaluation positive).

Les auteurs speciﬁent sept niveauX caracterisant la portee des questions posees. Nous allons
reprendre ces niveauX en indiquant a chaque fois comment etendre le paradigme pour pouvoir
l’eXploiter en dialogue multimodal.

3.1 DQR multimodal

Niveau 1 = « information eXplicite ». I1 s’agit du reperage d’une information eXplicitee dans
l’enonce, l’interét etant de tester la bonne comprehension de l’enonce litteral compte tenu de
la grande variabilite du langage spontane. Les eXemples donnes par les auteurs se contentent
de reprendre une partie de l’enonce et de demander une conﬁrmation de la comprehension de
cette partie : D = « vous prenez a droite apres les batiments blancs aux volets bleus » puis
Q = « volets blancs ? » ou « volets bleus ? ». L’eXtension de ce principe a la multimodalite
consiste a poser des questions sur les elements de l’enonce multimodal. Avec D = « mets ca
ici » + geste en (X1, y1) + geste en (X2, y2), on peut tester les capacites de capture de la
multimodalite en posant les questions Q suivantes: « ca ? » + geste en (X1, y1); « mettre
ici ? » + geste en (X2, y2) ; « mettre ca ? » + geste en (X2, y2) ; « mettre ca ici » + geste en (X2,
y2) + geste en (X1, y1) ; etc. La procedure peut sembler nai've, mais elle permet de tester de
maniere tres simple le bon appariement des gestes avec les eXpressions referentielles, ce qui
constitue un processus non negligeable de la fusion multimodale. Une attention particuliere
sera donnee a la synchronisation temporelle entre les mots prononces et les gestes produits.
Ainsi, un decalage temporel entre « ca » et le geste dans la question Q po11rra conduire selon
le systeme a une reponse positive reﬂetant sa robustesse pour l’appariement multimodal
meme quand les conditions de production sont deviantes, ou au contraire a une reponse
negative reﬂetant l’incapacite du systeme a sortir d’un certain intervalle temporel.

Niveau 2 = «information implicite ». Ce niveau concerne la resolution des anaphores, des
ellipses, des incompletudes et autres informations implicites mais recuperables auX niveauX
syntaXique et semantique. Un eXemple fait intervenir : D = « donnez-moi un billet pour Paris
et aussi pour Lyon » et Q = « billet pour Lyon ? ». La resolution de la reference etant l’un des
principauX aspects de la multimodalite spontanee, un DQR multimodal devra bien entendu en
rendre compte. Ainsi, en reprenant comme D la primitive universelle de la multimodalite,
« mets ca ici » avec deuX gestes de designation, les questions Q pourront introduire des
precisions sur les referents, en partant par eXemple de la mention de leur categorie et en allant
jusqu’a donner leur identifiant unique tel qu’il est gere par le systeme : « mettre cet objet ? » +
geste en (X1, y1) ; « mettre ce ﬁchier ? » + geste en (X1, y1) ; « mettre ‘subInis.teX’ ? » (sans

F rédéric Landragin

geste) ; « mettre obj4353 ? » (sans geste) ; etc. La procedure d’evaluation inclut donc la
paraphrase en langage naturel d’une reference multimodale. Ce qui reste simple pour le geste
deictique l’est beaucoup moins pour les autres types de gestes co-verbaux. Imaginons par
exemple ue « mets ca ici », ou plutot « deplace ca ici » pour ne pas trop compliquer
l’eXemple , s’accompagne d’un seul geste qui part de l’objet a deplacer et aboutit au lieu de
destination. Selon une premiere hypothese, cette trajectoire gestuelle est consideree comme la
materialisation de la necessaire transition entre la designation d’objet et la designation de lieu.
Dans ce cas, seules les extremites de la courbe sont utilisees lors des analyses semantiques : le
point (X1, y1) puis l’objet present en ce point ou dans un voisinage immediat sont unifies avec
« ca », et le point (X2, yz) est uniﬁe avec « ici ». Autrement dit on revient au cas precedent.
Selon une seconde hypothese, la trajectoire est consideree comme la combinaison de ces deux
designations avec un geste co-verbal illustratif apportant une caracteristique de l’action de
deplacement, a savoir le chemin (ou points de passage) a suivre. La trajectoire est alors
analysee d’un point de vue temporel (courbe produite de maniere reguliere, sans point d’arrét
signiﬁcatif) et d’un point de vue structurel (arc de cercle), avant d’etre uniﬁee a « deplace »,
c’est-a-dire d’etre interpretee comme un chemin de deplacement. Si l’on veut tester cette
fonctionnalite du systeme multimodal, il suffit de poser une question Q supplementaire :
« suivre cette trajectoire ? » ou « deplacer selon ces points de passage ? », en reprenant dans
un cas comme dans l’autre le geste complet. Le seul inconvenient reste celui qui est valable
pour l’ensemble de la methodologie DQR, a savoir la necessite pour le systeme de traiter de
telles questions.

Niveau 3 = «inference ». I1 s’agit ici de la construction du sens complet de l’enonce, la
difﬁculte etant l’identiﬁcation des sous-entendus, identiﬁcation qui fait appel a des
raisonnements de sens commun et a des inferences pragmatiques. Avec D : « je voudrais un
aller-retour pour Paris », les auteurs proposent Q : « vouloir billet ? ». Cet aspect est
independant des modalites, et reste valable dans l’etat pour le dialogue multimodal. Meme si
des inferences peuvent étre identifiees lors de l’utilisation consecutive de plusieurs gestes, il
est vrai que ce niveau conceme surtout la langue orale.

Niveau 4 = «interpretation du type d’acte illocutoire ». On entre ici dans les niveaux de
dialogue, avec un premier aspect concernant les actes de langage et la capacite du systeme a
identifier le bon type d’acte, meme en cas d’acte de langage indirect. Avec D : « un billet pour
Paris », qui peut faire suite a une question ou qui peut correspondre a une demande initiale, la
question Q : « est-ce une demande ? » permet d’evaluer l’acte identiﬁe par le systeme. Il est
necessaire ici de distinguer deux types de dialogue multimodal. Dans le premier type, les
gestes et les autres modalites de communication restent co-verbaux, c’est-a-dire que
l’information qu’ils apportent s’ajoute a celle portee par l’enonce en langage naturel, et l’acte
de langage de l’enonce multimodal est celui de l’enonce oral. C’est le cas des exemples
etudies jusqu’a present avec « mets ca ici » et « deplace ca ici ». Un autre type de dialogue
multimodal autorise des gestes quasi-linguistiques ou, d’une maniere generale, un message
effectue avec une modalite autre que le langage naturel et portant en lui-meme un acte de
communication (ou acte de dialogue), similaire a un acte de langage. C’est le cas par exemple
lorsque l’on etend une interface graphique et que l’on autorise des gestes ayant des formes
telles qu’une croix ou une ﬂeche, chaque forme etant associee a un declenchement d’action.
La croix est un equivalent du « supprimer » en langage naturel et prend comme argument

1 La difference releve de la resolution de la reference aux actions : << deplace » ne peut referer qu’a une action de
deplacement, alors que << mets » peut referer soit a une action de deplacement, soit a une action de creation.
Les considerations suivantes concernent l’existence de plusieurs primitives pour << deplace » :

‘déplacer (objet, lieu)’ et ‘déplacer (objet, lieu, chemin) ’.

Vers Z ’e’valuati0n des systémes de dialogue multimodaux

l’objet cible par le geste. Quant a la ﬂeche, elle equivaut au « deplace ca ici » avec les aspects
dont nous avons parle. Dans un tel type de systeme multimodal, l’analyse en termes d’actes de
langage et d’actes de dialogue met en jeu plusieurs processus : l’identification de l’acte de
l’enonce oral et du predicat associe, l’identiﬁcation de l’acte du geste et du predicat associe,
ainsi que l’analyse de la compatibilite ou de l’incompatibilite entre les diverses hypotheses de
maniere a aboutir a un seul acte de dialogue qui sera a l’origine de la reaction du systeme. Par
exemple, un geste en forme de ﬂeche effectue en meme temps que l’enonce oral « deplace ca
ici » ne posera pas de probleme, alors qu’un geste en forme de croix effectue en meme temps
que le meme enonce oral conduira a une incoherence. Selon le systeme, cette incoherence
po11rra etre interpretee soit comme une erreur soit comme l’execution de deux taches
paralleles. Tous ces aspects peuvent etre evalues grace aux questions Q suivantes : « ce geste
est-il une demande ? » + geste ; « ce geste accompagne-t-il la parole ? » + geste ; « l’enonce
multimodal est-il une demande ? » ; etc. A ce stade, nous avons fait le tour des principaux
problemes qui se posent pour le traitement des entrees en dialogue multimodal.

Niveau 5 = « reconnaissance des intentions ». I1 s’agit ici de determiner les intentions ou les
buts sous-jacents aux enonces de l’utilisateur, donc a un niveau plus profond que le niveau 4.
Le principe est d’interroger explicitement les etats intentionnels, avec des questions Q telles
que : « l’utilisateur sait-il/veut-il... ? ». De tels etats intentionnels sont independants des
modalites, et l’extension de DQR a la multimodalite ne change rien a ce niveau.

Niveau 6 = « pertinence de la reponse ». L’objet de la question evaluative est ici assez large
puisqu’il s’agit de tester la pertinence des reponses du systeme. Les aspects couverts sont
donc a priori les capacites linguistiques (et donc multimodales) dont font preuve les reponses,
leur adequation par rapport a l’enonce initial de l’utilisateur, par rapport aux connaissances de
l’application, par rapport aux moyens de communication, par rapport au profil de l’utilisateur,
etc. Dans (Zeiliger et al., 2000), les exemples de questions Q sont les suivants: « cette
question est-elle agressive ? » ; « cette question est-elle necessaire ? » ; « cette proposition est-
elle possible a cet instant ? ». Ces exemples interrogent a la fois la forme et le contenu de la
reponse. Realiser un systeme de dialogue capable de repondre a de telles questions n’est pas
simple. Cela suppose que le systeme (chacun de ses modules) soit capable d’evaluer la
pertinence de ses propres decisions, un peu comme dans le modele du carnet d’esquisses de
(Sabah, 1996). En dialogue multimodal, il faudrait ajouter tous les aspects lies a la
multimodalite en sortie, c’est-a-dire aux decisions que le systeme a prises lors de la
determination du contenu et de la forme de la reponse multimodale. Ainsi, des exemples
possibles pour Q sont: « le choix de la ou des modalites de sortie est-il pertinent ? » ; « le
message est-il surcharge ? »; « le message est-il redondant ? »; « le message est-il bien
synchronise ? » ; « les informations presentees sont-elles pertinentes ? » ; etc. Ces questions
font le tour des principaux problemes qui se posent en sortie dans le dialogue multimodal.
Elles integrent des aspects metalinguistiques qui ne sont generalement pas implantes dans le
modele conceptuel et le lexique des systemes. Ces aspects metalinguistiques, en plus des
aspects metacognitifs vus precedemment, constituent clairement une limite a la faisabilite de
ce sixieme niveau, ainsi qu’a celle du niveau suivant.

Niveau 7 = « pertinence de la strategie ». Ce demier niveau teste la qualite de la strategie de
dialogue, c’est-a-dire si elle a ete efﬁcacement menee et si elle est reussie. En fait, les
questions couvrent non seulement la strategie de dialogue, mais egalement la strategie de
gestion de la tache : « le client est-il content ? » ; « y a-t-il trop de questions de conﬁrmation
indirectes ? » ; etc. Peuvent egalement étre interroges la lenteur, le nombre d’incidences, les
raisons possibles d’une rupture, c’est-a-dire tous les aspects que le systeme de dialogue peut
(theoriquement) calculer. Ces aspects etant independants des modalites, nous les gardons et
nous obtenons un DQR multimodal complet.

F rédéric Landragin

3.2 DCR multimodal

Comme nous l’avons déja évoqué, une autre matérialisation est le paradigme DCR (Antoine,
Caelen, 1999) qui, en remplacant la question évaluative par un controle C, minimise le
probleme de la capacité du systeme a répondre a cette question parfois métalinguistique. Le
controle consiste en une simplification ou une reformulation de la demande utilisateur initiale.
Ainsi, en reprenant quelques-uns des eXemples précédents, on fera intervenir les controles
multimodauX C suivants : « mets ‘subInis.teX’ en (X1, yl) » ; « déplace obj4353 de (X1, y1) a (X2,
y12 » ; « déplace obj4353 selon les points de passage (X3, y3), (X4, y4), (X5, y5)... ». Passer du
DQR multimodal a un DCR multimodal nécessite donc la paraphrase de maniere simple et
non ambigue des références multimodales, avec la description en langage naturel de
coordonnées spatiales. Les autres aspects ne posent pas de probleme particulier, en tout cas
pas plus de probleme que le passage de DQR a DCR.

3.3 Vers un PEACE pour le dialogue multimodal ?

Les principes de PEACE (Devillers et al., 2002) sont la reformulation de l’historique en une
phrase unique, l’utilisation de cette phrase pour une évaluation conteXtuelle de l’énoncé
courant, et l’eXploitation de représentations sémantiques de référence. Nous avons déja parlé
de la difﬁculté d’appliquer ce dernier principe au dialogue multimodal, et c’est donc l’idée de
reformulation de l’historique qu’il s’agit d’étudier ici.

La modélisation de l’historique du dialogue est un probleme récurrent en dialogue homme-
machine, et s’avere particulierement compleXe en dialogue multimodal (Landragin, 2004). En
nous focalisant sur le probleme de la référence auX objets, l’historique doit conserver a la fois
l’identiﬁant des référents (pour ressortir ceuX-ci lors de l’interprétation d’une anaphore) et les
mentions utilisées pour y référer (non seulement pour interpréter les éventuelles références
mentionnelles ou métalinguistiques, mais aussi et surtout pour interpréter les ellipses, en
particulier les ellipses nominales). En multimodal, il en est de meme et les formes
référentielles multimodales doivent donc étre conservées. (Landragin, 2004) montre que l’état
de la scene visuelle doit également étre sauvegardé a chaque étape, conduisant ainsi au moins
a un historique linguistique, un historique gestuel et un historique visuel. Une chaine de
référence faisant appel auX modalités utilisées ou auX souvenirs de l’utilisateur est alors
interprétable, par eXemple : « l’objet que je viens de désigner », « les deuX objets groupés un
peu plus loin », « celui de gauche », « celui qui était a droite », « le dernier ». Ces eXpressions
référentielles montrent d’elles-memes que la paraphrase d’un historique multimodal est une
tache impossible a réaliser, ou alors au priX de simpliﬁcations telles que le biais introduit
enlevera toute plausibilité a l’évaluation. En effet, le seul processus de paraphrase
automatisable est l’utilisation systématique des identifiants des référents, or cette solution
semble plus destructrice en dialogue multimodal qu’en dialogue oral : elle met en effet de cote
l’ensemble des aspects multimodauX. Il nous apparait donc difficile d’appliquer les principes
de PEACE au dialogue multimodal.

4 Conclusion et perspectives

L’évaluation des systemes de dialogue multimodauX s’avere en ﬁn de compte plus compleXe
que celle des systemes orauX (pourtant déja bien délicate), surtout quand la multimodalité est
considérée comme l’association complémentaire du langage naturel et d’autres modalités de
communication sur lesquelles s’appuie le langage. Dans cet article nous avons proposé une
eXtension du paradigme DQR/DCR a la multimodalité. Nos illustrations ont porté sur des

Vers l ’évaluation des systemes de dialogue multimodaux

dérivations de l’eXemple a l’origine de l’essor des travaux sur la multimodalité (« mets ca
ici »), et sont ainsi applicables a la majorité des phénomenes de référence multimodale. Si nos
propositions et les remarques afférentes constituent un produit de recherche en soi, elles
peuvent peut-étre aussi étre utiles a la réalisation de systemes de dialogue, de par les questions
soulevées et les préoccupations détaillées.

Plusieurs aspects restent a étudier pour obtenir une méthodologie couvrant le champ occupé
actuellement par le dialogue multimodal. Un aspect concerne les pistes qui sont explorées en
ce moment pour simpliﬁer la réalisation de systemes multimodaux : comme les phénomenes
sont de plus en plus nombreux et les processus de plus en plus complexes, une solution
consiste a faciliter le travail des développeurs en leur foumissant des environnements de
développement capables d’automatiser certaines phases de conception. Un exemple en est
l’approche par dérivation et génération de modeles : en simplifiant un peu, les développeurs
écrivent des modeles, et l’environnement de développement génere automatiquement des
modules du systeme a partir de ces modeles. L’évaluation des systemes obtenus doit alors
reposer non seulement sur le comportement du systeme face a des utilisateurs, mais aussi sur
la qualité des modeles initiaux et sur celle de la chaine de dérivation de modeles. D’autre part,
quand les systemes de dialogue multimodaux seront suffisamment nombreux, il nous apparait
utile de revenir sur la méthode d’évaluation par déﬁ. Son principe, que ce soit l’étape de
dérivation d’énoncés a partir d’un ensemble d’énoncés initiaux ou l’échange des roles entre
différents concepteurs, nous apparait en effet tout a fait pertinent pour le dialogue multimodal.

Références

ANTOINE J .-Y. (2003). Pour une ingénierie des langues plus linguistique. HDR informatique,
Université de Bretagne Sud, Vannes.

ANTOINE J .-Y., CAELEN J . (1999). Pour une évaluation objective, prédictive et générique de la
compréhension en CHM orale : le paradigme DCR (Demande, Controle, Résultat). Langues,
vol. 2, n° 2, 130-139.

BERINGER N., KARTAL U., LOUKA K., SCHIEL F., TURK U. (2002). PROMISE — A procedure
for multimodal interactive system evaluation. Proceedings of the LREC Workshop on
Multimodal Resources and M ultimodal Systems Evaluation, Las Palmas, 77-80.

BERNSEN N.O., DYBKJER L. (2004). Evaluation of Spoken Multimodal Conversation.
Proceedings of the Sixth International Conference on Multimodal Interfaces (ICMI), Penn
State University, 38-45.

BOLT R.A. (1980). Put-That-There: Voice and gesture at the graphics interface. Proceedings
of the 7th Annual Conference on Computer Graphics and Interactive Techniques, Seattle.

BONNEAU-MAYNARD H., AYACHE C., BECHET F., DENIS A., KUHN A., LEFEVRE F., MOSTEFA
D., QUIGNARD M., ROSSET S., SERVAN C., VILLANEAU J . (2006). Results of the French Evalda-
Media Evaluation Campaign for Literal Understanding. Proceedings of the 5th International
Conference on Language Resources and Evaluation (LREC ’06), Génes, Italie.

CAELEN J ., XUEREB A. (2007). Interaction et pragmatique. Paris : Hermes-Lavoisier.

CHAUDIRON S. (Ed.) (2004). Evaluation des systemes de traitement de l ’information. Paris :
Hermes-Lavoisier.

F re’de’ric Landragin

DEVILLERS L., MAYNARD H., PAROUBEK P. (2002). Méthodologies d’évaluation des systemes
de dialogue parlé : réﬂexions et expériences autour de la compréhension. Traitement
Automatique des Langues, vol. 43, n° 2, 155-184.

DYBKJER L., BERNSEN N.O., DYBKJER H. (1998). A Methodology for diagnostic evaluation

of spoken human-machine dialogue, International Journal of Human Computer Studies,
vol. 48, 605-625.

DYBKJER L., BERNSEN N.O., MINKER W. (2004). Evaluation and usability of multimodal
spoken language dialogue systems, Speech Communication, vol. 43, n° 1-2, 33-54.

ECKERT W., LEVIN E., PIERACCINI R. (1998). Automatic evaluation of spoken dialogue
systems. Proceedings of the 2nd Workshop on Formal Semantics and Pragmatics of
Dialogue, University of Twente, Enschede, The Netherlands, 99-110.

GIBBON D., MERTINS I., MOORE R.K. (2000). Handbook of multimodal and spoken dialogue
systems.‘ Resources, terminology and product evaluation. Kluwer Academic Publishers.

HIRSCHMAN L. (1992). Multi-Site Data Collection for a Spoken Language Corpus:
MADCOW. Proceedings of the DARPA Speech and Natural Language Workshop, New York.

LANDRAGIN F. (2004). Dialogue homme-machine multimodal. Paris : Hermes-Lavoisier.

L1TMAN D.J., PAN S. (1999). Empirically evaluating an adaptable spoken dialogue system.
Proceedings of the 7th International Conference on User Modeling.

LOPEZ-COZAR R., ARAKI M. (2005). Spoken, multilingual and multimodal dialogue systems.‘
Development and assessment. John Wiley & Sons, Ltd.

LOPEZ-COZAR R., DE LA TORRE A., SEGURA J .C., RUBIO A.J. (2003). Assessment of dialogue
systems by means of a new simulation technique, Speech Communication, vol. 40, 387-407.

MOLLER S., SMEELE P., BOLAND H., KREBBER J . (2007). Evaluating spoken dialogue systems
according to de-facto standards: A case study, Computer Speech and Language, vol. 21.

SABAH G. (1996). Le « carnet d’esquisses » : une mémoire interprétative dynamique. Actes du
colloque AF CET— AFIA, Rennes.

VUURPIJL L.G., TEN BOSCH L., ROSSIGNOL S., NEUMANN A., PFLEGER N., ENGEL R. (2004).
Evaluation of multimodal dialog systems. Proceedings of the LREC Workshop on Multimodal
Corpora and Evaluation, Lisbon, Portugal.

WALKER M.A., PASSONNEAU R., BOLAND J .E. (2001). Quantitative and Qualitative Evaluation
of Darpa Communicator Spoken Dialogue Systems. Meeting of the Association of
Computational Linguistics.

WALKER M.A., WI-II'I'I‘AKER S., STENT A., MALOOR P., MOORE J ., JOHNSTON M., VASIREDDY
G. (2004). Generation and Evaluation of User Tailored Responses in Multimodal Dialogue.
Cognitive Science, vol. 28, n° 5, 811-840.

ZEILIGER J ., ANTOINE J .-Y., CAELEN J . (2000). La méthodologie DQR d’évaluation qualitative
des systemes de dialogue oral homme-machine, Dans Mariani J ., Masson N., Néel F., Chibout
K. (Ed.) Ressources et Evaluations en Ingénierie de la Langue, AUF et De Boeck Université.

