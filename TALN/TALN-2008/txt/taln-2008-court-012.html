<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Cascades de transducteurs pour le chunking de la parole conversationnelle : l&#8217;utilisation de la plateforme CasSys dans le projet EPAC</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2008, Avignon, juin 2008 
</p>
<p>Cascades de transducteurs pour le chunking de la parole 
conversationnelle : l&#8217;utilisation de la plateforme CasSys dans le 
</p>
<p>projet EPAC 
</p>
<p>Abdenour Mokrane, Nathalie Friburger, Jean-Yves Antoine 
</p>
<p>Universit&#233; Fran&#231;ois Rabelais Tours &#8211; LI, IUP Blois, France 
{prenom.nom}@univ-tours.fr 
</p>
<p> 
</p>
<p>R&#233;sum&#233; &#8211; Cet article pr&#233;sente l&#8217;utilisation de la plate-forme CasSys pour la segmentation 
de la parole conversationnelle (chunking) &#224; l&#8217;aide de cascades de transducteurs Unitex. Le 
syst&#232;me que nous pr&#233;sentons est utilis&#233; dans le cadre du projet ANR EPAC. Ce projet a pour 
objectif l&#8217;indexation et l&#8217;annotation automatique de grands flux de parole issus d&#8217;&#233;missions 
t&#233;l&#233;vis&#233;es ou radiophoniques. Cet article pr&#233;sente tout d&#8217;abord l&#8217;adaptation &#224; ce type de 
donn&#233;es d&#8217;un syst&#232;me ant&#233;rieur de chunking (Romus) qui avait &#233;t&#233; d&#233;velopp&#233; pour le dialogue 
oral homme-machine. Il d&#233;crit ensuite les principaux probl&#232;mes qui se posent &#224; l&#8217;analyse : 
traitement des disfluences de l&#8217;oral spontan&#233;, mais &#233;galement gestion des erreurs dues aux 
&#233;tapes ant&#233;rieures de reconnaissance de la parole et d&#8217;&#233;tiquetage morphosyntaxique. 
</p>
<p>Abstract &#8211; This paper describes the use of the CasSys platform in order to achieve the 
chunking of conversational speech transcripts by means of cascades of Unitex transducers. 
Our system is involved in the EPAC project of the French National Agency of Research 
(ANR). The aim of this project is to develop robust methods for the annotation of 
audio/multimedia document collections which contains conversational speech sequences such 
as TV or radio programs. At first, this paper presents the adaptation of a former chunking 
system (Romus) which was developed in the restricted framework of dedicated spoken man-
machine dialogue. Then, it describes the problems that are arising due to 1) spontaneous 
speech disfluencies and 2) errors for the previous stages of processing (automatic speech 
recognition and POS tagging).  
</p>
<p>Mots-cl&#233;s &#8211; Traitement Automatique du Langage Parl&#233; (TALP), segmentation, chunks, 
parole conversationnelle, transducteurs, Unitex. 
</p>
<p>Keywords &#8211; Spoken Language Processing, chunking, conversational speech, transducers, 
Unitex. 
</p>
<p> </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mokrane, Friburger, Antoine 
</p>
<p>1 Introduction : le projet EPAC 
Du fait du d&#233;veloppement des technologies de l&#8217;information et de la communication, le grand 
public et les professionnels ont acc&#232;s &#224; une masse de donn&#233;es num&#233;riques de taille de plus en 
plus consid&#233;rable. D&#232;s lors, la question qui se pose est celle de m&#233;thodes d&#8217;acc&#232;s efficaces &#224; 
l&#8217;information. Elle n&#233;cessite la mise en place de techniques avanc&#233;es de recherche 
d&#8217;information permettant une compr&#233;hension fine des requ&#234;tes et des documents manipul&#233;s. 
Pour fonctionner, ces techniques requi&#232;rent une indexation pr&#233;alable des donn&#233;es qui vont &#234;tre 
interrog&#233;es. Le projet EPAC vise la r&#233;alisation d&#8217;outils robustes d&#8217;indexation et d&#8217;annotation 
adapt&#233;s &#224; un type particulier de donn&#233;e : la parole conversationnelle issue principalement de 
flux de donn&#233;es multim&#233;dias tels que les &#233;missions radiophoniques ou t&#233;l&#233;visuelles. 
</p>
<p>Financ&#233; par l&#8217;ANR (programme MDCA - Masse de Donn&#233;es), EPAC r&#233;unit plusieurs 
laboratoires (LIUM, LIA, IRIT, LI) sp&#233;cialistes du traitement de la parole et du TALN. 
Comme l&#8217;ont montr&#233; les campagnes d&#8217;&#233;valuation ARPA Broadcast News pour l&#8217;anglais ou 
ESTER pour le fran&#231;ais (Galliano et al. 2005), les progr&#232;s de la reconnaissance de la parole 
rendent possible la transcription automatique de grands flux de donn&#233;es audio ou multim&#233;dia. 
Centr&#233;s sur les journaux d&#8217;information, ces campagnes ont principalement concern&#233; de la 
parole pr&#233;par&#233;e ou faiblement spontan&#233;e. A l&#8217;oppos&#233;, le projet EPAC s&#8217;int&#233;resse &#224; des flux 
multim&#233;dias comprenant des s&#233;quences de parole conversationnelle caract&#233;ris&#233;e par une 
interactivit&#233; &#233;lev&#233;e et une forte spontan&#233;it&#233;. Ce nouveau champ d&#8217;application n&#233;cessite la mise 
en &#339;uvre d&#8217;outils sp&#233;cifiques au niveau du traitement du signal : segmentation en zones de 
silence, parole, musique ou jingles, identification des tours de parole et des locuteurs, etc. La 
reconnaissance de la parole doit par ailleurs conserver sa robustesse en d&#233;pit de la nature 
spontan&#233;e de l&#8217;&#233;locution et de la pr&#233;sence de chevauchements entre locuteurs. Les premiers 
r&#233;sultats obtenus dans le cadre du projet montrent que la transcription automatique de la 
parole conversationnelle reste un objectif r&#233;aliste (Lecouteux et al. 2008). Au terme du projet, 
nous visons la diffusion d&#8217;un corpus transcrit d&#8217;une dur&#233;e de 200 heures d&#8217;enregistrement. 
</p>
<p>La segmentation du flux multim&#233;dia et la transcription fournissent un corpus orthographique, 
accompagn&#233; de m&#233;ta-donn&#233;es, qui est d&#233;j&#224; utilisable par la recherche d&#8217;information. Il est 
toutefois int&#233;ressant de l&#8217;enrichir par diff&#233;rents niveaux d&#8217;annotation &#233;tudi&#233;s dans EPAC : 
</p>
<p>&#1; Etiquetage morphosyntaxique et parenth&#232;sage en segments minimaux des transcriptions,  
&#1; D&#233;tection et typage des entit&#233;s nomm&#233;es, application &#224; l&#8217;identification du locuteur, 
&#1; D&#233;tection d&#8217;opinion pour chaque tour de parole. 
Le laboratoire LI est impliqu&#233; dans la t&#226;che de d&#233;tection des entit&#233;s nomm&#233;es et celle de la 
segmentation en chunks (chunking) sur laquelle porte cet article. Dans un premier temps, nous 
pr&#233;sentons notre d&#233;marche qui repose sur l&#8217;application de cascades de transducteurs qui 
mod&#233;lisent les chunks. Nous pr&#233;sentons ensuite la plateforme CasSys qui permet l&#8217;ex&#233;cution 
de cascades de transducteurs Unitex. On d&#233;crit ensuite la mise en &#339;uvre du chunking sur 
CasSys ainsi que des r&#233;sultats &#233;tudiant l&#8217;influence des erreurs d&#8217;&#233;tiquetage et des disfluences. 
</p>
<p>2 Chunking de la parole conversationnelle : probl&#232;mes 
La segmentation en chunks des &#233;nonc&#233;s s&#8217;est d&#233;velopp&#233;e en TALN &#224; la suite, notamment, des 
travaux de Steven Abney (1991). Cette notion a cependant &#233;t&#233; identifi&#233;e bien plus t&#244;t en </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Cascades de transducteurs pour le chunking de la parole conversationnelle 
</p>
<p>linguistique et en psycholinguistique. En premi&#232;re approximation, on peut d&#233;finir un chunk 
comme un groupe syntaxique minimal non r&#233;cursif. Consid&#233;rons l&#8217;&#233;nonc&#233; suivant : 
</p>
<p>(1) [cette petite phrase]GN [vous explicite]GV [la notion]GN [de chunk]GP  
</p>
<p>Il se d&#233;compose en diff&#233;rents chunks : nominal (GN), verbal (GV) ou pr&#233;positionnel (GP). La 
segmentation illustre le caract&#232;re non r&#233;cursif du GP, qui n&#8217;englobe pas de GN. Suivant les 
approches consid&#233;r&#233;es, la port&#233;e du chunk (granularit&#233;) peut cependant &#234;tre variable. Dans 
tous les cas, le parenth&#233;sage en chunks rev&#234;t plusieurs int&#233;r&#234;ts pour la recherche d&#8217;information 
dans un flux de parole conversationnelle : 
</p>
<p>&#1; Centr&#233; sur un mot lexical unique, le chunk correspond &#224; une unit&#233; minimale de sens dans 
l&#8217;univers du discours, sur laquelle peut reposer la recherche d&#8217;information. Ainsi, les 
entit&#233;s nomm&#233;es correspondent toujours &#224; un ou plusieurs chunks.  
</p>
<p>&#1; Le chunk est adapt&#233; &#224; la parole conversationnelle. Il est en effet le lieu de r&#233;alisation 
privil&#233;gi&#233; de l&#8217;entassement paradigmatique (Blanche-Benveniste, 1997:47) mis en jeu par 
les r&#233;p&#233;titions ou les r&#233;parations de l&#8217;oral spontan&#233;. Lorsqu&#8217;une disfluence a une port&#233;e 
sup&#233;rieure au chunk, elle n&#8217;affecte en aucune mani&#232;re les chunks ext&#233;rieurs.  
</p>
<p>Cette derni&#232;re remarque est importante, car les disfluences orales (h&#233;sitations, r&#233;p&#233;titions, 
r&#233;parations, incises) cassent souvent la structure syntaxique des &#233;nonc&#233;s, ce qui rend d&#8217;autant 
plus difficile leur analyse automatique.  
</p>
<p>De nombreux syst&#232;mes de chunking efficaces (Giguet &amp;Vergne 1997) ont &#233;t&#233; d&#233;velopp&#233;s 
pour le langage &#233;crit. Les disfluences de l&#8217;oral spontan&#233; interdisent toutefois leur application 
directe &#224; la parole hautement conversationnelle. C&#8217;est ainsi que la communaut&#233; parole s&#8217;est 
tourn&#233;e, &#224; la suite de (Hindle 1983), vers des approches plus ad-hoc de pr&#233;-correction avant 
analyse : on d&#233;tecte des patterns assez simples de reprises, dont le reparandum est  ensuite 
effac&#233; pour normaliser l&#8217;&#233;nonc&#233; (Bear et al. 1992 ; Heeman &amp; Allen 2001). Ces techniques 
ont donn&#233; de bons r&#233;sultats en d&#233;tection, mais op&#232;rent parfois des effacements abusifs. Plus 
globalement, l&#8217;effacement du reparandum peut gommer une information utile. Consid&#233;rons 
les deux exemples ci-dessous :  
</p>
<p>(2) Je cherche [un camping pr&#232;s de la gare]REP [euh non]ED un pr&#232;s de la c&#244;te pardon  
(3) Barton Fink est [un film dense]REP un film port&#233; par un sc&#233;nario foisonnant  
Dans l&#8217;exemple (2), la suppression du reparandum avant la zone d&#8217;&#233;dition euh non emp&#234;che le 
calcul de la r&#233;f&#233;rence dans l&#8217;alt&#233;ration un pr&#232;s de la c&#244;te. L&#8217;exemple (3) correspond &#224; une 
r&#233;p&#233;tition avec enrichissement lexical. Effacer le reparandum revient &#224; perdre une information 
qui n&#8217;est en rien corrig&#233;e par l&#8217;alt&#233;ration qui suit. Les cons&#233;quences de ces effacements 
abusifs peuvent &#234;tre importantes. Aussi adoptons nous une d&#233;marche non destructive. 
</p>
<p>3 Chunking incr&#233;mental de la parole : cascade de transducteurs 
Nous proposons une analyse incr&#233;mentale fond&#233;e sur la d&#233;tection d&#8217;ilots de certitude : les 
chunks non affect&#233;s par les disfluences. Dans un premier temps, on applique des r&#232;gles de  
segmentation d&#233;crivant les structures &#171; l&#233;gitimes &#187; des chunks. Les zones non segment&#233;es &#224; 
l&#8217;issue de cette &#233;tape sont marqu&#233;es comme disfluentes. Il est alors envisageable d&#8217;appliquer 
des r&#232;gles sp&#233;cifiques pour caract&#233;riser les diff&#233;rentes parties des disfluences (reparandum, </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mokrane, Friburger, Antoine 
</p>
<p>zone d&#8217;&#233;dition) sans les effacer. Cette d&#233;marche rejoint les principes du TAL robuste, &#224; savoir 
(A&#239;t-Mokhtar et al. 2003) que l&#8217;analyse est compl&#232;te mais superficielle (shallow parsing), 
qu&#8217;elle est non destructrice (on conserve l&#8217;information pour les &#233;tapes ult&#233;rieures) et suit une 
strat&#233;gie incr&#233;mentale o&#249; chaque niveau utilise une connaissance qui fait sens par elle-m&#234;me 
(ind&#233;pendance conceptuelle). 
</p>
<p>Nous avions adopt&#233; cette approche dans le syst&#232;me ROMUS de compr&#233;hension automatique de 
la parole (Goulian et al. 2003 ; Antoine et al. 2003). Dans ROMUS, la structure des chunks est 
d&#233;crite par des expressions r&#233;guli&#232;res travaillant sur les parties du discours associ&#233;es aux 
mots. Ces expressions sont compil&#233;es en transducteurs d&#233;terministes &#224; l&#8217;aide du toolkit FSA 
(Van Noord 1997). Chaque transducteur est utilis&#233; en cascade pour introduire dans l&#8217;&#233;nonc&#233; 
des marqueurs de d&#233;limitation, jusqu&#8217;&#224; arriver &#224; une segmentation compl&#232;te. L&#8217;ambigu&#239;t&#233; est 
g&#233;r&#233;e par une heuristique de maximisation des segments construits. Ces principes sont repris 
par le syst&#232;me SECARE que nous avons r&#233;alis&#233; pour EPAC, avec trois particularit&#233;s 
suppl&#233;mentaires : 
</p>
<p>&#1; le champ d&#8217;application de SECARE n&#8217;est plus le dialogue oral homme-machine finalis&#233; 
mais la langue g&#233;n&#233;rale. Il n&#8217;est donc plus possible de s&#8217;appuyer sur une connaissance 
pragmatique pour r&#233;soudre la caract&#233;risation finale des zones disfluentes, 
</p>
<p>&#1; alors que ROMUS travaillait sur de la parole transcrite, SECARE op&#233;rera sur les sorties 
r&#233;elles de la reconnaissance de la parole, fournies par les laboratoires LIA ou LIUM, 
</p>
<p>&#1; Les cascades de transducteurs ne sont plus implant&#233;es sur le toolkit FSa, mais sur la 
plateforme CasSys/Unitex. L&#8217;int&#233;r&#234;t d&#8217;Unitex est de fournir une repr&#233;sentation explicite 
de la structure des chunks, qui peut donc &#234;tre manipul&#233;e par des linguistes non 
informaticiens. 
</p>
<p>4 CasSys / Unitex 
CasSys est un syst&#232;me de cascade de transducteurs, d&#233;velopp&#233; au LI, utilisant des outils 
propos&#233;s par Unitex (Paumier 2003). La cascade est une suite de transducteurs, au format 
Unitex, pass&#233;s dans un ordre pr&#233;cis afin par exemple d'extraire ou de remplacer des motifs, ou 
encore d'enrichir le texte avec un balisage XML (Friburger. 2002).   
</p>
<p>Sous Unitex, les transducteurs sont repr&#233;sent&#233;s par des graphes (figure 1) facilement lisibles. 
Le fonctionnement interne &quot;simplifi&#233;&quot; d'Unitex est le suivant. Unitex m&#233;morise dans un 
fichier tous les motifs localis&#233;s et leur emplacement dans le texte analys&#233;. Puis si on demande 
une concordance, Unitex transforme le texte en fonction du mode choisi : en mode 
remplacement, il remplace les entr&#233;es du transducteur par ses sorties, alors qu&#8217;en mode fusion, 
il fusionne les entr&#233;es et sorties. 
</p>
<p>sous la direction de von Karajan
&lt;person&gt; &lt;/person&gt;
</p>
<p> 
</p>
<p>Figure 1: Un exemple de transducteur Unitex 
</p>
<p>CasSys ajoute &#224; Unitex la possibilit&#233; d'extraire un motif du texte (ce motif &#233;tant enrichi des 
&#233;ventuelles sorties du transducteur) pour le m&#233;moriser dans un fichier tandis qu'on le remplace 
dans le texte par une &#233;tiquette qui permettra de le retrouver plus tard. Suivant les principes de 
l&#8217;analyse en cascade, les transducteurs sont donc pass&#233;s de sorte qu'on reconnaisse en premier </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Cascades de transducteurs pour le chunking de la parole conversationnelle 
</p>
<p>les motifs les moins ambigus; ceux ci sont supprim&#233;s du texte et par la suite ne risquent pas 
d'&#234;tre confondus avec un motif reconnu par un autre transducteur. 
</p>
<p>A titre d&#8217;illustration, le graphe repr&#233;sent&#233; dans la figure 1 reconna&#238;t exclusivement la phrase 
&#171; sous la direction de von Karajan &#187;. On applique ce transducteur sur le texte suivant (4) pour 
obtenir apr&#232;s application la s&#233;quence (4&#8217;): 
</p>
<p>(4) Le concert a lieu, sous la direction de von Karajan, en Bavi&#232;re. 
(4&#8217;) Le concert a lieu, sous la direction de &lt;$exemple1:0$&gt;, en Bavi&#232;re. 
</p>
<p>Les entr&#233;es reconnues et les sorties du transducteur sont fusionn&#233;es pour donner la s&#233;quence 
&lt;person&gt; von Karajan &lt;/person&gt; qui est extraite du texte et plac&#233;e dans un index &#224; la 
position 0. On peut choisir que seule la partie reconnue entre les balises &lt;person&gt; et 
&lt;/person&gt; soit extraite du texte, dans ce cas la s&#233;quence sous la direction de est toujours dans 
le texte. L'&#233;tiquette &lt;$exemple1:0$&gt; ins&#233;r&#233;e dans le texte indique quel est le graphe qui a 
reconnu cette s&#233;quence (exemple1) et permet de retrouver la s&#233;quence correspondante dans le 
fichier index (position 0). A la fin de la cascade, les motifs extraits sont replac&#233;s dans le texte: 
</p>
<p>(4&#8217;&#8217;) Le concert a lieu, sous la direction de &lt;person&gt; von Karajan &lt;/person&gt;, en Bavi&#232;re. 
</p>
<p>5 Implantation des cascades de transducteurs  
</p>
<p>5.1 Formats de donn&#233;es : segmentation PEAS 
</p>
<p>Un des r&#233;sultats attendus du projet EPAC est la mise &#224; disposition d&#8217;un grand corpus de 
parole conversationnelle transcrite et annot&#233;e. La r&#233;utilisabilit&#233; de cette ressource est favoris&#233;e 
par la normalisation des formats d&#8217;encodage, qui utilisent tous XML. Les transcriptions 
suivent le format .trs Transcriber. Afin d&#8217;ajouter des couches d&#8217;annotations ind&#233;pendantes sur 
les transcriptions, nous avons d&#233;fini une r&#233;f&#233;rence temporelle de synchronisation qui se base 
sur une segmentation des transcriptions en tokens. Cette r&#233;f&#233;rence s&#8217;inspire du format utilis&#233; 
dans le projet europ&#233;en LUNA (www.ist-luna.eu/). 
La segmentation en chunks repose sur le format PEAS utilis&#233; lors de la campagne de test 
EASy (Paroubek et al. 2006). Le choix de PEAS rel&#232;ve de notre volont&#233; de normalisation. Il 
peut &#234;tre consid&#233;r&#233; en effet comme un format d&#8217;&#233;change accept&#233; par l&#8217;ensemble de la 
communaut&#233; francophone. Issu de difficiles compromis, PEAS a conduit &#224; une simplification 
extr&#234;me de la port&#233;e des chunks. Par exemple, la s&#233;quence de mots tr&#232;s tr&#232;s haut y est annot&#233;e 
comme la suite de deux groupes adverbiaux (GR) suivi d&#8217;un groupe adjectival (GA) alors 
qu&#8217;il est clair que les adverbes de degr&#233;s d&#233;pendent de l&#8217;adjectif qu&#8217;ils qualifient. PEAS rend 
compte de ces d&#233;pendances par des relations entre chunks. Il nous semble toutefois regrettable 
d&#8217;identifier des d&#233;pendances aussi locales et, par exemple, la relation de sous-cat&#233;gorisation 
entre un pr&#233;dicat verbal et ses arguments. Nous ne nous interdisons pas de regrouper en 
interne certains types de chunks pour accro&#238;tre leur port&#233;e. Mais les donn&#233;es qui seront 
diffus&#233;es suivront la norme PEAS, &#224; laquelle nous avons apport&#233; deux compl&#233;ments : 
</p>
<p>&#1; Cat&#233;gories sp&#233;cifiques aux disfluences orales, qui avaient pas &#233;t&#233; &#233;tudi&#233;es dans EASy et 
donc par PEAS, qui est plus centr&#233; sur l&#8217;&#233;crit : REP (reparandum) et ED (zone d&#8217;&#233;dition), 
</p>
<p>&#1; Cat&#233;gories sp&#233;cifiques pour assurer un parenth&#233;sage complet de l&#8217;&#233;nonc&#233;. Par exemple, 
ajout d&#8217;un chunk COO pour repr&#233;senter les conjonctions de coordination. La coordination </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mokrane, Friburger, Antoine 
</p>
<p>est repr&#233;sent&#233;e dans PEAS par une relation de d&#233;pendance. Il nous semble plus justifi&#233; de 
lui accorder le statut de chunk, &#224; la fois pour atteindre une segmentation compl&#232;te, mais 
&#233;galement parce que les coordinations peuvent contenir des disfluences orales complexes. 
</p>
<p>Pour rappel, PEAS distingue &#224; la base les chunks suivants : NV (noyau verbal), PV (groupe 
verbal infinitif introduit par une pr&#233;position), GN (groupe nominal), GP (groupe 
pr&#233;positionnel), GA (groupe adjectival sans les adjectifs ant&#233;pos&#233;s) et GR (groupe adverbial). 
</p>
<p>5.2 Implantation des cascades sur CasSys / Unitex 
</p>
<p>Comme nous l&#8217;avons vu (cf. &#167; 3), la segmentation est bas&#233;e sur une cascade de transducteurs 
qui identifie dans une premi&#232;re passe les chunks qui ont une structure norm&#233;e, suivant une 
strat&#233;gie par ilots de confiance. Ce n&#8217;est que dans un second temps que l&#8217;on s&#8217;int&#233;resse aux 
zones non identifi&#233;es, afin de r&#233;aliser une segmentation compl&#232;te des &#233;nonc&#233;s. A l&#8217;heure 
actuelle, seules des transcriptions manuelles de parole conversationnelle ont &#233;t&#233; diffus&#233;es aux 
partenaires du projet EPAC. Dans l&#8217;attente de la r&#233;ception de transcriptions automatiques, et 
compte tenu de l&#8217;influence centrale des erreurs de reconnaissance sur la robustesse des 
syst&#232;mes, nous avons choisi de n&#8217;impl&#233;menter int&#233;gralement que la premi&#232;re cascade et d&#8217;en 
&#233;tudier les limites. La seconde passe se limite &#224; la caract&#233;risation des cat&#233;gories 
compl&#233;mentaires aux annotations PEAS, tel que le chunk COO et le chunk PONCT (pour la 
ponctuation). Elle attribue enfin l&#8217;&#233;tiquette CHINC (chunk inconnu) aux zones non encore 
segment&#233;es. Ces s&#233;quences seront par la suite analys&#233;es, soit pour caract&#233;riser les disfluences, 
soit pour corriger des erreurs de reconnaissance ou d&#8217;&#233;tiquetage morphosyntaxique. La cha&#238;ne 
globale de traitement est illustr&#233;e dans la figure 2. 
</p>
<p>    
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p>Figure 2: cha&#238;ne de traitements pour le chunking 
</p>
<p>segmentation en  
chunks 
</p>
<p>(flux XML) 
transcriptions 
</p>
<p>+ &#233;tiquettes POS 
</p>
<p>CasSys / 
Unitex 
</p>
<p>Cascade de 
transducteurs : passe 1 
</p>
<p> 
</p>
<p>Segmentation en chunks 
 
</p>
<p>Cascade de 
transducteurs : passe 2 
</p>
<p>Analyse et 
interpr&#233;tation 
</p>
<p>Annotation 2 : 
CHINC, REP, ED 
</p>
<p> 
</p>
<p>Annotation 1 : 
PV, NV, GP, GN, GA, GR 
</p>
<p> 
</p>
<p>L&#8217;analyse repose sur la d&#233;finition d&#8217;un transducteur par type de chunk (GN, NV, etc.). A 
chaque chunk est associ&#233; un transducteur principal qui d&#233;crit sa structure syntaxique et une 
s&#233;rie de transducteurs interm&#233;diaires d&#233;di&#233;s &#224; la reconnaissance des mots avec leurs tags et &#224; 
la gestion des flux XML. Au final, la s&#233;quence de mots &#233;tiquet&#233;s ci-dessous : 
</p>
<p>&lt;word id=&quot;s0034_w0001&quot; token=&quot;s0034_t0005&quot; pos=&quot;AINDMP&quot;&gt; tous_les &lt;/word&gt; 
&lt;word id=&quot;s0034_w0002&quot; token=&quot;s0034_t0007&quot; pos=&quot;NMP&quot;&gt; jours &lt;/word&gt; 
</p>
<p>permet la g&#233;n&#233;ration, via la plate forme CasSys, du chunk GN suivant, &#233;galement en XML : 
&lt;chunk token_deb=&quot;s0034_t0005&quot; word_deb=&quot;s0034_w0001&quot; 
token_fin=&quot;s0034_t0007&quot; word_fin=&quot;s0034_w0002&quot; id=&quot;s0034_c&quot;&gt; GN &lt;/chunk&gt; </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Cascades de transducteurs pour le chunking de la parole conversationnelle 
</p>
<p>Nous avons &#233;galement r&#233;-impl&#233;ment&#233; certains automates pr&#233;d&#233;finis sous Unitex, tel que 
l&#8217;automate &lt;MOT&gt;, ceci afin de supporter certaines disfluences (amorces de mots inachev&#233;s, 
par exemple). La base d&#8217;identification des chunks de la premi&#232;re passe est compos&#233;e de 386 
transducteurs. La figure 3 donne un exemple de transducteur principal associ&#233; au chunk GN. 
    
</p>
<p> 
</p>
<p>Figure 3: Transducteur principal associ&#233; au chunk GN 
</p>
<p>L&#8217;ordre d&#8217;application des transducteurs dans la cascade est essentiel, puisqu&#8217;il permet de g&#233;rer 
les ambigu&#239;t&#233;s d&#8217;analyse, notamment pour les chunks qui se recouvrent. On comprend ainsi 
ais&#233;ment que le transducteur GP doit &#234;tre appliqu&#233; avant celui du GN. Un transducteur 
interm&#233;diaire GNpourGP permet par contre d&#8217;appeler la recherche de motifs de type GN une 
fois pass&#233;e la pr&#233;position (figure 4). Il en va de m&#234;me pour PV par rapport &#224; NV. Au final, la 
premi&#232;re cascade suit l&#8217;ordre PV puis NV, GP, GN, GA, et GR. L&#8217;application de NV avant 
GN est rendue n&#233;cessaire par l&#8217;inclusion potentielle de GN pronominaux dans les noyaux 
verbaux (pronoms personnels sujets ou clitiques). De m&#234;me, les GN peuvent inclure des 
adjectifs ant&#233;pos&#233;s, GA doit donc &#234;tre appliqu&#233; apr&#232;s GN dans la cascade. Dans la seconde 
passe, l&#8217;ordre est le suivant: PONCT, COO, puis CHINC. Appliqu&#233; en dernier, le transducteur 
CHINC (segments inconnus) servira ult&#233;rieurement &#224; l&#8217;analyse fine des disfluences. 
</p>
<p> 
</p>
<p>Figure 4:  Exemple de cas de chunks en recouvrement : transducteur GP 
</p>
<p>A titre d&#8217;exemple, le chunk CHINC ci-dessous est d&#251; &#224; une non reconnaissance (MOTINC : 
mot hors vocabulaire) de noms propres par le tagueur LIA_TAGG1 du laboratoire LIA. Nous 
revenons sur ce probl&#232;me dans le paragraphe suivant. 
</p>
<p>                                                 
</p>
<p>1
  LIA_TAGG : http://old.lia.univ-avignon.fr/chercheurs/bechet/download_fred.html </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mokrane, Friburger, Antoine 
</p>
<p>&lt;word id=&quot;s0002_w0003&quot; token=&quot;s0002_t0005&quot; pos=&quot;MOTINC&quot;&gt; Miroslav &lt;/word&gt; 
&lt;word id=&quot;s0002_w0004&quot; token=&quot;s0002_t0007&quot; pos=&quot;MOTINC&quot;&gt; Marcelli &lt;/word&gt; 
&lt;chunk token_deb=&quot;s0002_t0005&quot; word_deb=&quot;s0002_w0003&quot; 
token_fin=&quot;s0002_t0007&quot; word_fin=&quot;s0002_w0004&quot; id=&quot;s0002_c&quot;&gt;CHINC&lt;/chunk&gt; 
</p>
<p>6 R&#233;sultats 
Le syst&#232;me SECARE a &#233;t&#233; &#233;valu&#233; sur les transcriptions manuelles d&#233;j&#224; r&#233;alis&#233;es dans le cadre 
d&#8217;EPAC. Il n&#8217;est pas inutile de rappeler que ni EASy ni la premi&#232;re campagne d&#8217;&#233;valuation 
ESTER ne se sont int&#233;ress&#233;es au chunking de la parole conversationnelle. Il n&#8217;existe donc pas 
de r&#233;sultats de r&#233;f&#233;rence en la mati&#232;re. Les tests ont &#233;t&#233; effectu&#233;s sur un extrait d&#8217;&#233;mission 
radiophonique &#224; forte interactivit&#233;, regroupant 893 chunks. Les transcriptions ont &#233;t&#233; annot&#233;es 
en partie du discours par l&#8217;&#233;tiqueteur LIA_TAGG. Ces annotations comportent un certain taux 
d&#8217;erreurs, puisque LIA_TAGG n&#8217;a pas encore &#233;t&#233; adapt&#233; &#224; la t&#226;che EPAC.  
</p>
<p>SECARE a un comportement robuste en pr&#233;sence de disfluences. Les r&#233;parations ne cr&#233;ent pas 
de faux positifs et n&#8217;induisent pas d&#8217;erreurs dans la d&#233;limitation des chunks r&#233;guliers. Comme 
on pouvait s&#8217;y attendre, les erreurs de tagging ont par contre une influence directe sur les 
performances du syst&#232;me. Ainsi, les mots inconnus de LIA_TAGG peuvent fausser la 
d&#233;limitation des chunks. Consid&#233;rons l&#8217;exemple suivant : 
</p>
<p>(5) sortie LIA_TAGG) [le]DETMS [livre]NMS  [de]PREP_ADE [Pierre]XPREM [P&#233;an]MOTINC 
segmentation  [le livre]GN  [de Pierre]GP [P&#233;an]CHINC 
</p>
<p>LIA_TAGG ne connait pas le patronyme P&#233;an qui est &#233;tiquet&#233; comme mot inconnu. SECARE 
ne peut alors identifier le rattachement de ce dernier au groupe pr&#233;positionnel. Cette situation 
est particuli&#232;rement p&#233;nalisante dans le cas des entit&#233;s nomm&#233;es.  
</p>
<p>Dans l&#8217;exemple ci-dessous (6), ce n&#8217;est pas la r&#233;p&#233;tition du d&#233;terminant &#171;une&#187; qui trompe le 
syst&#232;me, mais le fait que sa seconde occurrence est &#233;tiquet&#233;e par erreur comme un adjectif : 
(6) sortie LIA_TAGG [d&#8217;]PREP_ADE [une]DETFS  [une]AFS [g&#233;n&#233;ration]NFS 
</p>
<p>segmentation  [d&#8217;une une g&#233;n&#233;ration]GP 
Au final, on r&#233;cup&#232;re un faux positif &#233;quivalent structurellement au chunk &#171;d&#8217;une belle 
g&#233;n&#233;ration&#187; alors que SECARE aurait normalement bien d&#233;tect&#233; la pr&#233;sence d&#8217;une disfluence.  
</p>
<p>Ces observations se retrouvent d&#8217;un point de vue quantitatif. Nous avons utilis&#233; plusieurs 
m&#233;triques de test, afin de caract&#233;riser aussi bien les erreurs de typage que de d&#233;limitation : 
</p>
<p>&#1; Rappel (R), pr&#233;cision (P) et F-score de la segmentation, 
</p>
<p>&#1; Les taux d&#8217;insertion (I), suppression (D) et substitution (S) quantifient mieux les erreurs 
de d&#233;limitation de chunks. Si un GP attendu est scind&#233; en un GR et un GN, trois erreurs 
vont &#234;tre imput&#233;es au syst&#232;me : la suppression du GP et l&#8217;insertion du GR et du GN. 
</p>
<p>Le tableau 1 pr&#233;sente les performances de SECARE sur l&#8217;ensemble du corpus et sur les chunks 
dans lesquels le LIA_TAGG n&#8217;a pas fait d&#8217;erreur d&#8217;&#233;tiquetage. Pour information, 9,4% des 
chunks &#233;tudi&#233;s pr&#233;sentaient au moins un mot avec une partie du discours erron&#233;e. Ces 
r&#233;sultats sugg&#232;rent que nos transducteurs sont robustes. Si le F-score n&#8217;est globalement que de 
0.805, les segmentations erron&#233;es sont majoritairement dues aux erreurs d&#8217;&#233;tiquetage 
morphosyntaxique. En effet, le F-score approche 0.94 sur les chunks sans erreur d&#8217;&#233;tiquetage.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Cascades de transducteurs pour le chunking de la parole conversationnelle 
</p>
<p>La plupart des erreurs du syst&#232;me correspond au d&#233;coupage des chunks attendus en plusieurs 
chunks diff&#233;rents. En particulier, si un mot a &#233;t&#233; mal &#233;tiquet&#233; par LIA_TAGG, il est fr&#233;quent 
que le chunk correct soit divis&#233; en deux ou trois chunks erron&#233;s, ce que traduit le fort taux 
d&#8217;insertions. A l&#8217;oppos&#233;, il est extr&#234;mement rare (3 observations sur l&#8217;ensemble du corpus de 
test) que les fronti&#232;res du chunk attendu ne se retrouvent pas dans la segmentation erron&#233;e.  
</p>
<p>Corpus R P F-score I D S 
Int&#233;gral (893 chunks)  85,1% 76,3% 0.805 20,0 % 10,8 % 3,7% 
</p>
<p>Sans erreurs de tagging (816 chunks) 95.3% 92.6% 0.939 n.c. n.c. n.c. 
Tableau 1: Performances du syst&#232;me SECARE sur un corpus de transcriptions manuelles. 
</p>
<p>Il est enfin &#224; remarquer qu&#8217;une partie assez significative des erreurs de LIA_TAGG est due &#224; 
la pr&#233;sence de mots inconnus dans les entit&#233;s nomm&#233;es (patronymes, toponymes, etc.). La 
fr&#233;quence de ces erreurs baissera sensiblement lorsque le LIA livrera un &#233;tiqueteur adapt&#233; &#224; la 
t&#226;che EPAC. Mais on peut d&#233;j&#224; remarquer qu&#8217;une part non n&#233;gligeable de ces erreurs est assez 
facilement mod&#233;lisable. Par exemple, un mot inconnu avec majuscule initiale pr&#233;c&#233;d&#233; d&#8217;un 
pr&#233;nom a toutes les chances d&#8217;&#234;tre un patronyme. Un travail assez rapide d&#8217;ajout de 
transducteurs de post-correction dans la seconde cascade nous a ainsi permis d&#8217;atteindre un F-
score de 0.884 (rappel : 90,7% ; pr&#233;cision 86, 2%) sur le corpus de test complet. 
</p>
<p>On peut &#234;tre &#233;tonn&#233; par notre strat&#233;gie d&#8217;analyse s&#233;quentielle (&#233;tiquetage puis segmentation) 
qui ne peut que cumuler les erreurs, alors qu&#8217;on sait que l&#8217;&#233;tiquetage morphosyntaxique gagne 
&#224; &#234;tre conduit en parall&#232;le avec le chunking (Giguet &amp; Vergne 1997). Cette observation 
demanderait &#224; &#234;tre confirm&#233;e sur de la parole conversationnelle. L&#224; n&#8217;est pas toutefois la 
justification de notre approche, qui d&#233;coule en fait des objectifs du projet EPAC. Celui-ci vise 
&#224; &#233;valuer le gain d&#8217;une r&#233;vision manuelle d&#8217;annotations automatiques par rapport &#224; une 
annotation purement manuelle. A terme, SECARE travaillera donc sur des donn&#233;es r&#233;vis&#233;es 
sans erreurs. Pour d&#8217;autres applications, nous envisageons par contre de coupler annotation et 
segmentation en utilisant le dictionnaire Delas, fourni avec Unitex, &#233;tendu  par la base Prolex 
de noms propres (Tran &amp; Maurel 2006). 
</p>
<p>7 Conclusion et perspectives 
Les performances de SECARE montrent qu&#8217;il est possible de g&#233;n&#233;raliser &#224; la langue g&#233;n&#233;rale 
les techniques de segmentation que nous avions d&#233;velopp&#233;es pour le dialogue homme-
machine. Il reste toutefois &#224; &#233;valuer le syst&#232;me sur des transcriptions automatiques pour 
confirmer cette observation. Dans l&#8217;imm&#233;diat, ces premi&#232;res exp&#233;riences montrent que le 
syst&#232;me est robuste sur des transcriptions exactes de parole spontan&#233;e. Nous allons maintenant 
compl&#233;ter la seconde cascade de transducteurs pour distinguer, parmi les zones inconnues, les 
segments disfluents (reparandum et zone d&#8217;&#233;dition). 
</p>
<p>Remerciements 
Ce projet est financ&#233; par l&#8217;Agence Nationale de la Recherche (projet ANR-06-MDCA-2006). 
Nous remercions Denis Maurel pour son aide sur l&#8217;utilisation du syst&#232;me Unitex. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mokrane, Friburger, Antoine 
</p>
<p>R&#233;f&#233;rences 
ABNEY S. (1991) Parsing by chunks, In. Berwick, Abney, Tenny (Eds.) Principle-based 
parsing. Amsterdam. Kluwer Academic Publ. Dordrecht, Pays-Bas. 
</p>
<p>A&#207;T-MOKHTAR S., CHANOD J.-P., ROUX C. (2003) Robustness beyond shallowness: 
incremental deep parsing, Natural Language Enginerring, Vol. 8 (3-2). 
ANTOINE J.-Y.., GOULIAN J., VILLANEAU J. (2003) Quand le TAL robuste s&#8217;attaque au langage 
parl&#233; : analyse incr&#233;mentale pour la comprehension de la parole spontan&#233;e. TALN&#8217;2003. Batz. 
</p>
<p>BEAR J., DOWDING J., SHRIBERG E. (1992) Integrating multiple knowledge sources for 
detection and correction of repairs in Human-Computer dialogue, Proc. Annual meeting of the 
ACL,  ACL&#8217;92, Newark, Danemark. pp. 56-63. 
</p>
<p>BLANCHE-BENVENISTE C. (1997) Approches de la langue parl&#233;e en fran&#231;ais, Coll. L&#8217;essentiel 
Fran&#231;ais, Ophrys, Paris, France. 
</p>
<p>FRIBURGER N. (2002) Reconnaissance automatique des noms propres; application &#224; la 
classification automatique de textes journalistiques. Th&#232;se de doctorat, U. Fr. Rabelais Tours.  
GALLIANO S., GEOFFROIS E., MOSTEFA D., CHOUKRI K., BONASTRE J.-F., GRAVIER G.(2005) 
The ESTER Phase II Evaluation Campaign for the Rich Transcription of French Broadcast 
News, Actes Eurospeech/Interspeech&#8217;2005, Lisbonne, Portugal. 
</p>
<p>GIGUET E., VERGNE J. (1997) From Part-of-Speech Tagging to Memory-based Deep Syntactic 
Analysis. Proc. IWPT'97, MIT, Boston, Massachussets, USA. 
</p>
<p>GOULIAN J., ANTOINE J.-Y., POIRIER F. (2003) How NLP techniques can improve speech 
understanding Actes Eurospeech&#8217;2003, Gen&#232;ve, Suisse. 2773-2776. 
</p>
<p>HEEMAN P., ALLEN J. (2001) Improving robustness by modelling spontaneous speech events, 
In. Robustness in language and speech technology, Kluwer, Dordrecht, Pays-Bas, pp. 123-
152. 
</p>
<p>HINDLE D. (1983) Deterministic parsing of syntactic nonfluencies. Actes ACL&#8217;83, pp. 123-128 
</p>
<p>TRAN M.,  MAUREL D. (2006), Prolexbase : Un dictionnaire relationnel multilingue de noms 
propres, Traitement automatique des langues, Vol. 47(3), 115-139 
</p>
<p>LECOUTEUX B., LINAR&#200;S G., EST&#200;VE Y., GRAVIER G. (2008), Generalized driven decoding for 
speech recognition system combination, Actes IEEE ICASSP 2008, Las Vegas, Nevada,USA. 
</p>
<p>PAROUBEK P., ROBBA I.,VILNAT A. AYACHE C. (2006) Data Annotations and Measures in 
EASY the Evaluation Campaign for Parsers of French, Actes 5th international Conference on 
Language Resources and Evaluation, LREC 2006, G&#234;nes, Italie, pp.315-320. 
</p>
<p>PAUMIER S. (2003) De la reconnaissance de formes linguistiques &#224; l'analyse syntaxique, Th&#232;se 
de Doctorat, Universit&#233; de Marne-la-Vall&#233;e, France. 
</p>
<p>VAN NOORD G. (1997) Fsa utilities: a toolbox to manipulate finite state automata. In 
Raymond D. et al. (Eds.) Automata Implementation, Springer Verlag, RFA. pp. 87-108. </p>

</div></div>
</body></html>