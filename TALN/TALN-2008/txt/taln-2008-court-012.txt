TALN 2008, Avignon, juin 2008

Cascades de transducteurs pour le chunking de la parole
conversationnelle : l’utilisation de la plateforme CasSys dans le
projet EPAC

Abdenour Mokrane, Nathalie Friburger, J ean—Yves Antoine

Université Francois Rabelais Tours — LI, IUP Blois, France
{prenom.nom} @univ—tours.fr

Résumé — Cet article présente l’utilisation de la plate-forme CasSys pour la segmentation
de la parole conversationnelle (chunking) a l’aide de cascades de transducteurs Unitex. Le
systéme que nous présentons est utilisé dans le cadre du projet ANR EPAC. Ce projet a pour
objectif l’indexation et l’annotation automatique de grands ﬂux de parole issus d’émissions
télévisées ou radiophoniques. Cet article présente tout d’abord l’adaptation a ce type de
données d’un systéme antérieur de chunking (Romus) qui avait été développé pour le dialogue
oral homme-machine. I1 décrit ensuite les principaux problémes qui se posent a l’analyse :
traitement des disﬂuences de l’oral spontané, mais également gestion des erreurs dues aux
étapes antérieures de reconnaissance de la parole et d’étiquetage morphosyntaxique.

Abstract — This paper describes the use of the CasSys platform in order to achieve the
chunking of conversational speech transcripts by means of cascades of Unitex transducers.
Our system is involved in the EPAC project of the French National Agency of Research
(ANR). The aim of this project is to develop robust methods for the annotation of
audio/multimedia document collections which contains conversational speech sequences such
as TV or radio programs. At ﬁrst, this paper presents the adaptation of a former chunking
system (Romus) which was developed in the restricted framework of dedicated spoken man-
machine dialogue. Then, it describes the problems that are arising due to 1) spontaneous
speech disﬂuencies and 2) errors for the previous stages of processing (automatic speech
recognition and POS tagging).

Mots-clés — Traitement Automatique du Langage Parlé (TALP), segmentation, chunks,
parole conversationnelle, transducteurs, Unitex.

Keywords — Spoken Language Processing, chunking, conversational speech, transducers,
Unitex.

Mokrane, F riburger, Antoine

1 Introduction : le projet EPAC

Du fait du développement des technologies de l’information et de la communication, le grand
public et les professionnels ont acces a une masse de données numériques de taille de plus en
plus considérable. Des lors, la question qui se pose est celle de méthodes d’acces efficaces a
l’information. Elle nécessite la mise en place de techniques avancées de recherche
d’information permettant une comprehension fine des requétes et des documents manipulés.
Pour fonctionner, ces techniques requierent une indexation préalable des données qui vont étre
interrogées. Le projet EPAC vise la réalisation d’outils robustes d’indexation et d’annotation
adaptés a un type particulier de donnée : la parole conversationnelle issue principalement de
ﬂux de données multimédias tels que les émissions radiophoniques ou télévisuelles.

Finance par l’ANR (programme MDCA - Masse de Données), EPAC réunit plusieurs
laboratoires (LIUM, LIA, IRIT, LI) spécialistes du traitement de la parole et du TALN.
Comme l’ont montré les campagnes d’évaluation ARPA Broadcast News pour l’anglais ou
ESTER pour le francais (Galliano et al. 2005), les progres de la reconnaissance de la parole
rendent possible la transcription automatique de grands ﬂux de données audio ou multimédia.
Centrés sur les joumaux d’information, ces campagnes ont principalement concerné de la
parole préparée ou faiblement spontanée. A l’opposé, le projet EPAC s’intéresse a des ﬂux
multimédias comprenant des séquences de parole conversationnelle caractérisée par une
interactivité élevée et une forte spontanéité. Ce nouveau champ d’application nécessite la mise
en oeuvre d’outils spéciﬁques au niveau du traitement du signal : segmentation en zones de
silence, parole, musique ou jingles, identification des tours de parole et des locuteurs, etc. La
reconnaissance de la parole doit par ailleurs conserver sa robustesse en dépit de la nature
spontanée de l’élocution et de la présence de chevauchements entre locuteurs. Les premiers
résultats obtenus dans le cadre du projet montrent que la transcription automatique de la
parole conversationnelle reste un objectif réaliste (Lecouteux et al. 2008). Au terme du projet,
nous visons la diffusion d’un corpus transcrit d’une durée de 200 heures d’enregistrement.

La segmentation du ﬂux multimédia et la transcription fournissent un corpus orthographique,
accompagné de méta-données, qui est déja utilisable par la recherche d’information. Il est
toutefois intéressant de l’enrichir par différents niveaux d’annotation étudiés dans EPAC :

- Etiquetage morphosyntaxique et parenthesage en segments minimaux des transcriptions,
- Détection et typage des entités nommées, application a l’identiﬁcation du locuteur,

- Détection d’opinion pour chaque tour de parole.

Le laboratoire LI est impliqué dans la tache de détection des entités nommées et celle de la
segmentation en chunks (Chunking) sur laquelle porte cet article. Dans un premier temps, nous
présentons notre démarche qui repose sur l’application de cascades de transducteurs qui
modélisent les chunks. Nous présentons ensuite la plateforme CasSys qui permet l’exécution
de cascades de transducteurs Unitex. On décrit ensuite la mise en oeuvre du chunking sur
CasSys ainsi que des résultats étudiant l’inﬂuence des erreurs d’étiquetage et des disﬂuences.

2 Chunking de la parole conversationnelle : problémes

La segmentation en chunks des énoncés s’est développée en TALN a la suite, notamment, des
travaux de Steven Abney (1991). Cette notion a cependant été identiﬁée bien plus tot en

Cascades de transducteurs pour le Chunking de la parole conversationnelle

linguistique et en psycholinguistique. En premiere approximation, on peut déﬁnir un chunk
comme un groupe syntaxique minimal non récursif. Considérons l’énoncé suivant :

(1) [cette petite phrase]GN [vous explicite]GV [la n0ti0n]GN [de chunk]Gp

11 se decompose en différents chunks : nominal (GN), verbal (GV) ou prépositionnel (GP). La
segmentation illustre le caractere non récursif du GP, qui n’englobe pas de GN. Suivant les
approches considérées, la portée du chunk (granularité) peut cependant etre variable. Dans
tous les cas, le parenthésage en chunks revét plusieurs intérets pour la recherche d’information
dans un ﬂux de parole conversationnelle :

- Centre sur un mot lexical unique, le chunk correspond a une unité Ininimale de sens dans
l’univers du discours, sur laquelle peut reposer la recherche d’information. Ainsi, les
entités nommées correspondent toujours a un ou plusieurs chunks.

- Le chunk est adapté a la parole conversationnelle. Il est en effet le lieu de realisation
privilégié de l’entassement paradigmatique (Blanche-Benveniste, 1997247) mis en jeu par
les répétitions ou les reparations de l’oral spontané. Lorsqu’une disﬂuence a une portée
supérieure au chunk, elle n’affecte en aucune maniere les chunks extérieurs.

Cette derniere remarque est importante, car les disﬂuences orales (hésitations, répétitions,
reparations, incises) cassent souvent la structure syntaxique des énoncés, ce qui rend d’autant
plus difﬁcile leur analyse automatique.

De nombreux systemes de chunking efficaces (Giguet &Vergne 1997) ont été développés
pour le langage écrit. Les disﬂuences de l’oral spontané interdisent toutefois leur application
directe a la parole hautement conversationnelle. C’est ainsi que la communauté parole s’est
toumée, a la suite de (Hindle 1983), vers des approches plus ad-hoc de pré-correction avant
analyse : on détecte des patterns assez simples de reprises, dont le reparandum est ensuite
effacé pour normaliser l’énoncé (Bear et al. 1992 ; Heeman & Allen 2001). Ces techniques
ont donné de bons résultats en detection, mais operent parfois des effacements abusifs. Plus
globalement, l’effacement du reparandum peut gommer une information utile. Considérons
les deux exemples ci-dessous :

(2) Je cherche [un camping pres de la gare]REp [euh n0n]ED un pres de la céte pardon

(3) Barton Fink est [un ﬁlm dense]REp an ﬁlm porte’ par un scenario foisonnant

Dans l’exemple (2), la suppression du reparandum avant la zone d’édition euh non empéche le
calcul de la référence dans l’altération M pres de la cote. L’exemple (3) correspond a une
répétition avec enrichissement lexical. Effacer le reparandum revient a perdre une information
qui n’est en rien corrigée par l’altération qui suit. Les consequences de ces effacements
abusifs peuvent etre importantes. Aussi adoptons nous une démarche non destructive.

3 Chunking incrémental de la parole : cascade de transducteurs

Nous proposons une analyse incrémentale fondée sur la detection d’ilots de certitude : les
chunks non affectés par les disﬂuences. Dans un premier temps, on applique des regles de
segmentation décrivant les structures « légitimes » des chunks. Les zones non segmentées a
l’issue de cette étape sont marquees comme disﬂuentes. Il est alors envisageable d’appliquer
des regles spéciﬁques pour caractériser les différentes parties des disﬂuences (reparandum,

Mokrane, F riburger, Antoine

zone d’edition) sans les effacer. Cette demarche rejoint les principes du TAL robuste, a savoir
(A'1't-Mokhtar et al. 2003) que l’analyse est complete mais superﬁcielle (shallow parsing),
qu’elle est non destructrice (on conserve l’information pour les etapes ulterieures) et suit une
strategie incrementale ou chaque niveau utilise une connaissance qui fait sens par elle-meme
(independance conceptuelle).

Nous avions adopte cette approche dans le systeme ROMUS de comprehension automatique de
la parole (Goulian et al. 2003 ; Antoine et al. 2003). Dans ROMUS, la structure des chunks est
decrite par des expressions regulieres travaillant sur les parties du discours associees aux
mots. Ces expressions sont compilees en transducteurs deterministes a l’aide du toolkit FSA
(Van Noord 1997). Chaque transducteur est utilise en cascade pour introduire dans l’enonce
des marqueurs de delimitation, jusqu’a arriver a une segmentation complete. L’ambigui'te est
geree par une heuristique de maximisation des segments construits. Ces principes sont repris
par le systeme SECARE que nous avons realise pour EPAC, avec trois particularites
supplementaires :

- le champ d’application de SECARE n’est plus le dialogue oral homme-machine ﬁnalise
mais la langue generale. Il n’est donc plus possible de s’appuyer sur une connaissance
pragmatique pour resoudre la caracterisation finale des zones disﬂuentes,

- alors que ROMUS travaillait sur de la parole transcrite, SECARE operera sur les sorties
reelles de la reconnaissance de la parole, foumies par les laboratoires LIA ou LIUM,

- Les cascades de transducteurs ne sont plus implantees sur le toolkit Fsa, mais sur la
plateforme CasSys/Unitex. L’interét d’Unitex est de foumir une representation explicite
de la structure des chunks, qui peut donc étre manipulee par des linguistes non
informaticiens.

4 CasSys / Unitex

CasSys est un systeme de cascade de transducteurs, developpe au LI, utilisant des outils
proposes par Unitex (Paumier 2003). La cascade est une suite de transducteurs, au format
Unitex, passes dans un ordre precis afin par exemple d'extraire ou de remplacer des motifs, ou
encore d'enrichir le texte avec un balisage XML (Friburger. 2002).

Sous Unitex, les transducteurs sont representes par des graphes (figure 1) facilement lisibles.
Le fonctionnement interne "simplifie" d’Unitex est le suivant. Unitex memorise dans un
ﬁchier tous les motifs localises et leur emplacement dans le texte analyse. Puis si on demande
une concordance, Unitex transforme le texte en fonction du mode choisi : en mode
remplacement, il remplace les entrees du transducteur par ses sorties, alors qu’en mode fusion,
il fusionne les entrees et sorties.

—[)—| sous la direction del>—[)—| Vonl>—| Karajan 

<person> </perso n>

Figure 1: Un exemple de transducteur Unitex

CasSys ajoute a Unitex la possibilite d'extraire un motif du texte (ce motif etant enrichi des
eventuelles sorties du transducteur) pour le memoriser dans un fichier tandis qu'on le remplace
dans le texte par une etiquette qui permettra de le retrouver plus tard. Suivant les principes de
l’analyse en cascade, les transducteurs sont donc passes de sorte qu'on reconnaisse en premier

Cascades de transducteurs pour le chunking de la parole conversationnelle

les motifs les moins ambigus; ceux ci sont supprimes du texte et par la suite ne risquent pas
d'etre confondus avec un motif reconnu par un autre transducteur.

A titre d’illustration, le graphe represente dans la ﬁgure 1 reconnait exclusivement la phrase
« sous la direction de von Karajan ». On applique ce transducteur sur le texte suivant (4) pour
obtenir apres application la sequence (4’):

(4) Le concert a lieu, sous la direction de von Karajan, en Baviere.
(4’) Le concert a lieu, sous la direction de <$exempleI.'0$>, en Baviere.

Les entrees reconnues et les sorties du transducteur sont fusionnees pour donner la sequence
<person> von Karajan </person> qui est extraite du texte et placee dans un index a la
position 0. On peut choisir que seule la partie reconnue entre les balises <person> et
</person> soit extraite du texte, dans ce cas la sequence sous la direction de est toujours dans
le texte. L'etiquette <$exemple1.'0$> inseree dans le texte indique quel est le graphe qui a
reconnu cette sequence (exemplel) et permet de retrouver la sequence correspondante dans le
ﬁchier index (position 0). A la ﬁn de la cascade, les motifs extraits sont replaces dans le texte:

(4”) Le concert a lieu, sous la direction de <person> von Karajan </person>, en Baviere.

5 Implantation des cascades de transducteurs

5.1 Formats de données : segmentation PEAS

Un des resultats attendus du projet EPAC est la mise a disposition d’un grand corpus de
parole conversationnelle transcrite et annotee. La reutilisabilite de cette ressource est favorisee
par la normalisation des formats d’encodage, qui utilisent tous XML. Les transcriptions
suivent le format .trs Transcriber. Afin d’ajouter des couches d’annotations independantes sur
les transcriptions, nous avons defini une reference temporelle de synchronisation qui se base
sur une segmentation des transcriptions en tokens. Cette reference s’inspire du format utilise
dans le projet europeen LUNA (www.ist-luna.eu/).

La segmentation en chunks repose sur le format PEAS utilise lors de la campagne de test
EASy (Paroubek et al. 2006). Le choix de PEAS releve de notre volonte de normalisation. Il
peut etre considere en effet comme un format d’echange accepte par l’ensemble de la
communaute francophone. Issu de difﬁciles compromis, PEAS a conduit a une simplification
extreme de la portee des chunks. Par exemple, la sequence de mots tres tres haut y est annotee
comme la suite de deux groupes adverbiaux (GR) suivi d’un groupe adjectival (GA) alors
qu’il est clair que les adverbes de degres dependent de l’adjectif qu’ils qualiﬁent. PEAS rend
compte de ces dependances par des relations entre chunks. Il nous semble toutefois regrettable
d’identiﬁer des dependances aussi locales et, par exemple, la relation de sous-categorisation
entre un predicat verbal et ses arguments. Nous ne nous interdisons pas de regrouper en
interne certains types de chunks pour accroitre leur portee. Mais les donnees qui seront
diffusees suivront la norme PEAS, a laquelle nous avons apporte deux complements :

- Categories speciﬁques aux disﬂuences orales, qui avaient pas ete etudiees dans EASy et
donc par PEAS, qui est plus centre sur l’ecrit : REP (reparandum) et ED (zone d’edition),

- Categories specifiques pour assurer un parenthesage complet de l’enonce. Par exemple,
ajout d’un chunk COO pour representer les conjonctions de coordination. La coordination

Mokrane, F riburger, Antoine

est représentée dans PEAS par une relation de dépendance. I1 nous semble plus justifié de
lui accorder le statut de chunk, a la fois pour atteindre une segmentation complete, mais
également parce que les coordinations peuvent contenir des disﬂuences orales complexes.

Pour rappel, PEAS distingue a la base les chunks suivants : NV (noyau verbal), PV (groupe
verbal infinitif introduit par une préposition), GN (groupe nominal), GP (groupe
prépositionnel), GA (groupe adjectival sans les adjectifs antéposés) et GR (groupe adverbial).

5.2 Implantation des cascades sur CasSys / Unitex

Comme nous l’avons vu (cf. § 3), la segmentation est basée sur une cascade de transducteurs
qui identifie dans une premiere passe les chunks qui ont une structure normée, suivant une
stratégie par ilots de conﬁance. Ce n’est que dans un second temps que l’on s’intéresse aux
zones non identifiées, aﬁn de réaliser une segmentation complete des énoncés. A l’heure
actuelle, seules des transcriptions manuelles de parole conversationnelle ont été diffusées aux
partenaires du projet EPAC. Dans l’attente de la réception de transcriptions automatiques, et
compte tenu de l’inﬂuence centrale des erreurs de reconnaissance sur la robustesse des
systemes, nous avons choisi de n’implémenter intégralement que la premiere cascade et d’en
étudier les limites. La seconde passe se limite a la caractérisation des catégories
complémentaires aux annotations PEAS, tel que le chunk COO et le chunk PONCT (pour la
ponctuation). Elle attribue enﬁn l’étiquette CHINC (chunk inconnu) aux zones non encore
segmentées. Ces séquences seront par la suite analysées, soit pour caractériser les disﬂuences,
soit pour corriger des erreurs de reconnaissance ou d’étiquetage morphosyntaxique. La chaine
globale de traitement est illustrée dans la ﬁgure 2.

Annotation l 2
PV, NV, GP, GN, GA, GR

9
Cascade de
transducteurs : passe l

_ _ segmentation en
transcriptions ----------------------- - - _, Analyse Ct
, ' . _> chunks
+ etlquettes P05 T» Segmentation en chunks interprétation (ﬂux XML)

Cascade de
transducteurs : passe 2

9

CasSys /
Unitex

 

Annotation 2 2
CHINC, REP, ED

Figure 2: chaine de traitements pour le chunking

L’analyse repose sur la definition d’un transducteur par type de chunk (GN, NV, etc.). A
chaque chunk est associé un transducteur principal qui décrit sa structure syntaxique et une
série de transducteurs intermédiaires dédiés a la reconnaissance des mots avec leurs tags et a
la gestion des ﬂux XML. Au final, la séquence de mots étiquetés ci-dessous :

<word id="s0034_w0001" token="s0034_t0005" pos="AINDMP"> tous_les </word>
<word id="s0034_w0002" token="s0034_t0007" pos="NMP"> jours </word>

permet la génération, via la plate forme CasSys, du chunk GN suivant, également en XML :

<chunk token_deb="s0034_t0005" word_deb="s0034_w0001"
token_fin="s0034_t0007" word_fin="s0034_w0002" id="s0034_c"> GN </chunk>

Cascades de transducteurs pour le chunking de la parole conversationnelle

Nous avons également ré-implémenté certains automates prédéﬁnis sous Unitex, tel que
l’automate <MOT>, ceci afin de supporter certaines disﬂuences (amorces de mots inachevés,
par exemple). La base d’identiﬁcation des chunks de la premiere passe est composée de 386
transducteurs. La figure 3 donne un exemple de transducteur principal associé au chunk GN.

  
    
 

 
   
  
     
   
  

btp Ds1\cletFp1
hip EIS 1 \nietFsl
btp Ds1\c1etmp1
btpDs1\o1etmsl
btp Ds1\cl.i.ntfp1
lJtpus1\d.i.nlfsl
btp Ds1\o1.i.m.mp1

    
  
 

btpos2\afp2
btpos2\afs2
lJtpns2\amp2
_ btpos2\ams2

" btp 0 s2\ai.no1fp2
btpos2\ai.mlfs2

   
  

I btpos2\aclv2 I

  
    
   
 
 

   

 
    
    
   
 
   

btpos3\nfp3
btpus3\nfs3
btpos3\nmp3
btpos3\nms3
btpos3\chJ.f3

     

   
   

  
  
 

   
  
  

   
  
  
  
 
 
 
  

 
  
  
  
  

  
   
 
   
  
  

btposlwmtrnsl lJtpUs2\ai.mirnp2
btpDs1\chif‘1 btpos2\ai.m1ms2
btposnnfpl btpos2\chiﬂ
btpos1\nfsl btpDs1\afp1
btposl\nmp1 btpus1\afsl
btpns1\nms1 btpDs1\amp1
btpos1\chi.f'1 btpDs1\amsl b1_ch\_mksg\gn2
btpDs1\ainclfp1
b‘F°51‘I°1°°‘°JfP1 btpDsl\aimiFsl
btpnsl\ppulJJfs1 mpnsnajndmpl
btposnppablmpl btpDsl\amd.ms1
btpos1\ppabJmsl btpnsnchjﬂ

     

btp 0 s1\pinclFp1
htp El sl\pimiFsl
btp 0 s1\pino1mp1
btpos1\pmd.msl

btposlbtpayfpl

   
 

  

D

lJ1.I:hur1ksl\gnl

  
 

  
  
 
 

   
  

   
  

btpos1\xpa}rFs1
lJLpnsl\xpaymp1
btposlhcpaymsl

btpus3\)cFaIrd]3
lJl.pDS3\)(‘pI‘Ef3
b1.pDs3\xprem3

   
  
 

  
 

 
 
 

bt.pos1\xsoc1
btpos1\xvi.l.le1

  
  
  
  

 
   

btposl\x:fami11
lJT.pDSl\X‘pt‘Bﬂ
btpasl\xprem1

btpas2\x:famiJ2
btpas2\xpref2
btpos2\xprern2

  

btpos1\JcFami11
btposlbcpreﬂ
btpasﬂxpreml

>9

btp 0 s3\xp ayfp3

htp 0 s3\xp a}rFs3
btposluletfpl btpos3\xpaymp3
btpasluletfsl btpos3\xpayms3
btposl\cletrnp1 btpos3\xsoc:3
btposlhzletmsl htpns3\xvi].le3
btpo s 1 \o1i.ntEp1
btpo s l \dmtfs1
btpo s 1 \cli.ntmp1
btpo s1\di.ntms1
btposl\chil"1

Figure 3: Transducteur principal associé au chunk GN

L’ordre d’application des transducteurs dans la cascade est essentiel, puisqu’il permet de gérer
les ambigu'1'tés d’analyse, notamment pour les chunks qui se recouvrent. On comprend ainsi
aisément que le transducteur GP doit étre appliqué avant celui du GN. Un transducteur
intermédiaire GNpourGP permet par contre d’appeler la recherche de motifs de type GN une
fois passée la préposition (ﬁgure 4). Il en Va de méme pour PV par rapport a NV. Au ﬁnal, la
premiere cascade suit l’ordre PV puis NV, GP, GN, GA, et GR. L’application de NV avant

GN est rendue nécessaire par l’inclusion potentielle de

GN pronominaux dans les noyaux

verbaux (pronoms personnels sujets ou clitiques). De méme, les GN peuvent inclure des
adjectifs antéposés, GA doit donc étre appliqué apres GN dans la cascade. Dans la seconde
passe, l’ordre est le suivant: PONCT, COO, puis CHINC. Appliqué en demier, le transducteur
CHINC (segments inconnus) servira ultérieurement a l’analyse fine des disﬂuences.

btp os1\prepdu1
btp os1\prepdes1
btp os1\prepaux1
btp os1\prepau1
btp os1\prepacle1
btp os1\prep1

 

bt.chunks2\gp2

  

Figure 4: Exemple de cas de chunks en recouvrement : transducteur GP

A titre d’exemple, le chunk CHINC ci-dessous est dﬁ a une non reconnaissance (MOTINC :
mot hors vocabulaire) de noms propres par le tagueur LIA_TAGG1 du laboratoire LIA. Nous

revenons sur ce probleme dans le paragraphe suivant.

1 LIA_TAGG : http://old.lia.uniV-avignon.fr/chercheurs/bechet/download_fred.htm1

Mokrane, F riburger, Antoine

<word id="s0O02_wO003" token="sO002_t0O05" pos="MOTINC"> Miroslav </word>
<word id="s0O02_wO0O4" token="sO002_t0007" pos="MOTINC"> Marcelli </word>
<chunk token_deb="s0002_t00O5" word_deb="s0O02_wO0O3"

token_fin="s0002_t00O7" word_fin="s0O02_wO004" id="s0002_c">CHINC</chunk>

6 Résultats

Le systeme SECARE a été évalué sur les transcriptions manuelles déja réalisées dans le cadre
d’EPAC. Il n’est pas inutile de rappeler que ni EASy ni la premiere campagne d’évaluation
ESTER ne se sont intéressées au chunking de la parole conversationnelle. Il n’existe donc pas
de résultats de référence en la matiere. Les tests ont été effectués sur un extrait d’éInission
radiophonique a forte interactivité, regroupant 893 chunks. Les transcriptions ont été annotées
en partie du discours par l’étiqueteur LIA_TAGG. Ces annotations comportent un certain taux
d’erreurs, puisque LIA_TAGG n’a pas encore été adapté a la tache EPAC.

SECARE a un comportement robuste en présence de disﬂuences. Les réparations ne créent pas
de faux positifs et n’induisent pas d’erreurs dans la délimitation des chunks réguliers. Come
on pouvait s’y attendre, les erreurs de tagging ont par contre une inﬂuence directe sur les
performances du systeme. Ainsi, les mots inconnus de LIA_TAGG peuvent fausser la
délimitation des chunks. Considérons l’exemple suivant :

(5) sortie LIA_TAGG) [le]DETMs [livre]NMs [de]pREp_ADE [Pierre]XpREM [Péan]MoT1Nc
segmentation [le livre]GN [de Pierre]Gp [Pe’an]cH1Nc

LIA_TAGG ne connait pas le patronyme Péan qui est étiqueté comme mot inconnu. SECARE
ne peut alors identiﬁer le rattachement de ce dernier au groupe prépositionnel. Cette situation
est particulierement pénalisante dans le cas des entités nommées.

Dans l’exemple ci-dessous (6), ce n’est pas la répétition du déterminant «une» qui trompe le
systeme, mais le fait que sa seconde occurrence est étiquetée par erreur comme un adjectif :

(6) sortie LIA_TAGG [d ’]pREp_ADE [une]DETFs [une]A1:s [ge’ne’rati0n]N1:s
segmentation [d ’une une ge’ne’rati0n]Gp

Au ﬁnal, on récupere un faux positif équivalent structurellement au chunk «d ’une belle
ge’ne’rati0n» alors que SECARE aurait normalement bien détecté la présence d’une disﬂuence.

Ces observations se retrouvent d’un point de vue quantitatif. Nous avons utilisé plusieurs
métriques detest, aﬁn de caractériser aussi bien les erreurs de typage que de délimitation :

- Rappel (R), précision (P) et F-score de la segmentation,

- Les taux d’insertion (I), suppression (D) et substitution (S) quantifient mieux les erreurs
de délimitation de chunks. Si un GP attendu est scindé en un GR et un GN, trois erreurs
vont étre imputées au systeme : la suppression du GP et l’insertion du GR et du GN.

Le tableau 1 présente les performances de SECARE sur l’ensemble du corpus et sur les chunks
dans lesquels le LIA_TAGG n’a pas fait d’erreur d’étiquetage. Pour information, 9,4% des
chunks étudiés présentaient au moins un mot avec une partie du discours erronée. Ces
résultats suggerent que nos transducteurs sont robustes. Si le F-score n’est globalement que de
0.805, les segmentations erronées sont majoritairement dues aux erreurs d’étiquetage
morphosyntaxique. En effet, le F-score approche 0.94 sur les chunks sans erreur d’étiquetage.

Cascades de transducteurs pour le chunking de la parole conversationnelle

La plupart des erreurs du systeme correspond au découpage des chunks attendus en plusieurs
chunks différents. En particulier, si un mot a été mal étiqueté par LIA_TAGG, il est frequent
que le chunk correct soit divisé en deux ou trois chunks erronés, ce que traduit le fort taux
d’insertions. A l’opposé, il est extrémement rare (3 observations sur l’ensemble du corpus de
test) que les frontieres du chunk attendu ne se retrouvent pas dans la segmentation erronée.

Corpus R P F-score I D S
Intégral (893 chunks) 85,1% 76,3% 0.805 20,0 % 10,8 % 3,7%
Sans erreurs de tagging (816 chunks) 95.3% 92.6% 0.939 n.c. n.c. n.c.

Tableau 1: Performances du systeme SECARE sur un corpus de transcriptions manuelles.

Il est enfin a remarquer qu’une partie assez significative des erreurs de LIA_TAGG est due a
la présence de mots inconnus dans les entités nommées (patronymes, toponymes, etc.). La
fréquence de ces erreurs baissera sensiblement lorsque le LIA livrera un étiqueteur adapté a la
tache EPAC. Mais on peut déja remarquer qu’une part non négligeable de ces erreurs est assez
facilement modélisable. Par exemple, un mot inconnu avec majuscule initiale précédé d’un
prénom a toutes les chances d’étre un patronyme. Un travail assez rapide d’ajout de
transducteurs de post-correction dans la seconde cascade nous a ainsi permis d’atteindre un F-
score de 0.884 (rappel : 90,7% ; precision 86, 2%) sur le corpus de test complet.

On peut étre étonné par notre stratégie d’analyse séquentielle (étiquetage puis segmentation)
qui ne peut que cumuler les erreurs, alors qu’on sait que l’étiquetage morphosyntaxique gagne
a étre conduit en parallele avec le chunking (Giguet & Vergne 1997). Cette observation
demanderait a étre confirmée sur de la parole conversationnelle. La n’est pas toutefois la
justiﬁcation de notre approche, qui découle en fait des objectifs du projet EPAC. Celui-ci vise
a évaluer le gain d’une révision manuelle d’annotations automatiques par rapport a une
annotation purement manuelle. A terme, SECARE travaillera donc sur des données révisées
sans erreurs. Pour d’autres applications, nous envisageons par contre de coupler annotation et
segmentation en utilisant le dictionnaire Delas, foumi avec Unitex, étendu par la base Prolex
de noms propres (Tran & Maurel 2006).

7 Conclusion et perspectives

Les performances de SECARE montrent qu’il est possible de généraliser a la langue générale
les techniques de segmentation que nous avions développées pour le dialogue homme-
machine. 11 reste toutefois a évaluer le systeme sur des transcriptions automatiques pour
confirmer cette observation. Dans l’immédiat, ces premieres experiences montrent que le
systeme est robuste sur des transcriptions exactes de parole spontanée. Nous allons maintenant
compléter la seconde cascade de transducteurs pour distinguer, parmi les zones inconnues, les
segments disﬂuents (reparandum et zone d’édition).

Remerciements

Ce projet est financé par l’Agence Nationale de la Recherche (projet ANR-06-MDCA-2006).
Nous remercions Denis Maurel pour son aide sur l’utilisation du systeme Unitex.

Mokrane, F riburger, Antoine

Références

ABNEY S. (1991) Parsing by chunks, In. Berwick, Abney, Tenny (Eds.) Principle-based
parsing. Amsterdam. Kluwer Academic Publ. Dordrecht, Pays-Bas.

AIT-MOKHTAR S., CHANOD J.-P., ROUX C. (2003) Robustness beyond shallowness:
incremental deep parsing, Natural Language Enginerring, Vol. 8 (3-2).

ANTOINE J .-Y.., GOULIAN J ., VILLANEAU J . (2003) Quand le TAL robuste s’attaque au langage
parlé : analyse incrémentale pour la comprehension de la parole spontanée. TALN’2003. Batz.

BEAR J ., DOWDING J ., SHRIBERG E. (1992) Integrating multiple knowledge sources for
detection and correction of repairs in Human-Computer dialogue, Proc. Annual meeting of the
ACL, ACL’92, Newark, Danemark. pp. 56-63.

BLANCHE-BENVENISTE C. (1997) Approches de la langue parlée en francais, Coll. L’essentiel
Francais, Ophrys, Paris, France.

FRIBURGER N. (2002) Reconnaissance automatique des noms propres; application a la
classification automatique de textes journalistiques. These de doctorat, U. Fr. Rabelais Tours.

GALLIANO S., GEOFFROIS E., MOSTEFA D., CHOUKRI K., BONASTRE J GRAVIER G.(2005)
The ESTER Phase II Evaluation Campaign for the Rich Transcription of French Broadcast
News, Actes Eurospeech/Interspeech’2005, Lisbonne, Portugal.

GIGUET E., VERGNE J . (1997) From Part-of-Speech Tagging to Memory-based Deep Syntactic
Analysis. Proc. IWPT'97, MIT, Boston, Massachussets, USA.

GOULIAN J ., ANTOINE J .-Y., POIRIER F. (2003) How NLP techniques can improve speech
understanding Actes Eurospeech’2003, Geneve, Suisse. 2773-2776.

HEEMAN P., ALLEN J . (2001) Improving robustness by modelling spontaneous speech events,
In. Robustness in language and speech technology, Kluwer, Dordrecht, Pays-Bas, pp. 123-
152.

HINDLE D. (1983) Deterministic parsing of syntactic nonﬂuencies. Actes ACL’83, pp. 123-128

TRAN M., MAUREL D. (2006), Prolexbase : Un dictionnaire relationnel multilingue de noms
propres, Traitement automatique des langues, Vol. 47(3), 115-139

LECOUTEUX B., LINARES G., ESTEVE Y., GRAVIER G. (2008), Generalized driven decoding for
speech recognition system combination, Actes IEEE I CASSP 2008, Las Vegas, Nevada,USA.

PAROUBEK P., ROBBA I.,VILNAT A. AYACHE C. (2006) Data Annotations and Measures in
EASY the Evaluation Campaign for Parsers of French, Actes 5th international Conference on
Language Resources and Evaluation, LREC 2006, Genes, Italie, pp.315-320.

PAUMIER S. (2003) De la reconnaissance de formes linguistiques a l'analyse syntaxique, These
de Doctorat, Université de Marne-la-Vallée, France.

VAN NOORD G. (1997) Fsa utilities: a toolbox to manipulate finite state automata. In
Raymond D. et al. (Eds.) Automata Implementation, Springer Verlag, RFA. pp. 87-108.

