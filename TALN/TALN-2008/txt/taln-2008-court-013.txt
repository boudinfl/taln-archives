TALN 2008, Avignon, 9-13 juin 2008

Regroupement automatique de documents en classes
événementielles

Aurélien Bossard Thierry Poibeau
LIPN - UMR 7030
CNRS - Université Paris 13

F-93430 Villetaneuse, France
{prenom.nom}@lipn.univ—parisl3.fr

Résumé. Cet article porte sur le regroupement automatique de documents sur une base
événementielle. Apres avoir précisé la notion d’événement, nous nous intéressons a la repre-
sentation des documents d’un corpus de dépeches, puis a une approche d’apprentissage pour
réaliser les regroupements de maniere non supervisée fondée sur k-means. Enﬁn, nous évaluons
le systeme de regroupement de documents sur un corpus de taille réduite et nous discutons de
l’évaluation quantitative de ce type de tache.

Abstract. This paper analyses the problem of automatic document clustering based on
events. We ﬁrst specify the notion of event. Then, we detail the document modelling method
and the learning approach for document clustering based on k-means. We ﬁnally evaluate our
document clustering system on a small corpus and discuss the quantitative evaluation for this
kind of task.

M0tS-CléS I Regroupement de documents, Suivi d’événement.

Keywords: Document clustering, Event tracking.

1 Introduction

La veille est devenue un enjeu majeur pour les entreprises, qu’il s’agisse de veille technique ou
scientiﬁque, commerciale ou stratégique. Les « veilleurs » manipulent des masses de données
de plus en plus importantes et ont besoin d’aides automatiques aﬁn d’explorer au mieux ces
données. Dans cet esprit, de nouvelles perspectives de recherche ont vu le jour aﬁn de faciliter
l’acces a un contenu noyé dans un ﬂot d’informations trop important. C’est notamment le cas
des taches de detection et de suivi d’événement (en anglais topic detection and tracking — TDT).

La detection et le suivi d’ événement consistent a regrouper dans une meme classe les documents
qui traitent d’un meme événement. A titre d’eXemple, deux dépeches ayant pour titre « Arrivée
en France de Laurent Gbagbo en vue d’une table ronde a Marcoussis » et « Ouverture des
négociations entre rebelles et gouvemement ivoirien a Marcoussis » se rapportent a un meme
événement : « La Table ronde de Marcoussis ». La notion d’événement est cependant une notion
vague, qu’il nous appartiendra de préciser au cours de cet article.

On distingue deux cadres applicatifs aux taches de detection et de suivi d’événement : le cadre
« en ligne » et le cadre « hors ligne ». Dans le premier cas, des documents arrivent les uns a

Aurélien Bossard, Thierry Poibeau

la suite des autres, et les systemes Inis en oeuvre pour traiter la détection d’événement doivent
tenir compte de la spéciﬁcité des ﬂux d’informations continus. Dans le deuxieme cas, les do-
cuments a traiter sont déja tous présents, et la détection d’événement consiste alors a regrouper
les documents dans différentes classes qui correspondent chacune a un événement différent.

Nous présentons dans cet article nos travaux sur l’aide a l’analyse de corpus et la détection
hors ligne d’événements, c’est-a-dire le regroupement non supervisé de documents selon les
événements dont ils traitent. Nous nous fondons pour cela sur une analyse automatique des
entités nommées, pour esquisser des liens entre documents. Cette analyse n’étant pas sufﬁsante,
nous étudions plusieurs techniques permettant de pondérer les différents types d’entités lors
de l’étape de regroupement automatique (classiﬁcation). Ces techniques permettent d’obtenir
des « paquets » de documents homogenes du point de vue de l’événement traité, ainsi qu’une
visualisation du fonds documentaire dans son ensemble, sous forme d’un réseau social.

Apres avoir présenté un état de l’art des technique de détection hors ligne d’événements, nous
essayons de Inieux caractériser la notion d’événement avant de présenter notre systeme de dé-
tection automatique. Nous détaillons ensuite la facon dont les documents sont caractérisés, puis
l’algorithme de classiﬁcation. Enﬁn, nous présentons l’évaluation de notre systeme sur un cor-
pus de dépéches AFP.

2 Etat de l’art

La détection d’événements permet de suivre en direct des ﬂux de dépéches et de les classer en
fonction du theme traité. Nous nous intéressons ici a la détection d’événements hors ligne. Ce
theme a été moins traité que la détection en ligne mais il est important, au moins dans deux cas
de ﬁgure bien identiﬁés :

1. les analystes sont souvent confrontés a des masses de documents traitant de plusieurs
themes. Avant d’accéder aux documents pertinents, une structuration du fonds documen-
taire est nécessaire.

2. les systemes automatiques d’extraction d’information nécessitent des masses de docu-
ments homogenes en entrée. Il faut donc les structurer par theme ou par événement avant
de passer a la phase d’extraction proprement dite.

Nous poursuivons ces deux buts a la fois, le but de notre application étant in ﬁne de produire
des syntheses sommaires a partir de masses de documents non structurés. La tache s’apparente
donc a du résumé multi-documents a partir d’un fonds documentaire non homogene en entrée.
La visualisation des données permet en outre a l’analyste de contr6ler le processus de regrou-
pement de documents en ensembles pertinents. Nous ne nous intéressons ici qu’a l’étape de
regroupement des documents.

Plusieurs auteurs ont décrit des systemes liés a la détection d’événements hors ligne. Il s’agit
de (Yang et al., 1999), (Hatzivassiloglou et al., 2000), (Zhiwei Li & Ma, 2005). Les premiers
et les seconds utilisent des algorithmes de classiﬁcation hiérarchique, tandis que les troisiemes
utilisent des modeles probabilistes.

(Hatzivassiloglou et al., 2000) se sont posé la question des données a utiliser pour la détection
d’événements : vaut-il mieux utiliser la totalité des mots/phrases, exclure des mots qui ne sont

Regroupement automatique de documents en classes événementielles

pas catégorisables comme termes uniques (e.g. le Palais, peut étre du Luxembourg, de l’Ely-
sée...), ou ne tenir compte que des noms propres ? Les auteurs arrivent a la conclusion que les
jeux de données avec lesquels ils obtiennent les meilleurs résultats sont ceux prenant en compte
tous les mots sans exception. Ils attribuent cela au fait que les outils d’extraction de termes ou
de noms propres qu’ils utilisent ne sont pas assez robustes pour ce type de tache.

(Yang et al., 1999) proposent une méthode de regroupement de documents o1‘1 chacun des do-
cuments est représenté par une liste de termes pondérés par leur Igfidf (cf. infra, ﬁg. 2). Sur
le programme TDT, en utilisant un algorithme k-means multi-passes, les auteurs arrivent a des
résultats de 61 % et 69 % en précision/rappel.

(Zhiwei Li & Ma, 2005) proposent quant a eux une approche probabiliste pour le regroupe-
ment de documents en utilisant comme représentation d’un document une matrice composée de
quatre vecteurs : les noms de personnes, de lieux, les dates et des mots-clefs. Leur modele pro-
babiliste appliqué a un extrait du corpus du programme TDT4 produit des résultats de l’ordre
de 85 % de précision et 67 % de rappel, en ﬁxant a la main le nombre de classes dans lesquelles
ranger les documents. Sur des jeux de données ne séparant pas les entités nommées des mots-
clefs, les résultats sont inférieurs de 10 %. Les auteurs l’expliquent par le fait que lorqu’elles ne
sont pas distinguées des mots-clefs, les entités nommées se retrouvent noyées dans les données,
alors que ce sont les éléments clés pour la construction d’un modele d’événement.

Les expériences visant a regrouper dynamiquement un ﬂux de documents en ligne utilisent glo-
balement les memes méthodes, a l’instar de (Binsztok et al., 2004) : il s’agit généralement d’ap-
proches probabilistes combinant des sacs de mots et une fenétre temporelle associée a chaque
groupe de documents.

Toutes les approches présentées ici, particulierement (Hatzivassiloglou et al., 2000), utilisent
pour caractériser un document des vocabulaires assez étendus. La taille des données induite par
ce type de caractérisation fait chuter les performances et la vitesse des systemes de classiﬁca-
tion. Par ailleurs, il a été montré dans (Zhiwei Li & Ma, 2005) que la prise en compte de tout
le vocabulaire est moins pertinente que la focalisation sur les seuls éléments clés, notamment
les entités nommées. Celles-ci ont par ailleurs un role déterminant puisque les fondre dans la
masse de données fait chuter les performances.

Enﬁn, par rapport a des approches comme (Zhiwei Li & Ma, 2005), nous souhaitons élaborer
une méthode qui évite d’avoir a préciser a la main a priori le nombre de classes visées. Plu-
sieurs solutions existent pour cela, dont l’utilisation de l’indice de Davies-Bouldin (Davies &
Bouldin, 1979), une mesure permettant de quantiﬁer la validité d’un clustering. Cet indice cor-
respond au rapport des inerties inter et intra-classes. Parmi les autres méthodes de sélection du
nombre de classes, on peut citer l’approche de (Hamerly & Feng, 2006), qui permet d’obtenir
une meilleure mesure de la validité du clustering dans des cas difﬁciles, comme les grandes
dimensions. Dans notre cas, l’indice de Davies-Bouldin semble approprié : nous travaillons sur
des données de taille modeste. Nous projetons d’exaIniner ces autres mesures sur des données
plus volumineuses.

3 Comment caractériser la notion d’événement ?

Si tous les travaux présentés dans l’état de l’art obtiennent des résultats satisfaisants, aucun n’a
tenté de décrire formellement ce qu’est un événement. Donner une déﬁnition d’un tel concept

Aurelien Bossard, Thierry Poibeau

est certes difﬁcile, mais nous avons cependant considere qu’il etait necessaire de caracteriser un
evenement, ne serait-ce que pour rendre plus objective l’evaluation.

Nous avons explore differentes deﬁnitions d’un evenement, notamment d’un point de vue so-
ciologique et d’un point de vue linguistique. D’un point de vue sociologique tout d’abord, l’eve-
nement prend autant de deﬁnitions que de champs disciplinaires dans lesquels il est considere
(Prestini-Christophe, 2006). Il existe cependant des points communs a toutes ces deﬁnitions :

— un evenement est un fait inattendu et correspond a une rupture,
— un fait devient evenement en fonction du monde dans lequel il advient : l’evenement est
subjectif.

D’un point de vue linguistique, Pustejosky a elabore une theorie (Pustejovsky, 2000) dans la-
quelle il fonde sa deﬁnition de l’evenement sur le reperage de structures predicat/arguments et
sur la notion de changement. L’evenement est identiﬁable grace a un prédicat d ’e’ve’nement (i.e.
un verbe qui implique un changement) et une structure argumentale equivalente (c’est-a-dire
une identite referentielle des arguments du predicat, meme si les formes de surface employees
sont differentes). Une implementation de cette theorie necessiterait des connaissances seman-
tiques tres ﬁnes sur les verbes, mais egalement des connaissances sur les differents arguments
possibles.

Etant donne le nombre de deﬁnitions et le peu de formalisation du concept d’evenement, il est
sﬁrement plus judicieux de partir de nos besoins aﬁn de deﬁnir le concept d’evenement dans
le cadre de notre travail. Notre tache consiste a regrouper les documents d’actualite (des de-
peches) qui traitent du meme evenement, aﬁn de realiser une synthese automatique des groupes
crees. On part du principe qu’une depeche traite d’un evenement unique (ceci est generalement
veriﬁe, sauf pour certaines depeches qui retracent tous les faits marquants d’une joumee, ou
le deroulement d’une succession de faits plus ou moins lies entre eux). Les depeches sont en
outre redigees en forme de pyramide inversee : le premier paragraphe doit normalement conte-
nir l’information sur l’evenement brut, les details, commentaires et opinions etant normalement
detailles dans la suite du document.

Il s’agit alors, aﬁn de realiser notre tache, de trouver les traits communs entre les depeches
qui traitent d’un meme evenement. Un evenement consiste en une action realisee par une ou
plusieurs personnes, a une certaine date, dans un certain lieu. Il est donc assez intuitif d’utiliser
ces marqueurs aﬁn de reconnaitre que deux depeches traitent du meme sujet. Nous retrouvons
ici les elements Inis en evidence par (Pustejovsky, 2000) concemant les arguments du predicat.
On peut par ailleurs utiliser des mots clefs, tels que « proces », « elections », « bombardement »,
aﬁn de departager des depeches partageant des entites nommees mais dont le lecteur a l’intuition
qu’ils se rapportent malgre tout a des evenements differents.

Reste a deﬁnir la portee d’un evenement. En d’autres termes, quelle fenetre temporelle doit-on
adopter pour exclure d’un groupe un document qui traite du meme evenement qu’un document
precedent? Contrairement a (Binsztok et al., 2004), nous considerons la notion de portee in-
dependante de toute notion temporelle. Un fait directement lie a un evenement initial peut se
produire longtemps apres le fait initial, comme la reconnaissance de l’innocence d’un homme
vingt ans apres sa condamnation.

Aﬁn d’eviter toute ambigui'te, nous appellerons dorenavant l’ensemble des depeches regroupees
ensemble, parlant de faits directement lies entre eux, le « sujet », et le fait initial, celui qui aura
conduit a cette succession de faits, l’« evenement ». Les regroupements que nous chercherons
a effectuer seront donc des regroupements par sujet, et non des regroupements par evenement.

Regroupement automatique de documents en classes evénementielles

Cette notion de sujet se rapproche de la notion d’<< activite >> telle que deﬁnie dans TDT4, par
opposition a la notion d’<< événement », toujours dans TDT4.

Malgré cette tentative d’<< objectivisation » des notions d’éVénement et de sujet, ces notions
restent largement subjectives. A titre d’exemple, prenons deux documents : l’un parlant des
elections anticipées en Cote d’Ivoire consécutives aux accords de Marcoussis, l’autre parlant de
la table ronde de Marcoussis. Faut—il créer deux sujets pour ces deux dépéches — l’un concer-
nant la reunion de Marcoussis, l’autre l’application des accords decides a Marcoussis, Voire les
election anticipées — ou les réunir au sein d’un meme sujet concemant les accords de Marcous-
sis, de leur négociation a leur application ? Il y a la une part de subjectivité qui ne peut etre
completement évitée.

4 Modéle de description des documents

Aﬁn de regrouper les documents par sujet, mais également aﬁn d’obtenir une representation gra-
phique qui permette a un utilisateur de prendre rapidement connaissance du contenu d’un fonds
documentaire, celui—ci est représenté a la maniere d’un réseau social (ﬁg 1). Chaque document
a des liens avec les autres documents du corpus. Le poids des liens entre deux documents est
calculé selon les entités nommées qu’ils partagent.

FIG. 1 — Un corpus VU. comme un réseau social : les noeuds sont les documents, leurs forme
et couleur dénotent leur appartenance a une classe, et la couleur des liens est fonction de leur
poids

Nous avons utilise, pour calculer la similarité de contenu entre deux documents, un indice J ac-
card pondéré. L’indice Jaccard est une métrique utilisée en statistique pour comparer la simila-
rite de deux ensembles, fondée sur le rapport entre la cardinalité de l’intersection et la cardinalité
de l’union des ensembles.

Aurélien Bossard, Thierry Poibeau

Chaque ensemble est formé des entités nommées contenues dans chaque document. Aﬁn d’af-
ﬁner l’importance relative des différentes entités, il est nécessaire de les pondérer. En effet,
les corpus privilégient souvent certains themes : certaines entités centrales apparaissent alors
de maniere relativement uniformes et ont de ce fait un pouvoir discriminant tres faible. Leur
participation au calcul de similarité doit étre en conséquence. Pour cela, nous avons testé deux
mesures : la mesure idf et la mesure du t f . idf (Salton & Buckley, 1988) (nous utilisons le
mode de calcul classique de ces deux mesures, cf. ﬁgure 2). Cette pondération permet en outre
de prendre en compte la fréquence d’un terme. Il y a en effet une tres forte probabilité que deux
documents qui contiennent les memes entités nommées avec des fréquences proches fassent
partie d’un meme sujet, et la mesure jaccard pondérée par le t f —idf permet de rendre compte
de ce fait.

Cette pondération selon le t f . idf comme réalisée dans (Yang et al., 1999) ne sufﬁt cependant
pas : certains types d’entités nommées ont un role plus important que d’autres dans la descrip-
tion d’un événement. En effet, les types d’entités les plus instables au sein d’un méme sujet
sont les types « Personnes » et « Organisations ». Si les références aux dates et aux lieux restent
globalement inchangées dans le suivi d’un sujet, les intervenants sont en revanche multiples et
variables. Il faut donc distinguer les entités suivant leur type aﬁn d’éviter la création de sujets
distincts correspondant a chaque intervenant. Nous avons alors affecté un poids a chaque type
d’entités nommées, en privilégiant les lieux et les dates par rapport aux noms de personnes et
d’organisations. Le calcul de la similarité entre documents est celui de la ﬁgure 3, le t f . idf
d’une entité pouvant étre remplacé par 1’ idf .

5 Classiﬁcation

Nous réalisons un regroupement des documents en utilisant l’ algorithme k-means (Forgy, 1965).
Cet algorithme réalise une classiﬁcation en k classes, en Ininimisant la variance intra-classe.
L’ algorithme se déroule en 4 étapes :

1. Choisir aléatoirement k objets qui seront les centres de k classes;

2. Parcourir tous les objets, et les affecter ou les réaffecter a la classe qui minimise la dis-
tance entre l’objet et le centre de la classe;

3. Calculer les barycentres de chaque classe, ils deviennent les nouveaux centres;

Calcul du tf d’un terme ti dans le document dj :
_ l!‘-ilj
 1 Z:k=0 

 

Calcul de l’ idf d’un terme t,- au sein d’un corpus D de documents dj :
idfti =log 

3- 1 J
Calcul du t f . idf du terme t,- pour un document dj :
tf.ldfti,dj 2 tfthdj X 

FIG. 2 — Calcul du tf . idf

Regroupement automatique de documents en classes événementielles

N11(i, j) = :p0ids(e;,) X t f.idf (ek) , ou les ek sont les entités nommées présentes dans i et j.

k=0
7:.

N1o(i,j) = :p0ids(e;,) >< tf.idf(e;,) , ou les ek sont les EN présentes seulement dans i.

k=0
7:.

N01(z',j) = :p0ids(e;,) >< tf.idf(e;,) , ou les ek sont les EN présentes seulement dansj.
k=0

FIG. 3 — Calcul de la mesure de similarité entre documents

4. Répéter les étapes 2 et 3 jusqu’a convergence. La convergence est atteinte lorsque les
classes deviennent stables.

L’ algorithme k-means prend comme parametre le nombre de classes (k). Dans le cadre du re-
groupement non-supervisé de documents, il est nécessaire de laisser ce parametre libre, et de
trouver le meilleur k possible. Aﬁn d’automatiser la recherche du meilleur parametre k, l’algo-
rithme k-means est appliqué n fois en incrémentant k a chaque fois. Finalement, le parametre
k minimisant l’indice de Davies-Bouldin (Davies & Bouldin, 1979) est retenu (cet indice per-
met de calculer la validité de la classiﬁcation, en mesurant la cohérence des regroupements;
les regroupements qui minimisent la distance entre objets de la méme classe et maximisent la
distance entre objets de classes différentes ont le meilleur indice).

6 Evaluation

Nous avons choisi d’évaluer le travail de classiﬁcation par un ensemble de mesures quantita-
tives. Une évaluation qualitative des résultats reste a mener.

6.1 Description du cadre applicatif

Cette recherche s’inscrit dans le cadre du projet Infomagic, du pole de compétitivité Cap Di-
gitall. Ce cadre nous permet d’avoir acces a des besoins opérationnels précis et a des corpus
variés.

Un de ces corpus largement mis a contribution dans le cadre d’Infomagic est un ensemble de
dépéches AFP portant sur la Cote d’Ivoire. Le corpus compte 15000 documents. L’ annotation
des documents avec les entités nommées nous a été fourni par la société Arisem (partenaire du
proj et Infomagic). Nous avons travaillé sur un extrait du corpus comptant 200 dépéches, aﬁn de
pouvoir évaluer au mieux la classiﬁcation. Ainsi, nous avons fait le choix de réaliser une double
annotation, aﬁn de pouvoir comparer notre approche a deux résultats obtenus manuellement
par des personnes différentes. Le corpus compte 1030 entités nommées différentes. Nous avons

1Cap Digital porte sur l’indexation multimedia. Cette recherche s’insere dans le cadre de l’<< axe texte » du pro-
jet, qui regroupe des entreprises et des laboratoires de recherche en traitement des langues, ainsi que des industriels
ayant des besoins spéciﬁques qui servent de cadres d’application communs.

Aurélien Bossard, Thierry Poibeau

établi un corpus de référence en classant les dépéches par sujet, et obtenu 44 classes avec une
répartition tres inégale.

Nous avons voulu évaluer toutes les étapes de la classiﬁcation, aﬁn d’identiﬁer les faiblesses de
la méthode utilisée. Dans un premier temps, nous avons évalué la qualité de la classiﬁcation en
examinant les résultats de l’algorithme k-means en faisant varier k de 2 a 100, ce qui correspond
a diviser le corpus en un nombre de classes allant de 2 a 100. Dans un second temps, nous avons
évalué le résultat « optimal » de l’apprentissage, qui correspond a la classiﬁcation qui minimise
l’indice de Davies-Bouldin en le comparant au meilleur résultat obtenu sur tous les lancements
de k-means, qualitativement parlant.

6.2 Evaluation globale

Nous avons évalué la pertinence de la classiﬁcation par deux méthodes :

— les micro-moyennes;
— les macro-moyennes.

Ces deux mesures donnent des résultats tres différents : le résultat de la macro-moyenne tient
plus compte des catégories ayant peu de documents pertinents, tandis que le résultat des micro-
moyennes fait plus ressortir les résultats sur les plus grosses classes. Ces deux mesures sont
donc nécessaires pour la bonne interprétation des résultats. La méthode des macro-moyennes
consiste a comparer chaque classe C, du corpus étiqueté automatiquement a la classe du corpus
de référence majoritaire dans C,-. Les deux classiﬁcations comparées doivent avoir le méme
nombre de classes. Nous avons donc ﬁxé k au nombre de classes du corpus de référence. Une
moyenne est effectuée sur les mesures de chaque classe, avec un poids égal pour chaque classe.
La méthode des Inicro-moyennes consiste a fusionner les tables de contingence de toutes les
classes eta calculer les mesures sur la table fusionnée. Nous avons utilisé les mesures classiques
de précision, rappel et F-mesure. La F-Mesure est la moyenne harmonique de la précision et du
rappel, et favorise les systemes qui ont des mesures de rappel et de précision proches.

Précision Rappel F-Mesure
Macro-Moyenne 61.4% 65.3 % 63.2%
Micro-Moyennes 52.3% 55.6% 53.9%

FIG. 4 — Résultats de l’évaluation avec le nombre de classes ﬁxé

Il est intéressant de noter que deux annotateurs humains ont obtenu sur ce meme corpus, des
résultats dont la F-Mesure est a 44%. Les deux annotations différentes se défendent, les résul-
tats de celles-ci dépendant fortement du choix de granularité utilisé par les annotateurs dans
les sujets, et du choix de raccorder certains événements a un sujet ou de créer un novueau su-
jet pour ceux-ci. Ceci pose le probleme de l’évaluation d’une classiﬁcation par des méthodes
quantitatives.

6.3 Sélection du k par l’indice de Davies-Bouldin

Nous avons évalué la sélection du k selon les deux points suivants :
— la difference entre le nombre de classes choisi automatiquement et le nombre de classes du
corpus de référence ;

Regroupement automatique de documents en classes evenementielles

— le rapport entre l’indice de Davies—Bouldin et une mesure d’évaluation de la classiﬁcation.
En moyenne sur 15 lancements de l’algorithme (donc 15 conﬁgurations de depart differentes),
nous avons trouve 37,4 classes contre 44 classes dans le corpus de reference. Le meme corpus
annoté par un deuxieme annotateur contient quant a lui 65 classes, l’annotateur ayant fait des
choix différents concemant les sujets existants. On constate donc une erreur dans le choix au-
tomatique du nombre de classes pouvant aller de 16% a 57%. Cette mesure n’est donc pas asez
signiﬁcative pour évaluer la qualité du choix du nombre de classes. Nous avons évalué la perti-
nence de l’utilisation de l’indice de Davies—Bouldin; la ﬁgure 5 montre l’évolution de l’indice
pour tous les k ainsi qu’une mesure d’évaluation du clustering, qui consiste a considérer tous
les documents lies au sein d’un meme cluster, et Ea effectuer les calculs de precision/rappel sur la
presence/absence des liens du corpus de reference dans le corpus clusterisé automatiquement.

70
65
60
55
50
45
40
35
30
25
20
15
10
5

\ Mesure F-1
\ Davies-Bouldin

 

246811ll1222223333344444555556666677777888889
O2468024680246802468024680246802468024680

FIG. 5 — Indice de Davies—Bouldin et Choix du k

On constate la non—corrélation de l’indice de Davies—Bouldin et le choix d’un nombre de classes
qui maximise la F—mesure. Ceci est en grande partie dﬁ au fait que le découpage du corpus
de reference n’est pas homogene : une des classes contient a elle seule 1/6 des documents
du corpus. Or, le choix d’un k par Davies—Bouldin et la classiﬁcation des documents par k-
means seront optimaux dans le cas ou les classes ont toutes approximativement le meme nombre
d’objets.

7 Conclusion

Nous avons présenté dans cet article un systeme de regroupement de dépéches, fondé sur les
entités nommées partagées entre documents. Les résultats obtenus suite Ea la classiﬁcation auto-
matique sont superieurs Ea ceux obtenus par des annotateurs humains.

L’ evaluation quantitative devrait Ea l’avenir étre complétée par une evaluation qualitative. En ef-
fet, les systemes d’evaluation quantitative ne permettent pas de valider l’utilisabilité des resul-
tats : la separation d’une classe en deux par un algorithme peut faire chuter le rappel de 50%. Les
résultats obtenus automatiquement sont toutefois intéressants et peuvent faire ressortir d’autres
regroupements que ceux choisis par les auteurs du corpus de reference, le regroupement de
documents étant tres subjectif.

Aurélien Bossard, Thierry Poibeau

L’ algorithme utilisé pour la classiﬁcation, k-means, n’est pas exempt de défauts : moins efﬁcace
sur des données a regrouper dans des classes non-homogenes, il devient également moins per-
formant sur des corpus de grande dimension. Pour passer a l’échelle supérieure, il nous faudra
donc explorer d’autres méthodes de classiﬁcation, comme les SVM et les cartes de Kohonen
non supervisées.

Remerciements

Ces recherches sont en partie ﬁnancées a travers le projet Infomagic de Pole de compétitivité
Cap Digital. Nous remercions en particulier la société Arisem qui nous a fourni l’annotation des
entités nommées.

Références

BINSZTOK H., ARTIERES T. & GALLINARI P. (2004). Un modele probabiliste de detection
en ligne de nouvel evénement. In Reconnaissance des Formes et Intelligence Artiﬁcielle (RFIA
2004), Toulouse, France.

DAVIES D. L. & BOULDIN D. W. (1979). A cluster separation measure. In IEEE Trans. on
Pattern Analysis and Machine Intelligence, p. 224-227.

FORGY E. (1965). Cluster analysis of multivariate data : Efﬁciency vs. interpretability of
classiﬁcations. Biometrics, p. 21-768.

HAMERLY G. & FENG Y. (2006). Pg-means : learning the number of clusters in data. In The
Twentieth Annual Conference on Neural Information processing systems, Vancouver, Canada.

HATZIVASSILOGLOU V., GRAvANo L. & MAGANTI A. (2000). An investigation of linguistic
features and clustering algorithms for topical document clustering. In SIGIR 2000 .' Procee-
dings of the 23rd Annual International ACM SIGIR Conference on Research and Development
in Information Retrieval, p. 224-231, Athens, Greece : ACM.

PRESTINI-CHRISTOPHE M. (2006). La notion d’evénement dans différents champs discipli-
naires. Pense’e Plurielle, 13, 21-29.

PUSTEJOVSKY J. (2000). Events and the semantics of opposition. In C. TENNY & J. PUS-
TEJ OVS KY, Eds., Events as Grammatical Objects, chapter 13, p. 445-482. CSLI Publications.

SALTON G. & BUCKLEY C. (1988). Term-weighting approaches in automatic text retrieval.
Information Processing and Management .' an International Journal, 24, 513-523.

YANG Y., CARBONEL J. G., BROWN R. D., PIERCE T. & BRIAN T. ARCHIBALD X. L.
(1999). Learning approaches for detecting and tracking news events. In IEEE Intelligent
Systems, p. 32-43, Cambridge, Massachusetts.

ZHIWEI LI, BIN WANG M. L. & MA W.-Y. (2005). A probabilistic model for retrospective
news event detection. In SIGIR 2005 .' Proceedings of the 28th Annual International ACM

SIGIR Conference on Research and Development in Information Retrieval, Salvador, Brazil :
ACM.

