<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Appariement d&#8217;entit&#233;s nomm&#233;es cor&#233;f&#233;rentes : combinaisons de mesures de similarit&#233; par apprentissage supervis&#233;</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2008, Avignon, 9&#8211;13 juin 2008
</p>
<p>Appariement d&#8217;entit&#233;s nomm&#233;es cor&#233;f&#233;rentes : combinaisons
de mesures de similarit&#233; par apprentissage supervis&#233;
</p>
<p>Erwan Moreau1 Fran&#231;ois Yvon2 Olivier Capp&#233;1
(1) Institut T&#233;l&#233;com ParisTech &amp; LTCI CNRS
</p>
<p>(2) Univ. Paris Sud &amp; LIMSI CNRS
emoreau@enst.fr, yvon@limsi.fr, cappe@enst.fr
</p>
<p>R&#233;sum&#233;. L&#8217;appariement d&#8217;entit&#233;s nomm&#233;es consiste &#224; regrouper les diff&#233;rentes formes
sous lesquelles appara&#238;t une entit&#233;. Pour cela, des mesures de similarit&#233; textuelle sont g&#233;n&#233;ra-
lement utilis&#233;es. Nous proposons de combiner plusieurs mesures afin d&#8217;am&#233;liorer les perfor-
mances de la t&#226;che d&#8217;appariement. &#192; l&#8217;aide d&#8217;exp&#233;riences men&#233;es sur deux corpus, nous mon-
trons la pertinence de l&#8217;apprentissage supervis&#233; dans ce but, particuli&#232;rement avec l&#8217;algorithme
C4.5.
</p>
<p>Abstract. Matching named entities consists in grouping the different forms under which
an entity may occur. Textual similarity measures are the usual tools for this task. We propose
to combine several measures in order to improve the performance. We show the relevance of
supervised learning in this objective through experiences with two corpora, especially in the
case of the C4.5 algorithm.
</p>
<p>Mots-cl&#233;s : Entit&#233;s nomm&#233;es, Appariement, Mesures de similarit&#233; textuelle, Apprentis-
sage supervis&#233;.
</p>
<p>Keywords: Named entities, Matching, Textual similarity measures, Supervised learning.
</p>
<p>1 Introduction
</p>
<p>La capacit&#233; &#224; structurer de grandes quantit&#233;s d&#8217;informations provenant de sources diff&#233;rentes
est un enjeu technologique essentiel, et cette capacit&#233; r&#233;side notamment dans la possibilit&#233; de
classer l&#8217;information par entit&#233;. Pour am&#233;liorer la recherche d&#8217;information, il est donc n&#233;cessaire
de savoir reconna&#238;tre la m&#234;me entit&#233; lorsqu&#8217;elle appara&#238;t sous des formes diff&#233;rentes.
</p>
<p>Nous traitons dans cet article du probl&#232;me de l&#8217;identification de s&#233;quences de mots repr&#233;sentant
une m&#234;me entit&#233; nomm&#233;e (EN), dans un cadre o&#249; l&#8217;on dispose des entit&#233;s elles-m&#234;me et du
contexte dans lequel elles apparaissent. La difficult&#233; porte sur les nombreuses variations tex-
tuelles possibles d&#8217;une EN : ces variations peuvent &#234;tre volontaires et/ou naturelles (&#233;criture
diff&#233;rente selon la langue, abr&#233;viations ou extensions, surnoms, etc.) ou involontaires (erreurs
typographiques ou orthographique, erreurs d&#8217;OCR, etc.). On s&#8217;int&#233;resse ici particuli&#232;rement aux
variations dues aux translitt&#233;rations (traductions entre syst&#232;mes d&#8217;&#233;criture diff&#233;rents). L&#8217;hypo-
th&#232;se de d&#233;part r&#233;side donc dans l&#8217;id&#233;e qu&#8217;un m&#234;me r&#233;f&#233;rent conduit g&#233;n&#233;ralement &#224; des formes
&#8220;similaires&#8221;, ainsi qu&#8217;&#224; des ressemblances de leurs contextes d&#8217;occurrence.
</p>
<p>L&#8217;appariement d&#8217;entit&#233;s nomm&#233;es cor&#233;f&#233;rentes est notamment &#233;tudi&#233; dans la probl&#233;matique du</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Erwan Moreau, Fran&#231;ois Yvon, Olivier Capp&#233;
</p>
<p>liage d&#8217;enregistrements (record linkage), qui consiste &#224; rep&#233;rer deux enregistrements distincts
repr&#233;sentant le m&#234;me &#233;l&#233;ment dans une base de donn&#233;es (pour la d&#233;duplication) ou dans deux
bases diff&#233;rentes (fusion de bases) (Winkler, 1999; Bilenko et al., 2003). Certains travaux, tels
que (Cohen et al., 2003; Christen, 2006), &#233;tudient plus sp&#233;cifiquement l&#8217;appariement de noms
de personnes. Dans (Freeman et al., 2006), les probl&#232;mes de translitt&#233;ration sp&#233;cifiques &#224; la
question de l&#8217;appariement sont trait&#233;s dans le cas particulier anglais/arabe, tandis que dans
(Pouliquen et al., 2006) les auteurs pr&#233;sentent un syst&#232;me d&#8217;appariement multilingue.
Les mesures de similarit&#233; (ou de distance) textuelle sont les principaux outils utilis&#233;s pour ce
type de t&#226;che. On peut grossi&#232;rement classer les diff&#233;rents types de mesures existants en trois
classes :
&#8211; les m&#233;thodes bas&#233;es sur les s&#233;quences de caract&#232;res, qui d&#233;finissent la similarit&#233; par la pr&#233;-
</p>
<p>sence de caract&#232;res identiques &#224; des positions similaires (e.g. Levenshtein, Jaro).
&#8211; les m&#233;thodes de type &#8220;sac de mots&#8221;, qui sont bas&#233;es sur le nombre de mots en commun entre
</p>
<p>les deux cha&#238;nes, ind&#233;pendamment de leur position. Notons que ces types de mesures sont
&#233;galement applicables aux n-grammes de caract&#232;res au lieu des mots.
</p>
<p>&#8211; les m&#233;thodes hybrides, qui combinent les caract&#233;ristiques des deux pr&#233;c&#233;dents types de me-
sures.
</p>
<p>Notre objectif est de combiner diff&#233;rentes mesures de similarit&#233; de fa&#231;on &#224; am&#233;liorer la qua-
lit&#233; de l&#8217;appariemment d&#8217;entit&#233;s. Dans cette optique, nous proposons de tirer profit aussi des
similitudes &#233;ventuelles entre les contextes des entit&#233;s, cette technique &#233;tant d&#233;j&#224; utilis&#233;e pour
le probl&#232;me connexe de la d&#233;sambiguisation d&#8217;homonymes, notamment dans (Pedersen &amp; Kul-
karni, 2007). La combinaison de plusieurs mesures est utilis&#233;e dans (Pouliquen et al., 2006),
o&#249; celle-ci consiste en une simple moyenne sur trois mesures. L&#8217;apprentissage supervis&#233; per-
met une prise en compte plus fine des caract&#233;ristiques des mesures et des donn&#233;es, comme le
montrent (Bilenko &amp; Mooney, 2003) &#224; l&#8217;aide de l&#8217;algorithme SVM dans le cadre des bases de
donn&#233;es. &#192; l&#8217;inverse, nous proposons ici d&#8217;appliquer diff&#233;rentes m&#233;thodes d&#8217;apprentissage dans
le cas de donn&#233;es issus de textes non structur&#233;s : dans ce contexte, on ne dispose pas de l&#8217;in-
formation apport&#233;e par les diff&#233;rents champs d&#8217;un enregistrement, mais seulement du contexte
dans lequel sont trouv&#233;es les EN.
</p>
<p>Notre approche privil&#233;gie la robustesse de l&#8217;appariement, au sens o&#249; nous proposons de r&#233;aliser
cette t&#226;che sur tout type d&#8217;EN, ind&#233;pendamment de ressources externes (e.g. dictionnaires de
noms, heuristiques sp&#233;cifiques &#224; un domaine, etc.), et autant que possible sans distinction de
langue. &#192; ce titre nous travaillons sur des donn&#233;es potentiellement bruit&#233;es. En effet, dans le
contexte d&#8217;applications r&#233;elles, cette t&#226;che d&#233;pend de nombreuses phases en amont : la qualit&#233;
du corpus d&#8217;origine, celle de l&#8217;extraction de sites web ainsi que celle de la phase de recon-
naissance des EN. Notre but n&#8217;est donc pas d&#8217;obtenir les meilleurs r&#233;sultats possibles sur des
donn&#233;es sp&#233;cifiques (objectif requ&#233;rant un travail d&#8217;expertise pr&#233;cis et co&#251;teux), mais plut&#244;t des
performances satisfaisantes facilement reproductibles sur diff&#233;rents types de donn&#233;es.
</p>
<p>Nous pr&#233;senterons dans un premier temps les donn&#233;es dont nous disposons et les principales
mesures de similarit&#233; utilis&#233;es dans le syst&#232;me que nous avons impl&#233;ment&#233;. Nous exposerons
ensuite notre approche face aux sp&#233;cificit&#233;s du probl&#232;me, et enfin nous pr&#233;senterons les exp&#233;-
riences r&#233;alis&#233;es et les r&#233;sultats obtenus.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Appariement d&#8217;entit&#233;s nomm&#233;es cor&#233;f&#233;rentes par apprentissage supervis&#233;
</p>
<p>2 Donn&#233;es et outils
</p>
<p>2.1 Corpus
</p>
<p>Le premier corpus (qui sera not&#233; MNI par la suite), en anglais, est constitu&#233; d&#8217;un recueil d&#8217;ar-
ticles de presse, de d&#233;p&#234;ches et de rapports officiels de provenance vari&#233;e consacr&#233;s &#224; la me-
nace nucl&#233;aire en Iran. Celui-ci provient du site www.nti.org1, dont nous utilisons la partie
traitant de l&#8217;Iran (pour la p&#233;riode 1991-2006) parce qu&#8217;elle contient de nombreux cas de trans-
litt&#233;rations de noms arabes. Ce corpus compte 236 000 mots, et la reconnaissance des EN a &#233;t&#233;
r&#233;alis&#233;e &#224; l&#8217;aide de l&#8217;outil GATE2. Nous conservons seulement les noms de personnes, d&#8217;orga-
nisations et de lieux dans l&#8217;ensemble des EN ainsi constitu&#233;. Nous obtenons ainsi 35 000 EN
(en nombre d&#8217;occurrences), contenant toutefois quelques erreurs de reconnaissance : principa-
lement des cas de balisage erron&#233; (entit&#233; tronqu&#233;e ou mots superflus inclus dans l&#8217;entit&#233;) et de
noms communs commen&#231;ant par une majuscule. Nous travaillons sur les EN de fr&#233;quence su-
p&#233;rieure ou &#233;gale &#224; 2, ce qui restreint &#224; 1588 le nombre d&#8217;entit&#233;s distinctes (repr&#233;sentant 33 147
occurrences).
Le second corpus (not&#233; MIF par la suite), long de 856 000 mots, est le r&#233;sultat de l&#8217;aspiration du
contenu de 20 sites web de m&#233;dias d&#8217;information francophones. Ces m&#233;dias ont &#233;t&#233; s&#233;lectionn&#233;s
selon les crit&#232;res suivants : volume suffisant, facilit&#233; d&#8217;acc&#232;s et surtout diversit&#233; g&#233;ographique,
de fa&#231;on &#224; maximiser les chances d&#8217;y trouver des translitt&#233;rations (c&#8217;est pourquoi nous avons
notamment int&#233;gr&#233; une part non n&#233;gligeable de m&#233;dias d&#8217;Afrique du Nord). L&#8217;extraction a &#233;t&#233;
r&#233;alis&#233;e durant 4 jours en juillet 2007 par Pertimm3. Le corpus ainsi obtenu a ensuite &#233;t&#233; trait&#233;
par Arisem4 pour la phase d&#8217;extraction des entit&#233;s : 34 000 occurrences d&#8217;EN ont &#233;t&#233; reconnues
comme noms de personnes, organisations ou lieux, parmi lesquelles on trouve encore quelques
erreurs (principalement des noms communs). De m&#234;me que pour le corpus MNI, on restreint
l&#8217;ensemble des entit&#233;s trait&#233;es &#224; celles apparaissant au moins deux fois : on d&#233;nombre alors
3278 entit&#233;s, correspondant &#224; 23725 occurrences.
</p>
<p>Rappelons que notre t&#226;che est centr&#233;e sur l&#8217;appariement et non la reconnaissance des EN, ce qui
signifie qu&#8217;on admet l&#8217;hypoth&#232;se que l&#8217;extraction des EN (en amont) est globalement &#8220;correcte&#8221;.
Nous n&#8217;avons pas cherch&#233; &#224; corriger les erreurs de cette phase, puisque cela contredirait notre
objectif de robustesse vis-&#224;-vis des donn&#233;es disponibles.
</p>
<p>2.2 Mesures de similarit&#233;s
</p>
<p>Nous pr&#233;sentons ci-dessous quelques-unes des principales mesures fr&#233;quemment utilis&#233;es pour
l&#8217;appariement d&#8217;EN (Christen, 2006; Cohen et al., 2003; Bilenko et al., 2003).
La distance d&#8217;&#233;dition de Levenshtein (et variantes). Cette mesure de distance d repr&#233;sente le
nombre minimal d&#8217;insertions, suppressions ou substitutions n&#233;cessaires pour transformer une
cha&#238;ne x en une cha&#238;ne y. Exemple : d(kitten, sitting) = 3 (k 7&#8594; s, e 7&#8594; i, &#949; 7&#8594; g). La
similarit&#233; s(x, y) normalis&#233;e sur [0, 1], est d&#233;finie par s = 1&#8722; d/max(|x|, |y|).
</p>
<p>1Nuclear Threat Initiative, qui recense par pays toutes les donn&#233;es disponibles li&#233;es au risque nucl&#233;aire.
2http ://gate.ac.uk
3www.pertimm.com
4www.arisem.com</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Erwan Moreau, Fran&#231;ois Yvon, Olivier Capp&#233;
</p>
<p>La m&#233;trique de Jaro. Cette mesure est bas&#233;e sur le nombre et l&#8217;ordre des caract&#232;res communs
entre deux cha&#238;nes. &#201;tant donn&#233;es deux cha&#238;nes x = a1 . . . an et y = b1 . . . bm, soit H =
min(n, m)/2 : un caract&#232;re ai de x est en commun avec y s&#8217;il existe bj dans y tel que ai = bj
et i &#8722; H &#8804; j &#8804; i + H . Soit x&#8242; = a&#8242;
</p>
<p>1
. . . a&#8242;n&#8242; (respectivement y&#8242; = b&#8242;1 . . . b&#8242;m&#8242;) la s&#233;quence de
</p>
<p>caract&#232;res de x (resp. y) en commun avec y (resp. x), dans l&#8217;ordre o&#249; les caract&#232;res apparaissent
dans x (resp. y). Toute position i telle que a&#8242;i 6= b&#8242;i est appel&#233;e une transposition. Soit T le
nombre de transpositions entre x&#8242; et y&#8242; divis&#233; par 2, la mesure de similarit&#233; de Jaro est d&#233;finie5
</p>
<p>par : Jaro(x, y) = 1
3
&#215;
</p>
<p>(
|x&#8242;|
</p>
<p>|x|
+
|y&#8242;|
</p>
<p>|y|
+
|y&#8242;| &#8722; T
</p>
<p>|y&#8242;|
</p>
<p>)
.
</p>
<p>Les mesures de type &#8220;sac de mots&#8221; ou &#8220;de n-grammes de caract&#232;res&#8221;. Pour ces mesures, chaque
entit&#233; est trait&#233;e comme un ensemble d&#8217;&#233;l&#233;ments (les mots ou les n-grammes). Soient X =
{xi}1&#8804;i&#8804;n et Y = {yi}1&#8804;i&#8804;m les ensembles repr&#233;sentant les EN x, y &#224; comparer. Les mesures
les plus simples ne prennent en compte que le nombre d&#8217;&#233;l&#233;ments en commun6, par exemple :
</p>
<p>Jaccard(x, y) =
|X &#8745; Y |
</p>
<p>|X &#8746; Y |
; Overlap(x, y) =
</p>
<p>|X &#8745; Y |
</p>
<p>min(|X|, |Y |)
; Cos(x, y) =
</p>
<p>|X &#8745; Y |&#8730;
|X|
</p>
<p>&#8730;
|Y |
</p>
<p>Certaines mesures plus &#233;labor&#233;es s&#8217;appuient sur une repr&#233;sentation vectorielle des ensembles
X et Y , qui peut tenir compte de param&#232;tres ext&#233;rieurs aux ensembles eux-m&#234;me. Soient A =
(a1, . . . , a|&#931;|) et B = (b1, . . . , b|&#931;|) ces vecteurs7, la similarit&#233; d&#233;finie par le cosinus de l&#8217;angle
</p>
<p>form&#233; par A et B est fr&#233;quemment utilis&#233;e : cos(A, B) = A
T B
</p>
<p>&#8214;A&#8214; &#215; &#8214;B&#8214;
. La repr&#233;sentation des
</p>
<p>&#233;l&#233;ments par leurs poids TF-IDF (Term Frequency-Inverse Document Frequency) est l&#8217;une des
plus classiques. Il s&#8217;agit dans notre cas de mesurer l&#8217;importance d&#8217;un &#233;l&#233;ment w pour une EN x
parmi un ensemble E d&#8217;entit&#233;s8 :
</p>
<p>tfw,x =
nw,x&#8721;
</p>
<p>w&#8242;&#8712;&#931; nw&#8242;,x
, idfw = log
</p>
<p>|E|
</p>
<p>|{x &#8712; E|w &#8712; x}|
, tfidfw,x = tfw,x &#215; idfw.
</p>
<p>Les combinaisons de mesures. Leur principe est la combinaison des propri&#233;t&#233;s des diff&#233;rents
types de mesures pr&#233;sent&#233;s ci-dessus. Il s&#8217;agit g&#233;n&#233;ralement d&#8217;appliquer une &#8220;sous-mesure&#8221;
sim&#8242; aux mots des deux EN &#224; comparer, puis d&#8217;en d&#233;duire un &#233;ventuel alignement optimal des
EN. Il s&#8217;agit donc d&#8217;appliquer une m&#233;thode de type &#8220;sac de mots&#8221;, mais sans subir la rigidit&#233;
d&#8217;un test d&#8217;identit&#233; entre mots : par exemple, les entit&#233;s &#8221;Director ElBaradei&#8221; et &#8221;Director-
General ElBareidi&#8221; pr&#233;sentent des similarit&#233;s importantes que les mesures &#8220;sac de mots&#8221; clas-
siques ne prennent pas en compte. La sous-mesure doit bien s&#251;r &#234;tre choisie judicieusement.
&#8211; La mesure de Monge-Elkan calcule simplement la moyenne des meilleurs paires de mots
</p>
<p>trouv&#233;s : sim(x, y) = 1
n
</p>
<p>n&#8721;
i=1
</p>
<p>m
max
j=1
</p>
<p>(sim&#8242;(xi, yj))
</p>
<p>&#8211; La mesure Soft-TFIDF propos&#233;e dans (Cohen et al., 2003) est une forme assouplie du co-
sinus sur les vecteurs de poids TF-IDF : grossi&#232;rement, deux mots diff&#233;rents peuvent &#234;tre
consid&#233;r&#233;s comme identiques selon que leur score de sous-mesure d&#233;passe ou non un seuil.
</p>
<p>Enfin, on peut mesurer la similarit&#233; des contextes des EN. On nomme contexte d&#8217;une occurrence
d&#8217;une EN l&#8217;ensemble des n mots qui la suivent et qui la pr&#233;c&#232;dent, et le contexte (global)
d&#8217;une entit&#233; distincte est form&#233; par l&#8217;union des contextes de toutes ses occurrences. De fa&#231;on
</p>
<p>5Il est utile de noter que cette mesure n&#8217;est pas sym&#233;trique. On trouve dans la litt&#233;rature et dans les impl&#233;men-
tations existantes diverses variantes pour contourner ce probl&#232;me.
</p>
<p>6Avec |E| le cardinal de l&#8217;ensemble E.
7
&#931; est l&#8217;ensemble des &#233;l&#233;ments consid&#233;r&#233;s (e.g. tous les mots apparaissant dans au moins une EN).
</p>
<p>8Avec nw,x le nombre d&#8217;occurrences de w dans l&#8217;EN x, et &#931; le vocabulaire.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Appariement d&#8217;entit&#233;s nomm&#233;es cor&#233;f&#233;rentes par apprentissage supervis&#233;
</p>
<p>classique (Pedersen &amp; Kulkarni, 2007), nous calculons l&#8217;ensemble des vecteurs repr&#233;sentant le
contexte de chaque entit&#233;, chaque vecteur contenant les poids TF-IDF des mots de ce contexte.
La similarit&#233; entre les contextes de deux EN est alors le cosinus de leurs vecteurs respectifs.
</p>
<p>3 Approche propos&#233;e
</p>
<p>Nous avons impl&#233;ment&#233; un prototype d&#8217;&#233;valuation de mesures de similarit&#233;s entre EN. &#192; partir
d&#8217;une liste d&#8217;entit&#233;s et de leur contexte, celui-ci calcule le score de similarit&#233; obtenu par chaque
couple d&#8217;EN pour un ensemble pr&#233;d&#233;fini de mesures. 48 mesures sont disponibles, dont une
vingtaine proviennent de deux librairies publiques : SimMetrics9 de S. Chapman et Second-
String10 de W. Cohen, P. Ravikumar et S. Fienberg.
</p>
<p>3.1 Difficult&#233;s pos&#233;es par l&#8217;&#233;tiquetage
</p>
<p>Il est bien entendu n&#233;cessaire de disposer de donn&#233;es &#233;tiquet&#233;es, d&#8217;une part pour pouvoir tester
et comparer les performances des diff&#233;rentes mesures, et d&#8217;autre part pour pratiquer l&#8217;appren-
tissage supervis&#233;. Cependant, la t&#226;che d&#8217;appariement pr&#233;sente certaines sp&#233;cificit&#233;s qui rendent
la phase d&#8217;&#233;tiquetage de donn&#233;es difficile. En effet, nous cherchons &#224; classer des couples d&#8217;EN
comme positifs (cor&#233;f&#233;rence) ou n&#233;gatif (non cor&#233;f&#233;rence). Or pour n entit&#233;s distinctes l&#8217;en-
semble des couples potentiel comprend n &#215; (n &#8722; 1)/2 &#233;l&#233;ments, il serait donc excessivement
co&#251;teux en temps d&#8217;envisager l&#8217;&#233;tiquetage manuel de cet ensemble (pour les valeurs de n &#233;tu-
di&#233;es). Dans de telles circonstances, une technique usuelle consiste &#224; n&#8217;&#233;tiqueter qu&#8217;un sous-
ensemble de couples tir&#233;s al&#233;atoirement. Mais cette alternative n&#8217;est pas envisageable ici, &#224;
cause de la disproportion entre couples positifs et n&#233;gatifs : dans nos donn&#233;es, on ne trouve
respectivement que 0,06% (pour MNI) et 0,02% (pour MIF) de couples positifs.
C&#8217;est pourquoi notre approche vise &#224; extraire de fa&#231;on semi-automatique un ensemble contenant
tous les couples positifs. Seul cet ensemble sera examin&#233; au cours de l&#8217;&#233;tiquetage manuel. Cette
approche repose sur l&#8217;hypoth&#232;se selon laquelle les couples positifs seront jug&#233;s similaires par au
moins une des m&#233;triques ; &#224; l&#8217;inverse, les couples qui ne sont bien class&#233;s par aucune m&#233;trique
sont consid&#233;r&#233;s n&#233;gatifs. Cette m&#233;thodologie n&#8217;est pas sans biais, mais une analyse approfondie
d&#8217;un ensemble d&#8217;entit&#233;s nous a permis de constater que ce biais &#233;tait en r&#233;alit&#233; faible, du fait de
la multiplicit&#233; et de la diversit&#233; des mesures utilis&#233;es.
</p>
<p>Les crit&#232;res d&#8217;&#233;tiquetage manuel ainsi que les m&#233;thodes automatiques de recherche de couples
candidats ont &#233;t&#233; affin&#233;s pour le traitement du corpus MIF, gr&#226;ce &#224; l&#8217;exp&#233;rience acquise avec
le corpus MNI. C&#8217;est pourquoi nous ne d&#233;taillons ci-dessous que la m&#233;thode employ&#233;e sur
MIF, sachant que le changement principal r&#233;side dans une d&#233;finition beaucoup plus stricte de la
cor&#233;f&#233;rence.
</p>
<p>Pour la recherche de couples candidats, notre syst&#232;me propose d&#8217;abord les couples obtenant
les k meilleurs scores selon chaque mesure. Deux autres techniques sont &#233;galement mises en
&#339;uvre : la premi&#232;re consiste &#224; appliquer automatiquement les relations de transitivit&#233; (si les
EN A et B sont cor&#233;f&#233;rentes et que B et C le sont aussi, alors A et C sont cor&#233;f&#233;rentes). La
seconde vise &#224; rep&#233;rer d&#8217;&#233;ventuels couples difficiles &#224; trouver de fa&#231;on globable (par exemple,
</p>
<p>9http://www.dcs.shef.ac.uk/~sam/stringmetrics.html
10http://secondstring.sourceforge.net</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Erwan Moreau, Fran&#231;ois Yvon, Olivier Capp&#233;
</p>
<p>les EN courtes sont d&#233;favoris&#233;es par la majorit&#233; des mesures) : dans ce but, l&#8217;ensemble des EN
est parcouru, en proposant pour chaque EN les n entit&#233;s les plus proches selon m &#8220;bonnes&#8221;
mesures. Les couples sont class&#233;s en trois cat&#233;gories : les positifs (cor&#233;f&#233;rence stricte, au moins
dans le corpus) ; les n&#233;gatifs (non-cor&#233;f&#233;rence stricte) ; les couples incertains (ne pouvant &#234;tre
accept&#233;s comme positifs mais pr&#233;sentant toutefois un lien &#233;troit11). Enfin certaines EN sont
&#233;limin&#233;es (principalement les erreurs de reconnaissance ou les EN mal form&#233;es, mais aussi
quelques cas ambigus).
Par rapport au corpus MNI, plus de temps a &#233;t&#233; consacr&#233; &#224; la recherche de couples cor&#233;f&#233;rents
parmi les entit&#233;s. En particulier, bon nombre d&#8217;acronymes ont &#233;t&#233; appari&#233;s manuellement avec
leur forme &#233;tendue, ainsi que quelques cas tels que &#8220;Quai d&#8217;Orsay&#8221; et &#8220;Minist&#232;re des affaires
&#233;trang&#232;res12. Le parcours d&#8217;appariement local, au cours duquel chaque EN est prise comme
r&#233;f&#233;rence, a permis de rep&#233;rer une douzaine de couples positifs suppl&#233;mentaires parmi environ
30 000. Pour toutes ces raisons, nous pensons que la probabilit&#233; pour un couple positif de n&#8217;avoir
pas &#233;t&#233; &#233;tiquet&#233; est tr&#232;s basse.
</p>
<p>Corpus EN EN &#233;limin&#233;es positifs n&#233;gatifs incertains total
Corpus MNI 1588 0 805 1 877 3 836 1 260 078
Corpus MIF 3278 745 741 32 348 419 3 206 778
</p>
<p>Dans les colonnes 2 et 3 de ce tableau sont repr&#233;sent&#233;s des nombres d&#8217;entit&#233;s, tandis que les suivantes contiennent
des nombres de couples d&#8217;entit&#233;s. Ainsi dans MIF 3278-745 EN repr&#233;sentent 3 206 778 couples, parmi lesquels
33 508 ont &#233;t&#233; &#233;tiquet&#233;s. Pour MNI, aucune EN reconnue n&#8217;avait &#233;t&#233; &#233;limin&#233;e (car la m&#233;thode employ&#233;e pour l&#8217;&#233;ti-
quetage &#233;tait diff&#233;rente), c&#8217;est pourquoi la proportion d&#8217;incertains est si importante (elle reste toutefois n&#233;gligeable
par rapport &#224; l&#8217;ensemble des couples).
</p>
<p>3.2 Apprentissage supervis&#233; : motivations et outils
</p>
<p>Nous d&#233;velopperons dans la partie 4.1 les r&#233;sultats obtenus par les mesures de similarit&#233; test&#233;es.
On peut n&#233;anmoins d&#233;j&#224; d&#233;duire de leurs d&#233;finitions (cf. partie 2.2) qu&#8217;elles ont chacune des
propri&#233;t&#233;s sp&#233;cifiques qui les rendent potentiellement compl&#233;mentaires. Nous pouvons observer
ces diff&#233;rences sur quelques cas positifs non triviaux issus du corpus MIF dans le tableau 3.2.
</p>
<p>Couple Levenshtein TF-IDF mots TF-IDF trigrammes TF-IDF contextes
&quot;Fatah al-Islam&quot; / &quot;Fateh el-Islam&quot; 281 &gt; 3000 686 &gt; 3000
&quot;Mosqu&#233;e Rouge&quot; / &quot;Mosqu&#233;e rouge d&#8217;Islamabad&quot; &gt; 3000 233 449 &gt; 3000
&quot;Omar al-Baghdadi&quot; / &quot;Omar de Bagdad&quot; 887 1802 2318 10
&quot;Recep Tayyip Erdogan&quot; / &quot;Erdogan&quot; &gt; 3000 746 2406 2510
</p>
<p>Les valeurs indiqu&#233;es repr&#233;sentent la position du couple dans la liste tri&#233;e par score d&#233;croissant de chaque me-
sure13 : le couple &quot;Fatah al-Islam&quot; / &quot;Fateh el-Islam&quot; est ainsi class&#233; 281e par la mesure de Levenshtein.
</p>
<p>Ces exemples illustrent le fait qu&#8217;aucune de ces mesures n&#8217;est capable de prendre en compte
tous les types d&#8217;indices permettant de statuer sur l&#8217;&#233;ventuelle cor&#233;f&#233;rence d&#8217;un couple d&#8217;entit&#233;s.
C&#8217;est pourquoi nous proposons d&#8217;utiliser l&#8217;apprentissage supervis&#233; : nous esp&#233;rons ainsi d&#233;ter-
miner une mani&#232;re optimale de combiner les scores obtenus &#224; l&#8217;aide de diff&#233;rentes mesures,
dans le but d&#8217;am&#233;liorer les performances de la t&#226;che d&#8217;appariement d&#8217;EN.
</p>
<p>11Exemples : &#8220;ONU&#8221; et &#8220;Conseil de s&#233;curit&#233; de l&#8217;ONU&#8221;, ou &#8220;Russie&#8221; et &#8220;Gouvernement russe&#8221;.
12Notons que ce type de couple est hors de port&#233;e des mesures de similarit&#233; textuelle.
13Rappelons que ce corpus contient 741 positifs, ce qui signifie qu&#8217;un seuil (choisi de fa&#231;on &#224; garantir une
</p>
<p>pr&#233;cision minimale) sur une seule mesure ne permettrait de conserver au mieux que les 500&#177;100meilleurs scores.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Appariement d&#8217;entit&#233;s nomm&#233;es cor&#233;f&#233;rentes par apprentissage supervis&#233;
</p>
<p>Dans les donn&#233;es fournies &#224; l&#8217;algorithme d&#8217;apprentissage, chaque couple d&#8217;entit&#233;s est repr&#233;-
sent&#233; par un ensemble de param&#232;tres choisis pour leur contribution potentielle &#224; la d&#233;tection
d&#8217;une cor&#233;f&#233;rence. Parmi ces param&#232;tres figurent bien entendu les scores de similarit&#233; obte-
nus avec diff&#233;rentes mesures, mais aussi certaines caract&#233;ristiques du couple d&#8217;EN telles que
leurs longueurs (en nombre de caract&#232;res et de mots) et leurs fr&#233;quences minimales et maxi-
males. Nous utilisons le logiciel Weka (Witten &amp; Frank, 2005) pour r&#233;aliser l&#8217;apprentissage14,
et testons deux m&#233;thodes de classification : La r&#233;gression logistique, qui apprend un s&#233;parateur
lin&#233;aire, et L&#8217;algorithme C4.5 (Quinlan, 1993), qui apprend un arbre de d&#233;cision.
</p>
<p>4 Exp&#233;rimentations et r&#233;sultats
</p>
<p>Conform&#233;ment &#224; l&#8217;approche que nous avons suivie pour l&#8217;&#233;tiquetage des donn&#233;es, les r&#233;sultats15
d&#233;taill&#233;s ci-dessous sont &#233;valu&#233;s sous les hypoth&#232;ses suivantes : tout couple non &#233;tiquet&#233; est
assimil&#233; &#224; un couple n&#233;gatif ; tout couple marqu&#233; comme &#8220;incertain&#8221; est simplement ignor&#233;.
</p>
<p>4.1 Observations g&#233;n&#233;rales
</p>
<p>Tout d&#8217;abord, nous constatons que les mesures se comportent de fa&#231;on similaire sur les deux
corpus. Des diff&#233;rences de performances importantes sont observ&#233;es, mais celles-ci sont prin-
cipalement dues aux crit&#232;res d&#8217;&#233;tiquetage diff&#233;rents (voir partie 3.1).
</p>
<p>FIG. 1 &#8211; Pr&#233;cision et rappel pour 4 mesures de similarit&#233; (corpus MIF)
</p>
<p> 0
</p>
<p> 20
</p>
<p> 40
</p>
<p> 60
</p>
<p> 80
</p>
<p> 100
</p>
<p> 0  500  1000  1500  2000  2500
</p>
<p>Pr
ec
</p>
<p>is
io
</p>
<p>n
</p>
<p>n meilleurs scores
</p>
<p>Jaro
Cosinus TF-IDF mots
</p>
<p>Cosinus TFIDF Trigrammes
Soft TF-IDF
</p>
<p> 0
</p>
<p> 20
</p>
<p> 40
</p>
<p> 60
</p>
<p> 80
</p>
<p> 100
</p>
<p> 0  500  1000  1500  2000  2500
</p>
<p>R
ap
</p>
<p>pe
l
</p>
<p>n meilleurs scores
</p>
<p>Jaro
Cosinus TF-IDF mots
</p>
<p>Cosinus TFIDF Trigrammes
Soft TF-IDF
</p>
<p>Exemple : pour la mesure de Jaro, si le seuil est fix&#233; de telle sorte que les couples obtenant les 500 scores les plus
&#233;lev&#233;s soient class&#233;s positifs, la pr&#233;cision est de 65% et le rappel de 46% (rappel : MIF contient 741 positifs).
</p>
<p>La typologie des ressemblances reconnues par type de mesure laisse appara&#238;tre quelques grandes
lignes : sur les mots simples qui pr&#233;sentent de l&#233;g&#232;res diff&#233;rences textuelles, souvent des noms
de lieux ou de personnes, les mesures de type Levenshtein/Jaro sont performantes. Mais celles-
ci deviennent inadapt&#233;es d&#232;s que plusieurs mots sont pr&#233;sents, ce qui est essentiellement le
cas des noms d&#8217;organisation mais aussi souvent des noms de personnes (e.g. avec/sans pr&#233;-
nom/titre) : les mesures &#8220;sac de mots&#8221; sont alors nettement meilleures (voir table 3.2).
</p>
<p>14Cet outil public propose un ensemble vari&#233; d&#8217;algorithmes d&#8217;apprentissage pr&#234;ts &#224; l&#8217;emploi pour la fouille de
donn&#233;e.
</p>
<p>15L&#8217;apprentissage est r&#233;alis&#233; par validation crois&#233;e en 10 sous-ensembles. Dans tous les cas &#233;tudi&#233;s, le taux
d&#8217;erreur global est tr&#232;s faible (inf&#233;rieur &#224; 0,1%) puisque le taux de couples n&#233;gatifs est tr&#232;s &#233;lev&#233;.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Erwan Moreau, Fran&#231;ois Yvon, Olivier Capp&#233;
</p>
<p>En g&#233;n&#233;ral, les mesures qui obtiennent les meilleures performances sont de type &#8220;sac de mots&#8221;
ou &#8220;sac de n-grammes&#8221;, tandis que les mesures bas&#233;es sur les s&#233;quences de caract&#232;res, moins
souples, ne permettent d&#8217;identifier sans erreur que les couples positifs tr&#232;s proches. Sans sur-
prise, la prise en compte de l&#8217;IDF am&#233;liore assez nettement les r&#233;sultats des mesures de type sac
de mots/n-grammes. Individuellement, la mesure de similarit&#233; des contextes n&#8217;a pas d&#8217;int&#233;r&#234;t16.
</p>
<p>4.2 Apport de l&#8217;apprentissage
</p>
<p>4.2.1 Mesures individuelles
</p>
<p>Dans le tableau 1 sont indiqu&#233;es les performances obtenues par quelques-une des meilleures
mesures individuelles. Celles-ci sont calcul&#233;es selon les deux m&#233;thodes d&#8217;apprentissage, de
fa&#231;on &#224; pouvoir servir de r&#233;f&#233;rence par rapport aux combinaisons de mesures d&#233;crites ci-apr&#232;s.
Dans ce m&#234;me tableau nous &#233;valuons l&#8217;apport des param&#232;tres de longueur/fr&#233;quence des EN. On
peut constater que les r&#233;sultats sont tr&#232;s proches avec les deux m&#233;thodes dans le cas des mesures
seules, tandis que le C4.5 tire beaucoup mieux profit des param&#232;tres de longueur/fr&#233;quence : la
F-mesure va jusqu&#8217;&#224; augmenter de 26 (MNI) ou 15 (MIF) points pour la mesure de Jaro.
</p>
<p>TAB. 1 &#8211; Mesures individuelles avec/sans longueurs et fr&#233;quences (pourcentages)
Corpus MNI Corpus MIF
</p>
<p>Param&#232;tres R&#233;gr. log. C4.5 R&#233;gr. log. C4.5
P R F P R F P R F P R F
</p>
<p>Jaro seule 66,0 25,0 36,2 74,3 17,6 28,5 89,4 40,2 55,4 91,6 38,7 54,4
Jaro + l/f 67,4 34,2 45,3 81,8 42,5 55,9 84,1 43,0 56,9 88,2 57,0 69,2
TF-IDF mots seule 85,6 58,5 69,5 83,3 60,0 69,7 81,9 51,0 62,9 91,5 46,7 61,8
TF-IDF mots + l/f 86,3 58,8 69,9 88,4 63,6 74,0 82,0 50,6 62,6 86,9 48,4 62,2
TF-IDF trigrammes seule 79,5 64,7 71,4 76,0 67,2 71,3 73,1 49,4 58,9 70,7 52,1 60,0
TF-IDF trigrammes + l/f 84,7 71,3 77,4 87,1 68,9 77,0 77,4 55,0 64,3 84,5 62,1 71,6
</p>
<p>P/R/F = Pr&#233;cision/Rappel/F-mesure. &#8220;+ l/f&#8221; signifie &#8220;avec les param&#232;tres de longueurs et fr&#233;quences&#8221;.
Exemple : sur le corpus MNI, l&#8217;apprentissage par C4.5 sur les param&#232;tres constitu&#233;s du score de TF-IDF sur les
mots et des longueurs et fr&#233;quences min. et max. de chaque couple donne un rappel de 63,6%.
</p>
<p>4.2.2 Combinaisons de mesures
</p>
<p>Nous avons test&#233; plusieurs s&#233;lections de mesures comme param&#232;tres de l&#8217;apprentissage. Les
r&#233;sultats de ces exp&#233;rimentations pour deux s&#233;lections de mesures et quelques variantes sont
fournis dans le tableau 2. On constate globalement une nette am&#233;lioration des performances par
rapport au cas des mesures individuelles : en comparant les meilleurs cas des deux situations, le
rappel passe ainsi de 69% &#224; 83% sur le corpus MNI et de 62% &#224; 75% sur le corpus MIF. C&#8217;est
encore une fois l&#8217;algorithme C4.5 qui combine les diff&#233;rents param&#232;tres de fa&#231;on optimale.
</p>
<p>En revanche, la contribution de la mesure de similarit&#233; des contextes, particuli&#232;rement &#233;tudi&#233;e
ici, est quasiment nulle. Cependant, en consid&#233;rant un ensemble restreint de mesures de fa&#231;on
&#224; analyser plus en d&#233;tail cette mesure (tableau 2), on constate un apport faible mais significatif
de celle-ci : l&#8217;algorithme C4.5 en permet un usage positif, puisque la F-mesure gagne 2,7 points
</p>
<p>16Elle n&#8217;atteint jamais les 20% de pr&#233;cision. Pourtant, on observe que ce score est bien repr&#233;sentatif d&#8217;une proxi-
mit&#233; s&#233;mantique, mais celle-ci s&#8217;av&#232;re trop peu pr&#233;cise pour marquer une &#233;ventuelle cor&#233;f&#233;rence (par exemple, on
trouve souvent parmi les bons scores des couples form&#233;s d&#8217;une organisation et du nom de son repr&#233;sentant).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Appariement d&#8217;entit&#233;s nomm&#233;es cor&#233;f&#233;rentes par apprentissage supervis&#233;
</p>
<p>TAB. 2 &#8211; Performances de diff&#233;rentes combinaisons de mesures (pourcentages)
Corpus MNI Corpus MIF
</p>
<p>Param&#232;tres R&#233;gr. log. C4.5 R&#233;gr. log. C4.5
P R F P R F P R F P R F
</p>
<p>A seules 85,9 75,0 80,1 85,1 83,2 84,2 78,7 58,8 67,3 89,7 67,6 77,1
A + l/f 87,2 76,4 81,5 85,2 80,9 83,0 79,0 59,2 67,6 87,3 71,0 78,3
A&#8217; seules 86,2 76,6 81,1 86,3 82,0 84,1 82,9 63,9 72,2 87,1 73,9 80,0
A&#8217; + l/f 87,5 77,4 82,1 84,5 80,5 82,4 82,2 63,8 71,8 85,1 75,2 79,8
B seules 82,9 69,1 75,3 83,1 76,3 79,5 74,4 51,6 60,9 87,2 71,0 78,2
B + l/f 84,9 73,3 78,7 82,5 78,3 80,3 80,5 59,4 68,4 87,0 70,7 78,0
B&#8217; seules 84,4 71,3 77,3 82,1 77,5 79,7 80,7 59,6 68,5 87,5 75,3 81,0
B&#8217; + l/f 86,6 74,2 79,9 83,8 79,3 81,5 81,9 64,0 71,9 85,9 75,4 80,3
</p>
<p>L&#8217;ensemble de mesures A est constitu&#233; des mesures Cosinus (nombre de mots), Jaro, Smith-Waterman-Gotoh, TFIDF mots, TFIDF trigrammes
et Soft-TFIDF. L&#8217;ensemble B est constitu&#233; des mesures Levenshtein, Jaro, TFIDF mots, TFIDF bigrammes, TFIDF trigrammes et une combi-
</p>
<p>naison par couplage de mots bas&#233;e sur Jaro. A&#8217; (resp. B&#8217;) est l&#8217;ensemble A (resp. B) auquel est ajout&#233; le TFIDF sur les contextes.
</p>
<p>dans le cas o&#249; ce param&#232;tre est ajout&#233; &#224; deux autres bonnes mesures. Un gain similaire est
observ&#233; entre l&#8217;une des mesures prise individuellement (tableau 1) et la m&#234;me avec le contexte.
</p>
<p>FIG. 2 &#8211; Influence de la mesure sur les contextes (corpus MIF) (pourcentages)
R&#233;gr. log. C4.5
</p>
<p>Param&#232;tres P R F P R F
TFIDF Trigrammes + Contexte + l/f 80,4 61,6 69,7 81,9 70,8 76,0
TFIDF Mots + Contexte + l/f 85,7 52,0 64,7 83,2 55,2 66,4
TFIDF Trigrammes + TFIDF Mots + l/f 77,4 57,5 66,0 86,0 64,2 73,5
TFIDF Trigrammes + TFIDF Mots + Contexte + l/f 80,5 62,0 70,0 83,1 70,3 76,2
</p>
<p>Le choix des mesures est une question complexe : tout d&#8217;abord, on constate assez naturelle-
ment que plus on fournit de param&#232;tres &#224; l&#8217;algorithme d&#8217;apprentissage, meilleur est le mod&#232;le
qu&#8217;il produit. Ainsi, nous avons test&#233; le C4.5 sur le corpus MNI avec 18 mesures diff&#233;rentes (et
les param&#232;tres de longueur/fr&#233;quence) : ceci permet d&#8217;obtenir jusqu&#8217;&#224; 84,9%/85,0% de pr&#233;ci-
sion/rappel. Toutefois cet apport est limit&#233; : le gain obtenu en combinant les scores de seulement
deux mesures (pertinentes) est important, mais il a tendance &#224; s&#8217;affaiblir avec l&#8217;augmentation
du nombre de mesures. Ceci est d&#251; en partie au fait qu&#8217;une combinaison de mesures n&#8217;a d&#8217;in-
t&#233;r&#234;t que si celles-ci sont compl&#233;mentaires, or on retrouve rapidement des mesures de m&#234;me
type. De plus, dans un cadre d&#8217;utilisation r&#233;elle, les ressources mat&#233;rielles ne permettent pas de
recourir au calcul de dizaines de mesures pour des volumes de donn&#233;es importants. C&#8217;est pour-
quoi il semble judicieux d&#8217;adopter un compromis raisonnable en s&#233;lectionnant de 3 &#224; 5 mesures
compl&#233;mentaires. &#192; ce titre, soulignons que malgr&#233; ses performances assez faibles la mesure
de similarit&#233; des contextes est un bon candidat sur le plan de la compl&#233;mentarit&#233;.
</p>
<p>5 Conclusion et perspectives
</p>
<p>Pour conclure, dans cet article nous avons montr&#233; l&#8217;int&#233;r&#234;t de combiner les scores de diff&#233;-
rentes mesures de similarit&#233; pour l&#8217;appariement d&#8217;EN extraites de textes non structur&#233;s. Les
exp&#233;riences men&#233;es sur deux corpus montrent que l&#8217;apprentissage supervis&#233; permet de telles
combinaisons, et que celles-ci am&#233;liorent de fa&#231;on significative les performances de la t&#226;che
d&#8217;appariement. Pour cet apprentissage, la comparaison de la r&#233;gression logistique et de l&#8217;algo-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Erwan Moreau, Fran&#231;ois Yvon, Olivier Capp&#233;
</p>
<p>rithme C4.5 est nettement en faveur de ce dernier. Dans ce cadre, nous avons &#233;galement &#233;tudi&#233;
l&#8217;apport d&#8217;une mesure de similarit&#233; des contextes, qui semble faible mais non n&#233;gligeable.
</p>
<p>L&#8217;inconv&#233;nient le plus important de cette m&#233;thode est certainement la n&#233;cessit&#233; de donn&#233;es
&#233;tiquet&#233;es, tr&#232;s difficiles et/ou co&#251;teuses &#224; obtenir &#224; cause des sp&#233;cificit&#233;s de cette probl&#233;ma-
tique (nombre de couples potentiels tr&#232;s &#233;lev&#233; et disproportion entre positifs et n&#233;gatifs). C&#8217;est
pourquoi il nous semble pertinent d&#8217;&#233;tudier les possibilit&#233;s d&#8217;apprentissage non-supervis&#233; ou
semi-supervis&#233; (par exemple en s&#233;lectionnant judicieusement les couples &#224; &#233;tiqueter).
</p>
<p>Remerciements
</p>
<p>Ces travaux ont &#233;t&#233; financ&#233;s par le projet Cap Digital - Infom@gic. Nous remercions L. Rigouste
(Pertimm), N. Dessaigne et A. Migeotte (Arisem) pour nous avoir fourni le corpus MIF annot&#233;.
</p>
<p>R&#233;f&#233;rences
BILENKO M. &amp; MOONEY R. J. (2003). Adaptive duplicate detection using learnable string
similarity measures. In P. DOMINGOS, C. FALOUTSOS, T. SENATOR, H. KARGUPTA &amp; L.
GETOOR, Eds., Proceedings of the ninth ACM SIGKDD International Conference on Know-
ledge Discovery and Data Mining (KDD-03), p. 39&#8211;48, New York : ACM Press.
BILENKO M., MOONEY R. J., COHEN W. W., RAVIKUMAR P. &amp; FIENBERG S. E. (2003).
Adaptive name matching in information integration. IEEE Intelligent Systems, 18(5), 16&#8211;23.
CHRISTEN P. (2006). A Comparison of Personal Name Matching : Techniques and Practi-
cal Issues. Rapport interne TR-CS-06-02, Department of Computer Science, The Australian
National University, Canberra 0200 ACT, Australia.
COHEN W. W., RAVIKUMAR P. &amp; FIENBERG S. E. (2003). A comparison of string distance
metrics for name-matching tasks. In S. KAMBHAMPATI &amp; C. A. KNOBLOCK, Eds., Procee-
dings of IJCAI-03 Workshop on Information Integration on the Web (IIWeb-03), August 9-10,
2003, Acapulco, Mexico, p. 73&#8211;78.
FREEMAN A., CONDON S. L. &amp; ACKERMAN C. (2006). Cross linguistic name matching in
English and Arabic. In R. C. MOORE, J. A. BILMES, J. CHU-CARROLL &amp; M. SANDERSON,
Eds., HLT-NAACL : The Association for Computational Linguistics.
PEDERSEN T. &amp; KULKARNI A. (2007). Unsupervised discrimination of person names in Web
contexts. In Proceedings of the Eighth International Conference on Intelligent Text Processing
and Computational Linguistics, Mexico City.
POULIQUEN B., STEINBERGER R., IGNAT C., TEMNIKOVA I., WIDIGER A., ZAGHOUANI
W. &amp; ZIZKA J. (2006). Multilingual person name recognition and transliteration. CORELA -
Cognition, Representation, Langage.
QUINLAN J. R. (1993). C4.5 : Programs for Machine Learning. San Mateo, CA : Morgan
Kaufmann.
WINKLER W. E. (1999). The state of record linkage and current research problems. Rapport
interne RR99/04, US Bureau of the Census.
WITTEN I. H. &amp; FRANK E. (2005). Data Mining : Practical Machine Learning Tools and
Techniques, Second Edition. Morgan Kaufmann.</p>

</div></div>
</body></html>