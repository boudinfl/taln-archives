TALN 2008, Avignon, 9-13 juin 2008

Appariement d’entités nommées coréférentes : combinaisons
de mesures de similarité par apprentissage supervisé

Erwan Moreaul Francois Yvon2 Olivier Cappél
(1) Institut Télécom ParisTech & LTCI CNRS
(2) Univ. Paris Sud & LIMSI CNRS

emoreau @ enst.fr, yvon @ limsi.fr, cappe @ enst.fr

Résumé. L’ appariement d’entités nommées consiste a regrouper les différentes formes
sous lesquelles apparait une entité. Pour cela, des mesures de similarité textuelle sont généra-
lement utilisées. Nous proposons de combiner plusieurs mesures aﬁn d’améliorer les perfor-
mances de la tache d’appariement. A l’aide d’expériences menées sur deux corpus, nous mon-
trons la pertinence de l’apprentissage supervisé dans ce but, particulierement avec l’algorithme
C4.5.

Abstract. Matching named entities consists in grouping the different forms under which
an entity may occur. Textual similarity measures are the usual tools for this task. We propose
to combine several measures in order to improve the performance. We show the relevance of
supervised learning in this objective through experiences with two corpora, especially in the
case of the C4.5 algorithm.

M0tS-CléS I Entités nommées, Appariement, Mesures de similarité textuelle, Apprentis-
sage supervisé.

Keywords: Named entities, Matching, Textual similarity measures, Supervised learning.

1 Introduction

La capacité a structurer de grandes quantités d’informations provenant de sources différentes
est un enjeu technologique essentiel, et cette capacité réside notamment dans la possibilité de
classer l’information par entité. Pour améliorer la recherche d’information, il est donc nécessaire
de savoir reconnaitre la méme entité lorsqu’elle apparait sous des formes différentes.

Nous traitons dans cet article du probleme de l’identiﬁcation de séquences de mots représentant
une méme entité nommée (EN), dans un cadre ou l’on dispose des entités elles-méme et du
contexte dans lequel elles apparaissent. La difﬁculté porte sur les nombreuses variations tex-
tuelles possibles d’une EN : ces variations peuvent étre volontaires et/ou naturelles (écriture
différente selon la langue, abréviations ou extensions, sumoms, etc.) ou involontaires (erreurs
typographiques ou orthographique, erreurs d’OCR, etc.). On s’intéresse ici particulierement aux
variations dues aux translittérations (traductions entre systemes d’écriture différents). L’ hypo-
these de départ réside donc dans l’idée qu’un méme référent conduit généralement a des formes
“similaires”, ainsi qu’a des ressemblances de leurs contextes d’occurrence.

L’ appariement d’entités nommées coréférentes est notamment étudié dans la problématique du

Erwan Moreau, Francois Yvon, Olivier Cappé

liage d’enregistrements (record linkage), qui consiste a repérer deux enregistrements distincts
représentant le meme élément dans une base de données (pour la déduplication) ou dans deux
bases différentes (fusion de bases) (Winkler, 1999; Bilenko et al., 2003). Certains travaux, tels
que (Cohen et al., 2003; Christen, 2006), étudient plus spéciﬁquement l’appariement de noms
de personnes. Dans (Freeman et al., 2006), les problemes de translittération spéciﬁques a la
question de l’appariement sont traités dans le cas particulier anglais/arabe, tandis que dans
(Pouliquen et al., 2006) les auteurs présentent un systeme d’appariement multilingue.

Les mesures de similarité (ou de distance) textuelle sont les principaux outils utilisés pour ce
type de tache. On peut grossierement classer les différents types de mesures existants en trois
classes :

— les méthodes basées sur les séquences de caractéres, qui déﬁnissent la similarité par la pre-
sence de caracteres identiques a des positions similaires (e. g. Levenshtein, J aro).

— les méthodes de type “sac de mots”, qui sont basées sur le nombre de mots en commun entre
les deux chaines, indépendamment de leur position. Notons que ces types de mesures sont
également applicables aux n-grammes de caracteres au lieu des mots.

— les méthodes hybrides, qui combinent les caractéristiques des deux précédents types de me-
sures.

Notre objectif est de combiner différentes mesures de similarité de facon a améliorer la qua-
lité de l’appariemment d’entités. Dans cette optique, nous proposons de tirer proﬁt aussi des
similitudes éventuelles entre les contextes des entités, cette technique étant déja utilisée pour
le probleme connexe de la désambiguisation d’homonymes, notamment dans (Pedersen & Kul-
karni, 2007). La combinaison de plusieurs mesures est utilisée dans (Pouliquen et al., 2006),
ou celle-ci consiste en une simple moyenne sur trois mesures. L’apprentissage supervisé per-
met une prise en compte plus ﬁne des caractéristiques des mesures et des données, comme le
montrent (Bilenko & Mooney, 2003) a l’aide de l’algorithme SVM dans le cadre des bases de
données. A l’inverse, nous proposons ici d’appliquer différentes méthodes d’apprentissage dans
le cas de données issus de textes non structurés : dans ce contexte, on ne dispose pas de l’in-
formation apportée par les différents champs d’un enregistrement, mais seulement du contexte
dans lequel sont trouvées les EN.

Notre approche privilégie la robustesse de l’appariement, au sens ou nous proposons de réaliser
cette tache sur tout type d’EN, indépendamment de ressources extemes (e.g. dictionnaires de
noms, heuristiques spéciﬁques a un domaine, etc.), et autant que possible sans distinction de
langue. A ce titre nous travaillons sur des données potentiellement bruitées. En effet, dans le
contexte d’applications réelles, cette tache dépend de nombreuses phases en amont : la qualité
du corpus d’origine, celle de l’extraction de sites web ainsi que celle de la phase de recon-
naissance des EN. Notre but n’est donc pas d’obtenir les meilleurs résultats possibles sur des
données spéciﬁques (objectif requérant un travail d’expertise précis et coﬁteux), mais plutot des
performances satisfaisantes facilement reproductibles sur différents types de données.

Nous présenterons dans un premier temps les données dont nous disposons et les principales
mesures de similarité utilisées dans le systeme que nous avons implémenté. Nous exposerons
ensuite notre approche face aux spéciﬁcités du probleme, et enﬁn nous présenterons les expe-
riences réalisées et les résultats obtenus.

Appariement d’entités nommées coréférentes par apprentissage supervisé

2 Données et outils

2.1 Corpus

Le premier corpus (qui sera noté MNI par la suite), en anglais, est constitué d’un recueil d’ar-
ticles de presse, de dépéches et de rapports ofﬁciels de provenance variée consacrés a la me-
nace nucléaire en Iran. Celui-ci provient du site www . nt i . orgl, dont nous utilisons la partie
traitant de 1’Iran (pour la période 1991-2006) parce qu’e1le contient de nombreux cas de trans-
littérations de noms arabes. Ce corpus compte 236 000 mots, et la reconnaissance des EN a été
réalisée a 1’aide de 1’outi1 GATE2. Nous conservons seulement les noms de personnes, d’orga-
nisations et de lieux dans 1’ensemb1e des EN ainsi constitué. Nous obtenons ainsi 35 000 EN
(en nombre d’occurrences), contenant toutefois quelques erreurs de reconnaissance : principa-
lement des cas de balisage erroné (entité tronquée ou mots superﬂus inclus dans 1’entité) et de
noms communs commencant par une majuscule. Nous travaillons sur les EN de fréquence su-
périeure ou égale a 2, ce qui restreint a 1588 1e nombre d’entités distinctes (représentant 33 147
occurrences).

Le second corpus (noté MIF par la suite), long de 856 000 mots, est le résultat de 1’aspiration du
contenu de 20 sites web de médias d’information francophones. Ces médias ont été sélectionnés
selon les criteres suivants : volume sufﬁsant, facilité d’acces et surtout diversité géographique,
de facon a maximiser les chances d’y trouver des translittérations (c’est pourquoi nous avons
notamment intégré une part non négligeable de médias d’Afrique du Nord). L’extraction a été
réalisée durant 4 jours en juillet 2007 par Pertimm3. Le corpus ainsi obtenu a ensuite été traité
par Arisem4 pour la phase d’extraction des entités : 34 000 occurrences d’EN ont été reconnues
comme noms de personnes, organisations ou lieux, parmi lesquelles on trouve encore quelques
erreurs (principalement des noms communs). De meme que pour le corpus MNI, on restreint
1’ensemb1e des entités traitées a celles apparaissant au moins deux fois : on dénombre alors
3278 entités, correspondant a 23725 occurrences.

Rappelons que notre tache est centrée sur1’appariement et non la reconnaissance des EN, ce qui
signiﬁe qu’ on admet 1’hypothese que 1’ extraction des EN (en amont) est globalement “correcte”.
Nous n’avons pas cherché a corriger les erreurs de cette phase, puisque cela contredirait notre
objectif de robustesse vis-a-vis des données disponibles.

2.2 Mesures de similarités

Nous présentons ci-dessous quelques-unes des principales mesures fréquemment utilisées pour
1’appariement d’EN (Christen, 2006; Cohen et al., 2003; Bilenko et al., 2003).

La distance d ’e’diti0n de Levenshtein (et variantes). Cette mesure de distance d représente 1e
nombre minimal d’insertions, suppressions ou substitutions nécessaires pour transformer une
chaine :13 en une chaine y. Exemple : d(kitten, sitting) = 3 (k I—> s, e I—> i, 5 I—> g). La
similarité s(a:, y) normalisée sur [0, 1], est déﬁnie par 3 = 1 — d/max(|a:|, 

1Nuclear Threat Initiative, qui recense par pays toutes les données disponibles liées au risque nucléaire.
zhttp ://gate.ac.uk

3www . pert imm . com

4www . arisem . com

Erwan Moreau, Francois Yvon, Olivier Cappé

La métrique de Jaro. Cette mesure est basée sur le nombre et l’ordre des caracteres communs
entre deux chaines. Etant données deux chaines 1: = a1...a,, et y = b1...bm, soit H =
mi11(n, m) / 2 : un caractere a,- de 1: est en commun avec y s’il existe bj dans y tel que a,- = bj
et 1' — H 3 j 3 i + H. Soit 1:’ = a’1 . . . ag, (respectivement y’ = b’1 . . . b;n,) la séquence de
caracteres de 1: (resp. y) en commun avec y (resp. 1:), dans l’ordre ou les caracteres apparaissent
dans :13 (resp. y). Toute position i telle que a; 73 b; est appelée une transposition. Soit T le
nombre de transpositions entre 1:’ et y’ divisé par 2, la mesure de similarité de J aro est déﬁnie5

1 |w’| |y’| |y’|-T
P“"““°‘”‘””‘é*(TNu+ M '

Les mesures de type “sac de mots ” on “de n-grammes de caracteres ”. Pour ces mesures, chaque
entité est traitée comme un ensemble d’éléments (les mots ou les n-grammes). Soient X =
{x,-}1S,-Sn et Y = {y,-}1S,-Sm les ensembles représentant les EN 1:, y a comparer. Les mesures
les plus simples ne prennent en compte que le nombre d’éléments en commun6, par exemple :

X H Y

|XnY|
J d — - , E
 ‘W min(|X|,|Yl) IXI m

‘ |X u Y| ’
Certaines mesures plus élaborées s’appuient sur une représentation vectorielle des ensembles
X et Y, qui peut tenir compte de parametres extérieurs aux ensembles eux-meme. Soient A =
(a1, . . . , algl) et B = (bl, . . . , blgl) ces vecteurs7, la similarité déﬁnie par le cosinus de l’angle
ATB
||A|| >< ||B||'
éléments par leurs poids TF-IDF (Term Frequency-Inverse Document Frequency) est l’une des
plus classiques. Il s’agit dans notre cas de mesurer l’importance d’un élément w pour une EN 1:
parmi un ensemble E d’entités8 :

formé par A et B est fréquemment utilisée : c0s(A, B) = La représentation des

nwa: . |E| . .
twm:N,a dw:1 Na tdwa::twa: dw-
f= z,,,E2n,,,,,, “f Og|{a:€E|wEa:}| f”f’ f= X”

Les combinaisons de mesures. Leur principe est la combinaison des propriétés des différents
types de mesures présentés ci-dessus. Il s’agit généralement d’appliquer une “sous-mesure”
sim’ aux mots des deux EN a comparer, puis d’en déduire un éventuel alignement optimal des
EN. Il s’agit donc d’appliquer une méthode de type “sac de mots”, mais sans subir la rigidité
d’un test d’identité entre mots : par exemple, les entités ”Direct0r ElBaradei” et ’’Director-
General ElBareidi ” présentent des similarités importantes que les mesures “sac de mots” clas-
siques ne prennent pas en compte. La sous-mesure doit bien sﬁr étre choisie judicieusement.

— La mesure de Monge-Elkan calcule simplement la moyenne des meilleurs paires de mots

1 77:
trouvés : sim(a:, y) = — Z1r_1T:aL1:><(sz'm’(aI:,-, ya-))
n .21 a=

— La mesure Soft-TFIDF proposée dans (Cohen et al., 2003) est une forme assouplie du co-
sinus sur les vecteurs de poids TF-IDF : grossierement, deux mots différents peuvent étre
considérés comme identiques selon que leur score de sous-mesure dépasse ou non un seuil.

Enﬁn, on peut mesurer la similarite’ des contextes des EN. On nomme contexte d’une occurrence
d’une EN l’ensemble des n mots qui la suivent et qui la precedent, et le contexte (global)
d’une entité distincte est formé par l’union des contextes de toutes ses occurrences. De facon

511 est utile de noter que cette mesure n’est pas symétrique. On trouve dans la littérature et dans les implémen—
tations existantes diverses Variantes pour contourner ce probléme.
5AVec  le cardinal de l’ensemble E.
723 est l’ensemble des éléments considérés (e.g. tous les mots apparaissant dans au moins une EN).
8AVec nwﬂ, le nombre d’occurrences de 11) dans l’EN 1:, et 2 le Vocabulaire.

Appariement d’entités nommées coréférentes par apprentissage supervisé

classique (Pedersen & Kulkarni, 2007), nous calculons l’ensemble des vecteurs représentant le
contexte de chaque entité, chaque vecteur contenant les poids TF-IDF des mots de ce contexte.
La similarité entre les contextes de deux EN est alors le cosinus de leurs vecteurs respectifs.

3 Approche proposée

Nous avons implémenté un prototype d’évaluation de mesures de similarités entre EN. A partir
d’une liste d’entités et de leur contexte, celui-ci calcule le score de similarité obtenu par chaque
couple d’EN pour un ensemble prédéﬁni de mesures. 48 mesures sont disponibles, dont une
vingtaine proviennent de deux librairies publiques : SimMetrics9 de S. Chapman et Second-
String“) de W. Cohen, P. Ravikumar et S. Fienberg.

3.1 Difﬁcultés posées par l’étiquetage

Il est bien entendu nécessaire de disposer de données étiquetées, d’une part pour pouvoir tester
et comparer les performances des différentes mesures, et d’autre part pour pratiquer l’appren-
tissage supervisé. Cependant, la tache d’appariement présente certaines spéciﬁcités qui rendent
la phase d’étiquetage de données difﬁcile. En effet, nous cherchons a classer des couples d’EN
comme positifs (coréférence) ou négatif (non coréférence). Or pour n entités distinctes l’en-
semble des couples potentiel comprend n X (n — 1) / 2 elements, il serait donc excessivement
coﬁteux en temps d’envisager l’étiquetage manuel de cet ensemble (pour les valeurs de n etu-
diées). Dans de telles circonstances, une technique usuelle consiste a n’étiqueter qu’un sous-
ensemble de couples tirés aléatoirement. Mais cette alternative n’est pas envisageable ici, a
cause de la disproportion entre couples positifs et négatifs : dans nos données, on ne trouve
respectivement que 0,06% (pour MNI) et 0,02% (pour MIF) de couples positifs.

C’est pourquoi notre approche vise a extraire de facon semi-automatique un ensemble contenant
tous les couples positifs. Seul cet ensemble sera examiné au cours de l’étiquetage manuel. Cette
approche repose sur l’hypothese selon laquelle les couples positifs seront jugés similaires par au
moins une des métriques; a l’inverse, les couples qui ne sont bien classés par aucune métrique
sont considérés négatifs. Cette méthodologie n’est pas sans biais, mais une analyse approfondie
d’un ensemble d’entités nous a permis de constater que ce biais était en réalité faible, du fait de
la multiplicité et de la diversité des mesures utilisées.

Les criteres d’étiquetage manuel ainsi que les méthodes automatiques de recherche de couples
candidats ont été afﬁnés pour le traitement du corpus MIF, grace a l’expérience acquise avec
le corpus MNI. C’est pourquoi nous ne détaillons ci-dessous que la méthode employée sur
MIF, sachant que le changement principal réside dans une déﬁnition beaucoup plus stricte de la
coréférence.

Pour la recherche de couples candidats, notre systeme propose d’abord les couples obtenant
les is meilleurs scores selon chaque mesure. Deux autres techniques sont également Inises en
oeuvre : la premiere consiste a appliquer automatiquement les relations de transitivité (si les
EN A et B sont coréférentes et que B et 0 le sont aussi, alors A et 0 sont coréférentes). La
seconde vise a repérer d’éventuels couples difﬁciles a trouver de facon globable (par exemple,

9http://www.dcs.shef.ac.uk/~sam/stringmetrics.html
whttp://secondstring.sourceforge.net

Erwan Moreau, Francois Yvon, Olivier Cappe

les EN courtes sont defavorisees par la majorite des mesures) : dans ce but, l’ensemble des EN
est parcouru, en proposant pour chaque EN les n entites les plus proches selon m “bonnes”
mesures. Les couples sont classes en trois categories : les positifs (coreference stricte, au moins
dans le corpus); les ne’gatzfs (non-coreference stricte); les couples incertains (ne pouvant étre
acceptes comme positifs mais presentant toutefois un lien etroit“). Enﬁn certaines EN sont
eliminees (principalement les erreurs de reconnaissance ou les EN mal formees, mais aussi
quelques cas ambigus).

Par rapport au corpus MNI, plus de temps a ete consacre a la recherche de couples coreferents
parmi les entites. En particulier, bon nombre d’acronymes ont ete apparies manuellement avec
leur forme etendue, ainsi que quelques cas tels que “Quai d ’0rsay” et “Ministére des aﬁaires
étrangéres”. Le parcours d’appariement local, au cours duquel chaque EN est prise comme
reference, a permis de reperer une douzaine de couples positifs supplementaires parmi environ
30 000. Pour toutes ces raisons, nous pensons que la probabilite pour un couple positif de n’avoir
pas ete etiquete est tres basse.

Corpus EN EN eliminees positifs negatifs incertains total
Corpus MNI 1588 0 805 1 877 3 836 1 260 078
Corpus MIF 3278 745 741 32 348 419 3 206 778

Dans les colonnes 2 et 3 de ce tableau sont representes des nombres d’entite’s, tandis que les suivantes contiennent
des nombres de couples d ’entz'te’s. Ainsi dans MIF 3278-745 EN representent 3 206778 couples, parmi lesquels
33 508 ont ete etiquetes. Pour MNI, aucune EN reconnue n’ avait ete eliminee (car la methode employee pour 1’ eti-
quetage etait djfferente), c’ est pourquoi la proportion d’ incertains est si importante (elle reste toutefois negligeable
par rapport a l’ensemble des couples).

3.2 Apprentissage supervisé : motivations et outils

Nous developperons dans la partie 4.1 les resultats obtenus par les mesures de similarite testees.
On peut neanmoins deja deduire de leurs deﬁnitions (cf. partie 2.2) qu’elles ont chacune des
proprietes speciﬁques qui les rendent potentiellement complementaires. Nous pouvons observer
ces differences sur quelques cas positifs non triviaux issus du corpus MIF dans le tableau 3.2.

I Couple l Levenshtein TF-]DF mots TF-]DF trigrammes TF-]DF contextes l
"Fatah a1—Islam" / "Fateh el—Islam" 281 > 3000 686 > 3000
"Mosquee Rouge" / "Mosquee rouge d’Islamabad" > 3000 233 449 > 3000
"Omar a1—Baghdadi" / "Omar de Bagdad" 887 1802 2318 10
"Recep Tayyip Erdogan"/ "Erdogan" > 3000 746 2406 2510

Les valeurs indiquees representent la position du couple dans la liste triee par score decroissant de chaque me-
sure” : le couple "Fatah al—Islam" / "Fateh el—Islam" est ainsi classe 281e par la mesure de Levenshtein.

Ces exemples illustrent le fait qu’aucune de ces mesures n’est capable de prendre en compte
tous les types d’indices permettant de statuer sur l’eventuelle coreference d’un couple d’entites.
C’est pourquoi nous proposons d’utiliser l’apprentissage supervise : nous esperons ainsi deter-
miner une maniere optimale de combiner les scores obtenus a l’aide de differentes mesures,
dans le but d’ameliorer les performances de la tache d’appariement d’EN.

“Exemples: “ONU” et “Conseil de sécurité de I ’0NU ”, ou “Russie” et “Gouvemement russe”.

12Notons que ce type de couple est hors de portee des mesures de similarité textuelle.

13Rappelons que ce corpus contient 741 positifs, ce qui signiﬁe qu’un seuil (choisi de fagon a garantir une
precision mjnimale) sur une seule mesure ne permettrait de conserver au mieux que les 500 :|: 100 meilleurs scores.

Appariement d’entités nommées coréférentes par apprentissage supervisé

Dans les données foumies a l’algorithme d’apprentissage, chaque couple d’entités est repré-
senté par un ensemble de parametres choisis pour leur contribution potentielle a la détection
d’une coréférence. Parmi ces parametres ﬁgurent bien entendu les scores de similarité obte-
nus avec différentes mesures, mais aussi certaines caractéristiques du couple d’EN telles que
leurs longueurs (en nombre de caracteres et de mots) et leurs fréquences Ininimales et maxi-
males. Nous utilisons le logiciel Weka (Witten & Frank, 2005) pour réaliser l’apprentissage14,
et testons deux méthodes de classiﬁcation : La régression logistique, qui apprend un séparateur
linéaire, et L’alg0rithme C4.5 (Quinlan, 1993), qui apprend un arbre de decision.

4 Expérimentations et résultats

Conformément a l’approche que nous avons suivie pour l’étiquetage des données, les résultats15
détaillés ci-dessous sont évalués sous les hypotheses suivantes : tout couple non étiqueté est
assimilé a un couple négatif; tout couple marqué comme “incertain” est simplement ignore.

4.1 Observations générales

Tout d’abord, nous constatons que les mesures se comportent de facon similaire sur les deux
corpus. Des differences de performances importantes sont observées, mais celles-ci sont prin-
cipalement dues aux criteres d’étiquetage différents (voir partie 3.1).

FIG. 1 — Précision et rappel pour 4 mesures de similarité (corpus MIF)

100

100 . . .

   
    

I I I I
Jaro Jaro
Cosinus TF-IDF mots ----- -- Cosinus TF-IDF mots ----- --
Cosinus TFIDF Trigrammes ------ -- Cosinus TFIDF Trigrammes --
Soft TF-IDF -------------- -- - 80 — Soft T lE}I=

    

80-

60-

Precision
Rappel

O I I I I O I I I I
0 500 1000 1500 2000 2500 0 500 1000 1500 2000 2500

n meilleurs scores n meilleurs scores

Exemple : pour la mesure de Jaro, si le seuil est ﬁxé de telle sorte que les couples obtenant les 500 scores les plus
elevés soient classes positifs, la precision est de 65% et le rappel de 46% (rappel : MIF contient 741 positifs).

La typologie des ressemblances reconnues par type de mesure laisse apparaitre quelques grandes
lignes : sur les mots simples qui présentent de légeres differences textuelles, souvent des noms
de lieux ou de personnes, les mesures de type Levenshtein/Jaro sont performantes. Mais celles-
ci deviennent inadaptées des que plusieurs mots sont présents, ce qui est essentiellement le
cas des noms d’organisation mais aussi souvent des noms de personnes (e.g. avec/sans pré-
nom/titre) : les mesures “sac de mots” sont alors nettement meilleures (voir table 3.2).

“Get outil public propose un ensemble Varié d’algorithmes d’apprentissage prets a l’emploi pour la fouille de
donnée.

15L’apprentissage est realise par Validation croisée en 10 sous—ensembles. Dans tous les cas étudiés, le taux
d’erreur global est tres faible (inférieur a 0,1%) puisque le taux de couples negatifs est tres eleve.

Erwan Moreau, Francois Yvon, Olivier Cappé

En général, les mesures qui obtiennent les meilleures performances sont de type “sac de mots”
ou “sac de n-grammes”, tandis que les mesures basées sur les séquences de caracteres, moins
souples, ne permettent d’identiﬁer sans erreur que les couples positifs tres proches. Sans sur-
prise, la prise en compte de l’IDF améliore assez nettement les résultats des mesures de type sac
de mots/n-grammes. Individuellement, la mesure de similarité des contextes n’a pas d’intérét16.

4.2 Apport de l’apprentissage
4.2.1 Mesures individuelles

Dans le tableau 1 sont indiquées les performances obtenues par quelques-une des meilleures
mesures individuelles. Celles-ci sont calculées selon les deux méthodes d’apprentissage, de
facon a pouvoir servir de référence par rapport aux combinaisons de mesures décrites ci-apres.
Dans ce meme tableau nous évaluons l’apport des parametres de longueur/fréquence des EN. On
peut constater que les résultats sont tres proches avec les deux méthodes dans le cas des mesures
seules, tandis que le C4.5 tire beaucoup Inieux proﬁt des parametres de longueur/fréquence : la
F-mesure va jusqu’a augmenter de 26 (MNI) ou 15 (MIF) points pour la mesure de J aro.

TAB. 1 — Mesures individuelles avec/sans longueurs et fréquences (pourcentages)

Corpus MNI Corpus MIF
Parametres Régr. log. C4.5 Régr. log. C4.5
P R F P R F P R F P R F

Jaro seule 66,0 25,0 36,2 74,3 17,6 28,5 89,4 40,2 55,4 91,6 38,7 54,4
Jaro + l/f 67,4 34,2 45,3 81,8 42,5 55,9 84,1 43,0 56,9 88,2 57,0 69,2
TF—IDF mots seule 85,6 58,5 69,5 83,3 60,0 69,7 81,9 51,0 62,9 91,5 46,7 61,8
TF—IDF mots + 1/f 86,3 58,8 69,9 88,4 63,6 74,0 82,0 50,6 62,6 86,9 48,4 62,2
TF—IDF trigrammes seule 79,5 64,7 71,4 76,0 67,2 71,3 73,1 49,4 58,9 70,7 52,1 60,0
TF—IDF trigrammes + 1/f 84,7 71,3 77,4 87,1 68,9 77,0 77,4 55,0 64,3 84,5 62,1 71,6

P/R/F = Precision/Rappel/F-mesure. “+ 1/f” signiﬁe “avec les parametres de longueurs et fréquences”.
Exemple : sur le corpus MNI, l’apprentissage par C4.5 sur les parametres constitués du score de TF—IDF sur les
mots et des longueurs et fréquences min. et max. de chaque couple donne un rappel de 63,6%.

4.2.2 Combinaisons de mesures

Nous avons testé plusieurs sélections de mesures comme parametres de l’apprentissage. Les
résultats de ces expérimentations pour deux sélections de mesures et quelques variantes sont
fournis dans le tableau 2. On constate globalement une nette amélioration des performances par
rapport au cas des mesures individuelles : en comparant les meilleurs cas des deux situations, le
rappel passe ainsi de 69% a 83% sur le corpus MNI et de 62% a 75% sur le corpus MIF. C’est
encore une fois l’algorithme C4.5 qui combine les différents parametres de facon optimale.

En revanche, la contribution de la mesure de similarité des contextes, particulierement étudiée
ici, est quasiment nulle. Cependant, en considérant un ensemble restreint de mesures de facon
a analyser plus en détail cette mesure (tableau 2), on constate un apport faible mais signiﬁcatif
de celle-ci : l’algorithme C4.5 en permet un usage positif, puisque la F-mesure gagne 2,7 points

15Elle n’atteint jamais les 20% de precision. Pourtant, on observe que ce score est bien représentatif d’une proxi-
mité sémantique, mais celle-ci s’avere trop peu precise pour marquer une éventuelle coréférence (par exemple, on
trouve souvent parmi les bons scores des couples formés d’une organisation et du nom de son représentant).

Appariement d’entites nommees coreferentes par apprentissage supervise

TAB. 2 — Performances de differentes combinaisons de mesures (pourcentages)
Corpus MNI Corpus MIF

Paramétres Regr. log. C4.5 Regr. log. C4.5

P R F P R F P R F P R F
A seules 85,9 75,0 80,1 85,1 83,2 84,2 78,7 58,8 67,3 89,7 67,6 77,1
A + 1/f 87,2 76,4 81,5 85,2 80,9 83,0 79,0 59,2 67,6 87,3 71,0 78,3
A’ seules 86,2 76,6 81,1 86,3 82,0 84,1 82,9 63,9 72,2 87,1 73,9 80,0
A’ + 1/f 87,5 77,4 82,1 84,5 80,5 82,4 82,2 63,8 71,8 85,1 75,2 79,8
B seules 82,9 69,1 75,3 83,1 76,3 79,5 74,4 51,6 60,9 87,2 71,0 78,2
B + 1/f 84,9 73,3 78,7 82,5 78,3 80,3 80,5 59,4 68,4 87,0 70,7 78,0
B’ seules 84,4 71,3 77,3 82,1 77,5 79,7 80,7 59,6 68,5 87,5 75,3 81,0
B’ + 1/f 86,6 74,2 79,9 83,8 79,3 81,5 81,9 64,0 71,9 85,9 75,4 80,3
L’ensemble de mesures A est constitué des mesures Cosinus (nombre de mots), Jaro, Smith-Waterman-Goto 1, TFIDF mots, TFIDF trigrammes

et Soft-TFIDF. L’ensemb1e B est constitué des mesures Levenshtein, Jaro, TFIDF mots, TFIDF bigrammes, TFIDF trigrammes et une combi-
naison par couplage de mots basée sur J aro. A’ (resp. B’) est 1’ensemble A (resp. B) auquel est ajouté le TFIDF sur les contextes.

dans le cas o1‘1 ce parametre est ajoute a deux autres bonnes mesures. Un gain siIr1ilaire est
observe entre l’une des mesures prise individuellement (tableau 1) et la meme avec le contexte.

FIG. 2 — Inﬂuence de la mesure sur les contextes (corpus MIF) (pourcentages)

Regr. log. C4.5
Paramétres P R F P R F
TFIDF Trigrammes + Contexte + l/f 80,4 61,6 69,7 81,9 70,8 76,0
TFIDF Mots + Contexte + 1/f 85,7 52,0 64,7 83,2 55,2 66,4
TFIDF Trigrammes + TFIDF Mots + l/f 77,4 57,5 66,0 86,0 64,2 73,5
TFIDF Trigrammes + TFIDF Mots + Contexte + l/f 80,5 62,0 70,0 83,1 70,3 76,2

Le choix des mesures est une question complexe : tout d’abord, on constate assez naturelle-
ment que plus on fournit de parametres a l’algorithme d’apprentissage, meilleur est le modele
qu’il produit. Ainsi, nous avons teste le C4.5 sur le corpus MNI avec 18 mesures differentes (et
les parametres de longueur/frequence) : ceci permet d’obtenir jusqu’a 84,9%/85,0% de preci-
sion/rappel. Toutefois cet apport est limite : le gain obtenu en combinant les scores de seulement
deux mesures (pertinentes) est important, mais il a tendance a s’affaiblir avec l’augmentation
du nombre de mesures. Ceci est dﬁ en partie au fait qu’une combinaison de mesures n’a d’in-
teret que si celles-ci sont complementaires, or on retrouve rapidement des mesures de meme
type. De plus, dans un cadre d’utilisation reelle, les ressources materielles ne permettent pas de
recourir au calcul de dizaines de mesures pour des volumes de donnees importants. C’est pour-
quoi il semble judicieux d’adopter un comproIr1is raisonnable en selectionnant de 3 a 5 mesures
complementaires. A ce titre, soulignons que malgre ses performances assez faibles la mesure
de similarite des contextes est un bon candidat sur le plan de la complementarite.

5 Conclusion et perspectives

Pour conclure, dans cet article nous avons montre l’interet de combiner les scores de diffe-
rentes mesures de similarite pour l’appariement d’EN extraites de textes non structures. Les
experiences menees sur deux corpus montrent que l’apprentissage supervise permet de telles
combinaisons, et que celles-ci ameliorent de facon signiﬁcative les performances de la tache
d’appariement. Pour cet apprentissage, la comparaison de la regression logistique et de l’algo-

Erwan Moreau, Francois Yvon, Olivier Cappé

rithme C4.5 est nettement en faveur de ce demier. Dans ce cadre, nous avons également étudié
l’apport d’une mesure de similarité des contextes, qui semble faible mais non négligeable.

L’inconvénient le plus important de cette méthode est certainement la nécessité de données
étiquetées, tres difﬁciles et/ou coﬁteuses a obtenir a cause des spéciﬁcités de cette problema-
tique (nombre de couples potentiels tres élevé et disproportion entre positifs et négatifs). C’est
pourquoi il nous semble pertinent d’étudier les possibilités d’apprentissage non-supervisé ou
semi-supervisé (par exemple en sélectionnant judicieusement les couples a étiqueter).

Remerciements

Ces travaux ont été ﬁnancés par le proj et Cap Digital - Infom@ gic. Nous remercions L. Rigouste
(Pertimm), N. Dessaigne et A. Migeotte (Arisem) pour nous avoir fourni le corpus MIF annoté.

Références

BILENKO M. & MOONEY R. J. (2003). Adaptive duplicate detection using learnable string
similarity measures. In P. DOMINGOS, C. FALOUTSOS, T. SENATOR, H. KARGUPTA & L.
GETOOR, Eds., Proceedings of the ninth ACM SIGKDD International Conference on Know-
ledge Discovery and Data Mining (KDD-03), p. 39-48, New York : ACM Press.

BILENKO M., MOONEY R. J ., COHEN W. W., RAVIKUMAR P. & FIENBERG S. E. (2003).
Adaptive name matching in information integration. IEEE Intelligent Systems, 18(5), 16-23.

CHRISTEN P. (2006). A Comparison of Personal Name Matching .' Techniques and Practi-
cal Issues. Rapport interne TR-CS-06-02, Department of Computer Science, The Australian
National University, Canberra 0200 ACT, Australia.

COHEN W. W., RAVIKUMAR P. & FIENBERG S. E. (2003). A comparison of string distance
metrics for name-matching tasks. In S. KAMBHAMPATI & C. A. KNOBLOCK, Eds., Procee-
dings of IJ CAI-03 Workshop on Information Integration on the Web (IIWeb-03), August 9-I0,
2003, Acapulco, Mexico, p. 73-78.

FREEMAN A., CONDON S. L. & ACKERMAN C. (2006). Cross linguistic name matching in
English and Arabic. In R. C. MOORE, J. A. BILMES, J. CHU-CARROLL & M. SANDERSON,
Eds., HLT-NAACL : The Association for Computational Linguistics.

PEDERSEN T. & KULKARNI A. (2007). Unsupervised discrimination of person names in Web
contexts. In Proceedings of the Eighth International Conference on Intelligent Text Processing
and Computational Linguistics, Mexico City.

POULIQUEN B., STEINBERGER R., IGNAT C., TEMNIKOVA 1., WIDIGER A., ZAGHOUANI
W. & ZIZKA J. (2006). Multilingual person name recognition and transliteration. CORELA -
Cognition, Representation, Langage.

QUINLAN J. R. (1993). C4.5 .' Programs for Machine Learning. San Mateo, CA : Morgan
Kaufmann.

WINKLER W. E. (1999). The state of record linkage and current research problems. Rapport
interne RR99/04, US Bureau of the Census.

WITTEN I. H. & FRANK E. (2005). Data Mining .' Practical Machine Learning Tools and
Techniques, Second Edition. Morgan Kaufmann.

