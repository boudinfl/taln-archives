TALN 2008, Avignon, 9-I3 juin 2008

Extraction automatique d'informations
a partir de micro-textes non structurés

Cédric Vidrequinl, Juan—Manuel Torres—Moreno1,
Jean—Jacques Schneiderz, Marc El—Beze1

(1) Laboratoire Informatique d'Avignon, Agroparc
BP1228, 84911 Avignon CEDEX 9, France

cedric.Vidre uin marc.elbeze uan—manuel.torres @univ—avi non.fr

(2) Société SEMAN TIA, Parc d'activité de Gémenos,
30 avenue du chateau de Jouques, 13420 Gémenos, France

]]schneider@ semantia.com

Résumé Nous présentons dans cet article une méthode d'extraction automatique
d'informations sur des textes de tres petite taille, faiblement structurés. Nous travaillons sur
des textes dont la rédaction n'est pas normalisée, avec tres peu de mots pour caractériser
chaque information. Les textes ne contiennent pas ou tres peu de phrases. Il s'agit le plus
souvent de morceaux de phrases ou d'expressions composées de quelques mots. Nous
comparons plusieurs méthodes d'extraction, dont certaines sont entierement automatiques.
D'autres utilisent en partie une connaissance du domaine que nous voulons réduite au
minimum, de facon a minimiser le travail manuel en amont. Enfin, nous présentons nos
résultats qui dépassent ce dont il est fait état dans la littérature, avec une précision équivalente
et un rappel supérieur.

Abstract In this article, we present a method of automatic extraction of informations on
very small-sized and weakly structured texts. We work on texts whose drafting is not
normalised, with very few words to characterize each information. Texts does not contain
sentences, or only few. There are mostly about fragments of sentences or about expressions of
some words. We compare several extracting methods, some completely automatic and others
using an small domain knowledge. We want this knowledge to be minimalistic to reduce as
much as possible any manual work. Then, we present our results, witch are better than those
published in the literature, with an equivalent precision and a greater recall.

Mots-clés extraction automatique, Inicro-texte, texte non structuré, petites annonces.
Keywords automatique extraction, micro-text, unstructured text, adds.

Cédric Vidrequin, Juan-Manuel Torres-Moreno, Jean-Jacques Schneider, Marc El-Béze

1 Introduction

L'extraction automatique d'informations sur des textes de petite taille peut se reveler
relativement simple ou tres compliquee, selon les caracteristiques des documents traites et le
type d'informations cherchees. Le domaine des petites annonces est souvent utilise pour
experimenter ce type d'extraction automatique car on peut travailler sur des petits, des tres
petits voire des micro-textes. De plus, on y rencontre a la fois des donnees speciﬁques a
chaque annonce, et des donnees communes liees au domaine. Deux approches sont utilisees
pour rediger une petite annonce : la saisie de texte libre ou la saisie par formulaire. La
premiere permet au vendeur de decrire son bien aussi precisement qu'il le desire. La seconde
accorde plus de facilite a l'acheteur lors de sa recherche, en proposant de filtrer les annonces
par criteres (marque, prix, garantie ...). Si la saisie par formulaire prevoit assez souvent une
zone de description libre, celle-ci n'est, en general, pas traitee lors de la recherche par critere.
On souhaiterait donc concilier la liberte apportee par la saisie en texte libre, et la simplicite de
la recherche par criteres. C'est dans cette optique que nous developpons une methode
d'extraction automatique d'informations, a partir de petites annonces. Les methodes
employees dans la litterature sont en general satisfaisantes, mais ne font etat que de
l'extraction d'une partie des informations. C'est pourquoi nous souhaitons developper un outil
capable de detecter le plus de criteres possibles, avec un taux d'erreur minimal.

En section 2, nous recensons les methodes existantes dont nous nous sommes inspires. Dans
la section 3, est decrite la methode que nous proposons. Enﬁn, nous rapportons, en section 4,
les resultats que nous obtenons avec notre systeme. Nous concluons en section 5 et donnons
les perspectives que nous envisageons l'avenir.

2 Méthodes pour l'extraction d'informations dans des petites
annonces

Une des approches utilisees pour extraire automatiquement des informations a partir de
petites annonces est de realiser un adaptateur (wrapper). Celui-ci parcourt le document et en
extrait une carte hiérarchique des donnees. Cette methode a besoin de documents structures
ou semi structures, comme des documents HTML, et implique le plus souvent la redaction
manuelle de regles d'extraction pour chaque critere. (Gao et Sterling, 1999) extraient des
informations a partir de sites web heterogenes en suivant deux etapes successives. Ils mettent
tout d'abord en evidence les criteres caracterisant chaque objet de l'annonce, puis ils groupent
les connaissances en concepts hierarchiques. La premiere etape est proche du probleme qui
nous interesse : les criteres recherches sont par exemple le prix, la superﬁcie ou le type d'un
bien immobilier. Ceux-ci sont mis en evidence grace a des fonctions d'extraction adaptees,
realisees de facon manuelle, en utilisant des listes de termes et des expressions regulieres. Les
listes peuvent caracteriser par exemple les marques et les modeles de vehicule automobile.
Les expressions regulieres, quant a elles, peuvent modeliser des informations comme le prix
ou la surface d'une habitation. La detection des criteres se fait a l'aide d'une liste de predicats
de priorite entre concepts et balisage HTML.

De la meme facon, (Seo et al., 2001) mettent en evidence des paires [etiquette, valeur] en
utilisant des connaissances du domaine de l'immobilier. Ces connaissances, modelisees dans
un fichier XML, representent les differentes facon de formuler chaque critere : a un meme
niveau de l'arbre XML se trouvent les differentes formulations pour la valeur du critere
conceme. Cette representation constitue une alternative a l'utilisation d'expressions regulieres.
Les paires detectees peuvent avoir differentes formes : $395 000 ou 5 BR ou encore 2 BA. Ces

Extraction automatique d ’inf0rmati0ns £1 partir de micro-textes non structurés

paires correspondent au critere prix qui a pour valeur 395 000, au critere nombre de chambres
qui a pour valeur 5, ou au critere nombre de miles de bain qui a pour valeur 2.

Notre facon d'aborder la problématique est différente de l'approche des auteurs. Ceux-ci
s'attachent plus a réaliser une segmentation des pages Web en annonces, qu'a un découpage
d'annonces. D'autre part, les criteres extraits sont tres limités, et ne représentent pas
l'ensemble de l'annonce. Ce nombre n'est d'ailleurs pas donné, mais les exemples illustrant
leurs résultats en comportent moins de dix pour chaque type d'annonce. L'évaluation de leur
performance porte uniquement sur les criteres qu'ils visent a détecter.

(Embley et al., 1998) réalisent une extraction semblable a celle de (Seo et al., 2001), sur des
textes non structurés, en s'appuyant sur une ontologie. Cette ontologie est obtenue a partir
d'un modele sémantique de données eta pour but de décrire la vue désirée du domaine retenu.
Les auteurs appliquent un parseur, un outil de reconnaissance de constantes et mots clés, puis
un générateur de texte structuré sur le texte non structuré. Des couples [clé, valeur] sont
générés, en respectant les contraintes et les regles de l'ontologie. Cette méthode n'a pas pour
prétention de fonctionner sur tout type de documents, mais vise les documents riches en
données constantes - dates, noms, identifiants, quantités - ou dont le domaine d'application est
décrit par une partie d'ontologie restreinte. C'est a partir de l'ontologie que sont générées les
expressions régulieres qui sont utilisées par l'outil de reconnaissance de paires [clé, valeur],
pour extraire les criteres. Le moteur de génération de texte structuré est ensuite appliqué,
suivant une liste d'heuristiques prédéfinies. (Embley et al., 1998) évaluent leur systeme sur un
ensemble de 216 annonces automobiles et 100 annonces d'offres d'emploi. Tout comme (Gao
et Sterling, 1999), ils n'extraient pas la totalité des criteres des annonces. Cette fois, la
limitation vient des contraintes imposées par l'ontologie. Par exemple, le numéro de téléphone
des annonces automobiles n'accepte qu'une seule valeur, méme si l'annonce en comporte
plusieurs. Les calculs de rappel et de précision sont effectués sur la base d'une réponse unique
et non sur l'ensemble des informations contenues dans l'annonce, et seuls les criteres déﬁnis
par l'ontologie sont pris en compte. Nous nous différencions des auteurs sur ce point, comme
nous le verrons en section 4.

(Peleato et al., 2000) étiquettent des données a partir de lexiques, d'expressions régulieres et
d'analyses de position des mots. Les étiquettes correspondent au nom des criteres, les données
a leur valeur. Les expressions et noms sont tout d'abord détectés grace a des lexiques, établis
a partir d'une étude de fréquence d'apparition des mots, dans un corpus de 10 000 annonces.
On rencontre dans ces listes des termes tels "camion", "airbag", ou encore "libre de suite".
Des listes publiques, obtenues sur le Web, sont utilisées pour détecter certaines informations
comme les noms de villes ou de pays, ainsi que les abréviations. Un jeu d'expressions
régulieres est ensuite appliqué pour les informations telles que les dates, les prix ou les
numéros de téléphone. Ce jeux d'expressions a été enrichi manuellement a partir de tests
basés sur un corpus d'entrainement. Un second processus a pour but d'identiﬁer la nature des
informations restantes, a partir de l'annonce partiellement étiquetée. Cette demiere est
segmentée suivant la ponctuation, et des prépositions dans le cas d'annonces d'offre d'emploi.
Les mots mis en évidence sont compares a des listes de mots clés décrivant chaque critere.
Ces listes ont été constituées manuellement, suite a l'étude précédemment citée. La différence
entre ces listes et les lexiques est que ces listes ne définissent pas une information précise,
mais plutot la catégorie d'information concemée. Par exemple, "climatisation" ou "alarme"
appartiennent a la catégorie "options" ; "spacieux" ou "charmant" appartiennent a la catégorie
"qualite"'. L'étiquetage du segment se fait en fonction de la liste a laquelle correspondent le
plus de mots du segment. Les positions relatives des mots sont utilisées pour étiqueter les
segments qui n'ont pu l'étre jusque-la. Ainsi, un segment est rattaché a celui qui le précede
directement, suivant un jeu prédéfini de regles. Par exemple, un mot non étiqueté suivant
directement la marque d'un véhicule est étiqueté comme modele. L'étude précédente montre

Cédric Vidrequin, Juan-Manuel Torres-Moreno, Jean-Jacques Schneider, Marc El-Béze

en effet que le modele d'un vehicule suit le plus souvent la marque. Les segments restants
sont etiquetes indéﬁnis. Le systeme est evalue sur 77 annonces dont 6 portent sur
l'automobile, 30 sur les offres d'emploi et 41 sur l'immobilier. Ces annonces sont annotees
manuellement par plusieurs personnes, les resultats donnant lieu a une mesure de kappa (1).
P{A)- P(E)

1—P{E) — 1 (1)

P(A) est la proportion de correcteurs proposant la meme etiquette, et P(E) la proportion
d'accord aleatoire (cas o1‘1 l'on met les etiquettes au hasard). Les auteurs obtiennent un kappa
k=0,9, ce qui est au dessus du taux k=0,8, considere comme tres acceptable. Une fois de plus,
tous les criteres des annonces ne sont pas pris en compte lors de l'evaluation. Lorsque les
correcteurs ne sont pas d'accord, le critere est considere comme neutre et ne fait pas partie de
l'evaluation. Si un critere n'est releve ni par les correcteurs, ni par le systeme, il est egalement
ignore. Sur l'ensemble de test, 519 criteres sont pris en compte sur 1 415 criteres. Pour les
criteres evalues, si les correcteurs et le systeme s'accordent sur la detection du critere, celui-ci
est compte comme correct, sinon il est compte comme incorrect. Seule la precision est
evaluee, en comparant manuellement les reponses des correcteurs et celles du systeme.

-1537:

3 Extraction automatique par le contenu

Nous parlons ici d'eXtraction plutot que de reperage, car cette derniere notion laisse sous-
entendre un chevauchement possible entre les criteres. La societe SEMANTIA nous fourni un
corpus de 83 749 petites annonces, longues en moyenne de 35 termes, et dont voici un
exemple : "206 1.6 16V ROLLAND GARROS 5 Portes VERT FONCE 24692 Km 2004
Essence Alarme Garantie I2 mois I2900€”. Notre objectif est d'utiliser le moins possible de
connaissances du domaine. Nous separons pour cela les informations entre informations a
valeur variable et informations a caractere booleen.

3.1 Les critéres 2‘: valeur variable

Le premier type de criteres correspond a ceux dont la valeur peut fortement varier d'une
annonce a l'autre, et pour lesquels on ne peut pas operer de detection automatique efficace. En
effet, on peut considerer que la valeur de ces criteres est presque unique pour chaque
annonce. C'est le cas pour des informations comme un prix, une date ou une marque. Nous
utilisons donc notre connaissance du domaine pour extraire ces criteres, ce qui necessite un
certain travail manuel, en amont de l'extraction. Tout comme (Gao et Sterling, 1999) ou
(Peleato et al., 2000), nous utilisons des listes pour mettre en evidence une partie des
informations. En revanche, notre objectif etant d'avoir la plus petite contribution manuelle en
amorce, nous en limitons fortement l'utilisation. Nous n'utilisons donc qu'une liste fermee de
valeurs et une liste d'expressions regulieres. La premiere est obtenue sur Internetl, et contient
uniquement les marques et les modeles des vehicules. Pour les autres informations, nous
fabriquons manuellement une courte liste d'expressions regulieres simples, modelisant
chacune des informations recherchees. Par exemple, le nombre de portes est extrait par
l'expression suivante : "([I-7][ ]*[Pp](0r|0R)?(te[s]?|TE[S]?))". Contrairement a (Embley
et al.,1998) qui utilisent 165 expressions regulieres pour l'automobile, notre liste contient une
156"“ d'expressions regulieres. Ces demieres permettent d'eXtraire des criteres comme le prix
du vehicule, le nombre de portes, le millesime ou encore le kilometrage. A la difference de
l'etude de frequence de (Peleato et al., 2000), dont la Inise en place a dure 45 jours, notre
amorce manuelle peut étre realisee en moins d'une journee, et peut etre, si besoin, rapidement
adaptee en fonction des resultats obtenus.

1 http://fr.wikipedia.org/wiki/Constructeur_automobi1e et liens sous—j acents

Extraction automatique d ’inf0rmati0ns £1 partir de micro-textes non structurés

Un seul groupe d'informations s'est révélé a l'usage trop compliqué a extraire : il s'agit des
informations puissance-m0t0risati0n-cylindrée. En effet, dans la plupart des annonces, on
constate que ces criteres ne sont pas nécessairement regroupés et ordonnés. Les informations
peuvent étre portées différemment d'une annonce l'autre, par un ou plusieurs mots. Certaines
informations peuvent étre absentes et les valeurs de ces criteres sont suffisamment variables
pour empécher une détection automatique efficace. Les combinaisons de ces informations
sont nombreuses, et si elles sont portées par un mot unique, il est alors peu probable de
pouvoir les mettre en évidence de facon totalement automatique, tout en garantissant une
extraction suffisamment fine. Pour ces raisons, le traitement de ces informations fait l'objet
d'une méthode d'extraction automatique spécifique, comme l'ont fait (Gao et Sterling, 1999).
Cette méthode combine un jeu de quatre expressions régulieres : la premiere, la plus générale,
permet d'extraire le groupe de criteres de l'annonce, comme par exemple "1 .5DCI 70CV”. Les
trois autres, plus spécialisées extraient chacun des trois criteres individuellement : la
puissance (70CV), la motorisation (DCI) et la cylindrée (1.5).

3.2 Les critéres £1 caractére booléen

Une fois les criteres a valeur variable extraits, nous considérons que les informations restantes
font partie du groupe des criteres a caractere booléen. Pour les extraire automatiquement,
nous tirons parti de la taille de notre corpus. Les sections suivantes décrivent deux méthodes
d'extraction qui ne nécessitent pas ou tres peu d'apport manuel.

3.2.1 Découpage suivant la ponctuation

Nous déﬁnissons ici une liste fermée de séparateurs [,-./;] suivant lesquels on découpe tour a
tour les annonces. On obtient ainsi plusieurs découpages possibles différents. Les criteres a
valeur variable déja extraits sont remplacés par le séparateur courant, ce qui donne un pre-
découpage fiable. Le texte restant est découpé en fonction du méme séparateur, aﬁn de mettre
en évidence les criteres potentiels. On trie les criteres des différents découpages, de facon
décroissante, et en fonction de leur nombre d'occurrences sur l'ensemble des annonces. De la
liste obtenue, on élimine les criteres automatiquement détectés qui sont trop courts ou trop
longs. Nous gardons arbitrairement les criteres longs de plus de trois lettres et comprenant au
maximum sept mots. Ces valeurs ont été déﬁnies en observant le comportement du systeme
durant la phase de développement. On élimine également les criteres qui contiennent
plusieurs fois le meme séparateur, en partant du principe qu'il s'agit potentiellement d'un
mauvais découpage. En effet, certaines annonces utilisent un type de séparateur, puis en
changent en cours d'annonce. L'extraction automatique des criteres se fait sur base de la liste
ainsi Inise en évidence.

Pour chaque annonce, on parcourt la liste des criteres automatiquement mis en évidence. Si le
critere est present, on l'extrait de l'annonce et on passe au suivant, sinon on passe directement
au critere suivant. Le traitement de l'annonce est terminé une fois que la liste des criteres est
entierement parcourue. Si cette méthode a l'avantage de donner de tres bons résultats en terme
de précision, elle a aussi des inconvénients. Elle est limitée en rappel dans la mesure ou elle
ne cherche pas a extraire tous les criteres des annonces, mais seulement ceux que la méthode
a retenus. Ensuite, certains criteres sont impossibles a extraire comme c'est le cas des criteres
contenant plusieurs ponctuationsz. Enﬁn, les criteres de plus de sept mots, comme par
exemple "livraison partout en France comprise dans le prix", ne peuvent étre extraits.

2 "Banquette arriére 2/3 — I/3" ou "rétroviseurs électr. — dégivr. &ab"

Cédric Vidrequin, Juan-Manuel Torres-Moreno, Jean-Jacques Schneider, Marc El-Béze

3.2.2 Découpage avec les collocations

Nous désirons a present augmenter le rappel en essayant d'extraire l'ensemble des criteres de
chaque annonce. Nous souhaitons également utiliser une méthode qui soit moins liée aux
caracteres de ponctuation, puisque ces demiers peuvent se trouver dans l'expression de
certains criteres. Afin de mettre en évidence des groupes de mots ayant un sens particulier
lorsqu'ils se suivent, nous avons développé une méthode d'extraction s'appuyant sur les
collocations et utilisant un filtrage basé sur les ratios de vraisemblance.

Une collocation (Manning et Schiitze, 1999) est une tournure de phrase pour laquelle le tout
est percu pour avoir un sens au-dela de la somme des parties. Les collocations comprennent
les groupes nominaux, les groupes verbaux ou encore les locutions. Enfin, tout type de groupe
de mots fréquemment répété est candidat au statut de collocation. Les collocations ont la
double particularité que les termes qui la composent apparaissent fréquemment ensemble,
tout en pouvant avoir une existence indépendante.

Les ratios de vraisemblance sont une approche par test d'hypothese. Ils sont appropriés pour
des données éparses et sont faciles a interpréter, grace a un nombre qui exprime la
vraisemblance entre les hypotheses testées. Les hypotheses Ho et H1 considerent
respectivement l'indépendance et la dépendance entre deux mots. Le ratio de vraisemblance
correspond a la probabilité de réunir les deux conditions de l'hypothese. Pour comparer les
collocations potentielles, le logarithme de vraisemblance est utilisé. Celui-ci a l'avantage de
mettre en évidence les collocations dont les occurrences sont rares. La variable aléatoire
utilisée est asymptotique3 a une distribution de type X2 et peut étre utilisée pour réaliser des
tests d'hypothese. Ainsi, en utilisant les tables de valeurs de référence d'une X2, on peut
valider ou refuser une hypothese, en associant un score de confiance a la décision prise.

La mise en évidence des criteres se fait de facon itérative en utilisant le corpus d'annonces.
Lors de la premiere itération, des couples de termes sont construits a partir de mots, tandis
que pour les itérations suivantes, les termes peuvent étre encore des mots ou des groupements
de mots. Nous recensons le nombre d'occurrences de chaque couple de termes, ainsi que celui
des termes pris séparément. A partir de ces informations, nous calculons le ratio de
vraisemblance des couples de termes et nous les classons par ordre décroissant. Le corpus
étant suffisamment grand, nous approximons la variable aléatoire qui définit le ratio de
vraisemblance par une distribution X2. Puisque nous travaillons a chaque itération sur des
couples de termes, le degré de liberté est de un. Nous décidons de tolérer un taux d'erreur de
0,001, ce qui nous amene a supprimer tous les couples dont le score est inférieur4 a 10,83.
Nous supprimons les couples pour lesquels le premier terme se termine par une ponctuation,
ou pour lesquels le second terme commence par une ponctuations, modélisant par la un
mauvais découpage potentiel de l'annonce. Nous avons expérimenté différents ensembles de
ponctuations concernées, y compris l'ensemble vide (section 4.2). Les couples conservés dans
la liste sont regroupés en une seule entité et représentent les criteres potentiels.

Des criteres pouvant se chevaucher, il est important de réaliser les choix qui favorisent le
découpage optimal. L'annonce "(...)I0000 km hifi systéme alarme garantie or ESP (...)"
présente une ambigui'té forte pouvant amener aux découpages suivants : [10000 km, hifi,
systéme alarme, garantie or, ESP] ou [10000 km, hifi systéme, alarme garantie, or, ESP].
Nous développons donc une méthode inspirée de l'algorithme de Viterbi (Viterbi 1967)
projeté sur une seule dimension. Parmi les découpages possibles, cette méthode cherche un
maximum global de la somme des ratios de vraisemblance correspondant aux criteres

3 Quand le corpus est suffisamment grand.
4 Tirée des tables des distributions X2
5 Exemple : "() Immobiliseur, Vitres électriques ,V0lant multifonctions. Garantie. ()"

Extraction automatique d ’inf0rmati0ns £1 partir de micro-textes non structurés

découpés. Soient 11 1e nombre de mots du plus long critere, m le nombre de mots de l'annonce
traitée, S un tableau de m cases qui fait correspondre les mots de la phrase et le score du
meilleur découpage de l'annonce jusqu'a ce mot, et I un tableau de m cases qui fait
correspondre a chaque mot l'indice du début du critere correspondant au meilleur découpage.
Nous faisons glisser une fenétre de mots sur le texte de l'annonce, en commencant par le
premier mot et en allant vers le dernier. A chaque décalage, nous prenons une fenétre de 11
mots que nous diminuons progressivement d'un mot, jusqu'a arriver au singleton. Pour chaque
groupe de mots de la fenétre, si le n-gramme est présent dans la liste de criteres proposés :

0 dans S : on calcule le score de la case correspondant au dernier mot de la fenétre :

- on normalise le ratio de vraisemblance du critere en le multipliant par le nombre
de mots du critere. Les ratios ont des valeur positives, supérieure a I . On favorise
ainsi la présence de criteres longs, plus difﬁciles a obtenir que des criteres courts ;

- on ajoute a ce score celui de la case précédant le premier mot du n-gramme (et
correspondant donc au dernier mot du n-gramme précédent). Cela permet de
cumuler les scores des criteres en fonction du découpage ;

0 dans I : on enregistre l'indice correspondant a la premiere case de la fenétre dans la
case correspondant au dernier mots de la fenétre. Cela nous permet de remonter par
la suite du dernier n-gramme vers le premier.

Un n-gramme peut ne pas apparaitre dans la liste des criteres, parce qu'il a été filtré, ou parce
qu'il s'agit d'un mot seul. Nous n'attribuons alors pas de poids supplémentaire au n-gramme, et
propageons simplement celui du découpage précédent. Dans le premier cas, cela permet de
conserver la possibilité de découper ce critere suivant le n-gramme, si on ne trouve pas de
meilleur découpage en réduisant ou/et en décalant la fenétre de mots. Dans le second cas, la
notion de collocation n'a pas vraiment de sens pour un mot seul, et nous n'avons pas a
disposition de probabilité associée a cet évenement. Malgré cela, la propagation du score sans
ajout de poids permet de considérer le mot seul comme un critere potentiel.

Une fois toutes les fenétres évaluées, nous prenons successivement les maxima de S pour
extraire le meilleur n-gramme courant. Une fois un n-gramme extrait, nous supprimons tous
les scores des mots lui appartenant. Nous réalisons le découpage du dernier critere trouvé vers
le premier. Les annonces découpées servent de base a l'itération suivante, ou les termes ne
sont plus des mots (ou des n-grammes) mais des bi-grammes (ou des n+1 grammes).

4 Expériences

L'évaluation de la performance du systeme nécessite une référence qui doit étre construite
manuellement. Ce processus étant long et fastidieux, seules 200 petites annonces prises au
hasard sont actuellement vérifiéesé. Cette évaluation comprend deux étapes, l'une portant sur
la méthode d'eXtraction par découpage en fonction des ponctuations, l'autre sur la méthode
des collocations. Nous utilisons les annonces pour lesquelles nous avons relevé manuellement
l'ensemble des criteres de chaque annonce. Nous comptabilisons ceux correctement détectés,
ceux mal détectés et ceux qui ne sont pas détectés. Contrairement a (Peleato et al., 2000),
nous évaluons tous les criteres de chaque annonce. Ainsi, nos mesures de précisions et de
rappel sont calculées sur un éventail plus large, et sont donc soumises a de plus fortes
contraintes. Durant cette phase d'évaluation, nous séparons l'évaluation des criteres a valeur
variable de celle des criteres a caractere booléen. Nous conjuguons, dans un second temps,
ces informations dans une moyenne globale. Cela nous permet de nous situer par rapport aux
résultats de la littérature. Les méthodes utilisent des principes similaires, mais les données des

6 Nous en préparons actuellement 200 supplémentaires.

Cédric Vidrequin, Juan-Manuel Torres-Moreno, Jean-Jacques Schneider, Marc El-Béze

systemes sont différentes, le nombre ainsi que le type de criteres détectés ne sont pas les
mémes. (Peleato et al., 2000) obtiennent 73% de précision en moyenne sur les trois domaines
testés7. Ils obtiennent leur meilleure précision pour les annonces automobile avec une valeur
de 88%. Souvenons nous qu'ici, le rappel n'est pas évalué. (Seo et al., 2001) comparent les
mots qu'ils ont extraits aux concepts auxquels ils correspondent. Ils obtiennent 100% de
précision et 80% de rappel, sur les 4 criteres qu'ils extraient. (Gao et Sterling, 1999) évaluent
seulement les criteres sur lesquels ils travaillent. Ils présentent des résultats allant de 90 a
99% pour la précision, et de 76 a 99% pour le rappel, suivant les pages web testées.
Rappelons tout de méme que leurs expériences sont basées sur des pages semi-structurées, ce
qui n'est pas notre cas. (Embley et al., 1998) obtiennent les meilleurs résultats en précision-
rappel avec des scores respectif de 99% et 94%. Cependant, dans le cas de valeurs multiples
pour un critere, une seule valeur est prise en compte.

1-3-3-
90
5%}
T''{!-
E4}
50
46-
34:}
2-3-
‘H’:-
1.-uieur b-Dc:-léen 1 Gkznt:-.'1|1 C‘-;k::-t:-dz Glc:-Dd 3 Gk:-ba.| 4 b-D-C:-Eens 5 I3-k::b.'1| 5
V3'i5blE collocations filtre sur les  et '-' collocations +
I seule-3 ponctuations autorisés connaissances clu domains-I
ponctuations seule-3 [;43||g|33ti43|'|3

Ipré-cisic:-n I rappel -F—r-Jlesure

Figure 1 : Résultats des méthodes proposées
4.1 Evaluation du découpage suivant les caractéres de ponctuation

Notre systeme extrait une quinzaine de criteres a valeur variable. De plus, il tient compte des
valeurs multiples pour un critere. Ainsi il est pénalisé s'il manque une valeur pouvant étre
extraite par un correcteur humain. Il est, de ce point de vue, jugé plus séverement que ses
concurrents. Enfin, notre systeme n'uti1ise que tres peu de connaissances du domaine,
comparativement aux autres systemes. Malgré ces contraintes, nos performances se situent
dans une bonne moyenne avec une F-mesure de 0,93 (Fig. 1 - valeur variable).

Mais cette évaluation n'est que partielle : elle ne prend pas en compte l'ensemble des criteres
des annonces. Nous la réalisons uniquement dans le but de nous positionner par rapport aux
travaux déja mis en oeuvre dans le domaine. Pour les criteres automatiquement détectés
(booléens I), nous obtenons une F-mesure de 0,56. Les performances de notre systeme restent
donc acceptables, avec une F-mesure globale de 0,75, soient 70,6% de précision et 81,3% de
rappel (Global 1). Cette évaluation prend en compte les criteres comportant des erreurs
récurrentes, des fautes d'orthographe ou des abréviations.

4.2 Evaluation du découpage basé sur les collocations

La premiere expérience que nous avons réalisée a pour but d'étudier l'impact de l'utilisation
des méthodes numériques seules. Nous n'utilisons donc que les criteres mis en évidence par

7 Automobile, immobilier et offres d'emploi

Extraction automatique d’informations a partir de micro-textes non structurés

les collocations, et nous ne réalisons pas de ﬁltrage sur les caracteres de ponctuation (Global
2). N'utilisant pas de connaissances du domaine, nous perdons beaucoup en performance et
obtenons seulement 0,42 lors du calcul de la F-mesure. De nouveaux criteres, impossibles a
détecter avec la méthode précédente, sont a present extraits. C'est notamment le cas de
"Banquette arriére 2/3 - I/3". En revanche, malgré une grande variabilité de l'ordre des
criteres, certains d'entre eux apparaissent suffisamment cote a cote pour étre regroupés. C'est
le cas par exemple de "vitres électriques vitres teinte’es".

Si l'on ﬁltre les criteres par rapport a la ponctuation (voir 3.2.2), la F-mesure chute alors a
0,24 (Global 3). De nombreux mots sont en effet regroupés de facon injustifiée du point de
vue du sens. C'est le cas par exemple des mots "6" et "Tél." qui sont rapprochés dans le méme
bi-gramme. En effet, nous empéchons la constitution d'un n-gramme dont l'un des mots est
suivi par un caractere de ponctuation. On ne peut donc pas regrouper le mot "Tél." et le
numéro de téléphone qui lui correspond. Ensuite, le numéro de téléphone du contact suit tres
fréquemment le prix de l'objet de la vente. Le regroupement de ces deux informations est
donc facilité. De plus, le numéro de téléphone est souvent découpé en cinq mots, un espace
séparant chacun des chiffres. Il est donc plus difficile de recomposer les 6-grammes que les
bi-grammes (lorsque les chiffres sont, par exemple, collés les uns aux autres). En permettant
l'apparition d'un point ou d'un tiret entre deux mots d'un critere, on améliore légerement les
résultats et l'on obtient 0,45 de F-mesure (Global 4). Si on se réfere a la premiere méthode,
l'une des raisons de la perte de performances, est liée au regroupement de criteres proches du
point de vue de l'information qu'ils portent. C'est notamment le cas de la marque et du
modele. Ces deux informations étant tres souvent regroupées au niveau de l'annonce, la
méthode des collocations en fait presque systématiquement un n-gramme. Le découpage n'est
donc pas aussi ﬁn que ce que l'on attend. On retrouve le meme genre de probleme avec des
informations beaucoup plus complexes a extraire comme la cylindrée, la motorisation et la
puissance. La encore, ces informations sont le plus souvent collées les unes aux autres, et
donc impossibles a extraire automatiquement.

Nous constatons donc que nous ne pouvons nous passer totalement de la connaissance du
domaine pour assurer une extraction satisfaisante. C'est pourquoi nous testons l'extraction des
collocations, apres avoir extrait au préalable les criteres a valeur variable. Nous obtenons
ainsi des performances légerement supérieures a la premiere méthode avec une F-mesure de
0,76 (Global 5). Les résultats de l'extraction des criteres a valeur variable sont évidemment
inchangés. Pour les criteres a caractere booléen, nous perdons un peu en précision (43,9%
contre 47,5% pour la premiere méthode) mais nous gagnons en rappel (73,8% contre 68,7%).
Ces résultats s'expliquent par le fait que l'on essaye ici d'extraire tous les criteres et non pas
seulement ceux qui ont été Inis en évidence automatiquement. On augmente donc le rappel,
mais puisque l'on prend plus de risques, on diminue forcément la précision. On note
également une amélioration de la qualité de certains criteres que l'on extrayait de facon
automatique. Ainsi les criteres complexes comme "coussins gonflables (4 &plus)" ou
"garanti garantie or 12 mois" sont correctement extraits, ce qui n'était pas le cas auparavant.

5 Conclusion

Nous avons vu dans cet article que les méthodes que nous proposons donnent des résultats
comparables a ce que l'on rencontre dans la littérature, mais en utilisant une connaissance du
domaine réduite tout en détectant plus de criteres. De plus, une partie des criteres est extraite
sans connaissances du domaine et notre méthode continue a donner des résultats acceptables.
A présent, nos objectifs sont d'amé1iorer nos résultats en testant l'impact de l'utilisation d'un
outil de racinisation. Nous générerons ainsi des criteres plus généraux, et nous espérons

Cédric Vidrequin, Juan-Manuel Torres-Moreno, Jean-Jacques Schneider, Marc El-Béze

rapprocher des criteres liés. Pour extraire les criteres des petites annonces, nous utiliserons cet
outil de racinisation pour faire correspondre n-grarnmes et criteres. D'autre part, nous
prévoyons de mettre a l'épreuve notre méthode en testant celle-ci sur des petites annonces
écrites dans une autre langue, ou traitant d'un autre domaine. Nous comptons appliquer notre
algorithme sur des petites annonces automobile en anglais, puis sur des petites annonces
immobilieres en francais. Ces expériences nous permettront en outre d'évaluer le coﬁt réel de
l'adaptation des connaissances du domaine. Enfin, pour résoudre les problemes de mots mal
découpés a cause des ponctuations ou pour des mots abrégés de facon particuliere (ex:
"de’givr.", "airbags front. et lat." ), nous réﬂéchissons a l'uti1isation d'un algorithme de
réduction de bruit. En considérant les annonces comme un ensemble de données bruitées, ou
contenant des erreurs, le but serait de détecter ces erreurs et de pouvoir les corriger
automatiquement, a condition, bien sur, que les formes correctes soient prédominantes sur les
formes incorrectes.

Remerciement Ces travaux sont co-ﬁnances par l'ANRT - CIFRE n° 777/2004.

Références

Y. CHOUEKA, T. KLEIN, E. NEUWITZ. Automatic retrieval of frequent idiomatic and collocational
expressions in a large corpus. Journal for literary and linguistic computing, 4:34-38.

GAo X., STERLING L. (1999). Serni-Structured Data Extraction from Heterogeneous Sources. In
Proceedings of 2cd International Workshop on Innovative Internet Information Systems
(IIIS'99) in conjunction with the European Conference on Information Systems (ECIS'99),
Copenhagen, Denmark.

EMBLEY D. W., CAMPBELL D. M., SMITH R. D. and LIDDLE S. W. (1998). Ontology-Based
Extraction and Structuring of Information from Data-Rich Unstructured Documents. In G.
Gardarin, J .C. French, N. Pissinou, K. Makki and L. Bouganim, editors, In Proceedings of the
International Conference on Knowledge Management. ACM.

PELEATo R. A., CHAPPELIER J.-C., and RAJMAN M. (2000). Automated Information Extraction out
of Classified Advertisements. In Natural Language Processing and Information Systems : 5th
International Conference on Applications of Natural Language to Information Systems,
NLDB 2000, Versailles, France.

SEo H., YANG J., and CHoI J. (2001), Knowledge-based Wrapper Generation by Using XML.
In IJCAI-2001 Workshop on Adaptive Text Extraction and Mining, Seattle, Washington.

MANNING C. D., SCHUTZE H. (1999). Foundations of statistical natural language processing.
MIT Press, 620 p., Cambridge, MA.

VHERBI A. (1967). Error bounds for convolutional codes and an asymptotically optimum
decoding algorithm. IEEE Transactions on Information Theory.

