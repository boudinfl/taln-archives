TALN 2008, Avignon, 9-13 juin 2008

Enertex : un systéme basé sur l’énergie textuelle

Silvia FERNANDEZL2, Eric SANJUAN1, Juan Manuel TORRES-MORENOL3
1 Laboratoire Informatique d’AVignon, BP 1228 84911 Avignon France
2 LPM UHP-Nancy, BP 239 54506 Vandoeuvre les Nancy France
3 Ecole Polytechnique de Montréal, CP 6079 Montreal, Canada H3C3A7

{silvia . fernandez, eric . sanjuan, juan—manuel . torres } @univ—avignon . fr

Résumé. Dans cet article, nous présentons des applications du systeme Enertex au Trai-
tement Automatique de la Langue Naturelle. Enertex est basé sur l’énergie textuelle, une ap-
proche par réseaux de neurones inspirée de la physique statistique des systemes magnétiques.
Nous avons appliqué cette approche aux problemes du résumé automatique multi-documents et
de la détection de frontieres thématiques. Les résultats, en trois langues : anglais, espagnol et
francais, sont tres encourageants.

Abstract. In this paper we present Enertex applications to study fundamental problems in
Natural Language Processing. Enertex is based on textual energy, a neural networks approach,
inspired by statistical physics of magnetic systems. We obtained good results on the application
of this method to automatic multi-document summarization and thematic border detection in
three languages : English, Spanish and French.

M0tS-CléS I Energie textuelle, Réseaux de neurones, Modele de Hopﬁeld, Résumé auto-
matique, Frontieres thématiques.

Keywords: Textual Energy, Neural Networks, Hopﬁeld Model, Automatic Summari-
zation, Thematic Boundaries.

1 Introduction

Des idées empruntées a la physique ont déja été utilisées dans l’analyse de textes. Les exemples
plus notables sont l’approche entropique de (Shannon, 1948), les travaux de (Zipf, 1935; Zipf,
1949) et de (Mandelbrot, 1953) 011 les auteurs font des considerations thermodynamiques d’éner-
gie et de température dans leurs études sur la Statistique Textuelle. Demierement (Takamura
et al., 2005) se sont servi des notions de polarisation des systemes de spins pour trouver les
orientations sémantiques des mots (désirable ou indésirable) a partir de mots amorce. La sortie
de ce systeme est une liste de mots indiquant leurs orientations estimés selon l’approximation
du champ moyen. Dans notre travail, nous avons utilisé différemment la notion de spin. Elle
nous a permis de représenter les présences (T) 011 absences (i) des mots dans les documents. A
partir de cet image, on apercoit le document comme un matériaux composé d’un ensemble de
unités en interaction dont l’énergie peut étre calculée. Nous avons étudié les problemes du Trai-
tement Automatique de la Langue Naturelle (TALN) en utilisant la notion d’énergie textuelle.
Récemment introduite (Fernandez et al., 2007a; Fernandez et al., 2007b), l’énergie textuelle a
été appliquée au résumé automatique et a la détection de frontieres sur des corpus en francais

Silvia FERNANDEZ, Eric SANJUAN, Juan Manuel TORRES-MORENO

et en anglais. Elle est aussi un des algorithmes utilisés dans (da Cunha et al., 2007) ou des
méthodes statistiques et linguistiques sont combinées pour résumer des articles médicaux en
espagnol. Dans cet article nous étudions l’inﬂuence de deux facteurs, inspirés aussi de la phy-
sique, sur l’énergie textuelle. 11 s’ agit d’un champ exteme et de la température. Cette démarche a
permis d’améliorer les performances du modele. Les résultats sur des corpus multi-documents
et trilingues (francais, anglais et espagnol) sont tres encourageants. Nous présentons dans la
Section 2 une breve introduction au modele neuronal de Hopﬁeld ainsi que son extension au
TALN. Nous appliquons l’énergie textuelle a deux taches bien distinctes : la génération de
résumés multi-documents guidés par une thématique dans la Section 3 et l’amélioration de l’al-
gorithme de détection de frontieres thématiques dans la Section 4. Finalement nous présentons
les conclusions et quelques perspectives.

2 L’énergie textuelle des documents

La contribution la plus importante de Hopﬁeld a la théorie des réseaux neuronaux a été l’in-
troduction du concept d’énergie issu de l’analogie avec les systemes magnétiques : systemes
constitués d’un ensemble de N petits aimants appelés spins qui peuvent s’orienter selon plu-
sieurs directions. Le cas le plus simple est représenté par le modele d’Ising, avec deux directions
possibles : vers le haut (T, +1 ou 1) ou vers le bas (1, -1 ou 0). Ce modele a été utilisé dans une
grande variété de systemes qui peuvent étre décrits par des variables binaires (Ma, 1985). Un
systeme de N unités binaires possede 1/ = 1, ..., 2N conﬁgurations (patrons) possibles. Dans
le modele de Hopﬁeld, les spins correspondent aux neurones qui interagissent selon la regle
d’apprentissage de Hebbl :

P
W" = Z sgsf, (1)
[.l,=1

31 et sj sont les états des neurones 1' et j. La sommation porte sur les P patrons a stocker. Ce
modele est aussi connu sous le nom de mémoire associative. I1 possede la capacité de stocker et
de récupérer un certain nombre de conﬁgurations du systeme, car la regle de Hebb transforme
ces conﬁgurations en attracteurs (minimaux locaux) de la fonction d’énergie (Hopﬁeld, 1982) :

1 N N l H -
E,,,=—§ZZs;, Jwsf, (2)

i=1 j=1

Si on présente un patron proche a 1/, chaque spin subira un champ local hi, =  J14 sf,
induit par les N spins des autres patrons ,u. Les spins s’aligneront selon ii; pour restituer le
patron stocké 1/. Hopﬁeld a démontré que l’énergie du systeme diminue toujours pendant le
processus de récupération. Nous ne développerons pas la méthode de récupération de patronsz,
car l’intérét porte sur la distribution et les propriétés de l’énergie du systeme. Cette fonction
monotone et décroissante a été utilisée uniquement pour montrer que l’apprentissage est borné.

D’un autre coté, le modele vectoriel de textes (Salton & McGill, 1983) transforme un document
dans un espace adéquat ou une matrice S contient l’information du texte sous forme de sacs de
mots. On peut considérer S comme l’ensemble des conﬁgurations d’un systeme dont on peut

1Hebb (Hertz et al., 1991) a suggéré que les connexions synaptiques changent proportionnellement £1 la corre-
lation entre les états des neurones.
2Cependant1e lecteur intéressé peut consulter, par exemple (Hopﬁeld, 1982; Hertz et al., 1991).

Enertex : un systeme basé sur l’énergie textuelle

calculer l’énergie. Les documents sont pré-traités avec des algorithmes classiques de ﬁltrage de
mots fonctionnels3, de normalisation et de lemmatisation (Porter, 1980; Manning & Schiitze,
1999) aﬁn de réduire la dimensionnalité. Une représentation en sac de mots produit une matrice
S[pXN] de fréquences/absences :

- TF1 si le terme i existe
Z
: : 3
S [8“] { 0 autrement ( )
o1‘1 ,u = 1, - - - ,P phrases et 1' = 1, - - - ,N termes. La présence du mot i représente un spin

31 T avec une magnitude donnée par sa fréquence TF1 (son absence par L respectivement), et
une phrase est donc une chaine de N spins. Pour calculer les interactions entre les N termes du
vocabulaire, on applique la regle de Hebb, qui sous forme matricielle se traduit par :

J=ST><S (4)

Chaque élément J14 E J [ NX N] est équivalent au calcul de (1). Enﬁn, l’énergie textuelle d’inter-
action (2) peut alors s’exprimer comme :

E=—%S><J><ST (5)

Un élément EM, 6 E[pXp] représente l’énergie textuelle entre les phrases ,u et 1/. La representa-
tion sous forme de graphe (Fernandez et al. , 2007b) nous a permis d’expliquer la nature des liens
que la mesure d’énergie textuelle induit. On a déduit qu’elle relie a la fois des phrases ayant des
mots communs, ainsi que des phrases qui partagent un meme voisinage sans pour autant par-
tager nécessairement un méme vocabulaire. C’est pour cette raison que l’énergie textuelle peut
étre utilisée comme mesure de similarité dans les applications du TALN. Nous avons développé
l’algorithme Enertex basé sur cette mesure de similarité. Les premieres applications ont porté
sur le résumé mono-document genérique et sur la détection de frontieres thématiques. Dans la
section suivante nous montrons une modiﬁcation qui consiste en mettre un champ exteme en
rapport avec un corpus multi-document. Cette stratégie permet de générer des résumés guidés
par les besoins de l’utilisateur. Une autre approche, montrée dans la section 4, utilise l’éner-
gie textuelle représentée comme un spectre de la phrase. Ceci permet la détection de frontieres
thématiques d’un document au moyen d’un test de concordance de Kendall. Nous montrons ici
comment l’introduction d’une température modiﬁe les spectres des phrases aﬁn que le test de
Kendall puisse mieux les identiﬁer.

3 Résumé multi-document guidé par une requéte

Les premiers systemes de résumé automatique multi-documents ont été développés dans les
années 90 (McKeown & Radev, 1995). Les conférences DUC portant sur la tache de résumé
automatique sont organisées depuis 2001 par le NIST4. La tache principale de DUC consiste a
traiter des questions complexes et réelles. Le type de réponse attendue ne peut pas étre une entité
simple (un nom, une date ou une quantité telle que classiquement déﬁni dans les conférences
TREC Question-Answering5). Le probleme peut se poser comme ceci : étant donnée une thé-
matique et un ensemble L‘, avec D documents pertinents, générer un court résumé de 250 mots,

3Nous avons effectué le ﬁltrage de chiffres et l’uti1isation d’anti—dictionnaires.
4http://www—nlpir.nist.gov/projects/duc
Shttp://trec.nist.gov/data/qamain.html

Silvia FERNANDEZ, Eric SANJUAN, Juan Manuel TORRES-MORENO

cohérent et bien organisé qui répondra aux questions de la thématique. Les D = 25 documents
proviennent du corpus AQUAINT : articles d’Associated Press, New York Hmes (1998-2000)
et Xinhua News Agency (1996-2000). L’ évaluation de la qualité des résumés mono-document
reste une tache difﬁcile. En multi-documents le probleme n’est pas plus simple. Des approches
manuelles et semi-automatiques ont été utilisées an ce propos. Ainsi Pyramid (Passonneau et al. ,
2005), Basic Elements (Hovy et al., 2005) et ROUGE (Lin, 2004) ont été employées. Plusieurs
mesures manuelles ont été évaluées : cohérence, grammaticalité, non-redondance, pertinence
au sujet, qualité linguistique. ROUGE est utilisée par la communauté comme mesure d’évalua-
tion semi-automatique. Elle mesure l’intersection d’ensembles de n-grammes entre les résumés
candidats et ceux de référence. Les métriques les plus populaires sont ROUGE-2 (bigrammes)
et SU4 (bigrammes séparés par un intervalle 3 4 mots). Nous avons utilisé l’énergie textuelle
pour la tache de résumé guidé par une thématique ou sujet. L’idée est d’observer la réponse
du systeme face a un champ exteme. Ce champ, représenté par le vecteur des termes d’un texte
décrivant un suj et a été Inis en relation avec le corpus multi-document. La ﬁgure 1 illustre le pro-
cessus d’obtention du résumé guidé par un sujet. Les documents sont concaténés dans un seul
document et un prétraitement standard (ﬁltrage et stemming (Porter, 1980)) lui est appliqué.
L’ énergie textuelle entre le sujet et les phrases du document concaténé est calculée selon :

. 1 N N I _ _ _
E(sujet, phrase) = -5 Z Z 3:,”-Ct J” sihmse (6)

i=1 j=1

Finalement, le résumé est formé avec les phrases présentant la plus haute énergie textuelle avec
le sujet. Un post-traitement de diminution de la redondance lui a été appliqué.

Corpus multidocument

sujet .  : —— —— "' ' ' de|a Résumé|
T ' redondance V
/J

ch3""'P Phrases
GXTBITIS ’ imeragissant le
plus avec Ie sujet

\|||\Hl\HJ

FIG. 1 — Résumé guidé par une thématique et un ensemble de documents.

Diminution de la redondance

Dans un résumé multi-document il y a une probabilité signiﬁcative de re-inclure l’informa-
tion déja présente. Pour diminuer ce probleme il faut une stratégie de diminution de la redon-
dance. Notre systeme ne possede pas un traitement linguistique et la stratégie d’anti-redondance
consiste a comparer les valeurs d’énergie des phrases candidates et leur longueur. Nous suppo-
sons que (dans de grands corpus) la probabilité que 2 phrases aient les mémes valeurs d’énergie
est tres faible. Ainsi, nous avons éliminé la présence de doublons (phrases avec exactement la
méme valeur d’énergie). Peut-on aller encore plus loin et détecter avec ce méme critere des
phrases égales a quelques mots pres ? Pour le tester, on considere que si 2 phrases partagent
la plus grande partie de leurs mots, elles apportent la méme information. On construit donc le
résumé avec la phrase la plus énergétique (en valeur absolue), puis la suivante dans le score (la
candidate) fera partie du résume si |E2 — E1| 2 e. E1 est l’énergie de la phrase déja présente.

Enertex : un systeme basé sur l’énergie textuelle

La 3eme phrase candidate fera partie du résumé si |E3 — E1| 2 6 et si |E3 — E2| 2 6. Les ener-
gies E1 et E2 sont considérées comme celles des phrases de référence. En général, une phrase
candidate 1' sera ajoutée au résumé, si pour chaque phrase de référence  — 1) :

Le cas contraire signiﬁe que les énergies sont tres proches avec une haute probabilité de redon-
dance. On présente sur la ﬁgure 2 a gauche les valeurs du rappel du produit ROUGE-2 >< SU4
pour différentes valeurs de AE. Le meilleur résultat sur les corpus DUC’05-07 est obtenu avec
AE m 0,003. Cela correspond aux phrases a 2 mots pres. Une autre stratégie permettant de

  
   

0,017 ____I
. ' u - A.
0 01s.‘ ‘'---‘‘-''I*..-... -12 Due 2007 0'0"; ._ r~.-I wk . ..
_ .__d__‘_‘__4___“ M‘ _ I. ..... .I3.[I.E:..£aIJ.;.....
- - - 14 - .'
0,015- “ ""--_, 0'0 I
A ' .'."',~_ - 5
— - - -_~ 12 — 5
§ 0,014—_ ‘- 3 °'° _ I 1.. Moyenne
cu _ Q. - 5 »__
5 []I013_ M g 0,010 - __________ __
SI . oyenne 5 I '_‘__~_’___“ -.....DU.6.;.I.JII.é ... ...... . 
‘ on u._ ____ __
g; 0,012—,..--..,._,.-'-....._ 0, 0,005 - - ~.......--- ..... ---- -------- --—-
cy _ 'a,_,..___I__'.,.‘-.____I E}. I DUC 2005
LIJ _ ‘Is LIJ _
(3 0,011 . DUO 2006 5,“.-‘n. (3 0,006 -
2 0,010-_ 'm‘-»-.__. 2 0,004..
0 009 - ..-~"----vv"‘-. .... ... I I
' - DUC 2005 """" ""1....._ 0'0” T
0,005‘ . . I . . I . . I . . I . . I . . I 1-"1'--I-'..U‘."' 0000 ' I I I I I I I I I
0,000 0,003 0,006 0,009 0,012 0,015 0,015 0,021 0,024 ’ 0 1 2 3 4 5 6 7 5 9 10
AE (Ecandldale-Ereference)

FIG. 2 — Diminution de la redondance 2 AE d’énergie des phrases et moyenne des longueurs de phrases.

diversiﬁer le contenu, consiste a écarter du résumé les phrases longues (dans les documents il y
a des phrases de taille % a celle du résumé demandé). On a déﬁni la taille maximale de phrase
come is X M o1‘1 M = nombre moyen de mots par phrase dans les documents originaux. Nous
avons fait varier is par petits pas en mesurant a chaque moment le produit de ROUGE-2 >< SU4.
Le comportement est montré sur la ﬁgure 2 a droite. Le meilleur résultat est avec k m 1, 6. Nous
avons ﬁxé k, puis le seuil d’énergie AE = 0,003 en maximisant le produit ROUGE-2><SU4.
En DUC’07 il y avait 2 baselines : la lere est tirée au hasard. La 2eme est un systeme de ré-
sumé générique. La ﬁgure 3 montre la position d’Enertex comparé aux participants apres les
campagnes DUC’05-07. Le cosinus obtient des performances ROUGE étonnament hautes, mais
qui peuvent donner lieu a des résumés avec beaucoup de redondance, car toutes les phrases se-
lectionnées sont proches de la thématique. Par contre l’énergie textuelle capture l’information
entre 2 phrases calculéé parmi toutes les autres. De ce fait, la similarité tient en compte pas uni-
quement du nombre de mots partagés (le recouvrement et le cosinus sont des mesures locales)
mais des interactions indirectes (chemins de longueur 2).

4 Frontiéres thématiques

Plusieurs stratégies ont été développées pour segmenter thématiquement un texte. On trouve
PLSA (Brants et al., 2002) qui estime les probabilités d’appartenance des termes a des classes
sémantiques, des méthodes s’appuyant sur des modeles de Markov (Amini et al., 2000), sur
une classiﬁcation des termes (Caillet et al., 2004; Chuang & Chien, 2004) ou sur des chaines
lexicales (Sitbon & Bellot, 2005). Plus récemment, (Ferret, 2007) a proposé l’identiﬁcation

Silvia FERNANDEZ, Eric SANJUAN, Juan Manuel TORRES-MORENO

0,136 0.16 0,18

Enerlex - a
ma _—°U°2°°5 ~— —. :4‘ 0,5 _ DUC zoos ° 0,17 ; DUC 2007 0°
cos':eo‘° I Enerlex ° 3 o 0 °
0,120 — O 014 T T T 0:16 " T T jJ§°oEne'1ex
0° ‘$13 ' cosinusqﬁo I .
0112 _ °o ma 0,15 _ coslnusv
- 0000 0.13 - 00 : 06V
0104 — 0 0 859” 0:14 - ‘Z. O E°'°"'“2
_ - 0 _ 0,12 - 9 _ - Q, 0
8 o ° 8 0 8 013 '- °
C}. 0.096 - ° ° :1. ca. ’ .
N D ,3 0.11 — O 5 _
cc 0': 0 0': 0,12 _ O
., 0.088 - V ., 0 ,0 _ ., -
8 Baseline 8 ' V 8 011 '_
0.080 — 009 _ Baseline | ’ 3 V
' 0,10 — Ease|lne1
0.072 — -
0.08 - l 0,09 '_
0.064 — 3
0,07 - 0,05 _
0.056 -0 O 1,
I I I I I I  I I I I I I I I 0,0 I I I I I I I I I
0.024 0,032 0.040 0.048 0.056 0.064 0.072 0.027 0.036 0.045 0.054 0.063 0.072 0.081 0,090 0,04 0,05 0,06 0,07 0,08 0,09 0,10 0,11 0,12
ROUGE-2 Rappel ROUGE-2 Rappel ROUGE-2 Rappel

FIG. 3 — Apercu du rappel SU4 VS ROUGE-2 des participants au-dessus des deux baselines.

préalable des sujets présentes dans le document comme stratégie pour améliorer la détection de
ruptures thématiques. L’identiﬁcation de sujets est faite a partir d’une analyse contextuelle ba-
sée sur la co-occurrence de mots. L’ idée est que si deux segments n’ont pas une forte cohésion
lexicale entre eux, mais ils apparaissent dans le méme contexte, alors ils appartiennent au méme
sujet et la rupture thématique n’existe pas. Dans ce travil, nous avons utilisé la matrice d’énergie
E (5). Chaque ligne de cette matrice produit un spectre qui répresente l’interaction de la phrase i
avec les autres. La ﬁgure 4 montre les spectres de quelques phrases d’un texte composé de deux
thématiques. I-/Etant donné que l’énergie textuelle détecte et pondere le voisinage d’une phrase,
on constate une similarité entre les courbes de l’une (en gras) et de l’autre thématique (en poin-
tillées). Pour comparer les spectres nous avons utilisé (Fernandez et al., 2007a) le coefﬁcient
de concordance 7' de Kendall (Siegel & Castellan, 1988) et le calcul de sa p—valeur qui per-
mettent de déﬁnir un test statistique de concordance entre 2 juges qui classent un ensemble de
P objets. Nous avons utilisé ce test pour trouver les frontieres thématiques entre segments. Ces
ruptures entre segments sont bien détectées si le voisinage commun entre les phrases est bien
repéré. Mais il se trouve que des phrases chevauchant les thématiques présentent des courbes
d’énergie que le test du 7' de Kendall s’avere incapable de distinguer. C’est le cas du spectre de
la phrase 23 de la ﬁgure 4. Pour diminuer cet effet nous avons proposé (Fernandez et al. , 2007b)
une variation du test de Kendall avec l’utilisation d’une fenétre glissante : la phrase centrale est
comparée aux autres dans la fenétre Cette stratégie a permis une meilleure détection des rup-
tures. Mais nous pensons qu’on peut faire Inieux. Dans ce travail nous introduisons une stratégie
portant directement sur la modiﬁcation des spectres des courbes : le lissage par un paramétre de
bruit B qui peut étre assimilé, en termes physiques, a l’inverse d’une température T.

Décroissance exponentielle : distance et température

La ﬁgure 4 montre que les spectres qui expriment correctement leur appartenance a une thé-
matique ont une forme décroissante par rapport a un maximum. Ce maximum correspond a
l’expression d’une forte interaction entre un couple de phrases. A partir de ce point maximal,
les autres interactions diminuent rapidement jusqu’a la ﬁn de la thématique. Cette décroissance
de l’énergie textuelle peut étre contrélée avec un facteur exp"/T 00 r est la distance entre la
phrase ,u et la phrase voisine qui présente la plus haute interaction avec elle et T un paramétre de
bruit présent dans les spectres6. La ﬁgure 5 montre le lissage induit dans les spectres pour deux

5Dans la littérature dc réseaux dc neurones on trouve souvent B = 1 / T

Enertex : un systeme basé sur l’énergie textuelle

{M40 12 13 22

FIG. 4 — Energie textuelle 2 en trait continu l’énergie des phrases de la 1é‘° thématique, en pointillé celle
de la 25"”. Le changement d’allure correspond a un changement thématique. L’ axe horizontal indique le
numéro de phrase et l’axe Vertical, l’énergie textuelle de la phrase par rapport aux autres.

   

phrases de la ﬁgure 4 par le facteur exp"/T (la phrase 23 est difﬁcile a classer en fonction de
ses pics). Nous avons diminué T progressivement aﬁn d’analyser l’évolution du chevauchement
des courbes. Cette diminution lisse les courbes de facon efﬁcace : a T m 8 le bruit de la courbe
23 est réduit et un classement correct a été obtenu. Le spectre de la phrase 10 a aussi été lissé
sans perte d’information. Nous faisons l’hypothese que avec ce lissage, le test de concordance



Phrase 23

     

no
T(1  z 0 4 8 10 25 50 100 Sp:ctres
originaux

FIG. 5 — Lissage par exp"/T des spectres. En trait continu le spectre d’une phrase thématiquement bien
déﬁnie et en pointillé celui d’une phrase inclassable. 7" est la distance au maximum et T la témpérature.

de Kendall identiﬁera mieux les phrases selon leur thématique. Mais quelle est la valeur cor-
recte de T ? Pour l’estimer nous avons réalisé des expériences sur des corpus multi-thématique
en anglais, espagnol et francais. Les corpus ont été construits a partir d’articles journalistiques
du BROWN CORPUS, LA J ORNADA et LE MONDE7. Les corpus comportent 4 ensembles de 100
documents qui correspondent a une taille de segments ﬁxée. Un document est constitué de 10
segments extraits d’articles thématiquement différents tirés au hasard. Pour chaque document
on a calculé l’énergie textuelle a différents températures : T = 1, - - - , 180. Les spectres ont été
comparés par le test de Kendall et les frontieres détectées ont été mesurés par Windiff (WD)
(Pevzner & Hearst, 2002)8. Plus la valeur WD est basse, Inieux la segmentation a été réalisée.
La ﬁgure 6 montre les résultats de 100 documents en francais et une taille de segments de 6-8
phrases. En trait continu l’évolution de la valeur moyenne de WD et en pointillé le nombre
de frontieres trouvées. On observe qu’a températures tres basses les courbes d’énergie perdent
leurs pics (sauf le maximum). Le test de Kendall ne détecte plus de frontieres et la valeur WD
est élevée. En augmentant la température les courbes voisines se ressemblente de plus en plus et
le nombre de frontiéres augmente. Nous avons retenu la valeur T = 80 qui maximise le nombre
de frontieres trouvées en Ininimisant la valeur WD.

7http ://khnt.aksis.uib.no/icame/manuals/brown, http ://www.jomada.una1n.mx et http ://www.lemonde.fr
8Windjff mesure la difference entre les frontieres Véritables et celles trouvées dans une fenétre glissante.

Silvia FERNANDEZ, Eric SANJUAN, Juan Manuel TORRES-MORENO

0,405

I
P
on
0

0.400

: u u u u 1 u   _
: Windiff

3‘
no
on

0,395

I
:5
N
o

0,390

I
P
o
0:

0.385

 

0,380

Windiff
I
5»
8
see/moi; smanuou ap qN

0.375 - :: _

5*’
N
01

0,370 -3’

5*’
as
0

0.365 — _ 3,45

 ' I I I I I I I I
0 20 40 60 80 100 120 140 160 180

Température = 1/[3

FIG. 6 — Evolution de WD et du nombre de frontiéres en fonction de T. La ligne horizontale représente
la valeur de WD 51 température inﬁnie. Taille des segment entre 6 et 8 phrases pour le corpus en francais.

La mesure 6-Front

(Pevzner & Hearst, 2002) ont montré que WD est peu sensible aux variations de la taille de
segments et plus équilibré que d’autres mesures dans la pénalisation des erreurs. Cependant
elle a ses faiblesses. WD ne peut pas étre assimilée a un taux d’erreur (sa valeur peut étre >
1) et elle n’est qu’un élément de comparaison de la ﬁabilité des méthodes et non un parametre
absolu de sa qualité (Sitbon & Bellot, 2004). De plus, nous avons trouvé qu’une méme valeur
de WD pouvait correspondre aux segmentations différentes du document. Nous introduisons
ici la mesure 6-Front qui calcule la distance euclidienne d(o) entre les vecteurs A et B de
dimension P (nombre des phrases du document) : A correspond aux frontieres véritables et B
a celles détectées. La valeur de la composante i est le nombre de phrases séparant la phrase 1'
de la frontiere la plus proche (ﬁgure 7). Le facteur de normalisation est calculé avec le vecteur
nul : ne contenant aucune frontiere sauf les extrémes. Plus la valeur 6-Front est basse, mieux la
segmentation a été réalisée.

d(A,B)
d(A,C)

On observe au tableau 1 que la valeur de T pour la meilleur segmentation dépend de la longueur

6-Front(A,B) = (8)

Frontiéres véritables F | I I
A I I I
0 1 1 0 1 2 1 O 1 2 1 0
Frontiéres detectées I I I I
B I I I
0 1 0 1 2 1 0 1 2 2 1 0
Pas de frontiéres I | ‘ I
c I |
0 1 2 3 4 5 5 4 3 2 1 0

FIG. 7 — La mesure 6-Front.

du document. Plus la taille du segment est grande (plus le document est long) plus la valeur T
est elevée. Les deux mesures ne sont pas toujours en accord. En francais WD obtient la valeur
la plus haute pour des segments de taille 9-11 et 6-Front pour 3-5. Cette différence peut étre due

Enertex : un systeme base sur l’energie textuelle

au nombre de veritables frontieres trouvees : 6-Front considere plus ﬁnement ce facteur. Les
methodes cites rapportent des meilleures performances en anglais qu’en francais, peut etre dﬁ
aux differences structurales et de repetition de mots entre ces langues. Cependant nos resultats
sont comparables dans les 3 langues. Cette stabilite decoule du calcul d’interactions des mots
combine au processus de comparaison de segmentes. (Ferret, 2007) constate en partie cet effet.

Taille du T Francais Espagnol Anglais Nb. frontiéres
segment WD 6-Front WD 6-Front WD 6-Front trouvées
9-11 120 0,4109 0,1817 0,3897 0,2069 0,3925 0,1524 m6/9
6-8 80 0,3638 0,1957 0,3601 0,2031 0,3804 0,1640 m5/9
3-11 40 0,3885 0,1974 0,3646 0,2043 0,3709 0,1634 m5/9
3-5 20 0,3851 0,4540 0,3598 0,3257 0,3786 0,3864 5:13/9

TAB. 1 — Mesures WD et 6-Front pour des corpus en 3 langues et segments de tailles Variables.

5 Conclusions

Nous avons presente le systeme Enertex base sur le concept d’energie textuelle. L’ energie tex-
tuelle est bien adaptee a la recherche de segments porteurs d’information d’un texte et a sa pon-
deration. L’ extraction et l’assemblage de ces segments donne le condense d’un document. Nous
avons elargi la portee de cet idee pour developper un algorithme de resume multi-document
guide par une thematique : un champ externe, represente par le vecteur des termes decrivant
une thematique a ete mis en relation avec les phrases d’un corpus multi-document. Ceci a per-
Inis de generer des resumes personnalises que nous avons evalue dans le cadre des taches DUC.
La position d’Enertex est excellente par rapport a la trentaine de participants compte tenu que
l’energie textuelle est exprimee comme un simple produit matriciel. Aucune autre mesure de
ponderation de phrases a ete incluse. En segmentation thematique, nous avons ameliore la de-
tection de fausses frontieres au travers d’une fonction pilotee par une temperature. Cela a permis
de surpasser nos resultats precedents. Compte tenu des faiblesses de WD, nous avons introduit
6-Front, une nouvelle mesure d’evaluation de segmentation thematique. Nous envisageons de
tester le modele de Potts, autre modele d’interaction entre spins qui favorise l’interaction entre
mots de meme frequence, ainsi qu’une etude des chemins de longueur > 2 dans le graphe (inte-
ractions d’ordre 2 3). Des applications en classiﬁcation de textes sont aussi envisagees.

Références

AMINI M.-R., ZARAGOZA H. & GALLINARI P. (2000). Learning for sequence extraction
tasks. In RIAO 2000, p. 476-489.

BRANTS T ., CHEN F. & TSOCHANTARIDIS I. (2002). Topic-based document segmentation
with probabilistic latent semantic anaysis. In CIKM’02, p. 211-218, McLean, Virginia, USA.

CAILLET M., PESSIOT J AMINI M. & GALLINARI P. (2004). Unsupervised learning
with term clustering for thematic segmentation of texts. In RIAO ’04, p. 648-657, France.
CHUANG S.-L. & CHIEN L.-F. (2004). A practical web-based approach to generating Topic
hierarchy for Text segments. In 30th ACM IKM, p. 127-136, Washington DC, USA.

Silvia FERNANDEZ, Eric SANJUAN, Juan Manuel ToRREs-MoRENo

DA CUNHA I., FERNANDEZ S., VELAZQUEZ MORALES P., VIVALDI J ., SANJUAN E. &
TORRES MORENO J . M. (2007). A new hybrid summarizer based on Vector Space model,
Statistical Physics and Linguistics. In LNAI 4287, MICAI’07, Mexico, p. 872-882.
FERNANDEZ S., SANJUAN E. & TORRES-MORENO J . M. (2007a). Energie textuelle des
mémories associatives. In TALN 2007, p. 25-34.

FERNANDEZ S., SANJUAN E. & ToRREs-MoRENo J . M. (2007b). Textual Energy of As-
sociative Memories : performants applications of ENERTEX algorithm in text summarization
and topic segmentation. In LNAI 4287, MICAI’07, Mexico, p. 861-871.

FERRET O. (2007). Finding document topics for improving topic segmentation. In ACL’07,
p. 480-487.

HERTZ J ., KROGH A. & PALMER G. (1991). Introduction to the theorie of Neural Computa-
tion. Redwood City, CA : Addison Wesley.

HOPFIELD J . (1982). Neural networks and physical systems with emergent collective compu-
tational abilities. Proceedings of the National Academy of Sciences of the USA, 9, 2554-2558.
HOVY E., LIN C. & ZHOU L. (2005). Evaluating DUC 2005 using Basic Elements. In DUC
2005.

LIN C.-Y. (2004). ROUGE : A Package for Automatic Evaluation of Summaries. In Text
Summarization Branches Out .' ACL-04 Workshop, p. 74-81, Spain.

MA S. (1985). Statistical Mechanics. Philadelphia, CA : World Scientiﬁc.

MANDELBROT B. (1953). An informational theory of the statistical structure of languages. In
Communication Theory, ed. By Willis Jackson, p. 486-502, New York : Academic Press.
MANNING C. D. & SCHUTZE H. (1999). Foundations of Statistical Natural Language Pro-
cessing. Cambridge, Massachusetts : The MIT Press.

MCKEOWN K. & RADEV D. (1995). Generating summaries of multiple news articles. In
18”‘ ACM SIGIR, p. 74-82.

PAssoNNEAU R., NENKOVA A., MCKEOWN K. & SIGLEMAN S. (2005). Applying the
Pyramid Method in DUC 2005.

PEVZNER L. & HEARST M. (2002). A critique and improvement of an evaluation metric for
text segmentation. In Computational Linguistic, volume 1, p. 19-36.

PORTER M. (1980). An algorithm for sufﬁx stripping. Program, 14(3), 130-137.

SALTON G. & MCGILL M. (1983). Introduction to modern information retrieval. Computer
Science Series McGraw Hill Publishing Company.

SHANNON C. (1948). A mathematical theory of communication. Bell System Technical Jour-
nal, 27, 79-423, 623-656.

SIEGEL S. & CASTELLAN N. (1988). Nonparametric statistics for the behavioral sciences.
McGraw Hill.

SITBON L. & BELLOT P. (2004). Evaluation de méthodes de segmentation thématique linéaire
non supervisées apres adaptation au francais. In TALN 2004, p. 10-19.

SITBON L. & BELLOT P. (2005). Segmentation thématique par chaines lexicales pondérées.
In TALN 2005, volume 1, p. 505-510.

TAKAMURA H., INUI T. & MANABU O. (2005). Extracting semantic orientations of words
using spin model. In ACL’05, p. 133-140.

ZIPF G. (1935). Psycho-biology of languages. Houghton-Miﬁlin, Boston, MA.

ZIPF G. (1949). Human behavior and the principle of least effort. Addison-Wesley, MA.

