TALN 2008, Avignon, 9-13 juin 2008

Recherche locale pour la traduction statistique
a base de segments

Philippe Langlais, Alexandre Patry et Fabrizio Gotti
Departement d’Informatique et de Recherche Operationnelle
Universite de Montreal,

C.P. 6128, succursale Centre-Ville

H3C 3J7, Montreal, Quebec, Canada
{felipe,patryale,gottif}@iro.umontreal.ca

Resume. Dans cette etude, nous nous interessons a des algorithmes de recherche locale
pour la traduction statistique a base de segments (phrase-based machine translation). Les algo-
rithmes que nous etudions s’appuient sur une formulation complete d’un etat dans l’espace de
recherche contrairement aux decodeurs couramment utilises qui explorent l’espace des preﬁxes
des traductions possibles. Nous montrons que la recherche locale seule, permet de produire des
traductions proches en qualite de celles fournies par les decodeurs usuels, en un temps nette-
ment inferieur et a un coﬁt memoire constant. Nous montrons egalement sur plusieurs directions
de traduction qu’elle permet d’ameliorer de maniere signiﬁcative les traductions produites par
le systeme al’etatde1’art Pharaoh (Koehn, 2004).

Abstract. Most phrase-based statistical machine translation decoders rely on a dynamic-
programming technique for maximizing a combination of models, including one or several
language models and translation tables. One implication of this choice is the design of a scoring
function that can be computed incrementally on partial translations, a restriction a search engine
using a complete-state formulation does not have. In this paper, we present experiments we
conducted with a simple, yet effective greedy search engine. We report signiﬁcant improvements
in translation quality over a state-of-the-art beam-search decoder, for some conﬁgurations.

M0tS-CléS I Traduction statistique, recherche locale, post-traitement.

Keywords: Statistical Machine Translation, local search, post-processing.

1 Introduction

Au debut des travaux sur la traduction statistique (TS), plusieurs chercheurs se sont interesses
au probleme de la recherche d’une meilleure traduction, etant donne un modele de traduction
base sur les mots (Berger et al., 1994; Tillmann et al., 1997; Wang & Waibel, 1997; Niessen
et al., 1998; Garcia & Casacuberta, 2001). Avec la montee en popularite des approches a base
de segments (Koehn et al., 2003), des decodeurs dedies ont commence a voir le jour au sein
de notre communaute, comme Pharaoh (Koehn, 2004), distribue sous forme d’un executable,

Langlais et al.

ainsi que différentes variantes logiciel-libre comme Mosesl (Koehn et al., 2006), Ramsesz

(Patry et al., 2006), Phramer3 (Olteanu et al., 2006) ou Marie4 (Crego & Marino, 2007)
pour des modeles n-graInInes bilingues. De nombreuses équipes utilisent ces boites a outils
pour construire leurs propres systemes de TS (Déchelotte et al., 2007; Besacier et al., 2007).

Tous ces décodeurs partagent la propriété de s’appuyer sur une fonction de score incrémentale
de maniere a pouvoir organiser l’espace de recherche efﬁcacement a l’aide de la programmation
dynamique (DP). I1 n’est pas difﬁcile d’imaginer des modeles de traduction ou cette propriété
n’est pas appropriée.

Le moteur de traduction ReWrite5 (Germann et al., 2001), qui utilise un modele de traduction
mot-a-mot (Brown et al., 1993) est une exception notable dans ce paysage. I1 s’agit d’un algo-
rithme de recherche locale qui tente d’ améliorer de maniere itérative une traduction courante, en
lui faisant subir un ensemble de perturbations. A chaque itération, la meilleure traduction issue
de ces perturbations devient l’hypothese courante. Le processus se termine lorsqu’il n’est plus
possible d’améliorer cette demiere, ce qui arrive typiquement apres quelques itérations. Une
version rapide de cet algorithme est décrite dans (Germann, 2003). Il est cependant accepté que
cet algorithme produit des traductions de qualité moindre que les décodeurs DP faisant usage
des memes modeles de traduction (Foster et al., 2003).

A notre connaissance, personne n’a fait l’étude d’algorithmes de recherche locale pour les mo-
deles de traduction a base de segments. Cette étude est une réponse a cette lacune. Nous mon-
trons qu’une implémentation simple de cette idée permet d’obtenir des traductions d’une qualité
proche de celles produites par les décodeurs standards a un coﬁt mémoire constant (alors qu’un
décodeur standard requiert un espace mémoire a tout le moins linéaire avec la taille de la phrase
a traduire) et en un temps de loin inférieur (quelques minutes contre quelques heures).

Nous montrons également que lorsqu’utilisé en cascade, a la sortie d’un décodeur a l’état de
l’art, notre algorithme permet d’en améliorer les traductions. Différentes expériences illustrent
a la fois la souplesse de l’approche et son potentiel comme méthode de post-traitement.

L’ article est organisé comme suit. Dans la section 2, nous décrivons précisément notre approche.
Le protocole expérimental est ensuite présenté en section 3. Nous décrivons les expériences rea-
lisées en section 4 puis concluons cette étude et proposons des pistes de recherche en section 6.

2 Algorithme glouton

L’ algorithme de recherche (voir ﬁgure 1) que nous étudions est une forme particulierement
simple de recherche locale souvent nommée recherche gloutonne. I1 utilise une formulation
complete, ce qui signiﬁe qu’un état dans l’espace de recherche est une traduction possible, a
contrario des décodeurs standards qui parcourent plutot l’espace des préﬁxes de traductions
possibles. Plus précisément, un état, que nous désignons de maniere interchangeable par hy-
pothese, est la donnée d’une traduction du texte source et d’un alignement entre les segments
(phrases) source et cibles.

lhttpz//www.statmt.org/moses/

Zhttp://smtmood.sourceforge.net

3http://www.phramer.org

4http://gps—tsc.upc.es/soft/marie
Shttp://www.isi.edu/publications/licensed-sw/rewrite—decoder/index.html

Recherche locale pour la traduction statistique a base de segments

L’ algorithme (désigné par f eGreedy dans la suite) dépend de la déﬁnition de trois opérateurs :
le premier (s e ed) est en charge de produire la premiere hypothese courante, le second (s co re)
implémente la fonction de score que nous tentons d’optimiser, le dernier (voisinage) pro-
pose les hypotheses voisines explorées a partir de l’hypothese courante.

Require: source une phrase a traduire
courant <— seed(s0urce)
loop

s_c0urant <— score(c0urant)

s <— s_c0urant

for all h E voisinage (courant) do
c <— s core(h)
if c > s then

s <— c
meilleur <— h

if s = s_c0urant then
return courant

else
courant <— meilleur

FIG. 1 — Algorithme de recherche locale glouton.

Ce type de recherche possede trois caractéristiques intéressantes. Premierement, une quantité
constante (et réduite) de mémoire est requise pour représenter l’espace de recherche. I1 s’agit
de l’espace nécessaire a l’encodage de l’hypothese courante. Deuxiemement, ce type d’algo-
rithme propose souvent des solutions raisonnables (en terme de la fonction de score que l’on
cherche a optimiser), en un temps habituellement tres court, a des problemes nécessitant une
recherche combinatoire (Russell & Norvig, 1995). Troisiemement, aucune hypothese n’est né-
cessaire quant a la fonction de score optimisée. En particulier, elle n’a pas besoin d’étre calculée
de maniere incrémentale. Bien sﬁr, cet inventaire de points positifs est contrebalancé par le fait
que cet algorithme ne possede aucune propriété d’optimalité. Nous verrons que ce défaut n’est
pas pénalisant dans notre cas.

2.1 La fonction de score

Dans ce travail, nous cherchons a maximiser la combinaison habituellement utilisée en TS a
base de segments. En particulier, nous nous intéressons dans un premier temps a maximiser la
meme fonction que celle que le décodeur a l’état de l’art Pharaoh (Koehn, 2004) maximise :

Score(e, f) = Azm 10gPlm(f) + 2.-A£:'2.1ogp£:;’.(ﬂe) — Ame, f) — mm <1)

o1‘1 les A sont des coefﬁcients controlant la contribution de chaque modele a la combinaison, pm
est un modele de langue (n-gramme),  représente différentes tables de transfert (qui dans nos
expériences partagent les memes parametres), | f | représente la longueur comptée en mots de la
traduction et pd(e, f) est un modele appelé généralement modele de distorsion (nous utilisons
le modele simple décrit dans (Koehn et al., 2003)).

Langlais et al.

SRC : le groupe csu au parlement européen le présent projet de charte
des droits fondamentaux rassemble et rende visibles les droits fondamentaux dont disposent
les citoyens vis-a-vis des organes et institutions del ’ ue .

Pharaoh the csu group in the european parliament the draft charter of fun-
damental rights lumps together and make visible the fundamental rights enjoyed by the citi-
zens towards the eu institutions and bodies . (-43.8823)

FIG. 2 — Exemple d’une traduction produite par Pharaoh pour une phrase francaise et son
score. Deux segments sources adjacents sont traduits a tort de maniere distante.

2.2 Fonction de voisinage

Par inspection de traductions produites par Pharaoh, nous avons déﬁni six faInilles de per-
turbation d’une hypothese courante. Cet ensemble n’est en aucun cas exhaustif. En particulier,
nous n’autorisons pas encore qu’un mot ou un segment soit inséré ou bien détruit.

Move Pharaoh (comme nombre de ses clones) s’autorise a reporter a plus tard la traduction
d’un segment source aﬁn de traduire le segment qui le suit (traduction non monotone). Ce
comportement est souhaitable pour rendre compte de certaines divergences locales entre deux
langues; il introduit cependant le probleme fréquent ou des segments adjacents sont traduits a
tort par des segments distants (le plus souvent sur la recommandation du modele de langue).
C’est par exemple le cas des segments se réjouit et que de l’exemple de la ﬁgure 2 traduits
respectivement par welcomes et that. Nous avons donc implémenté une opération qui autorise
deux segments cibles distants6 correspondant a la traduction de deux segments sources adjacents
a étre rapprochés (nous tentons tous les rapprochements possibles).

Swap Lorsqu’un segment du texte a traduire est absent du modele de traduction, ce segment
est traduit de maniere compositionnelle a l’aide de segments plus petits. L’ ordre des segments
traductions est alors souvent un compromis fragile entre les recommandations du modele de
langue et du modele de distorsion habituellement biaisé en faveur de traductions monotones.
Dans le but de corriger certains ordonnancements, nous autorisons deux segments cibles ad-
jacents a étre inversés. La complexité7 de cette opération est linéaire avec le nombre N de
segments sources dans l’hypothese courante.

Replace Cette opération permet de changer la traduction d’un segment source par une autre
traduction validée par la table de transfert. Cette operation a une complexité en O(N X T), o1‘1
T est le nombre de traductions considérées pour une phrase source (valeur typique de 10).

Bi-replace De la meme maniere, nous autorisons deux segments a changer simultanément de
traduction avec l’espoir que cela permettra a notre algorithme d’échapper a certains maxima
locaux. La complexité de cette opération est quadratique en T.

Split Un segment source peut étre scindé en deux parties, pour autant que les sous-parties soient
présentes dans la table de transfert. Cette opération est d’une complexité en O(N X S X T2),
o1‘1 S est le nombre de segments sources dans l’hypothese courante.

Merge I1 s’agit de l’opération inverse de la précédente. I1 convient de noter que ces deux ope-
rations s’accompagnent généralement d’un changement lexical de la traduction courante (d’o1‘1
la dépendance a T).

5Sont dits distants dans cette étude deux blocs séparés par au moins 3 mots.
7Nous mesurons le nombre d’hypothéses Voisines engendrées par une opération.

Recherche locale pour la traduction statistique a base de segments

M de plus , <—> furthermore ,  in addition , ... le bon exemple <—> a good example
étre modemisés <—> modernization  modernized ... modemisés <—> modernized

F de plus , nos systemes administratifs doivent étre modemisés . nous devons également
donner le bon exemple .

E in addition , our administrative systems must be modernised , and it is our duty to lead
by example .

S0 [de plus ,] [nos systemes administratifs] [doivent] [étre modemisés] [. nous devons
également] [donner le bon exemple .]

To [furthermore ,] [our administrative systems] [must] [modernization] [and we also need]
[set a good example .] -19.5068

S1 [de plus ,] [nos systemes administratifs] [doivent] [étre modernisés] [.] [nous devons
également] [donner le bon exemple .]

T1 [furthermore ,] [our administrative systems] [must] [modernization] [.] [we must also]
[set a good example .] SPLIT -17.4382

S2 [de plus ,] [nos systemes administratifs] [doivent] [étre] [modemisés] [.] [nous devons
également] [donner le bon exemple .]

T2 [furthermore ,] [our administrative systems] [must] [be] [modernized] [.] [we must
also] [set a good example .] SPLIT -15. 8488

S3 [de plus ,] [nos systemes administratifs] [doivent] [étre] [modemisés] [.] [nous devons
également] [donner] [le bon exemple .]

T3 [furthermore ,] [our administrative systems] [must] [be] [modernized] [.] [we must
also] [give] [a good example .] SPLIT -15. 5885

S4 [de plus ,] [nos systemes administratifs] [doivent] [étre] [modernisés] [.] [nous devons
également] [donner] [le bon exemple .]

T4 [in addition ,] [our administrative systems] [must] [be] [modernized] [.] [we must
also] [give] [a good example .] REPLACE -15.5199

FIG. 3 — Itérations impliquées dans la traduction par initialisation GLOSS (section 2.3) d’une
phrase francaise (F) de traduction de référence (E). Une segmentation (S0) est premierement
calculée a partir des 49 segments sources de M qui couvrent partiellement F. To est la traduction
(GLOSS) associée. Les segments en gras sont impliqués dans l’hypothese recevant le meilleur
score a chaque itération. Plus de 4,100 hypotheses ont été évaluées en un tiers de seconde.

2.3 L’opérateur d’initialisation

Initialisation GLOSS Dans Rewrite (Germann et al., 2001), l’hypothese courante est initia-
lisée en collectant pour chaque mot sa traduction privilégiée selon le modele lexical (paires de
mots source/cible). Nous avons adapté cette idée aux modeles de segments (paires de séquences
de mots source/cible). Une complication survient dans notre cas, puisque la phrase a traduire S
n’est pas pré-découpée en segments. Plusieurs segmentations étant possibles, nous avons décidé
de retenir celle qui minimise le nombre de segments sources du modele de segment M, tout en
couvrant completement S. Notre espoir est ici que des segments longs captureront plus d’in-
formation pertinente a leur traduction hors-contexte. Cette segmentation peut étre implémentée
efﬁcacement par programmation dynamique (Langlais et al., 2007).

Une fois la segmentation source effectuée, nous prenons simplement la traduction privilégiée
(selon M) de chaque segment que nous concaténons pour former une traduction.

Langlais et al.

Initialisation par Pharaoh Nous avons testé une autre maniere d’initialiser la recherche.
Elle consiste a partir de la meilleure traduction produite par Pharaohs. Cela revient a dire que
nous faisons le pari que la recherche locale permet de corriger certaines erreurs faites par le
premier décodeur. Nous appelons cette variante CASCADE dans la suite.

La ﬁgure 3 montre un exemple d’application de la recherche locale dans le cas de l’initialisation
GLOSS.

3 Protocole expérimental

3.1 Corpus

Nous avons réalisé nos experiences en utilisant les ressources de la tache partagée du workshop
sur la traduction statistique qui s’est tenu en 2006, en marge de l’ACL (Koehn & Monz, 2006).
Cette année-la, les systemes participants avaient a traduire des textes en espagnol, en allemand
et en francais vers et depuis l’anglais. Les textes disponibles pour l’entrainement proviennent du
corpus Europarl. Une portion d’environ 700 000 paires de phrases dans chaque langue, t rain,
constituait le matériel d’entrainement; deux corpus de développement de 2 000 phrases chacun,
dev et devtest, étaient destinés respectivement a ajuster les systemes (les A dans l’équa-
tion 1) et a réaliser des tests a blanc. Nous avons utilisé pour nos tests les 2 000 phrases du jeu
de test ofﬁciel de la tache partagée extraites du corpus Europarl9.

3.2 Systéme de référence

Le systeme de base que nous utilisons dans cette étude est le systeme état-de-l’art Inis a dispo-
sition par les organisateurs. Il s’agit d’un systeme maintenant classique ou le modele de langue
est un modele trigramme entrainé a l’aide de SRILM (Stolcke, 2002), les tables de traductions
(avec des segments d’au plus 7 mots) sont entrainées par les scripts fournis par les organisateurs.
Chaque paire de segments dans cette table est notée par quatre scores recevant chacun leur co-
efﬁcient de pondération (A) ainsi qu’un score permettant de controler (de maniere passive) la
longueur des traductions produites (phrase penalty). Le modele de distorsion natif a Pharaoh
ainsi qu’un second modele de controle de la longueur des traductions (word penalty) recoivent a
leur tour un coefﬁcient. Au total, ce sont huit coefﬁcients qui sont ajustés sur dev en appliquant
l’algorithme de minimisation d’erreur minimum—error—rate—t raining . perl.

4 Expériences

Nous comparons1° dans un premier temps f eGreedy et Pharaoh“ en leur demandant de
maximiser la méme fonction (equation 1). Les deux variantes du premier moteur (GLOSS et
CASCADE) sont testées. Les résultats sont indiqués dans le tableau 1.

8Pharaoh donne acces a l’alignement ayant produit la meilleure traduction grace a l’option —t race.
9Des résultats similaires sont observes sur la partie hors-domaine du jeu detest.
1°Par simplicité nous mesurons dans la suite la qualité des traductions produites a l’aide des mesures automa-
tiques WER (pour word error rate) et BLEU (Papineni et al., 2002) couramment employees dans la communauté.
“Les seuils controlant l’espace de recherche que Pharaoh explore ont été laissés a leurs Valeurs par défaut.

Recherche locale pour la traduction statistique a base de segments

L=fr L=es L=de
WER BLEU WER BLEU WER BLEU
Pharaoh 54.85 30.90 54.23 29.64 62.32 17.68
GLOSS 54.27 29.83 53.22 28.99 62.53 17.03
L—>en CASCADE 53.38 31.42 52.77 30.14 61.73 17.88
Pharaoh 51.69 29.96 51.04 30.54 60.54 24.45
GLOSS 50.93 29.13 50.77 29.67 57.55 23.84
en—>L CASCADE 50.46 30.27 50.02 30.87 58.85 24.66

TAB. 1 — Performances de différents algorithmes de recherche. Les données en gras sont signi-
ﬁcativement meilleures (a 99%) que celles associées a Pharaoh.

La variante GLOSS enregistre des valeurs de BLEU inférieures a celles mesurées pour Pharaoh,
les différences sont cependant assez faibles. Les taux d’erreurs au niveau des mots sont en fait
le plus souvent en faveur de GLOSS. Ceci est d’autant plus remarquable que notre implemen-
tation n’encode qu’un nombre restreint d’opérations de voisinage. Nous observons avec intérét
que CASCADE permet d’améliorer les traductions produites par Pharaoh, ce qui constitue un
résultat tres satisfaisant et valide l’idée que la recherche locale offre une facon simple et ef-
ﬁcace de corriger les traductions produites par un systeme natif. Pour toutes les directions de
traduction, les améliorations apportées par CASCADE sont signiﬁcativeslz.

Une analyse plus ﬁne des traces de cette session de traduction permet d’observer que 40% des
traductions produites par Pharaoh ont un meilleur score (equation 1) apres application de la
recherche locale (CASCADE). C’est donc en terme d’algorithme de recherche un succes. De
maniere moins surprenante, 90% des traductions initiales produite par GLOSS sont améliorées
par la recherche locale.

Pas moins de 40% des opérations remportant une itération dans l’algorithme local sont des
opérations de remplacement (replace) d’une traduction par une autre. L’ opération move est
également productive dans la variante CASCADE et illustre bien le pouvoir de post-correction
qu’offre la recherche locale. Une fois un probleme identiﬁé dans les traductions produites par
un systeme natif, il “sufﬁt” d’encoder une opération spéciﬁque visant a sa correction; ce que
nous avons fait pour l’opération move.

Certaines opérations sont marginalement utiles. C’est par exemple le cas de l’opération swap
ce qui s’explique par le fait que la table de transfert capture déja de nombreux réordonnan-
cements locaux. En derniere observation, soulignons que CASCADE requiert beaucoup moins
d’itérations pour converger que GLOSS, ce qui semble normal. 70% des traductions effectuées
par CASCADE nécessitent au plus 2 itérations, alors que seulement un peu plus de la moitié des
traductions effectuées par GLOSS requierent un maximum de 4 itérations. Dans les deux cas, les
deux variantes requierent habituellement moins de 10 iterations avant stabilisation.

Nous tenons a souligner que bien que n’ayant pas pris la peine d’implémenter une version ef-
ﬁcace de notre moteur de traduction, f eGreedy requiert de l’ordre de 4 minutes de calculs
pour traduire 1000 phrases”, contre plus d’une heure pour Pharaoh. Réduire les temps de

12Selon le test d’échantil1onnage multiple avec replacement (boostrap resampling) décrit dans (Zhang & Vogel,
2004), en évaluant 1 000 échantillons de 700 phrases chacun. Niveau de conﬁance ﬁxé a 99%.

13Ce temps ne tient pas compte du calcul de la premiere hypothese courante. Temps approximatifs mesures sur
un ordinateur Pentium a 3 GHz disposant de 4Go de mémoire Vive.

Langlais et al.

Pharaoh CASCADE
pile WER BLEU temps WER BLEU temps
50 51.82 29.24 40Inin. 50.26 29.65 <5 Inin.

100 51.46 29.23 1h. 20min. 50.32 29.62 <5 min.
200 51.15 29.44 2h. 40Inin. 50.18 29.69 <5 min.
500 50.86 29.51 6h. 15min. 50.11 29.74 <5 min.
1000 50.64 29.54 12h. 15Inin. 50.04 29.74 <5 min.

TAB. 2 — Performance de Pharaoh et de CASCADE sur les 1 000 premieres phrases du corpus
de test en fonction du nombre maximum d’hypotheses stockées par Pharaoh dans une pile.

calcul de notre implémentation serait facile puisqu’a chaque opération de voisinage, une nou-
velle hypothese est temporairement construite puis évaluée au complet, alors qu’une opération
n’introduit en général que peu de modiﬁcations dans le calcul de l’équation 1.

Nous concluons cette exploration de la recherche locale par une expérience ou nous augmentons
le nombre d’hypotheses que Pharaoh est autorisé a manipuler par pile. Les résultats de cette
expérience sont consignés en tableau 2 pour des systemes traduisant du francais vers l’anglais.

Nous observons d’une part qu’augmenter l’espace de recherche est payant, puisque plus d’un
point en WER peut étre gagné de cette facon. Ce gain ne doit pas nous faire oublier cependant
que le temps Inis pour obtenir les traductions passe de 40 minutes a plus de 12 heures lors-
qu’on passe d’une 1iInite de 100 hypotheses par pile a 1 000. De maniere plus intéressante, nous
constatons surtout que CASCADE permet systématiquement d’améliorer la meilleure traduction
produite par Pharaoh, que l’on mesure cette amélioration par WER ou par BLEU. L’ améliora-
tion en BLEU apportée par CASCADE a la meilleure traduction produite par la premiere version
de Pharaoh (la plus rapide) est supérieure a celle enregistrée par la version la plus longue de
Pharaoh (+.4 versus +.3). Moins de 5 minutes ont été nécessaires pour obtenir cette amélio-
ration, contre presque 12 heures dans le second cas.

5 Travaux reliés

L’ idée de composer des moteurs de traduction en cascade a été proposée initialement par (Berger
et al., 1994) dans le cadre du systeme Candide; systeme a base de modeles de traduction mot
a mot (Brown et al., 1993). Malheureusement, les auteurs ne décrivent ni leur algorithme de
recherche locale, ni n’en fournissent une évaluation. D’autres travaux ont été menés sur cette
idée. Notamment (Marcu, 2001) et (Watanabe & Sumita, 2003) ou un algorithme de recherche
locale basé sur les mots tente d’améliorer une traduction produite par un systeme de mémoires
de traductions (sous-phrastique dans le premier cas, phrastique dans le second).

Plus récemment, (Simard et al., 2007) et (Chen et al., 2007) présentaient simultanément la
meme idée qui consiste a entrainer un modele de traduction statistique a partir d’un bitexte dont
la partie source est produite par un systeme natif (le systeme Systran dans ces études) et la partie
cible est une traduction de référence (manuelle); l’espoir étant que le modele de traduction
résultant saura corriger des erreurs commises par le systeme natif. Il est important de souligner
que notre approche, bien qu’elle puisse étre utilisée comme une étape de post-traitement, ne
requiert aucun entrainement d’un modele de traduction supplémentaire.

Recherche locale pour la traduction statistique a base de segments

6 Conclusions et perspectives

Dans cette étude, nous avons développé un algorithme de recherche locale pour un systeme de
traduction statistique basé sur les segments. Nous avons discuté les avantages de notre approche
et avons réalisé des experiences la validant. Nous avons montré qu’une variante de cet algo-
rithme permet d’améliorer les traductions produites par le systeme a l’état de l’art Pharaoh.

Cette étude ouvre plusieurs perspectives. Nous souhaitons en particulier comparer différents
algorithmes de recherche locale, et étudier l’inﬂuence du processus de segmentation permet-
tant d’initialiser l’hypothese courante. Notre motivation initiale était d’explorer des approches
souples a la post-édition de traductions qui peuvent identiﬁer des erreurs systématiques dans les
traductions produites par un systeme donné. Un pas dans cette direction consiste a augmenter
le nombre de modeles utilisés dans la fonction de score et d’en ajuster les contributions via les
coefﬁcients qui leur sont associés.

Remerciements

Nous remercions les relecteurs pour leur commentaires pertinents.

Références

BERGER A. L., BROWN P. F., PIETRA S. A. D., PIETRA V. J. D., GILLETT J. R., LAF-
FERTY J. D., MERCER R. L., PRINTZ H. & URES L. (1994). The Candide system for
machine translation. In HLT, p. 157-162, Morristown, NJ, USA.

BESACIER L., MAHDHAOUI A. & LE V.-B. (2007). The LIG Arabic/English speech trans-
lation system at IWSLT 07. In 4th I WSLT, p. 137-140, Trento, Italy.

BRowN P. F., PIETRA S. A. D., PIETRA V. J. D. & MERCER R. L. (1993). The mathematics
of statistical machine translation : Parameter estimation. Computational Linguistics, 19(2),
263-31 1.

CHEN Y., EISELE A., FEDERMANN C., HASLER E., JELLINGHAUS M. & THEIsoN S.
(2007). Multi-engine machine translation with an open-source SMT decoder. In 2nd Workshop
on SMT, p. 193-196, Prague, Czech Republic.

CREGO J. M. & MARINO J. B. (2007). Extending MARIE : a N-gram-based smt decoder. In
ACL, Demo and Poster Sessions, p. 213-216, Prague.

DECHELOTTE D., SCHWENK H., BONNEAU-MAYNARD H., ALLAUZEN A. & ADDA G.
(2007). A state-of-the-art statistical machine translation system based on Moses. In Xlth MT
Summit, p. 127-133, Copenhagen, Denmark.

FOSTER G., GANDRABUR S., LANGLAIS P., PLAMONDON P., RUssEL G. & SIMARD M.
(2003). Statistical machine translation : Rapid development with limited resources. In MT
Summit IX, p. 110-117, New Orleans.

GARCIA I. & CASACUBERTA F. (2001). Search algorithms for statistical machine translation
based on dynamic programming and pruning techniques. In 8th MT Summit, p. 115-120,
Santiago de Compostela, Spain.

GERMANN U. (2003). Greedy decoding for statistical machine translation in almost linear
time. In HLT-NAACL, p. 72-79, Edmonton, Canada.

Langlais et al.

GERMANN U., JAHR M., KNIGHT K., MARCU D. & YAMADA K. (2001). Fast decoding
and optimal decoding for machine translation. In 39th ACL, p. 228-235, Toulouse, France.

KOEHN P. (2004). Pharaoh : a Beam Search Decoder for Phrase-Based SMT. In 6th AMTA,
p. 115-124, Washington, DC.

KOEHN P., FEDERICO M., SHEN W., BETOLDI N., HOANG H., CALLISON-BURCH C.,
COWAN B., ZENS R., DYER C., BOJAR 0., C.MORAN, CONSTANTIN A. & HERBST E.
(2006). Open Source Toolkit for Statistical Machine Translation .' Factored translation models
and confusion network decoding. University summer worskhop, Johns Hopkins University.

KOEHN P. & MONZ C. (2006). Manual and automatic evaluation of machine translation
between European languages. In 1 st Workshop on SMT, p. 102-121, New York City.

KOEHN P., OCH F. J. & MARCU D. (2003). Statistical Phrase-Based Translation. In HLT, p.
127-133.

LANGLAIS P., PATRY A. & GOTTI F. (2007). A greedy decoder for statistical phrase-based
machine translation. In 11th TMI, p. 104-113, Skovde, Sweden.

MARCU D. (2001). Towards a uniﬁed approach to memory- and statistical-based machine
translation. In 39th ACL, p. 378-385, Toulouse, France.

NIESSEN S., VOGEL S., NEY H. & TILLMANN C. (1998). A DP-based search algorithm
for statistical machine translation. In 36th ACL and 17th COLING, p. 960-966, Montréal,
Canada.

OLTEANU M., DAVIS C., VOLOSEN I. & MOLDOVAN D. (2006). Phramer - an open source
statistical phrased-based translator. In 1 st Workshop on SMT, p. 150-153, New York, USA.

PAPINENI K., ROUKOS S., WARD T. & ZHU W.-J. (2002). Bleu : a method for automatic
evaluation of machine translation. In Proceedings of the 40th ACL, p. 311-318, Philadelphia,
Pennsylvania.

PATRY A., GOTTI F. & LANGLAIS P. (2006). Mood : A modular object-oriented decoder for
statistical machine translation. In 5th LREC, p. 709-714, Genoa, Italy.

RUSSELL S. & NORVIG P. (1995). Artiﬁcial Intelligence. A Modern Approach. Prentice Hall.

SIMARD M., UEFF'ING N., ISABELLE P. & KUHN R. (2007). Rule-based translation with
statistical phrase-based post-editing. In 2nd Workshop on SMT, p. 203-206, Prague, Czech
Republic.

STOLCKE A. (2002). SRILM - an extensible language modeling toolkit. In ICSLP, Denver,
Colorado.

T ILLMANN C., VOGEL S., NEY H. & ZUBIAGA A. (1997). A DP-based search using mono-
tone alignments in statistical translation. In 35th ACL, p. 289-296, Madrid, Spain.

WANG Y.-Y. & WAIBEL A. (1997). Decoding algorithm in statistical machine translation. In
35th ACL, p. 366-372, Madrid, Spain.

WATANABE T. & SUMITA E. (2003). Example-based decoding for statistical machine trans-
lation. In MT Summit IX, p. 410-417, New Orleans, Louisiana.

ZHANG Y. & VOGEL S. (2004). Measuring conﬁdence intervals for the machine translation
evaluation metrics. In 10th TMI, p. 85-94, Baltimore, Maryland, USA.

