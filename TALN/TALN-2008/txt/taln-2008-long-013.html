<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Transcrire les SMS comme on reconna&#238;t la parole</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2008, Avignon, 9&#8211;13 juin 2008
</p>
<p>Transcrire les SMS comme on reconna&#238;t la parole
</p>
<p>Catherine Kobus1 Fran&#231;ois Yvon2 G&#233;raldine Damnati1
</p>
<p>(1) Orange Labs / 2, avenue Pierre Marzin, 22300 Lannion
(2) Univ. Paris Sud 11 &amp; LIMSI-CNRS, BP 133, 91403 Orsay Cedex
</p>
<p>R&#233;sum&#233;. Cet article pr&#233;sente une architecture inspir&#233;e des syst&#232;mes de reconnaissance
vocale pour effectuer une normalisation orthographique de messages en &#171; langage SMS &#187;. Nous
d&#233;crivons notre syst&#232;me de base, ainsi que diverses &#233;volutions de ce syst&#232;me, qui permettent
d&#8217;am&#233;liorer sensiblement la qualit&#233; des normalisations produites.
</p>
<p>Abstract. This paper presents a system aiming at normalizing the orthography of SMS
messages, using techniques that are commonly used in automatic speech recognition devices.
We describe a baseline system and various evolutions, which are shown to improve significantly
the quality of the output normalizations.
</p>
<p>Mots-cl&#233;s : SMS, d&#233;codage phon&#233;tique, mod&#232;les de langage, transducteurs finis.
</p>
<p>Keywords: SMS, phonetic decoding, language models, finite-state transducers.
</p>
<p>1 Introduction
</p>
<p>La diffusion des outils de communication &#233;lectronique (mails, SMS, blogs, forums de discus-
sion, chats, etc) a favoris&#233; l&#8217;&#233;mergence de nouvelles formes d&#8217;&#233;crits (Veronis &amp; Guimier de
Neef, 2006). Destin&#233;s &#224; des proches ou &#224; des pairs, r&#233;dig&#233;s dans l&#8217;instant, avec des interfaces
qui imposent des contraintes nouvelles (claviers d&#8217;ordinateurs, d&#8217;assistants personnels ou de t&#233;-
l&#233;phones portables), ces textes se caract&#233;risent par un net rel&#226;chement vis-&#224;-vis de la norme or-
thographique, ainsi que par de multiples d&#233;tournements de l&#8217;usage conventionnel des caract&#232;res
alphab&#233;tiques, utilis&#233;s non seulement pour encoder des formes linguistiques, mais &#233;galement
du m&#233;ta-discours (citations), des &#233;motions (col&#232;re, humour), des attitudes (emphase, d&#233;rision)
etc. Si chaque m&#233;dia impose des contraintes sp&#233;cifiques et se caract&#233;rise par des modes d&#8217;&#233;cri-
ture et des codes qui lui sont propres (voir, par exemple, (Torzec et al., 2001) pour les mails,
(Falaise, 2005) pour les chats, ou (Anis, 2001; Anis, 2002; Fairon et al., 2006) pour les SMS),
ces nouvelles formes de communication &#233;crite partagent de nombreuses similarit&#233;s. Face &#224; ces
textes d&#8217;un genre nouveau, il importe de d&#233;velopper de nouveaux outils de traitement automa-
tique, permettant, par exemple, de pouvoir indexer et effectuer des recherches dans des corpus
de messages. Dans cette &#233;tude, nous nous int&#233;ressons plus sp&#233;cifiquement aux SMS, messages
courts r&#233;dig&#233;s sur les claviers de t&#233;l&#233;phones portables, qui, nous semble-t-il, condensent &#224; l&#8217;ex-
tr&#234;me les difficult&#233;s que posent ces &#233;crits aux syst&#232;mes de traitement des langues.
</p>
<p>Le &#171; langage SMS &#187; a fait l&#8217;objet de plusieurs &#233;tudes linguistiques (Anis, 2001; Anis, 2002;
Fairon et al., 2006), qui permettent de cerner ses principales caract&#233;ristiques, notamment la
tr&#232;s forte variabilit&#233; graphique des formes lexicales. Cette variabilit&#233; r&#233;sulte, d&#8217;une part, de
l&#8217;utilisation simultan&#233;e de plusieurs syst&#232;mes d&#8217;encodage : pour dire vite , l&#8217;&#233;criture alphab&#233;-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Catherine Kobus, Fran&#231;ois Yvon, G&#233;raldine Damnati
</p>
<p>tique usuelle , est en comp&#233;tition avec une &#233;criture plus phon&#233;tique, ainsi qu&#8217;avec une &#233;criture
&#171; consonantique &#187; (seules subsistent les consonnes), enfin avec une &#233;criture &#171; r&#233;bus &#187; (lettres et
chiffres encodent la valeur phon&#233;tique de leur &#233;pellation). Elle d&#233;coule &#233;galement d&#8217;un style
de communication rel&#226;ch&#233;, qui autorise les plus grandes libert&#233;s par rapport &#224; la norme ortho-
graphique (non-respect des accords, des flexions verbales, etc). En cons&#233;quence, du point de
vue lexical, ces messages se caract&#233;risent par un tr&#232;s fort taux de mots &#171; hors-vocabulaire &#187;,
correspondant &#224; des n&#233;ographismes, ainsi que par une forte augmentation de l&#8217;ambigu&#239;t&#233; des
formes lexicales &#171; attest&#233;es &#187;. Restaurer une orthographe normalis&#233;e est donc un pr&#233;alable pour
pouvoir leur appliquer d&#8217;autres traitements (synth&#232;se vocale, indexation , etc.) ; elle repr&#233;sente
&#233;galement, du fait de la cr&#233;ativit&#233; des scripteurs, un s&#233;rieux d&#233;fi.
</p>
<p>Les travaux portant explicitement sur la normalisation automatique de SMS sont relativement
rares : mentionnons, pour le fran&#231;ais, (Guimier de Neef et al., 2007) qui aborde le probl&#232;me
sous l&#8217;angle de la correction orthographique et propose une cha&#238;ne compl&#232;te de traitements
symboliques pour effectuer cette correction ; (Barth&#233;lemy, 2007) est plus prospectif et sugg&#232;re
une mod&#233;lisation &#224; base d&#8217;automates finis permettant de g&#233;rer efficacement la concurrence entre
divers modes d&#8217;&#233;critures. Pour l&#8217;anglais, signalons (Aw et al., 2006), qui s&#8217;inspire des m&#233;thodes
utilis&#233;es en traduction statistique, ainsi que (Choudhury et al., 2007), dont le syst&#232;me de nor-
malisation utilise des m&#233;thodes statistiques de correction d&#8217;orthographe.
</p>
<p>Le syst&#232;me de normalisation pr&#233;sent&#233; dans cet article propose une approche diff&#233;rente, qui
cherche &#224; tirer parti de la proximit&#233;, relev&#233;e par de nombreux auteurs, entre les formes d&#8217;&#233;cri-
ture utilis&#233;es dans les SMS et la langue orale. Notre hypoth&#232;se est que le recensement (par
exemple dans un dictionnaire) de l&#8217;ensemble des variations orthographiques est vou&#233; &#224; l&#8217;&#233;chec.
Il semble comparativement plus ais&#233; de produire une repr&#233;sentation phon&#233;mique approximative
et ambigu&#235; d&#8217;un message, sous la forme d&#8217;un ensemble de phon&#233;tisations possibles, comme il
est commun de le faire en correction orthographique. La reconstruction d&#8217;un message norma-
lis&#233; est alors tr&#232;s similaire au d&#233;codage phon&#233;tique, puisqu&#8217;il s&#8217;agit de retrouver, dans un treillis
phon&#233;tique la s&#233;quence de mots la plus vraisemblable : il semble alors naturel d&#8217;utiliser, pour
ce probl&#232;me, des techniques utilis&#233;es en reconnaissance de la parole.
</p>
<p>Cet article est organis&#233; comme suit. Dans un premier temps, nous d&#233;crivons notre syst&#232;me de
base (section 2), avant de pr&#233;senter, &#224; la section 3, plusieurs &#233;volutions de ce syst&#232;me : am&#233;-
lioration du traitement des mots hors-vocabulaire ; introduction de grammaires locales pour les
heures et dates ; acquisition automatis&#233;e d&#8217;un dictionnaire d&#8217;exceptions. La section 4 pr&#233;sente
une &#233;valuation des performances du syst&#232;me de base et des &#233;volutions propos&#233;es, sur l&#8217;analyse
desquelles nous nous appuyons pour esquisser quelques perspectives (section 5).
</p>
<p>2 Architecture
</p>
<p>2.1 Principes g&#233;n&#233;raux
</p>
<p>Notre syst&#232;me de normalisation repose sur un principe d&#8217;expansion/contraction :
&#8211; dans un premier temps, le message est converti en un ensemble de s&#233;quences phon&#233;tiques
repr&#233;sentant toutes les prononciations possibles sous la forme d&#8217;un &#171; treillis &#187;1 de phon&#232;mes.
</p>
<p>&#8211; la conversion inverse est ensuite calcul&#233;e : transformation des s&#233;quences de phon&#232;mes en
</p>
<p>1Formellement, il s&#8217;agit d&#8217;un automate acyclique sur l&#8217;alphabet phon&#233;tique.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Transcrire les SMS comme on reconna&#238;t la parole
</p>
<p>SMS Pr&#233;-
traitements
</p>
<p>Traitement
des exceptions
</p>
<p>Phon&#233;tisation
</p>
<p>Dictionnaire
inverse
</p>
<p>Mod&#232;le de
langage
</p>
<p>SMS normalis&#233;
</p>
<p>S&#233;quence alphab&#233;tique
</p>
<p>Graphe alphab&#233;tique
</p>
<p>Graphe phon&#233;tique
</p>
<p>Graphe de motsS&#233;quence de mots
</p>
<p>FIG. 1 &#8211; &#201;tapes de la normalisation du SMS
</p>
<p>s&#233;quences de mots par acc&#232;s dictionnairique, puis s&#233;lection, par un mod&#232;le de langage statis-
tique, de la meilleure s&#233;quence de mots. Cette &#233;tape est identique aux calculs effectu&#233;s dans
un syst&#232;me de reconnaissance vocale : a ceci pr&#232;s que dans notre cas, l&#8217;incertitude sur les
phon&#232;mes et sur les positions des fronti&#232;res de mots est bien moins grande.
</p>
<p>Une vue sch&#233;matique des traitements r&#233;alis&#233;s dans le syst&#232;me de base est donn&#233;e Figure 1.
Apr&#232;s pr&#233;traitement du SMS, la normalisation d&#233;bute par le traitement des exceptions et des
abr&#233;viations (&quot;pr&quot; pour &quot;pour&quot; ou &quot;par&quot;, &quot;bcp&quot; pour &quot;beaucoup&quot;, etc), qui sont &#224; la fois tr&#232;s
fr&#233;quentes en langage SMS et difficiles &#224; mod&#233;liser autrement que par construction de listes.
Durant cette &#233;tape, les mots du message sont analys&#233;s et chaque forme trouv&#233;e dans le diction-
naire d&#8217;exception est mise en comp&#233;tition avec le ou les expansions associ&#233;es. Notons que la
forme originale est conserv&#233;e, car elle n&#8217;a pas n&#233;cesssairement &#233;t&#233; utilis&#233;e comme abr&#233;viation.
L&#8217;expansion des exceptions est donc non-d&#233;terministe et produit un treillis de formes.
</p>
<p>La troisi&#232;me &#233;tape est la phon&#233;tisation, qui utilise des r&#232;gles de r&#233;criture contextuelles non-
d&#233;terministes d&#233;crivant les correspondances graph&#232;me-phon&#232;me. Une r&#232;gle est formalis&#233;e par :
</p>
<p>&#966; [a]&#968; &#8594; [b]
qui exprime la r&#233;criture du motif a en b dans un contexte d&#233;crit par les expressions rationnelles
&#966; et &#968;. Le non-d&#233;terminisme de ces r&#232;gles, c.-&#224;-d. la possibilit&#233; que le langage d&#233;not&#233; par b
contienne plusieurs mots est inhabituel en transcription graph&#232;me-phon&#232;me : c&#8217;est toutefois un
aspect crucial du syst&#232;me, qui assure que l&#8217;espace des prononciations possibles est compl&#232;te-
ment envisag&#233;. Par exemple, la r&#232;gle de prononciation la plus g&#233;n&#233;rale de la lettre &#8217;c&#8217; lui associe
les quatre prononciations : /k/, /s/, /sE/, /se/ : si les deux premi&#232;res prononciations sont atten-
dues, les deux suivantes expriment la possibilit&#233; que cette lettre soit utilis&#233;e phon&#233;tiquement
(et doive donc &#234;tre &#171; &#233;pel&#233;e &#187;). Les exceptions d&#233;tect&#233;es lors de la premi&#232;re &#233;tape subissent ici
un traitement particulier : dans la mesure o&#249; ces formes sont d&#233;j&#224; normalis&#233;es, la phon&#233;tisation
s&#8217;applique de fa&#231;on d&#233;terministe, par acc&#232;s &#224; un dictionnaire de prononciation.
</p>
<p>La suite du traitement utilise les ressources suivantes :</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Catherine Kobus, Fran&#231;ois Yvon, G&#233;raldine Damnati
</p>
<p>&#8211; un dictionnaire de prononciation, utilis&#233; pour convertir des s&#233;quences de phon&#232;mes en s&#233;-
quences de mots ;
</p>
<p>&#8211; un mod&#232;le de langage statistique, qui permet d&#8217;ordonner par probabilit&#233; croissante les s&#233;-
quences de mots ;
</p>
<p>L&#8217;acc&#232;s au dictionnaire permet de d&#233;gager, &#224; partir du graphe de phon&#232;mes, l&#8217;ensemble des
s&#233;quences de mots possibles ; le mod&#232;le de langage permet de pond&#233;rer l&#8217;ensemble des hypo-
th&#232;ses de phrases possibles ; enfin, un algorithme de programmation dynamique s&#233;lectionne la
s&#233;quence de mots la plus probable.
</p>
<p>2.2 Impl&#233;mentation
</p>
<p>Chacun de ces modules peut &#234;tre implant&#233; par des automates ou transducteurs finis &#233;ventuel-
lement pond&#233;r&#233;s. C&#8217;est le cas des deux dictionnaires d&#233;crits dans la section pr&#233;c&#233;dente : le
dictionnaire d&#8217;exception r&#233;alise une transduction de s&#233;quences orthographiques en s&#233;quences
de phon&#232;mes (transducteur E), l&#8217;inverse du dictionnaire de prononciation (transducteur D) as-
socie des s&#233;quences de mots &#224; des s&#233;quences de phon&#232;mes. C&#8217;est encore le cas du module
appliquant des r&#232;gles de phon&#233;tisation contextuelles (Kaplan &amp; Kay, 1994; Mohri et al., 1996),
qui sont globalement compil&#233;es en un transducteur R, ainsi que du mod&#232;le de langage de type
n-gramme, repr&#233;sent&#233; par un accepteur pond&#233;r&#233; L. Ces transducteurs sont construits , pour les
trois premiers, par des scripts ad-hoc et par les outils de la suite GRM (Allauzen et al., 2005)
pour le mod&#232;le de langage. Une fois le message en entr&#233;e converti en un automate fini M par
le module de pr&#233;traitement2, l&#8217;ensemble des r&#233;critures r&#233;alisant la normalisation est prise en
charge par les op&#233;rations suivantes :
&#8211; construction de l&#8217;ensemble des s&#233;quences de mots possibles pourM , pond&#233;r&#233;es par leur pro-
babilit&#233; pour le mod&#232;le de langage. Cette op&#233;ration est r&#233;alis&#233;e par composition des diff&#233;rents
transducteurs : T =M &#9702;E &#9702;R &#9702;D &#9702;L, dont on ne conserve par projection que le langage de
sortie &#928;2(T ).
</p>
<p>&#8211; recherche de la s&#233;quence de probabilit&#233; maximale dans &#928;2(T ) par un algorithme calculant
des plus courts chemins dans un graphe valu&#233;.
</p>
<p>Il est possible d&#8217;optimiser ce traitement en pr&#233;calculant E &#9702; R &#9702;D &#9702; L, ainsi qu&#8217;en optimisant
(par d&#233;terminisation3 et minimisation) pr&#233;alablement D &#9702; L selon des proc&#233;d&#233;s usuellement
utilis&#233;s en reconnaissance vocale. L&#8217;ensemble de ces op&#233;rations est r&#233;alis&#233;e par les outils de la
suite de manipulation de transducteurs finis FSM (Mohri et al., 2000).
</p>
<p>Le passage par une repr&#233;sentation phon&#233;tique comporte un avantage suppl&#233;mentaire : dans l&#8217;op-
tique d&#8217;une vocalisation des SMS, il permet de produire sans calcul suppl&#233;mentaire non seule-
ment la forme orthographique normalis&#233;e, mais &#233;galement la forme phon&#233;tique associ&#233;e &#224; cette
normalisation.
</p>
<p>2.3 Le traitement des fronti&#232;res de mots
</p>
<p>L&#8217;architecture d&#233;crite ci-dessus permet de traiter simplement la question des fronti&#232;re de mots.
Il est courant de trouver dans les messages des formes agglutin&#233;es telles que :
</p>
<p>2Ce module accomplit &#233;galement certaines op&#233;rations de normalisation : traitement rudimentaire des chiffres,
insertion de marques de d&#233;buts et de fin de phrase, etc.
</p>
<p>3Comme il est usuel en reconnaissance vocale, la d&#233;terminisation est r&#233;alis&#233;e en traitant le mot de longueur
nulle &#949; comme un symbole &#224; part enti&#232;re.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Transcrire les SMS comme on reconna&#238;t la parole
</p>
<p>(1) Kestu fe ?
</p>
<p>(2) ... avec lbac blanc ...
</p>
<p>(3) g &#233;say&#233; 2tapel&#233; pl1 2foi (exemple tir&#233; de (Guimier de Neef et al., 2007))
</p>
<p>Ces exemples sont notoirement difficiles &#224; traiter par des syst&#232;mes symboliques (Guimier de
Neef et al., 2007). Pour autant, les messages &#224; normaliser sont partiellement segment&#233;s (espaces,
ponctuations) ; cette information est relativement fiable et doit &#234;tre utilis&#233;e. Notre architecture
</p>
<p>1 2
</p>
<p>3
</p>
<p>0/0
</p>
<p>4
</p>
<p>5
6
</p>
<p>&lt;eps&gt;:&lt;eps&gt;
</p>
<p>_#:&lt;eps&gt;
</p>
<p>p:paul
</p>
<p>O:&lt;eps&gt;
</p>
<p>l:&lt;eps&gt;
</p>
<p>_#:&lt;eps&gt;
</p>
<p>&lt;eps&gt;:&lt;eps&gt;
</p>
<p>l:louis
</p>
<p>w:&lt;eps&gt;
i:&lt;eps&gt;
</p>
<p>FIG. 2 &#8211; Gestion des fronti&#232;res de mots dans le dictionnaire inverse de prononciation
</p>
<p>permet &#224; la fois d&#8217;utiliser les informations de segmentation disponibles, en tout autorisant l&#8217;in-
sertion de nouvelles fronti&#232;res de mots. Ceci est r&#233;alis&#233; par la proc&#233;dure de construction du
transducteur repr&#233;sentant le dictionnaire inverse de prononciation D. Ce transducteur poss&#232;de
l&#8217;allure d&#8217;un arbre des pr&#233;fixes, chaque branche correspondant &#224; une s&#233;quence de phon&#232;mes le
long de laquelle le mot orthographique correspondant est &#233;mis. Deux transitions &#171; rebouclent &#187;
sur l&#8217;&#233;tat initial : l&#8217;une est &#233;tiquet&#233;e par le symbole /_#/, qui repr&#233;sente un s&#233;parateur explicite ;
l&#8217;autre est une transition &#949;, qui permet de d&#233;marrer la reconnaissance d&#8217;un nouveau mot alors
m&#234;me qu&#8217;aucun s&#233;parateur ne figure dans l&#8217;entr&#233;e. En pond&#233;rant diff&#233;rentiellement ces deux
transitions, on exprime une plus ou moins grande pr&#233;f&#233;rence envers une segmentation qui res-
pecterait les s&#233;parateurs originaux. Ce m&#233;canisme est illustr&#233; &#224; la figure 2, qui repr&#233;sente un
dictionnaire contenant les deux mots louis et paul. Deux transitions bouclent sur l&#8217;&#233;tat 0 &#224; partir
de l&#8217;&#233;tat 6 (fin de louis) : l&#8217;un est une transition &#949;. L&#8217;emprunter signifie qu&#8217;on introduit une
fronti&#232;re de mot qui est absente du message original ; l&#8217;autre est &#233;tiquet&#233;e _# : elle est utilis&#233;e
si l&#8217;on rencontre un s&#233;parateur dans le message.
</p>
<p>En revanche, il n&#8217;est pas possible, dans ce sch&#233;ma, que deux mots soient &#171; recoll&#233;s &#187; : tout
s&#233;parateur pr&#233;sent dans l&#8217;entr&#233;e sera &#233;galement pr&#233;sent dans la sortie. Ceci rend notre syst&#232;me
incapable de traiter correctement des entr&#233;es telles que &quot;je ne pep a mpaC dtoi&quot; ou encore &quot;slt
le zami&quot; dans lequel des formes sont incorrectement segment&#233;es.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Catherine Kobus, Fran&#231;ois Yvon, G&#233;raldine Damnati
</p>
<p>3 &#201;volutions du syst&#232;me
</p>
<p>3.1 Le syst&#232;me baseline
</p>
<p>Le syst&#232;me tel d&#233;crit ci-dessus (cf section 2) correspond &#224; notre syst&#232;me baseline. Son lexique
contient de plus de 23000 mots. Nous avons &#233;galement utilis&#233; un dictionnaire de plus de 900
exceptions, ainsi qu&#8217;un ensemble de 140 r&#232;gles de phon&#233;tisation contextuelles. Les contextes
</p>
<p>m:m
</p>
<p>e:e
</p>
<p>y:y r:r a:a
</p>
<p>r:r
</p>
<p>g:g
_#:_# _#:_#
</p>
<p>m:&lt;HV&gt;
</p>
<p>e:&lt;eps&gt;
</p>
<p>y:&lt;eps&gt;
r:&lt;eps&gt;
</p>
<p>a:&lt;eps&gt;
</p>
<p>r:&lt;eps&gt;
</p>
<p>g:&lt;eps&gt;
</p>
<p>FIG. 3 &#8211; Gestion des mots hors-vocabulaire
</p>
<p>des r&#232;gles concernent principalement les d&#233;buts ou les fins de mots et aident &#224; d&#233;crire la pro-
nonciation des finales muettes (comme &#8217;t&#8217;, &#8217;s&#8217;, &#8217;p&#8217;, etc.). Pour la lettre &#8217;p&#8217;, nous avons ainsi
deux r&#232;gles contextuelles distinctes : la premi&#232;re traite le cas d&#8217;une fin de mot (lettre muette
autoris&#233;e, symbolis&#233;e par &#15;) ; la seconde r&#232;gle s&#8217;applique aux autres contextes.
</p>
<p>p &#8594; /p/ | /pe/ | /pE/ |&#15; si fin de mot, p &#8594; /p/ | /pe/ | /pE/ sinon
</p>
<p>3.2 Traitement des mots hors-vocabulaire
</p>
<p>Comme dans un syst&#232;me de reconnaissance vocale, le lexique de l&#8217;application de normalisation
de SMS est fini. Avec le syst&#232;me baseline, les mots du hors-vocabulaire (HV) du SMS ne sont
pas correctement trait&#233;s. Dans la mesure o&#249; ils ne peuvent &#234;tre restitu&#233;s tels quels en sortie du
syst&#232;me, ils sont resegment&#233;s en mots phon&#233;tiquement proches : ainsi, &quot;puiske t&#233; a meyrarg&quot;
(&quot;meyrarg&quot; est HV) produit &quot;puisque t&#8217; es a mis rare&quot; ). Pour y rem&#233;dier, le module de pr&#233;-
traitement a &#233;t&#233; compl&#233;t&#233; de fa&#231;on &#224; produire une hypoth&#232;se suppl&#233;mentaire, correspondant &#224; la
recopie du mot HV dans la sortie : ces mots, qui sont potentiellement corrects, peuvent alors fi-
gurer dans la meilleure solution. La figure 3 d&#233;taille la fa&#231;on dont sont g&#233;r&#233;s les mots HV dans le
formalisme des FSMs, en l&#8217;illustrant sur la forme &#171;meyrarg&quot;. Lors du pr&#233;-traitement, &quot;meyrarg&quot;
est reconnu comme mot HV : deux chemins alternatifs sont alors cr&#233;&#233;s. Le premier segmente
l&#8217;entr&#233;e en graph&#232;mes &#233;l&#233;mentaires, qui seront phon&#233;tis&#233;s. Le second chemin est identique, &#224;
l&#8217;insertion pr&#232;s d&#8217;une balise &lt;HV&gt;. Cette balise rend transparentes les &#233;tapes de phon&#233;tisation
et d&#8217;acc&#232;s au dictionnaire. La s&#233;quence graph&#233;mique figurera dans l&#8217;ensemble des hypoth&#232;ses
de s&#233;quences de mots et pourra &#234;tre s&#233;lectionn&#233;e par le mod&#232;le de langage. Un post-traitement
permet de retrouver le mot correspondant initialement &#224; cette balise.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Transcrire les SMS comme on reconna&#238;t la parole
</p>
<p>_#:_# _#:_#
</p>
<p>2:_HEURE_
</p>
<p>0:&lt;eps&gt;
</p>
<p>h:&lt;eps&gt;
</p>
<p>2:2
</p>
<p>0:0
</p>
<p>2:_NOMBRE_
</p>
<p>0:&lt;eps&gt; h:h
</p>
<p>FIG. 4 &#8211; Int&#233;gration de grammaires locales : traitement de la cha&#238;ne &quot;... 20h ...&quot;
</p>
<p>3.3 Utilisation de grammaires locales
</p>
<p>Une seconde am&#233;lioration concerne le traitement des heures et des nombres, tr&#232;s nombreux dans
le corpus des SMS ; initialement, les chiffres sont trait&#233;s comme les autres graph&#232;mes. Ainsi, un
nombre &#224; deux chiffres est syst&#233;matiquement segment&#233; en deux chiffres distincts. Nous avons
donc introduit des grammaires r&#233;guli&#232;res, compil&#233;es sous la forme de transducteurs finis ; la
composition avec le SMS pr&#233;trait&#233; fournit l&#8217;ensemble des analyses possibles des heures et des
nombres. Lorsqu&#8217;une heure ou un nombre est reconnu, la balise associ&#233;e est &#233;mise ; les &#233;tapes
de traitement des exceptions, de phon&#233;tisation et d&#8217;acc&#232;s au dictionnaire restent identiques.
Le mod&#232;le de langage est appliqu&#233; au graphe de mots et de balises. Ce dernier est appris au
pr&#233;alable sur le m&#234;me corpus d&#8217;apprentissage que pr&#233;c&#233;demment, apr&#232;s &#233;tiquetage des nombres
et des montants (la phrase &#8217;Je viens &#224; 20 h&#8217; devient &#8217;Je viens &#224; _HEURE_&#8217; ). La figure 4
illustre, pour cette m&#234;me entr&#233;e, la fa&#231;on dont sont d&#233;finies les grammaires locales pour les
heures et les nombres dans le formalisme des transducteurs finis. Lors du pr&#233;-traitement, les
formes sont segment&#233;es en graph&#232;mes &#233;l&#233;mentaires et mises sous la forme d&#8217;un automate. Les
grammaires r&#233;guli&#232;res d&#233;crivant les heures et les nombres sont &#233;galement mises sous la forme
d&#8217;un transducteur. La composition du SMS initial avec ce dernier permet de retrouver toutes
les instances d&#8217;heures et de nombres dans le SMS initial (Figure 4). Une balise associ&#233;e &#224;
chacune de ces grammaires est &#233;mise. Comme pour les mots hors-vocabulaire, ces balises sont
transparentes aux &#233;tapes de phon&#233;tisation et d&#8217;acc&#232;s au dictionnaire. Elles figureront alors dans
l&#8217;ensemble des normalisations possibles et pourront &#234;tre s&#233;lectionn&#233;es par le mod&#232;le de langage.
</p>
<p>3.4 Apprentissage automatique des exceptions
</p>
<p>Le syst&#232;me baseline int&#232;gre un dictionnaire d&#8217;abr&#233;viations construit manuellement par analyse
de corpus. Dans cette section, nous d&#233;crivons une m&#233;thode permettant d&#8217;apprendre automa-
tiquement les abr&#233;viations les plus fr&#233;quentes &#224; partir d&#8217;un corpus d&#8217;apprentissage contenant
d&#8217;une part, les SMS originaux, pr&#233;-trait&#233;s (suppression de la ponctuation et des majuscules)
et leur transcription d&#8217;autre part. Cette m&#233;thode est bas&#233;e sur les alignements automatiques et
l&#8217;extraction de segments bilingues utilis&#233;s dans les syst&#232;mes de traduction statistique.
</p>
<p>Des alignements automatiques sont calcul&#233;s pour le corpus d&#8217;apprentissage &#224; l&#8217;aide du logiciel
GIZA++ (Och &amp; Ney, 2003). La technique des refined alignments (Koehn et al., 2003) permet
de d&#233;duire des alignements automatiques crois&#233;s une table de traduction, donnant pour chaque
segment &#171; source &#187; (en langage SMS) l&#8217;ensemble des segments &#171; cible &#187; associ&#233;s (en fran&#231;ais
standard). Pour les abr&#233;viations, nous ne conservons que les segments &quot;source&quot; constitu&#233;s d&#8217;un
seul mot et les segments &quot;cibles&quot; constitu&#233;s d&#8217;au maximum 3 mots (par exemple, l&#8217;abr&#233;viation</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Catherine Kobus, Fran&#231;ois Yvon, G&#233;raldine Damnati
</p>
<p>&quot;jtm&quot; align&#233;e avec la s&#233;quence &quot;je t&#8217;aime&quot; ). Un score, s(t, w) est enfin estim&#233;e pour chaque
segment t appari&#233; avec w ; s(w) = maxt P (t|w) d&#233;note alors le meilleur score d&#8217;un segment
appari&#233; avec w. Seuls les appariements dont la forme source est suffisamment fr&#233;quente (plus
de 5 occurrences) et dont le score est sup&#233;rieur &#224; un certain ratio &#945; (fix&#233; ici &#224; 0.1) du meilleur
score ({t | s(t, w) &#8805; &#945;s(w)}) sont finalement conserv&#233;s. Ont ainsi &#233;t&#233; extraites 3264 abr&#233;via-
tions/exceptions nouvelles, auxquelles sont associ&#233;es leurs meilleures expansions. Notons que
toutes ces exceptions ne sont pas utiles car il est possible qu&#8217;une abr&#233;viation et le segment
associ&#233; aient la m&#234;me phon&#233;tisation.
</p>
<p>4 Exp&#233;riences
</p>
<p>4.1 Corpus et M&#233;triques
</p>
<p>Les exp&#233;riences utilisent deux corpus : le premier a &#233;t&#233; collect&#233; par l&#8217;universit&#233; d&#8217;Aix en Pro-
vence (Hocq, 2006; Guimier de Neef et al., 2007) ; il est constitu&#233; d&#8217;environ 9700 messages.
Le second corpus est issu d&#8217;une collecte organis&#233;e en Belgique par l&#8217;Universit&#233; Catholique de
Louvain, et comprend 30000 messages (Fairon et al., 2006). Un corpus d&#8217;apprentissage App
de 36704 SMS a &#233;t&#233; constitu&#233; en m&#233;langeant les deux corpus. Les 2998 SMS restants nous ont
servi de corpus de test Test. Le mod&#232;le de langage utilis&#233; dans les &#233;valuations est un mod&#232;le
de langage 3-gram liss&#233; en utilisant un lissage de type Kneser-Ney et estim&#233; sur le corpus App.
</p>
<p>Contrairement &#224; (Aw et al., 2006; Guimier de Neef et al., 2007), qui &#233;valuent leurs performances
en termes de mesure BLEU (Papineni et al., 2002), nous avons choisi d&#8217;&#233;valuer nos syst&#232;mes
en termes de taux d&#8217;erreurs mots ou WER (Word Error Rate), m&#233;trique qui est &#233;galement uti-
lis&#233;e en reconnaissance vocale. La mesure BLEU, qui s&#8217;appuie sur un d&#233;compte des n-grams
pr&#233;sents dans l&#8217;hypoth&#232;se et dans une r&#233;f&#233;rence, ne vaut que lorsque plusieurs r&#233;f&#233;rences sont
disponibles, comme il est commun en traduction automatique. Pour notre probl&#232;me, l&#8217;ambi-
gu&#239;t&#233; dans le choix de la transcription de r&#233;f&#233;rence est presque nulle justifiant le calcul de taux
d&#8217;erreurs par mots et par phrases.
</p>
<p>4.2 R&#233;sultats
</p>
<p>Le tableau 4.2 d&#233;taille les r&#233;sultats obtenus et permet d&#8217;appr&#233;cier l&#8217;impact des am&#233;liorations
apport&#233;es au syst&#232;me. Le syst&#232;me baseline donne un WER de 19.79% ; la majorit&#233; des erreurs
sont des erreurs de substitution, qui portent souvent sur des mots courts comme &#8217;les&#8217; &#8596; &#8217;le&#8217;,
&#8217;j&#8221; &#8596; &#8217;je&#8217;, &#8217;des&#8217; &#8596; &#8217;de&#8217;, etc. Dans une majorit&#233; des cas, le mot est pourtant bien orthographi&#233;
dans le SMS, mais l&#8217;&#233;tape de phon&#233;tisation r&#233;introduit une ambigu&#239;t&#233; que le mod&#232;le de langage
ne parvient pas toujours &#224; compenser. La deuxi&#232;me ligne du tableau 4.2 montre l&#8217;apport du
traitement des mots hors-vocabulaire, qui permet de diminuer principalement le nombre d&#8217;in-
sertions ; en effet le syst&#232;me baseline avait tendance &#224; segmenter les mots HV en plusieurs petits
mots proches phon&#233;tiquement et donc &#224; commettre plus d&#8217;insertions. Sur l&#8217;exemple de &quot;puisk
t&#233; a meyrarg ...&quot;, le syst&#232;me baseline fournit &quot;puisque t&#8217;es &#224; mes ir argh&quot;, sortie qui est corrig&#233;e
par le traitement des mots HV.
</p>
<p>L&#8217;utilisation des grammaires locales (pour les nombres et les heures) am&#233;liore globalement les
r&#233;sultats en termes de WER ; moins d&#8217;erreurs sont commises sur les nombres. L&#8217;introduction</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Transcrire les SMS comme on reconna&#238;t la parole
</p>
<p>de ces grammaires am&#233;liore &#233;galement la capacit&#233; de g&#233;n&#233;ralisation du mod&#232;le de langage. Cet
effort d&#8217;introduction de grammaires locales doit donc &#234;tre poursuivi. Les deux derni&#232;res lignes
</p>
<p>WER Ins. Sub. Del.
baseline 19.79% 4.76% 13.44% 1.59%
</p>
<p>Traitement des mots HV 18.13% 2.51% 12.83% 2.80%
Utilisation de grammaires 17.58% 2.54% 12.68% 2.35%
Abr&#233;viations automatiques 16.96% 2.56% 12.10% 2.30%
</p>
<p>Combinaison 16.51% 2.21% 11.94% 2.36%
</p>
<p>TAB. 1 &#8211; Apport et &#233;valuations des diff&#233;rentes am&#233;liorations apport&#233;es
</p>
<p>du tableau 4.2 chiffrent l&#8217;apport de l&#8217;apprentissage automatique des exceptions par rapport &#224;
l&#8217;utilisation d&#8217;abr&#233;viations collect&#233;es manuellement. Les performances sont am&#233;lior&#233;es signi-
ficativement en termes de WER, d&#233;montrant la validit&#233; de l&#8217;approche propos&#233;e. Les r&#233;sultats
sont encore am&#233;lior&#233;s en combinant les deux dictionnaires d&#8217;abr&#233;viations.
</p>
<p>5 Bilan et Perspectives
</p>
<p>Nous avons pr&#233;sent&#233;, dans cet article, une nouvelle approche pour la normalisation des SMS,
bas&#233;e sur un d&#233;codage phon&#233;tique. Les diff&#233;rentes &#233;volutions ont permis d&#8217;am&#233;liorer sensible-
ment les performances du syst&#232;me baseline, qui sont probablement sous-estim&#233;es par la m&#233;-
trique WER : de nombreuses erreurs correspondent &#224; des probl&#232;mes d&#8217;accord, que le mod&#232;le
de langage &#233;choue &#224; corriger. Ces erreurs sont pourtant sans cons&#233;quence dans une perspective
de vocalisation car elles correspondent le plus souvent &#224; la perte ou &#224; l&#8217;ajout d&#8217;un morph&#232;me
flexionnel &#171; muet &#187;. Ces erreurs sont &#233;galement b&#233;nignes dans une optique d&#8217;indexation auto-
matique.
</p>
<p>Le syst&#232;me actuel peut toutefois &#234;tre am&#233;lior&#233; de multiples fa&#231;ons :
&#8211; les SMS contiennent de nombreuses formes qui sont correctement orthographi&#233;es : apr&#232;s
phon&#233;tisation, cette information est perdue. Une approche qui semble meilleure consiste &#224;
chercher celles qui existent dans le dictionnaire D et &#224; les phon&#233;tiser par acc&#232;s direct ; il
faudra ensuite exprimer, par des pond&#233;rations, que l&#8217;on pr&#233;f&#232;re utiliser une suite phon&#233;mique
extraite du dictionnaire plut&#244;t qu&#8217;une suite produite par des r&#232;gles.
</p>
<p>&#8211; les r&#232;gles de conversion graph&#232;me-phon&#232;me (module E) sont exag&#233;r&#233;ment lib&#233;rales. Si le
non-d&#233;terminisme doit &#234;tre pr&#233;serv&#233;, il importerait de le mod&#233;rer en pond&#233;rant les diff&#233;rentes
sorties des r&#232;gles de r&#233;criture : s&#8217;il est correct d&#8217;autoriser la lettre &#8217;&#233; &#8217; &#224; valoir /e/ ou /E/, il est
probable que l&#8217;on gagnerait &#224; rendre une des deux options plus probable que l&#8217;autre.
</p>
<p>&#8211; nous avons pour l&#8217;instant supprim&#233; toute information li&#233;e &#224; la ponctuation, aux majuscules ;
cette information pourrait nous &#234;tre utile pour segmenter le SMS et ainsi am&#233;liorer le pouvoir
pr&#233;dictif du mod&#232;le de langage.
</p>
<p>Remerciements
</p>
<p>Les auteurs remercient &#201;milie Guimier de Neef (Orange Labs) pour avoir mis &#224; disposition la
liste d&#8217;abr&#233;viations ainsi que les diff&#233;rents corpus.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Catherine Kobus, Fran&#231;ois Yvon, G&#233;raldine Damnati
</p>
<p>R&#233;f&#233;rences
</p>
<p>ALLAUZEN C., MOHRI M. &amp; ROARK B. (2005). The design principles and algorithms of a
weighted grammar library. International Journal of Foundations of Computer Science, 16(3),
403&#8211;421.
</p>
<p>ANIS J. (2001). Parlez-vous texto ? Guide des nouveaux langages du r&#233;seau. &#201;ditions du
Cherche Midi.
</p>
<p>ANIS J. (2002). Communication &#233;lectronique scipturale et formes langagi&#232;res : chats et SMS.
Actes des journ&#233;es &quot;S&#8217;&#233;crire avec les outils d&#8217;aujourd&#8217;hui&quot;.
</p>
<p>AW A., ZHANG M., XIAO J. &amp; SU J. (2006). A phrase-based statistical model for SMS text
normalization. In Proc. COLING/ACL, p. 33&#8211;40.
</p>
<p>BARTH&#201;LEMY F. (2007). Cun&#233;iforme et SMS : analyse graph&#233;mique de syst&#232;mes d&#8217;&#233;criture
h&#233;t&#233;rog&#232;nes. In Colloque Lexique et grammaire, Bonifacio.
</p>
<p>CHOUDHURY M., SARAF R., JAIN V., SARKAR S. &amp; BASU A. (2007). Investigation and
modeling of the structure of texting language. In Proceedings of the IJCAI Workshop on
&quot;Analytics for Noisy Unstructured Text Data&quot;, p. 63&#8211;70, Hyderabad, India.
</p>
<p>FAIRON C., KLEIN J. R. &amp; PAUMIER S. (2006). Le langage SMS. UCL Presses Universitaires
de Louvain.
</p>
<p>FALAISE A. (2005). Constitution d&#8217;un corpus de fran&#231;ais tchat&#233;. In Actes de TALN, p. 615&#8211;
624, Dourdan.
</p>
<p>GUIMIER DE NEEF E., DEBEURME A. &amp; PARK J. (2007). TILT correcteur de SMS : &#233;valua-
tion et bilan quantitatif. In Actes de TALN, p. 123&#8211;132, Toulouse.
</p>
<p>HOCQ S. (2006). &#201;tude des SMS en fran&#231;ais : constitution et exploitation d&#8217;un corpus align&#233;
SMS-langue standard. Rapport interne, Universit&#233; Aix-Marseille.
</p>
<p>KAPLAN R. &amp; KAY M. (1994). Regular models of phonological rule systems. Computational
Linguistics, 20(3), 331&#8211;378.
KOEHN P., OCH F. J. &amp; MARCU D. (2003). Statistical phrase-based translation. In Proc.
NAACL-HLT, p. 127&#8211;133, Edmondton, Canada.
</p>
<p>MOHRI M., PEREIRA F. &amp; RILEY M. (1996). An efficient compiler for weighted rewrite
rules. In Proceedings of the annual Meeting of the ACL, p. 231&#8211;238.
</p>
<p>MOHRI M., PEREIRA F. &amp; RILEY M. (2000). The design principles of a weighted finite-state
transducer library. Theoretical Computer Science, 231, 17&#8211;32.
OCH F. J. &amp; NEY H. (2003). A systematic comparison of various statistical alignment models.
Computational Linguistics, 29(1), 19&#8211;51.
PAPINENI K., ROUKOS S., WARD T. &amp; ZHU W.-J. (2002). Bleu : a method for automatic
evaluation of machine translation. In Proc. ACL, p. 311&#8211;318, Philadelphia, PA.
</p>
<p>TORZEC N., MOUDENC T. &amp; EMERARD F. (2001). Pr&#233;traitement et analyse linguistique
dans le syst&#232;me de synth&#232;se tts cvox : Application &#224; la vocalisation automatique d&#8217;e-mails. In
Actes de TALN, Nancy.
</p>
<p>VERONIS J. &amp; GUIMIER DE NEEF E. (2006). Le traitement des nouvelles formes de commu-
nication &#233;crite. In G. SABAH, Ed., Compr&#233;hension automatique des langues et interaction, p.
227&#8211;248 : Paris : Herm&#232;s Science.</p>

</div></div>
</body></html>