TALN 2008, Avignon, 9-13 juin 2008

Transcrire les SMS comme on reconnait la parole

Catherine Kobusl Francois Yvon2 Geraldine Damnatil
(1) Orange Labs / 2, avenue Pierre Marzin, 22300 Lannion
(2) Univ. Paris Sud 11 & LIMSI-CNRS, BP 133, 91403 Orsay Cedex

Résumé. Cet article présente une architecture inspirée des systemes de reconnaissance
vocale pour effectuer une normalisation orthographique de messages en « langage SMS ». Nous
décrivons notre systeme de base, ainsi que diverses évolutions de ce systeme, qui permettent
d’améliorer sensiblement la qualité des normalisations produites.

Abstract. This paper presents a system aiming at normalizing the orthography of SMS
messages, using techniques that are commonly used in automatic speech recognition devices.
We describe a baseline system and various evolutions, which are shown to improve signiﬁcantly
the quality of the output normalizations.

M0tS-CléS 2 SMS, décodage phonétique, modeles de langage, transducteurs ﬁnis.

Keywords: SMS, phonetic decoding, language models, ﬁnite-state transducers.

1 Introduction

La diffusion des outils de communication électronique (mails, SMS, blogs, forums de discus-
sion, chats, etc) a favorisé l’émergence de nouvelles formes d’écrits (Veronis & Guimier de
Neef, 2006). Destinés a des proches ou a des pairs, rédigés dans l’instant, avec des interfaces
qui imposent des contraintes nouvelles (claviers d’ordinateurs, d’assistants personnels ou de té-
léphones portables), ces textes se caractérisent par un net relachement vis-a-vis de la norme or-
thographique, ainsi que par de multiples détournements de l’usage conventionnel des caracteres
alphabétiques, utilisés non seulement pour encoder des formes linguistiques, mais également
du méta-discours (citations), des émotions (colere, humour), des attitudes (emphase, dérision)
etc. Si chaque média impose des contraintes spéciﬁques et se caractérise par des modes d’écri-
ture et des codes qui lui sont propres (voir, par exemple, (Torzec et al., 2001) pour les mails,
(Falaise, 2005) pour les chats, ou (Anis, 2001; Anis, 2002; Fairon et al., 2006) pour les SMS),
ces nouvelles formes de communication écrite partagent de nombreuses similarités. Face 51 ces
textes d’un genre nouveau, il importe de développer de nouveaux outils de traitement automa-
tique, permettant, par exemple, de pouvoir indexer et effectuer des recherches dans des corpus
de messages. Dans cette étude, nous nous intéressons plus spéciﬁquement aux SMS, messages
courts rédigés sur les claviers de téléphones portables, qui, nous semble-t-il, condensent a l’ex-
tréme les difﬁcultés que posent ces écrits aux systemes de traitement des langues.

Le « langage SMS » a fait l’objet de plusieurs études linguistiques (Anis, 2001; Anis, 2002;
Fairon et al., 2006), qui permettent de cerner ses principales caractéristiques, notamment la
tres forte variabilité graphique des formes lexicales. Cette variabilité résulte, d’une part, de
l’utilisation simultanée de plusieurs systemes d’encodage : pour dire Vite , l’écriture alphabe-

Catherine Kobus, Francois Yvon, Géraldine Damnati

tique usuelle , est en compétition avec une écriture plus phonétique, ainsi qu’avec une écriture
« consonantique » (seules subsistent les consonnes), enﬁn avec une écriture « rébus » (lettres et
chiffres encodent la valeur phonétique de leur épellation). Elle découle également d’un style
de communication relaché, qui autorise les plus grandes libertés par rapport a la norme ortho-
graphique (non-respect des accords, des ﬂexions verbales, etc). En conséquence, du point de
vue lexical, ces messages se caractérisent par un tres fort taux de mots « hors-vocabulaire »,
correspondant a des néographismes, ainsi que par une forte augmentation de l’ambigui'té des
formes lexicales « attestées ». Restaurer une orthographe normalisée est donc un préalable pour
pouvoir leur appliquer d’autres traitements (synthese vocale, indexation , etc.); elle représente
également, du fait de la créativité des scripteurs, un sérieux déﬁ.

Les travaux portant explicitement sur la normalisation automatique de SMS sont relativement
rares : mentionnons, pour le francais, (Guimier de Neef et al., 2007) qui aborde le probleme
sous l’angle de la correction orthographique et propose une chaine complete de traitements
symboliques pour effectuer cette correction; (Barthélemy, 2007) est plus prospectif et suggere
une modélisation a base d’automates ﬁnis permettant de gérer efﬁcacement la concurrence entre
divers modes d’écritures. Pour l’anglais, signalons (Aw et al., 2006), qui s’inspire des méthodes
utilisées en traduction statistique, ainsi que (Choudhury et al., 2007), dont le systeme de nor-
malisation utilise des méthodes statistiques de correction d’orthographe.

Le systeme de normalisation présenté dans cet article propose une approche différente, qui
cherche a tirer parti de la proximité, relevée par de nombreux auteurs, entre les formes d’écri-
ture utilisées dans les SMS et la langue orale. Notre hypothese est que le recensement (par
exemple dans un dictionnaire) de l’ensemble des variations orthographiques est voué a l’échec.
I1 semble comparativement plus aisé de produire une représentation phonémique approximative
et ambigue d’un message, sous la forme d’un ensemble de phonétisations possibles, comme il
est commun de le faire en correction orthographique. La reconstruction d’un message norma-
lisé est alors tres similaire au décodage phonétique, puisqu’il s’agit de retrouver, dans un treillis
phonétique la séquence de mots la plus vraisemblable : il semble alors naturel d’uti1iser, pour
ce probleme, des techniques utilisées en reconnaissance de la parole.

Cet article est organisé comme suit. Dans un premier temps, nous décrivons notre systeme de
base (section 2), avant de présenter, a la section 3, plusieurs évolutions de ce systeme : ame-
lioration du traitement des mots hors-vocabulaire; introduction de grammaires locales pour les
heures et dates; acquisition automatisée d’un dictionnaire d’exceptions. La section 4 présente
une évaluation des performances du systeme de base et des évolutions proposées, sur l’analyse
desquelles nous nous appuyons pour esquisser quelques perspectives (section 5).

2 Architecture

2.1 Principes généraux

Notre systeme de normalisation repose sur un principe d’expansion/contraction :

— dans un premier temps, le message est converti en un ensemble de séquences phonétiques
représentant toutes les prononciations possibles sous la forme d’un « treillis »1 de phonemes.

— la conversion inverse est ensuite calculée : transformation des séquences de phonemes en

1Formellement, il s’agit d’un automate acyclique sur l’alphabet phonétique.

Transcrire les SMS come on reconnait la parole

 
 

Séquence alphabétique
tra1tements des exce t1ons
Graphe alphabétique
Phonétisation
Graphe phonétique
SMS normalisé Modéle de
lan a e inverse

Séquence de mots Graphe de mots

FIG. 1 — Etapes de la normalisation du SMS

séquences de mots par acces dictionnairique, puis sélection, par un modele de langage statis-

tique, de la meilleure séquence de mots. Cette étape est identique aux calculs effectués dans

un systeme de reconnaissance vocale : a ceci pres que dans notre cas, l’incertitude sur les

phonemes et sur les positions des frontieres de mots est bien moins grande.
Une vue schématique des traitements réalisés dans le systeme de base est donnée Figure 1.
Apres prétraitement du SMS, la normalisation débute par le traitement des exceptions et des
abréviations ("pr" pour "pour" ou "par", "bcp" pour "beaucoup", etc), qui sont a la fois tres
fréquentes en langage SMS et difﬁciles a modéliser autrement que par construction de listes.
Durant cette étape, les mots du message sont analysés et chaque forme trouvée dans le diction-
naire d’exception est mise en compétition avec le ou les expansions associées. Notons que la
forme originale est conservée, car elle n’a pas nécesssairement été utilisée comme abréviation.
L’ expansion des exceptions est donc non-déterministe et produit un treillis de formes.

La troisieme étape est la phonétisation, qui utilise des regles de récriture contextuelles non-
déterministes décrivant les correspondances grapheme-phoneme. Une regle est formalisée par :

(Mali/I —> [bl

qui exprime la récriture du motif (1 en b dans un contexte décrit par les expressions rationnelles
qﬁ et 1/). Le non-déterminisme de ces regles, c.-a-d. la possibilité que le langage dénoté par b
contienne plusieurs mots est inhabituel en transcription grapheme-phoneme : c’est toutefois un
aspect crucial du systeme, qui assure que l’espace des prononciations possibles est complete-
ment envisagé. Par exemple, la regle de prononciation la plus générale de la lettre ’c’ lui associe
les quatre prononciations : /k/, /s/, /S8/, /se/ : si les deux premieres prononciations sont atten-
dues, les deux suivantes expriment la possibilité que cette lettre soit utilisée phonétiquement
(et doive donc étre « épelée »). Les exceptions détectées lors de la premiere étape subissent ici
un traitement particulier : dans la mesure o1‘1 ces formes sont déja normalisées, la phonétisation
s’applique de facon déterministe, par acces a un dictionnaire de prononciation.

La suite du traitement utilise les ressources suivantes :

Catherine Kobus, Francois Yvon, Geraldine Damnati

— un dictionnaire de prononciation, utilisé pour convertir des séquences de phonemes en se-
quences de mots ;
— un modele de langage statistique, qui permet d’ordonner par probabilité croissante les se-
quences de mots ;
L’acces au dictionnaire permet de dégager, a partir du graphe de phonemes, l’ensemble des
séquences de mots possibles; le modele de langage permet de pondérer l’ensemble des hypo-
theses de phrases possibles; enﬁn, un algorithme de programmation dynarnique sélectionne la
séquence de mots la plus probable.

2.2 Implémentation

Chacun de ces modules peut étre implanté par des automates ou transducteurs ﬁnis éventuel-

lement pondérés. C’est le cas des deux dictionnaires décrits dans la section précédente : le

dictionnaire d’eXception réalise une transduction de séquences orthographiques en séquences
de phonemes (transducteur E), l’inverse du dictionnaire de prononciation (transducteur D) as-
socie des séquences de mots a des séquences de phonemes. C’est encore le cas du module

appliquant des regles de phonétisation contextuelles (Kaplan & Kay, 1994; Mohri et al., 1996),

qui sont globalement compilées en un transducteur R, ainsi que du modele de langage de type

n-gramme, représenté par un accepteur pondéré L. Ces transducteurs sont construits , pour les

trois premiers, par des scripts ad-hoc et par les outils de la suite GRM (Allauzen et al., 2005)

pour le modele de langage. Une fois le message en entrée converti en un automate ﬁni M par

le module de prétraitementz, l’ensemble des récritures réalisant la normalisation est prise en
charge par les opérations suivantes :

— construction de l’ensemble des séquences de mots possibles pour M, pondérées par leur pro-
babilité pour le modele de langage. Cette opération est réalisée par composition des différents
transducteurs : T = M o E o R o D o L, dont on ne conserve par projection que le langage de
sortie H2 

— recherche de la séquence de probabilité maximale dans H2 (T) par un algorithme calculant
des plus courts chemins dans un graphe value.

11 est possible d’optimiser ce traitement en précalculant E o R o D o L, ainsi qu’en optimisant

(par déterminisation3 et minimisation) préalablement D o L selon des procédés usuellement

utilisés en reconnaissance vocale. L’ ensemble de ces opérations est réalisée par les outils de la

suite de manipulation de transducteurs ﬁnis FSM (Mohri et al., 2000).

Le passage par une représentation phonétique comporte un avantage supplémentaire : dans 1’ op-
tique d’une vocalisation des SMS, il permet de produire sans calcul supplémentaire non seule-
ment la forme orthographique normalisée, mais également la forme phonétique associée a cette
normalisation.

2.3 Le traitement des frontiéres de mots

L’ architecture décrite ci-dessus permet de traiter simplement la question des frontiere de mots.
Il est courant de trouver dans les messages des formes agglutinées telles que :

2Ce module accomplit également certaines operations de normalisation : traitement rudimentaire des chiffres,
insertion de marques de debuts et de ﬁn de phrase, etc.

3Comme il est usuel en reconnaissance Vocale, la déterrninisation est réalisée en traitant le mot de longueur
nulle 5 come un symbole a part entiere.

Transcrire les SMS come on reconnait la parole

(1) Kestu fe ?
(2)  avec lbac blanc 
(3) g ésayé Ztapelé p11 21°01’ (exemple tiré de (Guimier de Neef et al., 2007))

Ces exemples sont notoirement difﬁciles a traiter par des systemes symboliques (Guimier de
Neef et al., 2007). Pour autant, les messages a normaliser sont partiellement segmentés (espaces,
ponctuations); cette information est relativement ﬁable et doit étre utilisée. Notre architecture

<eps>:<eps>

   

_#:<eps>

i:<eps>

<eps>:<eps>

FIG. 2 — Gestion des frontieres de mots dans le dictionnaire inverse de prononciation

permet a la fois d’utiliser les informations de segmentation disponibles, en tout autorisant l’in-
sertion de nouvelles frontieres de mots. Ceci est réalisé par la procédure de construction du
transducteur représentant le dictionnaire inverse de prononciation D. Ce transducteur possede
l’allure d’un arbre des préﬁxes, chaque branche correspondant a une séquence de phonemes le
long de laquelle le mot orthographique correspondant est émis. Deux transitions « rebouclent »
sur l’état initial : l’une est étiquetée par le symbole /_#/, qui représente un séparateur explicite;
l’autre est une transition 5, qui permet de démarrer la reconnaissance d’un nouveau mot alors
meme qu’aucun séparateur ne ﬁgure dans l’entrée. En pondérant différentiellement ces deux
transitions, on exprime une plus ou moins grande préférence envers une segmentation qui res-
pecterait les séparateurs originaux. Ce mécanisme est illustré a la ﬁgure 2, qui représente un
dictionnaire contenant les deux mots 1ou1's et paul. Deux transitions bouclent sur l’état 0 a partir
de l’état 6 (ﬁn de 1ou1's) : l’un est une transition 5. L’emprunter signiﬁe qu’on introduit une
frontiere de mot qui est absente du message original; l’autre est étiquetée _# : elle est utilisée
si l’on rencontre un séparateur dans le message.

En revanche, il n’est pas possible, dans ce schéma, que deux mots soient « recollés » : tout
séparateur présent dans l’entrée sera également présent dans la sortie. Ceci rend notre systeme
incapable de traiter correctement des entrées telles que "je ne pep a mpaC dto1' " ou encore "s1t
1e zami " dans lequel des formes sont incorrectement segmentées.

Catherine Kobus, Francois Yvon, Géraldine Damnati

3 Evolutions du systéme

3.1 Le systéme baseline

Le systeme tel décrit ci-dessus (cf section 2) correspond a notre systeme baseline. Son lexique
contient de plus de 23000 mots. Nous avons également utilisé un dictionnaire de plus de 900
exceptions, ainsi qu’un ensemble de 140 regles de phonétisation contextuelles. Les contextes

FIT

    

y:<eps> r:<eps> a:<eps>

FIG. 3 — Gestion des mots hors-vocabulaire

des regles concernent principalement les débuts ou les ﬁns de mots et aident a décrire la pro-
nonciation des ﬁnales muettes (comme ’t’, ’s’, ’p’, etc.). Pour la lettre ’p’, nous avons ainsi
deux regles contextuelles distinctes : la premiere traite le cas d’une ﬁn de mot (lettre muette

autorisée, symbolisée par 6); la seconde regle s’applique aux autres contextes.

p —> /p/ I lpel I /p.<:/ |e si ﬁn de mot, p —> /p/ I lpel I lpsl sinon

3.2 Traitement des mots hors-vocabulaire

Comme dans un systeme de reconnaissance vocale, le lexique de l’application de normalisation
de SMS est ﬁni. Avec le systeme baseline, les mots du hors-vocabulaire (HV) du SMS ne sont
pas correctement traités. Dans la mesure o1‘1 ils ne peuvent étre restitués tels quels en sortie du
systeme, ils sont resegmentés en mots phonétiquement proches : ainsi, "puiske té a meyrarg"
("meyrarg" est HV) produit "puisque t’ es a mis rare"). Pour y remédier, le module de pre-
traitement a été complété de facon a produire une hypothese supplémentaire, correspondant a la
recopie du mot HV dans la sortie : ces mots, qui sont potentiellement corrects, peuvent alors ﬁ-
gurer dans la meilleure solution. La ﬁgure 3 détaille la facon dont sont gérés les mots HV dans le
formalisme des FSMs, en l’illustrant sur la forme « meyrarg". Lors du pré-traitement, "meyrarg"
est reconnu comme mot HV : deux chemins alternatifs sont alors créés. Le premier segmente
l’entrée en graphemes élémentaires, qui seront phonétisés. Le second chemin est identique, a
l’insertion pres d’une balise <HV>. Cette balise rend transparentes les étapes de phonétisation
et d’acces au dictionnaire. La séquence graphémique ﬁgurera dans l’ensemble des hypotheses
de séquences de mots et po11rra étre sélectionnée par le modele de langage. Un post-traitement
permet de retrouver le mot correspondant initialement a cette balise.

Transcrire les SMS come on reconnait la parole

 

FIG. 4 — Integration de grammaires locales : traitement de la chaine "... 2011  "

3.3 Utilisation de grammaires locales

Une seconde amelioration concerne le traitement des heures et des nombres, tres nombreux dans
le corpus des SMS ; initialement, les chiffres sont traités comme les autres graphemes. Ainsi, un
nombre a deux chiffres est systématiquement segmenté en deux chiffres distincts. Nous avons
donc introduit des grammaires régulieres, compilées sous la forme de transducteurs ﬁnis; la
composition avec le SMS prétraité fournit l’ensemble des analyses possibles des heures et des
nombres. Lorsqu’une heure ou un nombre est reconnu, la balise associée est émise; les étapes
de traitement des exceptions, de phonétisation et d’acces au dictionnaire restent identiques.
Le modele de langage est appliqué au graphe de mots et de balises. Ce dernier est appris au
préalable sur le meme corpus d’apprentissage que précédemment, apres étiquetage des nombres
et des montants (la phrase ’Je Viens a 20 h’ devient ’Je Viens a _H EU RE_’). La ﬁgure 4
illustre, pour cette meme entrée, la facon dont sont déﬁnies les grammaires locales pour les
heures et les nombres dans le formalisme des transducteurs ﬁnis. Lors du pré-traitement, les
formes sont segmentées en graphemes élémentaires et mises sous la forme d’un automate. Les
grammaires régulieres décrivant les heures et les nombres sont également mises sous la forme
d’un transducteur. La composition du SMS initial avec ce dernier permet de retrouver toutes
les instances d’heures et de nombres dans le SMS initial (Figure 4). Une balise associée a
chacune de ces grammaires est émise. Comme pour les mots hors-vocabulaire, ces balises sont
transparentes aux étapes de phonétisation et d’acces au dictionnaire. Elles ﬁgureront alors dans
l’ensemble des normalisations possibles et pourront étre sélectionnées par le modele de langage.

3.4 Apprentissage automatique des exceptions

Le systeme baseline integre un dictionnaire d’abréviations construit manuellement par analyse
de corpus. Dans cette section, nous décrivons une méthode permettant d’apprendre automa-
tiquement les abréviations les plus fréquentes a partir d’un corpus d’apprentissage contenant
d’une part, les SMS originaux, pré-traités (suppression de la ponctuation et des majuscules)
et leur transcription d’autre part. Cette méthode est basée sur les alignements automatiques et
l’extraction de segments bilingues utilisés dans les systemes de traduction statistique.

Des alignements automatiques sont calculés pour le corpus d’apprentissage a l’aide du logiciel
GIZA++ (Och & Ney, 2003). La technique des reﬁned alignments (Koehn et al., 2003) permet
de déduire des alignements automatiques croisés une table de traduction, donnant pour chaque
segment « source » (en langage SMS) l’ensemble des segments « cible » associés (en francais
standard). Pour les abréviations, nous ne conservons que les segments "source" constitués d’un
seul mot et les segments "cibles" constitués d’au maximum 3 mots (par exemple, l’abréviation

Catherine Kobus, Francois Yvon, Géraldine Damnati

"jtm" alignée avec la séquence "je t’aime''). Un score, s(t, w) est enﬁn estimée pour chaque
segment t apparié avec w; s(w) = max; P(t|w) dénote alors le meilleur score d’un segment
apparié avec w. Seuls les appariements dont la forme source est sufﬁsamment fréquente (plus
de 5 occurrences) et dont le score est supérieur a un certain ratio 04 (ﬁxé ici a 0.1) du meilleur
score ({t | s(t, w) 2 as(w)}) sont ﬁnalement conservés. Ont ainsi été extraites 3264 abrévia-
tions/exceptions nouvelles, auxquelles sont associées leurs meilleures expansions. Notons que
toutes ces exceptions ne sont pas utiles car il est possible qu’une abréviation et le segment
associé aient la méme phonétisation.

4 Expériences

4.1 Corpus et Métriques

Les expériences utilisent deux corpus : le premier a été collecté par l’université d’Aix en Pro-
vence (Hocq, 2006; Guimier de Neef et al., 2007); il est constitué d’environ 9700 messages.
Le second corpus est issu d’une collecte organisée en Belgique par l’Université Catholique de
Louvain, et comprend 30000 messages (Fairon et al., 2006). Un corpus d’apprentissage App
de 36704 SMS a été constitué en mélangeant les deux corpus. Les 2998 SMS restants nous ont
servi de corpus detest Test. Le modele de langage utilisé dans les évaluations est un modele
de langage 3-gram lissé en utilisant un lissage de type Kneser-Ney et estimé sur le corpus App.

Contrairement a (Aw et al. , 2006; Guimier de Neef et al. , 2007), qui évaluent leurs performances
en termes de mesure BLEU (Papineni et al., 2002), nous avons choisi d’évaluer nos systemes
en termes de taux d’erreurs mots ou WER (Word Error Rate), métrique qui est également uti-
lisée en reconnaissance vocale. La mesure BLEU, qui s’appuie sur un décompte des n-grams
présents dans l’hypothese et dans une référence, ne vaut que lorsque plusieurs références sont
disponibles, comme il est commun en traduction automatique. Pour notre probleme, l’ambi-
gui'té dans le choix de la transcription de référence est presque nulle justiﬁant le calcul de taux
d’erreurs par mots et par phrases.

4.2 Résultats

Le tableau 4.2 détaille les résultats obtenus et permet d’apprécier l’impact des améliorations
apportées au systeme. Le systeme baseline donne un WER de 19.79% ; la majorité des erreurs
sont des erreurs de substitution, qui portent souvent sur des mots courts comme ’1es’ <—> ’1e’,
’j” <—> ’je’, ’des’ <—> ’de’, etc. Dans une majorité des cas, le mot est pourtant bien orthographié
dans le SMS, mais l’étape de phonétisation réintroduit une ambigui'té que le modele de langage
ne parvient pas toujours a compenser. La deuxieme ligne du tableau 4.2 montre l’apport du
traitement des mots hors-vocabulaire, qui permet de diminuer principalement le nombre d’in-
sertions ; en effet le systeme baseline avait tendance a segmenter les mots HV en plusieurs petits
mots proches phonétiquement et donc a commettre plus d’insertions. Sur l’eXemple de "puisk
té a meyrarg  ", le systeme baseline foumit "puisque t’es a mes ir argh ", sortie qui est corrigée
par le traitement des mots HV.

L’utilisation des grammaires locales (pour les nombres et les heures) améliore globalement les
résultats en termes de WER; moins d’erreurs sont commises sur les nombres. L’introduction

Transcrire les SMS come on reconnait la parole

de ces grammaires améliore également la capacité de généralisation du modele de langage. Cet
effort d’introduction de grammaires locales doit donc étre poursuivi. Les deux dernieres lignes

WER Ins. Sub. Del.
baseline 19.79% 4.76% 13.44% 1.59%
Traitement des mots HV 18.13% 2.51% 12.83% 2.80%
Utilisation de grammaires 17.58% 2.54% 12.68% 2.35%
Abréviations automatiques 16.96% 2.56% 12.10% 2.30%
Combinaison 16.51% 2.21% 11.94% 2.36%

TAB. 1 — Apport et évaluations des différentes améliorations apportées

du tableau 4.2 chiffrent l’apport de l’apprentissage automatique des exceptions par rapport a
l’utilisation d’abréviations collectées manuellement. Les performances sont améliorées sigm-
ﬁcativement en termes de WER, démontrant la validité de l’approche proposée. Les résultats
sont encore améliorés en combinant les deux dictionnaires d’abréviations.

5 Bilan et Perspectives

Nous avons présenté, dans cet article, une nouvelle approche pour la normalisation des SMS,
basée sur un décodage phonétique. Les différentes évolutions ont permis d’amé1iorer sensible-
ment les performances du systeme baseline, qui sont probablement sous-estimées par la me-
trique WER : de nombreuses erreurs correspondent a des problemes d’accord, que le modele
de langage échoue a corriger. Ces erreurs sont pourtant sans conséquence dans une perspective
de vocalisation car elles correspondent le plus souvent a la perte ou a l’ajout d’un morpheme
ﬂexionnel « muet ». Ces erreurs sont également bénignes dans une optique d’indexation auto-
matique.

Le systeme actuel peut toutefois étre amélioré de multiples facons :

— les SMS contiennent de nombreuses formes qui sont correctement orthographiées : apres
phonétisation, cette information est perdue. Une approche qui semble meilleure consiste a
chercher celles qui existent dans le dictionnaire D et a les phonétiser par acces direct; il
faudra ensuite exprimer, par des pondérations, que l’on préfere utiliser une suite phonémique
extraite du dictionnaire plutot qu’une suite produite par des regles.

— les regles de conversion grapheme-phoneme (module E) sont exagérément libérales. Si le
non-déterminisme doit étre préservé, il importerait de le modérer en pondérant les différentes
sorties des regles de récriture : s’il est correct d’autoriser la lettre ’é ’ a valoir /e/ O11/8/, il est
probable que l’on gagnerait a rendre une des deux options plus probable que l’autre.

— nous avons pour l’instant supprimé toute information liée a la ponctuation, aux majuscules;
cette information pourrait nous étre utile pour segmenter le SMS et ainsi améliorer le pouvoir
prédictif du modele de langage.

Remerciements

Les auteurs remercient I-/Emilie Guimier de Neef (Orange Labs) pour avoir Inis a disposition la
liste d’abréviations ainsi que les différents corpus.

Catherine Kobus, Francois Yvon, Géraldine Damnati

Références

ALLAUZEN C., MOHRI M. & ROARK B. (2005). The design principles and algorithms of a
weighted grammar library. International Journal of Foundations of Computer Science, 16(3),
403-421.

ANIS J. (2001). Parlez-vous texto ? Guide des nouveaux langages du réseau. I-/Editions du
Cherche Midi.

ANIS J. (2002). Communication électronique scipturale et formes langagieres : chats et SMS.
Actes des journées "S’écrire avec les outils d’aujourd’hui".

AW A., ZHANG M., XIAO J. & SU J. (2006). A phrase-based statistical model for SMS text
normalization. In Proc. COLING/ACL, p. 33-40.

BARTHELEMY F. (2007). Cunéiforme et SMS : analyse graphémique de systemes d’écriture
hétérogenes. In Colloque Lexique et grammaire, Bonifacio.

CHOUDHURY M., SARAF R., JAIN V., SARKAR S. & BAsU A. (2007). Investigation and

modeling of the structure of texting language. In Proceedings of the IJCAI Workshop on
"Analytics for Noisy Unstructured Text Data”, p. 63-70, Hyderabad, India.

FAIRON C., KLEIN J. R. & PAUMIER S. (2006). Le langage SMS. UCL Presses Universitaires
de Louvain.

FALAISE A. (2005). Constitution d’un corpus de francais tchaté. In Actes de TALN, p. 615-
624, Dourdan.

GUIMIER DE NEEF E., DEBEURME A. & PARK J. (2007). TILT correcteur de SMS : evalua-
tion et bilan quantitatif. In Actes de TALN, p. 123-132, Toulouse.

HOCQ S. (2006). Etude des SMS en francais .' constitution et exploitation d ’un corpus aligne’
SMS-langue standard. Rapport interne, Université Aix-Marseille.

KAPLAN R. & KAY M. (1994). Regular models of phonological rule systems. Computational
Linguistics, 20(3), 331-378.

KOEHN P., OCH F. J. & MARCU D. (2003). Statistical phrase-based translation. In Proc.
NAACL-HLT, p. 127-133, Edmondton, Canada.

MOHRI M., PEREIRA F. & RILEY M. (1996). An efﬁcient compiler for weighted rewrite
rules. In Proceedings of the annual Meeting of the ACL, p. 231-238.

MOHRI M., PEREIRA F. & RILEY M. (2000). The design principles of a weighted ﬁnite-state
transducer library. Theoretical Computer Science, 231, 17-32.

OCH F. J. & NEY H. (2003). A systematic comparison of various statistical alignment models.
Computational Linguistics, 29(1), 19-51.

PAPINENI K., ROUKOS S., WARD T. & ZHU W.-J. (2002). Bleu : a method for automatic
evaluation of machine translation. In Proc. ACL, p. 311-318, Philadelphia, PA.

TORZEC N., MOUDENC T. & EMERARD F. (2001). Prétraitement et analyse linguistique
dans le systeme de synthese tts cvox : Application a la vocalisation automatique d’e-mails. In
Actes de TALN, Nancy.

VERONIS J. & GUIMIER DE NEEF E. (2006). Le traitement des nouvelles formes de commu-
nication écrite. In G. SABAH, Ed., Compréhension automatique des langues et interaction, p.
227-248 : Paris : Hermes Science.

