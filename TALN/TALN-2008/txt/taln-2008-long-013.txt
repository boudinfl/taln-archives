TALN 2008, Avignon, 9â€“13 juin 2008
Transcrire les SMS comme on reconnaÃ®t la parole
Catherine Kobus1 FranÃ§ois Yvon2 GÃ©raldine Damnati1
(1) Orange Labs / 2, avenue Pierre Marzin, 22300 Lannion
(2) Univ. Paris Sud 11 & LIMSI-CNRS, BP 133, 91403 Orsay Cedex
RÃ©sumÃ©. Cet article prÃ©sente une architecture inspirÃ©e des systÃ¨mes de reconnaissance
vocale pour effectuer une normalisation orthographique de messages en Â« langage SMS Â». Nous
dÃ©crivons notre systÃ¨me de base, ainsi que diverses Ã©volutions de ce systÃ¨me, qui permettent
dâ€™amÃ©liorer sensiblement la qualitÃ© des normalisations produites.
Abstract. This paper presents a system aiming at normalizing the orthography of SMS
messages, using techniques that are commonly used in automatic speech recognition devices.
We describe a baseline system and various evolutions, which are shown to improve significantly
the quality of the output normalizations.
Mots-clÃ©s : SMS, dÃ©codage phonÃ©tique, modÃ¨les de langage, transducteurs finis.
Keywords: SMS, phonetic decoding, language models, finite-state transducers.
1 Introduction
La diffusion des outils de communication Ã©lectronique (mails, SMS, blogs, forums de discus-
sion, chats, etc) a favorisÃ© lâ€™Ã©mergence de nouvelles formes dâ€™Ã©crits (Veronis & Guimier de
Neef, 2006). DestinÃ©s Ã  des proches ou Ã  des pairs, rÃ©digÃ©s dans lâ€™instant, avec des interfaces
qui imposent des contraintes nouvelles (claviers dâ€™ordinateurs, dâ€™assistants personnels ou de tÃ©-
lÃ©phones portables), ces textes se caractÃ©risent par un net relÃ¢chement vis-Ã -vis de la norme or-
thographique, ainsi que par de multiples dÃ©tournements de lâ€™usage conventionnel des caractÃ¨res
alphabÃ©tiques, utilisÃ©s non seulement pour encoder des formes linguistiques, mais Ã©galement
du mÃ©ta-discours (citations), des Ã©motions (colÃ¨re, humour), des attitudes (emphase, dÃ©rision)
etc. Si chaque mÃ©dia impose des contraintes spÃ©cifiques et se caractÃ©rise par des modes dâ€™Ã©cri-
ture et des codes qui lui sont propres (voir, par exemple, (Torzec et al., 2001) pour les mails,
(Falaise, 2005) pour les chats, ou (Anis, 2001; Anis, 2002; Fairon et al., 2006) pour les SMS),
ces nouvelles formes de communication Ã©crite partagent de nombreuses similaritÃ©s. Face Ã  ces
textes dâ€™un genre nouveau, il importe de dÃ©velopper de nouveaux outils de traitement automa-
tique, permettant, par exemple, de pouvoir indexer et effectuer des recherches dans des corpus
de messages. Dans cette Ã©tude, nous nous intÃ©ressons plus spÃ©cifiquement aux SMS, messages
courts rÃ©digÃ©s sur les claviers de tÃ©lÃ©phones portables, qui, nous semble-t-il, condensent Ã  lâ€™ex-
trÃªme les difficultÃ©s que posent ces Ã©crits aux systÃ¨mes de traitement des langues.
Le Â« langage SMS Â» a fait lâ€™objet de plusieurs Ã©tudes linguistiques (Anis, 2001; Anis, 2002;
Fairon et al., 2006), qui permettent de cerner ses principales caractÃ©ristiques, notamment la
trÃ¨s forte variabilitÃ© graphique des formes lexicales. Cette variabilitÃ© rÃ©sulte, dâ€™une part, de
lâ€™utilisation simultanÃ©e de plusieurs systÃ¨mes dâ€™encodage : pour dire vite , lâ€™Ã©criture alphabÃ©-
Catherine Kobus, FranÃ§ois Yvon, GÃ©raldine Damnati
tique usuelle , est en compÃ©tition avec une Ã©criture plus phonÃ©tique, ainsi quâ€™avec une Ã©criture
Â« consonantique Â» (seules subsistent les consonnes), enfin avec une Ã©criture Â« rÃ©bus Â» (lettres et
chiffres encodent la valeur phonÃ©tique de leur Ã©pellation). Elle dÃ©coule Ã©galement dâ€™un style
de communication relÃ¢chÃ©, qui autorise les plus grandes libertÃ©s par rapport Ã  la norme ortho-
graphique (non-respect des accords, des flexions verbales, etc). En consÃ©quence, du point de
vue lexical, ces messages se caractÃ©risent par un trÃ¨s fort taux de mots Â« hors-vocabulaire Â»,
correspondant Ã  des nÃ©ographismes, ainsi que par une forte augmentation de lâ€™ambiguÃ¯tÃ© des
formes lexicales Â« attestÃ©es Â». Restaurer une orthographe normalisÃ©e est donc un prÃ©alable pour
pouvoir leur appliquer dâ€™autres traitements (synthÃ¨se vocale, indexation , etc.) ; elle reprÃ©sente
Ã©galement, du fait de la crÃ©ativitÃ© des scripteurs, un sÃ©rieux dÃ©fi.
Les travaux portant explicitement sur la normalisation automatique de SMS sont relativement
rares : mentionnons, pour le franÃ§ais, (Guimier de Neef et al., 2007) qui aborde le problÃ¨me
sous lâ€™angle de la correction orthographique et propose une chaÃ®ne complÃ¨te de traitements
symboliques pour effectuer cette correction ; (BarthÃ©lemy, 2007) est plus prospectif et suggÃ¨re
une modÃ©lisation Ã  base dâ€™automates finis permettant de gÃ©rer efficacement la concurrence entre
divers modes dâ€™Ã©critures. Pour lâ€™anglais, signalons (Aw et al., 2006), qui sâ€™inspire des mÃ©thodes
utilisÃ©es en traduction statistique, ainsi que (Choudhury et al., 2007), dont le systÃ¨me de nor-
malisation utilise des mÃ©thodes statistiques de correction dâ€™orthographe.
Le systÃ¨me de normalisation prÃ©sentÃ© dans cet article propose une approche diffÃ©rente, qui
cherche Ã  tirer parti de la proximitÃ©, relevÃ©e par de nombreux auteurs, entre les formes dâ€™Ã©cri-
ture utilisÃ©es dans les SMS et la langue orale. Notre hypothÃ¨se est que le recensement (par
exemple dans un dictionnaire) de lâ€™ensemble des variations orthographiques est vouÃ© Ã  lâ€™Ã©chec.
Il semble comparativement plus aisÃ© de produire une reprÃ©sentation phonÃ©mique approximative
et ambiguÃ« dâ€™un message, sous la forme dâ€™un ensemble de phonÃ©tisations possibles, comme il
est commun de le faire en correction orthographique. La reconstruction dâ€™un message norma-
lisÃ© est alors trÃ¨s similaire au dÃ©codage phonÃ©tique, puisquâ€™il sâ€™agit de retrouver, dans un treillis
phonÃ©tique la sÃ©quence de mots la plus vraisemblable : il semble alors naturel dâ€™utiliser, pour
ce problÃ¨me, des techniques utilisÃ©es en reconnaissance de la parole.
Cet article est organisÃ© comme suit. Dans un premier temps, nous dÃ©crivons notre systÃ¨me de
base (section 2), avant de prÃ©senter, Ã  la section 3, plusieurs Ã©volutions de ce systÃ¨me : amÃ©-
lioration du traitement des mots hors-vocabulaire ; introduction de grammaires locales pour les
heures et dates ; acquisition automatisÃ©e dâ€™un dictionnaire dâ€™exceptions. La section 4 prÃ©sente
une Ã©valuation des performances du systÃ¨me de base et des Ã©volutions proposÃ©es, sur lâ€™analyse
desquelles nous nous appuyons pour esquisser quelques perspectives (section 5).
2 Architecture
2.1 Principes gÃ©nÃ©raux
Notre systÃ¨me de normalisation repose sur un principe dâ€™expansion/contraction :
â€“ dans un premier temps, le message est converti en un ensemble de sÃ©quences phonÃ©tiques
reprÃ©sentant toutes les prononciations possibles sous la forme dâ€™un Â« treillis Â»1 de phonÃ¨mes.
â€“ la conversion inverse est ensuite calculÃ©e : transformation des sÃ©quences de phonÃ¨mes en
1Formellement, il sâ€™agit dâ€™un automate acyclique sur lâ€™alphabet phonÃ©tique.
Transcrire les SMS comme on reconnaÃ®t la parole
SÃ©quence alphabÃ©tique
SMS PrÃ©- Traitement
traitements des exceptions
Graphe alphabÃ©tique
PhonÃ©tisation
Graphe phonÃ©tique
SMS normalisÃ© ModÃ¨le de Dictionnaire
langage inverse
SÃ©quence de mots Graphe de mots
FIG. 1 â€“ Ã‰tapes de la normalisation du SMS
sÃ©quences de mots par accÃ¨s dictionnairique, puis sÃ©lection, par un modÃ¨le de langage statis-
tique, de la meilleure sÃ©quence de mots. Cette Ã©tape est identique aux calculs effectuÃ©s dans
un systÃ¨me de reconnaissance vocale : a ceci prÃ¨s que dans notre cas, lâ€™incertitude sur les
phonÃ¨mes et sur les positions des frontiÃ¨res de mots est bien moins grande.
Une vue schÃ©matique des traitements rÃ©alisÃ©s dans le systÃ¨me de base est donnÃ©e Figure 1.
AprÃ¨s prÃ©traitement du SMS, la normalisation dÃ©bute par le traitement des exceptions et des
abrÃ©viations ("pr" pour "pour" ou "par", "bcp" pour "beaucoup", etc), qui sont Ã  la fois trÃ¨s
frÃ©quentes en langage SMS et difficiles Ã  modÃ©liser autrement que par construction de listes.
Durant cette Ã©tape, les mots du message sont analysÃ©s et chaque forme trouvÃ©e dans le diction-
naire dâ€™exception est mise en compÃ©tition avec le ou les expansions associÃ©es. Notons que la
forme originale est conservÃ©e, car elle nâ€™a pas nÃ©cesssairement Ã©tÃ© utilisÃ©e comme abrÃ©viation.
Lâ€™expansion des exceptions est donc non-dÃ©terministe et produit un treillis de formes.
La troisiÃ¨me Ã©tape est la phonÃ©tisation, qui utilise des rÃ¨gles de rÃ©criture contextuelles non-
dÃ©terministes dÃ©crivant les correspondances graphÃ¨me-phonÃ¨me. Une rÃ¨gle est formalisÃ©e par :
Ï† [a]Ïˆ â†’ [b]
qui exprime la rÃ©criture du motif a en b dans un contexte dÃ©crit par les expressions rationnelles
Ï† et Ïˆ. Le non-dÃ©terminisme de ces rÃ¨gles, c.-Ã -d. la possibilitÃ© que le langage dÃ©notÃ© par b
contienne plusieurs mots est inhabituel en transcription graphÃ¨me-phonÃ¨me : câ€™est toutefois un
aspect crucial du systÃ¨me, qui assure que lâ€™espace des prononciations possibles est complÃ¨te-
ment envisagÃ©. Par exemple, la rÃ¨gle de prononciation la plus gÃ©nÃ©rale de la lettre â€™câ€™ lui associe
les quatre prononciations : /k/, /s/, /sE/, /se/ : si les deux premiÃ¨res prononciations sont atten-
dues, les deux suivantes expriment la possibilitÃ© que cette lettre soit utilisÃ©e phonÃ©tiquement
(et doive donc Ãªtre Â« Ã©pelÃ©e Â»). Les exceptions dÃ©tectÃ©es lors de la premiÃ¨re Ã©tape subissent ici
un traitement particulier : dans la mesure oÃ¹ ces formes sont dÃ©jÃ  normalisÃ©es, la phonÃ©tisation
sâ€™applique de faÃ§on dÃ©terministe, par accÃ¨s Ã  un dictionnaire de prononciation.
La suite du traitement utilise les ressources suivantes :
Catherine Kobus, FranÃ§ois Yvon, GÃ©raldine Damnati
â€“ un dictionnaire de prononciation, utilisÃ© pour convertir des sÃ©quences de phonÃ¨mes en sÃ©-
quences de mots ;
â€“ un modÃ¨le de langage statistique, qui permet dâ€™ordonner par probabilitÃ© croissante les sÃ©-
quences de mots ;
Lâ€™accÃ¨s au dictionnaire permet de dÃ©gager, Ã  partir du graphe de phonÃ¨mes, lâ€™ensemble des
sÃ©quences de mots possibles ; le modÃ¨le de langage permet de pondÃ©rer lâ€™ensemble des hypo-
thÃ¨ses de phrases possibles ; enfin, un algorithme de programmation dynamique sÃ©lectionne la
sÃ©quence de mots la plus probable.
2.2 ImplÃ©mentation
Chacun de ces modules peut Ãªtre implantÃ© par des automates ou transducteurs finis Ã©ventuel-
lement pondÃ©rÃ©s. Câ€™est le cas des deux dictionnaires dÃ©crits dans la section prÃ©cÃ©dente : le
dictionnaire dâ€™exception rÃ©alise une transduction de sÃ©quences orthographiques en sÃ©quences
de phonÃ¨mes (transducteur E), lâ€™inverse du dictionnaire de prononciation (transducteur D) as-
socie des sÃ©quences de mots Ã  des sÃ©quences de phonÃ¨mes. Câ€™est encore le cas du module
appliquant des rÃ¨gles de phonÃ©tisation contextuelles (Kaplan & Kay, 1994; Mohri et al., 1996),
qui sont globalement compilÃ©es en un transducteur R, ainsi que du modÃ¨le de langage de type
n-gramme, reprÃ©sentÃ© par un accepteur pondÃ©rÃ© L. Ces transducteurs sont construits , pour les
trois premiers, par des scripts ad-hoc et par les outils de la suite GRM (Allauzen et al., 2005)
pour le modÃ¨le de langage. Une fois le message en entrÃ©e converti en un automate fini M par
le module de prÃ©traitement2, lâ€™ensemble des rÃ©critures rÃ©alisant la normalisation est prise en
charge par les opÃ©rations suivantes :
â€“ construction de lâ€™ensemble des sÃ©quences de mots possibles pourM , pondÃ©rÃ©es par leur pro-
babilitÃ© pour le modÃ¨le de langage. Cette opÃ©ration est rÃ©alisÃ©e par composition des diffÃ©rents
transducteurs : T =M â—¦E â—¦R â—¦D â—¦L, dont on ne conserve par projection que le langage de
sortie Î 2(T ).
â€“ recherche de la sÃ©quence de probabilitÃ© maximale dans Î 2(T ) par un algorithme calculant
des plus courts chemins dans un graphe valuÃ©.
Il est possible dâ€™optimiser ce traitement en prÃ©calculant E â—¦ R â—¦D â—¦ L, ainsi quâ€™en optimisant
(par dÃ©terminisation3 et minimisation) prÃ©alablement D â—¦ L selon des procÃ©dÃ©s usuellement
utilisÃ©s en reconnaissance vocale. Lâ€™ensemble de ces opÃ©rations est rÃ©alisÃ©e par les outils de la
suite de manipulation de transducteurs finis FSM (Mohri et al., 2000).
Le passage par une reprÃ©sentation phonÃ©tique comporte un avantage supplÃ©mentaire : dans lâ€™op-
tique dâ€™une vocalisation des SMS, il permet de produire sans calcul supplÃ©mentaire non seule-
ment la forme orthographique normalisÃ©e, mais Ã©galement la forme phonÃ©tique associÃ©e Ã  cette
normalisation.
2.3 Le traitement des frontiÃ¨res de mots
Lâ€™architecture dÃ©crite ci-dessus permet de traiter simplement la question des frontiÃ¨re de mots.
Il est courant de trouver dans les messages des formes agglutinÃ©es telles que :
2Ce module accomplit Ã©galement certaines opÃ©rations de normalisation : traitement rudimentaire des chiffres,
insertion de marques de dÃ©buts et de fin de phrase, etc.
3Comme il est usuel en reconnaissance vocale, la dÃ©terminisation est rÃ©alisÃ©e en traitant le mot de longueur
nulle Îµ comme un symbole Ã  part entiÃ¨re.
Transcrire les SMS comme on reconnaÃ®t la parole
(1) Kestu fe ?
(2) ... avec lbac blanc ...
(3) g Ã©sayÃ© 2tapelÃ© pl1 2foi (exemple tirÃ© de (Guimier de Neef et al., 2007))
Ces exemples sont notoirement difficiles Ã  traiter par des systÃ¨mes symboliques (Guimier de
Neef et al., 2007). Pour autant, les messages Ã  normaliser sont partiellement segmentÃ©s (espaces,
ponctuations) ; cette information est relativement fiable et doit Ãªtre utilisÃ©e. Notre architecture
<eps>:<eps>
O:<eps>
1 2
p:paul l:<eps>
3
_#:<eps>
0/0
l:louis _#:<eps>
4 w:<eps>
5 i:<eps>
6
<eps>:<eps>
FIG. 2 â€“ Gestion des frontiÃ¨res de mots dans le dictionnaire inverse de prononciation
permet Ã  la fois dâ€™utiliser les informations de segmentation disponibles, en tout autorisant lâ€™in-
sertion de nouvelles frontiÃ¨res de mots. Ceci est rÃ©alisÃ© par la procÃ©dure de construction du
transducteur reprÃ©sentant le dictionnaire inverse de prononciation D. Ce transducteur possÃ¨de
lâ€™allure dâ€™un arbre des prÃ©fixes, chaque branche correspondant Ã  une sÃ©quence de phonÃ¨mes le
long de laquelle le mot orthographique correspondant est Ã©mis. Deux transitions Â« rebouclent Â»
sur lâ€™Ã©tat initial : lâ€™une est Ã©tiquetÃ©e par le symbole /_#/, qui reprÃ©sente un sÃ©parateur explicite ;
lâ€™autre est une transition Îµ, qui permet de dÃ©marrer la reconnaissance dâ€™un nouveau mot alors
mÃªme quâ€™aucun sÃ©parateur ne figure dans lâ€™entrÃ©e. En pondÃ©rant diffÃ©rentiellement ces deux
transitions, on exprime une plus ou moins grande prÃ©fÃ©rence envers une segmentation qui res-
pecterait les sÃ©parateurs originaux. Ce mÃ©canisme est illustrÃ© Ã  la figure 2, qui reprÃ©sente un
dictionnaire contenant les deux mots louis et paul. Deux transitions bouclent sur lâ€™Ã©tat 0 Ã  partir
de lâ€™Ã©tat 6 (fin de louis) : lâ€™un est une transition Îµ. Lâ€™emprunter signifie quâ€™on introduit une
frontiÃ¨re de mot qui est absente du message original ; lâ€™autre est Ã©tiquetÃ©e _# : elle est utilisÃ©e
si lâ€™on rencontre un sÃ©parateur dans le message.
En revanche, il nâ€™est pas possible, dans ce schÃ©ma, que deux mots soient Â« recollÃ©s Â» : tout
sÃ©parateur prÃ©sent dans lâ€™entrÃ©e sera Ã©galement prÃ©sent dans la sortie. Ceci rend notre systÃ¨me
incapable de traiter correctement des entrÃ©es telles que "je ne pep a mpaC dtoi" ou encore "slt
le zami" dans lequel des formes sont incorrectement segmentÃ©es.
Catherine Kobus, FranÃ§ois Yvon, GÃ©raldine Damnati
3 Ã‰volutions du systÃ¨me
3.1 Le systÃ¨me baseline
Le systÃ¨me tel dÃ©crit ci-dessus (cf section 2) correspond Ã  notre systÃ¨me baseline. Son lexique
contient de plus de 23000 mots. Nous avons Ã©galement utilisÃ© un dictionnaire de plus de 900
exceptions, ainsi quâ€™un ensemble de 140 rÃ¨gles de phonÃ©tisation contextuelles. Les contextes
y:y r:r a:a
e:e
r:r
m:m g:g
_#:_# _#:_#
m:<HV> g:<eps>
e:<eps> r:<eps>
y:<eps> a:<eps>
r:<eps>
FIG. 3 â€“ Gestion des mots hors-vocabulaire
des rÃ¨gles concernent principalement les dÃ©buts ou les fins de mots et aident Ã  dÃ©crire la pro-
nonciation des finales muettes (comme â€™tâ€™, â€™sâ€™, â€™pâ€™, etc.). Pour la lettre â€™pâ€™, nous avons ainsi
deux rÃ¨gles contextuelles distinctes : la premiÃ¨re traite le cas dâ€™une fin de mot (lettre muette
autorisÃ©e, symbolisÃ©e par ) ; la seconde rÃ¨gle sâ€™applique aux autres contextes.
p â†’ /p/ | /pe/ | /pE/ | si fin de mot, p â†’ /p/ | /pe/ | /pE/ sinon
3.2 Traitement des mots hors-vocabulaire
Comme dans un systÃ¨me de reconnaissance vocale, le lexique de lâ€™application de normalisation
de SMS est fini. Avec le systÃ¨me baseline, les mots du hors-vocabulaire (HV) du SMS ne sont
pas correctement traitÃ©s. Dans la mesure oÃ¹ ils ne peuvent Ãªtre restituÃ©s tels quels en sortie du
systÃ¨me, ils sont resegmentÃ©s en mots phonÃ©tiquement proches : ainsi, "puiske tÃ© a meyrarg"
("meyrarg" est HV) produit "puisque tâ€™ es a mis rare" ). Pour y remÃ©dier, le module de prÃ©-
traitement a Ã©tÃ© complÃ©tÃ© de faÃ§on Ã  produire une hypothÃ¨se supplÃ©mentaire, correspondant Ã  la
recopie du mot HV dans la sortie : ces mots, qui sont potentiellement corrects, peuvent alors fi-
gurer dans la meilleure solution. La figure 3 dÃ©taille la faÃ§on dont sont gÃ©rÃ©s les mots HV dans le
formalisme des FSMs, en lâ€™illustrant sur la forme Â«meyrarg". Lors du prÃ©-traitement, "meyrarg"
est reconnu comme mot HV : deux chemins alternatifs sont alors crÃ©Ã©s. Le premier segmente
lâ€™entrÃ©e en graphÃ¨mes Ã©lÃ©mentaires, qui seront phonÃ©tisÃ©s. Le second chemin est identique, Ã 
lâ€™insertion prÃ¨s dâ€™une balise <HV>. Cette balise rend transparentes les Ã©tapes de phonÃ©tisation
et dâ€™accÃ¨s au dictionnaire. La sÃ©quence graphÃ©mique figurera dans lâ€™ensemble des hypothÃ¨ses
de sÃ©quences de mots et pourra Ãªtre sÃ©lectionnÃ©e par le modÃ¨le de langage. Un post-traitement
permet de retrouver le mot correspondant initialement Ã  cette balise.
Transcrire les SMS comme on reconnaÃ®t la parole
0:<eps>
2:_HEURE_ h:<eps>
_#:_# _#:_#
2:_NOMBRE_
0:<eps>
2:2 h:h
0:0
FIG. 4 â€“ IntÃ©gration de grammaires locales : traitement de la chaÃ®ne "... 20h ..."
3.3 Utilisation de grammaires locales
Une seconde amÃ©lioration concerne le traitement des heures et des nombres, trÃ¨s nombreux dans
le corpus des SMS ; initialement, les chiffres sont traitÃ©s comme les autres graphÃ¨mes. Ainsi, un
nombre Ã  deux chiffres est systÃ©matiquement segmentÃ© en deux chiffres distincts. Nous avons
donc introduit des grammaires rÃ©guliÃ¨res, compilÃ©es sous la forme de transducteurs finis ; la
composition avec le SMS prÃ©traitÃ© fournit lâ€™ensemble des analyses possibles des heures et des
nombres. Lorsquâ€™une heure ou un nombre est reconnu, la balise associÃ©e est Ã©mise ; les Ã©tapes
de traitement des exceptions, de phonÃ©tisation et dâ€™accÃ¨s au dictionnaire restent identiques.
Le modÃ¨le de langage est appliquÃ© au graphe de mots et de balises. Ce dernier est appris au
prÃ©alable sur le mÃªme corpus dâ€™apprentissage que prÃ©cÃ©demment, aprÃ¨s Ã©tiquetage des nombres
et des montants (la phrase â€™Je viens Ã  20 hâ€™ devient â€™Je viens Ã  _HEURE_â€™ ). La figure 4
illustre, pour cette mÃªme entrÃ©e, la faÃ§on dont sont dÃ©finies les grammaires locales pour les
heures et les nombres dans le formalisme des transducteurs finis. Lors du prÃ©-traitement, les
formes sont segmentÃ©es en graphÃ¨mes Ã©lÃ©mentaires et mises sous la forme dâ€™un automate. Les
grammaires rÃ©guliÃ¨res dÃ©crivant les heures et les nombres sont Ã©galement mises sous la forme
dâ€™un transducteur. La composition du SMS initial avec ce dernier permet de retrouver toutes
les instances dâ€™heures et de nombres dans le SMS initial (Figure 4). Une balise associÃ©e Ã 
chacune de ces grammaires est Ã©mise. Comme pour les mots hors-vocabulaire, ces balises sont
transparentes aux Ã©tapes de phonÃ©tisation et dâ€™accÃ¨s au dictionnaire. Elles figureront alors dans
lâ€™ensemble des normalisations possibles et pourront Ãªtre sÃ©lectionnÃ©es par le modÃ¨le de langage.
3.4 Apprentissage automatique des exceptions
Le systÃ¨me baseline intÃ¨gre un dictionnaire dâ€™abrÃ©viations construit manuellement par analyse
de corpus. Dans cette section, nous dÃ©crivons une mÃ©thode permettant dâ€™apprendre automa-
tiquement les abrÃ©viations les plus frÃ©quentes Ã  partir dâ€™un corpus dâ€™apprentissage contenant
dâ€™une part, les SMS originaux, prÃ©-traitÃ©s (suppression de la ponctuation et des majuscules)
et leur transcription dâ€™autre part. Cette mÃ©thode est basÃ©e sur les alignements automatiques et
lâ€™extraction de segments bilingues utilisÃ©s dans les systÃ¨mes de traduction statistique.
Des alignements automatiques sont calculÃ©s pour le corpus dâ€™apprentissage Ã  lâ€™aide du logiciel
GIZA++ (Och & Ney, 2003). La technique des refined alignments (Koehn et al., 2003) permet
de dÃ©duire des alignements automatiques croisÃ©s une table de traduction, donnant pour chaque
segment Â« source Â» (en langage SMS) lâ€™ensemble des segments Â« cible Â» associÃ©s (en franÃ§ais
standard). Pour les abrÃ©viations, nous ne conservons que les segments "source" constituÃ©s dâ€™un
seul mot et les segments "cibles" constituÃ©s dâ€™au maximum 3 mots (par exemple, lâ€™abrÃ©viation
Catherine Kobus, FranÃ§ois Yvon, GÃ©raldine Damnati
"jtm" alignÃ©e avec la sÃ©quence "je tâ€™aime" ). Un score, s(t, w) est enfin estimÃ©e pour chaque
segment t appariÃ© avec w ; s(w) = maxt P (t|w) dÃ©note alors le meilleur score dâ€™un segment
appariÃ© avec w. Seuls les appariements dont la forme source est suffisamment frÃ©quente (plus
de 5 occurrences) et dont le score est supÃ©rieur Ã  un certain ratio Î± (fixÃ© ici Ã  0.1) du meilleur
score ({t | s(t, w) â‰¥ Î±s(w)}) sont finalement conservÃ©s. Ont ainsi Ã©tÃ© extraites 3264 abrÃ©via-
tions/exceptions nouvelles, auxquelles sont associÃ©es leurs meilleures expansions. Notons que
toutes ces exceptions ne sont pas utiles car il est possible quâ€™une abrÃ©viation et le segment
associÃ© aient la mÃªme phonÃ©tisation.
4 ExpÃ©riences
4.1 Corpus et MÃ©triques
Les expÃ©riences utilisent deux corpus : le premier a Ã©tÃ© collectÃ© par lâ€™universitÃ© dâ€™Aix en Pro-
vence (Hocq, 2006; Guimier de Neef et al., 2007) ; il est constituÃ© dâ€™environ 9700 messages.
Le second corpus est issu dâ€™une collecte organisÃ©e en Belgique par lâ€™UniversitÃ© Catholique de
Louvain, et comprend 30000 messages (Fairon et al., 2006). Un corpus dâ€™apprentissage App
de 36704 SMS a Ã©tÃ© constituÃ© en mÃ©langeant les deux corpus. Les 2998 SMS restants nous ont
servi de corpus de test Test. Le modÃ¨le de langage utilisÃ© dans les Ã©valuations est un modÃ¨le
de langage 3-gram lissÃ© en utilisant un lissage de type Kneser-Ney et estimÃ© sur le corpus App.
Contrairement Ã  (Aw et al., 2006; Guimier de Neef et al., 2007), qui Ã©valuent leurs performances
en termes de mesure BLEU (Papineni et al., 2002), nous avons choisi dâ€™Ã©valuer nos systÃ¨mes
en termes de taux dâ€™erreurs mots ou WER (Word Error Rate), mÃ©trique qui est Ã©galement uti-
lisÃ©e en reconnaissance vocale. La mesure BLEU, qui sâ€™appuie sur un dÃ©compte des n-grams
prÃ©sents dans lâ€™hypothÃ¨se et dans une rÃ©fÃ©rence, ne vaut que lorsque plusieurs rÃ©fÃ©rences sont
disponibles, comme il est commun en traduction automatique. Pour notre problÃ¨me, lâ€™ambi-
guÃ¯tÃ© dans le choix de la transcription de rÃ©fÃ©rence est presque nulle justifiant le calcul de taux
dâ€™erreurs par mots et par phrases.
4.2 RÃ©sultats
Le tableau 4.2 dÃ©taille les rÃ©sultats obtenus et permet dâ€™apprÃ©cier lâ€™impact des amÃ©liorations
apportÃ©es au systÃ¨me. Le systÃ¨me baseline donne un WER de 19.79% ; la majoritÃ© des erreurs
sont des erreurs de substitution, qui portent souvent sur des mots courts comme â€™lesâ€™ â†” â€™leâ€™,
â€™jâ€ â†” â€™jeâ€™, â€™desâ€™ â†” â€™deâ€™, etc. Dans une majoritÃ© des cas, le mot est pourtant bien orthographiÃ©
dans le SMS, mais lâ€™Ã©tape de phonÃ©tisation rÃ©introduit une ambiguÃ¯tÃ© que le modÃ¨le de langage
ne parvient pas toujours Ã  compenser. La deuxiÃ¨me ligne du tableau 4.2 montre lâ€™apport du
traitement des mots hors-vocabulaire, qui permet de diminuer principalement le nombre dâ€™in-
sertions ; en effet le systÃ¨me baseline avait tendance Ã  segmenter les mots HV en plusieurs petits
mots proches phonÃ©tiquement et donc Ã  commettre plus dâ€™insertions. Sur lâ€™exemple de "puisk
tÃ© a meyrarg ...", le systÃ¨me baseline fournit "puisque tâ€™es Ã  mes ir argh", sortie qui est corrigÃ©e
par le traitement des mots HV.
Lâ€™utilisation des grammaires locales (pour les nombres et les heures) amÃ©liore globalement les
rÃ©sultats en termes de WER ; moins dâ€™erreurs sont commises sur les nombres. Lâ€™introduction
Transcrire les SMS comme on reconnaÃ®t la parole
de ces grammaires amÃ©liore Ã©galement la capacitÃ© de gÃ©nÃ©ralisation du modÃ¨le de langage. Cet
effort dâ€™introduction de grammaires locales doit donc Ãªtre poursuivi. Les deux derniÃ¨res lignes
WER Ins. Sub. Del.
baseline 19.79% 4.76% 13.44% 1.59%
Traitement des mots HV 18.13% 2.51% 12.83% 2.80%
Utilisation de grammaires 17.58% 2.54% 12.68% 2.35%
AbrÃ©viations automatiques 16.96% 2.56% 12.10% 2.30%
Combinaison 16.51% 2.21% 11.94% 2.36%
TAB. 1 â€“ Apport et Ã©valuations des diffÃ©rentes amÃ©liorations apportÃ©es
du tableau 4.2 chiffrent lâ€™apport de lâ€™apprentissage automatique des exceptions par rapport Ã 
lâ€™utilisation dâ€™abrÃ©viations collectÃ©es manuellement. Les performances sont amÃ©liorÃ©es signi-
ficativement en termes de WER, dÃ©montrant la validitÃ© de lâ€™approche proposÃ©e. Les rÃ©sultats
sont encore amÃ©liorÃ©s en combinant les deux dictionnaires dâ€™abrÃ©viations.
5 Bilan et Perspectives
Nous avons prÃ©sentÃ©, dans cet article, une nouvelle approche pour la normalisation des SMS,
basÃ©e sur un dÃ©codage phonÃ©tique. Les diffÃ©rentes Ã©volutions ont permis dâ€™amÃ©liorer sensible-
ment les performances du systÃ¨me baseline, qui sont probablement sous-estimÃ©es par la mÃ©-
trique WER : de nombreuses erreurs correspondent Ã  des problÃ¨mes dâ€™accord, que le modÃ¨le
de langage Ã©choue Ã  corriger. Ces erreurs sont pourtant sans consÃ©quence dans une perspective
de vocalisation car elles correspondent le plus souvent Ã  la perte ou Ã  lâ€™ajout dâ€™un morphÃ¨me
flexionnel Â« muet Â». Ces erreurs sont Ã©galement bÃ©nignes dans une optique dâ€™indexation auto-
matique.
Le systÃ¨me actuel peut toutefois Ãªtre amÃ©liorÃ© de multiples faÃ§ons :
â€“ les SMS contiennent de nombreuses formes qui sont correctement orthographiÃ©es : aprÃ¨s
phonÃ©tisation, cette information est perdue. Une approche qui semble meilleure consiste Ã 
chercher celles qui existent dans le dictionnaire D et Ã  les phonÃ©tiser par accÃ¨s direct ; il
faudra ensuite exprimer, par des pondÃ©rations, que lâ€™on prÃ©fÃ¨re utiliser une suite phonÃ©mique
extraite du dictionnaire plutÃ´t quâ€™une suite produite par des rÃ¨gles.
â€“ les rÃ¨gles de conversion graphÃ¨me-phonÃ¨me (module E) sont exagÃ©rÃ©ment libÃ©rales. Si le
non-dÃ©terminisme doit Ãªtre prÃ©servÃ©, il importerait de le modÃ©rer en pondÃ©rant les diffÃ©rentes
sorties des rÃ¨gles de rÃ©criture : sâ€™il est correct dâ€™autoriser la lettre â€™Ã© â€™ Ã  valoir /e/ ou /E/, il est
probable que lâ€™on gagnerait Ã  rendre une des deux options plus probable que lâ€™autre.
â€“ nous avons pour lâ€™instant supprimÃ© toute information liÃ©e Ã  la ponctuation, aux majuscules ;
cette information pourrait nous Ãªtre utile pour segmenter le SMS et ainsi amÃ©liorer le pouvoir
prÃ©dictif du modÃ¨le de langage.
Remerciements
Les auteurs remercient Ã‰milie Guimier de Neef (Orange Labs) pour avoir mis Ã  disposition la
liste dâ€™abrÃ©viations ainsi que les diffÃ©rents corpus.
Catherine Kobus, FranÃ§ois Yvon, GÃ©raldine Damnati
RÃ©fÃ©rences
ALLAUZEN C., MOHRI M. & ROARK B. (2005). The design principles and algorithms of a
weighted grammar library. International Journal of Foundations of Computer Science, 16(3),
403â€“421.
ANIS J. (2001). Parlez-vous texto ? Guide des nouveaux langages du rÃ©seau. Ã‰ditions du
Cherche Midi.
ANIS J. (2002). Communication Ã©lectronique scipturale et formes langagiÃ¨res : chats et SMS.
Actes des journÃ©es "Sâ€™Ã©crire avec les outils dâ€™aujourdâ€™hui".
AW A., ZHANG M., XIAO J. & SU J. (2006). A phrase-based statistical model for SMS text
normalization. In Proc. COLING/ACL, p. 33â€“40.
BARTHÃ‰LEMY F. (2007). CunÃ©iforme et SMS : analyse graphÃ©mique de systÃ¨mes dâ€™Ã©criture
hÃ©tÃ©rogÃ¨nes. In Colloque Lexique et grammaire, Bonifacio.
CHOUDHURY M., SARAF R., JAIN V., SARKAR S. & BASU A. (2007). Investigation and
modeling of the structure of texting language. In Proceedings of the IJCAI Workshop on
"Analytics for Noisy Unstructured Text Data", p. 63â€“70, Hyderabad, India.
FAIRON C., KLEIN J. R. & PAUMIER S. (2006). Le langage SMS. UCL Presses Universitaires
de Louvain.
FALAISE A. (2005). Constitution dâ€™un corpus de franÃ§ais tchatÃ©. In Actes de TALN, p. 615â€“
624, Dourdan.
GUIMIER DE NEEF E., DEBEURME A. & PARK J. (2007). TILT correcteur de SMS : Ã©valua-
tion et bilan quantitatif. In Actes de TALN, p. 123â€“132, Toulouse.
HOCQ S. (2006). Ã‰tude des SMS en franÃ§ais : constitution et exploitation dâ€™un corpus alignÃ©
SMS-langue standard. Rapport interne, UniversitÃ© Aix-Marseille.
KAPLAN R. & KAY M. (1994). Regular models of phonological rule systems. Computational
Linguistics, 20(3), 331â€“378.
KOEHN P., OCH F. J. & MARCU D. (2003). Statistical phrase-based translation. In Proc.
NAACL-HLT, p. 127â€“133, Edmondton, Canada.
MOHRI M., PEREIRA F. & RILEY M. (1996). An efficient compiler for weighted rewrite
rules. In Proceedings of the annual Meeting of the ACL, p. 231â€“238.
MOHRI M., PEREIRA F. & RILEY M. (2000). The design principles of a weighted finite-state
transducer library. Theoretical Computer Science, 231, 17â€“32.
OCH F. J. & NEY H. (2003). A systematic comparison of various statistical alignment models.
Computational Linguistics, 29(1), 19â€“51.
PAPINENI K., ROUKOS S., WARD T. & ZHU W.-J. (2002). Bleu : a method for automatic
evaluation of machine translation. In Proc. ACL, p. 311â€“318, Philadelphia, PA.
TORZEC N., MOUDENC T. & EMERARD F. (2001). PrÃ©traitement et analyse linguistique
dans le systÃ¨me de synthÃ¨se tts cvox : Application Ã  la vocalisation automatique dâ€™e-mails. In
Actes de TALN, Nancy.
VERONIS J. & GUIMIER DE NEEF E. (2006). Le traitement des nouvelles formes de commu-
nication Ã©crite. In G. SABAH, Ed., ComprÃ©hension automatique des langues et interaction, p.
227â€“248 : Paris : HermÃ¨s Science.
