<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2008, Avignon, 9&#8211;13 juin 2008
</p>
<p>Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais
</p>
<p>Beno&#238;t Crabb&#233; et Marie Candito
Universit&#233; Paris 7 (UFRL) et INRIA (Alpage)
30 rue du Ch&#226;teau des Rentiers 75013 Paris
</p>
<p>{bcrabbe,candito}@linguist.jussieu.fr
</p>
<p>R&#233;sum&#233;. Nous montrons qu&#8217;il est possible d&#8217;obtenir une analyse syntaxique statistique
satisfaisante pour le fran&#231;ais sur du corpus journalistique, &#224; partir des donn&#233;es issues du French
Treebank du laboratoire LLF, &#224; l&#8217;aide d&#8217;un algorithme d&#8217;analyse non lexicalis&#233;.
</p>
<p>Abstract. We show that we can acquire satisfactory parsing results for French from data
induced from the French Treebank using an unlexicalised parsing algorithm.
</p>
<p>Mots-cl&#233;s : Analyseur syntaxique statistique, Analyse syntaxique non lexicalis&#233;e, Ana-
lyse du fran&#231;ais.
</p>
<p>Keywords: Statistical parser, Unlexicalised parsing, French parsing.
</p>
<p>1 Introduction
</p>
<p>&#192; l&#8217;heure actuelle, la communaut&#233; francophone dispose de plusieurs environnements de d&#233;ve-
loppement de grammaires et d&#8217;analyse syntaxique symbolique automatique dite profonde. Ce-
pendant, dans la perspective de r&#233;aliser une analyse syntaxique profonde &#224; grande &#233;chelle sur
corpus, l&#8217;analyse syntaxique symbolique pose deux probl&#232;mes : (1) l&#8217;ambiguit&#233; inh&#233;rente des
grammaires1 et (2) leur faible capacit&#233; &#224; rendre compte d&#8217;un tr&#232;s grand nombre de ph&#233;nom&#232;nes
&#233;pars2.
</p>
<p>En vue de traiter ces deux probl&#232;mes, nous investiguons ici l&#8217;usage de grammaires de tree-
bank, afin de constituer une cha&#238;ne de traitement d&#8217;analyse syntaxique profonde int&#233;grant une
composante statistique. Nous montrons plus particuli&#232;rement comment r&#233;utiliser un algorithme
d&#8217;analyse &#171; &#233;tat de l&#8217;art &#187; pour le fran&#231;ais de mani&#232;re &#224; obtenir des r&#233;sultats comparables &#224; ceux
obtenus pour la plupart des langues europ&#233;ennes except&#233; l&#8217;anglais.
</p>
<p>La plupart des algorithmes d&#8217;analyse syntaxique statistique reposant sur une grammaire de tree-
bank sont mis au point &#224; partir du Penn Treebank (Marcus et al., 1994), corpus arbor&#233; de r&#233;f&#233;-
</p>
<p>1Les analyseurs symboliques bas&#233;s sur des grammaires formelles ne fournissent pas tels quels de solution &#224; la
d&#233;sambiguisation syntaxique. D&#8217;autres approches symboliques int&#232;grent directement la t&#226;che de d&#233;sambiguisation,
comme (Bourigault &amp; Fabre, 2000)
</p>
<p>2Les r&#232;gles de grammaires extraites d&#8217;un corpus arbor&#233; suivent une distribution de Zipf. On a comme corol-
laire que la taille de la grammaire augmente de mani&#232;re constante avec la taille du corpus, et pour cons&#233;quence
qu&#8217;une grammaire de corpus n&#8217;est pas born&#233;e. On a donc une contradiction avec l&#8217;hypoth&#232;se fondamentale qu&#8217;une
grammaire formelle est un objet born&#233;, ce qui explique &#8211; entre autres &#8211; les difficult&#233;s m&#233;thodologiques &#224; &#233;tablir un
traitement robuste sur corpus avec des grammaires dites de comp&#233;tence. Par contraste, les m&#233;thodes probabilistes
sont &#233;quip&#233;es de m&#233;canismes bien &#233;tudi&#233;s pour le traitement de ph&#233;nom&#232;nes de basse fr&#233;quence.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais
</p>
<p>rence pour l&#8217;anglais, comprenant en particulier le corpus du Wall Street Journal (ci-apr&#232;s WSJ),
auquel nous r&#233;f&#233;rons dans toute la suite. Utiliser tels quels ces algorithmes pour d&#8217;autres langues
donne souvent des r&#233;sultats d&#233;cevants.
</p>
<p>Nous pr&#233;sentons divers tests d&#8217;entra&#238;nement de parsers statistiques du fran&#231;ais, avec l&#8217;objectif
de : (i) tester sur le fran&#231;ais le comportement d&#8217;un algorithme d&#8217;apprentissage non lexicalis&#233;
(Petrov et al., 2006), (ii) tirer profit des sp&#233;cificit&#233;s du corpus d&#8217;entra&#238;nement utilis&#233; : le French
Treebank du laboratoire LLF (Abeill&#233; et al., 2003) (ci-apr&#232;s FTB), et particuli&#232;rement son an-
notation morphologique riche, (iii) contraster ces sp&#233;cificit&#233;s avec celles du WSJ.
Nous d&#233;crivons d&#8217;abord les caract&#233;ristiques pertinentes du FTB (Section 2), puis les travaux
ant&#233;rieurs sur le fran&#231;ais et l&#8217;algorithme qu&#8217;ils utilisent (Section 3). Nous pr&#233;sentons ensuite
l&#8217;algorithme que nous utilisons (Section 4) et discutons les exp&#233;riences r&#233;alis&#233;es (Section 5).
</p>
<p>2 Treebank fran&#231;ais
</p>
<p>Le FTB est le seul corpus arbor&#233; fran&#231;ais. Disponible depuis 2003, il est le r&#233;sultat d&#8217;un projet
d&#8217;annotation supervis&#233;e d&#8217;articles du journal Le Monde, men&#233; &#224; l&#8217;universit&#233; de Paris 7 depuis
une dizaine d&#8217;ann&#233;es, sous la direction d&#8217;Anne Abeill&#233;. Les annotations (cf. exemple en Figure
1) sont morphologiques et syntaxiques.
</p>
<p>&lt;SENT&gt;
&lt;NP fct=&quot;SUJ&quot;&gt;
</p>
<p>&lt;w cat=&quot;D&quot; ee=&quot;D-def-ms&quot; ei=&quot;Dms&quot; lemma=&quot;le&quot; mph=&quot;ms&quot; subcat=&quot;def&quot;&gt;le&lt;/w&gt;
&lt;w cat=&quot;N&quot; ee=&quot;N-C-ms&quot; ei=&quot;NCms&quot; lemma=&quot;bilan&quot; mph=&quot;ms&quot; subcat=&quot;C&quot;&gt;bilan&lt;/w&gt;
</p>
<p>&lt;/NP&gt;
&lt;VN&gt;
</p>
<p>&lt;w cat=&quot;ADV&quot; ee=&quot;ADV-neg&quot; ei=&quot;ADV&quot; lemma=&quot;ne&quot; subcat=&quot;neg&quot;&gt;n&#8217;&lt;/w&gt;
&lt;w cat=&quot;V&quot; ee=&quot;V--P3s&quot; ei=&quot;VP3s&quot; lemma=&quot;&#234;tre&quot; mph=&quot;P3s&quot; subcat=&quot;&quot;&gt;est&lt;/w&gt;
</p>
<p>&lt;/VN&gt;
&lt;AdP fct=&quot;MOD&quot;&gt;
</p>
<p>&lt;w compound=&quot;yes&quot; cat=&quot;ADV&quot; ee=&quot;ADV&quot; ei=&quot;ADV&quot; lemma=&quot;peut-&#234;tre&quot;&gt;
&lt;w catint=&quot;V&quot;&gt;peut&lt;/w&gt;
&lt;w catint=&quot;PONCT&quot;&gt;-&lt;/w&gt;
&lt;w catint=&quot;V&quot;&gt;&#234;tre&lt;/w&gt;
</p>
<p>&lt;/w&gt;
&lt;w cat=&quot;ADV&quot; ee=&quot;ADV-neg&quot; ei=&quot;ADV&quot; lemma=&quot;pas&quot; subcat=&quot;neg&quot;&gt;pas&lt;/w&gt;
</p>
<p>&lt;/AdP&gt;
&lt;AP fct=&quot;ATS&quot;&gt;
</p>
<p>&lt;w cat=&quot;ADV&quot; ee=&quot;ADV&quot; ei=&quot;ADV&quot; lemma=&quot;aussi&quot;&gt;aussi&lt;/w&gt;
&lt;w cat=&quot;A&quot; ee=&quot;A-qual-ms&quot; ei=&quot;Ams&quot; lemma=&quot;sombre&quot; mph=&quot;ms&quot; subcat=&quot;qual&quot;&gt;sombre&lt;/w&gt;
</p>
<p>&lt;/AP&gt;
&lt;w cat=&quot;PONCT&quot; ee=&quot;PONCT-S&quot; ei=&quot;PONCTS&quot; lemma=&quot;.&quot; subcat=&quot;S&quot;&gt;.&lt;/w&gt;
</p>
<p>&lt;/SENT&gt;
</p>
<p>FIG. 1 &#8211; Exemple simplifi&#233; de la source du FTB
</p>
<p>Ce corpus est toujours
en cours de d&#233;veloppe-
ment. Une version finali-
s&#233;e et compl&#232;tement cor-
rig&#233;e de la sous-partie du
corpus annot&#233;e en fonc-
tions syntaxiques(Abeill&#233;
&amp; Barrier, 2004) est atten-
due prochainement. Nous
avons travaill&#233; avec une
version provisoire de cette
sous-partie, partiellement
corrig&#233;e, qui comporte 12-
351 phrases (dans toute la
suite FTB r&#233;f&#232;re &#224; cette version).
Nous donnons ci-dessous les caract&#233;ristiques du FTB par rapport au WSJ, qu&#8217;il s&#8217;agisse de
caract&#233;ristiques li&#233;es &#224; la langue, au corpus ou au sch&#233;ma d&#8217;annotation choisi :
</p>
<p>La taille : Le FTB compte 385 458 occurrences de tokens, soit environ 3 fois moins de mots
que le WSJ.
</p>
<p>Un grand nombre de compos&#233;s : Contrairement au WSJ, les compos&#233;s sont explicitement an-
not&#233;s dans le FTB (cf. le codage de peut-&#234;tre, Figure 1), et sont tr&#232;s nombreux : 14,52% des
occurrences de tokens entrent dans un mot compos&#233;. Ils incluent des s&#233;quences dont les compo-
sants n&#8217;existent pas isol&#233;ment (aujourd&#8217;hui), dont la s&#233;mantique est non compositionnelle (carte
bleue), ou dont la syntaxe n&#8217;est pas r&#233;guli&#232;re (&#224; la va-vite), des expressions verbales (mettre en
garde), des entit&#233;s nomm&#233;es (Union hospitali&#232;re priv&#233;e), des s&#233;quences &#224; s&#233;mantique compo-
sitionnelle mais o&#249; l&#8217;insertion est peu ou pas possible (garde d&#8217;enfants, commission ex&#233;cutive).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais
</p>
<p>Les nombres en chiffres ou en lettres sont &#233;galement marqu&#233;s sous forme de compos&#233;s (plus de
10% des occurrences de compos&#233;s). Ainsi l&#8217;apprentissage &#224; r&#233;aliser sur le FTB est double : pour
une s&#233;quence N1 pr&#233;p N2, il faut d&#233;cider entre former un compos&#233;, ou attacher la pr&#233;position
au N1 ou plus haut dans l&#8217;arbre.
</p>
<p>La longueur des phrases : Le FTB est segment&#233; en 12351 phrases dont la longueur moyenne
est de 31 tokens contre 24 pour le WSJ.
</p>
<p>La flexion du fran&#231;ais : La flexion riche du fran&#231;ais comparativement &#224; l&#8217;anglais a potentielle-
ment un fort impact sur l&#8217;entra&#238;nement d&#8217;un analyseur. Le FTB compte 24 098 formes distinctes,
soit une moyenne de 16 occurrences par forme, contre 12 pour le WSJ. Cela a potentiellement
un impact n&#233;gatif par dispersion des donn&#233;es : l&#8217;utilisation brute (i.e. sans lemmatisation) du
FTB impose un nombre de formes distinctes en moyenne 1,3 fois sup&#233;rieur &#224; celui d&#8217;un corpus
&#233;quivalent anglais. &#192; l&#8217;inverse, la flexion peut constituer un atout en fournissant des indices
pour les rattachements syntaxiques.
</p>
<p>Une annotation morphologique riche : Les formes fl&#233;chies (simples ou compos&#233;es) sont r&#233;-
parties en 13 cat&#233;gories principales (trait cat), contre 44 pour le WSJ. Mais les 13 cat&#233;gories
pour le fran&#231;ais sont divis&#233;s en sous-cat&#233;gories (trait subcat) : 34 en tout. Les traits flexionnels
(trait mph) et le lemme sont explicit&#233;s.
Une structure plus plate : Comme le WSJ, le FTB annote en constituants et pas en d&#233;pen-
dances, mais avec une structure moins hi&#233;rarchis&#233;e. Par phrase, on trouve en moyenne 19,6
occurrences de symboles non terminaux autres que les cat&#233;gories, contre 18,7 pour le WSJ, et
24 en normalisant sur la longueur des phrases. L&#8217;impact du sch&#233;ma d&#8217;annotation est mal connu :
deux hypoth&#232;ses sont envisageables : (1) la structure plate faciliterait la t&#226;che de parsing (moins
de fronti&#232;res &#224; marquer) et (2) elle cause une dispersion des donn&#233;es (plus de parties droites
concurrentes pour un m&#234;me symbole gauche, ce qui compliquerait la t&#226;che dans le cadre PCFG
(cf. Section 3).
Fonctions syntaxiques : Les constituants du FTB sont &#233;galement partiellement marqu&#233;s par
une fonction (strictement) syntaxique (cf. trait fct, Figure 1). Le WSJ comporte des symboles
fonctionnels partag&#233;s entre fonctions syntaxiques et s&#233;mantiques.
</p>
<p>3 Analyse syntaxique lexicalis&#233;e pour le fran&#231;ais
</p>
<p>Nous pr&#233;sentons ici, en indiquant leurs limites, les travaux ant&#233;rieurs en analyse syntaxique sta-
tistique du fran&#231;ais. Ceux-ci reposent principalement sur une application de techniques d&#8217;ana-
lyse dites lexicalis&#233;es, en adaptant au fran&#231;ais l&#8217;algorithme d&#8217;analyse de Collins.
</p>
<p>Les grammaires hors-contexte probabilistes (PCFG) sont un formalisme classique pour l&#8217;ana-
lyse syntaxique. Il s&#8217;agit d&#8217;un mod&#232;le de langage qui assigne en particulier une probabilit&#233;
P (t) =
</p>
<p>&#8719;
A&#8594;&#945;&#8712;t
</p>
<p>P (A &#8594; &#945;) &#224; tout arbre t engendr&#233; par la grammaire en posant une hypo-
th&#232;se d&#8217;ind&#233;pendance conditionnelle entre les r&#232;gles &#233;mises. L&#8217;analyse syntaxique d&#233;sambi-
guis&#233;e consiste alors &#224; renvoyer l&#8217;arbre t qui a la plus grande probabilit&#233;, parmi les analyses
concurrentes pour une phrase. Si ce premier probl&#232;me d&#8217;optimisation se r&#233;sout techniquement
en adaptant des algorithmes de programmation dynamique bien connus (analyse tabulaire, Vi-
terbi), il reste que pour l&#8217;analyse du langage naturel, deux critiques sont formul&#233;es &#224; PCFG :
(1) les hypoth&#232;ses d&#8217;ind&#233;pendance conditionnelles sont trop fortes (2) le mod&#232;le accorde trop
peu d&#8217;importance au lexique (les cat&#233;gories de mots sont une g&#233;n&#233;ralisation trop forte). Un troi-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais
</p>
<p>si&#232;me probl&#232;me, pratique cette fois, est la dispersion des donn&#233;es. Dans le cas de grammaires de
treebank, l&#8217;estimation de probabilit&#233;s pour les r&#232;gles apparaissant rarement est rendue difficile.
Pour r&#233;soudre ce probl&#232;me, les algorithmes d&#8217;analyse comportent des proc&#233;dures de lissage qui
ont un impact consid&#233;rable sur leurs performances3.
</p>
<p>L&#8217;analyse syntaxique dite lexicalis&#233;e, introduite par (Collins, 2003) r&#233;pond &#224; la critique (2) en
annotant les noeuds syntagmatiques par le mot t&#234;te, probabilisant ainsi des d&#233;pendances lexica-
lis&#233;es. Pour contrer l&#8217;effet de dispersion de donn&#233;es, Collins formule son mod&#232;le en posant des
hypoth&#232;ses d&#8217;ind&#233;pendance suppl&#233;mentaires, entre les symboles non-t&#234;te des r&#232;gles de gram-
maire. C&#8217;est ce paradigme d&#8217;analyse qui permet d&#8217;obtenir les meilleurs parsers statistiques de
l&#8217;anglais, appris sur le WSJ. Cependant, nous pensons que l&#8217;application de ce type de mod&#232;le
au fran&#231;ais pose plusieurs probl&#232;mes. Premi&#232;rement, Collins int&#232;gre des heuristiques d&#233;pen-
dantes du sch&#233;ma d&#8217;annotation (distinction argument/ajout, coordination) non applicables telles
quelles au FTB. Deuxi&#232;mement, la caract&#233;ristique majeure du mod&#232;le lexicalis&#233;, les d&#233;pen-
dances bi-lexicales, est transposable telle quelle &#224; une autre langue. Mais elle est fortement
remise en cause comme explication des meilleures performances du mod&#232;le lexicalis&#233; : (Gil-
dea, 2001) montre non seulement que supprimer les d&#233;pendances lexicalis&#233;es a peu d&#8217;impact
dans le cas o&#249; phrases d&#8217;entra&#238;nement et de test proviennent du m&#234;me corpus (tests intra WSJ,
ou intra Brown), mais en plus que cela n&#8217;a aucun impact dans le cas o&#249; phrases d&#8217;entra&#238;nement
proviennent du WSJ et phrases de test proviennent du Brown corpus. En bref, les d&#233;pendances
lexicalis&#233;es sont rarement disponibles et c&#8217;est le lissage qui s&#8217;applique en g&#233;n&#233;ral, a fortiori
lorsque l&#8217;on change de corpus. Ce point est crucial pour une cha&#238;ne de traitement robuste, et
&#233;galement pour l&#8217;apprentissage &#224; partir du FTB, corpus de petite taille.
</p>
<p>Cette observation est renforc&#233;e par les r&#233;sultats mitig&#233;s obtenus avec des analyseurs lexicalis&#233;s,
&#224; partir de versions ant&#233;rieures et/ou modifi&#233;es du FTB : (Arun &amp; Keller, 2005) et (Schluter &amp;
van Genabith, 2007). Ils ont &#233;t&#233; amen&#233;s &#224; modifier les structures de donn&#233;es (automatiquement
pour les premiers, avec r&#233;annotation manuelle pour les seconds), pour se rapprocher des hy-
poth&#232;ses sous-jacentes &#224; l&#8217;algorithme de Collins. (Arun &amp; Keller, 2005) obtiennent un F-score
de 80.45 sur un corpus de 20609 phrases, et (Schluter &amp; van Genabith, 2007) obtiennent 79.95
sur un corpus r&#233;annot&#233; d&#8217;environ 4700 phrases4. (Nasr, 2006) d&#233;crit des exp&#233;riences de parsing
probabiliste en d&#233;pendances, &#224; partir du FTB, mais nous ne sommes pas actuellement en mesure
de comparer ses r&#233;sultats &#224; ceux obtenus avec une analyse en constituants.
</p>
<p>4 Analyse statistique non lexicalis&#233;e
</p>
<p>Nous proposons ici d&#8217;investiguer des analyseurs qui rel&#232;vent du paradigme dit non lexicalis&#233;
(Johnson, 1998; Klein &amp; Manning, 2003). Ceux-ci r&#233;pondent &#224; la critique (1) de PCFG (supra)
en utilisant des transformations du treebank internes au processus d&#8217;entra&#238;nement/analyse. Les
</p>
<p>3Ce probl&#232;me est particuli&#232;rement vrai dans le cas d&#8217;un corpus &#224; structure plate : les grammaires induites du
FTB comportent 13148 r&#232;gles contre 8433 pour un corpus anglais &#233;quivalent, extrait du WSJ (Section 5).
</p>
<p>4(Schluter &amp; van Genabith, 2007) estiment par r&#233;gression lin&#233;aire un r&#233;sultat de 82.44 en passant au corpus fran-
&#231;ais total, y compris phrases non fonctionnellement annot&#233;es, soit 18548 phrases. Les scores donn&#233;s correspondent
&#224; des exp&#233;riences avec algorithme lexicalis&#233;, fusion des compos&#233;s, tagging interne, et &#233;valuation PARSEVAL. Les
diff&#233;rences avec nos r&#233;sultats fournis Section 5, sont l&#8217;algorithme (non lexicalis&#233;), la non prise en compte de la
ponctuation dans l&#8217;&#233;valuation PARSEVAL, et le corpus d&#8217;entra&#238;nement : ces auteurs ont travaill&#233; chacun avec une
sous-partie diff&#233;rente d&#8217;une version ant&#233;rieure du corpus. Anne Abeill&#233; a depuis fourni une version des phrases
fonctionnellement annot&#233;es avec des corrections suppl&#233;mentaires.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais
</p>
<p>NP
</p>
<p>DET N ADJ PP
</p>
<p>NP
</p>
<p>DET NP :N+ADJ+PP
</p>
<p>N NP :ADJ+PP
</p>
<p>ADJ PP
</p>
<p>NP
</p>
<p>DET NP :N+ADJ
</p>
<p>N NP :ADJ+PP
</p>
<p>ADJ PP
</p>
<p>NP
</p>
<p>DET NP :N
</p>
<p>N NP :ADJ
</p>
<p>ADJ PP
</p>
<p>NP
</p>
<p>DET NP :
</p>
<p>N NP :
</p>
<p>ADJ PP
R&#232;gle Originale CNF ou Markovisation droite (h =&#8734;) Markovisation droite (h = 2) Markovisation droite (h = 1) Markovisation droite (h = 0)
</p>
<p>FIG. 2 &#8211; Exemples de markovisations horizontales d&#8217;ordre h
</p>
<p>manipulations effectu&#233;es sont de deux types : (a) Modifications de structure : une forme sp&#233;-
cifique de binarisation des arbres, la markovisation horizontale, est couramment utilis&#233;e pour
pallier &#224; la dispersion des donn&#233;es (Klein &amp; Manning, 2003) comme illustr&#233; en figure 25 (b)
Modifications de l&#8217;&#233;tiquetage des noeuds par sp&#233;cialisation / g&#233;n&#233;ralisation des cat&#233;gories syn-
tagmatiques ou lexicales pour r&#233;duire les hypoth&#232;ses d&#8217;ind&#233;pendances trop fortes de PCFG.
</p>
<p>Si (Klein &amp; Manning, 2003) montrent que la combinaison de ces techniques de pr&#233;compilation
augmentent consid&#233;rablement la correction (et l&#8217;efficacit&#233;) de l&#8217;analyse, les modifications de
type (a) et (b) p&#234;chent par leur caract&#232;re proc&#233;dural et leur interd&#233;pendance. Les d&#233;finir ma-
nuellement reste laborieux. Aussi, (Matsuzaki et al., 2005) am&#233;liorent cette premi&#232;re version
en la simulant par apprentissage6. Ils d&#233;finissent un mod&#232;le appel&#233; PCFG-LA ou PCFG aug-
ment&#233;e de symboles latents (cach&#233;s). La grammaire latente est engendr&#233;e automatiquement en
combinant tout non terminal d&#8217;une grammaire induite du treebank &#224; tout symbole cach&#233; pris
dans un ensemble pr&#233;d&#233;fini, ce qui a pour effet de d&#233;multiplier consid&#233;rablement la taille de la
grammaire. Les param&#232;tres de la grammaire latente sont estim&#233;s sur les arbres observ&#233;s &#224; l&#8217;aide
d&#8217;une instanciation sp&#233;cifique de l&#8217;algorithme Esp&#233;rance-Maximisation (EM).
Afin d&#8217;assigner les symboles cach&#233;s de mani&#232;re optimale, (Petrov et al., 2006) proposent la
m&#233;thode suivante : &#224; partir d&#8217;une grammaire de base G0 induite sur corpus, l&#8217;algorithme d&#8217;ap-
prentissage cr&#233;e it&#233;rativement n grammaires G1 . . . Gn (avec n = 5 en pratique). Chaque &#233;tape
de l&#8217;it&#233;ration comporte les &#233;tapes suivantes :
&#8211; SPLIT : produire une nouvelle grammaire Gi &#224; partir de Gi&#8722;1 en divisant chaque non terminal
</p>
<p>de Gi&#8722;1 en deux nouveaux non terminaux. Estimer Gi par maximum de vraisemblance sur
le treebank observ&#233; en utilisant une variante de inside/outside. Cette &#233;tape consiste &#224; ajouter
des annotations latentes.
</p>
<p>&#8211; MERGE : Pour chaque symbole divis&#233; &#224; l&#8217;&#233;tape pr&#233;c&#233;dente : le fusionner &#224; nouveau. Si la
baisse de vraisemblance (utilisation d&#8217;une variante de inside) du treebank observ&#233; est faible,
alors pr&#233;server la fusion, sinon pr&#233;server la division. Cette &#233;tape vise &#224; &#233;viter les divisions
inutiles et &#224; minimiser les risques de surentra&#238;nement.
</p>
<p>&#8211; SMOOTH : Lisser les probabilit&#233;s des r&#232;gles qui ont le m&#234;me symbole p&#232;re par interpolation.
Pour le fran&#231;ais cet algorithme a deux int&#233;r&#234;ts : (a) Une markovisation horizontale d&#8217;ordre 0
permet d&#8217;&#233;viter un effet d&#8217;&#233;parpillement des donn&#233;es d&#251; au sch&#233;ma d&#8217;annotation plat et &#224; la
petite taille du corpus d&#8217;entra&#238;nement et (b) la sp&#233;cialisation de la grammaire est ind&#233;pendante
de toute hypoth&#232;se a priori sur la structure des arbres du treebank, contrairement aux hypoth&#232;ses
sous-jacentes aux mod&#232;les lexicalis&#233;s.
</p>
<p>5La markovisation droite d&#8217;ordre h se formule comme suit : P (A &#8594; B1 . . . Bn)=def P (B1, . . . , Bn|A) =&#8719;
n&#8722;1
</p>
<p>i=1
P (Bi|Bi+1, . . . , Bn, A) &#8776;
</p>
<p>&#8719;
n&#8722;1
</p>
<p>i=1
P (Bi|Bi+1, . . . , Bi+h, A). Ce que (Petrov et al., 2006) impl&#233;mentent
</p>
<p>en binarisant les arbres comme d&#233;crit en figure 2, c&#8217;est-&#224;-dire en approximant cette formule par un fragment de
d&#233;rivation produit par une PCFG.
</p>
<p>6Ce qui donne en pratique des r&#233;sultats &#233;quivalents et g&#233;n&#233;ralement meilleurs. L&#8217;apprentissage ne porte que sur
les cat&#233;gories et pas sur la structure.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais
</p>
<p>5 Exp&#233;riences
</p>
<p>Les travaux en analyse syntaxique statistique pour le fran&#231;ais cit&#233;s pr&#233;c&#233;demment ont exploit&#233;
un minimum d&#8217;information du corpus arbor&#233; : les cat&#233;gories principales (attribut cat) associ&#233;es
aux pr&#233;terminaux ainsi que les cat&#233;gories standard des non terminaux. Nous &#233;tudions ici com-
ment tirer parti de l&#8217;information suppl&#233;mentaire contenue dans le treebank &#224; des fins d&#8217;analyse
automatique. Il s&#8217;agit de tester l&#8217;impact de diff&#233;rents param&#232;tres li&#233;s au sch&#233;ma d&#8217;annotation
du FTB sur l&#8217;algorithme de (Petrov et al., 2006). Nous comparons enfin les performances du
meilleur analyseur ainsi obtenu avec un apprentissage sur une sous-partie comparable du WSJ,
afin d&#8217;&#233;valuer la marge d&#8217;am&#233;lioration restante.
</p>
<p>Protocole L&#8217;ensemble des observations que nous pr&#233;sentons ci-dessous se fondent syst&#233;mati-
quement sur un argument d&#8217;&#233;valuation, avec le protocole suivant : pour chaque instance engen-
dr&#233;e, les 12351 phrases du treebank sont divis&#233;es en trois sections : (1) test (les 1235 premi&#232;res
phrases), (2) d&#233;veloppement (les 1235 phrases suivantes), et (3) entra&#238;nement (le reste).
La t&#226;che d&#8217;&#233;valuation donne en entr&#233;e &#224; chacun des analyseurs une cha&#238;ne parfaitement segmen-
t&#233;e de mani&#232;re d&#233;terministe. L&#8217;analyseur test&#233; est charg&#233; de produire un arbre d&#8217;analyse unique
&#224; comparer avec la r&#233;f&#233;rence. Les r&#233;sultats d&#8217;&#233;valuation sont report&#233;s en utilisant le protocole
PARSEVAL tel qu&#8217;impl&#233;ment&#233; par l&#8217;outil d&#8217;&#233;valuation evalb avec param&#232;tres standard de Col-
lins. Autrement dit, les scores de pr&#233;cision, rappel et f-mesure tiennent compte du parenth&#233;sage
mais &#233;galement des cat&#233;gories des noeuds7. Les r&#233;sultats sont report&#233;s pour les phrases de la
section (1) dont le nombre de mots est &#8804; 40.
Implantations utilis&#233;es Pour chaque exp&#233;rience men&#233;e, nous utilisons syst&#233;matiquement deux
algorithmes d&#8217;analyse. Le premier, qui sert de t&#233;moin, est un analyseur PCFG &#171; standard &#187; dont
l&#8217;&#233;tiquetage est r&#233;alis&#233; par un &#233;tiqueteur trigramme (TNT/LNCKY)8 . Pour chaque test, cet ana-
lyseur a &#233;t&#233; entrain&#233; sur les sections (2) et (3).
De plus, nous utilisons l&#8217;analyseur de Berkeley (Petrov et al., 2006), not&#233; BKY, avec une mar-
kovisation horizontale h=09. Nous avons adapt&#233; au fran&#231;ais (nous inspirant de (Arun &amp; Keller,
2005)) le mod&#232;le de lissage lexical de l&#8217;analyseur : il fonctionne par clustering de mots incon-
nus et utilise des indices de capitalisation, marques typographiques et suffixes discriminants.
Cet analyseur est entra&#238;n&#233; sur (3) et utilise la section (2) pour ajuster les param&#232;tres de EM.
</p>
<p>Exp&#233;riences Les exp&#233;riences que nous avons r&#233;alis&#233;es testent principalement 4 facteurs : (1)
l&#8217;impact des mots compos&#233;s sur la t&#226;che d&#8217;analyse, (2) l&#8217;impact de l&#8217;annotation morphologique,
(3) l&#8217;impact de la flexion riche du fran&#231;ais, et (4) l&#8217;usage de fonctions syntaxiques. Finalement,
nous mettons en perspective les r&#233;sultats obtenus pour le fran&#231;ais avec ceux obtenus sur un
corpus anglais approximant les propri&#233;t&#233;s formelles du corpus fran&#231;ais10.
</p>
<p>7Suivant les conventions classiques utilis&#233;es pour l&#8217;&#233;valuation sur le Penn TreeBank, nous avons ajout&#233; un
noeud racine artificiel &#224; chacun des arbres ; et les noeuds de ponctuation sont ignor&#233;s dans l&#8217;&#233;valuation, ce qui
n&#8217;est pas le cas pour (Schluter &amp; van Genabith, 2007)
</p>
<p>8Formellement, il ne s&#8217;agit donc pas strictement d&#8217;un algorithme PCFG compl&#232;tement standard. Il s&#8217;agit plut&#244;t
d&#8217;un compromis &#171; pratique &#187; o&#249; l&#8217;&#233;tiqueteur a pour fonction annexe de fournir un algorithme de lissage. L&#8217;&#233;ti-
queteur utilis&#233; est TNT (Brants, 2000), l&#8217;analyseur est l&#8217;impl&#233;mentation LNCKY distribu&#233;e par Mark Johnson
(http ://www.cog.brown.edu/&#8764;mj/Software.htm).
</p>
<p>9Pour le corpus TREEBANK+ (infra), nous obtenons F=86.41 pour h=0, 84.84 pour h=1, et 82.85 pour h=2.
10Les tests sont r&#233;alis&#233;s suite &#224; deux normalisations : (1) les nombres en chiffres arabes parfois encod&#233;s en
</p>
<p>plusieurs tokens, sont syst&#233;matiquement fusionn&#233;s en un seul token. (2) Les amalgames (ex. &#224;+le = au, &#224;+lequel</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais
</p>
<p>Mots compos&#233;s Les compos&#233;s explicites du FTB complexifient la t&#226;che d&#8217;apprentissage. Une
solution pour simplifier le probl&#232;me est de fusionner les compos&#233;s, suivant en cela (Arun &amp;
Keller, 2005) et (Schluter &amp; van Genabith, 2007). Par exemple un compos&#233; initialement marqu&#233;
(Adv (P de) (Adv m&#234;me)) est remplac&#233; par (Adv de_m&#234;me). Cela facilite la t&#226;che, et
suppose une utilisation du parser obtenu avec en entr&#233;e une fusion parfaite des compos&#233;s.
</p>
<p>Voici quelques exp&#233;riences ne supposant pas ce pr&#233;-traitement (Table 1). En n&#8217;utilisant que la
cat&#233;gorie principale (TREEBANKMIN), on obtient F-score=83.09 sans fusionner, &#224; comparer &#224;
F-score=84.85 avec fusion. Pour capturer qu&#8217;un composant n&#8217;a pas la m&#234;me distribution qu&#8217;un
mot simple, nous avons test&#233; de distinguer par un suffixe les symboles de composants de com-
pos&#233;s (Adv (P* de) (Adv* m&#234;me)), ce qui finalement n&#8217;a pas d&#8217;impact (F-score = 83.09).
Enfin, pour obtenir un parser moins d&#233;pendant de la d&#233;finition assez large de compos&#233; du FTB,
nous avons &#233;galement cherch&#233; sommairement &#224; ne conserver que les compos&#233;s syntaxiquement
non r&#233;guliers (par exemple (ADV (P en) (A particulier)), o&#249; la s&#233;quence P A se com-
porte comme un adverbe). Pour cela nous testons de &#8217;d&#233;faire&#8217; les compos&#233;s &#224; syntaxe r&#233;guli&#232;re
ayant les patrons les plus productifs : nous d&#233;faisons les compos&#233;s de patrons N=(N A? P D?
N), N=(A N) et N=(N A A?), soit 5854 occurrences de compos&#233;s sur 20413. Par exemple le
sous-arbre pour le compos&#233; (N (N loyer) (P de) (D l&#8217;) (N argent)) est rempla&#231;&#233;
par une suite de deux noeuds (N loyer) et (PP (P de) (NP (D l&#8217;) (N argent))),
qui s&#8217;ins&#232;rent comme fils du NP p&#232;re. A noter que cela modifie le nombre de constituants pris
en compte par PARSEVAL, donc le F-score obtenu (84.97) est meilleur mais pas comparable.
En revanche la diminution du nombre moyen de constituants qui croisent un constituant cor-
rect est un signe que les d&#233;pendances syntaxiques r&#233;guli&#232;res internes aux compos&#233;s d&#233;faits sont
globalement recaptur&#233;es.
</p>
<p>Dans toute la suite nous donnons des r&#233;sultats en mode fusionn&#233;, ce qui facilite les comparaisons
avec (Arun &amp; Keller, 2005) et (Schluter &amp; van Genabith, 2007).
</p>
<p>TRAITEMENT DES COMPOS&#201;S PR&#201;C. RAPPEL F-SCORE NB MOYEN NB DE PHRASES
SUR TREEBANKMIN CROISEMENTS TEST &#8804; 40 MOTS
Compos&#233;s fusionn&#233;s 85.25 84.46 84.85 0.94 992
Compos&#233;s tels quels 83.44 82.73 83.09 0.92 932
Composants marqu&#233;s 83.35 82.82 83.09 0.93 932
Compos&#233;s &#8217;d&#233;faits&#8217; 85.21 84.74 84.97 0.88 932
+ Composants restants marqu&#233;s
</p>
<p>TAB. 1 &#8211; Diff&#233;rents traitements des compos&#233;s sur TREEBANKMIN
</p>
<p>Annotation morphosyntaxique Le FTB comporte trois champs morphosyntaxiques : la ca-
t&#233;gorie principale (champ cat), une sous-cat&#233;gorie (champ subcat raffinant cat), comme
par exemple le d&#233;fini, l&#8217;interrogatif, le d&#233;monstratif ou le possessif pour un d&#233;terminant, ainsi
qu&#8217;un champ mph comportant des traits flexionnels (par exemple genre, nombre, personne).
De mani&#232;re &#224; tester l&#8217;impact des informations contenues dans ces champs, nous avons instan-
ci&#233; un corpus TREEBANKSUBCAT, dont les pr&#233;terminaux sont la concat&#233;nation des champs
cat + subcat, ainsi qu&#8217;un corpus TREEBANKMAX dont les pr&#233;terminaux sont la concat&#233;na-
tion des trois champs cat + subcat + mph.
</p>
<p>En comparant TREEBANKSUBCAT et TREEBANKMIN (table 3), on constate que l&#8217;annotation
= auquel encod&#233;s en deux tokens dont un vide sont recod&#233;s en un seul, de cat&#233;gorie P+D ou P+PRO selon le cas.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais
</p>
<p>TAG CAT SOUS-CAT MODE
V V - indicatif
VIMP V - imp&#233;ratif
VINF V - infinitif
VS V - subjonctif
VPP V - participe pass&#233;
VPR V - participe pr&#233;sent
NPP N P -
NC N C -
CS C S -
CC C C -
</p>
<p>TAG CAT SOUS-CAT MODE
CLS CL suj -
CLO CL obj -
CLR CL refl -
P P - -
P+D voir texte
P+PRO voir texte
I I - -
PONCT PONCT - -
ET ET - -
</p>
<p>TAG CAT SOUS-CAT MODE
ADJWH A int -
ADJ A &#172;int -
ADVWH ADV int -
ADV ADV &#172;int -
PROWH PRO int -
PROREL PRO rel -
PRO PRO &#172;(int | rel) -
DETWH D int -
DET D &#172;int -
</p>
<p>TAB. 2 &#8211; Symboles pr&#233;terminaux (tags) de TREEBANK+
</p>
<p>en sous-cat&#233;gories a un impact statistiquement significatif (p = 0.015)11 sur les performances de
l&#8217;analyseur de BKY. Par contre ajouter toute l&#8217;information morphologique (TREEBANKMAX),
d&#233;grade significativement les r&#233;sultats pour l&#8217;analyseur BKY.
</p>
<p>C&#8217;est une solution interm&#233;diaire, le corpus TREEBANK+, qui permet d&#8217;obtenir les meilleurs
r&#233;sultats, en s&#233;lectionnant uniquement le mode des verbes et certains traits de sous-cat&#233;gories
(table 2). L&#8217;intuition derri&#232;re le choix de ce jeu de pr&#233;terminaux est analogue &#224; celle indiqu&#233;e
dans (Schluter &amp; van Genabith, 2007) : on a ici guid&#233; l&#8217;apprentissage en distinguant les cat&#233;go-
ries verbales selon le mode, qui a un impact consid&#233;rable pour capturer l&#8217;ordre des mots autour
du verbe dans une grammaire. Le r&#233;sultat pour TREEBANK+ est une am&#233;lioration statistique-
ment significative des r&#233;sultats par comparaison avec TREEBANKSUBCAT (p = 0.002).
</p>
<p>CORPUS PR&#201;CISION RAPPEL F1-SCORE COUVERTURE TAG ACCY F1-SCORE
(TNT/LNCKY)
</p>
<p>TreebankMin 85.25 84.46 84.85 99.59 97.35 69.68
TreebankMax 84.17 84.08 84.13 99.69 92.20 74.76
</p>
<p>TreebankSubcat 85.91 85.58 85.74 99.59 96.63 72.54
Treebank+ 86.57 86.25 86.41 99.79 96.83 75.02
</p>
<p>TAB. 3 &#8211; &#201;valuation de l&#8217;impact de la richesse du jeu de pr&#233;terminaux
</p>
<p>Lexicalisation / Flexion Pour &#233;valuer l&#8217;impact de la flexion riche du fran&#231;ais, soulign&#233;e section
2, nous comparons l&#8217;utilisation de formes fl&#233;chies versus l&#8217;utilisation de symboles regroupant
des formes fl&#233;chies. Un regroupement par lemme semble trop grossier : nous testons plut&#244;t
un regroupement selon les cat&#233;gories du jeu TREEBANK+. Pour ce faire, nous rempla&#231;ons une
forme fl&#233;chie par (tag+lemme)12, y compris dans les phrases de test, ce qui induit un tagging
parfait13. Ce cas est donc &#224; comparer &#224; un &#233;quivalent en formes fl&#233;chies non regroup&#233;es, en
tagging parfait, simul&#233; en rempla&#231;ant une forme fl&#233;chie par (tag+forme). Les r&#233;sultats sont
donn&#233;s table 4. Le regroupement de formes a effectivement un impact positif, quoique faible
(F-score de 0.39 point sup&#233;rieur &#224; l&#8217;&#233;quivalent en formes fl&#233;chies, et meilleur nombre moyen
de croisements). La moindre dispersion des donn&#233;es a plus d&#8217;effet que la perte des marques
d&#8217;accord 14.
</p>
<p>Fonctions syntaxiques Nous avons test&#233; d&#8217;encoder dans les non terminaux les fonctions syn-
taxiques annot&#233;es dans le treebank. Cela cr&#233;e de mani&#232;re pr&#233;visible une dispersion des donn&#233;es,
</p>
<p>11En utilisant un t-test unidirectionnel d&#8217;&#233;carts &#224; la moyenne pour &#233;chantillons appari&#233;s.
12Par exemple, les diff&#233;rentes formes de manger sont remplac&#233;es par 6 symboles selon le jeu TREEBANK+ :
</p>
<p>manger-VINF, manger-VPP, manger-VPR, manger-V, manger-VS, manger-VIMP. Les deux formes d&#8217;un nom com-
mun sont remplac&#233;es par une seule, etc...
</p>
<p>13Le lissage lexical est modifi&#233; en cons&#233;quence. Nous envisageons une autre solution, sans le biais du tagging
parfait, qui consisterait &#224; disposer d&#8217;un tagger donnant en entr&#233;e &#224; l&#8217;analyseur des s&#233;quences de couples tag+lemme.
</p>
<p>14Ces r&#233;sultats sont &#224; comparer avec le remplacement simple des mots par leur tag, ce qui donne une version
purement non lexicalis&#233;e, en tagging parfait. On obtient 86.28, ce qui montre bien le peu d&#8217;utilisation de la lexica-
lisation par BKY (dit non lexicalis&#233;, mais o&#249; la lexicalisation intervient par division des cat&#233;gories lexicales).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais
</p>
<p>TERMINAUX PR&#201;CISION RAPPEL F-SCORE COUVERTURE TAG ACCY NB MOY. CROISEMENTS
tag+forme 87.85 87.73 87.79 99.89 99.74 0.86
tag+lemme 86.90 88.16 88.18 99.89 99.80 0.82
tag seul 86.28 86.27 86.28 99.89 100 0.95
</p>
<p>TAB. 4 &#8211; Regroupement de formes fl&#233;chies sur TREEBANK+ (en tagging parfait simul&#233;)
</p>
<p>d&#233;gradant ainsi les r&#233;sultats (F-score=78.73 pour TREEBANK+).
Evaluation sur corpus anglais comparable &#192; titre indicatif et pour estimer la d&#233;pendance &#224; la
langue, nous avons construit un &#233;chantillon du WSJ formellement analogue au corpus fran&#231;ais15,
et comparons les r&#233;sultats. Pour l&#8217;analyseur TNT/LNCKY, on obtient F=71.84 pour l&#8217;anglais
(vs F=75.02 pour le fran&#231;ais en TREEBANK+). Alors que le contraste est invers&#233; avec BKY :
F=88.61 pour l&#8217;anglais, versus F=86.41 pour le fran&#231;ais. Pour l&#8217;anglais, on peut &#233;galement
remarquer que l&#8217;&#233;chantillon utilis&#233;, qui divise la taille du WSJ par trois, ne fait baisser les
r&#233;sultats que de 1.5 point : (Petrov et al., 2006) obtiennent 90.15 sur la totalit&#233; du WSJ.
</p>
<p>6 Conclusion et perspectives
</p>
<p>Cet article montre qu&#8217;il est possible, &#224; partir du FTB et avec un algorithme non lexicalis&#233;, d&#8217;ob-
tenir un analyseur syntaxique statistique satisfaisant pour le fran&#231;ais sur corpus journalistique.
Il est obtenu sur TREEBANK+ et donne un F-Score de 86.41, le meilleur &#224; ce jour &#224; partir du
FTB.
</p>
<p>Les d&#233;savantages potentiels du FTB sont contourn&#233;s par un algorithme non lexicalis&#233; relati-
vement ind&#233;pendant du sch&#233;ma d&#8217;annotation : une markovisation horizontale radicale (h = 0)
diminue l&#8217;effet de dispersion des r&#232;gles, d&#251; &#224; la petite taille du corpus et &#224; la faible compacit&#233; de
la grammaire sous-jacente. Cette hypersimplification initiale est contre-balanc&#233;e dans un second
temps par un algorithme de fusion/s&#233;paration des symboles qui maximise le degr&#233; de granularit&#233;
(et att&#233;nue les effets des hypoth&#232;ses d&#8217;ind&#233;pendance conditionnelles) de la grammaire induite.
On remarque &#233;galement que tirer parti de l&#8217;information suppl&#233;mentaire encod&#233;e dans le tree-
bank (traits subcat,mph et lemma) a un impact sur les performances de l&#8217;analyseur syn-
taxique non lexicalis&#233;. On pense prolonger ce travail en augmentant ce premier analyseur ap-
pris d&#8217;un algorithme de reranking (Charniak &amp; Johnson, 2005) sp&#233;cifique au fran&#231;ais int&#233;grant
des traits non locaux. Il sera en particulier int&#233;ressant d&#8217;&#233;tudier comment exploiter d&#8217;avan-
tage l&#8217;information lexicale dans cette seconde passe. Les premiers r&#233;sultats en fonctions syn-
taxiques sont consid&#233;r&#233;s comme tr&#232;s encourageants. Nous envisageons tester diff&#233;rentes tech-
niques d&#8217;&#233;tiquetage fonctionnel et d&#8217;extraction de d&#233;pendances fonctionnelles en sortie d&#8217;ana-
lyse. Cela permettrait d&#8217;une part la comparaison avec d&#8217;autres analyseurs syntaxiques pour le
fran&#231;ais, et d&#8217;autre part une &#233;valuation interne plus fine, par type de d&#233;pendance.
</p>
<p>Les r&#233;sultats obtenus pour l&#8217;anglais sur un &#233;chantillon du WSJ formellement analogue au FTB,
montrent qu&#8217;il reste certainement une marge de progression : &#224; corpus formellement compa-
rables, les r&#233;sultats pour l&#8217;anglais sont 2 points au-dessus du fran&#231;ais. L&#8217;hypoth&#232;se que cette
</p>
<p>15Cet &#233;chantillon a &#233;t&#233; constitu&#233; par une proc&#233;dure al&#233;atoire augment&#233;e de deux contraintes : (1) l&#8217;&#233;chantillon
anglais comporte le m&#234;me nombre de tokens que TREEBANK+ et (2) la proc&#233;dure fait converger les distributions
en longueur des phrases. L&#8217;algorithme d&#8217;&#233;chantillonnage garantit la convergence des moyennes. Suivant la pratique
courante nous avons supprim&#233; les traces et les annotations fonctionnelles du Penn Treebank.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais
</p>
<p>diff&#233;rence provient d&#8217;une flexion plus riche du fran&#231;ais appara&#238;t comme insuffisante : le gain
obtenu en minimisant la dispersion par flexion est d&#233;cevant. Pour tenter d&#8217;expliquer cet &#233;cart,
nous pensons investiguer l&#8217;utilisation de modifications structurelles automatisables.
</p>
<p>Remerciements Les auteurs tiennent &#224; remercier Anne Abeill&#233;, Laurence Danlos, Slav Petrov,
Natalie Schluter et Djam&#233; Seddah pour leurs conseils lors de la r&#233;alisation de ce travail ainsi
que l&#8217;universit&#233; Paris 7 (Prix Diderot innovation) pour son soutien financier.
</p>
<p>R&#233;f&#233;rences
ABEILL&#201; A. &amp; BARRIER N. (2004). Enriching a french treebank. In Proceedings of Language
Ressources and Evaluation Conference (LREC), Lisbon.
ABEILL&#201; A., CL&#201;MENT L. &amp; TOUSSENEL F. (2003). Treebanks, chapter Building a treebank
for French. Kluwer : Dordrecht.
ARUN A. &amp; KELLER F. (2005). Lexicalization in crosslinguistic probabilistic parsing : The
case of french. In Proceedings of the 43rd Annual Meeting of the Association for Computatio-
nal Linguistics, p. 306&#8211;313, Ann Arbor, MI.
BOURIGAULT D. &amp; FABRE C. (2000). Approche linguistique pour l&#8217;analyse syntaxique de
corpus. Cahiers de grammaires, 25.
BRANTS T. (2000). Tnt &#8211; a statistical part-of-speech tagger. In Proceedings of the 6th Applied
NLP Conference (ANLP), Seattle-WA.
CHARNIAK E. &amp; JOHNSON M. (2005). Coarse-to-fine n-best parsing and maxent discrimina-
tive reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computatio-
nal Linguistics (ACL 2005), Ann Arbor (MI).
COLLINS M. (2003). Head-driven statistical models for natural language parsing. Computa-
tional Linguistics, 29(3).
GILDEA D. (2001). Corpus variation and parser performance. In Conference on Empirical
Methods in Natural Language Processing (EMNLP).
JOHNSON M. (1998). PCFG models of linguistic tree representations. Computational Lin-
guistics, 24(4), 613&#8211;632.
KLEIN D. &amp; MANNING C. D. (2003). Accurate unlexicalized parsing. In Proceedings of the
41st Meeting of the Association for Computational Linguistics.
MARCUS M. P., SANTORINI B. &amp; MARCINKIEWICZ M. A. (1994). Building a large anno-
tated corpus of english : The penn treebank. Computational Linguistics, 19(2), 313&#8211;330.
MATSUZAKI T., MIYAO Y. &amp; TSUJII J. (2005). Probabilistic cfg with latent annotations.
In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics
(ACL), p. 75&#8211;82.
NASR A. (2006). Grammaires de d&#233;pendances g&#233;n&#233;ratives probabilistes. mod&#232;le th&#233;orique et
application &#224; un corpus arbor&#233; du fran&#231;ais. Traitement Automatique des Langues, 46(1).
PETROV S., BARRETT L., THIBAUX R. &amp; KLEIN D. (2006). Learning accurate, compact,
and interpretable tree annotation. In Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meeting of the Association for Computational
Linguistics, Sydney, Australia : Association for Computational Linguistics.
SCHLUTER N. &amp; VAN GENABITH J. (2007). Preparing, restructuring, and augmenting a
french treebank : Lexicalised parsers or coherent treebanks ? In Proceedings of PACLING 07.</p>

</div></div>
</body></html>