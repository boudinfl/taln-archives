TALN 2008, Avignon, 9-13 juin 2008

Experiences d’analyse syntaxique statistique du frangais

Benoit Crabbe et Marie Candito
Université Paris 7 (UFRL) et INRIA (Alpage)
30 rue du Chateau des Rentiers 75013 Paris
{bcrabbe,candito}@linguist.jussieu.fr

Résllmé. Nous montrons qu’il est possible d’obtenir une analyse syntaxique statistique
satisfaisante pour le francais sur du corpus joumalistique, a partir des donnees issues du French
Treebank du laboratoire LLF, a l’aide d’un algorithme d’analyse non lexicalise.

Abstract. We show that we can acquire satisfactory parsing results for French from data
induced from the French Treebank using an unlexicalised parsing algorithm.

M0tS-CléS I Analyseur syntaxique statistique, Analyse syntaxique non lexicalisee, Ana-
lyse du francais.

Keywords: Statistical parser, Unlexicalised parsing, French parsing.

1 Introduction

A l’heure actuelle, la communaute francophone dispose de plusieurs environnements de deve-
loppement de grammaires et d’analyse syntaxique symbolique automatique dite profonde. Ce-
pendant, dans la perspective de realiser une analyse syntaxique profonde a grande echelle sur
corpus, l’analyse syntaxique symbolique pose deux problemes : (1) l’ambiguité inherente des
grammairesl et (2) leur faible capacite a rendre compte d’un tres grand nombre de phenomenes
eparsz.

En vue de traiter ces deux problemes, nous investiguons ici l’usage de grammaires de tree-
bank, aﬁn de constituer une chaine de traitement d’analyse syntaxique profonde integrant une
composante statistique. Nous montrons plus particulierement comment reutiliser un algorithme
d’analyse « etat de l’art » pour le francais de maniere a obtenir des resultats comparables a ceux
obtenus pour la plupart des langues europeennes excepte l’anglais.

La plupart des algorithmes d’analyse syntaxique statistique reposant sur une grammaire de tree-
bank sontIr1is au point a partir du Penn Treebank (Marcus et al., 1994), corpus arbore de refe-

1Les analyseurs symboliques bases sur des grammaires fonnelles ne foumissent pas tels quels de solution a la
desambiguisation syntaxique. D’ autres approches symboliques integrent directement la tache de desambiguisation,
comme (Bourigault & Fabre, 2000)

2Les regles de grammaires extraites d’un corpus arbore suivent une distribution de Zipf. On a come corol-
laire que la taille de la grammaire augmente de maniere constante avec la taille du corpus, et pour consequence
qu’une grammaire de corpus n’est pas bornee. On a done une contradiction avec l’hypothese fondamentale qu’une
grammaire fonnelle est un objet borne, ce qui explique — entre autres — les difﬁcultes methodologiques a etablir un
traitement robuste sur corpus avec des grammaires dites de competence. Par contraste, les methodes probabilistes
sont equipees de mecanismes bien etudies pour le traitement de phenomenes de basse frequence.

Experiences d’analyse syntaxique statistique du francais

rence pour l’anglais, comprenant en particulier le corpus du Wall Street Journal (ci-apres WSJ),
auquel nous référons dans toute la suite. Utiliser tels quels ces algorithmes pour d’autres langues
donne souvent des résultats décevants.

Nous présentons divers tests d’entrainement de parsers statistiques du francais, avec l’objectif
de : (i) tester sur le francais le comportement d’un algorithme d’apprentissage non lexicalisé
(Petrov et al., 2006), (ii) tirer proﬁt des spéciﬁcités du corpus d’entrainement utilisé : le French
Treebank du laboratoire LLF (Abeillé et al., 2003) (ci-apres FTB), et particulierement son an-
notation morphologique riche, (iii) contraster ces spéciﬁcités avec celles du WSJ.

Nous décrivons d’abord les caractéristiques pertinentes du FTB (Section 2), puis les travaux
antérieurs sur le francais et l’algorithme qu’ils utilisent (Section 3). Nous présentons ensuite
l’algorithme que nous utilisons (Section 4) et discutons les expériences réalisées (Section 5).

2 Treebank frangais

Le FTB est le seul corpus arboré francais. Disponible depuis 2003, il est le résultat d’un projet
d’annotation supervisée d’articles du journal Le Monde, mené a l’université de Paris 7 depuis
une dizaine d’années, sous la direction d’Anne Abeillé. Les annotations (cf. exemple en Figure
1) sont morphologiques et syntaxiques.

C6 COI'p11S 6St tO11_]O11I'S (SENT)
/ <NP fct="SUJ">
en cours de deve1oppe— (W cat="D" ee="D—def—ms" er:-ms-v lemma="le" mph="ms" subcat="def">le</w>
. . <w cat="N" ee="N—C—ms" ei="NCms" lemma="bilan" mph="ms" subcat="C">bilan</w>
ment. Une version ﬁnal1- </NP)
, \ <vN>
See Ct  COI'- <w cat="ADV" ee="ADV—neg" ei="ADV" lemma="ne" subcat="neg">n’</w>
. , . <w cat="V" ee="V——P3s" ei="VP3s" lemma="étre" mph="P3s" subcat="">est</w>
rigee de la sous-partie du </VN>

<AdP fct="MOD " >

Corpus  en fOnC- <w compound="yes" cat="ADV" ee="ADV" ei="ADV" lemma="peut—étre">
. . . I <w catint="V">peut</w>
t1ons syntax1ques(Abe1lle <w catint=woNcr">—</w>

<w catint="V">étre</w>

& Barrier, 2004) est atten- </w>

<w cat="ADV" ee="ADV—neg" ei="ADV" lemma="pas" subcat="neg">pas</w>

due prochainement. Nous </AdP>

<AP fct="ATS">

avons  avec une <w cat="ADV" ee="ADV" ei="ADV" lemma="aussi">aussi</w>

<w cat="A" ee="A-qual-ms" ei="Ams" lemma="sombre" mph="ms" subcat="qual">sombre</w>
    :1{rA::t="PONC'I"' ee="PONCT-S" ei="PONCTS" lemma="." subcat="S">.</w>
sous-partie, partiellement </SEN“
corrigée, qui comporte 12-
351 phrases (dans toute 1a FIG. 1 — Exemple simpliﬁé de la source du FTB

suite FTB réfere a cette version).

Nous donnons ci-dessous les caractéristiques du FTB par rapport au WSJ, qu’il s’agisse de
caractéristiques liées a la langue, au corpus ou au schéma d’annotation choisi :

La taille : Le FTB compte 385 458 occurrences de tokens, soit environ 3 fois moins de mots
que le WSJ.

Un grand nombre de composés : Contrairement au WSJ, les composés sont explicitement an-
notés dans le FTB (cf. le codage de pent-étre, Figure 1), et sont tres nombreux : 14,52% des
occurrences de tokens entrent dans un mot composé. Ils incluent des séquences dont les compo-
sants n’existent pas isolément (aujourd’hui), dont la sémantique est non compositionnelle (carte
bleue), ou dont la syntaxe n’est pas réguliere (61 la va-vite), des expressions verbales (mettre en
garde), des entités nommées (Union hospitaliére privée), des sequences a sémantique compo-
sitionnelle mais o1‘1 l’insertion est peu ou pas possible (garde d ’enfants, commission exécutive).

Experiences d’analyse syntaxique statistique du francais

Les nombres en chiffres ou en lettres sont egalement marques sous forme de composes (plus de
10% des occurrences de composes). Ainsi l’apprentissage a realiser sur le FTB est double : pour
une sequence N1 prép N2 , il faut decider entre former un compose, ou attacher la preposition
au N1 ou plus haut dans l’arbre.

La longueur des phrases : Le FTB est segmente en 12351 phrases dont la longueur moyenne
est de 31 tokens contre 24 pour le WSJ.

La ﬂexion du francais : La ﬂexion riche du francais comparativement a l’anglais a potentielle-
ment un fort impact sur l’entrainement d’un analyseur. Le FTB compte 24 098 formes distinctes,
soit une moyenne de 16 occurrences par forme, contre 12 pour le WSJ. Cela a potentiellement
un impact negatif par dispersion des donnees : l’utilisation brute (i.e. sans lemmatisation) du
FTB impose un nombre de formes distinctes en moyenne 1,3 fois superieur a celui d’un corpus
equivalent anglais. A l’inverse, la ﬂexion peut constituer un atout en fournissant des indices
pour les rattachements syntaxiques.

Une annotation morphologique riche : Les formes ﬂechies (simples ou composees) sont re-
parties en 13 categories principales (trait cat), contre 44 pour le WSJ. Mais les 13 categories
pour le francais sont divises en sous-categories (trait subcat) : 34 en tout. Les traits ﬂexionnels
(trait mph) et le lemme sont explicites.

Une structure plus plate : Comme le WSJ, le FTB annote en constituants et pas en depen-
dances, mais avec une structure moins hierarchisee. Par phrase, on trouve en moyenne 19,6
occurrences de symboles non terminaux autres que les categories, contre 18,7 pour le WSJ, et
24 en normalisant sur la longueur des phrases. L’ impact du schema d’annotation est mal connu :
deux hypotheses sont envisageables : (1) la structure plate faciliterait la tache de parsing (moins
de frontieres a marquer) et (2) elle cause une dispersion des donnees (plus de parties droites
concurrentes pour un meme symbole gauche, ce qui compliquerait la tache dans le cadre PCFG
(cf. Section 3).

Fonctions syntaxiques : Les constituants du FTB sont egalement partiellement marques par
une fonction (strictement) syntaxique (cf. trait f ct, Figure 1). Le WSJ comporte des symboles
fonctionnels partages entre fonctions syntaxiques et semantiques.

3 Analyse syntaxique lexicalisée pour le frangais

Nous presentons ici, en indiquant leurs limites, les travaux anterieurs en analyse syntaxique sta-
tistique du francais. Ceux-ci reposent principalement sur une application de techniques d’ana-
lyse dites lexicalisees, en adaptant au francais l’algorithme d’analyse de Collins.

Les grammaires hors-contexte probabilistes (PCFG) sont un formalisme classique pour l’ana-
lyse syntaxique. Il s’agit d’un modele de langage qui assigne en particulier une probabilite
P(t) = HA_,aEt P(A —> 04) a tout arbre t engendre par la grammaire en posant une hypo-
these d’independance conditionnelle entre les regles eIr1ises. L’analyse syntaxique desambi-
guisee consiste alors a renvoyer l’arbre t qui a la plus grande probabilite, parmi les analyses
concurrentes pour une phrase. Si ce premier probleme d’optimisation se resout techniquement
en adaptant des algorithmes de programmation dynamique bien connus (analyse tabulaire, Vi-
terbi), il reste que pour l’analyse du langage naturel, deux critiques sont formulees a PCFG :
(1) les hypotheses d’independance conditionnelles sont trop fortes (2) le modele accorde trop
peu d’impo1tance au lexique (les categories de mots sont une generalisation trop forte). Un troi-

Experiences d’analyse syntaxique statistique du francais

sieme probleme, pratique cette fois, est la dispersion des donnees. Dans le cas de grammaires de
treebank, l’estimation de probabilites pour les regles apparaissant rarement est rendue difﬁcile.
Pour resoudre ce probleme, les algorithmes d’analyse comportent des procedures de lissage qui

ont un impact considerable sur leurs performances3.

L’ analyse syntaxique dite lexicalisee, introduite par (Collins, 2003) repond a la critique (2) en
annotant les noeuds syntagmatiques par le mot tete, probabilisant ainsi des dependances lexica-
lisees. Pour contrer l’effet de dispersion de donnees, Collins formule son modele en posant des
hypotheses d’independance supplementaires, entre les symboles non-tete des regles de gram-
maire. C’est ce paradigme d’analyse qui permet d’obtenir les meilleurs parsers statistiques de
l’anglais, appris sur le WSJ. Cependant, nous pensons que l’application de ce type de modele
au francais pose plusieurs problemes. Premierement, Collins integre des heuristiques depen-
dantes du schema d’annotation (distinction argument/aj out, coordination) non applicables telles
quelles au FTB. Deuxiemement, la caracteristique majeure du modele lexicalise, les depen-
dances bi-lexicales, est transposable telle quelle a une autre langue. Mais elle est fortement
remise en cause comme explication des meilleures performances du modele lexicalise : (Gil-
dea, 2001) montre non seulement que supprimer les dependances lexicalisees a peu d’impact
dans le cas ou phrases d’entrainement et de test proviennent du meme corpus (tests intra WSJ,
ou intra Brown), mais en plus que cela n’a aucun impact dans le cas ou phrases d’entrainement
proviennent du WSJ et phrases de test proviennent du Brown corpus. En bref, les dependances
lexicalisees sont rarement disponibles et c’est le lissage qui s’applique en general, a fortiori
lorsque l’on change de corpus. Ce point est crucial pour une chaine de traitement robuste, et
egalement pour l’apprentissage a partir du FTB, corpus de petite taille.

Cette observation est renforcee par les resultats Initiges obtenus avec des analyseurs lexicalises,
a partir de versions anterieures et/ou modiﬁees du FTB : (Arun & Keller, 2005) et (Schluter &
van Genabith, 2007). Ils ont ete amenes a modiﬁer les structures de donnees (automatiquement
pour les premiers, avec reannotation manuelle pour les seconds), pour se rapprocher des hy-
potheses sous-jacentes a l’algorithme de Collins. (Arun & Keller, 2005) obtiennent un F-score
de 80.45 sur un corpus de 20609 phrases, et (Schluter & van Genabith, 2007) obtiennent 79.95
sur un corpus reannote d’environ 4700 phrases4. (Nasr, 2006) decrit des experiences de parsing
probabiliste en dependances, a partir du FTB, mais nous ne sommes pas actuellement en mesure
de comparer ses resultats a ceux obtenus avec une analyse en constituants.

4 Analyse statistique non lexicalisée

Nous proposons ici d’investiguer des analyseurs qui relevent du paradigme dit non lexicalise
(Johnson, 1998; Klein & Manning, 2003). Ceux-ci repondent a la critique (1) de PCFG (supra)
en utilisant des transformations du treebank intemes au processus d’entrainement/analyse. Les

3Ce probléme est particulierement Vrai dans le cas d’un Corpus :21 structure plate : les grammaires induites du
FTB comportent 13148 regles contre 8433 pour un corpus anglais equivalent, extrait du WSJ (Section 5).

4(Sch1uter & Van Genabith, 2007) estiment par regression lineaire un resultat de 82.44 en passant au corpus fran-
gais total, y compris phrases non fonctionnellement annotees, soit 18548 phrases. Les scores donnes correspondent
a des experiences avec algorithme lexicalisé, fusion des composes, tagging inteme, et evaluation PARSEVAL. Les
differences avec nos résultats foumis Section 5, sont l’a1gorithme (non lexicalisé), la non prise en compte de la
ponctuation dans 1’eVa1uation PARSEVAL, et le corpus d’entrainement : ces auteurs ont travaille chacun avec une
sous—partie djfferente d’une Version anterieure du corpus. Anne Abeille a depuis foumi une Version des phrases
fonctionnellement annotees avec des corrections supplementaires.

Experiences d’analyse syntaxique statistique du francais

NP NP NP NP NP
%W
DET N ADJ PP D ADJ+PP D +ADJ D 2N D 2
N NP :AD.l+PP N NP :AD.l+PP  ADJ 1‘1/\NP :
ADJ PP ADJ PP ADJ PP ADJ PP

Régle Originale CNF ou Markovisarion droite ( h = oo) Markovisarion dmite ( h = 2) Markovisarion droite ( h = 1) Markovisarian droite ( h = 0)

FIG. 2 — Exemples de markovisations horizontales d’ordre h

manipulations effectuées sont de deux types : (a) Modiﬁcations de structure : une forme spe-
ciﬁque de binarisation des arbres, la markovisation horizontale, est couramment utilisée pour
pallier a la dispersion des données (Klein & Manning, 2003) comme illustré en ﬁgure 25 (b)
Modiﬁcations de l’étiquetage des noeuds par spécialisation / généralisation des catégories syn-
tagmatiques ou lexicales pour réduire les hypotheses d’indépendances trop fortes de PCFG.

Si (Klein & Manning, 2003) montrent que la combinaison de ces techniques de précompilation
augmentent considérablement la correction (et l’efﬁcacité) de l’analyse, les modiﬁcations de
type (a) et (b) péchent par leur caractere procédural et leur interdépendance. Les déﬁnir ma-
nuellement reste laborieux. Aussi, (Matsuzaki et al., 2005) améliorent cette premiere version
en la simulant par apprentissage6. Ils déﬁnissent un modele appelé PCFG-LA ou PCFG aug-
mentée de symboles latents (cachés). La grammaire latente est engendrée automatiquement en
combinant tout non terminal d’une grammaire induite du treebank a tout symbole caché pris
dans un ensemble prédéﬁni, ce qui a pour effet de démultiplier considérablement la taille de la
grammaire. Les parametres de la grammaire latente sont estimés sur les arbres observés a l’aide
d’une instanciation spéciﬁque de l’algorithme Espérance-Maximisation (EM).

Aﬁn d’assigner les symboles cachés de maniere optimale, (Petrov et al., 2006) proposent la

méthode suivante : a partir d’une grammaire de base G0 induite sur corpus, l’algorithme d’ap-

prentissage crée itérativement n grammaires G1 . . .Gn (avec n = 5 en pratique). Chaque étape
de l’itération comporte les étapes suivantes :

— SPLIT : produire une nouvelle graInmaire G, a partir de G,-_1 en divisant chaque non terminal
de G,-_1 en deux nouveaux non terminaux. Estimer G, par maximum de vraisemblance sur
le treebank observé en utilisant une variante de inside/outside. Cette étape consiste a ajouter
des annotations latentes.

— MERGE : Pour chaque symbole divisé a l’étape précédente : le fusionner a nouveau. Si la
baisse de vraisemblance (utilisation d’une variante de inside) du treebank observé est faible,
alors préserver la fusion, sinon préserver la division. Cette étape vise a éviter les divisions
inutiles et a Ininimiser les risques de surentrainement.

— SMOOTH : Lisser les probabilités des regles qui ont le meme symbole pere par interpolation.

Pour le francais cet algorithme a deux intéréts : (a) Une markovisation horizontale d’ordre 0

permet d’éviter un effet d’éparpillement des données dﬁ au schéma d’annotation plat et a la

petite taille du corpus d’entrainement et (b) la spécialisation de la graInmaire est indépendante
de toute hypothese a priori sur la structure des arbres du treebank, contrairement aux hypotheses
sous-jacentes aux modeles lexicalisés.

5La markovisation droite d’ordre h se fonnule comme suit : P(A —> B1 . . .Bn) =d°f P(B1, . . . ,Bn|A) =
1'[,";f P(B,-|B,-+1, . . . , B”, A) 2 Hi": P(B,-|B,-+1, . . . , B,+,,, A). Ce que (Petrov et al., 2006) implémentent
en binarisant les arbres comme décrit en ﬁgure 2, c’est-a-dire en approximant cette fonnule par un fragment de
derivation produit par une PCFG.

5Ce qui donne en pratique des résultats equivalents et généralement meilleurs. L’ apprentissage ne porte que sur
les categories et pas sur la structure.

Experiences d’analyse syntaxique statistique du francais

5 Experiences

Les travaux en analyse syntaxique statistique pour le francais cites precedemment ont exploite
un minimum d’information du corpus arbore : les categories principales (attribut cat) associees
aux preterminaux ainsi que les categories standard des non terminaux. Nous etudions ici com-
ment tirer parti de l’information supplementaire contenue dans le treebank a des ﬁns d’analyse
automatique. I1 s’agit de tester l’impact de differents parametres lies au schema d’annotation
du FTB sur l’algorithme de (Petrov et al., 2006). Nous comparons enﬁn les performances du
meilleur analyseur ainsi obtenu avec un apprentissage sur une sous-partie comparable du WSJ,
aﬁn d’evaluer la marge d’amelioration restante.

Protocole L’ensemble des observations que nous presentons ci-dessous se fondent systemati-
quement sur un argument d’evaluation, avec le protocole suivant : pour chaque instance engen-
dree, les 12351 phrases du treebank sont divisees en trois sections : (1) test (les 1235 premieres
phrases), (2) developpement (les 1235 phrases suivantes), et (3) entrainement (le reste).

La tache d’evaluation donne en entree a chacun des analyseurs une chaine parfaitement segmen-
tee de maniere deterministe. L’ analyseur teste est charge de produire un arbre d’analyse unique
a comparer avec la reference. Les resultats d’evaluation sont reportes en utilisant le protocole
PARSEVAL tel qu’implemente par l’outil d’evaluation eva lb avec parametres standard de Col-
lins. Autrement dit, les scores de precision, rappel et f-mesure tiennent compte du parenthesage
mais egalement des categories des noeuds7. Les resultats sont reportes pour les phrases de la
section (1) dont le nombre de mots est 3 40.

Implantations utilisées Pour chaque experience menee, nous utilisons systematiquement deux
algorithmes d’analyse. Le premier, qui sert de temoin, est un analyseur PCFG « standard » dont
l’etiquetage est realise par un etiqueteur trigramme (TNT/LNCKY)8. Pour chaque test, cet ana-
lyseur a ete entraine sur les sections (2) et (3).

De plus, nous utilisons l’analyseur de Berkeley (Petrov et al., 2006), note BKY, avec une mar-
kovisation horizontale h=09. Nous avons adapte au francais (nous inspirant de (Arun & Keller,
2005)) le modele de lissage lexical de l’analyseur : il fonctionne par clustering de mots incon-
nus et utilise des indices de capitalisation, marques typographiques et sufﬁxes discriminants.
Cet analyseur est entraine sur (3) et utilise la section (2) pour ajuster les parametres de EM.

Experiences Les experiences que nous avons realisees testent principalement 4 facteurs : (1)
l’impact des mots composes sur la tache d’analyse, (2) l’impact de l’annotation morphologique,
(3) l’impact de la ﬂexion riche du francais, et (4) l’usage de fonctions syntaxiques. Finalement,
nous mettons en perspective les resultats obtenus pour le francais avec ceux obtenus sur un
corpus anglais approximant les proprietes formelles du corpus francaislo.

7Suivant les conventions classiques utilisées pour l’evaluation sur le Penn TreeBank, nous avons ajoute un
noeud racine artiﬁciel a chacun des arbres; et les noeuds de ponctuation sont ignores dans l’eva1uation, ce qui
n’est pas le cas pour (Schluter & van Genabith, 2007)
8Formellement, il ne s’agit donc pas strictement d’un algorithme PCFG completement standard. 11 s’agit plutot
d’un compromis << pratique » o1‘1 l’etiqueteur a pour fonction annexe de foumir un algorithme de lissage. L’ eti-
queteur utilise est TNT (Brants, 2000), l’analyseur est l’i1nplementation LNCKY distribuee par Mark Johnson
(http ://www . cog . brown . edu/~mj /Software . htm).
9Pour le corpus TREEBANK+ (infra), nous obtenons F=86.41 pour h=0, 84.84 pour h=1, et 82.85 pour h=2.
1°Les tests sont realises suite at deux normalisations : (1) les nombres en chiffres arabes parfois encodes en
plusieurs tokens, sont systématiquement fusionnes en un seul token. (2) Les amalgames (ex. d+le = au, a+lequel

Experiences d’analyse syntaxique statistique du francais

Mots composés Les composes explicites du FTB complexiﬁent la tache d’apprentissage. Une
solution pour simpliﬁer le probleme est de fusionner les composes, suivant en cela (Arun &
Keller, 2005) et (Schluter & van Genabith, 2007). Par exemple un compose initialement marque
(Adv (P de) (Adv méme) ) est remplace par (Adv de_méme). Cela facilite la tache, et
suppose une utilisation du parser obtenu avec en entree une fusion parfaite des composes.

Voici quelques experiences ne supposant pas ce pre-traitement (Table 1). En n’utilisant que la
categorie principale (TREEBANKMIN), on obtient F-score=83.09 sans fusionner, a comparer a
F-score=84.85 avec fusion. Pour capturer qu’un composant n’a pas la meme distribution qu’un
mot simple, nous avons teste de distinguer par un sufﬁxe les symboles de composants de com-
poses (Adv (P * de) (Adv* méme) ) , ce qui ﬁnalement n’a pas d’impact (F-score = 83.09).

Enﬁn, pour obtenir un parser moins dependant de la deﬁnition assez large de compose du FTB,
nous avons egalement cherche sommairement a ne conserver que les composes syntaxiquement
non reguliers (par exemple (ADV (P en) (A particulier) ) , ou la sequence P A se com-
porte comme un adverbe). Pour cela nous testons de ’defaire’ les composes a syntaxe reguliere
ayant les patrons les plus productifs : nous defaisons les composes de patrons N= (N A ? P D ?
N) , N= (A N) et N= (N A A ?) , soit 5854 occurrences de composes sur 20413. Par exemple le
sous-arbre pour le compose (N (N loyer) (P de) (D 1 ’ ) (N argent) ) est remplace
par une suite de deux noeuds (N loyer) et (PP (P de) (NP (D 1’) (N argent) ) ),
qui s’inserent comme ﬁls du NP pere. A noter que cela modiﬁe le nombre de constituants pris
en compte par PARSEVAL, donc le F-score obtenu (84.97) est meilleur mais pas comparable.
En revanche la diminution du nombre moyen de constituants qui croisent un constituant cor-
rect est un signe que les dependances syntaxiques regulieres internes aux composes defaits sont
globalement recapturees.

Dans toute la suite nous donnons des resultats en mode fusionne, ce qui facilite les comparaisons
avec (Arun & Keller, 2005) et (Schluter & van Genabith, 2007).

TRAITEMENT DES COMPOSES PREC. RAPPEL F-SCORE NB MOYEN NB DE PHRASES
SUR TREEBANKMIN CROISEMENTS TEST 3 40 MOTS
Composés fusionnés 85.25 84.46 84.85 0.94 992
Composés tels quels 83.44 82.73 83.09 0.92 932
Composants marqués 83.35 82.82 83.09 0.93 932
Composés ’défaits’ 85.21 84.74 84.97 0.88 932

+ Composants restants marqués

TAB. 1 — Differents traitements des composes sur TREEBANKMIN

Annotation morphosyntaxique Le FTB comporte trois champs morphosyntaxiques : la ca-
tegorie principale (champ cat), une sous-categorie (champ subcat rafﬁnant cat), comme
par exemple le deﬁni, l’interrogatif, le demonstratif ou le possessif pour un determinant, ainsi
qu’un champ mph comportant des traits ﬂexionnels (par exemple genre, nombre, personne).
De maniere a tester l’impact des informations contenues dans ces champs, nous avons instan-
cie un corpus TREEBANKSUBCAT, dont les preterminaux sont la concatenation des champs
cat + subcat, ainsi qu’un corpus TREEBANKMAX dont les preterminaux sont la concatena-
tion des trois champs cat + subcat + mph.

En comparant T REEBANKSUBCAT et TREEBANKMIN (table 3), on constate que l’annotation

= auquel encodes en deux tokens dont un Vide sont recodes en un seul, de categorie P+D ou P+PRO selon le cas.

Experiences d’analyse syntaxique statistique du francais

TAG CAT SOUS -CAT MODE TAG CAT SOUS-CAT MODE TAG CAT SOUS -CAT MODE
V V - indicatif CLS CL suj - ADJWH A int
VIMP V - impémtif CLO CL obj - ADJ A —«int
VINF V - inﬁnitif CLR CL reﬂ - ADVWH ADV int

VS V - subjonctif P P - - ADV ADV —uint
VPP V - participe passe P+D voir texte PROWH PRO int
VPR V - participe present P+PRO vair texte PROREL PRO rel
NPP N P — I I — — PRO PRO -«(int I rel)
NC N C PONCT PONCT DETWH D int

CS C S ET ET DET D -int
CC C C

TAB. 2 — Symboles preterminaux (tags) de TREEBANK+

en sous-categories a un impact statistiquement signiﬁcatif (p = 0.015)“ sur les performances de
l’analyseur de BKY. Par contre ajouter toute l’information morphologique (T REEBANKMAX),
degrade signiﬁcativement les resultats pour l’analyseur BKY.

C’est une solution intermediaire, le corpus TREEBANK+, qui permet d’obtenir les meilleurs
resultats, en selectionnant uniquement le mode des verbes et certains traits de sous-categories
(table 2). L’intuition derriere le choix de ce jeu de preterminaux est analogue a celle indiquee
dans (Schluter & van Genabith, 2007) : on a ici guide l’apprentissage en distinguant les catego-
ries verbales selon le mode, qui a un impact considerable pour capturer l’ordre des mots autour
du verbe dans une grammaire. Le resultat pour TREEBANK+ est une amelioration statistique-
ment signiﬁcative des resultats par comparaison avec TREEBANKSUB CAT (p = 0.002).

CORPUS PRECISION RAPPEL F1—SCORE COUVERTURE TAG ACCY F1-SCORE
(TNT/LNCKY)

Ti-eebankMin 85.25 84.46 84.85 99.59 97.35 69.68
TreebankMax 84.17 84.08 84.13 99.69 92.20 74.76
Treebanksubcat 85.91 85.58 85.74 99.59 96.63 72.54
'Ii~eebank+ 86.57 86.25 86.41 99.79 96.83 75.02

TAB. 3 — Evaluation de l’impact de la richesse du jeu de preterminaux

Lexicalisation / Flexion Pour evaluer l’impact de la ﬂexion riche du francais, soulignee section
2, nous comparons l’utilisation de formes ﬂechies versus l’utilisation de symboles regroupant
des formes ﬂechies. Un regroupement par lemme semble trop grossier : nous testons plutot
un regroupement selon les categories du jeu TREEBANK+. Pour ce faire, nous remplacons une
forme ﬂechie par (tag+lemme)12, y compris dans les phrases de test, ce qui induit un tagging
parfait13. Ce cas est donc a comparer a un equivalent en formes ﬂechies non regroupees, en
tagging parfait, simule en remplacant une forme ﬂechie par (tag+forme). Les resultats sont
donnes table 4. Le regroupement de formes a effectivement un impact positif, quoique faible
(F-score de 0.39 point superieur a l’equivalent en formes ﬂechies, et meilleur nombre moyen
de croisements). La moindre dispersion des donnees a plus d’effet que la perte des marques
d’accord 14.

Fonctions syntaxiques Nous avons teste d’encoder dans les non terminaux les fonctions syn-
taxiques annotees dans le treebank. Cela cree de maniere previsible une dispersion des donnees,

“En utilisant un t—test unidirectionnel d’ecarts a la moyenne pour echantillons apparies.

12Par exemple, les differentes formes de manger sont remplacees par 6 symboles selon le jeu TREEBANK+ :
manger-VINF, manger—VPP, manger—VPR, manger—V, manger—VS, manger—VIMP. Les deux formes d’un nom com-
mun sont remplacees par une seule, etc...

13Le lissage lexical est modiﬁe en consequence. Nous envisageons une autre solution, sans le biais du tagging
parfait, qui consisterait a disposer d’un tagger donnant en entree a 1’ analyseur des sequences de couples tag+lemme.

14Ces resultats sont a comparer avec le remplacement simple des mots par leur tag, ce qui donne une version
purement non lexicalisee, en tagging parfait. On obtient 86.28, ce qui montre bien le peu d’utilisation de la lexica-
lisation par BKY (dit non lexicalise’, mais ou la lexicalisation intervient par division des categories lexicales).

Expériences d’analyse syntaxique statistique du francais

TERMINAUX PRECISION RAPPEL F-SCORE COUVERTURE TAG ACCY NB MOY. CROISEMENTS
tag+forme 87.85 87.73 87.79 99.89 99.74 0.86
tag+lemme 86.90 88.16 88.18 99.89 99.80 0.82
tag seul 86.28 86.27 86.28 99.89 100 0.95

TAB. 4 — Regroupement de formes ﬂéchies sur TREEBANK+ (en tagging parfait simulé)

dégradant ainsi les résultats (F-score=78.73 pour TREEBANK+).

Evaluation sur corpus anglais comparable A titre indicatif et pour estimer la dépendance a la
langue, nous avons construit un échantillon du WSJ formellement analogue au corpus francais”,
et comparons les résultats. Pour l’analyseur TNT/LNCKY, on obtient F=71.84 pour l’anglais
(vs F=75.02 pour le francais en TREEBANK+). Alors que le contraste est inversé avec BKY :
F=88.61 pour l’anglais, versus F=86.41 pour le francais. Pour l’anglais, on peut également
remarquer que l’échantillon utilisé, qui divise la taille du WSJ par trois, ne fait baisser les
résultats que de 1.5 point : (Petrov et al., 2006) obtiennent 90.15 sur la totalité du WSJ.

6 Conclusion et perspectives

Cet article montre qu’il est possible, a partir du FTB et avec un algorithme non lexicalisé, d’ob-
tenir un analyseur syntaxique statistique satisfaisant pour le francais sur corpus journalistique.
Il est obtenu sur TREEBANK+ et donne un F-Score de 86.41, le meilleur a ce jour a partir du
FTB.

Les désavantages potentiels du FTB sont contournés par un algorithme non lexicalisé relati-
vement indépendant du schéma d’annotation : une markovisation horizontale radicale (h = 0)
diminue l’effet de dispersion des regles, dﬁ a la petite taille du corpus et a la faible compacité de
la grammaire sous-j acente. Cette hypersimpliﬁcation initiale est contre-balancée dans un second
temps par un algorithme de fusion/séparation des symboles qui maximise le degré de granularité
(et atténue les effets des hypotheses d’indépendance conditionnelles) de la grammaire induite.

On remarque également que tirer parti de l’information supplémentaire encodée dans le tree-
bank (traits subcat, mph et lemma) a un impact sur les performances de l’analyseur syn-
taxique non lexicalisé. On pense prolonger ce travail en augmentant ce premier analyseur ap-
pris d’un algorithme de reranking (Charniak & Johnson, 2005) spéciﬁque au francais intégrant
des traits non locaux. I1 sera en particulier intéressant d’étudier comment exploiter d’avan-
tage l’information lexicale dans cette seconde passe. Les premiers résultats en fonctions syn-
taxiques sont considérés comme tres encourageants. Nous envisageons tester différentes tech-
niques d’étiquetage fonctionnel et d’extraction de dépendances fonctionnelles en sortie d’ana-
lyse. Cela permettrait d’une part la comparaison avec d’autres analyseurs syntaxiques pour le
francais, et d’autre part une évaluation interne plus ﬁne, par type de dépendance.

Les résultats obtenus pour l’anglais sur un échantillon du WSJ formellement analogue au FTB,
montrent qu’il reste certainement une marge de progression : a corpus formellement compa-
rables, les résultats pour l’anglais sont 2 points au-dessus du francais. L’hypothese que cette

15Cet échantillon a été constitué par une procedure aléatoire augmentée de deux contraintes : (1) l’échantillon
anglais comporte le meme nombre de tokens que TREEBANK+ et (2) la procedure fait converger les distributions
en longueur des phrases. L’ algorithme d’ échantillonnage garantit la convergence des moyennes. Suivant la pratique
courante nous avons supprimé les traces et les annotations fonctionnelles du Penn Treebank.

Experiences d’analyse syntaxique statistique du francais

difference provient d’une ﬂexion plus riche du francais apparait comme insufﬁsante : le gain
obtenu en Ininimisant la dispersion par ﬂexion est décevant. Pour tenter d’expliquer cet écart,
nous pensons investiguer l’utilisation de modiﬁcations structurelles automatisables.

Remerciements Les auteurs tiennent a remercier Anne Abeillé, Laurence Danlos, Slav Petrov,
Natalie Schluter et Djamé Seddah pour leurs conseils lors de la réalisation de ce travail ainsi
que l’université Paris 7 (Prix Diderot innovation) pour son soutien ﬁnancier.

Références

ABEILLE A. & BARRIER N. (2004). Enriching a french treebank. In Proceedings of Language
Ressources and Evaluation Conference (LREC), Lisbon.

ABEILLE A., CLEMENT L. & TOUSSENEL F. (2003). Treebanks, chapter Building a treebank
for French. Kluwer : Dordrecht.

ARUN A. & KELLER F. (2005). Lexicalization in crosslinguistic probabilistic parsing : The
case of french. In Proceedings of the 43rd Annual Meeting of the Association for Computatio-
nal Linguistics, p. 306-313, Ann Arbor, MI.

BOURIGAULT D. & FABRE C. (2000). Approche linguistique pour l’analyse syntaxique de
corpus. Cahiers de grammaires, 25.

BRANTS T. (2000). Tnt - a statistical part-of-speech tagger. In Proceedings of the 6th Applied
NLP Conference (ANLP), Seattle-WA.

CHARNIAK E. & JOHNSON M. (2005). Coarse-to-ﬁne n-best parsing and maxent discrimina-
tive reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computatio-
nal Linguistics (ACL 2005), Ann Arbor (MI).

COLLINS M. (2003). Head-driven statistical models for natural language parsing. Computa-
tional Linguistics, 29(3).

GILDEA D. (2001). Corpus variation and parser performance. In Conference on Empirical
Methods in Natural Language Processing (EMNLP).

JOHNSON M. (1998). PCFG models of linguistic tree representations. Computational Lin-
guistics, 24(4), 613-632.

KLEIN D. & MANNING C. D. (2003). Accurate unlexicalized parsing. In Proceedings of the
41 st Meeting of the Association for Computational Linguistics.

MARCUS M. P., SANTORINI B. & MARCINKIEWICZ M. A. (1994). Building a large anno-
tated corpus of english : The penn treebank. Computational Linguistics, 19(2), 313-330.
MATSUZAKI T ., MIYAO Y. & TSUJII J. (2005). Probabilistic cfg with latent annotations.
In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics
(ACL), p. 75-82.

NASR A. (2006). Grammaires de dépendances génératives probabilistes. modele théorique et
application a un corpus arboré du francais. TraitementAutomatique des Langues, 46(1).
PETROV S., BARRETT L., THIBAUX R. & KLEIN D. (2006). Learning accurate, compact,
and interpretable tree annotation. In Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meeting of the Association for Computational
Linguistics, Sydney, Australia : Association for Computational Linguistics.

SCHLUTER N. & VAN GENABITH J. (2007). Preparing, restructuring, and augmenting a
french treebank : Lexicalised parsers or coherent treebanks ? In Proceedings of PACLING 07.

