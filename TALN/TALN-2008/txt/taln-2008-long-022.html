<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Une alternative aux mod&#232;les de traduction statistique d&#8217;IBM: Les triggers inter-langues</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2008, Avignon, 9&#8211;13 juin 2008
</p>
<p>Une alternative aux mode&#768;les de traduction statistique d&#8217;IBM :
Les triggers inter-langues
</p>
<p>Caroline Lavecchia1, 2 Kamel Sma&#305;&#776;li1, 2 David Langlois1, 3
(1) LORIA/Speech Group, Campus scientifique, BP 239, 54506 Vandoeuvre
</p>
<p>le&#768;s Nancy Cedex, France
(2) Universite&#769; Nancy2
(3) IUFM de Lorraine
</p>
<p>Re&#769;sume&#769;. Dans cet article, nous pre&#769;sentons une nouvelle approche pour la traduction au-
tomatique fonde&#769;e sur les triggers inter-langues. Dans un premier temps, nous expliquons le
concept de triggers inter-langues ainsi que la fac&#807;on dont ils sont de&#769;termine&#769;s. Nous pre&#769;sentons
ensuite les diffe&#769;rentes expe&#769;rimentations qui ont e&#769;te&#769; mene&#769;es a&#768; partir de ces triggers afin de
les inte&#769;grer au mieux dans un processus complet de traduction automatique. Pour cela, nous
construisons a&#768; partir des triggers inter-langues des tables de traduction suivant diffe&#769;rentes me&#769;-
thodes. Nous comparons par la suite notre syste&#768;me de traduction fonde&#769; sur les triggers inter-
langues a&#768; un syste&#768;me e&#769;tat de l&#8217;art reposant sur le mode&#768;le 3 d&#8217;IBM (Brown &amp; al., 1993). Les
tests mene&#769;s ont montre&#769; que les traductions automatiques ge&#769;ne&#769;re&#769;es par notre syste&#768;me ame&#769;liorent
le score BLEU (Papineni &amp; al., 2001) de 2, 4% compare&#769; a&#768; celles produites par le syste&#768;me e&#769;tat
de l&#8217;art.
</p>
<p>Abstract. In this paper, we present an original approach for machine translation based on
inter-lingual triggers. First, we describe the idea of inter-lingual triggers and how to determine
them. Then, we present the way to make good use of them in order to integrate them in an entire
translation process. We used inter-lingual triggers to estimate different translation tables. Then
we compared our translation system based on triggers to a state-of-the-art system based on IBM
model 3 (Brown &amp; al., 1993). The experiments showed that automatic translations generated by
our system outperform model 3 of IBM by 2.4% in terms of BLEU (Papineni &amp; al., 2001).
Mots-cle&#769;s : Traduction Automatique Statistique, Triggers Inter-Langues, Information
Mutuelle, Corpus paralle&#768;le, De&#769;codage.
</p>
<p>Keywords: Statistical Machine Translation, Inter-Lingual Triggers, Mutual Information,
Parallel corpus, Decoding process.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Caroline Lavecchia, Kamel Sma&#305;&#776;li, David Langlois
</p>
<p>1 Introduction
</p>
<p>L&#8217;objectif de la traduction automatique est de transformer une phrase donne&#769;e dans une langue
source en une phrase dans une langue cible. Pour re&#769;soudre ce proble&#768;me tre&#768;s complexe, il est
possible d&#8217;inte&#769;grer le savoir faire de traducteurs humains, mais cela demande une mode&#769;lisation
de ce savoir qui est en soi un sujet de recherche. Il faut utiliser des mode&#768;les formels des langues
source et cible issus du Traitement Automatique des Langues, et un mode&#768;le de traduction a&#768; base
de re&#768;gles, comme par exemple ce qui est fait dans le syste&#768;me de Systran (Jean Senellart, 2001).
Cet effort de conception doit e&#770;tre re&#769;pe&#769;te&#769; pour chaque couple de langues (me&#770;me si le savoir faire
peut e&#770;tre en partie transfe&#769;re&#769;). L&#8217;approche statistique, quant a&#768; elle, utilise une voie diffe&#769;rente. En
effet, elle n&#8217;utilise pas de connaissances a priori, mais s&#8217;appuie sur des corpus bilingues. Ces
corpus sont aligne&#769;s, c&#8217;est-a&#768;-dire que le lien entre chaque partie du texte de la langue source est
fait avec la partie correspondante dans la langue cible. Le lien est ge&#769;ne&#769;ralement fait au niveau
de la phrase. Partant de ces corpus, une analyse statistique utilise les redondances existantes
afin d&#8217;estimer les parame&#768;tres du processus de traduction. La traduction statistique est possible
car les mode&#768;les adhoc sont couple&#769;s avec des algorithmes de programmation dynamique qui
maximisent une fonction de traduction d&#8217;une phrase source vers une phrase cible. IBM a utilise&#769;
avec succe&#768;s cette approche (Brown &amp; al., 1993). La plupart des syste&#768;mes statistiques actuels
sont fonde&#769;s sur les mode&#768;les d&#8217;IBM.
</p>
<p>L&#8217;approche statistique ne&#769;cessite de de&#769;finir un mode&#768;le de traduction qui va permettre de calculer
les probabilite&#769;s de traduction entre les mots, les suites de mots et les autres constituants de la
phrase. Ainsi, on de&#769;finit pour toute phrase s de la langue source et toute phrase t de la langue
cible une valeur P (s|t) calcule&#769;e a&#768; l&#8217;aide de mode&#768;les compose&#769;s de nombreux parame&#768;tres. IBM
propose pour estimer ces parame&#768;tres une me&#769;thode ite&#769;rative engendrant 5 mode&#768;les de traduc-
tion diffe&#769;rents, du plus simple au plus complexe. Cela aboutit a&#768; des mode&#768;les performants, mais
longs et complexes a&#768; estimer. Cette complexite&#769; croit tre&#768;s vite au fur et a&#768; mesure des parame&#768;tres
supple&#769;mentaires pris en compte lors du processus de traduction. En plus du mode&#768;le de traduc-
tion, cette approche utilise un mode&#768;le de langage de la langue cible qui permet d&#8217;e&#769;valuer la
qualite&#769; de la phrase t. Un de&#769;codeur tel que Pharaoh (Koehn, 2004) utilise ces deux mode&#768;les afin
de rechercher pour une phrase s donne&#769;e une phrase t qui peut e&#770;tre accepte&#769;e comme traduction
de s.
</p>
<p>Dans cet article, nous proposons une nouvelle approche permettant de construire un mode&#768;le de
traduction fonde&#769; sur les triggers inter-langues (extension des triggers classiques) pour construire
notre syste&#768;me de traduction statistique. Le concept de triggers est bien connu de la communaute&#769;
de la mode&#769;lisation statistique du langage. Facile a&#768; mettre en oeuvre, il posse&#768;de une certaine
souplesse qui permet de l&#8217;appliquer a&#768; diffe&#769;rents niveaux de lecture de la phrase (mots, genre,
nombre, constituants syntaxiques). Nous montrerons que les triggers inter-langues permettent
de construire un mode&#768;le de traduction efficace. Nous comparerons ses re&#769;sultats a&#768; ceux fonde&#769;s
sur les mode&#768;les d&#8217;IBM.
</p>
<p>Nous pre&#769;sentons dans la partie 2 la notion ge&#769;ne&#769;rale des triggers. La partie 3 de&#769;finit le concept
de triggers inter-langues qui associe a&#768; chaque mot de la langue source une liste de traduc-
tions possibles. Dans la partie 4, nous pre&#769;sentons la manie&#768;re dont les triggers inter-langues ont
e&#769;te&#769; inte&#769;gre&#769;s a&#768; un processus complet de traduction automatique. Nous terminons enfin par une
conclusion qui met en avant les points forts de notre me&#769;thode et donne quelques perspectives
futures des travaux de notre groupe de recherche.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Une alternative aux mode&#768;les de traduction statistique d&#8217;IBM : Les triggers inter-langues
</p>
<p>2 Rappel sur les triggers
</p>
<p>Le concept de triggers est tre&#768;s souvent cite&#769; en mode&#769;lisation statistique du langage et plus parti-
culie&#768;rement en reconnaissance de la parole. Les triggers permettent entre autre d&#8217;ame&#769;liorer et de
ge&#769;ne&#769;raliser le mode&#768;le Cache (Kuhn &amp; DeMori, 1990). Le mode&#768;le Cache favorise la probabilite&#769;
d&#8217;un mot wi re&#769;cemment apparu dans le contexte gauche. Un mode&#768;le de triggers va plus loin et
accorde une probabilite&#769; plus importante a&#768; une liste de mots corre&#769;le&#769;s au mot wi (Tillmann &amp; Ney,
1996). Les triggers sont se&#769;lectionne&#769;s selon la valeur de l&#8217;Information Mutuelle (IM) donne&#769;e par
la formule suivante :
</p>
<p>IM(x, y) = P (x, y)log
P (x, y)
</p>
<p>P (x)P (y)
(1)
</p>
<p>Chaque mot appartenant au vocabulaire est alors associe&#769; a&#768; n mots qui lui sont le plus forte-
ment corre&#769;le&#769;s d&#8217;apre&#768;s la valeur de l&#8217;IM. Un trigger est un ensemble compose&#769; d&#8217;un mot appele&#769;
de&#769;clencheur et d&#8217;une liste de mots qu&#8217;il de&#769;clenche appele&#769;s de&#769;clenche&#769;s. La figure 1 illustre un
exemple de triggers anglais.
Les triggers ont beaucoup e&#769;te&#769; utilise&#769;s en reconnaissance de la Parole ou&#768; ils sont combine&#769;s avec
un mode&#768;le n-gramme classique (Tillmann &amp; Ney, 1997).
</p>
<p>Garry  Kasparov  is  a  chess  champion
</p>
<p>FIG. 1 &#8211; Exemples de triggers classiques
</p>
<p>3 Les triggers inter-langues
</p>
<p>Nous proposons dans ce qui suit d&#8217;e&#769;tendre ce concept pour l&#8217;utiliser avec des corpus bilingues
aligne&#769;s. Nous appelons ce concept triggers inter-langues. Un trigger inter-langue est de&#769;fini
comme e&#769;tant un ensemble compose&#769; d&#8217;un mot de&#769;clencheur d&#8217;une langue source et des mots
de&#769;clenche&#769;s d&#8217;une langue cible qui lui sont fortement corre&#769;le&#769;s. Ainsi, chaque mot f du voca-
bulaire franc&#807;ais VF est associe&#769; a&#768; n mots anglais ou triggers inter-langues qui lui sont le plus
fortement corre&#769;le&#769;s au sens de l&#8217;IM. Plus formellement,
</p>
<p>&#8704;fi &#8712; VF , Trign(fi) est l&#8217;ensemble des n triggers inter-langues de fi
</p>
<p>De la me&#770;me fac&#807;on, chaque mot e du vocabulaire anglais VE est associe&#769; a&#768; n mots franc&#807;ais :
</p>
<p>&#8704;ei &#8712; VE , Trign(ei) est l&#8217;ensemble des n triggers inter-langues de ei.
</p>
<p>Les triggers inter-langues sont de&#769;termine&#769;s suivant la valeur de l&#8217;Information Mutuelle calcule&#769;e
sur un corpus aligne&#769; au niveau de la phrase. Ce corpus est constitue&#769; de paires (E,F ) ou&#768; F est
la traduction de E. Les triggers permettent de repe&#769;rer les e&#769;le&#769;ments en relation d&#8217;une langue a&#768;
l&#8217;autre. Les triggers sont estime&#769;s en utilisant la formule (2).
</p>
<p>IM(f, e) = P (f, e) &#8727; log(
P (f, e)
</p>
<p>P (f) &#8727; P (e)
) (2)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Caroline Lavecchia, Kamel Sma&#305;&#776;li, David Langlois
</p>
<p>P (X) =
N(X)
</p>
<p>|Corpus|
P (f, e) =
</p>
<p>N(f, e)
</p>
<p>|Corpus|
(3)
</p>
<p>&#8211; e et f sont des e&#769;le&#769;ments de la paire de phrases (E,F )
&#8211; N(X) est le nombre de phrases dans lesquelles le mot X appara&#305;&#770;t
&#8211; N(e, f) est le nombre de paires (E,F ) de phrases du corpus aligne&#769; dans lesquelles les mots
e et f co-occurent.
</p>
<p>&#8211; |Corpus| est le nombre de paires de phrases constituant le corpus aligne&#769;.
La figure 2 montre un exemple de triggers inter-langues de l&#8217;Anglais vers le Franc&#807;ais. Ce qui
</p>
<p>Garry  Kasparov  is  a  chess  champion Garry  Kasparov  est  un  champion  d&#8217;  &#233;checs
</p>
<p>FIG. 2 &#8211; Exemples de triggers inter-langues
</p>
<p>motive l&#8217;utilisation de cette notion est le fait que l&#8217;on espe&#768;re trouver la traduction du mot
de&#769;clencheur dans la liste des mots de&#769;clenche&#769;s.
Notons que ce principe de triggers inter-langues est utilise&#769; en mode&#769;lisation du langage pour
enrichir des langues faiblement dote&#769;es a&#768; partir d&#8217;autres langues tre&#768;s riches en termes de corpus
(Kim &amp; Khudanpur, 2004).
</p>
<p>4 La traduction automatique avec les triggers inter-langues
</p>
<p>La premie&#768;re e&#769;tape pour la mise en place de notre syste&#768;me de traduction est l&#8217;apprentissage des
triggers inter-langues. Pour ce faire, nous les de&#769;terminons sur un corpus paralle&#768;le extrait des
actes du Parlement Europe&#769;en dont les statistiques sont re&#769;sume&#769;es dans le tableau 1.
</p>
<p>TAB. 1 &#8211; Corpus d&#8217;apprentissage
</p>
<p>Franc&#807;ais Anglais
Paires de phrases 596K
Taille (en mots) 17.3M 15.8M
Vocabulaire (en mots) 77.5K 60.3K
</p>
<p>Nous appliquons les formules (2) pour de&#769;tecter les couples (e, f) les plus corre&#769;le&#769;s et qui consti-
tuerons les triggers inter-langues.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Une alternative aux mode&#768;les de traduction statistique d&#8217;IBM : Les triggers inter-langues
</p>
<p>Quelques exemples de triggers Anglais-Franc&#807;ais sont pre&#769;sente&#769;s dans le tableau 2, de me&#770;me
des exemples de triggers Franc&#807;ais-Anglais sont pre&#769;sente&#769;s dans le tableau 3. La troisie&#768;me co-
lonne des tableaux indique pour chaque couple de mots de&#769;clencheur-de&#769;clenche&#769; la valeur de
l&#8217;Information Mutuelle qui lui est associe&#769;e. Une analyse qualitative de nos triggers montre
que les mots de&#769;clenche&#769;s peuvent souvent e&#770;tre apparente&#769;s a&#768; de possibles traductions du mot
de&#769;clencheur ou a&#768; des mots vraiment tre&#768;s proches du point de vue du sens. Par ailleurs, comme
le montrent les exemples des tableaux, les triggers de&#769;tectent e&#769;galement les diffe&#769;rents sens des
homographes (ainsi, deux sens de &#8217;porte&#8217; sont de&#769;tecte&#769;s avec de forts taux d&#8217;Information Mu-
tuelle). Ces constats sont valables dans les deux sens de traduction.
</p>
<p>TAB. 2 &#8211; Exemples de mots franc&#807;ais de&#769;clenche&#769;s par des mots anglais
</p>
<p>De&#769;clencheur
anglais
</p>
<p>De&#769;clenche&#769;s
franc&#807;ais
</p>
<p>IM
(10&#8722;4)
</p>
<p>De&#769;clencheur
anglais
</p>
<p>De&#769;clenche&#769;s
franc&#807;ais
</p>
<p>IM
(10&#8722;4)
</p>
<p>pion 0, 33 champion 2, 38
chess e&#769;chiquier 0, 29 champion championne 1, 00
</p>
<p>e&#769;checs 0, 26 homme 0, 28
porte 20, 96 sens 69, 06
</p>
<p>door ouverte 5, 15 sense bon 8, 91
portes 2, 73 sentiment 7, 23
traduction 34, 16 usine 7, 54
</p>
<p>translation erreur 2, 73 plant installation 3, 92
version 1, 49 plantes 3, 59
</p>
<p>TAB. 3 &#8211; Exemples de mots anglais de&#769;clenche&#769;s par des mots franc&#807;ais
</p>
<p>De&#769;clencheur
franc&#807;ais
</p>
<p>De&#769;clenche&#769;s
anglais
</p>
<p>IM
(10&#8722;4)
</p>
<p>De&#769;clencheur
franc&#807;ais
</p>
<p>De&#769;clenche&#769;s
anglais
</p>
<p>IM
(10&#8722;4)
</p>
<p>failures 5, 88 champion 2, 38
e&#769;checs failure 0, 88 champion expert 0, 25
</p>
<p>chess 0, 26 champions 0, 24
door 20, 96 sense 69, 06
</p>
<p>porte relates 5, 21 sens direction 28, 68
concerns 4, 23 meaning 11, 61
translation 34, 16 plants 19, 20
</p>
<p>traduction error 2, 51 plantes plant 3, 59
version 1, 49 crops 1, 98
</p>
<p>Nous proposons dans ce qui suit, d&#8217;utiliser l&#8217;ensemble des triggers inter-langues pour mettre en
place notre syste&#768;me de traduction. Nous le comparons ensuite a&#768; un syste&#768;me e&#769;tat de l&#8217;art reposant
sur le mode&#768;le 3 d&#8217;IBM (Brown &amp; al., 1993). Pour ce faire, nous avons utilise&#769; le de&#769;codeur
Pharaoh1(Koehn, 2004), afin de traduire automatiquement un corpus de test de 1444 phrases
</p>
<p>1Le mode&#768;le de langage de la langue cible est un mode&#768;le trigram (me&#769;thode de lissage de Good-Turing. Les poids
des diffe&#769;rents mode&#768;les sont les suivants : 1 pour le mode&#768;le de langage, 1 pour le mode&#768;le de traduction, 1 pour le
mode&#768;le de re&#769;-ordonnancement et enfin une pe&#769;nalite&#769; de mot de 0. Le de&#769;codage est fait avec re&#769;-ordonnancement.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Caroline Lavecchia, Kamel Sma&#305;&#776;li, David Langlois
</p>
<p>anglaises. Les traductions produites sont ensuite compare&#769;es a&#768; l&#8217;aide de la mesure Bleu, une
mesure automatique couramment employe&#769;e en traduction automatique (Papineni &amp; al., 2001).
Dans les sections suivantes, nous pre&#769;sentons trois fac&#807;ons d&#8217;identifier les traductions potentielles
d&#8217;un mot au sein de notre syste&#768;me a&#768; partir des triggers inter-langues de&#769;termine&#769;s auparavant.
Elles donnent lieu a&#768; l&#8217;estimation de trois tables de traduction.
</p>
<p>4.1 Les tables de traduction Trig-n
</p>
<p>Dans un premier temps, nous estimons que tous les triggers inter-langues peuvent e&#770;tre assimile&#769;s
a&#768; des traductions possibles. Par conse&#769;quent, nous les ajoutons tous dans la table de traduction.
Ainsi, un mot anglais ei est une traduction probable du mot franc&#807;ais fj s&#8217;il fait partie de ses
triggers inter-langues. La probabilite&#769; associe&#769;e a&#768; cette traduction est la valeur de l&#8217;Information
Mutuelle normalise&#769;e du couple (ei, fj).
</p>
<p>&#8704;fj &#8712; VF , &#8704;ei, ek &#8712; Trign(fj) P (ei|fj) =
IM(fj , ei)&#8721;n
</p>
<p>k=1 IM(fj , ek)
(4)
</p>
<p>Par la suite, nous appellerons les tables de traduction ainsi construites Trig-n avec n le nombre
de triggers inter-langues retenus pour chaque mot franc&#807;ais du vocabulaire.
L&#8217;e&#769;valuation de notre syste&#768;me mis en place avec les tables de traduction Trig-n, n variant de 10
a&#768; 200, est de&#769;crite par la se&#769;rie Trig-n de l&#8217;histogramme de la figure 3. Dans un premier temps,
nous remarquons une ame&#769;lioration du score Bleu de plus de 2 points entre Trig-10 et Trig-
20. Ceci montre que, globalement, les traductions correctes d&#8217;un mot de&#769;clencheur sont dans
les 20 meilleurs de&#769;clenche&#769;s. Toutefois, lorsque n prend des valeurs au dela&#768; de 20, l&#8217;impact est
beaucoup plus faible. Il faut pre&#769;ciser que, dans la configuration utilise&#769;e, Pharaoh, dans un souci
de rapidite&#769; de recherche, ne prend en compte que les 20 meilleures traductions d&#8217;un mot donne&#769;.
Donc, il est inutile d&#8217;aller au dela&#768; de 20. Toutefois l&#8217;impact montre&#769; n&#8217;est pas nul car le fait de
normaliser les probabilite&#769;s sur 20, 50 ou 100 triggers modifie l&#8217;e&#769;chelle des valeurs de la table
de traduction et donc le poids de cette table dans le processus de recherche. Notons que nous
avons modifie&#769; cette configuration afin de permettre a&#768; Pharaoh de tenir compte de plus de 20
traductions, mais que cela n&#8217;a pas eu d&#8217;impact positif sur les performances.
</p>
<p>4.2 Les tables de traduction Sym-n
</p>
<p>La deuxie&#768;me me&#769;thode de construction d&#8217;une table de traduction consiste a&#768; conside&#769;rer comme
traductions possibles les couples (fj , ei) qui respectent la contrainte de syme&#769;trie suivante :
</p>
<p>Si ei &#8712; Trign(fj) et fj &#8712; Trign(ei) Alors ei &#8712; Symn(fj) (5)
</p>
<p>ei appartient aux traductions possibles de fj (Symn(fj)), si ei fait partie des triggers inter-
langues de fj et inversement si fj est un trigger inter-langue de ei comme l&#8217;illustre la figure 4.
</p>
<p>Cette contrainte de syme&#769;trie nous permet d&#8217;affiner la liste des triggers inter-langues de fj pour
ne retenir que les plus pertinents. Nous supposons que si ei est un des n mots les plus corre&#769;le&#769;s
avec fj et que fj est e&#769;galement dans les n mots les plus de&#769;clenche&#769;s par ei, alors il y a de fortes
chances que ei soit une traduction de fj . La probabilite&#769; associe&#769;e a&#768; ce couple est calcule&#769;e de la</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Une alternative aux mode&#768;les de traduction statistique d&#8217;IBM : Les triggers inter-langues
</p>
<p> 25.5
</p>
<p> 26
</p>
<p> 26.5
</p>
<p> 27
</p>
<p> 27.5
</p>
<p> 28
</p>
<p> 28.5
</p>
<p> 29
</p>
<p>10 20 50 100 200
</p>
<p>Bl
eu
</p>
<p>n
</p>
<p>Trig-n
Sym-n
</p>
<p>Smooth-n
M3
</p>
<p>FIG. 3 &#8211; &#180;Evaluation des traductions produites a&#768; l&#8217;aide des tables de traduction Trig-n, Sym-n et
Smooth-n en fonction de n
</p>
<p>e
</p>
<p>e
f
f
f
</p>
<p>f
</p>
<p>f
</p>
<p>e
</p>
<p>e
</p>
<p>e
</p>
<p>e e
</p>
<p>ee
</p>
<p>e e
</p>
<p>ee
</p>
<p>e
</p>
<p>e
</p>
<p>e
</p>
<p>e:f , f , f1 i n
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>i
</p>
<p>n
</p>
<p>1 1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>11 2
</p>
<p>2 22 2
</p>
<p>1k
</p>
<p>2k
</p>
<p>i i2 ik i
</p>
<p>1 n2 n nk
</p>
<p>. . . . . .
</p>
<p>. . . . . .
</p>
<p>. . . ..
</p>
<p>. . . . . .
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>Triggers anglais&#8722;fran&#231;ais Triggers fran&#231;ais&#8722;anglais
</p>
<p>Traductions potentielles
</p>
<p>FIG. 4 &#8211; Identification des traductions potentielles d&#8217;un mot par syme&#769;trie
</p>
<p>manie&#768;re suivante :
</p>
<p>&#8704;fj &#8712; VF , &#8704;ei, ek &#8712; Symn(fj) Psym(ei|fj) =
IM(fj , ei)&#8721;n
</p>
<p>k=1 IM(fj , ik)
(6)
</p>
<p>La contrainte de syme&#769;trie re&#769;duit conside&#769;rablement le nombre de couples retenus parmi les trig-
gers inter-langues. En moyenne, seuls 21% des triggers inter-langues respectent la contrainte de
syme&#769;trie (5). Ainsi, nous espe&#769;rons n&#8217;avoir retenu que les triggers les plus pertinents.
La se&#769;rie Sym-n de l&#8217;histogramme de la figure 3 pre&#769;sente l&#8217;e&#769;valuation de notre syste&#768;me fonde&#769;
sur les tables de traduction Sym-n. Nous observons a&#768; nouveau une nette ame&#769;lioration du score
Bleu lorsque l&#8217;on utilise Sym-20 au lieu de la table Sym-10. Nous notons, e&#769;galement, une le&#769;ge&#768;re
ame&#769;lioration du score Bleu qui passe de 25, 84 pour Trig-10 a&#768; 25, 91 pour Sym-10. La contrainte
de syme&#769;trie nous permet donc, dans ce cas, d&#8217;e&#769;carter des triggers inter-langues qui ne seraient
pas de re&#769;elles traductions. Malheureusement, cette observation ne s&#8217;e&#769;tend pas aux autres tables
Sym-n (avec n &gt; 10) puisque leur score Bleu reste infe&#769;rieur a&#768; ceux obtenus avec les tables
Trig-n. Me&#770;me si cette intuition semble naturelle, la contrainte de syme&#769;trie semble donc e&#770;tre trop
restrictive pour ame&#769;liorer les performances de notre syst e&#768;me.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Caroline Lavecchia, Kamel Sma&#305;&#776;li, David Langlois
</p>
<p>Nous proposons donc une troisie&#768;me fac&#807;on d&#8217;identifier et d&#8217;estimer les traductions potentielles
pour assouplir cette contrainte de syme&#769;trie. Pour cela, nous de&#769;cidons d&#8217;utiliser une technique de
lissage des probabilite&#769;s (smoothing).
</p>
<p>4.3 Les tables de traduction Smooth-n
</p>
<p>Afin de ne pas affecter une probabilite&#769; nulle aux couples (f, e) qui ne satisfont pas la contrainte
de syme&#769;trie &#8220;e de&#769;clenche f et f de&#769;clenche e&#8221;, nous proposons d&#8217;utiliser une technique de lissage
pour estimer une troisie&#768;me table de traduction que nous appelons par conse&#769;quent Smooth-n. En
mode&#769;lisation du langage, ces techniques dites de smoothing permettent de lisser les probabi-
lite&#769;s de manie&#768;re a&#768; ce que chaque e&#769;ve&#768;nement, me&#770;me impossible, se voit affecter une probabilite&#769;
(Ney et al., 1994). Nous proposons d&#8217;employer le me&#770;me type de technique. Pour ce faire, nous
re&#769;duisons la probabilite&#769; des triggers syme&#769;triques des tables Sym-n. La masse ainsi re&#769;cupe&#769;re&#769;e est
re&#769;partie uniforme&#769;ment sur les triggers non syme&#769;triques. Cette nouvelle estimation est calcule&#769;e
de la manie&#768;re suivante :
</p>
<p>&#8704;ei &#8712; Trign(fj) Psmooth(ei|fj) =
</p>
<p>{
Psym(ei|fj) &#8722; &#491; si ei &#8712; Symn(fj)
&#947; sinon
</p>
<p>(7)
</p>
<p>Pour un mot franc&#807;ais, nous retirons une quantite&#769; &#491; a&#768; chaque probabilite&#769; de traduction assigne&#769;e a&#768;
ses triggers inter-langues syme&#769;triques et nous redistribuons la masse re&#769;colte&#769;e uniforme&#769;ment sur
ses autres triggers inter-langues non syme&#769;triques.
La dernie&#768;re se&#769;rie de l&#8217;histogramme de la figure 3 indique les performances de notre syste&#768;me
reposant sur les tables Smooth-n. Rappelons que n est le nombre de triggers inter-langues re-
tenus pour chaque mot du vocabulaire franc&#807;ais. L&#8217;allure de la se&#769;rie est la me&#770;me que pour les
expe&#769;riences pre&#769;ce&#769;dentes. Toutefois, nous pouvons constater que notre syste&#768;me est plus perfor-
mant avec les tables Smooth-n qu&#8217;avec les tables Sym-n. Par conse&#769;quent, nous pouvons dire
que la contrainte de syme&#769;trie est en effet trop restrictive, et que le fait de conserver les triggers
non-syme&#769;triques permet bien d&#8217;ame&#769;liorer les performances. En revanche, malgre&#769; ces efforts de
lissage, notre syste&#768;me reste le plus performant lorsque chaque trigger inter-langue est conside&#769;re&#769;
comme une traduction potentielle qu&#8217;il respecte la contrainte de syme&#769;trie ou non (se&#769;rie Trig-n).
Ces re&#769;sultats pourraient indiquer que la contrainte de syme&#769;trie est trop forte et que le processus
de traduction n&#8217;est pas ne&#769;cessairement syme&#769;trique. Cela serait a&#768; confirmer par une e&#769;tude au cas
par cas.
</p>
<p>4.4 Comparaison avec le mode&#768;le 3 de traduction d&#8217;IBM
</p>
<p>Afin d&#8217;e&#769;valuer la pertinence de notre syste&#768;me fonde&#769; sur les triggers inter-langues, nous avons
compare&#769; ses performances avec celles d&#8217;un syste&#768;me e&#769;tat de l&#8217;art reposant sur le mode&#768;le 3 d&#8217;IBM
et que nous appelons M3. Ce dernier a e&#769;te&#769; entra&#305;&#770;ne&#769;, a&#768; l&#8217;aide de l&#8217;outil Giza++ (Och &amp; Ney,
2000), sur le me&#770;me corpus paralle&#768;le d&#8217;apprentissage que les triggers inter-langues et teste&#769; avec le
me&#770;me de&#769;codeur sur les me&#770;mes 1444 phrases. Les performances du syste&#768;me M3 sont infe&#769;rieures
a&#768; celle de notre syste&#768;me. En effet, nous obtenons un score BLEU de 28, 07 ( cf. courbe M3 de
la figure 3) par rapport a&#768; un score de 28, 49 pour Trig-100.
Toutefois, comme nous l&#8217;avons dit pre&#769;ce&#769;demment, le de&#769;codeur Pharaoh ne prend en compte
pour chaque mot franc&#807;ais que les 20 meilleures traductions dans le but de re&#769;duire son espace</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Une alternative aux mode&#768;les de traduction statistique d&#8217;IBM : Les triggers inter-langues
</p>
<p>de recherche. Afin d&#8217;optimiser les performances de notre syste&#768;me, nous avons parame&#769;tre&#769; le
de&#769;codeur de telle sorte de lui laisser la possibilite&#769; de prendre en compte plus de 20 traduc-
tions par mot franc&#807;ais. Pour cela, nous faisons varier le parame&#768;tre ttable-limit. Nous optimi-
sons e&#769;galement le parame&#768;tre ttable-threshold qui permet d&#8217;e&#769;carter de l&#8217;espace de recherche
les couples de traductions dont la probabilite&#769; est infe&#769;rieure a&#768; un certain seuil. L&#8217;optimisation
est re&#769;alise&#769;e inde&#769;pendemment pour les deux syste&#768;mes. Les re&#769;sultats en terme de score Bleu
sont pre&#769;sente&#769;s dans le tableau 4. Les performances de notre syste&#768;me sont optimales lorsque
</p>
<p>TAB. 4 &#8211; Optimisation des parame&#768;tres ttable-limit et ttable-threshold
</p>
<p>Mode&#768;le ttable-limit ttable-threshold Bleu
Trig-100 22 0, 04 28, 95
</p>
<p>M3 53 0, 00 28, 27
</p>
<p>le de&#769;codeur restreint son espace de recherche aux 22 meilleures traductions par mot franc&#807;ais
dont la probabilite&#769; est supe&#769;rieure ou e&#769;gale a&#768; 0, 04. Celles du syste&#768;me M3 le sont lorsque le
de&#769;codeur re&#769;duit son espace de recherche aux 53 meilleures traductions pour un mot franc&#807;ais
sans contrainte sur la valeur des probabilite&#769;s. Notre syste&#768;me fonde&#769; sur les triggers inter-langues
apporte une ame&#769;lioration de 2, 4% en termes de score BLEU par rapport au syste&#768;me e&#769;tat de l&#8217;art.
</p>
<p>5 Conclusion et perspectives
</p>
<p>Nous avons pre&#769;sente&#769; dans cet article une alternative aux mode&#768;les d&#8217;IBM pour la traduction sta-
tistique. La me&#769;thode est fonde&#769;e sur les triggers inter-langues. Ces triggers ont e&#769;te&#769; se&#769;lectionne&#769;s a&#768;
partir d&#8217;un corpus paralle&#768;le aligne&#769; au niveau de la phrase extrait des actes du Parlement Eu-
rope&#769;en. Ils permettent de de&#769;finir pour chaque mot (franc&#807;ais ou anglais) une liste des mots
(franc&#807;ais ou anglais) qui lui sont fortement corre&#769;le&#769;s. Ainsi un mot franc&#807;ais est associe&#769; a&#768; une
liste de mots anglais et vice versa.
Dans le but d&#8217;e&#769;valuer la pertinence des triggers inter-langues en tant que traductions poten-
tielles, nous avons mis en place un syste&#768;me de traduction de mots base&#769; uniquement sur les
triggers inter-langues. Nous avons ensuite compare&#769; ses performances a&#768; celles d&#8217;un syste&#768;me de
re&#769;fe&#769;rence e&#769;tat de l&#8217;art reposant sur les mode&#768;les d&#8217;IBM. Apre&#768;s optimisation des deux syste&#768;mes,
les tests mene&#769;s ont montre&#769; qu&#8217;en ne retenant que 22 traductions potentielles pour chaque mot
franc&#807;ais, les performances de notre syste&#768;me apportent une ame&#769;lioration de 2, 4% du score BLEU
par rapport au syste&#768;me de re&#769;fe&#769;rence.
Ces premiers re&#769;sultats re&#769;ve&#768;lent la faisabilite&#769; de l&#8217;utilisation des triggers inter-langues en traduc-
tion automatique statistique. Par ailleurs, le concept de triggers inter-langues est un formalisme
souple et nous nous sommes concentre&#769;s ici que sur des triggers d&#8217;ordre 1-1, c&#8217;est-a&#768;-dire qu&#8217;un
mot est traduit par un seul mot. Nous proposons dans (Lavecchia et al., 2008) un syste&#768;me de
traduction fonde&#769; sur les triggers d&#8217;ordre n-m, ou&#768; plusieurs mots peuvent e&#770;tre traduits par plu-
sieurs mots. Ainsi, notre syste&#768;me devient un syste&#768;me de traduction de se&#769;quences de mots et non
plus de mots.
A plus long terme, nous pouvons envisager beaucoup d&#8217;autres manie&#768;res d&#8217;utiliser les triggers
inter-langues en traduction statistique, comme par exemple en tant que mesure de confiance. De
plus, nous venons de voir qu&#8217;ils permettent de prendre en compte des se&#769;quences de mots, mais</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Caroline Lavecchia, Kamel Sma&#305;&#776;li, David Langlois
</p>
<p>nous pouvons e&#769;galement imaginer de&#769;terminer des triggers inter-langues d&#8217;autre nature que le
mot comme par exemple des triggers de traits syntaxiques.
Nous pouvons aussi combiner les tables de traduction de Giza++ et les no&#770;tres afin de mesurer
leur apport respectif.
Plusieurs autres applications des triggers inter-langues ont e&#769;te&#769; envisage&#769;es et sont en cours de
de&#769;veloppement dans notre groupe de recherche.
</p>
<p>Remerciements
Ce travail est subventionne&#769; par la fondation d&#8217;entreprises EADS (European Aeronautic Defence
and Space Company) dans le cadre d&#8217;une the&#768;se sur la traduction Parole-Parole
</p>
<p>Re&#769;fe&#769;rences
BROWN P. F. &amp; AL. (1993). The mathematics of statistical machine translation : parameter
estimation. Computational Linguistics, 19, 263&#8211;311.
JEAN SENELLART, PE&#769;TER DIENES T. V. (2001). New generation systran translation system.
In MT Summit VIII, Santiago de Compostela, Spain.
KIM W. &amp; KHUDANPUR S. (2004). Lexical triggers and latent semantic analysis for cross-
lingual language model adaptation. ACM Transactions on Asian Language Information Pro-
cessing (TALIP), 3(2), 94&#8211;112.
KOEHN P. (2004). Pharaoh : A beam search decoder for phrase-based statistical machine
translation models. In 6th Conference Of The Association For Machine Translation In The
Americas, p. 115&#8211;224, Washington, DC, USA.
KUHN R. &amp; DEMORI R. (1990). A cache-based natural language model for speech recogni-
tion. IEEE Trans. PAMI, 12(6), 570&#8211;582.
LAVECCHIA C., LANGLOIS D. &amp; SMAI&#776;LI K. (2008). Phrase-based machine translation ba-
sed on simulated annealing. In Proceedings of the International Conference on Language
Ressources and Evaluation.
NEY H., ESSEN U. &amp; KNESER R. (1994). On structuring probabilistic dependences in sto-
chastic language modelling. Computer Speech and Language, 8, 1&#8211;38.
OCH F. J. &amp; NEY H. (2000). Improved statistical alignment models. In ACL &#8217;00 : Procee-
dings of the 38th Annual Meeting on Association for Computational Linguistics, p. 440&#8211;447,
Morristown, NJ, USA : Association for Computational Linguistics.
PAPINENI K. &amp; AL. (2001). Bleu : a method for automatic evaluation of machine translation.
In Proceedings of the 40th Annual of the Association for Computational linguistics, p. 311&#8211;
318, Philadelphia, USA.
TILLMANN C. &amp; NEY H. (1996). Selection criteria for word trigger pairs in language mo-
deling, In L. M. ET C. DE LA HIGUERA, Ed., Grammatical Inference : Learning Syntax from
Sentences, p. 98&#8211;106. Lecture Notes in Artificial Intelligence 1147, Springer Verlag.
TILLMANN C. &amp; NEY H. (1997). Word trigger and the EM algorithm. In Proceedings of the
Conference on Computational Natural Language Learning, p. 117&#8211;124, Madrid, Spain.</p>

</div></div>
</body></html>