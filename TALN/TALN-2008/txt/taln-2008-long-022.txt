TALN 2008, Avignon, 9Ð13 juin 2008
Une alternative aux mode`les de traduction statistique dÕIBM :
Les triggers inter-langues
Caroline Lavecchia1, 2 Kamel Smaõ¬li1, 2 David Langlois1, 3
(1) LORIA/Speech Group, Campus scientifique, BP 239, 54506 Vandoeuvre
le`s Nancy Cedex, France
(2) Universite« Nancy2
(3) IUFM de Lorraine
Re«sume«. Dans cet article, nous pre«sentons une nouvelle approche pour la traduction au-
tomatique fonde«e sur les triggers inter-langues. Dans un premier temps, nous expliquons le
concept de triggers inter-langues ainsi que la facüon dont ils sont de«termine«s. Nous pre«sentons
ensuite les diffe«rentes expe«rimentations qui ont e«te« mene«es a` partir de ces triggers afin de
les inte«grer au mieux dans un processus complet de traduction automatique. Pour cela, nous
construisons a` partir des triggers inter-langues des tables de traduction suivant diffe«rentes me«-
thodes. Nous comparons par la suite notre syste`me de traduction fonde« sur les triggers inter-
langues a` un syste`me e«tat de lÕart reposant sur le mode`le 3 dÕIBM (Brown & al., 1993). Les
tests mene«s ont montre« que les traductions automatiques ge«ne«re«es par notre syste`me ame«liorent
le score BLEU (Papineni & al., 2001) de 2, 4% compare« a` celles produites par le syste`me e«tat
de lÕart.
Abstract. In this paper, we present an original approach for machine translation based on
inter-lingual triggers. First, we describe the idea of inter-lingual triggers and how to determine
them. Then, we present the way to make good use of them in order to integrate them in an entire
translation process. We used inter-lingual triggers to estimate different translation tables. Then
we compared our translation system based on triggers to a state-of-the-art system based on IBM
model 3 (Brown & al., 1993). The experiments showed that automatic translations generated by
our system outperform model 3 of IBM by 2.4% in terms of BLEU (Papineni & al., 2001).
Mots-cle«s : Traduction Automatique Statistique, Triggers Inter-Langues, Information
Mutuelle, Corpus paralle`le, De«codage.
Keywords: Statistical Machine Translation, Inter-Lingual Triggers, Mutual Information,
Parallel corpus, Decoding process.
Caroline Lavecchia, Kamel Smaõ¬li, David Langlois
1 Introduction
LÕobjectif de la traduction automatique est de transformer une phrase donne«e dans une langue
source en une phrase dans une langue cible. Pour re«soudre ce proble`me tre`s complexe, il est
possible dÕinte«grer le savoir faire de traducteurs humains, mais cela demande une mode«lisation
de ce savoir qui est en soi un sujet de recherche. Il faut utiliser des mode`les formels des langues
source et cible issus du Traitement Automatique des Langues, et un mode`le de traduction a` base
de re`gles, comme par exemple ce qui est fait dans le syste`me de Systran (Jean Senellart, 2001).
Cet effort de conception doit eötre re«pe«te« pour chaque couple de langues (meöme si le savoir faire
peut eötre en partie transfe«re«). LÕapproche statistique, quant a` elle, utilise une voie diffe«rente. En
effet, elle nÕutilise pas de connaissances a priori, mais sÕappuie sur des corpus bilingues. Ces
corpus sont aligne«s, cÕest-a`-dire que le lien entre chaque partie du texte de la langue source est
fait avec la partie correspondante dans la langue cible. Le lien est ge«ne«ralement fait au niveau
de la phrase. Partant de ces corpus, une analyse statistique utilise les redondances existantes
afin dÕestimer les parame`tres du processus de traduction. La traduction statistique est possible
car les mode`les adhoc sont couple«s avec des algorithmes de programmation dynamique qui
maximisent une fonction de traduction dÕune phrase source vers une phrase cible. IBM a utilise«
avec succe`s cette approche (Brown & al., 1993). La plupart des syste`mes statistiques actuels
sont fonde«s sur les mode`les dÕIBM.
LÕapproche statistique ne«cessite de de«finir un mode`le de traduction qui va permettre de calculer
les probabilite«s de traduction entre les mots, les suites de mots et les autres constituants de la
phrase. Ainsi, on de«finit pour toute phrase s de la langue source et toute phrase t de la langue
cible une valeur P (s|t) calcule«e a` lÕaide de mode`les compose«s de nombreux parame`tres. IBM
propose pour estimer ces parame`tres une me«thode ite«rative engendrant 5 mode`les de traduc-
tion diffe«rents, du plus simple au plus complexe. Cela aboutit a` des mode`les performants, mais
longs et complexes a` estimer. Cette complexite« croit tre`s vite au fur et a` mesure des parame`tres
supple«mentaires pris en compte lors du processus de traduction. En plus du mode`le de traduc-
tion, cette approche utilise un mode`le de langage de la langue cible qui permet dÕe«valuer la
qualite« de la phrase t. Un de«codeur tel que Pharaoh (Koehn, 2004) utilise ces deux mode`les afin
de rechercher pour une phrase s donne«e une phrase t qui peut eötre accepte«e comme traduction
de s.
Dans cet article, nous proposons une nouvelle approche permettant de construire un mode`le de
traduction fonde« sur les triggers inter-langues (extension des triggers classiques) pour construire
notre syste`me de traduction statistique. Le concept de triggers est bien connu de la communaute«
de la mode«lisation statistique du langage. Facile a` mettre en oeuvre, il posse`de une certaine
souplesse qui permet de lÕappliquer a` diffe«rents niveaux de lecture de la phrase (mots, genre,
nombre, constituants syntaxiques). Nous montrerons que les triggers inter-langues permettent
de construire un mode`le de traduction efficace. Nous comparerons ses re«sultats a` ceux fonde«s
sur les mode`les dÕIBM.
Nous pre«sentons dans la partie 2 la notion ge«ne«rale des triggers. La partie 3 de«finit le concept
de triggers inter-langues qui associe a` chaque mot de la langue source une liste de traduc-
tions possibles. Dans la partie 4, nous pre«sentons la manie`re dont les triggers inter-langues ont
e«te« inte«gre«s a` un processus complet de traduction automatique. Nous terminons enfin par une
conclusion qui met en avant les points forts de notre me«thode et donne quelques perspectives
futures des travaux de notre groupe de recherche.
Une alternative aux mode`les de traduction statistique dÕIBM : Les triggers inter-langues
2 Rappel sur les triggers
Le concept de triggers est tre`s souvent cite« en mode«lisation statistique du langage et plus parti-
culie`rement en reconnaissance de la parole. Les triggers permettent entre autre dÕame«liorer et de
ge«ne«raliser le mode`le Cache (Kuhn & DeMori, 1990). Le mode`le Cache favorise la probabilite«
dÕun mot wi re«cemment apparu dans le contexte gauche. Un mode`le de triggers va plus loin et
accorde une probabilite« plus importante a` une liste de mots corre«le«s au mot wi (Tillmann & Ney,
1996). Les triggers sont se«lectionne«s selon la valeur de lÕInformation Mutuelle (IM) donne«e par
la formule suivante :
IM(x, y) = P (x, y)log
P (x, y)
P (x)P (y)
(1)
Chaque mot appartenant au vocabulaire est alors associe« a` n mots qui lui sont le plus forte-
ment corre«le«s dÕapre`s la valeur de lÕIM. Un trigger est un ensemble compose« dÕun mot appele«
de«clencheur et dÕune liste de mots quÕil de«clenche appele«s de«clenche«s. La figure 1 illustre un
exemple de triggers anglais.
Les triggers ont beaucoup e«te« utilise«s en reconnaissance de la Parole ou` ils sont combine«s avec
un mode`le n-gramme classique (Tillmann & Ney, 1997).
Garry  Kasparov  is  a  chess  champion
FIG. 1 Ð Exemples de triggers classiques
3 Les triggers inter-langues
Nous proposons dans ce qui suit dÕe«tendre ce concept pour lÕutiliser avec des corpus bilingues
aligne«s. Nous appelons ce concept triggers inter-langues. Un trigger inter-langue est de«fini
comme e«tant un ensemble compose« dÕun mot de«clencheur dÕune langue source et des mots
de«clenche«s dÕune langue cible qui lui sont fortement corre«le«s. Ainsi, chaque mot f du voca-
bulaire francüais VF est associe« a` n mots anglais ou triggers inter-langues qui lui sont le plus
fortement corre«le«s au sens de lÕIM. Plus formellement,
?fi ? VF , Trign(fi) est lÕensemble des n triggers inter-langues de fi
De la meöme facüon, chaque mot e du vocabulaire anglais VE est associe« a` n mots francüais :
?ei ? VE , Trign(ei) est lÕensemble des n triggers inter-langues de ei.
Les triggers inter-langues sont de«termine«s suivant la valeur de lÕInformation Mutuelle calcule«e
sur un corpus aligne« au niveau de la phrase. Ce corpus est constitue« de paires (E,F ) ou` F est
la traduction de E. Les triggers permettent de repe«rer les e«le«ments en relation dÕune langue a`
lÕautre. Les triggers sont estime«s en utilisant la formule (2).
IM(f, e) = P (f, e) ? log(
P (f, e)
P (f) ? P (e)
) (2)
Caroline Lavecchia, Kamel Smaõ¬li, David Langlois
P (X) =
N(X)
|Corpus|
P (f, e) =
N(f, e)
|Corpus|
(3)
Ð e et f sont des e«le«ments de la paire de phrases (E,F )
Ð N(X) est le nombre de phrases dans lesquelles le mot X apparaõöt
Ð N(e, f) est le nombre de paires (E,F ) de phrases du corpus aligne« dans lesquelles les mots
e et f co-occurent.
Ð |Corpus| est le nombre de paires de phrases constituant le corpus aligne«.
La figure 2 montre un exemple de triggers inter-langues de lÕAnglais vers le Francüais. Ce qui
Garry  Kasparov  is  a  chess  champion Garry  Kasparov  est  un  champion  dÕ  Žchecs
FIG. 2 Ð Exemples de triggers inter-langues
motive lÕutilisation de cette notion est le fait que lÕon espe`re trouver la traduction du mot
de«clencheur dans la liste des mots de«clenche«s.
Notons que ce principe de triggers inter-langues est utilise« en mode«lisation du langage pour
enrichir des langues faiblement dote«es a` partir dÕautres langues tre`s riches en termes de corpus
(Kim & Khudanpur, 2004).
4 La traduction automatique avec les triggers inter-langues
La premie`re e«tape pour la mise en place de notre syste`me de traduction est lÕapprentissage des
triggers inter-langues. Pour ce faire, nous les de«terminons sur un corpus paralle`le extrait des
actes du Parlement Europe«en dont les statistiques sont re«sume«es dans le tableau 1.
TAB. 1 Ð Corpus dÕapprentissage
Francüais Anglais
Paires de phrases 596K
Taille (en mots) 17.3M 15.8M
Vocabulaire (en mots) 77.5K 60.3K
Nous appliquons les formules (2) pour de«tecter les couples (e, f) les plus corre«le«s et qui consti-
tuerons les triggers inter-langues.
Une alternative aux mode`les de traduction statistique dÕIBM : Les triggers inter-langues
Quelques exemples de triggers Anglais-Francüais sont pre«sente«s dans le tableau 2, de meöme
des exemples de triggers Francüais-Anglais sont pre«sente«s dans le tableau 3. La troisie`me co-
lonne des tableaux indique pour chaque couple de mots de«clencheur-de«clenche« la valeur de
lÕInformation Mutuelle qui lui est associe«e. Une analyse qualitative de nos triggers montre
que les mots de«clenche«s peuvent souvent eötre apparente«s a` de possibles traductions du mot
de«clencheur ou a` des mots vraiment tre`s proches du point de vue du sens. Par ailleurs, comme
le montrent les exemples des tableaux, les triggers de«tectent e«galement les diffe«rents sens des
homographes (ainsi, deux sens de ÕporteÕ sont de«tecte«s avec de forts taux dÕInformation Mu-
tuelle). Ces constats sont valables dans les deux sens de traduction.
TAB. 2 Ð Exemples de mots francüais de«clenche«s par des mots anglais
De«clencheur
anglais
De«clenche«s
francüais
IM
(10?4)
De«clencheur
anglais
De«clenche«s
francüais
IM
(10?4)
pion 0, 33 champion 2, 38
chess e«chiquier 0, 29 champion championne 1, 00
e«checs 0, 26 homme 0, 28
porte 20, 96 sens 69, 06
door ouverte 5, 15 sense bon 8, 91
portes 2, 73 sentiment 7, 23
traduction 34, 16 usine 7, 54
translation erreur 2, 73 plant installation 3, 92
version 1, 49 plantes 3, 59
TAB. 3 Ð Exemples de mots anglais de«clenche«s par des mots francüais
De«clencheur
francüais
De«clenche«s
anglais
IM
(10?4)
De«clencheur
francüais
De«clenche«s
anglais
IM
(10?4)
failures 5, 88 champion 2, 38
e«checs failure 0, 88 champion expert 0, 25
chess 0, 26 champions 0, 24
door 20, 96 sense 69, 06
porte relates 5, 21 sens direction 28, 68
concerns 4, 23 meaning 11, 61
translation 34, 16 plants 19, 20
traduction error 2, 51 plantes plant 3, 59
version 1, 49 crops 1, 98
Nous proposons dans ce qui suit, dÕutiliser lÕensemble des triggers inter-langues pour mettre en
place notre syste`me de traduction. Nous le comparons ensuite a` un syste`me e«tat de lÕart reposant
sur le mode`le 3 dÕIBM (Brown & al., 1993). Pour ce faire, nous avons utilise« le de«codeur
Pharaoh1(Koehn, 2004), afin de traduire automatiquement un corpus de test de 1444 phrases
1Le mode`le de langage de la langue cible est un mode`le trigram (me«thode de lissage de Good-Turing. Les poids
des diffe«rents mode`les sont les suivants : 1 pour le mode`le de langage, 1 pour le mode`le de traduction, 1 pour le
mode`le de re«-ordonnancement et enfin une pe«nalite« de mot de 0. Le de«codage est fait avec re«-ordonnancement.
Caroline Lavecchia, Kamel Smaõ¬li, David Langlois
anglaises. Les traductions produites sont ensuite compare«es a` lÕaide de la mesure Bleu, une
mesure automatique couramment employe«e en traduction automatique (Papineni & al., 2001).
Dans les sections suivantes, nous pre«sentons trois facüons dÕidentifier les traductions potentielles
dÕun mot au sein de notre syste`me a` partir des triggers inter-langues de«termine«s auparavant.
Elles donnent lieu a` lÕestimation de trois tables de traduction.
4.1 Les tables de traduction Trig-n
Dans un premier temps, nous estimons que tous les triggers inter-langues peuvent eötre assimile«s
a` des traductions possibles. Par conse«quent, nous les ajoutons tous dans la table de traduction.
Ainsi, un mot anglais ei est une traduction probable du mot francüais fj sÕil fait partie de ses
triggers inter-langues. La probabilite« associe«e a` cette traduction est la valeur de lÕInformation
Mutuelle normalise«e du couple (ei, fj).
?fj ? VF , ?ei, ek ? Trign(fj) P (ei|fj) =
IM(fj , ei)·n
k=1 IM(fj , ek)
(4)
Par la suite, nous appellerons les tables de traduction ainsi construites Trig-n avec n le nombre
de triggers inter-langues retenus pour chaque mot francüais du vocabulaire.
LÕe«valuation de notre syste`me mis en place avec les tables de traduction Trig-n, n variant de 10
a` 200, est de«crite par la se«rie Trig-n de lÕhistogramme de la figure 3. Dans un premier temps,
nous remarquons une ame«lioration du score Bleu de plus de 2 points entre Trig-10 et Trig-
20. Ceci montre que, globalement, les traductions correctes dÕun mot de«clencheur sont dans
les 20 meilleurs de«clenche«s. Toutefois, lorsque n prend des valeurs au dela` de 20, lÕimpact est
beaucoup plus faible. Il faut pre«ciser que, dans la configuration utilise«e, Pharaoh, dans un souci
de rapidite« de recherche, ne prend en compte que les 20 meilleures traductions dÕun mot donne«.
Donc, il est inutile dÕaller au dela` de 20. Toutefois lÕimpact montre« nÕest pas nul car le fait de
normaliser les probabilite«s sur 20, 50 ou 100 triggers modifie lÕe«chelle des valeurs de la table
de traduction et donc le poids de cette table dans le processus de recherche. Notons que nous
avons modifie« cette configuration afin de permettre a` Pharaoh de tenir compte de plus de 20
traductions, mais que cela nÕa pas eu dÕimpact positif sur les performances.
4.2 Les tables de traduction Sym-n
La deuxie`me me«thode de construction dÕune table de traduction consiste a` conside«rer comme
traductions possibles les couples (fj , ei) qui respectent la contrainte de syme«trie suivante :
Si ei ? Trign(fj) et fj ? Trign(ei) Alors ei ? Symn(fj) (5)
ei appartient aux traductions possibles de fj (Symn(fj)), si ei fait partie des triggers inter-
langues de fj et inversement si fj est un trigger inter-langue de ei comme lÕillustre la figure 4.
Cette contrainte de syme«trie nous permet dÕaffiner la liste des triggers inter-langues de fj pour
ne retenir que les plus pertinents. Nous supposons que si ei est un des n mots les plus corre«le«s
avec fj et que fj est e«galement dans les n mots les plus de«clenche«s par ei, alors il y a de fortes
chances que ei soit une traduction de fj . La probabilite« associe«e a` ce couple est calcule«e de la
Une alternative aux mode`les de traduction statistique dÕIBM : Les triggers inter-langues
 25.5
 26
 26.5
 27
 27.5
 28
 28.5
 29
10 20 50 100 200
Bl
eu
n
Trig-n
Sym-n
Smooth-n
M3
FIG. 3 Ð «Evaluation des traductions produites a` lÕaide des tables de traduction Trig-n, Sym-n et
Smooth-n en fonction de n
e
e
f
f
f
f
f
e
e
e
e e
ee
e e
ee
e
e
e
e:f , f , f1 i n
1
2
3
i
n
1 1
1
1
1
11 2
2 22 2
1k
2k
i i2 ik i
1 n2 n nk
. . . . . .
. . . . . .
. . . ..
. . . . . .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Triggers anglais?franais Triggers franais?anglais
Traductions potentielles
FIG. 4 Ð Identification des traductions potentielles dÕun mot par syme«trie
manie`re suivante :
?fj ? VF , ?ei, ek ? Symn(fj) Psym(ei|fj) =
IM(fj , ei)·n
k=1 IM(fj , ik)
(6)
La contrainte de syme«trie re«duit conside«rablement le nombre de couples retenus parmi les trig-
gers inter-langues. En moyenne, seuls 21% des triggers inter-langues respectent la contrainte de
syme«trie (5). Ainsi, nous espe«rons nÕavoir retenu que les triggers les plus pertinents.
La se«rie Sym-n de lÕhistogramme de la figure 3 pre«sente lÕe«valuation de notre syste`me fonde«
sur les tables de traduction Sym-n. Nous observons a` nouveau une nette ame«lioration du score
Bleu lorsque lÕon utilise Sym-20 au lieu de la table Sym-10. Nous notons, e«galement, une le«ge`re
ame«lioration du score Bleu qui passe de 25, 84 pour Trig-10 a` 25, 91 pour Sym-10. La contrainte
de syme«trie nous permet donc, dans ce cas, dÕe«carter des triggers inter-langues qui ne seraient
pas de re«elles traductions. Malheureusement, cette observation ne sÕe«tend pas aux autres tables
Sym-n (avec n > 10) puisque leur score Bleu reste infe«rieur a` ceux obtenus avec les tables
Trig-n. Meöme si cette intuition semble naturelle, la contrainte de syme«trie semble donc eötre trop
restrictive pour ame«liorer les performances de notre syst e`me.
Caroline Lavecchia, Kamel Smaõ¬li, David Langlois
Nous proposons donc une troisie`me facüon dÕidentifier et dÕestimer les traductions potentielles
pour assouplir cette contrainte de syme«trie. Pour cela, nous de«cidons dÕutiliser une technique de
lissage des probabilite«s (smoothing).
4.3 Les tables de traduction Smooth-n
Afin de ne pas affecter une probabilite« nulle aux couples (f, e) qui ne satisfont pas la contrainte
de syme«trie Òe de«clenche f et f de«clenche eÓ, nous proposons dÕutiliser une technique de lissage
pour estimer une troisie`me table de traduction que nous appelons par conse«quent Smooth-n. En
mode«lisation du langage, ces techniques dites de smoothing permettent de lisser les probabi-
lite«s de manie`re a` ce que chaque e«ve`nement, meöme impossible, se voit affecter une probabilite«
(Ney et al., 1994). Nous proposons dÕemployer le meöme type de technique. Pour ce faire, nous
re«duisons la probabilite« des triggers syme«triques des tables Sym-n. La masse ainsi re«cupe«re«e est
re«partie uniforme«ment sur les triggers non syme«triques. Cette nouvelle estimation est calcule«e
de la manie`re suivante :
?ei ? Trign(fj) Psmooth(ei|fj) =
{
Psym(ei|fj) ? ? si ei ? Symn(fj)
? sinon
(7)
Pour un mot francüais, nous retirons une quantite« ? a` chaque probabilite« de traduction assigne«e a`
ses triggers inter-langues syme«triques et nous redistribuons la masse re«colte«e uniforme«ment sur
ses autres triggers inter-langues non syme«triques.
La dernie`re se«rie de lÕhistogramme de la figure 3 indique les performances de notre syste`me
reposant sur les tables Smooth-n. Rappelons que n est le nombre de triggers inter-langues re-
tenus pour chaque mot du vocabulaire francüais. LÕallure de la se«rie est la meöme que pour les
expe«riences pre«ce«dentes. Toutefois, nous pouvons constater que notre syste`me est plus perfor-
mant avec les tables Smooth-n quÕavec les tables Sym-n. Par conse«quent, nous pouvons dire
que la contrainte de syme«trie est en effet trop restrictive, et que le fait de conserver les triggers
non-syme«triques permet bien dÕame«liorer les performances. En revanche, malgre« ces efforts de
lissage, notre syste`me reste le plus performant lorsque chaque trigger inter-langue est conside«re«
comme une traduction potentielle quÕil respecte la contrainte de syme«trie ou non (se«rie Trig-n).
Ces re«sultats pourraient indiquer que la contrainte de syme«trie est trop forte et que le processus
de traduction nÕest pas ne«cessairement syme«trique. Cela serait a` confirmer par une e«tude au cas
par cas.
4.4 Comparaison avec le mode`le 3 de traduction dÕIBM
Afin dÕe«valuer la pertinence de notre syste`me fonde« sur les triggers inter-langues, nous avons
compare« ses performances avec celles dÕun syste`me e«tat de lÕart reposant sur le mode`le 3 dÕIBM
et que nous appelons M3. Ce dernier a e«te« entraõöne«, a` lÕaide de lÕoutil Giza++ (Och & Ney,
2000), sur le meöme corpus paralle`le dÕapprentissage que les triggers inter-langues et teste« avec le
meöme de«codeur sur les meömes 1444 phrases. Les performances du syste`me M3 sont infe«rieures
a` celle de notre syste`me. En effet, nous obtenons un score BLEU de 28, 07 ( cf. courbe M3 de
la figure 3) par rapport a` un score de 28, 49 pour Trig-100.
Toutefois, comme nous lÕavons dit pre«ce«demment, le de«codeur Pharaoh ne prend en compte
pour chaque mot francüais que les 20 meilleures traductions dans le but de re«duire son espace
Une alternative aux mode`les de traduction statistique dÕIBM : Les triggers inter-langues
de recherche. Afin dÕoptimiser les performances de notre syste`me, nous avons parame«tre« le
de«codeur de telle sorte de lui laisser la possibilite« de prendre en compte plus de 20 traduc-
tions par mot francüais. Pour cela, nous faisons varier le parame`tre ttable-limit. Nous optimi-
sons e«galement le parame`tre ttable-threshold qui permet dÕe«carter de lÕespace de recherche
les couples de traductions dont la probabilite« est infe«rieure a` un certain seuil. LÕoptimisation
est re«alise«e inde«pendemment pour les deux syste`mes. Les re«sultats en terme de score Bleu
sont pre«sente«s dans le tableau 4. Les performances de notre syste`me sont optimales lorsque
TAB. 4 Ð Optimisation des parame`tres ttable-limit et ttable-threshold
Mode`le ttable-limit ttable-threshold Bleu
Trig-100 22 0, 04 28, 95
M3 53 0, 00 28, 27
le de«codeur restreint son espace de recherche aux 22 meilleures traductions par mot francüais
dont la probabilite« est supe«rieure ou e«gale a` 0, 04. Celles du syste`me M3 le sont lorsque le
de«codeur re«duit son espace de recherche aux 53 meilleures traductions pour un mot francüais
sans contrainte sur la valeur des probabilite«s. Notre syste`me fonde« sur les triggers inter-langues
apporte une ame«lioration de 2, 4% en termes de score BLEU par rapport au syste`me e«tat de lÕart.
5 Conclusion et perspectives
Nous avons pre«sente« dans cet article une alternative aux mode`les dÕIBM pour la traduction sta-
tistique. La me«thode est fonde«e sur les triggers inter-langues. Ces triggers ont e«te« se«lectionne«s a`
partir dÕun corpus paralle`le aligne« au niveau de la phrase extrait des actes du Parlement Eu-
rope«en. Ils permettent de de«finir pour chaque mot (francüais ou anglais) une liste des mots
(francüais ou anglais) qui lui sont fortement corre«le«s. Ainsi un mot francüais est associe« a` une
liste de mots anglais et vice versa.
Dans le but dÕe«valuer la pertinence des triggers inter-langues en tant que traductions poten-
tielles, nous avons mis en place un syste`me de traduction de mots base« uniquement sur les
triggers inter-langues. Nous avons ensuite compare« ses performances a` celles dÕun syste`me de
re«fe«rence e«tat de lÕart reposant sur les mode`les dÕIBM. Apre`s optimisation des deux syste`mes,
les tests mene«s ont montre« quÕen ne retenant que 22 traductions potentielles pour chaque mot
francüais, les performances de notre syste`me apportent une ame«lioration de 2, 4% du score BLEU
par rapport au syste`me de re«fe«rence.
Ces premiers re«sultats re«ve`lent la faisabilite« de lÕutilisation des triggers inter-langues en traduc-
tion automatique statistique. Par ailleurs, le concept de triggers inter-langues est un formalisme
souple et nous nous sommes concentre«s ici que sur des triggers dÕordre 1-1, cÕest-a`-dire quÕun
mot est traduit par un seul mot. Nous proposons dans (Lavecchia et al., 2008) un syste`me de
traduction fonde« sur les triggers dÕordre n-m, ou` plusieurs mots peuvent eötre traduits par plu-
sieurs mots. Ainsi, notre syste`me devient un syste`me de traduction de se«quences de mots et non
plus de mots.
A plus long terme, nous pouvons envisager beaucoup dÕautres manie`res dÕutiliser les triggers
inter-langues en traduction statistique, comme par exemple en tant que mesure de confiance. De
plus, nous venons de voir quÕils permettent de prendre en compte des se«quences de mots, mais
Caroline Lavecchia, Kamel Smaõ¬li, David Langlois
nous pouvons e«galement imaginer de«terminer des triggers inter-langues dÕautre nature que le
mot comme par exemple des triggers de traits syntaxiques.
Nous pouvons aussi combiner les tables de traduction de Giza++ et les noötres afin de mesurer
leur apport respectif.
Plusieurs autres applications des triggers inter-langues ont e«te« envisage«es et sont en cours de
de«veloppement dans notre groupe de recherche.
Remerciements
Ce travail est subventionne« par la fondation dÕentreprises EADS (European Aeronautic Defence
and Space Company) dans le cadre dÕune the`se sur la traduction Parole-Parole
Re«fe«rences
BROWN P. F. & AL. (1993). The mathematics of statistical machine translation : parameter
estimation. Computational Linguistics, 19, 263Ð311.
JEAN SENELLART, PE«TER DIENES T. V. (2001). New generation systran translation system.
In MT Summit VIII, Santiago de Compostela, Spain.
KIM W. & KHUDANPUR S. (2004). Lexical triggers and latent semantic analysis for cross-
lingual language model adaptation. ACM Transactions on Asian Language Information Pro-
cessing (TALIP), 3(2), 94Ð112.
KOEHN P. (2004). Pharaoh : A beam search decoder for phrase-based statistical machine
translation models. In 6th Conference Of The Association For Machine Translation In The
Americas, p. 115Ð224, Washington, DC, USA.
KUHN R. & DEMORI R. (1990). A cache-based natural language model for speech recogni-
tion. IEEE Trans. PAMI, 12(6), 570Ð582.
LAVECCHIA C., LANGLOIS D. & SMAI¬LI K. (2008). Phrase-based machine translation ba-
sed on simulated annealing. In Proceedings of the International Conference on Language
Ressources and Evaluation.
NEY H., ESSEN U. & KNESER R. (1994). On structuring probabilistic dependences in sto-
chastic language modelling. Computer Speech and Language, 8, 1Ð38.
OCH F. J. & NEY H. (2000). Improved statistical alignment models. In ACL Õ00 : Procee-
dings of the 38th Annual Meeting on Association for Computational Linguistics, p. 440Ð447,
Morristown, NJ, USA : Association for Computational Linguistics.
PAPINENI K. & AL. (2001). Bleu : a method for automatic evaluation of machine translation.
In Proceedings of the 40th Annual of the Association for Computational linguistics, p. 311Ð
318, Philadelphia, USA.
TILLMANN C. & NEY H. (1996). Selection criteria for word trigger pairs in language mo-
deling, In L. M. ET C. DE LA HIGUERA, Ed., Grammatical Inference : Learning Syntax from
Sentences, p. 98Ð106. Lecture Notes in Artificial Intelligence 1147, Springer Verlag.
TILLMANN C. & NEY H. (1997). Word trigger and the EM algorithm. In Proceedings of the
Conference on Computational Natural Language Learning, p. 117Ð124, Madrid, Spain.
