TALN 2008, Avignon, 9-13 juin 2008

Une alternative aux modeles de traduction statistique d’IBM :
Les triggers inter-langues

Caroline LaVecchia1’2 Kamel Sma'ﬂi1*2 David Langlois1’3
(1) LORIA/Speech Group, Campus scientiﬁque, BP 239, 54506 Vandoeuvre
les Nancy Cedex, France
(2) Université Nancy2
(3) IUFM de Lorraine

Résumé. Dans cet article, nous présentons une nouvelle approche pour la traduction au-
tomatique fondée sur les triggers inter-langues. Dans un premier temps, nous expliquons le
concept de triggers inter-langues ainsi que la facon dont ils sont déterminés. Nous présentons
ensuite les différentes expérimentations qui ont été menées a partir de ces triggers aﬁn de
les intégrer au mieux dans un processus complet de traduction automatique. Pour cela, nous
construisons a partir des triggers inter-langues des tables de traduction suivant différentes me-
thodes. Nous comparons par la suite notre systeme de traduction fondé sur les triggers inter-
langues a un systeme état de l’art reposant sur le modele 3 d’IBM (Brown & al., 1993). Les
tests menés ont montré que les traductions automatiques générées par notre systeme améliorent
le score BLEU (Papineni & al., 2001) de 2, 4% compare a celles produites par le systeme état
de l’art.

Abstract. In this paper, we present an original approach for machine translation based on
inter-lingual triggers. First, we describe the idea of inter-lingual triggers and how to determine
them. Then, we present the way to make good use of them in order to integrate them in an entire
translation process. We used inter-lingual triggers to estimate different translation tables. Then
we compared our translation system based on triggers to a state-of-the-art system based on IBM
model 3 (Brown & al., 1993). The experiments showed that automatic translations generated by
our system outperform model 3 of IBM by 2.4% in terms of BLEU (Papineni & al., 2001).

M0tS-CléS I Traduction Automatique Statistique, Triggers Inter-Langues, Information
Mutuelle, Corpus parallele, Décodage.

Keywords: Statistical Machine Translation, Inter-Lingual Triggers, Mutual Information,
Parallel corpus, Decoding process.

Caroline Lavecchia, Kamel Sma'1'li, David Langlois

1 Introduction

L’ objectif de la traduction automatique est de transformer une phrase donnée dans une langue
source en une phrase dans une langue cible. Pour résoudre ce probleme tres complexe, il est
possible d’intégrer le savoir faire de traducteurs humain s, mais cela demande une modélisation
de ce savoir qui est en soi un sujet de recherche. I1 faut utiliser des modeles formels des langues
source et cible issus du Traitement Automatique des Langues, et un modele de traduction a base
de regles, comme par exemple ce qui est fait dans le systeme de Systran (Jean Senellart, 2001).
Cet effort de conception doit étre répété pour chaque couple de langues (meme si le savoir faire
peut étre en partie transféré). L’ approche statistique, quanta elle, utilise une voie différente. En
effet, elle n’utilise pas de connaissances a priori, mais s’appuie sur des corpus bilingues. Ces
corpus sont alignés, c’est-a-dire que le lien entre chaque partie du texte de la langue source est
fait avec la partie correspondante dans la langue cible. Le lien est généralement fait au niveau
de la phrase. Partant de ces corpus, une analyse statistique utilise les redondances existantes
aﬁn d’estimer les parametres du processus de traduction. La traduction statistique est possible
car les modeles adhoc sont couplés avec des algorithmes de programmation dynamique qui
maximisent une fonction de traduction d’une phrase source vers une phrase cible. IBM a utilisé
avec succes cette approche (Brown & al., 1993). La plupart des systemes statistiques actuels
sont fondés sur les modeles d’IBM.

L’ approche statistique nécessite de déﬁnir un modele de traduction qui va permettre de calculer
les probabilités de traduction entre les mots, les suites de mots et les autres constituants de la
phrase. Ainsi, on déﬁnit pour toute phrase 3 de la langue source et toute phrase t de la langue
cible une valeur P(s|t) calculée a l’aide de modeles composés de nombreux parametres. IBM
propose pour estimer ces parametres une méthode itérative engendrant 5 modeles de traduc-
tion différents, du plus simple au plus complexe. Cela aboutit a des modeles performants, mais
longs et complexes a estimer. Cette complexité croit tres vite au fur et a mesure des parametres
supplémentaires pris en compte lors du processus de traduction. En plus du modele de traduc-
tion, cette approche utilise un modele de langage de la langue cible qui permet d’évaluer la
qualité de la phrase 75. Un décodeur tel que Pharaoh (Koehn, 2004) utilise ces deux modeles aﬁn
de rechercher pour une phrase s donnée une phrase t qui peut étre acceptée comme traduction
de 3.

Dans cet article, nous proposons une nouvelle approche permettant de construire un modele de
traduction fondé sur les triggers inter-langues (extension des triggers classiques) pour construire
notre systeme de traduction statistique. Le concept de triggers est bien connu de la communauté
de la modélisation statistique du langage. Facile a mettre en oeuvre, il possede une certaine
souplesse qui permet de l’appliquer a différents niveaux de lecture de la phrase (mots, genre,
nombre, constituants syntaxiques). Nous montrerons que les triggers inter-langues permettent
de construire un modele de traduction efﬁcace. Nous comparerons ses résultats a ceux fondés
sur les modeles d’IBM.

Nous présentons dans la partie 2 la notion générale des triggers. La partie 3 déﬁnit le concept
de triggers inter-langues qui associe a chaque mot de la langue source une liste de traduc-
tions possibles. Dans la partie 4, nous présentons la maniere dont les triggers inter-langues ont
été intégrés a un processus complet de traduction automatique. Nous terminons enﬁn par une
conclusion qui met en avant les points forts de notre méthode et donne quelques perspectives
futures des travaux de notre groupe de recherche.

Une alternative aux modeles de traduction statistique d’IBM : Les triggers inter-langues

2 Rappel sur les triggers

Le concept de triggers est tres souvent cité en modélisation statistique du langage et plus parti-
culierement en reconnaissance de la parole. Les triggers permettent entre autre d’ améliorer et de
généraliser le modele Cache (Kuhn & DeMori, 1990). Le modele Cache favorise la probabilité
d’un mot wi récemment apparu dans le contexte gauche. Un modele de triggers va plus loin et
accorde une probabilité plus importante a une liste de mots corrélés au mot wi (Tillmann & Ney,
1996). Les triggers sont sélectionnés selon la valeur de l’Information Mutuelle (IM) donnée par
la formule suivante :
P (mu y)

P<x>P<y> ‘”
Chaque mot appartenant au vocabulaire est alors associé a n mots qui lui sont le plus forte-
ment corrélés d’apres la valeur de l’IlVI. Un trigger est un ensemble composé d’un mot appelé
déclencheur et d’une liste de mots qu’il déclenche appelés déclenchés. La ﬁgure 1 illustre un
exemple de triggers anglais.

Les triggers ont beaucoup été utilisés en reconnaissance de la Parole ou ils sont combinés avec
un modele n-graInme classique (Tillmann & Ney, 1997).

O5}

Garry Kasparov is a chess champion

IM(w,y) = P(w,y)l09

FIG. 1 — Exemples de triggers classiques

3 Les triggers inter-langues

Nous proposons dans ce qui suit d’étendre ce concept pour l’utiliser avec des corpus bilingues
alignés. Nous appelons ce concept triggers inter-langues. Un trigger inter-langue est déﬁni
comme étant un ensemble composé d’un mot déclencheur d’une langue source et des mots
déclenchés d’une langue cible qui lui sont fortement corrélés. Ainsi, chaque mot f du voca-
bulaire francais VF est associé a n mots anglais ou triggers inter-langues qui lui sont le plus
fortement corrélés au sens de l’IM. Plus formellement,

‘v’f,- E VF, Trign(f,-) est l’ensemble des 12 triggers inter-langues de f,-
De la meme facon, chaque mot e du vocabulaire anglais VE est associé a n mots francais :
‘v’e,- E VE, Trign(e,-) est l’ensemble des 12 triggers inter-langues de e,-.

Les triggers inter-langues sont déterminés suivant la valeur de l’Information Mutuelle calculée
sur un corpus aligné au niveau de la phrase. Ce corpus est constitué de paires (E, F) ou F est
la traduction de E. Les triggers permettent de repérer les éléments en relation d’une langue a
l’autre. Les triggers sont estimés en utilisant la formule (2).

P (f, 6)

IM(fa€) =P(fa€) *l09(  (2)

Caroline Lavecchia, Kamel Sma'1'li, David Langlois

P<X> =  Pox e) =  <3)

e et f sont des éléments de la paire de phrases (E, F)

N (X) est le nombre de phrases dans lesquelles le mot X apparait

N (e, f) est le nombre de paires (E, F) de phrases du corpus aligné dans lesquelles les mots
e et f co-occurent.

— |C0rpus| est le nombre de paires de phrases constituant le corpus aligné.

La ﬁgure 2 montre un exemple de triggers inter-langues de l’Anglais vers le Francais. Ce qui

    

Garry Kasparov is a chess champion Garry Kasparov est un champion d’ échecs

FIG. 2 — Exemples de triggers inter-langues

motive l’utilisation de cette notion est le fait que l’on espere trouver la traduction du mot
déclencheur dans la liste des mots déclenchés.

Notons que ce principe de triggers inter-langues est utilisé en modélisation du langage pour
enrichir des langues faiblement dotées a partir d’autres langues tres riches en termes de corpus
(Kim & Khudanpur, 2004).

4 La traduction automatique avec les triggers inter-langues

La premiere étape pour la mise en place de notre systeme de traduction est l’apprentissage des
triggers inter-langues. Pour ce faire, nous les déterminons sur un corpus parallele extrait des
actes du Parlement Européen dont les statistiques sont résumées dans le tableau 1.

TAB. 1 — Corpus d’apprentissage

Franc-ais | Anglais
Paires de phrases 596K

Taille (en mots) 17.3M 15.8M

Vocabulaire (en mots) 77.5K 60.3K

Nous appliquons les formules (2) pour détecter les couples (e, f) les plus corrélés et qui consti-
tuerons les triggers inter-langues.

Une alternative aux modeles de traduction statistique d’IBM : Les triggers inter-langues

Quelques exemples de triggers Anglais-Francais sont présentés dans le tableau 2, de meme
des exemples de triggers Francais-Anglais sont présentés dans le tableau 3. La troisieme co-
lonne des tableaux indique pour chaque couple de mots déclencheur-déclenché la valeur de
l’Information Mutuelle qui lui est associée. Une analyse qualitative de nos triggers montre
que les mots déclenchés peuvent souvent étre apparentés a de possibles traductions du mot
déclencheur ou a des mots vraiment tres proches du point de vue du sens. Par ailleurs, comme
le montrent les exemples des tableaux, les triggers détectent également les différents sens des
homographes (ainsi, deux sens de ’porte’ sont détectés avec de forts taux d’Information Mu-
tuelle). Ces constats sont valables dans les deux sens de traduction.

TAB. 2 — Exemples de mots francais déclenchés par des mots anglais

Déclencheur Déclenchés INI Déclencheur Déclenchés IM
anglais francais (1O‘4) anglais francais (10‘4)
pion 0, 33 champion 2, 38
chess échiquier 0,29 champion championne 1,00
échecs 0, 26 home 0, 28
porte 20,96 sens 69,06
door ouverte 5, 1 5 sense bon 8, 9 1
portes 2, 73 sentiment 7, 23
traduction 34, 1 6 usine 7, 54
translation erreur 2, 73 plant installation 3, 92
version 1 , 49 plantes 3, 59

TAB. 3 — Exemples de mots anglais déclenchés par des mots francais

Déclencheur Déclenchés INI Déclencheur Déclenchés IM
franc-ais anglais (10‘4) francais anglais (10‘4)
failures 5, 88 champion 2, 38
échecs failure 0,88 champion expert 0,25
chess 0, 26 champions 0, 24
door 20, 96 sense 69, 06
porte relates 5, 2 1 sens direction 28, 68
concerns 4, 23 meaning 1 1, 6 1
translation 34, 1 6 plants 1 9, 20
traduction error 2, 51 plantes plant 3, 59
version 1, 49 crops 1, 98

Nous proposons dans ce qui suit, d’utiliser l’ensemble des triggers inter-langues pour mettre en
place notre systeme de traduction. Nous le comparons ensuite a un systeme état de l’art reposant
sur le modele 3 d’IBM (Brown & al., 1993). Pour ce faire, nous avons utilisé le décodeur
Pharaoh1(Koehn, 2004), aﬁn de traduire automatiquement un corpus de test de 1444 phrases

1Le modele de langage de la langue cible est un modele trigram (méthode de lissage de Good—Turing. Les poids
des différents modeles sont les suivants : 1 pour le modele de langage, 1 pour le modele de traduction, 1 pour le
modele de ré—ordonnancement et enﬁn une pénalité de mot de 0. Le décodage est fait avec re—ordonnancement.

Caroline Lavecchia, Kamel Sma'1'li, David Langlois

anglaises. Les traductions produites sont ensuite comparées a l’aide de la mesure Bleu, une
mesure automatique couramment employée en traduction automatique (Papineni & al., 2001).
Dans les sections suivantes, nous présentons trois facons d’identiﬁer les traductions potentielles
d’un mot au sein de notre systeme a partir des triggers inter-langues déterminés auparavant.
Elles donnent lieu a l’estimation de trois tables de traduction.

4.1 Les tables de traduction Trig-n

Dans un premier temps, nous estimons que tous les triggers inter-langues peuvent étre assimilés
a des traductions possibles. Par conséquent, nous les ajoutons tous dans la table de traduction.
Ainsi, un mot anglais e,- est une traduction probable du mot francais fj s’il fait partie de ses
triggers inter-langues. La probabilité associée a cette traduction est la valeur de l’Information
Mutuelle normalisée du couple (e,-, fj).

Vfj E Vp,‘v’e,-,e;, E Trig,,(fj) P(e,-|fj) =  E§ﬁ)ew (4)
k=1 9:

Par la suite, nous appellerons les tables de traduction ainsi construites Trig-n avec n le nombre
de triggers inter-langues retenus pour chaque mot francais du vocabulaire.

L’ évaluation de notre systeme Inis en place avec les tables de traduction Trig-n, n variant de 10
a 200, est décrite par la série Trig-n de l’histograInme de la ﬁgure 3. Dans un premier temps,
nous remarquons une amélioration du score Bleu de plus de 2 points entre Trig-10 et Trig-
20. Ceci montre que, globalement, les traductions correctes d’un mot déclencheur sont dans
les 20 meilleurs déclenchés. Toutefois, lorsque n prend des valeurs au dela de 20, l’impact est
beaucoup plus faible. Il faut préciser que, dans la conﬁguration utilisée, Pharaoh, dans un souci
de rapidité de recherche, ne prend en compte que les 20 meilleures traductions d’un mot donné.
Donc, il est inutile d’aller au dela de 20. Toutefois l’impact montré n’est pas nul car le fait de
normaliser les probabilités sur 20, 50 ou 100 triggers modiﬁe l’échelle des valeurs de la table
de traduction et donc le poids de cette table dans le processus de recherche. Notons que nous
avons modiﬁé cette conﬁguration aﬁn de permettre a Pharaoh de tenir compte de plus de 20
traductions, mais que cela n’a pas eu d’impact positif sur les performances.

4.2 Les tables de traduction Sym-n

La deuxieme méthode de construction d’une table de traduction consiste a considérer comme
traductions possibles les couples (fj, e,-) qui respectent la contrainte de symétrie suivante :

Si e,- E Trign(fj) et fj E Trign(e,-) Alors e,- E Symn(fj) (5)

e,- appartient aux traductions possibles de fj (Sym,,(fj)), si e,- fait partie des triggers inter-
langues de fj et inversement si fj est un trigger inter-langue de e,- comme l’illustre la ﬁgure 4.

Cette contrainte de symétrie nous permet d’afﬁner la liste des triggers inter-langues de fj pour
ne retenir que les plus pertinents. Nous supposons que si e,- est un des n mots les plus corrélés
avec fj et que fj est également dans les n mots les plus déclenchés par e,-, alors il y a de fortes
chances que e,- soit une traduction de fj. La probabilité associée a ce couple est calculée de la

Une alternative aux modeles de traduction statistique d’IBM : Les triggers inter-langues

Bleu

 

FIG. 3 — Evaluation des traductions produites a l’aide des tables de traduction Trig-n, Sym-n et
Smooth-n en fonction de 12

Triggers anglais—frangais Triggers franca.is—anglais

fl/ele2...e...ek1

f2 :eZe;z......
fa

Traductions potentielles

 

FIG. 4 — Identiﬁcation des traductions potentielles d’un mot par symétrie

maniere suivante :

IM -, ,-
Vfj E VF,\V/Ci, Ck E  Psym(€i|fj) Z  

La contrainte de symétrie réduit considérablement le nombre de couples retenus parrni les trig-
gers inter-langues. En moyenne, seuls 21% des triggers inter-langues respectent la contrainte de
symétrie (5). Ainsi, nous espérons n’avoir retenu que les triggers les plus pertinents.

La série Sym-n de l’histograrnrne de la ﬁgure 3 présente l’évaluation de notre systeme fondé
sur les tables de traduction Sym-n. Nous observons a nouveau une nette amélioration du score
Bleu lorsque l’on utilise Sym-20 au lieu de la table Sym-10. Nous notons, également, une légere
arnélioration du score Bleu qui passe de 25, 84 pour Trig-10 a 25, 91 pour Sym-10. La contrainte
de symétrie nous perrnet donc, dans ce cas, d’écarter des triggers inter-langues qui ne seraient
pas de réelles traductions. Malheureusement, cette observation ne s’étend pas aux autres tables
Sym-n (avec n > 10) puisque leur score Bleu reste inférieur a ceux obtenus avec les tables
Trig-n. Meme si cette intuition semble naturelle, la contrainte de symétrie semble donc étre trop
restrictive pour améliorer les perforrnances de notre systeme.

Caroline Lavecchia, Kamel Sma'1'li, David Langlois

Nous proposons donc une troisieme facon d’identiﬁer et d’estimer les traductions potentielles
pour assouplir cette contrainte de symetrie. Pour cela, nous decidons d’utiliser une technique de
lissage des probabilites (smoothing).

4.3 Les tables de traduction Smooth-n

Aﬁn de ne pas affecter une probabilite nulle aux couples (f, e) qui ne satisfont pas la contrainte
de symetrie “e déclenche f et f déclenche e”, nous proposons d’utiliser une technique de lissage
pour estimer une troisieme table de traduction que nous appelons par consequent Smooth-n. En
modelisation du langage, ces techniques dites de smoothing permettent de lisser les probabi-
lites de maniere a ce que chaque evenement, meme impossible, se voit affecter une probabilite
(Ney et al., 1994). Nous proposons d’employer le meme type de technique. Pour ce faire, nous
reduisons la probabilite des triggers symetriques des tables Sym-n. La masse ainsi recuperee est
repartie uniformement sur les triggers non symetriques. Cette nouvelle estimation est calculee
de la maniere suivante :

Vei E  Psmooth.(ei|.fj) :

{Psym(e,-|fj) — 6 si e,- E Sym,,(fj) (7)

sinon

Pour un mot francais, nous retirons une quantite e a chaque probabilite de traduction assignee a
ses triggers inter-langues symetriques et nous redistribuons la masse recoltee uniformement sur
ses autres triggers inter-langues non symetriques.

La demiere serie de l’histograInme de la ﬁgure 3 indique les performances de notre systeme
reposant sur les tables Smooth-n. Rappelons que n est le nombre de triggers inter-langues re-
tenus pour chaque mot du vocabulaire francais. L’allure de la serie est la meme que pour les
experiences precedentes. Toutefois, nous pouvons constater que notre systeme est plus perfor-
mant avec les tables Smooth-n qu’avec les tables Sym-n. Par consequent, nous pouvons dire
que la contrainte de symetrie est en effet trop restrictive, et que le fait de conserver les triggers
non-symetriques permet bien d’ameliorer les performances. En revanche, malgre ces efforts de
lissage, notre systeme reste le plus performant lorsque chaque trigger inter-langue est considere
comme une traduction potentielle qu’il respecte la contrainte de symetrie ou non (serie Trig-n).

Ces resultats pourraient indiquer que la contrainte de symetrie est trop forte et que le processus
de traduction n’est pas necessairement symetrique. Cela serait a conﬁrmer par une etude au cas
par cas.

4.4 Comparaison avec le modéle 3 de traduction d’IBM

Aﬁn d’evaluer la pertinence de notre systeme fonde sur les triggers inter-langues, nous avons
compare ses performances avec celles d’un systeme etat de l’art reposant sur le modele 3 d’IBM
et que nous appelons M3. Ce demier a ete entraine, a l’aide de l’outil Giza++ (Och & Ney,
2000), sur le meme corpus parallele d’apprentissage que les triggers inter-langues et teste avec le
meme decodeur sur les memes 1444 phrases. Les performances du systeme M3 sont inferieures
a celle de notre systeme. En effet, nous obtenons un score BLEU de 28,07 ( cf. courbe M3 de
la ﬁgure 3) par rapport a un score de 28, 49 pour Trig-I00.

Toutefois, comme nous l’avons dit precedemment, le decodeur Pharaoh ne prend en compte
pour chaque mot francais que les 20 meilleures traductions dans le but de reduire son espace

Une alternative aux modeles de traduction statistique d’IBM : Les triggers inter-langues

de recherche. Aﬁn d’optiIniser les performances de notre systeme, nous avons paramétré le
décodeur de telle sorte de lui laisser la possibilité de prendre en compte plus de 20 traduc-
tions par mot francais. Pour cela, nous faisons varier le parametre ttable-limit. Nous optimi-
sons également le parametre ttable-threshold qui permet d’écarter de l’espace de recherche
les couples de traductions dont la probabilité est inférieure a un certain seuil. L’ optimisation
est réalisée indépendemment pour les deux systemes. Les résultats en terme de score Bleu
sont présentés dans le tableau 4. Les performances de notre systeme sont optimales lorsque

TAB. 4 — Optimisation des parametres ttable-limit et ttable-threshold

| Modele | ttable-limit | ttable-threshold | Bleu |

Trig-I00 22 0, 04 28, 95
M3 53 0, 00 28, 27

1e décodeur restreint son espace de recherche aux 22 meilleures traductions par mot francais
dont la probabilité est supérieure ou égale a 0,04. Celles du systeme M3 le sont lorsque le
décodeur réduit son espace de recherche aux 53 meilleures traductions pour un mot francais
sans contrainte sur la valeur des probabilités. Notre systeme fondé sur les triggers inter-langues
apporte une amélioration de 2, 4% en termes de score BLEU par rapport au systeme état de l’art.

5 Conclusion et perspectives

Nous avons présenté dans cet article une alternative aux modeles d’IBM pour la traduction sta-
tistique. La méthode est fondée sur les triggers inter-langues. Ces triggers ont été sélectionnés a
partir d’un corpus parallele aligné au niveau de la phrase extrait des actes du Parlement Eu-
ropéen. Ils permettent de déﬁnir pour chaque mot (francais ou anglais) une liste des mots
(francais ou anglais) qui lui sont fortement corrélés. Ainsi un mot francais est associé a une
liste de mots anglais et vice versa.

Dans le but d’évaluer la pertinence des triggers inter-langues en tant que traductions poten-
tielles, nous avons mis en place un systeme de traduction de mots basé uniquement sur les
triggers inter-langues. Nous avons ensuite comparé ses performances a celles d’un systeme de
référence état de l’art reposant sur les modeles d’IBM. Apres optimisation des deux systemes,
les tests menés ont montré qu’en ne retenant que 22 traductions potentielles pour chaque mot
francais, les performances de notre systeme apportent une amélioration de 2, 4% du score BLEU
par rapport au systeme de référence.

Ces premiers résultats révelent la faisabilité de l’utilisation des triggers inter-langues en traduc-
tion automatique statistique. Par ailleurs, le concept de triggers inter-langues est un formalisme
souple et nous nous sommes concentrés ici que sur des triggers d’ordre 1-1, c’est-a-dire qu’un
mot est traduit par un seul mot. Nous proposons dans (Lavecchia et al., 2008) un systeme de
traduction fondé sur les triggers d’ordre n-m, ou plusieurs mots peuvent étre traduits par plu-
sieurs mots. Ainsi, notre systeme devient un systeme de traduction de séquences de mots et non
plus de mots.

A plus long terme, nous pouvons envisager beaucoup d’autres manieres d’utiliser les triggers
inter-langues en traduction statistique, comme par exemple en tant que mesure de conﬁance. De
plus, nous venons de voir qu’ils permettent de prendre en compte des séquences de mots, mais

Caroline Lavecchia, Kamel Sma'1'li, David Langlois

nous pouvons également imaginer déterminer des triggers inter-langues d’autre nature que le
mot comme par exemple des triggers de traits syntaxiques.

Nous pouvons aussi combiner les tables de traduction de Giza++ et les notres aﬁn de mesurer
leur apport respectif.

Plusieurs autres applications des triggers inter-langues ont été envisagées et sont en cours de
développement dans notre groupe de recherche.

Remerciements

Ce travail est subventionné par la fondation d’entreprises EADS (European Aeronautic Defence
and Space Company) dans le cadre d’une these sur la traduction Parole-Parole

Références

BROWN P. F. & AL. (1993). The mathematics of statistical machine translation : parameter
estimation. Computational Linguistics, 19, 263-311.

JEAN SENELLART, PETER DIENES T. V. (2001). New generation systran translation system.
In MT Summit VIII, Santiago de Compostela, Spain.

KIM W. & KHUDANPUR S. (2004). Lexical triggers and latent semantic analysis for cross-

lingual language model adaptation. ACM Transactions on Asian Language Information Pro-
cessing (TALIP), 3(2), 94-112.

KOEHN P. (2004). Pharaoh : A beam search decoder for phrase-based statistical machine

translation models. In 6th Conference Of The Association For Machine Translation In The
Americas, p. 115-224, Washington, DC, USA.

KUHN R. & DEMORI R. (1990). A cache-based natural language model for speech recogni-
tion. IEEE Trans. PAMI, 12(6), 570-582.

LAVECCHIA C., LANGLOIS D. & SMA'I'LI K. (2008). Phrase-based machine translation ba-
sed on simulated annealing. In Proceedings of the International Conference on Language
Ressources and Evaluation.

NEY H., ESSEN U. & KNESER R. (1994). On structuring probabilistic dependences in sto-
chastic language modelling. Computer Speech and Language, 8, 1-38.

OCH F. J. & NEY H. (2000). Improved statistical alignment models. In ACL ’00 .' Procee-
dings of the 38th Annual Meeting on Association for Computational Linguistics, p. 440-447,
Morristown, NJ, USA : Association for Computational Linguistics.

PAPINENI K. & AL. (2001). Bleu : a method for automatic evaluation of machine translation.

In Proceedings of the 40th Annual of the Association for Computational linguistics, p. 311-
318, Philadelphia, USA.

TILLMANN C. & NEY H. (1996). Selection criteria for word trigger pairs in language mo-
deling, In L. M. ET C. DE LA HIGUERA, Ed., Grammatical Inference .' Learning Syntax from
Sentences, p. 98-106. Lecture Notes in Artiﬁcial Intelligence 1147, Springer Verlag.

TILLMANN C. & NEY H. (1997). Word trigger and the EM algorithm. In Proceedings of the
Conference on Computational Natural Language Learning, p. 117-124, Madrid, Spain.

