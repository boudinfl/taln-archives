TALN 2008, Avignon, 9–13 juin 2008
Une alternative aux modèles de traduction statistique d’IBM :
Les triggers inter-langues
Caroline Lavecchia1, 2 Kamel Smaı̈li1, 2 David Langlois1, 3
(1) LORIA/Speech Group, Campus scientifique, BP 239, 54506 Vandoeuvre
lès Nancy Cedex, France
(2) Université Nancy2
(3) IUFM de Lorraine
Résumé. Dans cet article, nous présentons une nouvelle approche pour la traduction au-
tomatique fondée sur les triggers inter-langues. Dans un premier temps, nous expliquons le
concept de triggers inter-langues ainsi que la façon dont ils sont déterminés. Nous présentons
ensuite les différentes expérimentations qui ont été menées à partir de ces triggers afin de
les intégrer au mieux dans un processus complet de traduction automatique. Pour cela, nous
construisons à partir des triggers inter-langues des tables de traduction suivant différentes mé-
thodes. Nous comparons par la suite notre système de traduction fondé sur les triggers inter-
langues à un système état de l’art reposant sur le modèle 3 d’IBM (Brown & al., 1993). Les
tests menés ont montré que les traductions automatiques générées par notre système améliorent
le score BLEU (Papineni & al., 2001) de 2, 4% comparé à celles produites par le système état
de l’art.
Abstract. In this paper, we present an original approach for machine translation based on
inter-lingual triggers. First, we describe the idea of inter-lingual triggers and how to determine
them. Then, we present the way to make good use of them in order to integrate them in an entire
translation process. We used inter-lingual triggers to estimate different translation tables. Then
we compared our translation system based on triggers to a state-of-the-art system based on IBM
model 3 (Brown & al., 1993). The experiments showed that automatic translations generated by
our system outperform model 3 of IBM by 2.4% in terms of BLEU (Papineni & al., 2001).
Mots-clés : Traduction Automatique Statistique, Triggers Inter-Langues, Information
Mutuelle, Corpus parallèle, Décodage.
Keywords: Statistical Machine Translation, Inter-Lingual Triggers, Mutual Information,
Parallel corpus, Decoding process.
Caroline Lavecchia, Kamel Smaı̈li, David Langlois
1 Introduction
L’objectif de la traduction automatique est de transformer une phrase donnée dans une langue
source en une phrase dans une langue cible. Pour résoudre ce problème très complexe, il est
possible d’intégrer le savoir faire de traducteurs humains, mais cela demande une modélisation
de ce savoir qui est en soi un sujet de recherche. Il faut utiliser des modèles formels des langues
source et cible issus du Traitement Automatique des Langues, et un modèle de traduction à base
de règles, comme par exemple ce qui est fait dans le système de Systran (Jean Senellart, 2001).
Cet effort de conception doit être répété pour chaque couple de langues (même si le savoir faire
peut être en partie transféré). L’approche statistique, quant à elle, utilise une voie différente. En
effet, elle n’utilise pas de connaissances a priori, mais s’appuie sur des corpus bilingues. Ces
corpus sont alignés, c’est-à-dire que le lien entre chaque partie du texte de la langue source est
fait avec la partie correspondante dans la langue cible. Le lien est généralement fait au niveau
de la phrase. Partant de ces corpus, une analyse statistique utilise les redondances existantes
afin d’estimer les paramètres du processus de traduction. La traduction statistique est possible
car les modèles adhoc sont couplés avec des algorithmes de programmation dynamique qui
maximisent une fonction de traduction d’une phrase source vers une phrase cible. IBM a utilisé
avec succès cette approche (Brown & al., 1993). La plupart des systèmes statistiques actuels
sont fondés sur les modèles d’IBM.
L’approche statistique nécessite de définir un modèle de traduction qui va permettre de calculer
les probabilités de traduction entre les mots, les suites de mots et les autres constituants de la
phrase. Ainsi, on définit pour toute phrase s de la langue source et toute phrase t de la langue
cible une valeur P (s|t) calculée à l’aide de modèles composés de nombreux paramètres. IBM
propose pour estimer ces paramètres une méthode itérative engendrant 5 modèles de traduc-
tion différents, du plus simple au plus complexe. Cela aboutit à des modèles performants, mais
longs et complexes à estimer. Cette complexité croit très vite au fur et à mesure des paramètres
supplémentaires pris en compte lors du processus de traduction. En plus du modèle de traduc-
tion, cette approche utilise un modèle de langage de la langue cible qui permet d’évaluer la
qualité de la phrase t. Un décodeur tel que Pharaoh (Koehn, 2004) utilise ces deux modèles afin
de rechercher pour une phrase s donnée une phrase t qui peut être acceptée comme traduction
de s.
Dans cet article, nous proposons une nouvelle approche permettant de construire un modèle de
traduction fondé sur les triggers inter-langues (extension des triggers classiques) pour construire
notre système de traduction statistique. Le concept de triggers est bien connu de la communauté
de la modélisation statistique du langage. Facile à mettre en oeuvre, il possède une certaine
souplesse qui permet de l’appliquer à différents niveaux de lecture de la phrase (mots, genre,
nombre, constituants syntaxiques). Nous montrerons que les triggers inter-langues permettent
de construire un modèle de traduction efficace. Nous comparerons ses résultats à ceux fondés
sur les modèles d’IBM.
Nous présentons dans la partie 2 la notion générale des triggers. La partie 3 définit le concept
de triggers inter-langues qui associe à chaque mot de la langue source une liste de traduc-
tions possibles. Dans la partie 4, nous présentons la manière dont les triggers inter-langues ont
été intégrés à un processus complet de traduction automatique. Nous terminons enfin par une
conclusion qui met en avant les points forts de notre méthode et donne quelques perspectives
futures des travaux de notre groupe de recherche.
Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues
2 Rappel sur les triggers
Le concept de triggers est très souvent cité en modélisation statistique du langage et plus parti-
culièrement en reconnaissance de la parole. Les triggers permettent entre autre d’améliorer et de
généraliser le modèle Cache (Kuhn & DeMori, 1990). Le modèle Cache favorise la probabilité
d’un mot wi récemment apparu dans le contexte gauche. Un modèle de triggers va plus loin et
accorde une probabilité plus importante à une liste de mots corrélés au mot wi (Tillmann & Ney,
1996). Les triggers sont sélectionnés selon la valeur de l’Information Mutuelle (IM) donnée par
la formule suivante :
P (x, y)
IM(x, y) = P (x, y)log (1)
P (x)P (y)
Chaque mot appartenant au vocabulaire est alors associé à n mots qui lui sont le plus forte-
ment corrélés d’après la valeur de l’IM. Un trigger est un ensemble composé d’un mot appelé
déclencheur et d’une liste de mots qu’il déclenche appelés déclenchés. La figure 1 illustre un
exemple de triggers anglais.
Les triggers ont beaucoup été utilisés en reconnaissance de la Parole où ils sont combinés avec
un modèle n-gramme classique (Tillmann & Ney, 1997).
Garry  Kasparov  is  a  chess  champion
FIG. 1 – Exemples de triggers classiques
3 Les triggers inter-langues
Nous proposons dans ce qui suit d’étendre ce concept pour l’utiliser avec des corpus bilingues
alignés. Nous appelons ce concept triggers inter-langues. Un trigger inter-langue est défini
comme étant un ensemble composé d’un mot déclencheur d’une langue source et des mots
déclenchés d’une langue cible qui lui sont fortement corrélés. Ainsi, chaque mot f du voca-
bulaire français VF est associé à n mots anglais ou triggers inter-langues qui lui sont le plus
fortement corrélés au sens de l’IM. Plus formellement,
∀fi ∈ VF , Trign(fi) est l’ensemble des n triggers inter-langues de fi
De la même façon, chaque mot e du vocabulaire anglais VE est associé à n mots français :
∀ei ∈ VE , Trign(ei) est l’ensemble des n triggers inter-langues de ei.
Les triggers inter-langues sont déterminés suivant la valeur de l’Information Mutuelle calculée
sur un corpus aligné au niveau de la phrase. Ce corpus est constitué de paires (E,F ) où F est
la traduction de E. Les triggers permettent de repérer les éléments en relation d’une langue à
l’autre. Les triggers sont estimés en utilisant la formule (2).
P (f, e)
IM(f, e) = P (f, e) ∗ log( ) (2)
P (f) ∗ P (e)
Caroline Lavecchia, Kamel Smaı̈li, David Langlois
N(X) N(f, e)
P (X) = P (f, e) = (3)
|Corpus| |Corpus|
– e et f sont des éléments de la paire de phrases (E,F )
– N(X) est le nombre de phrases dans lesquelles le mot X apparaı̂t
– N(e, f) est le nombre de paires (E,F ) de phrases du corpus aligné dans lesquelles les mots
e et f co-occurent.
– |Corpus| est le nombre de paires de phrases constituant le corpus aligné.
La figure 2 montre un exemple de triggers inter-langues de l’Anglais vers le Français. Ce qui
Garry  Kasparov  is  a  chess  champion Garry  Kasparov  est  un  champion  d’  échecs
FIG. 2 – Exemples de triggers inter-langues
motive l’utilisation de cette notion est le fait que l’on espère trouver la traduction du mot
déclencheur dans la liste des mots déclenchés.
Notons que ce principe de triggers inter-langues est utilisé en modélisation du langage pour
enrichir des langues faiblement dotées à partir d’autres langues très riches en termes de corpus
(Kim & Khudanpur, 2004).
4 La traduction automatique avec les triggers inter-langues
La première étape pour la mise en place de notre système de traduction est l’apprentissage des
triggers inter-langues. Pour ce faire, nous les déterminons sur un corpus parallèle extrait des
actes du Parlement Européen dont les statistiques sont résumées dans le tableau 1.
TAB. 1 – Corpus d’apprentissage
Français Anglais
Paires de phrases 596K
Taille (en mots) 17.3M 15.8M
Vocabulaire (en mots) 77.5K 60.3K
Nous appliquons les formules (2) pour détecter les couples (e, f) les plus corrélés et qui consti-
tuerons les triggers inter-langues.
Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues
Quelques exemples de triggers Anglais-Français sont présentés dans le tableau 2, de même
des exemples de triggers Français-Anglais sont présentés dans le tableau 3. La troisième co-
lonne des tableaux indique pour chaque couple de mots déclencheur-déclenché la valeur de
l’Information Mutuelle qui lui est associée. Une analyse qualitative de nos triggers montre
que les mots déclenchés peuvent souvent être apparentés à de possibles traductions du mot
déclencheur ou à des mots vraiment très proches du point de vue du sens. Par ailleurs, comme
le montrent les exemples des tableaux, les triggers détectent également les différents sens des
homographes (ainsi, deux sens de ’porte’ sont détectés avec de forts taux d’Information Mu-
tuelle). Ces constats sont valables dans les deux sens de traduction.
TAB. 2 – Exemples de mots français déclenchés par des mots anglais
Déclencheur Déclenchés IM Déclencheur Déclenchés IM
anglais français (10−4) anglais français (10−4)
pion 0, 33 champion 2, 38
chess échiquier 0, 29 champion championne 1, 00
échecs 0, 26 homme 0, 28
porte 20, 96 sens 69, 06
door ouverte 5, 15 sense bon 8, 91
portes 2, 73 sentiment 7, 23
traduction 34, 16 usine 7, 54
translation erreur 2, 73 plant installation 3, 92
version 1, 49 plantes 3, 59
TAB. 3 – Exemples de mots anglais déclenchés par des mots français
Déclencheur Déclenchés IM Déclencheur Déclenchés IM
français anglais (10−4) français anglais (10−4)
failures 5, 88 champion 2, 38
échecs failure 0, 88 champion expert 0, 25
chess 0, 26 champions 0, 24
door 20, 96 sense 69, 06
porte relates 5, 21 sens direction 28, 68
concerns 4, 23 meaning 11, 61
translation 34, 16 plants 19, 20
traduction error 2, 51 plantes plant 3, 59
version 1, 49 crops 1, 98
Nous proposons dans ce qui suit, d’utiliser l’ensemble des triggers inter-langues pour mettre en
place notre système de traduction. Nous le comparons ensuite à un système état de l’art reposant
sur le modèle 3 d’IBM (Brown & al., 1993). Pour ce faire, nous avons utilisé le décodeur
Pharaoh1(Koehn, 2004), afin de traduire automatiquement un corpus de test de 1444 phrases
1Le modèle de langage de la langue cible est un modèle trigram (méthode de lissage de Good-Turing. Les poids
des différents modèles sont les suivants : 1 pour le modèle de langage, 1 pour le modèle de traduction, 1 pour le
modèle de ré-ordonnancement et enfin une pénalité de mot de 0. Le décodage est fait avec ré-ordonnancement.
Caroline Lavecchia, Kamel Smaı̈li, David Langlois
anglaises. Les traductions produites sont ensuite comparées à l’aide de la mesure Bleu, une
mesure automatique couramment employée en traduction automatique (Papineni & al., 2001).
Dans les sections suivantes, nous présentons trois façons d’identifier les traductions potentielles
d’un mot au sein de notre système à partir des triggers inter-langues déterminés auparavant.
Elles donnent lieu à l’estimation de trois tables de traduction.
4.1 Les tables de traduction Trig-n
Dans un premier temps, nous estimons que tous les triggers inter-langues peuvent être assimilés
à des traductions possibles. Par conséquent, nous les ajoutons tous dans la table de traduction.
Ainsi, un mot anglais ei est une traduction probable du mot français fj s’il fait partie de ses
triggers inter-langues. La probabilité associée à cette traduction est la valeur de l’Information
Mutuelle normalisée du couple (ei, fj).
IM(fj
∀fj ∈ VF , ∀ei, ek ∈ Trign(fj) P (ei|fj) = ∑ , ei)n (4)
k IM(f=1 j , ek)
Par la suite, nous appellerons les tables de traduction ainsi construites Trig-n avec n le nombre
de triggers inter-langues retenus pour chaque mot français du vocabulaire.
L’évaluation de notre système mis en place avec les tables de traduction Trig-n, n variant de 10
à 200, est décrite par la série Trig-n de l’histogramme de la figure 3. Dans un premier temps,
nous remarquons une amélioration du score Bleu de plus de 2 points entre Trig-10 et Trig-
20. Ceci montre que, globalement, les traductions correctes d’un mot déclencheur sont dans
les 20 meilleurs déclenchés. Toutefois, lorsque n prend des valeurs au delà de 20, l’impact est
beaucoup plus faible. Il faut préciser que, dans la configuration utilisée, Pharaoh, dans un souci
de rapidité de recherche, ne prend en compte que les 20 meilleures traductions d’un mot donné.
Donc, il est inutile d’aller au delà de 20. Toutefois l’impact montré n’est pas nul car le fait de
normaliser les probabilités sur 20, 50 ou 100 triggers modifie l’échelle des valeurs de la table
de traduction et donc le poids de cette table dans le processus de recherche. Notons que nous
avons modifié cette configuration afin de permettre à Pharaoh de tenir compte de plus de 20
traductions, mais que cela n’a pas eu d’impact positif sur les performances.
4.2 Les tables de traduction Sym-n
La deuxième méthode de construction d’une table de traduction consiste à considérer comme
traductions possibles les couples (fj , ei) qui respectent la contrainte de symétrie suivante :
Si ei ∈ Trign(fj) et fj ∈ Trign(ei) Alors ei ∈ Symn(fj) (5)
ei appartient aux traductions possibles de fj (Symn(fj)), si ei fait partie des triggers inter-
langues de fj et inversement si fj est un trigger inter-langue de ei comme l’illustre la figure 4.
Cette contrainte de symétrie nous permet d’affiner la liste des triggers inter-langues de fj pour
ne retenir que les plus pertinents. Nous supposons que si ei est un des n mots les plus corrélés
avec fj et que fj est également dans les n mots les plus déclenchés par ei, alors il y a de fortes
chances que ei soit une traduction de fj . La probabilité associée à ce couple est calculée de la
Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues
 29
Trig-n
Sym-n
Smooth-n
M3
 28.5
 28
 27.5
 27
 26.5
 26
 25.5
10 20 50 100 200
n
FIG. 3 ́– Evaluation des traductions produites à l’aide des tables de traduction Trig-n, Sym-n et
Smooth-n en fonction de n
Triggers anglais−français Triggers français−anglais
e e . . . e . . . e
11 12 1k
f 11
Traductions potentielles
f2 e e . . . . . . e .21 22 2k 2
.
f .3 .
e .. e:f
.1, fi , fn
f i e e e . . . . . e .i1 i2 ik i
.
.
. .
.
.
fn e e . . . e . . .e
11 n2 n kn
FIG. 4 – Identification des traductions potentielles d’un mot par symétrie
manière suivante :
IM(fj , ei
∀fj ∈ VF , ∀ei, ek ∈ Symn(fj) Psym(ei|fj) = ∑ )n (6)
k IM(f i=1 j , k)
La contrainte de symétrie réduit considérablement le nombre de couples retenus parmi les trig-
gers inter-langues. En moyenne, seuls 21% des triggers inter-langues respectent la contrainte de
symétrie (5). Ainsi, nous espérons n’avoir retenu que les triggers les plus pertinents.
La série Sym-n de l’histogramme de la figure 3 présente l’évaluation de notre système fondé
sur les tables de traduction Sym-n. Nous observons à nouveau une nette amélioration du score
Bleu lorsque l’on utilise Sym-20 au lieu de la table Sym-10. Nous notons, également, une légère
amélioration du score Bleu qui passe de 25, 84 pour Trig-10 à 25, 91 pour Sym-10. La contrainte
de symétrie nous permet donc, dans ce cas, d’écarter des triggers inter-langues qui ne seraient
pas de réelles traductions. Malheureusement, cette observation ne s’étend pas aux autres tables
Sym-n (avec n > 10) puisque leur score Bleu reste inférieur à ceux obtenus avec les tables
Trig-n. Même si cette intuition semble naturelle, la contrainte de symétrie semble donc être trop
restrictive pour améliorer les performances de notre syst ème.
Bleu
Caroline Lavecchia, Kamel Smaı̈li, David Langlois
Nous proposons donc une troisième façon d’identifier et d’estimer les traductions potentielles
pour assouplir cette contrainte de symétrie. Pour cela, nous décidons d’utiliser une technique de
lissage des probabilités (smoothing).
4.3 Les tables de traduction Smooth-n
Afin de ne pas affecter une probabilité nulle aux couples (f, e) qui ne satisfont pas la contrainte
de symétrie “e déclenche f et f déclenche e”, nous proposons d’utiliser une technique de lissage
pour estimer une troisième table de traduction que nous appelons par conséquent Smooth-n. En
modélisation du langage, ces techniques dites de smoothing permettent de lisser les probabi-
lités de manière à ce que chaque évènement, même impossible, se voit affecter une probabilité
(Ney et al., 1994). Nous proposons d’employer le même type de technique. Pour ce faire, nous
réduisons la probabilité des triggers symétriques des tables Sym-n. La masse ainsi récupérée est
répartie uniformément sur les triggers non symétriques. Cette nouvelle estimation est calculée
de la manière suivante : {
Psym(ei|fj) − ǫ si ei ∈ Symn(fj)
∀ei ∈ Trign(fj) Psmooth(ei|fj) = (7)
γ sinon
Pour un mot français, nous retirons une quantité ǫ à chaque probabilité de traduction assignée à
ses triggers inter-langues symétriques et nous redistribuons la masse récoltée uniformément sur
ses autres triggers inter-langues non symétriques.
La dernière série de l’histogramme de la figure 3 indique les performances de notre système
reposant sur les tables Smooth-n. Rappelons que n est le nombre de triggers inter-langues re-
tenus pour chaque mot du vocabulaire français. L’allure de la série est la même que pour les
expériences précédentes. Toutefois, nous pouvons constater que notre système est plus perfor-
mant avec les tables Smooth-n qu’avec les tables Sym-n. Par conséquent, nous pouvons dire
que la contrainte de symétrie est en effet trop restrictive, et que le fait de conserver les triggers
non-symétriques permet bien d’améliorer les performances. En revanche, malgré ces efforts de
lissage, notre système reste le plus performant lorsque chaque trigger inter-langue est considéré
comme une traduction potentielle qu’il respecte la contrainte de symétrie ou non (série Trig-n).
Ces résultats pourraient indiquer que la contrainte de symétrie est trop forte et que le processus
de traduction n’est pas nécessairement symétrique. Cela serait à confirmer par une étude au cas
par cas.
4.4 Comparaison avec le modèle 3 de traduction d’IBM
Afin d’évaluer la pertinence de notre système fondé sur les triggers inter-langues, nous avons
comparé ses performances avec celles d’un système état de l’art reposant sur le modèle 3 d’IBM
et que nous appelons M3. Ce dernier a été entraı̂né, à l’aide de l’outil Giza++ (Och & Ney,
2000), sur le même corpus parallèle d’apprentissage que les triggers inter-langues et testé avec le
même décodeur sur les mêmes 1444 phrases. Les performances du système M3 sont inférieures
à celle de notre système. En effet, nous obtenons un score BLEU de 28, 07 ( cf. courbe M3 de
la figure 3) par rapport à un score de 28, 49 pour Trig-100.
Toutefois, comme nous l’avons dit précédemment, le décodeur Pharaoh ne prend en compte
pour chaque mot français que les 20 meilleures traductions dans le but de réduire son espace
Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues
de recherche. Afin d’optimiser les performances de notre système, nous avons paramétré le
décodeur de telle sorte de lui laisser la possibilité de prendre en compte plus de 20 traduc-
tions par mot français. Pour cela, nous faisons varier le paramètre ttable-limit. Nous optimi-
sons également le paramètre ttable-threshold qui permet d’écarter de l’espace de recherche
les couples de traductions dont la probabilité est inférieure à un certain seuil. L’optimisation
est réalisée indépendemment pour les deux systèmes. Les résultats en terme de score Bleu
sont présentés dans le tableau 4. Les performances de notre système sont optimales lorsque
TAB. 4 – Optimisation des paramètres ttable-limit et ttable-threshold
Modèle ttable-limit ttable-threshold Bleu
Trig-100 22 0, 04 28, 95
M3 53 0, 00 28, 27
le décodeur restreint son espace de recherche aux 22 meilleures traductions par mot français
dont la probabilité est supérieure ou égale à 0, 04. Celles du système M3 le sont lorsque le
décodeur réduit son espace de recherche aux 53 meilleures traductions pour un mot français
sans contrainte sur la valeur des probabilités. Notre système fondé sur les triggers inter-langues
apporte une amélioration de 2, 4% en termes de score BLEU par rapport au système état de l’art.
5 Conclusion et perspectives
Nous avons présenté dans cet article une alternative aux modèles d’IBM pour la traduction sta-
tistique. La méthode est fondée sur les triggers inter-langues. Ces triggers ont été sélectionnés à
partir d’un corpus parallèle aligné au niveau de la phrase extrait des actes du Parlement Eu-
ropéen. Ils permettent de définir pour chaque mot (français ou anglais) une liste des mots
(français ou anglais) qui lui sont fortement corrélés. Ainsi un mot français est associé à une
liste de mots anglais et vice versa.
Dans le but d’évaluer la pertinence des triggers inter-langues en tant que traductions poten-
tielles, nous avons mis en place un système de traduction de mots basé uniquement sur les
triggers inter-langues. Nous avons ensuite comparé ses performances à celles d’un système de
référence état de l’art reposant sur les modèles d’IBM. Après optimisation des deux systèmes,
les tests menés ont montré qu’en ne retenant que 22 traductions potentielles pour chaque mot
français, les performances de notre système apportent une amélioration de 2, 4% du score BLEU
par rapport au système de référence.
Ces premiers résultats révèlent la faisabilité de l’utilisation des triggers inter-langues en traduc-
tion automatique statistique. Par ailleurs, le concept de triggers inter-langues est un formalisme
souple et nous nous sommes concentrés ici que sur des triggers d’ordre 1-1, c’est-à-dire qu’un
mot est traduit par un seul mot. Nous proposons dans (Lavecchia et al., 2008) un système de
traduction fondé sur les triggers d’ordre n-m, où plusieurs mots peuvent être traduits par plu-
sieurs mots. Ainsi, notre système devient un système de traduction de séquences de mots et non
plus de mots.
A plus long terme, nous pouvons envisager beaucoup d’autres manières d’utiliser les triggers
inter-langues en traduction statistique, comme par exemple en tant que mesure de confiance. De
plus, nous venons de voir qu’ils permettent de prendre en compte des séquences de mots, mais
Caroline Lavecchia, Kamel Smaı̈li, David Langlois
nous pouvons également imaginer déterminer des triggers inter-langues d’autre nature que le
mot comme par exemple des triggers de traits syntaxiques.
Nous pouvons aussi combiner les tables de traduction de Giza++ et les nôtres afin de mesurer
leur apport respectif.
Plusieurs autres applications des triggers inter-langues ont été envisagées et sont en cours de
développement dans notre groupe de recherche.
Remerciements
Ce travail est subventionné par la fondation d’entreprises EADS (European Aeronautic Defence
and Space Company) dans le cadre d’une thèse sur la traduction Parole-Parole
Références
BROWN P. F. & AL. (1993). The mathematics of statistical machine translation : parameter
estimation. Computational Linguistics, 19, 263–311.
JEAN SENELLART, PÉTER DIENES T. V. (2001). New generation systran translation system.
In MT Summit VIII, Santiago de Compostela, Spain.
KIM W. & KHUDANPUR S. (2004). Lexical triggers and latent semantic analysis for cross-
lingual language model adaptation. ACM Transactions on Asian Language Information Pro-
cessing (TALIP), 3(2), 94–112.
KOEHN P. (2004). Pharaoh : A beam search decoder for phrase-based statistical machine
translation models. In 6th Conference Of The Association For Machine Translation In The
Americas, p. 115–224, Washington, DC, USA.
KUHN R. & DEMORI R. (1990). A cache-based natural language model for speech recogni-
tion. IEEE Trans. PAMI, 12(6), 570–582.
LAVECCHIA C., LANGLOIS D. & SMAÏLI K. (2008). Phrase-based machine translation ba-
sed on simulated annealing. In Proceedings of the International Conference on Language
Ressources and Evaluation.
NEY H., ESSEN U. & KNESER R. (1994). On structuring probabilistic dependences in sto-
chastic language modelling. Computer Speech and Language, 8, 1–38.
OCH F. J. & NEY H. (2000). Improved statistical alignment models. In ACL ’00 : Procee-
dings of the 38th Annual Meeting on Association for Computational Linguistics, p. 440–447,
Morristown, NJ, USA : Association for Computational Linguistics.
PAPINENI K. & AL. (2001). Bleu : a method for automatic evaluation of machine translation.
In Proceedings of the 40th Annual of the Association for Computational linguistics, p. 311–
318, Philadelphia, USA.
TILLMANN C. & NEY H. (1996). Selection criteria for word trigger pairs in language mo-
deling, In L. M. ET C. DE LA HIGUERA, Ed., Grammatical Inference : Learning Syntax from
Sentences, p. 98–106. Lecture Notes in Artificial Intelligence 1147, Springer Verlag.
TILLMANN C. & NEY H. (1997). Word trigger and the EM algorithm. In Proceedings of the
Conference on Computational Natural Language Learning, p. 117–124, Madrid, Spain.
