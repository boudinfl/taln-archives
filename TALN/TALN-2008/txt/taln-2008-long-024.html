<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Les architectures linguistiques et computationnelles en traduction automatique sont ind&#233;pendantes</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2008, Avignon, 9-13 juin 2008 
</p>
<p> 
</p>
<p>Les architectures linguistiques et computationnelles  
en traduction automatique sont ind&#233;pendantes 
</p>
<p>Christian BOITET 
</p>
<p>Laboratoire LIG, GETALP &#8211; Universit&#233; Joseph Fourier,  
385 rue de la biblioth&#232;que, BP 53, 38041 Grenoble, Cedex 9, France 
</p>
<p>Christian.Boitet@imag.fr 
</p>
<p>R&#233;sum&#233; Contrairement &#224; une id&#233;e r&#233;pandue, les architectures linguistiques et computationnelles des 
syst&#232;mes de traduction automatique sont ind&#233;pendantes. Les premi&#232;res concernent le choix des 
repr&#233;sentations interm&#233;diaires, les secondes le type d'algorithme, de programmation et de ressources 
utilis&#233;s. Il est ainsi possible d'utiliser des m&#233;thodes de calcul &#171; expertes &#187; ou &#171; empiriques &#187; pour 
construire diverses phases ou modules de syst&#232;mes d'architectures linguistiques vari&#233;es. Nous 
terminons en donnant quelques &#233;l&#233;ments pour le choix de ces architectures en fonction des situations 
traductionnelles et des ressources disponibles, en termes de dictionnaires, de corpus, et de 
comp&#233;tences humaines. 
Abstract Contrary to a wide-spread idea, the linguistic and computational architectures of MT 
systems are independent.  The former concern the choice of the intermediate representations, the latter 
the type of algorithm, programming, and resources used.  It is thus possible to use &quot;expert&quot; or 
&quot;empirical&quot; computational methods to build various phases or modules of systems having various 
linguistic architectures.  We finish by giving some elements for choosing these architectures 
depending on the translational situations and the available resources, in terms of dictionaries, corpora, 
and human competences. 
Mots-cl&#233;s : Traduction Automatique, TA, TAO, architecture linguistique, architecture 
computationnelle, TA experte, TA par r&#232;gles, TA empirique, TA statistique, TA par l'exemple 
Keywords: Machine Translation, MT, linguistic architecture, computational architecture, expert MT, 
rule-based MT, empirical MT, statistical MT, example-based MT. 
 
</p>
<p>Introduction 
Il y a un certain nombre d'id&#233;es fausses qui circulent parmi les chercheurs en TA, et freinent &#224; notre 
avis les progr&#232;s dans ce domaine. La premi&#232;re est que la plupart des syst&#232;mes op&#233;rationnels utilisent la 
TA statistique, alors que la plupart (voir le Compendium (Hutchins &amp; al. 2005) publi&#233; par l'EAMT) 
utilisent des m&#233;thodes &#171; expertes &#187; (&#171; &#224; r&#232;gles &#187;, mais pas seulement &#224; r&#232;gles). L'autre est que les 
syst&#232;mes utilisant un &#171; pivot interlingue &#187;, &#233;videmment tr&#232;s adapt&#233; &#224; la communication multilingue, 
sont n&#233;cessairement &#171; &#224; r&#232;gles &#187; (TAFR, en anglais RBMT ou &#171; rule-based MT &#187;), et donc tr&#232;s 
co&#251;teux &#224; construire (ce &#171; donc &#187; est faux aussi&#8230;).  
Il ne faut pas faire l'amalgame entre l'architecture linguistique d'un syst&#232;me de TA, caract&#233;ris&#233;e par les 
repr&#233;sentations interm&#233;diaires qu'il utilise durant le processus de traduction, et son architecture 
computationnelle, caract&#233;ris&#233;e par les m&#233;thodes de calcul et les ressources utilis&#233;es dans ses diverses 
&#171; phases &#187; transformant une repr&#233;sentation interm&#233;diaire en sa suivante dans le processus. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Christian BOITET 
</p>
<p> 
</p>
<p>Apr&#232;s une br&#232;ve partie consacr&#233;e aux d&#233;finitions des variantes de ces architectures, nous montrerons 
que, pour &#224; peu pr&#232;s chaque architecture linguistique, on trouve des syst&#232;mes utilisant diverses 
architectures computationnelles. De plus, une bonne partie des syst&#232;mes utilisent plusieurs 
architectures computationnelles dans leurs diff&#233;rentes phases. Nous essaierons enfin de d&#233;gager 
quelques indications sur les choix d'architecture appropri&#233;s aux diverses situations traductionnelles et 
des ressources disponibles, en termes de dictionnaires, de corpus, et de comp&#233;tences humaines. 
</p>
<p>1 Architectures des syst&#232;mes de TA 
</p>
<p>1.1 Architectures linguistiques 
Ces architectures correspondent aux &#171; chemins &#187; dans le fameux &#171; triangle de Vauquois &#187;. 
</p>
<p> 
Figure 1 : triangle de Vauquois (Vauquois &amp; Boitet 1985, Analectes de Vauquois &#8212; Boitet 1988) 
</p>
<p>Les syst&#232;mes directs n'utilisent que deux repr&#233;sentations, le texte d'entr&#233;e et le texte de sortie. Pour les 
langues ayant des syst&#232;mes d'&#233;criture &#224; s&#233;parateurs de mots ou de syllabes, le texte d'entr&#233;e n'est 
souvent pas strictement le flot de caract&#232;res tel quel, mais une suite de &#171; mots typographiques &#187; 
s&#233;par&#233;s gr&#226;ce &#224; des r&#232;gles simples. Les syst&#232;mes semi-directs ont une phase de segmentation ou 
d'analyse morphologique, voire morphosyntaxique, et une phase de g&#233;n&#233;ration morphologique. C'est le 
cas des syst&#232;mes de &#171; premi&#232;re g&#233;n&#233;ration &#187; (russe-anglais aux USA et anglais-russe en URSS d&#232;s les 
ann&#233;es 1950), et un certain nombre de syst&#232;mes commerciaux actuels sont toujours de ce type. 
Il existe au moins 7 variantes des syst&#232;mes &#224; transfert. La structure obtenue en fin d'analyse peut &#234;tre 
syntagmatique (bas&#233;e sur des constituants la plupart du temps connexes), ou bien d&#233;pendancielle, et 
dans ce cas surfacique (fonctions syntaxiques comme sujet, objet direct, &#233;pith&#232;te, attribut&#8230;) ou 
profonde (relations s&#233;mantiques comme agent, patient, cause, concession&#8230;). Les syst&#232;mes &#224; transfert 
profond fond&#233;s sur les th&#233;ories de Tesni&#232;re, puis de l'Ecole de Prague et de celle de Moscou, utilisent 
des repr&#233;sentations logico-s&#233;mantiques distinguant les arguments des circonstants.1  
</p>
<p>                                                     
1 Les circonstants portent des relations s&#233;mantiques (cas profonds), tandis que les arguments ne portent en 
</p>
<p>g&#233;n&#233;ral qu'un num&#233;ro (Arg0, Arg1&#8230; Arg4 ou Arg5 au maximum), car il est tr&#232;s difficile sinon impossible 
d'affecter fiablement une relation s&#233;mantique &#224; un argument, si le r&#233;pertoire de ces relations est celui utilis&#233; 
pour les circonstants. Le projet FrameNet montre d'ailleurs bien que, si on veut d&#233;finir des relations </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ind&#233;pendance des architectures linguistiques et computationnelles en traduction automatique 
</p>
<p>On dit qu'il y a &#171; transfert lexical &#187; quand on passe directement de &#171; l'espace lexical &#187; de la langue 
source &#224; celui de la langue cible. Par &#171; espace lexical &#187;, on entend tout le syst&#232;me lexical, qui va des 
&#171; formes &#187; de surface aux &#171; acceptions &#187;, en passant par les lemmes et &#233;ventuellement par les &#171; unit&#233;s 
lexicales &#187; (familles d&#233;rivationnelles) ou &#171; prolex&#232;mes &#187; (les m&#234;mes, un peu &#233;largies). 
Le &#171; pivot hybride &#187; (terme d&#251; &#224; Shaumyan) des syst&#232;mes du CETA des ann&#233;es 1965-70 &#233;tait un type 
de repr&#233;sentation utilisant des attributs et relations interlingues, et des unit&#233;s lexicales de chacune des 
langues. Ces syst&#232;mes &#233;taient donc &#224; transfert simple, alors qu'on a un double transfert en &#171; pivot &#187;. 
Les structures multiniveau de Vauquois sont bas&#233;es sur un graphe syntagmatique abstrait (suppression 
des auxiliaires, regroupement de lex&#232;mes discontinus comme give...up, etc.), lexicalis&#233; (chaque n&#339;ud 
interne domine un &#171; gouverneur &#187; lexical), et contenant aussi bien les informations et relations 
profondes que celles de surface. De telles structures sont &#171; g&#233;n&#233;ratrices &#187; des structures mononiveau 
usuelles, et offrent une sorte de &#171; filet de s&#233;curit&#233; &#187;. 
Les syst&#232;mes &#224; v&#233;ritable interlingua (comme ATLAS-II de Fujitsu ou PIVOT/Crossroads de NEC, ou 
KANT/CATALYST de CMU/Caterpillar, ou UNL, ou MASTOR-1 d'IBM, ce dernier en TA de 
parole) utilisent 3 espaces lexicaux, car un v&#233;ritable interlingua poss&#232;de son propre vocabulaire, m&#234;me 
si ce vocabulaire est construit comme union des acceptions2 d'un certain nombre de langues, comme 
UNL (Uchida 1996, 2004). Dans les syst&#232;mes de TA, il existe des interlinguas &#171; linguistico-
s&#233;mantiques &#187; (comme KANT, ULTRA, UNL) dont les &#171; lex&#232;mes &#187; sont construits &#224; partir des 
lemmes et des lexies de dictionnaires d'une ou plusieurs langues naturelles, et des interlinguas 
&#171; s&#233;mantiques &#187; ou &#171; s&#233;mantico-pragmatiques &#187;, dont les lex&#232;mes sont construits &#224; partir des entit&#233;s, 
propri&#233;t&#233;s, actions et processus d'un domaine pr&#233;cis et d'un ensemble de t&#226;ches bien identifi&#233;es (par 
exemple, r&#233;servation touristique). 
Enfin, si la plupart des syst&#232;mes de TA ont comme &#171; unit&#233; de traduction &#187; le &#171; segment &#187; (phrase ou 
titre) des syst&#232;mes d'aide au traducteur utilisant des m&#233;moires de traductions, certains ont des unit&#233;s de 
traduction de l'ordre de la page (Ariane-G5), ce qui permet de mieux traiter certains ph&#233;nom&#232;nes 
comme la concordance des temps et de r&#233;soudre des anaphores hors du contexte de la phrase. 
</p>
<p>1.2 Architectures computationnelles 
Pour ce qui est des processus automatiques, on distingue entre m&#233;thodes expertes et m&#233;thodes 
empiriques. Il y a aussi des distinctions &#224; faire si le processus de traduction est interactif. 
</p>
<p>1.2.1 M&#233;thodes &#171; expertes &#187; 
Les m&#233;thodes &#171; expertes &#187; sont plus ou moins proc&#233;durales ou d&#233;claratives, et font appel &#224; de la 
programmation directe ou fond&#233;e sur des &#171; mod&#232;les de calcul &#187; abstraits, d'o&#249; l'utilisation de LSPL 
(langages sp&#233;cialis&#233;s pour a programmation linguistique). On a en bref : 
&#8226; la programmation directe dans un langage algorithmique classique (souvent employ&#233;e au niveau 
</p>
<p>des traitements typographiques ou morphologiques). 
&#8226; la programmation directe dans un langage de haut ou tr&#232;s haut niveau (Lisp, Prolog) offrant des 
</p>
<p>structures de donn&#233;es et de contr&#244;le plus adapt&#233;es &#224; la programmation linguistique, mais 
demandant une grande expertise en programmation. 
</p>
<p>&#8226; la programmation dans des LSPL d'automates (comme les transducteurs finis, les ATN ou les 
transformateurs d'arbres, abusivement dits &#171; grammaires &#187; transformationnelles). 
</p>
<p>&#8226; la programmation dans des formalismes de grammaires d&#233;claratives (ou presque) comme LFG, 
GPSG, HPSG, ou TAG. 
</p>
<p>                                                                                                                                                                      
s&#233;mantiques pour les arguments, il faut le plus souvent les lexicaliser (&quot;donner&quot; aura alors &quot;donateur/donneur&quot; 
pour Arg0, &quot;don&quot; pour Arg1, &quot;donataire&quot; pour Arg2). 
</p>
<p>2 Une &quot;acception&quot; est un sens d'un mot, au sens de lemme ou terme, dans l'usage de la langue. Une &quot;lexie&quot; est un 
sens de mot dans un dictionnaire. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Christian BOITET 
</p>
<p> 
</p>
<p>Il est abusif de parler de syst&#232;mes &#171; &#224; r&#232;gles &#187; pour les deux premiers. Ainsi, Systran utilise des 
automates (transducteurs d'&#233;tats finis) pour l'analyse morphologique, tandis que l'analyse syntaxique 
n'est pas faite par &#171; r&#232;gles &#187;, mais par un programme instanciant un sch&#233;ma proc&#233;dural fixe (&#233;criture 
de &#171; macros &#187; d&#233;terminant des d&#233;cisions locales par examen d'une &#171; fen&#234;tre courante &#187; sur un graphe 
sans boucle repr&#233;sentant la phrase).   
</p>
<p>1.2.2 M&#233;thodes empiriques 
Ce sont les m&#233;thodes fond&#233;es sur les corpus :  
&#8226; TA statistique (SMT) et TA statistique &#224; syntagmes (PSMT, ou &#171; phrase-based &#187; SMT), 
&#8226; TA fond&#233;e sur les exemples (EBMT), avec 3 variantes. 
Notons que &#171; TA statistique &#187; est un assez mauvais terme, car on devrait plut&#244;t parler de TA 
&#171; probabiliste &#187;. En effet, un &#171; mod&#232;le de langage &#187; est une collection de probabilit&#233;s estim&#233;es d'apr&#232;s 
des comptages sur de gros ou tr&#232;s gros corpus. 
La diff&#233;rence essentielle entre SMT et EBMT est que, en EBMT, les exemples sont utilis&#233;s 
directement durant le processus de traduction, tandis que la SMT utilise les r&#233;sultats d'une sorte de 
gigantesque &#171; compilation &#187; de l'ensemble des exemples (corpus align&#233;). 
Les variantes de l'EBMT sont les suivantes : 
&#8226; En EBMT classique, on &#233;tend les techniques de recherche de segments voisins des syst&#232;mes d'aide 
</p>
<p>aux traducteurs avec m&#233;moire de traductions, et on propose, pour les mots diff&#233;renciant le 
segment &#224; traduire et le segment trouv&#233;, des remplacements venant d'autres exemples ou de 
dictionnaires. Le syst&#232;me Similis&#8482;(d&#233;riv&#233; de (Planas 1998)) d&#8217;aide au traducteur en est proche. 
</p>
<p>&#8226; En EBMT par analogie (Lepage &amp; Denoual 2005), si S1 est le segment &#224; traduire (en langue L1), 
on cherche les &#171; rectangles analogiques &#187; P1:Q1::R1:S1 tels qu'on dispose des exemples de 
traduction (P1,P2), (Q1,Q2), (R1,R2), et on r&#233;sout en X (dans la langue L2) l'&#233;quation 
analogique P2:Q2::R2:X. On obtient en g&#233;n&#233;ral plusieurs traductions X, qu'on filtre pour la fluidit&#233; 
par un mod&#232;le n-gramme. Si on ne trouve pas de tel rectangle, on r&#233;sout en Y (dans la langue L1) 
l'&#233;quation P1:Q1::Y:S1 et on continue r&#233;cursivement. Il n'y a donc pas de &#171; d&#233;composition en 
morceaux qui se correspondent &#187; puis de &#171; recomposition &#187;. 
</p>
<p>&#8226; Dans le syst&#232;me EBMT par exemples de correspondances structur&#233;es de Al-Adhaileh et Tang 
(USM, Penang), on utilise un corpus parall&#232;le annot&#233; par des S-SSTC (correspondances cha&#238;ne-
arbre structur&#233;es synchronis&#233;es). La traduction se fait par analyse-synth&#232;se. Une correspondance 
(C1, A1)&#8212;c&#8212;(C2, A2) est &#233;l&#233;mentaire ou compos&#233;e (= {(C1i, A1i)&#8212;ci&#8212;(C2i, A2i)}i). 
Quand on en trouve une car on a identifi&#233; un morceau C1 du segment S1 &#224; traduire, ou bien les 
correspondances la constituant, on a d'un seul coup les 3 autres &#233;l&#233;ments et leur synchronisation.  
</p>
<p>2 Vari&#233;t&#233; des architectures computationnelles 
Voici maintenant une &#233;tude synth&#233;tique (non exhaustive) des architectures computationnelles utilis&#233;es 
dans des syst&#232;mes de TA bas&#233;s sur 11 architectures linguistiques diff&#233;rentes. Pour la clart&#233;, nous 
utilisons des tableaux, organis&#233;s de la fa&#231;on la plus homog&#232;ne possible. Il n&#8217;a malheureusement pas 
&#233;t&#233; possible de suivre la suggestion d&#8217;un relecteur, et de faire un seul grand tableau croisant les deux 
architectures, car trop de syst&#232;mes utilisent diff&#233;rentes architectures computationnelles dans 
diff&#233;rentes phases du traitement. Pour des raisons de place, il n&#8217;a pas non plus &#233;t&#233; possible de mettre 
autant de r&#233;f&#233;rences qu&#8217;on l&#8217;aurait souhait&#233;. D&#8217;un autre c&#244;t&#233;, les r&#233;f&#233;rences sur les syst&#232;mes 
op&#233;rationnels (commerciaux comme Systran, ATLAS, The Translator, Honyaku-no-oo-sama, ProMT, 
Softissimo, Tracy, PIVOT/Crossroads, ALTFlash, METAL/Compendium, LanguageWeaver, etc., et 
non commerciaux ou semi-commerciaux comme PAHO-MTS, ALT/JE ou Google Translator) sont 
tr&#232;s rares et souvent anciennes. Le &#171; Compendium &#187; (Hutchins &amp; al. 2005) est une source importante, 
mais ne donne pas de d&#233;tails pr&#233;cis sur la fa&#231;on dont les syst&#232;mes cit&#233;s sont construits.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ind&#233;pendance des architectures linguistiques et computationnelles en traduction automatique 
</p>
<p>2.1 Syst&#232;mes de traduction directe  
Type &#201;tapes M&#233;thode Commentaires Exemples 
RBMT 
1975&#8212; 
</p>
<p>Segmentation 
Trad. mot &#224; mot 
</p>
<p>FST (r&#232;gles + dict.) 
r&#232;gles  
</p>
<p>Convient pour des langues tr&#232;s voisines 
japonais &#8596; cor&#233;en, hindi &#8596; urdu &#8230; 
</p>
<p>ATLAS-I Fujitsu,76-78 
(cor&#233;en&#8596;japonais) 
</p>
<p>SMT 
1980&#8212; 
 
</p>
<p>Segmentation, 
r&#233;arrangement&#8230; 
</p>
<p>Alignement + 
&#171; d&#233;codage &#187; 
statistique 
</p>
<p>SMT =  premi&#232;re id&#233;e sur la TA par les 
cryptographes de la 2&#176; guerre mondiale 
(W. Weaver 1949) 
</p>
<p>Beaucoup de syst&#232;mes 
statistiques (SMT)  
IBM 1980- 
</p>
<p>EBMT 
2000&#8212; 
 
</p>
<p>Pas de 
pr&#233;traitement 
EBMT &#171; pure &#187;  
</p>
<p>R&#233;solution analogique 
+ filtrage n-grammes  
analogique 
</p>
<p>R&#233;sultats &#8776; ceux de la SMT 
Nagao 1984 (plut&#244;t TA par similarit&#233;) 
Lepage 2000 (vraie analogie &#224; 4 termes) 
</p>
<p>ALEPH  
ATR 2000- 
GREYT, Caen 2006&#8212; 
</p>
<p>Le plus souvent, ces syst&#232;mes sont &#171; empiriques &#187;, mais certains utilisent une approche &#171; experte &#187;, 
comme ATLAS-I (diff&#233;rent de ATLAS-II). 
</p>
<p>2.2 Syst&#232;mes de traduction semi-directe  
Type &#201;tapes M&#233;thode Commentaires Exemples 
1G-MT 
1950&#8212; 
 
</p>
<p>Segmentation &amp; 
Lemmatisation par 
programme 
</p>
<p>Consultation de 
dictionnaire + &quot;macros&quot; 
de r&#233;arrangement 
proc&#233;dural 
</p>
<p>Tables + macros sur 
des cha&#238;nes 
proc&#233;dural 
</p>
<p>GAT (Georgetown) 
EURATOM, Ispra, 1965&#8212;69 
SPANAM-1, PAHO, &#8776;1975&#8212; 
GLOBALINK &#8592; Spanam-1 (PAHO) 
</p>
<p>SMT 
1990&#8212; 
</p>
<p>Lemmatisation  
D&#233;codage 
</p>
<p>Proc&#233;dural + r&#232;gles 
statistique 
</p>
<p>Mod&#232;le de langue 
probabiliste 
</p>
<p>Candide IBM, 1980&#8212;, Google 2005- 
Beaucoup de syst&#232;mes statistiques 
</p>
<p>Trad. 
pidgin  
 
</p>
<p>Lemmatisation 
Transfert lexical 
R&#233;arrangement 
G&#233;n&#233;ration 
</p>
<p>Traitement de cha&#238;nes 
r&#232;gles en syst&#232;mes-Q  
-- 
-- 
</p>
<p>proc&#233;dural (snobol4) 
&#201;nonc&#233; =  
graphe de cha&#238;nes 
d'arbres &#233;tiquet&#233;s 
</p>
<p>Id&#233;e de B. Harris  
(TAUM, &#171; traductologiste &#187;) 
rus &#8594; eng, fre (Boitet 1972) 
</p>
<p>GlobaLink a &#233;t&#233; fait &#224; partir d'une copie de Spanam-1. Spanam-2 est de type expert (ATN).   
Les syst&#232;mes actuels de Google sont (sans doute) plus PSMT (phrase-based SMT) que SMT.  
</p>
<p>2.3 Syst&#232;mes &#224; transfert descendant de constituants  
Type &#201;tapes M&#233;thode Commentaires Exemples 
RBMT 
1970&#8212; 
</p>
<p>Analyse par ATN 
 
Transfert/g&#233;n&#233;ration 
</p>
<p>LSPL &#233;tendant Lisp ou 
un autre Lprog 
Descente r&#233;cursive 
</p>
<p>r&#232;gles + dict. + 
transformation 
proc&#233;dural + r&#232;gles 
</p>
<p>ENGSPAN, SPANAM-2, ou  
&#8216;PAHO-MTS&#8217; (PAHO, &#8776;1978&#8212;) 
AS-Transac (Toshiba, 1982&#8212;) 
Reverso ProMT, 1986&#8212; 
</p>
<p>RBMT 
1980&#8212; 
 
</p>
<p>Analyse par ECFG 
(hors-contexte 
&#233;tendu)  
Transfert /g&#233;n&#233;ration 
</p>
<p>LSPL &#233;tendant Lisp ou 
un autre Lprog 
 
Descente r&#233;cursive 
</p>
<p>grammaire+dict. 
r&#232;gles 
 
proc&#233;dural + r&#232;gles 
</p>
<p>METAL (TUA+Siemens, 1982&#8212;) 
Duet-2 (Sharp, 1984&#8212;) 
Shalt-1 (IBM-Japon, 1982&#8212;) 
Kate KDD (1983&#8212;) 
</p>
<p>RBMT 
1984&#8212;  
 
</p>
<p>Lemmatisation  
Slot-grammars 
T+G en Prolog 
</p>
<p>Dictionnaire +tables 
LSPL &#233;tendant Prolog 
Descente r&#233;cursive 
</p>
<p>proc&#233;dural  
r&#232;gles 
proc&#233;dural + r&#232;gles 
</p>
<p>LMT (IBM-US, 1983&#8212;) 
PT-1 (Personal Tanslator) de 
Linguatec, d&#233;riv&#233; de LMT, &#8212;2000 
</p>
<p>Les syst&#232;mes r&#233;cents de type PSMT de LanguageWeaver sont sans doute aussi de ce type.  
</p>
<p>2.4 Syst&#232;mes &#224; transfert descendant de d&#233;pendances  
Type &#201;tapes M&#233;thode Commentaires Exemples 
1.5G-MT  
1990&#8212; 
 
</p>
<p>Lemmatisation 
Analyse produisant un 
graphe de d&#233;pendances 
Transfert /g&#233;n&#233;ration 
</p>
<p>FST (+ dictionnaires) 
macros C + dictionnaire 
Descente r&#233;cursive 
</p>
<p>r&#232;gles 
proc&#233;dural 
proc&#233;dural 
</p>
<p>Systran 1990&#8212; 
 
</p>
<p>RBMT  
1985&#8212; 
 
</p>
<p>Segm.+ lemmatisation 
Analyse de 
d&#233;pendances 
D&#233;samb. interactive 
Transfert /g&#233;n&#233;ration 
</p>
<p>dictionnaire + tables 
LSPL pour les grammaires de 
d&#233;pendances + contraintes 
limit&#233;es (1 seul quantificateur) 
Descente r&#233;cursive 
</p>
<p>proc&#233;dural 
grammaire + dict. 
r&#232;gles 
contraintes 
proc&#233;dural + r&#232;gles 
</p>
<p>JETS (IBM-Japon, 
1985-90) </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Christian BOITET 
</p>
<p> 
</p>
<p>RBMT 
/SMT 
2000&#8212; 
 
</p>
<p>Segmentation et 
lemmatisation multiple 
Analyse de 
d&#233;pendances 
Tranfert/g&#233;n&#233;ration 
</p>
<p>Programmation  
en Pascal puis C  
+ dictionnaire 
Algorithme factorisant (DP) 
Descente r&#233;cursive 
</p>
<p>proc&#233;dural + r&#232;gles 
Version hybride  
(TA experte + SMT) 
depuis 2006 
+ statistiques 
</p>
<p>Neon (Xiamen)  
En-Ch &amp; Ch-En, 
2000&#8212; 
 
</p>
<p>Systran est tr&#232;s ancien (1966), mais depuis 1990 environ il int&#232;gre des FST pour les traitements 
morphologiques, et les macros utilis&#233;es pour la suite du traitement sont d&#233;velopp&#233;es en C et plus en 
assembleur. Dans JETS (anc&#234;tre de Honyaku no oo-sama, actuellement commercialis&#233; par IBM-
Japon), les d&#233;pendances sont les &#171; cas profonds &#187; correspondant aux particules casuelles du japonais. 
</p>
<p>2.5 Syst&#232;mes &#224; transfert horizontal de constituants 
Type Analyse/donn&#233;es Transfert/pr&#233;paration G&#233;n&#233;ration/m&#233;thode Exemples 
RBMT  
1995&#8212; 
 
</p>
<p>Lemmatisation + 
Slot Grammars 
r&#232;gles  
</p>
<p>Contient la g&#233;n&#233;ration 
Prolog 
proc&#233;dural + dict. 
</p>
<p>Descente r&#233;cursive  
grammaire+dict. 
r&#232;gles  
</p>
<p>PT (= LMT d'IBM) 
Linguatech, 1995&#8212;2000 
 
</p>
<p>EBMT  
2000&#8212; 
 
</p>
<p>Donn&#233;es initiales: 
corpus // bilingue 
dictionnaire 
</p>
<p>Pr&#233;paration: construction 
autom. de S-SSTCs puis  
&#233;dition (humaine) 
</p>
<p>Traduction: 3 &#233;tapes 
en parall&#232;le (A//T//G) 
combinaison ascendante 
</p>
<p>&#171; EBMT &#187; (ou &#8216;Banturjah&#8217;) 
UTMK, USM, 2000&#8212; 
bas&#233; sur un corpus de S-SSTC 
</p>
<p>PSMT 
PSCFG  
2002&#8212; 
</p>
<p>Lemmatisation 
Chunking 
statistique 
</p>
<p>Alignement 
D&#233;codage 
statistique 
</p>
<p>Aplatissement de l'arbre 
Post-traitement 
statistique 
</p>
<p>LanguageWeaver 2002&#8212; 
Google  2005&#8212; 
+Wu, Melamed 1997, 2004 
</p>
<p>La diff&#233;rence avec les syst&#232;mes pr&#233;c&#233;dents est que le transfert produit une structure de m&#234;me nature 
que ce que produirait l'analyse de l'unit&#233; de traduction cible. Cela permet &#233;ventuellement de composer 
deux syst&#232;mes de TA en perdant beaucoup moins d'information et en introduisant beaucoup moins 
d'erreurs qu'en mettant bout &#224; bout deux syst&#232;mes complets, i.e. en passant par un &#171; pivot textuel &#187;.  
</p>
<p>2.6 Syst&#232;mes &#224; transfert horizontal de d&#233;pendances 
Type Analyse Transfert G&#233;n&#233;ration Exemples 
RBMT  
1975&#8212; 
 
</p>
<p>Grammaire + dict. 
Anal. de d&#233;pendance 
r&#232;gles 
</p>
<p>Dictionnaires 
Transformations d'arbres 
r&#232;gles 
</p>
<p>Aplatissement de l'arbre 
grammaire+dict. 
r&#232;gles 
</p>
<p>ETAP-2, ETAP-3  
IPPI, Moscou, 1977&#8212; 
 
</p>
<p>RBMT  
1992&#8212; 
 
</p>
<p>Lemmatisation + 
patrons lin&#233;aires 
r&#232;gles  
</p>
<p>Dictionnaire de &#171; treelets &#187;  
+ thesaurus s&#233;mantique 
r&#232;gles  
</p>
<p>Aplatissement de l'arbre 
grammaire+dict. 
r&#232;gles  
</p>
<p>TDMT, Furuse (prototype 
pour la TA de parole)  
ATR, 1992&#8212;1998 
</p>
<p>RBMT+ 
SMT 
1999&#8212; 
</p>
<p>Analyseurs de MSR 
(Microsoft) 
r&#232;gles (en G) 
</p>
<p>Apprentissage du transfert 
&#224; partir de paires (lf_s, lf_t) 
statistique 
</p>
<p>G&#233;n&#233;rateurs de 
Microsoft  
r&#232;gles (en G) 
</p>
<p>MTS-1 
(prototype sur de la 
documentation technique) 
</p>
<p>LMT (MacCord, IBM), est rang&#233; ici car les &#171; slots &#187; correspondent &#224; des fonctions syntaxiques.  
</p>
<p>2.7 Syst&#232;mes &#224; transfert multiniveau horizontal 
Type &#201;tapes M&#233;thode Commentaires Exemples 
RBMT  
1990&#8212; 
 
</p>
<p>Lemmatisation 
Analyse multiple par ECFG 
(gouvernement &amp; liage) 
D&#233;sambigu&#239;sation interactive 
si pas assez de place 
Transfert autonome 
G&#233;n&#233;ration 
</p>
<p>Dictionnaire + tables 
Programmation en 
langage &#233;volu&#233; 
(Modula) 
-- 
-- 
descente r&#233;cursive 
</p>
<p>proc&#233;dural + dict. 
dict. + grammaire 
proc&#233;dural + r&#232;gles 
interactif 
proc&#233;dural + r&#232;gles  
   + dictionnaire 
aplatissement de l'arbre 
</p>
<p>ITS-2 (Gen&#232;ve, 1990&#8212;) 
 
</p>
<p>RBMT  
2000&#8212; 
 
</p>
<p>Lemmatisation + 
Slot Grammars 
Transfert autonome 
G&#233;n&#233;ration 
</p>
<p>LSPL grammatical, 
analyse multiple 
dictionnaire de treelets 
descente r&#233;cursive 
</p>
<p>proc&#233;dural + dict. 
dict. + gram. 
proc&#233;dural + r&#232;gles 
(en Prolog) 
</p>
<p>PT-2 (Linguatec et 
Lingenio) depuis 2000 
</p>
<p>Passer d'une architecture &#224; transfert descendant &#224; celle de transfert &#171; horizontal &#187; a &#233;t&#233; tr&#232;s difficile 
(communication personnelle de K. Eberle de Linguatec &#224; COLING-2000). Cela a &#233;t&#233; aussi tent&#233; sur 
METAL (par Siemens puis Sietech), mais sans succ&#232;s. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ind&#233;pendance des architectures linguistiques et computationnelles en traduction automatique 
</p>
<p>2.8 Syst&#232;mes &#224; transfert ascendant multiniveau  
Type &#201;tapes M&#233;thode Commentaires Exemples 
RBMT  
1978&#8212; 
 
</p>
<p>Analyse morphologique 
Analyse structurale 
Tansfert lexical  
Transfert structural 
G&#233;n&#233;ration structurale  
G&#233;n&#233;ration morphol. 
</p>
<p>dictionnaire + automate 
transformations d'arbres 
r&#232;gles de r&#233;&#233;criture 
dictionnaires 
transformations d'arbres 
dictionnaire + automate 
</p>
<p>LSPL (5 au total) 
r&#232;gles 
pour toutes les 
phases 
dictionnaires pour 
certaines phases 
</p>
<p>Syst&#232;mes en Ariane-G5 
1974- 
ru-de&#8594;ru, en&#8594;my-th 80-87 
fr&#8594;en (BV/aero) 85-92 
fr&#8594;en-de-ru (LIDIA) 90-96 
HICATS Hitachi (1990-)  
Jemah USM, NUS (1990-) 
</p>
<p>Ici, le transfert produit une structure multiniveau &#171; g&#233;n&#233;ratrice &#187; dans laquelle les informations non 
interlingues correspondent &#224; celles de la langue source de fa&#231;on &#171; contrastive &#187;, et sont &#224; utiliser par le 
g&#233;n&#233;rateur comme des pr&#233;f&#233;rences ou des ordres en fonction des valeurs de certains attributs 
&#171; tactiques &#187;. La premi&#232;re phase de l'&#233;tape de g&#233;n&#233;ration consiste alors &#224; &#171; s&#233;lectionner une 
paraphrase &#187; en recalculant les informations de surface. 
</p>
<p>2.9 Syst&#232;mes &#224; transfert s&#233;mantique ou &#171; conceptuel &#187; 
Type &#201;tapes M&#233;thode Commentaires Exemples 
RBMT  
1982&#8212; 
</p>
<p>Segm. +lemmatisation 
Autres phases 
</p>
<p>Programmation en C 
Transformations d'arbres 
</p>
<p>proc&#233;dural 
r&#232;gles (gram.s + dict) 
</p>
<p>MU (Kyodai, 82-87) 
MAJESTIC (JICST, 87&#8212;) 
</p>
<p>On pourrait ajouter les syst&#232;mes du CETA (1962-70), &#224; &#171; pivot hybride &#187;, d&#233;crit plus haut. 
</p>
<p>2.10 Syst&#232;mes &#224; interlingua s&#233;mantique ou &#171; linguistico-s&#233;mantique &#187; 
Il s'agit de syst&#232;mes utilisant un interlingua muni d'un vocabulaire &#171; autonome &#187;. 
Type Enconversion D&#233;conversion Commentaires  Exemples 
RBMT  
1980&#8212; 
 
</p>
<p>Lemmatisation directe 
Transformations cha&#238;ne-graphe  
r&#232;gles 
</p>
<p>Transformations 
graphe-cha&#238;ne 
r&#232;gles 
</p>
<p>proc&#233;dural 
+ 
r&#232;gles 
</p>
<p>ATLAS-II  
Fujitsu, 1980&#8212; 
PIVOT Nec, 1983&#8212; 
</p>
<p>RBMT  
1980&#8212; 
</p>
<p>Formalisme proche des DCG 
r&#232;gles 
</p>
<p>LSPL fond&#233; sur des 
r&#232;gles Prolog  
</p>
<p>r&#232;gles ULTRA NMSU, 89-95 
</p>
<p>RBMT 
1997&#8212; 
</p>
<p>Selon les partenaires 
r&#232;gles (jusqu'&#224; pr&#233;sent) 
</p>
<p>Selon les partenaires 
r&#232;gles 
</p>
<p>graphe UNL = structure 
&#171; anglo-s&#233;mantique &#187; 
</p>
<p>UNL 1996&#8212; 
</p>
<p>Les graphes UNL sont &#171; linguistico-s&#233;mantiques &#187;. Le vocabulaire (UW) est l'union des acceptions 
des diff&#233;rentes langues trait&#233;es, comme dans ULTRA, mais les relations s&#233;mantiques et le traitement 
des idiomes sont li&#233;s &#224; l'anglais (et tant mieux, car les langues voient assez souvent diff&#233;remment les 
relations s&#233;mantiques dans des &#233;nonc&#233;s synonymes).  
</p>
<p>2.11 Syst&#232;mes &#224; ontologie 
Ces syst&#232;mes sont les seuls &#224; faire de la &#171; compr&#233;hension explicite &#187;, leur interlingua &#233;tant &#171; projet&#233; &#187; 
dans une ontologie &#937;, soit de fa&#231;on s&#233;par&#233;e, soit de fa&#231;on interne. 
Type Enconversion Projection dans une &#937; D&#233;conversion Examples 
KBMT  
1980&#8212; 
 
</p>
<p>Lemmatisation &amp; 
EPSG+f-structures 
+pseudo-unification 
R&#232;gles (Univ. Parser) 
</p>
<p>Oui, de tout sauf les 
&#233;l&#233;ments de discours 
dict. + r&#232;gles 
+ d&#233;samb. interactive  
</p>
<p>Planification de la 
structure profonde  
Descente r&#233;cursive 
r&#232;gles 
</p>
<p>KBMT-89 CMU, 1989&#8212;91 
KANT/Catalyst 
CMU+Caterpillar,  
en&#8594;fr-sp-de-? 1992&#8212; 
</p>
<p>RBMT  
1997&#8212; 
</p>
<p>Dictionnaire + FST 
r&#232;gles 
</p>
<p>Pas d'ontologie 
explicite s&#233;par&#233;e : 
</p>
<p>dictionnaire + FST 
r&#232;gles 
</p>
<p>CSTAR-II &amp; Nespole!  
GETA 97-03, ETRI (Cor&#233;e) 97-99 
</p>
<p>SMT 
2003&#8212; 
 
</p>
<p>Appris &#224; partir de 
couples (cha&#238;ne,IF)  
statistique 
</p>
<p>c'est l'id&#233;e (ancienne) 
des &#171; grammaires 
s&#233;mantiques &#187; 
</p>
<p>Appris &#224; partir de 
couples (IF,cha&#238;ne)  
statistique 
</p>
<p>CSTAR-II &amp; Nespole!  
Irst 98-03 
Mastor-1 (IBM 2003), sur PDA 
</p>
<p>L'IF (interface format) r&#233;f&#232;re &#224; une ontologie implicite, pas explicite.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Christian BOITET 
</p>
<p> 
</p>
<p>3 &#201;l&#233;ments pour le choix d'architectures en TA 
</p>
<p>3.1 Taille et co&#251;t des ressources / architectures computationnelles 
Le tableau suivant donne une estimation des ressources n&#233;cessaires pour construire un syst&#232;me de TA 
en fonction de la difficult&#233; de la t&#226;che, grossi&#232;rement estim&#233;e &#224; partir de la taille moyenne des phrases. 
Les co&#251;ts sont donn&#233;s ici en homme*ann&#233;e (h*a), M veut dire &#171; million &#187;, et K &#171; mille &#187;. 
&#8226; Pour la TA empirique, il s'agit de la taille du corpus, en mots, pages (de 250 mots), phrases, et du 
</p>
<p>temps humain de pr&#233;paration de ce corpus. S&#8217;il s&#8217;agit de traduction, nous utilisons le taux 
professionnel de 1h/page (avec la r&#233;vision, ce serait 1h20 par page). S&#8217;il s&#8217;agit d&#8217;annotation, les 
co&#251;ts ne sont la plupart du temps pas publi&#233;s, et nous utilisons des informations dont nous 
disposons par communications personnelles. Le co&#251;t par page est bien plus &#233;lev&#233;, mais le corpus 
peut &#234;tre beaucoup plus petit, et finalement bien moins co&#251;teux, pour de meilleurs r&#233;sultats. 
</p>
<p>&#8226; Pour la TA experte, il s'agit de la taille des dictionnaires et des grammaires, et du travail d'experts 
humains. Contrairement &#224; ce qu&#8217;on lit dans de nombreux cours sur la TA qu&#8217;on peut glaner sur le 
Web, ce co&#251;t est souvent tr&#232;s sur&#233;valu&#233;, et pas seulement par les tenants des m&#233;thodes empiriques.  
</p>
<p>Phrases 
Type 
</p>
<p>6.5 mots/phrase 
BTEC, METEO 
</p>
<p>25 mots/phrase 
Informations (news)  
</p>
<p>SMT 
PSMT 
EBMT par analogie  
</p>
<p>Co&#251;t : 
</p>
<p>0.9&#8212;3 M mots 
3.6&#8212;12 K pages 
0.15&#8212;0.5 M phrases 
2.4&#8212;8 h*a 
</p>
<p>50&#8212;200 M mots 
200&#8212;800 K pages 
2&#8212;8 M phrases 
100&#8212;400 h*a (rarement disponible !) 
</p>
<p>EBMT avec arbres 
SMT 
Mastor-1 (IBM)  
</p>
<p>Co&#251;t : 
</p>
<p>N/A pour ce type de phrases courtes 
Apprentissage supervis&#233; 
1h/page (par recoupements) 
</p>
<p>4&#8212;12.5 M mots  
15&#8212;50 K pages 
0.15&#8212;0.5 M phrases 
10&#8212;40 h*a 
</p>
<p>EBMT avec arbres et S-SSTCs 
Banturjah (USM)  
</p>
<p>Co&#251;t : 
</p>
<p>N/A pour phrases courtes  
Apprentissage supervis&#233; 
15 h/page (10 h/p esp&#233;r&#233;) 
dictionnaire (50 K) souvent disponible 
</p>
<p>4&#8212;12.5 M mots  
0.6&#8212;1 K pages 
0.006&#8212;0.01 M phrases 
6&#8212;10 h*a (travail assez sp&#233;cialis&#233;) 
</p>
<p>RBMT 
 
</p>
<p>Co&#251;t : 
</p>
<p>Dictionnaire 3-10 K 0.6&#8212;2 h*a  
 
Total 1&#8212;3 h*a 
</p>
<p>Dict. 50-500 K, soit  15&#8212;150 h*a  
Grammaires environ  25 h*a 
Total &#8776; 40&#8212;175 h*a 
</p>
<p>3.2 Br&#232;ve analyse 
1. Il est clair que, plus les corpus sont &#171; bruts &#187;, plus ils doivent &#234;tre grands. M&#234;me &#224; raison de 
</p>
<p>15h/page de travail humain, il semble int&#233;ressant d'utiliser une m&#233;thode comme celle de l'USM &#224; 
Penang, car on n'a besoin que de 1000 pages et d'un gros dictionnaire assez simple. 
</p>
<p>2. D'autre part, la SMT (et la PSMT) sont en fait adapt&#233;es &#224; des &#171; niches de riches &#187;, tout comme la 
TA &#171; experte &#187; pour sous-langages. En effet, il y a tr&#232;s peu de corpus parall&#232;les disponibles de 200 
&#224; 800 K pages ! Du point de vue des corpus, les diff&#233;rences entre couples de langues &#171; bien 
dot&#233;s &#187; et &#171; mal dot&#233;s &#187; sont encore plus grandes qu'en ce qui concerne les dictionnaires. 
</p>
<p>3. Cr&#233;er de tr&#232;s gros corpus parall&#232;les &#224; partir de z&#233;ro est 2 &#224; 3 fois plus co&#251;teux que de construire un 
grand syst&#232;me de TA par approche experte (proc&#233;durale et/ou &#224; automates et grammaires). 
</p>
<p>4. L'architecture linguistique par &#171; pivot interlingue &#187; peut utiliser n'importe quel paradigme 
computationnel, qu'il soit statistique, analogique, &#224; r&#232;gles, ou hybride. 
</p>
<p>5. En dernier ressort, le choix de l'architecture linguistique et de l'architecture computationnelle 
d&#233;pend des ressources disponibles en termes de corpus pr&#233;alablement traduits, et d'humains plus 
ou moins experts. Les types d'expertise recherch&#233;e sont, par ordre de difficult&#233; croissante (estim&#233;e 
via le temps de formation et la relative raret&#233; des experts) : la traduction, la post-&#233;dition, la 
correction d'annotations, l'annotation &#224; partir de rien, la terminologie, la lexicographie complexe </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ind&#233;pendance des architectures linguistiques et computationnelles en traduction automatique 
</p>
<p>(vocabulaire g&#233;n&#233;ral et tournures), l'&#233;criture de grammaires assez d&#233;claratives, la programmation 
par automates dans des LSPL adapt&#233;s, et enfin la programmation directe.  
</p>
<p>Conclusion 
Nous avons donc montr&#233; que les architectures linguistiques et computationnelles des syst&#232;mes de 
traduction automatique sont ind&#233;pendantes, au sens o&#249; on peut utiliser n'importe quelle architecture 
computationnelle pour r&#233;aliser n'importe quelle phase de traitement dans une architecture linguistique 
donn&#233;e, non seulement en th&#233;orie, mais en pratique, comme l'illustre la vari&#233;t&#233; des syst&#232;mes cit&#233;s en 
exemple. Nous avons aussi donn&#233; une &#233;valuation des tailles et des co&#251;ts de construction des ressources 
utilis&#233;es par diff&#233;rents types de syst&#232;mes de TA, ce qui donne quelques &#233;l&#233;ments pour le choix de 
l'architecture linguistique et computationnelle d'un syst&#232;me &#224; cr&#233;er, en fonction des situations 
traductionnelles et des ressources disponibles, en termes de dictionnaires, de corpus, et de 
comp&#233;tences humaines. 
Cette r&#233;flexion ouvre sur une perspective plus g&#233;n&#233;rale et &#171; soci&#233;tale &#187;. Si l'on veut surmonter la 
&#171; barri&#232;re linguistique &#187; entre toutes les langues, on ne pourra pas se contenter de construire des 
syst&#232;mes de TA entre l'anglais et les autres langues, m&#234;me pas pour le tchat entre deux langues 
diff&#233;rentes de l'anglais. En effet, l'anglais interm&#233;diaire serait n&#233;cessairement trop &#171; grossier &#187;, entach&#233; 
d'erreurs, et porteur d'ambigu&#239;t&#233;s nouvelles en sus des anciennes (celles de la langue source). La 
plupart des locuteurs (ou simplement lecteurs &#171; passifs &#187;) seront de plus toujours bien moins 
comp&#233;tents et &#224; l'aise en anglais que dans leur langue.  
Il faudra donc construire des syst&#232;mes fond&#233;s sur des interlingues, soit &#171; s&#233;mantico-pragmatiques &#187; 
(comme l'IF de CSTAR, Nespole! ou MASTOR-1) s'il s'agit de t&#226;ches et de domaines restreints et 
bien identifi&#233;s, soit &#171; linguistico-s&#233;mantiques &#187; (comme UNL). Cela sera d'autant plus n&#233;cessaire 
qu'on voudra int&#233;grer ces syst&#232;mes au &#171; Web s&#233;mantique &#187;, car il faudra alors demander aux 
internautes d'aider les syst&#232;mes d'annotation, sans doute par le m&#234;me type de &#171; d&#233;sambigu&#239;sation 
interactive &#187; que celui qui permet de compenser la n&#233;cessaire &#171; rusticit&#233; &#187; (ou la &#171; mauvaise qualit&#233; 
intrins&#232;que &#187;) des syst&#232;mes de TA &#171; tout terrain &#187; quand on veut les utiliser en &#171; tout automatique &#187;. 
Il ressort de ce qui pr&#233;c&#232;de qu'il devrait &#234;tre possible de construire des syst&#232;mes de TA entre toutes les 
langues, passant par un niveau s&#233;mantique comme UNL, non seulement par des approches 
&#171; expertes &#187; comme c'est le cas actuellement, mais par des approches empiriques moins co&#251;teuses et 
moins longues en d&#233;veloppement, si toutefois on disposait de corpus ad&#233;quats de taille suffisante. 
D'autre part, &#224; la lumi&#232;re des d&#233;veloppements r&#233;cents en alignement et en TA statistique, de tels 
corpus devraient pouvoir &#234;tre construits par &#171; transitivit&#233; &#187;, en alignant des corpus parall&#232;les et des 
corpus annot&#233;s en IL (en UNL par exemple) s'ils ont au moins une langue en commun.  
</p>
<p>R&#233;f&#233;rences  
BOITET C. (1986) The French National MT-Project: technical organization and translation results of 
CALLIOPE-AERO. Computers and Translation, 1, pp. 281&#8212;309.  
BOITET C. (1988) L'apport de Bernard Vauquois &#224; la traduction automatique et au traitement 
automatique des langues naturelles. Proc. Colloque sur l'Histoire de l'Informatique en France., 3-5 
mai 1988, P. Ch&#226;telin, ed., vol. 2/2, pp. 63&#8212;82.  
BOITET C. (1988) PROs and CONs of the pivot and transfer approaches in multilingual Machine 
Translation. Proc. Int. Conf. on &#171; New directions in Machine Translation &#187;, 18&#8211;19 August 1988, BSO, 
ed., Foris Publications, pp. 93&#8212;108.  
BOITET C. (1988) Representation and  Computation of Units of Translation for Machine Interpretation 
of Spoken Texts. Computers and Artificial Intelligence, 8/6, pp. 505&#8212;546.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Christian BOITET 
</p>
<p> 
</p>
<p>BOITET C. (1993) La TAO comme technologie scientifique : le cas de la TA fond&#233;e sur le dialogue. In 
La traductique, A. Clas et  P. Bouillon, ed., Presses de l'Universit&#233; de Montr&#233;al, pp. 109&#8212;148.  
BOITET C. (1993) TA et TAO &#224; Grenoble&#8230; 32 ans d&#233;j&#224; ! T.A.L. (revue semestrielle de l'ATALA), 
33/1&#8212;2, Sp&#233;cial Trentenaire, pp. 45&#8212;84.  
BOITET C. (1995) Factors for success (and failure) in Machine Translation &#8212; some lessons of the first 
50 years of R&amp;D. Proc. MTS-V (Fifth Machine Translation Summit), 11&#8212;13 July 1995, CEE, 17 p.  
BOITET C. (2001) Machine Translation. In Encyclopedia of Cognitive Science, Nature Publishing 
Group, London, (in manuscript form) 24 p.  
BOITET C. ET BLANCHON H. (1994) Promesses et probl&#232;mes de la &#171; TAO pour tous &#187; apr&#232;s LIDIA-
1, une premi&#232;re maquette. Langages, 116, pp. 20&#8212;47.  
BOITET C., BOGUSLAVSKIJ I. ET CARDE&#209;OSA I. (2007) An Evaluation of UNL Usability for High 
Quality Multilingualization and Projections for a Future UNL++ Language. In Computational 
Linguistics and Intelligent Text Processing (Proc. CICLING-2007), A. Gelbukh, ed., Springer (LNCS 
4394), pp. 361-373. (ISBN-10: 3-540-70938-X Springer, ISSN: 0302-9743)  
BOITET C., ed. (1988) BERNARD VAUQUOIS et la TAO, vingt-cinq ans de Traduction 
Automatique, ANALECTES. BERNARD VAUQUOIS and MT, twenty-five years of MT. Ass. 
Champollion &amp; GETA, Grenoble, 700 p. 
BOITET C. ET GERBER R. (1986) Expert Systems and other new techniques in MT. In Neue Ans&#228;tze 
in maschineller Sprach&#252;bersetzung, Niemeyer, T&#252;bingen, pp. 103&#8212;119.  
EISELE A. (2005) Exploiting Multilingual Corpora for Machine Translation. (JRC Enlargement and 
Integration Workshop on Exploiting parallel corpora in up to 20 languages), Arona, Saarland 
University &amp; DFKI, (slides) 
HUTCHINS W. J. (1986) Machine Translation : Past, Present, Future. Ellis Horwood, John Wiley &amp; 
Sons, Chichester, England, 382 p.  
HUTCHINS W. J. ET SOMERS H. L. (1992) An Introduction to Machine Translation. H. B. 
Jovanovich, ed., Academic Press, 362 p.  
HUTCHINS J., HARTMAN W. ET HITO E. (2005) Compendium of Translation Software (directory of 
machine translation systems and computer-aided translation support tools. EAMT, TIM/ISSCO, 
Geneva, 127 p. (Earlier editions of the Compendium are available as PDF files from: 
http://ourworld.compuserve.com/homepages/WJHutchins/compendium.htm)  
JEIDA (1989) A Japanese view of Machine Translation in light of the considerations and 
recommendations reported by ALPAC, USA. Japanese Electronic Industry Development Association.  
KRAIF O. (2006) Corpus multilingues &#8212; multilingual corpora. 22/11/06.   
http://w3.u-grenoble3.fr/kraif/index.php?option=com_content&amp;task=view&amp;id=20&amp;Itemid=36 
LEPAGE Y. ET DENOUAL E. (2005) Purest ever example-based machine translation: detailed 
presentation and assessment. Machine Translation Journal, 19, pp. 251&#8212;282.  
S&#201;NELLART J., BOITET C. ET ROMARY L. (2003) XML Machine Translation. Proc. MTS-IX 
(Machine Translation Summit), New-Orleans, 9 p.  
THURMAIR G. (2006) Using corpus information to improve MT quality. Proc. LR4Trans-III (3rd 
International Workshop on Language Resources for Translation Work, Research &amp; Training), LREC 
2006, Genoa, ELRA / ELDA, 4 p.  
UCHIDA H. (2004) The Universal Networking Language (UNL) Specifications Version 3 Edition 3. 
UNL Center, UNDL Foundation, December 2004.   
http://www.undl.org/unlsys/unl/UNLSpecs33.pdf 
VAUQUOIS B. ET BOITET C. (1985) Automated translation at Grenoble University. Computational 
Linguistics, 11/1, January-March 85, pp. 28&#8212;36.  </p>

</div></div>
</body></html>