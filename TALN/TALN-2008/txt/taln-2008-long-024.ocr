TALN 2008, Avignon, 9-13 juin 2008

Les architectures linguistiques et computationnelles
en traduction automatique sont indépendantes

Christian BOITET

Laboratoire LIG, GETALP — Universite Joseph Fourier,
385 rue de la bibliotheque, BP 53, 38041 Grenoble, Cedex 9, France
Christian.Boitet@imag.fr

Resume Contrairement a une idee repandue, les architectures linguistiques et computationnelles des
systemes de traduction automatique sont independantes. Les premieres concernent le choix des
representations intermediaires, les secondes le type d'algorithme, de programmation et de ressources
utilises. Il est ainsi possible d'utiliser des methodes de calcul «expertes >> ou << empiriques >> pour
construire diverses phases ou modules de systemes d'architectures linguistiques variees. Nous
terminons en donnant quelques elements pour le choix de ces architectures en fonction des situations
traductionnelles et des ressources disponibles, en termes de dictionnaires, de corpus, et de
competences humaines.

Abstract Contrary to a wide—spread idea, the linguistic and computational architectures of MT
systems are independent. The former concern the choice of the intermediate representations, the latter
the type of algorithm, programming, and resources used. It is thus possible to use "expert" or
"empirical" computational methods to build various phases or modules of systems having various
linguistic architectures. We finish by giving some elements for choosing these architectures
depending on the translational situations and the available resources, in terms of dictionaries, corpora,
and human competences.

Mots-clés: Traduction Automatique, TA, TAO, architecture linguistique, architecture
computationnelle, TA experte, TA par regles, TA empirique, TA statistique, TA par l'exemple

Keywords: Machine Translation, MT, linguistic architecture, computational architecture, expert MT,
rule—based MT, empirical MT, statistical MT, example—based MT.

Introduction

11 y a un certain nombre d'idees fausses qui circulent parmi les chercheurs en TA, et freinent a notre
avis les progres dans ce domaine. La premiere est que la plupart des systemes operationnels utilisent la
TA statistique, alors que la plupart (voir le Compendium (Hutchins & al. 2005) publie par l'EAMT)
utilisent des methodes << expertes >> (<< a regles >>, mais pas seulement a regles). L'autre est que les
systemes utilisant un << pivot interlingue >>, evidemment tres adapte a la communication multilingue,
sont necessairement << 51 regles >> (TAFR, en anglais RBMT ou << rule—based MT >>), et donc tres
coﬁteux a construire (ce << donc >> est faux aussi. . . ).

Il ne faut pas faire l'amal game entre l'architecture linguistique d'un systeme de TA, caracterisee par les
representations intermediaires qu'il utilise durant le processus de traduction, et son architecture
computationnelle, caracterisee par les methodes de calcul et les ressources utilisees dans ses diverses
<< phases » transformant une representation intermediaire en sa suivante dans le processus.

Christian BOITET

Apres une breve partie consacree aux definitions des Variantes de ces architectures, nous montrerons
que, pour a peu pres chaque architecture linguistique, on trouVe des systemes utilisant diverses
architectures computationnelles. De plus, une bonne partie des systemes utilisent plusieurs
architectures computationnelles dans leurs differentes phases. Nous essaierons enfin de degager
quelques indications sur les choix d'architecture appropries aux diverses situations traductionnelles et

des ressources disponibles, en termes de dictionnaires, de corpus, et de competences humaines.

1 Architectures des systémes de TA

1.1 Architectures linguistiques

Ces architectures correspondent aux « chemins » dans le fameux « triangle de Vauquois ».

  
   
    
 
 
 
 
 
 
  

Deep understanding level Onlolngical inle rlingua

lmerlingual level

Semanlim-linguistic interlingua

SPA-structures (semantic

Log’-“"”"m"ﬁ" I9“! & predicate-argument)

Mixing lewls Multilevel description

Symnetieo-funcrimal level F-structures {functional}

Synmgmaric level

C-structures (constituent)

Morphaasyntaelicleve  1, L ,  v ,,  ' Taggedtexl

Graplaemic level Text

Figure I .' triangle de Vauquois (Vauquois & Boiler Z985, Arialecies de Vauquois — Boiler 1988)

Les systemes directs n'utilisent que deux representations, le texte d'entree et le texte de sortie. Pour les
langues ayant des systemes d'ecriture a separateurs de mots ou de syllabes, le texte d'entree n'est
souVent pas strictement le ﬂot de caracteres tel quel, mais une suite de « mots typographiques »
separes grace a des regles simples. Les systemes semi—direcls ont une phase de segmentation ou
d'analyse morphologique, Voire morphosyntaxique, et une phase de generation morphologique. C'est le
cas des systemes de « premiere generation » (russe—anglais aux USA et anglais—russe en URSS des les
annees 1950), et un certain nombre de systemes commerciaux actuels sont toujours de ce type.

11 existe au moins 7 Variantes des systemes a lrarisferl. La structure obtenue en fin d'analyse peut étre
syntagmatique (basee sur des constituants la plupart du temps connexes), ou bien dependancielle, et
dans ce cas surfacique (fonctions syntaxiques comme sujet, objet direct, epithete, attribut. . .) ou
profonde (relations semantiques comme agent, patient, cause, concession. . . ). Les systemes a lrarisferl
proforid fondes sur les theories de Tesniere, puis de l'Ecole de Prague et de celle de Moscou, utilisent
des representations logico—semantiques distinguant les arguments des circonstants.1

1 Les circonstants portent des relations semantiques (cas profonds), tandis que les arguments ne portent en
general qu'un numero (Arg0, Argl... Arg4 ou Arg5 au maximum), car il est tres difficile sinon impossible
d'affecter fiablement une relation semantique a un argument, si le repertoire de ces relations est celui utilise
pour les circonstants. Le projet FrameNet montre d'ailleurs bien que, si on Veut definir des relations

Indépendance des architectures linguistiques et computationnelles en traduction automatique

On dit qu'il y a << transfert lexical >> quand on passe directement de << l'espace lexical >> de la langue
source a celui de la langue cible. Par << espace lexical >>, on entend tout le systeme lexical, qui Va des
<< formes >> de surface aux << acceptions >>, en passant par les lemmes et éventuellement par les << unites
lexicales >> (familles dérivationnelles) ou << prolexemes >> (les memes, un peu élargies).

Le << pivot hybride >> (terme dﬁ a Shaumyan) des systemes du CETA des années 1965-70 était un type
de representation utilisant des attributs et relations interlingues, et des unites lexicales de chacune des
langues. Ces systemes étaient donc a transfert simple, alors qu'on a un double transfert en << pivot >>.

Les structures multiniveau de Vauquois sont basées sur un graphe syntagmatique abstrait (suppression
des auxiliaires, regroupement de lexemes discontinus comme giVe...up, etc.), lexicalisé (chaque nceud
interne domine un << gouverneur » lexical), et contenant aussi bien les informations et relations
profondes que celles de surface. De telles structures sont << génératrices >> des structures mononiveau
usuelles, et offrent une sorte de << filet de sécurite’ >>.

Les systemes a veritable interlingua (comme ATLAS—II de Fujitsu ou PIVOT/Crossroads de NEC, ou
KANT/CATALYST de CMU/Caterpillar, ou UNL, ou MASTOR—1 d'IBM, ce dernier en TA de
parole) utilisent 3 espaces lexicaux, car un veritable interlingua possede son propre Vocabulaire, meme
si ce Vocabulaire est construit comme union des acceptionsz d'un certain nombre de langues, comme
UNL (Uchida 1996, 2004). Dans les systemes de TA, il existe des interlinguas << linguistico—
sémantiques >> (comme KANT, ULTRA, UNL) dont les << lexemes >> sont construits a partir des
lemmes et des lexies de dictionnaires d'une ou plusieurs langues naturelles, et des interlinguas
<< sémantiques >> ou << sémantico—pragmatiques >>, dont les lexemes sont construits a partir des entités,
propriétés, actions et processus d'un domaine précis et d'un ensemble de taches bien identifiées (par
exemple, reservation touristique).

Enfin, si la plupart des systemes de TA ont comme << unite de traduction >> le << segment >> (phrase ou
titre) des systemes d'aide au traducteur utilisant des mémoires de traductions, certains ont des unites de
traduction de l'ordre de la page (Ariane—G5), ce qui permet de mieux traiter certains phénomenes
comme la concordance des temps et de résoudre des anaphores hors du contexte de la phrase.

1.2 Architectures computationnelles

Pour ce qui est des processus automatiques, on distingue er1tre méthodes expertes et méthodes
empiriques. 11 y a aussi des distinctions a faire si le processus de traduction est interactif.

1 .2.1 Méthodes « expertes »

Les méthodes << expertes » sont plus ou moins procédurales ou déclaratives, et font appel a de la
programmation directe ou fondée sur des << modeles de calcul » abstraits, d'o1‘1 l'utilisation de LSPL
(langages specialises pour a programmation linguistique). On a en bref :

° la programmation directe dans un langage algorithmique classique (souvent employee au niveau
des traitements typographiques ou morphologiques).

° la programmation directe dans un langage de haut ou tres haut niveau (Lisp, Prolog) offrant des
structures de données et de controle plus adaptées a la programmation linguistique, mais
demandant une grande expertise en programmation.

° la programmation dans des LSPL d'automates (comme les transducteurs finis, les ATN ou les
transformateurs d'arbres, abusivement dits << grammaires >> transformationnelles).

° la programmation dans des formalismes de grammaires déclaratives (ou presque) comme LFG,
GPSG, HPSG, ou TAG.

sémantiques po11r les arguments, il faut le plus souvent les lexicaliser ("donner" aura alors "donateur/donneur"
pour ArgO, "don" pour Argl, "donataire" po11r Arg2).

2 Une "acception" est un sens d'un mot, au sens de lemme ou terme, dans l‘usage de la langue. Une "lexie" est un
sens de mot dans un dictionnaire.

Christian BOITET

Il est abusif de parler de systemes << a regles >> pour les deux premiers. Ainsi, Systran utilise des
automates (transducteurs d'états finis) pour l'analyse morphologique, tandis que l'analyse syntaxique
n'est pas faite par << regles >>, mais par un programme instanciant un schema procedural fixe (écriture
de << macros >> determinant des décisions locales par examen d'une << fenétre courante >> sur un graphe
sans boucle représentant la phrase).

1 .2.2 Méthodes empiriques

Ce sont les méthodes fondées sur les corpus :

° TA statistique (SMT) et TA statistique a syntagmes (PSMT, ou << phrase—based >> SMT),
° TA fondée sur les exemples (EBMT), avec 3 Variantes.

Notons que << TA statistique >> est un assez mauvais terme, car on devrait plutot parler de TA
<< probabiliste >>. En effet, un << modele de langage » est une collection de probabilités estimées d'apres
des comptages sur de gros ou tres gros corpus.

La difference essentielle entre SMT et EBMT est que, en EBMT, les exemples sont utilises
directement durant le processus de traduction, tandis que la SMT utilise les résultats d'une sorte de
gigantesque << compilation » de l'ensemble des exemples (corpus aligné).

Les Variantes de l'EBMT sont les suivantes :

° En EBMT classique, on étend les techniques de recherche de segments Voisins des systemes d'aide
aux traducteurs avec mémoire de traductions, et on propose, pour les mots différenciant le
segment a traduire et le segment trouve, des remplacements Venant d'autres exemples ou de
dictionnaires. Le systeme SimilisTM (derive de (Planas 1998)) d’aide au traducteur en est proche.

° En EBMT par cmalogie (Lepage & Denoual 2005), si S1 est le segment a traduire (en langue L1),
on cherche les << rectangles analogiques >> P1:Q1 : :Rl :s1 tels qu'on dispose des exemples de
traduction (P1 ,P2) , (Q1 ,Q2) , (R1 ,R2) , et on résout en x (dans la langue L2) l'équation
analogique P2 :Q2 : :R2 :x. On obtient en general plusieurs traductions x, qu'on filtre pour la fluidité
par un modele n— gramme. Si on ne trouve pas de tel rectangle, on résout en Y (dans la langue L1)
l'équation Pl :Q1: :Y:Sl et on continue récursivement. Il n'y a donc pas de << decomposition en
morceaux qui se correspondent >> puis de << recomposition >>.

° Dans le systeme EBMT par exemples de correspondances structurées de Al—Adhaileh et Tang
(USM, Penang), on utilise un corpus parallele annoté par des S—SSTC (correspondances chai‘ne—
arbre structurées synchronisées). La traduction se fait par analyse—synthese. Une correspondance
(Cl, A1)—c—(C2, A2) est élémentaire ou composée (: {(Cli, A1l.)—c1.—(C21., A21.) }i).
Quand on en trouve une car on a identifié un morceau C1 du segment S1 a traduire, ou bien les
correspondances la constituant, on a d'un seul coup les 3 autres elements et leur synchronisation.

2 Variété des architectures computationnelles

Voici maintenant une etude synthétique (non exhaustive) des architectures computationnelles utilisées
dans des systemes de TA basés sur 11 architectures linguistiques différentes. Pour la clarté, nous
utilisons des tableaux, organises de la facon la plus homogene possible. 11 n’a malheureusement pas
été possible de suivre la suggestion d’un relecteur, et de faire un seul grand tableau croisant les deux
architectures, car trop de systemes utilisent différentes architectures computationnelles dans
différentes phases du traitement. Pour des raisons de place, il n’a pas non plus été possible de mettre
autant de references qu’on l’aurait souhaité. D’un autre cote, les references sur les systemes
opérationnels (commerciaux comme Systran, ATLAS, The Translator, Honyaku—no—oo—sama, ProMT,
Softissimo, Tracy, PIVOT/Crossroads, ALTFlash, METAL/Compendium, LanguageWeaVer, etc., et
non commerciaux ou semi—commerciaux comme PAHO—MTS, ALT/JE ou Google Translator) sont
tres rares et souvent anciennes. Le << Compendium >> (Hutchins & al. 2005) est une source importante,
mais ne donne pas de details précis sur la facon dont les systemes cites sont construits.

Indépendance des architectures linguistiques et computatiormelles en traduction automatique

2.1 Systémes de traduction directe

Type Etapes Methode Commentaires Exemples
RBMT Segmentation FST (regles + dict.) Convient pour des langues tres voisines ATLAS-I Fujitsu,76-78
1975—Trad. mot a mot regles japonais <—> coreen, hindi <—> urdu  (coreen<—>japonais)
SMT Segmentation, Alignement + SMT = premiere idee sur la TA par les Beaucoup de systemes
1980—rearrangement... << decodage » cryptographes de la 2° guerre mondiale statistiques (SMT)
statistique (W. Weaver 1949) IBM 1980-
EBMT Pas de Resolution analogique Resultats z ceux de la SMT ALEPH
2000—pretraitement + filtrage n-grammes Nagao 1984 (plutot TA par sin1ilarite) ATR 2000-
EBMT << pure » analogique Lepage 2000 (vraie analogie a 4 termes) GREYT, Caen 2006—

Le plus souvent, ces systemes sont << empiriques >>, mais certains utilisent une approche << experte >>,
comme ATLAS-I (different de ATLAS—II).

2.2 Systémes de traduction semi-directe

Type Etapes Methode Commentaires Exemples
1G-MT Segmentation & Consultation de Tables + macros sur GAT (Georgetown)
1950— Lemmatisation par dictionnaire + "macros" des chaines EURATOM, Ispra, l965—69
programme de rearrangement procédural SPANAM-1, PAHO, z1975—
procédural GLOBALINK <— Spanam-1 (PAHO)
SMT Lemmatisation rocédural + regles Modele de langue Candide IBM, 1980—, Google 2005-
1990— Decodage statistique probabiliste Beaucoup de systemes statistiques
Trad. Lemmatisation Traitement de chaines procédural (snobol4) Idee de B. Harris
pidgin Transfert lexical regles en systemes-Q Enonce = (TAUM, << traductologiste »)
Rearrangement -- graphe de chaines rus —> eng, fre (Boitet 1972)
Generation -- d'arbres etiquetes

GlobaLink a ete fait a partir d'une copie de Spanam-1. Spanam—2 est de type expert (ATN).
Les systemes actuels de Google sont (sans doute) plus PSMT (phrase—based SMT) que SMT.

2.3 Systémes a transfert descendant de constituants

Type Etapes Methode Commentaires Exemples
RBMT Analyse par ATN LSPL etendant Lisp ou regles + dict. + ENGSPAN, SPANAM-2, ou
1970— un autre Lprog transformation ‘PAHO-MTS’ (PAHO, z1978—)
Transfert/generation Descente recursive procédural + regles AS-Transac (Toshiba, 1982—)
Reverso ProMT, 1986—
RBMT Analyse par ECFG LSPL etendant Lisp ou gran1rnaire+dict. METAL (TUA+Siemens, 1982—)
1980— (hors-contexte un autre Lprog regles Duet-2 (Sharp, 1984—)
etendu) Shalt-1 (IBM-Japon, 1982—)
Transfert /generationIDescente recursive procédural + regles Kate KDD (1983—)
RBMT Lemmatisation Dictionnaire +tables procédural LMT (IBM-US, 1983—)
1984— Slot-gran1mars LSPL etendant Prolog regles PT-1 (Personal Tanslator) de
T+G en Prolog Descente recursive procédural + regles Linguatec, derive de LMT, —2000

Les systemes recents de type PSMT de LanguageWeaVer sont sans doute aussi de ce type.

2.4 Systémes a transfert descendant de dépendances

Type Etapes Methode Commentaires Exemples
1.5G-MT Lemmatisation FST (+ dictionnaires) regles Systran 1990—
1990— Analyse produisant un macros C + dictionnaire procédural
graphe de dependances Descente recursive procédural
Transfert / generation
RBMT Segm.+ len1matisation dictionnaire + tables procédural JETS (IBM-Japon,
1985— Analyse de LSPL pour les grammaires de grammaire + dict. 1985-90)
dependances dependances + contraintes regles
Desamb. interactive limitees (1 seul quantificateur) contraintes
Transfert /generation Descente recursive rocédural + regles

Christian BOITET

RBMT Segmentation et Programmation procédural + régles Neon (Xiamen)
SMT lemmatisation multiple en Pascal puis C Version hybride En-Ch & Ch-En,
2000— Analyse de + dictionnaire (TA experte + SMT) 2000—
dépendances Algorithme factorisant (DP) depuis 2006
Tranfert/generation Descente recursive + statistiques

Systran est tres ancien (1966), mais depuis 1990 environ il integre des FST pour les traitements
morphologiques, et les macros utilisées pour la suite du traitement sont développées en C et plus en
assembleur. Dans JETS (ancétre de Honyaku no oo—sama, actuellement commercialise par IBM-
Japon), les dépendances sont les << cas profonds » correspondant aux particules casuelles du japonais.

2.5 Systémes a transfert horizontal de constituants

Type Analyse/donnees Transfert/preparation Generation/methode Exemples

RBMT Len1rnatisation + Contient la generation Descente recursive PT (= LMT d'IBM)

l995— Slot Grammars Prolog gran1rnaire+dict. Linguatech, 1995—2000
régles rocédural + dict. régles

EBMT Donnees initiales: Preparation: construction Traduction: 3 etapes << EBMT » (ou ‘Banturjah’)

2000— corpus // bilingue autom. de S-SSTCs puis en parallele (A//T//G) UT'lV[K, USM, 2000—
dictionnaire edition (humaine) combinaison ascendante base sur un corpus de S-SSTC

PSMT Len1rnatisation Alignement Aplatissement de l'arbre LanguageWeaver 2002—

PSCFG Chunking Decodage Post-traitement Google 2005—

2002— statistique statistique statistique +Wu, Melamed 1997, 2004

La différence avec les systemes précédents est que le transfert produit une structure de méme nature
que ce que produirait l'analyse de l'unité de traduction cible. Cela permet éventuellement de composer
deux systemes de TA en perdant beaucoup moins d'information et en introduisant beaucoup moins
d'erreurs qu'en mettant bout a bout deux systemes complets, i.e. en passant par un << pivot textuel >>.

2.6 Systémes a transfert horizontal de dépendances

Type Analyse Transfert Generation Exemples

RBMT Grammaire + dict. Dictionnaires Aplatissement de l'arbre ETAP-2, ETAP-3

l975— Anal. de dependance Transformations d'arbres gran1rnaire+dict. IPPI, Moscou, l977—
régles régles régles

RBMT Len1rnatisation + Dictionnaire de << treelets » Aplatissement de l'arbre TDMT, Furuse (prototype

l992— patrons lineaires + thesaurus semantique gran1rnaire+dict. pour la TA de parole)
régles régles régles ATR, l992—l998

RBMT+ Analyseurs de MSR Apprentissage du transfert Generateurs de MTS-1

SMT (Microsoft) a partir de paires (lf_s, lf_t) Microsoft (prototype sur de la

l999— régles (en G) statistique régles (en G) documentation technique)

LMT (MacCord, IBM), est rangé ici car les << slots » correspondent a des fonctions syntaxiques.

2.7 Systémes a transfert multiniveau horizontal

Type Etapes Methode Commentaires Exemples
RBMT Len1rnatisation Dictionnaire + tables procédural + dict. ITS-2 (Geneve, 1990—)
l990— Analyse multiple par ECFG Programmation en dict. + grammaire
(gouvemement & liage) langage evolue procédural + régles
Desambiguisation interactive (l\/Iodula) interactif
si pas assez de place -- procédural + régles
Transfert autonome -- + dictionnaire
Generation descente recursive aplatissement de l'arbre
RBMT Len1rnatisation + LSPL grammatical, procédural + dict. PT-2 (Linguatec et
2000— Slot Grammars analyse multiple dict. + gram. Lingenio) depuis 2000
Transfert autonome dictionnaire de treelets procédural + régles
Generation descente recursive (en Prolo g)

Passer d'une architecture a transfert descendant a celle de transfert << horizontal >> a été tres difficile
(communication personnelle de K. Eberle de Linguatec a COLING—2000). Cela a été aussi tenté sur
METAL (par Siemens puis Sietech), mais sans succes.

Indépendance des architectures linguistiques et computatiormelles en traduction automatique

2.8 Systémes a transfert ascendant multiniveau

Type Etapes Methode Commentaires Exemples

RBMT Analyse morphologique dictionnaire + automate LSPL (5 au total) Systemes en Ariane-G5

1978— Analyse structurale transformations d'arbres régles 1974-
Tansfert lexical régles de réécriture pour toutes les ru-de—>ru, en—>my-th 80-87
Transfert structural dictionnaires phases fr—>en (BV/aero) 85-92
Generation structurale transformations d'arbres dictionnaires pour f1-—>en-de-1-u(L1D1A) 90-95
Generation morphol. dictionnaire + automate certaines phases HICATS Hitachi (1990_)

Jemah USM, NUS (1990-)

Ici, le transfert produit une structure multiniveau << génératrice » dans laquelle les informations non
interlingues correspondent a celles de la langue source de fagon << contrastive >>, et sont a utiliser par le
générateur comme des préférences ou des ordres en fonction des Valeurs de certains attributs

<< tactiques >>. La premiere phase de l'étape de génération consiste alors a << sélectionner une
paraphrase » en recalculant les informations de surface.

2.9 Systémes a transfert sémantique ou « conceptuel >>

Type Etapes Methode Commentaires Exemples
RBMT Segm. +lemmatisation Pro grammation en C procédural MU (Kyodai, 82-87)
1982—Autres phases Transformations d'arbres régles (gram.s + dict) MAJESTIC (JICST, 87—)

On pourrait ajouter les systemes du CETA (1962-70), 51 << pivot hybride >>, décrit plus haut.

2.10 Systémes a interlingua sémantique ou « linguistico-sémantique >>

11 s'agit de systemes utilisant un interlingua muni d'un Vocabulaire << autonome >>.

Type Enconversion Deconversion Commentaires Exemples

RBMT Lemmatisation directe Transformations procédural ATLAS-II
1980—Transformations chaine-graphe graphe-chaine + Fujitsu, 1980—

régles régles régles PIVOT Nec, l983—

RBMTForn1alisme proche des DCG LSPL fonde sur des régles ULTRA NMSU, 89-95
1980—régles régles Prolog

RBMT Selon les partenaires Selon les partenaires graphe UNL = structure UNL l996—
1997—régles (jusqu'a present) régles << anglo-sémantique »

Les graphes UNL sont << linguistico—sémantiques >>. Le Vocabulaire (UW) est l'union des acceptions
des différentes langues traitées, comme dans ULTRA, mais les relations sémantiques et le traitement
des idiomes sont lies a l'anglais (et tant mieux, car les langues voient assez souvent différemment les
relations sémantiques dans des énoncés synonymes).

2.11 Systémes a ontologie

Ces systemes sont les seuls a faire de la << comprehension explicite >>, leur interlingua étant << projete’ >>
dans une ontologie S2, soit de fagon séparée, soit de fagon interne.

Type Enconversion Projection dans une Q Deconversion Examples

KBMTLemmatisation & Oui, de tout sauf les Planification de la KBMT-89 CMU, 1989—91
1980—EPSG+f-structures elements de discours structure profonde KANT/Catalyst

+pseudo-unification dict. + régles Descente recursive CMU+Caterpillar,

Régles (Univ. Parser) + desamb. interactive régles en—>fr-sp-de-? 1992—
RBMT Dictionnaire + FST Pas d'ontologie dictionnaire + FST CSTAR-II & Nespole!
1997—régles explicite separee : régles GETA 97-03, ETRI (Coree) 97-99

SMT Appris a partir de c'est l'idee (ancienne) Appris a partir de CSTAR-II & Nespole!
2003—couples (chaine,IF) des << grammaires couples (IF,chaine) Irst 98-03

statistique semantiques » statistique Mastor-1 (IBM 2003), sur PDA

L'IF (interface format) réfere a une ontologie implicite, pas explicite.

Christian BOITET

3 Eléments pour le choix d'architectures en TA

3.1 Taille et coﬁt des ressources / architectures computationnelles

Le tableau suivant donne une estimation des ressources nécessaires pour construire un systeme de TA
en fonction de la difficulté de la tﬁche, grossiérement estimée a partir de la taille moyenne des phrases.
Les coﬁts sont donnés ici en homme*année (h*a), M veut dire << million >>, et K << mille >>.

Pour la TA empirique, il s'agit de la taille du corpus, en mots, pages (de 250 mots), phrases, et du
temps humain de préparation de ce corpus. S’il s’agit de traduction, nous utilisons le taux
professionnel de lh/page (avec la révision, ce serait 1h2O par page). S’il s’agit d’annotation, les
coﬁts ne sont la plupart du temps pas publiés, et nous utilisons des informations dont nous
disposons par communications personnelles. Le coﬁt par page est bien plus élevé, mais le corpus
peut étre beaucoup plus petit, et finalement bien moins coﬁteux, pour de meilleurs résultats.

Pour la TA experte, il s'agit de la taille des dictionnaires et des grammaires, et du travail d'experts
humains. Contrairement a ce qu’on lit dans de nombreux cours sur la TA qu’on peut glaner sur le
Web, ce coﬁt est souvent tres surévalué, et pas seulement par les tenants des méthodes empiriques.

hrases 6.5 mots/phrase 25 mots/phrase

Type BTEC, 1\/[ETEO Infomiations (news)
SMT 0.9—3 M mots 50—200 M mots
PSMT 3.6—12 K pages 200—800 K pages
EBMT par analogie 0.15—0.5 M phrases 2—8 M phrases

Coﬁt :2.4—8 h*a 100—400 h*a (rarement disponible !)
EBMT avec arbres N/A pour ce type de phrases courtes 4—12.5 M mots
SMT Apprentissage supervise 15—50 K pages
Mastor-1 (IBM) 1h/page (par recoupements) 0.15—0.5 M phrases

Coﬁt : 10—40 h*a
EBMT avec arbres et S-SSTCs N/A pour phrases courtes 4—12.5 M mots
Bantu1jah(USM) Apprentissage supervise 0.6—1 K pages

Coﬁt :15 h/page (10 h/p espére) 0.006—0.01 M phrases

dictionnaire (50 K) souvent disponible 6—10 h*a (travail assez specialise)
RBMT Dictionnaire 3-10 K 0.6—2 h*a Dict. 50-500 K, soit 15—150 h*a
Grammaires environ 25 h*a

Coﬁt :Total 1—3 h*a Total z 40—175 h*a

3.2 Bréve analyse

1.

Il est clair que, plus les corpus sont << bruts », plus ils doivent étre grands. Méme a raison de
15h/page de travail humain, il semble intéressant d'utiliser une méthode comme celle de l'USM a
Penang, car on n'a besoin que de 1000 pages et d'un gros dictionnaire assez simple.

D'autre part, la SMT (et la PSMT) sont en fait adaptées a des << niches de riches >>, tout comme la
TA << experte >> pour sous—langages. En effet, il y a tres peu de corpus paralleles disponibles de 200
a 800 K pages ! Du point de vue des corpus, les différences entre couples de langues << bien
dotés >> et << mal dotés » sont encore plus grandes qu'en ce qui concerne les dictionnaires.

Créer de tres gros corpus paralleles a partir de zéro est 2 a 3 fois plus coﬁteux que de construire un
grand systeme de TA par approche experte (procédurale et/ou a automates et grammaires).

L'architecture linguistique par << pivot interlingue >> peut utiliser n'importe quel paradigme
computationnel, qu'il soit statistique, analogique, a regles, ou hybride.

En dernier ressort, le choix de l'architecture linguistique et de l'architecture computationnelle
dépend des ressources disponibles en termes de corpus préalablement traduits, et d'humains plus
ou moins experts. Les types d'expertise recherchée sont, par ordre de difficulté croissante (estimée
via le temps de formation et la relative rareté des experts): la traduction, la post—édition, la
correction d'annotations, l'annotation a partir de rien, la terminologie, la lexicographie complexe

Independance des architectures linguistiques et computationnelles en traduction automatique

(vocabulaire general et tournures), l'écriture de grammaires assez déclaratives, la programmation
par automates dans des LSPL adaptés, et enfin la programmation directe.

Conclusion

Nous avons donc montré que les architectures linguistiques et computationnelles des systemes de
traduction automatique sont indépendantes, au sens o1‘1 on peut utiliser n'importe quelle architecture
computationnelle pour réaliser n'importe quelle phase de traitement dans une architecture linguistique
donnée, non seulement en théorie, mais en pratique, comme l'illustre la variété des systemes cites en
exemple. Nous avons aussi donne une evaluation des tailles et des coﬁts de construction des ressources
utilisées par différents types de systemes de TA, ce qui donne quelques elements pour le choix de
l'architecture linguistique et computationnelle d'un systeme a créer, en fonction des situations
traductionnelles et des ressources disponibles, en termes de dictionnaires, de corpus, et de
competences humaines.

Cette réﬂexion ouvre sur une perspective plus générale et << sociétale >>. Si l'on veut surmonter la
<< barriere linguistique » entre toutes les langues, on ne pourra pas se contenter de construire des
systemes de TA entre l'anglais et les autres langues, meme pas pour le tchat er1tre deux langues
différentes de l'anglais. En effet, l'anglais intermédiaire serait nécessairement trop << grossier >>, entaché
d'erreurs, et porteur d'ambigu'1tés nouvelles en sus des anciennes (celles de la langue source). La
plupart des locuteurs (ou simplement lecteurs <<passifs >>) seront de plus toujours bien moins
compétents et a l'aise en anglais que dans leur langue.

I1 faudra donc construire des systemes fondés sur des interlingues, soit << sémantico—pragmatiques >>
(comme l'IF de CSTAR, Nespole! ou MASTOR—1) s'il s'agit de taches et de domaines restreints et
bien identifies, soit << linguistico—sémantiques >> (comme UNL). Cela sera d'autant plus nécessaire
qu'on voudra intégrer ces systemes au << Web sémantique >>, car il faudra alors demander aux
internautes d'aider les systemes d'annotation, sans doute par le meme type de «désambigu'1'sation
interactive >> que celui qui permet de compenser la nécessaire << rusticite’ >> (ou la << mauvaise qualité
intrinseque >>) des systemes de TA << tout terrain >> quand on veut les utiliser en << tout automatique >>.

11 ressort de ce qui precede qu'il devrait étre possible de construire des systemes de TA er1tre toutes les
langues, passant par un niveau sémantique comme UNL, non seulement par des approches
<< expertes » comme c'est le cas actuellement, mais par des approches empiriques moins coﬁteuses et
moins longues en développement, si toutefois on disposait de corpus adéquats de taille suffisante.
D'autre part, a la lumiere des développements récents en alignement et en TA statistique, de tels
corpus devraient pouvoir étre construits par << transitivité >>, en alignant des corpus paralleles et des
corpus annotés en IL (en UNL par exemple) s'ils ont au moins une langue en commun.

Références

BOITET C. (1986) The French National MT—Project: technical organization and translation results of
CALLIOPE—AERO. Computers and Translation, 1, pp. 281 —309.

BOITET C. (1988) L'apport de Bernard Vauquois a la traduction automatique et au traitement
automatique des langues naturelles. Proc. Colloque sur l 'Histoire de l'Informatique en France., 3-5
mai 1988, P. Chatelin, ed., vol. 2/2, pp. 63—82.

BOITET C. (1988) PROS and CONS of the pivot and transfer approaches in multilingual Machine
Translation. Proc. Int. Conf. on « New directions in Machine Translation », 18-19 August 1988, BSO,
ed., Foris Publications, pp. 93— 108.

BOITET C. (1988) Representation and Computation of Units of Translation for Machine Interpretation
of Spoken Texts. Computers and Artiﬁcial Intelligence, 8/6, pp. 505—546.

Christian BOITET

BOITET C. (1993) La TAO comme technologie scientifique : le cas de la TA fondée sur le dialogue. In
La traductique, A. Clas et P. Bouillon, ed., Presses de l'Université de Montreal, pp. 109— 148.

BOITET C. (1993) TA et TAO a Grenoble... 32 ans déja ! T.AL. (revue semestrielle de l'ATALA),
33/1 —2, Special Trentenaire, pp. 45—84.

BOITET C. (1995) Factors for success (and failure) in Machine Translation — some lessons of the first
50 years of R&D. Proc. MTS—V (Fifth Machine Translation Summit), 11— 13 July 1995, CEE, 17 p.

BOITET C. (2001) Machine Translation. In Encyclopedia of Cognitive Science, Nature Publishing
Group, London, (in manuscript form) 24 p.

BOITET C. ET BLANCHON H. (1994) Promesses et problemes de la << TAO pour tous >> apres LIDIA-
1, une premiere maquette. Langages, 116, pp. 20—47.

BOITET C., BOGUSLAVSKIJ I. ET CARDENOSA I. (2007) An Evaluation of UNL Usability for High
Quality Multilingualization and Projections for a Future UNL++ Language. In Computational
Linguistics and Intelligent Text Processing (Proc. CICLING-2007), A. Gelbukh, ed., Springer (LNCS
4394), pp. 361-373. (ISBN-10: 3—540—70938—X Springer, ISSN: 0302-9743)

BOITET C., ed. (1988) BERNARD VAUQUOIS et la TAO, Vingt-cinq ans de Traduction
Automatique, ANALECTES. BERNARD VAUQUOIS and MT, twenty-five years of MT. Ass.
Champollion & GETA, Grenoble, 700 p.

BOITET C. ET GERBER R. (1986) Expert Systems and other new techniques in MT. In Neue Ansa'tze
in maschineller Sprachiibersetzung, Niemeyer, Tiibingen, pp. 103— 119.

EISELE A. (2005) Exploiting Multilingual Corpora for Machine Translation. (JRC Enlargement and
Integration Workshop on Exploiting parallel corpora in up to 20 languages), Arona, Saarland
University & DFKI, (slides)

HUTCHINS W. J. (1986) Machine Translation: Past, Present, Future. Ellis Horwood, John Wiley &
Sons, Chichester, England, 382 p.

HUTCHINS W. J. ET SOMERS H. L. (1992) An Introduction to Machine Translation. H. B.
Jovanovich, ed., Academic Press, 362 p.

HUTCHINS J ., HARTMAN W. ET HITO E. (2005) Compendium of Translation Software (directory of
machine translation systems and computer-aided translation support tools. EAMT, TIM/ISSCO,
Geneva, 127 p. (Earlier editions of the Compendium are available as PDF files from:
http://ourworld.compuserve.com/homepages/WJHutchins/compendium.htm)

JEIDA (1989) A Japanese view of Machine Translation in light of the considerations and
recommendations reported by ALPAC, USA. Japanese Electronic Industry Development Association.

KRAIF O. (2006) Corpus multilingues — multilingual corpora. 22/11/06.
http://w3.u-grenoble3.fr/kraif/index.php?option:com_content&task:view&id:20&Itemid:36

LEPAGE Y. ET DENOUAL E. (2005) Purest ever example-based machine translation: detailed
presentation and assessment. Machine Translation Journal, 19, pp. 251 —282.

SENELLART J ., BOITET C. ET ROMARY L. (2003) XML Machine Translation. Proc. MT S-IX
(Machine Translation Summit), New-Orleans, 9 p.

THURMAIR G. (2006) Using corpus information to improve MT quality. Proc. LR4Trans-III (3rd
International Workshop on Language Resources for Translation Work, Research & Training), LREC
2006, Genoa, ELRA / ELDA, 4 p.

UCHIDA H. (2004) The Universal Networking Language (UNL) Specifications Version 3 Edition 3.
UNL Center, UNDL Foundation, December 2004.
http://www.undl.org/unlsys/unl/UNLSpecs33.pdf

VAUQUOIS B. ET BOITET C. (1985) Automated translation at Grenoble University. Computational
Linguistics, 11/ 1, January-March 85, pp. 28—36.

