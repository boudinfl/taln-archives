TALN 2008, Avignon, 9-I3juin 2008

Vérification sémantique pour l’annotation d’entités nommées

Caroline Brun (1), Caroline Hagege (2)

(1) Xerox Research Centre Europe — 6, chemin de Maupertuis, 38240 Meylan
France
Caroline.Brun@xrce.xerox.com
(2) Xerox Research Centre Europe — 6, chemin de Maupertuis, 38240 Meylan
France
Caroline.Hagege@xrce.xerox.com

Résumé Dans cet article, nous proposons une méthode Visant a corriger et a associer
dynamiquement de nouveaux types sémantiques dans le cadre de systemes de détection
automatique d’entités nommées (EN). Apres la détection des entités nommées et aussi de
maniere plus générale des noms propres dans les textes, une Verification de compatibilité de
types sémantiques est effectuée non seulement pour confirmer ou corriger les résultats
obtenus par le systeme de détection d’EN, mais aussi pour associer de nouveaux types non
couverts par le systeme de détection d’EN. Cette Verification est effectuée en utilisant
l’inforrnation syntaxique associée aux EN par un systeme d’analyse syntaxique robuste et en
confrontant ces résultats avec la ressource sémantique WordNet. Les résultats du systeme de
détection d’EN sont alors considérablement enrichis, ainsi que les étiquettes sémantiques
associées aux EN, ce qui est particulierement utile pour l’adaptation de systemes de détection
d’EN a de nouveaux domaines.

Abstract In this paper we propose a new method that enables to correct and to associate
new semantic types in the context of Named Entity (NE) Recognition Systems. After named
entities (and more generally proper nouns) have been detected in texts, a semantic
compatibility checking is performed. This checking can not only confirm or correct previous
results of the NER system but also associate new NE types that have not been previously
foreseen. This checking is performed using information associated to the NE by a robust
syntactic analyzer and confronting this information to WordNet. After this checking is
performed, final results of the NER system are better and new NE semantic tags are created.
This second point is particularly useful when adapting existing NER systems to new domains.

Mots-clés 2 Entités nommées, Analyse syntaxique robuste, Types sémantiques
Keywords: Named Entities, Robust Parsing, Semantic Types

Caroline Brun, Caroline Hagége

1 Introduction

Dans cet article, nous proposons une méthode perrnettant d’enrichir les résultats obtenus par
un systeme de détection automatique d’entités nommées en utilisant les relations syntaxiques
qui leur sont associées par un analyseur syntaxique robuste, XIP (Xerox Incremental Parser),
et en Vérifiant les types sémantiques des arguments en relation syntaxique a l’aide de la
ressource ontologique WordNet (Fellbaum, 1998). L’utilisation de relations syntaxiques pour
raffiner la tache de détection d’EN n’est pas nouvelle, Voir par exemple (Ehrrnann et Jacquet,
2006) ou (Brun et Hagege, 2004). De méme, l’utilisation de WordNet dans le cadre de la
détection d’EN est décrite dans plusieurs travaux, comme par exemple dans (Magnini et al.,
2002). Les travaux de (Benetti et al., 2006) montrent aussi l’enrichissement d’un systeme de
reconnaissance d’EN grace a l’utilisation de Wikipedia. La nouveauté de notre méthode est de
coupler information syntaxique et information sémantique sur les résultats de cette analyse
syntaxique fine. Cela Va nous permettre non seulement de valider ou d’inValider les résultats
préalablement fournis par le systeme de détection d’EN, mais aussi de considérer de
nouveaux types sémantiques via WordNet et de les associer a des noms propres non typés par
le systeme initial, créant ainsi de nouvelles catégories d’entités nommées.

Apres avoir présenté l’analyseur syntaxique robuste XIP, ainsi que le systeme de détection
d’EN, basé également sur XIP, nous décrivons en détail cette méthode et son implantation.
Puis, nous donnons les résultats de différentes expérimentations réalisées avec le prototype
que nous avons développé. Enfin, nous tirons les conclusions relatives a cette méthode.

2 Détection d’entités nommées

2.1 Généralités

La détection d’entités nommées fait l’objet d’un intérét certain pour le TALN (Voir les
conférences MUC http://www.itl.nist.goV/iaui/894.02/related_projects/muc/, les campagnes
ACE http://www.nist.gov/speech/tests/ace/, ESTER, etc.), en particulier pour la tache
d’extraction d’information, mais aussi pour beaucoup d’autres applications spécifiques. De
nombreux systemes, symboliques ou statistiques, détectent et catégorisent les NE avec de
bonnes performances (environ 90 de f-mesure). Cependant, certaines applications requierent
plus de précision et la méthode que nous proposons Vise a améliorer a posteriori les résultats
d’en systeme d’extraction d’EN.

2.2 L’analyseur syntaxique robuste XIP

XIP (Ait-Mokhtar et al., 2002) est un analyseur dont l'objectif est d'extraire des dépendances
syntaxiques de facon robuste. Cet analyseur accepte en entrée n’importe quel document ou
partie de document au format texte ou XML et produit en sortie une représentation
grammaticale du contenu de ce document.

Le forrnalisme proposé par XIP nous permet d'exprimer un large éventail de regles qui Vont
de la désambigu'1'sation catégorielle a la construction de dépendances, en passant par la
constitution de syntagmes noyaux: XIP permet de relier par des relations des éléments
linguistiques qui peuvent étre des éléments lexicaux, mais aussi des éléments non lexicaux
correspondant a des syntagmes noyaux.

Vérification sémantique pour Z ’ann0tati0n d ’entités nommées

Dans le cadre du travail présenté dans cet article, nous utilisons la version la plus complete de
la grammaire de l’anglais développée au sein de XIP, que nous désignons par grammaire <<de
normalisation». Cette grammaire est construite sur la base des résultats obtenus lors de
l’analyse grammaticale générale de l’anglais.

Grammaire générale : La grammaire générale de l’anglais permet le << chunking >> (analyse
en syntagmes noyaux) et réalise une extraction des dépendances standards (Sujet, Objet,
modiﬁeurs, attributs etc.).

A titre d’exemple, voici une phrase analysée par cette grammaire :

MbMurphy was successful in changing many of the rules that were imposed
upon them by Nurse Ratched.

Analvse par XIP (grammaire générale):

MAIN(was) NUCL_VLINK_PASSIVE(were,imposed)
NUCL_SUBJCOMPL(was,successful) SUBJ_PRE_RELATIV(were,that)
SUBJ_PRE(was,McMurphy) AGENT(imposed,Nurse Ratched)
MOD_POST_GERUND(was,changing) MOD_POST(imposed,them)
OBJ_POST(changing,rules) MOD_POST(them,Nurse Ratched)
QUANTD(rules,many) PERSON(Nurse Ratched)
MOD_POST_SENTENCE_RELATIV(rules,im PERSON(McMurphy)

posed)

Grammaire de normalisation (Hagege, Roux, 2003): Une couche supplémentaire de
développement a été rajoutée a cette grammaire de base, l’objectif applicatif visé étant
l’extraction d’information. Ces développements permettent d'avoir, apres l'analyse, une
représentation commune pour des suites de signiﬁants qui ne sont pas identiques mais qui
véhiculent une information similaire. A l'heure actuelle, ce travail de normalisation s'effectue
selon trois axes :

0 L'exploitation des relations syntaxiques mises en évidence lors de l'analyse générale :
L'analyse par la grammaire générale est tout d’abord rafﬁnée afin de considérer les
sujets et objets de verbes non finis et les antécédents des relatives dans le calcul du
sujet et de l'objet, de norrnaliser la forme passive en forme active et de typer certains
compléments. Ensuite, certaines alternances verbales telles qu’elles sont définies dans
(Levin, 93) sont exploitées.

0 La hiérarchisation des propositions dans une phrase : la grammaire normalisée permet
de reconnaitre les degrés d’enchassements des verbes par rapport au verbe principal.

0 L'exploitation d'inforrnation de morphologie dérivationnelle : cette information permet
d’exprimer des équivalences entre verbe-compléments et nom-arguments.

L’analyse de la phrase précédente avec cette version de la grammaire donne alors :

Analvse par XIP (grammaire normalisée):

ATTRIB(McMurphy,successful) SUBJ—N(changing,McMurphy)
MAIN(was) MOD_POST_SENTENCE_RELATIV(rules,im
MOD_POST_GERUND(was,changing) posed)

SUBJ—N_PRE(was,McMurphy) SUBJ—N(imposed,Nurse Ratched)
OBJ—N(changing,rules) OBJ—N(imposed,rules)

EMBED_PROG(changing,was) MOD_POST(imposed,them)

Caroline Brun, Caroline Hagege

MOD_POST(them,Nurse Ratched) PERSON(McMurphy)
PERSON(Nurse Ratched) SUBJ—N(succeed,McMurphy)

Nous pouvons remarquer dans l’analyse effectuée par la grammaire de normalisation qu’une
relation de type << sujet normalisé>> (SUBJ-N) est établie entre le verbe << succeed» et
<<McMurphy>> (a partir de la suite <<McMurphy was successful»). L’identification de
l’antécédent de la relative ainsi que la normalisation entre forme passive et forme active
perrnettent d’extraire une relation << sujet normalisé >> entre le verbe << impose >> et << Nurse
Ratched >> et une relation << obj et normalisé >> entre ce méme verbe et le nom << rule >>. Enﬁn,
une relation << sujet normalisé >> est également extraite entre le verbe << change >> et le nom
<< McMurphy >>.

C’est cette version de la grammaire que nous avons utilisée dans pour construire le prototype
de validation et découverte d’EN.

2.3 XIP et la détection d’EN

Un systeme de détection des EN a été développé au sein de l’analyseur XIP. Il perrnet de
détecter les types << standards >> d’entités nommées a savoir : dates, pourcentages, monnaies,
lieux, personnes, organisations. 11 s’agit d’un systeme a base de regles, consistant en un
ensemble de regles locales qui utilisent de l’information lexicale combinée a de l’information
contextuelle sur les catégories syntaxiques. Ces regles locales sont tres similaires a des regles
de << chunking >> (identification des syntagmes noyaux), sauf qu’elles operent au niveau du
nom.

. . 1
Vo1c1 un exemple d’analyse :

Margaret Sinclair Trudeau, born September 10, 1948 in Vancouver, British Columbia,
Canada, was the wife of the late Canadian Prime Minister Pierre Trudeau. The daughter of
James Sinclair, a former Liberal member of the Parliament of Canada and fisheries minister,
she attended Simon Fraser University where she obtained a degree in English literature.

PERSON(Margaret Sinclair Trudeau)
DATE(September 10 , 1948)

LOC_CITY(Vancouver)

LOC_REGION(British Columbia)
LOC_COUNTRY(Canada)

PERSON(Canadian Prime Minister Pierre Trudeau)
PERSON(James Sinclair)

ORGANISATION(Parliament of Canada)
ORGANISATION(Simon Fraser University)

Le systeme a été évalué en interne, sur un corpus de dépéches d’environ 87000 mots, et
montre une f-mesure de 90 tous types d’entités confondus (Erhmann 2004). Ce systeme de
détection des entités nommées est intégré aux différentes grammaires présentées dans le
paragraphe précédent. La validation et découverte d’EN se fait sur la base des résultats
obtenus par ce systeme initial.

1 Les entités extraites sont présentées sous forme de << de'pendances unaires ».

Verification sémantique pour Z ’annotation d ’entités nommées

3 Validation et découverte d’EN

3.1 Détection des relations attributives

La premiere étape réalisée par notre prototype est de détecter les entités nommées ainsi que
les entités potentielles non étiquetées sémantiquement (noms propres) a l’aide du systéme
présenté au paragraphe 2.3. Notre systéme Va considérer comme nom propre, toute suite de
mots (éventuellement non reconnus par l’analyseur lexical) présentant des particularités
typographiques comme une majuscule initiale et ne rentrant dans aucune des catégories
d’entités nommées reconnues par le systéme.

Nous appliquons ensuite sur le méme texte la grammaire norrnalisée. Cette grammaire
norrnalisée a pour particularité d’extraire une relation que nous désignons par relation
attributive. Une relation attributive relie des suites de caractéres lorsque des indicateurs
textuels et des constructions syntaxiques perrnettent d’afﬁrmer qu’ils entretiennent une
relation de type IS-A

Les exemples suivants illustrent la notion de relation attributive telle que nous l’entendons.

(1) John Smith was an inventor.

(2) John Smith, the inventor, made a presentation.

(3) John Smith is expected to be an inventor.

(4) They consider John Smith an inventor.

(5) The inventor John Smith was awarded.

(6) An inventor called John Smith was awarded.

(7) John Smith, who is a great inventor, was awarded.

(8) John Smith, as the inventor of the process, was awarded.

Dans tous ces exemples, “John Smith” est en relation attributive avec “inventor”.

A titre d’exemple, l’analyse donnée par XIP pour la phrase (5), en utilisant la grammaire de
normalisation, est la suivante :

SUBJ—N_PRE(consider,They) OBJ—N(consider,Smith)
PREPD(inventor,as) ATTRIB(John Smith,inventor)
PERSON (John Smith)

Nous nous intéresserons uniquement aux relations attributives mettant en jeu les entités
nommées et nom propres extraites a l’aide de XIP : elles correspondent a une relation de type
IS-A du point de vue sémantique, et Vont ainsi nous permettre de typer sémantiquement les
EN.

Caroline Brun, Caroline Hagége

3.2 Confrontation avec WordNet

Nous utilisons l’information semantique fournie par la base de données lexicale WordNet2
(Fellbaum 1998), en particulier les classes semantiques de plus haut niveau associees aux
synsets.

Une fois les relations attributives extraites entre entites et attribut nominal, le systeme utilise
WordNet pour associer un type semantique a l’attribut nominal. Pour ce faire, nous avons
extrait de WordNet tous les noms dont le << super type >> (person, artifact, substance, etc.) n’est
pas ambigu, par exemple :

Girl [5 sens] 9 noun.person Ship [1 sens] 9 noun.artifact
Drug [1 sens] 9 noun.artifact Liquidation [3 sens] 9 noun.act

En resulte un Vocabulaire de 44406 noms accompagnes de leur << super type >> semantique qui
est integre a des lexiques au sein de XIP. Un appariement entre << super type >> semantique de
WordNet et type d’entités nommees reconnues par le systeme initial est egalement effectue
(par exemple le type WordNet << person >> correspond au type << PERSON >> de notre systeme
de reconnaissance de EN.

Le schema suivant decrit l’architecture du prototype que nous avons developpe :

Texte en entree

V
Extraction des EN et XIP 0
Noms Propres (NPr)

Detection des relations attributives

+

      
 

EN/NPI et types des
attributs norninaux

N,“ et LVPE3 EN et t.V:P€ Sémamiqlle EN et type semantique de
Senlantlclue de 1 atmbllt 110“ l’attribut compatibles

de l’attribut Compatibles I

I I
Découvene Conﬂit de Confirmation
de type type d9 type

\.l /

Suite de l’analyse avec
detection d’EN amelioree

l

Le resultat de la confrontation entre entite nommee ou nom propre extraits par le systeme
initial et type semantique de l’attribut nominal selon WordNet peut produire les cas de ﬁgures
suivants :

2 http://wordnet.princeton.edu/

Ve’rification sémantique pour l ’annotation d ’entités nommées

1) Conﬂit de type

Dans ce cas, le systeme initial a associé a une EN un certain type sémantique qui n’est pas
compatible avec le type que WordNet assigne a l’attribut de cette entité, comme par exemple
dans la phrase (ou l’EN est indiquée en gras) :

The warship is called the Armando Diaz

Le type de l’EN extrait par le systeme initial est << PERSON >> alors que le type de << warship >>
selon WordNet est << artifact >>. Ces deux types sont contradictoires.

2) Confirmation de type

C’est le cas pour lequel le type de l’entité nommée est compatible avec le type WordNet de
son attribut. Dans ce cas, il s’agit d’une information supplémentaire qui vient conﬁrmer le
choix du systeme initial, comme par exemple dans :

If one man has done more than any other to keep Old Labour behind Tony Blair it is surely
his deputy, John Prescott.

Une relation attributive est détectée entre << deputy» et << John Prescott», préalablement
identiﬁé comme nom de personne par le systeme initial. Selon WordNet, << deputy»,
n’appartient qu’au << super type >> << person >>. Les deux types sont parfaitement compatibles,
donc le systeme conﬁrme le type de l’entité.

3) Découverte d’un nouveau type

Ce cas s’applique uniquement aux noms propres non typés extraits par le systeme initial.
Grace a l’association d’un attribut a ce nom propre, et au typage par WordNet de cet attribut,
nous pouvons proposer d’attribuer ce type sémantique WordNet au nom propre. Par exemple
dans la phrase suivante :

Activia is yogurt, but not just any yogurt.

“Activia” n’est pas détecté comme une EN par le systeme initial de XIP. Il est cependant en
relation attributive avec le nom << yogurt >>, dont le super type dans WordNet est << food >>. Le
systeme associe donc la nouvelle etiquette sémantique << food >> a << Activia >>.

4 Expérimentations sur corpus

4.1 Corpus général

Le corpus general, de 5500 mots, est constitué d’un ensemble de dépéches de provenance
diverse (Herald Tribune, The Guardian, The Observer, The New York Times) ainsi que de
quelques courtes biographies. Le systeme initial de reconnaissance d’EN détecte 7441 entités
nommées.

L’application postérieure de notre méthode nous permet de considérer 115 entités, parmi
lesquelles 78 sont des compatibilités entre types, 19 sont des découvertes de nouveau type, 18
sont des conﬂits ;

Caroline Brun, Caroline Hagege
Compatibilité :

Seuls des entités de type PERSON et ORGANISATION sont concemées. Les 78 cas de
compatibilités extraites sont justes, comme par exemple pour la phrase suivante :

The Democratic challenger, John Kerry, has called on the White House to turn words into
action.

John Kerry a été détecté comme EN de type personne par le systeme général (“John” étant
une suite codée comme prénom dans le lexique). Cela est conﬁrmé dans un deuxieme temps
grace a l’identiﬁcation du lien attributif entre “John Kerry” et “challenger” qui lui-méme est
considéré comme de type personne par WordNet.

Découverte :

Les types découverts et proposés par le biais de WordNet dans ce texte sont les types
COMMUNICATION et ARTIFACT, comme par exemple dans :

For Tom Hanks, it's his maiden voyage to Cannes where he will be publicising the Coen
brothers ’ remake of the classic British comedy The Ladykillers.

ENTITE (Cannes) LOCORG_CITY (Cannes)

ENTITE (Ladykillers) ATTRIB(Ladyki1lers, comedy)
PERSON (Tom Hanks) DISCOVERY_WN_COMMUNICATION (Lady
PERSON (Coen) killers)

“Ladykillers” qui avait simplement été repérée comme nom propre par le systeme général, se
Voit attribuer le type “COMMUNICATION” grace a la relation attributive qu’il entretient
avec le nom “comedy”.

Sur les 19 entités découvertes, 5 sont erronées et 14 sont correctes. Les erreurs sont dues a des
erreurs de detection de la relation attributive provenant en général d’une erreur dans la
détection de la téte d’un groupe nominal complexe. Cette erreur de detection de la téte est a
son tour souvent liée a des erreurs de désambiguisation de la partie du discours.

On peut remarquer que le faible nombre d’entités découvertes s’explique par le fait que le
corpus traité est en harmonie avec le type d’entités que le systeme général prévoit (langue
générale, presse).

Conﬂit :

Nous obtenons pour ce corpus 17 cas de conﬂit. Il est intéressant de noter que parmi ces
conﬂits, certains relevent de cas d’emploi métonymique des entités nommées, comme par
exemple dans la phrase suivante :

While Schro'der was saying that D-Day signaled the starting point for today’s new Europe
and maintained that the EU was the best guarantor of peace in Europe,...

Une relation attributive entre l’entité nommée << EU >> et le nom << guarantor >> est extraite. Le
systeme de base de détection des EN indique que << EU >> est de type ORG. Par le biais de
notre méthode, dans la mesure ou le nom << guarantor >> est de type PERSON, nous obtenons
un conﬂit de type.

Ve’rification sémantique pour Z ’annotation d ’entités nommées

Or, dans le cas présent, c’est bien un usage métonymique de l’entité << EU >> dont il s’agit dans
cette phrase, méme si par nature, << EU >> correspond a un lieu ou a une organisation.

Parrni les 18 cas de conﬂit, nous obtenons 6 cas de conﬂits lies a des usages métonymiques
des entités nomrnées détectées. Nous pouvons donc considérer que ces 6 cas sont pertinents.
Nous obtenons également 3 cas pertinents de conﬂits pour lesquels le systeme initial de
détection des EN a fait des erreurs que nous pouvons corriger grace a notre méthode.

Enﬁn, les 8 cas restants sont des détections de conﬂit erronées, ces erreurs étant
essentiellement liées, comme pour les erreurs de découverte a des erreurs d’analyse
syntaxique et de désambigu'1'sation.

4.2 Corpus spécialisé

Nous avons également testé notre méthode sur un corpus3 spécialisé de biologie, d’enViron
92000 mots (il s’agit de 422 articles extraits de pubmed). Nous nous sommes intéressées aux
noms de genes, annotés dans ce corpus, et qui correspondent aux classes sémantiques
<< BODY» et << SUBSTANCE» de Wordnet. Sur ce corpus, le systeme << découvre >> 505
noms de genes, et détecte 8 cas de conﬂits avec le systeme initial. Voici une illustration de
ces résultats :

(1) Structural basis of multidrug recognition by BmrR, a transcription activator of a
multidrug transporter.

ATTRIB (activator,Bn1rR)

DISCOVERY_WN_SUB STANCE(BmrR)

0>TOP{NP{AP{Structural} basis} PP{of NP{multidrug recognition}} PP{by NP{BmrR}} , NP{a transcription
activator} PP{of NP{a AP{mul11'drug} transporter}} .}

Le nom propre << Bmr>> est découvert comme une entité de type << Substance >> (gene) par
notre systeme car l’attribut << activator» appartient a la classe noun.substance dans WordNet.

(2) ADP is an inhibitor of the phosphorylation by ATP.

ORGANISATION(ADP)

ATTRIB(ADP,inhibitor)

CONFLICT_WN_SUB STANCE(ADP)

0>TOP{SC{NP{ADP} FV{is}} NP{an inhibitor} PP{of NP{the phosphorylation}} PP{by NP{ATP}}}

Ici, un conﬂit est détecte car le systeme initial de reconnaissance considere ADP comme une
organisation (ADP= Aéroport de Paris), alors que notre systeme lui associe le type
SUB STANCE.

Les 8 cas de conﬂits détectés sont tous corrects, c'est-a-dire que le systeme initial donne une
annotation erronée pour un nom de gene. Concernant les noms de genes découverts,
l’éValuation sur ce corpus donne 85% de précision et 6,6 % de rappel.

Nous obtenons donc une tres bonne précision pour un rappel faible, ce dernier point étant
assez prévisible car le systeme n’utilise que des relations attributives pour détecter les EN. A
titre d’information, 1900 relations attributives sont détectées sur l’ensemble du corpus.

3 Disponible ici : http://n1ig.jouy.inra.fr/recherches/bibliome/linguistic-and-sen1antic-
resources/corpora/manual_genes_annotation.tar.bz2/view

Caroline Brun, Caroline Hagege

5 Conclusion

La méthode que nous présentons permet d’améliorer les résultats d’un systeme de
reconnaissance d’entités nommées en Validant ou invalidant les résultats produits par ce
systeme et permet également de proposer de nouveaux types d’entités nommées pour des
noms propres détectés mais non typés par le systeme. La méthode utilise les résultats d’une
analyse syntaxique ﬁne permettant d’extraire des relations de type IS-A entre noms propres et
entités reconnues par le systeme initial et d’autres noms communs catégorisés
sémantiquement par la ressource WordNet.

Les tests effectués sur les corpus montrent que l’apport de notre méthode est tres Variable
selon le type de corpus sur lequel on travaille. Dans le cas de textes appartenant a un domaine
particulier, c’est l’aspect découverte de nouvelles entités dont les types n’ont pas été
préalablement prédéﬁnis qui semble le plus intéressant. En effet, méme si la couverture reste
basse elle peut constituer une amorce ﬁable pour des systemes d’apprentissage. Dans le cas de
textes généraux pour lesquels les types d’entités nommées prédéﬁnis sont couvrants, c’est
l’aspect conﬁrmation qui semble le plus prometteur.

Références

A1T-MOKTHAR S., CHANOD J.P., ROUX C. (2002). Robustness beyond Shallowness:
Incremental Dependency Parsing. Special issue of NLE Journal.

BENETI A., HAMMOUMI W., HIELSCHER E., MULLER M., PERSONS D. (2006). Automatic
Generation of Fine-Grained Named Entity Classification,
http://www.ifarm.nl/erikt/ltp2006/ltp2006.pdf

BRUN C. HAGEGE H. (2004). Intertwining deep syntactic processing and named entity
detection. Actes de ESTAL 2004, Alicante, Spain, October 20-22, 2004.

EHRMANN M. (2004). Evaluation d'un Systeme d'extraction d'Entités Nommées. Rapport de
stage DESS Texte, Nancy, 2004.

EHRMANN M., JACQUET G. (2006). Vers une double annotation des entités nommées. Revue
TAL, numéro 46, Volume 3.

FELLBAUM C. (1998). WordNet.‘ An Electronical Lexical Database. MIT Press, Cambridge,
USA.

HAGEGE C, ROUX C. (2003). Entre syntaxe et sémantique: normalisation de l’analyse
syntaxique en Vie de l’amelioration de l’extraction d’information. Actes de TALN 2003, Batz-
sur-Mer, France.

LEVIN, B. (1993). English Verb Classes and Alternations — A preliminary Investigation. The
University of Chicago Press.

MAGNINI B, NEGRI M, PREVETE R., TAEV H. (2002). A WordNEt-Based Approach to Named
Entities Recognition. COLING-02 on SEMANET, Vol.11, pp. 1-7

