TALN 2008, Avignon, 9-13 juin 2008

Résolution de Métonymie des Entités Nommées : proposition
d’une méthode hybride

Caroline Brunl Maud Ehrmannl Guillaume J acquetl
(1) Xerox Research Center Europe - XRCE
6, Chemin de Maupertuis, 38240 Meylan
{Caroline.Brun, Maud.Ehrmann, Guillaume.Jacquet} @xrce.xerox.com

Résumé. Dans cet article, nous décrivons la méthode que nous avons développée pour la
résolution de métonymie des entités nommées dans le cadre de la compétition SemEval 2007.
Aﬁn de résoudre les métonymies sur les noms de lieux et noms d’organisation, tel que requis
pour cette tache, nous avons mis au point un systeme hybride basé sur l’utilisation d’un analy-
seur syntaxique robuste combiné avec une méthode d’analyse distributionnelle. Nous décrivons
cette méthode ainsi que les résultats obtenus par le systeme dans le cadre de la compétition
SemEval 2007.

Abstract. In this paper, we describe the method we develop in order to solve Named entity
metonymy in the framework of the SemEval 2007 competition. In order to perform Named
Entity metonymy resolution on location names and company names, as required for this task,
we developed a hybrid system based on the use of a robust parser that extracts deep syntactic
relations combined with a non supervised distributional approach, also relying on the relations
extracted by the parser. We describe this methodology as well as the results obtained at SemEval
2007

M0tS-CléS I Entités Nommées, métonymie, méthode hybride, analyse syntaxique ro-
buste, approche distributionnelle.

Keywords: Named Entities, metonymy, hybrid method, robust parsing, distributional
approach.

Caroline Brun, Maud Ehrmann, Guillaume J acquet

1 Introduction

Le traitement des entites nommees fait aujourd’hui ﬁgure d’incontoumable en Traitement Au-
tomatique des Langues (TAL). Apparue au milieu des annees 1990 a la faveur des dernieres
conferences MUC (Message Understanding Conferences, (MUC, 1995) et (MUC, 1998)), la
tache de reconnaissance et de categorisation des noms de personnes, de lieux, d’organisations,
etc. apparait en effet comme fondamentale pour diverses applications participant de l’analyse de
contenu et nombreux sont les travaux se consacrant a sa Inise en oeuvre, obtenant des resultats
plus qu’honorables (F-mesurel depassant generalement 0.9), et ce pour diverses langues. Fort
de ce succes, le traitement des entites nommees s’oriente desormais vers de nouvelles perspec-
tives avec, entre autres, la categorisation ﬁne (Ehrmann & Jacquet, 2006), la normalisation et
la desambiguisation. En effet, a l’instar des autres unites lexicales, plusieurs phenomenes de
glissement ou de superposition de sens peuvent avoir lieu au regard des entites nommees et
il importe de pouvoir les resoudre aﬁn de traiter au Inieux ces unites. Nous nous interessons
plus particulierement a la metonymie des entites nommees et presentons dans cet article une
methode hybride pour la resolution de ce type particulier de polysemie.

La premiere section reviendra tout d’ abord sur la deﬁnition et la caracterisation de la metonymie
des entites nommees. La suivante presentera rapidement la campagne d’evaluation SemEval
(Semantic Evaluation), dans le cadre de laquelle les travaux ici presentes ont ete realises et
evalues, puis la troiseme section s’attachera a decrire le systeme mis au point. Enﬁn, la demiere
section rendra compte de l’evaluation.

2 La metonymie des entités nommmées

La metonymie correspond au fait d’employer un mot (par exemple, le mot re’c0lte) attache a
une certaine entite (l’action de recolter) pour en designer une autre (les produits recueillis), la
seconde etant liee a la premiere par une relation de type partie-tout ou une relation fonctionnelle
(ici relation de cause a effet). Si la metonymie permet un nombre indeﬁni de glissements de sens,
il existe neanmoins des changements de sens reguliers ou systematiques, au regard notamment
des entites nommees. Examinons les exemples suivants :

La politique américaine est plombée par Z ’Irak.
La France a gagné en demi-ﬁnale.

Dans la premiere phrase, il n’est bien sﬁr pas question du pays proprement dit mais de l’evene-
ment qui s’y deroule, tout comme dans la seconde ou il s’agit non pas de la France en tant que
telle mais d’une equipe sportive frangaise. Cet usage des unites Irak et France en tant qu’eve-
nement et equipe sportive respectivement est possible pour d’autres noms de pays dans des
situations similaires. Il existe bien d’autres exemples possibles, sur lesquels nous reviendrons
par la suite, mais il est d’ores et deja possible de postuler une certaine regularite et productivite
des phenomenes de metonymie pour les entites nommees.

Outre ces caracteristiques, des etudes conduites par K. Markert, U. Hahn et M. Nissim (Markert
& Hahn, 2002), (Markert & Nissim, 2006) ont fait etat de la frequence de ce phenomene, mon-
trant que 17% de l’ensemble des occurrences dans un corpus de 27 magazines allemands etaient

1Moyenne harmonique de la precision et du rappel : : (2 x precision >< rappel)/(precision + rappel).

Résolution de Métonymie des Entités Nommées : proposition d’une méthode hybride

métonymiques, tout come 20% des occurrences des noms de pays et 30% de celles des noms
d’organisation sur des extraits signiﬁcatifs du British National Corpus. Réguliere, productive et
fréquente, la métonymie des entités nommées constitue ainsi un réel intérét pour le traitement
automatique des langues.

3 Résolution de métonymie pour la campagne SemEval

La campagne SemEval2007 proposait 18 taches d’évaluations autour de problemes sémantiques
tels que la désambigu'1'sation de prépositions, l’annotation d’expressions et de relations tempo-
relles (TempEval) ou encore la désambiguisation des noms de personne sur le web (Web People
Search). La tache proposée par K. Markert et M. Nissim est une tache lexicale sur l’anglais, por-
tant plus précisément sur la résolution de métonymie pour deux classes sémantiques, la classe
LOCATION avec des noms de lieux et la classe ORGANISATION avec des noms d’entreprises.
L’ objectif pour les participants est de classer automatiquement des occurences pré-sélectionnées
et en contexte de noms de lieux et d’entreprises, et ce en fonction de leur interprétation litérale
ou non-litérale. Cette premiere alternative correspond a l’annotation “ gros grain” ou coarse-
grained annotation. Deux autres niveaux d’annotation sont possibles : un niveau “ moyen ” (me-
dium) pour lequel il faut faire la distinction entre des interprétations litérales, métonymiques et
mixtes et, enﬁn, un niveau “ﬁn” (ﬁne), pour lequel il importe de préciser, en cas d’interpré-
tation métonymique, le patron métonymique dont il est question. A titre d’illustration, nous
pouvons reprendre les exemples donnés par les organisatrices dans le document décrivant la
tache (Markert & Nissim, 2007) :

At the time of Vietnam, increased spending led to inﬂation.
BMW slipped 4p to 31 p.
The BMW slowed down.

Pour la premiere phrase, le nom Wetnam ne renvoie pas au pays mais a la guerre qui s’y est
déroulée, il convient donc d’annoter cette entité comme non—literal (niveau 1), come
metonymic (niveau 2) ou comme place—for—event (niveau 3). De meme, les occur-
rences de BMW dans les exemples suivants ne renvoient pas a l’entreprise mais a l’action de
l’entreprise pour la premiere (org—for—index) et au produit de cette entreprise pour la se-
conde (org—for—product) . Les trois niveaux d’annotation pour les noms d’entreprise et
pour les noms de pays sont représentés ci-apres dans le tableau 12 .

4 Un systéme de résolution de métonymie pour les EN

Notre participation a la tache de résolution de métonymie pour les noms de pays et d’entreprises
(Brun et al., 2007) a consisté en l’élaboration d’un systeme automatique hybride reposant sur la
combinaison d’un composant symbolique et d’un composant distributionnel. Nous présenterons
successivement ces deux composants.

2DaVantage de précisions sur les catégories d’annotation (ou patrons métonymiques) sont disponibles dans
(Markert & Nissim, 2007).

Caroline Brun, Maud Ehrmann, Guillaume J acquet

coarse medium ﬁne
literal literal literal
mixed mixed
Othermet

Object—for—name
Categorie I ORGANISATION Ob j ect — fOr—represent at i on

nOn—literal _ OrganisatiOn—for—members
metonymic

Organisation—fOr—event

OrganisatiOn—for—prOduct

organisatiOn—for—facility

OrganisatiOn—for—index

coarse medium ﬁne

literal literal literal
mixed mixed

Othermet
Categorie 2 LOCATION Object—for—name

non—literal _ Object—fOr—representatiOn

metonymic

place—for—people

place—fOr—event

place—for—product

TAB. 1 — Niveaux de granularite et categories d’annotation pour les classes ORGANISATION et
LOCAHON.

4.1 Composant symbolique

Analyse syntaxique robuste avec XIP L’element fondamental sur lequel repose notre ap-
proche est l’analyseur syntaxique robuste XIP (Ai't-Mokhtar & Chanod, 1997), (Ai't-Mokhtar
et al. , 2002). Xerox Incremental Parser prend en entree du texte tout venant et produit en sortie
de facon robuste une analyse syntaxique profonde. A partir d’un ensemble de regles, l’ana-
lyseur est capable de faire de la desambiguisation de categories, de construire des syntagmes
noyaux et d’extraire des relations de dependances syntaxiques entre unites lexicales simples
et/ou complexes. En plus de l’analyse des relations syntaxiques de surface, XIP effectue egale-
ment une analyse syntaxique dite “profonde ” ou “normalisee ” (prise en compte des sujets et
objets de verbes non ﬁnis, normalisation de la forme passive en forme active, etc (Hagege &
Roux, 2003)), l’eXploitation d’information de semantique lexicale, avec les classes verbales de
Levin (Levin, 1993) et quelques elements de Framenet (Ruppenhofer et al., 2006). Ci-dessous
un exemple de sortie XIP (avec l’arbre des chunks et les relations de dependance) pour la phrase
suivante :

Iran wanted the two centers to generate part of its electricity needs. TOP { sc{ NP{ Iran} FV{wanted}}
NP{the two centers}IV{to generate}NP{part}PP{OfNP{its electricity needs}}}

MOD_PRE(needs,electricity) SUBLN(generate,centers)
LOCATION (I ran) EXPERIENCER-PRE(wanted, I ran)
CONTENNManted,centers) OB}¢Kgenerate,needs)

Résolution de Métonymie des Entités Nommées : proposition d’une méthode hybride

L’analyseur décrit ci-dessus contient déja un module de reconnaissance d’entités nommées
(Brun & Hagege, 2004), mais ce dernier ne permet pas le traitement de la métonymie ; il a
fallu procéder a son adaptation.

Adaptation in la téiche de résolution de métonymie Pour ce faire, nous avons étudié les cor-
pus d’entrainement a l’aide de XIP, en tenant compte des directives d’annotation. Pour les noms
de pays et d’entreprises, notre attention s’est focalisée sur les types de relations grammaticales
dans lesquelles étaient impliquées les unités a étudier et sur les informations lexicales ou se-
mantiques attachées aux arguments de ces relations. Pour chaque patron métonymique, nous
avons donc analysé l’ensemble de ses occurrences (attachées a une unité lexicale) dans le cor-
pus d’entrainement pour dégager des conﬁgurations grammaticales et lexicales jouant le role d’
“ amorces ” d’interprétations métonymiques.

Au terme de cette étude de corpus, il fut possible de prendre en compte l’ensemble des indices
récoltés et d’élaborer un module de résolution de métonymie dans XIP. Intervenant a la ﬁn de
la chaine de traitements de l’analyseur, cette adaptation consiste en l’écriture de regles tradui-
sant les conﬁgurations discriminantes relevées pour tel ou tel patron d’une part, et a l’ajout de
lexique d’autre part. A titre d’exemple, prenons l’hypothese suivante : “Si un nom de pays est
sujet d ’un verbe renvoyant a une action économique, alors le patron loc—for—people doit
s’appliquer” ; cette hypothese se retrouve dans XIP sous la forme de regle :

if (LocATIoN(#1) & SUBJ-N (#2[v_econ],#1))
LOC-FOR-PEOPLE (#1)

Regle qui se lit ainsi : si le parseur a détecté un nom de pays (#1) qui est le sujet d’un verbe (#2)
portant le trait “ v_econ ”, alors il créée un relation unaire LOC-FOR-PEOPLE pour le nom de

pays.

En sus des indices récoltés lors de l’étude de corpus, nous avons exploité des informations lexi-
cales déja codées dans XIP, comme par exemple les traits attachés aux verbes de communication
(say, deny, comment) et les catégories relevant du cadre “experiencer” de Framenet, a savoir
des verbes tels que feel, sense, see, les noms despair, compassion, adoration ou les adjectifs syn-
pathetic, sad, etc. En effet, eu égard au fait que ce cadre “ experiencer ” renvoie a des personnes
ou a des groupes de personnes, des lors qu’un nom de pays ou d’entreprise a ce role, il peut étre
annoté en tant que loc—for—people ou organisation—for—members. Ci-dessous un
exemple de sortie de l’analyseur avec le nouveau développement :

It was the largest Fiat everyone had ever seen.

ORG_FOR_PRODUCT (Fiat) MOD_PRE (seen, ever)
SUB]-N_PRE (was, It) ATTRIB(It, Fiat)
EXPERIENCER_PRE(seen, everyone) QUALIF(Fiat , largest)

Dans cet exemple, la présence de la relation QUALIF entre le nom d’entreprise Fiat et l’ad-
jectif largest, renforcée par la présence d’un article déﬁni, conduit a l’annotation en tant que
0RG_FOR_PRODUCT. Ce composant symbolique constitue le premier volet de notre méthode
de résolution de métonymie, il est complété par un composant distributionnel, qu’il convient a
present de détailler.

Caroline Brun, Maud Ehrmann, Guillaume J acquet

4.2 Composant distributionnel

Intervient en “ deuxieme passe ” de notre systeme, un composant distributionnel. L’ idée princi-
pale de cette combinaison est d’exploiter deux méthodes relevant d’approches différentes mais
complémentaires, autrement dit de pallier les manquements de l’analyse symbolique, focalisée
sur des données précises nécessitant une étude Ininutieuse, par une analyse distributionnelle,
apte a récolter des informations a grande échelle sur d’importantes données textuelles. Le prin-
cipe est donc, lorsqu’une unité n’a pu étre traitée par le composant symbolique, d’essayer de
trouver son annotation en exploitant les informations présentes a propos de cette unité ou d’une
unité de meme type dans un grand corpus. Nous présentons rapidement l’analyse distribution-
nelle avant de détailler sa Inise en oeuvre pour la résolution de métonymie.

L’analyse distributionnelle La notion d’analyse distributionnelle a été introduite par Z. S.
Harris. En linguistique de corpus, cette méthode est aujourd’hui largement exploitée, notam-
ment dans les travaux de terminologie, de structuration de terminologie et de construction
d’ontologies (Faure & Nedellec, 1999) (Assadi, 1998) (Bourigault, 2002). L’hypothese est la
suivante : il serait possible, a partir de régularités syntaxiques observées pour un ensemble de
mots, de déduire des propriétés sémantiques pour ces mots. Concretement, il s’agit d’étudier
la distribution des mots, c’est a dire les contextes lexico-syntaxiques dans lesquels ils appa-
raissent, pour ensuite tenter de dégager des parentés sémantiques. S’inscrivant dans ce cadre,
G. J acquet et F. Venant ont élaboré une méthode automatique de désambiguisation du sens d’un
mot en contexte, reposant sur la prise en compte de l’inﬂuence des éléments syntaxiques et
lexicaux présents dans l’énoncé (Jacquet & Venant, 2003). Ainsi, il ne cherchent plus seule-
ment a créer des classes de mots relevant du méme champ sémantique “mais des classes de
mots dont le comportement sémantique inﬂuence de la meme facon un contexte d0nne”’. Le
composant distributionnel élaboré pour la résolution de métonymie s’inscrit dans la perspective
de ces travaux.

Méthode distributionnelle pour la résolution de métonymie L’ objectif ici est de rappro-
cher des contextes et d’exploiter les résultats du composant symbolique. Cette méthode com-
porte deux processus. Il s’agit d’une part de constr11ire un espace distributionnel pour étre en
mesure de rapprocher des contextes en fonction d’une entité donnée et, d’autre part, de capitali-
ser l’information du composant symbolique sous la forme d’une sorte de “ base de donnée ” de
contextes avec annotation. Nous détaillons ces deux processus successivement.

Construction de l’espace distributionnel et rapprochement des contextes Ce premier pro-
cessus comporte 5 étapes. Le point de départ est le corpus BNC dans son entier (100 millions
de mots), duquel on été extraits les corpus d’entrainement et de test de la tache de résolution de
métonymie.

La premiere étape correspond a l’analyse syntaxique de ce corpus (a l’aide de l’analyseur XIP)
aﬁn d’en extraire des dépendances syntaxiques. C’est a partir de ces dépendances que sont
construits les contextes et les unités lexicales. Prenons un exemple, avec la proposition provide
Albania with food aid. Les dépendances extraites par XIP sont les suivantes :

IND-OBJ-N3(VERB :provide,NOUN :Albania)
PREP_WITH(VERB :provide,NOUN :aid)

31a relation ind—obj—n correspond a la relation syntaxique objet indirect.

Résolution de Métonymie des Entités Nommées : proposition d’une méthode hybride

PREP_WITH(VERB :provide,NOUN :food aid)

on l’on peut voir que les arguments des dépendances sont de simples unités lexicales (aid) ou
des syntagmes (food aid).

La deuxieme étape de ce processus est la construction d’un espace distributionnel a partir de
ces dépendances. Cet espace distributionnel est l’inverse de celui habituellement construit en
analyse distributionnelle : puisque l’objectif est de rapprocher des contextes, chaque point de
l’espace est une contexte syntaxique et chaque dimension est une unité lexicale. Cet inversion
constitue une premiere différence avec l’approche de G. J acquet et F. Venant (J acquet & Venant,
2003). Chaque dépendance obtenue lors de l’étape précédente permet de construire plusieurs
contextes simples et/ou composés. Un contexte syntaxique comporte une relation et une unité
lexicale. La méthode prévoit également de construire des contextes composés (autre différence
par rapport a (J acquet & Venant, 2003)), soit des contextes combinant plusieurs contextes, dont
le premier comporte nécessairement un syntagme verbal et le second a pour recteur ce méme
syntagme. Pour la phrase analysée ci-dessus, les unités lexicales, les contextes simples (1. pour
recteur et 2. pour régi) et les contextes composés sont les suivants :

Unités lexicales Contextes simples Contextes composés

VERB zprovide l.VERB :provide.IND-OB]-N l.VERB :provide.IND-OB]-N + 2.NoUN : aid.PREP_WITH
NOUN :1-Xlbania l.VERB :provide.PREP_w1TH l.VERB :provide.IND-OB]-N + 2.NoUN :aid.PREP_WITH

NOUN zaid 2.NoUN :1-\lbania.IND-OB]-N l.VERB :provide.IND-OB]-N + 2.NoUN :food aid.PREP_WITH
NOUN :food aid 2.NoUN :aid.PREP_WITH l.VERB :provide.PREP_w1TH + 2.NoUN :Albania.IND-OBJ-N

2.NoUN :food aid.PREP_WITH

Une heuristique permet de ﬁltrer ces données en fonction de leur productivité : chaque unité
lexicale doit étre présente au moins 100 fois dans le corpus, tout comme les contextes (y compris
les contextes composés). Avec le corpus BNC de 100 millions de mots, on obtient au ﬁnal 60 849
unités lexicales et 140 634 contextes. Il est donc possible de construire un espace distributionnel
comportant 140 634 points (les contextes) et 60 849 dimensions (les unités lexicales). Cet espace
est le matériau de base a partir duquel les autres traitements viennent s’effectuer.

A partir de la troisieme étape intervient la prise en compte d’une unité lexicale précise, pour
laquelle le composant symbolique n’a pu trouver d’annotation. En fonction de cette unité et de
son contexte d’apparition (soit telle qu’elle apparait dans un extrait de SemEval), il s’agit tout
d’abord de construire un sous-espace, de la maniere suivante :

Pour un couple donné formé d’un contexte i et d’une unité lexicale j :

— Le sous-espace des contextes équivaut a la liste des contextes occurrant avec l’unité lexicale
j. S’il y a plus de k contextes, alors on ne garde que ces k contextes les plus fréquents ;

— Le sous-espace des dimensions équivaut a la liste des unités lexicales occurrant avec au moins
un des contextes du sous-espace des contextes. S’il y a plus de 11 unités, alors on ne garde que
ces n unités les plus fréquentes.

La quatrieme étape consiste a réduire les dimensions de ce sous-espace, a l’aide d’une analyse
factorielle des correspondances (AFC ; équivaut a une ACP avec la métrique du Chi2).

Enﬁn, la cinquieme étape consiste a rapprocher les contextes restants, c’est a dire ayant passés
le ﬁltre des deux étapes précédentes. Ce rapprochement est calculé a l’aide de la distance eucli-
dienne. On obtient ainsi, au ﬁnal, une liste des contextes proches de celui de l’unité considérée.

Caroline Brun, Maud Ehrmann, Guillaume J acquet

Pour l’unité Albania dans le contexte provide, les contextes les plus proches sont présentés dans
la premiere colonne du tableau 2.

Pour pouvoir utiliser cette liste de contextes, encore faut-il savoir s’ils ont recu ou non une
annotation par le composant symbolique. Intervient alors le second processus.

Capitalisation de l’information du composant symbolique Ce second processus a pour ob-
jectif de construire une sorte de base de données de contextes avec annotations. Deux étapes
sont nécessaires. Le corpus est analysé BNC avec XIP, augmenté cette fois-ci du module de ré-
solution de métonymie. Cette analyse permet d’obtenir des dépendances syntaxiques mettant en
jeu des noms de pays et des noms d’entreprise avec leurs annotation métonymique (application
du module de résolution de métonymie sur les entités nommées reconnues par l’analyseur, inde-
pendamment des données de SemEval). Le résultat de cette premiere étape est donc une série de
contextes impliquant des unités lexicales avec leur annotation. La deuxieme étape correspond
a la sélection de contextes discriminants au regard des annotations. Par exemple, si le contexte
VERB :al low.IND-OBJ-N se retrouve pour 10% des cas avec une unité comportant l’annotation
1 it e ral et pour 90% des autres avec une unité comportant l’annotation loc— f or—people,
alors le contexte est considéré comme discriminant vis-a-vis de cette derniere annotation. En
revanche, si un contexte se trouve dans 50% des cas avec telle annotation et 50% des cas avec
telle autre, alors il n’est pas conservé. A l’issue de cette sélection de contextes discriminants, on
dispose alors d’un stock de contextes avec leurs annotations, pouvant étre exploité en parallele
avec le processus précédent.

Annotation d’une unité Le premier processus permet de déterminer une liste de contextes
plus ou moins proches du contexte dans lequel apparait une unité lexicale non annotée. Le
second permet de collecter un certain nombre de contextes avec leur annotation. Ces deux types
de données peuvent des lors étre croisées pour permettre l’annotation d’une unité.

Ci-dessous (tableau de gauche) la liste de contextes proches du contexte VERB :provide.IND-
OBJ-N pour la proposition provide Albania with food aid, avec l’indication de leur distance et
de leur annotation correspondante dans la base de données de contextes :

Contexte Distance Annotation

VERB :provide.IND-OBJ-N 0.00

VERB :allow.OBJ-N 0.76 LOC-FOR-PEOPLE

VERB :include.OBJ-N 0.96 Annotation Score
ADJ :new.MOD_PRE 1.02 LOC-FOR-PEOPLE 3.11
VERB :be.SUBJ-N 1.43 LITERAL 1.23
VERB :supply.SUBJ-N_PRE 1.47 LITERAL LOC-FOR-EVENT 0.00
VERB :become.SUBJ-N_PRE 1.64

VERB :come.SUBJ-N_PRE 1.69

VERB :support.SUBJ-N_PRE 1.70 LOC-FOR-PEOPLE

TAB. 2 — Listes des contextes les plus proches de VERB :provide.IND-OBJ-N et Scores des almotations.

Pour pouvoir déterminer une annotation pour le contexte p rovi de .IND-OBJ -N, il faut regarder
les annotations attribuées a ses contextes les plus proches et examiner si elles sont pertinentes
ou non. Pour ce faire, il importe de calculer un score pour chaque annotation, valorisant sa

Résolution de Métonymie des Entités Nommées : proposition d’une méthode hybride

présence dans les contextes de “téte de liste : le score d’une annotation donnée est égal a
l’inverse de la somme des distances des contextes portant cette annotation. Pour notre cas, les
scores sont présentés dans le tableau ci-dessus a gauche ; il est alors possible, en fonction de ces
scores, d’attribuer l’annotation LOC-FOR-PEOPLE a l’unité Albania dans la proposition provide
Albania with food aid.

5 Evaluation et analyse des résultats

Ci-dessous les taux de précisions pour l’ensemble des participants pour les noms de lieux (ta-
bleau 3) et les noms d’entreprises (tableau 4).

Systemes _
A baseline up13 FUH UTD-HLT-CG XRCE-M GYDER
T ache
LOCATION-coarse 0.794 0.754 0.778 0.841 0.851 0.852
LOCATION-medium 0.794 0.750 0.772 0.840 0.848 0.848
LOCATION-ﬁne 0.794 0.741 0.759 0.822 0.841 0.844

TAB. 3 — Taux de Précision pour tous les systemes pour la classe LOCATION.

Systemes _
A baseline XRCE-M UTD—HLT—CG GYDER
T ache
ORGANISATION-coarse 0.618 0.732 0.739 0.767
ORGANISATION-medium 0.618 0.711 0.711 0.733
ORGANISATION-ﬁne 0.618 0.700 0.711 0.728

TAB. 4 — Taux de Précision pour tous les systemes pour la classe ORGANISATION.

Malgré certaines imperfections, XRCE-M est relativement bien placé au sein des autres systemes
ayant participé a l’évaluation (cf tableaux 3 et 4), avec notamment une seule erreur de plus
pour la classe LOCATION par rapport au systeme le plus performant GYDER. Cinq systemes
ont participé a la tache sur les LOCATION et trois a celle sur les ORGANISATION, pour tous les
niveaux de granularité a chaque fois. Hormis XRCE-M, les systemes reposaient sur des méthodes
statistiques par apprentissage, mais surtout, notre systeme est le seul a ne pas avoir utilisé les
annotations syntaxiques manuelles fournies par les organisatrices. Deux systemes ne sont pas
parvenus a atteindre la baseline pour les noms de lieux.

6 Conclusion

Dans cet article, nous avons décrit un systeme hybride pour la résolution de métonymies. Notre
approche, quoique perfectible, a d’ores et déja montré des résultats encourangeants lors de la
compétition SemEval. Les perspectives de développement sont nombreuses, pour notre systeme
tout comme pour la tache de résolution de métonymie en general. A notre échelle, nous envi-
sageons de poursuivre le travail entrepris aﬁn d’améliorer les performances du systeme pour
les glissement de sens déja pris en compte et d’étendre ce traitement a d’autres types d’entités
nommees.

Caroline Brun, Maud Ehrmann, Guillaume J acquet

Références

(1995). M UC-6. Proceedings of the Sixth Message Understanding Conference. Informations
disponibles a l’adresse suivante : http ://www.cs.nyu.edu/cs/faculty/grishman/muc6.html.

(1998). M UC-7. Proceedings of the Seventh Message Understanding Conference. Informa-
tions disponibles a l’adresse suivante : http ://www-nlpir.nist.gov/related_projects/muc/.

ASSADI H. (1998). Construction d ’ontologies a partir de textes techniques. Application aux
systemes documentaires. PhD thesis, Université Paris VI.

AIT-MOKHTAR S. & CHANOD J. P. (1997). Incremental ﬁnite-state parsing. In Proceedings
of Applied Natural Language Processing, Washington, DC.

AIT-MOKHTAR S., CHANOD J. P. & ROUX C. (2002). Robustness beyond shallowness :
incremental dependency parsing. NLE Journal.

BOURIGAULT D. (2002). Upery : un outil d’analyse distributionnelle étendue pour la construc-
tion d’ontologies a partir de corpus. In Actes de TALN 2002, Nancy.

BRUN C., EHRMANN M. & JACQUET G. (2007). XRCE-M : A hybrid system for named
entity metonymy resolution. In 4th International Workshop on Semantic Evaluations, Prague :
ACL-SemEval 2007.

BRUN C. & HAGEGE C. (2004). Intertwining deep syntactic processing and named entity
detection. In ESTAL, Alicante, Espagne.

EHRMANN M. & JACQUET G. (2006). Vers une double annotation des entités nommées.
Traitement Automatique des Langues, 47(3). Disponible sur : http ://www.atala.org.

FAURE D. & NEDELLEC C. (1999). Knowledge acquisition of predicate argument structures
from technical texts using machine learning : the system asium. In Poceeedings of the I I th
European Workshop, Knowledge Acquisition, Modelling and Managment (EKAW’99), Juan-
les-Pins, France.

HAGEGE C. & ROUX C. (2003). Entre syntaxe et sémantique : Normalisation de la sortie de
l’analyse syntaxique en vue de l’amélioration de l’eXtraction d’information a partir de textes.
In TALN 2003, Batz-sur-Mer.

JACQUET G. & VENANT F. (2003). Construction automatique de classes de sélection dis-
tributionnelle. In Actes de la I Oeme confe’rence annuelle sur le Traitement Automatique des
Langues (TALN 2003), Dourdan, France.

LEVIN B. (1993). English Verb Classes and Alternations - A Preliminary Investigation. The
University of Chicago Press,.

MARKERT K. & HAHN U. (2002). Understanding metonymies in discourse. Artiﬁcial Intel-
ligence, 135(1/2), 145-198.

MARKERT K. & NISSIM M. (2006). Metonymic proper names : a corpus based account. In A.
STEFANOWITSCH & S. GRIES, Eds., Corpus-based approaches to Metaphor and Metonymy,
p. 152-174. Mouton de Gruyter.

MARKERT K. & NISSIM M. (2007). Metonymy Resolution at SemEval I .' Guidelines for
Participants. Rapport interne, SemEval.

RUPPENHOFER J ., ELLSWORTH M., PETRUCK M., JOHNSON C. & SCHEFFCZYK J . (2006).
Framenet II .' Extended Theory and Practice. Rapport interne, University of Berkeley. Dispo-
nible sur : http ://framenet.icsi.berkeley.edu/.

