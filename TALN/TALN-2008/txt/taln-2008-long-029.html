<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Influence de la qualit&#233; de l&#8217;&#233;tiquetage sur le chunking : une corr&#233;lation d&#233;pendant de la taille des chunks</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2008, Avignon, 9&#8211;13 juin 2008
</p>
<p>Influence de la qualit&#233; de l&#8217;&#233;tiquetage sur le chunking : une
corr&#233;lation d&#233;pendant de la taille des chunks
</p>
<p>Philippe Blache, St&#233;phane Rauzy
Laboratoire Parole et Langage
</p>
<p>CNRS &amp; Universit&#233; de Provence
philippe.blache@lpl-aix.fr, stephane.rauzy@lpl-aix.fr
</p>
<p>R&#233;sum&#233;. Nous montrons dans cet article qu&#8217;il existe une corr&#233;lation &#233;troite existant entre
la qualit&#233; de l&#8217;&#233;tiquetage morpho-syntaxique et les performances des chunkers. Cette corr&#233;lation
devient lin&#233;aire lorsque la taille des chunks est limit&#233;e. Nous appuyons notre d&#233;monstration
sur la base d&#8217;une exp&#233;rimentation conduite suite &#224; la campagne d&#8217;&#233;valuation Passage 2007
(de la Clergerie et al., 2008). Nous analysons pour cela les comportements de deux analyseurs
ayant particip&#233; &#224; cette campagne. L&#8217;interpr&#233;tation des r&#233;sultats montre que la t&#226;che de chunking,
lorsqu&#8217;elle vise des chunks courts, peut &#234;tre assimil&#233;e &#224; une t&#226;che de &#8220;super-&#233;tiquetage&#8221;.
</p>
<p>Abstract. We show in this paper that a strong correlation exists between the performance
of chunk parsers and the quality of the tagging task in input. This dependency becomes linear
when the size of the chunks is small. Our demonstration is based on an experiment conducted at
the end of the Passage 2007 shared task evaluation initiative (de la Clergerie et al., 2008). The
performance of two parsers which took part in this evaluation has been investigated. The results
indicate that the chunking task, for sufficiently short chunks, is similar to a super-tagging task.
</p>
<p>Mots-cl&#233;s : Analyse syntaxique, &#233;tiquetage morphosyntaxique, analyseur stochastique,
analyseur symbolique superficiel, chunker.
</p>
<p>Keywords: Parsing, tagging, stochastic parser, symbolic shallow parser, chunker.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Blache, St&#233;phane Rauzy
</p>
<p>1 Introduction
</p>
<p>La qualit&#233; de l&#8217;&#233;tiquetage morpho-syntaxique a bien &#233;videmment des cons&#233;quences directes sur
les r&#233;sultats des analyseurs syntaxiques. Mais l&#8217;importance de cette relation d&#233;pend &#233;galement
de la t&#226;che fix&#233;e : les performances d&#8217;un chunker sont en effet plus directement li&#233;es &#224; celle
de l&#8217;&#233;tiqueteur qu&#8217;un analyseur syntaxique profond. Nous montrons dans cet article qu&#8217;il existe
en fait une corr&#233;lation lin&#233;aire entre la t&#226;che de chunking et celle d&#8217;&#233;tiquetage et que cette
corr&#233;lation d&#233;pend du type de chunk vis&#233; par la t&#226;che.
</p>
<p>Nous nous appuyons dans cet article sur les r&#233;sultats que nous avons obtenus dans le cadre de la
campagne d&#8217;&#233;valuation Passage 20071 (de la Clergerie et al., 2008) qui est une continuation de
la campagne Easy (Paroubek et al., 2006). Ces campagnes ont permis une &#233;valuation compara-
tive de plusieurs analyseurs syntaxiques du fran&#231;ais en s&#8217;appuyant sur un format d&#8217;annotation
ad hoc (le guide d&#8217;annotation PEAS (Gendner et al., 2003)) proposant des unit&#233;s syntaxiques
plates (i.e. sans constituants embo&#238;t&#233;s). Deux &#233;valuations distinctes &#233;taient propos&#233;es durant ces
campagnes, l&#8217;une portant sur la t&#226;che de formation et d&#8217;identification des groupes syntaxiques,
l&#8217;autre consistant &#224; &#233;tablir les relations de d&#233;pendance entre les groupes obtenus. Nous nous
concentrons dans cet article sur la premi&#232;re t&#226;che qui correspond ici &#224; un probl&#232;me classique de
chunking : il s&#8217;agit de rep&#233;rer les types et fronti&#232;res des constituants de niveau 1. Nous avons
test&#233; dans le cadre de la derni&#232;re campagne deux analyseurs, l&#8217;un utilisant des techniques num&#233;-
riques (il s&#8217;agit d&#8217;un des premiers analyseurs stochastiques pour le fran&#231;ais), l&#8217;autre &#233;tant bas&#233;
sur une approche symbolique. Tous deux ont obtenu des r&#233;sultats tr&#232;s satisfaisants, l&#8217;analyseur
stochastique se situant dans le trio de t&#234;te des analyseurs &#233;valu&#233;s durant la campagne Passage
2007. Ces deux analyseurs prennent en entr&#233;e un texte &#233;tiquet&#233; d&#233;sambigu&#239;s&#233;.
</p>
<p>Pour montrer la corr&#233;lation entre &#233;tiquetage et chunking, nous proposons de faire varier de
fa&#231;on contr&#244;l&#233;e la qualit&#233; de l&#8217;&#233;tiquetage fourni en entr&#233;e et d&#8217;observer les cons&#233;quences sur les
r&#233;sultats des analyseurs.
</p>
<p>La premi&#232;re partie de cet article pr&#233;sente notre m&#233;thode d&#8217;&#233;tiquetage et les diff&#233;rentes tech-
niques utilis&#233;es permettant le contr&#244;le de la variation du r&#233;sultat. La seconde partie d&#233;crit les
deux analyseurs &#233;tudi&#233;s. La troisi&#232;me partie pr&#233;sente les r&#233;sultats obtenus par nos analyseurs
en fonction de la qualit&#233; de l&#8217;entr&#233;e propos&#233;e. La derni&#232;re partie est consacr&#233;e &#224; l&#8217;interpr&#233;tation
des r&#233;sultats, montrant que la corr&#233;lation provient du type de chunk propos&#233; dans le cadre de
cette campagne.
</p>
<p>2 Etiquetage morphosyntaxique
</p>
<p>2.1 Segmentation et lexique
</p>
<p>L&#8217;objectif de cette t&#226;che est de segmenter en tokens le texte en entr&#233;e, puis d&#8217;associer &#224; chacun
des tokens de l&#8217;&#233;nonc&#233; la liste des cat&#233;gories morphosyntaxiques qui lui correspondent. Notre
segmenteur permet de r&#233;p&#233;rer les fronti&#232;res entre les tokens et d&#8217;identifier les entit&#233;s n&#233;cessitant
un traitement sp&#233;cial (nombres, dates, heures, noms propres, sigles, ...). Une fois les tokens for-
m&#233;s, la liste des cat&#233;gories morphosyntaxiques correspondant &#224; une graphie donn&#233;e est obtenue
par acc&#232;s au lexique.
</p>
<p>1Le lien vers l&#8217;action Passage : http ://atoll.inria.fr/passage/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Analyse syntaxique et &#233;valuation
</p>
<p>Nous utilisons dans cette &#233;tude le lexique DicoLPL (Vanrullen et al., 2005). Il s&#8217;agit d&#8217;un
lexique assez couvrant du fran&#231;ais (440 000 formes) qui est de plus enrichi par la donn&#233;e des
fr&#233;quences lexicales pour chacune des formes (ie. le couple graphie et cat&#233;gorie morphosyn-
taxique). Ces fr&#233;quences lexicales sont extraites d&#8217;un corpus de textes &#233;crits d&#8217;environ 150 mil-
lion de mots pr&#233;alablement &#233;tiquet&#233;, voir (Vanrullen et al., 2005) pour plus de d&#233;tails. L&#8217;infor-
mation sur les fr&#233;quences lexicales permet notamment de pr&#233;ciser la r&#233;partition entre cat&#233;gories
qui est sp&#233;cifique &#224; chaque graphie ambigu&#235;. Ainsi, la graphie dans est rencontr&#233;e dans le cor-
pus 1 056 924 fois sous forme de pr&#233;position contre 195 fois sous forme de nom commun, alors
que la graphie envers se distribue plus uniform&#233;ment (5 174 pour la pr&#233;position, 2 123 pour
le nom commun).
</p>
<p>2.2 D&#233;sambiguisation
</p>
<p>La proc&#233;dure de d&#233;sambiguisation consiste &#224; associer &#224; chacun des tokens de l&#8217;&#233;nonc&#233; une
cat&#233;gorie morphosyntaxique unique. Nous utilisons ici le mod&#232;le des patrons (Blache &amp; Rauzy,
2006; Blache &amp; Rauzy, 2007), un mod&#232;le de Markov cach&#233; (HMM) plus performant que les
mod&#232;les de type N-grammes. Pour les N-grammes, les &#233;tats de l&#8217;automate sont identifi&#233;s par
des s&#233;quences de cat&#233;gories de taille identique N . Le mod&#232;le des patrons rel&#226;che cette contrainte
en acceptant des &#233;tats identifi&#233;s par des s&#233;quences de longueur variable (voir par exemple (Ron
et al., 1996)). Cette caract&#233;ristique permet en pratique d&#8217;extraire du corpus d&#8217;apprentissage un
ensemble d&#8217;&#233;tats, les patrons du mod&#232;le, qui capture de fa&#231;on optimale l&#8217;information contenue
dans le corpus.
</p>
<p>Le mod&#232;le est entrain&#233; sur le corpus Grace/Multitag (Paroubek &amp; Rajman, 2000), un &#233;chantillon
d&#8217;environ 700 000 mots annot&#233; morphosyntaxiquement selon le jeu de traits Multext (Ide &amp;
V&#233;ronis, 1994). Dans notre &#233;tude, l&#8217;information morphosyntaxique disponible est group&#233;e en
44 cat&#233;gories distinctes (2 types de cat&#233;gories pour les ponctuations, 1 pour les interjections,
2 pour les adjectifs, 2 pour les conjonctions, 1 pour les d&#233;terminants, 3 pour les noms, 8 pour
les auxiliaires, 4 pour les verbes, 5 pour les pr&#233;positions, 3 pour les adverbes et 11 pour les
pronoms). Les informations comme les traits d&#8217;accords en genre, nombre et personne ou le
temps des verbes ne sont pas exploit&#233;es dans la pr&#233;sente analyse.
</p>
<p>Afin d&#8217;&#233;tudier l&#8217;influence de la qualit&#233; de l&#8217;&#233;tiquetage sur la performance des analyseurs syn-
taxiques, plusieurs proc&#233;dures de d&#233;sambiguisation sont propos&#233;es :
</p>
<p>&#8211; RAW : Aucun mod&#232;le n&#8217;est dans ce cas appliqu&#233;. L&#8217;&#233;tiquette associ&#233;e &#224; chaque token est la
premi&#232;re entr&#233;e apparaissant dans la liste des cat&#233;gories propos&#233;es pour le token.
</p>
<p>&#8211; UNI : Le mod&#232;le unigramme est ici appliqu&#233;. Il donne la distribution de probabilit&#233; non
contextuelle des cat&#233;gories utilis&#233;es. Pour chaque token, l&#8217;&#233;tiquette retenue est celle poss&#233;-
dant la probabilit&#233; la plus forte parmi la liste des cat&#233;gories propos&#233;es.
</p>
<p>&#8211; RAW+F : Aucun mod&#232;le n&#8217;est appliqu&#233;, mais on prend en compte la distribution des fr&#233;-
quences lexicales dans la liste des cat&#233;gories associ&#233;es &#224; la graphie du token (cf. section 2.1).
L&#8217;&#233;tiquette retenue est la cat&#233;gorie pr&#233;sentant la fr&#233;quence lexicale maximale.
</p>
<p>&#8211; BIG : Un mod&#232;le de bigrammes est utilis&#233; (information sur les probabilit&#233;s des cat&#233;gories
conditionn&#233;es par la cat&#233;gorie pr&#233;c&#233;dente). Le mod&#232;le est alors d&#233;crit par 44 patrons, un pour
chacune des cat&#233;gories utilis&#233;es. Pour chaque &#233;nonc&#233;, l&#8217;&#233;tiquetage optimal est obtenu par
application de l&#8217;algorithme de Viterbi.
</p>
<p>&#8211; BIG+F : Le mod&#232;le de bigrammes est appliqu&#233; avec un sch&#233;ma de pond&#233;ration qui rend
compte des fr&#233;quences lexicales associ&#233;es &#224; chaque graphie de l&#8217;&#233;nonc&#233;.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Blache, St&#233;phane Rauzy
</p>
<p>&#8211; PM : Le mod&#232;le des patrons complet, compos&#233; de 3 053 patrons de taille variable (le plus
grand contexte dans la liste des patrons est compos&#233; d&#8217;une s&#233;quence de 6 cat&#233;gories). L&#8217;&#233;ti-
quetage optimal est obtenu par application de l&#8217;algorithme de Viterbi.
</p>
<p>&#8211; PM+F : Le mod&#232;le des patrons complet avec prise en compte des fr&#233;quences lexicales.
</p>
<p>2.3 Evaluation de l&#8217;&#233;tiquetage
</p>
<p>L&#8217;&#233;valuation de la qualit&#233; de l&#8217;&#233;tiquetage est ici r&#233;alis&#233;e en calculant les scores de pr&#233;cision, rap-
pel et F-Mesure sur l&#8217;&#233;chantillon de r&#233;f&#233;rence Grace/Multitag. Les erreurs affectant l&#8217;&#233;tiquetage
de la r&#233;f&#233;rence imposent un seuil maximum limite pour les scores d&#8217;&#233;valuation obtenus. Elles
proviennent de mani&#232;re g&#233;n&#233;rale d&#8217;une description incompl&#232;te, voire contradictoire, des r&#232;gles
d&#8217;annotation ou de fautes d&#8217;annotation sur la r&#233;f&#233;rence. Ces seuils limites sont fix&#233;s pour une
r&#233;f&#233;rence donn&#233;e. La valeur des scores est ensuite d&#233;pendante des erreurs provenant de chacun
des modules composant la cha&#238;ne de traitement :
</p>
<p>&#8211; Erreurs de segmentation
&#8211; Erreurs du lexique (entr&#233;es manquantes, incorrectes, incompl&#232;tes)
&#8211; Erreurs du mod&#232;le implant&#233; dans le module de d&#233;sambiguisation
</p>
<p>Model Precision Recall F-Measure
RAW 0.829 0.696 0.757
UNI 0.769 0.770 0.770
RAW+F 0.900 0.885 0.893
BIG 0.909 0.902 0.906
PM 0.927 0.923 0.925
BIG+F 0.933 0.926 0.929
PM+F 0.943 0.937 0.940
</p>
<p>FIG. 1 &#8211; La qualit&#233; de l&#8217;&#233;tiquetage
morphosyntaxique mesur&#233;e sur la r&#233;-
f&#233;rence Grace/Multitag en termes de
F-Mesure, pr&#233;cision et rappel pour les
sept mod&#232;les de d&#233;sambiguisation pr&#233;-
sent&#233;s section 2.2.
</p>
<p>Nous pr&#233;sentons figure 1 les r&#233;sultats de l&#8217;&#233;valuation des sept mod&#232;les propos&#233;s section 2.2. Les
sept mod&#232;les partagent les erreurs de segmentation et du lexique. Les valeurs des scores ne sont
pas absolues, elles d&#233;pendent de la finesse de description du syst&#232;me de cat&#233;gorisation adopt&#233;
(ici 44 cat&#233;gories). Nous pouvons remarquer l&#8217;influence de la prise en compte des fr&#233;quences
lexicales. Cette information de nature extra-syntaxique apporte un gain significatif quel que soit
le mod&#232;le consid&#233;r&#233;. Les F-Mesures de nos diff&#233;rents mod&#232;les couvrent l&#8217;intervalle [0.75, 0.95],
ce qui nous permettra section 4 d&#8217;&#233;tudier l&#8217;influence de la qualit&#233; de l&#8217;&#233;tiquetage sur les perfor-
mances de nos analyseurs syntaxiques dans cette gamme de valeurs.
</p>
<p>3 Analyse syntaxique superficielle
</p>
<p>3.1 L&#8217;analyseur stochastique StP1
</p>
<p>L&#8217;analyseur stochastique StP1, comme notre &#233;tiqueteur, est bas&#233; sur le mod&#232;le des patrons (voir
section 2.2). La phase d&#8217;apprentissage est effectu&#233;e sur le gold standard Easy, un corpus annot&#233;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Analyse syntaxique et &#233;valuation
</p>
<p>en constituants d&#8217;environ 100 000 mots qui a servi de r&#233;f&#233;rence pour la campagne d&#8217;&#233;valua-
tion Easy (Paroubek et al., 2006). La grammaire Easy compte six constituants (ie. les groupes
Easy GN, GP, NV, GA, PV et GR) faiblement hi&#233;rarchis&#233;s. Le corpus ne fournit pas les &#233;ti-
quettes des tokens composant les &#233;nonc&#233;s. Une phase pr&#233;alable d&#8217;&#233;tiquetage (en utilisant notre
mod&#232;le le plus performant PM+F, voir section 3.3) a donc &#233;t&#233; n&#233;cessaire pour produire notre
&#233;chantillon d&#8217;apprentissage. Le module d&#8217;apprentissage nous permet d&#8217;extraire de cet &#233;chan-
tillon 1080 patrons de taille variable identifi&#233;s par des s&#233;quences de cat&#233;gories terminales (les
cat&#233;gories morphosyntaxiques) ou non-terminales (les groupes Easy).
L&#8217;analyseur stochastique StP1 prend en entr&#233;e un texte &#233;tiquet&#233; et d&#233;sambiguis&#233; (c&#8217;est cette
option qui sera utilis&#233;e dans la suite de l&#8217;article), ou une liste de cat&#233;gories associ&#233;e &#224; chaque
token de l&#8217;&#233;nonc&#233; (ie. la sortie de la phase segmentation plus acc&#232;s au lexique). Pour chaque
&#233;nonc&#233;, l&#8217;algorithme de Viterbi permet d&#8217;ins&#233;rer les groupes Easy maximisant la probabilit&#233; de
l&#8217;&#233;nonc&#233;. Dans le cadre de la campagne Passage 2007, StP1 a obtenu une F-Mesure de 93.03 %.
</p>
<p>3.2 L&#8217;analyseur superficiel ShP1
</p>
<p>Il s&#8217;agit d&#8217;un analyseur symbolique d&#233;terministe. Il repose sur les Grammaires de Propri&#233;t&#233;s
avec une strat&#233;gie de coin gauche. La grammaire utilis&#233;e est compl&#232;te en ce sens qu&#8217;elle peut
&#234;tre utilis&#233;e indiff&#233;remment pour une analyse profonde ou superficielle (Balfourier et al., 2005).
La particularit&#233; de ShP1 est de s&#8217;appuyer sur un sous-ensemble de contraintes de la grammaire
(en particulier les propri&#233;t&#233;s de lin&#233;arit&#233; et de constituance) pour identifier les coins gauches. La
strat&#233;gie consiste &#224; rep&#233;rer &#224; partir des coins gauches la fronti&#232;re droite du chunk sur la base des
autres propri&#233;t&#233;s. Cette heuristique est tr&#232;s efficace et permet &#224; l&#8217;analyseur de b&#233;n&#233;ficier d&#8217;une
grande rapidit&#233; (moins de 4 minutes pour traiter 1M de mots). Dans le cadre de la campagne
Passage 2007, cet analyseur a obtenu une F-Mesure de 91.57 %.
</p>
<p>3.3 Evaluation des analyseurs
</p>
<p>L&#8217;&#233;valuation des performances des analyseurs est ici r&#233;alis&#233;e en calculant la F-Mesure des
groupes Easy sur l&#8217;ensemble ou une partie du gold standard Easy. L&#8217;estimation du score de
F-Mesure n&#8217;est pas unique lorsqu&#8217;il s&#8217;agit de comparer deux structures d&#8217;arbre (ie. la r&#233;f&#233;rence
et la sortie de l&#8217;analyseur), et d&#233;pend de l&#8217;heuristique employ&#233;e. Notre score de F-Mesure est par
exemple syst&#233;matiquement plus bas que celui calcul&#233; dans la campagne d&#8217;&#233;valuation Passage
2007.
</p>
<p>Les erreurs d&#8217;annotations sur la r&#233;f&#233;rence Easy induisent un seuil maximum limite pour les
scores obtenus, ceci ind&#233;pendamment de l&#8217;analyseur &#233;valu&#233;. Elles sont dues d&#8217;une part aux
impr&#233;cisions du guide d&#8217;annotations Peas (Gendner et al., 2003) rassemblant les consignes
fournies aux annotateurs, et d&#8217;autre part aux fautes commises par les annotateurs eux-m&#234;me. Il
serait int&#233;ressant d&#8217;estimer ce taux d&#8217;erreurs, par exemple en comparant un passage du corpus
annot&#233; par plusieurs annotateurs diff&#233;rents. Il fixe en effet le score maximum pouvant &#234;tre atteint
par un analyseur.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Blache, St&#233;phane Rauzy
</p>
<p>FIG. 2 &#8211; En ordonn&#233;es, les per-
formances des analyseurs StP1
et ShP1 (pour l&#8217;&#233;crit) mesur&#233;es
sur les groupes du gold stan-
dard Easy. En abscisses, la F-
Mesure calcul&#233;e sur le corpus
Grace mesurant la performance
des mod&#232;les utilis&#233;s pour &#233;tique-
ter l&#8217;entr&#233;e propos&#233;e aux analy-
seurs. Les &#233;tiquetages sont ob-
tenus &#224; partir de sept mod&#232;les
class&#233;s par ordre de performance
croissant (voir figure 1).
</p>
<p>4 R&#233;sultats
</p>
<p>Nous avons r&#233;alis&#233; figure 2 une exp&#233;rience permettant de tester l&#8217;influence de la qualit&#233; de
l&#8217;&#233;tiquetage sur la performance de nos analyseurs. Pour chacun des sept mod&#232;les de d&#233;sam-
biguisation propos&#233;s section 2.2, le gold standard Easy a &#233;t&#233; &#233;tiquet&#233;, puis analys&#233; par nos
deux analyseurs. Les scores de F-Mesure des analyseurs sont port&#233;s en ordonn&#233;es, la F-Mesure
mesurant la qualit&#233; de l&#8217;&#233;tiquetage pour chaque mod&#232;le en abscisses. Les scores obtenus pour
l&#8217;&#233;tiquetage le plus fiable, celui g&#233;n&#233;r&#233; par le mod&#232;le des patrons en utilisant les fr&#233;quences
lexicales (PM+F), sont respectivement de 0.899 pour l&#8217;analyseur StP1 et 0.830 pour l&#8217;analy-
seur ShP1 sur tout le corpus2. Les scores montr&#233;s figure 2 ne concernent que les textes dans le
registre de l&#8217;&#233;crit (0.915 pour StP1 et 0.842 pour ShP1).
Pour les deux analyseurs, on observe une d&#233;pendance lin&#233;aire entre les F-Mesures mesurant la
performance des analyseurs et les F-Mesures mesurant la qualit&#233; de l&#8217;&#233;tiquetage. Ainsi, dans
le domaine de valeurs consid&#233;r&#233;es, la progression de la performance des analyseurs est directe-
ment contr&#244;l&#233;e par la proc&#233;dure d&#8217;&#233;tiquetage adopt&#233;e. Nous expliquons section 5 ce ph&#233;nom&#232;ne
d&#8217;un point de vue syntaxique. Nous constatons de plus que l&#8217;analyseur symbolique ShP1 pr&#233;-
sente une pente de progression plus faible que l&#8217;analyseur stochastique StP1. L&#8217;analyseur ShP1
n&#8217;exploite qu&#8217;une partie de l&#8217;information apport&#233;e par l&#8217;&#233;tiqueteur (les 44 cat&#233;gories sont en
effet group&#233;es en 18 sur-cat&#233;gories distinctes pour l&#8217;analyse ShP1). Nous interpr&#233;tons la diff&#233;-
rence de pentes observ&#233;e comme une manifestation de cet effet.
</p>
<p>Une deuxi&#232;me exp&#233;rience a &#233;t&#233; r&#233;alis&#233;e dans le but de pr&#233;ciser les r&#233;sultats obtenus. Nous avons
s&#233;lectionn&#233; un sous-&#233;chantillon du gold standard Easy (de taille modeste, 5 000 mots pour le
registre de l&#8217;&#233;crit, 1 000 mots pour l&#8217;oral) pour lequel nous avons manuellement corrig&#233; l&#8217;&#233;ti-
quetage morphosyntaxique. Nous pr&#233;sentons figure 3 la d&#233;pendance observ&#233;e entre la qualit&#233; de
l&#8217;&#233;tiquetage et la performance des analyseurs pour les deux &#233;chantillons, en distinguant l&#8217;oral
de l&#8217;&#233;crit. En abcisses, les sept &#233;tiquetages propos&#233;s correspondent aux mod&#232;les RAW, UNI,
RAW+F, BIG, PM, PM+F de la section 2.2, et de l&#8217;&#233;tiquetage manuel de r&#233;f&#233;rence (F-Mesure
= 1 par d&#233;finition). La F-Mesure des diff&#233;rents mod&#232;les est cette fois-ci calcul&#233;e par rapport &#224;
</p>
<p>2L&#8217;heuristique utilis&#233;e pour calculer la F-Mesure dans le cadre de la campagne Passage 2007 donne des scores
sup&#233;rieurs, 0.9303 pour StP1 et 0.9157 pour ShP1. Nos deux analyseurs obtiennent de bon r&#233;sultats lorsque com-
par&#233;s aux scores des analyseurs participants &#224; la campagne.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Analyse syntaxique et &#233;valuation
</p>
<p>FIG. 3 &#8211; En ordonn&#233;es,
les performances des analy-
seurs StP1 et ShP1 (pour
l&#8217;oral et l&#8217;&#233;crit) en fonc-
tion de la performance de
l&#8217;&#233;tiquetage propos&#233; en en-
tr&#233;e. Les mesures sont effec-
tu&#233;es sur un sous-&#233;chantillon
du gold standard Easy pour
lequel l&#8217;&#233;tiquetage morpho-
syntaxique a &#233;t&#233; corrig&#233; ma-
nuellement. Des courbes de
tendance (polyn&#244;mes de de-
gr&#233;s 2) soulignent le compor-
tement des 2 analyseurs.
</p>
<p>l&#8217;&#233;chantillon de r&#233;f&#233;rence corrig&#233; manuellement. Les F-Mesures mesurant les performances des
deux analyseurs sont pr&#233;sent&#233;es en ordonn&#233;es. Des courbes de tendance ont &#233;t&#233; ajout&#233;es afin de
souligner le comportement de chaque analyseur.
</p>
<p>L&#8217;analyseur stochastique StP1 montre clairement un plateau lorsque la qualit&#233; de l&#8217;&#233;tiquetage
converge vers l&#8217;unit&#233; alors que cet effet est peu marqu&#233; pour l&#8217;analyseur symbolique ShP1.
Ce comportement peut s&#8217;expliquer de la mani&#232;re suivante. L&#8217;analyseur stochastique StP1 a &#233;t&#233;
entrain&#233; sur le gold standard Easy, enrichi par un &#233;tiquetage automatique des cat&#233;gories fourni
par notre meilleur mod&#232;le de d&#233;sambiguisation (PM+F). La qualit&#233; de cet &#233;tiquetage est bonne
(F-Mesure de 95 % mesur&#233;e par rapport &#224; la r&#233;f&#233;rence manuelle), mais pas parfaite. L&#8217;analyseur
StP1 est ainsi limit&#233; par le taux d&#8217;erreurs affectant son corpus d&#8217;apprentissage. Ce n&#8217;est pas le
cas pour l&#8217;analyseur symbolique ShP1 qui repose sur la sp&#233;cification de sa grammaire, d&#8217;o&#249; la
quasi-absence d&#8217;un plateau au voisinage de l&#8217;unit&#233; pour ShP1.
</p>
<p>Les r&#233;sultats pour l&#8217;oral, m&#234;me si l&#8217;&#233;chantillon est de taille modeste (environ 1 000 mots) et
donc sujet &#224; des fluctuations statistiques, nous renseignent sur les diff&#233;rences d&#8217;ordre syntaxique
entre le registre oral et le registre &#233;crit. A mod&#232;le &#233;quivalent, l&#8217;&#233;tiquetage de l&#8217;oral est de moins
bonne qualit&#233; que l&#8217;&#233;tiquetage de l&#8217;&#233;crit (3 % en moyenne pour la F-Mesure). C&#8217;est un effet
attendu, notre &#233;tiqueteur ayant &#233;t&#233; entrain&#233; sur les textes &#233;crits du corpus Grace/Multitag. Cet
effet n&#8217;explique n&#233;anmoins pas compl&#233;tement la diff&#233;rence de performances des analyseurs
entre les deux registres. A qualit&#233; d&#8217;&#233;tiquetage &#233;quivalent, la figure 3 montre que les scores
obtenus pour l&#8217;oral sont plus faibles de l&#8217;ordre de 6 % pour l&#8217;analyseur ShP1 et 9 % pour StP1.
</p>
<p>5 Interpr&#233;tation
</p>
<p>Le type de chunking propos&#233; dans les campagnes Easy et Passage repose sur la d&#233;finition de
6 types de groupes : GA (Groupe Adjectival), GN (Groupe Nominal), GP (Groupe Pr&#233;posi-
tionnel), GR (Groupe Adverbial), NV (Noyau Verbal) et PV (Groupe verbal introduit par une</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Blache, St&#233;phane Rauzy
</p>
<p>4.1. Distribution des chunks par type 4.2. Taille des chunks par type
</p>
<p>FIG. 4 &#8211; Distribution et taille des chunks
</p>
<p>pr&#233;position). La figure 4.1 donne une indication de la r&#233;partition des types sur un corpus de
195 000 mots form&#233; d&#8217;extraits de journaux, de textes litt&#233;raires et de transcriptions de discours
spontan&#233;. Nous donnons pour information la distribution des types de chunks dans les sous-
ensembles de textes &#233;crits et oraux de ce corpus. La figure 4.2 indique quant &#224; elle la taille
moyenne des chunks par type.
</p>
<p>Ces figures montrent tout d&#8217;abord que les chunks sont globalement tr&#232;s courts. Les groupes les
plus nombreux sont aussi les plus longs (GN, GP, NV), mais globalement la taille moyenne
globale des chunks reste faible (2, 33 mots en moyenne). Cette propri&#233;t&#233; est essentielle pour
la caract&#233;risation du processus de chunking vis&#233; dans ces campagnes d&#8217;&#233;valuation. Cette t&#226;che
peut se faire de nombreuses fa&#231;ons diff&#233;rentes, y compris en effectuant une analyse syntaxique
globale. Cependant, si nous nous limitons aux fonctions de base, le chunking consiste &#224; iden-
tifier les fronti&#232;res gauches et droites des groupes (Abney, 1991). Examinons s&#233;par&#233;ment ces
deux t&#226;ches. La premi&#232;re peut se r&#233;sumer &#224; l&#8217;identification de coins gauches (Rosenkrantz &amp;
Lewis, 1970). Il s&#8217;agit globalement d&#8217;une t&#226;che assez simple consistant &#224; identifier le type d&#8217;un
chunk &#224; partir de n&#8217;importe quelle cat&#233;gorie (pas n&#233;cessairement la t&#234;te) pouvant d&#233;buter le
groupe. Cette t&#226;che peut &#234;tre contr&#244;l&#233;e &#224; l&#8217;aide d&#8217;un certain nombre d&#8217;heuristiques en vue de
sa d&#233;sambigu&#239;sation. L&#8217;identification de la fronti&#232;re droite est plus complexe et repose sur des
techniques pouvant s&#8217;approcher de l&#8217;analyse syntaxique compl&#232;te.
</p>
<p>La taille des chunks joue ici un r&#244;le d&#233;terminant. Dans le cas des chunks d&#8217;une longueur de
1 mot, il y a &#233;videmment confusion entre fronti&#232;re droite et fronti&#232;re gauche. Le cas g&#233;n&#233;ral
quant &#224; lui est &#233;galement s&#233;v&#232;rement contr&#244;l&#233; par la taille : la fen&#234;tre d&#8217;analyse n&#233;cessaire &#224;
l&#8217;identification des fronti&#232;res gauches (que ce soit pour une approche statistique ou symbolique)
est limit&#233;e, ce qui permet d&#8217;obtenir une approche extr&#234;mement efficace. Cette observation a une
cons&#233;quence directe sur la t&#226;che d&#8217;identification de fronti&#232;re droite. En effet, si les fronti&#232;res
gauches sont d&#233;termin&#233;es avec une tr&#232;s forte probabilit&#233;, l&#8217;identification des fronti&#232;res droites
joue donc un r&#244;le secondaire dans le processus. Elle est en tout cas tr&#232;s fortement contrainte au
point de devenir quasi sans cons&#233;quence (ce qui ne serait pas le cas avec des chunks plus longs).
En conclusion, le processus de chunking dans le cadre de cette campagne peut se r&#233;duire &#224; un
processus d&#8217;identification des fronti&#232;res gauches.
</p>
<p>Par ailleurs, l&#8217;op&#233;ration de chunking repose g&#233;n&#233;ralement sur un ensemble de types limit&#233;.
Dans le cas Easy/Passage, 6 types diff&#233;rents sont utilis&#233;s, globalement peu ambigus (seuls deux</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Analyse syntaxique et &#233;valuation
</p>
<p>types ont la m&#234;me cat&#233;gorie potentiellement fronti&#232;re gauche : PV et GP)3. La relation entre
les cat&#233;gories lexicales et leur projection possible vers un type de chunk est &#233;galement peu
ambigu&#235;. Ce ph&#233;nom&#232;ne explique donc la corr&#233;lation &#233;troite existant entre cat&#233;gorisation et
chunking.
</p>
<p>6 Conclusion
</p>
<p>Nous avons montr&#233; dans cet article la corr&#233;lation &#233;troite existant entre la qualit&#233; de l&#8217;&#233;tiquetage
et les performances des chunkers. Cette corr&#233;lation devient lin&#233;aire lorsque la taille des chunks
est limit&#233;e : on peut dans ce cas r&#233;duire la t&#226;che de chunking &#224; celle de l&#8217;identification des fron-
ti&#232;res gauche. Cette fonction, compte tenu du nombre limit&#233; du type de chunks, est directement
d&#233;pendante de la cat&#233;gorie morpho-syntaxique. Nous montrons ainsi que la qualit&#233; du chunking
d&#233;pend directement de celle de l&#8217;&#233;tiquetage.
</p>
<p>Nous pouvons ainsi conclure que la t&#226;che propos&#233;e dans le type de campagne d&#8217;&#233;valuation in-
diqu&#233; est plus proche d&#8217;un &#8220;super-&#233;tiquetage&#8221; que d&#8217;une analyse syntaxique. Ce r&#233;sultat permet
de souligner l&#8217;importance du r&#244;le que peut jouer la fonction d&#8217;identification de coin gauche. En
termes d&#8217;&#233;valuation, il constitue un argument en faveur de l&#8217;utilisation d&#8217;un m&#234;me corpus &#233;ti-
quet&#233; par tous les analyseurs participant &#224; une campagne : la qualit&#233; propre de chaque technique
d&#8217;analyse peut ainsi &#234;tre compar&#233;e pr&#233;cis&#233;ment.
</p>
<p>R&#233;f&#233;rences
ABNEY S. (1991). Parsing by chunks. In Principle-Based Parsing. Kluwer Academic Publi-
shers, p. 257&#8211;278.
BALFOURIER J.-M., BLACHE P., GU&#201;NOT M.-L. &amp; VANRULLEN T. (2005). Comparaison
de trois analyseurs symboliques pour une t&#226;che d&#8217;annotation syntaxique. In Actes de Traite-
ment Automatique des Langues Naturelles, volume 2, p. 41&#8211;48, Dourdan, France.
BLACHE P. &amp; RAUZY S. (2006). M&#233;canismes de contr&#244;le pour l&#8217;analyse en grammaires de
propri&#233;t&#233;s. In Actes de Traitement Automatique des Langues Naturelles, p. 415&#8211;424, Leuven,
Belgique.
BLACHE P. &amp; RAUZY S. (2007). Le moteur de pr&#233;diction de mots de la plateforme de com-
munication alternative. Traitement Automatique des Langues, 48(2). sous presse.
DE LA CLERGERIE E., AYACHE C., DE CHALANDAR G., FRANCOPOULO G., GARDENT C.
&amp; PAROUBEK P. (2008). Large scale production of syntactic annotations for french. In Pro-
ceedings of the international workshop on Automated Syntactic Annotations for Interoperable
Language Resources, Hong-Kong.
</p>
<p>GENDNER V., ILLOUZ G., JARDINO M., MONCEAUX L., PAROUBEK P., ROBBA I. &amp; VIL-
NAT A. (2003). PEAS, the first instantiation of a comparative framework for evaluating parsers
of french. In Research Notes of EACL 2003, Budapest, Hongrie.
</p>
<p>3La difficult&#233; essentielle dans la t&#226;che de rep&#233;rage de fronti&#232;re gauche ne se situe donc pas dans l&#8217;identification
du type, mais dans l&#8217;analyse du contexte permettant de d&#233;terminer si une cat&#233;gorie potentiellement fronti&#232;re gauche
est un coin gauche effectif.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Philippe Blache, St&#233;phane Rauzy
</p>
<p>IDE N. &amp; V&#201;RONIS J. (1994). MULTEXT : Multilingual text tools and corpora. In Pro-
ceedings of the 15th. International Conference on Computational Linguistics (COLING 94),
volume I, p. 588&#8211;592, Kyoto, Japan.
PAROUBEK P. &amp; RAJMAN M. (2000). Multitag, une ressource linguistique produit du para-
digme d&#8217;&#233;valuation. In Actes de Traitement Automatique des Langues Naturelles, p. 297&#8211;306,
Lausanne, Suisse.
PAROUBEK P., ROBBA I., VILNAT A. &amp; AYACHE C. (2006). Data annotations and measures
in EASY the evaluation campaign for parsers in french. In Proceedings of the 5th international
Conference on Language Resources and Evaluation, p. 314&#8211;320, Genoa, Italy.
RON D., SINGER Y. &amp; TISHBY N. (1996). The power of amnesia : Learning probabilistic
automata with variable memory length. Machine Learning, 25, 117&#8211;149.
ROSENKRANTZ S. &amp; LEWIS P. (1970). Deterministic left corner parsing. In Proceedings of
the 11th Annual Symposium on Switching and Automata, p. 139&#8211;152.
VANRULLEN T., BLACHE P., PORTES C., RAUZY S., MAEYHIEUX J.-F., GU&#201;NOT M.-
L., BALFOURIER J.-M. &amp; BELLENGIER E. (2005). Une plateforme pour l&#8217;acquisition, la
maintenance et la validation de ressources lexicales. In Actes de Traitement Automatique des
Langues Naturelles, volume 1, p. 511&#8211;516, Dourdan, France.</p>

</div></div>
</body></html>