TALN 2008, Avignon, 9-13 juin 2008

Inﬂuence de la qualité de l’étiquetage sur le chunking : une
corrélation dépendant de la taille des chunks

Philippe Blache, Stéphane Rauzy
Laboratoire Parole et Langage

CNRS & Université de Provence
philippe . blache@lpl—aix . fr, stephane . rauzy@lpl—aix . fr

Résumé. Nous montrons dans cet article qu’il existe une corrélation étroite existant entre
la qualité de l’étiquetage morpho-syntaxique et les performances des chunkers. Cette corrélation
devient linéaire lorsque la taille des chunks est limitée. Nous appuyons notre demonstration
sur la base d’une experimentation conduite suite a la campagne d’évaluation Passage 2007
(de la Clergerie et al., 2008). Nous analysons pour cela les comportements de deux analyseurs
ayant participé a cette campagne. L’ interpretation des résultats montre que la tache de chunking,
lorsqu’elle vise des chunks courts, peut étre assimilée a une tache de “super-étiquetage”.

Abstract. We show in this paper that a strong correlation exists between the performance
of chunk parsers and the quality of the tagging task in input. This dependency becomes linear
when the size of the chunks is small. Our demonstration is based on an experiment conducted at
the end of the Passage 2007 shared task evaluation initiative (de la Clergerie et al., 2008). The
performance of two parsers which took part in this evaluation has been investigated. The results
indicate that the chunking task, for sufﬁciently short chunks, is similar to a super-tagging task.

M0tS-CléS I Analyse syntaxique, étiquetage morphosyntaxique, analyseur stochastique,
analyseur symbolique superﬁciel, chunker.

Keywords: Parsing, tagging, stochastic parser, symbolic shallow parser, chunker.

Philippe Blache, Stephane Rauzy

1 Introduction

La qualite de l’etiquetage morpho-syntaxique a bien evidemment des consequences directes sur
les resultats des analyseurs syntaxiques. Mais l’importance de cette relation depend egalement
de la tache ﬁxee : les performances d’un chunker sont en effet plus directement liees a celle
de l’etiqueteur qu’un analyseur syntaxique profond. Nous montrons dans cet article qu’il existe
en fait une correlation lineaire entre la tache de chunking et celle d’etiquetage et que cette
correlation depend du type de chunk vise par la tache.

Nous nous appuyons dans cet article sur les resultats que nous avons obtenus dans le cadre de la
campagne d’evaluation Passage 20071 (de la Clergerie et al., 2008) qui est une continuation de
la campagne Easy (Paroubek et al., 2006). Ces campagnes ont perInis une evaluation compara-
tive de plusieurs analyseurs syntaxiques du frangais en s’appuyant sur un format d’annotation
ad hoc (le guide d’annotation PEAS (Gendner et al., 2003)) proposant des unites syntaxiques
plates (i.e. sans constituants emboites). Deux evaluations distinctes etaient proposees durant ces
campagnes, l’une portant sur la tache de formation et d’identiﬁcation des groupes syntaxiques,
l’autre consistant a etablir les relations de dependance entre les groupes obtenus. Nous nous
concentrons dans cet article sur la premiere tache qui correspond ici a un probleme classique de
chunking : il s’agit de reperer les types et frontieres des constituants de niveau 1. Nous avons
teste dans le cadre de la derniere campagne deux analyseurs, l’un utilisant des techniques nume-
riques (il s’agit d’un des premiers analyseurs stochastiques pour le frangais), l’autre etant base
sur une approche symbolique. Tous deux ont obtenu des resultats tres satisfaisants, l’analyseur
stochastique se situant dans le trio de tete des analyseurs evalues durant la campagne Passage
2007. Ces deux analyseurs prennent en entree un texte etiquete desambigu'1'se.

Pour montrer la correlation entre etiquetage et chunking, nous proposons de faire varier de
fagon controlee la qualite de l’etiquetage foumi en entree et d’observer les consequences sur les
resultats des analyseurs.

La premiere partie de cet article presente notre methode d’etiquetage et les differentes tech-
niques utilisees permettant le controle de la variation du resultat. La seconde partie decrit les
deux analyseurs etudies. La troisieme partie presente les resultats obtenus par nos analyseurs
en fonction de la qualite de l’entree proposee. La demiere partie est consacree a l’interpretation
des resultats, montrant que la correlation provient du type de chunk propose dans le cadre de
cette campagne.

2 Etiquetage morphosyntaxique

2.1 Segmentation et lexique

L’ objectif de cette tache est de segmenter en tokens le texte en entree, puis d’associer a chacun
des tokens de l’enonce la liste des categories morphosyntaxiques qui lui correspondent. Notre
segmenteur permet de reperer les frontieres entre les tokens et d’identiﬁer les entites necessitant
un traitement special (nombres, dates, heures, noms propres, sigles, ...). Une fois les tokens for-
mes, la liste des categories morphosyntaxiques correspondant a une graphie donnee est obtenue
par acces au lexique.

1Le lien vers l’action Passage : http ://atoll.inria.fr/passage/

Analyse syntaxique et evaluation

Nous utilisons dans cette etude le lexique DicoLPL (Vanrullen et al., 2005). I1 s’agit d’un
lexique assez couvrant du francais (440 000 formes) qui est de plus enrichi par la donnee des
frequences lexicales pour chacune des formes (ie. le couple graphie et categorie morphosyn-
taxique). Ces frequences lexicales sont extraites d’un corpus de textes ecrits d’environ 150 mil-
lion de mots prealablement etiquete, voir (Vanrullen et al., 2005) pour plus de details. L’infor-
mation sur les frequences lexicales permet notaInment de preciser la repartition entre categories
qui est speciﬁque a chaque graphie ambigue. Ainsi, la graphie dans est rencontree dans le cor-
pus 1 056 924 fois sous forme de preposition contre 195 fois sous forme de nom commun, alors
que la graphie envers se distribue plus uniformement (5 174 pour la preposition, 2 123 pour
le nom commun).

2.2 Désambiguisation

La procedure de desambiguisation consiste a associer a chacun des tokens de l’enonce une
categorie morphosyntaxique unique. Nous utilisons ici le modele des patrons (Blache & Rauzy,
2006; Blache & Rauzy, 2007), un modele de Markov cache (HMM) plus performant que les
modeles de type N-grammes. Pour les N-grammes, les etats de l’automate sont identiﬁes par
des sequences de categories de taille identique N. Le modele des patrons relache cette contrainte
en acceptant des etats identiﬁes par des sequences de longueur variable (voir par exemple (Ron
et al., 1996)). Cette caracteristique permet en pratique d’extraire du corpus d’apprentissage un
ensemble d’etats, les patrons du modele, qui capture de facon optimale l’information contenue
dans le corpus.

Le modele est entraine sur le corpus Grace/Multitag (Paroubek & Rajman, 2000), un echantillon
d’environ 700 000 mots annote morphosyntaxiquement selon le jeu de traits Multext (Ide &
Veronis, 1994). Dans notre etude, l’information morphosyntaxique disponible est groupee en
44 categories distinctes (2 types de categories pour les ponctuations, 1 pour les interjections,
2 pour les adjectifs, 2 pour les conjonctions, 1 pour les determinants, 3 pour les noms, 8 pour
les auxiliaires, 4 pour les verbes, 5 pour les prepositions, 3 pour les adverbes et 11 pour les
pronoms). Les informations comme les traits d’accords en genre, nombre et personne ou le
temps des verbes ne sont pas exploitees dans la presente analyse.

Aﬁn d’etudier l’inﬂuence de la qualite de l’etiquetage sur la performance des analyseurs syn-
taxiques, plusieurs procedures de desambiguisation sont proposees :

— RAW : Aucun modele n’est dans ce cas applique. L’etiquette associee a chaque token est la
premiere entree apparaissant dans la liste des categories proposees pour le token.

— UNI : Le modele unigramme est ici applique. I1 donne la distribution de probabilite non
contextuelle des categories utilisees. Pour chaque token, l’etiquette retenue est celle posse-
dant la probabilite la plus forte parIni la liste des categories proposees.

— RAW+F : Aucun modele n’est applique, mais on prend en compte la distribution des fre-
quences lexicales dans la liste des categories associees a la graphie du token (cf. section 2.1).
L’ etiquette retenue est la categorie presentant la frequence lexicale maximale.

— BIG : Un modele de bigrammes est utilise (information sur les probabilites des categories
conditionnees par la categorie precedente). Le modele est alors decrit par 44 patrons, un pour
chacune des categories utilisees. Pour chaque enonce, l’etiquetage optimal est obtenu par
application de l’algorithme de Viterbi.

— BIG+F : Le modele de bigrammes est applique avec un schema de ponderation qui rend
compte des frequences lexicales associees a chaque graphie de l’enonce.

Philippe Blache, Stéphane Rauzy

— PM : Le modele des patrons complet, composé de 3 053 patrons de taille variable (le plus
grand contexte dans la liste des patrons est composé d’une séquence de 6 categories). L’éti-
quetage optimal est obtenu par application de l’algorithme de Viterbi.

— PM+F : Le modele des patrons complet avec prise en compte des fréquences lexicales.

2.3 Evaluation de l’étiquetage

L’ évaluation de la qualité de l’étiquetage est ici réalisée en calculant les scores de précision, rap-
pel et F-Mesure sur l’échantillon de référence Grace/Multitag. Les erreurs affectant l’étiquetage
de la référence imposent un seuil maximum limite pour les scores d’évaluation obtenus. Elles
proviennent de maniere générale d’une description incomplete, voire contradictoire, des regles
d’annotation ou de fautes d’annotation sur la référence. Ces seuils limites sont ﬁxes pour une
référence donnée. La valeur des scores est ensuite dépendante des erreurs provenant de chacun
des modules composant la chaine de traitement :

— Erreurs de segmentation
— Erreurs du lexique (entrées manquantes, incorrectes, incompletes)
— Erreurs du modele implanté dans le module de désambiguisation

Model Precision Recall F—Measure

RAW 0.829 0.696 0.757 FIG. 1 — La qualité de l’étiquetage
UNI 0 - 7 6 9 0 - 7 7 0 0 - 7 7 0 morphosyntaxique mesurée sur la ré-
RAW+F 0 ' 9 O O O ' 8 8 5 O ' 8 9 3 férence Grace/Multitag en termes de
BIG 0 ' 90 9 0 ' 902 O ' 90 6 F-Mesure précision et rappel pour les
PM 0.927 0.923 0.925 ’

BIG+F 0 _ 9 3 3 0 _ 9 2 6 0 _ 9 2 9 sept modeles de désambiguisation pré-
PM+F 0.943 0.937 0.940 sentés section 2.2.

Nous présentons ﬁgure 1 les résultats de l’évaluation des sept modeles proposés section 2.2. Les
sept modeles partagent les erreurs de segmentation et du lexique. Les valeurs des scores ne sont
pas absolues, elles dépendent de la ﬁnesse de description du systeme de catégorisation adopté
(ici 44 categories). Nous pouvons remarquer l’inﬂuence de la prise en compte des fréquences
lexicales. Cette information de nature extra-syntaxique apporte un gain signiﬁcatif quel que soit
le modele considéré. Les F-Mesures de nos différents modeles couvrent l’intervalle [0.7 5, 0.95],
ce qui nous permettra section 4 d’étudier l’inﬂuence de la qualité de l’étiquetage sur les perfor-
mances de nos analyseurs syntaxiques dans cette gamme de valeurs.

3 Analyse syntaxique superﬁcielle

3.1 L’analyseur stochastique StP1

L’ analyseur stochastique StP1, comme notre étiqueteur, est basé sur le modele des patrons (voir
section 2.2). La phase d’apprentissage est effectuée sur le gold standard Easy, un corpus annoté

Analyse syntaxique et évaluation

en constituants d’environ 100 000 mots qui a servi de référence pour la campagne d’évalua-
tion Easy (Paroubek et al., 2006). La grammaire Easy compte six constituants (ie. les groupes
Easy GN, GP, NV, GA, PV et GR) faiblement hiérarchisés. Le corpus ne fournit pas les éti-
quettes des tokens composant les énoncés. Une phase préalable d’étiquetage (en utilisant notre
modele le plus performant PM+F, voir section 3.3) a donc été nécessaire pour produire notre
échantillon d’apprentissage. Le module d’apprentissage nous permet d’extraire de cet échan-
tillon 1080 patrons de taille variable identiﬁés par des séquences de catégories terminales (les
catégories morphosyntaxiques) ou non-terminales (les groupes Easy).

L’ analyseur stochastique StP1 prend en entrée un texte étiqueté et désambiguisé (c’est cette
option qui sera utilisée dans la suite de l’article), ou une liste de catégories associée a chaque
token de l’énoncé (ie. la sortie de la phase segmentation plus acces au lexique). Pour chaque
énoncé, l’algorithme de Viterbi permet d’insérer les groupes Easy maximisant la probabilité de
l’énoncé. Dans le cadre de la campagne Passage 2007, StP1 a obtenu une F-Mesure de 93.03 %.

3.2 L’analyseur superﬁciel ShP1

I1 s’agit d’un analyseur symbolique déterministe. I1 repose sur les Grammaires de Propriétés
avec une stratégie de coin gauche. La grammaire utilisée est complete en ce sens qu’elle peut
étre utilisée indifféremment pour une analyse profonde ou superﬁcielle (Balfourier et al., 2005).
La particularité de ShP1 est de s’appuyer sur un sous-ensemble de contraintes de la grammaire
(en particulier les propriétés de linéarité et de constituance) pour identiﬁer les coins gauches. La
stratégie consiste a repérer a partir des coins gauches la frontiere droite du chunk sur la base des
autres propriétés. Cette heuristique est tres efﬁcace et permet a l’analyseur de bénéﬁcier d’une
grande rapidité (moins de 4 minutes pour traiter 1M de mots). Dans le cadre de la campagne
Passage 2007, cet analyseur a obtenu une F-Mesure de 91.57 %.

3.3 Evaluation des analyseurs

L’évaluation des performances des analyseurs est ici réalisée en calculant la F-Mesure des
groupes Easy sur l’ensemble ou une partie du gold standard Easy. L’estimation du score de
F-Mesure n’est pas unique lorsqu’il s’agit de comparer deux structures d’arbre (ie. la référence
et la sortie de l’analyseur), et dépend de l’heuristique employée. Notre score de F-Mesure est par
exemple systématiquement plus bas que celui calculé dans la campagne d’évaluation Passage
2007.

Les erreurs d’annotations sur la référence Easy induisent un seuil maximum limite pour les
scores obtenus, ceci indépendamment de l’analyseur évalué. Elles sont dues d’une part aux
imprécisions du guide d’annotations Peas (Gendner et al., 2003) rassemblant les consignes
foumies aux annotateurs, et d’autre part aux fautes commises par les annotateurs eux-méme. I1
serait intéressant d’estimer ce taux d’erreurs, par exemple en comparant un passage du corpus
annoté par plusieurs annotateurs différents. I1 ﬁxe en effet le score maximum pouvant étre atteint
par un analyseur.

Philippe Blache, Stephane Rauzy

0.95 L FIG. 2 — En ordonnees, les per-
 DJ merit (Sm) formances des analyseurs StP1
a warm (SM711 et ShP1 (pour l’ecr1t) mesurees
E 0.35 MG” sur les groupes du gold stan-
E ,A/E,‘,,‘(?“*F dard Easy. En abscisses, la F-

0.3 " ' ,

S / MMBIG Mesure calculee sur le corpus

Z .

§ 0.75 K —— — — . — Grace mesurant la performance

Z / des modeles utilises pour etique-

: 0' 7 % ter l’entree proposee aux analy-

m u

5 M5 seurs. Les et1quetages sont ob-

H Um ‘ ' d‘l
Rm tenus a part1r de sept mo e es

9 ' 5 classes par ordre de performance
$1.75 0.80 |]|w,85 0,90‘ 0.95

T‘agI‘ger F_Meas..m (Grace, croissant (voir ﬁgure 1).

4 Résultats

Nous avons realise ﬁgure 2 une experience permettant de tester l’inﬂuence de la qualite de
l’etiquetage sur la performance de nos analyseurs. Pour chacun des sept modeles de desam-
biguisation proposes section 2.2, le gold standard Easy a ete etiquete, puis analyse par nos
deux analyseurs. Les scores de F-Mesure des analyseurs sont portes en ordonnees, la F-Mesure
mesurant la qualite de l’etiquetage pour chaque modele en abscisses. Les scores obtenus pour
l’etiquetage le plus ﬁable, celui genere par le modele des patrons en utilisant les frequences
lexicales (PM+F), sont respectivement de 0.899 pour l’analyseur StP1 et 0.830 pour l’analy-
seur ShP1 sur tout le corpusz. Les scores montres ﬁgure 2 ne concernent que les textes dans le
registre de l’ecrit (0.915 pour StP1 et 0.842 pour ShP1).

Pour les deux analyseurs, on observe une dependance lineaire entre les F-Mesures mesurant la
performance des analyseurs et les F-Mesures mesurant la qualite de l’etiquetage. Ainsi, dans
le domaine de valeurs considerees, la progression de la performance des analyseurs est directe-
ment controlee par la procedure d’etiquetage adoptee. Nous expliquons section 5 ce phenomene
d’un point de vue syntaxique. Nous constatons de plus que l’analyseur symbolique ShP1 pre-
sente une pente de progression plus faible que l’analyseur stochastique StP1. L’ analyseur ShP1
n’exploite qu’une partie de l’information apportee par l’etiqueteur (les 44 categories sont en
effet groupees en 18 sur-categories distinctes pour l’analyse ShP1). Nous interpretons la diffe-
rence de pentes observee comme une manifestation de cet effet.

Une deuxieme experience a ete realisee dans le but de preciser les resultats obtenus. Nous avons
selectionne un sous-echantillon du gold standard Easy (de taille modeste, 5 000 mots pour le
registre de l’ecrit, 1 000 mots pour l’oral) pour lequel nous avons manuellement corrige l’eti-
quetage morphosyntaxique. Nous presentons ﬁgure 3 la dependance observee entre la qualite de
l’etiquetage et la performance des analyseurs pour les deux echantillons, en distinguant l’oral
de l’ecrit. En abcisses, les sept etiquetages proposes correspondent aux modeles RAW, UNI,
RAW+F, BIG, PM, PM+F de la section 2.2, et de l’etiquetage manuel de reference (F-Mesure
= 1 par deﬁnition). La F-Mesure des differents modeles est cette fois-ci calculee par rapport a

2L’heuristique utilisee pour calculer la F-Mesure dans le cadre de la campagne Passage 2007 donne des scores
superieurs, 0.9303 pour StP1 et 0.9157 pour ShP1. Nos deux analyseurs obtiennent de bon resultats lorsque com-
pares aux scores des analyseurs participants a la campagne.

Analyse syntaxique et évaluation

FIG. 3 — En ordonnées,
les performances des analy-

0.9 } _ __
‘Emit (SW13 1 A seurs StP1 et ShP1 (pour
“'35 ‘Emit FEW“ L l’oral et l’écrit) en fonc-
§Oral (StP1J _
“L3 .0111 (ShP1L tion de la performance de

'7 : l’étiquetage proposé en en-
 — ‘ trée. Les mesures sont effec-

V x i tuées sur un sous-échantillon
/3’

du gold standard Easy pour
lequel l’étiquetage morpho-
syntaxique a été corrigé ma-
nuellement. Des courbes de
tendance (polynomes de de-
u. 7‘ 0. 75 0 . 3 0 . 35 11 . 9‘ 0. 95 1 grés 2) soulignent le compor-
Tagger F—Measure (Easy corrected) tement des 2 analyseurs.

Parser F-Measure [Easy groups]
0
‘H!
m

 

l’échantillon de référence corrigé manuellement. Les F-Mesures mesurant les performances des
deux analyseurs sont présentées en ordonnées. Des courbes de tendance ont été ajoutées aﬁn de
souligner le comportement de chaque analyseur.

L’ analyseur stochastique StP1 montre clairement un plateau lorsque la qualité de l’étiquetage
converge vers l’unité alors que cet effet est peu marqué pour l’analyseur symbolique ShP1.
Ce comportement peut s’expliquer de la maniere suivante. L’ analyseur stochastique StP1 a été
entrainé sur le gold standard Easy, enrichi par un étiquetage automatique des catégories foumi
par notre meilleur modele de désambiguisation (PM+F). La qualité de cet étiquetage est bonne
(F-Mesure de 95 % mesurée par rapport a la référence manuelle), mais pas parfaite. L’ analyseur
StP1 est ainsi limité par le taux d’erreurs affectant son corpus d’apprentissage. Ce n’est pas le
cas pour l’analyseur symbolique ShP1 qui repose sur la spéciﬁcation de sa grammaire, d’o1‘1 la
quasi-absence d’un plateau au voisinage de l’unité pour ShP1.

Les résultats pour l’oral, méme si l’échantillon est de taille modeste (environ 1 000 mots) et
donc sujet a des ﬂuctuations statistiques, nous renseignent sur les différences d’ordre syntaxique
entre le registre oral et le registre écrit. A modele équivalent, l’étiquetage de l’oral est de moins
bonne qualité que l’étiquetage de l’écrit (3 % en moyenne pour la F-Mesure). C’est un effet
attendu, notre étiqueteur ayant été entrainé sur les textes écrits du corpus Grace/Multitag. Cet
effet n’eXplique néanmoins pas complétement la différence de performances des analyseurs
entre les deux registres. A qualité d’étiquetage équivalent, la ﬁgure 3 montre que les scores
obtenus pour l’oral sont plus faibles de l’ordre de 6 % pour l’analyseur ShP1 et 9 % pour StP1.

5 Interprétation

Le type de chunking proposé dans les campagnes Easy et Passage repose sur la déﬁnition de
6 types de groupes : GA (Groupe Adjectival), GN (Groupe Nominal), GP (Groupe Preposi-
tionnel), GR (Groupe Adverbial), NV (Noyau Verbal) et PV (Groupe verbal introduit par une

Philippe Blache, Stéphane Rauzy

‘],35:— 4';

   

 

Q3 3.5 
0,25. 3 
2.5 .
M ‘ nlorat.
2 I 2 .
0,15. \ WEE“?
H 1.5
0'1 ' 7 i 1  ,_
G.n5l‘  ‘ HIS  
u—  — — — 0 —— 4 —
on I- on GM GP G? W Pm:
4.1. Distribution des chunks par type 4.2. Taille des chunks par type

FIG. 4 — Distribution et taille des chunks

préposition). La ﬁgure 4.1 donne une indication de la répartition des types sur un corpus de
195 000 mots formé d’extraits de joumaux, de textes littéraires et de transcriptions de discours
spontané. Nous donnons pour information la distribution des types de chunks dans les sous-
ensembles de textes écrits et oraux de ce corpus. La ﬁgure 4.2 indique quant a elle la taille
moyenne des chunks par type.

Ces ﬁgures montrent tout d’abord que les chunks sont globalement tres courts. Les groupes les
plus nombreux sont aussi les plus longs (GIV, GP, NV), mais globalement la taille moyenne
globale des chunks reste faible (2, 33 mots en moyenne). Cette propriété est essentielle pour
la caractérisation du processus de chunking visé dans ces campagnes d’évaluation. Cette tache
peut se faire de nombreuses facons différentes, y compris en effectuant une analyse syntaxique
globale. Cependant, si nous nous limitons aux fonctions de base, le chunking consiste a iden-
tiﬁer les frontieres gauches et droites des groupes (Abney, 1991). Examinons séparément ces
deux taches. La premiere peut se résumer a l’identiﬁcation de coins gauches (Rosenkrantz &
Lewis, 1970). Il s’agit globalement d’une tache assez simple consistant a identiﬁer le type d’un
chunk a partir de n’importe quelle catégorie (pas nécessairement la téte) pouvant débuter le
groupe. Cette tache peut étre controlée a l’aide d’un certain nombre d’heuristiques en vue de
sa désambigu'1'sation. L’identiﬁcation de la frontiere droite est plus complexe et repose sur des
techniques pouvant s’approcher de l’analyse syntaxique complete.

La taille des chunks joue ici un role déterminant. Dans le cas des chunks d’une longueur de
1 mot, il y a évidemment confusion entre frontiere droite et frontiere gauche. Le cas général
quant a lui est également séverement controlé par la taille : la fenétre d’analyse nécessaire a
l’identiﬁcation des frontieres gauches (que ce soit pour une approche statistique ou symbolique)
est limitée, ce qui permet d’obtenir une approche extrémement efﬁcace. Cette observation a une
conséquence directe sur la tache d’identiﬁcation de frontiere droite. En effet, si les frontieres
gauches sont déterminées avec une tres forte probabilité, l’identiﬁcation des frontieres droites
joue donc un role secondaire dans le processus. Elle est en tout cas tres fortement contrainte au
point de devenir quasi sans conséquence (ce qui ne serait pas le cas avec des chunks plus longs).
En conclusion, le processus de chunking dans le cadre de cette campagne peut se réduire a un
processus d’identiﬁcation des frontieres gauches.

Par ailleurs, l’opération de chunking repose généralement sur un ensemble de types limité.
Dans le cas Easy/Passage, 6 types différents sont utilisés, globalement peu ambigus (seuls deux

Analyse syntaxique et évaluation

types ont la meme catégorie potentiellement frontiere gauche : PV et GP)3. La relation entre
les catégories lexicales et leur projection possible vers un type de chunk est également peu
ambigue. Ce phénomene explique donc la corrélation étroite existant entre catégorisation et
chunking.

6 Conclusion

Nous avons montré dans cet article la corrélation étroite existant entre la qualité de l’étiquetage
et les performances des chunkers. Cette corrélation devient linéaire lorsque la taille des chunks
est limitée : on peut dans ce cas réduire la tache de chunking a celle de l’identiﬁcation des fron-
tieres gauche. Cette fonction, compte tenu du nombre limité du type de chunks, est directement
dépendante de la catégorie morpho-syntaxique. Nous montrons ainsi que la qualité du chunking
dépend directement de celle de l’étiquetage.

Nous pouvons ainsi conclure que la tache proposée dans le type de campagne d’évaluation in-
diqué est plus proche d’un “super-étiquetage” que d’une analyse syntaxique. Ce résultat permet
de souligner l’importance du role que peut jouer la fonction d’identiﬁcation de coin gauche. En
termes d’évaluation, il constitue un argument en faveur de l’utilisation d’un meme corpus eti-
queté par tous les analyseurs participant a une campagne : la qualité propre de chaque technique
d’analyse peut ainsi étre comparée précisément.

Références

ABNEY S. (1991). Parsing by chunks. In Principle-Based Parsing. Kluwer Academic Publi-
shers, p. 257-278.

BALFOURIER J .—M., BLACHE P., GUENOT M.-L. & VANRULLEN T. (2005). Comparaison
de trois analyseurs symboliques pour une tache d’annotation syntaxique. In Actes de Traite-
ment Automatique des Langues Naturelles, volume 2, p. 41-48, Dourdan, France.

BLACHE P. & RAUZY S. (2006). Mécanismes de controle pour l’analyse en grammaires de
propriétés. In Actes de Traitement Automatique des Langues Naturelles, p. 415-424, Leuven,
Belgique.

BLACHE P. & RAUZY S. (2007). Le moteur de prédiction de mots de la plateforme de com-
munication alternative. Traitement Automatique des Langues, 48(2). sous presse.

DE LA CLERGERIE E., AYACHE C., DE CHALANDAR G., FRANCOPOULO G., GARDENT C.
& PAROUBEK P. (2008). Large scale production of syntactic annotations for french. In Pro-
ceedings of the international workshop on Automated Syntactic Annotations for Interoperable
Language Resources, Hong-Kong.

GENDNER V., ILLoUz G., JARDINO M., MONCEAUX L., PAROUBEK P., ROBBA I. & VIL-
NAT A. (2003). PEAS, the ﬁrst instantiation of a comparative framework for evaluating parsers
of french. In Research Notes of EACL 2003, Budapest, Hongrie.

3La difﬁculté essentielle dans la tache de repérage de frontiere gauche ne se situe donc pas dans 1’identiﬁcation
du type, mais dans 1’ analyse du contexte permettant de determiner si une catégorie potentiellement frontiere gauche
est un coin gauche effectif.

Philippe Blache, Stéphane Rauzy

IDE N. & VERONIS J. (1994). MULTEXT : Multilingual text tools and corpora. In Pro-
ceedings of the 15th. International Conference on Computational Linguistics (COLING 94),
volume I, p. 588-592, Kyoto, Japan.

PAROUBEK P. & RAJMAN M. (2000). Multitag, une ressource linguistique produit du para-
digme d’éValuation. In Actes de TraitementAutomatique des Langues Naturelles, p. 297-306,
Lausanne, Suisse.

PAROUBEK P., ROBBA I., VILNAT A. & AYACHE C. (2006). Data annotations and measures
in EASY the evaluation campaign for parsers in french. In Proceedings of the 5th international
Conference on Language Resources and Evaluation, p. 314-320, Genoa, Italy.

RON D., SINGER Y. & TISHBY N. (1996). The power of amnesia : Learning probabilistic
automata with variable memory length. Machine Learning, 25, 117-149.

ROSENKRANTZ S. & LEWIS P. (1970). Deterministic left corner parsing. In Proceedings of
the 11th Annual Symposium on Switching and Automata, p. 139-152.

VANRULLEN T., BLACHE P., PORTES C., RAUZY S., MAEYHIEUX J GUENOT M.-
L., BALFOURIER J .-M. & BELLENGIER E. (2005). Une plateforme pour l’acquisition, la
maintenance et la validation de ressources lexicales. In Actes de Traitement Automatique des
Langues Naturelles, volume 1, p. 511-516, Dourdan, France.

