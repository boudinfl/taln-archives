<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Adaptation de parsers statistiques lexicalis&#233;s pour le fran&#231;ais : Une &#233;valuation compl&#232;te sur corpus arbor&#233;s</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009 &#8211; Session posters , Senlis, 24&#8211;26 juin 2009
</p>
<p>Adaptation de parsers statistiques lexicalis&#233;s pour le
fran&#231;ais : Une &#233;valuation compl&#232;te sur corpus arbor&#233;s
</p>
<p>Djam&#233; Seddah&#8900;, Marie Candito* et Beno&#238;t Crabb&#233;*
&#8900; Universit&#233; Paris-Sorbonne
LALIC et INRIA (Alpage)
</p>
<p>* Universit&#233; Paris 7
UFRL et INRIA (Alpage)
</p>
<p>R&#233;sum&#233;. Cet article1 pr&#233;sente les r&#233;sultats d&#8217;une &#233;valuation exhaustive des principaux
analyseurs syntaxiques probabilistes dit &#8220;lexicalis&#233;s&#8221; initialement con&#231;us pour l&#8217;anglais, adap-
t&#233;s pour le fran&#231;ais et &#233;valu&#233;s sur le CORPUS ARBOR&#201; DU FRAN&#199;AIS (Abeill&#233; et al., 2003) et
le MODIFIED FRENCH TREEBANK (Schluter &amp; van Genabith, 2007).
Confirmant les r&#233;sultats de (Crabb&#233; &amp; Candito, 2008), nous montrons que les mod&#232;les lexica-
lis&#233;s, &#224; travers les mod&#232;les de Charniak (Charniak, 2000), ceux de Collins (Collins, 1999) et
le mod&#232;le des TIG Stochastiques (Chiang, 2000), pr&#233;sentent des performances moindres face &#224;
un analyseur PCFG &#224; Annotation Latente (Petrov et al., 2006). De plus, nous montrons que le
choix d&#8217;un jeu d&#8217;annotations issus de tel ou tel treebank oriente fortement les r&#233;sultats d&#8217;&#233;valua-
tions tant en constituance qu&#8217;en d&#233;pendance non typ&#233;e. Compar&#233;s &#224; (Schluter &amp; van Genabith,
2008; Arun &amp; Keller, 2005), tous nos r&#233;sultats sont state-of-the-art et infirment l&#8217;hypoth&#232;se
d&#8217;une difficult&#233; particuli&#232;re qu&#8217;aurait le fran&#231;ais en terme d&#8217;analyse syntaxique probabiliste et
de sources de donn&#233;es.
</p>
<p>Abstract. This paper presents complete investigation results on the statistical parsing
of French by bringing a complete evaluation on French data of the main based probabilistic
lexicalized (Charniak, Collins, Chiang) and unlexicalized (Berkeley) parsers designed first on
the Penn Treebank. We adapted the parsers on the two existing treebanks of French (Abeill&#233;
et al., 2003; Schluter &amp; van Genabith, 2007). To our knowledge, all the results reported here
are state-of-the-art for the constituent parsing of French on every available treebank and inva-
lidate the hypothesis of French being particularly difficult to parse. Regarding the algorithms,
the comparisons show that lexicalized parsing models are outperformed by the unlexicalized
Berkeley parser. Regarding the treebanks, we observe that a tag set with specific features has
direct influences over evaluation results depending on the parsing model.
</p>
<p>Mots-cl&#233;s : Analyse syntaxique probabiliste, corpus arbor&#233;s, &#233;valuation, analyse du fran-
&#231;ais.
</p>
<p>Keywords: Probabilistic parsing, treebanks, evaluation, French parsing.
</p>
<p>1Ce travail est soutenu par l&#8217;ANR programme DEFI 2008 dans le cadre du projet SEQUOIA.
Nous tenons &#224; remercier Abishek Arun, Josef Van Genabith, Alexis Nasr et Natalie Schluter pour nous avoir permis
d&#8217;utiliser leurs ressources ainsi que Marwan El Markour et Rosa Stern pour leur aide.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Seddah, Candito &amp; Crabb&#233;
</p>
<p>1 Introduction
Depuis la mise &#224; disposition progressive du Corpus Arbor&#233; de Paris 7 (FTB, (Abeill&#233; et al.,
2003)), diff&#233;rents travaux pr&#233;curseurs portant tant sur l&#8217;extraction de grammaires d&#8217;arbres ad-
joints (Dybro-Johansen, 2004) que sur l&#8217;entra&#238;nement d&#8217;analyseurs statistiques (Arun &amp; Keller,
2005) sont apparus et d&#233;montrent la faisabilit&#233; de telles t&#226;ches sur le FTB. N&#233;anmoins, l&#8217;ab-
sence d&#8217;annotations fonctionnelles permettant de pallier l&#8217;aspect plat des structures syntaxiques
du FTB et l&#8217;&#233;tat pr&#233;liminaire du corpus disponible &#224; cette &#233;poque compliquent ces t&#226;ches et
rendent d&#233;licate toute comparaison avec les travaux r&#233;cents de (Crabb&#233; &amp; Candito, 2008) et
ceux ayant motiv&#233; la cr&#233;ation du &#8220;Modified French Treebank&#8221; (Schluter &amp; van Genabith, 2007;
Schluter &amp; van Genabith, 2008).
Dans cet article, nous pr&#233;sentons les r&#233;sultats d&#8217;une &#233;valuation extensive de cinq mod&#232;les de
parsing probabiliste sur les deux corpus arbor&#233;s du fran&#231;ais, qui montrent que (1) des r&#233;sultats
state of the art sont atteints sur toutes les versions du corpus, par cons&#233;quent le probl&#232;me de
la source de donn&#233;es pour l&#8217;analyse syntaxique du fran&#231;ais est r&#233;solue et (2) que le d&#233;bat port&#233;
par N.Schluter et A.Arun, sur l&#8217;utilit&#233; d&#8217;algorithmes lexicalis&#233;s pour le fran&#231;ais, est loin d&#8217;&#234;tre
tranch&#233;.
Dans un premier temps, section 2, nous pr&#233;sentons nos corpus de travail, puis, section 3, nous
introduisons bri&#232;vement les mod&#232;les d&#8217;analyses avant de pr&#233;senter notre protocole exp&#233;rimental
section 4. Enfin, nous discutons les r&#233;sultats pr&#233;sent&#233;s section 5 puis nous concluons.
</p>
<p>2 Treebanks pour le fran&#231;ais
Cette section pr&#233;sente un bref aper&#231;u des corpus pour lesquels nous pr&#233;sentons des r&#233;sultats : le
Corpus Arbor&#233; du Fran&#231;ais (FTB, (Abeill&#233; et al., 2003)) et le Modified French Treebank (MFT,
(Schluter &amp; van Genabith, 2007)).
Le Corpus arbor&#233; du fran&#231;ais (FTB)
Le FTB est le premier corpus arbor&#233; (ie. treebank) annot&#233; et corrig&#233; manuellement disponible
pour le fran&#231;ais. Les annotations sont morphologiques et syntaxiques, les secondes incluant
des annotations fonctionnelles pour les d&#233;pendants verbaux (cf. (Abeill&#233; et al., 2003) pour plus
de d&#233;tails). La version utilis&#233;e pour ce travail contient 12351 phrases, 385 458 occurrences
de tokens et pr&#233;sente une longueur moyenne de 27 tokens. Comparativement &#224; une longueur
moyenne de 24 tokens pour le Penn Treebank (i.e. PTB, (Marcus et al., 1994)) qui contient pr&#232;s
de 44 000 phrases pour plus d&#8217;un million de tokens, cela rend la tache d&#8217;analyse syntaxique plus
d&#233;licate. Comme d&#8217;autres treebanks (par exemple Tiger, Negra pour l&#8217;allemand), le FTB propose
une structure hi&#233;rarchique plus plate que celle du PTB. En effet, bas&#233;e sur une repr&#233;sentation
X-barre, celle-ci permet une distinction configurationnelle des syntagmes sous-cat&#233;goris&#233;s par
le verbe tandis que seule l&#8217;annotation fonctionnelle permet cette distinction dans le cas du FTB.
Ceci est li&#233;, entre autres, au choix de ne pas inclure de noeuds de type VP dans les annotations
syntaxiques du FTB et a en partie conduit les auteurs de (Schluter &amp; van Genabith, 2007) &#224;
r&#233;-annoter une partie du corpus &#224; leur disposition dans une optique d&#8217;extraction de grammaires
LFG.
</p>
<p>le &#8220;Modified French Treebank&#8221; (MFT)
Le MFT (Schluter &amp; van Genabith, 2007; Schluter &amp; van Genabith, 2008) est un sous-ensemble
de 4739 phrases tir&#233;es du FTB initial, r&#233;-annot&#233;es semi-automatiquement et corrig&#233;es &#224; la main.
Ses auteurs ont introduit deux diff&#233;rences formelles par rapport &#224; la source : des diff&#233;rences
structurelles et des modification du jeu d&#8217;annotation. D&#8217;un point de vue structurel, les trans-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Parsing statistique lexicalis&#233; pour le fran&#231;ais
</p>
<p>formations principales incluent une stratification accrue des r&#232;gles sous-jacentes au treebank
(comme l&#8217;introduction d&#8217;un noeud VP) et mettent l&#8217;accent sur une modification du sch&#233;ma de
coordination (celui-ci ajoutant d&#233;sormais &#224; l&#8217;&#233;tiquette COORD le label du noeud coordonn&#233;).
Ces modifications permettent une meilleur ad&#233;quation &#224; l&#8217;architecture d&#233;crite dans (Cahill et al.,
2004) et permettent de r&#233;duire la taille de la grammaire extraite du treebank. Par ailleurs, le
MFT inclut aussi un affinage du jeu d&#8217;annotation via l&#8217;ajout de certaines informations morpho-
logiques sur les labels des n&#339;uds (tels que des traits de mode suppl&#233;mentaires sur les noeuds
VP et VN) et par l&#8217;affinement du jeu d&#8217;&#233;tiquettes fonctionnelles.
Finalement, une phase d&#8217;error mining et une correction manuelle extensive ont &#233;t&#233; appliqu&#233;es
sur le corpus.
Le tableau 1 synth&#233;tise un certain nombre d&#8217;&#233;l&#233;ments de comparaison entre les deux treebanks
sous leur forme canonique. Les nombres report&#233;s sont calcul&#233;s en fonction des cat&#233;gories syn-
taxiques de bases, sans annotations fonctionnelles et sans annotations morpho-syntaxiques sur
les parties du discours (eg. pas de traits &#8220;genre&#8221; ni &#8220;nombre&#8221;). La comparaison du nombre
moyen de branchements par n&#339;uds (2.60 pour le FTB et 2.11 pour le MFT) d&#233;montre la strati-
fication plus &#233;lev&#233;e du MFT.
</p>
<p>Carac. FTB MFT
Taille (phrases) 12351 4739
Longueur moy. des phrases 27.48 28.38
Nbre moy. de branch/noeuds 2.60 2.11
Taille de la grammaire (hors r&#232;gles lex.) 14874 6944
Symb. non-terminaux 13 39
POS tags 15 27
</p>
<p>TAB. 1 &#8211; Statistiques sur Treebanks
</p>
<p>3 Algorithmes d&#8217;analyse syntaxique probabiliste
Les grammaires hors-contexte probabilistes (PCFG) sont le formalisme de base pour l&#8217;analyse
syntaxique (ie. parsing) probabiliste et leur extraction est ais&#233;e de par la nature fondamenta-
lement hors-contexte des annotations syntaxiques d&#8217;un treebank(Jurafsky et al., 2000). N&#233;an-
moins, de la faible puissance g&#233;n&#233;rative du mod&#232;le d&#233;coulent deux probl&#232;mes majeurs pour le
parsing &#224; partir de grammaires extraites de treebank :(a) Les hypoth&#232;ses d&#8217;ind&#233;pendances du
mod&#232;le PCFG sont trop fortes, (b) Les probabilit&#233;s lexicales ne sont pas prises en compte
par le mod&#232;le de base.
Des techniques se projetant dans diff&#233;rents paradigmes de parsing, ont et&#233; propos&#233;es, principa-
lement pour l&#8217;anglais, pour r&#233;soudre ces deux probl&#232;mes. Nous nous proposons d&#8217;explorer ces
techniques en les appliquant sur le fran&#231;ais via deux classes d&#8217;analyseurs. Une premi&#232;re classe
non lexicalis&#233;e qui tente de r&#233;pondre au probl&#232;me (a) et diff&#233;rents mod&#232;les lexicalis&#233;s r&#233;pondant
aux probl&#232;mes (a) et (b).
Algorithmes lexicalis&#233;s : L&#8217;id&#233;e sous-jacente aux algorithmes lexicalis&#233;s est de mod&#233;liser les
d&#233;pendances lexicales entre un gouverneur et ses d&#233;pendants afin d&#8217;am&#233;liorer les choix d&#8217;at-
tachements (Jurafsky et al., 2000). L&#8217;id&#233;e semble &#233;vidente mais bien qu&#8217;il ait &#233;t&#233; maintes fois
prouv&#233; que la lexicalisation &#233;tait utile pour le parsing du PTB (Collins, 1999; Charniak, 2000),
la question de son ad&#233;quation &#224; d&#8217;autres langues s&#8217;est pos&#233;e pour l&#8217;allemand (Dubey &amp; Keller,
2003) et pour le fran&#231;ais (Arun &amp; Keller, 2005). Pour ce dernier, les auteurs d&#233;fendent l&#8217;id&#233;e</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Seddah, Candito &amp; Crabb&#233;
</p>
<p>que le parsing du fran&#231;ais tire b&#233;n&#233;fice de la lexicalisation mais que la platitude du treebank r&#233;-
duit son impact. Notons que ce point a &#233;t&#233; remis en cause par (Schluter &amp; van Genabith, 2007).
En effet, les auteurs maintiennent qu&#8217;un sch&#233;ma d&#8217;annotation am&#233;lior&#233; ainsi qu&#8217;une plus grande
homog&#233;n&#233;it&#233; dans le treebank participent &#224; l&#8217;obtention de r&#233;sultats state-of-the-art.
Ce d&#233;bat sur le fran&#231;ais et la lexicalisation s&#8217;est concentr&#233; sur l&#8217;impl&#233;mentation des mod&#232;les 1
et 2 de Collins par (Bikel, 2002) en tant qu&#8217;instance d&#8217;algorithmes lexicalis&#233;s. Le mod&#232;le g&#233;-
n&#233;ratif de Collins ayant &#233;t&#233; extr&#234;mement optimis&#233; pour les annotations du PTB (Bikel, 2004),
les tentatives d&#8217;adaptation vers d&#8217;autres langues se sont montr&#233;es plus ou moins fructueuses (en
particulier pour l&#8217;allemand o&#249; un mod&#232;le PCFG s&#8217;est av&#233;r&#233; plus efficace que le mod&#232;le 2 de
Collins, m&#234;me avec un mod&#232;le de parsing enrichi (Dubey &amp; Keller, 2003)).
C&#8217;est pourquoi afin d&#8217;apporter des &#233;l&#233;ments de r&#233;ponses suppl&#233;mentaires, nous avons adapt&#233;,
outre les mod&#232;les de Collins via l&#8217;adaptation au FTB de leur impl&#233;mentation par (Bikel, 2002),
le parser de Charniak (Charniak, 2000) ainsi que le parser STIG de David Chiang (Chiang,
2000).
Algorithmes non lexicalis&#233;s : Comme instance de ce paradigme, le dernier parser que nous
utilisons est le parser de Berkeley (ie. BKY, (Petrov et al., 2006)). Son algorithme est une
&#233;volution des principes de transformation de treebank visant &#224; r&#233;duire les hypoth&#232;ses d&#8217;ind&#233;-
pendance propres aux PCFG (Johnson, 1998; Klein &amp; Manning, 2003). Les transformations
de treebank peuvent &#234;tre de deux types : (1) modification de structures et (2) modification du
jeu d&#8217;annotation. BKY se concentre sur le second point en consid&#233;rant la recherche d&#8217;un jeu
d&#8217;annotation des symboles non-terminaux comme un probl&#232;me d&#8217;apprentissage semi-supervis&#233;
visant &#224; apprendre une PCFG &#224; Annotations Latentes (PCFG-LA). (Crabb&#233; &amp; Candito, 2008)
rapporte les scores les plus &#233;lev&#233;s d&#8217;&#233;valuation en constituants sur le FTB en ayant adapt&#233; ce
parser pour le fran&#231;ais puis construit un jeu d&#8217;annotations optimisant ses r&#233;sultats.
</p>
<p>4 Protocole exp&#233;rimental
4.1 Param&#233;trage des parsers
Configuration : Dans le cas de BKY, suivant en cela (Crabb&#233; &amp; Candito, 2008), nous l&#8217;utilisons
avec une markovisation horizontale h = 5 et 5 cycles split/merge. Toute l&#8217;information n&#233;ces-
saire &#224; l&#8217;apprentissage de BKY est contenue dans le treebank, aucune heuristique n&#8217;est utilis&#233;e
except&#233; pour le traitement des mots inconnus qui suit celui de (Arun &amp; Keller, 2005). Tous les
autres parsers sont utilis&#233;s dans leurs configurations de base et n&#8217;ont subi que des modifications
li&#233;es aux nouveaux jeux d&#8217;annotations propres aux treebanks du fran&#231;ais. Notons enfin que les
jeux d&#8217;annotations n&#8217;ont pas &#233;t&#233; modifi&#233;s sp&#233;cifiquement pour tel ou tel parser, ainsi les auxi-
liaires, contrairement &#224; (Charniak, 2000), ne re&#231;oivent pas de traitements particuliers.
Adaptation Morphologique et typographique : Dans le cas des parsers lexicalis&#233;s, nous avons
automatiquement converti les parties du discours associ&#233;es aux marques de ponctuation au for-
mat du PTB. Le traitement morphologique pour les mots inconnus est le m&#234;me pour les mod&#232;les
de Collins que pour BKY. Les mots inconnus sont clusteris&#233;s, &#224; l&#8217;aide d&#8217;indices typographiques
et morphologiques, si leur fr&#233;quence est inf&#233;rieure &#224; 6 sauf dans le cas de CHARNIAK o&#249; tous
les mots sont pris en compte mais subissent un lissage lexical afin d&#8217;att&#233;nuer la dispersion de
donn&#233;es.
Table de percolation des t&#234;tes et distinction argument-adjoint : Tous les parsers lexicalis&#233;s
que nous utilisons font usage d&#8217;une table de percolation de t&#234;te (ie. headrules) qui utilise des
informations configurationnelles pour d&#233;terminer dynamiquement la t&#234;te d&#8217;un noeud donn&#233; en</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Parsing statistique lexicalis&#233; pour le fran&#231;ais
</p>
<p>fonction des cat&#233;gories de ses fils (Collins, 1999). Par cons&#233;quent, l&#8217;adaptation de ces parsers
au fran&#231;ais n&#233;cessite de construire une telle table. Nous avons ainsi adapt&#233; celles construites par
(Dybro-Johansen, 2004) &#224; des fins d&#8217;extractions de grammaires d&#8217;arbres adjoints &#224; partir du FTB
originel. Comme le mod&#232;le 2 de Collins et le mod&#232;le STIG n&#233;cessitent de pouvoir distinguer
entre arguments et adjoints (pour apprendre les probabilit&#233;s des cadres de sous-cat&#233;gorisations
dans le cas de Collins et pour extraire les arbres initiaux de la grammaire TIG dans celui de
STIG), nous avons impl&#233;ment&#233; une table de distinction argument-adjoint (d&#233;sormais TDAA)
bas&#233;e sur les annotations fonctionnelles. C&#8217;est l&#8217;une des principales diff&#233;rences entre nos exp&#233;-
rimentations et celles de (Arun &amp; Keller, 2005; Dybro-Johansen, 2004) o&#249; les auteurs, n&#8217;ayant
pas de corpus avec annotations fonctionnelles, ont d&#251; construire des TDAA uniquement bas&#233;es
sur les cat&#233;gories syntaxiques d&#8217;un corpus extr&#234;mement plat.
D&#233;tails d&#8217;impl&#233;mentation Notons que dans le cas du parser STIG, le fait de n&#8217;avoir pas acc&#232;s &#224;
une TDAA le conduit &#224; extraire une grammaire o&#249; presque tous les arbres ont une structure &#8220;fi-
laire&#8221; compos&#233;e uniquement du chemin entre un &#233;l&#233;ment lexical et sa projection maximale (que
nous appelons spine2). Cette configuration particuli&#232;re permet au mod&#232;le probabiliste STIG,
se d&#233;coupant entre les probabilit&#233;s associ&#233;es aux sch&#233;mas d&#8217;arbres &#233;l&#233;mentaires et celles des
ancres, de produire une grammaire moins &#233;parpill&#233;e que le mod&#232;le STIG standard. Pr&#233;cisons
enfin que le transcodage des tables vers les formats attendus par les parsers est enti&#232;rement au-
tomatis&#233;.
En guise d&#8217;&#233;mulation &#8220;brutale&#8221; du mod&#232;le 1 de Collins, nous utilisons le param&#233;trage standard
du mod&#232;le 2 fourni par l&#8217;impl&#233;menation sans informations de sous-cat&#233;gorisation. Par ailleurs,
en utilisant un jeu de param&#232;tres non standard visant &#224; modifier la fa&#231;on dont le mod&#232;le g&#233;n&#233;-
ratif tient compte des non-terminaux modifieurs, nous obtenons des r&#233;sultats significativement
meilleurs que ceux du mod&#232;le 2 sur le fran&#231;ais. Dans un cas (le MOD&#200;LE X) tous les modi-
fieurs pr&#233;c&#233;dant la t&#234;te sont inclus dans le mod&#232;le alors que seul le modifieur, pr&#233;alablement
clusteris&#233;, qui la pr&#233;c&#232;de est inclus dans le MOD&#200;LE 2.
</p>
<p>4.2 Protocole d&#8217;&#233;valuation
Pour chaque exp&#233;rience, nous donnons les r&#233;sultats selon un d&#233;coupage classique des treebanks
en 3 parties (entra&#238;nement, d&#233;veloppement et test) de respectivement 80, 10 et 10% de la taille
totale du corpus. Les corpus de test et de d&#233;veloppement sont respectivement les deux premi&#232;res
tranches de 1235 phrases du FTB et sont pr&#233;d&#233;finis pour le MFT. Dans tous les cas, les mots
compos&#233;s sont fusionn&#233;s dans une phase de pr&#233;processus. Les parsers re&#231;oivent en entr&#233;e du
texte nu, except&#233; le parser STIG qui n&#8217;accepte que des entr&#233;es &#233;tiquet&#233;es et pour lequel nous
avons entra&#238;n&#233; le tagger TNT (Brants, 2000) sur les treebanks.3
</p>
<p>M&#233;triques d&#8217;&#233;valuation : Nous utilisons la m&#233;trique standard PARSEVAL 4 ainsi qu&#8217;une &#233;va-
luation en d&#233;pendance non typ&#233;e, d&#233;crite comme une m&#233;trique plus neutre que PARSEVAL face
au jeu d&#8217;annotation (cf.(Rehbein &amp; van Genabith, 2007)). L&#8217;&#233;valuation des d&#233;pendances non
typ&#233;es est faite selon l&#8217;algorithme de (Lin, 1995) et utilise les headrules de Dybro-Johansen.
Le F-score en d&#233;pendances non-typ&#233;es donne le pourcentage des tokens hors ponctuation qui
</p>
<p>2A ne pas confondre avec le spine dans le mod&#232;le TAG qui est le chemin entre un noeud pied et la racine d&#8217;un
arbre auxiliaire (Joshi, 1987).
</p>
<p>3Les performances de cet &#233;tiqueteur sont du m&#234;me ordre que celles de l&#8217;&#233;tiqueteur interne des autres parsers,
avec une pr&#233;cision d&#8217;&#233;tiquetage allant de 97.33% sur le FTB avec tagset minimal pour BIKEL (mod&#232;le 1) et 97.21%
pour STIG (spinal) avec entr&#233;es TNT.
</p>
<p>4Impl&#233;ment&#233;e par le programme classique EVALB avec les param&#232;tres standard de Collins et calcul&#233;e sur les
phrases de longueur &lt; &#224; 40 mots.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Seddah, Candito &amp; Crabb&#233;
</p>
<p>re&#231;oivent la t&#234;te correcte.
</p>
<p>Baseline : Comparaison sur les jeux d&#8217;annotations minimum Nous avons compar&#233; tous
les parsers sur 2 diff&#233;rentes instances du FTB et du MFT et afin d&#8217;&#233;tablir une baseline, les
jeux d&#8217;annotations (ie. tagset) des treebanks sont convertis vers un tagset minimal ne conte-
nant que les cat&#233;gories syntaxiques de base sans aucune autre information que les &#233;tiquettes
fonctionnelles, utilis&#233;es uniquement dans le cas pr&#233;cis des parsers STIG-pure et des mod&#232;les
de Collins. Notons qu&#8217;ici nous ne cherchons pas &#224; comparer la forme des treebanks ou leurs
parsabilit&#233;s intrins&#232;ques, il s&#8217;agit simplement d&#8217;&#233;tablir un tour d&#8217;horizon des parsers sur des
treebanks d&#233;nu&#233;s de toute optimisation de leurs tagsets. Dans tous les cas, nous observons que
BKY pr&#233;sente des performances sup&#233;rieures aux autres dans toutes les m&#233;triques (cf.Tableau
2), ce qui confirme les r&#233;sultats observ&#233;s dans (Crabb&#233; &amp; Candito, 2008). le parser STIG, dans
ses deux modes de fonctionnement pur et spinal, ne pr&#233;sente pas de diff&#233;rence statistiquement
signifiante en m&#233;trique PARSEVAL5 au moins dans les r&#233;sultats PARSEVAL. C&#8217;est pourquoi dans
un souci d&#8217;espace nous ne pr&#233;sentons par la suite que les r&#233;sultat en mode STIG-spinal.
</p>
<p>FTB-min MFT-min
COLLINS MX PARSEVAL 81.65 79.19
</p>
<p>UNLAB. DEP 88.48 84.96
COLLINS M2 PARSEVAL 80.1 78.38
</p>
<p>UNLAB. DEP 87.45 84.57
COLLINS M1 PARSEVAL 77.98 76.09
</p>
<p>UNLAB. DEP 85.67 82.83
CHARNIAK PARSEVAL 82,44 81.34
</p>
<p>UNLAB. DEP 88.42 84.90
CHIANG-SPINAL PARSEVAL 80.66 80.74
</p>
<p>UNLAB. DEP 87.92 85,14
BKY PARSEVAL 84,93 83.16
</p>
<p>UNLAB. DEP 90.06 87.29
CHIANG-PUR PARSEVAL 80.52 79.56
</p>
<p>UNLAB. DEP 87,95 85.02
</p>
<p>TAB. 2 &#8211; F1 scores des parsers lexicalis&#233;s et non lexicalis&#233;s sur Treebank avec tagset minimal
</p>
<p>5 Evaluation des analyseurs en fonction des variations des
jeux d&#8217;annotations
</p>
<p>Dans (Crabb&#233; &amp; Candito, 2008) les auteurs ont pr&#233;sent&#233; des exp&#233;riences visant &#224; d&#233;terminer un
jeu d&#8217;annotation (i.e. tagset), nomm&#233; FTB-CC ici et TREEBANK+ dans l&#8217;article, maximisant les
performances du parser de Berkeley sur le FTB avec un F1-score(&lt;=40) de 86.41%. Ce tagset
inclut des informations de mode pour les verbes (ie. indicatif, imp&#233;ratif, participe pass&#233;, etc.) et
certains traits de sous-cat&#233;gorie (cf. (Crabb&#233; &amp; Candito, 2008), Table 2). L&#8217;impact de diverses
variations de tagsets appliqu&#233;es au FTB, qui n&#8217;a pas &#233;t&#233; con&#231;u dans une optique de parsing, a
ainsi &#233;t&#233; test&#233; via des mesures de constituance comme indicateur de performance.
Sachant que le MFT a par contre &#233;t&#233; con&#231;u dans une optique de maximisation des performances
d&#8217;un analyseur de grammaires LFG, donc visant &#224; produire des d&#233;pendances syntaxiques pro-
fondes, induites &#224; partir de sortie d&#8217;analyseurs statistiques (Schluter &amp; van Genabith, 2008), il
offre des performances n&#233;anmoins &#233;tonnantes au vu de sa taille r&#233;duite. L&#8217;influence de son tag-
set et de ses modifications structurelles sont d&#233;terminantes et il aurait &#233;t&#233; int&#233;ressant de v&#233;rifier
</p>
<p>5avec une p-value en F-score de 0.32</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Parsing statistique lexicalis&#233; pour le fran&#231;ais
</p>
<p>leur impact sur davantage de donn&#233;es.
Malheureusement, des modifications semi-automatiques du MFT (en particulier celles apport&#233;es
au sch&#233;ma de coordination) ne peuvent pas &#234;tre reproduites de fa&#231;on r&#233;versible et automatique.
Toutefois, si nous ne pouvons pas r&#233;ellement &#233;valuer l&#8217;influence de la structure, nous pouvons
&#233;valuer celle d&#8217;un tagset particulier appliqu&#233; &#224; un autre treebank &#224; l&#8217;aide d&#8217;outils de conversions.
A cette fin, les tagsets maximisant les r&#233;sultats PARSEVAL sont extraits de leurs treebanks res-
pectifs (le tagset CC pour le FTB et le tagset SCHLU pour le MFT) et appliqu&#233;s sur l&#8217;autre tree-
bank. Nous avons donc deux tagsets pour chaque treebank sur lesquels nous &#233;valuons chaque
parser en d&#233;pendance non-typ&#233;e et en constituance. La table 3 pr&#233;sente les r&#233;sultats en surli-
gnant les meilleurs scores pour chaque paire de treebanks.
</p>
<p>Parser
</p>
<p>Collins (MX)
Collins (M2)
Collins (M1)
Charniak
Chiang (Sp)
Bky
</p>
<p>Parseval Dependency
MFTCC MFTSCH. MFTCC MFTSCH.
</p>
<p>80.2 80.96 85.97 87.98
78.56 79.91 84.84 87.43
</p>
<p>74 78.49 81.31 85.94
82.5 82.66 86.45 86.94
82.6 81.97 86.7 87.16
83.96 82.86 87.41 86.87
</p>
<p>Parseval Dependency
FTBCC FTBSCH. FTBCC FTBSCH.
82.52 82.65 88.96 89.12
80.8 79.56 87.94 87.87
</p>
<p>79.16 78.51 86.66 86.93
84.27 83.27 89.7 89.67
81.73 81.54 88.85 89.02
86.02 84.95 90.48 90.73
</p>
<p>TAB. 3 &#8211; R&#233;sultats d&#8217;&#233;valuation MFT-CC vs MFT-SCHLU et FTB-CC vs FTB-SCHLU
</p>
<p>Les r&#233;sultats de ces exp&#233;riences, Table 3, confirment la tendance visible dans le cas d&#8217;un parsing
avec tagset minimal (cf. Table 2), &#224; savoir que BKY pr&#233;sente toujours les scores les plus &#233;lev&#233;s
quelque soit la m&#233;trique. Notons que les &#233;valuations en d&#233;pendances non-typ&#233;es sont syst&#233;ma-
tiquement meilleures sur le tagset SCHLU que sur le tagset CC. On peut l&#8217;expliquer par une plus
grande pr&#233;cision des headrules sur ce tagset. En effet, ces r&#232;gles ayant &#233;t&#233; g&#233;n&#233;r&#233;es &#224; partir de
m&#233;ta-descriptions6 , leurs couvertures et leurs pr&#233;cisions globales sont plus &#233;lev&#233;es. On a, par
exemple, 18 r&#232;gles pour FTB-CC et 43 pour FTB-SCHLU.
Comme pr&#233;vu au regard des scores sur le PTB, le classement PARSEVAL des parsers lexicalis&#233;s
donne &#224; CHARNIAK les meilleurs performances quel que soit le tagset, en ne consid&#233;rant pas le
score de STIG-spinal sur le MFT-CC qui t&#233;moigne d&#8217;une variation non statistiquement signifi-
cative avec le score de CHARNIAK sur ce treebank.7 En revanche, l&#8217;&#233;valuation en d&#233;pendance
des parsers lexicalis&#233;s est diff&#233;rentes selon le treebank. Dans le cas du FTB, CHARNIAK pr&#233;-
sente les meilleurs scores, tandis que le mod&#232;le STIG-spinal a de meilleures performances sur
les MFT-SCHLU et MFT-CC. Notons que les variations du mod&#232;le 2 de Collins pr&#233;sentent des
r&#233;sultats &#233;lev&#233;s en d&#233;pendance sur le MFT-SCHLU alors que leurs scores parseval sont les plus
faibles. Les faibles scores des mod&#232;les de Collins de base en constituance peuvent s&#8217;expliquer
par la dispersion de donn&#233;es accrue apport&#233;e par les annotations fonctionnelles, en particulier
sur des corpus de taille r&#233;duite.
</p>
<p>6 Discussion
Comme nous l&#8217;avons d&#233;ja dit dans l&#8217;introduction, les travaux pr&#233;curseurs sur le FTB ont &#233;t&#233;
initi&#233;s par (Dybro-Johansen, 2004) dans une optique d&#8217;extraction de grammaire TAG ; bien
qu&#8217;elle n&#8217;y reporte pas de r&#233;sultats d&#8217;analyse syntaxique, les m&#234;mes probl&#232;mes de distinction
</p>
<p>6Un label COORD se r&#233;&#233;crit par exemple COORD_vfinite, COORD_sint, etc.
7P-value &#233;lev&#233;e de 0.1272 en pr&#233;cision et 0.06 en rappel.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Seddah, Candito &amp; Crabb&#233;
</p>
<p>entre compl&#233;ments et adjoints que (Arun &amp; Keller, 2005) se sont pos&#233;s. C&#8217;est l&#8217;aspect tr&#232;s plat
du treebank ainsi que l&#8217;absence d&#8217;annotations fonctionnelles dans cette version distribu&#233;e en
2004 qui ont conduit Arun &#224; modifier le jeu d&#8217;annotation (par exemple VNG pour distinguer
les noeuds VN qui dominent un verbe sous-cat&#233;gorisant des clitiques) et &#224; enrichir le mod&#232;le
g&#233;n&#233;ratif de Collins afin d&#8217;am&#233;liorer les performances globales de l&#8217;analyseur.
La question se pose de savoir si ces modifications se justifiaient sur le treebank initial &#233;tant
donn&#233; que les r&#233;sultats de nos analyseurs entra&#238;n&#233;s sur le corpus initial sont sup&#233;rieurs non
seulement &#224; ceux report&#233;s dans (Arun &amp; Keller, 2005)8 mais aussi &#224; ceux obtenus en utilisant
leur propre impl&#233;mentation du mod&#232;le 2 de Collins entra&#238;n&#233; avec notre table de percolation de
t&#234;te et avec leur propre TDAA.
</p>
<p>PARSER FTBARUN MFTSCHLU
Arun (acl05) 80.45 -
Arun (emnlp) 81.08 -
Schluter - 79.95
Collins (Mx) 81.5 80,96
Collins (M2) 79.36 79,91
Collins (M1) 77.82 -
Charniak 82.35 82,66
Chiang (Sp) 80.94 81,86
Bky 84.03 82.86
</p>
<p>TAB. 4 &#8211; Scores Parseval sur le FTB utilis&#233; par Arun et sur le MFT
</p>
<p>Nous sommes aussi directement comparables avec (Schluter &amp; van Genabith, 2007) dont le
meilleur F1 score PARSEVAL en texte nu est de 79.95 quand le n&#244;tre est de 82.86 sur le MFT
(cf. Table. 4).
Concernant les faibles r&#233;sultats du mod&#232;le 2 de Collins dans presque tous les cas de figure, cela
est selon nous d&#251; &#224; l&#8217;&#233;parpillement provoqu&#233; par l&#8217;ajout d&#8217;annotations fonctionnelles dans des
petits treebanks. De plus, con&#231;us pour l&#8217;anglais, son mod&#232;le s&#8217;exporte manifestement moins
bien dans des treebanks moins hi&#233;rarchis&#233;s que le PTB. Cette observation rejoint celles &#233;mises
par (Corazza et al., 2004) dans le cas d&#8217;une adaptation de ce mod&#232;le &#224; l&#8217;italien sur de tr&#232;s pe-
tits treebanks (moins de 3000 phrases). En revanche, nous ne partageons pas le point de vue
commun&#233;ment admis sur un relatif &#233;chec des mod&#232;les lexicalis&#233;s ; &#224; notre connaissance seuls
les mod&#232;les de Collins, via leur impl&#233;mentation de BIKEL ont &#233;t&#233; adapt&#233;s &#224; des langues euro-
p&#233;ennes. Les performances compar&#233;es du mod&#232;le de Charniak face &#224; celui de BKY s&#8217;&#233;valuent
selon un ordre de grandeur similaire &#224; celui connu pour le parsing du la section 23 du PTB. Par
manque de place, nous ne pouvons inclure qu&#8217;un graphique repr&#233;sentant la courbe d&#8217;apprentis-
sage des parsers, n&#8217;utilisant pas de TDAA, en mode Perfect-tagging sur le FTB-CC (fig. 1), mais
celle-ci montre que la courbe d&#8217;apprentissage de CHARNIAK est quasiment parall&#232;le &#224; celle de
BKY tandis que les mod&#232;les de Collins (ici le mod&#232;le X sans TDAA a &#233;t&#233; utilis&#233;) et STIG ont
des courbes qui se confondent quasiment et qui plafonnent tr&#232;s vite.9 Ces deux mod&#232;les ayant
des back-off extr&#234;mement similaires, on peut se demander (1) si ce n&#8217;est pas eux qu&#8217;on compare
en r&#233;alit&#233; et (2) si la petite taille des corpus autres que le PTB ne pousse pas la communaut&#233; &#224;
</p>
<p>8Les r&#233;sultats actualis&#233;s sont disponibles via l&#8217;url suivante :
(http ://homepages.inf.ed.ac.uk/s0343799/acl2005slides.pdf).
</p>
<p>9Nous sommes bien s&#251;r conscients que les valeurs de cette courbe sont aussi fonction du nombre de nouvelles
productions amen&#233;es par l&#8217;accroissement du lexique ; dans ce cas il faudrait aussi comparer les modes de &#8220;pruning&#8221;
de ces mod&#232;les.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Parsing statistique lexicalis&#233; pour le fran&#231;ais
</p>
<p>consid&#233;rer les mod&#232;les lexicalis&#233;s, &#224; travers les seuls mod&#232;les de Collins, comme inad&#233;quats &#224;
d&#8217;autres langues que l&#8217;anglais du type Wall Street Journal.
</p>
<p>FIG. 1 &#8211; Courbe d&#8217;apprentissage sur FTB-CC en mode perfect-tagging
</p>
<p>7 Conclusion
</p>
<p>Nous avons pr&#233;sent&#233; des r&#233;sultats de parsing statistique lexicalis&#233; et non lexicalis&#233; sur tous les
treebanks du fran&#231;ais &#224; notre disposition. Ces r&#233;sultats state of the art confirment la maturit&#233;
du FTB en cette mati&#232;re et soulignent l&#8217;influence du jeu d&#8217;annotation sur les performances des
analyseurs. Par ailleurs, par le test de multiples analyseurs, nous avons montr&#233; que le d&#233;bat
sur les b&#233;n&#233;fices de la lexicalisation pouvait b&#233;n&#233;ficier de l&#8217;inclusion de diff&#233;rents mod&#232;les
lexicalis&#233;s.
</p>
<p>R&#233;f&#233;rences
ABEILL&#201; A., CL&#201;MENT L. &amp; TOUSSENEL F. (2003). Building a Treebank for French, In
Treebanks. Kluwer : Dordrecht.
ARUN A. &amp; KELLER F. (2005). Lexicalization in crosslinguistic probabilistic parsing : The
case of french. In Proceedings of the 43rd Annual Meeting of the Association for Computatio-
nal Linguistics, p. 306&#8211;313, Ann Arbor, MI.
BIKEL D. M. (2002). Design of a multi-lingual, parallel-processing statistical parsing en-
gine. In Proceedings of the second international conference on Human Language Technology
Research, p. 178&#8211;182 : Morgan Kaufmann Publishers Inc. San Francisco, CA, USA.
BIKEL D. M. (2004). Intricacies of Collins&#8217; Parsing Model. Computational Linguistics, 30(4),
479&#8211;511.
BRANTS T. (2000). Tnt &#8211; a statistical part-of-speech tagger. In Proceedings of the 6th Applied
NLP Conference (ANLP), Seattle-WA.
CAHILL A., BURKE M., O&#8217;DONOVAN R., VAN GENABITH J. &amp; WAY A. (2004). Long-
Distance Dependency Resolution in Automatically Acquired Wide-Coverage PCFG-Based
LFG Approximations. In Proceedings of the 42nd Annual Meeting of the Association for
Computational Linguistics, p. 320&#8211;327, Barcelona, Spain.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Seddah, Candito &amp; Crabb&#233;
</p>
<p>CHARNIAK E. (2000). A maximum-entropy-inspired parser. In Proceedings of the 1st Annual
Meeting of the North American Chapter of the ACL (NAACL), Seattle.
CHIANG D. (2000). Statistical parsing with an automatically-extracted tree adjoining gram-
mar. Proceedings of the 38th Annual Meeting on Association for Computational Linguistics,
p. 456&#8211;463.
COLLINS M. (1999). Head Driven Statistical Models for Natural Language Parsing. PhD
thesis, University of Pennsylvania, Philadelphia.
CORAZZA A., LAVELLI A., SATTA G. &amp; ZANOLI R. (2004). Analyzing an Italian treebank
with state-of-the-art statistical parsers. In Proc. of the Third Third Workshop on Treebanks
(TLT 2004) and Linguistic Theories.
CRABB&#201; B. &amp; CANDITO M. (2008). Exp&#233;riences d&#8217;analyse syntaxique statistique du fran-
&#231;ais. In Actes de la 15&#232;me Conf&#233;rence sur le Traitement Automatique des Langues Naturelles
(TALN&#8217;08), p. 45&#8211;54, Avignon.
DUBEY A. &amp; KELLER F. (2003). Probabilistic parsing for german using sister-head depen-
dencies. In In Proceedings of the 41st Annual Meeting of the Association for Computational
Linguistics, p. 96&#8211;103.
DYBRO-JOHANSEN A. (2004). Extraction automatique de grammaires &#224; partir d&#8217;un corpus
fran&#231;ais. Master&#8217;s thesis, Universit&#233; Paris 7.
JOHNSON M. (1998). PCFG models of linguistic tree representations. Computational Lin-
guistics, 24(4), 613&#8211;632.
JOSHI A. K. (1987). Introduction to tree adjoining grammar. In A. MANASTER-RAMER, Ed.,
The Mathematics of Language : J. Benjamins.
JURAFSKY D., MARTIN J., KEHLER A., VANDER LINDEN K. &amp; WARD N. (2000). Speech
and language processing : An introduction to natural language processing, computational
linguistics, and speech recognition. MIT Press.
KLEIN D. &amp; MANNING C. D. (2003). Accurate unlexicalized parsing. In Proceedings of the
41st Annual Meeting on Association for Computational Linguistics-Volume 1, p. 423&#8211;430 :
Association for Computational Linguistics Morristown, NJ, USA.
LIN D. (1995). A dependency-based method for evaluating broad-coverage parsers. In Inter-
national Joint Conference on Artificial Intelligence, p. 1420&#8211;1425, Montreal.
MARCUS M. P., SANTORINI B. &amp; MARCINKIEWICZ M. A. (1994). Building a large anno-
tated corpus of english : The penn treebank. Computational Linguistics, 19(2), 313&#8211;330.
PETROV S., BARRETT L., THIBAUX R. &amp; KLEIN D. (2006). Learning accurate, compact,
and interpretable tree annotation. In Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meeting of the Association for Computational
Linguistics, Sydney, Australia : Association for Computational Linguistics.
REHBEIN I. &amp; VAN GENABITH J. (2007). Treebank Annotation Schemes and Parser Evalua-
tion for German. In Proceedings of the 16th Nordic Conference of Computational Linguistics
NODALIDA-2007, Tartu, Estonia.
SCHLUTER N. &amp; VAN GENABITH J. (2007). Preparing, restructuring, and augmenting a
french treebank : Lexicalised parsers or coherent treebanks ? In Proceedings of PACLING 07.
SCHLUTER N. &amp; VAN GENABITH J. (2008). Treebank-based acquisition of lfg parsing re-
sources for french. In E. L. R. A. (ELRA), Ed., Proceedings of the Sixth International
Language Resources and Evaluation (LREC&#8217;08), Marrakech, Morocco.</p>

</div></div>
</body></html>