TALN 2009 — Session posters , Senlis, 24-26 juin 2009

Adaptation de parsers statistiques lexicalisés pour le
francais : Une évaluation complete sur corpus arborés

Djamé Seddah<>, Marie Candito* et Benoit Crabbé*
<> Université Paris-Sorbonne * Université Paris 7
LALIC et INRIA (Alpage) UFRL et INRIA (Alpage)

Résumé. Cet articlel présente les résultats d’une évaluation exhaustive des principaux
analyseurs syntaxiques probabilistes dit “lexicalisés” initialement concus pour l’anglais, adap-
tés pour le francais et évalués sur le CORPUS ARBORE DU FRANQAIS (Abeillé et al., 2003) et
le MODIFIED FRENCH TREEBANK (Schluter & van Genabith, 2007).

Conﬁrmant les résultats de (Crabbé & Candito, 2008), nous montrons que les modeles lexica-
lisés, a travers les modeles de Charniak (Charniak, 2000), ceux de Collins (Collins, 1999) et
le modele des TIG Stochastiques (Chiang, 2000), présentent des performances moindres face a
un analyseur PCFG a Annotation Latente (Petrov et al., 2006). De plus, nous montrons que le
choix d’un jeu d’annotations issus de tel ou tel treebank oriente fortement les résultats d’évalua-
tions tant en constituance qu’en dépendance non typée. Comparés a (Schluter & van Genabith,
2008; Arun & Keller, 2005), tous nos résultats sont state-of-the-art et inﬁrment l’hypothese
d’une difﬁculté particuliere qu’aurait le francais en terme d’analyse syntaxique probabiliste et
de sources de données.

Abstract. This paper presents complete investigation results on the statistical parsing
of French by bringing a complete evaluation on French data of the main based probabilistic
lexicalized (Charniak, Collins, Chiang) and unlexicalized (Berkeley) parsers designed ﬁrst on
the Penn Treebank. We adapted the parsers on the two existing treebanks of French (Abeillé
et al., 2003; Schluter & van Genabith, 2007). To our knowledge, all the results reported here
are state-of-the-art for the constituent parsing of French on every available treebank and inva-
lidate the hypothesis of French being particularly difﬁcult to parse. Regarding the algorithms,
the comparisons show that lexicalized parsing models are outperformed by the unlexicalized
Berkeley parser. Regarding the treebanks, we observe that a tag set with speciﬁc features has
direct inﬂuences over evaluation results depending on the parsing model.

M0tS-CléS I Analyse syntaxique probabiliste, corpus arborés, évaluation, analyse du fran-
cais.

Keywords: Probabilistic parsing, treebanks, evaluation, French parsing.

1Ce travail est soutenu par l’ANR programme DEFI 2008 dans le cadre du projet SEQUOIA.
Nous tenons a remercier Abishek Arun, Josef Van Genabith, Alexis Nasr et Natalie Schluter pour nous avoir permis
d ’utiliser leurs ressources ainsi que Marwan El Markour et Rosa Stern pour leur aide.

Seddah, Candito & Crabbe

1 Introduction

Depuis la Inise a disposition progressive du Corpus Arbore de Paris 7 (FTB, (Abeille et al.,
2003)), differents travaux precurseurs portant tant sur l’extraction de grammaires d’arbres ad-
joints (Dybro-Johansen, 2004) que sur l’entrainement d’analyseurs statistiques (Arun & Keller,
2005) sont apparus et demontrent la faisabilite de telles taches sur le FTB. Neanmoins, l’ab-
sence d’annotations fonctionnelles permettant de pallier l’aspect plat des structures syntaxiques
du FTB et l’etat preliminaire du corpus disponible a cette epoque compliquent ces taches et
rendent delicate toute comparaison avec les travaux recents de (Crabbe & Candito, 2008) et
ceux ayant motive la creation du “Modiﬁed French Treebank” (Schluter & van Genabith, 2007;
Schluter & van Genabith, 2008).

Dans cet article, nous presentons les resultats d’une evaluation extensive de cinq modeles de
parsing probabiliste sur les deux corpus arbores du frangais, qui montrent que (1) des resultats
state of the art sont atteints sur toutes les versions du corpus, par consequent le probleme de
la source de donnees pour l’analyse syntaxique du frangais est resolue et (2) que le debat porte
par N.Schluter et A.Arun, sur l’utilite d’algorithmes lexicalises pour le frangais, est loin d’etre
tranche.

Dans un premier temps, section 2, nous presentons nos corpus de travail, puis, section 3, nous
introduisons brievement les modeles d’analyses avant de presenter notre protocole experimental
section 4. Enﬁn, nous discutons les resultats presentes section 5 puis nous concluons.

2 Treebanks pour le francais

Cette section presente un bref apergu des corpus pour lesquels nous presentons des resultats : le
Corpus Arbore du Frangais (FTB, (Abeille et al., 2003)) et le Modiﬁed French Treebank (MFT,
(Schluter & van Genabith, 2007)).

Le Corpus arboré du franc-ais (FTB)

Le FTB est le premier corpus arbore (ie. treebank) annote et corrige manuellement disponible
pour le frangais. Les annotations sont morphologiques et syntaxiques, les secondes incluant
des annotations fonctionnelles pour les dependants verbaux (cf. (Abeille et al., 2003) pour plus
de details). La version utilisee pour ce travail contient 12351 phrases, 385 458 occurrences
de tokens et presente une longueur moyenne de 27 tokens. Comparativement a une longueur
moyenne de 24 tokens pour le Penn Treebank (i.e. PTB, (Marcus et al., 1994)) qui contient pres
de 44 000 phrases pour plus d’un million de tokens, cela rend la tache d’analyse syntaxique plus
delicate. Comme d’autres treebanks (par exemple Tiger, Negra pour l’allemand), le FTB propose
une structure hierarchique plus plate que celle du PTB. En effet, basee sur une representation
X-barre, celle-ci permet une distinction conﬁgurationnelle des syntagmes sous-categorises par
le verbe tandis que seule l’annotation fonctionnelle permet cette distinction dans le cas du FTB.
Ceci est lie, entre autres, au choix de ne pas inclure de noeuds de type VP dans les annotations
syntaxiques du FTB et a en partie conduit les auteurs de (Schluter & van Genabith, 2007) a
re-annoter une partie du corpus a leur disposition dans une optique d’extraction de grammaires
LFG.

le “Modiﬁed French Treebank” (MFT)

Le MFT (Schluter & van Genabith, 2007; Schluter & van Genabith, 2008) est un sous-ensemble
de 4739 phrases tirees du FTB initial, re-annotees seIni-automatiquement et corrigees a la main.
Ses auteurs ont introduit deux differences formelles par rapport a la source : des differences
structurelles et des modiﬁcation du jeu d’annotation. D’un point de vue structurel, les trans-

Parsing statistique lexicalisé pour le francais

formations principales incluent une stratiﬁcation accrue des regles sous-jacentes au treebank
(comme l’introduction d’un noeud VP) et mettent l’accent sur une modiﬁcation du schéma de
coordination (celui-ci ajoutant désormais a l’étiquette COORD le label du noeud coordonné).
Ces modiﬁcations permettent une meilleur adéquation a l’architecture décrite dans (Cahill et al. ,
2004) et permettent de réduire la taille de la grammaire extraite du treebank. Par ailleurs, le
MFT inclut aussi un afﬁnage du jeu d’annotation via l’ajout de certaines informations morpho-
logiques sur les labels des noeuds (tels que des traits de mode supplémentaires sur les noeuds
VP et VN) et par l’afﬁnement du jeu d’étiquettes fonctionnelles.

Finalement, une phase d’err0r mining et une correction manuelle extensive ont été appliquées
sur le corpus.

Le tableau 1 synthétise un certain nombre d’éléments de comparaison entre les deux treebanks
sous leur forme canonique. Les nombres reportés sont calculés en fonction des catégories syn-
taxiques de bases, sans annotations fonctionnelles et sans annotations morpho-syntaxiques sur
les parties du discours (eg. pas de traits “genre” ni “nombre”). La comparaison du nombre
moyen de branchements par noeuds (2.60 pour le FTB et 2.11 pour le MFT) démontre la strati-
ﬁcation plus élevée du MFT.

Carac. FTB MFT
Taille (phrases) 12351 4739
Longueur moy. des phrases 27.48 28.38
Nbre moy. de branch/noeuds 2.60 2.11
Taille de la grammaire (hors régles lex.) 14874 6944
Symb. non—terminaux 13 39
POS tags 15 27

TAB. 1 — Statistiques sur Treebanks

3 Algorithmes d’analyse syntaxique probabiliste

Les grammaires hors-contexte probabilistes (PCFG) sont le formalisme de base pour l’analyse
syntaxique (ie. parsing) probabiliste et leur extraction est aisée de par la nature fondamenta-
lement hors-contexte des annotations syntaxiques d’un treebank(Jurafsky et al., 2000). Nean-
moins, de la faible puissance générative du modele découlent deux problemes majeurs pour le
parsing a partir de grammaires extraites de treebank :(a) Les hypotheses d’indépendances du
modéle PCFG sont trop fortes, (b) Les probabilités lexicales ne sont pas prises en compte
par le modéle de base.

Des techniques se projetant dans différents paradigmes de parsing, ont eté proposées, principa-
lement pour l’anglais, pour résoudre ces deux problemes. Nous nous proposons d’explorer ces
techniques en les appliquant sur le francais via deux classes d’analyseurs. Une premiere classe
non lexicalisée qui tente de répondre au probleme (a) et différents modeles lexicalisés répondant
aux problemes (a) et (b).

Algorithmes lexicalisés : L’idée sous-jacente aux algorithmes lexicalisés est de modéliser les
dépendances lexicales entre un gouvemeur et ses dépendants aﬁn d’améliorer les choix d’at-
tachements (Jurafsky et al., 2000). L’idée semble évidente mais bien qu’il ait été maintes fois
prouvé que la lexicalisation était utile pour le parsing du PTB (Collins, 1999; Charniak, 2000),
la question de son adéquation a d’autres langues s’est posée pour l’allemand (Dubey & Keller,
2003) et pour le francais (Arun & Keller, 2005). Pour ce dernier, les auteurs défendent l’idée

Seddah, Candito & Crabbé

que le parsing du francais tire bénéﬁce de la lexicalisation mais que la platitude du treebank ré-
duit son impact. Notons que ce point a été remis en cause par (Schluter & van Genabith, 2007).
En effet, les auteurs maintiennent qu’un schéma d’annotation amélioré ainsi qu’une plus grande
homogénéité dans le treebank participent a l’obtention de résultats state-of-the-art.

Ce débat sur le francais et la lexicalisation s’est concentré sur l’implémentation des modeles 1
et 2 de Collins par (Bikel, 2002) en tant qu’instance d’algorithmes lexicalisés. Le modele ge-
nératif de Collins ayant été extrémement optimisé pour les annotations du PTB (Bikel, 2004),
les tentatives d’adaptation vers d’autres langues se sont montrées plus ou moins fructueuses (en
particulier pour l’allemand o1‘1 un modele PCFG s’est avéré plus efﬁcace que le modele 2 de
Collins, méme avec un modele de parsing enrichi (Dubey & Keller, 2003)).

C’est pourquoi aﬁn d’apporter des éléments de réponses supplémentaires, nous avons adapté,
outre les modeles de Collins via l’adaptation au FTB de leur implémentation par (Bikel, 2002),
le parser de Charniak (Charniak, 2000) ainsi que le parser STIG de David Chiang (Chiang,
2000)

Algorithmes non lexicalisés : Comme instance de ce paradigme, le dernier parser que nous
utilisons est le parser de Berkeley (ie. BKY, (Petrov et al., 2006)). Son algorithme est une
évolution des principes de transformation de treebank visant a réduire les hypotheses d’indé-
pendance propres aux PCFG (Johnson, 1998; Klein & Manning, 2003). Les transformations
de treebank peuvent étre de deux types : (1) modiﬁcation de structures et (2) modiﬁcation du
jeu d’annotation. BKY se concentre sur le second point en considérant la recherche d’un jeu
d’annotation des symboles non-terminaux comme un probleme d’apprentissage semi-supervisé
visant a apprendre une PCFG a Annotations Latentes (PCFG-LA). (Crabbé & Candito, 2008)
rapporte les scores les plus élevés d’évaluation en constituants sur le FTB en ayant adapté ce
parser pour le francais puis construit un jeu d’annotations optimisant ses résultats.

4 Protocole expérimental
4.1 Paramétrage des parsers

Conﬁguration : Dans le cas de BKY, suivant en cela (Crabbé & Candito, 2008), nous l’utilisons
avec une markovisation horizontale h = 5 et 5 cycles split/merge. Toute l’information neces-
saire a l’apprentissage de BKY est contenue dans le treebank, aucune heuristique n’est utilisée
excepté pour le traitement des mots inconnus qui suit celui de (Arun & Keller, 2005). Tous les
autres parsers sont utilisés dans leurs conﬁgurations de base et n’ont subi que des modiﬁcations
liées aux nouveaux jeux d’annotations propres aux treebanks du francais. Notons enﬁn que les
jeux d’annotations n’ont pas été modiﬁés spéciﬁquement pour tel ou tel parser, ainsi les auxi-
liaires, contrairement a (Charniak, 2000), ne recoivent pas de traitements particuliers.
Adaptation Morphologique et typographique : Dans le cas des parsers lexicalisés, nous avons
automatiquement converti les parties du discours associées aux marques de ponctuation au for-
mat du PTB. Le traitement morphologique pour les mots inconnus est le méme pour les modeles
de Collins que pour BKY. Les mots inconnus sont clusterisés, a l’aide d’indices typographiques
et morphologiques, si leur fréquence est inférieure a 6 sauf dans le cas de CHARNIAK ou tous
les mots sont pris en compte mais subissent un lissage lexical aﬁn d’atténuer la dispersion de
données.

Table de percolation des tétes et distinction argument-adjoint : Tous les parsers lexicalisés
que nous utilisons font usage d’une table de percolation de téte (ie. headmles) qui utilise des
informations conﬁgurationnelles pour déterminer dynamiquement la téte d’un noeud donné en

Parsing statistique lexicalise pour le francais

fonction des categories de ses ﬁls (Collins, 1999). Par consequent, l’adaptation de ces parsers
au francais necessite de construire une telle table. Nous avons ainsi adapte celles construites par
(Dybro-Johansen, 2004) a des ﬁns d’extractions de grarnmaires d’arbres adjoints a partir du FTB
originel. Comme le modele 2 de Collins et le modele STIG necessitent de pouvoir distinguer
entre arguments et adjoints (pour apprendre les probabilites des cadres de sous-categorisations
dans le cas de Collins et pour extraire les arbres initiaux de la grarnmaire TIG dans celui de
STIG), nous avons implemente une table de distinction argument-adjoint (desormais TDAA)
basee sur les annotations fonctionnelles. C’est l’une des principales differences entre nos expe-
rimentations et celles de (Arun & Keller, 2005; Dybro-Johansen, 2004) ou les auteurs, n’ayant
pas de corpus avec annotations fonctionnelles, ont dﬁ construire des TDAA uniquement basees
sur les categories syntaxiques d’un corpus extremement plat.

Details d’implémentation Notons que dans le cas du parser STIG, le fait de n’avoir pas acces a
une T DAA le conduit a extraire une grarnrnaire ou presque tous les arbres ont une structure “ﬁ-
laire” composee uniquement du chemin entre un element lexical et sa projection maximale (que
nous appelons spinez). Cette conﬁguration particuliere permet au modele probabiliste STIG,
se decoupant entre les probabilites associees aux schemas d’arbres elementaires et celles des
ancres, de produire une grarnmaire moins eparpillee que le modele STIG standard. Precisons
enﬁn que le transcodage des tables vers les formats attendus par les parsers est entierement au-
tomatise.

En guise d’emulation “brutale” du modele 1 de Collins, nous utilisons le parametrage standard
du modele 2 fourni par l’implemenation sans informations de sous-categorisation. Par ailleurs,
en utilisant un jeu de parametres non standard visant a modiﬁer la facon dont le modele gene-
ratif tient compte des non-terminaux modiﬁeurs, nous obtenons des resultats signiﬁcativement
meilleurs que ceux du modele 2 sur le francais. Dans un cas (le MODELE X) tous les modi-
ﬁeurs precedant la tete sont inclus dans le modele alors que seul le modiﬁeur, prealablement
clusterise, qui la precede est inclus dans le MODELE 2.

4.2 Protocole d’évaluation

Pour chaque experience, nous donnons les resultats selon un decoupage classique des treebanks
en 3 parties (entrainement, developpement et test) de respectivement 80, 10 et 10% de la taille
totale du corpus. Les corpus detest et de developpement sont respectivement les deux premieres
tranches de 1235 phrases du FTB et sont predeﬁnis pour le MFT. Dans tous les cas, les mots
composes sont fusionnes dans une phase de preprocessus. Les parsers recoivent en entree du
texte nu, excepte le parser STIG qui n’accepte que des entrees etiquetees et pour lequel nous
avons entraine le tagger TNT (Brants, 2000) sur les treebanks.3

Métriques d’évaluation : Nous utilisons la metrique standard PARSEVAL 4 ainsi qu’une eva-
luation en dependance non typee, decrite comme une metrique plus neutre que PARSEVAL face
au jeu d’annotation (cf.(Rehbein & van Genabith, 2007)). L’evaluation des dependances non
typees est faite selon l’algorithme de (Lin, 1995) et utilise les headmles de Dybro-Johansen.
Le F-score en dependances non-typees donne le pourcentage des tokens hors ponctuation qui

2A ne pas confondre avec le spine dans le modele TAG qui est le chemin entre un noeud pied et la racine d’un
arbre auxiliaire (Joshi, 1987).

3Les performances de cet etiqueteur sont du meme ordre que celles de l’etiqueteur inteme des autres parsers,
avec une precision d’etiquetage allant de 97.33% sur le FTB avec tagset minimal pour BIKEL (modele 1) et 97.21%
pour STIG (spinal) avec entrees TNT.

4Implementee par le programme classique EVALB avec les parametres standard de Collins et calculee sur les
phrases de longueur < a 40 mots.

Seddah, Candito & Crabbé

recoivent la téte correcte.

Baseline : Comparaison sur les jeux d’annotations minimum Nous avons comparé tous
les parsers sur 2 différentes instances du FTB et du MFT et aﬁn d’établir une baseline, les
jeux d’annotations (ie. tagset) des treebanks sont convertis vers un tagset minimal ne conte-
nant que les catégories syntaxiques de base sans aucune autre information que les étiquettes
fonctionnelles, utilisées uniquement dans le cas précis des parsers STIG-pure et des modeles
de Collins. Notons qu’ici nous ne cherchons pas a comparer la forme des treebanks ou leurs
parsabilités intrinseques, il s’agit simplement d’établir un tour d’horizon des parsers sur des
treebanks dénués de toute optimisation de leurs tagsets. Dans tous les cas, nous observons que
BKY présente des performances supérieures aux autres dans toutes les métriques (cf.Tableau
2), ce qui conﬁrme les résultats observés dans (Crabbé & Candito, 2008). le parser STIG, dans
ses deux modes de fonctionnement pur et spinal, ne présente pas de différence statistiquement
signiﬁante en métrique PARSEVAL5 au moins dans les résultats PARSEVAL. C’est pourquoi dans
un souci d’espace nous ne présentons par la suite que les résultat en mode STIG-spinal.

FTB-min MFT-min
COLLINS MX PARSEVAL 81.65 79.19
UNLAB. DEP 88.48 84.96
COLLINS M2 PARSEVAL 80.1 78.38
UNLAB. DEP 87 .45 84.57
COLLINS M1 PARSEVAL 77.98 76.09
UNLAB. DEP 85.67 82.83
CHARNIAK PARSEVAL 82,44 81.34
UNLAB. DEP 88.42 84.90
CHIANG-SPINAL PARSEVAL 80.66 80.74
UNLAB. DEP 87.92 85,14
BKY PARSEVAL 84,93 83.16
UNLAB. DEP 90.06 87.29
CHIANG-PUR PARSEVAL 80.52 79.56
UNLAB. DEP 87,95 85.02

TAB. 2 — F1 scores des parsers lexicalisés et non lexicalisés sur Treebank avec tagset minimal

5 Evaluation des analyseurs en fonction des variations des
jeux d’annotations

Dans (Crabbé & Candito, 2008) les auteurs ont présenté des expériences visant a déterminer un
jeu d’annotation (i.e. tagset), nommé FTB-CC ici et TREEBANK+ dans l’article, maximisant les
performances du parser de Berkeley sur le FTB avec un F1-score(<=40) de 86.41%. Ce tagset
inclut des informations de mode pour les verbes (ie. indicatif, impératif, participe passé, etc.) et
certains traits de sous-catégorie (cf. (Crabbé & Candito, 2008), Table 2). L’impact de diverses
variations de tagsets appliquées au FTB, qui n’a pas été concu dans une optique de parsing, a
ainsi été testé via des mesures de constituance comme indicateur de performance.
Sachant que le MFT a par contre été concu dans une optique de maximisation des performances
d’un analyseur de grammaires LFG, donc visant a produire des dépendances syntaxiques pro-
fondes, induites a partir de sortie d’analyseurs statistiques (Schluter & van Genabith, 2008), i1
offre des performances néanmoins étonnantes au vu de sa taille réduite. L’ inﬂuence de son tag-
set et de ses modiﬁcations structurelles sont déterminantes et il aurait été intéressant de vériﬁer
5

avec une p-Value en F—score de 0.32

Parsing statistique lexicalisé pour le francais

leur impact sur davantage de données.

Malheureusement, des modiﬁcations semi-automatiques du MFT (en particulier celles apportées
au schéma de coordination) ne peuvent pas étre reproduites de facon réversible et automatique.
Toutefois, si nous ne pouvons pas réellement évaluer l’inﬂuence de la structure, nous pouvons
évaluer celle d’un tagset particulier appliqué a un autre treebank a l’aide d’outils de conversions.
A cette ﬁn, les tagsets maximisant les résultats PARSEVAL sont extraits de leurs treebanks res-
pectifs (le tagset CC pour le FTB et le tagset SCHLU pour le MFT) et appliqués sur l’autre tree-
bank. Nous avons donc deux tagsets pour chaque treebank sur lesquels nous évaluons chaque
parser en dépendance non-typée et en constituance. La table 3 présente les résultats en surli-
gnant les meilleurs scores pour chaque paire de treebanks.

Parser Parseval Dependency Parseval Dependency
MFTCC MFTSCH. MFTCC MFTSCH. FTBCC FTBSCH. FTBCC FTBSCH.

Collins (MX) 80.2 80.96 85.97 87.98 82.52 82.65 88.96 89.12
Collins (M2) 78.56 79.91 84.84 87.43 80.8 79.56 87.94 87.87
Collins (M1) 74 78.49 81.31 85.94 79.16 78.51 86.66 86.93
Cliamiak 82.5 82.66 86.45 86.94 84.27 83.27 89.7 89.67
Cliiang (Sp) 82.6 81.97 86.7 87.16 81.73 81.54 88.85 89.02
Bky 83.96 82.86 87.41 86.87 86.02 84.95 90.48 90.73

TAB. 3 — Résultats d’évaluation MFT-CC vs MFT-SCHLU et FTB-CC vs FTB-SCHLU

Les résultats de ces expériences, Table 3, conﬁrment la tendance visible dans le cas d’un parsing
avec tagset minimal (cf. Table 2), a savoir que BKY présente toujours les scores les plus élevés
quelque soit la métrique. Notons que les évaluations en dépendances non-typées sont systema-
tiquement meilleures sur le tagset SCHLU que sur le tagset CC. On peut l’expliquer par une plus
grande précision des headrules sur ce tagset. En effet, ces regles ayant été générées a partir de
méta-descriptions6 , leurs couvertures et leurs précisions globales sont plus élevées. On a, par
exemple, 18 regles pour FTB-CC et 43 pour FTB-SCHLU.

Comme prévu au regard des scores sur le PTB, le classement PARSEVAL des parsers lexicalisés
donne a CHARNIAK les meilleurs performances quel que soit le tagset, en ne considérant pas le
score de STIG-spinal sur le MFT-CC qui témoigne d’une variation non statistiquement signiﬁ-
cative avec le score de CHARNIAK sur ce treebank.7 En revanche, l’évaluation en dépendance
des parsers lexicalisés est différentes selon le treebank. Dans le cas du FTB, CHARNIAK pré-
sente les meilleurs scores, tandis que le modele STIG-spinal a de meilleures performances sur
les MFT-SCHLU et MFT-CC. Notons que les variations du modele 2 de Collins présentent des
résultats élevés en dépendance sur le MFT-SCHLU alors que leurs scores parseval sont les plus
faibles. Les faibles scores des modeles de Collins de base en constituance peuvent s’expliquer
par la dispersion de données accrue apportée par les annotations fonctionnelles, en particulier
sur des corpus de taille réduite.

6 Discussion

Comme nous l’avons déja dit dans l’introduction, les travaux précurseurs sur le FTB ont été
initiés par (Dybro-Johansen, 2004) dans une optique d’extraction de grammaire TAG; bien
qu’elle n’y reporte pas de résultats d’analyse syntaxique, les memes problemes de distinction

5Un label COORD se réécrit par exemple COORD_Vﬁnite, COORD_sint, etc.
7P-Value élevée de 0.1272 en précision et 0.06 en rappel.

Seddah, Candito & Crabbé

entre compléments et adjoints que (Arun & Keller, 2005) se sont posés. C’est l’aspect tres plat
du treebank ainsi que l’absence d’annotations fonctionnelles dans cette version distribuée en
2004 qui ont conduit Arun a modiﬁer le jeu d’annotation (par exemple VNG pour distinguer
les noeuds VN qui doIr1inent un verbe sous-catégorisant des clitiques) et a enrichir le modele
génératif de Collins aﬁn d’améliorer les performances globales de l’analyseur.

La question se pose de savoir si ces modiﬁcations se justiﬁaient sur le treebank initial étant
donné que les résultats de nos analyseurs entrainés sur le corpus initial sont supérieurs non
seulement a ceux reportés dans (Arun & Keller, 2005)8 mais aussi a ceux obtenus en utilisant
leur propre implémentation du modele 2 de Collins entrainé avec notre table de percolation de
téte et avec leur propre T DAA.

PARSER FTBARUN MFTSCHLU
Arun (acl05) 80.45 —
Arun (emnlp) 81.08 —
Schluter — 79.95
Collins (Mx) 81.5 80,96
Collins (M2) 79.36 79,91
Collins (M1) 77 .82 —
Charniak 82.35 82,66
Chiang (Sp) 80.94 81,86
Bky 84.03 82.86

TAB. 4 — Scores Parseval sur le FTB utilisé par Arun et sur le MFT

Nous sommes aussi directement comparables avec (Schluter & van Genabith, 2007) dont le
meilleur F1 score PARSEVAL en texte nu est de 79.95 quand le notre est de 82.86 sur le MFT
(cf. Table. 4).

Concemant les faibles résultats du modele 2 de Collins dans presque tous les cas de ﬁgure, cela
est selon nous dﬁ a l’éparpillement provoqué par l’ajout d’annotations fonctionnelles dans des
petits treebanks. De plus, concus pour l’anglais, son modele s’eXporte manifestement moins
bien dans des treebanks moins hiérarchisés que le PTB. Cette observation rejoint celles émises
par (Corazza et al., 2004) dans le cas d’une adaptation de ce modele a l’italien sur de tres pe-
tits treebanks (moins de 3000 phrases). En revanche, nous ne partageons pas le point de vue
communément adIr1is sur un relatif échec des modeles lexicalisés; a notre connaissance seuls
les modeles de Collins, via leur implémentation de BIKEL ont été adaptés a des langues euro-
péennes. Les performances comparées du modele de Charniak face a celui de BKY s’évaluent
selon un ordre de grandeur similaire a celui connu pour le parsing du la section 23 du PTB. Par
manque de place, nous ne pouvons inclure qu’un graphique représentant la courbe d’apprentis-
sage des parsers, n’utilisant pas de TDAA, en mode Perfect-tagging sur le FTB-CC (ﬁg. 1), mais
celle-ci montre que la courbe d’apprentissage de CHARNIAK est quasiment parallele a celle de
BKY tandis que les modeles de Collins (ici le modéle X sans TDAA a été utilise’) et STIG ont
des courbes qui se confondent quasiment et qui plafonnent tres vite.9 Ces deux modeles ayant
des back-oﬁfextrémement similaires, on peut se demander (1) si ce n’est pas eux qu’on compare
en réalité et (2) si la petite taille des corpus autres que le PTB ne pousse pas la communauté a

8Les résultats actualisés sont disponibles Via l’url suivante :
(http ://homepages.inf.ed.ac.uk/s0343799/acl2005slides.pdf).

9Nous sommes bien sﬁr conscients que les Valeurs de cette courbe sont aussi fonction du nombre de nouvelles
productions amenées par l’accroissement du lexique ; dans ce cas il faudrait aussi comparer les modes de “pruning”
de ces modéles.

Parsing statistique lexicalisé pour le frangais

considérer les modeles lexicalisés, a travers les seuls modeles de Collins, comme inadéquats a
d’autres langues que l’anglais du type Wall Street Journal.

 

: BKY F1 term = form + tag :-CHIA [>1 term = form + tag
—- BIKEL I-1 term = form + tag -—Cnarmak [-1 term = form +tag
90
 j
989 19/1 2965 3953 4941 5929 691)‘ I905 B393 9881

FIG. 1 - Courbe d’apprentissage sur FTB-CC en mode perfect-tagging

7 Conclusion

Nous avons présenté des résultats de parsing statistique lexicalisé et non lexicalisé sur tous les
treebanks du frangais a notre disposition. Ces résultats state of the art conﬁrment la maturité
du FTB en cette matiere et soulignent l’inﬂuence du jeu d’annotation sur les performances des
analyseurs. Par ailleurs, par le test de multiples analyseurs, nous avons montré que le débat
sur les bénéﬁces de la lexicalisation pouvait bénéﬁcier de l’inclusion de différents modeles
lexicalisés.

Références

ABEILLE A., CLEMENT L. & TOUSSENEL F. (2003). Building a Treebank for French, In
Treebanks. Kluwer : Dordrecht.

ARUN A. & KELLER F. (2005). Lexicalization in crosslinguistic probabilistic parsing : The
case of french. In Proceedings of the 43rd Annual Meeting of the Association for Computatio-
nal Linguistics, p. 306-313, Ann Arbor, MI.

BIKEL D. M. (2002). Design of a multi-lingual, parallel-processing statistical parsing en-
gine. In Proceedings of the second international conference on Human Language Technology
Research, p. 178-182 : Morgan Kaufmann Publishers Inc. San Francisco, CA, USA.

BIKEL D. M. (2004). Intricacies of Collins’ Parsing Model. Computational Linguistics, 30(4),
479-51 1.

BRANTS T. (2000). Tnt - a statistical part-of-speech tagger. In Proceedings of the 6th Applied
NLP Conference (ANLP), Seattle-WA.

CAHILL A., BURKE M., O’DoNoVAN R., VAN GENABITH J. & WAY A. (2004). Long-
Distance Dependency Resolution in Automatically Acquired Wide-Coverage PCFG-Based
LFG Approximations. In Proceedings of the 42nd Annual Meeting of the Association for
Computational Linguistics, p. 320-327, Barcelona, Spain.

Seddah, Candito & Crabbé

CHARNIAK E. (2000). A maximum-entropy-inspired parser. In Proceedings of the I st Annual
Meeting of the North American Chapter of the ACL (NAACL), Seattle.

CHIANG D. (2000). Statistical parsing with an automatically-extracted tree adjoining gram-
mar. Proceedings of the 38th Annual Meeting on Association for Computational Linguistics,
p. 456-463.

COLLINS M. (1999). Head Driven Statistical Models for Natural Language Parsing. PhD
thesis, University of Pennsylvania, Philadelphia.

CoRAzzA A., LAVELLI A., SATTA G. & ZANoLI R. (2004). Analyzing an Italian treebank
with state-of-the-art statistical parsers. In Proc. of the Third Third Workshop on Treebanks
(TLT 2004) and Linguistic Theories.

CRABBE B. & CANDITO M. (2008). Experiences d’analyse syntaxique statistique du fran-

cais. In Actes de la I 5eme Conférence sur le Traitement Automatique des Langues Naturelles
(TALN’08), p. 45-54, Avignon.

DUBEY A. & KELLER F. (2003). Probabilistic parsing for german using sister-head depen-
dencies. In In Proceedings of the 41 st Annual Meeting of the Association for Computational
Linguistics, p. 96-103.

DYBRO-JOHANSEN A. (2004). Extraction automatique de grammaires a partir d’un corpus
francais. Master’s thesis, Université Paris 7.

JOHNSON M. (1998). PCFG models of linguistic tree representations. Computational Lin-
guistics, 24(4), 613-632.

J OSHI A. K. (1987). Introduction to tree adjoining grammar. In A. MANASTER-RAMER, Ed.,
The Mathematics of Language : J . Benjamins.

J URAFSKY D., MARTIN J ., KEHLER A., VANDER LINDEN K. & WARD N. (2000). Speech
and language processing .' An introduction to natural language processing, computational
linguistics, and speech recognition. MIT Press.

KLEIN D. & MANNING C. D. (2003). Accurate unlexicalized parsing. In Proceedings of the
41st Annual Meeting on Association for Computational Linguistics-Volume I, p. 423-430 :
Association for Computational Linguistics Morristown, NJ, USA.

LIN D. (1995). A dependency-based method for evaluating broad-coverage parsers. In Inter-
national Joint Conference on Artiﬁcial Intelligence, p. 1420-1425, Montreal.

MARCUS M. P., SANToRINI B. & MARCINKIEWICZ M. A. (1994). Building a large anno-
tated corpus of english : The penn treebank. Computational Linguistics, 19(2), 313-330.

PETRoV S., BARRETT L., THIBAUX R. & KLEIN D. (2006). Learning accurate, compact,
and interpretable tree annotation. In Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meeting of the Association for Computational
Linguistics, Sydney, Australia : Association for Computational Linguistics.

REHBEIN I. & VAN GENABITH J . (2007). Treebank Annotation Schemes and Parser Evalua-

tion for German. In Proceedings of the I 6th Nordic Conference of Computational Linguistics
NODALIDA-2007, Tartu, Estonia.

SCHLUTER N. & VAN GENABITH J . (2007). Preparing, restructuring, and augmenting a
french treebank : Lexicalised parsers or coherent treebanks ? In Proceedings of PACLING 07.

SCHLUTER N. & VAN GENABITH J . (2008). Treebank-based acquisition of lfg parsing re-
sources for french. In E. L. R. A. (ELRA), Ed., Proceedings of the Sixth International
Language Resources and Evaluation (LREC’08), Marrakech, Morocco.

