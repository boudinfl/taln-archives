<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Analyse en d&#233;pendances &#224; l&#8217;aide des grammaires d&#8217;interaction</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009 &#8211; Session posters , Senlis, 24&#8211;26 juin 2009
</p>
<p>Analyse en d&#233;pendances &#224; l&#8217;aide des grammaires
d&#8217;interaction
</p>
<p>Jonathan Marchand1 Bruno Guillaume2 Guy Perrier1
</p>
<p>(1) LORIA / Universit&#233; Nancy 2
(2) LORIA / INRIA Nancy Grand-Est
</p>
<p>pr&#233;nom.nom@loria.fr
</p>
<p>R&#233;sum&#233;. Cet article propose une m&#233;thode pour extraire une analyse en d&#233;pendances d&#8217;un
&#233;nonc&#233; &#224; partir de son analyse en constituants avec les grammaires d&#8217;interaction. Les gram-
maires d&#8217;interaction sont un formalisme grammatical qui exprime l&#8217;interaction entre les mots &#224;
l&#8217;aide d&#8217;un syst&#232;me de polarit&#233;s. Le m&#233;canisme de composition syntaxique est r&#233;gi par la sa-
turation des polarit&#233;s. Les interactions s&#8217;effectuent entre les constituants, mais les grammaires
&#233;tant lexicalis&#233;es, ces interactions peuvent se traduire sur les mots. La saturation des polarit&#233;s
lors de l&#8217;analyse syntaxique d&#8217;un &#233;nonc&#233; permet d&#8217;extraire des relations de d&#233;pendances entre
les mots, chaque d&#233;pendance &#233;tant r&#233;alis&#233;e par une saturation. Les structures de d&#233;pendances
ainsi obtenues peuvent &#234;tre vues comme un raffinement de l&#8217;analyse habituellement effectu&#233;e
sous forme d&#8217;arbre de d&#233;pendance. Plus g&#233;n&#233;ralement, ce travail apporte un &#233;clairage nouveau
sur les liens entre analyse en constituants et analyse en d&#233;pendances.
</p>
<p>Abstract. This article proposes a method to extract dependency structures from phrase-
structure level parsing with Interaction Grammars. Interaction Grammars are a formalism which
expresses interactions among words using a polarity system. Syntactical composition is led by
the saturation of polarities. Interactions take place between constituents, but as grammars are
lexicalized, these interactions can be translated at the level of words. Dependency relations are
extracted from the parsing process : every dependency is the consequence of a polarity satura-
tion. The dependency relations we obtain can be seen as a refinement of the usual dependency
tree. Generally speaking, this work sheds new light on links between phrase structure and de-
pendency parsing.
</p>
<p>Mots-cl&#233;s : Analyse syntaxique, grammaires de d&#233;pendances, grammaires d&#8217;interaction,
polarit&#233;.
</p>
<p>Keywords: Syntactic analysis, dependency grammars, interaction grammars, polarity.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Jonathan Marchand, Bruno Guillaume, Guy Perrier
</p>
<p>1 Introduction
</p>
<p>Les grammaires de constituants et les grammaires de d&#233;pendances sont souvent pr&#233;sent&#233;es
comme orthogonales : les premi&#232;res organisent les groupes de mots en syntagmes alors que
les secondes mettent la d&#233;pendance entre mots au centre de la structure syntaxique. Avec les
grammaires de constituants lexicalis&#233;es, telles que les grammaires d&#8217;arbres adjoints (TAG) et
les grammaires cat&#233;gorielles (CG), o&#249; chaque &#233;l&#233;ment de la grammaire est associ&#233; &#224; un mot,
la composition syntaxique lors de l&#8217;analyse met en &#233;vidence des liens entre les mots. Ces liens
pr&#233;sentent des similitudes avec les relations de d&#233;pendances et ont fait l&#8217;objet de diff&#233;rentes
&#233;tudes.
</p>
<p>A. Dikovsky et L. Modina ont &#233;tudi&#233; du point de vue formel le passage d&#8217;une analyse en consti-
tuants &#224; une analyse en d&#233;pendances et vice versa (Dikovsky &amp; Modina, 2000). O. Rambow
et A. Joshi ont expliqu&#233; comment retrouver une analyse en d&#233;pendances &#224; partir d&#8217;une analyse
dans les TAG o&#249; les substitutions et les adjonctions sont vues comme des relations de d&#233;pen-
dances entre les mots (Rambow &amp; Joshi, 1997). Enfin, l&#8217;article (Clark et al., 2002) propose une
m&#233;thode similaire pour les grammaires cat&#233;gorielles combinatoires o&#249; l&#8217;application des r&#232;gles
combinatoires donne lieu &#224; des relations de d&#233;pendances entre les mots.
</p>
<p>Les grammaires d&#8217;interaction (IG) sont des grammaires de constituants lexicalis&#233;es qui &#233;tendent
par un syst&#232;me de polarit&#233;s plus riche le syst&#232;me besoins/ressources employ&#233; dans les gram-
maires cat&#233;gorielles. Dans cet article, nous g&#233;n&#233;ralisons, les r&#233;sultats (Clark et al., 2002) cit&#233;s
plus haut pour les CG au cas des IG, en r&#233;visant la m&#233;thode : en effet, cette derni&#232;re impose
d&#8217;&#233;tendre les entr&#233;es lexicales avec des marqueurs pour aider &#224; la construction des d&#233;pendances
lors de l&#8217;analyse, et produit trop de d&#233;pendances, alors que notre m&#233;thode s&#8217;appuie plus simple-
ment sur le lien entre polarit&#233;s et d&#233;pendances.
</p>
<p>Dans la section 2, les IG sont pr&#233;sent&#233;es et illustr&#233;es par un exemple. La section 3 d&#233;crit la
m&#233;thode d&#8217;extraction des d&#233;pendances &#224; partir d&#8217;une analyse avec une IG. Finalement, dans la
section 4, nous &#233;tudions les structures de d&#233;pendances obtenues et nous mettons en perspective
avec d&#8217;autres travaux.
</p>
<p>2 Les grammaires d&#8217;interaction
</p>
<p>Les grammaires d&#8217;interaction (Perrier, 2003) sont un formalisme grammatical s&#8217;appuyant sur
la notion de description d&#8217;arbres. Cette notion a &#233;t&#233; introduite par M. Marcus, D. Hindle et
M. Fleck en 1983 (Marcus et al., 1983), et K. Vijay-Shanker l&#8217;a utilis&#233;e pour repr&#233;senter de
fa&#231;on monotone l&#8217;op&#233;ration d&#8217;adjonction des TAG (Vijay-Shanker, 1992).
</p>
<p>Une description d&#8217;arbres est d&#233;finie par un ensemble de n&#339;uds et de relations d&#8217;ascendance,
de parent&#233; et de pr&#233;c&#233;dence entre ces n&#339;uds. Les n&#339;uds repr&#233;sentent des syntagmes (&#233;ventuel-
lement vides) et les relations expriment les d&#233;pendances entre ces syntagmes. Les propri&#233;t&#233;s
morpho-syntaxiques de ces syntagmes sont d&#233;crites par des structures de traits.
</p>
<p>Cette approche flexible est bien adapt&#233;e &#224; l&#8217;ambigu&#239;t&#233; des langues naturelles. Cependant, l&#8217;ana-
lyse syntaxique fond&#233;e sur des descriptions d&#8217;arbres est tr&#232;s co&#251;teuse (Koller et al., 1998). En
effet, dans cette approche, l&#8217;analyse syntaxique consiste &#224; chercher des mod&#232;les de descrip-
tions d&#8217;arbres sous forme d&#8217;arbres syntaxiques compl&#232;tement sp&#233;cifi&#233;s, ce qui est un probl&#232;me
NP-complet.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Analyse en d&#233;pendances &#224; l&#8217;aide des grammaires d&#8217;interaction
</p>
<p>Dans les formalismes op&#233;rationnels fond&#233;s sur les descriptions d&#8217;arbres (comme les D-tree sub-
stitution grammars (Rambow et al., 2001) ou les TT-MCTAG (Kallmeyer, 2005)), cet ind&#233;ter-
minisme est limit&#233; en contraignant la syntaxe des descriptions et le m&#233;canisme de composition
syntaxique.
</p>
<p>L&#8217;originalit&#233; des grammaires d&#8217;interaction est de proposer un m&#233;canisme de composition syn-
taxique tr&#232;s souple qui consiste &#224; superposer les descriptions d&#8217;arbres mais qui est guid&#233; par
une contrainte de saturation de polarit&#233;s. Cette contrainte fait r&#233;f&#233;rence &#224; l&#8217;id&#233;e de valence de
Tesni&#232;re (Tesni&#232;re, 1934) et est essentielle dans les CG : chaque mot est &#233;quip&#233; d&#8217;une valence
exprimant ses possibilit&#233;s d&#8217;interaction avec les autres mots. La composition syntaxique est
contr&#244;l&#233;e pas une dualit&#233; besoins/ressources : certaines ressources munies de polarit&#233;s n&#233;ga-
tives sont attendues alors que d&#8217;autres, munies de polarit&#233;s positives, sont disponibles. Dans les
IG, cette id&#233;e de valence est reprise et g&#233;n&#233;ralis&#233;e.
</p>
<p>2.1 Syst&#232;me de polarit&#233;s
</p>
<p>Contrairement aux CG, les IG attachent les polarit&#233;s aux traits qui d&#233;corent les n&#339;uds. Mais
nous nous en tiendrons ici &#224; une version simplifi&#233;e des IG o&#249; les polarit&#233;s sont accroch&#233;es aux
n&#339;uds. Une autre diff&#233;rence avec les CG est que le syst&#232;me de polarit&#233;s est plus riche. En effet,
les IG proposent deux types d&#8217;interaction &#224; base de polarit&#233;s :
&#8211; les interactions lin&#233;aires : chaque n&#339;ud portant une polarit&#233; positive (not&#233;e +) doit fusion-
</p>
<p>ner avec exactement un n&#339;ud portant une polarit&#233; n&#233;gative (not&#233;e &#8722;) et r&#233;ciproquement.
&#8211; les interactions non-lin&#233;aires : chaque n&#339;ud portant une polarit&#233; virtuelle (not&#233;e &#8764;) doit
</p>
<p>fusionner exactement, soit avec un n&#339;ud positif et un n&#339;ud n&#233;gatif, soit avec un n&#339;ud portant
la polarit&#233; satur&#233;e (not&#233;e =). En revanche, un nombre quelconque de noeuds virtuels peuvent
fusionner avec le m&#234;me couple positif/n&#233;gatif ou avec le m&#234;me n&#339;ud satur&#233;.
</p>
<p>&#8764; &#8722; + =
&#8764; &#8764; &#8722; + =
&#8722; &#8722; =
+ + =
= =
</p>
<p>Lors de la fusion de deux n&#339;uds, le n&#339;ud r&#233;sultant porte la polarit&#233;
issue de la composition des polarit&#233;s des n&#339;uds initiaux. La com-
position d&#8217;une polarit&#233; positive et d&#8217;une polarit&#233; n&#233;gative donne une
polarit&#233; satur&#233;e alors que la polarit&#233; virtuelle est l&#8217;&#233;l&#233;ment neutre
de cette op&#233;ration. Toute autre composition provoque l&#8217;&#233;chec de la
fusion (cf. tableau ci-contre). L&#8217;op&#233;ration de composition est asso-
ciative et commutative, l&#8217;ordre de fusion des n&#339;uds n&#8217;a donc pas
d&#8217;importance dans le processus de composition syntaxique.
</p>
<p>2.2 Analyse avec les IG
</p>
<p>La structure syntaxique &#233;l&#233;mentaire manipul&#233;e dans les IG est appel&#233;e description d&#8217;arbre
polaris&#233;e (DAP). Une IG particuli&#232;re est d&#233;finie par un ensemble de DAP ; chaque DAP est
associ&#233;e &#224; un mot1. La grammaire est ainsi un lexique o&#249; un mot peut avoir plusieurs entr&#233;es.
Pour analyser une phrase, il faut choisir pour chaque mot l&#8217;une des DAP associ&#233;e &#224; ce mot.
Un tel choix est appel&#233;e une s&#233;lection lexicale. L&#8217;analyse consiste ensuite &#224; composer ces DAP
pour obtenir un arbre d&#8217;analyse.
</p>
<p>L&#8217;op&#233;ration atomique de composition syntaxique consiste &#224; superposer deux n&#339;uds pour saturer
</p>
<p>1Dans nos grammaires, il n&#8217;y a pas de co-ancre et donc un seul mot par DAP (l&#8217;usage de co-ancre peut-&#234;tre
simul&#233; en utilisant des polarit&#233;s).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Jonathan Marchand, Bruno Guillaume, Guy Perrier
</p>
<p>leurs polarit&#233;s. On it&#232;re l&#8217;op&#233;ration de saturation de n&#339;uds pour construire progressivement
l&#8217;analyse de la phrase sous forme d&#8217;un arbre.
</p>
<p>Les DAP d&#8217;une s&#233;lection lexicale pour la phrase &#8220;Jean en conna&#238;t la couleur&#8221; sont repr&#233;sent&#233;es
sur la figure 1.
</p>
<p>B1+NP
Jean
</p>
<p>A2~S
C2~V D2~NP
</p>
<p>E2=PRO F2~V H2~N
</p>
<p>en
I2~N J2=PP
</p>
<p>K2=PREP L2=NP
&#949; &#949;
</p>
<p>A3=S
B3-NP C3=V D3-NP
</p>
<p>F3=V
conna&#238;t
</p>
<p>G4+DET
la
</p>
<p>D5+NP
G5-DET H5=N
</p>
<p>I5=N
couleur
</p>
<p>FIG. 1 &#8211; DAP associ&#233;es &#224; la phrase &#8220;Jean en conna&#238;t la couleur&#8221;
</p>
<p>La DAP repr&#233;sentant le mot &#8220;en&#8221; d&#233;crit l&#8217;intuition linguistique suivante : le pronom &#8220;en&#8221;
est utilis&#233; comme compl&#233;ment du nom &#8220;couleur&#8221; mais il vient s&#8217;adjoindre devant le verbe
&#8220;conna&#238;t&#8221; qui admet &#8220;la couleur&#8221; comme objet direct. La DAP montre &#224; droite du noyau verbal
C2 un syntagme objet D2 attendu comportant un compl&#233;ment du nom J2 qui est d&#233;j&#224; compl&#232;-
tement satur&#233; mais sans r&#233;alisation phonologique. Le n&#339;ud I2 renseigne la positionnement du
nom dans le syntagme H2. Au niveau du noyau verbal C2, le pronom &#8220;en&#8221; E2 est positionn&#233; &#224;
gauche du verbe F2.
</p>
<p>&#192; partir de l&#8217;ensemble des DAP de la figure 1, on peut construire l&#8217;arbre syntaxique satur&#233;
repr&#233;sent&#233; sur la figure 2. Sur chaque n&#339;ud de l&#8217;arbre est indiqu&#233; l&#8217;ensemble des n&#339;uds des
DAP qui ont &#233;t&#233; superpos&#233;s. Par exemple le n&#339;ud A2-A3 repr&#233;sente la superposition du n&#339;ud
A2 de la DAP de &#8220;en&#8221; et du n&#339;ud A3 de la DAP de &#8220;conna&#238;t&#8221;.
</p>
<p>A2-A3=S
B1-B3=NP C2-C3=V D2-D3-D5=NP
</p>
<p>Jean
E2=PRO F2-F3=V G4-G5=DET H2-H5=N
</p>
<p>en conna&#238;t la
I2-I5=N J2=PP
</p>
<p>couleur
K2=PREP L2=NP
&#949; &#949;
</p>
<p>FIG. 2 &#8211; Arbre d&#8217;analyse de &#8220;Jean en conna&#238;t la couleur&#8221;
</p>
<p>2.3 Grammaire du fran&#231;ais
</p>
<p>Pour valider le formalisme, nous avons d&#233;velopp&#233; une grammaire du fran&#231;ais (Perrier, 2007).
Cette grammaire a &#233;t&#233; &#233;valu&#233;e sur la TSNLP (Lehmann et al., 1996) qui contient 1690 &#233;nonc&#233;s</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Analyse en d&#233;pendances &#224; l&#8217;aide des grammaires d&#8217;interaction
</p>
<p>grammaticaux et 1935 &#233;nonc&#233;s agrammaticaux. Ce jeu de tests ne couvre pas toute la langue
fran&#231;aise, il y a peu de phrases complexes mais il insiste sur certains ph&#233;nom&#232;nes comme la
coordination ou la position des compl&#233;ments adverbiaux. Cependant, notre grammaire couvre
d&#8217;autres ph&#233;nom&#232;nes dont la TSNLP ne tient pas compte, comme par exemple : la voix passive,
la sous-cat&#233;gorisation des noms et des adjectifs pr&#233;dicatifs, le contr&#244;le du sujet des compl&#233;ments
infinitifs, les propositions relatives et interrogatives. 88% des 1690 phrases grammaticales sont
mod&#233;lis&#233;es et 85% des 1935 phrases agrammaticales sont rejet&#233;es. Les 15% d&#8217;&#233;nonc&#233;s agram-
maticaux sont accept&#233;s car la grammaire ne mod&#233;lise pas les r&#232;gles phonologiques et la s&#233;man-
tique. Les raisons pour lesquelles 12% des &#233;nonc&#233;s grammaticaux ne sont pas analys&#233;s sont
diverses (phrases retranscrites de l&#8217;oral, expressions fig&#233;es, causatifs, superlatifs).
</p>
<p>3 Analyse en d&#233;pendances
</p>
<p>L&#8217;analyse syntaxique est obtenue par superposition des DAP d&#8217;une s&#233;lection lexicale. La super-
position est guid&#233;e par la fusion des n&#339;uds portant des polarit&#233;s se saturant. Au niveau d&#8217;une
DAP, ces polarit&#233;s repr&#233;sentent les besoins/ressources du mot dans un &#233;nonc&#233;. La saturation
de ces derni&#232;res peut alors se voir comme la r&#233;solution d&#8217;une d&#233;pendance entre ces mots. On
peut alors retrouver les relations de d&#233;pendances d&#8217;une phrase &#224; partir de l&#8217;ensemble des DAP
associ&#233;es aux mots de la phrase et de son analyse.
</p>
<p>3.1 D&#233;pendances lin&#233;aires
</p>
<p>Nous nous int&#233;ressons dans un premier temps au cas simple de la saturation lin&#233;aire de deux
polarit&#233;s + et &#8722;. Par exemple, dans la phrase &#8220;Jean en conna&#238;t la couleur&#8221; (Figure 2), la DAP
repr&#233;sentant le d&#233;terminant &#8220;la&#8221; poss&#232;de un n&#339;ud G4 portant une polarit&#233; positive et &#233;tiquet&#233;
par la cat&#233;gorie syntaxique DET. La DAP du nom &#8220;couleur&#8221; comporte quant &#224; elle un n&#339;ud G5
portant une polarit&#233; n&#233;gative qui est aussi &#233;tiquet&#233; par DET.
</p>
<p>Lors de l&#8217;analyse, ces deux n&#339;uds fusionnent pour obtenir un n&#339;ud satur&#233;, la DAP r&#233;sultante
repr&#233;sentant une analyse partielle de &#8220;la couleur&#8221;. La saturation de ces deux n&#339;uds peut &#234;tre
vue comme la r&#233;alisation d&#8217;une relation de d&#233;pendances entre les deux mots correspondants.
</p>
<p>L&#8217;op&#233;ration de saturation repr&#233;sente la satisfaction d&#8217;une contrainte de besoins/ressources. Un
&#233;l&#233;ment qui se pr&#233;sente comme n&#233;cessitant une ressource est consid&#233;r&#233; comme le gouverneur
de la relation de d&#233;pendances, tandis qu&#8217;un &#233;l&#233;ment qui se pr&#233;sente comme fournissant une
ressource se retrouve comme le d&#233;pendant de cette relation. Ainsi, en cas d&#8217;interaction lin&#233;aire,
le mot dont la DAP contient le n&#339;ud n&#233;gatif est le gouverneur et le mot dont la DAP contient
le n&#339;ud positif est le d&#233;pendant de la relation de d&#233;pendances.
</p>
<p>Les relations de d&#233;pendances engendr&#233;es par la saturation des n&#339;uds portant des polarit&#233;s op-
pos&#233;es seront appel&#233;es d&#233;pendances lin&#233;aires. Dans la grammaire actuelle du fran&#231;ais, elles
repr&#233;sentent les relations t&#234;te-compl&#233;ment et t&#234;te-sp&#233;cifieur.
</p>
<p>Dans l&#8217;exemple &#8220;Jean en conna&#238;t la couleur&#8221;, les d&#233;pendances lin&#233;aires obtenues sont repr&#233;-
sent&#233;es sur la figure 3 (les arcs portent la cat&#233;gorie qui a fait l&#8217;objet d&#8217;une saturation2).
</p>
<p>2en pratique, il est possible d&#8217;utiliser d&#8217;autres &#233;tiquettes sur les arcs comme les fonctions syntaxiques (elles
sont indiqu&#233;es dans les structures de traits).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Jonathan Marchand, Bruno Guillaume, Guy Perrier
</p>
<p>Jean en conna&#238;t la couleur
</p>
<p>NP
</p>
<p>DETNP
</p>
<p>FIG. 3 &#8211; Relations de d&#233;pendances lin&#233;aires dans la phrase &#8220;Jean en conna&#238;t la couleur&#8221;
</p>
<p>Cette analyse poss&#232;de un n&#339;ud &#8220;en&#8221; isol&#233;. La DAP du pronom &#8220;en&#8221; ne porte en effet pas de
polarit&#233; positive ou n&#233;gative et ainsi ne produit pas de relation de d&#233;pendances lin&#233;aires avec
le reste de la phrase. La saturation des polarit&#233;s positives et n&#233;gatives ne suffit donc pas pour
exprimer toutes les relations de d&#233;pendances d&#8217;une phrase. Nous allons donc voir comment
certaines relations de d&#233;pendances peuvent &#234;tre produites pas des interactions non-lin&#233;aires.
</p>
<p>3.2 D&#233;pendances non-lin&#233;aires
</p>
<p>H6~N
L6=ADJ I6~N
</p>
<p>belle
</p>
<p>Dans la grammaire actuelle, la DAP pour l&#8217;adjectif &#8220;belle&#8221; dans le groupe no-
minal &#8220;la belle couleur&#8221; est donn&#233;e par la figure ci-contre. De fa&#231;on habituelle
en d&#233;pendances, on consid&#232;re qu&#8217;il y a une d&#233;pendance de &#8220;belle&#8221; vis &#224; vis de
&#8220;couleur&#8221;. Deux n&#339;uds sont non-satur&#233;s (H6 et I6) et ils portent tous les deux
une polarit&#233;s virtuelle, c&#8217;est donc la saturation de l&#8217;une de ces deux polarit&#233;s
qui doit induire la d&#233;pendance. Dans ce cas, les deux polarit&#233;s peuvent &#234;tre
&#224; l&#8217;origine de la d&#233;pendance. Cependant, il ne doit &#234;tre produit qu&#8217;une seule
relation de d&#233;pendances, il faut choisir alors quelle polarit&#233; engendrera une
d&#233;pendance lors de sa saturation.
</p>
<p>A7~S
C7~V D7+NP
</p>
<p>M7=PRO F7~V
le
</p>
<p>Un autre exemple d&#8217;usage des polarit&#233;s virtuelles dans la grammaire du
fran&#231;ais est illustr&#233; par l&#8217;exemple &#8220;Jean le conna&#238;t&#8221;. Dans cette phrase,
le pronom &#8220;le&#8221; (ci-contre) est l&#8217;objet direct du verbe &#8220;conna&#238;t&#8221; : cette re-
lation de d&#233;pendances est produite par la saturation lin&#233;aire des polarit&#233;s
du n&#339;ud D7 de la DAP du pronom &#8220;le&#8221; et du n&#339;ud D3 de la DAP du mot
&#8220;conna&#238;t&#8221;. Mais la DAP du pronom &#8220;le&#8221; poss&#232;de trois n&#339;uds A7, C7,
F7 portant une polarit&#233; virtuelle dont la saturation non-lin&#233;aire n&#8217;apporte
aucune information de d&#233;pendances entre les mots &#8220;le&#8221; et &#8220;conna&#238;t&#8221;.
Ces polarit&#233;s contr&#244;lent simplement la place des syntagmes lors de la
superposition des deux DAP et g&#232;rent le fait que le pronom &#8220;le&#8221; se place
avant le verbe alors que la place canonique du groupe nominal objet dans
la phrase est apr&#232;s le verbe. Dans l&#8217;arbre d&#8217;analyse de &#8220;Jean le conna&#238;t&#8221; les trois n&#339;uds vir-
tuels A7, C7, F7 sont satur&#233;s, respectivement, par les trois n&#339;uds A3, C3, F3 de la DAP du
mot &#8220;conna&#238;t&#8221;.
</p>
<p>Les deux derniers exemples montrent bien qu&#8217;il y a deux usages distincts des polarit&#233;s virtuelles
qui ne se comportent pas de la m&#234;me mani&#232;re pour la production de relation de d&#233;pendances :
&#8211; les polarit&#233;s virtuelles de d&#233;pendances qui portent une information sur les relations de
</p>
<p>d&#233;pendances d&#8217;un mot avec son environnement ;
&#8211; les polarit&#233;s virtuelles de contexte qui imposent des contraintes sur le contexte syntaxique
</p>
<p>d&#8217;un mot.
Il n&#8217;est pas possible de distinguer automatiquement, dans une grammaire donn&#233;e, les deux types
de polarit&#233;s virtuelles. C&#8217;est donc &#224; l&#8217;auteur de la grammaire de se baser sur des crit&#232;res lin-
guistiques pour distinguer ces deux usages. Cependant, dans la pratique, l&#8217;utilisation de m&#233;ta-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Analyse en d&#233;pendances &#224; l&#8217;aide des grammaires d&#8217;interaction
</p>
<p>grammaires (notre grammaire, par exemple, est construite avec XMG (Duchier et al., 2005))
permet de faire ce travail rapidement, de fa&#231;on coh&#233;rente sur l&#8217;ensemble de la grammaire. Cela
concerne uniquement les mots jouant le r&#244;le de modificateurs (adjectifs &#233;pith&#232;tes, adverbes,
pr&#233;positions introduisant des compl&#233;ments adjoints, pronoms relatifs dans leur r&#244;le par rapport
&#224; leur ant&#233;c&#233;dent, pronom clitique &quot;il&quot; utilis&#233; en redoublement du sujet, etc.). Il s&#8217;agit, dans la
DAP associ&#233; au mot concern&#233; de marquer le n&#339;ud consid&#233;r&#233; comme n&#339;ud privil&#233;gi&#233; de ratta-
chement au mot qui est modifi&#233;. Le travail a &#233;t&#233; effectu&#233; sur notre grammaire du fran&#231;ais &#224; large
couverture en moins d&#8217;une heure.
</p>
<p>Ainsi, dans la DAP de &#8220;en&#8221; (figure 1), toutes les polarit&#233;s virtuelles des n&#339;uds A2, C2, D2 et
F2 sont des polarit&#233;s virtuelles de contexte qui g&#232;rent le positionnement de &#8220;en&#8221;. Pour rendre
compte du fait que &#8220;en&#8221; d&#233;pend de &#8220;couleur&#8221;, il faut que l&#8217;une des deux polarit&#233;s virtuelles H2
ou I2 soit une polarit&#233; virtuelle de d&#233;pendances. Dans notre cas, nous avons choisi arbitraire-
ment la polarit&#233; H2.
</p>
<p>Dans le cas o&#249; une relation de d&#233;pendances est produite, le d&#233;pendant est le mot dont la DAP
porte le n&#339;ud virtuel de d&#233;pendances. La polarit&#233; virtuelle peut &#234;tre satur&#233; :
&#8211; soit par un n&#339;ud portant la polarit&#233; =, dans ce cas ce n&#339;ud est le gouverneur ;
&#8211; soit par un couple de n&#339;ud (un positif et un n&#233;gatif), dans ce cas le gouverneur est le n&#339;ud
</p>
<p>portant la polarit&#233; positive.
Les relations ainsi engendr&#233;es sont appel&#233;es d&#233;pendances non-lin&#233;aires. En effet, un n&#339;ud
satur&#233; pouvant se composer avec z&#233;ro ou plusieurs n&#339;uds virtuels, plusieurs relations de d&#233;pen-
dances peuvent avoir comme gouverneur le m&#234;me mot. Ces relations de d&#233;pendances expriment
g&#233;n&#233;ralement une relation modifieur-modifi&#233;.
</p>
<p>Dans les structures de d&#233;pendances (figures 4 ci-dessous et 5 plus loin) les d&#233;pendances lin&#233;aires
sont repr&#233;sent&#233;es au-dessus de la phrase et les non-lin&#233;aires au-dessous.
</p>
<p>La proc&#233;dure d&#8217;extraction des d&#233;pendances se r&#233;sume ainsi :
</p>
<p>&#8211; La saturation de polarit&#233;s oppos&#233;es engendre une relation de d&#233;pendances lin&#233;aire entre les
mots ; la relation va de la polarit&#233; n&#233;gative vers la polarit&#233; positive.
</p>
<p>&#8211; La saturation d&#8217;une polarit&#233; virtuelle de d&#233;pendances avec une polarit&#233; positive ou satur&#233;e
engendre une relation de d&#233;pendances non lin&#233;aire entre les mots ; la relation va de la polarit&#233;
satur&#233;e ou positive vers la polarit&#233; virtuelle de d&#233;pendances.
</p>
<p>Cette proc&#233;dure permet d&#8217;obtenir l&#8217;analyse en d&#233;pendances de &#8220;Jean en conna&#238;t la couleur&#8221;
repr&#233;sent&#233;e figure 4.
</p>
<p>Jean en conna&#238;t la couleur
</p>
<p>NP
</p>
<p>DETNP
</p>
<p>N
</p>
<p>FIG. 4 &#8211; Relations de d&#233;pendances dans la phrase &#8220;Jean en conna&#238;t la couleur&#8221;
</p>
<p>Pour garantir que les structures de d&#233;pendances sont connexes (chaque mot est en relation
avec au moins un autre mot de l&#8217;&#233;nonc&#233;), il suffit d&#8217;imposer que chaque DAP de la grammaire
contienne au moins un n&#339;ud positif, un n&#339;ud n&#233;gatif ou un n&#339;ud portant une polarit&#233; virtuelle
de d&#233;pendances. C&#8217;est la cas de la grammaire actuellement implant&#233;e pour le fran&#231;ais.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Jonathan Marchand, Bruno Guillaume, Guy Perrier
</p>
<p>4 Structures de d&#233;pendances obtenues
</p>
<p>Le choix du type de structures pour repr&#233;senter les d&#233;pendances d&#8217;une phrase est une question
&#233;pineuse qui divisent les linguistes. L&#8217;id&#233;e de d&#233;part des grammaires de d&#233;pendances est de
consid&#233;rer que chaque mot de la phrase (sauf le verbe principal) est gouvern&#233; par exactement
un autre mot de la m&#234;me phrase. Cette hypoth&#232;se conduit &#224; consid&#233;rer que les bonnes structures
de d&#233;pendances sont les arbres, nous allons voir ce qu&#8217;il en est avec notre m&#233;thode qui permet
d&#8217;observer, sans a priori, les structures obtenues.
</p>
<p>4.1 Graphes orient&#233;s
</p>
<p>De fa&#231;on g&#233;n&#233;rale, la structure en d&#233;pendances que l&#8217;on obtient est un graphe orient&#233; ; de plus,
avec la restriction impos&#233;e sur les DAP de la grammaire, on sait que ce graphe est connexe.
</p>
<p>L&#8217;analyse en d&#233;pendances pour la phrase &#8220;Jean en conna&#238;t la couleur&#8221; donn&#233;e par la figure 4 est
un arbre ; en effet, tous les mots, sauf &#8220;conna&#238;t&#8221;, ont un et un seul gouverneur. Il existe cepen-
dant des exemples pour lesquels la structure de d&#233;pendances n&#8217;est pas un arbre. L&#8217;application
de notre m&#233;thode &#224; la phrase &#8220;la fille que Jean aime vient&#8221; produit l&#8217;analyse de la figure 5.
Cette structure n&#8217;est pas un arbre car elle contient un cycle3 et le pronom relatif &#8220;que&#8221; a deux
gouverneurs.
</p>
<p>la fille que Jean aime vient
</p>
<p>DET NP
</p>
<p>S
</p>
<p>NP
</p>
<p>NP
</p>
<p>NP
</p>
<p>FIG. 5 &#8211; Relations de d&#233;pendances dans la phrase &#8220;la fille que Jean aime vient&#8221;
</p>
<p>On retrouve ainsi avec notre m&#233;thode le probl&#232;me qui se pose habituellement en grammaire de
d&#233;pendances pour g&#233;rer les ph&#233;nom&#232;nes d&#8217;extraction. Par exemple, si nous reprenons la phrase
&#8220;la fille que Jean aime vient&#8221;, le mot &#8220;que&#8221; remplit ici deux r&#244;les, il est l&#8217;objet anaphorique
de &#8220;aime&#8221; et subordonne la relative &#224; l&#8217;ant&#233;c&#233;dent. Ce double r&#244;le suppose naturellement deux
relations de d&#233;pendances distinctes qui contredisent le principe de repr&#233;sentation en arbre, alors
que l&#8217;analyse pr&#233;sent&#233;e figure 5 rend bien compte de ce double emploi. D&#8217;autres approches
d&#8217;analyses en d&#233;pendances utilise &#233;galement des structures qui ne sont pas des arbres : S. Ka-
hane (Kahane, 2000) propose une analyse dans laquelle un pronom relatif a deux gouverneurs ;
R. Hudson (Hudson, 1990) utilise &#233;galement souvent des structures dans lesquelles un mot peut
avoir plusieurs gouverneurs.
</p>
<p>4.2 Projectivit&#233;
</p>
<p>Une autre question r&#233;currente &#224; propos des structures de d&#233;pendances &#224; consid&#233;rer pour la des-
cription de la langue est celle de la projectivit&#233;. En effet une structure projective induit que les
</p>
<p>3&#8220;aime&#8221; gouverne &#8220;que&#8221; car &#8220;que&#8221; est le compl&#233;ment d&#8217;objet de &#8220;aime&#8221; ;&#8220;que&#8221; gouverne &#8220;aime&#8221; car c&#8217;est
le pronom relatif qui introduit la relative o&#249; &#8220;aime&#8221; est le verbe.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Analyse en d&#233;pendances &#224; l&#8217;aide des grammaires d&#8217;interaction
</p>
<p>relations de d&#233;pendances restent &#224; un niveau local, ce qui permet une analyse simple et efficace.
</p>
<p>Cette notion initialement d&#233;finie pour les arbres peut se transposer sur les graphes : une structure
de d&#233;pendances est dite projective si pour tout mot donn&#233;, l&#8217;ensemble des n&#339;uds atteignables
depuis ce mot dans la structure de d&#233;pendances (qu&#8217;on appellera emprise du mot) correspond
&#224; un segment continu de l&#8217;&#233;nonc&#233;. Par exemple la structure de la figure 5 est projective alors
que celle de la figure 4 ne l&#8217;est pas : dans cette analyse, l&#8217;emprise du mot &#8220;couleur&#8221; est form&#233;
de deux segments &#8220;en&#8221; et &#8220;la couleur&#8221; s&#233;par&#233;s par le mot &#8220;conna&#238;t&#8221;.
</p>
<p>4.3 Classes de structures de d&#233;pendances
</p>
<p>R. Debusmann and M. Kuhlmann proposent des crit&#232;res qui permettent de classer plus fine-
ment les analyses non-projectives. Il obtiennent ainsi une hi&#233;rarchisation en classes du pouvoir
expressif que permettent les diff&#233;rentes structures de d&#233;pendances (Debusmann &amp; Kuhlmann,
2009). La notion de degr&#233; de discontinuit&#233; (block-degree) associe &#224; une structure un entier qui
est le nombre maximum de segments continus disjoints dans l&#8217;emprise d&#8217;un mot (un degr&#233; de
discontinuit&#233; de 1 correspond exactement &#224; la projectivit&#233;). Pour les structures dont le degr&#233; de
discontinuit&#233; est au moins 2, ils distinguent celles qui sont bien imbriqu&#233;es (well-nestedness)
c&#8217;est-&#224;-dire celle qui sont telles que les emprises des deux mots ne se croisent pas (soit elles
sont disjointes, soit l&#8217;une est enti&#232;rement incluse entre deux segments de l&#8217;autre). Sur le Prague
Dependency Treebank, les auteurs montrent que 99,5% des analyses sont bien imbriqu&#233;es et de
degr&#233; de discontinuit&#233; au plus deux (ce qui est &#233;quivalent &#224; &#234;tre dans la classe de langages des
TAG).
</p>
<p>L&#8217;application de notre m&#233;thode &#224; cette grammaire du fran&#231;ais sur la TSNLP ne produit pas
d&#8217;analyse mal imbriqu&#233;es. On obtient dans la plupart des cas des structures de d&#233;pendances pro-
jectives. Les exemples pour lesquels le degr&#233; de discontinuit&#233; est de 2 sont d&#251;s principalement
au placement de l&#8217;auxiliaire dans le noyau verbal. Les mots &#8220;en&#8221; ou &#8220;y&#8221; ainsi que l&#8217;inversion
sujet/verbe lors de l&#8217;emploi de pronoms interrogatifs sont d&#8217;autres sources de discontinuit&#233;,
mais nous n&#8217;avons pas trouv&#233; d&#8217;exemple qui aille au-del&#224; d&#8217;un degr&#233; de discontinuit&#233; de 2.
</p>
<p>5 Conclusion
</p>
<p>Dans cet article, nous avons propos&#233; une m&#233;thode pour construire une analyse en d&#233;pendances
d&#8217;un &#233;nonc&#233; &#224; partir de son analyse en constituants dans les IG. Cette m&#233;thode, bas&#233;e sur la satu-
ration des polarit&#233;s, a mis en &#233;vidence deux types de d&#233;pendances : les d&#233;pendances lin&#233;aires qui
repr&#233;sentent les relations t&#234;te-compl&#233;ment ou t&#234;te-sp&#233;cifieur et les d&#233;pendances non-lin&#233;aires
qui repr&#233;sentent les relations modifieur-modifi&#233;.
</p>
<p>Les structures de d&#233;pendances obtenues par cette m&#233;thode sont des graphes orient&#233;s, elles sont
plus riches que les structures obtenues habituellement par des grammaires de d&#233;pendances.
Cette repr&#233;sentation permet de g&#233;rer simplement les ph&#233;nom&#232;nes linguistiques posant habituel-
lement des difficult&#233;s dans les grammaires de d&#233;pendances.
</p>
<p>Pour la suite du travail, nous souhaitons &#233;tudier dans quelle mesure il est possible de transposer
les m&#233;thodes d&#8217;analyses d&#8217;un formalisme &#224; l&#8217;autre. Par exemple, Nous avons remarqu&#233; que tr&#232;s
peu d&#8217;analyses sont non-projectives ; on pourrait donc isoler les cas non-projectifs et adapter un
algorithme d&#8217;analyse des grammaires de d&#233;pendances qui servirait de guide &#224; l&#8217;analyse dans les</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Jonathan Marchand, Bruno Guillaume, Guy Perrier
</p>
<p>IG. Il serait &#233;galement int&#233;ressant d&#8217;&#233;tudier l&#8217;application de nos m&#233;thodes d&#8217;analyse sp&#233;cifiques
aux IG &#224; l&#8217;analyse pour des grammaires de d&#233;pendances lexicalis&#233;es.
</p>
<p>R&#233;f&#233;rences
</p>
<p>CLARK S., HOCKENMAIER J. &amp; STEEDMAN M. (2002). Building deep dependency struc-
tures with a wide-coverage CCG parser. In In Proceedings of the 40th Meeting of the ACL, p.
327&#8211;334.
</p>
<p>DEBUSMANN R. &amp; KUHLMANN M. (2009). Dependency grammar : Classification and ex-
ploration. In Resource-Adaptive Cognitive Processes : Springer.
</p>
<p>DIKOVSKY A. &amp; MODINA L. (2000). Dependencies on the other Side of the Curtain. T.A.L,
1, 79&#8211;111.
DUCHIER D., LE ROUX J. &amp; PARMENTIER Y. (2005). XMG : Un Compilateur de M&#233;ta-
Grammaires Extensible. In M. JARDINO, Ed., Actes de TALN 2005 (Traitement automatique
des langues naturelles), Dourdan : ATALA LIMSI.
</p>
<p>HUDSON R. A. (1990). English Word Grammar. Blackwell.
</p>
<p>KAHANE S. (2000). Extractions dans une grammaire de d&#233;pendance &#224; bulles. T.A.L., 41(1),
187&#8211;216.
</p>
<p>KALLMEYER L. (2005). Tree-local Multicomponent Tree Adjoining Grammars with Shared
Nodes. Computational Linguistics, 31(2), 187&#8211;225.
KOLLER A., NIEHREN J. &amp; TREINEN R. (1998). Dominance constraints : Algorithms and
complexity. In LACL&#8217;98, p. 106&#8211;125, Heidelberg.
</p>
<p>LEHMANN S., OEPEN S., C I., BAUR H. H., LBDKAN O. &amp; ARNOLD D. (1996). tsnlp &#8212;
test suites for natural language processing. In In J. Nerbonne (Ed.), Linguistic Databases (pp.
13 - 36, p. 711&#8211;716 : CSLI Publications.
</p>
<p>MARCUS M. P., HINDLE D. &amp; FLECK M. M. (1983). D-theory : talking about talking about
trees. In Proceedings of the 21st annual meeting on Association for Computational Linguistics,
p. 129&#8211;136, Morristown, NJ, USA : Association for Computational Linguistics.
</p>
<p>PERRIER G. (2003). Les grammaires d&#8217;interaction. Habilitation &#224; diriger les recherches,
Universit&#233; Nancy 2.
</p>
<p>PERRIER G. (2007). A French Interaction Grammar. In RANLP 2007, p. 463&#8211;467, Borovets
Bulgarie.
</p>
<p>RAMBOW O. &amp; JOSHI A. (1997). A Formal Look at Dependency Grammars and Phrase-
Structure Grammars, with Special Consideration of Word-Order Phenomena. In Current Is-
sues in Meaning-Text Theory, London : Pinter.
</p>
<p>RAMBOW O., WEIR D. &amp; VIJAY-SHANKER K. (2001). D-tree substitution grammars. Com-
put. Linguist., 27(1), 89&#8211;121.
TESNI&#200;RE L. (1934). Comment construire une syntaxe. Bulletin de la Facult&#233; des Lettres de
Strasbourg, 12(7), 219&#8211;229.
VIJAY-SHANKER K. (1992). Using Description of Trees in Tree Adjoining Grammar frame-
work. Computational Linguistics, 18(4), 481&#8211;518.</p>

</div></div>
</body></html>