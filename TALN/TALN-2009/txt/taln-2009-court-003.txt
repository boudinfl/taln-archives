TALN 2009 — Session posters , Senlis, 24-26 juin 2009

Analyse en dépendances a l’aide des grammaires
d’interaction

Jonathan Marchandl Bruno Guillaumez Guy Perrierl
(1) LORIA / Université Nancy 2
(2) LORIA / INRIA Nancy Grand-Est
prénom.nom@loria.fr

Résumé. Cet article propose une méthode pour extraire une analyse en dépendances d’un
énoncé a partir de son analyse en constituants avec les grammaires d’interaction. Les gram-
maires d’interaction sont un formalisme grammatical qui exprime l’interaction entre les mots a
l’aide d’un systeme de polarités. Le mécanisme de composition syntaxique est régi par la sa-
turation des polarités. Les interactions s’effectuent entre les constituants, mais les grammaires
étant lexicalisées, ces interactions peuvent se traduire sur les mots. La saturation des polarités
lors de l’analyse syntaxique d’un énoncé permet d’extraire des relations de dépendances entre
les mots, chaque dépendance étant réalisée par une saturation. Les structures de dépendances
ainsi obtenues peuvent étre vues comme un rafﬁnement de l’analyse habituellement effectuée
sous forme d’arbre de dépendance. Plus généralement, ce travail apporte un éclairage nouveau
sur les liens entre analyse en constituants et analyse en dépendances.

Abstract. This article proposes a method to extract dependency structures from phrase-
structure level parsing with Interaction Grammars. Interaction Grammars are a formalism which
expresses interactions among words using a polarity system. Syntactical composition is led by
the saturation of polarities. Interactions take place between constituents, but as grammars are
lexicalized, these interactions can be translated at the level of words. Dependency relations are
extracted from the parsing process : every dependency is the consequence of a polarity satura-
tion. The dependency relations we obtain can be seen as a reﬁnement of the usual dependency
tree. Generally speaking, this work sheds new light on links between phrase structure and de-
pendency parsing.

M0tS-CléS I Analyse syntaxique, grammaires de dépendances, grammaires d’interaction,
polarité.

Keywords: Syntactic analysis, dependency grammars, interaction grammars, polarity.

Jonathan Marchand, Bruno Guillaume, Guy Perrier

1 Introduction

Les grammaires de constituants et les grammaires de dépendances sont souvent présentées
comme orthogonales : les premieres organisent les groupes de mots en syntagmes alors que
les secondes mettent la dépendance entre mots au centre de la structure syntaxique. Avec les
grammaires de constituants lexicalisées, telles que les grammaires d’arbres adjoints (TAG) et
les grammaires catégorielles (CG), o1‘1 chaque élément de la grammaire est associé a un mot,
la composition syntaxique lors de l’analyse met en évidence des liens entre les mots. Ces liens
présentent des similitudes avec les relations de dépendances et ont fait l’objet de différentes
études.

A. Dikovsky et L. Modina ont étudié du point de vue formel le passage d’une analyse en consti-
tuants a une analyse en dépendances et vice versa (Dikovsky & Modina, 2000). O. Rambow
et A. J oshi ont expliqué comment retrouver une analyse en dépendances a partir d’une analyse
dans les TAG ou les substitutions et les adjonctions sont vues comme des relations de dépen-
dances entre les mots (Rambow & J oshi, 1997). Enﬁn, l’article (Clark et al., 2002) propose une
méthode similaire pour les grammaires catégorielles combinatoires o1‘1 l’application des regles
combinatoires donne lieu a des relations de dépendances entre les mots.

Les grammaires d’interaction (IG) sont des grammaires de constituants lexicalisées qui étendent
par un systeme de polarités plus riche le systeme besoins/ressources employé dans les gram-
maires catégorielles. Dans cet article, nous généralisons, les résultats (Clark et al., 2002) cités
plus haut pour les CG au cas des IG, en révisant la méthode : en effet, cette derniere impose
d’étendre les entrées lexicales avec des marqueurs pour aider a la construction des dépendances
lors de l’analyse, et produit trop de dépendances, alors que notre méthode s’appuie plus simple-
ment sur le lien entre polarités et dépendances.

Dans la section 2, les IG sont présentées et illustrées par un exemple. La section 3 décrit la
méthode d’extraction des dépendances a partir d’une analyse avec une IG. Finalement, dans la
section 4, nous étudions les structures de dépendances obtenues et nous mettons en perspective
avec d’autres travaux.

2 Les grammaires d’interaction

Les grammaires d’interaction (Perrier, 2003) sont un formalisme grammatical s’appuyant sur
la notion de description d ’arbres. Cette notion a été introduite par M. Marcus, D. Hindle et
M. Fleck en 1983 (Marcus et al., 1983), et K. Vijay-Shanker l’a utilisée pour représenter de
fagon monotone l’opération d’adjonction des TAG (Vijay-Shanker, 1992).

Une description d’arbres est déﬁnie par un ensemble de noeuds et de relations d’ascendance,
de parenté et de précédence entre ces noeuds. Les noeuds représentent des syntagmes (éventuel-
lement vides) et les relations expriment les dépendances entre ces syntagmes. Les propriétés
morpho-syntaxiques de ces syntagmes sont décrites par des structures de traits.

Cette approche ﬂexible est bien adaptée al’ambigu'1'té des langues naturelles. Cependant, l’ana-
lyse syntaxique fondée sur des descriptions d’arbres est tres coﬁteuse (Koller et al., 1998). En
effet, dans cette approche, l’analyse syntaxique consiste a chercher des modeles de descrip-
tions d’arbres sous forme d’arbres syntaxiques completement spéciﬁés, ce qui est un probleme
NP-complet.

Analyse en dépendances a l’aide des grammaires d’interaction

Dans les forrnalismes opérationnels fondés sur les descriptions d’arbres (comme les D-tree sub-
stitution grammars (Rambow et al., 2001) ou les TT-MCTAG (Kallmeyer, 2005)), cet indéter-
rninisme est lirnité en contraignant la syntaxe des descriptions et le mécanisme de composition
syntaxique.

L’ originalité des grammaires d’interaction est de proposer un mécanisme de composition syn-
taxique tres souple qui consiste a superposer les descriptions d’arbres mais qui est guidé par
une contrainte de saturation de polarités. Cette contrainte fait reference a l’idée de valence de
Tesniere (Tesniere, 1934) et est essentielle dans les CG : chaque mot est équipé d’une valence
exprimant ses possibilités d’interaction avec les autres mots. La composition syntaxique est
controlée pas une dualité besoins/ressources : certaines ressources munies de polarités nega-
tives sont attendues alors que d’autres, munies de polarités positives, sont disponibles. Dans les
IG, cette idée de valence est reprise et généralisée.

2.1 Systéme de polarités

Contrairement aux CG, les IG attachent les polarités aux traits qui décorent les noeuds. Mais
nous nous en tiendrons ici a une version simpliﬁée des IG o1‘1 les polarités sont accrochées aux
noeuds. Une autre différence avec les CG est que le systeme de polarités est plus riche. En effet,
les IG proposent deux types d’interaction a base de polarités :

— les interactions linéaires : chaque noeud portant une polarité positive (notée +) doit fusion-
ner avec exactement un noeud portant une polarité négative (notée —) et réciproquement.

— les interactions non-linéaires : chaque noeud portant une polarité virtuelle (notée ~) doit
fusionner exactement, soit avec un noeud positif et un noeud négatif, soit avec un noeud portant
la polarité saturée (notée =). En revanche, un nombre quelconque de noeuds virtuels peuvent
fusionner avec le meme couple positif/négatif ou avec le méme noeud saturé.

Lors de la fusion de deux noeuds, le noeud résultant porte la polarité

issue de la composition des polarités des noeuds initiaux. La com- N _ + =
position d’une polarité positive et d’une polarité négative donne une N N _ + —
polarité saturée alors que la polarité virtuelle est l’élément neutre — — =

de cette opération. Toute autre composition provoque l’échec de la + + =

fusion (cf. tableau ci-contre). L’ opération de composition est asso- = =

ciative et commutative, l’ordre de fusion des noeuds n’a donc pas
d’importance dans le processus de composition syntaxique.

2.2 Analyse avec les IG

La structure syntaxique élémentaire manipulée dans les IG est appelée description d’arbre
polarisée (DAP). Une IG particuliere est déﬁnie par un ensemble de DAP; chaque DAP est
associée a un motl. La grammaire est ainsi un lexique ou un mot peut avoir plusieurs entrées.
Pour analyser une phrase, il faut choisir pour chaque mot l’une des DAP associée a ce mot.
Un tel choix est appelée une sélection lexicale. L’ analyse consiste ensuite a composer ces DAP
pour obtenir un arbre d’analyse.

L’ opération atornique de composition syntaxique consiste a superposer deux noeuds pour saturer

1Dans nos grarnmaires, il n’y a pas de co—ancre et donc un seul mot par DAP (l’usage de co—ancre peut-étre
simulé en utilisant des polarités).

Jonathan Marchand, Bruno Guillaume, Guy Perrier

leurs polarités. On itere l’opération de saturation de noeuds pour construire progressivement
l’analyse de la phrase sous forme d’un arbre.

Les DAP d’une sélection lexicale pour la phrase “Jean en connaft la couleur” sont représentées
sur la ﬁgure 1.

 

FIG. 1 — DAP associées a la phrase “Jean en connaft la couleur”

La DAP représentant le mot “en” décrit l’intuition linguistique suivante : le pronom “en”
est utilisé comme complément du nom “couleur” mais il vient s’adjoindre devant le verbe
“connaft” qui admet “la couleur” comme objet direct. La DAP montre a droite du noyau verbal
C2 un syntagme objet D2 attendu comportant un complément du nom J2 qui est déja comple-
tement saturé mais sans réalisation phonologique. Le noeud I 2 renseigne la positionnement du
nom dans le syntagme H2. Au niveau du noyau verbal C2, le pronom “en” E2 est positionné a
gauche du verbe F2.

A partir de l’ensemble des DAP de la ﬁgure 1, on peut construire l’arbre syntaxique saturé
représenté sur la ﬁgure 2. Sur chaque noeud de l’arbre est indiqué l’ensemble des noeuds des
DAP qui ont été superposés. Par exemple le noeud A2 —A3 représente la superposition du noeud
A2 de la DAP de “en” et du noeud A3 de la DAP de “connaft”.

 

FIG. 2 — Arbre d’analyse de “Jean en connaft la couleur”

2.3 Grammaire du francais

Pour valider le formalisme, nous avons développé une grammaire du francais (Perrier, 2007).
Cette grammaire a été évaluée sur la TSNLP (Lehmann et al., 1996) qui contient 1690 énoncés

Analyse en dépendances a l’aide des grammaires d’interaction

grammaticaux et 1935 énoncés agrammaticaux. Ce jeu de tests ne couvre pas toute la langue
francaise, il y a peu de phrases complexes mais il insiste sur certains phénomenes comme la
coordination ou la position des compléments adverbiaux. Cependant, notre grammaire couvre
d’autres phénomenes dont la TSNLP ne tient pas compte, comme par exemple : la voix passive,
la sous-categorisation des noms et des adjectifs prédicatifs, le controle du sujet des compléments
inﬁnitifs, les propositions relatives et interrogatives. 88% des 1690 phrases grammaticales sont
modélisées et 85% des 1935 phrases agrammaticales sont rejetées. Les 15% d’énoncés agram-
maticaux sont acceptés car la grammaire ne modélise pas les regles phonologiques et la seman-
tique. Les raisons pour lesquelles 12% des énoncés grammaticaux ne sont pas analysés sont
diverses (phrases retranscrites de l’oral, expressions ﬁgées, causatifs, superlatifs).

3 Analyse en dépendances

L’ analyse syntaxique est obtenue par superposition des DAP d’une sélection lexicale. La super-
position est guidée par la fusion des noeuds portant des polarités se saturant. Au niveau d’une
DAP, ces polarités représentent les besoins/ressources du mot dans un énoncé. La saturation
de ces demieres peut alors se voir comme la résolution d’une dépendance entre ces mots. On
peut alors retrouver les relations de dépendances d’une phrase a partir de l’ensemble des DAP
associées aux mots de la phrase et de son analyse.

3.1 Dépendances linéaires

Nous nous intéressons dans un premier temps au cas simple de la saturation linéaire de deux
polarités + et —. Par exemple, dans la phrase “Jean en connaft la couleur” (Figure 2), la DAP
représentant le déterminant “la” possede un noeud G4 portant une polarité positive et étiqueté
par la catégorie syntaxique DET. La DAP du nom “couleur” comporte quant a elle un noeud G5
portant une polarité negative qui est aussi étiqueté par DET.

Lors de l’analyse, ces deux noeuds fusionnent pour obtenir un noeud saturé, la DAP résultante
représentant une analyse partielle de “la couleur”. La saturation de ces deux noeuds peut étre
vue comme la réalisation d’une relation de dépendances entre les deux mots correspondants.

L’ opération de saturation représente la satisfaction d’une contrainte de besoins/ressources. Un
élément qui se présente comme nécessitant une ressource est considéré comme le gouvemeur
de la relation de dépendances, tandis qu’un élément qui se présente comme foumissant une
ressource se retrouve comme le dépendant de cette relation. Ainsi, en cas d’interaction linéaire,
le mot dont la DAP contient le noeud négatif est le gouvemeur et le mot dont la DAP contient
le noeud positif est le dépendant de la relation de dépendances.

Les relations de dépendances engendrées par la saturation des noeuds portant des polarités op-
posées seront appelées dépendances linéaires. Dans la grammaire actuelle du francais, elles
représentent les relations téte-complément et téte-spéciﬁeur.

Dans l’exemple “Jean en connaft la couleur”, les dépendances linéaires obtenues sont repré-
sentées sur la ﬁgure 3 (les arcs portent la catégorie qui a fait l’objet d’une saturationz).

zen pratique, il est possible d’utiliser d’autres étiquettes sur les arcs comme les fonctions syntaxiques (elles
sont indiquées dans les structures de traits).

Jonathan Marchand, Bruno Guillaume, Guy Perrier

r —r;:m

N P
Jean en connait couleur

FIG. 3 — Relations de dépendances linéaires dans la phrase “Jean en connaft la couleur”

Cette analyse possede un noeud “en ” isolé. La DAP du pronom “en ” ne porte en effet pas de
polarité positive ou négative et ainsi ne produit pas de relation de dépendances linéaires avec
le reste de la phrase. La saturation des polarités positives et négatives ne sufﬁt donc pas pour
exprimer toutes les relations de dépendances d’une phrase. Nous allons donc voir comment
certaines relations de dépendances peuvent étre produites pas des interactions non-linéaires.

3.2 Dépendances non-linéaires

Dans la graInmaire actuelle, la DAP pour l’adjectif “belle” dans le groupe no-

minal “la belle couleur” est donnée par la ﬁgure ci-contre. De facon habituelle

en dépendances, on considere qu’il y a une dépendance de “belle” vis a vis de

“couleur”. Deux noeuds sont non-saturés (H 6 et I 6) et ils portent tous les deux a

une polarités virtuelle, c’est donc la saturation de l’une de ces deux polarités 
qui doit induire la dépendance. Dans ce cas, les deux polarités peuvent étre

a l’origine de la dépendance. Cependant, il ne doit étre produit qu’une seule

relation de dépendances, il faut choisir alors quelle polarité engendrera une

dépendance lors de sa saturation.

Un autre exemple d’usage des polarités virtuelles dans la grammaire du
francais est illustré par l’exemple “Jean le connaft”. Dans cette phrase,

le pronom “le ” (ci-contre) est l’objet direct du verbe “connaft” : cette re- 9
lation de dépendances est produite par la saturation linéaire des polarités
du noeud D 7 de la DAP du pronom “le ” et du noeud D 3 de la DAP du mot 

“connaft”. Mais la DAP du pronom “le” possede trois noeuds A7, C7, ‘

F 7 portant une polarité virtuelle dont la saturation non-linéaire n’apporte ® a
aucune information de dépendances entre les mots “le” et “connaft”.

Ces polarités controlent simplement la place des syntagmes lors de la

superposition des deux DAP et gerent le fait que le pronom “le ” se place

avant le verbe alors que la place canonique du groupe nominal objet dans

la phrase est apres le verbe. Dans l’arbre d’analyse de “Jean le connaft” les trois noeuds vir-
tuels A7, C7, F7 sont saturés, respectivement, par les trois noeuds A3, C3, F3 de la DAP du
mot “connaft”.

Les deux derniers exemples montrent bien qu’il y a deux usages distincts des polarités virtuelles

qui ne se comportent pas de la meme maniere pour la production de relation de dépendances :

— les polarités virtuelles de dépendances qui portent une information sur les relations de
dépendances d’un mot avec son environnement;

— les polarités virtuelles de contexte qui imposent des contraintes sur le contexte syntaxique
d’un mot.

Il n’est pas possible de distinguer automatiquement, dans une grammaire donnée, les deux types

de polarités virtuelles. C’est donc a l’auteur de la grammaire de se baser sur des criteres lin-

guistiques pour distinguer ces deux usages. Cependant, dans la pratique, l’utilisation de meta-

Analyse en dépendances a l’aide des grammaires d’interaction

grammaires (notre grammaire, par exemple, est constr11ite avec XMG (Duchier et al., 2005))
permet de faire ce travail rapidement, de facon cohérente sur l’ensemble de la grammaire. Cela
concerne uniquement les mots jouant le role de modiﬁcateurs (adjectifs épithetes, adverbes,
prépositions introduisant des compléments adjoints, pronoms relatifs dans leur role par rapport
a leur antécédent, pronom clitique "il" utilisé en redoublement du sujet, etc.). Il s’agit, dans la
DAP associé au mot concerné de marquer le noeud considéré comme noeud privilégié de ratta-
chement au mot qui est modiﬁé. Le travail a été effectué sur notre grammaire du francais a large
couverture en moins d’une heure.

Ainsi, dans la DAP de “en ” (ﬁgure 1), toutes les polarités virtuelles des noeuds A2, C2, D2 et
F2 sont des polarités virtuelles de contexte qui gerent le positionnement de “en ”. Pour rendre
compte du fait que “en ” dépend de “couleur”, il faut que l’une des deux polarités virtuelles H2
ou I2 soit une polarité virtuelle de dépendances. Dans notre cas, nous avons choisi arbitraire-
ment la polarité H2.

Dans le cas ou une relation de dépendances est produite, le dépendant est le mot dont la DAP
porte le noeud virtuel de dépendances. La polarité virtuelle peut étre saturé :

— soit par un noeud portant la polarité =, dans ce cas ce noeud est le gouverneur;

— soit par un couple de noeud (un positif et un négatif), dans ce cas le gouverneur est le noeud

portant la polarité positive.

Les relations ainsi engendrées sont appelées dépendances non-linéaires. En effet, un noeud
saturé pouvant se composer avec zéro ou plusieurs noeuds virtuels, plusieurs relations de dépen-
dances peuvent avoir comme gouverneur le meme mot. Ces relations de dépendances expriment
généralement une relation modiﬁeur-modiﬁé.

Dans les structures de dépendances (ﬁgures 4 ci-dessous et 5 plus loin) les dépendances linéaires
sont représentées au-dessus de la phrase et les non-linéaires au-dessous.

La procédure d’extraction des dépendances se résume ainsi :

— La saturation de polarités opposées engendre une relation de dépendances linéaire entre les
mots ; la relation va de la polarité négative vers la polarité positive.

— La saturation d’une polarité virtuelle de dépendances avec une polarité positive ou saturée
engendre une relation de dépendances non linéaire entre les mots ; la relation va de la polarité
saturée ou positive vers la polarité virtuelle de dépendances.

Cette procédure permet d’obtenir l’analyse en dépendances de “Jean en connaft la couleur”

représentée ﬁgure 4.
7 ﬂ I F DET 1 I
la

N P
Jean en connait couleur

mom]

FIG. 4 — Relations de dépendances dans la phrase “Jean en connaft la couleur”

Pour garantir que les structures de dépendances sont connexes (chaque mot est en relation
avec au moins un autre mot de l’énoncé), il sufﬁt d’imposer que chaque DAP de la grammaire
contienne au moins un noeud positif, un noeud négatif ou un noeud portant une polarité virtuelle
de dépendances. C’est la cas de la grammaire actuellement implantée pour le francais.

Jonathan Marchand, Bruno Guillaume, Guy Perrier

4 Structures de dépendances obtenues

Le choix du type de structures pour représenter les dépendances d’une phrase est une question
épineuse qui divisent les linguistes. L’idée de départ des grammaires de dépendances est de
considérer que chaque mot de la phrase (sauf le verbe principal) est gouveme’ par exactement
un autre mot de la meme phrase. Cette hypothese conduit a considérer que les bonnes structures
de dépendances sont les arbres, nous allons voir ce qu’il en est avec notre méthode qui permet
d’observer, sans a priori, les structures obtenues.

4.1 Graphes orientés

De fagon générale, la structure en dépendances que l’on obtient est un graphe orienté ; de plus,
avec la restriction imposée sur les DAP de la grammaire, on sait que ce graphe est connexe.

L’ analyse en dépendances pour la phrase “Jean en connaft la couleur” donnée par la ﬁgure 4 est
un arbre; en effet, tous les mots, sauf “connaft”, ont un et un seul gouverneur. Il existe cepen-
dant des exemples pour lesquels la structure de dépendances n’est pas un arbre. L’ application
de notre méthode a la phrase “la ﬁlle que Jean aime vient” produit l’analyse de la ﬁgure 5.
Cette structure n’est pas un arbre car elle contient un cycle3 et le pronom relatif “que” a deux
gouverneurs.

NP

la ﬁlle que Jean aime vient

LNPJ

FIG. 5 — Relations de dépendances dans la phrase “la ﬁlle que Jean aime vient”

On retrouve ainsi avec notre méthode le probleme qui se pose habituellement en grammaire de
dépendances pour gérer les phénomenes d’extraction. Par exemple, si nous reprenons la phrase
“la ﬁlle que Jean aime vient”, le mot “que” remplit ici deux roles, il est l’objet anaphorique
de “aime” et subordonne la relative a l’antécédent. Ce double role suppose naturellement deux
relations de dépendances distinctes qui contredisent le principe de representation en arbre, alors
que l’analyse présentée ﬁgure 5 rend bien compte de ce double emploi. D’autres approches
d’analyses en dépendances utilise également des structures qui ne sont pas des arbres : S. Ka-
hane (Kahane, 2000) propose une analyse dans laquelle un pronom relatif a deux gouverneurs ;
R. Hudson (Hudson, 1990) utilise également souvent des structures dans lesquelles un mot peut
avoir plusieurs gouverneurs.

4.2 Projectivité

Une autre question récurrente a propos des structures de dépendances a considérer pour la des-
cription de la langue est celle de la projectivité. En effet une structure projective induit que les

1:,“

3 “aime” gouverne “que” car “que” est le complement d’objet de “aime , que” gouverne “aime” car c’est

le pronom relatif qui introduit la relative ou “aime ” est le verbe.

Analyse en dépendances a l’aide des grammaires d’interaction

relations de dépendances restent a un niveau local, ce qui permet une analyse simple et efﬁcace.

Cette notion initialement déﬁnie pour les arbres peut se transposer sur les graphes : une structure
de dépendances est dite projective si pour tout mot donné, l’ensemble des noeuds atteignables
depuis ce mot dans la structure de dépendances (qu’on appellera emprise du mot) correspond
a un segment continu de l’énoncé. Par exemple la structure de la ﬁgure 5 est projective alors
que celle de la ﬁgure 4 ne l’est pas : dans cette analyse, l’emprise du mot “couleur” est formé
de deux segments “en ” et “la couleur” séparés par le mot “connaft”.

4.3 Classes de structures de dépendances

R. Debusmann and M. Kuhlmann proposent des criteres qui permettent de classer plus ﬁne-
ment les analyses non-projectives. I1 obtiennent ainsi une hiérarchisation en classes du pouvoir
expressif que permettent les différentes structures de dépendances (Debusmann & Kuhlmann,
2009). La notion de degré de discontinuité (block-degree) associe a une structure un entier qui
est le nombre maximum de segments continus disjoints dans l’emprise d’un mot (un degré de
discontinuité de 1 correspond exactement a la projectivité). Pour les structures dont le degré de
discontinuité est au moins 2, ils distinguent celles qui sont bien imbriquées (well-nestedness)
c’est-a-dire celle qui sont telles que les emprises des deux mots ne se croisent pas (soit elles
sont disjointes, soit l’une est entierement incluse entre deux segments de l’autre). Sur le Prague
Dependency Treebank, les auteurs montrent que 99,5% des analyses sont bien imbriquées et de
degré de discontinuité au plus deux (ce qui est equivalent a étre dans la classe de langages des
TAG).

L’ application de notre méthode a cette grammaire du francais sur la TSNLP ne produit pas
d’analyse mal imbriquées. On obtient dans la plupart des cas des structures de dépendances pro-
jectives. Les exemples pour lesquels le degré de discontinuité est de 2 sont dﬁs principalement
au placement de l’auxiliaire dans le noyau verbal. Les mots “en ” ou “y” ainsi que l’inversion
sujet/verbe lors de l’emploi de pronoms interrogatifs sont d’autres sources de discontinuité,

mais nous n’avons pas trouvé d’eXemple qui aille au-dela d’un degré de discontinuité de 2.

5 Conclusion

Dans cet article, nous avons proposé une méthode pour constr11ire une analyse en dépendances
d’un énoncé a partir de son analyse en constituants dans les IG. Cette méthode, basée sur la satu-
ration des polarités, a Inis en évidence deux types de dépendances : les dépendances linéaires qui
représentent les relations téte-complément ou téte-spéciﬁeur et les dépendances non-linéaires
qui représentent les relations modiﬁeur-modiﬁé.

Les structures de dépendances obtenues par cette méthode sont des graphes orientés, elles sont
plus riches que les structures obtenues habituellement par des grammaires de dépendances.
Cette représentation permet de gérer simplement les phénomenes linguistiques posant habituel-
lement des difﬁcultés dans les grammaires de dépendances.

Pour la suite du travail, nous souhaitons étudier dans quelle mesure il est possible de transposer
les méthodes d’analyses d’un formalisme a l’autre. Par exemple, Nous avons remarqué que tres
peu d’analyses sont non-projectives ; on pourrait donc isoler les cas non-projectifs et adapter un
algorithme d’analyse des grammaires de dépendances qui servirait de guide a l’analyse dans les

Jonathan Marchand, Bruno Guillaume, Guy Perrier

IG. Il serait également intéressant d’étudier l’application de nos méthodes d’analyse spéciﬁques
aux IG a l’analyse pour des grammaires de dépendances lexicalisées.

Références

CLARK S., HOCKENMAIER J. & STEEDMAN M. (2002). Building deep dependency struc-
tures with a wide-coverage CCG parser. In In Proceedings of the 40th Meeting of the ACL, p.
327-334.

DEBUSMANN R. & KUHLMANN M. (2009). Dependency grammar : Classiﬁcation and ex-
ploration. In Resource-Adaptive Cognitive Processes : Springer.

DIKOVSKY A. & MODINA L. (2000). Dependencies on the other Side of the Curtain. TA.L,
1, 79-1 1 1.

DUCHIER D., LE Roux J. & PARMENTIER Y. (2005). XMG : Un Compilateur de Meta-

GraInInaires Extensible. In M. JARDINO, Ed., Actes de TALN 2005 (Traitement automatique
des langues naturelles), Dourdan : ATALA LIMSI.

HUDSON R. A. (1990). English Word Grammar. Blackwell.

KAHANE S. (2000). Extractions dans une grammaire de dépendance a bulles. TA.L., 41(1),
187-216.

KALLMEYER L. (2005). Tree-local Multicomponent Tree Adjoining Grammars with Shared
Nodes. Computational Linguistics, 31(2), 187-225.

KOLLER A., NIEHREN J . & TREINEN R. (1998). Dominance constraints : Algorithms and
complexity. In LACL’98, p. 106-125, Heidelberg.

LEHMANN S., OEPEN S., C I., BAUR H. H., LBDKAN O. & ARNOLD D. (1996). tsnlp —
test suites for natural language processing. In In J. Nerbonne (Ed.), Linguistic Databases (pp.

I3 - 36, p. 711-716 : CSLI Publications.

MARCUS M. P., HINDLE D. & FLECK M. M. (1983). D-theory : talking about talking about
trees. In Proceedings of the 21 st annual meeting on Association for Computational Linguistics,
p. 129-136, Morristown, NJ, USA : Association for Computational Linguistics.

PERRIER G. (2003). Les grammaires d’interaction. Habilitation a diriger les recherches,
Université Nancy 2.

PERRIER G. (2007). A French Interaction Grammar. In RANLP 2007, p. 463-467, Borovets
Bulgarie.

RAMBOW O. & J OSHI A. (1997). A Formal Look at Dependency Grammars and Phrase-
Structure Grammars, with Special Consideration of Word-Order Phenomena. In Current Is-
sues in Meaning- Text Theory, London : Pinter.

RAMBOW 0., WEIR D. & VIJAY-SHANKER K. (2001). D—tree substitution grammars. Com-
put. Linguist., 27(1), 89-121.

T ESNIERE L. (1934). Comment constr11ire une syntaxe. Bulletin de la Faculte’ des Lettres de
Strasbourg, 12(7), 219-229.

VIJAY-SHANKER K. (1992). Using Description of Trees in Tree Adjoining Grammar frame-
work. Computational Linguistics, 18(4), 481-518.

