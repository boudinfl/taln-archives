<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Analyse rel&#226;ch&#233;e &#224; base de contraintes</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009 &#8211; Session posters , Senlis, 24&#8211;26 juin 2009
</p>
<p>Analyse rel&#226;ch&#233;e &#224; base de contraintes
</p>
<p>Jean-Philippe Prost&#8727;
</p>
<p>LIFO, Universit&#233; d&#8217;Orl&#233;ans
JPProst@gmail.com
</p>
<p>R&#233;sum&#233;. La question de la grammaticalit&#233;, et celle duale de l&#8217;agrammaticalit&#233;, sont des
sujets d&#233;licats &#224; aborder, d&#232;s lors que l&#8217;on souhaite int&#233;grer diff&#233;rents degr&#233;s, tant de grammat-
icalit&#233; que d&#8217;agrammaticalit&#233;. En termes d&#8217;analyse automatique, les probl&#232;mes pos&#233;s sont de
l&#8217;ordre de la repr&#233;sentation des connaissances, du traitement, et bien &#233;videment de l&#8217;&#233;valuation.
Dans cet article, nous nous concentrons sur l&#8217;aspect traitement, et nous nous penchons sur la
question de l&#8217;analyse d&#8217;&#233;nonc&#233;s agrammaticaux. Nous explorons la possibilit&#233; de fournir une
analyse la plus compl&#232;te possible pour un &#233;nonc&#233; agrammatical, sans l&#8217;apport d&#8217;information
compl&#233;mentaire telle que par le biais de mal-r&#232;gles ou autre grammaire d&#8217;erreurs. Nous pro-
posons une solution algorithmique qui permet l&#8217;analyse automatique d&#8217;un &#233;nonc&#233; agrammati-
cal, sur la seule base d&#8217;une grammaire mod&#232;le-th&#233;orique de bonne formation. Cet analyseur est
prouv&#233; g&#233;n&#233;rer une solution optimale, selon un crit&#232;re num&#233;rique maximis&#233;.
</p>
<p>Abstract. The question of grammaticality, and the dual one of ungrammaticality, are top-
ics delicate to address when interested in modeling different degrees, whether of grammaticality
or ungrammaticality. As far as parsing is concerned, the problems are with regard to knowledge
representation, processing, and obviously evaluation. In this paper, we concentrate on the pro-
cessing aspect and we address the question of parsing ungrammatical utterances. We explore
the possibility to provide a full parse for an ungrammatical utterance without relying on any
kind of additional information, which would be provided by mal-rules or other error grammar.
We propose an algorithmic solution in order to parse an ungrammatical utterance using only
a model-theoretic grammar of well-formedness. The parser is proven to generate an optimal
solution, according to a maximised criterion.
</p>
<p>Mots-cl&#233;s : grammaticalit&#233;, analyse syntaxique, contraintes, syntaxe mod&#232;le-th&#233;orique.
</p>
<p>Keywords: grammaticality, syntactic parsing, constraints, Model-Theoretic Syntax.
</p>
<p>1 Introduction
</p>
<p>La notion m&#234;me de grammaticalit&#233; est sujette &#224; diff&#233;rentes interpr&#233;tations, selon le cadre th&#233;ori-
que auquel elle s&#8217;applique. Ainsi, il est possible de d&#233;gager trois grandes interpr&#233;tations aux dif-
f&#233;rences notables, qui s&#8217;appliquent &#224; des cadres formels diff&#233;rents. Au sens g&#233;n&#233;ratif du terme,
la grammaticalit&#233; est une notion strictement binaire selon laquelle une phrase est soit grammat-
icale, soit agrammaticale. Cette notion g&#233;n&#233;rative est &#233;troitement li&#233;e au processus d&#8217;analyse
et &#224; l&#8217;existence ou non d&#8217;un arbre syntaxique pour cette phrase : une phrase est grammaticale
</p>
<p>&#8727;Ces travaux ont &#233;t&#233; men&#233;s conjointement au CLT &#224; Macquarie University, Sydney, Australie, et au LPL &#224;
l&#8217;Universit&#233; de Provence.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>J-Ph. Prost
</p>
<p>si et seulement si il est possible d&#8217;en g&#233;n&#233;rer une analyse &#224; l&#8217;aide d&#8217;une grammaire donn&#233;e.
L&#8217;objet th&#233;orique de la Syntaxe G&#233;n&#233;rative-&#201;num&#233;rative1 (GES) ne concerne que l&#8217;explication
des ph&#233;nom&#232;nes linguistiques qui rel&#232;vent de la grammaticalit&#233;, et ne permet pas d&#8217;expliquer
des ph&#233;nom&#232;nes atypiques, tels que l&#8217;ouverture lexicale (apparition permanente de nouveaux
termes), les fragments bien-form&#233;s (e.g. &#8220;Il me semble que...&#8221;, &#8220;Oui, mais alors je...&#8221;, etc..),
l&#8217;agrammaticalit&#233;, ou encore la grammaticalit&#233; graduelle (i.e. gradience) (Pullum &amp; Scholz,
2001).
</p>
<p>Au sens de la Th&#233;orie de l&#8217;Optimalit&#233; (OT) (Prince &amp; Smolensky, 1993), la grammaticalit&#233;
s&#8217;applique cette fois non pas &#224; une phrase, mais &#224; une structure : par d&#233;finition, une structure
candidate pour une phrase est grammaticale si et seulement si cette structure est optimale parmi
l&#8217;ensemble des candidats. D&#232;s lors, toute phrase pour laquelle la fonction GEN g&#233;n&#232;re au moins
une structure candidate est n&#233;cessairement grammaticale au sens d&#8217;OT. Cependant, l&#8217;objet d&#8217;OT
n&#8217;est pas de d&#233;crire les m&#233;canismes de g&#233;n&#233;ration de structures syntaxiques (la fonction GEN
est donn&#233;e), mais bien de permettre d&#8217;expliquer pourquoi une structure donn&#233;e est optimale
aux yeux d&#8217;une grammaire donn&#233;e. En ce sens, la couverture d&#8217;OT en termes de ph&#233;nom&#232;nes
linguistiques est donc th&#233;oriquement plus &#233;tendue que celle de la GES. En revanche, la notion de
grammaticalit&#233; qu&#8217;elle introduit peut poser probl&#232;me, puisqu&#8217;elle ne permet pas de distinguer la
bonne-formation de la mal-formation, et donc la grammaticalit&#233; de l&#8217;agrammaticalit&#233;. Ceci est
li&#233; au fait que la violation de contraintes grammaticales n&#8217;est pas n&#233;cessairement significative
d&#8217;agrammaticalit&#233;, ne serait-ce que partielle. Tout au plus, les diff&#233;rentes structures candidates
associ&#233;es &#224; un &#233;nonc&#233; peuvent &#234;tre ordonn&#233;es en fonction de leur acceptabilit&#233; grammaticale,
comme le permet la Th&#233;orie Lin&#233;aire de l&#8217;Optimalit&#233; (Keller, 2000). Si la n&#233;cessit&#233; de pouvoir
clairement distinguer grammaticalit&#233; et agrammaticalit&#233; au sein d&#8217;une th&#233;orie linguistique est
certes discutable (Meurers, 2007), il est des contextes applicatifs, comme l&#8217;apprentissage d&#8217;une
langue ou la correction grammaticale, o&#249; une telle distinction s&#8217;impose.
</p>
<p>Au sens de la Syntaxe Mod&#232;le-Th&#233;orique (MTS) (Pullum, 2007), la grammaticalit&#233; d&#8217;un &#233;nonc&#233;
est d&#233;finie par la consistance d&#8217;un mod&#232;le pour cet &#233;nonc&#233;, c&#8217;est-&#224;-dire la satisfaction par ce
mod&#232;le des contraintes grammaticales. La diff&#233;rence fondamentale d&#8217;avec la syntaxe g&#233;n&#233;ra-
tive vient de ce que le r&#244;le de la grammaire n&#8217;est plus de g&#233;n&#233;rer mais de valider des structures
linguistiques. Une grammaire MTS est alors un ensemble de contraintes non-ordonn&#233;es, qui
peuvent &#234;tre &#233;valu&#233;es ind&#233;pendament les unes des autres. Cette propri&#233;t&#233; facilite &#233;galement, en
th&#233;orie, la relaxation de certaines contraintes, ce qui permet d&#8217;int&#233;grer des degr&#233;s de grammat-
icalit&#233; et d&#8217;agrammaticalit&#233;, selon des modalit&#233;s &#224; d&#233;finir. Les cadres formels pour la MTS les
plus communs sont HPSG (Pollard &amp; Sag, 1994), ou la famille des formalismes bas&#233;s sur les
grammaires de d&#233;pendances par contraintes (Maruyama, 1990).
</p>
<p>Au-del&#224; des possibilit&#233;s offertes par tel ou tel cadre en mati&#232;re d&#8217;analyse robuste, la question
g&#233;n&#233;rale que nous posons est celle, double, de la repr&#233;sentation des propri&#233;t&#233;s syntaxiques d&#8217;un
&#233;nonc&#233; agrammatical, et de l&#8217;estimation de son degr&#233; de grammaticalit&#233;. Peut-on analyser les
propri&#233;t&#233;s syntaxiques d&#8217;un &#233;nonc&#233; agrammatical, en ne disposant que d&#8217;une grammaire de
bonne-formation2 ? L&#8217;aspect du probl&#232;me qu&#8217;il est important de souligner concerne la nature de
l&#8217;information syntaxique dont on dispose au sujet d&#8217;un &#233;nonc&#233;, qu&#8217;il soit grammatical ou non.
Cette information doit d&#8217;une part nous permettre de conclure quant &#224; la grammaticalit&#233; d&#8217;un
</p>
<p>1Le terme Generative-Enumerative Syntax a &#233;t&#233; introduit dans (Pullum &amp; Scholz, 2001).
2Nous faisons r&#233;f&#233;rence ici &#224; bon nombre de travaux en analyse syntaxique robuste, qui font appel, en plus d&#8217;une
</p>
<p>grammaire de bonne-formation, &#224; un compl&#233;ment de r&#232;gles de mal-formation (Bender et al., 2004; Foster, 2007).
Outre leur efficacit&#233; pratique, le probl&#232;me de ces approches est qu&#8217;elles ne proposent pas de solution g&#233;n&#233;rale pour
expliquer des ph&#233;nom&#232;nes qui ne seraient pas couverts par les grammaires de bonne- et mal-formation.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Analyse rel&#226;ch&#233;e &#224; base de contraintes
</p>
<p>&#233;nonc&#233;, et d&#8217;autre part de permettre l&#8217;estimation de son degr&#233; d&#8217;(a)grammaticalit&#233;. Dans cet
article nous nous concentrons uniquement sur l&#8217;aspect analytique et n&#8217;abordons pas la question
de la gradation. Nous formulons l&#8217;hypoth&#232;se selon laquelle, dans un cadre de syntaxe mod&#232;le-
th&#233;orique, un mod&#232;le (i.e. une structure syntaxique) qui optimise le nombre de contraintes sat-
isfaites par rapport au nombre de contraintes viol&#233;es peut constituer une analyse compl&#232;te plau-
sible pour une phrase agrammaticale. Afin de tester cette hypoth&#232;se nous avons d&#233;velopp&#233; un
algorithme d&#8217;analyse syntaxique pour le cadre mod&#232;le-th&#233;orique des Grammaires de Propri&#233;t&#233;s
(GP) (Blache, 2005) qui g&#233;n&#232;re la structure de constituant de m&#233;rite maximum pour une phrase
donn&#233;e, qu&#8217;elle soit grammaticale ou non. Notre analyseur diff&#232;re des analyseurs existants pour
les GP (Morawietz &amp; Blache, 2002; Dahl &amp; Blache, 2004; VanRullen, 2005) principalement
de par l&#8217;optimalit&#233; de la solution propos&#233;e. Apr&#232;s avoir introduit et detaill&#233; cet algorithme nous
pr&#233;sentons les r&#233;sultats de l&#8217;&#233;valuation faite de son implantation.
</p>
<p>2 Algorithme
</p>
<p>Cet article introduit un algorithme d&#8217;analyse tabulaire par satisfaction rel&#226;ch&#233;e (Loose Satis-
faction Chart Parsing, LSCP), d&#233;crit par l&#8217;Algorithme 1. L&#8217;analyseur LSCP est bas&#233; sur l&#8217;al-
gorithme d&#8217;analyse tabulaire probabiliste de Cocke-Kasami-Younger (CKY). Il utilise le m&#234;me
</p>
<p>Algorithme 1 Analyse tabulaire &#224; base de satisfaction rel&#226;ch&#233;e (Loose Satisfaction Chart Parsing)
/&#8727; Initialisation &#8727;/
Create and clear the chart pi : every score in pi set to 0
</p>
<p>/&#8727; Cas de base : peupler pi avec des POS-tags pour chaque mot &#8727;/
for i&#8592; 1 to num_words
</p>
<p>for (each POS-construction T of wi)
if merit(T ) &#8805; pi[i, 1, T ] then
</p>
<p>Create constituent wTi , whose construction is T
pi[i, 1, T ]&#8592; {wTi ,merit(wTi )}
</p>
<p>/&#8727; Cas r&#233;cursif &#8727;/
/&#8727; Etape 1 : S&#201;LECTION de l&#8217;empan courant de r&#233;f&#233;rence &#8727;/
for span&#8592; 1 to num_words
</p>
<p>for offset&#8592; 1 to num_words&#8722; span + 1
end &#8592; offset + span&#8722; 1
K &#8592; &#8709;
</p>
<p>/&#8727; Etape 2 : &#201;NUMERATION de toutes les configurations &#8727;/
for (every set partition P in [offset, . . . , end])
</p>
<p>KP &#8592; buildConfigurations(P)
K &#8592; K &#8746;KP
</p>
<p>/&#8727; Etape 3 : CARACT&#201;RISATION du syst&#232;me de contraintes de la grammaire &#8727;/
for (every configurationA &#8712; KP )
</p>
<p>&#967;A &#8592; characterisation(A)
/&#8727; Etape 4 : PROJECTION de constructions &#8727;/
</p>
<p>/&#8727; CA est un ensemble de constituants candidats. &#8727;/
CA &#8592; projection(&#967;A )
checkpoint(CA)
</p>
<p>/&#8727; Etape 5 : M&#201;MOISATION du constituant candidat optimal &#8727;/
for (every candidate constituent x &#8712; CA, of construction C)
</p>
<p>if merit(x) &#8805; pi[offset, span, C] then
pi[offset, span, C]&#8592; {x,merit(x)}
</p>
<p>if pi[offset, span] = &#8709; then
pi[offset, span]&#8592; preferred forest in K
</p>
<p>squelette que le CKY, sur lequel vient se greffer un processus de satisfaction rel&#226;ch&#233;e de con-
traintes, d&#233;crit plus bas. Le terme de tabulaire fait r&#233;f&#233;rence &#224; l&#8217;utilisation d&#8217;une table de pro-
grammation dynamique. L&#8217;algorithme LSCP diff&#232;re cependant du CKY sur diff&#233;rents points.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>J-Ph. Prost
</p>
<p>S15
</p>
<p>NP3
D1
</p>
<p>Le
</p>
<p>N2
</p>
<p>juge
</p>
<p>VP9
</p>
<p>V8
</p>
<p>octroie
</p>
<p>*NP7
</p>
<p>AP6
</p>
<p>A4
</p>
<p>bref
</p>
<p>N5
</p>
<p>entretien
</p>
<p>PP10
</p>
<p>P11
</p>
<p>&#224;
</p>
<p>NP12
</p>
<p>D13
</p>
<p>ce
</p>
<p>N14
</p>
<p>plaignant
</p>
<p>FIG. 1 &#8211; Exemple d&#8217;analyse g&#233;n&#233;r&#233;e par l&#8217;analyseur LSCP pour une phrase agrammaticale.
</p>
<p>Alors que le CKY n&#233;cessite une grammaire en Forme Normale de Chomsky (CNF), le LSCP
prend une grammaire de propri&#233;t&#233;s ordinaire, aucun &#233;quivalent de la CNF n&#8217;existant pour le
formalisme des GP. La cons&#233;quence directe en est la g&#233;n&#233;ration de structures arborescentes n-
aires, et non d&#8217;arbres binaires. Une autre diff&#233;rence tient dans l&#8217;utilisation de valeurs de m&#233;rite
des constituants en lieu et places des probabilit&#233;s. C&#8217;est sur la base de cette valeur de m&#233;rite
&#224; maximiser que l&#8217;analyseur optimise le choix de la solution. La Figure 1 illustre un exemple
d&#8217;analyse g&#233;n&#233;r&#233;e par l&#8217;analyseur LSCP pour une phrase agrammaticale.
</p>
<p>L&#8217;algorithme LSCP, comme le CKY, repose sur une technique de programmation dynamique.
Ainsi, la recherche d&#8217;une solution g&#233;n&#233;rale optimale se d&#233;compose en sous-probl&#232;mes pour cha-
cun desquels l&#8217;analyseur trouve une solution optimale. Ces solutions partielles interm&#233;diaires
sont dites sous-structures optimales. Dans notre cas, le principe fondamental qui s&#8217;applique
est qu&#8217;une solution optimale n&#8217;est n&#233;cessairement compos&#233;e que de sous-constituants qui tous
optimisent la solution globale. En supposant que la fonction de m&#233;rite pr&#233;sente les propri&#233;t&#233;s
ad&#233;quates quant &#224; l&#8217;optimalit&#233;, il est ais&#233; de montrer, par l&#8217;absurde, que s&#8217;il existe une solution
de m&#233;rite optimal, et si l&#8217;un de ses sous-constituants n&#8217;optimise pas ce m&#233;rite, alors il existe
n&#233;cessairement un autre sous-constituant qui, lorsqu&#8217;il est substitu&#233; au constituant sous-optimal,
conduit &#224; une solution de meilleur m&#233;rite, ce qui contredit l&#8217;hypoth&#232;se. Ces sous-structures op-
timales sont m&#233;moris&#233;es dans une table de programmation dynamique (TPD), par un processus
de m&#233;moisation. La programmation dynamique permet &#233;galement d&#8217;optimiser le processus en
&#233;vitant les r&#233;-it&#233;rations redondantes du m&#234;me sous-probl&#232;me. La TPD qu&#8217;utilise LSCP prend
pour coordonn&#233;es les mots de la phrase &#224; analyser comme abscisse, et les tailles d&#8217;empans
analys&#233;s en ordonn&#233;es.
</p>
<p>2.1 &#201;tape de s&#233;lection
</p>
<p>L&#8217;&#233;tape de s&#233;lection est une it&#233;ration sur la taille d&#8217;empan (span) entre 1 et le nombre de mots
que comporte la phrase &#224; analyser, ainsi que sur la position du coin gauche de l&#8217;empan (offset),
de fa&#231;on &#224; couvrir tous les mots de la phrase. L&#8217;it&#233;ration telle que {offset, span} = {i, j} resoud
le sous-probl&#232;me dont la solution est m&#233;moris&#233;e dans pi aux coordonn&#233;ees {i, j}. La s&#233;lec-
tion S de constituants pour l&#8217;empan courant contient tous les constituants pr&#233;sents dans pi aux
coordonn&#233;es pi[i, 1], pi[i, 2], . . . , pi[i, j &#8722; 1], . . . , pi[i+ 1, 1], . . . , pi[i+ 1, j &#8722; 2], . . . , pi[end, 1].
Notons que l&#8217;it&#233;ration sur la variable span d&#233;bute avec la valeur 1 (et non 2 comme dans le</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Analyse rel&#226;ch&#233;e &#224; base de contraintes
</p>
<p>CKY original), ce qui permet de g&#233;n&#233;rer des constituants dont l&#8217;empan n&#8217;est que d&#8217;un mot (par
exemple, un GN seulement compos&#233; d&#8217;un N).
</p>
<p>2.2 &#201;tape d&#8217;&#233;numeration
</p>
<p>L&#8217;empan d&#8217;une configuration de constituants valide doit couvrir les mots entre offset et end
(empan courant). Lorsqu&#8217;on consid&#232;re une partition d&#8217;ensemblede S = [offset . . . end] chaque
sous-ensemble correspond &#224; un sous-probl&#232;me d&#233;j&#224; r&#233;solu, puisque sa cardinalit&#233; est n&#233;ces-
sairement inf&#233;rieure &#224; celle de l&#8217;empan courant. La sous-structure optimale correspondante est
donc d&#233;j&#224; m&#233;moris&#233;e dans pi et peut donc &#234;tre r&#233;cup&#233;r&#233;e. Une configuration s&#8217;obtient &#224; partir
d&#8217;une partition, en combinant ensemble toutes les sous-structures de cette partition. En calculant
toutes les partitions possible de S on s&#8217;assure donc que toutes les configurations possibles sont
parcourues pour l&#8217;empan courant. De fa&#231;on intuitive, une configuration peut &#234;tre vue comme
une structure de constituant dont le label de la racine (i.e. sa Construction) n&#8217;est pas encore
connu. Lorsque n&#233;cessaire, nous utiliserons par la suite le terme de configuration non-lab&#233;lis&#233;e.
</p>
<p>2.3 &#201;tape de caract&#233;risation
</p>
<p>Une fois les configurations &#233;num&#233;r&#233;es, chacune d&#8217;entre elles doit &#234;tre caract&#233;ris&#233;e. En GP, le
processus de caract&#233;risation permet d&#8217;associer une valeur bool&#233;enne &#224; chaque contrainte carac-
t&#233;ristique d&#8217;un constituant, selon que cette contrainte est satisfaite ou non. Ce processus de sat-
isfaction de contrainte est ici implant&#233; &#224; l&#8217;aide de l&#8217;Algorithme 2 ; une configuration joue le r&#244;le
d&#8217;une assignation de variables. Plus pr&#233;cis&#233;ment, l&#8217;assignation est faite de tous les constituants
</p>
<p>Algorithme 2 Fonction de caract&#233;risation
function characterisation(A = &#12296;c1, . . . , cn&#12297; : assignment, G : grammar)
</p>
<p>returns the set of evaluated properties relevant toA,
and the set of projected constructions forA.
</p>
<p>/&#8727; Pour m&#233;moriser le r&#233;sultat de la caract&#233;risation : &#8727;/
create and clear &#967;A [property] : table of boolean, indexed by property
</p>
<p>/&#8727; Pour m&#233;moriser les constructions projet&#233;es : &#8727;/
create and clear CA : set of construction
</p>
<p>/&#8727; Pour m&#233;moriser temporairement les propri&#233;t&#233;s (i.e. contraintes) &#224; &#233;valuer : &#8727;/
create and clear S : set of property
</p>
<p>for (mask &#8712; [1 . . . 2n &#8722; 1])
key&#8592; applyBinaryMask(A,mask)
if (key is in the set of indexes for G) then
</p>
<p>/&#8727; Les propri&#233;t&#233;s sont r&#233;cup&#233;r&#233;es depuis la grammaire, puis &#233;valu&#233;es &#8727;/
S &#8592; G[key].getProperties()
&#967;A &#8592; evaluate(S)
</p>
<p>/&#8727; Etape de projection : r&#233;cup&#233;ration des constructions &#224; projeter &#8727;/
CA &#8592; G[key].getDominantConstructions()
</p>
<p>return &#967;A , CA
</p>
<p>La clef key d&#233;termin&#233;e par applyBinaryMask est une combinaison de constructions (i.e. ces constructions de A pour lesquelles le bit
correspondant dans le masque mask est positionn&#233; &#224; 1) ; elle est utilis&#233;e, apr&#232;s application d&#8217;une fonction de hashage, comme un index, pour
acc&#233;der aux contraintes de la grammaire qui concernent cette combinaison.
</p>
<p>imm&#233;diats de la configuration non-lab&#233;lis&#233;e courante. L&#8217;&#233;tape de Projection dans l&#8217;Algorithme</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>J-Ph. Prost
</p>
<p>1 est pr&#233;sent&#233;e s&#233;par&#233;ment de celle de Caract&#233;risation &#224; des fins de clart&#233; ; ces deux &#233;tapes sont
en fait implant&#233;es au sein d&#8217;une m&#234;me fonction afin d&#8217;&#233;conomiser des it&#233;rations.
</p>
<p>La caract&#233;risation est un processus de satisfaction rel&#226;ch&#233;e. Les contraintes de la grammaire
(G) sont l&#226;chement satisfaites (loosely satisfied) pour une assignation A en ce sens qu&#8217;elle peu-
vent &#234;tre satisfaites ou viol&#233;es. Notons que A ne constitue pas n&#233;cessairement une assignation
pour l&#8217;ensemble des contraintes de G. Certaines contraintes peuvent contenir des variables pour
lesquelles A n&#8217;assigne aucun constituant. Ces derni&#232;res sont consid&#233;r&#233;es comme &#233;tant triviale-
ment satisfaites et sont donc ignor&#233;es. Pour des raisons d&#8217;efficacit&#233; le processus fait appel &#224;
une table d&#8217;indexation des contraintes, qui a &#233;t&#233; cr&#233;&#233;e lors de l&#8217;initialisation de l&#8217;analyseur.
Chaque contrainte de G figure dans la table, index&#233;e par une clef (hash-code). Le d&#233;tail de cette
clef, ainsi que de la table d&#8217;indexation, ne sont pas l&#8217;objet de cet article. Bri&#232;vement, l&#8217;id&#233;e est
d&#8217;utiliser une configuration de constituants (A), d&#8217;en extraire la combinaison de constructions
correspondante, et d&#8217;utiliser cette combinaison comme une clef d&#8217;acc&#232;s pour isoler toutes les
contraintes dont les variables sont compatibles avec les constructions de la combinaison. Par
exemple, la combinaison (D,N) form&#233;e d&#8217;un D&#233;terminant et d&#8217;un Nom permet d&#8217;acc&#233;der aux
contraintes D &#8826; N et N &#8658; D (entre autres).
Bien qu&#8217;en apparence nombre de contraintes semblent &#234;tre r&#233;&#233;valu&#233;es pour les m&#234;mes construc-
tions, ces r&#233;&#233;valuations ne sont en fait redondantes que dans le cas des contraintes monotones
(Lin&#233;arit&#233; et D&#233;pendance). Pour tous les autres types, le fait que chaque nouvelle configura-
tion corresponde &#224; une assignation diff&#233;rente signifie que les contraintes peuvent &#234;tre &#233;valu&#233;es
diff&#233;rement sous chaque assignation, d&#8217;o&#249; le besoin d&#8217;une r&#233;&#233;valuation.
</p>
<p>2.4 &#201;tape de projection
</p>
<p>Conceptuellement, l&#8217;&#233;tape de projection consiste &#224; porter un jugement quant &#224; la Construction
d&#8217;un constituant. Le probl&#232;me est celui de la cat&#233;gorisation d&#8217;une configuration non-lab&#233;lis&#233;e
au sein d&#8217;une construction, en fonction de la caract&#233;risation de cette configuration. De fa&#231;on pra-
tique, il s&#8217;agit de lab&#233;liser des configurations non-lab&#233;lis&#233;es. Une grammaire en GP est g&#233;n&#233;rale-
ment pr&#233;sent&#233;e comme une collection de constructions, chacune d&#8217;entre elles &#233;tant sp&#233;cifi&#233;e &#224;
l&#8217;aide d&#8217;un ensemble de contraintes. L&#8217;op&#233;ration qui doit maintenant &#234;tre effectu&#233;e n&#233;cessite
d&#8217;inverser l&#8217;information, en ce sens que la connaissance d&#8217;un ensemble de contrainte doit per-
mettre de d&#233;terminer quelles constructions peuvent &#234;tre projet&#233;es. Une table d&#8217;indexation est
cr&#233;&#233;e &#224; cet effet lors de l&#8217;initialisation de l&#8217;analyseur, qui permet un acc&#232;s direct aux construc-
tions concern&#233;es en utilisant une contrainte comme clef d&#8217;acc&#232;s. Cette partie du processus est
en fait implant&#233;e au sein de la fonction de caract&#233;risation (Algorithme 2).
</p>
<p>2.5 &#201;tape de m&#233;moisation
</p>
<p>L&#8217;&#233;tape de m&#233;moisation vise &#224; la fois &#224; m&#233;moriser et optimiser les sous-structures : elle m&#233;-
morise donc le constituant optimal (i.e. dont le score de m&#233;rite est maximal) pour chaque con-
struction possible, pour une cellule donn&#233;e de la TPD. La fonction de m&#233;rite utilis&#233;e pour l&#8217;op-
timalit&#233; de la structure est la proportion de contraintes satisfaites, par rapport au nombre total
de contraintes satisfaites ou viol&#233;es. Notons que l&#8217;optimalit&#233; ne garantit pas l&#8217;unicit&#233; de la so-
lution : il est possible d&#8217;obtenir plusieurs analyses distinctes mais de scores identiques pour
un m&#234;me &#233;nonc&#233;. Ce sera typiquement le cas en pr&#233;sence d&#8217;une ambigu&#239;t&#233; linguistique, telle</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Analyse rel&#226;ch&#233;e &#224; base de contraintes
</p>
<p>que dans &#8220;*le chats&#8221;. Le but du LSCP n&#8217;&#233;tant pas de r&#233;gler ces cas ambigus, l&#8217;algorithme a &#233;t&#233;
implant&#233; de fa&#231;on &#224; fournir toutes les solutions &#233;quivalentes possibles.
</p>
<p>Dans le cas o&#249; la cellule courante dans la TPD ne pourrait pas se voir affecter au moins un
constituant, une for&#234;t d&#8217;arbres partiels lui est attribu&#233;e &#224; la place. Cette for&#234;t pr&#233;f&#233;r&#233;e est con-
struite au fur et &#224; mesure de l&#8217;&#233;num&#233;ration des configurations possibles (au sein de la fonction
buildConfigurations, lors de l&#8217;&#233;tape d&#8217;&#233;numeration). La pr&#233;f&#233;rence s&#8217;&#233;tablit selon l&#8217;or-
dre suivant :
&#8211; les constituants avec l&#8217;empan le plus large ;
&#8211; les for&#234;ts avec le plus faible nombre de constituants.
Cette pr&#233;f&#233;rence se traduit par une heuristique num&#233;rique, par le biais d&#8217;un score de pr&#233;f&#233;rence.
Ce score est calcul&#233; de la fa&#231;on suivante (o&#249; F d&#233;note la for&#234;t, Ci ses constituants, merit(Ci)
le m&#233;rite de chacun de ses constituants, span la taille de l&#8217;empan, et pF le score de pr&#233;f&#233;rence as-
soci&#233; &#224; F ) : pF = span &#183;(merit(Ci)+span). pF est une sorte de &quot;score de la derni&#232;re chance&quot; :
lorsque le processus d&#8217;analyse ne parvient pas &#224; trouver une construction dominante pour un en-
semble de constituants, les diff&#233;rentes configurations de ces constituants entrent en comp&#233;tition
afin que l&#8217;une d&#8217;entre elles soit choisie comme structure par d&#233;faut (pour l&#8217;empan concern&#233;).
Le vainqueur est la configuration avec le meilleur score de pr&#233;f&#233;rence. Notons que dans le
pire des cas, lorsque la TPD est enti&#232;rement peupl&#233;e de sous-structures par d&#233;faut, le r&#233;sultat
final est alors une s&#233;quence d&#8217;&#233;l&#233;ments du discours (Part-of-Speech). De cette fa&#231;on, l&#8217;algo-
rithme LSCP fournit toujours une analyse, quelle que soit la phrase en entr&#233;e. Bien &#233;videment,
puisque l&#8217;heuristique pF n&#8217;est que l&#8217;une des possibilit&#233;s de calculer une telle pr&#233;f&#233;rence parmi
de nombreuses autres possibilit&#233;s, il serait int&#233;ressant d&#8217;explorer dans plus de d&#233;tail laquelle
de ces possibilit&#233;s permet les meilleurs r&#233;sultats. La question, cependant, de savoir en quoi une
for&#234;t d&#8217;analyses partielles est meilleure qu&#8217;une autre n&#8217;est pas sans poser des probl&#232;mes, et sort
du champ d&#8217;investigation de cet article. Il serait probablement utile de m&#233;moiser &#233;galement
d&#8217;autres informations, telles que les partitions d&#8217;ensembles, ou les contraintes monotones. Ces
derni&#232;res, en particulier, pourraient &#234;tre m&#233;mois&#233;es en s&#8217;inspirant des techniques de compila-
tion de contraintes mises en &#339;uvre dans le SeedParser de (VanRullen, 2005). Cette option reste
cependant &#224; explorer.
</p>
<p>3 &#201;valuation
</p>
<p>La question de l&#8217;&#233;valuation est d&#233;licate : le but de l&#8217;analyseur LSCP (dont l&#8217;implantation est bap-
tis&#233;e Numbat) &#233;tant de fournir une structure hi&#233;rarchique de constituants, tant pour les phrases
bien form&#233;es que celles mal form&#233;es, il est difficile de d&#233;terminer avec certitude quelle doit
&#234;tre la structure de r&#233;f&#233;rence attendue. L&#8217;id&#233;al serait de disposer d&#8217;un corpus de phrases gram-
maticales et agrammaticales, chacune &#233;tant annot&#233;e avec une unique structure de constituants
(ou &#233;ventuellement une s&#233;rie d&#8217;alternatives). Un tel Gold Standard n&#8217;est, &#224; notre connaissance,
malheureusement pas disponible. Pour pallier ce probl&#232;me nous avons men&#233; deux &#233;valuations
distinctes, qui visent &#224; mesurer les performances de Numbat sur des phrases grammaticales
pour l&#8217;une, et sur des phrases agrammaticales pour l&#8217;autre. Chacune de ces deux &#233;valuations
pr&#233;sente ses faiblesses. L&#8217;&#201;valuation 1 s&#8217;effectue uniquement sur un analyse partielle des &#233;non-
c&#233;s, et ne mesure donc pas l&#8217;aptitude &#224; produire une structure hi&#233;rarchique unique, c&#8217;est-&#224;-dire
en constituants imbriqu&#233;s (contrairement &#224; une for&#234;t). L&#8217;&#233;valuation 2, pour sa part, mesure bien
cette aptitude (une structure est dite compl&#232;te pour une phrase lorsqu&#8217;elle est constitu&#233;e d&#8217;un
constituant dominant unique), mais souffre d&#8217;une absence de mesure de r&#233;f&#233;rence.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>J-Ph. Prost
</p>
<p>L&#8217;&#201;valuation 1, dont les r&#233;sultats sont rapport&#233;s dans la Table 1, mesure les performances de
l&#8217;analyseur3 pour la bonne formation. Cette premi&#232;re &#233;valuation a &#233;t&#233; effectu&#233;e selon le proto-
</p>
<p>Pr&#233;cision Rappel F-mesure
Total 0.7835 0.7057 0.7416
general_lemonde 0.8187 0.7515 0.7837
general_mlcc 0.7175 0.6366 0.6746
general_senat 0.8647 0.7069 0.7779
litteraire 0.8124 0.7651 0.788
mail 0.7193 0.6951 0.707
medical 0.8573 0.678 0.757
oral_delic 0.6817 0.621 0.649
questions_amaryllis 0.8081 0.7432 0.7743
questions_trec 0.8208 0.7069 0.7596
</p>
<p>TAB. 1 &#8211; &#201;valuation 1 de Numbat, selon le protocole EASY
</p>
<p>cole &#233;labor&#233; pour la campagne EASY d&#8217;&#201;valuation d&#8217;Analyseurs SYntaxiques (Paroubek et al.,
2003), sur une partie du corpus utilis&#233; lors de cette m&#234;me campagne. &#192; titre de comparaison,
la Table 2 rapporte les performances mesur&#233;es dans les m&#234;mes conditions pour deux autres
analyseurs que Numbat : l&#8217;un superficiel (VanRullen, 2005), &#233;galement bas&#233; sur le formalisme
des GP, et l&#8217;autre stochastique (VanRullen et al., 2006). L&#8217;&#201;valuation 2, dont les r&#233;sultats sont
</p>
<p>Pr&#233;cision Rappel F-mesure
Analyseur superficiel 0.7846 0.8376 0.8102
Analyseur stochastique 0.9013 0.8978 0.8995
</p>
<p>TAB. 2 &#8211; &#201;valuation d&#8217;un analyseur superficiel et d&#8217;un analyseur stochastique selon le protocole EASY
</p>
<p>rapport&#233;s dans la Table 3, mesure les performances de Numbat pour l&#8217;agrammaticalit&#233;. Pour
cette &#233;valuation nous avons demand&#233; &#224; cinq annotateurs experts, tous linguistes, de d&#233;cider si
la structure syntaxique fournie par Numbat pour chaque phrase agrammaticale &#233;tait correcte ou
non. Pour d&#233;cider, les annotateurs devaient d&#233;terminer si la solution de Numbat &#233;tait un arbre
syntaxique possible et acceptable pour la phrase. Des instructions sp&#233;cifiques &#233;taient fournies
pour que le jugement ne porte pas sur l&#8217;acceptabilit&#233; grammaticale de la phrase support, mais
bien sur l&#8217;arbre qui lui &#233;tait associ&#233;. Le corpus utilis&#233; est celui construit artificiellement par
(Blache et al., 2006), qui est constitu&#233; &#224; 94% de phrases pr&#233;sentant des irr&#233;gularit&#233;s gram-
maticales. Pour les besoins de cette &#233;valuation les mesures de Pr&#233;cision et Rappel ont d&#251; &#234;tre
modifi&#233;es. Le nombre total de phrases en entr&#233;e est interpr&#233;t&#233; comme le nombre de pr&#233;dictions,
le nombre de structures compl&#232;tes est interpr&#233;t&#233; comme le nombre d&#8217;observations, et le nombre
de structures ayant fait l&#8217;objet d&#8217;un jugement humain CORRECT est interpr&#233;t&#233; comme le nombre
de solutions correctes. Nous obtenons ainsi les formulations suivantes :
</p>
<p>pr&#233;cision = CORRECT/COMPLET
rappel = CORRECT/total
</p>
<p>F = 2 &#183; pr&#233;cision &#183; rappel/(pr&#233;cision + rappel) ' 0.71
3La grammaire utilis&#233;e pour cette &#233;valuation est celle de (VanRullen, 2005), tandis que l&#8217;&#201;valuation 2 utilise
</p>
<p>une grammaire propre, bas&#233;e sur la pr&#233;c&#233;dente. La diff&#233;rence entre ces deux grammaires tient essentiellement dans
la profondeur des constituants d&#233;crits.
</p>
<p>Nb. total Nb. structures Nb. structures Pr&#233;cision = Rappel =
annotat&#233; correctes compl&#232;tes Correct
</p>
<p>Complet
Correct
Total
</p>
<p>469 694 632 0.74 0.68
</p>
<p>TAB. 3 &#8211; &#201;valuation 2 de Numbat pour des phrases agrammaticales</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Analyse rel&#226;ch&#233;e &#224; base de contraintes
</p>
<p>L&#8217;&#233;valuation 1 montre que la pr&#233;cision obtenue par Numbat est du m&#234;me ordre que celle obtenue
par l&#8217;analyseur superficiel, pour un rappel sensiblement plus faible. Ce r&#233;sultat est globalement
positif, compte-tenu de ce que l&#8217;analyseur LSCP n&#8217;est initialement pas con&#231;u pour g&#233;n&#233;rer des
structures superficielles telles que celles attendues par le protocole EASY. L&#8217;analyse attendue
pour une phrase n&#8217;est, en effet, pas un constituant unique couvrant toute la phrase, mais une suc-
cesion de constituants multiples couvrants chacun une partie seulement de la phrase, tels que
GN, GV, GP, etc. De ce fait, l&#8217;analyse g&#233;n&#233;r&#233;e par Numbat repose en grande partie sur l&#8217;heuris-
tique de pr&#233;f&#233;rence d&#233;crite ci-dessus, qui permet de produire une for&#234;t d&#8217;arbres partiels. Cette
heuristique n&#8217;est cependant pas con&#231;ue &#224; cette fin, mais simplement pour fournir une analyse
par d&#233;faut en l&#8217;absence d&#8217;une solution englobante. Les r&#233;sultats de l&#8217;&#233;valuation 1 montrent donc
&#224; la fois que cette heuristique pourrait &#234;tre am&#233;lior&#233;e, mais &#233;galement que l&#8217;analyseur LSCP est
suffisament flexible pour s&#8217;adapter &#224; diff&#233;rentes granularit&#233;s d&#8217;analyse.
</p>
<p>L&#8217;&#233;valuation 2 donne, pour sa part, des indications encourageantes quant &#224; la possibilit&#233; de
g&#233;n&#233;rer une analyse compl&#232;te pour une phrase agrammaticale, puisque 92% des phrases du cor-
pus sont analys&#233;s par une structure de constituant compl&#232;te. La mesure de Pr&#233;cision indique que
74% de ces analyses compl&#232;tes sont &#233;valu&#233;s comme &#233;tant syntactiquement correctes, tandis que
le Rappel indique que les analyses correctes repr&#233;sentent 68% du corpus. Compar&#233;s aux scores
obtenus sur les phrases grammaticales (pr&#233;cision/rappel/F-mesure = 0.78/0.71/0.74), et sachant
que la quasi-totalit&#233; du corpus est constitu&#233; de phrases agrammaticales (94%), les scores de
l&#8217;&#233;valuation 2 mettent en &#233;vidence la bonne performance de Numbat face aux &#233;nonc&#233;s agram-
maticaux, par rapport aux objectifs fix&#233;s d&#8217;analyse compl&#232;te.
</p>
<p>4 Conclusion
</p>
<p>Dans cet article nous avons abord&#233; le probl&#232;me de l&#8217;analyse syntaxique automatique du langage
tant grammatical qu&#8217;agrammatical. Parmi les nombreuses questions que ce probl&#232;me soul&#232;ve,
nous nous sommes plus particuli&#232;rement pench&#233;s sur celles de la repr&#233;sentation d&#8217;une structure
syntaxique d&#8217;un tel &#233;nonc&#233;, et celle de sa grammaticalit&#233;. Nous avons vu que la notion m&#234;me de
grammaticalit&#233; d&#8217;un &#233;nonc&#233; se d&#233;cline sous diff&#233;rentes formes, selon la th&#233;orie syntaxique sous-
jacente. D&#232;s lors qu&#8217;on souhaite fournir une analyse syntaxique pour un &#233;nonc&#233; quelconque,
tout en conservant la possibilit&#233; de conclure sur son caract&#232;re grammatical ou agrammatical,
un cadre de syntaxe mod&#232;le-th&#233;orique s&#8217;impose pour la repr&#233;sentation de cette analyse. Dans
un tel cadre, une analyse syntaxique de l&#8217;&#233;nonc&#233; est un mod&#232;le (au sens de la th&#233;orie des mod-
&#232;les) pour la grammaire. En mati&#232;re de traitement, se posent alors les questions de la g&#233;n&#233;ration
d&#8217;un tel mod&#232;le d&#8217;une part, et celle du choix de la meilleure solution parmi un ensemble de
candidats d&#8217;autre part. Nous r&#233;pondons &#224; ces deux questions en proposant une solution algo-
rithmique qui g&#233;n&#232;re l&#8217;analyse syntaxique optimale pour un &#233;nonc&#233; quelconque, sur la seule
base d&#8217;une grammaire mod&#232;le-th&#233;orique de bonne formation. Cette analyse est optimale en ce
sens qu&#8217;elle maximise la proportion de contraintes grammaticales satisfaites. L&#8217;algorithme que
nous pr&#233;sentons (LSCP) fait appel &#224; un processus de satisfaction rel&#226;ch&#233;e de contraintes, ainsi
qu&#8217;&#224; des techniques de programmation dynamique. La satisfaction rel&#226;ch&#233;e est un m&#233;canisme
par lequel un mod&#232;le l&#233;gitime pour un &#233;nonc&#233; peut &#224; la fois satisfaire une partie de la gram-
maire et en violer une autre. L&#8217;&#233;valuation de cet analyseur montre que ses performances sur des
&#233;nonc&#233;s grammaticaux sont comparables &#224; celles d&#8217;analyseurs traditionnels. Les performances
obtenues sur des &#233;nonc&#233;s agrammaticaux montrent, elles, que les structures de constituants op-
timales propos&#233;es comme solutions sont jug&#233;es acceptables dans une tr&#232;s large mesure selon</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>J-Ph. Prost
</p>
<p>des crit&#232;res humains.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BENDER E. M., FLICKINGER D., OEPEN S., WALSH A. &amp; BALDWIN T. (2004). Ar-
boretum : Using a precision grammar for grammar checking in CALL. In Proc. of In-
STIL/ICALL2004, volume 17.
</p>
<p>BLACHE P. (2005). Property Grammars : A Fully Constraint-based Theory. In Constraint
Solving and Language Processing, volume 3438 of LNAI. Springer.
</p>
<p>BLACHE P., HEMFORTH B. &amp; RAUZY S. (2006). Acceptability prediction by means of gram-
maticality quantification. In Proc. of CoLing/ACL 2006, p. 57&#8211;64 : ACL.
</p>
<p>DAHL V. &amp; BLACHE P. (2004). Directly Executable Constraint Based Grammars. In Actes
de JPFLC&#8217;2004, p. 149&#8211;166.
</p>
<p>FOSTER J. (2007). Real bad grammar : Realistic grammatical description with grammaticality.
Corpus Linguistics and Lingustic Theory, 3(1), 73&#8211;86.
KELLER F. (2000). Gradience in Grammar - Experimental and Computational Aspects of
Degrees of Grammaticality. PhD thesis, University of Edinburgh.
</p>
<p>MARUYAMA H. (1990). Structural Disambiguation with Constraint Propagation. In Proc. of
ACL 1990, p. 31&#8211;38.
</p>
<p>MEURERS W. D. (2007). Advancing linguistics between the extremes : Some thoughts on
geoffrey sampson&#8217;s Grammar without Grammaticality. Corpus Linguistics and Linguistic
Theory, 3(1).
MORAWIETZ F. &amp; BLACHE P. (2002). Parsing Natural Languages with CHR.
</p>
<p>PAROUBEK P., ROBBA I. &amp; VILNAT A. (2003). EASY : An Evaluation Protocol for Syntactic
Parsers. http ://www.limsi.fr/RS2005/chm/lir/lir11/. (as of August 2008).
</p>
<p>POLLARD C. &amp; SAG I. (1994). Head-driven Phrase Structure Grammars. CSLI, Chicago
University Press.
</p>
<p>PRINCE A. &amp; SMOLENSKY P. (1993). Optimality Theory : Constraint Interaction in Gener-
atire Grammar. Rapport interne, TR-2, Rutgers University.
</p>
<p>PULLUM G. &amp; SCHOLZ B. (2001). On the Distinction Between Model-Theoretic and
Generative-Enumerative Syntactic Frameworks. In Proc. of LACL&#8217;2001, number 2099 in
LNAI, p. 17&#8211;43 : Springer Verlag.
</p>
<p>PULLUM G. K. (2007). The Evolution of Model-Theoretic Frameworks in Linguistics. In
Proc. of MTS@10, p. 1&#8211;10.
</p>
<p>VANRULLEN T. (2005). Vers une analyse syntaxique &#224; granularit&#233; variable. PhD thesis,
Universit&#233; de Provence.
</p>
<p>VANRULLEN T., BLACHE P. &amp; BALFOURIER J.-M. (2006). Constraint-Based Parsing as an
Efficient Solution : Results from the Parsing Evaluation Campaign EASy. In Proc. of LREC
2006, p. 165&#8211;170.</p>

</div></div>
</body></html>