TALN 2009 — Session posters , Senlis, 24-26 juin 2009

Analyse relachée a base de contraintes

J ean-Philippe Prost*
LIFO, Universite d’Orléans

JPProst@gmail.com

Resume. La question de la grammaticalite, et celle duale de l’agraInmaticalite, sont des
sujets delicats a aborder, des lors que l’on souhaite integrer differents degres, tant de graInmat-
icalite que d’agraInmaticalite. En termes d’analyse automatique, les problemes poses sont de
l’ordre de la representation des connaissances, du traitement, et bien evidement de l’evaluation.
Dans cet article, nous nous concentrons sur l’aspect traitement, et nous nous penchons sur la
question de l’analyse d’enonces agrammaticaux. Nous explorons la possibilite de fournir une
analyse la plus complete possible pour un enonce agrammatical, sans l’apport d’information
complementaire telle que par le biais de mal-regles ou autre grammaire d’erreurs. Nous pro-
posons une solution algorithmique qui permet l’analyse automatique d’un enonce agraIr1mati-
cal, sur la seule base d’une grammaire modele-theorique de bonne formation. Cet analyseur est
prouve generer une solution optimale, selon un critere numerique maxiIr1ise.

Abstract. The question of grammaticality, and the dual one of ungrammaticality, are top-
ics delicate to address when interested in modeling different degrees, whether of grammaticality
or ungrammaticality. As far as parsing is concerned, the problems are with regard to knowledge
representation, processing, and obviously evaluation. In this paper, we concentrate on the pro-
cessing aspect and we address the question of parsing ungrammatical utterances. We explore
the possibility to provide a full parse for an ungrammatical utterance without relying on any
kind of additional information, which would be provided by mal-rules or other error grammar.
We propose an algorithmic solution in order to parse an ungrammatical utterance using only
a model-theoretic grammar of well-formedness. The parser is proven to generate an optimal
solution, according to a maximised criterion.

M0tS-CléS I grammaticalite, analyse syntaxique, contraintes, syntaxe modele-theorique.

Keywords: grammaticality, syntactic parsing, constraints, Model-Theoretic Syntax.

1 Introduction

La notion meme de grammaticalite est suj ette a differentes interpretations, selon le cadre theori-
que auquel elle s’applique. Ainsi, il est possible de degager trois grandes interpretations aux dif-
ferences notables, qui s’app1iquent a des cadres formels differents. Au sens generatif du terme,
la grammaticalite est une notion strictement binaire selon laquelle une phrase est soit graInmat-
icale, soit agrammaticale. Cette notion generative est etroitement liee au processus d’analyse
et a l’existence ou non d’un arbre syntaxique pour cette phrase : une phrase est grammaticale

Ces travaux ont ete menes conjointement au CLT a Macquarie University, Sydney, Australie, et au LPL a
l’Universite de Provence.

J -Ph. Prost

si et seulement si il est possible d’en generer une analyse a l’aide d’une grammaire donnee.
L’ objet theorique de la Syntaxe Generative-Enumerativel (GES) ne concerne que l’exp1ication
des phenomenes linguistiques qui relevent de la grammaticalite, et ne permet pas d’expliquer
des phenomenes atypiques, tels que l’ouverture lexicale (apparition permanente de nouveaux
termes), les fragments bien-formes (e.g. “Il me semble que...”, “Oui, mais alors je...”, etc..),
l’agraInmaticalite, ou encore la grammaticalite graduelle (i.e. gradience) (Pullum & Scholz,
2001).

Au sens de la Theorie de l’Optimalite (OT) (Prince & Smolensky, 1993), la grammaticalite
s’applique cette fois non pas a une phrase, mais a une structure : par deﬁnition, une structure
candidate pour une phrase est grammaticale si et seulement si cette structure est optimale parmi
l’ensemble des candidats. Des lors, toute phrase pour laquelle la fonction GEN genere au moins
une structure candidate est necessairement grammaticale au sens d’OT. Cependant, l’objet d’OT
n’est pas de decrire les mecanismes de generation de structures syntaxiques (la fonction GEN
est donnee), mais bien de permettre d’expliquer pourquoi une structure donnee est optimale
aux yeux d’une grammaire donnee. En ce sens, la couverture d’OT en termes de phenomenes
linguistiques est donc theoriquement plus etendue que celle de la GES. En revanche, la notion de
grammaticalite qu’elle introduit peut poser probleme, puisqu’elle ne permet pas de distinguer la
bonne-formation de la mal-formation, et donc la grammaticalite de l’agraInmaticalite. Ceci est
lie au fait que la violation de contraintes grammaticales n’est pas necessairement signiﬁcative
d’agraInmaticalite, ne serait-ce que partielle. Tout au plus, les differentes structures candidates
associees a un enonce peuvent étre ordonnees en fonction de leur acceptabilite grammaticale,
comme le permet la Theorie Lineaire de l’Optimalite (Keller, 2000). Si la necessite de pouvoir
clairement distinguer grammaticalite et agrammaticalite au sein d’une theorie linguistique est
certes discutable (Meurers, 2007), il est des contextes applicatifs, comme l’apprentissage d’une
langue ou la correction grammaticale, ou une telle distinction s’impose.

Au sens de la Syntaxe Modele-Theorique (MTS) (Pullum, 2007), la grammaticalite d’un enonce
est deﬁnie par la consistance d’un modele pour cet enonce, c’est-a-dire la satisfaction par ce
modele des contraintes grammaticales. La difference fondamentale d’avec la syntaxe genera-
tive vient de ce que le role de la grammaire n’est plus de generer mais de valider des structures
linguistiques. Une grammaire MTS est alors un ensemble de contraintes non-ordonnees, qui
peuvent etre evaluees independament les unes des autres. Cette propriete facilite egalement, en
theorie, la relaxation de certaines contraintes, ce qui permet d’integrer des degres de graInmat-
icalite et d’agraInmaticalite, selon des modalites a deﬁnir. Les cadres formels pour la MTS les
plus communs sont HPSG (Pollard & Sag, 1994), ou la faInille des formalismes bases sur les
grammaires de dependances par contraintes (Maruyama, 1990).

Au-dela des possibilites offertes par tel ou tel cadre en matiere d’analyse robuste, la question
generale que nous posons est celle, double, de la representation des proprietes syntaxiques d’un
enonce agrammatical, et de l’estimation de son degre de grammaticalite. Peut-on analyser les
proprietes syntaxiques d’un enonce agrammatical, en ne disposant que d’une grammaire de
bonne-formationz ? L’ aspect du probleme qu’il est important de souligner concerne la nature de
l’information syntaxique dont on dispose au sujet d’un enonce, qu’il soit grammatical ou non.
Cette information doit d’une part nous permettre de conclure quant a la grammaticalite d’un

1Le tenne GeneratiVe—EnumeratiVe Syntax a ete introduit dans (Pullum & Scholz, 2001).

2Nous faisons reference ici a bon nombre de travaux en analyse syntaxique robuste, qui font appel, en plus d’une
grammaire de bonne-formation, a un complement de regles de mal—fonnation (Bender et al., 2004; Foster, 2007).
Outre leur efﬁcacite pratique, le probleme de ces approches est qu’elles ne proposent pas de solution generale pour
expliquer des phenomenes qui ne seraient pas couverts par les grammaires de bonne— et ma1—fonnation.

Analyse relachée a base de contraintes

énoncé, et d’autre part de permettre l’estimation de son degré d’(a)grammaticalité. Dans cet
article nous nous concentrons uniquement sur l’aspect analytique et n’abordons pas la question
de la gradation. Nous formulons l’hypothese selon laquelle, dans un cadre de syntaxe modele-
théorique, un modele (i. e. une structure syntaxique) qui optimise le nombre de contraintes sat-
isfaites par rapport au nombre de contraintes violées peut constituer une analyse complete plau-
sible pour une phrase agrammaticale. Aﬁn de tester cette hypothese nous avons développé un
algorithme d’analyse syntaxique pour le cadre modele-théorique des Grammaires de Propriétés
(GP) (Blache, 2005) qui génere la structure de constituant de mérite maximum pour une phrase
donnée, qu’elle soit grammaticale ou non. Notre analyseur differe des analyseurs existants pour
les GP (Morawietz & Blache, 2002; Dahl & Blache, 2004; VanRullen, 2005) principalement
de par l’optimalité de la solution proposée. Apres avoir introduit et detaillé cet algorithme nous
présentons les résultats de l’évaluation faite de son implantation.

2 Algorithme

Cet article introduit un algorithme d’analyse tabulaire par satisfaction relachée (Loose Satis-
faction Chart Parsing, LSCP), décrit par l’Algorithme 1. L’ analyseur LSCP est basé sur l’al-
gorithme d’analyse tabulaire probabiliste de Cocke-Kasami-Younger (CKY). Il utilise le meme

Algorithme 1 Analyse tabulaire a base de satisfaction relachée (Loose Satisfaction Chart Parsing)

/* Initialisation */
Create and clear the chart 1r : every score in 1r set to 0

/* Cas de base : peupler 1r avec des POS-tags pour chaque mot */
fori <— 1 to num_words

for (each POS-construction T of w,-)
ifmerit(T) Z 7r[i,1,T] then
Create constituent 11117", whose construction is T
«[z;1,T1 - {w$!merit(w$)}

/* Cas récursif */

/* Etape 1 : SELECTION de l’empan courant de référence */

for span <— 1 to num_words

for ojfset <— 1 to num_words — span + 1

end <— oﬂset + span — 1

K <— (Z)

/* Etape 2 : ENUMERATION de toutes les conﬁgurations */

for (every set partition '13 in [oﬂset, . . . , end])

Kp <— buildConfigurations(’P)

K <_ K O Kp

/* Etape 3 : CARACTERISATION du systeme de contraintes de la grammaire */
for (every conﬁguration A E K p)

XA <— characterisation(.A)

/* Etape 4 : PROJECTION de constructions */

/* CA est un ensemble de constituants candidats. */
CA <— projection(xA)

checkpoint (CA)

/* Etape 5 : MEMOISATION du constituant candidat optimal */

for (every candidate constituent :1: E C A, of construction 0)

if merit(a:) Z 7r[oﬂset, span, 0] then
7r[oﬂset, span, 0] <— {a:, merit(a:)}
if 7r[0ﬂset, span] = (3 then
1r[oﬂset, span] <— preferred forest in K

squelette que le CKY, sur lequel vient se greffer un processus de satisfaction reldchée de con-
traintes, décrit plus bas. Le terme de tabulaire fait reference a l’utilisation d’une table de pro-
grammation dynamique. L’ algorithme LSCP differe cependant du CKY sur différents points.

J -Ph. Prost

N3 V9

  

* P7 P 10
octioie AQS P11K\12
I I I

4 entretien 5 D 13 14

I I
bref cc plaignant

FIG. 1 — Exemple d’analyse générée par l’analyseur LSCP pour une phrase agrammaticale.

Alors que le CKY nécessite une grammaire en Forme Normale de Chomsky (CNF), le LSCP
prend une grammaire de propriétés ordinaire, aucun équivalent de la CNF n’eXistant pour le
formalisme des GP. La consequence directe en est la génération de structures arborescentes n-
aires, et non d’arbres binaires. Une autre difference tient dans l’utilisation de valeurs de mérite
des constituants en lieu et places des probabilités. C’est sur la base de cette valeur de mérite
a maximiser que l’analyseur optimise le choix de la solution. La Figure 1 illustre un exemple
d’analyse générée par l’analyseur LSCP pour une phrase agrammaticale.

L’ algorithme LSCP, comme le CKY, repose sur une technique de programmation dynamique.
Ainsi, la recherche d’une solution générale optimale se décompose en sous-problemes pour cha-
cun desquels l’analyseur trouve une solution optimale. Ces solutions partielles intermédiaires
sont dites sous-structures optimales. Dans notre cas, le principe fondamental qui s’applique
est qu’une solution optimale n’est nécessairement composée que de sous-constituants qui tous
optimisent la solution globale. En supposant que la fonction de mérite présente les propriétés
adéquates quanta l’optimalité, il est aisé de montrer, par l’absurde, que s’il existe une solution
de mérite optimal, et si l’un de ses sous-constituants n’optimise pas ce mérite, alors il existe
nécessairement un autre sous-constituant qui, lorsqu’il est substitué au constituant sous-optimal,
conduit a une solution de meilleur mérite, ce qui contredit l’hypothese. Ces sous-structures op-
timales sont mémorisées dans une table de programmation dynamique (TPD), par un processus
de mémoisation. La programmation dynamique permet également d’optimiser le processus en
évitant les ré-itérations redondantes du méme sous-probleme. La TPD qu’utilise LSCP prend
pour coordonnées les mots de la phrase a analyser comme abscisse, et les tailles d’empans
analysés en ordonnées.

2.1 Etape de sélection

L’ étape de sélection est une iteration sur la taille d’empan (span) entre 1 et le nombre de mots
que comporte la phrase a analyser, ainsi que sur la position du coin gauche de l’empan (oﬁset),
de fagon a couvrir tous les mots de la phrase. L’itération telle que {0ﬁ°set, span} = {i, j} resoud
le sous-probleme dont la solution est mémorisée dans 7r aux coordonnéees {i, j La selec-
tion 8 de constituants pour l’empan courant contient tous les constituants présents dans 7r aux
coordonnées 7r[z', 1],7r[i, 2], . . . ,7r[i,j — 1], . . . ,7r[i + 1,1],...,7r[i+ 1,j — 2], . . . ,7r[end, 1].

Notons que l’itération sur la variable span débute avec la valeur 1 (et non 2 come dans le

Analyse relachée a base de contraintes

CKY original), ce qui permet de générer des constituants dont l’empan n’est que d’un mot (par
exemple, un GN seulement composé d’un N).

2.2 Etape d’énumeration

L’ empan d’une conﬁguration de constituants valide doit couvrir les mots entre oﬁset et end
(empan courant). Lorsqu’on considere une partition d’ensemblede S = [oﬁ°set. . .end] chaque
sous-ensemble correspond a un sous-probleme déja résolu, puisque sa cardinalité est néces-
sairement inférieure a celle de l’empan courant. La sous-structure optimale correspondante est
donc déja mémorisée dans 7r et peut donc étre récupérée. Une conﬁguration s’obtient a partir
d’une partition, en combinant ensemble toutes les sous-structures de cette partition. En calculant
toutes les partitions possible de S on s’assure donc que toutes les conﬁgurations possibles sont
parcourues pour l’empan courant. De facon intuitive, une conﬁguration peut étre vue comme
une structure de constituant dont le label de la racine (i.e. sa Construction) n’est pas encore
connu. Lorsque nécessaire, nous utiliserons par la suite le terme de conﬁguration non-labélisée.

2.3 Etape de caractérisation

Une fois les conﬁgurations énumérées, chacune d’entre elles doit étre caracte’rise’e. En GP, le
processus de caractérisation permet d’associer une valeur booléenne a chaque contrainte carac-
téristique d’un constituant, selon que cette contrainte est satisfaite ou non. Ce processus de sat-
isfaction de contrainte est ici implanté a l’aide de l’Algorithme 2 ; une conﬁguration joue le role
d’une assignation de variables. Plus précisément, l’assignation est faite de tous les constituants

Algorithme 2 Fonction de caractérisation

function characterisation(.A = (C1, . . . ,cn) : assignment, 9 : grammar)
returns the set of evaluated properties relevant to A,
and the set of projected constructions for A.

/* Pour mémoriser le résultat de la caractérisation : */
create and clear XA [property] : table of boolean, indexed by property

/* Pour mémoriser les constructions projetées : */
create and clear C A : set of construction

/* Pour mémoriser temporairement les propriétés (i.e. contraintes) a évaluer : */
create and clear 5' : set of property

fo1'(maskE [1...2" —1])

key <— applyBinaryMask(.A,mask)

if (key is in the set of indexes for Q) then
/* Les propriétés sont récupérées depuis la grammaire, puis évaluées */
S <\ g[key] /getProperties()
XA <— evaluate(S)

/* Etape de projection : récupération des constructions a projeter */
CA <— Q[key].getDominantConstructions()

1'eturnXA,C_,4

La clef key déterminée par applyBinaryMask est une combinaison de constructions (i.e. ces constructions de A pour lesquelles le bit
correspondant dans le masque mask est positionné a 1); elle est utilisée, apres application d’une fonction de hashage, comme un index, pour
accéder aux contraintes de la grammaire qui concernent cette combinaison.

immédiats de la conﬁguration non-labélisée courante. L’ étape de Projection dans l’Algorithme

J -Ph. Prost

1 est présentée séparément de celle de Caractérisation a des ﬁns de clarté ; ces deux étapes sont
en fait implantées au sein d’une meme fonction aﬁn d’éconoIniser des itérations.

La caractérisation est un processus de satisfaction relachée. Les contraintes de la grammaire
(Q) sont lachement satisfaites (loosely satisﬁed) pour une assignation .4 en ce sens qu’elle peu-
vent étre satisfaites ou violées. Notons que .4 ne constitue pas nécessairement une assignation
pour l’ensemble des contraintes de G . Certaines contraintes peuvent contenir des variables pour
lesquelles A n’assigne aucun constituant. Ces dernieres sont considérées comme étant triviale-
ment satisfaites et sont donc ignorées. Pour des raisons d’efﬁcacité le processus fait appel a
une table d’indexation des contraintes, qui a été créée lors de l’initialisation de l’analyseur,
Chaque contrainte de G ﬁgure dans la table, indexée par une clef (hash-code). Le détail de cette
clef, ainsi que de la table d’indexation, ne sont pas l’objet de cet article. Brievement, l’idée est
d’utiliser une conﬁguration de constituants (A), d’en extraire la combinaison de constructions
correspondante, et d’utiliser cette combinaison comme une clef d’acces pour isoler toutes les
contraintes dont les variables sont compatibles avec les constructions de la combinaison. Par
exemple, la combinaison (D, N) formée d’un Déterminant et d’un Nom permet d’accéder aux
contraintes D < N et N => D (entre autres).

Bien qu’en apparence nombre de contraintes semblent étre réévaluées pour les memes construc-
tions, ces réévaluations ne sont en fait redondantes que dans le cas des contraintes monotones
(Linéarité et Dépendance). Pour tous les autres types, le fait que chaque nouvelle conﬁgura-
tion corresponde a une assignation différente signiﬁe que les contraintes peuvent étre évaluées
différement sous chaque assignation, d’o1‘1 le besoin d’une réévaluation.

2.4 Etape de projection

Conceptuellement, l’étape de projection consiste a porter un jugement quant a la Construction
d’un constituant. Le probleme est celui de la catégorisation d’une conﬁguration non-labélisée
au sein d’une construction, en fonction de la caractérisation de cette conﬁguration. De facon pra-
tique, il s’agit de labéliser des conﬁgurations non-labélisées. Une grammaire en GP est générale-
ment présentée comme une collection de constructions, chacune d’entre elles étant spéciﬁée a
l’aide d’un ensemble de contraintes. L’ opération qui doit maintenant étre effectuée nécessite
d’inverser l’information, en ce sens que la connaissance d’un ensemble de contrainte doit per-
mettre de déterminer quelles constructions peuvent étre projetées. Une table d’indexation est
créée a cet effet lors de l’initialisation de l’analyseur, qui permet un acces direct aux construc-
tions concemées en utilisant une contrainte comme clef d’acces. Cette partie du processus est
en fait implantée au sein de la fonction de caractérisation (Algorithme 2).

2.5 Etape de mémoisation

L’ étape de mémoisation vise a la fois a mémoriser et optimiser les sous-structures : elle mé-
morise donc le constituant optimal (i. e. dont le score de mérite est maximal) pour chaque con-
struction possible, pour une cellule donnée de la TPD. La fonction de mérite utilisée pour l’op-
timalité de la structure est la proportion de contraintes satisfaites, par rapport au nombre total
de contraintes satisfaites ou violées. Notons que l’optimalité ne garantit pas l’unicité de la so-
lution : il est possible d’obtenir plusieurs analyses distinctes mais de scores identiques pour
un meme énoncé. Ce sera typiquement le cas en présence d’une ambigu'1'té linguistique, telle

Analyse relachée a base de contraintes

que dans “*le chats”. Le but du LSCP n’étant pas de régler ces cas ambigus, l’algorithme a été
implanté de facon a fournir toutes les solutions équivalentes possibles.

Dans le cas ou la cellule courante dans la TPD ne pourrait pas se voir affecter au moins un
constituant, une forét d ’arbres partiels lui est attribuée a la place. Cette forét préférée est con-
struite au fur eta mesure de l’énumération des conﬁgurations possibles (au sein de la fonction
bu i 1 dc on f i gu rat ion s , lors de l’ étape d’énumeration). La préférence s’ établit selon l’ or-
dre suivant :

— les constituants avec l’empan le plus large;

— les foréts avec le plus faible nombre de constituants.

Cette préférence se traduit par une heuristique numérique, par le biais d’un score de préférence.
Ce score est calculé de la facon suivante (ou F dénote la forét, C, ses constituants, merit
le mérite de chacun de ses constituants, span la taille de l’empan, et pp le score de préférence as-
socié a F) : pp = span- (merit  +span). pp est une sorte de "score de la derniere chance" :
lorsque le processus d’analyse ne parvient pas a trouver une construction doIr1inante pour un en-
semble de constituants, les différentes conﬁgurations de ces constituants entrent en compétition
aﬁn que l’une d’entre elles soit choisie comme structure par défaut (pour l’empan concerné).
Le vainqueur est la conﬁguration avec le meilleur score de préférence. Notons que dans le
pire des cas, lorsque la TPD est entierement peuplée de sous-structures par défaut, le résultat
ﬁnal est alors une séquence d’éléments du discours (Part-of-Speech). De cette facon, l’algo-
rithme LSCP fournit toujours une analyse, quelle que soit la phrase en entrée. Bien évidement,
puisque l’heuristique pp n’est que l’une des possibilités de calculer une telle préférence parmi
de nombreuses autres possibilités, il serait intéressant d’eXplorer dans plus de détail laquelle
de ces possibilités permet les meilleurs résultats. La question, cependant, de savoir en quoi une
forét d’analyses partielles est meilleure qu’une autre n’est pas sans poser des problemes, et sort
du champ d’investigation de cet article. Il serait probablement utile de mémoiser également
d’autres informations, telles que les partitions d’ensembles, ou les contraintes monotones. Ces
dernieres, en particulier, pourraient étre mémoisées en s’inspirant des techniques de compila-
tion de contraintes mises en oeuvre dans le SeedParser de (VanRullen, 2005). Cette option reste
cependant a explorer.

3 Evaluation

La question de 1’ evaluation est délicate : le but de l’ analyseur LSCP (dont l’implantation est bap-
tisée Numbat) étant de fournir une structure hiérarchique de constituants, tant pour les phrases
bien formées que celles mal formées, il est difﬁcile de déterminer avec certitude quelle doit
étre la structure de référence attendue. L’idéal serait de disposer d’un corpus de phrases gram-
maticales et agrammaticales, chacune étant annotée avec une unique structure de constituants
(ou éventuellement une série d’alternatives). Un tel Gold Standard n’est, a notre connaissance,
malheureusement pas disponible. Pour pallier ce probleme nous avons mené deux évaluations
distinctes, qui visent a mesurer les performances de Numbat sur des phrases grammaticales
pour l’une, et sur des phrases agrammaticales pour l’autre. Chacune de ces deux évaluations
présente ses faiblesses. L’ Evaluation 1 s’effectue uniquement sur un analyse partielle des énon-
cés, et ne mesure donc pas l’aptitude a produire une structure hiérarchique unique, c’est-a-dire
en constituants imbriqués (contrairement a une forét). L’ evaluation 2, pour sa part, mesure bien
cette aptitude (une structure est dite compléte pour une phrase lorsqu’elle est constituée d’un
constituant dominant unique), mais souffre d’une absence de mesure de référence.

J -Ph. Prost

L’Evaluation 1, dont les résultats sont rapportés dans la Table 1, mesure les performances de
l’analyseur3 pour la bonne formation. Cette premiere evaluation a été effectuée selon le proto-

Précision Rappel F-mesure
Total 0.7835 0.7057 0.7416
general_lemonde 0.8187 0.7515 0.7837
general_mlcc 0.7175 0.6366 0.6746
general_senat 0.8647 0.7069 0.7779
litteraire 0.8124 0.7651 0.788
mail 0.7193 0.6951 0.707
medical 0.8573 0.678 0.757
oral_delic 0.6817 0.621 0.649
questions_amaryllis 0.8081 0.7432 0.7743
questions_trec 0.8208 0.7069 0.7596

TAB . l — Evaluation 1 dc Numbat, selon le protocole EASY

cole élaboré pour la campagne EASY d’Evaluation d’Analyseurs SYntaxiques (Paroubek et al. ,
2003), sur une partie du corpus utilisé lors de cette meme campagne. A titre de comparaison,
la Table 2 rapporte les performances mesurées dans les memes conditions pour deux autres
analyseurs que Numbat : l’un superﬁciel (VanRullen, 2005), également basé sur le formalisme
des GP, et l’autre stochastique (VanRullen et al., 2006). L’Evaluation 2, dont les résultats sont

Précision Rappel F-mesure
Analyseur superﬁciel 0.7846 0.8376 0.8102
Analyseur stochastique 0.9013 0.8978 0.8995

TAB . 2 — Evaluation d’un analyseur superﬁciel et d’un analyseur stochastique selon le protocole EASY

rapportés dans la Table 3, mesure les performances de Numbat pour l’agrammaticalité. Pour
cette évaluation nous avons demandé a cinq annotateurs experts, tous linguistes, de decider si
la structure syntaxique fournie par Numbat pour chaque phrase agrammaticale était correcte ou
non. Pour decider, les annotateurs devaient determiner si la solution de Numbat était un arbre
syntaxique possible et acceptable pour la phrase. Des instructions spéciﬁques étaient fournies
pour que le jugement ne porte pas sur l’acceptabilité grammaticale de la phrase support, mais
bien sur l’arbre qui lui était associé. Le corpus utilisé est celui construit artiﬁciellement par
(Blache et al., 2006), qui est constitué a 94% de phrases présentant des irrégularités gram-
maticales. Pour les besoins de cette évaluation les mesures de Precision et Rappel ont dﬁ étre
modiﬁées. Le nombre total de phrases en entrée est interprété comme le nombre de prédictions,
le nombre de structures completes est interprété comme le nombre d’0bservati0ns, et le nombre
de structures ayant fait l’objet d’un jugement humain CORRECT est interprété comme le nombre
de solutions correctes. Nous obtenons ainsi les formulations suivantes :

précision = CORRECT/COMPLET
rappel = CORRECT / total
F = 2 - précision - rappel/(précision + rappel) 2 0.71

3La grammaire utilisée pour cette évaluation est celle de (VanRullen, 2005), tandis que l’Evaluation 2 utilise
une grammaire propre, basée sur la précédente. La différence entre ces deux grammaires tient essentiellement dans
la profondeur des constituants décrits.

Nb. total Nb. structures Nb. structures Précision= Rappel:

annotaté correctes completes %$  
469 694 632 0.74 0.68

TAB . 3 — Evaluation 2 dc Numbat pour des phrases agrammaticales

Analyse relachée a base de contraintes

L’ evaluation 1 montre que la précision obtenue par Numbat est du méme ordre que celle obtenue
par l’analyseur superﬁciel, pour un rappel sensiblement plus faible. Ce résultat est globalement
positif, compte-tenu de ce que l’analyseur LSCP n’est initialement pas concu pour générer des
structures superﬁcielles telles que celles attendues par le protocole EASY. L’analyse attendue
pour une phrase n’est, en effet, pas un constituant unique couvrant toute la phrase, mais une suc-
cesion de constituants multiples couvrants chacun une partie seulement de la phrase, tels que
GN, GV, GP, etc. De ce fait, l’analyse générée par Numbat repose en grande partie sur l’heuris-
tique de préférence décrite ci-dessus, qui permet de produire une forét d’arbres partiels. Cette
heuristique n’est cependant pas concue a cette ﬁn, mais simplement pour fournir une analyse
par défaut en l’absence d’une solution englobante. Les résultats de l’évaluation 1 montrent donc
a la fois que cette heuristique pourrait étre améliorée, mais également que l’analyseur LSCP est
sufﬁsament ﬂexible pour s’adapter a différentes granularités d’analyse.

L’ evaluation 2 donne, pour sa part, des indications encourageantes quant a la possibilité de
générer une analyse complete pour une phrase agrammaticale, puisque 92% des phrases du cor-
pus sont analysés par une structure de constituant complete. La mesure de Précision indique que
74% de ces analyses completes sont évalués comme étant syntactiquement correctes, tandis que
le Rappel indique que les analyses correctes représentent 68% du corpus. Comparés aux scores
obtenus sur les phrases grammaticales (précision/rappel/F-mesure = 0.78/0.71/0.74), et sachant
que la quasi-totalité du corpus est constitué de phrases agrammaticales (94%), les scores de
l’évaluation 2 mettent en évidence la bonne performance de Numbat face aux énoncés agram-
maticaux, par rapport aux objectifs ﬁxés d’analyse complete.

4 Conclusion

Dans cet article nous avons abordé le probleme de l’analyse syntaxique automatique du langage
tant grammatical qu’agraInInatical. Parmi les nombreuses questions que ce probleme souleve,
nous nous sommes plus particulierement penchés sur celles de la représentation d’une structure
syntaxique d’un tel énoncé, et celle de sa grammaticalité. Nous avons vu que la notion meme de
grammaticalité d’un énoncé se décline sous différentes formes, selon la théorie syntaxique sous-
jacente. Des lors qu’on souhaite foumir une analyse syntaxique pour un énoncé quelconque,
tout en conservant la possibilité de conclure sur son caractere grammatical ou agrammatical,
un cadre de syntaxe modele-théorique s’impose pour la représentation de cette analyse. Dans
un tel cadre, une analyse syntaxique de l’énoncé est un modele (au sens de la théorie des mod-
eles) pour la grammaire. En matiere de traitement, se posent alors les questions de la génération
d’un tel modele d’une part, et celle du choix de la meilleure solution parmi un ensemble de
candidats d’autre part. Nous répondons a ces deux questions en proposant une solution algo-
rithmique qui génere l’analyse syntaxique optimale pour un énoncé quelconque, sur la seule
base d’une grammaire modele-théorique de bonne formation. Cette analyse est optimale en ce
sens qu’elle maximise la proportion de contraintes grammaticales satisfaites. L’ algorithme que
nous présentons (LSCP) fait appel a un processus de satisfaction reldchée de contraintes, ainsi
qu’a des techniques de programmation dynaInique. La satisfaction relachée est un mécanisme
par lequel un modele légitime pour un énoncé peut a la fois satisfaire une partie de la gram-
maire et en violer une autre. L’ évaluation de cet analyseur montre que ses performances sur des
énoncés grammaticaux sont comparables a celles d’analyseurs traditionnels. Les performances
obtenues sur des énoncés agrammaticaux montrent, elles, que les structures de constituants op-
timales proposées comme solutions sont jugées acceptables dans une tres large mesure selon

J -Ph. Prost

des criteres humains.

Références

BENDER E. M., FLICKINGER D., OEPEN S., WALSH A. & BALDWIN T. (2004). Ar-
boretum : Using a precision grammar for grammar checking in CALL. In Proc. of In-
STIL/ICALL2004, volume 17.

BLACHE P. (2005). Property Grammars : A Fully Constraint-based Theory. In Constraint
Solving and Language Processing, Volume 3438 of LNAI. Springer.

BLACHE P., HEMFORTH B. & RAUZY S. (2006). Acceptability prediction by means of gram-
maticality quantiﬁcation. In Proc. of CoLing/ACL 2006, p. 57-64 : ACL.

DAHL V. & BLACHE P. (2004). Directly Executable Constraint Based Grammars. In Actes
de JPFLC’2004, p. 149-166.

FOSTER J . (2007). Real bad grammar : Realistic grammatical description with grammaticality.
Corpus Linguistics and Lingustic Theory, 3(1), 73-86.

KELLER F. (2000). Gradience in Grammar - Experimental and Computational Aspects of
Degrees of Grammaticality. PhD thesis, University of Edinburgh.

MARUYAMA H. (1990). Structural Disambiguation with Constraint Propagation. In Proc. of
ACL 1990, p. 31-38.

MEURERS W. D. (2007). Advancing linguistics between the extremes : Some thoughts on
geoffrey sampson’s Grammar without Grammaticality. Corpus Linguistics and Linguistic
Theory, 3(1).

MORAWIETZ F. & BLACHE P. (2002). Parsing Natural Languages with CHR.

PAROUBEK P., ROBBA I. & VILNAT A. (2003). EASY : An Evaluation Protocol for Syntactic
Parsers. http ://www.limsi.fr/RS2005/chm/lir/lir11/. (as of August 2008).

POLLARD C. & SAG I. (1994). Head-driven Phrase Structure Grammars. CSLI, Chicago
University Press.

PRINCE A. & SMOLENSKY P. (1993). Optimality Theory .' Constraint Interaction in Gener-
atire Grammar. Rapport interne, TR-2, Rutgers University.

PULLUM G. & SCHOLZ B. (2001). On the Distinction Between Model-Theoretic and
Generative-Enumerative Syntactic Frameworks. In Proc. of LACL’2001, number 2099 in
LNAI, p. 17-43 : Springer Verlag.

PULLUM G. K. (2007). The Evolution of Model-Theoretic Frameworks in Linguistics. In
Proc. ofMTS@I0, p. 1-10.

VANRULLEN T. (2005). Vers une analyse syntaxique a granularite’ variable. PhD thesis,
Université de Provence.

VANRULLEN T., BLACHE P. & BALFOURIER J .-M. (2006). Constraint-Based Parsing as an
Efﬁcient Solution : Results from the Parsing Evaluation Campaign EASy. In Proc. of LREC
2006, p. 165-170.

