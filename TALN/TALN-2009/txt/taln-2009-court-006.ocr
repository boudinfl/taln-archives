TALN 2009 — Session posters , Senlis, 24-26 juin 2009

Apport de la syntaxe dans un systéme de question-réponse :
étude du systéme FIDJI.

Véronique Moriceau Xavier Tannier
Université Paris-Sud 11 / LIMSI-CNRS
BP 133, 91403 Orsay Cedex, France
{moriceau, xtannier} @limsi.fr

Résumé. Cet article présente une série d’évaluations visant a étudier l’apport d’une ana-
lyse syntaxique robuste des questions et des documents dans un systéme de questions-réponses.
Ces évaluations ont été effectuées sur le systéme FIDJI, qui utilise a la fois des informations
syntaxiques et des techniques plus “traditionnelles”.

La sélection des documents, l’extraction de la réponse ainsi que le comportement selon les
différents types de questions ont été étudiés.

Abstract. This paper presents some experiments aiming at estimating the contribution
of a syntactic parser on both questions and documents in a question-answering system. This
evaluation has been performed with the system FIDJI, which makes use of both syntactic infor-
mation and more “traditional” techniques.

Document selection, answer extraction as well as system behaviour on different types of ques-
tions have been experimented.

M0tS-CléS I Systémes de questions-réponses, analyse syntaxique, évaluation.

Keywords: Question-answering, syntactic analysis, evaluation.

1 Introduction

Nous présentons ici les résultats d’une série d’évaluations sur le systeme FIDJI1 (Finding In
Documents Justiﬁcations and Inferences), un systeme de questions-réponses en domaine ouvert
pour le francais, utilisant notamment l’analyse syntaxique des textes et des questions.

Les objectifs de cet article sont les suivants :

— Montrer que la syntaxe, exploitée en complément de techniques plus “traditionnelles” de
questions-réponses, peut conduire a une amélioration notable des résultats globaux;

— Etudier a quelles étapes du traitement et pour quels types de questions l’utilisation de l’ana-
lyse syntaxique peut apporter une réelle plus-value.

Dans un premier temps, la section 2 résume l’architecture et le fonctionnement du systeme
FIDJI. Puis l’évaluation modulaire, coeur de cet article, est présentée a la section 3, avec une
présentation globale des résultats, puis des études sur l’apport de l’analyse syntaxique lors de

1Ce travail est ﬁnancé partiellement par le projet CONIQUE ANR—05-BLAN—008501 et par OSEO dans le
cadre du programme Quaero.

Véronique Moriceau, Xavier Tannier

la phase de sélection des documents, de l’eXtraction de la réponse, et enﬁn sur les différences
entre les différents types de questions.

2 Une approche syntaxique pour la validation de réponses

2.1 Présentation de FIDJ I

La plupart des systemes de questions-réponses peut extraire une réponse a une question factuelle
quand celle-ci est explicitement présente dans le texte, mais ils ne sont pas capables de combiner
plusieurs informations pour produire une réponse.

Le systeme de questions-réponses FIDJI vise a introduire des mécanismes de compréhension
reposant sur des inférences. L’ obj ectif est de produire des réponses qui sont entierement validées
par des extraits de textes (des passages).

Pour la premiere étape de développement de ce systeme, nous avons introduit l’utilisation d’un
analyseur syntaxique robuste, d’une part pour le traitement et la décomposition des questions et
d’autre part pour l’analyse des documents.

L’ ajout d’informations syntaxiques a plusieurs buts :

— Faciliter l’obtention des caractéristiques portées par la question : type de la question, de la
réponse attendue, entités nommées, etc.

— Décomposer éventuellement la question avec pour objectif de valider une réponse potentielle
dans plusieurs documents.

— Sélectionner des passages candidats (i. e. contenant peut-étre la réponse) de facon plus précise,
en utilisant non plus des mots-clés simples, mais des dépendances syntaxiques.

— Enﬁn, extraire la réponse de ces passages a partir de la combinaison des informations issues
de la question et des phrases étudiées.

Beaucoup de systemes de questions-réponses utilisent des informations syntaxiques, en particu-
lier les relations de dépendance, principalement pour l’extraction des réponses. Deux approches
émergent : la premiere consiste a rechercher un appariement exact entre les relations de dépen-
dance de la question et celles d’un passage (Katz & Lin, 2003), tandis que la seconde approche
calcule une distance d’édition entre les arbres représentant la question et le passage (Ligozat,
2007). En ce qui conceme la décomposition des questions, les stratégies proposées se posi-
tionnent a un niveau a la fois syntaxique et sémantique (Katz et al., 2005; Hartrumpf et al.,
2008).

Notre but est d’extraire et de valider des réponses en allant au-dela d’un appariement syntaxique
exact entre la question et le passage, et cela sans utiliser de ressources sémantiques. Dans ce
contexte de validation de réponse, nous avons remarqué que la stratégie de validation a appliquer
(validation par un seul ou plusieurs documents) peut étre guidée par la question, et en particulier
par le type de réponse attendu.

Une présentation détaillée du fonctionnement de FIDJ I et de chacun de ses modules est donnée
dans (Moriceau et al., 2009).

Apport de la syntaxe dans un systéme de question-réponse

 

Analyse de la question Analyse des documents Sélection des documents

 
  
  
  
    
     

— Analyse syntaxique — Analyse syntaxique ‘ D0CU'"e“'3_ mmenam '9 , 7

_ —> _p , —;- plus de relations the la " l

Que-“'0” — Type de la question — Regles de reécriture question '\ l /i :
- Type de la réponse — Etiquetage Entités nommées ‘ — ' ' — — — ' ' — — — ' ' — — ’

Qacumenls

sélecli onnés. l

 

Validation de la réponse Extraction de la réponse

T -7 — Unification entre les 7 I/'2'\
"- relations synnaxique de la \ ’

_ _(_l!e§[i9“_ EL d_e~°’_d9‘2J”_“3_”?5_ __V_

— Extraction cles reponses
potentielles

— Veriﬁcation du type de la
Réponse 4’ réponse dans le document
sélectionné

Documents‘
I

  

réponses
c_ani:lit:_l_als
— ou dans un autre document

FIG. 1 — Architecture de FIDJ I
2.2 Principe général

Nous présentons ici l’architecture générale ainsi que deux exemples : 1) l’eXtraction d’une ré-
ponse et la validation de son type dans le document sélectionné, et 2) l’eXtraction d’une réponse
et la validation de son type dans plusieurs documents.

La ﬁgure 1 présente l’architecture de FIDJI. L’ensemble des documents est indexé par le mo-
teur de recherche Lucene (Hatcher & Gospodnetié, 2004). On extrait de la question les relations
syntaxiques a rechercher, le type de la question (liste, déﬁnition, fait. . .) ainsi que le type de la
réponse (type d’entité nommée ou type plus spéciﬁque — voir l’exemple 2) et les mots-clés signi-
ﬁcatifsz. L’index est interrogé avec ces mots-clés et les 100 premiers documents sont conservés.

L’ approche consiste a déterminer, pour une question donnée, si toutes les caractéristiques de
la question (en l’occurrence les dépendances syntaxiques) peuvent étre trouvées dans un ou
plusieurs documents. Notre systéme s’appuie sur les analyses syntaxiques produites par Syn-
tex (Bourigault & Fabre, 2000), un analyseur robuste pour le francais.

2.2.1 Exemple 1

Dans un premier temps, l’analyse de la question fournit les relations de dépendance syntaxique,
le type de la question et le type de réponse attendu. Par exemple :

2C’est—a—dire les mots étiquetés comme nom, Verbe, adj ectif ou adverbe par 1’ana1yseur syntaxique.

Véronique Moriceau, Xavier Tannier

Question 2 Quelle ville a été secouée par un tremblement de terre le 17 janvier ?
]Dﬂmn¢umes2DATE(l7 janvier)

attribut_de(tremblement, terre)

SUJ(secouer, REPONSE)

AUX(étre, secouer)

modif_par(secouer, tremblement)
Type de la question 2 factuelle
Type de réponse attendu 2 ville (entité nommée)

Les phrases contenant le plus de relations en commun avec la question sont ensuite selection-
nées dans un sous-ensemble de documents de la collection. Par exemple 2

Passage 2 Le tremblement de terre qui a secoué, <date>lundi 17 janvier</date>, <ville>Los An-
geles</ville> ne serait pas associé directement a la fameuse faille...
DATE(l7 janvier)
attribut_de(tremblement, terre)
SUJ(secouer, tremblement)
OBJ(secouer, Los Angeles)
SUJ(secouer, Los Angeles)
AUX(étre, secouer)
modif;par(secouer,tremblement)

Ici, toutes les relations de la question sont présentes dans l’analyse du passage (on note qu’ici,
les relations en italique ont été obtenues par une regle de réécriture de la voix active vers la voix
passive). Par uniﬁcation avec la variable réponse de la question, la réponse potentielle qui est
extraite est donc Los Angeles. 11 reste alors a vériﬁer que le type de cette réponse correspond
bien au type de réponse attendu (ville).

Pour cela, les entités nommées des documents ont été préalablement étiquetées en utilisant un
ensemble d’environ 160 types (Rosset et al., 2007) (e. g. personne, organisation, lieu, nationa-
lité, date, nombre, etc.). Ainsi, le passage étiqueté en entités nommées permet de valider le type
de la réponse candidate extraite (Los Angeles).

2.2.2 Exemple 2

Soit la question 2 Quel premier ministre s’est suicidé en 1993 ?
I)épendances2
DATE(se suicider, 1993)
SUJ(se suicider, REPONSE)
attribut(REPONSE, ministre)
attribut(ministre, premier)
Type de la question 2 factuelle
Type de réponse attendu 2 personne (type précis 2 premier ministre)

Apport de la syntaxe dans un systeme de question-réponse

Et la phrase sélectionnée suivante :

<personne>Pierre Bérégovoy</personne> s’est suicidé en 1993.
DATE (se suicider, 1 9 93)
SUJ ( se suicider, Pierre Bérégovoy)

La variable REPONSE s’uniﬁe avec Pierre Bérégovoy qui devient une réponse candidate : le
type d’entité nommée et les deux premieres dépendances de la question sont ainsi vériﬁés dans
cette phrase. 11 manque les deux dépendances suivantes, concernant le type précis de la réponse
(Pierre Bérégovoy était-il premier Ininistre ?).

Une nouvelle question est donc construite pour valider la réponse candidate. La validation est
opérée en deux étapes. Tout d’abord, le systeme vériﬁe que la réponse candidate est bien un
ministre, en recherchant une relation ’attribut’ (attribut (Bérégovoy, ministre) ) dans
l’ensemble des documents. Si cela est conﬁrmé, le type étendu est également vériﬁé et les deux
relations attribut (Bérégovoy, ministre) et attribut (frangais, ministre) sont
attendues dans la meme phrase.

Dans les cas ou la variable REPONSE n’existe pas ou n’est pas instanciée par des relations
du passage, le systeme recherche un ou plusieurs candidats dans la phrase parmi les entités
nommées du type attendu.

3 Apport de la syntaxe dans FIDJ I

Come nous l’avons indiqué, si les résultats généraux ont de l’intérét, nous nous sommes sur-
tout attachés a l’estimation du role de la phase d’analyse syntaxique dans notre systeme. En
effet, il est important d’évaluer le bénéﬁce de la syntaxe par rapport aux techniques plus clas-
siques, et ce indépendamment des autres caractéristiques propres a un systeme donné.

Plusieurs points sont ici évalués :
— les performances d’une approche syntaxique associée a des techniques classiques en question-
réponse,

— l’apport de la stratégie de décomposition des questions,

— l’apport de la syntaxe pour la sélection des documents,

— l’apport de la syntaxe pour l’eXtraction des réponses,

— les différences concernant l’eXtraction des réponses selon le type de la question.

Nous avons évalué le systeme sur les données de test de la campagne d’évaluation CLEF
2005 (Vallin et al., 2005). La collection de documents est composée d’environ 177000 articles
de joumaux en francais (Le Monde et ATS 1994-1995 (environ 2 Go)). Ces documents sont
censés étre syntaxiquement corrects. Les questions sont factuelles ou de type déﬁnition. Lors
de cette campagne, les systemes sont autorisés a proposer 3 réponses pour chaque question, ces
réponses devant étre classées par ordre de conﬁance.

La méthodologie employée et les résultats obtenus sont décrits dans les sections suivantes.

Veronique Moriceau, Xavier Tannier

3.1 Performances globales de FIDJ I

Le tableau 1 presente les resultats obtenus par FIDJI sur les donnees de CLEF 2005 (nombre
de reponses correctes proposees en premiere position). Nous comparons ces resultats avec ceux
de QRISTAL (Laurent et al., 2005; Laurent et al., 2006), le meilleur systeme de questions-
reponses pour le francais lors de ces campagnes.

Type de question FIDJ I QRISTAL
Factuelle 53 % 59 %
Deﬁnition 78 % 86 %

TOTAL 58.5 % 64 %

TAB. 1 — Resultats de FIDJ I sur les donnees de CLEF 2005.

Le nombre de reponses correctes s’eleve a 58.5 % pour les reponses donnees en rang 1 et a
70 % si l’on considere les rangs 1 a 3.

Les resultats de FIDJ I sont inferieurs a ceux de QRISTAL qui utilise aussi une approche syn-
taxique mais qui beneﬁcie de l’utilisation de nombreuses ressources telles que des diction-
naires et des ontologies. Cependant, notre systeme se place "virtuellement" a la deuxieme place
puisque le systeme qui a atteint la deuxieme place lors de CLEF 2005 a obtenu un score de
35 % de reponses correctes.

Nous evaluons maintenant l’apport de la strategie de decomposition syntaxique des questions
dans le but de valider une reponse grace a plusieurs passages.

Dans l’ensemble de questions de CLEF 2005, sur les 51 questions qui peuvent etre decompo-
sees en sous-questions en appliquant notre strategie, FIDJ I trouve une reponse correcte (sans
tenir compte du rang) pour 32 questions. Rappelons que chaque fois que la decomposition des
questions est appliquee, le systeme peut rechercher des justiﬁcations a la reponse dans des do-
cuments differents. Parmi ces 32 reponses correctes, 22 % ont une justiﬁcation dans plusieurs
documents. En revanche, si FIDJI n’utilise pas la strategie de decomposition et de validation
par plusieurs documents, seulement 64 % des reponses sont correctes (au lieu de 70 %).

Le tableau 2 montre le nombre de reponses correctes dont la justiﬁcation a ete trouvee dans un
ou plusieurs documents.

Réponses correctes en rang 1 £1 3 CLEF 2005
Avec justiﬁcation dans 1 document 78 %
Avec justiﬁcation dans plusieurs documents 22 %
Sans validation multi-documents 64 %
Avec validation multi-documents 70 %

TAB. 2 — Evaluation de la strategie de decomposition des questions.

Ces resultats montrent une amelioration des performances du systeme lorsque l’on utilise une
strategie de decomposition des questions aﬁn de valider les reponses par l’intermediaire de
plusieurs documents (Moriceau et al., 2009).

Apport de la syntaxe dans un systeme de question-réponse

3.2 Apport de la syntaxe pour la sélection des passages

Dans les systemes de questions-réponses, la sélection des passages candidats est généralement
effectuée en prenant en compte les mots de la question. Dans FIDJI, nous nous situons au niveau
des dépendances syntaxiques, en sélectionnant les phrases comportant le plus de dépendances
(nom de la relation et arguments) en commun avec la question.

Pour évaluer l’apport de cette technique, nous l’avons comparée avec une sélection des phrases
comportant simplement le maximum de mots-clés de la question (désactivation du module note
0) dans la ﬁgure 1).

L’ évaluation est effectuée sur la collection de CLEF 2005 et les résultats sont reproduits dans le
tableau 3. La progression du nombre de bons passages (passages contenant la réponse en rang 1)
est tout a fait signiﬁcative (+8,1 %). Mais le nombre de bonnes réponses en rang 1 augmente
encore plus (+15,8 %). Ainsi, la syntaxe ne permet pas seulement de récupérer plus de bons
passages candidats, mais ces passages sont méme plus pertinents pour une extraction efﬁcace
de la réponse.

Par ailleurs, on constate que le progres pour les rangs 1 a 3 est plus faible. Cela semble montrer
que les passages renvoyés sont comparables, mais que l’utilisation des relations syntaxiques en
améliore le classement.

Mots-clés Dépendances
Réponses correctes en rang 1 50.5 % 58.5 %
Réponses correctes en rang 1 a 3 68.5 % 70 %
Passages contenant la réponse en rang 1 62.6 % 67.7 %
Passages contenant la réponse en rang 1 a 3 72.7 % 75.8 %

TAB. 3 — Apport de l’utilisation de la syntaxe pour la sélection des passages candidats.

3.3 Apport de la syntaxe pour l’extraction des réponses

L’ évaluation de l’apport de la syntaxe lors de l’eXtraction de la réponse est effectuée en n’appli-
quant pas la technique d’uniﬁcation de la variable réponse décrite a la section 2.2.1 (désactiva-
tion du module note (2 dans la ﬁgure 1).

Les résultats sont présentés dans le tableau 4. Ils montrent une hausse de 34,5 % du nombre
de bonnes réponses en rang 1 en présence du module syntaxique. Enﬁn, le tableau 5 donne les
résultats obtenus par le systeme en n’appliquant aucune technique d’ordre syntaxique (désacti-
vation des modules (D et (9 de la ﬁgure 1).

Si la progression obtenue est importante, il faut noter que pour un certain nombre de ques-
tions, aucune méthode “de secours”, c’est-a-dire n’utilisant pas la syntaxe, n’est prévue. C’est
pourquoi il est nécessaire de comparer les résultats en distinguant les types de questions; c’est
l’objectif des expérimentations décrites dans la section suivante.

Véronique Moriceau, Xavier Tannier

TAB. 4 — Apport de l’utilisation de la syntaxe pour l’eXtraction des réponses.

Sans Avec
uniﬁcation uniﬁcation

Réponses correctes en rang 1 43.5 % 58.5 %
Réponses correctes en rang 1 a 3 55.5 % 70 %
Passages contenant la réponse en rang 1 55.6 % 67.7 %
Passages contenant la réponse en rang 1 a 3 64.6 % 75.8 %

Sans syntaxe Avec syntaxe
Réponses correctes en rang 1 36 % 58.5 %
Réponses correctes en rang 1 a 3 51.5 % 70 %
Passages contenant la réponse en rang 1 47 % 67.7 %
Passages contenant la réponse en rang 1 a 3 61.1 % 75.8 %

TAB. 5 — Apport de l’utilisation de la syntaxe pour l’eXtraction des réponses.

3.4 Apport de la syntaxe selon les types de réponses

Dans le but d’évaluer de facon plus précise l’apport du module d’extraction de la réponse par
uniﬁcation des relations syntaxiques, nous avons isolé les questions pour lesquelles le systeme
identiﬁe un type d’entité nommée (EN) a rechercher. En effet, pour ces questions, en l’absence
du module (2, le systeme va simplement rechercher une entité nommée du bon type dans le
passage sélectionné. En revanche, pour les autres questions, l’uniﬁcation syntaxique étant le
seul moyen d’extraire une réponse candidate, le débranchement du module conduit a une ab-
sence de réponse. La progression globale constatée dépend donc fortement de la ﬁnesse de la
classiﬁcation en entités nommées et de l’analyse des questions correspondante.

Sur les 200 questions de la campagne CLEF 2005, 169 ont été identiﬁées comme attendant
une entité nommée3. Par ailleurs, il est également intéressant de distinguer les questions dites
factuelles des questions de deﬁnition.

Le tableau 6 résume les résultats sur ces trois classes (non mutuellement exclusives) de ques-
tions, en comparant les proportions de bonnes réponses renvoyées en premiere position. Il est
particulierement notable que méme lorsque l’information sur l’EN attendue est présente, l’ana-
lyse syntaxique permet un gain de 14,6 %.

Sans uniﬁcation Avec uniﬁcation
Questions sur une EN 52.7 % 60.4 %
Questions factuelles 48.3 % 53 %
Questions deﬁnition 35.3 % 78 %

TAB. 6 — Apport de l’utilisation de la syntaxe par types de questions (réponses en rang 1).

3Ce chiffre peut Varier fortement selon des systemes ou la typologie des EN utilisées et l’ana1yse des questions
peuvent etre radicalement différentes. Ainsi, la question Qui est Javier Solana ? attend des EN de type “fonction”,
“profession”, etc. car 1’étiqueteur est en mesure de les détecter (Rosset et al., 2007).

Apport de la syntaxe dans un systeme de question-reponse

3.5 Conclusion

Le systeme FIDJ I presente une architecture et un fonctionnement representatifs des briques
classiques utilisees par les systemes de questions-reponses classiques, a ceci pres qu’il fait ap-
pel en complement a des connaissances d’ordre syntaxique sur les documents interroges et les
questions posees.

Il est ainsi interessant de proceder a une evaluation detaillee de l’apport de l’analyse syntaxique,
d’une part a differents niveaux de la chaine de questions-reponses (selection des documents,
puis extraction de la reponse), mais egalement selon les differents types de questions.

Nous avons presente dans cet article une serie d’eXperimentations montrant que l’analyse syn-
taxique, combinee a des methodes robustes et plus classiques (moteur de recherche, etiquetage
en entites nommees. . .), pouvait conduire a une progression tout a fait signiﬁcative a chaque
etape du traitement.

La prochaine etape va consister, dans le cadre du projet Quaero4, a tester notre systeme sur une
collection de documents provenant du Web (2 millions de pages) et ainsi evaluer ses perfor-
mances sur de tres grandes collections de documents de styles et de formes tres differents.

Références

BOURIGAULT D. & FABRE C. (2000). Approche linguistique pour l’analyse syntaxique de
corpus. Cahiers de Grammaire, 25.

HARTRUMPF S., GLOCKNER I. & LEVELING J. (2008). University of hagen at qa@clef
2008 : Efﬁcient question answering with question decomposition and multiple answer streams.
In P. FORNER, A. PENAS, I. ALEGRIA, C. FORASCU, N. MOREAU, P. OSENOVA, P. PRO-
KOPIDIS, P. ROCHA, B. SACALEANU, R. SUTCLIFFE & E. T. K. SANG, Eds., Working Notes
for the CLEF 2008 Workshop, Aarhus, Denmark.

HATCHER E. & GOSPODNETIC O. (2004). Lucene in Action. Manning.

KATZ B., BORCHARDT G. & FELSHIN S. (2005). Syntactic and semantic decomposition
strategies for question answering from multiple resources. In Actes de AAAI 2005 Workshop
on Inference for Textual Question Answering, Pittsburgh.

KATZ B. & LIN J. (2003). Selectively using relations to improve precision in question answe-
ring. In Actes de Workshop on Natural Language Processing for Question Answering, EACL,
Budapest.

LAURENT D., SEGUELA P. & NEGRE S. (2005). Cross lingual question answering using
qristal for clef 2005. In Working Notes QA@CLEF, Vienna.

LAURENT D., SEGUELA P. & NEGRE S. (2006). Cross lingual question answering using
qristal for clef 2006. In Working Notes QA@ CLEF, Alicante.

LIGOZAT A. (2007). Apport de l’analyse syntaxique des phrases dans un systeme de
questions-reponses. TraitementAutomatique des Langues, 46.

MORICEAU V., TANNIER X. & GRAU B. (2009). Utilisation de la syntaxe pour valider
les reponses a des questions par plusieurs documents. In Actes C0nfe’rence en Recherche
d’Information et Applications, CORIA, Presqu’ile de Giens.

4http ://www.quaero.org

Véronique Moriceau, Xavier Tannier

ROSSET S., GALIBERT 0., ADDA G. & BILINSKI E. (2007). The limsi qast systems : compa-
rison between human and automatic rules generation for question-answering on speech trans-
criptions. In ASRU, Kyoto.

VALLIN A., GIAMPICCOLO D., AUNIMO L., AYACHE C., OSENOVA P., PENAS A.,
DE RIJKE M., SACALEANU B., SANTOS D. & SUTCLIFFE R. (2005). Overview of the
clef 2005 multilingual question answering track. In Working Notes QA@ CLEF, Vienna.

