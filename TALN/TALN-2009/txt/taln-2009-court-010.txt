TALN 2009 — Session posters , Senlis, 24-26 juin 2009

Catégorisation sémantico-discursive des évaluations
exprimées dans la blogosphére

Matthieu Vernierl Laura Monceauxl Beatrice Daillel Estelle Dubreill
(1) LINA / CNRS UMR 6241, Université de Nantes
{Prenom.Nom} @univ-nantes.fr

Résumé. Les blogs constituent un support d’observations idéal pour des applications liées
a la fouille d’opinion. Toutefois, ils imposent de nouvelles problématiques et de nouveaux déﬁs
au regard des méthodes traditionnelles du domaine. De ce fait, nous proposons une méthode
automatique pour la détection et la catégorisation des évaluations localement exprimées dans
un corpus de blogs multi-domaine. Celle-ci rend compte des spéciﬁcités du langage évaluatif
décrites dans deux théories linguistiques. L’ outil développé au sein de la plateforme UIlV[A vise
d’une part a construire automatiquement une grammaire du langage évaluatif, et d’autre part
a utiliser cette grammaire pour la détection et la catégorisation des passages évaluatifs d’un
texte. La catégorisation traite en particulier l’aspect axiologique de l’évaluation, sa conﬁgura-
tion d’énonciation et sa modalité dans le discours.

Abstract. Blogs are an ideal observation for applications related to the opinion mining
task. However, they impose new problems and new challenges in this ﬁeld. Therefore, we pro-
pose a method for automatic detection and classiﬁcation of appraisal locally expressed in a
multi-domain blogs corpus. It reﬂects the speciﬁc aspects of appraisal language described in
two linguistic theories. The tool developed within the UIMA platform aims both to automati-
cally build a grammar of the appraisal language, and the other part to use this grammar for the
detection and categorization of evaluative segments in a text. Categorization especially deals
with axiological aspect of an evaluative segments, enunciative conﬁguration and its attitude in
discourse.

M0tS-CléS I fouille d’opinion, langage évaluatif, catégorisation des évaluations.

Keywords: opinion mining, appraisal language, appraisal classiﬁcation.

1 Introduction

Ces dernieres années, les blogs ont conquis leur place a coté des médias traditionnels et
deviennent une source d’informations incontoumable. Les blogueurs l’utilisent majoritairement
a des ﬁns d’auto-représentation, et la plupart se forment autour des affects ou des idées propres
a leur auteur. Le blog est souvent construit autour d’une stratégie argumentative o1‘1 l’auteur
cherche a convaincre, plus ou moins intensément, ses lecteurs d’adopter son point de vue ou sa
facon d’évaluer le monde. De par la force et la rapidité des échanges sur le Web, un blog peut
devenir célebre au sein de la communauté a laquelle il appartient en tres peu de temps. Certains
blogs sont d’ailleurs si inﬂuents que les informations qui en sont issues semblent se propager
aux autres blogs pour créer des phénoménes de buzz ou de sujets émergents dont les évolutions
peuvent étre observées au ﬁl des jours ou des semaines.

Vernier et al.

Dans le cadre de la blogosphere, les recherches en fouille d’opinion suscitent un intérét majeur,
notamment aﬁn de caractériser la facon dont l’un de ces sujets émergents est évalué : est-il
évalué globalement positivement ou négativement? Sur quels aspects est-il positivement ou
négativement évalué ? Selon les sujets émergents, les domaines d’applications sont particuliere-
ment nombreux : la sociologie, la politique, le marketing, la création de réseaux sociaux autour
d’opinions communes, etc. La quantité des blogs, leur qualité grandissante et leur réactivité vis
a vis de l’actualité mondiale suggerent la possibilité d’analyser en temps réel l’évolution des
avis portés sur un méme sujet cible. L’ enjeu pour la recherche en traitement de la langue et un
des verrous technologiques de cette problématique résident principalement sur la facon de de-
tecter et catégoriser automatiquement l’expression d’une opinion dans la langue. D’un point de
vue terminologique, nous préférons adopter le terme d’évaluation et de langage évaluatif pour
faire référence aux différentes modalités linguistiques possibles pour exprimer l’opinion, l’ap-
préciation, le jugement, l’émotion, l’accord, le désaccord porté sur un sujet. Nous justiﬁons cet
emploi en adoptant le point de vue des théories linguistiques anglo-saxonnes (Martin & White,
2005) et francaises (Charaudeau, 1992; Galatanu, 2000).

Les billets publiés sur les blogs par les auteurs, et les commentaires qui y sont associés, sont
particulierement hétérogenes a la fois dans la diversité des themes abordés et dans leur forme
discursive. Un billet peut parler d’un seul concept ou, dans la maj orité des cas, évoquer plusieurs
concepts bien distincts. L’ auteur peut étre présent ou absent dans l’énonciation (utilisation du
pronom « je »); sa stratégie argumentative peut chercher a créer une atmosphere volontaire-
ment subjective ou, au contraire, créer une fausse impression d’objectivité. Notre objectif est
d’aboutir a une méthode pour la fouille d’opinion qui tienne compte de la diversité possible
des thématiques et des formes discursives des textes. Nous cherchons ainsi a détecter les éva-
luations exprimées localement dans les blogs et a catégoriser leur modalité, leur conﬁguration
d’énonciation et leur axiologie (positive ou négative).

Dans cet article, nous présentons l’évolution des problématiques du domaine aﬁn de préciser
en quoi les méthodes existantes en fouille d’opinion ne sont pas précisément adaptées a nos
objectifs (section 2). Pour caractériser du mieux possible le phénomene complexe de l’évalua-
tion, nous nous appuyons sur deux modeles linguistiques pour proposer un schéma d’annotation
(section 3). A partir d’un corpus annoté manuellement, notre approche consiste a apprendre au-
tomatiquement une grammaire de l’évaluation et a utiliser celle-ci a posteriori pour détecter et
catégoriser la modalité, la conﬁguration d’énonciation et l’aXiologie des évaluations issues des
blogs (section 4). Nous expérimentons et évaluons notre méthode sur un corpus test a travers
deux exemples d’applications (section 5).

2 Evolution des problématiques en fouille d’opinion

L’évolution des travaux en fouille d’opinion depuis une dizaine d’années semble guidée par
deux courants : comment adapter des méthodes pour traiter du monodomaine a du multido-
maine sans repasser par une phase d’entrainement coﬁteuse ? comment adapter des méthodes
qui analysent un texte dans sa globalité vers des méthodes qui analysent séparement différents
passages d’un texte ? Ces deux axes sont également deux de nos préoccupations induites par
notre support d’observations : les blogs.

Categorisation semantico-discursive des evaluations dans la blogosphere

2.1 Du mono-thématique au multi-thematique

Quelques travaux en fouille d’opinion prenant les blogs comme support d’etude (Mishne &
Glance, 2006; Mullen & Malouf, 2006) se sont limites a analyser les blogs d’une meme the-
matique : le cinema ou la politique notamment. Par opposition, notre objectif est de prendre
en compte le plus large eventail possible de domaines discutes sur les blogs. Ce point souleve
une problematique qui prend sa source dans les travaux pionniers de la fouille d’opinion. De
nombreux travaux proposent des methodes par apprentissage supervise pour classer automati-
quement des textes a partir d’un corpus homogene thematiquement : des critiques de ﬁlms, de
livres, de telephones, d’appareil photos ou de voyages (Pang et al., 2002; Dave et al., 2003;
Maurel et al., 2008). Pour chaque domaine d’application, ces methodes beneﬁcient de l’exis-
tence de ressources exploitables : les sites de critiques en ligne o1‘1 chaque texte est associe a une
note attribuee en amont par les utilisateurs du site. Ces methodes permettent d’eXtraire statisti-
quement des unites textuelles (mots, n-grammes) associees a une polarite positive ou negative
selon leur frequence d’apparition dans les textes notes positivement ou negativement. Souvent
ces indices textuels ne font sens que dans le seul domaine etudie, voire uniquement dans le
corpus d’etude. Ainsi, (Aue & Gamon, 2005) montre que le terme le plastique est negatif lors-
qu’on evalue une cuisine et qu’il n’a aucune polarite selon les classiﬁeurs entraines sur d’autres
domaines.

Des travaux plus recents (Aue & Gamon, 2005; Blitzer et al., 2007) proposent des me-
thodes pour comparer les unites textuelles extraites statistiquement sur plusieurs corpus mono-
thematiques et conserver uniquement celles qui font sens dans plusieurs domaines. Ces unites
textuelles sont ainsi considerees comme sufﬁsament generiques pour pouvoir s’adapter a des
textes d’un domaine o1‘1 il n’existe pas de corpus d’entrainement disponible. Toutefois, a notre
connaissance tres peu d’experiences ont ete menees a grande echelle sur des corpus reellement
multi-thematiques. Le besoin d’envisager d’autres methodes en supplement des classiﬁeurs su-
pervises classiques s’exprime de plus en plus avec les nouveaux besoins applicatifs en fouille
d’opinion.

2.2 Dela catégorisation de texte £1 la catégorisation des évaluations

Un deuxieme aspect qui distingue notre objectif des problematiques habituelles en fouille
d’opinion reside dans le constat suivant : un billet ou un commentaire publie sur un blog parle,
dans la majorite des cas, de plusieurs concepts bien distincts. Chaque concept peut etre evalue
differemment. Il n’est donc pas pertinent de chercher a categoriser positivement ou negative-
ment un blog dans sa globalite. D’autres travaux font ce meme constat et envisagent differentes
strategies. (Nigam & Hurst, 2006) commence par extraire les groupes de phrases d’un corpus
qui traitent d’une meme thematique speciﬁee en amont pour ainsi se replacer dans les condi-
tions d’une classiﬁcation mono-thematique. Selon le meme principe, mais avec un niveau de
granularite plus ﬁn, (Hu & Liu, 2004) categorise les phrases une par une a partir des adjectifs
presents dans la phrase. Citons egalement (Whitelaw et al., 2005) qui s’interesse a caracteriser
les evaluations a un niveau intra-phrastique (very good, not terribly funny) a partir de la theorie
de l’evaluation anglo-saxonne (Martin & White, 2005). Nous nous inscrivons davantage dans
ce demier axe de recherche en nous questionnant sur la deﬁnition d’une evaluation, quelles sont
ses differentes formes et ses differents marqueurs linguistiques qui permettraient d’aboutir a
une methode robuste pour la detection et la categorisation des evaluations.

Vernier et al.

3 Langage évaluatif

3.1 Théories linguistiques

L’ évaluation est deﬁnie par (Lavelle, 1950) comme l’acte de rupture de l’indzﬁ‘e’rence par
laquelle nous mettons toutes les chases sur le méme plan et considérons toutes les actions
comme équivalentes. Tout acte de langage revelant une rupture d’indifference releve donc du
phenomene evaluatif. Ces actes mettent en jeu des mecanismes semantiques, pragmatiques ou
enonciatifs complexes faisant l’objet de nombreuses etudes (Kerbrat-Orecchioni, 1997; Ans-
combre & Ducrot, 1983). (Charaudeau, 1992) montre qu’il existe cinq modalites permettant a
un locuteur d’exprimer une evaluation (l’opinion, l’accord ou le désaccord, l’acceptation ou
le refus, le jugement et l’appréciation). Chacune de ces modalites revele une attitude particu-
liere du locuteur : sa croyance plus ou moins certaine par rapport a l’evaluation qu’il exprime,
le champ d’experience dans lequel il se positionne (ethique, moral, intellectuel, esthetique, etc),
sa position par rapport a son enonce (presence ou absence du « je »). Selon Charaudeau, il existe
des marqueurs lexicaux et des structures linguistiques speciﬁques a ces modalites (Tab. 1).

Marqueurs | Modalité
étre sceptique, douter, croire, penser, étre convaincu Opinion (conviction faible a forte)
effectivement, d’ accord, non, étre faux Accord ou Désaccord
courageux, intéressant, lache, mentir Jugement (éthique, moral, intellectuel)
adorer, ha'1‘r, joli, triste Appreciation (affect, hédonique)

TAB. 1 — Exemples de marqueurs lexicaux pour les modalites de l’evaluation

La theorie de (Galatanu, 2000) sur l’evaluation complete le modele de Chauraudeau en hierar-
chisant les modalites sur une echelle de subjectivite. Lorsqu’un locuteur organise son enonce, il
peut choisir d’objectiver ou de subj ectiver son discours en activant certaines modalites ou par la
conﬁguration enonciative des modalites qu’il active. Dans les exemples Tab. 2, la valeur Inise en
jeu « mentir » (modalite de jugement) intervient dans une strategie argumentative differente. Le
locuteur dissimule sa presence (conﬁguration implicite) et eventuellement sur-modalise l’eva-
luation en marquant qu’il s’agit d’une opinion ou d’une appreciation. Ces exemples ont un
impact different sur l’effet d’objectivite ou de subjectivite de l’enonce.

Exemple | Sur-modalité | Modalité
Je doute ’il mente faible

est ment
Oui,

   
   

    
     
 
 

   
   

Je n ’aime pas qu mente Jugement

TAB. 2 — Exemple de discours evaluatif different pour la meme valeur mentir

3.2 Langage évaluatif sur les blogs

A des ﬁns d’apprentissage et de test, nous annotons les evaluations exprimees dans un corpus
de blogs a partir d’un schema d’annotations en adequation avec les theories linguistiques pre-
sentees. Pour chaque evaluation annotee, nous precisons sa modalite, sa conﬁguration d’enon-
ciation, son axiologie et le concept evalue. Nous renvoyons a (Dubreil et al., 2008) pour une
description plus precise de la methodologie d’annotation. Le corpus d’entra'1‘nement annote
est compose de 200 billets de blogs associes aux commentaires postes par les lecteurs sur ce

Categorisation sémantico-discursive des évaluations dans la blogosphere

billet. Ils sont extraits automatiquement de la plateforme de blogs OverBlog et appartiennent

volontairement a des thématiques les plus variées possibles (actualité, artiste, faInille, gastrono-

mie, internet, santé, science, voyage, etc), en excluant les billets qui ne contiennent pas ou tres
peu de texte. 4945 passages évaluatifs ont ainsi été annotés manuellement. Par ailleurs, nous
constituons semi-manuellement trois ressources lexico-sémantiques :

— un lexique de l’évaluation (1115 entrées), développé par Sinequa (Stern, 2008), contenant
les termes évaluatifs fréquents dans le corpus, associées a leur catégorie grammaticale, leur
modalité, leur énonciation et leur axiologie. ex : machiste, chapeau bas, douter,

— un lexique de l’intensité (21 entrées) ex : particuliérement, trés,

— un lexique de la négation (15 entrées) ex : pas, aucun,

Le corpus d’entrainement et les ressources lexicales sont a la base de notre méthode pour

construire automatiquement une grammaire du langage évaluatif.

4 Méthode symbolique pour catégoriser les évaluations

Notre approche consiste a apprendre automatiquement les structures du langage qui sont spe-
ciﬁquement utilisées pour évaluer et utiliser la généricité des structures apprises pour détecter
et catégoriser les évaluations dans de nouveaux textes. Nous partons de l’idée de Chauraudeau
qu’il existe des structures lexicales, grammaticales et sémantiques pour chaque modalité d’éva-
luation. Par exemple, j’en doute et nous en sommes persuadés sont des évaluations de modalité
d’opinion généralisables car : douter et étre persuade’ ont la méme classe sémantique (verbes
marqueurs d ’opinion), je et nous ont la meme fonction grammaticale et impliquent explicite-
ment le locuteur.

4.1 Apprentissage automatique des structures évaluatives

Plateforme pour le TAL Nous tirons proﬁt de la plateforme pour le TAL UIMA1 pour
construire une chaine de traitements linguistiques. Cette plateforme permet de traiter des textes
non structurés et d’y aj outer des annotations dans un format normalisé assurant la réutilisabilité
des composants et l’échange des annotations entre composants.

Pré-traitements L’ apprentissage des structures évaluatives (Fig. 1) est réalisé a partir du cor-

pus d’entrainement annoté manuellement, présenté dans la section précédente. Les composants

de pré-traitements annotent des informations morpho-syntaxiques et sémantiques a partir de

ressources extérieures (TreeTagger et lexiques). Ces annotations portent sur des mots ou des

suites de mots, nous utilisons le terme abstrait symbole pour nommer ce niveau de granularité.

Des lors, le ﬂux de données qui transite entre composants est constitué d’une suite de symboles,

chacun associé a des traits :

— lexico-grammaticaux : forme, lemme (lem), catégorie grammaticale (pos),

— sémantiques : type (évaluation (eval), intensite’ (int), négation (neg), autre (mot)), moda-
lité (appréciation (app), opinion (op), accord-désaccord (acc)), conﬁguration d’énonciation
(exclamative (excl), explicite (exp), implicite) (imp), axiologie (positzf, négatif, ambigu).

1Unstructured Information Management Architecture : développée par IBM et Apache. http ://incuba-
tor.apache.org/ui1na/.

Vernier et al.

V‘ . . . .
ENTREE N Tn-..eTagger 503:1]; I
+ L¢xi'7l11*'-5 Grammairc :
stnmtunes évalilatives /4
Prér-traitemelnts xtractian des passags Génémlisaﬁan Cu K
m.orpho—syntzur.1qL1es eva1L1at1fs . .
. . . , stru::tL1res symboliques
prcgectlon ]ex1qL1es annotes ma11L1-ellemerlt

 

FIG. 1 — Chaine de traitements pour l’apprentissage de structures évaluatives

Chaines symboliques et généralisation A partir des 4945 passages évaluatifs annotés ma-
nuellement dans le corpus, et des chaines symboliques correspondantes, il s’agit de gagner en
généricité en spéciﬁant automatiquement les valeurs de trait qui peuvent étre substituées par
une autre valeurz, ceci aﬁn de repérer plus d’évaluations. La ﬁgure 2 représente la chaine de
symboles génériques construite a partir de l’exemple d’évaluation n’est-ce pas plus original.

forme ’X’ forme ’X’ forme ’X’ forme ’X’ foxme ’X’ forme ’Y’
lex lex lex , , lex lex lex

lem ’X’ lem ’étre’ lem ce lem ’X’ lem ’p1us’ lem ’Y’
gram [pos ’adv’] gram [pos ’ver’] gram [pos ’pm’] gram [pos ’adv’] gram [pos ’adv’] gram [pos ’adj’]
type ’neg’ type ’mot’ type ’mot’ type ’neg’ type ’mot’ type ’eval.’
m modal ’ ’ m modal ’ ’ m modal ’ ’ m modal ’ ’ m modal ’ ’ m modal ’app.’
Se conﬁg ’ ’ Se conﬁg ’ ’ Se conﬁg ’ ’ Se conﬁg ’ ’ Se conﬁg ’ ’ Se conﬁg ’imp.’
axiol ’ ’ axiol ’ ’ axiol ’ ’ axiol ’ ’ axiol ’ ’ axiol ’Y’

FIG. 2 — Structure générique extraite a partir de l’exemple n’est-ce pas plus original.

Nos regles de généralisation sont les suivantes :

Généralisation de la valeur des traits axiol, forme et de lemme (Y sur la ﬁg. 2) pour tous les
symboles de type évaluation et de modalité appréciation,

Généralisation de la valeur du trait lex (X sur la ﬁg. 2) pour certains symboles (adverbe,
pronom ...) ainsi que le trait lem pour les symboles de type adverbe

Ajout de l’opérateur standard * sur les symboles de type intensite’ et généralisation de la
valeur des traits forme et de lemme de ces symboles,

Ajout de l’opérateur standard + (une ou plusieurs fois) pour les symboles de conﬁg explicite
et de pos pronom et généralisation de la valeur des traits forme et de lemme de ces symboles.
Ce processus de création de structure générique permet de distinguer des tournures évaluatives
tres proches mais dont la signiﬁcation peut étre radicalement différente : n ’est-ce pas plus origi-
nal est positif, n’est pas plus original est négatif et ne semble pas plus original est négatif mais
avec une opinion de conviction moyenne. Le processus de généralisation permet également de
regrouper certaines évaluations ayant la meme structure évaluative (c’est génial, c’est super)
d’o1‘1 une réduction des 4945 structures annotées manuellement a 2830 structures apprises dans
notre grammaire.

Grammaire du langage évaluatif Nous stockons chaque structure évaluative générique ainsi
extraite dans une ressource au format XML. Pour chacune d’elle, le dernier composant de la
chaine ajoute des méta-données qui serviront lors de la catégorisation : le nombre d’occurences
de la structure dans le corpus d’entrainement, le nombre d’occurences par modalité, le nombre
d’occurences par conﬁguration d’énonciation et la tournure de la structure. Nous entendons par
tournure, le fait que certaines structures peuvent étre :

2Traits ayant pour valeur ’ ‘.7’ dans Fig.2

Categorisation semantico-discursive des evaluations dans la blogosphere

directes : pour notre plus grand plaisir, pour notre plus grand malheur,
inversives : loin d’étre génial, loin d’étre mauvais,

ﬁgées positives : faire taire la critique, marcher nickel,

ﬁgées négatives : équipe de bras cassé, c’est la 01) le bdt blesse.

4.2 Catégorisation semantico-discursive des évaluations

I1 s’agit ensuite d’uti1iser1a grammaire du langage evaluatif generee pour detecter et catego-
riser les evaluations dans de nouveaux textes.

   

ENTREE S3‘ Tr.ﬁ.-paggﬂ. Gramrnaire :  (“R -“E bi“
+ Lexiques srrL|crL|L'es ' i

( ex-';1lLI at ives  '=1U“""“

\‘ ‘I,
Pré-traitements Détection d,!S' Catégﬂrisaﬁan
mor;nho—syntaxiqL1es H» , 1 .f mo-d:1liIc',c’nonciation.,
projection 1-exiques passages em “an S ﬂliﬂlogiﬁ

FIG. 3 — Chaine de traitements pour la detection et la categorisation de structures evaluatives

Détection La tache de detection consiste a annoter les segments evaluatifs sans les catego-
riser. Nous considerons que ces segments sont d’un niveau intra-phrastique. Les phrases d’un
document sont donc traitees une par une. La strategie du composant de detection consiste a :

— extraire les symboles de la phrase (et leurs traits) pour constituer une chaine symbolique,

— tester 1’uniﬁcation des sous-chaines symboliques avec les structures apprises, en commengant

par les sous-chaines les plus longues possibles et par le debut de la phrase,

— creer une annotation 1orsqu’une chaine s’uniﬁe avec une structure (Si) de la grammaire.
Nous calculons un coefﬁcient de conﬁance pour cette tache a 1’aide des meta-donnees de Si
contenues dans la grammaire.

_ _ _ Eval(S
ad5t5Ctw”(S1) _ Eval(Si)+NonlEval(Si)
Eval(Si) : nombre d’occurrences dc Si annotees dans le corpus d’entrainement

N onEval(Si) : nombre d’occurrences dc Si non armotees dans le corpus d’entrainement

Catégorisation La categorisation consiste a determiner la modalite, la conﬁguration enoncia-
tive et 1’axio1ogie de 1’eva1uation detectee prealablement. Les meta-donnees de Si stockees dans
la grammaire permet de calculer la meilleure probabilite pour la modalite et1’enonciation :

_ Eval(Si,Mj)
O‘wtM0dalit6(Siv Mi) — Eval(Si,Mj)+NonEval(Si,Mj)

_ Eval (Si ,app1'eciation,C'Ej)
_ Eval (Si ,appvreciation,C'Ej ) +NonEval (Si ,app1'eciation,C'Ej)

acatC'onfigEnon  appreciation: 

Eval(Si, M j) : nombre d’occurrences dc Si dc modalite M j lors de d’entrainement
N onEval (Si, M j) : nombre d’occurrences dc Si d’une autre modalite lors de1’entrainement
Eval(Si, appreciation, C'Ej) : nombre d’occurrences dc Si dc type appreciation ayant une conﬁguration
d’enonciation C'Ej lors de d’entrainement

Vernier et al.

La toumure de 3, est donnee dans la grammaire, le composant determine alors l’aXiologie de
l’instance de 3, rencontree :

— structure directe : la polarite axiologique est identique a celle du symbole axiologise,

— structure inverse : la polarite axiologique est inverse a celle du symbole axiologise,

— structure ﬁgee : la polarite axiologique est indiquee dans les meta-donnees de la structure.
Par exemple, Pas la plus belle est inversive, belle est positif donc l’evaluation est negative.

5 Experiences et résultats

Corpus Test Aﬁn d’evaluer la detection et la categorisation des structures evaluatives, un
corpus test a ete elabore et annote en se focalisant essentiellement sur les modalites d’opinion,
d’accord-desaccord et d’appreciation3. Les billets de ce corpus test ont ete extraits a partir de
l’utilisation des mots cles suivants : Sarah Palin (25 billets) et Sushi (25 billets). Comme pour
le corpus d’entrainement, le corpus a ete annote manuellement par un linguiste avec les memes
contraintes : on denote 955 instances d’evaluation. Dans la suite, nous allons evaluer chaque
composant de notre outil de detection et categorisation des evaluations.

Detection des evaluations Dans un premier temps, nous evaluons l’etape de detection des
evaluations sur le corpus test, sachant que nous n’avons aucune connaissance lexicale en amont
sur ce corpus. Nous considerons une evaluation comme correctement detectee si l’evaluation
est correctement delimitee (meme delimitation manuelle) ou si l’une des deux bomes est erro-
nee a un ou deux mots d’ecarts par rapport a l’annotation manuelle (l’accord inter-annotateur
sur les bornes n’est pas representatif). Les structures symboliques apprises semblent etre des
indicateurs assez precis (88.4 % de precision) pour detecter les evaluations. Cependant de ma-
niere previsible, le rappel (50,1 %) chute fortement. Cela peut s’expliquer par la grande variete
orthographique presente dans les blogs pour accentuer les evaluations (ex : j’ad0000re), ou
par l’absence de connaissances semantiques sur des adjectifs evaluatifs non presents dans le
lexique de l’evaluation (ex .' te’le’ge’nique, puritaine) ou encore par la non connaissance de cer-
taines structures ﬁgees particulierement presentes dans les textes de Sarah Palin (ex : pittbull
aux levres rouges, ﬁbre écolo).

Tiiche Precision Rappel
DETECTION 88,4% (478/541) 50,1 % (478/955)
CATEGORISATION MODALITE - -

Opinion 88,0% (44/50) 100,0% (44/44)
Appreciation 100,0% (393/393) 99,0% (393/397)
Accord/Désaccord 100,0% (35/35) 94,6% (35/37)
CATEGORISATION CONFIG. ENONCIATIVE - -
Explicite 89,6% (60/67) 96,8% (60/62)
Implicite 97,6% (290/297) 97,9% (290/296)
Exclamative 100,0% (29/29) 82,9% (29/35)
CATEGORISATION AXIOLOGIQUE - -
Favorable 93,3% (279/299) 97,6% (279/286)
Défavorable 96,5% (83/86) 77,6% (83/107)
Ambigué 8 occurences

TAB. 3 — Mesure des resultats obtenus par l’outil d’analyse des blogs sur le corpus test.

Categorisation de la modalite Dans un deuxieme temps, nous evaluons l’outil de categori-
sation a partir des evaluations correctement detectees. Nous observons (voir ﬁg. 3) qu’il y a tres

3Nous regroupons les jugements et les appreciations sous cette modalite de par leur forte proximite semantique.

Categorisation semantico-discursive des evaluations dans la blogosphere

peu d’ambigu'1'te entre les differentes modalites annotees. Les structures et les entites lexicales
qui composent ces differents types d’evaluation sont assez bien distincts. De ce fait, les resultats
obtenus sont presque maximaux et viennent corroborer les deﬁnitions theoriques donnees par
Charaudeau.

Catégorisation de la conﬁguration d’énonciation La tache de categorisation de la conﬁgu-
ration d’enonciation des appreciations fournit de bons resultats (voir Tab.3). On ne s’interesse
ici qu’aux appreciations correctement detectees. Comme pour les modalites, les structures sym-
boliques sont particulierement differentes entre les appreciations implicites et explicites. En
effet, l’absence de pronoms ou de verbes d’appreciation implique souvent le fait que l’appre-
ciation soit implicite. L’ ambigu'1'te se situe plutot sur les appreciations exclamatives puisque
souvent une phrase exclamative ne contient pas qu’une seule appreciation d’o1‘1 la difﬁculte de
rattacher l’exclamation a une seule ou toutes les appreciations.

Catégorisation axiologique La tache de categorisation axiologique des appreciations correc-
tement detectees fournit egalement des resultats encourageants (voir ﬁg.3). Suite a la phase
d’entrainement, nous avions constate qu’il y avait en effet peu d’ambigu'1'tes entre une tournure
inversive et une tournure directe des structures symboliques. Les resultats montrent toutefois
que le rappel des appreciations defavorables est plus faible, ce qui est dﬁ essentiellement a
des structures inversives non apprises (ex : ce n’est pas chose facile) et a la presence de cas
d’evaluations ironiques (ex : Toujours aussi passionnant).

6 Conclusion et perspectives

L’ outil de categorisation des evaluations est tres satisfaisant. Le plus difﬁcile reste la detec-
tion de celles ci, necessitant notamment une amelioration automatique de la couverture lexicale.
Pour realiser cet objectif, nous envisageons une methode non supervisee pour apprendre de nou-
veaux termes et de nouvelles expressions ﬁgees utilisees pour evaluer. L’association frequente
d’un terme ou d’une expression avec certaines structures grammaticales apprises (ex : c’est un
véritable + NOM) est un indice permettant d’induire leur role evaluatif. En s’inspirant de Hat-
zivassiloglou et McKeown (1997), il est egalement possible de determiner automatiquement
la polarite axiologique des termes ainsi extraits. Un deuxieme axe de perspectives consiste a
rechercher le concept sur lequel porte l’evaluation en cherchant les groupes nominaux ou les
noms propres les plus pertinents dans le co-texte selon un algorithme proche de la resolution
d’anaphore. La methode symbolique pour la fouille d’opinion presentee dans cet article permet
de detecter et categoriser l’axiologie positive ou negative et le role discursif des evaluations ex-
primees localement dans les blogs avec une bonne precision. La grammaire du langage evaluatif
construite automatiquement contient environ 2800 regles et permet de faire la distinction entre
des structures evaluatives assez proches pouvant induire en erreur les approches sac-de-mots
classiques en fouille d’opinion. Les regles de grammaire et les ressources lexicales developpees
peuvent ainsi etre appliquees sur des corpus dont la thematique n’est pas ﬁxee en amont sans
perdre en precision. Ces travaux s’inscrivent dans le projet BLOGOSCOPIE, soutenu par le
programme Technologies Logicielles 2006 de l’ANR et realise en collaboration avec Syllabs,
Sinequa et Over-Blog.

Vernier et al.

Références

ANSCOMBRE J. & DUCROT O. (1983). L’argumentation dans la langue. Pierre Mardag.

AUE A. & GAMON M. (2005). Customizing sentiment classiﬁers to new domains : A case
study. In Recent Advances in Natural Language Processing (RANLP).

BLITZER J ., DREDZE M. & PEREIRA F. (2007). Biographies, Bollywood, boom-boxes and
blenders : Domain adaptation for sentiment classiﬁcation. In Proceedings of the 45th Annual
Meeting of the Association for Computational Linguistics (ACL 2007), p. 440-447.

CHARAUDEAU P. (1992). Grammaire du sens et de l ’expression. Hachette Education, COM-
MUNICATION, PARA UNIVERSITAIRE.

DAVE K., LAWRENCE S. & PENNOCK D. M. (2003). Mining the peanut gallery : Opinion
extraction and semantic classiﬁcation of product reviews. In Proceedings of the 12th World
Wide Web Conference (WW 2003), p. 519-528.

DUBREIL E., VERNIER M., MONCEAUX L. & DAILLE B. (2008). Annotating opinion -
evaluation of blogs. In Workshop of LREC 2008 Conference, Sentiment Analysis .' Metaphor,
Ontology and Terminology ( EM OT-08 ), p. 124.

GALATANU O. (2000). Signiﬁcation, sens, formation. In Education et Formation, Biennales
de l’éducation, (sous la direction de Jean-Marie Barbier, d ’0lga Galatanu), Paris : PUF.

HU M. & LIU B. (2004). Mining opinion features in customer reviews. In Proceedings of
the 19th National Conference on Artiﬁcial Intelligence, p. 755-760 : AAAI Press / The MIT
Press.

KERBRAT-ORECCHIONI C. (1997). L’énonciation, de la subjectivite’ dans le langage. Colin
(edition 2002).

LAVELLE L. (1950). Traite’ des valeurs, volume tome 1. PUF.

MARTIN J . & WHITE P. (2005). The Language of Evaluation, Appraisal in English. Palgrave
Macmillan.

MAUREL S., CURTONI P. & DINI L. (2008). L’analyse des sentiments dans les forums. In
actes de l ’atelier F ODOP ’08 (fouille de données d ’opinions) (INF ORSID ’08 ), p. 111-117.
MISHNE G. & GLANCE N. (2006). Predicting movie sales from blogger sentiment. In AAAI
Symposium on Computational Approaches to Analysing Weblogs (AAAI-CAAW), p. 155-158.
MULLEN T. & MALOUF R. (2006). A preliminary investigation into sentiment analysis of
informal political discourse. In AAAI Symposium on Computational Approaches to Analysing
Weblogs (AAAI-CAAW), p. 159-162.

NIGAM K. & HURST M. (2006). Towards a robust metric of polarity. In J . G. SHANAHAN,
Y. QU & J . WIEBE, Eds., Computing Attitude and Ajfect in Text .' Theories and Applications,
number 20 in the Information Retrieval Series : Springer.

PANG B., LEE L. & VAITHYANATHAN S. (2002). Thumbs up ? sentiment classiﬁcation using
machine learning techniques. In Proceedings of the Conference on Empirical Methods in
Natural Language Processing (EMNLP 2002), p. 79-86.

STERN R. (2008). Constitution d’un lexique de sentiment. In Me’moire de Master de Recherche
Linguistique-Informatique : Université Paris 7.

WHITELAW C., GARG N. & ARGAMON S. (2005). Using appraisal groups for sentiment

analysis. In Proceedings of the ACM SIGIR Conference on Information and Knowledge Ma-
nagement (CIKM), p. 625-631 : ACM.

