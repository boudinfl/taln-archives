<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Exploitation d&#8217;une structure pour les questions encha&#238;n&#233;es</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009 &#8211; Session posters , Senlis, 24&#8211;26 juin 2009
</p>
<p>Exploitation d&#8217;une structure pour les questions encha&#238;n&#233;es
</p>
<p>K&#233;vin S&#233;journ&#233;
Universit&#233; de Paris Sud XI, Limsi/CNRS
</p>
<p>kevin.sejourne@limsi.fr
R&#233;sum&#233;. Nous pr&#233;sentons des travaux r&#233;alis&#233;s dans le domaine des syst&#232;mes de ques-
tions r&#233;ponses (SQR) utilisant des questions encha&#238;n&#233;es. La recherche des documents dans un
SQR est perturb&#233;e par l&#8217;absence des &#233;l&#233;ments utiles &#224; la recherche dans les questions li&#233;es,
&#233;l&#233;ments figurant dans les &#233;changes pr&#233;c&#233;dents. Les r&#233;centes campagnes d&#8217;&#233;valuation montrent
que ce probl&#232;me est sous-estim&#233;, et n&#8217;a pas fait l&#8217;objet de technique d&#233;di&#233;e. Afin d&#8217;am&#233;liorer
la recherche des documents dans un SQR nous utilisons une m&#233;thode r&#233;cente d&#8217;organisation
des informations li&#233;es aux interactions entre questions. Celle-ci se base sur l&#8217;exploitation d&#8217;une
structure de donn&#233;es adapt&#233;e &#224; la transmission des informations des questions li&#233;es jusqu&#8217;au
moteur d&#8217;interrogation. Le moteur d&#8217;interrogation doit alors &#234;tre adapt&#233; afin de tirer partie de
cette structure de donn&#233;es.
</p>
<p>Abstract. We present works realized in the field of the questions answering (QA) using
chained questions. The documents search in QA system is disrupted because useful elements
are missing for search using bound questions. Recents evaluation campaigns show this problem
as underestimated, and this problem wasn&#8217;t solve by specific techniques. To improve docu-
ments search in a QA we use a recent information organization method for bound questions
to the interactions between questions. This methode is bases on the operation of a special data
structure. This data structure transmit informations from bound questions to the interrogation
engine. Then the interrogation engine must be improve to take advantage of this data structure.
</p>
<p>Mots-cl&#233;s : Question r&#233;ponse encha&#238;n&#233;e.
Keywords: chained question answering.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>K&#233;vin S&#233;journ&#233;
</p>
<p>1 Introduction
</p>
<p>Dans la foul&#233;e des syst&#232;mes de r&#233;ponse &#224; des questions, il a &#233;t&#233; envisag&#233; de consid&#233;rer qu&#8217;un
utilisateur &#233;tait susceptible de poser plusieurs questions sur une m&#234;me th&#233;matique, des ques-
tions qui donc s&#8217;encha&#238;nent les unes aux autres. Ainsi, chaque question doit &#234;tre interpr&#233;t&#233;e en
connaissance de l&#8217;historique des questions et des r&#233;ponses pr&#233;c&#233;dentes. Il y a eu r&#233;cemment
plusieurs campagnes d&#8217;&#233;valuation de syst&#232;mes de questions r&#233;ponses (SQR) o&#249; des questions
encha&#238;n&#233;es &#233;taient propos&#233;es. Selon les corpus, les questions encha&#238;n&#233;es peuvent faire r&#233;f&#233;rence
&#224; un contexte global (ou sujet global) pr&#233;alablement introduit comme ce fut le cas dans la cam-
pagne d&#8217;&#233;valuation TREC (Zhou et al., 2006). Elles peuvent aussi faire r&#233;f&#233;rence aux r&#233;ponses
pr&#233;c&#233;dentes ou avoir de multiples r&#233;f&#233;rences vers d&#8217;autres questions. Les questions encha&#238;-
n&#233;es peuvent pr&#233;senter toutes ces difficult&#233;s sans les annoncer explicitement, comme dans la
campagne d&#8217;&#233;valuation des SQR Clef07 (Penas et al., 2007) ; la premi&#232;re question peut m&#234;me
parfois avoir le r&#244;le d&#8217;un introducteur de contexte. Le tableau 1 montre un exemple de groupe
de questions encha&#238;n&#233;es. On voit sur cet exemple que pour r&#233;pondre aux questions 2, 3 ou 4, il
faut conna&#238;tre le contexte pos&#233; par les questions pr&#233;c&#233;dentes. Parfois les SQR sont inter-lingues,
c&#8217;est-&#224;-dire que la langue des questions est diff&#233;rente de la langue des documents dans lesquels
on cherche la r&#233;ponse, comme c&#8217;&#233;tait le cas pour une des pistes de la campagne Clef07. C&#8217;est
le corpus de cette campagne que nous utilisons par la suite dans cet article.
</p>
<p>Le syst&#232;me Musclef (figure 1) d&#233;velopp&#233; au Limsi, et qui a particip&#233; aux pr&#233;c&#233;dentes cam-
pagnes classiques de Questions-R&#233;ponses, a globalement une architecture semblable aux SQR
classiques. C&#8217;est lui qui nous sert de base pour tester ces nouvelles conditions. Le probl&#232;me que
nous nous posons est alors de savoir utiliser aux mieux les informations des d&#233;pendances entre
questions pour am&#233;liorer la recherche des documents, des phrases et ainsi des r&#233;ponses.
</p>
<p>Dans cet article nous pr&#233;senterons d&#8217;abord la structure que nous construisons afin de d&#233;crire les
interactions entre des questions. Nos r&#233;sultats vont d&#233;pendre des performances de cette &#233;tape.
Ensuite, nous pr&#233;senterons une m&#233;thode de pond&#233;ration dynamique des termes des documents
dans un moteur de recherche pour la r&#233;solution de questions encha&#238;n&#233;es.
</p>
<p>2 Analyse des questions encha&#238;n&#233;es
</p>
<p>Nous devons d&#8217;abord trouver les d&#233;pendances entre les questions d&#8217;un m&#234;me groupe, et pour
cela &#233;tudier les diff&#233;rents ph&#233;nom&#232;nes linguistiques qui permettent d&#8217;inf&#233;rer leur pr&#233;sence sans
</p>
<p> ( I ) 
 ( II ) 
</p>
<p> ( III ) 
</p>
<p>Questions
en fran&#231;ais
</p>
<p>Traduction
en anglais
</p>
<p>   Focus 
   Type de la r&#233;ponse
</p>
<p>   Termes reli&#233;s s&#233;mantiquement
</p>
<p>   Verbe principal 
   Termes
</p>
<p>   Relations syntaxiques
</p>
<p>Analyse de la question  
</p>
<p>Termes
en anglais
</p>
<p>Fusion
de r&#233;ponses
</p>
<p>2 listes tri&#233;es
R&#233;ponses
en anglais
</p>
<p>Questions
en anglais
</p>
<p>(a)
</p>
<p>   S&#233;lection
   Marquage des EN
</p>
<p>Extraction de la r&#233;ponse
</p>
<p>   R&#233;&#8722;indexation et tri
</p>
<p>   Pond&#233;ration des phrases
</p>
<p>Traitement des documents
</p>
<p>(b)
   Extraction de la r&#233;ponse
</p>
<p>   
</p>
<p>Collection
</p>
<p>recherche
de
</p>
<p>Moteur
</p>
<p>FIG. 1 &#8211; Architecture du syst&#232;me Musclef en mode inter-lingue</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Exploitation d&#8217;une structure pour les questions encha&#238;n&#233;es
</p>
<p>Groupe{Nil}
</p>
<p>q1 O&#249; se trouve le mus&#233;e de l&#8217;Ermitage ? Saint-Petersbourg
</p>
<p>q2 Qui &#233;tait le directeur du mus&#233;e en 1994 ? Nilq3 Dans quel palais le mus&#233;e est-il log&#233; ? Palais d&#8217;Hiver
</p>
<p>q4 Combien de chambre y a-t-il dans ce palais ? 400 salles
</p>
<p>FIG. 2 &#8211; L&#8217;arbre correspondant au groupe du tableau 1
</p>
<p>1 O&#249; se trouve le mus&#233;e de l&#8217;Ermitage ?
2 Qui &#233;tait le directeur du mus&#233;e en 1994 ?
3 Dans quel palais le mus&#233;e est-il log&#233; ?
4 Combien de chambres y a-t-il dans ce palais ?
</p>
<p>TAB. 1 &#8211; Exemple d&#8217;un groupe de questions encha&#238;n&#233;es tir&#233;es du corpus utilis&#233; pour la cam-
pagne d&#8217;&#233;valuation CLEF 2007.
</p>
<p>trop de bruit (c&#8217;est-&#224;-dire de fausses d&#233;pendances). Pour am&#233;liorer la recherche dans les do-
cuments, nous devons repr&#233;senter les d&#233;pendances entre les questions d&#8217;un m&#234;me groupe. En
s&#8217;inspirant des travaux sur les structures de dialogue (Vilnat, 2005)(van Schooten &amp; op den
Akker, 2006), de la nature s&#233;quentielle des groupes de questions et du partage des termes des
questions d&#233;j&#224; r&#233;solues du groupe, il a &#233;t&#233; propos&#233; dans (S&#233;journ&#233;, 2008) d&#8217;organiser un groupe
de questions en un arbre (figure 2) repr&#233;sentant les liens entre les diff&#233;rentes questions d&#8217;un
groupe.
</p>
<p>&#192; sa racine nous trouvons le contexte commun &#224; toutes les questions dans un n&#339;ud nomm&#233;
groupe. Le contexte est compos&#233; d&#8217;une liste d&#8217;&#233;l&#233;ments faisant &#233;ventuellement r&#233;f&#233;rence &#224; la
r&#233;ponse. &#192; chaque autre n&#339;ud sont indiqu&#233;s une question et son contexte propre. La structure
de l&#8217;arbre traduit les d&#233;pendances qui sont identifi&#233;es.
</p>
<p>La structure d&#8217;arbre permet de repr&#233;senter efficacement les groupes o&#249; les questions ne re-
prennent que le contexte issu de la premi&#232;re question. L&#8217;ajout des &#233;l&#233;ments d&#8217;informations utiles
&#224; la recherche d&#8217;information &#224; chaque n&#339;ud permet une repr&#233;sentation homog&#232;ne des groupes
o&#249; les questions r&#233;utilisent des contextes li&#233;s les uns aux autres. Les questions qui comme la
premi&#232;re, ne r&#233;utilisent pas le contexte des pr&#233;c&#233;dentes, sont rattach&#233;es au n&#339;ud groupe. Il
permet &#233;galement de recevoir des &#233;l&#233;ments contraignant l&#8217;espace de recherche exprim&#233;e hors
question &#224; la mani&#232;re des &#233;valuations de Trec 2006 1 (Hickl et al., 2006).
Nous pr&#233;sentons maintenant la m&#233;thode utilis&#233;e pour trouver les d&#233;pendances entre les ques-
tions d&#8217;un m&#234;me groupe. Nous pouvons formaliser la probabilit&#233; d&#8217;existence d&#8217;une d&#233;pendance
en un calcul d&#8217;argMax sur une collection de traits. Soit &#945; et &#946; deux couples de questions et r&#233;-
ponses. Soit &#915; l&#8217;ensemble des termes que l&#8217;utilisateur doit fournir dans ces 2 questions pour que
la r&#233;ponse &#224; &#946; puisse &#234;tre trouv&#233;e. &#915; d&#233;pend des strat&#233;gies du SQR utilis&#233; ainsi que des corpus
de documents dans lesquels la r&#233;ponse est cherch&#233;e. La probabilit&#233; P &#224; calculer est l&#8217;existence
</p>
<p>1Un contexte &#233;tait donn&#233; explicitement pour chaque groupe de questions.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>K&#233;vin S&#233;journ&#233;
</p>
<p>de l&#8217;&#233;v&#232;nement : &#946; est une sous-partie de &#915; strictement plus petite que &#915;. Notons que m&#234;me si
&#915; n&#8217;est pas optimum (l&#8217;utilisateur pourrait fournir plus d&#8217;informations), rien n&#8217;emp&#234;che d&#8217;avoir
suffisamment d&#8217;information pour que la probabilit&#233; d&#8217;association d&#8217;une d&#233;pendance soit maxi-
malement correcte. Soit &#936; une collection de traits munis d&#8217;une fonction d&#8217;&#233;valuation (type de la
question, cat&#233;gorie, ou des combinaisons plus complexes, traits issus de l&#8217;analyse de la question
comme illustr&#233; sur la figure 1) permettant de d&#233;crire l&#8217;apport et la capacit&#233; d&#8217;unification de &#946;
dans &#915;. Alors P est la somme des plus grandes possibilit&#233;s d&#8217;apport et capacit&#233; d&#8217;unification,
soit :
P&#945;&#946; = argMax(&#931;T i&#8712;&#936;eval(Ti, &#945;&#946;))
</p>
<p>C&#8217;est une simplification de la m&#233;thode pr&#233;sent&#233;e dans (S&#233;journ&#233;, 2008). Il est alors plus simple
de d&#233;finir une strat&#233;gie utilisant un seuil de probabilit&#233; de correction, en dessous duquel nous
d&#233;cidons que la d&#233;pendance n&#8217;existe pas. Le calcul des d&#233;pendances via &#936; est ax&#233; sur les infor-
mations disponibles dans les SQR classiques, puisqu&#8217;il r&#233;utilise directement les traits issus de
l&#8217;analyse de la question.
</p>
<p>Nous avons utilis&#233; les m&#234;mes traits pour nourrir l&#8217;algorithme g&#233;n&#233;rique de construction des d&#233;-
pendances. Nous avons ajout&#233; un trait concernant les r&#233;p&#233;titions de segments de texte communs
&#224; deux questions. Un apprentissage nous a permis de d&#233;terminer que la pr&#233;sence de segments
communs de plus de 15 caract&#232;res qui ne sont en position pr&#233;fixe ni dans l&#8217;une ni dans l&#8217;autre,
tend &#224; montrer qu&#8217;il n&#8217;y a pas de d&#233;pendance unitaire entre les deux questions.
Quand l&#8217;homme politique irlandais Willie O&#8217;Dea est-il n&#233; ?
O&#249; l&#8217;homme politique irlandais Willie O&#8217;Dea est-il n&#233; ?
Le syst&#232;me effectue donc une recherche du plus long segment commun entre les deux questions,
puis il teste sa longueur et celles des pr&#233;fixes, pour &#233;liminer les cas expos&#233;s pr&#233;c&#233;demment. Ce
crit&#232;re est utilis&#233; en compl&#233;ment des autres crit&#232;res.
</p>
<p>Nous avons aussi re-utilis&#233; la m&#234;me m&#233;thode d&#8217;&#233;valuation, et le m&#234;me corpus de question
(Clef@QA2007). Des r&#233;ponses &#224; des questions en fran&#231;ais sont cherch&#233;es dans des documents
en anglais.2 Soit &#171;Commun&#187; l&#8217;ensemble des d&#233;pendances communes &#224; l&#8217;ensemble des d&#233;pen-
dances annot&#233;es &#171; &#224; la main &#187; et &#224; l&#8217;ensemble de d&#233;pendances trouv&#233;es par le syst&#232;me. Le rappel
est alors calcul&#233; en prenant le rapport de &#171; Commun &#187; sur le nombre total de d&#233;pendances an-
not&#233;es. La pr&#233;cision est calcul&#233;e en prenant le rapport de &#171; Commun &#187; sur le nombre total de
questions en rang au moins deux d&#8217;un groupe. 3 L&#8217;ajout de ce trait &#224; ceux utilis&#233;s pr&#233;c&#233;demment
permet une d&#233;tection des d&#233;pendances unitaires avec une F-mesure d&#8217;environ 0.8 pour un rappel
de 0.739 et une pr&#233;cision de 0.883. C&#8217;est un gain de 11% en terme de F-mesure li&#233; &#224; un gain en
pr&#233;cision et en rappel. Nous pouvons alors construire la structure d&#8217;arbre pr&#233;sent&#233;e ci-dessus en
fonction des d&#233;pendances ainsi calcul&#233;es, c&#8217;est cette structure qui constituera le contexte dans
la suite de ce texte.
</p>
<p>3 Moteur de recherche
</p>
<p>Pour trouver dans la collection de r&#233;f&#233;rence, les documents susceptibles de contenir la r&#233;ponse &#224;
une question pos&#233;e, nous utilisons des moteurs de recherche &#224; base de r&#233;alisation d&#8217;une fonction
</p>
<p>2Ce corpus contient 53 groupes d&#8217;au moins 2 questions dont 133 questions en position au-del&#224; de 2, et une
majorit&#233; de groupe de 4 questions(37). L&#8217;annotation &#171;&#224; la main&#187; r&#233;v&#232;le 96 d&#233;pendances.
</p>
<p>3La F-mesure est calcul&#233;e par la formule : (P &#8727; rappel &#8727; pre&#769;cision)/(rappel + pre&#769;cision) Nous avons
choisis P = 2 pour nos &#233;valuations.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Exploitation d&#8217;une structure pour les questions encha&#238;n&#233;es
</p>
<p>de score. Les documents sont alors ordonn&#233;es et les n meilleurs s&#233;lectionn&#233;s. La pond&#233;ration
consiste &#224; attribuer un poids &#224; chaque terme utilis&#233; pour la recherche, qu&#8217;il provienne de la ques-
tion consid&#233;r&#233;e ou d&#8217;un couple question-r&#233;ponse dont il d&#233;pend, en faisant varier leur influence
dans le score total en fonction de leur position dans la structure de d&#233;pendance. Il n&#8217;est pas
&#233;vident de choisir une pond&#233;ration qui a priori aurait des propri&#233;t&#233;s correctes pour chaque type
de terme, qu&#8217;il soit issu de la requ&#234;te, d&#8217;un document, d&#8217;une traduction, de l&#8217;ajout de synonymes
de termes de la question.
</p>
<p>Choix de la corr&#233;lation des termes. En nous appuyant sur la structure de d&#233;pendance calcul&#233;e
pr&#233;c&#233;demment, nous proposons de r&#233;aliser des tests de corr&#233;lation des termes d&#8217;un niveau &#224;
l&#8217;autre. Il s&#8217;agit de prendre deux termes de niveaux contigus dans l&#8217;arbre et de regarder s&#8217;ils sont
pr&#233;sents simultan&#233;ment dans un document. Le principe est ensuite g&#233;n&#233;ralis&#233; aux arbres ayant
un nombre quelconque de niveaux. Pour chaque terme d&#8217;un niveau, il faut regarder s&#8217;il existe
au moins un terme de chaque niveau dont il d&#233;pend avec lequel il est pr&#233;sent dans le document
dont il faut calculer le score. Des tests incr&#233;mentaux par niveau de la pr&#233;sence simultan&#233;e des
termes servent alors de pond&#233;ration implicite et dynamique.
</p>
<p>3.1 Utilisation pour la recherche des documents.
</p>
<p>Formes possibles de la g&#233;n&#233;ralisation. Cette g&#233;n&#233;ralisation peut prendre plusieurs formes. Il
est possible de choisir que tous les termes des niveaux pr&#233;c&#233;dents soient pr&#233;sents, mais comme
les strat&#233;gies de s&#233;lection et extension de termes ajoutent de nombreux mots clefs de sens voisins
dans la requ&#234;te, il est peu probable d&#8217;obtenir un effet satisfaisant. Il est possible de choisir que
seule contribuera au score du document, soit la plus grande corr&#233;lation de termes soit chaque
sous corr&#233;lation de termes. Il est possible d&#8217;&#233;liminer arbitrairement les documents ne pr&#233;sentant
aucun terme d&#8217;un rang donn&#233;, mais l&#8217;impact des termes de rang inf&#233;rieur est ignor&#233; et la r&#233;sis-
tance au glissement de sujet est inf&#233;rieure. Il est possible d&#8217;oublier le contexte de rang sup&#233;rieur
&#224; un rang o&#249; aucun document ne poss&#232;de au moins un terme de ce rang etc ...
</p>
<p>Score &#224; base de somme de corr&#233;lation La corr&#233;lation des termes rang &#224; rang avec une g&#233;n&#233;-
ralisation et une contribution au score pour chaque sous corr&#233;lation de termes poss&#232;de d&#8217;autres
avantages. 4.
</p>
<p>1) Tailles des groupes : Un terme n&#8217;est effectivement pris en compte que s&#8217;il existe au moins
un document contenant au moins un exemplaire de terme pour chaque rang du contexte. Jamais
un terme de rang n ne peut prendre plus d&#8217;importance relative que la totalit&#233; des termes de
rang n &#8722; 1. La taille des groupes de termes pour chaque rang du contexte &#224; un impact moins
important que dans les strat&#233;gies de pond&#233;rations par rang du contexte.
</p>
<p>2) Divergence de score : Si la g&#233;n&#233;ralisation aboutit, alors cette m&#233;thode r&#233;sout les probl&#232;mes
li&#233;s &#224; la pond&#233;ration. La pond&#233;ration est exprim&#233;e en fonction des termes. La divergence est
alors contr&#244;l&#233;e par la pr&#233;sence corr&#233;l&#233;e des termes dans les documents. Le terme d&#8217;une ques-
tion ne sera jamais &#233;cras&#233; par un gros coefficient, car ou bien les termes devront &#234;tre pr&#233;sents
simultan&#233;ment ou bien ils ne comptent pas. La pr&#233;sence corr&#233;l&#233;e est en elle-m&#234;me une garantie
de pond&#233;ration qui respecte le crit&#232;re de divergence.
</p>
<p>4Nous faisons l&#8217;hypoth&#232;se que la strat&#233;gie de s&#233;lection des termes dispose d&#8217;un maximum(soit m ce maximum)
dans le nombre de termes par rang s&#233;lectionn&#233;. Pour les calculs de convergence nous faisons l&#8217;hypoth&#232;se que m
est aussi une valeur cible pour le nombre de termes &#224; s&#233;lectionner dans la strat&#233;gie de s&#233;lection de termes. m n&#8217;est
utilis&#233; qu&#8217;&#224; la section suivante.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>K&#233;vin S&#233;journ&#233;
</p>
<p>3.2 Construction du scoring par cooccurence.
</p>
<p>La m&#233;trique du TfxIdf peut &#234;tre d&#233;clin&#233;e en diff&#233;rentes variantes. Nous pouvons trouver les plus
utilis&#233;es dans (Manning et al., 2008). Nous noterons :
&#8211; #Term(t,D) = Nombre d&#8217;occurrences du terme &#171;t&#187; dans le document D. (#Term)
&#8211; #Docs(t) = Nombre de documents pr&#233;sentant au moins une occurrence du terme &#171;t&#187; dans
</p>
<p>une collection donn&#233;e. (#Docs)
&#8211; N = Nombre total de document dans la collection.
Notre m&#233;thode consiste &#224; modifier la mani&#232;re dont le score est calcul&#233; de mani&#232;re &#224; tenir compte
de la pr&#233;sence simultan&#233;e des termes de la question et du contexte dans les documents. Nous
faisons l&#8217;hypoth&#232;se qu&#8217;un terme d&#8217;un contexte utilis&#233; sans aucun terme de la question a moins
de valeur qu&#8217;un terme trouv&#233; de la question sans son contexte.
</p>
<p>Une variante du TFxIDF. Le Tf5 est construit sur la base de la fr&#233;quence des termes dans
un document. l&#8217;Idf6 est construit sur la base du nombre de documents contenant un terme par
rapport au nombre total de documents. Le score est construit de cette mani&#232;re Score(Q,D) =
&#931;ti&#8712;QTf &#8727; Idf . Souvent une m&#233;thode de normalisation est ajout&#233;e pour rem&#233;dier aux disparit&#233;s
de longueur des documents et de dispersion des termes (Salton &amp; Buckley, 1988). Comme nous
ne cherchons pas seulement un terme x, mais des corr&#233;lations de termes, nous devons calculer
une valeur fond&#233;e sur le nombre de documents contenant un terme de la question et des termes
du contexte par rapport au nombre total de documents. Pour un m&#234;me document, il faut tenir
compte des risques d&#8217;absences et de mauvais choix des termes. Ces risques sont importants pour
les termes du contexte dont l&#8217;erreur r&#233;elle d&#233;pend aussi de la d&#233;tection des d&#233;pendances entre
les questions. Il nous faut donc &#233;tendre le TfxIdf, pour tenir compte des niveaux du contexte.
</p>
<p>La &#171;partie&#187; Tf est augment&#233;e avec les cooccurrences &#233;ventuelles des termes dans le document
tout en tenant compte des erreurs faites &#224; la d&#233;termination des termes. La &#171;partie&#187; Idf est r&#233;duite
pour tenir compte de la quantit&#233; de documents qui pr&#233;sente ces m&#234;mes cooccurrences. Soit tij
le terme de rang du contexte i qui est le j-ieme de son niveau. Si i = 0 alors il s&#8217;agit d&#8217;un terme
de la question. Soit nombreDeRangs le nombre de rang du contexte.
</p>
<p>Construisons un indicateur de la fr&#233;quence des termes de la question et du contexte dans un
document, le Tf &#8242;. Nous accordons de l&#8217;importance &#224; un terme du contexte de rang n unique-
ment si un terme du contexte du rang n &#8722; 1 est pr&#233;sent dans le document. Cela se fait selon
l&#8217;algorithme suivant :
</p>
<p>freq(t,D) = 1/#Term | #Term &gt; 0 et freq(t,D) = 0 | #Term = 0 .
</p>
<p>Construisons l&#8217;indicateur de fr&#233;quence des d&#233;pendances comme un syst&#232;me de fr&#233;quence des
termes d&#8217;un rangs pond&#233;r&#233; par les fr&#233;quences des termes pr&#233;c&#233;dents.
</p>
<p>Tf &#8242;(D) =
&#8730;
&#931;i
1
&#928;i
1
&#928;j
1
(freq(ti,j , D) + 1)&#8722; nombreDeRangs
</p>
<p>&#8214;i &#8712; rangs du contexte , j &#8712; terme du rang(i)
</p>
<p>C&#8217;est la somme des produits des fr&#233;quences d&#8217;un rang par le produit des fr&#233;quences des sous
rangs, donc une corr&#233;lation niveau &#224; niveau.
</p>
<p>Nous commen&#231;ons par calculer l&#8217;impact pour les termes de rang 1, nous r&#233;alisons un produit
des fr&#233;quences (au sens d&#233;fini ci-dessus) pour obtenir un impact global pour le rang. Par rapport
</p>
<p>5Tf(ti,D) = 1/(#Term(ti,D))
6Idf(ti) = log(N) &#8722; log(1 + #Docs(ti))</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Exploitation d&#8217;une structure pour les questions encha&#238;n&#233;es
</p>
<p>au Tf traditionnel, chaque rang est trait&#233; comme s&#8217;il s&#8217;agissait d&#8217;un terme unique, mais chaque
rang est pond&#233;r&#233; non pas par une valeur fixe, mais par le produit des fr&#233;quences de tous les
sous-rangs pr&#233;c&#233;dents. Il en r&#233;sulte que moins les termes des premiers rangs sont pr&#233;sents,
moins l&#8217;impact des termes des rangs les plus anciens est important. Notons que si un terme de
rang n est absent, alors il repr&#233;sente un &#233;l&#233;ment neutre pour l&#8217;op&#233;ration de multiplication &#928;. Si
tous les termes de rang n sont absents, leur impact est exactement compens&#233; par la soustraction
finale par le nombre de rangs. Par exemple pour un contexte de profondeur 3 avec m = 2 nous
obtenons le d&#233;veloppement suivant :
</p>
<p>Soit tp,q le q-i&#232;me terme du p-i&#232;me rang et freq(x, D) + 1 = f(x) alors
Tf &#8242;(D)2 + 3 = f(t1,1) &#8727; f(t1,2)
</p>
<p>+f(t1,1) &#8727; f(t1,2) &#8727; f(t2,1) &#8727; f(t2,2)
+f(t1,1) &#8727; f(t1,2) &#8727; f(t2,1) &#8727; f(t2,2) &#8727; f(t3,1) &#8727; f(t3,2)
</p>
<p>Il est alors &#233;vident que les i &#8722; 1|i &#8712; rangs du contexte premiers termes du produit des rangs
agissent comme une pond&#233;ration d&#233;finie dynamiquement.
</p>
<p>Construisons un indicateur de la fr&#233;quence des documents poss&#233;dant des termes corr&#233;l&#233;s, l&#8217;Idf &#8242;7.
Soit &#8857; l&#8217;op&#233;rateur binaire commutatif de corr&#233;lation de pr&#233;sence de deux termes dans un docu-
ment. #docs(ti,j &#8857; tx,y) d&#233;signe donc le nombre de documents dans un corpus qui contiennent
&#224; la fois le y-i&#232;me terme du rang x du contexte et le j-i&#232;me terme du rang i du contexte. Un terme
d&#8217;un rang du contexte ne peut &#234;tre utilis&#233; que si au moins un terme de chaque rang inf&#233;rieur peut
aussi &#234;tre utilis&#233; pour d&#233;terminer l&#8217;importance d&#8217;un nombre de documents. Dans le cas o&#249; tous
les termes sont corrects et effectivement pr&#233;sents dans tous les documents contenant la bonne
r&#233;ponse la quantit&#233; #docs(ti) peut donc &#234;tre substitu&#233;e par #docs(ti &#8857; t1,x &#8857; t2,y &#8857; ... &#8857; tn,z)
o&#249; les valeurs x y ... z varient dans les limites possibles du rang du contexte concern&#233;. Notons
que les ti de la requ&#234;te sont int&#233;gr&#233;s aux calculs s&#233;par&#233;ment les uns des autres. Nous pouvons r&#233;-
duire nos contraintes en rel&#226;chant des termes du contexte de mani&#232;re &#224; autoriser des corr&#233;lations
de pr&#233;sences de termes moins fortes. Plus la mesure est faible plus il existe un grand nombre
de documents poss&#233;dant ces termes corr&#233;l&#233;s. Par r&#233;cursion nous pouvons obtenir la m&#233;thode de
calcul suivante :
</p>
<p>Idf &#8242;(ti) = 1 + log(N)&#8722; log(1+
#docs(ti)
+ &#931;x1(#docs(ti &#8857; t1,x) | x &#8712; t1 )
+ &#931;x1&#931;
</p>
<p>y
1
( #docs(ti &#8857; t1,x &#8857; t2,y) | x &#8712; t1 , y &#8712; t2)
</p>
<p>+ ...
+ &#931;x1 ... &#931;
</p>
<p>z
1( #docs(ti &#8857; t1,x ... tn,z ) | x &#8712; t1 , ... , z &#8712; tn
</p>
<p>, n = nombreDeRangs &#8722; 1))
</p>
<p>Pour un terme unique sans aucune d&#233;pendance nous retrouvons bien la formule de base8 de
calcul de l&#8217;Idf (1 + log(N) &#8722; log(1 + docs(ti))). Imaginons maintenant que nous disposons
d&#8217;un rang suppl&#233;mentaire de d&#233;pendance. Le rang est ajout&#233; &#224; la partie pr&#233;c&#233;dente du calcul en
faisant attention &#224; la pr&#233;sence simultan&#233;e avec les termes de rangs inf&#233;rieurs. Pour la pr&#233;sence
simultan&#233;e, le syst&#232;me utilise l&#8217;op&#233;rateur de corr&#233;lation de pr&#233;sence. Chaque terme du rang est
ajout&#233; 1 &#224; 1 en v&#233;rifiant la pr&#233;sence des termes de rangs inf&#233;rieurs, la formule visualise bien cela
</p>
<p>7Rappelons que log(N/(1 + #Docs(yi))) = log(N) &#8722; log((1 + #Docs(ti)))
8log(N/(1 + #Docs(yi))) = log(N) &#8722; log((1 + #Docs(ti)))</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>K&#233;vin S&#233;journ&#233;
</p>
<p>sous la forme &#931;x
1
|x &#8712; t1. L&#8217;addition (&#931;) et la corr&#233;lation de pr&#233;sence(&#8857;) &#233;tant commutatives, la
</p>
<p>g&#233;n&#233;ralisation pour des d&#233;pendances avec plus de rangs ne pose pas de probl&#232;mes.
</p>
<p>Variante du Score A notre variante du TfxIdf nous associons alors une variante de la m&#233;thode
de calcul du score d&#8217;un document. Par g&#233;n&#233;ralisation, c&#8217;est une extension des m&#233;thodes de
scores par fr&#233;quences9.
Le score d&#8217;un document est alors d&#233;fini par : score(Q, D) = &#931;ti&#8712;QTf &#8242;(D) &#8727; Idf &#8242;(ti)
</p>
<p>3.3 Evaluer la modification.
</p>
<p>Voyons maintenant la m&#233;thodologie retenue pour &#233;valuer l&#8217;impact sur les performances de la
recherche dans les documents.
</p>
<p>D&#233;terminer la pr&#233;sence de la r&#233;ponse dans un document. Dans un premier temps, une liste
des r&#233;ponses courtes attendue est r&#233;alis&#233;e pour chaque question semi-automatiquement. De ces
r&#233;ponses courtes, nous en d&#233;duisons des ensembles de patrons fig&#233;s qui permettent de les identi-
fier dans des documents. Nous calculons alors l&#8217;ensemble des documents contenant ces patrons.
Nous bouclons alors sur deux op&#233;rations jusqu&#8217;&#224; ce que le premier choix soit syst&#233;matiquement
r&#233;alis&#233;. Soit, il y a suffisamment peu de documents, nous v&#233;rifions &#171; &#224; la main &#187; pour chaque do-
cument que le patron fig&#233; qui est trouv&#233; correspond bien &#224; la r&#233;ponse. Sinon nous s&#233;lectionnons
alors un &#233;chantillon de documents que nous analysons &#224; la main. Ces documents permettent
de d&#233;terminer un ensemble de patrons secondaires &#171; le contexte &#187; qui doivent &#234;tre pr&#233;sents
dans le document pour que le patron r&#233;ponse identifie vraiment la r&#233;ponse. Et nous recalcu-
lons l&#8217;ensemble des documents contenant les patrons avec &#171; le contexte &#187;. Nous obtenons alors
2 ensembles, un ensemble de documents contenant les r&#233;ponses, un ensemble de patrons de
r&#233;ponses sur une logique de type &#171;et/ou&#187; permettant d&#8217;obtenir les documents contenant les r&#233;-
ponses. In fine, nous avons adapt&#233; le programme de s&#233;lection des documents r&#233;ponses pour qu&#8217;il
puisse &#233;valuer les r&#233;sultats retourn&#233;s par les diff&#233;rentes versions des tests sur la recherche de
document.
</p>
<p>Caract&#233;ristiques de l&#8217;&#233;valuation sur corpus. Notre &#233;valuation a port&#233; sur les 200 questions
du corpus QA@Clef2007 en fran&#231;ais avec r&#233;ponse attendue &#224; partir du corpus anglais de la Wi-
kip&#233;dia de novembre 2006 et de l&#8217;ann&#233;e 1994 des journaux LA et GH. Nos patrons de bonnes
r&#233;ponses nous permettent de d&#233;couvrir un maximum de 116 bonnes r&#233;ponses et nous savons
qu&#8217;il existe au moins 3 questions pour lesquelles aucune r&#233;ponse ne se trouve dans les docu-
ments.
</p>
<p>Les r&#233;sultats bruts de nos &#233;valuations sont r&#233;capitul&#233;s dans le tableau 3.3. Qalc r&#233;cup&#232;re 100
documents qui sont transmis au module de s&#233;lection des phrases. La r&#233;cup&#233;ration de n = 100 ne
se r&#233;alise vraiment que si la posting-list fait au moins n documents. Notre m&#233;thode de recherche
de documents en une seule interrogation ne cherche pas &#224; obtenir des documents suppl&#233;men-
taires en formulant une requ&#234;te alternative. Une des raisons est que certaines questions n&#8217;ont
pas de r&#233;ponse dans les documents.
</p>
<p>Le MRR(Ok) est calcul&#233; en ne tenant compte que des questions pour lesquelles au moins une
9Nous avons propos&#233; ici les versions, &#171;racine carr&#233;e&#187; et &#171;quantit&#233; d&#8217;information&#187; des Tf &#8242; et Idf &#8242;. La raison en
</p>
<p>est que nous voulions obtenir un mod&#232;le proche de celui de Lucene pour les tests. La version &#171;quantit&#233; d&#8217;informa-
tion&#187; du Tf &#8242; peut s&#8217;obtenir simplement en rempla&#231;ant la fonction &#171;racine carr&#233;e&#187; par une fonction du &#171;log + 1&#187;.
Tf(D) = log(1 + 1/#Term) = log(freq(D) + 1) or par construction nous avions choisi une &#233;tude &#224; base de&#8730;
(freq(D) + 1).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Exploitation d&#8217;une structure pour les questions encha&#238;n&#233;es
</p>
<p>Strat&#233;gie Bonnes r&#233;ponses MRR(Ok) Moyenne(Ok) MRR(All) Moyenne(All)
A 59 0.20 19.15 0.06 76.15
B 88 0.24 16.17 0.10 63.12
C 88 0.32 16.78 0.14 63.38
D 106 0.19 76.54 0.10 510.5
E 106 0.15 193.7 0.08 572.7
F 92 0.31 18.57 0.14 62.54
</p>
<p>TAB. 2 &#8211; Caract&#233;ristiques des bonnes r&#233;ponses pour diff&#233;rentes strat&#233;gies d&#8217;attribution de
scores.
</p>
<p>r&#233;ponse a &#233;t&#233; trouv&#233; : c&#8217;est la moyenne des inverses des rangs des questions pour lesquelles un
document-r&#233;ponse a &#233;t&#233; trouv&#233; dans les n premiers documents. De m&#234;me pour la Moyenne(Ok)
qui est une moyenne de rang de document-r&#233;ponse. Les MRR(All) et Moyenne(All) sont les
approximations avec autant de d&#233;cimales significatives que le MRR et la Moyenne tradition-
nelles. Contrairement au MRR(Ok) si une r&#233;ponse n&#8217;est pas dans les n premiers documents
nous comptons simplement z&#233;ro. C&#8217;est ou bien la somme inverse des rangs des questions ou
bien z&#233;ro, divis&#233; par le nombre total de questions. De mani&#232;re similaire, la Moyenne(All) est
calcul&#233;e en comptant n+ 1 s&#8217;il n&#8217;y a pas de document-r&#233;ponse dans les n premiers documents.
Les calculs des All sont r&#233;alis&#233;s sur une base de 200 questions, mais ce qui est vraiment int&#233;-
ressant, c&#8217;est l&#8217;apport relatif des diff&#233;rentes m&#233;thodes. Il est facile de recalculer &#224; partir des OK
n&#8217;importe quel MRR ou Moyenne.
</p>
<p>M&#233;thode A, le hors contexte Les questions sont trait&#233;es de mani&#232;re traditionnelle sans prise en
compte du contexte. Elles sont envoy&#233;es dans la m&#233;thode classique de Lucene. Nous constatons
que par rapport &#224; la plus mauvaise m&#233;thode en contexte basique, 29 nouvelles bonnes r&#233;ponses
sont trouv&#233;es, soit un gain de 49.15% en introduisant des termes du contexte.
</p>
<p>M&#233;thode B,D et C,E Les m&#233;thodes D et E ont &#233;t&#233; r&#233;alis&#233;s avec n = 1000 alors que les m&#233;thodes
B et C ont &#233;t&#233; r&#233;alis&#233; avec n = 100 Les m&#233;thodes B et D ont &#233;t&#233; r&#233;alis&#233;s avec la m&#233;thode par
d&#233;faut de Lucene o&#249; l&#8217;origine des termes est oubli&#233;e... Les m&#233;thodes C et E ont &#233;t&#233; r&#233;alis&#233;s avec
notre nouvelle m&#233;thode d&#8217;attribution des scores aux documents.
</p>
<p>M&#233;thode F, la fusion. Nous avons remarqu&#233; que les m&#233;thodes B et C ont des moyennes d&#8217;OK
tr&#232;s inf&#233;rieures &#224; 50 ; or nous s&#233;lectionnons plus de 100 documents. Il est donc sans risque de
soit r&#233;duire le nombre de documents soit prendre les 50 premiers des 2 m&#233;thodes. Ici nous avons
pris les 50 premiers documents de B et C, puis retir&#233;s les doublons. Il aurait &#233;t&#233; possible d&#8217;aller
chercher plus de 50 documents une fois les doublons retir&#233;s. 10
</p>
<p>L&#8217;explication principale vient de la nature du corpus. Comme les SQR modifi&#233;s en vue de faire
de l&#8217;interaction ne sont pas encore vraiment d&#233;ploy&#233;s, la majorit&#233; des questions sont ind&#233;pen-
dantes. Par la nature m&#234;me des liens entre les questions, il est difficile de cr&#233;er des classes pour
s&#233;parer les diff&#233;rents types de questions : Il apparait tr&#232;s clairement que l&#8217;ajout du contexte
est un plus non n&#233;gligeable. Il est moins &#233;vident que tenir compte de l&#8217;affordance du contexte
</p>
<p>10Il aurait aussi &#233;t&#233; possible de faire un m&#233;lange alternatif tenant compte des rangs des questions (En rang 1 et 2
nous prendrions les questions en rang 1 de chaque m&#233;thode, etc...), cela permettrait d&#8217;augmenter le Mrr. En effet,
les bonnes r&#233;ponses sont class&#233;es en moyenne au rang 16-17 par les deux m&#233;thodes, cela remonterait leur rang
moyen de 50+17 &#224; 17+17. Les tests de fusion exacts n&#8217;auraient pas forc&#233;ment &#233;t&#233; plus int&#233;ressants, car ce sont
d&#233;j&#224; nos meilleurs r&#233;sultats. Nous observons le m&#234;me Mrr(All) que pour le syst&#232;me C car ce sont les r&#233;ponses du
syst&#232;me C qui ont &#233;t&#233; mises en premi&#232;re place.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>K&#233;vin S&#233;journ&#233;
</p>
<p>soit un plus. Si nous r&#233;duisons notre &#233;tude &#224; l&#8217;ensemble des groupes de questions disposant
d&#8217;une structure de d&#233;pendance non triviale, les r&#233;sultats sont significativement meilleurs, mais
en contrepartie la significativit&#233; des r&#233;sultats est bien plus faible.
</p>
<p>4 Conclusion
</p>
<p>En exploitant les informations des d&#233;pendances entre questions, nous avons construit un mo-
d&#232;le dynamique de la pond&#233;ration des termes et documents bas&#233; sur la corr&#233;lation de pr&#233;sence
de deux termes dans un document. Nous n&#8217;avons pas pu &#233;tablir de boucle d&#8217;optimisation : tests,
analyse, modification. Nous ne disposons pas de suffisamment de corpus pour cela, la difficult&#233;
impos&#233;e par le domaine ouvert emp&#234;che notamment des analyses trop fines des questions et
des corpus de documents. Nous ne voulions pas risquer la critique du surapprentissage, seule la
tactique de la fusion des deux sources de r&#233;sultats a &#233;t&#233; r&#233;alis&#233;e puisque les analyses montrent
qu&#8217;elle est statiquement fond&#233;e. Cette astuce d&#233;duite de la r&#233;partition des r&#233;sultats a permis
d&#8217;am&#233;liorer les r&#233;sultats par rapport &#224; celles existantes de la t&#226;che de r&#233;cup&#233;ration des docu-
ments dans un SQR avec des questions encha&#238;n&#233;es.
Un nouvel objectif serait d&#8217;optimiser &#224; partir de nouveaux corpus, que ce soit par une meilleure
organisation des calculs, une meilleure propagation des cons&#233;quences de l&#8217;existence d&#8217;un mo-
d&#232;le d&#8217;encha&#238;nement de questions. Nous n&#8217;avons pas tenu compte de l&#8217;impact de l&#8217;indexation
des documents sp&#233;cifiquement pour les d&#233;pendances. Il serait int&#233;ressant de tester s&#8217;il est pos-
sible de construire l&#8217;index diff&#233;remment, de nettoyer les documents diff&#233;remment afin de tenir
compte d&#232;s l&#8217;indexation du type de calcul que nous allons r&#233;aliser. Nous devons aussi appro-
fondir les avantages de la fusion des 2 strat&#233;gies de recherche que nous avons test&#233;s.
</p>
<p>R&#233;f&#233;rences
HICKL A., WILLIAMS J., BENSLEY J., ROBERTS K., SHI Y. &amp; RINK B. (2006). Question
answering with lcc&#8217;s chaucer at trec 2006. 15th Text REtrieval Conference, Gaithersburg, p.&#732;1.
MANNING C. D., RAGHAVAN P. &amp; SCH&#220;TZE H. (2008). Introduction to Information Retrie-
val.
PENAS A., FORNER P. &amp; GIAMPICCOLO D. (2007). Guidelines for participants in qa at clef
2007. CELCT, Trento(IT) and UNED, Madrid, p.&#732;1.
SALTON G. &amp; BUCKLEY C. (1988). Term-weighting approaches in automatic text retrieval.
Information Processing and Management, 24(5), 513&#8211;523.
S&#201;JOURN&#201; K. (2008). Une structure pour les questions enchain&#233;es. RECITAL, Avignon, 9-13
juin.
VAN SCHOOTEN B. &amp; OP DEN AKKER R. (2006). Follow-up utterances in qa dialogue.
TALN-05, 1(46(3)).
VILNAT A. (2005). Habilitation &#224; diriger les recherches : Dialogue et analyse de phrases.
PhD thesis, University de Paris-Sud XI LIMSI/CNRS. 2009 :http :// www.limsi.fr /Indi-
vidu/anne/HDR/MemoireHDR.pdf.
ZHOU Y., YUAN X., CAO J., HUANG X. &amp; WU L. (2006). Fduqa on trec2006 qa track. 15th
Text REtrieval Conference, Gaithersburg, p. 1026&#8211;1033.</p>

</div></div>
</body></html>