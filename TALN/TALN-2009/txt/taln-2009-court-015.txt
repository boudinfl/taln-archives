TALN 2009 — Session posters , Senlis, 24-26 juin 2009

Exploitation d’une structure pour les questions enchainées

Kévin Séjourné
Université de Paris Sud XI, Limsi/CNRS
kevin.sejourne@limsi.fr

Résumé. Nous présentons des travaux réalisés dans le domaine des systemes de ques-
tions réponses (SQR) utilisant des questions enchainées. La recherche des documents dans un
SQR est perturbée par l’absence des éléments utiles a la recherche dans les questions liées,
éléments ﬁgurant dans les échanges précédents. Les récentes campagnes d’évaluation montrent
que ce probleme est sous-estimé, et n’a pas fait l’objet de technique dédiée. Aﬁn d’améliorer
la recherche des documents dans un SQR nous utilisons une méthode récente d’organisation
des informations liées aux interactions entre questions. Celle-ci se base sur l’eXploitation d’une
structure de données adaptée a la transmission des informations des questions liées jusqu’au
moteur d’interrogation. Le moteur d’interrogation doit alors étre adapté aﬁn de tirer partie de
cette structure de données.

Abstract. We present works realized in the ﬁeld of the questions answering (QA) using
chained questions. The documents search in QA system is disrupted because useful elements
are missing for search using bound questions. Recents evaluation campaigns show this problem
as underestimated, and this problem wasn’t solve by speciﬁc techniques. To improve docu-
ments search in a QA we use a recent information organization method for bound questions
to the interactions between questions. This methode is bases on the operation of a special data
structure. This data structure transmit informations from bound questions to the interrogation
engine. Then the interrogation engine must be improve to take advantage of this data structure.

M0tS-CléS 2 Question réponse enchainée.

Keywords: chained question answering.

Kevin Sejourne

1 Introduction

Dans la foulee des systemes de reponse a des questions, il a ete envisage de considerer qu’un
utilisateur etait susceptible de poser plusieurs questions sur une meme thematique, des ques-
tions qui donc s’enchainent les unes aux autres. Ainsi, chaque question doit etre interpretee en
connaissance de l’historique des questions et des reponses precedentes. Il y a eu recemment
plusieurs campagnes d’evaluation de systemes de questions reponses (SQR) ou des questions
enchainees etaient proposees. Selon les corpus, les questions enchainees peuvent faire reference
a un contexte global (ou sujet global) prealablement introduit comme ce fut le cas dans la cam-
pagne d’evaluation TREC (Zhou et al., 2006). Elles peuvent aussi faire reference aux reponses
precedentes ou avoir de multiples references vers d’autres questions. Les questions enchai-
nees peuvent presenter toutes ces difﬁcultes sans les annoncer explicitement, comme dans la
campagne d’evaluation des SQR Clef07 (Penas et al., 2007); la premiere question peut meme
parfois avoir le rele d’un introducteur de contexte. Le tableau 1 montre un exemple de groupe
de questions enchainees. On voit sur cet exemple que pour repondre aux questions 2, 3 ou 4, il
faut connaitre le contexte pose par les questions precedentes. Parfois les SQR sont inter-lingues,
c’est-a-dire que la langue des questions est differente de la langue des documents dans lesquels
on cherche la reponse, comme c’etait le cas pour une des pistes de la campagne Clef07. C’est
le corpus de cette campagne que nous utilisons par la suite dans cet article.

Le systeme Musclef (ﬁgure 1) developpe au Limsi, et qui a participe aux precedentes cam-
pagnes classiques de Questions-Reponses, a globalement une architecture semblable aux SQR
classiques. C’est lui qui nous sert de base pour tester ces nouvelles conditions. Le probleme que
nous nous posons est alors de savoir utiliser aux mieux les informations des dependances entre
questions pour ameliorer la recherche des documents, des phrases et ainsi des reponses.

Dans cet article nous presenterons d’abord la structure que nous construisons aﬁn de decrire les
interactions entre des questions. Nos resultats vont dependre des performances de cette etape.
Ensuite, nous presenterons une methode de ponderation dynamique des termes des documents
dans un moteur de recherche pour la resolution de questions enchainees.

2 Analyse des questions enchainées

Nous devons d’abord trouver les dependances entre les questions d’un meme groupe, et pour
cela etudier les differents phenomenes linguistiques qui permettent d’inferer leur presence sans

Collection
(111) ad;
Analyse de la question Traitement des documen
Type de 1a I-éponse Ré—1ndexat1on et trl . .
(1) Focus M°l3e“1' Sélection 2 hstes mées »
Questions Termes relies semauti I H) de M (1 EN dc réponses Reponses
9"“ ' _ arquage 63 en an ais
ell fI‘all§alS i Relations symtaxiques : ? recherche (3) g]

E  Verbe principal : : Extraction de la réponse
= g Termes . . _
! 5 , . Pondération des phrases
I :
I I - : : Termes E ' d 1 ré
‘ ! estions xtraction e a ponse
: - 1 '
: {99.%3.gl%.1§ Traduction <- — -' :°“‘“‘g “S 0’)
I

_ _ _ _ _;

=—--—--—--—--—-> en anglais

FIG. 1 — Architecture du systeme Musclef en mode inter-lingue

Exploitation d’une structure pour les questions enchainées

Groupe{ Nil }

q1| on se trouve le musée de l’Ermitage ? ‘Saint-Petersbourg

/\

q3| Dans quel palais le musée est-il logé ? lPalais d’HiVer q2‘ Qui était le directeur du musée en 1994 ? lNil

q4| Combien de chambre y a-t-il dans ce palais ? |400 salles

FIG. 2 — L’ arbre correspondant au groupe du tableau 1

on se trouve le musée de l’Ermitage ?
Qui était le directeur du musée en 1994 ?
Dans quel palais le musée est-il logé ?
Combien de chambres y a-t-il dans ce palais ?

-|>UJ[\.)>—t

TAB. 1 — Exemple d’un groupe de questions enchainées tirées du corpus utilisé pour la cam-
pagne d’évaluation CLEF 2007.

trop de bruit (c’est-a-dire de fausses dépendances). Pour améliorer la recherche dans les do-
cuments, nous devons représenter les dépendances entre les questions d’un meme groupe. En
s’inspirant des travaux sur les structures de dialogue (Vilnat, 2005)(van Schooten & op den
Akker, 2006), de la nature séquentielle des groupes de questions et du partage des terInes des
questions déja résolues du groupe, il a été proposé dans (Séjoumé, 2008) d’organiser un groupe
de questions en un arbre (ﬁgure 2) représentant les liens entre les différentes questions d’un
groupe.

\

A sa racine nous trouvons le contexte commun a toutes les questions dans un noeud nommé
groupe. Le contexte est composé d’une liste d’éléments faisant éventuellement reference a la
réponse. A chaque autre noeud sont indiqués une question et son contexte propre. La structure
de l’arbre traduit les dépendances qui sont identiﬁées.

La structure d’arbre permet de représenter efﬁcacement les groupes ou les questions ne re-
prennent que le contexte issu de la premiere question. L’ ajout des éléments d’informations utiles
a la recherche d’information a chaque noeud permet une représentation homogene des groupes
ou les questions réutilisent des contextes liés les uns aux autres. Les questions qui comme la
premiere, ne réutilisent pas le contexte des précédentes, sont rattachées au noeud groupe. I1
permet également de recevoir des éléments contraignant l’espace de recherche exprimée hors
question a la maniere des évaluations de Trec 2006 1 (Hickl et al., 2006).

Nous présentons maintenant la méthode utilisée pour trouver les dépendances entre les ques-
tions d’un meme groupe. Nous pouvons formaliser la probabilité d’existence d’une dépendance
en un calcul d’argMax sur une collection de traits. Soit 04 et B deux couples de questions et ré-
ponses. Soit I‘ l’ensemble des termes que l’utilisateur doit fournir dans ces 2 questions pour que
la réponse a B puisse étre trouvée. I‘ depend des stratégies du SQR utilisé ainsi que des corpus
de documents dans lesquels la réponse est cherchée. La probabilité P a calculer est l’existence

1Un contexte était donné explicitement pour chaque groupe de questions.

Kevin Sejourne

de l’evenement : B est une sous-partie de I‘ strictement plus petite que I‘. Notons que meme si
I‘ n’est pas optimum (l’utilisateur pourrait foumir plus d’informations), rien n’empeche d’avoir
sufﬁsamment d’information pour que la probabilite d’association d’une dependance soit maxi-
malement correcte. Soit \II une collection de traits munis d’une fonction d’evaluation (type de la
question, categorie, ou des combinaisons plus complexes, traits issus de l’analyse de la question
comme illustre sur la ﬁgure 1) permettant de decrire l’apport et la capacite d’uniﬁcation de 3
dans I‘. Alors P est la somme des plus grandes possibilites d’apport et capacite d’uniﬁcation,
soit :

Pug = argMa1:(ET,-Eq,e11al(Ti, 0zﬂ))

C’est une simpliﬁcation de la methode presentee dans (Sejourne, 2008). Il est alors plus simple
de deﬁnir une strategie utilisant un seuil de probabilite de correction, en dessous duquel nous
decidons que la dependance n’existe pas. Le calcul des dependances via \II est axe sur les infor-
mations disponibles dans les SQR classiques, puisqu’il reutilise directement les traits issus de
l’analyse de la question.

Nous avons utilise les memes traits pour nourrir l’algorithme generique de construction des de-
pendances. Nous avons aj oute un trait concemant les repetitions de segments de texte communs
a deux questions. Un apprentissage nous a permis de determiner que la presence de segments
communs de plus de 15 caracteres qui ne sont en position preﬁxe ni dans l’une ni dans l’autre,
tend a montrer qu’il n’y a pas de dependance unitaire entre les deux questions.

Qmmd l’homme politique irlandais Willie 0’Dea est-il ne’ ?

012 l ’homme politique irlandais Willie 0’Dea est-il ne’ ?

Le systeme effectue donc une recherche du plus long segment commun entre les deux questions,
puis il teste sa longueur et celles des preﬁxes, pour eliminer les cas exposes precedemment. Ce
critere est utilise en complement des autres criteres.

Nous avons aussi re-utilise la meme methode d’evaluation, et le meme corpus de question
(Clef@QA2007). Des reponses a des questions en francais sont cherchees dans des documents
en anglais.2 Soit «Commun» l’ensemble des dependances communes a l’ensemble des depen-
dances annotees « a la main » eta l’ensemble de dependances trouvees par le systeme. Le rappel
est alors calcule en prenant le rapport de « Commun » sur le nombre total de dependances an-
notees. La precision est calculee en prenant le rapport de « Commun » sur le nombre total de
questions en rang au moins deux d’un groupe. 3 L’ ajout de ce trait a ceux utilises precedemment
permet une detection des dependances unitaires avec une F-mesure d’environ 0.8 pour un rappel
de 0.739 et une precision de 0.883. C’est un gain de 11% en terme de F-mesure lie a un gain en
precision et en rappel. Nous pouvons alors construire la structure d’arbre presentee ci-dessus en
fonction des dependances ainsi calculees, c’est cette structure qui constituera le contexte dans
la suite de ce texte.

3 Moteur de recherche

Pour trouver dans la collection de reference, les documents susceptibles de contenir la reponse a
une question posee, nous utilisons des moteurs de recherche a base de realisation d’une fonction

2Ce corpus contient 53 groupes d’au moins 2 questions dont 133 questions en position au—de1a de 2, et une
maj orite de groupe de 4 questions(37). L’ annotation «a la main» revéle 96 dependances.

3La F-mesure est calculée par la fonnule : (P * rappel * precision)/(rappel + precision) Nous avons
choisis P = 2 pour nos evaluations.

Exploitation d’une structure pour les questions enchainees

de score. Les documents sont alors ordonnees et les n meilleurs selectionnes. La ponderation
consiste a attribuer un poids a chaque terme utilise pour la recherche, qu’il provienne de la ques-
tion consideree ou d’un couple question-reponse dont il depend, en faisant varier leur inﬂuence
dans le score total en fonction de leur position dans la structure de dependance. I1 n’est pas
evident de choisir une ponderation qui a priori aurait des proprietes correctes pour chaque type
de terme, qu’il soit issu de la requéte, d’un document, d’une traduction, de l’ajout de synonymes
de terInes de la question.

Choix de la corrélation des termes. En nous appuyant sur la structure de dependance calculee
precedemment, nous proposons de réaliser des tests de corrélation des termes d ’un niveau 61
l ’autre. I1 s’agit de prendre deux termes de niveaux contigus dans l’arbre et de regarder s’ils sont
presents simultanement dans un document. Le principe est ensuite generalise aux arbres ayant
un nombre quelconque de niveaux. Pour chaque terme d’un niveau, il faut regarder s’il existe
au moins un terme de chaque niveau dont il depend avec lequel il est present dans le document
dont il faut calculer le score. Des tests incrementaux par niveau de la presence simultanee des
termes servent alors de ponderation implicite et dynamique.

3.1 Utilisation pour la recherche des documents.

Formes possibles de la generalisation. Cette generalisation peut prendre plusieurs formes. Il
est possible de choisir que tous les termes des niveaux precedents soient presents, mais comme
les strategies de selection et extension de termes ajoutent de nombreux mots clefs de sens voisins
dans la requéte, il est peu probable d’obtenir un effet satisfaisant. Il est possible de choisir que
seule contribuera au score du document, soit la plus grande correlation de termes soit chaque
sous correlation de termes. Il est possible d’eliminer arbitrairement les documents ne presentant
aucun terme d’un rang donne, mais l’impact des termes de rang inferieur est ignore et la resis-
tance au glissement de sujet est inferieure. Il est possible d’oub1ierle contexte de rang superieur
a un rang ou aucun document ne possede au moins un terme de ce rang etc 

Score 51 base de somme de corrélation La correlation des termes rang a rang avec une gene-
ralisation et une contribution au score pour chaque sous correlation de termes possede d’autres
avantages. 4.

1) Tailles des groupes : Un terme n’est effectivement pris en compte que s’il existe au moins
un document contenant au moins un exemplaire de terme pour chaque rang du contexte. J amais
un terme de rang n ne peut prendre plus d’importance relative que la totalite des termes de
rang n — 1. La taille des groupes de termes pour chaque rang du contexte a un impact moins
important que dans les strategies de ponderations par rang du contexte.

2) Divergence de score : Si la generalisation aboutit, alors cette methode resout les problemes
lies a la ponderation. La ponderation est exprimee en fonction des termes. La divergence est
alors controlee par la presence correlee des termes dans les documents. Le terme d’une ques-
tion ne sera jamais ecrase par un gros coefﬁcient, car ou bien les termes devront etre presents
simultanement ou bien ils ne comptent pas. La presence correlee est en elle-meme une garantie
de ponderation qui respecte le critere de divergence.

4Nous faisons l’hypothese que la strategie de selection des termes dispose d’un maxi1nu1n(soit m ce maximum)
dans le nombre de termes par rang selectionne. Pour les calculs de convergence nous faisons l’hypothese que m
est aussi une valeur cible pour le nombre de termes a selectionner dans la strategie de selection de termes. m n’est
utilise qu’a la section suivante.

Kévin Séjourné

3.2 Construction du scoring par cooccurence.

La métrique du Tfxldf peut étre déclinée en différentes variantes. Nous pouvons trouver les plus
utilisées dans (Manning et al., 2008). Nous noterons :

— #Term(t, D) = Nombre d’occurrences du terme «t» dans le document D. (#Term)

— #D0cs (t) = Nombre de documents présentant au moins une occurrence du terme «t» dans

une collection donnée. (#D0cs)

— N = Nombre total de document dans la collection.

Notre méthode consiste a modiﬁer la maniere dont le score est calculé de maniere a tenir compte
de la présence simultanée des termes de la question et du contexte dans les documents. Nous
faisons l’hypothese qu’un terme d’un contexte utilisé sans aucun terme de la question a moins
de valeur qu’un terme trouvé de la question sans son contexte.

Une variante du TFXIDF. Le Tf5 est construit sur la base de la fréquence des termes dans
un document. l’Idf6 est construit sur la base du nombre de documents contenant un terme par
rapport au nombre total de documents. Le score est construit de cette maniere Sc0re(Q, D) =
EJWQT f * I df . Souvent une méthode de normalisation est ajoutée pour remédier aux disparités
de longueur des documents et de dispersion des termes (Salton & Buckley, 1988). Come nous
ne cherchons pas seulement un terme X, mais des corrélations de termes, nous devons calculer
une valeur fondée sur le nombre de documents contenant un terme de la question et des termes
du contexte par rapport au nombre total de documents. Pour un méme document, il faut tenir
compte des risques d’absences et de mauvais choix des termes. Ces risques sont importants pour
les termes du contexte dont l’erreur réelle dépend aussi de la détection des dépendances entre
les questions. Il nous faut donc étendre le Tfxldf, pour tenir compte des niveaux du contexte.

La «partie» Tf est augmentée avec les cooccurrences éventuelles des termes dans le document
tout en tenant compte des erreurs faites a la détermination des termes. La «partie» Idf est réduite
pour tenir compte de la quantité de documents qui présente ces mémes cooccurrences. Soit tij
le terme de rang du contexte i qui est le j-ieme de son niveau. Si 1' = 0 alors il s’agit d’un terme
de la question. Soit n0mbreDeRangs le nombre de rang du contexte.

Construisons un indicateur de la fréquence des termes de la question et du contexte dans un
document, le T f ’ . Nous accordons de l’importance a un terme du contexte de rang n unique-
ment si un terme du contexte du rang n — 1 est présent dans le document. Cela se fait selon
l’algorithme suivant :

freq(t, D) = 1/#Term | #Term > 0 et freq(t, D) = 0 | #Term = 0 .

Construisons l’indicateur de fréquence des dépendances comme un systeme de fréquence des
termes d’un rangs pondéré par les fréquences des termes précédents.

Tf’(D) = \/EPiHliH71.(freq(t,-,3-,D) + 1) — n0mbreDeRangs
 E rungs du contexte , j E terme du rang(i)

C’est la somme des produits des fréquences d’un rang par le produit des fréquences des sous
rangs, donc une corrélation niveau a niveau.

Nous commencons par calculer l’impact pour les termes de rang 1, nous réalisons un produit
des fréquences (au sens déﬁni ci-dessus) pour obtenir un impact global pour le rang. Par rapport

5Tf(t,-,D) = 1/(#Term(t,-,D))
5Idf(t,-) = log(N) — log(1 + #Docs(t,-))

Exploitation d’une structure pour les questions enchainées

au Tf traditionnel, chaque rang est traité comme s’il s’agissait d’un terme unique, mais chaque
rang est pondéré non pas par une valeur ﬁxe, mais par le produit des fréquences de tous les
sous-rangs précédents. Il en résulte que moins les termes des premiers rangs sont pre’sents,
moins l’impact des termes des rangs les plus anciens est important. Notons que si un terme de
rang n est absent, alors il représente un élément neutre pour l’opération de multiplication H. Si
tous les termes de rang n sont absents, leur impact est exactement compensé par la soustraction
ﬁnale par le nombre de rangs. Par exemple pour un contexte de profondeur 3 avec m = 2 nous
obtenons le développement suivant :

Soit tm le q-iéme terme du p-iéme rang et f req(:v, D) + 1 = f alors
Tf'(D)2 + 3 = f(t1,1) * f(t1,2)

+f(t1,1) * f(t1,2) * f(t2,1) * f(t2,2)

+f(t1,1) *f(t1,2) * f(t2,1) *f(t2,2) * f(t3,1) *f(t3,2)

Il est alors évident que les 1' — 1|i E rangs du contexte premiers termes du produit des rangs
agissent comme une pondération déﬁnie dynamiquement.

Construisons un indicateur de la fréquence des documents possédant des termes corrélés, 1’ I df ’ 7.

Soit G) l’opérateur binaire commutatif de corrélation de présence de deux termes dans un docu-
ment. #d0cs (t,-J G) tm) désigne donc le nombre de documents dans un corpus qui contiennent
a la fois le y-ieme terme du rang X du contexte et le j-ieme terme du rang i du contexte. Un terme
d’un rang du contexte ne peut étre utilisé que si au moins un terme de chaque rang inférieur peut
aussi étre utilisé pour déterminer l’importance d’un nombre de documents. Dans le cas ou tous
les termes sont corrects et effectivement présents dans tous les documents contenant la bonne
réponse la quantité #d0cs(t,-) peut donc étre substituée par #d0cs(t,- ® tm ® 752,1, 6)  G) tm)
ou les valeurs X y  z varient dans les limites possibles du rang du contexte concerné. Notons
que les ti de la requéte sont intégrés aux calculs séparément les uns des autres. Nous pouvons ré-
duire nos contraintes en relachant des termes du contexte de maniere a autoriser des corrélations
de présences de termes moins fortes. Plus la mesure est faible plus il existe un grand nombre
de documents possédant ces termes corrélés. Par récursion nous pouvons obtenir la méthode de
calcul suivante :

Idf’(t,-) = 1 +l0g(N) —l0g(1+

#d0cs(t1-)

+ E’f(#d0cs(t1- (D t1,,,,) |:v 6 t1 )

+ EfEi1’( #d0cs(t,- G t1,$ (D t2,y) |:v 6 t1 , y 6 t2)

+ 
+  Ef( #d0cs(ti (D t1,;,,.  tmz) |:v 6 t1, , z E tn
,n = n0mbreDeRangs — 1))

Pour un terme unique sans aucune dépendance nous retrouvons bien la formule de base8 de
calcul de l’Idf (1 + log(N) — l0g(1 + d0cs(t,-))). Imaginons maintenant que nous disposons
d’un rang supplémentaire de dépendance. Le rang est ajouté a la partie précédente du calcul en
faisant attention a la présence simultanée avec les termes de rangs inférieurs. Pour la présence
simultanée, le systeme utilise l’opérateur de corrélation de présence. Chaque terme du rang est
ajouté 1 a 1 en vériﬁant la présence des termes de rangs inférieurs, la formule visualise bien cela

7Rappelons que log(N/(1 + #Docs(y¢))) = log(N) — log((1 + #Docs(t,-)))
8log(N/(1 + #Docs(y,-))) = log(N) — log((1 + #Docs(t,~)))

Kévin Séjourné

sous la forme 291” |a: 6 t1. L’ addition (2) et la corrélation de présence(®) étant commutatives, la
généralisation pour des dépendances avec plus de rangs ne pose pas de problemes.

Variante du Score A notre variante du Tfxldf nous associons alors une variante de la méthode
de calcul du score d’un document. Par généralisation, c’est une extension des méthodes de
scores par fréquences9.

Le score d’un document est alors déﬁni par : score(Q, D) = EQEQT f’ (D) >«< Idf’(t,-)

3.3 Evaluer la modiﬁcation.

Voyons maintenant la méthodologie retenue pour évaluer l’impact sur les performances de la
recherche dans les documents.

Déterminer la présence de la réponse dans un document. Dans un premier temps, une liste
des réponses courtes attendue est réalisée pour chaque question seIr1i-automatiquement. De ces
réponses courtes, nous en déduisons des ensembles de patrons ﬁgés qui permettent de les identi-
ﬁer dans des documents. Nous calculons alors l’ensemble des documents contenant ces patrons.
Nous bouclons alors sur deux opérations jusqu’a ce que le premier choix soit systématiquement
réalisé. Soit, il y a sufﬁsamment peu de documents, nous vériﬁons « a la main » pour chaque do-
cument que le patron ﬁgé qui est trouvé correspond bien a la réponse. Sinon nous sélectionnons
alors un échantillon de documents que nous analysons a la main. Ces documents permettent
de déterminer un ensemble de patrons secondaires « le contexte » qui doivent étre présents
dans le document pour que le patron réponse identiﬁe vraiment la réponse. Et nous recalcu-
lons l’ensemble des documents contenant les patrons avec « le contexte ». Nous obtenons alors
2 ensembles, un ensemble de documents contenant les réponses, un ensemble de patrons de
réponses sur une logique de type «et/ou» permettant d’obtenir les documents contenant les ré-
ponses. In ﬁne, nous avons adapté le programme de sélection des documents réponses pour qu’il
puisse évaluer les résultats retournés par les différentes versions des tests sur la recherche de
document.

Caractéristiques de l’évaluation sur corpus. Notre evaluation a porté sur les 200 questions
du corpus QA@Clef2007 en francais avec réponse attendue a partir du corpus anglais de la Wi-
kipédia de novembre 2006 et de l’année 1994 des joumaux LA et GH. Nos patrons de bonnes
réponses nous permettent de découvrir un maximum de 116 bonnes réponses et nous savons
qu’il existe au moins 3 questions pour lesquelles aucune réponse ne se trouve dans les docu-
ments.

Les résultats bruts de nos évaluations sont récapitulés dans le tableau 3.3. Qalc récupere 100
documents qui sonttransIr1is au module de sélection des phrases. La récupération de n = 100 ne
se réalise vraiment que si la posting-list fait au moins n documents. Notre méthode de recherche
de documents en une seule interrogation ne cherche pas a obtenir des documents supplemen-
taires en formulant une requéte alternative. Une des raisons est que certaines questions n’ont
pas de réponse dans les documents.

Le MRR(Ok) est calculé en ne tenant compte que des questions pour lesquelles au moins une

9Nous avons propose ici les Versions, «racine carrée» et «quantité d ’information» des T f ’ et I df ’ . La raison en
est que nous Voulions obtenir un modele proche de celui de Lucene pour les tests. La Version «quantité d ’informa-
tion» du T f ’ peut s’obtenir simplement en remplagant la fonction «racine carrée» par une fonction du <<log + 1».
T f (D) = log(1 + 1/#Term) = log(f1"eq(D) + 1) or par construction nous avions choisi une etude a base de

\/Ef1"eq(D) + 1).

Exploitation d’une structure pour les questions enchainées

Stratégie Bonnes réponses MRR(Ok) Moyenne(Ok) MRR(All) Moyenne(All)
A 59 0.20 19.15 0.06 76.15
B 88 0.24 16.17 0.10 63.12
C 88 0.32 16.78 0.14 63.38
D 106 0.19 76.54 0.10 510.5
E 106 0.15 193.7 0.08 572.7
F 92 0.31 18.57 0.14 62.54

TAB. 2 — Caractéristiques des bonnes réponses pour différentes strategies d’attribution de
scores.

réponse a été trouvé : c’est la moyenne des inverses des rangs des questions pour lesquelles un
document-réponse a été trouvé dans les 12 premiers documents. De meme pour la Moyenne(Ok)
qui est une moyenne de rang de document-réponse. Les MRR(All) et Moyenne(All) sont les
approximations avec autant de décimales signiﬁcatives que le MRR et la Moyenne tradition-
nelles. Contrairement au MRR(Ok) si une réponse n’est pas dans les n premiers documents
nous comptons simplement zero. C’est ou bien la somme inverse des rangs des questions ou
bien zero, divisé par le nombre total de questions. De maniere similaire, la Moyenne(All) est
calculée en comptant n + 1 s’il n’y a pas de document-réponse dans les n premiers documents.
Les calculs des All sont realises sur une base de 200 questions, mais ce qui est vraiment inte-
ressant, c’est l’apport relatif des différentes méthodes. Il est facile de recalculer a partir des OK
n’importe quel MRR ou Moyenne.

Méthode A, le hors contexte Les questions sont traitées de maniere traditionnelle sans prise en
compte du contexte. Elles sont envoyées dans la méthode classique de Lucene. Nous constatons
que par rapport a la plus mauvaise méthode en contexte basique, 29 nouvelles bonnes réponses
sont trouvées, soit un gain de 49.15% en introduisant des termes du contexte.

Méthode B,D et C,E Les méthodes D et E ont été realises avec n = 1000 alors que les méthodes
B et C ont été réalisé avec n = 100 Les méthodes B et D ont été realises avec la méthode par
défaut de Lucene ou l’origine des termes est oubliée... Les méthodes C et E ont été réalisés avec
notre nouvelle méthode d’attribution des scores aux documents.

Méthode F, la fusion. Nous avons remarqué que les méthodes B et C ont des moyennes d’OK
tres inférieures a 50; or nous sélectionnons plus de 100 documents. 11 est donc sans risque de
soit réduire le nombre de documents soit prendre les 50 premiers des 2 méthodes. Ici nous avons
pris les 50 premiers documents de B et C, puis retires les doublons. I1 aurait été possible d’aller
chercher plus de 50 documents une fois les doublons retires. 1°

L’ explication principale vient de la nature du corpus. Comme les SQR modiﬁes en vue de faire
de l’interaction ne sont pas encore vraiment déployés, la majorité des questions sont indepen-
dantes. Par la nature meme des liens entre les questions, il est difﬁcile de créer des classes pour
séparer les différents types de questions : I1 apparait tres clairement que l’ajout du contexte
est un plus non négligeable. Il est moins evident que tenir compte de l’affordance du contexte

1°11 aurait aussi été possible de faire un mélange altematif tenant compte des rangs des questions (En rang 1 et 2
nous prendrions les questions en rang 1 de chaque méthode, etc...), cela permettrait d’augmenter le Mrr. En effet,
les bonnes réponses sont classees en moyenne au rang 16- 17 par les deux méthodes, cela remonterait leur rang
moyen de 50+17 :21 17+17. Les tests de fusion exacts n’auraient pas forcément été plus interessants, car ce sont
deja nos meilleurs resultats. Nous observons le meme Mrr(All) que pour le systeme C car ce sont les réponses du
systeme C qui ont été mises en premiere place.

Kévin Séjourné

soit un plus. Si nous réduisons notre étude a l’ensemble des groupes de questions disposant
d’une structure de dépendance non triviale, les résultats sont signiﬁcativement meilleurs, mais
en contrepartie la signiﬁcativité des résultats est bien plus faible.

4 Conclusion

En exploitant les informations des dépendances entre questions, nous avons construit un mo-
dele dynaInique de la pondération des termes et documents basé sur la corrélation de présence
de deux termes dans un document. Nous n’avons pas pu établir de boucle d’optimisation : tests,
analyse, modiﬁcation. Nous ne disposons pas de sufﬁsamment de corpus pour cela, la difﬁculté
imposée par le domaine ouvert empéche notamment des analyses trop ﬁnes des questions et
des corpus de documents. Nous ne voulions pas risquer la critique du surapprentissage, seule la
tactique de la fusion des deux sources de résultats a été réalisée puisque les analyses montrent
qu’elle est statiquement fondée. Cette astuce déduite de la répartition des résultats a permis
d’améliorer les résultats par rapport a celles existantes de la tache de récupération des docu-
ments dans un SQR avec des questions enchainées.

Un nouvel objectif serait d’optiIniser a partir de nouveaux corpus, que ce soit par une meilleure
organisation des calculs, une meilleure propagation des conséquences de l’existence d’un mo-
dele d’enchainement de questions. Nous n’avons pas tenu compte de l’impact de l’indexation
des documents spéciﬁquement pour les dépendances. I1 serait intéressant de tester s’il est pos-
sible de construire l’index différemment, de nettoyer les documents différemment aﬁn de tenir
compte des l’indexation du type de calcul que nous allons réaliser. Nous devons aussi appro-
fondir les avantages de la fusion des 2 strategies de recherche que nous avons testés.

Références

HICKL A., WILLIAMS J ., BENSLEY J ., ROBERTS K., SHI Y. & RINK B. (2006). Question
answering with lcc’s chaucer at trec 2006. I 5th Text REtrieval Conference, Gaithersburg, p.1.

MANNING C. D., RAGHAVAN P. & SCHUTZE H. (2008). Introduction to Information Retrie-
val.

PENAS A., FORNER P. & GIAMPICCOLO D. (2007). Guidelines for participants in qa at clef
2007. CELCZ Trento(IT) and UNED, Madrid, p.1.

SALTON G. & BUCKLEY C. (1988). Term-weighting approaches in automatic text retrieval.
Information Processing and Management, 24(5), 513-523.

SEJOURNE K. (2008). Une structure pour les questions enchainées. RECITAL, Avignon, 9-I3
juin.

VAN SCHOOTEN B. & OP DEN AKKER R. (2006). Follow-up utterances in qa dialogue.
TALN-05, 1(46(3)).

VILNAT A. (2005). Habilitation a diriger les recherches .' Dialogue et analyse de phrases.
PhD thesis, University de Paris-Sud XI LIMSI/CNRS. 2009 :http :// www.limsi.fr [Indi-
vidu/anneﬂ-IDR/MemoireHDR.pdf.

ZHOU Y., YUAN X., CAO J ., HUANG X. & WU L. (2006). Fduqa on trec2006 qa track. I5th
Text REtrieval Conference, Gaithersburg, p. 1026-1033.

