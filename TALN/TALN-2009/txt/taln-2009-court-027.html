<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>La /fOnetizasjc/ comme un probl&#232;me de translitt&#233;ration</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009 &#8211; Session posters , Senlis, 24&#8211;26 juin 2009
</p>
<p>La /fOnetizasjO&#771;/ comme un probl&#232;me de translitt&#233;ration
</p>
<p>Vincent Claveau
IRISA-CNRS
</p>
<p>Campus de Beaulieu, 35042 Rennes cedex
vincent.claveau@irisa.fr
</p>
<p>R&#233;sum&#233;. La phon&#233;tisation est une &#233;tape essentielle pour le traitement de l&#8217;oral. Dans
cet article, nous d&#233;crivons un syst&#232;me automatique de phon&#233;tisation de mots isol&#233;s qui est
simple, portable et performant. Il repose sur une approche par apprentissage ; le syst&#232;me est
donc construit &#224; partir d&#8217;exemples de mots et de leur repr&#233;sentation phon&#233;tique. Nous utili-
sons pour cela une technique d&#8217;inf&#233;rence de r&#232;gles de r&#233;&#233;criture initialement d&#233;velopp&#233;e pour
la translitt&#233;ration et la traduction. Pour &#233;valuer les performances de notre approche, nous avons
utilis&#233; plusieurs jeux de donn&#233;es couvrant diff&#233;rentes langues et divers alphabets phon&#233;tiques,
tir&#233;s du challenge Pascal Pronalsyl. Les tr&#232;s bons r&#233;sultats obtenus &#233;galent ou d&#233;passent ceux
des meilleurs syst&#232;mes de l&#8217;&#233;tat de l&#8217;art.
</p>
<p>Abstract. Phonetizing is a crucial step to process oral documents. In this paper, a new
word-based phonetization approach is proposed ; it is automatic, simple, portable and efficient.
It relies on machine learning ; thus, the system is built from examples of words with their pho-
netic representations. More precisely, it makes the most of a technique inferring rewriting rules
initially developed for transliteration and translation. In order to evaluate the performances of
this approach, we used several datasets from the Pronalsyl Pascal challenge, including different
languages. The obtained results equal or outperform those of the best known systems.
</p>
<p>Mots-cl&#233;s : Phon&#233;tisation, phon&#233;misation, inf&#233;rence de r&#232;gles de r&#233;&#233;criture, challenge
Pronalsyl, conversion graph&#232;me-phon&#232;me, translitt&#233;ration.
</p>
<p>Keywords: Phonetization, phonemization, inference of rewriting rule, Pronalsyl
challenge, grapheme-phoneme conversion, transliteration.
</p>
<p>1 Introduction
</p>
<p>La phon&#233;tisation est le processus qui associe &#224; une s&#233;quence mots une ou plusieurs fa&#231;ons de
la prononcer. C&#8217;est une &#233;tape essentielle pour le traitement de l&#8217;oral (transcription de la pa-
role, synth&#232;se de la parole, indexation de documents audios...). Les approches dictionnaire des
premiers syst&#232;mes de traitement de l&#8217;oral ayant rapidement montr&#233; leurs limites, beaucoup ont
cherch&#233; &#224; d&#233;velopper des syst&#232;mes de phon&#233;tisation capables de manipuler des mots inconnus.
Dans le contexte de la phon&#233;tisation de mots isol&#233;s &#224; laquelle nous nous int&#233;ressons ici, l&#8217;ap-
proche la plus commune pour r&#233;soudre ce probl&#232;me est de s&#8217;appuyer sur la forme graphique
des mots pour deviner leur prononciation. En pratique, cela consiste &#224; faire correspondre &#224; un
mot-forme (repr&#233;sent&#233; par sa cha&#238;ne de caract&#232;re) une cha&#238;ne de symboles repr&#233;sentant une fa-
&#231;on prototypique de prononcer ce mot-forme. C&#8217;est pourquoi cette t&#226;che est aussi connue sous
les noms de conversion lettre-phon&#232;me, conversion graph&#232;me-phon&#232;me, ou de phon&#233;misation.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Vincent Claveau
</p>
<p>Dans notre cas, la phon&#233;tisation s&#8217;ins&#232;re dans une probl&#233;matique plus large d&#8217;indexation de
flux vid&#233;o dans laquelle nous sommes amen&#233;s &#224; manipuler des mots isol&#233;s inconnus de notre
syst&#232;me de transcription (n&#233;ologismes, noms propres, sigles, imports de langues de sp&#233;cialit&#233;).
Pour les traiter, nous voulons disposer d&#8217;une technique produisant des phon&#233;tisations de bonne
qualit&#233;, mais qui soit &#233;galement rapide, automatique et portable pour pouvoir &#234;tre adapt&#233;e &#224;
plusieurs langues et &#233;ventuellement &#224; plusieurs sous-groupes de mots ou m&#234;me &#224; un locuteur.
L&#8217;approche que nous proposons &#8211; que nous appelons IrisaPhon &#8211; r&#233;pond &#224; ces diff&#233;rents crit&#232;res
et part du constat que ce probl&#232;me de phon&#233;tisation peut &#234;tre vu comme de la translitt&#233;ration.
Nous avons donc adapt&#233; une technique d&#8217;apprentissage que nous avions d&#233;velopp&#233;e initialement
pour la translitt&#233;ration et la traduction de termes biom&#233;dicaux (Claveau, 2007; Claveau, 2009).
Cette technique permet d&#8217;inf&#233;rer tr&#232;s efficacement des r&#232;gles de r&#233;&#233;criture &#224; partir d&#8217;exemples,
c&#8217;est-&#224;-dire dans notre cas &#224; partir de mots-formes coupl&#233;s &#224; leur repr&#233;sentation phon&#233;tique. Elle
n&#8217;utilise aucune autre connaissance linguistique que ces exemples, assurant ainsi sa portabilit&#233;.
</p>
<p>Apr&#232;s une revue des principales approches existantes en phon&#233;tisation, nous d&#233;crivons notre
technique en section 3. Dans la section 4, nous pr&#233;sentons, comparons et discutons diff&#233;rents
r&#233;sultats d&#8217;&#233;valuations. Quelques perspectives ouvertes par ce travail sont enfin pr&#233;sent&#233;es dans
la derni&#232;re partie.
</p>
<p>2 Travaux connexes
</p>
<p>La phon&#233;tisation automatique de mot a d&#233;j&#224; fait l&#8217;objet de nombreux travaux. La plupart adopte
le paradigme de conversion lettre-phon&#232;me : la phon&#233;tisation comme s&#233;quence de phon&#232;mes est
d&#233;duite de la s&#233;quence de caract&#232;res formant le mot. Les techniques automatiques s&#8217;appuient
sur des exemples de mots coupl&#233;s &#224; leur repr&#233;sentation phon&#233;tique. Ces exemples sont le plus
g&#233;n&#233;ralement align&#233;s lettre &#224; lettre, souvent par des relations 1-1 (Black et al., 1998; Damper
et al., 2005) mais de meilleures performances ont &#233;t&#233; obtenues en tenant compte d&#8217;alignements
multiples (Bisani &amp; Ney, 2002; Jiampojamarn et al., 2007) qui rendent mieux compte du fait
que plusieurs lettres peuvent &#234;tre repr&#233;sent&#233;es par un phon&#232;me, et une lettre par plusieurs pho-
n&#232;mes. &#192; partir de ces exemples, certains ont utilis&#233;, et &#233;ventuellement adapt&#233;, des techniques
d&#8217;apprentissage classiques comme les arbres de d&#233;cision (Black et al., 1998; Daelemans &amp;
Bosch, 1997) ou des techniques lazy learning (Bosch &amp; Daelemans, 1998). D&#8217;autres ont mis
l&#8217;emphase sur l&#8217;aspect s&#233;quentiel du probl&#232;me et utilisent par exemple des HMM (Taylor, 2005)
ou des techniques par analogie (Yvon, 1996; Marchand &amp; Damper, 2000, inter alia). Enfin, cer-
tains ont tent&#233; de mettre en &#339;uvre des approches s&#8217;inspirant &#224; la fois de l&#8217;apprentissage tout en
tenant compte des aspects s&#233;quentiels. C&#8217;est le cas du syst&#232;me CSInf (2006) ou des approches
de Jaimpojamarn et al. (2007; 2008) bas&#233;s sur des SVM modifi&#233;s ou des HMM. Ces derni&#232;res
approches qui int&#232;grent bien les aspects s&#233;quentiels sont parmi les plus performantes. Nous
revenons sur les performances de quelques-uns de ces syst&#232;mes dans la partie &#233;valuation.
</p>
<p>3 Phon&#233;tisation et r&#233;&#233;criture
</p>
<p>Comme nous l&#8217;avons annonc&#233; pr&#233;c&#233;demment, notre approche IrisaPhon prend ses racines dans
un syst&#232;me d&#8217;apprentissage de r&#232;gles de r&#233;&#233;criture initialement d&#233;velopp&#233; pour la translitt&#233;ra-
tion de termes biom&#233;dicaux. Nous en rappelons les principes ci-dessous ; le lecteur int&#233;ress&#233;
peut se reporter &#224; Claveau (2009) pour une description plus d&#233;velopp&#233;e et son utilisation en
traduction de termes biom&#233;dicaux.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La /fOnetizasjO&#771;/ comme un probl&#232;me de translitt&#233;ration
</p>
<p>Pour phon&#233;tiser un mot-forme inconnu, IrisaPhon lui applique des r&#232;gles de r&#233;&#233;criture et choisit
la phon&#233;tisation la plus probable parmi les candidats g&#233;n&#233;r&#233;s &#224; l&#8217;aide d&#8217;un mod&#232;le de langue.
Les r&#232;gles et le mod&#232;le de langue sont appris &#224; partir de donn&#233;es d&#8217;entra&#238;nement, c&#8217;est-&#224;-dire des
listes de mots-formes (cha&#238;nes de caract&#232;res) coupl&#233;s &#224; leur repr&#233;sentation phon&#233;tique (cha&#238;nes
de symboles phon&#233;tiques).
</p>
<p>3.1 Apprentissage de r&#232;gles de r&#233;&#233;criture
</p>
<p>La technique permettant d&#8217;inf&#233;rer les r&#232;gles de r&#233;&#233;criture &#224; partir des exemples est relativement
simple. Une liste de mots coupl&#233;s &#224; leur repr&#233;sentation phon&#233;tique est donn&#233;e en entr&#233;e du sys-
t&#232;me ; &#224; chaque mot et repr&#233;sentation phon&#233;tique sont ajout&#233;s deux caract&#232;res pour repr&#233;senter
le d&#233;but et la fin de la cha&#238;ne de caract&#232;res (resp. # et $).
</p>
<p>L&#8217;algorithme 1 d&#233;crit le processus qui permet d&#8217;inf&#233;rer des r&#232;gles &#224; partir de cette liste
d&#8217;exemples. La premi&#232;re &#233;tape, l&#8217;alignement, est r&#233;alis&#233;e &#224; l&#8217;aide de DPalign (http://www.
cnts.ua.ac.be/~decadt/?section=dpalign). Des caract&#232;res vides (not&#233;s &#8217;_&#8217;) peuvent &#234;tre
ins&#233;r&#233;s au besoin. Par la suite, le mot-forme en entr&#233;e (respectivement la phon&#233;tisation en sor-
tie) d&#8217;une telle paire align&#233;e p est not&#233; input(p) (resp. output(p)) ; de plus, align(x, y) indique
que la sous-cha&#238;ne x est align&#233;e avec la sous-cha&#238;ne y dans la paire de termes consid&#233;r&#233;e. Pour
</p>
<p>Algorithme 1 Apprentissage des r&#232;gles de r&#233;&#233;criture
1: aligner les paires au niveau des lettres, mettre le r&#233;sultat dans L
2: for all paire W1 dans L do
3: for all alignement de lettres dont les 2 lettres diff&#232;rent dans W1 do
4: trouver la meilleure hypoth&#232;se de r&#232;gles r dans l&#8217;espace de recherche E
5: ajouter r &#224; l&#8217;ensemble de r&#232;gles R
6: end for
7: end for
</p>
<p>chaque diff&#233;rence entre deux lettres align&#233;es, notre algorithme doit g&#233;n&#233;rer la r&#232;gle de r&#233;&#233;criture
jug&#233;e la meilleure selon un certain score. Beaucoup de r&#232;gles sont &#233;ligibles ; consid&#233;rons par
exemple la diff&#233;rence o/@ dans le couple #phonolog_y$ / #f @nAl@dZi$. Les r&#232;gles o&#8594; @, pho
&#8594; f @, #phono &#8594; #f @nA, etc., sont par exemple possibles.
Le score d&#8217;une r&#232;gle est calcul&#233; sur la liste L comme le ratio entre le nombre de fois o&#249; la
r&#232;gle peut effectivement s&#8217;appliquer et le nombre de fois o&#249; la pr&#233;misse de la r&#232;gle correspond
&#224; une sous-cha&#238;ne d&#8217;un mot-forme. Parmi toutes les r&#232;gles possibles sur cet exemple, la r&#232;gle
maximisant ce score est donc retenue, et l&#8217;algorithme passe &#224; une nouvelle diff&#233;rence entre
l&#8217;input et l&#8217;output ou &#224; un nouveau couple de L.
La recherche de la meilleure r&#232;gle parmi toutes celles possibles est l&#8217;&#233;tape cl&#233; de notre algo-
rithme. Pour choisir cette r&#232;gle dans notre espace de recherche de la mani&#232;re la plus efficace
possible, nous d&#233;finissons une relation hi&#233;rarchique entre r&#232;gles. Cette relation est not&#233;e par le
symbole &#186; (si r1 &#186; r2, alors r1 est dite plus g&#233;n&#233;rale que r2).
</p>
<p>D&#233;finition 1 (Relation hi&#233;rarchique) Soit r1 et r2 deux r&#232;gles, alors r1 &#186; r2 &#8660; (input(r1) &#8838;
input(r2) &#8743; output(r1) &#8838; output(r2)).
Cette relation est r&#233;flexive, transitive et anti-sym&#233;trique ; elle d&#233;finit un ordre partiel sur l&#8217;espace
de recherche E qui peut donc s&#8217;organiser sous forme de treillis. La figure 1 pr&#233;sente un extrait</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Vincent Claveau
</p>
<p>du treillis de recherche construit &#224; partir de la diff&#233;rence o/@ dans l&#8217;alignement #phonolog_y$
/ #f @nAl@dZi$. En pratique, ces treillis sont explor&#233;s de haut en bas : les r&#232;gles sont g&#233;n&#233;r&#233;es &#224;
</p>
<p>o &#8594; @
</p>
<p>ho &#8594; @ on &#8594; @n
</p>
<p>hon &#8594; @n ono &#8594; @nA
</p>
<p>hono &#8594; @nA onol &#8594; @nAl
</p>
<p>#phonolog_y$ &#8594; #f @nAl@dZi$
</p>
<p>pho &#8594; f @
</p>
<p>#pho &#8594; #f @
</p>
<p>FIG. 1 &#8211; Treillis E de l&#8217;exemple o/@ dans #phonolog_y$ / #f @nAl@dZi$
</p>
<p>la vol&#233;e avec un op&#233;rateur tr&#232;s simple qui produit, pour une r&#232;gle donn&#233;e, toutes les r&#232;gles qui
sont imm&#233;diatement plus sp&#233;cifiques. En choisissant une fonction de score qui soit consistante
avec cet op&#233;rateur de sp&#233;cialisation et la structure de treillis qu&#8217;il sous-tend, il nous est possible
de choisir rapidement la meilleure r&#232;gle selon ce score (Claveau, 2009).
</p>
<p>3.2 Choix de la phon&#233;tisation
</p>
<p>Lorsqu&#8217;un mot nouveau doit &#234;tre phon&#233;tis&#233;, on lui applique toutes les r&#232;gles de r&#233;&#233;criture col-
lect&#233;es, ce qui g&#233;n&#232;re usuellement un grand nombre de phon&#233;tisations possibles. Il est important
de noter que par construction, ces phon&#233;tisations sont align&#233;es avec le mot de d&#233;part. Toutes ces
alternatives sont conserv&#233;es et la plus probable va &#234;tre propos&#233;e. Cette probabilit&#233; est calcul&#233;e
de mani&#232;re classique par un mod&#232;le de langue portant le couple mot/phon&#233;tisation. L&#8217;informa-
tion de base (unigramme) de ce mod&#232;le de langue est donc une lettre align&#233;e avec un symbole
</p>
<p>phon&#233;tique, que l&#8217;on note (par exemple) :
s
z
</p>
<p>. Avec les notations standard, pour un mot m ali-
</p>
<p>gn&#233; avec sa repr&#233;sentation phon&#233;tique f compos&#233;s respectivement des lettres (y compris les
vides _ ajout&#233;s pour l&#8217;alignement) l1, l2, ..., lm et k1, k2, ..., km, la probabilit&#233; se calcule par
l&#8217;&#233;quation 1. En pratique, un historique de quelques lettres est suffisant. Dans les exp&#233;riences
pr&#233;sent&#233;es ci-dessous, cet historique est fix&#233; &#224; 6 lettres, et un lissage de Kneiser-Ney modifi&#233;
est appliqu&#233;.
</p>
<p>P
</p>
<p>(
m
f
</p>
<p>)
=
</p>
<p>m&#8719;
i=1
</p>
<p>P
</p>
<p>(
li
ki
</p>
<p>&#8739;&#8739;&#8739;&#8739; l1k1 , ..., li&#8722;1ki&#8722;1
)
</p>
<p>(1)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La /fOnetizasjO&#771;/ comme un probl&#232;me de translitt&#233;ration
</p>
<p>Corpus IrisaPhon MIRA M-M Joint CSInf PbA LIA_PHON
HMM n-gram
</p>
<p>N&#233;erlandais CELEX 95.58 95.32 91.69 &#8211; 94.5 &#8211; &#8211;
Allemand CELEX 93.60 93.61 90.31 92.5 &#8211; &#8211; &#8211;
Anglais NETtalk 71.25 67.82 59.32 64.6 &#8211; 65.35 &#8211;
Anglais CMUDict 74.40 71.99 65.38 &#8211; &#8211; &#8211; &#8211;
Fran&#231;ais Brulex 94.75 94.51 89.77 89.1 &#8211; &#8211; &#8211;
</p>
<p>TAB. 1 &#8211; Pr&#233;cision en pourcentage d&#8217;IrisaPhon compar&#233;s &#224; diff&#233;rents syst&#232;mes
</p>
<p>4 Exp&#233;rimentations
</p>
<p>Pour &#233;valuer notre approche, nous utilisons plusieurs jeux de donn&#233;es couvrant plusieurs
langues et plusieurs jeux de phon&#232;mes. Ces donn&#233;es sont celles propos&#233;es dans le cadre du
Letter-to-Phoneme Conversion Challenge (Pronalsyl) du r&#233;seau Pascal http://pascallin2.
ecs.soton.ac.uk/Challenges/PRONALSYL. Parmi les jeux de donn&#233;es disponibles, nous nous
sommes concentr&#233;s sur ceux pour lesquels il existait des r&#233;sultats publi&#233;s pour nous y compa-
rer. Tous ces jeux de donn&#233;es comportent plusieurs milliers de paires r&#233;parties en 10 listes sur
lesquelles les &#233;valuations se font en validation crois&#233;e en 10 plis.
</p>
<p>La mesure d&#8217;&#233;valuation que nous utilisons est la pr&#233;cision en mot (moyenn&#233;e sur les 10 tours
de validation crois&#233;e) : nombre de mots parfaitement et enti&#232;rement phon&#233;tis&#233;s sur le nombre
de mots donn&#233;s &#224; phon&#233;tiser. C&#8217;est la mesure utilis&#233;e par les syst&#232;mes participant au challenge
Pronalsyl.
</p>
<p>Le tableau 1 pr&#233;sente la pr&#233;cision obtenue par IrisaPhon sur les diff&#233;rents jeux de donn&#233;es. &#192;
des fins de comparaison, nous indiquons &#233;galement les r&#233;sultats obtenus sur les m&#234;mes jeux
de donn&#233;es, lorsqu&#8217;ils sont disponibles, par diff&#233;rents syst&#232;mes de l&#8217;&#233;tat de l&#8217;art. Ces syst&#232;mes
sont : MIRA (Jiampojamarn et al., 2008), M-M HMM (Jiampojamarn et al., 2007), Joint n-gram
(Demberg et al., 2007), CSInf (Bosch &amp; Canisius, 2006), PbA (Marchand &amp; Damper, 2006),
LIA_PHON (B&#233;chet, 2001). Nous indiquons en gras les meilleurs r&#233;sultats obtenus pour un jeu
de test donn&#233;.
</p>
<p>Le r&#233;sultat est tout &#224; fait satisfaisant puisqu&#8217;IrisaPhon obtient les meilleurs r&#233;sultats sur qua-
siment tous les jeux de donn&#233;es. Il semble en particulier assez robuste aux jeux de donn&#233;es
difficiles (NETtalk et CMUDict), bien qu&#8217;une large marge de progression subsiste.
</p>
<p>5 Conclusion
</p>
<p>La parti-pris de notre approche qui a &#233;t&#233; de consid&#233;rer la phon&#233;tisation de mot comme un pro-
bl&#232;me de translitt&#233;ration porte clairement ses fruits. Notre syst&#232;me IrisaPhon se compare avan-
tageusement aux syst&#232;mes de l&#8217;&#233;tat de l&#8217;art, aussi bien en terme de pr&#233;cision qu&#8217;en terme de
temps de calcul. Bien s&#251;r, les performances mesur&#233;es ici sur des donn&#233;es divis&#233;es artificielle-
ment en jeu d&#8217;entra&#238;nement et jeu de test doivent &#234;tre consid&#233;r&#233;es comme des maxima, et des
&#233;valuations de notre syst&#232;me dans un contexte r&#233;el restent &#224; mener. L&#8217;int&#233;gration de ce syst&#232;me
dans notre probl&#233;matique plus large d&#8217;indexation de document vid&#233;o permettra de r&#233;pondre en
partie &#224; ce soucis d&#8217;&#233;valuation.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Vincent Claveau
</p>
<p>R&#233;f&#233;rences
</p>
<p>BISANI M. &amp; NEY H. (2002). Investigations on joint-multigram models for grapheme-to-
phoneme conversion. In Proceedings of the 7th International Conference on Spoken Language
Processing, Denver, USA.
</p>
<p>BLACK A. W., LENZO K. &amp; PAGEL V. (1998). Issues in building general letter to sound rules.
In Proceedings of the 3rd ESCA Workshop in Speech Synthesis, Jenolan Caves, Australie.
</p>
<p>BOSCH A. V. D. &amp; CANISIUS S. (2006). Improved morpho-phonological sequence proces-
sing with constraint satisfaction inference. In Proceedings of the 8th Meeting of the ACL Spe-
cial Interest Group in Computational Phonology, SIGPHON&#8217;06, p. 41&#8211;49, New York, USA.
</p>
<p>BOSCH A. V. D. &amp; DAELEMANS W. (1998). Do not forget: Full memory in memory-based
learning of word pronunciation. In Proceedings of NeMLaP3/CoNLL98, Sydney, Australie.
</p>
<p>B&#201;CHET F. (2001). LIA_PHON : un syst&#232;me complet de phon&#233;tisation de textes. Traitement
Automatique des Langues - TAL, 42(1), 47&#8211;67.
CLAVEAU V. (2007). Inf&#233;rence de r&#232;gles de r&#233;&#233;criture pour la traduction de termes biom&#233;-
dicaux. In Actes de la conf&#233;rence Traitement automatique des langues naturelles, TALN&#8217;07,
Toulouse, France.
</p>
<p>CLAVEAU V. (2009). Translation of biomedical terms by inferring rewriting rules. In V.
PRINCE &amp; M. ROCHE, Eds., Information Retrieval in Biomedicine: Natural Language Pro-
cessing for Knowledge Integration. IGI - Global.
</p>
<p>DAELEMANS W. &amp; BOSCH A. V. D. (1997). Language-independent data-oriented grapheme-
to-phoneme conversion. In Progress in Speech Synthesis, p. 77&#8211;89. New York, USA.
</p>
<p>DAMPER R. I., MARCHAND Y., MARSTERS J. D. &amp; BAZIN A. I. (2005). Aligning text
and phonemes for speech technology applications using an em-like algorithm. International
Journal of Speech Technology, 8(2).
DEMBERG V., SCHMID H., &amp; M&#214;HLER G. (2007). Phonological constraints and morpho-
logical preprocessing for grapheme-to-phoneme conversion. In Proceedings of the 45th An-
nual Meeting of the Association of Computational Linguistics, p. 96&#8211;103, Prague, R&#233;publique
tch&#232;que.
</p>
<p>JIAMPOJAMARN S., CHERRY C. &amp; KONDRAK G. (2008). Joint processing and discriminative
training for letter-to-phoneme conversion. In Proceedings of ACL HLT 2008, Columbus, USA.
</p>
<p>JIAMPOJAMARN S., KONDRAK G., &amp; SHERIF T. (2007). Applying many-to-many align-
ments and hidden markov models to letter-to-phoneme conversion. In Proceedings of the
conference of the North American Chapter of the Association for Computational Linguistics,
Rochester, New York, USA.
</p>
<p>MARCHAND Y. &amp; DAMPER R. I. (2000). A multistrategy approach to improving pronuncia-
tion by analogy. Computational Linguistics, 26(2).
MARCHAND Y. &amp; DAMPER R. I. (2006). Can syllabification improve pronunciation by ana-
logy of english ? Natural Language Engineering, 13(1).
TAYLOR P. (2005). Hidden markov models for grapheme to phoneme conversion. In Procee-
dings of the 9th European Conference on Speech Communication and Technology, Lisbonne,
Portugal.
</p>
<p>YVON F. (1996). Prononcer par analogie : motivations, formalisations et &#233;valuations. Th&#232;se
de doctorat, ENST, Paris.</p>

</div></div>
</body></html>