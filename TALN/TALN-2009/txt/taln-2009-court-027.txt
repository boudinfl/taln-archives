TALN 2009 — Session posters , Senlis, 24-26 juin 2009

La /f':)netizasj5/ comme un probléme de translittération

Vincent Claveau
IRISA-CNRS
Campus de Beaulieu, 35042 Rennes cedex
vincent.claveau@irisa.fr

Résumé. La phonétisation est une étape essentielle pour le traitement de l’oral. Dans
cet article, nous décrivons un systeme automatique de phonétisation de mots isolés qui est
simple, portable et performant. Il repose sur une approche par apprentissage; le systeme est
donc construit a partir d’exemples de mots et de leur représentation phonétique. Nous utili-
sons pour cela une technique d’inférence de regles de réécriture initialement développée pour
la translittération et la traduction. Pour évaluer les performances de notre approche, nous avons
utilisé plusieurs jeux de données couvrant différentes langues et divers alphabets phonétiques,
tirés du challenge Pascal Pronalsyl. Les tres bons résultats obtenus égalent ou dépassent ceux
des meilleurs systemes de l’état de l’art.

Abstract. Phonetizing is a crucial step to process oral documents. In this paper, a new
word-based phonetization approach is proposed; it is automatic, simple, portable and efﬁcient.
It relies on machine learning; thus, the system is built from examples of words with their pho-
netic representations. More precisely, it makes the most of a technique inferring rewriting rules
initially developed for transliteration and translation. In order to evaluate the performances of
this approach, we used several datasets from the Pronalsyl Pascal challenge, including different
languages. The obtained results equal or outperform those of the best known systems.

M0tS-CléS I Phonétisation, phonérnisation, inférence de regles de réécriture, challenge
Pronalsyl, conversion grapheme-phoneme, translittération.

Keywords: Phonetization, phonernization, inference of rewriting rule, Pronalsyl
challenge, grapheme-phoneme conversion, transliteration.

1 Introduction

La phonétisation est le processus qui associe a une séquence mots une ou plusieurs facons de
la prononcer. C’est une étape essentielle pour le traitement de l’oral (transcription de la pa-
role, synthese de la parole, indexation de documents audios...). Les approches dictionnaire des
premiers systemes de traitement de l’oral ayant rapidement montré leurs lirnites, beaucoup ont
cherché a développer des systemes de phonétisation capables de manipuler des mots inconnus.
Dans le contexte de la phonétisation de mots isolés a laquelle nous nous intéressons ici, l’ap-
proche la plus commune pour résoudre ce probleme est de s’appuyer sur la forme graphique
des mots pour deviner leur prononciation. En pratique, cela consiste a faire correspondre a un
mot-forrne (représenté par sa chaine de caractere) une chaine de symboles représentant une fa-
con prototypique de prononcer ce mot-forme. C’est pourquoi cette tache est aussi connue sous
les noms de conversion lettre-phoneme, conversion grapheme-phoneme, ou de phonérnisation.

Vincent Claveau

Dans notre cas, la phonétisation s’insere dans une problématique plus large d’indexation de
ﬂux vidéo dans laquelle nous sommes amenés a manipuler des mots isolés inconnus de notre
systeme de transcription (néologismes, noms propres, sigles, imports de langues de spécialité).
Pour les traiter, nous voulons disposer d’une technique produisant des phonétisations de bonne
qualité, mais qui soit également rapide, automatique et portable pour pouvoir étre adaptée a
plusieurs langues et éventuellement a plusieurs sous-groupes de mots ou meme a un locuteur.
L’ approche que nous proposons — que nous appelons IrisaPhon — répond a ces différents criteres
et part du constat que ce probleme de phonétisation peut étre vu comme de la translittération.
Nous avons donc adapté une technique d’apprentissage que nous avions développée initialement
pour la translittération et la traduction de termes biomédicaux (Claveau, 2007; Claveau, 2009).
Cette technique permet d’inférer tres efﬁcacement des regles de réécriture a partir d’eXemples,
c’est-a-dire dans notre cas a partir de mots-formes couples a leur représentation phonétique. Elle
n’utilise aucune autre connaissance linguistique que ces exemples, assurant ainsi sa portabilité.

Apres une revue des principales approches existantes en phonétisation, nous décrivons notre
technique en section 3. Dans la section 4, nous présentons, comparons et discutons différents
résultats d’évaluations. Quelques perspectives ouvertes par ce travail sont enﬁn présentées dans
la demiere partie.

2 Travaux connexes

La phonétisation automatique de mot a déja fait l’objet de nombreux travaux. La plupart adopte
le paradigme de conversion lettre-phoneme : la phonétisation comme séquence de phonemes est
déduite de la séquence de caracteres formant le mot. Les techniques automatiques s’appuient
sur des exemples de mots couples a leur représentation phonétique. Ces exemples sont le plus
généralement alignés lettre a lettre, souvent par des relations 1-1 (Black et al., 1998; Damper
et al., 2005) mais de meilleures performances ont été obtenues en tenant compte d’alignements
multiples (Bisani & Ney, 2002; Jiampojamarn et al., 2007) qui rendent Inieux compte du fait
que plusieurs lettres peuvent étre représentées par un phoneme, et une lettre par plusieurs pho-
nemes. A partir de ces exemples, certains ont utilisé, et éventuellement adapté, des techniques
d’apprentissage classiques comme les arbres de décision (Black et al., 1998; Daelemans &
Bosch, 1997) ou des techniques lazy learning (Bosch & Daelemans, 1998). D’autres ont mis
l’emphase sur l’aspect séquentiel du probleme et utilisent par exemple des HMM (Taylor, 2005)
ou des techniques par analogie (Yvon, 1996; Marchand & Damper, 2000, inter alia). Enﬁn, cer-
tains ont tenté de mettre en oeuvre des approches s’inspirant a la fois de l’apprentissage tout en
tenant compte des aspects séquentiels. C’est le cas du systeme CSInf (2006) ou des approches
de Jaimpojamarn et al. (2007; 2008) basés sur des SVM modiﬁés ou des HMM. Ces dernieres
approches qui integrent bien les aspects séquentiels sont parmi les plus performantes. Nous
revenons sur les performances de quelques-uns de ces systemes dans la partie evaluation.

3 Phonétisation et réécriture

Comme nous l’avons annoncé précédemment, notre approche IrisaPhon prend ses racines dans
un systeme d’apprentissage de regles de réécriture initialement développé pour la translittéra-
tion de termes biomédicaux. Nous en rappelons les principes ci-dessous; le lecteur intéressé
peut se reporter a Claveau (2009) pour une description plus développée et son utilisation en
traduction de termes biomédicaux.

La /fonetizasj5/ comme un probleme de translitteration

Pour phonetiser un mot-forrne inconnu, IrisaPhon lui applique des regles de reecriture et choisit
la phonetisation la plus probable parmi les candidats generes a l’aide d’un modele de langue.
Les regles et le modele de langue sont appris a partir de donnees d’entrainement, c’est-a-dire des
listes de mots-formes (chaines de caracteres) couples a leur representation phonetique (chaines
de symboles phonetiques).

3.1 Apprentissage de régles de réécriture

La technique permettant d’inferer les regles de reecriture a partir des exemples est relativement
simple. Une liste de mots couples a leur representation phonetique est donnee en entree du sys-
teme; a chaque mot et representation phonetique sont ajoutes deux caracteres pour representer
le debut et la ﬁn de la chaine de caracteres (resp. # et $).

L’ algorithme 1 decrit le processus qui permet d’inferer des regles a partir de cette liste
d’exemples. La premiere etape, l’alignement, est realisee a l’aide de DPalign (http://www.
cnts .ua . ac.be/~decadt/ ?section=dpa1ign). Des caracteres vides (notes ’_’) peuvent etre
inseres au besoin. Par la suite, le mot-forme en entree (respectivement la phonetisation en sor-
tie) d’une telle paire alignee p est note input (p) (resp. output (12)) ; de plus, align (at, y) indique
que la sous-chaine :13 est alignee avec la sous-chaine y dans la paire de termes consideree. Pour

Algorithme 1 Apprentissage des regles de reecriture

1: aligner les paires au niveau des lettres, mettre le resultat dans L‘,

2: for all paire W1 dans E do

3: for all alignement de lettres dont les 2 lettres different dans W1 do

4 trouver la meilleure hypothese de regles r dans l’espace de recherche 8
5 ajouter r a l’ensemble de regles R
6: end for
7: end for

chaque difference entre deux lettres alignees, notre algorithme doit generer la regle de reecriture
jugee la meilleure selon un certain score. Beaucoup de regles sont eligibles; considerons par
exemple la difference 0/9 dans le couple #phono|og_y$ / #f_on(11od3i$. Les regles 0 —> 9, pho
—> f_o, #phono —> #f_on(1, etc., sont par exemple possibles.

Le score d’une regle est calcule sur la liste L‘, comme le ratio entre le nombre de fois ou la
regle peut effectivement s’appliquer et le nombre de fois ou la preIr1isse de la regle correspond
a une sous-chaine d’un mot-forrne. Parmi toutes les regles possibles sur cet exemple, la regle
maximisant ce score est donc retenue, et l’algorithme passe a une nouvelle difference entre
l’input et l’0utput ou a un nouveau couple de E.

La recherche de la meilleure regle parmi toutes celles possibles est l’etape cle de notre algo-
rithme. Pour choisir cette regle dans notre espace de recherche de la maniere la plus efﬁcace
possible, nous deﬁnissons une relation hierarchique entre regles. Cette relation est notee par le
symbole 5 (si r1 5 r2, alors r1 est dite plus generale que r2).

Deﬁnition 1 (Relation hierarchique) Soit r1 et r2 deux régles, alors r1 5 r2 <=> (input(r1) Q
input(r2) /\ 0utput(r1) Q 0utput(r2)).

Cette relation est reﬂexive, transitive et anti-symetrique ; elle deﬁnit un ordre partiel sur l’espace
de recherche 8 qui peut donc s’organiser sous forme de treillis. La ﬁgure 1 presente un extrait

Vincent Claveau

du treillis de recherche construit a partir de la difference 0/9 dans l’alignement #phono|og_y$
/ #f_on(11od3i$. En pratique, ces treillis sont explores de haut en bas : les regles sont generees a

o —> 9
ho —> .9 on —> on
pho —» f_9 hon —> .911 ono —» and
#pho —> #f_9 ‘ ’/ hono —> _9nu onol —> anal

/ \ I \
/

/

#phono|og_y$  #f_9n(1l9d3i$

FIG. 1 — Treillis 8 de l’exemple 0/9 dans #phono|og_y$ / #f_on(11od3i$

la volee avec un operateur tres simple qui produit, pour une regle donnee, toutes les regles qui
sont immediatement plus speciﬁques. En choisissant une fonction de score qui soit consistante
avec cet operateur de specialisation et la structure de treillis qu’il sous-tend, il nous est possible
de choisir rapidement la meilleure regle selon ce score (Claveau, 2009).

3.2 Choix de la phonétisation

Lorsqu’un mot nouveau doit etre phonetise, on lui applique toutes les regles de reecriture col-
lectees, ce qui genere usuellement un grand nombre de phonetisations possibles. Il est important
de noter que par construction, ces phonetisations sont alignees avec le mot de depart. Toutes ces
alternatives sont conservees et la plus probable Va etre proposee. Cette probabilite est calculee
de maniere classique par un modele de langue portant le couple mot/phonetisation. L’informa-
tion de base (unigramme) de ce modele de langue est donc une lettre alignee avec un symbole

phonetique, que l’on note (par exemple) : : . Avec les notations standard, pour un mot m ali-

gne avec sa representation phonetique f composes respectivement des lettres (y compris les
vides _ ajoutes pour l’alignement) l1, l2, ..., lm et kl, [C2, ..., km, la probabilite se calcule par
l’equation 1. En pratique, un historique de quelques lettres est sufﬁsant. Dans les experiences
presentees ci-dessous, cet historique est ﬁxe a 6 lettres, et un lissage de Kneiser-Ney modiﬁe

est applique.
P( f > = HP ( 
i=1

l1 li—1
kl 7"‘?  > 

La /f:)netizasj5/ comme un probleme de translittération

Corpus IrisaPhon MIRA M—M Joint CSInf PbA LIA_PHON
HMM n-gram
Néerlandais CELEX 95.58 95.32 91.69 — 94.5 — —
Allemand CELEX 93.60 93.61 90.31 92.5 — — —
Anglais NETtalk 71.25 67.82 59.32 64.6 — 65.35 —
Anglais CMUDict 74.40 71.99 65.38 — — — —
Francais Brulex 94.75 94.51 89.77 89.1 — — —

TAB. 1 — Précision en pourcentage d’IrisaPhon compares a différents systemes
4 Expérimentations

Pour évaluer notre approche, nous utilisons plusieurs jeux de données couvrant plusieurs
langues et plusieurs jeux de phonemes. Ces données sont celles proposées dans le cadre du
Letter-to-Phoneme Conversion Challenge (Pronalsyl) du réseau Pascal http : / /pascallin2.
ecs . sot on . ac . uk / Challenges / PRONALSYL. Parmi les jeux de données disponibles, nous nous
sommes concentrés sur ceux pour lesquels il existait des résultats publiés pour nous y compa-
rer. Tous ces jeux de données comportent plusieurs milliers de paires réparties en 10 listes sur
lesquelles les évaluations se font en validation croisée en 10 plis.

La mesure d’évaluation que nous utilisons est la précision en mot (moyennée sur les 10 tours
de validation croisée) : nombre de mots parfaitement et entierement phonétisés sur le nombre
de mots donnés a phonétiser. C’est la mesure utilisée par les systemes participant au challenge
Pronalsyl.

\

Le tableau 1 présente la précision obtenue par IrisaPhon sur les différents jeux de données. A
des ﬁns de comparaison, nous indiquons également les résultats obtenus sur les memes jeux
de données, lorsqu’ils sont disponibles, par différents systemes de l’état de l’art. Ces systemes
sont : MIRA (Jiampojamarn et al., 2008), M—M HMM (Jiampojamarn et al., 2007), Joint n-gram
(Demberg et al., 2007), CSInf (Bosch & Canisius, 2006), PbA (Marchand & Damper, 2006),
LIA_PHON (Béchet, 2001). Nous indiquons en gras les meilleurs résultats obtenus pour un jeu
de test donné.

Le résultat est tout a fait satisfaisant puisqu’IrisaPhon obtient les meilleurs résultats sur qua-
siment tous les jeux de données. Il semble en particulier assez robuste aux jeux de données
difﬁciles (NETtalk et CMUDict), bien qu’une large marge de progression subsiste.

5 Conclusion

La parti-pris de notre approche qui a été de considérer la phonétisation de mot comme un pro-
bleme de translittération porte clairement ses fruits. Notre systeme IrisaPhon se compare avan-
tageusement aux systemes de l’état de l’art, aussi bien en terme de précision qu’en terme de
temps de calcul. Bien sur, les performances mesurées ici sur des données divisées artiﬁcielle-
ment en jeu d’entrainement et jeu de test doivent étre considérées comme des maxima, et des
évaluations de notre systeme dans un contexte réel restent a mener. L’ intégration de ce systeme
dans notre problématique plus large d’indexation de document vidéo permettra de répondre en
partie a ce soucis d’évaluation.

Vincent Claveau

Références

BISANI M. & NEY H. (2002). Investigations on joint-multigram models for grapheme-to-
phoneme conversion. In Proceedings of the 7th International Conference on Spoken Language
Processing, Denver, USA.

BLACK A. W., LENZO K. & PAGEL V. (1998). Issues in building general letter to sound rules.
In Proceedings of the 3rd ESCA Workshop in Speech Synthesis, J enolan Caves, Australie.

BOSCH A. V. D. & CANISIUS S. (2006). Improved morpho-phonological sequence proces-
sing with constraint satisfaction inference. In Proceedings of the 8th Meeting of the ACL Spe-
cial Interest Group in Computational Phonology, SIGPHON’06, p. 41-49, New York, USA.

BOSCH A. V. D. & DAELEMANS W. (1998). Do not forget: Full memory in memory-based
learning of word pronunciation. In Proceedings of NeMLaP3/CoNLL98, Sydney, Australie.

BECHET F. (2001). LIA_PHON : un systeme complet de phonétisation de textes. Traitement
Automatique des Langues - TAL, 42(1), 47-67.

CLAVEAU V. (2007). Inférence de regles de réécriture pour la traduction de termes biome-
dicaux. In Actes de la confe’rence Traitement automatique des langues naturelles, TALN’07,
Toulouse, France.

CLAVEAU V. (2009). Translation of biomedical terms by inferring rewriting rules. In V.
PRINCE & M. ROCHE, Eds., Information Retrieval in Biomedicine: Natural Language Pro-
cessing for Knowledge Integration. IGI - Global.

DAELEMANS W. & BOSCH A. V. D. (1997). Language-independent data-oriented grapheme-
to-phoneme conversion. In Progress in Speech Synthesis, p. 77-89. New York, USA.

DAMPER R. 1., MARCHAND Y., MARSTERS J . D. & BAZIN A. I. (2005). Aligning text
and phonemes for speech technology applications using an em-like algorithm. International
Journal of Speech Technology, 8(2).

DEMBERG V., SCHMID H., & MOHLER G. (2007). Phonological constraints and morpho-
logical preprocessing for grapheme-to-phoneme conversion. In Proceedings of the 45th An-
nual Meeting of the Association of Computational Linguistics, p. 96-103, Prague, République
tcheque.

J IAMPOJAMARN S ., CHERRY C. & KONDRAK G. (2008). Joint processing and discriminative
training for letter-to-phoneme conversion. In Proceedings of ACL HLT 2008, Columbus, USA.

JIAMPOJAMARN S., KONDRAK G., & SHERIF T. (2007). Applying many-to-many align-
ments and hidden markov models to letter-to-phoneme conversion. In Proceedings of the

conference of the North American Chapter of the Association for Computational Linguistics,
Rochester, New York, USA.

MARCHAND Y. & DAMPER R. I. (2000). A multistrategy approach to improving pronuncia-
tion by analogy. Computational Linguistics, 26(2).

MARCHAND Y. & DAMPER R. I. (2006). Can syllabiﬁcation improve pronunciation by ana-
logy of english ? Natural Language Engineering, 13(1).

TAYLOR P. (2005). Hidden markov models for grapheme to phoneme conversion. In Procee-
dings of the 9th European Conference on Speech Communication and Technology, Lisbonne,
Portugal.

YVON F. (1996). Prononcer par analogie .' motivations, formalisations et évaluations. These
de doctorat, ENST, Paris.

