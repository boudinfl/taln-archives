<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Plusieurs langues (bien choisies) valent mieux qu&#8217;une : traduction statistique multi-source par renforcement lexical</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009 &#8211; Session posters , Senlis, 24&#8211;26 juin 2009
</p>
<p>Plusieurs langues (bien choisies) valent mieux qu&#8217;une :
traduction statistique multi-source par renforcement lexical
</p>
<p>Josep Maria Crego1, Aur&#233;lien Max1,2 et Fran&#231;ois Yvon1,2
{jmcrego,amax,yvon}@limsi.fr
</p>
<p>(1) LIMSI-CNRS, Orsay
(2) Universit&#233; Paris-Sud 11, Orsay
</p>
<p>R&#233;sum&#233;. Les syst&#232;mes de traduction statistiques int&#232;grent diff&#233;rents types de mod&#232;les
dont les pr&#233;dictions sont combin&#233;es, lors du d&#233;codage, afin de produire les meilleures traduc-
tions possibles. Traduire correctement des mots polys&#233;miques, comme, par exemple, le mot
avocat du fran&#231;ais vers l&#8217;anglais (lawyer ou avocado), requiert l&#8217;utilisation de mod&#232;les suppl&#233;-
mentaires, dont l&#8217;estimation et l&#8217;int&#233;gration s&#8217;av&#232;rent complexes. Une alternative consiste &#224; tirer
parti de l&#8217;observation selon laquelle les ambigu&#239;t&#233;s li&#233;es &#224; la polys&#233;mie ne sont pas les m&#234;mes
selon les langues source consid&#233;r&#233;es. Si l&#8217;on dispose, par exemple, d&#8217;une traduction vers l&#8217;espa-
gnol dans laquelle avocat a &#233;t&#233; traduit par aguacate, alors la traduction de ce mot vers l&#8217;anglais
n&#8217;est plus ambigu&#235;. Ainsi, la connaissance d&#8217;une traduction fran&#231;ais&#8594;espagnol permet de ren-
forcer la s&#233;lection de la traduction avocado pour le syst&#232;me fran&#231;ais&#8594;anglais. Dans cet article,
nous proposons d&#8217;utiliser des documents en plusieurs langues pour renforcer les choix lexicaux
effectu&#233;s par un syst&#232;me de traduction automatique. En particulier, nous montrons une am&#233;lio-
ration des performances sur plusieurs m&#233;triques lorsque les traductions auxiliaires utilis&#233;es sont
obtenues manuellement.
</p>
<p>Abstract. Statistical Machine Translation (SMT) systems integrate various models that
exploit all available features during decoding to produce the best possible translation hypo-
theses. Correctly translating polysemous words, such as the French word avocat into English
(lawyer or avocado) requires integrating complex models. Such translation lexical ambiguities,
however, depend on the language pair considered. If one knows, for instance, that avocat was
translated into Spanish as aguacate, then translating it into English is no longer ambiguous
(avocado). Thus, in this example, the knowledge of the Spanish translation allows to reinforce
the choice of the appropriate English word for the French&#8594;English system. In this article, we
present an approach in which documents available in several languages are used to reinforce the
lexical choices made by a SMT system. In particular, we show that gains can be obtained on
several metrics when using auxiliary translations produced by human translators.
</p>
<p>Mots-cl&#233;s : Traduction automatique statistique, d&#233;sambigu&#239;sation lexicale, r&#233;&#233;valuation
de listes d&#8217;hypoth&#232;ses.
</p>
<p>Keywords: Statistical Machine Translation, Word Sense Disambiguation, N-best list
rescoring.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1 Introduction
</p>
<p>Les syst&#232;mes de traduction statistiques actuels int&#232;grent diff&#233;rents mod&#232;les qui mettent en jeu,
lors du d&#233;codage, le plus d&#8217;informations disponibles afin de produire les meilleures traductions
possibles. En particulier, dans leur version standard, ces syst&#232;mes embarquent un mod&#232;le de
traduction qui probabilise la correspondance entre des s&#233;quences de taille variable en source
et en cible, un mod&#232;le de r&#233;ordonnancement, qui &#233;value les distortions entre l&#8217;ordre des mots
en source et en cible, et un mod&#232;le de langage, qui d&#233;termine la probabilit&#233; des phrases cible
(Koehn et al., 2003). Les scores combin&#233;s de ces trois mod&#232;les permettent de d&#233;terminer la
meilleure traduction pour le syst&#232;me. Une d&#233;ficience, soulign&#233;e dans de nombreux travaux, de
cette approche est l&#8217;absence d&#8217;un mod&#232;le permettant de r&#233;soudre explicitement les ambigu&#239;t&#233;s
s&#233;mantiques en source (Carpuat &amp; Wu, 2005).
&#201;tendre les syst&#232;mes standard, afin de pouvoir traduire correctement des mots polys&#233;miques,
comme par exemple le mot avocat du fran&#231;ais vers l&#8217;anglais (lawyer ou avocado), requiert l&#8217;in-
t&#233;gration de mod&#232;les complexes (voir par ex. (Max et al., 2009)). Or, cette difficult&#233; inh&#233;rente
&#224; la polys&#233;mie n&#8217;est pas la m&#234;me en fonction des langues sources consid&#233;r&#233;es. Si l&#8217;on dispose,
par exemple, d&#8217;un document en espagnol dans lequel avocat a &#233;t&#233; traduit par aguacate, alors la
traduction de ce mot vers l&#8217;anglais n&#8217;est pas ambigu&#235; et permet donc de renforcer la s&#233;lection
de la traduction avocado pour le syst&#232;me fran&#231;ais&#8594; anglais. Dans cet article, nous proposons
d&#8217;utiliser des documents en plusieurs langues pour renforcer les choix lexicaux op&#233;r&#233;s par un
syst&#232;me de traduction automatique. L&#8217;objectif g&#233;n&#233;ral est d&#8217;am&#233;liorer un syst&#232;me pour une
paire de langues L1&#8594;L2 en exploitant conjointement des traductions disponibles dans d&#8217;autres
langues Li (avec i &gt; 2) et les sorties de syst&#232;mes automatiques Li&#8594;L2. Nous pr&#233;sentons deux
mani&#232;res d&#8217;aborder ce probl&#232;me : 1) en exploitant des traductions humaines disponibles entre
les langues L1 et Li, et 2) en exploitant des traductions automatiques entre les langues L1 et Li.
Cet article est organis&#233; comme suit. Nous commen&#231;ons par analyser bri&#232;vement les approches
permettant d&#8217;exploiter plusieurs syst&#232;mes et des entr&#233;es multiples (section 2). Nous d&#233;crivons
ensuite les particularit&#233;s de notre approche (section 3.1), et les architectures correspondant aux
deux contextes d&#8217;application (section 3.2). Nous pr&#233;sentons une &#233;valuation de notre approche
sur une t&#226;che de traduction fran&#231;ais&#8594; anglais (section 4.1) et les scores de r&#233;&#233;valuation des
hypoth&#232;ses de traduction utilis&#233;s (section 4.2). Les r&#233;sultats obtenus en utilisant simultan&#233;ment
les neuf langues auxiliaires disponibles sont pr&#233;sent&#233;s (section 4.3), puis nous d&#233;crivons deux
strat&#233;gies de recherche heuristique permettant de trouver des ensembles de langues minimaux
menant aux meilleurs r&#233;sultats possibles (section 4.4). Nous discutons enfin nos r&#233;sultats et
concluons (section 5).
</p>
<p>2 Travaux ant&#233;rieurs
</p>
<p>La r&#233;&#233;valuation des meilleures hypoth&#232;ses (N-best list reranking) produites par un syst&#232;me de
traduction automatique statistique est fr&#233;quemment op&#233;r&#233;e comme un post-traitement en sortie
d&#8217;un d&#233;codeur (ex. (Shen et al., 2004)), car elle permet d&#8217;appliquer des mod&#232;les plus fins pour
la s&#233;lection de la meilleure hypoth&#232;se sur la liste des N meilleures traductions propos&#233;es en
premi&#232;re passe1. Il est ainsi possible de calculer les scores de mod&#232;les difficiles &#224; int&#233;grer lors
</p>
<p>1Une &#233;valuation de type oracle sur une sortie constitu&#233;e de 1000 meilleures hypoth&#232;ses pour nos exp&#233;riences
d&#233;crites dans la section 4 montre un potentiel important d&#8217;un gain de 8.8 points BLEU entre la meilleure hypoth&#232;se</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Traduction statistique multisource par renforcement lexical
</p>
<p>du d&#233;codage (par ex. utilisation d&#8217;un mod&#232;le de langue &#224; grand empan) ou n&#233;cessitant des
hypoth&#232;ses correspondant &#224; des phrases compl&#232;tes, lorsqu&#8217;il s&#8217;agit par exemple d&#8217;exploiter des
traits syntaxiques (Hasan et al., 2006).
Un nombre important de travaux ont &#233;galement port&#233; sur l&#8217;exploitation conjointe des sorties
propos&#233;es par plusieurs syst&#232;mes distincts, afin notamment de faire b&#233;n&#233;ficier le syst&#232;me com-
bin&#233; des forces de chacune des approches impl&#233;ment&#233;es. L&#8217;&#233;tude pr&#233;sent&#233;e par (Rosti et al.,
2007) porte sur la combinaison de sorties de syst&#232;mes &#224; diff&#233;rents niveaux et montre que les
meilleurs gains sont obtenus en combinant les hypoth&#232;ses &#224; la fois au niveau des mots, des
segments et des phrases.
</p>
<p>Si la majorit&#233; des travaux dans le domaine portent sur la combinaison de syst&#232;mes impl&#233;men-
tant des approches diff&#233;rentes pour une m&#234;me paire de langues, (Och &amp; Ney, 2001) ont pro-
pos&#233; d&#8217;utiliser des traductions disponibles en plusieurs langues et de les traduire vers une m&#234;me
langue, puis de s&#233;lectionner pour chaque phrase la traduction obtenue menant au meilleur score,
ce qui revient implicitement &#224; s&#233;lectionner la meilleure langue source pour chaque phrase &#224; tra-
duire. En proc&#233;dant de cette mani&#232;re, ils observent des am&#233;liorations notables pour la m&#233;trique
WER. (Nomoto, 2004) s&#8217;inscrit dans la m&#234;me logique, en reclassant les diff&#233;rentes hypoth&#232;ses
propos&#233;es par un mod&#232;le de langue cible. Les exp&#233;riences plus r&#233;centes de Schwartz (Schwartz,
2008), si elles mettent clairement en &#233;vidence les potentialit&#233;s de l&#8217;approche multi-source, sou-
lignent les limites de la d&#233;marche de Och et Ney, dont les gains (pour la m&#233;trique BLEU)
s&#8217;av&#232;rent plus faibles qu&#8217;esp&#233;r&#233;, et discute d&#8217;alternatives. Parmi celles-ci, l&#8217;utilisation de r&#233;-
seaux de concensus construits &#224; partir de traductions de langues diff&#233;rentes, est conceptuelle-
ment simple &#224; impl&#233;menter, et conduit effectivement &#224; des am&#233;liorations importantes (Callison-
Burch et al., 2008; Leusch et al., 2009). Notre m&#233;thode, qui s&#8217;appuie sur les m&#234;mes intuitions
que ces travaux, utilise des moyens sensiblement diff&#233;rents : &#224; la mani&#232;re de (Hildebrand &amp; Vo-
gel, 2008) (qui ne manipulent qu&#8217;une langue source) la combinaison de syst&#232;mes s&#8217;op&#232;re dans
une &#233;tape de r&#233;&#233;valuation, durant laquelle les diff&#233;rentes hypoth&#232;ses sont renforc&#233;es explicite-
ment via des scores qui favorisent les traductions concensuelles.
</p>
<p>3 Traduction multisource par renforcement lexical
</p>
<p>3.1 Description de l&#8217;approche
</p>
<p>Notre approche vise &#224; am&#233;liorer les performances d&#8217;un syst&#232;me pour une paire de langues par-
ticuli&#232;re en exploitant des textes source disponibles en plusieurs langues. Elle se distingue tou-
tefois des approches comparables dans la mesure o&#249; elle privil&#233;gie une direction de traduction
(correspondant au syst&#232;me que nous d&#233;signerons dans la suite comme le syst&#232;me principal) ;
les autres sources disponibles (alimentant des syst&#232;mes auxiliaires) fournissent des informa-
tions suppl&#233;mentaires susceptibles d&#8217;aider le syst&#232;me principal.
</p>
<p>L&#8217;objectif poursuivi est de renforcer les choix lexicaux qui sont pr&#233;sents dans les hypoth&#232;ses
multiples du syst&#232;me (N-best lists) et &#233;galement propos&#233;s par des syst&#232;mes traduisant depuis
d&#8217;autres langues vers la m&#234;me langue cible. Par exemple, lorsque la traduction d&#8217;un mot poly-
s&#233;mique est ambigu&#235;, si l&#8217;on dispose d&#8217;une traduction du texte &#224; traduire dans une autre langue
pour laquelle la traduction n&#8217;est pas ambigu&#235;, alors cette traduction peut &#234;tre pr&#233;f&#233;r&#233;e. Le mot
</p>
<p>du syst&#232;me initial et la meilleure hypoth&#232;se pour chaque phrase relativement au score BLEU.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>fran&#231;ais avocat, dont deux sens peuvent se traduire en anglais par lawyer et avocado, poss&#232;de
&#233;galement deux traductions couvrant les m&#234;mes sens en espagnol, respectivement abogado et
aguacate, mais la traduction de chacune d&#8217;elles vers l&#8217;anglais n&#8217;est plus ambigu&#235;. La connais-
sance de la traduction en espagnol permet donc de choisir la traduction en anglais. En g&#233;n&#233;ral,
cependant, il est difficile de garantir qu&#8217;une traduction n&#8217;est pas ambigu&#235;. Les traductions pro-
pos&#233;es &#224; partir d&#8217;autres langues pourront donc jouer le r&#244;le d&#8217;indices venant renforcer les choix
du syst&#232;me principal.
</p>
<p>Une caract&#233;ristique importante de cette approche est la d&#233;pendance des performances du sys-
t&#232;me principal aux syst&#232;mes auxiliaires utilis&#233;s. En effet, si ces syst&#232;mes tendent &#224; produire de
mauvaises traductions, ils peuvent renforcer de mauvaises hypoth&#232;ses. &#192; l&#8217;inverse, une am&#233;-
lioration sensible d&#8217;un syst&#232;me auxiliaire permettra d&#8217;am&#233;liorer le renforcement des choix du
syst&#232;me principal, sans que celui-ci n&#8217;ait eu &#224; conna&#238;tre d&#8217;am&#233;lioration directe. Une impl&#233;men-
tation performante de cette approche permettra donc un cercle vertueux, o&#249; les am&#233;liorations
d&#8217;un syst&#232;me profiteront &#233;galement aux autres.
</p>
<p>En outre, l&#8217;approche propos&#233;e se distingue de l&#8217;approche pivot plus traditionnelle (ex., (Wu &amp;
Wang, 2007)) dans laquelle un syst&#232;me est construit pour une paire de langues en traduisant
successivement de la langue source vers une langue interm&#233;diaire, puis de cette langue interm&#233;-
diaire vers la langue cible. Si ce type d&#8217;approche est int&#233;ressant lorsque les ressources parall&#232;les
disponibles sont trop limit&#233;es pour constuire un syst&#232;me de traduction direct, elle a comme in-
conv&#233;nient que les erreurs commises lors de la traduction de la langue source vers la langue
pivot sont difficilement r&#233;parables. La traduction multisource par renforcement lexical permet
de renforcer certaines hypoth&#232;ses d&#8217;un syst&#232;me, et offre donc des perspectives de correction de
la meilleure hypoth&#232;se produite par un syst&#232;me par s&#233;lection d&#8217;une autre hypoth&#232;se. Il est, par
ailleurs, possible de n&#8217;utiliser qu&#8217;une seule langue auxiliaire, et les performances du syst&#232;me
seront d&#8217;autant am&#233;lior&#233;es que cette langue sera bien choisie.
</p>
<p>3.2 Contextes d&#8217;utilisation et architectures des syst&#232;mes
</p>
<p>Il existe de nombreux contextes dans lesquels des traductions existent dans plusieurs langues
et o&#249; l&#8217;on peut souhaiter traduire vers de nouvelles langues, comme dans le cas de traductions
de manuels techniques, o&#249; des traductions sont tout d&#8217;abord effectu&#233;es vers des langues princi-
pales puis vers des langues &#224; impact commercial moins important. Un tel contexte de traduction
en s&#233;rie permet l&#8217;exploitation conjointe, par un syst&#232;me automatique, de textes d&#233;j&#224; traduits en
plusieurs langues. L&#8217;architecture de l&#8217;exp&#233;rience MultiRef correspondante est pr&#233;sent&#233;e dans la
partie gauche de la figure 1. Dans cet exemple, on traduit un texte du fran&#231;ais vers l&#8217;anglais,
en utilisant les traductions vers l&#8217;anglais des textes disponibles en espagnol, allemand et n&#233;er-
landais. Ces traductions sont utilis&#233;es par un module de r&#233;&#233;valuation des meilleures hypoth&#232;ses
du syst&#232;me principal, qui s&#233;lectionne de nouvelles hypoth&#232;ses sur la base d&#8217;un renforcement
lexical. Ce type de r&#233;&#233;valuation est particuli&#232;rement utile lorsqu&#8217;il permet de calculer les scores
de mod&#232;les qui requi&#232;rent des phrases cibles compl&#232;tes. Bien que cette contrainte ne soit pas
impos&#233;e par notre approche, la r&#233;&#233;valuation permet ici de ne pas avoir &#224; modifier les d&#233;codeurs
des syst&#232;mes de traduction.
</p>
<p>La s&#233;lection d&#8217;hypoth&#232;ses par renforcement lexical se base cependant sur l&#8217;hypoth&#232;se forte que
les diff&#233;rents textes disponibles seront des traductions assez directes les uns des autres, et qu&#8217;ils
n&#8217;auront pas subi une &#171; localisation &#187; trop importante. Les traductions automatiques, qui sont
souvent plus litt&#233;rales, peuvent ici &#234;tre utilis&#233;es de fa&#231;on avantageuse. Dans ce contexte, on</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Traduction statistique multisource par renforcement lexical
</p>
<p>pourrait penser que le renforcement lexical pourrait plus simplement &#234;tre effectu&#233; par consul-
tation des mod&#232;les de traduction. Or, un syst&#232;me de traduction met en jeu plusieurs mod&#232;les,
dont en particulier un mod&#232;le de langue cible, qui ont pour but de mieux choisir les traductions
en contexte. La partie droite de la figure 1 pr&#233;sente l&#8217;architecture de l&#8217;exp&#233;rience MultiAuto,
dans laquelle plusieurs langues auxiliaires sont utilis&#233;es. Les langues utilis&#233;es sont les m&#234;mes
que pour l&#8217;exemple pr&#233;c&#233;dent, mais les traductions du texte &#224; traduire en espagnol, allemand
et hollandais sont ici obtenues de fa&#231;on automatique. Ce contexte correspond &#224; des situations
beaucoup plus communes dans lesquelles un seul texte source est disponible.
</p>
<p>FIG. 1 &#8211; Architecture de deux syst&#232;mes MultiRef et MultiAuto pour la paire fran&#231;ais&#8594;anglais
avec l&#8217;espagnol, l&#8217;allemand et le n&#233;erlandais comme langues auxiliaires.
</p>
<p>4 Exp&#233;riences et r&#233;sultats
</p>
<p>4.1 Donn&#233;es et syst&#232;mes utilis&#233;s
</p>
<p>Comme source de textes parall&#232;les fortement multilingues, nous avons utilis&#233; le corpus de d&#233;-
bats parlementaires europ&#233;ens Europarl (Koehn, 2005) pour les 11 langues suivantes : allemand
(de), anglais (en), danois (da), espagnol (es), finlandais (fi), fran&#231;ais (fr), grec (el), italien (it),
n&#233;erlandais (nl), portugais (pt) et su&#232;dois (sv). Afin d&#8217;utiliser des syst&#232;mes aux performances
comparables, nous avons retenu la partie commune &#224; toutes les langues du corpus, pour un total
de 318 804 lignes (soit environ 10,3 millions de mots pour le fran&#231;ais). La paire de langues
principale pour nos exp&#233;riences est la paire fran&#231;ais&#8594;anglais.
</p>
<p>Tous nos syst&#232;mes sont des syst&#232;mes statistiques bas&#233;s sur les tuples (Crego &amp; Mari&#241;o, 2007),
qui combinent lin&#233;airement plusieurs scores. Un mod&#232;le de traduction est estim&#233; comme un
mod&#232;le de langue n-gram bas&#233; sur les tuples, qui d&#233;finit une probabilit&#233; jointe entre les langues
d&#8217;une paire (Mari&#241;o et al., 2006). Lors du d&#233;codage, seuls les r&#233;ordonnancements encod&#233;s dans
un treillis de mots sont consid&#233;r&#233;s. Le mod&#232;le de r&#233;ordonnancement en source est appris au-
tomatiquement depuis un corpus parall&#232;le bilingue align&#233; au niveau des mots, et est appliqu&#233;
aux phrases &#224; traduire avant leur traduction. Les cat&#233;gories morphosyntaxiques sont utilis&#233;es
pour g&#233;n&#233;raliser le mod&#232;le de r&#233;ordonnancement. Une r&#232;gle telle que NN JJ ; JJ NN per-
met par exemple d&#8217;exprimer l&#8217;inversion adjectif-nom entre le fran&#231;ais et l&#8217;anglais. Les phrases
en fran&#231;ais, espagnol et allemand sont analys&#233;es avec le TreeTagger2 pour obtenir les cat&#233;go-
ries morphosyntaxiques ; pour les autres langues, les r&#232;gles de r&#233;ordonnancement sont apprises
</p>
<p>2http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>directement sur des s&#233;quences de formes, ce qui conduit, en pratique, &#224; des syst&#232;mes moins
performants. Une impl&#233;mentation maison de la recherche du simplexe (Nelder &amp; Mead, 1965)
est utilis&#233;e pour d&#233;terminer les pond&#233;rations des diff&#233;rents mod&#232;les, en optimisant les scores
BLEU (Papineni et al., 2002) obtenus sur un corpus de d&#233;veloppement.
Le syst&#232;me de r&#233;f&#233;rence correspond &#224; un syst&#232;me de traduction &#224; base de tuples standard. Les
syst&#232;mes MultiRef et MultiAuto, correspondant respectivement &#224; un syst&#232;me multisource utili-
sant des traductions de r&#233;f&#233;rence et &#224; un syst&#232;me multisource utilisant des traductions automa-
tiques, exploitent les neuf langues auxiliaires restantes.
</p>
<p>4.2 R&#233;&#233;valuation de listes d&#8217;hypoth&#232;ses
</p>
<p>Nous fondons notre r&#233;&#233;valuation des hypoth&#232;ses du syst&#232;me principal sur le score donn&#233; par le
d&#233;codeur pour chaque hypoth&#232;se, ainsi que sur le nombre de n-grams d&#8217;une traduction candidate
qui sont &#233;galement pr&#233;sents dans une ou plusieurs traductions de &#171; r&#233;f&#233;rence &#187;, &#224; la mani&#232;re de
la m&#233;trique automatique BLEU, qui privil&#233;gie les traductions qui sont de taille comparable
avec une traduction servant de r&#233;f&#233;rence et partageant le plus de n-grams communs avec celle-
ci. Pour les scores portant sur les unigrammes, seuls les mots n&#8217;appartenant pas une liste de
mots vides (obtenue par seuillage sur les fr&#233;quences &#224; partir du corpus d&#8217;apprentissage) ont &#233;t&#233;
retenus, afin de ne pas donner trop d&#8217;importance &#224; la pr&#233;sence de mots outils pour lesquels notre
approche n&#8217;est s&#251;rement pas adapt&#233;e. Cette limitation ne pouvait cependant pas s&#8217;appliquer de
fa&#231;on naturelle aux n-grams plus grands. Le score calcul&#233; par un mod&#232;le (interpr&#233;table comme
un co&#251;t) pour chaque langue auxiliaire l correspond &#224;3 :
</p>
<p>score(l) =
4&#8721;
</p>
<p>n=1
</p>
<p>(1&#8722; npn(l)) (1)
</p>
<p>np est la pr&#233;cision n-gram d&#233;finie comme : npn = |N
hyp
n &#8745;N
</p>
<p>ref
n |
</p>
<p>|Nhypn |
, o&#249; Nhyp
</p>
<p>1
et N ref
</p>
<p>1
correspondent
</p>
<p>respectivement &#224; l&#8217;ensemble des mots pleins de l&#8217;hypoth&#232;se et de la r&#233;f&#233;rence, et Nhypn et N refn
(2&#8805;n&#8805;4) correspondent aux n-grams de mots.
Une seconde &#233;tape de r&#233;glage des poids associ&#233;s &#224; ces diff&#233;rents scores est effectu&#233;e sur un
corpus de d&#233;veloppement, de nouveau gr&#226;ce &#224; la m&#233;thode du simplexe, qui permet de trouver la
combinaison de poids maximisant le score BLEU sur ce corpus.
</p>
<p>4.3 R&#233;sultats exploitant toutes les langues disponibles
</p>
<p>La figure 2 pr&#233;sente les scores automatiques BLEU, TER (Translation Edit Rate) et WER (Word
Error Rate) obtenus en ajoutant au score du d&#233;codeur un score de pr&#233;cision n-gram pour chacune
</p>
<p>3Nous avons exp&#233;riment&#233; avec d&#8217;autres scores, tels que la pr&#233;cision unigram seule ou la moyenne des pr&#233;-
cisions n-grams, dont les moins bons r&#233;sultats, que nous imputons en grande partie au param&#232;trage utilis&#233; pour
l&#8217;optimisation par le simplexe, n&#8217;ont pas &#233;t&#233; rapport&#233;s ici. En outre, le score BLEU ne pouvait pas &#234;tre utilis&#233; car
celui-ci retourne des scores nuls lorsqu&#8217;une valeur de pr&#233;cision n-gram (avec typiquement 1 &#8805; n &#8805; 4) est nulle,
ce qui arrive fr&#233;quemment avec notre approche. L&#8217;utilisation de scores ind&#233;pendants correspondant aux diff&#233;rentes
pr&#233;cisions n-gram pour les diff&#233;rentes langues nous a permis d&#8217;obtenir de bons r&#233;sultats, mais l&#8217;optimisation du
nombre de mod&#232;les correspondants (jusqu&#8217;&#224; 4 &#8727; 9 = 36 avec neuf langues auxiliaires) n&#8217;a pas &#233;t&#233; possible avec la
technique d&#8217;optimisation utilis&#233;e.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Traduction statistique multisource par renforcement lexical
</p>
<p>des neuf langues ajout&#233;es. La condition MultiRef m&#232;ne &#224; des gains sur le corpus de test de +1.29
en BLEU, -2.95 en TER4 et -3.19 en WER, qui montrent la capacit&#233; de la m&#233;thode pr&#233;sent&#233;e &#224;
exploiter &#224; bon escient le renforcement lexical implicitement fourni par l&#8217;utilisation de plusieurs
langues. La condition MultiAuto m&#232;ne elle &#224; des gains bien moins importants (+0.09 BLEU,
-0.53 TER et -0.57 WER), observ&#233;s cependant sur toutes les m&#233;triques, ce qui semble traduire
une am&#233;lioration du syst&#232;me principal. Les raisons principales pour expliquer les faibles gains
obtenus incluent le fait que les syst&#232;mes utilis&#233;s ne sont pas tr&#232;s performants car appris sur peu
de donn&#233;es et n&#8217;int&#232;grent pas de mod&#232;les de d&#233;sambigu&#239;sation lexicale. De plus, la d&#233;pendance
aux seules meilleures sorties de ces syst&#232;mes ne permet pas de renforcer des choix lexicaux
propos&#233;s par les hypoth&#232;ses suivantes.
</p>
<p>Baseline MultiRef MultiAuto
BLEU 30.47 31.76 30.54
TER 53.73 50.78 53.18
WER 58.08 54.89 57.32
</p>
<p>FIG. 2 &#8211; R&#233;sultats pour les m&#233;triques automatiques BLEU, TER et WER en utilisant les neuf
langues disponibles pour les trois syst&#232;mes.
</p>
<p>4.4 Recherche d&#8217;un ensemble minimal de langues
</p>
<p>Les exp&#233;riences rapport&#233;es en 4.3 consid&#232;rent le cas o&#249; toutes les langues disponibles sont
utilis&#233;es. Il est toutefois int&#233;ressant d&#8217;essayer d&#8217;obtenir des performances comparables avec le
moins de langues possible, car cela autorise davantage de contextes d&#8217;utilisation, et permet no-
tamment d&#8217;aborder une traduction fortement multicible par traductions successives. En outre,
il est &#233;galement important de voir si l&#8217;utilisation d&#8217;un nombre de langues auxiliaires plus petit
permet d&#8217;am&#233;liorer les r&#233;sultats d&#8217;un syst&#232;me, ce qui correspondrait &#224; des cas o&#249; une langue
auxiliaire serait moins d&#233;sambigu&#239;satrice que d&#8217;autres relativement &#224; une paire de langues prin-
cipale, et/ou aurait davantage tendance &#224; renforcer de mauvais choix lexicaux et donc &#224; d&#233;grader
les performances d&#8217;un syst&#232;me.
</p>
<p>La recherche d&#8217;une combinaison optimale de langues n&#233;cessite la mise en place et l&#8217;optimi-
sation des syst&#232;mes pour l&#8217;ensemble des configurations possibles pour les langues auxiliaires.
Avec neuf langues comme pr&#233;c&#233;demment, il y aurait donc
</p>
<p>&#8721;
9
</p>
<p>k=1 C
k
9
</p>
<p>= 511 combinaisons &#224;
essayer. Afin de proposer une solution plus g&#233;n&#233;rale s&#8217;appliquant quel que soit le nombre de
langues impliqu&#233;es, nous avons impl&#233;ment&#233; une recherche heuristique gloutone. L&#8217;ensemble
des combinaisons impliquant une seule langue auxiliaire est tout d&#8217;abord &#233;valu&#233;, puis l&#8217;en-
semble des combinaisons impliquant la meilleure langue et une seconde langue, et successive-
ment les combinaisons impliquant jusqu&#8217;&#224; neuf langues. Le nombre maximal de configurations
est ainsi r&#233;duit &#224;
</p>
<p>&#8721;
1
</p>
<p>i=9 i = 45 ; la recherche peut &#234;tre interrompue d&#232;s que des pertes sup&#233;rieures
&#224; un seuil sont observ&#233;es.
</p>
<p>Une approche alternative pour diriger la recherche consiste &#224; estimer les contributions en ren-
forcement lexical positif, ainsi qu&#8217;en renforcement n&#233;gatif. On consid&#232;re pour cela l&#8217;ensemble
I constitu&#233; de l&#8217;intersection, pour chaque phrase &#224; traduire, des n-grams pr&#233;sents dans une tra-
duction de &#171; r&#233;f&#233;rence &#187; pour la langue cible (ensemble T ) et dans les hypoth&#232;ses du syst&#232;me
</p>
<p>4TER et WER sont des taux d&#8217;erreurs : il est souhaitable de les faire diminuer.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>principal (ensemble P). L&#8217;ensemble ordonn&#233; L, initialement vide, correspond &#224; la s&#233;quence des
langues par contribution d&#233;croissante, o&#249; la contribution d&#8217;une langue s&#8217;entend relativement
&#224; l&#8217;ensemble des langues pr&#233;c&#233;demment ajout&#233;es. L&#8217;ensemble R (pour &#171; renforc&#233;s &#187;) contient
l&#8217;ensemble des n-grams issus de I qui ont &#233;t&#233; propos&#233;s par l&#8217;hypoth&#232;se d&#8217;au moins une langue
ajout&#233;e, et est donc initialement vide. Pour &#233;valuer la contribution d&#8217;une nouvelle langue &#233;tant
donn&#233; un &#233;tat pour {L, I,R}, on consid&#232;re les trois valeurs suivantes :
</p>
<p>&#8211; la quantit&#233; de n-grams propos&#233;s par l&#8217;hypoth&#232;se de la langue consid&#233;r&#233;e appartenant &#224; I &#8745; R,
not&#233;e a ; cela correspond au fait de renforcer des n-grams qui n&#8217;avaient pas encore &#233;t&#233; renfor-
c&#233;s par d&#8217;autres langues, ce qui est donc une contribution tr&#232;s souhaitable ;
</p>
<p>&#8211; la quantit&#233; de n-grams propos&#233;s par l&#8217;hypoth&#232;se de la langue consid&#233;r&#233;e appartenant d&#233;j&#224; &#224;
R, not&#233;e b ; cela correspond au fait de renforcer des n-grams d&#233;j&#224; renforc&#233;s par au moins une
autre langue, ce qui est une contribution souhaitable ;
</p>
<p>&#8211; la quantit&#233; de n-grams propos&#233;s par l&#8217;hypoth&#232;se de la langue consid&#233;r&#233;e appartenant &#224; P &#8745;I ,
not&#233;e c ; cela correspond au fait de renforcer des n-grams propos&#233;s par le syst&#232;me principal
mais n&#8217;appartenant pas &#224; la traduction de r&#233;f&#233;rence, ce qui est interpr&#233;t&#233; ici comme une
contribution non souhaitable5.
</p>
<p>Dans cette &#233;tude, la fonction d&#8217;&#233;valuation utilis&#233;e par notre seconde recherche heuristique est :
h(l, I,R,P) = 4 &#8727; a + 2 &#8727; b&#8722; c. Le tableau de la figure 1 donne les r&#233;sultats pour les 3 m&#233;-
triques automatiques pr&#233;c&#233;dentes, tout d&#8217;abord en ajoutant une seule langue, puis apr&#232;s chaque
ajout de langue en suivant les deux m&#233;thodes heuristiques pr&#233;sent&#233;es.
On constate tout d&#8217;abord que les deux langues ayant l&#8217;impact le plus fort individuellement
sont une langue proche de la langue source (espagnol) et une langue proche de la langue cible
(su&#232;dois). Ces deux langues r&#233;alisent la contribution collective la plus marqu&#233;e (par ex., 75%
du gain en BLEU) sur MultiRef.
Il est par ailleurs int&#233;ressant de constater que, hormi pour les trois premi&#232;res langues ajout&#233;es,
les deux heuristiques ne se contentent pas d&#8217;ajouter les langues par impact individuel d&#233;crois-
sant, ce qui laisse entendre que la compl&#233;mentarit&#233; au niveau de la d&#233;sambigu&#239;sation op&#233;r&#233;e
rel&#232;ve de m&#233;canismes assez complexes. Le cas de l&#8217;allemand est &#224; ce titre assez int&#233;ressant,
puisque, dans les s&#233;quences d&#8217;ajout incr&#233;mental de langues, cette langue semble toujours appor-
ter un compl&#233;ment, et notamment dans le cas de la condition MultiAuto. Enfin, notre deuxi&#232;me
heuristique, qui obtient sur MultiRef des performances comparables &#224; la recherche gloutonne,
permet de d&#233;finir &#224; moindre co&#251;t un ordonnancement des langues comp&#233;titif.
</p>
<p>5 Discussion et perspectives
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; une approche permettant d&#8217;am&#233;liorer un syst&#232;me de tra-
duction statistique en utilisant des traductions dans d&#8217;autres langues du texte &#224; traduire. Des
am&#233;liorations significatives sont obtenues lorsque ces traductions sont r&#233;vis&#233;es par des humains.
Nos r&#233;sultats actuels ne montrent cependant pas d&#8217;am&#233;lioration marqu&#233;e lorsque ces traduc-
</p>
<p>5Le fait de consid&#233;rer cette derni&#232;re situation comme non souhaitable est discutable : il pourrait en effet s&#8217;agir
de n-grams participant &#224; des traductions correctes bien qu&#8217;absents de la traduction de r&#233;f&#233;rence. Cela sugg&#232;re la
prise en compte de traductions de r&#233;f&#233;rences multiples, comme dans les mesures d&#8217;&#233;valuation du type de BLEU.
Par ailleurs, on ne consid&#232;re pas ici les n-grams propos&#233;s qui n&#8217;appartiennent pas &#224;P , bien que cette valeur pourrait
&#234;tre utilis&#233;e, en particulier pour juger qu&#8217;une traduction auxiliaire est trop diff&#233;rente des hypoth&#232;ses du syst&#232;me
principal et ne peut donc pas &#234;tre utilis&#233;e par notre approche.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Traduction statistique multisource par renforcement lexical
</p>
<p>Ajout d&#8217;une seule langue (MultiRef)
Language - es sv da fi it de nl el pt
</p>
<p>BLEU 30.47 31.05 30.90 30.76 30.48 30.43 30.59 30.29 30.51 30.62
TER 53.73 52.45 52.83 52.67 53.36 53.25 53.24 53.12 52.87 53.22
WER 58.08 56.67 57.06 56.91 57.61 57.48 57.55 57.34 56.93 57.53
</p>
<p>Recherche gloutone (MultiRef)
Languages - +es +sv +da +fi +it +de +nl +el +pt
</p>
<p>BLEU 30.47 31.05 31.49 31.52 31.54 31.54 31.60 31.79 31.78 31.76
TER 53.73 52.45 51.51 51.59 51.38 51.40 51.09 50.88 50.87 50.78
WER 58.08 56.67 55.69 55.80 55.54 55.53 55.20 55.02 55.00 54.89
</p>
<p>Recherche par ajout de langue par compl&#233;mentarit&#233; d&#233;croissante (MultiRef)
Languages - +es +sv +da +pt +el +de +it +nl +fi
</p>
<p>BLEU 30.47 31.05 31.49 31.52 31.50 31.57 31.73 31.73 31.54 31.76
TER 53.73 52.45 51.51 51.59 51.58 51.55 51.24 51.17 51.12 50.78
WER 58.08 56.67 55.69 55.80 55.71 55.65 55.37 55.35 55.23 54.89
</p>
<p>Recherche par ajout de langue par compl&#233;mentarit&#233; d&#233;croissante (MultiAuto)
Languages - +es +sv +da +pt +el +de +it +nl +fi
</p>
<p>BLEU 30.47 30.50 30.47 30.41 30.53 30.45 30.66 30.48 30.57 30.54
TER 53.73 53.72 53.73 53.63 53.49 53.48 53.35 53.35 53.25 53.18
WER 58.08 58.06 58.08 57.92 57.66 57.76 57.57 57.57 57.40 57.32
</p>
<p>TAB. 1 &#8211; R&#233;sultats sur le corpus de test obtenus pour chaque langue auxiliaire et par ajout
successif de langues auxiliaires avec les deux m&#233;thodes heuristiques
</p>
<p>tions auxiliaires sont produites automatiquement. Nos travaux &#224; venir porteront notamment sur
l&#8217;&#233;tude de l&#8217;impact de l&#8217;am&#233;lioration des syst&#232;mes auxiliaires utilis&#233;s sur la performance du sys-
t&#232;me principal, et sur l&#8217;application &#224; d&#8217;autres paires de langues. En particulier, nous souhaiterons
valider l&#8217;hypoth&#232;se que la prise en compte du contexte source pour des syst&#232;mes auxiliaires, &#224;
la mani&#232;re de (Max et al., 2009), permettra d&#8217;am&#233;liorer notre approche. Nous avons &#233;galement
propos&#233; dans cet article une approche permettant d&#8217;identifier de fa&#231;on heuristique un ensemble
minimal de langues menant aux gains les plus importants. Un r&#233;sultat particulier de notre &#233;tude
est que les langues les plus utiles parmi neuf langues europ&#233;ennes pour am&#233;liorer un syst&#232;me
fran&#231;ais&#8594;anglais sont l&#8217;espagnol et le su&#232;dois.
</p>
<p>Parmi les perspectives de ce travail, nous envisageons &#233;galement d&#8217;int&#233;grer un travail sp&#233;ci-
fique sur l&#8217;optimisation du syst&#232;me de r&#233;&#233;valuation. Par ailleurs, nous porterons notre attention
sur les niveaux de correspondance utilis&#233;s pour le renforcement lexical, en passant du niveau
des phrases compl&#232;tes au niveau des tuples, ainsi que sur l&#8217;am&#233;lioration de la robustesse de
notre approche, en consid&#233;rant plusieurs r&#233;f&#233;rences plut&#244;t qu&#8217;une seule ou en ayant recours aux
lemmes, synonymes ou paraphrases locales des n-grams impliqu&#233;s.
</p>
<p>R&#233;f&#233;rences
CALLISON-BURCH C., FORDYCE C. S., KOEHN P., MONZ C. &amp; SCHROEDER J. (2008).
Further meta-evaluation of machine translation. In Proceedings of the Third Workshop on
Statistical Machine Translation, p. 70&#8211;106, Columbus, Ohio.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CARPUAT M. &amp; WU D. (2005). Word sense disambiguation vs statistical machine translation.
In Proceedings of ACL, p. 387&#8211;394, Ann Arbor, USA.
CREGO J. &amp; MARI&#209;O J. (2007). Improving statistical mt by coupling reordering and deco-
ding. Machine Translation, 20(3), 199&#8211;215.
HASAN S., BENDER O. &amp; NEY H. (2006). Reranking translation hypotheses using structural
properties. In Proceedings of the EACL06 Workshop on Learning Structured Information in
Natural Language Applications, p. 41&#8211;48, Trento, Italy.
HILDEBRAND A. S. &amp; VOGEL S. (2008). Combination of machine translation systems via
hypothesis selection from combined n-best lists. In Proceedings of the Eighth Conference of
the Association for Machine Translation in the Americas, p. 254&#8211;261, Waikiki, Hawa&#239;.
KOEHN P. (2005). Europarl : A parallel corpus for statistical machine translation. In Procee-
dings of MT Summit, Phuket, Thailand.
KOEHN P., OCH F. J., &amp; MARCU D. (2003). Statistical phrase-based translation. In Procee-
dings of NAACL/HLT, p. 127&#8211;133, Edmonton, Canada.
LEUSCH G., MATUSOV E. &amp; NEY H. (2009). The RWTH system combination system for
WMT 2009. In Proceedings of the ACL workshop on Statistical Machine Translation, p. 51&#8211;
55, Athens, Greece.
MARI&#209;O J., BANCHS R., CREGO J., DE GISPERT A., LAMBERT P., FONOLLOSA J. &amp;
COSTAJUSS&#192; M. (2006). N-gram based machine translation. Computational Linguistics,
32(4), 527&#8211;549.
MAX A., MAKHLOUFI R. &amp; LANGLAIS P. (2009). Prise en compte de d&#233;pendances syn-
taxiques pour la traduction contextuelle de segments. In Actes de TALN 2009, Senlis, France.
NELDER J. &amp; MEAD R. (1965). A simplex method for function minimization. The Computer
Journal, 7, 308&#8211;313.
NOMOTO T. (2004). Multi-engine machine translation with voted language model. In Procee-
dings of the 42nd Meeting of the Association for Computational Linguistics (ACL&#8217;04), Main
Volume, p. 494&#8211;501, Barcelona, Spain.
OCH F. J. &amp; NEY H. (2001). Statistical multi-source translation. In Proceedings of MT
Summit, Santiago de Compostela, Spain.
PAPINENI K., ROUKOS S., WARD T. &amp; ZHU W.-J. (2002). Bleu : a method for automatic
evaluation of machine translation. In Proceedings of ACL, p. 127&#8211;133, Philadelphia, USA.
ROSTI A.-V., AYAN N. F., XIANG B., MATSOUKAS S., SCHWATZ R. &amp; DORR B. J. (2007).
Combining outputs from multiple machine translation systems. In Proceedings of NAACL-
HTL, p. 127&#8211;133, Rochester, USA.
SCHWARTZ L. (2008). Multi-source translation methods. In MT at work : Proceedings of the
Eighth Conference of the Association for Machine Translation in the Americas, p. 279&#8211;288,
Waikiki, Hawa&#239;.
SHEN L., SARKAR A. &amp; OCH F. J. (2004). Discriminative reranking for machine translation.
In D. M. SUSAN DUMAIS &amp; S. ROUKOS, Eds., HLT-NAACL 2004 : Main Proceedings, p.
177&#8211;184, Boston, Massachusetts, USA : Association for Computational Linguistics.
WU H. &amp; WANG H. (2007). Pivot language approach for phrase-based statistical machine
translation. In Proceedings of the 45th Annual Meeting of the Association of Computational
Linguistics, p. 856&#8211;863, Prague, Czech Republic.</p>

</div></div>
</body></html>