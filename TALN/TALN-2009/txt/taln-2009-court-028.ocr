TALN 2009 — Session posters , Senlis, 24-26 juin 2009

Plusieurs langues (bien choisies) valent mieux qu’une :
traduction statistique multi-source par renforcement lexical

J osep Maria Cregol, Aurélien Max” et Francois Yvon”
{j mcrego,amax,yvon} @ limsi.fr
(1) LIMSI-CNRS, Orsay
(2) Université Paris-Sud 11, Orsay

Résumé. Les systemes de traduction statistiques integrent différents types de modeles
dont les prédictions sont combinées, lors du décodage, aﬁn de produire les meilleures traduc-
tions possibles. Traduire correctement des mots polysémiques, comme, par exemple, le mot
avocat du frangais vers l’anglais (lawyer ou avocado), requiert l’utilisation de modeles supple-
mentaires, dont 1’ estimation et l’intégration s’averent complexes. Une alternative consiste a tirer
parti de l’observation selon laquelle les ambigu'1'tés liées a la polysémie ne sont pas les memes
selon les langues source considérées. Si l’on dispose, par exemple, d’une traduction vers l’espa-
gnol dans laquelle avocat a été traduit par aguacate, alors la traduction de ce mot vers l’anglais
n’est plus ambigue. Ainsi, la connaissance d’une traduction fran<;ais—> espagnol permet de ren-
forcer la sélection de la traduction avocado pour le systeme frangais—> anglais. Dans cet article,
nous proposons d’utiliser des documents en plusieurs langues pour renforcer les choix lexicaux
effectués par un systeme de traduction automatique. En particulier, nous montrons une amelio-
ration des performances sur plusieurs métriques lorsque les traductions auxiliaires utilisées sont
obtenues manuellement.

Abstract. Statistical Machine Translation (SMT) systems integrate various models that
exploit all available features during decoding to produce the best possible translation hypo-
theses. Correctly translating polysemous words, such as the French word avocat into English
(lawyer or avocado) requires integrating complex models. Such translation lexical ambiguities,
however, depend on the language pair considered. If one knows, for instance, that avocat was
translated into Spanish as aguacate, then translating it into English is no longer ambiguous
(avocado). Thus, in this example, the knowledge of the Spanish translation allows to reinforce
the choice of the appropriate English word for the French—> English system. In this article, we
present an approach in which documents available in several languages are used to reinforce the
lexical choices made by a SMT system. In particular, we show that gains can be obtained on
several metrics when using auxiliary translations produced by human translators.

M0tS-CléS I Traduction automatique statistique, désambiguisation lexicale, réévaluation
de listes d’hypotheses.

Keywords: Statistical Machine Translation, Word Sense Disambiguation, N-best list
rescoring.

1 Introduction

Les systemes de traduction statistiques actuels integrent differents modeles qui mettent en jeu,
lors du decodage, le plus d’informations disponibles aﬁn de produire les meilleures traductions
possibles. En particulier, dans leur version standard, ces systemes embarquent un modele de
traduction qui probabilise la correspondance entre des sequences de taille variable en source
et en cible, un modele de reordonnancement, qui evalue les distortions entre l’ordre des mots
en source et en cible, et un modele de langage, qui determine la probabilite des phrases cible
(Koehn et al., 2003). Les scores combines de ces trois modeles permettent de determiner la
meilleure traduction pour le systeme. Une deﬁcience, soulignee dans de nombreux travaux, de
cette approche est l’absence d’un modele permettant de resoudre explicitement les ambigu'1'tes
semantiques en source (Carpuat & Wu, 2005).

I-/Etendre les systemes standard, aﬁn de pouvoir traduire correctement des mots polysemiques,
comme par exemple le mot avocat du frangais vers l’anglais (lawyer ou avocado), requiert l’in-
tegration de modeles complexes (voir par ex. (Max et al., 2009)). Or, cette difﬁculte inherente
a la polysemie n’est pas la meme en fonction des langues sources considerees. Si l’on dispose,
par exemple, d’un document en espagnol dans lequel avocat a ete traduit par aguacate, alors la
traduction de ce mot vers l’anglais n’est pas ambigue et permet donc de renforcer la selection
de la traduction avocado pour le systeme fran<;ais—> anglais. Dans cet article, nous proposons
d’utiliser des documents en plusieurs langues pour renforcer les choix lexicaux operes par un
systeme de traduction automatique. L’objectif general est d’ameliorer un systeme pour une
paire de langues L1—> L2 en exploitant conjointement des traductions disponibles dans d’autres
langues L,- (avec i > 2) et les sorties de systemes automatiques L,-—> L2. Nous presentons deux
manieres d’aborder ce probleme : 1) en exploitant des traductions humaines disponibles entre
les langues L1 et L,-, et 2) en exploitant des traductions automatiques entre les langues L1 et L,-.

Cet article est organise comme suit. Nous commengons par analyser brievement les approches
permettant d’exploiter plusieurs systemes et des entrees multiples (section 2). Nous decrivons
ensuite les particularites de notre approche (section 3.1), et les architectures correspondant aux
deux contextes d’application (section 3.2). Nous presentons une evaluation de notre approche
sur une tache de traduction frangais—> anglais (section 4.1) et les scores de reevaluation des
hypotheses de traduction utilises (section 4.2). Les resultats obtenus en utilisant simultanement
les neuf langues auxiliaires disponibles sont presentes (section 4.3), puis nous decrivons deux
strategies de recherche heuristique permettant de trouver des ensembles de langues minimaux
menant aux meilleurs resultats possibles (section 4.4). Nous discutons enﬁn nos resultats et
concluons (section 5).

2 Travaux antérieurs

La reevaluation des meilleures hypotheses (N-best list reranking) produites par un systeme de
traduction automatique statistique est frequemment operee comme un post-traitement en sortie
d’un decodeur (ex. (Shen et al., 2004)), car elle permet d’appliquer des modeles plus ﬁns pour
la selection de la meilleure hypothese sur la liste des N meilleures traductions proposees en
premiere passel. Il est ainsi possible de calculer les scores de modeles difﬁciles a integrer lors

1Une evaluation de type oracle sur une sortie constituee de 1000 meilleures hypotheses pour nos experiences
decrites dans la section 4 montre un potentiel important d’un gain de 8.8 points BLEU entre la meilleure hypothese

Traduction statistique multisource par renforcement lexical

du décodage (par ex. utilisation d’un modele de langue a grand empan) ou nécessitant des
hypotheses correspondant a des phrases completes, lorsqu’il s’agit par exemple d’exploiter des
traits syntaxiques (Hasan et al., 2006).

Un nombre important de travaux ont également porté sur l’exploitation conjointe des sorties
proposées par plusieurs systemes distincts, aﬁn notamment de faire bénéﬁcier le systeme com-
biné des forces de chacune des approches implémentées. L’étude présentée par (Rosti et al.,
2007) porte sur la combinaison de sorties de systemes a différents niveaux et montre que les
meilleurs gains sont obtenus en combinant les hypotheses a la fois au niveau des mots, des
segments et des phrases.

Si la majorité des travaux dans le domaine portent sur la combinaison de systemes implémen-
tant des approches différentes pour une meme paire de langues, (Och & Ney, 2001) ont pro-
pose d’utiliser des traductions disponibles en plusieurs langues et de les traduire vers une meme
langue, puis de sélectionner pour chaque phrase la traduction obtenue menant au meilleur score,
ce qui revient implicitement a sélectionner la meilleure langue source pour chaque phrase a tra-
duire. En procédant de cette maniere, ils observent des améliorations notables pour la métrique
WER. (Nomoto, 2004) s’inscrit dans la meme logique, en reclassant les différentes hypotheses
proposées par un modele de langue cible. Les expériences plus récentes de Schwartz (Schwartz,
2008), si elles mettent clairement en évidence les potentialités de l’approche multi-source, sou-
lignent les liIr1ites de la démarche de Och et Ney, dont les gains (pour la métrique BLEU)
s’averent plus faibles qu’espéré, et discute d’altematives. Parmi celles-ci, l’utilisation de ré-
seaux de concensus construits a partir de traductions de langues différentes, est conceptuelle-
ment simple a implémenter, et conduit effectivement a des améliorations importantes (Callison-
Burch et al., 2008; Leusch et al., 2009). Notre méthode, qui s’appuie sur les memes intuitions
que ces travaux, utilise des moyens sensiblement différents : a la maniere de (Hildebrand & Vo-
gel, 2008) (qui ne manipulent qu’une langue source) la combinaison de systemes s’opere dans
une étape de réévaluation, durant laquelle les différentes hypotheses sont renforcées explicite-
ment via des scores qui favorisent les traductions concensuelles.

3 Traduction multisource par renforcement lexical

3.1 Description de l’approche

Notre approche vise a améliorer les performances d’un systeme pour une paire de langues par-
ticuliere en exploitant des textes source disponibles en plusieurs langues. Elle se distingue tou-
tefois des approches comparables dans la mesure ou elle privilégie une direction de traduction
(correspondant au systeme que nous désignerons dans la suite comme le systeme principal);
les autres sources disponibles (alimentant des systemes auxiliaires) fournissent des informa-
tions supplémentaires susceptibles d’aider le systeme principal.

L’ objectif poursuivi est de renforcer les choix lexicaux qui sont présents dans les hypotheses
multiples du systeme (N -best lists) et également proposés par des systemes traduisant depuis
d’autres langues vers la meme langue cible. Par exemple, lorsque la traduction d’un mot poly-
sémique est ambigue, si l’on dispose d’une traduction du texte a traduire dans une autre langue
pour laquelle la traduction n’est pas ambigue, alors cette traduction peut étre préférée. Le mot

du systéme initial et la meilleure hypothése pour chaque phrase relativement au score BLEU.

francais avocat, dont deux sens peuvent se traduire en anglais par lawyer et avocado, possede
également deux traductions couvrant les memes sens en espagnol, respectivement abogado et
aguacate, mais la traduction de chacune d’elles vers l’anglais n’est plus ambigue. La connais-
sance de la traduction en espagnol permet donc de choisir la traduction en anglais. En général,
cependant, il est difﬁcile de garantir qu’une traduction n’est pas ambigue. Les traductions pro-
posées a partir d’autres langues pourront donc jouer le role d’indices venant renforcer les choix
du systeme principal.

Une caractéristique importante de cette approche est la dépendance des performances du sys-
teme principal aux systemes auxiliaires utilisés. En effet, si ces systemes tendent a produire de
mauvaises traductions, ils peuvent renforcer de mauvaises hypotheses. A l’inverse, une amé-
lioration sensible d’un systeme auxiliaire permettra d’améliorer le renforcement des choix du
systeme principal, sans que celui-ci n’ait eu a connaitre d’aInélioration directe. Une implemen-
tation performante de cette approche permettra donc un cercle vertueux, ou les améliorations
d’un systeme proﬁteront également aux autres.

En outre, l’approche proposée se distingue de l’approche pivot plus traditionnelle (ex., (Wu &
Wang, 2007)) dans laquelle un systeme est construit pour une paire de langues en traduisant
successivement de la langue source vers une langue intermédiaire, puis de cette langue intermé-
diaire vers la langue cible. Si ce type d’approche est intéressant lorsque les ressources paralleles
disponibles sont trop limitées pour constuire un systeme de traduction direct, elle a come in-
convénient que les erreurs commises lors de la traduction de la langue source vers la langue
pivot sont difﬁcilement réparables. La traduction multisource par renforcement lexical permet
de renforcer certaines hypotheses d’un systeme, et offre donc des perspectives de correction de
la meilleure hypothese produite par un systeme par sélection d’une autre hypothese. Il est, par
ailleurs, possible de n’utiliser qu’une seule langue auxiliaire, et les performances du systeme
seront d’autant améliorées que cette langue sera bien choisie.

3.2 Contextes d’utilisation et architectures des systémes

Il existe de nombreux contextes dans lesquels des traductions existent dans plusieurs langues
et ou l’on peut souhaiter traduire vers de nouvelles langues, comme dans le cas de traductions
de manuels techniques, ou des traductions sont tout d’abord effectuées vers des langues princi-
pales puis vers des langues a impact commercial moins important. Un tel contexte de traduction
en série permet l’exploitation conjointe, par un systeme automatique, de textes déja traduits en
plusieurs langues. L’ architecture de l’expérience MultiRef correspondante est présentée dans la
partie gauche de la ﬁgure 1. Dans cet exemple, on traduit un texte du francais vers l’anglais,
en utilisant les traductions vers l’anglais des textes disponibles en espagnol, allemand et néer-
landais. Ces traductions sont utilisées par un module de réévaluation des meilleures hypotheses
du systeme principal, qui sélectionne de nouvelles hypotheses sur la base d’un renforcement
lexical. Ce type de réévaluation est particulierement utile lorsqu’il permet de calculer les scores
de modeles qui requierent des phrases cibles completes. Bien que cette contrainte ne soit pas
imposée par notre approche, la réévaluation permet ici de ne pas avoir a modiﬁer les décodeurs
des systemes de traduction.

La sélection d’hypotheses par renforcement lexical se base cependant sur l’hypothese forte que
les différents textes disponibles seront des traductions assez directes les uns des autres, et qu’ils
n’auront pas subi une «localisation » trop importante. Les traductions automatiques, qui sont
souvent plus littérales, peuvent ici étre utilisées de facon avantageuse. Dans ce contexte, on

Traduction statistique multisource par renforcement lexical

pourrait penser que le renforcement lexical pourrait plus simplement étre effectué par consul-
tation des modeles de traduction. Or, un systeme de traduction met en jeu plusieurs modeles,
dont en particulier un modele de langue cible, qui ont pour but de mieux choisir les traductions
en contexte. La partie droite de la ﬁgure 1 présente l’architecture de l’expérience MultiAuto,
dans laquelle plusieurs langues auxiliaires sont utilisées. Les langues utilisées sont les memes
que pour l’exemple précédent, mais les traductions du texte a traduire en espagnol, allemand
et hollandais sont ici obtenues de facon automatique. Ce contexte correspond a des situations
beaucoup plus communes dans lesquelles un seul texte source est disponible.

'11-aducllon men réévaluatiun
Traduction: fr:* ?

ii:

Systéme fr:en MultiRef Systéme fr:en MultiAuto

[Tnductlon fr:an réévamation

 

 

   

 

FIG. 1 — Architecture de deux systemes MultiRef et MultiAuto pour la paire francais—> anglais
avec l’espagnol, l’allemand et le néerlandais comme langues auxiliaires.

4 Expériences et résultats

4.1 Données et systémes utilisés

Comme source de textes paralleles fortement multilingues, nous avons utilisé le corpus de de-
bats parlementaires européens Europarl (Koehn, 2005) pour les 11 langues suivantes : allemand
(de), anglais (en), danois (da), espagnol (es), ﬁnlandais (ﬁ), francais (fr), grec (el), italien (it),
néerlandais (nl), portugais (pt) et suedois (sv). Aﬁn d’utiliser des systemes aux performances
comparables, nous avons retenu la partie commune a toutes les langues du corpus, pour un total
de 318 804 lignes (soit environ 10,3 millions de mots pour le francais). La paire de langues
principale pour nos expériences est la paire francais—> anglais.

Tous nos systemes sont des systemes statistiques basés sur les tuples (Crego & Mariﬁo, 2007),
qui combinent linéairement plusieurs scores. Un modele de traduction est estimé comme un
modele de langue n-gram basé sur les tuples, qui déﬁnit une probabilité jointe entre les langues
d’une paire (Mariﬁo et al., 2006). Lors du décodage, seuls les réordonnancements encodés dans
un treillis de mots sont considérés. Le modele de réordonnancement en source est appris au-
tomatiquement depuis un corpus parallele bilingue aligné au niveau des mots, et est appliqué
aux phrases a traduire avant leur traduction. Les catégories morphosyntaxiques sont utilisées
pour généraliser le modele de réordonnancement. Une regle telle que N N J J «»> J J N N per-
met par exemple d’exprimer l’inversion adjectif-nom entre le francais et l’anglais. Les phrases
en francais, espagnol et allemand sont analysées avec le TreeTagger2 pour obtenir les catego-
ries morphosyntaxiques ; pour les autres langues, les regles de réordonnancement sont apprises

Zhttp://www.ims.uni—stuttgart.de/projekte/corplex/TreeTagger.

directement sur des séquences de formes, ce qui conduit, en pratique, a des systemes moins
performants. Une implémentation maison de la recherche du simplexe (Nelder & Mead, 1965)
est utilisée pour déterminer les pondérations des différents modeles, en optimisant les scores
BLEU (Papineni et al., 2002) obtenus sur un corpus de développement.

Le systeme de référence correspond a un systeme de traduction a base de tuples standard. Les
systemes MultiRef et MultiAuto, correspondant respectivement a un systeme multisource utili-
sant des traductions de référence et a un systeme multisource utilisant des traductions automa-
tiques, exploitent les neuf langues auxiliaires restantes.

4.2 Réévaluation de listes d’hypothéses

Nous fondons notre réévaluation des hypotheses du systeme principal sur le score donné par le
décodeur pour chaque hypothese, ainsi que sur le nombre de n-grams d’une traduction candidate
qui sont également présents dans une ou plusieurs traductions de « référence », a la maniere de
la métrique automatique BLEU, qui privilégie les traductions qui sont de taille comparable
avec une traduction servant de référence et partageant le plus de n-grams communs avec celle-
ci. Pour les scores portant sur les unigrammes, seuls les mots n’appartenant pas une liste de
mots vides (obtenue par seuillage sur les fréquences a partir du corpus d’apprentissage) ont été
retenus, aﬁn de ne pas donner trop d’importance a la présence de mots outils pour lesquels notre
approche n’est sﬁrement pas adaptée. Cette limitation ne pouvait cependant pas s’appliquer de
facon naturelle aux n-grams plus grands. Le score calculé par un modele (interprétable comme
un coﬁt) pour chaque langue auxiliaire l correspond a3 :

sc0re(l) = 31 — npn(l)) (1)

2 - - 2 - . |N1{“‘nN$ff I
np est la precision n-gram deﬁnie comme . npn = T
TL

respectivement a l’ensemble des mots pleins de l’hypothese et de la référence, et Nffyp et Ngef
(22n24) correspondent aux n-grams de mots.

\ h.
, ou N1 W’ et Nfef correspondent

Une seconde étape de réglage des poids associés a ces différents scores est effectuée sur un
corpus de développement, de nouveau grace a la méthode du simplexe, qui permet de trouver la
combinaison de poids maximisant le score BLEU sur ce corpus.

4.3 Résultats exploitant toutes les langues disponibles

La ﬁgure 2 présente les scores automatiques BLEU, TER (Translation Edit Rate) et WER (Word
Error Rate) obtenus en aj outant au score du décodeur un score de précision n- gram pour chacune

3Nous avons expérimenté avec d’autres scores, tels que la precision unigram seule ou la moyenne des pré-
cisions n—grams, dont les moins bons résultats, que nous imputons en grande partie au parametrage utilise pour
l’optimisation par le simplexe, n’ont pas été rapportés ici. En outre, le score BLEU ne pouvait pas etre utilise car
celui—ci retoume des scores nuls lorsqu’une Valeur de precision n—gram (avec typiquement 1 2 n 2 4) est nulle,
ce qui arrive fréquemment avec notre approche. L’ utilisation de scores indépendants correspondant aux différentes
précisions n—gram pour les différentes langues nous a pennis d’obtenir de bons résultats, mais l’optimisation du
nombre de modeles correspondants (iusqu’a 4 * 9 = 36 avec neuf langues auxiliaires) n’a pas été possible avec la
technique d’optimisation utilisée.

Traduction statistique multisource par renforcement lexical

des neuf langues ajoutées. La condition MultiRef mene a des gains sur le corpus de test de +1.29
en BLEU, -2.95 en TER4 et -3. 19 en WER, qui montrent la capacité de la méthode présentée a
exploiter a bon escient le renforcement lexical implicitement fourni par l’utilisation de plusieurs
langues. La condition MultiAuto mene elle a des gains bien moins importants (+0.09 BLEU,
-0.53 TER et -0.57 WER), observés cependant sur toutes les métriques, ce qui semble traduire
une amélioration du systeme principal. Les raisons principales pour expliquer les faibles gains
obtenus incluent le fait que les systemes utilisés ne sont pas tres performants car appris sur peu
de données et n’integrent pas de modeles de désambigu'1'sation lexicale. De plus, la dépendance
aux seules meilleures sorties de ces systemes ne permet pas de renforcer des choix lexicaux
proposés par les hypotheses suivantes.

Baseline MultiRef M11ltiAuto
BLEU 30.47 31.76 30.54
TER 53.73 50.78 53.18
WER 58.08 54.89 57.32

FIG. 2 — Résultats pour les métriques automatiques BLEU, TER et WER en utilisant les neuf
langues disponibles pour les trois systemes.

4.4 Recherche d’un ensemble minimal de langues

Les expériences rapportées en 4.3 considerent le cas ou toutes les langues disponibles sont
utilisées. Il est toutefois intéressant d’essayer d’obtenir des performances comparables avec le
moins de langues possible, car cela autorise davantage de contextes d’utilisation, et permet no-
tamment d’aborder une traduction fortement multicible par traductions successives. En outre,
il est également important de voir si l’utilisation d’un nombre de langues auxiliaires plus petit
permet d’améliorer les résultats d’un systeme, ce qui correspondrait a des cas ou une langue
auxiliaire serait moins désambiguisatrice que d’autres relativement a une paire de langues prin-
cipale, et/ou aurait davantage tendance a renforcer de mauvais choix lexicaux et donc a dégrader
les performances d’un systeme.

La recherche d’une combinaison optimale de langues nécessite la mise en place et l’optiIr1i-
sation des systemes pour l’ensemble des conﬁgurations possibles pour les langues auxiliaires.
Avec neuf langues comme précédemment, il y aurait donc 2221 C’; = 511 combinaisons a
essayer. Aﬁn de proposer une solution plus générale s’appliquant quel que soit le nombre de
langues impliquées, nous avons implémenté une recherche heuristique gloutone. L’ ensemble
des combinaisons impliquant une seule langue auxiliaire est tout d’abord évalué, puis l’en-
semble des combinaisons impliquant la meilleure langue et une seconde langue, et successive-
ment les combinaisons impliquant jusqu’a neuf langues. Le nombre maximal de conﬁgurations
est ainsi réduit a 2:29 i = 45 ; la recherche peut étre interrompue des que des pertes supérieures
a un seuil sont observées.

Une approche alternative pour diriger la recherche consiste a estimer les contributions en ren-
forcement lexical positif, ainsi qu’en renforcement négatif. On considere pour cela l’ensemble
I constitué de l’intersection, pour chaque phrase a traduire, des n-grams présents dans une tra-
duction de « référence » pour la langue cible (ensemble T) et dans les hypotheses du systeme

4TER et WER sont des taux d’erreurs : il est souhaitable de les faire diminuer.

principal (ensemble 7?). L’ ensemble ordonne LI, initialement vide, correspond a la sequence des
langues par contribution decroissante, ou la contribution d’une langue s’entend relativement
a l’ensemble des langues precedemment ajoutees. L’ensemble R (pour « renforces ») contient
l’ensemble des n-grams issus de I qui ont ete proposes par l’hypothese d’au moins une langue
ajoutee, et est donc initialement vide. Pour evaluer la contribution d’une nouvelle langue etant
donne un etat pour {L',, I, R}, on considere les trois valeurs suivantes :

— la quantite de n-grams proposes par l’hypothese de la langue consideree appartenant a I D R,
notee a ; cela correspond au fait de renforcer des n-grams qui n’avaient pas encore ete renfor-
ces par d’autres langues, ce qui est donc une contribution tres souhaitable;

— la quantite de n-grams proposes par l’hypothese de la langue consideree appartenant deja a
R, notee b ; cela correspond au fait de renforcer des n-grams deja renforces par au moins une
autre langue, ce qui est une contribution souhaitable;

— la quantite de n-grams proposes par l’hypothese de la langue consideree appartenant a 73 HT,
notee c; cela correspond au fait de renforcer des n-grams proposes par le systeme principal
mais n’appartenant pas a la traduction de reference, ce qui est interprete ici comme une
contribution non souhaitable5 .

Dans cette etude, la fonction d’evaluation utilisee par notre seconde recherche heuristique est :
h(l,I, R, 73) = 4 >:< a + 2 * b — c. Le tableau de la ﬁgure 1 donne les resultats pour les 3 me-
triques automatiques precedentes, tout d’abord en ajoutant une seule langue, puis apres chaque
ajout de langue en suivant les deux methodes heuristiques presentees.

On constate tout d’abord que les deux langues ayant l’impact le plus fort individuellement
sont une langue proche de la langue source (espagnol) et une langue proche de la langue cible
(suedois). Ces deux langues realisent la contribution collective la plus marquee (par eX., 75%
du gain en BLEU) sur MultiRef.

Il est par ailleurs interessant de constater que, hormi pour les trois premieres langues ajoutees,
les deux heuristiques ne se contentent pas d’ajouter les langues par impact individuel decrois-
sant, ce qui laisse entendre que la complementarite au niveau de la desambigu'1'sation operee
releve de mecanismes assez complexes. Le cas de l’allemand est a ce titre assez interessant,
puisque, dans les sequences d’ajout incremental de langues, cette langue semble toujours appor-
ter un complement, et notamment dans le cas de la condition MultiAuto. Enﬁn, notre deuxieme
heuristique, qui obtient sur MultiRef des performances comparables a la recherche gloutonne,
permet de deﬁnir a moindre coﬁt un ordonnancement des langues competitif.

5 Discussion et perspectives

Dans cet article, nous avons presente une approche permettant d’ameliorer un systeme de tra-
duction statistique en utilisant des traductions dans d’autres langues du texte a traduire. Des
ameliorations signiﬁcatives sont obtenues lorsque ces traductions sont revisees par des humains.
Nos resultats actuels ne montrent cependant pas d’amelioration marquee lorsque ces traduc-

5Le fait de considerer cette derniere situation comme non souhaitable est discutable : il pourrait en effet s’agir
de n-grams participant a des traductions correctes bien qu’absents de la traduction de reference. Cela suggere la
prise en compte de traductions de references multiples, comme dans les mesures d’eVa1uation du type de BLEU.
Par ailleurs, on ne considere pas ici les n—grarns proposes qui n’ appartiennent pas a 73, bien que cette Valeur pourrait
étre utilisée, en particulier pour juger qu’une traduction auxiliaire est trop djfferente des hypotheses du systeme
principal et ne peut donc pas étre utilisée par notre approche.

Traduction statistique multisource par renforcement lexical

Ajout d’une se11le langue (MultiRef)

Language - es sv da ﬁ it de nl el pt

BLEU 30.47 31.05 30.90 30.76 30.48 30.43 30.59 30.29 30.51 30.62

TER 53.73 52.45 52.83 52.67 53.36 53.25 53.24 53.12 52.87 53.22

WER 58.08 56.67 57.06 56.91 57.61 57.48 57.55 57.34 56.93 57.53

Recherche gloutone (MultiRef)

Languages - +es +sv +da +ﬁ +it +de +nl +el +pt

BLEU 30.47 31.05 31.49 31.52 31.54 31.54 31.60 31.79 31.78 31.76

TER 53.73 52.45 51.51 51.59 51.38 51.40 51.09 50.88 50.87 50.78

WER 58.08 56.67 55.69 55.80 55.54 55.53 55.20 55.02 55.00 54.89

Recherche par ajout de langue par complémentarité décroissante (MultiRef)

Languages - +es +sv +da +pt +el +de +it +nl +ﬁ

BLEU 30.47 31.05 31.49 31.52 31.50 31.57 31.73 31.73 31.54 31.76

TER 53.73 52.45 51.51 51.59 51.58 51.55 51.24 51.17 51.12 50.78

WER 58.08 56.67 55.69 55.80 55.71 55.65 55.37 55.35 55.23 54.89

Recherche par ajout de langue par complémentarité décroissante (MultiAuto)
Languages - +es +sv +da +pt +el +de +it +nl +ﬁ

BLEU 30.47 30.50 30.47 30.41 30.53 30.45 30.66 30.48 30.57 30.54

TER 53.73 53.72 53.73 53.63 53.49 53.48 53.35 53.35 53.25 53.18

WER 58.08 58.06 58.08 57.92 57.66 57.76 57.57 57.57 57.40 57.32

TAB. 1 — Résultats sur le corpus de test obtenus pour chaque langue auxiliaire et par ajout
successif de langues auxiliaires avec les deux méthodes heuristiques

tions auxiliaires sont produites automatiquement. Nos travaux a venir porteront notamment sur
l’étude de l’impact de l’amélioration des systemes auxiliaires utilisés sur la performance du sys-
teme principal, et sur l’application a d’autres paires de langues. En particulier, nous souhaiterons
valider l’hypothese que la prise en compte du contexte source pour des systemes auxiliaires, a
la maniere de (Max et al., 2009), permettra d’améliorer notre approche. Nous avons également
proposé dans cet article une approche permettant d’identiﬁer de facon heuristique un ensemble
minimal de langues menant aux gains les plus importants. Un résultat particulier de notre étude
est que les langues les plus utiles parmi neuf langues européennes pour améliorer un systeme
francais—> anglais sont l’espagnol et le suedois.

Parmi les perspectives de ce travail, nous envisageons également d’intégrer un travail speci-
ﬁque sur l’optimisation du systeme de réévaluation. Par ailleurs, nous porterons notre attention
sur les niveaux de correspondance utilisés pour le renforcement lexical, en passant du niveau
des phrases completes au niveau des tuples, ainsi que sur l’amélioration de la robustesse de
notre approche, en considérant plusieurs références plutot qu’une seule ou en ayant recours aux
lemmes, synonymes ou paraphrases locales des n-grams impliqués.

Références

CALLISON-BURCH C., FORDYCE C. S., KOEHN P., MONZ C. & SCHROEDER J. (2008).
Further meta-evaluation of machine translation. In Proceedings of the Third Workshop on
Statistical Machine Translation, p. 70-106, Columbus, Ohio.

CARPUAT M. & WU D. (2005). Word sense disambiguation vs statistical machine translation.
In Proceedings of ACL, p. 387-394, Ann Arbor, USA.

CREGO J. & MARINO J. (2007). Improving statistical mt by coupling reordering and deco-
ding. Machine Translation, 20(3), 199-215.

HASAN S., BENDER O. & NEY H. (2006). Reranking translation hypotheses using structural
properties. In Proceedings of the EACL06 Workshop on Learning Structured Information in
Natural Language Applications, p. 41-48, Trento, Italy.

HILDEBRAND A. S. & VOGEL S. (2008). Combination of machine translation systems via
hypothesis selection from combined n-best lists. In Proceedings of the Eighth Conference of
the Association for Machine Translation in the Americas, p. 254-261, Waikiki, Hawa'1'.

KOEHN P. (2005). Europarl : A parallel corpus for statistical machine translation. In Procee-
dings of M T Summit, Phuket, Thailand.

KOEHN P., OCH F. J ., & MARCU D. (2003). Statistical phrase-based translation. In Procee-
dings of NAACI/HLT, p. 127-133, Edmonton, Canada.

LEUSCH G., MATUSOV E. & NEY H. (2009). The RWTH system combination system for
WMT 2009. In Proceedings of the ACL workshop on Statistical Machine Translation, p. 51-
55, Athens, Greece.

MARINO J ., BANCHS R., CREGO J ., DE GISPERT A., LAMBERT P., FoNoLLosA J. &
COSTAJUSSA M. (2006). N-gram based machine translation. Computational Linguistics,
32(4), 527-549.

MAX A., MAKHLOUFI R. & LANGLAIS P. (2009). Prise en compte de dépendances syn-
taxiques pour la traduction contextuelle de segments. In Actes de TALN 2009, Senlis, France.

NELDER J . & MEAD R. (1965). A simplex method for function minimization. The Computer
Journal, 7, 308-313.

NOMOTO T. (2004). Multi-engine machine translation with voted language model. In Procee-
dings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main
Volume, p. 494-501, Barcelona, Spain.

OCH F. J . & NEY H. (2001). Statistical multi-source translation. In Proceedings of MT
Summit, Santiago de Compostela, Spain.

PAPINENI K., ROUKOS S., WARD T. & ZHU W.-J. (2002). Bleu : a method for automatic
evaluation of machine translation. In Proceedings of ACL, p. 127-133, Philadelphia, USA.

ROSTI A.-V., AYAN N. F., XIANG B., MATSOUKAS S., SCHWATZ R. & DoRR B. J . (2007).
Combining outputs from multiple machine translation systems. In Proceedings of NAACL-
HTL, p. 127-133, Rochester, USA.

SCHWARTZ L. (2008). Multi-source translation methods. In MT at work .' Proceedings of the
Eighth Conference of the Association for Machine Translation in the Americas, p. 279-288,
Waikiki, Hawa'1'.

SHEN L., SARKAR A. & OCH F. J . (2004). Discriminative reranking for machine translation.
In D. M. SUSAN DUMAIS & S. ROUKOS, Eds., HLT-NAACL 2004 .' Main Proceedings, p.
177-184, Boston, Massachusetts, USA : Association for Computational Linguistics.

WU H. & WANG H. (2007). Pivot language approach for phrase-based statistical machine
translation. In Proceedings of the 45th Annual Meeting of the Association of Computational
Linguistics, p. 856-863, Prague, Czech Republic.

