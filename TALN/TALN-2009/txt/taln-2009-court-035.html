<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>R&#233;sum&#233; automatique multi-document et ind&#233;pendance de la langue : une premi&#232;re &#233;valuation en fran&#231;ais</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009 &#8211; Session posters , Senlis, 24&#8211;26 juin 2009
</p>
<p>R&#233;sum&#233; automatique multi-document et ind&#233;pendance de la
langue : une premi&#232;re &#233;valuation en fran&#231;ais
</p>
<p>Florian Boudin1 Juan-Manuel Torres-Moreno1, 2
</p>
<p>(1) LIA / Universit&#233; d&#8217;Avignon, 339 chemin des Meinajari&#232;s, 84911 Avignon
(2) &#201;cole Polytechnique de Montr&#233;al, CP 6079 Succ. Centre-ville, Montr&#233;al
</p>
<p>{florian.boudin,juan-manuel.torres}@univ-avignon.fr
</p>
<p>R&#233;sum&#233;. Le r&#233;sum&#233; automatique de texte est une probl&#233;matique difficile, fortement d&#233;-
pendante de la langue et qui peut n&#233;cessiter un ensemble de donn&#233;es d&#8217;apprentissage cons&#233;-
quent. L&#8217;approche par extraction peut aider &#224; surmonter ces difficult&#233;s. (Mihalcea, 2004) a d&#233;-
montr&#233; l&#8217;int&#233;r&#234;t des approches &#224; base de graphes pour l&#8217;extraction de segments de texte im-
portants. Dans cette &#233;tude, nous d&#233;crivons une approche ind&#233;pendante de la langue pour la
probl&#233;matique du r&#233;sum&#233; automatique multi-documents. L&#8217;originalit&#233; de notre m&#233;thode repose
sur l&#8217;utilisation d&#8217;une mesure de similarit&#233; permettant le rapprochement de segments morpholo-
giquement proches. De plus, c&#8217;est &#224; notre connaissance la premi&#232;re fois que l&#8217;&#233;valuation d&#8217;une
approche de r&#233;sum&#233; automatique multi-document est conduite sur des textes en fran&#231;ais.
</p>
<p>Abstract. Automatic text summarization is a difficult task, highly language-dependent
and which may require a large training dataset. Recently, (Mihalcea, 2004) has shown that
graph-based approaches applied to the sentence extraction issue can achieve good results. In
this paper, we describe a language-independent approach for automatic multi-document text
summarization. The main originality of our approach is the use of an hybrid similarity measure
during the graph building process that can identify morphologically similar words. Moreover,
this is as far as we know, the first time that the evaluation of a summarization approach is
conducted on French documents.
</p>
<p>Mots-cl&#233;s : R&#233;sum&#233; automatique de texte, Approches &#224; base de graphes, Extraction d&#8217;in-
formation.
</p>
<p>Keywords: Text summarization, Graph-Based approaches, Information Extraction.
</p>
<p>1 Introduction
</p>
<p>Un r&#233;sum&#233; est un texte reformul&#233; dans un espace plus r&#233;duit. Il doit exprimer avec un mini-
mum de mots le contenu essentiel d&#8217;un document. Son but est d&#8217;aider le lecteur &#224; rep&#233;rer les
informations qui peuvent l&#8217;int&#233;resser sans pour autant devoir lire le document en entier. Mais
pourquoi avons-nous tant besoin de r&#233;sum&#233;s ? Simplement parce que nous ne disposons pas
d&#8217;assez de temps et d&#8217;&#233;nergie pour tout lire. La masse d&#8217;information textuelle sous forme &#233;lec-
tronique ne cesse d&#8217;augmenter, que ce soit sur Internet ou dans les r&#233;seaux des entreprises. Ce
volume croissant de textes disponibles rend difficile l&#8217;acc&#232;s &#224; l&#8217;information d&#233;sir&#233;e sans l&#8217;aide
d&#8217;outils sp&#233;cifiques. Mais produire un r&#233;sum&#233; est une t&#226;che tr&#232;s complexe car elle n&#233;cessite des
connaissances linguistiques ainsi que des connaissances du monde qui restent tr&#232;s difficiles &#224;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florian Boudin et Juan-Manuel Torres-Moreno
</p>
<p>incorporer dans un syst&#232;me automatique. Il existe n&#233;anmoins des approches permettant d&#8217;imiter
une partie du processus cognitif du r&#233;sum&#233;. Ces derni&#232;res peuvent &#234;tre regroup&#233;es en deux ca-
t&#233;gories, les m&#233;thodes extractives et abstractives. Bien que des m&#233;thodes par abstraction ont &#233;t&#233;
mises au point, les outils n&#233;cessaires &#224; la compr&#233;hension s&#233;mantique du texte ou &#224; la g&#233;n&#233;ration
de texte en langue naturelle n&#8217;ont pas atteint la maturit&#233; indispensable &#224; une utilisation robuste.
L&#8217;approche que nous proposons repose sur un processus extractif. Dans ce paradigme, les seg-
ments textuels &#8211;le plus souvent des phrases&#8211; contenant les id&#233;es essentielles du document sont
extraits puis assembl&#233;s afin de produire un r&#233;sum&#233;, &#233;galement appel&#233; extrait (Mani &amp; Maybury,
1999).
</p>
<p>Il existe de nombreuses variantes de r&#233;sum&#233; automatique. La plus simple &#233;tant le r&#233;sum&#233; g&#233;-
n&#233;rique mono-document o&#249; il s&#8217;agit de produire un r&#233;sum&#233; en pr&#233;servant au mieux toutes les
id&#233;es essentielles contenues dans un document. Cette variante, qui pourtant para&#238;t &#234;tre la plus
simple, pose encore de nombreux probl&#232;mes. En effet, du type de document que l&#8217;on veut r&#233;-
sumer d&#233;pend les performances des syst&#232;mes. Il est envisageable de g&#233;n&#233;rer un r&#233;sum&#233; &#224; partir
d&#8217;un article de journal tandis qu&#8217;il est, du moins actuellement, quasiment impossible de le faire
&#224; partir d&#8217;&#339;uvres litt&#233;raires (Mihalcea &amp; Ceylan, 2007). Par opposition au r&#233;sum&#233; g&#233;n&#233;rique, la
t&#226;che de r&#233;sum&#233; orient&#233; consiste en la production d&#8217;un r&#233;sum&#233; qui satisfait les besoins d&#8217;un uti-
lisateur. Ces besoins, g&#233;n&#233;ralement exprim&#233;s au moyen d&#8217;une requ&#234;te, doivent permettre au sys-
t&#232;me d&#8217;isoler les parties du document concernant une (plusieurs) th&#233;matique(s) pr&#233;cise(s) pour
ensuite produire un r&#233;sum&#233; n&#8217;incluant que ces derni&#232;res. &#192; ces deux variantes, peut s&#8217;ajouter la
probl&#233;matique des r&#233;sum&#233;s multi-documents. De nouvelles difficult&#233;s sont alors introduites : les
phrases extraites &#224; partir de documents diff&#233;rents peuvent &#234;tre compl&#233;mentaires, redondantes ou
contradictoires. Il faudra donc veiller &#224; la coh&#233;sion des phrases mais surtout &#224; la coh&#233;rence du
r&#233;sum&#233; (absence de contradiction ou de redondance dans l&#8217;encha&#238;nement des phrases).
</p>
<p>&#201;valuer la qualit&#233; d&#8217;un r&#233;sum&#233; est un probl&#232;me difficile auquel la communaut&#233; n&#8217;a pour le mo-
ment su r&#233;pondre qu&#8217;avec des solutions partielles. En effet, il n&#8217;existe pas de r&#233;sum&#233; &#171; id&#233;al &#187;.
Les r&#233;sum&#233;s &#233;crits par des personnes diff&#233;rentes ne sont pas toujours convergents au niveau
du contenu. La r&#233;daction de ce type de document requiert une analyse du texte afin d&#8217;en d&#233;-
gager les id&#233;es, le style et les arguments, ce que chaque personne fait de mani&#232;re diff&#233;rente.
Par cons&#233;quent, deux r&#233;sum&#233;s de contenu informationnel tr&#232;s similaire peuvent &#234;tre produits en
utilisant un vocabulaire totalement diff&#233;rent. De mani&#232;re g&#233;n&#233;rale, les m&#233;thodes d&#8217;&#233;valuation
peuvent &#234;tre class&#233;es en deux cat&#233;gories (Sp&#228;rck Jones &amp; Galliers, 1996). La premi&#232;re regroupe
les &#233;valuations dites extrins&#232;ques, les r&#233;sum&#233;s sont &#233;valu&#233;s en se basant sur leur aptitude &#224; ac-
c&#233;l&#233;rer la compl&#233;tion de t&#226;ches annexes (e.g. l&#8217;utilisation des r&#233;sum&#233;s, &#224; la place des documents
sources, dans des syst&#232;mes question/r&#233;ponse ou de classification de documents). La deuxi&#232;me
cat&#233;gorie r&#233;unit les &#233;valuations intrins&#232;ques, o&#249; les r&#233;sum&#233;s sont alors jug&#233;s directement en se
basant sur leur analyse. Cette t&#226;che peut &#234;tre r&#233;alis&#233;e manuellement (des juges &#233;valuant les qua-
lit&#233;s d&#8217;un r&#233;sum&#233; comme la lisibilit&#233;, la complexit&#233; de la langue ou la pr&#233;sence des concepts
majeurs du document source) ou automatiquement en calculant des mesures de similarit&#233; entre
le r&#233;sum&#233; candidat et un ou plusieurs r&#233;sum&#233;s de r&#233;f&#233;rence. Ce n&#8217;est que tr&#232;s r&#233;cemment que la
communaut&#233; a su mettre &#224; disposition des mesures d&#8217;&#233;valuation automatique pertinentes (Lin,
2004) ainsi que des ensembles de donn&#233;es de qualit&#233; (Nenkova, 2005). Le probl&#232;me majeur res-
tant que la langue utilis&#233;e dans ces corpora est presque toujours l&#8217;anglais. (Ch&#226;ar et al., 2004)
ont n&#233;anmoins propos&#233; un protocole d&#8217;&#233;valuation sur des documents en fran&#231;ais qui utilise les
donn&#233;es des campagnes d&#8217;&#233;valuation CLEF. Bien que ne portant pas sur la qualit&#233; linguistique
des r&#233;sum&#233;s, les mesures d&#8217;&#233;valuation report&#233;es montrent le degr&#233; de pr&#233;cision avec lequel les
unit&#233;s informatives peuvent &#234;tre extraites par leur approche.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;sum&#233; automatique, une premi&#232;re &#233;valuation en fran&#231;ais
</p>
<p>Dans cet article, nous proposons d&#8217;&#233;tudier le comportement de plusieurs approches extractives
ind&#233;pendantes de la langue des documents &#224; traiter. La probl&#233;matique que nous abordons est
le r&#233;sum&#233; g&#233;n&#233;rique multi-documents d&#8217;articles de journaux en fran&#231;ais &#224; partir de m&#233;thodes &#224;
base de graphes. Nous pr&#233;sentons en section 2 un rapide &#233;tat de l&#8217;art sur le r&#233;sum&#233; automatique
de texte et la probl&#233;matique d&#8217;adaptabilit&#233;. Nous montrons en section 3 la m&#233;thode de construc-
tion du graphe et la s&#233;lection des segments bas&#233;e sur son analyse. Nous &#233;valuons notre approche
en section 4 en la comparant aux r&#233;sum&#233;s de r&#233;f&#233;rence produits manuellement. Nous discutons
des r&#233;sultats obtenus en section 5, et proposons des perspectives de recherche.
</p>
<p>2 Travaux pr&#233;c&#233;dents
</p>
<p>(Luhn, 1958) a probablement &#233;t&#233; le premier &#224; proposer une m&#233;thode num&#233;rique pour la pro-
duction d&#8217;extraits. D&#233;j&#224; motiv&#233; par la probl&#233;matique de surcharge d&#8217;information face &#224; des
quantit&#233;s qui peuvent para&#238;tre d&#233;risoires presque 50 ans plus tard, Luhn d&#233;crit une technique
simple, sp&#233;cifique aux articles scientifiques qui utilise la distribution des fr&#233;quences de mots
dans le document pour pond&#233;rer les phrases. Par la suite, (Edmunson, 1969) est all&#233; plus loin
en introduisant des crit&#232;res comme la position des phrases, la pr&#233;sence de mots provenant de la
structure du document (i.e. titres, sous-titres, etc.) ou la pr&#233;sence de mots indices (cue words).
Leurs travaux ont eu un impact consid&#233;rable, la grande majorit&#233; des approches d&#8217;aujourd&#8217;hui
&#233;tant toujours bas&#233;es sur ces m&#234;mes id&#233;es. Quelques-unes de ces approches, parmi lesquelles
certaines font partie des plus performantes (Teufel &amp; Moens, 1997; Hirao et al., 2002), utilisent
des algorithmes supervis&#233;s qui tentent de caract&#233;riser ce qui fait un bon r&#233;sum&#233;. Cependant, le
prix &#224; payer pour obtenir de bons r&#233;sultats est de disposer d&#8217;un ensemble de donn&#233;es d&#8217;appren-
tissage. C&#8217;est ce point qui rend ce type d&#8217;approche difficilement adaptable &#224; d&#8217;autres langues
ou domaines.
</p>
<p>Il existe n&#233;anmoins quelques m&#233;thodes destin&#233;es &#224; r&#233;soudre ce probl&#232;me. Ainsi, (Mihalcea,
2004; Erkan &amp; Radev, 2004) proposent de consid&#233;rer le processus extractif comme une identi-
fication des segments les plus prestigieux dans un graphe. Les algorithmes de classement bas&#233;s
sur les graphes tel que PageRank (Brin &amp; Page, 1998) ont &#233;t&#233; utilis&#233;s avec succ&#232;s dans les
r&#233;seaux sociaux, l&#8217;analyse du nombre de citations ou l&#8217;&#233;tude de la structure du Web. Ces algo-
rithmes peuvent &#234;tre vus comme les &#233;l&#233;ments cl&#233;s du paradigme amorc&#233; dans le domaine de
la recherche sur Internet, &#224; savoir le classement des pages Web par l&#8217;analyse de leurs positions
dans le r&#233;seau et non pas de leurs contenus. En d&#8217;autres termes, ces algorithmes permettent
de d&#233;cider de l&#8217;importance du sommet d&#8217;un graphe en se basant non pas sur l&#8217;analyse locale
du sommet lui m&#234;me, mais sur l&#8217;information globale issue de l&#8217;analyse r&#233;cursive du graphe
complet. Appliqu&#233; au r&#233;sum&#233; automatique cela signifie que le document est repr&#233;sent&#233; par un
graphe d&#8217;unit&#233;s textuelles (phrases) li&#233;es entre elles par des relations issues de calculs de si-
milarit&#233;. Les phrases sont ensuite s&#233;lectionn&#233;es selon des crit&#232;res de centralit&#233; ou de prestige
dans le graphe puis assembl&#233;es pour produire des extraits. Les r&#233;sultats report&#233;s montrent que
les performances des approches &#224; base de graphe sont au niveau des meilleurs syst&#232;mes actuels
(Mihalcea, 2005) mais ne portent que sur des documents en anglais et en portugais. Deux ques-
tions se posent alors : que doit-on attendre des r&#233;sultats sur des documents en fran&#231;ais ? peut-on
am&#233;liorer les performances des syst&#232;mes &#224; base de graphes ?
</p>
<p>Il est important de noter que les m&#233;thodes de classement sont enti&#232;rement d&#233;pendantes de la
bonne construction du graphe sens&#233; repr&#233;senter le document. Puisque ce graphe est g&#233;n&#233;r&#233; &#224;
partir de mesures de similarit&#233;s inter-phrases, l&#8217;impact que peut avoir le choix de la m&#233;thode</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florian Boudin et Juan-Manuel Torres-Moreno
</p>
<p>de calcul est &#224; consid&#233;rer. Dans leurs travaux, (Mihalcea, 2004; Erkan &amp; Radev, 2004) utilisent
le mod&#232;le en sac-de-mots pour repr&#233;senter chaque phrase comme un vecteur &#224; N dimensions,
o&#249; N est le nombre total de mots diff&#233;rents du regroupement et chaque composante du vecteur
un poids tf &#215; idf . Les valeurs de similarit&#233; entre phrases sont ensuite obtenues par un calcul
du cosinus entre leurs repr&#233;sentations vectorielles. Le point faible de cette mesure, et plus g&#233;-
n&#233;ralement de toutes les mesures utilisant les mots comme unit&#233;s, est qu&#8217;elles sont tributaires
du vocabulaire. Dans une optique d&#8217;ind&#233;pendance de la langue, les pr&#233;-traitements qui sont
appliqu&#233;s aux segments se doivent d&#8217;&#234;tre minimaux. C&#8217;est malheureusement dans cette confi-
guration que les performances de la mesure cosinus chutent car elle ne permet en aucun cas
de mettre en relation des mots qui morphologiquement peuvent &#234;tre tr&#232;s proches. Une solution
peut venir de la combinaison avec des mesures de similarit&#233; bas&#233;es sur les caract&#232;res. (Boudin
et al., 2008) proposent une mesure d&#233;riv&#233;e d&#8217;un calcul de similarit&#233; entre cha&#238;nes de caract&#232;res
originellement employ&#233; pour la d&#233;tection d&#8217;entit&#233;s redondantes (Record Linkage). Cette me-
sure permet de cr&#233;er des relations entre deux segments qui m&#234;me s&#8217;il ne partagent aucun mot,
en contiennent des morphologiquement proches. Une seconde question est donc de savoir si
la construction du graphe du document &#224; partir de mesures mixtes (mots et caract&#232;res) permet
d&#8217;am&#233;liorer l&#8217;extraction de segments.
</p>
<p>3 M&#233;thode
</p>
<p>3.1 Construction du graphe
</p>
<p>Afin de permettre aux algorithmes de classement d&#8217;&#234;tre appliqu&#233;s sur des documents en langage
naturel, nous devons construire un graphe qui repr&#233;sente le texte et interconnecte les unit&#233;s
textuelles avec des relations de sens. La nature des relations et la taille des unit&#233;s d&#233;pend bien
entendu du type d&#8217;application que l&#8217;on cible. Pour le r&#233;sum&#233; automatique le choix le plus simple
au niveau de la taille des unit&#233;s est la phrase compl&#232;te. En effet, cela permet lors de la g&#233;n&#233;ration
du r&#233;sum&#233; de ne pas avoir &#224; se soucier de la grammaticalit&#233; des segments assembl&#233;s. Une
connexion entre deux phrases est d&#233;finie comme une mesure de similarit&#233; morphologique. Ce
type de relation peut &#234;tre vu comme une recommandation. Une phrase qui traite de certains
concepts du texte donne au lecteur une recommandation quant aux autres phrases partageant du
contenu en commun.
</p>
<p>Les segments ont tout d&#8217;abord &#233;t&#233; nettoy&#233;s de leurs ponctuation et la casse normalis&#233;e 1. Le seul
pr&#233;-traitement statistique qui leur est appliqu&#233; correspond &#224; un filtrage des mots communs &#224;
l&#8217;aide d&#8217;une liste 2. Il s&#8217;agit d&#8217;un processus simple et facilement adaptable &#224; d&#8217;autres langues ou
domaines. Pour chaque ensemble de documents, un graphe non dirig&#233; et valu&#233; G = (S,A) est
construit. S est l&#8217;ensemble de sommets du graphe et A est l&#8217;ensemble des ar&#234;tes, A &#8838; S &#215; S.
La valeur de chaque ar&#234;te est &#233;valu&#233;e &#224; l&#8217;aide d&#8217;une mesure de similarit&#233; calcul&#233;e entre les
deux n&#339;uds de la connexion. Dans les formulations originelles de (Mihalcea, 2004; Erkan &amp;
Radev, 2004), la mesure de similarit&#233; utilis&#233;e est le cosinus. Nous proposons de la combiner
avec une mesure morphologique de plus longue sous-cha&#238;ne de caract&#232;res, qui nous pensons,
peut permettre d&#8217;augmenter la qualit&#233; des connexions entre segments (voir &#233;quation 1).
</p>
<p>1. Transformation des majuscules en minuscules.
2. Les mots outils et non informatifs sont supprim&#233;s des segments.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;sum&#233; automatique, une premi&#232;re &#233;valuation en fran&#231;ais
</p>
<p>sim(S1, S2) = &#945; &#183; cos(S1, S2) + (1&#8722; &#945;) &#183; LCS&#8727;(S1, S2); 0 &lt; &#945; &lt; 1 (1)
</p>
<p>Le param&#232;tre &#945; a &#233;t&#233; fix&#233; empiriquement &#224; 0, 9.
</p>
<p>L&#8217;&#233;quation 2 montre la mesure LCS (Longest Common Substring) que nous avons modifi&#233;e en
LCS&#8727; pour calculer la similarit&#233; entre deux segments S1 et S2.
</p>
<p>LCS&#8727;(S1, S2) =
1
</p>
<p>|S1| &#183;
&#8721;
m1&#8712;S1
</p>
<p>max
m2&#8712;S&#8242;2
</p>
<p>LCS(m1,m2) (2)
</p>
<p>o&#249; S &#8242;2 est l&#8217;ensemble de mots du segment S2 dans lequel les mots m2, qui ont d&#233;j&#224; maximis&#233;
LCS(m1,m2) durant les &#233;tapes pr&#233;c&#233;dentes du calcul, ont &#233;t&#233; enlev&#233;s. Le facteur |S1|&#8722;1 permet
de normaliser le calcul.
</p>
<p>Pour r&#233;duire le bruit qui peut &#234;tre introduit par une mesure calcul&#233;e sur les caract&#232;res, nous
avons ajout&#233; un seuil qui filtre les valeurs minimales. La somme est faite uniquement pour des
valeurs de maximum sup&#233;rieur &#224; 0, 6, c&#8217;est &#224; dire pour deux mots partageant au moins 60%
des caract&#232;res en commun. Ce traitement, qui remplace avantageusement une lemmatisation ou
stemming classique, rend notre m&#233;thode plus ind&#233;pendante de la langue. Un exemple de graphe
est montr&#233; dans la Table 2 (section annexe).
</p>
<p>3.2 Pond&#233;ration des segments
</p>
<p>Le paradigme extractif pour le r&#233;sum&#233; automatique a permis la mise au point de m&#233;thodes per-
formantes qui peuvent se passer d&#8217;un ensemble de donn&#233;es d&#8217;apprentissage. Le document est
repr&#233;sent&#233; par un graphe d&#8217;unit&#233;s textuelles (les phrases) li&#233;es entre elles par des relations is-
sues de mesures de similarit&#233;. Les algorithmes de classement permettent ensuite de d&#233;cider de
l&#8217;importance d&#8217;un segment en se basant sur l&#8217;information globale issue de l&#8217;analyse r&#233;cursive du
graphe. Les m&#233;thodes extractives fonctionnent par une s&#233;lection d&#8217;un sous-ensemble de phrases.
Ce processus peut &#234;tre vu comme une identification des segments les plus centraux, i.e. conte-
nant les id&#233;es essentielles du texte original. Cette section d&#233;crit les algorithmes de classement
que nous avons utilis&#233; pour extraire cet sous-ensemble de phrases &#224; partir d&#8217;un graphe.
</p>
<p>3.2.1 Popularit&#233;
</p>
<p>Cette m&#233;thode est une interpr&#233;tation na&#239;ve du ph&#233;nom&#232;ne de popularit&#233; : une phrase est consi-
d&#233;r&#233;e importante si elle est reli&#233;e &#224; un grand nombre d&#8217;autres phrases dans le graphe. Le score
de popularit&#233; de chaque sommet est calcul&#233; &#224; partir du nombres d&#8217;ar&#234;tes rentrantes.
</p>
<p>popularit&#233;(s) = card{adj[s]} (3)
</p>
<p>o&#249; card {adj[s]} est la cardinalit&#233; de l&#8217;ensemble de sommets reli&#233;s &#224; s dans une matrice d&#8217;ad-
jacence. Il est possible d&#8217;utiliser un seuil (empirique) afin d&#8217;&#233;liminer certaines ar&#234;tes que l&#8217;on
peut juger comme peu significatives, car leurs valeurs sont tr&#232;s faibles.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florian Boudin et Juan-Manuel Torres-Moreno
</p>
<p>3.2.2 LexRank
</p>
<p>PageRank (Brin &amp; Page, 1998) est sans doute le plus populaire des algorithmes de classe-
ment, con&#231;u &#224; l&#8217;origine pour d&#233;terminer l&#8217;importance d&#8217;une page Web. (Erkan &amp; Radev, 2004)
proposent une interpr&#233;tation de cet algorithme, d&#233;nomm&#233;e LexRank, pour le classement des
segments textuels. Contrairement &#224; la m&#233;thode originelle de PageRank, le graphe de segments
est construit &#224; partir de mesures de similarit&#233; sym&#233;triques, il est par cons&#233;quent non dirig&#233;. Le
score de chaque sommet s est calcul&#233; it&#233;rativement jusqu&#8217;&#224; la convergence 3 par :
</p>
<p>p(s) = (1&#8722; d) + d&#215;
&#8721;
</p>
<p>v&#8712;adj[s]
</p>
<p>p(v)
</p>
<p>popularit&#233;(v)
(4)
</p>
<p>o&#249; popularit&#233;(v) est le nombre d&#8217;ar&#234;tes du sommet v et d est un facteur d&#8217;amortissement (dam-
ping factor) g&#233;n&#233;ralement fix&#233; &#224; 0, 85.
</p>
<p>3.2.3 TextRank
</p>
<p>TextRank est une variante de l&#8217;algorithme LexRank dans laquelle les valeurs de similarit&#233; as-
sign&#233;es aux arcs sont utilis&#233;es pour la pond&#233;ration des sommets. De cette mani&#232;re l&#8217;impact
des sommets connect&#233;s par des arcs de valeurs faibles est minimis&#233; dans le calcul du score du
segment. Le score de chaque sommet s est calcul&#233; it&#233;rativement jusqu&#8217;&#224; la convergence par :
</p>
<p>p(s) = (1&#8722; d) + d&#215;
&#8721;
</p>
<p>v&#8712;adj[s]
</p>
<p>Sim(s, v)&#8721;
z&#8712;adj[v] Sim(z, v)
</p>
<p>p(v) (5)
</p>
<p>3.3 Assemblage des r&#233;sum&#233;s
</p>
<p>Une fois les phrases pond&#233;r&#233;es, elles doivent &#234;tre s&#233;lectionn&#233;es et assembl&#233;es afin de produire
le r&#233;sum&#233;. La taille des r&#233;sum&#233;s est fix&#233;e par un nombre de mots maximum. L&#8217;algorithme de
production que nous proposons tente de maximiser le nombre de mots dans le r&#233;sum&#233; tout
en privil&#233;giant les segments de plus hauts scores. La redondance intra-r&#233;sum&#233; est minimis&#233;e
par un simple seuil de similarit&#233; inter-phrases appliqu&#233; en amont. De nombreuses contraintes
s&#8217;ajoutent lors de la concat&#233;nation des segments. En effet, les segments doivent &#234;tre ordonn&#233;s
temporairement dans le r&#233;sum&#233;, c&#8217;est &#224; dire en respectant les dates de publications des docu-
ments sources mais aussi la position dans le document si deux segments proviennent de la m&#234;me
source. De plus, un ensemble de post-traitements est appliqu&#233; aux segments qui dans la plupart
des cas modifie leurs tailles. Il convient donc de produire le r&#233;sum&#233; en plusieurs passes, l&#8217;as-
semblage des segments devant &#234;tre dynamiquement modifiable en fonction des contraintes. Les
post-traitements suivants sont effectu&#233;s en consid&#233;rant l&#8217;ordre d&#8217;apparition des phrases dans le
r&#233;sum&#233; : i) suppression du contenu entre parenth&#232;ses, ii) normalisation des r&#233;f&#233;rences tempo-
relles 4 et iii) normalisation de la ponctuation.
</p>
<p>3. Un seuil d&#8217;acceptation d&#8217;erreur e = 0.0001 permet d&#8217;arr&#234;ter les it&#233;rations lorsque les valeurs de tous les
sommets n&#8217;ont pas &#233;t&#233; modifi&#233;s de plus de e.
</p>
<p>4. Les dates compl&#232;tes de la forme &#171; 15 d&#233;cembre 1982 &#187; sont remplac&#233;es par &#171; 15/12/1982 &#187;.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;sum&#233; automatique, une premi&#232;re &#233;valuation en fran&#231;ais
</p>
<p>4 &#201;valuation
</p>
<p>Depuis 2001, le National Institute of Standards and Technology 5 (NIST) organise la campagne
d&#8217;&#233;valuation Document Understanding Conference (DUC), devenue depuis 2008 la campagne
Text Analysis Conference (TAC) 6. Son but est de promouvoir les progr&#232;s r&#233;alis&#233;s dans le do-
maine du r&#233;sum&#233; automatique de textes mais surtout de permettre aux chercheurs de participer
&#224; des exp&#233;rimentations de grande envergure tant au point de vue du d&#233;veloppement que de
l&#8217;&#233;valuation de leurs syst&#232;mes. Dans le cadre de ces campagnes, l&#8217;&#233;valuation des syst&#232;mes est
r&#233;alis&#233;e de mani&#232;re intrins&#232;que sur le fond ainsi que sur la forme des r&#233;sum&#233;s produits. Plu-
sieurs notations sont attribu&#233;es manuellement aux r&#233;sum&#233;s. Elle sont compl&#233;t&#233;es par le calcul
d&#8217;un ensemble de mesures semi-automatiques qui, au travers de mesures de similarit&#233;s calcu-
l&#233;es entre un r&#233;sum&#233; candidat et un ou plusieurs r&#233;sum&#233;s de r&#233;f&#233;rence, permettent de juger de
la qualit&#233; du contenu. C&#8217;est ce type de mesures que nous avons utilis&#233; pour &#233;valuer la qualit&#233; de
nos r&#233;sum&#233;s.
</p>
<p>L&#8217;&#233;valuation de nos m&#233;thodes a &#233;t&#233; conduite en suivant un protocole tr&#232;s similaire &#224; celui du
NIST. Un corpus compos&#233; de 20 th&#233;matiques diff&#233;rentes (par exemple la &#171; Visite du Dala&#239;
Lama en France &#187;, &#171; Les Jeux Olympiques &#224; Pekin &#187;, etc.) a &#233;t&#233; constitu&#233; 7. Pour chacune de
ses th&#233;matiques, un regroupement (cluster) de 10 articles de journaux de sources diff&#233;rentes a
&#233;t&#233; assembl&#233;. Quatre annotateurs ont ensuite produit manuellement quatre r&#233;sum&#233;s de r&#233;f&#233;rence
pour chaque cluster. Les recommandations principales qui leur ont &#233;t&#233; donn&#233;es &#233;taient de cr&#233;er
un r&#233;sum&#233; d&#8217;un maximum de 100 mots, contenant les id&#233;es essentielles de l&#8217;ensemble de docu-
ments tout en utilisant un minimum de connaissances externes. La t&#226;che du syst&#232;me de r&#233;sum&#233;
automatique est de produire un r&#233;sum&#233; d&#8217;un maximum de 100 mots &#224; partir de chaque cluster
de documents. Nous utilisons les mesures semi-automatiques ROUGE (Recall-Oriented Unders-
tudy for Gisting Evaluation) (Lin, 2004) calcul&#233;es &#224; partir des quatre r&#233;sum&#233;s de r&#233;f&#233;rence pour
attribuer un score &#224; chacune des m&#233;thodes que nous voulons &#233;valuer.
</p>
<p>Nous avons compar&#233; les scores obtenus avec les m&#233;thodes par classement de popularite&#769;, Lex-
Rank et TextRank sur des graphes construit &#224; partir de mesures de similarit&#233; cosinus et de me-
sures de similarit&#233; mixtes (&#233;quation 1). &#192; titre de comparaison, deux autres m&#233;thodes ont &#233;t&#233;
ajout&#233;es. La premi&#232;re est une baseline bien connue qui consiste &#224; produire un r&#233;sum&#233; &#224; partir
des premi&#232;res phrases du document le plus r&#233;cent, et qui est d&#8217;ailleurs tr&#232;s difficile &#224; battre
car elle garde &#224; la fois, l&#8217;information essentielle et la coh&#233;rence. La seconde m&#233;thode a &#233;t&#233;
propos&#233;e par (Radev et al., 2004) et sugg&#232;re de consid&#233;rer le processus extractif comme une
identification des segments les plus centraux du cluster. La centralit&#233; d&#8217;un segment est d&#233;finie
en fonction de la centralit&#233; des mots qu&#8217;il contient. Une mani&#232;re simple d&#8217;&#233;valuer la centralit&#233;
est alors de construire le centro&#239;de, ce dernier pouvant &#234;tre vu comme un pseudo-document
compos&#233; des mots ayant un poids tf &#215; idf sup&#233;rieur &#224; un seuil pr&#233;d&#233;fini. Les segments par-
tageant le plus de mots avec le centro&#239;de sont consid&#233;r&#233;s comme centraux et seront assembl&#233;s
pour g&#233;n&#233;rer le r&#233;sum&#233;. Cette m&#233;thodologie &#224; conduit au d&#233;veloppement du premier syst&#232;me
de r&#233;sum&#233; multi-documents sur le Web (Radev et al., 2001).
</p>
<p>Les r&#233;sultats de cette &#233;valuation sont montr&#233;s dans la table 1. On peut constater que les scores
obtenus sur des graphes construits avec des mesures de similarit&#233; mixtes sont toujours meilleurs
que ceux obtenus avec cosinus. Il est &#233;galement int&#233;ressant de noter que toutes les m&#233;thodes
</p>
<p>5. http ://www.nist.gov
6. http ://www.nist.gov/tac
7. Le corpus sera disponible sur le site du projet RPM2.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florian Boudin et Juan-Manuel Torres-Moreno
</p>
<p>&#224; base de graphes ont de meilleurs scores que la baseline. &#192; titre de comparaison, le score
ROUGE-1 moyen obtenu par le syst&#232;me LexRank (Erkan &amp; Radev, 2004) (meilleur syst&#232;me sur
la t&#226;che de r&#233;sum&#233; automatique de la campagne DUC 2004) &#233;tait de 0,396.
</p>
<p>Evaluation Popularit&#233; LexRank TextRank Centro&#239;de Baseline
cosinus mixte cosinus mixte cosinus mixte
</p>
<p>ROUGE-1 0,37634 0,38702 0,36943 0,38934 0,36842 0,38994 0,31236 0,34661
ROUGE-2 0,11228 0,11539 0,10587 0,11625 0,10301 0,12318 0,06952 0,08324
ROUGE-SU4 0,13759 0,13993 0,13320 0,14126 0,13273 0,14836 0,09876 0,11470
</p>
<p>TABLE 1 &#8211; R&#233;sultats des m&#233;thodes de pond&#233;ration.
</p>
<p>5 Conclusion et discussion
</p>
<p>Nous avons pr&#233;sent&#233; une premi&#232;re &#233;valuation formelle pour la t&#226;che du r&#233;sum&#233; automatique
multi-documents en fran&#231;ais. La m&#233;thode que nous avons propos&#233;e est bas&#233;e sur une approche &#224;
base de graphes et se veut &#234;tre la plus ind&#233;pendante de la langue possible. Des tests sur un corpus
de textes en fran&#231;ais ont &#233;t&#233; r&#233;alis&#233;s et &#233;valu&#233;s selon un protocole similaire &#224; celui utilis&#233; par le
NIST. Nous avons introduit une mesure mixte combinant le cosinus et la somme des distances
morphologiques entre mots, ce qui a permis d&#8217;am&#233;liorer les r&#233;sultats pour toutes les m&#233;thodes
de classement. La d&#233;tection num&#233;rique de la similarit&#233; morphologique &#233;vite les traitements de
lemmatisation qui peuvent s&#8217;averer &#234;tre tr&#232;s lourds et trop d&#233;pendants de la langue. La t&#226;che
de r&#233;sum&#233; multi-documents est beaucoup plus complexe que celle du r&#233;sum&#233; mono-document,
et les ph&#233;nom&#232;nes de coh&#233;sion et de coh&#233;rence y sont bien plus g&#234;nants. Afin d&#8217;am&#233;liorer la
qualit&#233; du r&#233;sum&#233;, plusieurs strat&#233;gies ont vu le jour. Bien que les graphes dirig&#233;s (backward
et forward) semblent am&#233;liorer les r&#233;sultats en mono-document (Mihalcea, 2004), en multi-
document la probl&#233;matique est diff&#233;rente. La prise en compte de la contrainte de temporalit&#233;
des phrases ne garantit pas la qualit&#233; de la coh&#233;rence dans le r&#233;sum&#233;. Des recherches plus
approfondies doivent &#234;tre entreprises dans cette voie.
</p>
<p>Remerciements
</p>
<p>Ce travail &#224; &#233;t&#233; financ&#233; par le projet ANR RPM2 (R&#233;sum&#233; Plurim&#233;dia, Multi-documents et
Multi-opinions), http ://labs.sinequa.com/rpm2. Les auteurs remercient Claude de Loupy, Chris-
telle Ayache et Somara Seng pour avoir rendu l&#8217;&#233;valuation de notre approche possible.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BOUDIN F., TORRES-MORENO J.-M. &amp; VEL&#193;ZQUEZ-MORALES P. (2008). An Efficient
Statistical Approach for Automatic Organic Chemistry Summarization. In B. NORDSTR&#214;M
&amp; A. RANTA, Eds., 6th International Conference on Natural Language Processing, GoTAL
2008, volume 5221 of Lecture Notes in Computer Science, p. 89&#8211;99, Gothenburg, Sweden :
Springer.
BRIN S. &amp; PAGE L. (1998). The anatomy of a large-scale hypertextual Web search engine.
Computer Networks and ISDN Systems, 30(1-7), 107&#8211;117.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;sum&#233; automatique, une premi&#232;re &#233;valuation en fran&#231;ais
</p>
<p>CH&#194;AR S., FERRET O. &amp; FLUHR C. (2004). Filtrage pour la construction de r&#233;sum&#233;s multi-
documents guid&#233;e par un profil. Traitement automatique des langues, 45(1), 65&#8211;93.
EDMUNSON H. P. (1969). New Methods in Automatic Extracting. Journal of the Association
for Computing : Machinery, 16(2), 264&#8211;285.
ERKAN G. &amp; RADEV D. R. (2004). LexRank : Graph-based Lexical Centrality as Salience
in Text Summarization. Journal of Artificial Intelligence Research, 22(2004), 457&#8211;479.
HIRAO T., SASAKI Y., ISOZAKI H. &amp; MAEDA E. (2002). NTT&#8217;s text summarization sys-
tem for duc-2002. In Document Understanding Conference (DUC), p. 104&#8211;107, Philadephia,
Pennsylvania, USA.
</p>
<p>LIN C.-Y. (2004). Rouge : A package for automatic evaluation of summaries. In Text Summa-
rization Branches Out : Proceedings of the ACL-04 Workshop, p. 74&#8211;81, Barcelona, Spain :
Association for Computational Linguistics.
</p>
<p>LUHN H. P. (1958). The automatic creation of literature abstracts. IBM Journal of Research
and Development, 2(2), 159&#8211;165.
MANI I. &amp; MAYBURY M. T. (1999). Advances in Automatic Text Summarization. MIT Press.
</p>
<p>MIHALCEA R. (2004). Graph-based ranking algorithms for sentence extraction, applied to text
summarization. In ACL 2004 on Interactive poster and demonstration sessions, p. 181&#8211;184 :
Association for Computational Linguistics Morristown, NJ, USA.
</p>
<p>MIHALCEA R. (2005). Language independent extractive summarization. In Proceedings of
the ACL Interactive Poster and Demonstration Sessions, p. 49&#8211;52, Ann Arbor, Michigan :
Association for Computational Linguistics.
</p>
<p>MIHALCEA R. &amp; CEYLAN H. (2007). Explorations in Automatic Book Summarization. In
Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL), p. 380&#8211;389.
</p>
<p>NENKOVA A. (2005). Automatic Text Summarization of Newswire : Lessons Learned from
the Document Understanding Conference. In National Conference on Artificial Intelligence
(AAAI&#8217;05), Pittsburgh, Pennsylvania, USA.
</p>
<p>RADEV D. R., BLAIR-GOLDENSOHN S. &amp; ZHANG Z. (2001). Experiments in single
and multi-document summarization using MEAD. In Document Understanding Conference
(DUC), New Orleans, LA, USA.
</p>
<p>RADEV D. R., JING H., STYS&#769; M. &amp; TAM D. (2004). Centroid-based summarization of
multiple documents. Information Processing and Management, 40(6), 919&#8211;938.
SP&#196;RCK JONES K. &amp; GALLIERS J. R. (1996). Evaluating Natural Language Processing
Systems : An Analysis and Review. Springer.
</p>
<p>TEUFEL S. &amp; MOENS M. (1997). Sentence extraction as a classification task. In ACL/EACL
Workshop on Intelligent Scalable Text Summarization, p. 58&#8211;65, Madrid, Spain.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Florian Boudin et Juan-Manuel Torres-Moreno
</p>
<p>Annexe
S0 La police a proc&#233;d&#233; aux arrestations lors d&#8217;une manifestation &#224; Lhassa, co&#239;ncidant avec le 49e anniversaire du d&#233;part forc&#233; du dala&#239; lama.
S1 Une soixantaine de moines bouddhistes ont &#233;t&#233; arr&#234;t&#233;s lundi &#224; Lhassa, la capitale du Tibet, &#224; l&#8217;occasion d&#8217;une manifestation co&#239;ncidant avec le
</p>
<p>49e anniversaire du d&#233;part forc&#233; du dala&#239; lama, a affirm&#233; mardi Radio Free Asia (RFA).
S2 Entre 50 et 60 manifestants ont &#233;t&#233; arr&#234;t&#233;s par la police par les forces de l&#8217;ordre, qui ont &#233;galement bloqu&#233; les routes et encercl&#233; les monast&#232;res
</p>
<p>pour emp&#234;cher les manifestations de se propager.
S3 Cependant, onze personnes ont r&#233;ussi &#224; protester dans le centre de Lhassa avant d&#8217;&#234;tre arr&#234;t&#233;es, selon les m&#234;mes sources cit&#233;es par RFA.
S4 Des responsables de la police et des affaires religieuses &#224; Lhassa ont refus&#233; de s&#8217;exprimer.
S5 Le dignitaire religieux de 72 ans, qui a fui le Tibet en 1959 apr&#232;s l&#8217;&#233;chec d&#8217;un soul&#232;vement anti-chinois, a abandonn&#233; ses revendications d&#8217;in-
</p>
<p>d&#233;pendance, se bornant &#224; r&#233;clamer &quot;une large autonomie&quot; pour sauvegarder la langue, la culture et l&#8217;environnement de ce territoire himalayen.
S6 La Chine, qui en a pris le contr&#244;le &#224; partir de 1950 -avant d&#8217;y mener une sanglante r&#233;pression- n&#8217;a cess&#233; de rejeter ces demandes qualifi&#233;es par
</p>
<p>le dala&#239; lama de diplomatie de la &quot;voie moyenne&quot;.
S7 Depuis lundi, des moines bouddhistes manifestent au Tibet et dans les r&#233;gions avoisinantes, &#224; l&#8217;occasion du 49e anniversaire du soul&#232;vement
</p>
<p>de Lhassa, qui a conduit &#224; l&#8217;exil du dala&#239;-lama.
S8 Depuis Dharamsala, dans le nord de l&#8217;Inde, le dala&#239;-lama a demand&#233; &#224; P&#233;kin de &quot;renoncer &#224; l&#8217;usage de la force&quot; contre les manifestants.
S9 Son porte-parole a jug&#233; sans fondement les accusations chinoises selon lesquelles il aurait foment&#233; les manifestations violentes.
S10 Ce nouvel embrasement, dans une r&#233;gion sensible, sous contr&#244;le chinois depuis 1951, devrait accentuer la pression que subit d&#233;j&#224; le gouverne-
</p>
<p>ment chinois pour am&#233;liorer les droits de l&#8217;homme, comme il s&#8217;est engag&#233; &#224; le faire en obtenant l&#8217;organisation des JO de P&#233;kin, dont l&#8217;ouverture
aura lieu dans cinq mois.
</p>
<p>S11 Le gouvernement chinois a propos&#233; d&#8217;indemniser les familles des civils qui ont, selon lui, &#233;t&#233; tu&#233;s lors des violences dans la capitale tib&#233;taine
ce mois-ci, a rapport&#233; vendredi soir l&#8217;agence de presse officielle chinoise Chine nouvelle.
</p>
<p>S12 Selon le d&#233;compte du gouvernement chinois, 18 civils ont &#233;t&#233; tu&#233;s le 14 mars lors de manifestations contre la tutelle chinoise &#224; Lhassa, au cours
desquelles des manifestants ont lanc&#233; des pierres en direction des forces de l&#8217;ordre, br&#251;l&#233; et pill&#233; des magasins.
</p>
<p>S13 Les familles des victimes recevront 200.000 yuans ( 18.000 euros), a indiqu&#233; Chine nouvelle sur la foi d&#8217;une circulaire du gouvernement
r&#233;gional du Tibet.
</p>
<p>S14 &quot;Des mesures sont prises pour aider les gens &#224; r&#233;parer leurs maisons et leurs magasins d&#233;truits pendant les troubles ou &#224; en construire d&#8217;autres&quot;,
pr&#233;cise la circulaire selon Chine nouvelle.
</p>
<p>S15 Toute personne bless&#233;e lors des &#233;meutes pourra &#234;tre soign&#233;e gratuitement, a ajout&#233; Chine nouvelle.
S16 Le bilan officiel de deux semaines de violences au Tibet et dans l&#8217;ouest de la Chine est de 19 morts, mais le gouvernement tib&#233;tain en exil fait
</p>
<p>&#233;tat de 140 morts.
S17 La r&#233;pression des &#233;meutes par les autorit&#233;s chinoises a provoqu&#233; des protestations internationales &#224; l&#8217;approche des Jeux olympiques de P&#233;kin.
</p>
<p>0.44
</p>
<p>0.29
0.140.17
</p>
<p>0.12
</p>
<p>0.20
</p>
<p>0.17
</p>
<p>0.120.14
</p>
<p>0.17 0.13
</p>
<p>0.12
</p>
<p>0.12
</p>
<p>0.13 S1 [0.677]
</p>
<p>S0 [0.731]
</p>
<p>S17 [0.161]
</p>
<p>S2 [0.486]
S3 [0.313]S4 [0.102]
</p>
<p>S5 [0.000]
</p>
<p>S6 [0.982]
</p>
<p>S7 [0.844]
</p>
<p>S8 [0.540]
</p>
<p>S9 [0.051]
</p>
<p>S10 [0.989]
</p>
<p>S11 [0.877]
S12 [0.503] S13 [0.724]
</p>
<p>S14 [0.597]
</p>
<p>S15 [0.754]
</p>
<p>S16 [0.881]
</p>
<p>TABLE 2 &#8211; Exemple de graphe construit &#224; partir d&#8217;un cluster d&#8217;articles journalistiques traitant
de l&#8217;actualit&#233; au Tibet. Les scores TextRank de chaque segment sont montr&#233;s entre crochets.</p>

</div></div>
</body></html>