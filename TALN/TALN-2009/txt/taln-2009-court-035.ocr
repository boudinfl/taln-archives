TALN 2009 — Session posters , Senlis, 24-26 juin 2009

Résumé automatique multi-document et indépendance de la
langue : une premiére évaluation en frangais

Florian Boudinl Juan-Manuel Torres-Morenol’ 2
(1) LIA / Université d’Avignon, 339 chemin des Meinajaries, 84911 Avignon
(2) Ecole Polytechnique de Montréal, CP 6079 Succ. Centre-ville, Montréal

{florian.boudin,juan—manuel.torres}@univ—avignon.fr

Résumé. Le résumé automatique de texte est une problématique difﬁcile, fortement dé-
pendante de la langue et qui peut nécessiter un ensemble de données d’apprentissage conse-
quent. L’ approche par extraction peut aider a surmonter ces difﬁcultés. (Mihalcea, 2004) a de-
montré l’intérét des approches a base de graphes pour l’extraction de segments de texte im-
portants. Dans cette étude, nous décrivons une approche indépendante de la langue pour la
problématique du résumé automatique multi-documents. L’ originalité de notre méthode repose
sur l’utilisation d’une mesure de similarité permettant le rapprochement de segments morpholo-
giquement proches. De plus, c’est a notre connaissance la premiere fois que l’évaluation d’une
approche de résumé automatique multi-document est conduite sur des textes en francais.

Abstract. Automatic text summarization is a difﬁcult task, highly language-dependent
and which may require a large training dataset. Recently, (Mihalcea, 2004) has shown that
graph-based approaches applied to the sentence extraction issue can achieve good results. In
this paper, we describe a language-independent approach for automatic multi-document text
summarization. The main originality of our approach is the use of an hybrid similarity measure
during the graph building process that can identify morphologically similar words. Moreover,
this is as far as we know, the ﬁrst time that the evaluation of a summarization approach is
conducted on French documents.

M0tS-CléS 2 Resume automatique de texte, Approches a base de graphes, Extraction d’in-
formation.

Keywords: Text summarization, Graph-Based approaches, Information Extraction.

1 Introduction

Un résumé est un texte reformulé dans un espace plus réduit. Il doit exprimer avec un mini-
mum de mots le contenu essentiel d’un document. Son but est d’aider le lecteur a repérer les
informations qui peuvent l’intéresser sans pour autant devoir lire le document en entier. Mais
pourquoi avons-nous tant besoin de résumés ? Simplement parce que nous ne disposons pas
d’assez de temps et d’énergie pour tout lire. La masse d’information textuelle sous forme elec-
tronique ne cesse d’augmenter, que ce soit sur Internet ou dans les réseaux des entreprises. Ce
volume croissant de textes disponibles rend difﬁcile l’acces a l’information désirée sans l’aide
d’outils spéciﬁques. Mais produire un résumé est une tache tres complexe car elle nécessite des
connaissances linguistiques ainsi que des connaissances du monde qui restent tres difﬁciles a

Florian Boudin et J uan-Manuel Torres-Moreno

incorporer dans un systeme automatique. Il existe néanmoins des approches permettant d’iIniter
une partie du processus cognitif du résumé. Ces demieres peuvent étre regroupées en deux ca-
tégories, les méthodes extractives et abstractives. Bien que des méthodes par abstraction ont été
mises au point, les outils nécessaires a la compréhension sémantique du texte ou a la génération
de texte en langue naturelle n’ont pas atteint la maturité indispensable a une utilisation robuste.
L’ approche que nous proposons repose sur un processus extractif. Dans ce paradigme, les seg-
ments textuels —le plus souvent des phrases— contenant les idées essentielles du document sont
extraits puis assemblés aﬁn de produire un résumé, également appelé extrait (Mani & Maybury,
1999)

Il existe de nombreuses variantes de résumé automatique. La plus simple étant le résumé ge-
nérique mono-document o1‘1 il s’agit de produire un résumé en préservant au Inieux toutes les
idées essentielles contenues dans un document. Cette variante, qui pourtant parait étre la plus
simple, pose encore de nombreux problemes. En effet, du type de document que l’on veut ré-
sumer dépend les performances des systemes. Il est envisageable de générer un résumé a partir
d’un article de journal tandis qu’il est, du moins actuellement, quasiment impossible de le faire
a partir d’oeuvres littéraires (Mihalcea & Ceylan, 2007). Par opposition au résumé générique, la
tache de résumé orienté consiste en la production d’un résumé qui satisfait les besoins d’un uti-
lisateur. Ces besoins, généralement exprimés au moyen d’une requéte, doivent permettre au sys-
teme d’isoler les parties du document concernant une (plusieurs) thématique(s) précise(s) pour
ensuite produire un résumé n’incluant que ces dernieres. A ces deux variantes, peut s’ajouter la
problématique des résumés multi-documents. De nouvelles difﬁcultés sont alors introduites : les
phrases extraites a partir de documents différents peuvent étre complémentaires, redondantes ou
contradictoires. Il faudra donc veiller a la cohésion des phrases mais surtout a la cohérence du
résumé (absence de contradiction ou de redondance dans l’enchainement des phrases).

Evaluer la qualité d’un résumé est un probleme difﬁcile auquel la communauté n’a pour le mo-
ment su répondre qu’avec des solutions partielles. En effet, il n’existe pas de résumé « idéal ».
Les résumés écrits par des personnes différentes ne sont pas toujours convergents au niveau
du contenu. La rédaction de ce type de document requiert une analyse du texte aﬁn d’en de-
gager les idées, le style et les arguments, ce que chaque personne fait de maniere différente.
Par conséquent, deux résumés de contenu informationnel tres similaire peuvent étre produits en
utilisant un vocabulaire totalement différent. De maniere générale, les méthodes d’évaluation
peuvent étre classées en deux catégories (Sparck Jones & Galliers, 1996). La premiere regroupe
les évaluations dites extrinseques, les résumés sont évalués en se basant sur leur aptitude a ac-
célérer la complétion detaches annexes (e. g. l’utilisation des résumés, a la place des documents
sources, dans des systemes question/réponse ou de classiﬁcation de documents). La deuxieme
catégorie réunit les évaluations intrinseques, ou les résumés sont alors jugés directement en se
basant sur leur analyse. Cette tache peut étre réalisée manuellement (des juges évaluant les qua-
lités d’un résumé comme la lisibilité, la complexité de la langue ou la présence des concepts
majeurs du document source) ou automatiquement en calculant des mesures de similarité entre
le résumé candidat et un ou plusieurs résumés de référence. Ce n’est que tres récemment que la
communauté a su mettre a disposition des mesures d’évaluation automatique pertinentes (Lin,
2004) ainsi que des ensembles de données de qualité (Nenkova, 2005). Le probleme majeur res-
tant que la langue utilisée dans ces corpora est presque toujours l’anglais. (Chaar et al., 2004)
ont néanmoins proposé un protocole d’évaluation sur des documents en francais qui utilise les
données des campagnes d’évaluation CLEF. Bien que ne portant pas sur la qualité linguistique
des résumés, les mesures d’évaluation reportées montrent le degré de précision avec lequel les
unités informatives peuvent étre extraites par leur approche.

Résumé automatique, une premiere évaluation en francais

Dans cet article, nous proposons d’étudier le comportement de plusieurs approches extractives
indépendantes de la langue des documents a traiter. La problématique que nous abordons est
le résumé générique multi-documents d’articles de journaux en francais a partir de méthodes a
base de graphes. Nous présentons en section 2 un rapide état de l’art sur le résumé automatique
de texte et la problématique d’adaptabilité. Nous montrons en section 3 la méthode de construc-
tion du graphe et la sélection des segments basée sur son analyse. Nous évaluons notre approche
en section 4 en la comparant aux résumés de référence produits manuellement. Nous discutons
des résultats obtenus en section 5, et proposons des perspectives de recherche.

2 Travaux précédents

(Luhn, 1958) a probablement été le premier a proposer une méthode numérique pour la pro-
duction d’extraits. Déja motivé par la problématique de surcharge d’information face a des
quantités qui peuvent paraitre dérisoires presque 50 ans plus tard, Luhn décrit une technique
simple, spéciﬁque aux articles scientiﬁques qui utilise la distribution des fréquences de mots
dans le document pour pondérer les phrases. Par la suite, (Edmunson, 1969) est allé plus loin
en introduisant des criteres comme la position des phrases, la présence de mots provenant de la
structure du document (i.e. titres, sous-titres, etc.) ou la présence de mots indices (cue words).
Leurs travaux ont eu un impact considérable, la grande majorité des approches d’aujourd’hui
étant toujours basées sur ces memes idées. Quelques-unes de ces approches, parmi lesquelles
certaines font partie des plus performantes (Teufel & Moens, 1997; Hirao et al., 2002), utilisent
des algorithmes supervisés qui tentent de caractériser ce qui fait un bon résumé. Cependant, le
prix a payer pour obtenir de bons résultats est de disposer d’un ensemble de données d’appren-
tissage. C’est ce point qui rend ce type d’approche difﬁcilement adaptable a d’autres langues
ou domaines.

I1 existe néanmoins quelques méthodes destinées a résoudre ce probleme. Ainsi, (Mihalcea,
2004; Erkan & Radev, 2004) proposent de considérer le processus extractif comme une identi-
ﬁcation des segments les plus prestigieux dans un graphe. Les algorithmes de classement basés
sur les graphes tel que PageRank (Brin & Page, 1998) ont été utilisés avec succes dans les
réseaux sociaux, l’analyse du nombre de citations ou l’étude de la structure du Web. Ces algo-
rithmes peuvent étre vus comme les éléments clés du paradigme amorcé dans le domaine de
la recherche sur Internet, a savoir le classement des pages Web par l’analyse de leurs positions
dans le réseau et non pas de leurs contenus. En d’autres termes, ces algorithmes permettent
de décider de l’importance du sommet d’un graphe en se basant non pas sur l’analyse locale
du sommet lui méme, mais sur l’information globale issue de l’analyse récursive du graphe
complet. Appliqué au résumé automatique cela signiﬁe que le document est représenté par un
graphe d’unités textuelles (phrases) liées entre elles par des relations issues de calculs de si-
Inilarité. Les phrases sont ensuite sélectionnées selon des criteres de centralité ou de prestige
dans le graphe puis assemblées pour produire des extraits. Les résultats reportés montrent que
les performances des approches a base de graphe sont au niveau des meilleurs systemes actuels
(Mihalcea, 2005) mais ne portent que sur des documents en anglais et en portugais. Deux ques-
tions se posent alors : que doit-on attendre des résultats sur des documents en francais ? peut-on
améliorer les performances des systemes a base de graphes ?

Il est important de noter que les méthodes de classement sont entierement dépendantes de la
bonne construction du graphe sensé représenter le document. Puisque ce graphe est généré a
partir de mesures de similarités inter-phrases, l’impact que peut avoir le choix de la méthode

Florian Boudin et J uan-Manuel Torres-Moreno

de calcul est a considérer. Dans leurs travaux, (Mihalcea, 2004; Erkan & Radev, 2004) utilisent
le modele en sac-de-mots pour représenter chaque phrase comme un vecteur a N dimensions,
ou N est le nombre total de mots différents du regroupement et chaque composante du vecteur
un poids t f X idf. Les valeurs de similarité entre phrases sont ensuite obtenues par un calcul
du cosinus entre leurs représentations vectorielles. Le point faible de cette mesure, et plus ge-
néralement de toutes les mesures utilisant les mots comme unités, est qu’elles sont tributaires
du vocabulaire. Dans une optique d’indépendance de la langue, les pré-traitements qui sont
appliqués aux segments se doivent d’étre minimaux. C’est malheureusement dans cette conﬁ-
guration que les performances de la mesure cosinus chutent car elle ne permet en aucun cas
de mettre en relation des mots qui morphologiquement peuvent étre tres proches. Une solution
peut venir de la combinaison avec des mesures de similarité basées sur les caracteres. (Boudin
et al., 2008) proposent une mesure dérivée d’un calcul de similarité entre chaines de caracteres
originellement employé pour la détection d’entités redondantes (Record Linkage). Cette me-
sure permet de créer des relations entre deux segments qui meme s’il ne partagent aucun mot,
en contiennent des morphologiquement proches. Une seconde question est donc de savoir si
la construction du graphe du document a partir de mesures Inixtes (mots et caracteres) permet
d’améliorer l’extraction de segments.

3 Méthode

3.1 Construction du graphe

Aﬁn de permettre aux algorithmes de classement d’étre appliqués sur des documents en langage
naturel, nous devons construire un graphe qui représente le texte et interconnecte les unités
textuelles avec des relations de sens. La nature des relations et la taille des unités dépend bien
entendu du type d’application que l’on cible. Pour le résumé automatique le choix le plus simple
au niveau de la taille des unités est la phrase complete. En effet, cela permet lors de la génération
du résumé de ne pas avoir a se soucier de la grammaticalité des segments assemblés. Une
connexion entre deux phrases est déﬁnie comme une mesure de similarité morphologique. Ce
type de relation peut étre vu comme une recommandation. Une phrase qui traite de certains
concepts du texte donne au lecteur une recommandation quant aux autres phrases partageant du
contenu en commun.

Les segments ont tout d’abord été nettoyés de leurs ponctuation et la casse normalisée 1. Le seul
pré-traitement statistique qui leur est appliqué correspond a un ﬁltrage des mots communs a
l’aide d’une liste 2. Il s’agit d’un processus simple et facilement adaptable a d’autres langues ou
domaines. Pour chaque ensemble de documents, un graphe non dirigé et valué G = (S, A) est
construit. S est l’ensemble de sommets du graphe et A est l’ensemble des arétes, A Q S X S .
La valeur de chaque aréte est évaluée a l’aide d’une mesure de similarité calculée entre les
deux noeuds de la connexion. Dans les formulations originelles de (Mihalcea, 2004; Erkan &
Radev, 2004), la mesure de similarité utilisée est le cosinus. Nous proposons de la combiner
avec une mesure morphologique de plus longue sous-chaine de caracteres, qui nous pensons,
peut permettre d’augmenter la qualité des connexions entre segments (voir equation 1).

1. Transformation des majuscules en minuscules.
2. Les mots outils et non informatifs sont supprimés des segments.

Résumé automatique, une premiere évaluation en francais

sim(S1, S2) = 04 - cos(S1, 32) + (1 — oz) -LCS*(S1, S2); 0 < 04 < 1 (1)

Le parametre 04 a été ﬁxé empiriquement a 0,9.

L’ equation 2 montre la mesure LCS (Longest Common Substring) que nous avons modiﬁée en
LCS* pour calculer la similarité entre deux segments S1 et S2.

1
LC§*(,S'1,S2) : W . mggl  LCS(m1,m2) (2)

ou S5 est l’ensemble de mots du segment S2 dans lequel les mots mg, qui ont déja maximisé
LCS(m1, mg) durant les étapes précédentes du calcul, ont été enlevés. Le facteur |S1|‘1 permet
de normaliser le calcul.

Pour réduire le bruit qui peut étre introduit par une mesure calculée sur les caracteres, nous
avons ajouté un seuil qui ﬁltre les valeurs minimales. La somme est faite uniquement pour des
valeurs de maximum supérieur a 0,6, c’est a dire pour deux mots partageant au moins 60%
des caracteres en commun. Ce traitement, qui remplace avantageusement une lemmatisation ou
stemming classique, rend notre méthode plus indépendante de la langue. Un exemple de graphe
est montré dans la Table 2 (section annexe).

3.2 Pondération des segments

Le paradigme extractif pour le résumé automatique a permis la mise au point de méthodes per-
formantes qui peuvent se passer d’un ensemble de données d’apprentissage. Le document est
représenté par un graphe d’unités textuelles (les phrases) liées entre elles par des relations is-
sues de mesures de similarité. Les algorithmes de classement permettent ensuite de décider de
l’importance d’un segment en se basant sur l’information globale issue de l’analyse récursive du
graphe. Les méthodes extractives fonctionnent par une sélection d’un sous-ensemble de phrases.
Ce processus peut étre vu comme une identiﬁcation des segments les plus centraux, i. e. conte-
nant les idées essentielles du texte original. Cette section décrit les algorithmes de classement
que nous avons utilisé pour extraire cet sous-ensemble de phrases a partir d’un graphe.

3.2.1 Popularité

Cette méthode est une interprétation na'1've du phénomene de popularité : une phrase est consi-
dérée importante si elle est reliée a un grand nombre d’autres phrases dans le graphe. Le score
de popularité de chaque sommet est calculé a partir du nombres d’arétes rentrantes.

popularité(s) = card{adj  (3)

ou card {adj [s]} est la cardinalité de l’ensemble de sommets reliés a s dans une matrice d’ad-
jacence. Il est possible d’utiliser un seuil (empirique) aﬁn d’éliminer certaines arétes que l’on
peut juger comme peu signiﬁcatives, car leurs valeurs sont tres faibles.

Florian Boudin et J uan-Manuel Torres-Moreno

3.2.2 LexRank

PageRank (Brin & Page, 1998) est sans doute le plus populaire des algorithmes de classe-
ment, concu a l’origine pour déterIr1inerl’importance d’une page Web. (Erkan & Radev, 2004)
proposent une interprétation de cet algorithme, dénommée LexRank, pour le classement des
segments textuels. Contrairement a la méthode originelle de PageRank, le graphe de segments
est construit a partir de mesures de similarité symétriques, il est par conséquent non dirigé. Le
score de chaque sommet s est calculé itérativement jusqu’a la convergence 3 par :

(11)
M8) (1 ) + X vEgi;[s] popular1te(v) (4)

o1‘1 popularité(v) est le nombre d’arétes du sommet 11 et d est un facteur d’amortissement (dam-
ping factor) généralement ﬁxé a 0, 85.

3.2.3 TextRank

TextRank est une variante de l’algorithme LexRank dans laquelle les valeurs de similarité as-
signées aux arcs sont utilisées pour la pondération des sommets. De cette maniere l’impact
des sommets connectés par des arcs de valeurs faibles est minimisé dans le calcul du score du
segment. Le score de chaque sommet s est calculé itérativement jusqu’a la convergence par :

p(s)=(1—d)+d><

Sim(s,11) ) 19(1)) (5)
vEadj[s]

ZzEadj[v] Sim(Z7 1}

3.3 Assemblage des résumés

Une fois les phrases pondérées, elles doivent étre sélectionnées et assemblées aﬁn de produire
le résumé. La taille des résumés est ﬁxée par un nombre de mots maximum. L’algorithme de
production que nous proposons tente de maximiser le nombre de mots dans le résumé tout
en privilégiant les segments de plus hauts scores. La redondance intra-résumé est Ininimisée
par un simple seuil de similarité inter-phrases appliqué en amont. De nombreuses contraintes
s’ajoutent lors de la concaténation des segments. En effet, les segments doivent étre ordonnés
temporairement dans le résumé, c’est a dire en respectant les dates de publications des docu-
ments sources mais aussi la position dans le document si deux segments proviennent de la méme
source. De plus, un ensemble de post-traitements est appliqué aux segments qui dans la plupart
des cas modiﬁe leurs tailles. Il convient donc de produire le résumé en plusieurs passes, l’as-
semblage des segments devant étre dynamiquement modiﬁable en fonction des contraintes. Les
post-traitements suivants sont effectués en considérant l’ordre d’apparition des phrases dans le
résumé :  suppression du contenu entre parentheses,  normalisation des références tempo-
relles 4 et  normalisation de la ponctuation.

3. Un seuil d’acceptation d’erreur e = 0.0001 pennet d’arreter les iterations lorsque les valeurs de tous les
sommets n’ont pas été modiﬁes de plus de 6.
4. Les dates completes de la forme << 15 décembre 1982 » sont remplacées par << 15/12/1982 ».

Resume automatique, une premiere evaluation en francais

4 Evaluation

Depuis 2001, le National Institute of Standards and Technology 5 (NIST) organise la campagne
d’evaluation Document Understanding Conference (DUC), devenue depuis 2008 la campagne
Text Analysis Conference (TAC) 6. Son but est de promouvoir les progres realises dans le do-
maine du resume automatique de textes mais surtout de permettre aux chercheurs de participer
a des experimentations de grande envergure tant au point de vue du developpement que de
l’evaluation de leurs systemes. Dans le cadre de ces campagnes, l’evaluation des systemes est
realisee de maniere intrinseque sur le fond ainsi que sur la forme des resumes produits. Plu-
sieurs notations sont attribuees manuellement aux resumes. Elle sont completees par le calcul
d’un ensemble de mesures semi-automatiques qui, au travers de mesures de similarites calcu-
lees entre un resume candidat et un ou plusieurs resumes de reference, permettent de juger de
la qualite du contenu. C’est ce type de mesures que nous avons utilise pour evaluer la qualite de
nos resumes.

L’ evaluation de nos methodes a ete conduite en suivant un protocole tres similaire a celui du
NIST. Un corpus compose de 20 thematiques differentes (par exemple la « Visite du Dalai
Lama en France », « Les Jeux Olympiques a Pekin », etc.) a ete constitue7. Pour chacune de
ses thematiques, un regroupement (cluster) de 10 articles de journaux de sources differentes a
ete assemble. Quatre annotateurs ont ensuite produit manuellement quatre resumes de reference
pour chaque cluster. Les recommandations principales qui leur ont ete donnees etaient de creer
un resume d’un maximum de 100 mots, contenant les idees essentielles de l’ensemble de docu-
ments tout en utilisant un minimum de connaissances externes. La tache du systeme de resume
automatique est de produire un resume d’un maximum de 100 mots a partir de chaque cluster
de documents. Nous utilisons les mesures semi-automatiques ROUGE (Recall-Oriented Unders-
tudy for Gisting Evaluation) (Lin, 2004) calculees a partir des quatre resumes de reference pour
attribuer un score a chacune des methodes que nous voulons evaluer.

Nous avons compare les scores obtenus avec les methodes par classement de popularité, Lex-
Rank et TextRank sur des graphes construit a partir de mesures de similarite cosinus et de me-
sures de similarite mixtes (equation 1). A titre de comparaison, deux autres methodes ont ete
ajoutees. La premiere est une baseline bien connue qui consiste a produire un resume a partir
des premieres phrases du document le plus recent, et qui est d’ailleurs tres difﬁcile a battre
car elle garde a la fois, l’information essentielle et la coherence. La seconde methode a ete
proposee par (Radev et al., 2004) et suggere de considerer le processus extractif comme une
identiﬁcation des segments les plus centraux du cluster. La centralite d’un segment est deﬁnie
en fonction de la centralite des mots qu’il contient. Une maniere simple d’evaluer la centralite
est alors de construire le centro'1'de, ce demier pouvant etre vu comme un pseudo-document
compose des mots ayant un poids t f X idf superieur a un seuil predeﬁni. Les segments par-
tageant le plus de mots avec le centroi'de sont consideres comme centraux et seront assembles
pour generer le resume. Cette methodologie a conduit au developpement du premier systeme
de resume multi-documents sur le Web (Radev et al., 2001).

Les resultats de cette evaluation sont montres dans la table 1. On peut constater que les scores
obtenus sur des graphes construits avec des mesures de similarite mixtes sont touj ours meilleurs
que ceux obtenus avec cosinus. Il est egalement interessant de noter que toutes les methodes

5. http ://www.nist. gov
6. http ://www.nist.goV/tac
7. Le corpus sera disponible sur le site du projet RPM2.

Florian Boudin et J uan-Manuel Torres-Moreno

a base de graphes ont de meilleurs scores que la baseline. A titre de comparaison, le score
ROUGE-1 moyen obtenu par le systeme LexRank (Erkan & Radev, 2004) (meilleur systeme sur
la tache de resume automatique de la campagne DUC 2004) etait de 0,396.

Evaluation _Popularité_ _LexRank_ _TextRank_ Centro'1'de Baseline
cosinus minute cosinus mzmte cosinus minute

ROUGE-1 0,37634 0,38702 0,36943 0,38934 0,36842 0,38994 0,31236 0,34661
ROUGE-2 0,11228 0,11539 0,10587 0,11625 0,10301 0,12318 0,06952 0,08324
ROUGE—SU4 0,13759 0,13993 0,13320 0,14126 0,13273 0,14836 0,09876 0,11470

TABLE 1 — Resultats des methodes de ponderation.

5 Conclusion et discussion

Nous avons presente une premiere evaluation formelle pour la tache du resume automatique
multi-documents en frangais. La methode que nous avons proposee est basee sur une approche a
base de graphes et se veut etre la plus independante de la langue possible. Des tests sur un corpus
de textes en frangais ont ete realises et evalues selon un protocole similaire a celui utilise par le
NIST. Nous avons introduit une mesure mixte combinant le cosinus et la somme des distances
morphologiques entre mots, ce qui a permis d’ameliorer les resultats pour toutes les methodes
de classement. La detection numerique de la siIr1ilarite morphologique evite les traitements de
lemmatisation qui peuvent s’averer etre tres lourds et trop dependants de la langue. La tache
de resume multi-documents est beaucoup plus complexe que celle du resume mono-document,
et les phenomenes de cohesion et de coherence y sont bien plus genants. Aﬁn d’ameliorer la
qualite du resume, plusieurs strategies ont vu le jour. Bien que les graphes diriges (backward
et forward) semblent ameliorer les resultats en mono-document (Mihalcea, 2004), en multi-
document la problematique est differente. La prise en compte de la contrainte de temporalite
des phrases ne garantit pas la qualite de la coherence dans le resume. Des recherches plus
approfondies doivent etre entreprises dans cette voie.

Remerciements

Ce travail a ete ﬁnance par le projet ANR RPM2 (Resume Plurimedia, Multi-documents et
Multi-opinions), http ://labs.sinequa.coIn/rpm2. Les auteurs remercient Claude de Loupy, Chris-
telle Ayache et Somara Seng pour avoir rendu l’evaluation de notre approche possible.

Références

BOUDIN F., TORRES-MORENO J .-M. & VELAZQUEZ-MORALES P. (2008). An Efﬁcient
Statistical Approach for Automatic Organic Chemistry Summarization. In B. NORDSTROM
& A. RANTA, Eds., 6th International Conference on Natural Language Processing, GoTAL
2008, volume 5221 of Lecture Notes in Computer Science, p. 89-99, Gothenburg, Sweden :
Springer.

BRIN S. & PAGE L. (1998). The anatomy of a large-scale hypertextual Web search engine.
Computer Networks and ISDN Systems, 30(1-7), 107-117.

Résumé automatique, une premiere évaluation en francais

CHAAR S., FERRET O. & FLUHR C. (2004). Filtrage pour la construction de résumés multi-
docuInents guidée par un proﬁl. Traitement automatique des langues, 45(1), 65-93.

EDMUNS ON H. P. (1969). New Methods in Automatic Extracting. Journal of the Association
for Computing .' Machinery, 16(2), 264-285.

ERKAN G. & RADEV D. R. (2004). LexRank : Graph-based Lexical Centrality as Salience
in Text Summarization. Journal of Artiﬁcial Intelligence Research, 22(2004), 457-479.

HIRAO T., SASAKI Y., ISOZAKI H. & MAEDA E. (2002). NTT’s text summarization sys-
tem for duc-2002. In Document Understanding Conference (DUC), p. 104-107, Philadephia,
Pennsylvania, USA.

LIN C.-Y. (2004). Rouge : A package for automatic evaluation of summaries. In Text Summa-
rization Branches Out .' Proceedings of the ACL-04 Workshop, p. 74-81, Barcelona, Spain :
Association for Computational Linguistics.

LUHN H. P. (1958). The automatic creation of literature abstracts. IBM Journal of Research
and Development, 2(2), 159-165.

MANI I. & MAYBURY M. T. (1999). Advances in Automatic Text Summarization. MIT Press.

MIHALCEA R. (2004). Graph-based ranking algorithms for sentence extraction, applied to text
summarization. In ACL 2004 on Interactive poster and demonstration sessions, p. 181-184 :
Association for Computational Linguistics Morristown, NJ, USA.

MIHALCEA R. (2005). Language independent extractive summarization. In Proceedings of

the ACL Interactive Poster and Demonstration Sessions, p. 49-52, Ann Arbor, Michigan :
Association for Computational Linguistics.

MIHALCEA R. & CEYLAN H. (2007). Explorations in Automatic Book Summarization. In
Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL), p. 380-389.

NENKOVA A. (2005). Automatic Text Summarization of Newswire : Lessons Learned from
the Document Understanding Conference. In National Conference on Artiﬁcial Intelligence
(AAAI’05), Pittsburgh, Pennsylvania, USA.

RADEV D. R., BLAIR-GOLDENSOHN S. & ZHANG Z. (2001). Experiments in single

and multi-document summarization using MEAD. In Document Understanding Conference
(DUC), New Orleans, LA, USA.

RADEV D. R., JING H., STYS M. & TAM D. (2004). Centroid-based summarization of
multiple documents. Information Processing and Management, 40(6), 919-938.

SPARCK JONES K. & GALLIERS J . R. (1996). Evaluating Natural Language Processing
Systems .' An Analysis and Review. Springer.

T EUFEL S. & MOENS M. (1997). Sentence extraction as a classiﬁcation task. In ACI/EACL
Workshop on Intelligent Scalable Text Summarization, p. 58-65, Madrid, Spain.

S0
S1

S2

S3

S5

S6

S7

S8

S9

S10

S11

S12

S13

S14

S15
S16

S17

Florian Boudin et J uan-Manuel Torres-Moreno

Annexe

La police a procédé aux arrestations lors d’une manifestation a Lhassa, coincidant avec le 49e anniversaire du départ forcé du dalai lama.

Une soixantaine de moines bouddhistes ont été arrétés lundi a Lhassa, la capitale du Tibet, a l’occasion d’ une manifestation coincidant avec le
49e anniversaire du départ forcé du dalai lama, a afﬁrmé mardi Radio Free Asia (RFA).

Entre 50 et 60 manifestants ont été arrétés par la police par les forces de l’ordre, qui ont également bloqué les routes et encerclé les monasteres
pour empécher les manifestations de se propager.

Cependant, onze personnes ont réussi a protester dans le centre de Lhassa avant d’étre arrétées, selon les mémes sources citées par RFA.

Des responsables de la police et des affaires religieuses a Lhassa ont refusé de s’exprimer.

Le dignitaire religieux de 72 ans, qui a fui le Tibet en 1959 apres l’échec d’un soulevement anti-chinois, a abandonné ses revendications d’in-
dépendance, se bomant a réclamer "une large autonomie" pour sauvegarder la langue, la culture et l’environnement de ce territoire himalayen.
La Chine, qui en a pris le controle a partir de 1950 -avant d’y mener une sanglante répression- n’a cessé de rejeter ces demandes qualiﬁées par
le dalai lama de diplomatie de la "voie moyenne".

Depuis lundi, des moines bouddhistes manifestent au Tibet et dans les régions avoisinantes, a l’occasion du 49e anniversaire du soulevement
de Lhassa, qui a conduit a l’exil du dalai-lama.

Depuis Dharamsala, dans le nord de l’Inde, le dalai-lama a demandé a Pékin de "renoncer a l’usage de la force" contre les manifestants.

Son porte-parole a jugé sans fondement les accusations chinoises selon lesquelles il aurait fomenté les manifestations violentes.

Ce nouvel embrasement, dans une région sensible, sous controle chinois depuis 1951, devrait accentuer la pression que subit déja le gouveme-
ment chinois pour améliorer les droits de l’homme, comme il s’est engagé ale faire en obtenant l’organisation des J 0 de Pékin, dont l’ouverture
aura lieu dans cinq mois.

Le gouvemement chinois a proposé d’indemniser les familles des civils qui ont, selon lui, été tués lors des violences dans la capitale tibétaine
ce mois-ci, a rapporté vendredi soir l’agence de presse ofﬁcielle chinoise Chine nouvelle.

Selon le décompte du gouvemement chinois, 18 civils ont été tués le 14 mars lors de manifestations contre la tutelle chinoise a Lhassa, au cours
desquelles des manifestants ont lancé des pierres en direction des forces de l’ordre, brﬁlé et pillé des magasins.

Les familles des victimes recevront 200.000 yuans ( 18.000 euros), a indiqué Chine nouvelle sur la foi d’une circulaire du gouvemement
régional du Tibet.

"Des mesures sont prises pour aider les gens a réparer leurs maisons et leurs magasins détruits pendant les troubles ou a en construire d’autres",
précise la circulaire selon Chine nouvelle.

Toute personne blessée lors des émeutes po11rra étre soignée gratuitement, a ajouté Chine nouvelle.

Le bilan ofﬁciel de deux semaines de violences au Tibet et dans l’ouest de la Chine est de 19 morts, mais le gouvemement tibétain en exil fait
état de 140 morts.

La répression des émeutes par les autorités chinoises a provoqué des protestations intemationales a l’approche des Jeux olympiques de Pékin.
S12 [0.503] S13 [0.724]
S11 [0.877] 0-17 0- 0-12 S14 [0.597]
S10 [0.989] 515 [0-7541

S8 [o.54o] 51 [0.677]

  
  
   

57 [0.844] 50 [0.731]

ml
/

E
\

56 [0.982]

.29

' s17 [o.161]

55 [0.000]

54 [0.102]

53 [0.313]

TABLE 2 — Exemple de graphe construit a partir d’un cluster d’articles journalistiques traitant
de l’actualité au Tibet. Les scores TeXtRank de chaque segment sont montrés entre crochets.

