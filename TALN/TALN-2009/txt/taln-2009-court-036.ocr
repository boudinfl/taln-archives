TALN 2009 — Session posters, Senlis, 24-26 juin 2009

Segmentation et classiﬁcation non supervisée de conversations
téléphoniques automatiquement retranscrites

Laurent Bozzi, Philippe Suignard, Claire Waast—Richard

EDF R&D
1, avenue du Général de Gaulle
92141 Clamart Cedex
Laurent.Bozzi@edf.fr, Phi1ippe.Suignard@edf.fr, Claire.Waast—Richard@edf.fr

Résumé 2 Cette étude porte sur l’analyse de conversations entre des clients et des télé-
conseillers d’EDF. Elle propose une chaine de traitements permettant d’automatiser la
détection des sujets abordés dans chaque conversation. L’aspect multi-thématique des
conversations nous incite a trouver une unité de documents entre le simple tour de parole et la
conversation entiere. Cette démarche enchaine une étape de segmentation de la conversation
en themes homogenes basée sur la notion de cohesion lexicale, puis une étape de text-mining
comportant une analyse linguistique enrichie d’un vocabulaire métier spécifique a EDF, et
enfin une classification non supervisée des segments obtenus. Plusieurs algorithmes de
segmentation ont été évalués sur un corpus de test, segmenté et annoté manuellement : le plus
« proche » de la segmentation de référence est C99. Cette démarche, appliquée a la fois sur un
corpus de conversations transcrites a la main, et sur les memes conversations décodées par un
moteur de reconnaissance vocale, aboutit quasiment a l’obtention des 20 memes classes
thématiques.

Abstract 2This study focuses on the analysis of conversations and between clients and
EDF agent. It offers a range of treatments designed to automate the detection of the topics
covered in each conversation. As the conversations are multi-thematic we have to find a
document unit, between the simple turn of speech and the whole conversation. The proposed
approach starts with a step of segmentation of the conversation (based on lexical cohesion),
and then a stage of text-mining, including a language enriched by a vocabulary specific to
EDF, and ﬁnally a clustering of the segments. Several segmentation algorithms were tested on
a test corpus, manually annotated and segmented : the "closest" to the reference segmentation
is C99. This approach, applied to both a corpus of conversations transcribed manually, and on
the same conversations decoded by a voice recognition engine, leads to almost obtain the
same 200 clusters.

Mots-clés 2 audio-Inining, text mining, segmentation, classification, categorisation,
reconnaissance vocale, données textuelles, conversations téléphoniques, centre d’appel.
Keywords 2 audio-mining, text mining, segmentation, clustering, categorization, voice
recognition, textual data, phone conversation, call center.

Bozzi Laurent, Suignard Philippe, Waast-Richard Claire

1 Introduction

Le développement des NTIC dans une entreprise de la taille du Groupe EDF a entrainé une
augmentation du volume et des ﬂux de données hétérogenes (téléphone, intemet ...) qui
peuvent étre traitées par des méthodes de fouille et de classement automatique. En particulier
en ce qui conceme les centres d’appels, les directions marketing cherchent a mieux connaitre
les motifs d’appels des clients, a en faire une typologie. I1 s’agit de comprendre la relation des
clients a l’entreprise mais aussi de mesurer les impacts de certains événements (publicité,
nouvelles offres...). Le projet Infom@gic, du pole de compétitivité CAP DIGITAL, et le
sous-projet CallSurf s’inscrivent dans le cadre du traitement automatique de conversations.

   
 
 
     
    

3 ‘i.

E I

I.

-x

'9

MI

2

I-

E .’ .

u _ I

in i g, ‘f 7_ Interface utilisateur,
recherche et navigation eDF

mis cmouchede m'.”f.'§i';E..

  
    
 

  

connaissances
Clusterer

Fouille de données, I
classiﬁcation rd‘ L
, i I

Figure 1 : Schéma fonctionnel de CallSurf

CallSurf (Garnier-Rizet, 2008) est un systeme de transcription et de classement de données
audio comportant plusieurs étapes: enregistrement des conversations entre client et télé-
conseiller dans un centre d’appel, transcription automatique des conversations en texte,
classiﬁcation des conversations préalablement segmentées en themes homogenes en un ou
plusieurs themes et catégorisation qui consiste a calculer un modele d’affectation d’une
nouvelle conversation a un ou plusieurs des themes prédéfinis. Les sections suivantes
décrivent les premiers travaux ayant conduit a une classification automatique satisfaisante des
conversations téléphoniques.

2 Segmentation des conversations

Une classiﬁcation des conversations dans leur ensemble s’avere trop grossiere car une
conversation peut comporter plusieurs themes. A l’inverse, classifier les tours de paroles est
difficile car beaucoup d’échanges oraux sont peu porteurs de sens. C’est pourquoi, on cherche
d’abord a découper les conversations en segments homogenes pour ensuite les classiﬁer. La
suite de cette partie présente la démarche suivie afin d’aboutir a la meilleure segmentation
possible : constitution d’un corpus de référence, test et choix d’algorithmes.

2.1 Corpus de référence

Plusieurs conversations ont été segmentées a la main par des « experts » EDF aboutissant a
une nomenclature de segmentation et d’annotation en themes (avec environ une vingtaine de
themes possibles comme ouverture, cloture, motif, facture. . .). Cette description a ainsi permis

Segmentation et classification non supervisée de conversations téléphoniques
automatiquement retranscrites

de segmenter et d’annoter manuellement environ 150 conversations, représentant environ 15h,
et ainsi consumer un corpus de référence. Ce corpus comporte des particularités par rapport a
d’autres corpus utilisés pour tester des algorithmes de segmentation (DEFT par exemple) : il
s’agit d’un corpus de parole conversationnelle, donc assez différent du texte écrit, avec des
dysﬂuences, reprises, répétitions, mots tronqués. .. entre deux ou plusieurs personnes, avec du
vouvoiement entre client et agent EDF, mais tutoiement entre agents. Par ailleurs, il présente
une grande variabilité sur la longueur des segments.

2.2 Algorithmes testés

Les algorithmes testés ici font partie de la famille des méthodes non supervisées. Elles
s’appuient sur la notion de cohésion lexicale et partent du principe qu’a un theme donné,
correspond un vocabulaire spécifique. Ainsi, pour détecter les changements de theme, il suffit
de détecter les ruptures lexicales. La méthode fondatrice du domaine s’appelle « TextTiling »
(Hearst, 1997). Pour nos conversations composées de tours de parole, elle consiste a
considérer deux fenétres lexicales constituées de N tours de paroles situés avant et apres le
tour de parole i. Pour chaque tour de parole i, on compare le vocabulaire des deux fenétres par
la mesure des cosinus. En faisant glisser les deux fenétres le long des tours de parole, on
obtient une courbe de cohésion. Détecter les chutes de cette cohésion permet de détecter les
ruptures de theme.

 

f /\ f /\ E
/A\ i / \\§/ )§ /
.s'2im[;r. ,1/‘J : Zj fihj X fyj \  /   /
V2. La >< Zj  \\§// 5 /\/

Avec fy _. le nombre _ : '
d’occurreii{§§s du mot j dans le 5   Rlmtures thématimles
phrase x (ici, tour de parole x).

 

Figure 2 : Principe de l’algorithme TextTi1ing

« C99 » (Cho'1', 2000), est la grande reference a laquelle toutes les autres méthodes se
comparent. Cette méthode commence par calculer les similarités 2 a 2 entre tous les unités
textuelles (ici les tours de parole), puis regroupe ces unités, de maniere successive, jusqu’a
obtenir la répartition obtenant la meilleure densité. Cet algorithme a été utilisé tel quel,
directement téléchargé depuis le site de son auteur.

Une méthode fortement inspirée de « SegGen » (Lamprier, 2007) a été reprogrammée : elle
consiste a générer aléatoirement une population de N segmentations pour un texte initial
donné. Par croisements successifs des segmentations entre elles, elle converge vers la
« meilleure » segmentation en maximisant un score « intra segment » qui mesure la cohésion
du segment lui-meme et en minimisant un score «inter segment » mesurant la similarité entre

deux segments consécutifs.

2.3 Mesures de distance

Pour tester la qualité des segmentations obtenues par ces algorithmes, nous avons retenu la
mesure WindowDiff (WD) (Pevzner & Hearst, 2002) :

Zt u»cire.r:. )2-er;+;..> ~ bihygo.»-. h.yP~.'+A-J I)

II’?I:do1u'Dq'_if’J‘ey': f:_1p,i = V F‘

Bozzi Laurent, Suignard Philippe, Waast-Richard Claire

Avec b(xi, xj) le nombre de frontieres entre les tours i et j dans le texte X, contenant N tours
de parole, k étant un entier fixé au départ (par exemple la moitié de la longueur moyenne des
segments du document de référence).

2.4 Tests et résultats

Chacun (les 3 algorithmes a été testé sur les 150 conversations en faisant varier les traitements
en amont sur le texte : suppression de la ponctuation, suppression de mots a priori parasites
comme euh, hum, hein, ben... ou inutiles comme oui, non, bon, d’accord... ou encore en
racinisant les mots (pour supprimer les sufﬁxes ﬂexionnels et dérivationnels). Les conclusions
de tous ces tests sont les suivantes :

- C99 est retenu pour générer la segmentation : avec un WD moyen de 0.45 et un nombre
moyen de 7.3 tours de parole par segment contre 8.3 dans le corpus de référence. Il
présente l’intérét d’étre «tout terrain » (méme quand il ne foumit pas toujours les
meilleurs résultats, la segmentation produite est « correcte »).

- Tous ces tests poussent a l’interrogation concernant la fiabilité de la mesure WD1. Par
exemple, deux segmentations différentes peuvent obtenir un méme score, mais avec un
nombre de segments tres différents (10 segments dans un cas et 30 dans l’autre).

- Il faut également s’interroger sur les segmentations de référence (il peut y avoir jusqu’a 31
segments dans une conversation). Pour cela, d’autres conversations sont en train d’étre
segmentées et annotées a la main pour augmenter la taille du corpus de référence et par
des personnes différentes.

3 Classification des conversations

La partie de classification des conversations s’est faite en plusieurs étapes, et sur plusieurs
jeux de données, 170 heures (1421 conversations) retranscrites manuellement, dont 20 heures
(188 conversations) de facon détaillée.

3.1 Analyse sur les données retranscrites manuellement

Pour les premiers essais, la démarche d’analyse textuelle suivante a été suivie: analyse
morpho-syntaxique, lemmatisation, transformation des données textuelles en matrice
termes*documents, réduction de cette matrice par décomposition en SVD2 , pondération par la
méthode tf*idf, classification des vecteurs représentant X% de l’inertie totale (X étant
paramétrable) par l’algorithme EM (Expectation-Maximization).

En classifiant les tours de parole en 10 classes, on s’est apercus de la nécessité de segmenter
les conversations (cf. §2). Pour les essais suivants, et aﬁn d’optimiser les résultats, nous avons
joué sur plusieurs leviers :

- Segmentation de la conversation en parties homogenes (cf. partie précédente).

- Amélioration de la partie linguistique, en utilisant conjointement les possibilités offertes
par Temis pour développer une « cartouche » spécifique a EDF3, et l’analyseur morpho-
syntaxique de Sinequa, adapté lui aussi aux données d’EDF.

Une autre mesure, 5—Front (Fernandez et a1., 2008) a également été testée, mais présente le meme genre
d’inconvénients.

SVD : Singular Value Decomposition (Decomposition en valeurs singulieres)

Segmentation et classification non supervisée de conversations téléphoniques
automatiquement retranscrites

- Classification, par la méthode k-means. Au vu du nombre d’essais a pratiquer, sa rapidité
d’exécution était un plus, pour des résultats tres proches, au niveau qualitatif, de ceux
obtenus avec l’algorithme EM. Afin de réduire la matrice termes*documents, nous avons
essentiellement conservé les mots présents au moins 3 fois dans l’ensemble du corpus, et
étiquetés comme verbes, noms communs, adjectifs et concepts créés a l’étape précédente.

- Augmentation du nombre de classes : on a choisi de faire une classiﬁcation « a plat » avec
beaucoup de classes, plutot qu’une classiﬁcation hiérarchique, avec moins de classes au
départ, elles-mémes sous-classiﬁées.

Cette méthode nous a permis de mettre en évidence une vingtaine de classes, certaines portant
sur la structure de la conversation, et d’autres sur son theme : cloture/ouverture de
conversation, paiement de facture / mensualisation, coordonnées / références client, reglement
facture / probleme de paiement, résiliation, coordonnées de l’entreprise, coordonnées du
client, prise de rendez-vous, probleme de puissance (souvent demande d’augmentation), mise
en service, demande de branchement / raccordement, coordonnées bancaires, usages
chauffage, climatisation et autres, énergies concurrentes (gaz), Inise en attente de la part de
l’agent / recherche du dossier client, dates ou jours de rendez-vous. En revanche, la taille des
classes n’est pas homogene, un quart des segments de conversations concernent soit
l’ouverture soit la cloture de la conversation (car ces classes structurelles font partie de
quasiment toutes les conversations). De meme, les échanges de coordonnées (référence client,
adresse, téléphone, etc.) représentent une bonne part des segments, 20%.

3.2 Analyse sur les données retranscrites automatiquement

Notre objectif étant de proposer une chaine de traitements completement automatisée, on a
alors utilisé un premier jeu de données retranscrites automatiquement (reconnaissance vocale).
Les résultats des tests suivants sont toutefois provisoires, car ces données ont servi de base
d’apprentissage au modele de langage.

On a constate que l’outil de classification était assez robuste, puisqu’on retrouvait les
principaux themes des classifications précédentes, sur données transcrites manuellement. Pour
illustrer cela, si l’on prend une classe qui nous intéresse particulierement, comme les
«moyens de paiement », on constate que cette classe représente 7% des segments sur les
conversations retranscrites manuellement et 6% sur les conversations automatiques. En outre,
le champ lexical caractérisant les classes des deux jeux de données est quasiment le méme, les
mots-clés caractérisant cette classes étant les suivants :

0 Sur les données manuelles 2 moyen_paiement ; envoyer ; facture ; reglement ; recevoir ;
carte_bancaire ; re’gler ; courrier ; prelevement ; payer; noter ; relance ; probleme ; mettre ; voir

0 Sur les données automatiques: moyen_paiement ; envoyer ; facture ; étre ; recevoir ;
reglement ; courrier ; payer; re’gler ; y_avoir ; d’accord ; voir ; prelevement ; probleme ; mettre ;
relance ; retard ; attendre ; jour ; septembre

4 Conclusions et perspectives

Nous proposons donc une chaine de traitements assez complexe, permettant de passer d’un
signal audio, a une liste de themes contenus dans ce signal. La détection des themes de la

3 Une << cartouche » de Temis, permet de prendre en compte des expressions régulieres, de synonymiser

certains mots ou groupes de mots, et surtout de créer des concepts clés spéciﬁques au vocabulaire employé
dans les conversations de télé—conseillers. Par exemple, regroupement sous le concept << moyen de paiement »
des termes << cheques », << TIP », << RIB ».

Bozzi Laurent, Suignard Philippe, Waast-Richard Claire

conversation a été grandement facilité par la segmentation thématique automatique (apres le
choix de C99) et la prise en compte de regles linguistiques propre au vocabulaire d’EDF. Par
ailleurs, le passage de données manuelles a des données automatiquement retranscrites n’a pas
perturbé ce processus. Cependant, de nouvelles analyses seront réalisées sur des données
n’ayant pas servi a caler le modele de langage.

Plusieurs limites ou problemes sont apparus. Concernant la segmentation, les algorithmes
automatiques présentent plusieurs parametres. De plus, le choix de l’algorithme de
segmentation n’est pas tranché, en raison de la mesure WD utilisée, peut-étre pas adaptée a un
corpus oral. Enfin, lors de la classification, le nombre de classes doit se faire de maniere
experte a la suite de plusieurs itérations. De ce fait, a chaque étape (segmentation,
classiﬁcation), nous sommes confrontés a de nombreux choix successifs, dont les effets sur le
résultat final sont difficiles a évaluer. Afin d’améliorer les résultats, nous essaierons de régler
de facon plus fine les parametres des algorithmes de segmentation, et tenterons d’améliorer
les classiﬁcations par des techniques de ré-échantillonnage.

Remerciements
CapDigital, les partenaires du projet :Vecsys, LIlV[SI, Sinéqua et Témis.
Références

CAILLIAU F., POUDAT C., (2008) Caractérisation lexicale des contributions clients agents dans un
corpus de conversations téléphoniques retranscrites, J ADT 2008.

CHo1 F. Y. Y. (2000). Advances in domain independent linear text segmentation. In
Proceedings of the 1st Meeting of the North American Chapter of the Association for
Computational Linguistics, USA.

FERNANDEZ S., SANJUAN E., TORRES-MORENO J-M. (2008). Enertex: un systeme basé sur l'énergie
textuelle. Actes de Traitement Automatique de la Langue Naturelle, TALN 2008.

GARNIER-RIZET M., ADDA G., CAILLIAU F., GAUVAIN J. L., GUILLEMIN-LANNE S., LAMEL L., VANN1 S.,
WAAST-RICHARD C. (2008). CallSurf - Automatic transcription, indexing and structuration of
call center conversational speech for knowledge extraction and query by content, LREC 2008.

HEARST M. A. (1997). Text-tiling : segmenting text into multi-paragraph subtopic passages.
Computational Linguistics, p. 59-66.

LABADIE A., PRINCE V. (2008). Comparaison de méthodes lexicales et syntaxico-sémantiques
dans la segmentation thématique de texte non supervisée. Actes de Traitement Automatique
de la Langue Naturelle, TALN 2008.

LAMPRIER S., AMGHAR T., LEvRATB., SAUBION F. (2007) SegGen: A Genetic Algorithm for
Linear Text Segmentation. Actes de IJCAI.

PEVZNER L. & HEARST M. A. (2002). A critique and improvement of an evaluation metric for text
segmentation. Computational Linguistics, p. 19-36.

