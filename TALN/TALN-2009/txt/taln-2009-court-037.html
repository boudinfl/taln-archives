<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Segmentation multiple d&#8217;un flux de donn&#233;es textuelles pour la mod&#233;lisation statistique du langage</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009 &#8211; Session posters, Senlis, 24-26 juin 2009 
</p>
<p>Segmentation multiple d&#8217;un flux de donn&#233;es textuelles pour la 
mod&#233;lisation statistique du langage 
</p>
<p>Sopheap Seng (1, 2), Laurent Besacier (1), Brigitte Bigi (1), Eric Castelli (2) 
</p>
<p>(1) Laboratoire LIG/GETALP, Grenoble France 
{Sopheap.Seng, Laurent.Besacier, Brigitte.Bigi}@imag.fr 
</p>
<p>(2) Laboratoire MICA, CNRS/UMI-2954, Hanoi Vietnam 
Eric.Castelli@mica.edu.vn 
</p>
<p>R&#233;sum&#233; Dans cet article, nous traitons du probl&#232;me de la mod&#233;lisation statistique du 
langage pour les langues peu dot&#233;es et sans segmentation entre les mots. Tandis que le 
manque de donn&#233;es textuelles a un impact sur la performance des mod&#232;les, les erreurs 
introduites par la segmentation automatique peuvent rendre ces donn&#233;es encore moins 
exploitables. Pour exploiter au mieux les donn&#233;es textuelles, nous proposons une m&#233;thode qui 
effectue des segmentations multiples sur le corpus d&#8217;apprentissage au lieu d&#8217;une segmentation 
unique. Cette m&#233;thode bas&#233;e sur les automates d&#8217;&#233;tat finis permet de retrouver les n-grammes 
non trouv&#233;s par la segmentation unique et de g&#233;n&#233;rer des nouveaux n-grammes pour 
l&#8217;apprentissage de mod&#232;le du langage. L&#8217;application de cette approche pour l&#8217;apprentissage 
des mod&#232;les de langage pour les syst&#232;mes de reconnaissance automatique de la parole en 
langue khm&#232;re et vietnamienne s&#8217;est montr&#233;e plus performante que la m&#233;thode par 
segmentation unique, &#224; base de r&#232;gles. 
</p>
<p>Abstract In this article we deal with the problem of statistical language modelling for 
under-resourced language with a writing system without word boundary delimiters. While the 
lack of text resources has an impact on the performance of language models, the errors 
produced by the word segmentation makes those data less usable. To better exploit the text 
resources, we propose a method to make multiples segmentations on the training corpus 
instead of a unique segmentation. This method based on finite state machine allows obtaining 
the n-grams not found by the unique segmentation and generate new n-grams. We use this 
approach to train the language models for automatic speech recognition systems of Khmer 
and Vietnamese languages and it proves better performance than the unique segmentation 
method. 
</p>
<p>Mots-cl&#233;s : segmentation multiple, langue non segment&#233;e, mod&#233;lisation statistique du 
langage 
Keywords: multiple segmentation, unsegmented language, statistical language modeling</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>S. Seng, L. Besacier, B. Bigi et E. Castelli 
</p>
<p>1 Introduction 
Un mod&#232;le statistique du langage est une distribution de probabilit&#233;s sur des mots ou suites de 
mots. Il permet de classer les mots ou les phrases selon leur probabilit&#233; d&#8217;apparition. Son 
objectif est d&#8217;assigner relativement une grande probabilit&#233; aux s&#233;quences de mots fr&#233;quentes, 
significatives, grammaticalement correctes et une faible probabilit&#233; aux s&#233;quences de mots 
rares, insens&#233;es ou grammaticalement incorrectes. Les mod&#232;les de langage sont utilis&#233;s dans 
des applications telles que la reconnaissance automatique de la parole, la reconnaissance 
automatique de l&#8217;&#233;criture manuscrite, la correction orthographique, la traduction automatique 
et toute autre application introduisant une composante linguistique. La nature statistique des 
approches utilis&#233;es dans la mod&#233;lisation du langage par n-grammes, n&#233;cessite une grande 
quantit&#233; de donn&#233;es textuelles pour obtenir une estimation pr&#233;cise des probabilit&#233;s. Ces 
donn&#233;es ne sont pas disponibles en grande quantit&#233; pour les langues dites peu dot&#233;es et le 
manque de donn&#233;es d&#8217;apprentissage a un impact direct sur les performances des mod&#232;les de 
langage.  
</p>
<p>Tandis que le mot est g&#233;n&#233;ralement l&#8217;unit&#233; de base dans la mod&#233;lisation statistique du 
langage, l&#8217;identification de mots dans un texte n&#8217;est pas une t&#226;che simple m&#234;me pour les 
langues qui s&#233;parent les mots par un caract&#232;re (un espace en g&#233;n&#233;ral). Pour les langues dites 
non segment&#233;es qui poss&#232;dent un syst&#232;me d&#8217;&#233;criture sans s&#233;paration &#233;vidente entre les mots, 
les n-grammes de mots sont estim&#233;s &#224; partir de corpus d&#8217;apprentissage segment&#233;s en mots en 
utilisant des m&#233;thodes automatiques. La segmentation automatique n&#8217;est pas une t&#226;che triviale 
et introduit des erreurs &#224; cause des ambigu&#239;t&#233;s de la langue naturelle et la pr&#233;sence de mots 
inconnus dans le texte &#224; segmenter. Alors que le manque de donn&#233;es textuelles a un impact 
sur la performance des mod&#232;les de langage, les erreurs introduites par la segmentation 
automatique peuvent rendre ces donn&#233;es encore moins exploitables. Une alternative possible 
consiste &#224; calculer les probabilit&#233;s &#224; partir d&#8217;unit&#233;s sous-lexicales. Parmi les travaux existants 
qui utilisent des unit&#233;s sous-lexicales pour la mod&#233;lisation du langage, nous pouvons citer 
(Kurimo, 2006), (Abdillahi, 2006) et (Afify, 2006) qui utilisent les morph&#232;mes 
respectivement pour la mod&#233;lisation de l'arabe, du finnois, et du somalien. Pour une langue 
non-segment&#233;e comme le japonais, le caract&#232;re (id&#233;ogramme) est utilis&#233; dans (Denoual, 
2006). Dans un travail pr&#233;c&#233;dent sur la reconnaissance automatique de la parole en langue 
khm&#232;re1 (Seng, 2008), nous avons exploit&#233; les diff&#233;rentes unit&#233;s lexicales et sous-lexicales 
(mot, syllabe et groupe de caract&#232;res2) dans la mod&#233;lisation du langage de cette langue peu 
dot&#233;e. Nous avons propos&#233; des mod&#232;les de langage simples bas&#233;s sur le mot, la syllabe, le 
groupe de caract&#232;res. Notre objectif &#233;tait de comparer la performance de ces diff&#233;rentes unit&#233;s 
et nous avons observ&#233; que le mot reste l&#8217;unit&#233; la plus performante.   
</p>
<p>Dans cet article, nous traitons du probl&#232;me de la mod&#233;lisation statistique du langage &#224; base de 
mots pour les langues sans segmentation &#233;vidente entre les mots. Tandis que le manque de 
donn&#233;es textuelles a un impact sur la performance des mod&#232;les, les erreurs introduites par la 
segmentation automatique peuvent rendre ces donn&#233;es encore moins exploitables. Les n-
                                                 
1  Le khmer est la langue officielle du Cambodge 
2  En khmer, un groupe de caract&#232;res ou un cluster de caract&#232;res (CC) est une s&#233;quence de caract&#232;res 
</p>
<p>ins&#233;parables et poss&#232;de une structure bien d&#233;finie. La segmentation d&#8217;un texte khmer en CC est triviale et 
peut se faire &#224; bases des r&#232;gles. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmentation multiple de donn&#233;es textuelles pour la mod&#233;lisation statistique du langage 
</p>
<p>grammes de mots non trouv&#233;s dans le corpus d&#8217;apprentissage peuvent l&#8217;&#234;tre &#224; cause d&#8217;erreurs 
de segmentation mais aussi parce qu&#8217;une s&#233;quence de caract&#232;res peut avoir plusieurs 
segmentations correctes mais une seule segmentation a &#233;t&#233; consid&#233;r&#233;e dans le corpus 
d&#8217;apprentissage. Dans un objectif consistant &#224; mieux exploiter les donn&#233;es textuelles en 
utilisant les diff&#233;rentes vues sur les m&#234;mes donn&#233;es, nous proposons une m&#233;thode qui effectue 
des segmentations multiples sur le corpus d&#8217;apprentissage au lieu d&#8217;une segmentation unique. 
Cette nouvelle m&#233;thode de segmentation bas&#233;e sur des automates d&#8217;&#233;tat finis permet de 
g&#233;n&#233;rer toutes les segmentations possibles &#224; partir d&#8217;une s&#233;quence de caract&#232;res et nous 
pouvons ensuite en extraire les n-grammes. Elle permet de retrouver les n-grammes non 
trouv&#233;s par la segmentation unique et d&#8217;ajouter de nouveaux n-grammes dans le mod&#232;le de 
langage. L&#8217;application de cette approche pour l&#8217;apprentissage des mod&#232;les de langage pour 
les syst&#232;mes de reconnaissance automatique de la parole en langue khm&#232;re et vietnamienne 
s&#8217;est montr&#233;e plus performante que la m&#233;thode classique par segmentation unique. Dans les 
sections suivantes, nous allons d&#8217;abord faire un &#233;tat de l&#8217;art sur les m&#233;thodes de segmentation 
automatique en mots avant de pr&#233;senter notre m&#233;thode exploitant des segmentations multiples 
et les r&#233;sultats d&#8217;exp&#233;rimentations sur le khmer et le vietnamien.   
</p>
<p>2 Segmentation automatique en mots 
</p>
<p>2.1 Etat de l&#8217;art 
La segmentation de textes est l&#8217;une des t&#226;ches fondamentales dans le traitement automatique 
des langues naturelles (TALN). Beaucoup d&#8217;applications de TALN n&#233;cessitent en entr&#233;e des 
textes segment&#233;s en mots avant d&#8217;effectuer les autres traitements car le mot est consid&#233;r&#233; 
comme l&#8217;unit&#233; linguistique et s&#233;mantique de r&#233;f&#233;rence. Pour des langues comme le fran&#231;ais et 
l&#8217;anglais, il est assez naturel de d&#233;finir un mot comme une s&#233;quence de caract&#232;res s&#233;par&#233;s par 
des espaces. Cependant, pour les langues non segment&#233;es, la segmentation en mots n&#8217;est pas 
un probl&#232;me simple. A cause des ambigu&#239;t&#233;s dans la langue naturelle, une s&#233;quence de 
caract&#232;res peut &#234;tre segment&#233;e de plusieurs fa&#231;ons.  Cette ambigu&#239;t&#233; ne pose pas vraiment de 
probl&#232;me pour l&#8217;&#234;tre humain, peut &#234;tre &#224; cause du fait qu&#8217;une segmentation incorrecte donne 
g&#233;n&#233;ralement une phrase incompr&#233;hensible. De plus, il peut exister des d&#233;saccords entre 
diff&#233;rentes personnes sur la segmentation d&#8217;une phrase donn&#233;e. Ce d&#233;saccord existe car il y a 
souvent diff&#233;rentes conventions de segmentation et la d&#233;finition du mot dans une langue est 
souvent ambigu&#235;. 
</p>
<p>La technique g&#233;n&#233;rale de segmentation en mots emploie un algorithme qui recherche dans un 
dictionnaire les mots correspondant &#224; ceux du texte et qui, en cas d&#8217;ambigu&#239;t&#233;, s&#233;lectionne 
celui qui optimise un param&#232;tre d&#233;pendant de la strat&#233;gie choisie. Dans les strat&#233;gies les plus 
courantes, l&#8217;optimisation consiste &#224; : 
</p>
<p>&#8226; maximiser la taille des mots, pris un par un de gauche &#224; droite, avec retour arri&#232;re en 
cas d&#8217;&#233;chec (&#171; plus longue cha&#238;ne d&#8217;abord &#187; ou &#171; longest matching &#187;), 
</p>
<p>&#8226; minimiser le nombre de mots dans la phrase enti&#232;re (&#171; plus petit nombre de mots &#187; ou 
&#171; maximal matching &#187;). 
</p>
<p>Ces techniques recourent intensivement &#224; des dictionnaires, qu&#8217;il faut donc cr&#233;er. Bien que 
cela puisse &#234;tre fait automatiquement par apprentissage &#224; partir d&#8217;un corpus, ces dictionnaires 
ont souvent &#233;t&#233; cr&#233;&#233;s manuellement. Les travaux de recherche sur la segmentation </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>S. Seng, L. Besacier, B. Bigi et E. Castelli 
</p>
<p>automatique en mots de la langue chinoise et tha&#239;e sont tr&#232;s actifs. Parmi les travaux qui 
utilisent ces techniques, nous pouvons citer (Li, 1998) pour le chinois et (Haruechaiyasak, 
2008) pour le tha&#239;. La performance de ces m&#233;thodes est acceptable en g&#233;n&#233;ral mais elle 
d&#233;pend fortement de la taille et de la qualit&#233; des dictionnaires utilis&#233;s pour la segmentation. 
La performance diminue en pr&#233;sence de cas d&#8217;ambigu&#239;t&#233; et de mots inconnus (voir tableau 1 
pour les r&#233;sultats de la segmentation des textes khmers). 
</p>
<p>Il existe des m&#233;thodes plus &#233;labor&#233;es qui utilisent des m&#233;thodes statistiques et/ou passent par 
une phase d&#8217;apprentissage. Dans (Wu, 2003), pour une phrase chinoise &#224; segmenter, un treillis 
de tous les mots possibles est construit en fonction d&#8217;un vocabulaire. Ensuite, des m&#233;thodes 
statistiques sont appliqu&#233;es pour d&#233;coder le chemin le plus probable sur le treillis. Une 
m&#233;thode statistique et linguistique de segmentation en mots est aussi propos&#233;e et impl&#233;ment&#233;e 
sur la langue tha&#239;e (Meknavin, 1997). Dans cette m&#233;thode, le contexte des mots est analys&#233; 
linguistiquement pour d&#233;terminer la segmentation la plus probable.  
</p>
<p>Les m&#233;thodes de l&#8217;&#233;tat de l&#8217;art utilisent la combinaison de dictionnaires avec les statistiques 
pour obtenir un meilleur r&#233;sultat. Cependant, les m&#233;thodes statistiques n&#233;cessitent de disposer 
d&#8217;un grand corpus de texte segment&#233; au pr&#233;alable manuellement. Les m&#233;thodes statistiques et 
les m&#233;thodes d&#8217;apprentissage complexes ne sont pas appropri&#233;es dans notre contexte des 
langues peu dot&#233;es car les ressources n&#233;cessaires pour impl&#233;menter ces m&#233;thodes n&#8217;existent 
pas. Pour une langue consid&#233;r&#233;e, nous cherchons des m&#233;thodes de segmentation performantes, 
rapides, faciles &#224; impl&#233;menter et qui tirent, au mieux, b&#233;n&#233;fice des ressources limit&#233;es 
existantes pour la langue.  
</p>
<p>2.2 Segmentation automatique de la langue khm&#232;re  
Pour illustrer l&#8217;impact des mots hors-vocabulaire sur la performance des m&#233;thodes de 
segmentation automatique &#224; base de dictionnaire, nous d&#233;veloppons les outils de segmentation 
automatique de textes khmers en utilisant les deux crit&#232;res d&#8217;optimisation : &#171; plus longue 
cha&#238;ne d&#8217;abord &#187; (longest matching) et &#171; plus petit nombre de mots &#187; (maximal matching). 
Notre corpus de test contient 1000 phrases. Apr&#232;s la segmentation manuelle, nous obtenons 
31042 mots et un dictionnaire de 4875 mots. Nous enlevons ensuite les mots les moins 
fr&#233;quents du dictionnaire de d&#233;part pour cr&#233;er des dictionnaires avec taux de mots hors-
vocabulaire croissants (de 5% &#224; 50%) par rapport au corpus de test. Les performances de 
segmentation sont pr&#233;sent&#233;es dans le tableau 1.  
</p>
<p>Performance de la segmentation (%) Taux des mots hors 
vocabulaire Maximal Matching Longest Matching 
</p>
<p>0% 91,6 91,7 
5% 90,1 90,2 
</p>
<p>10% 90,2 90,3 
20% 86,3 86,9 
30% 82,6 83,5 
40% 75,7 77,2 
50% 68,8 72,4 
</p>
<p>Table 1 : Taux des mots corrects pour deux m&#233;thodes de segmentation 
 &#224; base de dictionnaire en fonction du taux de mots hors-vocabulaire </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmentation multiple de donn&#233;es textuelles pour la mod&#233;lisation statistique du langage 
</p>
<p>Nous observons que, dans le cas d&#8217;absence de mots hors vocabulaire, la performance est 
autour de 92% pour les deux m&#233;thodes mais la performance chute &#224; 69% et 72% quand il y a 
50% des mots hors vocabulaire dans le corpus &#224; segmenter. Pour les langues peu dot&#233;es, il est 
difficile d&#8217;obtenir un dictionnaire avec un taux de mots hors-vocabulaire faible. Dans ce cas, 
on risque donc d&#8217;atteindre une mauvaise performance de segmentation automatique sur le 
corpus d&#8217;apprentissage et la performance du mod&#232;le du langage appris &#224; partir de ce corpus 
mal segment&#233; sera alors mauvaise. 
</p>
<p>3 Segmentation multiple pour la mod&#233;lisation statistique du 
langage 
</p>
<p>3.1 Pourquoi une segmentation multiple ?  
Contrairement &#224; la segmentation unique d&#233;crite dans la section pr&#233;c&#233;dente qui recherche dans 
une s&#233;quence de caract&#232;res la meilleure segmentation selon un crit&#232;re d&#8217;optimisation, notre 
approche par segmentations multiples cherche &#224; g&#233;n&#233;rer, &#224; partir d&#8217;une s&#233;quence de 
caract&#232;res, toutes les s&#233;quences des mots valides (basant sur un dictionnaire). C&#8217;est &#224; partir de 
toutes ces s&#233;quences de mots que des n-grammes seront compt&#233;s pour l&#8217;apprentissage du 
mod&#232;le de langage.  
</p>
<p> 
Figure 1 : Exemple de la segmentation multiple d&#8217;une phrase en khmer  
</p>
<p>Figure 1 montre un exemple de la segmentation multiple d&#8217;une phrase en khmer. Nous 
montrons trois segmentations possibles d&#8217;une s&#233;quence de caract&#232;res en khmer. La 
segmentation 1 correspond bien &#224; la segmentation unique de type &#171; longest matching &#187;. Dans 
le cas de la segmentation unique (segmentation 1), nous obtenons 4 tri-grammes. Si nous 
appliquons la segmentation multiple sur cette phrase, nous avons au total 9 tri-grammes. 5 
nouveaux tri-grammes sont obtenus &#224; partir des deux autres segmentations (segmentation 2 et 
3). Il est &#224; noter que nous ne comptons qu&#8217;une seule fois un tri-gramme qui se pr&#233;sente 
plusieurs fois dans les segmentations multiples d&#8217;un phrase.  
</p>
<p>Par rapport &#224; la segmentation unique, la segmentation multiple permet d&#8217;obtenir plus de n-
grammes. Nous pouvons diviser ces nouveaux n-grammes en trois diff&#233;rentes cat&#233;gories : </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>S. Seng, L. Besacier, B. Bigi et E. Castelli 
</p>
<p>1. des n-grammes de mots qui sont effectivement pr&#233;sents dans le corpus d&#8217;apprentissage 
d&#8217;origine, non segment&#233;, mais &#224; cause d&#8217;erreurs introduites par la segmentation 
unique, ils ne sont pas retrouv&#233;s apr&#232;s la segmentation. 
</p>
<p>2. des n-grammes de mots qui sont effectivement pr&#233;sents dans le corpus d&#8217;apprentissage 
d&#8217;origine, non segment&#233;, mais comme une s&#233;quence de caract&#232;res peut avoir plusieurs 
segmentations correctes et qu&#8217;un seul choix est effectu&#233; lors de la segmentation 
unique, ils ne sont pas alors retrouv&#233;s apr&#232;s la segmentation. 
</p>
<p>3. des n-grammes de mots qui ne sont pas pr&#233;sents dans le corpus d&#8217;apprentissage m&#234;me 
si la segmentation est parfaitement correcte. Dans ce cas, la segmentation multiple 
g&#233;n&#232;re ces n-grammes parce qu&#8217;il est possible de segmenter enti&#232;rement une phrase en 
une s&#233;quence de mots valides (m&#234;me si cela donne une phrase insens&#233;e) mais aussi 
parce que notre m&#233;thode de segmentation multiple permet &#233;galement de g&#233;n&#233;rer 
localement les s&#233;quences de mots dans une phrase en marquant les parties restantes 
qui ne correspondent pas aux mots valides comme &#171; mot inconnu &#187;.  
</p>
<p>Les n-grammes de cat&#233;gorie 1 et 2 sont des n-grammes potentiellement utiles pour la 
mod&#233;lisation du langage car il s&#8217;agit de s&#233;quences de mots valides de la langue et ils sont 
effectivement pr&#233;sents dans le corpus d&#8217;apprentissage. Les n-grammes de cat&#233;gorie 3 peuvent 
perturber la mod&#233;lisation. 
</p>
<p>Nous d&#233;veloppons un outil de segmentation multiple qui permet de sortir les Nseg meilleures 
segmentations &#224; partir d&#8217;une s&#233;quence de caract&#232;res donn&#233;e en entr&#233;e. Nous allons d&#233;crire 
dans la section suivante comment la segmentation multiple est impl&#233;ment&#233;e. 
</p>
<p>3.2 Segmentation multiple utilisant les automates d&#8217;&#233;tat fini 
Notre outil de segmentation multiple est d&#233;velopp&#233; &#224; l&#8217;aide d&#8217;automates d&#8217;&#233;tat fini en utilisant 
la bo&#238;te &#224; outils de AT&amp;T FSM toolkit (Mohri, 2002). L&#8217;algorithme utilis&#233; est inspir&#233; des 
travaux sur la segmentation des mots arabes de (Zitouni, 2006) et (Lee, 2003). La 
segmentation multiple d&#8217;une s&#233;quence de caract&#232;res est faite &#224; l&#8217;aide de la composition de 
trois automates. Le premier automate est un transducteur qui g&#233;n&#232;re un treillis avec tous les 
segments possibles quand une s&#233;quence de caract&#232;res est donn&#233;e en entr&#233;e. Le deuxi&#232;me 
automate peut &#234;tre vu comme un dictionnaire sous forme de transducteur qui accepte les 
caract&#232;res et produit les s&#233;quences correspondant aux mots contenus dans le dictionnaire qui 
doit &#234;tre disponible au d&#233;but de l&#8217;algorithme. Le troisi&#232;me automate est un mod&#232;le de langage 
qui peut assigner les scores &#224; chaque s&#233;quence dans le treillis. Nous composons ces trois 
automates pour produire un treillis d&#8217;hypoth&#232;ses de segmentation en mots, &#224; partir d&#8217;une 
entr&#233;e en caract&#232;res (ou en syllabes pour le vietnamien).  En parcourant ce treillis, nous 
pouvons g&#233;n&#233;rer les Nseg meilleures segmentations pour une entr&#233;e donn&#233;e. Les Nseg meilleures 
segmentations obtenues sont ensuite utilis&#233;es pour compter le nombre des n-grammes selon la 
m&#233;thode de comptage pr&#233;sent&#233;e dans figure 1. 
</p>
<p>4 Exp&#233;rimentations 
Les exp&#233;rimentations sont men&#233;es sur deux langues peu dot&#233;es et non segment&#233;es, le khmer 
et le vietnamien. Pour comparer les performances de la segmentation multiple et la 
segmentation unique &#224; base de dictionnaire dans la mod&#233;lisation statistique du langage,  nous </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmentation multiple de donn&#233;es textuelles pour la mod&#233;lisation statistique du langage 
</p>
<p>apprenons des mod&#232;les de langage trigrammes &#224; partir des corpus d&#8217;apprentissage segment&#233;s 
en mots en utilisant ces deux approches de segmentation. Pour observer l&#8217;impact du nombre 
de segmentations multiples sur la performance des mod&#232;les de langage, nous effectuons 
plusieurs tests en faisant la segmentation multiple sur les corpus d&#8217;apprentissage en faisant 
varier le nombre Nseg de meilleures segmentations pour chaque phrase de 2 &#224; 1000. A l&#8217;aide 
d&#8217;un corpus de d&#233;veloppement, nous comparons la couverture en trigrammes (trigram hits) de 
ces mod&#232;les de langage et leur perplexit&#233;. Nous &#233;valuons ensuite les performances de ces 
mod&#232;les de langage en les utilisant dans un syst&#232;me de reconnaissance automatique de la 
parole.  
</p>
<p>4.1 Exp&#233;rimentations sur le khmer 
Le khmer est la langue officielle du Cambodge parl&#233;e par plus de 15 millions de personnes 
dans le monde. Elle appartient au groupe des langues m&#244;n-khm&#232;res. Elle est class&#233;e comme 
une langue peu dot&#233;e car les ressources linguistiques et les services pour le traitement 
automatique de la langue ne sont pas encore bien d&#233;velopp&#233;s. Au niveau de l&#8217;&#233;criture, le 
khmer est &#233;crit sans espaces entre les mots.  
</p>
<p>Notre corpus d&#8217;apprentissage de la langue khm&#232;re contient environ un demi million de 
phrases de type news. Un dictionnaire de 20k mots extraits du dictionnaire Chuon Nath de 
l&#8217;Institut Bouddhique du Cambodge est utilis&#233; dans cette exp&#233;rimentation. La segmentation 
unique &#224; base de ce dictionnaire avec le crit&#232;re d&#8217;optimisation &#171; longest matching &#187; donne un 
corpus de 15 millions de mots. Cinq autres corpus sont obtenus en effectuant les 
segmentations multiples avec le nombre de Nseg meilleures segmentations qui varie de 2 &#224; 
1000. Il est &#224; noter que la segmentation multiple utilise le m&#234;me dictionnaire que la 
segmentation unique. Le comptage des n-grammes est effectu&#233; sur ces corpus et les mod&#232;les 
de langage n-gramme sont ensuite appris en utilisant ce m&#234;me dictionnaire de 20k mots. 
</p>
<p>Un corpus de d&#233;veloppement (dev) de 370 phrases (11k mots apr&#232;s la segmentation unique) 
est utilis&#233; pour &#233;valuer la couverture en trigrammes (trigram hits) et la perplexit&#233; des mod&#232;les 
de langage du khmer. Nous pr&#233;sentons dans le tableau 2 le nombre de trigrammes dans les 
mod&#232;les de langage, la couverture en trigrammes de ces mod&#232;les, la perplexit&#233; et la 
performance du syst&#232;me de reconnaissance automatique de la parole en langue khm&#232;re (sur 
un corpus de test constitu&#233; de 160 phrases de type news et dont les transcriptions sont 
diff&#233;rentes de l&#8217;ensemble de dev) qui utilise ces mod&#232;les dans le d&#233;codage. Les d&#233;tails sur le 
syst&#232;me de reconnaissance automatique en langue khm&#232;re (d&#233;codeur, mod&#232;le acoustique) sont 
donn&#233;s dans (Seng, 2008).  
</p>
<p>Les mod&#232;les de langage issus des diff&#233;rentes segmentations  
M_Unique M_2 M_5 M_10 M_50 M_100 M_500 M_1000 
</p>
<p>Nombre de trigrammes dans le 
mod&#232;le de langage (million) 5,67 7,34 8.95 10,17 12,52 13,31 14,85 15,41 
Nombre de trigram hits sur dev 3404 3744 3799 3867 4020 4065 4162 4204 
% trigram hits sur dev 31% 34,1% 34,6% 35,2% 36,6% 37% 37,9% 38,3% 
Perplexit&#233; sur dev 394,9 322,5 348,8 361.8 373,9 374,7 378 378 
Taux d&#8217;erreur Reco. sur test 22% 21.7% 20.8% 20.5% 20.6% 20.7% 20.9% 21% 
</p>
<p>Table 2 : Les r&#233;sultats des exp&#233;rimentations en langue khm&#232;re </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>S. Seng, L. Besacier, B. Bigi et E. Castelli 
</p>
<p>4.2 Exp&#233;rimentations sur le vietnamien 
Le vietnamien est la langue officielle du Vietnam. Elle est parl&#233;e par environ 70 millions de 
personnes dans le monde. Son origine est toujours sujette &#224; d&#233;bat parmi les linguistes. Il est 
cependant g&#233;n&#233;ralement admis qu&#8217;elle a des racines communes et fortes avec le m&#244;n-khmer 
qui fait partie de la branche austro asiatique. L&#8217;orthographe est latine depuis le XVII&#232; si&#232;cle, 
avec des caract&#232;res accentu&#233;s pour les tons. Le vietnamien est &#233;crit avec les espaces entre les 
syllabes mais ces espaces ne marquent pas les fronti&#232;res entre les mots dans une phrase car un 
mot peut se composer d&#8217;une ou plusieurs syllabes. La figure 2 donne un exemple d&#8217;une phrase 
de la langue vietnamienne. 
</p>
<p> 
</p>
<p>Figure 2 : Exemple d&#8217;une phrase vietnamienne 
</p>
<p>Le corpus d&#8217;apprentissage du vietnamien contient 3 millions de phrases soit plus de 56 
millions de syllabes. Un dictionnaire de 30k mots extraits &#224; partir d&#8217;un dictionnaire bilingue 
Vietnamien-Fran&#231;ais est utilis&#233; dans cette exp&#233;rimentation. Apr&#232;s la segmentation unique 
automatique &#224; base de ce dictionnaire avec le crit&#232;re d&#8217;optimisation &#171; longest matching &#187;, 
nous obtenons un corpus de 46 millions de mots. Les segmentations multiples sont effectu&#233;es 
avec les nombres de Nseg variant de 2 &#224; 1000. Les mod&#232;les de langage de trigrammes sont 
ensuite appris &#224; partir de ces corpus en utilisant un dictionnaire de 30k mots (cf 
exp&#233;rimentation sur le khmer). 
</p>
<p>Un corpus de d&#233;veloppement (dev) de 1000 phrases (44k mots apr&#232;s la segmentation unique)  
est utilis&#233; pour &#233;valuer la couverture en trigramme et la perplexit&#233; des mod&#232;les de langage. 
Les performances de reconnaissance de la parole sont estim&#233;es sur un corpus de test de 400 
phrases de type news (dont les transcriptions sont diff&#233;rentes de l&#8217;ensemble de dev). Les 
d&#233;tails sur le syst&#232;me de reconnaissance automatique en langue vietnamienne sont donn&#233;s 
dans (Le, 2008). Les r&#233;sultats des exp&#233;rimentations sur le vietnamien sont dans le tableau 3. 
</p>
<p> Les mod&#232;les issus des diff&#233;rentes segmentations 
 M_Unique M_2 M_5 M_10 M_50 M_100 M_500 M_1000 
</p>
<p>Nombre de trigrammes dans le 
mod&#232;le de langage (million) 20.32 24,06 28,92 32,82 34,2 34,9 35.83 36.8 
</p>
<p>Nombre de trigram hits sur le dev 15901 16190 16384 16458 16547 16569 16593 16614 
% de trigram hits sur le dev 47,7% 48,6% 49,2% 49,4% 49,7% 49,7% 49,8% 49,9% 
Perplexit&#233; sur le dev 118,9 118,1 125,9 129 133,4 134,8 136,9 137,6 
Taux d&#8217;erreur de Reco sur le test 36,5% 35,5% 36% 36,1% 36,1% 36,2% 36,5% 36,5% 
</p>
<p>Table 3 : Les r&#233;sultats d&#8217;exp&#233;rimentation sur la langue vietnamienne 
</p>
<p>4.3 Discussion   
A travers les r&#233;sultats d&#8217;exp&#233;rimentations sur le khmer et le vietnamien, nous pouvons 
constater que l&#8217;approche par segmentations multiples permet de g&#233;n&#233;rer des nouveaux 
trigrammes par rapport &#224; la segmentation unique, quand le nombre de Nseg meilleures 
segmentations est augment&#233; Cette augmentation de nombre de trigrammes dans le model du </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Segmentation multiple de donn&#233;es textuelles pour la mod&#233;lisation statistique du langage 
</p>
<p>langage am&#233;liore la couverture en trigrammes et la perplexit&#233;. Cette am&#233;lioration montre que 
les nouveaux trigrammes g&#233;n&#233;r&#233;s par la segmentation multiple sont pertinents pour la 
mod&#233;lisation statistique du langage. Dans le cas du khmer, la meilleur taux d&#8217;erreurs du 
syst&#232;me de reconnaissance automatique de la parole est obtenue avec le model du langage 
M_10 et la performance drops si nous continuons &#224; augmenter le nombre de Nseg meilleures 
segmentations. Cela montre qu&#8217;&#224; partir d&#8217;un certain niveau de segmentation, quand on 
augmente encore Nseg, on ajoute beaucoup de mauvais trigrammes et cela perturbe la bonne 
r&#233;partition des probabilit&#233;s dans le mod&#232;le du langage. Ce ph&#233;nom&#232;ne peut &#234;tre observ&#233; 
clairement dans le cas de la langue vietnamienne : la couverture en trigramme n&#8217;augmente 
que de 0,2% quand on augmente le nombre de Nseg meilleures segmentations de 50 &#224; 1000 
mais on ajoute plus de 2,5 millions de nouveaux trigrammes dans le mod&#232;le. La meilleur taux 
d&#8217;erreurs du syst&#232;me de reconnaissance automatique de la parole dans le cas de vietnamien est 
obtenue avec le nombre de segmentation Nseg= 2. Avec une analyse plus d&#233;taill&#233;e sur le corpus 
d&#8217;apprentissage vietnamien, nous avons constat&#233; que pr&#232;s de 80% des mots dans le corpus 
sont les mots monosyllabiques et seulement 20% qui sont multi-syllabiques. Cela veut dire 
qu&#8217;il n&#8217;y pas beaucoup de bonne segmentations possibles que l&#8217;on peut g&#233;n&#233;rer comparant &#224; 
la langue khm&#232;re. 
</p>
<p>5 Conclusion 
Nous proposons dans cet article une approche qui consiste &#224; effectuer des segmentations 
multiples sur le corpus d&#8217;apprentissage pour la mod&#233;lisation statistique du langage dans le 
contexte des langues peut dot&#233;es et non segment&#233;es. Cette approche permet de retrouver les n-
grammes non trouv&#233;s par la segmentation unique et de g&#233;n&#233;rer de nouveaux n-grammes dans 
les mod&#232;les. L&#8217;application de cette m&#233;thode pour l&#8217;apprentissage des mod&#232;les de langage 
pour les syst&#232;mes de reconnaissance automatique de la parole en langue khm&#232;re et 
vietnamienne s&#8217;est montr&#233;e plus performante (en perplexit&#233; et en taux d&#8217;erreur de 
reconnaissance) que la m&#233;thode par segmentation unique.  
</p>
<p>R&#233;f&#233;rences 
Abdillahi N. et al. (2006). Automatic transcription of Somali language. Interspeech&#8217;06. 289-
292. Pittsburgh, PA 
Afify M. et al. (2006) On the use of morphological analysis for dialectal Arabic Speech 
Recognition. Interspeech&#8217;06, 277-280. Pittsburgh, PA 
Denoual E., Lepage Y. (2006). The character as an appropriate unit of processing for non-
segmenting languages. NLP Annual Meeting. 731-734, Tokyo Japan 
</p>
<p>Haruechaiyasak C., Kongyoung S., et Dailey M.N. (2008). A Comparative Study on Thai 
Word Segmentation Approaches. In Proceedings of ECTI-CON. 125-128. Thailand 
</p>
<p>Kurimo M. et al. (2006). Unsupervised segmentation of words into morphemes - Morpho 
Challenge 2005: Application to Automatic Speech Recognition. Interspeech&#8217;06. 1021-1024. 
Pittsburgh, PA </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>S. Seng, L. Besacier, B. Bigi et E. Castelli 
</p>
<p>Le V.B., Besacier L., Seng S., Bigi B., DO T.N.D. (2008). Recent Advances in Automatic 
Speech Recognition for Vietnamese. International Workshop on Spoken Languages 
Technologies for Under-Ressourced Languages. SLTU&#8217;08 Hanoi Vietnam 
</p>
<p>Lee, Y., Papineni, K., Roukos, S., Emam, O., et Hassan, H. (2003). Language model based 
arabic word segmentation. In Proceedings of the 41st Annual Meeting on Association For 
Computational Linguistics - Volume 1 399-406. Sapporo. Japan. 
</p>
<p>Li H., Yuan B. (1998). Chinese word segmentation. Proceedings of the 12th Paci Asia 
Conference on Language, Information and Computation. PACLIC-12. Singapore 
</p>
<p>Meknavin S., Charoenpornsawat P., Kijsirikul B. (1997). Feature-based Thai Word 
Segmentation. NLPRS&#8217;97. Phuket. Thailand 
</p>
<p>Mohri M., Pereira F., et Riley M. (2002). Weighted Finite-State Transducers in Speech 
Recognition. Computer Speech and Language. 16(1) 69-88 
</p>
<p>Seng S., Sam S., Le V. B., Besacier L. et Bigi B. (2008). Which Units for Acoustic and 
Language Modelling for Khmer Automatic Speech Recognition? SLTU&#8217;08. 33-38, Hanoi 
Vietnam 
</p>
<p>Wu A. (2003) Chinese word segmentation in MSR-NLP, SIGHAN Workshop on Chinese 
Language Processing. Sapporo. Japan 
</p>
<p>Zitouni I. (2006). Finite state based Arabic word segmentation. ArabTEXtest for Ali 
Farghaly. CSLI Publication. </p>

</div></div>
</body></html>