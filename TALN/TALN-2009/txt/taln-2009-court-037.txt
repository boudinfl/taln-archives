TALN 2009 — Session posters, Senlis, 24-26 juin 2009

Segmentation multiple d’un ﬂux de données textuelles pour la
modélisation statistique du langage

Sopheap Seng (1, 2), Laurent Besacier (1), Brigitte Bi gi (1), Eric Castelli (2)

(1) Laboratoire LIG/GETALP, Grenoble France
{Sopheap.Seng, Laurent.Besacier, Brigitte.Bigi} @imag.fr
(2) Laboratoire MICA, CNRS/UMI—2954, Hanoi Vietnam
Eric.Castelli @mica.edu.Vn

Résumé Dans cet article, nous traitons du probléme de la modélisation statistique du
langage pour les langues peu dotées ct sans segmentation entre les mots. Tandis que le
manque de données textuelles a un impact sur la performance des modéles, les erreurs
introduites par la segmentation automatique peuvent rendre ces données encore moins
exploitables. Pour exploiter au mieux les données textuelles, nous proposons une méthode qui
effectue des segmentations multiples sur le corpus d’apprentissage au lieu d’une segmentation
unique. Cette méthode basée sur les automates d’état finis permet de retrouver les n—grammes
non trouvés par la segmentation unique et de générer des nouveaux n—grammes pour
l’apprentissage de modéle du langage. L’application de cette approche pour l’apprentissage
des modéles de langage pour les systémes de reconnaissance automatique de la parole en
langue khmére ct Vietnamienne s’est montrée plus performante que la méthode par
segmentation unique, 51 base de régles.

Abstract In this article we deal with the problem of statistical language modelling for
under—resourced language with a writing system without word boundary delimiters. While the
lack of text resources has an impact on the performance of language models, the errors
produced by the word segmentation makes those data less usable. To better exploit the text
resources, we propose a method to make multiples segmentations on the training corpus
instead of a unique segmentation. This method based on finite state machine allows obtaining
the n—grams not found by the unique segmentation and generate new n—grams. We use this
approach to train the language models for automatic speech recognition systems of Khmer
and Vietnamese languages and it proves better performance than the unique segmentation
method.

M0tS-CléS 2 segmentation multiple, langue non segmentée, modélisation statistique du
langage

Keywords: multiple segmentation, unsegmented language, statistical language modeling

S. Seng, L. Besacier, B. Bigi et E. Castelli

1 Introduction

Un modele statistique du langage est une distribution de probabilités sur des mots ou suites de
mots. ll perrnet de classer les mots ou les phrases selon leur probabilité d’apparition. Son
objectif est d’assigner relativement une grande probabilité aux sequences de mots fréquentes,
significatives, grammaticalement correctes et une faible probabilité aux sequences de mots
rares, insensées ou grammaticalement incorrectes. Les modeles de langage sont utilises dans
des applications telles que la reconnaissance automatique de la parole, la reconnaissance
automatique de l’écriture manuscrite, la correction orthographique, la traduction automatique
et toute autre application introduisant une composante linguistique. La nature statistique des
approches utilisées dans la modélisation du langage par n—grammes, nécessite une grande
quantité de données textuelles pour obtenir une estimation precise des probabilités. Ces
données ne sont pas disponibles en grande quantité pour les langues dites peu dotées et le
manque de données d’apprentissage a un impact direct sur les performances des modeles de
langage.

Tandis que le mot est généralement l’unité de base dans la modélisation statistique du
langage, l’identification de mots dans un texte n’est pas une tache simple meme pour les
langues qui séparent les mots par un caractere (un espace en general). Pour les langues dites
non segmentées qui possedent un systeme d’écriture sans separation évidente entre les mots,
les n—grammes de mots sont estimés a partir de corpus d’apprentissage segmentés en mots en
utilisant des méthodes automatiques. La segmentation automatique n’est pas une tache triviale
et introduit des erreurs a cause des ambigu'1'tés de la langue naturelle et la presence de mots
inconnus dans le texte a segmenter. Alors que le manque de données textuelles a un impact
sur la performance des modeles de langage, les erreurs introduites par la segmentation
automatique peuvent rendre ces données encore moins exploitables. Une alternative possible
consiste a calculer les probabilités a partir d’unités sous—leXicales. Parmi les travaux existants
qui utilisent des unites sous—leXicales pour la modélisation du langage, nous pouvons citer
(Kurimo, 2006), (Abdillahi, 2006) et (Afify, 2006) qui utilisent les morphemes
respectivement pour la modélisation de l'arabe, du finnois, et du somalien. Pour une langue
non—segmentée comme le japonais, le caractere (idéogramme) est utilise dans (Denoual,
2006). Dans un travail precedent sur la reconnaissance automatique de la parole en langue
khmerel (Seng, 2008), nous avons exploité les différentes unites lexicales et sous—leXicales
(mot, syllabe et groupe de caracteresz) dans la modélisation du langage de cette langue peu
dotée. Nous avons propose des modeles de langage simples bases sur le mot, la syllabe, le
groupe de caracteres. Notre objectif était de comparer la performance de ces différentes unites
et nous avons observe que le mot reste l’unité la plus performante.

Dans cet article, nous traitons du probleme de la modélisation statistique du langage a base de
mots pour les langues sans segmentation évidente entre les mots. Tandis que le manque de
données textuelles a un impact sur la performance des modeles, les erreurs introduites par la
segmentation automatique peuvent rendre ces données encore moins exploitables. Les n-

1 Le khmer est la langue officielle du Cambodge
2 En khmer, un groupe de caractéres ou un cluster de caractéres (CC) est une séquence de caractéres
inséparables et posséde une structure bien définie. La segmentation d’un texte khmer en CC est triviale et
peut se faire 51 bases des régles.

Segmentation multiple de dormees textuelles pour la modelisation statistique du langage

grammes de mots non trouves dans le corpus d’apprentissage peuvent l’etre a cause d’erreurs
de segmentation mais aussi parce qu’une sequence de caracteres peut avoir plusieurs
segmentations correctes mais une seule segmentation a ete consideree dans le corpus
d’apprentissage. Dans un objectif consistant a mieux exploiter les donnees textuelles en
utilisant les differentes Vues sur les memes donnees, nous proposons une methode qui effectue
des segmentations multiples sur le corpus d’apprentissage au lieu d’une segmentation unique.
Cette nouvelle methode de segmentation basee sur des automates d’etat finis permet de
generer toutes les segmentations possibles a partir d’une sequence de caracteres et nous
pouvons ensuite en extraire les n—grammes. Elle permet de retrouver les n—grammes non
trouves par la segmentation unique et d’ajouter de nouveaux n—grammes dans le modele de
langage. L’application de cette approche pour l’apprentissage des modeles de langage pour
les systemes de reconnaissance automatique de la parole en langue khmere et Vietnamienne
s’est montree plus performante que la methode classique par segmentation unique. Dans les
sections suivantes, nous allons d’abord faire un etat de l’art sur les methodes de segmentation
automatique en mots avant de presenter notre methode exploitant des segmentations multiples
et les resultats d’experimentations sur le khmer et le Vietnamien.

2 Segmentation automatique en mots

2.1 Etat de l’art

La segmentation de textes est l’une des taches fondamentales dans le traitement automatique
des langues naturelles (TALN). Beaucoup d’applications de TALN necessitent en entree des
textes segmentes en mots avant d’effectuer les autres traitements car le mot est considere
comme l’unite linguistique et semantique de reference. Pour des langues comme le francais et
l’anglais, il est assez naturel de definir un mot comme une sequence de caracteres separes par
des espaces. Cependant, pour les langues non segmentees, la segmentation en mots n’est pas
un probleme simple. A cause des ambigu'1'tes dans la langue naturelle, une sequence de
caracteres peut etre segmentee de plusieurs facons. Cette ambigu'1'te ne pose pas Vraiment de
probleme pour l’etre humain, peut etre a cause du fait qu’une segmentation incorrecte donne
generalement une phrase incomprehensible. De plus, il peut exister des desaccords entre
differentes personnes sur la segmentation d’une phrase donnee. Ce desaccord existe car il y a
souvent differentes conventions de segmentation et la definition du mot dans une langue est
souvent ambigue.

La technique generale de segmentation en mots emploie un algorithme qui recherche dans un
dictionnaire les mots correspondant a ceux du texte et qui, en cas d’ambigu'1'te, selectionne
celui qui optimise un parametre dependant de la strategie choisie. Dans les strategies les plus
courantes, l’optimisation consiste a :

° maximiser la taille des mots, pris un par un de gauche a droite, avec retour arriere en
cas d’echec (« plus longue chaine d’abord >> ou « longest matching >>),

0 minimiser le nombre de mots dans la phrase entiere (« plus petit nombre de mots >> ou
« maximal matching >>).

Ces techniques recourent intensivement a des dictionnaires, qu’il faut donc creer. Bien que
cela puisse etre fait automatiquement par apprentissage a partir d’un corpus, ces dictionnaires
ont souvent ete crees manuellement. Les travaux de recherche sur la segmentation

S. Seng, L. Besacier, B. Bigi et E. Castelli

automatique en mots de la langue chinoise et tha'1'e sont tres actifs. Parmi les travaux qui
utilisent ces techniques, nous pouvons citer (Li, 1998) pour le chinois et (Haruechaiyasak,
2008) pour le tha'1'. La performance de ces méthodes est acceptable en general mais elle
depend fortement de la taille et de la qualité des dictionnaires utilises pour la segmentation.
La performance diminue en presence de cas d’ambigu'1'té et de mots inconnus (Voir tableau 1
pour les résultats de la segmentation des textes khmers).

ll existe des méthodes plus élaborées qui utilisent des méthodes statistiques et/ou passent par
une phase d’apprentissage. Dans (Wu, 2003), pour une phrase chinoise a segmenter, un treillis
de tous les mots possibles est construit en fonction d’un Vocabulaire. Ensuite, des méthodes
statistiques sont appliquées pour decoder le chemin le plus probable sur le treillis. Une
méthode statistique et linguistique de segmentation en mots est aussi proposée et implémentée
sur la langue tha'1'e (Meknavin, 1997). Dans cette méthode, le contexte des mots est analyse
linguistiquement pour determiner la segmentation la plus probable.

Les méthodes de l’état de l’art utilisent la combinaison de dictionnaires avec les statistiques
pour obtenir un meilleur résultat. Cependant, les méthodes statistiques nécessitent de disposer
d’un grand corpus de texte segmenté au préalable manuellement. Les méthodes statistiques et
les méthodes d’apprentissage complexes ne sont pas appropriées dans notre contexte des
langues peu dotées car les ressources nécessaires pour implémenter ces méthodes n’existent
pas. Pour une langue considérée, nous cherchons des méthodes de segmentation performantes,

rapides, faciles a implémenter et qui tirent, au mieux, bénéfice des ressources limitées
existantes pour la langue.

2.2 Segmentation automatique de la langue khmére

Pour illustrer l’impact des mots hors—Vocabulaire sur la performance des méthodes de
segmentation automatique a base de dictionnaire, nous développons les outils de segmentation
automatique de textes khmers en utilisant les deux criteres d’optimisation: << plus longue
chaine d’abord >> (longest matching) et « plus petit nombre de mots >> (maximal matching).
Notre corpus de test contient 1000 phrases. Apres la segmentation manuelle, nous obtenons
31042 mots et un dictionnaire de 4875 mots. Nous enlevons ensuite les mots les moins
frequents du dictionnaire de depart pour créer des dictionnaires avec taux de mots hors-
Vocabulaire croissants (de 5% a 50%) par rapport au corpus de test. Les performances de
segmentation sont présentées dans le tableau 1.

Taux des mots hors Performance de la segmentation (%)
Vocablllaire Maximal Matching Longest Matching

0% 9 1 ,6 9 1 ,7

5% 90,1 90,2

10% 90,2 90,3
20% 86,3 86,9
30% 82,6 83,5
40% 75,7 77,2
50% 68,8 72,4

Table I : T aux des mots corrects pour deux me’th0des de segmentation
a base de dictionnaire en fonction du taux de mots h0rs—v0cabulaire

Segmentation multiple de dormees textuelles pour la modélisation statistique du langage

Nous observons que, dans le cas d’absence de mots hors Vocabulaire, la performance est
autour de 92% pour les deux methodes mais la performance chute a 69% et 72% quand il y a
50% des mots hors Vocabulaire dans le corpus a segmenter. Pour les langues peu dotees, il est
difficile d’obtenir un dictionnaire avec un taux de mots hors—Vocabulaire faible. Dans ce cas,
on risque donc d’atteindre une mauvaise performance de segmentation automatique sur le
corpus d’apprentissage et la performance du modele du langage appris a partir de ce corpus
mal segmente sera alors mauvaise.

3 Segmentation multiple pour la modélisation statistique du
langage

3.1 Pourquoi une segmentation multiple ?

Contrairement a la segmentation unique decrite dans la section precedente qui recherche dans
une sequence de caracteres la meilleure segmentation selon un critere d’optimisation, notre
approche par segmentations multiples cherche a generer, a partir d’une sequence de
caracteres, toutes les sequences des mots Valides (basant sur un dictionnaire). C’est a partir de
toutes ces sequences de mots que des n—grammes seront comptes pour l’apprentissage du
modele de langage.

Phrase LnZt]§fnLn:UIUL’cjiSiU3'h 3-grams Count
wl W2 wa
Segmematiorm [fl  W LE1: UIULEE ‘ES ‘ILUILJ W2 W3 W4
wl W2 w W4 W5 we w3 w4 w5
w4 w5 we
. Lnzns m Ln: U18 Lﬁ is itﬁh w2W3w7
Segmentation 2 "" ” w3 w7 w
w w2 w3 w7 w8 w5 we
w7 w8 w5

Ln: n9 m Ln: we Ltj is ttfih w,w,w2

Segmentation 3
W3 W9 w2 w, w, we ws we W9W2W3

Traduction Le bouddha est notre mattre supréme

Figure I :Exemple de la segmentation multiple d ‘une phrase en khmer

Figure 1 montre un exemple de la segmentation multiple d’une phrase en khmer. Nous
montrons trois segmentations possibles d’une sequence de caracteres en khmer. La
segmentation 1 correspond bien a la segmentation unique de type << longest matching >>. Dans
le cas de la segmentation unique (segmentation 1), nous obtenons 4 tri—grammes. Si nous
appliquons la segmentation multiple sur cette phrase, nous avons au total 9 tri—grammes. 5
nouveaux tri— grammes sont obtenus a partir des deux autres segmentations (segmentation 2 et
3). Il est a noter que nous ne comptons qu’une seule fois un tri—gramme qui se presente
plusieurs fois dans les segmentations multiples d’un phrase.

Par rapport a la segmentation unique, la segmentation multiple permet d’obtenir plus de n-
grammes. Nous pouvons diviser ces nouveaux n—grammes en trois differentes categories :

S. Seng, L. Besacier, B. Bigi et E. Castelli

1. des n—grammes de mots qui sont effectivement presents dans le corpus d’apprentissage
d’origine, non segmenté, mais a cause d’erreurs introduites par la segmentation
unique, ils ne sont pas retrouvés apres la segmentation.

2. des n—grammes de mots qui sont effectivement presents dans le corpus d’apprentissage
d’origine, non segmenté, mais comme une sequence de caracteres peut avoir plusieurs
segmentations correctes et qu’un seul choix est effectué lors de la segmentation
unique, ils ne sont pas alors retrouvés apres la segmentation.

3. des n—grammes de mots qui ne sont pas presents dans le corpus d’apprentissage meme
si la segmentation est parfaitement correcte. Dans ce cas, la segmentation multiple
génere ces n—grammes parce qu’il est possible de segmenter entierement une phrase en
une sequence de mots Valides (meme si cela donne une phrase insensée) mais aussi
parce que notre méthode de segmentation multiple permet également de générer
localement les sequences de mots dans une phrase en marquant les parties restantes
qui ne correspondent pas aux mots Valides comme << mot inconnu >>.

Les n—grammes de catégorie 1 et 2 sont des n—grammes potentiellement utiles pour la
modélisation du langage car il s’agit de sequences de mots Valides de la langue et ils sont
effectivement presents dans le corpus d’apprentissage. Les n—grammes de catégorie 3 peuvent
perturber la modélisation.

Nous développons un outil de segmentation multiple qui permet de sortir les Nseg meilleures
segmentations a partir d’une sequence de caracteres donnée en entree. Nous allons décrire
dans la section suivante comment la segmentation multiple est implémentée.

3.2 Segmentation multiple utilisant les automates d’état fini

Notre outil de segmentation multiple est développé a l’aide d’automates d’état fini en utilisant
la boite a outils de AT&T FSM toolkit (Mohri, 2002). L’algorithme utilise est inspire des
travaux sur la segmentation des mots arabes de (Zitouni, 2006) et (Lee, 2003). La
segmentation multiple d’une sequence de caracteres est faite a l’aide de la composition de
trois automates. Le premier automate est un transducteur qui génere un treillis avec tous les
segments possibles quand une sequence de caracteres est donnée en entree. Le deuxieme
automate peut étre Vu comme un dictionnaire sous forme de transducteur qui accepte les
caracteres et produit les sequences correspondant aux mots contenus dans le dictionnaire qui
doit étre disponible au debut de l’algorithme. Le troisieme automate est un modele de langage
qui peut assigner les scores a chaque sequence dans le treillis. Nous composons ces trois
automates pour produire un treillis d’hypotheses de segmentation en mots, a partir d’une
entree en caracteres (ou en syllabes pour le Vietnamien). En parcourant ce treillis, nous
pouvons générer les Nseg meilleures segmentations pour une entree donnée. Les Nseg meilleures
segmentations obtenues sont ensuite utilisées pour compter le nombre des n—grammes selon la
méthode de comptage présentée dans figure 1.

4 Expérimentations
Les expérimentations sont menées sur deux langues peu dotées et non segmentées, le khmer

et le Vietnamien. Pour comparer les performances de la segmentation multiple et la
segmentation unique a base de dictionnaire dans la modélisation statistique du langage, nous

Segmentation multiple de dormees textuelles pour la m0de'lisati0n statistique du langage

apprenons des modeles de langage trigrammes a partir des corpus d’apprentissage segmentes
en mots en utilisant ces deux approches de segmentation. Pour observer l’impact du nombre
de segmentations multiples sur la performance des modeles de langage, nous effectuons
plusieurs tests en faisant la segmentation multiple sur les corpus d’apprentissage en faisant
Varier le nombre Nseg de meilleures segmentations pour chaque phrase de 2 a 1000. A l’aide
d’un corpus de developpement, nous comparons la couverture en trigrammes (trigram hits) de
ces modeles de langage et leur perplexite. Nous evaluons ensuite les performances de ces
modeles de langage en les utilisant dans un systeme de reconnaissance automatique de la
parole.

4.1 Expérimentations sur le khmer

Le khmer est la langue officielle du Cambodge parlee par plus de 15 millions de personnes
dans le monde. Elle appartient au groupe des langues mon—khmeres. Elle est classee comme
une langue peu dotee car les ressources linguistiques et les services pour le traitement
automatique de la langue ne sont pas encore bien developpes. Au niveau de l’ecriture, le
khmer est ecrit sans espaces entre les mots.

Notre corpus d’apprentissage de la langue khmere contient environ un demi million de
phrases de type news. Un dictionnaire de 20k mots extraits du dictionnaire Chuon Nath de
l’Institut Bouddhique du Cambodge est utilise dans cette experimentation. La segmentation
unique a base de ce dictionnaire avec le critere d’optimisation << longest matching >> donne un
corpus de 15 millions de mots. Cinq autres corpus sont obtenus en effectuant les
segmentations multiples avec le nombre de Nseg meilleures segmentations qui Varie de 2 a
1000. Il est a noter que la segmentation multiple utilise le meme dictionnaire que la
segmentation unique. Le comptage des n—grammes est effectue sur ces corpus et les modeles
de langage n— gramme sont ensuite appris en utilisant ce meme dictionnaire de 20k mots.

Un corpus de developpement (dev) de 370 phrases (11k mots apres la segmentation unique)
est utilise pour evaluer la couverture en tri grammes (trigram hits) et la perplexite des modeles
de langage du khmer. Nous presentons dans le tableau 2 le nombre de trigrammes dans les
modeles de langage, la couverture en trigrammes de ces modeles, la perplexite et la
performance du systeme de reconnaissance automatique de la parole en langue khmere (sur
un corpus de test constitue de 160 phrases de type news et dont les transcriptions sont
differentes de l’ensemble de dev) qui utilise ces modeles dans le decodage. Les details sur le
systeme de reconnaissance automatique en langue khmere (decodeur, modele acoustique) sont
donnes dans (Seng, 2008).

Les modéles de langage issus des differentes segmentations
M_Unique M_2 M_5 M_1o M_50 M_100 M_500 M_1000

5,67 7,34 8.95 10,17 12,52 13,31 14,85 15,41

Nombre de Iligrammes dans le
modéle de langage (million)
Nombre de trigram hits sur dev 3404 3744 3799 3867 4020 4065 4162 4204

% trigram hits s11r dev 31% 34,1% 34,6% 35,2% 36,6% 37% 37,9% 38,3%
Peiplexite sur dev 394,9 322,5 348,8 361.8 373,9 374,7 378 378
Taux d’erreur Reco. sur test 22% 21.7% 20.8% 20.5% 20.6% 29%? 20.9% 21%

Table 2 : Les résultats des expérimentations en langue khmere

S. Seng, L. Besacier, B. Bigi et E. Castelli

4.2 Expérimentations sur le Vietnamien

Le Vietnamien est la langue officielle du Vietnam. Elle est parlée par environ 70 millions de
personnes dans le monde. Son origine est toujours sujette a débat parrni les linguistes. Il est
cependant généralement admis qu’elle a des racines communes et fortes avec le mon—khmer
qui fait partie de la branche austro asiatique. L’orthographe est latine depuis le XVIIe siecle,
avec des caracteres accentués pour les tons. Le Vietnamien est écrit avec les espaces entre les
syllabes mais ces espaces ne marquent pas les frontieres entre les mots dans une phrase car un
mot peut se composer d’une ou plusieurs syllabes. La figure 2 donne un exemple d’une phrase
de la langue Vietnamienne.

Phrase \'1etnanuenne: H6m nay, Chung téi de”n tru’c‘$ng béng xe hdi.

motl mot2 mot3 mot4 mots mots

Traduction en fraugais : Aujourd'hui, nous allons é |'e'-(ole en volture.

Figure 2 :Exemple d ‘une phrase vietnamienne

Le corpus d’apprentissage du Vietnamien contient 3 millions de phrases soit plus de 56
millions de syllabes. Un dictionnaire de 30k mots extraits a partir d’un dictionnaire bilingue
Vietnamien—Francais est utilise dans cette experimentation. Apres la segmentation unique
automatique a base de ce dictionnaire avec le critere d’optimisation << longest matching >>,
nous obtenons un corpus de 46 millions de mots. Les segmentations multiples sont effectuées
avec les nombres de Nseg Variant de 2 a 1000. Les modeles de langage de trigrammes sont
ensuite appris a partir de ces corpus en utilisant un dictionnaire de 30k mots (cf
experimentation sur le khmer).

Un corpus de développement (dev) de 1000 phrases (44k mots apres la segmentation unique)
est utilise pour évaluer la couverture en trigramme et la perplexité des modeles de langage.
Les performances de reconnaissance de la parole sont estimées sur un corpus de test de 400
phrases de type news (dont les transcriptions sont différentes de l’ensemble de dev). Les
details sur le systeme de reconnaissance automatique en langue Vietnamienne sont donnés
dans (Le, 2008). Les résultats des expérimentations sur le Vietnamien sont dans le tableau 3.

Les modéles issus des différentes segmentations
M_Unique M_2 M_5 M_10 M_50 M_100 M_500 M_1000

Nombre de tri grammes dans le
modéle dc langage (million)

Nombre de trigram hits s11r le dev 15901 16190 16384 16458 16547 16569 16593 16614

20.32 24,06 28,92 32,82 34,2 34,9 35.83 36.8

% dc trigraln hits sur le dev 47,7% 48,6% 49,2% 49,4% 49,7% 49,7% 49,8% 49,9%
Perplcxité sur lc dev 118,9 118,1 125,9 129 133,4 134,8 136,9 137,6
Taux d’erreur dc Reco sur le test 36,5% 35,5% 36% 36,1% 36,1% 36,2% 36,5% 36,5%

Table 3 : Les résultats d ’expe’rimentati0n sur la langue vietnamienne

4.3 Discussion

A travers les résultats d’expérimentations sur le khmer et le Vietnamien, nous pouvons
constater que l’approche par segmentations multiples permet de générer des nouveaux
trigrammes par rapport a la segmentation unique, quand le nombre de Nseg meilleures
segmentations est augmenté Cette augmentation de nombre de trigrammes dans le model du

Segmentation multiple de d0rme'es textuelles pour la m0de'lisati0n statistique du langage

langage améliore la couverture en trigrammes et la perplexité. Cette amelioration montre que
les nouveaux trigrammes générés par la segmentation multiple sont pertinents pour la
modélisation statistique du langage. Dans le cas du khmer, la meilleur taux d’erreurs du
systeme de reconnaissance automatique de la parole est obtenue avec le model du langage
M_10 et la performance drops si nous continuons a augmenter le nombre de Nseg meilleures
segmentations. Cela montre qu’a partir d’un certain niveau de segmentation, quand on
augmente encore Nseg, on ajoute beaucoup de mauvais trigrammes et cela perturbe la bonne
repartition des probabilités dans le modele du langage. Ce phénomene peut étre observé
clairement dans le cas de la langue vietnamienne: la couverture en trigramme n’augmente
que de 0,2% quand on augmente le nombre de Nseg meilleures segmentations de 50 a 1000
mais on ajoute plus de 2,5 millions de nouveaux trigrammes dans le modele. La meilleur taux
d’erreurs du systeme de reconnaissance automatique de la parole dans le cas de vietnamien est
obtenue avec le nombre de segmentation Nsegz 2. Avec une analyse plus détaillée sur le corpus
d’apprentissage vietnamien, nous avons constaté que pres de 80% des mots dans le corpus
sont les mots monosyllabiques et seulement 20% qui sont multi—syllabiques. Cela veut dire
qu’il n’y pas beaucoup de bonne segmentations possibles que l’on peut générer comparant a

la langue khmere.

5 Conclusion

\

Nous proposons dans cet article une approche qui consiste a effectuer des segmentations
multiples sur le corpus d’apprentissage pour la modélisation statistique du langage dans le
contexte des langues peut dotées et non segmentées. Cette approche permet de retrouver les n-
grammes non trouvés par la segmentation unique et de générer de nouveaux n—grammes dans
les modeles. L’application de cette méthode pour l’apprentissage des modeles de langage
pour les systemes de reconnaissance automatique de la parole en langue khmere et
vietnamienne s’est montrée plus performante (en perplexité et en taux d’erreur de
reconnaissance) que la méthode par segmentation unique.

Références

Abdillahi N. et al. (2006). Automatic transcription of Somali language. Interspeech’06. 289-
292. Pittsburgh, PA

Afify M. et al. (2006) On the use of morphological analysis for dialectal Arabic Speech
Recognition. Interspeech’06, 277-280. Pittsburgh, PA

Denoual E., Lepage Y. (2006). The character as an appropriate unit of processing for non-
segmenting languages. NLP Annual Meeting. 731-734, Tokyo Japan

Haruechaiyasak C., Kongyoung S., et Dailey M.N. (2008). A Comparative Study on Thai
Word Segmentation Approaches. In Proceedings of ECTI-CON. 125-128. Thailand

Kurimo M. et al. (2006). Unsupervised segmentation of words into morphemes - Morpho
Challenge 2005: Application to Automatic Speech Recognition. Interspeech’06. 1021-1024.
Pittsburgh, PA

S. Seng, L. Besacier, B. Bigi et E. Castelli

Le V.B., Besacier L., Seng S., Bigi B., DO T.N.D. (2008). Recent Advances in Automatic
Speech Recognition for Vietnamese. International Workshop on Spoken Languages
Technologies for Under—Ressourced Languages. SLTU’08 Hanoi Vietnam

Lee, Y., Papineni, K., Roukos, S., Emam, 0., et Hassan, H. (2003). Language model based
arabic word segmentation. In Proceedings of the 41st Annual Meeting on Association For
Computational Linguistics — Volume 1 399-406. Sapporo. Japan.

Li H.,Yuan B. (1998). Chinese word segmentation. Proceedings of the 12th Paci Asia
Conference on Language, Information and Computation. PACLIC—12. Singapore

Meknavin S., Charoenpornsawat P., Kijsirikul B. (1997). Feature—based Thai Word
Segmentation. NLPRS’97. Phuket. Thailand

Mohri M., Pereira F., et Riley M. (2002). Weighted Finite—State Transducers in Speech
Recognition. Computer Speech and Language. 16(1) 69-88

Seng S., Sam S., Le V. B., Besacier L. et Bigi B. (2008). Which Units for Acoustic and
Language Modelling for Khmer Automatic Speech Recognition? SLTU’08. 33-38, Hanoi
Vietnam

Wu A. (2003) Chinese word segmentation in MSR—NLP, SIGHAN Workshop on Chinese
Language Processing. Sapporo. Japan

Zitouni I. (2006). Finite state based Arabic word segmentation. ArabTEXtest for Ali
Farghaly. CSLI Publication.

