TALN 2009 – Session posters , Senlis, 24–26 juin 2009
Un Algorithme d’Analyse de Type Earley pour Grammaires à
Concaténation d’Intervalles
Laura Kallmeyer1 Wolfgang Maier1 Yannick Parmentier2
(1) SFB 441 / Universität Tübingen, Nauklerstr. 35, D-72074 Tübingen
(2) LORIA / Nancy Université, Campus Scientifique, BP 239,
F-54506 Vandœuvre-Lès-Nancy Cedex
lk@sfs.uni-tuebingen.de wo.maier@uni-tuebingen.de parmenti@loria.fr
Résumé. Nous présentons ici différents algorithmes d’analyse pour grammaires à conca-
ténation d’intervalles (Range Concatenation Grammar, RCG), dont un nouvel algorithme de
type Earley, dans le paradigme de l’analyse déductive. Notre travail est motivé par l’intérêt
porté récemment à ce type de grammaire, et comble un manque dans la littérature existante.
Abstract. We present several different parsing algorithms for Range Concatenation Gram-
mar (RCG), inter alia an entirely novel Earley-style algorithm, using the deductive parsing fra-
mework. Our work is motivated by recent interest in range concatenation grammar in general
and fills a gap in the existing literature.
Mots-clés : Analyse syntaxique déductive, grammaires à concaténation d’intervalles.
Keywords: Deductive parsing, range concatenation grammar.
1 Introduction
Les grammaires à concaténation d’intervalles (RCG) (Boullier, 2000) ont récemment reçu une
attention particulière dans différents contextes de travail. Ceux-ci incluent la traduction auto-
matique dirigée par la syntaxe (Søgaard, 2008), le développement de grammaires (Sagot, 2005)
ou encore l’extraction de grammaires à partir de treebanks (Maier & Søgaard, 2008).
En outre, d’un point de vue formel, les RCGs sont intéressantes car elles génèrent exactement
la classe des langages analysables en un temps polynômial (Bertsch & Nederhof, 2001). En
particulier, elles sont plus puissantes que la classe des RCGs « simples », une sous-classe de
RCG qui est équivalente aux systèmes de réécriture hors-contexte linéaires (Linear Context-
Free rewriting Systems, LCFRS), aux grammaires d’arbres adjoints multi-composantes locales
aux arbres (Set-Local Multi-Component Tree-Adjoining Grammars, SL-MCTAG) (Weir, 1988)
et aux grammaires hors-contexte multiples (Multiple Context-Free Grammars, MCFG) (Seki
et al., 1991) (les preuves sont données par Boullier (1998)). Or, il a été démontré que cette
dernière classe des RCGs simples est incapable de traiter certains phénomènes de la langue
naturelle, comme par exemple la permutation d’arguments dans le « brouillage » (scrambling)
des langues dites à ordre des mots libres (Becker et al., 1992), ou encore les constructions non
Laura Kallmeyer, Wolfgang Maier et Yannick Parmentier
semi-linéaires telles que l’empilement de cas en géorgien ancien (Michaelis & Kracht, 1996),
et les nombres chinois (Radzinski, 1991), phénomènes que les RCGs peuvent traiter (Boullier,
1999).
Aussi, des algorithmes d’analyse pour RCG ont été présentés par (i) Boullier (2000), qui définit
un algorithme d’analyse descendante directionnelle, et (ii) Barthélemy et al. (2001), qui ajoutent
un oracle à l’algorithme de Boullier afin de limiter l’espace de recherche. La classe des RCGs
simples a reçu une plus grande attention, comme en témoignent les travaux sur l’analyse à base
d’automates de De La Clergerie (2002), ceux sur l’analyse déductive de LCFRS de Burden et
Ljunglöf (2005), ou encore l’approche de Kanazawa (2008) pour l’analyse de MCFG au moyen
de Datalog.
Dans cet article, nous ne prétendons pas motiver l’utilisation des RCGs (pour cela, se référer aux
articles sus-cités), mais cherchons plutôt à combler un manque dans la littérature sur les algo-
rithmes d’analyse pour RCG non-simples. Plus précisément, nous fournissons une formulation
de l’analyse de la classe entière des RCGs dans le cadre de l’analyse par déduction. Nous pré-
sentons dans un même cadre des algorithmes descendants, des algorithmes de type CYK, et un
algorithme de type Earley, facilitant ainsi une comparaison des différentes stratégies d’analyse.
Pour profiter pleinement de cette comparaison, il est utile d’avoir des connaissances en analyse
déductive, et notamment des règles de déduction du type de celles présentées par Shieber et
al. (1995). L’article est structuré comme suit. En Section 2, nous introduisons les notions préli-
minaires nécessaires. En Section 3, nous introduisons les algorithmes descendants, en Section 4
les algorithmes de type CYK et en Section 5 un algorithme de type Earley. Nous terminons en
donnant quelques chiffres sur l’efficacité relative des ces algorithmes.
2 Notions préliminaires
Les RCGs sont des grammaires dont les productions (appelées clauses) réécrivent des prédicats
couvrant certaines parties de la phrase en d’autres prédicats. Par exemple, une clause de la forme
S(aXb) ? S(X) indique qu’un prédicat S est vrai pour une partie de la phrase si cette partie
commence par un a et finit par un b, et si, de plus, S est également vrai pour la portion de phrase
comprise entre a et b. Une clause S(c) ? ? indique que S est vrai pour tout terminal c, sans
autre condition. La RCG ayant les deux clauses S(aXb) ? S(X), S(c)? ? génère le langage
{ancbn |n ≥ 0}.
Dans cet article, nous nous intéressons uniquement aux RCG positives car elles correspondent
à la variante utilisée dans les travaux sus-mentionnés. Les RCG non-positives, appelées RCG
négatives, permettent l’utilisation de prédicats négatifs de la forme A(?1, . . . , ?n). De tels pré-
dicats permettent de reconnaître le langage complémentaire de celui généré au moyen des pré-
dicats positifs correspondants (voir Boullier (2000) pour plus de détails).
Définition 1 (Grammaire à concaténation d’intervalle). Une grammaire à concaténation d’in-
tervalle (RCG) est un 5-uplet G = ?N, T, V, P, S?. N est un ensemble fini de noms de prédicats,
avec une fonction d’arité définie comme suit : dim: N ? N \ {0}, T et V sont des ensembles
finis de symboles terminaux et de variables respectivement. P est un ensemble fini de clauses de
la forme ?0 ? ?1 . . . ?m, où m ≥ 0 et chacun des ?i, 0 ≤ i ≤ m, est un prédicat de la forme
Ai(?1, . . . , ?dim(Ai)) avec Ai ? N et ?j ? (T ? V )
? pour 1 ≤ j ≤ dim(Ai). Comme raccourci
de notation pour Ai(?1, . . . , ?dim(Ai)), nous utilisons Ai(~?). S ? N est le nom du prédicat de
départ, tel que dim(S) = 1.
Un Algorithme d’Analyse de Type Earley pour Grammaires à Concaténation d’Intervalles
Le concept d’intervalle est primordial pour les RCG. Nous définissons ce concept et celui de
vecteur d’intervalle ci-dessous.
Définition 2 (Intervalle). Pour tout w ? T ?, où w = w1 . . . wn avec wi ? T pour 1 ≤ i ≤ n,
nous définissons :
– Pos(w) := {0, . . . , n}.
– Une paire ?l, r? ? Pos(w) ? Pos(w) avec l ≤ r est un intervalle dans w. Sa production
?l, r?(w) est la sous-chaîne wl+1 . . . wr.
– Pour deux intervalles ?1 = ?l1, r1?, ?2 = ?l2, r2? : si r1 = l2, alors ?1 · ?2 = ?l1, r2? ; sinon
?1 · ?2 n’est pas défini.
Définition 3 (Vecteur d’intervalles). Pour un w ? T ? donné, nous appelons un vecteur ? =
(?x1, y1?, . . . , ?xk, yk?) vecteur d’intervalles de dimension k dans w si ?xi, yi? est un intervalle
dans w pour 1 ≤ i ≤ k. ?(i).l (resp. ?(i).r) dénote alors le premier (resp. second) composant
du ie élément de ?, c’est-à-dire xi (resp. yi).
Afin d’instancier une clause de la grammaire, nous avons besoin de déterminer les intervalles
couverts par toutes les variables dans la clause, et de toutes les occurrences de symboles ter-
minaux. Par souci de clarté, nous supposons que les variables d’une clause et les occurrences
de symboles terminaux sont équipées d’indices distincts, commençant à 1, ordonnés de gauche
à droite, et tels que, pour les variables, seule la première occurrence donne lieu à un nouvel
indice. Nous introduisons alors une fonction ? : P ? N retournant l’indice maximal dans une
clause. De plus, nous définissons ?(c, x) pour une clause c et une variable ou une occurrence
d’un terminal x donnés comme étant l’indice de x dans c.
Définition 4 (Instanciation de clause). Une instanciation d’une clause c ? P avec ?(c) =
j par rapport à une chaîne w est donnée par le vecteur d’intervalles ? avec dim(?) = j.
L’application de ? à un prédicat A(~?) dans c associe toutes les occurrences de x ? (T ? V )
avec ?(c, x) = i dans ~? à ?(i). Si le résultat est défini (c’est-à-dire, les images de variables
adjacentes peuvent être concaténées), celui-ci est appelé un prédicat instancié et le résultat de
l’application de ? à tous les prédicats dans c, s’il est défini, est appelé une clause instanciée.
En plus des vecteurs d’intervalles, nous introduisons également des vecteurs de contraintes
d’intervalle. Ceux-ci sont des vecteurs contenant des paires composées de variables d’extrémité
d’intervalle, et un ensemble de contraintes sur ces variables.
Définition 5 (Vecteur de contraintes d’intervalles). Soit Vr = {r1, r2, . . .} un ensemble de va-
riables d’extrémité d’intervalle.
Un vecteur de contraintes d’intervalles de dimension k est une paire ?~?, C? où
– ? ? (V 2r )
k ; nous définissons Vr(?) comme l’ensemble des variables d’extrémité d’intervalle
apparaissant dans ~?.
– C est un ensemble de contraintes cr ayant l’une des formes suivantes :
r1 = r2, k = r1, r1 + k = r2, k ≤ r1, r1 ≤ k, r1 ≤ r2 ou r1 + k ≤ r2
pour r1, r2 ? Vr(?) et k ? N.
Nous disons qu’un vecteur d’intervalles ? satisfait un vecteur de contraintes d’intervalles ??, C?
ssi ? et ? ont la même dimension k et qu’il existe une fonction f : Vr ? N associant ?(i).l
à ?(i).l et ?(i).r à ?(i).r pour tout 1 ≤ i ≤ k telle que toutes les contraintes dans C soient
satisfaites. De plus, nous disons qu’un vecteur de contraintes d’intervalles ??, C? est satisfiable
ssi il existe un vecteur d’intervalles ? qui le satisfait.
Laura Kallmeyer, Wolfgang Maier et Yannick Parmentier
Définition 6 (Vecteur de contraintes d’intervalles d’une clause). Pour toute clause c, nous défi-
nissons son vecteur de contraintes d’intervalles ??, C? par rapport à une chaîne w avec |w| = n
comme suit :
– ? a pour dimension ?(c), et toutes les variables d’extrémité d’intervalle dans ? sont diffé-
rentes deux à deux.
– Pour tout ?r1, r2? ? ? : 0 ≤ r1, r1 ≤ r2, r2 ≤ n ? C.
Pour toutes les occurrences x de terminaux dans c avec i = ?(c, x) : ?(i).l+1 = ?(i).r ? C.
Pour toutes x, y qui sont des variables ou des occurrences de terminaux dans c telles que xy
est une sous-chaîne d’un des arguments de c : ?(?(c, x)).r = ?(?(c, y)).l ? C.
Ce sont toutes les contraintes dans C.
Intuitivement, un vecteur de contraintes d’intervalles d’une clause capture toute l’information
sur les extrémités formant un intervalle, sur les intervalles contenant un unique terminal, et sur
les occurrences de variables / terminaux adjacentes dans la clause.
Une dérivation RCG consiste en la réécriture de prédicats instanciés :
Définition 7 (Dérivation). Étant donné une RCG G et une chaîne d’entrée w, nous définissons
la relation ?G,w (appelée dérive) sur les chaînes des prédicats instanciés de la manière sui-
vante. Soient ?1,?2 des chaînes de prédicats instanciés. Si A0( ~?0) ? A1( ~?1) . . . Am( ~?m) est
l’instanciation d’une clause c ? PG, alors ?1A0( ~?0)?2 ?G,w ?1A1( ~?1) . . . Am( ~?m)?2.
Intuitivement, si le membre de gauche d’une clause instanciée apparaît dans la chaîne de prédi-
cats instanciés, il peut être remplacé par son membre de droite.
Définition 8 (Langage). Le langage d’une RCG G est l’ensemble des chaînes qui peuvent être
réduites au mot vide : L(G) = {w | S(?0, |w|?) +?G,w ?}.
La capacité générative des RCGs dépasse celle des formalismes légèrement sensibles au contexte.
Par exemple, on peut considérer la RCG G = ?{S, eq}, {a}, {X, Y }, P, S? avecP = {S(XY ) ?
S(X)eq(X, Y ), S(a) ? ?, eq(aX, aY ) ? eq(X, Y ), eq(a, a) ? ?}. Il est facile de constater
que L(G) = {a2n | n ≥ 0}. Ce langage n’est pas légèrement sensible au contexte car il n’a pas
la propriété de croissance constante.
Par souci de clarté, nous supposons dans ce qui suit, sans perte de généralité, que les arguments
vides (?) apparaissent uniquement dans les clauses dont les membres de droite sont vides.1
3 Analyse descendante
Analyse descendante non-directionnelle L’idée de l’analyse descendante est d’instancier le
prédicat de départ par rapport à la chaîne d’entrée toute entière et de vérifier récursivement s’il
existe un moyen de réduire tous les prédicats des membres de droite à ?.
Les items ont la forme [A, ?,flag ], où A est un prédicat, ? est un vecteur d’intervalles de di-
mension dim(A) (contenant les intervalles avec lesquels sont instanciés les arguments de A) et
flag ? {c, p} indique si l’item a été complété ou prédit.
1Toute RCG peut être transformée en une RCG satisfaisant cette condition : pour cela, il suffit d’introduire un
nouveau prédicat unaire Eps et une clause Eps(?) ? ?, puis, pour chaque clause x dont le membre de droite n’est
pas ?, de remplacer chaque argument ? qui apparaît dans c par une nouvelle variable X? et d’ajouter le prédicat
Eps(X?) au membre de droite de c.
Un Algorithme d’Analyse de Type Earley pour Grammaires à Concaténation d’Intervalles
Comme axiome, nous prédisons S couvrant toute la chaîne d’entrée. Ainsi, la règle initialisa-
tion est la suivante :
[S, (?0, n?), p]
L’opération prédiction prédit de nouveaux items à partir des items précédemment prédits :
[A0, ?, p]
[A1, ?1, p] . . . [Ak, ?k, p]
s’il existe une clause A0(~x0) ? A1(~x1) . . . Ak(~xk) avec une instanciation ? telle que ?(c) =
A(?)? A1(?1) . . . Ak(?k).
Puisque, à la différence de l’analyse descendante standard pour grammaires hors-contexte, nous
commençons avec l’intégralité de la chaîne d’entrée à l’initialisation, nous avons besoin d’un
moyen pour propager l’information sur les prédicats instanciés. Ceci se fait via un flag p/c, dont
la valeur est donnée par les opérations de lecture et de complétion. L’opération de lecture met
la valeur du flag à c pour un item décrivant un prédicat préalablement prédit :
[A, ?, p]
[A, ?, c]
s’il existe une clause c = A(~x) ? ? avec une instanciation ? telle que ?(A(~x)) = A(?). La
règle de complétion met le flag à c pour un prédicat d’un membre de droite complété :
[A0, ?, p], [A1, ?1, c] . . . [Ak, ?k, c]
[A0, ?, c]
La reconnaissance réussit s’il existe un moyen de déclarer que le prédicat de départ est complété.
Pour cela, nous utilisons un item but : [S, (?0, n?), c].
Analyse descendante directionnelle L’algorithme ci-dessus peut être amélioré en évaluant les
prédicats d’un membre de droite de manière ordonnée (de gauche à droite), et en interrompant
l’évaluation dès qu’une instanciation de prédicat échoue. Cette variante correspond à l’algo-
rithme présenté dans Boullier (2000).2 Aussi, nous devons distinguer les items passifs des items
actifs. Les items passifs ont les mêmes forme et signification que les items de l’algorithme non-
directionnel présenté précédemment. Les items actifs permettent de déplacer un signet (appelé
dot) le long d’un membre de droite d’une clause : [A(~x) ? ? • ?, ?] où A(~x) ? ?? est
une clause et ? est un vecteur d’intervalles de dimension j = ?(A(~x) ? ??) qui fournit
l’instanciation de la clause.
L’axiome est la prédiction du prédicat de départ couvrant toute la chaîne d’entrée. Ainsi la règle
initialisation est la même que celle de l’algorithme non-directionnel. L’item but ne change pas
non plus. Nous avons à présent deux opérations de prédiction. La première, prédiction-règle,
prédit des items actifs avec leur dot au début de leur membre de droite, pour un item passif
prédit donné :
[A,?, p]
[A(~x) ? •?, ?]
avec ?(A(~x)) = A(?)
La seconde, prédiction-préd, prédit un item passif pour un prédicat suivant le dot dans un item
actif :
[A(~x)? ? •B(~y)?, ?]
[B,?, p]
avec ?(B(~y)) = B(?)
2Notons que cet algorithme n’est pas celui implanté dans le système SYNTAX développé par Boullier et al.
Laura Kallmeyer, Wolfgang Maier et Yannick Parmentier
L’opération de lecture est la même que dans le cas non-directionnel. L’opération de complétion
déplace le dot au-dessus d’un prédicat dans le membre de droite d’un item actif si l’item passif
correspondant a été complété :
[B, ?B, c], [A(~x) ? ? •B(~y)?, ?]
[A(~x) ? ?B(~y) •?, ?]
avec ?(B(~y)) = B(?B)
Une fois que le dot a atteint la fin du membre de droite, nous pouvons effectuer une conversion
de l’item actif en un item passif complété :
[A(~x)? ?•, ?]
[A,?, c]
avec ?(A(~x)) = A(?)
Un problème évident de cet algorithme est que la règle prédiction-règle doit calculer toutes les
instanciations possibles des clauses correspondant à un prédicat instancié donné. Prenons par
exemple la RCG pour {a2n |n ≥ 0} de la Section 2. Si w = aaaa, à partir de [S, (?0, 4?), p]
prédiction-règle prédirait (entre autres) tous les items actifs [S(X1Y2) ? •S(X1)eq(X1, Y2),
(?0, r?, ?r, 4?)] avec r ? {0, 1, 2, 3, 4}. Le calcul de toutes les instanciations possibles est très
coûteux, et va être évité dans l’algorithme de type Earley présenté en Section 5. En effet, dans
ce dernier, nous utiliserons des vecteurs de contraintes d’intervalles (au lieu de vecteurs d’inter-
valles) pour ne prédire qu’un seul item actif :
[S(X1Y2)? •S(X1)eq(X1, Y2), ??(r1, r2), (r3, r4)?, {0 = r1, r1 ≤ r2, r2 = r3, r3 ≤ r4, 4 = r4}?]
4 Analyse ascendante
Analyse CYK L’analyse CYK (Cocke, Younger, Kasami) est une technique d’analyse ascen-
dante non-directionnelle. Les items ont la forme [A, ?] où A est un prédicat et ? un vecteur
d’intervalles de dimension dim(A).
Règle de lecture:
[A, ?]
s’il existe une clause c = A(~x) ? ? avec une instanciation ? telle que ?(A(~x)) = A(?).
Règle de complétion:
[A1, ?1] . . . [Ak, ?k]
[A, ?]
où A(?)? A1(?1) . . . Ak(?k) est une clause instanciée.
L’item but est : [S, (?0, n?)].
Analyse ascendante directionnelle Un désavantage évident de l’algorithme CYK est que, afin
de réaliser une opération de complétion, tous les A1, . . . , Ak du membre de droite doivent être
vérifiés pour les items correspondants. Ce qui mène à un grand nombre d’indices qui doivent
être vérifiés en même temps. Pour éviter cela, nous pouvons à nouveau déplacer un signet le
long du membre de droite d’une clause. Comme dans le cas descendant directionnel, en plus
des items ci-dessus (appelés items passifs), nous ajoutons des items actifs. Dans les items actifs,
nous gardons une trace des positions déjà déterminées pour les extrémités gauche et droite des
occurrences de variables et terminaux. Ceci est réalisé par l’enrichissement des items liés à la
Un Algorithme d’Analyse de Type Earley pour Grammaires à Concaténation d’Intervalles
Grammaire G : S(XY ) ? S(X)eq(X,Y ), S(a1) ? ?, eq(a1X, a2Y ) ? eq(X,Y ), eq(a1, a2) ? ?
Items générés pour la chaîne w = aa (les contraintes 0 ≤ r1, r2 ≤ n pour un intervalle ?r1, r2? sont omises) :
Item Opération
1. [S, (?0, 1?)] lecture S(a1) ? ?
2. [S, (?1, 2?)] lecture S(a1) ? ?
3. [eq, (?0, 1?, ?0, 1?)] lecture eq(a1, a2) ? ?
4. [eq, (?0, 1?, ?1, 2?)] lecture eq(a1, a2) ? ?
5. [eq, (?1, 2?, ?0, 1?)] lecture eq(a1, a2) ? ?
6. [eq, (?1, 2?, ?1, 2?)] lecture eq(a1, a2) ? ?
7. [S(XY ) ? •S(X)eq(X,Y ), {X.l ≤ X.r,X.r = Y.l, Y.l ≤ Y.r}] initialisation,
8. [eq(a1X, a2Y ) ? •eq(X,Y ),
{a1.l + 1 = a1.r, a1.r = X.l,X.l ≤ X.r, a2.l + 1 = a2.r, a2.r = Y.l, Y.l ≤ Y.r}]initialisation
9. [S(XY ) ? S(X) • eq(X,Y ), ?{. . . , 0 = X.l, 1 = X.r}] complétion 7. avec 1.
10. [S(XY ) ? S(X) • eq(X,Y ), {. . . , 1 = X.l, 2 = X.r}] complétion 7. avec 2.
11. [eq(a1X, a2Y ) ? eq(X,Y )•, {. . . , 1 = X.l, 2 = X.r, 1 = Y.l, 2 = Y.r}] complétion 8. avec 6.
12. [S(XY ) ? S(X)eq(X,Y )•, {. . . , 0 = X.l, 1 = X.r, 1 = Y.l, 2 = Y.r}] complétion 9. avec 4.
13. [eq, (?0, 2?, ?0, 2?)] conversion 11.
14. [S, (?0, 1?, ?1, 2?)] conversion 12.
FIG. 1 – Trace d’une analyse CYK directionnelle.
clause. Les items actifs ont la forme [A(~x) ? ? • ?, ??, C?] avec A(~x) ? ?? une clause,
?? 6= ?, ?(A(~x ? ??)) = j et ??, C? un vecteur de contraintes d’intervalles de dimension
j. Nous imposons que ??, C? doit être satisfiable. Les items qui diffèrent uniquement par une
bijection des variables d’intervalles sont considérés comme équivalents.
La règle de lecture et celle de but sont les mêmes que dans le cas non-directionnel. En outre,
la règle initialisation introduit des clauses dont le dot est au début du membre de droite :
[A(~x) ? •?, ??, C?]
A(~x) ? ? étant une clause avec pour vecteur de contraintes d’intervalles ??, C?,? 6= ?.
La règle de complétion déplace le dot au-dessus d’un prédicat dans le membre de droite d’un
item actif si l’item passif correspondant a été complété :
[B, ?B],
[A(~x)? ? •B(x1...y1, ..., xk...yk)?, ??, C?]
[A(~x) ? ?B(x1...y1, ..., xk...yk) •?, ??, C
??]
où C ? = C ? {?B(j).l = ?(?(xj)).l, ?B(j).r = ?(?(yj)).r | 1 ≤ j ≤ k}. Notons que les
conditions sur les items nécessitent que le nouvel ensemble de contraintes pour ? soit satisfiable.
La règle de conversion convertit un item actif dont le dot est à la fin du membre de droite en un
item passif complété :
[A(~x) ? ?•, ??, C?]
[A, ?]
s’il existe une instanciation ? de A(~x)? ? qui satisfasse ??, C? tel que ?(A(~x)) = A(?).
Un exemple de trace d’exécution est donné en Fig. 1. Par souci de clarté, au lieu de variables
d’intervalles, nous utilisons X.l (resp. X.r) pour l’extrémité gauche (resp. droite) de l’intervalle
associé à X .
Laura Kallmeyer, Wolfgang Maier et Yannick Parmentier
5 Algorithme de type Earley
Règles de déduction Nous ajoutons à présent une opération de prédiction à l’algorithme CYK
avec items actifs, ce qui conduit à un algorithme de type Earley. Les items passifs sont enrichis
avec un flag additionnel qui peut prendre les valeur p ou c selon que l’item est prédit ou com-
plété. De plus, ils contiennent un vecteur de contraintes d’intervalles puisque, lorsqu’on prédit
un prédicat, les extrémités gauche et droite de ses arguments peuvent ne pas être connues.
Les items passifs ont soit la forme [A, ??, C?, p] pour les items prédits, où ??, C? est un vecteur
de contraintes d’intervalles de dimension dim(A), soit la forme [A, ?, c] pour les items com-
plétés où ? est un vecteur d’intervalles de dimension dim(A). Les items actifs sont les mêmes
que dans le cas CYK. L’axiome est la prédiction d’un prédicat S couvrant la chaîne d’entrée,
c’est-à-dire, la règle initialisation est la suivante :
[S, ?(?r1, r2?), {0 = r1, n = r2}?, p]
Nous avons deux opérations de prédiction. La première, prédiction-règle, prédit des items
actifs avec le dot au début de leur membre de droite, pour un item passif prédit donné :
[A, ??, C?, p]
[A(x1 . . . y1, . . . , xk . . . yk) ? •?, ??
?, C ??]
où ???, C ?? est obtenu à partir du vecteur de contraintes d’intervalles de la clause
A(x1 . . . y1, . . . , xk . . . yk) ? ? en prenant toutes les contraintes de C, en associant tous les
?(i).l à ??(?(xi)).l et tous les ?(i).r à ??(?(yi)).r, et en ajoutant les contraintes résultant au
vecteur de contraintes de la clause. La seconde opération, prédiction-pred, prédit un item passif
pour le prédicat suivant le dot dans un item actif :
[A(...) ? ? •B(x1...y1, ..., xk...yk)?, ??, C?]
[B, ???, C ??, p]
où ??(i).l = ?(?(xi)).l, ??(i).r = ?(?(yi)).r pour tout 1 ≤ i ≤ k et C ? = {c | c ? C, c ne
contient que des variables d’intervalles de ??}. L’opération lecture peut être appliquée si un
prédicat prédit peut être dérivé par une ?-clause :
[A, ??, C?, p]
[A, ?, c]
s’il existe une clause A(~x)? ? avec une instanciation possible ? qui satisfasse ??, C? telle que
?(A(~x)) = A(?).
Finalement, les règles de complétion, de conversion sont celles de l’algorithme CYK avec
items actifs à ceci près que nous ajoutons des flags c aux items passifs apparaissant dans ces
règles. L’item but est le même que précédemment. La Fig. 2 illustre cet algorithme avec la RCG
et la chaîne d’entrée définies dans l’exemple de la Fig. 1.
Correction et complétude Il est aisé de constater que l’algorithme de type Earley est à la fois
correct et complet. Plus précisément, si un item complété est généré, alors le prédicat corres-
pondant peut être dérivé : [A,?, c] ? A(?). De plus, si on peut dériver un constituant A(?),
alors on peut également générer l’item correspondant. Soit ? une chaîne de prédicats instan-
ciés. Alors S(?0, n?) ??l A(?)?
?
?l ? ssi [A,?, c] où
?
?l signifie “dérivation plus à gauche”.
En particulier, [S, (?0, n?), c] ssi S(?0, n?) ?? ?.
Un Algorithme d’Analyse de Type Earley pour Grammaires à Concaténation d’Intervalles
Item Opération
1 [S, ?(?r1, r2?), {0 = r1, r1 ≤ r2, 2 = r2}?, p] initialisation
2 [S(XY ) ? •S(X)eq(X,Y ), {X.l ≤ X.r,X.r = Y.l, Y.l ≤ Y.r, 0 = X.l, 2 = Y.r}] prédiction-règle de 1
3 [S, ?(?r1, r2?), {0 = r1, r1 ≤ r2}?, p] prédiction-pred de 2
4 [S, (?0, 1?), c] lecture de 3
5 [S(XY ) ? •S(X)eq(X,Y ), {X.l ≤ X.r,X.r = Y.l, Y.l ≤ Y.r, 0 = X.l, }] prédiction-règle de 3
6 [S(XY ) ? S(X) • eq(X,Y ), {. . . , 0 = X.l, 2 = Y.r, 1 = X.r}] complét. de 2 avec 4
7 [S(XY ) ? S(X) • eq(X,Y ), {X.l ≤ X.r,X.r = Y.l, Y.l ≤ Y.r, 0 = X.l, 1 = X.r}]complét. de 5 avec 4
8 [eq, ?(?r1, r2?, ?r3, r4?), {r1 ≤ r2, r2 = r3, r3 ≤ r4, 0 = r1, 2 = r4, 1 = r2}?] prédiction-pred de 6
9 [eq(a1X, a2Y ) ? •eq(X,Y ), {a1.l + 1 = a1.r, a1.r = X.l,X.l ≤ X.r,
a2.l + 1 = a2.r, a2.r = Y.l, Y.l ≤ Y.r,X.r = a2.l, 0 = a1.l, 1 = X.r, 2 = Y.r}] prédiction-règle de 8
. . .
10 [eq, (?0, 1?, ?1, 2?), c] lecture 8
11 [S(XY ) ? S(X)eq(X,Y )•, {. . . , 0 = X.l, 2 = Y.r, 1 = X.r, 1 = Y.l}] complét. de 6 avec 10
12 [S, (?0, 2?), c] conversion 11
FIG. 2 – Trace d’une analyse de type Earley pour la chaîne aa.
Obtenir une forêt d’analyse Jusqu’ici, nous avons décrit des reconnaisseurs et non des ana-
lyseurs. Cependant, chaque fois qu’une conversion est réalisée, une clause complètement ins-
tanciée a été trouvée. En collectant ces clauses, nous obtenons une représentation compacte de
la forêt. En partant d’un prédicat S couvrant toute la chaîne d’entrée, nous pouvons extraire
directement les analyses de cette représentation.
Complexité Il est clair que tous les algorithmes présentés ici sont polynômiaux par rapport à
la taille de la chaîne d’entrée. Un grand facteur de complexité avec RCG, comme l’a montré
Boullier (2000), est le nombre maximal de variables d’intervalles apparaissant dans un argument
d’un prédicat. Dans notre approche à la Earley, nous essayons de retarder au maximum le calcul
des valeurs que ces intervalles peuvent prendre, afin de réduire l’espace de recherche. Afin
d’avoir une idée de l’efficacité de notre approche, nous donnons une évaluation du coût relatif
des algorithmes directionnel descendant et de type Earley. Ces algorithmes ont été testés sur
différents mots du langage L = {a2n |n ≤ 0}. La table ci-dessous donne le nombre d’items
générés. Nous constatons que la propagation de contraintes d’intervalles augmente la quantité
d’information transportée dans un item, et ainsi diminue grandement le nombre d’items.3
Mots Earley Descendant Mots Earley Descendant
a2 15 21 a16 100 539
a8 55 164 a32 185 1894
6 Conclusion
Nous avons présenté différents algorithmes d’analyse pour la classe entière des RCGs, au moyen
du paradigme de l’analyse par déduction. Seul l’algorithme descendant directionnel avait été
présenté jusqu’alors. La différence cruciale entre cet algorithme et notre algorithme de type
Earley est que, alors que le premier calcule toutes les instanciations de clause lors des opérations
de prédiction, le second évite cela en utilisant une technique de mise à jour dynamique d’un
ensemble de contraintes sur les extrémités des intervalles. Les expériences menées montrent
que l’algorithme de type Earley génère bien moins d’items, ce qui confirme que la propagation
de contraintes d’intervalles est une méthode viable pour un calcul paresseux des intervalles.
3Bien entendu, la présence de contraintes rend la comparaison entre items plus complexe, nécessitant ainsi
l’utilisation de représentations de bas niveau et de techniques efficaces de résolution de contraintes.
Laura Kallmeyer, Wolfgang Maier et Yannick Parmentier
Références
BARTHÉLEMY F., BOULLIER P., DESCHAMP P. & DE LA CLERGERIE É. (2001). Guided
parsing of Range Concatenation Languages. In Proceedings of the 39th Annual Meeting on
Association for Computational Linguistics, p. 42–49.
BECKER T., RAMBOW O. & NIV M. (1992). The Derivationel Generative Power of For-
mal Systems or Scrambling is Beyond LCFRS. Technical Report IRCS-92-38, Institute for
Research in Cognitive Science, University of Pennsylvania.
BERTSCH E. & NEDERHOF M.-J. (2001). On the complexity of some extensions of RCG
parsing. In Proceedings of the Seventh International Workshop on Parsing Technologies, p.
66–77, Beijing, China.
BOULLIER P. (1998). Proposal for a Natural Language Processing Syntactic Backbone. Rap-
port de Recherche RR-3342, Institut National de Recherche en Informatique et en Automa-
tique, Le Chesnay, France.
BOULLIER P. (1999). Chinese numbers, mix, scrambling, and range concatenation grammars.
In Proceedings of the 9th Conference of the European Chapter of the Association for Compu-
tational Linguistics (EACL’99), p. 53–60, Bergen, Norway.
BOULLIER P. (2000). Range concatenation grammars. In Proceedings of the Sixth Internatio-
nal Workshop on Parsing Technologies (IWPT 2000), p. 53–64, Trento, Italy.
BURDEN H. & LJUNGLÖF P. (2005). Parsing linear context-free rewriting systems. In Pro-
ceedings of the Ninth International Workshop on Parsing Technology, p. 11–17, Vancouver,
British Columbia.
KANAZAWA M. (2008). A prefix-correct earley recognizer for multiple context-free gram-
mars. In Proceedings of the Ninth International Workshop on Tree Adjoining Grammars and
Related Formalisms (TAG+9), p. 49–56, Tübingen, Germany.
MAIER W. & SØGAARD A. (2008). Treebanks and mild context-sensitivity. In Proceedings
of the 13th Conference on Formal Grammar 2008, Hamburg, Germany.
MICHAELIS J. & KRACHT M. (1996). Semilinearity as a Syntactic Invariant. In Logical
Aspects of Computational Linguistics, Nancy.
RADZINSKI D. (1991). Chinese number-names, tree adjoining languages, and mild context-
sensitivity. Computational Linguistics, 17, 277–299.
SAGOT B. (2005). Linguistic facts as predicates over ranges of the sentence. In Proceedings of
LACL 05, number 3492 in Lecture Notes in Computer Science, p. 271–286, Bordeaux, France.
SEKI H., MATSUMURA T., FUJII M. & KASAMI T. (1991). On multiple context-free gram-
mars. Theoretical Computer Science, 88, 191–229.
SHIEBER S. M., SCHABES Y. & PEREIRA F. C. N. (1995). Principles and implementation
of deductive parsing. Journal of Logic Programming, 24(1& 2), 3–36.
SØGAARD A. (2008). Range concatenation grammars for translation. In Proceedings of the
22nd International Conference on Computational Linguistics, Manchester, England.
VILLEMONTE DE LA CLERGERIE E. (2002). Parsing mildly context-sensitive languages with
thread automata. In Proceedings of the 19th International Conference on Computational Lin-
guistics, p. 1–7, Taipei, Taiwan.
WEIR D. J. (1988). Characterizing mildly context-sensitive grammar formalisms. PhD thesis,
University of Pennsylvania, Philadelphia, PA.
