<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Un nouveau sch&#233;ma de pond&#233;ration pour la cat&#233;gorisation de documents manuscrits</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009 &#8211; Session posters , Senlis, 24&#8211;26 juin 2009
</p>
<p>Un nouveau sch&#233;ma de pond&#233;ration pour la cat&#233;gorisation de
documents manuscrits
</p>
<p>Sebasti&#225;n Pe&#241;a Saldarriaga1 Emmanuel Morin1 Christian Viard-Gaudin2
</p>
<p>(1) LINA - UMR CNRS 6241, Universit&#233; de Nantes
(2) IRCCyN - UMR CNRS 6597, Universit&#233; de Nantes
</p>
<p>{Pr&#233;nom.Nom}@univ-nantes.fr
</p>
<p>R&#233;sum&#233;. Les sch&#233;mas de pond&#233;ration utilis&#233;s habituellement en cat&#233;gorisation de textes,
et plus g&#233;n&#233;ralement en recherche d&#8217;information (RI), ne sont pas adapt&#233;s &#224; l&#8217;utilisation de
donn&#233;es li&#233;es &#224; des textes issus d&#8217;un processus de reconnaissance de l&#8217;&#233;criture. En particulier,
les candidats-mot &#224; la reconnaissance ne pourraient &#234;tre exploit&#233;s sans introduire de fausses
occurrences de termes dans le document. Dans cet article nous pr&#233;sentons un nouveau sch&#233;ma
de pond&#233;ration permettant d&#8217;exploiter les listes de candidats-mot. Il permet d&#8217;estimer le pouvoir
discriminant d&#8217;un terme en fonction de la probabilit&#233; a posteriori d&#8217;un candidat-mot dans une
liste de candidats. Les r&#233;sultats montrent que le taux de classification de documents fortement
d&#233;grad&#233;s peut &#234;tre am&#233;lior&#233; en utilisant le sch&#233;ma propos&#233;.
</p>
<p>Abstract. The traditional weighting schemes used in information retrieval, and especially
in text categorization cannot exploit information intrinsic to texts obtained through an on-line
handwriting recognition process. In particular, top n (n &gt; 1) candidates could not be used
without introducing false occurrences of spurious terms thus making the resulting text noisier.
In this paper, we propose an improved weighting scheme for text categorization, that estimates
a term importance from the posterior probabilities of the top n candidates. The experimental
results show that the categorization rate of poorly recognized texts increases when our weighting
model is applied.
</p>
<p>Mots-cl&#233;s : Cat&#233;gorisation de textes, &#233;criture en-ligne, n-best candidats, pond&#233;ration.
</p>
<p>Keywords: Text categorization, on-line handwriting, n-best candidates, weighting.
</p>
<p>1 Introduction
</p>
<p>Les avanc&#233;es dans le domaine de la reconnaissance de l&#8217;&#233;criture en-ligne permettent de pro-
duire, &#224; partir d&#8217;un signal manuscrit, des textes en langue naturelle. Il devient alors possible
d&#8217;appliquer des technologies de gestion du contenu normalement utilis&#233;es pour des textes &#233;lec-
troniques tels que pages web et e-mails (Vinciarelli, 2006). Cependant, l&#8217;exploitation des don-
n&#233;es issues de la reconnaissance n&#8217;est pas aussi simple qu&#8217;il y para&#238;t. En effet, les transcriptions
sont souvent bruit&#233;es, c&#8217;est-&#224;-dire qu&#8217;elles contiennent des suppressions, insertions et rempla-
cements de mots par rapport au texte correspondant r&#233;ellement au signal manuscrit.
</p>
<p>La cat&#233;gorisation automatique de textes est une probl&#233;matique classique en intelligence arti-
ficielle li&#233;e au traitement automatique des langues. Toutefois, ce domaine n&#8217;a &#233;t&#233; explor&#233; de</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Pe&#241;a Saldarriaga et al.
</p>
<p>fa&#231;on approfondie que pour les documents &#233;lectroniques (Sebastiani, 2002), et peu de travaux
existent sur la cat&#233;gorisation de documents manuscrits. Des travaux r&#233;cents se sont int&#233;ress&#233;s &#224;
cette probl&#233;matique (Vinciarelli, 2005; Pe&#241;a Saldarriaga et al., 2009) et ont mis en &#233;vidence une
diff&#233;rence, pouvant &#234;tre significative, entre les r&#233;sultats obtenus avec les donn&#233;es manuscrites et
les textes &#233;lectroniques originaux. L&#8217;ampleur de cette diff&#233;rence d&#233;pend de la quantit&#233; de bruit
existant dans les documents issus du processus de reconnaissance de l&#8217;&#233;criture.
</p>
<p>Mais, si un syst&#232;me de reconnaissance induit du bruit dans les transcriptions qu&#8217;il produit, il
peut &#233;galement estimer la qualit&#233; du texte en sortie. En particulier, une probabilit&#233; peut &#234;tre
associ&#233;e &#224; chacun des mots du texte. De plus, une liste de candidats-mot &#224; la reconnaissance
peut &#233;galement &#234;tre obtenue comme le montre la figure 1.
</p>
<p>(1) NOTE i per-shone ameunts adjusted
</p>
<p>(2) VIOTE is per-share amounts adjured
</p>
<p>(3) ulotE ; pen-shane remounts abjured
</p>
<p>FIGURE 1 &#8211; Reconnaissance avec 3 candidats-mots
</p>
<p>Nous pensons que l&#8217;utilisation de ces candidats-mot pour la cat&#233;gorisation peut aider &#224; r&#233;duire
la diff&#233;rence de performances observ&#233;e dans les travaux pr&#233;cit&#233;s. Le travail propos&#233; ici a pour
but d&#8217;apporter une fonctionnalit&#233; de cat&#233;gorisation en utilisant les listes successives de n-best
candidats-mots &#224; la reconnaissance, l&#224; o&#249; les approches explor&#233;es jusqu&#8217;ici se contentent d&#8217;uti-
liser la s&#233;quence de mots la plus probable donn&#233;e par le syst&#232;me de reconnaissance, contenant
la plupart du temps le candidat-mot arriv&#233; en t&#234;te de la liste.
</p>
<p>Cependant, si l&#8217;utilisation des n-best candidats peut permettre de conserver l&#8217;information cor-
respondant &#224; un terme qui ne serait pas arriv&#233; en premi&#232;re position, elle introduit &#233;galement de
fausses apparitions de mots avec un poids &#233;gal : le contenu du document s&#8217;en trouve alt&#233;r&#233; et
la cat&#233;gorisation aussi. Afin de r&#233;duire l&#8217;impact de ces fausses apparitions, il faut red&#233;finir les
sch&#233;mas de pond&#233;ration classiques utilis&#233;s avec le formalisme vectoriel de repr&#233;sentation des
donn&#233;es (Salton et al., 1975), en nous basant sur la probabilit&#233; associ&#233;e &#224; chaque candidat-mot.
De plus il serait convenable d&#8217;ajuster dynamiquement le nombre de candidats-mot, en seuillant
sur la valeur des probabilit&#233;s, limitant ainsi l&#8217;incidence des candidats tr&#232;s peu probables.
</p>
<p>La section 2 s&#8217;attache &#224; introduire la probl&#233;matique de la reconnaissance de l&#8217;&#233;criture en-
ligne. Nous y d&#233;crivons &#233;galement le moteur de reconnaissance utilis&#233; et les ressources lin-
guistiques qui lui sont associ&#233;es. Le nouveau sch&#233;ma de pond&#233;ration bas&#233; sur les probabilit&#233;s
des candidats-mot est pr&#233;sent&#233; dans la section 3. Afin de montrer l&#8217;int&#233;r&#234;t du sch&#233;ma de pond&#233;-
ration propos&#233;, nous d&#233;crivons en section 4 les exp&#233;riences r&#233;alis&#233;es sur une base de documents
reproduisant sous forme manuscrite les d&#233;p&#234;ches de l&#8217;agence Reuters bien connues dans le do-
maine de la cat&#233;gorisation de textes (Debole &amp; Sebastiani, 2005). Enfin, dans la section 5, nous
concluons en &#233;voquant les perspectives de ce travail.
</p>
<p>2 Reconnaissance et &#233;criture en-ligne
</p>
<p>Souvent cantonn&#233;e &#224; la saisie sur des terminaux de petite taille (PDA, smartphone), l&#8217;&#233;criture
en-ligne devient aujourd&#8217;hui une nouvelle source d&#8217;information en langue naturelle. Cela r&#233;sulte</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Pond&#233;ration pour la cat&#233;gorisation de documents manuscrits
</p>
<p>de l&#8217;&#233;mergence des dispositifs de saisie que sont les stylos &#233;lectroniques coupl&#233;s &#224; des supports
papier. Ils permettent de produire des v&#233;ritables documents de diverses natures : notes de cours,
copies d&#8217;examens, articles, formulaires, etc.
</p>
<p>Dans le domaine de l&#8217;&#233;criture en-ligne, un document se pr&#233;sente sous la forme d&#8217;une s&#233;quence
de points ordonn&#233;s dans le temps (x(t), y(t)). Le trac&#233; correspond &#224; la trajectoire &#233;chantillonn&#233;e
de l&#8217;instrument d&#8217;&#233;criture, chaque point &#233;tant une position o&#249; le crayon s&#8217;est trouv&#233; pos&#233; (cf.
figure 2).
</p>
<p>17
</p>
<p>utilis&#233; dans la reconnaissance d&#8217;adresse sur les enveloppes. Un exemple des deux types de
donn&#233;e est pr&#233;sent&#233; en figure 3.1.
</p>
<p>FIG. 3.1 &#8211; &#201;criture en-ligne et hors-ligne
</p>
<p>La reconnaissance en-ligne apporte beaucoup plus d&#8217;informations que l&#8217;approche hors-
ligne, mais n&#8217;est pas forc&#233;ment accessible dans toutes les applications. Cette &#233;tude utilise
exclusivement la reconnaissance en-ligne qui est la seule support&#233;e par l&#8217;environnement
de d&#233;veloppement et qui est le support des MIMEMA.
</p>
<p>3.3 Support de l&#8217;&#233;criture
</p>
<p>Pour cette &#233;tude nous avons utilis&#233; des stylos num&#233;riques et du papier type Anoto. Le
papier est pr&#233;-imprim&#233; de points judicieusement plac&#233;s permettant un rep&#233;rage absolu et
pr&#233;cis du stylo sur la feuille. Le stylo est muni d&#8217;une cam&#233;ra infrarouge captant plusieurs
points en m&#234;me temps, mais aussi d&#8217;une pointe &#224; bille classique pour aider le scripteur
&#224; suivre le fil de son &#233;criture (ce qui n&#8217;est pas le cas avec une tablette graphique). Le
processeur du stylo, en combinant les coordonn&#233;es des diff&#233;rents points capt&#233;s est capable
de calculer sa position sur la feuille. En effectuant un &#233;chantillonnage r&#233;gulier, il enregistre
son trajet sur la feuille. Les lev&#233;s et pos&#233;s de stylo sont &#233;galement stock&#233;s.
</p>
<p>3.4 &#201;tapes de la reconnaissance avec MyScript Builder
</p>
<p>Dans MyScript Builder, la reconnaissance de formes s&#8217;effectue &#224; l&#8217;aide de trois experts
logiciels travaillant de concert, se concentrant respectivement sur la segmentation, l&#8217;&#233;cri-
ture et le langage. Nous pr&#233;sentons par la suite rapidement leur r&#244;le sans toutefois rentrer
dans les d&#233;tails puisque nous n&#8217;intervenons pas dans le processus &#224; ce niveau, mais uni-
quement d&#8217;un point de vue linguistique.
</p>
<p>3.4.1 Segmentation
</p>
<p>La segmentation est importante puisqu&#8217;une mauvaise segmentation conduira n&#233;cessai-
rement &#224; une reconnaissance erron&#233;e.
</p>
<p>Pour segmenter un &#233;chantillon d&#8217;&#233;criture manuscrite, l&#8217;expert le d&#233;coupe d&#8217;abord en
graph&#232;mes (fig. 3.2), c&#8217;est-&#224;-dire en unit&#233;s graphiques minimales puis les rassemble pour
</p>
<p>FIGURE 2 &#8211; Exemple de trac&#233; en-ligne pour la lettre i
</p>
<p>L&#8217;objectif de la reconnaissance en-ligne est de d&#233;terminer la suite de caract&#232;res la plus vraisem-
blable &#233;tant donn&#233; le signal correspondant au trac&#233; manuscrit &#224; l&#8217;aide d&#8217;informations fourni s
par un ensemble de connaissances a priori sur la langue (Perraud et al., 2005).
</p>
<p>Dans le cadre de cette &#233;tude, nous avons privil&#233;gi&#233; l&#8217;utilisation d&#8217;un moteur de reconnaissance
stable et pr&#234;t &#224; l&#8217;emploi : My cript Builder 1. Ce moteur de reconnaissance permet d&#8217;associer
diff&#233;rentes ressources linguistiques afin de guider et d&#8217;optimiser la reconnaissance (cf. figure 3).
</p>
<p>MyScript Builder Handwriti g
</p>
<p>Ressources Linguistiques
</p>
<p>Entr&#233;e Sortie
</p>
<p>FIGURE 3 &#8211; Reconnaissance avec MyScript Builder SDK
</p>
<p>Il est possible de d&#233;finir des resso rces sp&#233;cifiques, oit sous forme de lexiques ou encore d&#8217;au-
tomates lexicaux, ou bien d&#8217;utiliser les deux ressources standard livr&#233;es avec MyScript Builder :
</p>
<p>&#8211; lk-text est une ressource constitu&#233;e d&#8217;un lexique standard et d&#8217;un mod&#232;le statistique du lan-
gage au niveau mot. Ce dernier permet de favoriser la reconnaissance des s&#233;quences de mots
les plus probables. Ainsi, &#8216;je tue&#8217; sera priorit ire par rappo t &#224; &#8216;je tu&#8217;. Cette ressour e rmet
&#233;galement de reconna&#238;tre des &#233;l&#233;ments hors-lexique comme les dates, les codes postaux, etc.
</p>
<p>&#8211; lk-free apporte peu de contraintes sur ce que l&#8217;on veut reconna&#238;tre. Il n&#8217;y pas de lexique mais
seulement un mod&#232;le de langage au niveau caract&#232;re. Cette ressource permet de favoriser les
s&#233;quences de caract&#232;res les plus vraisemblables, par exemple &#8216;MATIN&#8217; sera prioritaire par
rapport &#224; &#8216;MAT1N&#8217;.
</p>
<p>1. http://www.visionobjects.com/products/software-development-kits/
myscript-builder/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Pe&#241;a Saldarriaga et al.
</p>
<p>2.1 &#201;valuation de la reconnaissance
</p>
<p>Le bruit induit par la reconnaissance est souvent mesur&#233; au niveau des mots. Le taux d&#8217;erreur
au niveau mot ou Word Error Rate (WER) correspond au pourcentage de mots mal reconnus
sur la totalit&#233; de mots &#224; reconna&#238;tre pour une s&#233;quence donn&#233;e :
</p>
<p>WER = 1&#8722;
&#8721;N
</p>
<p>i min (wf(i), wf
&#8242;(i))&#8721;N
</p>
<p>i wf(i)
(1)
</p>
<p>Avec wf(i) and wf &#8242;(i) les fr&#233;quences du mot i dans le texte d&#8217;origine et le texte reconnu
respectivement, et N le nombre de mots &#224; reconna&#238;tre.
</p>
<p>Une autre fa&#231;on de mesurer le bruit, est de travailler au niveau terme. Le taux d&#8217;erreur au
niveau terme ou Term Error Rate (TER) est plus adapt&#233; &#224; la cat&#233;gorisation car il tient compte
de la normalisation de textes (cf. section 4.1). Puisque &#8216;r&#234;vas&#8217; et &#8216;r&#234;ves&#8217; ont la m&#234;me racine,
reconna&#238;tre l&#8217;un &#224; la place de l&#8217;autre ne modifie pas la liste de termes reconnus. Reconna&#238;tre
&#8216;pour&#8217; &#224; la place de &#8216;par&#8217; ne la modifie pas non plus, car quelque soit le mot reconnu, il sera
filtr&#233; puisque c&#8217;est un mot outil.
</p>
<p>Le TER est calcul&#233; gr&#226;ce &#224; la formule suivante (Vinciarelli, 2005) :
</p>
<p>TER = 1&#8722;
&#8721;N
</p>
<p>i min (tf(i), tf
&#8242;(i))&#8721;N
</p>
<p>i tf(i)
(2)
</p>
<p>Avec tf(i) and tf &#8242;(i) les fr&#233;quences du terme i dans le texte d&#8217;origine et le texte reconnu
respectivement, et N le nombre de termes de r&#233;f&#233;rence.
</p>
<p>Dans nos exp&#233;riences, nous utilisons ces deux mesures comme indicateurs de la qualit&#233; des do-
cuments produits en fonction de la ressource linguistique associ&#233;e au moteur de reconnaissance.
</p>
<p>3 Pond&#233;ration et seuillage de candidats-termes
</p>
<p>La mauvaise reconnaissance des documents engendre une cat&#233;gorisation moins bonne (Vincia-
relli, 2005; Pe&#241;a Saldarriaga et al., 2009). En effet, suite &#224; la reconnaissance, un terme pertinent
peut ne pas se trouver dans un document alors qu&#8217;il aurait d&#251; y &#234;tre. Or, les occurrences des
termes sont au coeur de la r&#233;ussite des algorithmes de cat&#233;gorisation, et ce d&#8217;autant plus qu&#8217;ils
utilisent le formalisme vectoriel et des sch&#233;mas de pond&#233;ration comme tf &#215; idf (Sp&#228;rck Jones,
1979). L&#8217;utilisation des n-best candidats-mot peut permettre de capturer l&#8217;information corres-
pondant &#224; un terme qui ne serait pas arriv&#233; en premi&#232;re position. En effet, plus la liste de n-best
est grande, plus le mot attendu a des chances de s&#8217;y trouver. Cependant, l&#8217;introduction artifi-
cielle de mots fausserait les r&#233;sultats d&#8217;un algorithme de cat&#233;gorisation. Dans ce contexte nous
red&#233;finissons la pond&#233;ration tf &#215; idf pour tenir compte des probabilit&#233;s des candidats des dif-
f&#233;rentes listes de n-best. Dans un second temps, une strat&#233;gie de seuillage est propos&#233;e afin de
filtrer des candidats tr&#232;s peu probables.
</p>
<p>3.1 Pond&#233;ration
</p>
<p>Dans la suite de ce document nous consid&#233;rons qu&#8217;un candidat-terme est simplement l&#8217;entit&#233;
repr&#233;sentative du sens d&#8217;un candidat-mot dans l&#8217;espace vectoriel. Autrement dit, il s&#8217;agit de la</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Pond&#233;ration pour la cat&#233;gorisation de documents manuscrits
</p>
<p>racine (Porter, 1980) ou du lemme (Namer, 2000) d&#8217;un candidat-mot.
</p>
<p>D&#233;finition 1 Fr&#233;quence d&#8217;un candidat-terme
</p>
<p>Soit pn(i) la probabilit&#233; d&#8217;un candidat-terme i dans la n-i&#232;me liste de candidats, et N le
nombre de listes de candidats-terme dans lesquels i appara&#238;t au sein d&#8217;un document. La fr&#233;-
quence du candidat-terme i est donn&#233;e par la formule suivante :
</p>
<p>ctf(i) =
N&#8721;
n=1
</p>
<p>pn(i) (3)
</p>
<p>Nous pouvons multiplier la fr&#233;quence ainsi obtenue par le facteur idf classique pour obtenir
une mesure ctf &#215; idf adapt&#233;e &#224; l&#8217;exploitation des listes de candidats-mots.
</p>
<p>D&#233;finition 2 Mesure candidate-tf &#215; idf
Soit K le nombre de documents dans un corpus, et ki le nombre de documents dans lesquels
le candidat-terme i appara&#238;t au moins une fois. La pond&#233;ration ctf &#215; idf peut &#234;tre calcul&#233;e
gr&#226;ce &#224; la formule suivante :
</p>
<p>ctf.idf(i) = ctf(i)&#215; log K
ki
</p>
<p>(4)
</p>
<p>Afin de r&#233;duire les effets engendr&#233;s par les diff&#233;rences de longueurs des documents, il convient
de normaliser cette mesure, en particulier lorsqu&#8217;elle est utilis&#233;e avec des approches &#224; base de
distances ou mesures de similarit&#233;.
</p>
<p>D&#233;finition 3 Mesure candidate-tf &#215; idf normalis&#233;e
Soit M le nombre de termes de l&#8217;espace de repr&#233;sentation vectorielle et i un candidat-terme
donn&#233;. La mesure ctf &#215; idf normalis&#233;e est donn&#233;e par la formule suivante :
</p>
<p>nctf.idf(i) =
ctf(i)&#215; log K
</p>
<p>ki&#8730;&#8721;M
j=1(ctf(j)&#215; log Kkj )2
</p>
<p>(5)
</p>
<p>La d&#233;finition de ce nouveau sch&#233;ma de pond&#233;ration va permettre de calculer facilement le poids
d&#8217;un candidat-terme i dans un vecteur. Des m&#233;thodes de cat&#233;gorisation standard ou des syst&#232;mes
existants (Pe&#241;a Saldarriaga et al., 2009) peuvent alors &#234;tre utilis&#233;s sans modification majeure.
</p>
<p>3.2 Seuillage
</p>
<p>Le but de la strat&#233;gie de seuillage propos&#233;e ci-dessous est d&#8217;ajuster dynamiquement la taille des
listes de candidats. Nous supposons que la liste de n-best candidats est tri&#233;e par ordre d&#233;croissant
probabilit&#233; et que
</p>
<p>&#8721;n
i=0 p(i) = 1 avec n le nombre de candidats dans la liste et p(i) la probabilit&#233;
</p>
<p>d&#8217;un candidat-terme i. Nous cherchons &#224; trouver les k (k &lt; n) premiers candidats tels que&#8721;k
j=0 p(j) &#8776; t, 0 &lt; t &#8804; 1 o&#249; t est le seuil d&#233;sir&#233;. La figure 4 montre le comportement de notre
</p>
<p>strat&#233;gie de seuillage pour t = 0, 8 et diff&#233;rentes listes de n-best candidats.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Pe&#241;a Saldarriaga et al.
</p>
<p>exchequer 0, 61
</p>
<p>exoneration 0, 22
</p>
<p>exonerator 0, 11
</p>
<p>excheqwr 0, 04
</p>
<p>exchcqwr 0, 02
</p>
<p>implication 0, 54
</p>
<p>implications 0, 14
</p>
<p>imputation 0, 12
</p>
<p>imprecation 0, 11
</p>
<p>implicated 0, 09
</p>
<p>fuel 0, 23
</p>
<p>gull 0, 21
</p>
<p>gulf 0, 19
</p>
<p>full 0, 19
</p>
<p>cruel 0, 18
</p>
<p>FIGURE 4 &#8211; Exemple de seuillage sur diff&#233;rentes listes de candidats
</p>
<p>4 Exp&#233;riences
</p>
<p>Afin de valider le nouveau sch&#233;ma de pond&#233;ration, nous avons men&#233; plusieurs exp&#233;riences sur
le corpus pr&#233;sent&#233; ci-dessous. En premier lieu, nous avons effectu&#233; la reconnaissance des docu-
ments manuscrits et observ&#233; l&#8217;&#233;volution des taux d&#8217;erreur en fonction du nombre de candidats-
mot accept&#233;s. Ensuite, nous avons cat&#233;goris&#233; les documents en utilisant la sortie standard du
syst&#232;me de reconnaissance ainsi que la sortie comportant des listes de candidats-mot &#224; la recon-
naissance. Les r&#233;sultats de ces exp&#233;riences sont pr&#233;sent&#233;s et comment&#233;s dans les sous-sections
4.2 et suivantes.
</p>
<p>4.1 Donn&#233;es et param&#232;tres exp&#233;rimentaux
</p>
<p>Pour la r&#233;alisation des exp&#233;riences, nous avons utilis&#233; un jeu de donn&#233;es compos&#233; de 2 029 d&#233;-
p&#234;ches du corpus Reuters-21578 reproduites sous forme manuscrite et r&#233;parties sur 10 classes.
L&#8217;ensemble d&#8217;entra&#238;nement est constitu&#233; de 1 625 documents et celui de test de 404 d&#233;p&#234;ches.
La partition en ensembles d&#8217;entra&#238;nement et de test suit le protocole ModApt&#233; (Apt&#233; et al.,
1994). Les donn&#233;es sont mono-cat&#233;gorie, c&#8217;est-&#224;-dire que les documents n&#8217;appartiennent qu&#8217;&#224;
une seule classe. La figure 5 montre un exemple de document manuscrit de notre base.
</p>
<p>FIGURE 5 &#8211; Document du corpus manuscrit
</p>
<p>Nous avons choisi d&#8217;utiliser deux m&#233;thodes de cat&#233;gorisation simples mais performantes. Il
s&#8217;agit de la m&#233;thode des k-Plus Proches Voisins (kPPV) et des S&#233;parateurs &#224; Vaste Marge
(SVM) (Vapnik, 1995), ces deux approches &#233;tant reconnues parmi les approches les plus per-
formantes d&#233;velopp&#233;es durant la d&#233;cennie (Yang &amp; Liu, 1999; Joachims, 2002; Debole &amp; Se-
bastiani, 2005).
</p>
<p>Avant l&#8217;application de ces algorithmes, une &#233;tape de normalisation a lieu. Elle consiste &#224; seg-
menter les textes en occurrences de forme, filtrer les mots outils et appliquer l&#8217;algorithme de
racinisation de Porter (1980). Durant la phase d&#8217;entra&#238;nement, l&#8217;ensemble des termes de l&#8217;espace
de repr&#233;sentation des documents est choisi en utilisant la statistique du &#967;2 (Yang &amp; Pedersen,
1997) coupl&#233;e &#224; l&#8217;algorithme de Forman (2004).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Pond&#233;ration pour la cat&#233;gorisation de documents manuscrits
</p>
<p>L&#8217;&#233;valuation du syst&#232;me se fait sur la base du document, c&#8217;est-&#224;-dire en utilisant la micro-
moyenne de la pr&#233;cision et du rappel. Comme les donn&#233;es sont mono-cat&#233;gorie, sans rejet,
la pr&#233;cision et le rappel inter-classes sont &#233;gaux (Beney, 2008). De ce fait, nous donnerons
une seule mesure de la qualit&#233; d&#8217;un classifieur que nous appellerons taux de classification,
correspondant &#224; la micro-moyenne de la pr&#233;cision ou le rappel.
</p>
<p>4.2 Reconnaissance
</p>
<p>Les documents du corpus manuscrit sont reconnus en utilisant les deux ressources d&#233;crites
pr&#233;c&#233;demment : lk-text et lk-free. La figure 6 montre l&#8217;&#233;volution du WER et du TER en fonction
du nombre de candidats-mot.
</p>
<p>Les textes reconnus avec la ressource lk-free sont fortement degrad&#233;s. En effet plus d&#8217;un mot sur
deux est perdu en moyenne, alors qu&#8217;avec lk-text 77% des mots et autant de termes pr&#233;sents dans
les textes sont correctement reconnus. Introduire des mod&#232;les de langage permet d&#8217;am&#233;liorer
consid&#233;rablement le taux d&#8217;erreur (Perraud et al., 2005). Quand il n&#8217;y a pas d&#8217;a priori apport&#233;
par un tel mod&#232;le, comme c&#8217;est le cas de la ressource lk-free les performances d&#8217;un syst&#232;me de
reconnaissance sont tr&#232;s mauvaises.
</p>
<p>Nous observons &#233;galement que plus la liste de candidats-mots est grande, plus le terme attendu
a des chances de s&#8217;y trouver, le taux d&#8217;erreur s&#8217;en trouve alors diminu&#233; comme le montre la
figure 6.
</p>
<p>1 2 3 4 5 10 15
10 %
</p>
<p>20 %
</p>
<p>30 %
</p>
<p>40 %
</p>
<p>50 %
</p>
<p>60 %
</p>
<p>Nombre de candidats-mot (n)
</p>
<p>Ta
ux
</p>
<p>d&#8217;
er
</p>
<p>re
ur
</p>
<p>lk-text/WER lk-text/TER
lk-free/WER lk-free/TER
</p>
<p>FIGURE 6 &#8211; Taux d&#8217;erreur en fonction du
nombre de candidats-mot
</p>
<p>1 2 3 4 5 10 15
</p>
<p>80%
</p>
<p>85%
</p>
<p>90%
</p>
<p>Nombre de candidats-mot (n)
</p>
<p>Ta
ux
</p>
<p>de
cl
</p>
<p>as
si
</p>
<p>fic
at
</p>
<p>io
n
</p>
<p>svm/lk-text kppv/lk-text
svm/lk-free kppv/lk-free
</p>
<p>FIGURE 7 &#8211; Taux de classification en fonc-
tion du nombre de candidats
</p>
<p>4.3 Cat&#233;gorisation
</p>
<p>La cat&#233;gorisation des 404 documents d&#8217;&#233;valuation a &#233;t&#233; effectu&#233;e aussi bien sur les documents
issus de la reconnaissance avec un seul ou avec plusieurs candidats-mot.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Pe&#241;a Saldarriaga et al.
</p>
<p>lk-text/n=10 lk-text/n=15 lk-free/n=10 lk-free/n=15
</p>
<p>87%
</p>
<p>88%
</p>
<p>89%
</p>
<p>90%
</p>
<p>Ta
ux
</p>
<p>de
cl
</p>
<p>as
si
</p>
<p>fic
at
</p>
<p>io
n
</p>
<p>sans seuillage t=0,9 t=0,8
</p>
<p>(a) SVM
</p>
<p>lk-text/n=10 lk-text/n=15 lk-free/n=10 lk-free/n=15
</p>
<p>80%
</p>
<p>82%
</p>
<p>84%
</p>
<p>86%
</p>
<p>sans seuillage t=0,9 t=0,8
</p>
<p>(b) kPPV
</p>
<p>FIGURE 8 &#8211; Taux de classification avec seuillage
</p>
<p>Les param&#232;tres des classifieurs ont &#233;t&#233; optimis&#233;s afin d&#8217;obtenir le meilleur taux de classification.
Nous avons utilis&#233; pour cela, un sous-ensemble de l&#8217;ensemble d&#8217;entra&#238;nement reconnu avec un
seul candidat-mot. Les SVM sont utilis&#233;s avec un espace vectoriel de 1000 termes, et les kPPV
avec 300 termes et k = 15.
</p>
<p>La figure 7 montre le taux de classification en fonction de l&#8217;algorithme, de la ressource et du
nombre de candidats-mot utilis&#233;s.
</p>
<p>Lorsque nous utilisons une liste de candidats-terme avec lk-text le taux de classification baisse
avec l&#8217;augmentation du nombre de candidats. En revanche, lorsque les documents de lk-free
sont utilis&#233;s, pour tout n &gt; 1 le taux de classification est sup&#233;rieur &#224; celui obtenu en ne prenant
que le premier candidat. Une augmentation moyenne de 2,1 % avec un &#233;cart-type de 1,2 peut
&#234;tre signal&#233;e et ce, quel que soit le classifieur utilis&#233;.
</p>
<p>Nous avons utilis&#233; la strat&#233;gie de seuillage pr&#233;sent&#233;e en 3.2 pour n = 10 et n = 15, les r&#233;sultats
obtenus en fonction de la valeur du seuil t utilis&#233; sont donn&#233;s par la figure 8. L&#8217;application
du seuillage n&#8217;a pas permis d&#8217;am&#233;liorer, de fa&#231;on g&#233;n&#233;rale, le taux de classification avec la
ressource lk-text. L&#8217;am&#233;lioration observ&#233;e pour les SVM et n = 15 para&#238;t logique : le seuillage
a eu pour effet de r&#233;duire n, le point le plus bas de la courbe svm/lk&#8722;text de la figure 7 va donc
remonter car la courbe d&#233;cro&#238;t de fa&#231;on quasi-monotone en fonction du nombre de candidats.
</p>
<p>Notre strat&#233;gie appara&#238;t plus efficace lorsqu&#8217;elle est appliqu&#233;e avec la ressource lk-free. Avec
SVM et n = 15, une am&#233;lioration importante est observ&#233;e, le taux de classification est m&#234;me
sup&#233;rieur &#224; celui obtenu avec des documents moins d&#233;grad&#233;s (lk-text) dans une configuration
identique. Une l&#233;g&#232;re augmentation avec kPPV et n = 10 se produit &#233;galement, mais ne permet
pas de d&#233;passer les r&#233;sultats obtenus avec les documents de lk-text dans la m&#234;me configuration.
</p>
<p>Nous pouvons observer qu&#8217;un seuil fort (t = 0, 9) permet d&#8217;obtenir des meilleurs r&#233;sultats par
rapport &#224; des seuils plus faibles. Cependant, les seuils utilis&#233;s ont &#233;t&#233; d&#233;finis manuellement et
peuvent ne pas &#234;tre optimaux, ce qui pourrait expliquer en partie les r&#233;sultats de notre strat&#233;gie
de seuillage.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Pond&#233;ration pour la cat&#233;gorisation de documents manuscrits
</p>
<p>5 Conclusion
</p>
<p>Le travail pr&#233;sent&#233; dans cet article d&#233;crit un nouveau sch&#233;ma de pond&#233;ration pour l&#8217;utilisation
des listes de n-best candidats-terme dans un processus de cat&#233;gorisation textuelle de documents
manuscrits en-ligne. Nous pensions que l&#8217;utilisation de ces listes permettrait d&#8217;atteindre un taux
de cat&#233;gorisation sup&#233;rieur &#224; celui obtenu avec juste le premier candidat.
</p>
<p>Notre hypoth&#232;se de d&#233;part n&#8217;est pas enti&#232;rement confirm&#233;e par les r&#233;sultats exp&#233;rimentaux. En
effet, l&#8217;utilisation des candidats-termes n&#8217;a pas permis d&#8217;am&#233;liorer le taux de cat&#233;gorisation des
documents o&#249; environ 77% des termes d&#8217;indexation sont correctement reconnus. En revanche,
l&#8217;utilisation de la liste des n-best mots s&#8217;est r&#233;v&#233;l&#233;e b&#233;n&#233;fique pour des documents o&#249; plus de la
moiti&#233; de l&#8217;information est perdue. Aussi bien avec les kPPV qu&#8217;avec les SVM, une augmenta-
tion moyenne de 2,1 % du taux de cat&#233;gorisation a &#233;t&#233; observ&#233;e.
</p>
<p>La strat&#233;gie de seuillage propos&#233;e ne semble pas suffisante pour limiter l&#8217;influence des candi-
dats tr&#232;s peu probables dans la cat&#233;gorisation des documents de lk-text. Elle a permis cependant
d&#8217;am&#233;liorer les r&#233;sultats obtenus avec lk-free et un nombre de candidats important (n &#8805; 10).
Ces r&#233;sultats apparaissent prometteurs mais une question se pose, comment d&#233;finir le seuil op-
timal ? De nouvelles exp&#233;riences doivent &#234;tres effectu&#233;es afin d&#8217;explorer diff&#233;rentes techniques
d&#8217;estimation de ce seuil (validation crois&#233;e, leave-one-out, m&#233;ta-heuristiques).
</p>
<p>De mani&#232;re g&#233;n&#233;rale, les r&#233;sultats pr&#233;sent&#233;s dans cette contribution montrent que l&#8217;utilisation
des listes de n-best candidats-terme permettent d&#8217;obtenir des niveaux convenables de cat&#233;gori-
sation sur des documents fortement d&#233;grad&#233;s.
</p>
<p>Remerciements
</p>
<p>Ces travaux ont ete soutenus par la R&#233;gion Pays de la Loire &#224; travers le Projet MILES et par
l&#8217;Agence Nationale de la Recherche &#224; travers le programme Technologies Logicielles (ANR-
06-TLOG-009).
</p>
<p>R&#233;f&#233;rences
</p>
<p>APT&#201; C., DAMERAU F. &amp; WEISS S. M. (1994). Towards language independent automated
learning of text categorization models. In Proceedings of the 17th Annual International ACM
SIGIR Conference (SIGIR &#8217;94), p. 23&#8211;30.
</p>
<p>BENEY J. (2008). Classification supervis&#233;e de documents. Herm&#232;s Science / Lavoisier.
</p>
<p>DEBOLE F. &amp; SEBASTIANI F. (2005). An analysis of the relative hardness of reuters-21578
subsets. Journal of the American Society for Information Science and Technology, 56(6), 584&#8211;
596.
</p>
<p>FORMAN G. (2004). A pitfall and solution in multi-class feature selection for text classi-
fication. In Proceedings of the 21st International Conference on Machine Learning (ICML
&#8217;04).
</p>
<p>JOACHIMS T. (2002). Learning to Classify Text using Support Vector Machines. Kluwer
Academic Publishers.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Pe&#241;a Saldarriaga et al.
</p>
<p>NAMER F. (2000). Flemm : Un analyseur flexionnel du fran&#231;ais &#224; base de r&#232;gles. Traitement
Automatique des Langues, 41(2), 523&#8211;547.
PE&#209;A SALDARRIAGA S., VIARD-GAUDIN C. &amp; MORIN E. (2009). On-line handwritten
text categorization. In Proceedings of Document Recognition and Retrieval XVI, IS&amp;T/SPIE
International Symposium on E.I. (DRR &#8217;09), volume 7247, p. 724709.
</p>
<p>PERRAUD F., VIARD-GAUDIN C., MORIN E. &amp; LALLICAN P. M. (2005). Statistical lan-
guage models for on-line handwriting recognition. IEICE Transactions on Information and
Systems, E88-D(8), 1807&#8211;1814.
PORTER M. F. (1980). An algorithm for suffix stripping. Program, 14(3), 130&#8211;137.
SALTON G., WONG A. &amp; WANG C. S. (1975). A vector space model for automatic indexing.
Communications of the ACM, 18(11), 613&#8211;620.
SEBASTIANI F. (2002). Machine learning in automated text categorization. ACM Computing
Surveys, 34(1), 1&#8211;47.
SP&#196;RCK JONES K. (1979). Experiments in relevance weighting of search terms. Information
Processing &amp; Management, 15, 133&#8211;144.
VAPNIK V. (1995). The Nature of Statistical Learning Theory. Springer-Verlag.
</p>
<p>VINCIARELLI A. (2005). Noisy text categorization. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 27(12), 1882&#8211;1895.
VINCIARELLI A. (2006). Indexation de documents manuscrits. In Actes du 9&#232;me Colloque
International Francophone sur l&#8217;Ecrit et le Document (CIFED &#8217;06), p. 49&#8211;54.
</p>
<p>YANG Y. &amp; LIU X. (1999). A re-examination of text categorization methods. In Proceedings
of the 22nd Annual International ACM SIGIR Conference (SIGIR &#8217;99), p. 42&#8211;49.
</p>
<p>YANG Y. &amp; PEDERSEN J. O. (1997). A comparative study on feature selection in text cate-
gorization. In Proceedings of the 14th International Conference on Machine Learning (ICML
&#8217;97), p. 412&#8211;420.</p>

</div></div>
</body></html>