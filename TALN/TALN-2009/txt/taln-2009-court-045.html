<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Utilisation de PLSI en recherche d&#8217;information Repr&#233;sentation des requ&#234;tes</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009 &#8211; Session posters , Senlis, 24&#8211;26 juin 2009
</p>
<p>Utilisation de PLSI en recherche d&#8217;information
Repr&#233;sentation des requ&#234;tes&#8224;
</p>
<p>Jean-C&#233;dric Chappelier Emmanuel Eckard
Laboratoire d&#8217;Intelligence Artificielle
</p>
<p>&#201;cole polytechnique f&#233;d&#233;rale de Lausanne, Suisse
{jean-cedric.chappelier, emmanuel.eckard}@epfl.ch
</p>
<p>R&#233;sum&#233;. Le mod&#232;le PLSI (&#171; Probabilistic Latent Semantic Indexing &#187;) offre une approche
de l&#8217;indexation de documents fond&#233;e sur des mod&#232;les probabilistes de cat&#233;gories s&#233;mantiques
latentes et a conduit &#224; des applications dans diff&#233;rents domaines. Toutefois, ce mod&#232;le rend
impossible le traitement de documents inconnus au moment de l&#8217;apprentissage, probl&#232;me par-
ticuli&#232;rement sensible pour la repr&#233;sentation des requ&#234;tes dans le cadre de la recherche d&#8217;infor-
mation. Une m&#233;thode, dite de &#171; folding-in &#187;, permet dans une certaine mesure de contourner ce
probl&#232;me, mais pr&#233;sente des faiblesses. Cet article introduit nouvelle une mesure de similarit&#233;
document-requ&#234;te pour PLSI, fond&#233;e sur les mod&#232;les de langue, o&#249; le probl&#232;me du &#171; folding-in &#187;
ne se pose pas. Nous comparons cette nouvelle similarit&#233; aux noyaux de Fisher, l&#8217;&#233;tat de l&#8217;art en
la mati&#232;re. Nous pr&#233;sentons aussi une &#233;valuation de PLSI sur un corpus de recherche d&#8217;infor-
mation de pr&#232;s de 7500 documents et de plus d&#8217;un million d&#8217;occurrences de termes provenant
de la collection TREC&#8211;AP, une taille consid&#233;rable dans le cadre de PLSI.
</p>
<p>Abstract. The PLSI model (&#8220;Probabilistic Latent Semantic Indexing&#8221;) offers a docu-
ment indexing scheme based on probabilistic latent category models. It entailed applications in
diverse fields, notably in information retrieval (IR). Nevertheless, PLSI cannot process docu-
ments not seen during parameter inference, a major liability for queries in IR. A method known
as &#8220;folding-in&#8221; allows to circumvent this problem up to a point, but has its own weaknesses. The
present paper introduces a new document-query similarity measure for PLSI based on language
models that entirely avoids the problem a query projection. We compare this similarity to Fisher
kernels, the state of the art similarities for PLSI. Moreover, we present an evaluation of PLSI on
a particularly large training set of almost 7500 document and over one million term occurrence
large, created from the TREC&#8211;AP collection.
</p>
<p>1 Introduction
</p>
<p>Depuis dix ans, le mod&#232;le PLSI (&#171; Probabilistic Latent Semantic Indexing &#187;) (Hofmann, 1999;
Hofmann, 2000; Hofmann, 2001) offre une approche de l&#8217;indexation de documents fond&#233;e sur
des mod&#232;les probabilistes de cat&#233;gories s&#233;mantiques latentes. Ce mod&#232;le a conduit &#224; plusieurs
applications (Ahrendt et al., 2005; Gaussier et al., 2002; Jin et al., 2004; Mei &amp; Zhai, 2006;
Steyvers et al., 2004; Vinokourov &amp; Girolami, 2002), notamment dans le domaine de la recherche
d&#8217;information (RI). Toutefois, une limitation majeure de ce mod&#232;le vient du fait qu&#8217;il n&#8217;est pas
g&#233;n&#233;ratif vis &#224; vis de documents dont le mod&#232;le est inconnu, et qu&#8217;il tend &#224; sur-apprendre (Blei
</p>
<p>&#8224; Ce travail a &#233;t&#233; financ&#233; dans le cadre du projet 200020&#8211;119745 du Fond National Suisse.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Jean-C&#233;dric Chappelier, Emmanuel Eckard
</p>
<p>et al., 2003; Popescul et al., 2001). Un certain nombre d&#8217;extensions et d&#8217;alternatives ont &#233;t&#233; pro-
pos&#233;es pour y rem&#233;dier : Latent Dirichlet Allocation (Blei et al., 2003), undirected PLSI (Welling
et al., 2005), correlated topic models (Blei &amp; Lafferty, 2007), rate adapting Poisson mod-
els (Gehler et al., 2006) ; mais ces am&#233;liorations restent co&#251;teuses en terme de complexit&#233;.
Dans le cadre de la RI, la nature non g&#233;n&#233;rative de PLSI vis-&#224;-vis des mod&#232;les de document
inconnus conduit &#224; un traitement sp&#233;cifique des requ&#234;tes, appel&#233; &#171; folding-in &#187;, qui consiste
&#224; estimer leurs param&#232;tres sp&#233;cifiques, non vus pendant la phase d&#8217;apprentissage (Hofmann,
1999; Hinneburg et al., 2007). Le but de cet article est d&#8217;introduire une nouvelle similarit&#233;
document&#8211;requ&#234;te th&#233;oriquement fond&#233;e, pr&#233;sent&#233;e en section 3, qui &#233;vite le &#171; folding-in &#187; : on
consid&#232;re les requ&#234;tes comme de nouvelles instances g&#233;n&#233;r&#233;es par des mod&#232;les de documents
d&#233;j&#224; connus. Cette nouvelle approche est compar&#233;e &#224; l&#8217;&#233;tat de l&#8217;art pour PLSI bas&#233; sur les
noyaux de Fisher (Chappelier &amp; Eckard, 2009). Pour finir, la section 4 apporte des r&#233;sultats
exp&#233;rimentaux obtenus sur une grande collection cr&#233;&#233;e &#224; partir du corpus d&#8217;&#233;valuation TREC&#8211;
AP. PLSI n&#8217;&#233;tant pas g&#233;n&#233;ratif, ses param&#232;tres doivent &#234;tre effectivement appris sur toute la
collection utilis&#233;e, et non seulement sur un &#233;chantillon d&#8217;apprentissage. &#192; notre connaissance,
il n&#8217;avait jamais &#233;t&#233; tent&#233; d&#8217;appliquer PLSI &#224; une base d&#8217;une telle envergure, plus de 7000
documents et d&#8217;un million d&#8217;occurrences de termes.
</p>
<p>2 Le mod&#232;le PLSI
</p>
<p>Dans le mod&#232;le PLSI, les documents sont repr&#233;sent&#233;s comme des occurrences successives de
paires d&#8217;indices (d, w) pour une cat&#233;gorie z &#8712; Z donn&#233;e, d &#233;tant l&#8217;indice d&#8217;un document et w,
celui d&#8217;un terme. De plus, w et d sont suppos&#233;s ind&#233;pendants sachant z, de sorte que le mod&#232;le
s&#8217;&#233;crit : P (d, w) =
</p>
<p>&#8721;
z&#8712;Z P (z) P (w|z) P (d|z).
</p>
<p>Les param&#232;tres de PLSI sont &#952; = (P (z), P (w|z), P (d|z)), pour tous les z, w et d possibles dans
le mod&#232;le. Ces param&#232;tres s&#8217;estiment pour une collection de documents donn&#233;e en utilisant une
variante de l&#8217;algorithme expectation-maximisation (EM) (Hofmann, 1999; Hofmann, 2001).
Le mod&#232;le de similarit&#233; document-requ&#234;te utilis&#233; dans PLSI repose sur les noyaux de Fisher (Hof-
mann, 2000). Plusieurs variantes existent en fonction des approximations effectu&#233;es (Chappelier
&amp; Eckard, 2009), mais chacune se compose de deux termes additifs qui traduisent respective-
ment la contribution directe des cat&#233;gories latentes, not&#233;e Kz, et celle des termes, not&#233;e Kw. La
diff&#233;rence la plus significative entre ces variantes r&#233;side dans la fa&#231;on d&#8217;approcher la matrice
d&#8217;information de Fisher, soit pas la matrice identit&#233; comme fait initialement, soit par la diago-
nale (variantes DFIM, pour &#171; Diagonal Fisher Information Matrix &#187;). La prise en compte des
termes DFIM pond&#232;re les composantes Kz et Kw, &#233;vitant une sur-repr&#233;sentation de Kz, dont
les performances sont faibles (Chappelier &amp; Eckard, 2009).
</p>
<p>3 &#201;viter la projection des requ&#234;tes
La projection des requ&#234;tes (&#171; folding-in &#187;) est une technique qui permet de contourner la na-
ture non g&#233;n&#233;rative de PLSI en estimant les param&#232;tres des documents inconnus tels que les
requ&#234;tes : les param&#232;tres P (q|z) d&#8217;une requ&#234;te q sont estim&#233;s par un processus EM simplifi&#233;
o&#249; les valeurs des P (w|z) et P (z) sont fix&#233;es sur celles initialement apprises sur le corpus.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PLSI pour la recherche d&#8217;information
</p>
<p>Cette m&#233;thode a ses inconv&#233;nients, notamment pour l&#8217;estimation de la vraisemblance du corpus
d&#8217;apprentissage (Welling et al., 2008) et la coh&#233;rence avec les P (d|z) connus.
Nous pr&#233;sentons ici une nouvelle mesure de similarit&#233; document&#8211;requ&#234;te qui s&#8217;inspire des m&#233;th-
odes &#224; base de mod&#232;les de langue (Ponte &amp; Croft, 1998; Zhai, 2008) qui &#233;vite enti&#232;rement la
phase de projection pour les requ&#234;tes et les probl&#232;mes li&#233;s &#224; l&#8217;apprentissage des param&#232;tres
P (q|z) : on repr&#233;sente les requ&#234;tes non comme des nouveaux mod&#232;les de documents pour
lesquels les param&#232;tres P (q|z) sont &#224; apprendre, mais comme de nouvelles occurrences des
mod&#232;les des documents d&#233;j&#224; connus. On r&#233;duit ainsi la RI &#224; un probl&#232;me d&#8217;identification de
mod&#232;le : pour une requ&#234;te q donn&#233;e, quels sont les mod&#232;les d d&#233;j&#224; connus les plus repr&#233;sentat-
ifs de q ?
</p>
<p>Une solution classique &#224; une telle question consiste &#224; maximiser la log-vraisemblance de la
requ&#234;te par rapport au mod&#232;le P (d, w) (Ponte &amp; Croft, 1998) :
</p>
<p>SLogL(d, q) =
&#8721;
</p>
<p>w&#8712;q&#8745;d
</p>
<p>n(q, w) log P (d, w), (1)
</p>
<p>o&#249; n(q, w) est le nombre d&#8217;occurrences du terme w dans la requ&#234;te q, et o&#249; &#171; w &#8712; q &#8745; d &#187;
repr&#233;sente les termes qui apparaissent dans q (i.e. n(q, w) &gt; 0) et tels que P (d, w) &gt; 0.
Une autre solution courante pour l&#8217;identification de mod&#232;le est la minimisation de la divergence
de Kullback-Leibler entre la distribution empirique (q) et la distribution du mod&#232;le (d) (Lafferty
&amp; Zhai, 2001) :
</p>
<p>SKL(d, q) = &#8722;KL
(
</p>
<p>P&#770; (w|q)
</p>
<p>&#8741;&#8741;&#8741;&#8741;P (w|d)
)
</p>
<p>=
&#8721;
</p>
<p>w&#8712;q&#8745;d
</p>
<p>P&#770; (w|q) log
P (w|d)
</p>
<p>P&#770; (w|q)
, (2)
</p>
<p>avec P&#770; (w|q) = n(q, w)/|q| le nombre d&#8217;occurrences du terme w dans la requ&#234;te q divis&#233; par sa
longueur |q|.
</p>
<p>Ces deux approches, bien que li&#233;es, ne sont pas &#233;quivalentes :
</p>
<p>SKL(d, q) =
1
</p>
<p>|q|
</p>
<p>(
SLogL(d, q)&#8722; |q| log P (d)
</p>
<p>)
&#8722;
</p>
<p>&#8721;
w
</p>
<p>P&#770; (w|q) log P&#770; (w|q)
</p>
<p>&#65080; &#65079;&#65079; &#65080;
f(q)
</p>
<p>.
</p>
<p>Lors de la maximisation de S(d, q) par rapport &#224; d pour une requ&#234;te q donn&#233;e, les deux ap-
proches se distinguent par un facteur additif |q| log P (d) : cela revient &#224; prendre ou non en
compte la longueur des documents via |q| et P (d), qui est en pratique tr&#232;s proche de |d|/|C| (o&#249;
|C| est la taille de tout le corpus).
On peut aussi g&#233;n&#233;raliser les d&#233;marches pr&#233;c&#233;dentes &#224; tout estimateur P&#771; (w|q) de P&#770; (w|q). Par
exemple, le lissage de Jelinek-Mercer (JM) (Zhai &amp; Lafferty, 2004) donne P&#771; (w|q) = (1 &#8722;
&#955;) P&#770; (w|q) + &#955;PGE(w), avec une constante de lissage &#955; comprise entre 0 et 1, et PGE(w) la
probabilit&#233; a priori ( &#171;General English&#187; ) du terme w, typiquement estim&#233;e par PGE(w) =&#8721;
</p>
<p>d&#8712;C P&#770; (w, d).
</p>
<p>Une autre fa&#231;on de construire un estimateur P&#771; (w|q) de P&#770; (w|q) consiste &#224; prendre les documents
les plus pertinents d&#8217;une premi&#232;re phase de recherche, comme il est fait dans le Mod&#232;le de
Pertinence (Lavrenko &amp; Croft, 2001) et dans le pseudo-feedback (Zhai &amp; Lafferty, 2001) : une</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Jean-C&#233;dric Chappelier, Emmanuel Eckard
</p>
<p>CACM CRAN TIME CISI MED AP89_01XX
Nb. de termes 4 911 4 063 13 367 5 545 7 688 13 379
</p>
<p>Nb. d&#8217;occurrences (|C|) 90 927 120 973 114 850 87 067 76 571 1 321 482
Nb. de documents 1 587 1 398 425 1 460 1 033 7 466
</p>
<p>|d| moyen 56.8 85.1 268.6 56.7 73.8 177.2
Nb. de requ&#234;tes 64 225 83 112 30 50
</p>
<p>|q| moyen 12.7 8.9 8.2 37.7 11.4 79.3
</p>
<p>TAB. 1 &#8211; Donn&#233;es des collections de documents utilis&#233;es pour l&#8217;&#233;valuation.
</p>
<p>premi&#232;re recherche est effectu&#233;e en utilisant la similarit&#233; ci-dessus (Eq. (2), avec P&#770; (w|q) ou sa
version liss&#233;e) ; on utilise alors les N documents les plus pertinents pour estimer P&#771; (w|q) par
</p>
<p>P&#771; (w|q) =
1
</p>
<p>N
</p>
<p>N&#8721;
i=1
</p>
<p>P (di(q), w) ,
</p>
<p>avec di(q) le i&#232;me meilleur document pour la requ&#234;te q. Une deuxi&#232;me phase est ensuite effec-
tu&#233;e en utilisant S(d, q) = &#8722;KL(P&#771; (w|q), P (w|d)).
</p>
<p>On obtient donc finalement huit sch&#233;mas de recherche sans projection de requ&#234;tes : la log-
vraisemblance (Eq. 1) ou la divergence de Kullback-Leibler (Eq. 2), avec pour chacune la pos-
sibilit&#233; d&#8217;appliquer un lissage de Jelinek-Mercer, le pseudo-feedback, ou les deux.
</p>
<p>4 Exp&#233;riences
</p>
<p>Afin d&#8217;&#233;valuer l&#8217;approche propos&#233;e ici, nous consid&#233;rons 14 mesures de similarit&#233; : les huit
bas&#233;es sur les mod&#232;les de langage (d&#233;crite en section pr&#233;c&#233;dente) et les 6 meilleures variantes du
noyau de Fisher (Chappelier &amp; Eckard, 2009) : le mod&#232;le d&#8217;origine de Hofmann KH , sa version
DFIM KDFIM-H, ainsi que leurs composantes &#171; termes &#187; Kw et &#171; cat&#233;gories &#187; Kz. Les questions
suivantes se posent alors : 1) comment se comporte la nouvelle approche sans &#171; folding-in &#187; par
rapport aux meilleurs noyaux de Fisher ? 2) comment ces mesures se comparent-elles &#224; l&#8217;&#233;tat
de l&#8217;art, le mod&#232;le BM25 (Robertson et al., 1994) ? 3) la r&#233;-estimation de P (w|q), que ce soit &#224;
l&#8217;aide du lissage de Jelinek-Mercer ou du pseudo-feedback, am&#233;liore-t-il les r&#233;sultats ?
</p>
<p>La nature non g&#233;n&#233;rative de PLSI oblige &#224; estimer les param&#232;tres sur l&#8217;enti&#232;ret&#233; de la collection
&#233;valu&#233;e, et il est donc impossible d&#8217;utiliser des collections aussi grandes que celles de TREC
dans leur totalit&#233;. En coh&#233;rence avec les travaux pr&#233;c&#233;demment publi&#233;es sur PLSI, nous util-
isons les collections d&#8217;&#233;valuation de SMART1 : CACM, CISI, MED, CRAN et TIME pour
r&#233;pondre &#224; ces questions. De plus, nous utilisons un plus grand corpus constitu&#233; d&#8217;une partie de
la collection TREC&#8211;AP 89. Pour les m&#234;mes raisons, nous n&#8217;avons gard&#233; que les 7466 premiers
documents de cette collection, et les requ&#234;tes 1 &#224; 50.2 Les caract&#233;ristiques de ces collections
sont donn&#233;es dans le tableau 1.
</p>
<p>1ftp://ftp.cs.cornell.edu/pub/smart/
2Les documents AP890101-0001 &#224; AP890131-0311. La phase d&#8217;apprentissage de EM pour |Z| = 128 a pris
</p>
<p>45 heures de temps CPU, et utilis&#233; 6.7 Gb de RAM, sur un serveur de calcul Intel Xenon octo-c&#339;ur de 2 GHz avec
32 Gb de m&#233;moire.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PLSI pour la recherche d&#8217;information
</p>
<p>CACM CRAN TIME CISI MED AP89
MAP de BM25 31.4 42.4 69.2 12.3 52.3 19.7
MAP du meilleur mod&#232;le PLSI 30.0 39.6 60.8 20.2 53.8 21.6
Meilleur mod&#232;le PLSI : KHw SKL KDFIM-Hw KHw KH KDFIM-Hw
</p>
<p>R
&#233;s
</p>
<p>u
lta
</p>
<p>ts
</p>
<p>Obtenu pour |Z| = 16 128 8 8 32 48
MAP de SKL,|Z|=128 22.9 39.6 49.1 19.5 52.8 11.4
PLSI &gt; BM25 ? Non Non Non OUI oui oui
</p>
<p>Co
n
</p>
<p>cl
.
</p>
<p>SKL,|Z|=128 vs noyaux de Fisher &lt; &gt; &lt; &#8771; &#8771; &lt;
</p>
<p>TAB. 2 &#8211; Principaux r&#233;sultats des 14 mod&#232;les sur les 6 collections.
</p>
<p>Pour les collections SMART, chaque exp&#233;rience a &#233;t&#233; effectu&#233;e 6 fois avec des conditions ini-
tiales d&#8217;apprentissage diff&#233;rentes, pour chaque mod&#232;le, et pour diff&#233;rentes quantit&#233;s de cat&#233;-
gories latentes : |Z| &#8712; {1, 2, 8, 16, 32, 64, 128} ; soit 2940 exp&#233;riences en tout. Pour TREC-AP,
les exp&#233;riences ont &#233;t&#233; effectu&#233;es avec une seule condition initiale d&#8217;apprentissage, pour chaque
|Z| &#8712; {1, 32, 48, 64, 80, 128}, soit 84 exp&#233;riences en tout.
</p>
<p>Pour toutes ces exp&#233;riences, le stemmer de Porter impl&#233;ment&#233; dans Xapian3 a &#233;t&#233; utilis&#233;. Les
r&#233;sultats de l&#8217;&#233;valuation ont &#233;t&#233; obtenus par l&#8217;outil standard trec_eval4. Nous pr&#233;sentons ici
les r&#233;sultats en termes de Mean Average Precision (MAP), mais les conclusions sont similaires
si l&#8217;on utilise la pr&#233;cision &#224; 5 points ou la R-pr&#233;cision. A l&#8217;exception de la figure 2, les figures
publi&#233;es repr&#233;sentent la MAP en fonction du nombre |Z| de cat&#233;gories latentes, moyenn&#233;e
sur 6 exp&#233;riences, ainsi que les barres d&#8217;erreur correspondant &#224; un &#233;cart-type. Les principales
conclusions de ces 3024 exp&#233;riences, r&#233;sum&#233;es dans le tableau 2, sont :
</p>
<p>1. Figure 1 : SKL (Eq. 2) donne de meilleures performances que SLogL (Eq. 1).
Les deux mesures (SKL et SLogL) am&#233;liorent leurs performances au fur et &#224; mesure que
|Z| grandit. Nous nous sommes arr&#234;t&#233;s &#224; |Z| = 128 pour des raisons pratiques.
</p>
<p>2. Figures 3 et 4 : SKL surpasse les meilleurs noyaux de Fisher sur CRAN et obtient des
performances similaires sur MED et CISI. Rappelons qu&#8217;il est aussi sup&#233;rieur parce qu&#8217;il
ne requiert de phase sp&#233;cifique pour les requ&#234;tes (&#171; folding-in &#187;).
</p>
<p>3. Figures 3 et 4 : le lissage de P&#770; (q|w) n&#8217;am&#233;liore pas les performances, ni par lissage JM,
ni par le pseudo-feedback. De plus, bien que l&#8217;impl&#233;mentation ait fait l&#8217;objet d&#8217;un effort
particulier pour en limiter la complexit&#233;, le lissage augmente consid&#233;rablement le temps
d&#8217;&#233;valuation (il n&#8217;a pas d&#8217;effet sur le temps d&#8217;apprentissage) : contrairement &#224; la variante
non liss&#233;e, ce ne sont pas seulement les termes pr&#233;sents dans la requ&#234;te, aussi ceux du
document, voire de toute la collection, qui entrent en ligne de compte ; aussi l&#8217;&#233;valuation
d&#8217;une requ&#234;te est-elle bien plus lente que sans lissage : entre 2 (CISI) et 20 (TIME, MED)
fois plus lents pour le lissage de Jelinek-Mercer, et entre 30 (MED) et 150 (CRAN) fois
plus lent avec la recherche en deux passes avec N = 3.
</p>
<p>4. Figures 3 : sur des collections &#171; s&#233;mantiquement difficiles &#187;, les meilleurs noyaux PLSI
ont de meilleures performances que le mod&#232;le BM25 : CISI, o&#249; les requ&#234;tes et les docu-
ments ne partagent que de rares termes (et donc particuli&#232;rement utile pour mesurer dans
quelle mesure un mod&#232;le de recherche est robuste &#224; la synonymie.)5, MED (vocabulaire
sp&#233;cialis&#233;), et TREC&#8211;AP.
</p>
<p>3http://xapian.org/
4http://trec.nist.gov/trec_eval/
5CISI est remarquable pour avoir des requ&#234;tes cens&#233;es retourner des documents avec lesquelles elles ne parta-
</p>
<p>gent aucun terme significatif.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Jean-C&#233;dric Chappelier, Emmanuel Eckard
</p>
<p>1 8 16 32 64 128
</p>
<p>0.
0
</p>
<p>0.
1
</p>
<p>0.
2
</p>
<p>0.
3
</p>
<p>0.
4
</p>
<p>KL
LogL
ZDFIMH
ZH
</p>
<p>FIG. 1 &#8211; Exemple typique (ici sur CRAN)
qui montre comment la similarit&#233; SKL bas&#233;e
sur P (w|d) d&#233;passe SLogL bas&#233;e sur P (d, w).
Les composantes KHz (ZH) et KDFIM-Hz (ZD-
FIMH) des noyaux de Fisher sont &#233;galement
repr&#233;sent&#233;es.
</p>
<p>Recall
</p>
<p>Pr
ec
</p>
<p>is
io
</p>
<p>n
</p>
<p>0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
</p>
<p>0.
2
</p>
<p>0.
4
</p>
<p>0.
6
</p>
<p>0.
8
</p>
<p>BM25
DFIMH64
H32
KL128
WH32
ZH32
</p>
<p>FIG. 2 &#8211; Courbes pr&#233;cision-rappel sur MED
pour BM25, KDFIM-H &#224; |Z| =64 (DFIMH64),
KH &#224; |Z| =32 (H32), SKL &#224; |Z| =128
(KL128), KHw &#224; |Z| =32 (WH32), et KHz &#224;
|Z| =32 (YH32).
</p>
<p>Les conclusions doivent &#234;tre plus nuanc&#233;es pour MED : les diff&#233;rents mod&#232;les n&#8217;ont pas le
m&#234;me comportement &#224; diff&#233;rentes valeurs de rappel (figure 2) ; certains sont meilleurs pour un
rappel bas et d&#8217;autres meilleurs &#224; un rappel haut. Des mesures de performance globales comme
la MAP ou la R-pr&#233;cision ne rendent pas compte de ces subtilit&#233;s.
</p>
<p>5 Conclusions
</p>
<p>Cet article apporte un mod&#232;le de similarit&#233; pour PLSI th&#233;oriquement fond&#233;e &#233;vitant enti&#232;rement
les &#233;cueils de la repr&#233;sentation des requ&#234;tes ; par ailleurs, il fournit une &#233;valuation des perfor-
mances de PLSI sur une collection plus grande que les collections SMART sur lesquelles les
exp&#233;riences ont &#233;t&#233; faites jusqu&#8217;&#224; pr&#233;sent. Aux questions qui se posent, nous pouvons r&#233;pondre :
</p>
<p>1. que la nouvelle approche sans &#171; folding-in &#187; des requ&#234;tes se compare favorablement aux
meilleures variantes du noyau de Fisher, particuli&#232;rement pour les plus grands nombres
de cat&#233;gories latentes ;
</p>
<p>2. et que ces mod&#232;les se comparent favorablement avec BM25 pour les collections s&#233;man-
tiquement difficiles comme CISI, MED et TREC&#8211;AP.
</p>
<p>3. Figures 3 et 4 : le lissage de P&#770; (w|q) n&#8217;am&#233;liore les r&#233;sultats dans aucun des cas test&#233;s.
Sur les huit variantes propos&#233;es, seule la similarit&#233; de Kullback-Leibler avec P (w|d) non
liss&#233; est valable.
</p>
<p>Ainsi, nous confirmons exp&#233;rimentalement que les mod&#232;les &#224; cat&#233;gories latentes comme PLSI
pourraient s&#8217;av&#233;rer int&#233;ressants pour la recherche d&#8217;information sur des collections de taille
raisonnable, mais s&#233;mantiquement difficiles, o&#249; les requ&#234;tes et les documents qui leur sont
pertinents ne partagent que peu de termes. Dans ces cas, il est recommand&#233; d&#8217;utiliser KDFIM-Hw
ou SKL (Eq. 2) s&#8217;il est possible de faire tourner l&#8217;apprentissage avec un nombre suffisant de</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PLSI pour la recherche d&#8217;information
</p>
<p>CACM
</p>
<p>1 8 16 32 64 128
</p>
<p>0.
00
</p>
<p>0.
05
</p>
<p>0.
10
</p>
<p>0.
15
</p>
<p>0.
20
</p>
<p>0.
25
</p>
<p>0.
30
</p>
<p>0.
35
</p>
<p>H
KL
WDFIMH
WH
</p>
<p>CISI
</p>
<p>1 8 16 32 64 128
</p>
<p>0.
00
</p>
<p>0.
05
</p>
<p>0.
10
</p>
<p>0.
15
</p>
<p>0.
20
</p>
<p>0.
25
</p>
<p>H
KL
WDFIMH
WH
</p>
<p>CRAN
</p>
<p>1 8 16 32 64 128
</p>
<p>0.
0
</p>
<p>0.
1
</p>
<p>0.
2
</p>
<p>0.
3
</p>
<p>0.
4
</p>
<p>H
KL
WDFIMH
WH
</p>
<p>MED
</p>
<p>1 8 16 32 64 128
</p>
<p>0.
0
</p>
<p>0.
1
</p>
<p>0.
2
</p>
<p>0.
3
</p>
<p>0.
4
</p>
<p>0.
5
</p>
<p>H
KL
WDFIMH
WH
</p>
<p>TIME
</p>
<p>1 8 16 32 64 128
</p>
<p>0.
0
</p>
<p>0.
1
</p>
<p>0.
2
</p>
<p>0.
3
</p>
<p>0.
4
</p>
<p>0.
5
</p>
<p>0.
6
</p>
<p>0.
7
</p>
<p>H
KL
WDFIMH
WH
</p>
<p>TREC&#8722;AP89_01XX
</p>
<p>1 32 48 64 80 128
</p>
<p>0.
00
</p>
<p>0.
05
</p>
<p>0.
10
</p>
<p>0.
15
</p>
<p>0.
20
</p>
<p>H
KL
WDFIMH
WH
ZN
</p>
<p>FIG. 3 &#8211; R&#233;sultats obtenus sur les 6 collections pour diff&#233;rents mod&#232;les : KH (H), SKL (KL),
KDFIM-Hw (WDFIMH), et KHw (WH). Les lignes horizontales repr&#233;sentent les performances de
BM25, qui ne d&#233;pend pas de |Z|.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Jean-C&#233;dric Chappelier, Emmanuel Eckard
</p>
<p>1 8 16 32 64 128
</p>
<p>0.
1
</p>
<p>0.
2
</p>
<p>0.
3
</p>
<p>0.
4 1e&#8722;1
</p>
<p>1e&#8722;2
1e&#8722;3
1e&#8722;4
1e&#8722;5
1e&#8722;6
l0
</p>
<p>1 8 16 32 64 128
</p>
<p>0.
1
</p>
<p>0.
2
</p>
<p>0.
3
</p>
<p>0.
4
</p>
<p>1&#8722;step
2&#8722;step, N=1
2&#8722;step, N=2
2&#8722;step, N=3
</p>
<p>FIG. 4 &#8211; Exemple typique montrant (ici sur TIME) comment le lissage de Jelinek-Mercer de
P&#770; (q|w) (&#224; gauche) ou par le pseudo-feedback (&#224; droite) d&#233;gradent les performances, compar&#233; &#224;
la variante non liss&#233;e P&#770; (q|w) not&#233;e &#171; l0 &#187; &#224; gauche, et &#171; 1 step &#187; &#224; droite.
</p>
<p>cat&#233;gories latentes. SKL pr&#233;sente de plus l&#8217;avantage de ne pas demander de r&#233;-apprentissage
pour la projection des requ&#234;tes (&#171; folding in &#187;).
Toutefois, la conclusion globale est que PLSI n&#8217;est pas adapt&#233; &#224; la recherche documentaire sur
de grandes collections : comme il comporte en param&#232;tre un mod&#232;le des documents vus pendant
l&#8217;apprentissage, il est pas nature non g&#233;n&#233;ratif, et ne passe tout simplement pas &#224; l&#8217;&#233;chelle
lorsque le nombre de documents atteint les dizaines de milliers. De plus, pour sophistiqu&#233; qu&#8217;il
soit, PLSI surpasse &#224; peine le mod&#232;le BM25, et cela au prix d&#8217;une complexit&#233; et d&#8217;un temps de
calcul r&#233;dhibitoires.
</p>
<p>On peut sp&#233;culer que PLSI pourrait s&#8217;av&#233;rer significativement meilleur que les mod&#232;les de
l&#8217;&#233;tat de l&#8217;art en utilisant un bien plus grand nombre de cat&#233;gories latentes, mais les limitations
induites par le nombre de param&#232;tres &#224; apprendre rendent ces cas impossibles &#224; calculer en
pratique. Il est fort probable qu&#8217;un tr&#232;s grand |Z| am&#233;liore les performances de Kz ou de SKL,
mais l&#8217;apprentissage de tels mod&#232;les s&#8217;av&#232;re en pratique impossible, tout particuli&#232;rement pour
les grandes collections pour lesquelles de tels |Z| seraient justement le plus appropri&#233;s.
</p>
<p>R&#233;f&#233;rences
AHRENDT P., GOUTTE C. &amp; LARSEN J. (2005). Co-occurrence models in music genre classification.
In IEEE Int. Workshop on Machine Learning for Signal Processing.
BLEI D. &amp; LAFFERTY J. (2007). A correlated topic model of Science. An. of App. Stat., 1(1), 17&#8211;35.
BLEI D. M., NG A. Y. &amp; JORDAN M. I. (2003). Latent Dirichlet allocation. Journal of Machine
Learning Research, 3, 993&#8211;1022.
CHAPPELIER J.-C. &amp; ECKARD E. (2009). R&#244;le de la matrice d&#8217;information et pond&#233;ration des com-
posantes dans les noyaux de Fisher pour PLSI. In Actes de la Sixi&#232;me Conf&#233;rence francophone en
Recherche d&#8217;Information et Applications, p. 267&#8211;282 : LSIS-USTV.
GAUSSIER E., GOUTTE C., POPAT K. &amp; CHEN F. (2002). A hierarchical model for clustering and
categorising documents. In Proc. of 24th BCS-IRSG European Colloquium on IR Research, p. 229&#8211;247.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PLSI pour la recherche d&#8217;information
</p>
<p>GEHLER P. V., HOLUB A. D. &amp; WELLING M. (2006). The rate adapting Poisson model for informa-
tion retrieval and object recognition. In Proc. of the 23rd Int. Conf. on Machine Learning, p. 337&#8211;344.
HINNEBURG A., GABRIEL H.-H. &amp; GOHR A. (2007). Bayesian folding-in with Dirichlet kernels for
PLSI. In Proc. of the 7th IEEE Int. Conf. on Data Mining, p. 499&#8211;504.
HOFMANN T. (1999). Probabilistic latent semantic indexing. In Proc. of 22th Annual Int. ACM SIGIR
Conf. on Research and Development in Information Retrieval, p. 50&#8211;57.
HOFMANN T. (2000). Learning the similarity of documents : An information-geometric approach to
document retrieval and categorization. In Adv. in Neural Inf. Proc. Sys. (NIPS), volume 12, p. 914&#8211;920.
HOFMANN T. (2001). Unsupervised learning by probabilistic latent semantic analysis. Machine Learn-
ing, 42(1), 177&#8211;196.
JIN X., ZHOU Y. &amp; MOBASHER B. (2004). Web usage mining based on probabilistic latent semantic
analysis. In Proc. of 10th Int. Conf. on Knowledge Discovery and Data Mining, p. 197&#8211;205.
LAFFERTY J. &amp; ZHAI C. (2001). Document language models, query models, and risk minimization
for information retrieval. In Proc. of 24th Annual Int. Conference on Research and Development in
Information Retrieval (SIGIR), p. 111&#8211;119.
LAVRENKO V. &amp; CROFT W. B. (2001). Relevance based language models. In Proc. of 24th Annual
Int. ACM SIGIR Conf. on Research and Development in Information Retrieval, p. 120&#8211;127.
MEI Q. &amp; ZHAI C. (2006). A mixture model for contextual text mining. In Proc. of 12th Int. Conf. on
Knowledge Discovery and Data Mining, p. 649&#8211;655.
PONTE J. M. &amp; CROFT W. B. (1998). A language modeling approach to information retrieval. In
Proc. of 21st Int. Conf. on Research and Development in Information Retrieval (SIGIR), p. 275&#8211;281.
POPESCUL A., UNGAR L. H., PENNOCK D. M. &amp; LAWRENCE S. (2001). Probabilistic models for
unified collaborative and content-based recommendation in sparse-data environments. In Proc. of the
17th Conf. in Uncertainty in Artificial Intelligence, p. 437&#8211;444.
ROBERTSON S. E., WALKER S., JONES S., HANCOCK-BEAULIEU M. &amp; GATFORD M. (1994). Okapi
at TREC&#8211;3. Proc. of the 3rd Text REtrieval Conf.
STEYVERS M., SMYTH P., ROSEN-ZVI M. &amp; GRIFFITHS T. (2004). Probabilistic author-topic models
for information discovery. In 10th Int. Conf. on Knowledge Discovery and Data Mining, p. 306&#8211;315.
VINOKOUROV A. &amp; GIROLAMI M. (2002). A probabilistic framework for the hierarchic organisation
and classification of document collections. Journ. of Intelligent Information Systems, 18(2/3), 153&#8211;172.
WELLING M., CHEMUDUGUNTA C. &amp; SUTTER N. (2008). Deterministic latent variable models and
their pitfalls. SIAM Conference on Data Mining SDM 2008.
WELLING M., ROSEN-ZVI M. &amp; HINTON G. (2005). Exponential family harmoniums with an appli-
cation to information retrieval. In Ad. in Neural Inf. Proc. Sys. (NIPS), volume 17, p. 1481&#8211;1488.
ZHAI C. (2008). Statistical language models for information retrieval a critical review. Found. Trends
Inf. Retr., 2(3), 137&#8211;213.
ZHAI C. &amp; LAFFERTY J. (2001). Model-based feedback in the language modeling approach to infor-
mation retrieval. In Proc. of 10th Int. Conf. on Information and Knowledge Management (CIKM), p.
403&#8211;410.
ZHAI C. &amp; LAFFERTY J. (2004). A study of smoothing methods for language models applied to
information retrieval. ACM Trans. Inf. Syst., 22(2), 179&#8211;214.</p>

</div></div>
</body></html>