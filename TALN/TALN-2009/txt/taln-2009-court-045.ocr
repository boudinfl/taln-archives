TALN 2009 — Session posters , Senlis, 24-26 juin 2009

Utilisation de PLSI en recherche d’information
Représentation des requétesi

J ean-Cedric Chappelier Emmanuel Eckard
Laboratoire d’Inte11igence Artiﬁcielle
Ecole polytechnique federale de Lausanne, Suisse
{jean—cedric.chappelier, emmanuel.eckard}@epfl.ch

Resume. Le modele PLSI (« Probabilistic Latent Semantic Indexing ») offre une approche
de l’indexation de documents fondee sur des modeles probabilistes de categories semantiques
latentes et a conduit a des applications dans differents domaines. Toutefois, ce modele rend
impossible le traitement de documents inconnus au moment de l’apprentissage, probleme par-
ticulierement sensible pour la representation des requetes dans le cadre de la recherche d’infor-
mation. Une methode, dite de « folding-in », permet dans une certaine mesure de contourner ce
probleme, mais presente des faiblesses. Cet article introduit nouvelle une mesure de similarite
document-requete pour PLSI, fondee sur les modeles de langue, ou le probleme du «folding-in »
ne se pose pas. Nous comparons cette nouvelle similatite aux noyaux de Fisher, l’etat de l’art en
la matiere. Nous presentons aussi une evaluation de PLSI sur un corpus de recherche d’infor-
mation de pres de 7500 documents et de plus d’un million d’occurrences de termes provenant
de la collection TREC—AP, une taille considerable dans le cadre de PLSI.

Abstract. The PLSI model (“Probabilistic Latent Semantic Indexing”) offers a docu-
ment indexing scheme based on probabilistic latent category models. It entailed applications in
diverse ﬁelds, notably in information retrieval (IR). Nevertheless, PLSI cannot process docu-
ments not seen during parameter inference, a major liability for queries in IR. A method known
as “folding-in” allows to circumvent this problem up to a point, but has its own weaknesses. The
present paper introduces a new document-query similarity measure for PLSI based on language
models that entirely avoids the problem a query projection. We compare this similarity to Fisher
kernels, the state of the art similarities for PLSI. Moreover, we present an evaluation of PLSI on
a particularly large training set of almost 7500 document and over one million term occurrence
large, created from the TREC—AP collection.

1 Introduction

Depuis dix ans, le modele PLSI (« Probabilistic Latent Semantic Indexing ») (Hofmann, 1999;
Hofmann, 2000; Hofmann, 2001) offre une approche de l’indexation de documents fondee sur
des modeles probabilistes de categories semantiques latentes. Ce modele a conduit a plusieurs
applications (Ahrendt et al., 2005; Gaussier et al., 2002; Jin et al., 2004; Mei & Zhai, 2006;
Steyvers et al., 2004; Vinokourov & Girolami, 2002), notamment dans le domaine de la recherche
d’information (RI). Toutefois, une limitation majeure de ce modele vient du fait qu’il n’est pas
generatif vis a vis de documents dont le modele est inconnu, et qu’il tend a sur-apprendre (Blei

7 Ce travail a ete ﬁnance dans le cadre du projet 200020—119745 du Fond National Suisse.

J ean-Cédric Chappelier, Emmanuel Eckard

et al., 2003; Popescul et al., 2001). Un certain nombre d’eXtensions et d’altematives ont été pro-
posées pour y remédier : Latent DirichletAllocation (Blei et al. , 2003), undirected PLSI (Welling
et al., 2005), correlated topic models (Blei & Lafferty, 2007), rate adapting Poisson mod-
els (Gehler et al., 2006); mais ces améliorations restent coﬁteuses en terme de complexité.

Dans le cadre de la RI, la nature non générative de PLSI vis-a-vis des modeles de document
inconnus conduit a un traitement spéciﬁque des requétes, appelé « folding-in », qui consiste
a estimer leurs parametres spéciﬁques, non vus pendant la phase d’apprentissage (Hofmann,
1999; Hinneburg et al., 2007). Le but de cet article est d’introduire une nouvelle similarité
document—requéte théoriquement fondée, présentée en section 3, qui évite le «folding-in » : on
considere les requétes comme de nouvelles instances générées par des modeles de documents
de’ja connus. Cette nouvelle approche est comparée a l’état de l’art pour PLSI basé sur les
noyaux de Fisher (Chappelier & Eckard, 2009). Pour ﬁnir, la section 4 apporte des résultats
expérimentaux obtenus sur une grande collection créée a partir du corpus d’évaluation TREC—
AP. PLSI n’étant pas génératif, ses parametres doivent étre effectivement appris sur toute la
collection utilisée, et non seulement sur un échantillon d’apprentissage. A notre connaissance,
il n’avait jamais été tenté d’appliquer PLSI a une base d’une telle envergure, plus de 7000
documents et d’un million d’occurrences de termes.

2 Le modéle PLSI

Dans le modele PLSI, les documents sont représentés comme des occurrences successives de
paires d’indices (d, w) pour une catégorie z E Z donnée, d étant l’indice d’un document et w,
celui d’un terme. De plus, 11; et d sont supposés indépendants sachant 2, de sorte que le modele
s’écrit : P(d, w) = Z/ZEZ P(z) P(w|z) P(d|z).

Les parametres de PLSI sont 6 = (P(z), P(w|z), P(d|z)), pour tous les 2, 11; et d possibles dans
le modele. Ces parametres s’estiment pour une collection de documents donnée en utilisant une
variante de l’algorithme expectation-maximisation (EM) (Hofmann, 1999; Hofmann, 2001).

Le modele de similarité document-requéte utilisé dans PLSI repose sur les noyaux de Fisher (Hof-
mann, 2000). Plusieurs variantes existent en fonction des approximations effectuées (Chappelier
& Eckard, 2009), mais chacune se compose de deux termes additifs qui traduisent respective-
ment la contribution directe des categories latentes, notée K Z, et celle des termes, notée K w. La
différence la plus signiﬁcative entre ces variantes réside dans la facon d’approcher la matrice
d’information de Fisher, soit pas la matrice identité comme fait initialement, soit par la diago-
nale (variantes DFIM, pour « Diagonal Fisher Information Matrix »). La prise en compte des
termes DFIM pondere les composantes K Z et K w, évitant une sur-représentation de Kz, dont
les performances sont faibles (Chappelier & Eckard, 2009).

3 Eviter la projection des requétes

La projection des requétes (« folding-in ») est une technique qui permet de contourner la na-
ture non générative de PLSI en estimant les parametres des documents inconnus tels que les
requétes : les parametres P(q|z) d’une requéte q sont estimés par un processus EM simpliﬁé
o1‘1 les valeurs des P(w|z) et P(z) sont ﬁxées sur celles initialement apprises sur le corpus.

PLSI pour la recherche d’information

Cette méthode a ses inconvénients, notamment pour l’estimation de la vraisemblance du corpus
d’apprentissage (Welling et al., 2008) et la cohérence avec les P(d|z) connus.

Nous présentons ici une nouvelle mesure de similarité document—requéte qui s’inspire des méth-
odes a base de modeles de langue (Ponte & Croft, 1998; Zhai, 2008) qui évite entierement la
phase de projection pour les requétes et les problemes lies a l’apprentissage des parametres
P(q|z) : on représente les requétes non comme des nouveaux modeles de documents pour
lesquels les parametres P(q|z) sont a apprendre, mais comme de nouvelles occurrences des
modeles des documents déja connus. On réduit ainsi la RI a un probleme d’identiﬁcation de
modele : pour une requéte q donnée, quels sont les modeles d déja connus les plus representat-
ifs de q ?

Une solution classique a une telle question consiste a maximiser la log-vraisemblance de la
requéte par rapport au modele P(d, w) (Ponte & Croft, 1998) :

8LogL(d7  : Z n(q7w)1Og  w): 

weqﬂd

ou n(q, w) est le nombre d’occurrences du terme w dans la requéte q, et ou « w E q H d »
représente les termes qui apparaissent dans q (i.e. n(q, w) > 0) et tels que P(d, w) > 0.

Une autre solution courante pour l’identiﬁcation de modele est la minimisation de la divergence
de Kullback-Leibler entre la distribution empirique (q) et la distribution du modele (d) (Lafferty
& Zhai, 2001) :

sKL<d,q> = —KL(13(w|q)“P(wld)> = Z 13(w|q)1og11;EZ|d), <2)

weqﬂd iq)

avec 1B(w|q) = n(q, w) / |q| le nombre d’occurrences du terme w dans la requéte q divisé par sa
longueur 

Ces deux approches, bien que liées, ne sont pas équivalentes :

sKL<d,q> = ﬁ(sLogL<d, q) — ml 1ogP<d>) — Z13(wlq)1og13(w|q)-

 

f (<1)

Lors de la maximisation de 8 (d, g) par rapport a d pour une requéte q donnée, les deux ap-
proches se distinguent par un facteur additif |q| log P(d) : cela revient a prendre ou non en
compte la longueur des documents via |q| et P(d), qui est en pratique tres proche de |d| / |C | (ou
|C | est la taille de tout le corpus).

On peut aussi généraliser les démarches précédentes a tout estimateur §(w|q) de  Par
exemple, le lissage de Jelinek-Mercer (JM) (Zhai & Lafferty, 2004) donne 15(w|q) = (1 —
A) ﬁ(w|q) + )\PGE(w), avec une constante de lissage A comprise entre 0 et 1, et PGE(w) la
probabilité a priori ( «General English» ) du terme w, typiquement estimée par PGE(w) =

21160 ﬁ(w> 

Une autre facon de construire un estimateur 15(w |q) de §(w | q) consiste a prendre les documents
les plus pertinents d’une premiere phase de recherche, comme il est fait dans le Modele de
Pertinence (Lavrenko & Croft, 2001) et dans le pseudo-feedback (Zhai & Lafferty, 2001) : une

J ean-Cédric Chappelier, Emmanuel Eckard

1 H CACM| CRAN | TIlV[E 1 CISI | MED |AP89_01XX|

Nb. de termes 4 911 4 063 13 367 5 545 7 688 13 379
Nb. d’occurrences (|C|) 90 927 120 973 114 850 87 067 76 571 1 321 482

Nb. de documents 1 587 1 398 425 1 460 1 033 7 466

|d| moyen 56.8 85.1 268.6 56.7 73.8 177.2
Nb. de requétes 64 225 83 112 30 50
|q| moyen 12.7 8.9 8.2 37.7 11.4 79.3

TAB. 1 — Données des collections de documents utilisées pour l’évaluation.

premiere recherche est effectuée en utilisant la similarité ci-dessus (Eq. (2), avec ﬁ(w|q) ou sa
version lissée) ; on utilise alors les N documents les plus pertinents pour estimer P(w |q) par

ﬁ<w1q>-;§)P<d.-<q>,w>,

avec d,-(q) le ieme meilleur document pour la requéte q. Une deuxieme phase est ensuite effec-
tuée en utilisant 8(d, q) = —KL(P(w|q), P(w|d)).

On obtient donc ﬁnalement huit schémas de recherche sans projection de requétes : la log-
vraisemblance (Eq. 1) ou la divergence de Kullback-Leibler (Eq. 2), avec pour chacune la pos-
sibilité d’appliquer un lissage de J elinek-Mercer, le pseudo-feedback, ou les deux.

4 Expériences

Aﬁn d’évaluer l’approche proposée ici, nous considérons 14 mesures de similarité : les huit
basées sur les modeles de langage (décrite en section précédente) et les 6 meilleures variantes du
noyau de Fisher (Chappelier & Eckard, 2009) : le modele d’origine de Hofmann K H , sa version
DFIM K DF'M'H, ainsi que leurs composantes « termes » K w et « catégories » Kz. Les questions
suivantes se posent alors : 1) comment se comporte la nouvelle approche sans «folding-in » par
rapport aux meilleurs noyaux de Fisher ? 2) comment ces mesures se comparent-elles a l’état
de l’art, le modele BM25 (Robertson et al., 1994) ? 3) la ré-estimation de P(w|q), que ce soit a
l’aide du lissage de J elinek-Mercer ou du pseudo-feedback, améliore-t-il les résultats ?

La nature non générative de PLSI oblige a estimer les parametres sur l’entiereté de la collection
évaluée, et il est donc impossible d’utiliser des collections aussi grandes que celles de TREC
dans leur totalité. En cohérence avec les travaux précédemment publiées sur PLSI, nous util-
isons les collections d’évaluation de SMART1 : CACM, CISI, MED, CRAN et TIME pour
répondre a ces questions. De plus, nous utilisons un plus grand corpus constitué d’une partie de
la collection TREC—AP 89. Pour les memes raisons, nous n’avons gardé que les 7466 premiers
documents de cette collection, et les requétes 1 a 50.2 Les caractéristiques de ces collections
sont données dans le tableau 1.

lftpz//ftp.cs.cornell.edu/pub/smart/

2Les documents AP890101—0001 a AP890131—0311. La phase d’apprentissage de EM pour |Z| = 128 a pris
45 heures de temps CPU, et utilise 6.7 Gb de RAM, sur un serveur de calcul Intel Xenon octo—coeur de 2 GHz avec
32 Gb de mémoire.

PLSI pour la recherche d’information

CACM CRAN TIME CISI MED AP89

MAP de BM25 31.4 42.4 69.2 12.3 52.3 19.7
3 MAP du meilleur modele PLSI 30.0 39.6 60.8 20.2 53.8 21.6
§ Meilleur modele PLSI : K B SKL K BF'M'H K B K H K BF'M'H
E2 Obtenu pour |Z| = 16 128 8 8 32 48

MAP de SKL,|z|=12g 22.9 39.6 49.1 19.5 52.8 11.4
E; PLSI > BM25 ? Non Non Non OUI oui oui
8 8KL,|z|=128 vs noyaux de Fisher < > < 2 2 <

TAB. 2 — Principaux resultats des 14 modeles sur les 6 collections.

Pour les collections SMART, chaque experience a ete effectuee 6 fois avec des conditions ini-
tiales d’apprentissage differentes, pour chaque modele, et pour differentes quantites de cate-
gories latentes : |Z | E {1, 2, 8, 16, 32, 64, 128} ; soit 2940 experiences en tout. Pour TREC-AP,
les experiences ont ete effectuees avec une seule condition initiale d’apprentissage, pour chaque
|Z| E {1, 32, 48, 64, 80, 128}, soit 84 experiences en tout.

Pour toutes ces experiences, le stemmer de Porter implemente dans Xapian3 a ete utilise. Les
resultats de l’evaluation ont ete obtenus par l’outil standard t re c_eva 14. Nous presentons ici
les resultats en termes de Mean Average Precision (MAP), mais les conclusions sont similaires
si l’on utilise la precision a 5 points ou la R-precision. A l’eXception de la ﬁgure 2, les ﬁgures
publiees representent la MAP en fonction du nombre |Z| de categories latentes, moyennee
sur 6 experiences, ainsi que les barres d’erreur correspondant a un ecart-type. Les principales
conclusions de ces 3024 experiences, resumees dans le tableau 2, sont :

1. Figure 1 : SKL (Eq. 2) donne de meilleures performances que 8L0gL (Eq. 1).

Les deux mesures (SKL et 8LogL) ameliorent leurs performances au fur et a mesure que
|Z | grandit. Nous nous sommes arretes a |Z | = 128 pour des raisons pratiques.

2. Figures 3 et 4 : SKL surpasse les meilleurs noyaux de Fisher sur CRAN et obtient des
performances similaires sur MED et CISI. Rappelons qu’il est aussi superieur parce qu’il
ne requiert de phase speciﬁque pour les requetes (« folding-in >>).

3. Figures 3 et 4 : le lissage de P(q|w) n’ameliore pas les performances, ni par lissage JM,
ni par le pseudo-feedback. De plus, bien que l’implementation ait fait l’objet d’un effort
particulier pour en limiter la complexite, le lissage augmente considerablement le temps
d’evaluation (il n’a pas d’effet sur le temps d’apprentissage) : contrairement a la variante
non lissee, ce ne sont pas seulement les termes presents dans la requéte, aussi ceux du
document, voire de toute la collection, qui entrent en ligne de compte; aussi l’evaluation
d’une requete est-elle bien plus lente que sans lissage : entre 2 (CISI) et 20 (TIME, MED)
fois plus lents pour le lissage de Jelinek-Mercer, et entre 30 (MED) et 150 (CRAN) fois
plus lent avec la recherche en deux passes avec N = 3.

4. Figures 3 : sur des collections « semantiquement difﬁciles », les meilleurs noyaux PLSI
ont de meilleures performances que le modele BM25 : CISI, ou les requetes et les docu-
ments ne partagent que de rares termes (et donc particulierement utile pour mesurer dans
quelle mesure un modele de recherche est robuste a la synonymie.)5, MED (vocabulaire
specialise), et TREC-AP,

3http://xapian.org/

4http : //trec . ni st . gov/trec_eval/

5CISI est remarquable pour avoir des requétes censees retourner des documents avec lesquelles elles ne parta-
gent aucun terme signiﬁcatif.

0.4

0.3

0.2

 

0.1

KL

- LogL

-- ZDFIMH
~ ZH

¥+P+

0.0

_ II I I I I I
1 3 15 32 64 128

FIG. 1 — Exemple typique (ici sur CRAN)
qui montre comment la similarité SKL basée
sur P(w|d) dépasse 8LogL basée sur P(d, w).
Les composantes K? (ZH) et K EFIMH (ZD-
FIMH) des noyaux de Fisher sont également

J ean-Cédric Chappelier, Emmanuel Eckard

0.8
I

0.6
I

Precision
0.4

  

_9_

_A_.
+
x-

0.2

   

-9- WH32
--V-- ZH32

I I I I I I I I I I I
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

Recall

FIG. 2 — Courbes précision-rappel sur MED
pour BM25, K DF'M'H a |Z | :64 (DFIMH64),
K“ a |Z| =32 (H32), SKL a |Z| =128
(KL128), KS a |Z| =32 (WH32), et K? a
|Z| =32 (YH32).

représentées.

Les conclusions doivent étre plus nuancées pour MED : les différents modeles n’ont pas le
méme comportement a différentes valeurs de rappel (ﬁgure 2); certains sont meilleurs pour un
rappel bas et d’autres meilleurs a un rappel haut. Des mesures de performance globales comme
la MAP ou la R-précision ne rendent pas compte de ces subtilités.

5 Conclusions

Cet article apporte un modele de similarité pour PLSI théoriquement fondée évitant entierement
les écueils de la représentation des requétes; par ailleurs, il fournit une évaluation des perfor-
mances de PLSI sur une collection plus grande que les collections SMART sur lesquelles les
expériences ont été faites jusqu’a présent. Aux questions qui se posent, nous pouvons répondre :

1. que la nouvelle approche sans « folding-in » des requétes se compare favorablement aux
meilleures variantes du noyau de Fisher, particulierement pour les plus grands nombres
de catégories latentes;

2. et que ces modeles se comparent favorablement avec BM25 pour les collections seman-
tiquement difﬁciles comme CISI, MED et T REC—AP.

3. Figures 3 et 4 : le lissage de F(w|q) n’amé1iore les résultats dans aucun des cas testés.
Sur les huit variantes proposées, seule la similarité de Kullback-Leibler avec P(w|d) non
lissé est valable.

Ainsi, nous conﬁrmons expérimentalement que les modeles a catégories latentes comme PLSI
pourraient s’avérer intéressants pour la recherche d’information sur des collections de taille
raisonnable, mais sémantiquement difﬁciles, ou les requétes et les documents qui leur sont
pertinents ne partagent que peu de termes. Dans ces cas, il est recommandé d’utiliser K BF'M'H
ou SKL (Eq. 2) s’il est possible de faire toumer l’apprentissage avec un nombre sufﬁsant de

PLSI pour la recherche d’information

CACM CISI

 

E
E _
o‘ I" 2 _
/" o ,'
Z
.
9 _ E I.
o ’ 9
K’ 3- :
3 ‘ —e— H O -9- H
O - ¢— KL A A- KL
, + WDFIMH + WDFIMH
'. x- WH x- WH
8 _ A‘ 8 _
0' 0'
II I I I I I II I I I I I
1 B 16 32 64 128 1 B 16 32 64 128
GRAN MED

"2 _

o

"I _

o

 

0.2
0.2
P

0.1
IIII

FIMH * FIMH

IIII
§s%=
l>~ _____>_.< ‘N
§s%=

00
I
00

II I I I I I II I I I I I
1 8 16 32 64 128 1 8 16 32 64 128

TIME TREG-AP89_01XX

_ .+-.

 

75"
I"

“‘II>I__

0
I
HM
ss¢=
I
E
I

‘’-u..

II I I I I I
1 B 16 32 64 128

 

FIG. 3 — Résultats obtenus sur les 6 collections pour différents modeles : K H (H), SKL (KL),
K BFIMH (WDFIMH), et KB (WH). Les lignes horizontales représentent les performances de
BM25, qui ne dépend pas de |Z 

J ean-Cédric Chappelier, Emmanuel Eckard

O
V _ V _  
cs 0 O
0}
—e— 1—step
-4- 2—step. N=1
K‘?
3 — C5 — --+-- 2—step.N=2
--x-- 2—step.N=3
0 ,,.$
..~A_ X

“I _ N — '

Q O

O
.;-zu:>"'}-
.- -_ _ .;-:‘‘§:‘'’
6 _ O 4 "
Q=‘.:»-“’/-
01:‘
5’ IS-—-»&/
0

 

II I I I I I
1 8 1 6 32 64 128 1 8 1 6 32 64 128

I/<‘\IG. 4 - Exemple typique montrant (ici sur TIME) comment le lissage de J elinek-Mercer de
P(q|w) (a gauche) ou par le pseudo-feedback (a droite) dégradent les performances, compare a
la variante non lissée P(q|w) notée « 10 » a gauche, et « 1 step » a droite.

catégories latentes. SKL présente de plus l’avantage de ne pas demander de ré-apprentissage
pour la projection des requétes («folding in >>).

Toutefois, la conclusion globale est que PLSI n’est pas adapté a la recherche documentaire sur
de grandes collections : comme il comporte en parametre un modele des documents vus pendant
l’apprentissage, il est pas nature non génératif, et ne passe tout simplement pas a l’échelle
lorsque le nombre de documents atteint les dizaines de milliers. De plus, pour sophistiqué qu’il
soit, PLSI surpasse a peine le modele BM25, et cela au prix d’une complexité et d’un temps de
calcul rédhibitoires.

On peut spéculer que PLSI pourrait s’avérer signiﬁcativement meilleur que les modeles de
l’état de l’art en utilisant un bien plus grand nombre de catégories latentes, mais les limitations
induites par le nombre de parametres a apprendre rendent ces cas impossibles a calculer en
pratique. Il est fort probable qu’un tres grand |Z | améliore les performances de K Z ou de SKL,
mais l’apprentissage de tels modeles s’avere en pratique impossible, tout particulierement pour
les grandes collections pour lesquelles de tels |Z | seraient justement le plus appropriés.

Références

AHRENDT P., GOUTTE C. & LARSEN J . (2005). Co-occurrence models in music genre classiﬁcation.
In IEEE Int. Workshop on Machine Learning for Signal Processing.

BLEI D. & LAFFERTY J . (2007). A correlated topic model of Science. An. of App. Stat., 1(1), 17-35.
BLEI D. M., NG A. Y. & JORDAN M. I. (2003). Latent Dirichlet allocation. Journal of Machine
Learning Research, 3, 993-1022.

CHAPPELIER J .-C. & ECKARD E. (2009). Role de la matrice d’information et pondération des com-
posantes dans les noyaux de Fisher pour PLSI. In Acres de la Sixie‘me Conference francophone en
Recherche d’Information et Applications, p. 267-282 2 LSIS-USTV.

GAUSSIER E., GOUTTE C., POPAT K. & CHEN F. (2002). A hierarchical model for clustering and
categorising documents. In Proc. of 24th BCS-IRSG European Colloquium on IR Research, p. 229-247.

PLSI pour la recherche d’information

GEHLER P. V., HOLUB A. D. & WELLING M. (2006). The rate adapting Poisson model for informa-
tion retrieval and object recognition. In Proc. of the 23rd Int. Conf on Machine Learning, p. 337-344.
HINNEBURG A., GABRIEL H.-H. & GOHR A. (2007). Bayesian folding-in with Dirichlet kernels for
PLSI. In Proc. of the 7th IEEE Int. Conf on Data Mining, p. 499-504.

HOFMANN T. (1999). Probabilistic latent semantic indexing. In Proc. of 22th Annual Int. ACM SIGIR
Conf on Research and Development in Information Retrieval, p. 50-57.

HOFMANN T. (2000). Learning the similarity of documents 2 An information-geometric approach to
document retrieval and categorization. In Adv. in Neural Inf Proc. Sys. (NIPS), volume 12, p. 914-920.
HOFMANN T. (2001). Unsupervised learning by probabilistic latent semantic analysis. Machine Learn-
ing, 42(1), 177-196.

J IN X., ZHOU Y. & MOBASHER B. (2004). Web usage mining based on probabilistic latent semantic
analysis. In Proc. of 10th Int. Conf on Knowledge Discovery and Data Mining, p. 197-205.
LAFFERTY J . & ZHAI C. (2001). Document language models, query models, and risk minimization
for information retrieval. In Proc. of 24th Annual Int. Conference on Research and Development in
Information Retrieval (SIGIR), p. 111-119.

LAVRENKO V. & CROFT W. B. (2001). Relevance based language models. In Proc. of 24th Annual
Int. ACM SIGIR Conf on Research and Development in Information Retrieval, p. 120-127.

MEI Q. & ZHAI C. (2006). A mixture model for contextual text mining. In Proc. of 12th Int. Conf on
Knowledge Discovery and Data Mining, p. 649-655.

PONTE J . M. & CROFT W. B. (1998). A language modeling approach to information retrieval. In
Proc. of 21 st Int. Conf on Research and Development in Information Retrieval (SIGIR), p. 275-281.
POPESCUL A., UNGAR L. H., PENNOCK D. M. & LAWRENCE S. (2001). Probabilistic models for
uniﬁed collaborative and content-based recommendation in sparse-data environments. In Proc. of the
17th Conf in Uncertainty in Artificial Intelligence, p. 437-444.

ROBERTSON S. E., WALKER S., J ONES S., HANCOCK-BEAULIEU M. & GATFORD M. (1994). Okapi
at TREC-3. Proc. of the 3rd Text REtrieval Conf

STEYVERS M., SMYTH P., R0sEN-ZVI M. & GRIFFITHS T. (2004). Probabilistic author-topic models
for information discovery. In 10th Int. Conf on Knowledge Discovery and Data Mining, p. 306-315.
VINOKOUROV A. & GIROLAMI M. (2002). A probabilistic framework for the hierarchic organisation
and classiﬁcation of document collections. Joum. of Intelligent Information Systems, 18(2/3), 153-172.
WELLING M., CHEMUDUGUNTA C. & SUTTER N. (2008). Deterministic latent variable models and
their pitfalls. SIAM Conference on Data Mining SDM 2008.

WELLING M., ROSEN-ZVI M. & HINTON G. (2005). Exponential family harmoniums with an appli-
cation to information retrieval. In Ad. in Neural Inf Proc. Sys. (NIPS), volume 17, p. 1481-1488.

ZHAI C. (2008). Statistical language models for information retrieval a critical review. Found. Trends
Inf Retr, 2(3), 137-213.

ZHAI C. & LAFFERTY J . (2001). Model-based feedback in the language modeling approach to infor-
mation retrieval. II1 Proc. of 10th Int. Conf on Information and Knowledge Management (CIKM), p.
403-410.

ZHAI C. & LAFFERTY J . (2004). A study of smoothing methods for language models applied to
information retrieval. ACM Trans. Inf Syst., 22(2), 179-214.

