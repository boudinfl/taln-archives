<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Utiliser des sens de mots pour la segmentation th&#233;matique ?</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009 &#8211; Session posters , Senlis, 24&#8211;26 juin 2009
</p>
<p>Utiliser des sens de mots pour la segmentation th&#233;matique ?
</p>
<p>Olivier Ferret
CEA, LIST
</p>
<p>18 route du Panorama, BP6, Fontenay-aux-Roses, F-92265 France
olivier.ferret@cea.fr
</p>
<p>R&#233;sum&#233;. La segmentation th&#233;matique est un domaine de l&#8217;analyse discursive ayant donn&#233;
lieu &#224; de nombreux travaux s&#8217;appuyant sur la notion de coh&#233;sion lexicale. La plupart d&#8217;entre eux
n&#8217;exploitent que la simple r&#233;currence lexicale mais quelques uns ont n&#233;anmoins explor&#233; l&#8217;usage
de connaissances rendant compte de cette coh&#233;sion lexicale. Celles-ci prennent g&#233;n&#233;ralement
la forme de r&#233;seaux lexicaux, soit construits automatiquement &#224; partir de corpus, soit issus
de dictionnaires &#233;labor&#233;s manuellement. Dans cet article, nous examinons dans quelle mesure
une ressource d&#8217;une nature un peu diff&#233;rente peut &#234;tre utilis&#233;e pour caract&#233;riser la coh&#233;sion
lexicale des textes. Il s&#8217;agit en l&#8217;occurrence de sens de mots induits automatiquement &#224; partir
de corpus, &#224; l&#8217;instar de ceux produits par la t&#226;che &#171; Word Sense Induction and Discrimination &#187;
de l&#8217;&#233;valuation SemEval 2007. Ce type de ressources apporte une structuration des r&#233;seaux
lexicaux au niveau s&#233;mantique dont nous &#233;valuons l&#8217;apport pour la segmentation th&#233;matique.
</p>
<p>Abstract. Many topic segmenters rely on lexical cohesion. Most of them only exploit
lexical recurrence but some of them makes use of knowledge sources about lexical cohesion.
These sources are generally lexical networks built either by hand or automatically from corpora.
In this article, we study to what extent a new source of knowledge about lexical cohesion can
be used for topic segmentation. This source is a set of word senses that were automatically
discriminated from corpora, as the word senses resulting from the Word Sense Induction and
Discrimination task of the SemEval 2007 evaluation. Such a resource is a way to structurate
lexical networks at a semantic level. The impact of this structuring on topic segmentation is
evaluated in this article.
</p>
<p>Mots-cl&#233;s : Segmentation th&#233;matique, d&#233;sambigu&#239;sation s&#233;mantique.
Keywords: Topic segmentation, word sense disambiguation.
</p>
<p>1 Introduction
</p>
<p>Le travail que nous pr&#233;sentons dans cet article peut &#234;tre appr&#233;hend&#233; selon un double &#233;clairage.
Le plus &#233;vident est celui de la segmentation th&#233;matique, probl&#232;me d&#233;sormais classique consis-
tant &#224; d&#233;couper des textes en une suite de segments th&#233;matiquement homog&#232;nes. De ce point
de vue, ce travail explore l&#8217;int&#233;r&#234;t de l&#8217;utilisation pour cette t&#226;che d&#8217;une nouvelle source de
connaissances s&#233;mantiques, en l&#8217;occurrence des sens de mots induits &#224; partir de corpus1. Le se-
cond point de vue est celui des connaissances : les travaux sur la d&#233;sambigu&#239;sation s&#233;mantique
</p>
<p>1Nous parlerons ici de &#171; sens de mot &#187; afin de reprendre un vocable largement reconnu mais celui de &#171; contexte
d&#8217;usage &#187; utilis&#233; dans (V&#233;ronis, 2003) nous semble plus juste.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier Ferret
</p>
<p>ont fait &#233;merger la probl&#233;matique de la construction de r&#233;pertoires de sens &#224; partir de corpus afin
de pallier les insuffisances des dictionnaires traditionnels (Kilgarriff, 1997), au point de donner
lieu &#224; une &#233;valuation sp&#233;cifique au sein de SemEval 2007 (Agirre &amp; Soroa, 2007). L&#8217;utilisation
des sens de mots ainsi d&#233;finis, soit directement, soit par le biais de la d&#233;sambigu&#239;sation s&#233;man-
tique, reste n&#233;anmoins un champ &#224; peu pr&#232;s vierge que nous nous proposons d&#8217;explorer ici dans
le cadre de la segmentation th&#233;matique.
</p>
<p>La plupart des travaux dans le domaine de la segmentation th&#233;matique s&#8217;appuient sur les seules
caract&#233;ristiques intrins&#232;ques des documents : la r&#233;currence lexicale dans le cas de (Hearst,
1994), (Choi, 2000), (Utiyama &amp; Isahara, 2001), (Galley et al., 2003) ou plus r&#233;cemment (Ei-
senstein &amp; Barzilay, 2008) ; la pr&#233;sence de marques linguistiques pour (Passonneau &amp; Litman,
1997) ou (Galley et al., 2003). L&#8217;absence de recours &#224; des connaissances externes donne &#224; ces
m&#233;thodes un champ d&#8217;application en apparence large mais la r&#233;currence lexicale n&#8217;est un in-
dice th&#233;matique fiable que si les concepts du document consid&#233;r&#233; ne sont pas exprim&#233;s sous
des formes trop diverses (synonymes, etc.) et les marques linguistiques sont souvent peu nom-
breuses.
</p>
<p>Pour surmonter ces limitations, un certain nombre de syst&#232;mes exploitent des connaissances sur
les relations de coh&#233;sion lexicale, connaissances qui pr&#233;sentent elles aussi l&#8217;avantage d&#8217;une cer-
taine g&#233;n&#233;ralit&#233;. Elles prennent la forme d&#8217;un r&#233;seau lexical construit &#224; partir d&#8217;un dictionnaire
dans (Kozima, 1993), d&#8217;un th&#233;saurus dans (Morris &amp; Hirst, 1991), de relations issues de Word-
Net dans (Stokes, 2003) ou encore d&#8217;un large ensemble de cooccurrences lexicales dans (Choi
et al., 2001). D&#8217;une certaine fa&#231;on, ces connaissances permettent aux syst&#232;mes de segmentation
th&#233;matique de d&#233;tecter les r&#233;currences &#224; un niveau plus conceptuel en leur donnant acc&#232;s &#224; des
relations d&#8217;&#233;quivalence lexicale. Elles sont n&#233;anmoins d&#233;pourvues de structuration th&#233;matique.
</p>
<p>Ce dernier point peut &#234;tre r&#233;solu en exploitant des connaissances sur les th&#232;mes susceptibles
d&#8217;&#234;tre rencontr&#233;s dans les documents analys&#233;s. Ces connaissances sont g&#233;n&#233;ralement construites
automatiquement &#224; partir d&#8217;un ensemble de documents repr&#233;sentatifs des th&#232;mes consid&#233;r&#233;s,
comme dans (Yamron et al., 1998) ou (Beeferman et al., 1999). L&#8217;am&#233;lioration de la pr&#233;cision
ainsi obtenue se fait n&#233;anmoins au d&#233;triment de la couverture des syst&#232;mes consid&#233;r&#233;s. Enfin,
des syst&#232;mes hybrides combinant diff&#233;rentes approches parmi celles pr&#233;sent&#233;es ci-dessus ont
&#233;galement &#233;t&#233; d&#233;velopp&#233;s : (Jobbins &amp; Evett, 1998) associe ainsi la r&#233;currence lexicale, l&#8217;uti-
lisation de cooccurrences et celle d&#8217;un th&#233;saurus ; (Beeferman et al., 1999) s&#8217;appuie &#224; la fois
sur une mod&#233;lisation statistique des th&#232;mes et sur l&#8217;utilisation de marques discursives ; (Galley
et al., 2003) se fonde conjointement sur la r&#233;currence lexicale et sur des marques discursives.
Dans ce contexte, le travail que nous pr&#233;sentons dans cet article se range parmi les approches
reposant sur des connaissances relatives &#224; la coh&#233;sion lexicale des textes. Plus pr&#233;cis&#233;ment, il
int&#232;gre l&#8217;utilisation de sens de mots induits &#224; partir de corpus au sein de F06 (Ferret, 2006), un
environnement d&#233;di&#233; &#224; la segmentation th&#233;matique fond&#233; sur la coh&#233;sion lexicale, et cherche
ainsi &#224; situer l&#8217;int&#233;r&#234;t de ce type de connaissances par rapport &#224; l&#8217;exploitation de la r&#233;currence
lexicale ou de cooccurrences lexicales. Nous d&#233;buterons l&#8217;expos&#233; de ce travail par un aper&#231;u de
la source de connaissances ainsi utilis&#233;e.
</p>
<p>2 Des sens de mots construits &#224; partir de textes
</p>
<p>Du point de vue de la caract&#233;risation des sens de mots obtenus, il est possible de distinguer deux
grandes m&#233;thodes de construction &#224; partir d&#8217;un corpus :</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Utiliser des sens de mots pour la segmentation th&#233;matique ?
</p>
<p>&#8211; les m&#233;thodes rassemblant les mots en classes d&#8217;&#233;quivalence selon un principe de distribution-
nalit&#233;, &#224; l&#8217;instar de (Pantel &amp; Lin, 2002). Dans ce cas de figure, les diff&#233;rents sens d&#8217;un mot
correspondent aux diff&#233;rents classes auxquelles il appartient. Un sens de mot est ici l&#8217;&#233;qui-
valent d&#8217;un synset de WordNet ;
</p>
<p>&#8211; les m&#233;thodes discriminant les sens d&#8217;un mot en op&#233;rant une classification non supervis&#233;e de
ses cooccurrents. Chaque sens de mot est ainsi d&#233;fini par un sous-ensemble des cooccurrents
du mot consid&#233;r&#233;. C&#8217;est l&#8217;approche retenue dans (V&#233;ronis, 2003) mais &#233;galement pour les
sens de mots utilis&#233;s ici (Ferret, 2004).
</p>
<p>Sans entrer dans les d&#233;tails, explicit&#233;s dans (Ferret, 2004), la construction des sens de mots
utilis&#233;s ici s&#8217;effectue en deux grandes &#233;tapes. La premi&#232;re consiste &#224; construire &#224; partir d&#8217;un
corpus un r&#233;seau de cooccurrences lexicales en utilisant une fen&#234;tre graphique d&#8217;une taille assez
large. 24 mois du journal Le Monde ont ici &#233;t&#233; utilis&#233;s avec une fen&#234;tre de 20 mots pleins. La
</p>
<p>Sens D&#233;finition (cooccurrents repr&#233;sentatifs du sens)
barrage de protestation conducteur, trafic, routier, route, camion, chauffeur, voiture, blo-quer, poids_lourd
</p>
<p>barrage hydraulique eau, m&#232;tre, lac, pluie, rivi&#232;re, bassin, fleuve, site, poisson, affluent,
montagne, crue, vall&#233;e
</p>
<p>barrage fronti&#232;re casque_bleu, soldat, tir, convoi, milicien, blind&#233;, milice, a&#233;roport,bless&#233;, incident, croate
TAB. 1 &#8211; Sens discrimin&#233;s pour le mot barrage &#224; partir du journal Le Monde
</p>
<p>seconde &#233;tape est une classification non supervis&#233;e des cooccurrents de chaque mot dont on
souhaite discriminer les sens. Cette classification est plus pr&#233;cis&#233;ment appliqu&#233;e au sous-graphe
du r&#233;seau de cooccurrences d&#233;limit&#233; par les cooccurrents du mot cible. La Figure 1 montre ce
sous-graphe pour le mot barrage. La discrimination des sens se fait donc par l&#8217;identification des
composantes de forte densit&#233; dans ce sous-graphe.
</p>
<p>Cette identification est r&#233;alis&#233;e en dans le cas pr&#233;sent par l&#8217;algorithme Shared Nearest Neighbors
(Ert&#246;z et al., 2001). Cet algorithme se d&#233;compose en deux grandes phases. La premi&#232;re vise &#224;
identifier les germes des futures classes (ici des sens) en commen&#231;ant par &#171; &#233;claircir &#187; le graphe
en ne conservant pour chaque n&#339;ud que ses k plus proches voisins2, puis en le transposant en
un graphe dans lequel la pond&#233;ration d&#8217;un arc correspond au nombre des voisins partag&#233;s par
les n&#339;uds qu&#8217;il relie. Un seuil sur la distribution de ces valeurs permet d&#8217;identifier des liens
dits forts. Chaque n&#339;ud se voit associer son nombre de liens forts et cette valeur est utilis&#233;e
pour simultan&#233;ment s&#233;lectionner les germes des futures classes et &#233;liminer les n&#339;uds les moins
repr&#233;sentatifs. La seconde grande phase de l&#8217;algorithme consiste &#224; rattacher les n&#339;uds restants
aux germes des classes. Un premier rattachement au germe le plus proche est r&#233;alis&#233; sous condi-
tion d&#8217;une similarit&#233; suffisamment importante avec lui. Lors de cette &#233;tape, des germes peuvent
ainsi s&#8217;associer, impliquant ainsi la fusion des classes qu&#8217;ils repr&#233;sentent. Une seconde &#233;tape
de rattachement permet d&#8217;associer les n&#339;uds restants aux classes en prenant en compte leur
proximit&#233; par rapport &#224; la globalit&#233; de chaque classe form&#233;e.
</p>
<p>Le Tableau 1 donne les sens discrimin&#233;s selon cette m&#233;thode pour le mot barrage &#224; partir du
graphe de coocurrents de la Figure 1. Plus globalement, le r&#233;pertoire de sens obtenu pour le
Fran&#231;ais se compose de 7 373 lemmes avec une moyenne de 2,8 sens par lemme et un nombre
</p>
<p>2Les valeurs de similarit&#233; dans le sous-graphe des cooccurrents correspondent &#224; une estimation de l&#8217;information
mutuelle dans le r&#233;seau de cooccurrences.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier Ferret
</p>
<p>amont
</p>
<p>fleuve
</p>
<p>kilom&#232;tre
</p>
<p>aval
</p>
<p>eau
</p>
<p>bassin
</p>
<p>rivi&#232;re m&#232;tre
pollution
</p>
<p>pont
</p>
<p>acc&#232;s
</p>
<p>autoroute
</p>
<p>blocage
</p>
<p>barrer
</p>
<p>convoi
</p>
<p>bloquer
</p>
<p>a&#233;roport
</p>
<p>blind&#233;
</p>
<p>circulation
</p>
<p>filtrer
</p>
<p>routier
</p>
<p>affluent
</p>
<p>noyer
</p>
<p>crue
</p>
<p>poisson
</p>
<p>pluie
</p>
<p>plaine
</p>
<p>m&#232;tre_cube
</p>
<p>saumon
</p>
<p>escargot
</p>
<p>blocus
</p>
<p>forcer
</p>
<p>approvisionnement
</p>
<p>lev&#233;e
</p>
<p>croate
</p>
<p>couper
</p>
<p>milice
</p>
<p>coordination
</p>
<p>lever
</p>
<p>car
</p>
<p>bless&#233;
</p>
<p>conducteur
</p>
<p>camion
</p>
<p>chauffeur
</p>
<p>manifestant
police
</p>
<p>route
</p>
<p>v&#233;hicule
</p>
<p>touriste
</p>
<p>voiture
</p>
<p>am&#233;nagement
</p>
<p>automobiliste
</p>
<p>axe
</p>
<p>vall&#233;e
</p>
<p>trafic
</p>
<p>poids_lourd
</p>
<p>agriculteur
</p>
<p>forces_de_lordre
</p>
<p>hectare
</p>
<p>protester
</p>
<p>incident
</p>
<p>irrigation
</p>
<p>s&#233;cheresse
</p>
<p>pr&#233;fecture
</p>
<p>permis
</p>
<p>chantier
</p>
<p>construction
</p>
<p>pr&#233;fet
</p>
<p>site
</p>
<p>casque_bleu
</p>
<p>&#233;vacuer
</p>
<p>apr&#232;s&#8722;midi
</p>
<p>calme
</p>
<p>matin&#233;e
</p>
<p>h&#233;licopt&#232;re
</p>
<p>tir matin
</p>
<p>irriguer
</p>
<p>montagne
</p>
<p>sud&#8722;est
</p>
<p>aube
</p>
<p>arm&#233;
</p>
<p>soldat
combattant
</p>
<p>incendier
</p>
<p>gendarme
</p>
<p>milicien
</p>
<p>cheval
</p>
<p>sauvage
</p>
<p>obstacle
</p>
<p>sauter
</p>
<p>&#233;cologiste
</p>
<p>d&#233;placer
</p>
<p>construire
</p>
<p>chauffeur_routier
</p>
<p>p&#234;che
</p>
<p>alimenter
</p>
<p>r&#233;servoir
</p>
<p>&#233;lectricit&#233;
&#233;lectrique
</p>
<p>division
</p>
<p>match
</p>
<p>hydro&#233;lectrique
</p>
<p>tonne
</p>
<p>lac
</p>
<p>ing&#233;nieur
</p>
<p>paralyser
</p>
<p>front_national
</p>
<p>pierre
</p>
<p>eau_potable
</p>
<p>hydraulique
</p>
<p>heurter
</p>
<p>mine
</p>
<p>centrale
</p>
<p>d&#233;clencher
</p>
<p>perturber
</p>
<p>camionneur
</p>
<p>franchir
</p>
<p>dresser
</p>
<p>endroit
</p>
<p>retenue
</p>
<p>hauteur
</p>
<p>interrompre
</p>
<p>FIG. 1 &#8211; Cooccurrents du mot barrage (ceux impliqu&#233;s dans ses 3 sens apparaissant en rouge)
</p>
<p>moyen de mots formant la d&#233;finition d&#8217;un sens &#233;gal &#224; 16,1. Le vocabulaire initial &#233;tait constitu&#233;
de 17 261 lemmes mais pour un peu plus de la moiti&#233; des lemmes, la densit&#233; des liens dans le
sous-graphe des cooccurrents n&#8217;&#233;tait pas assez forte pour former des classes significatives.
</p>
<p>3 F06 : un cadre pour la segmentation th&#233;matique
</p>
<p>3.1 Principes
</p>
<p>Apr&#232;s la pr&#233;sentation rapide de la source de connaissances &#224; tester, nous allons maintenant
pr&#233;senter F06 (Ferret, 2006), le cadre retenu pour son application &#224; la segmentation th&#233;matique.
F06 reprend les principes propos&#233;s par Hearst dans TextTiling (Hearst, 1994) avec un processus
de segmentation articul&#233; en trois grandes parties :
</p>
<p>&#8211; le pr&#233;traitement linguistique des documents ;
&#8211; l&#8217;&#233;valuation de la coh&#233;sion lexicale au sein du document ;
&#8211; l&#8217;identification des changements de th&#232;me.
</p>
<p>Le pr&#233;traitement linguistique, qui s&#8217;appuie sur l&#8217;outil TreeTagger, d&#233;coupe les documents en
phrases et repr&#233;sente chacune d&#8217;elles comme la s&#233;quence de ses mots pleins normalis&#233;s, c&#8217;est-
&#224;-dire ses noms (communs et propres), ses verbes et ses adjectifs. L&#8217;&#233;valuation de la coh&#233;sion
lexicale s&#8217;appuie comme dans TextTiling sur l&#8217;utilisation d&#8217;une fen&#234;tre glissante de taille fixe.
Cette fen&#234;tre se d&#233;place sur le texte de phrase en phrase. &#192; chaque station de cette fen&#234;tre,
la coh&#233;sion lexicale est &#233;valu&#233;e en son sein et affect&#233;e &#224; la fin de phrase sur laquelle elle est
centr&#233;e. Le r&#233;sultat final est une courbe de coh&#233;sion couvrant l&#8217;ensemble du document.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Utiliser des sens de mots pour la segmentation th&#233;matique ?
</p>
<p>La troisi&#232;me partie de l&#8217;algorithme s&#8217;inspire quant &#224; elle de son homologue dans le syst&#232;me
LCseg (Galley et al., 2003). Elle comprend elle-m&#234;me trois &#233;tapes :
&#8211; le calcul d&#8217;un score &#233;valuant la probabilit&#233; pour chaque minimum de la courbe de coh&#233;sion
</p>
<p>de correspondre &#224; un changement de th&#232;me ;
&#8211; la suppression des candidats segments de trop petite taille ;
&#8211; la s&#233;lection des bornes de segments th&#233;matiques.
</p>
<p>Le calcul du score initial d&#8217;un minimum commence par la recherche de la paire de maxima g
et d qui l&#8217;entourent. En notant, CL(x) la valeur de la coh&#233;sion lexicale &#224; la position x, le score
d&#8217;un minimum m est donn&#233; par :
</p>
<p>score(m) =
CL(g) + CL(d)&#8722; 2 &#183; CL(m)
</p>
<p>2
(1)
</p>
<p>Ce score, compris entre 0 et 1, est d&#8217;autant plus &#233;lev&#233; que la diff&#233;rence entre le minimum consi-
d&#233;r&#233; et les maxima qui l&#8217;entourent est plus importante. Il favorise ainsi comme changements
de th&#232;me potentiels les minima caract&#233;ris&#233;s par une chute tr&#232;s nette de la coh&#233;sion lexicale. La
suppression des candidats segments trop petits s&#8217;effectue quant &#224; elle par une simple comparai-
son par rapport &#224; un seuil de r&#233;f&#233;rence : les minima se trouvant &#224; 2 phrases au plus du minimum
qui les pr&#233;c&#232;de sont &#233;limin&#233;s en tant que possibles changements de th&#232;me. Finalement, la s&#233;lec-
tion des bornes de segments th&#233;matiques est r&#233;alis&#233;e par l&#8217;utilisation d&#8217;un seuil s&#8217;adaptant &#224; la
distribution des scores des minima. Un minimum m est ainsi retenu comme borne de segment
si score(m) &gt; &#181;&#8722;&#945; &#183; &#963;, o&#249; &#181; correspond &#224; la moyenne des scores de minima, &#963;, &#224; l&#8217;&#233;cart-type
de ces scores et &#945;, &#224; un coefficient de modulation.
</p>
<p>3.2 &#201;valuation de la coh&#233;sion lexicale
L&#8217;&#233;valuation de la coh&#233;sion lexicale est l&#8217;&#233;tape la plus importante du processus de segmentation
dans F06 et c&#8217;est &#224; son niveau que sont introduites les diff&#233;rentes sources de coh&#233;sion lexicale
&#224; tester. Globalement, cette &#233;valuation est r&#233;alis&#233;e suivant le principe propos&#233; dans (Jobbins &amp;
Evett, 1998) : la coh&#233;sion est mesur&#233;e par l&#8217;application du coefficient de Dice entre les vecteurs
repr&#233;sentant les deux moiti&#233;s de la fen&#234;tre glissante. Dans le cas de la r&#233;currence lexicale, ce
principe est repris strictement : si Fg d&#233;signe le vocabulaire de la moiti&#233; gauche de la fen&#234;tre et
Fd, celui de sa moiti&#233; droite, la coh&#233;sion au sein de la fen&#234;tre est donn&#233;e par :
</p>
<p>cohe&#769;sion_re&#769;c(x) =
2 &#183; card(Fg &#8745; Fd)
</p>
<p>card(Fg) + card(Fd)
(2)
</p>
<p>Lorsque les relations de coh&#233;sion ne sont pas des relations de r&#233;currence3, la mesure utilis&#233;e
est une extension du coefficient de Dice. Dans chaque volet de la fen&#234;tre, le nombre de mots
li&#233;s par ces relations de coh&#233;sion avec les mots de l&#8217;autre volet de la fen&#234;tre est d&#233;termin&#233; en
excluant les mots d&#233;j&#224; impliqu&#233;s dans des relations de r&#233;currence. Les contributions des deux
volets de la fen&#234;tre sont ensuite somm&#233;es et ramen&#233;es au nombre total de mots dans la fen&#234;tre4 :
</p>
<p>cohe&#769;sion_rel(x) =
card(Mrel(g)&#8722;Mre&#769;c) + card(Mrel(d)&#8722;Mre&#769;c)
</p>
<p>card(Fg) + card(Fd)
(3)
</p>
<p>3Plus g&#233;n&#233;ralement, on parlera de relations d&#8217;&#233;galit&#233; ou d&#8217;&#233;quivalence entre mots, se limitant ici &#224; la r&#233;currence.
4Dans le cas du coefficient de Dice, la contribution de chaque volet correspond &#224; leur intersection.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier Ferret
</p>
<p>o&#249; Mrel(x) repr&#233;sente les mots du volet x de la fen&#234;tre (gauche ou droit) s&#233;lectionn&#233;s sur la
base des relations de coh&#233;sion lexicale et Mre&#769;c, les mots impliqu&#233;s dans une relation de r&#233;-
currence. La coh&#233;sion globale au sein de la fen&#234;tre est finalement donn&#233;e par la somme de
cohe&#769;sion_re&#769;c(x) et des valeurs de cohe&#769;sion_rel(x) correspondant aux diff&#233;rents types de rela-
tions de coh&#233;sion distingu&#233;s.
</p>
<p>4 Utiliser des sens de mots pour la segmentation th&#233;matique
</p>
<p>Comme nous l&#8217;avons vu &#224; la section pr&#233;c&#233;dente, l&#8217;int&#233;gration au sein de F06 d&#8217;une nouvelle
source de connaissances sur la coh&#233;sion lexicale se fait au niveau de l&#8217;&#233;valuation de la coh&#233;-
sion de la fen&#234;tre glissante d&#8217;analyse et plus pr&#233;cis&#233;ment lors de la d&#233;termination des mots de
chacun de ses volets li&#233;s aux mots de l&#8217;autre volet. Dans le cas des sens de mots pr&#233;sent&#233;s &#224; la
Section 2, la m&#233;thode d&#8217;int&#233;gration en apparence la plus directe serait une forme d&#8217;extension de
la r&#233;currence lexicale : au lieu de se focaliser sur la r&#233;p&#233;tition des mots, elle se focaliserait sur la
r&#233;p&#233;tition des sens de mots. Cette m&#233;thode impose de r&#233;aliser une d&#233;sambigu&#239;sation s&#233;mantique
des textes. Sachant que dans un texte, il est peu fr&#233;quent qu&#8217;un m&#234;me mot soit utilis&#233; avec deux
sens diff&#233;rents pour faire r&#233;f&#233;rence &#224; deux th&#232;mes diff&#233;rents, il appara&#238;t probable que le gain
de pr&#233;cision esp&#233;r&#233; du fait de l&#8217;utilisation de sens de mots soit en pratique effac&#233; par le taux
d&#8217;erreur du processus de d&#233;sambigu&#239;sation s&#233;mantique.
</p>
<p>FIG. 2 &#8211; Utilisation des sens de mots pour l&#8217;&#233;valuation de la coh&#233;sion lexicale
</p>
<p>Nous avons donc opt&#233; pour une solution plus souple dans laquelle l&#8217;identification des sens de
mots entre les deux volets de la fen&#234;tre d&#8217;analyse ne passe pas par la pr&#233;sence explicite du
m&#234;me sens pour un mot donn&#233; dans ces deux volets mais par le fait qu&#8217;un lien peut &#234;tre &#233;tabli
entre les deux volets si l&#8217;un d&#8217;eux contient un sens d&#8217;un mot et l&#8217;autre un nombre significatif
d&#8217;&#233;l&#233;ments de d&#233;finition de ce sens. Ainsi que l&#8217;illustre la Figure 2, si l&#8217;un des volets de la fen&#234;tre
contient le mot barrage avec le sens barrage-hydraulique et que l&#8217;autre volet contient les mots
eau, montagne et rivi&#232;re, tous trois faisant partie de la d&#233;finition du sens barrage-hydraulique
(cf. Tableau 1), nous faisons l&#8217;hypoth&#232;se de la pr&#233;sence d&#8217;un lien de coh&#233;sion entre les deux
volets de la fen&#234;tre, lien sous-tendu par la co-pr&#233;sence, l&#8217;une explicite, l&#8217;autre implicite, du sens
barrage hydraulique.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Utiliser des sens de mots pour la segmentation th&#233;matique ?
</p>
<p>Dans le cadre de F06, et plus pr&#233;cis&#233;ment de l&#8217;&#233;quation 3, l&#8217;identification d&#8217;un tel lien se traduit
par l&#8217;ajout des mots de la d&#233;finition pr&#233;sents dans un volet de la fen&#234;tre &#224; l&#8217;ensemble Mrel(x)
associ&#233; &#224; ce volet et l&#8217;ajout du mot d&#233;fini &#224; l&#8217;ensemble Mrel(x) de l&#8217;autre volet. En pratique,
ce m&#233;canisme est d&#233;clench&#233; d&#232;s lors qu&#8217;au moins 2 mots de la d&#233;finition d&#8217;un sens de mot
sont pr&#233;sents dans un volet de la fen&#234;tre. Lorsque la discrimination de sens ne produit pas de
r&#233;sultat pour un mot, une proc&#233;dure de rattrapage est appliqu&#233;e pour maximiser la d&#233;tection des
relations de coh&#233;sion : le mot est suppos&#233; n&#8217;avoir qu&#8217;un seul sens, d&#233;fini par ses cooccurrents
dans le r&#233;seau de cooccurrences initialement utilis&#233; pour discriminer les sens de mots.
</p>
<p>Le m&#233;canisme d&#8217;int&#233;gration d&#233;crit ci-dessus repose sur la possibilit&#233; d&#8217;identifier le sens des
mots au sein de la fen&#234;tre d&#8217;analyse. Pour ce faire, les mots de chacun de ses deux volets
sont d&#233;sambigu&#239;s&#233;s en prenant comme contexte les mots du volet dans lequel ils se trouvent.
Cette d&#233;sambigu&#239;sation est r&#233;alis&#233;e selon une approche de type Lesk : le recouvrement entre le
contenu du volet de la fen&#234;tre dans lequel un mot se trouve et la d&#233;finition de chacun de ses
sens est &#233;valu&#233; et le sens retenu est celui pour lequel ce recouvrement est le plus important. Plus
pr&#233;cis&#233;ment, ce recouvrement est &#233;valu&#233; par la mesure Cosinus.
</p>
<p>5 &#201;valuation
5.1 M&#233;thodologie
</p>
<p>L&#8217;objectif de l&#8217;&#233;valuation men&#233;e dans ce travail &#233;tant de d&#233;terminer l&#8217;int&#233;r&#234;t de l&#8217;utilisation de
sens de mots comme source de coh&#233;sion lexicale dans F06, nous reprendrons le m&#234;me cadre
d&#8217;&#233;valuation que celui d&#233;velopp&#233; pour F06. Celui-ci s&#8217;inspire de la d&#233;sormais classique m&#233;thode
d&#8217;&#233;valuation propos&#233;e par Choi dans (Choi, 2000). Cette m&#233;thode est fond&#233;e sur la constitution
d&#8217;un corpus d&#8217;&#233;valuation compos&#233; de morceaux de documents de taille variable coll&#233;s les uns
&#224; la suite des autres. L&#8217;objectif pour le segmenteur &#233;valu&#233; est de retrouver les fronti&#232;res des
morceaux de documents. Dans (Ferret, 2006), nous avons propos&#233; une adaptation de cette pro-
c&#233;dure visant &#224; contr&#244;ler plus pr&#233;cis&#233;ment sa dimension th&#233;matique, ce qui permet d&#8217;ailleurs de
se rapprocher de conditions plus r&#233;alistes d&#8217;apr&#232;s les r&#233;sultats obtenus. Au lieu de tirer chaque
extrait d&#8217;un document diff&#233;rent, nous n&#8217;utilisons que deux documents. Chacun d&#8217;entre eux est
divis&#233; comme dans le cas de Choi en segments de 3 &#224; 11 phrases et le document d&#8217;&#233;valuation
est constitu&#233; en prenant, &#224; partir du d&#233;but des documents, alternativement un segment dans un
des deux documents et le suivant dans l&#8217;autre et ce, jusqu&#8217;&#224; obtenir 10 segments ou jusqu&#8217;&#224; ce
que le processus de construction atteigne la fin d&#8217;un des deux documents.
</p>
<p>Pour nous assurer que deux segments cons&#233;cutifs font r&#233;f&#233;rence &#224; deux th&#232;mes diff&#233;rents et
que le changement de th&#232;me entre les deux est effectif, les deux documents sont s&#233;lectionn&#233;s de
mani&#232;re &#224; appartenir &#224; des th&#233;matiques diff&#233;rentes. Pour ce faire, nous nous sommes appuy&#233;s sur
les donn&#233;es constitu&#233;es pour l&#8217;&#233;valuation CLEF sur la recherche d&#8217;information multilingue. Les
documents source utilis&#233;s pour r&#233;aliser notre corpus &#233;taient ainsi des documents issus du corpus
CLEF pour lesquels nous disposions d&#8217;un jugement de pertinence par rapport &#224; un des topics
d&#8217;interrogation d&#233;finis pour l&#8217;&#233;valuation. Chaque document de notre corpus a ainsi &#233;t&#233; construit
&#224; partir de deux documents du corpus CLEF jug&#233;s pertinents pour deux topics diff&#233;rents. Nous
avons ainsi constitu&#233; un corpus d&#8217;&#233;valuation de 100 documents construits &#224; partir de 11 topics
et de documents issus de deux ans du journal Le Monde.
Classiquement, nous avons utilis&#233; la mesure d&#8217;erreur Pk (Beeferman et al., 1999) pour &#233;valuer</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier Ferret
</p>
<p>la qualit&#233; des r&#233;sultats des segmenteurs. Pk &#233;value la probabilit&#233; que deux mots choisis al&#233;a-
toirement dans un document et s&#233;par&#233;s par k mots soient jug&#233;s comme appartenant au m&#234;me
segment alors qu&#8217;ils sont dans des segments diff&#233;rents (faux n&#233;gatif) ou qu&#8217;ils soient jug&#233;s
comme appartenant &#224; des segments diff&#233;rents alors qu&#8217;ils sont dans le m&#234;me (fausse alarme). k
est &#233;gal &#224; la moiti&#233; de la taille moyenne en mots des segments au niveau du corpus de r&#233;f&#233;rence.
L&#8217;objectif est de minimiser Pk. WindowDiff (Pevzner &amp; Hearst, 2002), dont nous donnons aussi
les r&#233;sultats, est une variante de Pk prenant en compte le nombre de fronti&#232;res de segments
s&#233;parant deux mots situ&#233;s dans des segments diff&#233;rents.
</p>
<p>5.2 R&#233;sultats et discussion
</p>
<p>Le Tableau 2 donne les r&#233;sultats obtenus par les segmenteurs test&#233;s dans le cadre F06 sur le
corpus d&#233;crit &#224; la Section 5.1 mais &#233;galement les r&#233;sultats sur ce m&#234;me corpus de m&#233;thodes
de r&#233;f&#233;rence : U00 est ainsi la m&#233;thode d&#233;crite dans (Utiyama &amp; Isahara, 2001), C99, celle
propos&#233;e dans (Choi, 2000) et LCseg est pr&#233;sent&#233;e dans (Galley et al., 2003). TextTiling* est
une variante de TextTiling dans laquelle la troisi&#232;me &#233;tape d&#8217;identification des changements de
th&#232;me est reprise de (Galley et al., 2003).
Au sein de F06, F06R s&#8217;appuie sur la seule r&#233;currence lexicale. F06C (Ferret, 2006) met en
&#339;uvre l&#8217;utilisation de relations de cooccurrence lexicale au sein de F06 en s&#8217;appuyant sur
l&#8217;&#233;quation 3 : si un mot m d&#8217;un volet de la fen&#234;tre d&#8217;analyse est li&#233; &#224; un nombre minimal
(en l&#8217;occurrence 2) de mots de son autre volet par des relations de cooccurrence d&#8217;un niveau de
coh&#233;sion suffisamment haut, ces cooccurrents de m sont ajout&#233;s &#224; l&#8217;ensemble Mrel(x) associ&#233;
au volet de la fen&#234;tre o&#249; ils apparaissent. Pour les segmenteurs exploitant des sens de mots, 2
syst&#232;mes ont &#233;t&#233; test&#233;s. F06WS correspond strictement au descriptif de la Section 4 tandis que
F06WSr est une variante sans d&#233;sambigu&#239;sation s&#233;mantique : les mots dans un des volets de la
fen&#234;tre peuvent correspondre &#224; l&#8217;un quelconque des sens de l&#8217;un des mots de l&#8217;autre volet.
</p>
<p>Les sens d&#8217;un mot pouvant &#234;tre vus comme une forme de structuration de ses cooccurrents,
F06WS et F06Wr se comparent naturellement &#224; F06C, F06R servant de r&#233;f&#233;rence basse. Pour
chaque r&#233;sultat de ces m&#233;thodes, nous donnons donc le degr&#233; de signification p de sa diff&#233;-
rence avec F06R et F06C, niveau &#233;valu&#233; gr&#226;ce &#224; un test de Student unilat&#233;ral dont les valeurs
inf&#233;rieures &#224; 0,05 sont consid&#233;r&#233;es comme significatives (en gras).
</p>
<p>syst&#232;mes Pk (%) WindowDiff (%)
erreur p(F06R) p(F06C) erreur p(F06R) p(F06C)
</p>
<p>U00 25,91 0,003 1,3e-07 27,42 0,799 0,032
C99 27,57 4,2e-05 3,6e-10 35,42 8,6e-07 6,5e-13
</p>
<p>TextTiling* 21,08 0,699 0,037 27,43 0,803 0,032
LCseg 20,55 0,439 0,111 28,31 0,767 0.007
F06R 21,58 / 6,5e-05 27,83 / 4,8e-06
F06C 16,48 6,5e-05 / 20,94 4,8e-06 /
</p>
<p>F06WSr 18,50 0,015 0,10 23,14 0,002 0,11
F06WS 18,17 0,006 0,16 23,20 0,002 0,12
</p>
<p>TAB. 2 &#8211; R&#233;sultats des diff&#233;rents segmenteurs test&#233;s sur le corpus de la Section 5.1
</p>
<p>Le premier constat que l&#8217;on peut tirer de l&#8217;analyse de ce tableau est que globalement, l&#8217;apport
de connaissances externes sur la coh&#233;sion lexicale, que ce soit sous la forme de cooccurrences</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Utiliser des sens de mots pour la segmentation th&#233;matique ?
</p>
<p>lexicales ou de sens de mots, repr&#233;sente un atout ind&#233;niable puisque les valeurs de Pk et de
WindowDiff sont nettement meilleures pour les m&#233;thodes utilisant ces connaissances (F06C,
F06WS et F06WSr) que pour celles n&#8217;exploitant que la r&#233;currence lexicale et ce, de fa&#231;on
statistiquement significative dans la plupart des cas.
</p>
<p>Concernant plus sp&#233;cifiquement les sens de mots, cette &#233;valuation fait appara&#238;tre que si leur
utilisation permet d&#8217;am&#233;liorer les r&#233;sultats par rapport &#224; F06R, elle ne permet pas en revanche
pas d&#8217;obtenir de progr&#232;s vis-&#224;-vis de l&#8217;utilisation de cooccurrences lexicales. Les r&#233;sultats avec
les sens de mots sont m&#234;me moins bons mais la diff&#233;rence n&#8217;est pas statistiquement significative.
Les deux variantes test&#233;es, F06WS et F06WSr, sont &#224; cet &#233;gard comparables, sans diff&#233;rence
significative sur le plan statistique.
</p>
<p>Ce r&#233;sultat est d&#233;cevant dans la mesure o&#249; les sens de mots utilis&#233;s ici, bien que proches des
relations de cooccurrence de par leur d&#233;finition, repr&#233;sentent un degr&#233; de structuration sup&#233;-
rieur des connaissances, degr&#233; dont on pourrait attendre un impact positif sur la pr&#233;cision de
la segmentation. M&#234;me s&#8217;il est assez difficile d&#8217;analyser dans le d&#233;tail les causes de ces r&#233;sul-
tats, il est probable que le processus de structuration des cooccurrents intervenant lors de la
discrimination des sens de mots provoque une perte d&#8217;informations de coh&#233;sion lexicale. Cette
perte peut avoir pour origine &#224; la fois l&#8217;&#233;limination de certains cooccurrents jug&#233;s sans doute
&#224; tort non significatifs et le fait que la m&#233;thode de clustering utilis&#233;e est de type &#171; hard cluste-
ring &#187;, conduisant &#224; construire des sens sans aucun partage des mots constituant leur d&#233;finition.
Cette perte d&#8217;informations masque ainsi les gains potentiellement apport&#233;s par une plus grande
structuration des connaissances.
</p>
<p>6 Conclusion et perspectives
</p>
<p>Dans cet article, nous avons &#233;tudi&#233; l&#8217;int&#233;r&#234;t de l&#8217;utilisation de sens de mots discrimin&#233;s &#224; partir
de corpus pour la segmentation th&#233;matique de textes. Cette &#233;tude a &#233;t&#233; r&#233;alis&#233;e en s&#8217;appuyant
sur F06, un cadre d&#8217;&#233;tude de la segmentation th&#233;matique fond&#233;e sur la coh&#233;sion lexicale. Les
r&#233;sultats obtenus montrent que les sens de mots pr&#233;sentent un int&#233;r&#234;t par rapport &#224; l&#8217;exploitation
de la simple r&#233;currence lexicale mais qu&#8217;en revanche, ils ne se r&#233;v&#232;lent pas meilleurs de ce point
de vue que de simples relations de cooccurrence lexicale.
</p>
<p>Les perspectives de ce travail sont directement li&#233;es &#224; l&#8217;analyse des r&#233;sultats et poussent &#224; porter
les efforts davantage sur la construction des sens de mots que sur leur exploitation. En particu-
lier, il serait int&#233;ressant de modifier la m&#233;thode de clustering utilis&#233;e afin de permettre un certain
recouvrement entre les d&#233;finitions des sens de mots. Le test d&#8217;autres m&#233;thodes de clustering se-
rait &#233;galement pertinent. Enfin, le recours &#224; des sens de mots d&#233;finis sur la base de classes
d&#8217;&#233;quivalence distributionnelles constitue une autre piste &#224; explorer, compl&#233;mentaire de celle
d&#233;j&#224; emprunt&#233;e. Au final, on notera qu&#8217;en d&#233;pit de r&#233;sultats un peu d&#233;cevants, l&#8217;utilisation de
sens de mots dans le cadre de la segmentation th&#233;matique appara&#238;t comme un moyen possible
pour &#233;valuer ce type de ressource et contribuer ainsi &#224; cette t&#226;che intrins&#232;quement difficile.
</p>
<p>R&#233;f&#233;rences
AGIRRE E. &amp; SOROA A. (2007). Semeval-2007 task 02 : Evaluating word sense induction and
discrimination systems. In Fourth International Workshop on Semantic Evaluations (SemEval-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Olivier Ferret
</p>
<p>2007), p. 7&#8211;12.
BEEFERMAN D., BERGER A. &amp; LAFFERTY J. (1999). Statistical models for text segmenta-
tion. Machine Learning, 34(1), 177&#8211;210.
CHOI F. Y. Y. (2000). Advances in domain independent linear text segmentation. In NAA-
CL&#8217;00, p. 26&#8211;33.
CHOI F. Y. Y., WIEMER-HASTINGS P. &amp; MOORE J. (2001). Latent semantic analysis for
text segmentation. In EMNLP&#8217;01, p. 109&#8211;117.
EISENSTEIN J. &amp; BARZILAY R. (2008). Bayesian unsupervised topic segmentation. In 2008
Conference on Empirical Methods in Natural Language Processing (EMNLP 2008).
ERT&#214;Z L., STEINBACH M. &amp; KUMA V. (2001). Finding topics in collections of documents :
A shared nearest neighbor approach. In Text Mine&#8217;01, Workshop of the 1st SIAM International
Conference on Data Mining.
FERRET O. (2004). Discovering word senses from a network of lexical cooccurrences. In 20th
International Conference on Computational Linguistics (COLING 2004), p. 1326&#8211;1332.
FERRET O. (2006). Approches endog&#232;ne et exog&#232;ne pour am&#233;liorer la segmentation th&#233;ma-
tique de documents. Traitement Automatique des Langues (TAL), num&#233;ro sp&#233;cial Discours et
Document, 47(2), 111&#8211;135.
GALLEY M., MCKEOWN K., FOSLER-LUSSIER E. &amp; JING H. (2003). Discourse segmenta-
tion of multi-party conversation. In 41st Annual Meeting of the Association for Computational
Linguistics (ACL-03), p. 562&#8211;569.
HEARST M. A. (1994). Multi-paragraph segmentation of expository text. In 32th Annual
Meeting of the Association for Computational Linguistics, p. 9&#8211;16.
JOBBINS A. C. &amp; EVETT L. J. (1998). Text segmentation using reiteration and collocation.
In ACL-COLING&#8217;98, p. 614&#8211;618.
KILGARRIFF A. (1997). I don&#8217;t believe in word senses. Computers and the Humanities, 31(2),
91&#8211;113.
KOZIMA H. (1993). Text segmentation based on similarity between words. In 31th Annual
Meeting of the Association for Computational Linguistics (Student Session), p. 286&#8211;288.
MORRIS J. &amp; HIRST G. (1991). Lexical cohesion computed by thesaural relations as an
indicator of the structure of text. Computational Linguistics, 17(1), 21&#8211;48.
PANTEL P. &amp; LIN D. (2002). Discovering word senses from text. In ACM SIGKDD Confe-
rence on Knowledge Discovery and Data Mining 2002, p. 613&#8211;619.
PASSONNEAU R. J. &amp; LITMAN D. J. (1997). Discourse segmentation by human and automa-
ted means. Computational Linguistics, 23(1), 103&#8211;139.
PEVZNER L. &amp; HEARST M. A. (2002). A critique and improvement of an evaluation metric
for text segmentation. Computational Linguistics, 28(1), 19&#8211;36.
STOKES N. (2003). Spoken and written news story segmentation using lexical chains. In
HLT-NAACL 2003, student session, p. 49&#8211;54.
UTIYAMA M. &amp; ISAHARA H. (2001). A statistical model for domain-independent text seg-
mentation. In ACL 2001, p. 491&#8211;498.
V&#201;RONIS J. (2003). Cartographie lexicale pour la recherche d&#8217;information. In 10e&#768;me Conf&#233;-
rence sur le Traitement automatique des langues naturelles (TALN 2003), p. 265&#8211;274.
YAMRON J., CARP I., GILLICK L., LOWE S. &amp; VAN MULBREGT P. (1998). A hidden markov
model approach to text segmentation and event tracking. In IEEE Conference on Acoustics,
Speech and Signal Processing, p. 333&#8211;336.</p>

</div></div>
</body></html>