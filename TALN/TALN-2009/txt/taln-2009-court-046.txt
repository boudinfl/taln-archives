TALN 2009 — Session posters , Senlis, 24-26 juin 2009

Utiliser des sens de mots pour la segmentation thématique ?

Olivier Ferret
CEA, LIST
18 route du Panorama, BP6, Fontenay-aux-Roses, F-92265 France
olivier.ferret@cea.fr

Résumé. La segmentation thématique est un domaine de l’analyse discursive ayant donné
lieu a de nombreux travaux s’appuyant sur la notion de cohésion lexicale. La plupart d’entre eux
n’exploitent que la simple récurrence lexicale mais quelques uns ont néanmoins exploré l’usage
de connaissances rendant compte de cette cohésion lexicale. Celles-ci prennent généralement
la forme de réseaux lexicaux, soit construits automatiquement a partir de corpus, soit issus
de dictionnaires élaborés manuellement. Dans cet article, nous exarninons dans quelle mesure
une ressource d’une nature un peu différente peut étre utilisée pour caractériser la cohésion
lexicale des textes. Il s’agit en l’occurrence de sens de mots induits automatiquement a partir
de corpus, a l’instar de ceux produits par la tache « Word Sense Induction and Discrimination »
de l’évaluation SemEval 2007. Ce type de ressources apporte une structuration des réseaux
lexicaux au niveau sémantique dont nous évaluons l’apport pour la segmentation thématique.

Abstract. Many topic segmenters rely on lexical cohesion. Most of them only exploit
lexical recurrence but some of them makes use of knowledge sources about lexical cohesion.
These sources are generally lexical networks built either by hand or automatically from corpora.
In this article, we study to what extent a new source of knowledge about lexical cohesion can
be used for topic segmentation. This source is a set of word senses that were automatically
discriminated from corpora, as the word senses resulting from the Word Sense Induction and
Discrimination task of the SemEval 2007 evaluation. Such a resource is a way to structurate
lexical networks at a semantic level. The impact of this structuring on topic segmentation is
evaluated in this article.

M0tS-CléS I Segmentation thématique, désambiguisation sémantique.

Keywords: Topic segmentation, word sense disambiguation.

1 Introduction

Le travail que nous présentons dans cet article peut étre appréhendé selon un double éclairage.
Le plus évident est celui de la segmentation thématique, probleme désorrnais classique consis-
tant a découper des textes en une suite de segments thématiquement homogenes. De ce point
de vue, ce travail explore l’intérét de l’utilisation pour cette tache d’une nouvelle source de
connaissances sémantiques, en l’occurrence des sens de mots induits a partir de corpusl. Le se-
cond point de vue est celui des connaissances : les travaux sur la désambiguisation sémantique

1Nous parlerons ici de << sens de mot » aﬁn de reprendre un vocable largement reconnu mais celui de << contexte
d’usage » utilisé dans (Véronis, 2003) nous semble plus juste.

Olivier Ferret

ont fait émerger la problématique de la construction de répertoires de sens a partir de corpus aﬁn
de pallier les insufﬁsances des dictionnaires traditionnels (Kilgarriff, 1997), au point de donner
lieu a une évaluation spéciﬁque au sein de SemEval 2007 (Agirre & Soroa, 2007). L’ utilisation
des sens de mots ainsi déﬁnis, soit directement, soit par le biais de la désambigu'1'sation seman-
tique, reste néanmoins un champ a peu pres vierge que nous nous proposons d’explorer ici dans
le cadre de la segmentation thématique.

La plupart des travaux dans le domaine de la segmentation thématique s’appuient sur les seules
caractéristiques intrinseques des documents : la récurrence lexicale dans le cas de (Hearst,
1994), (Choi, 2000), (Utiyama & Isahara, 2001), (Galley et al., 2003) ou plus récemment (Ei-
senstein & Barzilay, 2008); la présence de marques linguistiques pour (Passonneau & Litman,
1997) ou (Galley et al., 2003). L’absence de recours a des connaissances extemes donne a ces
méthodes un champ d’application en apparence large mais la récurrence lexicale n’est un in-
dice thématique ﬁable que si les concepts du document considéré ne sont pas exprimés sous
des formes trop diverses (synonymes, etc.) et les marques linguistiques sont souvent peu nom-
breuses.

Pour surmonter ces limitations, un certain nombre de systemes exploitent des connaissances sur
les relations de cohésion lexicale, connaissances qui présentent elles aussi l’avantage d’une cer-
taine généralité. Elles prennent la forme d’un réseau lexical construit a partir d’un dictionnaire
dans (Kozima, 1993), d’un thésaurus dans (Morris & Hirst, 1991), de relations issues de Word-
Net dans (Stokes, 2003) ou encore d’un large ensemble de cooccurrences lexicales dans (Choi
et al., 2001). D’une certaine facon, ces connaissances permettent aux systemes de segmentation
thématique de détecter les récurrences a un niveau plus conceptuel en leur donnant acces a des
relations d’équivalence lexicale. Elles sont néanmoins dépourvues de structuration thématique.

Ce demier point peut étre résolu en exploitant des connaissances sur les themes susceptibles
d’étre rencontrés dans les documents analysés. Ces connaissances sont généralement construites
automatiquement a partir d’un ensemble de documents représentatifs des themes considérés,
comme dans (Yamron et al., 1998) ou (Beeferman et al., 1999). L’aInélioration de la précision
ainsi obtenue se fait néanmoins au détriment de la couverture des systemes considérés. Enﬁn,
des systemes hybrides combinant différentes approches parmi celles présentées ci-dessus ont
également été développés : (Jobbins & Evett, 1998) associe ainsi la récurrence lexicale, l’uti-
lisation de cooccurrences et celle d’un thésaurus; (Beeferman et al., 1999) s’appuie a la fois
sur une modélisation statistique des themes et sur l’utilisation de marques discursives; (Galley
et al., 2003) se fonde conjointement sur la récurrence lexicale et sur des marques discursives.

Dans ce contexte, le travail que nous présentons dans cet article se range parmi les approches
reposant sur des connaissances relatives a la cohésion lexicale des textes. Plus précisément, il
integre l’utilisation de sens de mots induits a partir de corpus au sein de F06 (Ferret, 2006), un
environnement dédié a la segmentation thématique fondé sur la cohésion lexicale, et cherche
ainsi a situer l’intérét de ce type de connaissances par rapport a l’exploitation de la récurrence
lexicale ou de cooccurrences lexicales. Nous débuterons l’eXposé de ce travail par un apercu de
la source de connaissances ainsi utilisée.

2 Des sens de mots construits a partir de textes

Du point de vue de la caractérisation des sens de mots obtenus, il est possible de distinguer deux
grandes méthodes de construction a partir d’un corpus :

Utiliser des sens de mots pour la segmentation thématique ?

— les méthodes rassemblant les mots en classes d’équivalence selon un principe de distribution-
nalité, a l’instar de (Pantel & Lin, 2002). Dans ce cas de ﬁgure, les différents sens d’un mot
correspondent aux différents classes auxquelles il appartient. Un sens de mot est ici l’équi-
valent d’un synset de WordNet ;

— les méthodes discriminant les sens d’un mot en opérant une classiﬁcation non supervisée de
ses cooccurrents. Chaque sens de mot est ainsi déﬁni par un sous-ensemble des cooccurrents
du mot considéré. C’est l’approche retenue dans (Véronis, 2003) mais également pour les
sens de mots utilisés ici (Ferret, 2004).

Sans entrer dans les détails, explicités dans (Ferret, 2004), la construction des sens de mots
utilisés ici s’effectue en deux grandes étapes. La premiere consiste a construire a partir d’un
corpus un réseau de cooccurrences lexicales en utilisant une fenétre graphique d’une taille assez
large. 24 mois du journal Le Monde ont ici été utilisés avec une fenétre de 20 mots pleins. La

| Sens | Déﬁnition (cooccurrents représentatifs du sens) |

conducteur, traﬁc, routier, route, caInion, chauffeur, voiture, blo-
quer, poids_lourd

eau, metre, lac, pluie, riviere, bassin, ﬂeuve, site, poisson, afﬂuent,
montagne, crue, vallée

casque_bleu, soldat, tir, convoi, milicien, blindé, milice, aéroport,
blessé, incident, croate

barrage de protestation

barrage hydraulique

barrage fromfiere

TAB. 1 — Sens discriminés pour le mot barrage a partir du journal Le Monde

seconde étape est une classiﬁcation non supervisée des cooccurrents de chaque mot dont on
souhaite discriminer les sens. Cette classiﬁcation est plus précisément appliquée au sous-graphe
du réseau de cooccurrences délimité par les cooccurrents du mot cible. La Figure 1 montre ce
sous-graphe pour le mot barrage. La discrimination des sens se fait donc par l’identiﬁcation des
composantes de forte densité dans ce sous-graphe.

Cette identiﬁcation est réalisée en dans le cas présent par l’algorithme Shared Nearest Neighbors
(Ertoz et al., 2001). Cet algorithme se décompose en deux grandes phases. La premiere vise a
identiﬁer les germes des futures classes (ici des sens) en commencant par « éclaircir » le graphe
en ne conservant pour chaque noeud que ses k plus proches voisinsz, puis en le transposant en
un graphe dans lequel la pondération d’un arc correspond au nombre des voisins partagés par
les noeuds qu’il relie. Un seuil sur la distribution de ces valeurs permet d’identiﬁer des liens
dits forts. Chaque noeud se voit associer son nombre de liens forts et cette valeur est utilisée
pour simultanément sélectionner les germes des futures classes et éliminer les noeuds les moins
représentatifs. La seconde grande phase de l’algorithme consiste a rattacher les noeuds restants
aux germes des classes. Un premier rattachement au germe le plus proche est réalisé sous condi-
tion d’une similarité sufﬁsamment importante avec lui. Lors de cette étape, des germes peuvent
ainsi s’associer, impliquant ainsi la fusion des classes qu’ils représentent. Une seconde étape
de rattachement permet d’associer les noeuds restants aux classes en prenant en compte leur
proximité par rapport a la globalité de chaque classe formée.

Le Tableau 1 donne les sens discriminés selon cette méthode pour le mot barrage a partir du
graphe de coocurrents de la Figure 1. Plus globalement, le répertoire de sens obtenu pour le
Francais se compose de 7 373 lemmes avec une moyenne de 2,8 sens par lemme et un nombre

2Les valeurs de similarité dans le sous-graphe des cooccurrents correspondent a une estimation de l’information
mutuelle dans le réseau de cooccurrences.

Olivier Ferret

Mé 'déc|encher uforcer
“front_nationa| ,  T _ \ ‘heme:

  
  
 

“lever

'fi|tre r

      
   
 
   

. . ‘—, '1 '
-dresser 'éco|ogist;gar-iF"°V*6*4l1D.E”.‘€_ ./“
_ ,__r._—f /P;J'?uper

" blocage

' paralyser

"camionneur

"chauffeur_routier

‘ escargot

"7 . "sauter
Q; cheval

. . _ " 7 " ’ »  -.."’_§.’v
~ . jg -_ 5 ti ménagement
— \
' >_. , 4 ' ‘oonstruire
“hydroél "

chantier
'ingénieur

aval
-hydraulique irrigation

FIG. 1 — Cooccurrents du mot barrage (ceux impliqués dans ses 3 sens apparaissant en rouge)

moyen de mots formant la déﬁnition d’un sens égal a 16,1. Le vocabulaire initial était constitué
de 17 261 lemmes mais pour un peu plus de la moitié des lemmes, la densité des liens dans le
sous-graphe des cooccurrents n’était pas assez forte pour former des classes signiﬁcatives.

3 F06 : un cadre pour la segmentation thématique

3.1 Principes

Apres la présentation rapide de la source de connaissances a tester, nous allons maintenant
présenter F06 (Ferret, 2006), le cadre retenu pour son application a la segmentation thématique.
F06 reprend les principes proposés par Hearst dans TextTiling (Hearst, 1994) avec un processus
de segmentation articulé en trois grandes parties :

— le prétraitement linguistique des documents ;
— l’évaluation de la cohésion lexicale au sein du document;
— l’identiﬁcation des changements de theme.

Le prétraitement linguistique, qui s’appuie sur l’outil TreeTagger, découpe les documents en
phrases et représente chacune d’elles comme la séquence de ses mots pleins normalisés, c’est-
a-dire ses noms (communs et propres), ses verbes et ses adjectifs. L’ évaluation de la cohésion
lexicale s’appuie comme dans TextTiling sur l’utilisation d’une fenétre glissante de taille ﬁxe.
Cette fenétre se déplace sur le texte de phrase en phrase. A chaque station de cette fenétre,
la cohésion lexicale est évaluée en son sein et affectée a la ﬁn de phrase sur laquelle elle est
centrée. Le résultat ﬁnal est une courbe de cohésion couvrant l’ensemble du document.

Utiliser des sens de mots pour la segmentation thematique ?

La troisieme partie de l’algorithme s’inspire quant a elle de son homologue dans le systeme
LCseg (Galley et al., 2003). Elle comprend elle-meme trois etapes :

— le calcul d’un score evaluant la probabilite pour chaque minimum de la courbe de cohesion
de correspondre a un changement de theme;
— la suppression des candidats segments de trop petite taille;
— la selection des bomes de segments thematiques.

Le calcul du score initial d’un minimum commence par la recherche de la paire de maxima g
et d qui l’entourent. En notant, C'L(x) la valeur de la cohesion lexicale a la position 1:, le score
d’un minimum m est donne par :

C'L(g) + CL(d) — 2 - CL(m)
2

sc0re(m) = (1)
Ce score, compris entre 0 et 1, est d’autant plus eleve que la difference entre le minimum consi-
dere et les maxima qui l’entourent est plus importante. I1 favorise ainsi comme changements
de theme potentiels les Ininima caracterises par une chute tres nette de la cohesion lexicale. La
suppression des candidats segments trop petits s’effectue quant a elle par une simple comparai-
son par rapport a un seuil de reference : les minima se trouvant a 2 phrases au plus du minimum
qui les precede sont elimines en tant que possibles changements de theme. Finalement, la selec-
tion des bomes de segments thematiques est realisee par l’utilisation d’un seuil s’adaptant a la
distribution des scores des Ininima. Un minimum m est ainsi retenu comme borne de segment
si sc0re(m) > ,u — oz - 0, ou ,u correspond a la moyenne des scores de minima, 0, a l’ecart-type
de ces scores et oz, a un coefﬁcient de modulation.

3.2 Evaluation de la cohesion lexicale

L’ evaluation de la cohesion lexicale est l’etape la plus importante du processus de segmentation
dans F06 et c’est a son niveau que sont introduites les differentes sources de cohesion lexicale
a tester. Globalement, cette evaluation est realisee suivant le principe propose dans (J obbins &
Evett, 1998) : la cohesion est mesuree par l’application du coefﬁcient de Dice entre les vecteurs
representant les deux moities de la fenetre glissante. Dans le cas de la recurrence lexicale, ce
principe est repris strictement : si F9 designe le vocabulaire de la moitie gauche de la fenetre et
Fd, celui de sa moitie droite, la cohesion au sein de la fenetre est donnee par :

2 - card(Fg ﬂ Fd)

c0hesi0n_rec(J:) = ecaTd(Fg) + caTd(Fd)

(2)

Lorsque les relations de cohesion ne sont pas des relations de recurrence3, la mesure utilisee
est une extension du coefﬁcient de Dice. Dans chaque volet de la fenétre, le nombre de mots
lies par ces relations de cohesion avec les mots de l’autre volet de la fenetre est determine en
excluant les mots deja impliques dans des relations de recurrence. Les contributions des deux
volets de la fenetre sont ensuite sommees et ramenees au nombre total de mots dans la fenetre4 :

card(MTe;(g) — Mréc) + card(MTe;(d) — Mréc)
card(Fg) + card(Fd)

c0hési0n_rel  =

(3)

3Plus generalement, on parlera de relations d’ egalite ou d’ equivalence entre mots, se limitant ici a la recurrence.
4Dans le cas du coefﬁcient de Dice, la contribution de chaque volet correspond a leur intersection.

Olivier Ferret

o1‘1 Mm; represente les mots du volet :13 de la fenetre (gauche ou droit) selectionnes sur la
base des relations de cohesion lexicale et Mm, les mots impliques dans une relation de re-
currence. La cohesion globale au sein de la fenetre est ﬁnalement donnee par la somme de
c0hési0n_réc(a:) et des valeurs de c0hési0n_rel(x) correspondant aux differents types de rela-
tions de cohesion distingues.

4 Utiliser des sens de mots pour la segmentation thématique

Comme nous l’avons vu a la section precedente, l’integration au sein de F06 d’une nouvelle
source de connaissances sur la cohesion lexicale se fait au niveau de l’evaluation de la cohe-
sion de la fenetre glissante d’analyse et plus precisement lors de la determination des mots de
chacun de ses volets lies aux mots de l’autre volet. Dans le cas des sens de mots presentes a la
Section 2, la methode d’integration en apparence la plus directe serait une forme d’extension de
la recurrence lexicale : au lieu de se focaliser sur la repetition des mots, elle se focaliserait sur la
repetition des sens de mots. Cette methode impose de realiser une desambigu'1'sation semantique
des textes. Sachant que dans un texte, il est peu frequent qu’un meme mot soit utilise avec deux
sens differents pour faire reference a deux themes differents, il apparait probable que le gain
de precision espere du fait de l’utilisation de sens de mots soit en pratique efface par le taux
d’erreur du processus de desambiguisation semantique.

présence explicite présence implicite
barrage-hydraulique barrage-hydraulique
A A
Sens , \ , \

Définition du sens
barrage—hydrau|ique

  
 
  

barrage—hydrauIique

metre, lac, pluie, bassin,
montagne fleuve, site, poisson, affluent,
. .\ , II’
“Were crue va ee

Désambigutsation
semantique

volet gauche volet droit
Fenetre d'analyse

FIG. 2 — Utilisation des sens de mots pour l’evaluation de la cohesion lexicale

Nous avons donc opte pour une solution plus souple dans laquelle l’identiﬁcation des sens de
mots entre les deux volets de la fenetre d’analyse ne passe pas par la presence explicite du
meme sens pour un mot donne dans ces deux volets mais par le fait qu’un lien peut etre etabli
entre les deux volets si l’un d’eux contient un sens d’un mot et l’autre un nombre signiﬁcatif
d’elements de deﬁnition de ce sens. Ainsi que l’illustre la Figure 2, si l’un des volets de la fenetre
contient le mot barrage avec le sens barrage-hydraulique et que l’autre volet contient les mots
eau, montagne et riviére, tous trois faisant partie de la deﬁnition du sens barrage-hydraulique
(cf. Tableau 1), nous faisons l’hypothese de la presence d’un lien de cohesion entre les deux
volets de la fenetre, lien sous-tendu par la co-presence, l’une explicite, l’autre implicite, du sens
barrage hydraulique.

Utiliser des sens de mots pour la segmentation thématique ?

Dans le cadre de F06, et plus précisément de l’équation 3, l’identiﬁcation d’un tel lien se traduit
par l’ajout des mots de la déﬁnition présents dans un volet de la fenétre a l’ensemble Mm;
associé a ce volet et l’ajout du mot déﬁni a l’ensemble Mm; de l’autre volet. En pratique,
ce mécanisme est déclenché des lors qu’au moins 2 mots de la déﬁnition d’un sens de mot
sont présents dans un volet de la fenétre. Lorsque la discrimination de sens ne produit pas de
résultat pour un mot, une procédure de rattrapage est appliquée pour maximiser la détection des
relations de cohésion : le mot est supposé n’avoir qu’un seul sens, déﬁni par ses cooccurrents
dans le réseau de cooccurrences initialement utilisé pour discriminer les sens de mots.

Le mécanisme d’intégration décrit ci-dessus repose sur la possibilité d’identiﬁer le sens des
mots au sein de la fenétre d’analyse. Pour ce faire, les mots de chacun de ses deux volets
sont désambiguisés en prenant comme contexte les mots du volet dans lequel ils se trouvent.
Cette désambigui'sation est réalisée selon une approche de type Lesk : le recouvrement entre le
contenu du volet de la fenétre dans lequel un mot se trouve et la déﬁnition de chacun de ses
sens est évalué et le sens retenu est celui pour lequel ce recouvrement est le plus important. Plus
précisément, ce recouvrement est évalué par la mesure Cosinus.

5 Evaluation

5.1 Méthodologie

L’ objectif de l’évaluation menée dans ce travail étant de déterminer l’intérét de l’utilisation de
sens de mots comme source de cohésion lexicale dans F06, nous reprendrons le méme cadre
d’évaluation que celui développé pour F06. Celui-ci s’inspire de la désormais classique méthode
d’évaluation proposée par Choi dans (Choi, 2000). Cette méthode est fondée sur la constitution
d’un corpus d’évaluation composé de morceaux de documents de taille variable collés les uns
a la suite des autres. L’ objectif pour le segmenteur évalué est de retrouver les frontieres des
morceaux de documents. Dans (Ferret, 2006), nous avons proposé une adaptation de cette pro-
cedure visant a controler plus précisément sa dimension thématique, ce qui permet d’ailleurs de
se rapprocher de conditions plus réalistes d’apres les résultats obtenus. Au lieu de tirer chaque
extrait d’un document différent, nous n’utilisons que deux documents. Chacun d’entre eux est
divisé comme dans le cas de Choi en segments de 3 a 11 phrases et le document d’évaluation
est constitué en prenant, a partir du début des documents, altemativement un segment dans un
des deux documents et le suivant dans l’autre et ce, jusqu’a obtenir 10 segments ou jusqu’a ce
que le processus de construction atteigne la ﬁn d’un des deux documents.

Pour nous assurer que deux segments consécutifs font reference a deux themes différents et
que le changement de theme entre les deux est effectif, les deux documents sont sélectionnés de
maniere a appartenir a des thématiques différentes. Pour ce faire, nous nous sommes appuyés sur
les données constituées pour l’évaluation CLEF sur la recherche d’information multilingue. Les
documents source utilisés pour réaliser notre corpus étaient ainsi des documents issus du corpus
CLEF pour lesquels nous disposions d’un jugement de pertinence par rapport a un des topics
d’interrogation déﬁnis pour l’évaluation. Chaque document de notre corpus a ainsi été construit
a partir de deux documents du corpus CLEF jugés pertinents pour deux topics différents. Nous
avons ainsi constitué un corpus d’évaluation de 100 documents construits a partir de 11 topics
et de documents issus de deux ans du journal Le Monde.

Classiquement, nous avons utilisé la mesure d’erreur Pk (Beeferman et al., 1999) pour évaluer

Olivier Ferret

la qualité des résultats des segmenteurs. Pk évalue la probabilité que deux mots choisis aléa-
toirement dans un document et séparés par 16 mots soient jugés comme appartenant au méme
segment alors qu’ils sont dans des segments différents (faux négatii) ou qu’ils soient jugés
comme appartenant a des segments différents alors qu’ils sont dans le méme (fausse alarme). k
est égal a la moitié de la taille moyenne en mots des segments au niveau du corpus de référence.
L’ objectif est de Ininimiser Pk. Wind0wD1ﬁ‘ (Pevzner & Hearst, 2002), dont nous donnons aussi
les résultats, est une variante de Pk prenant en compte le nombre de frontieres de segments
séparant deux mots situés dans des segments différents.

5.2 Résultats et discussion

Le Tableau 2 donne les résultats obtenus par les segmenteurs testés dans le cadre F06 sur le
corpus décrit a la Section 5.1 mais également les résultats sur ce méme corpus de méthodes
de référence : U00 est ainsi la méthode décrite dans (Utiyama & Isahara, 2001), C99, celle
proposée dans (Choi, 2000) et LCseg est présentée dans (Galley et al., 2003). TextTiling* est
une variante de TeXtTiling dans laquelle la troisieme étape d’identiﬁcation des changements de
theme est reprise de (Galley et al., 2003).

Au sein de F06, F06R s’appuie sur la seule récurrence lexicale. F06C (Ferret, 2006) met en
oeuvre l’utilisation de relations de cooccurrence lexicale au sein de F06 en s’appuyant sur
l’équation 3 : si un mot m d’un volet de la fenétre d’analyse est lié a un nombre minimal
(en l’occurrence 2) de mots de son autre volet par des relations de cooccurrence d’un niveau de
cohésion sufﬁsamment haut, ces cooccurrents de m sont ajoutés a l’ensemble Mm; associé
au volet de la fenétre ou ils apparaissent. Pour les segmenteurs exploitant des sens de mots, 2
systemes ont été testés. F06WS correspond strictement au descriptif de la Section 4 tandis que
F06WSr est une variante sans désambigu'1'sation sémantique : les mots dans un des volets de la
fenétre peuvent correspondre a l’un quelconque des sens de l’un des mots de l’autre volet.

Les sens d’un mot pouvant étre vus comme une forme de structuration de ses cooccurrents,
F06WS et F06Wr se comparent naturellement a F06C, F06R servant de référence basse. Pour
chaque résultat de ces méthodes, nous donnons donc le degré de signiﬁcation p de sa diffé-
rence avec F06R et F06C, niveau évalué grace a un test de Student unilatéral dont les valeurs
inférieures a 0,05 sont considérées comme signiﬁcatives (en gras).

systémes Pk (%) Wind0WDiff (%)
erreur | p(F06R) | p(F06C) erreur | p(F06R) | p(F06C)
U00 25,91 0,003 1,3e-07 27,42 0,799 0,032
C99 27,57 4,2e-05 3,6e-10 35,42 8,6e-07 6,5e-13

TextTiling* 21,08 0,699 0,037 27,43 0,803 0,032
LCseg 20,55 0,439 0,111 28,31 0,767 0.007
F06R 21,58 / 6,5e-05 27,83 / 4,8e-06
F06C 16,48 6,5e-05 / 20,94 4,8e-06 /

F06WSr 18,50 0,015 0,10 23,14 0,002 0,11
F06WS 18,17 0,006 0,16 23,20 0,002 0,12

TAB. 2 — Résultats des différents segmenteurs testés sur le corpus de la Section 5.1

Le premier constat que l’on peut tirer de l’analyse de ce tableau est que globalement, l’apport
de connaissances extemes sur la cohésion lexicale, que ce soit sous la forme de cooccurrences

Utiliser des sens de mots pour la segmentation thematique ?

lexicales ou de sens de mots, represente un atout indeniable puisque les valeurs de P], et de
WindowDiﬁ" sont nettement meilleures pour les methodes utilisant ces connaissances (F06C,
F06WS et F06WSr) que pour celles n’exploitant que la recurrence lexicale et ce, de facon
statistiquement signiﬁcative dans la plupart des cas.

Concernant plus speciﬁquement les sens de mots, cette evaluation fait apparaitre que si leur
utilisation permet d’ameliorer les resultats par rapport a F06R, elle ne permet pas en revanche
pas d’obtenir de progres vis-a-vis de l’utilisation de cooccurrences lexicales. Les resultats avec
les sens de mots sont meme moins bons mais la difference n’est pas statistiquement signiﬁcative.
Les deux variantes testees, F06WS et F06WSr, sont a cet egard comparables, sans difference
signiﬁcative sur le plan statistique.

Ce resultat est decevant dans la mesure ou les sens de mots utilises ici, bien que proches des
relations de cooccurrence de par leur deﬁnition, representent un degre de structuration supe-
rieur des connaissances, degre dont on pourrait attendre un impact positif sur la precision de
la segmentation. Meme s’il est assez difﬁcile d’analyser dans le detail les causes de ces resul-
tats, il est probable que le processus de structuration des cooccurrents intervenant lors de la
discrimination des sens de mots provoque une perte d’informations de cohesion lexicale. Cette
perte peut avoir pour origine a la fois l’eliIr1ination de certains cooccurrents juges sans doute
a tort non signiﬁcatifs et le fait que la methode de clustering utilisee est de type « hard cluste-
ring », conduisant a construire des sens sans aucun partage des mots constituant leur deﬁnition.
Cette perte d’informations masque ainsi les gains potentiellement apportes par une plus grande
structuration des connaissances.

6 Conclusion et perspectives

Dans cet article, nous avons etudie l’interet de l’utilisation de sens de mots discrimines a partir
de corpus pour la segmentation thematique de textes. Cette etude a ete realisee en s’appuyant
sur F06, un cadre d’etude de la segmentation thematique fondee sur la cohesion lexicale. Les
resultats obtenus montrent que les sens de mots presentent un interet par rapport a l’exploitation
de la simple recurrence lexicale mais qu’en revanche, ils ne se revelent pas meilleurs de ce point
de vue que de simples relations de cooccurrence lexicale.

Les perspectives de ce travail sont directement liees a l’analyse des resultats et poussent a porter
les efforts davantage sur la construction des sens de mots que sur leur exploitation. En particu-
lier, il serait interessant de modiﬁer la methode de clustering utilisee aﬁn de permettre un certain
recouvrement entre les deﬁnitions des sens de mots. Le test d’autres methodes de clustering se-
rait egalement pertinent. Enﬁn, le recours a des sens de mots deﬁnis sur la base de classes
d’equivalence distributionnelles constitue une autre piste a explorer, complementaire de celle
deja empruntee. Au ﬁnal, on notera qu’en depit de resultats un peu decevants, l’utilisation de
sens de mots dans le cadre de la segmentation thematique apparait comme un moyen possible
pour evaluer ce type de ressource et contribuer ainsi a cette tache intrinsequement difﬁcile.

References

AGIRRE E. & SOROA A. (2007). Semeval-2007 task 02 : Evaluating word sense induction and
discrimination systems. In Fourth International Workshop on Semantic Evaluations (SemEval-

Olivier Ferret

2007), p. 7-12.

BEEFERMAN D., BERGER A. & LAFFERTY J. (1999). Statistical models for text segmenta-
tion. Machine Learning, 34(1), 177-210.

CHOI F. Y. Y. (2000). Advances in domain independent linear text segmentation. In NAA-
CL’00, p. 26-33.

CHOI F. Y. Y., WIEMER-HASTINGS P. & MOORE J. (2001). Latent semantic analysis for
text segmentation. In EMNLP’0I, p. 109-117.

EISENSTEIN J. & BARZILAY R. (2008). Bayesian unsupervised topic segmentation. In 2008
Conference on Empirical Methods in Natural Language Processing (EMNLP 2008).

ERTOZ L., STEINBACH M. & KUMA V. (2001). Finding topics in collections of documents :
A shared nearest neighbor approach. In Text Mine ’0I , Workshop of the I 3‘ SIAM International
Conference on Data Mining.

FERRET O. (2004). Discovering word senses from a network of lexical cooccurrences. In 20”‘
International Conference on Computational Linguistics (COLING 2004 ), p. 1326-1332.
FERRET O. (2006). Approches endogene et exogene pour améliorer la segmentation thema-
tique de documents. Traitement Automatique des Langues (TAL), numéro spe’cial Discours et
Document, 47(2), 111-135.

GALLEY M., MCKEOWN K., FOSLER-LUSSIER E. & JING H. (2003). Discourse segmenta-
tion of multi-party conversation. In 413‘ Annual Meeting of the Association for Computational
Linguistics (ACL-03), p. 562-569.

HEARST M. A. (1994). Multi-paragraph segmentation of expository text. In 32”‘ Annual
Meeting of the Association for Computational Linguistics, p. 9-16.

J OBBINS A. C. & EVETT L. J . (1998). Text segmentation using reiteration and collocation.
In ACL-COLING’98, p. 614-618.

KILGARRIFF A. (1997). I don’t believe in word senses. Computers and the Humanities, 31(2),
91-1 13.

KOZIMA H. (1993). Text segmentation based on similarity between words. In 31”" Annual
Meeting of the Association for Computational Linguistics (Student Session), p. 286-288.
MORRIS J . & HIRST G. (1991). Lexical cohesion computed by thesaural relations as an
indicator of the structure of text. Computational Linguistics, 17(1), 21-48.

PANTEL P. & LIN D. (2002). Discovering word senses from text. In ACM SIGKDD Confe-
rence on Knowledge Discovery and Data Mining 2002, p. 613-619.

PASSONNEAU R. J . & LITMAN D. J . (1997). Discourse segmentation by human and automa-
ted means. Computational Linguistics, 23(1), 103-139.

PEVZNER L. & HEARST M. A. (2002). A critique and improvement of an evaluation metric
for text segmentation. Computational Linguistics, 28(1), 19-36.

STOKES N. (2003). Spoken and written news story segmentation using lexical chains. In
HLT-NAACL 2003, student session, p. 49-54.

UTIYAMA M. & ISAHARA H. (2001). A statistical model for domain-independent text seg-
mentation. In ACL 2001, p. 491-498.

VERONIS J . (2003). Cartographie lexicale pour la recherche d’information. In I Oéme Confe’-
rence sur le Traitement automatique des langues naturelles (TALN 2003 ), p. 265-274.
YAMRON J ., CARP 1., GILLICK L., LowE S. & VAN MULBREGT P. (1998). A hidden markov
model approach to text segmentation and event tracking. In IEEE Conference on Acoustics,
Speech and Signal Processing, p. 333-336.

