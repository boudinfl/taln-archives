<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Analyse d&#233;ductive pour les grammaires d&#8217;interaction</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009, Senlis, 24&#8211;26 juin 2009
</p>
<p>Analyse d&#233;ductive pour les grammaires d&#8217;interaction
</p>
<p>Joseph Le Roux
NCLT, Dublin City University
</p>
<p>jleroux@computing.dcu.ie
R&#233;sum&#233;. Nous proposons un algorithme d&#8217;analyse pour les grammaires d&#8217;interaction qui
utilise le cadre formel de l&#8217;analyse d&#233;ductive. Cette approche donne un point de vue nouveau sur
ce probl&#232;me puisque les m&#233;thodes pr&#233;c&#233;dentes r&#233;duisaient ce dernier &#224; la r&#233;&#233;criture de graphes
et utilisaient des techniques de r&#233;solution de contraintes. D&#8217;autre part, cette pr&#233;sentation per-
met de d&#233;crire le processus de mani&#232;re standard et d&#8217;exhiber les sources d&#8217;ind&#233;terminisme qui
rendent ce probl&#232;me difficile.
</p>
<p>Abstract. We propose a parsing algorithm for Interaction Grammars using the deductive
parsing framework. This approach brings new perspectives on this problem, departing from
previous methods relying on constraint-solving techniques to interpret it as a graph-rewriting
problem. Furthermore, this presentation allows a standard description of the algorithm and a
fine-grained inspection of the sources of non-determinism.
</p>
<p>Mots-cl&#233;s : Analyse syntaxique, grammaires d&#8217;interaction.
Keywords: Parsing, Interaction Grammars.
</p>
<p>1 Introduction
</p>
<p>Une grammaire d&#8217;interaction (GI) (Guillaume &amp; Perrier, 2008) permet de d&#233;crire la syntaxe
d&#8217;une langue en insistant sur la valence, c&#8217;est-&#224;-dire la capacit&#233; des mots &#224; se combiner. Cette
valence s&#8217;exprime au moyen de polarit&#233;s qui d&#233;corent les syntagmes ou les traits associ&#233;s &#224;
ces syntagmes. D&#8217;autres formalismes utilisent cette notion, comme les grammaires cat&#233;go-
rielles (Lambek, 1958), les grammaires d&#8217;unification polaris&#233;es (Kahane, 2004) ou encore les
grammaires minimalistes (Chomsky, 1995). Une autre caract&#233;ristique des GI est l&#8217;utilisation de
structures dites sous-sp&#233;cifi&#233;es. Les grammaires de (Duchier &amp; Thater, 1999) utilisent aussi ces
structures mais avec un syst&#232;me de polarit&#233;s moins riche.
</p>
<p>Dans cet article, nous pr&#233;sentons un algorithme proche de celui d&#233;crit par (Earley, 1970) pour
l&#8217;analyse des grammaires hors-contexte. D&#8217;autres m&#233;thodes d&#8217;analyse existent pour les GI,
comme par exemple la m&#233;thode shift-reduce de (Bonfante et al., 2003) qui r&#233;duit l&#8217;analyse &#224;
la r&#233;&#233;criture de graphes. Ici, nous consid&#233;rons une approche radicalement diff&#233;rente. Nous in-
troduisons notre algorithme en utilisant une m&#233;thode standard de ce domaine : l&#8217;analyse d&#233;duc-
tive (Shieber et al., 1995). Cette approche &#233;vite d&#8217;inventer des notions et des notations ad hoc.
Elle permet aussi aux lecteurs qui y sont habitu&#233;s de comprendre rapidement les sp&#233;cificit&#233;s de
l&#8217;analyse des GI. (Le Roux, 2007) d&#233;crit un algorithme tr&#232;s proche mais notre pr&#233;sentation, en
d&#233;composant la pr&#233;diction, est bien plus simple.
</p>
<p>Le reste de l&#8217;article s&#8217;organise comme suit : nous pr&#233;sentons les GI (section 2), puis nous d&#233;-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Joseph Le Roux
</p>
<p>crivons l&#8217;algorithme (section 3). Nous discutons ensuite certains aspects techniques de l&#8217;algo-
rithme (section 4) avant de conclure (section 5).
</p>
<p>2 Les grammaires d&#8217;interaction
</p>
<p>Nous reprenons la d&#233;finition des GI donn&#233;e par (Guillaume &amp; Perrier, 2008) 1. Cependant, nous
pr&#233;sentons ici une version sans structure de traits de mani&#232;re &#224; simplifier l&#8217;expos&#233;.
</p>
<p>2.1 Descriptions d&#8217;arbre polaris&#233;es
</p>
<p>La structure fondamentale des GI est la description d&#8217;arbre polaris&#233;e (DAP) qui repr&#233;sente un
fragment d&#8217;arbre d&#8217;analyse. Elle contient des n&#339;uds polaris&#233;s, c&#8217;est-&#224;-dire d&#233;cor&#233;s de polarit&#233;s.
</p>
<p>Les GI distinguent 4 polarit&#233;s P = {&#8594;,&#8592;,=,&#8764;}, respectivement positive, n&#233;gative, neutre
et virtuelle. Un multi-ensemble de polarit&#233;s est satur&#233; s&#8217;il contient exactement une polarit&#233;
positive et exactement une polarit&#233; n&#233;gative, ou bien s&#8217;il ne contient aucune polarit&#233; positive ni
n&#233;gative et au moins une polarit&#233; neutre. Un multi-ensemble de polarit&#233;s est superposable s&#8217;il
contient au plus une polarit&#233; positive et au plus une polarit&#233; n&#233;gative.
</p>
<p>Les n&#339;uds polaris&#233;s sont &#233;tiquet&#233;s par une cat&#233;gorie et une polarit&#233;. Un ensemble de n&#339;uds est
satur&#233; (resp. superposable) si tous ses &#233;l&#233;ments ont la m&#234;me cat&#233;gorie et si le multi-ensemble
induit par leur polarit&#233; est satur&#233; (resp. superposable).
Une DAP est un graphe. Il existe quatre relations binaires d&#233;finies sur les n&#339;uds polaris&#233;s d&#8217;une
DAP : la parent&#233; imm&#233;diate&gt;, la parent&#233; l&#226;che &gt;&#8727;, la pr&#233;c&#233;dence imm&#233;diate&#8826; et la pr&#233;c&#233;dence
l&#226;che &#8826;+. De plus, pour &#234;tre valide une DAP doit v&#233;rifier :
&#8211; &gt; et &gt;&#8727; d&#233;finissent une structure d&#8217;arbre,
&#8211; &#8826; et &#8826;+ ne sont d&#233;finies que pour des n&#339;uds ayant le m&#234;me ant&#233;c&#233;dent par &gt;.
Dans chaque DAP il existe des n&#339;uds feuilles (sans descendant par &gt; ou &gt;&#8727;), appel&#233;s ancres.
Pour all&#233;ger l&#8217;expos&#233; , si n &gt;&#8727; m, on appelle m un n&#339;ud contraint (par n) et pour un ensemble
N de n&#339;uds, on d&#233;finit N&gt; = {N |&#8707;M &#8712; N ,M &gt; N} et N&gt;&#8727; = {N |&#8707;M &#8712; N ,M &gt;&#8727; N}.
</p>
<p>2.2 Grammaires d&#8217;interaction
</p>
<p>Une GI est un tuple G = {&#931;,C, S,P, phon}, o&#249; &#931; est l&#8217;alphabet des symboles terminaux, C
est l&#8217;alphabet des symboles non-terminaux (ou cat&#233;gories), S &#8712; C est le symbole initial, P est
un ensemble de DAP dont les n&#339;uds sont &#233;tiquet&#233;s par des &#233;l&#233;ments de C&#215; P et phon est une
fonction partielle des n&#339;uds de P vers &#931;. Elle n&#8217;est d&#233;finie que pour les ancres.
</p>
<p>Le r&#233;sultat d&#8217;une analyse syntaxique est un arbre syntaxique, c&#8217;est-&#224;-dire un arbre totalement
ordonn&#233; dans lequel tous les n&#339;uds sont &#233;tiquet&#233;s par une cat&#233;gorie. On note lab(A) l&#8217;&#233;tiquette
du n&#339;ud A. Certains n&#339;uds feuilles F sont &#233;tiquet&#233;s par un terminal t. Dans ce cas, on notera
mot(F ) = t, et mot(F ) = &#949; sinon.
</p>
<p>On notera M &#8811; N si le n&#339;ud M est le p&#232;re du n&#339;ud N et N &#8811; [N1, . . . , Nk] si le n&#339;ud N est
le p&#232;re des n&#339;uds de la liste ordonn&#233;e [N1, . . . , Nk]. L&#8217;ordre entre n&#339;uds fils s&#8217;exprime &#224; l&#8217;aide
</p>
<p>1. Nous reportons les lecteurs &#224; cet article pour ce qui concerne l&#8217;utilisation linguistique des GI.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Un analyseur syntaxique descendant pour les GI
</p>
<p>de de la relation &#8826;&#8826;. M &#8826;&#8826; N indique que N est le successeur imm&#233;diat de M . On notera
&#8826;&#8826;+ la cl&#244;ture transitive de &#8826;&#8826; et &#8811;&#8727; la cl&#244;ture r&#233;flexive transitive de &#8811;.
</p>
<p>Enfin nous avons besoin de la projection phonologique PP d&#8217;un n&#339;ud, d&#233;finie r&#233;cursivement :
</p>
<p>PP (M) =
</p>
<p>{
[t] si M &#8811; [] et mot(M) = t
[PP (N1) . . . PP (Nk)] si M &#8811; [N1, . . . , Nk]
</p>
<p>Un arbre syntaxique T est un mod&#232;le du multi-ensemble de DAP D s&#8217;il existe une fonction
totale I des n&#339;uds de D (not&#233;s ND) vers les n&#339;uds de T (not&#233;s NT ) qui v&#233;rifie :
</p>
<p>1. si A &#8712; NT alors I&#8722;1(A) est satur&#233; et non-vide.
2. si M,N &#8712; ND et M &gt; N alors I(M)&#8811; I(N)
3. si M,N &#8712; ND et M &gt;&#8727; N alors I(M)&#8811;&#8727; I(N)
4. si M,N &#8712; ND et M &#8826; N alors I(M) &#8826;&#8826; I(N)
5. si M,N &#8712; ND et M &#8826;+ N alors I(M) &#8826;&#8826;+ I(N)
6. si A,B &#8712; NT et A&#8811; B alors il existe M &#8712; I&#8722;1(A) et N &#8712; I&#8722;1(B) tels que M &gt; N
7. si A &#8712; NT alors lab(A) = lab(M) pour tout M &#8712; I&#8722;1(A)
8. si M &#8712; ND et phon(M) = m alors PP (I(M)) = [m]
</p>
<p>&#201;tant donn&#233; une GI G = {&#931;,C, S,P, phon} et une phrase p = m1, . . . , mn de &#931;&#8727;, un arbre
syntaxique T est un arbre d&#8217;analyse pour p s&#8217;il existe un multi-ensembleD de DAP issues de P
tel que T est un mod&#232;le de D, la racine R de T est &#233;tiquet&#233;e par S et PP (R) = [m1, . . . , mn].
Le langage engendr&#233; par G est l&#8217;ensemble des phrases de &#931;&#8727; pour lesquelles il existe un arbre
d&#8217;analyse.
</p>
<p>3 D&#233;finition de l&#8217;algorithme
</p>
<p>Nous utilisons le cadre de l&#8217;analyse d&#233;ductive (Shieber et al., 1995) pour expliquer notre algo-
rithme : un &#233;tat de l&#8217;analyse est d&#233;crit par un item et des r&#232;gles de d&#233;duction permettent d&#8217;obtenir
de nouveaux items &#224; partir d&#8217;items d&#233;j&#224; cr&#233;&#233;s. On applique ces r&#232;gles jusqu&#8217;&#224; stabilisation de
l&#8217;ensemble d&#8217;items. L&#8217;analyse est amorc&#233;e par la cr&#233;ation d&#8217;un item axiome. La phrase d&#8217;entr&#233;e
appartient au langage si un item sp&#233;cifique, appel&#233; item but est cr&#233;&#233; durant l&#8217;analyse 2.
</p>
<p>3.1 Les items
</p>
<p>Nos items sont de la forme [A(H,N, F )&#8594; &#945;&#8226;&#946;, i, j, (O,U,D)]. Ils sont constitu&#233;s d&#8217;une r&#232;gle
point&#233;e, de deux indices de position 0 &#8804; i &#8804; j &#8804; n, o&#249; n est la longueur de la phrase d&#8217;entr&#233;e,
et d&#8217;un triplet d&#8217;ensembles de n&#339;uds qui contr&#244;le l&#8217;utilisation des n&#339;uds contraints.
</p>
<p>La r&#232;gle point&#233;e A(H,N, F ) &#8594; &#945; &#8226; &#946; affirme qu&#8217;il existe un n&#339;ud A de l&#8217;arbre d&#8217;analyse,
mod&#232;le de l&#8217;ensemble H &#8746;N &#8746;F . Les &#233;l&#233;ments Al dans &#945; sont &#233;galement des n&#339;uds de l&#8217;arbre
syntaxique. Ils indiquent que des sous-analyses ont d&#233;j&#224; &#233;t&#233; effectu&#233;es et que l&#8217;on a trouv&#233; pour
</p>
<p>2. Nous pr&#233;sentons ici un reconnaisseur. Pour en faire un analyseur, il faudrait garder l&#8217;historique des items.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Joseph Le Roux
</p>
<p>ces n&#339;uds des ensembles d&#8217;ant&#233;c&#233;dents satur&#233;s. Les &#233;l&#233;mentsBk(Hk)de &#946; signifient qu&#8217;il existe
un n&#339;ud Bk dans l&#8217;arbre syntaxique dont un sous-ensemble des ant&#233;c&#233;dents est Hk. De plus Hk
est constitu&#233; uniquement de n&#339;uds dans (H &#8746;N &#8746; F )&gt;. Cet item pr&#233;dit que l&#8217;arbre syntaxique
contient A&#8811; [A1 . . . AkB1 . . . Bl] et que PP (A1) &#9702; &#183; &#183; &#183; &#9702; PP (Ak) = [mi+1 . . . mj].
</p>
<p>C&#8217;est le contr&#244;le de l&#8217;utilisation des n&#339;uds contraints qui complique la t&#226;che de l&#8217;analyseur. Le
triplet d&#8217;ensembles de n&#339;uds (O,U,D) permet de v&#233;rifier les contraintes sur ces n&#339;uds :
&#8211; Les ensemble O et D contiennent des n&#339;uds contraints qui seront disponibles quand on cher-
</p>
<p>chera des ant&#233;c&#233;dents pour pr&#233;dire l&#8217;existence d&#8217;un nouveau n&#339;ud dans l&#8217;arbre syntaxique.
&#8211; Les n&#339;uds de O seront utilis&#233;s obligatoirement dans la sous-analyse courante. Pour qu&#8217;un
</p>
<p>item puisse compl&#233;ter une analyse, il faudra imp&#233;rativement que cet ensemble soit vide.
&#8211; L&#8217;ensemble U contient des n&#339;uds qui &#233;taient disponibles puis ont &#233;t&#233; utilis&#233;s sans que l&#8217;on
</p>
<p>ait encore v&#233;rifi&#233; &#224; quelle sous-analyse ils devaient appartenir.
Par ailleurs, on utilisera 3 symboles suppl&#233;mentaires :
&#8211; &#8868;, la partie gauche de la r&#232;gle point&#233;e axiome. On peut voir &#8868; comme une racine ajout&#233;e &#224;
</p>
<p>l&#8217;arbre syntaxique durant sa construction.
&#8211; Le point &#8226; pourra devenir &#4; ou &#7; dans les r&#232;gles de pr&#233;paration &#224; la pr&#233;diction (p1 et p2) pour
</p>
<p>indiquer que les items les contenant ne peuvent pas &#234;tre utilis&#233;s dans d&#8217;autres r&#232;gles.
Nous aurons besoin de construire des suites d&#8217;ensembles de n&#339;uds superposables qui respectent
les relations de pr&#233;c&#233;dence des DAP. &#201;tant donn&#233; un ensemble de n&#339;uds N , nous d&#233;finissons :
ord(N ) = {[N1 . . .Nk]| (Ni)1&#8804;i&#8804;k est une partition de N&#8743;
</p>
<p>1 &#8804; i &#8804; k,Ni est superposable &#8743;
si n1, n2 &#8712; N et n1 &#8826; n2 alors &#8707;1 &#8804; j &lt; k t.q. n1 &#8712; Nj et n2 &#8712; Nj+1&#8743;
si n1, n2 &#8712; N et n1 &#8826;+ n2 alors &#8707;1 &#8804; i &lt; j &#8804; k t.q. n1 &#8712; Ni et n2 &#8712; Nj}
</p>
<p>3.2 Les r&#232;gles de d&#233;duction
</p>
<p>Dans cette section, on suppose vouloir analyser une phrase d&#8217;entr&#233;e p = m1, . . . , mn avec une
GI G = {&#931;,C, S,P, phon}.
</p>
<p>Axiome C&#8217;est la r&#232;gle de d&#233;part. On se pr&#233;pare &#224; pr&#233;dire un n&#339;ud de cat&#233;gorie initiale S.
Aucun mot n&#8217;a &#233;t&#233; lu et il n&#8217;y a aucune contrainte sur les relations l&#226;ches.
</p>
<p>[&#8868; &#8594; &#8226;S(&#8709;), 0, 0, (&#8709;, &#8709;, &#8709;)]
ax
</p>
<p>Pr&#233;diction C&#8217;est la r&#232;gle qui permet de commencer une sous-analyse. Nous l&#8217;avons divis&#233;e
en 3 sous-r&#232;gles pour introduire les diff&#233;rentes contraintes s&#233;par&#233;ment.
</p>
<p>[A(H,N, F )&#8594; &#945; &#8226; C(Hc)&#946;, i, j, (O,U,D)]
</p>
<p>[C(HC, &#8709;, &#8709;)&#8594; &#4;, j, j, (&#8709;, U,D &#8746;O)]
p1
</p>
<p>Dans cette premi&#232;re &#233;tape, on va commencer une nouvelle sous-analyse &#224; la limite de l&#8217;analyse
courante, en position j. On indique que le focus se situe sur un n&#339;ud C, pour lequel on a d&#233;j&#224;
choisi une partie des ant&#233;c&#233;dents HC .</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Un analyseur syntaxique descendant pour les GI
</p>
<p>Les n&#339;uds de O, qui sont les n&#339;uds &#224; utiliser obligatoirement dans la sous-analyse de A de-
viennent des n&#339;uds disponibles pour l&#8217;analyse de C et toutes les sous-analyses suivantes.
</p>
<p>[C(HC , &#8709;, &#8709;)&#8594; &#4;, j, j, (&#8709;, U1, D1)]
</p>
<p>[C(HC , NC , &#8709;)&#8594; &#7;, j, j, (&#8709;, U2, D2)]
p2
</p>
<p>&#63729;&#63732;&#63732;&#63732;&#63730;
&#63732;&#63732;&#63732;&#63732;&#63731;
</p>
<p>HC &#8746;NC 6= &#8709;
HC &#8746;NC est superposable
NC &#8834; D1 &#8746; P
D2 = D1 &#8722;NC
U2 = U1 &#8746; (D1 &#8745;NC)
</p>
<p>Dans cette seconde sous-r&#232;gle, les ant&#233;c&#233;dents de C sont compl&#233;t&#233;s avec l&#8217;ensemble de n&#339;uds
NC , choisis parmi les n&#339;uds disponibles D1 et les racines des DAP de la GI dans P 3. Le triplet
de v&#233;rification est ensuite mis &#224; jour. Les n&#339;uds contraints choisis pour compl&#233;ter C ne sont
plus disponibles et sont ajout&#233;s &#224; l&#8217;ensemble des n&#339;uds utilis&#233;s.
</p>
<p>[C(HC , NC , &#8709;)&#8594; &#7;, j, j, (&#8709;, U,D)]
</p>
<p>[C(HC , NC , FC)&#8594; &#8226;&#947;, j, j, (O,U,D)]
p3
</p>
<p>&#63729;&#63732;&#63732;&#63732;&#63732;&#63730;
&#63732;&#63732;&#63732;&#63732;&#63731;
</p>
<p>HC &#8746;NC &#8746; FC est satur&#233;
&#947; &#8712; ord((HC &#8746;NC &#8746; FC)&gt;)
FC =
</p>
<p>&#8899;
i Qi, Q0 &#8838; (HC &#8746;NC)
</p>
<p>&gt;&#8727; , Qi+1 &#8838; Q
&gt;&#8727;
</p>
<p>i
</p>
<p>O = (HC &#8746;NC &#8746; FC)&gt;
&#8727;
</p>
<p>&#8722; FC
aucun n&#339;ud ancre dans HC &#8746;NC &#8746; FC
</p>
<p>Dans la derni&#232;re &#233;tape de la pr&#233;diction, on compl&#232;te les ant&#233;c&#233;dents de C avec des n&#339;uds
contraints par des n&#339;uds d&#233;j&#224; ant&#233;c&#233;dents de C. On peut aussi s&#233;lectionner des n&#339;uds dans
la cl&#244;ture transitive de cette relation &#224; condition que leur pr&#233;d&#233;cesseurs aient &#233;t&#233; eux-m&#234;mes
s&#233;lectionn&#233;s. L&#8217;ensemble des ant&#233;c&#233;dents doit alors &#234;tre satur&#233;. Il faut ensuite pr&#233;dire la forme
des prochaines sous-analyses. Pour cela, il faut grouper les fils des ant&#233;c&#233;dents et respecter leur
cat&#233;gories et les relations de pr&#233;c&#233;dence qui existent entre eux. On choisit donc une partition
de (HC , NC , FC)&gt; qui respecte ord. Enfin, les n&#339;uds &#224; utiliser obligatoirement dans les sous-
analyses sont les n&#339;uds contraints par les ant&#233;c&#233;dents qui ne sont pas eux-m&#234;mes ant&#233;c&#233;dents.
</p>
<p>Balayage C&#8217;est la r&#232;gle qui v&#233;rifie les pr&#233;dictions d&#233;j&#224; effectu&#233;es par la pr&#233;sence d&#8217;un terminal
&#224; la position courante de l&#8217;analyse. C&#8217;est un cas particulier de la r&#232;gle pr&#233;c&#233;dente quand l&#8217;un
des ant&#233;c&#233;dents de C est une ancre.
</p>
<p>[C(HC , NC , &#8709;)&#8594; &#7;, j, j, (&#8709;, U,D)]
</p>
<p>[C(HC, NC , FC)&#8594; &#8226;, j, j + 1, (&#8709;, U,D)]
b
</p>
<p>&#63729;&#63732;&#63732;&#63732;&#63732;&#63732;&#63730;
&#63732;&#63732;&#63732;&#63732;&#63732;&#63732;&#63731;
</p>
<p>HC &#8746;NC &#8746; FC est satur&#233;
(HC &#8746;NC &#8746; FC)
</p>
<p>&gt; = &#8709;
FC =
</p>
<p>&#8899;
i Qi, Q0 &#8838; (HC &#8746;NC)
</p>
<p>&gt;&#8727; , Qi+1 &#8838; Q
&gt;&#8727;
</p>
<p>i
</p>
<p>(HC &#8746;NC &#8746; FC)&gt;
&#8727;
</p>
<p>&#8722; FC = &#8709;
un unique n&#339;ud ancre a dans HC &#8746;NC &#8746; FC
phon(a) = pj+1
</p>
<p>Si on lit sur la cha&#238;ne d&#8217;entr&#233;e le terminal attendu &#224; la position courante, on fait progresser
l&#8217;analyse. Cette r&#232;gle ne s&#8217;applique que si tous les n&#339;uds contraints par les ant&#233;c&#233;dents sont
eux-m&#234;mes ant&#233;c&#233;dents, puisqu&#8217;il n&#8217;y a pas de sous-analyse dans laquelle utiliser ces n&#339;uds.
</p>
<p>3. Par abus de langage, on notera de la m&#234;me fa&#231;on une DAP et sa racine. Il faut &#233;galement noter qu&#8217;une racine
peut &#234;tre s&#233;lectionn&#233;e plusieurs fois (si plusieurs occurrences du m&#234;me mot apparaissent dans la phrase &#224; analyser
par exemple) et qu&#8217;un renommage de n&#339;uds peut s&#8217;imposer pour distinguer chaque occurrence.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Joseph Le Roux
</p>
<p>Jean
</p>
<p>= NP
</p>
<p>-&gt; NP
</p>
<p>que
</p>
<p>= CPL
</p>
<p>&lt;- S
</p>
<p>~ S
</p>
<p>~ NP
</p>
<p>~ NP
</p>
<p>-&gt; NP~ V
</p>
<p>Marie
</p>
<p>= NP
</p>
<p>-&gt; S
</p>
<p>&lt;- NP
aimer
</p>
<p>= V
= NP
</p>
<p>-&gt; NP
</p>
<p>~ NP
</p>
<p>&lt;- S
</p>
<p>-&gt; S
</p>
<p>semble
</p>
<p>= V
&lt;- NP
</p>
<p>-&gt; S
</p>
<p>dort
</p>
<p>= V
&lt;- NP
</p>
<p>.
</p>
<p>= PUN
</p>
<p>&lt;- S
</p>
<p>Jean
</p>
<p>NP
S
</p>
<p>que
</p>
<p>CPL
NP S
</p>
<p>semble
</p>
<p>V
</p>
<p>NP
dort
</p>
<p>V
</p>
<p>.
</p>
<p>PUN
</p>
<p>Marie
</p>
<p>NP
NP
</p>
<p>aimer
</p>
<p>V
NP
</p>
<p>S
</p>
<p>FIGURE 1 &#8211; les DAP et l&#8217;arbre d&#8217;analyse pour Jean que Marie semble aimer dort.
</p>
<p>Compl&#233;tion Cette r&#232;gle permet de revenir d&#8217;une sous-analyse et d&#8217;&#233;tendre l&#8217;analyse courante.
</p>
<p>[A(H,N, F )&#8594; &#945; &#8226; C(Hc)&#946;, i, j, (O1, U1, D1)]
[C(HC , NC , FC)&#8594; &#947;&#8226;, j, k, (&#8709;, U2, D2)]
[A(H,N, F )&#8594; &#945;C &#8226; &#946;, i, k, (O3, U3, D3)]
</p>
<p>c
</p>
<p>&#63729;&#63732;&#63732;&#63732;&#63732;&#63732;&#63730;
&#63732;&#63732;&#63732;&#63732;&#63732;&#63732;&#63731;
</p>
<p>NC &#8838; D1 &#8746; O1 &#8746; P
D2 &#8838; (D1 &#8746; O1)&#8722;NC
U1 &#8838; U2
O3 = O1 &#8722; U2
D3 = D1 &#8722; U2
U3 = U2 &#8722; O1
</p>
<p>On doit ici s&#8217;assurer que la sous-analyse de C peut &#234;tre branch&#233;e sur l&#8217;analyse courante :
&#8211; L&#8217;ensemble des n&#339;uds disponibles dans la sous-analyse est un sous-ensemble des n&#339;uds
</p>
<p>disponibles dans l&#8217;analyse principale. En d&#8217;autres termes, la sous-analyse a pu utiliser des
n&#339;uds qui &#233;taient disponibles dans l&#8217;analyse principale mais n&#8217;a pas pu rendre de nouveaux
n&#339;uds disponibles sans les avoir utilis&#233;s.
</p>
<p>&#8211; Pour les m&#234;mes raisons, l&#8217;ensemble des n&#339;uds utilis&#233;s dans l&#8217;analyse principale doit &#234;tre un
sous-ensemble des n&#339;uds utilis&#233;s dans la sous-analyse.
</p>
<p>&#8211; On retire des n&#339;uds &#224; utiliser obligatoirement ceux qui ont &#233;t&#233; utilis&#233;s dans la sous-analyse.
</p>
<p>Item but L&#8217;analyse r&#233;ussit si l&#8217;on obtient [&#8868; &#8594; S&#8226;, 0, n, (&#8709;, &#8709;, &#8709;)].
</p>
<p>3.3 Exemple
</p>
<p>Pour voir comment les relations de parent&#233; l&#226;che sont contr&#244;l&#233;es, nous allons analyser la phrase
Jean que Marie semble aimer dort. On peut voir les DAP utilis&#233;es pour l&#8217;analyse sur la Figure 1.
Elles proviennent du logiciel LEOPAR 4. Nous appellerons les descriptions j, q,m, s, a, d et p et
nous d&#233;signerons les positions des n&#339;uds par leur adresse de Gorn. Par exemple la racine de la
DAP associ&#233;e &#224; Marie est m et le n&#339;ud le plus &#233;loign&#233; de la racine de la DAP associ&#233;e &#224; semble
est s31. Les relations &gt; et &gt;&#8727; sont repr&#233;sent&#233;es par des traits, respectivement plein et pointill&#233;.
Les relations &#8826; et &#8826;+ sont repr&#233;sent&#233;es par des fl&#232;ches, respectivement noire et color&#233;e. Les
items qui permettent d&#8217;arriver une analyse et les r&#232;gles pour les produire sont list&#233;s dans la
Table 1.
</p>
<p>4. Ce logiciel est disponible &#224; http://leopar.loria.fr/.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Un analyseur syntaxique descendant pour les GI
</p>
<p>L&#8217;algorithme commence par pr&#233;dire une racine S image de d et p (items 1, 2 et 3), puis ordonne
les fils de ces n&#339;uds (item 4). L&#8217;analyse se poursuit par la pr&#233;diction d&#8217;un n&#339;ud NP dont un
des ant&#233;c&#233;dents doit &#234;tre d1, puisque d a &#233;t&#233; choisi plus t&#244;t. L&#8217;analyse se poursuit jusqu&#8217;&#224; la
pr&#233;diction du n&#339;ud S (item 12) dont la projection phonologique est que Marie semble aimer.
Ce n&#339;ud a pour ant&#233;c&#233;dents q2 et s. Le n&#339;ud q22 contraint par q2 n&#8217;est pas ant&#233;c&#233;dent, il doit
donc &#234;tre obligatoirement utilis&#233; dans cette sous-analyse et il est ajout&#233; &#224; l&#8217;ensemble O de cet
item. Ce n&#339;ud devient ensuite disponible pour l&#8217;analyse de que et semble mais n&#8217;est pas utilis&#233;.
Il est donc toujours dans l&#8217;ensemble O de l&#8217;item 22, ainsi que dans celui de l&#8217;item 24.
Les items 25, 26 et 27 d&#233;crivent la pr&#233;diction du n&#339;ud S dont la projection phonologique est
aimer. On s&#233;lectionne q22 comme ant&#233;c&#233;dent qui devient utilis&#233; (ensemble U). Lors de la com-
pl&#233;tion du S dont la projection phonologique est que Marie semble aimer (item 34), le contrat
qui for&#231;ait l&#8217;utilisation de q22 a &#233;t&#233; rempli et on retire donc ce n&#339;ud des n&#339;uds obligatoires. Le
reste de l&#8217;analyse ne pose pas de probl&#232;me particulier.
</p>
<p>4 Discussion
</p>
<p>4.1 Correction et compl&#233;tude
</p>
<p>L&#8217;algorithme pr&#233;sent&#233; maintient un invariant tout au long de l&#8217;analyse. Chaque item de la forme
[A(H,N, F )&#8594; &#945; &#8226; &#946;, i, j, (O,U,D)] assure que :
&#8211; A est mod&#232;le d&#8217;un ensemble satur&#233; de n&#339;uds qui ne sont plus disponibles pour &#234;tre ant&#233;c&#233;-
</p>
<p>dents d&#8217;un autre n&#339;ud de l&#8217;arbre syntaxique en construction. Il en est de m&#234;me des n&#339;uds
dans &#945;. Les conditions 1, 7 et 3 (cas r&#233;flexif) que doit v&#233;rifier un mod&#232;le sont respect&#233;es.
</p>
<p>&#8211; Les ensembles &#946;k sont superposables. On a &#946;k &#8838; (A&#8722;1)&gt; (conditions 2 et 6)
&#8211; l&#8217;ordre des &#945;&#946; est compatible avec les relations d&#8217;ordre des DAP (conditions 4 et 5).
&#8211; PP (&#945;1) &#9702; . . . &#9702; PP (&#945;l) = [mi+1 &#183; &#183; &#183;mj ]
&#8211; les n&#339;uds de O sont des n&#339;uds contraints en relation avec des n&#339;uds de DAP qui sont
</p>
<p>ant&#233;c&#233;dents de A et qui n&#8217;ont pas encore &#233;t&#233; utilis&#233;s comme ant&#233;c&#233;dents.
&#8211; les n&#339;uds de D sont des n&#339;uds contraints en relation avec des n&#339;uds de DAP qui sont
</p>
<p>ant&#233;c&#233;dents de n&#339;uds de l&#8217;arbre syntaxique situ&#233;s entre sa racine et A et qui n&#8217;ont pas encore
&#233;t&#233; utilis&#233;s comme ant&#233;c&#233;dents
</p>
<p>&#8211; un n&#339;ud N de U est un n&#339;ud contraint en relation par &gt;&#8727; avec un n&#339;ud de DAP qui est
ant&#233;c&#233;dent d&#8217;un n&#339;ud situ&#233; &#224; la fois entre la racine de l&#8217;arbre syntaxique et A, distinct de A
et entre la racine et I(N) (condition 3).
</p>
<p>On peut v&#233;rifier cet invariant par induction sur les r&#232;gles. En d&#8217;autres termes un tel item affirme
qu&#8217;il existe une fonction partielle J des n&#339;uds d&#8217;un sous-ensemble des DAP d&#8217;une GI vers
un arbre syntaxique de racine &#233;tiquet&#233;e par O et qui a pour projection phonologique m1 . . .mj .
Cette fonction J est similaire &#224; la fonction I des mod&#232;les. Elle v&#233;rifie les m&#234;mes propri&#233;t&#233;s mais
les conditions 2&#8211;5 ne sont respect&#233;es que si les deux n&#339;uds sont dans le domaine. L&#8217;algorithme
&#233;tend cette fonction J jusqu&#8217;&#224; (1) l&#8217;obtention d&#8217;une fonction totale et (2) la couverture compl&#232;te
de la cha&#238;ne d&#8217;entr&#233;e. J d&#233;finit alors un arbre syntaxique qui est un arbre d&#8217;analyse.
</p>
<p>D&#8217;autre part, s&#8217;il existe un arbre syntaxique pour une GI et une phrase d&#8217;entr&#233;e, un parcours
pr&#233;fixe de cet arbre permet de retrouver les items cr&#233;&#233;s par l&#8217;algorithme</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Joseph Le Roux
</p>
<p>1 [&#8868; &#8594; &#8226;S(&#8709;), 0, 0, (&#8709;, &#8709;, &#8709;)] ax
2 [S(&#8709;, &#8709;, &#8709;)&#8594; &#4;, 0, 0, (&#8709;, &#8709;, &#8709;)] p1(1)
3 [S(&#8709;, {d, p}, &#8709;)&#8594; &#7;, 0, 0, (&#8709;, &#8709;, &#8709;)] p2(2)
4 [S(&#8709;, {d, p}, &#8709;)&#8594; &#8226;NP(d1)V (d2)PUN(p1), 0, 0, (&#8709;, &#8709;, &#8709;)] p3(3)
5 [NP({d1}, &#8709;, &#8709;)&#8594; &#4;, 0, 0, (&#8709;, &#8709;, &#8709;)] p1(4)
6 [NP({d1}, {j, q}, &#8709;)&#8594; &#7;, 0, 0, (&#8709;, &#8709;, &#8709;)] p2(5)
7 [NP({d1}, {j, q}, &#8709;)&#8594; &#8226;NP(j1, q1)S(q2), 0, 0, (&#8709;, &#8709;, &#8709;)] p3(6)
8 [NP({j1, q1}, &#8709;, &#8709;)&#8594; &#8226;, 0, 1, (&#8709;, &#8709;, &#8709;)] b &#9702; p2 &#9702; p1(7)
9 [NP({d1}, {j, q}, &#8709;)&#8594; NP &#8226; S(q2), 0, 1, (&#8709;, &#8709;, &#8709;)] c(7, 8)
10 [S({q2}, &#8709;, &#8709;)&#8594; &#4;, 1, 1, (&#8709;, &#8709;, &#8709;)] p1(9)
11 [S({q2}, {s}, &#8709;)&#8594; &#7;, 1, 1, (&#8709;, &#8709;, &#8709;)] p2(10)
12 [S({q2}, {s}, &#8709;)&#8594; &#8226;CPL(q21)NP(s1)V (s2)S(s3), 1, 1, ({q22}, &#8709;, &#8709;)] p3(11)
13 [CPL({q21}, &#8709;, &#8709;)&#8594; &#4;, 1, 1, (&#8709;, &#8709;, {q22})] p1(12)
14 [CPL({q21}, &#8709;, &#8709;)&#8594; &#7;, 1, 1, (&#8709;, &#8709;, {q22})] p2(13)
15 [CPL({q21}, &#8709;, &#8709;)&#8594; &#8226;, 1, 2, (&#8709;, &#8709;, {q22})] b(14)
16 [S({q2}, {s}, &#8709;)&#8594; CPL &#8226; NP(s1)V (s2)S(s3), 1, 2, ({q22}, &#8709;, &#8709;)] c(12, 15)
17 [NP({s1}, &#8709;, &#8709;)&#8594; &#4;, 2, 2, (&#8709;, &#8709;, {q22})] p1(16)
18 [NP({s1}, {m}, &#8709;)&#8594; &#7;, 2, 2, (&#8709;, &#8709;, {q22})] p2(17)
19 [NP({s1}, {m}, &#8709;)&#8594; &#8226;NP(m1), 2, 2, (&#8709;, &#8709;, {q22})] p3(18)
20 [NP({m1}, &#8709;, &#8709;)&#8594; &#8226;, 2, 3, (&#8709;, &#8709;, {q22})] b &#9702; p2 &#9702; p1(19)
21 [NP({s1}, {m}, &#8709;)&#8594; NP&#8226;, 2, 3, (&#8709;, &#8709;, {q22})] c(19, 20)
22 [S({q2}, {s}, &#8709;)&#8594; CPL NP &#8226; V (s2)S(s3), 1, 3, ({q22}, &#8709;, &#8709;)] c(16, 21)
23 [V ({s2}, &#8709;, &#8709;)&#8594; &#8226;, 3, 4, (&#8709;, &#8709;, {q22})] b &#9702; p2 &#9702; p1(22)
24 [S({q2}, {s}, &#8709;)&#8594; CPL NP V &#8226; S(s3), 1, 4, ({q22}, &#8709;, &#8709;)] c(22, 23)
25 [S({s3}, &#8709;, &#8709;)&#8594; &#4;, 4, 4, (&#8709;, &#8709;, {q22})] p1(24)
26 [S({s3}, {a, q22}, &#8709;)&#8594; &#7;, 4, 4, (&#8709;, {q22}, &#8709;)] p2(25)
27 [S({s3}, {a, q22}, &#8709;)&#8594; &#8226;NP(a1, s31)V (a2, q221)NP(q222, a3), 4, 4, (&#8709;, {q22}, &#8709;)] p3(26)
28 [NP({a1, s31}, &#8709;, &#8709;)&#8594; &#8226;, 4, 4, (&#8709;, {q22}, &#8709;)] p3 &#9702; p2 &#9702; p1(27)
29 [S({s3}, {a, q22}, &#8709;)&#8594; NP &#8226; V (a2, q221)NP(q222, a3), 4, 4, (&#8709;, {q22}, &#8709;)] c(27, 28)
30 [V ({a2, q221}, &#8709;, &#8709;)&#8594; &#8226;, 4, 5, (&#8709;, {q22}, &#8709;)] b &#9702; p2 &#9702; p1(29)
31 [S({s3}, {a, q22}, &#8709;)&#8594; NP V &#8226; NP(q222, a3), 4, 5, (&#8709;, {q22}, &#8709;)] c(29, 30)
32 [NP({q222, a3}, &#8709;, &#8709;)&#8594; &#8226;, 5, 5, (&#8709;, {q22}, &#8709;)] p3 &#9702; p2 &#9702; p1(31)
33 [S({s3}, {a, q22}, &#8709;)&#8594; NP V NP&#8226;, 4, 5, (&#8709;, {q22}, &#8709;)] c(31, 32)
34 [S({q2}, {s}, &#8709;)&#8594; CPL NP V S&#8226;, 1, 5, (&#8709;, &#8709;, &#8709;)] c(24, 33)
35 [NP({d1}, {j, q}, &#8709;)&#8594; NP S&#8226;, 0, 5, (&#8709;, &#8709;, &#8709;)] c(9, 34)
36 [S(&#8709;, {d, p}, &#8709;)&#8594; NP &#8226; V (d2)PUN(p1), 0, 5, (&#8709;, &#8709;, &#8709;)] c(4, 35)
37 [V ({d2}, &#8709;, &#8709;)&#8594; &#8226;, 5, 6, (&#8709;, &#8709;, &#8709;)] b &#9702; p2 &#9702; p1(36)
38 [S(&#8709;, {d, p}, &#8709;)&#8594; NP V &#8226; PUN(p1), 0, 6, (&#8709;, &#8709;, &#8709;)] c(36, 37)
39 [PUN({p1}, &#8709;, &#8709;)&#8594; &#8226;, 6, 7, (&#8709;, &#8709;, &#8709;)] b &#9702; p2 &#9702; p1(38)
40 [S(&#8709;, {d, p}, &#8709;)&#8594; NP V PUN&#8226;, 0, 7, (&#8709;, &#8709;, &#8709;)] c(38, 39)
41 [&#8868; &#8594; S&#8226;, 0, 7, (&#8709;, &#8709;, &#8709;)] c(1, 40)
</p>
<p>TABLE 1 &#8211; Items pour l&#8217;analyse de Jean que Marie semble aimer dort.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Un analyseur syntaxique descendant pour les GI
</p>
<p>4.2 Complexit&#233;
</p>
<p>Le probl&#232;me de l&#8217;analyse des GI est un probl&#232;me NP-difficile dans le cas lexicalis&#233; et m&#234;me en
l&#8217;absence d&#8217;ambigu&#239;t&#233; lexicale (Bonfante et al., 2003).
En regardant les r&#232;gles de notre algorithme, on peut voir plusieurs sources d&#8217;ind&#233;terminisme :
&#8211; dans la r&#232;gle p2, il faut choisir de nouveaux ant&#233;c&#233;dents (l&#8217;ensemble NC) qui soient super-
</p>
<p>posables avec les ant&#233;c&#233;dents h&#233;rit&#233;s des choix pr&#233;c&#233;dents (l&#8217;ensemble HC). Ces nouveaux
ant&#233;c&#233;dents sont &#224; choisir parmi les n&#339;uds disponibles et les racines des DAP de la GI uti-
lis&#233;e. Il y a un nombre exponentiel de tels choix, d&#8217;autant plus grand que les GI r&#233;alistes
contiennent plus de 2000 DAP.
Cependant, en pratique, on va filtrer les choix possibles gr&#226;ce aux cat&#233;gories et aux polarit&#233;s.
De plus, les GI utilis&#233;es dans l&#8217;implantation LEOPAR sont lexicalis&#233;es. On ne va donc consi-
d&#233;rer qu&#8217;un sous-ensemble des DAP de la grammaire, qui correspond aux DAP qui ont pour
ancre un mot de la phrase d&#8217;entr&#233;e. Enfin, des techniques de filtrages lexical (supertagging)
tr&#232;s efficaces ont &#233;t&#233; d&#233;velopp&#233;es pour les GI, comme (Bonfante et al., 2006) qui permettent
de restreindre de fa&#231;on drastique le nombre de DAP qui peuvent &#234;tre utilis&#233;es.
</p>
<p>&#8211; dans la r&#232;gle p3 et la r&#232;gle b, il faut choisir un sous-ensemble de n&#339;uds contraints par des
ant&#233;c&#233;dents d&#233;j&#224; choisis. Ici encore il existe un nombre exponentiel de choix. Cependant,
dans les GI utilis&#233;es en pratique, les n&#339;uds des DAP ont au plus un successeur par la relation
&gt;&#8727; et il n&#8217;existe pas de cha&#238;ne de n&#339;uds reli&#233;s par &gt;&#8727;. On peut donc borner le nombre de
n&#339;uds dans FC par le nombre de n&#339;uds dans HC &#8746;NC .
</p>
<p>&#8211; dans la r&#232;gle p3, on doit ordonner et partitionner les fils par &gt; des ant&#233;c&#233;dents. Dans le cas o&#249;
il n&#8217;existe aucune relation de pr&#233;c&#233;dence entre ces fils, il y a &#224; nouveau un nombre exponentiel
de possibilit&#233;. Cependant, en pratique, le nombre de n&#339;uds &#224; ordonner/partitionner est petit.
On peut imaginer calculer l&#8217;ordre de fa&#231;on paresseuse en l&#8217;&#233;tendant &#224; chaque compl&#233;tion,
comme le proposent (Nederhof et al., 2003) pour les pomset-CFG.
</p>
<p>On remarque que la r&#232;gle qui fait intervenir le plus d&#8217;indices de position est la compl&#233;tion et
qu&#8217;il n&#8217;y a pas d&#8217;ind&#233;terminisme &#224; cette &#233;tape. Ce n&#8217;est donc pas directement la taille de la
phrase qui rend le probl&#232;me de l&#8217;analyse des GI difficile mais la taille de la GI et des DAP &#224;
consid&#233;rer. La longueur de la phrase ne joue qu&#8217;un r&#244;le indirect, le nombre de DAP utilisables
augmentant avec le nombre de mots.
</p>
<p>5 Conclusion
</p>
<p>Nous avons pr&#233;sent&#233; un algorithme d&#8217;analyse pour les GI. Bien que nous ayons utilis&#233; une
version sans structure de traits, nous pensons qu&#8217;il n&#8217;y a aucune difficult&#233; majeure &#224; y ajouter
un m&#233;canisme d&#8217;unification.
</p>
<p>L&#8217;originalit&#233; de notre travail r&#233;side dans l&#8217;utilisation du cadre formel de l&#8217;analyse d&#233;ductive pour
un formalisme qui se r&#233;clame de l&#8217;approche par th&#233;orie des mod&#232;les (Pullum &amp; Scholz, 2001).
Ce cadre formel permet de distinguer les sources de l&#8217;ind&#233;terminisme qui rendent difficile le
probl&#232;me de l&#8217;analyse dans les GI. Ce travail est donc un premier pas vers une &#233;tude plus
approfondie de sa complexit&#233;.
</p>
<p>&#192; l&#8217;avenir, il sera int&#233;ressant de rechercher, comme pour la m&#233;thode shift-reduce ou comme
pour les (k-)TT-MCTAG (Kallmeyer &amp; Parmentier, 2008), des approximations de l&#8217;algorithme
ou du formalisme qui ne consid&#232;rent qu&#8217;un nombre born&#233; de n&#339;uds &#224; chaque &#233;tape, de mani&#232;re</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Joseph Le Roux
</p>
<p>&#224; rendre l&#8217;analyse efficace (polynomiale).
</p>
<p>R&#233;f&#233;rences
BONFANTE G., GUILLAUME B. &amp; PERRIER G. (2003). Analyse syntaxique &#233;lectrostatique.
Traitement Automatique des Langues.
BONFANTE G., LE ROUX J. &amp; PERRIER G. (2006). Lexical disambiguation with polarities
and automata. In O. H. IBARRA &amp; H.-C. YEN, Eds., The 11th International Conference on
Implementation and Application of Automata (CIAA 2006).
CHOMSKY N. (1995). The Minimalist Program. MIT Press.
DUCHIER D. &amp; THATER S. (1999). Parsing with tree descriptions : a constraint based ap-
proach. In Natural Language Understanding and Logic Programming NLULP&#8217;99, Dec 1999,
Las Cruces, New Mexico.
EARLEY J. (1970). An efficient context-free parsing algorithm. Communications of the ACM,
13(2), 94&#8211;102.
GUILLAUME B. &amp; PERRIER G. (2008). Interaction Grammars. Research Report RR-6621,
INRIA.
KAHANE S. (2004). Grammaires d&#8217;unification polaris&#233;es. In TALN2004, F&#232;s, Maroc, p. 233&#8211;
242.
KALLMEYER L. &amp; PARMENTIER Y. (2008). Convertir des grammaires d&#8217;arbres adjoints
&#224; composantes multiples avec tuples d&#8217;arbres (TT-MCTAG) en grammaires &#224; concat&#233;nation
d&#8217;intervalles (RCG). In 15e Conf&#233;rence sur le Traitement Automatique des Langues Natu-
relles, Avignon France : ATALA.
LAMBEK J. (1958). The mathematics of sentence structure. American Mathematical Monthly,
65(3), 154&#8211;170.
LE ROUX J. (2007). La coordination dans les grammaires d&#8217;interaction. PhD thesis, Ecole
Doctorale IAEM Lorraine ; Institut National Polytechnique de Lorraine - INPL.
NEDERHOF M., SATTA G. &amp; SHIEBER S. (2003). Partially ordered multiset context-free
grammars and ID/LP parsing. In Proceedings of the Eighth International Workshop on Parsing
Technologies, p. 171&#8211;182, Nancy, France.
PULLUM G. &amp; SCHOLZ B. (2001). On the distinction between model-theoretic and
generative-enumerative syntactic frameworks. In Proccedings of the 4th conference on Lo-
gical Aspects of Computational Linguistics.
SHIEBER S., SCHABES Y. &amp; PEREIRA F. P. (1995). Principles and implementation of deduc-
tive parsing. Journal of Logic Programming, 24(1&#8211;2), 3&#8211;36.</p>

</div></div>
</body></html>