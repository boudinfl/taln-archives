TALN 2009, Senlis, 24–26 juin 2009
Analyse déductive pour les grammaires d’interaction
Joseph Le Roux
NCLT, Dublin City University
jleroux@computing.dcu.ie
Résumé. Nous proposons un algorithme d’analyse pour les grammaires d’interaction qui
utilise le cadre formel de l’analyse déductive. Cette approche donne un point de vue nouveau sur
ce problème puisque les méthodes précédentes réduisaient ce dernier à la réécriture de graphes
et utilisaient des techniques de résolution de contraintes. D’autre part, cette présentation per-
met de décrire le processus de manière standard et d’exhiber les sources d’indéterminisme qui
rendent ce problème difficile.
Abstract. We propose a parsing algorithm for Interaction Grammars using the deductive
parsing framework. This approach brings new perspectives on this problem, departing from
previous methods relying on constraint-solving techniques to interpret it as a graph-rewriting
problem. Furthermore, this presentation allows a standard description of the algorithm and a
fine-grained inspection of the sources of non-determinism.
Mots-clés : Analyse syntaxique, grammaires d’interaction.
Keywords: Parsing, Interaction Grammars.
1 Introduction
Une grammaire d’interaction (GI) (Guillaume & Perrier, 2008) permet de décrire la syntaxe
d’une langue en insistant sur la valence, c’est-à-dire la capacité des mots à se combiner. Cette
valence s’exprime au moyen de polarités qui décorent les syntagmes ou les traits associés à
ces syntagmes. D’autres formalismes utilisent cette notion, comme les grammaires catégo-
rielles (Lambek, 1958), les grammaires d’unification polarisées (Kahane, 2004) ou encore les
grammaires minimalistes (Chomsky, 1995). Une autre caractéristique des GI est l’utilisation de
structures dites sous-spécifiées. Les grammaires de (Duchier & Thater, 1999) utilisent aussi ces
structures mais avec un système de polarités moins riche.
Dans cet article, nous présentons un algorithme proche de celui décrit par (Earley, 1970) pour
l’analyse des grammaires hors-contexte. D’autres méthodes d’analyse existent pour les GI,
comme par exemple la méthode shift-reduce de (Bonfante et al., 2003) qui réduit l’analyse à
la réécriture de graphes. Ici, nous considérons une approche radicalement différente. Nous in-
troduisons notre algorithme en utilisant une méthode standard de ce domaine : l’analyse déduc-
tive (Shieber et al., 1995). Cette approche évite d’inventer des notions et des notations ad hoc.
Elle permet aussi aux lecteurs qui y sont habitués de comprendre rapidement les spécificités de
l’analyse des GI. (Le Roux, 2007) décrit un algorithme très proche mais notre présentation, en
décomposant la prédiction, est bien plus simple.
Le reste de l’article s’organise comme suit : nous présentons les GI (section 2), puis nous dé-
Joseph Le Roux
crivons l’algorithme (section 3). Nous discutons ensuite certains aspects techniques de l’algo-
rithme (section 4) avant de conclure (section 5).
2 Les grammaires d’interaction
Nous reprenons la définition des GI donnée par (Guillaume & Perrier, 2008) 1. Cependant, nous
présentons ici une version sans structure de traits de manière à simplifier l’exposé.
2.1 Descriptions d’arbre polarisées
La structure fondamentale des GI est la description d’arbre polarisée (DAP) qui représente un
fragment d’arbre d’analyse. Elle contient des nœuds polarisés, c’est-à-dire décorés de polarités.
Les GI distinguent 4 polarités P = {→,←,=,∼}, respectivement positive, négative, neutre
et virtuelle. Un multi-ensemble de polarités est saturé s’il contient exactement une polarité
positive et exactement une polarité négative, ou bien s’il ne contient aucune polarité positive ni
négative et au moins une polarité neutre. Un multi-ensemble de polarités est superposable s’il
contient au plus une polarité positive et au plus une polarité négative.
Les nœuds polarisés sont étiquetés par une catégorie et une polarité. Un ensemble de nœuds est
saturé (resp. superposable) si tous ses éléments ont la même catégorie et si le multi-ensemble
induit par leur polarité est saturé (resp. superposable).
Une DAP est un graphe. Il existe quatre relations binaires définies sur les nœuds polarisés d’une
DAP : la parenté immédiate>, la parenté lâche >∗, la précédence immédiate≺ et la précédence
lâche ≺+. De plus, pour être valide une DAP doit vérifier :
– > et >∗ définissent une structure d’arbre,
– ≺ et ≺+ ne sont définies que pour des nœuds ayant le même antécédent par >.
Dans chaque DAP il existe des nœuds feuilles (sans descendant par > ou >∗), appelés ancres.
Pour alléger l’exposé , si n >∗ m, on appelle m un nœud contraint (par n) et pour un ensemble
N de nœuds, on définit N> = {N |∃M ∈ N ,M > N} et N>∗ = {N |∃M ∈ N ,M >∗ N}.
2.2 Grammaires d’interaction
Une GI est un tuple G = {Σ,C, S,P, phon}, où Σ est l’alphabet des symboles terminaux, C
est l’alphabet des symboles non-terminaux (ou catégories), S ∈ C est le symbole initial, P est
un ensemble de DAP dont les nœuds sont étiquetés par des éléments de C× P et phon est une
fonction partielle des nœuds de P vers Σ. Elle n’est définie que pour les ancres.
Le résultat d’une analyse syntaxique est un arbre syntaxique, c’est-à-dire un arbre totalement
ordonné dans lequel tous les nœuds sont étiquetés par une catégorie. On note lab(A) l’étiquette
du nœud A. Certains nœuds feuilles F sont étiquetés par un terminal t. Dans ce cas, on notera
mot(F ) = t, et mot(F ) = ε sinon.
On notera M ≫ N si le nœud M est le père du nœud N et N ≫ [N1, . . . , Nk] si le nœud N est
le père des nœuds de la liste ordonnée [N1, . . . , Nk]. L’ordre entre nœuds fils s’exprime à l’aide
1. Nous reportons les lecteurs à cet article pour ce qui concerne l’utilisation linguistique des GI.
Un analyseur syntaxique descendant pour les GI
de de la relation ≺≺. M ≺≺ N indique que N est le successeur immédiat de M . On notera
≺≺+ la clôture transitive de ≺≺ et ≫∗ la clôture réflexive transitive de ≫.
Enfin nous avons besoin de la projection phonologique PP d’un nœud, définie récursivement :
{
[t] si M ≫ [] et mot(M) = t
PP (M) =
[PP (N1) . . . PP (Nk)] si M ≫ [N1, . . . , Nk]
Un arbre syntaxique T est un modèle du multi-ensemble de DAP D s’il existe une fonction
totale I des nœuds de D (notés ND) vers les nœuds de T (notés NT ) qui vérifie :
1. si A ∈ NT alors I−1(A) est saturé et non-vide.
2. si M,N ∈ ND et M > N alors I(M)≫ I(N)
3. si M,N ∈ ND et M >∗ N alors I(M)≫∗ I(N)
4. si M,N ∈ ND et M ≺ N alors I(M) ≺≺ I(N)
5. si M,N ∈ ND et M ≺+ N alors I(M) ≺≺+ I(N)
6. si A,B ∈ NT et A≫ B alors il existe M ∈ I−1(A) et N ∈ I−1(B) tels que M > N
7. si A ∈ NT alors lab(A) = lab(M) pour tout M ∈ I−1(A)
8. si M ∈ ND et phon(M) = m alors PP (I(M)) = [m]
Étant donné une GI G = {Σ,C, S,P, phon} et une phrase p = m1, . . . , mn de Σ∗, un arbre
syntaxique T est un arbre d’analyse pour p s’il existe un multi-ensembleD de DAP issues de P
tel que T est un modèle de D, la racine R de T est étiquetée par S et PP (R) = [m1, . . . , mn].
Le langage engendré par G est l’ensemble des phrases de Σ∗ pour lesquelles il existe un arbre
d’analyse.
3 Définition de l’algorithme
Nous utilisons le cadre de l’analyse déductive (Shieber et al., 1995) pour expliquer notre algo-
rithme : un état de l’analyse est décrit par un item et des règles de déduction permettent d’obtenir
de nouveaux items à partir d’items déjà créés. On applique ces règles jusqu’à stabilisation de
l’ensemble d’items. L’analyse est amorcée par la création d’un item axiome. La phrase d’entrée
appartient au langage si un item spécifique, appelé item but est créé durant l’analyse 2.
3.1 Les items
Nos items sont de la forme [A(H,N, F )→ α•β, i, j, (O,U,D)]. Ils sont constitués d’une règle
pointée, de deux indices de position 0 ≤ i ≤ j ≤ n, où n est la longueur de la phrase d’entrée,
et d’un triplet d’ensembles de nœuds qui contrôle l’utilisation des nœuds contraints.
La règle pointée A(H,N, F ) → α • β affirme qu’il existe un nœud A de l’arbre d’analyse,
modèle de l’ensemble H ∪N ∪F . Les éléments Al dans α sont également des nœuds de l’arbre
syntaxique. Ils indiquent que des sous-analyses ont déjà été effectuées et que l’on a trouvé pour
2. Nous présentons ici un reconnaisseur. Pour en faire un analyseur, il faudrait garder l’historique des items.
Joseph Le Roux
ces nœuds des ensembles d’antécédents saturés. Les élémentsBk(Hk)de β signifient qu’il existe
un nœud Bk dans l’arbre syntaxique dont un sous-ensemble des antécédents est Hk. De plus Hk
est constitué uniquement de nœuds dans (H ∪N ∪ F )>. Cet item prédit que l’arbre syntaxique
contient A≫ [A1 . . . AkB1 . . . Bl] et que PP (A1) ◦ · · · ◦ PP (Ak) = [mi+1 . . . mj].
C’est le contrôle de l’utilisation des nœuds contraints qui complique la tâche de l’analyseur. Le
triplet d’ensembles de nœuds (O,U,D) permet de vérifier les contraintes sur ces nœuds :
– Les ensemble O et D contiennent des nœuds contraints qui seront disponibles quand on cher-
chera des antécédents pour prédire l’existence d’un nouveau nœud dans l’arbre syntaxique.
– Les nœuds de O seront utilisés obligatoirement dans la sous-analyse courante. Pour qu’un
item puisse compléter une analyse, il faudra impérativement que cet ensemble soit vide.
– L’ensemble U contient des nœuds qui étaient disponibles puis ont été utilisés sans que l’on
ait encore vérifié à quelle sous-analyse ils devaient appartenir.
Par ailleurs, on utilisera 3 symboles supplémentaires :
– ⊤, la partie gauche de la règle pointée axiome. On peut voir ⊤ comme une racine ajoutée à
l’arbre syntaxique durant sa construction.
– Le point • pourra devenir  ou  dans les règles de préparation à la prédiction (p1 et p2) pour
indiquer que les items les contenant ne peuvent pas être utilisés dans d’autres règles.
Nous aurons besoin de construire des suites d’ensembles de nœuds superposables qui respectent
les relations de précédence des DAP. Étant donné un ensemble de nœuds N , nous définissons :
ord(N ) = {[N1 . . .Nk]| (Ni)1≤i≤k est une partition de N∧
1 ≤ i ≤ k,Ni est superposable ∧
si n1, n2 ∈ N et n1 ≺ n2 alors ∃1 ≤ j < k t.q. n1 ∈ Nj et n2 ∈ Nj+1∧
si n1, n2 ∈ N et n1 ≺+ n2 alors ∃1 ≤ i < j ≤ k t.q. n1 ∈ Ni et n2 ∈ Nj}
3.2 Les règles de déduction
Dans cette section, on suppose vouloir analyser une phrase d’entrée p = m1, . . . , mn avec une
GI G = {Σ,C, S,P, phon}.
Axiome C’est la règle de départ. On se prépare à prédire un nœud de catégorie initiale S.
Aucun mot n’a été lu et il n’y a aucune contrainte sur les relations lâches.
ax
[⊤ → •S(∅), 0, 0, (∅, ∅, ∅)]
Prédiction C’est la règle qui permet de commencer une sous-analyse. Nous l’avons divisée
en 3 sous-règles pour introduire les différentes contraintes séparément.
[A(H,N, F )→ α • C(Hc)β, i, j, (O,U,D)]
p1
[C(HC, ∅, ∅)→ , j, j, (∅, U,D ∪O)]
Dans cette première étape, on va commencer une nouvelle sous-analyse à la limite de l’analyse
courante, en position j. On indique que le focus se situe sur un nœud C, pour lequel on a déjà
choisi une partie des antécédents HC .
Un analyseur syntaxique descendant pour les GI
Les nœuds de O, qui sont les nœuds à utiliser obligatoirement dans la sous-analyse de A de-
viennent des nœuds disponibles pour l’analyse de C et toutes les sous-analyses suivantes.
 H
[ 
C ∪NC 6= ∅
H
C(HC , ∅, ∅)→ , j, j, (∅, U1, D
C ∪NC est superposable
1)]
p2 NC ⊂ D1 ∪ P
[C(HC , NC , ∅)→ , j, j, (∅, U2, D2)]  D2 = D1 −NC
U2 = U1 ∪ (D1 ∩NC)
Dans cette seconde sous-règle, les antécédents de C sont complétés avec l’ensemble de nœuds
NC , choisis parmi les nœuds disponibles D1 et les racines des DAP de la GI dans P 3. Le triplet
de vérification est ensuite mis à jour. Les nœuds contraints choisis pour compléter C ne sont
plus disponibles et sont ajoutés à l’ensemble des nœuds utilisés.
 H N aturé
[ 
C ∪ C ∪ FC est s
γ ∈ or
C(HC , NC , ∅)→ , j, j, (∅, U,D)] ⋃d((HC ∪NC ∪ FC)>)
p3 FC = C ∪NC)>
∗
, Qi+1 ⊆ Q
>∗
[C(H iC , NC , FC)→ •γ, j, j, (O,U,D)]  i
Qi, Q0 ⊆ (H
 O = (HC ∪NC ∪ FC)>
∗
− FC
aucun nœud ancre dans HC ∪NC ∪ FC
Dans la dernière étape de la prédiction, on complète les antécédents de C avec des nœuds
contraints par des nœuds déjà antécédents de C. On peut aussi sélectionner des nœuds dans
la clôture transitive de cette relation à condition que leur prédécesseurs aient été eux-mêmes
sélectionnés. L’ensemble des antécédents doit alors être saturé. Il faut ensuite prédire la forme
des prochaines sous-analyses. Pour cela, il faut grouper les fils des antécédents et respecter leur
catégories et les relations de précédence qui existent entre eux. On choisit donc une partition
de (HC , NC , FC)> qui respecte ord. Enfin, les nœuds à utiliser obligatoirement dans les sous-
analyses sont les nœuds contraints par les antécédents qui ne sont pas eux-mêmes antécédents.
Balayage C’est la règle qui vérifie les prédictions déjà effectuées par la présence d’un terminal
à la position courante de l’analyse. C’est un cas particulier de la règle précédente quand l’un
des antécédents de C est une ancre.
 H turé C
∪NC ∪ FC est sa

∗
[  (HC ∪⋃NC ∪ FC)
> = ∅
C(HC , NC , ∅)→ , j, j, (∅, U,D)] F ,Q
b C
= i Qi, Q0 ⊆ (HC ∪NC)
>
i+1 ⊆ Q
>∗
i
[C(HC, NC , FC)→ •, j, j + 1, (∅, U,D)]  (H C
∪NC ∪ FC)>
∗
− FC = ∅
 un unique nœud ancre a dans HC ∪NC ∪ FC
phon(a) = pj+1
Si on lit sur la chaîne d’entrée le terminal attendu à la position courante, on fait progresser
l’analyse. Cette règle ne s’applique que si tous les nœuds contraints par les antécédents sont
eux-mêmes antécédents, puisqu’il n’y a pas de sous-analyse dans laquelle utiliser ces nœuds.
3. Par abus de langage, on notera de la même façon une DAP et sa racine. Il faut également noter qu’une racine
peut être sélectionnée plusieurs fois (si plusieurs occurrences du même mot apparaissent dans la phrase à analyser
par exemple) et qu’un renommage de nœuds peut s’imposer pour distinguer chaque occurrence.
Joseph Le Roux
S
-> NP ~ NP -> NP -> S -> S
dort .
NP
V PUN
Jean Marie semble dort
~ NP <- S <- NP <- S <- NP
= NP = NP = V = V Jean
S
NP
que
~ S -> S ~ NP <- S
= CPL que sembleNP S
CPL V
aimer .
~ V -> NP = NP <- NP Marie aimer
= V = PUN NP NPNP V
FIGURE 1 – les DAP et l’arbre d’analyse pour Jean que Marie semble aimer dort.
Complétion Cette règle permet de revenir d’une sous-analyse et d’étendre l’analyse courante.
 N C
⊆ D1 ∪ O1 ∪ P
[A(H,N, F )→ α • C(H Cc)β, i, j, (O 1, U1, D1)]  D2 ⊆ (D1 ∪ O1)−N
U
[C(H 1
⊆ U2
C , NC , FC)→ γ•, j, k, (∅, U2, D2)] c O
[ 3
= O1 − U2
A(H,N, F )→ αC • β, i, k, (O 3, U3, D3)]  D3 = D1 − U2
U3 = U2 − O1
On doit ici s’assurer que la sous-analyse de C peut être branchée sur l’analyse courante :
– L’ensemble des nœuds disponibles dans la sous-analyse est un sous-ensemble des nœuds
disponibles dans l’analyse principale. En d’autres termes, la sous-analyse a pu utiliser des
nœuds qui étaient disponibles dans l’analyse principale mais n’a pas pu rendre de nouveaux
nœuds disponibles sans les avoir utilisés.
– Pour les mêmes raisons, l’ensemble des nœuds utilisés dans l’analyse principale doit être un
sous-ensemble des nœuds utilisés dans la sous-analyse.
– On retire des nœuds à utiliser obligatoirement ceux qui ont été utilisés dans la sous-analyse.
Item but L’analyse réussit si l’on obtient [⊤ → S•, 0, n, (∅, ∅, ∅)].
3.3 Exemple
Pour voir comment les relations de parenté lâche sont contrôlées, nous allons analyser la phrase
Jean que Marie semble aimer dort. On peut voir les DAP utilisées pour l’analyse sur la Figure 1.
Elles proviennent du logiciel LEOPAR 4. Nous appellerons les descriptions j, q,m, s, a, d et p et
nous désignerons les positions des nœuds par leur adresse de Gorn. Par exemple la racine de la
DAP associée à Marie est m et le nœud le plus éloigné de la racine de la DAP associée à semble
est s31. Les relations > et >∗ sont représentées par des traits, respectivement plein et pointillé.
Les relations ≺ et ≺+ sont représentées par des flèches, respectivement noire et colorée. Les
items qui permettent d’arriver une analyse et les règles pour les produire sont listés dans la
Table 1.
4. Ce logiciel est disponible à http://leopar.loria.fr/.
Un analyseur syntaxique descendant pour les GI
L’algorithme commence par prédire une racine S image de d et p (items 1, 2 et 3), puis ordonne
les fils de ces nœuds (item 4). L’analyse se poursuit par la prédiction d’un nœud NP dont un
des antécédents doit être d1, puisque d a été choisi plus tôt. L’analyse se poursuit jusqu’à la
prédiction du nœud S (item 12) dont la projection phonologique est que Marie semble aimer.
Ce nœud a pour antécédents q2 et s. Le nœud q22 contraint par q2 n’est pas antécédent, il doit
donc être obligatoirement utilisé dans cette sous-analyse et il est ajouté à l’ensemble O de cet
item. Ce nœud devient ensuite disponible pour l’analyse de que et semble mais n’est pas utilisé.
Il est donc toujours dans l’ensemble O de l’item 22, ainsi que dans celui de l’item 24.
Les items 25, 26 et 27 décrivent la prédiction du nœud S dont la projection phonologique est
aimer. On sélectionne q22 comme antécédent qui devient utilisé (ensemble U). Lors de la com-
plétion du S dont la projection phonologique est que Marie semble aimer (item 34), le contrat
qui forçait l’utilisation de q22 a été rempli et on retire donc ce nœud des nœuds obligatoires. Le
reste de l’analyse ne pose pas de problème particulier.
4 Discussion
4.1 Correction et complétude
L’algorithme présenté maintient un invariant tout au long de l’analyse. Chaque item de la forme
[A(H,N, F )→ α • β, i, j, (O,U,D)] assure que :
– A est modèle d’un ensemble saturé de nœuds qui ne sont plus disponibles pour être antécé-
dents d’un autre nœud de l’arbre syntaxique en construction. Il en est de même des nœuds
dans α. Les conditions 1, 7 et 3 (cas réflexif) que doit vérifier un modèle sont respectées.
– Les ensembles βk sont superposables. On a βk ⊆ (A−1)> (conditions 2 et 6)
– l’ordre des αβ est compatible avec les relations d’ordre des DAP (conditions 4 et 5).
– PP (α1) ◦ . . . ◦ PP (αl) = [mi+1 · · ·mj ]
– les nœuds de O sont des nœuds contraints en relation avec des nœuds de DAP qui sont
antécédents de A et qui n’ont pas encore été utilisés comme antécédents.
– les nœuds de D sont des nœuds contraints en relation avec des nœuds de DAP qui sont
antécédents de nœuds de l’arbre syntaxique situés entre sa racine et A et qui n’ont pas encore
été utilisés comme antécédents
– un nœud N de U est un nœud contraint en relation par >∗ avec un nœud de DAP qui est
antécédent d’un nœud situé à la fois entre la racine de l’arbre syntaxique et A, distinct de A
et entre la racine et I(N) (condition 3).
On peut vérifier cet invariant par induction sur les règles. En d’autres termes un tel item affirme
qu’il existe une fonction partielle J des nœuds d’un sous-ensemble des DAP d’une GI vers
un arbre syntaxique de racine étiquetée par O et qui a pour projection phonologique m1 . . .mj .
Cette fonction J est similaire à la fonction I des modèles. Elle vérifie les mêmes propriétés mais
les conditions 2–5 ne sont respectées que si les deux nœuds sont dans le domaine. L’algorithme
étend cette fonction J jusqu’à (1) l’obtention d’une fonction totale et (2) la couverture complète
de la chaîne d’entrée. J définit alors un arbre syntaxique qui est un arbre d’analyse.
D’autre part, s’il existe un arbre syntaxique pour une GI et une phrase d’entrée, un parcours
préfixe de cet arbre permet de retrouver les items créés par l’algorithme
Joseph Le Roux
1 [⊤ → •S(∅), 0, 0, (∅, ∅, ∅)] ax
2 [S(∅, ∅, ∅)→ , 0, 0, (∅, ∅, ∅)] p1(1)
3 [S(∅, {d, p}, ∅)→ , 0, 0, (∅, ∅, ∅)] p2(2)
4 [S(∅, {d, p}, ∅)→ •NP(d1)V (d2)PUN(p1), 0, 0, (∅, ∅, ∅)] p3(3)
5 [NP({d1}, ∅, ∅)→ , 0, 0, (∅, ∅, ∅)] p1(4)
6 [NP({d1}, {j, q}, ∅)→ , 0, 0, (∅, ∅, ∅)] p2(5)
7 [NP({d1}, {j, q}, ∅)→ •NP(j1, q1)S(q2), 0, 0, (∅, ∅, ∅)] p3(6)
8 [NP({j1, q1}, ∅, ∅)→ •, 0, 1, (∅, ∅, ∅)] b ◦ p2 ◦ p1(7)
9 [NP({d1}, {j, q}, ∅)→ NP • S(q2), 0, 1, (∅, ∅, ∅)] c(7, 8)
10 [S({q2}, ∅, ∅)→ , 1, 1, (∅, ∅, ∅)] p1(9)
11 [S({q2}, {s}, ∅)→ , 1, 1, (∅, ∅, ∅)] p2(10)
12 [S({q2}, {s}, ∅)→ •CPL(q21)NP(s1)V (s2)S(s3), 1, 1, ({q22}, ∅, ∅)] p3(11)
13 [CPL({q21}, ∅, ∅)→ , 1, 1, (∅, ∅, {q22})] p1(12)
14 [CPL({q21}, ∅, ∅)→ , 1, 1, (∅, ∅, {q22})] p2(13)
15 [CPL({q21}, ∅, ∅)→ •, 1, 2, (∅, ∅, {q22})] b(14)
16 [S({q2}, {s}, ∅)→ CPL • NP(s1)V (s2)S(s3), 1, 2, ({q22}, ∅, ∅)] c(12, 15)
17 [NP({s1}, ∅, ∅)→ , 2, 2, (∅, ∅, {q22})] p1(16)
18 [NP({s1}, {m}, ∅)→ , 2, 2, (∅, ∅, {q22})] p2(17)
19 [NP({s1}, {m}, ∅)→ •NP(m1), 2, 2, (∅, ∅, {q22})] p3(18)
20 [NP({m1}, ∅, ∅)→ •, 2, 3, (∅, ∅, {q22})] b ◦ p2 ◦ p1(19)
21 [NP({s1}, {m}, ∅)→ NP•, 2, 3, (∅, ∅, {q22})] c(19, 20)
22 [S({q2}, {s}, ∅)→ CPL NP • V (s2)S(s3), 1, 3, ({q22}, ∅, ∅)] c(16, 21)
23 [V ({s2}, ∅, ∅)→ •, 3, 4, (∅, ∅, {q22})] b ◦ p2 ◦ p1(22)
24 [S({q2}, {s}, ∅)→ CPL NP V • S(s3), 1, 4, ({q22}, ∅, ∅)] c(22, 23)
25 [S({s3}, ∅, ∅)→ , 4, 4, (∅, ∅, {q22})] p1(24)
26 [S({s3}, {a, q22}, ∅)→ , 4, 4, (∅, {q22}, ∅)] p2(25)
27 [S({s3}, {a, q22}, ∅)→ •NP(a1, s31)V (a2, q221)NP(q222, a3), 4, 4, (∅, {q22}, ∅)] p3(26)
28 [NP({a1, s31}, ∅, ∅)→ •, 4, 4, (∅, {q22}, ∅)] p3 ◦ p2 ◦ p1(27)
29 [S({s3}, {a, q22}, ∅)→ NP • V (a2, q221)NP(q222, a3), 4, 4, (∅, {q22}, ∅)] c(27, 28)
30 [V ({a2, q221}, ∅, ∅)→ •, 4, 5, (∅, {q22}, ∅)] b ◦ p2 ◦ p1(29)
31 [S({s3}, {a, q22}, ∅)→ NP V • NP(q222, a3), 4, 5, (∅, {q22}, ∅)] c(29, 30)
32 [NP({q222, a3}, ∅, ∅)→ •, 5, 5, (∅, {q22}, ∅)] p3 ◦ p2 ◦ p1(31)
33 [S({s3}, {a, q22}, ∅)→ NP V NP•, 4, 5, (∅, {q22}, ∅)] c(31, 32)
34 [S({q2}, {s}, ∅)→ CPL NP V S•, 1, 5, (∅, ∅, ∅)] c(24, 33)
35 [NP({d1}, {j, q}, ∅)→ NP S•, 0, 5, (∅, ∅, ∅)] c(9, 34)
36 [S(∅, {d, p}, ∅)→ NP • V (d2)PUN(p1), 0, 5, (∅, ∅, ∅)] c(4, 35)
37 [V ({d2}, ∅, ∅)→ •, 5, 6, (∅, ∅, ∅)] b ◦ p2 ◦ p1(36)
38 [S(∅, {d, p}, ∅)→ NP V • PUN(p1), 0, 6, (∅, ∅, ∅)] c(36, 37)
39 [PUN({p1}, ∅, ∅)→ •, 6, 7, (∅, ∅, ∅)] b ◦ p2 ◦ p1(38)
40 [S(∅, {d, p}, ∅)→ NP V PUN•, 0, 7, (∅, ∅, ∅)] c(38, 39)
41 [⊤ → S•, 0, 7, (∅, ∅, ∅)] c(1, 40)
TABLE 1 – Items pour l’analyse de Jean que Marie semble aimer dort.
Un analyseur syntaxique descendant pour les GI
4.2 Complexité
Le problème de l’analyse des GI est un problème NP-difficile dans le cas lexicalisé et même en
l’absence d’ambiguïté lexicale (Bonfante et al., 2003).
En regardant les règles de notre algorithme, on peut voir plusieurs sources d’indéterminisme :
– dans la règle p2, il faut choisir de nouveaux antécédents (l’ensemble NC) qui soient super-
posables avec les antécédents hérités des choix précédents (l’ensemble HC). Ces nouveaux
antécédents sont à choisir parmi les nœuds disponibles et les racines des DAP de la GI uti-
lisée. Il y a un nombre exponentiel de tels choix, d’autant plus grand que les GI réalistes
contiennent plus de 2000 DAP.
Cependant, en pratique, on va filtrer les choix possibles grâce aux catégories et aux polarités.
De plus, les GI utilisées dans l’implantation LEOPAR sont lexicalisées. On ne va donc consi-
dérer qu’un sous-ensemble des DAP de la grammaire, qui correspond aux DAP qui ont pour
ancre un mot de la phrase d’entrée. Enfin, des techniques de filtrages lexical (supertagging)
très efficaces ont été développées pour les GI, comme (Bonfante et al., 2006) qui permettent
de restreindre de façon drastique le nombre de DAP qui peuvent être utilisées.
– dans la règle p3 et la règle b, il faut choisir un sous-ensemble de nœuds contraints par des
antécédents déjà choisis. Ici encore il existe un nombre exponentiel de choix. Cependant,
dans les GI utilisées en pratique, les nœuds des DAP ont au plus un successeur par la relation
>∗ et il n’existe pas de chaîne de nœuds reliés par >∗. On peut donc borner le nombre de
nœuds dans FC par le nombre de nœuds dans HC ∪NC .
– dans la règle p3, on doit ordonner et partitionner les fils par > des antécédents. Dans le cas où
il n’existe aucune relation de précédence entre ces fils, il y a à nouveau un nombre exponentiel
de possibilité. Cependant, en pratique, le nombre de nœuds à ordonner/partitionner est petit.
On peut imaginer calculer l’ordre de façon paresseuse en l’étendant à chaque complétion,
comme le proposent (Nederhof et al., 2003) pour les pomset-CFG.
On remarque que la règle qui fait intervenir le plus d’indices de position est la complétion et
qu’il n’y a pas d’indéterminisme à cette étape. Ce n’est donc pas directement la taille de la
phrase qui rend le problème de l’analyse des GI difficile mais la taille de la GI et des DAP à
considérer. La longueur de la phrase ne joue qu’un rôle indirect, le nombre de DAP utilisables
augmentant avec le nombre de mots.
5 Conclusion
Nous avons présenté un algorithme d’analyse pour les GI. Bien que nous ayons utilisé une
version sans structure de traits, nous pensons qu’il n’y a aucune difficulté majeure à y ajouter
un mécanisme d’unification.
L’originalité de notre travail réside dans l’utilisation du cadre formel de l’analyse déductive pour
un formalisme qui se réclame de l’approche par théorie des modèles (Pullum & Scholz, 2001).
Ce cadre formel permet de distinguer les sources de l’indéterminisme qui rendent difficile le
problème de l’analyse dans les GI. Ce travail est donc un premier pas vers une étude plus
approfondie de sa complexité.
À l’avenir, il sera intéressant de rechercher, comme pour la méthode shift-reduce ou comme
pour les (k-)TT-MCTAG (Kallmeyer & Parmentier, 2008), des approximations de l’algorithme
ou du formalisme qui ne considèrent qu’un nombre borné de nœuds à chaque étape, de manière
Joseph Le Roux
à rendre l’analyse efficace (polynomiale).
Références
BONFANTE G., GUILLAUME B. & PERRIER G. (2003). Analyse syntaxique électrostatique.
Traitement Automatique des Langues.
BONFANTE G., LE ROUX J. & PERRIER G. (2006). Lexical disambiguation with polarities
and automata. In O. H. IBARRA & H.-C. YEN, Eds., The 11th International Conference on
Implementation and Application of Automata (CIAA 2006).
CHOMSKY N. (1995). The Minimalist Program. MIT Press.
DUCHIER D. & THATER S. (1999). Parsing with tree descriptions : a constraint based ap-
proach. In Natural Language Understanding and Logic Programming NLULP’99, Dec 1999,
Las Cruces, New Mexico.
EARLEY J. (1970). An efficient context-free parsing algorithm. Communications of the ACM,
13(2), 94–102.
GUILLAUME B. & PERRIER G. (2008). Interaction Grammars. Research Report RR-6621,
INRIA.
KAHANE S. (2004). Grammaires d’unification polarisées. In TALN2004, Fès, Maroc, p. 233–
242.
KALLMEYER L. & PARMENTIER Y. (2008). Convertir des grammaires d’arbres adjoints
à composantes multiples avec tuples d’arbres (TT-MCTAG) en grammaires à concaténation
d’intervalles (RCG). In 15e Conférence sur le Traitement Automatique des Langues Natu-
relles, Avignon France : ATALA.
LAMBEK J. (1958). The mathematics of sentence structure. American Mathematical Monthly,
65(3), 154–170.
LE ROUX J. (2007). La coordination dans les grammaires d’interaction. PhD thesis, Ecole
Doctorale IAEM Lorraine ; Institut National Polytechnique de Lorraine - INPL.
NEDERHOF M., SATTA G. & SHIEBER S. (2003). Partially ordered multiset context-free
grammars and ID/LP parsing. In Proceedings of the Eighth International Workshop on Parsing
Technologies, p. 171–182, Nancy, France.
PULLUM G. & SCHOLZ B. (2001). On the distinction between model-theoretic and
generative-enumerative syntactic frameworks. In Proccedings of the 4th conference on Lo-
gical Aspects of Computational Linguistics.
SHIEBER S., SCHABES Y. & PEREIRA F. P. (1995). Principles and implementation of deduc-
tive parsing. Journal of Logic Programming, 24(1–2), 3–36.
