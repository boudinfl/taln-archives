TALN 2009, Senlis, 24-26 juin 2009

Analyse syntaxique en dépendances de l’oral spontané

Alexis Nasrl Frédéric Béchetz
(1) LIF - CNRS - Université Aix Marseille
(2) LIA - Université d’AVignon

Résumé. Cet article décrit un modele d’analyse syntaxique de l’oral spontané axé sur
la reconnaissance de cadres valenciels verbaux. Le modele d’analyse se décompose en deux
étapes : une étape générique, basée sur des ressources génériques du francais et une étape de ré-
ordonnancement des solutions de l’analyseur réalisé par un modele spéciﬁque a une application.
Le modele est évalué sur le corpus MEDIA.

Abstract. We describe in this paper a syntactic parser for spontaneous speech geared
towards the identiﬁcation of verbal subcategorization frames. The parser proceeds in two stages.
The ﬁrst stage is based on generic syntactic ressources for French. The second stage is a reranker
which is specially trained for a given application. The parser is evaluated on the MEDIA corpus.

M0tS-CléS I Analyse syntaxique, reconnaissance automatique de la parole.

Keywords: Syntactic parsing, automatic speech recognition.

1 Introduction

De nombreux systemes automatiques contemporains de compréhension de la parole produisent
des représentations du sens des énoncés sous la forme de cadres sémantiques a la FrameNet (Ba-
ker et al., 1998). La construction de ces représentations suppose en général une étape d’analyse
syntaxique plus ou moins poussée. Cette derniére se situe habituellement en aval d’un sys-
téme automatique de reconnaissance de la parole (SRAP), qui produit, pour un signal acous-
tique donné, correspondant a un énoncé, la retranscription jugée la plus probable par le SRAP
ou bien les n retranscriptions les plus probables représentées sous la forme d’un graphe de
forrnes. L’ analyse syntaxique d’un tel graphe est confrontée a de nombreux problemes, en sus
des problemes traditionnels de l’analyse syntaxique. Ceux-ci sont de natures diverses, provenant
des spéciﬁcités de l’oral par rapport a l’écrit, mais aussi du caractere imparfait des retranscrip-
tions produites par le SRAP, surtout lorsque la parole a transcrire est spontanée. Du fait de
ces particularités, il est illusoire de recourir, pour une telle tache, a des analyseurs syntaxiques
probabilistes modernes, concus pour traiter la langue écrite. Il n’est pas possible non plus de
réentrainer ces analyseurs sur des corpus de l’oral, car nous ne disposons pas actuellement de
corpus syntaxiques pour l’oral (ou chaque enoncé est associé a un arbre d’analyse syntaxique).

Face a une telle situation, une solution consiste a développer des analyseurs ad-hoc, adaptés a
un registre de langue donné, a un champ sémantique particulier, voire méme a un SRAP donné.

1Ces travaux sont ﬁnancés par l’ANR, dans le cadre du projet EPAC, contrat numéro ANR-06-MDCA—006.

Alexis Nasr, Frédéric Béchet

Une telle approche, meme si elle peut donner des résultats satisfaisants (Seneff, 1992), péche
par son manque de généricité et rend l’adaptation de tels systemes particulierement coﬁteux.

Une solution alternative consiste a distinguer, parmi les connaissances mobilisées par un tel
systeme, ce qui releve de la syntaxe générale de ce qui est propre a un domaine applicatif. C’est
dans cette direction que s’inscrit le travail présenté ici. I1 propose un traitement en deux étapes.

Dans un premier temps, une analyse syntaxique partielle des sorties du SRAP est effectuée. Elle
repose sur des ressources génériques, en particulier une grammaire syntagmatique partielle, ce
qui n’est pas une nouveauté dans le domaine de l’analyse syntaxique automatique de l’oral (voir
(Antoine et al., )), mais aussi, et c’est une originalité de notre approche, sur deux ressources
générales que sont le lexique syntaxique dicovalence (van den Eynde & Mertens, 2003) et sur la
grammaire d’adjonction d’arbres du francais FXMG (Crabbé, 2005b). Cette étape produit, pour
un graphe donné de formes, plusieurs instanciations de cadres de valence. I1 s’agit d’assigner
aux verbes présents dans le graphe un cadre valenciel (verbe intransitif, verbe transitif direct
...) ainsi que ses actants (sujet, objet direct, objet indirect ...). Nous avons opté pour ce type
d’analyse syntaxique, plutot qu’une analyse syntagmatique plus traditionnelle, car elle fournit
des représentations plus adaptées au calcul de cadres sémantiques mentionnés ci-dessus.

La seconde étape du traitement prend en entrée les cadres de valence instanciés produits a
l’issue de l’étape précédente et les réordonne en fonction d’un modele spéciﬁque a une tache
particuliere. Cette étape repose sur un modele de boosting (Schapire & Singer, 2000). Ce dernier
est entrainé sur un corpus spéciﬁque a l’application visée.

L’ organisation de l’article est la suivante : dans la section 2, nous décrivons l’analyseur syn-
taxique, la section 3 décrit le modele de reclassement utilisé. La section 4 est consacrée a la
partie expérimentale de ce travail et la section 5 conclut l’article.

2 Analyse syntaxique

L’ analyse linguistique des sorties du SRAP se décompose, de maniere classique, en une série de
processus qui constituent une chaine de traitements : l’entrée d’un processus correspond a la
sortie du processus précédent. Les différents modules qui constituent notre chaine vériﬁent tous
un certain nombre de principes, en particulier :

1 - Les modules sont monotones, ils ajoutent de l’information linguistique a leurs entrées mais
ne modiﬁent pas les informations déja présentes.

2 - Les modules adInettent plusieurs hypotheses pondérées en entrée et produisent a leur tour
plusieurs hypotheses pondérées a l’aide d’une fonction de coﬁt propre au module. Le nombre
d’hypotheses produites en sortie peut étre controlé grace a la pondération (on ne produit que les
n hypotheses de meilleurs poids).

3 - L’ ambigu'1'té est représentée sous la forme de graphes (graphes de formes, de mots, de cate-
gories, de syntagmes . . . ) qui permettent de mettre en facteur des parties communes a plusieurs
hypotheses. Ces graphes sont représentés par des transducteurs ﬁnis pondérés et la majorité des
traitements correspondent a des opérations standard sur les transducteurs.

Les premiers modules de la chaine sont standards, nous ne ferons que les évoquer pour nous
attarder plus longuement sur le dernier, l’analyseur en dépendances partiel.

Analyse syntaxique de l’oral

Le graphe de formes issu du SRAP est traité, dans un premier temps, par un module lexical
qui permet de regrouper certaines formes. C’est a ce niveau que sont reconnues des unités
lexicales complexes telles que les locutions (au dessus de, 61 mesure que ...) ou encore les
mots composés (pomme de terre, couvre chef. . . ). Ce module repose sur le lexique des formes
ﬂéchies du francais (le Lejjﬁ‘) (Sagot et al., 2006). Conformément au second principe ce module
permet de conserver plusieurs découpages possibles, pour les cas de chevauchement d’unités
lexicales complexes. Le module produit un graphe d’unités lexicales.

Ce dernier constitue l’entrée d’un module d’ étiquetage morpho-syntaxique qui produit un graphe
de catégories morpho-syntaxiques, chaque catégorie étant associée a une unité lexicale. L’ eti-
queteur repose sur un modele de Markov caché classique dont l’estimation des parametres a été
réalisée sur le corpus paris 7 (Abeillé et al., 2003).

Le graphe de catégories est alors traité par un module d’analyse morphologique qui associe
a tout couple composé d’une unité lexicale et d’une catégorie une ou plusieurs analyses mor-
phologiques. Une analyse morphologique est composée d’un lemme et d’une série de traits
morphologiques. Ce module repose, tout comme le premier, sur le Leﬁf.

La quatrieme étape consiste en une analyse syntaxique partielle du graphe de categories. 11
s’agit de regrouper des séquences de catégorie au sein de syntagmes non récursifs, souvent
appelés chunks. L’ idée sous jacente est de n’effectuer que des regroupements non ambigus (tel
qu’une séquence déterminant, adjectij‘, nom ou encore auxiliaire, participe passe’ . . . ). I1 n’y a
en particulier pas de rattachements prépositionnels effectués a ce niveau. Les traitements sont
réalisés a l’aide d’une cascade de transducteurs, a l’image de (Abney, 1996). Les grammaires
locales correspondant a chaque syntagme sont produites manuellement. Tout syntagme possede
une téte qui est spéciﬁée dans la grammaire correspondante.

Le résultat de cette suite de traitements est un graphe de syntagmes. I1 constitue l’entrée du
module d’analyse de dépendances syntaxiques partiel qui est l’objet de la section suivante.

Il est important de noter que, de maniere générale, le nombre d’hypotheses potentielles aug-
mente au fur et a mesure que l’on évolue dans la chaine de traitement. A une suite de formes
peut correspondre plusieurs découpages en mots. Une séquence de mots peut correspondre a
plusieurs séquences de catégories, chacune pouvant correspondre a plusieurs découpages en
unités syntaxiques.

2.1 L’analyseur de dépendances syntaxiques partiel

L’ objectif de ce module est de retrouver des dépendances actancielles (sujet, objet direct, objet
indirect, régime d’une préposition, certains complément de noms ...) dans un graphe de sortie
d’un SRAP, préalablement traité par les modules décrits ci-dessus. Nous nous intéresserons ici
aux seules relations actancielles ayant pour gouvemeur un verbe. La principale source d’infor-
mation utilisée pour détecter l’occurrence de telles dépendances est une description des cadres
valenciels (appelés aussi schémas de régime ou cadres de sous-catégorisation) des verbes.

Le module doit offrir simultanément une bonne couverture, de la souplesse et de l’efﬁcacité.

La couverture revét deux aspects, la couverture lexicale (le nombre de verbes pour lesquels
on dispose d’une description du cadre valenciel), et la couverture syntaxique (les différentes
réalisations possibles d’un cadre valenciel).

Alexis Nasr, Frederic Bechet

La souplesse est la capacite a retrouver des occurrences de dependances actancielles dans des
entrees bruitees. Le bruit etant constitue des particularites de la syntaxe de l’oral (disﬂuences,
hesitations) et des erreurs commises par le systeme de reconnaissance de parole.

La couverture est assuree par deux ressources existantes, le lexique syntaxique Dicovalence
(van den Eynde & Mertens, 2003) et la grammaire d’adjonction d’arbres FXMG (Crabbe, 2005a).
La souplesse et l’efﬁcacite sont assurees par une representation sous speciﬁee des realisations
des cadres valenciels sous la forme de transducteurs ﬁnis.

Ces aspects sont decrits successivement dans les deux sections suivantes.
Couverture lexicale et syntaxique

Dicovalence est un lexique syntaxique de verbes du francais. I1 recence les cadres valenciels
de plus de 3700 verbes. Un cadre valenciel decrit une conﬁguration de complements valenciels
d’un verbe (le nombre, la nature et la fonction de ses complement). La description des cadres
valenciels repose sur les principes de l’approche pronominale (van den Eynde & Blanche-
Benveniste, 1978) : chaque position actantielle, appelee paradigme, est decrite par le paradigme
des pronoms qui peuvent l’occuper. 20 paradigmes sont distingues, parmi lesquels on trouve
P0, P1 et P2 qui correspondent grosso modo aux sujet, objet direct et objet indirect de la
grammaire traditionnelle. Comme nous l’avons precise ci-dessus, 3700 verbes sont repertories,
qui constituent plus de 8000 entrees, un verbe pouvant etre associe a plusieurs cadres valen-
ciels. 311 cadres valenciels distincts sont repertories. Un cadre valenciel est decrit de maniere
concise par un identiﬁant qui en resume les caracteristiques principales. L’identiﬁant P0 P1
par exemple decrit le cadre valenciel transitif direct. Il est constitue des deux paradigmes : P O
pour le sujet et P 1 pour l’objet direct. Une entree lexicale associe a un lemme verbal un cadre
valenciel ainsi que les pronoms des differents paradigmes qui composent le cadre valenciel.

Dicovalence offre une bonne couverture lexicale (il couvre 89, 3% des verbes du corpus Pa-
ris 7) mais sa couverture syntaxique est par construction liIr1itee dans la mesure ou seules les
realisations pronominales des actants sont repertoriees. Pour obtenir une meilleure couverture
syntaxique, il est necessaire d’associer a tout cadre valenciel ses realisations non pronominales.
Cette etape est realisee a l’aide de la grammaire FXMG.

La grammaire FXMG est une grammaire d’adj onction d’arbres produite automatiquement a par-
tir d’une meta-grammaire a l’aide du logiciel XMG (Crabbe, 2005a). Nous ne ferons pas ici de
presentation des grammaires d’adjonction d’arbres, rappelons simplement qu’une telle gram-
maire associe a toute entree lexicale un ensemble d’arbres e’le’mentaires qui decrivent, entre
autre, une realisation possible d’un cadre valenciel de l’entree lexicale. Les arbres elemen-
taires sont regroupes en familles, chaque famille etant composee des differentes realisations
syntaxiques d’un cadre valenciel donne. Ainsi, est associe a un verbe transitif une famille com-
posee de l’arbre representant la realisation nominale du sujet et de l’objet direct (Jean mange la
pomme), d’une cliticisation de l’objet direct (Jean la mange), de la diathese passive (la pomme
est mange’e par Jean) et ainsi de suite. La grammaire ainsi produite est de taille importante,
elle est composee de 7600 arbres elementaires, regroupes en 92 families. Les familles sont de
tailles inegales. A titre d’exemple la famille des verbes transitifs est composee de 159 arbres
elementaires. Comme nous l’avons precise ci-dessus, une telle grammaire est produite auto-
matiquement a partir d’une description plus abstraite, appelee meta-grammaire. Tout arbre ele-
mentaire de la grammaire est caracterise de maniere bi-univoque par un ensemble de traits qui
en decrivent ses caracteristiques syntaxiques (realisation morpho-syntaxique des actants, ordre
lineaire, diathese ...). Cette representation permet un ﬁltrage simple et motive de l’ensemble

Analyse syntaxique de l’oral

des arbres élémentaires : on peut décider de ne garder que les arbres élémentaires possédant
certains traits particuliers. Chaque famille est associée a un identiﬁant qui exprime de maniere
concise le cadre valenciel associé a la faIr1ille : la famille associée aux verbes transitifs est
nOVnl la famille des verbes di-transitifs dont l’objet indirect est introduit par la préposition 61
est nOVnlan2 et ainsi de suite.

La couverture de FXMG a été évaluée sur le corpus TSNLP (Lehmann, 1996) par (Crabbé,
2005b), elle est de 75% ce qui peut étre considéré comme un résultat satisfaisant étant donné les
caractéristiques de ce corpus (les fréquences d’occurrence des constructions ne correspondent
pas a leur fréquence d’usage dans la langue).

FXMG déﬁnit donc un ensemble d’arbres élémentaires, regroupés en familles, mais n’établit pas
de lien entre les entrées lexicales et les arbres élémentaires. Il est facile de voir a cette étape
de notre exposé la complémentarité de dicovalence et de FXMG. Le premier possede une bonne
couverture lexicale tandis que le second possede une bonne couverture syntaxique.

Pour effectuer un lien entre dicovalence et FXMG, il convient de traduire les cadres valenciels
de dicovalence en noms de familles de FXMG. Cette traduction est réalisée a l’aide de regles
qui associent un couple (paradigme, pronom) a un fragment d’identiﬁant de famille. A titre
d’exemple, la regle (P O , je) —> n O indique que la réalisation du paradigme sujet (P O) sous
la forme du pronomje se traduit par n0 dans un identiﬁant de famille de FXMG. Les fragments
d’identiﬁants de familles sont ensuite concaténésl pour constituer des identiﬁants de familles.

Représentation des schémas de valence sous la forme d’automates

Nous avons décrit dans la section précédente la maniere dont les deux ressources dicovalence
et FXMG avaient été reliées entre elles a l’aide de regles de correspondance. Nous disposons
donc, pour chacun des 3700 verbes de dicovalence, d’une ou de plusieurs familles d’arbres
élémentaires qui décrivent les différentes réalisations possibles des cadres de valence de ces
verbes. Aﬁn de retrouver une occurrence d’un cadre de valence dans les sorties de l’analyseur
syntaxique partiel, chaque arbre élémentaire est représente sous la forme d’un automate ﬁni.
On effectue ensuite l’union des automates correspondant aux arbres d’une famille donnée pour
constituer l’automate de la famille.

Le processus de construction d’un automate a partir d’un arbre élémentaire est simple. I1 consiste
a parcourir l’arbre de maniere descendante (en profondeur d’abord, de gauche a droite) et de
construire pour tout noeud de substitution de l’arbre une transition étiquetée par la catégorie
du noeud de substitution. Nous avons représente dans la partie droite de la ﬁgure 1 l’automate
correspondant a l’arbre de la partie gauche.

On remarquera que tout état de l’automate de la ﬁgure 1 possede une transition sur lui-méme
pour chaque élément de l’alphabet 2. Ce dernier est composé des différentes étiquettes de
groupes syntaxiques et de catégories morpho-syntaxiques. Ces transitions permettent aux diffé-
rents actants du verbe de se trouver a une distance arbitraire de ce dernier.

On po11rra remarquer que l’automate correspondant a un arbre élémentaire ne représente qu’une
partie de l’information syntaxique de ce dernier, plus précisément, son nombre de noeuds de
substitution, leur nature et leur ordre linéaire relatif. Ce relachement de contraintes syntaxiques
peut aboutir a des rattachements erronés. Pour attenuer cet effet, des pondérations (oz et 3) sont

1Cette operation est en fait un peu plus complexe car les indices des paradigmes dans dicovalence (le 1 de P 1)
et les indices dans les familles d’arbres (le 0 de n0 dans nOVn1) n’ont pas la meme sémantique. Le premier réfere
grosso modo a une fonction syntaxique tandis que le second désigne une position linéaire.

Alexis Nasr, Frédéric Béchet

/\ 2 Ella 2/on 2
 W 0 0 0 0

/\ /\ /\ f-\

V GN,L V7 GN/[5 K‘jnOvN1 \/ GN/[3 ©
nOvn1

FIG. 1 — Transformation d’un arbre élémentaire en automate

ajoutées aux transitions. oz matérialise une pénalité qui s’accroit au fur et a mesure que croit la
distance entre le verbe et un de ses actants. B correspond a une récompense pour chaque actant
trouvé. Ce jeux de pondérations permet d’implémenter une heuristique simple : on favorise la
proximité entre le verbe et ses actants, ainsi que le nombre d’actants.

Le processus d’instanciation des cadres de valences dans un graphe de syntagmes issu de l’ana-
lyseur syntaxique partiel est réalisé a l’aide de l’opération de composition d’automates. De
maniere plus précise, nous disposons de l’automate des sytagmes, noté T3 et d’un automate par
famille d’arbres élémentaires, soit n automates notés TF1, . . . ,Tpn. Les n automates de familles
sont composés successivement avec l’automate T3 et les résultats de ces compositions sont re-
goupés entre eux grace a l’opération d’union2. Le résultat est donc LJ;‘:1T3 o T1.-,3. Ce modele
s’oppose a une cascade de transducteurs (T3 o TF1 o . . . o Tpn). Cette difference est importante
dans le cas de phrases complexes (comportant plusieurs verbes). Elle correspond a l’idée que
l’on n’essaye pas de trouver une analyse complete cohérente de la phrase mais a retrouver les
actants potentiels de chacun de ses verbes, indépendamment. Certaines analyses peuvent étre,
par conséquent, incompatibles (un meme groupe syntaxique peut étre actant de deux verbes
distincts de la phrase). Ce choix est motivé par des considérations d’efﬁcacité. En effet, étant
donné le relachement syntaxique Inis en oeuvre, la recherche d’analyses completes aboutit a une
multiplication déraisonnable de solutions, et par conséquent une augmentation déraisonnable
de la taille des automates produits.

2.2 Exemple

Nous avons représenté ci-dessous le résultat du traitement du graphe de reconnaissance cor-
respondant a l’énoncé oui donc j’ aimerais réserver maintenant du onze au euh quatorze mai
c’est-£1-dire trois nuits la méme prestation £1 carcassonne. Le graphe est traité successivement
par le module lexical, l’étiqueteur morpho-syntaxique, l’analyseur morphologique, l’analyseur
syntaxique partiel puis, ﬁnalement par l’analyseur en dépendances partiel. Ce sont les dix solu-
tions de meilleur poids que l’on a reportées dans le tableau ci-dessous4.

2Pour des raisons de lisibilité, nous avons omis un certain nombre de details techniques concemant la structure
des automates Tp, et Ts. En particulier, avant l’opération de composition, les transitions de Ts étiquetées par
un groupe Verbal dont la tete est associée a n cadres Valenciels est remplacée par 11 transitions étiquetées par
l’identiﬁant du cadre Valenciel. D’autres details ne presentant pas d’interet fondamental sont passes sous silence.

3Dans la pratique, on effectue des 12 meilleurs chemins de l’automate produit lors de 1’ operation de composition.
La formule est donc : U,."=1nbest(TS o T1.-1., n) ou nbest(A, 12) est l’opérateur produisant l’automate compose des
11 chemins de meilleur poids de l’automate A.

4La presence incongrue du mot stade dans quatorze mai stade provient d’une erreur de reconnaissance : sub-
stitution de c ’est ti dire par stade.

Analyse syntaxique de l’oral

n Cadre Sujet Verbe Objet direct Complément locatif
1 n OV j’ aimerais réserver 0 0

2 r1 OVn 1 j ’ aimerais réserver quatorze mai stade 0

3 n OVn 1 j ’ aimerais réserver trois nuits 0

4 n OVn 1 1 o cn2 j ’ aimerais réserver quatorze mai stade £1 carcassonne
5 r1 OVn 1 1 o cn2 j ’ aimerais réserver la méme prestations £1 carcassonne
6 r1 OVn 1 1 o cn2 j ’ aimerais réserver trois nuits £1 carcassonne
7 n OVn 1 j’ aimerais réserver la méme prestations 0

8 r1 OV1 o cn 1 j ’ aimerais réserver 0 £1 carcassonne
9 n OVn 1 j ’ aimerais réserver stade 0

10 n OVn 1 1 o cn2 j ’ aimerais réserver la méme £1 carcassonne

Les dix solutions représentées dans le tableau correspondent a dix instanciations de cadres va-
lenciels associés au Verbe réserver. Quatre cadres valenciels ont été sélectionnés, 11 0V (intransi-
tif), n OVn1 (transitif direct), n OVn 1 1ocn2 (objet direct et complément locatif prépositionnel)
et nOV1ocn1 (complément locatif). Le classement de ces solutions est réalisé d’apres la com-
binaison des poids donnés par les différents modules successifs. I1 s’agit d’une fonction de coﬁt
complexe, combinaison linéaire des fonctions de coﬁt de chaque module.

Nous aurions aimé voir en premieres positions de la liste les solutions 5 et 6 qui peuvent étre
considérées comme des analyses correctes de l’énoncé. Leur positionnement en 5eme et 6eme
rang illustre l’imperfection de la fonction de coﬁt. Mais il montre aussi qu’il est illusoire d’espé-
rer déﬁnir une fonction de coﬁt générique optimale. En particulier, notre fonction de coﬁt n’im-
plémente aucune contrainte de sélection (ou préférence lexicale) qui favoriserait, par exemple,
le groupe nominal trois nuits par rapport a quatorze mai stade comme objet direct de réserver.
De telles préférences sont étroitement liées a un domaine sémantique et a un cadre applicatif
particuliers, c’est pourquoi nous considérons qu’elles sont du ressort d’un module spéciﬁque a
une application. Ce demier est décrit dans la section suivante, il se présente sous la forme d’un
réordonnanceur (reranker) qui prend en entrée n solutions de l’analyseur et les réordonne en
fonction de connaissances propres a l’app1ication.

3 Réordonnancement des solutions de l’analyseur

Comme nous l’avons décrit dans la section précédente, les traitements génériques ont permis de
construire, pour les sorties d’un SRAP correspondant a un énoncé donné, plusieurs instanciations
de cadres de valence associés aux verbes de l’énoncé considérés pertinents pour la tache visée
(verbes cibles dans la suite de l’article). Les cadres de valences ainsi produits constituent l’en-
trée d’un processus de réordonnancement qui integre des contraintes propres a une application
particuliere.

Ce processus est basé sur un classiﬁeur qui est entrainé pour sélectionner les analyses valides
parmi l’ensemble des analyses produites. Nous utilisons un classiﬁeur a large marge spécialisé
dans le traitement de données textuelles, ICSIBOOST5, basé sur un algorithme de boosting (Scha-
pire & Singer, 2000) de classiﬁeurs simples (des arbres de decision a 1 niveau de profondeur sur
la présence ou l’absence de n-graInmes de mots). L’entrainement de ce classiﬁeur est effectué
de la maniere suivante :

1 - Tout d’abord un corpus d’apprentissage composé de segments de parole transcrits manuel-

5http ://code.google.comlplicsiboostl

Alexis Nasr, Frédéric Béchet

lement est traité par l’analyseur.

2 - Pour chaque segment, et pour chaque Verbe cible, la liste de n meilleurs cadres de valences
produits est présentée a un juge humain qui valide la ou les analyses correctes, lorsqu’elles
existent. A l’issue de cette étape de validation manuelle, chaque cadre valenciel est étiqueté
comme correct ou erroné.

3 - Tous les cadres valenciels produits sur le corpus d’apprentissage sont alors regroupés et cha-
cun d’euX est représenté par la séquence de mots du segment enrichis de la fonction syntaxique
du constituant auquel il appartient ou NULL si le mot n’ appartient a aucun constituant. Le classi-
ﬁeur ICSIBOOST est alors entrainé pour séparer les exemples jugés corrects des exemples jugés
incorrects.

Lors du traitement d’un segment de parole, le classiﬁeur réévalue chaque cadre de valence
instancié produit par l’analyseur robuste et produit un nouveau classement de la liste de n-
meilleures hypotheses. A l’issue de cette phase de réordonnancement, l’hypothese ou les hypo-
theses ayant les meilleurs scores au sens du classiﬁeur sont choisies comme solution.

Dans l’exemple de la section précédente, le juge aura marqué les deux hypotheses de rang 5 et
6 come correctes. I1 faut noter que cette étape d’adaptation manuelle a une tache est bien plus
légere que l’annotation manuelle de corpus ou l’adaptation de grammaire. Elle est cependant
limitée par la nature de la tache de réordonnancement : elle ne peut proposer une solution qui
n’a pas été créée par l’analyseur.

4 Cadre experimental et évaluation

Le cadre applicatif choisi est issu du corpus de dialogue MEDIA (Bonneau-Maynard et al., 2005)
développé lors du projet Technolangue homonyme. Ce corpus a été enregistré selon un proto-
cole de type Magicien d ’0z simulant un serveur vocal téléphonique permettant la réservations
d’h6tels. Huit catégories de scénario ont été déﬁnies correspondant a des degrés de complexités
différents. Le corpus compte 1250 dialogues enregistrés aupres de 250 interlocuteurs et repré-
sente environ 70 heures de parole.

L’ analyseur de la section 2 a été appliqué sur deux versions des transcriptions du corpus ME-
DIA : les transcriptions manuelles de référence et les transcriptions automatiques obtenues a
partir des ﬁchiers audio du corpus grace au systeme de reconnaissance automatique de la parole
SPEERAL (Nocera et al., 2002). Dans cette premiere étude nous avons volontairement restreint
le champs experimental en ne considérant qu’un seul Verbe cible, le Verbe : "réserver", évidem-
ment central dans une tache de réservation hoteliere.

Le corpus utilisé dans cette étude a été découpé en trois parties : un corpus d’apprentissage
constitué des lots 1,2,3 et 4 du corpus MEDIA; un corpus de développement constitué du "test
61 blanc" de la campagne MEDIA et un corpus de test correspondant au corpus "test Hors-
Contexte" de la campagne MEDIA. Les caractéristiques des trois parties sont décrites ci-dessous :

Corpus Apprentissage Développement Test
Nb de dialogues 727 79 208
Nb de tours de parole (utilisateur) 12988 1265 3524
Nb d’occurrences du Verbe réserver 659 73 187
Taux d’erreur/mot 14.5 25.3 27.4

Analyse syntaxique de l’oral

Les trois corpus ont été traités par l’analyseur et a chaque tour de parole a été associée la liste
d’hypotheses de dépendance (éventuellement vide) pour le verbe cible. A l’issue de cette ana-
lyse, les listes d’hypotheses ont été manuellement vériﬁées pour marquer les cadres de valences
corrects. Le classiﬁeur chargé du réordonnancement des hypotheses a été entrainé sur ce cor-
pus d’apprentissage étiqueté. Les parametres de l’algorithme (nombre d’itérations, taille des
n-grammes pour les classiﬁeurs simples, ...) ont été ajustés sur le corpus de développement.
Rappelons que seul le réordonnanceur a été entrainé sur le corpus d’apprentissage. L’ analyseur
syntaxique, lui, n’a subi aucune adaptation. Enﬁn l’évaluation a été faite sur le corpus detest.

Les performances sont exprimées par les mesures de rappel, précision et F-mesure en utilisant
deux mesures d’évaluation. Dans la premiere, une hypothese est jugée correcte si le cadre de
valence sélectionné pour le verbe est correct ainsi que tous les actants (leur fonction syntaxique
et la séquence de formes qui les constituent) La seconde mesure (représentée entre parentheses
dans le tableau) est moins sévere, elle n’évalue que la détection des actants d’un verbe (leur
fonction syntaxique et la séquence de formes qui les constituent), en faisant abstraction du
cadre de valence.

T rois systemes ont été évalués :

— le systeme Oracle consiste a choisir l’hypothese correcte, si elle existe, dans la liste des n-
meilleures hypotheses produites par l’analyseur. I1 correspond a la borne maximale que l’on
peut atteindre a l’issue du réordonnancement.

— le systeme Baseline se contente de choisir la premiere hypothese produite par l’analyseur.

— le systeme Réordonnancement réordonne les hypotheses de l’analyseur avec le classiﬁeur
présenté dans la section précédente et entrainé sur le corpus d’apprentissage MEDIA.

Les résultats sont donnés ci-dessous :

Corpus trans. manuelle trans. auto
systéme précision rappel F-mesure précision rappel F-mesure
Oracle 90.0 90.0 90.0 63.2 63.2 63.2

Baseline 42.8 (88.8) 38.3 (76.6) 40.4 (82.4) 34.7 (78.2) 29.2 (63.5) 31.6 (70.1)

Reclas. 59.9 (91.1) 70.8 (90.2) 64.9 (90.6) 45.9 (80.4) 53.1 (76.0) 49.2 (78.2)

Les résultats présentés ci-dessus permettent de tirer un certain nombre de conclusions. La cou-
verture de l’analyseur sur des entrées transcrites manuellement sont bonnes (90% de F-mesure).
L’ analyseur se comporte donc bien sur des retranscriptions manuelles de l’oral. Cette couver-
ture chute a 63% pour des transcriptions automatiques, illustrant la sensibilité de l’analyseur
aux erreurs du SRAP. La médiocrité des résultats du systeme baseline peut étre interprétée de
deux maniere : la fonction de coﬁt de l’analyseur est globalement mauvaise (certains choix sont
syntaxiquement aberrants) ou bien elle n’est pas adaptée au corpus traité (certains choix sont
syntaxiquement raisonnables, mais sémantiquement incorrects). Une inspection rapide des ré-
sultats montre que la réalité se situe entre les deux : la fonction de coﬁt de l’analyseur peut
étre améliorée mais certains cas relevent de la sémantique. Enﬁn, la comparaison de la baseline
et du systeme de réordonnancement montre le role important du réordonnanceur (ameliora-
tion de 55% de la F-mesure sur les transcriptions automatiques), mais qu’il reste une marge
de progression importante (28.4%). Ces tendances sont aussi valables pour la seconde mesure
d’évaluation, avec des performances globales plus satisfaisantes (78.2%) pour une tache qui
reste intéressante dans le cadre de la compréhension de parole.

Alexis Nasr, Frederic Bechet

5 Conclusions

Nous avons propose dans cet article un modele de traitement syntaxique de l’oral spontane qui
se decompose en deux etapes. Une analyse syntaxique axee sur la detection de cadre valenciels,
suivie d’une etape de reordonnancement des resultats de l’analyse. La premiere est elle meme
composee d’une analyse syntagmatique partielle, suivie d’une etape de detection de cadres va-
lenciels. Ces deux demieres ont ete adaptees au bruit inherent aux graphes produits par des
SRAP. Mais cette adaptation doit etre amelioree. En particulier la detection de cadres valen-
ciels repose sur un relachement extreme des contraintes syntaxiques, qui pourrait etre modere.
D’autre part, l’analyse syntagmatique manque de robustesse face aux phenomenes propres a
l’oral. Deux voies sont envisagees : la modiﬁcation de la grammaire syntagmatique et le pre-
traitement des graphes produits par le SRAP aﬁn d’en eliminer certains phenomenes (hesitations,
certaines repetitions).

Références

ABEILLE A., CLEMENT L. & TOUSSENEL F. (2003). Building a treebank for french. In A.
ABEILLE, Ed., Treebanks. Dordrecht : Kluwer.

ABNEY S. (1996). Partial parsing via ﬁnite-state cascades. In Workshop on Robust Parsing,
8th European Summer School in Logic, Language and Information, Prague, Czech Republic.
ANTOINE J .-Y., GOULIAN J . & VILLANEAU J . Quand le TAL robuste s’attaque au langage
parle : analyse incrementale pour la comprehension de la parole spontanee. In TALN.

BAKER C. F., FILLMORE C. J . & LOWE J . B. (1998). The Berkeley FrameNet project. In
COLING/ACL-98, p. 86-90.

BONNEAU-MAYNARD H., ROSSET S., AYACHE C., KUHN A. & MOSTEFA D. (2005). Se-
mantic annotation of the french media dialog corpus. In Eurospeech, Lisboa, Portugal.
CRABBE B. (2005a). Grammatical development with xmg. In Logical Aspects of Computa-
tional Linguistics.

CRABBE B. (2005b). Representation informatique de grammairesfortement lexicalisées, ap-
plication a la grammaire d’arbres adjoints. PhD thesis, Universite Nancy 2.

LEHMANN S. et al. (1996). TSNLP : Test suites for natural language processing. In Procee-
dings of the 16th conference on Computational linguistics, p. 711-716.

NOCERA P., LINARES G. & MASSONIE D. (2002). Principes et performances du decodeur
parole continue Speeral. In Proc. Joume’es d’Etude sur la Parole (JEP).

SAGOT B., CLEMENT L., ERICE VILLEMONTE DE LA CLERGERIE & BOULLIER P. (2006).
The lefff 2 syntactic lexicon for french : architecture, acquisition, use. In LREC.

SCHAPIRE R. E. & SINGER Y. (2000). BoosTexter : A boosting-based system for text cate-
gorization. Machine Learning, 39, 135-168.

SENEFF S. (1992). TINA : A natural language system for spoken language applications.
Computational Linguistics, 18(1), 61-86.

VAN DEN EYNDE K. & BLANCHE-BENVENISTE C. (1978). Syntaxe et mecanismes descrip-
tifs : presentation de l’approche pronominale. Cahiers de lexicologie, 32, 63-104.

VAN DEN EYNDE K. & MERTENS P. (2003). La valence : l’approche pronominale et son
application au lexique verbal. Journal of French Language Studies, 13, 63-104.

