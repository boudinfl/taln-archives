<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Annotation fonctionnelle de corpus arbor&#233;s avec des Champs Al&#233;atoires Conditionnels</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009, Senlis, 24&#8211;26 juin 2009
</p>
<p>Annotation fonctionnelle de corpus arbor&#233;s avec des Champs
Al&#233;atoires Conditionnels &#8727;
</p>
<p>Erwan Moreau1, Isabelle Tellier2, Antonio Balvet3, Gr&#233;goire Laurence4,
Antoine Rozenknop1, Thierry Poibeau1
</p>
<p>(1) LIPN, universit&#233; de Paris 13, (2) LIFO, universit&#233; d&#8217;Orl&#233;ans, (3) UMR STL
8163, universit&#233; de Lille (4) LIFL, Inria Lille-nord Europe
</p>
<p>erwan.moreau@lipn.univ-paris13.fr, isabelle.tellier@univ-orleans.fr
</p>
<p>R&#233;sum&#233;. L&#8217;objectif de cet article est d&#8217;&#233;valuer dans quelle mesure les &#8220;fonctions syn-
taxiques&#8221; qui figurent dans une partie du corpus arbor&#233; de Paris 7 sont apprenables &#224; par-
tir d&#8217;exemples. La technique d&#8217;apprentissage automatique employ&#233;e pour cela fait appel aux
&#8220;Champs Al&#233;atoires Conditionnels&#8221; (Conditional Random Fields ou CRF), dans une variante
adapt&#233;e &#224; l&#8217;annotation d&#8217;arbres. Les exp&#233;riences men&#233;es sont d&#233;crites en d&#233;tail et analys&#233;es.
Moyennant un bon param&#233;trage, elles atteignent une F1-mesure de plus de 80%.
</p>
<p>Abstract. The purpose of this paper is to evaluate whether the &quot;syntactic functions&quot; present
in a part of the Paris 7 Treebank are learnable from examples. The learning technic used is the
one of &quot;Conditional Random Fields&quot; (CRF), in an original variant adapted to tree labelling.
The conducted experiments are extensively described and analyzed. With good parameters, a
F1-mesure value of over 80% is reached.
</p>
<p>Mots-cl&#233;s : fonctions syntaxiques, Conditional Random Fields, corpus arbor&#233;s.
Keywords: syntactic functions, Conditional Random Fields, Treebanks.
</p>
<p>1 Introduction
</p>
<p>Nous nous int&#233;ressons dans cet article &#224; l&#8217;application de techniques d&#8217;apprentissage automa-
tique statistique pour identifier les fonctions syntaxiques (comme &#8220;sujet&#8221;, &#8220;objet&#8221;, &#8220;modifieur&#8221;
etc.) pr&#233;sentes &#224; l&#8217;int&#233;rieur de phrases fran&#231;aises. Identifier ces fonctions est pr&#233;cieux pour des
applications qui requi&#232;rent une analyse linguistique de haut niveau comme les syst&#232;mes &#8220;ques-
tions/r&#233;ponses&#8221; ou ceux de traduction automatique (Blaheta, 2004). C&#8217;est une t&#226;che tr&#232;s li&#233;e &#224;
l&#8217;analyse syntaxique et nous ne l&#8217;abordons ici qu&#8217;en partant d&#8217;un corpus de phrases d&#233;j&#224; ana-
lys&#233;es. Par exemple, nous nous attendons &#224; ce que la structure syntaxique d&#8217;une phrase comme
&#8220;l&#8217;oiseau chante chaque matin&#8221; refl&#232;te le fait que le GN qui suit le verbe est un modifieur de la
phrase et non un compl&#233;ment d&#8217;objet.
Ce probl&#232;me est &#233;tudi&#233; depuis quelques ann&#233;es, principalement pour l&#8217;anglais (Blaheta &amp; Char-
niak, 2000; Blaheta, 2004; Merlo &amp; Musillo, 2005; Musillo &amp; Merlo, 2005). Une t&#226;che com-
parable, mais requ&#233;rant l&#8217;identification plus fine des r&#244;les th&#233;matiques (comme &#8220;agent&#8221;, &#8220;pa-
tient&#8221;...) a aussi fait l&#8217;objet d&#8217;une comp&#233;tition lors de la conf&#233;rence CoNLL 2004 et 2005 (Carre-
</p>
<p>&#8727;. Ce travail a b&#233;n&#233;fici&#233; du soutien de l&#8217;Agence Nationale de la Recherche ANR-07-MDCO-03</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>E. Moreau, I. Tellier, A. Balvet, G. Laurence, A. Rozenknop, T. Poibeau
</p>
<p>ras &amp; Marquez, 2005) 1, avec des donn&#233;es issues du Penn Treebank (Marcus, 1993). Or, la com-
munaut&#233; francophone du TALN dispose maintenant, avec le corpus arbor&#233; de Paris 7 (Abeill&#233;,
2003), d&#8217;un outil de travail pertinent puisqu&#8217;une partie de ce corpus est &#233;tiquet&#233;e avec des fonc-
tions syntaxiques. Notre objectif est donc d&#8217;apprendre un &#233;tiqueteur &#224; partir de ces donn&#233;es.
Il existe peu de techniques d&#8217;apprentissage automatique capables de prendre en compte directe-
ment les structures de donn&#233;es arborescentes. Bien s&#251;r, nous pourrions (comme l&#8217;avaient fait la
plupart des participants &#224; la comp&#233;tition CoNLL), consid&#233;rer les arbres comme des simples ta-
bleaux de donn&#233;es et appliquer des m&#233;thodes de classification sur chacun des n&#339;uds des arbres
ind&#233;pendamment. A la place, nous voulons mettre en &#339;uvre la th&#233;orie des &#8220;Champs Al&#233;a-
toires Conditionnels&#8221; (Conditional Random Fields ou CRF). Les CRF (Lafferty et al., 2001;
Sutton &amp; McCallum, 2006) sont des mod&#232;les statistiques d&#8217;annotation tr&#232;s puissants qui ob-
tiennent d&#8217;excellentes performances (souvent les meilleures) pour la reconnaissance d&#8217;entit&#233;s
nomm&#233;es (McCallum &amp; Li, 2003), l&#8217;extraction d&#8217;informations (Pinto et al., 2003), l&#8217;&#233;tiquetage
Part-Of-Speech (Altun et al., 2003) ou le shallow parsing (Sha &amp; Pereira, 2003). Par rapport
aux techniques de classification, ils pr&#233;sentent l&#8217;int&#233;r&#234;t de mod&#233;liser des d&#233;pendances entre an-
notations. Ils ont aussi r&#233;cemment &#233;t&#233; mis en &#339;uvre pour faire de l&#8217;analyse syntaxique (Finkel
et al., 2008). Mais, dans toutes ces applications, les CRF ne sont employ&#233;s que pour annoter
des s&#233;quences. Or, ils ont aussi r&#233;cemment &#233;t&#233; adapt&#233;s &#224; l&#8217;annotation d&#8217;arbres (Gilleron et al.,
2006a; Gilleron et al., 2006b; Jousse, 2007). Cette adaptation n&#8217;avait jusqu&#8217;&#224; pr&#233;sent &#233;t&#233; test&#233;e
que pour l&#8217;&#233;tiquetage de pages Web, en vue d&#8217;en extraire de l&#8217;information ou d&#8217;en transformer
la structure (Jousse, 2007). Il est temps de la confronter &#224; des donn&#233;es linguistiques.
Dans la suite de l&#8217;article, nous commen&#231;ons par d&#233;crire les donn&#233;es du corpus de Paris 7. Nous
pr&#233;sentons ensuite le mod&#232;le g&#233;n&#233;ral des CRF, et son instanciation aux s&#233;quences ou aux arbres.
Nous exposons enfin quelques-uns des r&#233;sultats de nos exp&#233;riences, avec divers param&#233;trages
mais en ne faisant appel &#224; aucune ressource linguistique externe. Ces exp&#233;riences montrent que
les taux de reconnaissance de l&#8217;ordre de 80% de F1-mesure, qui sont l&#8217;&#233;tat de l&#8217;art sur les corpus
anglais, sont aussi atteignables sur nos donn&#233;es.
</p>
<p>2 Le corpus et ses annotations
</p>
<p>Le French Treebank (par la suite not&#233; FTB) est d&#233;crit dans (Abeill&#233;, 2003). Ce corpus, constitu&#233;
&#224; partir d&#8217;extraits du journal Le Monde de 1989 &#224; 1993, est, bien s&#251;r, fortement influenc&#233; par
le Penn Treebank, mais les objectifs d&#8217;application vis&#233;s en priorit&#233; (la constitution d&#8217;une gram-
maire &#233;lectronique du fran&#231;ais) ont entra&#238;n&#233; des descriptions syntaxiques de granularit&#233; plus
fine. (Abeill&#233;, 2003) recense pour le FTB 12 parties principales du discours : A(djectif), Adv,
CL, C(onjonction), D(&#233;terminant), ET(ranger), I(nterjections), N, P(r&#233;position), PRO, PREF, et
enfin V, auxquelles s&#8217;ajoute la ponctuation PONCT. Chacune des 12 cat&#233;gories majeures pos-
s&#232;de des sous-cat&#233;gories, ainsi que, le cas &#233;ch&#233;ant, des indications morphologiques classiques,
et des indications de mode/temps pour les verbes. Le FTB pr&#233;sente ainsi un jeu de cat&#233;gories
maximal de 218 &#233;l&#233;ments, en tenant compte de toutes les combinaisons valides.
</p>
<p>Mais, surtout, le FTB est un corpus arbor&#233; : une analyse en constituants principaux est fournie,
sous la forme de balises XML, pour chacune des 22 000 phrases du corpus. 2 Les constituants
</p>
<p>1. http ://www.lsi.upc.edu/ srlconll/
2. Ces estimations chiffr&#233;es sont bas&#233;es sur des d&#233;comptes r&#233;alis&#233;s sur les fichiers source du corpus.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Annotation fonctionnelle de corpus arbor&#233;s avec des CRF
</p>
<p>distingu&#233;s 3 sont les syntagmes dont la t&#234;te est l&#8217;une des cat&#233;gories majeures suivantes : Nom,
Verbe, Adjectif, Adverbe, Pr&#233;position. S&#8217;y ajoutent les propositions relatives, les subordonn&#233;es,
les &#8220;autres subordonn&#233;es&#8221;, les infinitives, les participiales et enfin les syntagmes coordonn&#233;s. Il
est &#224; noter que seul le noyau verbal est compl&#232;tement d&#233;crit au regard de ses adjoints et de ses
arguments, autrement dit les noms et adjectifs pr&#233;dicatifs ne sont pas identifi&#233;s comme tels. Par
ailleurs, les t&#234;tes de constituants ne sont pas explicitement identifi&#233;es.
</p>
<p>Enfin, une partie du FTB, soit environ 9 000 phrases, comprend en outre des annotations fonc-
tionnelles pour les constituants majeurs : SUJ (sujet), OBJ (objet), MOD (modifieur), A-OBJ
(objet introduit par une pr&#233;position &#8220;&#224;&#8221;), DE-OBJ (idem pour &#8220;de&#8221;), P-OBJ (objet pr&#233;posi-
tionnel), ATS (attribut du sujet) et ATO (attribut de l&#8217;objet), soit 8 fonctions diff&#233;rentes. Ces
&#233;tiquettes sont pr&#233;sentes dans le corpus par le biais d&#8217;attributs affect&#233;s &#224; certaines balises (VN,
VP...). Le parti pris pour cet &#233;tiquetage fonctionnel a &#233;t&#233; une annotation de surface. Ainsi, par
exemple, les sujets des infinitives ne sont pas not&#233;s : dans je dis &lt;PP&gt; &#224; Marie &lt;/PP&gt; de venir,
le groupe pr&#233;positionnel PP est marqu&#233; comme A-OBJ de &#8220;dire&#8221;, mais pas comme SUJ de &#8220;ve-
nir&#8221;. Dans le corpus du challenge CoNLL au contraire, ces fonctions auraient figur&#233; toutes les
deux : chaque occurrence de verbe y donne lieu &#224; une annotation sp&#233;cifique compl&#232;te, de telle
sorte que le sujet d&#8217;un verbe peut tr&#232;s bien aussi &#234;tre l&#8217;objet d&#8217;un autre. Ce choix a certainement
rendu la t&#226;che de CoNLL plus abordable. Nous n&#8217;avons pris en compte pour nos exp&#233;riences
que ces 9 000 phrases syntaxiquement analys&#233;es et fonctionnellement annot&#233;es.
</p>
<p>3 Les CRF et leur adaptation aux arbres
</p>
<p>3.1 Pr&#233;sentation g&#233;n&#233;rale des CRF
</p>
<p>Les CRF permettent d&#8217;associer &#224; une observation x une annotation y, en se basant sur un en-
semble d&#8217;exemples &#233;tiquet&#233;s, c&#8217;est-&#224;-dire un ensemble de couples (x, y). Souvent, x est une
s&#233;quence d&#8217;unit&#233;s (par exemple une suite de mots) et y la s&#233;quence des &#233;tiquettes correspon-
dante (par exemple la suite de leur cat&#233;gorie syntaxique). Mais, dans notre application, x et y
proviendront tous les deux des arbres du FTB : x sera un arbre d&#8217;analyse syntaxique et y l&#8217;arbre
de m&#234;me structure dont les n&#339;uds internes ne sont constitu&#233;s que de fonctions syntaxiques (ou
d&#8217;une &#233;tiquette &#8869; signifiant &#8220;aucune fonction syntaxique&#8221;), comme dans la Figure 1.
Les CRF appartiennent &#224; la famille des mod&#232;les graphiques non dirig&#233;s. Ils sont d&#233;finis par X
et Y , deux champs al&#233;atoires d&#233;crivant respectivement l&#8217;observation x et son annotation y, et
par un graphe G = (V,E) dont V = X &#8746; Y est l&#8217;ensemble des n&#339;uds (vertices) et E &#8838; V &#215; V
l&#8217;ensemble des arcs (edges). On note Yv la variable al&#233;atoire du n&#339;ud v &#8712; V dans Y . On dit
que (X, Y ) respecte la propri&#233;t&#233; de Markov si :
</p>
<p>&#8704;v, p(Yv|X, {Yw, w 6= v}) = p(Yv|X, {Yw, (Yv, Yw) &#8712; E})
</p>
<p>Elle signifie que l&#8217;annotation d&#8217;un n&#339;ud Yv ne d&#233;pend que des annotations Yw des n&#339;uds avec
lesquels il est connect&#233; dans G et de toute l&#8217;observation globale X . Les CRF rentrent dans ce
cadre. Dans le graphe correspondant, chaque Yv est donc toujours implicitement reli&#233;e &#224; toutes
les variables du champ X , ce qui explique qu&#8217;on omette la repr&#233;sentation des n&#339;uds de X dans
le dessin de G. D&#8217;apr&#232;s le th&#233;or&#232;me de Hammersley-Clifford (Hammersley &amp; Clifford, 1971),
</p>
<p>3. Ces informations sont tir&#233;es des guides fournis aux annotateurs lors de la constitution du corpus.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>E. Moreau, I. Tellier, A. Balvet, G. Laurence, A. Rozenknop, T. Poibeau
</p>
<p>SENT
</p>
<p>NP
</p>
<p>Sligos
</p>
<p>VN
</p>
<p>va
</p>
<p>VPinf
</p>
<p>VN
</p>
<p>prendre
</p>
<p>NP
</p>
<p>pied
</p>
<p>PP
</p>
<p>au NP
</p>
<p>Royaume-Uni
</p>
<p>.
</p>
<p>&#8869;
</p>
<p>SUJ
</p>
<p>&#8869;
</p>
<p>&#8869;
</p>
<p>&#8869;
</p>
<p>OBJ
</p>
<p>&#8869;
</p>
<p>&#8869;
</p>
<p>OBJ
</p>
<p>&#8869;
</p>
<p>MOD
</p>
<p>&#8869; &#8869;
</p>
<p>&#8869;
</p>
<p>&#8869;
</p>
<p>FIGURE 1 &#8211; un arbre observ&#233; x (&#224; gauche) et son annotation y (&#224; droite)
</p>
<p>cette condition permet d&#8217;&#233;crire :
</p>
<p>p(y|x) =
1
</p>
<p>Z(x)
</p>
<p>&#8719;
c&#8712;C
</p>
<p>&#968;c(yc, x) avec Z(x) =
&#8721;
</p>
<p>y
</p>
<p>&#8719;
c&#8712;C
</p>
<p>&#968;c(yc, x)
</p>
<p>o&#249; C est l&#8217;ensemble des cliques (sous-graphes compl&#232;tement connect&#233;s) de G sur Y , yc la confi-
guration prise par les variables de Y dans la clique c, les &#968;c sont des &#8220;fonctions de potentiels&#8221;
sur c et Z(x) est un coefficient de normalisation.
</p>
<p>Dans ces mod&#232;les, on dispose donc directement d&#8217;une formule pour calculer p(y|x) sans avoir
besoin de passer par le calcul de p(x, y)/p(x), ce qui fait toute la diff&#233;rence entre les mod&#232;les
discriminants (comme les CRF) et les mod&#232;les g&#233;n&#233;ratifs (comme les HMMs : Hidden Markov
Models ou les PCFGs : Probabilistic Context-Free Grammars) dans lesquels il est n&#233;cessaire
d&#8217;&#233;valuer p(x, y), c&#8217;est-&#224;-dire de mod&#233;liser comment l&#8217;observation x est produite conjointement
&#224; son annotation y. Les mod&#232;les g&#233;n&#233;ratifs doivent mod&#233;liser comment les observations x sont
g&#233;n&#233;r&#233;es, alors que les mod&#232;les discriminants ne font aucune hypoth&#232;se sur x.
</p>
<p>Pour d&#233;finir les CRF, (Lafferty et al., 2001) ont propos&#233; de donner aux fonctions de potentiels
&#968;c la forme suivante :
</p>
<p>&#968;c(yc, x) = exp
(&#8721;
</p>
<p>k
</p>
<p>&#955;kfk(yc, x, c)
)
</p>
<p>Les fonctions fk sont appel&#233;es features : elles sont d&#233;finies &#224; l&#8217;int&#233;rieur de chaque clique c et
sont &#224; valeurs r&#233;elles, mais souvent choisies pour donner un r&#233;sultat binaire (0 ou 1). C&#8217;est &#224;
travers ces fonctions, fournies par l&#8217;utilisateur, que des ressources ou des connaissances sur le
domaine peuvent &#234;tre int&#233;gr&#233;es dans le mod&#232;le. Par exemple, l&#8217;association entre un mot xi et
une cat&#233;gorie yi &#224; une m&#234;me position i peut &#234;tre test&#233;e par une feature fk(yi, xi, i) qui vaut 1 si
(xi, yi) est pr&#233;sent dans un dictionnaire, 0 sinon. Par d&#233;finition, la valeur de ces fonctions peut
aussi d&#233;pendre de la valeur de x n&#8217;importe o&#249; dans la donn&#233;e (et pas uniquement &#224; l&#8217;int&#233;rieur
de la clique c), ce qui est impossible &#224; exprimer dans les HMMs. Les poids &#955;k, qui permettent
d&#8217;accorder plus ou moins d&#8217;importance &#224; chaque feature fk, sont les param&#232;tres du mod&#232;le :
l&#8217;enjeu de la phase d&#8217;apprentissage est de fixer leur valeur. Dans un CRF, on a donc finalement :
</p>
<p>p(y|x) =
1
</p>
<p>Z(x)
exp
(&#8721;
</p>
<p>c&#8712;C
</p>
<p>&#8721;
k
</p>
<p>&#955;kfk(yc, x, c)
)
avec Z(x) =
</p>
<p>&#8721;
y
</p>
<p>exp
(&#8721;
</p>
<p>c&#8712;C
</p>
<p>&#8721;
k
</p>
<p>&#955;kfk(yc, x, c)
)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Annotation fonctionnelle de corpus arbor&#233;s avec des CRF
</p>
<p>Le premier probl&#232;me associ&#233; aux CRF est celui de l&#8217;inf&#233;rence ou de l&#8217;apprentissage, qui consiste
&#224; estimer les param&#232;tres &#955;k qui rendent le mieux compte d&#8217;un &#233;chantillon S d&#8217;observations an-
not&#233;es : S = {(xj , yj)1&#8804;j&#8804;n}. Classiquement, on cherche l&#8217;ensemble des param&#232;tres qui maxi-
misent la log-vraisemblance du mod&#232;le. Des techniques de descente de gradient sont utilis&#233;es
pour estimer cet ensemble optimal. Le second probl&#232;me est celui de l&#8217;annotation qui consiste,
une fois les param&#232;tres du CRF fix&#233;s, &#224; trouver la valeur de y la plus probable associ&#233;e &#224; une
nouvelle observation x, autrement dit &#224; trouver argmaxyp(y|x). Il est trait&#233; en mettant en &#339;uvre
des algorithmes de programmation dynamique.
</p>
<p>3.2 Les CRF sur les s&#233;quences et sur les arbres
</p>
<p>Les CRF ont pour l&#8217;instant surtout &#233;t&#233; utilis&#233;s pour annoter des s&#233;quences. Dans ce cas, le
graphe utilis&#233; est une &#8220;cha&#238;ne lin&#233;aire du premier ordre&#8221; dans laquelle chaque variable Yv est
reli&#233;e uniquement &#224; sa voisine droite et &#224; sa voisine gauche. Toutes les distributions de proba-
bilit&#233;s exprimables par un HMM peuvent &#234;tre reproduites dans un CRF de cette forme (Sut-
ton &amp; McCallum, 2006). Plusieurs biblioth&#232;ques sont disponibles pour les mettre en &#339;uvre :
&#8220;crf.source.net&#8221; de Sarawagi, &#8220;Mallet&#8221; de McCallum et &#8220;CRF++&#8221; de Taku Kado.
</p>
<p>Des travaux r&#233;cents proposent d&#8217;adapter le mod&#232;le g&#233;n&#233;ral des CRF au cas de l&#8217;annotation
d&#8217;arbres dans lesquels chaque n&#339;ud interne peut avoir un nombre quelconque de fils ordonn&#233;s.
Cette adaptation a &#233;t&#233; initialement d&#233;finie pour annoter des documents XML. Elle a ainsi &#233;t&#233;
employ&#233;e avec succ&#232;s dans des t&#226;ches d&#8217;extraction d&#8217;information &#224; partir de pages Web, et de
transformation de documents (Gilleron et al., 2006a; Gilleron et al., 2006b; Jousse, 2007). Elle
peut aussi s&#8217;appliquer aux arbres pr&#233;sents dans le FTB.
</p>
<p>Nos champs al&#233;atoires X et Y sont donc d&#233;sormais identifi&#233;s &#224; l&#8217;ensemble des n&#339;uds pos-
sibles d&#8217;un arbre. Nous devons, dans un premier temps, proposer un graphe pour connecter les
variables de Y . Nous avons en fait envisag&#233; 3 variantes possibles, de complexit&#233; croissante :
&#8211; dans la variante appel&#233;e 1-CRF, le graphe se r&#233;duit &#224; un ensemble de singletons non connec-
</p>
<p>t&#233;s. L&#8217;annotation yv d&#8217;un n&#339;ud quelconque v ne d&#233;pend alors que de sa position dans l&#8217;arbre,
et de l&#8217;ensemble de l&#8217;arbre observ&#233; x. La t&#226;che d&#8217;annotation par 1-CRF est donc ramen&#233;e
&#224; une t&#226;che de classification de n&#339;uds. Ce mod&#232;le, aussi connu sous le nom de maximum
d&#8217;entropie ind&#233;pendant sur chacun des n&#339;uds, servira de baseline &#224; nos exp&#233;riences.
</p>
<p>&#8211; dans la variante 2-CRF, nous prenons en compte les relations hi&#233;rarchiques sp&#233;cifiques des
arbres : nous relions entre eux dans le graphe chaque couple de n&#339;uds de variables sur Y en
relation p&#232;re-fils dans l&#8217;arbre initial.
</p>
<p>&#8211; enfin, dans la variante 3-CRF, nous tenons en plus compte de l&#8217;ordre des annotations port&#233;es
par les fils successifs d&#8217;un m&#234;me p&#232;re. Le graphe relie donc alors &#224; la fois les couples en
relation p&#232;re-fils et les couples en relation fr&#232;res successifs d&#8217;un m&#234;me p&#232;re. Dans de tels
graphes, les cliques maximales sont &#8220;triangulaires&#8221; : elles sont compos&#233;es d&#8217;un p&#232;re et de
deux de ses fils cons&#233;cutifs.
</p>
<p>La Figure 2 montre les graphes sur les annotations correspondant &#224; l&#8217;arbre droit de la Figure
1, pour un 2-CRF et un 3-CRF. La variante 2-CRF ram&#232;ne en quelque sorte un arbre &#224; l&#8217;en-
semble des chemins allant de sa racine &#224; chacune de ses feuilles : elle peut &#234;tre simul&#233;e avec
les outils mettant en &#339;uvre les CRF sur les s&#233;quences. C&#8217;est l&#8217;approche adopt&#233;e par (Cohn &amp;
Blusom, 2005) pour la t&#226;che de CoNLL. La variante 3-CRF, en revanche, est vraiment originale
et seule l&#8217;application XCRF 4, issue des travaux pr&#233;c&#233;demment &#233;voqu&#233;s, l&#8217;autorise. L&#8217;&#233;quipe qui
</p>
<p>4. disponible librement sur : treecrf.gforge.inria.fr/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>E. Moreau, I. Tellier, A. Balvet, G. Laurence, A. Rozenknop, T. Poibeau
</p>
<p>&#8869;
</p>
<p>SUJ
</p>
<p>&#8869;
</p>
<p>&#8869;
</p>
<p>&#8869;
</p>
<p>OBJ
</p>
<p>&#8869;
</p>
<p>&#8869;
</p>
<p>OBJ
</p>
<p>&#8869;
</p>
<p>MOD
</p>
<p>&#8869; &#8869;
</p>
<p>&#8869;
</p>
<p>&#8869;
</p>
<p>&#8869;
</p>
<p>SUJ
</p>
<p>&#8869;
</p>
<p>&#8869;
</p>
<p>&#8869;
</p>
<p>OBJ
</p>
<p>&#8869;
</p>
<p>&#8869;
</p>
<p>OBJ
</p>
<p>&#8869;
</p>
<p>MOD
</p>
<p>&#8869; &#8869;
</p>
<p>&#8869;
</p>
<p>&#8869;
</p>
<p>FIGURE 2 &#8211; graphes sur Y pour un 2-CRF (&#224; gauche) et un 3-CRF (&#224; droite)
</p>
<p>l&#8217;a produite a d&#251; red&#233;finir enti&#232;rement les algorithmes d&#8217;apprentissage et d&#8217;annotation adapt&#233;s
&#224; ce mod&#232;le &#8220;arbor&#233;&#8221;. Elle a aussi montr&#233; que toutes les distributions de probabilit&#233;s expri-
mables par une PCFG sous forme normale de Chomsky peuvent &#234;tre reproduites par un 3-CRF
(Gilleron et al., 2006a; Jousse, 2007).
</p>
<p>4 Exp&#233;riences
</p>
<p>4.1 Pr&#233;-traitements des donn&#233;es
</p>
<p>Avant de lancer nos exp&#233;riences, des pr&#233;traitements ont &#233;t&#233; n&#233;cessaires. En effet, alors que le
corpus de CoNLL est centr&#233; sur les verbes, aucune &#8220;fonction syntaxique&#8221; sp&#233;cifique n&#8217;est atta-
ch&#233;e aux verbes dans le FTB. Or, les fonctions syntaxiques des groupes nominaux d&#233;pendent
essentiellement de leur position par rapport au verbe principal de la phrase : le sujet aura ten-
dance &#224; &#234;tre &#224; sa gauche, le ou les objet(s) &#224; sa droite. Nous avons donc commenc&#233; par ajouter
syst&#233;matiquement des &#233;tiquettes PRED (pour &#8220;pr&#233;dicat&#8221;) &#224; tous les n&#339;uds VN qui n&#8217;ont pas
d&#233;j&#224; d&#8217;&#233;tiquette. Sans cet ajout, similaire &#224; celui propos&#233; dans (Schluter &amp; van Genabith, 2008),
il n&#8217;y aurait pas grand sens &#224; prendre en compte des d&#233;pendances &#8220;horizontales&#8221; entre &#233;tiquettes
de fonctions, comme c&#8217;est le cas dans un 3-CRF. De plus, parmi les VN d&#233;j&#224; &#233;tiquet&#233;s, certains
(par exemples des verbes &#224; l&#8217;infinitifs), occupaient une fonction SUJ ou OBJ : ils n&#8217;ont pas &#233;t&#233;
modifi&#233;s. Mais d&#8217;autres avaient pour &#233;tiquette la concat&#233;nation des fonctions des clitiques qui
s&#8217;y rattachent et sont leurs fils dans l&#8217;arbre. Dans ce cas, nous avons remplac&#233; cette annotation
au niveau du VN par l&#8217;&#233;tiquette PREDC (pour &#8220;pr&#233;dicat complexe&quot;) et nous avons automati-
quement &#8220;fait descendre&#8221; les fonctions des clitiques aux fils concern&#233;s, en se fondant sur des
informations pr&#233;sentes dans certains attributs de l&#8217;arbre initial. Certaines ambiguit&#233;s r&#233;siduelles
ont &#233;t&#233; trait&#233;es &#224; la main. Apr&#232;s ce traitement, chaque n&#339;ud du corpus n&#8217;a au plus qu&#8217;une seule
&#233;tiquette de fonction syntaxique parmi 11 possibles (les 8 initiales plus PRED, PREDC et &#8869;).
Nous avons compt&#233; dans le corpus ainsi enrichi 8 588 phrases contenant 439 370 n&#339;uds parmi
lesquels 62 390 ont une vraie &#233;tiquette de fonction syntaxique (cf. la table en section 4.3 pour
voir leur r&#233;partition). Il y a 97 diff&#233;rents types de cliques &#8220;p&#232;re-fils&#8221; annot&#233;es (correspondant</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Annotation fonctionnelle de corpus arbor&#233;s avec des CRF
</p>
<p>&#224; 430 782 occurrences) et 474 diff&#233;rentes cliques &#8220;triangulaires&#8221; (correspondant &#224; 261 098
occurrences). Ces nombres apparaissent comme suffisants pour esp&#233;rer trouver des r&#233;gularit&#233;s
dans les donn&#233;es, m&#234;me si toutes les cat&#233;gories ne sont bien s&#251;r pas &#233;galement repr&#233;sent&#233;es.
</p>
<p>4.2 S&#233;lection des features
</p>
<p>Le choix de features pertinentes est essentiel &#224; la construction d&#8217;un mod&#232;le fiable. La technique
utilis&#233;e dans (Jousse, 2007) pour les arbres XML/HTML s&#8217;est av&#233;r&#233;e inadapt&#233;e pour le FTB :
elle menait &#224; une F1-mesure inf&#233;rieure &#224; 50%. Nous avons donc red&#233;fini totalement le mode de
s&#233;lection de ces features, sans pour autant faire appel &#224; des ressources linguistiques externes.
Dans nos exp&#233;riences, chaque feature est caract&#233;ris&#233;e par une clique c et un couple (C, T ) :
&#8211; C &#233;num&#232;re l&#8217;ensemble yc des valeurs de Y sur la clique c du graphe. Les features de type 1 (ou
</p>
<p>FT1) sont r&#233;duites &#224; une seule valeur, elles correspondent aux 1-CRF. Les FT2 (resp. FT3)
contiennent les annotations d&#8217;un couple de n&#339;uds p&#232;re-fils (resp. les triplets d&#8217;annotations
d&#8217;une clique triangulaire) et correspondent aux 2-CRF (resp. 3-CRF). Par exemple, pour la
clique triangulaire 5 identifi&#233;e par c0 = (3, 3.2, 3.3) dans l&#8217;arbre &#224; droite de la Figure 1, on a
une FT3 qui donne : C0 = {OBJ,OBJ,MOD}
</p>
<p>&#8211; T = {t1, t2, ..., tn} est un ensemble (&#233;ventuellement vide) de tests bool&#233;ens portant sur les
valeurs de l&#8217;observation x. Par exemple, pour l&#8217;arbre gauche de la Figure 1 o&#249; x3.1 d&#233;signe le
premier fils du troisi&#232;me fils de la racine de l&#8217;observation, on peut d&#233;finir T0 = {x3.1 = V N}.
</p>
<p>Ainsi, le couple (C0, T0) pr&#233;c&#233;dent caract&#233;rise la feature de la clique c0 suivante :
f(C0,T0)(yc0, x, c0) = 1 si (y3 = OBJ) &#8743; (y3.2 = OBJ) &#8743; (y3.3 = MOD) &#8743; (x3.1 = V N)
f(C0,T0)(yc0, x, c0) = 0 sinon
En th&#233;orie, alors que les &#233;l&#233;ments de C sont restreints &#224; une clique c de G, ceux de T peuvent
porter sur tout l&#8217;arbre observ&#233; x. Pour g&#233;n&#233;rer les features qui seront employ&#233;es dans nos exp&#233;-
riences, nous pouvons faire varier les param&#232;tres suivants sur les tests de T :
&#8211; la nature de l&#8217;information disponible sur x prise en compte : nous nous sommes content&#233;s ici
</p>
<p>d&#8217;utiliser les &#233;tiquettes syntaxiques et aucun autre attribut accessible dans l&#8217;arbre (comme les
lemmes, les genres/nombres..., mais aussi le nombre de fils d&#8217;un n&#339;ud, sa profondeur, etc.)
</p>
<p>&#8211; le voisinage autour de la position du n&#339;ud courant de la clique (en autorisant &#224; aller dans
toutes les directions : p&#232;re, fils, fr&#232;re gauche, fr&#232;re droit) jusqu&#8217;o&#249; peuvent porter les tests.
Dans notre exemple, le n&#339;ud courant qui identifie la clique c0 est en position 3.2, et les tests
sont limit&#233;s &#224; un voisinage de 1 (le n&#339;ud x3.1 est bien &#224; une distance 1 de ce n&#339;ud courant).
</p>
<p>&#8211; le nombre maximal de tests autoris&#233;s dans un m&#234;me ensemble T
Pour une clique et un FT donn&#233;s, un voisinage et un nombre de tests fix&#233;s, nous g&#233;n&#233;rons toutes
les features repr&#233;sent&#233;es dans l&#8217;ensemble d&#8217;apprentissage. Pour limiter la combinatoire, nous
nous restreignons &#224; un voisinage de 2 et &#224; un nombre maximal de tests &#233;gal &#224; 2. Cependant,
dans ce cas, nous avons r&#233;alis&#233; les exp&#233;riences en gardant ou non les features issues des confi-
gurations &#224; occurrence unique. Les diff&#233;rences de performance sont minimes (jamais plus de
0.5%) mais ne pas tenir compte de ces features permet d&#8217;acc&#233;l&#233;rer l&#8217;apprentissage.
</p>
<p>4.3 R&#233;sultats et analyse
</p>
<p>Dans les r&#233;sultats qui suivent, la pr&#233;cision et le rappel ne sont calcul&#233;s que pour les &#8220;vraies&#8221;
&#233;tiquettes, c&#8217;est-&#224;-dire sans tenir compte de &#8869;, trop fr&#233;quent : 85% des n&#339;uds n&#8217;ont pas de
</p>
<p>5. o&#249; le n&#339;ud num&#233;rot&#233; i.j est le j-&#232;me fils du i-&#232;me fils de la racine</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>E. Moreau, I. Tellier, A. Balvet, G. Laurence, A. Rozenknop, T. Poibeau
</p>
<p>fonction syntaxique et sont presque toujours correctement identifi&#233;s (99% de F1-mesure quel
que soit le mod&#232;le utilis&#233;). C&#8217;est la fa&#231;on habituelle de mesurer la performance dans la t&#226;che
consid&#233;r&#233;e (Blaheta, 2004). Pour nos exp&#233;riences, nous avons d&#233;coup&#233; le corpus en 5 parties
&#233;gales : 1/5 (c&#8217;est-&#224;-dire 20%) est utilis&#233; comme donn&#233;es d&#8217;apprentissage, pendant que les &#233;ti-
quettes de fonctions syntaxiques sont retir&#233;es des 4/5 (ou 80%) restant, utilis&#233;s comme corpus
de test. Nous avons proc&#233;d&#233; &#224; une validation crois&#233;e et fait la moyenne des exp&#233;riences. Les
tables qui suivent donnent un panorama des r&#233;sultats obtenus : &#224; gauche en faisant varier cer-
tains param&#232;tres, &#224; droite en d&#233;taillant les r&#233;sultats du meilleur mod&#232;le sur chaque cat&#233;gorie.
</p>
<p>voisinage=1 voisinage=2
Config. Feat. F1 Feat. F1
</p>
<p>FT1 / 1T 103 44.3 508 78.8
FT1 / 2T 123 44.5 3,716&#8727; 79.14&#8727;
FT2 / 1T 579 52.9 2,358 81.3
FT2 / 2T 704 52.9 12,292&#8727; 80.4&#8727;
FT3 / 1T 1,766 79.1 6,570 81.6
FT3 / 2T 2,131 78.8 24,436&#8727; 80.3&#8727;
</p>
<p>&#8727; : sans les features &#224; occurrence unique
Feat. / F1 : nb de features / F1-mesure en %
</p>
<p>FTn / mT : Feature type n avec m tests
</p>
<p>&#233;tiquette Prop. P R F1
NO TAG - 99.61 99.64 99.62
A-OBJ 2.75 20.22 8.72 11.88
ATO 0.24 55.66 23.08 28.81
ATS 3.72 73.86 49.96 59.57
DE-OBJ 2.56 36.27 16.87 22.95
MOD 23.27 71.31 81.47 75.96
OBJ 17.67 78.21 82.03 80.03
P-OBJ 1.53 13.62 5.72 6.12
PRED 26.27 95.72 97.54 96.62
PREDC 0.26 41.22 13.39 17.61
SUJ 21.72 88.70 91.07 89.87
Total 100.00 81.67 81.54 81.60
</p>
<p>Le tableau de gauche montre qu&#8217;il vaut mieux augmenter les voisinages que le nombre de tests
dans la g&#233;n&#233;ration des features. Celui de droite montre que les &#233;tiquettes les plus fr&#233;quentes
(PRED, MOD, SUJ, OBJ) sont, sans surprise, plus faciles &#224; retrouver que les autres. Comme on
pouvait s&#8217;y attendre, on obtient de meilleures performances en utilisant des FT2 qu&#8217;en utilisant
des FT1, et de meilleures encore avec des FT3, mais l&#8217;&#233;cart tend &#224; diminuer quand le voisinage
augmente. Il est difficile de comparer ces r&#233;sultats avec d&#8217;autres, puisque ces exp&#233;riences sont
les premi&#232;res men&#233;es sur le FTB. Pourtant, les meilleurs travaux portant sur le Penn Trebank
(Blaheta &amp; Charniak, 2000; Blaheta, 2004; Merlo &amp; Musillo, 2005; Musillo &amp; Merlo, 2005)
donnent des valeurs comparables. Notons aussi que les baselines &#8220;de bon sens&#8221;, faisant appel
aux m&#234;mes informations mais sans aucun apprentissage, que nous avons essay&#233; de program-
mer directement (avec des r&#232;gles du genre &#8220;le GN principal &#224; gauche du verbe est SUJ&#8221;) se
comportaient nettement moins bien (F1-mesure inf&#233;rieure &#224; 60% pour SUJ, par exemple).
</p>
<p> 0
</p>
<p> 20
</p>
<p> 40
</p>
<p> 60
</p>
<p> 80
</p>
<p> 100
</p>
<p>FT 1 FT 2 FT 3
</p>
<p>Pr&#233;cision
Rappel
</p>
<p> 50
 55
 60
 65
 70
 75
 80
 85
 90
</p>
<p> 0  2  4  6  8  10  12  14  16  18  20
</p>
<p>F1
&#8722;M
</p>
<p>es
ur
</p>
<p>e 
(%
</p>
<p>)
</p>
<p>Part du corpus utilis&#233;e pour l&#8217;entra&#238;nement (%)
</p>
<p>Voisinage 2, FT3, 1 test
</p>
<p>Fig. 3 : pr&#233;cision et rappel en fonction de FT Fig. 4 : influence du nombre d&#8217;exemples
cas d&#8217;un voisinage 1, avec 1 test. proportion utilis&#233; en apprentissage (%)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Annotation fonctionnelle de corpus arbor&#233;s avec des CRF
</p>
<p>Les Figures 3 et 4 illustrent d&#8217;autres propri&#233;t&#233;s. On voit notamment sur la Figure 3 que le gain
apport&#233; par les mod&#232;les plus complexes concerne surtout le rappel. Un autre avantage, moins
visible, des FT3 sur les FT2 (et les FT1) est qu&#8217;ils se comportent mieux sur les cat&#233;gories
moins repr&#233;sent&#233;es. Par exemple, DE-OBJ (2.5% des annotations), est reconnu avec seulement
14%/1% de pr&#233;cision/rappel avec un mod&#232;le de voisinage 1/FT1, mais avec 41%/13% de pr&#233;ci-
sion/rappel avec un mod&#232;le de voisinage 1/FT3. Avec la Figure 4, on a la confirmation que les
CRF n&#233;cessitent peu d&#8217;exemples pour &#234;tre performants : avec seulement 0.25% du corpus (21
phrases), on obtient d&#233;j&#224; 66% de F1-mesure (valid&#233; sur des exemples nouveaux repr&#233;sentant
80% du corpus). Cette propri&#233;t&#233; est int&#233;ressante en termes d&#8217;efficacit&#233; : ainsi, avec 7.5% des
donn&#233;es, l&#8217;apprentissage avec un 3-CRF prend environ 40mn et atteint 80% de F1-mesure.
</p>
<p>Nous avons aussi r&#233;alis&#233; quelques exp&#233;riences qui montrent qu&#8217;en int&#233;grant un minimum de
connaissances linguistiques dans nos features, il est possible d&#8217;am&#233;liorer encore ces scores. Par
exemple, nos mod&#232;les ont du mal &#224; discriminer les &#233;tiquettes A-OBJ, DE-OBJ et P-OBJ, peu
fr&#233;quentes et apparaissant dans des contextes tr&#232;s similaires, surtout quand on ne s&#8217;autorise &#224;
regarder que les cat&#233;gories syntaxiques. Nous avons ainsi construit des tests ad hoc qui regardent
si le lemme du premier fils du constituant est &#8220;de&#8221; ou &#8220;&#224;&#8221; et nous avons g&#233;n&#233;r&#233; toutes les features
possibles avec les cliques pr&#233;sentes dans le corpus d&#8217;apprentissage et un de ces tests. Dans les
m&#234;mes conditions que celles de la table des r&#233;sultats par cat&#233;gorie, la pr&#233;cision et le rappel pour
l&#8217;&#233;tiquette DE-OBJ (resp. A-OBJ) atteignent alors 63.9% et 64.1% (resp. 56.1% et 57.1%), soit
un gain de plus 40%. La F1-mesure globale monte alors &#224; 83.2%.
</p>
<p>5 Conclusion et perspectives
</p>
<p>Dans cet article, nous avons d&#233;crit le mod&#232;le g&#233;n&#233;ral des CRF, et comment il peut s&#8217;instancier
selon diverses variantes, en fonction du graphe que l&#8217;on se fixe entre annotations. Nous avons
ensuite montr&#233; exp&#233;rimentalement que les mod&#232;les les plus complexes permettent, comme on
pouvait l&#8217;esp&#233;rer, d&#8217;atteindre de meilleurs taux de reconnaissance sur la t&#226;che que nous nous
sommes fix&#233;e. Le mod&#232;le des 3-CRF, qui n&#8217;avait encore jamais &#233;t&#233; test&#233; sur des donn&#233;es lin-
guistiques, offre des perspectives int&#233;ressantes, m&#234;me si son param&#233;trage reste encore sensible
(notamment pour le mode de g&#233;n&#233;ration et de s&#233;lection des features). Nous avons aussi gr&#226;ce &#224;
lui particip&#233; &#224; la campagne CoNLL 2009, dans une t&#226;che o&#249; il s&#8217;agissait d&#8217;affecter des r&#244;les th&#233;-
matiques dans des arbres de d&#233;pendances provenant de corpus multilingues 6, avec des r&#233;sultats
tr&#232;s honorables (Moreau &amp; Tellier, 2009).
Les CRF peuvent donc prendre directement en compte des structures arbor&#233;es et ils n&#233;cessitent
peu d&#8217;exemples pour apprendre. Ils sont aussi g&#233;n&#233;riques : le programme d&#8217;apprentissage que
nous avons employ&#233; (g&#233;n&#233;ration des features inclus) est totalement ind&#233;pendant de la langue
du corpus. D&#8217;un autre c&#244;t&#233;, les CRF sont aussi suffisamment flexibles pour int&#233;grer facilement
des connaissances ou des ressources linguistiques externes sous la forme de dictionnaires ou
de r&#232;gles, comme l&#8217;illustre l&#8217;exemple du traitement des &#233;tiquettes DE-OBJ et A-OBJ. Dans le
m&#234;me esprit nous comptons aussi, par exemple, traduire sous forme de features des sch&#233;mas de
sous-cat&#233;gorisation de verbes, et &#233;valuer leur apport. Les CRF pourraient ainsi contribuer &#224; r&#233;-
concilier apprentissage symbolique (via la g&#233;n&#233;ration de features) et apprentissage statistique 7.
</p>
<p>6. http ://ufal.mff.cuni.cz/conll2009-st/
7. Ce travail r&#233;sulte du projet ANR CRoTAL, CRF pour le TAL : http ://crotal.gforge.inria.fr/pmwiki-2.1.27/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>E. Moreau, I. Tellier, A. Balvet, G. Laurence, A. Rozenknop, T. Poibeau
</p>
<p>R&#233;f&#233;rences
A. ABEILL&#201;, Ed. (2003). Treebanks, Building and Using Parsed Corpora. Dor-
drecht/Boston/London : Kluwer Academic Publishers.
ALTUN Y., JOHNSON M. &amp; HOFMANN T. (2003). Investigating loss functions and optimiza-
tion methods for discriminative learning of label sequences. In Proceedings of EMNLP.
BLAHETA D. (2004). Function Tagging. PhD thesis, Brown University.
BLAHETA D. &amp; CHARNIAK E. (2000). Assigning function tags to parsed text. In Proceedings
of NAACL-00, p. 234&#8211;240.
X. CARRERAS &amp; L. MARQUEZ, Eds. (2005). actes de CoNNL 2005.
COHN T. &amp; BLUSOM P. (2005). Semantic role labelling with tree conditional random fields.
In (Carreras &amp; Marquez, 2005).
FINKEL J. R., KLEEMAN A. &amp; MANNING C. D. (2008). Efficient, feature-based, conditional
random field parsing. In Proceedings of ACL-08 :HLT, p. 959&#8211;967, Columbus, Ohio : ACL.
GILLERON R., JOUSSE F., TELLIER I. &amp; TOMMASI M. (2006a). Conditional random fields
for xml trees. In ECML workshop on Mining and Learning in Graphs.
GILLERON R., JOUSSE F., TELLIER I. &amp; TOMMASI M. (2006b). Xml document transforma-
tion with conditional random fields,. In S. L. 4518, Ed., INEX 2006.
HAMMERSLEY J. &amp; CLIFFORD P. (1971). Markov fields on finite graphs and lattices. Unpu-
blished.
JOUSSE F. (2007). Transformations d&#8217;Arbres XML avec des Mod&#232;les Probabilistes pour l&#8217;An-
notation. PhD thesis, Universit&#233; Charles de Gaulle - Lille 3.
LAFFERTY J., MCCALLUM A. &amp; PEREIRA F. (2001). Conditional random fields : Proba-
bilistic models for segmenting and labeling sequence data. In Proceedings of ICML&#8217;01, p.
282&#8211;289.
MARCUS M. (1993). Building a large annotated corpus : the penn treebank. In Computational
Linguistics, p. 313&#8211;330.
MCCALLUM A. &amp; LI W. (2003). Early results for named entity recognition with conditional
random fields. In Proceedings of CoNLL 2003.
MERLO P. &amp; MUSILLO G. (2005). Accurate function parsing. In proceedings of HLT &#8217;05, p.
620&#8211;627 : ACL.
MOREAU E. &amp; TELLIER I. (2009). The crotal srl system : a generic tool based on tree-
structured crf. In proceedings of CoNNL 2009.
MUSILLO G. &amp; MERLO P. (2005). Lexical and structural biases for function parsing. In
Proceedings of IWPT 2005, p. 83&#8211;93.
PINTO D., MCCALLUM A., LEE X. &amp; CROFT W. (2003). Table extraction using conditional
random fields. In SIGIR&#8217;03 : Proceedings of the 26th ACM SIGIR.
SCHLUTER N. &amp; VAN GENABITH J. (2008). Treebank-based acquisition of lfg parsing re-
sources for french. In Proceedings of LREC 08, Marrakech, Morocco.
SHA F. &amp; PEREIRA F. (2003). Shallow parsing with conditional random fields. In Technical
Report CIS TR MS-CIS-02-35, University of Pennsylvania, 2003.
SUTTON C. &amp; MCCALLUM A. (2006). An Introduction to Conditional Random Fields for
Relational Learning, In L. GETOOR &amp; B. TASKAR, Eds., Introduction to Statistical Relational
Learning. MIT Press.</p>

</div></div>
</body></html>