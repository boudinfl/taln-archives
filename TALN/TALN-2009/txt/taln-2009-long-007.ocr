TALN 2009, Senlis, 24-26 juin 2009

Classiﬁcation d’un contenu encyclopédique en vue d’un
étiquetage par entités nommées

Eric Chartonl Juan-Manuel Torres-Morenol
(1) LIA / Université d’Avignon, 339 chemin des Meinajaries, 84911 Avignon
eric.charton@univ-avignon.fr, juan-manuel.torres @univ-avignon.fr

Résumé. On utilise souvent des ressources lexicales externes pour améliorer les perfor-
mances des systemes d’étiquetage d’entités nommées. Les contenus de ces ressources lexicales
peuvent étre variés : liste de noms propres, de lieux, de marques. On note cependant que la
disponibilité de corpus encyclopédiques exhaustifs et ouverts de grande taille tels que World-
net ou Wikipedia, a fait émerger de nombreuses propositions spéciﬁques d’exploitation de ces
contenus par des systemes d’étiquetage. Un probleme demeure néanmoins ouvert avec ces res-
sources : celui de l’adaptation de leur taxonomie interne, complexe et composée de dizaines
de milliers categories, aux exigences particulieres de l’étiquetage des entités nommées. Pour
ces dernieres, au plus de quelques centaines de classes sémantiques sont requises. Dans cet ar-
ticle nous explorons cette difﬁculté et proposons un systeme complet de transformation d’un
arbre taxonomique encyclopédique en une systeme a classe sémantiques adapté a l’étiquetage
d’entités nommées.

Abstract. The advent of Wikipedia and WordNet aroused new interest in labeling by na-
med entity aided by external resources. The availability of these large, multilingual, comprehen-
sive and open digital encyclopaedic corpora suggests the development of labeling solutions that
exploit the knowledge contained in these corpora. The mapping of a word sequence to an en-
cyclopedic document is possible, however the classiﬁcation of encyclopaedic entities and their
related labels, is not yet fully resolved. The inconsistency of an open encyclopaedic corpus such
as Wikipedia, makes sometimes difﬁcult establishing a relationship between its entities and a
restricted taxonomy. In this article we explore this problem and propose a complete system to
meet this need.

M0tS-CléS I Etiquetage, Entités nommées, classiﬁcation, taxonomie.

Keywords: Named entity recognition, classiﬁcation, taxonomie.

1 Introduction

Les systemes d’étiquetage par entités nommées (EEN) font le plus souvent appel a plusieurs
familles de ressources : des systemes tels que celui de (Brun & Hagege, 2008) sont associés
a des analyseurs syntaxiques robustes. Ils recourent également a des ressources extemes telles
que WordNet (Fellbaum, 1998) ou l’encyclopédie en ligne Wikipedia 1. Ces systemes, qu’ils
exploitent des ressources lexicales extemes, ou de type automate a états ﬁnis (FSM), doivent
régulierement étre conﬁgures pour répondre a un besoin d’extraction précis : la bio-technologie
ou les textes médicaux (Sasaki et al., 2008) par exemple. Si les systemes a base d’automates
peuvent étre rapidement adaptés par une séquence d’apprentissage, le probleme posé par les
contenus lexicaux extemes tels que Wordnet ou Wikipedia est différent. En effet, par nature, les

1. http ://www.wikipedia.org

Eric Charton, J uan-Manuel Torres-Moreno

entités encyclopédiques sont tres nombreuses (plusieurs millions désormais pour Wikipédia) et
constituent des réservoirs d’entités pré-existants sur lesquels doit étre appliquée, pour chaque
besoin, une nouvelle cartographie. Or, les analyses que nous avons conduites sur quatre versions
linguistiques du corpus Wikipédia (anglaise, francaise, allemande et espagnole) font état non
seulement de grandes divergences de classement, mais aussi d’une grande disparité de taille de
classes.

Cette question de l’application d’une cartographie de classes a un lexique d’étiquetage est a
la fois importante et délicate. Délicate car elle fait intervenir deux disciplines du traitement
et de l’analyse de la langue, a savoir la classiﬁcation et l’extraction d’information. Importante
car de la ﬁnesse ou de la souplesse d’une catégorisation d’un corpus de connaissance appliqué
a la détection d’entitées, dépendront les performances ﬁnales du systeme d’extraction et son
adaptabilité a des taches variées.

Cet article propose un systeme capable de générer un lexique issu de Wikipédia, utilisable
pour l’étiquetage d’entités nommées. Ce lexique est constitué par un ensemble de métadonnées,
composées de formes de surface des termes encyclopédiques et de sacs de mots utilisables pour
la désambiguisation.

Nous décrivons dans un premier temps les propositions récentes de dictionnaires et de lexiques
appliqués a la détection d’entités et reposant sur des contenus encyclopédiques. Nous mettons
en perspective ces ressources avec les besoins taxonoIr1iques d’une tache d’étiquetage par en-
tités nommées. Nous utilisons, a titre d’exemple, les besoins rencontrés lors des campagnes
d’évaluation Ace 2, CoNLL3 ou Ester4. Nous présentons ensuite le systeme de classiﬁcation
que nous avons appliqué au corpus Wikipédia pour produire un lexique aisément adaptable aux
besoins de l’étiquetage d’entités nommées, puis nous décrivons les résultats de nos expériences.
Nous avons mesuré la qualité des classes d’étiquetage affectées aux entités encyclopédiques par
notre systeme, puis nous avons déployé un systeme d’étiquetage complet sur des données de la
campagne Ester. Nous présentons pour ﬁnir nos conclusions et perspectives de développement
sur ce projet naissant, et indiquons comment nous mettons a la disposition de la communauté
scientiﬁque notre systeme et les données lexicales qu’il contient.

2 Utilisation de Wikipédia comme lexique d’entités nommées

L’un des premiers systemes proposés pour exploiter un contenu encyclopédique tel que Wiki-
pédia a des ﬁns de désambiguisation d’entités nommées est celui de (Bunescu & Pasca, 2006).
L’ idée est d’extraire de la structure particuliere de Wikipédia (pages de redirection, de synony-
mie, d’entités) des dictionnaires d’entités nommées et d’associer a chaque entité un sac de mots
extrait de sa description encyclopédique. Chaque terme d’un sac de mots est ensuite affecté d’un
poids TF.Idf. Le principe du systeme de détection et de désambiguisation consiste a calculer la
similarite’ cosinus entre le contexte d’un mot a étiqueter et les sacs de mots reliés a des entités
candidates issues de Wikipédia.

La ﬁnalité de ce systeme est d’associer, avec précision, un mot détecté avec son entité ency-
clopédique. Dans cette démonstration, il n’existe pas a proprement parler d’étiquetage selon
les standards d’évaluation. Un noyautaxonoIr1ique reposant sur les catégories de Wikipédia est
entrainé avec des classiﬁeurs du type Machine a Vecteurs de Support (SVM), mais a ﬁn exclu-
sive de restreindre le champ des recherches de similarités entre les mots d’une requéte et une
entité encyclopédique. Il est donc relativement difﬁcile d’appliquer tel quel ce systeme dans un

2. http ://www.nist.govlspeechltestslacel
3. http ://www.cnts.ua.ac.be/conll2003/ner/
4. http ://www.afcp-parole.orglesterl

Classiﬁcation encyclopédique en vue d’un étiquetage par entités nommées

contexte d’extraction d’entités nommées.

Un systeme dérivé de celui de Bunescu et Pasca est présenté dans (Jun’ichi & Kentaro, 2007).
Il adjoint a l’index d’entités extraites, en exploitant les liens internes du corpus Wikipédia, un
ensemble de relations complémentaires entre termes. Dans Wikipédia, une relation entre deux
documents peut étre représentée par un lien reliant une entité et sa description

(ex [[B0bDylan(Sz'nger)|Dylan]]). C’est ce type de lien qui est repris pour étendre le dic-
tionnaire de formes de surface reliées a une entité. Le systeme de détection d’entités nommées
n’est pas directement appliqué a une tache de reconnaissance d’entités. Ce systeme — apres en-
trainement d’un classiﬁeur a base de Champs Conditionnels Aléatoires (CRF) — associe a des
étiquettes du corpus de CoNLL ( PER, LOC, ORG, MISC ) des entités de Wikipédia, mais ne
procede pas directement a un étiquetage des entités.

C’est dans (Wisam & Silviu, 2008) que l’on trouve le systeme le plus proche de la tache d’éti-
quetage. Dans ce travail, qui reprend le systeme de (Bunescu & Pasca, 2006), les pages d’une
version linguistique de Wikipédia sont classiﬁées en utilisant le systeme taxonomique des en-
tités nommées de (Sang & Meulder, 2003). C’est un classiﬁeur SVM qui est déployé pour
attribuer une des cinq étiquettes de classes a des pages d’un corpus linguistique de Wikipédia.

3 Normes taxonomiques des entités nommées

Il n’existe pas a proprement parler de standard taxonomique pour les étiquettes. Néanmoins, on
observe que les propositions de classes retenues pour les systemes d’étiquetage génériques sont
généralement issues d’un tronc commun de déﬁnitions conceptuelles, proposées lors des cam-
pagnes d’évaluation. Dans les systemes anglophones, ce sont les regles de la campagne MUC 5
ACE6 ou CoNLL qui sont mises en oeuvre. Dans le monde francophone, l’unique disponibi-
lité des corpus de la tache d’étiquetage de la campagne Ester7 a fait des regles taxonomiques
proposées par ce groupe un standard de-facto.

De maniere générale, on peut observer que les principales entités nommées recherchées sont
regroupées dans des classes racines de type organisationnelles (ORG), individuelles (PERS),
géographiques (LOC), des descriptions de produits ou d’objets, et plus généralement de toute
conception humaine (PROD). A ces déﬁnitions d’entités sont parfois adjointes des propriétés
(les titres ou fonctions), des entités temporelles telles que les dates (DATE), les horaires (TIME),
ou des entités numériques (AMOUNT) telles que les poids ou les mesures.

La granularité des classes se développe régulierement. Les classes racines sont afﬁnées dans
les récentes campagnes d’évaluations (ACE 2007 et Ester 2) par des sous-classes ﬁlles plus
précises : ORG.COM ou ORG.NON-PROFIT, etc.

3.1 Autres besoins taxonomiques exprimés

Ces grandes familles de classes sont inadaptées pour répondre a certains besoins émergents ou
particuliers : c’est le cas par exemple des classes d’étiquetage pour des entités de types bio-
logiques ou chimiques (application a la recherche médicale (Kulick et al., 2004)). On note
aussi la nécessité d’étiquetages particuliers pour répondre a des taches de type Question et
Réponse (Turmo et al., 2007). Par ailleurs, de nouvelles taches d’eXtraction d’information ou-
vertes au cours des deux dernieres années peuvent imposer l’usage d’un étiquetage adapté a
une thématique particuliere : c’est le cas pour la construction automatique d’ontologies sur des

5. http ://www.itl.nist.gov/iaui/894.02/related_projectslmucl
6. http ://nist.gov/speech/tests/ace/2008/doc/ace08—evalplan.v1.2d.pdf
7. http ://www.afcp—parole.org/ester/docs/Conventions_EN_ESTER2_v01.pdf

Eric Charton, J uan-Manuel Torres-Moreno

individus d’apres des corpus de pages web ou de textes, telle que proposee lors de campagnes
Web People Search (Artiles et al. , 2007) en 2008 et pour une tache specialisee, heritant de ACE,
intitulee Knowledge Base Population, entamee par le Nist en 20098. Dans ces experiences,
les extractions d’information demandees peuvent amener a rechercher des entites particulieres
telles que les titres, les diplomes, les adresses postales, etc.

3.2 Spéciﬁcités de la taxonomie appliquée au corpus Wikipédia

Les versions recentes de Wikipedia contiennent de nombreuses entites nommees. Mais pour

exploiter cette connaissance, il est important de la cartographier en l’adaptant a des exigences

taxonomiques qui varient selon le cadre applicatif. Les particularites taxonomiques d’une cam-
pagne d’evaluation par exemple. Or, l’application a Wikipedia d’une cartographie de classes
adaptees a l’EEN est une tache qui se heurte a plusieurs difﬁcultes :

— 11 a ete souligne lors de precedentes campagnes d’evaluation, et notamment lors du Deﬁ
Fouille de textes 2008 (Hurault-Plantet et al., 2008) qui consistait a segmenter un corpus
contenant notamment des ﬁches Wikipedia, qu’il est difﬁcile de depasser avec les meilleures
methodes (numeriques) une precision de classiﬁcation superieure a 90%, meme avec un
nombre de classes restreint. Cette precision est insufﬁsante puisqu’elle implique qu’une tache
d’EEN reposant sur les entites derivees de Wikipedia pourrait produire 10% d’erreurs.

— La mise au point d’un classiﬁeur non equiprobable (i. e. modelisant a la fois des classes de
tres grande taille et d’autres de petite taille sur un meme corpus) est particulierement delicate,
et donc peu adaptee a la modelisation de certaines classes peu representees dans Wikipedia
et pourtant recherchees en EEN (c’est le cas des fonctions et des diplomes par exemple).

— La reutilisation de la taxonomie interne de Wikipedia pour en deriver un nouveau systeme
de classes adaptees a l’EEN, comme cela a ete recemment propose par (Suchanek et al.,
2007) pour le domaine ontologique, est delicate dans le cas de l’EEN car elle implique la
transformation d’un graphe de classes volumineux, granulaire et dont les noeuds sont tres
imbriques, en un arbre taxonomique compact et precis.

On peut donc resumer la difﬁculte de cette tache par son exigence de reduction de classes d’un

facteur consequent : au maximum quelques centaines de classes sont exigees en EEN. Or, nos

mesures statistiques9 indiquent que la version francaise1° de Wikipedia contient 100.731 ca-
tegories et la version anglaise, 256.000. Par ailleurs la distribution de ces categories peut etre
representee par une loi de Zipf-Mandelbrot : dans la version francaise, la classe la mieux re-
presentee est celle des dates de naissances (regroupant 144.000 entites de types personnes, soit

7,68% du corpus), suivie des deces (69.970 entites soit 3,7% du corpus). A la suite de ces

classes volumineuses, on trouve des milliers de categories qui caracterisent moins de 0,1% du

corpus. Or ces Inicro-classes sont parfois exigees en EEN. C’est le cas des fonctions militaires
par exemple ( FONC.MIL de la campagne ESTER 2), representees par 151 entites dans Wiki-
pedia 11, ventilees sur trois classes.

On ajoutera qu’a cette difﬁculte de transformation du graphe de categories de Wikipedia en

arbre taxonomique adapte a l’EEN, s’ajoute celle de la selection des entites pertinentes pour

l’EEN. Wikipedia integre en effet 140.000 descriptions encyclopediques inutiles pour les taches
d’EEN (des noms communs par exemple — ﬁche Voiture ou Dirigeable) qui sont elles aussi
referencees par le systeme taxonomique de l’encyclopedie, et parfois melangees avec des entites

8. Voir http ://ap1.jhu.edu/ paulmac/kbp/090220—KBPTaskGuide1ines.pdf
9. Voir notammentwww.n1gbase.org, et www.n1gbase.org/fr/stat.htm1
10. Version du dump XML
11. Voir www.n1gbase.org/fr/stat/stat_c1ust.htm1

Classiﬁcation encyclopédique en vue d’un étiquetage par entités nommées

Vlnztolr Hugo "'

.F't'.wIr.Ia5 amblas F1:un9ny,'ne5_. wan"! H.-gs er Warm I‘-Lugs |'PJomon_yJru'e,'. V‘

Victor-llarie Hugo. Illé Ile 25 ‘l=_".'rIer ‘I5-IIZ é E\a5anI>or.. IIMN1 Ila 22 mil 1535 $1 Paris.

at mm =_'I::ri'.'airI. dramaturga. poéta. hnmma politlzqua. anamérrician at intallacn.-2|
engagaé frangais nnnsidlélé comma le Ipl|iSIllMﬂM1&ll dla écriwains romantlauas de

langua Iranpaise at um Ella Ipllws Iimportams é::ri'.'ain5 the Ila littératue iranpaisa.

Sour oewwe est his diveuse : rornarss. paésia lgrrlzaha. «dramas an vars at am prose.
dliswuns politiz.-4.25 é Ila Chambra :12; Pairs. Dorresponzﬂanca a‘lwxndIam2e.

III a mnmwllawé. mm wmme Bautialaire. aw rrenoumzlllenmem de la poﬁuie at de la
Iliﬂ7éfa‘llIllE.

9mIImaIIe[nLaa:mar]

 

1.3 L‘exII
I 4 Le IIE‘}'J..I E‘! FI312 E‘: Ia man

 

:32
Basrxn
D9095 22 'Y|a| 1555
Dan;

IV-mnramam[sg R-:~|a*'.Is"va

 

FIGURE 1 — La ﬁche de Wctor Hugo dans Wikipédia contient un texte descriptif et une boite
d’information (sur la droite). Dans le cas de cette ﬁche, la boite d’information est celle des
écrivains.

Ban ample I ‘-"::tar I-.u;:n I Besanean I Personnallté nu slécla I Et:rI'.‘aIn Irar._pa _u XIX: 5|-écla I Ecm-aln rarraantlqual Faéta

X= 5ié1:l= I Pnéta rnmantlmj Irarpais I DramatMg= ‘I xngais -nu Ilia siécla I C)pp:n=ar:t an Secanz Errvpira I Pnillalléna I Persnnna

.é:nn Paris I lﬁambre -:2 lléwzlérria ‘rang’:-is Naissanne an ‘B32 I Naissarlﬁ § Easancor I Bénés er 1SS5| Dénésé
jar-5 la DDLIJSI [+]I

   

  
 

FIGURE 2 — Les catégories associées a la ﬁche Wctor Hugo de Wikipédia.

elles-mémes pertinentes 12. Ces entités non désirées doivent étre isolées pour ne pas introduire
de bruit dans la tache de détection. Elles sont référencées dans notre systeme par le label UNK.

4 Approches de classiﬁcation adaptées a Wikipédia

Nous avons développé un ensemble d’algorithmes de classiﬁcation permettant d’eXtraire et de
structurer les contenus encyclopédiques, mais aussi de transformer la classiﬁcation interne tres
complexe et ouverte de Wikipédia.

Considérons, pour la mise au point de notre systeme, une entité encyclopédique et ses éléments

constitutifs :

— Elle contient un texte qui peut étre analysé par un classiﬁeur numérique (voir ﬁgure 1).

— Des "Cate’g0ries" lui sont attribuées, faisant partie d’un graphe qui peut étre exploré et par-
tiellement décrit par un arbre taxonomique (voir ﬁgure 2).

— Elle contient des boites d’information nommées "Inf0b0x" qui décrivent des propriétés stan-
dardisées de l’objet décrit par l’entité encyclopédique. Par exemple, pour un écrivain, sa date
de naissance, son lieu de naissance, etc. (voir ﬁgure 1)

Notre idée est de tirer parti de l’existence de ces trois éléments susceptibles de participer d’une

classiﬁcation. Dans un tel cadre applicatif, nous nous trouvons face a des ensembles ayant des

intersections plus ou moins larges, suivant des regles a ﬁnalités divergentes. Notre systeme
fonctionne en deux phases que nous intitulerons Wkl et W192 :

12. Voir par exemple la classe Catégorie :Um'versite’ de la Version frangaise de Wikipédia qui inclut aussi bien
des établissements que des personnes ou des concepts

Eric Charton, J uan-Manuel Torres-Moreno

Phase Wkl : premiére classiﬁcation

La premiére phase permet de créer une classiﬁcation générale, du niveau de l’état de l’art pour
ce qui est de la classe racine (par exemple la classe descriptive des Organisation, ORG), et moins
exhaustive et précise pour ce qui est du second niveau d’étiquetage de l’arbre taxonomique
(ORG.DIV ou LOC.GEO). La phase Wkl se déroule ainsi :

— Une étape de classiﬁcation numérique est appliquée pour inventorier les contenus affectés
aux classes racines (par exemple ORG, PERS, LOC ou PROD)

— Une étape de classiﬁcation est menée a partir de regles établies d’apres des catégories sélec-
tionnées au sein de la taxonomie de Wikipédia, pour le second niveau de classe (par exemple
ORG.DIV, LOC.ADMI ou PERS.HUM ).

— Une étape de classiﬁcation est conduite a partir de regles établies d’apres des catégories pour
les micro-classes (tel que les titres nobiliaires ou les fonctions).

A l’issue de cette premiere phase, nous obtenons une premiere classiﬁcation qui décrit le second

niveau taxonomique tres partiellement. Par exemple 85% a 89% des lieux sont correctement

étiquetés LOC, mais moins de la moitié des éléments de sous classes LOC.GEO ou LOC.ADMIN
est détectée. Il faut donc afﬁner le processus.

Phase W,,2 : perfectionnement de la classiﬁcation

Nous utilisons les informations déja disponibles pour procéder a un nouvel apprentissage suivi

d’une nouvelle phase de classiﬁcation, la phase W,,2 :

— L’ apprentissage consiste a inventorier la classe attribuée lors de la phase précédente pour
chaque document Wikipédia contenant une Infobox.

— Cette information étant disponible, la probabilité qu’une classe d’étiquetage soit associée a
une Infobox est évaluée. Puis des regles d’association entre Infobox et classes sont élaborées
(par exemple Infobox Communes de France sera associée a LOC.ADMI).

— Le corpus Wikipédia est reclassé en utilisant en tant que regles d’attribution de classe la
présence d’une Infobox

La seconde phase de détection W;,2 s’applique a la totalité des pages contenant une Inf0b0x13.

A l’issue de cette phase les classes associées aux Infobox sont ﬁables a 99%. Apres cette phase,

nous obtenons un gain de qualité ﬁnale de la classiﬁcation — par rapport a Wkl — de l’ordre de

8% a 15% (voir tableau 1).

4.1 Classiﬁcation numérique

Le systeme numérique utilisé pour Wkl est une fusion ternaire des résultats produits par un
classiﬁeur SVM, un classiﬁeur bayésien na'1'f et AdaBoost, tel que présenté dans (Charton et al.,
2008). Les classes de détection sont construites apres application de pré-traitements au corpus
d’apprentissage : linéarisation des classes par comparaison des distributions de Zipf, utilisation
de trigrammes et application d’un anti-dictionnaire.

La fusion par vote majoritaire que nous avons déployée est triviale. Elle consiste a confronter
les propositions des trois meilleurs classiﬁeurs (SVMLib, Na'1've Bayes, Icsiboost) pour chaque
document. Si une majorité l’emporte (2/3 ou 3/3), la classe majoritaire est choisie, dans le cas
contraire, la stratégie de fusion se replie sur le systeme le plus performant (le classiﬁeur SVM
avec noyau linéaire).

13. Mesure réalisée sur le dump XML Wikipédia référencé frwiki—20081201—pages—artic1es.xm1 disponible sur
down1oad.wikipedia.org

Classiﬁcation encyclopedique en vue d’un etiquetage par entites nommees

Ce systeme n’est efﬁcace que sur des classes de poids equivalents et n’est donc deploye que sur
les classes PERS, PROD, ORG, LOC et UNK. Les classes FONC et DATE (representant moins
de 1% du corpus) ne sont pas modelisables avec ce systeme de classiﬁcation, tout comme les
sous-classes.

4.2 Classiﬁcation d’apres des Infobox

Pour executer la phase W,,2 nous utilisons les Infobox de Wikipedia aﬁn d’introduire un second
niveau de classement des entites encyclopediques.

Soient un ensemble D de documents issus de Wikipedia, un ensemble 0 de categories de Wiki-
pedia et un ensemble I d’Inf0b0x de Wikipedia. Denommons etiquette de second niveau (ES N)
la sous-classe d’une classe racine.

Considerons un ensemble de documents E E D appartenant a une categorie c E 0, un ensemble
de documents F E D munis d’une Infoboxi E I, et un ensemble de documents G E D etiquetes
par un label l qui est une ESN.

SoitU=EﬂFﬂG.

Tous les elements de U ont en commun la categorie c, l’Inf0b0xz' et le label d’ESN l. On peut
donc en deduire une association directe entre l’Inf0b0xi et le label d’ ES N l pour les documents
de U.

Ceci nous permet d’elaborer automatiquement, en partant d’un petit groupe de categories re-
presentatives de chaque ES N , la table des associations entre les Infobox et les etiquettes ES N .
Nous utilisons cette table d’associations pour reclasser toutes les entites de Wikipedia en detec-
tant la presence eventuelle d’une Infobox dans le document qui les decrit et en lui attribuant le
label d’ ES N qui lui est associee.

4.3 Classiﬁcation d’apres des categories

Un residu de documents du corpus Wikipedia ne peut etre classe par les deux methodes prece-
dentes : soit leur contenu trop faiblement informatif pour ce qui est de la classiﬁcation nume-
rique, soit ils ne contiennent pas d’Inf0b0x. Pour ces documents, nous prevoyons dans la phase
W;,2 une derniere etape qui consiste a associer une etiquette a une categorie de Wikipedia. Cette
methode peut etre tres performante si une classe est fortement representative, mais tres coﬁteuse
lorsque les categories sont mal deﬁnies ou tres granulaires.

On notera, par exemple, que plus de 144.000 entites encyclopediques sont associees a la cate-
gorie Naissance en : ce type de categorie utilise comme regle de detection augmente considera-
blement la precision de la classe PERS.HUM. En revanche, la categorie Locution ou expression
latine qui devrait categoriser des entites de type UNK est de faible utilite avec les 124 ele-
ments encyclopediques qu’elle contient 14. Les regles categorielles, du fait de leur variabilite,
ne peuvent donc etre employees que pour afﬁner ou renforcer l’etiquetage des entites ou pour
traiter des micro-classes non modelisables par methodes numeriques.

5 Experiences et résultats

Pour evaluer l’interet de notre dictionnaire d’entites nous avons procede a un ensemble d’eXpe-
riences et de mesures. Le standard retenu pour nos experiences est celui etabli par la campagne
Ester 2 pour ce qui est de la taxonomie des entites nommees et de la veriﬁcation de couverture
du dictionnaire. Seules les entites racines et de second niveau des familles PERS, ORG, LOC,

14. Voir les analyses de categories sur www.nlgbase.org/fr/stat/stat_cat.ht1n1

Eric Charton, J uan-Manuel Torres-Moreno

PROD et FONC ont été retenues pour ces expériences. Les étiquettes de type AMOUNT, TIME,
ne sont pas concernées par le dictionnaire extrait de Wikipédia et ne sont donc pas mesurées ici.
Les étiquettes de type DATE qui sont présentes en tant que descriptifs de dates historiques dans
Wikipédia, sont mesurées a titre indicatif mais ne sont pas exploitées dans le cadre applicatif de
la détection.

Nous avons tout d’abord évalué la qualité de la classiﬁcation des entités de Wikipédia obtenues
avec les algorithmes Wkl et W,,2 en mesurant la précision et le rappel d’apres un échantillon
de référence. Nous avons ensuite introduit le dictionnaire produit d’apres Wikipédia dans un
systeme d’étiquetage inspiré de la proposition de (Bunescu & Pasca, 2006) et évalué ses perfor-
mances sur une partie des transcriptions étiquetées de la campagne ESTER 2.

5.1 Mesure de la classiﬁcation

Les résultats de l’attribution de classes d’étiquetages aux entités nommées représentées par les
entités encyclopédiques de Wikipédia sont présentés dans le tableau 1. Les données de référence
utilisées pour mesurer la précision et le rappel sont fournies par un corpus de 5.500 entités
extraites aléatoirement dans Wikipédia; 4.800 entités de référence sont étiquetées de maniere
semi-automatique et corrigées a la main; 700 entités de référence sont entierement étiquetées a
la main.

Classes Wkl Classiﬁcation numérique W192 : Classiﬁcation complete

(P) (T) (F-S) (15) (T) (F-S)
Pers 0,92 0,91 0,92 0,95 0,97 0,96
Org 0,74 0,83 0,79 0,82 0,89 0,87
Loc 0,85 0,89 0,87 0,93 0,96 0,95
Prod 0,80 0,94 0,86 0,90 0,95 0,93
Unk 0,95 0,78 0,85 0,96 0,92 0,94

Date - - - 1 1 1
Fonc - - - 1 1 1
Total 0,86 0,95

TABLE 1 — Precision (p), Rappel (f), F-Score (E-s) obtenus sur le jeu detest

Ce tableau est divisé en deux sections : la premiere présente le F-Score15 obtenu pour chaque
classe par la classiﬁcation numérique de l’algorithme Wkl ; la seconde met en évidence l’amé-
lioration obtenue apres utilisation des modes de détection de classes complémentaires offerts
par les classiﬁeurs de l’algorithme W;,2. Les scores détaillés des sous-classes introduites dans
l’algorithme W;,2 ne sont pas présentés ici16. En effet, seules les classes racines sont classiﬁées
a la fois par Wkl et W,,2 ce qui permet une comparaison des résultats obtenus (les sous-classes
n’étant classiﬁées que par W,,2).

A l’eXception de la classe ORG qui pose des problemes de modélisation spéciﬁques 17, la pré-
cision et le rappel obtenus sur des entités classées semblent sufﬁsamment élevés (de l’ordre de
95% de précision) pour envisager une utilisation dans une tache d’EEN.

15. Mesure harmonique combinant la précision et le rappel.

16. Voir le détajl des sous classes sur wwwnlgbase.org/fr/stat/stat_clust.ht1n1

17. La classe ORG prévue par la campagne ESTER 2 fait cohabiter des partis politiques, des organisations com-
merciales, des entités géopolitiques et des émissions de divertissements. Ces entités sont sufﬁsamment différentes
pour rendre délicate la mise au point de leur classe de détection

Classiﬁcation encyclopedique en vue d’un etiquetage par entites nommees

5.2 Mesure de l’étiquetage

L’etiquetage est realise sur les transcriptions pre-etiquetees et manuellement corrigees de la
campagne Ester 2. Nous avons selectionne un ensemble de trois transcriptions representatives
de ce corpus 18 et mesure le Slot Error Rate (SER)19. Le SER est mesure en distinguant trois
types d’erreurs : In les insertions, qui sont des entites detectees n’ayant aucun mot commun
avec une entite de reference, De les suppressions ou entites manquees par le systeme, et Sn les
entites substituees, c’est a dire correspondant de maniere incorrecte a des entites de reference.
Cette derniere mesure est particulierement interessante dans notre cadre applicatif puisqu’elle
correspond aux erreurs de classiﬁcation des entites. En notant R l’ensemble des entites de refe-
rence on obtient la formule de calcul de SER comme suit : SER = (In + De + Sn) / R.

Entites R In De Su S ER
ORG 240 23 5 10 0,15
PERS 1071 15 60 6 0,07
LOC 190 19 6 2 0,14
PROD 1 10 21 0 2 0,20
FONC 26 10 0 7 0,65
Total 1637 88 71 27 0,12

Ces transcriptions representent 35.000 mots et 1.637 entites a etiqueter. Nous ne mesurons pas
dans cette experience les performances de detection sur les classes d’EN temporelles (DATE,
AMOUNT). On observe dans ces resultats un bon niveau de performance sur les entites de type
PERS (S ER < 7%) qui sont par ailleurs particulierement bien retrouvees et etiquetees par notre
systeme (F-Score de 0,96) dans le corpus Wikipedia.

L’ etiquette de fonction FONC cree des difﬁcultes particulieres : cette classe est difﬁcile a construire
d’apres les informations trop fragmentaires extraites depuis Wikipedia et la detection de ses
entites par des systemes a base de regles ou d’automates semble plus appropriee pour son eti-
quetage. On doit probablement voir dans cette particularite que le contexte d’une entite de type
attribut (comme une fonction) est moins bien mesure par similarite cosinus avec l’algorithme
de (Bunescu & Pasca, 2006) que celui d’une entite de type nom propre.

6 Conclusion

Nous avons presente un systeme capable de produire, d’apres un corpus encyclopedique tel
que Wikipedia, un dictionnaire d’entites nommees etiquetees, pretes a l’emploi dans une tache
d’EEN et utilisant des mesures de siIr1ilarite pour desambigiiiser des entites en contexte. Les
performances obtenues nous permettent d’envisager que ce type de ressources puisse faire pro-
gresser signiﬁcativement les applications d’EEN.

Le corpus d’entites classees que nous proposons est disponible en telechargement 2°. Avec cette
mise a disposition nous esperons que notre contribution permettra a des chercheurs desireux de
developper leur propre systeme d’etiquetage, de gagner du temps.

En l’etat notre corpus d’entites classees permet d’extraire facilement des sous-lexiques specia-
lises de noms propres, de noms de personnes ou de lieux. A terme, nous envisageons de faire
evoluer nos algorithmes vers un systeme d’etiquetage et d’extraction d’information applicable
dans des campagnes tels que Weps ou KBP.

18. L’ experience est reproductible sur www.n1gbase.org/perl/nlgetiq.pl
19. J. Makhoul, F. Kubala, R. Schwartz, and R. Weischedel, Performance measures for information extraction,
in Proceedings of DARPA Broadcast News Workshop, February 1999
20. Consulter www.n1gbase.org

Eric Charton, J uan-Manuel Torres-Moreno

Références

ARTILES J ., GONZALO J . & SEKINE S. (2007). The semeval-2007 weps evaluation : Establi-
shing a benchmark for the web people search task. In Proceedings of the Fourth International
Workshop on Semantic Evaluations (SemEval-2007), p. 64-69, Prague, Czech Republic : As-
sociation for Computational Linguistics.

BRUN C. & HAGEGE C. (2008). Vériﬁcation sémantique pour l’annotation d’entités nom-
mées. In TALN08, Actes de la confe’rence TALN-RECITAL 08, 2008, Avignon.

BUNESCU R. & PASCA M. (2006). Exploiting wikipedia as external knowledge for named
entity recognition. In ACLWEB Antology 2006.

CHARTON E., CAMELIN N., ACUNA-AGOST R., GOTAB P., LAVALLEY R., KESSLER R. &
FERNANDEZ S. (2008). Prétraitements classiques ou par analyse distributionnelle : application
aux méthodes de classiﬁcation automatique déployées pour deft08. In Atelier DEF T’08, Actes
de la conférence TALN-RECITAL 08, 2008, Avignon, p. 101-110.

C. FELLBAUM, Ed. (1998). WordNet An Electronic Lexical Database. Cambridge, MA;
London : The MIT Press.

HURAULT-PLANTET M., BERTHELIN J .—B., AYARI S. E., GROUIN C., LOISEAU S. & PA-
ROUBEK P. (2008). Résultats de l’édition 2008 du deﬁ fouille de textes. In Actes de l ’atelier
DEF T’08, TALN08 Avignon : limsi.fr.

J UN’ICHI K. & KENTARO T. (2007). Exploiting wikipedia as external knowledge for named
entity recognition. In Joint Conference on Empirical Methods in Natural Language Processing
and Computational Natural Language Learning, p. 698-707.

KULICK S., BIES A., LIBERMAN M., MANDEL M., MCDONALD R., PALMER M., SCHEIN
A. & UNGAR L. (2004). Integrated annotation for biomedical information extraction. In
HLT/NAACL 2004 Workshop .' Biolink 2004, pp. 61-68.

SANG E. T. K. & MEULDER F. D. (2003). Introduction to the conll-2003 shared task :
Language-independent named entity recognition. In Proceedings of CoNLL-2003, Edmonton,
Canada, 2003, pp. 142-147.

SASAKI Y., TSURUOKA Y., MCNAUGHT J . & ANANIADOU S. (2008). How to make the
most of ne dictionaries in statistical ner. BMC bioinformatics, 9 Suppl 11.

SUCHANEK F. M., KASNECI G. & WEIKUM G. (2007). Yago, a core of semantic knowledge.
In Proceedings of WW 2007.

TURMO D., COMAS P., AYACHE C., MOSTEFA D., ROSSET S. & LAMEL L. (2007). Over-
view of qast 2007. In Working Notes for the CLEF 2007 Workshop, Budapest, Hungary,
September 2007.

WISAM D. & SILVIU C. (2008). Augmenting wikipedia with named entity tags. In ACL
Proceedings of the Third International Joint Conference on Natural Language Processing.

