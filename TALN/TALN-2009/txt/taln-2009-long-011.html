<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Int&#233;gration de l&#8217;alignement de mots dans le concordancier bilingue TransSearch</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009, Senlis, 24&#8211;26 juin 2009
</p>
<p>Int&#233;gration de l&#8217;alignement de mots dans
le concordancier bilingue TransSearch
</p>
<p>St&#233;phane Huet Julien Bourdaillet Philippe Langlais
DIRO - Universit&#233; de Montr&#233;al
C.P. 6128, succursale centre-ville
</p>
<p>H3C 3J7, Montr&#233;al, Qu&#233;bec, Canada
{huetstep,bourdaij,felipe}@iro.umontreal.ca
</p>
<p>R&#233;sum&#233;. Malgr&#233; les nombreuses &#233;tudes visant &#224; am&#233;liorer la traduction automatique, la
traduction assist&#233;e par ordinateur reste la solution pr&#233;f&#233;r&#233;e des traducteurs lorsqu&#8217;une sortie de
qualit&#233; est recherch&#233;e. Dans cet article, nous pr&#233;sentons nos travaux men&#233;s dans le but d&#8217;am&#233;-
liorer le concordancier bilingue TransSearch. Ce service, accessible sur le Web, repose
principalement sur un alignement au niveau des phrases. Dans cette &#233;tude, nous discutons et
&#233;valuons l&#8217;int&#233;gration d&#8217;un alignement statistique au niveau des mots. Nous pr&#233;sentons deux
nouvelles probl&#233;matiques essentielles au succ&#232;s de notre nouveau prototype : la d&#233;tection des
traductions erron&#233;es et le regroupement des variantes de traduction similaires.
</p>
<p>Abstract. Despite the impressive amount of recent studies devoted to improving the state
of the art of machine translation, computer assisted translation tools remain the preferred solu-
tion of human translators when publication quality is of concern. In this paper, we present our
ongoing efforts conducted within a project which aims at improving the commercial bilingual
concordancer TransSearch. The core technology of this Web-based service mainly relies
on sentence-level alignment. In this study, we discuss and evaluate the embedding of statistical
word-level alignment. Two novel issues that are essential to the success of our new prototype
are tackled: detecting erroneous translations and grouping together similar translations.
</p>
<p>Mots-cl&#233;s : alignement au niveau des mots, concordancier bilingue, traduction automa-
tique.
</p>
<p>Keywords: word-level alignment, bilingual concordancer, machine translation.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>St&#233;phane Huet, Julien Bourdaillet, Philippe Langlais
</p>
<p>1 Introduction
</p>
<p>Bien qu&#8217;un effort soutenu ait &#233;t&#233; consacr&#233; cette derni&#232;re d&#233;cennie &#224; l&#8217;am&#233;lioration des syst&#232;mes
de traduction automatique, les traducteurs professionnels pr&#233;f&#232;rent encore aujourd&#8217;hui se tour-
ner vers les outils de la traduction assist&#233;e par ordinateur (TAO), parmi lesquels figurent les
syst&#232;mes &#224; m&#233;moire de traduction (MT) et les concordanciers bilingues. Ces deux types de sys-
t&#232;mes exploitent une m&#233;moire de traduction constitu&#233;e d&#8217;un bitexte, i.e. un ensemble de paires
d&#8217;unit&#233;s (typiquement des phrases) qui sont la traduction l&#8217;une de l&#8217;autre. Alors qu&#8217;un syst&#232;me
&#224; MT est un dispositif de traduction (Planas &amp; Furuse, 1999), un concordancier bilingue est
conceptuellement plus simple puisque son objectif principal est de trouver au sein d&#8217;un bitexte
les paires d&#8217;unit&#233;s qui contiennent une requ&#234;te (en g&#233;n&#233;ral une s&#233;quence de mots) soumise par
un utilisateur. C&#8217;est ensuite &#224; l&#8217;utilisateur de localiser lui-m&#234;me les parties int&#233;ressantes dans
les r&#233;ponses obtenues. Bien que ce type de syst&#232;me paraisse tr&#232;s simple, les concordanciers
bilingues restent un outil tr&#232;s populaire en TAO. Macklovitch et al. (2008), indiquent ainsi que
TransSearch1, le concordancier commercial mis en ligne sur le Web et faisant l&#8217;objet de cet
article, a re&#231;u en moyenne 177 000 requ&#234;tes par mois sur une p&#233;riode d&#8217;un an (2006&#8211;2007).
</p>
<p>La figure 1(a) pr&#233;sente une capture d&#8217;&#233;cran du concordancier TransSearch dans sa version
actuelle. Dans cet exemple, suite &#224; la requ&#234;te in keeping with soumise par un utilisateur,
le syst&#232;me retourne une page contenant les 25 premi&#232;res paires de phrases de la m&#233;moire de
traduction qui contiennent une occurrence de la requ&#234;te. Comme on peut le constater, rien n&#8217;est
mis en valeur dans les phrases cibles retourn&#233;es, ce qui contraint l&#8217;utilisateur &#224; rechercher la
traduction &#224; l&#8217;int&#233;rieur de chaque phrase cible propos&#233;e.
</p>
<p>(a) Version actuelle. (b) Version en d&#233;veloppement.
</p>
<p>FIG. 1 &#8211; R&#233;sultats affich&#233;s par TransSearch pour la requ&#234;te in keeping with.
</p>
<p>L&#8217;objectif du projet TS3 est d&#8217;identifier automatiquement dans les phrases retourn&#233;es les dif-
f&#233;rentes traductions d&#8217;une requ&#234;te utilisateur. Bien que l&#8217;aspect du nouveau prototype ne soit
pas encore d&#233;finitif, la figure 1(b) montre une interface o&#249; l&#8217;utilisateur peut consulter les traduc-
tions automatiquement identifi&#233;es et consid&#233;r&#233;es comme les plus pertinentes. S&#8217;il reste toujours
possible de consulter les paires de phrases contenant la requ&#234;te, l&#8217;utilisateur peut dor&#233;navant
cliquer sur une traduction donn&#233;e et visualiser son contexte d&#8217;emploi.
</p>
<p>1http://www.tsrali.com</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Int&#233;gration de l&#8217;alignement de mots dans le concordancier bilingue TransSearch
</p>
<p>Dans la suite, nous pr&#233;sentons tout d&#8217;abord la technique mise en &#339;uvre pour rep&#233;rer les tra-
ductions au sein des phrases. Nous d&#233;crivons ensuite deux nouveaux probl&#232;mes importants que
nous avons rencontr&#233;s: l&#8217;identification des alignements erron&#233;s (section 3) et le regroupement
de variantes de traduction (section 4). Nous d&#233;crivons les donn&#233;es utilis&#233;es en section 5 et pr&#233;-
sentons nos r&#233;sultats exp&#233;rimentaux en section 6.
</p>
<p>2 Rep&#233;rage de traduction
</p>
<p>Le rep&#233;rage de traduction ou transpotting (diminutif de translation spotting), une partie es-
sentielle du projet TS3, consiste &#224; identifier dans du texte cible la traduction d&#8217;une requ&#234;te en
langue source (V&#233;ronis &amp; Langlais, 2000). Nous appelons transpot l&#8217;ensemble des mots cibles
automatiquement associ&#233;s &#224; une requ&#234;te dans une paire de phrases. Dans l&#8217;exemple de la fi-
gure 1(b), conform&#233;ment &#224; et va dans le sens de sont deux des six transpots pr&#233;sent&#233;s
&#224; l&#8217;utilisateur pour la requ&#234;te in keeping with.
</p>
<p>2.1 Algorithme de transpotting
</p>
<p>Le transpotting peut &#234;tre vu comme un sous-probl&#232;me de l&#8217;alignement au niveau des mots,
comme sugg&#233;r&#233; dans (Simard, 2003). La traduction statistique est encore fortement bas&#233;e sur
des mod&#232;les d&#8217;alignement de mots (Brown et al., 1993) que nous utilisons dans cette &#233;tude.
</p>
<p>Formellement, &#224; partir d&#8217;une phrase S = s1...sn exprim&#233;e dans une langue dite source et de sa
traduction T = t1...tm, un alignement a = a1...am de type IBM revient &#224; connecter chaque mot
de T &#224; un mot de S (aj &#8712; {1, ..., n}) ou au mot vide (aj = 0), ce dernier rendant compte des
mots cibles non traduits. Plusieurs mod&#232;les propos&#233;s par Brown et al. (1993) d&#233;composent la
probabilit&#233; conjointe d&#8217;une phrase cible et de son alignement, &#233;tant donn&#233;e la phrase source.
Pour des raisons calculatoires, nous nous concentrons dans cette &#233;tude sur la forme la plus
simple, correspondant aux mod&#232;les IBM 1 et 2 :
</p>
<p>p(tm1 , a
m
1 |sn1 ) =
</p>
<p>m&#8719;
j=1
</p>
<p>&#8721;
i&#8712;[0,n]
</p>
<p>p(tj|si)&#215; p(i|j,m, n)
</p>
<p>o&#249; le premier terme de la somme est la probabilit&#233; de transfert et le second la probabilit&#233; d&#8217;ali-
gnement. Avec cette d&#233;composition, il est facile et efficace de calculer l&#8217;alignement le plus
probable entre deux phrases, argmaxam1 p(a
</p>
<p>m
1 |tm1 , sn1 ), ce que nous appelons l&#8217;alignement de Vi-
</p>
<p>terbi par la suite. Toutefois, cette approche produit souvent des alignments discontinus, alors
que ce type d&#8217;alignement n&#8217;est g&#233;n&#233;ralement pas n&#233;cessaire pour retrouver les bons transpots.
</p>
<p>Afin de produire des transpots contigus, nous avons impl&#233;ment&#233; un algorithme de transpotting
propos&#233; initialement par Simard (2003). Pour chaque paire &#12296;j1, j2&#12297; &#8712; [1,m] &#215; [1,m], nous
calculons deux alignements de Viterbi : l&#8217;un entre la suite de mots tj2j1 et la requ&#234;te s
</p>
<p>i2
i1
, et l&#8217;autre
</p>
<p>entre les mots restants des phrases source et cible s&#772;i2i1 &#8801; si1&#8722;11 sni2+1 et t&#772;j2j1 &#8801; tj1&#8722;11 tmj2+1. Nous
calculons alors :
</p>
<p>t&#770;j&#770;2
j&#770;1
= argmax
</p>
<p>(j1,j2)
</p>
<p>{
max
a
j2
j1
</p>
<p>p(aj2j1|si2i1 , tj2j1)&#215;max
a&#772;
j2
j1
</p>
<p>p(a&#772;j2j1|s&#772;i2i1 , t&#772;j2j1)
}</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>St&#233;phane Huet, Julien Bourdaillet, Philippe Langlais
</p>
<p>Cette m&#233;thode, ayant une complexit&#233; en O(nm3), s&#8217;est av&#233;r&#233;e la plus performante de celles que
nous avons test&#233;es (Bourdaillet et al., 2009).
</p>
<p>2.2 Int&#233;r&#234;t du post-traitement
</p>
<p>Avec la d&#233;marche pr&#233;c&#233;demment d&#233;crite, les requ&#234;tes fr&#233;quentes dans la m&#233;moire re&#231;oivent un
grand nombre de traductions. La figure 2 illustre ce ph&#233;nom&#232;ne en montrant 12 des nombreuses
s&#233;quences de mots retourn&#233;es par l&#8217;algorithme de transpotting pour la requ&#234;te in keeping
with. Dans cet exemple, certains transpots annot&#233;s d&#8217;une &#233;toile sont clairement mauvais (e.g.
&#224;), tandis que d&#8217;autres en italique sont partiellement corrects (e.g. conform&#233;ment). Il appara&#238;t
en outre que de nombreux transpots sont tr&#232;s proches (e.g. conforme &#224; et conformes &#224;).
</p>
<p>conforme &#224; (45) conform&#233;ment &#224; (29) &#224;? (21) dans? (20) . . .
conforme au (12) conformes &#224; (11) avec? (9) conform&#233;ment (9) . . .
correspond &#224; (1) respectent (1) d&#8217;actualit&#233;? (1) gestes en? (1)
</p>
<p>FIG. 2 &#8211; Sous-ensemble des 273 transpots diff&#233;rents retourn&#233;s pour la requ&#234;te in keeping
with, leur fr&#233;quence &#233;tant indiqu&#233;e entre parenth&#232;ses.
</p>
<p>Afin d&#8217;am&#233;liorer les performances du syst&#232;me et d&#8217;augmenter la diversit&#233; des traductions af-
fich&#233;es, il est donc n&#233;cessaire d&#8217;identifier les erreurs d&#8217;alignement et de d&#233;tecter les transpots
similaires. Ce sont les deux probl&#232;mes que nous &#233;tudions dans les sections suivantes.
</p>
<p>3 Filtrage des transpots
</p>
<p>Distinguer les bons transpots des mauvais peut &#234;tre vu comme un probl&#232;me de classification.
Nous avons consid&#233;r&#233; plusieurs classificateurs classiques2 : l&#8217;algorithme du voted-perceptron
(VP) (Freund &amp; Schapire, 1999) qui s&#8217;est d&#233;j&#224; montr&#233; performant dans plusieurs t&#226;ches de
TALN (Collins, 2002), un s&#233;parateur &#224; vaste marge (SVM) qui est souvent employ&#233; en ap-
prentissage supervis&#233;, un arbre de d&#233;cision &#224; un niveau (decision stump) pour sa simplicit&#233;,
AdaBoost qui utilise un decision stump comme classificateur faible et un classificateur &#224; vote
majoritaire combinant un voted-perceptron, un SVM et AdaBoost.
</p>
<p>Chaque classificateur a &#233;t&#233; entra&#238;n&#233; de mani&#232;re supervis&#233;e &#224; partir d&#8217;un corpus annot&#233; (cf. sec-
tion 5). Nous avons calcul&#233; trois ensembles de caract&#233;ristiques pour chaque exemple, i.e. chaque
paire requ&#234;te/transpot (q, t). Le premier ensemble est constitu&#233; de caract&#233;ristiques relatives &#224; la
taille (compt&#233;e en nombre de mots) de q et t, avec l&#8217;intuition que les deux tailles sont corr&#233;-
l&#233;es. Le second ensemble regroupe plusieurs scores d&#8217;alignement obtenus avec des mod&#232;les
IBM d&#8217;alignement de mots. Le dernier regroupe des indices plus linguistiques, parmi lesquels
le pourcentage de mots grammaticaux dans q et t, ou le nombre de pr&#233;positions et d&#8217;articles. Au
total, chaque exemple est associ&#233; au maximum &#224; 40 caract&#233;ristiques num&#233;riques.
</p>
<p>2Nous avons employ&#233; WEKA dans nos exp&#233;riences http://www.cs.waikato.ac.nz/ml/weka.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Int&#233;gration de l&#8217;alignement de mots dans le concordancier bilingue TransSearch
</p>
<p>4 Regroupement de variantes
</p>
<p>M&#234;me apr&#232;s avoir identifi&#233; les transpots erron&#233;s, il reste souvent de nombreuses traductions
pour une requ&#234;te donn&#233;e. Par exemple, notre meilleur classificateur (voir la section 6.2) identifie
91 mauvais transpots parmi les 273 initialement propos&#233;s pour la requ&#234;te in keeping with.
Parmi les transpots restants, certains sont tr&#232;s similaires et sont donc redondants pour l&#8217;utilisa-
teur (voir la figure 2)3. Nous estimons que parmi les 182 transpots restants, pas moins de 37
traductions canoniques sont int&#233;ressantes. Regrouper les transpots proches permet d&#8217;identifier
plus facilement un sous-ensemble des traductions pertinentes.
</p>
<p>Distance d&#8217;&#233;dition bas&#233;e sur les mots. Nous avons d&#233;velopp&#233; une distance d&#8217;&#233;dition sp&#233;-
cifique au niveau des mots pour regrouper les variantes. Diff&#233;rents co&#251;ts de substitution, de
suppression et d&#8217;insertion ont &#233;t&#233; d&#233;finis empiriquement selon les classes grammaticales ou les
flexions possibles des mots ; ce param&#233;trage est donc d&#233;pendant de la langue. Nous avons uti-
lis&#233; un lexique d&#233;velopp&#233; au RALI, qui liste, pour le fran&#231;ais et l&#8217;anglais, les lemmes de chaque
forme fl&#233;chie et leurs diff&#233;rentes parties du discours.
</p>
<p>Un co&#251;t minimal de substitution a &#233;t&#233; attribu&#233; empiriquement entre des formes fl&#233;chies d&#8217;un
m&#234;me lemme. De plus, un score a &#233;t&#233; fix&#233; afin de p&#233;naliser de mani&#232;re croissante et dans
l&#8217;ordre suivant les op&#233;rations d&#8217;&#233;dition impliquant des signes de ponctuation, des articles, des
mots grammaticaux (pr&#233;positions, conjonctions et pronoms), des verbes auxiliaires et des mots
lexicaux (verbes, noms, adjectifs et adverbes).
</p>
<p>Regroupement des transpots. La comparaison de paires de transpots avec notre distance
d&#8217;&#233;dition peut &#234;tre vue comme un cas particulier de l&#8217;alignement multiple de s&#233;quences, un
probl&#232;me classique en bio-informatique (Chenna et al., 2003). Nous avons adopt&#233; l&#8217;approche
de construction progressive de l&#8217;alignement. Cette m&#233;thode commence par calculer les distances
d&#8217;&#233;dition au niveau des mots entre chaque paire de transpots et sauvegarde les r&#233;sultats dans une
matrice de distances. Un algorithme de clustering ascendant appel&#233; neighbor-joining (Saiou &amp;
Nei, 1987) est ensuite appliqu&#233; ; celui-ci construit un arbre en regroupant soit deux transpots,
qui sont des feuilles de l&#8217;arbre, soit un transpot et un n&#339;ud de l&#8217;arbre repr&#233;sentant d&#233;j&#224; plusieurs
traductions, soit encore, deux n&#339;uds. &#192; chaque &#233;tape, la paire la plus similaire est regroup&#233;e et
ajout&#233;e &#224; l&#8217;arbre, jusqu&#8217;&#224; ce que tous les transpots soient align&#233;s.
</p>
<p>Au final, l&#8217;algorithme neighbor-joining fournit un arbre dont les feuilles sont les transpots ;
les feuilles les plus proches dans cet arbre correspondent aux variantes les plus similaires, ce
qui permet de construire des clusters de variantes en traversant l&#8217;arbre selon un parcours en
profondeur. Les transpots associ&#233;s &#224; deux feuilles voisines et qui diff&#232;rent uniquement selon
des mots grammaticaux ou des flexions des m&#234;mes formes simples, se retrouvent ainsi r&#233;unis
dans un m&#234;me cluster. Ce processus est r&#233;p&#233;t&#233; jusqu&#8217;&#224; ce qu&#8217;aucune variante ne soit identifi&#233;e
comme similaire aux autres. Ce principe est illustr&#233; par la figure 3. Les deux transpots voisins
conforme &#224; et conformes &#224; sont tout d&#8217;abord regroup&#233;s, de m&#234;me que conforme au et
conforme aux. Ces deux groupes sont ensuite fusionn&#233;s au sein d&#8217;un m&#234;me cluster, le transpot
correspondant &#224;, jug&#233; trop diff&#233;rent des autres, n&#8217;&#233;tant pas inclus dans le nouvel ensemble
ainsi form&#233;.
</p>
<p>3Ce ph&#233;nom&#232;me est particuli&#232;rement important en fran&#231;ais du fait notamment des nombreuses formes conju-
gu&#233;es pour les verbes. De nombreux transpots diff&#232;rent seulement par des signes de ponctuation ou des mots
grammaticaux.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>St&#233;phane Huet, Julien Bourdaillet, Philippe Langlais
</p>
<p>FIG. 3 &#8211; Regroupement de transpots proches.
</p>
<p>5 Corpus
</p>
<p>M&#233;moire de traduction. La m&#233;moire de traduction sur laquelle s&#8217;appuie TransSearch
est compos&#233;e principalement du Hansard canadien, constitu&#233; de textes parall&#232;les, en fran&#231;ais
et en anglais, issus des enregistrements officiels des sessions du parlement canadien. Pour les
exp&#233;riences d&#233;taill&#233;es ci-dessous, nous avons index&#233; avec Lucene4 une m&#233;moire comprenant
8,3 millions de paires de phrases fran&#231;ais-anglais.
</p>
<p>Corpus de r&#233;f&#233;rence automatique. Nous avons d&#233;velopp&#233; de fa&#231;on automatis&#233;e un corpus
de r&#233;f&#233;rence (REF) en croisant notre m&#233;moire de traduction avec un lexique bilingue du RALI
compos&#233; de pr&#232;s de 60 000 expressions (mots ou s&#233;quences de mots) ainsi qu&#8217;avec les 5 000
requ&#234;tes les plus fr&#233;quemment soumises au syst&#232;me par les utilisateurs. Notre r&#233;f&#233;rence est
constitu&#233;e de plus d&#8217;1,4 million de paires de phrases qui contiennent toutes une requ&#234;te et une
traduction valid&#233;e par notre lexique.
</p>
<p>R&#233;f&#233;rence humaine. Afin d&#8217;entra&#238;ner les classificateurs d&#233;crits dans la section 3, quatre anno-
tateurs humains ont &#233;t&#233; charg&#233;s d&#8217;identifier les mauvais transpots r&#233;sultant de notre algorithme
de transpotting. Nous avons d&#233;cid&#233; d&#8217;annoter hors-contexte un peu plus de 12 000 paires re-
qu&#234;te/traduction, ce qui permet une annotation rapide5 mais laisse des cas difficiles &#224; juger.
Par exemple, dans notre exemple, conforme &#224; est un transpot pouvant &#234;tre facilement class&#233;
comme correct, mais d&#8217;autres ne sont pas aussi &#233;vidents, comme dans le sens de ou tenir
compte de qui peuvent &#234;tre valides en fonction du contexte. Un score kappa de 0,76 t&#233;moigne
d&#8217;un haut degr&#233; d&#8217;accord inter-annotateurs.
</p>
<p>6 Exp&#233;riences
</p>
<p>6.1 Transpotting
</p>
<p>Pour chacune des 1 416 000 paires de phrases du corpus REF, nous avons &#233;valu&#233; la capacit&#233; de
notre algorithme de transpotting d&#233;crit dans la section 2.1 &#224; identifier la traduction de r&#233;f&#233;rence
t&#770; pour une requ&#234;te q suivant les mesures de pr&#233;cision et rappel calcul&#233;es comme suit :
</p>
<p>rappel = |t &#8745; t&#770;| / |t&#770;| pr&#233;cision = |t &#8745; t&#770;| / |t| (1)
</p>
<p>o&#249; t est le transpot identifi&#233; par l&#8217;algorithme et l&#8217;intersection retourne la plus longue s&#233;quence
de mots commune &#224; t et t&#770;. De fa&#231;on &#224; calculer ces m&#233;triques sur l&#8217;int&#233;gralit&#233; du corpus de
r&#233;f&#233;rence, nous moyennons dans un premier temps le rappel et la pr&#233;cision sur l&#8217;ensemble des
</p>
<p>4http://lucene.apache.org
5De l&#8217;ordre de 40 secondes par requ&#234;te.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Int&#233;gration de l&#8217;alignement de mots dans le concordancier bilingue TransSearch
</p>
<p>paires correspondant &#224; chaque requ&#234;te q. Dans un second temps, nous moyennons les scores
ainsi obtenus en accordant le m&#234;me poids &#224; chaque requ&#234;te. La F-mesure est ensuite d&#233;duite de
la pr&#233;cision et du rappel calcul&#233;s sur l&#8217;ensemble du corpus.
</p>
<p>pr&#233;cision rappel F-mesure
transpotting 0,79 0,84 0,81
transpotting + filtrage 0,82 0,90 0,86
</p>
<p>TAB. 1 &#8211; R&#233;sultat du transpotting avant et apr&#232;s le filtrage du classificateur sur le corpus REF.
Voir la section 6.2 pour l&#8217;explication de la ligne 2.
</p>
<p>Notre algorithme de transpotting (ligne 1 du tableau 1) obtient une pr&#233;cision de 0, 79 et un rappel
de 0, 84, qui sont des r&#233;sultats satisfaisants. La raison pour laquelle la pr&#233;cision est moins bonne
que le rappel est li&#233;e au fait qu&#8217;assez souvent, la traduction de r&#233;f&#233;rence est une sous-s&#233;quence
du transpot identifi&#233;, comme par exemple dans la figure 4.
</p>
<p>Je crois qu&#8217;il est tout &#224; fait conforme &#224; l&#8217;esprit du projet de loi.
</p>
<p>FIG. 4 &#8211; Transpot (soulign&#233;) et traduction de r&#233;f&#233;rence (en gras) pour la requ&#234;te in keeping
with.
</p>
<p>6.2 Entra&#238;nement des classificateurs
</p>
<p>Comme indiqu&#233; dans la section 3, nous avons entra&#238;n&#233; plusieurs classificateurs &#224; reconna&#238;tre les
mauvais transpots. Ces classificateurs et plusieurs approches na&#239;ves (mais tr&#232;s comp&#233;titives)
sont &#233;valu&#233;s suivant le taux d&#8217;exemples correctement classifi&#233;s (TECC). Puisque la t&#226;che qui
nous int&#233;resse est celle de filtrer les mauvais transpots, nous pr&#233;sentons &#233;galement les taux de
pr&#233;cision et rappel relatifs &#224; cette classe.
</p>
<p>Le tableau 2 pr&#233;sente les r&#233;sultats obtenus avec une validation crois&#233;e &#224; 10 blocs. La premi&#232;re
approche na&#239;ve utilis&#233;e (ligne 1) classifie tous les exemples comme bons. Elle obtient ainsi un
TECC de 0, 62, mais n&#8217;est d&#8217;aucune utilit&#233; pour le filtrage. Une approche plus sens&#233;e &#8212; que
nous avons d&#233;couverte apr&#232;s avoir explor&#233; l&#8217;utilit&#233; des diff&#233;rents ensembles de caract&#233;ristiques
&#8212; classifie comme mauvais transpots ceux dont le taux de mots grammaticaux est sup&#233;rieur &#224;
0, 75. Cette approche obtient un bon TECC de 0, 78.
</p>
<p>Nous avons commenc&#233; les exp&#233;riences en &#233;tudiant la contribution de chaque ensemble de ca-
ract&#233;ristiques avec le voted-perceptron6. Quand le voted-perceptron est entra&#238;n&#233; en utilisant un
seul ensemble de caract&#233;ristiques, celui utilisant uniquement les caract&#233;ristiques grammaticales
obtient le meilleur TECC de 0, 79 et une F-mesure de 0, 65. Bien que la configuration bas&#233;e
uniquement sur les caract&#233;ristiques issues des mod&#232;les d&#8217;alignement de mots IBM 2 obtienne
un TECC l&#233;g&#232;rement inf&#233;rieur (0, 78), nous la consid&#233;rons comme meilleure en raison de sa
F-mesure de 0, 73 qui est plus &#233;lev&#233;e. La configuration utilisant toutes les caract&#233;ristiques pour
repr&#233;senter un exemple am&#233;liore clairement les r&#233;sultats de l&#8217;approche na&#239;ve avec un TECC de
0, 83 et une F-mesure de 0, 77. On peut &#233;galement remarquer qu&#8217;alors que la meilleure approche
</p>
<p>6Des r&#233;sultats similaires ont &#233;t&#233; observ&#233;s pour les diff&#233;rents ensembles de caract&#233;ristiques avec les autres clas-
sificateurs et ne sont pas pr&#233;sent&#233;s ici.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>St&#233;phane Huet, Julien Bourdaillet, Philippe Langlais
</p>
<p>mauvais transpots
Approche Caract&#233;ristiques TECC pr&#233;c. rappel F-mes.
na&#239;ve: tous bons 0,62 0,00 0,00 0,00
na&#239;ve: taux mots gram. &gt; 0, 75 0,78 0,88 0,49 0,63
</p>
<p>Voted-Perceptron
</p>
<p>taille 0,73 0,75 0,47 0,58
IBM 0,78 0,69 0,78 0,73
grammaticales 0,79 0,88 0,52 0,65
toutes 0,83 0,81 0,73 0,77
</p>
<p>Vote majoritaire 0,84 0,84 0,71 0,77
</p>
<p>TAB. 2 &#8211; Performance des algorithmes de classification pour identifier les mauvais transpots.
</p>
<p>na&#239;ve obtient une pr&#233;cision plus &#233;lev&#233;e que celle du meilleur voted-perceptron, ce dernier ob-
tient un rappel et une pr&#233;cision plus &#233;quilibr&#233;s. Dans la mesure o&#249; il est difficile de savoir s&#8217;il
vaut mieux privil&#233;gier la pr&#233;cision ou le rappel dans notre cas, nous pr&#233;f&#233;rons maximiser la
F-mesure. En entra&#238;nant les autres classificateurs avec tous les ensembles de caract&#233;ristiques,
aucun gain significatif n&#8217;a &#233;t&#233; observ&#233;. N&#233;anmoins, avec le vote majoritaire combinant plusieurs
m&#233;thodes, nous avons obtenu un meilleur TECC de 0, 84 et une F-mesure de 0, 77, comme re-
port&#233; &#224; la derni&#232;re ligne du tableau 2.
</p>
<p>Avec le meilleur classificateur obtenu, le vote majoritaire, nous avons &#233;valu&#233; l&#8217;impact du fil-
trage en utilisant ce classificateur pour filtrer les r&#233;sultats du transpotting sur le corpus REF. Les
r&#233;sultats sont pr&#233;sent&#233;s dans le tableau 1 (ligne 2). En supprimant ainsi 7,9% des transpots, on
peut observer un gain significatif en F-mesure qui cro&#238;t de 0, 81 &#224; 0, 86. Le gain le plus impor-
tant est en rappel qui passe de 0, 84 &#224; 0, 90, ce qui signifie que le filtrage &#233;limine principalement
les transpots trop courts. En examinant manuellement les transpots filtr&#233;s, nous avons constat&#233;
que les mauvais transpots courts, comme les mots grammaticaux, &#233;taient fr&#233;quemment identi-
fi&#233;s comme mauvais par le classificateur. Bien que les m&#233;thodes de classification supervis&#233;es
test&#233;es n&#8217;obtiennent pas d&#8217;am&#233;liorations majeures par rapport &#224; une l&#8217;approche na&#239;ve bas&#233;e sur
l&#8217;observation des mots grammaticaux, les gains significatifs constat&#233;s par rapport &#224; l&#8217;algorithme
initial de transpotting d&#233;montrent l&#8217;int&#233;r&#234;t de filtrer les mauvais transpots.
</p>
<p>6.3 Regroupement de variantes
</p>
<p>Si regrouper les variantes similaires est une fonctionnalit&#233; tr&#232;s int&#233;ressante d&#8217;un point de vue
ergonomique, il n&#8217;est cependant pas facile de trouver le bon niveau de granularit&#233; du regroupe-
ment des transpots7. En cons&#233;quence, nous avons &#233;tudi&#233; deux approches. La premi&#232;re m&#233;thode
regroupe les variantes qui ne diff&#232;rent que par des signes de ponctuation ou qui sont des formes
fl&#233;chies d&#8217;un m&#234;me lemme. Elle est bas&#233;e sur une distance d&#8217;&#233;dition, appel&#233;eD1, qui utilise les
m&#234;mes co&#251;ts d&#8217;&#233;dition pour les mots grammaticaux et lexicaux. La seconde m&#233;thode est plus
laxiste car elle est bas&#233;e sur une distance d&#8217;&#233;dition, appel&#233;e D2, qui attribue un co&#251;t d&#8217;&#233;dition
moindre aux mots grammaticaux qu&#8217;aux mots lexicaux.
</p>
<p>En regroupant les transpots obtenus &#224; partir des 5 000 requ&#234;tes du corpus REF (et filtr&#233;s par
notre meilleur classificateur), la premi&#232;re m&#233;thode obtient un nombre moyen de 136 clusters
</p>
<p>7Cela n&#233;cessiterait probablement des tests avec des utilisateurs r&#233;els.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Int&#233;gration de l&#8217;alignement de mots dans le concordancier bilingue TransSearch
</p>
<p>par requ&#234;te avec D1, alors qu&#8217;on a en moyenne 164 transpots par requ&#234;te (sans regroupement).
Comme attendu, en utilisant D2, on r&#233;duit drastiquement le nombre de clusters &#224; 86 par re-
qu&#234;te. En effet, contrairement &#224; D1, D2 permet de regrouper des variantes similaires comme
sur des ann&#233;es et durant des ann&#233;es. Toutefois cela conduit occasionnellement &#224; des
regroupements erron&#233;s comme tout &#224; fait avec fait tout.
</p>
<p>La figure 5 pr&#233;sente les 5 transpots les plus fr&#233;quents obtenus pour deux requ&#234;tes par l&#8217;algo-
rithme de transpotting avec et sans regroupement. Sans le regroupement, on peut observer que
la tendance est de proposer des formes fl&#233;chies d&#8217;une m&#234;me traduction. Appliquer le regroupe-
ment conduit &#224; plus de diversit&#233;, ce qui est pr&#233;f&#233;rable puisque le nombre de variantes pouvant
&#234;tre affich&#233;es &#224; l&#8217;&#233;cran dans TransSearch est limit&#233; : nous estimons que l&#8217;affichage de 5
transpots sur une m&#234;me page est un bon compromis (voir la figure 1(b)).
</p>
<p>sans regroup. d&#233;crits d&#233;crite d&#233;crit tel que d&#233;crit comme l&#8217;a
regroup. D2 d&#233;crits pr&#233;vu comme l&#8217;a tel que prescrit comme le propose
sans regroup. s&#8217;est r&#233;v&#233;l&#233; s&#8217;est av&#233;r&#233; s&#8217;est av&#233;r&#233;e s&#8217;est r&#233;v&#233;l&#233;e a &#233;t&#233;
regroup. D2 s&#8217;est r&#233;v&#233;l&#233; s&#8217;est av&#233;r&#233; a &#233;t&#233; s&#8217;est montr&#233; a prouv&#233;
</p>
<p>FIG. 5 &#8211; Les 5 transpots les plus fr&#233;quents pour les requ&#234;tes as described et has proven
to be avec ou sans regroupement.
</p>
<p>Afin de simuler cela, nous avons mesur&#233; la diversit&#233; des 5 transpots les plus fr&#233;quents8 propos&#233;s
en les consid&#233;rant comme des sacs d&#8217;unigrammes. Pour cette &#233;valuation, les mots sont lemmati-
s&#233;s et les mots grammaticaux sont supprim&#233;s. Nous utilisons les mesures de pr&#233;cision et rappel
pour comparer les sacs de mots g&#233;n&#233;r&#233;s par les m&#233;thodes de regroupement &#224; ceux de la r&#233;f&#233;-
rence, celle-ci &#233;tant form&#233;e &#224; partir de la ressource humaine d&#233;crite dans la section 5. Suivant
ces principes, nous avons obtenu une pr&#233;cision de 0, 90 et un rappel de 0, 43 sans recourir au
regroupement. En construisant des clusters, le rappel a &#233;t&#233; significativement augment&#233; jusqu&#8217;&#224;
0, 47 avec D1 et &#224; 0, 54 avec D2, alors que la pr&#233;cision est rest&#233;e sensiblement la m&#234;me (0, 89
avecD1 et 0, 86 avecD2). Ces r&#233;sultats sont corr&#233;l&#233;s avec la plus grande diversit&#233; obtenue gr&#226;ce
au regroupement de variantes.
</p>
<p>7 Discussion
</p>
<p>Dans cette &#233;tude, nous avons &#233;tudi&#233; l&#8217;am&#233;lioration du concordancier bilingue TransSearch
gr&#226;ce &#224; l&#8217;alignement de mots. Un algorithme de transpotting a &#233;t&#233; propos&#233; et &#233;valu&#233;. Nous avons
pr&#233;sent&#233; deux nouvelles probl&#233;matiques essentielles au succ&#232;s de notre nouveau prototype : la
d&#233;tection des transpots erron&#233;s et le regroupement des variantes similaires. Nous avons propos&#233;
des solutions &#224; ces deux probl&#232;mes et &#233;valu&#233; leur efficacit&#233;. En particulier, nous avons montr&#233;
qu&#8217;il est possible de mieux d&#233;tecter les mauvais transpots par rapport &#224; une approche na&#239;ve
comp&#233;titive, et que le regroupement de variantes am&#233;liore la diversit&#233; des transpots propos&#233;s.
</p>
<p>Jusqu&#8217;&#224; pr&#233;sent il nous a &#233;t&#233; difficile de comparer notre approche &#224; d&#8217;autres de la communaut&#233;.
Cela est d&#251; principalement au caract&#232;re unique du syst&#232;me TransSearch qui archive une
m&#233;moire de traduction cons&#233;quente. Pour donner un point de comparaison, dans (Callisson-
Burch et al., 2005) les auteurs pr&#233;sentent les r&#233;sultats d&#8217;alignement obtenus pour 120 requ&#234;tes
</p>
<p>8Ces transpots correspondent &#224; la variante la plus fr&#233;quente de chacun des 5 clusters les plus fr&#233;quents.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>St&#233;phane Huet, Julien Bourdaillet, Philippe Langlais
</p>
<p>issues d&#8217;une m&#233;moire de traduction de 50 000 paires de phrases. Cela reste plusieurs ordres de
grandeur inf&#233;rieur aux exp&#233;riences pr&#233;sent&#233;es dans cet article.
</p>
<p>Nous avons consid&#233;r&#233; des mod&#232;les d&#8217;alignements simples dans cette &#233;tude. Nous souhaitons
&#233;tudier des mod&#232;les d&#8217;alignement plus pr&#233;cis, dont celui d&#233;crit dans (Vogel et al., 1996)
</p>
<p>Remerciements
</p>
<p>Cette &#233;tude est financ&#233;e par le Conseil National de Recherche du Canada, en collaboration avec
l&#8217;entreprise canadienne Terminotix.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BOURDAILLET J., HUET S., GOTTI F., LAPALME G. &amp; LANGLAIS P. (2009). Enhancing
the bilingual concordancer TransSearch with word-level alignment. In 22nd Conference of the
Canadian Society for Computational Studies of Intelligence, Kelowna, Canada.
BROWN P., DELLA PIETRA V., DELLA PIETRA S. &amp; MERCER R. (1993). The mathematics
of statistical machine translation: parameter estimation. Computational Linguistics, 19(2),
263&#8211;311.
CALLISSON-BURCH C., BANNARD C. &amp; SCHROEDER J. (2005). A compact data structure
for searchable translation memories. In 10th European Conference of the Association for
Machine Translation (EAMT), p. 59&#8211;65, Budapest, Hongrie.
CHENNA R., SUGAWARA H., KOIKE T., LOPEZ R., GIBSON T. J., HIGGINS D. G. &amp;
THOMPSON J. D. (2003). Multiple sequence alignment with the Clustal series of programs.
Nucleic Acids Research, 31(13), 3497&#8211;3500.
COLLINS M. (2002). Discriminative training methods for hidden Markov models: theory and
experiments with perceptron algorithms. In EMNLP, p. 1&#8211;8, Philadelphie, PA, USA.
FREUND Y. &amp; SCHAPIRE R. (1999). Large margin classification using the perceptron algo-
rithm. Machine Learning, 37(3), 277&#8211;296.
MACKLOVITCH E., LAPALME G. &amp; GOTTI F. (2008). Transsearch: What are translators
looking for ? In 18th Conference of the Association for Machine Translation in the Americas
(AMTA), p. 412&#8211;419, Waikiki, Hawai&#8217;i, USA.
PLANAS E. &amp; FURUSE O. (1999). Formalizing translation memories. In 7th Machine Trans-
lation Summit, p. 331&#8211;339, Singapour.
SAIOU N. &amp; NEI M. (1987). The neighbor-joining method: A new method for reconstructing
phylogenetic trees. Molecular Biology and Evolution, 4(4), 406&#8211;425.
SIMARD M. (2003). Translation spotting for translation memories. In HLT-NAACL 2003
Workshop on Building and using parallel texts: data driven machine translation and beyond,
p. 65&#8211;72, Edmonton, Canada.
V&#201;RONIS J. &amp; LANGLAIS P. (2000). Evaluation of Parallel text Alignment Systems &#8212; The
Arcade Project., chapter 19, p. 369&#8211;388. Kluwer Academic Publisher, Dordrecht, Pays-Bas.
VOGEL S., NEY H. &amp; C. T. (1996). HMM-based word alignment in statistical translation. In
16th conference on Computational linguistics, p. 836&#8211;841, Copenhague, Danemark.</p>

</div></div>
</body></html>