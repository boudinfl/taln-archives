TALN 2009, Senlis, 24-26 juin 2009

Intégration de l’alignement de mots dans
le concordancier bilingue TransSearch

Stéphane Huet Julien Bourdaillet Philippe Langlais
DIRO - Université de Montréal
C.P. 6128, succursale centre-ville

H3C 3J7, Montréal, Québec, Canada
{huetstep,bourdaij,felipe}@iro.umontreal.ca

Résumé. Malgré les nombreuses études visant a améliorer la traduction automatique, la
traduction assistée par ordinateur reste la solution préférée des traducteurs lorsqu’une sortie de
qualité est recherchée. Dans cet article, nous présentons nos travaux menés dans le but d’amé-
liorer le concordancier bilingue Transsearch. Ce service, accessible sur le Web, repose
principalement sur un alignement au niveau des phrases. Dans cette étude, nous discutons et
évaluons l’intégration d’un alignement statistique au niveau des mots. Nous présentons deux
nouvelles problématiques essentielles au succes de notre nouveau prototype : la détection des
traductions erronées et le regroupement des variantes de traduction similaires.

Abstract. Despite the impressive amount of recent studies devoted to improving the state
of the art of machine translation, computer assisted translation tools remain the preferred solu-
tion of human translators when publication quality is of concern. In this paper, we present our
ongoing efforts conducted within a project which aims at improving the commercial bilingual
concordancer Transsearch. The core technology of this Web-based service mainly relies
on sentence-level alignment. In this study, we discuss and evaluate the embedding of statistical
word-level alignment. Two novel issues that are essential to the success of our new prototype
are tackled: detecting erroneous translations and grouping together similar translations.

M0tS-CléS I alignement au niveau des mots, concordancier bilingue, traduction automa-
tique.

Keywords: word-level alignment, bilingual concordancer, machine translation.

Stéphane Huet, J ulien Bourdaillet, Philippe Langlais

1 Introduction

Bien qu’un effort soutenu ait été consacré cette derniere décennie a l’amélioration des systemes
de traduction automatique, les traducteurs professionnels préferent encore aujourd’hui se tour-
ner vers les outils de la traduction assistée par ordinateur (TAO), parini lesquels ﬁgurent les
systemes a mémoire de traduction (MT) et les concordanciers bilingues. Ces deux types de sys-
temes exploitent une mémoire de traduction constituée d’un bitexte, i. e. un ensemble de paires
d’unités (typiquement des phrases) qui sont la traduction l’une de l’autre. Alors qu’un systeme
a MT est un dispositif de traduction (Planas & Furuse, 1999), un concordancier bilingue est
conceptuellement plus simple puisque son objectif principal est de trouver au sein d’un bitexte
les paires d’unités qui contiennent une requéte (en général une sequence de mots) soumise par
un utilisateur. C’est ensuite a l’uti1isateur de localiser lui-méme les parties intéressantes dans
les réponses obtenues. Bien que ce type de systeme paraisse tres simple, les concordanciers
bilingues restent un outil tres populaire en TAO. Macklovitch et al. (2008), indiquent ainsi que
Trans Searchl, le concordancier commercial mis en ligne sur le Web et faisant l’objet de cet
article, a regu en moyenne 177 000 requétes par mois sur une période d’un an (2006-2007).

La ﬁgure 1(a) présente une capture d’écran du concordancier Transsearch dans sa version
actuelle. Dans cet exemple, suite a la requéte in keeping with soumise par un utilisateur,
le systeme retoume une page contenant les 25 premieres paires de phrases de la mémoire de
traduction qui contiennent une occurrence de la requéte. Come on peut le constater, rien n’est
mis en valeur dans les phrases cibles retoumées, ce qui contraint l’utilisateur a rechercher la
traduction a l’intérieur de chaque phrase cible proposée.

R 0 0 Ttanssearrn '8 9 8 Tl-inssearcni nurture
EC] «T CE W
Transsearch in Katerina W ‘fen ‘ r
Transsearch _ _ :
Results 6 possible translations for in keeping with (phrase
nsquaue i Muuwmpte i iaeeimm i Aide i Quilter -* in in sentences)
Signet Tr:irisS:iirv:h , _ ‘
I U“ E: “C :.mi_i conlormement a — [130 sentences matched] [3] ‘
Collection de documents : Hansard rariadien 4i9sa—2na7i Q conlnrme a — [24 sentences matched, 2 shown] [1] [:1 ‘

That certainly is our policy C'émit  notre politique.

Expression 1 ll'\ keeping with ’ Etierther ‘ ’ Reuuéte iiiiingue ‘
T T l ask myseu, his  the .19 me pose la uuestiun suivante: esme que
charter ot rig and treedoms ? c‘%t  la charte des dmis at
En vettu ties regimes di: reglementation Under the eurrent regulatory regimes and libeités '2 rr:
aetuels et dans le eatire ties ‘competences in keeping with the federal constitutional "me 59,.;e,,.,s5 )>
eonferees au gouvetnemmt federal par la jIll'LS(l1CIiDn. Health Canada has legislative
Constitution, Saute Canada est deja investi authorities in place to regulate the safety

lidéles ‘a — [18 sentences , [:1

do lautoriié legislative rieeessaitc: pour anti effectiveness of medical devices and
teglementer la seeunte et l'effieaeiie' des their manuﬁeturers under the Food and VB dans '9 SENS lie — [19 Sentences matched. 2 SNOWFII [1] [:1
1n5]'fﬂﬂﬂg1|]§ ' ;;[ [gm-5 fab]-[(;an|g my Dmgg Am and [he mgdical dgviggg in our opinion this amend merit clariﬁes the A nc_:tre avis. cetamendement izlariﬁe Ia
vetlu de la Loi sur les alitrienis et drogucs et regulations. ""°"°" a"d '5. ' ‘ "‘°"°" E‘ '3
. . . recommendation 73 iecemmandatinn 73. Sr:
des reglemeriis telaltfs aux instruments —
rriedicaux. This is DIIIEEIEI-‘DE the northwest Cela |’api>n=I=he de
' ' ' ’ to appiya ' justice ' que ' ' du nam-
_ _ justice approach. Guests: sont engagégs pplique-r. ﬂ
Sort adoption Strtall oonuaite au Jugetrient To pass it would go against the very ) L
 de la majonte dos Canadiens. eonuaire 51 ee sensibility of the majority of Canadians,  
qui. scion eux, est larehose 3: faire et 51 ee against whatthey know is right and what Salon '25 buts _ [1 Sentence manned] [:1 l
qui repond aux besoiris qui existent au they know is in keeping with the needs in .
Canada auinurd‘hui. Canada today. en toute Iogique aver: — [1 sentence matched] [3] :
a
. . ,
(a) Version actuelle. 0)) Version en developpement.

FIG. 1 — Résultats afﬁchés par Transsearch pour la requéte in keeping with.

L’ objectif du projet TS3 est d’identiﬁer automatiquement dans les phrases retoumées les dif-
férentes traductions d’une requéte utilisateur. Bien que l’aspect du nouveau prototype ne soit
pas encore déﬁnitif, la ﬁgure 1(b) montre une interface o1‘1l’utilisateur peut consulter les traduc-
tions automatiquement identiﬁées et considérées comme les plus pertinentes. S’il reste toujours
possible de consulter les paires de phrases contenant la requéte, l’uti1isateur peut dorénavant
cliquer sur une traduction donnée et Visualiser son contexte d’emploi.

lhttpz//www.tsrali.com

Integration de l’alignement de mots dans le concordancier bilingue TransSearch

Dans la suite, nous présentons tout d’abord la technique Inise en oeuvre pour repérer les tra-
ductions au sein des phrases. Nous décrivons ensuite deux nouveaux problemes importants que
nous avons rencontrés: l’identiﬁcation des alignements erronés (section 3) et le regroupement
de variantes de traduction (section 4). Nous décrivons les données utilisées en section 5 et pré-
sentons nos résultats expérimentaux en section 6.

2 Repérage de traduction

Le repérage de traduction ou transpotting (diminutif de translation spotting), une partie es-
sentielle du projet TS3, consiste a identiﬁer dans du texte cible la traduction d’une requéte en
langue source (Véronis & Langlais, 2000). Nous appelons transpot l’ensemble des mots cibles
automatiquement associés a une requéte dans une paire de phrases. Dans l’exemple de la ﬁ-
gure 1(b), conformément a et va dans le sens de sont deux des six transpots présentés
a l’utilisateur pour la requéte in keeping with.

2.1 Algorithme de transpotting

Le transpotting peut étre vu comme un sous-probleme de l’alignement au niveau des mots,
comme suggéré dans (Simard, 2003). La traduction statistique est encore fortement basée sur
des modeles d’alignement de mots (Brown et al., 1993) que nous utilisons dans cette étude.

Formellement, a partir d’une phrase S = s1...sn exprimée dans une langue dite source et de sa
traduction T = t1...tm, un alignement a = a1...am de type IBM revient a connecter chaque mot
de T a un mot de S (aj E «[1, ..., n}) ou au mot vide (aj = 0), ce dernier rendant compte des
mots cibles non traduits. Plusieurs modeles proposés par Brown et al. (1993) décomposent la
probabilité conjointe d’une phrase cible et de son alignement, étant donnée la phrase source.
Pour des raisons calculatoires, nous nous concentrons dans cette étude sur la forme la plus
simple, correspondant aux modeles [BM 1 et 2 :

m
p(t’{‘,a'{‘|s§‘) = H 2 p(t,-ls.) >< p(m‘,m,n)

j=1 iE[0,n]

ou le premier terme de la somme est la probabilité de transfert et le second la probabilité d’ali-
gnement. Avec cette décomposition, il est facile et efﬁcace de calculer l’alignement le plus
probable entre deux phrases, argmaxain p(a§” |t§”, 3}‘), ce que nous appelons l’alignement de Vi-
terbi par la suite. Toutefois, cette approche produit souvent des alignments discontinus, alors
que ce type d’alignement n’est généralement pas nécessaire pour retrouver les bons transpots.

Aﬁn de produire des transpots contigus, nous avons implémenté un algorithme de transpotting
proposé initialement par Simard (2003). Pour chaque paire (j1,j2) E [1, m] X [_1, m], nous
calculons deux alignements de Viterbi : l’un entre la suite de mots  et la requéte 3:3, et l’autre
entre les mots restants des phrases source et cible  E s’f"1s§; +1 et  E t’11_1t;-Z +1. Nous
calculons alors :

"12 _ j2 1' j2 —j2 -1‘ ‘J2
ti — argmax mgXp(aj1|s,-it]-1) X Ir_1gXp(aj1|s,-f,tj1)
(31:92) ajl ajl

Stéphane Huet, J ulien Bourdaillet, Philippe Langlais

Cette méthode, ayant une complexité en O(nm3), s’est avérée la plus performante de celles que
nous avons testées (Bourdaillet et al., 2009).

2.2 Intérét du post-traitement

Avec la démarche précédemment décrite, les requétes fréquentes dans la mémoire recoivent un
grand nombre de traductions. La ﬁgure 2 illustre ce phénomene en montrant 12 des nombreuses
séquences de mots retoumées par l’algorithme de transpotting pour la requéte in keeping
with. Dans cet exemple, certains transpots annotés d’une étoile sont clairement mauvais (e. g.
a), tandis que d’autres en italique sont partiellement corrects (e. g. conformément). I1 apparait
en outre que de nombreux transpots sont tres proches (e. g. con f orme a et conformes a).

conforme a (45) conformément a (29) a* (21) dans* (20)
conforme au (12) conformes a (11) avec* (9) conformément (9)
correspond a (1) respectent (1) d’ actualité* (1) gestes en* (1)

FIG. 2 — Sous-ensemble des 273 transpots différents retoumés pour la requéte in keeping
with, leur fréquence étant indiquée entre parentheses.

Aﬁn d’amé1iorer les performances du systeme et d’augmenter la diversité des traductions af-
ﬁchées, il est donc nécessaire d’identiﬁer les erreurs d’a1ignement et de détecter les transpots
similaires. Ce sont les deux problemes que nous étudions dans les sections suivantes.

3 Filtrage des transpots

Distinguer les bons transpots des mauvais peut étre vu comme un probleme de classiﬁcation.
Nous avons considéré plusieurs classiﬁcateurs classiquesz : l’algorithme du voted-perceptron
(VP) (Freund & Schapire, 1999) qui s’est déja montré performant dans plusieurs taches de
TALN (Collins, 2002), un séparateur £1 vaste marge (SVM) qui est souvent employé en ap-
prentissage supervisé, un arbre de decision 61 un niveau (decision stump) pour sa simplicité,
AdaBoost qui utilise un decision stump comme classiﬁcateur faible et un classiﬁcateur 61 vote
majoritaire combinant un voted-perceptron, un SVM et AdaBoost.

Chaque classiﬁcateur a été entrainé de maniere supervisée a partir d’un corpus annoté (cf sec-
tion 5). Nous avons calculé trois ensembles de caractéristiques pour chaque exemple, i. e. chaque
paire requéte/transpot (q, t). Le premier ensemble est constitué de caractéristiques relatives a la
taille (comptée en nombre de mots) de q et t, avec l’intuition que les deux tailles sont corre-
lées. Le second ensemble regroupe plusieurs scores d’alignement obtenus avec des modeles
IBM d’alignement de mots. Le demier regroupe des indices plus linguistiques, parmi lesquels
le pourcentage de mots grammaticaux dans q et t, ou le nombre de prépositions et d’articles. Au
total, chaque exemple est associé au maximum a 40 caractéristiques numériques.

2Nous avons employé WEKA dans nos expériences http : //www . cs . waikato . ac . nz/ml/weka.

Integration de l’alignement de mots dans le concordancier bilingue TransSearch

4 Regroupement de variantes

Meme apres avoir identiﬁe les transpots errones, il reste souvent de nombreuses traductions
pour une requete donnee. Par exemple, notre meilleur classiﬁcateur (voir la section 6.2) identiﬁe
91 mauvais transpots parmi les 273 initialement proposes pour la requete in keeping with.
Parmi les transpots restants, certains sont tres similaires et sont donc redondants pour l’utilisa-
teur (voir la ﬁgure 2)3. Nous estimons que parmi les 182 transpots restants, pas moins de 37
traductions canoniques sont interessantes. Regrouper les transpots proches permet d’identiﬁer
plus facilement un sous-ensemble des traductions pertinentes.

Distance d’édition basée sur les mots. Nous avons developpe une distance d’edition spe-
ciﬁque au niveau des mots pour regrouper les variantes. Differents coﬁts de substitution, de
suppression et d’insertion ont ete deﬁnis empiriquement selon les classes grammaticales ou les
ﬂexions possibles des mots; ce parametrage est donc dependant de la langue. Nous avons uti-
lise un lexique developpe au RALI, qui liste, pour le francais et l’anglais, les lemmes de chaque
forme ﬂechie et leurs differentes parties du discours.

Un coﬁt minimal de substitution a ete attribue empiriquement entre des formes ﬂechies d’un
meme lemme. De plus, un score a ete ﬁxe aﬁn de penaliser de maniere croissante et dans
l’ordre suivant les operations d’edition impliquant des signes de ponctuation, des articles, des
mots grammaticaux (prepositions, conjonctions et pronoms), des verbes auxiliaires et des mots
lexicaux (verbes, noms, adjectifs et adverbes).

Regroupement des transpots. La comparaison de paires de transpots avec notre distance
d’edition peut etre vue comme un cas particulier de l’alignement multiple de sequences, un
probleme classique en bio-informatique (Chenna et al., 2003). Nous avons adopte l’approche
de construction progressive de l’alignement. Cette methode commence par calculer les distances
d’edition au niveau des mots entre chaque paire de transpots et sauvegarde les resultats dans une
matrice de distances. Un algorithme de clustering ascendant appele neighbor-joining (Saiou &
Nei, 1987) est ensuite applique; celui-ci construit un arbre en regroupant soit deux transpots,
qui sont des feuilles de l’arbre, soit un transpot et un noeud de l’arbre representant deja plusieurs
traductions, soit encore, deux noeuds. A chaque etape, la paire la plus similaire est regroupee et
ajoutee a l’arbre, jusqu’a ce que tous les transpots soient alignes.

Au ﬁnal, l’algorithme neighbor-joining foumit un arbre dont les feuilles sont les transpots;
les feuilles les plus proches dans cet arbre correspondent aux variantes les plus similaires, ce
qui permet de construire des clusters de variantes en traversant l’arbre selon un parcours en
profondeur. Les transpots associes a deux feuilles voisines et qui different uniquement selon
des mots grammaticaux ou des ﬂexions des memes formes simples, se retrouvent ainsi reunis
dans un meme cluster. Ce processus est repete jusqu’a ce qu’aucune variante ne soit identiﬁee
comme similaire aux autres. Ce principe est illustre par la ﬁgure 3. Les deux transpots voisins
conforme a et conformes a sont tout d’abord regroupes, de meme que conforme au et
conf o rme aux. Ces deux groupes sont ensuite fusionnes au sein d’un meme cluster, le transpot
correspondant a, juge trop different des autres, n’etant pas inclus dans le nouvel ensemble
ainsi forme.

3Ce phenomeme est particulierement important en frangais du fait notamment des nombreuses formes conju-
guees pour les verbes. De nombreux transpots different seulement par des signes dc ponctuation ou des mots
grammaticaux.

Stéphane Huet, J ulien Bourdaillet, Philippe Langlais

correspondant £1 conforme ,5 correspondant 5
conformes ‘a
‘ /
conforme au

. . conforme aux
conforme a. conformes a conforme au conforme aux

FIG. 3 — Regroupement de transpots proches.
5 Corpus

Mémoire de traduction. La mémoire de traduction sur laquelle s’appuie Transsearch
est composée piincipalement du Hansard canadien, constitué de textes paralleles, en francais
et en anglais, issus des enregistrements ofﬁciels des sessions du parlement canadien. Pour les
expériences détaillées ci-dessous, nous avons indexé avec Lucene4 une mémoire comprenant
8,3 millions de paires de phrases francais-anglais.

Corpus de référence automatique. Nous avons développé de facon automatisée un corpus
de référence (REF) en croisant notre mémoire de traduction avec un lexique bilingue du RALI
composé de pres de 60000 expressions (mots ou séquences de mots) ainsi qu’avec les 5 000
requétes les plus fréquemment soumises au systeme par les utilisateurs. Notre référence est
constituée de plus d’ 1,4 million de paires de phrases qui contiennent toutes une requéte et une
traduction validée par notre lexique.

Référence humaine. Aﬁn d’entrainer les classiﬁcateurs déciits dans la section 3, quatre anno-
tateurs humains ont été charges d’identiﬁer les mauvais transpots résultant de notre algoiithme
de transpotting. Nous avons décidé d’annoter hors-contexte un peu plus de 12 000 paires re-
quéte/traduction, ce qui permet une annotation rapide5 mais laisse des cas difﬁciles a juger.
Par exemple, dans notre exemple, con f orme a est un transpot pouvant étre facilement classé
comme correct, mais d’autres ne sont pas aussi évidents, comme dans le sens de ou tenir
compte de qui peuvent étre valides en fonction du contexte. Un score kappa de 0,76 témoigne
d’un haut degré d’accord inter-annotateurs.

6 Expériences

6.1 Transpotting

Pour chacune des 1416 000 paires de phrases du corpus REF, nous avons évalué la capacité de
notre algorithme de transpotting décrit dans la section 2.1 a identiﬁer la traduction de référence
t pour une requéte q suivant les mesures de précision et rappel calculées comme suit :

rappel = |tﬂf| / |f| précision = |tﬂf| / |t| (1)

ou t est le transpot identiﬁé par l’algorithme et l’intersection retourne la plus longue séquence
de mots commune a t et t. De facon a calculer ces métriques sur l’intégralité du corpus de
référence, nous moyennons dans un premier temps le rappel et la précision sur l’ensemble des

4http://lucene.apache.org
5De1’ordre de 40 secondes par requéte.

Integration de l’alignement de mots dans le concordancier bilingue TransSearch

paires correspondant a chaque requete q. Dans un second temps, nous moyennons les scores
ainsi obtenus en accordant le meme poids a chaque requéte. La F-mesure est ensuite deduite de
la precision et du rappel calcules sur l’ensemble du corpus.

‘ |precision rappel F-mesure |

transpotting 0,79 0,84 0,81
transpotting + ﬁltrage 0,82 0,90 0,86

TAB. 1 — Resultat du transpotting avant et apres le ﬁltrage du classiﬁcateur sur le corpus REF.
Voir la section 6.2 pour l’explication de la ligne 2.

Notre algorithme de transpotting (ligne 1 du tableau 1) obtient une precision de 0, 79 et un rappel
de 0, 84, qui sont des resultats satisfaisants. La raison pour laquelle la precision est moins bonne
que le rappel est liee au fait qu’assez souvent, la traduction de reference est une sous-sequence
du transpot identiﬁe, comme par exemple dans la ﬁgure 4.

Je crois qu’il est tout a fait conforme é l’esprit du projet de loi.

FIG. 4 — Transpot (souligne) et traduction de reference (en gras) pour la requéte in keeping
with.

6.2 Entrainement des classiﬁcateurs

Comme indique dans la section 3, nous avons entraine plusieurs classiﬁcateurs a reconnaitre les
mauvais transpots. Ces classiﬁcateurs et plusieurs approches na'1'ves (mais tres competitives)
sont evalues suivant le taux d’exemples correctement classiﬁes (TECC). Puisque la tache qui
nous interesse est celle de ﬁltrer les mauvais transpots, nous presentons egalement les taux de
precision et rappel relatifs a cette classe.

Le tableau 2 presente les resultats obtenus avec une validation croisee a 10 blocs. La premiere
approche na'1've utilisee (ligne 1) classiﬁe tous les exemples comme bons. Elle obtient ainsi un
TECC de 0,62, mais n’est d’aucune utilite pour le ﬁltrage. Une approche plus sensee — que
nous avons decouverte apres avoir explore l’utilite des differents ensembles de caracteristiques
— classiﬁe comme mauvais transpots ceux dont le taux de mots grammaticaux est superieur a
0,75. Cette approche obtient un bon TECC de 0,78.

Nous avons commence les experiences en etudiant la contribution de chaque ensemble de ca-
racteristiques avec le voted-perceptron6. Quand le voted-perceptron est entraine en utilisant un
seul ensemble de caracteristiques, celui utilisant uniquement les caracteristiques grammaticales
obtient le meilleur TECC de 0, 79 et une F-mesure de 0,65. Bien que la conﬁguration basee
uniquement sur les caracteristiques issues des modeles d’alignement de mots IBM 2 obtienne
un TECC legerement inferieur (0, 78), nous la considerons comme meilleure en raison de sa
F-mesure de 0,73 qui est plus elevee. La conﬁguration utilisant toutes les caracteristiques pour
representer un exemple ameliore clairement les resultats de l’approche na'1've avec un TECC de
0, 83 et une F-mesure de 0, 77. On peut egalement remarquer qu’alors que la meilleure approche

5Des resultats similaires ont ete observes pour les djfferents ensembles de caracteristiques avec les autres clas-
siﬁcateurs et ne sont pas presentes ici.

Stéphane Huet, J ulien Bourdaillet, Philippe Langlais

mauvais transpots

| Approche l Caractéristiques l TECC préc. rappel F-mes.
na'1've: tous bons 0,62 0,00 0,00 0,00
na'1've: taux mots gram. > 0, 75 0,78 0,88 0,49 0,63
taille 0,73 0,75 0,47 0,58
Votedyerceptron Ig]:.a1\I/innaticales    
toutes 0,83 0,81 0,73 0,77
| Vote majoritaire l l 0,84 l 0,84 0,71 0,77 l

TAB. 2 — Performance des algorithmes de classiﬁcation pour identiﬁer les mauvais transpots.

na'1've obtient une précision plus élevée que celle du meilleur voted-perceptron, ce dernier ob-
tient un rappel et une précision plus équilibrés. Dans la mesure o1‘1 il est difﬁcile de savoir s’il
vaut mieux privilégier la précision ou le rappel dans notre cas, nous préférons maximiser la
F-mesure. En entrainant les autres classiﬁcateurs avec tous les ensembles de caractéristiques,
aucun gain signiﬁcatif n’a été observé. Néanmoins, avec le vote maj oritaire combinant plusieurs
méthodes, nous avons obtenu un meilleur TECC de 0, 84 et une F-mesure de 0,77, comme re-
porté a la derniere ligne du tableau 2.

Avec le meilleur classiﬁcateur obtenu, le vote majoritaire, nous avons évalué l’impact du ﬁl-
trage en utilisant ce classiﬁcateur pour ﬁltrer les résultats du transpotting sur le corpus REF. Les
résultats sont présentés dans le tableau 1 (ligne 2). En supprimant ainsi 7,9 % des transpots, on
peut observer un gain signiﬁcatif en F-mesure qui croit de 0, 81 a 0,86. Le gain le plus impor-
tant est en rappel qui passe de 0, 84 a 0, 90, ce qui signiﬁe que le ﬁltrage élimine principalement
les transpots trop courts. En examinant manuellement les transpots ﬁltrés, nous avons constaté
que les mauvais transpots courts, comme les mots grammaticaux, étaient fréquemment identi-
ﬁés comme mauvais par le classiﬁcateur. Bien que les méthodes de classiﬁcation supervisées
testées n’obtiennent pas d’améliorations majeures par rapport a une l’approche na'1've basée sur
l’observation des mots grammaticaux, les gains signiﬁcatifs constatés par rapport a l’algorithme
initial de transpotting démontrent l’intérét de ﬁltrer les mauvais transpots.

6.3 Regroupement de variantes

Si regrouper les variantes similaires est une fonctionnalité tres intéressante d’un point de vue
ergonoIr1ique, il n’est cependant pas facile de trouver le bon niveau de granularité du regroupe-
ment des transpots7. En conséquence, nous avons étudié deux approches. La premiere méthode
regroupe les variantes qui ne different que par des signes de ponctuation ou qui sont des formes
ﬂéchies d’un méme lemme. Elle est basée sur une distance d’édition, appelée D1, qui utilise les
memes coﬁts d’édition pour les mots grammaticaux et lexicaux. La seconde méthode est plus
laxiste car elle est basée sur une distance d’édition, appelée D2, qui attribue un coﬁt d’édition
moindre aux mots grammaticaux qu’aux mots lexicaux.

En regroupant les transpots obtenus a partir des 5 000 requétes du corpus REF (et ﬁltrés par
notre meilleur classiﬁcateur), la premiere méthode obtient un nombre moyen de 136 clusters

7Ce1a nécessiterait probablement des tests avec des utilisateurs réels.

Integration de l’alignement de mots dans le concordancier bilingue TransSearch

par requete avec D1, alors qu’on a en moyenne 164 transpots par requete (sans regroupement).
Comme attendu, en utilisant D2, on reduit drastiquement le nombre de clusters a 86 par re-
quete. En effet, contrairement a D1, D2 permet de regrouper des variantes similaires comme
sur des années et durant des annees. Toutefois cela conduit occasionnellement a des
regroupements errones comme tout a f ait avec f ait tout.

La ﬁgure 5 presente les 5 transpots les plus frequents obtenus pour deux requetes par l’algo-
rithme de transpotting avec et sans regroupement. Sans le regroupement, on peut observer que
la tendance est de proposer des formes ﬂechies d’une meme traduction. Appliquer le regroupe-
ment conduit a plus de diversite, ce qui est preferable puisque le nombre de variantes pouvant
etre afﬁchees a l’ecran dans Transsearch est limite : nous estimons que l’afﬁchage de 5
transpots sur une meme page est un bon compromis (voir la ﬁgure 1(b)).

sans regroup. decrits decrite decrit tel que decrit comme l’a
regroup. D2 decrits prevu comme l’a tel que prescrit comme le propose
sans regroup. s’est revele s’est avere s’est averee s’est revelee a ete
regroup. D2 s’est revele s’est avere a ete s’est montre a prouve

FIG. 5 — Les 5 transpots les plus frequents pour les requetes as described et has proven
to be avec ou sans regroupement.

Aﬁn de simuler cela, nous avons mesure la diversite des 5 transpots les plus frequents8 proposes
en les considerant comme des sacs d’unigraInmes. Pour cette evaluation, les mots sont lemmati-
ses et les mots grammaticaux sont supprimes. Nous utilisons les mesures de precision et rappel
pour comparer les sacs de mots generes par les methodes de regroupement a ceux de la refe-
rence, celle-ci etant formee a partir de la ressource humaine decrite dans la section 5. Suivant
ces principes, nous avons obtenu une precision de 0,90 et un rappel de 0,43 sans recourir au
regroupement. En construisant des clusters, le rappel a ete signiﬁcativement augmente jusqu’a
0,47 avec D1 et a 0,54 avec D2, alors que la precision est restee sensiblement la meme (0, 89
avec D1 et 0, 86 avec D2). Ces resultats sont correles avec la plus grande diversite obtenue grace
au regroupement de variantes.

7 Discussion

Dans cette etude, nous avons etudie l’amelioration du concordancier bilingue Transsearch
grace a l’alignement de mots. Un algorithme de transpotting a ete propose et evalue. Nous avons
presente deux nouvelles problematiques essentielles au succes de notre nouveau prototype : la
detection des transpots errones et le regroupement des variantes similaires. Nous avons propose
des solutions a ces deux problemes et evalue leur efﬁcacite. En particulier, nous avons montre
qu’il est possible de Inieux detecter les mauvais transpots par rapport a une approche na'1've
competitive, et que le regroupement de variantes ameliore la diversite des transpots proposes.

J usqu’a present il nous a ete difﬁcile de comparer notre approche a d’autres de la communaute.
Cela est dﬁ principalement au caractere unique du systeme Transsearch qui archive une
memoire de traduction consequente. Pour donner un point de comparaison, dans (Callisson-
Burch et al., 2005) les auteurs presentent les resultats d’alignement obtenus pour 120 requetes

8Ces transpots correspondent a la variante la plus frequente de chacun des 5 clusters les plus frequents.

Stéphane Huet, J ulien Bourdaillet, Philippe Langlais

issues d’une mémoire de traduction de 50 000 paires de phrases. Cela reste plusieurs ordres de
grandeur inférieur aux expériences présentées dans cet article.

Nous avons considéré des modeles d’alignements simples dans cette étude. Nous souhaitons
étudier des modeles d’alignement plus précis, dont celui décrit dans (Vogel et al., 1996)

Remerciements

Cette étude est ﬁnancée par le Conseil National de Recherche du Canada, en collaboration avec
l’entreprise canadienne Terminotix.

Références

BOURDAILLET J ., HUET S., GoTTI F., LAPALME G. & LANGLAIS P. (2009). Enhancing
the bilingual concordancer TransSearch with word-level alignment. In 22nd Conference of the
Canadian Society for Computational Studies of Intelligence, Kelowna, Canada.

BROWN P., DELLA PIETRA V., DELLA PIETRA S. & MERCER R. (1993). The mathematics
of statistical machine translation: parameter estimation. Computational Linguistics, 19(2),
263-31 1.

CALLISSON-BURCH C., BANNARD C. & SCHROEDER J . (2005). A compact data structure
for searchable translation memories. In 10th European Conference of the Association for
Machine Translation (EAMT), p. 59-65, Budapest, Hongrie.

CHENNA R., SUGAWARA H., KOIKE T., LOPEZ R., GIBSON T. J ., HIGGINS D. G. &
THOMPSON J . D. (2003). Multiple sequence alignment with the Clustal series of programs.
Nucleic Acids Research, 31(13), 3497-3500.

COLLINS M. (2002). Discriminative training methods for hidden Markov models: theory and
experiments with perceptron algorithms. In EMNLP, p. 1-8, Philadelphie, PA, USA.
FREUND Y. & SCHAPIRE R. (1999). Large margin classiﬁcation using the perceptron algo-
rithm. Machine Learning, 37(3), 277-296.

MACKLOVITCH E., LAPALME G. & GOTTI F. (2008). Transsearch: What are translators
looking for ? In 18th Conference of the Association for Machine Translation in the Americas
(AMTA), p. 412-419, Waikiki, Hawai’i, USA.

PLANAS E. & FURUSE O. (1999). Formalizing translation memories. In 7th Machine Trans-
lation Summit, p. 331-339, Singapour.

SAIOU N. & NEI M. (1987). The neighbor-joining method: A new method for reconstructing
phylogenetic trees. Molecular Biology and Evolution, 4(4), 406-425.

SIMARD M. (2003). Translation spotting for translation memories. In HLT-NAACL 2003
Workshop on Building and using parallel texts.‘ data driven machine translation and beyond,
p. 65-72, Edmonton, Canada.

VERONIS J . & LANGLAIS P. (2000). Evaluation of Parallel text Alignment Systems — The
Arcade Project., chapter 19, p. 369-388. Kluwer Academic Publisher, Dordrecht, Pays-Bas.

VOGEL S., NEY H. & C. T. (1996). HMM-based word alignment in statistical translation. In
16th conference on Computational linguistics, p. 836-841, Copenhague, Danemark.

