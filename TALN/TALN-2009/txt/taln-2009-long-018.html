<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Quel indice pour mesurer l'efficacit&#233; en segmentation de textes?</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009, Senlis, 24-26 juin 2009 
</p>
<p>Quel indice pour mesurer l'efficacit&#233; en segmentation de textes? 
</p>
<p>Yves Bestgen 
</p>
<p>CECL / PSOR &#8211; Universit&#233; catholique de Louvain 
Place du Cardinal Mercier, 10 &#8212; B-1348 Louvain-la-Neuve &#8212; Belgique 
</p>
<p>yves.bestgen@psp.ucl.ac.be 
</p>
<p>R&#233;sum&#233; L'&#233;valuation de l'efficacit&#233; d'algorithmes de segmentation th&#233;matique est 
g&#233;n&#233;ralement effectu&#233;e en quantifiant le degr&#233; d'accord entre une segmentation hypoth&#233;tique 
et une segmentation de r&#233;f&#233;rence. Les indices classiques de pr&#233;cision et de rappel &#233;tant peu 
adapt&#233;s &#224; ce domaine, WindowDiff (Pevzner, Hearst, 2002) s'est impos&#233; comme l'indice de 
r&#233;f&#233;rence. Une analyse de cet indice montre toutefois qu'il pr&#233;sente plusieurs limitations. 
L'objectif de ce rapport est d'&#233;valuer un indice propos&#233; par Bookstein, Kulyukin et Raita 
(2002), la distance de Hamming g&#233;n&#233;ralis&#233;e, qui est susceptible de rem&#233;dier &#224; celles-ci. Les 
analyses montrent que celui-ci conserve tous les avantages de WindowDiff sans les 
limitations. De plus, contrairement &#224; WindowDiff, il pr&#233;sente une interpr&#233;tation simple 
puisqu'il correspond &#224; une vraie distance entre les deux segmentations &#224; comparer. 
</p>
<p>Abstract The evaluation of thematic segmentation algorithms is generally carried out by 
quantifying the degree of agreement between a hypothetical segmentation and a gold 
standard. The traditional indices of precision and recall being little adapted to this field, 
WindowDiff (Pevzner, Hearst, 2002) has become the standard for this kind of assessment. An 
analysis of this index shows however that it presents several limitations. The objective of this 
report is to evaluate an index developed by Bookstein, Kulyukin and Raita (2002), the 
Generalized Hamming Distance, which is likely to overcome these limitations. The analyzes 
show that it preserves all the advantages of WindowDiff without its limitations. Moreover, 
contrary to WindowDiff, it presents a simple interpretation since it corresponds to a true 
distance between the two segmentations. 
</p>
<p>Mots-cl&#233;s : Segmentation th&#233;matique, &#233;valuation, distance de Hamming g&#233;n&#233;ralis&#233;e, 
WindowDiff  
Keywords:   Thematic segmentation, evaluation, generalized Hamming distance, 
WindowDiff 
</p>
<p> </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Yves Bestgen 
</p>
<p>1 &#201;valuation en segmentation th&#233;matique 
La segmentation th&#233;matique de textes a pour objectif de localiser les changements de th&#232;me 
dans des documents. Ce type d&#8217;informations peut permettre l&#8217;am&#233;lioration de diverses 
applications en traitement automatique des langues naturelles comme l&#8217;extraction 
d&#8217;informations, le r&#233;sum&#233; automatique ou encore la navigation &#224; l&#8217;int&#233;rieur de longs textes. 
Une s&#233;rie de recherches ont par exemple mis en &#233;vidence l&#8217;int&#233;r&#234;t de segmenter des textes en 
fonction des th&#232;mes qu&#8217;ils abordent afin d&#8217;am&#233;liorer les r&#233;sultats de proc&#233;dures d&#8217;extraction 
d&#8217;informations (Hearst, 1997 ; Prince, Labadi&#233;, 2007). Ces derni&#232;res ann&#233;es, de nombreux 
algorithmes de segmentation th&#233;matique, bas&#233;s principalement sur la coh&#233;sion lexicale, ont 
&#233;t&#233; propos&#233;s (p.ex., Choi, 2000 ; Ferret, 2002 ; Hearst, 1997 ; Ponte, Croft, 1997 ; Utiyama, 
Isahara, 2001) rendant encore plus important les probl&#232;mes que pose leur &#233;valuation. 
</p>
<p>Si quelques recherches ont &#233;valu&#233; les performances d&#8217;une proc&#233;dure de segmentation sur la 
base des b&#233;n&#233;fices qu&#8217;elle apporte &#224; l&#8217;application pour laquelle elle a &#233;t&#233; con&#231;ue (Bellot, El-
B&#232;ze, 2001 ; Prince, Labadi&#233;, 2007), la majorit&#233; des chercheurs proc&#232;dent en comparant la 
segmentation postul&#233;e &#224; une norme cens&#233;e correspondre &#224; la vraie segmentation du texte1. 
Pour d&#233;terminer cette norme, deux approches sont principalement employ&#233;es. La premi&#232;re 
consiste &#224; demander &#224; des juges d&#8217;effectuer la m&#234;me t&#226;che que l&#8217;algorithme et donc &#224; 
segmenter des textes de diverses origines (Bestgen, Pi&#233;rard, 2006 ; Hearst, 1997). La seconde 
s&#8217;appuie sur un mat&#233;riel artificiel obtenu en concat&#233;nant des textes, les changements de th&#232;me 
&#224; identifier correspondant aux fronti&#232;res entre ceux-ci. Cette seconde approche s&#8217;est tr&#232;s 
largement impos&#233;e en raison de l&#8217;existence d&#8217;un mat&#233;riel de r&#233;f&#233;rence (Choi, 2000), qui 
permet de comparer les performances de tout nouvel algorithme &#224; celles des algorithmes 
consid&#233;r&#233;s comme les plus efficaces selon la litt&#233;rature.  
</p>
<p>Quelle que soit l'origine de la norme, l'&#233;valuation requiert un indice pour mesurer le degr&#233; 
d'accord entre la segmentation propos&#233;e par l'algorithme et la segmentation de r&#233;f&#233;rence. 
Depuis quelques ann&#233;es, le taux d'erreur WindowDiff (Pevzner, Hearst, 2002), sur la base 
d'une analyse critique de l'indice Pk (Beeferman et al., 1999), s'est impos&#233;. Cet indice 
pr&#233;sente toutefois plusieurs faiblesses. Sa pr&#233;sentation et la discussion de ses limitations font 
l'objet des deux sections suivantes. La quatri&#232;me section pr&#233;sente la distance de Hamming 
g&#233;n&#233;ralis&#233;e, propos&#233;e par Bookstein et al. (2002), qui, comme l'indique la cinqui&#232;me section, 
r&#233;pond &#224; ces limitations tout en conservant les avantages de WindowDiff par rapport &#224; Pk. 
</p>
<p>2 Indices pour mesurer l&#8217;efficacit&#233; d'un algorithme 
D&#232;s les premi&#232;res recherches en segmentation th&#233;matique, les indices classiques en extraction 
d'information que sont le rappel et la pr&#233;cision ont &#233;t&#233; critiqu&#233;s parce qu'ils ne font aucune 
diff&#233;rence entre des erreurs l&#233;g&#232;res, comme le fait de placer une fronti&#232;re juste &#224; c&#244;t&#233; de la 
position attendue, par comparaison aux erreurs plus graves, comme placer une fronti&#232;re &#224; une 
grande distance de cette position attendue, manquer une fronti&#232;re (faux n&#233;gatif) ou en ajouter 
une (faux positif). Pour cette raison, des indices d'efficacit&#233; sp&#233;cifiques &#224; ce champ de 
recherches ont &#233;t&#233; propos&#233;s. Le premier &#224; avoir fait l&#8217;objet d&#8217;un consensus est le taux d'erreur 
                                                
1  R&#233;cemment, Lamprier et al. (2007) ont propos&#233; de se passer de toute segmentation de r&#233;f&#233;rence en basant 
</p>
<p>l'&#233;valuation sur la stabilit&#233; de la segmentation postul&#233;e aux permutations des unit&#233;s internes aux segments. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Quel indice pour mesurer l'efficacit&#233; en segmentation de textes? 
</p>
<p>Pk (Beeferman et al., 1999). Une analyse critique par Pevzner et Hearst (2002) a soulign&#233; son 
int&#233;r&#234;t par rapport aux indices classiques de pr&#233;cision et de rappel, mais &#233;galement plusieurs 
de ces limitations. Afin d'y rem&#233;dier, Pevzner et Hearst (2002) ont propos&#233; une version 
modifi&#233;e de Pk qu'ils ont appel&#233; WindowDiff (WD) et qu'ils formulent2 comme suit 
</p>
<p>! 
</p>
<p>WD(ref ,hyp) =
1
</p>
<p>N &quot; k
b(refi,refi+k ) &quot; b(hypi,hypi+k ) &gt; 0( )
</p>
<p>1
</p>
<p>N&quot;k
</p>
<p>#  
</p>
<p>o&#249; b(i, j) repr&#233;sente le nombre de fronti&#232;res entre les positions i et j, N le nombre de positions, 
k correspond &#224; la moiti&#233; de la longueur moyenne d&#8217;un segment dans l&#8217;annotation de 
r&#233;f&#233;rence3. On peut d&#233;crire le fonctionnement de WD de la mani&#232;re suivante. Une fen&#234;tre de 
taille k est d&#233;plac&#233;e tout au long des unit&#233;s minimales de segmentation d&#8217;un texte 
(habituellement les phrases). Pour chaque position de la fen&#234;tre, on compare le nombre de 
fronti&#232;res de segments que celle-ci englobe selon la norme de r&#233;f&#233;rence au nombre de 
fronti&#232;res d&#233;tect&#233;es par l&#8217;algorithme. Celui-ci est p&#233;nalis&#233; d&#8217;un point chaque fois que ces 
nombres sont diff&#233;rents. Le d&#233;nominateur permet d&#8217;obtenir un score WD compris entre 0 et 1. 
S&#8217;agissant d&#8217;une mesure d&#8217;erreur, plus sa valeur est proche de 0, meilleure est la performance. 
</p>
<p> 
</p>
<p>Figure 1 : Exemple de calcul de WD (adapt&#233; de Pevzner et Hearst, 2002). 
</p>
<p>La figure 1 illustre le fonctionnement de cet indice. Les unit&#233;s minimales d&#8217;un texte y sont 
repr&#233;sent&#233;es par des chiffres qui traduisent la segmentation selon la norme de r&#233;f&#233;rence. La 
segmentation hypoth&#233;tique met en &#233;vidence deux ruptures, l&#8217;une identique &#224; une de celles 
mises en &#233;vidence par la norme de r&#233;f&#233;rence et l&#8217;autre non. Il est n&#233;cessaire de d&#233;finir ici trois 
types d'erreurs. La non-identification par la segmentation hypoth&#233;tique de la fronti&#232;re entre D 
et E est appel&#233;e un faux n&#233;gatif. L'ajout erron&#233; par la segmentation hypoth&#233;tique d'une 
fronti&#232;re entre D2 et D3 peut &#234;tre consid&#233;r&#233; de deux mani&#232;res diff&#233;rentes. On peut le voir 
comme un faux positif, c'est-&#224;-dire l'ajout dans la segmentation hypoth&#233;tique d'une rupture qui 
n'existe pas dans celle de r&#233;f&#233;rence. On peut aussi le voir comme une erreur l&#233;g&#232;re si on 
</p>
<p>                                                
2  Une autre formule, prenant en compte le nombre de diff&#233;rences entre les deux segmentations et non la 
</p>
<p>dichotomisation de ce nombre, est parfois (mais rarement) employ&#233;e, m&#234;me si elle ne correspond pas &#224; la 
formule originale de Pevzner et Hearst (2002). 
</p>
<p>3  Cette valeur a &#233;t&#233; propos&#233;e par Beeferman et al. (1999) et reprise par Pevzner et Hearst (2002) parce qu'elle 
permet d'attribuer des scores m&#233;diocres et relativement similaires aux algorithmes d&#233;g&#233;n&#233;r&#233;s les plus 
courants comme ceux qui ne segmentent jamais ou chaque fois que possible. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Yves Bestgen 
</p>
<p>consid&#232;re qu'il s'agit de la rupture pr&#233;sente entre D et E dans la segmentation de r&#233;f&#233;rence, 
mais que la segmentation hypoth&#233;tique ne l'a pas plac&#233;e exactement au m&#234;me endroit. Cette 
seconde interpr&#233;tation impose de revoir celle qui fait de la non-identification de la fronti&#232;re 
entre D et E un cas de faux n&#233;gatif. 
</p>
<p>Pour un param&#232;tre k &#233;gal &#224; 4, les traits horizontaux traduisent le d&#233;placement de la fen&#234;tre 
mobile. Les trois premiers traits (verts et continus) signalent des fen&#234;tres pour lesquelles les 
deux segmentations sont d&#8217;accord puisqu&#8217;elles marquent le m&#234;me nombre de ruptures (0 ou 
1). Les traits discontinus et rouges signalent des points de d&#233;saccord : les deux extr&#233;mit&#233;s de 
la fen&#234;tre mobile ne sont pas s&#233;par&#233;es par le m&#234;me nombre de ruptures selon les deux 
segmentations. Elles p&#233;nalisent donc la segmentation hypoth&#233;tique. 
</p>
<p>Afin de d&#233;montrer les avantages de WD par rapport &#224; Pk, Pevzner et Hearst (2002) ont men&#233; 
une s&#233;rie de simulations dans lesquelles la fluctuation de la longueur des segments ainsi que 
la proportion et la gravit&#233; des diff&#233;rents types d'erreurs &#233;taient manipul&#233;es. Il en r&#233;sulte que, 
contrairement &#224; Pk, WD p&#233;nalise de mani&#232;re &#233;quivalente les faux positifs et les faux n&#233;gatifs, 
qu'il p&#233;nalise moins les erreurs l&#233;g&#232;res que les faux positifs de m&#234;me ampleur et que, s'il reste 
sensible &#224; la fluctuation de la taille des segments, il l'est nettement moins que Pk. 
</p>
<p>M&#234;me si de nombreux chercheurs continuent &#224; rapporter Pk dans leur analyse afin de faciliter 
la comparaison avec les &#233;tudes ant&#233;rieures &#224; 2002, WD s'est impos&#233; comme l'indice de 
r&#233;f&#233;rence. Son importance pour l'&#233;valuation en segmentation th&#233;matique a encore &#233;t&#233; 
r&#233;cemment renforc&#233;e par Artstein et Poesio (2008) qui recommandent son emploi pour 
mesurer l'accord entre les juges afin de prendre en compte le fait que les juges, comme les 
proc&#233;dures automatiques, peuvent d&#233;tecter les diff&#233;rents th&#232;mes tout en se trompant sur la 
localisation exacte de leurs fronti&#232;res (pour une analyse de cette recommendation, voir 
Bestgen, 2009).  
</p>
<p>3 Limitations de WindowDiff  
Malgr&#233; les avantages qu'il apporte par rapport &#224; Pk, WindowDiff a fait l'objet de plusieurs 
critiques. Lamprier et al. (2007) ont fait remarquer que WD, comme Pk, p&#233;nalise 
diff&#233;remment les erreurs selon leur position dans le texte. Les erreurs qui se produisent &#224; 
moins de k positions du d&#233;but d'un texte ou de sa fin sont p&#233;nalis&#233;es moins lourdement que 
celles qui se produisent entre ces deux bornes. Georgescul et al. (2006) ont soulign&#233; que 
l'interpr&#233;tation des valeurs produites par WD n'est pas plus &#233;vidente que celle de Pk parce que 
ces indices ne refl&#232;tent pas directement l'efficacit&#233; de l'algorithme. 
</p>
<p>WD pr&#233;sente deux autres probl&#232;mes, h&#233;rit&#233;s de Pk. Tout d'abord, une erreur l&#233;g&#232;re (telle que 
d&#233;finie &#224; la section 2) qui se produit &#224; une distance inf&#233;rieure &#224; k de la vraie fronti&#232;re, mais 
sup&#233;rieure &#224; k/2, est plus p&#233;nalis&#233;e qu'un faux positif pur (&#233;loign&#233; de toute segmentation dans 
la norme). En effet, celui-ci re&#231;oit une p&#233;nalit&#233; de k, alors qu'une erreur l&#233;g&#232;re re&#231;oit une 
p&#233;nalit&#233; sup&#233;rieure &#224; k puisqu'&#233;gale au double de sa distance &#224; la vraie fronti&#232;re. Cette 
situation est d'autant plus probl&#233;matique que WD a &#233;t&#233; d&#233;velopp&#233; dans le but de r&#233;duire les 
p&#233;nalit&#233;s attribu&#233;es &#224; des erreurs l&#233;g&#232;res.  
</p>
<p>Un second probl&#232;me, mentionn&#233; par Pevzner et Hearst (2002), est que deux ou plus faux 
positifs qui sont proches les uns des autres (&#224; une distance inf&#233;rieure &#224; k) sont moins p&#233;nalis&#233;s 
que s'ils se produisent &#224; des distances sup&#233;rieures &#224; k. Il en est de m&#234;me de deux ou plus faux 
n&#233;gatifs qui sont proches les uns des autres.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Quel indice pour mesurer l'efficacit&#233; en segmentation de textes? 
</p>
<p>On notera enfin, comme le signalent Pevzner et Hearst (2002), que si WD est moins sensible &#224; 
la fluctuation des longueurs de segments que Pk, il reste n&#233;anmoins affect&#233; par celle-ci. 
</p>
<p>4 La distance de Hamming g&#233;n&#233;ralis&#233;e : un indice plus efficace? 
L'objectif majeur de cette &#233;tude est d'&#233;valuer un indice susceptible de r&#233;pondre aux limitations 
pr&#233;sent&#233;es par WD tout en conservant ses avantages par rapport &#224; Pk : la distance de 
Hamming g&#233;n&#233;ralis&#233;e propos&#233;e, ind&#233;pendamment du d&#233;veloppement de Pk et de WD, par 
Bookstein et al. (2002). Ces auteurs se sont int&#233;ress&#233;s &#224; la mesure de la distance entre des 
vecteurs binaires de m&#234;mes longueurs. Ce genre de donn&#233;es s'obtient en traitement du signal, 
mais aussi en segmentation th&#233;matique o&#249; la pr&#233;sence d'une fronti&#232;re entre deux unit&#233;s 
minimales peut-&#234;tre cod&#233;e par un &quot;1&quot; et l'absence de fronti&#232;re par un &quot;0&quot;.  Pour ce type de 
donn&#233;es, une mesure classique est la distance de Hamming (ici appliqu&#233;e &#224; des donn&#233;es 
binaires) qui est bas&#233;e sur le nombre de bits qu'il est n&#233;cessaire de modifier pour transformer 
une s&#233;quence en une autre. Consid&#233;r&#233;e comme une forme particuli&#232;re de distance d'&#233;dition, 
elle correspond au co&#251;t minimal des op&#233;rations n&#233;cessaires pour effectuer cette 
transformation lorsque les deux seules op&#233;rations autoris&#233;es sont :  
&#8211; l'op&#233;ration d'insertion qui change un 0 en 1 pour un co&#251;t Ci = 1 ; 
&#8211; l'op&#233;ration de suppression qui change un 1 en 0 pour un co&#251;t Cs = 1.  
Les termes insertion et suppression sont, comme le soulignent Bookstein et al. (2002), 
employ&#233;s dans un sens diff&#233;rent de celui utilis&#233; habituellement dans les travaux sur la 
manipulation de cha&#238;nes de caract&#232;res puisque ni l'insertion, ni la suppression ne modifient la 
taille de la cha&#238;ne.  
</p>
<p>Dans sa version originale, la distance de Hamming pr&#233;sente la m&#234;me limitation que les 
indices de pr&#233;cision et de rappel puisqu'elle se base exclusivement sur l'accord ou le 
d&#233;saccord entre deux bits. Pour d&#233;passer cette limitation, Bookstein et al. (2002) proposent 
d'adjoindre une troisi&#232;me op&#233;ration :  
&#8211; l'op&#233;ration de d&#233;placement qui fait glisser un &quot;1&quot; vers la gauche ou vers la droite de la 
</p>
<p>s&#233;quence afin de le mettre en correspondance avec un &quot;1&quot; dans l'autre s&#233;quence. Le co&#251;t de 
cette op&#233;ration (Cd) est une fonction strictement positive et monotoniquement croissante 
de la longueur du d&#233;placement n&#233;cessaire.  
</p>
<p>La distance de Hamming g&#233;n&#233;ralis&#233;e (DHG) correspond au co&#251;t minimum pour transformer 
une s&#233;quence en l'autre au moyen de ces trois op&#233;rations. Bookstein et al. (2002) montrent 
que DHG est une vraie distance en ce sens qu'elle en pr&#233;sente toutes les propri&#233;t&#233;s lorsque les 
co&#251;ts des diff&#233;rentes op&#233;rations remplissent certaines conditions. C'est tout particuli&#232;rement le 
cas lorsque Ci = Cs &gt; 0 et que le co&#251;t total d'un d&#233;placement est proportionnel &#224; la longueur 
de celui-ci. En divisant le co&#251;t minimal par la longueur des s&#233;quences, on obtient une mesure 
relative dont le minimum est 0 alors que le maximum d&#233;pend des co&#251;ts attribu&#233;s aux 
diff&#233;rentes op&#233;rations. 
</p>
<p>La figure 2 pr&#233;sente l'application de DHG &#224; l'exemple de segmentation d&#233;j&#224; employ&#233; &#224; la 
figure 1 sur la base des co&#251;ts suivants : Ci = Cs = 2 et Cd = 1.  Ci et Cs ont une valeur &#233;gale &#224; 
celle de k/2 de sorte que pour qu'un d&#233;placement soit plus avantageux qu'une insertion et une 
suppression, sa longueur doit &#234;tre inf&#233;rieure &#224; k, soit &#224; la moiti&#233; de la longueur d'un segment 
dans la segmentation de r&#233;f&#233;rence. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Yves Bestgen 
</p>
<p>Bookstein et al. (2002) proposent un algorithme qui permet de calculer DHG en fonction des 
p&#233;nalit&#233;s attribu&#233;es &#224; chaque op&#233;ration. Cet algorithme a &#233;t&#233; impl&#233;ment&#233; en C++ par Vladimir 
Kulyukin (www.cs.usu.edu/~vkulyukin/vkweb/software/ghd/ghd.html). Jiang (2009) propose 
un algorithme plus rapide. 
</p>
<p> 
</p>
<p>Figure 2 : Exemple de calcul de DHG. 
</p>
<p>5 &#201;valuation compar&#233;e de WD et de DHG 
Bien que Bookstein et al. (2002) mentionnent la segmentation de texte comme un domaine 
d'application de leur distance, aucune &#233;tude n'a, &#224; ma connaissance4, compar&#233; DHG &#224; WD. 
Une analyse des propri&#233;t&#233;s de DHG montre qu'il est une alternative int&#233;ressante &#224; WD. On 
notera en premier lieu qu'il pr&#233;sente les m&#234;mes avantages que WD par rapport &#224; Pk. Lorsque 
Ci = Cs, les faux positifs et les faux n&#233;gatifs sont p&#233;nalis&#233;s de la m&#234;me mani&#232;re. De plus, 
toutes les erreurs sont p&#233;nalis&#233;es, qu'elles soient proches ou &#233;loign&#233;es les unes des autres. 
</p>
<p>DHG r&#233;pond aussi, de par sa construction, &#224; plusieurs des critiques formul&#233;es &#224; l'encontre de 
WD. Tout d'abord, la position d'une erreur dans la s&#233;quence, au tout d&#233;but, au milieu ou &#224; la 
fin, n'a aucun impact sur la p&#233;nalit&#233; encourue. Ensuite, DHG a une interpr&#233;tation simple et 
directe puisqu'il s'agit d'une vraie distance qui correspond au co&#251;t minimal des op&#233;rations 
n&#233;cessaires pour transformer une segmentation en l'autre. Ces op&#233;rations prennent en compte 
la sp&#233;cificit&#233; de l'&#233;valuation en segmentation th&#233;matique en distinguant une erreur grave 
comme un faux n&#233;gatif et un faux positif, d'une erreur plus l&#233;g&#232;re comme placer une fronti&#232;re 
&#224; une faible distance de la position attendue.  
</p>
<p>Enfin, DHG r&#233;pond aux deux autres critiques adress&#233;es &#224; WD. Il est en effet impossible que 
cet indice p&#233;nalise plus une erreur l&#233;g&#232;re qu'un faux positif (ou qu'un faux n&#233;gatif) puisque 
dans ce cas, c'est l'op&#233;ration de suppression (ou d'insertion) qui sera choisie afin d'obtenir le 
co&#251;t minimal. De m&#234;me, les faux positifs re&#231;oivent toujours la m&#234;me p&#233;nalit&#233; quelle que soit 
la distance entre eux puisque le co&#251;t est toujours identique &#224; Cs.  
</p>
<p>Afin de confirmer ces analyses, une &#233;valuation comparative de WD et de DHG, ainsi que de 
Pk, a &#233;t&#233; r&#233;alis&#233;e au moyen des deux simulations les plus importantes d&#233;crites dans Pevzner et 
Hearst (2002). Pour chaque simulation, 10 segmentations de r&#233;f&#233;rences, chacune compos&#233;e de 
1000 segments d'une longueur moyenne de 25 unit&#233;s sont g&#233;n&#233;r&#233;es al&#233;atoirement et pour 
                                                
4  Ant&#233;rieurement au d&#233;veloppement de WD et de DHG, Ponte et Croft (1997) ont employ&#233; pour &#233;valuer leur 
</p>
<p>algorithme de segmentation un indice bas&#233; sur les op&#233;rations d'&#233;dition. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Quel indice pour mesurer l'efficacit&#233; en segmentation de textes? 
</p>
<p>chacune de celles-ci 100 segmentations hypoth&#233;tiques sont g&#233;n&#233;r&#233;es et compar&#233;es &#224; celle de 
r&#233;f&#233;rence au moyen des trois indices Pk, WD et DHG, les r&#233;sultats finaux correspondants aux 
moyennes pour les 1000 essais.   
</p>
<p>5.1 Effet de la fluctuation de la longueur des segments 
</p>
<p>La premi&#232;re s&#233;rie de simulations a pour objectif d'&#233;valuer l'impact de la fluctuation des 
longueurs de segments sur les taux d'erreurs. Dans chaque simulation, les segmentations de 
r&#233;f&#233;rence sont g&#233;n&#233;r&#233;es sur la base de longueurs de segments uniform&#233;ment distribu&#233;es entre 
deux valeurs &#224; &#233;gale distance de la longueur moyenne de 25. Ces valeurs sont [20, 30], [15, 
35], [10, 40] et [5, 45]. Les segmentations hypoth&#233;tiques sont quant &#224; elles g&#233;n&#233;r&#233;es selon 
trois types de distribution d'erreurs diff&#233;rents : 
&#8211; FN: une segmentation avec une probabilit&#233; d'occurrence d'un faux n&#233;gatif de 0.5 &#224; chaque 
</p>
<p>fronti&#232;re r&#233;elle.  
&#8211; FP1: une segmentation avec une probabilit&#233; d'occurrence d'un faux positif de 0.5 dans 
</p>
<p>chaque segment, les faux positifs &#233;tant uniform&#233;ment distribu&#233;s dans ceux-ci.  
&#8211; FNP1: une segmentation qui combine les deux pr&#233;c&#233;dentes et donc les deux types 
</p>
<p>d'erreurs.  
</p>
<p>Le sch&#233;ma de co&#251;ts attribu&#233;s aux diff&#233;rentes op&#233;rations pour le calcul de DHG correspond &#224; 
celui propos&#233; dans la section 4, sauf que les trois valeurs ont &#233;t&#233; multipli&#233;es par 2 (Cd=2 et 
Ci=Cs=k) de fa&#231;on &#224; faciliter la comparaison entre WD et DHG car ceci permet d'&#233;galiser le 
co&#251;t pour DHG d'un faux positif pur (&#233;loign&#233; de toute segmentation dans la norme) et d'un 
faux n&#233;gatif pur &#224; la p&#233;nalit&#233; encourue par ces m&#234;mes erreurs selon WD puisque celle-ci est 
de k. Le param&#232;tre k a &#233;t&#233; fix&#233; &#224; 12 afin d'obtenir les valeurs les plus similaires possibles &#224; 
celles rapport&#233;es par Pevzner et Hearst (2002). 
</p>
<p> FN FP1 FNP1 
</p>
<p> 20-30 15-35 10-40 5-45 20-30 15-35 10-40 5-45 20-30 15-35 10-40 5-45 
</p>
<p>Pk .240 .240 .237 .218 .128 .122 .112 .106 .314 .305 .288 .266 
</p>
<p>WD .240 .240 .239 .233 .236 .235 .235 .232 .370 .364 .353 .339 
</p>
<p>DHG .240 .240 .240 .240 .240 .240 .240 .240 .378 .373 .367 .356 
</p>
<p>Tableau 1 : Valeurs moyennes de Pk, WD et DHG pour la premi&#232;re s&#233;rie de simulations 
</p>
<p>Comme l'indique le tableau 1, WD est moins fortement affect&#233; par la fluctuation des 
longueurs des segments que Pk, un r&#233;sultat attendu. Plus int&#233;ressant est le fait que DHG est 
encore moins affect&#233; par cette fluctuation. Pour quantifier objectivement cette diff&#233;rence, des 
analyses de variance &#224; un facteur (fluctuation) ont &#233;t&#233; effectu&#233;es. Ces analyses permettent de 
d&#233;terminer la part de variance expliqu&#233;e (aussi appel&#233;e R-carr&#233;) qu'apporte la connaissance 
des niveaux de fluctuation pour pr&#233;dire les trois indices (Howell, 2008, pp. 336-338). Cette 
part de variance correspond au rapport entre la variabilit&#233; des valeurs moyennes d'un indice en 
fonction du facteur fluctuation (variabilit&#233; inter-niveaux) et la variabilit&#233; totale de l'indice, qui 
inclut la variabilit&#233; inter-niveaux et la variabilit&#233; &#224; l'int&#233;rieur de chaque niveau de fluctuation 
(variabilit&#233; intra-niveau). Plus ce rapport est proche de 1, plus l'indice en question est sensible </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Yves Bestgen 
</p>
<p>&#224; la fluctuation des longueurs des segments. Comme le montre le tableau 2, ces parts de 
variance sont &#224; chaque fois les plus faibles pour DHG. Lorsqu'on compare, dans le tableau 1, 
les r&#233;sultats pour les faux n&#233;gatifs et les faux positifs, on observe que DHG et WD se 
comportent d'une mani&#232;re similaire, mais diff&#233;rente de Pk qui sous-p&#233;nalise nettement les 
faux positifs comme le pr&#233;dit l'analyse de Pevzner et Hearst (2002).  
</p>
<p>Pk WD DHG 
</p>
<p>FN FP1 FNP1 FN FP1 FNP1 FN FP1 FNP1 
</p>
<p>.58 .76 .84 .13 .03 .69 .00 .00 .48 
</p>
<p>Tableau 2 : Parts de variance expliqu&#233;es par le facteur fluctuation pour les trois indices.  
</p>
<p>5.2 Effet du type de distribution des erreurs 
</p>
<p>La seconde s&#233;rie de simulations vise &#224; &#233;valuer l'impact de diff&#233;rentes distributions d'erreurs 
sur les indices. Pour celles-ci, Pevzner et Hearst (2002) ont choisi de n'employer qu'un seul 
niveau de fluctuation de la longueur moyenne des segments, celui allant de 15 &#224; 35. Sept 
distributions d'erreurs ont &#233;t&#233; &#233;valu&#233;es, dont trois sont communes avec les premi&#232;res 
simulations (FN, FP1 et FNP1). Les quatre distributions suppl&#233;mentaires sont :  
&#8211; FP2: une segmentation avec une probabilit&#233; d'occurrence d'un faux positif de 0.5 dans 
</p>
<p>chaque segment, les faux positifs &#233;tant distribu&#233;s autour des fronti&#232;res des segments selon 
une distribution normale avec un &#233;cart-type &#233;gal &#224; &#188; de la longueur du segment.  
</p>
<p>&#8211; FP3: une segmentation avec des faux positifs distribu&#233;s uniform&#233;ment dans l'ensemble de 
la s&#233;quence, la probabilit&#233; d'occurrence d'un faux positif en chaque position possible &#233;tant 
de 0.02, ce qui correspond &#224; une probabilit&#233; d'occurrence dans chaque segment de 0.5.  
</p>
<p>&#8211; FNP2: combine FN et FP2.  
&#8211; FNP3: combine FN et FP3.  
</p>
<p> FN FP1 FP2 FP3 FNP1 FNP2 FNP3 
</p>
<p>Pk .240 .122 .096 .116 .305 .268 .306 
</p>
<p>WD .240 .235 .232 .215 .364 .340 .361 
</p>
<p>DHG .240 .240 .240 .240 .373 .350 .385 
</p>
<p>Tableau 3 : Valeurs moyennes de Pk, WD et DHG pour la deuxi&#232;me s&#233;rie de simulations 
</p>
<p>Le tableau 3 montre, comme attendu, que Pk se comporte tr&#232;s diff&#233;remment de DHG alors 
que celui-ci donne lieu &#224; des r&#233;sultats tr&#232;s semblables &#224; ceux de WD. La principale diff&#233;rence 
entre ceux-ci porte sur les valeurs obtenues pour FP3. WD consid&#232;re que cette distribution 
d'erreurs est meilleure que FP2 et FP1 alors que DHG consid&#232;re que les trois distributions FPx 
sont &#233;quivalentes. Comme l'indiquent Pevzner et Hearst (2002, p. 33), WD sous-p&#233;nalise FP3 
parce que c'est dans ce genre de distributions que des faux positifs ont le plus de chance de se 
produire les uns pr&#232;s des autres et donc d'&#234;tre sous-p&#233;nalis&#233;s. Pour DHG, ces trois </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Quel indice pour mesurer l'efficacit&#233; en segmentation de textes? 
</p>
<p>distributions d'erreurs donnent lieu &#224; un m&#234;me nombre d'op&#233;rations de suppression et donc &#224; 
un m&#234;me co&#251;t total.  
</p>
<p>Les distributions FNPx m&#233;ritent aussi une attention toute particuli&#232;re. FNP3 g&#233;n&#232;re, par 
construction, les plus mauvaises segmentations. Cette distribution d'erreurs inclut, comme les 
deux autres, 50% de faux n&#233;gatifs et un pourcentage &#233;quivalent de faux positifs, mais la 
distribution de ceux-ci n'est pas construite pour favoriser les erreurs l&#233;g&#232;res puisque les faux 
positifs sont uniform&#233;ment distribu&#233;s. De ce point de vue, FNP2 est la moins mauvaise des 
distributions, puisque c'est celle qui maximise les chances que les faux positifs soient les plus 
proches des faux n&#233;gatifs, et FNP1 est interm&#233;diaire. Si WD identifie correctement l'avantage 
de FNP2 par rapport aux deux autres, il consid&#232;re que FNP3 est meilleur que FNP1 (parce 
qu'il sous-p&#233;nalise FNP3 pour la m&#234;me raison qu'il sous-p&#233;nalise FP3). DHG ne commet pas 
cette erreur et met nettement plus en &#233;vidence les diff&#233;rences.  
</p>
<p>6 Conclusion 
L'objectif de cette recherche &#233;tait d'&#233;valuer les indices qui permettent de mesurer l'efficacit&#233; 
d'algorithmes de segmentation th&#233;matique. Tout particuli&#232;rement, la distance de Hamming 
g&#233;n&#233;ralis&#233;e (DHG), propos&#233;e par Bookstein et al. (2002), est d&#233;crite et compar&#233;e &#224; l'indice le 
plus fr&#233;quemment employ&#233; dans ce genre de recherche, WindowDiff (WD) de Pevzner et 
Hearst (2002). L'analyse des propri&#233;t&#233;s de DHG montre qu'il conserve tous les avantages que 
WD pr&#233;sente par rapport &#224; son pr&#233;d&#233;cesseur, Pk, sans les limitations que ces deux-ci 
partagent. Il faut toutefois noter que, dans les simulations r&#233;alis&#233;es, les diff&#233;rences entre DHG 
et WD sont relativement faibles.  Ce r&#233;sultat n'est pas &#233;tonnant parce que les simulations 
utilis&#233;es ont &#233;t&#233; propos&#233;es par Pevzner et Hearst (2002) pour confronter WD &#224; Pk et n'ont 
donc pas &#233;t&#233; con&#231;ues en fonction des diff&#233;rences entre DHG et WD. Des exp&#233;riences 
compl&#233;mentaires sont n&#233;cessaires. Toutefois, m&#234;me si on devait juger que les am&#233;liorations 
apport&#233;es par DHG sont insuffisantes pour justifier un changement d'indice de r&#233;f&#233;rence, un 
apport de cette &#233;tude est de proposer pour WindowDiff une interpr&#233;tation plus simple que celle 
donn&#233;e par Pevzner et Hearst (2002). En effet, ce raisonnement conduit &#224; consid&#233;rer que 
WindowDiff approxime une vraie distance entre les deux segmentations &#224; comparer, distance 
qui correspond au co&#251;t minimal des op&#233;rations n&#233;cessaires pour transformer la segmentation 
propos&#233;e par l'algorithme en la segmentation de r&#233;f&#233;rence. Si, par contre, on consid&#232;re que la 
distance de Hamming g&#233;n&#233;ralis&#233;e vaut la peine d'&#234;tre adopt&#233;e, il sera n&#233;cessaire de mener des 
analyses approfondies de l'impact des co&#251;ts attribu&#233;s aux op&#233;rations sur les valeurs obtenues, 
et ce, entre autres, par des algorithmes &quot;d&#233;g&#233;n&#233;r&#233;s&quot;. Comparer dans ce type de situations WD, 
DHG, mais aussi l'indice de stabilit&#233; propos&#233; par Lamprier et al. (2007), serait tr&#232;s informatif.  
</p>
<p>Remerciements 
Yves Bestgen est chercheur qualifi&#233; du F.R.S-FNRS. Il tient &#224; remercier les experts pour leurs 
commentaires. 
</p>
<p>R&#233;f&#233;rences 
ARTSTEIN R., POESIO M. (2008). Inter-coder agreement for computational linguistics. 
Computational Linguistics 34,  555&#8211;596. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Yves Bestgen 
</p>
<p>BEEFERMAN D., BERGER A., LAFFERTY J. (1999). Statistical models for text segmentation, 
Machine Learning 34, 177&#8211;210. 
</p>
<p>BELLOT  P., EL-BEZE M. (2001). Classification et segmentation de textes par arbres de 
d&#233;cision. Application &#224; la recherche documentaire. Technique et science informatiques 20, 
107&#8211;134. 
</p>
<p>BESTGEN  Y. (2009). Jugements humains et &#233;valuation des algorithmes de segmentation 
th&#233;matique : application de WindowDiff. Actes de EvalECD'09, 15-24. 
</p>
<p>BESTGEN  Y., PIERARD  S. (2006). Comment &#233;valuer les algorithmes de segmentation 
automatique? Essai de construction d'un mat&#233;riel de r&#233;f&#233;rence. Actes de TALN'06, 407-414. 
</p>
<p>BOOKSTEIN A., KULYUKIN V.A., RAITA T. (2002). Generalized Hamming distance. 
Information Retrieval 5, 353&#8211;375. 
</p>
<p>CHOI F. (2000). Advances in domain independent linear text segmentation, Proceedings of 
NAACL-00, 26&#8211;33. 
</p>
<p>FERRET O. (2002). Using collocations for topic segmentation and link detection. Proceedings 
of COLING 2002, 260-266. 
</p>
<p>GEORGESCUL M., CLARK A., ARMSTRONG S. (2006). An analysis of quantitative aspects in 
the evaluation of thematic segmentation algorithms. Proceedings of SIGdial'06, 144&#8211;151. 
</p>
<p>HEARST M. (1997). TextTiling: Segmenting text into multi-paragraph subtopic passages. 
Computational Linguistics 23, 33&#8211;64.  
</p>
<p>HOWELL D.C. (2008) M&#233;thodes statistiques en sciences humaines, Bruxelles, De B&#339;ck. 
</p>
<p>JIANG M. (2009). A linear-time algorithm for Hamming distance with shifts. Theory of 
Computing Systems, 44, 349-355. 
</p>
<p>LAMPRIER S., AMGHAR T., LEVRAT B., SAUBION F. (2007). On evaluation methodologies for 
text segmentation algorithms. Proceedings of ICTAI 2007, 19-26. 
</p>
<p>PASSONNEAU R., LITMAN D. (1997). Discourse segmentation by human and automated 
means. Computational Linguistics 23, 103-139. 
</p>
<p>PEVZNER L., HEARST M. (2002). A critique and improvement of an evaluation metric for text 
segmentation, Computational Linguistics 28, 19-36. 
</p>
<p>PONTE J., CROFT W. (1997). Text segmentation by topic. Proceedings of 1st ECDL, 120-129. 
</p>
<p>PRINCE V., LABADIE A. (2007). Text segmentation based on document understanding for 
information retrieval. Proceedings of NLDB 2007, 295&#8211;304. 
</p>
<p>UTIYAMA M., ISAHARA H. (2001). A Statistical model for domain-independent text 
segmentation. Proceedings of ACL&#8217;2001, 491&#8211;498. </p>

</div></div>
</body></html>