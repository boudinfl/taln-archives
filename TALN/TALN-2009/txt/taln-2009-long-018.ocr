TALN 2009, Senlis, 24-26 juin 2009

Quel indice pour mesurer l'efficacité en segmentation de textes?

Yves Bestgen

CECL / PSOR — Université catholique de Louvain
Place du Cardinal Mercier, 10 — B—1348 Louvain—la—Neuve — Belgique
yves.bestgen@psp.ucl.ac.be

Résumé L'évaluation de l'efficacité d'algorithmes de segmentation thématique est
généralement effectuée en quantifiant le degré d'accord entre une segmentation hypothétique
et une segmentation de référence. Les indices classiques de précision et de rappel étant peu
adaptés 51 Ce domaine, WindowDiff (Pevzner, Hearst, 2002) s'est imposé comme l'indice de
référence. Une analyse de cet indice montre toutefois qu'il présente plusieurs limitations.
L'obj ectif de ce rapport est d'évaluer un indice proposé par Bookstein, Kulyukin et Raita
(2002), la distance de Hamming généralisée, qui est susceptible de remédier a celles—ci. Les
analyses montrent que celui—ci conserve tous les avantages de WindowDiff sans les
limitations. De plus, contrairement a WindowDiff, il présente une interpretation simple
puisqu'il correspond a une vraie distance entre les deux segmentations a comparer.

Abstract The evaluation of thematic segmentation algorithms is generally carried out by
quantifying the degree of agreement between a hypothetical segmentation and a gold
standard. The traditional indices of precision and recall being little adapted to this field,
WindowDiff (Pevzner, Hearst, 2002) has become the standard for this kind of assessment. An
analysis of this index shows however that it presents several limitations. The objective of this
report is to evaluate an index developed by Bookstein, Kulyukin and Raita (2002), the
Generalized Hamming Distance, which is likely to overcome these limitations. The analyzes
show that it preserves all the advantages of WindowDiff without its limitations. Moreover,
contrary to WindowDiff, it presents a simple interpretation since it corresponds to a true
distance between the two segmentations.

Mots-clés 2 Segmentation thématique, évaluation, distance de Hamming généralisée,
WindowDiff

Keywords: Thematic segmentation, evaluation, generalized Hamming distance,
WindowDiff

Yves Bestgen

1 Evaluation en segmentation thématique

La segmentation thématique de textes a pour objectif de localiser les changements de theme
dans des documents. Ce type d’informations peut permettre l’amélioration de diverses
applications en traitement automatique des langues naturelles comme l’extraction
d’informations, le résumé automatique ou encore la navigation a l’intérieur de longs textes.
Une série de recherches ont par exemple mis en évidence l’intérét de segmenter des textes en
fonction des themes qu’ils abordent afin d’améliorer les résultats de procédures d’extraction
d’informations (Hearst, 1997 ; Prince, Labadié, 2007). Ces dernieres années, de nombreux
algorithmes de segmentation thématique, basés principalement sur la cohésion lexicale, ont
été proposés (p.ex., Choi, 2000 ; Ferret, 2002 ; Hearst, 1997 ; Ponte, Croft, 1997 ; Utiyama,
Isahara, 2001) rendant encore plus important les problemes que pose leur evaluation.

Si quelques recherches ont évalué les performances d’une procédure de segmentation sur la
base des bénéfices qu’elle apporte a l’application pour laquelle elle a été concue (Bellot, El-
Beze, 2001 ; Prince, Labadié, 2007), la majorité des chercheurs procedent en comparant la
segmentation postulée a une norme censée correspondre a la Vraie segmentation du textel.
Pour déterminer cette norme, deux approches sont principalement employees. La premiere
consiste a demander a des juges d’effectuer la meme tache que l’algorithme et donc a
segmenter des textes de diverses origines (Bestgen, Piérard, 2006 ; Hearst, 1997). La seconde
s’appuie sur un matériel artificiel obtenu en concaténant des textes, les changements de theme
a identifier correspondant aux frontieres entre ceux—ci. Cette seconde approche s’est tres
largement imposée en raison de l’existence d’un matériel de référence (Choi, 2000), qui
permet de comparer les performances de tout nouvel algorithme a celles des algorithmes
considérés comme les plus efficaces selon la littérature.

Quelle que soit l'origine de la norme, l'éValuation requiert un indice pour mesurer le degré
d'accord entre la segmentation proposée par l'algorithme et la segmentation de référence.
Depuis quelques années, le taux d'erreur Wind0wDiﬂ" (Pevzner, Hearst, 2002), sur la base
d'une analyse critique de l'indice Pk (Beeferman et al., 1999), s'est imposé. Cet indice
présente toutefois plusieurs faiblesses. Sa presentation et la discussion de ses limitations font
l'objet des deux sections suivantes. La quatrieme section présente la distance de Hamming
généralisée, proposée par Bookstein et al. (2002), qui, comme l'indique la cinquieme section,
répond a ces limitations tout en conservant les avantages de Wind0wDiﬂ" par rapport 51 Pk.

2 Indices pour mesurer l’efficacité d'un algorithme

Des les premieres recherches en segmentation thématique, les indices classiques en extraction
d'information que sont le rappel et la précision ont été critiques parce qu'ils ne font aucune
différence entre des erreurs légeres, comme le fait de placer une frontiere juste a coté de la
position attendue, par comparaison aux erreurs plus graves, comme placer une frontiere a une
grande distance de cette position attendue, manquer une frontiere (faux négatij) ou en ajouter
une (faux positif). Pour cette raison, des indices d'efficacité spécifiques a ce champ de
recherches ont été proposés. Le premier a avoir fait l’objet d’un consensus est le taux d'erreur

1 Récemment, Lamprier et a1. (2007) out proposé de se passer de toute segmentation de référence en basant

l‘évaluation sur la stabilité de la segmentation postulée aux permutations des unités intemes aux segments.

Quel indice pour mesurer l'eﬁ“icacite' en segmentation de textes?

Pk (Beeferman et al., 1999). Une analyse critique par Pevzner et Hearst (2002) a souligné son
intérét par rapport aux indices classiques de précision et de rappel, mais également plusieurs
de ces limitations. Afin d'y remédier, Pevzner et Hearst (2002) ont propose une Version
modifiée de Pk qu'ils ont appelé Wind0wDiﬂ" (WD) et qu'ils formulentz comme suit

Nk

WD<ref,hyp> = N446 2(|b(ref,Je ..,.> — b<hyp..hyp..,.>| > 0)

1

ou b( i, j) représente le nombre de frontieres entre les positions i et j, N le nombre de positions,
k correspond a la moitié de la longueur moyenne d’un segment dans l’annotation de
référence3. On peut décrire le fonctionnement de WD de la maniere suivante. Une fenétre de
taille k est déplacée tout au long des unités minimales de segmentation d’un texte
(habituellement les phrases). Pour chaque position de la fenétre, on compare le nombre de
frontieres de segments que celle—ci englobe selon la norme de référence au nombre de
frontieres détectées par l’algorithme. Celui—ci est pénalisé d’un point chaque fois que ces
nombres sont différents. Le dénominateur permet d’obtenir un score WD compris entre 0 et 1.
S’agissant d’une mesure d’erreur, plus sa Valeur est proche de 0, meilleure est la performance.

   

Rupture hypothétique Rupture selon Ia référence

 
C D E
...23456%“ 45123...
| | J J
E___—_—__

\ \ \ ——————

o=o1=1 1=12:‘=12=‘e1 1&0
Légende : bwp) '? hm, pourk = 4

Figure 1 : Exemple de calcul de WD (adapté de Pevzner et Hearst, 2002).

La figure 1 illustre le fonctionnement de cet indice. Les unités minimales d’un texte y sont
représentées par des chiffres qui traduisent la segmentation selon la norme de référence. La
segmentation hypothétique met en evidence deux ruptures, l’une identique a une de celles
mises en évidence par la norme de référence et l’autre non. Il est nécessaire de définir ici trois
types d'erreurs. La non—identification par la segmentation hypothétique de la frontiere entre D
et E est appelée un faux négatif. L'ajout erroné par la segmentation hypothétique d'une
frontiere entre D2 et D3 peut étre considéré de deux manieres différentes. On peut le Voir
comme un faux positzf, c'est—a—dire l'ajout dans la segmentation hypothétique d'une rupture qui
n'existe pas dans celle de référence. On peut aussi le Voir comme une erreur légére si on

2 Une autre formule, prenant en compte le nombre de différences entre les deux segmentations et non la

dichotomisation de ce nombre, est parfois (mais rarement) employée, méme si elle ne correspond pas a la
formule originale de Pevzner et Hearst (2002).

Cette Valeur a été proposée par Beeferman et al. (1999) et reprise par Pevzner et Hearst (2002) parce qu‘elle
permet d'att1ibuer des scores médiocres et relativement similaires aux algorithmes dégénérés les plus
courants comme ceux qui ne segmentent jamais ou chaque fois que possible.

Yves Bestgen

considere qu'il s'agit de la rupture presente entre D et E dans la segmentation de reference,
mais que la segmentation hypothetique ne l'a pas placee exactement au meme endroit. Cette
seconde interpretation impose de revoir celle qui fait de la non—identification de la frontiere
entre D et E un cas de faux negatif.

Pour un parametre k egal a 4, les traits horizontaux traduisent le deplacement de la fenetre
mobile. Les trois premiers traits (Verts et continus) signalent des fenetres pour lesquelles les
deux segmentations sont d’accord puisqu’elles marquent le meme nombre de ruptures (0 ou
1). Les traits discontinus et rouges signalent des points de desaccord : les deux extremites de
la fenetre mobile ne sont pas separees par le meme nombre de ruptures selon les deux
segmentations. Elles penalisent donc la segmentation hypothetique.

Afin de demontrer les avantages de WD par rapport a Pk, Pevzner et Hearst (2002) ont mene
une serie de simulations dans lesquelles la fluctuation de la longueur des segments ainsi que
la proportion et la gravite des differents types d'erreurs etaient manipulees. 11 en resulte que,
contrairement a Pk, WD penalise de maniere equivalente les faux positifs et les faux negatifs,
qu'il penalise moins les erreurs legeres que les faux positifs de meme ampleur et que, s'il reste
sensible a la fluctuation de la taille des segments, il l'est nettement moins que Pk.

Meme si de nombreux chercheurs continuent a rapporter Pk dans leur analyse afin de faciliter
la comparaison avec les etudes anterieures a 2002, WD s'est impose comme l'indice de
reference. Son importance pour l'eValuation en segmentation thematique a encore ete
recemment renforcee par Artstein et Poesio (2008) qui recommandent son emploi pour
mesurer l'accord entre les juges afin de prendre en compte le fait que les juges, comme les
procedures automatiques, peuvent detecter les differents themes tout en se trompant sur la
localisation exacte de leurs frontieres (pour une analyse de cette recommendation, Voir
Bestgen, 2009).

3 Limitations de Wind0wDiff

Malgre les avantages qu'il apporte par rapport a Pk, Wind0wDiﬂ" a fait l'objet de plusieurs
critiques. Lamprier et al. (2007) ont fait remarquer que WD, comme Pk, penalise
differemment les erreurs selon leur position dans le texte. Les erreurs qui se produisent a
moins de k positions du debut d'un texte ou de sa fin sont penalisees moins lourdement que
celles qui se produisent entre ces deux bornes. Georgescul et al. (2006) ont souligne que
l'interpretation des Valeurs produites par WD n'est pas plus evidente que celle de Pk parce que
ces indices ne refletent pas directement l'efficacite de l'algorithme.

WD presente deux autres problemes, herites de Pk. Tout d'abord, une erreur legere (telle que
definie a la section 2) qui se produit a une distance inferieure a k de la Vraie frontiere, mais
superieure a k/2, est plus penalisee qu'un faux positif pur (eloigne de toute segmentation dans
la norme). En effet, celui—ci recoit une penalite de k, alors qu'une erreur legere recoit une
penalite superieure a k puisqu'egale au double de sa distance a la Vraie frontiere. Cette
situation est d'autant plus problematique que WD a ete developpe dans le but de reduire les
penalites attribuees a des erreurs legeres.

Un second probleme, mentionne par Pevzner et Hearst (2002), est que deux ou plus faux
positifs qui sont proches les uns des autres (a une distance inferieure a k) sont moins penalises
que s'ils se produisent a des distances superieures a k. 11 en est de meme de deux ou plus faux
negatifs qui sont proches les uns des autres.

Quel indice pour mesurer l'eﬁ“icacite' en segmentation de textes?

On notera enfin, comme le signalent Pevzner et Hearst (2002), que si WD est moins sensible a
la fluctuation des longueurs de segments que Pk, il reste néanmoins affecté par celle—ci.

4 La distance de Hamming généralisée : un indice plus efficace?

L'objectif majeur de cette etude est d'éValuer un indice susceptible de répondre aux limitations
présentées par WD tout en conservant ses avantages par rapport a Pk : la distance de
Hamming généralisée proposée, indépendamment du développement de Pk et de WD, par
Bookstein et al. (2002). Ces auteurs se sont intéressés a la mesure de la distance entre des
Vecteurs binaires de memes longueurs. Ce genre de données s'obtient en traitement du signal,
mais aussi en segmentation thématique ou la presence d'une frontiere entre deux unites
minimales peut—étre codée par un "1" et l'absence de frontiere par un "0". Pour ce type de
données, une mesure classique est la distance de Hamming (ici appliquée a des données
binaires) qui est basée sur le nombre de bits qu'il est nécessaire de modifier pour transformer
une sequence en une autre. Considérée comme une forme particuliere de distance d'édition,
elle correspond au coﬁt minimal des operations nécessaires pour effectuer cette
transformation lorsque les deux seules operations autorisées sont :

— l'ope'ration d'insertion qui change un 0 en 1 pour un coﬁt Ci = 1 ;
— l'ope'ration de suppression qui change un 1 en 0 pour un coﬁt Cs = 1.

Les termes insertion et suppression sont, comme le soulignent Bookstein et al. (2002),
employés dans un sens different de celui utilise habituellement dans les travaux sur la
manipulation de chaines de caracteres puisque ni l'insertion, ni la suppression ne modifient la
taille de la chaine.

Dans sa Version originale, la distance de Hamming présente la meme limitation que les
indices de precision et de rappel puisqu'elle se base exclusivement sur l'accord ou le
désaccord entre deux bits. Pour dépasser cette limitation, Bookstein et al. (2002) proposent
d'adjoindre une troisieme operation :

— l'ope'ration de de'placement qui fait glisser un "1" Vers la gauche ou Vers la droite de la
sequence afin de le mettre en correspondance avec un " 1" dans l'autre sequence. Le coﬁt de
cette operation (Cd) est une fonction strictement positive et monotoniquement croissante
de la longueur du déplacement nécessaire.

La distance de Hamming généralisée (DHG) correspond au coﬁt minimum pour transformer
une sequence en l'autre au moyen de ces trois operations. Bookstein et al. (2002) montrent
que DHG est une Vraie distance en ce sens qu'elle en présente toutes les propriétés lorsque les
coﬁts des différentes operations remplissent certaines conditions. C'est tout particulierement le
cas lorsque Ci = Cs > 0 et que le coﬁt total d'un déplacement est proportionnel a la longueur
de celui—ci. En divisant le coﬁt minimal par la longueur des sequences, on obtient une mesure
relative dont le minimum est 0 alors que le maximum depend des coﬁts attribués aux
différentes operations.

La figure 2 présente l'application de DHG a l'exemple de segmentation déja employé a la
figure 1 sur la base des coﬁts suivants : Ci = Cs = 2 et Cd = 1. Ci et Cs ont une Valeur égale a
celle de k/2 de sorte que pour qu'un déplacement soit plus avantageux qu'une insertion et une
suppression, sa longueur doit étre inférieure a k, soit a la moitié de la longueur d'un segment
dans la segmentation de référence.

Yves Bestgen

Bookstein et al. (2002) proposent un algorithme qui permet de calculer DHG en fonction des
pénalités attribuées a chaque opération. Cet algorithme a été implémenté en C++ par Vladimir
Kulyukin (www.cs.usu.edu/~Vkulyukin/Vkweb/software/ghd/ghd.html). Jiang (2009) propose
un algorithme plus rapide.

H Rupture hypothétique  | Rupture selon Ia référence |
..\\;
C D E
...2345612345123...
0- — — - ->
avec un coﬁt de 3Cd = 3

qui est inférieur 21 Cs + Ci = 4
(k=4, donc la longueur moyenne des segments est de 8)

Figure 2 : Exemple de calcul de DHG.

5 Evaluation comparée de WD et de DHG

Bien que Bookstein et al. (2002) mentionnent la segmentation de texte comme un domaine
d'application de leur distance, aucune étude n'a, a ma connaissance4, comparé DHG a WD.
Une analyse des propriétés de DHG montre qu'il est une alternative intéressante a WD. On
notera en premier lieu qu'il présente les mémes avantages que WD par rapport a Pk. Lorsque
Ci = Cs, les faux positifs et les faux négatifs sont pénalisés de la méme maniere. De plus,
toutes les erreurs sont pénalisées, qu'elles soient proches ou éloignées les unes des autres.

DHG répond aussi, de par sa construction, a plusieurs des critiques formulées a l'encontre de
WD. Tout d'abord, la position d'une erreur dans la séquence, au tout début, au milieu ou a la
fin, n'a aucun impact sur la pénalité encourue. Ensuite, DHG a une interprétation simple et
directe puisqu'il s'agit d'une Vraie distance qui correspond au coﬁt minimal des opérations
nécessaires pour transformer une segmentation en l'autre. Ces opérations prennent en compte
la spécificité de l'éValuation en segmentation thématique en distinguant une erreur grave
comme un faux négatif et un faux positif, d'une erreur plus légere comme placer une frontiere
a une faible distance de la position attendue.

Enfin, DHG répond aux deux autres critiques adressées a WD. 11 est en effet impossible que
cet indice pénalise plus une erreur légere qu'un faux positif (ou qu'un faux négatif) puisque
dans ce cas, c'est l'opération de suppression (ou d'insertion) qui sera choisie afin d'obtenir le
coﬁt minimal. De méme, les faux positifs recoivent toujours la méme pénalité quelle que soit
la distance entre eux puisque le coﬁt est toujours identique a Cs.

Afin de confirmer ces analyses, une évaluation comparative de WD et de DHG, ainsi que de
Pk, a été réalisée au moyen des deux simulations les plus importantes décrites dans Pevzner et
Hearst (2002). Pour chaque simulation, 10 segmentations de références, chacune composée de
1000 segments d'une longueur moyenne de 25 unités sont générées aléatoirement et pour

4 Antérieurement au développement de WD et de DHG, Ponte et Croft (1997) out employé pour évaluer leur

algorithme de segmentation un indice basé sur les opérations d'édition.

Quel indice pour mesurer l'eﬁ“icacite' en segmentation de textes?

chacune de celles-ci 100 segmentations hypothétiques sont générées et comparées a celle de
référence au moyen des trois indices Pk, WD et DHG, les résultats finaux correspondants aux
moyennes pour les 1000 essais.

5.1 Effet de la ﬂuctuation de la longueur des segments

La premiere série de simulations a pour objectif d'éValuer l'impact de la ﬂuctuation des
longueurs de segments sur les taux d'erreurs. Dans chaque simulation, les segmentations de
référence sont générées sur la base de longueurs de segments uniformément distribuées entre
deux Valeurs a égale distance de la longueur moyenne de 25. Ces Valeurs sont [20, 30], [15,
35], [10, 40] et [5, 45]. Les segmentations hypothétiques sont quant a elles générées selon
trois types de distribution d'erreurs différents :

— PN: une segmentation avec une probabilité d'occurrence d'un faux négatif de 0.5 a chaque
frontiere réelle.

— FP1: une segmentation avec une probabilité d'occurrence d'un faux positif de 0.5 dans
chaque segment, les faux positifs étant uniformément distribués dans ceux-ci.

— FNP1: une segmentation qui combine les deux précédentes et donc les deux types
d'erreurs.

Le schéma de coﬁts attribués aux différentes opérations pour le calcul de DHG correspond a
celui proposé dans la section 4, sauf que les trois Valeurs ont été multipliées par 2 (Cd=2 et
Ci=Cs=k) de facon a faciliter la comparaison entre WD et DHG car ceci permet d'égaliser le
coﬁt pour DHG d'un faux positif pur (éloigné de toute segmentation dans la norme) et d'un
faux négatif pur a la pénalité encourue par ces mémes erreurs selon WD puisque celle-ci est
de k. Le parametre k a été fixé a 12 afin d'obtenir les Valeurs les plus similaires possibles a
celles rapportées par Pevzner et Hearst (2002).

FN FP1 FNP1

20-30 15-35 10-40 5-45 20-30 15-35 10-40 5-45 20-30 15-35 10-40 5-45

Pk .240 .240 .237 .218 .128 .122 .112 .106 .314 .305 .288 .266

WD .240 .240 .239 .233 .236 .235 .235 .232 .370 .364 .353 .339

DHG .240 .240 .240 .240 .240 .240 .240 .240 .378 .373 .367 .356

Tableau 1 : Valeurs moyennes de Pk, WD et DHG pour la premiere série de simulations

Comme l'indique le tableau 1, WD est moins fortement affecté par la ﬂuctuation des
longueurs des segments que Pk, un résultat attendu. Plus intéressant est le fait que DHG est

encore moins affecté par cette ﬂuctuation. Pour quantifier objectivement cette différence, des
analyses de Variance a un facteur (ﬂuctuation) ont été effectuées. Ces analyses permettent de

déterminer la part de Variance expliquée (aussi appelée R-carré) qu'apporte la connaissance
des niveaux de ﬂuctuation pour prédire les trois indices (Howell, 2008, pp. 336-338). Cette
part de Variance correspond au rapport entre la Variabilité des Valeurs moyennes d'un indice en
fonction du facteurﬂuctuation (Variabilité inter-niveaux) et la Variabilité totale de l'indice, qui
inclut la Variabilité inter-niveaux et la Variabilité a l'intérieur de chaque niveau de ﬂuctuation
(Variabilité intra-niveau). Plus ce rapport est proche de 1, plus l'indice en question est sensible

Yves Bestgen

a la fluctuation des longueurs des segments. Comme le montre le tableau 2, ces parts de
Variance sont a chaque fois les plus faibles pour DHG. Lorsqu'on compare, dans le tableau 1,
les résultats pour les faux négatifs et les faux positifs, on observe que DHG et WD se
comportent d'une maniere similaire, mais différente de Pk qui sous—pénalise nettement les
faux positifs comme le prédit l'analyse de Pevzner et Hearst (2002).

Pk WD DHG

FN FP1 FNP1 FN FP1 FNP1 FN FP1 FNP1

.58 .76 .84 .13 .03 .69 .00 .00 .48

Tableau 2 : Parts de Variance expliquées par le facteur fluctuation pour les trois indices.

5.2 Effet du type de distribution des erreurs

La seconde série de simulations Vise a évaluer l'impact de différentes distributions d'erreurs
sur les indices. Pour celles—ci, Pevzner et Hearst (2002) ont choisi de n'employer qu'un seul
niveau de fluctuation de la longueur moyenne des segments, celui allant de 15 a 35. Sept
distributions d'erreurs ont été évaluées, dont trois sont communes avec les premieres
simulations (FN, FP1 et FNP1). Les quatre distributions supplémentaires sont :

— FP2: une segmentation avec une probabilité d'occurrence d'un faux positif de 0.5 dans
chaque segment, les faux positifs étant distribués autour des frontieres des segments selon
une distribution normale avec un écart—type égal a 1/1 de la longueur du segment.

— FP3: une segmentation avec des faux positifs distribués uniformément dans l'ensemble de
la sequence, la probabilité d'occurrence d'un faux positif en chaque position possible étant
de 0.02, ce qui correspond a une probabilité d'occurrence dans chaque segment de 0.5.

— FNP2: combine FN et FP2.
— FNP3: combine FN et FP3.

FN FP1 FP2 FP3 FNP1 FNP2 FNP3

Pk .240 .122 .096 .116 .305 .268 .306

WD .240 .235 .232 .215 .364 .340 .361

DHG .240 .240 .240 .240 .373 .350 .385

Tableau 3 : Valeurs moyennes de Pk, WD et DHG pour la deuxieme série de simulations

Le tableau 3 montre, comme attendu, que Pk se comporte tres différemment de DHG alors
que celui—ci donne lieu a des résultats tres semblables a ceux de WD. La principale difference
entre ceuX—ci porte sur les Valeurs obtenues pour FP3. WD considere que cette distribution
d'erreurs est meilleure que FP2 et FP1 alors que DHG considere que les trois distributions FPx
sont équivalentes. Comme l'indiquent Pevzner et Hearst (2002, p. 33), WD sous—pénalise FP3
parce que c'est dans ce genre de distributions que des faux positifs ont le plus de chance de se
produire les uns pres des autres et donc d'étre sous—pénalisés. Pour DHG, ces trois

Quel indice pour mesurer l'eﬁ“icacite' en segmentation de textes?

distributions d'erreurs donnent lieu a un meme nombre d'opérations de suppression et donc a
un meme coﬁt total.

Les distributions FNPx méritent aussi une attention toute particuliere. FNP3 génere, par
construction, les plus mauvaises segmentations. Cette distribution d'erreurs inclut, comme les
deux autres, 50% de faux négatifs et un pourcentage equivalent de faux positifs, mais la
distribution de ceux—ci n'est pas construite pour favoriser les erreurs légeres puisque les faux
positifs sont uniformément distribués. De ce point de vue, FNP2 est la moins mauvaise des
distributions, puisque c'est celle qui maximise les chances que les faux positifs soient les plus
proches des faux négatifs, et FNP1 est intermédiaire. Si WD identifie correctement l'avantage
de FNP2 par rapport aux deux autres, il considere que FNP3 est meilleur que FNP1 (parce
qu'il sous—pénalise FNP3 pour la meme raison qu'il sous—pénalise FP3). DHG ne commet pas
cette erreur et met nettement plus en évidence les differences.

6 Conclusion

L'objectif de cette recherche était d'évaluer les indices qui permettent de mesurer l'efficacité
d'algorithmes de segmentation thématique. Tout particulierement, la distance de Hamming
généralisée (DHG), proposée par Bookstein et al. (2002), est décrite et comparée a l'indice le
plus fréquemment employé dans ce genre de recherche, Wind0wDiﬂ" (WD) de Pevzner et
Hearst (2002). L'analyse des propriétés de DHG montre qu'il conserve tous les avantages que
WD présente par rapport a son prédécesseur, Pk, sans les limitations que ces deux—ci
partagent. ll faut toutefois noter que, dans les simulations réalisées, les différences entre DHG
et WD sont relativement faibles. Ce résultat n'est pas étonnant parce que les simulations
utilisées ont été proposées par Pevzner et Hearst (2002) pour confronter WD a Pk et n'ont
donc pas été concues en fonction des différences entre DHG et WD. Des experiences
complémentaires sont nécessaires. Toutefois, meme si on devait juger que les améliorations
apportées par DHG sont insuffisantes pour justifier un changement d'indice de référence, un
apport de cette étude est de proposer pour Wind0wDiﬁ" une interprétation plus simple que celle
donnée par Pevzner et Hearst (2002). En effet, ce raisonnement conduit a considérer que
Wind0wDiﬂ" approxime une vraie distance entre les deux segmentations a comparer, distance
qui correspond au coﬁt minimal des opérations nécessaires pour transformer la segmentation
proposée par l'algorithme en la segmentation de référence. Si, par contre, on considere que la
distance de Hamming généralisée vaut la peine d'étre adoptée, il sera nécessaire de mener des
analyses approfondies de l'impact des coﬁts attribués aux opérations sur les valeurs obtenues,
et ce, entre autres, par des algorithmes "dégénérés". Comparer dans ce type de situations WD,
DHG, mais aussi l'indice de stabilité propose par Lamprier et al. (2007), serait tres informatif.

Remerciements
Yves Bestgen est chercheur qualifié du F.R.S—FNRS. ll tient a remercier les experts pour leurs
commentaires.

Références

ARTSTEIN R., POESIO M. (2008). Inter—coder agreement for computational linguistics.
Computational Linguistics 34, 555-596.

Yves Bestgen

BEEFERMAN D., BERGER A., LAFFERTY J. (1999). Statistical models for text segmentation,
Machine Learning 34, 177-210.

BELLOT P., EL-BEZE M. (2001). Classification et segmentation de textes par arbres de

décision. Application a la recherche documentaire. Technique et science informatiques 20,
107-134.

BESTGEN Y. (2009). Jugements humains et évaluation des algorithmes de segmentation
thématique : application de WindowDiff. Actes de EvalECD’09, 15-24.

BESTGEN Y., PIERARD S. (2006). Comment évaluer les algorithmes de segmentation
automatique? Essai de construction d'un matériel de référence. Actes de TALN '06, 407-414.

BOOKSTEIN A., KULYUKIN V.A., RAITA T. (2002). Generalized Hamming distance.
Information Retrieval 5, 353-375.

CHOIF. (2000). Advances in domain independent linear text segmentation, Proceedings of
NAACL—00, 26-33.

FERRET O. (2002). Using collocations for topic segmentation and link detection. Proceedings
of COLING 2002, 260-266.

GEORGESCUL M., CLARK A., ARMSTRONG S. (2006). An analysis of quantitative aspects in
the evaluation of thematic segmentation algorithms. Proceedings of SIGdial '06, 144-151.

HEARST M. (1997). TextTiling: Segmenting text into multi—paragraph subtopic passages.
Computational Linguistics 23, 33-64.

HOWELL D.C. (2008) Me'thodes statistiques en sciences humaines, Bruxelles, De Boeck.

JLANG M. (2009). A linear—time algorithm for Hamming distance with shifts. Theory of
Computing Systems, 44, 349-355.

LAMPRIER S., AMGHAR T., LEVRAT B., SAUBION F. (2007). On evaluation methodologies for
text segmentation algorithms. Proceedings of ICTAI 2007, 19-26.

PASSONNEAU R., LITMAN D. (1997). Discourse segmentation by human and automated
means. Computational Linguistics 23, 103-139.

PEVZNER L., HEARST M. (2002). A critique and improvement of an evaluation metric for text
segmentation, Computational Linguistics 28, 19-36.

PONTE J., CROFT W. (1997). Text segmentation by topic. Proceedings of 1 st ECDL, 120-129.

PRINCE V., LABADIE A. (2007). Text segmentation based on document understanding for
information retrieval. Proceedings of NLDB 2007, 295-304.

UTIYAIVIA M., ISAHARA H. (2001). A Statistical model for domain—independent text
segmentation. Proceedings of ACL’2001, 491-498.

