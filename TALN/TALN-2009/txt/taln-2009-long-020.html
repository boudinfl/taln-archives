<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>R&#233;sum&#233; automatique de textes d&#8217;opinions</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009, Senlis, 24&#8211;26 juin 2009
</p>
<p>R&#233;sum&#233; automatique de textes d&#8217;opinions
</p>
<p>Michel G&#233;n&#233;reux et Aur&#233;lien Bossard
Laboratoire d&#8217;Informatique de Paris-Nord
(CNRS UMR 7030 et Universit&#233; Paris 13)
99, av. J.-B. Cl&#233;ment &#8211; 93430 Villetaneuse
</p>
<p>pr&#233;nom.nom@lipn.univ-paris13.fr
</p>
<p>R&#233;sum&#233;. Le traitement des langues fait face &#224; une demande croissante en mati&#232;re d&#8217;ana-
lyse de textes v&#233;hiculant des critiques ou des opinions. Nous pr&#233;sentons ici un syst&#232;me de
r&#233;sum&#233; automatique tourn&#233; vers l&#8217;analyse d&#8217;articles post&#233;s sur des blogues, o&#249; sont exprim&#233;es
&#224; la fois des informations factuelles et des prises de position sur les faits consid&#233;r&#233;s. Nous mon-
trons qu&#8217;une approche classique &#224; base de traits de surface est tout &#224; fait efficace dans ce cadre.
Le syst&#232;me est &#233;valu&#233; &#224; travers une participation &#224; la campagne d&#8217;&#233;valuation internationale TAC
(Text Analysis Conference) o&#249; notre syst&#232;me a r&#233;alis&#233; des performances satisfaisantes.
</p>
<p>Abstract. There is currently a growing need concerning the analysis of texts expressing
opinions or judgements. In this paper, we present a summarization system that is specifically
designed to process blog posts, where factual information is mixed with opinions. We show
that a classical approach based on surface cues is efficient to summarize this kind of texts. The
system is evaluated through a participation to TAC (Text Analysis Conference), an international
evaluation framework for automatic summarization, in which our system obtained good results.
</p>
<p>Mots-cl&#233;s : r&#233;sum&#233; automatique, analyse de textes subjectifs, &#233;valuation automatique.
</p>
<p>Keywords: automatic summarization, analysis of subjective texts, automatic evaluation.
</p>
<p>1 Introduction
</p>
<p>Le r&#233;sum&#233; automatique a connu un fort renouveau ces derni&#232;res ann&#233;es et les recherches en ce
domaine ont fortement &#233;volu&#233; r&#233;cemment : l&#8217;apparition de gros corpus parfois h&#233;t&#233;rog&#232;nes et
la g&#233;n&#233;ralisation des techniques d&#8217;analyse de surface ont &#224; la fois renouvel&#233; les besoins et les
approches. Plus r&#233;cemment encore, avec l&#8217;av&#232;nement de m&#233;dias plus interactifs, la n&#233;cessit&#233; de
rep&#233;rer les citations, les jugements et les opinions s&#8217;est av&#233;r&#233; de plus en plus crucial. Le but n&#8217;est
plus seulement de produire une synth&#232;se de l&#8217;information contenue dans les textes, il faut en
outre d&#233;gager des tendances, identifier les opinions exprim&#233;es et si possible en faire la synth&#232;se.
Cet article d&#233;crit des recherches men&#233;es dans ce cadre : nous avons d&#233;velopp&#233; un syst&#232;me
visant &#224; faire une synth&#232;se automatique d&#8217;opinions exprim&#233;es sur Internet sur un sujet donn&#233;,
en particulier dans des articles post&#233;s sur des blogues (ci-apr&#232;s blogues). Le syst&#232;me repose
sur une synth&#232;se entre des techniques classiques de production de r&#233;sum&#233; par extraction de
passages pertinents et l&#8217;analyse des opinions exprim&#233;es dans ces textes. Les blogues comportant
g&#233;n&#233;ralement une structure syntaxique irr&#233;guli&#232;re ainsi qu&#8217;une grande richesse n&#233;ologique, un</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Michel G&#233;n&#233;reux et Aur&#233;lien Bossard
</p>
<p>minimum de modification est n&#233;cessaire pour adapter un tel syst&#232;me pour le traitement d&#8217;autres
types de documents moins complexes.
</p>
<p>Pour &#233;valuer notre syst&#232;me, nous avons particip&#233; &#224; la campagne TAC 2008, une campagne
d&#8217;&#233;valuation internationale organis&#233;e par le NIST (National Institute of Standards and Tech-
nology) et tourn&#233;e vers les syst&#232;mes de questions-r&#233;ponses et de r&#233;sum&#233; automatique. L&#8217;&#233;va-
luation propos&#233;e dans ce cadre m&#234;lait r&#233;sum&#233; factuel et analyse d&#8217;opinion, &#224; partir des sorties
de syst&#232;mes de questions-r&#233;ponses. L&#8217;enjeu &#233;tait de produire des synth&#232;ses coh&#233;rentes &#224; par-
tir de questions en langage naturel &#8212; en g&#233;n&#233;ral, un r&#233;sum&#233; correspond &#224; plusieurs questions
li&#233;es (appel&#233;es squishy list) sur un th&#232;me donn&#233; (appel&#233; target). Pour prendre un exemple, un
des th&#232;mes propos&#233; &#233;tait la personnalit&#233; de l&#8217;ann&#233;e d&#233;sign&#233;e par le magazine Time pour 2005
(&#8220;Time Magazine 2005 Person of the Year&#8221;). Une des questions li&#233;es &#233;tait la suivante : &#8220;Why
did readers support Time&#8217;s inclusion of Bono for Person of the Year ?&#8221;. On voit qu&#8217;il s&#8217;agit de
questions en &#8220;pourquoi&#8221; (why) : contrairement aux questions factuelles (questions dites fac-
to&#239;des, o&#249; la r&#233;ponse est g&#233;n&#233;ralement une entit&#233; nomm&#233;e), il n&#8217;est pas possible de r&#233;pondre
de fa&#231;on simple &#224; ces questions en pourquoi. Les syst&#232;mes de questions-r&#233;ponses traditionnels,
qui produisent des fragments en guise de r&#233;ponse (&#8220;snippets&#8221;, c&#8217;est-&#224;-dire de courtes s&#233;quences
de texte issues du fonds documentaire et cens&#233;es contenir une r&#233;ponse pertinente) ne sont pas
encore tout &#224; fait adapt&#233;s pour ce type de probl&#232;me. L&#8217;extraction de phrases donnant une id&#233;e
des informations essentielles contenues dans le fonds documentaire et formant autant que pos-
sible un tout coh&#233;rent, semble une voie plus prometteuse. Les participants &#224; la campagne TAC
Opinion 2008 disposaient de fragments extraits par les syst&#232;mes de questions-r&#233;ponses afin de
les aider &#224; produire une synth&#232;se coh&#233;rente. Nous avons utilis&#233; ces extraits et nous avons ainsi
pu &#233;laborer un syst&#232;me tr&#232;s performant par rapport aux autres syst&#232;mes &#233;valu&#233;s1. Cependant,
cette approche rend notre syst&#232;me d&#233;pendant des syst&#232;mes de questions-r&#233;ponses.
</p>
<p>Dans ce qui suit, nous pr&#233;sentons un rapide &#233;tat de l&#8217;art du domaine. Nous pr&#233;sentons ensuite le
syst&#232;me que le LIPN a d&#233;velopp&#233; pour le r&#233;sum&#233; automatique de textes v&#233;hiculant une opinion ;
ses diff&#233;rents aspects sont d&#233;taill&#233;s, notamment les traits de surface utilis&#233;s, les proc&#233;dures de
choix des phrases extraites et leur ordonnancement. Nous pr&#233;sentons ensuite les adaptations que
nous avons d&#251; faire pour r&#233;pondre aux besoins particuliers de la campagne TAC, les r&#233;sultats
que nous avons obtenus et leurs limites.
</p>
<p>2 &#201;tat de l&#8217;art
</p>
<p>La g&#233;n&#233;ration de r&#233;sum&#233;s reposant sur des principes linguistiques avanc&#233;s s&#8217;est rapidement
av&#233;r&#233;e trop ambitieuse. C&#8217;est pourquoi d&#232;s les ann&#233;es 1950, la recherche s&#8217;est alors tourn&#233;e
vers des techniques plus sommaires visant &#224; extraire des (segments de) phrases pertinentes.
L&#8217;id&#233;e consiste &#224; attribuer &#224; chaque phrase un poids puis &#224; extraire, en fonction d&#8217;un taux de
compression, les N phrases dont le poids est le plus &#233;lev&#233;.
</p>
<p>Les techniques &#224; l&#8217;&#339;uvre sont assez intuitives et ont &#233;t&#233; bien d&#233;crites d&#232;s les ann&#233;es 1960 (Ed-
mundson, 1969) : rep&#233;rage de mots cl&#233;s (par rapport au th&#232;me abord&#233;), de &#8220;signatures&#8221; (syn-
tagmes introducteurs typiques de s&#233;quences importantes comme en r&#233;sum&#233;, en conclusion, etc.),
prise en compte de la position des phrases dans le documents, etc. Un des syst&#232;mes actuellement
</p>
<p>1Un autre syst&#232;me, appel&#233; LIPN2-Opinion, a &#233;galement obtenu de bonnes performances sans utiliser les frag-
ments fournis par les syst&#232;mes de questions-r&#233;ponses. Ce syst&#232;me est d&#233;taill&#233; dans (Bossard et al., 2008).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;sum&#233; automatique de textes d&#8217;opinions
</p>
<p>les plus populaires, le syst&#232;me MEAD2 mis au point par Radev, repose sur une approche de ce
type (Radev et al., 2001). Le syst&#232;me cherche d&#8217;abord &#224; identifier les mots les plus saillants
dans chaque texte, les centro&#239;des, et &#224; favoriser les phrases essentiellement constitu&#233;es des cen-
tro&#239;des. D&#8217;autres travaux ont apport&#233; des am&#233;liorations &#224; partir de ce sch&#233;ma de base. On notera
par exemple le syst&#232;me Neo-cortex d&#233;velopp&#233; &#224; l&#8217;Universit&#233; d&#8217;Avignon, qui tire partie de plu-
sieurs mesures de s&#233;lection de phrases afin de combiner les avantages de diff&#233;rents types de
traits (Boudin &amp; Moreno, 2007). Ce syst&#232;me a r&#233;cemment obtenu de tr&#232;s bons r&#233;sultats3 en
utilisant l&#8217;algorithme MMR (Maximal Marginal Relevance) de (Carbonell &amp; Goldstein, 1998).
</p>
<p>Il y a eu des tentatives r&#233;centes pour r&#233;introduire de la linguistique profonde dans les syst&#232;mes
de r&#233;sum&#233;s. Il s&#8217;agit essentiellement de travaux op&#233;rant directement sur l&#8217;arbre syntaxique pour
essayer de proposer des proc&#233;d&#233;s permettant de comparer les arbres, de les &#233;laguer ou de les
fusionner (Gotti et al., 2007), ou encore de m&#233;thodes de compression syntaxique bas&#233;e sur
des propri&#233;t&#233;s linguistiques th&#233;oriques et empiriques (Yousfi-Monod, 2007). Nous en restons
dans ce qui suit &#224; une analyse de surface et nous n&#8217;avons pas recours &#224; la syntaxe mais ces
travaux constituent des perspectives int&#233;ressantes et naturelles au travail pr&#233;sent&#233; ici. D&#8217;autres
approches sont possibles, notamment celles fond&#233;es sur la repr&#233;sentation des connaissances
(Mani, 2004), la segmentation th&#233;matique (Farzindar et al., 2004) ou le profil utilisateur (Ch&#226;ar
et al., 2004; Crispino &amp; Couto, 2004).
</p>
<p>Dans le domaine des opinions, les travaux pr&#233;c&#233;dents se sont surtout attard&#233;s &#224; leur d&#233;tection
ainsi qu&#8217;&#224; la gradation de leur niveau affectif, et ce selon trois niveaux principaux de sous-
t&#226;ches. La premi&#232;re sous-t&#226;che consiste &#224; distinguer les textes subjectifs des textes objectifs
(Yu &amp; Hatzivassiloglou, 2003). La seconde sous-t&#226;che s&#8217;attarde &#224; classer les textes subjectifs
en positifs or n&#233;gatifs (Turney, 2002). Le troisi&#232;me niveau de raffinement essaie de d&#233;terminer
jusqu&#8217;&#224; quel point les textes sont positifs ou n&#233;gatifs (Wilson et al., 2004). L&#8217;impulsion donn&#233;e
par des campagnes telles que TREC Blog Opinion Task depuis 2006 est incontestable (Zhang
et al., 2007; Dey &amp; Haque, 2008). Il faut reconna&#238;tre que notre traitement des opinions pour
l&#8217;aide &#224; la production de r&#233;sum&#233; de textes d&#8217;opinion ne va pas au-del&#224; de la distinction standard
positif versus n&#233;gatif, et qu&#8217;il faut signaler les efforts r&#233;cents pour r&#233;introduire des approches
plus linguistiques et discursives (prise en compte de la modalit&#233;, de l&#8217;&#233;nonciateur) dans ce
domaine (Asher et al., 2008).
</p>
<p>En ce qui concerne l&#8217;&#233;valuation de r&#233;sum&#233;s, soulignons la contribution de (Goulet, 2007) qui
va au-del&#224; de la couverture des n-grammes et propose une terminologie adapt&#233;e au fran&#231;ais.
</p>
<p>3 Description du syst&#232;me
</p>
<p>L&#8217;approche que nous avons d&#233;velopp&#233;e combine des techniques traditionnellement employ&#233;es
pour le r&#233;sum&#233; automatique de textes avec des techniques de d&#233;tection et d&#8217;analyse d&#8217;opinions.
</p>
<p>3.1 Principes g&#233;n&#233;raux
</p>
<p>A la diff&#233;rence des syst&#232;mes de r&#233;sum&#233; traditionnels qui prennent en entr&#233;e un texte (ou un
ensemble de textes dans le cas du r&#233;sum&#233; multi-documents), notre syst&#232;me repose fondamenta-
</p>
<p>2http://www.summarization.com/mead/
3NIST Document Understanding Conference (DUC) 2006</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Michel G&#233;n&#233;reux et Aur&#233;lien Bossard
</p>
<p>lement sur une requ&#234;te qui permet de pr&#233;ciser le fait ou l&#8217;objet &#224; propos duquel l&#8217;utilisateur sou-
haite obtenir une synth&#232;se. En effet, il n&#8217;y a gu&#232;re de sens &#224; proposer un syst&#232;me produisant des
r&#233;sum&#233;s rendant compte des opinions exprim&#233;es si l&#8217;on n&#8217;a pas pr&#233;cis&#233; d&#8217;abord la cible recher-
ch&#233;e, c&#8217;est-&#224;-dire l&#8217;&#233;v&#233;nement, la personne ou l&#8217;objet &#224; propos duquel on cherche &#224; conna&#238;tre
l&#8217;&#233;tat de l&#8217;opinion. De ce fait, le syst&#232;me repose fondamentalement sur deux &#233;l&#233;ments : 1) une
requ&#234;te comprenant une cible et &#233;ventuellement des questions annexes permettant de pr&#233;ciser
l&#8217;information recherch&#233;e, 2) le fonds documentaire qui sert de base &#224; la production de r&#233;sum&#233;.
On remarquera, du fait de la pr&#233;sence d&#8217;une requ&#234;te, le lien assez direct entre ce type de sys-
t&#232;mes et les syst&#232;mes de questions-r&#233;ponses.
</p>
<p>Notons &#224; ce propos que la campagne TAC 2008 fournissait en outre une liste de fragments (snip-
pets ou fragments) pr&#233;alablement produits par un syst&#232;me de questions-r&#233;ponses (un snippet est
un court extrait de texte, de taille fixe ou non, mais ne correspondant pas obligatoirement &#224; une
s&#233;quence linguistique compl&#232;te, cens&#233; donner un &#233;l&#233;ment de r&#233;ponse par rapport &#224; une requ&#234;te).
On verra l&#8217;importance de ces &#233;l&#233;ments de r&#233;ponse pour le syst&#232;me dans la section traitant plus
sp&#233;cifiquement de notre participation &#224; la campagne TAC.
</p>
<p>Comme la plupart des syst&#232;mes participant aux campagnes d&#8217;&#233;valuation comme TAC, notre
syst&#232;me repose fondamentalement sur un ensemble d&#8217;heuristiques. Celles-ci refl&#232;tent indirec-
tement les observations d&#8217;analystes quant aux facteurs &#224; prendre en compte pour produire un
r&#233;sum&#233; par extraction. Soulignons d&#232;s &#224; pr&#233;sent le manque de fondement th&#233;orique de ce type
d&#8217;approches, leur d&#233;pendance plus ou moins grande vis-&#224;-vis du domaine ou du type de texte
consid&#233;r&#233; ; toutefois, comme nous l&#8217;avons rappel&#233; dans la section pr&#233;c&#233;dente, le peu de r&#233;sultats
des approches g&#233;n&#233;ratives a contribu&#233; au succ&#232;s des approches &#224; base d&#8217;heuristiques (m&#234;me si
les approches g&#233;n&#233;ratives semblent reposer sur des fondements linguistiques plus assur&#233;s).
</p>
<p>3.2 Architecture
</p>
<p>Dans cette campagne TAC, le syst&#232;me construit doit traiter en entr&#233;e une cible, une ou deux
questions en rapport avec la cible, un groupe de documents (des blogues) pouvant contenir les
r&#233;ponses ou &#233;l&#233;ments essentiels &#224; nos questions, ainsi que les snippets, fournis par TAC mais
dont l&#8217;usage en entr&#233;e est optionelle. En sortie, le syst&#232;me pruduit doit fournir un seul r&#233;sum&#233;
pour chaque combinaison cible/questions/documents.
</p>
<p>Cette section d&#233;crit les diff&#233;rents modules mis au point et encha&#238;n&#233;s lors de l&#8217;analyse. Comme
les documents analys&#233;s sont des blogues, il est dans un premier temps souvent n&#233;cessaire de les
nettoyer pour extraire le texte et exclure tous les &#233;l&#233;ments qui peuvent parasiter l&#8217;analyse.
</p>
<p>Nettoyage Chaque blogue est analys&#233; par un ensemble de programmes visant &#224; extraire le texte
et &#224; &#233;liminer toutes les parties bruit&#233;es et annexes (balises, javascript, etc.).
</p>
<p>S&#233;lection des documents pertinents par rapport &#224; une requ&#234;te La phase de s&#233;lection des do-
cuments pertinents vise &#224; regrouper les documents par rapport &#224; une requ&#234;te donn&#233;e. La
liste des documents potentiellement pertinents &#233;tait fournie directement par les organi-
sateur de TAC mais un tel module doit &#234;tre int&#233;gr&#233; &#224; la plate-forme si le syst&#232;me doit
s&#8217;appuyer directement sur le fonds documentaire.
</p>
<p>Calcul des crit&#232;res de s&#233;lection de phrases Une fois que les textes pertinents ont pu &#234;tre iso-
l&#233;s, il est possible de proc&#233;der au calcul des traits pertinents pour l&#8217;analyse. Nous prenons
en compte quatre types de crit&#232;res principaux :</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;sum&#233; automatique de textes d&#8217;opinions
</p>
<p>&#8211; la mesure de l&#8217;opinion v&#233;hicul&#233;e (polarit&#233; positive ou n&#233;gative) ;
&#8211; la pr&#233;sence de mots centro&#239;des ;
&#8211; la similarit&#233; de la phrase vis&#233;e avec la requ&#234;te ou un des fragments ;
&#8211; la position de la phrase dans le texte.
Nous d&#233;taillons de mani&#232;re beaucoup plus pr&#233;cise l&#8217;ensemble de ces &#233;l&#233;ments dans les
sections qui suivent.
</p>
<p>Pond&#233;ration des phrases La s&#233;lection des phrases est faite sur la base d&#8217;un vecteur de valeurs
issu des calculs effectu&#233;s &#224; l&#8217;&#233;tape pr&#233;c&#233;dente. Pour &#233;viter d&#8217;avoir affaire &#224; des phrases
trop courtes (phrases qui peuvent parasiter l&#8217;analyse car elles correspondent souvent &#224;
des titres ou des parenth&#232;ses mal reconnues lors du d&#233;coupage initial), on exclut toutes
les phrases dont la longueur est inf&#233;rieure &#224; un seuil fix&#233; &#224; l&#8217;avance (ici nous avons utilis&#233;
un seuil de dix mots).
Pour le reste, un score est attribu&#233; &#224; chaque trait, en fonction de son int&#233;r&#234;t pour la t&#226;che.
Ces scores sont attribu&#233;s a priori, sur la base d&#8217;exp&#233;riences faites sur les donn&#233;es d&#8217;entra&#238;-
nement, qui sont parfois disponibles en faible quantit&#233; ou qui ne sont pas compl&#232;tement
repr&#233;sentatives des donn&#233;es &#224; analyser in fine.
</p>
<p>D&#233;tection de la redondance et production du r&#233;sum&#233; Les phrases ayant re&#231;u les scores les
plus &#233;lev&#233;s sont enfin s&#233;lectionn&#233;es pour produire le r&#233;sum&#233;, en commen&#231;ant bien &#233;vi-
demment par la phrase dont le score le plus &#233;lev&#233; (cens&#233; identifier la phrase v&#233;hiculant le
plus d&#8217;information pertinente par rapport &#224; la cible).
Par ailleurs, comme le rel&#232;ve (Radev et al., 2001), ce type d&#8217;approche souffre du fait que
des phrases redondantes peuvent &#234;tre int&#233;gr&#233;es au r&#233;sum&#233;. Avant d&#8217;int&#233;grer une phrase au
r&#233;sum&#233;, on la compare avec les phrases d&#233;j&#224; s&#233;lectionn&#233;es. Si la phrase en cours d&#8217;analyse
a un taux de similarit&#233; sup&#233;rieur &#224; un seuil pr&#233;d&#233;fini, elle n&#8217;est pas int&#233;gr&#233;e.
</p>
<p>Nous avons d&#233;taill&#233; ici les grands principes qui guident la production de r&#233;sum&#233;s. La liste pr&#233;-
cise des traits consid&#233;r&#233;s, leurs poids respectifs et les techniques utilis&#233;es d&#233;pendent de l&#8217;appli-
cation vis&#233;e, ce qui permet d&#8217;avoir un syst&#232;me &#224; la fois g&#233;n&#233;rique et tr&#232;s facilement adaptable &#224;
de nouveaux besoins.
</p>
<p>Nous pr&#233;cisons dans la suite de cette section les techniques de reconnaissance de l&#8217;opinion
v&#233;hicul&#233;e. Les sections suivantes d&#233;tailleront les &#8220;instanciations&#8221; de cette architecture g&#233;n&#233;rique
r&#233;alis&#233;es pour la campagne TAC Opinion Pilot 2008.
</p>
<p>3.3 Calcul de l&#8217;opinion v&#233;hicul&#233;e dans les textes
</p>
<p>Afin de produire un r&#233;sum&#233; rendant compte des opinions exprim&#233;es sur un th&#232;me donn&#233;, il
est n&#233;cessaire d&#8217;identifier les opinions, leur orientation positive et n&#233;gative et si possible leur
intensit&#233;. On peut ainsi regrouper les avis exprim&#233;s par groupes coh&#233;rents et &#233;ventuellement
calculer l&#8217;orientation g&#233;n&#233;rale de l&#8217;opinion sur un sujet donn&#233;.
</p>
<p>Dans les exp&#233;riences que nous pr&#233;sentons ici, nous nous contentons de classer les opinions en
deux grandes classes, positives ou n&#233;gatives. Pour faire cette classification, notre approche est
fond&#233;e sur l&#8217;utilisation d&#8217;un classifieur binaire reposant sur un apprentissage &#224; partir de do-
cuments repr&#233;sentatifs pr&#233;alablement annot&#233;s. Le classifieur essaie de rep&#233;rer automatiquement
les &#233;l&#233;ments pertinents pour une prise de d&#233;cision (texte v&#233;hiculant une opinion positive vs texte
v&#233;hiculant une opinion n&#233;gative). Nous nous appuyons sur un s&#233;parateur &#224; vaste marge (SVM4)
</p>
<p>4http://www.cs.waikato.ac.nz/ml/weka/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Michel G&#233;n&#233;reux et Aur&#233;lien Bossard
</p>
<p>binaire entra&#238;n&#233;e sur des donn&#233;es typiques pour la t&#226;che (en l&#8217;occurrence des exemples de re-
qu&#234;tes fournies pour la phase de mise au point et annot&#233;es manuellement ainsi que le corpus de
films de Cornell5). Le but de cette &#233;tape &#8212; outre la reconnaissance des opinions en elles-m&#234;mes
&#8212; est de permettre ensuite le regroupement des phrases extraites en fonction de l&#8217;opinion ex-
prim&#233;e et de tenir compte de la proportion d&#8217;opinions allant dans un sens ou dans l&#8217;autre, afin
d&#8217;am&#233;liorer le rendu et la lisibilit&#233; du r&#233;sum&#233;.
</p>
<p>Comme nous le montrons plus loin, les r&#233;sultats de l&#8217;analyse de l&#8217;opinion sur les donn&#233;es de
TAC ne semblent pas avoir eu d&#8217;effet positif sur les r&#233;sultats, ce qui est &#233;videmment d&#233;cevant.
Nous analysons ces r&#233;sultats dans la section suivante, mais disons d&#232;s maintenant que l&#8217;ap-
proche au moyen de SVM ne permet pas de classer directement les phrases, car celles-ci com-
portent trop peu d&#8217;&#233;l&#233;ments caract&#233;ristiques. Le choix que nous avons alors d&#251; faire, &#224; savoir de
calculer l&#8217;opinion directement au niveau du blogue puis de reporter cette analyse au niveau de
chaque phrase est sans doute trop grossier, de nombreuses phrases n&#8217;exprimant pas d&#8217;opinion
en tant que tel. Pour illustrer le lien qui existe entre r&#233;sum&#233; et analyse d&#8217;opinions, consid&#233;rons la
requ&#234;te positive &#8220;What features do people like about Vista ?&#8221;, pour laquelle le syst&#232;me pr&#233;f&#233;rera
des phrases tir&#233;es de textes positifs pour le r&#233;sum&#233; (e.g. &#8220;One of the quantum leaps Windows
Vista will make is the move from raster graphics to high-quality vector graphics.&#8221;), et la requ&#234;te
n&#233;gative &#8220;What features do people dislike about Vista ?&#8221;, pour laquelle le syst&#232;me pr&#233;f&#233;rera des
phrases tir&#233;es de textes n&#233;gatifs pour le r&#233;sum&#233; (e.g. &#8220;Buyers may feel hard done-by with this
option, and severely out of pocket purchasing the real Vista experience.&#8221;).
</p>
<p>4 Exp&#233;rience : campagne TAC Opinion 2008
</p>
<p>Nous d&#233;taillons dans cette section l&#8217;instanciation de notre architecture pour la campagne TAC
Opinion 2008. Lors de cette campagne, le syst&#232;me pr&#233;sent&#233; par le LIPN a obtenu des perfor-
mances tr&#232;s homog&#232;nes, &#233;tant la plupart du temps class&#233; parmi les cinq premiers syst&#232;mes et
obtenant m&#234;me le meilleur r&#233;sultat si l&#8217;on fait la moyenne des diff&#233;rents &#233;l&#233;ments &#233;valu&#233;s lors
de la campagne.
</p>
<p>4.1 Description du corpus
</p>
<p>Comme nous l&#8217;avons d&#233;j&#224; dit, la campagne Opinion Pilot 2008 portait sur des blogues en anglais
et &#233;tait tr&#232;s li&#233;e &#224; la campagne de questions-r&#233;ponses ayant lieu dans le m&#234;me cadre. Nous avons
donn&#233; en introduction (section 1) un exemple repr&#233;sentatif. Rappelons que les r&#233;sum&#233;s doivent
correspondre &#224; un th&#232;me, pr&#233;cis&#233; par une liste de questions (la &#8220;squishy list&#8221;).
</p>
<p>Le syst&#232;me disposait en outre d&#8217;une liste de blogues potentiellement pertinents pour la question
et de fragments fournis par les syst&#232;mes de questions-r&#233;ponses. Rappelons ici qu&#8217;un fragment
ne correspond g&#233;n&#233;ralement pas &#224; une s&#233;quence linguistique compl&#232;te et qu&#8217;il peut &#234;tre erron&#233;
(ne pas contenir de r&#233;ponse pertinente par rapport &#224; la question pos&#233;e).
</p>
<p>5http://www.cs.cornell.edu/People/pabo/movie-review-data/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;sum&#233; automatique de textes d&#8217;opinions
</p>
<p>4.2 Instanciation du syst&#232;me pour TAC : liste des traits pris en compte
</p>
<p>Cette section pr&#233;sente l&#8217;instanciation du syst&#232;me d&#233;taill&#233; dans la section pr&#233;c&#233;dente pour TAC.
</p>
<p>Valeur d&#8217;opinion : Nous entra&#238;nons deux classifieurs binaires, le premier pour classer chacun
des blogues, le deuxi&#232;me pour classer les requ&#234;tes. L&#8217;analyse des requ&#234;tes r&#233;v&#232;le une va-
riation limit&#233;e : elles respectent des patrons syntaxico-s&#233;mantiques relativement simples
que le SVM capte ais&#233;ment. Quelques exemples typiques ont suffit &#224; entra&#238;ner le classi-
fieur. L&#8217;analyse des phrases issues des blogues est beaucoup plus difficile. Celles-ci sont
en effet tr&#232;s variables quant &#224; leur longueur, leur structure et leur contenu. Ces obser-
vations ont conduit &#224; une approche prudente mais relativement grossi&#232;re : chaque texte
issu d&#8217;un blogue a &#233;t&#233; pris comme un tout et a servi de base &#224; l&#8217;apprentissage. La valeur
obtenue pour le texte entier a ensuite &#233;t&#233; affect&#233;e &#224; chaque phrase isol&#233;e. Cette approche
a &#233;t&#233; adopt&#233;e apr&#232;s avoir observ&#233; que les blogues &#233;taient tr&#232;s peu souvent nuanc&#233;s. Ils
v&#233;hiculent g&#233;n&#233;ralement des opinions quasi-uniform&#233;ment positives ou n&#233;gatives, ce qui
nous a pouss&#233; &#224; adopter cette approche o&#249; la tendance g&#233;n&#233;rale est r&#233;percut&#233;e sur chaque
phrase particuli&#232;re. Les phrases cens&#233;es v&#233;hiculer une opinion positive re&#231;oivent un score
de +1, les phrases v&#233;hiculant une opinion n&#233;gative un score de -1.
</p>
<p>Phrase la plus longue : La phrase la plus longue d&#8217;un texte re&#231;oit un score de 1, toutes les
autres phrases ont un score &#233;quivalent &#224; 0. D&#8217;autres mesures plus fines sont possibles,
comme par exemple le nombre de mots signifiants.
</p>
<p>Similarit&#233; avec la cible : La similarit&#233; de la phrase avec la cible permet d&#8217;attribuer un score
compris entre 0 et 1.
</p>
<p>Similarit&#233; avec la requ&#234;te : La similarit&#233; de la phrase avec la requ&#234;te re&#231;oit de la m&#234;me ma-
ni&#232;re une valeur situ&#233;e entre 0 et 1.
</p>
<p>Similarit&#233; avec la premi&#232;re phrase du blogue : La similarit&#233; de chaque phrase du blogue consi-
d&#233;r&#233; avec la premi&#232;re phrase du texte re&#231;oit une valeur comprise entre 0 et 1. Ce calcul
repose sur le fait que la premi&#232;re phrase comporte souvent les &#233;l&#233;ments essentiels, au
moins le th&#232;me abord&#233;, comme dans le cas des d&#233;p&#234;ches d&#8217;agence.
</p>
<p>Similarit&#233; avec les fragments : Une liste de fragments est fournie pour chaque cible consid&#233;-
r&#233;e. Chaque phrase re&#231;oit un score compris entre 0 et 1, correspondant &#224; la valeur la plus
grande obtenue lors du calcul (valeur correspondant au trait de similarit&#233; entre la phrase
et le fragment qui lui est le plus semblable).
</p>
<p>Centro&#239;des : Un score est attribu&#233; &#224; chaque phrase s en fonction du nombre de mots significa-
tifs (les centro&#239;des) qu&#8217;elle contient. Cette valeur est calcul&#233;e comme suit :
</p>
<p>centroids =
&#8721;
mots
</p>
<p>term_frequencymot,s &#8727; inverse_document_frequencymot,s (1)
</p>
<p>Cette valeur est finalement normalis&#233;e afin d&#8217;obtenir un score entre 0 et 1. Pour ce faire,
on divise le score obtenu pour chaque phrase par le score obtenu pour la phrase dont le
score est le plus &#233;lev&#233;.
</p>
<p>Position dans le document : Cette valeur refl&#232;te la position de la phrase s par rapport au d&#233;but
du texte. Elle est calcul&#233;e comme suit (sno = le num&#233;ro de la phrase) :
</p>
<p>positions =
&#8730;
1/snos (2)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Michel G&#233;n&#233;reux et Aur&#233;lien Bossard
</p>
<p>Les scores attribu&#233;s &#224; chaque &#233;l&#233;ment sont en outre pond&#233;r&#233;s d&#8217;apr&#232;s la formule 3.
</p>
<p>n&#8721;
i=0
</p>
<p>wi &#8727; fi (3)
</p>
<p>o&#249; wi repr&#233;sente le poids du trait fi. Apr&#232;s une phase exp&#233;rimentale jaugeant la qualit&#233; des r&#233;-
sum&#233;s produits aux vues de diff&#233;rentes combinaisons de poids, la s&#233;lection finale des diff&#233;rents
poids est pr&#233;sent&#233;e dans le tableau 1.
</p>
<p>Crit&#232;re Requ&#234;te positive Requ&#234;te n&#233;gative
Sim...Fragments +100 +100
Sim...Requ&#234;te +40 +40
Sim...Cible +20 +20
Opinion +20 -20
Sim...Premi&#232;rePhrase +10 +10
Centro&#239;des +10 +10
Position +10 +10
PhraseLaPlusLongue -10 -10
</p>
<p>TAB. 1 &#8211; Poids accord&#233; aux diff&#233;rents traits
</p>
<p>On voit ici qu&#8217;un poids important a &#233;t&#233; attribu&#233; &#224; la similarit&#233; entre les phrases et les fragments
(Sim...Fragments), ce qui signifie que le syst&#232;me s&#8217;appuie assez fortement sur les r&#233;sultats des
syst&#232;mes de questions-r&#233;ponses. Les phrases longues sont l&#233;g&#232;rement p&#233;nalis&#233;es.
</p>
<p>4.3 R&#233;sultats obtenus lors de la campagne TAC
</p>
<p>Les r&#233;sultats sont &#233;valu&#233;s en utilisant la m&#233;trique PYRAMIDE (Nenkova et al., 2007), qui
v&#233;rifie que les &#233;l&#233;ments d&#8217;informations essentiels (tels qu&#8217;on les trouve dans des r&#233;sum&#233;s de
r&#233;f&#233;rence r&#233;alis&#233;s par des humains) sont pr&#233;sents. Cette m&#233;trique est compl&#233;t&#233;e par une s&#233;rie
d&#8217;appr&#233;ciations (not&#233;es sur dix par des experts humains) visant &#224; d&#233;terminer la qualit&#233; du r&#233;sum&#233;
(en termes de lisibilit&#233;, grammaticalit&#233;, coh&#233;rence, fluidit&#233; et pertinence). Comme on peut le
voir dans le tableau 2, le syst&#232;me LIPN1-opinion a obtenu des r&#233;sultats tout &#224; fait comp&#233;titifs
par rapport aux autres syst&#232;mes (36 runs ont &#233;t&#233; soumis par l&#8217;ensemble des participants).
</p>
<p>Pyramide Grammaticalit&#233;
F-mesure : 0.393 score : 6.636
</p>
<p>(premier : 0.534, dernier : 0.101) (premier : 7.545, dernier : 3.545)
Absence de redondance Coh&#233;rence
</p>
<p>score : 6.818 score : 3.045
(premier : 8.045, dernier : 4.364) (premier : 3.591, dernier : 2.000)
</p>
<p>Fluidit&#233; Pertinence
score : 4.591 score : 4.500
</p>
<p>(premier : 5.318, dernier : 2.636) (premier : 5.773, dernier : 1.682)
</p>
<p>TAB. 2 &#8211; R&#233;sultats de l&#8217;&#233;valuation</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;sum&#233; automatique de textes d&#8217;opinions
</p>
<p>Si l&#8217;on donne le m&#234;me poids &#224; chacun des six &#233;l&#233;ments &#233;valu&#233;s lors de TAC, LIPN1-opinion
se classe premier avec un score moyen de 0,492 (dernier : 0,290). Si on regroupe les r&#233;sultats
suivant les trois &#8220;axes d&#8217;&#233;valuation&#8221; propos&#233;s par TAC6 et si on prend en compte aussi bien les
r&#233;sum&#233;s produits automatiquement que les r&#233;sum&#233;s &#8220;de contr&#244;le&#8221;, produits par des humains &#224;
titre de r&#233;f&#233;rence et de comparaison, on obtient les r&#233;sultats suivants :
</p>
<p>Contenu : LIPN1-opinion (F-mesure = 0,393 ; premier : 0,534 &#8211; dernier : 0,101) est class&#233; 5e,
derri&#232;re un r&#233;sum&#233; produit &#224; la main et trois produits automatiquement ;
</p>
<p>Lisibilit&#233; : LIPN1-opinion (score = 4,218 ; premier : 4,873 &#8211; dernier : 2,727) est class&#233; 4e,
derri&#232;re un r&#233;sum&#233; produit &#224; la main et deux produits automatiquement ;
</p>
<p>Pertinence globale : LIPN1-opinion (score = 4.500 ; premier : 5,318 &#8211; dernier : 2,636) est
class&#233; 8e, derri&#232;re un r&#233;sum&#233; produit &#224; la main et six produits automatiquement.
</p>
<p>5 Conclusion
</p>
<p>Dans cet article, nous avons montr&#233; un syst&#232;me permettant de produire automatiquement des
r&#233;sum&#233;s de textes porteurs d&#8217;opinions, des blogues notamment. Le syst&#232;me repose sur des tech-
niques classiques en r&#233;sum&#233; : le calcul de diff&#233;rents traits reposant sur des heuristiques d&#233;cou-
lant de diverses exp&#233;riences sont &#224; la base de notre approche.
</p>
<p>Etant donn&#233; les r&#233;sultats que nous avons obtenus pour la campagne TAC 2008, nous pensons
que ce syst&#232;me, encore tr&#232;s basique, constitue n&#233;anmoins un bon point d&#8217;entr&#233;e pour cette t&#226;che.
Nous avons aussi montr&#233; qu&#8217;au-del&#224; des traits sp&#233;cifiques mis en place pour TAC 2008 (notam-
ment l&#8217;usage des fragments &#8212; snippets), d&#8217;autres facteurs pouvaient jouer un r&#244;le positif et
qu&#8217;une combinaison appropri&#233;e de traits pertinents permet d&#8217;obtenir de bons r&#233;sultats.
</p>
<p>L&#8217;approche exp&#233;rimentale adopt&#233;e permet de pr&#233;ciser l&#8217;int&#233;r&#234;t des diff&#233;rents facteurs tradition-
nellement d&#233;crits pour le r&#233;sum&#233; automatique de documents (et inversement, l&#8217;&#233;tude a permis
de montrer le peu d&#8217;int&#233;r&#234;t de certains crit&#232;res pertinents dans d&#8217;autres contextes). Cette &#233;tude
ouvre de nouvelles perspectives pour l&#8217;int&#233;gration de techniques d&#8217;analyse d&#8217;opinions au sein
de syst&#232;mes de r&#233;sum&#233; de texte.
</p>
<p>Remerciements
</p>
<p>Ce travail a &#233;t&#233; en partie financ&#233; par INFOM@GIC du P&#244;le de Comp&#233;titivit&#233; CAP DIGITAL7.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ASHER N., BENAMARA F. &amp; MATHIEU Y. Y. (2008). Distilling opinion in discourse : A
preliminary study. In Coling 2008 : Companion volume : Posters, p. 7&#8211;10, Manchester, UK :
Coling 2008 Organizing Committee.
</p>
<p>6Le NIST, dans un fichier fourni avec les r&#233;sultats, propose les regroupements suivants pour faciliter la lecture
des r&#233;sultats : 1. Contenu (Pyramid) ; 2. Lisibilit&#233; (Grammaticality, Non-redundancy, Structure/Coherence and
Fluency/Readability) et 3. Pertinence globale (Responsiveness).
</p>
<p>7http://www.capdigital.com/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Michel G&#233;n&#233;reux et Aur&#233;lien Bossard
</p>
<p>BOSSARD A., G&#201;N&#201;REUX M. &amp; POIBEAU T. (2008). Description of the LIPN Systems
at TAC2008 : Summarizing Information and Opinions. In Proceedings of the Text Analysis
Conference, NIST, Gaithersburg.
BOUDIN F. &amp; MORENO J. M. T. (2007). NEO-CORTEX : A Performant User-Oriented
Multi-Document Summarization System. In Computational Linguistics and Intelligent Text
Processing, Heidelberg : Springer, Lecture Notes in Computer Science.
CARBONELL J. &amp; GOLDSTEIN J. (1998). The Use of MMR, Diversity-based Reranking for
Reordering Documents and Producing Summaries. In Proc. of the 21st annual international
ACM SIGIR conference on Research and development in IR, p. 335&#8211;336, Melbourne.
CH&#194;AR S. L., FERRET O. &amp; FLUHR C. (2004). Filtrage pour la construction de r&#233;sum&#233;s
multidocuments guid&#233;e par un profil. Traitement Automatique des Langues, 45(1).
CRISPINO G. &amp; COUTO J. (2004). Construction automatique de r&#233;sum&#233;s. Une approche
dynamique. Traitement Automatique des Langues, 45(1).
DEY L. &amp; HAQUE S. K. M. (2008). Opinion mining from noisy text data. In AND &#8217;08 :
Proceedings of the second workshop on Analytics for noisy unstructured text data, p. 83&#8211;90,
New York, NY, USA : ACM.
EDMUNDSON H. P. (1969). New Methods in Automatic Extracting. Journal of the Association
for Computing Machinery, 16(2).
FARZINDAR A., LAPALME G. &amp; DESCL&#201;S J.-P. (2004). R&#233;sum&#233; de textes juridiques par
identification de leur structure th&#233;matique. Traitement Automatique des Langues, 45(1).
GOTTI F., LAPALME G., NERIMA L. &amp; WEHRLI E. (2007). GOFAIsum : A Symbolic Sum-
marizer for DUC. In Document Understanding Conference, Rochester.
GOULET M.-J. (2007). Terminologie et param&#232;tres exp&#233;rimentaux pour l&#8217;&#233;valuation des r&#233;-
sum&#233;s automatiques. Traitement Automatique des Langues, 48(1).
MANI I. (2004). Narrative Summarization. Traitement Automatique des Langues, 45(1).
NENKOVA A., PASSONNEAU R. &amp; MCKEOWN K. (2007). The pyramid method : incorpo-
rating human content selection variation in summarization evaluation. ACM Transactions on
Speech and Language Processing, 4(2), 1&#8211;23.
RADEV D. R., BLAIR-GOLDENSOHN S. &amp; ZHANG Z. (2001). Experiments in single and
multidocument summarization using mead. In First Document Understanding Conference.
TURNEY P. D. (2002). Thumbs up or thumbs down ? semantic orientation applied to unsuper-
vised classification of reviews. In 40th Annual Meeting of the ACL, Philadelphia.
WILSON T., WIEBE J. &amp; HWA R. (2004). Just how mad are you ? Finding strong and weak
opinion clauses. In Proceedings of AAAI-04, 21st Conference of the American Association for
Artificial Intelligence, p. 761&#8211;769, San Jose, US : AAAI Press / The MIT Press.
YOUSFI-MONOD M. (2007). Compression automatique ou semi-automatique de textes par
&#233;lagage des constituants effa&#231;ables : une approche interactive et ind&#233;pendante des corpus.
PhD thesis, Universit&#233; Montpellier II.
YU H. &amp; HATZIVASSILOGLOU V. (2003). Towards answering opinion questions : Separating
facts from opinions and identifying the polarity of opinion sentences. In M. COLLINS &amp;
M. STEEDMAN, Eds., Proceedings of EMNLP-03, 8th Conference on Empirical Methods in
Natural Language Processing, p. 129&#8211;136, Sapporo, JP.
ZHANG W., YU C. &amp; MENG W. (2007). Opinion retrieval from blogs. In CIKM &#8217;07 :
Proceedings of the sixteenth ACM conference on Conference on information and knowledge
management, p. 831&#8211;840, New York, NY, USA : ACM.</p>

</div></div>
</body></html>