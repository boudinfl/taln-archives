TALN 2009, Senlis, 24-26 juin 2009

Résumé automatique de textes d’opinions

Michel Généreux et Aurélien Bossard
Laboratoire d’Informatique de Paris-Nord
(CNRS UMR 7030 et Université Paris 13)
99, av. J.-B. Clément — 93430 Villetaneuse

prénom.nom @ lipn.univ-paris 13.fr

Résumé. Le traitement des langues fait face a une demande croissante en matiere d’ana-
lyse de textes véhiculant des critiques ou des opinions. Nous présentons ici un systeme de
résumé automatique tourné vers l’analyse d’articles postés sur des blogues, ou sont exprimées
a la fois des informations factuelles et des prises de position sur les faits considérés. Nous mon-
trons qu’une approche classique a base de traits de surface est tout a fait efﬁcace dans ce cadre.
Le systeme est évalué a travers une participation a la campagne d’évaluation internationale TAC
(Text Analysis Conference) ou notre systeme a réalisé des performances satisfaisantes.

Abstract. There is currently a growing need concerning the analysis of texts expressing
opinions or judgements. In this paper, we present a summarization system that is speciﬁcally
designed to process blog posts, where factual information is mixed with opinions. We show
that a classical approach based on surface cues is efﬁcient to summarize this kind of texts. The
system is evaluated through a participation to TAC (Text Analysis Conference), an international
evaluation framework for automatic summarization, in which our system obtained good results.

M0tS-CléS I résumé automatique, analyse de textes subjectifs, évaluation automatique.

Keywords: automatic summarization, analysis of subjective texts, automatic evaluation.

1 Introduction

Le résumé automatique a connu un fort renouveau ces dernieres années et les recherches en ce
domaine ont fortement évolué récemment : l’apparition de gros corpus parfois hétérogenes et
la généralisation des techniques d’analyse de surface ont a la fois renouvelé les besoins et les
approches. Plus récemment encore, avec l’avenement de médias plus interactifs, la nécessité de
repérer les citations, les jugements et les opinions s’est avéré de plus en plus crucial. Le but n’est
plus seulement de produire une synthese de l’information contenue dans les textes, il faut en
outre dégager des tendances, identiﬁer les opinions exprimées et si possible en faire la synthese.
Cet article décrit des recherches menées dans ce cadre : nous avons développé un systeme
visant a faire une synthese automatique d’opinions exprimées sur Internet sur un sujet donné,
en particulier dans des articles postés sur des blogues (ci-apres blogues). Le systeme repose
sur une synthese entre des techniques classiques de production de résumé par extraction de
passages pertinents et l’analyse des opinions exprimées dans ces textes. Les blogues comportant
généralement une structure syntaxique irréguliere ainsi qu’une grande richesse néologique, un

Michel Généreux et Aurélien Bossard

minimum de modiﬁcation est nécessaire pour adapter un tel systeme pour le traitement d’autres
types de documents moins complexes.

Pour évaluer notre systeme, nous avons participé a la campagne TAC 2008, une campagne
d’évaluation internationale organisée par le NIST (National Institute of Standards and Tech-
nology) et tournée vers les systemes de questions-réponses et de résumé automatique. L’éva-
luation proposée dans ce cadre mélait résumé factuel et analyse d’opinion, a partir des sorties
de systemes de questions-réponses. L’ enjeu était de produire des syntheses cohérentes a par-
tir de questions en langage naturel — en général, un résumé correspond a plusieurs questions
liées (appelées squishy list) sur un theme donné (appelé target). Pour prendre un exemple, un
des themes proposé était la personnalité de l’année désignée par le magazine Time pour 2005
(“Time Magazine 2005 Person of the Year”). Une des questions liées était la suivante : “Why
did readers support Time ’s inclusion of Bono for Person of the Year .7”. On Voit qu’il s’agit de
questions en “pourquoi” (why) : contrairement aux questions factuelles (questions dites fac-
toides, ou la réponse est généralement une entité nommée), il n’est pas possible de répondre
de facon simple a ces questions en pourquoi. Les systemes de questions-réponses traditionnels,
qui produisent des fragments en guise de réponse (“snippets”, c’est-a-dire de courtes séquences
de texte issues du fonds documentaire et censées contenir une réponse pertinente) ne sont pas
encore tout a fait adaptés pour ce type de probleme. L’ extraction de phrases donnant une idée
des informations essentielles contenues dans le fonds documentaire et formant autant que pos-
sible un tout cohérent, semble une voie plus prometteuse. Les participants a la campagne TAC
Opinion 2008 disposaient de fragments extraits par les systemes de questions-réponses aﬁn de
les aider a produire une synthese cohérente. Nous avons utilisé ces extraits et nous avons ainsi
pu élaborer un systeme tres performant par rapport aux autres systemes évaluésl. Cependant,
cette approche rend notre systeme dépendant des systemes de questions-réponses.

Dans ce qui suit, nous présentons un rapide état de l’art du domaine. Nous présentons ensuite le
systeme que le LIPN a développé pour le résumé automatique de textes véhiculant une opinion ;
ses différents aspects sont détaillés, notaInment les traits de surface utilisés, les procédures de
choix des phrases extraites et leur ordonnancement. Nous présentons ensuite les adaptations que
nous avons dﬁ faire pour répondre aux besoins particuliers de la campagne TAC, les résultats
que nous avons obtenus et leurs limites.

2 Etat de l’art

La génération de résumés reposant sur des principes linguistiques avancés s’est rapidement
avérée trop ambitieuse. C’est pourquoi des les années 1950, la recherche s’est alors tournée
vers des techniques plus sommaires visant a extraire des (segments de) phrases pertinentes.
L’idée consiste a attribuer a chaque phrase un poids puis a extraire, en fonction d’un taux de
compression, les N phrases dont le poids est le plus élevé.

Les techniques a l’oeuvre sont assez intuitives et ont été bien décrites des les années 1960 (Ed-
mundson, 1969) : repérage de mots clés (par rapport au theme abordé), de “signatures” (syn-
tagmes introducteurs typiques de séquences importantes comme en re’sume’, en conclusion, etc.),
prise en compte de la position des phrases dans le documents, etc. Un des systemes actuellement

1Un autre systeme, appelé LIPN2—Opinion, a également obtenu de bonnes performances sans utiliser les frag-
ments foumis par les systemes de questions-réponses. Ce systeme est détaillé dans (Bossard et al., 2008).

Résumé automatique de textes d’opinions

les plus populaires, le systeme MEAD2 Inis au point par Radev, repose sur une approche de ce
type (Radev et al., 2001). Le systeme cherche d’abord a identiﬁer les mots les plus saillants
dans chaque texte, les centroides, eta favoriser les phrases essentiellement constituées des cen-
troi'des. D’autres travaux ont apporté des améliorations a partir de ce schéma de base. On notera
par exemple le systeme Neo-cortex développé a l’Université d’Avignon, qui tire partie de plu-
sieurs mesures de sélection de phrases aﬁn de combiner les avantages de différents types de
traits (Boudin & Moreno, 2007). Ce systeme a récemment obtenu de tres bons résultats3 en
utilisant l’algorithme MMR (Maximal Marginal Relevance) de (Carbonell & Goldstein, 1998).

11 y a eu des tentatives récentes pour réintroduire de la linguistique profonde dans les systemes
de résumés. I1 s’agit essentiellement de travaux opérant directement sur l’arbre syntaxique pour
essayer de proposer des procédés permettant de comparer les arbres, de les élaguer ou de les
fusionner (Gotti et al., 2007), ou encore de méthodes de compression syntaxique basée sur
des propriétés linguistiques théoriques et empiriques (Yousﬁ-Monod, 2007). Nous en restons
dans ce qui suit a une analyse de surface et nous n’avons pas recours a la syntaxe mais ces
travaux constituent des perspectives intéressantes et naturelles au travail présenté ici. D’autres
approches sont possibles, notamment celles fondées sur la représentation des connaissances
(Mani, 2004), la segmentation thématique (Farzindar et al., 2004) ou le proﬁl utilisateur (Chaar
et al., 2004; Crispino & Couto, 2004).

Dans le domaine des opinions, les travaux précédents se sont surtout attardés a leur détection
ainsi qu’a la gradation de leur niveau affectif, et ce selon trois niveaux principaux de sous-
taches. La premiere sous-tache consiste a distinguer les textes subjectifs des textes objectifs
(Yu & Hatzivassiloglou, 2003). La seconde sous-tache s’attarde a classer les textes subjectifs
en positifs or ne’gatifs (Turney, 2002). Le troisieme niveau de rafﬁnement essaie de déterminer
jusqu’a quel point les textes sont positifs ou négatifs (Wilson et al., 2004). L’impulsion donnée
par des campagnes telles que TREC Blog Opinion Task depuis 2006 est incontestable (Zhang
et al., 2007; Dey & Haque, 2008). I1 faut reconnaitre que notre traitement des opinions pour
l’aide a la production de résumé de textes d’opinion ne Va pas au-dela de la distinction standard
positif versus négatif, et qu’il faut signaler les efforts récents pour réintroduire des approches
plus linguistiques et discursives (prise en compte de la modalité, de l’énonciateur) dans ce
domaine (Asher et al., 2008).

En ce qui concerne l’évaluation de résumés, soulignons la contribution de (Goulet, 2007) qui
Va au-dela de la couverture des n-grammes et propose une terminologie adaptée au francais.

3 Description du systeme

L’ approche que nous avons développée combine des techniques traditionnellement employées
pour le résumé automatique de textes avec des techniques de détection et d’analyse d’opinions.

3.1 Principes généraux

A la différence des systemes de résumé traditionnels qui prennent en entrée un texte (ou un
ensemble de textes dans le cas du résumé multi-documents), notre systeme repose fondamenta-

zhttp : //www . summari zation . com/mead/
3NIST Document Understanding Conference (DUC) 2006

Michel Généreux et Aurélien Bossard

lement sur une requéte qui permet de préciser le fait ou l’objet a propos duquel l’utilisateur sou-
haite obtenir une synthese. En effet, il n’y a guere de sens a proposer un systeme produisant des
résumés rendant compte des opinions exprimées si l’on n’a pas précisé d’abord la cible recher-
chée, c’est-a-dire l’événement, la personne ou l’objet a propos duquel on cherche a connaitre
l’état de l’opinion. De ce fait, le systeme repose fondamentalement sur deux éléments : 1) une
requéte comprenant une cible et éventuellement des questions annexes permettant de préciser
l’information recherchée, 2) le fonds documentaire qui sert de base a la production de résumé.
On remarquera, du fait de la présence d’une requéte, le lien assez direct entre ce type de sys-
temes et les systemes de questions-réponses.

Notons a ce propos que la campagne TAC 2008 fournissait en outre une liste de fragments (snip-
pets ou fragments) préalablement produits par un systeme de questions-réponses (un snippet est
un court extrait de texte, de taille ﬁxe ou non, mais ne correspondant pas obligatoirement a une
séquence linguistique complete, censé donner un élément de réponse par rapport a une requéte).
On verra l’importance de ces éléments de réponse pour le systeme dans la section traitant plus
spéciﬁquement de notre participation a la campagne TAC.

Comme la plupart des systemes participant aux campagnes d’évaluation comme TAC, notre
systeme repose fondamentalement sur un ensemble d’heuristiques. Celles-ci reﬂetent indirec-
tement les observations d’analystes quant aux facteurs a prendre en compte pour produire un
résumé par extraction. Soulignons des a present le manque de fondement théorique de ce type
d’approches, leur dépendance plus ou moins grande vis-a-vis du domaine ou du type de texte
considéré ; toutefois, comme nous l’avons rappelé dans la section précédente, le peu de résultats
des approches génératives a contribué au succes des approches a base d’heuristiques (meme si
les approches génératives semblent reposer sur des fondements linguistiques plus assurés).

3.2 Architecture

Dans cette campagne TAC, le systeme construit doit traiter en entrée une cible, une ou deux
questions en rapport avec la cible, un groupe de documents (des blogues) pouvant contenir les
réponses ou éléments essentiels a nos questions, ainsi que les snippets, fournis par TAC mais
dont l’usage en entrée est optionelle. En sortie, le systeme pruduit doit foumir un seul résumé
pour chaque combinaison cible/questions/documents.

Cette section décrit les différents modules Inis au point et enchainés lors de l’analyse. Comme
les documents analysés sont des blogues, il est dans un premier temps souvent nécessaire de les
nettoyer pour extraire le texte et exclure tous les éléments qui peuvent parasiter l’analyse.

N ettoyage Chaque blogue est analysé par un ensemble de programmes visant a extraire le texte
et a éliminer toutes les parties bruitées et annexes (balises, javascript, etc.).

Sélection des documents pertinents par rapport £1 une requéte La phase de sélection des do-
cuments pertinents vise a regrouper les documents par rapport a une requéte donnée. La
liste des documents potentiellement pertinents était foumie directement par les organi-
sateur de TAC mais un tel module doit étre intégré a la plate-forme si le systeme doit
s’appuyer directement sur le fonds documentaire.

Calcul des critéres de sélection de phrases Une fois que les textes pertinents ont pu étre iso-
lés, il est possible de procéder au calcul des traits pertinents pour l’analyse. Nous prenons
en compte quatre types de criteres principaux :

Résumé automatique de textes d’opinions

la mesure de l’opinion véhiculée (polarité positive ou négative) ;

la présence de mots centroi'des;

la similarité de la phrase visée avec la requéte ou un des fragments;

la position de la phrase dans le texte.

Nous détaillons de maniere beaucoup plus précise l’ensemble de ces éléments dans les
sections qui suivent.

Pondération des phrases La sélection des phrases est faite sur la base d’un vecteur de valeurs
issu des calculs effectués a l’étape précédente. Pour éviter d’avoir affaire a des phrases
trop courtes (phrases qui peuvent parasiter l’analyse car elles correspondent souvent a
des titres ou des parentheses mal reconnues lors du découpage initial), on exclut toutes
les phrases dont la longueur est inférieure a un seuil ﬁxé a l’avance (ici nous avons utilisé
un seuil de dix mots).
Pour le reste, un score est attribué a chaque trait, en fonction de son intérét pour la tache.
Ces scores sont attribués a priori, sur la base d’expé1iences faites sur les données d’entrai-
nement, qui sont parfois disponibles en faible quantité ou qui ne sont pas completement
représentatives des données a analyser in ﬁne.

Détection de la redondance et production du résumé Les phrases ayant recu les scores les

plus élevés sont enﬁn sélectionnées pour produire le résumé, en commencant bien evi-
demment par la phrase dont le score le plus élevé (censé identiﬁer la phrase véhiculant le
plus d’information pertinente par rapport a la cible).
Par ailleurs, comme le releve (Radev et al., 2001), ce type d’approche souffre du fait que
des phrases redondantes peuvent étre intégrées au résumé. Avant d’intégrer une phrase au
résumé, on la compare avec les phrases déja sélectionnées. Si la phrase en cours d’analyse
a un taux de similarité supérieur a un seuil prédéﬁni, elle n’est pas intégrée.

Nous avons détaillé ici les grands principes qui guident la production de résumés. La liste pré-
cise des traits considérés, leurs poids respectifs et les techniques utilisées dépendent de l’appli-
cation visée, ce qui permet d’avoir un systeme a la fois générique et tres facilement adaptable a
de nouveaux besoins.

Nous précisons dans la suite de cette section les techniques de reconnaissance de l’opinion
véhiculée. Les sections suivantes détailleront les “instanciations” de cette architecture générique
réalisées pour la campagne TAC Opinion Pilot 2008.

3.3 Calcul de l’opinion véhiculée dans les textes

Aﬁn de produire un résumé rendant compte des opinions exprimées sur un theme donné, il
est nécessaire d’identiﬁer les opinions, leur orientation positive et négative et si possible leur
intensité. On peut ainsi regrouper les avis exprimés par groupes cohérents et éventuellement
calculer l’orientation générale de l’opinion sur un sujet donné.

Dans les expériences que nous présentons ici, nous nous contentons de classer les opinions en
deux grandes classes, positives ou négatives. Pour faire cette classiﬁcation, notre approche est
fondée sur l’utilisation d’un classiﬁeur binaire reposant sur un apprentissage a partir de do-
cuments représentatifs préalablement annotés. Le classiﬁeur essaie de repérer automatiquement
les éléments pertinents pour une prise de décision (texte véhiculant une opinion positive vs texte
véhiculant une opinion négative). Nous nous appuyons sur un séparateur a vaste marge (SVM4)

4http://www.cs.waikato.ac.nz/ml/weka/

Michel Généreux et Aurélien Bossard

binaire entrainée sur des données typiques pour la tache (en l’occurrence des exemples de re-
quétes fournies pour la phase de Inise au point et annotées manuellement ainsi que le corpus de
ﬁlms de Comell5). Le but de cette étape — outre la reconnaissance des opinions en elles-mémes
— est de permettre ensuite le regroupement des phrases extraites en fonction de l’opinion ex-
primée et de tenir compte de la proportion d’opinions allant dans un sens ou dans l’autre, aﬁn
d’améliorer le rendu et la lisibilité du résumé.

Comme nous le montrons plus loin, les résultats de l’analyse de l’opinion sur les données de
TAC ne semblent pas avoir eu d’effet positif sur les résultats, ce qui est évidemment décevant.
Nous analysons ces résultats dans la section suivante, mais disons des maintenant que l’ap-
proche au moyen de SVM ne permet pas de classer directement les phrases, car celles-ci com-
portent trop peu d’éléments caractéristiques. Le choix que nous avons alors dﬁ faire, a savoir de
calculer l’opinion directement au niveau du blogue puis de reporter cette analyse au niveau de
chaque phrase est sans doute trop grossier, de nombreuses phrases n’exprimant pas d’opinion
en tant que tel. Pour illustrer le lien qui existe entre résumé et analyse d’opinions, considérons la
requéte positive “What features do people like about Wsta ? ”, pour laquelle le systeme préférera
des phrases tirées de textes positifs pour le résumé (e. g. “One of the quantum leaps Windows
Wsta will make is the move from raster graphics to high-quality vector graphics.”), et la requéte
négative “What features do people dislike about Wsta ? ”, pour laquelle le systeme préférera des
phrases tirées de textes négatifs pour le résumé (e.g. “Buyers may feel hard done-by with this
option, and severely out of pocket purchasing the real Wsta experience”).

4 Expérience : campagne TAC Opinion 2008

Nous détaillons dans cette section l’instanciation de notre architecture pour la campagne TAC
Opinion 2008. Lors de cette campagne, le systeme présenté par le LIPN a obtenu des perfor-
mances tres homogenes, étant la plupart du temps classé parmi les cinq premiers systemes et
obtenant meme le meilleur résultat si l’on fait la moyenne des différents éléments évalués lors
de la campagne.

4.1 Description du corpus

Comme nous l’avons déja dit, la campagne Opinion Pilot 2008 portait sur des blogues en anglais
et était tres liée a la campagne de questions-réponses ayant lieu dans le meme cadre. Nous avons
donné en introduction (section 1) un exemple représentatif. Rappelons que les résumés doivent
correspondre a un theme, précisé par une liste de questions (la “squishy list”).

Le systeme disposait en outre d’une liste de blogues potentiellement pertinents pour la question
et de fragments fournis par les systemes de questions-réponses. Rappelons ici qu’un fragment
ne correspond généralement pas a une séquence linguistique complete et qu’il peut étre erroné
(ne pas contenir de réponse pertinente par rapport a la question posée).

Shttp://www.cs.cornell.edu/People/pabo/movie-review—data/

Résumé automatique de textes d’opinions

4.2 Instanciation du systéme pour TAC : liste des traits pris en compte

Cette section présente l’instanciation du systeme détaillé dans la section précédente pour TAC.

Valeur d’opinion : Nous entrainons deux classiﬁeurs binaires, le premier pour classer chacun
des blogues, le deuxieme pour classer les requétes. L’ analyse des requétes révele une va-
riation limitée : elles respectent des patrons syntaxico-sémantiques relativement simples
que le SVM capte aisément. Quelques exemples typiques ont sufﬁt a entrainer le classi-
ﬁeur. L’analyse des phrases issues des blogues est beaucoup plus difﬁcile. Celles-ci sont
en effet tres variables quant a leur longueur, leur structure et leur contenu. Ces obser-
vations ont conduit a une approche prudente mais relativement grossiere : chaque texte
issu d’un blogue a été pris comme un tout et a servi de base a l’apprentissage. La valeur
obtenue pour le texte entier a ensuite été affectée a chaque phrase isolée. Cette approche
a été adoptée apres avoir observé que les blogues étaient tres peu souvent nuancés. Ils
véhiculent généralement des opinions quasi-uniformément positives ou négatives, ce qui
nous a poussé a adopter cette approche ou la tendance générale est répercutée sur chaque
phrase particuliere. Les phrases censées véhiculer une opinion positive recoivent un score
de +1, les phrases véhiculant une opinion négative un score de -1.

Phrase la plus longue : La phrase la plus longue d’un texte recoit un score de 1, toutes les
autres phrases ont un score equivalent a 0. D’autres mesures plus ﬁnes sont possibles,
comme par exemple le nombre de mots signiﬁants.

Similarité avec la cible : La similarité de la phrase avec la cible permet d’attribuer un score
compris entre 0 et 1.

Similarité avec la requéte : La similarité de la phrase avec la requéte recoit de la meme ma-
niere une valeur située entre 0 et 1.

Similarité avec la premiere phrase du blogue : La similarité de chaque phrase du blogue consi-
déré avec la premiere phrase du texte recoit une valeur comprise entre 0 et 1. Ce calcul
repose sur le fait que la premiere phrase comporte souvent les éléments essentiels, au
moins le theme abordé, comme dans le cas des dépéches d’agence.

Similarité avec les fragments : Une liste de fragments est foumie pour chaque cible conside-
rée. Chaque phrase recoit un score compris entre 0 et 1, correspondant a la valeur la plus
grande obtenue lors du calcul (valeur correspondant au trait de similarité entre la phrase
et le fragment qui lui est le plus semblable).

Centro'1'des : Un score est attribué a chaque phrase s en fonction du nombre de mots signiﬁca-
tifs (les centro'1'des) qu’elle contient. Cette valeur est calculée comme suit :

centroids = Z term_frequencym0,;,s * im1erse_document_ frequencymohs (1)
mots

Cette valeur est ﬁnalement normalisée aﬁn d’obtenir un score entre 0 et 1. Pour ce faire,
on divise le score obtenu pour chaque phrase par le score obtenu pour la phrase dont le
score est le plus élevé.

Position dans le document : Cette valeur reﬂete la position de la phrase s par rapport au début
du texte. Elle est calculée comme suit (sno = le numéro de la phrase) :

positions = V 1/3720, (2)

Michel Généreux et Aurélien Bossard

Les scores attribués a chaque élément sont en outre pondérés d’apres la formule 3.

g wi * fi (3)
i=0

ou w,- représente le poids du trait f,-. Apres une phase expérimentale jaugeant la qualité des ré-
sumés produits aux vues de différentes combinaisons de poids, la sélection ﬁnale des différents
poids est présentée dans le tableau 1.

Critére Requéte positive Requéte négative
Sim...Fragments + 100 +100
Sim...Requéte +40 +40
Sim...Cib1e +20 +20
Opinion +20 -20
Sim...PremierePhrase +10 +10
Centroi'des +10 +10
Position +10 +10
PhraseLaPlusLongue -10 - 10

TAB. 1 — Poids accordé aux différents traits

On voit ici qu’un poids important a été attribué a la similarité entre les phrases et les fragments
(Sim...Fragments), ce qui signiﬁe que le systeme s’appuie assez fortement sur les résultats des
systemes de questions-réponses. Les phrases longues sont légerement pénalisées.

4.3 Résultats obtenus lors de la campagne TAC

Les résultats sont évalués en utilisant la métrique PYRAMIDE (Nenkova et al., 2007), qui
vériﬁe que les éléments d’informations essentiels (tels qu’on les trouve dans des résumés de
référence réalisés par des humains) sont présents. Cette métrique est complétée par une série
d’ appréciations (notées sur dix par des experts humains) visant a déterminer la qualité du résumé
(en termes de lisibilité, grammaticalité, cohérence, ﬂuidité et pertinence). Come on peut le
voir dans le tableau 2, le systeme LIPN1-opinion a obtenu des résultats tout a fait compétitifs
par rapport aux autres systemes (36 runs ont été soumis par l’ensemble des participants).

Pyramide Grammaticalité
F-mesure : 0.393 score : 6.636
(premier : 0.534, demier : 0.101) (premier : 7.545, dernier : 3.545)
Absence de redondance Cohérence
score : 6.818 score : 3.045
(premier : 8.045, demier : 4.364) (premier : 3.591, dernier : 2.000)
Fluidité Pertinence
score : 4.591 score : 4.500
(premier : 5.318, demier : 2.636) (premier : 5.773, dernier : 1.682)

TAB. 2 — Résultats de l’évaluation

Resume automatique de textes d’opinions

Si l’on donne le meme poids a chacun des six elements evalues lors de TAC, LIPN1-opinion
se classe premier avec un score moyen de 0,492 (demier : 0,290). Si on regroupe les resultats
suivant les trois “axes d’evaluation” proposes par TAC6 et si on prend en compte aussi bien les
resumes produits automatiquement que les resumes “de controle”, produits par des humains a
titre de reference et de comparaison, on obtient les resultats suivants :

Contenu : LIPN1-opinion (F-mesure = 0,393 ; premier : 0,534 — dernier : 0,101) est classe 55,
derriere un resume produit a la main et trois produits automatiquement;

Lisibilité : LIPN1-opinion (score = 4,218; premier : 4,873 — demier : 2,727) est classe 45,
derriere un resume produit a la main et deux produits automatiquement;

Pertinence globale: LIPN1-opinion (score = 4.500; premier : 5,318 — demier : 2,636) est
classe 86, derriere un resume produit a la main et six produits automatiquement.

5 Conclusion

Dans cet article, nous avons montre un systeme permettant de produire automatiquement des
resumes de textes porteurs d’opinions, des blogues notamment. Le systeme repose sur des tech-
niques classiques en resume : le calcul de differents traits reposant sur des heuristiques decou-
lant de diverses experiences sont a la base de notre approche.

Etant donne les resultats que nous avons obtenus pour la campagne TAC 2008, nous pensons
que ce systeme, encore tres basique, constitue neanmoins un bon point d’ entree pour cette tache.
Nous avons aussi montre qu’au-dela des traits speciﬁques mis en place pour TAC 2008 (notam-
ment l’usage des fragments — snippets), d’autres facteurs pouvaient jouer un role positif et
qu’une combinaison appropriee de traits pertinents permet d’obtenir de bons resultats.

L’ approche experimentale adoptee permet de preciser l’interet des differents facteurs tradition-
nellement decrits pour le resume automatique de documents (et inversement, l’etude a permis
de montrer le peu d’interét de certains criteres pertinents dans d’autres contextes). Cette etude
ouvre de nouvelles perspectives pour l’integration de techniques d’analyse d’opinions au sein
de systemes de resume de texte.

Remerciements

Ce travail a ete en partie ﬁnance par INF OM @ GIC du Pole de Competitivite CAP DIGITAL7.

Références

ASHER N., BENAMARA F. & MATHIEU Y. Y. (2008). Distilling opinion in discourse : A
preliminary study. In Coling 2008 .' Companion volume .' Posters, p. 7-10, Manchester, UK :
Coling 2008 Organizing Committee.

5Le NIST, dans un ﬁchier foumi avec les résultats, propose les regroupements suivants pour faciliter la lecture
des résultats : 1. Contenu (Pyramid); 2. Lisibilité (Grammaticality, Non-redundancy, Structure/Coherence and
F1uency/Readability) et 3. Pertinence globale (Responsiveness).

7http://www.capdigital.com/

Michel Généreux et Aurélien Bossard

BOSSARD A., GENEREUX M. & POIBEAU T. (2008). Description of the LIPN Systems
at TAC2008 : Summarizing Information and Opinions. In Proceedings of the Text Analysis
Conference, NIST, Gaithersburg.

BOUDIN F. & MORENO J. M. T. (2007). NEO-CORTEX : A Performant User-Oriented
Multi-Document Summarization System. In Computational Linguistics and Intelligent Text
Processing, Heidelberg : Springer, Lecture Notes in Computer Science.

CARBONELL J. & GOLDSTEIN J. (1998). The Use of MMR, Diversity-based Reranking for
Reordering Documents and Producing Summaries. In Proc. of the 21 st annual international
ACM SIGIR conference on Research and development in IR, p. 335-336, Melbourne.

CHAAR S. L., FERRET O. & FLUHR C. (2004). Filtrage pour la construction de résumés
multidocuments guidée par un proﬁl. Traitement Automatique des Langues, 45(1).

CRISPINO G. & COUTO J. (2004). Construction automatique de résumés. Une approche
dynamique. Traitement Automatique des Langues, 45(1).

DEY L. & HAQUE S. K. M. (2008). Opinion mining from noisy text data. In AND ’08 .-
Proceedings of the second workshop on Analytics for noisy unstructured text data, p. 83-90,
New York, NY, USA : ACM.

EDMUNDSON H. P. (1969). New Methods in Automatic Extracting. Journal of the Association
for Computing Machinery, 16(2).

FARZINDAR A., LAPALME G. & DESCLES J .-P. (2004). Résumé de textes juridiques par
identiﬁcation de leur structure thématique. Traitement Automatique des Langues, 45(1).
GOTTI F., LAPALME G., NERIMA L. & WEHRLI E. (2007). GOFAIsum : A Symbolic Sum-
marizer for DUC. In Document Understanding Conference, Rochester.

GOULET M.-J. (2007). Terminologie et parametres expérimentaux pour l’évaluation des re-
sumés automatiques. Traitement Automatique des Langues, 48(1).

MANI I. (2004). Narrative Summarization. Traitement Automatique des Langues, 45(1).
NENKOVA A., PASSONNEAU R. & MCKEOWN K. (2007). The pyramid method : incorpo-
rating human content selection variation in summarization evaluation. ACM Transactions on
Speech and Language Processing, 4(2), 1-23.

RADEV D. R., BLAIR-GOLDENSOHN S. & ZHANG Z. (2001). Experiments in single and
multidocument summarization using mead. In First Document Understanding Conference.

T URNEY P. D. (2002). Thumbs up or thumbs down ? semantic orientation applied to unsuper-
vised classiﬁcation of reviews. In 40th Annual Meeting of the ACL, Philadelphia.

WILSON T., WIEBE J . & HWA R. (2004). Just how mad are you ? Finding strong and weak
opinion clauses. In Proceedings of AAAI-04, 21 st Conference of the American Association for
Artiﬁcial Intelligence, p. 761-769, San Jose, US : AAAI Press / The MIT Press.
YOUSFI-MONOD M. (2007). Compression automatique ou semi-automatique de textes par
élagage des constituants ejfacables .' une approche interactive et indépendante des corpus.
PhD thesis, Université Montpellier II.

YU H. & HATZIVASSILOGLOU V. (2003). Towards answering opinion questions : Separating
facts from opinions and identifying the polarity of opinion sentences. In M. COLLINS &
M. STEEDMAN, Eds., Proceedings of EMNLP-03, 8th Conference on Empirical Methods in
Natural Language Processing, p. 129-136, Sapporo, JP.

ZHANG W., YU C. & MENG W. (2007). Opinion retrieval from blogs. In CIKM ’07 .-

Proceedings of the sixteenth ACM conference on Conference on information and knowledge
management, p. 831-840, New York, NY, USA : ACM.

