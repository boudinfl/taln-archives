TALN 2009, Senlis, 24-26 juin 2009

Vers des contraintes plus linguistiques en résolution de
coréférences

Etienne Ailloud Manfred Klenner
Institute of Computational Linguistics
Zurich University

Zurich, Switzerland
{ailloud,klenner} @cl.uzh.ch

Résumé. Nous proposons un modele ﬁltrant de résolution de coréférences basé sur les
notions de transitivité et d’exclusivité linguistique. A partir de l’hypothese générale que les
chaines de coréférence demeurent cohérentes tout au long d’un texte, notre modele assure le
respect de certaines contraintes linguistiques (via des ﬁltres) quant a la coréférence, ce qui
améliore la résolution globale. Le ﬁltrage a lieu a différentes étapes de l’approche standard
(c-a-d. par apprentissage automatique), y compris avant l’apprentissage et avant la classiﬁcation,
accélérant et améliorant ce processus.

Abstract. We propose a ﬁlter model of coreference resolution that is based on the notions
of transitivity and linguistic exclusivity. Starting from the general assumption that coreference
sets remain coherent throughout a text, our model enforces the checking of some compatibil-
ity criteria (ﬁlters) between coreference candidates, thereby improving resolution performance.
This ﬁltering is achieved at different stages of the workﬂow of machine-leaming-based corefer-
ence resolution, including at the standard learning and testing steps, where it may help reduce
the computational load and better distribute the actual occurrences to be learned.

M0tS-CléS I Résolution de coréférences, apprentissage automatique, linguistique infor-
matique par contraintes.

Keywords: Coreference resolution, Machine learning, Constraint-based NLP.

I-/Etienne Ailloud, Manfred Klenner

1 Introduction

La résolution de coréférences est une tache utile dans de nombreuses applications de traitement
du langage naturel, par exemple l’extraction d’informations. Pour identiﬁer une entité parmi
un ensemble de documents, il est crucial de pouvoir identiﬁer les diverses expressions pouvant
y référer, y compris les expressions anaphoriques (p. ex.des pronoms). Trouver un antécédent
a chacune de celles-ci se nomme la résolution d’anaphores, trouver toutes les occurrences de
la méme entité est la résolution de coréférences, plus générale. Mais méme pour la résolution
d’anaphores comme sous-tache, les systemes actuels ont encore des performances insatisfai-
santes (entre 55% et 70% pour la F-mesure sur données réelles). L’approche standard consiste
a entrainer un modele d’apprentissage automatique a produire des décisions binaires (des ré-
ponses a « L’ expression a coréfere-t-elle avec l’expression b ? »).

Le probleme majeur dans l’approche informatique de la résolution de coréférences est son
manque de contraintes : l’éventail des contraintes qui régissent le phénomene de coréférence
est plus large que ce qui peut étre correctement modélisé a l’heure actuelle. Par exemple, se
restreindre aux seules contraintes morpho-syntaxiques jouant sur différentes expressions lin-
guistiques ne sufﬁt pas, dans beaucoup de langues (méme celles morphologiquement marquées
comme l’allemand), a discriminer sufﬁsamment entre différent candidats potentiellement réfé-
rents (les markables). Les contraintes nécessaires ici sont issues d’autres couches du traitement
du langage : sémantique, pragmatique. En l’absence de ces contraintes de haut niveau, la resolu-
tion de coréférences devient un probleme combinatoire : l’énumération de toutes les possibilités
(c-a-d. toutes les paires de markables) occupe Vite trop d’espace en mémoire. Aussi la réduction
de l’espace de recherche constitue-t-elle la pierre d’achoppement de la plupart des approches
d’apprentissage automatique : pour rester réalisables, celles-ci sont restreintes par des heuris-
tiques qui font que seulement une partie des possibilités est explorée. Par exemple, on se limite
généralement a des paires de markables (en se fondant sur le postulat usuel que l’observation
binaire est sufﬁsante pour capturer le phénomene de coréférence) ; la résolution de coréférences
est généralement restreinte en portée, également : en utilisant p. ex. des fenétres mobiles (la
derniere référence a une entité connue étant susceptible d’apparaitre dans un contexte récent).

Considérons l’exemple en allemand suivant, dans lequel différents constituants nominaux mas-
culins font référence a deux entités différentes :

[Der jugoslawische Prasident], ist in diesem Sinne kalt, denn [er] 3- kennt [[seinen];,

Westen] ;. [Er]m hat [ihn],, dort studiert, wo [er] 1, am westlichsten ist, als Banker in

New York.

[The Yugoslavian president], is in this sense cold, for [he] 3- knows [[his],, western

society];. [He]m studied [it],, where [it] 1, is at its most west-like, as a banker in New

York.
La traduction anglaise de ces phrases révele immédiatement les coréférences, a travers l’op-
position masculin/neutre. Cependant, la morphologie allemande ne permet pas de distinguer
ces syntagmes les uns des autres, tous de méme genre, nombre et personne, alors que la lec-
ture préférée donne i E j E k E m 5.5 l E n E p (ou, comme chaines de coréférence :

{{1} J) k, m}, {la n,p}}).

On peut aussi formuler des restrictions de portée plus générale (non locale), p. ex. la transitivite’.
Celle-ci permet, couplée avec l’exclusivité, d’exclure des paires de coréférence impossibles (en
considérant la partition en classes d’équivalence selon la relation 2) : Sachant que j 5.5 ll,

1. << A non-reﬂexive pronoun must not be coindexed with a c—commandjng NP within the minimal NP or S that

Vers des contraintes plus linguistiques en resolution de coreferences

chercher a lier [Er]m dans la phrase precedente oblige a choisir (de maniere exclusive) soit
m E j, soit m E l. Cette observation simple liInite le choix de chaines de coreference a deux
possibilites (pour les trois markables consideres) : {{j, m},  et {{j}, {l, m}}; Pourtant
un classiﬁeur automatique, limite dans sa vision binaire, peut eventuellement produire 61 la
fois m E j et m E l, induisant par transitivite la chaine de coreference {{m, j,  Celle-
ci est inconsistante en ce qu’elle implique que j E l, bien que la paire (j, l) n’ait jamais ete
consideree elle-meme (car elle contredit l’exclusivite du sujet j et de l’objet non-reﬂexif l).
Nous y reviendrons en partie 3.

La transitivite et l’exclusivite sont deux restrictions dures, la premiere etant meme indepen-
dante d’une quelconque theorie syntaxique : c’est plutot au manque de consistance logique
qu’elle s’attaque. Ceci n’a pas ete reellement aborde dans la litterature (voir cependant (Finkel
& Manning, 2008) ou (Denis & Baldridge, 2008a)), alors que nous montrons qu’elle peut ame-
liorer les performances globales de la resolution de coreferences. L’ elimination des paires de
markables qui contredisent la transitivite, couplee a une notion d’exclusivite adaptee, constitue
une sorte de ﬁltre de consistance.

Dans la prochaine partie nous decrirons le contexte general de l’apprentissage automatique ou
se situe notre modele. Puis la partie 3 ira plus en details dans les concepts-cles de transitivite et
d’exclusivite, conduisant a la description du modele lui-meme en partie 4. Nous presenterons
des resultats experimentaux a l’appui en partie 5, et des approches comparables en partie 6.

2 Apprentissage automatique de paires de coréférence

En partant d’une liste de markables—les objets linguistiques se referant potentiellement aux en-
tites du discours—et des informations s’y rapportant (leurs traits linguistiques, p. ex.), l’objectif
est de predire lesquels sont coreferents parmi des markables non vus. La plupart des approches
sont basees sur l’apprentissage automatique de paires de markables. Une seconde phase agrege
les markables coreferents en classes d’equivalence (les chaines de coreference).

Traits Le classiﬁeur extrait l’information qui lui est utile d’un ensemble de traits, determines
a partir des markables ou de paires d’iceux en utilisant l’information linguistique accessible ; ils
sont relatifs a : la structure superﬁcielle (p. ex. la distance entre deux markables), la morpho-
syntaxe (p. ex. leur fonction grammaticale), de la semantique basique (p. ex. la compatibilite
ontologique des markables). D’un point de vue linguistique, certains traits encodent en fait
peu d’information, comme la distance entre deux markables; certains sont plus ou moins une
transcription directe de l’information foumie (p. ex. quand les categories lexicales elles-memes
sont utilisees comme traits).

Phase d’agrégation Une consequence importante de la production de paires de markables
est qu’un post-traitement est necessaire pour acceder aux chaines de coreference. Celles-ci sont
obtenues en fusionnant les paires de markables coreferents en classes d’equivalence. Leur im-
portance, par opposition aux seules paires en sortie, se reﬂete aussi dans le schema d’evaluation :
la mesure standard MUC (Vilain et al., 1995), de meme que son extension B3 (Bagga & Bald-
win, 1998), mesure l’harmonie des resultats avec le gold standard plutot sur le plan des chaines

contains it. » (cf. (Chierchia & McConnell-Ginet, 1990))

I-/Etienne Ailloud, Manfred Klenner

que des paires. Ceci est d’autant plus vrai pour la nouvelle mesure ECM (introduite dans (Luo,
2005)), qui cherche d’abord a aligner les chaines de coréférence avec le standard et ensuite
seulement calcule les résultats.

L’ exemple de l’introduction illustre le probleme majeur dans le traitement binaire de la coréfé-
rence : L’ agrégation canonique de markables a partir de paires, par simple fusionnement (c-a-d.
quand deux markables appartiennent a la méme chaine ss’ils forment une paire coréférente),
induit une inconsistance dans les chaines de coréférence? Cette inconsistance est inévitable, car
le classiﬁeur binaire considere les paires de markables comme des événements indépendants : il
ne peut pas apprendre a faire le rapprochement entre deux paires, méme si elles ont un élément
en commun—il ne peut pas apprendre la transitivité.

D’autres procédés d’agrégation plus sophistiqués produisent de l’inconsistance de la meme ma-
niere. Ils fonctionnent de gauche a droite de maniere incrémentielle, en assignant a chaque
« anaphore » un « antécédent » idoine parmi les markables la précédant.3 L’ agrégation closest-
ﬁrst consiste a prendre pour cela le premier markable satisfaisant dans le contexte gauche de
l’anaphore (voir p. ex. (Soon et al., 2001)). L’agrégation best-ﬁrst constitue tout d’abord une
liste de candidats a l’antécédence dans le contexte gauche, puis sélectionne parmi ceux-ci ce-
lui qui, avec l’anaphore, maximise une certaine probabilité de coréférence (voir p. ex. (Ng &
Cardie, 2002)). Typiquement, un classiﬁeur produit non seulement une décision binaire mais
aussi un poids associé a cette décision, ce demier mesurant ladite probabilité. La construc-
tion de chaines d’entités coréférentes commune a ces deux procédés est incrémentielle et glou-
tonne ; nous appelons ces approches « na'1'ves ». L’ agrégation na'1've (comptant aussi la canonique
aggressive-merging) ne garantit pas la consistance. Une prise en compte globale de la transiti-
vité comme nous le proposons est un moyen d’y remédier.

3 Transitivité et exclusivité

Comme requis pour la consistance (logique), nous considérons la relation de coréférence com-
me une relation mathématique, dont les chaines de coréférence sont les classes d’équivalence.
L’ exemple a montré plus haut que l’apprentissage automatique binaire suivi d’une agrégation
na'1've sont voués a produire des chaines inconsistantes. Une solution est d’agréger différemment
les paires de markables en chaines, en autorisant le modele a réviser ces décisions binaires aﬁn
de garantir transitivité et exclusivité. Cette approche est plutot rare dans la littérature, sans doute
a cause de la complexité de modélisation : la transitivité est une contrainte globale, a valider
sur la totalité d’un texte/paragraphe/unité de discours. La prendre en compte exhaustivement
implique une complexité de calcul élevée.4

On peut distinguer deux types d’entorse a la consistance :

1. Auto-contradiction : une regle d’exclusivité est enfreinte. Ceci constitue une forme faible

2. Dans l’exemple et son traitement putatif du texte << [. . .] er kennt seinen Westen. Er [. . .] » par apprentissage
automatique, ceci reviendrait a fusionner les deux decisions binaires {[seinen Westen] ;, [Er]m} et {[er] j, [Er]m} en
la chaine de coréférence {[er]j, [seinen Westen];, [Er]m}—inconsistante parce que j 5.6 l.

3. Ils sont traditionnellement nommés ainsi par souci de généralité, mais une relation cataphorique, p. ex., sera
bien sﬁr orientée dans l’autre direction. Néanmoins, la phase d’agrégation ne connait qu’une direction.

4. Etant domes n markables, il y a M";1§"—4l possibilités d’exprimer la transitivité e11tre trois quelconques
d’entre eux, comme dans : << si 1' et j sont coréférents et j et k aussi, alors 1' et k aussi ». La contrainte de transitivité
est donc cubiquement quantiﬁée en le nombre de markables, ce qui implique que, pour etre exhaustif, la complexité
de tout algorithme traitant de maniere extensionnelle ces contraintes doit etre maj orée par un exposant trois.

Vers des contraintes plus linguistiques en résolution de coréférences

(et linguistique) d’inconsistance, puisqu’elle pourrait éventuellement etre détectée et evi-
tée par un classiﬁeur automatique. Un exemple est de poser j E l dans l’exemple plus
haut;

2. Contradiction indirecte : l’exclusivité et la transitivité se contredisent. Dans ce cas la
paire fautive n’est meme pas générée (par le classiﬁeur), mais apparait implicitement par
transitivité. C’est cela-meme que notre modele vise principalement a améliorer : l’incon-
sistance ne peut etre levée meme avec des ﬁltres durs (cf. partie 4), qui eux aussi sont
locaux et conﬁnés a leur perspective binaire.

Dans le cas de deux paires transitivement inconsistantes, la question se pose quant a laquelle
instantier positivement. Ceci met au jour la non-localité du processus de decision : pour résoudre
exactement ce probleme, il faudrait effectuer une optimisation globale ; les poids de paires iso-
lees ne sufﬁsent pas pour fournir la solution globalement optimale. En fait, il faudrait pondérer
des partitions entieres de chaines de coréférence pour y accéder, et optimiser sur toutes les ma-
nieres de partitionner un ensemble de markables. Ceci se trouve etre l’espace de recherche de la
résolution de coréférences, l’arbre de Bell. Malheureusement sa taille est rédhibitoire, limitant
son exploration a des heuristiques (comme dans (Luo et al., 2004), ou l’arbre est élagué selon
un modele statistique, qui n’a plus alors le bénéﬁce de l’optima1ité).

Notre modele constitue de meme une solution alternative (gloutonne) a l’optimisation. 11 con-
siste a réorganiser l’espace de recherche (comme heuristique) : en permettant aux decisions les
plus ﬁables d’etre évaluées d’abord. I1 pallie la non-localité par une approche incrémentielle qui
aborde la transitivité de maniere intensionnelle ; nous le présentons dans la prochaine partie.

4 Notre modéle ﬁltrant

Dans cette partie nous décrivons la reduction des possibilités opérée par notre modele au moyen
de ﬁltres appliqués sur les paires apprises et classiﬁées et pendant l’agrégation. L’ exclusivité est
réalisée par ce ﬁltrage sur la génération de vecteurs puis sur l’agrégation, la transitivité par
l’incrémentialité de l’agrégation.

Filtrage de la génération de vecteurs La premiere étape consiste a sélectionner les données
a passer par l’apprentissage automatique : Nous utilisons des ﬁltres durs pour réduire le nombre
de ces instances (représentées par des vecteurs de traits)—en apprentissage et en classiﬁcation.
Ils éliminent beaucoup d’improbables instances de coréférence en se basant sur des criteres
immédiats comme l’accord (morpho-syntaxique). Ils font respecter l’exclusivité linguistique et
en tant que tels éliminent le premier type d’exclusivité évoqué en partie 3. Ceux utilises ici as-
surent l’exclusivité de deux conﬁgurations, entre autres : d’abord la clause-boundness, vériﬁée
par deux markables s’ils apparaissent de maniere non-appositive dans la meme proposition, au-
cun n’étant un pronom réﬂexif ou adjectif possessif (p. ex. dans « [He]m studied [it],, », [He]m
et [it],, sont clause-bound, la paire (m, n) n’est donc meme pas générée pour l’apprentissage).
Ensuite l’exclusivité de la NP-boundness assure que deux markables ne soient pas coréférents
s’ils apparaissent dans le meme syntagme nominal.

Le ﬁltrage est d’autant plus important pour la phase d’apprentissage que la relation de coréfé-
rence est un phénomene disperse : la grande maj orité des paires-instances sont en fait negatives
(non-coréférentes), de sorte que le modele apprend plutet un certain concept de non-coréfé-

I-/Etienne Ailloud, Manfred Klenner

rence. Le downsampling, la réduction du rapport d’instances négatives aux instances posi-
tives, peut lui faire mieux cerner les véritables relations entre markables coréférents. Les ﬁltres
s’averent également utiles en phase de test : un modele de classiﬁcation recentré sur les moins
nombreuses instances positives po11rra aussi classiﬁer plus vite, d’o1‘1 un gain de temps.

Apprentissage automatique L’apprentissage est ensuite lancé sur ces vecteurs ﬁltrés, com-
me en partie 2. Le modele utilise ici des traits classiquement utilisés dans les modeles actuels
(cf. (Soon et al., 2001) pour un exemple tres suivi); Voici par exemple un vecteur généré pour
la paire ([Derjugos1aWisc11e Préisident],-, [i11n]n), dans lequel apparaissent distances entre mar-
kables, étiquettes individuelles, comparaisons entre les markables, l’extension du mot pour les
pronoms et mesures de salience individuelles (basées sur la fréquence) :

( o 6 NN PPER SUBJ OBJA false false noun ihn 3 4 unknown )
distance en POS fonction matching chaine pronom salience classes

phrases . . f . . sémantiques

markables l n 1 l n strict l uzzy Z n 1 cornpatibles

Nous utilisons le classiﬁeur a mémoire «lazy » TiMBL (Daelemans et al., 2004) pour l’ap-
prentissage; il produit pour chaque instance une prédiction booléenne, basée sur les nombres
d’instances positives et négatives trouvées similaires a l’instance testée (la mesure de similarité
étant le produit de l’apprentissage).

Pondération On assigne ensuite aux instances prédites positives un poids fonction de ces
nombres ; il modélise le coﬁt de considérer une instance un bon candidat a la coréférence :

{ 0 Si my = 0 fl n,-j est le nombre d’instances négatives similaires a (i, j)
 : nij - , . . . . . . \ . .
Tnij +1,” S1I10I1 p,-j est le nombre d instances pos1t1ves s1m1la1res a (z, ])

Une instance qui ne connait que des instances similaires positives est un candidat sur, elle recoit
donc un poids nul. Une qui n’a au contraire que des instances similaires négatives recoit le poids
maximum 1. Les instances prédites positives sont celles qui ont au moins autant d’instances
similaires positives que négatives (c-a-d. un poids d’au plus 1 / 2).

Une fois les instances pondérées, le coeur de notre algorithme consiste a considérer d’abord
les meilleurs candidats, induisant par-la un ordre sur les paires positives produites par TiMBL,
inspiré de l’algorithme de Balas (Balas, 1965) : O31/2 = Ci]-,Ckl, . . . pour w,-j 3 wk; 3 . . . 3 

Agrégation Cette étape met en oeuvre le principe ébauché en partie 3. Elle va plus loin que
l’agrégation canonique (cf. partie 2) en ce qu’elle autorise une décision binaire produite par
TiMBL a étre révisée : A chaque itération, la compatibilité d’une nouvelle paire (i, j) de O31/2
est testée par rapport a toutes les chaines construites jusqu’alors qui contiennenti et j . A savoir :
si 81- et Sj sont des chaines contenant 1' et j, respectivement, chaque élément de 81- est successi-
vement compare a chaque élément de 83-. Si un seul de ces tests échoue, (i, j) n’est plus retenue
comme bon candidat—c’est une paire inconsistante avec les chaines en cours de construction.
C’est la que l’ordre de Balas a son importance, lorsque les meilleurs candidats sont testés en
premier (d’autres ordres se sont effectivement avérés moins performants, comme montré dans
(Klenner & Ailloud, 2008)).

Notre déﬁnition de la compatibilité implique le meme ﬁltrage que pendant la génération des
vecteurs. En particulier, ces ﬁltres instantient différentes couches de criteres linguistiques :

Vers des contraintes plus linguistiques en résolution de coréférences

— exclusivite’ : Les deux prédicats intraphrasaux vus plus haut jouent ici leur role : Généra-
lement, deux markables clause-bound sont exclusifs; de meme, deux markables NP-bound
sont exclusifs aussi5.

— accord morpho-syntaxique : Ceci dépend en grande partie de la catégorie lexicale de l’élé-
ment anaphorique; en allemand, par exemple, le pronom relatif s’accorde en genre, nombre
et personne avec son antécédent;

— accord sémantique : L’ antécédent nominal d’une anaphore nominale doit avoir la méme (ou
compatible) classe sémantique.

Dans les expériences, pour investiguer sur différents comportements linguistiques, nous appli-

quons ou neutralisons plusieurs de ces ﬁltres a l’agrégation (cf. partie 5).

Notre approche de l’agrégation représente donc un compromis entre l’approche na'1've entiere-
ment gloutonne (rejeter sur la base d’une probabilité plus faible une de deux paires-instances
qui trans gressent la transitivité) et la stratégie d’exploration exhaustive de l’espace de recherche
(l’arbre de Bell, cf. partie 3) lourde en calcul (équivalente a un backtracking total) qui trouve la
partition optimale. Notre algorithme impose donc transitivement toute contrainte d’exclusivité
appelée par le test de compatibilité—ces deux principes sont traités intensionnellement.

Extensions du modéle Des expériences actuelles avec le modele impliquent des contraintes
qui ne sont ni transitives ni exclusives ; nous les appelons contraintes de liage d ’entite’s, au sens
ou elles obligent une entité anaphorique donnée a avoir un antécédent. Par exemple, on pourrait
édicter que «tout pronom possessif doit étre lié », ou bien qu’« un syntagme nominal demons-
tratif doit étre lié au maximum trois phrases en arriere ». Techniquement, de telles contraintes
requierent des outils algorithmiques plus élaborés qu’un simple test d’exclusivité de paire.

On pourrait aussi songer a des ﬁltres d’exclusivité «techniques », excluant des conﬁgurations
comme celle entre un pronom réﬂexif (sans indication de genre ou nombre en allemand) et un
markable le suivant, cf. j et is dans «  hat [s1'c11]j amiisiert. [S1'e],, nicht. » («  [s’]J-est
bien amusé. [E11e],, pas. ») Ce ﬁltre permettrait d’exclure j E k, par laquelle l’erreur pourrait
se propager : par transitivité, les hypotheses correctes i E j et j E k (c-a-d. les paires sont
compatibles) amenent i E k, qui constitue une paire exclusive. Bien que j et k puissent étre
prédits coréférents, ils ne forment pas une relation anaphorique ; l’apprentissage gagnerait donc
a se passer de cette paire.

Dans une conﬁguration en apparence semblable : « [Mr. Clinton], [. . .] [Clinton] 9- [. . .] [She],, »,
les deux paires (i, j) et (j, k) sont bien compatibles, mais on ne peut pas appliquer un ﬁltre tel
que celui plus haut, car [Clinton] ,- pourrait réellement étre l’antécédent de l’anaphore [She];,.
Nous appelons ceci un pom‘ d ’inc0nsistance via j ; l’exclusivité seule n’y remédie pas, cette
fois. Dans une telle conﬁguration, il n’y a pas d’autre solution que de faire jouer la transitivité;
celle-ci reste donc nécessaire, aussi précis que soient les ﬁltres d’exclusivité. Ce dernier exemple
montre bien qu’il est important de repasser par les ﬁltres durant l’agrégation, pour éliminer les
éventuels ponts d’inconsistance.

5. 11 y a quelques exceptions, notamment l’usage attributif (adjectival) de syntagmes verbaux imbriqués, ou
un pronom réﬂexif peut étre co-indexé avec le syntagme nominal entier : cf. [das [s1'c11],- amiisierende Ma'dc11en],-
([1a ﬁ11e qui [s’],- amuSe]¢)—le verbe allemand sich amiisieren étant aussi réﬂexif. Mais comme les markables
imbriqués ne sont pas annotés pour la coréférence dans notre gold standard, (cf. partie 5), le ﬁltre plus restrictif est
quand méme utilisé.

I-/Etienne Ailloud, Manfred Klenner

5 Résultats

Dans cette partie nous montrons que la transitivite et l’exclusivite peuvent ameliorer la phase
d’agregation. Notre gold standard, le Corpus arbore d’allemand ecrit de Tiibingen (Telljohann
et al., 2005, TiiBa), se compose d’articles de joumaux en allemand; annotes en structure syn-
taxique et en coreference. Celle-ci couvre plus de 1 100 textes pour plus de 23 000 phrases.

Etalon Nous avons utilise 80% des textes du corpus pour la phase d’apprentissage et le reste
(soit 217 textes) pour la classiﬁcation. Notre systeme-etalon consiste a lancer TiMBL dans ces
conditions, les vecteurs soumis au classiﬁeur ainsi que le gold standard ayant passe au prea-
lable nos ﬁltres durs. Ceci implique que l’evaluation doit étre interpretee modulo les ﬁltres de
vecteurs : seules les conﬁgurations qu’ils acceptent explicitement se retrouvent dans les paires
a classiﬁer et celles du gold standard. Par exemple, les conﬁgurations impliquant es (pronom
personnel neutre 3° pers.), majoritairement expletif, sont ignorees. Les donnees apres ﬁltrage re-
presentent 60 414 (resp. 15 659) paires d’instance pour l’entrainement (resp. la classiﬁcation).
Nos resultats reposent sur les seules mentions réelles (les markables reellement coreferents avec
un autre); ceci permet de concentrer l’etude sur un phenomene particulier ((Luo et al., 2004)
p. ex. utilise egalement cette restriction), comme ici le gain apporte par l’agregation ﬁltrante.

Parametre ETALON MORPH MORPH+EXCL MoRPH+ExcL+s13:M

Precision 73.61 78.13 79.23 82.02
Rappel 63.36 65.76 66.09 68.27

F-mesure 68.10 71.41 72.07 74.52

TAB. 1 — Experience : contribution des differentes couches ﬁltrantes a l’agregation consistante.

Paramétres expérimentaux du ﬁltrage Le tableau 1 presente les progres atteints par rapport
a l’etalon : differentes couches ﬁltrantes y sont aj outees (morpho-syntaxe, exclusivite intraphra-
sale, semantique) dans le but de montrer l’effet de la transitivite combinee aux ﬁltres d’exclusi-
vite. L’effet de l’ exclusivite sur une base morphologique (regles d’ accords) apparait en troisieme
colonne, avec deja un gain de 3,31% en F-mesure (+4,52% en precision et +2,4% en rappel).
La colonne suivante presente l’effet combine avec l’exclusivite « pure » (c-a-d. intraphrasale)
en sus, soit une nouvelle augmentation, de 0,72%, de la F-mesure. Globalement, l’agregation
transitive qui propage l’exclusivite apporte pour nos donnees une amelioration de 6,42%. On
peut voir que l’exclusivite et les criteres morpho-syntaxiques contribuent grandement a rendre
consistantes les chaines de coreference implicitement produites par TiMBL. L’ efﬁcacite du cri-
tere semantique peut étre interpretee par la suppression des ponts d’inconsistance.

Notre evaluation fait usage de la mesure de coreference ECM (presentee dans (Luo, 2005)),
qui met l’accent sur les chaines de coreference plutot que de comparer simplement le nombre
de paires en accord avec le gold standard. Ceci peut expliquer l’augmentation du rappel en
colonnes 3, 4 et 5, alors que notre algorithme ne peut que rejeter une paire incompatible en
la revisant. C’est que la mesure ECM cherche a aligner les chaines de coreference avec le
gold standard : la suppression a raison d’un maillon peut engendrer une chaine supplementaire
alignee avec succes, ce qui augmente le rappel. La mesure ECM offre plusieurs avantages par
rapport au traditionnel MUC, comme decrit p. ex. dans (Luo, 2005).

Vers des contraintes plus linguistiques en resolution de coreferences

6 Travaux antérieurs

11 y a eu d’importants efforts de recherche sur l’apprentissage automatique de la resolution de
coreferences; on a recemment commence a aborder les limites de portee inherentes aux mo-
deles binaires. Par exemple, le modele propose dans (Yang et al., 2004) incorpore des traits
etendus, qui prennent non seulement en compte les paires de markables mais aussi les chaines
de coreference partielles construites durant l’agregation. Cependant le modele ne fait pas etat de
contraintes dures sur ces chaines et reste dans la lignee standard. Comme mentionne en partie 2,
l’arbre de Bell ne peut pas étre explore dans son integralite. Dans (Luo et al., 2004), un mo-
dele statistique y apporte une solution en elaguant l’arbre selon les scores obtenus sur ses che-
mins, perdant la garantie d’optimalite. Cette approche reste egalement purement statistique—
elle n’apporte pas de contraintes supplementaires en dehors du classiﬁeur. Une autre perspective
est abordee dans (Denis & Baldridge, 2008b), ou des modeles differencies sont entraines selon
les differentes categories de markables (susceptibles d’exhiber differents motifs de coreference).

On a plus recemment insiste sur l’importance de la transitivite en resolution de coreferences.
Les modeles dans (Denis & Baldridge, 2008a) et (Finkel & Manning, 2008) font tous deux res-
pecter cette contrainte globale par programmation lineaire entiere (ILP), ce faisant assurant une
certaine notion d’optimalite aux chaines produites. Aucun toutefois n’y combine des contraintes
d’exclusivite qui pourraient l’utiliser pour se propager (bien que la combinaison avec la recon-
naissance d’entites nommees dans le modele similaire de Denis & Baldridge (2008a) engendre
une propagation mutuelle des deux taches). De plus, l’ILP impose l’extentionnalisation des
contraintes, ce qui affecte la clarte, voire la faisabilite dans le cas de longs textes, pour la tran-
sitivite.

7 Conclusion et travaux futurs

Nous avons propose un modele de resolution de coreferences, bati autour d’un modele binaire
d’apprentissage automatique et se basant sur des ﬁltres pour imposer transitivite et exclusivite.
Nous avons montre que le ﬁltrage transitif pendant la phase d’agregation foumit de meilleurs
resultats de par la consistance des chaines de coreference produites, ce qui constitue une ame-
lioration par rapport aux approches binaires classiques.

Dans des travaux ulterieurs nous chercherons a trouver de nouveaux ﬁltres d’exclusivite, aﬁn
de coller—a terme—au plus pres des donnees empiriques: ceux-ci devront étre d’inspiration
linguistique et necessiteront probablement peu d’adaptation a d’autres langues (de plus, la tran-
sitivite est une contrainte universelle). En outre nous voulons continuer a experimenter sur des
contraintes, en particulier celles qui imposent le liage d’entites, bien que celles-ci modiﬁent
quelque peu l’architecture du modele.

Remerciements

La recherche effectuee dans le cadre de ce travail est ﬁnancee par le projet n° 105211—118108/1
du Fonds National Suisse. Nous tenons a remercier Anne Goehring ainsi que les deux relecteurs
anonymes.

Etienne Ailloud, Manfred Klenner

Références

BAGGA A. & BALDWIN B. (1998). Algorithms for scoring coreference chains. In Pro-

ceedings of the Linguistic Coreference Workshop at The First International Conference on
Language Resources and Evaluation (LREC’98), p. 563-566.

BALAS E. (1965). An additive algorithm for solving linear programs with zero-one variables.
Operations Research, 13(4), 517-546.

CHIERCHIA G. & MCCONNELL-GINET S. (1990). Meaning and Grammar, An Introduction
to Semantics. MIT Press, Cambridge.

DAELEMANS W., ZAVREL J ., VAN DER SLOOT K. & VAN DEN BOSCH A. (2004). TiMBL:
Tilburg Memory-Based Learner.

DENIS P. & BALDRIDGE J . (2008a). Coreference with named entity classiﬁcation and transi-
tivity constraints and evaluation with MUC, B-CUBED, and CEAF. In Proceedings of Corpus-
Based Approaches to Coreference Resolution in Romance Languages (CBA 2008 ), Barcelona,
Spain. A paraitre.

DENIS P. & BALDRIDGE J. (2008b). Specialized models and ranking for coreference reso-

lution. In Proceedings of the Empirical Methods in Natural Language Processing (EMNLP
2008), Hawaii, USA. A paraitre.

FINKEL J. & MANNING C. (2008). Enforcing transitivity in coreference resolution. In Pro-
ceedings of the Annual Meeting of the Association for Computational Linguistics - Human
Language Technology Conference, p. 45-48: Association for Computational Linguistics.

KLENNER M. & AILLOUD E. (2008). Enhancing coreference clustering. In C. J OHANSSON,
Ed., Proc. of the Second Workshop on Anaphora Resolution (WAR II), Volume 2 of NEALT
Proceedings Series, p. 31-40, Bergen, Norway.

LUO X. (2005). On coreference resolution performance metrics. In Proceedings of the confe-
rence on Human Language Technology and Empirical Methods in Natural Language Proces-
sing, p. 25-32: Association for Computational Linguistics Morristown, NJ, USA.

LUO X., ITTYCHERIAH A., JING H., KAMBHATLA N. & RoUKos S. (2004). A mention-
synchronous coreference resolution algorithm based on the Bell tree. Proceedings of the 42nd
Annual Meeting on Association for Computational Linguistics.

NG V. & CARDIE C. (2002). Improving machine learning approaches to coreference resolu-
tion. Proceedings of the 40th Annual Meeting of the Association for Computational Linguis-
tics, p. 104-111.

SOON W., NG H. & LIM D. (2001). A machine learning approach to coreference resolution
of noun phrases. Computational Linguistics, 27(4), 521-544.

TELLJOHANN H., HINRICHS E., KUBLER S. & ZINSMEISTER H. (2005). Stylebook for the
Tiibingen treebank of written German (TiiBa-D/Z). Seminar fur Sprachwissenschaft, Univer-
sita't Tubingen, Tubingen, Germany.

VILAIN M., BURGER J ., ABERDEEN J ., CONNOLLY D. & HIRSCHMAN L. (1995). A model-

theoretic coreference scoring scheme. In Proceedings of the 6th conference on Message un-
derstanding, p. 45-52: Association for Computational Linguistics Morristown, NJ, USA.

YANG X., SU J ., ZHOU G. & TAN C. (2004). An NP-cluster based approach to coreference
resolution. Proceedings of COLING.

