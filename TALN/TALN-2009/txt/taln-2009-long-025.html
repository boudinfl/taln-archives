<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Une approche mixte-statistique et structurelle - pour le r&#233;sum&#233; automatique de d&#233;p&#234;ches</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009, Senlis, 24&#8211;26 juin 2009
</p>
<p>Une approche mixte-statistique et structurelle - pour le
r&#233;sum&#233; automatique de d&#233;p&#234;ches
</p>
<p>Aur&#233;lien Bossard
LIPN - UMR 7030
</p>
<p>CNRS - Universit&#233; Paris 13
F-93430 Villetaneuse, France
</p>
<p>aurelien.bossard@lipn.univ-paris13.fr
</p>
<p>R&#233;sum&#233;. Les techniques de r&#233;sum&#233; automatique multi-documents par extraction ont r&#233;cem-
ment &#233;volu&#233; vers des m&#233;thodes statistiques pour la s&#233;lection des phrases &#224; extraire.
Dans cet article, nous pr&#233;sentons un syst&#232;me conforme &#224; l&#8217;&#171; &#233;tat de l&#8217;art &#187; &#8212; CBSEAS &#8212; que
nous avons d&#233;velopp&#233; pour les t&#226;ches Opinion (r&#233;sum&#233;s d&#8217;opinions issues de blogs) et Update
(r&#233;sum&#233;s de d&#233;p&#234;ches et mise &#224; jour du r&#233;sum&#233; &#224; partir de nouvelles d&#233;p&#234;ches sur le m&#234;me
&#233;v&#233;nement) de la campagne d&#8217;&#233;valuation TAC 2008, et montrons l&#8217;int&#233;r&#234;t d&#8217;analyses struc-
turelles et linguistiques des documents &#224; r&#233;sumer. Nous pr&#233;sentons &#233;galement notre &#233;tude sur la
structure des d&#233;p&#234;ches et l&#8217;impact de son int&#233;gration &#224; CBSEAS.
</p>
<p>Abstract. Automatic multi-document summarization techniques have recently evolved
into statistical methods for selecting the sentences that will be used to generate the summary.
In this paper, we present a system in accordance with &#171; State-of-the-art &#187; &#8212; CBSEAS &#8212; that
we have developped for the &#171; Opinion Task &#187; (automatic summaries of opinions from blogs)
and the &#171; Update Task &#187; (automatic summaries of newswire articles and information update) of
the TAC 2008 evaluation campaign, and show the interest of structural and linguistic analysis
of the documents to summarize . We also present our study on news structure and its integration
to CBSEAS impact.
</p>
<p>Mots-cl&#233;s : R&#233;sum&#233; automatique, structure de documents.
</p>
<p>Keywords: Automatic summarization, document structure.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Aur&#233;lien Bossard
</p>
<p>1 Introduction
</p>
<p>Port&#233; par une large communaut&#233; de chercheurs et des campagnes d&#8217;&#233;valuation telles que DUC
(Document Understanding Conference) et TAC (Text Analysis Conference), le r&#233;sum&#233; automa-
tique a connu ces derni&#232;res ann&#233;es une &#233;volution rapide.
</p>
<p>Nous pr&#233;sentons dans ce papier une nouvelle approche pour le r&#233;sum&#233; automatique. Une nou-
velle m&#233;thode pour d&#233;tecter la redondance a &#233;t&#233; int&#233;gr&#233;e au coeur de notre syst&#232;me, CBSEAS.
Cette m&#233;thode vise &#224; mieux prendre en compte la redondance des informations que les sys-
t&#232;mes existants afin de cr&#233;er des r&#233;sum&#233;s a priori plus pertinents. Les r&#233;sultats obtenus lors de
la campagne d&#8217;&#233;valuation TAC 2008 prouvent que notre syst&#232;me est adaptable et la m&#233;thode
efficace. Cependant, ils pointent &#233;galement du doigt les faiblesses de CBSEAS auxquelles nous
nous effor&#231;ons de trouver des solutions que nous pr&#233;sentons ici.
</p>
<p>Cet article est organis&#233; de la mani&#232;re suivante : en premier lieu, nous pr&#233;sentons les principales
approches de r&#233;sum&#233; automatique par extraction existantes. Nous d&#233;crivons ensuite notre sys-
t&#232;me g&#233;n&#233;rique, puis les modifications que nous lui avons apport&#233;es afin de participer &#224; TAC
ainsi que son &#233;valuation lors de cette campagne. Enfin, nous montrons comment nous comp-
tons am&#233;liorer CBSEAS sur la t&#226;che particuli&#232;re du r&#233;sum&#233; de d&#233;p&#234;ches en prenant en compte
la structure des documents comme une mani&#232;re de d&#233;terminer la pertinence de leurs extraits.
Nous pr&#233;sentons &#233;galement les premi&#232;res exp&#233;riences men&#233;es dans ce sens.
</p>
<p>2 Etat de l&#8217;art
</p>
<p>L&#8217;int&#233;r&#234;t pour le r&#233;sum&#233; automatique a commenc&#233; &#224; la fin des ann&#233;es 1950 avec les travaux de
(Luhn, 1958) ainsi que ceux (Edmundson &amp; Wyllys, 1961). Les bases du r&#233;sum&#233; par extrac-
tion &#233;taient alors pos&#233;es. Les travaux de (Luhn, 1958) consistaient &#224; classer les mots du ou des
documents &#224; r&#233;sumer selon un indice de fr&#233;quence qui n&#8217;est pas sans rappeler le tf-idf introduit
par (Salton &amp; McGill, 1986). Les phrases contenant le plus de mots proches les uns des autres
consid&#233;r&#233;s comme importants par l&#8217;indice de fr&#233;quence &#233;taient alors s&#233;lectionn&#233;es pour g&#233;n&#233;rer
un r&#233;sum&#233;. Edmundson, en plus de mesures de fr&#233;quence des mots, prenait en compte la po-
sition des phrases dans leur document et favorisait certaines positions pour certains types de
documents &#8212;les premi&#232;res phrases pour des d&#233;p&#234;ches de presse, les derni&#232;res pour un article
scientifique. Il prenait &#233;galement en compte le nombre de mots commen&#231;ant par une majuscule
(&#224; l&#8217;&#233;poque, on ne parle pas encore d&#8217;entit&#233;s nomm&#233;es), la pr&#233;sence d&#8217;expressions-cl&#233; telles que
&#171; In conclusion &#187;, &#171; hardly &#187;.
</p>
<p>Les r&#233;sum&#233;s automatiques sont alors cr&#233;&#233;s uniquement sur la notion de centralit&#233;, ou d&#8217;impor-
tance d&#8217;un &#233;l&#233;ment relativement &#224; son contexte. La notion de diversit&#233; ou de non-redondance
des informations expos&#233;es dans le r&#233;sum&#233; n&#8217;&#233;tait alors pas consid&#233;r&#233;e, la recherche ne s&#8217;&#233;tant
pas encore int&#233;ress&#233;e au r&#233;sum&#233; multi-documents.
</p>
<p>Plus r&#233;cemment, des travaux ont int&#233;gr&#233; cette notion de diversit&#233;. Certains en post-traitement,
apr&#232;s classement des phrases &#224; extraire par des scores refl&#233;tant la centralit&#233;. C&#8217;est le cas de
(Radev, 2004). Un &#171; centroid &#187;, groupe de termes dont la fr&#233;quence d&#8217;apparition d&#233;note l&#8217;impor-
tance, est cr&#233;&#233; pour chaque groupe de documents &#224; r&#233;sumer. Les phrases sont class&#233;es suivant le
nombre de termes du &#171; centroid &#187; qu&#8217;elles contiennent. Radev a &#233;galement propos&#233; dans (Erkan
&amp; Radev, 2004) une m&#233;thode inspir&#233;e des r&#233;seaux sociaux et de la notion de &#171; prestige &#187;. Il</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Une approche mixte-statistique et structurelle - pour le r&#233;sum&#233; automatique de d&#233;p&#234;ches
</p>
<p>&#233;tablit un graphe dans lequel les noeuds sont les phrases et les ar&#234;tes la similarit&#233; des phrases
les unes aux autres. Apr&#232;s avoir effectu&#233; un parcours al&#233;atoire de ce graphe, il classe les phrases
selon le nombre de fois qu&#8217;elles ont &#233;t&#233; visit&#233;es. Dans ces deux m&#233;thodes, Radev g&#232;re la di-
versit&#233; en s&#233;lectionnant les phrases dans l&#8217;ordre de classement et en &#233;liminant les phrases trop
similaires &#224; une phrase d&#233;j&#224; s&#233;lectionn&#233;e pour faire partie du r&#233;sum&#233;.
</p>
<p>D&#8217;autres travaux g&#232;rent la diversit&#233; dans le m&#234;me temps que la centralit&#233;. Partant du principe
que la diversit&#233; &#233;tant aussi importante que la centralit&#233;, leurs auteurs consid&#232;rent que ces deux
aspects devaient &#234;tre g&#233;r&#233;s dans le m&#234;me temps. Parmi ceux-ci, la m&#233;thode MMR de (Carbonell
&amp; Goldstein, 1998) combine deux mesures : l&#8217;une refl&#233;tant la centralit&#233; ou l&#8217;importance vis-&#224;-
vis d&#8217;une requ&#234;te utilisateur, l&#8217;autre la diversit&#233;. La diversit&#233; est fonction de la similarit&#233; aux
phrases d&#233;j&#224; s&#233;lectionn&#233;es pour le r&#233;sum&#233;.
</p>
<p>On peut &#233;galement citer (Goldberg, 2007). Sa m&#233;thode reprend celle de (Erkan &amp; Radev, 2004).
Cependant, au lieu de r&#233;aliser un simple parcours al&#233;atoire, il utilise un parcours al&#233;atoire
markovien &#224; &#233;tats absorbants. Ainsi, les noeuds centraux absorbent les scores des noeuds qui
les entourent, ce qui permet de g&#233;rer la diversit&#233; en m&#234;me temps que la centralit&#233;.
</p>
<p>(Boudin et al., 2007) a travaill&#233; sur la fusion de diff&#233;rentes m&#233;triques. Le syst&#232;me, baptis&#233; Neo-
Cortex, tire ainsi les b&#233;n&#233;fices de l&#8217;utilisation de m&#233;triques qui rendent compte de diff&#233;rents
types de traits. Ce syst&#232;me s&#8217;est tr&#232;s bien class&#233; dans la campagne d&#8217;&#233;valuation DUC 2006.
</p>
<p>Une derni&#232;re approche, celle de (Barzilay, 2003), aborde le probl&#232;me de mani&#232;re tout &#224; fait
diff&#233;rente : elle d&#233;tecte dans un premier temps les paraphrases en appliquant une SVM sur les
arbres syntaxiques normalis&#233;s des phrases des documents &#224; r&#233;sumer. Les informations les plus
importantes sont alors les plus paraphras&#233;es. Cette technique est extr&#234;mement bien adapt&#233;e &#224;
la probl&#233;matique du r&#233;sum&#233; multi-documents, o&#249; d&#251; &#224; la multiplicit&#233; des sources, la notion de
centralit&#233; se rapproche de celle de redondance. Cependant, &#224; cause de la quantit&#233; de ressources
linguistiques qu&#8217;elle demande, cette m&#233;thode n&#8217;est pas adaptable &#224; toutes les langues. Nous
voulons d&#233;velopper une m&#233;thode dans laquelle, &#224; l&#8217;instar de (Barzilay, 2003), la redondance
occupe une place majeure, et qui soit assez ind&#233;pendante des ressources linguistiques pour
permettre son adaptation &#224; diff&#233;rentes langues.
</p>
<p>3 CBSEAS : &#171; Clustering-Based Sentence Extractor for Au-
tomatic Summarization &#187;
</p>
<p>Nous supposons que dans une probl&#233;matique de r&#233;sum&#233; multi-document, les informations les
plus redondantes sont les &#233;l&#233;ments les plus importants pour produire un r&#233;sum&#233; pertinent. Par
cons&#233;quent, les phrases qui portent ces informations sont les phrases &#224; extraire, moyennant
l&#8217;&#233;limination de la redondance. Le regroupement des phrases qui v&#233;hiculent la m&#234;me infor-
mation est la premi&#232;re &#233;tape de notre approche. L&#8217;algorithme d&#233;velopp&#233; &#233;tablit une similarit&#233;
entre les phrases des documents &#224; r&#233;sumer puis applique un algorithme de classification &#8212; fast
global k-means (L&#243;pez-Escobar et al., 2006) &#8212; sur la matrice de similarit&#233; afin de cr&#233;er des
regroupements au sein desquels les phrases v&#233;hiculent la m&#234;me information, ou tout du moins
sont les plus proches les unes des autres.
</p>
<p>Premi&#232;rement, nous s&#233;lectionnons n2 phrases pour cr&#233;er un r&#233;sum&#233; de n phrases. L&#8217;algorithme
d&#8217;apprentissage cr&#233;era n classes pour g&#233;n&#233;rer un r&#233;sum&#233; de n phrases. Il appara&#238;t en effet que
fast global k-means est plus performant pour cr&#233;er n classes avec n2 observations. L&#8217;&#233;lection de</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Aur&#233;lien Bossard
</p>
<p>for all ej in E
C1 &#8592; ej
</p>
<p>for i from 1 to k do
for j from 1 to i
</p>
<p>centre(Cj)&#8592; em|em maximise
&#8721;
</p>
<p>eninCj
</p>
<p>sim(em, en)
</p>
<p>for all ej in E
placer ej dans Cl|Cl maximise sim(centre(Cl, ej)
</p>
<p>ajouter un nouveau cluster : Ci qui contient initialement uniquement l&#8217;&#233;l&#233;ment le moins bien repr&#233;sent&#233; par sa classe
done
</p>
<p>FIG. 1 &#8211; Algorithme Fast global k-means
</p>
<p>ces n2 phrases se fait d&#8217;apr&#232;s leur similarit&#233; &#224; une requ&#234;te utilisateur dans le cas o&#249; il y en a une,
ou d&#8217;apr&#232;s leur proximit&#233; au centroid compos&#233; des m termes les plus importants, importance
refl&#233;t&#233;e par leur tf-idf.
</p>
<p>La similarit&#233; entre les phrases est calcul&#233;e &#224; l&#8217;aide de la mesure &#171; Jaccard &#187;. Cette mesure est
efficace pour la comparaison d&#8217;ensembles. Les phrases sont au pr&#233;alable &#233;tiquet&#233;es morpho-
syntaxiquement &#224; l&#8217;aide de tree-tagger1 et la comparaison se fait sur les lemmes.
</p>
<p>Une fois la matrice de similarit&#233; &#233;tablie, CBSEAS effectue une classification des phrases en util-
isant l&#8217;algorithme fast global k-means (description de l&#8217;algorithme en figure 1). Cet algorithme
de classification a le double avantage de pouvoir prendre en entr&#233;e une matrice de similarit&#233; et
de s&#8217;affranchir de la s&#233;lection des centres de classes pr&#233;alablement &#224; la classification, un d&#233;faut
majeur de k-means.
</p>
<p>La classification &#233;tablie, CBSEAS s&#233;lectionne une phrase par classe afin de g&#233;n&#233;rer un r&#233;sum&#233;
qui contienne la plus grande partie des informations/id&#233;es pertinentes des documents d&#8217;origine.
La s&#233;lection des phrases s&#8217;op&#232;re selon une combinaison lin&#233;aire de la proximit&#233; des phrases au
centre de leur classe et de la similarit&#233; &#224; la requ&#234;te/au centroid du groupe de documents.
</p>
<p>4 Evaluation au sein de TAC 2008 : &#171; Opinion Task &#187;
</p>
<p>Afin d&#8217;&#233;valuer notre syst&#232;me, nous avons particip&#233; &#224; deux t&#226;ches de la campagne TAC (Text
Analysis Conference) 2008. La premi&#232;re des deux t&#226;ches, Opinion Task, consistait &#224; r&#233;sumer
les opinions contenues dans des blogs. Les r&#233;sum&#233;s &#233;taient orient&#233;s par une ou des requ&#234;tes
utilisateur telles que : &#171; Why do people dislike ... ? &#187;.
</p>
<p>Les r&#233;sum&#233;s ont &#233;t&#233; &#233;valu&#233;s manuellement par des analystes de NIST2 suivant le protocole
&#171; Pyramid &#187; (Lin et al., 2006). Le score PYRAMID d&#8217;un r&#233;sum&#233; automatique d&#233;pend du nom-
bre d&#8217;unit&#233;s s&#233;mantiques qu&#8217;il contient et qui sont consid&#233;r&#233;es comme importantes par les anno-
tateurs. L&#8217;importance d&#8217;une unit&#233; s&#233;mantique est fonction de son nombre d&#8217;occurences au sein
des r&#233;sum&#233;s g&#233;n&#233;r&#233;s &#224; la main par les annotateurs. Les r&#233;sum&#233;s ont &#233;galement &#233;t&#233; not&#233;s sur cinq
autres crit&#232;res par les &#233;valuateurs humains : grammaticalit&#233;, non-redondance, structure, fluidit&#233;
et &#171; r&#233;pondance &#187;.
</p>
<p>Les organisateurs de TAC offraient aux participants &#224; la campagne d&#8217;&#233;valuation la possibilit&#233;
1http ://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
2National Institute of Science and Technology : http ://www.nist.gov</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Une approche mixte-statistique et structurelle - pour le r&#233;sum&#233; automatique de d&#233;p&#234;ches
</p>
<p>Evaluation CBSEAS Mean Best Worst Rank
Pyramid .169 .151 .251 .101 5/20
Grammatic. 5.95 5.14 7.54 3.54 3/20
Non-redund. 6.64 5.88 7.91 4.36 4/20
Structure 3.50 2.68 3.59 2.04 2/20
Fluency 4.45 3.43 5.32 2.64 2/20
Responsiv. 2.64 2.61 5.77 1.68 8/20
</p>
<p>FIG. 2 &#8211; R&#233;sultats de la t&#226;che &#171; Opinion &#187;
</p>
<p>d&#8217;utiliser des fragments de texte a priori pertinents produits par des syst&#232;mes de Questions-
R&#233;ponse (QR). Nous avons pens&#233; qu&#8217;il est plus r&#233;aliste de consid&#233;rer la production de r&#233;sum&#233;
ind&#233;pendamment de la t&#226;che de QR (m&#234;me si ces deux t&#226;ches sont relativement proches) pour
deux raisons : suivant le contexte, un tel syst&#232;me n&#8217;est pas toujours disponible et surtout cu-
muler deux syst&#232;mes diff&#233;rents brouille l&#8217;&#233;valuation, &#224; moins de &#171; tracer &#187; les erreurs. Nous ne
pr&#233;sentons en 4.2 que les r&#233;sultats des syst&#232;mes qui n&#8217;ont pas utilis&#233; ces fragments de texte.
</p>
<p>4.1 Modifications apport&#233;es au syst&#232;me
</p>
<p>Les blogs ont &#233;t&#233; pass&#233;s dans un module de filtrage visant &#224; &#233;liminer les phrases pr&#233;sentant des
incoh&#233;rences lexicales. Les phrases avec un ratio nombre de mots fr&#233;quents/nombre total de mots
en dessous de 0.35 ont &#233;t&#233; &#233;cart&#233;es. Les &#171; mots fr&#233;quents &#187; sont les cent mots les plus fr&#233;quents
en langue anglaise ; ils constituent environ la moiti&#233; des textes &#233;crits (Fry et al., 2000).
</p>
<p>Les requ&#234;tes ainsi que toutes les phrases des documents ont &#233;t&#233; &#233;tiquet&#233;es selon l&#8217;opinion
qu&#8217;elles v&#233;hiculent &#8212; positive ou n&#233;gative &#8212; selon une m&#233;thode d&#8217;analyse d&#8217;opinion d&#233;velop-
p&#233;e par Michel G&#233;n&#233;reux. Plus de d&#233;tails &#224; ce propos sont disponibles dans (Bossard &amp; G&#233;n&#233;reux,
2009).
</p>
<p>CBSEAS est alors utilis&#233; sur les donn&#233;es nettoy&#233;es afin de produire un premier r&#233;sum&#233;. Ce
r&#233;sum&#233; est ensuite r&#233;organis&#233; selon l&#8217;&#233;tiquetage en opinion des phrases qui le composent et
de l&#8217;ordre des requ&#234;tes. Par exemple, si la premi&#232;re requ&#234;te &#233;tait &#171; Why do people appreciate
Linux ? &#187; et la deuxi&#232;me &#171; For what reasons do people dislike Linux ? &#187;, alors le premier para-
graphe du r&#233;sum&#233; final contiendra les opinions positives et le second les opinions n&#233;gatives.
</p>
<p>4.2 R&#233;sultats
</p>
<p>Le syst&#232;me propos&#233; pour la t&#226;che Opinion de TAC 2008 s&#8217;est tr&#232;s bien comport&#233; (cf figure 2). En
effet, il se classe parmi le premier quart des participants except&#233; sur le score &#171; Responsiveness &#187;.
Le champ &#171; Structure &#187; montre que l&#8217;int&#233;gration du syst&#232;me d&#8217;&#233;tiquetage d&#8217;opinion a constitu&#233;
un v&#233;ritable atout. Les scores Pyramid ainsi que le score de non-redondance d&#233;notent quant &#224;
eux le bien-fond&#233; de notre approche b&#226;tie sur la d&#233;tection de la redondance. Le mauvais score
relatif en &#171; responsiveness &#187; s&#8217;explique en grande partie par la longueur de nos r&#233;sum&#233;s : nous
avions choisi d&#8217;utiliser le maximum de caract&#232;res autoris&#233;s par TAC, soit 7000 caract&#232;res par
requ&#234;te, ce qui s&#8217;est r&#233;v&#233;l&#233; a posteriori &#234;tre une erreur.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Aur&#233;lien Bossard
</p>
<p>FIG. 3 &#8211; R&#233;sultats de CBSEAS sur la t&#226;che &#171; Update &#187;
</p>
<p>5 Evaluation au sein de TAC 2008 : &#171; Update Task &#187;
</p>
<p>Nous avons &#233;galement &#233;valu&#233; CBSEAS dans la t&#226;che &#171; Update &#187;. Cette t&#226;che consistait &#224; fournir
des r&#233;sum&#233;s pour diff&#233;rents th&#232;mes. Chaque th&#232;me &#233;tait compos&#233; de deux groupes de docu-
ments. Les documents &#233;taient uniquement tir&#233;s du corpus AQUAINT-2, un corpus regroupant
des d&#233;p&#234;ches de presse tir&#233;s des plus grandes agences de presse internationales (AFP, Xinhua,
NYT...) Deux r&#233;sum&#233;s devaient &#234;tre fournis pour chaque th&#232;me, le premier synth&#233;tisant le pre-
mier groupe de documents, le deuxi&#232;me r&#233;sumant les informations contenues dans le deuxi&#232;me
groupe de documents et qui constituaient une nouveaut&#233; par rapport au premier groupe. Les
r&#233;sum&#233;s ne devaient pas exc&#233;der 100 mots.
</p>
<p>Deux &#233;valuations ont &#233;t&#233; propos&#233;es : la premi&#232;re utilisant PYRAMID, la deuxi&#232;me utilisant les
mesures ROUGE (Lin, 2004), des mesures fond&#233;es sur la comparaison de n-grammes entre le
r&#233;sum&#233; automatique et un r&#233;sum&#233; de r&#233;f&#233;rence.
</p>
<p>5.1 Modifications apport&#233;es au syst&#232;me
</p>
<p>Notre syst&#232;me a &#233;t&#233; modifi&#233; de mani&#232;re &#224; g&#233;rer la mise &#224; jour au cours de l&#8217;apprentissage de la
classification des phrases. Apr&#232;s avoir &#233;tabli la classification en n classes des phrases du premier
groupe de documents et s&#233;lectionn&#233; une phrase par classe pour g&#233;n&#233;rer le r&#233;sum&#233;, les phrases
du second groupe de documents sont ajout&#233;es au syst&#232;me de classification. Fast global k-means
est alors r&#233;it&#233;r&#233; jusqu&#8217;&#224; obtenir n classes de plus, avec les contraintes suivantes :
&#8211; les phrases du premier groupe de documents sont inamovibles ;
&#8211; les centres des n premi&#232;res classes sont fix&#233;s et ne peuvent pas &#234;tre recalcul&#233;s.
Le r&#233;sum&#233; du deuxi&#232;me groupe de documents est alors g&#233;n&#233;r&#233; avec les n derni&#232;res classes.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Une approche mixte-statistique et structurelle - pour le r&#233;sum&#233; automatique de d&#233;p&#234;ches
</p>
<p>5.2 R&#233;sultats
</p>
<p>Les r&#233;sultats pr&#233;sent&#233;s en figure 3 sont les r&#233;sultats des mesures ROUGE-2 et ROUGE-SU4
(Lin, 2004). Suite &#224; un mauvais param&#233;trage de CBSEAS, les r&#233;sum&#233;s envoy&#233;s &#224; TAC ne com-
portaient que 75 mots en moyenne, soit 3/4 des 100 mots autoris&#233;s, ce qui a grandement p&#233;nalis&#233;
le syst&#232;me lors de l&#8217;&#233;valuation. Des exp&#233;riences ont &#233;t&#233; r&#233;alis&#233;es apr&#232;s TAC (syst&#232;me CBSEAS
v0.5). L&#8217;&#233;valuation post&#233;rieure &#224; la campagne sur les m&#234;mes donn&#233;es se limite donc aux dif-
f&#233;rentes mesures ROUGE &#8212; enti&#232;rement automatiques donc reproductibles &#8212; avec comme
&#233;talon les r&#233;sum&#233;s de r&#233;f&#233;rence fournis par NIST.
</p>
<p>Malgr&#233; une m&#233;thode de mise &#224; jour tr&#232;s efficace (le syst&#232;me se classe parmi les premiers sur
les r&#233;sum&#233;s des seconds groupes de documents), CBSEAS ne se positionne pas bien sur cette
t&#226;che. Cela signifie que les scores de CBSEAS sur les r&#233;sum&#233;s des premiers jeux de documents
sont faibles. Nous l&#8217;expliquons par un manque d&#8217;adaptation du syst&#232;me &#224; la t&#226;che sp&#233;cifique du
r&#233;sum&#233; de d&#233;p&#234;ches. En effet, les d&#233;p&#234;ches de presse comportent des sp&#233;cificit&#233;s et adoptent un
style d&#8217;&#233;criture qui permet d&#8217;am&#233;liorer consid&#233;rablement la qualit&#233; des r&#233;sum&#233;s si on les prend
en compte. La plupart des syst&#232;mes de r&#233;sum&#233; automatique incorporent par cons&#233;quent des
caract&#233;ristiques comme la position d&#8217;une phrase dans le document ou la similarit&#233; de celle-ci
au titre pour calculer son score.
</p>
<p>Cependant, ces crit&#232;res, fond&#233;s sur des &#233;tudes anciennces, ne rendent pas enti&#232;rement compte
des sp&#233;cificit&#233;s des d&#233;p&#234;ches. C&#8217;est pourquoi nous proposons ici une mani&#232;re d&#8217;int&#233;grer la struc-
ture des d&#233;p&#234;ches &#224; un syst&#232;me de r&#233;sum&#233; automatique, afin d&#8217;en renforcer la pertinence des
r&#233;sultats.
</p>
<p>6 La structure des d&#233;p&#234;ches et son int&#233;gration &#224; CBSEAS
</p>
<p>(Lucas, 2005) a men&#233; une &#233;tude sur la structure &#233;nonciative des d&#233;p&#234;ches de presse. Il ressort
de cette &#233;tude que l&#8217;aspect temporel prime dans la structuration des d&#233;p&#234;ches. Elle propose
&#233;galement une cat&#233;gorisation des d&#233;p&#234;ches :
&#8211; D&#233;p&#234;ches comment&#233;es (premi&#232;re partie : explication factuelle, deuxi&#232;me partie : projection),
</p>
<p>cf fig 4 ;
&#8211; D&#233;p&#234;ches &#233;labor&#233;es (plus d&#8217;un &#233;v&#233;nement) ;
&#8211; D&#233;p&#234;ches d&#8217;action (feuilleton : un fil d&#8217;&#233;v&#233;nements fortement li&#233;s les uns aux autres, d&#233;p&#234;ches
</p>
<p>boursi&#232;res...)
et des m&#233;thodes pour les cat&#233;goriser ainsi que pour rep&#233;rer automatiquement les diff&#233;rentes
parties qui les composent.
</p>
<p>(Lucas, 2005) montre &#233;galement que les d&#233;p&#234;ches comment&#233;es suivent la m&#234;me pr&#233;sentation
chronologique. L&#8217;auteur pr&#233;sente d&#8217;abord l&#8217;&#233;v&#233;nement pr&#233;sent, puis donne une explication &#224; cet
&#233;v&#233;nement en se fondant sur des faits pass&#233;s. En dernier lieu, l&#8217;auteur d&#233;crit les cons&#233;quences
futures, probables ou av&#233;r&#233;es de l&#8217;&#233;v&#233;nement pr&#233;sent&#233;. Identifier ces trois parties peut s&#8217;av&#233;rer
utile : elles suivent toutes la r&#232;gle classique de l&#8217;&#233;criture de d&#233;p&#234;ches : l&#8217;information impor-
tante est port&#233;e par la premi&#232;re phrase. Les m&#234;mes remarques s&#8217;appliquent aux autres types de
d&#233;p&#234;ches.
</p>
<p>En parcourant le corpus AQUAINT-2, fourni lors de la campagne d&#8217;&#233;valuation TAC 2008, nous
avons d&#233;gag&#233; d&#8217;autres types de d&#233;p&#234;ches :</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Aur&#233;lien Bossard
</p>
<p>(a) Une d&#233;p&#234;che comment&#233;e
</p>
<p>(b) Une chronologie
</p>
<p>FIG. 4 &#8211; Exemples de d&#233;p&#234;ches
</p>
<p>&#8211; Les revues d&#8217;opinion (rapport des r&#233;actions de plusieurs intervenants &#224; un m&#234;me sujet) ;
&#8211; Les rapports de discours ;
&#8211; Les chronologies (se diff&#233;rencient des d&#233;p&#234;ches en feuilleton par un style plus concis et un
</p>
<p>marquage temporel explicite), cf fig 4 ;
&#8211; Les d&#233;p&#234;ches comparatives (comparaison d&#8217;un &#233;tat de fait en divers lieux, &#233;poques...) ;
&#8211; Les d&#233;p&#234;ches &#233;num&#233;ratives.
</p>
<p>Les trois derni&#232;res cat&#233;gories sont int&#233;ressantes pour un syst&#232;me de r&#233;sum&#233; automatique. En
effet, alors qu&#8217;elles ne repr&#233;sentent que 5% du corpus AQUAINT-2, elles contiennent 80% des
informations pertinentes dans les donn&#233;es d&#8217;entra&#238;nement de la t&#226;che &#171; Update &#187; qui utilisent
un extrait d&#8217;AQUAINT-2. De plus, les d&#233;p&#234;ches appartenant &#224; ces cat&#233;gories sont &#233;crites dans
un style concis, ce qui fait des phrases qui les composent des candidats parfaits &#224; l&#8217;int&#233;gration
dans le r&#233;sum&#233; automatique. Elles ont &#233;galement des caract&#233;ristiques bien sp&#233;cifiques qui les
rendent facilement identifiables :
</p>
<p>&#8211; Les paragraphes des chronologies commencent presque tous par une r&#233;f&#233;rence temporelle ;
&#8211; les chronologies commencent souvent par une expression-cl&#233; telle que &#171; Here is a timeline of
</p>
<p>events surrounding the election : &#187; ;
&#8211; Les d&#233;p&#234;ches comparatives et &#233;num&#233;ratives contiennent des listes bien structur&#233;es ;
&#8211; Les &#233;l&#233;ments d&#8217;une liste issue d&#8217;une d&#233;p&#234;che comparative d&#233;butent par des termes qui appar-
</p>
<p>tiennent &#224; un m&#234;me cadre s&#233;mantique (par exemple, des noms de pays) ;
</p>
<p>Nous avons impl&#233;ment&#233; un classifieur qui classe les d&#233;p&#234;ches en quatre groupes : chronolo-
gies, d&#233;p&#234;ches comparatives, d&#233;p&#234;ches &#233;num&#233;ratives et d&#233;p&#234;ches &#171; classiques &#187;. Nous projetons
de d&#233;velopper un syst&#232;me plus complet qui g&#232;re tous les types de d&#233;p&#234;ches que nous avons</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Une approche mixte-statistique et structurelle - pour le r&#233;sum&#233; automatique de d&#233;p&#234;ches
</p>
<p>identifi&#233;s, ainsi que ceux d&#233;gag&#233;s par (Lucas, 2005).
</p>
<p>Nous avons &#233;valu&#233; notre classifieur sur une petite partie (300 documents) du corpus AQUAINT-
2 annot&#233;e &#224; la main. Nous obtenons 100% de pr&#233;cision et 81% de rappel pour les chronologies,
73% de pr&#233;cision et 65% de rappel pour les d&#233;p&#234;ches comparatives, et 65% de pr&#233;cision et
67% de rappel pour les d&#233;p&#234;ches &#233;num&#233;ratives. Nous expliquons les r&#233;sultats mitig&#233;s obtenus
sur les deux derni&#232;res cat&#233;gories par la proximit&#233; structurelle des d&#233;p&#234;ches comparatives et
&#233;num&#233;ratives et par la confusion que cela engendre pour notre classifieur.
</p>
<p>Nous avons int&#233;gr&#233; les r&#233;sultats de notre classifieur au syst&#232;me CBSEAS. Dans un premier
temps, les d&#233;p&#234;ches class&#233;es &#171; chronologie &#187;, &#171; comparative &#187; ou &#171; &#233;num&#233;rative &#187; se voient at-
tribuer un &#171; th&#232;me &#187;. Nous d&#233;finissons le th&#232;me comme la concat&#233;nation du titre de la d&#233;p&#234;che
et de la phrase d&#8217;introduction de la chronologie ou des comparaisons/&#233;num&#233;rations. Si le th&#232;me
d&#8217;une d&#233;p&#234;che est assez proche de la requ&#234;te utilisateur, alors CBSEAS favorise les phrases qui
en sont issues, en augmentant leur score de 15%. Nous avons compar&#233; les scores ROUGE-SU4
des r&#233;sum&#233;s des groupes de documents qui contiennent au moins une d&#233;p&#234;che class&#233;e &#171; non
classique &#187; et dont le th&#232;me se rapprochait de la requ&#234;te, et avons constat&#233; une am&#233;lioration de
10% par rapport aux r&#233;sultats de CBSEAS v0.5. Ces r&#233;sultats nous encouragent &#224; int&#233;grer la
structure des d&#233;p&#234;ches de mani&#232;re plus globale &#224; notre syst&#232;me de r&#233;sum&#233; automatique.
</p>
<p>7 Perspectives
</p>
<p>Notre classifieur de d&#233;p&#234;ches doit &#234;tre am&#233;lior&#233; : la m&#233;thode utilis&#233;e ne reconna&#238;t pour le mo-
ment que trois cat&#233;gories, qui sont les plus simples &#224; identifier. Les autres cat&#233;gories ont &#233;gale-
ment des caract&#233;ristiques qui leur sont propres ; la relation structure/importance des phrases
diff&#232;re d&#8217;une cat&#233;gorie de d&#233;p&#234;che &#224; une autre. La structure des d&#233;p&#234;ches et la temporalit&#233; &#233;tant
fortement li&#233;es, nous envisageons d&#8217;appliquer des techniques d&#8217;apprentissage comme les SVM
&#224; des documents annot&#233;s temporellement pour d&#233;tecter les types des d&#233;p&#234;ches et en d&#233;gager la
structure automatiquement.
</p>
<p>Un deuxi&#232;me axe de recherche concerne le syst&#232;me de r&#233;sum&#233; automatique lui-m&#234;me. En effet,
CBSEAS utilise des poids, notamment pour attribuer un score &#224; chaque phrase, qui ont &#233;t&#233; &#233;tab-
lis manuellement. Nous voudrions trouver automatiquement les poids qui optimisent la qualit&#233;
des r&#233;sum&#233;s. Pour cela, nous projetons d&#8217;utiliser un algorithme de recherche dans l&#8217;espace des
param&#232;tres qui fixe les poids de mani&#232;re &#224; maximiser un score automatique calcul&#233; par rapport
&#224; un r&#233;sum&#233; de r&#233;f&#233;rence.
</p>
<p>8 Conclusion
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; une nouvelle approche au r&#233;sum&#233; automatique multi-
document. Elle utilise une m&#233;thode de classification non supervis&#233;e pour regrouper les phrases
en classes s&#233;mantiques. Cette approche peut &#234;tre compar&#233;e aux approches qui utilisent le voisi-
nage des phrases comme crit&#232;re de s&#233;lection (Erkan &amp; Radev, 2004), car les phrases qui sont
fortement reli&#233;es &#224; un grand nombre d&#8217;autres phrases sont celles qui ont la plus grande prob-
abilit&#233; d&#8217;&#234;tre extraites. Cependant, notre approche diff&#232;re en un point crucial : la s&#233;lection des
phrases est directement d&#233;pendante de la d&#233;tection de redondance. Un deuxi&#232;me point de di-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Aur&#233;lien Bossard
</p>
<p>vergence est la m&#233;thode d&#8217;&#233;limination de la redondance, qui a lieu dans CBSEAS avant la
s&#233;lection finale des phrases qui constitueront le r&#233;sum&#233;. De plus, notre m&#233;thode permet la d&#233;-
tection/&#233;limination de la redondance de mani&#232;re non supervis&#233;e sans d&#233;finition d&#8217;un seuil de
similarit&#233; entre les phrases au-del&#224; duquel deux phrases sont consid&#233;r&#233;es redondantes.
</p>
<p>Nous avons &#233;galement propos&#233; une mani&#232;re d&#8217;am&#233;liorer la qualit&#233; des r&#233;sum&#233;s de d&#233;p&#234;ches, en
utilisant la structure sp&#233;cifique de ce type de documents. Nous avons montr&#233;, en int&#233;grant des
traits de structure basiques, que la prise en compte de la structure de tels documents augmentait
r&#233;ellement la qualit&#233; des r&#233;sum&#233;s g&#233;n&#233;r&#233;s.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BARZILAY R. (2003). Information Fusion for Multidocument Summarization : Paraphrasing
and Generation. PhD thesis.
BOSSARD A. &amp; G&#201;N&#201;REUX M. (2009). R&#195; c&#169;sum&#195; c&#169; automatique de textes d&#8217;opinion. In
Actes de la 16eme conf&#195; c&#169;rence sur le Traitement Automatique des Langues (TALN), Senlis,
France.
BOUDIN F., BECHET F., EL-BEZE M., FAVRE B., GILLARD L. &amp; TORRES-MORENO J.-
M. (2007). The LIA summarization system at DUC-2007. In Proceedings of DUC 2007
Document Understanding Conference.
CARBONELL J. &amp; GOLDSTEIN J. (1998). The use of MMR, diversity-based reranking for
reordering documents and producing summaries. In Proceedings of the 21st annual interna-
tional ACM SIGIR conference, p. 335&#8211;336, New York, NY, USA : ACM.
EDMUNDSON H. P. &amp; WYLLYS R. E. (1961). Automatic abstracting and indexing&#8212;survey
and recommendations. Commun. ACM, 4(5), 226&#8211;234.
ERKAN G. &amp; RADEV D. R. (2004). Lexrank : Graph-based centrality as salience in text
summarization. Journal of Artificial Intelligence Research (JAIR).
FRY E. B., KRESS J. E. &amp; FOUNTOUKIDIS D. L. (2000). The Reading Teachers Book of
Lists. Jossey-Bass, 4th edition.
GOLDBERG A. (2007). Cs838-1 advanced NLP : Automatic summarization.
LIN C.-Y. (2004). Rouge : a package for automatic evaluation of summaries. In Proceedings
of the Workshop on Text Summarization Branches Out (WAS 2004), Barcelona, Spain.
LIN C.-Y., CAO G., GAO J. &amp; NIE J.-Y. (2006). An information-theoretic approach to auto-
matic evaluation of summaries. In Proceedings of HLTC NACACL, p. 463&#8211;470, Morristown,
NJ, USA : Association for Computational Linguistics.
L&#211;PEZ-ESCOBAR S., CARRASCO-OCHOA J. A. &amp; TRINIDAD J. F. M. (2006). Fast global
k-means with similarity functions algorithm. In IDEAL, volume 4224 of Lecture Notes in
Computer Science, p. 512&#8211;521 : Springer.
LUCAS N. (2005). The enunciative structure of news dispatches, a contrastive rhetorical ap-
proach. In Proceedings of the ASLA Conference, p. 154&#8211;164.
LUHN H. (1958). The automatic creation of literature abstracts. IBM Journal, 2(2), 159&#8211;165.
RADEV D. (2004). MEAD - a platform for multidocument multilingual text summarization.
In Proceedings of LREC 2004, Lisbon, Portugal.
SALTON G. &amp; MCGILL M. J. (1986). Introduction to Modern Information Retrieval. New
York, NY, USA : McGraw-Hill, Inc.</p>

</div></div>
</body></html>