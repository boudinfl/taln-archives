
Une approche mixte-statistique et structurelle - pour le
résumé automatique de dépêches

Aurélien Bossard
LIPN - UMR 7030
CNRS - Université Paris 13
F-93430 Villetaneuse, France
aurelien.bossard@lipn.univ-paris13.fr

Résumé.          Les techniques de résumé automatique multi-documents par extraction ont récem-
ment évolué vers des méthodes statistiques pour la sélection des phrases à extraire.
Dans cet article, nous présentons un système conforme à l’« état de l’art » — CBSEAS — que
nous avons développé pour les tâches Opinion (résumés d’opinions issues de blogs) et Update
(résumés de dépêches et mise à jour du résumé à partir de nouvelles dépêches sur le même
événement) de la campagne d’évaluation TAC 2008, et montrons l’intérêt d’analyses struc-
turelles et linguistiques des documents à résumer. Nous présentons également notre étude sur la
structure des dépêches et l’impact de son intégration à CBSEAS.
Abstract.         Automatic multi-document summarization techniques have recently evolved
into statistical methods for selecting the sentences that will be used to generate the summary.
In this paper, we present a system in accordance with « State-of-the-art » — CBSEAS — that
we have developped for the « Opinion Task » (automatic summaries of opinions from blogs)
and the « Update Task » (automatic summaries of newswire articles and information update) of
the TAC 2008 evaluation campaign, and show the interest of structural and linguistic analysis
of the documents to summarize . We also present our study on news structure and its integration
to CBSEAS impact.
Mots-clés :        Résumé automatique, structure de documents.

Keywords:          Automatic summarization, document structure.
Aurélien Bossard
1    Introduction

Porté par une large communauté de chercheurs et des campagnes d’évaluation telles que DUC
(Document Understanding Conference) et TAC (Text Analysis Conference), le résumé automa-
tique a connu ces dernières années une évolution rapide.
Nous présentons dans ce papier une nouvelle approche pour le résumé automatique. Une nou-
velle méthode pour détecter la redondance a été intégrée au coeur de notre système, CBSEAS.
Cette méthode vise à mieux prendre en compte la redondance des informations que les sys-
tèmes existants afin de créer des résumés a priori plus pertinents. Les résultats obtenus lors de
la campagne d’évaluation TAC 2008 prouvent que notre système est adaptable et la méthode
efficace. Cependant, ils pointent également du doigt les faiblesses de CBSEAS auxquelles nous
nous efforçons de trouver des solutions que nous présentons ici.
Cet article est organisé de la manière suivante : en premier lieu, nous présentons les principales
approches de résumé automatique par extraction existantes. Nous décrivons ensuite notre sys-
tème générique, puis les modifications que nous lui avons apportées afin de participer à TAC
ainsi que son évaluation lors de cette campagne. Enfin, nous montrons comment nous comp-
tons améliorer CBSEAS sur la tâche particulière du résumé de dépêches en prenant en compte
la structure des documents comme une manière de déterminer la pertinence de leurs extraits.
Nous présentons également les premières expériences menées dans ce sens.
2    Etat de l’art

L’intérêt pour le résumé automatique a commencé à la fin des années 1950 avec les travaux de
(Luhn, 1958) ainsi que ceux (Edmundson & Wyllys, 1961). Les bases du résumé par extrac-
tion étaient alors posées. Les travaux de (Luhn, 1958) consistaient à classer les mots du ou des
documents à résumer selon un indice de fréquence qui n’est pas sans rappeler le tf-idf introduit
par (Salton & McGill, 1986). Les phrases contenant le plus de mots proches les uns des autres
considérés comme importants par l’indice de fréquence étaient alors sélectionnées pour générer
un résumé. Edmundson, en plus de mesures de fréquence des mots, prenait en compte la po-
sition des phrases dans leur document et favorisait certaines positions pour certains types de
documents —les premières phrases pour des dépêches de presse, les dernières pour un article
scientifique. Il prenait également en compte le nombre de mots commençant par une majuscule
(à l’époque, on ne parle pas encore d’entités nommées), la présence d’expressions-clé telles que
« In conclusion », « hardly ».
Les résumés automatiques sont alors créés uniquement sur la notion de centralité, ou d’impor-
tance d’un élément relativement à son contexte. La notion de diversité ou de non-redondance
des informations exposées dans le résumé n’était alors pas considérée, la recherche ne s’étant
pas encore intéressée au résumé multi-documents.
Plus récemment, des travaux ont intégré cette notion de diversité. Certains en post-traitement,
après classement des phrases à extraire par des scores reflétant la centralité. C’est le cas de
(Radev, 2004). Un « centroid », groupe de termes dont la fréquence d’apparition dénote l’impor-
tance, est créé pour chaque groupe de documents à résumer. Les phrases sont classées suivant le
nombre de termes du « centroid » qu’elles contiennent. Radev a également proposé dans (Erkan
& Radev, 2004) une méthode inspirée des réseaux sociaux et de la notion de « prestige ». Il
Une approche mixte-statistique et structurelle - pour le résumé automatique de dépêches
établit un graphe dans lequel les noeuds sont les phrases et les arêtes la similarité des phrases
les unes aux autres. Après avoir effectué un parcours aléatoire de ce graphe, il classe les phrases
selon le nombre de fois qu’elles ont été visitées. Dans ces deux méthodes, Radev gère la di-
versité en sélectionnant les phrases dans l’ordre de classement et en éliminant les phrases trop
similaires à une phrase déjà sélectionnée pour faire partie du résumé.
D’autres travaux gèrent la diversité dans le même temps que la centralité. Partant du principe
que la diversité étant aussi importante que la centralité, leurs auteurs considèrent que ces deux
aspects devaient être gérés dans le même temps. Parmi ceux-ci, la méthode MMR de (Carbonell
& Goldstein, 1998) combine deux mesures : l’une reflétant la centralité ou l’importance vis-à-
vis d’une requête utilisateur, l’autre la diversité. La diversité est fonction de la similarité aux
phrases déjà sélectionnées pour le résumé.
On peut également citer (Goldberg, 2007). Sa méthode reprend celle de (Erkan & Radev, 2004).
Cependant, au lieu de réaliser un simple parcours aléatoire, il utilise un parcours aléatoire
markovien à états absorbants. Ainsi, les noeuds centraux absorbent les scores des noeuds qui
les entourent, ce qui permet de gérer la diversité en même temps que la centralité.
(Boudin et al., 2007) a travaillé sur la fusion de différentes métriques. Le système, baptisé Neo-
Cortex, tire ainsi les bénéfices de l’utilisation de métriques qui rendent compte de différents
types de traits. Ce système s’est très bien classé dans la campagne d’évaluation DUC 2006.
Une dernière approche, celle de (Barzilay, 2003), aborde le problème de manière tout à fait
différente : elle détecte dans un premier temps les paraphrases en appliquant une SVM sur les
arbres syntaxiques normalisés des phrases des documents à résumer. Les informations les plus
importantes sont alors les plus paraphrasées. Cette technique est extrêmement bien adaptée à
la problématique du résumé multi-documents, où dû à la multiplicité des sources, la notion de
centralité se rapproche de celle de redondance. Cependant, à cause de la quantité de ressources
linguistiques qu’elle demande, cette méthode n’est pas adaptable à toutes les langues. Nous
voulons développer une méthode dans laquelle, à l’instar de (Barzilay, 2003), la redondance
occupe une place majeure, et qui soit assez indépendante des ressources linguistiques pour
permettre son adaptation à différentes langues.
3    CBSEAS : « Clustering-Based Sentence Extractor for Au-
tomatic Summarization »
Nous supposons que dans une problématique de résumé multi-document, les informations les
plus redondantes sont les éléments les plus importants pour produire un résumé pertinent. Par
conséquent, les phrases qui portent ces informations sont les phrases à extraire, moyennant
l’élimination de la redondance. Le regroupement des phrases qui véhiculent la même infor-
mation est la première étape de notre approche. L’algorithme développé établit une similarité
entre les phrases des documents à résumer puis applique un algorithme de classification — fast
global k-means (López-Escobar et al., 2006) — sur la matrice de similarité afin de créer des
regroupements au sein desquels les phrases véhiculent la même information, ou tout du moins
sont les plus proches les unes des autres.
Premièrement, nous sélectionnons n2 phrases pour créer un résumé de n phrases. L’algorithme
d’apprentissage créera n classes pour générer un résumé de n phrases. Il apparaît en effet que
fast global k-means est plus performant pour créer n classes avec n2 observations. L’élection de
Aurélien Bossard
for all ej in E
C 1 ← ej
for i from 1 to k do
for j from 1 to i
centre(Cj ) ← em |em maximise               sim(em , en )
en inCj
for all ej in E
placer ej dans Cl |Cl maximise sim(centre(Cl , ej )
ajouter un nouveau cluster : Ci qui contient initialement uniquement l’élément le moins bien représenté par sa classe
done
F IG . 1 – Algorithme Fast global k-means

ces n2 phrases se fait d’après leur similarité à une requête utilisateur dans le cas où il y en a une,
ou d’après leur proximité au centroid composé des m termes les plus importants, importance
reflétée par leur tf-idf.
La similarité entre les phrases est calculée à l’aide de la mesure « Jaccard ». Cette mesure est
efficace pour la comparaison d’ensembles. Les phrases sont au préalable étiquetées morpho-
syntaxiquement à l’aide de tree-tagger1 et la comparaison se fait sur les lemmes.
Une fois la matrice de similarité établie, CBSEAS effectue une classification des phrases en util-
isant l’algorithme fast global k-means (description de l’algorithme en figure 1). Cet algorithme
de classification a le double avantage de pouvoir prendre en entrée une matrice de similarité et
de s’affranchir de la sélection des centres de classes préalablement à la classification, un défaut
majeur de k-means.
La classification établie, CBSEAS sélectionne une phrase par classe afin de générer un résumé
qui contienne la plus grande partie des informations/idées pertinentes des documents d’origine.
La sélection des phrases s’opère selon une combinaison linéaire de la proximité des phrases au
centre de leur classe et de la similarité à la requête/au centroid du groupe de documents.
4        Evaluation au sein de TAC 2008 : « Opinion Task »
Afin d’évaluer notre système, nous avons participé à deux tâches de la campagne TAC (Text
Analysis Conference) 2008. La première des deux tâches, Opinion Task, consistait à résumer
les opinions contenues dans des blogs. Les résumés étaient orientés par une ou des requêtes
utilisateur telles que : « Why do people dislike ... ? ».
Les résumés ont été évalués manuellement par des analystes de NIST2 suivant le protocole
« Pyramid » (Lin et al., 2006). Le score PYRAMID d’un résumé automatique dépend du nom-
bre d’unités sémantiques qu’il contient et qui sont considérées comme importantes par les anno-
tateurs. L’importance d’une unité sémantique est fonction de son nombre d’occurences au sein
des résumés générés à la main par les annotateurs. Les résumés ont également été notés sur cinq
autres critères par les évaluateurs humains : grammaticalité, non-redondance, structure, fluidité
et « répondance ».
Les organisateurs de TAC offraient aux participants à la campagne d’évaluation la possibilité
1
http ://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
2
National Institute of Science and Technology : http ://www.nist.gov
Une approche mixte-statistique et structurelle - pour le résumé automatique de dépêches
Evaluation    CBSEAS     Mean   Best   Worst   Rank
Pyramid       .169       .151   .251   .101    5/20
Grammatic.    5.95       5.14   7.54   3.54    3/20
Non-redund.   6.64       5.88   7.91   4.36    4/20
Structure     3.50       2.68   3.59   2.04    2/20
Fluency       4.45       3.43   5.32   2.64    2/20
Responsiv.    2.64       2.61   5.77   1.68    8/20

F IG . 2 – Résultats de la tâche « Opinion »
d’utiliser des fragments de texte a priori pertinents produits par des systèmes de Questions-
Réponse (QR). Nous avons pensé qu’il est plus réaliste de considérer la production de résumé
indépendamment de la tâche de QR (même si ces deux tâches sont relativement proches) pour
deux raisons : suivant le contexte, un tel système n’est pas toujours disponible et surtout cu-
muler deux systèmes différents brouille l’évaluation, à moins de « tracer » les erreurs. Nous ne
présentons en 4.2 que les résultats des systèmes qui n’ont pas utilisé ces fragments de texte.
4.1    Modifications apportées au système

Les blogs ont été passés dans un module de filtrage visant à éliminer les phrases présentant des
incohérences lexicales. Les phrases avec un ratio nombre de mots fréquents/nombre total de mots
en dessous de 0.35 ont été écartées. Les « mots fréquents » sont les cent mots les plus fréquents
en langue anglaise ; ils constituent environ la moitié des textes écrits (Fry et al., 2000).
Les requêtes ainsi que toutes les phrases des documents ont été étiquetées selon l’opinion
qu’elles véhiculent — positive ou négative — selon une méthode d’analyse d’opinion dévelop-
pée par Michel Généreux. Plus de détails à ce propos sont disponibles dans (Bossard & Généreux,
2009).
CBSEAS est alors utilisé sur les données nettoyées afin de produire un premier résumé. Ce
résumé est ensuite réorganisé selon l’étiquetage en opinion des phrases qui le composent et
de l’ordre des requêtes. Par exemple, si la première requête était « Why do people appreciate
Linux ? » et la deuxième « For what reasons do people dislike Linux ? », alors le premier para-
graphe du résumé final contiendra les opinions positives et le second les opinions négatives.
4.2    Résultats

Le système proposé pour la tâche Opinion de TAC 2008 s’est très bien comporté (cf figure 2). En
effet, il se classe parmi le premier quart des participants excepté sur le score « Responsiveness ».
Le champ « Structure » montre que l’intégration du système d’étiquetage d’opinion a constitué
un véritable atout. Les scores Pyramid ainsi que le score de non-redondance dénotent quant à
eux le bien-fondé de notre approche bâtie sur la détection de la redondance. Le mauvais score
relatif en « responsiveness » s’explique en grande partie par la longueur de nos résumés : nous
avions choisi d’utiliser le maximum de caractères autorisés par TAC, soit 7000 caractères par
requête, ce qui s’est révélé a posteriori être une erreur.
Aurélien Bossard
F IG . 3 – Résultats de CBSEAS sur la tâche « Update »
5     Evaluation au sein de TAC 2008 : « Update Task »

Nous avons également évalué CBSEAS dans la tâche « Update ». Cette tâche consistait à fournir
des résumés pour différents thèmes. Chaque thème était composé de deux groupes de docu-
ments. Les documents étaient uniquement tirés du corpus AQUAINT-2, un corpus regroupant
des dépêches de presse tirés des plus grandes agences de presse internationales (AFP, Xinhua,
NYT...) Deux résumés devaient être fournis pour chaque thème, le premier synthétisant le pre-
mier groupe de documents, le deuxième résumant les informations contenues dans le deuxième
groupe de documents et qui constituaient une nouveauté par rapport au premier groupe. Les
résumés ne devaient pas excéder 100 mots.
Deux évaluations ont été proposées : la première utilisant PYRAMID, la deuxième utilisant les
mesures ROUGE (Lin, 2004), des mesures fondées sur la comparaison de n-grammes entre le
résumé automatique et un résumé de référence.
5.1    Modifications apportées au système

Notre système a été modifié de manière à gérer la mise à jour au cours de l’apprentissage de la
classification des phrases. Après avoir établi la classification en n classes des phrases du premier
groupe de documents et sélectionné une phrase par classe pour générer le résumé, les phrases
du second groupe de documents sont ajoutées au système de classification. Fast global k-means
est alors réitéré jusqu’à obtenir n classes de plus, avec les contraintes suivantes :
– les phrases du premier groupe de documents sont inamovibles ;
– les centres des n premières classes sont fixés et ne peuvent pas être recalculés.
Le résumé du deuxième groupe de documents est alors généré avec les n dernières classes.
Une approche mixte-statistique et structurelle - pour le résumé automatique de dépêches
5.2   Résultats

Les résultats présentés en figure 3 sont les résultats des mesures ROUGE-2 et ROUGE-SU4
(Lin, 2004). Suite à un mauvais paramétrage de CBSEAS, les résumés envoyés à TAC ne com-
portaient que 75 mots en moyenne, soit 3/4 des 100 mots autorisés, ce qui a grandement pénalisé
le système lors de l’évaluation. Des expériences ont été réalisées après TAC (système CBSEAS
v0.5). L’évaluation postérieure à la campagne sur les mêmes données se limite donc aux dif-
férentes mesures ROUGE — entièrement automatiques donc reproductibles — avec comme
étalon les résumés de référence fournis par NIST.
Malgré une méthode de mise à jour très efficace (le système se classe parmi les premiers sur
les résumés des seconds groupes de documents), CBSEAS ne se positionne pas bien sur cette
tâche. Cela signifie que les scores de CBSEAS sur les résumés des premiers jeux de documents
sont faibles. Nous l’expliquons par un manque d’adaptation du système à la tâche spécifique du
résumé de dépêches. En effet, les dépêches de presse comportent des spécificités et adoptent un
style d’écriture qui permet d’améliorer considérablement la qualité des résumés si on les prend
en compte. La plupart des systèmes de résumé automatique incorporent par conséquent des
caractéristiques comme la position d’une phrase dans le document ou la similarité de celle-ci
au titre pour calculer son score.
Cependant, ces critères, fondés sur des études anciennces, ne rendent pas entièrement compte
des spécificités des dépêches. C’est pourquoi nous proposons ici une manière d’intégrer la struc-
ture des dépêches à un système de résumé automatique, afin d’en renforcer la pertinence des
résultats.
6     La structure des dépêches et son intégration à CBSEAS

(Lucas, 2005) a mené une étude sur la structure énonciative des dépêches de presse. Il ressort
de cette étude que l’aspect temporel prime dans la structuration des dépêches. Elle propose
également une catégorisation des dépêches :
– Dépêches commentées (première partie : explication factuelle, deuxième partie : projection),
cf fig 4 ;
– Dépêches élaborées (plus d’un événement) ;
– Dépêches d’action (feuilleton : un fil d’événements fortement liés les uns aux autres, dépêches
boursières...)
et des méthodes pour les catégoriser ainsi que pour repérer automatiquement les différentes
parties qui les composent.
(Lucas, 2005) montre également que les dépêches commentées suivent la même présentation
chronologique. L’auteur présente d’abord l’événement présent, puis donne une explication à cet
événement en se fondant sur des faits passés. En dernier lieu, l’auteur décrit les conséquences
futures, probables ou avérées de l’événement présenté. Identifier ces trois parties peut s’avérer
utile : elles suivent toutes la règle classique de l’écriture de dépêches : l’information impor-
tante est portée par la première phrase. Les mêmes remarques s’appliquent aux autres types de
dépêches.
En parcourant le corpus AQUAINT-2, fourni lors de la campagne d’évaluation TAC 2008, nous
avons dégagé d’autres types de dépêches :
Aurélien Bossard
(a) Une dépêche commentée
(b) Une chronologie

F IG . 4 – Exemples de dépêches
– Les revues d’opinion (rapport des réactions de plusieurs intervenants à un même sujet) ;
– Les rapports de discours ;
– Les chronologies (se différencient des dépêches en feuilleton par un style plus concis et un
marquage temporel explicite), cf fig 4 ;
– Les dépêches comparatives (comparaison d’un état de fait en divers lieux, époques...) ;
– Les dépêches énumératives.
Les trois dernières catégories sont intéressantes pour un système de résumé automatique. En
effet, alors qu’elles ne représentent que 5% du corpus AQUAINT-2, elles contiennent 80% des
informations pertinentes dans les données d’entraînement de la tâche « Update » qui utilisent
un extrait d’AQUAINT-2. De plus, les dépêches appartenant à ces catégories sont écrites dans
un style concis, ce qui fait des phrases qui les composent des candidats parfaits à l’intégration
dans le résumé automatique. Elles ont également des caractéristiques bien spécifiques qui les
rendent facilement identifiables :
– Les paragraphes des chronologies commencent presque tous par une référence temporelle ;
– les chronologies commencent souvent par une expression-clé telle que « Here is a timeline of
events surrounding the election : » ;
– Les dépêches comparatives et énumératives contiennent des listes bien structurées ;
– Les éléments d’une liste issue d’une dépêche comparative débutent par des termes qui appar-
tiennent à un même cadre sémantique (par exemple, des noms de pays) ;
Nous avons implémenté un classifieur qui classe les dépêches en quatre groupes : chronolo-
gies, dépêches comparatives, dépêches énumératives et dépêches « classiques ». Nous projetons
de développer un système plus complet qui gère tous les types de dépêches que nous avons
Une approche mixte-statistique et structurelle - pour le résumé automatique de dépêches
identifiés, ainsi que ceux dégagés par (Lucas, 2005).
Nous avons évalué notre classifieur sur une petite partie (300 documents) du corpus AQUAINT-
2 annotée à la main. Nous obtenons 100% de précision et 81% de rappel pour les chronologies,
73% de précision et 65% de rappel pour les dépêches comparatives, et 65% de précision et
67% de rappel pour les dépêches énumératives. Nous expliquons les résultats mitigés obtenus
sur les deux dernières catégories par la proximité structurelle des dépêches comparatives et
énumératives et par la confusion que cela engendre pour notre classifieur.
Nous avons intégré les résultats de notre classifieur au système CBSEAS. Dans un premier
temps, les dépêches classées « chronologie », « comparative » ou « énumérative » se voient at-
tribuer un « thème ». Nous définissons le thème comme la concaténation du titre de la dépêche
et de la phrase d’introduction de la chronologie ou des comparaisons/énumérations. Si le thème
d’une dépêche est assez proche de la requête utilisateur, alors CBSEAS favorise les phrases qui
en sont issues, en augmentant leur score de 15%. Nous avons comparé les scores ROUGE-SU4
des résumés des groupes de documents qui contiennent au moins une dépêche classée « non
classique » et dont le thème se rapprochait de la requête, et avons constaté une amélioration de
10% par rapport aux résultats de CBSEAS v0.5. Ces résultats nous encouragent à intégrer la
structure des dépêches de manière plus globale à notre système de résumé automatique.
7    Perspectives

Notre classifieur de dépêches doit être amélioré : la méthode utilisée ne reconnaît pour le mo-
ment que trois catégories, qui sont les plus simples à identifier. Les autres catégories ont égale-
ment des caractéristiques qui leur sont propres ; la relation structure/importance des phrases
diffère d’une catégorie de dépêche à une autre. La structure des dépêches et la temporalité étant
fortement liées, nous envisageons d’appliquer des techniques d’apprentissage comme les SVM
à des documents annotés temporellement pour détecter les types des dépêches et en dégager la
structure automatiquement.
Un deuxième axe de recherche concerne le système de résumé automatique lui-même. En effet,
CBSEAS utilise des poids, notamment pour attribuer un score à chaque phrase, qui ont été étab-
lis manuellement. Nous voudrions trouver automatiquement les poids qui optimisent la qualité
des résumés. Pour cela, nous projetons d’utiliser un algorithme de recherche dans l’espace des
paramètres qui fixe les poids de manière à maximiser un score automatique calculé par rapport
à un résumé de référence.
8    Conclusion

Dans cet article, nous avons présenté une nouvelle approche au résumé automatique multi-
document. Elle utilise une méthode de classification non supervisée pour regrouper les phrases
en classes sémantiques. Cette approche peut être comparée aux approches qui utilisent le voisi-
nage des phrases comme critère de sélection (Erkan & Radev, 2004), car les phrases qui sont
fortement reliées à un grand nombre d’autres phrases sont celles qui ont la plus grande prob-
abilité d’être extraites. Cependant, notre approche diffère en un point crucial : la sélection des
phrases est directement dépendante de la détection de redondance. Un deuxième point de di-
Aurélien Bossard
vergence est la méthode d’élimination de la redondance, qui a lieu dans CBSEAS avant la
sélection finale des phrases qui constitueront le résumé. De plus, notre méthode permet la dé-
tection/élimination de la redondance de manière non supervisée sans définition d’un seuil de
similarité entre les phrases au-delà duquel deux phrases sont considérées redondantes.
Nous avons également proposé une manière d’améliorer la qualité des résumés de dépêches, en
utilisant la structure spécifique de ce type de documents. Nous avons montré, en intégrant des
traits de structure basiques, que la prise en compte de la structure de tels documents augmentait
réellement la qualité des résumés générés.
Références
BARZILAY R. (2003). Information Fusion for Multidocument Summarization : Paraphrasing
and Generation. PhD thesis.
B OSSARD A. & G ÉNÉREUX M. (2009). RÃ c sumÃ c automatique de textes d’opinion. In
Actes de la 16eme confÃ c rence sur le Traitement Automatique des Langues (TALN), Senlis,
France.
B OUDIN F., B ECHET F., E L -B EZE M., FAVRE B., G ILLARD L. & T ORRES -M ORENO J.-
M. (2007). The LIA summarization system at DUC-2007. In Proceedings of DUC 2007
Document Understanding Conference.
C ARBONELL J. & G OLDSTEIN J. (1998). The use of MMR, diversity-based reranking for
reordering documents and producing summaries. In Proceedings of the 21st annual interna-
tional ACM SIGIR conference, p. 335–336, New York, NY, USA : ACM.
E DMUNDSON H. P. & W YLLYS R. E. (1961). Automatic abstracting and indexing—survey
and recommendations. Commun. ACM, 4(5), 226–234.
E RKAN G. & R ADEV D. R. (2004). Lexrank : Graph-based centrality as salience in text
summarization. Journal of Artificial Intelligence Research (JAIR).
F RY E. B., K RESS J. E. & F OUNTOUKIDIS D. L. (2000). The Reading Teachers Book of
Lists. Jossey-Bass, 4th edition.
G OLDBERG A. (2007). Cs838-1 advanced NLP : Automatic summarization.
L IN C.-Y. (2004). Rouge : a package for automatic evaluation of summaries. In Proceedings
of the Workshop on Text Summarization Branches Out (WAS 2004), Barcelona, Spain.
L IN C.-Y., C AO G., G AO J. & N IE J.-Y. (2006). An information-theoretic approach to auto-
matic evaluation of summaries. In Proceedings of HLTC NACACL, p. 463–470, Morristown,
NJ, USA : Association for Computational Linguistics.
L ÓPEZ -E SCOBAR S., C ARRASCO -O CHOA J. A. & T RINIDAD J. F. M. (2006). Fast global
k-means with similarity functions algorithm. In IDEAL, volume 4224 of Lecture Notes in
Computer Science, p. 512–521 : Springer.
L UCAS N. (2005). The enunciative structure of news dispatches, a contrastive rhetorical ap-
proach. In Proceedings of the ASLA Conference, p. 154–164.
L UHN H. (1958). The automatic creation of literature abstracts. IBM Journal, 2(2), 159–165.
R ADEV D. (2004). MEAD - a platform for multidocument multilingual text summarization.
In Proceedings of LREC 2004, Lisbon, Portugal.
S ALTON G. & M C G ILL M. J. (1986). Introduction to Modern Information Retrieval. New
York, NY, USA : McGraw-Hill, Inc.
