TAL 2009, Senlis, 24-26 juin 2009 
Un système modulaire d’acquisition automatique de traductions à 
partir du Web 
Stéphanie Léon 
LIRMM, 161 rue Ada, 34392 Montpellier Cedex 51 
stephanie.leon@lirmm.fr 
Résumé Nous présentons une méthode de Traduction Automatique d’Unités Lexicales 
Complexes (ULC) pour la construction de ressources bilingues français/anglais, basée sur un 
système modulaire qui prend en compte les propriétés linguistiques des unités sources 
(compositionnalité, polysémie, etc.). Notre système exploite les différentes « facettes » du 
Web multilingue pour valider des traductions candidates ou acquérir de nouvelles traductions. 
Après avoir collecté une base d’ULC en français à partir d’un corpus de pages Web, nous 
passons par trois phases de traduction qui s’appliquent à un cas linguistique, avec une 
méthode adaptée : les traductions compositionnelles non polysémiques, les traductions 
compositionnelles polysémiques et les traductions non compositionnelles et/ou inconnues. 
Notre évaluation sur un vaste échantillon d’ULC montre que l’exploitation du Web pour la 
traduction et la prise en compte des propriétés linguistiques au sein d’un système modulaire 
permet une acquisition automatique de traductions avec une excellente précision. 
Abstract We present a method of automatic translation (French/English) of Complex 
Lexical Units (CLU) for aiming at extracting a bilingual lexicon. Our modular system is based 
on linguistic properties (compositionality, polysemy, etc.). Different aspects of the 
multilingual Web are used to validate candidate translations and collect new terms. We first 
build a French corpus of Web pages to collect CLU. Three adapted processing stages are 
applied for each linguistic property : compositional and non polysemous translations, 
compositional polysemous translations and non compositional translations. Our evaluation on 
a sample of CLU shows that our technique based on the Web can reach a very high precision. 
Mots-clés : Traduction Automatique, Unités Lexicales Complexes, Désambiguïsation 
lexicale, World Wide Web, Terminologie 
Keywords : Automatic translation, Complex lexical units, Lexical disambiguisation, 
World Wide Web, Terminology 
1 Introduction 
L’ambiguïté lexicale est un problème majeur pour les systèmes de traduction automatique ou 
de recherche d’informations interlingue. Par exemple, la traduction anglaise du terme français 
                                                 
1 Cet article est issu d’un travail de thèse soutenue en décembre 2008 sous la direction de Jean Véronis (LIF). 
Stéphanie Léon 
caisse est différente selon que l'usage concerne, entre autres, l’ISTRUMET DE MUSIQUE 
(drum), la BAQUE (fund) ou la VALISE (case). L’absence de désambiguïsation lexicale pour 
la traduction automatique conduit à des résultats qui gênent souvent la compréhension. Ainsi, 
le système Systran2 traduit l’Unité Lexicale Complexe (ULC)3 caisse claire par clear case, ce 
qui est incompréhensible pour un anglophone. La co-occurrence caisse/claire constitue un 
indice désambiguïsateur très fort, qui, si elle était correctement enregistrée dans une base de 
données bilingue pourrait servir à générer des traductions correctes (caisse claire > snare 
drum). La polysémie est rendue faible dès que l'on envisage les unités lexicales selon leur co-
occurrent (Yarowsky, 1993), (Shütze, 1998) et (Véronis, 2003). Les travaux existants ont 
proposé des méthodes d’acquisition de terminologie bilingue à partir de corpus parallèles 
(voir (Véronis, 2000)) ou comparables (citons, entre autres, (Rapp, 1999), (Fung, McKeown, 
1997) (Fung, Yee, 1998) et (Morin et al., 2004)). Les corpus parallèles constituent des 
ressources rares tandis que les corpus comparables se limitent à un domaine de spécialité. Le 
Web, qui génère des besoins considérables en traduction, offre en même temps un réservoir 
gigantesque de données multilingues qui pourraient être exploitées afin d’acquérir les 
traductions correctes.  
Les contraintes de Traduction Automatique d’ULC varient en fonction des caractéristiques 
linguistiques des unités sources. Si les constituants de l’ULC sont polysémiques, la tâche 
consiste à sélectionner la bonne traduction de chaque constituant parmi des traductions 
candidates. Si les constituants ne sont pas polysémiques, la tâche consiste à valider ou pas la 
combinaison de leurs traductions. Les traductions d’ULC peuvent être compositionnelles, 
c’est-à-dire basées sur une combinaison des traductions des constituants, ou non 
compositionnelles (traduction non littérale). Les travaux d’acquisition de traductions n’ont pas 
exploité ces indices linguistiques et ont proposé des méthodes globales. Nous appliquons un 
traitement automatique adapté à une typologie linguistique, pour la construction d’un système 
modulaire d’acquisition automatique de traductions d’ULC du français vers l’anglais, à partir 
du Web. Ce système s’appuie sur la détection automatique des propriétés linguistiques de 
traduction des ULC (compositionnalité, polysémie des constituants) et chaque module est 
consacré à un type de traduction. Les propriétés multilingues du Web sont exploitées afin de 
collecter et de filtrer automatiquement des traductions candidates (pages parallèles ou 
« partiellement » parallèles, fréquences, comparaison de mondes lexicaux). Notre système 
permet d’acquérir des ULC sources en français, à partir d’un corpus de pages Web et de 
proposer un système modulaire de traductions de ces ULC. La section 2 présente notre 
méthodologie, l’acquisition automatique des données et la méthode de traduction sur un 
échantillon aléatoire. La section 3 présente l’évaluation, les résultats et les perspectives. 
2 Méthodologie et traitement des données 
Nous procédons à une extraction d’ULC en français à partir d’un corpus de pages Web 
étiqueté morpho-syntaxiquement. Nous analysons automatiquement leurs propriétés 
linguistiques via un dictionnaire électronique bilingue. Le module de traduction est 
sélectionné en fonction de ces caractéristiques. Après avoir décrit la méthode d’acquisition 
d’ULC sources (2.1), nous décrivons l’architecture du système et détaillons chaque module 
(2.2). 
                                                 
2  http://www.systransoft.com/ 
3  Nous parlons d’ULC afin de désigner une cooccurrence lexicale entre deux lexèmes liés syntaxiquement. 
Un système modulaire d’acquisition automatique de traductions à partir du Web 
2.1 Acquisition d’ULC en langue source 
Nous collectons des pages Web associées à une liste aléatoire de noms simples extraits du 
dictionnaire électronique bilingue Collins Pocket (français-anglais)4. Ces pages sont nettoyées 
automatiquement et étiquetées via le logiciel Treetagger5. Nous appliquons ensuite des filtres 
linguistiques et des filtres de fréquence. D’un point de vue linguistique, nous définissons les 
patrons morpho-syntaxiques répondant aux relations de dépendances syntaxiques recherchées 
(NOM-ADJECTIF ET NOM-de(d’)-NOM) en ne prenant en compte que les séquences 
contigües. En ce qui concerne la fréquence, nous posons des seuils fixes. La fréquence de 
l’ULC au sein de notre corpus doit être supérieure ou égale à 10. Ensuite, les ULC sont testées 
en tant que requêtes sur le moteur de recherche Yahoo et nous ne conservons que celles dont 
les nombres d'occurrences estimés par le moteur de recherche sont les plus élevés 6. Ce filtre 
peut provoquer du silence, mais nous posons volontairement un filtre élevé afin d’obtenir des 
ressources de très bonne qualité, sans aucune intervention humaine. Cette étape pourra être 
améliorée par la suite par des méthodes statistiques plus poussées, mais elle constitue en l’état 
un banc de test satisfaisant afin d’évaluer notre système de traduction. Nous obtenons 9664 
ULC en français, associées à 1664 têtes sémantiques7(noms simples dont vont dépendre 
sémantiquement les autres actants au sein d’une ULC). Le nombre moyen d’ULC par tête 
sémantique est de 6. Notre corpus de pages Web est constitué d’environ 4 160 000 pages Web 
et continue de grossir au quotidien. Le schéma suivant présente le nombre d’ULC sources 
obtenus par patron morpho-syntaxique : 
(OM-ADJECTIF 5 166
(OM-DE-(OM 2934
(OM-D'-(OM 1564
TOTAL 9664  
Tableau 1 : Proportion d’ULC par patron morpho-syntaxique 
Voici un extrait d’ULC associées à la tête sémantique appareil : 
OM-D’-OM : Appareil d’état, appareil d’imagerie, catégorie d’appareil 
OM-DE-OM : Appareil de chauffage, appareil de contrôle, appareil de cuisson 
OM-ADJECTIF : Appareil administratif, appareil argentique, appareil auditif 
Afin de tester notre méthodologie de traduction, nous réalisons un échantillon aléatoire de 
1075 ULC. Nous avons évalué la qualité des ULC de façon manuelle et aucune n’a été 
éliminée. 
                                                 
4  Nous aurions pu partir d’une liste monolingue d’ULC déjà existante mais il n’existe pas de ressource à très 
vaste échelle.  
5  http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/ 
6  La fréquence de l’ULC retournée par le moteur de recherche en tant qu’expression littérale doit être 
supérieure ou égale à 10000 et la fréquence de l’ULC, précédée par un article (défini ou indéfini) doit être 
supérieure ou égale à 1000. 
7  Nous parlons de tête sémantique afin de désigner l’élément dont dépendent sémantiquement les autres actants 
au sein d’une ULC. 
Stéphanie Léon 
2.2 Architecture et spécification du système d’acquisition des traductions 
Notre système est modulaire (chaque phase traite d’ULC ayant des caractéristiques 
spécifiques de traduction) et linéaire (les traductions non obtenues au sein d’un module sont 
renvoyées au module suivant). Chaque sous-section présente un module : les traductions 
compositionnelles non polysémiques (2.2.1), les traductions compositionnelles polysémiques 
(2.2.2) et les traductions non compositionnelles et/ou inconnues (2.2.3). 
2.2.1 Traductions compositionnelles non polysémiques 
Le premier module traite des traductions compositionnelles non polysémiques : le sens est 
transparent (chaque constituant peut être traduit de façon littérale) et le sens de chaque 
constituant n’est pas ambigu (non polysémique)8. Cette tâche peut consister à déterminer si la 
combinaison de chaque traduction candidate des constituants de l’ULC, générée par une 
ressource dictionnairique est valide ou pas. (Léon et Millon, 2005) montrent que la fréquence 
sur le Web de traductions candidates peut être exploitée pour la validation si les unités sources 
ne sont pas polysémiques. Nous nous appuyons sur le nombre de traductions candidates de 
chaque constituant dans notre dictionnaire bilingue (Dagan et al., 1991) et ne conservons que 
celles dont les constituants ne comptent qu’une traduction. Par exemple, l’ULC ambiance 
musicale est conservée puisque ambiance et musicale ne comptent respectivement qu’une 
seule traduction (atmosphere/musical). Nous générons automatiquement toutes les traductions 
candidates via le Collins Pocket selon la méthode de (Léon, Millon, 2005 ; Léon, 2006), qui 
consiste à générer toutes les combinaisons possibles des traductions des éléments simples et à 
effectuer des règles de transformation morpho-syntaxique, comme institut de 
psychologie (institut / institute, psychologie / psychology), dont les traductions candidates 
sont institute of psychology et psychology institute. Les règles de transformation morpho-
syntaxiques pour chaque patron sont les suivantes :  
OM1 de OM 2 > OM1 of OM2 
OM1 de OM 2 > OM2 OM1 
OM ADJECTIF > ADJECTIF OM 
Le moteur de recherche Yahoo est interrogé automatiquement afin de récupérer le nombre 
d’occurrences de chaque traduction candidate. Pour chaque traduction candidate, nous 
générons un ensemble de requêtes selon le modèle suivant : 
(OM-ADJECTIF « the ADJ NOM » OR « a ADJ NOM »
(OM1-DE(D')-(OM2 « the NOM1 of NOM2 » OR « a NOM1 of NOM2 » 
« the NOM2 NOM1 » OR « a NOM2 NOM1 »  
Tableau 2 : Patrons des requêtes des traductions candidates 
Un filtre simple est appliqué aux traductions candidates. Nous ne conservons que celles dont 
la fréquence sur le Web est au moins égale à un dix-millième des occurrences du mot cible. 
                                                 
8  Nous considérons qu’une unité est non polysémique si elle a strictement une unique traduction dans notre 
dictionnaire bilingue. Le terme de « polysémie » est donc ici employé de façon pratique, dans le contexte de 
la traduction et à partir d’une ressource donnée.  
Un système modulaire d’acquisition automatique de traductions à partir du Web 
Prenons pour exemple9 « messe de minuit » et deux de ses traductions candidates « midnight 
mass » et « mass of midnight » : Seuil_mass : 764 000 000 / 10 000 = 30400. La traduction 
« midnight mass » (avec une fréquence de 336 000, donc supérieure au seuil limite pour le 
nom cible mass) est retenue, tandis que « mass of midnight » (avec une fréquence de 65, donc 
inférieure au seuil limite pour le nom cible mass) est rejetée. Après le filtre automatique sur 
les fréquences, 39.24% des traductions candidates sont conservées. Les traductions obtenues 
comptent pour 9.11% de nos unités lexicales à traduire10. Parmi les unités lexicales non 
polysémiques, 57.40% d’entre elles obtiennent une traduction à cette étape. Le tableau suivant 
présente la proportion de traductions conservées après le filtre automatique. 
Traductions 
générées
(OM ADJ 29 20 68,97%
(OM DE (OM 40 8 20,00%
(OM D' (OM 10 3 30,00%
TOTAL 79 31 39,24%
Filtre automatique
Filtre seuil fréquence
 
Tableau 3 : Résultats du filtre des traductions après la phase 1 
2.2.2 Traductions compositionnelles polysémiques 
Lorsque les constituants à traduire sont polysémiques, la tâche de traduction ne consiste pas 
en une simple validation mais en une sélection parmi de nombreuses traductions candidates. Il 
s’agit de désambiguïser le sens de chaque constituant. (Léon, 2006) montre qu’une 
comparaison des mondes lexicaux sur le Web entre l’unité source et chaque traduction 
candidate permet de lever un grand nombre d’ambiguïtés lexicales. Selon nous, un « monde 
lexical » désigne les co-occurrences fréquentes (plus larges que le co-occurrent immédiat) 
d'une unité lexicale au sein d’une collection de textes (Véronis, 2003). Ce deuxième module 
est une version améliorée de la méthode de (Léon, 2006) qui procède à une désambigüisation 
lexicale pour la traduction via les contextes lexicaux sources et cibles sur le Web. Les 
traductions candidates sont générées avec la même méthode que celle décrite en 2.2.1. 
Comme celles-ci sont en grande quantité, il serait coûteux de générer les mondes lexicaux de 
chacune d’elle. Nous utilisons deux filtres préalables qui permettent d’éliminer les traductions 
les plus erronées. Nous testons les fréquences des couples de traduction sur le Web. Notre 
hypothèse est que si la traduction est correcte, le couple doit apparaître au moins une fois dans 
un même document : de nombreux documents du Web sont des textes linguistiquement 
mixtes (traductions de manuels, de catalogues, glossaires, etc.). Nous engendrons 
automatiquement une requête pour chaque couple restant, du type de « caisse centrale » 
«central fund » et ne conservons que les couples dont la fréquence est supérieure ou égale à 1. 
Notre second filtre détermine le rapport entre la fréquence sur le Web de l’ULC source et 
celui des traductions candidates. Par exemple, « caisse de retraite » apparaît 157000 fois. 
« retirement cas » apparaît 2850 fois, tandis que « retirement fund » apparaît 1240000 fois. 
On exclut les traductions ayant une fréquence inférieure au terme français (étant donné le 
                                                 
9     Juillet 2008. 
10  Viennent s’ajouter les ULC déjà traduites au sein de notre dictionnaire que nous conservons d’emblée, à 
savoir 98 traductions à l’issue de la phase 1 sur les 1075 ULC de départ. 
Stéphanie Léon 
rapport entre le nombre de pages indexées en anglais et en français, une traduction correcte en 
anglais doit avoir une fréquence supérieure à son ULC source en français). 
Nous construisons enfin les mondes lexicaux de chaque ULC source et des traductions 
candidates restantes. Nous collectons les 1000 premiers résumés retournés par le moteur de 
recherche Yahoo pour chaque requête correspondant à une ULC source et à chacune de ses 
traductions candidates. Nous collectons ensuite les cinquante noms et les cinquante adjectifs 
les plus fréquents parmi les résumés étiquetés de façon morpho-syntaxique. Ces mondes 
lexicaux français et anglais pour les noms et pour les adjectifs sont respectivement comparés 
via le dictionnaire bilingue. Le nombre de mots communs entre les mondes lexicaux français 
et anglais est comptabilisé. Le coefficient de Jaquard est utilisé afin de mesurer le degré de 
similitude entre les deux ensembles : | inter(X,Y) | / | union (X,Y) |. Seules les traductions 
candidates dont l’indice de Jaquard est supérieur à un seuil fixé (pour la catégorie des noms et 
pour la catégorie des adjectifs) sont conservées et nous sélectionnons celle qui a le plus haut 
score pour chaque ULC. A l’issue de cette étape, nous obtenons pour 68.98% des ULC 
restantes traduire. 
 
Tableau 4 : Résultats des filtres après la phase 2 
2.2.3 Traductions non compositionnelles et/ou inconnues 
A ce stade, plusieurs difficultés expliquent l’absence de traduction des ULC restantes. Il arrive 
que la somme des traductions de chaque élément de l’ULC ne permette pas d’obtenir la 
traduction adéquate, comme dans caisse claire > snare drum (tambour/ piège). Il peut aussi 
s’agir de cas où la base et/ou le co-occurrent est recensé dans notre dictionnaire, mais l’emploi 
pertinent n’est pas répertorié, comme pour caisse d’épargne > savings bank. Ici, l’emploi de 
caisse (BAQUE) n’est pas répertorié dans notre dictionnaire. Enfin, il peut s’agir de cas où la 
base ou le co-occurrent est un terme technique non recensé dans nos ressources 
dictionnairiques comme dans appareil circulatoire. Dans cet exemple, la traduction de 
circulatoire est inconnue de nos ressources et notre objectif est également de découvrir de 
nouvelles traductions. Notre dernière phase vise à pallier deux difficultés, le problème de la 
non-compositionnalité et celui de co-occurrents inconnus de nos ressources dictionnairiques, 
parce qu’ils sont trop techniques ou récents. Le point commun est qu’une utilisation de 
ressources existantes n’est pas satisfaisante. Le principe de ce module est de collecter 
directement les traductions à partir de résumés « mixtes » sur le Web, à l’instar de Nagata 
(2001) pour le japonais et l’anglais. Notre méthode d’acquisition de résumés mixtes consiste à 
générer des requêtes en français (langue source), recherchées dans des pages en anglais 
(langue cible), ce qui ramène majoritairement des pages linguistiquement « mixtes ». A partir 
de ces résumés, nous appliquons deux stratégies de repérage des traductions candidates : dans 
un premier temps, nous identifions des cognats (« occurrences qui sont identiques ou se 
ressemblent graphiquement », Véronis, 2000), et dans un second temps, nous repérons les 
couples les plus fréquents. Ces deux étapes se présentent de la même façon que les étapes 
précédentes, c’est-à-dire qu’elles sont successives : nous recherchons d’abord les cognats. Il 
peut s’agir, par exemple de mots graphiquement apparentés tels que langue et language (ibid.) 
Filtre Web
parallèle,
« top 3 »
Filtre
rapport
français/ 
anglais
Filtre
indice de
Jaquard
977 18 844 1919 1239 674
Unités lexicales
restantes après la
phase 1
Traductions candidates
générées
 
Filtre automatique 
Un système modulaire d’acquisition automatique de traductions à partir du Web 
ou alors de formes communes. Nous comparons les quatre premières lettres du co-occurrent 
anglais (premier constituant du couple) avec celui du co-occurrent français (deuxième 
constituant). Nous aurions pu appliquer une méthode de comparaison plus classique telle 
qu’une distance de Levenshtein mais nous ne nous intéressons qu’aux chaines communes qui 
se trouvent dans la même position au sein des mots source et cible. Nous passons ensuite par 
plusieurs filtres de validation, selon le même modèle que dans la phase précédente (requêtes 
en couple sur le Web et filtre du rapport entre les fréquences françaises et anglaises). Il reste, 
après tous les filtres, 292 traductions candidates. Les traductions candidates restantes sont 
ensuite filtrées par l’indice de Jaquard. A l’issue de cette sous-étape, 89 traductions sont 
validées, soit 29.37% des unités lexicales de départ pour cette phase, et 8.27% de la totalité de 
nos données de départ. Les traductions non obtenues passent ensuite par le module des 
couples fréquents. Etant donné que le texte contient plusieurs langues, il est délicat de 
procéder à un étiquetage morpho-syntaxique. Nous conservons les résumés bruts retournés par 
le moteur de recherche et récoltons les couples de mots les plus fréquents au sein de ces 
résumés. Nous nous centrons volontairement sur les couples candidats, et ne prenons pas en 
compte les chaines plus longues, ce qui peut provoquer des cas de silence pour le repérage du 
patron OM-of-OM ou d’une unité simple. Toutefois, l’analyse de textes non étiquetés est 
une tâche délicate et nous nous centrons sur le patron morpho-syntaxique candidat le plus 
fréquent. A partir des 303 unités lexicales sources restantes à traduire, 327 815 couples 
différents sont générés. A l’issue des mêmes filtres que précédemment, 26 traductions sont 
validées (soit 115 en tout pour la phase complète). Le tableau 5 montre un exemple de 
traductions obtenues à chaque étape (la totalité des traductions est de 887) et le tableau 6 
présente la quantité de traductions obtenues par phase. 
psychologie sociale/social psychology 
drame musical/musical drama
acide nucléique/nucleic acid
souris d’agneau/lamb shank 
PHASE 1 (Méthode des fréquences)
PHASE 2 (Mondes lexicaux)
PHASE 3 (Cognats et couples fréquents)
accident grave/serious accident                  
éclat naturel/natural shine
Tableau 5 : Exemples de traductions 
11,05%
75,99%
12,97%
PHASE 1 (Méthode des fréquences) 98
PHASE 2 (Mondes lexicaux) 674
PHASE 3 (Cognats et couples fréquents) 115
 
Tableau 6 : Traductions obtenues pour chaque phase11 
3 Evaluation et analyse des résultats 
Au sein de notre échantillon aléatoire, nous évaluons les 887 traductions obtenues. Nous 
avons opté pour une évaluation manuelle, effectuée par un locuteur bilingue12, avec trois 
                                                 
11  La phase 1 combine les traductions obtenues à cette étape avec les ULC déjà traduites dans notre dictionnaire 
que nous conservons telles quelles.  
12  L’évaluatrice est Amanda Grey, traductrice professionnelle (http://www.amandagrey.com/). 
Stéphanie Léon 
appréciations possibles : A (Bonne traduction), B (Traduction acceptable), ou C (Mauvaise 
traduction). Le locuteur a eu accès aux contextes des traductions, en observant les contextes 
retournés par le moteur de recherche, pour chaque requête d’ULC source et chaque traduction 
obtenue. Les résultats obtenus montrent que 89,29% des traductions ont été considérées 
comme correctes par l’évaluatrice (catégorie A) et 5,07% ont été considérées comme 
acceptables (B). Seulement 5,64% de traductions ont été jugées erronées (C). Ces résultats 
sont particulièrement satisfaisants puisqu’ils montrent que 94,36% des résultats sont 
directement exploitables, sans aucune intervention humaine, soit une précision très 
satisfaisante. Le taux de rappel, lui, est de 77,86%. Nous analysons les erreurs de traduction 
(3.1), puis nous présentons nos perspectives d’évolution (3.2). 
3.1 Analyse des erreurs 
Les erreurs que nous analysons ici concernent exclusivement celles qui ont été relevées via la 
non acceptation de l’évaluation de l’expert, à savoir le bruit. Nous recensons trois grandes 
catégories d’erreurs, les erreurs lexicales (3.1.1), les erreurs morpho-syntaxiques (3.1.2) et les 
erreurs « idiomatiques » (3.1.3). 
3.1.1 Erreurs lexicales 
Les erreurs lexicales désignent un mauvais choix lexical d’au moins un des constituants de 
l’ULC. Le choix lexical peut être proche d’un point de vue thématique mais non équivalent (il 
s’agit de la tête sémantique, du co-occurrent ou de la totalité des éléments) comme dans 
l’exemple de Parc nucléaire > nuclear energy. Le choix lexical peut être totalement erroné, 
c’est-à-dire que la désambigüisation lexicale n’a pas été correctement effectuée (il s’agit 
systématiquement d’un mauvais choix de la tête sémantique) comme dans Fond d’aide > help 
back. 
3.1.2 Erreurs morpho-syntaxiques 
Un autre type d’erreur concerne les cas de traductions ayant une structure morpho-syntaxique 
erronée. Les erreurs morpho-syntaxiques altèrent moins la compréhension globale que les 
erreurs lexicales, comme dans l’exemple de Analyse de marché > analysis of market (au lieu 
de market analysis). Parmi les erreurs morpho-syntaxiques, nous distinguons deux cas pour la 
structure syntaxique source OM-DE-OM (du type de analyse de marché). Certaines erreurs 
consistent en un mauvais choix entre les structures de type « germanique » (OM-OM) et de 
type « roman » (OM OF OM) (Chuquet et Paillard, 1987). D’autres erreurs consistent en 
une non prise en compte de la structure de type « possessif », faisant intervenir le génitif. 
3.1.3 Erreurs idiomatiques 
Un dernier type d’erreur concerne un choix lexical sémantiquement pertinent, mais dont le 
caractère idiomatique n’est pas pleinement satisfaisant, comme dans l’exemple de Fête 
d’anniversaire > anniversary party. Bien que cette traduction soit considérée comme 
acceptable et reste compréhensible, le choix lexical de anniversary (au lieu de birthday) ne 
correspond pas au choix le plus pertinent d’un point de vue idiomatique.  
Un système modulaire d’acquisition automatique de traductions à partir du Web 
3.1.4 Perspectives 
3.1.4.1 Thématiques de recherche 
Nous avons fait le choix de n’extraire qu’une seule traduction par unité lexicale source. Nous 
pourrions nous intéresser à un recensement de toutes les traductions possibles pour une ULC. 
Nous pourrions nous intéresser à un ensemble de domaines ou de thématiques sur le Web. Par 
exemple, une traduction satisfaisante en langue générale (l’usage le plus courant) peut être 
inadéquat dans un domaine de spécialité. Considérons la traduction appareil numérique > 
digital camera. Bien que l’usage le plus courant soit l’usage PHOTOGRAPHIE, la traduction 
digital camera est inappropriée dans certains domaines. Dans le domaine médical, la 
traduction est digital device. Une évolution sera de nous intéresser aux domaines de spécialité 
sur le Web, afin de pallier les limites liées à l’ambigüité lexicale.  
3.1.4.2 Amélioration de la conparaison des mondes lexicaux 
Une limite de la mesure de Jaquard (comparaison des mondes lexicaux) est de ne pas prendre 
en compte les différences de fréquences. Si le partage des fréquences est inégal, la 
comparaison est moins efficace que si la répartition des fréquences était équilibrée. Nous 
pourrions prendre en compte le poids (fréquence) des unités lexicales au sein de chaque 
monde lexical et obtenir une comparaison pondérée. De nombreuses méthodes peuvent être 
envisagées afin de tenir compte de la fréquence des unités au sein des textes à comparer. Dans 
une discussion sur le choix d’une méthode de mesure de comparaison entre deux textes, 
Brunet (2003) montre que quelle que soit la méthode, les différences sont peu sensibles. 
3.1.4.3 Ajout de ressources externes 
Prince et Chauché (2008) présentent une méthode de traduction basée sur l’exploitation de 
ressources de type ontologique. Chaque thesaurus en anglais (English Roget Thesaurus) et en 
français (Thesaurus Larousse) est exploité tel un espace vectoriel, dans lequel les entrées 
monolingues forment un vecteur de concepts associés. Les entrées françaises sont représentées 
sous la forme de leur équivalence dans l’espace anglais. La tâche de désambigüisation lexicale 
consiste à sélectionner le vecteur approprié au sein des vecteurs bilingues par comparaison 
avec un vecteur contextuel de la phrase source. L’exploitation de ressources externes pour la 
désambigüisation lexicale pourrait être combinée à notre méthode, afin de mêler des 
connaissances encyclopédiques (thésaurus) à des connaissances textuelles (mondes lexicaux). 
4 Conclusion 
Notre travail a porté sur l’analyse de l’aspect interlingue des ULC pour l’acquisition 
automatique de traductions à partir du Web. La prise en compte des caractéristiques 
linguistiques de traduction permet d’apporter un traitement adapté à chaque cas. Nous avons 
proposé une application de l’utilisation du Web dans le cadre d’applications linguistiques, en 
proposant une méthode « mixte » de stratégies. Les ressources que nous avons collectées 
jusqu’à présent sont de bonne qualité, avec une précision de traduction très satisfaisante, à 
savoir environ 94% de traductions acceptables. Le rappel est également honorable, avec un 
taux d’environ 77%. Nous nous sommes également centrée sur l’étude du contexte des ULC 
en testant ce phénomène à vaste échelle, en collectant les mondes lexicaux directement à 
partir du Web. Ces mondes lexicaux, en français et en anglais, ont été exploités pour la 
désambigüisation lexicale pour la traduction mais pourront être exploitées pour la 
construction de ressources de type ontologiques. 
Stéphanie Léon 
Références 
BRUNET E. (2003). Peut-on mesurer la distance entre deux textes ? Corpus, La distance 
intertextuelle 2. 
CHUQUET, H., PAILLARD, M. (1987). Approche linguistique des problèmes de traduction 
anglais <-> français. Gap, Paris : Ophrys. 
DAGAN I., ITAI A., SCHWALL U. (1991). Two languages are more informative than one. 
Actes de Annual Meeting of the Association for Computational Linguistics (ACL), 130-137. 
FUNG P., MCKEOWN K. (1997). Finding terminology translations from non-parallel 
corpora. Actes de Annual Workshop on Very Large Corpora, 192-202. 
FUNG P., YEE L. Y. (1998). An IR approach for translating new words from nonparallel, 
comparable texts. Actes de International Conference on Computational Linguistics 
(COLIG), 414-420. 
LEON S., MILLON C. (2005). Acquisition semi-automatique de relations lexicales bilingues 
(français-anglais) à partir du Web. Actes de Rencontre des Etudiants Chercheurs en 
Informatique pour le Traitement Automatique des Langues (RECITAL), 595-604. 
LEON S. (2006). Acquisition automatique de traductions de termes complexes par 
comparaison de « mondes lexicaux » sur le Web. Actes de Rencontre des Etudiants 
Chercheurs en Informatique pour le Traitement Automatique des Langues (RECITAL), 700-
709. 
MORIN E., DUFOUR-KOWALSKI S., DAILLE B. (2004). Extraction de terminologies 
bilingues à partir de corpus. Actes de Traitement Automatique des Langues aturelles 
(TAL). 
NAGATA M. (2001). Using the Web as a bilingual dictionary. 39th ACL Worshop on Data-
Driven Methods in Machine Translation. 
PRINCE V., CHAUCHE, J. (2008). Building a Bilingual Representation of the Roget 
Thesaurus for French to English Machine Translation. Actes de international conference on 
Language REsources and Evaluation (LREC).. 
RAPP R. (1999). Automatic Identification of Word Translations from Unrelated English and 
German Corpora. Actes de Association for Computational Linguistics (ACL), 519-525. 
SCHÜTZE H. (1998). Automatic word sense discrimination. Computational Linguistics 
(24)1, 97-124. 
VÉRONIS J. (2000). Parallel Text Processing: Alignment and use of translation corpora. 
Dordrecht : Kluwer Academic Publishers. 
VERONIS J. (2003). Hyperlex : cartographie lexicale pour la recherche d’informations. Actes 
de Traitement Automatique des Langues aturelles (TAL), 265-274. 
YAROWSKY D. (1993). One Sense per Collocation. Actes de ARPA Human Language 
Technology Workshop, 266-271.  
