<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Nouveau paradigme d&#8217;&#233;valuation des syst&#232;mes de dialogue homme-machine</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2009, Senlis, 24&#8211;26 juin 2009
</p>
<p>Nouveau paradigme d&#8217;&#233;valuation des syst&#232;mes de dialogue
homme-machine
</p>
<p>Marianne Laurent1 Ghislain Putois1 Philippe Bretier 1 Thierry Moudenc1
</p>
<p>(1) Orange Labs, Lannion, 2 avenue Pierre Marzin, 22307 Lannion Cedex
</p>
<p>R&#233;sum&#233;. L&#8217;&#233;valuation des syst&#232;mes de dialogue homme-machine est un probl&#232;me diffi-
cile et pour lequel ni les objectifs ni les solutions propos&#233;es ne font aujourd&#8217;hui l&#8217;unanimit&#233;. Les
approches ergonomiques traditionnelles soumettent le syst&#232;me de dialogue au regard critique de
l&#8217;utilisateur et tente d&#8217;en capter l&#8217;expression, mais l&#8217;absence d&#8217;un cadre objectivable des usages
de ces utilisateurs emp&#234;che une comparaison entre syst&#232;mes diff&#233;rents, ou entre &#233;volutions d&#8217;un
m&#234;me syst&#232;me. Nous proposons d&#8217;inverser cette vision et de mesurer le comportement de l&#8217;uti-
lisateur au regard du syst&#232;me de dialogue. Aussi, au lieu d&#8217;&#233;valuer l&#8217;ad&#233;quation du syst&#232;me
&#224; ses utilisateurs, nous mesurons l&#8217;ad&#233;quation des utilisateurs au syst&#232;me. Ce changement de
paradigme permet un changement de r&#233;f&#233;rentiel qui n&#8217;est plus les usages des utilisateurs mais
le cadre du syst&#232;me. Puisque le syst&#232;me est compl&#232;tement d&#233;fini, ce paradigme permet des
approches quantitatives et donc des &#233;valuations comparatives de syst&#232;mes.
</p>
<p>Abstract. Evaluation of a human-machine dialogue system is a difficult problem for
which neither the objectives nor the proposed solutions gather a unanimous support. Traditio-
nal approaches in the ergonomics field evaluate the system by describing how it fits the user
in the user referential of practices. However, the user referential is even more complicated to
formalise, and one cannot ground a common use context to enable the comparison of two sys-
tems, even if they are merely an evolution of the same service. We propose to shift the point of
view on the evaluation problem : instead of evaluating the system in interaction with the user
in the user&#8217;s referential, we will now measure the user&#8217;s adequacy to the system in the system
referential. This is our Copernician revolution : for the evaluation purpose, our system is no
longer user-centric, because the user referential is not properly objectifiable, while the system
referential is completely known by design.
</p>
<p>Mots-cl&#233;s : &#201;valuation, Dialogue.
</p>
<p>Keywords: Evaluation, Dialogue.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Marianne Laurent, Ghislain Putois, Philippe Bretier et Thierry Moudenc
</p>
<p>1 Introduction
</p>
<p>La question de l&#8217;&#233;valuation est aujourd&#8217;hui un enjeu majeur pour la recherche en dialogue vocal.
Pour preuve, nombreuses sont les manifestations aujourd&#8217;hui d&#233;di&#233;es &#224; ce sujet (Jokinen et al.,
2007) (McTear et al., 2008). L&#8217;&#233;tude critique r&#233;alis&#233;e par (Paek, 2007; Paek, 2001) a identifi&#233;
deux perspectives diff&#233;rentes face &#224; cette probl&#233;matique. D&#8217;un c&#244;t&#233;, la recherche acad&#233;mique
s&#8217;attache &#224; identifier quelle est la meilleure d&#233;marche d&#8217;&#233;valuation pour comparer pr&#233;cis&#233;ment
des syst&#232;mes de dialogue entre eux. De l&#8217;autre, l&#8217;industrie, qui est confront&#233;e &#224; des objectifs
op&#233;rationnels de d&#233;ploiement en situation r&#233;elle (contrainte de co&#251;t et n&#233;cessit&#233; de qualit&#233;),
r&#233;fl&#233;chit &#224; des outils pour l&#8217;aider &#224; concevoir de meilleurs syst&#232;mes de dialogue vocal.
</p>
<p>De fa&#231;on g&#233;n&#233;rale, avec les outils dont elle dispose, l&#8217;industrie n&#8217;a qu&#8217;une vue partielle de la
qualit&#233; de ses services. Certes elle sait collecter une grande vari&#233;t&#233; de mesures, de mani&#232;re &#224;
la fois quantitative sur des s&#233;lections d&#8217;indicateurs, et qualitative pour estimer la satisfaction
utilisateur, mais elle bute sur la d&#233;finition de processus qui puissent r&#233;pondre de mani&#232;re fiable
&#224; ses besoins. Ce manque de m&#233;triques de qualit&#233; complique la t&#226;che des concepteurs, mais nuit
&#233;galement &#224; l&#8217;essor des syst&#232;mes de dialogue vocal par frilosit&#233; des entreprises susceptibles
de les d&#233;ployer. Aussi, en marge de la recherche d&#8217;un paradigme universel d&#8217;&#233;valuation pour
la comparaison entre syst&#232;mes, nous pr&#233;sentons ici une m&#233;thode pragmatique proposant aux
concepteurs des cl&#233;s pour &#233;valuer leur syst&#232;me face aux attentes op&#233;rationnelles.
</p>
<p>Dans les sections suivantes, nous pr&#233;sentons notre contexte industriel de d&#233;veloppement de
syst&#232;me de dialogue, puis nous introduisons une nouvelle approche au probl&#232;me de l&#8217;&#233;valuation,
et pr&#233;sentons enfin des m&#233;thodes d&#8217;&#233;valuation associ&#233;es &#224; ce changement d&#8217;approche, et qui
viennent soutenir l&#8217;industrie tout au long du cycle de vie de ses syst&#232;mes.
</p>
<p>2 D&#233;veloppement industriel d&#8217;un syst&#232;me de dialogue vocal
</p>
<p>Les syst&#232;mes de dialogue vocaux sont des objets complexes. Aussi, leur &#233;valuation, qui, selon
l&#8217;objectif, peut intervenir &#224; tout moment du cycle de d&#233;veloppement, requiert la prise en compte
de diff&#233;rents points de vue (en particulier logiciel, fonctionnel, pragmatique, sociologique). Po-
sons tout d&#8217;abord quelques d&#233;finitions associ&#233;es &#224; ces points de vue. Nous d&#233;signons par syst&#232;me
de dialogue la plateforme mat&#233;rielle et les composantes logicielles associ&#233;es : moteurs de recon-
naissance et synth&#232;se vocales, gestion des lignes t&#233;l&#233;phoniques, composants de compr&#233;hension
et de g&#233;n&#233;ration en langue naturelle, moteur de dialogue. La logique de dialogue d&#233;signe la lo-
gique suivie par le syst&#232;me de dialogue lors de ses interactions avec l&#8217;utilisateur. Elle est d&#233;di&#233;e
&#224; une t&#226;che et suit une logique m&#233;tier d&#233;finie pour l&#8217;accomplir. Enfin, l&#8217;application englobe
l&#8217;ensemble form&#233; par le syst&#232;me de dialogue et la logique de dialogue.
</p>
<p>Chez Orange, la conception industrielle d&#8217;une application de dialogue s&#8217;organise en quatre
&#233;tapes. Tout d&#8217;abord, la phase de r&#233;alisation correspond &#224; la cr&#233;ation d&#8217;une premi&#232;re version
de l&#8217;application. Puis celle-ci est ensuite progressivement am&#233;lior&#233;e par les phases d&#8217;exp&#233;ri-
mentation et pilote au travers une s&#233;ries d&#8217;it&#233;rations. Enfin la phase d&#8217;exploitation marque son
d&#233;ploiement. &#192; chaque &#233;tape on effectue une analyse des interactions men&#233;es entre l&#8217;appli-
cation et ses utilisateurs de sorte, notamment, &#224; identifier les &#233;carts entre les comportements
utilisateurs attendus et ceux observ&#233;s, tant en mati&#232;re de type de comportement (typologie de
r&#233;ponses et de questions) que d&#8217;occurrence (fr&#233;quence, d&#233;lais) ou de forme (choix lexicaux,
forme syntaxique). Cette analyse nourrit ainsi les it&#233;rations qui correspondent &#224; des retours</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Nouveau paradigme d&#8217;&#233;valuation des syst&#232;mes de dialogue homme-machine
</p>
<p>de l&#8217;application en conception durant lesquels on modifie son comportement en fonction des
exp&#233;riences observ&#233;es dans les traces de dialogue.
</p>
<p>La phase de r&#233;alisation s&#8217;articule autour des &#233;tapes de conception (r&#233;flexions, sp&#233;cifications,
mod&#233;lisation), de d&#233;veloppement et de test de l&#8217;application au sein m&#234;me de l&#8217;&#233;quipe de d&#233;ve-
loppement. Celle-ci met en place tous les aspects d&#8217;une version initiale de l&#8217;application : design,
linguistique, ergonomie et technique (notamment li&#233; &#224; l&#8217;int&#233;gration de l&#8217;application dans son en-
vironnement informatique). L&#8217;&#233;valuation &#224; cette &#233;tape repose sur des tests effectu&#233;s par l&#8217;&#233;quipe
de d&#233;veloppement et constitue une &#233;valuation du bon fonctionnement technique.
</p>
<p>Lors de la phase d&#8217;exp&#233;rimentation, l&#8217;application est test&#233;e par un nombre restreint d&#8217;utilisateurs
puis ouvert &#224; un faible flux de trafic r&#233;el. On collecte alors la mati&#232;re n&#233;cessaire &#224; l&#8217;analyse des
comportements utilisateur face &#224; l&#8217;application. Cette analyse permet d&#8217;alimenter les boucles
d&#8217;it&#233;rations qui vont se succ&#233;der pour am&#233;liorer l&#8217;application jusqu&#8217;&#224; l&#8217;atteinte d&#8217;un niveau de
performance jug&#233; satisfaisant. La collecte et l&#8217;analyse du corpus d&#8217;interaction permettent ainsi
de capturer des usages et des r&#233;actions des utilisateurs et donc d&#8217;adapter les diff&#233;rents para-
m&#232;tres du design, tels que les mod&#232;les de reconnaissance vocale, la syntaxe et la terminologie
des prompts ou la temporisation du dialogue. L&#8217;&#233;valuation &#224; cette &#233;tape vise donc l&#8217;am&#233;lioration
de l&#8217;application et notamment l&#8217;alignement des pr&#233;visions et des observations.
</p>
<p>Lors de la phase pilote, les tests sont effectu&#233;s dans les conditions r&#233;elles d&#8217;exploitation. D&#8217;abord,
le panel d&#8217;utilisateurs peut couvrir une zone g&#233;ographique (souvent r&#233;gion ou d&#233;partement), une
zone t&#233;l&#233;phonique, une zone de plateau de t&#233;l&#233;conseillers ou un panel de clients cibles, mais elle
couvre toujours une partie du flux r&#233;el. Ensuite, l&#8217;&#233;valuation est r&#233;alis&#233;e &#224; partir de l&#8217;architecture
technique compl&#232;te de l&#8217;application. Cette &#233;tape correspond donc &#224; une phase de beta-testing
o&#249; les probl&#232;mes majeurs sont d&#233;cel&#233;s et combl&#233;s avant la mise en production qui ouvre l&#8217;ap-
plication &#224; l&#8217;ensemble des usagers. L&#8217;&#233;valuation &#224; cette &#233;tape &#224; pour but de valider globalement
l&#8217;application.
</p>
<p>Enfin, la phase d&#8217;exploitation correspond &#224; la mise &#224; disposition totale de l&#8217;application avec
maintien op&#233;rationnel. L&#8217;&#233;valuation se focalise alors sur la supervision. Cette &#233;valuation permet
notamment d&#8217;analyser la fa&#231;on dont l&#8217;application est utilis&#233;e en situation r&#233;elle par les utili-
sateurs, d&#8217;analyser l&#8217;usage et les retours d&#8217;exp&#233;rience utilisateurs et leurs &#233;volutions dans le
temps.
</p>
<p>3 Changement de paradigme
</p>
<p>Comme pour tout processus d&#8217;&#233;valuation, &#233;valuer une application de dialogue n&#233;cessite un r&#233;-
f&#233;rentiel d&#8217;&#233;tude. Les tentatives traditionnelles cherchent &#224; appr&#233;hender les usages des utilisa-
teurs pour mesurer l&#8217;ad&#233;quation de l&#8217;application &#224; ces usages (Norros &amp; Savioja, 2007). Ces
m&#233;thodes d&#8217;&#233;valuation recens&#233;es par (Grislin &amp; Kolski, 1996) et (Paek, 2001) s&#8217;articulent en
deux &#233;tapes. D&#8217;abord on collecte un corpus de travail par le biais d&#8217;&#233;tudes qualitatives telles
que des tests terrains, des interviews, des questionnaires de satisfaction ou des simulations en
Magicien d&#8217;Oz (Caelen et al., 1997). Puis les ergonomes interpr&#232;tent des usages et des attentes
utilisateurs &#224; partir de ce corpus pour former le r&#233;f&#233;rentiel d&#8217;&#233;tude.
</p>
<p>Les pratiques actuelles sont focalis&#233;es sur les besoins de la recherche, &#224; savoir un outil pr&#233;cis
pour le benchmark de solutions. Par exemple, un paradigme r&#233;pandu pour l&#8217;&#233;valuation compa-
rative d&#8217;applications de dialogue homme-machine est PARADISE de (Walker et al., 1997). Il</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Marianne Laurent, Ghislain Putois, Philippe Bretier et Thierry Moudenc
</p>
<p>consiste &#224; r&#233;aliser des mesures quantitatives sur les traces d&#8217;interaction d&#8217;une application afin
d&#8217;approximer la satisfaction utilisateur par une combinatoire de m&#233;triques quantitatives. Ces
m&#233;thodes cherchent &#224; b&#226;tir leur r&#233;f&#233;rentiel d&#8217;&#233;valuation sur l&#8217;utilisateur humain, ce qui rend
la t&#226;che complexe et difficilement objectivable. La constitution de ce r&#233;f&#233;rentiel devient donc
artisanale, sp&#233;cifique &#224; une application donn&#233;e, et en cons&#233;quence, la t&#226;che doit &#234;tre r&#233;it&#233;r&#233;e
&#224; chaque nouvelle campagne d&#8217;&#233;valuation. Pour autant, &#233;tudier une application n&#233;cessite de
prendre en compte ses utilisateurs, puisque c&#8217;est en interagissant avec eux que l&#8217;application
prend tout son sens et devient objet propice &#224; l&#8217;&#233;valuation.
</p>
<p>Nous avons bien conscience qu&#8217;une &#233;valuation se fait toujours par rapport &#224; un cadre, mais nous
souhaitons ici rappeler que dans le domaine des syst&#232;mes de dialogue, chaque interaction entre
l&#8217;utilisateur et l&#8217;application pr&#233;sente le caract&#232;re unique d&#8217;une performance. Chaque nouveau
dialogue est co-construit diff&#233;remment selon les capacit&#233;s propres &#224; la fois &#224; l&#8217;application et
&#224; l&#8217;utilisateur, ce dernier sachant s&#8217;adapter tr&#232;s vite, et changer ses pratiques. Pour pouvoir
r&#233;aliser une &#233;valuation comparative entre deux applications ou entre deux &#233;volutions d&#8217;une
m&#234;me application, nous avons imp&#233;rativement besoin que ce cadre d&#8217;&#233;valuation soit stable et
applicable aux deux. Or les pratiques utilisateurs ne sont pas assez stables pour constituer ce
cadre, justement &#224; cause des grandes facult&#233;s d&#8217;adaptation humaines.
</p>
<p>Dans l&#8217;industrie, les exigences de commensurabilit&#233; au regard de l&#8217;&#233;valuation sont moins grandes.
L&#8217;industrie cherche avant tout &#224; mesurer l&#8217;ad&#233;quation d&#8217;une application face aux attentes op&#233;-
rationnelles (contraintes de co&#251;t et n&#233;cessit&#233; de qualit&#233;). En se pla&#231;ant dans cette logique indus-
trielle, il nous semble donc pertinent d&#8217;inverser notre approche sur la relation entre application
et utilisateur pour l&#8217;&#233;valuation. Au lieu de tenter de mesurer &#224; quel point l&#8217;application est proche
de l&#8217;utilisateur et de ses pratiques, envisageons plut&#244;t de d&#233;terminer dans quelle mesure l&#8217;utilisa-
teur est proche de l&#8217;application et des pratiques qu&#8217;elle propose. Le cadre d&#8217;&#233;valuation &#224; prendre
en compte est alors beaucoup plus stable, car l&#8217;application s&#8217;adapte beaucoup moins vite que
l&#8217;utilisateur, et seulement dans la mesure o&#249; on la fait &#233;voluer ou on la dote de capacit&#233;s d&#8217;ap-
prentissage (toujours assez limit&#233;es). Elle est donc enti&#232;rement ma&#238;trisable, car l&#8217;application est
con&#231;ue pour r&#233;pondre &#224; un ensemble de besoins fonctionnels.
</p>
<p>Parmi ces besoins, il y a la n&#233;cessit&#233; &#224; traiter les comportements utilisateurs (des mots aux
encha&#238;nements d&#8217;actes de langage). Le niveau technologique actuel ne permettant pas de traiter
tous les usages de la langue, le design n&#233;cessite de circonscrire les comportements &#224; consid&#233;rer,
c&#8217;est-&#224;-dire de pr&#233;dire les comportements utilisateurs. De plus, la connaissance issue des &#233;tudes
centr&#233;es utilisateur sert &#224; la pr&#233;diction des comportements utilisateurs, et in fine &#224; la d&#233;finition
des besoins fonctionnels. Ces besoins, comme dans tout processus industriel, doivent &#233;galement
pouvoir se traduire par un ensemble de m&#233;triques pour v&#233;rifier qu&#8217;ils sont adress&#233;s. De plus, ils
sont les invariants principaux qui d&#233;finissent la raison d&#8217;&#234;tre d&#8217;une application, et donc ils restent
majoritairement valables tout au long du cycle de vie de l&#8217;application, ce qui permet d&#8217;utiliser
le m&#234;me cadre d&#8217;&#233;valuation pour comparer deux &#233;volutions d&#8217;une m&#234;me application.
</p>
<p>4 Les mesures industrielles
</p>
<p>Pour refonder notre &#233;valuation, pla&#231;ons-nous maintenant dans le r&#233;f&#233;rentiel de l&#8217;application qui
a &#233;t&#233; d&#233;fini dans la section pr&#233;c&#233;dente. Dans ce nouveau r&#233;f&#233;rentiel, il est possible d&#8217;extraire des
caract&#233;ristiques r&#233;currentes de l&#8217;application et des mesures objectivables associ&#233;es, qui consti-
tueront la mati&#232;re premi&#232;re pour l&#8217;&#233;valuation quantitative des applications. Ainsi, pour &#233;valuer</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Nouveau paradigme d&#8217;&#233;valuation des syst&#232;mes de dialogue homme-machine
</p>
<p>la pertinence d&#8217;une application de dialogue, nous choisissons des indicateurs qui mesurent l&#8217;ac-
complissement de la t&#226;che et la mani&#232;re dont le dialogue est men&#233; avec l&#8217;utilisateur. Des corpus
de mesure sont ainsi constitu&#233;s &#224; partir d&#8217;une s&#233;lection d&#8217;indicateurs. Une multitude d&#8217;indi-
cateurs peuvent ainsi &#234;tre sollicit&#233;s, parmi lesquels : les performances de chaque composant
logiciel, le nombre d&#8217;appels au service, le nombre moyen de tours de dialogue pour accomplir
une t&#226;che, la dur&#233;e de chaque tour de dialogue, le nombre et l&#8217;instant des raccroch&#233;s en cours
de dialogue et les taux d&#8217;incompr&#233;hension de la reconnaissance vocale et des composants de
compr&#233;hension du langage naturel.
</p>
<p>Pour passer de la mesure &#224; l&#8217;&#233;valuation, il faut d&#233;finir un cadre d&#8217;&#233;valuation. On s&#233;lectionne
d&#8217;abord un ensemble d&#8217;indicateurs qui apparaissent a priori repr&#233;sentatifs du bon fonctionne-
ment de l&#8217;application, puis on associe des interpr&#233;tations aux ensembles de valeurs possibles de
ces indicateurs. Le cadre ainsi construit est ind&#233;pendant du syst&#232;me initial, il d&#233;finit des seuils
sur les indicateurs. Ce cadre d&#8217;&#233;valuation peut alors &#234;tre appliqu&#233; &#224; un autre syst&#232;me de dialogue
ou &#224; une version alternative de l&#8217;application.
</p>
<p>Rappelons que des processus d&#8217;&#233;valuation interviennent &#224; plusieurs endroits distincts du cycle
de vie d&#8217;une application. Ceci implique autant de red&#233;finitions d&#8217;un cadre d&#8217;&#233;valuation propre
aux m&#233;tiers concern&#233;s (design, marketing, exploitation, etc.), en fonction de leurs objectifs res-
pectifs et des moyens de mesure &#224; leur disposition. Ainsi, lors de la phase de r&#233;alisation, les
designers v&#233;rifient le comportement nominal de l&#8217;application par rapport aux pratiques qu&#8217;ils
ont pr&#233;alablement d&#233;finies dans le cahier des charges. L&#8217;application n&#8217;&#233;tant bien souvent test&#233;e
ni sur l&#8217;architecture cible, ni par des utilisateurs r&#233;els, seuls quelques indicateurs cl&#233;s sont uti-
lis&#233;s. Ensuite, on mobilise davantage d&#8217;indicateurs pour les phases d&#8217;exp&#233;rimentation et pilote
afin d&#8217;&#233;valuer l&#8217;&#233;cart entre les usages r&#233;els et les pr&#233;dictions d&#8217;usages tels qu&#8217;impl&#233;ment&#233;s dans
l&#8217;application. Enfin, en phase d&#8217;exploitation, seuls quelques indicateurs cl&#233;s sont utilis&#233;s pour
la supervision. L&#8217;application &#233;tant cens&#233;e bien fonctionner, on v&#233;rifie alors principalement que
les utilisateurs continuent d&#8217;interagir avec l&#8217;application conform&#233;ment aux possibilit&#233;s d&#8217;inter-
action.
</p>
<p>Nous voyons donc comment les processus de conception de l&#8217;application et de conception de
son &#233;valuation peuvent &#234;tre &#233;troitement entrem&#234;l&#233;s dans le cadre d&#8217;un d&#233;veloppement industriel.
Ceci est d&#8217;autant plus vrai que les sp&#233;cifications de l&#8217;application se focalisent sur des aspects
locaux de l&#8217;application. A titre d&#8217;exemple, notre application automatique de renseignement par
t&#233;l&#233;phone propose une mise en communication avec l&#8217;interlocuteur recherch&#233; moyennant une
surtaxe. Une &#233;valuation locale sur les taux de r&#233;ponses positives &#224; la derni&#232;re question de l&#8217;ap-
plication a fait opter les designers pour le prompt syst&#232;me &#171;Pour &#234;tre mis en relation, dites oui.&#187;
qui avait un meilleur score que son pr&#233;d&#233;cesseur &#171;Souhaitez-vous &#234;tre mis en relation ?&#187;.
</p>
<p>5 Conclusion
</p>
<p>Consciente des &#233;conomies que les syst&#232;mes de dialogue vocal peuvent g&#233;n&#233;rer, et de l&#8217;impact
de la satisfaction client en termes d&#8217;image, l&#8217;industrie des services cherche donc &#224; rationaliser
l&#8217;&#233;valuation de ses applications pour pouvoir ma&#238;triser leur exploitation et leurs usages.
</p>
<p>Les utilisateurs ont de fortes capacit&#233;s d&#8217;adaptation aux contraintes impos&#233;es par les applica-
tions. Nous sugg&#233;rons donc de ne pas chercher &#224; &#233;valuer les applications de dialogue unique-
ment avec des m&#233;thodes centr&#233;es utilisateur, mais au contraire d&#8217;exploiter la construction des
syst&#232;mes autour d&#8217;un ensemble d&#8217;usages pr&#233;d&#233;finis, et de chercher alors &#224; &#233;valuer si les utili-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Marianne Laurent, Ghislain Putois, Philippe Bretier et Thierry Moudenc
</p>
<p>sateurs s&#8217;accommodent des usages propos&#233;s. La conception des &#233;valuations est alors plus ais&#233;e
pour chaque phase de d&#233;cision du cycle de vie d&#8217;un syst&#232;me, puisqu&#8217;elle se r&#233;f&#232;re directement
&#224; des objectifs d&#233;finis dans le cahier des charges, eux-m&#234;mes quantifiables par des indicateurs
de performance du syst&#232;me &#233;valu&#233;.
</p>
<p>La m&#233;thode propos&#233;e r&#233;pond donc &#224; un besoin industriel. Elle repose sur des optimisations
locales dans le but de r&#233;duire l&#8217;&#233;cart entre les interactions observ&#233;es entre l&#8217;application et ses
utilisateurs et celles attendues. Ainsi, si elle int&#232;gre la notion de progr&#232;s dans la comparaison
de plusieurs versions d&#8217;une m&#234;me application, elle n&#8217;adresse cependant pas la question de re-
cherche d&#8217;un optimum global de qualit&#233;, notion que nous ne savons pas d&#233;finir aujourd&#8217;hui.
</p>
<p>Remerciements
</p>
<p>Nous souhaitons remercier les &#233;quipes Dialogue et Synth&#232;se Vocale, les &#233;quipes multidiscipli-
naires et op&#233;rationnelles d&#8217;Orange pour leur contribution &#224; ces r&#233;flexions.
</p>
<p>R&#233;f&#233;rences
</p>
<p>CAELEN J., ZEILIGER J., BESSAC M., SIROUX J. &amp; P&#201;RENNOU G. (1997). Les corpus
pour l&#8217;&#233;valuation du dialogue homme-machine. In Actes des 1&#232;res JST FRANCIL 1997,
Journ&#233;es Scientifiques et Techniques du R&#233;seau Francophone de l&#8217;Ing&#233;nierie de la Langue
de l&#8217;AUPELF-URE, Avignon, 15/04/97-16/04/97, p. 215&#8211;222 : -.
GRISLIN M. &amp; KOLSKI C. (1996). Evaluation des interfaces homme-machine lors du d&#233;-
veloppement des syst&#232;mes interactifs = human-machine interface evaluation during the de-
velopment of interactives systems. TSI. Technique et science informatiques ISSN 0752-4072
CODEN TTSIDJ, 15(3), 265&#8211;296.
JOKINEN K., MCTEAR M. &amp; LARSON J. (2007). Dialogue on dialogues &#8211; multidisciplinary
evaluation of advanced speech-based interactive systems : A report on the interspeech 2006
satellite event. AI Magazine, 28(2).
MCTEAR M., JOKINEN K. &amp; LARSON J. (2008). Special issue on evaluating new methods
and models for advanced speech-based interactive systems. Speech Communication, 50(8-9).
NORROS L. &amp; SAVIOJA P. (2007). Vers une th&#233;orie et une m&#233;thode d&#8217;&#233;valuation de l&#8217;utilisa-
bilit&#233; des syst&#232;mes complexes homme-technologie. @ctivit&#233;s, 4(2).
PAEK T. (2001). Empirical methods for evaluating dialog systems. In Proceedings of the
workshop on Evaluation for Language and Dialogue Systems, p. 1&#8211;8, Morristown, NJ, USA :
Association for Computational Linguistics.
PAEK T. (2007). Toward evaluation that leads to best practices : Reconciling dialog evaluation
in research and industry. In Proceedings of the Workshop on Bridging the Gap : Academic
and Industrial Research in Dialog Technologies, p. 40&#8211;47, Rochester, NY : Association for
Computational Linguistics.
WALKER M. A., LITMAN D. J., KAMM C. A. &amp; ABELLA A. (1997). Paradise : a framework
for evaluating spoken dialogue agents. In Proceedings of the eighth conference on European
chapter of the Association for Computational Linguistics, p. 271&#8211;280, Morristown, NJ, USA :
Association for Computational Linguistics.</p>

</div></div>
</body></html>