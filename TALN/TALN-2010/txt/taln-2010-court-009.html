<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Une approche paresseuse de l&#8217;analyse s&#233;mantique ou comment construire une interface syntaxe-s&#233;mantique &#224; partir d&#8217;exemples</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>UNE APPROCHE PARESSEUSE DE L&#8217;ANALYSE S&#201;MANTIQUE 
</p>
<p>Une approche paresseuse de l&#8217;analyse s&#233;mantique ou comment construire 
une interface syntaxe-s&#233;mantique &#224; partir d&#8217;exemples 
</p>
<p>Fran&#231;ois-R&#233;gis Chaumartin
1,2
</p>
<p>   Sylvain Kahane
3,2
</p>
<p> 
</p>
<p>(1)  Proxem, 7 impasse Dumur, 92110 Clichy 
(2) Alpage, Universit&#233; Paris 7 &amp; INRIA 
</p>
<p>(3) Modyco, Universit&#233; Paris Ouest Nanterre &amp; CNRS 
</p>
<p>frc@proxem.com, sylvain@kahane.fr 
</p>
<p>R&#233;sum&#233; Cet article montre comment calculer une interface syntaxe-s&#233;mantique &#224; partir d&#8217;un analyseur 
en d&#233;pendance quelconque et interchangeable, de ressources lexicales vari&#233;es et d&#8217;une base d&#8217;exemples 
associ&#233;s &#224; leur repr&#233;sentation s&#233;mantique. Chaque exemple permet de construire une r&#232;gle d&#8217;interface. Nos 
repr&#233;sentations s&#233;mantiques sont des graphes hi&#233;rarchis&#233;s de relations pr&#233;dicat-argument entre des 
</p>
<p>acceptions lexicales et notre interface syntaxe-s&#233;mantique est une grammaire de correspondance polaris&#233;e. 
</p>
<p>Nous montrons comment obtenir un syst&#232;me tr&#232;s modulaire en calculant certaines r&#232;gles par 
</p>
<p>&#171; soustraction &#187; de r&#232;gles moins modulaires. 
</p>
<p>Abstract This article shows how to extract a syntax-semantics interface starting from an 
interchangeable dependency parser, various lexical resources and from samples associated with their 
</p>
<p>semantic representations. Each example allows us to build an interface rule. Our semantic representations 
</p>
<p>are hierarchical graphs of predicate-argument relations between lexical meanings and our syntax-
</p>
<p>semantics interface is a polarized unification grammar. We show how to obtain a very modular system by 
</p>
<p>computing some rules by &#8220;subtraction&#8221; of less modular rules. 
</p>
<p>Mots-cl&#233;s :   Interface syntaxe-s&#233;mantique, graphe s&#233;mantique, grammaires de d&#233;pendance, GUP 
(Grammaire d&#8217;unification polaris&#233;e), GUST (Grammaire d&#8217;unification Sens-Texte) 
</p>
<p>Keywords:   Syntax-semantics Interface, Semantic Graph, Dependency Grammar, PUG (Polarized 
Unification Grammar), MTUG (Meaning-Text Unification Grammar) 
</p>
<p>Introduction 
</p>
<p>Une interface syntaxe-s&#233;mantique est un module qui prend en entr&#233;e les sorties d&#8217;un analyseur syntaxique 
et produit des repr&#233;sentations s&#233;mantiques correspondantes qui sont des graphes de relations pr&#233;dicat-
</p>
<p>argument entre des acceptions lexicales. Le d&#233;veloppement manuel d&#8217;un tel module peut &#234;tre co&#251;teux et il 
est p&#233;rilleux de construire une interface syntaxe-s&#233;mantique qui s&#8217;appuie sur les sorties d&#8217;un analyseur 
syntaxique particulier qui peut rapidement devenir obsol&#232;te. Notre objectif est donc de pouvoir extraire 
</p>
<p>une interface-s&#233;mantique automatiquement pour n&#8217;importe quel analyseur syntaxique. Notre id&#233;e est de 
partir d&#8217;une base de phrases d&#8217;exemples associ&#233;es &#224; leur repr&#233;sentation s&#233;mantique, de traiter ces exemples 
avec l&#8217;analyseur de notre choix et de calculer ainsi une grammaire permettant de faire la correspondance </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FRAN&#199;OIS-R&#201;GIS CHAUMARTIN, SYLVAIN KAHANE 
</p>
<p>entre les arbres de d&#233;pendance en sortie de l&#8217;analyseur et des graphes s&#233;mantiques. Contrairement aux 
strat&#233;gies d&#8217;extraction de grammaires sur corpus annot&#233;s par des m&#233;thodes statistiques, nous calculons une 
grammaire formelle purement alg&#233;brique. Chaque exemple de notre base est con&#231;u pour obtenir une r&#232;gle 
</p>
<p>et peut &#234;tre vu comme une demi-r&#232;gle contenant la partie s&#233;mantique et dont la partie syntaxique est 
</p>
<p>calcul&#233;e par l&#8217;analyseur syntaxique. 
</p>
<p>Notre repr&#233;sentation s&#233;mantique est un graphe de relations pr&#233;dicat-argument entre les signifi&#233;s des unit&#233;s 
</p>
<p>lexicales et grammaticales d&#8217;une phrase (o&#249; chaque unit&#233; lexicale a &#233;t&#233; d&#233;sambigu&#239;s&#233;e par rapport &#224; un 
lexique de r&#233;f&#233;rence). Elle est directement inspir&#233;e des repr&#233;sentations s&#233;mantique et syntaxique profonde 
</p>
<p>de la Th&#233;orie Sens-Texte (Mel&#8217;&#269;uk 1988a ; Candito &amp; Kahane 1998 ; Kahane 2002). Il s&#8217;agit d&#8217;une 
repr&#233;sentation s&#233;mantique du contenu linguistique et pas d&#8217;une s&#233;mantique d&#233;notationnelle comme les 
repr&#233;sentations s&#233;mantiques bas&#233;es sur la logique. Il n&#8217;y a donc pas &#224; proprement parler de calcul de 
valeurs de v&#233;rit&#233; associ&#233;es ; par contre, ce type de repr&#233;sentation permet des calculs de paraphrases 
</p>
<p>(Mel&#8217;&#269;uk 1988b ; Mili&#263;evi&#263; 2007) et a &#233;t&#233; impl&#233;ment&#233; avec succ&#232;s pour la g&#233;n&#233;ration de textes 
(Iordanskaja et al. 1988 ; Bohnet &amp; Wanner 2001) ou la traduction automatique (Apresjan et al. 2003). 
</p>
<p>Des repr&#233;sentations similaires ont &#233;t&#233; propos&#233;es par d&#8217;autres auteurs sans r&#233;f&#233;rence explicite &#224; la Th&#233;orie 
Sens-Texte. Voir par exemple (Copestake 2009) ou (B&#233;daride &amp; Gardent 2009). 
</p>
<p>Nous commencerons par pr&#233;senter le formalisme utilis&#233; pour l&#8217;&#233;criture d&#8217;une interface syntaxe-s&#233;mantique 
(section 1), puis les principes g&#233;n&#233;raux du calcul de r&#232;gles grammaticales ne n&#233;cessitant pas de 
</p>
<p>connaissances lexicales (section 2). L&#8217;exploitation de ressources lexicales pour la production de nouvelles 
r&#232;gles sera esquiss&#233;e (section 3). Nous terminerons en montrant comment r&#233;aliser l&#8217;articulation lexique-
grammaire par la &#171; soustraction &#187; de r&#232;gles lexicales &#224; nos r&#232;gles grammaticales (section 4). Cet article 
</p>
<p>porte essentiellement sur les questions th&#233;oriques li&#233;es au calcul de l&#8217;interface syntaxe-s&#233;mantique. Une 
impl&#233;mentation non encore &#233;valu&#233;e est en cours. 
</p>
<p>1. &#201;crire une interface syntaxe-s&#233;mantique 
</p>
<p>Pour &#233;crire notre interface syntaxe-s&#233;mantique, nous utilisons un formalisme g&#233;n&#233;rique, la Grammaire 
</p>
<p>d&#8217;Unification Polaris&#233;e (GUP) (Kahane, 2004). Ce formalisme permet d&#8217;&#233;crire des grammaires de 
correspondances entre graphes et a d&#233;j&#224; &#233;t&#233; propos&#233; pour l&#8217;interface syntaxe-s&#233;mantique (Kahane &amp; 
Lareau, 2005). Ce formalisme permet, &#224; l&#8217;image de TAG, de combiner des structures &#233;l&#233;mentaires afin 
d&#8217;obtenir une structure compl&#232;te. Les structures que nous souhaitons obtenir sont des couples form&#233;s d&#8217;un 
arbre de d&#233;pendance syntaxique et d&#8217;un graphe s&#233;mantique ; nos structures &#233;l&#233;mentaires sont donc des 
fragments d&#8217;arbre syntaxique associ&#233;s &#224; des fragments de graphe s&#233;mantique. La particularit&#233; de ce 
formalisme est un contr&#244;le rigoureux de ce que chaque r&#232;gle consomme, &#224; l&#8217;aide de polarit&#233;s associ&#233;es aux 
objets manipul&#233;s par les r&#232;gles. Le jeu de polarit&#233;s le plus simple est constitu&#233; de deux polarit&#233;s, que nous 
</p>
<p>appelons noir (&#9632;) et blanc (&#9633;). Chaque objet de la structure re&#231;oit une polarit&#233;. Sont consid&#233;r&#233;s comme des 
objets les n&#339;uds (identifi&#233;s avec l&#8217;&#233;l&#233;ment lexical qu&#8217;ils portent), les d&#233;pendances et les &#233;l&#233;ments 
flexionnels ayant une contribution s&#233;mantique (temps verbal, nombre nominal, etc.). Les r&#232;gles sont 
</p>
<p>combin&#233;es par identification des objets dont les &#233;tiquettes peuvent s&#8217;unifier et les polarit&#233;s se combiner. 
</p>
<p>La Figure 1 pr&#233;sente un exemple d&#8217;interface syntaxe-s&#233;mantique en GUP. En haut &#224; gauche se trouve la 
phrase Mary seems to sleep avec l&#8217;analyse syntaxique en d&#233;pendance qu&#8217;en propose le Stanford Parser. 
Les d&#233;pendances syntaxiques sont orient&#233;es vers la gauche (&lt;nsubj) ou vers la droite (xcomp&gt;). Nous 
</p>
<p>ajoutons des polarit&#233;s blanches sur les d&#233;pendances (&#9633;) et les mots (&#9633;) indiquant que ces objets doivent &#234;tre 
</p>
<p>consomm&#233;s par des r&#232;gles d&#8217;interface. Pour les verbes, une deuxi&#232;me polarit&#233; blanche (&#9675;) indique que la 
flexion verbale doit aussi &#234;tre consomm&#233;e. En haut &#224; droite se trouve le r&#233;sultat attendu, c&#8217;est-&#224;-dire un 
graphe s&#233;mantique associ&#233; &#224; la phrase et polaris&#233; en noir puisque produit par l&#8217;interface. Pour assurer cette 
correspondance, nous utilisons les trois r&#232;gles qui figurent en dessous.
</p>
<p> 
Ce sont des r&#232;gles lexicales </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UNE APPROCHE PARESSEUSE DE L&#8217;ANALYSE S&#201;MANTIQUE 
associ&#233;es aux lemmes SEEM, SLEEP et MARY. Comme on peut le voir la r&#232;gle associ&#233;e &#224; SEEM 
</p>
<p>consomme la totalit&#233; des d&#233;pendances syntaxiques, mais ne produit qu&#8217;une d&#233;pendance s&#233;mantique. La 
deuxi&#232;me d&#233;pendance s&#233;mantique est produite par la r&#232;gle de SLEEP. Mais pour que cette r&#232;gle puisse 
</p>
<p>s&#8217;appliquer il est n&#233;cessaire que la r&#232;gle de SEEM restitue une d&#233;pendance syntaxique. Notons pour 
terminer que la r&#232;gle de SEEM impose &#224; son xcomp&gt; d&#8217;&#234;tre un verbe infinitif (Vinf) et consomme ainsi sa 
</p>
<p>polarit&#233; flexionnelle (&#9679;). 
</p>
<p> 
</p>
<p>Figure 1. Un exemple d&#8217;interface syntaxe-s&#233;mantique en GUP 
</p>
<p>2. Calcul d&#8217;une r&#232;gle grammaticale d&#8217;interface syntaxe-s&#233;mantique 
</p>
<p>Nous allons calculer la r&#232;gle pour l&#8217;aspect progressif. Celui-ci est exprim&#233; par BE + Ving et nous voulons 
r&#233;cup&#233;rer au niveau s&#233;mantique un attribut [aspect= progressive] sur le verbe. Pour apprendre la r&#232;gle, 
</p>
<p>nous construirons un exemple de phrase avec un progressif (en l&#8217;occurrence Mary is sleeping) en indiquant 
</p>
<p>que pour is le lemme seul sera consomm&#233; (&#9632;&#9675;) et que pour sleeping la flexion seule sera consomm&#233;e (&#9633;&#9679;) 
</p>
<p>(voir Figure 3). Autrement dit, nous connaissons d&#233;j&#224; la r&#232;gle et nous pourrions l&#8217;&#233;crire &#224; la main. Notre 
objectif est de l&#8217;adapter automatiquement et sans effort aux sorties de n&#8217;importe quel analyseur, d&#8217;autant 
que les analyseurs varient non seulement dans les &#233;tiquettes qu&#8217;ils utilisent, mais aussi dans les structures 
qu&#8217;ils manipulent. Dans le cas du progressif, nous ne savons pas si le sujet sera reli&#233; &#224; l&#8217;auxiliaire ou au 
verbe lexical. Nos deux analyseurs de r&#233;f&#233;rence, le Stanford Parser et le Link Grammar, font des choix 
</p>
<p>diff&#233;rents. C&#8217;est pourquoi nous int&#233;grons le sujet dans la r&#232;gle et consid&#233;rons donc une relation s&#233;mantique 
&lt;arg1 correspondante. Nous verrons dans la section 4 comment &#171; retirer &#187; cette information.  
</p>
<p> 
</p>
<p>Figure 3. Calcul de la r&#232;gle du progressif : exemple de d&#233;part (&#224; gauche) et r&#232;gles obtenues  
</p>
<p>pour le Stanford Parser (au centre) et pour Link Grammar Parser (&#224; droite) 
</p>
<p>3. Des r&#232;gles lexicales pour l&#8217;interface syntaxe-s&#233;mantique 
</p>
<p>L&#8217;utilisation d&#8217;un lexique &#233;lectronique permet le calcul automatique de r&#232;gles. Par exemple, une ressource 
telle que VerbNet (pour l&#8217;anglais) ou Dicovalence (pour le fran&#231;ais), d&#233;crivant des cadres de sous-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FRAN&#199;OIS-R&#201;GIS CHAUMARTIN, SYLVAIN KAHANE 
</p>
<p>cat&#233;gorisation, peut &#234;tre mise &#224; profit. L&#8217;id&#233;e est alors d&#8217;analyser les exemples fournis pour en d&#233;duire les 
r&#232;gles. Par exemple, le cadre give-13.1 de VerbNet est d&#233;crit de la fa&#231;on suivante : 
</p>
<p>&lt;DESCRIPTION descriptionNumber=&quot;0.2&quot; primary=&quot;NP V NP PP.recipient&quot;/&gt;  
</p>
<p>&lt;EXAMPLES&gt;&lt;EXAMPLE&gt;They lent a bicycle to me.&lt;/EXAMPLE&gt;&lt;/EXAMPLES&gt; 
</p>
<p>&lt;SYNTAX&gt;&lt;NP value=&quot;Agent&quot; /&gt; &lt;VERB /&gt; &lt;NP value=&quot;Theme&quot; /&gt; &lt;PREP value=&quot;to&quot; /&gt; 
</p>
<p>&lt;NP value=&quot;Recipient&quot; /&gt;&lt;/SYNTAX&gt; 
</p>
<p>Cette description peut &#234;tre utilis&#233;e pour cr&#233;er automatiquement la r&#232;gle lexicale de la Figure 4, avec le 
</p>
<p>processus d&#233;crit dans (Chaumartin, 2005). Premi&#232;re &#233;tape : &#224; partir de l&#8217;exemple donn&#233; par VerbNet et sa 
description dans VerbNet la demi-r&#232;gle s&#233;mantique est construite. Deuxi&#232;me &#233;tape : l&#8217;exemple est analys&#233; 
par l&#8217;analyseur de notre choix (ici le Stanford Parser), ce qui nous fournit une r&#232;gle lexicale pour 
l&#8217;interface avec les r&#233;sultats de cet analyseur. 
</p>
<p>   
</p>
<p>Figure 4. Extraction d&#8217;une r&#232;gle lexicale &#224; partir du cadre give-13.1 de VerbNet : 
exemple de d&#233;part construit &#224; partir de VerbNet &#224; gauche, r&#232;gle obtenue pour le Stanford Parser &#224; droite 
</p>
<p>Cette r&#232;gle est par ailleurs utile pour lever des ambigu&#239;t&#233;s lexicales et syntaxiques : en effet, d&#8217;une part, la 
recherche de la r&#232;gle la plus couvrante dans la for&#234;t d&#8217;analyses syntaxiques produite pour une phrase 
donn&#233;e permet d&#8217;augmenter le score des analyses o&#249; la r&#232;gle est applicable ; d&#8217;autre part, VerbNet pr&#233;cise 
les sens du verbe compatibles avec le cadre de sous-cat&#233;gorisation, et impose &#233;ventuellement des 
</p>
<p>contraintes de s&#233;lection sur ses arguments. 
</p>
<p>4. Articulation lexique-grammaire et soustraction de r&#232;gles 
</p>
<p>Consid&#233;rons une phrase telle que They were lending me a bicycle. Nous pouvons y appliquer la r&#232;gle 
</p>
<p>grammaticale du progressif (calcul&#233;e en Section 2). Mais cette r&#232;gle consomme le lien sujet et nous ne 
</p>
<p>pourrons pas ensuite appliquer la r&#232;gle lexicale du verbe LEND que nous avons cr&#233;&#233;e &#224; partir de VerbNet 
</p>
<p>(Section 3). La solution habituelle &#224; ce probl&#232;me est celle adopt&#233;e par exemple par les grammaires TAG 
</p>
<p>consistant &#224; produire &#224; partir de la diath&#232;se de base toutes les r&#233;alisations possibles (Candito 1999) ou 
</p>
<p>(B&#233;daride &amp; Gardent, 2009) dans un formalisme similaire au notre. Il en r&#233;sulte un lexique-grammaire 
</p>
<p>assez volumineux en raison de la croissance rapide du nombre de r&#232;gles en fonction du nombre de 
</p>
<p>ph&#233;nom&#232;nes pris en compte (le lexique inclut en fait la grammaire). Plut&#244;t que d&#8217;additionner divers 
ph&#233;nom&#232;nes au sein d&#8217;une m&#234;me r&#232;gle, nous proposons au contraire de soustraire aux r&#232;gles 
grammaticales la partie lexicale pour permettre &#224; la r&#232;gle lexicale de se combiner avec les r&#232;gles 
</p>
<p>grammaticales. Dans le cas du progressif, r&#233;alis&#233; par une construction avec un auxiliaire BE + Ving nous 
</p>
<p>nous ramenons au cas d&#8217;une forme verbale simple. Pour ramener la construction A au cas d&#8217;une 
construction B, nous proposons simplement de calculer comme pr&#233;c&#233;demment des r&#232;gles pour A et B, puis 
</p>
<p>de soustraire la r&#232;gle de B &#224; celle de A. La soustraction est contr&#244;l&#233;e par les polarit&#233;s selon le calcul 
</p>
<p>suivant : 
</p>
<p>&#9632;   -  &#9632; =  suppression (autrement dit, tout objet manipul&#233; dans A et B est supprim&#233;) 
</p>
<p>(&#9633; -) &#9632; = &#9633; (un objet uniquement manipul&#233; dans B doit &#234;tre absolument introduit dans la r&#232;gle A&#8211;B 
pour &#234;tre consomm&#233; ensuite par l&#8217;application de B) </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UNE APPROCHE PARESSEUSE DE L&#8217;ANALYSE S&#201;MANTIQUE 
</p>
<p> 
</p>
<p>Figure 6. Calcul de la r&#232;gle pour le progressif 
</p>
<p>Dans la Figure 6, la premi&#232;re ligne montre les r&#232;gles obtenues pour le Link Grammar et la deuxi&#232;me 
</p>
<p>montre celles obtenues pour le Stanford Parser. Rappelons que la base d&#8217;exemple contient uniquement la 
partie inf&#233;rieure des r&#232;gles (le graphe s&#233;mantique) pour les deux exemples, A = Mary is sleeping and B = 
</p>
<p>Mary sleeps). La partie sup&#233;rieure est calcul&#233;e par l&#8217;analyseur, puis la r&#232;gle B est soustraite de A. Dans le 
cas du Ling Grammar, le lien &lt;&#9632;S de B ne correspond pas au lien &lt;&#9632;S de A (ils n&#8217;ont pas le m&#234;me 
gouverneur) et donne donc un lien &lt;&#9633;S dans A&#8211;B. Dans le cas du Standford Parser, les liens &lt;&#9632;nsubj de A 
et B se correspondent et s&#8217;annulent donc l&#8217;un l&#8217;autre. Notons que le lien &lt;&#9632;S dans la r&#232;gle du progressif 
obtenue avec le Ling Grammar n&#8217;est pas un probl&#232;me m&#234;me pour l&#8217;analyse d&#8217;une phrase comme Mary 
seems to be sleeping : l&#8217;application de la r&#232;gle pour SEEM (Figure 1) permettra de se ramener &#224; une 
structure similaire &#224; celle de la phrase Mary is sleeping, o&#249; la r&#232;gle du progressif pourra s&#8217;appliquer.  
</p>
<p>Terminons en pr&#233;sentant la r&#232;gle pour le passif. Comme pr&#233;c&#233;demment, le principe consiste &#224; se ramener &#224; 
</p>
<p>une forme plus simple, c&#8217;est-&#224;-dire, dans ce cas, l&#8217;actif. La polarisation des n&#339;uds est donn&#233;e dans la base 
d&#8217;exemples (les parties inf&#233;rieures qui s&#8217;annulent, puisque le passif n&#8217;a pas de contribution s&#233;mantique, ne 
sont pas montr&#233;es), la partie sup&#233;rieure est calcul&#233;e par l&#8217;analyseur (ici le Link Grammar), puis la r&#232;gle 
d&#233;finitive est obtenue par soustraction. 
</p>
<p>  -   =   
Figure 7. Calcul de la r&#232;gle pour le passif 
</p>
<p>Conclusion 
</p>
<p>L&#8217;id&#233;e de d&#233;velopper une interface syntaxe-s&#233;mantique entre arbre de d&#233;pendance et graphe de relation 
pr&#233;dicat-argument est ancienne et remonte au d&#233;but de la Th&#233;orie Sens-Texte dans les ann&#233;es 60 (Mel&#8217;&#269;uk 
1988, Kahane 2002). L&#8217;originalit&#233; du pr&#233;sent travail est de proposer une strat&#233;gie simple pour construire 
une telle interface &#224; partir de ressources existantes, analyseurs syntaxiques et lexiques s&#233;mantiques. D&#8217;une 
part, notre grammaire s&#8217;adapte automatiquement aux sorties de n&#8217;importe quel analyseur syntaxique en 
d&#233;pendance. D&#8217;autre part, notre grammaire est tr&#232;s modulaire avec une seule r&#232;gle pour chaque r&#233;gime 
d&#8217;une unit&#233; lexicale et des r&#232;gles grammaticales s&#233;par&#233;es pour les diff&#233;rentes constructions et 
redistributions dont cette unit&#233; lexicale peut faire l&#8217;objet. Nous pensons que cette approche est 
pragmatique dans la mesure o&#249; elle met en &#339;uvre des ressources de large couverture dans leur &#233;tat actuel. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FRAN&#199;OIS-R&#201;GIS CHAUMARTIN, SYLVAIN KAHANE 
</p>
<p>Les avantages escompt&#233;s de cette approche sont une grande modularit&#233; et une facilit&#233; de maintenance de 
</p>
<p>l&#8217;interface syntaxe-s&#233;mantique obtenue, l&#8217;ind&#233;pendance vis-&#224;-vis de tout analyseur syntaxique particulier, 
et une facilit&#233; de prise en compte de nouvelles ressources. Notons que notre grammaire est compl&#232;tement 
</p>
<p>r&#233;versible et peut servir aussi bien pour l&#8217;analyse que pour la g&#233;n&#233;ration de texte. La mise en &#339;uvre d&#8217;une 
telle grammaire pose &#233;videmment des difficult&#233;s qui ne sont pas abord&#233;es ici. Notons simplement que le 
</p>
<p>formalisme a d&#233;j&#224; fait l&#8217;objet d&#8217;une impl&#233;mentation (Lison, 2006) ; nous en d&#233;veloppons actuellement une 
nouvelle impl&#233;mentation, en utilisant l&#8217;outil de r&#233;&#233;criture de graphes GrGen et diff&#233;rentes heuristiques afin 
d&#8217;&#233;viter toute explosion combinatoire. 
</p>
<p>R&#233;f&#233;rences 
</p>
<p>APRESJAN J. ET AL. (2003). ETAP-3 Linguistic Processor: a Full-Fledged NLP Implementation of the MTT. Actes 
</p>
<p>de MTT, Paris, 279-288. 
</p>
<p>BEDARIDE P., GARDENT C. (2009). Semantic Normalisation: a Framework and an Experiment. Actes d&#8217;IWCS&#8217;09: 
8th International Conference on Computational Semantics, Tilburg, Netherland. 
</p>
<p>BOHNET B., WANNER L. (2001). On using a parallel graph rewriting formalism in generation. Actes du Workshop 
</p>
<p>on Natural Language Generation, ACL 2001, Toulouse. 
</p>
<p>CANDITO M.-H., KAHANE S. (1998). Can the derivation tree represent a semantic graph? An answer in the light of 
</p>
<p>Meaning-Text Theory&#8221;. Actes de TAG+4, Philadelphie, 21-24. 
</p>
<p>CANDITO, M.-H. (1999). Organisation modulaire et param&#233;trable de grammaires &#233;lectroniques lexicalis&#233;es. 
</p>
<p>Application au fran&#231;ais et &#224; l'italien. Th&#232;se de doctorat, Universit&#233; Paris 7. 
</p>
<p>CHAUMARTIN F.-R. (2005). Conception et r&#233;alisation d&#8217;une interface syntaxe / s&#233;mantique utilisant des ressources 
de large couverture en langue anglaise. Actes de RECITAL 2007. 
</p>
<p>CHAUMARTIN F.-R. (2008). ANTELOPE, une plateforme industrielle de traitement linguistique. TAL 49.2.  
</p>
<p>COPESTAKE A. (2009). Slacker semantics : Why superficiality, dependency and avoidance of commitment can be the 
right way to go. Actes d&#8217;EACL 2009, Invited Talk, 1&#8211;9, Ath&#232;nes. 
</p>
<p>IORDANSKAJA L., KITTREDGE R., POLGU&#200;RE A. (1988). Implementing a Meaning-Text Model for Language 
</p>
<p>Generation. Actes de COLING 1998. 
</p>
<p>KAHANE S. (2002). Grammaire d&#8217;Unification Sens-Texte : Vers un mod&#232;le math&#233;matique articul&#233; de la langue 
naturelle, Document de synth&#232;se de l&#8217;Habilitation &#224; diriger des recherches, Universit&#233; Paris 7. 
</p>
<p>KAHANE S. (2004). Grammaires d&#8217;unification polaris&#233;es. Actes de TALN 2004, F&#232;z. 
</p>
<p>KAHANE S., LAREAU F. (2005). Meaning-Text Unification Grammar: modularity and polarization. Actes de MTT 
</p>
<p>2005, Moscou. 
</p>
<p>LISON P. (2006). Impl&#233;mentation d&#8217;une interface s&#233;mantique-syntaxe bas&#233;e sur des grammaires d&#8217;unification 
polaris&#233;es. Master&#8217;s thesis, Universit&#233; Catholique de Louvain, Louvain-la-Neuve, Belgium. 
</p>
<p>MEL&#8217;CUK I. (1988a). Dependency Syntax: Theory and Practice, SUNY Press, Albany. 
</p>
<p>MEL&#8217;&#268;UK I. (1988b). Paraphrase et lexique dans la th&#233;orie linguistique Sens-Texte : vingt ans apr&#232;s, Revue 
internationale de lexicologie et lexicographie, Vol. 52/53, pp. 5-50/5-53. 
</p>
<p>MILI&#262;EVI&#262; J. (2007). La paraphrase - Mod&#233;lisation de la paraphrase langagi&#232;re. Bern : Peter Lang. 
</p>
<p>Ressources cit&#233;es 
</p>
<p>Dicouebe (MEL&#8217;&#268;UK, POLGU&#200;RE) : http://olst.ling.umontreal.ca/dicouebe/ 
</p>
<p>Dicovalence (MERTENS, VAN DEN EYNDE) : http://bach.arts.kuleuven.be/dicovalence/ 
</p>
<p>GrGen : http://www.info.uni-karlsruhe.de/software/grgen/ 
</p>
<p>Link Grammar (SLEATOR, TEMPERLEY, LAFFERTY) : http://www.link.cs.cmu.edu/link/:  
</p>
<p>Stanford Parser (MANNING, KLEIN) : http://nlp.stanford.edu/software/lex-parser.shtml 
</p>
<p>VerbNet (KIPPER, SCHULER) : http://verbs.colorado.edu/~mpalmer/projects/verbnet.html </p>

</div></div>
</body></html>