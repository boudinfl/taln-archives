UNE APPROCHE PARESSEUSE DE L’ANALYSE SEMANTIQUE

Une approehe paresseuse de l’analyse sémantique ou comment construire
une interface syntaxe-sémantique a partir d’exemples

Francois-Régis Chaumartin1’2 Sylvain Kahane3’2

(1) Proxem, 7 impasse Dumur, 92110 Clichy
(2) Alpage, Université Paris 7 & INRIA
(3) Modyco, Université Paris Ouest Nanterre & CNRS
frc@proxem.com, sy1Vain@kahane.fr

Résumé Cet article montre comment calculer une interface syntaxe-sémantique a partir d’un analyseur
en dépendance quelconque et interchangeable, de ressources lexicales Variées et d’une base d’exemples
associés a leur représentation sémantique. Chaque exemple perrnet de construire une regle d’interface. Nos
représentations sémantiques sont des graphes hiérarchisés de relations prédicat-argument entre des
acceptions lexicales et notre interface syntaxe-sémantique est une grammaire de correspondance polarisée.
Nous montrons comment obtenir un systeme tres modulaire en calculant certaines regles par
<< soustraction >> de regles moins modulaires.

Abstract This article shows how to extract a syntax-semantics interface starting from an
interchangeable dependency parser, Various lexical resources and from samples associated with their
semantic representations. Each example allows us to build an interface rule. Our semantic representations
are hierarchical graphs of predicate-argument relations between lexical meanings and our syntax-
semantics interface is a polarized unification grammar. We show how to obtain a Very modular system by
computing some rules by “subtraction” of less modular rules.

Mots-elés 2 Interface syntaxe-sémantique, graphe sémantique, grammaires de dépendance, GUP
(Grammaire d’unification polarisée), GUST (Grammaire d’unification Sens-Texte)

Keywords: Syntax-semantics Interface, Semantic Graph, Dependency Grammar, PUG (Polarized
Unification Grammar), MTUG (Meaning-Text Unification Grammar)

Introduction

Une interface syntaxe-sémantique est un module qui prend en entrée les sorties d’un analyseur syntaxique
et produit des représentations sémantiques correspondantes qui sont des graphes de relations prédicat-
argument entre des acceptions lexicales. Le développement manuel d’un tel module peut étre coﬁteux et il
est périlleux de construire une interface syntaxe-sémantique qui s’appuie sur les sorties d’un analyseur
syntaxique particulier qui peut rapidement devenir obsolete. Notre obj ectif est donc de pouvoir extraire
une interface-sémantique automatiquement pour n’importe quel analyseur syntaxique. Notre idée est de
partir d’une base de phrases d’exemples associées a leur représentation sémantique, de traiter ces exemples
avec l’analyseur de notre choix et de calculer ainsi une grammaire perrnettant de faire la correspondance

FRANCOIS-REGIS CHAUMARTIN, SYLVAIN KAHANE

entre les arbres de dependance en sortie de l’analyseur et des graphes semantiques. Contrairement aux
strategies d’extraction de grammaires sur corpus annotes par des methodes statistiques, nous calculons une
grammaire formelle purement algebrique. Chaque exemple de notre base est concu pour obtenir une regle
et peut étre vu comme une demi-regle contenant la partie semantique et dont la partie syntaxique est
calculee par l’analyseur syntaxique.

Notre representation semantique est un graphe de relations predicat-argument entre les signifies des unites
lexicales et grammaticales d’une phrase (ou chaque unite lexicale a ete desambigu'1'see par rapport a un
lexique de reference). Elle est directement inspiree des representations semantique et syntaxique profonde
de la Theorie Sens-Texte (Mel’euk 1988a; Candito & Kahane 1998; Kahane 2002). Il s’agit d’une
representation semantique du contenu linguistique et pas d’une semantique denotationnelle comme les
representations semantiques basees sur la logique. Il n’y a donc pas a proprement parler de calcul de
valeurs de Verite associees; par contre, ce type de representation permet des calculs de paraphrases
(Mel’euk 1988b ; Milieevie 2007) et a ete implemente avec succes pour la generation de textes
(Iordanskaja et al. 1988 ; Bohnet & Wanner 2001) ou la traduction automatique (Apresjan et al. 2003).
Des representations similaires ont ete proposees par d’autres auteurs sans reference explicite a la Theorie
Sens-Texte. Voir par exemple (Copestake 2009) ou (Bedaride & Gardent 2009).

Nous commencerons par presenter le formalisme utilise pour l’ecriture d’une interface syntaxe-semantique
(section 1), puis les principes generaux du calcul de regles grammaticales ne necessitant pas de
connaissances lexicales (section 2). L’exploitation de ressources lexicales pour la production de nouvelles
regles sera esquissee (section 3). Nous terrninerons en montrant comment realiser l’articulation lexique-
grammaire par la << soustraction >> de regles lexicales a nos regles grammaticales (section 4). Cet article
porte essentiellement sur les questions theoriques liees au calcul de l’interface syntaxe-semantique. Une
implementation non encore evaluee est en cours.

1. Ecrire une interface syntaxe-semantique

Pour ecrire notre interface syntaxe-semantique, nous utilisons un formalisme generique, la Grammaire
d’Unification Polarisee (GUP) (Kahane, 2004). Ce formalisme permet d’ecrire des grammaires de
correspondances entre graphes et a deja ete propose pour l’interface syntaxe-semantique (Kahane &
Lareau, 2005). Ce formalisme permet, a l’image de TAG, de combiner des structures elementaires afin
d’obtenir une structure complete. Les structures que nous souhaitons obtenir sont des couples formes d’un
arbre de dependance syntaxique et d’un graphe semantique; nos structures elementaires sont donc des
fragments d’arbre syntaxique associes a des fragments de graphe semantique. La particularite de ce
formalisme est un contr6le rigoureux de ce que chaque regle consomme, a l’aide de polarites associees aux
obj ets manipules par les regles. Le jeu de polarites le plus simple est constitue de deux polarites, que nous
appelons noir (I) et blanc (I:I). Chaque obj et de la structure recoit une polarite. Sont consideres comme des
objets les noeuds (identiﬁes avec l’element lexical qu’ils portent), les dependances et les elements
ﬂexionnels ayant une contribution semantique (temps Verbal, nombre nominal, etc.). Les regles sont
combinees par identification des obj ets dont les etiquettes peuvent s’uniﬁer et les polarites se combiner.

La Figure 1 presente un exemple d’interface syntaxe-semantique en GUP. En haut a gauche se trouve la
phrase Mary seems to sleep avec l’analyse syntaxique en dependance qu’en propose le Stanford Parser.
Les dependances syntaxiques sont orientees Vers la gauche (<nsubj) ou Vers la droite (xcomp>). Nous
ajoutons des polarites blanches sur les dependances (D) et les mots (D) indiquant que ces obj ets doivent étre
consommes par des regles d’interface. Pour les verbes, une deuxieme polarite blanche (O) indique que la
ﬂexion Verbale doit aussi étre consommee. En haut a droite se trouve le resultat attendu, c’est-a-dire un
graphe semantique associe a la phrase et polarise en noir puisque produit par l’interface. Pour assurer cette
correspondance, nous utilisons les trois regles qui figurent en dessous. Ce sont des regles lexicales

UNE APPROCHE PARESSEUSE DE L’ANALYSE SEMANTIQUE

associées aux lemmes SEEM, SLEEP et MARY. Comme on peut le Voir la regle associée a SEEM
consomme la totalité des dépendances syntaxiques, mais ne produit qu’une dépendance sémantique. La
deuxieme dépendance sémantique est produite par la regle de SLEEP. Mais pour que cette regle puisse
s’appliquer il est nécessaire que la regle de SEEM restitue une dépendance syntaxique. Notons pour
terrniner que la regle de SEEM impose a son xcomp> d’étre un Verbe infinitif (Vinf) et consomme ainsi sa
polarité ﬂexionnelle (o).

:':c o1m37i>
|—«::nsL1l3"|<| I-<_au:‘
Z F0 F F

%_‘ _O

  

|——aJ:qlI>—
<Iar<[_L
|:|—|<Insubj]-r I
_o 
¥ — 1 E $ ¥
Larc; lI.‘:>—l i_<-31-g1J

Figure 1. Un exemple d’interface syntaxe-sémantique en GUP

2. Calcul d’une régle grammaticale d’interface syntaxe-sémantique

Nous allons calculer la regle pour l’aspect progressif. Celui-ci est exprimé par BE + Ving et nous Voulons
récupérer au niveau sémantique un attribut [aspect= progressive] sur le Verbe. Pour apprendre la regle,
nous construirons un exemple de phrase avec un progressif (en l’occurrence Mary is sleeping) en indiquant
que pour is le lemme seul sera consommé (lo) et que pour sleeping la ﬂexion seule sera consommée (Do)
(Voir Figure 3). Autrement dit, nous connaissons déja la regle et nous pourrions l’écrire a la main. Notre
objectif est de l’adapter automatiquement et sans effort aux sorties de n’importe quel analyseur, d’autant
que les analyseurs Varient non seulement dans les étiquettes qu’ils utilisent, mais aussi dans les structures
qu’ils manipulent. Dans le cas du progressif, nous ne savons pas si le sujet sera relié a l’auxiliaire ou au
Verbe lexical. Nos deux analyseurs de référence, le Stanford Parser et le Link Grammar, font des choix
différents. C’est pourquoi nous intégrons le sujet dans la regle et considérons donc une relation sémantique
<argl correspondante. Nous verrons dans la section 4 comment << retirer >> cette information.

[—<I11su]:>1
<-aux  
V l r l2 1.

D -Q El. D .0 D. D

Z - M | _ _ I I j
m ﬂ[a=Pr°9re55j-V9] |:| Ij[a=progre55j_V-e] D D[a=progressive]
L—<larcIi I-—<larql— l—<larctl

Figure 3. Calcul de la regle du progressif : exemple de départ (a gauche) et regles obtenues
pour le Stanford Parser (au centre) et pour Link Grammar Parser (a droite)

3. Des régles lexicales pour l’interface syntaxe-sémantique

L’utilisation d’un lexique électronique permet le calcul automatique de regles. Par exemple, une ressource
telle que VerbNet (pour l’anglais) ou Dicovalence (pour le francais), décrivant des cadres de sous-

FRANCOIS-REGIS CHAUMARTIN, SYLVAIN KAHANE
categorisation, peut étre mise a profit. L’idée est alors d’analyser les exemples foumis pour en déduire les
regles. Par exemple, le cadre give-13.1 de VerbNet est décrit de la facon suivante :

<DESCRIPTION descriptionNumber="0.2" primary="NP V NP PP.recipient"/>
<EXAMPLES><EXAMPLE>They lent a bicycle to me.</EXAMPLE></EXAMPLES>

<SYNTAX><NP value="Agent" /> <VERB /> <NP value="Theme" /> <PREP value="to" />
<NP value="Recipient" /></SYNTAX>

Cette description peut étre utilisée pour créer automatiquement la regle lexicale de la Figure 4, avec le
processus décrit dans (Chaumartin, 2005). Premiere étape : a partir de l’exemple donné par VerbNet et sa
description dans VerbNet la demi-regle sémantique est construite. Deuxieme étape : l’exemple est analysé
par l’analyseur de notre choix (ici le Stanford Parser), ce qui nous foumit une regle lexicale pour
l’interface avec les résultats de cet analyseur.

l0bjI

r<Insubin———iob1I>——1
C -0 C U [ i IO l f [ I
2 2 - a ‘ I # I I
C I C‘ D C C‘ D

L<IAqentfRecipientI>J L<IAqentnRecipientI>J
———Themel>—— -———ThemeI>———

Figure 4. Extraction d’une regle lexicale a partir du cadre give-13.1 de VerbNet :
exemple de départ construit a partir de VerbNet a gauche, regle obtenue pour le Stanford Parser a droite

Cette regle est par ailleurs utile pour lever des ambigu'1'tés lexicales et syntaxiques : en effet, d’une part, la
recherche de la regle la plus couvrante dans la forét d’analyses syntaxiques produite pour une phrase
donnée permet d’augmenter le score des analyses ou la regle est applicable ; d’autre part, VerbNet précise
les sens du Verbe compatibles avec le cadre de sous-categorisation, et impose éventuellement des
contraintes de sélection sur ses arguments.

4. Articulation lexique-grammaire et soustraction de régles

Considérons une phrase telle que They were lending me a bicycle. Nous pouvons y appliquer la regle
grammaticale du progressif (calculée en Section 2). Mais cette regle consomme le lien sujet et nous ne
pourrons pas ensuite appliquer la regle lexicale du Verbe LEND que nous avons créée a partir de VerbNet
(Section 3). La solution habituelle a ce probleme est celle adoptée par exemple par les grammaires TAG
consistant a produire a partir de la diathese de base toutes les réalisations possibles (Candito 1999) ou
(Bédaride & Gardent, 2009) dans un forrnalisme similaire au notre. 11 en résulte un lexique-grammaire
assez volumineux en raison de la croissance rapide du nombre de regles en fonction du nombre de
phénomenes pris en compte (le lexique inclut en fait la grammaire). Plut6t que d’additionner divers
phénomenes au sein d’une méme regle, nous proposons au contraire de soustraire aux regles
grammaticales la partie lexicale pour permettre a la regle lexicale de se combiner avec les regles
grammaticales. Dans le cas du progressif, réalisé par une construction avec un auxiliaire BE + Ving nous
nous ramenons au cas d’une forme Verbale simple. Pour ramener la construction A au cas d’une
construction B, nous proposons simplement de calculer comme précédemment des regles pour A et B, puis
de soustraire la regle de B a celle de A. La soustraction est controlée par les polarités selon le calcul
su1Vant :

I - I = suppression (autrement dit, tout obj et manipulé dans A et B est supprimé)

(D -) I = CI (un obj et uniquement manipulé dans B doit étre absolument introduit dans la regle A—B
pour étre consommé ensuite par l’application de B)

UNE APPROCHE PARESSEUSE DE L’ANALYSE SEMANTIQUE

<-Sf?->j _ fmjo 
I I

I: I0 3- = :1 lo C0
I - _ I - i
I: :l[a=progressive] _ |:| Cl C [a=progressive]

|—<Iarc;1J H<Ia:c[l—l

<I115u]:-‘] <Insub‘|
|—<Iau;/l T |—<Iau:/.
Io jo — ’ :
2

I: _ DO I0 C0

I — I I — 2

I: :l[a=progressive] _ Cl C [a=progressive]
|—<Iarq.L—J ;<Iarqi4

Figure 6. Calcul de la regle pour le progressif

Dans la Figure 6, la premiere ligne montre les regles obtenues pour le Link Grammar et la deuxieme
montre celles obtenues pour le Stanford Parser. Rappelons que la base d’exemple contient uniquement la
partie inférieure des regles (le graphe sémantique) pour les deux exemples, A = Mary is sleeping and B =
Mary sleeps). La partie supérieure est calculée par l’analyseur, puis la regle B est soustraite de A. Dans le
cas du Ling Grammar, le lien <lS de B ne correspond pas au lien <lS de A (ils n’ont pas le méme
gouverneur) et donne donc un lien <DS dans A—B. Dans le cas du Standford Parser, les liens <lnsubj de A
et B se correspondent et s’annulent donc l’un l’autre. Notons que le lien <lS dans la regle du progressif
obtenue avec le Ling Grammar n’est pas un probleme méme pour l’analyse d’une phrase comme Mary
seems to be sleeping: l’application de la regle pour SEEM (Figure 1) perrnettra de se ramener a une
structure similaire a celle de la phrase Mary is sleeping, ou la regle du progressif pourra s’appliquer.

Terminons en présentant la regle pour le passif. Comme précédemment, le principe consiste a se ramener a
une forme plus simple, c’est-a-dire, dans ce cas, l’actif. La polarisation des noeuds est donnée dans la base
d’exemples (les parties inférieures qui s’annulent, puisque le passif n’a pas de contribution sémantique, ne
sont pas montrées), la partie supérieure est calculée par l’analyseur (ici le Link Grammar), puis la regle
definitive est obtenue par soustraction.

.r<'S;:':”:">;~*'i. .r<'S;:'>i. 

Peter is Seen by Mary - Mary sees Peter = BE Ved by N

Figure 7. Calcul de la regle pour le passif

Conclusion

L’idée de développer une interface syntaxe-sémantique entre arbre de dépendance et graphe de relation
prédicat-argument est ancienne et remonte au début de la Théorie Sens-Texte dans les années 60 (Mel’<':uk
1988, Kahane 2002). L’originalité du présent travail est de proposer une stratégie simple pour construire
une telle interface a partir de ressources existantes, analyseurs syntaxiques et lexiques sémantiques. D’une
part, notre grammaire s’adapte automatiquement aux sorties de n’importe quel analyseur syntaxique en
dépendance. D’autre part, notre grammaire est tres modulaire avec une seule regle pour chaque régime
d’une unité lexicale et des regles grammaticales séparées pour les différentes constructions et
redistributions dont cette unité lexicale peut faire l’objet. Nous pensons que cette approche est
pragmatique dans la mesure ou elle met en oeuvre des ressources de large couverture dans leur état actuel.

FRANCOIS-REGIS CHAUMARTIN, SYLVAIN KAHANE

Les avantages escomptes de cette approche sont une grande modularite et une facilite de maintenance de
l’interface syntaxe-semantique obtenue, l’independance vis-a-vis de tout analyseur syntaxique particulier,
et une facilite de prise en compte de nouvelles ressources. Notons que notre grammaire est completement
reversible et peut servir aussi bien pour l’analyse que pour la generation de texte. La mise en oeuvre d’une
telle grammaire pose evidemment des difficultes qui ne sont pas abordees ici. Notons simplement que le
forrnalisme a deja fait l’objet d’une implementation (Lison, 2006) ; nous en developpons actuellement une
nouvelle implementation, en utilisant l’outil de reecriture de graphes GrGen et differentes heuristiques afin
d’eviter toute explosion combinatoire.

Ré férences
APRESJAN J. ET AL. (2003). ETAP—3 Linguistic Processor: a Full—Fledged NLP Implementation of the MTT. Actes
de MTT, Paris, 279-288.

BEDARIDE P., GARDENT C. (2009). Semantic Normalisation: a Framework and an Experiment. Actes d’IWCS ’09.'
8th International Conference on Computational Semantics, Tilburg, Netherland.

BOHNET B., WANNER L. (2001). On using a parallel graph rewriting formalism in generation. Actes du Workshop
on Natural language Generation, ACL 2001, Toulouse.

CANDITO M.—H., KAHANE S. (1998). Can the derivation tree represent a semantic graph? An answer in the light of
Mear1ing—Text Theory”. Actes de TAG+ 4, Philadelphie, 21-24.

CANDITO, M.—H. (1999). Organisation modulaire et paramétrable de grammaires électroniques lexicalisées.
Application au frangais et a l'italien. These de doctorat, Université Paris 7.

CHAUMARTIN F.—R. (2005). Conception et realisation d’une interface syntaxe / semantique utilisant des ressources
de large couverture en langue anglaise. Actes de RECITAL 2007.

CHAUMARTIN F.—R. (2008). AN TELOPE, une plateforme industrielle de traitement linguistique. TAL 49.2.

COPESTAKE A. (2009). Slacker semantics : Why superﬁciality, dependency and avoidance of commitment can be the
right way to go. Actes d’EACL 2009, Invited Talk, 1-9, Athenes.

IORDANSKAJA L., KI'I'1‘REDGER., POLGUERE A. (1988). Implementing a Mear1ing—Text Model for Language
Generation. Actes de COLING 1998.

KAHANE S. (2002). Grammaire d’Umﬁcati0n Sens—Texte: Vers un modele mathématique articulé de la langue
naturelle, Document de synthese de l’Habilitation a diriger des recherches, Universite Paris 7.

KAHANE S. (2004). Grammaires d’uniﬁcation polarisees. Actes de TALN 2004, Fez.

KAHANE S., LAREAU F. (2005). Mear1ing—Text Uniﬁcation Grammar: modularity and polarization. Actes de MTT
2005, Moscou.

LISON P. (2006). Implémentation d’une interface semantique-syntaxe basée sur des grammaires d’umﬁ'cati0n
polarisees. Master’s thesis, Universite Catholique de Louvain, Louvain—la—Neuve, Belgium.

MEL’CUK I. (1988a). Dependency Syntax: Theory and Practice, SUNY Press, Albany.

MEL’C1UK I. (1988b). Paraphrase et lexique dans la théorie linguistique Sens—Texte: vingt ans apres, Revue
internationale de lexicologie et lexicographic, Vol. 52/53, pp. 5-50/5-53.

MILI('1EVI('1 J. (2007). Ia paraphrase - Modélisation de la paraphrase langagiere. Bern : Peter Lang.

Ressources citées

Dicouebe (MEL’C1UK, POLGUERE) : http://olst.ling.umontreal.ca/dicouebe/

Dicovalence (MERTENS, VAN DEN EYNDE) : http://bach.arts.kuleuven.be/dicovalence/
GrGen : http://www.info.uni-karlsruhe.de/soﬁware/grgen/

Link Grammar (SLEATOR, TEMPERLEY, LAFFERTY) : http://www.link.cs.cmu.edu/link/:
Stanford Parser (MANNING, KLEIN) : http://nlp.stanford.edu/software/lex-parser.shtml
VerbNet(K1PPER, SCHULER) : http://verbs.colorado.edu/~mpalmer/projects/verbnet.html

