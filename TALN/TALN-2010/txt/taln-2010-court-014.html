<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Segmentation Automatique de Lettres Historiques</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montre&#769;al, 19&#8211;23 juillet 2010
</p>
<p>Segmentation Automatique de Lettres Historiques
</p>
<p>Michel Ge&#769;ne&#769;reux, Rita Marquilhas, Iris Hendrickx
Centro de Lingu&#305;&#769;stica da Universidade de Lisboa
</p>
<p>Av. Prof. Gama Pinto, 2
1649-003 Lisboa - Portugal
</p>
<p>Re&#769;sume&#769;. Cet article pre&#769;sente une approche base&#769;e sur la comparaison fre&#769;quentielle de mode&#768;les lexi-
caux pour la segmentation automatique de textes historiques Portugais. Cette approche traite d&#8217;abord le
proble&#768;me de la segmentation comme un proble&#768;me de classification, en attribuant a&#768; chaque e&#769;le&#769;ment lexical
pre&#769;sent dans la phase d&#8217;apprentissage une valeur de saillance pour chaque type de segment. Ces mode&#768;les
lexicaux permettent a&#768; la fois de produire une segmentation et de faire une analyse qualitative de textes
historiques. Notre e&#769;valuation montre que l&#8217;approche adopte&#769;e permet de tirer de l&#8217;information se&#769;mantique
que des approches se concentrant sur la de&#769;tection des frontie&#768;res se&#769;parant les segments ne peuvent acque&#769;rir.
</p>
<p>Abstract. This article presents an approach based on the frequency comparison of lexical models for
the automatic segmentation of historical texts. This approach first addresses the problem of segmentation
as a classification problem by assigning each token present in the learning phase a value of salience for each
type of segment. These lexical patterns can both produce a segmentation and make possible a qualitative
analysis of historical texts. Our evaluation shows that the approach can extract semantic information that
approaches focusing on the detection of boundaries between segments cannot capture.
</p>
<p>Mots-cle&#769;s : Corpus comparables, Saillance, Segmentation, Textes historiques.
</p>
<p>Keywords: Comparable corpora, Salience, Segmentation, Historical Texts.
</p>
<p>1 Introduction
</p>
<p>Dans le projet CARDS1, des lettres prive&#769;es allant du 16ie&#768;me jusqu&#8217;au 19ie&#768;me sie&#768;cle au Portugal sont trans-
crites manuellement. Le corpus CARDS est e&#769;tiquete&#769; textuellement pour identifier les formules d&#8217;ouver-
ture (opening) et de fermeture (closing), d&#8217;exorde (harengue) et de conclusion ou pe&#769;roraison (peroration).
Dans l&#8217;e&#769;tude pre&#769;sente&#769;e ici, le but est de re&#769;duire la charge de travail manuel par le traitement automatique
des corpus en ce qui concerne la segmentation afin de produire une e&#769;dition critique e&#769;lectronique et une
interpre&#769;tation historique et linguistique des lettres. Ce papier pre&#769;sente donc un travail dont le but est de seg-
menter automatiquement des lettres faisant partie d&#8217;un corpus historique, en les se&#769;parant en cinq parties,
le corps de la lettre et quatre parties formelles identifie&#769;es par les historiens (ouverture, exorde, conclusion
et clo&#770;ture). Le mode&#768;le choisi est purement lexical, chaque mot e&#769;tant classifie&#769; en une de ces cinq classes
pour indiquer qu&#8217;il appartient a&#768; une partie ou a&#768; une autre. Des scores d&#8217;associations de n-grammes (pour
n=1,2 et 3) sont calcule&#769;s pour choisir la classe d&#8217;un mot donne&#769;.
</p>
<p>1http://alfclul.clul.ul.pt/cards-fly</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>GE&#769;NE&#769;REUX, MARQUILHAS, HENDRICKX
</p>
<p>2 Segmentation des Textes
</p>
<p>La segmentation de lettres historiques est une ta&#770;che difficile parce que les outils qui nous permettent
normalement d&#8217;extraire des informations significatives a&#768; partir du lexique des lettres (cate&#769;gories gramma-
ticales, lemmes) n&#8217;existent tout simplement pas. Par conse&#769;quent, il faut s&#8217;appuyer sur les formes dites de
&#171;surface&#187; du mot (le lexis), ce qui repre&#769;sente une se&#769;rieuse limitation sur la capacite&#769; des outils automa-
tiques de faire des ge&#769;ne&#769;ralisations utiles. Par exemple, les noms propres sont plus informatifs comme une
cate&#769;gorie que comme un mot, puisque le nom propre lui-me&#770;me n&#8217;a pas tendance a&#768; re&#769;appara&#305;&#770;tre dans les
textes. Nous avons tout de me&#770;me fait une tentative pour e&#769;tiqueter les noms propres sur la base d&#8217;une liste
ad hoc de 6923 noms portugais provenant de diverses sources locales et en ligne. Les lemmes sont aussi
utiles parce que la me&#770;me information se&#769;mantique peut e&#770;tre capture&#769;e dans un lemme unique, qui peut e&#770;tre
instancie&#769; sous plusieurs formes au travers des mots dans les textes. Un sous-ensemble de 402 textes pour la
phase d&#8217;apprentissage et 100 textes pour la phase de test ont e&#769;te&#769; choisis au hasard dans le corpus CARDS.
</p>
<p>2.1 Cre&#769;ation des mode&#768;les lexicaux
</p>
<p>La ta&#770;che de segmentation consiste a&#768; attribuer a&#768; chaque mot (1-gramme) des lettres historiques un seul des
quatre e&#769;tiquettes/segments (opener, harengue, peroration ou closer) disponibles. Il est e&#769;galement possible
qu&#8217;aucune e&#769;tiquette ne soit attribue&#769;e a&#768; un mot (free). Contrairement a&#768; d&#8217;autres approches (Sporleder &amp; La-
pata, 2006) qui utilisent une varie&#769;te&#769; de bases de connaissances (indicateurs textuels, information relie&#769;e a&#768;
la syntaxe et au discours) ou cherchent a&#768; identifier les patrons lexicaux permettant d&#8217;identifier les change-
ments de the&#768;mes (Hearst, 1997; Ferret, 2002), nous nous appuyons sur des mode&#768;les lexicaux pour chacune
des classes que nous cherchons a&#768; identifier, ce qui a l&#8217;avantage de produire du me&#770;me coup un vocabu-
laire pour chaque segment. Notre approche est de re&#769;colter tous les n-grammes (n &#8804; 3) dans les donne&#769;es
du corpus d&#8217;apprentissage et de calculer un score repre&#769;sentant leur saillance dans le segment dans lequel
le n-gramme appara&#305;&#770;t, ce qui la rattache a&#768; la composante bottom-up de l&#8217;analyse du discours pre&#769;sente&#769;e
dans (Biber et al., 2007). Nous utilisons le log odds ratio (Everitt, 1992) comme mesure statistique de la
saillance d&#8217;un n-gramme. Le log odds ratio compare la fre&#769;quence d&#8217;occurrence de chaque n-gramme dans
un corpus spe&#769;cialise&#769; a&#768; sa fre&#769;quence d&#8217;occurrence dans un corpus de re&#769;fe&#769;rence :
</p>
<p>log odds ratio = ln(ad/cb) = ln(a) + ln(d)&#8722; ln(c)&#8722; ln(b)
</p>
<p>ou&#768; a est la fre&#769;quence du mot dans le corpus spe&#769;cialise&#769;, b est la taille du corpus spe&#769;cialise&#769; moins a, c est
la fre&#769;quence du mot dans le corpus ge&#769;ne&#769;ral et d est la taille du corpus ge&#769;ne&#769;ral moins c. Une grande valeur
de saillance positive indique une saillance forte, alors qu&#8217;une grande valeur ne&#769;gative indique un mot sans
importance pour le segment. Nous avons construit quatre corpus spe&#769;cialise&#769;s, un pour chacun des quatre
segments (opener, closer, harengue or peroration) et un pour les mots qui n&#8217;appartiennent a&#768; aucun segment
(free). Nous avons adopte&#769; le corpus Tycho Brahe&#769;2 comme corpus de re&#769;fe&#769;rence. La comparaison avec un
corpus de refe&#769;rence permet non seulement de comparer les classes entre elles, mais aussi de les situer par
rapport a&#768; un discours neutre. Notons qu&#8217;il existe d&#8217;autres mesures de comparaison de fre&#769;quences (Frantzi
et al., 2000). Le corpus Tycho Brahe&#769; constitue un bon e&#769;talon de re&#769;fe&#769;rence pour trois raisons principales :
</p>
<p>1. Il est assez varie&#769; selon les genres tandis que CARDS ne dispose que de lettres prive&#769;es.
</p>
<p>2http://www.tycho.iel.unicamp.br/&#732;tycho/corpus/en/index.html</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>SEGMENTATION AUTOMATIQUE DE LETTRES HISTORIQUES
</p>
<p>Corpus Nb textes 1-gramme 2-gramme 3-gramme Nb segments Nb mots/segment
re&#769;fe&#769;rence 44 1508386 1268345 1052225 - -
</p>
<p>opener 275 1366 1077 815 275 5.3
closer 343 4070 3585 3141 343 13.6
</p>
<p>harengue 121 2788 2597 2408 124 25.6
peroration 231 3223 2890 2582 266 15.4
</p>
<p>free 402 111745 105921 100242 - -
</p>
<p>TAB. 1 &#8211; Corpus de Re&#769;fe&#769;rence et Spe&#769;cialise&#769;s
</p>
<p>Segment 2-gramme 3-gramme
opener Exmo Snr &#8216;Tre&#768;s Excellent Mr&#8217; 12.7 Illmo e Exmo &#8216;Tre&#768;s Illustre et Excellent&#8217; 12.9
closer De V &#8216;De Vous&#8217; 11.2 De V Exa &#8216;De Votre Excellence&#8217; 10.8
</p>
<p>harengue saude q &#8216;sante&#769; que&#8217; 10.1 da q me &#8216;de la que me&#8217; 8.6
peroration gde a &#8216;garde a&#768;&#8217; 13.0 Ds gde a &#8216;Dieu garde a&#768;&#8217; 11.6
</p>
<p>TAB. 2 &#8211; 2-grammes et 3-grammes les plus saillants
</p>
<p>2. Il est presque entie&#768;rement constitue&#769; par des e&#769;chantillons du portugais litte&#769;raire formel de l&#8217;e&#768;re mo-
derne ; en revanche, le corpus CARDS est assez varie&#769; tant en termes de registre (formel et informel)
que de repre&#769;sentativite&#769; sociale.
</p>
<p>3. Il a e&#769;te&#769; en partie normalise&#769; en fonction de l&#8217;orthographe tandis que CARDS maintient syste&#769;matiquement
l&#8217;orthographe des manuscrits originaux3.
</p>
<p>Nos 402 lettres servant a&#768; l&#8217;apprentissage ont e&#769;te&#769; utilise&#769;es pour cre&#769;er les corpus spe&#769;cialise&#769;s en concate&#769;nant,
pour chaque lettre, tous les mots appartenant a&#768; un segment particulier, en pre&#769;servant la ponctuation et les
limites des segments de telle sorte qu&#8217;aucun n mots conse&#769;cutifs ne peut appartenir a&#768; diffe&#769;rentes phrases ou
segments. Ces corpus d&#8217;apprentissage sont de&#769;crits dans le tableau 1. Les saillances pour chaque n-gramme
ont ensuite e&#769;te&#769; calcule&#769;es et trie&#769;es du plus grand au plus petit. Dans le tableau 2, nous affichons pour chaque
segment le 2-gramme et le 3-gramme le plus saillant ainsi que sa valeur de saillance.
</p>
<p>2.2 Classer chaque mot
</p>
<p>Les listes de n-grammes avec des valeurs de saillance pour chaque segment constituent nos mode&#768;les lexi-
caux pour notre classificateur. Pour savoir a&#768; quel segment un mot appartient, le classificateur adopte la
strate&#769;gie en deux e&#769;tapes suivante :
</p>
<p>1. On attribue a&#768; chaque 1-gramme les valeurs de saillance pour chaque segment que l&#8217;on peut trouver
dans les mode&#768;les, ze&#769;ro sinon ;
</p>
<p>2. Chaque mot d&#8217;un n-gramme (n &#8712; (2,3)) voit sa valeur de saillance augmente&#769;e par la valeur de
saillance correspondant aux n-grammes dans les mode&#768;les, si elles existent.
</p>
<p>La strate&#769;gie ci-dessus peut e&#770;tre limite&#769;e a&#768; un sous-ensemble d&#8217;un, deux ou trois mode&#768;les. Par conse&#769;quent,
chaque mot a une valeur de saillance pour chaque segment, et peut prendre en compte des informa-
</p>
<p>3Nous avons inclu des textes de re&#769;fe&#769;rence non normalise&#769;s pour e&#769;viter de se retrouver avec un corpus de re&#769;fe&#769;rence trop petit.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>GE&#769;NE&#769;REUX, MARQUILHAS, HENDRICKX
</p>
<p>n-gramme F-scores % Exactitude
utilise&#769;(s) opener harengue peroration closer ge&#769;ne&#769;rale %
{1} 4 15 6 25 53
{2} 9 20 8 33 62
{3} 30 16 14 24 88
{1,2} 5 14 8 25 47
{1,3} 4 18 8 29 53
{2,3} 9 21 8 35 63
{1,2,3} 5 15 9 26 47
TAB. 3 &#8211; F-scores et exactitudes pour la classification des mots
</p>
<p>tions contextuelles (si les mode&#768;les supe&#769;rieurs a&#768; 1-gramme ont e&#769;te&#769; inclus dans le proce&#769;de&#769; de calcul de&#769;crit
pre&#769;ce&#769;demment). Le segment final est celui correspondant a&#768; la saillance la plus e&#769;leve&#769;e, diminue&#769;e de la
valeur de la saillance des autres classes. L&#8217;e&#769;valuation sur 100 lettres sont pre&#769;sente&#769;s dans le tableau 3.
</p>
<p>2.3 Production de segments
</p>
<p>L&#8217;approche pre&#769;ce&#769;dente pour classer les mots d&#8217;une lettre sur une base individuelle ne peut pas toujours pro-
duire des regroupements d&#8217;e&#769;tiquettes continus semblables a&#768; de vrais segments, il y a donc ine&#769;vitablement
des discontinuite&#769;s entre des groupes de mots distants ayant la me&#770;me e&#769;tiquette. Regardons l&#8217;exemple sui-
vant4, ou&#768; l&#8217;indice5 indique une e&#769;tiquette propose&#769;e par le classifieur et ou&#768; les balises indiquent la vraie
classe telle qu&#8217;annote&#769;e par les humains.
</p>
<p>&lt;opener&gt; Meoo amoo ec Sro &lt;/opener&gt; &lt;harengue&gt;Aindac qh VMf meh na&#771;oh querh
darh oc alivioh deh suash novash ah minhah amizadeh na&#771;oh pideh talh discuidoc eh assih
lembresseh VMh deo mimf qh comh novash suash qh bemh sabeh qf na&#771;oh temh qmp lhash
dezejeh comh maish verasp . &lt;/harengue&gt; Sabadof novef destef mesf . . . porf na&#771;of ficarf
comf escrupellof &lt;peroration&gt; aquip ficop a&#769;sh ordensp dep VMp pap of qp mep quizerp
mandarp comf gdep vontadep Dsp gdep ap VMp &lt;/peroration&gt; &lt;closer&gt; Pradaf 10f def
Julhoc dec 1712f Mayorf Amoc ec Servidorc def VMc Frandof dec Sa&#769;f Menezesf &lt;/closer&gt;
</p>
<p>Bien que les patrons d&#8217;e&#769;tiquettes calcule&#769;s suivent a&#768; peu pre&#768;s l&#8217;annotation &#171;vraie&#187;, une technique de lissage
pourrait e&#770;tre applique&#769;e pour tenter de rattacher les ilo&#770;ts d&#8217;e&#769;tiquettes disparates et de cre&#769;er des segments
proches de ceux cre&#769;e&#769;s par des annotateurs humains. Pour obtenir un lissage des patrons &#171;segmentaires&#187;
obtenus par l&#8217;e&#769;tiquetage automatique de chaque mot individuellement, nous choisissons un intervalle pour
la longueur de chaque segment de telle sorte que 95% des valeurs moyennes (pour la longueur) se trouvent
dans cette intervalle. Ceci est donne&#769; dans la distribution normale par le calcul (moyenne&#8723; 2 * e&#769;cart-type)6.
</p>
<p>4Traduction franc&#807;aise : &lt;opener&gt; Mon ami et Seigneur &lt;/opener&gt; &lt;harengue&gt;Bien que votre Gra&#770;ce ne veut pas me
soulager avec des nouvelles de votre Gra&#770;ce, mon amitie&#769; ne demande pas un tel manque d&#8217;attention, alors, accordez votre Gra&#770;ce
de moi avec vos nouvelles, parce que vous savez bien qu&#8217;il n&#8217;y a personne a&#768; les de&#769;sirer plus que moi, vraiment &lt;/harengue&gt;
Le Samedi 9 de ce mois . . . de ne pas avoir des scrupules &lt;peroration&gt;ici je reste aux ordres de votre Gra&#770;ce pour ce que votre
Gra&#770;ce le veuille ordonner, de toute ma volonte&#769;, Dieu garde a&#768; votre Gra&#770;ce &lt;/peroration&gt;&lt;closer&gt; Prada, le 10 juillet de 1712
Le plus grand ami et serviteur de votre Gra&#770;ce Fernando de Sa&#769; Menezes &lt;/closer&gt;
</p>
<p>5o=opener, c=closer, h=harengue, p=peroration and f=free
6Nous avons calcule&#769; la moyenne et l&#8217;e&#769;cart-type a&#768; partir des donne&#769;es d&#8217;apprentissage.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>SEGMENTATION AUTOMATIQUE DE LETTRES HISTORIQUES
</p>
<p>n-gramme F-scores % Exactitude
utilise&#769;(s) opener harengue peroration closer ge&#769;ne&#769;rale %
{1} 2 10 4 35 26
{2} 6 26 6 41 33
{3} 31 23 12 28 79
{1,2} 2 14 6 31 25
{1,3} 2 21 7 38 27
{2,3} 7 31 6 41 33
{1,2,3} 3 15 7 32 26
</p>
<p>TAB. 4 &#8211; F-scores et exactitudes pour chaque mot apre&#768;s la production de segments
</p>
<p>On obtient donc les valeurs d&#8217;intervalles suivantes : [1,15] pour opener, [1,60] pour harengue, [1,43] pour
peroration et [1,28] pour closer. Cela signifie que nous allons examiner seulement les opener dont la taille
varie entre 1 et 15 mots, etc.
</p>
<p>A&#768; partir du premier mot de chaque lettre historique, on calcule un score pour chaque segment de chacune
des quatre classes, compte tenu de la longueur des intervalles de&#769;finis pre&#769;ce&#769;demment pour chaque segment.
Les scores de chaque segment sont obtenus en retenant la classe pour laquelle la somme S des scores de
chaque mot dans le segment est la plus e&#769;leve&#769;e. En d&#8217;autres termes, un segment de N mots conse&#769;cutifs est
susceptible d&#8217;e&#770;tre e&#769;tiquete&#769; avec la classe C si elle a beaucoup de mots avec des valeurs de saillance e&#769;leve&#769;es
pour C. Nous conservons les segments au-dessus d&#8217;un certain seuil pour S et qui ne se chevauchent pas.
L&#8217;e&#769;valuation de ce classificateur utilisant la me&#770;me me&#769;trique que dans la section 2.2 sont indique&#769;s dans le
tableau 4.
</p>
<p>2.4 Remarques
</p>
<p>Bien que l&#8217;exactitude du classifieur soit nettement supe&#769;rieure a&#768; celle d&#8217;une base ale&#769;atoire (cinq classes&#8658;
20%), les valeurs pour les F-scores indique&#769;es dans les tableaux 3 et 4 concernant les mots appartenant a&#768;
l&#8217;un des quatre segments d&#8217;inte&#769;re&#770;t sont de&#769;cevantes mais pas surprenantes : les lettres historiques pre&#769;sentent
en effet un grand nombre de variantes orthographiques. Nous avions e&#769;galement a&#768; notre disposition un
corpus d&#8217;apprentissage pluto&#770;t petit (402 textes). Ne&#769;anmoins, nous pensons que notre approche base&#769;e sur la
fre&#769;quence de comparaison des n-grammes et de lissage pour la cre&#769;ation de ve&#769;ritables segments est un bon
point de de&#769;part. Les re&#769;sultats pre&#769;sente&#769;s dans les tableaux 3 et 4 nous permettent e&#769;galement de formuler
trois observations inte&#769;ressantes :
&#8211; Les 3-grammes et 2-grammes permettent d&#8217;e&#769;tablir une meilleure discrimination entre les quatre classes.
&#8211; Harengue et closer sont les classes qui peuvent e&#770;tre le plus facilement discrimine&#769;es.
&#8211; Le lissage pour produire des segments plus re&#769;alistes permet d&#8217;ame&#769;liorer la classification de chaque mot
</p>
<p>dans le cas de harengue et closer.
D&#8217;autre part, l&#8217;analyse des n-grammes les plus saillants nous a permis de faire les constatations suivantes :
&#8211; opener : la se&#769;mantique du respect social exprime&#769; par des formes de courtoisie nominales (ce qui e&#769;quivaut
</p>
<p>a&#768; Tre&#768;s Excellent Monsieur)
&#8211; harengue : la se&#769;mantique de la sante&#769;, combine&#769;e avec des verbes psychologiques et des expressions
</p>
<p>phatiques, typique des formules de souhaits dans les de&#769;buts de dialogue (e&#769;quivalent a&#768; J&#8217;espe&#768;re que vous</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>GE&#769;NE&#769;REUX, MARQUILHAS, HENDRICKX
</p>
<p>e&#770;tes en bonne sante&#769;)
&#8211; peroration : la se&#769;mantique de la religion, aussi combine&#769;e avec des expressions phatiques, typique de
</p>
<p>l&#8217;invocation de Dieu dans les fins de dialogue (l&#8217;e&#769;quivalent de Que Dieu soit avec vous)
&#8211; closer : de nouveau la se&#769;mantique du respect social, exprime&#769;e ici par des formes adjectivales et nomi-
</p>
<p>nales d&#8217;autode&#769;rision (e&#769;quivalent a&#768; Je suis votre humble serviteur).
Notons que pour e&#769;valuer spe&#769;cifiquement notre mode&#768;le lexical, nous avons pre&#769;fe&#769;re&#769; ne pas exploiter l&#8217;infor-
mation relative au positionnement normal des segments dans les textes. Finalement, nous avons l&#8217;intention
d&#8217;e&#769;valuer notre syste&#768;me avec des mesures classiques en segmentation (Sitbon &amp; Bellot, 2006).
</p>
<p>3 Conclusion
</p>
<p>Nous avons pre&#769;sente&#769; une e&#769;tude visant a&#768; segmenter automatiquement des lettres historiques selon quatre
classes. E&#769;tant donne&#769; l&#8217;absence d&#8217;outils permettant d&#8217;extraire des informations linguistiques sur lequel
s&#8217;appuyer, nous avons adopte&#769; une approche essentiellement statistique, sur la base de mode&#768;les lexicaux et
d&#8217;une comparaison fre&#769;quentielle avec un corpus de re&#769;fe&#769;rence, ce qui nous a permis de voir les limites d&#8217;une
telle approche, mais aussi de faire une analyse re&#769;solument objective de certaines caracte&#769;ristiques des textes
anciens. Nous pensons qu&#8217;avec l&#8217;assistance d&#8217;outils permettant l&#8217;acquisition d&#8217;information linguistique,
les performances d&#8217;une telle approche peuvent e&#770;tre grandement ame&#769;liore&#769;es.
</p>
<p>De fac&#807;on plus ge&#769;ne&#769;rale, le traitement informatise&#769; des donne&#769;es historiques, tels que les lettres des socie&#769;te&#769;s
du passe&#769;, permet d&#8217;e&#769;tablir une base de comparaison avec des e&#769;chantillons comparables contemporains. Au
cours du XXe sie&#768;cle, des millions de lettres ont e&#769;te&#769; e&#769;crites dans les socie&#769;te&#769;s occidentales, et certaines de
ces lettres ont surve&#769;cu. En termes d&#8217;e&#769;tude du changement linguistique et social, des e&#769;le&#769;ments de preuve
comparables provenant du passe&#769; et du pre&#769;sent sont ne&#769;cessaires, et la technologie informatique semble e&#770;tre
un outil indispensable pour la re&#769;alisation de cet objectif.
</p>
<p>Re&#769;fe&#769;rences
</p>
<p>BIBER D., CONNER U. &amp; UPTON T. (2007). Discourse on the move : Using corpus analysis to describe
discourse structure. Amsterdam : John Benjamins.
</p>
<p>EVERITT B. (1992). The Analysis of Contingency Tables. Chapman and Hall, 2nd edition.
</p>
<p>FERRET O. (2002). Segmenter et structurer the&#769;matiquement des textes par l&#8217;utilisation conjointe de
collocations et de la re&#769;currence lexicale. In TALN 2002, Nancy.
</p>
<p>FRANTZI K., ANANIADOU S. &amp; MIMA H. (2000). Automatic recognition of multi-word terms : the
C-value/NC-value Method. International Journal on Digital Libraries, 3(2), 115&#8211;130.
HEARST M. A. (1997). TextTiling : Segmenting text into multi-paragraph subtopic passages. Comput.
Linguist., 23(1), 33&#8211;64.
SITBON L. &amp; BELLOT P. (2006). Tools and methods for objective or contextual evaluation of topic
segmentation. In Proceedings of Language Resources and Evaluation (LREC) 2006.
</p>
<p>SPORLEDER C. &amp; LAPATA M. (2006). Broad coverage paragraph segmentation across languages and
domains. ACM Trans. Speech Lang. Process., 3(2), 1&#8211;35.</p>

</div></div>
</body></html>