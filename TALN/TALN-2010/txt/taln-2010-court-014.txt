TALN 2010, Montréal, 19–23 juillet 2010
Segmentation Automatique de Lettres Historiques
Michel Généreux, Rita Marquilhas, Iris Hendrickx
Centro de Linguı́stica da Universidade de Lisboa
Av. Prof. Gama Pinto, 2
1649-003 Lisboa - Portugal
Résumé. Cet article présente une approche basée sur la comparaison fréquentielle de modèles lexi-
caux pour la segmentation automatique de textes historiques Portugais. Cette approche traite d’abord le
problème de la segmentation comme un problème de classification, en attribuant à chaque élément lexical
présent dans la phase d’apprentissage une valeur de saillance pour chaque type de segment. Ces modèles
lexicaux permettent à la fois de produire une segmentation et de faire une analyse qualitative de textes
historiques. Notre évaluation montre que l’approche adoptée permet de tirer de l’information sémantique
que des approches se concentrant sur la détection des frontières séparant les segments ne peuvent acquérir.
Abstract. This article presents an approach based on the frequency comparison of lexical models for
the automatic segmentation of historical texts. This approach first addresses the problem of segmentation
as a classification problem by assigning each token present in the learning phase a value of salience for each
type of segment. These lexical patterns can both produce a segmentation and make possible a qualitative
analysis of historical texts. Our evaluation shows that the approach can extract semantic information that
approaches focusing on the detection of boundaries between segments cannot capture.
Mots-clés : Corpus comparables, Saillance, Segmentation, Textes historiques.
Keywords: Comparable corpora, Salience, Segmentation, Historical Texts.
1 Introduction
Dans le projet CARDS1, des lettres privées allant du 16ième jusqu’au 19ième siècle au Portugal sont trans-
crites manuellement. Le corpus CARDS est étiqueté textuellement pour identifier les formules d’ouver-
ture (opening) et de fermeture (closing), d’exorde (harengue) et de conclusion ou péroraison (peroration).
Dans l’étude présentée ici, le but est de réduire la charge de travail manuel par le traitement automatique
des corpus en ce qui concerne la segmentation afin de produire une édition critique électronique et une
interprétation historique et linguistique des lettres. Ce papier présente donc un travail dont le but est de seg-
menter automatiquement des lettres faisant partie d’un corpus historique, en les séparant en cinq parties,
le corps de la lettre et quatre parties formelles identifiées par les historiens (ouverture, exorde, conclusion
et clôture). Le modèle choisi est purement lexical, chaque mot étant classifié en une de ces cinq classes
pour indiquer qu’il appartient à une partie ou à une autre. Des scores d’associations de n-grammes (pour
n=1,2 et 3) sont calculés pour choisir la classe d’un mot donné.
1http://alfclul.clul.ul.pt/cards-fly
GÉNÉREUX, MARQUILHAS, HENDRICKX
2 Segmentation des Textes
La segmentation de lettres historiques est une tâche difficile parce que les outils qui nous permettent
normalement d’extraire des informations significatives à partir du lexique des lettres (catégories gramma-
ticales, lemmes) n’existent tout simplement pas. Par conséquent, il faut s’appuyer sur les formes dites de
«surface» du mot (le lexis), ce qui représente une sérieuse limitation sur la capacité des outils automa-
tiques de faire des généralisations utiles. Par exemple, les noms propres sont plus informatifs comme une
catégorie que comme un mot, puisque le nom propre lui-même n’a pas tendance à réapparaı̂tre dans les
textes. Nous avons tout de même fait une tentative pour étiqueter les noms propres sur la base d’une liste
ad hoc de 6923 noms portugais provenant de diverses sources locales et en ligne. Les lemmes sont aussi
utiles parce que la même information sémantique peut être capturée dans un lemme unique, qui peut être
instancié sous plusieurs formes au travers des mots dans les textes. Un sous-ensemble de 402 textes pour la
phase d’apprentissage et 100 textes pour la phase de test ont été choisis au hasard dans le corpus CARDS.
2.1 Création des modèles lexicaux
La tâche de segmentation consiste à attribuer à chaque mot (1-gramme) des lettres historiques un seul des
quatre étiquettes/segments (opener, harengue, peroration ou closer) disponibles. Il est également possible
qu’aucune étiquette ne soit attribuée à un mot (free). Contrairement à d’autres approches (Sporleder & La-
pata, 2006) qui utilisent une variété de bases de connaissances (indicateurs textuels, information reliée à
la syntaxe et au discours) ou cherchent à identifier les patrons lexicaux permettant d’identifier les change-
ments de thèmes (Hearst, 1997; Ferret, 2002), nous nous appuyons sur des modèles lexicaux pour chacune
des classes que nous cherchons à identifier, ce qui a l’avantage de produire du même coup un vocabu-
laire pour chaque segment. Notre approche est de récolter tous les n-grammes (n ≤ 3) dans les données
du corpus d’apprentissage et de calculer un score représentant leur saillance dans le segment dans lequel
le n-gramme apparaı̂t, ce qui la rattache à la composante bottom-up de l’analyse du discours présentée
dans (Biber et al., 2007). Nous utilisons le log odds ratio (Everitt, 1992) comme mesure statistique de la
saillance d’un n-gramme. Le log odds ratio compare la fréquence d’occurrence de chaque n-gramme dans
un corpus spécialisé à sa fréquence d’occurrence dans un corpus de référence :
log odds ratio = ln(ad/cb) = ln(a) + ln(d)− ln(c)− ln(b)
où a est la fréquence du mot dans le corpus spécialisé, b est la taille du corpus spécialisé moins a, c est
la fréquence du mot dans le corpus général et d est la taille du corpus général moins c. Une grande valeur
de saillance positive indique une saillance forte, alors qu’une grande valeur négative indique un mot sans
importance pour le segment. Nous avons construit quatre corpus spécialisés, un pour chacun des quatre
segments (opener, closer, harengue or peroration) et un pour les mots qui n’appartiennent à aucun segment
(free). Nous avons adopté le corpus Tycho Brahé2 comme corpus de référence. La comparaison avec un
corpus de reférence permet non seulement de comparer les classes entre elles, mais aussi de les situer par
rapport à un discours neutre. Notons qu’il existe d’autres mesures de comparaison de fréquences (Frantzi
et al., 2000). Le corpus Tycho Brahé constitue un bon étalon de référence pour trois raisons principales :
1. Il est assez varié selon les genres tandis que CARDS ne dispose que de lettres privées.
2http://www.tycho.iel.unicamp.br/̃tycho/corpus/en/index.html
SEGMENTATION AUTOMATIQUE DE LETTRES HISTORIQUES
Corpus Nb textes 1-gramme 2-gramme 3-gramme Nb segments Nb mots/segment
référence 44 1508386 1268345 1052225 - -
opener 275 1366 1077 815 275 5.3
closer 343 4070 3585 3141 343 13.6
harengue 121 2788 2597 2408 124 25.6
peroration 231 3223 2890 2582 266 15.4
free 402 111745 105921 100242 - -
TAB. 1 – Corpus de Référence et Spécialisés
Segment 2-gramme 3-gramme
opener Exmo Snr ‘Très Excellent Mr’ 12.7 Illmo e Exmo ‘Très Illustre et Excellent’ 12.9
closer De V ‘De Vous’ 11.2 De V Exa ‘De Votre Excellence’ 10.8
harengue saude q ‘santé que’ 10.1 da q me ‘de la que me’ 8.6
peroration gde a ‘garde à’ 13.0 Ds gde a ‘Dieu garde à’ 11.6
TAB. 2 – 2-grammes et 3-grammes les plus saillants
2. Il est presque entièrement constitué par des échantillons du portugais littéraire formel de l’ère mo-
derne ; en revanche, le corpus CARDS est assez varié tant en termes de registre (formel et informel)
que de représentativité sociale.
3. Il a été en partie normalisé en fonction de l’orthographe tandis que CARDS maintient systématiquement
l’orthographe des manuscrits originaux3.
Nos 402 lettres servant à l’apprentissage ont été utilisées pour créer les corpus spécialisés en concaténant,
pour chaque lettre, tous les mots appartenant à un segment particulier, en préservant la ponctuation et les
limites des segments de telle sorte qu’aucun n mots consécutifs ne peut appartenir à différentes phrases ou
segments. Ces corpus d’apprentissage sont décrits dans le tableau 1. Les saillances pour chaque n-gramme
ont ensuite été calculées et triées du plus grand au plus petit. Dans le tableau 2, nous affichons pour chaque
segment le 2-gramme et le 3-gramme le plus saillant ainsi que sa valeur de saillance.
2.2 Classer chaque mot
Les listes de n-grammes avec des valeurs de saillance pour chaque segment constituent nos modèles lexi-
caux pour notre classificateur. Pour savoir à quel segment un mot appartient, le classificateur adopte la
stratégie en deux étapes suivante :
1. On attribue à chaque 1-gramme les valeurs de saillance pour chaque segment que l’on peut trouver
dans les modèles, zéro sinon ;
2. Chaque mot d’un n-gramme (n ∈ (2,3)) voit sa valeur de saillance augmentée par la valeur de
saillance correspondant aux n-grammes dans les modèles, si elles existent.
La stratégie ci-dessus peut être limitée à un sous-ensemble d’un, deux ou trois modèles. Par conséquent,
chaque mot a une valeur de saillance pour chaque segment, et peut prendre en compte des informa-
3Nous avons inclu des textes de référence non normalisés pour éviter de se retrouver avec un corpus de référence trop petit.
GÉNÉREUX, MARQUILHAS, HENDRICKX
n-gramme F-scores % Exactitude
utilisé(s) opener harengue peroration closer générale %
{1} 4 15 6 25 53
{2} 9 20 8 33 62
{3} 30 16 14 24 88
{1,2} 5 14 8 25 47
{1,3} 4 18 8 29 53
{2,3} 9 21 8 35 63
{1,2,3} 5 15 9 26 47
TAB. 3 – F-scores et exactitudes pour la classification des mots
tions contextuelles (si les modèles supérieurs à 1-gramme ont été inclus dans le procédé de calcul décrit
précédemment). Le segment final est celui correspondant à la saillance la plus élevée, diminuée de la
valeur de la saillance des autres classes. L’évaluation sur 100 lettres sont présentés dans le tableau 3.
2.3 Production de segments
L’approche précédente pour classer les mots d’une lettre sur une base individuelle ne peut pas toujours pro-
duire des regroupements d’étiquettes continus semblables à de vrais segments, il y a donc inévitablement
des discontinuités entre des groupes de mots distants ayant la même étiquette. Regardons l’exemple sui-
vant4, où l’indice5 indique une étiquette proposée par le classifieur et où les balises indiquent la vraie
classe telle qu’annotée par les humains.
<opener> Meoo amoo ec Sro </opener> <harengue>Aindac qh VMf meh nãoh querh
darh oc alivioh deh suash novash ah minhah amizadeh nãoh pideh talh discuidoc eh assih
lembresseh VMh deo mimf qh comh novash suash qh bemh sabeh qf nãoh temh qmp lhash
dezejeh comh maish verasp . </harengue> Sabadof novef destef mesf . . . porf nãof ficarf
comf escrupellof <peroration> aquip ficop ásh ordensp dep VMp pap of qp mep quizerp
mandarp comf gdep vontadep Dsp gdep ap VMp </peroration> <closer> Pradaf 10f def
Julhoc dec 1712f Mayorf Amoc ec Servidorc def VMc Frandof dec Sáf Menezesf </closer>
Bien que les patrons d’étiquettes calculés suivent à peu près l’annotation «vraie», une technique de lissage
pourrait être appliquée pour tenter de rattacher les ilôts d’étiquettes disparates et de créer des segments
proches de ceux créés par des annotateurs humains. Pour obtenir un lissage des patrons «segmentaires»
obtenus par l’étiquetage automatique de chaque mot individuellement, nous choisissons un intervalle pour
la longueur de chaque segment de telle sorte que 95% des valeurs moyennes (pour la longueur) se trouvent
dans cette intervalle. Ceci est donné dans la distribution normale par le calcul (moyenne∓ 2 * écart-type)6.
4Traduction française : <opener> Mon ami et Seigneur </opener> <harengue>Bien que votre Grâce ne veut pas me
soulager avec des nouvelles de votre Grâce, mon amitié ne demande pas un tel manque d’attention, alors, accordez votre Grâce
de moi avec vos nouvelles, parce que vous savez bien qu’il n’y a personne à les désirer plus que moi, vraiment </harengue>
Le Samedi 9 de ce mois . . . de ne pas avoir des scrupules <peroration>ici je reste aux ordres de votre Grâce pour ce que votre
Grâce le veuille ordonner, de toute ma volonté, Dieu garde à votre Grâce </peroration><closer> Prada, le 10 juillet de 1712
Le plus grand ami et serviteur de votre Grâce Fernando de Sá Menezes </closer>
5o=opener, c=closer, h=harengue, p=peroration and f=free
6Nous avons calculé la moyenne et l’écart-type à partir des données d’apprentissage.
SEGMENTATION AUTOMATIQUE DE LETTRES HISTORIQUES
n-gramme F-scores % Exactitude
utilisé(s) opener harengue peroration closer générale %
{1} 2 10 4 35 26
{2} 6 26 6 41 33
{3} 31 23 12 28 79
{1,2} 2 14 6 31 25
{1,3} 2 21 7 38 27
{2,3} 7 31 6 41 33
{1,2,3} 3 15 7 32 26
TAB. 4 – F-scores et exactitudes pour chaque mot après la production de segments
On obtient donc les valeurs d’intervalles suivantes : [1,15] pour opener, [1,60] pour harengue, [1,43] pour
peroration et [1,28] pour closer. Cela signifie que nous allons examiner seulement les opener dont la taille
varie entre 1 et 15 mots, etc.
À partir du premier mot de chaque lettre historique, on calcule un score pour chaque segment de chacune
des quatre classes, compte tenu de la longueur des intervalles définis précédemment pour chaque segment.
Les scores de chaque segment sont obtenus en retenant la classe pour laquelle la somme S des scores de
chaque mot dans le segment est la plus élevée. En d’autres termes, un segment de N mots consécutifs est
susceptible d’être étiqueté avec la classe C si elle a beaucoup de mots avec des valeurs de saillance élevées
pour C. Nous conservons les segments au-dessus d’un certain seuil pour S et qui ne se chevauchent pas.
L’évaluation de ce classificateur utilisant la même métrique que dans la section 2.2 sont indiqués dans le
tableau 4.
2.4 Remarques
Bien que l’exactitude du classifieur soit nettement supérieure à celle d’une base aléatoire (cinq classes⇒
20%), les valeurs pour les F-scores indiquées dans les tableaux 3 et 4 concernant les mots appartenant à
l’un des quatre segments d’intérêt sont décevantes mais pas surprenantes : les lettres historiques présentent
en effet un grand nombre de variantes orthographiques. Nous avions également à notre disposition un
corpus d’apprentissage plutôt petit (402 textes). Néanmoins, nous pensons que notre approche basée sur la
fréquence de comparaison des n-grammes et de lissage pour la création de véritables segments est un bon
point de départ. Les résultats présentés dans les tableaux 3 et 4 nous permettent également de formuler
trois observations intéressantes :
– Les 3-grammes et 2-grammes permettent d’établir une meilleure discrimination entre les quatre classes.
– Harengue et closer sont les classes qui peuvent être le plus facilement discriminées.
– Le lissage pour produire des segments plus réalistes permet d’améliorer la classification de chaque mot
dans le cas de harengue et closer.
D’autre part, l’analyse des n-grammes les plus saillants nous a permis de faire les constatations suivantes :
– opener : la sémantique du respect social exprimé par des formes de courtoisie nominales (ce qui équivaut
à Très Excellent Monsieur)
– harengue : la sémantique de la santé, combinée avec des verbes psychologiques et des expressions
phatiques, typique des formules de souhaits dans les débuts de dialogue (équivalent à J’espère que vous
GÉNÉREUX, MARQUILHAS, HENDRICKX
êtes en bonne santé)
– peroration : la sémantique de la religion, aussi combinée avec des expressions phatiques, typique de
l’invocation de Dieu dans les fins de dialogue (l’équivalent de Que Dieu soit avec vous)
– closer : de nouveau la sémantique du respect social, exprimée ici par des formes adjectivales et nomi-
nales d’autodérision (équivalent à Je suis votre humble serviteur).
Notons que pour évaluer spécifiquement notre modèle lexical, nous avons préféré ne pas exploiter l’infor-
mation relative au positionnement normal des segments dans les textes. Finalement, nous avons l’intention
d’évaluer notre système avec des mesures classiques en segmentation (Sitbon & Bellot, 2006).
3 Conclusion
Nous avons présenté une étude visant à segmenter automatiquement des lettres historiques selon quatre
classes. Étant donné l’absence d’outils permettant d’extraire des informations linguistiques sur lequel
s’appuyer, nous avons adopté une approche essentiellement statistique, sur la base de modèles lexicaux et
d’une comparaison fréquentielle avec un corpus de référence, ce qui nous a permis de voir les limites d’une
telle approche, mais aussi de faire une analyse résolument objective de certaines caractéristiques des textes
anciens. Nous pensons qu’avec l’assistance d’outils permettant l’acquisition d’information linguistique,
les performances d’une telle approche peuvent être grandement améliorées.
De façon plus générale, le traitement informatisé des données historiques, tels que les lettres des sociétés
du passé, permet d’établir une base de comparaison avec des échantillons comparables contemporains. Au
cours du XXe siècle, des millions de lettres ont été écrites dans les sociétés occidentales, et certaines de
ces lettres ont survécu. En termes d’étude du changement linguistique et social, des éléments de preuve
comparables provenant du passé et du présent sont nécessaires, et la technologie informatique semble être
un outil indispensable pour la réalisation de cet objectif.
Références
BIBER D., CONNER U. & UPTON T. (2007). Discourse on the move : Using corpus analysis to describe
discourse structure. Amsterdam : John Benjamins.
EVERITT B. (1992). The Analysis of Contingency Tables. Chapman and Hall, 2nd edition.
FERRET O. (2002). Segmenter et structurer thématiquement des textes par l’utilisation conjointe de
collocations et de la récurrence lexicale. In TALN 2002, Nancy.
FRANTZI K., ANANIADOU S. & MIMA H. (2000). Automatic recognition of multi-word terms : the
C-value/NC-value Method. International Journal on Digital Libraries, 3(2), 115–130.
HEARST M. A. (1997). TextTiling : Segmenting text into multi-paragraph subtopic passages. Comput.
Linguist., 23(1), 33–64.
SITBON L. & BELLOT P. (2006). Tools and methods for objective or contextual evaluation of topic
segmentation. In Proceedings of Language Resources and Evaluation (LREC) 2006.
SPORLEDER C. & LAPATA M. (2006). Broad coverage paragraph segmentation across languages and
domains. ACM Trans. Speech Lang. Process., 3(2), 1–35.
