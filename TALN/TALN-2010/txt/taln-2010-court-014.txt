TALN 2010, Montre«al, 19Ð23 juillet 2010
Segmentation Automatique de Lettres Historiques
Michel Ge«ne«reux, Rita Marquilhas, Iris Hendrickx
Centro de Linguõ«stica da Universidade de Lisboa
Av. Prof. Gama Pinto, 2
1649-003 Lisboa - Portugal
Re«sume«. Cet article pre«sente une approche base«e sur la comparaison fre«quentielle de mode`les lexi-
caux pour la segmentation automatique de textes historiques Portugais. Cette approche traite dÕabord le
proble`me de la segmentation comme un proble`me de classification, en attribuant a` chaque e«le«ment lexical
pre«sent dans la phase dÕapprentissage une valeur de saillance pour chaque type de segment. Ces mode`les
lexicaux permettent a` la fois de produire une segmentation et de faire une analyse qualitative de textes
historiques. Notre e«valuation montre que lÕapproche adopte«e permet de tirer de lÕinformation se«mantique
que des approches se concentrant sur la de«tection des frontie`res se«parant les segments ne peuvent acque«rir.
Abstract. This article presents an approach based on the frequency comparison of lexical models for
the automatic segmentation of historical texts. This approach first addresses the problem of segmentation
as a classification problem by assigning each token present in the learning phase a value of salience for each
type of segment. These lexical patterns can both produce a segmentation and make possible a qualitative
analysis of historical texts. Our evaluation shows that the approach can extract semantic information that
approaches focusing on the detection of boundaries between segments cannot capture.
Mots-cle«s : Corpus comparables, Saillance, Segmentation, Textes historiques.
Keywords: Comparable corpora, Salience, Segmentation, Historical Texts.
1 Introduction
Dans le projet CARDS1, des lettres prive«es allant du 16ie`me jusquÕau 19ie`me sie`cle au Portugal sont trans-
crites manuellement. Le corpus CARDS est e«tiquete« textuellement pour identifier les formules dÕouver-
ture (opening) et de fermeture (closing), dÕexorde (harengue) et de conclusion ou pe«roraison (peroration).
Dans lÕe«tude pre«sente«e ici, le but est de re«duire la charge de travail manuel par le traitement automatique
des corpus en ce qui concerne la segmentation afin de produire une e«dition critique e«lectronique et une
interpre«tation historique et linguistique des lettres. Ce papier pre«sente donc un travail dont le but est de seg-
menter automatiquement des lettres faisant partie dÕun corpus historique, en les se«parant en cinq parties,
le corps de la lettre et quatre parties formelles identifie«es par les historiens (ouverture, exorde, conclusion
et cloöture). Le mode`le choisi est purement lexical, chaque mot e«tant classifie« en une de ces cinq classes
pour indiquer quÕil appartient a` une partie ou a` une autre. Des scores dÕassociations de n-grammes (pour
n=1,2 et 3) sont calcule«s pour choisir la classe dÕun mot donne«.
1http://alfclul.clul.ul.pt/cards-fly
GE«NE«REUX, MARQUILHAS, HENDRICKX
2 Segmentation des Textes
La segmentation de lettres historiques est une taöche difficile parce que les outils qui nous permettent
normalement dÕextraire des informations significatives a` partir du lexique des lettres (cate«gories gramma-
ticales, lemmes) nÕexistent tout simplement pas. Par conse«quent, il faut sÕappuyer sur les formes dites de
ÇsurfaceÈ du mot (le lexis), ce qui repre«sente une se«rieuse limitation sur la capacite« des outils automa-
tiques de faire des ge«ne«ralisations utiles. Par exemple, les noms propres sont plus informatifs comme une
cate«gorie que comme un mot, puisque le nom propre lui-meöme nÕa pas tendance a` re«apparaõötre dans les
textes. Nous avons tout de meöme fait une tentative pour e«tiqueter les noms propres sur la base dÕune liste
ad hoc de 6923 noms portugais provenant de diverses sources locales et en ligne. Les lemmes sont aussi
utiles parce que la meöme information se«mantique peut eötre capture«e dans un lemme unique, qui peut eötre
instancie« sous plusieurs formes au travers des mots dans les textes. Un sous-ensemble de 402 textes pour la
phase dÕapprentissage et 100 textes pour la phase de test ont e«te« choisis au hasard dans le corpus CARDS.
2.1 Cre«ation des mode`les lexicaux
La taöche de segmentation consiste a` attribuer a` chaque mot (1-gramme) des lettres historiques un seul des
quatre e«tiquettes/segments (opener, harengue, peroration ou closer) disponibles. Il est e«galement possible
quÕaucune e«tiquette ne soit attribue«e a` un mot (free). Contrairement a` dÕautres approches (Sporleder & La-
pata, 2006) qui utilisent une varie«te« de bases de connaissances (indicateurs textuels, information relie«e a`
la syntaxe et au discours) ou cherchent a` identifier les patrons lexicaux permettant dÕidentifier les change-
ments de the`mes (Hearst, 1997; Ferret, 2002), nous nous appuyons sur des mode`les lexicaux pour chacune
des classes que nous cherchons a` identifier, ce qui a lÕavantage de produire du meöme coup un vocabu-
laire pour chaque segment. Notre approche est de re«colter tous les n-grammes (n ² 3) dans les donne«es
du corpus dÕapprentissage et de calculer un score repre«sentant leur saillance dans le segment dans lequel
le n-gramme apparaõöt, ce qui la rattache a` la composante bottom-up de lÕanalyse du discours pre«sente«e
dans (Biber et al., 2007). Nous utilisons le log odds ratio (Everitt, 1992) comme mesure statistique de la
saillance dÕun n-gramme. Le log odds ratio compare la fre«quence dÕoccurrence de chaque n-gramme dans
un corpus spe«cialise« a` sa fre«quence dÕoccurrence dans un corpus de re«fe«rence :
log odds ratio = ln(ad/cb) = ln(a) + ln(d)? ln(c)? ln(b)
ou` a est la fre«quence du mot dans le corpus spe«cialise«, b est la taille du corpus spe«cialise« moins a, c est
la fre«quence du mot dans le corpus ge«ne«ral et d est la taille du corpus ge«ne«ral moins c. Une grande valeur
de saillance positive indique une saillance forte, alors quÕune grande valeur ne«gative indique un mot sans
importance pour le segment. Nous avons construit quatre corpus spe«cialise«s, un pour chacun des quatre
segments (opener, closer, harengue or peroration) et un pour les mots qui nÕappartiennent a` aucun segment
(free). Nous avons adopte« le corpus Tycho Brahe«2 comme corpus de re«fe«rence. La comparaison avec un
corpus de refe«rence permet non seulement de comparer les classes entre elles, mais aussi de les situer par
rapport a` un discours neutre. Notons quÕil existe dÕautres mesures de comparaison de fre«quences (Frantzi
et al., 2000). Le corpus Tycho Brahe« constitue un bon e«talon de re«fe«rence pour trois raisons principales :
1. Il est assez varie« selon les genres tandis que CARDS ne dispose que de lettres prive«es.
2http://www.tycho.iel.unicamp.br/÷tycho/corpus/en/index.html
SEGMENTATION AUTOMATIQUE DE LETTRES HISTORIQUES
Corpus Nb textes 1-gramme 2-gramme 3-gramme Nb segments Nb mots/segment
re«fe«rence 44 1508386 1268345 1052225 - -
opener 275 1366 1077 815 275 5.3
closer 343 4070 3585 3141 343 13.6
harengue 121 2788 2597 2408 124 25.6
peroration 231 3223 2890 2582 266 15.4
free 402 111745 105921 100242 - -
TAB. 1 Ð Corpus de Re«fe«rence et Spe«cialise«s
Segment 2-gramme 3-gramme
opener Exmo Snr ÔTre`s Excellent MrÕ 12.7 Illmo e Exmo ÔTre`s Illustre et ExcellentÕ 12.9
closer De V ÔDe VousÕ 11.2 De V Exa ÔDe Votre ExcellenceÕ 10.8
harengue saude q Ôsante« queÕ 10.1 da q me Ôde la que meÕ 8.6
peroration gde a Ôgarde a`Õ 13.0 Ds gde a ÔDieu garde a`Õ 11.6
TAB. 2 Ð 2-grammes et 3-grammes les plus saillants
2. Il est presque entie`rement constitue« par des e«chantillons du portugais litte«raire formel de lÕe`re mo-
derne ; en revanche, le corpus CARDS est assez varie« tant en termes de registre (formel et informel)
que de repre«sentativite« sociale.
3. Il a e«te« en partie normalise« en fonction de lÕorthographe tandis que CARDS maintient syste«matiquement
lÕorthographe des manuscrits originaux3.
Nos 402 lettres servant a` lÕapprentissage ont e«te« utilise«es pour cre«er les corpus spe«cialise«s en concate«nant,
pour chaque lettre, tous les mots appartenant a` un segment particulier, en pre«servant la ponctuation et les
limites des segments de telle sorte quÕaucun n mots conse«cutifs ne peut appartenir a` diffe«rentes phrases ou
segments. Ces corpus dÕapprentissage sont de«crits dans le tableau 1. Les saillances pour chaque n-gramme
ont ensuite e«te« calcule«es et trie«es du plus grand au plus petit. Dans le tableau 2, nous affichons pour chaque
segment le 2-gramme et le 3-gramme le plus saillant ainsi que sa valeur de saillance.
2.2 Classer chaque mot
Les listes de n-grammes avec des valeurs de saillance pour chaque segment constituent nos mode`les lexi-
caux pour notre classificateur. Pour savoir a` quel segment un mot appartient, le classificateur adopte la
strate«gie en deux e«tapes suivante :
1. On attribue a` chaque 1-gramme les valeurs de saillance pour chaque segment que lÕon peut trouver
dans les mode`les, ze«ro sinon ;
2. Chaque mot dÕun n-gramme (n ? (2,3)) voit sa valeur de saillance augmente«e par la valeur de
saillance correspondant aux n-grammes dans les mode`les, si elles existent.
La strate«gie ci-dessus peut eötre limite«e a` un sous-ensemble dÕun, deux ou trois mode`les. Par conse«quent,
chaque mot a une valeur de saillance pour chaque segment, et peut prendre en compte des informa-
3Nous avons inclu des textes de re«fe«rence non normalise«s pour e«viter de se retrouver avec un corpus de re«fe«rence trop petit.
GE«NE«REUX, MARQUILHAS, HENDRICKX
n-gramme F-scores % Exactitude
utilise«(s) opener harengue peroration closer ge«ne«rale %
{1} 4 15 6 25 53
{2} 9 20 8 33 62
{3} 30 16 14 24 88
{1,2} 5 14 8 25 47
{1,3} 4 18 8 29 53
{2,3} 9 21 8 35 63
{1,2,3} 5 15 9 26 47
TAB. 3 Ð F-scores et exactitudes pour la classification des mots
tions contextuelles (si les mode`les supe«rieurs a` 1-gramme ont e«te« inclus dans le proce«de« de calcul de«crit
pre«ce«demment). Le segment final est celui correspondant a` la saillance la plus e«leve«e, diminue«e de la
valeur de la saillance des autres classes. LÕe«valuation sur 100 lettres sont pre«sente«s dans le tableau 3.
2.3 Production de segments
LÕapproche pre«ce«dente pour classer les mots dÕune lettre sur une base individuelle ne peut pas toujours pro-
duire des regroupements dÕe«tiquettes continus semblables a` de vrais segments, il y a donc ine«vitablement
des discontinuite«s entre des groupes de mots distants ayant la meöme e«tiquette. Regardons lÕexemple sui-
vant4, ou` lÕindice5 indique une e«tiquette propose«e par le classifieur et ou` les balises indiquent la vraie
classe telle quÕannote«e par les humains.
<opener> Meoo amoo ec Sro </opener> <harengue>Aindac qh VMf meh na÷oh querh
darh oc alivioh deh suash novash ah minhah amizadeh na÷oh pideh talh discuidoc eh assih
lembresseh VMh deo mimf qh comh novash suash qh bemh sabeh qf na÷oh temh qmp lhash
dezejeh comh maish verasp . </harengue> Sabadof novef destef mesf . . . porf na÷of ficarf
comf escrupellof <peroration> aquip ficop a«sh ordensp dep VMp pap of qp mep quizerp
mandarp comf gdep vontadep Dsp gdep ap VMp </peroration> <closer> Pradaf 10f def
Julhoc dec 1712f Mayorf Amoc ec Servidorc def VMc Frandof dec Sa«f Menezesf </closer>
Bien que les patrons dÕe«tiquettes calcule«s suivent a` peu pre`s lÕannotation ÇvraieÈ, une technique de lissage
pourrait eötre applique«e pour tenter de rattacher les iloöts dÕe«tiquettes disparates et de cre«er des segments
proches de ceux cre«e«s par des annotateurs humains. Pour obtenir un lissage des patrons ÇsegmentairesÈ
obtenus par lÕe«tiquetage automatique de chaque mot individuellement, nous choisissons un intervalle pour
la longueur de chaque segment de telle sorte que 95% des valeurs moyennes (pour la longueur) se trouvent
dans cette intervalle. Ceci est donne« dans la distribution normale par le calcul (moyenne? 2 * e«cart-type)6.
4Traduction francüaise : <opener> Mon ami et Seigneur </opener> <harengue>Bien que votre Graöce ne veut pas me
soulager avec des nouvelles de votre Graöce, mon amitie« ne demande pas un tel manque dÕattention, alors, accordez votre Graöce
de moi avec vos nouvelles, parce que vous savez bien quÕil nÕy a personne a` les de«sirer plus que moi, vraiment </harengue>
Le Samedi 9 de ce mois . . . de ne pas avoir des scrupules <peroration>ici je reste aux ordres de votre Graöce pour ce que votre
Graöce le veuille ordonner, de toute ma volonte«, Dieu garde a` votre Graöce </peroration><closer> Prada, le 10 juillet de 1712
Le plus grand ami et serviteur de votre Graöce Fernando de Sa« Menezes </closer>
5o=opener, c=closer, h=harengue, p=peroration and f=free
6Nous avons calcule« la moyenne et lÕe«cart-type a` partir des donne«es dÕapprentissage.
SEGMENTATION AUTOMATIQUE DE LETTRES HISTORIQUES
n-gramme F-scores % Exactitude
utilise«(s) opener harengue peroration closer ge«ne«rale %
{1} 2 10 4 35 26
{2} 6 26 6 41 33
{3} 31 23 12 28 79
{1,2} 2 14 6 31 25
{1,3} 2 21 7 38 27
{2,3} 7 31 6 41 33
{1,2,3} 3 15 7 32 26
TAB. 4 Ð F-scores et exactitudes pour chaque mot apre`s la production de segments
On obtient donc les valeurs dÕintervalles suivantes : [1,15] pour opener, [1,60] pour harengue, [1,43] pour
peroration et [1,28] pour closer. Cela signifie que nous allons examiner seulement les opener dont la taille
varie entre 1 et 15 mots, etc.
A` partir du premier mot de chaque lettre historique, on calcule un score pour chaque segment de chacune
des quatre classes, compte tenu de la longueur des intervalles de«finis pre«ce«demment pour chaque segment.
Les scores de chaque segment sont obtenus en retenant la classe pour laquelle la somme S des scores de
chaque mot dans le segment est la plus e«leve«e. En dÕautres termes, un segment de N mots conse«cutifs est
susceptible dÕeötre e«tiquete« avec la classe C si elle a beaucoup de mots avec des valeurs de saillance e«leve«es
pour C. Nous conservons les segments au-dessus dÕun certain seuil pour S et qui ne se chevauchent pas.
LÕe«valuation de ce classificateur utilisant la meöme me«trique que dans la section 2.2 sont indique«s dans le
tableau 4.
2.4 Remarques
Bien que lÕexactitude du classifieur soit nettement supe«rieure a` celle dÕune base ale«atoire (cinq classes?
20%), les valeurs pour les F-scores indique«es dans les tableaux 3 et 4 concernant les mots appartenant a`
lÕun des quatre segments dÕinte«reöt sont de«cevantes mais pas surprenantes : les lettres historiques pre«sentent
en effet un grand nombre de variantes orthographiques. Nous avions e«galement a` notre disposition un
corpus dÕapprentissage plutoöt petit (402 textes). Ne«anmoins, nous pensons que notre approche base«e sur la
fre«quence de comparaison des n-grammes et de lissage pour la cre«ation de ve«ritables segments est un bon
point de de«part. Les re«sultats pre«sente«s dans les tableaux 3 et 4 nous permettent e«galement de formuler
trois observations inte«ressantes :
Ð Les 3-grammes et 2-grammes permettent dÕe«tablir une meilleure discrimination entre les quatre classes.
Ð Harengue et closer sont les classes qui peuvent eötre le plus facilement discrimine«es.
Ð Le lissage pour produire des segments plus re«alistes permet dÕame«liorer la classification de chaque mot
dans le cas de harengue et closer.
DÕautre part, lÕanalyse des n-grammes les plus saillants nous a permis de faire les constatations suivantes :
Ð opener : la se«mantique du respect social exprime« par des formes de courtoisie nominales (ce qui e«quivaut
a` Tre`s Excellent Monsieur)
Ð harengue : la se«mantique de la sante«, combine«e avec des verbes psychologiques et des expressions
phatiques, typique des formules de souhaits dans les de«buts de dialogue (e«quivalent a` JÕespe`re que vous
GE«NE«REUX, MARQUILHAS, HENDRICKX
eötes en bonne sante«)
Ð peroration : la se«mantique de la religion, aussi combine«e avec des expressions phatiques, typique de
lÕinvocation de Dieu dans les fins de dialogue (lÕe«quivalent de Que Dieu soit avec vous)
Ð closer : de nouveau la se«mantique du respect social, exprime«e ici par des formes adjectivales et nomi-
nales dÕautode«rision (e«quivalent a` Je suis votre humble serviteur).
Notons que pour e«valuer spe«cifiquement notre mode`le lexical, nous avons pre«fe«re« ne pas exploiter lÕinfor-
mation relative au positionnement normal des segments dans les textes. Finalement, nous avons lÕintention
dÕe«valuer notre syste`me avec des mesures classiques en segmentation (Sitbon & Bellot, 2006).
3 Conclusion
Nous avons pre«sente« une e«tude visant a` segmenter automatiquement des lettres historiques selon quatre
classes. E«tant donne« lÕabsence dÕoutils permettant dÕextraire des informations linguistiques sur lequel
sÕappuyer, nous avons adopte« une approche essentiellement statistique, sur la base de mode`les lexicaux et
dÕune comparaison fre«quentielle avec un corpus de re«fe«rence, ce qui nous a permis de voir les limites dÕune
telle approche, mais aussi de faire une analyse re«solument objective de certaines caracte«ristiques des textes
anciens. Nous pensons quÕavec lÕassistance dÕoutils permettant lÕacquisition dÕinformation linguistique,
les performances dÕune telle approche peuvent eötre grandement ame«liore«es.
De facüon plus ge«ne«rale, le traitement informatise« des donne«es historiques, tels que les lettres des socie«te«s
du passe«, permet dÕe«tablir une base de comparaison avec des e«chantillons comparables contemporains. Au
cours du XXe sie`cle, des millions de lettres ont e«te« e«crites dans les socie«te«s occidentales, et certaines de
ces lettres ont surve«cu. En termes dÕe«tude du changement linguistique et social, des e«le«ments de preuve
comparables provenant du passe« et du pre«sent sont ne«cessaires, et la technologie informatique semble eötre
un outil indispensable pour la re«alisation de cet objectif.
Re«fe«rences
BIBER D., CONNER U. & UPTON T. (2007). Discourse on the move : Using corpus analysis to describe
discourse structure. Amsterdam : John Benjamins.
EVERITT B. (1992). The Analysis of Contingency Tables. Chapman and Hall, 2nd edition.
FERRET O. (2002). Segmenter et structurer the«matiquement des textes par lÕutilisation conjointe de
collocations et de la re«currence lexicale. In TALN 2002, Nancy.
FRANTZI K., ANANIADOU S. & MIMA H. (2000). Automatic recognition of multi-word terms : the
C-value/NC-value Method. International Journal on Digital Libraries, 3(2), 115Ð130.
HEARST M. A. (1997). TextTiling : Segmenting text into multi-paragraph subtopic passages. Comput.
Linguist., 23(1), 33Ð64.
SITBON L. & BELLOT P. (2006). Tools and methods for objective or contextual evaluation of topic
segmentation. In Proceedings of Language Resources and Evaluation (LREC) 2006.
SPORLEDER C. & LAPATA M. (2006). Broad coverage paragraph segmentation across languages and
domains. ACM Trans. Speech Lang. Process., 3(2), 1Ð35.
