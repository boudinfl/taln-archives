TALN 2010, Montréal, 19-23 juillet 2010

Segmentation Automatique de Lettres Historiques

Michel Généreux, Rita Marquilhas, Iris Hendrickx
Centro de Linguistica da Universidade de Lisboa
Av. Prof. Gama Pinto, 2
1649-003 Lisboa - Portugal

Résumé. Cet article présente une approche basée sur la comparaison fréquentielle de modeles lexi-
caux pour la segmentation automatique de textes historiques Portugais. Cette approche traite d’abord le
probleme de la segmentation comme un probleme de classiﬁcation, en attribuant a chaque élément lexical
présent dans la phase d’apprentissage une valeur de saillance pour chaque type de segment. Ces modeles
lexicaux permettent a la fois de produire une segmentation et de faire une analyse qualitative de textes
historiques. Notre évaluation montre que l’approche adoptée permet de tirer de l’information sémantique
que des approches se concentrant sur la détection des frontieres séparant les segments ne peuvent acquérir.

Abstract. This article presents an approach based on the frequency comparison of lexical models for
the automatic segmentation of historical texts. This approach ﬁrst addresses the problem of segmentation
as a classiﬁcation problem by assigning each token present in the learning phase a value of salience for each
type of segment. These lexical patterns can both produce a segmentation and make possible a qualitative
analysis of historical texts. Our evaluation shows that the approach can extract semantic information that
approaches focusing on the detection of boundaries between segments cannot capture.

M0tS-CléS 2 Corpus comparables, Saillance, Segmentation, Textes historiques.

Keywords: Comparable corpora, Salience, Segmentation, Historical Texts.

1 Introduction

Dans le projet CARDS1, des lettres privées allant du 16ieme jusqu’au 19ieme siecle au Portugal sont trans-
crites manuellement. Le corpus CARDS est étiqueté textuellement pour identiﬁer les formules d’ouver-
ture (opening) et de fermeture (closing), d’exorde (harengue) et de conclusion ou péroraison (peroration).
Dans l’étude présentée ici, le but est de réduire la charge de travail manuel par le traitement automatique
des corpus en ce qui conceme la segmentation aﬁn de produire une édition critique électronique et une
interpretation historique et linguistique des lettres. Ce papier présente donc un travail dont le but est de seg-
menter automatiquement des lettres faisant partie d’un corpus historique, en les séparant en cinq parties,
le corps de la lettre et quatre parties formelles identiﬁées par les historiens (ouverture, exorde, conclusion
et cloture). Le modele choisi est purement lexical, chaque mot étant classiﬁé en une de ces cinq classes
pour indiquer qu’il appartient a une partie ou in une autre. Des scores d’associations de n-grammes (pour
n=1,2 et 3) sont calculés pour choisir la classe d’un mot donné.

lhttp://alfclul.clul.ul.pt/cards—fly

GENEREUX, MARQUILHAS, HENDRICKX

2 Segmentation des Textes

La segmentation de lettres historiques est une tﬁche difﬁcile parce que les outils qui nous permettent
normalement d’extraire des informations signiﬁcatives a partir du lexique des lettres (categories graInma-
ticales, lemmes) n’eXistent tout simplement pas. Par consequent, il faut s’appuyer sur les formes dites de
«surface» du mot (le lexis), ce qui represente une serieuse limitation sur la capacite des outils automa-
tiques de faire des generalisations utiles. Par exemple, les noms propres sont plus informatifs comme une
categorie que comme un mot, puisque le nom propre lui-meme n’a pas tendance a reapparaitre dans les
textes. Nous avons tout de meme fait une tentative pour etiqueter les noms propres sur la base d’une liste
ad hoc de 6923 noms portugais provenant de diverses sources locales et en ligne. Les lemmes sont aussi
utiles parce que la meme information semantique peut etre capturee dans un lemme unique, qui peut etre
instancie sous plusieurs formes au travers des mots dans les textes. Un sous-ensemble de 402 textes pour la
phase d’apprentissage et 100 textes pour la phase de test ont ete choisis au hasard dans le corpus CARDS.

2.1 Création des modeles lexicaux

La teche de segmentation consiste a attribuer a chaque mot (1-gramme) des lettres historiques un seul des
quatre etiquettes/segments (opener, harengue, peroration ou closer) disponibles. Il est egalement possible
qu’aucune etiquette ne soit attribuee a un mot (free). Contrairement a d’autres approches (Sporleder & La-
pata, 2006) qui utilisent une variete de bases de connaissances (indicateurs textuels, information reliee a
la syntaxe et au discours) ou cherchent a identiﬁer les patrons lexicaux permettant d’identiﬁer les change-
ments de themes (Hearst, 1997; Ferret, 2002), nous nous appuyons sur des modeles lexicaux pour chacune
des classes que nous cherchons a identiﬁer, ce qui a l’avantage de produire du meme coup un vocabu-
laire pour chaque segment. Notre approche est de recolter tous les n-graIr1Ines (n 3 3) dans les donnees
du corpus d’apprentissage et de calculer un score representant leur saillance dans le segment dans lequel
le n-gramme apparait, ce qui la rattache a la composante bottom-up de l’analyse du discours presentee
dans (Biber et al., 2007). Nous utilisons le log odds ratio (Everitt, 1992) comme mesure statistique de la
saillance d’un n-gramme. Le log odds ratio compare la frequence d’occurrence de chaque n-gramme dans
un corpus specialise a sa frequence d’occurrence dans un corpus de reference :

log odds ratio = ln(ad/cb) = ln(a) + ln(d) — ln(c) — ln(b)

ou a est la frequence du mot dans le corpus specialise, b est la taille du corpus specialise moins a, c est
la frequence du mot dans le corpus general et d est la taille du corpus general moins c. Une grande valeur
de saillance positive indique une saillance forte, alors qu’une grande valeur negative indique un mot sans
importance pour le segment. Nous avons construit quatre corpus specialises, un pour chacun des quatre
segments (opener, closer, harengue or peroration) et un pour les mots qui n’appartiennent a aucun segment
(free). Nous avons adopte le corpus Tycho Brahe’2 comme corpus de reference. La comparaison avec un
corpus de reference permet non seulement de comparer les classes entre elles, mais aussi de les situer par
rapport a un discours neutre. Notons qu’il existe d’autres mesures de comparaison de frequences (Frantzi
et al., 2000). Le corpus Tycho Brahe constitue un bon etalon de reference pour trois raisons principales :

1. Il est assez varie selon les genres tandis que CARDS ne dispose que de lettres privees.

Zhttp://www.tycho.iel.unicamp.br/~tycho/corpus/en/index.html

SEGMENTATION AUTOMATIQUE DE LETTRES HISTORIQUES

1 Corpus 1 Nb textes 1 1-graInme 1 2-gramme 1 3-graInme 1 Nb segments 1 Nb mots/segment 1

référence 44 1508386 1268345 1052225 - -
opener 275 1366 1077 815 275 5.3

closer 343 4070 3585 3141 343 13.6
harengue 121 2788 2597 2408 124 25.6
peroration 231 3223 2890 2582 266 15.4

free 402 1 1 1745 105921 100242 - -

TAB. 1 — Corpus de Référence et Spécialisés

1 Segment 1 2-gramme 1 3-gramme 1
opener Exmo Snr ‘Tres Excellent Mr’ 12.7 Illmo e Exmo ‘Tres Illustre et Excellent’ 12.9
closer De V ‘De Vous’ 11.2 De VExa ‘De Votre Excellence’ 10.8
harengue saude q ‘santé que’ 10.1 da q me ‘de la que me’ 8.6
peroration gde a ‘garde a’ 13.0 Ds gde a ‘Dieu garde a’ 11.6

TAB. 2 — 2-grammes et 3-grammes les plus saillants

2. Il est presque entierement constitué par des échantillons du portugais littéraire formel de l’ere mo-
derne ; en revanche, le corpus CARDS est assez varié tant en termes de registre (formel et informel)
que de représentativité sociale.

3. II a été en partie normalisé en fonction de l’orthographe tandis que CARDS maintient systématiquement

l’orthographe des manuscrits originaux3.

Nos 402 lettres servant a l’apprentissage ont été utilisées pour créer les corpus spécialisés en concaténant,
pour chaque lettre, tous les mots appartenant a un segment particulier, en préservant la ponctuation et les
limites des segments de telle sorte qu’aucun n mots consécutifs ne peut appartenir a différentes phrases ou
segments. Ces corpus d’apprentissage sont décrits dans le tableau 1. Les saillances pour chaque n-graInme
ont ensuite été calculées et triées du plus grand au plus petit. Dans le tableau 2, nous afﬁchons pour chaque
segment le 2-gramme et le 3-graInme le plus saillant ainsi que sa valeur de saillance.

2.2 Classer chaque mot

Les listes de n-graInmes avec des valeurs de saillance pour chaque segment constituent nos modeles lexi-
caux pour notre classiﬁcateur. Pour savoir a quel segment un mot appartient, le classiﬁcateur adopte la
stratégie en deux étapes suivante :

1. On attribue a chaque 1-graInIne les valeurs de saillance pour chaque segment que l’on peut trouver
dans les modeles, zéro sinon;

2. Chaque mot d’un n-gramme (n 6 (2,3)) voit sa valeur de saillance augmentée par la valeur de
saillance correspondant aux n-graInmes dans les modeles, si elles existent.

La stratégie ci-dessus peut étre limitée a un sous-ensemble d’un, deux ou trois modeles. Par conséquent,
chaque mot a une valeur de saillance pour chaque segment, et peut prendre en compte des informa-

3Nous avons inclu des textes de référence non nonnalisés pour éviter de se retrouver avec un corpus de référence trop petit.

GENEREUX, MARQUILHAS, HENDRICKX

n-gramme F-scores % Exactitude

utilisé(s) opener harengue peroration closer générale %
{1} 4 15 6 25 53
{2} 9 20 8 33 62
{3} 30 16 14 24 88
{1,2} 5 14 8 25 47
{1,3} 4 18 8 29 53
{2,3} 9 21 8 35 63
{1,2,3} 5 15 9 26 47

TAB. 3 — F-scores et exactitudes pour la classiﬁcation des mots

tions contextuelles (si les modeles supérieurs a 1-gramme ont été inclus dans le procédé de calcul décrit
précédemment). Le segment ﬁnal est celui correspondant a la saillance la plus élevée, diminuée de la
valeur de la saillance des autres classes. L’ évaluation sur 100 lettres sont présentés dans le tableau 3.

2.3 Production de segments

L’ approche précédente pour classer les mots d’une lettre sur une base individuelle ne peut pas touj ours pro-
duire des regroupements d’étiquettes continus semblables a de vrais segments, il y a donc inévitablement
des discontinuités entre des groupes de mots distants ayant la meme étiquette. Regardons l’exemple sui-
vant4, ou l’indice5 indique une étiquette proposée par le classiﬁeur et ou les balises indiquent la vraie
classe telle qu’annotée par les humains.

<opener> Meoo amoo ec Sro </opener> <harengue>Aindac qh VMf meh naoh querh
darh oc alivioh deh suash novash ah minhah amizadeh naoh pideh talh discuidoc eh assih
lembresseh VMh deo mimf qh comh novash suash qh bemh sabeh qf naoh temh qmp lhash
dezejeh comh maish verasp . </harengue> Sabadof novef destef mesf . . . porf naof ﬁcarf
comf escrupellof <peroration> aquip ﬁcop ash ordensp dep VMP pap of qp mep quizerp
mandarp comf gdep vontadep Dsp gdep ap VM,, </peroration> <closer> Pradaf 10f def
Julhoc dec 1712f Mayorf Amoc ec Servidorc def VMC Frandof dec Saf Menezesf </closer>

Bien que les patrons d’étiquettes calculés suivent a peu pres l’annotation <<vraie>>, une technique de lissage
pourrait étre appliquée pour tenter de rattacher les ilots d’étiquettes disparates et de créer des segments
proches de ceux créés par des annotateurs humains. Pour obtenir un lissage des patrons <<segmentaires>>
obtenus par l’étiquetage automatique de chaque mot individuellement, nous choisissons un intervalle pour
la longueur de chaque segment de telle sorte que 95% des valeurs moyennes (pour la longueur) se trouvent
dans cette intervalle. Ceci est donné dans la distribution normale par le calcul (moyenne 2|: 2 * écart-type)6.

4Traduction frangaise : <opener> Mon ami et Seigneur </0pener> <harengue>Bien que Votre Grace ne Veut pas me
soulager avec des nouvelles de Votre Grace, mon amitié ne demande pas un tel manque d’attention, alors, accordez Votre Grace
de moi avec Vos nouvelles, parce que Vous savez bien qu’il n’y a personne ales désirer plus que moi, Vraiment </harengue>
Le Samedi 9 de ce mois . . . de ne pas avoir des scrupules <peroration>ici je reste aux ordres de Votre Grace pour ce que Votre
Grace le Veuille ordonner, de toute ma Volonté, Dieu garde a Votre Grace </per0rati0n> <closer> Prada, le 10 juillet de 1712
Le plus grand ami et serviteur de Votre Grace Fernando de sa Menezes </cl0ser>

5o=opener, c=closer, h=harengue, p=peroration and f=free

5Nous avons calculé la moyenne et l’écart—type a partir des données d’apprentissage.

SEGMENTATION AUTOMATIQUE DE LETTRES HISTORIQUES

n- gramme F- scores % Exactitude

utilisé(s) opener harengue peroration closer générale %
{1} 2 10 4 35 26
{2} 6 26 6 41 33
{3} 31 23 12 28 79
{1,2} 2 14 6 31 25
{1,3} 2 21 7 38 27
{2,3} 7 31 6 41 33
{1,2,3} 3 15 7 32 26

TAB. 4 — F-scores et exactitudes pour chaque mot apres la production de segments

On obtient donc les valeurs d’intervalles suivantes : [1,15] pour opener, [1,60] pour harengue, [1,43] pour
peroration et [1,28] pour closer. Cela signiﬁe que nous allons examiner seulement les opener dont la taille
varie entre 1 et 15 mots, etc.

A partir du premier mot de chaque lettre historique, on calcule un score pour chaque segment de chacune
des quatre classes, compte tenu de la longueur des intervalles déﬁnis précédemment pour chaque segment.
Les scores de chaque segment sont obtenus en retenant la classe pour laquelle la somme S des scores de
chaque mot dans le segment est la plus élevée. En d’autres termes, un segment de N mots consécutifs est
susceptible d’étre étiqueté avec la classe C si elle a beaucoup de mots avec des valeurs de saillance élevées
pour C. Nous conservons les segments au-dessus d’un certain seuil pour S et qui ne se chevauchent pas.
L’évaluation de ce classiﬁcateur utilisant la meme métrique que dans la section 2.2 sont indiqués dans le
tableau 4.

2.4 Remarques

Bien que l’exactitude du classiﬁeur soit nettement supérieure a celle d’une base aléatoire (cinq classes =>

20%), les valeurs pour les F-scores indiquées dans les tableaux 3 et 4 concernant les mots appartenant a

l’un des quatre segments d’intérét sont décevantes mais pas surprenantes : les lettres historiques présentent

en effet un grand nombre de variantes orthographiques. Nous avions également a notre disposition un

corpus d’apprentissage plutot petit (402 textes). Néanmoins, nous pensons que notre approche basée sur la

fréquence de comparaison des n-grammes et de lissage pour la création de véritables segments est un bon

point de départ. Les résultats présentés dans les tableaux 3 et 4 nous permettent également de formuler

trois observations intéressantes :

— Les 3-grammes et 2-grammes permettent d’établir une meilleure discrimination entre les quatre classes.

— Harengue et closer sont les classes qui peuvent étre le plus facilement discriminées.

— Le lissage pour produire des segments plus réalistes permet d’améliorer la classiﬁcation de chaque mot
dans le cas de harengue et closer.

D’autre part, l’analyse des n-grammes les plus saillants nous a permis de faire les constatations suivantes :

— opener : la sémantique du respect social exprimé par des formes de courtoisie nominales (ce qui équivaut
a Tres Excellent Monsieur)

— harengue : la sémantique de la santé, combinée avec des verbes psychologiques et des expressions
phatiques, typique des formules de souhaits dans les débuts de dialogue (equivalent a J ’espere que vous

GENEREUX, MARQUILHAS, HENDRICKX

étes en bonne sante’)
- peroration : la sémantique de la religion, aussi combinée avec des expressions phatiques, typique de
l’invocation de Dieu dans les ﬁns de dialogue (l’équivalent de Que Dieu soit avec vous)
- closer : de nouveau la sémantique du respect social, exprimée ici par des formes adjectivales et nomi-
nales d’autodérision (equivalent a Je suis votre humble serviteur).
Notons que pour évaluer spéciﬁquement notre modele lexical, nous avons préféré ne pas exploiter l’infor-
mation relative au positionnement normal des segments dans les textes. Finalement, nous avons l’intention
d’évaluer notre systeme avec des mesures classiques en segmentation (Sitbon & Bellot, 2006).

3 Conclusion

Nous avons présenté une étude visant a segmenter automatiquement des lettres historiques selon quatre
classes. I-’3tant donné l’absence d’outils permettant d’extraire des informations linguistiques sur lequel
s’appuyer, nous avons adopté une approche essentiellement statistique, sur la base de modeles lexicaux et
d’une comparaison fréquentielle avec un corpus de référence, ce qui nous a permis de voir les limites d’une
telle approche, mais aussi de faire une analyse résolument objective de certaines caractéristiques des textes
anciens. Nous pensons qu’avec l’assistance d’outils permettant l’acquisition d’information linguistique,
les performances d’une telle approche peuvent étre grandement améliorées.

De facon plus générale, le traitement informatisé des données historiques, tels que les lettres des sociétés
du passé, permet d’établir une base de comparaison avec des échantillons comparables contemporains. Au
cours du XXe siecle, des millions de lettres ont été écrites dans les sociétés occidentales, et certaines de
ces lettres ont survécu. En termes d’étude du changement linguistique et social, des éléments de preuve
comparables provenant du passé et du présent sont nécessaires, et la technologie informatique semble étre
un outil indispensable pour la réalisation de cet objectif.

Références

BIBER D., CONNER U. & UPTON T. (2007). Discourse on the move .' Using corpus analysis to describe
discourse structure. Amsterdam : John Benjamins.

EVERITT B. (1992). The Analysis of Contingency Tables. Chapman and Hall, 2nd edition.

FERRET O. (2002). Segmenter et structurer thématiquement des textes par l’utilisation conjointe de
collocations et de la récurrence lexicale. In TALN 2002, Nancy.

FRANTZI K., ANANIADOU S. & MIMA H. (2000). Automatic recognition of multi-word terms : the
C-value/NC-value Method. International Journal on Digital Libraries, 3(2), 115-130.

HEARST M. A. (1997). TextTiling : Segmenting text into multi-paragraph subtopic passages. Comput.
Linguist., 23(1), 33-64.

SITBON L. & BELLOT P. (2006). Tools and methods for objective or contextual evaluation of topic
segmentation. In Proceedings of Language Resources and Evaluation (LREC) 2006.

SPORLEDER C. & LAPATA M. (2006). Broad coverage paragraph segmentation across languages and
domains. ACM Trans. Speech Lang. Process., 3(2), 1-35.

