<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>JAWS : Just Another WordNet Subset</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>JAWS : Just Another WordNet Subset
</p>
<p>Claire Mouton1, 2 Ga&#235;l de Chalendar1
</p>
<p>(1) CEA, LIST, Laboratoire Vision et Ing&#233;nierie des Contenus, Fontenay aux Roses,
F-92265, France;
</p>
<p>(2) Exalead, 10 place de la Madeleine, 75008 Paris
claire.mouton@cea.fr, gael.de-chalendar@cea.fr
</p>
<p>R&#233;sum&#233;. WordNet, une des ressources lexicales les plus utilis&#233;es aujourd&#8217;hui a &#233;t&#233; constitu&#233;e en
anglais et les chercheurs travaillant sur d&#8217;autres langues souffrent du manque d&#8217;une telle ressource. Malgr&#233;
les efforts fournis par la communaut&#233; fran&#231;aise, les diff&#233;rents WordNets produits pour la langue fran&#231;aise
ne sont toujours pas aussi exhaustifs que le WordNet de Princeton. C&#8217;est pourquoi nous proposons une
m&#233;thode novatrice dans la production de termes nominaux instanciant les diff&#233;rents synsets de WordNet
en exploitant les propri&#233;t&#233;s syntaxiques distributionnelles du vocabulaire fran&#231;ais. Nous comparons la
ressource que nous obtenons avec WOLF et montrons que notre approche offre une couverture plus large.
</p>
<p>Abstract. WordNet, one of the most used lexical resource until today has been made up for the
English language and scientists working on other languages suffer from the lack of such a resource. Despite
the efforts performed by the French community, the different WordNets produced for the French language
are still not as exhaustive as the original Princeton WordNet. We propose a new approach in the way of
producing nominal terms filling the synset slots. We use syntactical distributional properties of French
vocabulary to determine which of the candidates given by a bilingual dictionary matches the best. We
compare the resource we obtain with WOLF and show that our approach provides a much larger coverage.
</p>
<p>Mots-cl&#233;s : ressources lexicales fran&#231;aises, WordNet, relations s&#233;mantiques, distributions syn-
taxiques.
</p>
<p>Keywords: French lexical resources, WordNet, semantic relations, syntactical distributionality.
</p>
<p>1 Introduction
</p>
<p>La majorit&#233; des ressources lexicales ont d&#8217;abord &#233;t&#233; constitu&#233;es pour l&#8217;anglais. Cependant, les diff&#233;rentes
communaut&#233;s non anglophones ont aussi besoin de telles ressources. Nous nous int&#233;ressons ici &#224; la consti-
tution d&#8217;une version fran&#231;aise du r&#233;seau lexical WordNet de l&#8217;universit&#233; de Princeton (Fellbaum, 1998).
WordNet r&#233;pertorie les mots du vocabulaire en fonction de leur sens et des relations s&#233;mantiques qui lient
ces mots entre eux.
</p>
<p>Il existe d&#233;j&#224; plusieurs tentatives de constitution de WordNet pour le fran&#231;ais telles que celles d&#233;velopp&#233;es
dans les travaux de (Vossen, 1998) ou (WOLF, (Sagot &amp; Fi&#353;er, 2008)) mais aussi pour d&#8217;autres langues
comme les travaux de (Barbu &amp; Barbu Mititelu, 2005) par exemple. Le point le plus d&#233;licat de ces trans-
ferts r&#233;side dans la traduction des mots polys&#233;miques, et c&#8217;est sur ce point particulier que nous souhai-
tons proposer une approche originale. L&#8217;id&#233;e principale est d&#8217;exploiter les propri&#233;t&#233;s des distributions des</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CLAIRE MOUTON, GA&#203;L DE CHALENDAR
</p>
<p>contextes syntaxiques des noms dans un grand corpus afin de caract&#233;riser les relations s&#233;mantiques pr&#233;-
sentes dans WordNet. L&#8217;&#233;valuation de ce type de travaux est difficile puisqu&#8217;il n&#8217;existe pas par d&#233;finition
de v&#233;rit&#233; terrain sur laquelle s&#8217;appuyer. L&#8217;&#233;valuation de notre travail repose d&#8217;une part sur une comparai-
son avec une des pr&#233;c&#233;dentes tentatives de constitution d&#8217;un WordNet fran&#231;ais (WOLF) et d&#8217;autre part sur
une &#233;valuation manuelle.
</p>
<p>2 Travaux pr&#233;c&#233;dents
</p>
<p>Parmi les m&#233;thodes propos&#233;es pr&#233;c&#233;demment pour la constitution de nouvelles versions de WordNet,
deux grandes tendances se d&#233;gagent : les approches par fusion parmi lesquelles se situe l&#8217;approche de
(Kotis et al., 2006) et les approches par extension comme celle propos&#233;e par (Sagot &amp; Fi&#353;er, 2008). Les
approches par fusion consistent &#224; construire des ontologies ind&#233;pendamment et de d&#233;terminer un mapping
avec les WordNet existants a posteriori. L&#8217;avantage d&#8217;une telle approche est que l&#8217;on peut s&#8217;abstraire
de la structure existante de WordNet. Au contraire, les approches par extension font l&#8217;hypoth&#232;se que la
structure du WordNet anglais peut en premi&#232;re approximation &#234;tre reprise dans la langue cible. Il s&#8217;agit
alors de traduire les lex&#232;mes de l&#8217;anglais vers la langue cible. Nous nous pla&#231;ons dans ce cadre.
</p>
<p>Beaucoup de travaux utilisent un dictionnaire bilingue pour y s&#233;lectionner les traductions les plus perti-
nentes selon diverses heuristiques, c&#8217;est le cas de (Barbu &amp; Barbu Mititelu, 2005). La difficult&#233; majeure
d&#8217;une telle traduction est le traitement des termes source polys&#233;miques, qui sont associ&#233;s &#224; plusieurs syn-
sets de WordNet 1. En effet, les traductions donn&#233;es par un dictionnaire ne correspondent pas forc&#233;ment &#224;
tous les synsets d&#8217;un m&#234;me terme, il s&#8217;agit de d&#233;terminer la ou les traduction(s) adapt&#233;e(s) &#224; chaque synset.
Une approche originale de (Sagot &amp; Fi&#353;er, 2008) utilise des corpus parall&#232;les pour lesquels ils effectuent
la d&#233;sambigu&#239;sation du corpus anglais &#224; l&#8217;aide des synsets de WordNet et proposent les mots align&#233;s de la
langue cible comme nouveaux termes. Dans le pr&#233;sent article, nous proposons une m&#233;thode un peu diff&#233;-
rente, qui utilise un dictionnaire bilingue tout en caract&#233;risant les relations s&#233;mantiques du r&#233;seau lexical
par des propri&#233;t&#233;s syntaxiques distributionnelles.
</p>
<p>3 Approche propos&#233;e
</p>
<p>La structure du WordNet de Princeton (PWN) est tout d&#8217;abord reproduite pour la constitution du WordNet
de langue cible. Apr&#232;s une phase d&#8217;extraction des candidats de traduction, chaque heuristique d&#233;finie dans
la suite de cette section est appliqu&#233;e de fa&#231;on it&#233;rative, de sorte que le WordNet cible se remplisse petit &#224;
petit et qu&#8217;&#224; chaque it&#233;ration, de nouvelles informations viennent rendre possible de nouvelles traductions.
Nous ne traitons dans ce travail que des termes et syntagmes nominaux auxquels nous r&#233;f&#233;rerons d&#232;s lors
plus simplement par l&#8217;emploi du mot terme.
</p>
<p>La phase d&#8217;extraction consiste &#224; traduire tous les termes associ&#233;s &#224; un seul synset par toutes les traductions
propos&#233;es par notre dictionnaire bilingue 2. Pour les autres termes et chacun de leurs synsets associ&#233;s,
nous conservons toutes les traductions comme termes cible candidats. La d&#233;sambigu&#239;sation consistera &#224;
</p>
<p>1. Rappelons ici que la structure de WordNet distingue les sens des mots par le regroupement en synsets. Un synset corres-
pond &#224; un ensemble de synonymes associ&#233; &#224; une d&#233;finition. Certains synsets sont reli&#233;s entre eux par des relations s&#233;mantiques.
</p>
<p>2. Nous utilisons la concat&#233;nation du dictionnaire SCI-FRAN-EuRADic (http://catalog.elra.info/product_
info.php?products_id=666&amp;language=fr) et du Wiktionnaire fran&#231;ais.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>JAWS : JUST ANOTHER WORDNET SUBSET
</p>
<p>d&#233;terminer quel terme candidat (s&#8217;il existe) correspond au sens de chaque synset. La structure du PWN est
ainsi conserv&#233;e : l&#8217;appelation synset fait maintenant &#224; la fois r&#233;f&#233;rence aux termes source et aux termes
cible. Cette &#233;tape d&#8217;extraction sera not&#233;e E dans les r&#233;sultats pr&#233;sent&#233;s plus loin. On parlera de synset
instanci&#233; pour r&#233;f&#233;rer aux synsets auxquels on a assign&#233; au moins un terme cible. Nous pouvons &#224; pr&#233;sent
d&#233;finir des heuristiques de d&#233;sambigu&#239;sation qui exploiteront les relations s&#233;mantiques de PWN ainsi que
des caract&#233;ristiques de distribution des termes cible dans les espaces s&#233;mantiques. Les espaces s&#233;mantiques
que nous utilisons sont calcul&#233;s &#224; partir d&#8217;une analyse en d&#233;pendances syntaxiques sur un corpus fran&#231;ais
issu du Web. Les documents furent obtenus apr&#232;s avoir envoy&#233; 600 000 mots d&#8217;un dictionnaire comme
requ&#234;tes sur un moteur de recherche et t&#233;l&#233;charg&#233; les 100 premiers r&#233;sultats pour chaque requ&#234;te. Ces
espaces sont d&#233;crits plus en d&#233;tails dans (Grefenstette, 2007) et (Mouton et al., 2009).
</p>
<p>La premi&#232;re heuristique, d&#233;sign&#233;e par S dans les r&#233;sultats, exploite une mesure de similarit&#233; s&#233;mantique
dans les espaces s&#233;mantiques d&#233;crits ci-dessus. Nous utilisons une similarit&#233; cosinus caract&#233;ris&#233;e par l&#8217;in-
formation mutuelle sp&#233;cifique (PMI). Cette mesure permet de trouver des relations proches de la syno-
nymie (Turney, 2001). Soit un terme source d&#8217;un synset. S&#8217;il a plusieurs traductions candidates, et que le
synset a d&#233;j&#224; &#233;t&#233; instanci&#233;, alors la traduction choisie est celle la plus proche des termes cible instanci&#233;s.
Par exemple, en fran&#231;ais saw se traduit par dicton ou scie. Pour un des synsets de PWN associ&#233; &#224; saw, les
termes cible instanci&#233;s pr&#233;c&#233;demment sont adage, proverbe et sentence. La proximit&#233; issue des espaces
s&#233;mantiques indique alors que pour ce synset la meilleure traduction est dicton.
</p>
<p>On se propose &#233;galement d&#8217;exploiter les relations d&#8217;hyponymie et d&#8217;hyperonymie pour d&#233;terminer quel est
le candidat de traduction le plus adapt&#233;. Un mot sp&#233;cifique poss&#233;dant des caract&#233;ristiques plus compl&#232;tes
que son hyperonyme, nous &#233;mettons la double hypoth&#232;se suivante : (1) les contextes syntaxiques d&#8217;un mot
g&#233;n&#233;ral apparaissent souvent comme contexte syntaxique de ses hyponymes (e.g. : la vitesse du v&#233;hicule,
et la vitesse du train, du bateau, du camion) et (2) l&#8217;&#233;ventail des contextes syntaxiques d&#8217;un mot sp&#233;cifique
est plus grand que ceux de ses hyperonymes (e.g. : la quille du bateau mais pas la quille du v&#233;hicule). &#192;
partir de ces deux hypoth&#232;ses, on d&#233;duit la caract&#233;risation suivante : pour un synset S poss&#233;dant au moins
un synset hyponyme instanci&#233; h(S) et au moins un synset hyperonyme instanci&#233; H(S), on calcule pour
chaque terme candidat c le score &#963;(c) suivant :
</p>
<p>&#963;(c) =
1
</p>
<p>|h(S)| .
&#8721;
</p>
<p>{Tcible&#8712;h(S)}
</p>
<p>|ctx(Tcible) &#8745; ctx(c)|
|ctx(c)| +
</p>
<p>1
</p>
<p>|H(S)| .
&#8721;
</p>
<p>{Tcible&#8712;H(S)}
</p>
<p>|ctx(c) &#8745; ctx(Tcible)|
|ctx(Tcible)|
</p>
<p>avec ctx(x) l&#8217;ensemble des termes cibles contextes de x. L&#8217;hypoth&#232;se (2) sert ici &#224; limiter les diviseurs &#224;
|ctx(c)| et |ctx(Tcible)| et non |ctx(c) &#8746; ctx(Tcible)|. Le candidat de score le plus grand est valid&#233;. Nous
utilisons cette heuristique distinctement sur les espaces s&#233;mantiques de compl&#233;ment du nom, sujet-verbe,
et objet-verbe, en l&#8217;appelant respectivement Hc, Hs et Ho.
</p>
<p>Les relations de m&#233;ronymie ou d&#8217;holonymie (relation est une partie de) avec des synsets d&#233;j&#224; instanci&#233;s
peuvent &#233;galement &#234;tre exploit&#233;es pour d&#233;terminer le meilleur candidat cible. Notre hypoth&#232;se est qu&#8217;un
concept compris dans un autre est fortement susceptible d&#8217;appara&#238;tre dans ses cooccurrents par la relation
compl&#233;ment du nom : la p&#233;dale du v&#233;lo, le toit de l&#8217;immeuble. Pour d&#8217;autre langue que le fran&#231;ais, la
relation peut-&#234;tre diff&#233;rente (i.e. bicycle pedal). Cette heuristique est discutable car certaines pr&#233;positions
formant la relation de compl&#233;ment du nom ne r&#233;alisent que rarement la relation de m&#233;ronymie dans le sens
propos&#233;. De plus, m&#234;me si la pr&#233;position de correspond parfois &#224; notre caract&#233;risation, ce n&#8217;est pas toujours
le cas (tour du monde, coup de vent...). L&#8217;ensemble des candidats &#233;tant restreint par les traductions des
termes source, cette heuristique peut n&#233;anmoins permettre le choix du bon candidat. Le score d&#8217;un candidat
est alors la moyenne des scores prenant en compte le nombre d&#8217;occurrences de la relation compl&#233;ment du</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CLAIRE MOUTON, GA&#203;L DE CHALENDAR
</p>
<p>nom entre chaque m&#233;ronyme (ou holonyme) et le candidat, divis&#233; par le nombre d&#8217;occurences du candidat
et du m&#233;ronyme (ou holonyme) en position de compl&#233;ment du nom. Les candidats ayant les plus hauts
scores sont conserv&#233;s pour traduction. Cette heuristique sera not&#233;e M dans les r&#233;sultats.
</p>
<p>Nous appliquons une derni&#232;re heuristique (not&#233;e F) : la racine &#233;tymologique d&#8217;un mot pouvant &#234;tre conser-
v&#233;e d&#8217;une langue &#224; l&#8217;autre, nous validons le meilleur candidat dont la distance de Levenshtein avec le mot
source est en dessous d&#8217;un certain seuil.
</p>
<p>A chaque it&#233;ration de l&#8217;algorithme, on produit autant de nouvelles ressources (ensemble de traductions)
que d&#8217;heuristiques. Puis, une &#233;valuation automatique 3 est men&#233;e pour d&#233;terminer quelle heuristique four-
nit la meilleure ressource en pr&#233;cision. On &#233;limine les autres et on r&#233;it&#232;re en utilisant la ressource conser-
v&#233;e.
</p>
<p>4 &#201;valuation
</p>
<p>Afin de valider notre approche et la validit&#233; de nos hypoth&#232;ses, nous nous comparons &#224; la ressource WOLF
qui pr&#233;sente l&#8217;int&#233;r&#234;t d&#8217;avoir d&#233;j&#224; &#233;t&#233; &#233;valu&#233;e. La version de JAWS &#233;valu&#233;e est donc construite &#224; partir de
la version du PWN 2.0 utilis&#233;e par WOLF. Nous mesurons d&#8217;une part la couverture obtenue par WOLF et
JAWS en pourcentage du nombre de synsets polys&#233;miques de PWN. D&#8217;autre part, nous classons les paires
Terme-Synset P obtenues dans la ressource cible en trois cat&#233;gories : dans la cat&#233;gorie 1, P est pr&#233;sente
dans WOLF. Dans la 2, P est absente dans WOLF mais il existe au moins une traduction du synset S et dans
la cat&#233;gorie 3, le synset S ayant produit P n&#8217;a pas de traduction dans WOLF. Les r&#233;sultats sont pr&#233;sent&#233;s
dans le tableau 1. Pour des raisons de place, seuls les r&#233;sultats apr&#232;s extraction et ceux issus de la meilleure
s&#233;quence d&#8217;heuristiques sont montr&#233;s ici. Nos r&#233;sultats montrent que l&#8217;extraction pure produit moins de
traductions que ce que l&#8217;on trouve dans WOLF (27 % contre 30 % des synsets de PWN). En revanche,
chaque heuristique seule produit un plus grand nombre de traductions que WOLF. La s&#233;quence it&#233;rative
E+FMHc produit 64 % du nombre de synsets polys&#233;miques de PWN avec 13 % des paires pr&#233;sentes dans
WOLF (pr&#233;cision des termes nominaux polys&#233;miques de WOLF estim&#233;e &#224; 77 % par leurs auteurs). Parmi
les paires g&#233;n&#233;r&#233;es : 42 % sont produites par l&#8217;&#233;tape E, puis 47 % par F, 2 % par M, et 9 % par Hc.
</p>
<p>Paires traduites Cat1. P &#8712;WOLF Cat2. P /&#8712;WOLF Cat3. S /&#8712;WOLF
WOLF 30 %
</p>
<p>Extraction 27 % 8 %(31 %) 19 %(70 %) 73 %
E+FMHc 64 % 13 %(38 %) 21 %(62 %) 67 %
</p>
<p>TABLE 1 &#8211; Pourcentage des paires nominales polys&#233;miques traduites et r&#233;partition des paires sur 3 cat&#233;-
gories. Entre parenth&#232;ses figure le cas o&#249; l&#8217;on consid&#232;re uniquement les synsets appartenant &#224; WOLF.
</p>
<p>WOLF ne r&#233;pertoriant pas exhaustivement l&#8217;ensemble des paires possibles pour un synset, nous proc&#233;dons
&#224; l&#8217;analyse manuelle d&#8217;un extrait al&#233;atoire des paires de cat&#233;gorie 2 et 3. Nous proposons de classer les
diff&#233;rences entre WOLF et JAWS selon le tableau 2. Le tableau 3 montre l&#8217;analyse manuelle (sur un
&#233;chantillon de 40 paires) des paires absentes de WOLF mais pr&#233;sentes dans JAWS pour les synsets pr&#233;sents
dans WOLF (61 % des paires concernant ces synsets). On constate que pour E+FMHc, 58 % de ces paires
sont meilleures ou &#233;gales &#224; celles de WOLF (MP1 +D1 +D2 +D3).
</p>
<p>3. L&#8217;&#233;valuation consid&#232;re l&#8217;intersection avec WOLF comme v&#233;rit&#233;-terrain, cf. section suivante</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>JAWS : JUST ANOTHER WORDNET SUBSET
</p>
<p>Cat.2
</p>
<p>Manque Partiel dans WOLF : au moins une
traduction de S mais pas de traduction de L
</p>
<p>MP1 Traduction JAWS correcte
MP2 Traduction JAWS incorrecte
</p>
<p>Diff&#233;rence de traduction
</p>
<p>D1 La traduction de WOLF est incorrecte et celle de JAWS est correcte
D2 La traduction de WOLF est moins bonne
D3 Les deux traductions sont correctes et &#233;quivalentes
D4 La traduction de JAWS est moins bonne
D5 La traduction de JAWS est incorrecte et celle de WOLF est correcte
</p>
<p>Non r&#233;solu W Aucune traduction n&#8217;est adapt&#233;e
</p>
<p>Cat.3 Absent de WOLF : aucune traduction de S MT1 Traduction JAWS correcteMT2 Traduction JAWS incorrecte
</p>
<p>TABLE 2 &#8211; Diff&#233;rences par rapport &#224; WOLF pour une paire P associ&#233;e &#224; un synset S issue d&#8217;un terme T
</p>
<p>MP1 MP2 D1 D2 D3 D4 D5 W MP1+D1+D2+D3
Extraction 20 5 3 0 4 1 6 1 68 %&#177; 14
E+FMHc (16+4) (2+9) (1+0) (0+2) 0 (0+2) (1+3) 0 58 %&#177; 15
</p>
<p>TABLE 3 &#8211; Analyse des paires de cat&#233;gorie 2 (P /&#8712; WOLF ) sur un &#233;chantillon de 40 paires. La derni&#232;re
colonne est le pourcentage de pr&#233;cision pour cette cat&#233;gorie.
</p>
<p>Quand aux paires correspondant &#224; la cat&#233;gorie 3 (synsets absents de WOLF), leur analyse manuelle (sur
un nouvel &#233;chantillon de 40 paires) montre qu&#8217;elles sont bonnes &#224; 73 % pour E+FMHc (tableau 4). Ce
dernier tableau indique aussi la micro pr&#233;cision estim&#233;e &#224; l&#8217;aide de WOLF et des validations manuelles :&#8721;
</p>
<p>i&#8712;{1,2,3} Pre&#769;cision(Cat(i)) &#8727; Pourcentage(paire &#8712; Cat(i)). On obtient un WordNet fran&#231;ais couvrant
deux fois plus de synsets nominaux polys&#233;miques que WOLF pour une perte de pr&#233;cision de 6 points.
</p>
<p>MT1 MT2 Pestime&#769;e
Extraction 83 %&#177; 12 17 %&#177; 12 80 %&#177; 8
E+FMHc 73 %&#177; 14 27 %&#177; 14 71 %&#177; 9
</p>
<p>TABLE 4 &#8211; Analyse des paires de cat&#233;gorie 3 (S /&#8712; WOLF ). La derni&#232;re colonne est la probabilit&#233; estim&#233;e
sur l&#8217;ensemble des cat&#233;gories. (Ex : 0.13 &#8727; 77 + 0.21 &#8727; 58 + 0.67 &#8727; 73 = 71)
</p>
<p>5 R&#233;sultats et discussions
</p>
<p>Apr&#232;s 3 it&#233;rations des heuristiques (soit F, M, Hc), nous obtenons la meilleure ressource avec une conver-
ture de 64 % du nombre de paires d&#8217;origine. La ressource obtenue contient un total de 26 807 termes
nominaux uniques, et ceci avec une pr&#233;cision estim&#233;e &#224; 71 % pour les termes nominaux polys&#233;miques.
</p>
<p>Un des inconv&#233;nients de la m&#233;thode propos&#233;e r&#233;side dans l&#8217;incapacit&#233; du syst&#232;me &#224; ne choisir aucun
candidat parmi les traductions propos&#233;es. Si le dictionnaire bilingue fournit un certain nombre de candidats
mais ne fournit pas de traduction pour un des sens WordNet du terme source, la traduction choisie sera
n&#233;cessairement fausse. Si le candidat le plus correct ne figure pas dans les entr&#233;es de l&#8217;espace s&#233;mantique
(comme les noms propres dans notre cas), la traduction choisie sera n&#233;cessairement fausse. La m&#233;thode
gagnerait donc &#224; fixer quelques crit&#232;res de non-choix de candidat.
</p>
<p>L&#8217;heuristique fournissant les meilleurs r&#233;sultats &#224; la premi&#232;re it&#233;ration est celle exploitant la distance de</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CLAIRE MOUTON, GA&#203;L DE CHALENDAR
</p>
<p>Levenshtein. Ceci peut s&#8217;expliquer par le fait qu&#8217;un faible nombre de synsets sont instanci&#233;s avant la
premi&#232;re it&#233;ration, ceci rendant difficile l&#8217;exploitation des autres heuristiques. Par ailleurs, bien que toutes
les heuristiques ne soient pas utilis&#233;es dans la s&#233;quence optimale, on remarque qu&#8217;elles produisent chacune
des r&#233;sultats int&#233;ressants. Nous souhaitons donc &#233;tudier dans des travaux ult&#233;rieurs le gain &#233;ventuel en
pr&#233;cision apport&#233; par une utilisation combin&#233;e (et non s&#233;quentielle) des diff&#233;rentes heuristiques.
</p>
<p>6 Conclusion
</p>
<p>Le WordNet fran&#231;ais ainsi obtenu couvre deux fois plus de nominaux polys&#233;miques que WOLF, avec une
perte de pr&#233;cision estim&#233;e &#224; 6 points. L&#8217;id&#233;al serait maintenant de pouvoir combiner ces ressources.
</p>
<p>La m&#233;thode peut &#234;tre g&#233;n&#233;ralis&#233;e &#224; d&#8217;autres langues, &#224; condition que l&#8217;on dispose d&#8217;un dictionnaire bi-
lingue riche, d&#8217;un analyseur syntaxique, et que la langue cible partage beaucoup de cognats avec la
langue source (l&#8217;heuristique la plus efficace &#233;tant la distance de Levenshtein). Enfin, quelques modifi-
cations peuvent &#234;tre n&#233;cessaires pour des langues dans lesquelles la structure de compl&#233;ment du nom ne
s&#8217;emploierait pas de la m&#234;me mani&#232;re.
</p>
<p>Ces heuristiques ne sont pas suffisamment robustes pour acqu&#233;rir les mots et les relations qui les lient sans
l&#8217;utilisation de la structure de WordNet. Nous projetons d&#8217;analyser de fa&#231;on plus syst&#233;matique les distribu-
tions syntaxiques caract&#233;risant les relations s&#233;mantiques en utilisant le PWN et des espaces s&#233;mantiques
constitu&#233;s &#224; partir de langue anglaise. S&#8217;il existe r&#233;ellement une telle caract&#233;risation, cette analyse m&#232;nera
&#224; une caract&#233;risation distributionnelle plus fine et plus exploitable des relations s&#233;mantiques.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BARBU E. &amp; BARBU MITITELU V. (2005). Automatic building of Wordnets. In Proc. of RANLP 2005,
p. 329&#8211;332.
</p>
<p>C. FELLBAUM, Ed. (1998). WordNet : An Electronic Lexical Database. MIT Press.
</p>
<p>GREFENSTETTE G. (2007). Conquering language : Using NLP on a massive scale to build high dimen-
sional language models from the Web. In Proc. of the 8th CICLing Conference, p. 35&#8211;49, Mexico.
</p>
<p>KOTIS K., VOUROS G. A. &amp; STERGIOU K. (2006). Towards automatic merging of domain ontologies :
The HCONE-merge approach. Web Semantics : Science, Services and Agents on the World Wide Web,
4(1), 60&#8211;79.
MOUTON C., PITEL G., DE CHALENDAR G. &amp; VILNAT A. (2009). Word Sense Induction from multiple
semantic spaces. In Proc. of RANLP 2009, Borovets, Bulgarie.
</p>
<p>SAGOT B. &amp; FI&#352;ER D. (2008). Construction d&#8217;un WordNet libre du fran&#231;ais &#224; partir de ressources
multilingues. In Actes de TALN 2008 (Traitement automatique des langues naturelles), Avignon : LIA.
</p>
<p>TURNEY P. D. (2001). Mining the web for synonyms : PMI&#8211;IR versus LSA on TOEFL. Lecture Notes
in Computer Science, 2167, 491&#8211;502.
VOSSEN P. (1998). EuroWordNet : A multilingual database with lexical semantic networks. Computa-
tional Linguistics, 24(4), 628&#8211;630.</p>

</div></div>
</body></html>