TALN 2010, Montréal, 19-23 jui11et2010

JAWS : Just Another WordNet Subset

Claire Mouton1= 2 Gael de Chalendarl
(1) CEA, LIST, Laboratoire Vision et Ingénierie des Contenus, Fontenay aux Roses,
F-92265, France;
(2) Exalead, 10 place de la Madeleine, 75008 Paris
claire.mouton@cea.fr, gael.de-chalendar@cea.fr

Résumé. WordNet, une des ressources lexicales les plus utilisées aujourd’hui a été constituée en
anglais et les chercheurs travaillant sur d’autres langues souffrent du manque d’une telle ressource. Malgré
les efforts fournis par la communauté francaise, les différents WordNets produits pour la langue francaise
ne sont toujours pas aussi exhaustifs que le WordNet de Princeton. C’est pourquoi nous proposons une
méthode novatrice dans la production de termes nominaux instanciant les différents synsets de WordNet
en exploitant les propriétés syntaxiques distributionnelles du vocabulaire francais. Nous comparons la
ressource que nous obtenons avec WOLF et montrons que notre approche offre une couverture plus large.

Abstract. WordNet, one of the most used lexical resource until today has been made up for the
English language and scientists working on other languages suffer from the lack of such a resource. Despite
the efforts performed by the French community, the different WordNets produced for the French language
are still not as exhaustive as the original Princeton WordNet. We propose a new approach in the way of
producing nominal terms ﬁlling the synset slots. We use syntactical distributional properties of French
vocabulary to determine which of the candidates given by a bilingual dictionary matches the best. We
compare the resource we obtain with WOLF and show that our approach provides a much larger coverage.

M0tS-CléS I ressources lexicales francaises, WordNet, relations sémantiques, distributions syn-
taxiques.

Keywords: French lexical resources, WordNet, semantic relations, syntactical distributionality.

1 Introduction

La majorité des ressources lexicales ont d’abord été constituées pour l’anglais. Cependant, les différentes
communautés non anglophones ont aussi besoin de telles ressources. Nous nous intéressons ici a la consti-
tution d’une version francaise du réseau lexical WordNet de l’université de Princeton (Fellbaum, 1998).
WordNet répertorie les mots du vocabulaire en fonction de leur sens et des relations sémantiques qui lient
ces mots entre eux.

I1 existe déja plusieurs tentatives de constitution de WordNet pour le francais telles que celles développées
dans les travaux de (Vossen, 1998) ou (WOLF, (Sagot & Fiser, 2008)) mais aussi pour d’autres langues
comme les travaux de (Barbu & Barbu Mititelu, 2005) par exemple. Le point le plus délicat de ces trans-
ferts réside dans la traduction des mots polysémiques, et c’est sur ce point particulier que nous souhai-
tons proposer une approche originale. L’idée principale est d’exploiter les propriétés des distributions des

CLAIRE MOUTON, GAEL DE CHALENDAR

contextes syntaxiques des noms dans un grand corpus aﬁn de caractériser les relations sémantiques pré-
sentes dans WordNet. L’ évaluation de ce type de travaux est difﬁcile puisqu’il n’existe pas par déﬁnition
de vérité terrain sur laquelle s’appuyer. L’ évaluation de notre travail repose d’une part sur une comparai-
son avec une des précédentes tentatives de constitution d’un WordNet francais (WOLF) et d’autre part sur
une évaluation manuelle.

2 Travaux précédents

Parmi les méthodes proposées précédemment pour la constitution de nouvelles versions de WordNet,
deux grandes tendances se dégagent : les approches par fusion parmi lesquelles se situe l’approche de
(Kotis et al., 2006) et les approches par extension comme celle proposée par (Sagot & Fiser, 2008). Les
approches par fusion consistent a constr11ire des ontologies indépendamment et de déterminer un mapping
avec les WordNet existants a posteriori. L’avantage d’une telle approche est que l’on peut s’abstraire
de la structure existante de WordNet. Au contraire, les approches par extension font l’hypothese que la
structure du WordNet anglais peut en premiere approximation étre reprise dans la langue cible. I1 s’agit
alors de traduire les lexemes de l’anglais vers la langue cible. Nous nous placons dans ce cadre.

Beaucoup de travaux utilisent un dictionnaire bilingue pour y sélectionner les traductions les plus perti-
nentes selon diverses heuristiques, c’est le cas de (Barbu & Barbu Mititelu, 2005). La difﬁculté majeure
d’une telle traduction est le traitement des termes source polysémiques, qui sont associés a plusieurs syn-
sets de WordNet1. En effet, les traductions données par un dictionnaire ne correspondent pas forcément a
tous les synsets d’un meme terme, il s’agit de déterminer la ou les traduction(s) adaptée(s) a chaque synset.
Une approche originale de (Sagot & Fiser, 2008) utilise des corpus paralleles pour lesquels ils effectuent
la désambiguisation du corpus anglais a l’aide des synsets de WordNet et proposent les mots alignés de la
langue cible comme nouveaux termes. Dans le present article, nous proposons une méthode un peu diffe-
rente, qui utilise un dictionnaire bilingue tout en caractérisant les relations sémantiques du réseau lexical
par des propriétés syntaxiques distributionnelles.

3 Approche proposée

La structure du WordNet de Princeton (PWN) est tout d’abord reproduite pour la constitution du WordNet
de langue cible. Apres une phase d’extraction des candidats de traduction, chaque heuristique déﬁnie dans
la suite de cette section est appliquée de facon itérative, de sorte que le WordNet cible se remplisse petit a
petit et qu’a chaque itération, de nouvelles informations viennent rendre possible de nouvelles traductions.
Nous ne traitons dans ce travail que des termes et syntagmes nominaux auxquels nous référerons des lors
plus simplement par l’emploi du mot terme.

La phase d’extraction consiste a traduire tous les termes associés a un seul synset par toutes les traductions
proposées par notre dictionnaire bilinguez. Pour les autres termes et chacun de leurs synsets associés,
nous conservons toutes les traductions comme termes cible candidats. La désambigu'1'sation consistera a

1. Rappelons ici que la structure de WordNet distingue les sens des mots par le regroupement en synsets. Un synset corres-
pond a un ensemble de synonymes associé a une déﬁnition. Certains synsets sont relies entre eux par des relations sémantiques.

2. Nous utilisons la concatenation du dictionnaire SCI—FRAN—EuRADic (http : / / catalog . elra . info /product_
info . php?product s_id=666&language=fr) et du Wiktionnaire frangais.

JAWS : JUST ANOTHER WORDNET SUBSET

déterminer quel terme candidat (s’il existe) correspond au sens de chaque synset. La structure du PWN est
ainsi conservée : l’appelation synset fait maintenant a la fois référence aux termes source et aux termes
cible. Cette étape d’extraction sera notée E dans les résultats présentés plus loin. On parlera de synset
instancié pour référer aux synsets auxquels on a assigné au moins un terme cible. Nous pouvons a present
déﬁnir des heuristiques de désambiguisation qui exploiteront les relations sémantiques de PWN ainsi que
des caractéristiques de distribution des termes cible dans les espaces sémantiques. Les espaces sémantiques
que nous utilisons sont calculés a partir d’une analyse en dépendances syntaxiques sur un corpus francais
issu du Web. Les documents furent obtenus apres avoir envoyé 600 000 mots d’un dictionnaire comme
requétes sur un moteur de recherche et téléchargé les 100 premiers résultats pour chaque requéte. Ces
espaces sont décrits plus en détails dans (Grefenstette, 2007) et (Mouton et al., 2009).

La premiere heuristique, désignée par S dans les résultats, exploite une mesure de similarité sémantique
dans les espaces sémantiques décrits ci-dessus. Nous utilisons une similarité cosinus caractérisée par l’in-
formation mutuelle spéciﬁque (PMI). Cette mesure permet de trouver des relations proches de la syno-
nymie (Turney, 2001). Soit un terme source d’un synset. S’il a plusieurs traductions candidates, et que le
synset a déja été instancié, alors la traduction choisie est celle la plus proche des termes cible instanciés.
Par exemple, en francais saw se traduit par dicton ou scie. Pour un des synsets de PWN associé a saw, les
termes cible instanciés précédemment sont adage, proverbe et sentence. La proximité issue des espaces

sémantiques indique alors que pour ce synset la meilleure traduction est dicton.

On se propose également d’exploiter les relations d’hyponyInie et d’hyperonyIr1ie pour déterminer quel est
le candidat de traduction le plus adapté. Un mot spéciﬁque possédant des caractéristiques plus completes
que son hyperonyme, nous émettons la double hypothese suivante : (1) les contextes syntaxiques d’un mot
général apparaissent souvent comme contexte syntaxique de ses hyponymes (e.g. : la vitesse du véhicule,
et la vitesse du train, du bateau, du camion) et (2) l’éventail des contextes syntaxiques d’un mot spéciﬁque
est plus grand que ceux de ses hyperonymes (e. g. : la quille du bateau mais pas la quille du véhicule). A
partir de ces deux hypotheses, on déduit la caractérisation suivante : pour un synset S possédant au moins
un synset hyponyme instancié h(S) et au moins un synset hyperonyme instancié H(S), on calcule pour
chaque terme candidat c le score 0(0) suivant :

0(0) : 1 Z |ctaI:(Tc,-we) ﬂ ctJ:(c)| 1 |ctJ:(c) ﬂ ct1:(Tc,-b;e)|
W3)

|.{T..u.eh<s>} |Ct”"(C)| |H(S)| ' {TcibteEH(3)} |C‘””(T”""€)|

avec ctX(X) l’ensemble des termes cibles contextes de X. L’hypothese (2) sert ici a limiter les diviseurs a
|cta:(c)| et |ctx(Tc,-;,;e)| et non |cta:(c) U ctar:(Tc,-;,;e)|. Le candidat de score le plus grand est validé. Nous
utilisons cette heuristique distinctement sur les espaces sémantiques de complément du nom, sujet-verbe,
et objet-verbe, en l’appelant respectivement Hc, Hs et H0.

Les relations de méronymie ou d’holonymie (relation est une partie de) avec des synsets déja instanciés
peuvent également étre exploitées pour déterminer le meilleur candidat cible. Notre hypothese est qu’un
concept compris dans un autre est fortement susceptible d’apparaitre dans ses cooccurrents par la relation
complément du nom : la pe’dale du ve’l0, le toit de l’immeuble. Pour d’autre langue que le francais, la
relation peut-étre différente (i.e. bicycle pedal). Cette heuristique est discutable car certaines prépositions
formant la relation de complément du nom ne réalisent que rarement la relation de méronymie dans le sens
proposé. De plus, meme si la préposition de correspond parfois a notre caractérisation, ce n’est pas toujours
le cas (tour du monde, coup de vent...). L’ ensemble des candidats étant restreint par les traductions des
termes source, cette heuristique peut néanmoins permettre le choix du bon candidat. Le score d’un candidat
est alors la moyenne des scores prenant en compte le nombre d’occurrences de la relation complement du

CLAIRE MOUTON, GAEL DE CHALENDAR

nom entre chaque méronyme (ou holonyme) et le candidat, divisé par le nombre d’occurences du candidat
et du méronyme (ou holonyme) en position de complement du nom. Les candidats ayant les plus hauts
scores sont conservés pour traduction. Cette heuristique sera notée M dans les résultats.

Nous appliquons une derniere heuristique (notée F) : la racine étymologique d’un mot pouvant étre conser-
vée d’une langue a l’autre, nous validons le meilleur candidat dont la distance de Levenshtein avec le mot
source est en dessous d’un certain seuil.

A chaque itération de l’algorithme, on produit autant de nouvelles ressources (ensemble de traductions)
que d’heuristiques. Puis, une évaluation automatique 3 est menée pour déterminer quelle heuristique four-
nit la meilleure ressource en précision. On élimine les autres et on réitere en utilisant la ressource conser-
vée.

4 Evaluation

Aﬁn de valider notre approche et la validité de nos hypotheses, nous nous comparons a la ressource WOLF
qui présente l’intérét d’avoir déja été évaluée. La version de JAWS évaluée est donc construite a partir de
la version du PWN 2.0 utilisée par WOLF. Nous mesurons d’une part la couverture obtenue par WOLF et
JAWS en pourcentage du nombre de synsets polysémiques de PWN. D’autre part, nous classons les paires
Terme-Synset P obtenues dans la ressource cible en trois catégories : dans la catégorie 1, P est présente
dans WOLF. Dans la 2, P est absente dans WOLF mais il existe au moins une traduction du synset S et dans
la catégorie 3, le synset S ayant produit P n’a pas de traduction dans WOLF. Les résultats sont présentés
dans le tableau 1. Pour des raisons de place, seuls les résultats apres extraction et ceux issus de la meilleure
séquence d’heuristiques sont montrés ici. Nos résultats montrent que l’eXtraction pure produit moins de
traductions que ce que l’on trouve dans WOLF (27 % contre 30 % des synsets de PWN). En revanche,
chaque heuristique seule produit un plus grand nombre de traductions que WOLF. La séquence itérative
E+FMHc produit 64 % du nombre de synsets polysémiques de PWN avec 13 % des paires présentes dans
WOLF (précision des terrnes nominaux polysémiques de WOLF estimée a 77 % par leurs auteurs). Parmi
les paires générées : 42 % sont produites par l’étape E, puis 47 % par F, 2 % par M, et 9 % par Hc.

Paires traduites Catl. P E WOLF Cat2. P ¢ WOLF Cat3. S ¢ WOLF
WOLF 30 %
Extraction 27 % 8 %(3l %) 19 %(70 %) 73 %
E+FMHc 64 % 13 %(38 %) 21 %(62 %) 67 %

TABLE 1 — Pourcentage des paires nominales polysémiques traduites et répartition des paires sur 3 caté-
gories. Entre parentheses ﬁgure le cas o1‘1l’on considere uniquement les synsets appartenant a WOLF.

WOLF ne répertoriant pas exhaustivement l’ensemble des paires possibles pour un synset, nous procédons
a l’analyse manuelle d’un extrait aléatoire des paires de catégorie 2 et 3. Nous proposons de classer les
différences entre WOLF et JAWS selon le tableau 2. Le tableau 3 montre l’analyse manuelle (sur un
échantillon de 40 paires) des paires absentes de WOLF mais présentes dans JAWS pour les synsets présents
dans WOLF (61 % des paires concernant ces synsets). On constate que pour E+FMHc, 58 % de ces paires
sont meilleures ou égales a celles de WOLF (M P1 + D1 + D2 + D3).

3. L’ évaluation considére l’intersection avec WOLF comme Vérité-terrain, cf. section suivante

JAWS : JUST ANOTHER WORDNET SUBSET

Manque Partiel dans WOLF : au moins une MP1 Traduction JAWS correcte
traduction de S mais pas de traduction de L MP2 Traduction JAWS incorrecte
D1 La traduction de WOLF est incorrecte et celle de JAWS est correcte
Cat 2 D2 La traduction de WOLF est moins bonne
' Différence de traduction D3 Les deux traductions sont correctes et équivalentes
D4 La traduction de JAWS est moins bonne
D5 La traduction de JAWS est incorrecte et celle de WOLF est correcte
Non résolu W Aucune traduction n’est adaptée
Cat.3 Absent de WOLF : aucune traduction de S  Tggiiztéinlllfvyésiﬁggggtge

TABLE 2 — Différences par rapport a WOLF pour une paire P associée a un synset S issue d’un terme T

MP1 MP2 D1 D2 D3 D4 D5 W MP1+Dl+D2+D3
Extraction 20 5 3 0 4 1 6 1 68 % i 14
E+FMHc (16+4) (2+9) ( 1+0) (0+2) 0 (0+2) ( 1+3) 0 58 % :|: 1 5

TABLE 3 — Analyse des paires de catégorie 2 (P ¢ WOLF) sur un échantillon de 40 paires. La derniére
colonne est le pourcentage de précision pour cette catégorie.

Quand aux paires correspondant a la catégorie 3 (synsets absents de WOLF), leur analyse manuelle (sur
un nouvel échantillon de 40 paires) montre qu’elles sont bonnes a 73 % pour E+FMHc (tableau 4). Ce
demier tableau indique aussi la micro précision estimée a l’aide de WOLF et des validations manuelles :
Z,-E{1,2,3} Précisi0n(Cat(i)) * P0urcentage(paire E Cat(i)). On obtient un WordNet frangais couvrant
deux fois plus de synsets nominaux polysémiques que WOLF pour une perte de précision de 6 points.

MT1 MT2 P estimée
Extraction 83 % i 12 17 % i 12 80 % i 8
E+FMHc 73 % :|: 14 27 % :|: 14 71 % :|: 9

TABLE 4 — Analyse des paires de catégorie 3 (3 ¢ WOLF). La derniére colonne est la probabilité estimée
sur l’ensemble des catégories. (Ex : 0.13 * 77 + 0.21 >:< 58 + 0.67 * 73 = 71)

5 Résultats et discussions

Aprés 3 itérations des heuristiques (soit F, M, Hc), nous obtenons la meilleure ressource avec une conver-
ture de 64 % du nombre de paires d’origine. La ressource obtenue contient un total de 26 807 termes
nominaux uniques, et ceci avec une précision estimée a 71 % pour les termes nominaux polysémiques.

Un des inconvénients de la méthode proposée réside dans l’incapacité du systéme a ne choisir aucun
candidat parmi les traductions proposées. Si le dictionnaire bilingue fournit un certain nombre de candidats
mais ne fournit pas de traduction pour un des sens WordNet du terme source, la traduction choisie sera
nécessairement fausse. Si le candidat le plus correct ne ﬁgure pas dans les entrées de l’espace sémantique
(comme les noms propres dans notre cas), la traduction choisie sera nécessairement fausse. La méthode
gagnerait done a ﬁxer quelques critéres de non-choix de candidat.

L’heuristique foumissant les meilleurs résultats a la premiere itération est celle exploitant la distance de

CLAIRE MOUTON, GAEL DE CHALENDAR

Levenshtein. Ceci peut s’expliquer par le fait qu’un faible nombre de synsets sont instanciés avant la
premiere itération, ceci rendant difﬁcile l’exploitation des autres heuristiques. Par ailleurs, bien que toutes
les heuristiques ne soient pas utilisées dans la séquence optimale, on remarque qu’elles produisent chacune
des résultats intéressants. Nous souhaitons donc étudier dans des travaux ultérieurs le gain éventuel en
précision apporté par une utilisation combinée (et non séquentielle) des différentes heuristiques.

6 Conclusion

Le WordNet frangais ainsi obtenu couvre deux fois plus de noIr1inaux polysémiques que WOLF, avec une
perte de précision estimée a 6 points. L’ idéal serait maintenant de pouvoir combiner ces ressources.

La méthode peut étre généralisée a d’autres langues, a condition que l’on dispose d’un dictionnaire bi-
lingue riche, d’un analyseur syntaxique, et que la langue cible partage beaucoup de cognats avec la
langue source (l’heuristique la plus efﬁcace étant la distance de Levenshtein). Enﬁn, quelques modiﬁ-
cations peuvent étre nécessaires pour des langues dans lesquelles la structure de complément du nom ne
s’emploierait pas de la meme maniere.

Ces heuristiques ne sont pas sufﬁsamment robustes pour acquérir les mots et les relations qui les lient sans
l’utilisation de la structure de WordNet. Nous proj etons d’analyser de fagon plus systématique les distribu-
tions syntaxiques caractérisant les relations sémantiques en utilisant le PWN et des espaces sémantiques
constitués a partir de langue anglaise. S’il existe réellement une telle caractérisation, cette analyse menera
a une caractérisation distributionnelle plus ﬁne et plus exploitable des relations sémantiques.

Références

BARBU E. & BARBU MITITELU V. (2005). Automatic building of Wordnets. In Proc. of RANLP 2005,
p. 329-332.

C. FELLBAUM, Ed. (1998). WordNet .' An Electronic Lexical Database. MIT Press.

GREFENSTETTE G. (2007). Conquering language : Using NLP on a massive scale to build high dimen-
sional language models from the Web. In Proc. of the 8th CICLing Conference, p. 35-49, Mexico.

KOTIS K., VOUROS G. A. & STERGIOU K. (2006). Towards automatic merging of domain ontologies :
The HCONE-merge approach. Web Semantics .' Science, Services and Agents on the World Wide Web,
4(1), 60-79.

MOUTON C., PITEL G., DE CHALENDAR G. & VILNAT A. (2009). Word Sense Induction from multiple
semantic spaces. In Proc. of RANLP 2009, Borovets, Bulgarie.

SAGOT B. & FISER D. (2008). Construction d’un WordNet libre du frangais a partir de ressources
multilingues. In Actes de TALN 2008 (Traitement automatique des langues naturelles), Avignon : LIA.

TURNEY P. D. (2001). Mining the web for synonyms : PMI-IR Versus LSA on TOEFL. Lecture Notes
in Computer Science, 2167, 491-502.

VOSSEN P. (1998). EuroWordNet : A multilingual database with lexical semantic networks. Computa-
tional Linguistics, 24(4), 628-630.

