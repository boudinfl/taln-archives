<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Comparaison de ressources lexicales pour l&#8217;extraction de synonymes</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montre&#769;al, 19&#8211;23 juillet 2010
</p>
<p>Comparaison de ressources lexicales pour l&#8217;extraction de synonymes
</p>
<p>Philippe {Muller(1), Langlais(2)}
(1) IRIT, Universite&#769; de Toulouse &amp; Alpage, INRIA
</p>
<p>(2) DIRO, Universite&#769; de Montre&#769;al
</p>
<p>1 Introduction
</p>
<p>La construction automatique de thesaurus par collecte d&#8217;un ensemble de relations entre unite&#769;s lexicales
(synonymie, antonymie, me&#769;ronymie, etc) est un objectif relativement ancien en traitement automatique
des langues. Il est parfois e&#769;tendu par l&#8217;ajout d&#8217;associations the&#769;matiques, aux contours variables. Les tenta-
tives initiales e&#769;taient fonde&#769;es soit sur des dictionnaires nume&#769;riques, soit sur des analyses distributionnelles
rapprochant des termes ayant des contextes de cooccurrence similaires, soit les deux (Niwa &amp; Nitta, 1994),
prenant e&#769;ventuellement en compte les fonctions syntaxiques (Lin, 1998). De nombreuses instances de ces
ide&#769;es ont e&#769;te&#769; propose&#769;es plus re&#769;cemment, que ce soit en exploitant les structures de dictionnaires ou des
donne&#769;es distributionnelles. Quand ils sont e&#769;value&#769;s, ces efforts se re&#769;ve&#768;lent pluto&#770;t de&#769;cevants : sauf a&#768; faire
des restrictions importantes, les similarite&#769;s ainsi de&#769;finies rapportent un me&#769;lange he&#769;te&#769;roge&#768;ne de fonctions
lexicales et de termes se&#769;mantiquement apparente&#769;s sans que les contours de cette parente&#769; soient e&#769;vidents
a&#768; de&#769;limiter. La synonymie est sans doute la fonction lexicale la plus teste&#769;e parmi ces tentatives, car on
dispose de re&#769;fe&#769;rences qui permettent de l&#8217;e&#769;valuer, jusqu&#8217;a&#768; un certain point. Le bilan a&#768; tirer de ces travaux
est que les donne&#769;es utilise&#769;es pour extraire des relations lexicales n&#8217;ont sans doute pas livre&#769; tout le potentiel
que les auteurs leur attribuent et que l&#8217;on conna&#305;&#770;t encore mal la place re&#769;elle occupe&#769;e par les termes en
relations de synonymie parmi les associations calcule&#769;es.
</p>
<p>Il a e&#769;te&#769; aussi propose&#769;, de fac&#807;on plus marginale, d&#8217;utiliser des corpus paralle&#768;les multilingues pour retrouver
une similarite&#769; entre termes (Dyvik, 2002) en se fondant sur l&#8217;hypothe&#768;se que des termes proches doivent
partager largement leurs traductions. Dans cette optique, on conside&#768;re les termes associe&#769;s par des traduc-
tions en &#8220;miroir&#8221; : les traductions d&#8217;un terme d&#8217;une langue source 1 dans une langue cible 2 sont mis en
rapport avec leur traduction dans la langue 1. L&#8217;hypothe&#768;se est que les termes obtenus apre&#768;s cet aller-retour
1-2-1 sont des bons candidats a&#768; la synonymie avec le terme de de&#769;part.
</p>
<p>Notre but ici est d&#8217;e&#769;valuer la pre&#769;sence de la synonymie dans des donne&#769;es d&#8217;alignement et des donne&#769;es
distributionnelles pour le franc&#807;ais, en prenant en compte de fac&#807;on conjointe les phe&#769;nome&#768;nes de fre&#769;quence
des termes dans l&#8217;une ou l&#8217;autre de ces ressources. L&#8217;une des originalite&#769;s de cette e&#769;tude par rapport aux
travaux mentionne&#769;s est d&#8217;utiliser et d&#8217;e&#769;valuer un score d&#8217;association en miroir entre termes (Dyvik, 2002),
quand les efforts d&#8217;e&#769;valuation existants se sont concentre&#769;s uniquement sur des similarite&#769;s de vecteurs
d&#8217;alignements.
</p>
<p>La suite de l&#8217;article pre&#769;sente les ressources utilise&#769;es (section 2), les expe&#769;rimentations mene&#769;es (section 3) et
les premie&#768;res analyses que nous en tirons (section 4). Nous revenons enfin a&#768; une discussion des approches
comparables a&#768; la no&#770;tre en section 5.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>2 Protocole
Nous tentons de comparer l&#8217;aptitude d&#8217;une approche distributionnelle et d&#8217;une approche miroir a&#768; identifier
des synonymes. Nous avons pour cela se&#769;lectionne&#769; un nombre arbitraire de substantifs et de verbes (4000
de chaque environ) ve&#769;rifiant des seuils de fre&#769;quence minimale afin d&#8217;e&#769;viter les termes trop spe&#769;cifiques.
Les fre&#769;quences dans cette e&#769;tude ont e&#769;te&#769; calcule&#769;es a&#768; partir de la version francophone de Wikipe&#769;dia1, soit
environ 200 millions de mots. Les substantifs e&#769;tant plus nombreux dans notre re&#769;fe&#769;rence, nous les avons
e&#769;chantillonne&#769;s avec deux seuils diffe&#769;rents de fre&#769;quence minimale, fixe&#769;s arbitrairement a&#768; 100 et 1000.
</p>
<p>Les deux approches (distributionnelle et miroir) produisent pour chacun de ces termes &#8220;cibles&#8221; une liste de
termes candidats synonymes, ordonne&#769;s selon un score indiquant leur degre&#769; d&#8217;association (voir la figure 1).
Ces listes sont e&#769;value&#769;es par leur aptitude a&#768; identifier les synonymes d&#8217;un lexique de re&#769;fe&#769;rence. Nous cal-
culons donc les taux de pre&#769;cision/rappel/f-mesure, soit des n meilleurs candidats dans la liste (en faisant
varier n), soit en gardant tous les candidats dont le score de&#769;passe un certain seuil (en faisant varier le seuil).
</p>
<p>avoir (0,046), consommer (0,039), e&#770;tre (0,032), nourrir (0,020), gruger (0,007), aller (0,007), faire
(0,006), prendre (0,005), de&#769;vorer (0,005), absorber (0,005), d&#305;&#770;ner (0,005), de&#769;poser (0,005), de&#769;jeuner
(0,004), alimenter (0,003), servir (0,003), ronger (0,003), avaler (0,003), engloutir (0,003), . . .
</p>
<p>FIG. 1 &#8211; Verbes candidats a&#768; la synonymie produits par l&#8217;approche miroir pour le verbe manger. Ceux en
gras appartiennent a&#768; DicoSyn, celui en italique y appara&#305;&#770;t sous forme pronominale (se nourrir).
</p>
<p>Notre lexique de re&#769;fe&#769;rence est l&#8217;union des dictionnaires de synonymes que constitue la ressource e&#769;lectro-
nique DicoSyn, initie&#769;e par Ploux &amp; Victorri (1998) a&#768; partir de sept dictionnaires classiques2. Ces dic-
tionnaires sont assez he&#769;te&#769;roge&#768;nes ; ainsi les trois plus gros e&#769;le&#769;ments de cet ensemble qui ont une taille
comparable (Du Chazaud, Robert, Larousse) ont un taux de recouvrement moyen assez faible (entre 0,42
et 0,55 de f-score si on les compare deux a&#768; deux). La ressource suffit cependant a&#768; un objectif de compara-
ison de diffe&#769;rentes configurations.
</p>
<p>La fre&#769;quence moyenne des verbes (calcule&#769;e sur Wikipedia), des noms moyennement fre&#769;quents et fre&#769;quents
est respectivement de 2500, 4300 et 9700, alors le que le nombre moyen de synonymes dans la re&#769;fe&#769;rence
est de 26, 12 et 15, respectivement, avec un maximum d&#8217;environ 180, hors stop-words (abri pour les noms,
battre pour les verbes).
</p>
<p>Comme e&#769;valuation alternative, on peut aussi envisager des tests comme ceux du TOEFL ou&#768; la ta&#770;che con-
siste a&#768; distinguer, parmi plusieurs candidats, un synonyme d&#8217;un mot donne&#769; dans une phrase exemple. La
synonymie peut e&#770;tre aussi teste&#769;e au coup par coup par des lexicographes (Falk et al., 2009).
</p>
<p>3 Approches
Nous avons utilise&#769; deux types de ressources pour l&#8217;expe&#769;rimentation : un corpus paralle&#768;le pour calculer les
associations d&#8217;alignement, et des donne&#769;es distributionnelles collecte&#769;es a&#768; partir de Wikipedia.
</p>
<p>Ressources distributionnelles : La base de &#8220;voisins&#8221; distributionnels utilise&#769;e a e&#769;te&#769; ge&#769;ne&#769;re&#769;e a&#768; partir du cor-
pus de l&#8217;ensemble des articles de la version francophone de Wikipe&#769;dia. Elle a e&#769;te&#769; constitue&#769;e en suivant l&#8217;ap-
proche de Lin (1998) : un analyseur syntaxique fournit des comptes de triplets syntaxiques (gouverneur,
</p>
<p>1Les donne&#769;es distributionnelles, ainsi que tout ce qui est extrait de Wikipedia, nous ont e&#769;te&#769; fournies par le laboratoire
CLLE-ERSS, ou&#768; elles ont e&#769;te&#769; collecte&#769;es par Frank Sajous.
</p>
<p>2La ressource a e&#769;te&#769; de plus cate&#769;gorise&#769;e en verbes/noms/adjectifs par l&#8217;e&#769;quipe CLLE-ERSS.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>relation, de&#769;pendant) a&#768; un module d&#8217;analyse de&#769;veloppe&#769; par Bourigault (2002) porte&#769; sur Wikipedia par Frank
Sajous. Ce module calcule la similarite&#769; de Lin entre des couples de &#8220;pre&#769;dicats&#8221; (gouverneur, relation), ou
bien entre des couples de de&#769;pendants syntaxiques (&#8220;arguments&#8221;). Si on conside&#768;re un pre&#769;dicat X et un
argument Y , Lin introduit une notion de quantite&#769; d&#8217;information associe&#769;e a&#768; X ou Y , note&#769; qinfo(X), qui est
le logarithme du nombre d&#8217;arguments diffe&#769;rents du pre&#769;dicat X rapporte&#769; au nombre total d&#8217;arguments pos-
sibles. Un score interme&#769;diaire d&#8217;information mutuelle entre deux pre&#769;dicats est alors donne&#769; par la somme
des quantite&#769;s d&#8217;informations des arguments qu&#8217;ils partagent et le score d&#8217;association de Lin est de&#769;fini en
normalisant par rapport aux sommes de qinfo de tous les arguments des deux pre&#769;dicats. Certains seuils
e&#769;tant applique&#769;s aux diffe&#769;rentes e&#769;tapes du traitement, chaque item lexical posse&#768;de un nombre de voisins
variables, qui peut e&#770;tre nul. Le vocabulaire couvert par les voisins de nos termes cibles repre&#769;sente 25% des
verbes de la re&#769;fe&#769;rence (hors locutions), et 18-19% des noms selon la restriction fre&#769;quentielle. L&#8217;ensemble
des paires cibles-candidats couvre respectivement 24, 25 et 29% des paires recense&#769;es par DicoSyn pour
chaque cate&#769;gorie de cible. Il est e&#769;vident que les choix du corpus, de la mesure de similarite&#769; choisie et de
l&#8217;analyseur syntaxique ont une influence en bout de cha&#305;&#770;ne et seront e&#769;value&#769;s a&#768; terme.
</p>
<p>Ressources bilingues : Nous avons mis a&#768; profit une des bases de traductions de l&#8217;application TSRali
(Bourdaillet et al., 2010). Cette base contient 8.3 millions de paires de phrases des de&#769;bats parlementaires
canadiens aligne&#769;s au niveau des phrases. Ces textes ont ensuite e&#769;te&#769; lemmatise&#769;s a&#768; l&#8217;aide de TreeTager3.
La bo&#305;&#770;te a&#768; outil Giza++4 a enfin e&#769;te&#769; utilise&#769;e afin d&#8217;entra&#305;&#770;ner un mode&#768;le de traduction statistique. Les
distributions lexicales (IBM4) ps2t et pt2s des mode&#768;les obtenus en changeant la langue conside&#769;re&#769;e comme
source au moment de l&#8217;entra&#305;&#770;nement5 ont ensuite e&#769;te&#769; utilise&#769;es de manie&#768;re a&#768; re&#769;aliser une approche miroir.
Formellement, nous calculons pour chaque mot de test w :
</p>
<p>p(s|w) &#8776; &#8721;
t&#8712;&#964;s2t(w)
</p>
<p>ps2t(t|w)&#215; pt2s(s|t)
</p>
<p>pour tout mot de la langue source s atteignable depuis w en utilisant la langue cible comme pivot (&#964;s2t(w)
de&#769;signe l&#8217;ensemble des mots associe&#769;s a&#768; w dans le mode&#768;le ps2t). En pratique, deux seuils (source et cible)
contro&#770;lent le bruit pre&#769;sent dans les distributions lexicales.
</p>
<p>Cette ressource concerne 93 458 (resp. 103 770) formes anglaise (resp. franc&#807;aises). L&#8217;ensemble des termes
&#8220;propose&#769;s&#8221; par la ressource repre&#769;sente 70% des verbes mentionne&#769;s dans la re&#769;fe&#769;rence DicoSyn(hors lo-
cutions), 40% des noms (F&gt;100) et 44% des noms (F&gt;1000). Tous les verbes propose&#769;s sont pre&#769;sents dans
DicoSyn, alors qu&#8217;environ 20% des noms n&#8217;apparaissent pas dans cette re&#769;fe&#769;rence. L&#8217;ensemble des paires
cibles-candidats couvre respectivement 50, 40 et 43% des paires recense&#769;es par DicoSyn pour chaque
cate&#769;gorie de cible. Au vu de ces statistiques, nous avons restreint les e&#769;valuations au vocabulaire couvert
en commun par les ressources et la re&#769;fe&#769;rence.
</p>
<p>4 Expe&#769;rimentations et re&#769;sultats
Sur le principe des expe&#769;riences pre&#769;sente&#769;es pre&#769;ce&#769;demment (e&#769;tude des n meilleurs candidats, ou passant un
seuil variable), nous avons e&#769;tudie&#769; l&#8217;influence des parame&#768;tres suivants : cate&#769;gorie syntaxique (noms, verbes)
classe de fre&#769;quence des termes cibles (pour les noms, deux classes de fre&#769;quence &#8220;forte&#8221; et &#8220;moyenne
a&#768; forte&#8221;), fre&#769;quence minimale des termes candidats (en faisant varier ce seuil de 0 a&#768; 5000 par palliers
</p>
<p>3http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
4http://fjoch.com/GIZA++.html
5Les mode&#768;les IBM ne sont pas syme&#769;triques.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>exponentiels) et influence d&#8217;un filtre de mots tabous sur les noms (&#8220;stop words&#8221;) dans le cas des donne&#769;es
d&#8217;alignement6. Pour les verbes nous avons enleve&#769; les 15 items les plus fre&#769;quents dans tous les cas. Dans
le cas des n meilleurs candidats, nous avons ajoute&#769; un cas ou&#768; un oracle donne a&#768; la me&#769;thode le nombre de
synonymes de la re&#769;fe&#769;rence pour choisir le n adapte&#769; a&#768; chaque terme. Enfin nous avons e&#769;tudie&#769; la combinaison
des ressources en testant l&#8217;intersection des candidats propose&#769;s par les deux me&#769;thodes.
</p>
<p>La figure 2 illustre pour une fre&#769;quence de filtre donne&#769;e l&#8217;e&#769;volution du F-score des candidats propose&#769;s par
la me&#769;thode des voisins et des miroirs, en faisant varier le nombre de termes candidats retenus (gauche),
ou le seuil de score (droite). Dans ce dernier cas, me&#770;me si les scores d&#8217;association des termes ne sont pas
comparables, on voit nettement la dominance de la me&#769;thode miroir en observant les maxima des deux
courbes dans ce cas pre&#769;cis.
</p>
<p>0 20 40 60 80 100
nbest
</p>
<p>0.04
</p>
<p>0.06
</p>
<p>0.08
</p>
<p>0.10
</p>
<p>0.12
</p>
<p>0.14
</p>
<p>0.16
</p>
<p>0.18
</p>
<p>0.20
</p>
<p>0.22
</p>
<p>sc
or
</p>
<p>e
</p>
<p>vsn
miroir
</p>
<p>0.0 0.1 0.2 0.3 0.4 0.5
threshold
</p>
<p>0.00
</p>
<p>0.05
</p>
<p>0.10
</p>
<p>0.15
</p>
<p>0.20
</p>
<p>0.25
</p>
<p>sc
or
</p>
<p>e
</p>
<p>vsn
miroir
</p>
<p>FIG. 2 &#8211; Evolution du F-score moyen pour les verbes en fonction des n candidats garde&#769;s (gauche) et d&#8217;un
seuil minimal d&#8217;association (droite). Un filtre de fre&#769;quence&gt;1000 des candidats a e&#769;te&#769; applique&#769;.
</p>
<p>La table 1 de&#769;taille les re&#769;sultats en fonction des n premiers candidats conside&#769;re&#769;s, en fixant quelques valeurs
des parame&#768;tres. Les scores sont meilleurs quand on filtre les candidats en fre&#769;quence, les scores e&#769;voluant
de fac&#807;on re&#769;gulie&#768;re logarithmiquement. Nous ne montrons ici que les valeurs mimale et maximale des
parame&#768;tres de fre&#769;quence des candidats. On peut constater que la me&#769;thode du miroir est supe&#769;rieure de
fac&#807;on a&#768; peu pre&#768;s uniforme a&#768; celle utilisant les voisins, surtout pour les candidats de fre&#769;quence plus e&#769;leve&#769;e.
L&#8217;e&#769;limination des mots tabous donne un gain de 2 ou 3% supple&#769;mentaires, en enlevant une source de bruit.
Le re&#769;sultat est similaire sur les types de cibles, noms moyennement ou tre&#768;s fre&#769;quents et verbes. Il faut
noter que beaucoup des termes cibles n&#8217;ont pas de voisins (environ 60%), me&#770;me sans filtrage. Un certain
nombre de constatations peuvent e&#770;tre faites, dont nous ne pouvons pre&#769;senter le de&#769;tail par manque de place,
mais que nous synthe&#769;tisons ici. Pour les re&#769;sultats se&#769;pare&#769;s en pre&#769;cision et rappel, on retrouve la me&#770;me
supe&#769;riorite&#769; de la me&#769;thode miroir, qui diminue quand n augmente (les rappels finissent par se confondre).
Les meilleurs re&#769;sultats sont sur les noms, avec a&#768; chaque fois 1 ou 2% de diffe&#769;rence selon les configurations.
Les scores conside&#769;re&#769;s par seuil pre&#769;sentent des e&#769;volutions comparables, et ne font pas appara&#305;&#770;tre de valeur
cle&#769; qui permettrait de de&#769;finir une valeur ge&#769;ne&#769;rale de filtrage. Nous avons donc montre&#769; seulement ceux avec
les n meilleurs candidats, plus faciles a&#768; interpre&#769;ter. On peut noter aussi que combiner les deux ressources
ame&#769;liore encore un peu la fiabilite&#769; des termes propose&#769;s. Les scores en gras sont les maximums d&#8217;une ligne,
</p>
<p>6Les termes pre&#769;sents dans trop de listes candidates sont e&#769;limine&#769;s, comme avoir ou aller dans l&#8217;exemple de la figure 1.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>n 1 5 10 20 30 50 100 oracle
</p>
<p>(N) voisins
freq=1 0,034 0,079 0,097 0,106 0,105 0,097 0,083 0,089
freq=5000 0,081 0,145 0,153 0,145 0,133 0,117 0,092 0,123
</p>
<p>(N) miroir
freq=1 0,059 0,130 0,148 0,149 0,139 0,122 0,093 0,139
freq=5000 0,123 0,201 0,193 0,163 0,141 0,111 0,076 0,179
</p>
<p>(N) combinaison m/vsn
freq=1 0,067 0,143 0,166 0,172 0,169 0,151 0,125 0,138
freq=5000 0,146 0,231 0,232 0,214 0,193 0,163 0,127 0,186
</p>
<p>(N) stop freq=1 0,073 0,151 0,170 0,171 0,161 0,140 0,110 0,136
+ combinaison m/vsn freq=5000 0,170 0,248 0,235 0,199 0,173 0,140 0,104 0,193
</p>
<p>(V) voisins
freq=1 0,030 0,066 0,081 0,098 0,103 0,106 0,102 0,087
freq=5000 0,047 0,103 0,123 0,132 0,130 0,126 0,117 0,097
</p>
<p>(V) miroir
freq=1 0,063 0,143 0,168 0,171 0,162 0,142 0,111 0,161
freq=5000 0,115 0,211 0,209 0,176 0,151 0,119 0,083 0,186
</p>
<p>(V) combinaison m/vs
freq=1 0,060 0,154 0,188 0,205 0,205 0,193 0,163 0,079
freq=5000 0,124 0,250 0,273 0,262 0,245 0,211 0,163 0,127
</p>
<p>TAB. 1 &#8211; F-score moyen par mot, en gardant n candidats pour les verbes, et les noms cibles de
fre&#769;quence&gt;1000, et en faisant varier la fre&#769;quence minimale des candidats. L&#8217;oracle correspond a&#768; n=nombre
de synonymes de la re&#769;fe&#769;rence, pour chaque mot.
</p>
<p>et les scores grise&#769;s sont les maximums d&#8217;une colonne pour chaque cate&#769;gorie (N/V).
</p>
<p>On observe que les scores sont assez bas. La meilleure me&#769;thode qui combine l&#8217;approche distributionnelle
et l&#8217;approche miroir en e&#769;liminant les candidats a&#768; la synonymie dont la fre&#769;quence (dans Wikipe&#769;dia) est
infe&#769;rieure a&#768; 5000 obtient un f-score de 0,273. Ces scores doivent donc pluto&#770;t e&#770;tre conside&#769;re&#769;s comme une
indication de la pertinence des ressources pour une ta&#770;che ulte&#769;rieure de classification de paires synonymes.
Notre objectif a&#768; terme est de replonger les termes dans leurs contextes d&#8217;emploi pour affiner cette premie&#768;re
approche.
</p>
<p>Finalement, nous observons que les scores augmentent syste&#769;matiquement avec la fre&#769;quence minimale des
termes candidats, de fac&#807;on logarithmique, dans une plage de 10% environ. Ce phe&#769;nome&#768;ne est a&#768; peu pre&#768;s
similaire entre les deux me&#769;thodes (voisins/miroir). Nous omettons le cas verbe+liste de stops, peu diffe&#769;rent
des autres.
</p>
<p>5 Discussion
Nos diffe&#769;rentes expe&#769;rimentations montrent qu&#8217;aucune des deux approches de&#769;crites ne permet d&#8217;identifier
seule des relations synonymiques avec fiabilite&#769;. Bien que de nombreux facteurs puissent e&#770;tre responsables
de ce constat, nous observons cependant la supe&#769;riorite&#769; de l&#8217;approche miroir. Les donne&#769;es d&#8217;alignement
bilingue ont e&#769;te&#769; les moins exploite&#769;es pour la recherche de synonymes. On peut citer quelques pre&#769;curseurs
expe&#769;rimentaux, tels que (van der Plas &amp; Tiedemann, 2006), qui comparent deux items avec une mesure de
similarite&#769; entre leurs &#8220;vecteurs d&#8217;alignement&#8221; (la fre&#769;quence d&#8217;alignement d&#8217;un mot avec les autres mots
du lexique) dans diffe&#769;rentes langues, et (Wu &amp; Zhou, 2003) qui ont tente&#769; de combiner line&#769;airement des
classifieurs regroupant tous les types de ressources mentionne&#769;s : similarite&#769; d&#8217;alignement, de distribution
syntaxique, et de proximite&#769; dans un graphe de dictionnaire. Les premiers rapportent des f-scores maxi-
maux de 12%. Les seconds combinent plusieurs classifieurs inte&#769;grant des donne&#769;es distributionnelles et des</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>dictionnaires ; les tests portent sur des classes de termes de fre&#769;quence variable, la meilleure combinaison
donnant 23% sur les noms et 30% sur les verbes. Les donne&#769;es d&#8217;alignement seules donnent respectivement
22 et 26%.
</p>
<p>Les performances de notre approche miroir sont donc comparables, me&#770;me si l&#8217;approche que nous de&#769;crivons
est bien plus simple puisque les travaux sus-mentionne&#769;s doivent calculer entie&#768;rement la matrice N &#215; N
de similarite&#769; des alignements, ou&#768; N est la taille du lexique, et ou&#768; chaque terme est code&#769; par un vecteur de
tous les termes que l&#8217;on peut aligner avec lui.
</p>
<p>A&#768; terme, notre objectif est d&#8217;e&#769;valuer la faisabilite&#769; de l&#8217;apprentissage d&#8217;une relation lexicale a&#768; partir de ces
donne&#769;es, avec comme horizon la collecte d&#8217;un corpus comple&#769;mentaire ou&#768; les termes seraient e&#769;valuables
en contexte. La comple&#769;mentarite&#769; de ces ressources est aussi une question ouverte. Le principal obstacle
the&#769;orique a&#768; ce genre d&#8217;approche est lie&#769; a&#768; la polyse&#769;mie des termes, qu&#8217;elles ne peuvent gue&#768;re distinguer, et
a&#768; la variabilite&#769; en fre&#769;quence des emplois diffe&#769;rents. C&#8217;est pourquoi nous avons aussi analyse&#769; le ro&#770;le de la
fre&#769;quence dans les re&#769;sultats. D&#8217;une part on peut supposer que les mots peu fre&#769;quents ne fourniront pas des
donne&#769;es fiables, et d&#8217;autre part qu&#8217;il sera plus difficile de discriminer les diffe&#769;rentes fonctions des mots
tre&#768;s fre&#769;quents.
</p>
<p>Re&#769;fe&#769;rences
</p>
<p>BOURDAILLET J., HUET S., LANGLAIS P. &amp; LAPALME G. (2010). TransSearch : from a bilingual
concordancer to a translation finder. Mach. Transl., p. 35 pages. To appear.
</p>
<p>BOURIGAULT D. (2002). UPERY : un outil d&#8217;analyse distributionnelle e&#769;tendue pour la construction
d&#8217;ontologies a&#768; partir de corpus. In Actes de la 9ieme confe&#769;rence sur le Traitement Automatique de la
Langue Naturelle, p. 75&#8211;84, Nancy.
</p>
<p>DYVIK H. (2002). Translations as semantic mirrors : From parallel corpus to
wordnet. In The Theory and Use of English Language Corpora, ICAME 2002.
http ://www.hf.uib.no/i/LiLi/SLF/Dyvik/ICAMEpaper.pdf.
</p>
<p>FALK I., GARDENT C., JACQUEY E. &amp; VENANT F. (2009). Sens, synonymes et de&#769;finitions. In
Confe&#769;rence sur le Traitement Automatique du Langage Naturel - TALN&#8217;2009, Senlis France.
</p>
<p>LIN D. (1998). Automatic retrieval and clustering of similar words. In Proceedings of COLING-ACL
&#8217;98, volume 2, p. 768&#8211;774, Montreal.
</p>
<p>NIWA Y. &amp; NITTA Y. (1994). Co-occurrence vectors from corpora vs. distance vectors from dictionaries.
In Proceedings of Coling 1994.
</p>
<p>PLOUX S. &amp; VICTORRI B. (1998). Construction d&#8217;espaces se&#769;mantiques a&#768; l&#8217;aide de dictionnaires de
synonymes. Traitement automatique des langues, 39(1), 161&#8211;182.
VAN DER PLAS L. &amp; TIEDEMANN J. (2006). Finding synonyms using automatic word alignment and
measures of distributional similarity. In Proceedings of the COLING/ACL 2006 Main Conference Poster
Sessions, p. 866&#8211;873, Sydney, Australia : Association for Computational Linguistics.
</p>
<p>WU H. &amp; ZHOU M. (2003). Optimizing synonyms extraction with mono and bilingual resources. In
Proceedings of the Second International Workshop on Paraphrasing, Sapporo, Japan : Association for
Computational Linguistics.</p>

</div></div>
</body></html>