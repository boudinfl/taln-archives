TALN 2010, Montréal, 19-23 juillet 2010

Comparaison de ressources lexicales pour l’eXtraction de synonymes

Philippe {Muller(1) , Langlais(2)}
(1) IRIT, Université de Toulouse & Alpage, INRIA
(2) DIRO, Université de Montreal

1 Introduction

La construction automatique de thesaurus par collecte d’un ensemble de relations entre unités lexicales
(synonymie, antonymie, méronymie, etc) est un objectif relativement ancien en traitement automatique
des langues. Il est parfois étendu par l’ajout d’associations thématiques, aux contours variables. Les tenta-
tives initiales étaient fondées soit sur des dictionnaires numériques, soit sur des analyses distributionnelles
rapprochant des termes ayant des contextes de cooccurrence similaires, soit les deux (Niwa & Nitta, 1994),
prenant éventuellement en compte les fonctions syntaxiques (Lin, 1998). De nombreuses instances de ces
idées ont été proposées plus récemment, que ce soit en exploitant les structures de dictionnaires ou des
données distributionnelles. Quand ils sont évalués, ces efforts se révelent plutot décevants : sauf a faire
des restrictions importantes, les similarités ainsi déﬁnies rapportent un mélange hétérogene de fonctions
lexicales et de termes sémantiquement apparentés sans que les contours de cette parenté soient évidents
a délimiter. La synonymie est sans doute la fonction lexicale la plus testée parIni ces tentatives, car on
dispose de références qui permettent de l’évaluer, jusqu’a un certain point. Le bilan a tirer de ces travaux
est que les données utilisées pour extraire des relations lexicales n’ont sans doute pas livré tout le potentiel
que les auteurs leur attribuent et que l’on connait encore mal la place réelle occupée par les termes en
relations de synonymie parmi les associations calculées.

II a été aussi proposé, de fagon plus marginale, d’utiliser des corpus paralleles multilingues pour retrouver
une similarité entre termes (Dyvik, 2002) en se fondant sur l’hypothese que des termes proches doivent
partager largement leurs traductions. Dans cette optique, on considere les termes associés par des traduc-
tions en “miroir” : les traductions d’un terme d’une langue source 1 dans une langue cible 2 sont Inis en
rapport avec leur traduction dans la langue 1. L’ hypothése est que les termes obtenus apres cet aller-retour
1-2-1 sont des bons candidats a la synonymie avec le terme de départ.

Notre but ici est d’évaluer la présence de la synonymie dans des données d’alignement et des données
distributionnelles pour le frangais, en prenant en compte de fagon conjointe les phénomenes de fréquence
des termes dans l’une ou l’autre de ces ressources. L’une des originalités de cette étude par rapport aux
travaux mentionnés est d’utiliser et d’évaluer un score d’association en miroir entre termes (Dyvik, 2002),
quand les efforts d’évaluation existants se sont concentrés uniquement sur des similarités de vecteurs
d’a1ignements.

La suite de l’article présente les ressources utilisées (section 2), les expérimentations menées (section 3) et
les premieres analyses que nous en tirons (section 4). Nous revenons enﬁn a une discussion des approches
comparables a la notre en section 5.

2 Protocole

Nous tentons de comparer l’aptitude d’une approche distributionnelle et d’une approche miroir a identiﬁer
des synonymes. Nous avons pour cela sélectionné un nombre arbitraire de substantifs et de verbes (4000
de chaque environ) vériﬁant des seuils de fréquence minimale aﬁn d’éviter les termes trop spéciﬁques.
Les fréquences dans cette étude ont été calculées a partir de la version francophone de Wikipédial, soit
environ 200 millions de mots. Les substantifs étant plus nombreux dans notre référence, nous les avons
échantillonnés avec deux seuils différents de fréquence Ininimale, ﬁxés arbitrairement a 100 et 1000.

Les deux approches (distributionnelle etIr1iroir) produisent pour chacun de ces termes “cibles” une liste de
termes candidats synonymes, ordonnés selon un score indiquant leur degré d’association (voir la ﬁgure 1).
Ces listes sont évaluées par leur aptitude a identiﬁer les synonymes d’un lexique de référence. Nous cal-
culons donc les taux de précision/rappel/f-mesure, soit des n meilleurs candidats dans la liste (en faisant
varier n), soit en gardant tous les candidats dont le score dépasse un certain seuil (en faisant varier le seuil).

avoir (0,046), consommer (0,039), étre (0,032), nourrir (0,020), gruger (0,007), aller (0,007), faire
(0,006), prendre (0,005), dévorer (0,005), absorber (0,005), diner (0,005), déposer (0,005), déjeuner
(0,004), alimenter (0,003), servir (0,003), ronger (0,003), avaler (0,003), engloutir (0,003), ...

FIG. 1 — Verbes candidats a la synonymie produits par l’approche Iniroir pour le verbe manger. Ceux en
gras appartiennent a Dicosyn, celui en italique y apparait sous forme pronominale (se nourrir).

Notre lexique de référence est l’union des dictionnaires de synonymes que constitue la ressource electro-
nique Dicosyn, initiée par Ploux & Victorri (1998) a partir de sept dictionnaires classiquesz. Ces dic-
tionnaires sont assez hétérogenes; ainsi les trois plus gros éléments de cet ensemble qui ont une taille
comparable (Du Chazaud, Robert, Larousse) ont un taux de recouvrement moyen assez faible (entre 0,42
et 0,55 de f-score si on les compare deux a deux). La ressource sufﬁt cependant a un objectif de compara-
ison de différentes conﬁgurations.

La fréquence moyenne des verbes (calculée sur Wikipedia), des noms moyennement fréquents et fréquents
est respectivement de 2500, 4300 et 9700, alors le que le nombre moyen de synonymes dans la référence
est de 26, 12 et 15, respectivement, avec un maximum d’environ 180, hors stop-words (abri pour les noms,
battre pour les verbes).

Comme évaluation alternative, on peut aussi envisager des tests comme ceux du TOEFL ou la tache con-
siste a distinguer, parmi plusieurs candidats, un synonyme d’un mot donné dans une phrase exemple. La
synonymie peut étre aussi testée au coup par coup par des lexicographes (Falk et al., 2009).

3 Approches

Nous avons utilisé deux types de ressources pour l’expérimentation : un corpus parallele pour calculer les
associations d’alignement, et des données distributionnelles collectées a partir de Wikipedia.

Ressources distributionnelles : La base de “voisins” distributionnels utilisée a été générée a partir du cor-
pus de l’ensemble des articles de la version francophone de Wikipédia. Elle a été constituée en suivant l’ap-
proche de Lin (1998) : un analyseur syntaxique fournit des comptes de triplets syntaxiques (gouverneur,

1Les données distributionnelles, ainsi que tout ce qui est extrait de Wikipedia, nous ont été foumies par le laboratoire
CLLE—ERSS, o1‘1 elles ont été collectées par Frank Saj ous.
2La ressource a été de plus catégorisée en Verbes/noms/adj ectifs par l’équipe CLLE-ERSS.

relation, dépendant) a un module d’ analyse développé par Bourigault (2002) porté sur Wikipedia par Frank
Sajous. Ce module calcule la similarité de Lin entre des couples de “prédicats” (gouverneur, relation), ou
bien entre des couples de dépendants syntaxiques (“arguments”). Si on considere un prédicat X et un
argument Y, Lin introduit une notion de quantité d’information associée a X ou Y, noté q,-nfo (X), qui est
le logarithme du nombre d’arguments différents du prédicat X rapporté au nombre total d’arguments pos-
sibles. Un score intermédiaire d’information mutuelle entre deux prédicats est alors donné par la somme
des quantités d’informations des arguments qu’ils partagent et le score d’association de Lin est déﬁni en
normalisant par rapport aux sommes de q,-nfo de tous les arguments des deux prédicats. Certains seuils
étant appliqués aux différentes étapes du traitement, chaque item lexical possede un nombre de voisins
variables, qui peut étre nul. Le vocabulaire couvert par les voisins de nos termes cibles représente 25% des
verbes de la référence (hors locutions), et 18-19% des noms selon la restriction fréquentielle. L’ ensemble
des paires cibles-candidats couvre respectivement 24, 25 et 29% des paires recensées par Dicosyn pour
chaque catégorie de cible. Il est évident que les choix du corpus, de la mesure de similarité choisie et de
l’analyseur syntaxique ont une inﬂuence en bout de chaine et seront évalués a terme.

Ressources bilingues : Nous avons Inis a proﬁt une des bases de traductions de l’application TSRali
(Bourdaillet et al., 2010). Cette base contient 8.3 millions de paires de phrases des débats parlementaires
canadiens alignés au niveau des phrases. Ces textes ont ensuite été lemmatisés a l’aide de TreeTager3.
La boite a outil Giza++4 a enﬁn été utilisée aﬁn d’entrainer un modele de traduction statistique. Les
distributions lexicales (IBM4) psgt et pm des modeles obtenus en changeant la langue considérée comme
source au moment de l’entrainement5 ont ensuite été utilisées de maniere a réaliser une approche miroir.
Formellement, nous calculons pour chaque mot de test w :

P(3|w)“ Z Ps2t(t|w)><Pt2s(3|t)

($6732); (111)

pour tout mot de la langue source 3 atteignable depuis w en utilisant la langue cible comme pivot (7's2,;(w)
désigne l’ensemble des mots associés a w dans le modele pm). En pratique, deux seuils (source et cible)
controlent le bruit présent dans les distributions lexicales.

Cette ressource concerne 93 458 (resp. 103 770) formes anglaise (resp. francaises). L’ ensemble des termes
“proposés” par la ressource représente 70% des verbes mentionnés dans la référence DicoSyn(hors lo-
cutions), 40% des noms (F> 100) et 44% des noms (F>1000). Tous les verbes proposés sont présents dans
Dicosyn, alors qu’environ 20% des noms n’apparaissent pas dans cette référence. L’ ensemble des paires
cibles-candidats couvre respectivement 50, 40 et 43% des paires recensées par Dicosyn pour chaque
catégorie de cible. Au vu de ces statistiques, nous avons restreint les évaluations au vocabulaire couvert
en commun par les ressources et la reference.

4 Expérimentations et résultats

Sur le principe des expériences présentées précédemment (étude des n meilleurs candidats, ou passant un
seuil variable), nous avons étudié l’inﬂuence des parametres suivants : catégorie syntaxique (noms, verbes)
classe de fréquence des termes cibles (pour les noms, deux classes de fréquence “forte” et “moyenne
a forte”), fréquence minimale des termes candidats (en faisant varier ce seuil de 0 a 5000 par palliers

3http://www.ims.uni—stuttgart.de/projekte/corplex/TreeTagger/
4http : //fjoch . com/GIZA++ .html
5Les modéles IBM ne sont pas symétriques.

exponentiels) et inﬂuence d’un ﬁltre de mots tabous sur les noms (“stop words”) dans le cas des donnees
d’alignement6. Pour les verbes nous avons enleve les 15 items les plus frequents dans tous les cas. Dans
le cas des n meilleurs candidats, nous avons ajoute un cas ou un oracle donne a la methode le nombre de
synonymes de la reference pour choisir le n adapte a chaque terme. Enﬁn nous avons etudie la combinaison
des ressources en testant l’intersection des candidats proposes par les deux methodes.

La ﬁgure 2 illustre pour une frequence de ﬁltre donnee l’evolution du F-score des candidats proposes par
la methode des voisins et des miroirs, en faisant varier le nombre de termes candidats retenus (gauche),
ou le seuil de score (droite). Dans ce dernier cas, meme si les scores d’association des termes ne sont pas
comparables, on voit nettement la dominance de la methode Iniroir en observant les maxima des deux
courbes dans ce cas precis.

0.22 , . . . 0.25 .

 s-0 vsn 0-0 vsn
0.20—   ><---->< miroir — X X X X ><---->< miroir

g _ X ........................................... H _

.5 X--._ 0.20— 5 X" 
0.1s—.-  — _; 

.5 X L "
0.16—__: _ X

 0.15— 
o.14—_:' _ Q, ‘
g ‘:  =5 . _ _ —¢ \
8  ﬂ . I ’ ‘ \ X
0.124 z’'‘‘’‘ ‘ ' — - --0 — — _ . __";--..., — 5 c’ 0‘
, ____ _ _ . , \
,/  ‘ " - - —-o 010-; ~
p  _; // ‘I\
0.10— /  5 ¢ ~ \
3 I

4 - ~

I 5 ‘\ -.
0.08— 1 L 5 ‘ ‘-.

, 0.05: \\ 

\’.
0 06-'1 — "'-
. I (_
I .

0040 2'0 4‘0 60 80 100 (108.0 0I.l 0.2 013 014 0.5
nbest threshold

FIG. 2 — Evolution du F-score moyen pour les verbes en fonction des 12 candidats gardes (gauche) et d’un
seuil minimal d’association (droite). Un ﬁltre de frequence> 1000 des candidats a ete applique.

La table 1 detaille les resultats en fonction des n premiers candidats consideres, en ﬁxant quelques valeurs
des parametres. Les scores sont meilleurs quand on ﬁltre les candidats en frequence, les scores evoluant
de facon reguliere logarithmiquement. Nous ne montrons ici que les valeurs mimale et maximale des
parametres de frequence des candidats. On peut constater que la methode du Iniroir est superieure de
facon a peu pres uniforme a celle utilisant les voisins, surtout pour les candidats de frequence plus elevee.
L’eliIr1ination des mots tabous donne un gain de 2 ou 3% supplementaires, en enlevant une source de bruit.
Le resultat est similaire sur les types de cibles, noms moyennement ou tres frequents et verbes. Il faut
noter que beaucoup des termes cibles n’ont pas de voisins (environ 60%), meme sans ﬁltrage. Un certain
nombre de constatations peuvent etre faites, dont nous ne pouvons presenter le detail par manque de place,
mais que nous synthetisons ici. Pour les resultats separes en precision et rappel, on retrouve la meme
superiorite de la methode miroir, qui diminue quand n augmente (les rappels ﬁnissent par se confondre).
Les meilleurs resultats sont sur les noms, avec a chaque fois 1 ou 2% de difference selon les conﬁgurations.
Les scores consideres par seuil presentent des evolutions comparables, et ne font pas apparaitre de valeur
cle qui permettrait de deﬁnir une valeur generale de ﬁltrage. Nous avons donc montre seulement ceux avec
les n meilleurs candidats, plus faciles a interpreter. On peut noter aussi que combiner les deux ressources
ameliore encore un peu la ﬁabilite des termes proposes. Les scores en gras sont les maximums d’une ligne,

5Les termes presents dans trop de listes candidates sont elimines, comme avoir ou aller dans l’exemple de la ﬁgure 1.

n 1 5 10 20 30 50 100 oracle
freq=1 0,034 0,079 0,097 0,106 0,105 0,097 0,083 0,089
freq=5000 0,081 0,145 0,153 0,145 0,133 0,117 0,092 0,123
freq=1 0,059 0,130 0,148 0,149 0,139 0,122 0,093 0,139
freq=5000 0,123 0,201 0,193 0,163 0,141 0,111 0,076 0,179
freq=1 0,067 0,143 0,166 0,172 0,169 0,151 0,125 0,138
freq=5000 0,146 0,231 0,232 0,214 0,193 0,163 0,127 0,186
(N) stop freq=1 0,073 0,151 0,170 0,171 0,161 0,140 0,110 0,136
+ combinaison In/vsn freq=5000 0,170 0,248 0,235 0,199 0,173 0,140 0,104 0,193

freq=1 0,030 0,066 0,081 0,098 0,103 0,106 0,102 0,087
freq=5000 0,047 0,103 0,123 0,132 0,130 0,126 0,117 0,097
freq=1 0,063 0,143 0,168 0,171 0,162 0,142 0,111 0,161
freq=5000 0,115 0,211 0,209 0,176 0,151 0,119 0,083 0,186
freq=1 0,060 0,154 0,188 0,205 0,205 0,193 0,163 0,079
freq=5000 0,124 0,250 0,273 0,262 0,245 0,211 0,163 0,127

(N) voisins

(N) Iniroir

(N) combinaison In/vsn

(V) voisins

(V) Iniroir

(V) combinaison In/vs

TAB. 1 — F-score moyen par mot, en gardant n candidats pour les verbes, et les noms cibles de
fréquence> 1000, et en faisant varier la fréquence minimale des candidats. L’ oracle correspond a n=nombre
de synonymes de la référence, pour chaque mot.

et les scores grisés sont les maximums d’une colonne pour chaque catégorie (NN).

On observe que les scores sont assez bas. La meilleure méthode qui combine 1’approche distributionnelle
et 1’approche miroir en éliminant les candidats a la synonymie dont la fréquence (dans Wikipédia) est
inférieure a 5000 obtient un f-score de 0,273. Ces scores doivent donc plutot étre considérés comme une
indication de la pertinence des ressources pour une tache ultérieure de classiﬁcation de paires synonymes.
Notre obj ectif a terme est de replonger les termes dans leurs contextes d’emp1oi pour afﬁner cette premiere
approche.

Finalement, nous observons que les scores augmentent systématiquement avec la fréquence minimale des
termes candidats, de facon logarithmique, dans une plage de 10% environ. Ce phénomene est a peu pres
similaire entre les deux méthodes (voisins/miroir). Nous omettons le cas verbe+liste de stops, peu différent
des autres.

5 Discussion

Nos différentes expérimentations montrent qu’aucune des deux approches décrites ne permet d’identiﬁer
seule des relations synonymiques avec ﬁabilité. Bien que de nombreux facteurs puissent étre responsables
de ce constat, nous observons cependant la supériorité de 1’approche miroir. Les données d’a1ignement
bilingue ont été les moins exploitées pour la recherche de synonymes. On peut citer quelques précurseurs
expérimentaux, tels que (van der Plas & Tiedemann, 2006), qui comparent deux items avec une mesure de
similarité entre leurs “vecteurs d’a1ignement” (la fréquence d’a1ignement d’un mot avec les autres mots
du lexique) dans différentes langues, et (Wu & Zhou, 2003) qui ont tenté de combiner linéairement des
classiﬁeurs regroupant tous les types de ressources mentionnés : similarité d’a1ignement, de distribution
syntaxique, et de proximité dans un graphe de dictionnaire. Les premiers rapportent des f-scores maxi-
maux de 12%. Les seconds combinent plusieurs classiﬁeurs intégrant des données distributionnelles et des

dictionnaires; les tests portent sur des classes de termes de fréquence variable, la meilleure combinaison
donnant 23% sur les noms et 30% sur les verbes. Les données d’alignement seules donnent respectivement
22 et 26%.

Les performances de notre approche Iniroir sont donc comparables, meme si 1’ approche que nous décrivons
est bien plus simple puisque les travaux sus-mentionnés doivent calculer entierement la matrice N X N
de similarité des alignements, ou N est la taille du lexique, et ou chaque terme est codé par un vecteur de
tous les termes que l’on peut aligner avec lui.

A terme, notre objectif est d’évaluer la faisabilité de l’apprentissage d’une relation lexicale a partir de ces
données, avec comme horizon la collecte d’un corpus complémentaire ou les termes seraient évaluables
en contexte. La complémentarité de ces ressources est aussi une question ouverte. Le principal obstacle
théorique a ce genre d’approche est lié a la polysémie des termes, qu’elles ne peuvent guere distinguer, et
a la variabilité en fréquence des emplois différents. C’est pourquoi nous avons aussi analysé le role de la
fréquence dans les résultats. D’une part on peut supposer que les mots peu fréquents ne fourniront pas des
données ﬁables, et d’autre part qu’il sera plus difﬁcile de discriminer les différentes fonctions des mots
tres fréquents.

Références

BOURDAILLET J ., HUET S., LANGLAIS P. & LAPALME G. (2010). TransSearch : from a bilingual
concordancer to a translation ﬁnder. Mach. Transl., p. 35 pages. To appear.

BOURIGAULT D. (2002). UPERY : un outil d’analyse distributionnelle étendue pour la construction
d’ontologies a partir de corpus. In Actes de la 9ieme conference sur le Traitement Automatique de la
Langue Naturelle, p. 75-84, Nancy.

DYVIK H. (2002). Translations as semantic mirrors : From parallel corpus to
wordnet. In The Theory and Use of English Language Corpora, ICAME 2002.
http ://www.hf.uib.no/i/LiLi/SLF/Dyvik/ICAMEpaper.pdf.

FALK I., GARDENT C., JACQUEY E. & VENANT F. (2009). Sens, synonymes et déﬁnitions. In
Conference sur le Traitement Automatique du Langage Naturel - TALN’2009, Senlis France.

LIN D. (1998). Automatic retrieval and clustering of similar words. In Proceedings of COLING-ACL
’98, volume 2, p. 768-774, Montreal.

NIWA Y. & NITTA Y. (1994). Co-occurrence vectors from corpora vs. distance vectors from dictionaries.
In Proceedings of Coling I994.

PLOUX S. & VICTORRI B. (1998). Construction d’espaces sémantiques a l’aide de dictionnaires de
synonymes. Traitement automatique des langues, 39(1), 161-182.

VAN DER PLAS L. & TIEDEMANN J . (2006). Finding synonyms using automatic word alignment and
measures of distributional similarity. In Proceedings of the COLING/ACL 2006 Main Conference Poster
Sessions, p. 866-873, Sydney, Australia : Association for Computational Linguistics.

WU H. & ZHOU M. (2003). Optimizing synonyms extraction with mono and bilingual resources. In
Proceedings of the Second International Workshop on Paraphrasing, Sapporo, Japan : Association for
Computational Linguistics.

