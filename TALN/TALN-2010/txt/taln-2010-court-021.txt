TALN 2010, Montréal, 19–23 juillet 2010
Comparaison de ressources lexicales pour l’extraction de synonymes
Philippe {Muller(1), Langlais(2)}
(1) IRIT, Université de Toulouse & Alpage, INRIA
(2) DIRO, Université de Montréal
1 Introduction
La construction automatique de thesaurus par collecte d’un ensemble de relations entre unités lexicales
(synonymie, antonymie, méronymie, etc) est un objectif relativement ancien en traitement automatique
des langues. Il est parfois étendu par l’ajout d’associations thématiques, aux contours variables. Les tenta-
tives initiales étaient fondées soit sur des dictionnaires numériques, soit sur des analyses distributionnelles
rapprochant des termes ayant des contextes de cooccurrence similaires, soit les deux (Niwa & Nitta, 1994),
prenant éventuellement en compte les fonctions syntaxiques (Lin, 1998). De nombreuses instances de ces
idées ont été proposées plus récemment, que ce soit en exploitant les structures de dictionnaires ou des
données distributionnelles. Quand ils sont évalués, ces efforts se révèlent plutôt décevants : sauf à faire
des restrictions importantes, les similarités ainsi définies rapportent un mélange hétérogène de fonctions
lexicales et de termes sémantiquement apparentés sans que les contours de cette parenté soient évidents
à délimiter. La synonymie est sans doute la fonction lexicale la plus testée parmi ces tentatives, car on
dispose de références qui permettent de l’évaluer, jusqu’à un certain point. Le bilan à tirer de ces travaux
est que les données utilisées pour extraire des relations lexicales n’ont sans doute pas livré tout le potentiel
que les auteurs leur attribuent et que l’on connaı̂t encore mal la place réelle occupée par les termes en
relations de synonymie parmi les associations calculées.
Il a été aussi proposé, de façon plus marginale, d’utiliser des corpus parallèles multilingues pour retrouver
une similarité entre termes (Dyvik, 2002) en se fondant sur l’hypothèse que des termes proches doivent
partager largement leurs traductions. Dans cette optique, on considère les termes associés par des traduc-
tions en “miroir” : les traductions d’un terme d’une langue source 1 dans une langue cible 2 sont mis en
rapport avec leur traduction dans la langue 1. L’hypothèse est que les termes obtenus après cet aller-retour
1-2-1 sont des bons candidats à la synonymie avec le terme de départ.
Notre but ici est d’évaluer la présence de la synonymie dans des données d’alignement et des données
distributionnelles pour le français, en prenant en compte de façon conjointe les phénomènes de fréquence
des termes dans l’une ou l’autre de ces ressources. L’une des originalités de cette étude par rapport aux
travaux mentionnés est d’utiliser et d’évaluer un score d’association en miroir entre termes (Dyvik, 2002),
quand les efforts d’évaluation existants se sont concentrés uniquement sur des similarités de vecteurs
d’alignements.
La suite de l’article présente les ressources utilisées (section 2), les expérimentations menées (section 3) et
les premières analyses que nous en tirons (section 4). Nous revenons enfin à une discussion des approches
comparables à la nôtre en section 5.
2 Protocole
Nous tentons de comparer l’aptitude d’une approche distributionnelle et d’une approche miroir à identifier
des synonymes. Nous avons pour cela sélectionné un nombre arbitraire de substantifs et de verbes (4000
de chaque environ) vérifiant des seuils de fréquence minimale afin d’éviter les termes trop spécifiques.
Les fréquences dans cette étude ont été calculées à partir de la version francophone de Wikipédia1, soit
environ 200 millions de mots. Les substantifs étant plus nombreux dans notre référence, nous les avons
échantillonnés avec deux seuils différents de fréquence minimale, fixés arbitrairement à 100 et 1000.
Les deux approches (distributionnelle et miroir) produisent pour chacun de ces termes “cibles” une liste de
termes candidats synonymes, ordonnés selon un score indiquant leur degré d’association (voir la figure 1).
Ces listes sont évaluées par leur aptitude à identifier les synonymes d’un lexique de référence. Nous cal-
culons donc les taux de précision/rappel/f-mesure, soit des n meilleurs candidats dans la liste (en faisant
varier n), soit en gardant tous les candidats dont le score dépasse un certain seuil (en faisant varier le seuil).
avoir (0,046), consommer (0,039), être (0,032), nourrir (0,020), gruger (0,007), aller (0,007), faire
(0,006), prendre (0,005), dévorer (0,005), absorber (0,005), dı̂ner (0,005), déposer (0,005), déjeuner
(0,004), alimenter (0,003), servir (0,003), ronger (0,003), avaler (0,003), engloutir (0,003), . . .
FIG. 1 – Verbes candidats à la synonymie produits par l’approche miroir pour le verbe manger. Ceux en
gras appartiennent à DicoSyn, celui en italique y apparaı̂t sous forme pronominale (se nourrir).
Notre lexique de référence est l’union des dictionnaires de synonymes que constitue la ressource électro-
nique DicoSyn, initiée par Ploux & Victorri (1998) à partir de sept dictionnaires classiques2. Ces dic-
tionnaires sont assez hétérogènes ; ainsi les trois plus gros éléments de cet ensemble qui ont une taille
comparable (Du Chazaud, Robert, Larousse) ont un taux de recouvrement moyen assez faible (entre 0,42
et 0,55 de f-score si on les compare deux à deux). La ressource suffit cependant à un objectif de compara-
ison de différentes configurations.
La fréquence moyenne des verbes (calculée sur Wikipedia), des noms moyennement fréquents et fréquents
est respectivement de 2500, 4300 et 9700, alors le que le nombre moyen de synonymes dans la référence
est de 26, 12 et 15, respectivement, avec un maximum d’environ 180, hors stop-words (abri pour les noms,
battre pour les verbes).
Comme évaluation alternative, on peut aussi envisager des tests comme ceux du TOEFL où la tâche con-
siste à distinguer, parmi plusieurs candidats, un synonyme d’un mot donné dans une phrase exemple. La
synonymie peut être aussi testée au coup par coup par des lexicographes (Falk et al., 2009).
3 Approches
Nous avons utilisé deux types de ressources pour l’expérimentation : un corpus parallèle pour calculer les
associations d’alignement, et des données distributionnelles collectées à partir de Wikipedia.
Ressources distributionnelles : La base de “voisins” distributionnels utilisée a été générée à partir du cor-
pus de l’ensemble des articles de la version francophone de Wikipédia. Elle a été constituée en suivant l’ap-
proche de Lin (1998) : un analyseur syntaxique fournit des comptes de triplets syntaxiques (gouverneur,
1Les données distributionnelles, ainsi que tout ce qui est extrait de Wikipedia, nous ont été fournies par le laboratoire
CLLE-ERSS, où elles ont été collectées par Frank Sajous.
2La ressource a été de plus catégorisée en verbes/noms/adjectifs par l’équipe CLLE-ERSS.
relation, dépendant) à un module d’analyse développé par Bourigault (2002) porté sur Wikipedia par Frank
Sajous. Ce module calcule la similarité de Lin entre des couples de “prédicats” (gouverneur, relation), ou
bien entre des couples de dépendants syntaxiques (“arguments”). Si on considère un prédicat X et un
argument Y , Lin introduit une notion de quantité d’information associée à X ou Y , noté qinfo(X), qui est
le logarithme du nombre d’arguments différents du prédicat X rapporté au nombre total d’arguments pos-
sibles. Un score intermédiaire d’information mutuelle entre deux prédicats est alors donné par la somme
des quantités d’informations des arguments qu’ils partagent et le score d’association de Lin est défini en
normalisant par rapport aux sommes de qinfo de tous les arguments des deux prédicats. Certains seuils
étant appliqués aux différentes étapes du traitement, chaque item lexical possède un nombre de voisins
variables, qui peut être nul. Le vocabulaire couvert par les voisins de nos termes cibles représente 25% des
verbes de la référence (hors locutions), et 18-19% des noms selon la restriction fréquentielle. L’ensemble
des paires cibles-candidats couvre respectivement 24, 25 et 29% des paires recensées par DicoSyn pour
chaque catégorie de cible. Il est évident que les choix du corpus, de la mesure de similarité choisie et de
l’analyseur syntaxique ont une influence en bout de chaı̂ne et seront évalués à terme.
Ressources bilingues : Nous avons mis à profit une des bases de traductions de l’application TSRali
(Bourdaillet et al., 2010). Cette base contient 8.3 millions de paires de phrases des débats parlementaires
canadiens alignés au niveau des phrases. Ces textes ont ensuite été lemmatisés à l’aide de TreeTager3.
La boı̂te à outil Giza++4 a enfin été utilisée afin d’entraı̂ner un modèle de traduction statistique. Les
distributions lexicales (IBM4) ps2t et pt2s des modèles obtenus en changeant la langue considérée comme
source au moment de l’entraı̂nement5 ont ensuite été utilisées de manière à réaliser une approche miroir.
Formellement, nous calculons pour chaque mot de test w :
p(s|w) ≈ ∑ ps2t(t|w)× pt2s(s|t)
t∈τs2t(w)
pour tout mot de la langue source s atteignable depuis w en utilisant la langue cible comme pivot (τs2t(w)
désigne l’ensemble des mots associés à w dans le modèle ps2t). En pratique, deux seuils (source et cible)
contrôlent le bruit présent dans les distributions lexicales.
Cette ressource concerne 93 458 (resp. 103 770) formes anglaise (resp. françaises). L’ensemble des termes
“proposés” par la ressource représente 70% des verbes mentionnés dans la référence DicoSyn(hors lo-
cutions), 40% des noms (F>100) et 44% des noms (F>1000). Tous les verbes proposés sont présents dans
DicoSyn, alors qu’environ 20% des noms n’apparaissent pas dans cette référence. L’ensemble des paires
cibles-candidats couvre respectivement 50, 40 et 43% des paires recensées par DicoSyn pour chaque
catégorie de cible. Au vu de ces statistiques, nous avons restreint les évaluations au vocabulaire couvert
en commun par les ressources et la référence.
4 Expérimentations et résultats
Sur le principe des expériences présentées précédemment (étude des n meilleurs candidats, ou passant un
seuil variable), nous avons étudié l’influence des paramètres suivants : catégorie syntaxique (noms, verbes)
classe de fréquence des termes cibles (pour les noms, deux classes de fréquence “forte” et “moyenne
à forte”), fréquence minimale des termes candidats (en faisant varier ce seuil de 0 à 5000 par palliers
3http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
4http://fjoch.com/GIZA++.html
5Les modèles IBM ne sont pas symétriques.
exponentiels) et influence d’un filtre de mots tabous sur les noms (“stop words”) dans le cas des données
d’alignement6. Pour les verbes nous avons enlevé les 15 items les plus fréquents dans tous les cas. Dans
le cas des n meilleurs candidats, nous avons ajouté un cas où un oracle donne à la méthode le nombre de
synonymes de la référence pour choisir le n adapté à chaque terme. Enfin nous avons étudié la combinaison
des ressources en testant l’intersection des candidats proposés par les deux méthodes.
La figure 2 illustre pour une fréquence de filtre donnée l’évolution du F-score des candidats proposés par
la méthode des voisins et des miroirs, en faisant varier le nombre de termes candidats retenus (gauche),
ou le seuil de score (droite). Dans ce dernier cas, même si les scores d’association des termes ne sont pas
comparables, on voit nettement la dominance de la méthode miroir en observant les maxima des deux
courbes dans ce cas précis.
0.22 0.25
vsn vsn
0.20 miroir miroir
0.18 0.20
0.16
0.15
0.14
0.12
0.10
0.10
0.08 0.05
0.06
0.040 20 40 60 80 100 0.000.0 0.1 0.2 0.3 0.4 0.5
nbest threshold
FIG. 2 – Evolution du F-score moyen pour les verbes en fonction des n candidats gardés (gauche) et d’un
seuil minimal d’association (droite). Un filtre de fréquence>1000 des candidats a été appliqué.
La table 1 détaille les résultats en fonction des n premiers candidats considérés, en fixant quelques valeurs
des paramètres. Les scores sont meilleurs quand on filtre les candidats en fréquence, les scores évoluant
de façon régulière logarithmiquement. Nous ne montrons ici que les valeurs mimale et maximale des
paramètres de fréquence des candidats. On peut constater que la méthode du miroir est supérieure de
façon à peu près uniforme à celle utilisant les voisins, surtout pour les candidats de fréquence plus élevée.
L’élimination des mots tabous donne un gain de 2 ou 3% supplémentaires, en enlevant une source de bruit.
Le résultat est similaire sur les types de cibles, noms moyennement ou très fréquents et verbes. Il faut
noter que beaucoup des termes cibles n’ont pas de voisins (environ 60%), même sans filtrage. Un certain
nombre de constatations peuvent être faites, dont nous ne pouvons présenter le détail par manque de place,
mais que nous synthétisons ici. Pour les résultats séparés en précision et rappel, on retrouve la même
supériorité de la méthode miroir, qui diminue quand n augmente (les rappels finissent par se confondre).
Les meilleurs résultats sont sur les noms, avec à chaque fois 1 ou 2% de différence selon les configurations.
Les scores considérés par seuil présentent des évolutions comparables, et ne font pas apparaı̂tre de valeur
clé qui permettrait de définir une valeur générale de filtrage. Nous avons donc montré seulement ceux avec
les n meilleurs candidats, plus faciles à interpréter. On peut noter aussi que combiner les deux ressources
améliore encore un peu la fiabilité des termes proposés. Les scores en gras sont les maximums d’une ligne,
6Les termes présents dans trop de listes candidates sont éliminés, comme avoir ou aller dans l’exemple de la figure 1.
score
score
n 1 5 10 20 30 50 100 oracle
freq=1 0,034 0,079 0,097 0,106 0,105 0,097 0,083 0,089
(N) voisins
freq=5000 0,081 0,145 0,153 0,145 0,133 0,117 0,092 0,123
freq=1 0,059 0,130 0,148 0,149 0,139 0,122 0,093 0,139
(N) miroir
freq=5000 0,123 0,201 0,193 0,163 0,141 0,111 0,076 0,179
freq=1 0,067 0,143 0,166 0,172 0,169 0,151 0,125 0,138
(N) combinaison m/vsn
freq=5000 0,146 0,231 0,232 0,214 0,193 0,163 0,127 0,186
(N) stop freq=1 0,073 0,151 0,170 0,171 0,161 0,140 0,110 0,136
+ combinaison m/vsn freq=5000 0,170 0,248 0,235 0,199 0,173 0,140 0,104 0,193
freq=1 0,030 0,066 0,081 0,098 0,103 0,106 0,102 0,087
(V) voisins
freq=5000 0,047 0,103 0,123 0,132 0,130 0,126 0,117 0,097
freq=1 0,063 0,143 0,168 0,171 0,162 0,142 0,111 0,161
(V) miroir
freq=5000 0,115 0,211 0,209 0,176 0,151 0,119 0,083 0,186
freq=1 0,060 0,154 0,188 0,205 0,205 0,193 0,163 0,079
(V) combinaison m/vs
freq=5000 0,124 0,250 0,273 0,262 0,245 0,211 0,163 0,127
TAB. 1 – F-score moyen par mot, en gardant n candidats pour les verbes, et les noms cibles de
fréquence>1000, et en faisant varier la fréquence minimale des candidats. L’oracle correspond à n=nombre
de synonymes de la référence, pour chaque mot.
et les scores grisés sont les maximums d’une colonne pour chaque catégorie (N/V).
On observe que les scores sont assez bas. La meilleure méthode qui combine l’approche distributionnelle
et l’approche miroir en éliminant les candidats à la synonymie dont la fréquence (dans Wikipédia) est
inférieure à 5000 obtient un f-score de 0,273. Ces scores doivent donc plutôt être considérés comme une
indication de la pertinence des ressources pour une tâche ultérieure de classification de paires synonymes.
Notre objectif à terme est de replonger les termes dans leurs contextes d’emploi pour affiner cette première
approche.
Finalement, nous observons que les scores augmentent systématiquement avec la fréquence minimale des
termes candidats, de façon logarithmique, dans une plage de 10% environ. Ce phénomène est à peu près
similaire entre les deux méthodes (voisins/miroir). Nous omettons le cas verbe+liste de stops, peu différent
des autres.
5 Discussion
Nos différentes expérimentations montrent qu’aucune des deux approches décrites ne permet d’identifier
seule des relations synonymiques avec fiabilité. Bien que de nombreux facteurs puissent être responsables
de ce constat, nous observons cependant la supériorité de l’approche miroir. Les données d’alignement
bilingue ont été les moins exploitées pour la recherche de synonymes. On peut citer quelques précurseurs
expérimentaux, tels que (van der Plas & Tiedemann, 2006), qui comparent deux items avec une mesure de
similarité entre leurs “vecteurs d’alignement” (la fréquence d’alignement d’un mot avec les autres mots
du lexique) dans différentes langues, et (Wu & Zhou, 2003) qui ont tenté de combiner linéairement des
classifieurs regroupant tous les types de ressources mentionnés : similarité d’alignement, de distribution
syntaxique, et de proximité dans un graphe de dictionnaire. Les premiers rapportent des f-scores maxi-
maux de 12%. Les seconds combinent plusieurs classifieurs intégrant des données distributionnelles et des
dictionnaires ; les tests portent sur des classes de termes de fréquence variable, la meilleure combinaison
donnant 23% sur les noms et 30% sur les verbes. Les données d’alignement seules donnent respectivement
22 et 26%.
Les performances de notre approche miroir sont donc comparables, même si l’approche que nous décrivons
est bien plus simple puisque les travaux sus-mentionnés doivent calculer entièrement la matrice N × N
de similarité des alignements, où N est la taille du lexique, et où chaque terme est codé par un vecteur de
tous les termes que l’on peut aligner avec lui.
À terme, notre objectif est d’évaluer la faisabilité de l’apprentissage d’une relation lexicale à partir de ces
données, avec comme horizon la collecte d’un corpus complémentaire où les termes seraient évaluables
en contexte. La complémentarité de ces ressources est aussi une question ouverte. Le principal obstacle
théorique à ce genre d’approche est lié à la polysémie des termes, qu’elles ne peuvent guère distinguer, et
à la variabilité en fréquence des emplois différents. C’est pourquoi nous avons aussi analysé le rôle de la
fréquence dans les résultats. D’une part on peut supposer que les mots peu fréquents ne fourniront pas des
données fiables, et d’autre part qu’il sera plus difficile de discriminer les différentes fonctions des mots
très fréquents.
Références
BOURDAILLET J., HUET S., LANGLAIS P. & LAPALME G. (2010). TransSearch : from a bilingual
concordancer to a translation finder. Mach. Transl., p. 35 pages. To appear.
BOURIGAULT D. (2002). UPERY : un outil d’analyse distributionnelle étendue pour la construction
d’ontologies à partir de corpus. In Actes de la 9ieme conférence sur le Traitement Automatique de la
Langue Naturelle, p. 75–84, Nancy.
DYVIK H. (2002). Translations as semantic mirrors : From parallel corpus to
wordnet. In The Theory and Use of English Language Corpora, ICAME 2002.
http ://www.hf.uib.no/i/LiLi/SLF/Dyvik/ICAMEpaper.pdf.
FALK I., GARDENT C., JACQUEY E. & VENANT F. (2009). Sens, synonymes et définitions. In
Conférence sur le Traitement Automatique du Langage Naturel - TALN’2009, Senlis France.
LIN D. (1998). Automatic retrieval and clustering of similar words. In Proceedings of COLING-ACL
’98, volume 2, p. 768–774, Montreal.
NIWA Y. & NITTA Y. (1994). Co-occurrence vectors from corpora vs. distance vectors from dictionaries.
In Proceedings of Coling 1994.
PLOUX S. & VICTORRI B. (1998). Construction d’espaces sémantiques à l’aide de dictionnaires de
synonymes. Traitement automatique des langues, 39(1), 161–182.
VAN DER PLAS L. & TIEDEMANN J. (2006). Finding synonyms using automatic word alignment and
measures of distributional similarity. In Proceedings of the COLING/ACL 2006 Main Conference Poster
Sessions, p. 866–873, Sydney, Australia : Association for Computational Linguistics.
WU H. & ZHOU M. (2003). Optimizing synonyms extraction with mono and bilingual resources. In
Proceedings of the Second International Workshop on Paraphrasing, Sapporo, Japan : Association for
Computational Linguistics.
