TALN 2010, Montre«al, 19Ð23 juillet 2010
Comparaison de ressources lexicales pour lÕextraction de synonymes
Philippe {Muller(1), Langlais(2)}
(1) IRIT, Universite« de Toulouse & Alpage, INRIA
(2) DIRO, Universite« de Montre«al
1 Introduction
La construction automatique de thesaurus par collecte dÕun ensemble de relations entre unite«s lexicales
(synonymie, antonymie, me«ronymie, etc) est un objectif relativement ancien en traitement automatique
des langues. Il est parfois e«tendu par lÕajout dÕassociations the«matiques, aux contours variables. Les tenta-
tives initiales e«taient fonde«es soit sur des dictionnaires nume«riques, soit sur des analyses distributionnelles
rapprochant des termes ayant des contextes de cooccurrence similaires, soit les deux (Niwa & Nitta, 1994),
prenant e«ventuellement en compte les fonctions syntaxiques (Lin, 1998). De nombreuses instances de ces
ide«es ont e«te« propose«es plus re«cemment, que ce soit en exploitant les structures de dictionnaires ou des
donne«es distributionnelles. Quand ils sont e«value«s, ces efforts se re«ve`lent plutoöt de«cevants : sauf a` faire
des restrictions importantes, les similarite«s ainsi de«finies rapportent un me«lange he«te«roge`ne de fonctions
lexicales et de termes se«mantiquement apparente«s sans que les contours de cette parente« soient e«vidents
a` de«limiter. La synonymie est sans doute la fonction lexicale la plus teste«e parmi ces tentatives, car on
dispose de re«fe«rences qui permettent de lÕe«valuer, jusquÕa` un certain point. Le bilan a` tirer de ces travaux
est que les donne«es utilise«es pour extraire des relations lexicales nÕont sans doute pas livre« tout le potentiel
que les auteurs leur attribuent et que lÕon connaõöt encore mal la place re«elle occupe«e par les termes en
relations de synonymie parmi les associations calcule«es.
Il a e«te« aussi propose«, de facüon plus marginale, dÕutiliser des corpus paralle`les multilingues pour retrouver
une similarite« entre termes (Dyvik, 2002) en se fondant sur lÕhypothe`se que des termes proches doivent
partager largement leurs traductions. Dans cette optique, on conside`re les termes associe«s par des traduc-
tions en ÒmiroirÓ : les traductions dÕun terme dÕune langue source 1 dans une langue cible 2 sont mis en
rapport avec leur traduction dans la langue 1. LÕhypothe`se est que les termes obtenus apre`s cet aller-retour
1-2-1 sont des bons candidats a` la synonymie avec le terme de de«part.
Notre but ici est dÕe«valuer la pre«sence de la synonymie dans des donne«es dÕalignement et des donne«es
distributionnelles pour le francüais, en prenant en compte de facüon conjointe les phe«nome`nes de fre«quence
des termes dans lÕune ou lÕautre de ces ressources. LÕune des originalite«s de cette e«tude par rapport aux
travaux mentionne«s est dÕutiliser et dÕe«valuer un score dÕassociation en miroir entre termes (Dyvik, 2002),
quand les efforts dÕe«valuation existants se sont concentre«s uniquement sur des similarite«s de vecteurs
dÕalignements.
La suite de lÕarticle pre«sente les ressources utilise«es (section 2), les expe«rimentations mene«es (section 3) et
les premie`res analyses que nous en tirons (section 4). Nous revenons enfin a` une discussion des approches
comparables a` la noötre en section 5.
2 Protocole
Nous tentons de comparer lÕaptitude dÕune approche distributionnelle et dÕune approche miroir a` identifier
des synonymes. Nous avons pour cela se«lectionne« un nombre arbitraire de substantifs et de verbes (4000
de chaque environ) ve«rifiant des seuils de fre«quence minimale afin dÕe«viter les termes trop spe«cifiques.
Les fre«quences dans cette e«tude ont e«te« calcule«es a` partir de la version francophone de Wikipe«dia1, soit
environ 200 millions de mots. Les substantifs e«tant plus nombreux dans notre re«fe«rence, nous les avons
e«chantillonne«s avec deux seuils diffe«rents de fre«quence minimale, fixe«s arbitrairement a` 100 et 1000.
Les deux approches (distributionnelle et miroir) produisent pour chacun de ces termes ÒciblesÓ une liste de
termes candidats synonymes, ordonne«s selon un score indiquant leur degre« dÕassociation (voir la figure 1).
Ces listes sont e«value«es par leur aptitude a` identifier les synonymes dÕun lexique de re«fe«rence. Nous cal-
culons donc les taux de pre«cision/rappel/f-mesure, soit des n meilleurs candidats dans la liste (en faisant
varier n), soit en gardant tous les candidats dont le score de«passe un certain seuil (en faisant varier le seuil).
avoir (0,046), consommer (0,039), eötre (0,032), nourrir (0,020), gruger (0,007), aller (0,007), faire
(0,006), prendre (0,005), de«vorer (0,005), absorber (0,005), dõöner (0,005), de«poser (0,005), de«jeuner
(0,004), alimenter (0,003), servir (0,003), ronger (0,003), avaler (0,003), engloutir (0,003), . . .
FIG. 1 Ð Verbes candidats a` la synonymie produits par lÕapproche miroir pour le verbe manger. Ceux en
gras appartiennent a` DicoSyn, celui en italique y apparaõöt sous forme pronominale (se nourrir).
Notre lexique de re«fe«rence est lÕunion des dictionnaires de synonymes que constitue la ressource e«lectro-
nique DicoSyn, initie«e par Ploux & Victorri (1998) a` partir de sept dictionnaires classiques2. Ces dic-
tionnaires sont assez he«te«roge`nes ; ainsi les trois plus gros e«le«ments de cet ensemble qui ont une taille
comparable (Du Chazaud, Robert, Larousse) ont un taux de recouvrement moyen assez faible (entre 0,42
et 0,55 de f-score si on les compare deux a` deux). La ressource suffit cependant a` un objectif de compara-
ison de diffe«rentes configurations.
La fre«quence moyenne des verbes (calcule«e sur Wikipedia), des noms moyennement fre«quents et fre«quents
est respectivement de 2500, 4300 et 9700, alors le que le nombre moyen de synonymes dans la re«fe«rence
est de 26, 12 et 15, respectivement, avec un maximum dÕenviron 180, hors stop-words (abri pour les noms,
battre pour les verbes).
Comme e«valuation alternative, on peut aussi envisager des tests comme ceux du TOEFL ou` la taöche con-
siste a` distinguer, parmi plusieurs candidats, un synonyme dÕun mot donne« dans une phrase exemple. La
synonymie peut eötre aussi teste«e au coup par coup par des lexicographes (Falk et al., 2009).
3 Approches
Nous avons utilise« deux types de ressources pour lÕexpe«rimentation : un corpus paralle`le pour calculer les
associations dÕalignement, et des donne«es distributionnelles collecte«es a` partir de Wikipedia.
Ressources distributionnelles : La base de ÒvoisinsÓ distributionnels utilise«e a e«te« ge«ne«re«e a` partir du cor-
pus de lÕensemble des articles de la version francophone de Wikipe«dia. Elle a e«te« constitue«e en suivant lÕap-
proche de Lin (1998) : un analyseur syntaxique fournit des comptes de triplets syntaxiques (gouverneur,
1Les donne«es distributionnelles, ainsi que tout ce qui est extrait de Wikipedia, nous ont e«te« fournies par le laboratoire
CLLE-ERSS, ou` elles ont e«te« collecte«es par Frank Sajous.
2La ressource a e«te« de plus cate«gorise«e en verbes/noms/adjectifs par lÕe«quipe CLLE-ERSS.
relation, de«pendant) a` un module dÕanalyse de«veloppe« par Bourigault (2002) porte« sur Wikipedia par Frank
Sajous. Ce module calcule la similarite« de Lin entre des couples de Òpre«dicatsÓ (gouverneur, relation), ou
bien entre des couples de de«pendants syntaxiques (ÒargumentsÓ). Si on conside`re un pre«dicat X et un
argument Y , Lin introduit une notion de quantite« dÕinformation associe«e a` X ou Y , note« qinfo(X), qui est
le logarithme du nombre dÕarguments diffe«rents du pre«dicat X rapporte« au nombre total dÕarguments pos-
sibles. Un score interme«diaire dÕinformation mutuelle entre deux pre«dicats est alors donne« par la somme
des quantite«s dÕinformations des arguments quÕils partagent et le score dÕassociation de Lin est de«fini en
normalisant par rapport aux sommes de qinfo de tous les arguments des deux pre«dicats. Certains seuils
e«tant applique«s aux diffe«rentes e«tapes du traitement, chaque item lexical posse`de un nombre de voisins
variables, qui peut eötre nul. Le vocabulaire couvert par les voisins de nos termes cibles repre«sente 25% des
verbes de la re«fe«rence (hors locutions), et 18-19% des noms selon la restriction fre«quentielle. LÕensemble
des paires cibles-candidats couvre respectivement 24, 25 et 29% des paires recense«es par DicoSyn pour
chaque cate«gorie de cible. Il est e«vident que les choix du corpus, de la mesure de similarite« choisie et de
lÕanalyseur syntaxique ont une influence en bout de chaõöne et seront e«value«s a` terme.
Ressources bilingues : Nous avons mis a` profit une des bases de traductions de lÕapplication TSRali
(Bourdaillet et al., 2010). Cette base contient 8.3 millions de paires de phrases des de«bats parlementaires
canadiens aligne«s au niveau des phrases. Ces textes ont ensuite e«te« lemmatise«s a` lÕaide de TreeTager3.
La boõöte a` outil Giza++4 a enfin e«te« utilise«e afin dÕentraõöner un mode`le de traduction statistique. Les
distributions lexicales (IBM4) ps2t et pt2s des mode`les obtenus en changeant la langue conside«re«e comme
source au moment de lÕentraõönement5 ont ensuite e«te« utilise«es de manie`re a` re«aliser une approche miroir.
Formellement, nous calculons pour chaque mot de test w :
p(s|w) Å ·
t??s2t(w)
ps2t(t|w)? pt2s(s|t)
pour tout mot de la langue source s atteignable depuis w en utilisant la langue cible comme pivot (?s2t(w)
de«signe lÕensemble des mots associe«s a` w dans le mode`le ps2t). En pratique, deux seuils (source et cible)
controölent le bruit pre«sent dans les distributions lexicales.
Cette ressource concerne 93 458 (resp. 103 770) formes anglaise (resp. francüaises). LÕensemble des termes
Òpropose«sÓ par la ressource repre«sente 70% des verbes mentionne«s dans la re«fe«rence DicoSyn(hors lo-
cutions), 40% des noms (F>100) et 44% des noms (F>1000). Tous les verbes propose«s sont pre«sents dans
DicoSyn, alors quÕenviron 20% des noms nÕapparaissent pas dans cette re«fe«rence. LÕensemble des paires
cibles-candidats couvre respectivement 50, 40 et 43% des paires recense«es par DicoSyn pour chaque
cate«gorie de cible. Au vu de ces statistiques, nous avons restreint les e«valuations au vocabulaire couvert
en commun par les ressources et la re«fe«rence.
4 Expe«rimentations et re«sultats
Sur le principe des expe«riences pre«sente«es pre«ce«demment (e«tude des n meilleurs candidats, ou passant un
seuil variable), nous avons e«tudie« lÕinfluence des parame`tres suivants : cate«gorie syntaxique (noms, verbes)
classe de fre«quence des termes cibles (pour les noms, deux classes de fre«quence ÒforteÓ et Òmoyenne
a` forteÓ), fre«quence minimale des termes candidats (en faisant varier ce seuil de 0 a` 5000 par palliers
3http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
4http://fjoch.com/GIZA++.html
5Les mode`les IBM ne sont pas syme«triques.
exponentiels) et influence dÕun filtre de mots tabous sur les noms (Òstop wordsÓ) dans le cas des donne«es
dÕalignement6. Pour les verbes nous avons enleve« les 15 items les plus fre«quents dans tous les cas. Dans
le cas des n meilleurs candidats, nous avons ajoute« un cas ou` un oracle donne a` la me«thode le nombre de
synonymes de la re«fe«rence pour choisir le n adapte« a` chaque terme. Enfin nous avons e«tudie« la combinaison
des ressources en testant lÕintersection des candidats propose«s par les deux me«thodes.
La figure 2 illustre pour une fre«quence de filtre donne«e lÕe«volution du F-score des candidats propose«s par
la me«thode des voisins et des miroirs, en faisant varier le nombre de termes candidats retenus (gauche),
ou le seuil de score (droite). Dans ce dernier cas, meöme si les scores dÕassociation des termes ne sont pas
comparables, on voit nettement la dominance de la me«thode miroir en observant les maxima des deux
courbes dans ce cas pre«cis.
0 20 40 60 80 100
nbest
0.04
0.06
0.08
0.10
0.12
0.14
0.16
0.18
0.20
0.22
sc
or
e
vsn
miroir
0.0 0.1 0.2 0.3 0.4 0.5
threshold
0.00
0.05
0.10
0.15
0.20
0.25
sc
or
e
vsn
miroir
FIG. 2 Ð Evolution du F-score moyen pour les verbes en fonction des n candidats garde«s (gauche) et dÕun
seuil minimal dÕassociation (droite). Un filtre de fre«quence>1000 des candidats a e«te« applique«.
La table 1 de«taille les re«sultats en fonction des n premiers candidats conside«re«s, en fixant quelques valeurs
des parame`tres. Les scores sont meilleurs quand on filtre les candidats en fre«quence, les scores e«voluant
de facüon re«gulie`re logarithmiquement. Nous ne montrons ici que les valeurs mimale et maximale des
parame`tres de fre«quence des candidats. On peut constater que la me«thode du miroir est supe«rieure de
facüon a` peu pre`s uniforme a` celle utilisant les voisins, surtout pour les candidats de fre«quence plus e«leve«e.
LÕe«limination des mots tabous donne un gain de 2 ou 3% supple«mentaires, en enlevant une source de bruit.
Le re«sultat est similaire sur les types de cibles, noms moyennement ou tre`s fre«quents et verbes. Il faut
noter que beaucoup des termes cibles nÕont pas de voisins (environ 60%), meöme sans filtrage. Un certain
nombre de constatations peuvent eötre faites, dont nous ne pouvons pre«senter le de«tail par manque de place,
mais que nous synthe«tisons ici. Pour les re«sultats se«pare«s en pre«cision et rappel, on retrouve la meöme
supe«riorite« de la me«thode miroir, qui diminue quand n augmente (les rappels finissent par se confondre).
Les meilleurs re«sultats sont sur les noms, avec a` chaque fois 1 ou 2% de diffe«rence selon les configurations.
Les scores conside«re«s par seuil pre«sentent des e«volutions comparables, et ne font pas apparaõötre de valeur
cle« qui permettrait de de«finir une valeur ge«ne«rale de filtrage. Nous avons donc montre« seulement ceux avec
les n meilleurs candidats, plus faciles a` interpre«ter. On peut noter aussi que combiner les deux ressources
ame«liore encore un peu la fiabilite« des termes propose«s. Les scores en gras sont les maximums dÕune ligne,
6Les termes pre«sents dans trop de listes candidates sont e«limine«s, comme avoir ou aller dans lÕexemple de la figure 1.
n 1 5 10 20 30 50 100 oracle
(N) voisins
freq=1 0,034 0,079 0,097 0,106 0,105 0,097 0,083 0,089
freq=5000 0,081 0,145 0,153 0,145 0,133 0,117 0,092 0,123
(N) miroir
freq=1 0,059 0,130 0,148 0,149 0,139 0,122 0,093 0,139
freq=5000 0,123 0,201 0,193 0,163 0,141 0,111 0,076 0,179
(N) combinaison m/vsn
freq=1 0,067 0,143 0,166 0,172 0,169 0,151 0,125 0,138
freq=5000 0,146 0,231 0,232 0,214 0,193 0,163 0,127 0,186
(N) stop freq=1 0,073 0,151 0,170 0,171 0,161 0,140 0,110 0,136
+ combinaison m/vsn freq=5000 0,170 0,248 0,235 0,199 0,173 0,140 0,104 0,193
(V) voisins
freq=1 0,030 0,066 0,081 0,098 0,103 0,106 0,102 0,087
freq=5000 0,047 0,103 0,123 0,132 0,130 0,126 0,117 0,097
(V) miroir
freq=1 0,063 0,143 0,168 0,171 0,162 0,142 0,111 0,161
freq=5000 0,115 0,211 0,209 0,176 0,151 0,119 0,083 0,186
(V) combinaison m/vs
freq=1 0,060 0,154 0,188 0,205 0,205 0,193 0,163 0,079
freq=5000 0,124 0,250 0,273 0,262 0,245 0,211 0,163 0,127
TAB. 1 Ð F-score moyen par mot, en gardant n candidats pour les verbes, et les noms cibles de
fre«quence>1000, et en faisant varier la fre«quence minimale des candidats. LÕoracle correspond a` n=nombre
de synonymes de la re«fe«rence, pour chaque mot.
et les scores grise«s sont les maximums dÕune colonne pour chaque cate«gorie (N/V).
On observe que les scores sont assez bas. La meilleure me«thode qui combine lÕapproche distributionnelle
et lÕapproche miroir en e«liminant les candidats a` la synonymie dont la fre«quence (dans Wikipe«dia) est
infe«rieure a` 5000 obtient un f-score de 0,273. Ces scores doivent donc plutoöt eötre conside«re«s comme une
indication de la pertinence des ressources pour une taöche ulte«rieure de classification de paires synonymes.
Notre objectif a` terme est de replonger les termes dans leurs contextes dÕemploi pour affiner cette premie`re
approche.
Finalement, nous observons que les scores augmentent syste«matiquement avec la fre«quence minimale des
termes candidats, de facüon logarithmique, dans une plage de 10% environ. Ce phe«nome`ne est a` peu pre`s
similaire entre les deux me«thodes (voisins/miroir). Nous omettons le cas verbe+liste de stops, peu diffe«rent
des autres.
5 Discussion
Nos diffe«rentes expe«rimentations montrent quÕaucune des deux approches de«crites ne permet dÕidentifier
seule des relations synonymiques avec fiabilite«. Bien que de nombreux facteurs puissent eötre responsables
de ce constat, nous observons cependant la supe«riorite« de lÕapproche miroir. Les donne«es dÕalignement
bilingue ont e«te« les moins exploite«es pour la recherche de synonymes. On peut citer quelques pre«curseurs
expe«rimentaux, tels que (van der Plas & Tiedemann, 2006), qui comparent deux items avec une mesure de
similarite« entre leurs Òvecteurs dÕalignementÓ (la fre«quence dÕalignement dÕun mot avec les autres mots
du lexique) dans diffe«rentes langues, et (Wu & Zhou, 2003) qui ont tente« de combiner line«airement des
classifieurs regroupant tous les types de ressources mentionne«s : similarite« dÕalignement, de distribution
syntaxique, et de proximite« dans un graphe de dictionnaire. Les premiers rapportent des f-scores maxi-
maux de 12%. Les seconds combinent plusieurs classifieurs inte«grant des donne«es distributionnelles et des
dictionnaires ; les tests portent sur des classes de termes de fre«quence variable, la meilleure combinaison
donnant 23% sur les noms et 30% sur les verbes. Les donne«es dÕalignement seules donnent respectivement
22 et 26%.
Les performances de notre approche miroir sont donc comparables, meöme si lÕapproche que nous de«crivons
est bien plus simple puisque les travaux sus-mentionne«s doivent calculer entie`rement la matrice N ? N
de similarite« des alignements, ou` N est la taille du lexique, et ou` chaque terme est code« par un vecteur de
tous les termes que lÕon peut aligner avec lui.
A` terme, notre objectif est dÕe«valuer la faisabilite« de lÕapprentissage dÕune relation lexicale a` partir de ces
donne«es, avec comme horizon la collecte dÕun corpus comple«mentaire ou` les termes seraient e«valuables
en contexte. La comple«mentarite« de ces ressources est aussi une question ouverte. Le principal obstacle
the«orique a` ce genre dÕapproche est lie« a` la polyse«mie des termes, quÕelles ne peuvent gue`re distinguer, et
a` la variabilite« en fre«quence des emplois diffe«rents. CÕest pourquoi nous avons aussi analyse« le roöle de la
fre«quence dans les re«sultats. DÕune part on peut supposer que les mots peu fre«quents ne fourniront pas des
donne«es fiables, et dÕautre part quÕil sera plus difficile de discriminer les diffe«rentes fonctions des mots
tre`s fre«quents.
Re«fe«rences
BOURDAILLET J., HUET S., LANGLAIS P. & LAPALME G. (2010). TransSearch : from a bilingual
concordancer to a translation finder. Mach. Transl., p. 35 pages. To appear.
BOURIGAULT D. (2002). UPERY : un outil dÕanalyse distributionnelle e«tendue pour la construction
dÕontologies a` partir de corpus. In Actes de la 9ieme confe«rence sur le Traitement Automatique de la
Langue Naturelle, p. 75Ð84, Nancy.
DYVIK H. (2002). Translations as semantic mirrors : From parallel corpus to
wordnet. In The Theory and Use of English Language Corpora, ICAME 2002.
http ://www.hf.uib.no/i/LiLi/SLF/Dyvik/ICAMEpaper.pdf.
FALK I., GARDENT C., JACQUEY E. & VENANT F. (2009). Sens, synonymes et de«finitions. In
Confe«rence sur le Traitement Automatique du Langage Naturel - TALNÕ2009, Senlis France.
LIN D. (1998). Automatic retrieval and clustering of similar words. In Proceedings of COLING-ACL
Õ98, volume 2, p. 768Ð774, Montreal.
NIWA Y. & NITTA Y. (1994). Co-occurrence vectors from corpora vs. distance vectors from dictionaries.
In Proceedings of Coling 1994.
PLOUX S. & VICTORRI B. (1998). Construction dÕespaces se«mantiques a` lÕaide de dictionnaires de
synonymes. Traitement automatique des langues, 39(1), 161Ð182.
VAN DER PLAS L. & TIEDEMANN J. (2006). Finding synonyms using automatic word alignment and
measures of distributional similarity. In Proceedings of the COLING/ACL 2006 Main Conference Poster
Sessions, p. 866Ð873, Sydney, Australia : Association for Computational Linguistics.
WU H. & ZHOU M. (2003). Optimizing synonyms extraction with mono and bilingual resources. In
Proceedings of the Second International Workshop on Paraphrasing, Sapporo, Japan : Association for
Computational Linguistics.
