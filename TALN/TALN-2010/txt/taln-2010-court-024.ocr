TALN 2010, Montréal, 19-23 juillet 2010

Processus de décision a base de SVM
pour la composition d’arbres de frames sémantiques

Marie-Jean Meurs Fabrice Lefevre
Université d’ Avignon et des Pays de Vaucluse
Laboratoire Informatique d’Avignon (EA 931), F-84911 Avignon, France.
{marie—jean.meurs,fabrice.lefevre}@univ—avignon.fr

Résumé. Cet article présente un processus de décision basé sur des classiﬁeurs a vaste marge (SVMDP)
pour extraire l’information sémantique dans un systeme de dialogue oral. Dans notre composant de com-
préhension, l’information est représentée par des arbres de frames sémantiques déﬁnies selon le paradigme
FrameNet. Le processus d’interprétation est réalisé en deux étapes. D’abord, des réseaux bayésiens dy-
namiques (DBN) sont utilisés comme modeles de génération pour inférer des fragments d’arbres de la
requéte utilisateur. Ensuite, notre SVMDP dépendant du contexte compose ces fragments aﬁn d’obtenir
la représentation sémantique globale du message. Les expériences sont menées sur le corpus de dialogue
MEDIA. Une procédure semi-automatique fournit une annotation de référence en frames sur laquelle les
parametres des DBN et SVMDP sont appris. Les résultats montrent que la méthode permet d’améliorer
les performances d’identiﬁcation de frames pour les exemples de test les plus complexes par rapport a un
processus de décision déterministe ad hoc.

Abstract. This paper presents a decision process based on Support Vector Machines to extract the
semantic information from the user’s input in a spoken dialog system. In our interpretation component,
the information is represented by means of trees of semantic frames, as deﬁned in the Berkeley FrameNet
paradigm, and the understanding process is performed in two steps. First Dynamic Bayesian Networks are
used as generative models to sequentially infer tree fragments from the users’ inputs. Then the context-
sensitive SVMDP introduced in this paper is applied to detect the relations between the frames hypothesi-
zed in the fragments and compose them to obtain the overall semantic representation of the user’s request.
Experiments are reported on the French MEDIA dialogue corpus. A semi-automatic process provides a
reference frame annotation of the speech training data. The parameters of DBNs and SVMDP are learned
from these data. The method is shown to outperform an ad-hoc deterministic decision process on the most
complex test examples for frame identiﬁcation.

M0tS-CléS I systeme de dialogue oral, compréhension de la parole, composition sémantique, frame
sémantique, séparateur a vaste marge.

Keywords: spoken dialogue system, spoken language understanding, semantic composition, se-
mantic frame, support vector machines.

MARIE—JEAN MEURS, FABRICE LEFEVRE

1 Introduction

L’obtention de la representation semantique des propositions orales a ete l’objet de nombreux travaux
au cours des vingt dernieres annees. L’introduction de composants stochastiques dans les systemes de
dialogue oral ameliore leurs performances globales en les rendant plus robustes aux variabilites de la
parole (Lefevre, 2007; He & Young, 2006). A partir des transcriptions foumies par le module de recon-
naissance automatique de la parole, le module de comprehension construit une representation semantique
de haut niveau des propos du locuteur qu’il transmet au gestionnaire de dialogue. Dans un travail pre-
cedent (Meurs et al., 2009), nous avons propose un modele entierement stochastique base sur des reseaux
bayesiens dynamiques (DBN) extrayant les concepts de base de la requete d’un utilisateur puis gene-
rant les sous-arbres de frames semantiques a partir de tous les niveaux d’annotation disponibles (mots
et concepts). La generation des fragments semantiques par les DBN etant sequentielle, elle ne tient pas
compte des dependances longue-distances. Cet article decrit l’algorithme de recomposition que nous ap-
pliquons aux fragments pour obtenir la representation semantique globale de la requete de l’utilisateur.
Un apprentissage strictement statistique des fragments en contexte (voir (Zettlemoyer & Collins, 2009)
pour une approche utilisant des graInmaires) permet a l’algorithme propose de s’appuyer sur un processus
de decision par classiﬁcation binaire. L’article est organise comme suit. La section 2 presente la gene-
ration des frames semantiques sur le corpus MEDIA. La section 3 introduit ensuite notre algorithme de
composition des fragments semantiques. Enﬁn, la section 4 detaille experiences et resultats.

2 Generation de frames semantiques sur le corpus MEDIA

Issu de la simulation d’un serveur telephonique d’informations touristiques et de reservation d’h6tels, le
corpus MEDIA (Bonneau-Maynard et al., 2005) est compose de 1.257 dialogues en frangais collectes en
utilisant le protocole du Magicien d’0z (un operateur humain simule les reponses du serveur). Trans-
cription et annotation semantique manuelles ont ete realisees par deux experts. A partir du dictionnaire
semantique MEDIA (83 concepts) des segments de mots sont associes a une paire concept-valeur. Le
choix dans nos travaux d’annoter le corpus MEDIA en frames semantiques (Lowe et al., 1997) est mo-
tive par l’aptitude des frames a representer les dialogues de negociation. Une frame decrit une situation
concrete ou abstraite impliquant ses roles, les frame-elements (FE). Nous avons deﬁni, selon le paradigme
du projet FrameNet (Fillmore et al., 2003), des frames couvrant le domaine du corpus MEDIA et adaptees
a la nature particuliere du support textuel. L’ontologie MEDIA est composee de 21 frames et de 86 FE
deﬁnis par des modeles composes d’unites lexicales et de concepts de base. Les donnees d’entrainement
sont automatiquement annotees par un systeme a base de regles (voir (Meurs et al., 2008)). Une annota-
tion de reference en frames et FE est ainsi obtenue permettant l’apprentissage des parametres des modeles
stochastiques utilises pour generer les fragments semantiques de frames-FE associes a la proposition du
locuteur.

Ces modeles a base de DBN (Bilmes & Zweig, 2002) sont exposes et evalues dans (Meurs et al., 2009).
L’apprentissage de leurs parametres necessite la determination des fragments semantiques associes aux
concepts (et aux mots) de la requete du locuteur. La representation en frames etant hierarchique, des
situations de recouvrement peuvent se produire lors de la determination des frames et FE associes a
un concept. Pour resoudre ce probleme, un algorithme de projection d’arbre est applique sur l’anno-
tation en frames et FE de la phrase complete. 11 permet de deﬁnir les fragments semantiques (sous-
branches) associes a un concept. Partant d’une feuille de l’arbre, un fragment de frames-FE est obtenue
en agregeant les valeurs de noeuds peres aussi longtemps qu’ils sont associes au meme concept (ou a au-
cun). Par exemple, la sequence de mots réserver un hotel 61 Paris, illustree ﬁgure 1, entraine la creation
des branches projetees de frames et FE HOTEL—lodging_hotel—LODGING—reserve_theme—RESERVE et

PROCESSUS DE DECISION POUR LA COMPOSITION DE FRAMES SEMANTIQUES

location_town—LOCATION—lodging_location—LODGING. La séquentialité du décodage des fragments
entraine la perte d’une partie des liens entre frames et FE.

3 Composition d’arbres

L’ algorithme de projection réalise deux types d’opérations. Les se’parations rompent des liens entre frames
et FE selon les concepts qui leurs sont associés. Les duplications des objets sémantiques (frames ou FE)
sont nécessaires lorsque ces objets sont présents dans plusieurs sous-branches distinctes. L’algorithme
de recomposition est développé pour rassembler les fragments produits par les DBN et rétablir l’arbre
sémantique associé a la globalité du message. Il décide des operations réciproques de celles effectuées
lors de la projection, soit des opérations de liaison entre frames et FE et des operations d’ identiﬁcation
entre frames ou FE.

Les liaisons potentielles inter-fragments s’appuient sur l’ontologie développée pour le domaine du corpus
MEDIA : deux objets sémantiques ne peuvent étre reliés que s’ils le sont dans l’ontologie. Les liaisons
consistent donc en l’ajout d’arétes entre des noeuds de fragments sémantiques distincts pour les rassem-
bler sous un arbre sémantique unique. Les identiﬁcations potentielles concernent les objets sémantiques
semblables présents au sein de plusieurs fragments associés a un meme message. L’ algorithme de recom-
position considere ces objets et décide de la pertinence de leurs présences multiples. Les identiﬁcations
suppriment ainsi les objets sémantiques redondants produits par les DBN. Lorsque deux noeuds de sous-
branches sont identiﬁe’s, un seul est conservé dans l’arbre sémantique global et les noeuds ﬁls du noeud
supprimé sont reliés au noeud conservé.

L’exemple de la ﬁgure 1 illustre ces proces-
sus. L’arbre sémantique associé au message
nu" re’server un hotel a Paris est reproduit sur la
gauche de la ﬁgure. Les branches de l’arbre
décomposé sont reproduites a droite. Lors de
‘*2 la decomposition pour l’apprentissage des pa-
cg rametres des modeles DBN, la frame LODGING
est dupliquée et le FE reserve_theme est sé-
paré d’une des deux instances de cette frame.
message: "ﬁ 91 L’ algorithme de recomposition doit étre a
concepts : (:1 (:2 A , -
meme de recomposerl arbre complet en d1spo-
sant du message, des concepts associés et des
branches générées par le DBN a partir de ces
connaissances.

    

FIG. 1 — Projection et recomposition de l’arbre séman-
tique associé a la requéte re’server un hotel a Paris

La pertinence de l’arbre sémantique recomposé est donc directement dépendante de la pertinence des de-
cisions de liaisons et d’identiﬁcations. Deux stratégies de décision sont évaluées dans ce travail, présentées
ci-apres.

3.1 Méthode de connexion forte
La premiere stratégie évaluée est une heuristique visant a obtenir pour chaque message une representation

sémantique compacte dans le cadre autorisé par l’ontologie. Dans cette méthode de connexion forte (CF),
toute liaison ou identiﬁcation, possible selon l’ontologie, est réalisée. Cette approche est a priori efﬁcace
pour les messages simples contenant des phrases courtes et peu ambigiies. En revanche, elle ne prend pas
en compte les mots et les concepts associés au message. Elle n’est donc pas tres adaptée aux messages
complexes dont la representation sémantique peut contenir de nombreuses sous-structures non connectées.

MARIE—JEAN MEURS, FABRICE LEFEVRE

3.2 Processus de décision £1 base de séparateurs £1 vaste marge (SVMDP)

La seconde méthode de connexion évaluée est basée sur l’apprentissage de classiﬁeurs SVM. Le choix
du type de classiﬁeurs linéaires employés est dicté par plusieurs considérations : la quantité de données
disponibles, la rapidité de réponse ou encore les performances obtenues sur des données comparables. En
raison de leurs propriétés, les classiﬁeurs SVM s’adaptent parfaitement au contexte applicatif de ce travail.

Apprentissage

Les séparations et les duplications réalisées lors de la projection des arbres sont recensées. A chaque
opération est associé l’ensemble des exemples du corpus d’entrainement contenant les objets sémantiques
qu’elle fait intervenir. Ces messages sont répartis en deux classes selon qu’ils ont ou non déclenche’ l’opé-
ration. On dispose de T, ensemble des exemples d’apprentissage annotés en arbres sémantiques par le
systeme a base de regles évoqué en section 2. Soit A l’ensemble construit a partir de T tel que tout ele-
ment de A est composé des mots, des concepts et de l’arbre sémantique associés a un exemple de T. Soit
A7’ l’ensemble construit a partir de A tel que tout élément de A1’ est composé des mots, des concepts,
des fragments sémantiques obtenus apres projection de l’arbre sémantique et des opérations de projec-
tion réalisées lors de la projection de l’arbre sémantique d’un exemple de A. Soient (D) l’ensemble des
opérations observées dans A7’. Par souci de simpliﬁcation, une opération de projection et sa réciproque
de recomposition (ou regroupement) seront également notées (9,, le contexte d’application levant toute
ambigiiité.

Chaque opération de projection O,- E (0) met en relation deux objets sémantiques f i1 et f 1'2 et on notera
O,- = f,-1Rf,-2. Pour chaque paire {f,-1, f,-2} associée a une opération de (0), on construit l’ensemble Ag’ des
exemples de A1’ contenant f,-1 et f,-2. Les exemples de Ag’ pour lesquels l’opération O, s’est appliquée lors
de la projection sont dits “positifs” pour 0,. Les exemples Ag’ contenant f,-1 et f,-2 pour lesquels O, n’a pas
été appliquée sont “négatifs” pour (9,. On dispose pour chaque operation (9, de la partition {Ag’ +, Ag’ _}
de Ag’ o1‘1 Ag’ J“ et Ag’ _ sont respectivement les sous-ensembles d’exemples positifs et négatifs de Ag’.

Pour appliquer la méthode de classiﬁcation SVM, il est nécessaire de plonger les données dans IR“. Un
exemple 8 est représenté dans IR“ par un point E dont les coordonnées sont les index numériques des
mots et trigrammes de mots de l’exemple, de la séquence de concepts associée a l’exemple et des frames
et FE présents dans les fragments sémantiques associés a cet exemple. L’introduction des n-grammes de
mots dans le point caractérisant un exemple permet de prendre en compte une information séquentielle.
Les parametres d’un classiﬁeur linéaire binaire a base de SVM sont appris sur les points représentant les
exemples de chaque ensemble Ag’. A l’issue de cette procedure, on dispose d’un classiﬁeur 8, par opera-
tion (9, et on a |(O>| = |S| = I, avec S l’ensemble des classiﬁeurs entrainés.

Application aux exemples de l’ensemble de test

Pour chaque exemple 8 de l’ensemble de test, annoté en fragments sémantiques, on construit l’ensemble
des opérations pouvant le concerner en fonction des paires d’objets sémantiques contenues dans ses frag-
ments. Soit (0)5 cet ensemble, on a :

(0)5 = {(9,-E1 = f,-173122 tel que f 1'1 et f.-2 appartiennent aux fragments sémantiques associés a 8} et
(0)5 C (0). Pour toute opération O,- 6 (05, 1e point E représentant l’exemple 8 est soumis au classiﬁeur
S,-. La réponse de Si quant a la classe de E détermine la pertinence de la réalisation de Oi sur les objets
sémantiques de l’eXemple. A l’issue de ce processus, la phase de composition sémantique est achevée par
la réalisation sur les objets sémantiques de 8 de toutes les opérations jugées pertinentes par les S,-E1. Ces
deux méthodes sont évaluées sur les fragments sémantiques produits par le DBN.

PROCESSUS DE DECISION POUR LA COMPOSITION DE FRAMES SEMANTIQUES

4 Expériences et résultats

Les expériences sont menées sur l’ensemble de test MEDIA (3005 tours de parole) dans trois conditions
différentes, fonctions de la nature des données utilisées. Les données de type MAN rassemblent les tours de
parole du locuteur, manuellement transcrits et annotés en concepts. Pour celles de type SLU, les concepts
de base sont décodés a partir des transcriptions manuelles des tours de parole locuteur en utilisant le
modele a base de DBN décrit dans (Lefevre, 2007) (taux d’erreurs concepts : 10,6%). Pour les données
de type ASR+SLU, les concepts sont décodés par le modele de compréhension en utilisant la meilleure
hypothese de séquence de mots générée par un systeme conforme a (Barrault et al., 2008) (taux d’erreurs :
mots 27%, concepts 24,3%).

Quatre niveaux d’évaluation sont considérés. Au niveau Frames, les hypotheses de frames sont correctes
des lors que les frames correspondantes sont présentes dans la référence, idem pour le niveau FE. Au
niveau FE{Fr}, seules les hypotheses de FE appartenant a des hypotheses de frames correctes sont exa-
minées et au niveau Liens{Fr}, seules les hypotheses de liens reliant des hypotheses de frames et FE
correctes sont examinées.

Toutes les expérimentations ont été réalisées en utilisant la librairie libSVM (EL-Manzalawy & Honavar,
2005) pour WEKA (Bouckaert et al., 2008). Le tableau 1 regroupe les résultats issus de l’application des
méthodes CF et SVMDP sur les fragments sémantiques issus des 3005 tours de parole detest (5,5 frames
ou FE par tour en moyenne) ; des 515 tours contenant plus de 6 segments conceptuels (17,5 frames ou FE
par tour en moyenne) et des 223 tours contenant plus de 10 segments conceptuels (24,2 frames ou FE par
tour en moyenne). Les résultats sont donnés en termes de F-mesure pour les trois types de données (MAN,
SLU, ASR+SLU).

Trs de parole test complet + de 6 concepts + de 10 concepts

Données F-m F-m F-m
MAN CF SVMDP CF SVMDP CF SVMDP
Frames 0,90 0,91 0,85 0,87 0,84 0,87
FEs 0,87 0,88 0,73 0,74 0,72 0,74
FE{F} 0,95 0,94 0,85 0,83 0,84 0,81
Liens{F} 0,88 0,87 0,67 0,64 0,66 0,61
SLU CF SVMDP CF SVMDP CF SVMDP
Frames 0,89 0,90 0,83 0,85 0,82 0,85
FEs 0,82 0,83 0,65 0,67 0,66 0,68
FE{F} 0,91 0,91 0,79 0,78 0,79 0,77

Liens{F} 0,84 0,84 0,61 0,60 0,60 0,58
ASR+SLU CF SVMDP CF SVMDP CF SVMDP

Frames 0,80 0,81 0,77 0,79 0,78 0,80
FEs 0,77 0,77 0,61 0,62 0,62 0,63
FE{F} 0,91 0,90 0,78 0,76 0,77 0,75

Liens{F} 0,84 0,83 0,61 0,59 0,59 0,57

TAB. 1 — F-mesures sur le test MEDIA, les tours a + de 6 concepts et les tours a + de 10 concepts apres
application des méthodes CF et SVMDP sur les fragments sémantiques générés par le modele DBN.

La méthode SVMDP utilise 74 classiﬁeurs appris sur le corpus d’entrainement : 18 classiﬁeurs sont dédiés
a l’identiﬁcation de frames (10) ou de FE (8) et 56 classiﬁeurs sont dédiés a la liaison entre frames et FE.

MARIE—JEAN MEURS, FABRICE LEFEVRE

Les résultats conﬁrment l’aptitude de ces algorithmes a composer les fragments d’arbre sémantiques de
grande taille pour former une représentation complete consistante du message de l’utilisateur. La structure
de la base de connaissance et le contexte relativement fermé des messages de test peuvent expliquer les
performances comparables des deux méthodes. En effet, les opérations d’identiﬁcation et de liaison des
objets sémantiques contenus dans les fragments étant presque toujours justiﬁées, la méthode de connexion
forte commet ﬁnalement peu d’erreurs mais on notera que l’emploi de la méthode SVMDP permet une
sélection plus ﬁne des frames et FE.

5 Conclusion

Cet article présente et évalue un processus de decision a base de SVM pour la composition de fragments
sémantiques (sous-arbres de frames). Les fragments sont séquentiellement décodés par un modele entiere-
ment stochastique a base de réseaux bayésiens dynamiques. La composition de ces fragments est réalisée
par un processus de décision SVM dépendant du contexte. Les expériences menées sur le corpus MEDIA
attestent la validité de notre approche. Les performances du systeme proposé conﬁrment son aptitude a
produire automatiquement une représentation sémantique consistante de la requéte d’un utilisateur.

Références

BARRAULT L., SERVAN C., MATROUF D., LINARES G. & DE MORI R. (2008). Frame-based acoustic
feature integration for speech understanding. In IEEE I CASSP, Las Vegas.

BILMES J. & ZWEIG G. (2002). The graphical models toolkit : An open source software system for
speech and time-series processing. In IEEE ICASSP, Orlando, Florida.

BONNEAU-MAYNARD H., ROSSET S., AYACHE C., KUHN A. & MOSTEFA D. (2005). Semantic
annotation of the french media dialog corpus. In Eurospeech, Lisboa, Portugal.

BOUCKAERT R. R., FRANK E., HALL M., KIRKBY R., REUTEMANN P., SEEWALD A. & SCUSE D.
(2008). WEKA Manual for Version 3-6-0. User manual, The University of Waikato, New Zealand.
EL-MANZALAWY Y. & HONAVAR V. (2005). WLSVM .' Integrating LibSVM into Weka Environment.
Software available at http : //www . cs . iastate . edu/~yasser/wlsvm.

FILLMORE C. J ., JOHNSON C. R. & PETRUCK M. R. (2003). Background to framenet. International
Journal of Lexicography, 16.3, 235-250.

HE Y. & YOUNG S. (2006). Spoken language understanding using the hidden vector state model. Speech
Communication, 48 (3-4)(3-4), 262-275.

LEFEVRE F. (2007). Dynamic bayesian networks and discriminative classiﬁers for multi-stage semantic
interpretation. In IEEE I CASSP, Hawaii, USA.

LOWE J ., BAKER C. & FILLMORE C. (1997). A frame-semantic approach to semantic annotation. In
SIGLEX Workshop on Tagging Text with Lexical Semantics .' Why, What, and How ?, Washington D.C.,
USA.

MEURS M.-J., DUVERT F., BECHET F., LEFEVRE F. & DE MORI R. (2008). Semantic frame annota-
tion on the french media corpus. In LREC, Marrakech, Maroc.

MEURS M.-J., LEFEVRE F. & DE MORI R. (2009). Learning bayesian networks for semantic frame
composition in a spoken dialog system. In NAACL-HLT, Boulder, CO, USA.

ZETTLEMOYER L. S. & COLLINS M. (2009). Learning context-dependent mappings from sentences to
logical form. In ACL-IJCNLP.

