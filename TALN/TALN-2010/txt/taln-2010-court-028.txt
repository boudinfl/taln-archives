TALN 2010, Montréal, 19-23 juillet 2010

Fouille de données séquentielles d’itemsets pour
l’apprentissage de patrons linguistiques

Peggy Cellier Thierry Charnois
GREYC — CNRS UMR 6072
Université de Caen — Bd Mal Juin 14032 Caen, France
prénom.nom@info.unicaen.fr

Résumé. Dans cet article nous présentons une méthode utilisant l’extraction de motifs séquentiels
d’itemsets pour l’apprentissage automatique de patrons linguistiques. De plus, nous proposons de nous
appuyer sur l’ordre partiel existant entre les motifs pour les énumérer de facon structurée et ainsi faciliter
leur validation en tant que patrons linguistiques.

Abstract. In this paper, we present a method based on the extraction of itemset sequential patterns
in order to automatically generate linguistic patterns. In addition, we propose to use the partial ordering
between sequential patterns to enumerate and validate them.

M0tS-CléS I Fouille de données, motifs séquentiels, extraction d’information, apprentissage de pa-
trons linguistiques.

Keywords: Data mining, sequential patterns, information extraction, linguistic pattern learning.

1 Introduction

Face 51 l’abondance et a la prolifération des données textuelles, l’acces a l’information pertinente dans
les corpus est devenu un enjeu majeur avec des besoins dans différents domaines. On peut citer l’analyse
du discours évaluatif qui connait un intérét croissant pour des applications telles que la veille d’opinions,
l’analyse de tendances ou de marchés (Pang & Lee, 2007). Les approches symboliques du traitement
automatique des langues dédiées a l’extraction d’information reposent sur des ressources élaborées ma-
nuellement dont le coﬁt est important en temps de développement, voire prohibitif lorsqu’il s’agit de les
adapter a un nouveau domaine (Poibeau, 2003). C’est pourquoi les méthodes permettant d’apprendre auto-
matiquement les ressources connaissent un essor important. Certaines approches s’appuient sur des corpus
annotés (Califf & Mooney, 2003) souvent difﬁciles a obtenir. D’autres méthodes utilisent des corpus bruts
(Riloff, 1996) mais elles reposent sur une analyse syntaxique qui impacte la qualité des résultats. On
peut aussi citer les approches dans la lignée de (Hearst, 1992) qui visent a acquérir des relations séman-
tiques d’un type particulier (hyperonymie) pour enrichir automatiquement des lexiques ou des ontologies.
Dans (Charnois et al., 2009) une approche a été proposée pour apprendre automatiquement des patrons
linguistiques pour la découverte de relations entre entités nommées. Cette approche s’appuie sur l’utilisa-
tion de motifs séquentiels d’items, qui permettent de générer automatiquement des patrons linguistiques,
et sur la fouille de données récursive des motifs qui permet de gérer la quantité de patrons extraits. Cette

PEGGY CELLIER, THIERRY CHARNOIS

Identiﬁant Séquence
1 ((h0mme homme NOM) (de de PRP) (culture culture NOM))
2 ((en en PRP) (uieuac uieuac ADJ) ( f arceur farceur N OM ) (misanthrope misanthrope ADJ
3 ((réputé réputer VER pper) (pour pour PRP)(sa son DET POS) (cruauté cruauté NOM

TAB. 1 — Extrait d’une base de séquences pour les textes : “homme de culture, en vieux farceur misan-
thrope, réputé pour sa cruauté”.

approche a l’avantage de ne pas nécessiter d’analyse syntaxique ni de ressource extérieure autre qu’un
corpus d’apprentissage brut, et n’est pas dédiée a l’apprentissage d’un type de patrons spéciﬁques.

Dans cet article, nous proposons une méthode basée sur les motifs séquentiels d’itemsets. Cela signiﬁe
qu’au lieu de décrire un mot par un seul item (son lemme ou sa catégorie grammaticale ou la conjonction
des deux) comme dans (Chamois et al., 2009), un mot est décrit par un ensemble d’items. L’avantage de
cette description plus riche est de pouvoir générer automatiquement des patrons linguistiques sophistiqués
contenant a la fois des lemmes et des categories grammaticales, comme le patron « homme de NOM ». De
plus, pour gérer le probleme du grand nombre de motifs extraits a valider par un expert, nous proposons de
nous appuyer sur l’ordre partiel existant entre ces motifs. Cela permet une énumération structurée des mo-
tifs et facilite leur exploration. Nous appliquons notre approche a l’apprentissage de patrons linguistiques
pour la découverte de constituants en position détachée, extra-prédicatifs, et porteurs de qualiﬁcation, voire
de jugement, comme illustrée dans la table 1. Toutefois, le processus peut étre facilement adapté pour dé-
couvrir d’autres types de patrons linguistiques Dans la section 2, la méthode proposée est détaillée. La
section 3 présente l’application de la méthode pour la découverte d’expressions qualiﬁcatives.

2 Apprentissage des patrons linguistiques

L’extraction automatique des patrons linguistiques et leur validation s’effectuent en deux étapes : 1) les
motifs séquentiels fréquents sont extraits de la base d’exemples; 2) ces motifs extraits sont ensuite struc-
turés dans un diagramme de Hasse aﬁn de faciliter leur sélection en tant que patrons linguistiques.

2.1 Extraction de motifs séquentiels d’itemsets pour la découverte de patrons

L’extraction de motifs séquentiels d’itemsets a été introduite dans (Agrawal & Srikant, 1995; Srikant &
Agrawal, 1996). L’extraction de motifs séquentiels se fait a partir d’une base de séquences, BDD, o1‘1
chaque séquence est décrite par une liste ordonnée d’ensembles de littéraux appelés items. Un ensemble
d’items est communément appelé itemset, noté  o1‘1 les ij sont des items. Une séquence est donc
une liste ordonnée d’itemsets, notée (s1...s,,) o1‘1 les sj sont des itemsets. Dans le cas de la découverte de
patrons linguistiques, nous constituons une base de séquences (la base d’exemples) a partir de morceaux
de texte. Chaque morceau de texte représente donc une séquence de la base et est décrit par l’ensemble
des mots qui le composent. Les motslsont représentés par des itemsets qui décrivent le mot par sa forme
ﬂéchie, son lemme et sa catégorie grammaticale 2. Un extrait de base contenant 3 constituants en position

1En fonction de 1’ application il est tout a fait possible de choisir un grain different, par exemple : syllabe, phrase, paragraphe.
2Notons que d’autres infonnations pourraient etre ajoutées comme des traits sémantiques.

FOUILLE DE SEQUENCES D’ITEMSETS POUR L’APPRENTISSAGE DE PATRONS LINGUISTIQUES

  
 

 
    

File Lngi: Browsing Updating Actions Help
' ' Erérédent Qguivant: ﬂ Agmaliser lﬁignregistrel
Rﬂagage des motifs
_ _ déié validés
. NOT 9 = >= <= Zoum Pivot
3"‘ 193 v ‘{ NOM H PRP } sup:805‘
15 v '{ chamion NOM }{ FRF } 5u:106'
1 D '( thampmn NDM H Ele PRP }( la is DETART H NOM } sup:1D‘
2 V '{ champion NOM H du FRF det) sup=96'

4 D *{ thampmn MOM }{ des du PRF net ;— sup:12’
E 1 D 1 charnpmn NDM H du FRF det }( AD} } su =2‘
'43 7 | D -{ cnamgion mm }{ du PRPdet H mm } suE=94' | < NOM PRP > SU=805
E3 5 D ‘{(har'i1psurme (hampum NOM H du PRP dei 1 Sup=33'
> . i : ;
ru 6 D l"‘a"“‘°‘°""“'“'""'“” “O” H P” } 5”” 34 I<(champion NOM) (PRP)> sup=lO6I i<(NoM) (du PRP det) > 5up=187I
C 20 D '{ femme NOM }{ PRP } 5up:127'
% 89 D ‘{ homme NOM H PRP } sup=537‘
9 110 D ‘{ NOM H de PR9} sun=617' I<(champion NOM) (du PRP det (NOM)> 5uD=94I
_Q 52 V ’ NOM du PRF det Su:187‘
L V I
< I V ‘{ (hampmn NOM }( du PRP det} sLIp=96'

4 D t{ mampmn MUM H deg du pm; net } SW32’ < cham ion NOM do PRP det Danemar|< NONI > su :2

1 p 1 Champm, Nam }( du pap det}(,qD}}5up=1‘ <(champiDns sham ion NOM) (du PRP det) (monde NOM)) sup=26I

7 |1> '{ Champion NOM }{ du PRP det }{ NOM } §up=94' |

5 D ‘{chan1prunne charnpiun NOM H du PRP def ) 5up:33‘

FIG. 1 —Navigation dans les patrons lin- FIG. 2 — Extrait du diagramme de Hasse contenant des motifs
guistiques pour les valider. sequentiels.

detachee de qualiﬁcation est donne a la table 1. Une sequence, S1 = (a1...a,,) est contenue dans une se-
quence S2 = (b1...bm) s’il existe des entiers i1 <  < in tels que a1 Q b,-1, ..., an Q bin. S1 est alors
appelee sous-séquence de S2, note S1 3 S2. Le support d’une sequence3, S, dans une base, BDD, est
le nombre de sequences de BDD qui contiennent S. Par exemple, pour le motif ((PRP)(ADJ son
support dans BDD est de 1 (Sequence 2). Les motifs sequentiels ne sont pas necessairement des suites
contigues. Par exemple, le motif ((PRP)(ADJ couvre aussi l’expression « en homme courageux ».
Un motif sequentiel fréquent dans BDD est une sequence dont le support est superieur a un seuil ﬁxe :
minsup. Notons que l’utilisation des itemsets permet une description plus riche des mots que l’utilisa-
tion de simples items. Cet ajout d’information sur les mots donne la possibilite de decouvrir des patrons
linguistiques plus sophistiques, composes d’information Inixte come a la fois les lemmes mais aussi
les categories grammaticales. Par exemple, on trouve des patrons linguistiques de la forme : ((en PRP)
(homme N OM )(de PRP)(NOM Pour diriger l’extraction des motifs sequentiels vers l’objectif de
l’utilisateur, on deﬁnit des contraintes sur les motifs a extraitre. Par exemple, la contrainte gap (Dong &
Pei, 2007) impose que pour que S1 soit contenue dans S2 il faut que chaque couple d’itemsets adjacents
de S1 ne soit pas separe dans S2 par plus d’un certain nombre d’itemsets. Ce nombre est appele maxgap.
Les contraintes linguistiques permettent de deﬁnir le type de patrons linguistiques recherches.

2.2 Maitrise du nombre de motifs

Beaucoup de motifs sequentiels sont generes. Pour pallier a ce probleme nous utilisons une representation
condensee des motifs quieliIr1ine les redondances entre motifs : les motifs fermés (Yan et al., 2003), et un
ordre partiel qui permet d’avoir une enumeration des motifs structuree et de faciliter leur exploration.

Un motif frequent, S, est un motif ferme’ frequent, s’il n’existe pas de motif frequent S’ tel que S < S’ et
sup(S) = sup(S’). Par exemple, soient S = ((h0mme NOM) (de) (NOM)) et S’ = ((h0mme NOM)

_ nombre de sequences de la base qui contiennent S
nombre de sequences de la base

3Parfois le support normalise est utilise : sup(S)

PEGGY CELLIER, THIERRY CHARNOIS

(de) (culture NOM deux séquences telles que sup(S) = sup(S’) = 10, alors S n’est pas un motif
fermé. En effet les 10 exemples couverts par le motif S sont aussi couverts par le motif 3’ .

Les motifs fermés fréquents extraits sont partiellement ordonnés entre eux. Aﬁn de mieux visualiser cette
relation d’ordre on peut afﬁcher les motifs dans un diagramme de Hasse qui est une représentation gra-
phique d’un ordre partiel (Davey & Priestley, 1990). Un exemple de diagramme de Hasse est présenté a la
ﬁgure 2. La taille du diagramme de Hasse peut étre trop grande pour que le diagramme soit afﬁché entie-
rement. Nous proposons donc d’utiliser un outil de navigation permettant de naviguer dans le diagramme
des motifs les plus généraux aux plus spéciﬁques aﬁn de les valider en tant que patrons linguistiques.
A la ﬁgure 1 nous donnons un exemple de navigation avec l’outil Came1is4 (Ferré, 2009). La navigation
se fait via « l’arbre de navigation » se trouvant a gauche de l’outil. Notons que lorsqu’un motif, M, est
sélectionné par l’expert comme patron linguistique, tous les motifs dont M est une sous-séquence ne sont
plus a examiner. En effet, lors de l’app1ication des patrons, les morceaux de texte qu’ils reconnaissent
sont inclus dans les morceaux de texte reconnus par M. Camelis offre la possibilité de marquer les motifs
validés comme patrons linguistiques et donc de ne plus les afﬁcher ainsi que les motifs qui les contiennent
(cf « not ’Motif Valide’ » dans ﬁgure 1), réduisant l’espace des motifs a vériﬁer et facilitant l’exploration.

3 Cas d’étude : la reconnaissance d’expressions qualiﬁcatives

Nous avons appliqué notre méthode a l’apprentissage de patrons linguistiques dénotant des expressions
porteuses de qualiﬁcation et en position détachée comme décrites dans (Jackiewicz et al., 2009a). Les
expressions en gras dans les exemples (1) et (2) illustrent le type d’expressions qui nous intéressent :

(1) Ni trop sentimental, ni trop énergique, il maitrise, avec une ﬁnesse quasi mozartienne, un []

(2) Figure légendaire de l’opposition au régime communiste, éminent professeur d’histoire médié-
vale, ministre des affaires étrangéres de la Pologne de 1997 51 2000, Bronislaw Geremek avait [ ]

Nous souhaitons apprendre des patrons linquistiques comme ceux déﬁnis manuellement par (J ackiewicz
et al., 2009a), par exemple :

— Groupes noIr1inaux (GN) : [det] N de GN (Femme de téte,X ; X, le maestro de la désinﬂation).

— Adverbes (courageusement, X); groupes prépositionnels (en mauvaise posture, X).

— Constructions détachées : groupes adjectivaux (imprévisible et fantasque, X); constructions absolues

(l’0eil vigilant, X) ; participes (réputé pour son caractére bourru, X).

3.1 Corpus d’apprentissage

Deux corpus d’apprentissage ont été générés automatiquement pour pal1ierl’absence de corpus disponible.
Le corpus AXIOLO est issu des expériences de (Jackiewicz et al., 2009a). 11 est constitué d’expressions
reconnues par application d’une dizaine de patrons élaborés manuellement sur des articles issus du journal
Le Monde, catégorie « Portraits », de la période juillet a décembre 2002 (soit 884 articles), ainsi que sur
la période 2003 a 2006 de l’ensemble des articles du Monde pour deux autres patrons spéciﬁques : en Adj
<expansi0n>5 et en N <expansi0n>6 (Jackiewicz et al., 2009b). Ce corpus d’expressions qualiﬁcatives

4http ://www.irisa.fr/LIS/ferre/Camelis/index.ht1n1
5avec Adj appartenant a une liste d’adjectifs ﬁxés (bon, vrai, authentique, ...) : en vrai professionnel
Gavec N appartenant a une liste de noms Giomme, femme, virtuose, ...) : en homme sensible et généreux

FOUILLE DE SEQUENCES D’ITEMSETS POUR UAPPRENTISSAGE DE PATRONS LINGUISTIQUES

contient 4 063 expressions (i.e. séquences), ce qui représente 12 257 mots. Il est tres peu bruité. Le corpus
ARTS a été généré a partir de regles heuristiques sur les articles de la rubrique "Art" du journal Le Monde,
année 2006, soit 3 539 articles. Ces heuristiques sont destinées a ﬁltrer parmi les constituants périphériques
ceux qui ne sont a priori pas porteurs de qualiﬁcation (exemples : proposition de la phrase contenant
un verbe conjugué, groupe circonstanciel de temps, espace, but, causalité). Ce corpus est constitué de
13 576 expressions (i.e. séquences), ce qui représente 85 153 mots. I1 contient des exemples négatifs.
Nous estimons a environ 32% 1e pourcentage d’expressions non qualiﬁcatives (bruit).

3.2 Apprentissage des patrons de qualiﬁcation

Paramétres de l’apprentissage. Pour 1e calcul des motifs fermés d’itemsets, nous avons utilisé 1’imp1é-
mentation de Clospan (Yan et al., 2003) proposée dans Illimine7. Nous cherchons des patrons linguistiques
décrivant des expressions de qualiﬁcation en position détachée. Pour cela, nous ﬁxons deux contraintes sur
les motifs a extraire : 1) ils débutent l’expression ; 2) ils sont formés d’éléments contigiis (maxgap=0). Pour
chacun des deux corpus nous avons calculé les motifs séquentiels en faisant varier les valeurs du seuil de
support, minsup, de 50% a 0,05%. On constate que des seuils de support élevés (50% ou 25%) ne four-
nissent que des motifs tres généraux ou seuls les catégories grammaticales apparaissent. Il est donc plus
intéressant de choisir des seuils de support tres bas pour obtenir des motifs spéciﬁques et capturer des
expressions, ou phénomenes, linguistiques peu fréquentss.

Résultats quantitatifs. Avec le corpus AXIOLO, pour minsup = 0,05 (2 expressions), 8 264 motifs
fermés fréquents sont extraits en moins d’une seconde. Apres application des deux contraintes il reste
1 789 motifs. Avec le corpus ARTS, pour minsup = 0,05 (6 expressions), environ 8 millions de motifs
fermés fréquents sont extraits en 7h. Apres application des contraintes il reste 7 818 motifs9.

Résultats qualitatifs et discussion. Des expériences ont été conduites en ne considérant qu’un seul item
pour décrire un mot comme dans (Charnois et al., 2009). Sans surprise, on constate que les motifs dé-
couverts sont soit tres spéciﬁques (par exemple : (homme de conviction) pour les séquences représentées
par les lemmes seuls), soit tres génériques ((N OM PRP N OM )) lorsque les séquences ne sont formées
que des catégories grammaticales. Un motif comme ((h0mme)(de PRP)(NOM ne peut étre appris
qu’a partir de séquences d’itemsets. De plus, l’analyse des motifs séquentiels d’itemsets extraits du corpus
AXIOLO montre la complétude de la méthode. On retrouve en effet tous les motifs présentés précédem-
ment et qui ont servi a générer ce corpus. Enﬁn, les expériences réalisées sur le corpus ARTS ontperIr1is
de tester la méthode a une échelle relativement importante sur un corpus généré automatiquement et non
annoté. L’ensemble des motifs produits comporte des motifs inintéressants dﬁs au bruit présent dans le
corpus. Face a ce probleme, la navigation au sein de la hiérarchie des motifs est un point fort de la mé-
thode permettant aisément d’élaguer des groupes de motifs inintéressants. Enﬁn, de nouveaux patrons sont
extraits au regard de ceux déja concus manuellement dans (J ackiewicz et al., 2009a). C’est le cas du motif
((ADJ pour DET NOM ("célebre pour son monastere", "baroque pour une histoire d’amour", ...) et
de ses variantes ou extensions : ((ADV) (ADJ) (p0ur)) ("tres célebre pour..."), ((ADJ)(p0ur)(VER))
("indispensable pour assurer...").

7http ://illimine.cs.uiuc.edu/

8Les motifs obtenus sont consultables : http : //users . info . unicaen . fr/~pce11ier/taln2 010/

9Soulignons que les indices classiques de rappel et de précision ne sont pas adaptés pour cette approche qui vise a organiser
et non a élaguer les motifs extraits. Cette méthode aurait donc un trés bon rappel et une précision médiocre.

PEGGY CELLIER, THIERRY CHARNOIS

4 Conclusion

Dans cet article nous présentons une méthode utilisant l’extraction de motifs séquentiels d’itemsets pour
la génération automatique de patrons linguistiques. Cette approche a l’avantage d’éviter un recoupement
manuel d’expressions pour déterminer des patrons. De plus, les patrons extraits sont compréhensibles
par un humain. L’avantage de décrire les mots non plus par un seul lemme comme dans (Charnois et al.,
2009), mais par un ensemble d’items, est une plus grande expressivité des patrons linguistiques découverts
(combinant des informations hétérogenes). Nous proposons aussi une solution pour gérer le nombre de
motifs extraits en s’appuyant sur un ordre partiel qui existe entre ces motifs. Un utilisateur humain peut
ainsi facilement naviguer dans les motifs et les valider en tant que patrons linguistiques. Nous avons utilisé
notre méthode pour l’apprentissage de patrons linguistiques pour la reconnaissance de constituants de
qualiﬁcation en position détachée. Le processus peut étre utilisé pour apprendre d’autres types de patrons
linguistiques, comme les relations entre entités nommées, en déﬁnissant des contraintes appropriées.

Références

AGRAWAL R. & SRIKANT R. (1995). Mining sequential patterns. In Int. Conf on Data Engineering :
IEEE.

CALIFF M. E. & MOONEY R. J. (2003). Bottom-up relational learning of pattern matching rules for
information extraction. J. Mach. Learn. Res., 4, 177-210.

CHARNOIS T., PLANTEVIT M., RIGOTTI C. & CREMILLEUX B. (2009). Fouille de données sequen-
tielles pour l’extraction d’information. Traitement Automatique des Langues, 50(3).

DAVEY B. A. & PRIESTLEY H. A. (1990). Introduction To Lattices And Order. Cambridge University
Press.

DONG G. & PEI J. (2007). Sequence Data Mining. Springer.

FERRE S. (2009). Camelis : a logical information system to organize and browse a collection of docu-
ments. Int. J. General Systems, 38(4).

HEARST M. (1992). Automatic acquisition of hyponyms from large text corpora. In Int. Conf on
Computational Linguistics.

JACKIEWICZ A., CHARNOIS T. & FERRARI S. (2009a). Jugements d’évaluation et constituants peri-
phériques. In Conference sur le traitement automatique des langues naturelles.

JACKIEWICZ A., VIGIER D., CHARNOIS T. & FERRARI S. (2009b). Vers une analyse automatique des
discours évaluatifs. Le cas des constituants détachés "en N <exp>". In Linguistic and Psycholinguistic
Approaches to Text Structuring : ENS.

PANG B. & LEE L. (2007). Opinion mining and sentiment analysis. Foundations and Trends in Infor-
mation Retrieval, 2(1-2), 1-135.

POIBEAU T. (2003). Extraction automatique d ’information .' Du texte brut au web sémantique. Lavoisier.
RILOFF E. (1996). Automatically generating extraction patterns from untagged text. In AAAUIAAP96.
SRIKANT R. & AGRAWAL R. (1996). Mining sequential patterns : Generalizations and performance
improvements. In Int. Conf on Extending Database Technology (EDBT), LNCS, p. 3-17 : Springer.

YAN X., HAN J . & AFSHAR R. (2003). Clospan : Mining closed sequential patterns in large databases.
In Int. Conf on Data Mining : SIAM.

