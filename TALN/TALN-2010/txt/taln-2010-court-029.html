<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Tree analogical learning. Application in NLP</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>Tree analogical learning. Application in NLP
</p>
<p>A.Ben Hassena L.Miclet
ENSSAT / IRISA, Lannion, France
</p>
<p>{benhasse, miclet}@enssat.fr
</p>
<p>Abstract. In Artificial Intelligence, analogy is used as a non exact reasoning technique to solve
problems, for natural language processing, for learning classification rules, etc. This paper is interested
in the analogical proportion, a simple form of the reasoning by analogy, and presents some of its uses in
machine learning for NLP. The analogical proportion is a relation between four objects that expresses that
the way to transform the first object into the second is the same as the way to transform the third in the
fourth.
We firstly give definitions about the general notion of analogical proportion between four objects. We
give a special focus on objects structured as ordered and labeled trees, with an original definition of
analogy based on optimal alignment. Secondly, we present two algorithms which deal with tree analogical
matching and solving analogical equations between trees. We show their use in two applications : the
learning of the syntactic tree (parsing) of a sentence and the generation of prosody for synthetic speech.
</p>
<p>R&#233;sum&#233;. En intelligence artificielle, l&#8217;analogie est utilis&#233;e comme une technique de raisonnement
non exact pour la r&#233;solution de probl&#232;mes, la compr&#233;hension du langage naturel, l&#8217;apprentissage des r&#232;gles
de classification, etc. Cet article s&#8217;int&#233;resse &#224; la proportion analogique, une forme simple du raisonnement
par analogie, et pr&#233;sente son application en apprentissage automatique pour le TALN. La proportion ana-
logique est une relation entre quatre objets qui exprime que la mani&#232;re de transformer le premier objet en
le second est la m&#234;me que la fa&#231;on de transformer le troisi&#232;me en le quatri&#232;me.
Premi&#232;rement, nous d&#233;finissons formellement la proportion analogique entre quatre objets. Nous nous
int&#233;ressons particuli&#232;rement aux objets structur&#233;s que sont les arbres ordonn&#233;s et &#233;tiquet&#233;s, avec une d&#233;fi-
nition originale de l&#8217;analogie fond&#233;e sur l&#8217;alignement optimal. Ensuite, nous pr&#233;sentons deux algorithmes
qui calculent la dissemblance analogique entre quatre arbres et qui trouvent des solutions, &#233;ventuellement
approch&#233;es, &#224; une &#233;quation analogique entre arbres. Nous montrons leur utilisation dans deux applica-
tions : l&#8217;apprentissage de l&#8217;arbre syntaxique d&#8217;une phrase et la g&#233;n&#233;ration de la prosodie dans la synth&#232;se
de parole.
</p>
<p>Mots-cl&#233;s : Proportion analogique, arbre syntaxique, analyseur syntaxique analogique.
</p>
<p>Keywords: Analogical proportion, syntactic tree, analogical syntactic parser.
</p>
<p>1 Introduction
</p>
<p>The concept of analogy has been studied as one of the modality of reasoning since Aristotle ((Lepage,
2003) ; (Holyoak, 2005)). It is a form of reasoning by generalization, but neither abductive nor inductive,
which models a third form of learning. Recently, a growing interest has been manifested for a formal</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>A.BEN HASSENA, L.MICLET
</p>
<p>point of view on the analogical proportion. This concept is now rigorously defined and its applications
in representation spaces of various kinds have been developed, with interesting operational results. Its
application to learning and generation is conceptually simple ; however, as in many areas of artificial
intelligence, the complexity of some algorithmic problems remains to surmount.
In this paper we consider the problem of analogical learning using dissimilarity between trees, which
we define as a multiple alignment of four ordered labeled trees, according to the notion of analogical
proportion. We extend the concept of alignment defined by (Jiang et al., 1994) to more than two trees.
When four trees are considered, we propose to apply the concept of analogical proportion to trees and we
extend it to that of analogical dissimilarity.
In the next section, we present the general notion of analogical proportion between four objects. In the
third section, we describe our approach, starting from several original definitions to define the analogical
dissimilarity between trees. Section 4 presents two algorithms performing analogical tasks in the universe
of trees. In the last section, we apply these algorithms to the learning of the syntactic tree of a sentence
and give hints to use it to predict prosody in speech synthesis.
</p>
<p>2 The Analogical Proportion and its Applications
</p>
<p>The analogical proportion is a relation between four objects which expresses that the way to transform
the first object into the second is the same as the way to transform the third in the fourth. Let us call the
objects O1, O2, O3 and O4. An analogical proportion is generally written as : &quot;O1 is to O2 as O3 is to O4&quot;
and is denoted by O1 : O2 :: O3 : O4 (Lepage, 2003).
</p>
<p>2.1 The Analogical Proportion, an algebraic definition
</p>
<p>Definition 2.1 An Analogical Proportion on a set E is a relation on E4 such that, for every 4-tuple A, B,
C and D in relation in this order (which is denoted as A : B :: C : D), one has :
</p>
<p>1. A : B :: C : D&#8660; C : D :: A : B
2. A : B :: C : D&#8660; A : C :: B : D
</p>
<p>Moreover, every couple of elements must satisfy the relation : A : B :: A : B
</p>
<p>An analogical equation is a relation of the form A : B :: C : X , which has to be solved in X . It may have
no, one or several solutions.
</p>
<p>A nice formulation of the analogical proportion according to these axioms, based on the notion of factori-
sation, has been given in (Stroppa &amp; Yvon, 2005).
</p>
<p>2.2 Semantics and examples
</p>
<p>The relation A : B :: C : D is generally interpreted as &#8221;A is to B as C is to D&#8221;, which means that to
transform A into B, one has to make the same operations than to transform C in D. The analogical
proportion has been studied and its semantics explored especially in the following domains :</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>{0, 1}d. Four objects defined by a vector of binary attribute are in analogical proportion when, on each co-
ordinate, one has one among the six proportions : 0 : 0 :: 1 : 1, 1 : 1 :: 0 : 0, 1 : 0 :: 1 : 0, 0 : 1 :: 0 : 1,
0 : 0 :: 0 : 0 or 1 : 1 :: 1 : 1.
</p>
<p>Rd. Four objects defined as vectors of numerical attributes are in additive analogical proportion when
&#8722;&#8594;
AC =
</p>
<p>&#8722;&#8594;
BD, i.e. on every coordinate : Ai : Bi :: Ci : Di &#8660; Ai +Di = Bi + Ci .
</p>
<p>&#931;?. Some theory and algorithms about the analogical proportion on strings and its use can be found in
(Lepage, 2003; Stroppa &amp; Yvon, 2005; Miclet et al., 2008; Hofstadter, 1994; Langlais et al., 2008).
An analogical proportion on strings is, for example : overlook is to looked as overcook is to
cooked.
</p>
<p>3 Analogical proportion and trees
</p>
<p>With the same principles that (Stroppa &amp; Yvon, 2005) and (Miclet et al., 2008) for strings, we present
in this paragraph our methodology to define an analogical proportion between ordered and labelled trees.
The only prerequisite is that there exists an analogical proportion in the alphabet of the label of the nodes,
augmented with the empty word &#955;. A node with label &#955; is also denoted &#955; and is called an empty node.
</p>
<p>Definition 3.1 (Alignment between two trees (Jiang et al., 1994)) An alignment between two trees T1,
T2 whose labels are in &#931;&#955; = &#931; &#8746; &#955; is a tree with labels in (&#931;&#955;) &#215; (&#931;&#955;)/(&#955;, &#955;) which first projection is
T1, where the empty nodes &#955; are ignored and which second projection is T2, where the empty node &#955; are
ignored.
Informally, an alignment represents a one to one node matching between two trees, in which some empty
nodes may be inserted. The cost of an alignment is the sum of all nodes matching costs.
</p>
<p>This definition can straightforwardly be extended to the alignment of any number of trees. When aligning
four trees, we can apply the concept of analogical proportion to trees.
</p>
<p>Definition 3.2 (Analogical proportion between trees) Let x, y, z and t be four trees whose labels are
in &#931;&#955;. We suppose that an analogical proportion exists in &#931;&#955;. We say that these trees are in analogical
proportion if there is an alignment of the four trees x, y, z and t, with labels in &#931;4&#955;, such that : for every
node i of the alignment, the analogical proportion xi : yi :: zi : ti of the labels holds true (figure 1 (a),(b)).
</p>
<p>Definition 3.3 (Tree analogical equation) T4 is a solution of the analogical equation T1 : T2 : : T3 : X if
and only if the analogical proportion (T1 : T2 : : T3 : T4) holds true.
</p>
<p>3.1 Analogical Dissimilarity between trees
</p>
<p>In this section, we are interested in defining what could be a relaxed analogy, which linguistic expression
would be &#8221;A is to B almost as C is to D&#8221;. To remain coherent with our previous definitions, we mea-
sure the term &#8220;almost as&#8221; by some positive real value, equal to 0 when the analogical proportion is true,
and increasing when the four objects are less likely to be in proportion. We call this value &#8220;analogical
dissimilarity&#8221;, in short AD.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>A.BEN HASSENA, L.MICLET
</p>
<p>This measure has been introduced on binary vectors, numerical vectors and sequences in (Miclet et al.,
2008), and we want now to extend it to trees. We present in the following our definition of AD between
four trees and we give its properties. This definition uses the notion of alignment between four trees. We
assume there is some analogical dissimilarity existing on the alphabet of the nodes labels &#931;&#955;. Let a, b, c
and d be node labels in &#931;&#955;. We have AD(a, b, c, d) = 0 iff a : b :: c : d and AD(a, b, c, d) &gt; 0 in the other
case. Thus, the Analogical Dissimilarity between four ordered labeled trees can be defined by :
</p>
<p>Definition 3.4 (AD between trees) Let X , Y , Z and T be four trees with labels &#8712; &#931;&#955;. The analogical
dissimilarity AD(X, Y, Z, T ) is the cost of the alignment of minimum cost between the four trees.
This alignment is a tree A, and the cost (or analogical dissimilarity) of an alignment is defined as :
</p>
<p>AD(X, Y, Z, T ) =
&#8721;
AD(xi, yi, zi, ti), with i &#8712; [1.. |A|] and xi, yi, zi and ti &#8712; &#931;&#955;.
</p>
<p>Definition 3.5 (Best approximate solution to an analogical equation)
Let T1 : T2 : : T3 : X be an analogical equation in trees. The set of best approximate solution to this
</p>
<p>equation is given by :
X = { x : x = ArgMin AD(T1, T2, T3, x)}
</p>
<p>3.2 Algorithms
</p>
<p>We have described in (BenHassena &amp; Miclet, 2010) two algorithms based on dynamic programming,
called AnaTree and SolvTree that allow :
&#8211; from four trees, to compute their AD and their optimal alignment, according to definition 3.4 ; this
</p>
<p>procedure is in O(|T |4), where |T| is the number of nodes of the bigger tree.
&#8211; from three trees T1, T2 and T3, to compute a fourth tree T4 such that AD(T1, T2, T3, T4) is minimal,
</p>
<p>according to definition 3.5. This procedure is in O(|T |3).
</p>
<p>4 Analogical syntactic parser
</p>
<p>We apply these algorithms of analogical matching between structured objects to automatic parsing. Our
hypothesis is simple : if four sentences have their sequences in analogical proportion (or with a low AD),
then their syntactic trees are also in analogical proportion (or with a low AD). We test this hypothesis on a
corpus of parsed sentences, each of these sentences being associated to its syntactic tree. The sentences are
composed as sequences of grammatical categories, which are found as labels of the syntactic tree leaves.
The labels of the tree nodes are syntactic labels as the &quot;noun phrase (NP)&quot;, etc. Figure 1 (b) shows an
example of parsing.
</p>
<p>This assumption leads to a method for automatically generating syntactic tree (parsing automatic). We
consider a sentence P0, which sequence S0 of grammatical categories is known and which syntactic struc-
ture T0 is searched for. Let AP a learning set of sentences (S, T ), each sentence consisting of a sequence
and a syntactic structure. The process of prediction by analogy of the parse tree T0 is as follows :
</p>
<p>1. Search for a triple of sentences (P1, P2, P3) with sequences (S1, S2, S3) and syntactic structures (T1,
T2, T3) such as the sequences S0, S1, S2 and S3 define an analogical proportion S0 : S1 : S2 : S3</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>(a) Analogical proportion between trees (b) Example of parsing
</p>
<p>(c) The tree resulting of an analogical proportion
</p>
<p>FIGURE 1 &#8211; Analogical syntactic parser
</p>
<p>2. We make the hypothesis that, if the sequences are in analogy, so are the structures. Hence, we predict
T0 from the resolution of the analogical equation on trees : x : T1 :: T2 : T3.
</p>
<p>The corpus at our disposal consists of 316 sentences extracted from the base The Wall Street Journal
Penn Treebank (Marcus et al., 1993). Since the data available is limited, we have used the leave-one-out
technique to evaluate the results. Preliminaries results give an exact or almost exact (with a AD lower than
2) restitution of the parsing tree from the sequence in 82 % of cases. Note that, since we have kept in
the learning set only sentences that have different sequences of grammatical categories, a simple nearest
neighbor method would have given an null accuracy at a null distance. This shows that the analogical
proportion takes profit of the recombination of subsequences and of subtrees.
</p>
<p>5 Analogical prosody prediction
</p>
<p>We present here ongoing work on prosody prediction for speech synthesis. This approach considers sen-
tences as tree structures and infers the prosody from a corpus of such structures using a machine learning
technique. The prediction is achieved from the prosody of the closest (at minimal AD) sentences of the
corpus through tree analogical dissimilarity measurements, using also the analogy-based approach. Given
three known tree structures T1, T2, T3 and a new one T0, an analogical proportion would be expressed</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>A.BEN HASSENA, L.MICLET
</p>
<p>as : T1 is to T2 as T3 is to T0 if and only if the set of operations transforming T1 into T2 is equivalent
to the set of operations transforming T3 into T0. This relation can be relaxed according to the notion of
analogical dissimilarity. Next, the analogical transfer would apply on the prosodic string associated to T3
the transformation defined between the prosodic strings associated to T1 and T2 to produce the prosody of
T0. From these two notions, the analogical inference would be therefore defined as :
&#8211; firstly, retrieve all analogical proportions involving T0 and three trees in the corpus ;
&#8211; secondly, compute the analogical transfer for each 3-tuple of the corresponding prosodic strings, and
</p>
<p>store the result in a set of possible outputs if the transfer succeeds.
Experiments are currently under process to qualify this approach.
</p>
<p>6 Conclusion
</p>
<p>In this paper, we have proposed a new learning method based on the analogical proportion between trees,
and its approximation called &quot;analogical dissimilarity&quot;. As an application we have firstly proposed a case-
based parsing system, with preliminary promising results. Secondly, we have presented hints on a new
prosody prediction method. Further investigations will be conducted, taking into account that the proposed
brute force method is time-consuming, but can be ameliorated, as shown in (Langlais &amp; Yvon, 2008) and
(Miclet et al., 2008).
</p>
<p>R&#233;f&#233;rences
</p>
<p>BENHASSENA A. &amp; MICLET L. (2010). Analogical learning using dissimilarity between tree-structures.
In Proceedings of ECAI 2010. To be published.
HOFSTADTER D. (1994). Fluid Concepts and Creative Analogies. New York : Basic Books.
HOLYOAK K. (2005). Analogy. In The Cambridge Handbook of Thinking and Reasoning, chapter 6.
Cambridge University Press.
JIANG T., WANG L. &amp; ZHANG K. (1994). Alignment of trees - an alternative to tree edit. In CPM &#8217;94 :
Proceedings of the 5th Annual Symposium on Combinatorial Pattern Matching, p. 75&#8211;86, London, UK :
Springer-Verlag.
LANGLAIS P. &amp; YVON F. (2008). Scaling up analogical learning. In 22nd International Conference on
Computational Linguistics (COLING 2008), p. 51&#8211;54, Manchester, United Kingdom. Poster.
LANGLAIS P., YVON F. &amp; ZWEIGENBAUM P. (2008). An Analogical Learning Approach to Translating
Terms. Rapport interne, Paritech, INFRES, IC2, Paris, France.
LEPAGE Y. (2003). De l&#8217;analogie rendant compte de la commutation en linguistique. Grenoble. Habili-
tation &#224; diriger les recherches.
MARCUS M. P., MARCINKIEWICZ M. A. &amp; SANTORINI B. (1993). Building a large annotated corpus
of english : the penn treebank. Comput. Linguist., 19(2), 313&#8211;330.
MICLET L., BAYOUDH S. &amp; DELHAY A. (2008). Analogical dissimilarity : Definition, algorithms and
two experiments in machine learning. Journal of Artificial Intelligence Research, 32, 793&#8211;824.
STROPPA N. &amp; YVON F. (2005). Analogical learning and formal proportions : Definitions and methodo-
logical issues. Rapport interne ENST-2005-D004, &#201;cole Nationale Sup&#233;rieure des T&#233;l&#233;communications.</p>

</div></div>
</body></html>