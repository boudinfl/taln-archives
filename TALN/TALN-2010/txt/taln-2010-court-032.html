<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Semi-automated Extraction of a Wide-Coverage Type-Logical Grammar for French</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>Semi-automated Extraction of a Wide-Coverage Type-Logical
Grammar for French&#8727;
</p>
<p>Richard Moot
LaBRI (CNRS, Bordeaux) &amp; SIGNES (INRIA Bordeaux SW)
</p>
<p>351 cours de la Lib&#233;ration, 33405 Talence, FRANCE
Richard.Moot@labri.fr
</p>
<p>Abstract. The paper describes the development of a wide-coverage type-logical grammar for French,
which has been extracted from the Paris 7 treebank and received a significant amount of manual ver-
ification and cleanup. The resulting treebank is evaluated using a supertagger and performs at a level
comparable to the best supertagging results for English.
</p>
<p>R&#233;sum&#233;. Cet article d&#233;crit le d&#233;veloppement d&#8217;une grammaire cat&#233;gorielle &#224; large couverture du
Fran&#231;ais, extraite &#224; partir du corpus arbor&#233; de Paris 7 et v&#233;rifi&#233;e et corrig&#233;e manuellement. Le gram-
maire cat&#233;gorielle r&#233;sultant est &#233;valu&#233;e en utilisant un supertagger et obtient des r&#233;sultats comparables aux
meilleurs supertaggers pour l&#8217;Anglais.
</p>
<p>Mots-cl&#233;s : Extraction de grammaires, grammaires cat&#233;gorielles, supertagging.
Keywords: Categorial grammar, grammar extraction, supertagging, type-logical grammar.
</p>
<p>1 Introduction
</p>
<p>Though the development of parsers for the French language is an active area of research &#8212; as witnessed,
for example, by the participation in the EASy evaluation &#8212; currently available grammar and parsers
for the French language produce structures (typically shared forests or dependency structures) which are
not easily exploitable for semantic tasks. Recently, the first results for wide-coverage semantic analysis
for English have begun to emerge (Bos et al., 2004); these developments have been made possible to a
large extent by the availability of an automatically extracted grammar which permits an easy mapping of
syntactic structures to semantic structures: the CCGbank (Hockenmaier &amp; Steedman, 2007), a treebank
for English with annotations in combinatory categorial grammar (CCG).
This paper describes the development of a type-logical treebank for French, which has been developed with
is usefulness for such semantic tasks in mind. Using the Paris 7 treebank as a starting point, type-logical
formulas are extracted automatically and then verified and corrected manually. The resulting grammar,
which is still highly ambiguous because of the large number of lexical categories assigned to each word,
is then evaluated using a supertagger, which disambiguates the lexical categories using local information
only, and found to perform at a level comparable to the best results for English.
</p>
<p>&#8727;This research has been partially financed by the conseil r&#233;gional d&#8217;Aquitaine in the context of the ITIPY project.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>RICHARD MOOT
</p>
<p>2 Type-logical Grammar
</p>
<p>This introduction to modern type-logical grammars will be necessarily brief and gives only an informal
sketch of many of the ideas without going into the formal details. However, this short introduction will be
sufficient to help the reader understand the grammar extraction in the next section. The interested reader
can find a more detailed introduction and motivations in (Moortgat, 1997).
Type-logical grammars are a grammatical formalism with its roots in formal logic and the theory of types.
A type-logical grammar defines a finite set of atomic formulas (typically s for sentence, np for noun
phrase, n for noun and pp for prepositional phrase) and complex formulas A /B (which looks to its right
for an expression of type B in order to produce an expression of A) and B \ A (which looks to its left for
an expression of type B in order to produce an expression of type A).
Therefore (np\s)/np is a formula of the calculus. It would be the formula assigned to a transitive verb. It
states that it combines first with a noun phrase to its right to produce an expression of type np \ s (the type
assigned to an intransitive verb) after which it combines with a noun phrase to its left to form a sentence.
In order to give an account of long-distance dependencies, such as those introduced by relativizers like que
in French, we assign a formula of the form (n\n) / (s /32np). Here, abstracting over the logical details,
this formula indicates that que is looking to its right for a sentence s missing a noun phrase somewhere, as
indicated by the subformula s / 32np, after which is will function as a noun modifier, selecting an n to
its left to form an n.
</p>
<p>In addition, the multimodal type-logical grammar used here (Moortgat, 1997) permits a controlled access
to &#8220;movement&#8221; operations, and allows the assignment of a formula s\1s indicating that the adverb is a
sentence modifier with mode information 1 allowing it to &#8216;move&#8217; towards the head of the phrase.
</p>
<p>In order to obtain the semantics for a syntactic analysis in a type-logical grammars we can directly apply
the fact that the set of derivations in a type-logical grammar is a proper subset of the set of derivations in
intuitionistic logic and thereby obtain the semantics of a derivation simply by means of the well-established
Curry-Howard isomorphism between proofs and &#955;-terms. This means that from a categorial derivation &#8212;
and an approriated lexicon assigning &#955;-terms to word-formulas pairs &#8212; we can directly obtain a semantic
representation in the style of Montague or in a more modern dynamic framework such as DRT (Bos et al.,
2004).
</p>
<p>3 Grammar Extraction
</p>
<p>The Paris 7 treebank (Abeill&#233; et al., 2003) is a corpus containing extracts of the &#8216;Le Monde&#8217; newspaper
from December 1989 to January 1994. Part of this corpus (12,440 sentences containing a total of 371,029
word tokens, with 25,280 word types) has been given a functional annotation as well. Given that this
functional annotation helps the extraction process and reduces the number of manual corrections, the
grammar extraction has been defined for this sub-corpus only.
</p>
<p>Figure 1 shows a tree from the Paris 7 corpus, a segment of the longer phrase &#8220;La cour a, d&#8217;autre part,
att&#233;nu&#233; le montant des amendes que la 11 chambre avait inflig&#233;es aux autres pr&#233;venus&#8221;. This sentence
segment suffices to discuss the most interesting cases of the extraction algorithm.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>SEMI-AUTOMATED EXTRACTION OF A WIDE-COVERAGE TLG FOR FRENCH
</p>
<p>Srel
</p>
<p>NP
obj
</p>
<p>PROREL
</p>
<p>que
</p>
<p>NP
suj
</p>
<p>DET
</p>
<p>la
</p>
<p>ADJ
</p>
<p>11
</p>
<p>NC
</p>
<p>chambre
</p>
<p>VN
</p>
<p>V
</p>
<p>avait
</p>
<p>VPP
</p>
<p>inflig&#233;es
</p>
<p>PP
aobj
</p>
<p>P+D
</p>
<p>aux
</p>
<p>NP
</p>
<p>ADJ
</p>
<p>autres
</p>
<p>NC
</p>
<p>pr&#233;venus
</p>
<p>Figure 1: Example tree from the Paris 7 treebank with the extracted formulas indicated below the leaves
</p>
<p>n\n
</p>
<p>(n\n)/(s/32np)
</p>
<p>que
</p>
<p>s
</p>
<p>np
</p>
<p>np/n
</p>
<p>la
</p>
<p>n
</p>
<p>n/n
</p>
<p>11
</p>
<p>n
</p>
<p>chambre
</p>
<p>np\s
</p>
<p>(np\s)/(np\sppart)
</p>
<p>avait
</p>
<p>np\sppart
</p>
<p>(np\sppart)/ppa
</p>
<p>((np\sppart)/ppa)/np
</p>
<p>inflig&#233;es
</p>
<p>np
</p>
<p>&#491;
</p>
<p>ppa
</p>
<p>ppa/n
</p>
<p>aux
</p>
<p>n
</p>
<p>n/n
</p>
<p>autres
</p>
<p>n
</p>
<p>pr&#233;venus
</p>
<p>Figure 2: The tree from Figure 1 binarized and with formula information added
</p>
<p>The grammar extraction algorithm used follows the general principles of grammar extraction for categorial
grammars, as it has been used in other contexts (Buszkowski &amp; Penn, 1990; Hockenmaier &amp; Steedman,
2007; Moot, 2010).
</p>
<p>1. the tree is binarized, when necessary nodes are inserted for &#8216;traces&#8217; (we will see this in more detail
in the example below).
</p>
<p>2. in the resulting tree, a distinction is made between heads (functors), arguments and modifiers; a
simple table lookup is used to decide between the different cases based on the node labels and
their functional annotation, so in a sentence (annotated by SENT) the verb cluster (annotated by
VN) is assigned as its head, NP and PP daughters are assigned as arguments1, whereas adverbs
(annotated by ADV and ADVP) would be assigned a modifier role. Similarly, in an NP, adjectives
and prepositions will be modifiers.
</p>
<p>3. formulas are assigned in a top-down fashion starting with the root node and descending the tree by
case analysis; again a table lookup is used to convert syntactic categories to atomic formulas
</p>
<p>&#8226; if the parent node has formula A assigned to it and the left (resp. right) daughter is a modifier
then the left daughter will receive formula A/A and the right daughter formula A (resp. A and
A\A in the case the right daughter was a modifier
</p>
<p>&#8226; if the left daughter is an argument and the right daughter is a functor, we look up the cor-
responding formula B in the table and assign B and B\A to the two daughters; similarly if
</p>
<p>1unless they have the NPmod functional annotation, as would expressions like &#8220;dimanche 5 janvier&#8221; or &#8220;cette fois&#8221; or the
PPmod functional annotation, as would expressions like &#8220;en Espagne&#8221; or &#8220;sauf accident&#8221;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>RICHARD MOOT
</p>
<p>the left daughter is a functor and the right daughter an argument with formula B then the
corresponding formulas will be A/B and B respectively.
</p>
<p>&#8226; for a leaf with word w and computed formula A, the pair w &#8722;A is added to the lexicon.
</p>
<p>Figure 2 shows the result of the extraction algorithm for the tree discussed above. I will just comment on
some of the less evident aspects of the extracted lexicon.
</p>
<p>Firstly, some restructuring has taken place. The prepositional phrase headed by aux was assigned in the
corpus as an argument of the verb cluster VN, where in the extracted lexicon it is an argument of the past
participle inflig&#233;es. Again, these cases are very common and this reattachment gives us a more natural
lexicon. Otherwise, the binarization is without surprises.
</p>
<p>A second important element is the analysis of the relative pronoun que. As can be seen in Figure 1, the
corpus indicates the que is has the role of object in the relative phrase, but in addition it functions as
a modifier of the noun amendes (absent from the figure). The extraction algorithm adds an np &#8216;trace&#8217;,
indicated by &#491;, to the rightmost verb of the first verbal group occurring after the relativizer, though manual
verification is often necessary to verify this is the correct position.2 The relation between the trace and
the relativizer is indicated in the figure by a dotted line. Readers familiar with multimodal categorial
grammars will recognize the dotted line corresponds to the introduction rule for the implication [/I]. All
in all, this gives us the category for the relative pronoun que which we discussed in Section 2: a noun
modifier selecting a sentence missing a noun phrase to its right.
</p>
<p>Finally, it should be noted that some of the syntactic categories have subcategories: we distinguish between
s when it occurs as a past participle (sppart) or infinitive group (sinf) making it possible for a verb to admit
only specific verb groups as its arguments. This allows us to assign (np\s)/(np\sppart) to the different
forms of avoir and (np\s)/(np\sinf) to the different forms of vouloir.
</p>
<p>4 Improving the extracted grammar
</p>
<p>A first run of the extraction algorithm gives a highly ambiguous grammar with 5.240 distinct formulas
which have been assigned at least once to one of the words in the lexicon. Manual inspection of this first
treebank TLG0 reveals that the extracted lexicon contains many formulas which are the result either of
inconsistencies in the treebank or of inconsistencies between the way a phenomenon is analyzed in the
treebank and the way it would preferably be analyzed in a type-logical grammar.
</p>
<p>A first improvement is the reduction of the different formulas assigned to adverbs. One of the prototypical
positions for an adverb is directly to the right of the verb it modifies. This means that if we assign the
formula A to this verb, the adverb will have formula A\A assigned to it. However, using the multimodal
solution sketched in Section 2 permits us to reduce these instances to the formula s \1 s.
</p>
<p>In addition, by inspecting the different lexical entries, both for the most frequent words and for the different
part-of-speech tags, entries which have been deemed suspect have been manually verified and, where
necessary, corrected. Inversely, the list of words assigned to each of the different formulas has been
inspected and again formulas which looked inappropriate for the words to which they were assigned
have been verified, corrected and made more consistent. To give an indication of the impact of these
</p>
<p>2Some relatative pronouns like qui are easy, whereas others, like dont and laquelle require more effort.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>SEMI-AUTOMATED EXTRACTION OF A WIDE-COVERAGE TLG FOR FRENCH
</p>
<p>simplifications, the different formulas for conjunctions have been reduced from 606 in TLG0 to 188 in
TLG.
</p>
<p>Taken together, these improvements reduce the number of lexical formulas to a more reasonable, but
still quite large, number of 817 distinct formulas. This second treebank, TLG, while undoubtedly still
containing a fair amount of errors, provides a good balance between lexicon size and descriptive adequacy.
</p>
<p>Some differences with the English treebank CCGbank should be noted. First of all, in the CCGbank,
conjunctions (in our case et, ou and on some occasions the comma) are handled by the parser whereas in
the TLG treebank this information is handled by the supertagger, hence the 188 different categories cited
above. In addition, to reduce the number of lexical categories, the CCGbank uses a number of non-logical
axioms which transform past participles to adjectives (useful in noun phrases like &#8220;le risque li&#233; au n&#233;goce
international&#8221;, where li&#233; is assigned (n\n)/ppa &#8212; instead of its usual (np\sppart)/ppa &#8212; indicating that
in this context, it selects a prepositional phrase to its right in order to become a noun modifier). Other non-
logical axiom include a rule allowing an n to function as an np, which is used for a noun phrases without
a determiner. In order to give an indication of the effects of these simplifications in the current context, a
second grammar by automatically simplifying the first grammar in accordance with these strategies. We
will refer to this more compact grammar as TLGc.
</p>
<p>5 Evaluation
</p>
<p>&#946; TLG #/w TLGc #/w
1.0 90.5 1.0 93.5 1.0
0.1 96.4 2.7 97.5 2.5
</p>
<p>0.05 97.3 3.1 98.0 2.9
0.01 98.4 4.7 98.8 3.8
</p>
<p>Table 1: Supertagger results for the TLG
treebanks
</p>
<p>In spite of all the reductions made to the treebanks, the re-
sulting lexicon still has a very high number of formulas as-
signed to each word. In order for the extracted grammar to be
more easily parsed, a &#8216;classic&#8217; strategy is to use a supertag-
ger which decides, based on the surrounding local context &#8212;
the words and part-of-speech tags occurring in a two-word
window around the current word as well as the previous two
formulas or &#8216;supertags&#8217; &#8212; which is the most likely formula
to assign to the current word.
</p>
<p>The maximum entropy supertagger developed by Clark &amp; Curran (2004) has been used to evaluate su-
pertagger performance on the TLG treebank. The treebank has been split into two set: a of training data
containing 11.196 sentences and 334.525 words and a set of test data, containing 1.244 sentences and
36.504 words. The maximum entropy model has been trained with the Clark &amp; Curran (2004) supertagger
using their adaptation of the L-BFGS algorithm to optimize parameter estimation.
</p>
<p>Results for the extracted grammars TLG and TLGc are shown in Table 1.3 For the first row only the best
supertag has been kept, whereas the other rows list the result for a multitagger which keeps all supertag
with probability greater than &#946; times the highest probability (Clark, 2002), with a lower &#946; value meaning
a larger set of supertags assigned to each word. The left-hand column lists the percentage of the sets
of supertags assigned to word-POS tag pairs containing the correct supertag for experiments TLG and
TLGc, with the right-hand column listing the average number of supertags per word. Though we should
</p>
<p>3Results for the treebank TLG0 which incorporates none of the improvements described in Section 4 are not shown in the
table. Supertagging predicision for this treebank is 79.4 %, which is in line with results reported for automatically extracted
TAGs (Chen &amp; Vijay-Sjanker, 2000) both in terms of the number of different supertags and precision.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>RICHARD MOOT
</p>
<p>be careful making direct comparisons between results from different languages and different formalisms,
these results indicate a supertagger performance comparable with the supertaggers for English described
in (Clark, 2002), though our results have a slightly higher number of supertags assigned to each word for
the lower &#946; values.
</p>
<p>6 Conclusion and Future Work
</p>
<p>In this paper a wide-coverage type-logical gramar for French has been semi-automatically extracted from
the Paris 7 treebank and the resulting corpus has been evaluated using a supertagger. The supertagger
obtains state-of-the-art performance compared to English supertaggers.
</p>
<p>Currently, different parsing strategies are being developped for further evaluation of the results of the
supertagger, and early results look promising. Development of a wide-coverage semantic lexicon for this
grammar &#8212; in the style of Bos et al. (2004) &#8212; is progressing rapidly and both this lexicon and the
trained models for the POS and supertagger will be made available to the research community under the
LGPL-LR license.
</p>
<p>ABEILL&#201; A., CL&#201;MENT L. &amp; TOUSSENEL F. (2003). Building a treebank for French. In A. ABEILL&#201;,
Ed., Treebanks: Building and Using Parsed Corpora, chapter 10, p. 165&#8211;187. Dordrecht: Kluwer.
</p>
<p>BOS J., CLARK S., STEEDMAN M., CURRAN J. R. &amp; HOCKENMAIER J. (2004). Wide-coverage
semantic representation from a CCG parser. In Proceedings of the 20th International Conference on
Computational Linguistics (COLING-2004), p. 1240&#8211;1246, Geneva, Switzerland.
BUSZKOWSKI W. &amp; PENN G. (1990). Categorial grammars determined from linguistic data by unifica-
tion. Studia Logica, 49, 431&#8211;454.
</p>
<p>CHEN J. &amp; VIJAY-SJANKER K. (2000). Automated extraction of TAGs from the Penn treebank. In
Proceedings of the 6th International Workshop on Parsing Technologies, Trento, Italy.
CLARK S. (2002). Supertagging for combinatory categorial grammar. In Proceedings of the 6th Inter-
national Workshop on Tree Adjoining Grammars and Related Formalisms, p. 19&#8211;24, Venice.
CLARK S. &amp; CURRAN J. R. (2004). Parsing the WSJ using CCG and log-linear models. In Proceedings
of the 42nd annual meeting of the Association for Computational Linguistics (ACL-2004), p. 104&#8211;111,
Barcelona, Spain.
</p>
<p>HOCKENMAIER J. &amp; STEEDMAN M. (2007). CCGbank, a corpus of CCG derivations and dependency
structures extracted from the Penn Treebank. Computational Linguistics, 33(3), 355&#8211;396.
MOORTGAT M. (1997). Categorial type logics. In J. VAN BENTHEM &amp; A. TER MEULEN, Eds., Hand-
book of Logic and Language, chapter 2, p. 93&#8211;177. Elsevier/MIT Press.
MOOT R. (2010). Automated extraction of type-logical supertags from the spoken dutch corpus. In S.
BANGALORE &amp; A. JOSHI, Eds., Supertagging: Using Complex Lexical Descriptions in Natural Lan-
guage Processing. MIT Press.</p>

</div></div>
</body></html>