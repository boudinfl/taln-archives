TALN 2010, Montreal, 19-23 juillet 2010

Traduction de requétes basée sur Wikipédia

Benoit Gaillard, Olivier Collin, Malek Boualem

Orange Labs — 2, Avenue Pierre Marzin, 22300 Lannion, France,
benoit.gaillard@univ—tlse2.fr, olivier.collin, malek.boualem@orange—

ftgroup.com

Résumé Cet article s'inscrit dans le domaine de la recherche d'information multilingue. Il
propose une méthode de traduction automatique de requétes basée sur Wikipédia. Une phase
d'analyse permet de segmenter la requéte en syntagmes ou unités lexicales a traduire en
s'appuyant sur les liens multilingues entre les articles de Wikipédia. Une deuxieme phase
permet de choisir, parmi les traductions possibles, celle qui est la plus cohérente en s'appuyant
sur les informations d'ordre sémantique fournies par les catégories associées a chacun des
articles de Wikipédia. Cet article justifie que les données issues de Wikipédia sont
particulierement pertinentes pour la traduction de requétes, détaille l'approche proposée et son
implémentation, et en démontre le potentiel par la comparaison du taux d'erreur du prototype
de traduction avec celui d'autres services de traduction automatique.

Abstract This work investigates query translation using only Wikipedia-based resources
in a two steps approach: analysis and disambiguation. After arguing that data mined from
Wikipedia is particularly relevant to query translation, we detail the implementation of the
approach. In the analysis phase, queries are segmented into lexical units that are associated to
several possible translations using a bilingual dictionary extracted from Wikipedia. During the
second phase, one translation is chosen amongst the various candidates, based on consistency,
asserted with the help of semantic information carried by categories associated to Wikipedia
articles. These two steps take advantage of data mined from Wikipedia, which is very rich and
detailed, constantly updated but also easy and free to access. We report promising results
regarding translation accuracy.

lV[0tS-CléS: recherche d'information multilingue, traduction de requétes, Wikipédia.
Keywords: cross language information retrieval, query translation, Wikipedia.

TALN 2010, Montréal, 19-23 juillet 2010

1 Introduction de notre approche comparée a l'état de l'art

1.1 Approches lexicales de la traduction et de l'analyse de requétes

Les approches lexicales de traduction de requétes pour la recherche d'information multilingue
se heurtent a des difficultés de couverture lexicale et d'ambigu'1'té. L'encyclopédie en ligne
Wikipédia permet de proposer des solutions a ces deux problemes car d'une part elle met a
disposition une quantité conséquente de connaissances, constamment Inises a jour et
accessibles, ce qui permet d'en extraire aisément des lexiques dont la couverture est optimale
et d'autre part ces connaissances sont organisées sémantiquement par le biais de catégories
fournies par les contributeurs (Zesh et al., 2007). Nous montrons que les données issues de
Wikipédia ont des propriétés adaptées au traitement des requétes et exposons une méthode de
segmentation des requétes en unités lexicales et une stratégie de choix de traduction parmi
plusieurs alternatives, par homogénéité thématique s'appuyant sur les catégories. Beaucoup
d'approches de traduction lexicale de requétes s'appuient accessoirement sur Wikipédia,
contrairement a notre approche qui en utilise exclusivement l'apport lexical et sémantique. Par
exemple, Ballesteros et al. (1997) utilisent des syntagmes extraits d'un corpus parallele traduit
manuellement, alors que (Jones et al., 2008) utilisent un lexique de syntagmes issus de
Wikipédia. Pour extraire les syntagmes de la requéte, ces auteurs utilisent la méthode dite de
"Maximum forward matching" qui consiste a détecter le plus long syntagme possible dans la
requéte, en partant du début, puis a répéter récursivement l'opération. Notre approche pour la
détection de syntagmes, en revanche, s'appuie sur le seul lexique issu des titres d'articles de
Wikipédia et maximise la taille des unités lexicales extraites sur la requéte dans son ensemble.

1.2 Approches sémantiques pour la désambiguisation des requétes

Des mesures telles que la "similarité sémantique" initialement développées par (Resnik, 1995)
peuvent étre appliquées a des requétes en s'appuyant sur Wikipédia (Strube, Ponzetto, 2006).
(Bunescu, Pasca, 2006) proposent une méthode de reconnaissance et de désambigu'1'sation
d'entités nommées (EN) a l'aide d'un dictionnaire extrait de Wikipédia et de la similarité
cosinus entre les mots du contexte autour de l'EN et les mots de l'article correspondant a l'EN
candidate. Nous fondons notre mesure de proximité uniquement sur les catégories, qui offrent
une représentation plus concise du theme sémantique d'un article que celle issue du texte car
c'est l'objectif meme de leur ajout. (Schonhofen et al., 2008) s'appuient sur les articles,
considérés comme des concepts, de Wikipédia en langue cible pour désambigiiiser les
requétes par homogénéité thématique (topic homogeneity) (Gledson, Keane, 2008) pour
ensuite les reformuler. Notre approche s'appuie aussi sur l'homogénéité thématique, mais nos
alternatives sont des traductions directes, alors que les leurs sont des concepts qui, une fois
sélectionnés, sont utilisés pour générer les requétes en langue cible, come a l'aide d'un pivot.

2 Wikipédia: une ressource pour le traitement des requétes

Propriétés lexicales et sémantiques des titres et catégories d'articles: Les conventions
relatives au nommage des articles sont déﬁnies sur la page explicative de Wikipédial. En
particulier, le titre idéal est le titre le plus concis, ne commencant pas par un article. Si
plusieurs titres sont possibles, le plus commun est utilisé, par application du principe de
moindre surprise (http://fr.wikipedia.org/wiki/Principe_de_moindre_surprise). Ces

lhtt J/en.wild edia.or  edia:Namin conventions accessed Feb. 2010

conventions ont pour consequence qu'une forte proportion de titres sont des EN et des groupes
nominaux et ne comportent que quelques mots, comme la grande majorité des requetes (Jones
et al., 2008). Un utilisateur a tendance a formuler la requete la plus courte possible. La
denomination d'un sujet la plus commune, choisie pour le titre d'un article, est aussi la plus
commune dans un corpus de requetes. Les requetes présentent donc des propriétes
linguistiques qui correspondent a celles des titres d'articles de Wikipédia. (Strube et al., 2006)
appellent folksonomie la structure resultant de categorisation des articles de Wikipedia. Par
ailleurs Zesh et al., (2007) montrent que le graphe constitué par les categories de Wikipedia
partage de nombreuses propriétes avec des reseaux semantiques lexicaux tels que WordNet.
Cela permet de penser que le graphe des categories de Wikipédia est une ressource
sémantique valide pour des applications de TALN, tout en étant beaucoup plus riche que des
thesaurus coﬁteux a créer et a maintenir manuellement.

Génération de données issues de Wikipédia: Nous avons extrait de la page de ressources de
Wikipedia (http://download.wikimedia.org/enwiki/latest/ downloaded Nov. 2009) un lexique
bilingue dans lequel les titres francais d'articles de Wikipédia sont associés aux titres anglais
correspondants par des liens multilingues entre articles traitant du meme sujet. Ce lexique
contient 540.920 traductions, dont un grand nombre d'ENs et de syntagmes, comme par
exemple: "Avocat du diable" <3? Devil's advocate"; "L'Avocat du diable (ﬁlm)" <t> "Guilty as
Sin". Les contributeurs de Wikipedia associent des categories a chaque article ainsi qu'a
d'autres categories par des relations hierarchiques (thematique ou hyperonymique). Les
hierarchies de categories associées aux articles de Wikipédia ont éte extraites du site de
ressources de Wikipédia. Elles ne constituent pas une taxonomie rigoureuse car elles sont
librement construites par des contributeurs varies, ce qui fait toute la richesse de cette
folksonomie (Strube, Ponzetto, 2007). C'est pourquoi, pour ne pas en subir les inévitables
inexactitudes ou redondances, nous avons sélectionné environ 20 categories parmi la ou les
centaines de categories associées a un article directement ou par filiation. Cette selection
détaillée dans (Collin et al. 2010) s'appuie sur l'heuristique selon laquelle le chemin le plus
court parmi les chemins reliant les articles a des categories pseudo—terminales serait le plus
pertinent. Cette 20aine de categories est utilisée de maniere non pondérée.

3 Misc en oeuvre du prototype de traduction de requétes

Les deux phases consécutives de la traduction des requetes sont illustrées Figure 1: D'abord la
segmentation en unites lexicales, ensuite la désambigijisation a l'aide des categories.

Requéte seg mentée,
alternatives de
traduction:

Requéte AB C D requéte
Iangue A. C. D. Iangue
source: - .

—> 4» A" C” D“ 4» 4. cible .
ABCD cm A..c...D.
Correspondence

Lexicale Similarité
Sémantique
 Liens 7 -AT\;

     

Articles Wikipédia Articles Wikipédia Categories Wikipédia
(larigue source) (langue cible ) (langue cible )

Figure 1: Schema synoptique de la traduction de requétes basée sur les titres et les articles de Wlkipédia.

TALN 2010, Montreal, 19-23 juillet 2010

3.1 Segmentation des requétes a l'aide des titres d'articles traduits

Une requéte est fréquemment constituée de plusieurs mots qui forment une unite lexicale qui
se traduit de maniere non littérale. Par exemple, "Amicalement votre" se traduit en anglais par
"The Persuaders". Une requéte composée de plusieurs mots doit étre segmentée en unites
lexicales. Par exemple, la requéte ABCD (composée des Quatre mots A,B, C et D) peut se
décomposer en: "ABCD"; "ABC,D"; "AB,CD"; "A,BCD"; "A,BC,D";"AB,C,D";"A,B,CD"
ou "A,B,C,D". Le choix de la meilleure segmentation se base sur l'hypothese que lorsque
plusieurs mots successifs peuvent se traduire comme une unite, cette traduction est la plus
correcte. La méthode consiste a verifier, pour Chacune des segmentations candidates, si les
unites qui la composent appartiennent au lexique bilingue extrait de Wikipédia, dans l'ordre
défini par les trois regles Rl a R3:

- (R1) Minimiser le nombre d'unités lexicales ("A,B,CD" plutét que "A,B,C,D").

- (R2) Pour 1e méme nombre d'unités, Maximiser la taille de la plus grande unite lexicale
("ABC,D" plutot que " AB,CD").

- (R3) Pour la méme taille d'unité, privilégier les unites lexicales en debut de requéte
("ABC,D" plutot que "A,BCD").

Une segmentation est acceptée si un pourcentage suffisant (80%, dans ce travail) de mots (de
la requéte en langue source) se trouvent dans des unites lexicales qui donnent lieu a une
traduction non vide. Par exemple, si le découpage [AB][C][DE] se traduit par [A'B'][][D'E'],
alors ce pourcentage est de 80%. Si les regles Rl et R2 correspondent bien a l'intuition, le
critere de la regle R3 et celui des 80% sont choisis empiriquement et leur optimalité
mériteraient d'étre évalué lors de travaux poursuivant le travail présenté ici.

3.2 Désambiguisation des requétes traduites par homogénéité thématique

Chaque unite d'une requéte peut étre traduite par plusieurs alternatives. Nous choisissons la
traduction qui maximise lhomogénéité thématique. Chacune des alternatives en langue cible
est représentee, dans l'espace vectoriel défini par les categories, par un vecteur de coordonnée
l selon Chacune des categories associées a l'article correspondant (environs 20, come
expliqué section 2), 0 selon Chacune des autres categories. La proximité sémantique de deux
alternatives est définie par la similarité cosinus de leurs vecteurs de categories, comme illustré
par la Figure 2. Les proximités sémantiques de toutes les paires d'unités traduites sont
calculées puis ajoutées, mesurant ainsi lhomogéneité thématique de la requéte traduite.

  
   
 
 
   

CD

Catégories
Vvikipedia

Titres
d'ar'tic|es
(FR)

tit res d‘ articles
(EN)

 
 

I écluse 1 ] bateau |

Figure 2:Choix de la traduction de « lock >> par "écluse" par homogénéité thématique avec "bateau".

4 Evaluation de la traduction des requétes et perspectives

Le tableau 1 illustre des résultats satisfaisants. Les lignes 1 et 2 illustrent la bonne couverture
lexicale des ENs et termes en montrant que notre prototype est le seul a traduire correctement
le titre de ﬁlm ou le terme. Les lignes 2 et 4 illustrent les bonnes capacités de

désambiguisation par homogénéité thématique: le fruit avocat est plus probablement he a
l'agriculture biologique que l'homme de loi avocat, car ils partagent le theme de l'agriculture.

Source Traduction Wikipédia Traduction Systran Traduction Google
Maman, j'ai raté Home Alone Mom, I missed the Mom, I missed the plane
l'avion plane
vélo tout terrain mountain bike bicycle any ground road bike
juge avocat Judge Lawyer judge lawyer Judge Advocate
avocat agriculture Avocado Organic lawyer organic farming Advocate farming
biologique Farming

Tableau 1: Illustration de la segmentation, de la traduction des EN et syntagmes et de la désambiguisation.

La traduction a été évaluée sur un corpus d'environs 7000 requétes saisies sur un moteur de
recherche d'un portail multimédia monolingue publique d'Orange2, se rapportant au domaine
des actualités. Les requétes, composées en general de quelques mots, comportent de
nombreuses ENs et erreurs orthographiques, comme reporté dans (Bouraoui et al. 2010).
Nous avons comparé les traductions du prototype avec celles de 3 logiciels de traduction
automatique du marché, en libre service3: Systran, ProMT et Google. Le taux d'erreur (ER) est
évalué par 1 humain qui assigne une note a chaque traduction (0: mauvaise traduction, 0.5:
partiellement correcte, 1: bonne traduction). La moyenne M de ces scores est calculée sur la
base des 7000 requétes, méme répétées car la performance d'un moteur se mesure par l'usage.
Le taux d'erreur est déﬁni par la formule: ER=1-M. Notre prototype ne proposant aucune
correction orthographique ou traitement grammatical, nous avons distingué les requétes
comportant des erreurs ou des structures telles que des dates ou des phrases (environ le tiers
de toutes les requétes). Ainsi, le Tableau 2 présente 2 ER différents: pour toutes les requétes
(ER), et pour celles sans erreur ni structure (ER_og).

Wikipédia Systran ProMT Goo gle
ER 0,131 0,132 0,170 0,077
ER*,g 0,100 0,118 0,156 0,064

Tableau 2: Comparaison des Taux d'Erreurs de plusieurs traducteurs appliqués aux requétes.

La traduction par lexique et categories de Wikipédia uniquement est meilleure que celle de 2
des 3 traducteurs testés. Nos résultats inférieurs a ceux de Google s'eXpliquent par le fait que
nous traitons mal de nombreuses requétes comportant des opérateurs booléens, des mots

Zhttp://www.2424actu.fr

3 http://WWW.s)§t1'an.f1'/; http://tr.voila.fr/;http://wvvw.google.fr/language tools?hl=fr

TALN 2010, Montréal, 19-23 juillet 2010

simples tels que «de», ou des verbes conjugués. L'évaluation d'un moteur de CLIR tirant parti
de cette approche dépasse le cadre de ce travail, mais la qualité relative des traductions
obtenues malgré son implémentation minimaliste permet de penser que, lors de travaux futurs,
notre approche sera en mesure de contribuer a l'élaboration de moteurs de recherche
multilingues performants.

Références

BALLESTEROS L., CROFT W. B. (1997). Phrasal translation and Query Expansion Techniques
for Cross Language Information Retrieval. Actes de 20th annual international ACM SIGIR
conference on research and development in information retrieval, SIGIR 1997, 84-91.

BOURAOUI J.L., GAILLARD B., GUIIVIIER DE NEEF E., BOUALEM M. (2010). Annotation of
linguistic phenomena in query logs. Actes de Congreso Internacional de Lingiiistica de
Corpus, May 2010, University of A Coruﬁa.

BUNESCU R. C., PASCA M. (2006). Using encyclopedic knowledge for named entity
disambiguation. Actes de 11th conference of the European Chapter of the Association for
Computational Linguistics (EACL-2006), Trento, Italy, 9-16.

COLLIN 0., GAILLARD B., BOURAOUI J .L., GIRAULT, T. (2010). Constitution d'une resource
sémantique issue du treillis des catégories de Wikipédia. Actes de 17é conference sur le
Traitement Automatique des Langues Naturelles (TALN 2010), Montreal, Canada.

GLEDSON A., KEANE J . (2008). Measuring Topic Homogeneity and its Application to
Dictionary-Based Word-Sense Disambiguation. COLING 2008, Manchester, UK 273-280.

JONES, G.J.F., FANTINO F., NEWMAN E., ZHANG Y. (2008). Domain-specific query translation
for multilingual information access using machine translation augmented with dictionaries
mined from Wikipedia. 2nd International Wbrkshop on Cross Lingual Information Access:
Addressing the Information Need of Multilingual Societies, Hyderabad, India, 34-41.

LESK M. E. (1996). Automatic sense disambiguation using machine readable dictionaries:
How to tell a pine cone from and ice cream cone. 5th Annual Conference on Systems
Documentation, Toronto, Ontario, Canada, 24-26.

RESNIK P. (1995). Using information content to evaluate semantic similarity in a taxonomy.
International Joint Conference for Artiﬁcial Intelligence (IJCAI-95), 1, 448-453.

SCHONHOFEN P., BENCZUR A., B1ROI., AND CSALOGANY K. (2008). Cross-Language Retrieval
with Wikipedia. Lecture Notes in Computer Science: Advances in Multilingual and
Multimodal Information Retrieval, 5152, (CLEF 2007) 72-79.

STRUBE M., PONZETIO S. P. (2006). WikiRelate!: Computing Semantic Relatedness Using
Wikipedia. Actes de AAAI 2006, 1419-1424.

ZESCH. T., GUREVYCH I.,MUHLHAUSER M. (2007). Analysing and Accessing Wikipedia as a
Lexical Semantic Resource. Actes de Data Structures for Linguistic Resources and
Applications, 197-205.

