<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>LEOPAR, un analyseur syntaxique pour les grammaires d&#8217;interaction</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>LEOPAR, un analyseur syntaxique pour les grammaires d&#8217;interaction
</p>
<p>Bruno Guillaume, Guy Perrier
INRIA Nancy-Grand Est - LORIA - Nancy-Universit&#233;
</p>
<p>R&#233;sum&#233;. Nous pr&#233;sentons ici l&#8217;analyseur syntaxique LEOPAR bas&#233; sur les grammaires d&#8217;interaction
ainsi que d&#8217;autres outils utiles pour notre cha&#238;ne de traitement syntaxique.
</p>
<p>Abstract. We present the parser LEOPAR which is based on the Interaction Grammars formalism.
We present also other tools used in our framework for parsing.
</p>
<p>Mots-cl&#233;s : Analyse syntaxique, grammaires d&#8217;interaction, polarit&#233;s.
</p>
<p>Keywords: Parsing, Interaction Grammars, polarities.
</p>
<p>Introduction
</p>
<p>Les grammaires d&#8217;interaction (Guillaume &amp; Perrier, 2010) sont un formalisme grammatical qui place la
notion de polarit&#233; au c&#339;ur du m&#233;canisme de composition syntaxique. Les objets de base d&#8217;une grammaire
d&#8217;interaction sont des fragments d&#8217;arbres syntaxiques sous-sp&#233;cifi&#233;s qui sont d&#233;cor&#233;s par des polarit&#233;s. Ces
polarit&#233;s expriment l&#8217;&#233;tat de saturation du fragment concern&#233; et sa capacit&#233; d&#8217;interaction avec d&#8217;autres
fragments. La composition syntaxique consiste alors &#224; superposer partiellement ces fragments d&#8217;arbres
pour saturer leurs polarit&#233;s et obtenir un arbre unique compl&#232;tement sp&#233;cifi&#233; o&#249; toutes les polarit&#233;s auront
&#233;t&#233; satur&#233;es.
</p>
<p>L&#8217;op&#233;ration de superposition d&#8217;arbres est plus g&#233;n&#233;rale que les op&#233;rations habituelles dans les grammaires
d&#8217;arbres comme les TAG et elle permet donc de mieux abstraire et de factoriser un certain nombre de
constructions syntaxiques. Cependant les grammaires &#224; large couverture restent n&#233;cessairement tr&#232;s am-
bigu&#235;s. Avec les ressources actuelles pour le fran&#231;ais, l&#8217;ambigu&#239;t&#233; moyenne par mot est de l&#8217;ordre de 7,
c&#8217;est-&#224;-dire qu&#8217;il y a en moyenne 7 descriptions d&#8217;arbres diff&#233;rentes &#224; consid&#233;rer pour chaque mot d&#8217;une
phrase et donc que le nombre de combinaison &#224; consid&#233;rer pour une phrase de N mots et de l&#8217;ordre de 7N .
</p>
<p>Les outils que nous avons d&#233;velopp&#233;s ont pour but de valider le formalisme en permettant d&#8217;&#233;crire des
ressources &#224; large &#233;chelle et de les tester. Ainsi l&#8217;analyseur LEOPAR dans sa version actuelle est con&#231;u
pour construire, &#224; l&#8217;aide d&#8217;une grammaire et d&#8217;un lexique, toutes les analyses possibles d&#8217;une phrase en
entr&#233;e. Compte tenu de cet objectif, nous n&#8217;avons pas d&#233;velopp&#233; de m&#233;thodes statistiques pour l&#8217;anal-
yse syntaxique dans les grammaires d&#8217;interaction et nous utilisons peu d&#8217;heuristiques lors des analyses.
Nous nous sommes essentiellement int&#233;ress&#233;s &#224; la mise au point de m&#233;thodes exactes de d&#233;sambigu&#239;sation
lexicale.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>BRUNO GUILLAUME, GUY PERRIER
</p>
<p>1 La cha&#238;ne de traitement
</p>
<p>La cha&#238;ne de traitement de LEOPAR est d&#233;crite par la figure ci-dessous :
</p>
<p>Ressources linguistiques
</p>
<p>Lexique LEXICOMP
</p>
<p>R&#232;gles de segmentation TOKTOK
</p>
<p>Grammaire source XMG
</p>
<p>Lexique
compress&#233; Phrase
</p>
<p>Automate
d'hypertags
</p>
<p>LEOPAR
(ancrage)
</p>
<p>Automate de
descriptions d'arbre
</p>
<p>Grammaire
objet
</p>
<p>LEOPAR
(filtrage par polarit&#233;s)
</p>
<p>LEOPAR
(filtrage par d&#233;pendances)
</p>
<p>LEOPAR
(analyse)
</p>
<p>Arbres syntagmatiques
</p>
<p>Structures en d&#233;pendances
</p>
<p>Le compilateur de grammaires XMG 1 est un outil de d&#233;veloppement de grammaires &#224; large couverture,
pour lesquelles le maintien de la coh&#233;rence est une t&#226;che particuli&#232;rement difficile. XMG est fond&#233; sur
la distinction entre grammaire source et grammaire objet. La premi&#232;re est &#233;crite par un humain dans un
langage de haut niveau sous forme de classes combin&#233;es par conjonction ou disjonction. Ensuite, XMG
compile cette grammaire source en un grammaire objet directement utilisable par un syst&#232;me de TAL.
</p>
<p>Le compilateur de lexiques LEXICOMP permet de compiler des lexiques extensionnels sous forme d&#8217;au-
tomates compacts et rapides d&#8217;acc&#232;s. Chaque forme fl&#233;chie est d&#233;crite &#224; l&#8217;aide d&#8217;hypertags qui regroupent
les informations syntaxiques et morphologiques.
</p>
<p>Le segmenteur en mots TOKTOK permet de segmenter en mots une phrase. Il utilise les informations du
lexique et repr&#233;sente l&#8217;ambigu&#239;t&#233; &#224; l&#8217;aide d&#8217;automates acycliques.
</p>
<p>L&#8217;ancrage de la grammaire dans le lexique utilise la notion d&#8217;hypertag. &#192; chaque arbre produit par
XMG est associ&#233; un hypertag qui d&#233;crit les contraintes d&#8217;ancrage qui se fait alors par unification avec les
informations lexicales.
</p>
<p>Le filtrage avec les polarit&#233;s (Bonfante et al., 2004) utilise la saturation des polarit&#233;s comme principe
contr&#244;lant la composition syntaxique. Ce principe est utilis&#233; pour la d&#233;sambigu&#239;sation lexicale : on peut
&#233;liminer les choix lexicaux qui ne sont pas globalement neutres.
</p>
<p>Le filtrage avec les d&#233;pendances (Bonfante et al., 2009) repose sur le fait que chaque arbre initial est une
structure insatur&#233;e qui attend d&#8217;interagir avec un autre arbre pour cr&#233;er une d&#233;pendance. On peut calculer
statiquement sur la grammaire objet une matrice de contraintes ; celle-ci permet, pour une phrase donn&#233;e,
de supprimer les choix lexicaux qui n&#8217;ont pas de possibilit&#233; de se saturer dans la phrase consid&#233;r&#233;e.
</p>
<p>L&#8217;analyse profonde recherche de fa&#231;on exhaustive l&#8217;ensemble des mod&#232;les pour lesquels l&#8217;analyse de
gauche &#224; droite ne laisse pas un nombre trop grand de polarit&#233;s non r&#233;solues. La recherche se fait incr&#233;-
mentalement par fusion successives de n&#339;uds.
</p>
<p>2 La mise en &#339;uvre de LEOPAR
</p>
<p>En plus d&#8217;une interface par ligne de commande, l&#8217;analyseur offre une interface graphique de dialogue avec
l&#8217;utilisateur. Cette interface permet de piloter l&#8217;analyse mais aussi de visualiser les ressources lexicales
et grammaticales, ce qui est tr&#232;s utile pour le d&#233;bogage. Sous une forme ou sous une autre, l&#8217;interface
</p>
<p>1. XMG (Duchier et al., 2004) est librement disponible sous licence CeCILL (http://sourcesup.cru.fr/xmg)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LEOPAR
</p>
<p>utilisateur fournit diff&#233;rents param&#232;tres qui permettent de personnaliser l&#8217;utilisation de l&#8217;analyseur.
</p>
<p>L&#8217;analyse peut &#234;tre effectu&#233;e de fa&#231;on totalement automatique ou selon un mode manuel. Dans ce cas,
c&#8217;est l&#8217;utilisateur qui effectue la s&#233;lection lexicale et qui ensuite choisit, &#224; chaque &#233;tape de l&#8217;analyse,
les n&#339;uds &#224; fusionner. Une fen&#234;tre interactive permet de visualiser l&#8217;&#233;tat d&#8217;analyse &#224; chaque &#233;tape et de
revenir &#233;ventuellement en arri&#232;re pour la reprendre diff&#233;remment. Comme il est expliqu&#233; dans Marchand
et al. (2009, 2010), les saturations utilis&#233;es lors de l&#8217;analyse permettent &#233;galement de d&#233;duire une structure
en d&#233;pendances.
</p>
<p>Notre cha&#238;ne de traitement a &#233;t&#233; utilis&#233;e pour produire FRIGRAM, une GI du fran&#231;ais &#224; large couverture.
La plupart des constructions grammaticales du fran&#231;ais sont couvertes, et parmi elles, un certain nombre
qui sont non triviales : coordination, extraction avec &quot;pied piping&quot; et barri&#232;res, n&#233;gation . . . La grammaire
objet, dans son &#233;tat actuel, contient 2 670 arbres &#233;l&#233;mentaires sous-sp&#233;cifi&#233;s non ancr&#233;s issus de 359 classes
de la grammaire source.
</p>
<p>La grammaire a &#233;t&#233; test&#233;e sur la TSNLP du fran&#231;ais (Test Suite for Natural Language Processing). Le
fait que notre grammaire soit fond&#233;e sur des connaissances linguistiques lui assure une bonne pr&#233;cision
et limite la surg&#233;n&#233;ration : 88% des 1 300 phrases grammaticales sont analys&#233;es correctement et 85% des
1 600 phrases non grammaticales sont rejet&#233;es par notre grammaire.
</p>
<p>3 Exemple
</p>
<p>Consid&#233;rons la phrase : &#171; Un &#233;l&#232;ve qui est lent &#224; comprendre est d&#233;courag&#233; par le travail. &#187;
</p>
<p>La figure ci-dessous montre les r&#233;sultats obtenus par les diff&#233;rentes m&#233;thodes de filtrage. Avant tout
d&#233;sambigu&#239;sation, chaque mot a en moyenne 7.34 structures possibles (soit 7.3412 = 24 &#215; 109 s&#233;lec-
tions lexicales &#224; consid&#233;rer). Chacune des deux m&#233;thodes de filtrages permet de diminuer fortement cette
ambigu&#239;t&#233; moyenne (2.63 pour les polarit&#233;s et 2.90 pour les d&#233;pendances) mais surtout, elles sont tr&#232;s
compl&#233;mentaires tant en temps de filtrage qu&#8217;en termes d&#8217;ambigu&#239;t&#233; (au final une ambigu&#239;t&#233; moyenne de
1.53, c&#8217;est-&#224;-dire seulement 168 s&#233;lections lexicales &#224; consid&#233;rer).
</p>
<p>M&#233;thode de d&#233;sambigu&#239;sation Nombre de s&#233;lections lexicales Ambigu&#239;t&#233; par mot temps
avant d&#233;sambigu&#239;sation 24 671 606 400 7.34
</p>
<p>polarit&#233; 112 781 2.63 1.78s
d&#233;pendances 362 880 2.90 0.02s
</p>
<p>polarit&#233; + d&#233;pendances 168 1.53 0.16s
</p>
<p>Faute de place, seul le format en structure de d&#233;pendances est illustr&#233; ci-dessous pour notre exemple. Il
est int&#233;ressant de noter qu&#8217;on obtient plus que des d&#233;pendances de surfaces : en traits discontinus, par
exemple, on note que le nom &#233;l&#232;ve est le sujet de l&#8217;infinitif comprendre.
</p>
<p>un
det
</p>
<p>&#233;l&#232;ve
n
</p>
<p>qui
pro
</p>
<p>est
v
</p>
<p>lent
adj
</p>
<p>&#224;
prep
</p>
<p>comprendre
v
</p>
<p>est
aux
</p>
<p>d&#233;courag&#233;
v
</p>
<p>par
prep
</p>
<p>le
det
</p>
<p>travail
n
</p>
<p>modif
</p>
<p>det subj subjattr aobj obj
</p>
<p>subj
</p>
<p>subj
passiv agt
</p>
<p>obj
det</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>BRUNO GUILLAUME, GUY PERRIER
</p>
<p>4 Perspectives
</p>
<p>De fa&#231;on &#233;vidente, LEOPAR n&#8217;est pas actuellement op&#233;rationnel pour traiter de gros corpus comme ceux
en jeu dans la derni&#232;re campagne d&#8217;&#233;valuation PASSAGE 2. LEOPAR n&#8217;est pas con&#231;u pour faire de l&#8217;anal-
yse robuste, il ne fournit donc aucune information partielle pour des phrases qui ne sont pas grammaticales
au sens de notre grammaire. De plus, LEOPAR n&#8217;utilise pas de statistiques, il fait une recherche exhaustive
parmi les nombreuses ambigu&#239;t&#233;s possibles pour une phrase d&#8217;un corpus ; les m&#233;thodes de d&#233;sambigu&#239;-
sation d&#233;velopp&#233;es permettent d&#8217;analyser des phrases d&#8217;environ 20 mots mais nous ne pouvons pas pour
l&#8217;instant analyser les phrases plus longues.
</p>
<p>Les deux points sur lesquels nous travaillons actuellement sont, d&#8217;une part, le d&#233;veloppement de m&#233;thodes
d&#8217;analyses syntaxiques robustes et, d&#8217;autre part, la d&#233;veloppement d&#8217;analyses s&#233;mantiques &#224; partir des
structures produites par l&#8217;analyseur (Bonfante et al., 2010).
</p>
<p>Remerciements
</p>
<p>Nous tenons &#224; remercier Paul Masson qui a largement contribu&#233; au d&#233;veloppement des outils pr&#233;sent&#233;s
ici.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BONFANTE G., GUILLAUME B. &amp; MOREY M. (2009). Dependency constraints for lexical disambigua-
tion. In proceedings of IWPT 09, Paris, France.
</p>
<p>BONFANTE G., GUILLAUME B., MOREY M. &amp; PERRIER G. (2010). R&#233;&#233;criture de graphes de d&#233;pen-
dances pour l&#8217;interface syntaxe-s&#233;mantique. In Actes de TALN 10, Montr&#233;al, Canada.
</p>
<p>BONFANTE G., GUILLAUME B. &amp; PERRIER G. (2004). Polarization and abstraction of grammatical
formalisms as methods for lexical disambiguation. In CoLing&#8217;2004, 2004, p. 303&#8211;309, Geneva, Switzer-
land.
</p>
<p>DUCHIER D., LE ROUX J. &amp; PARMENTIER Y. (2004). The metagrammar compiler : A NLP Applica-
tion with a Multi-paradigm Architecture. In Second International Mozart/Oz Conference - MOZ 2004,
Charleroi, Belgium.
</p>
<p>GUILLAUME B. &amp; PERRIER G. (2010). Interaction Grammars. Research on Language and Computation
(&#224; para&#238;tre).
</p>
<p>MARCHAND J., GUILLAUME B. &amp; PERRIER G. (2009). Analyse en d&#233;pendances &#224; l&#8217;aide des gram-
maires d&#8217;interaction. In Actes de TALN 09, Senlis, France. poster.
</p>
<p>MARCHAND J., GUILLAUME B. &amp; PERRIER G. (2010). Motifs de graphe pour le calcul de d&#233;pendances
syntaxiques compl&#232;tes. In Actes de TALN 10, Montr&#233;al, Canada.
</p>
<p>2. http://atoll.inria.fr/passage/eval2.fr.html</p>

</div></div>
</body></html>