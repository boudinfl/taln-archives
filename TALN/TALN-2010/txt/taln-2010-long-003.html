<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Exploitation d&#8217;une ressource lexicale pour la construction d&#8217;un &#233;tiqueteur morpho-syntaxique &#233;tat-de-l&#8217;art du fran&#231;ais</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>Exploitation d&#8217;une ressource lexicale pour la construction
d&#8217;un &#233;tiqueteur morpho-syntaxique &#233;tat-de-l&#8217;art du fran&#231;ais
</p>
<p>Pascal Denis &amp; Beno&#238;t Sagot
Alpage, INRIA Paris&#8211;Rocquencourt &amp; Universit&#233; Paris 7
Rocquencourt, BP 105, 78153 Le Chesnay Cedex, France
</p>
<p>{pascal.denis,benoit.sagot}@inria.fr
</p>
<p>R&#233;sum&#233;. Cet article pr&#233;sente MEltfr, un &#233;tiqueteur morpho-syntaxique automatique du fran&#231;ais. Il
repose sur un mod&#232;le probabiliste s&#233;quentiel qui b&#233;n&#233;ficie d&#8217;informations issues d&#8217;un lexique exog&#232;ne, &#224;
savoir le Lefff . Evalu&#233; sur le FTB, MEltfr atteint un taux de pr&#233;cision de 97.75% (91.36% sur les mots
inconnus) sur un jeu de 29 &#233;tiquettes. Ceci correspond &#224; une diminution du taux d&#8217;erreur de 18% (36.1%
sur les mots inconnus) par rapport au m&#234;me mod&#232;le sans couplage avec le Lefff . Nous &#233;tudions plus en
d&#233;tail la contribution de cette ressource, au travers de deux s&#233;ries d&#8217;exp&#233;riences. Celles-ci font appara&#238;tre
en particulier que la contribution des traits issus du Lefff est de permettre une meilleure couverture, ainsi
qu&#8217;une mod&#233;lisation plus fine du contexte droit des mots.
</p>
<p>Abstract. This paper presents MEltfr, an automatic POS tagger for French. This system relies on a
sequential probabilistic model that exploits information extracted from an external lexicon, namely Lefff .
When evaluated on the FTB corpus, MEltfr achieves an accuracy of 97.75% (91.36% on unknow words)
using a tagset of 29 categories. This corresponds to an error rate decrease of 18% (36.1% on unknow
words) compared to the same model without Lefff information. We investigate in more detail the contri-
bution of this resource through two sets of experiments. These reveal in particular that the Lefff features
allow for an increased coverage and a finer-grained modeling of the context at the right of a word.
</p>
<p>Mots-cl&#233;s : Etiquetage morpho-syntaxique, mod&#232;les &#224; maximisation d&#8217;entropie, fran&#231;ais, lexique.
</p>
<p>Keywords: POS tagging, maximum entropy models, French, lexicon.
</p>
<p>1 Introduction
</p>
<p>De nombreux syst&#232;mes pour l&#8217;&#233;tiquetage automatique en parties du discours ont &#233;t&#233; d&#233;velopp&#233;s pour un
large &#233;ventail de langues. Parmi les syst&#232;mes les plus performants, on trouve ceux qui s&#8217;appuient sur
des techniques d&#8217;apprentissage automatique1. Pour certaines langues comme l&#8217;anglais ou d&#8217;autres langues
tr&#232;s &#233;tudi&#233;es, ces syst&#232;mes ont atteint des niveaux de performance proches des niveaux humains. Il est
int&#233;ressant de constater que la majorit&#233; de ces syst&#232;mes n&#8217;ont pas recours &#224; une source externe d&#8217;infor-
mations lexicales, et se contentent d&#8217;un lexique extrait &#171; &#224; la vol&#233;e &#187; &#224; partir du corpus d&#8217;apprentissage
(cf. cependant (Hajic&#780;, 2000)). On est donc en droit de se demander s&#8217;il est possible d&#8217;am&#233;liorer encore
</p>
<p>1Se reporter &#224; (Manning &amp; Sch&#252;tze, 1999) pour un panorama complet.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PASCAL DENIS &amp; BENO&#206;T SAGOT
</p>
<p>les performances des &#233;tiqueteurs en exploitant ce type de ressources. Un avantage potentiel de l&#8217;utilisa-
tion d&#8217;un lexique externe consiste en un meilleur traitement des mots &#171; inconnus &#187;, c&#8217;est-&#224;-dire des mots
absents du corpus d&#8217;apprentissage, d&#232;s lors qu&#8217;ils sont pr&#233;sents dans le lexique externe.
</p>
<p>Dans (Denis &amp; Sagot, 2009), nous avons montr&#233; qu&#8217;un mod&#232;le d&#8217;&#233;tiquetage peut b&#233;n&#233;ficier &#224; la fois
d&#8217;informations provenant d&#8217;un corpus d&#8217;entra&#238;nement et d&#8217;un lexique exog&#232;ne &#224; large couverture. Nous
avons pour cela utilis&#233; des mod&#232;les markoviens &#224; maximisation d&#8217;entropie, &#224; savoir une classe de mod&#232;les
discriminants adapt&#233;s aux probl&#232;mes s&#233;quentiels et par ailleurs tr&#232;s rapides &#224; entra&#238;ner. Les exp&#233;riences
men&#233;es en couplant ainsi le Corpus Arbor&#233; de Paris 7, dor&#233;navant FTB pour French TreeBank (Abeill&#233;
et al., 2003), et le lexique Lefff (Sagot, 2010) ont ainsi conduit &#224; un &#233;tiqueteur de niveau &#233;tat de l&#8217;art
pour le fran&#231;ais, nomm&#233; MEltfr et distribu&#233; librement2, qui a une pr&#233;cision de 97, 7% sur le jeu de test.
(Denis &amp; Sagot, 2009) montre par ailleurs que l&#8217;utilisation d&#8217;informations extraites du Lefff permet, pour
des taux de pr&#233;cision similaires, de r&#233;duire le volume du corpus d&#8217;entra&#238;nement par un facteur de 2 &#224;
3. Ind&#233;pendamment, un travail comparable, mais qui int&#232;gre en plus dans le mod&#232;le les informations de
lemmatisation, a &#233;galement montr&#233; la pertinence de ce type d&#8217;approches (Chrupa&#322;a et al., 2008).
</p>
<p>Toutefois, les causes pr&#233;cises de l&#8217;am&#233;lioration des performances lorsque les informations du Lefff sont
exploit&#233;es n&#8217;avaient pas encore &#233;t&#233; explor&#233;es de fa&#231;on syst&#233;matique. On s&#8217;attend naturellement &#224; ce que
de telles informations suppl&#233;mentaires am&#233;liorent l&#8217;&#233;tiquetage des mots inconnus. Mais les informations
extraites du Lefff sont-elles les plus utiles &#224; propos du mot courant ou du contexte gauche ou droit ?
Sont-elles plus cruciales pour &#233;tiqueter les mots appartenant &#224; des classes ferm&#233;es ou ouvertes ?
</p>
<p>Pour apporter des &#233;l&#233;ments de r&#233;ponse &#224; ces questions, nous avons conduit plusieurs s&#233;ries d&#8217;exp&#233;riences.
Nous commen&#231;ons par d&#233;crire les ressources utilis&#233;es (section 2). Nous d&#233;taillons ensuite le fonctionne-
ment et les performances de l&#8217;&#233;tiqueteur MEltfr, am&#233;lior&#233; depuis sa pr&#233;sentation dans (Denis &amp; Sagot,
2009), et nous le comparons avec d&#8217;autres &#233;tiqueteurs entra&#238;n&#233;s sur les m&#234;mes donn&#233;es (section 3). Afin
de mieux comprendre la fa&#231;on dont le couplage avec le Lefff am&#233;liore les performances, nous pr&#233;sen-
tons alors des exp&#233;riences faisant varier la fa&#231;on dont les informations extraites du Lefff sont exploit&#233;es
(section 4), puis des exp&#233;riences faisant varier les jeux d&#8217;&#233;tiquettes du corpus et du lexique (section 5).
</p>
<p>2 Ressources utilis&#233;es
</p>
<p>Le corpus annot&#233; en parties du discours que nous avons utilis&#233; est une variante du FTB. Il diff&#232;re du FTB
originel en ceci que tous les compos&#233;s qui ne correspondent pas &#224; une s&#233;quence r&#233;guli&#232;re de parties du
discours sont fusionn&#233;s en un token unique, alors que les autres sont repr&#233;sent&#233;s par des s&#233;quences de plu-
sieurs tokens (Candito, c.p.). Le corpus r&#233;sultat contient 350 931 tokens pour 12 351 phrases. Dans le FTB
originel, les mots sont r&#233;partis en 13 cat&#233;gories principales, elles-m&#234;mes r&#233;parties en 34 sous-cat&#233;gories.
La version du corpus que nous avons utilis&#233;e a &#233;t&#233; obtenue en convertissant ces sous-cat&#233;gories en un jeu
de 29 parties du discours, avec une granularit&#233; interm&#233;diaire entre cat&#233;gories et sous-cat&#233;gories. Ces 29
&#233;tiquettes am&#233;liorent les cat&#233;gories principales par des informations sur le mode des verbes, ainsi que par
quelques traits lexicaux suppl&#233;mentaires. Ce jeu d&#8217;&#233;tiquettes est celui qui conduit aux meilleurs r&#233;sultats
d&#8217;analyse syntaxique probabiliste pour le fran&#231;ais (Crabb&#233; &amp; Candito, 2008)3. Comme dans (Crabb&#233; &amp;
Candito, 2008), le FTB est divis&#233; en 3 sections : entra&#238;nement (80%), d&#233;veloppement (10%) et test (10%).
</p>
<p>2http://gforge.inria.fr/projects/lingwb/.
3Ce jeu d&#8217;&#233;tiquettes est nomm&#233; TREEBANK+ dans (Crabb&#233; &amp; Candito, 2008).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UN &#201;TIQUETEUR MORPHOSYNTAXIQUE &#201;TAT-DE-L&#8217;ART DU FRAN&#199;AIS
</p>
<p>Les tailles respectives de ces sections sont d&#233;taill&#233;es &#224; la table 1, ainsi que les nombres et proportions de
tokens inconnus.4
</p>
<p>Section # de phrases # de tokens # de tokens inconnus # de tokens inconnus
et absents du Lefff
</p>
<p>FTB-TRAIN 9 881 278 083
FTB-DEV 1 235 36 508 1 790 (4, 9%) 604 (1, 7%)
FTB-TEST 1 235 36 340 1 701 (4, 7%) 588 (1, 6%)
</p>
<p>TAB. 1 &#8211; Jeux de donn&#233;es
</p>
<p>La source d&#8217;informations lexicales que nous avons utilis&#233;e est le lexique Lefff (Sagot, 2010)5. Nous avons
extrait du Lefff 502 223 entr&#233;es distinctes de la forme (forme, &#233;tiquette), les &#233;tiquettes correspondant apr&#232;s
conversion au jeu de 29 &#233;tiquettes de la variante du FTB d&#233;crite ci-dessus et utilis&#233;e pour l&#8217;apprentissage.
</p>
<p>3 &#201;tiquetage avec un mod&#232;le &#224; maximisation d&#8217;entropie
</p>
<p>Dans cette section, nous d&#233;crivons le mod&#232;le markovien &#224; maximisation d&#8217;entropie (MMME) sur lequel
repose l&#8217;&#233;tiqueteur MEltfr. Nous pr&#233;sentons d&#8217;abord la variante MEltnolexfr , qui n&#8217;exploite pas les informa-
tions lexicales du Lefff . Il est comparable aux syst&#232;mes de Ratnaparkhi (1996) et Toutanova &amp; Manning
(2000), &#224; la fois quant au mod&#232;le et quant aux traits utilis&#233;s. Aujourd&#8217;hui, les &#233;tiqueteurs reposant sur
ce type de mod&#232;les sont parmi les meilleurs pour l&#8217;anglais.6 Un avantage important de ces mod&#232;les (sur
les mod&#232;les de Markov cach&#233;s, notamment) est de permettre de combiner ensemble des traits tr&#232;s divers,
&#233;ventuellement redondants, sans qu&#8217;il soit n&#233;cessaire de faire une hypoth&#232;se d&#8217;ind&#233;pendance entre eux.
C&#8217;est ce qui nous a permis de construire MEltfr en rajoutant &#224; MEltnolexfr des traits lexicaux extraits du
Lefff . Enfin, ces mod&#232;les sont &#233;galement attrayants du fait qu&#8217;ils sont tr&#232;s rapides &#224; entra&#238;ner7.
</p>
<p>3.1 Le mod&#232;le de base
</p>
<p>&#201;tant donn&#233; un jeu d&#8217;&#233;tiquettes T et une cha&#238;ne de mots (tokens) wn1 , on d&#233;finit la t&#226;che d&#8217;&#233;tiquetage
comme le processus consistant &#224; assigner &#224; wn1 la s&#233;quence d&#8217;&#233;tiquettes t&#770;
</p>
<p>n
1 &#8712; T n de vraisemblance maxi-
</p>
<p>male. Suivant (Ratnaparkhi, 1996), on peut alors approcher la probabilit&#233; conditionnelle P (tn1 |wn1 ) de sorte
que :
</p>
<p>t&#770;n1 = arg max
tn1&#8712;Tn
</p>
<p>P (tn1 |wn1 ) &#8776; arg max
tn1&#8712;Tn
</p>
<p>n&#8719;
i=1
</p>
<p>P (ti|hi), (1)
</p>
<p>o&#249; ti est l&#8217;&#233;tiquette du mot wi et hi est le contexte de (wi, ti), qui comprend la s&#233;quence des &#233;tiquettes d&#233;j&#224;
assign&#233;es ti&#8722;11 et la s&#233;quence des mots wn1 .
</p>
<p>4Il s&#8217;agit des tokens inconnus &#224; la fois sous leur forme d&#8217;origine et sous leur forme minusculis&#233;e.
5Le Lefff est librement distribu&#233; sous licence LGPL-LR &#224; l&#8217;adresse http://alexina.gforge.inria.fr/.
6(Ratnaparkhi, 1996) et (Toutanova &amp; Manning, 2000) obtiennent des pr&#233;cisions respectives de 96.43 et 96.86 sur les
</p>
<p>sections 23 et 24 du Penn Treebank.
7Les Champs Al&#233;atoires Conditionnels (Conditional Random Fields, CRF) sont souvent consid&#233;r&#233;s comme plus adapt&#233;s
</p>
<p>aux probl&#232;mes de pr&#233;diction s&#233;quentielle et structur&#233;e (Lafferty et al., 2001), mais ils sont aussi nettement plus lents en temps
d&#8217;entra&#238;nement.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PASCAL DENIS &amp; BENO&#206;T SAGOT
</p>
<p>Dans un mod&#232;le &#224; maximisation d&#8217;entropie, on estime les param&#232;tres d&#8217;un mod&#232;le exponentiel qui a la
forme suivante :
</p>
<p>P (ti|hi) = 1
Z(h)
</p>
<p>&#183; exp
&#63723;&#63725; m&#8721;
</p>
<p>i=j
</p>
<p>&#955;jfj(hi, ti)
</p>
<p>&#63734;&#63736; (2)
Les fm1 sont des traits, fonctions d&#233;finies sur l&#8217;ensemble des &#233;tiquettes ti et des historiques hi (avec
f(hi, ti) &#8712; {0, 1}), les &#955;m1 sont les param&#232;tres associ&#233;s aux fm1 , et Z(h) est un facteur de normalisation sur
les diff&#233;rentes &#233;tiquettes. Dans ce type de mod&#232;le, le choix des param&#232;tres est assujetti &#224; des contraintes
garantissant que l&#8217;esp&#233;rance de chaque trait soit &#233;gale &#224; son esp&#233;rance empirique telle que mesur&#233;e sur
le corpus d&#8217;apprentissage (Berger et al., 1996). Dans nos exp&#233;riences, les param&#232;tres ont &#233;t&#233; estim&#233;s en
utilisant l&#8217;algorithme dit Limited Memory Variable Metric Algorithm (Malouf, 2002) impl&#233;ment&#233; au sein
du syst&#232;me Megam8 (Daum&#233; III, 2004).
</p>
<p>Les classes de traits que nous avons utilis&#233;es pour la conception du mod&#232;le de base MEltnolexfr d&#8217;&#233;tiquetage
du fran&#231;ais, c&#8217;est-&#224;-dire du mod&#232;le n&#8217;utilisant pas le lexique Lefff , est un sur-ensemble des traits utilis&#233; par
(Ratnaparkhi, 1996) et (Toutanova &amp; Manning, 2000) pour l&#8217;anglais (qui &#233;taient largement ind&#233;pendants
de la langue). Ces traits peuvent &#234;tre regroup&#233;s en deux sous-ensembles. Le premier rassemble des traits
dits internes qui essaient de capturer les caract&#233;ristiques du mot &#224; &#233;tiqueter. Il s&#8217;agit notamment du mot
wi lui-m&#234;me, de ses pr&#233;fixes et suffixes de longueur 1 &#224; 4, ainsi que de traits bool&#233;ens qui testent si wi
contient ou non certains caract&#232;res particuliers comme les chiffres, le tiret ou les majuscules. Le deuxi&#232;me
ensemble de traits, dits externes, mod&#233;lise le contexte du mot &#224; &#233;tiqueter. Il s&#8217;agit tout d&#8217;abord des mots
qui sont dans les contextes gauche et droit de wi (&#224; une distance d&#8217;au plus 2). Ensuite, nous int&#233;grons
comme traits l&#8217;&#233;tiquette ti&#8722;1 assign&#233;e au mot pr&#233;c&#233;dent, ainsi que la concat&#233;nation des &#233;tiquettes ti&#8722;1 et
ti&#8722;2 pour les deux mots pr&#233;c&#233;dents wi. La liste d&#233;taill&#233;e des classes de traits utilis&#233;es dans MEltnolexfr est
indiqu&#233;e &#224; la table 2.
</p>
<p>Traits internes
wi = X &amp; ti = T
Pr&#233;fixe de wi = P, |P | &lt; 5 &amp; ti = T
Suffixe de wi = S, |S| &lt; 5 &amp; ti = T
wi contient un nombre &amp; ti = T
wi contient un tiret &amp; ti = T
wi contient une majuscule &amp; ti = T
wi contient uniquement des majuscules &amp; ti = T
wi contient une majuscule et n&#8217;est pas le premier mot d&#8217;une phrase &amp; ti = T
Traits externes
ti&#8722;1 = X &amp; ti = T
ti&#8722;2ti&#8722;1 = XY &amp; ti = T
wi+j = X, j &#8712; {&#8722;2,&#8722;1, 1, 2} &amp; ti = T
</p>
<p>TAB. 2 &#8211; Traits de base utilis&#233;s par MEltnolexfr
</p>
<p>Une diff&#233;rence importante avec le jeu de traits de (Ratnaparkhi, 1996) vient du fait que nous n&#8217;avons
pas restreint l&#8217;application des traits de type pr&#233;fixes et suffixes aux mots qui sont rares dans le corpus
d&#8217;apprentissage. Dans notre mod&#232;le, ces traits sont toujours construits, m&#234;me pour les mots fr&#233;quents.
En effet, nous avons constat&#233; lors du d&#233;veloppement que la prise en compte syst&#233;matique de ces traits
conduit &#224; de meilleurs r&#233;sultats, notamment sur les mots inconnus. De plus, ces traits sont probablement
</p>
<p>8Librement disponible &#224; l&#8217;adresse http://www.cs.utah.edu/~hal/megam/.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UN &#201;TIQUETEUR MORPHOSYNTAXIQUE &#201;TAT-DE-L&#8217;ART DU FRAN&#199;AIS
</p>
<p>plus discriminants sur le fran&#231;ais que sur l&#8217;anglais, puisque le fran&#231;ais est morphologiquement plus riche.
Une autre diff&#233;rence entre notre mod&#232;le de base et les travaux ant&#233;rieurs concerne le lissage. (Ratnaparkhi,
1996) et (Toutanova &amp; Manning, 2000) seuillent leurs traits &#224; un nombre d&#8217;occurrence de 10 pour &#233;viter
les donn&#233;es statistiquement non significatives. Nous n&#8217;avons pas seuill&#233; nos traits mais avons utilis&#233; &#224;
la place une r&#233;gularisation gaussienne sur les poids, ce qui est une technique de lissage plus motiv&#233;e
statistiquement.
</p>
<p>3.2 Int&#233;gration des informations lexicales dans l&#8217;&#233;tiqueteur
</p>
<p>L&#8217;avantage du mod&#232;le sous-jacent &#224; MEltnolexfr est de permettre un ajout ais&#233; de traits suppl&#233;mentaires, y
compris de traits dont les valeurs sont calcul&#233;es &#224; partir d&#8217;une ressource externe au corpus d&#8217;apprentissage,
et notamment d&#8217;un lexique comme le Lefff .
</p>
<p>Pour chaque mot wi, nous g&#233;n&#233;rons une nouvelle s&#233;rie de traits internes bas&#233;s sur la pr&#233;sence (ou non)
de wi dans le Lefff et, le cas &#233;ch&#233;ant, les &#233;tiquettes associ&#233;es &#224; wi par le Lefff . Si wi est associ&#233; &#224; une
&#233;tiquette unique ti, nous g&#233;n&#233;rons un trait qui encode l&#8217;association non ambigu&#235; entre wi et ti,0. Lorsque
wi est associ&#233; &#224; plusieurs &#233;tiquettes ti,0, . . . , ti,m par le Lefff , nous g&#233;n&#233;rons un trait interne pour chacune
de ses &#233;tiquettes possibles ti,j , ainsi qu&#8217;un trait interne qui repr&#233;sente la disjonction dem &#233;tiquettes. Enfin,
si wi n&#8217;est pas recens&#233; dans le Lefff , nous cr&#233;ons un trait sp&#233;cifique qui encode le statut d&#8217;inconnu du
Lefff .9
</p>
<p>De m&#234;me, nous utilisons le Lefff pour construire de nouveaux traits externes : nous construisons l&#8217;&#233;qui-
valent des traits internes pour les mots des contextes gauche et droit &#224; une distance de moins de 2 du mot
courant. Nous g&#233;n&#233;rons &#233;galement des traits bigrammes correspondant &#224; la concat&#233;nation des &#233;tiquettes
du Lefff pour les 2 mots &#224; gauche, les 2 mots &#224; droite, et les deux mots qui entourent wi. Lorsque ces
mots sont ambigus pour le Lefff , seule leur disjonction contribue au bigramme, et si l&#8217;un ce ces mots est
inconnu, la valeur unk tient lieu d&#8217;&#233;tiquette.10
</p>
<p>La liste d&#233;taill&#233;e des classes de traits utilis&#233;es pour MEltfr, en plus de ceux de la table 2, est indiqu&#233;e &#224; la
table 3. Ce jeu de traits &#233;tend l&#233;g&#232;rement celui pr&#233;sent&#233; par (Denis &amp; Sagot, 2009).
</p>
<p>Traits lexicaux internes
ti =uni X , if lefff(wi) = {X} &amp; ti = T
ti = X , &#8704;X &#8712; lefff(wi) if |lefff(wi)| &gt; 1 &amp; ti = T
ti =
</p>
<p>&#8744;
lefff(wi) if |lefff(wi)| &gt; 1 &amp; ti = T
</p>
<p>ti = unk, if lefff(wi) = &#8709; &amp; ti = T
Traits lexicaux externes
ti+j =
</p>
<p>&#8744;
lefff(wi+1), j &#8712; {&#8722;2,&#8722;1, 1, 2} &amp; ti = T
</p>
<p>ti+jti+k =
&#8744;
</p>
<p>lefff(wi+j)
&#8744;
</p>
<p>lefff(wi+k), (j, k) &#8712; {(&#8722;2,&#8722;1), (+1,+2), (&#8722;1,+1)} &amp; ti = T
TAB. 3 &#8211; Traits lexicaux ajout&#233;s au mod&#232;le de base dans MEltfr
</p>
<p>Ces diff&#233;rents traits permettent d&#8217;avoir une information, ne serait-ce qu&#8217;ambigu&#235;, sur les &#233;tiquettes dans le
contexte droit du mot, ce que ne permettent pas les traits de base utilis&#233;s par MEltnolexfr . Ceux-ci n&#8217;incluent
</p>
<p>9Pour les mots qui apparaissent en position initiale dans la phrase, nous v&#233;rifions au pr&#233;lalable que la version d&#233;capitalis&#233;e
du mot n&#8217;est pas pr&#233;sente non plus dans le Lefff .
</p>
<p>10Diff&#233;rentes valeurs de &#171; fen&#234;tre &#187; ont &#233;t&#233; essay&#233;es lors de la phase de d&#233;veloppement : 1, 2 et 3. Bien que le passage de 1 &#224;
2 m&#232;ne &#224; une am&#233;lioration significative, le passage de 2 &#224; 3 m&#232;ne &#224; une l&#233;g&#232;re d&#233;gradation.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PASCAL DENIS &amp; BENO&#206;T SAGOT
</p>
<p>que les &#233;tiquettes sur le contexte gauche, les seules &#224; pouvoir &#234;tre int&#233;gr&#233;es dans un d&#233;codage gauche-
droite. Par ailleurs, cette mani&#232;re d&#8217;int&#233;grer les informations issues du lexique au mod&#232;le sous forme
de traits suppl&#233;mentaires a l&#8217;avantage de ne pas ajouter de contraintes fortes, et d&#8217;&#234;tre ainsi robuste &#224;
d&#8217;&#233;ventuelles erreurs ou incompl&#233;tudes du lexique.
</p>
<p>Une autre fa&#231;on, plus directe, d&#8217;exploiter une ressource lexicale exog&#232;ne consiste en effet &#224; utiliser les in-
formations lexicales comme filtre. A savoir, on contraint l&#8217;&#233;tiqueteur &#224; choisir pour un mot w une &#233;tiquette
correspondant soit &#224; une occurrence de w dans le corpus, soit &#224; une entr&#233;e du lexique pour w. C&#8217;est l&#8217;ap-
proche employ&#233;e par exemple par (Hajic&#780;, 2000) pour des langues &#224; morphologie tr&#232;s riche, et notamment
pour le tch&#232;que. Dans (Denis &amp; Sagot, 2009), nous avons montr&#233; que cette strat&#233;gie ne permet d&#8217;am&#233;liorer
que marginalement les performances de MEltnolexfr , et restent largement en-de&#231;&#224; de celles de MEltfr.
</p>
<p>3.3 D&#233;codage
</p>
<p>La proc&#233;dure de d&#233;codage (c&#8217;est-&#224;-dire l&#8217;&#233;tiquetage proprement dit une fois le mod&#232;le construit) repose
sur un algorithme de type beam search pour trouver la s&#233;quence d&#8217;&#233;tiquettes la plus probable pour une
phrase donn&#233;e. Autrement dit, chaque phrase est d&#233;cod&#233;e de gauche &#224; droite, et l&#8217;on conserve pour chaque
mot wi les n s&#233;quences d&#8217;&#233;tiquettes candidates les plus probables du d&#233;but de la phrase jusqu&#8217;&#224; la position
i. Pour nos exp&#233;riences, nous avons utilis&#233; un beam de taille 311. De plus, la proc&#233;dure de test utilise un
dictionnaire d&#8217;&#233;tiquettes) qui liste pour chaque mot les &#233;tiquettes qui lui sont associ&#233;es dans le corpus
d&#8217;apprentissage. Ceci r&#233;duit consid&#233;rablement l&#8217;ensemble des &#233;tiquettes parmi lesquelles l&#8217;&#233;tiqueteur peut
choisir pour &#233;tiqueter un mot donn&#233;, ce qui conduit, comme le montrent nos exp&#233;riences, &#224; de meilleures
performances tant en termes de pr&#233;cision que d&#8217;efficacit&#233; en temps.
</p>
<p>3.4 Comparaisons avec d&#8217;autres syst&#232;mes
</p>
<p>Nous avons compar&#233; les r&#233;sultats de MEltnolexfr et de MEltfr &#224; divers autres &#233;tiqueteurs, dont les deux
premiers n&#8217;utilisent pas le Lefff , mais qui ont tous &#233;t&#233; (r&#233;)entra&#238;n&#233;s d&#8217;une fa&#231;on ou d&#8217;une autre sur le
corpus d&#8217;apprentissage du FTB :
&#8211; UNIGRAM, un &#233;tiqueteur de base qui fonctionne comme suit : pour un mot pr&#233;sent dans le corpus
d&#8217;entra&#238;nement, l&#8217;&#233;tiqueteur assigne l&#8217;&#233;tiquette la plus fr&#233;quemment trouv&#233;e dans le corpus ; pour les
autres mots, il utilise l&#8217;&#233;tiquette la plus fr&#233;quente du corpus (ici, NC) ;
</p>
<p>&#8211; TreeTagger, un &#233;tiqueteur statistique12 qui repose sur les arbres de d&#233;cision (Schmid, 1994) r&#233;entra&#238;n&#233;
sur notre corpus d&#8217;apprentissage.
</p>
<p>&#8211; UNIGRAMLefff , comme UNIGRAM, est un mod&#232;le unigramme qui repose sur le corpus d&#8217;apprentissage,
mais qui utilise le Lefff pour &#233;tiqueter les mots inconnus : parmi les &#233;tiquettes que le Lefff associe &#224; un
mot inconnu du corpus, l&#8217;&#233;tiquette la plus fr&#233;quente &#224; l&#8217;&#233;chelle de tout le corpus est utilis&#233;e ; les mots
qui sont inconnus et du corpus et du Lefff re&#231;oivent l&#8217;&#233;tiquette la plus fr&#233;quente (ici, NC) ;
</p>
<p>&#8211; TreeTaggerLefff est une variante de TreeTagger, le Lefff &#233;tant fourni comme lexique externe ;
&#8211; F-BKY, une instance de l&#8217;analyseur syntaxique de Berkeley tel qu&#8217;adapt&#233; au fran&#231;ais par Crabb&#233; &amp;
Candito (2008), et utilis&#233;e comme &#233;tiqueteur.
</p>
<p>11Nous avons essay&#233; d&#8217;autres valeurs (5, 10, 20) pendant le d&#233;veloppement, mais ces valeurs n&#8217;ont pas conduit &#224; des variations
significatives de performance.
</p>
<p>12Disponible sur http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UN &#201;TIQUETEUR MORPHOSYNTAXIQUE &#201;TAT-DE-L&#8217;ART DU FRAN&#199;AIS
</p>
<p>Les r&#233;sultats de cette compraison sur le corpus de test du FTB font l&#8217;objet du tableau 4.
</p>
<p>&#201;tiqueteur Pr&#233;cision globale (%) Pr&#233;cision sur les mots inconnus (%)
UNIGRAM 91, 90 24, 50
TreeTagger 96, 14 75, 77
UNIGRAMLefff 93, 40 55, 00
TreeTaggerLefff 96, 55 82, 14
F-BKY 97, 25 82, 90
MEltnolexfr 97, 25 86, 47
MEltfr 97,75 91,36
</p>
<p>TAB. 4 &#8211; Comparaison des performances de divers &#233;tiqueteurs en partie du discours pour le fran&#231;ais
</p>
<p>Parmi les &#233;tiqueteurs ne faisant pas usage du Lefff , on constate que MEltnolexfr atteint d&#233;j&#224; une pr&#233;cision
de 97, 25%, avec 86.47% sur les mots inconnus. Ceci est significativement meilleur que TreeTagger, avec
un gain de plus de 10% sur les mots inconnus13. On peut avancer plusieurs hypoth&#232;ses pour expliquer
des &#233;carts si importants sur l&#8217;&#233;tiquetage des mots inconnus. Tout d&#8217;abord, l&#8217;estimation des param&#232;tres
dans un mod&#232;le &#224; maximisation d&#8217;entropie est moins sujette au probl&#232;me du manque de donn&#233;es pour
certains traits ou certaines valeurs de traits que d&#8217;autres approches comme les arbres de d&#233;cision (utilis&#233;s
par TreeTagger), notamment parce qu&#8217;aucune partition des donn&#233;es d&#8217;entra&#238;nement n&#8217;est effectu&#233;e. Par
ailleurs, TreeTagger n&#8217;est pas en mesure de faire autant de g&#233;n&#233;ralisations que MEltnolexfr sur les traits
internes, puisqu&#8217;il ne prend en compte que les suffixes, et ce, uniquement sur les mots inconnus.
</p>
<p>Parmi les &#233;tiqueteurs faisant usage du Lefff , le meilleur d&#8217;entre eux est MEltfr, avec une exactitude de
97, 75% globalement et 91, 36% sur les mots inconnus. Ces deux r&#233;sultats constituent des am&#233;liorations
significatives de 0, 5% et 4, 89% par rapport au mod&#232;le sans Lefff . Ces scores sont meilleurs que ceux
de tous les &#233;tiqueteurs que nous avons pu tester, y compris l&#8217;analyseur F-BKY qui exploite des r&#233;sultats
d&#8217;analyse syntaxique probabiliste, et ce, avec un &#233;cart significatif14.
</p>
<p>D&#8217;autres &#233;tiqueteurs ont &#233;t&#233; propos&#233;s pour le fran&#231;ais, notamment lors de la campagne d&#8217;&#233;valuation
GRACE15. Bien qu&#8217;une comparaison directe soit difficile, &#233;tant donn&#233; la diff&#233;rence de corpus d&#8217;&#233;valua-
tion et de jeux d&#8217;&#233;tiquettes, notons que le meilleurs r&#233;sultats report&#233;s lors de cette campagne sont de 96%
(Adda et al., 1999) et qu&#8217;ils ont &#233;t&#233; obtenus par des analyseurs syntaxiques. Notons par ailleurs que (Nasr
&amp; Volanschi, 2004) reporte des scores de 97.82 sur le corpus de Paris 7, mais leur &#233;tiqueteur/chunker ne
prend pas en compte les mots inconnus.
</p>
<p>Une analyse d&#233;taill&#233;e des causes d&#8217;erreurs de MEltfr (Denis &amp; Sagot, 2009) peut &#234;tre r&#233;sum&#233;e ainsi :
43, 5% des erreurs sont des erreurs classiques (dont 4% d&#8217;erreurs sur de, du et des, et 5, 5% de confusions
entre adjectifs et participes pass&#233;s), 15, 5% des erreurs concernent des nombres, 27, 5% des erreurs sont
li&#233;es &#224; des entit&#233;s nomm&#233;es, et 13, 5% des erreurs n&#8217;en sont pas vraiment, soit que le corpus de r&#233;f&#233;rence
contient lui-m&#234;me une erreur (9% des cas), soit que l&#8217;&#233;tiquette de r&#233;f&#233;rence et l&#8217;&#233;tiquette propos&#233;e par
MEltfr semblent toutes deux correctes (4, 5% des cas).
</p>
<p>13Des tests de significativit&#233; statistique (tests du &#967;2) ont &#233;t&#233; appliqu&#233;s aux &#233;carts de pr&#233;cision, avec un param&#232;tre p &#224; 0, 01.
14Une adaptation au fran&#231;ais de Morfette (Chrupa&#322;a et al., 2008) utilisant le FTB et le Lefff a &#233;t&#233; r&#233;alis&#233;e par G. Chrupa&#322;a
</p>
<p>et D. Seddah (c.p.). Leur pr&#233;cision est comparable &#224; celle de MEltfr (sur les m&#234;mes jeux de donn&#233;es, Henestroza et Candito
(c.p.) ont obtenu 97, 68%). Sur d&#8217;autres variantes du FTB (tokenisation d&#8217;origine), Chrupa&#322;a et Seddah (c.p.) obtiennent 97, 9%.
Ces comparaisons sont &#224; nuancer dans la mesure o&#249; des informations suppl&#233;mentaires (les lemmes) sont extraites des corpus
d&#8217;apprentissage et prises en compte dans ce mod&#232;le.
</p>
<p>15http://www.limsi.fr/TLP/grace/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PASCAL DENIS &amp; BENO&#206;T SAGOT
</p>
<p>Nous avons cherch&#233; &#224; comprendre au mieux la fa&#231;on dont les informations extraites du Lefff permettent
d&#8217;am&#233;liorer les r&#233;sultats. Pour cela, nous avons men&#233; un certain nombre d&#8217;exp&#233;riences, notamment en
faisant varier les jeux de traits et d&#8217;&#233;tiquettes.
</p>
<p>4 Impact de diff&#233;rents jeux de traits extraits du Lefff
</p>
<p>En vue de mieux comprendre l&#8217;impact des informations extraites du Lefff sur notre mod&#232;le, nous nous
sommes livr&#233;s &#224; plusieurs exp&#233;riences d&#8217;ablation sur les traits d&#233;crits dans le tableau 3. Plus sp&#233;cifique-
ment, nous avons &#233;valu&#233; les 8 configurations possibles qui consistent &#224; inclure (ou non) les traits lexicaux
internes (INT), les traits lexicaux externes d&#233;finis sur le contexte gauche (LEFT) et les traits lexicaux ex-
ternes d&#233;finis sur le contexte droit (RIGHT). Les r&#233;sultats de ces diff&#233;rentes exp&#233;riences men&#233;es sur le
corpus de d&#233;veloppement FTB-DEV sont repris dans le tableau 5. Notons que les configurations les plus
extr&#234;mes, &#8709; et INT+LEFT+RIGHT, correspondent respectivement aux syst&#232;mes MEltnolexfr et MEltfr.
</p>
<p>Traits Lefff Pr&#233;cision globale (%) Pr&#233;cision sur les mots inconnus (%)
&#8709; (MEltnolexfr ) 96, 54 83, 95
INT 97, 04 91, 4
LEFT 96, 38 85, 36
RIGHT 96, 39 86, 48
INT+LEFT 96, 92 91, 28
INT+RIGHT 97, 30 92, 01
LEFT+RIGHT 96, 57 86, 93
INT+LEFT+RIGHT (MEltfr) 97, 41 92, 35
</p>
<p>TAB. 5 &#8211; Comparaison des performances de MEltfr avec diff&#233;rents sous-ensembles de traits sur FTB-DEV
</p>
<p>Ces r&#233;sultats indiquent que c&#8217;est la combinaison des traits internes et des traits sur le contexte droit qui
apporte le plus d&#8217;informations &#224; l&#8217;&#233;tiqueteur. Le sous-ensemble INT+RIGHT donne en effet les meilleurs
scores apr&#232;s MEltfr lui-m&#234;me, aussi bien sur l&#8217;ensemble des mots que sur les mots inconnus seuls. Ces
deux sous-ensembles sont compl&#233;mentaires : les traits INT permettent d&#8217;am&#233;liorer la couverture lexicale
de l&#8217;&#233;tiqueteur (certains mots inconnus, c&#8217;est-&#224;-dire absents du corpus d&#8217;entra&#238;nement, sont couverts par
le lexique), alors que les traits RIGHT fournissent des informations importantes sur le contexte droit que
les traits de MEltnolexfr ne mod&#233;lisent que frustement.
</p>
<p>5 Impact de diff&#233;rents jeux d&#8217;&#233;tiquettes
</p>
<p>Ind&#233;pendamment des exp&#233;riences pr&#233;sent&#233;es &#224; la section pr&#233;c&#233;dente, nous avons entra&#238;n&#233; diff&#233;rentes ver-
sions de MEltfr en faisant varier &#224; chaque fois le jeu d&#8217;&#233;tiquettes utilis&#233; par le lexique et par le corpus
d&#8217;apprentissage. Rappelons en effet que ces deux jeux d&#8217;&#233;tiquettes n&#8217;ont aucunement besoin d&#8217;&#234;tre iden-
tiques, les traits lexicaux permettant d&#8217;int&#233;grer les informations issues du lexique quels que soient les deux
jeux d&#8217;&#233;tiquettes utilis&#233;s. La comparaison entre ces diff&#233;rentes variantes de MEltfr est utile &#224; deux points
de vue au moins. Tout d&#8217;abord, elle permet de donner une id&#233;e des performances de MEltfr avec diff&#233;rents
jeux de param&#232;tres. Certaines t&#226;ches de traitement automatique ou d&#8217;extraction d&#8217;informations n&#8217;ont peut-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UN &#201;TIQUETEUR MORPHOSYNTAXIQUE &#201;TAT-DE-L&#8217;ART DU FRAN&#199;AIS
</p>
<p>&#234;tre pas besoin de la granularit&#233; de notre jeu d&#8217;&#233;tiquettes d&#8217;origine. Par ailleurs, ces exp&#233;riences permettent
d&#8217;aborder par un autre angle l&#8217;analyse de l&#8217;impact des informations lexicales sur les performances.
</p>
<p>Nous avons donc utilis&#233; diff&#233;rentes variantes du jeu d&#8217;&#233;tiquettes, qui sont les suivantes :
</p>
<p>29 le jeu de d&#233;part (cf. section 2) ;
</p>
<p>15 les cat&#233;gories principales du FTB (cf. section 2) ;
</p>
<p>open le m&#234;me que 15, o&#249; toutes les classes ferm&#233;es (autres que NC, NPP, ADJ, ADV et V) sont regroup&#233;es
en une seule classe CLOSED ;
</p>
<p>gram le m&#234;me que 15, o&#249; toutes les classes ouvertes sont regroup&#233;es en une seule classe LEX.
</p>
<p>Jeu d&#8217;&#233;tiquettes Jeu d&#8217;&#233;tiquettes du lexique
du corpus pas de Lefff gram open 15 29
gram 96,74% 98,55% 98,82% 98,81% 98,76%
open 97,29% 97,88% 98,12% 98,19% 98,25%
15 96,86% 97,15% 97,75% 97,87% 97,87%
29 96,54% 96,63% 97,04% 97,29% 97,41%
</p>
<p>TAB. 6 &#8211; Comparaison des performances de MEltfr sur FTB-DEV avec divers jeux d&#8217;&#233;tiquettes. L&#8217;&#233;tique-
tage et donc l&#8217;&#233;valuation se font sur le jeu d&#8217;&#233;tiquettes du corpus.
</p>
<p>Ces r&#233;sultats permettent de tirer quelques enseignements g&#233;n&#233;raux :
&#8211; comme attendu, plus le jeu d&#8217;&#233;tiquettes sur lequel on s&#8217;&#233;value est riche, plus les r&#233;sultats se d&#233;gradent ;
une exception toutefois : d&#232;s lors que l&#8217;on utilise une des variantes du Lefff , &#233;tiqueter les 10 classes
ferm&#233;es est plus facile qu&#8217;&#233;tiqueter les 5 classes ouvertes ;
</p>
<p>&#8211; en g&#233;n&#233;ral, les informations du Lefff sont d&#8217;une aide d&#8217;autant plus grande que les &#233;tiquettes qui en sont
extraites sont riches ;
</p>
<p>&#8211; les informations lexicales semblent plus am&#233;liorer l&#8217;&#233;tiquetage des classes ferm&#233;es que celui des classes
ouvertes ; nous soup&#231;onnons que ceci s&#8217;explique par l&#8217;ambigu&#239;t&#233; des mots grammaticaux et le fait qu&#8217;ils
soient difficiles &#224; &#233;tiqueter sans aucune information lexicale sp&#233;cifique.
</p>
<p>6 Conclusions et perspectives
</p>
<p>Nous avons pr&#233;sent&#233; un &#233;tiqueteur morpho-syntaxique hybride du fran&#231;ais, MEltfr, qui a des performances
&#233;tat-de-l&#8217;art. Il a pour particularit&#233; de chercher &#224; exploiter au mieux des informations extraites d&#8217;un lexique
exog&#232;ne non probabilis&#233;, le Lefff , en plus de celles extraites d&#8217;un corpus d&#8217;apprentissage extrait du FTB.
Nous avons essay&#233; de comprendre au mieux de quelle fa&#231;on ces informations lexicales contribuent au gain
de performance observ&#233; entre MEltfr et sa contrepartie MEltnolexfr qui n&#8217;utilise pas le Lefff .
</p>
<p>Les perspectives de ce travail sont nombreuses. Tout d&#8217;abord, des travaux pr&#233;liminaires ont &#233;t&#233; men&#233;s qui
montrent la pertinence du mod&#232;le sous-jacent &#224; MEltfr sur d&#8217;autres langues que le fran&#231;ais, en particulier si
une ressource lexicale comparable au Lefff est disponible. Ensuite, des informations suppl&#233;mentaires pour-
raient &#234;tre extraites du Lefff , qui sont susceptibles d&#8217;am&#233;liorer les performances. Ainsi, des informations
de sous-cat&#233;gorisation verbale, disponibles dans le Lefff , pourraient par exemple am&#233;liorer l&#8217;&#233;tiquetage
d&#8217;un mot tel que de, ambigu entre d&#8217;une part, une pr&#233;position qui introduit parfois un argument de type
objet indirect et d&#8217;autre part, un d&#233;terminant partitif qui d&#233;bute parfois un argument de type objet direct.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PASCAL DENIS &amp; BENO&#206;T SAGOT
</p>
<p>Enfin, nous souhaitons permettre &#224; MEltfr de prendre en entr&#233;e pas seulement une s&#233;quence de mots mais
plus g&#233;n&#233;ralement un graphe de formes, afin de permettre d&#8217;utiliser MEltfr pour lever des ambigu&#239;t&#233;s de
segmentation, voire de correction orthographique, en plus de fournir une annotation en parties du discours.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ABEILL&#201; A., CL&#201;MENT L. &amp; TOUSSENEL F. (2003). Building a treebank for French. In A. ABEILL&#201;,
Ed., Treebanks. Kluwer, Dordrecht.
</p>
<p>ADDA G., MARIANI J., PAROUBEK P., RAJMAN M. &amp; LECOMTE J. (1999). M&#233;trique et premiers
r&#233;sultats de l&#8217;&#233;valuation grace des &#233;tiqueteurs morphosyntaxiques pour le fran&#231;ais. In TALN.
</p>
<p>BERGER A., PIETRA S. D. &amp; PIETRA V. D. (1996). A maximum entropy approach to natural language
processing. Computational Linguistics, 22(1), 39&#8211;71.
CHRUPA&#321;A G., DINU G. &amp; VAN GENABITH J. (2008). Learning morphology with morfette. In Procee-
dings of the 6th Language Resource and Evaluation Conference, Marrakech, Maroc.
</p>
<p>CRABB&#201; B. &amp; CANDITO M. (2008). Exp&#233;riences d&#8217;analyses syntaxique statistique du fran&#231;ais. In
Proceedings of TALN&#8217;08, Avignon, France.
</p>
<p>DAUM&#201; III H. (2004). Notes on CG and LM-BFGS optimization of logistic regression. Paper available
at http://pub.hal3.name#daume04cg-bfgs, implementation available at http://hal3.
name/megam/.
</p>
<p>DENIS P. &amp; SAGOT B. (2009). Coupling an annotated corpus and a morphosyntactic lexicon for state-
of-the-art POS tagging with less human effort. In Proceedings of PACLIC 2009, Hong Kong.
</p>
<p>HAJIC&#780; J. (2000). Morphological Tagging : Data vs. Dictionaries. In Proceedings of ANLP&#8217;00, p. 94&#8211;101,
Seattle, WA, USA.
</p>
<p>LAFFERTY J. D., MCCALLUM A. &amp; PEREIRA F. C. N. (2001). Conditional random fields : Probabilistic
models for segmenting and labeling sequence data. In ICML, p. 282&#8211;289.
</p>
<p>MALOUF R. (2002). A comparison of algorithms for maximum entropy parameter estimation. In Pro-
ceedings of the Sixth Workshop on Natural Language Learning, p. 49&#8211;55, Taipei, Taiwan.
</p>
<p>MANNING C. D. &amp; SCH&#220;TZE H. (1999). Foundations of Statistical Natural Language Processing.
Cambridge, MA : MIT Press.
</p>
<p>NASR A. &amp; VOLANSCHI A. (2004). Couplage d&#8217;un &#233;tiqueteur morpho-syntaxique et d&#8217;un analyseur
partiel repr&#233;sent&#233;s sous la forme d&#8217;automates finis pond&#233;r&#233;s. In TALN.
</p>
<p>RATNAPARKHI A. (1996). A maximum entropy model for part-of-speech tagging. In Proceedings of
International Conference on Empirical Methods in Natural Language Processing, p. 133&#8211;142.
</p>
<p>SAGOT B. (2010). The Lefff , a freely available, accurate and large-coverage lexicon for french. In
Proceedings of the 7th Language Resource and Evaluation Conference, La Valette, Malte. &#224; para&#238;tre.
</p>
<p>SCHMID H. (1994). Probabilistic part-of-speech tagging using decision trees. In Proceedings of Inter-
national Conference on New Methods in Language Processing, Manchester, UK.
</p>
<p>TOUTANOVA K. &amp; MANNING C. D. (2000). Enriching the knowledge sources used in a maximum
entropy part-of-speech tagger. In Proceedings of International Conference on New Methods in Language
Processing, p. 63&#8211;70, Hong Kong.</p>

</div></div>
</body></html>