<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Similarit&#233; s&#233;mantique et extraction de synonymes &#224; partir de corpus</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>Similarit&#233; s&#233;mantique et extraction de synonymes &#224; partir de corpus
</p>
<p>Olivier Ferret
CEA, LIST, Laboratoire Vision et Ing&#233;nierie des Contenus,
</p>
<p>Fontenay-aux-Roses, F-92265 France.
olivier.ferret@cea.fr
</p>
<p>R&#233;sum&#233;. La d&#233;finition de mesures s&#233;mantiques au niveau lexical a fait l&#8217;objet de nombreux travaux
depuis plusieurs ann&#233;es. Dans cet article, nous nous focalisons plus sp&#233;cifiquement sur les mesures de
nature distributionnelle. Bien que diff&#233;rentes &#233;valuations ont &#233;t&#233; r&#233;alis&#233;es les concernant, il reste difficile
&#224; &#233;tablir si une mesure donnant de bons r&#233;sultats dans un cadre d&#8217;&#233;valuation peut &#234;tre appliqu&#233;e plus lar-
gement avec le m&#234;me succ&#232;s. Dans le travail pr&#233;sent&#233;, nous commen&#231;ons par s&#233;lectionner une mesure de
similarit&#233; sur la base d&#8217;un test de type TOEFL &#233;tendu. Nous l&#8217;appliquons ensuite au probl&#232;me de l&#8217;extrac-
tion de synonymes &#224; partir de corpus en comparant nos r&#233;sultats avec ceux de (Curran &amp; Moens, 2002).
Enfin, nous testons l&#8217;int&#233;r&#234;t pour cette t&#226;che d&#8217;extraction de synonymes d&#8217;une m&#233;thode d&#8217;am&#233;lioration de
la qualit&#233; des donn&#233;es distributionnelles propos&#233;e dans (Zhitomirsky-Geffet &amp; Dagan, 2009).
</p>
<p>Abstract. The definition of lexical semantic measures has been the subject of lots of works for many
years. In this article, we focus more specifically on distributional semantic measures. Although several
evaluations about this kind of measures were already achieved, it is still difficult to determine if a measure
that performs well in an evaluation framework can be applied more widely with the same success. In
the work we present here, we first select a similarity measure by testing it against an extended TOEFL
test. Then, we apply this measure for extracting automatically synonyms from a corpus and we compare
our results to those of (Curran &amp; Moens, 2002). Finally, we test the interest for synonym extraction of a
method proposed in (Zhitomirsky-Geffet &amp; Dagan, 2009) for improving the quality of distributional data.
</p>
<p>Mots-cl&#233;s : extraction de synonymes, similarit&#233; s&#233;mantique, m&#233;thodes distributionnelles.
</p>
<p>Keywords: synonym extraction, semantic similarity, distributional methods.
</p>
<p>1 Introduction
</p>
<p>Cet article s&#8217;inscrit dans le champ de la s&#233;mantique lexicale et plus pr&#233;cis&#233;ment de ce que l&#8217;on nomme
&#171; similarit&#233; s&#233;mantique lexicale &#187;. L&#8217;objectif des travaux men&#233;s dans ce domaine de recherche est de d&#233;-
terminer dans quelle mesure deux mots sont proches sur le plan s&#233;mantique et, lorsque leur similarit&#233; est
suffisamment forte, d&#8217;expliciter le type de la relation s&#233;mantique qui les unit. Une partie de ces travaux
(cf. (Zesch &amp; Gurevych, 2010) pour en avoir un panorama) exploitent pour ce faire des sources de connais-
sances plus ou moins structur&#233;es, tels que des dictionnaires. Dans cet article, nous nous focaliserons plus
particuli&#232;rement sur les approches &#224; base de corpus. La plupart d&#8217;entre elles s&#8217;appuient sur l&#8217;hypoth&#232;se
distributionnelle selon laquelle des mots se trouvant dans des contextes similaires tendent &#224; avoir des sens
similaires (Firth, 1957). Dans le prolongement de (Grefenstette, 1994) et de (Lin, 1998), cette hypoth&#232;se</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>OLIVIER FERRET
</p>
<p>est g&#233;n&#233;ralement mise en &#339;uvre en collectant des cooccurrences &#224; partir de corpus de taille importante et
en caract&#233;risant chaque terme T de ces corpus par le vecteur de ses cooccurrents. Ceux-ci sont pond&#233;r&#233;s
en fonction de la force de leur lien avec T. La similarit&#233; s&#233;mantique entre deux termes est &#233;valu&#233;e quant &#224;
elle en calculant une mesure de similarit&#233; entre les vecteurs qui leur sont associ&#233;s. Cette perspective a &#233;t&#233;
adopt&#233;e et explor&#233;e en profondeur par des travaux tels que (Curran &amp; Moens, 2002) ou (Weeds, 2003) en
testant un nombre important de mesures de similarit&#233; et de fonctions de pond&#233;ration des cooccurrents.
</p>
<p>Quelques variantes de ce sch&#233;ma de base ont &#233;t&#233; propos&#233;es, sans n&#233;anmoins sortir du cadre distributionnel.
L&#8217;une d&#8217;elles est de nature probabiliste : chaque terme y est caract&#233;ris&#233; par une distribution de probabilit&#233;
sur ses cooccurrents et la similarit&#233; s&#233;mantique entre deux termes est &#233;valu&#233;e par une distance entre leurs
distributions respectives (Weeds, 2003). L&#8217;utilisation de m&#233;thodes de r&#233;duction de dimensions couvre un
autre ensemble de variantes dans le cadre desquelles la similarit&#233; entre deux termes est &#233;valu&#233;e dans
l&#8217;espace s&#233;mantique issu de la r&#233;duction de dimensions r&#233;alis&#233;e. L&#8217;Analyse S&#233;mantique Latente (Landauer
&amp; Dumais, 1997) et le Random Indexing (Salgren, 2006) sont les principaux repr&#233;sentants de ce courant
auquel peut se rattacher indirectement les vecteurs conceptuels (Schwab et al., 2007).
</p>
<p>Les travaux concernant la similarit&#233; s&#233;mantique lexicale se d&#233;finissent &#233;galement par la fa&#231;on dont ils
&#233;valuent les mesures de similarit&#233; s&#233;mantique qu&#8217;ils proposent. Une mani&#232;re r&#233;pandue de r&#233;aliser cette
&#233;valuation, utilis&#233;e initialement par (Landauer &amp;Dumais, 1997), est d&#8217;appliquer ces mesures aux questions
de synonymie de tests de type TOEFL. Ces questions sont constitu&#233;es d&#8217;un mot cible et de quatre mots
candidats parmi lesquels un synonyme du mot cible doit &#234;tre identifi&#233;. Les syst&#232;mes d&#233;velopp&#233;s ayant
atteint un haut niveau de performance sur les questions issues du TOEFL (Turney et al., 2003), diverses
extensions de cette approche ont &#233;t&#233; explor&#233;es, soit par l&#8217;utilisation de questions issues d&#8217;autres tests
similaires, comme l&#8217;ESL (Moraliyski &amp; Dias, 2007), soit par la construction automatique d&#8217;un ensemble
beaucoup plus large de questions en s&#8217;appuyant sur une ressource de r&#233;f&#233;rence telle que WordNet (Freitag
et al., 2005; Piasecki et al., 2007), soit enfin par l&#8217;extension des questions &#224; des relations de nature plus
large que la synonymie comme les relations d&#8217;analogie pr&#233;sentes dans le test SAT (Turney, 2008).
</p>
<p>Un autre mode commun d&#8217;&#233;valuation des mesures de similarit&#233; s&#233;mantique est la comparaison de leurs
r&#233;sultats &#224; une ressource de r&#233;f&#233;rence. Des jugements humains portant sur la similarit&#233; de couples de
mots sont parfois utilis&#233;s dans cet esprit (Weeds, 2003) mais de tels jugements constituent en pratique
des ressources rares et de petite taille. De ce fait, un mode d&#8217;&#233;valuation plus indirect est g&#233;n&#233;ralement
adopt&#233; (Curran &amp;Moens, 2002; Lin, 1998) : les mesures de similarit&#233; &#224; tester sont appliqu&#233;es pour trouver
les plus proches voisins s&#233;mantiques d&#8217;un mot et la pertinence de ces voisins est &#233;valu&#233;e en les comparant
&#224; un ensemble de synonymes de r&#233;f&#233;rence issus de ressources telles que WordNet ou le th&#233;saurus Roget.
</p>
<p>L&#8217;objectif global du travail que nous pr&#233;sentons ici est d&#8217;extraire des synonymes de noms &#224; partir de corpus
en s&#8217;appuyant sur l&#8217;hypoth&#232;se distributionnelle, ce qui n&#233;cessite en premier lieu de choisir une mesure de
similarit&#233; s&#233;mantique ad&#233;quate. En d&#233;pit du nombre significatif de travaux d&#233;j&#224; r&#233;alis&#233;s dans ce domaine,
comme nous avons pu le voir ci-dessus, il est difficile en pratique de transposer leurs r&#233;sultats &#224; notre
probl&#232;me : beaucoup d&#8217;entre eux ont &#233;t&#233; &#233;valu&#233;s sur des tests de type TOEFL, t&#226;che moins exigeante que
la n&#244;tre, et les comparaisons avec des ressources de r&#233;f&#233;rence sont souvent donn&#233;es pour des ensembles
de mots tr&#232;s fr&#233;quents (Curran &amp; Moens, 2002) ou portent sur un ensemble de relations de proximit&#233;
s&#233;mantique plus large que la simple synonymie (van der Plas &amp; Bouma, 2004). Dans cet article, nous
commen&#231;ons par pr&#233;senter les exp&#233;rimentations que nous avons men&#233;es en anglais afin de trouver la me-
sure de similarit&#233; s&#233;mantique la plus efficace dans le cadre des contraintes que nous nous fixons en nous
fondant un test de type TOEFL &#233;tendu. Nous rendons compte ensuite de l&#8217;application de cette mesure &#224;
l&#8217;extraction de synonymes &#224; partir de corpus pour des noms. Enfin, nous &#233;tudions si des m&#233;thodes d&#8217;am&#233;-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>SIMILARIT&#201; S&#201;MANTIQUE ET EXTRACTION DE SYNONYMES
</p>
<p>lioration de la caract&#233;risation distributionnelle des mots fond&#233;es sur l&#8217;amor&#231;age sont op&#233;rantes dans notre
cas de figure. Notre objectif est ainsi d&#8217;avoir une vue plus globale de la notion de similarit&#233; s&#233;mantique, &#224;
l&#8217;instar de (Turney, 2008) ou de (Baroni &amp; Lenci, 2009).
</p>
<p>2 Test de mesures de similarit&#233; s&#233;mantique
</p>
<p>2.1 D&#233;finition des mesures de similarit&#233; s&#233;mantique
</p>
<p>Une mesure de similarit&#233; s&#233;mantique fond&#233;e sur l&#8217;hypoth&#232;se distributionnelle d&#233;pend fortement &#224; la fois du
corpus &#224; partir duquel les donn&#233;es distributionnelles sont constitu&#233;es et des moyens utilis&#233;s pour r&#233;aliser
leur extraction. Bien que les corpus utilis&#233;s dans ce cadre tendent &#224; devenir de plus en plus gros, ainsi
que l&#8217;illustre (Pantel et al., 2009), nous avons choisi d&#233;lib&#233;r&#233;ment un corpus de taille moyenne, le corpus
AQUAINT-2, comprenant environ 380 millions de mots et constitu&#233; d&#8217;articles de journaux. Ce choix est
motiv&#233; par le fait que la collecte de tr&#232;s gros corpus, outre les moyens que leur traitement induit, n&#8217;est pas
toujours possible dans tous les domaines et pour toutes les langues.
</p>
<p>Mesure de similarit&#233; des vecteurs de contexte Fonction de pond&#233;ration des cooccurrents
</p>
<p>Cosinus
&#8721;
</p>
<p>i
poids(xi)&#183;poids(yi)&#8730;&#8721;
</p>
<p>j
poids(xj)2&#183;
</p>
<p>&#8721;
j
poids(yj)2
</p>
<p>Information mutuelle (im) log( p(x,c)
p(x)&#183;p(c))
</p>
<p>Jaccard
&#8721;
</p>
<p>i
min(poids(xi),poids(yi))&#8721;
</p>
<p>j
max(poids(xj),poids(yj))
</p>
<p>T-test p(x,c)&#8722;p(x)&#183;p(c)&#8730;
p(x)&#183;p(c)
</p>
<p>Jaccard&#8224;
&#8721;
</p>
<p>i
min(poids(xi),poids(yi))&#8721;
</p>
<p>i
max(poids(xi),poids(yi))
</p>
<p>Tf.Idf N(x, c) &#183; log( Nx
Nx,c
</p>
<p>)
</p>
<p>Dice 2&#183;
&#8721;
</p>
<p>i
min(poids(xi),poids(yi))&#8721;
</p>
<p>j
poids(xj)+
</p>
<p>&#8721;
j
poids(yj)
</p>
<p>c : cooccurrent
</p>
<p>Dice&#8224; 2&#183;
&#8721;
</p>
<p>i
min(poids(xi),poids(yi))&#8721;
i
poids(xi)+poids(yi)
</p>
<p>Lin
&#8721;
</p>
<p>i
poids(xi)+poids(yi)&#8721;
</p>
<p>j
poids(xj)+
</p>
<p>&#8721;
j
poids(yj)
</p>
<p>TAB. 1 &#8211; Mesures de similarit&#233; des contextes et fonctions de pond&#233;ration de leurs constituants test&#233;es1
</p>
<p>Concernant l&#8217;extraction des donn&#233;es distributionnelles, nous avons opt&#233; l&#224; aussi pour une approche peu
exigeante quant aux moyens utilis&#233;s. Bien qu&#8217;un certain nombre de travaux utilisent des analyseurs syn-
taxiques de surface, suivant en cela (Grefenstette, 1994) et (Lin, 1998), nous nous sommes limit&#233;s &#224; un
pr&#233;-traitement linguistique des documents prenant la forme d&#8217;une lemmatisation et d&#8217;une s&#233;lection des
mots pleins (noms, verbes et adjectifs) en nous appuyant sur l&#8217;outil TreeTagger (Schmid, 1994). La faci-
lit&#233; d&#8217;acc&#232;s &#224; un analyseur syntaxique de surface pour l&#8217;anglais ne doit pas cacher en effet que ce type
d&#8217;outils n&#8217;est pas encore largement r&#233;pandu pour la plupart des autres langues. Les donn&#233;es distribution-
nelles que nous associons &#224; chaque nom N repr&#233;sentatif du corpus AQUAINT-21 prennent donc la forme
d&#8217;un vecteur de cooccurrents obtenu en comptabilisant les cooccurrences observ&#233;es entre N et les noms,
</p>
<p>1En pratique, seuls les mots de fr&#233;quence strictement sup&#233;rieure &#224; 10 sont retenus, aussi bien pour les noms cibles de nos
&#233;valuations que pour les cooccurrents constituant les vecteurs qui leur sont associ&#233;s.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>OLIVIER FERRET
</p>
<p>verbes et adjectifs d&#8217;une fen&#234;tre de taille fixe centr&#233;e sur toutes les occurrences de N dans le corpus. Nous
d&#233;nommons ce vecteur un vecteur de contexte.
</p>
<p>Dans ce cadre, nous d&#233;finissons une mesure de similarit&#233; s&#233;mantique entre un mot x et un mot y par le
biais des quatre caract&#233;ristiques suivantes :
</p>
<p>&#8211; une mesure de similarit&#233; des vecteurs de contexte associ&#233;s &#224; x et &#224; y ;
&#8211; une fonction de pond&#233;ration estimant l&#8217;importance d&#8217;un cooccurrent au sein d&#8217;un vecteur de contexte ;
&#8211; la taille de la fen&#234;tre utilis&#233;e pour collecter les cooccurrents ;
&#8211; le seuil appliqu&#233; pour &#233;liminer au sein des vecteurs de contexte les mots cooccurrant trop rarement avec
le mot cible.
</p>
<p>Le Tableau 1 donne la d&#233;finition des diff&#233;rentes mesures de similarit&#233; des vecteurs de contexte et des
diff&#233;rentes fonctions de pond&#233;ration des cooccurrents en leur sein que nous avons test&#233;es. S&#8217;y ajoute
la mesure propos&#233;e par (Ehlert, 2003) qui, de par sa nature probabiliste, &#233;chappe au sch&#233;ma ci-dessus
puisqu&#8217;elle repose sur la probabilit&#233; des cooccurrents et non sur un poids d&#233;fini de fa&#231;on externe.
</p>
<p>2.2 R&#233;sultats et &#233;valuation
</p>
<p>Comme indiqu&#233; en introduction, notre s&#233;lection d&#8217;une mesure de similarit&#233; s&#233;mantique en vue de l&#8217;ex-
traction de synonymes s&#8217;est op&#233;r&#233;e sur la base d&#8217;un test de type TOEFL &#233;tendu, et plus pr&#233;cis&#233;ment du
WordNet-Based Synonymy Test (WBST), propos&#233; par (Freitag et al., 2005)2. Le WBST a &#233;t&#233; produit en
g&#233;n&#233;rant automatiquement un large ensemble de questions de type TOEFL &#224; partir des synonymes de
WordNet. (Freitag et al., 2005) montre que ce test est plus difficile que le test originel du TOEFL dont
les 80 questions ont &#233;t&#233; initialement utilis&#233;es dans (Landauer &amp; Dumais, 1997). La partie du WBST se
limitant aux noms, auxquels nous nous restreignons dans ce travail, comprend 9 887 questions. Toutes
les combinaisons possibles entre les mesures de similarit&#233; des vecteurs de contexte et les fonctions de
pond&#233;ration des cooccurrents ont &#233;t&#233; test&#233;es avec des tailles de fen&#234;tre comprises entre 1 et 5 et des seuils
fr&#233;quentiels sur les cooccurrents allant de 1 &#224; 5. En pratique, pour chaque question du test, la mesure de
similarit&#233; test&#233;e est calcul&#233;e entre l&#8217;entr&#233;e constituant la question et les quatre choix possibles. Ces choix
sont ensuite tri&#233;s selon l&#8217;ordre d&#233;croissant de leur score et celui ayant la similarit&#233; la plus forte est retenu
comme candidat synonyme. Dans les rares cas o&#249; les donn&#233;es distributionnelles ne permettent pas de d&#233;-
partager les diff&#233;rents choix (entre 3,7 et 6,7% des cas selon les mesures), un tirage al&#233;atoire est r&#233;alis&#233;.
La mesure d&#8217;&#233;valuation utilis&#233;e est tout simplement le pourcentage de candidats synonymes exacts, ce
que l&#8217;on peut aussi voir comme la pr&#233;cision au rang 1 puisque nos mesures ordonnancent les choix. Le
Tableau 2 donne pour chaque mesure de similarit&#233; entre vecteurs de contexte les trois autres param&#232;tres
permettant d&#8217;obtenir les meilleurs r&#233;sultats sur le WBST.
</p>
<p>La premi&#232;re observation notable &#224; propos de cette &#233;valuation est que pour toutes les mesures de similarit&#233;
entre vecteurs de contexte, les meilleurs r&#233;sultats sont obtenus pour une taille de fen&#234;tre et un seuil sur les
cooccurrents &#233;gaux &#224; 13. Ceci laisse donc &#224; penser que la notion de similarit&#233; s&#233;mantique est plut&#244;t carac-
t&#233;ris&#233;e par des cooccurrents de tr&#232;s courte port&#233;e parmi lesquels seuls les cooccurrents dont la pr&#233;sence
est la plus probablement fortuite sont &#233;cart&#233;s. Le deuxi&#232;me constat tir&#233; du Tableau 2 est que le couple
</p>
<p>1i : index sur les cooccurrents communs &#224; x et y ; j : index sur tous les cooccurrents de x et de y ; N(x, c) : fr&#233;quence de c
comme cooccurrent de x ; Nx : nombre de mots ; Nx,c : nombre de mots ayant c comme cooccurrent.
</p>
<p>2Disponible &#224; l&#8217;adresse http://www.cs.cmu.edu/~dayne/wbst-nanews.tar.gz.
3Ce qui conduit &#224; supprimer globalement la moiti&#233; environ des cooccurrents.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>SIMILARIT&#201; S&#201;MANTIQUE ET EXTRACTION DE SYNONYMES
</p>
<p>taille fen&#234;tre 1 3 5
seuil fr&#233;quence 1 3 5 1 3 5 1 3 5
</p>
<p>im 71,6 69,7 67,6 65,7 63,7 62,8 62,5 60,6 59,4
cosinus t-test 68,9 66,7 65,0 65,4 64,6 63,8 63,3 62,9 62,0
</p>
<p>tf.idf 64,0 63,1 62,0 63,3 62,9 62,5 62,6 62,4 61,7
ehlert &#8211; 70,2 68,5 66,2 68,9 67,2 65,9 66,9 65,9 64,4
</p>
<p>im 64,8 63,0 61,7 57,1 55,0 54,1 54,6 52,6 51,3
jaccard t-test 68,1 65,8 63,9 61,3 58,8 57,7 58,4 55,9 54,6
</p>
<p>tf.idf 54,2 53,9 53,6 49,7 49,6 49,3 48,0 47,9 47,4
im 64,8 63,0 61,7 57,1 55,0 54,1 54,6 52,6 51,3
</p>
<p>dice t-test 68,1 65,8 63,9 61,3 58,8 57,7 58,4 55,9 54,6
tf.idf 54,2 53,9 53,6 49,7 49,6 49,3 48,0 47,9 47,4
im 65,6 63,5 61,7 57,0 54,6 53,6 54,2 52,1 51,1
</p>
<p>lin t-test 67,3 65,3 63,3 61,0 59,5 58,9 58,5 57,3 55,9
tf.idf 60,6 59,6 58,3 57,9 56,6 55,9 56,6 54,9 53,9
im 65,0 63,2 61,5 58,7 57,5 57,0 56,5 55,9 55,3
</p>
<p>dice&#8224; t-test 66,0 64,3 62,3 59,7 57,9 57,0 57,5 56,0 55,1
tf.idf 51,6 52,3 52,7 48,4 47,9 48,3 47,2 47,2 46,6
im 56,1 54,7 53,2 54,3 54,3 53,4 54,0 54,3 53
</p>
<p>jaccard&#8224; t-test 39,6 37,9 38,2 46,7 43,7 42,2 48,1 45,7 43,0
tf.idf 35,3 34,3 34,4 40,2 38,1 37,3 41,4 39,7 38,4
</p>
<p>TAB. 2 &#8211; &#201;valuation des mesures de similarit&#233; s&#233;mantique
</p>
<p>Information mutuelle &#8211; Cosinus et la mesure de Ehlert obtiennent toutes deux les meilleurs r&#233;sultats,
conform&#233;ment aux conclusions de (Freitag et al., 2005), &#233;tablies &#233;galement avec des cooccurrences &#171; gra-
phiques &#187;. N&#233;anmoins, (Freitag et al., 2005) donnait l&#8217;avantage &#224; Ehlert par rapport au Cosinus et nous
observons la tendance inverse. Plus pr&#233;cis&#233;ment, notre meilleur r&#233;sultat pour le Cosinus est &#233;gal &#224; leur
meilleur r&#233;sultat pour Elhert (en dehors d&#8217;une optimisation supervis&#233;e &#233;galement propos&#233;e). Par ailleurs,
les performances rapport&#233;es dans (Freitag et al., 2005) ont &#233;t&#233; obtenues avec un corpus d&#8217;un milliard de
mots environ, c&#8217;est-&#224;-dire beaucoup plus grand que le n&#244;tre, et la fr&#233;quence des noms du WBST dans leur
corpus &#233;tait au moins &#233;gale &#224; 1000 tandis que nous avons &#233;cart&#233; seulement les mots de fr&#233;quence inf&#233;rieure
&#224; 11. Enfin, les performances de notre meilleure mesure se comparent favorablement &#224; celles de (Broda
et al., 2009), qui s&#8217;appuie sur des cooccurrences syntaxiques : pour les noms de fr&#233;quence sup&#233;rieure &#224; 10
dans leur corpus de r&#233;f&#233;rence, le British National Corpus (BNC), un corpus de 100 millions de mots, un
pourcentage d&#8217;exactitude de 68,04 est obtenu sur un ensemble de 14 376 noms faisant partie du WBST.
</p>
<p>3 Extraire des synonymes gr&#226;ce &#224; une mesure s&#233;mantique
</p>
<p>Les r&#233;sultats ci-dessus montrent que nous avons construit une mesure de similarit&#233; s&#233;mantique distribu-
tionnelle dont les performances, dans un cadre d&#8217;&#233;valuation standard pour des mesures de ce type, sont
au moins aussi &#233;lev&#233;es que celles de l&#8217;&#233;tat de l&#8217;art, tout en mobilisant des moyens moindres. Nous ren-
dons compte maintenant dans cette section de l&#8217;application de cette mesure au probl&#232;me de l&#8217;extraction</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>OLIVIER FERRET
</p>
<p>automatique de synonymes &#224; partir de corpus.
</p>
<p>Notre processus d&#8217;extraction est simple : les synonymes possibles d&#8217;un mot sont trouv&#233;s en recherchant
les N plus proches voisins de ce mot selon notre mesure de similarit&#233;. Plus pr&#233;cis&#233;ment, cette recherche
consiste &#224; appliquer cette mesure de similarit&#233; entre ce mot cible et tous les autres mots du vocabulaire
consid&#233;r&#233; ayant la m&#234;me cat&#233;gorie morpho-syntaxique (ici, les noms d&#8217;AQUAINT-2). Finalement, tous
ces mots sont tri&#233;s suivant leur valeur de similarit&#233; et seuls les N plus proches voisins, avec N = 100 dans
nos exp&#233;rimentations, sont conserv&#233;s en tant que candidats synonymes4. Puisque nous nous appuyons sur
le Cosinus au niveau de notre mesure de similarit&#233; s&#233;mantique, il serait possible de rendre cette recherche
lin&#233;aire plus efficace, sans perdre en qualit&#233; de r&#233;sultat, en utilisant une m&#233;thode du type &#171; recherche
exhaustive des paires similaires &#187; telle que celle pr&#233;sent&#233;e dans (Bayardo et al., 2007), ou pour un domaine
plus proche du n&#244;tre, dans (Pantel et al., 2009) pour une transposition aux tr&#232;s gros volumes de textes.
</p>
<p>fr&#233;q. r&#233;f. # mots # syn.
cibles
</p>
<p>% syn.
trou-
v&#233;s
</p>
<p>R-pr&#233;c. MAP P@1 P@5 P@10 P@100
</p>
<p>&gt; 10 W 10473 29947 24,6 0,082 0,098 0,117 0,051 0,034 0,007
(tous) M 9216 460923 9,5 0,067 0,032 0,241 0,164 0,130 0,048
# 14670 WM 12243 473833 9.8 0,077 0,056 0,225 0,140 0,108 0,038
&gt; 1000 W 3690 13509 28,3 0,111 0,125 0,171 0,077 0,051 0,010
# 4378 M 3732 258836 11,4 0,102 0,049 0,413 0.280 0,219 0,079
</p>
<p>WM 4164 263216 11,5 0,110 0,065 0.413 0,268 0,208 0,073
100 &lt; W 3732 9562 28,6 0,104 0,125 0,136 0,058 0,037 0,007
&#8804; 1000 M 3306 136467 9,3 0,064 0,031 0,187 0,131 0,104 0,038
# 5175 WM 4392 140750 9,8 0,092 0,073 0,209 0,123 0,093 0,031
&#8804; 100 W 3051 6876 11,9 0,021 0,033 0,026 0,012 0,009 0,003
# 5117 M 2178 65620 2,8 0,012 0,005 0,025 0,015 0,015 0,008
</p>
<p>WM 3687 69867 3,5 0,021 0,024 0,033 0,017 0,015 0,007
</p>
<p>TAB. 3 &#8211; &#201;valuation de l&#8217;extraction des synonymes
</p>
<p>Le Tableau 3 montre les r&#233;sultats de l&#8217;application de notre mesure de similarit&#233; s&#233;mantique &#224; l&#8217;extraction
de synonymes. Nous avons pris comme r&#233;f&#233;rence deux ressources : WordNet (W), dans sa version 3.0,
et le th&#233;saurus Moby (M). Notre but &#233;tant en premier lieu d&#8217;&#233;valuer la capacit&#233; d&#8217;une mesure s&#233;mantique
distributionnelle &#224; extraire des synonymes d&#8217;un corpus, nous avons filtr&#233; ces ressources en &#233;liminant en
leur sein les termes ne faisant pas partie du vocabulaire des noms simples retenus pour construire nos
donn&#233;es distributionnelles. Nous avons &#233;galement cr&#233;&#233; une ressource fusionnant WordNet et le th&#233;saurus
Moby (WM). Il est &#224; noter que si les synsets de WordNet sont par d&#233;finition constitu&#233;s de synonymes, les
entr&#233;es du th&#233;saurus Moby contiennent &#233;galement des mots dits li&#233;s. Dans ce cas, notre &#233;valuation s&#8217;&#233;tend
donc &#224; la notion de proximit&#233; s&#233;mantique, au del&#224; de la stricte synonymie.
</p>
<p>La fr&#233;quence des mots en relation avec la taille des corpus &#233;tant une donn&#233;e importante dans les approches
distributionnelles, nous donnons des r&#233;sultats globaux mais nous les diff&#233;rencions &#233;galement suivant trois
tranches fr&#233;quentielles &#224; peu pr&#232;s &#233;quilibr&#233;es en termes d&#8217;effectifs (cf. 1e&#768;re colonne) : les mots tr&#232;s fr&#233;-
quents (fr&#233;quence &gt; 1000), moyennement fr&#233;quents (100 &lt; fr&#233;quence &#8804; 1000) et faiblement fr&#233;quents
</p>
<p>4De mani&#232;re indicative, cette recherche est r&#233;alis&#233;e approximativement en 4 heures sur 48 c&#339;urs d&#8217;un cluster.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>SIMILARIT&#201; S&#201;MANTIQUE ET EXTRACTION DE SYNONYMES
</p>
<p>(10 &lt; fr&#233;quence &#8804; 100). La 3e&#768;me colonne du Tableau 3 donne le nombre d&#8217;entr&#233;es de chaque ressource
pour lesquelles l&#8217;&#233;valuation a &#233;t&#233; r&#233;alis&#233;e, tous les noms du vocabulaire du corpus AQUAINT-2 de fr&#233;-
quence sup&#233;rieure &#224; 10 n&#8217;apparaissant pas dans nos ressources de r&#233;f&#233;rence. La 4e&#768;me colonne de ce m&#234;me
tableau correspond au nombre de synonymes &#224; trouver dans chaque ressource pour l&#8217;ensemble des entr&#233;es
faisant partie du vocabulaire AQUAINT-2 tandis que sa 5e&#768;me colonne fournit le pourcentage de synonymes
effectivement trouv&#233;s parmi les 100 voisins s&#233;mantiques de chaque entr&#233;e de notre base distributionnelle.
Ces voisins &#233;tant ordonn&#233;s, il est possible de faire le parall&#232;le entre la recherche de synonymes et la
recherche de documents en recherche d&#8217;information et de r&#233;utiliser ainsi les m&#233;triques d&#8217;&#233;valuation clas-
siquement utilis&#233;es pour cette derni&#232;re. C&#8217;est l&#8217;objet des derni&#232;res colonnes du Tableau 3 : la R-pr&#233;cision
(R-pr&#233;c.) est la pr&#233;cision obtenue en se limitant aux R premiers voisins, R &#233;tant le nombre de synonymes
dans la ressource de r&#233;f&#233;rence pour l&#8217;entr&#233;e consid&#233;r&#233;e ; la MAP (Mean Average Precision) est la moyenne
des pr&#233;cisions pour chacun des rangs auxquels un synonyme de r&#233;f&#233;rence a &#233;t&#233; identifi&#233; ; enfin, sont don-
n&#233;es les pr&#233;cisions pour diff&#233;rents seuils de nombre de voisins s&#233;mantiques examin&#233;s (pr&#233;cision apr&#232;s
avoir examin&#233; les 1, 5, 10 et 100 premiers voisins).
</p>
<p>Une premi&#232;re vue d&#8217;ensemble du Tableau 3 laisse appara&#238;tre que malgr&#233; ses performances int&#233;ressantes
sur des tests de similarit&#233; s&#233;mantique, la mesure que nous avons s&#233;lectionn&#233;e n&#8217;obtient dans l&#8217;absolu
que des r&#233;sultats assez modestes lorsqu&#8217;elle est appliqu&#233;e au probl&#232;me de l&#8217;extraction de synonymes.
Cette faiblesse est observable aussi bien au niveau du taux de rappel des synonymes (environ 25% pour
WordNet et 10% pour le th&#233;saurus Moby) qu&#8217;au niveau de leur rang parmi les voisins s&#233;mantiques (cf. R-
pr&#233;cision, MAP et P@{1,5,10,100}). Ce constat a une port&#233;e plus g&#233;n&#233;rale que notre travail sp&#233;cifique
dans la mesure o&#249; la mesure s&#233;mantique que nous avons utilis&#233;e peut &#234;tre consid&#233;r&#233;e comme classique.
Cette faiblesse g&#233;n&#233;rale cache n&#233;anmoins des diff&#233;rences importantes suivant la fr&#233;quence des mots. On
observe ainsi une corr&#233;lation claire entre le niveau des r&#233;sultats et la fr&#233;quence des mots dans le corpus de
constitution des donn&#233;es distributionnelles : plus cette fr&#233;quence est &#233;lev&#233;e, plus la mesure de similarit&#233; est
efficace du point de vue de l&#8217;extraction des synonymes et plus son caract&#232;re s&#233;mantique semble s&#8217;affirmer
si l&#8217;on consid&#232;re cette t&#226;che repr&#233;sentative d&#8217;un tel caract&#232;re. M&#234;me si cette constatation semble plaider en
faveur de l&#8217;accroissement de la taille des corpus, elle n&#8217;&#233;carte pas l&#8217;id&#233;e d&#8217;un comportement distributionnel
diff&#233;rent des mots plus rares &#224; prendre en compte de fa&#231;on sp&#233;cifique.
</p>
<p>Sur un autre plan, le Tableau 3 montre que le profil des ressources de r&#233;f&#233;rence consid&#233;r&#233;es a aussi son
importance quant aux r&#233;sultats obtenus. WordNet fournit un nombre restreint de synonymes stricts pour
chaque nom (2,8 en moyenne) tandis que le th&#233;saurus Moby contient pour chaque entr&#233;e un nombre
beaucoup plus important de synonymes et de mots li&#233;s (50 en moyenne). Cette diff&#233;rence explique que
la m&#234;me mesure obtient, pour des mots de fr&#233;quence sup&#233;rieure &#224; 1 000, une pr&#233;cision au rang 1 &#233;gale &#224;
0,413 pour le th&#233;saurus Moby et de seulement 0,171 pour WordNet.
</p>
<p>En l&#8217;absence d&#8217;un cadre d&#8217;&#233;valuation clairement reconnu pour ce type de t&#226;ches, la comparaison avec
d&#8217;autres travaux n&#8217;est pas ais&#233;e. Un certain nombre d&#8217;entre eux utilisent en effet pour leurs &#233;valuations un
ensemble de relations s&#233;mantiques de r&#233;f&#233;rence plus large que la synonymie. C&#8217;est le cas de (van der Plas
&amp; Bouma, 2004), qui adopte la version n&#233;erlandaise d&#8217;EuroWordNet comme r&#233;f&#233;rence mais en s&#8217;appuyant
sur une distance int&#233;grant les relations d&#8217;hyperonymie. (Pantel et al., 2009) s&#8217;int&#233;resse pour sa part &#224; la
notion d&#8217;ensemble d&#8217;entit&#233;s (Entity Sets), sous-tendue par une gamme de relations tr&#232;s &#233;tendue. (Curran &amp;
Moens, 2002) est en revanche un travail le plus directement comparable au n&#244;tre. Il met en &#339;uvre diverses
mesures de similarit&#233; fond&#233;es sur des cooccurrences syntaxiques qui sont ensuite &#233;valu&#233;es du point de
vue de l&#8217;extraction de voisins s&#233;mantiques en adoptant comme r&#233;f&#233;rence la fusion des th&#233;saurus Roget,
Moby et Macquarie. Cette &#233;valuation porte sur 70 noms choisis au hasard dans WordNet en respectant</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>OLIVIER FERRET
</p>
<p>une diversit&#233; de fr&#233;quences et de degr&#233;s de sp&#233;cificit&#233;. Parmi les diff&#233;rentes mesures test&#233;es, la meilleure
performance (Dice&#8224; + T-test) obtenue est une pr&#233;cision au rang 1 de 0,76, au rang 5 de 0,52 et au rang
10 de 0,45 pour 70 noms, &#224; comparer avec 0,413, 0,280 et 0,219 dans notre cas pour 3 732 noms. Il faut
souligner n&#233;anmoins qu&#8217;outre la diff&#233;rence de taille du jeu de test, les r&#233;f&#233;rences utilis&#233;es sont diff&#233;rentes,
ce qui a une grande influence sur le niveau des r&#233;sultats ainsi que nous l&#8217;avons illustr&#233; ci-dessus. Pour nos
3 732 noms, le th&#233;saurus Moby fournit en moyenne 69 synonymes tandis que pour les 70 noms de (Curran
&amp; Moens, 2002), ce nombre monte &#224; 331. On constate en outre que le taux de rappel est diff&#233;rent dans
les deux &#233;valuations : il est de 8,3% pour (Curran &amp; Moens, 2002) tandis qu&#8217;il est de 11,4% dans notre
cas. M&#234;me s&#8217;il est difficile d&#8217;estimer le niveau exact d&#8217;influence des diff&#233;rences de richesse des ressources
utilis&#233;es, cette comparaison sugg&#232;re que l&#8217;utilisation de cooccurrences syntaxiques permet d&#8217;obtenir une
meilleure pr&#233;cision dans l&#8217;extraction de synonymes tandis que les cooccurrences graphiques tendraient &#224;
en favoriser le rappel.
</p>
<p>4 Test d&#8217;am&#233;lioration d&#8217;une mesure de similarit&#233; s&#233;mantique
</p>
<p>Le niveau des performances de notre mesure de similarit&#233; s&#233;mantique pour l&#8217;extraction de synonymes
nous a conduit &#224; examiner si des m&#233;thodes de repond&#233;ration des vecteurs de cooccurrents telles que celles
pr&#233;sent&#233;es dans (Broda et al., 2009) ou (Zhitomirsky-Geffet &amp; Dagan, 2009) pouvaient am&#233;liorer nos
r&#233;sultats. Nous nous sommes focalis&#233;s sur (Zhitomirsky-Geffet &amp; Dagan, 2009) dans la mesure o&#249; les
am&#233;liorations rapport&#233;es par (Broda et al., 2009) sont modestes, m&#234;me si l&#8217;&#233;valuation dans (Zhitomirsky-
Geffet &amp; Dagan, 2009) portait sur des mots en relation d&#8217;implication (entailment) et non de synonymie.
</p>
<p>fr&#233;q. r&#233;f. % syn. trouv&#233;s R-pr&#233;c. MAP P@1 P@5 P@10 P@100
&gt; 10 W 21,5 0,060 0,074 0,087 0,039 0,026 0,006
(tous) M 9,0 &#8211; 0,030 0,211 0,144 0,114 0,0445
&gt; 1000 W 25,1 0,088 0,099 0,137 0,061 0,040 0,009
</p>
<p>M 10,5 &#8211; 0,045 0,360 0,245 0,192 0,073
100 &lt; W 23,4 0,069 0,087 0,092 0,040 0,025 0,006
&#8804; 1000 M 8,7 0,055 0,028 0,163 0,113 0,091 0,036
&#8804; 100 W 11,6 0,017 0,028 0,022 0,011 0,008 0,002
</p>
<p>M 4,0 0,015 0,006 0,034 0,022 0,019 0,012
</p>
<p>TAB. 4 &#8211; &#201;valuation de l&#8217;extraction des synonymes apr&#232;s repond&#233;ration des cooccurrents
</p>
<p>La m&#233;thode propos&#233;e par (Zhitomirsky-Geffet &amp; Dagan, 2009) est fond&#233;e sur un principe d&#8217;amor&#231;age.
Son id&#233;e g&#233;n&#233;rale est d&#8217;exploiter les valeurs de similarit&#233; calcul&#233;es entre le vecteur de contexte V Ct d&#8217;un
mot cible t et les vecteurs de contexte V Ci des autres mots i de la base distributionnelle consid&#233;r&#233;e pour
favoriser les cooccurrents de V Ct pr&#233;sents dans les vecteurs de contexte des mots les plus similaires &#224; t.
Plus formellement, la m&#233;thode prend la forme d&#8217;une repond&#233;ration des cooccurrents cj de t telle que :
</p>
<p>V Ct(cj) =
&#8721;
</p>
<p>(i6=t)&#8743;(cj 6=0)
sim(t, i) (1)
</p>
<p>o&#249; V Ct(cj) est le poids du cooccurrent cj du vecteur de contexte de t.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>SIMILARIT&#201; S&#201;MANTIQUE ET EXTRACTION DE SYNONYMES
</p>
<p>En outre, un seuil de similarit&#233; minimale est appliqu&#233; aux voisins s&#233;mantiques i de t et un second seuil im-
posant un poids minimal pour la prise en compte des cooccurrents d&#8217;un voisin s&#233;mantique i est &#233;galement
fix&#233;. Nous avons &#233;tabli la valeur de ces seuils dans notre cas par le biais d&#8217;un processus d&#8217;optimisation sur
60 entr&#233;es de notre base distributionnelle, choisies de mani&#232;re &#233;quilibr&#233;e sur le plan fr&#233;quentiel.
</p>
<p>Le Tableau 4 montre l&#8217;impact de cette proc&#233;dure de repond&#233;ration des cooccurrents des vecteurs de
contexte sur l&#8217;&#233;valuation pr&#233;sent&#233;e &#224; la Section 3. Il appara&#238;t clairement que si cette proc&#233;dure s&#8217;est av&#233;r&#233;e
tr&#232;s int&#233;ressante dans le cas des relations d&#8217;implication, ses r&#233;sultats sont d&#233;cevants concernant les syno-
nymes puisqu&#8217;elle entra&#238;ne une nette chute de tous les r&#233;sultats (&#224; l&#8217;exception d&#8217;une valeur). Plusieurs ex-
plications peuvent &#234;tre avanc&#233;es. L&#8217;&#233;valuation pr&#233;sent&#233;e dans (Zhitomirsky-Geffet &amp; Dagan, 2009) concer-
nait la capacit&#233; &#224; reproduire des jugements humains sur la pr&#233;sence de relations d&#8217;implication entre deux
mots. Outre le nombre r&#233;duit de mots sources (30 mots de fr&#233;quence sup&#233;rieure &#224; 500 pour 3 200 rela-
tions), il faut noter que cette t&#226;che est plus proche des tests du TOEFL que de l&#8217;extraction de synonymes.
Par ailleurs, les donn&#233;es distributionnelles &#233;taient constitu&#233;es dans ce cas de cooccurrents syntaxiques. En-
fin, il est probable que cette proc&#233;dure d&#8217;amor&#231;age, que l&#8217;on peut voir comme une forme d&#8217;amplificateur,
n&#8217;est effective que si les similarit&#233;s initiales entre les mots sont suffisamment significatives, ce qui n&#8217;est
sans doute pas le cas ici pour les mots de faible fr&#233;quence.
</p>
<p>5 Conclusion et perspectives
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; dans un premier temps les exp&#233;rimentations que nous avons r&#233;alis&#233;es
afin de s&#233;lectionner la mesure de similarit&#233; s&#233;mantique reposant sur l&#8217;hypoth&#232;se distributionnelle qui soit
la plus &#224; m&#234;me de rendre compte des relations de proximit&#233; s&#233;mantique entre mots. Cette s&#233;lection s&#8217;est
appuy&#233;e sur un test de type TOEFL &#233;tendu. Nous avons ensuite appliqu&#233; cette mesure au probl&#232;me de
l&#8217;extraction automatique de synonymes en prenant comme r&#233;f&#233;rence deux ressources compl&#233;mentaires :
WordNet et le th&#233;saurus Moby. Les r&#233;sultats de cette application, compatibles avec l&#8217;&#233;tat de l&#8217;art dans
ce domaine, montrent que les tests de similarit&#233; s&#233;mantique utilis&#233;s habituellement ne garantissent pas
n&#233;cessairement de bonnes performances pour une t&#226;che comme l&#8217;extraction de synonymes. Enfin, nous
avons montr&#233; que la m&#233;thode propos&#233;e dans (Zhitomirsky-Geffet &amp; Dagan, 2009) pour am&#233;liorer la qualit&#233;
des donn&#233;es distributionnelles n&#8217;est pas op&#233;rante pour une telle t&#226;che.
</p>
<p>Le prolongement le plus direct de ce travail est l&#8217;utilisation de cooccurrences syntaxiques en lieu et place
des cooccurrences graphiques afin de d&#233;terminer si les premi&#232;res apportent v&#233;ritablement le surcro&#238;t de
pr&#233;cision que notre analyse des r&#233;sultats de (Curran &amp; Moens, 2002) semble sugg&#233;rer. Si une telle am&#233;lio-
ration est constat&#233;e, nous envisageons de mener des travaux compl&#233;mentaires concernant l&#8217;am&#233;lioration
des donn&#233;es distributionnelles, en commen&#231;ant par un test de la m&#233;thode de (Zhitomirsky-Geffet &amp; Da-
gan, 2009) avec ces cooccurrences syntaxiques et au del&#224;, la prise en compte de nouveaux crit&#232;res comme
l&#8217;utilisation de sens de mots discrimin&#233;s automatiquement.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BARONI M. &amp; LENCI A. (2009). One distributional memory, many semantic spaces. In EACL 2009
Workshop on Geometrical Models of Natural Language Semantics, p. 1&#8211;8, Athens, Greece.
</p>
<p>BAYARDO R. J., MA Y. &amp; SRIKANT R. (2007). Scaling up all pairs similarity search. In 16th interna-
tional conference on World Wide Web (WWW&#8217;07), p. 131&#8211;140, Banff, Alberta, Canada.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>OLIVIER FERRET
</p>
<p>BRODA B., PIASECKI M. &amp; SZPAKOWICZ S. (2009). Rank-Based Transformation in Measuring Se-
mantic Relatedness. In 22nd Canadian Conference on Artificial Intelligence, p. 187&#8211;190.
CURRAN J. &amp; MOENS M. (2002). Improvements in automatic thesaurus extraction. InWorkshop of the
ACL Special Interest Group on the Lexicon (SIGLEX), p. 59&#8211;66, Philadelphia, USA.
EHLERT B. (2003). Making Accurate Lexical Semantic Similarity Judgments Using Wordcontext Co-
occurrence Statistics. Master&#8217;s thesis, University of California, San Diego, USA.
FIRTH J. (1957). Studies in Linguistic Analysis, chapter A synopsis of linguistic theory 1930-1955, p.
1&#8211;32. Blackwell : Oxford.
FREITAG D., BLUME M., BYRNES J., CHOW E., KAPADIA S., ROHWER R. &amp; WANG Z. (2005).
New experiments in distributional representations of synonymy. In Ninth Conference on Computational
Natural Language Learning (CoNLL 2005), p. 25&#8211;32, Ann Arbor, Michigan, USA.
GREFENSTETTE G. (1994). Explorations in automatic thesaurus discovery. Kluwer.
LANDAUER T. K. &amp; DUMAIS S. T. (1997). A solution to Plato&#8217;s problem : the latent semantic analysis
theory of acquisition, induction, and representation of knowledge. Psychological review, 104(2), 211&#8211;
240.
LIN D. (1998). Automatic retrieval and clustering of similar words. In ACL-COLING&#8217;98, p. 768&#8211;774,
Montr&#233;al, Canada.
MORALIYSKI R. &amp; DIAS G. (2007). One Sense Per Discourse for Synonym Detection. In 5th Interna-
tional Conference Recent Advances in Natural Language Processing (RANLP 2007), Borovets, Bulgaria.
PANTEL P., CRESTAN E., BORKOVSKY A., POPESCU A.-M. &amp; VYAS V. (2009). Web-Scale Distri-
butional Similarity and Entity Set Expansion. In 2009 Conference on Empirical Methods in Natural
Language Processing, p. 938&#8211;947, Singapore.
PIASECKI M., SZPAKOWICZ S. &amp; BRODA B. (2007). Extended Similarity Test for the Evaluation of
Semantic Similarity Functions. In Language Technology Conference (LTC), p. 104&#8211;108, Poznan&#769;, Poland.
SALGREN M. (2006). The Word-space model. PhD thesis, Stockholm University.
SCHMID H. (1994). Probabilistic Part-of-Speech Tagging Using Decision Trees. In International Confe-
rence on New Methods in Language Processing.
SCHWAB D., TZE L. L. &amp; LAFOURCADE M. (2007). Les vecteurs conceptuels, un outil compl&#233;mentaire
aux r&#233;seaux lexicaux. In 14e&#768;me Conf&#233;rence sur le Traitement automatique des langues naturelles (TALN
2007), p. 293&#8211;302, Toulouse.
TURNEY P., LITTMAN M., BIGHAM J. &amp; SHNAYDER V. (2003). Combining independent modules
to solve multiple-choice synonym and analogy problems. In 4th International Conference on Recent
Advances in Natural Language Processing (RANLP-03), p. 482&#8211;489, Borovets, Bulgaria.
TURNEY P. D. (2008). A Uniform Approach to Analogies, Synonyms, Antonyms, and Association. In
COLING 2008, p. 905&#8211;912, Manchester, UK.
VAN DER PLAS L. &amp; BOUMA G. (2004). Syntactic contexts for finding semantically related words. In
Fifteenth Computational Linguistics in the Netherlands Meeting (CLIN 2004), Leiden, Netherlands.
WEEDS J. (2003). Measures and Applications of Lexical Distributional Similarity. PhD thesis, Depart-
ment of Informatics, University of Sussex.
ZESCH T. &amp; GUREVYCH I. (2010). Wisdom of crowds versus wisdom of linguists - measuring the
semantic relatdness of words. Natural Language Engineering, 16(1), 25&#8211;59.
ZHITOMIRSKY-GEFFET M. &amp; DAGAN I. (2009). Bootstrapping Distributional Feature Vector Quality.
Computational Linguistics, 35(3), 435&#8211;461.</p>

</div></div>
</body></html>