TALN 2010, Montréal, 19-23 juillet 2010

Similarité sémantique et extraction de synonymes a partir de corpus

Olivier Ferret
CEA, LIST, Laboratoire Vision et Ingénierie des Contenus,
Fontenay-aux-Roses, F-92265 France.
olivier.ferret@cea.fr

Résumé. La déﬁnition de mesures sémantiques au niveau lexical a fait l’objet de nombreux travaux
depuis plusieurs années. Dans cet article, nous nous focalisons plus spéciﬁquement sur les mesures de
nature distributionnelle. Bien que différentes évaluations ont été réalisées les concernant, il reste difﬁcile
a établir si une mesure donnant de bons résultats dans un cadre d’évaluation peut étre appliquée plus lar-
gement avec le méme succes. Dans le travail présenté, nous commengons par sélectionner une mesure de
similarité sur la base d’un test de type TOEFL étendu. Nous l’appliquons ensuite au probleme de l’extrac-
tion de synonymes a partir de corpus en comparant nos résultats avec ceux de (Curran & Moens, 2002).
Enﬁn, nous testons l’intérét pour cette tache d’extraction de synonymes d’une méthode d’amélioration de
la qualité des données distributionnelles proposée dans (Zhitomirsky-Geffet & Dagan, 2009).

Abstract. The deﬁnition of lexical semantic measures has been the subject of lots of works for many
years. In this article, we focus more speciﬁcally on distributional semantic measures. Although several
evaluations about this kind of measures were already achieved, it is still difﬁcult to determine if a measure
that performs well in an evaluation framework can be applied more widely with the same success. In
the work we present here, we ﬁrst select a similarity measure by testing it against an extended TOEFL
test. Then, we apply this measure for extracting automatically synonyms from a corpus and we compare
our results to those of (Curran & Moens, 2002). Finally, we test the interest for synonym extraction of a
method proposed in (Zhitomirsky-Geffet & Dagan, 2009) for improving the quality of distributional data.

M0tS-CléS I extraction de synonymes, similarité sémantique, méthodes distributionnelles.

Keywords: synonym extraction, semantic similarity, distributional methods.

1 Introduction

Cet article s’inscrit dans le champ de la sémantique lexicale et plus précisément de ce que l’on nomme
« similarité sémantique lexicale ». L’ objectif des travaux menés dans ce domaine de recherche est de dé-
terminer dans quelle mesure deux mots sont proches sur le plan sémantique et, lorsque leur similarité est
sufﬁsamment forte, d’expliciter le type de la relation sémantique qui les unit. Une partie de ces travaux
(cf. (Zesch & Gurevych, 2010) pour en avoir un panorama) exploitent pour ce faire des sources de connais-
sances plus ou moins structurées, tels que des dictionnaires. Dans cet article, nous nous focaliserons plus
particulierement sur les approches a base de corpus. La plupart d’entre elles s’appuient sur l’hypothese
distributionnelle selon laquelle des mots se trouvant dans des contextes similaires tendent a avoir des sens
similaires (Firth, 1957). Dans le prolongement de (Grefenstette, 1994) et de (Lin, 1998), cette hypothese

OLIVIER FERRET

est généralement mise en oeuvre en collectant des cooccurrences a partir de corpus de taille importante et
en caractérisant chaque terme T de ces corpus par le vecteur de ses cooccurrents. Ceux-ci sont pondérés
en fonction de la force de leur lien avec T. La similarité sémantique entre deux termes est évaluée quanta
elle en calculant une mesure de similarité entre les vecteurs qui leur sont associés. Cette perspective a été
adoptée et explorée en profondeur par des travaux tels que (Curran & Moens, 2002) ou (Weeds, 2003) en
testant un nombre important de mesures de similarité et de fonctions de pondération des cooccurrents.

Quelques variantes de ce schéma de base ont été proposées, sans néanmoins sortir du cadre distributionnel.
L’une d’elles est de nature probabiliste : chaque terme y est caractérisé par une distribution de probabilité
sur ses cooccurrents et la similarité sémantique entre deux termes est évaluée par une distance entre leurs
distributions respectives (Weeds, 2003). L’utilisation de méthodes de réduction de dimensions couvre un
autre ensemble de variantes dans le cadre desquelles la similarité entre deux termes est évaluée dans
l’espace sémantique issu de la réduction de dimensions réalisée. L’Analyse Sémantique Latente (Landauer
& Dumais, 1997) et le Random Indexing (Salgren, 2006) sont les principaux représentants de ce courant
auquel peut se rattacher indirectement les vecteurs conceptuels (Schwab et al., 2007).

Les travaux concernant la similarité sémantique lexicale se déﬁnissent également par la facon dont ils
évaluent les mesures de similarité sémantique qu’ils proposent. Une maniére répandue de réaliser cette
évaluation, utilisée initialement par (Landauer & Dumais, 1997), est d’ appliquer ces mesures aux questions
de synonyIr1ie de tests de type TOEFL. Ces questions sont constituées d’un mot cible et de quatre mots
candidats parmi lesquels un synonyme du mot cible doit étre identiﬁé. Les systémes développés ayant
atteint un haut niveau de performance sur les questions issues du TOEFL (Tumey et al., 2003), diverses
extensions de cette approche ont été explorées, soit par l’utilisation de questions issues d’autres tests
similaires, comme l’ESL (Moraliyski & Dias, 2007), soit par la construction automatique d’un ensemble
beaucoup plus large de questions en s’appuyant sur une ressource de référence telle que WordNet (Freitag
et al., 2005; Piasecki et al., 2007), soit enﬁn par l’extension des questions a des relations de nature plus
large que la synonymie comme les relations d’analogie présentes dans le test SAT (Turney, 2008).

Un autre mode commun d’évaluation des mesures de similarité sémantique est la comparaison de leurs
résultats a une ressource de référence. Des jugements humains portant sur la similarité de couples de
mots sont parfois utilisés dans cet esprit (Weeds, 2003) mais de tels jugements constituent en pratique
des ressources rares et de petite taille. De ce fait, un mode d’évaluation plus indirect est généralement
adopté (Curran & Moens, 2002; Lin, 1998) : les mesures de similarité a tester sont appliquées pour trouver
les plus proches voisins sémantiques d’un mot et la pertinence de ces voisins est évaluée en les comparant
a un ensemble de synonymes de référence issus de ressources telles que WordNet ou le thésaurus Roget.

L’ objectif global du travail que nous présentons ici est d’extraire des synonymes de noms a partir de corpus
en s’appuyant sur l’hypothése distributionnelle, ce qui nécessite en premier lieu de choisir une mesure de
similarité sémantique adéquate. En dépit du nombre signiﬁcatif de travaux déja réalisés dans ce domaine,
comme nous avons pu le voir ci-dessus, il est difﬁcile en pratique de transposer leurs résultats a notre
probléme : beaucoup d’entre eux ont été évalués sur des tests de type TOEFL, tache moins exigeante que
la n6tre, et les comparaisons avec des ressources de référence sont souvent données pour des ensembles
de mots trés fréquents (Curran & Moens, 2002) ou portent sur un ensemble de relations de proximité
sémantique plus large que la simple synonymie (van der Plas & Bouma, 2004). Dans cet article, nous
commencons par présenter les expérimentations que nous avons menées en anglais aﬁn de trouver la me-
sure de similarité sémantique la plus efﬁcace dans le cadre des contraintes que nous nous ﬁxons en nous
fondant un test de type TOEFL étendu. Nous rendons compte ensuite de l’application de cette mesure a
l’eXtraction de synonymes a partir de corpus pour des noms. Enﬁn, nous étudions si des méthodes d’amé-

SIMILARITE SEMANTIQUE ET EXTRACTION DE SYNONYMES

lioration de la caractérisation distributionnelle des mots fondées sur l’amorcage sont opérantes dans notre
cas de ﬁgure. Notre objectif est ainsi d’avoir une vue plus globale de la notion de similarité sémantique, a
l’instar de (Tumey, 2008) ou de (Baroni & Lenci, 2009).

2 Test de mesures de similarité sémantique

2.1 Déﬁnition des mesures de similarité sémantique

Une mesure de similarité sémantique fondée sur l’hypothese distributionnelle dépend fortement a la fois du
corpus a partir duquel les données distributionnelles sont constituées et des moyens utilisés pour réaliser
leur extraction. Bien que les corpus utilisés dans ce cadre tendent a devenir de plus en plus gros, ainsi
que l’illustre (Pantel et al., 2009), nous avons choisi délibérément un corpus de taille moyenne, le corpus
AQUAINT-2, comprenant environ 380 millions de mots et constitué d’articles de journaux. Ce choix est
motivé par le fait que la collecte de tres gros corpus, outre les moyens que leur traitement induit, n’est pas
toujours possible dans tous les domaines et pour toutes les langues.

Mesure de similarité des vecteurs de contexte Fonction de pondération des cooccurrents

\/221:b1;(::(::(_9::).?£)i(i;S()(:’(ii‘:(y-)2 Information mutuelle (im) 1og(p&()””,;)°()c))
Z .Jmin(poids(a:,-),;oids(yi)) T_teSt p($,c) —p($).p(c)
23- m“$(P0id5(7’j)aP0id3(?Jj)) 3 /p(a:)-p(c)

Z.min( ids(a:,-), oids(  _L
Jaccard’[ jgma$;:ids($i):0ids(:i)) T f.Idf N (av, c) - 1og(1{,‘:,c)

2-2:1. min(poids(a:,-),poids(y,-))
Z]. poids(mj)+Zj poids(yj)
2-Z. min(poids(a:,-),poids(y,-))
2:1. poids(a:,-)+poids(y,-)

Z . poids(a:,-)+poids(y,-)
Z]. poids(a:j)+Zj poids(yj)

Cosinus

J accard
Dice c : cooccurrent
Dice’[

Lin

TAB. 1 — Mesures de similarité des contextes et fonctions de pondération de leurs constituants testéesl

Concernant l’extraction des données distributionnelles, nous avons opté la aussi pour une approche peu
exigeante quant aux moyens utilisés. Bien qu’un certain nombre de travaux utilisent des analyseurs syn-
taxiques de surface, suivant en cela (Grefenstette, 1994) et (Lin, 1998), nous nous sommes limités a un
pré-traitement linguistique des documents prenant la forme d’une lemmatisation et d’une sélection des
mots pleins (noms, verbes et adjectifs) en nous appuyant sur l’outil TreeTagger (Schmid, 1994). La faci-
lité d’acces a un analyseur syntaxique de surface pour l’anglais ne doit pas cacher en effet que ce type
d’outils n’est pas encore largement répandu pour la plupart des autres langues. Les données distribution-
nelles que nous associons a chaque nom N représentatif du corpus AQUAINT-21 prennent donc la forme
d’un vecteur de cooccurrents obtenu en comptabilisant les cooccurrences observées entre N et les noms,

1En pratique, seuls les mots de fréquence strictement supérieure a 10 sont retenus, aussi bien pour les noms cibles de nos
évaluations que pour les cooccurrents constituant les vecteurs qui leur sont associés.

OLIVIER FERRET

verbes et adjectifs d’une fenétre de taille ﬁxe centrée sur toutes les occurrences de N dans le corpus. Nous
dénommons ce vecteur un vecteur de contexte.

Dans ce cadre, nous déﬁnissons une mesure de similarité sémantique entre un mot 1: et un mot y par le
biais des quatre caractéristiques suivantes :

— une mesure de similarité des vecteurs de contexte associés a :13 eta y;

— une fonction de pondération estimant l’importance d’un cooccurrent au sein d’un vecteur de contexte ;

— la taille de la fenétre utilisée pour collecter les cooccurrents ;

— le seuil appliqué pour éliminer au sein des vecteurs de contexte les mots cooccurrant trop rarement avec
le mot cible.

Le Tableau 1 donne la déﬁnition des différentes mesures de similarité des vecteurs de contexte et des
différentes fonctions de pondération des cooccurrents en leur sein que nous avons testées. S’y ajoute
la mesure proposée par (Ehlert, 2003) qui, de par sa nature probabiliste, échappe au schéma ci-dessus
puisqu’elle repose sur la probabilité des cooccurrents et non sur un poids déﬁni de facon exteme.

2.2 Résultats et évaluation

Comme indiqué en introduction, notre sélection d’une mesure de similarité sémantique en vue de l’ex-
traction de synonymes s’est opérée sur la base d’un test de type TOEFL étendu, et plus précisément du
WordNet-Based Synonymy Test (WBST), proposé par (Freitag et al., 2005)2. Le WBST a été produit en
générant automatiquement un large ensemble de questions de type TOEFL a partir des synonymes de
WordNet. (Freitag et al., 2005) montre que ce test est plus difﬁcile que le test originel du TOEFL dont
les 80 questions ont été initialement utilisées dans (Landauer & Dumais, 1997). La partie du WBST se
limitant aux noms, auxquels nous nous restreignons dans ce travail, comprend 9 887 questions. Toutes
les combinaisons possibles entre les mesures de similarité des vecteurs de contexte et les fonctions de
pondération des cooccurrents ont été testées avec des tailles de fenétre comprises entre 1 et 5 et des seuils
fréquentiels sur les cooccurrents allant de 1 a 5. En pratique, pour chaque question du test, la mesure de
similarité testée est calculée entre l’entrée constituant la question et les quatre choix possibles. Ces choix
sont ensuite triés selon l’ordre décroissant de leur score et celui ayant la similarité la plus forte est retenu
comme candidat synonyme. Dans les rares cas o1‘1 les données distributionnelles ne permettent pas de de-
partager les différents choix (entre 3,7 et 6,7% des cas selon les mesures), un tirage aléatoire est réalisé.
La mesure d’évaluation utilisée est tout simplement le pourcentage de candidats synonymes exacts, ce
que l’on peut aussi voir comme la précision au rang 1 puisque nos mesures ordonnancent les choix. Le
Tableau 2 donne pour chaque mesure de similarité entre vecteurs de contexte les trois autres parametres
permettant d’obtenir les meilleurs résultats sur le WBST.

La premiere observation notable a propos de cette évaluation est que pour toutes les mesures de similarité
entre vecteurs de contexte, les meilleurs résultats sont obtenus pour une taille de fenétre et un seuil sur les
cooccurrents égaux a 13. Ceci laisse donc a penser que la notion de similarité sémantique est plutot carac-
térisée par des cooccurrents de tres courte portée parmi lesquels seuls les cooccurrents dont la présence
est la plus probablement fortuite sont écartés. Le deuxieme constat tiré du Tableau 2 est que le couple

12' : index sur les cooccurrents communs a :17 et y ; j : index sur tous les cooccurrents de :17 et de y; N(1:, c) : fréquence de c
comme cooccurrent de x; N,, : nombre de mots; Nwjc : nombre de mots ayant c comme cooccurrent.
2Disponible a l’adresse http : //www . cs . cmu . edu/~dayne/wbst—nanews . tar . gz .
3Ce qui conduit :21 supprimer globalement la moitié environ des cooccurrents.

SIMILARITE SEMANTIQUE ET EXTRACTION DE SYNONYMES

taille fenétre 1 3 5
seuil fréquence 1 3 5 1 3 5 1 3 5
im 71,6 69,7 67,6 65,7 63,7 62,8 62,5 60,6 59,4
cosinus t-test 68,9 66,7 65,0 65,4 64,6 63,8 63,3 62,9 62,0
tf.idf 64,0 63,1 62,0 63,3 62,9 62,5 62,6 62,4 61,7
| ehlert \ — | 70,2 68,5 66,2 | 68,9 67,2 65,9 | 66,9 65,9 64,4 |
im 64,8 63,0 61,7 57,1 55,0 54,1 54,6 52,6 51,3
jaccard t-test 68,1 65,8 63,9 61,3 58,8 57,7 58,4 55,9 54,6
tf.idf 54,2 53,9 53,6 49,7 49,6 49,3 48,0 47,9 47,4
im 64,8 63,0 61,7 57,1 55,0 54,1 54,6 52,6 51,3
dice t-test 68,1 65,8 63,9 61,3 58,8 57,7 58,4 55,9 54,6
tf.idf 54,2 53,9 53,6 49,7 49,6 49,3 48,0 47,9 47,4
im 65,6 63,5 61,7 57,0 54,6 53,6 54,2 52,1 51,1
lin t-test 67,3 65,3 63,3 61,0 59,5 58,9 58,5 57,3 55,9
tf.idf 60,6 59,6 58,3 57,9 56,6 55,9 56,6 54,9 53,9
im 65,0 63,2 61,5 58,7 57,5 57,0 56,5 55,9 55,3
dice’[ t-test 66,0 64,3 62,3 59,7 57,9 57,0 57,5 56,0 55,1
tf.idf 51,6 52,3 52,7 48,4 47,9 48,3 47,2 47,2 46,6
im 56,1 54,7 53,2 54,3 54,3 53,4 54,0 54,3 53
jaccardf t-test 39,6 37,9 38,2 46,7 43,7 42,2 48,1 45,7 43,0
tf.idf 35,3 34,3 34,4 40,2 38,1 37,3 41,4 39,7 38,4

TAB. 2 — Evaluation des mesures de similarité sémantique

Information mutuelle — Cosinus et la mesure de Ehlert obtiennent toutes deux les meilleurs résultats,
conformément aux conclusions de (Freitag et al., 2005), établies également avec des cooccurrences « gra-
phiques ». Néanmoins, (Freitag et al., 2005) donnait l’avantage a Ehlert par rapport au Cosinus et nous
observons la tendance inverse. Plus précisément, notre meilleur résultat pour le Cosinus est égal a leur
meilleur résultat pour Elhert (en dehors d’une optimisation supervisée également proposée). Par ailleurs,
les performances rapportées dans (Freitag et al., 2005) ont été obtenues avec un corpus d’un milliard de
mots environ, c’est-a-dire beaucoup plus grand que le notre, et la fréquence des noms du WBST dans leur
corpus était au moins égale a 1000 tandis que nous avons écarté seulement les mots de fréquence inférieure
a 11. Enﬁn, les performances de notre meilleure mesure se comparent favorablement a celles de (Broda
et al., 2009), qui s’appuie sur des cooccurrences syntaxiques : pour les noms de fréquence supérieure a 10
dans leur corpus de référence, le British National Corpus (BNC), un corpus de 100 millions de mots, un
pourcentage d’eXactitude de 68,04 est obtenu sur un ensemble de 14 376 noms faisant partie du WBST.

3 Extraire des synonymes grace in une mesure sémantique

Les résultats ci-dessus montrent que nous avons construit une mesure de similarité sémantique distribu-
tionnelle dont les performances, dans un cadre d’évaluation standard pour des mesures de ce type, sont
au moins aussi élevées que celles de l’état de l’art, tout en mobilisant des moyens moindres. Nous ren-
dons compte maintenant dans cette section de l’application de cette mesure au probleme de l’eXtraction

OLIVIER FERRET

automatique de synonymes a partir de corpus.

Notre processus d’extraction est simple : les synonymes possibles d’un mot sont trouvés en recherchant
les N plus proches voisins de ce mot selon notre mesure de similarité. Plus précisément, cette recherche
consiste a appliquer cette mesure de similarité entre ce mot cible et tous les autres mots du vocabulaire
considéré ayant la meme catégorie morpho-syntaxique (ici, les noms d’AQUAINT-2). Finalement, tous
ces mots sont triés suivant leur valeur de similarité et seuls les N plus proches voisins, avec N = 100 dans
nos expérimentations, sont conservés en tant que candidats synonymes4. Puisque nous nous appuyons sur
le Cosinus au niveau de notre mesure de similarité sémantique, il serait possible de rendre cette recherche
linéaire plus efﬁcace, sans perdre en qualité de résultat, en utilisant une méthode du type « recherche
exhaustive des paires similaires » telle que celle présentée dans (Bayardo et al. , 2007), ou pour un domaine
plus proche du notre, dans (Pantel et al., 2009) pour une transposition aux tres gros volumes de textes.

fréq. réf. # mots # syn. % syn. R-préc. MAP P@ 1 P@5 P@ 10 P@ 100
cibles trou-
vés

> 10 W 10473 29947 24,6 0,082 0,098 0,117 0,051 0,034 0,007
(tous) M 9216 460923 9,5 0,067 0,032 0,241 0,164 0,130 0,048
# 14670 WM 12243 473833 9.8 0,077 0,056 0,225 0,140 0,108 0,038
> 1000 W 3690 13509 28,3 0,111 0,125 0,171 0,077 0,051 0,010
# 4378 M 3732 258836 11,4 0,102 0,049 0,413 0.280 0,219 0,079

WM 4164 263216 11,5 0,110 0,065 0.413 0,268 0,208 0,073
100 < W 3732 9562 28,6 0,104 0,125 0,136 0,058 0,037 0,007
3 1000 M 3306 136467 9,3 0,064 0,031 0,187 0,131 0,104 0,038
# 5175 WM 4392 140750 9,8 0,092 0,073 0,209 0,123 0,093 0,031
3 100 W 3051 6876 11,9 0,021 0,033 0,026 0,012 0,009 0,003
# 5117 M 2178 65620 2,8 0,012 0,005 0,025 0,015 0,015 0,008

WM 3687 69867 3,5 0,021 0,024 0,033 0,017 0,015 0,007

TAB. 3 — Evaluation de l’eXtraction des synonymes

Le Tableau 3 montre les résultats de l’application de notre mesure de similarité sémantique a l’eXtraction
de synonymes. Nous avons pris comme référence deux ressources : WordNet (W), dans sa version 3.0,
et le thésaurus Moby (M). Notre but étant en premier lieu d’évaluer la capacité d’une mesure sémantique
distributionnelle a extraire des synonymes d’un corpus, nous avons ﬁltré ces ressources en éliminant en
leur sein les termes ne faisant pas partie du vocabulaire des noms simples retenus pour construire nos
données distributionnelles. Nous avons également créé une ressource fusionnant WordNet et le thésaurus
Moby (WM). 11 est a noter que si les synsets de WordNet sont par deﬁnition constitués de synonymes, les
entrées du thésaurus Moby contiennent également des mots dits liés. Dans ce cas, notre évaluation s’étend
donc a la notion de proximité sémantique, au dela de la stricte synonymie.

La fréquence des mots en relation avec la taille des corpus étant une donnée importante dans les approches
distributionnelles, nous donnons des résultats globaux mais nous les différencions également suivant trois
tranches fréquentielles a peu pres équilibrées en termes d’effectifs (cf. lm colonne) : les mots tres fré-
quents (fréquence > 1000), moyennement frequents (100 < fréquence 3 1000) et faiblement frequents

4De maniere indicative, cette recherche est réalisée approximativement en 4 heures sur 48 coeurs d’un cluster.

SIMILARITE SEMANTIQUE ET EXTRACTION DE SYNONYMES

(10 < fréquence 3 100). La Béme colonne du Tableau 3 donne le nombre d’entrées de chaque ressource
pour lesquelles l’évaluation a été réalisée, tous les noms du vocabulaire du corpus AQUAINT-2 de fré-
quence supérieure a 10 n’apparaissant pas dans nos ressources de référence. La 4&7” colonne de ce méme
tableau correspond au nombre de synonymes a trouver dans chaque ressource pour l’ensemble des entrées
faisant partie du vocabulaire AQUAINT-2 tandis que sa 5é"‘e colonne fournit le pourcentage de synonymes
effectivement trouvés parmi les 100 voisins sémantiques de chaque entrée de notre base distributionnelle.
Ces voisins étant ordonnés, il est possible de faire le parallele entre la recherche de synonymes et la
recherche de documents en recherche d’information et de réutiliser ainsi les métriques d’évaluation clas-
siquement utilisées pour cette demiere. C’est l’objet des dernieres colonnes du Tableau 3 : la R-précision
(R-préc.) est la précision obtenue en se limitant aux R premiers voisins, R étant le nombre de synonymes
dans la ressource de référence pour l’entrée considérée ; la MAP (Mean Average Precision) est la moyenne
des précisions pour chacun des rangs auxquels un synonyme de référence a été identiﬁé; enﬁn, sont don-
nées les précisions pour différents seuils de nombre de voisins sémantiques examinés (précision apres
avoir examiné les 1, 5, 10 et 100 premiers voisins).

Une premiere vue d’ensemble du Tableau 3 laisse apparaitre que malgré ses performances intéressantes
sur des tests de similarité sémantique, la mesure que nous avons sélectionnée n’obtient dans l’absolu
que des résultats assez modestes lorsqu’elle est appliquée au probleme de l’eXtraction de synonymes.
Cette faiblesse est observable aussi bien au niveau du taux de rappel des synonymes (environ 25% pour
WordNet et 10% pour le thésaurus Moby) qu’au niveau de leur rang parmi les voisins sémantiques (cf. R-
précision, MAP et P@{1,5,10,100}). Ce constat a une portée plus générale que notre travail spéciﬁque
dans la mesure ou la mesure sémantique que nous avons utilisée peut étre considérée comme classique.
Cette faiblesse générale cache néanmoins des différences importantes suivant la fréquence des mots. On
observe ainsi une corrélation claire entre le niveau des résultats et la fréquence des mots dans le corpus de
constitution des données distributionnelles : plus cette fréquence est élevée, plus la mesure de similarité est
efﬁcace du point de vue de l’eXtraction des synonymes et plus son caractere sémantique semble s’afﬁrmer
si l’on considere cette tache représentative d’un tel caractere. Meme si cette constatation semble plaider en
faveur de l’accroissement de la taille des corpus, elle n’écarte pas l’idée d’un comportement distributionnel
différent des mots plus rares a prendre en compte de facon spéciﬁque.

Sur un autre plan, le Tableau 3 montre que le proﬁl des ressources de référence considérées a aussi son
importance quant aux résultats obtenus. WordNet foumit un nombre restreint de synonymes stricts pour
chaque nom (2,8 en moyenne) tandis que le thésaurus Moby contient pour chaque entrée un nombre
beaucoup plus important de synonymes et de mots liés (50 en moyenne). Cette différence explique que
la méme mesure obtient, pour des mots de fréquence supérieure a 1 000, une précision au rang 1 égale a
0,413 pour le thésaurus Moby et de seulement 0,171 pour WordNet.

En l’absence d’un cadre d’évaluation clairement reconnu pour ce type de taches, la comparaison avec
d’autres travaux n’est pas aisée. Un certain nombre d’entre eux utilisent en effet pour leurs évaluations un
ensemble de relations sémantiques de référence plus large que la synonymie. C’est le cas de (van der Plas
& Bouma, 2004), qui adopte la version néerlandaise d’EuroWordNet comme référence mais en s’appuyant
sur une distance intégrant les relations d’hyperonyIr1ie. (Pantel et al., 2009) s’intéresse pour sa part a la
notion d’ensemble d’entités (Entity Sets), sous-tendue par une gaInme de relations tres étendue. (Curran &
Moens, 2002) est en revanche un travail le plus directement comparable au notre. 11 met en oeuvre diverses
mesures de similarité fondées sur des cooccurrences syntaxiques qui sont ensuite évaluées du point de
vue de l’extraction de voisins sémantiques en adoptant comme référence la fusion des thésaurus Roget,
Moby et Macquarie. Cette évaluation porte sur 70 noms choisis au hasard dans WordNet en respectant

OLIVIER FERRET

une diversite de frequences et de degres de speciﬁcite. Parmi les differentes mesures testees, la meilleure
performance (Dice’[ + T-test) obtenue est une precision au rang 1 de 0,76, au rang 5 de 0,52 et au rang
10 de 0,45 pour 70 noms, a comparer avec 0,413, 0,280 et 0,219 dans notre cas pour 3 732 noms. Il faut
souligner neanmoins qu’outre la difference de taille du jeu de test, les references utilisees sont differentes,
ce qui a une grande inﬂuence sur le niveau des resultats ainsi que nous l’avons illustre ci-dessus. Pour nos
3 732 noms, le thesaurus Moby fournit en moyenne 69 synonymes tandis que pour les 70 noms de (Curran
& Moens, 2002), ce nombre monte a 331. On constate en outre que le taux de rappel est different dans
les deux evaluations : il est de 8,3% pour (Curran & Moens, 2002) tandis qu’il est de 11,4% dans notre
cas. Meme s’il est difﬁcile d’estimer le niveau exact d’inﬂuence des differences de richesse des ressources
utilisees, cette comparaison suggere que l’utilisation de cooccurrences syntaxiques permet d’obtenir une
meilleure precision dans l’eXtraction de synonymes tandis que les cooccurrences graphiques tendraient a
en favoriser le rappel.

4 Test d’amélioration d’une mesure de similarité sémantique

Le niveau des performances de notre mesure de similarite semantique pour l’extraction de synonymes
nous a conduit a examiner si des methodes de reponderation des vecteurs de cooccurrents telles que celles
presentees dans (Broda et al., 2009) ou (Zhitomirsky-Geffet & Dagan, 2009) pouvaient ameliorer nos
resultats. Nous nous sommes focalises sur (Zhitomirsky-Geffet & Dagan, 2009) dans la mesure ou les
ameliorations rapportees par (Broda et al., 2009) sont modestes, meme si l’evaluation dans (Zhitomirsky-
Geffet & Dagan, 2009) portait sur des mots en relation d’implication (entailment) et non de synonymie.

| fréq. | réf. | % syn.trouvés | R-préc. | MAP | P@1 | P@5 | P@10 | P@100 |

> 10 W 21,5 0,060 0,074 0,087 0,039 0,026 0,006
(tous) M 9,0 — 0,030 0,211 0,144 0,114 0,0445
> 1000 W 25,1 0,088 0,099 0,137 0,061 0,040 0,009
M 10,5 — 0,045 0,360 0,245 0,192 0,073

100 < W 23,4 0,069 0,087 0,092 0,040 0,025 0,006
3 1000 M 8,7 0,055 0,028 0,163 0,113 0,091 0,036
3 100 W 11,6 0,017 0,028 0,022 0,011 0,008 0,002
M 4,0 0,015 0,006 0,034 0,022 0,019 0,012

TAB. 4 — Evaluation de l’eXtraction des synonymes apres reponderation des cooccurrents

La methode proposee par (Zhitomirsky-Geffet & Dagan, 2009) est fondee sur un principe d’amorcage.
Son idee generale est d’exploiter les valeurs de similarite calculees entre le vecteur de contexte V0,; d’un
mot cible t et les vecteurs de contexte VC, des autres mots 1' de la base distributionnelle consideree pour
favoriser les cooccurrents de V0,; presents dans les vecteurs de contexte des mots les plus similaires a 75.
Plus formellement, la methode prend la forme d’une reponderation des cooccurrents Cj de t telle que :

VC,(c,-) = Z sim(t, i) (1)
<i¢t>A<cj¢o>

o1‘1 VC,;(cj) est le poids du cooccurrent cj du vecteur de contexte de t.

SIMILARITE SEMANTIQUE ET EXTRACTION DE SYNONYMES

En outre, un seuil de similarité minimale est appliqué aux voisins sémantiques 1' de t et un second seuil im-
posant un poids minimal pour la prise en compte des cooccurrents d’un voisin sémantique i est également
ﬁxé. Nous avons établi la valeur de ces seuils dans notre cas par le biais d’un processus d’optimisation sur
60 entrées de notre base distributionnelle, choisies de maniere équilibrée sur le plan fréquentiel.

Le Tableau 4 montre l’impact de cette procédure de repondération des cooccurrents des vecteurs de
contexte sur l’évaluation présentée a la Section 3. I1 apparait clairement que si cette procédure s’est avérée
tres intéressante dans le cas des relations d’implication, ses résultats sont décevants concemant les syno-
nymes puisqu’elle entraine une nette chute de tous les résultats (a l’exception d’une valeur). Plusieurs ex-
plications peuvent étre avancées. L’ évaluation présentée dans (Zhitomirsky-Geffet & Dagan, 2009) concer-
nait la capacité a reproduire des jugements humains sur la présence de relations d’implication entre deux
mots. Outre le nombre réduit de mots sources (30 mots de fréquence supérieure a 500 pour 3 200 rela-
tions), il faut noter que cette tache est plus proche des tests du TOEFL que de l’eXtraction de synonymes.
Par ailleurs, les données distributionnelles étaient constituées dans ce cas de cooccurrents syntaxiques. En-
ﬁn, il est probable que cette procédure d’amorcage, que l’on peut voir comme une forme d’ampliﬁcateur,
n’est effective que si les similarités initiales entre les mots sont sufﬁsamment signiﬁcatives, ce qui n’est
sans doute pas le cas ici pour les mots de faible fréquence.

5 Conclusion et perspectives

Dans cet article, nous avons présenté dans un premier temps les expérimentations que nous avons réalisées
aﬁn de sélectionner la mesure de similarité sémantique reposant sur l’hypothese distributionnelle qui soit
la plus a meme de rendre compte des relations de proximité sémantique entre mots. Cette sélection s’est
appuyée sur un test de type TOEFL étendu. Nous avons ensuite appliqué cette mesure au probleme de
l’eXtraction automatique de synonymes en prenant comme référence deux ressources complémentaires :
WordNet et le thésaurus Moby. Les résultats de cette application, compatibles avec l’état de l’art dans
ce domaine, montrent que les tests de similarité sémantique utilisés habituellement ne garantissent pas
nécessairement de bonnes performances pour une tache comme l’extraction de synonymes. Enﬁn, nous
avons montré que la méthode proposée dans (Zhitomirsky-Geffet & Dagan, 2009) pour améliorer la qualité
des données distributionnelles n’est pas opérante pour une telle tache.

Le prolongement le plus direct de ce travail est l’utilisation de cooccurrences syntaxiques en lieu et place
des cooccurrences graphiques aﬁn de déterminer si les premieres apportent véritablement le surcroit de
précision que notre analyse des résultats de (Curran & Moens, 2002) semble suggérer. Si une telle amelio-
ration est constatée, nous envisageons de mener des travaux complémentaires concemant l’amélioration
des données distributionnelles, en commencant par un test de la méthode de (Zhitomirsky-Geffet & Da-
gan, 2009) avec ces cooccurrences syntaxiques et au dela, la prise en compte de nouveaux criteres comme
l’utilisation de sens de mots discriminés automatiquement.

Références

BARONI M. & LENCI A. (2009). One distributional memory, many semantic spaces. In EACL 2009
Workshop on Geometrical Models of Natural Language Semantics, p. 1-8, Athens, Greece.

BAYARDO R. J ., MA Y. & SRIKANT R. (2007). Scaling up all pairs similarity search. In 16”‘ interna-
tional conference on World Wide Web (WWW’07), p. 131-140, Banff, Alberta, Canada.

OLIVIER FERRET

BRODA B., PIASECKI M. & SZPAKOWICZ S. (2009). Rank-Based Transformation in Measuring Se-
mantic Relatedness. In 22nd Canadian Conference on Artiﬁcial Intelligence, p. 187-190.

CURRAN J . & MOENS M. (2002). Improvements in automatic thesaurus extraction. In Workshop of the
ACL Special Interest Group on the Lexicon (SIGLEX), p. 59-66, Philadelphia, USA.

EHLERT B. (2003). Making Accurate Lexical Semantic Similarity Judgments Using Wordcontext Co-
occurrence Statistics. Master’s thesis, University of California, San Diego, USA.

FIRTH J. (1957). Studies in Linguistic Analysis, chapter A synopsis of linguistic theory 1930-1955, p.
1-32. Blackwell : Oxford.

FREITAG D., BLUME M., BYRNES J ., CHOW E., KAPADIA S., RoHwER R. & WANG Z. (2005).
New experiments in distributional representations of synonymy. In Ninth Conference on Computational
Natural Language Learning (CoNLL 2005 ), p. 25-32, Ann Arbor, Michigan, USA.

GREFENSTETTE G. (1994). Explorations in automatic thesaurus discovery. Kluwer.

LANDAUER T. K. & DUMAIS S. T. (1997). A solution to Plato’s problem : the latent semantic analysis
theory of acquisition, induction, and representation of knowledge. Psychological review, 104(2), 211-
240.

LIN D. (1998). Automatic retrieval and clustering of similar words. In ACL-COLING’98, p. 768-774,
Montréal, Canada.

MORALIYSKI R. & DIAS G. (2007). One Sense Per Discourse for Synonym Detection. In 5”‘ Interna-
tional Conference Recent Advances in Natural Language Processing (RANLP 2007), Borovets, Bulgaria.
PANTEL P., CRESTAN E., BORKOVSKY A., POPESCU A.-M. & VYAS V. (2009). Web-Scale Distri-
butional Similarity and Entity Set Expansion. In 2009 Conference on Empirical Methods in Natural
Language Processing, p. 938-947, Singapore.

PIASECKI M., SZPAKOWICZ S. & BRODA B. (2007). Extended Similarity Test for the Evaluation of
Semantic Similarity Functions. In Language Technology Conference (LTC), p. 104-108, Poznan, Poland.
SALGREN M. (2006). The Word-space model. PhD thesis, Stockholm University.

SCHMID H. (1994). Probabilistic Part-of-Speech Tagging Using Decision Trees. In International Confe-
rence on New Methods in Language Processing.

SCHWAB D., TZE L. L. & LAFOURCADE M. (2007). Les vecteurs conceptuels, un outil complémentaire
aux réseaux lexicaux. In I 4&7” Conférence sur le Traitement automatique des langues naturelles (TALN
2007), p. 293-302, Toulouse.

TURNEY P., LITTMAN M., BIGHAM J . & SHNAYDER V. (2003). Combining independent modules
to solve multiple-choice synonym and analogy problems. In 4”‘ International Conference on Recent
Advances in Natural Language Processing (RANLP-03), p. 482-489, Borovets, Bulgaria.

T URNEY P. D. (2008). A Uniform Approach to Analogies, Synonyms, Antonyms, and Association. In
COLING 2008, p. 905-912, Manchester, UK.

VAN DER PLAS L. & BOUMA G. (2004). Syntactic contexts for ﬁnding semantically related words. In
Fifteenth Computational Linguistics in the Netherlands Meeting (CLIN 2004 ), Leiden, Netherlands.
WEEDS J . (2003). Measures and Applications of Lexical Distributional Similarity. PhD thesis, Depart-
ment of Informatics, University of Sussex.

ZESCH T. & GUREVYCH I. (2010). Wisdom of crowds versus wisdom of linguists - measuring the
semantic relatdness of words. Natural Language Engineering, 16(1), 25-59.

ZHITOMIRSKY-GEFFET M. & DAGAN I. (2009). Bootstrapping Distributional Feature Vector Quality.
Computational Linguistics, 35(3), 435-461.

