TALN 2010, Montréal, 19-23 juillet 2010

Au-dela de la paire de mots :
extraction de cooccurrences syntaxiques multilexémiques

Simon CHAREST, Eric BRUNELLE, Jean FONTAINE

Druide informatique inc.
1435, rue Saint—Alexandre, bureau 1040
Montreal (Québec) H3A 2G4, Canada

developpement@druide.com

Résumé

Cet article décrit l’élaboration de la deuxieme édition du dictionnaire de cooccurrences du logiciel d’aide a
la rédaction Antidote. Cette nouvelle mouture est le résultat d’une refonte complete du processus
d’extraction, ayant principalement pour but l’extraction de cooccurrences de plus de deux unités lexicales.
La principale contribution de cet article est la description d’une technique originale pour l’extraction de
cooccurrences de plus de deux mots conservant une structure syntaxique complete.

Abstract

This article describes the elaboration of the second edition of the co—occurrence dictionary included in
Antidote HD, a commercial software tool for writing in French. This second edition is the result of a
complete overhaul of the extraction process, with the objective of extracting co—occurrences of more than
two lexical units. The main contribution of this article is the description of an original method for
extracting co—occurrences of more than two words retaining their full syntactic structure.

Mots-clés 2 Antidote, cooccurrences, collocations, expressions multimots.

Keywords: Antidote, co—occurrences, collocations, multi—word expressions (MWE).

Simon CHAREST, Eric BRUNELLE, Jean FONTAINE

1 Introduction

En 2006 paraissait avec Antidote RX1 le premier dictionnaire électronique grand public de cooccurrencesz
du frangais (Charest et coll., 2007). Ce dictionnaire a été élaboré en utilisant l’analyseur syntaxique
d’Antidote pour extraire, d’un corpus de 500 millions de mots, 17 millions de paires de mots différentes
liées par diverses relations syntaxiques. Un score correspondant au rapport de Vraisemblance (log-
likelihood ratio) avait été calculé sur chacune de ces cooccurrences candidates afin d’en dégager les plus
significatives. Au final, apres Validation par une équipe de linguistes, 800 000 cooccurrences avaient été
retenues, réparties en 36 000 entrées, classées par sens et relations syntaxiques et illustrées par 880 000
exemples tirés du corpus.

Parmi les limitations de ce dictionnaire, nous avions noté la présence de cooccurrences incompletes:
l’eXtracteur ne considérant que les associations de deux mots, il lui arrivait de générer des combinaisons
incompletes, auxquelles il manque un élément essentiel, comme dans prendre le taureau T, nager en
T de'lire ou T le feu aux poudres. Ces cooccurrences avaient été soit rejetées par le linguiste, soit
augmentées manuellement par l’aj out du mot manquant.

Pour la deuxieme édition de notre dictionnaire de cooccurrences, parue en 2009 avec Antidote HD, nous
avons revu notre processus d’eXtraction afin d’eXtraire automatiquement des cooccurrences de plus de
deux mots. Le present article décrit la démarche entreprise pour arriver 51 ce résultat.

2 Travaux antérieurs

La plupart des travaux sur les collocations (en anglais multi—w0rd expression [MWE]) ont porté sur les
combinaisons de deux mots. Tutin (2008) analyse les collocations de plus de deux mots et conclut qu’elles
peuvent le plus souvent étre considérées comme des combinaisons binaires respectant une structure
prédicat—argument. Selon elle, la majorité des collocations n—aires peuvent étre analysées comme des
superpositions de collocations ou comme des collocations récursives, tandis que quelques cas sont de
Vraies collocations n—aires, ou la séquence ne peut pas étre décomposée.

Dans la tﬁche d’eXtraction de collocations 51 partir de corpus, les mesures statistiques d’association
employées pour quantifier le degré de cohésion — et donc de pertinence — des combinaisons candidates
sont pour la plupart formulées pour évaluer les associations de deux éléments (ou bigrammes). De
nombreuses études ont comparé les performances de diverses mesures d’association. Dans l’une des plus
ambitieuses, Pecina et Schlesinger (2006) ont évalué 82 mesures dans une téche d’eXtraction de
collocations en tcheque, et ont combiné les plus performantes 51 l’aide de techniques d’apprentissage.

Les choses se compliquent lorsque Vient le temps de mesurer la force d’association de combinaisons de
plus de deux mots. Deux grandes approches sont possibles: 1) employer des mesures statistiques plus

1 Logiciel d’aide 51 la redaction grand pulic (www.antidote.info), sixieme edition.

2 Par cooccurrence, nous entendons la presence simultanée et statistiquement significative, dans un corpus, de deux unités
linguistiques ou plus en relation syntaxique. Notre concept de cooccurrence englobe des combinaisons lexicales dont le
degré de figement est variable : nous y incluons 51 la fois des combinaisons libres (entendre un cri), des combinaisons semi-
figées ou collocations au sens strict (pousser un cri) et des locutions figées courantes (cri du coeur) ou terminologiques (cri

primal).

AU—DELA DE LA PAIRE DE MOTS I EXTRACTION DE COOCCURRENCES SYNTAXIQUES MULTILEXEMIQUES

complexes formulees pour evaluer les associations d’un nombre arbitraire d’elements; ou 2) employer des
mesures d’association de bi grammes sur des groupes de mots plutet que sur des mots individuels.

La premiere approche a ete suivie par Dias et coll. (2000), qui ont propose une normalisation de quatre
mesures d’association courantes (le coefficient de Dice, l’information mutuelle specifique, (I32 et le rapport
de vraisemblance) afin de pouvoir calculer la cohesion de n—grammes pour n >= 2. La normalisation est
effectuee en considerant toutes les facons possibles de diviser un n—gramme en 2 sous—groupes (creant
ainsi des « pseudobigrammes >>), et en prenant la moyenne arithmetique des frequences de toutes les
combinaisons possibles. Ils ont en outre introduit une nouvelle mesure, l’expectative mutuelle, calculee
selon le meme principe et donnant, selon leurs tests, de meilleurs resultats que les mesures classiques.

Dans la meme veine, Blaheta et Johnson (2001) ont employe un modele log—lineaire pour l’extraction de
locutions verbales en anglais. Les modeles log—lineaires permettent de mettre en evidence des interactions
complexes entre plusieurs variables. Villada Moiron (2005) a compare des modeles bigrammes et
trigrammes pour l’extraction de locutions verbales et prepositionnelles en neerlandais. Parmi les modeles
tri grammes, elle a teste deux mesures (l’information mutuelle specifique et le test du Chi—carre de Pearson)
qu’elle a etendues aux trigrammes, de meme que le modele log—lineaire de Blaheta et Johnson (2001).
D’apres ses tests, le modele bi gramme utilisant le rapport de vraisemblance a donne les meilleurs resultats.

A propos du rapport de vraisemblance, il est interessant de noter qu’il est en fait mathematiquement tres
similaire a l’information mutuelle3. Dans la formulation de Dunning (1993), reprise dans Manning et
Schutze (1999), le rapport de vraisemblance est exprime comme le rapport entre les probabilites de deux
hypotheses, modelisant respectivement l’independance et la dependance de deux evenements. Comme
telle, la formule s’applique mal a plus de deux evenements. Mais, comme le mentionnent Moore (2004) et
Evert (2005), le rapport de vraisemblance (G2) peut etre reformule, par une serie de derivations, sous une
forme presque equivalente a celle de l’information mutuelle de deux variables aleatoires (MJ.).

Equation 1 : information mutuelle Equation 2 : rapport de Vraisemblance
de deux variables aléatoires (log-likelihood ratio) pour deux événements
M.I.=— f..logT" G2 =2 f..logT"
N  U ft;  U :2

L’avantage de cette reformulation est qu’elle peut s’etendre aux n—grammes de degre superieur.
Cependant, avec n >= 3, il existe plus d’une facon de modeliser l’hypothese nulle (Banerjee et Pedersen,
2003). Par exemple, pour n=3, on peut considerer le modele ou les trois mots sont mutuellement
independants, mais aussi trois autres modeles ou une paire de mots est dependante, mais independante du
tro1s1eme.

Le nombre de modeles a considerer, de meme que le nombre de frequences marginales a calculer,
augmente rapidement avec n, ce qui rend l’approche n—gramme plus complexe. C’est pourquoi plusieurs
auteurs ont prefere le modele bi gramme.

3 A ne pas confondre avec l’<< information mutuelle spécifique » (PA/II, pointwise mutual information), qui est une mesure de

dépendance entre deux événements X = x et Y = y. En théorie de l’information, l’information mutuelle mesure la
dépendance de deux variables aléatoires X et Y, et correspond 51 la valeur espérée des Pl\/II sur l’ensemble de toutes les
éventualités de X et Y.

Simon CHAREST, Eric BRUNELLE, Jean FONTAINE

Mettant a contribution l’analyseur syntaxique profond F ips, Seretan et coll. (2003) décrivent une méthode
itérative pour extraire des cooccurrences multimots. Tous les bigrammes candidats sont d’abord extraits,
puis, dans un processus itératif, des (11 + 1)— grammes sont construits a partir de n— grammes partageant n — 1
mots. Les n—grammes ainsi combinés sont exclus des résultats, la procédure ne conservant que les
combinaisons les plus longues. Le rapport de Vraisemblance est employé comme mesure de pertinence des
combinaisons extraites. Pour un n— gramme de plus de 2 mots, ce score est calculé a partir des fréquences
des (11 — 1)— grammes le composant. Par rapport a des techniques d’eXtraction basées sur des patrons
syntaxiques, leur méthode a l’aVantage d’étre souple, car aucune restriction n’est imposée sur la structure
syntaxique des combinaisons extraites. De plus, des relations syntaxiques éloignées sont prises en compte.

L’approche que nous avons employée se rapproche de celle de Seretan et coll. (2003). Comme eux, nous
employons un analyseur syntaxique. Nous avons aussi choisi de nous en tenir au modele bigramme, pour
sa simplicité. La prochaine section décrit la méthodologie que nous avons mise au point pour extraire les
cooccurrences multimots.

3 Méthodologie

3. 1 Analyse syntaxique

De 500 millions de mots pour la premiere édition, nous avons augmenté le corpus a 1,8 milliard de mots
ou 92 millions de phrases. Ces phrases ont été analysées par le moteur syntaxique d’Antidote, qui effectue
une analyse en dépendance et génere des arbres syntaxiques complets. Lorsque plusieurs analyses sont
trouvées pour une méme phrase, l’arbre le plus probable, selon la pondération de l’analyseur, est choisi.
Un arbre syntaxique complet correspond en fait a un ensemble de liens de dépendance entre les divers
mots de la phrase. Chaque lien unit un gouverneur (que nous appelons mere) a un dépendant (que nous
appelons fille), au moyen d’une relation syntaxique. Les liens correspondant aux relations syntaxiques les
plus pertinentes (sujet, COD, CO1, épithete, complément du nom, etc.) sont alors extraits de ces arbres et
entreposés dans une base de données. Au total, 440 millions de liens sont ainsi extraits, correspondant a 60
millions de combinaisons <mere — relation — fille> différentes, chaque combinaison apparaissant en
moyenne 7,3 fois dans le corpus. Par exemple, prenons la phrase << Le département joue un role de premier
plan. >>. L’arbre produit par l’analyseur syntaxique, ainsi que les relations pertinentes qui en sont extraites,
sont illustrés a la Figure 1.

/°ue\ jouer Sujet département
département role . jouer T COD m role

\
Le un /Jlaﬂ role Compl. du nom : plan
[ plan T Epithéte premier

de premier

Figure 1 : extraction des relations pertinentes

Au—dela des relations syntaxiques directes, le systeme s’efforce d’eXtraire des relations plus profondes.
Ainsi, on substitue a un pronom relatif son antécédent afin d’eXtraire la relation entre l’antécédent et le
Verbe de la relative (la femme qu’il a séduite 9 séduire une femme). Lorsqu’un nom agit comme agent

AU—DELA DE LA PAIRE DE MOTS I EXTRACTION DE COOCCURRENCES SYNTAXIQUES MULTILEXEMIQUES

d’un Verbe a l’infinitif, ce lien est transformé en relation << sujet >> (il incombe au juge de trancher 9 le
juge tranche). Lorsqu’une relation met en jeu un nom collectif ayant un complement, une relation directe
avec le complement est aussi générée (un groupe d’e'tudiants revendique 9 les étudiants revendiquent).

3.2 Inférence des cooccurrences intéressantes

L’idée principale de notre approche est la suiVante: plutot que d’utiliser, comme base de nos calculs
statistiques, des combinaisons de deux mots simples, nous travaillons avec des combinaisons de deux
arbres. Comme pour les combinaisons de mots, nous avons une mere et une fille, unies par une relation
syntaxique. Or, si chaque occurrence d’une relation correspond a une seule combinaison de mots, elle peut
correspondre a plusieurs combinaisons d’arbres. Par exemple, a la Figure 2, pour la relation entre B et D,
nous obtenons 8 combinaisons différentes, selon les branches que l’on inclut sous B et D.

B B B B

\ \ \ \

B D /D D\ /D\
A/ \D A C E C E
C/ \E /B\ /B\ /B\ /B\

A D A D A D A D
/ \ / \
C E C E

Figure 2 : toutes les combinaisons d ’arbres pour une relation donnée

Notre approche considere toutes les combinaisons possibles de tous les sous—arbres ayant pour téte chacun
des deux mots lies par une relation de dépendance. En théorie, la taille des arbres générés n’est limitée que
par la longueur et la structure des phrases du corpus. En pratique, nous avons decide de limiter les arbres
considérés a 5 mots maximum, pour raccourcir le temps de calcul et parce que les combinaisons trop
longues ont tendance a étre moins intéressantes linguistiquement. Les 60 millions de combinaisons de
mots différentes trouvées dans le corpus correspondent a 1,1 milliard de combinaisons d’arbres de
longueur 5 ou moins, chaque combinaison d’arbres apparaissant en moyenne 1,5 fois.

3.3 Calcul de la force en tenant compte de la dispersion

Comme pour les combinaisons de mots, nous calculons la force des combinaisons d’arbres a l’aide de la
Version bigramme du rapport de Vraisemblance. Nous avons fixé empiriquement un seuil, de facon a ne
conserver que les combinaisons les plus fortes. Nous excluons aussi les combinaisons ayant une fréquence
inférieure a 4, car les mesures d’association sont moins fiables lorsque les fréquences sont tres faibles. En
effet, Evert (2005) mentionne que les estimations de probabilités sont biaisées pour les évenements de
faible fréquence, et suggere fortement de toujours exclure les données de fréquencel ou 2. Le biais
diminue progressivement a mesure que monte la fréquence. A partir d’une fréquence de 5, le biais devient
minime et les mesures d’association se comportent bien.

Nous avions remarqué, pour la premiere edition de notre dictionnaire, que certaines cooccurrences ayant
une fréquence étonnamment élevée provenaient en fait d’un seul site Web (ou d’un nombre restreint de
sites) traitant d’un sujet particulier. Ces cooccurrences sont souvent inintéressantes linguistiquement, car

Simon CHAREST, Eric BRUNELLE, Jean FONTAINE

elles ne sont pas le reﬂet de la langue en général, mais d’une terminologie associée 51 un contexte
spécifique. Comme nous l’aVions fait alors, nous avons adapté le calcul de la force pour tenir compte de la
dispersion d’une combinaison 51 travers plusieurs sources, et ainsi réduire l’effet des cooccurrences trop
dépendantes du choix du corpus. A l’époque, nous avions implémenté un calcul de fréquence pondérée qui
correspondait 51 la somme des racines carrées des fréquences pour chaque source (Charest et coll., 2007).
Or, cette technique, en plus de ne pas étre fondée mathématiquement, avait le désavantage de compliquer
le calcul des fréquences, en particulier pour la phase de l’élagage (Voir section 3.4).

Cette fois—ci, nous employons comme mesure de dispersion l’écart de proportions (Deviation of
Proportions [DP]) de Gries (2008). Cette mesure, qui allie simplicité et ﬂexibilité, se calcule en prenant la
somme des différences entre les proportions espérée et observée d’un phénoméne dans chacune des
sources par rapport 2‘1l’ensemble du corpus.

Equation 3 : écart de proportions (DP)

ft _ ti
2 2;: Ex.
DP = ’ 2 ’ dispersion = 1- DP

ou 1",. est la fréquence d’une combinaison dans la source i et t,. est la taille de la source i. Gries (2008)
mentionne que la plupart des mesures de dispersion sont appliquées directement sur la fréquence pour
obtenir des fréquences dites ajustées; cependant, il n’est pas clair pour lui ce que représentent réellement
ces pseudofréquences. Plutot que de modifier les fréquences, nous avons donc choisi de multiplier
directement la Valeur de la force (calculée par le rapport de Vraisemblance avec les fréquences brutes) par
la Valeur de dispersion. Cette facon de faire, plus simple, nous apparait tout aussi Valable.

Enfin, mentionnons que le score calculé correspond 51 la relation entre la téte d’un l’arbre syntaxique et
l’une de ses filles. Lorsque la téte a plus d’une fille, chaque relation génére un score. Par exemple, dans
prendre ses jambes a son cou, on a deux filles branchées sur la méme mere. Ces deux branchements
correspondent aux interprétations [prendre ses jambes] + [£1 son cou] et [prendre 51 son cou] + [ses jambes].
Pour le besoin du filtrage statistique des cooccurrences, un seul score suffit. Nous choisissons alors le plus
élevé comme score de la cooccurrence.

3.4 Elagage

Certaines cooccurrences de plus de deux mots ne sont pas naturellement décomposables. Par exemple,
méme si les fréquences de prendre le taureau et prendre par les cornes sont nécessairement au moins
aussi élevées que la fréquence de prendre le taureau par les cornes, seule cette derniére est intéressante.

Pour élaguer ces combinaisons moins intéressantes, Silva et coll. (1999) ont introduit un algorithme
nommé LocalMaXs, qui sélectionne les combinaisons de n mots dont le score est 51 la fois supérieur ou égal
51 celui de toutes les combinaisons de n — 1 mots incluses dans celles—ci et supérieur 51 celui de toutes les
combinaisons de n + 1 mots dérivées de celles—ci. Cet algorithme leur évite aussi de devoir fixer un seuil
empiriquement : toutes les combinaisons satisfaisant 51 ces critéres sont conservées, peu importe leur score.

AU—DELA DE LA PAIRE DE MOTS I EXTRACTION DE COOCCURRENCES SYNTAXIQUES MULTILEXEMIQUES

De notre cote, nous avons plutot choisi de réduire la force des cooccurrences incompletes en modifiant
leur fréquence brute. Lorsqu’une cooccurrence complexe a une fréquence relativement élevée par rapport a
une cooccurrence plus simple incluse dans celle—ci, on recalculera le score de la cooccurrence plus simple
en prenant une fréquence modifiée qui ne tient pas compte des occurrences de la cooccurrence complexe.
Ainsi, pour prendre le taureau, on comptera seulement les occurrences ou cette combinaison n’est pas
accompagnée du complement par les cornes. Par contre, si aucune cooccurrence plus complexe n’a une
fréquence assez élevée par rapport a une cooccurrence simple, sa fréquence n’est pas réduite. Par exemple,
la fréquence de jouer un réle ne sera pas affectée par jouer un réle important, jouer un grand réle, jouer
un réle de premier plan, etc.

3.5 Détermination des attributs de forme

Outre les mots formant la cooccurrence, nous notons certaines données morphosyntaxiques qui définissent
la distribution de ses emplois. Nous retenons ainsi, pour chaque cooccurrence, les types des determinants,
le genre, le nombre et la casse de chaque mot, la position relative de ceuX—ci, la presence de clitiques (en,
y), de pronoms réfléchis (se, s’) ou de particules negatives autour des verbes, etc. Ces données déterminent
la formulation la plus fréquente de la cooccurrence, qui sera utilisée pour générer la forme finale de la
cooccurrence au moment de son affichage.

3.6 Révision manuelle

Les cooccurrences qui ne faisaient pas partie de la premiere edition du dictionnaire ont toutes été révisées
par une équipe de linguistes. Les cooccurrences incompletes, inintéressantes, délicates (offensantes,
Vulgaires, etc.), fautives (impropriétés, calques, pléonasmes, etc.) ou resultant d’une mauvaise analyse
syntaxique ont été retranchées. Comme on pouvait s’y attendre, les mauvaises analyses sont plus
fréquentes pour les cooccurrences de plus de deux mots. Meme si une forme peut sembler correcte en
surface, lorsque l’on examine en detail la structure syntaxique, on découvre parfois un mauvais
branchement ou la substitution d’un mot par son homographe. Dans ce dernier cas, un mécanisme permet
au linguiste de corriger la situation en transférant la cooccurrence sur le bon mot. Le linguiste a aussi la
possibilité de modifier les attributs des mots de la cooccurrence qui ont été choisis automatiquement (les
determinants, la flexion, la casse, etc.). Enfin, le linguiste a aussi pour tache de classer les cooccurrences
des mots polysémiques selon leurs divers sens.

4 Résultats

Du 1,1milliard de combinaisons d’arbres identifiées par le systeme, 4,2 millions sont a la fois assez
fréquentes et assez fortes pour étre conservées dans notre base de données. Ces cooccurrences se
répartissent comme suit : 49,0 % sont de 2 mots, 42,1 % de 3 mots, 7,5 % de 4 mots et 1,4 % de 5 mots. A
ce jour, 952 000 cooccurrences ont été revues par un linguiste, en procédant par ordre décroissant de force.
Parmi celles—ci, 55 000 (5,8 %) ont été rejetées, car inintéressantes; 25000 (2,6 %) ont été identifiées
comme étant de mauvaises analyses; 10 000 (1,1 %) ont été jugées incompletes. Au total, 862 000
cooccurrences, dont 783 000 de deux mots (90,8 %)4, ont été retenues et font partie de la présente edition.

4 La proportion de cooccurrences de deux mots est plus élevée pour les cooccurrences retenues (90,8 %) que pour les

cooccurrences brutes (49,0 %), car la majorité d’entre elles faisait partie de la premiere édition et a été conservée.

Simon CHAREST, Eric BRUNELLE, Jean FONTAINE

5 Presentation des cooccurrences

Nous avons maintenu les principes de base que nous avions determines pour la presentation des
cooccurrences de la premiere edition et qui ont fait leurs preuves : affichage des cooccurrences completes
avec leurs attributs morphosyntaxiques reels, histogramme illustrant la force, regroupement par sens puis
par contexte syntaxique, affichage initial des 5 premieres cooccurrences de chaque groupe avec possibilite
d’afficher la suite en un clic, exemples reels tires du corpus presentes dans un panneau secondaire.

 

  
 

        
  

 
  

  

   

8 O O Antidote — Dictionnaires ' ‘
«-—v
Qv emission I‘-" ( V i  !
V
Redierche Historique Découvrir Imprimer Guides
l Dictionnaires Ill V Cooccurrences de emission (n. f.) Force V III Exemples de la cooccurrence
! Définitions 5 v » - . . .
> [TELECOMMUNICATIONS] Obiet (313) plus (6! H, nm._H.l' In Ruim,
! Locutions S
V [SCIENCES NATURELLESI Phénoméne (99)
! Synonymes 55
V Avec epithete (21)
! Amonymes 2 > emissions polluantes .
, . . . . . Ix l)L'\‘()II'.('()ln
A :;;_-_-_> _ ____-_._- _ _r_ emissions mondiales de gaz ci eftet de serre
. . emissions atmospheriques _ _ . . , 1
! Comugmson emissions anthropiques L“ pays (Want mime C
. . . . . mm ‘ol- r- r’i: ~ni -ni 5:3 "'.
! ramme 20 emissions nocives P _ ‘p ‘jg ‘V’  "
_J;§ moncli.-ilcs dc
! A"a'°9i°5 194 V Ave: complement nominal (.18)  i ,  (it-‘ 
! citations 15 emissions de gaz a effet de serre ‘ [_'|-jxlmn,-;‘,,,
. . reduire les emissions de gaz ii effet de serre
! msmnque 11 reduction des emissions de gaz J effet de. . on Park. ég‘-l|Cm,_.m dc |a
! Anagfammgs 9 diminuer les emissions de gaz ti effet de serre réduﬂion dc L1 pollution ct’
. emissions mondiailes de gaz a effet de serre L  ‘ A i_ l.~J~:.v_~»i
I Le “sue. 9 V, _ x ( (.l'nlLI‘(.|'hLl1I.( L _ _
ea quotas d emission de gaz zi effet de serre iii?“ ‘ mi. , .
(ic  .1  (ic 
> emissions de gaz \\'il\'iiM"<“-‘I
> emissions de dioxyde de carbone
> emissions de polluants [<05 CH0!-‘ P0l£‘nl|0l-‘:11:
> emissions de carbone lhugmo.-ntrition dc-s’ 
(lu R '‘l_ 21  (lc  font
V SW” "43’ l'ol)ict (ic <‘ontrovc-rscs entre
les emissions de gaz é effet de serre augmentent \_(_icnmiqucs_
les emissions proviennent de _ .
les émissions augmentem l.'l‘.iic_\'c|op6¢iic (iv l.'.-\goi';i
les emissions diminuent _
V complémem dim“ (10, l.c-gouxwrnenicnt lcdcml
y réduire les émissions (loit ctre lelicitc pour cc
MOIS Df°Ch€5 (2) Cat reduire les emissions de gaz ii effet de serre gcste lrés important Cn V
émission n. f. reduire les emissions polluantes ‘ . . . . ,
i€mlSSlOf‘|S v. les pays reduisent leurs emissions V i
A -9--. A emissions de gziz A effet (3 Rt-‘I‘iH3-J:-CC? ﬂ

 

© 2010 Druide informatique inc.
Figure 3 : interface du dictionnaire de cooccurrences d ’Antid0te HD

La seule adaptation que nous avons effectuee concerne l’affichage des cooccurrences de plus de deux
mots. Nous avons choisi de regrouper celles—ci sous une cooccurrence plus simple s’il en existe une dont la
force n’est pas trop faible par rapport a la force des cooccurrences plus complexes. Par exemple, a la
Figure 3, nous avons, sous le deuxieme sens de l’entree émission, a la relation << avec complement
nominal >>, la cooccurrence de 4 mots émissions de gaz ci eﬂet de serre, dont la force est tres elevee. Sous
elle, diverses cooccurrences de 5 mots comme réduire les émissions de gaz ci eﬂet de serre. Cette derniere

AU—DELA DE LA PAIRE DE MOTS I EXTRACTION DE COOCCURRENCES SYNTAXIQUES MULTILEXEMIQUES

cooccurrence se retrouve aussi a la relation << complement direct », sous la cooccurrence de 3 mots réduire
les émissions. En effet, le mot—vedette émission est a la fois complement direct de réduire et mere du
complement nominal de gaz ci eﬂet de serre. Notons que la cooccurrence de 4 mots émissions de gaz d
eﬂet de serre n’est pas classée sous la cooccurrence plus simple émission de gaz, car sa force est
significativement plus élevée que celle de cette demiere.

6 Conclusion et perspectives

Nous venons de presenter une technique originale pour l’extraction de cooccurrences de plus de deux mots
conservant une structure syntaxique complete. Notre approche se situe dans la meme veine que celle de
Seretan et coll. (2003), en ce sens qu’elle allie la sortie d’une analyse syntaxique profonde a un test
statistique applique sur deux groupes de mots, pour dégager des cooccurrences saillantes de plusieurs mots
pour lesquelles aucune restriction de structure syntaxique n’est imposée. Comme la leur, notre approche se
démarque donc des méthodes d’eXtraction multimot basées sur du texte brut ou simplement annoté
grammaticalement, qui par nature sont beaucoup plus restreintes syntaxiquement (Seretan, 2008).

Notre approche se distingue par contre a plusieurs points de vue. D’abord, la méthode que nous proposons
n’est pas recursive ni iterative: les cooccurrences plus complexes ne sont pas construites a partir de
cooccurrences plus simples. Nous avons plutot choisi l’approche combinatoire : pour une relation
syntaxique entre deux mots dans l’analyse d’une phrase, toutes les combinaisons de tous les sous—arbres
ayant pour téte chacun des deux mots sont évaluées. Le calcul des fréquences pour la mesure d’association
est aussi different. L’approche recursive de Seretan et coll. (2003) considere une cooccurrence complexe
comme étant formée de deux cooccurrences plus simples en intersection, et ce sont les fréquences de ces
deux cooccurrences qui sont utilisées dans la table de contingence. De notre cote, les fréquences utilisées
sont celles des deux arbres formant la cooccurrence, arbres qui sont nécessairement disjoints.

Parmi les améliorations envisagées, nous aimerions étendre le concept de cooccurrences a des
généralisations des arguments des fonctions syntaxiques. Par exemple, la cooccurrence avoir besoin pour
vivre, telle qu’eXtraite par notre systeme, semble incomplete. Elle a dﬁ étre augmentée manuellement par
un linguiste pour devenir avoir besoin de ggch. pour vivre. En généralisant les complements que prennent
les verbes a l’aide de pronoms génériques comme qqch. et qqn, nous espérons pouvoir inférer ces ajouts
automatiquement.

Remerciements

Nous tenons a remercier Mala Bergevin, Jean Saint—Germain, Maud Pironneau et toute l’équipe des
druides sans qui Antidote HD n’aurait pu voir le jour.

Simon CHAREST, Eric BRUNELLE, Jean FONTAINE

Références

BANERJEE S., PEDERSEN T. (2003). The Design, Implementation and Use of the Ngram Statistics Package.
Proceedings of the Fourth International Conference on Intelligent Text Processing and Computational
Linguistics, 370-381.

BLAHETA D., JOHNSON M. (2001). Unsupervised learning of multi-word Verbs. Proceedings of the ACL
Workshop on Collocations, 54-60.

CHAREST S., BRUNELLE  FONTAINE J ., PELLETIER, B. (2007). Elaboration automatique d’un dictionnaire
de cooccurrences grand public. Actes de la I4e confe'rence sur le Traitement Automatique des Langues
Naturelles (TALN 2007), 283-292.

Dms G., GUILLORE S., PEREIRA LOPES, J. G. (2000). Normalization of Association Measures for
Multiword Lexical Unit Extraction. International Conference on Artiﬁcial and Computational Intelligence
for Decision Control and Automation in Engineering and Industrial Applications (ACIDCA 2000), 207-
216.

DUNNING, T. (1993). Accurate methods for the statistics of surprise and coincidence. Computational
Linguistics 19, 61-74.

EVERT S. (2005). The Statistics of Word Cooccurrences : Word Pairs and Collocations. These de doctorat,
Université de Stuttgart.

GRIES, S. (2008). Dispersions and adjusted frequencies in corpora. International Journal of Corpus
Linguistics, Vol. 13, no 4, 403-437.

MANNING C., SCHUTZE H. (1999). Foundations of Statistical Natural Language Processing. Cambridge :
The MIT Press.

MOORE R. C. (2004). On log-likelihood-ratios and the significance of rare events. Proceedings of the 2004
Conference on EMNLP, 333-340.

PECINA P., SCHLESINGER P. (2006). Combining association measures for collocation extraction.

Proceedings of the 21th International Conference on Computational Linguistics and 44th Annual Meeting
of the Association for Computational Linguistics (COLING/ACL 2006 ), 651-658.

SERETAN V. (2008). Collocation extraction based on syntactic parsing. These de doctorat, Université de
Geneve.

SERETAN V., NERIMA L., WEHRLI E. (2003). Extraction of Multi-Word Collocations Using Syntactic
Bigram Composition. Proceedings of the Fourth International Conference on Recent Advances in NLP
(RANLP—2003), 424-43 1.

SILVA J., Dms G., GUILLORE S., PEREIRA LOPES, J. G. (1999). Using LocalMaxs Algorithm for the
Extraction of Contiguous and Non-contiguous Multiword Lexical Units. Proceedings of 9th Portuguese
Conference in Artificial Intelligence, 21-24.

TUTIN A. (2008). For an extended definition of lexical collocations. Proceedings of the XIII Euralex
International Congress (Barcelona, 15-19 July 2008), 1453-1460.

VILLADA MOIRON B. (2005). Data—driven Identiﬁcation of ﬁxed expressions and their modiﬁability. These
de doctorat, Université de Groningue.

