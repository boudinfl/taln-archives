TALN 2010, Montréal, 19-23 juillet 2010

Une approche cognitive de la fouille de grandes collections de
documents

Adil El Ghalil Yann Vigile Hoareau1’2
(1) Lutin User Lab, Cité des Sciences, AV C. Cariou, 75019 Paris
(2) Université Paris 8, rue de la Liberté, 93200 Saint Denis
elghali@lutin-userlab.fr, hoareau@lutin-userlab.fr

Résumé. La récente éclosion du Web2.0 engendre un accroissement considérable de volumes tex-
tuels et intensiﬁe ainsi l’importance d’une réﬂexion sur l’exploitation des connaissances a partir de grandes
collections de documents. Dans cet article, nous présentons une approche de rechercher d’information qui
s’inspire des certaines recherches issues de la psychologie cognitive pour la fouille de larges collections
de documents. Nous utilisons un document comme requéte permettant de récupérer des informations a
partir d’une collection représentée dans un espace sémantique. Nous déﬁnissons les notions d’identité sé-
mantique et de pollution sémantique dans un espace de documents. Nous illustrons notre approche par
la description d’un systeme appelé BRAT (Blogosphere Random Analysis using Texts) basé sur les no-
tions préalablement introduites d’identité et de pollution sématique appliquées a une tache d’identiﬁcation
des actualités dans la blogosphere mondiale lors du concours TREC’09. Les premiers résultats produits
sont tout a fait encourageant et indiquent les pistes des recherches a mettre en oeuvre aﬁn d’améliorer les
performances de BRAT.

Abstract. Mining Web 2.0 content become nowadays an important task in Information Retrieval and
Search communities. The work related in this paper present an original approach of blogs mining, inspired
from researches in cognitive psychology. We deﬁne the notions of semantic identity of blogs, and the
semantic pollution in a semantic space. Then, we describe a system called BRAT (Blogosphere Random
Analysis using Texts) based on these notions that has been applied to the Top Stories identiﬁcation task of
the Blog Track at the TREC’09 contest. The performance of BRAT at TREC’09 in its preliminary stage
of development are very encouraging and the results of the experiences described here-after draw the lines
of the future researches that should be realized in order to upgrade its performances.

M0tS-CléS I Fouille de textes, Random-Indexing, Cognition, Marche aléatoire.

Keywords: Text-Mining, Random-Indexing, Cognition, Random walk.

1 Introduction

Dans le present article, nous nous intéressons a la recherche d’informations dans de grandes collections
de documents en utilisant un ou plusieurs documents comme requéte. Nous déﬁnissons un systeme a deux
modules pour réaliser cette tache. Le premier module distribue et représente les documents textuels dans
des espaces sémantiques construits avec la méthode Random Indexing (RI) (Kanerva et al., 2000). Le

ADIL EL GHALI, YANN VIGILE HOAREAU

deuxieme module réalise la recherche des documents en utilisant une marche aléatoirel pour parcourir
l’espace sémantique et trouver les éléments en rapport avec une requéte donnée, composée d’un ou plu-
sieurs documents. Le systeme a été construit en s’appuyant sur deux hypotheses de travail que nous consi-
dérons importantes lorsqu’il est question de traiter la sémantique de grandes collections de documents :
les notions d’identité sémantique et de pollution sémantique.

L’ article est organisé comme suit. Dans la premiere partie, nous présentons brievement les modeles d’es-
paces sémantiques utilisés ainsi que leurs propriétés. Nous déﬁnissons ensuite les notions d’identité sé-
mantique et de pollution sémantique qui donnent quelques unes des propriétés principales de l’espace
sémantique. Nous décrivons également dans cette partie comment utiliser des documents en tant que re-
quétes. Dans la deuxieme partie, nous présentons une instanciation de notre systeme concu pour aborder la
tache d’identiﬁcation des dépéches d’actualité 2 dans le cadre du TREC’09, nommé BRAT (Blogosphere
Random Analysis using Texts). La troisieme partie décrit les propriétés et les performances des différentes
exécutions souIr1ises dans le cadre du TREC’09.

2 La cognition de la fouille de textes

2.1 Les espaces sémantiques

Les modeles de représentation vectorielle de la sémantique des mots sont une famille de modeles qui
représentent la similarité sémantique entre les mots en fonction de l’environnement textuel dans lequel
ces mots apparaissent. La distribution de co-occurrence des mots dans le corpus est rassemblée, analysée
puis transformée en espace sémantique dans lequel les mots sont représentés comme des vecteurs dans
un espace vectoriel de grande dimension. LSA (Landauer & Dumais, 1997), HAL (Lund & Burgess,
1996) et RI (Kanerva et al., 2000) en sont quelques exemples. Ces modeles sont basés sur l’hypothese
distributionnelle de (Harris, 1968) qui afﬁrme que les mots qui apparaissent dans des contextes similaires
ont un sens similaire. La caractérisation de l’unité de contexte est une problematique commune a toutes ces
méthodes, sa déﬁnition est différente suivant les modeles. Par exemple, LSA construit une matrice mot-
document dans laquelle chaque cellule a,-j contient la fréquence d’un mot i dans une unité de contexte
j. HAL déﬁnit une fenétre ﬂottante de n mots qui parcourt chaque mot du corpus, puis construit une
matrice mot-mot dans laquelle chaque cellule a,-j contient la fréquence a laquelle un mot i co-occure
avec un mot j dans la fenétre précédemment déﬁnie. Différentes méthodes mathématiques et statistiques
permettant d’eXtraire la signiﬁcation des concepts, en réduisant la dimensionnalité de l’espace de co-
occurence, sont appliquées a la distribution des fréquences stockées dans la matrice mot-document ou
mot-mot. Le premier objectif de ces traitements mathématiques est d’extraire les «patrons» qui rendent
compte des variations de fréquences et qui permettent d’éliminer ce qui peut étre considéré comme du
« bruit ». LSA emploie une méthode générale de décomposition linéaire d’une matrice en composantes
indépendantes : la décomposition de valeur singuliere (SVD). Dans HAL la dimension de l’espace est
réduite en maintenant un nombre restreint de composantes principales de la matrice de co-occurrence. A la
ﬁn de ce processus de réduction de dimensionnalité, la similitude entre deux mots peut étre calculée selon
différentes méthodes. Classiquement, la valeur du cosinus de l’angle entre deux vecteurs correspondant a
deux mots ou a deux groupes de mots est calculée aﬁn d’approximer leur similarité sémantique.

1. Random Walk
2. Top—stories identiﬁcation task

FOUILLE DE GRANDES COLLECTIONS DE DOCUMENTS

2.2 La notion d’identité sémantique

Lors de l’utilisation de méthodes d’espaces sémantiques pour représenter le sens, nous avons commence
a exposer ci-dessus la l’idée selon laquelle la sémantique produite pour un mot donné dépend de la distri-
bution des autres mots avec lesquels il co-occure. Par conséquent, quelque soit le mot, aucune sémantique
ne peut étre produite ex nihilo, c’est-a-dire sans la réalisation d’une phase d’apprentissage appliquée a
une distribution de contextes ou d’épisodes donnée. La sémantique ﬁnale associée a un mot dispose ainsi
d’une identité forgée tout au long de la phase d’apprentissage, qui est réalisée par la SVD pour LSA ou
par le procesus d’accumulation pour RI. L’identité sémantique d’un mot donné change en fonction du
corpus dans lequel on le retrouve. En prenant l’exemple concret des espaces sémantiques de l’université
du Colorado Boulder3 disponibles en libre acces. Les cinq plus proches voisins du mot «table» dans le
«Biology HS betatest » (articles scientiﬁques) sont : table (0.98), listed (0.80), summarized (0.68), detail
(0.47), following (0.46) 4. En revanche, le corpus du «General Reading up to 1st year of college » (ma-
nuels de lecture) donne comme voisins : table (0.98), tables (0.68), centerpiece (0.65), dinnerware (0.62),
tablecloth (0.61) 5. Il est aisé de s’apercevoir que les identités sémantiques du mot «table» dans les deux
corpus sont tres différentes.

La notion d’identité sémantique s’applique non seulement a l’échelle des mots mais également l’échelle
de l’espace sémantique. Un espace sémantique dispose d’une identité spéciﬁque qui lui est donné par la
distribution de la co-occurrence des mots dont il est composé.

2.3 La notion de pollution sémantique

La notion d’identité sémantique n’est pas révolutionnaire pour des chercheurs familiers avec les espaces
sémantiques et pourrait sembler quelque peu triviale si elle ne faisait pas ressortir une seconde notion
que nous appellerons « pollution sémantique». Dans le précédent exemple d’un espace sémantique Inixte,
scientiﬁque et général, l’identité sémantique du mot «table» est constituée autant par la sémantique re-
lative a la science que par celle de la vie quotidienne. Dans un espace sémantique général, si un mot est
similaire au mot «table», l’on peut supposer que ce mot n’est pas tres éloigné du mot «vaisselle» dans l’es-
pace sémantique. Dans un espace sémantique Inixte, une telle supposition parait moins raisonnable, car la
sémantique du mot «table» a été d’une certaine maniere «polluée» par la partie scientiﬁque du corpus.

On pourrait soutenir que la pollution sémantique n’est autre que de la polysémie. Cela est vrai dans le cas
du mot «table» parce que c’est un mot polysémique, toutefois la pollution de l’identité du mot «table»
a pour effet de polluer l’identité de mots sémantiquement proches du mot «table» tels que «récapitulé»,
«énuméré», «vaisselle», «maison», etc. Ces mots ne sont pas des mots polysémiques mais leurs identités
sémantiques se retrouveront polluées aussi. A cause du mot «table», des mots tels que «récapitulé» peuvent
étre éventuellement semblables au mot «vaisselle» dans un espace sémantique Inixte (Beyer et al., 1999;
Giannella, 2009). En conclusion, la pollution sémantique adresse non seulement l’échelle du mot mais
également l’échelle de l’espace sémantique et de sa structure.

3. http ://lsa.colorado.edu/
4. «table» (0,98), «énuméré» (0,80), «récapitulé» (0,68), «détajl» (0,47), <<suiVant» (0,46)
5. «table» (0,98), «tables» (0,68), «centre de table» (0,65), «vaisselle» (0,62), «nappe» (0,6l)

ADIL EL GHALI, YANN VIGILE HOAREAU
2.4 Des documents comme requétes

Dans de nombreuses applications, l’utilisateur qui recherche des documents dans une grande collection
dispose d’un ou plusieurs documents qui peuvent étre utilisés comme requéte. Dans l’application décrite
dans la section 4 : la tache d’identiﬁcation des dépéches importantes6 dans le cadre de la Blog-Track
du TREC’09, l’utilisateur cherche a extraire les posts de blogs qui sont pertinentes étant donné une dé-
péche d’actualité. Dans ce cas, la dépéches peut étre utilisé comme requéte pour rechercher les éléments
pertinants dans l’espace sémantique représentant la blogosphere. Aﬁn d’étre en mesure d’utiliser ces do-
cuments en tant que requéte, nous avons besoin pour représenter documents dans l’espace de recherche.
Dans un espace sémantique, les mots sont représentés par des vecteurs dans un espace de dimension n.
Cette représentation peut étre étendu a documents en associant a chaque document le vecteur correspon-
dant a la somme des mots qu’il contient (Rehder et al., 1998). Le vecteur d’un document est ainsi donné

par :

17d = Z 17., (1)

wed

Cette représentation permet de réaliser les mémes calculs sur les documents que sur les mots dans l’es-
pace sémantique. De plus, l’espace les documents composés par les vecteurs des documents ales mémes
propriétés que l’espace les mots. Les notions de l’identité sémantique et de la pollution sémantique sont
naturellement étendues aux documents.

3 BRAT

BRAT représente dans un méme espace sémantique la production de la blogosphere et la production
journalistiques aﬁn de permettre d’identiﬁer pour chacune des dépéches, les posts de blogs pertinents.
I1 construit des représentations l’identité sémantique liée a l’actualité du point de vue de la blogosphere et
du point de vue de la production joumalistique, puis établit la pertinence des posts en fonction (i) de leur
similarité sémantique avec la dépéche, (ii) de la proximité des posts par rapport a l’identité sémantique
du point de vue de la blogosphere et (iii) de la proximité des posts par rapport a l’identité sémantique du
point de vue de la production journalistique.

3.1 Construction des espaces sémantiques

La méthode de construction d’espace sémantique utilisé est Random Indexing (RI), qui est relativement

éloignée des autres méthodes de construction d’espaces sémantiques. Ses particularités sont (i) qu’elle

ne construit pas de matrice de co-occurrence et (ii) qu’elle ne nécessite pas, contrairement aux autres

modeles vectoriels de représentation sémantique, des traitements statistiques lourds comme la SVD pour

LSA. RI est basée sur la projection aléatoire (Bingham & Mannila, 2001), qui permet un meilleur passage

a l’échelle pour grand nombre des documents. La construction d’un espace sémantique avec RI se déroule

comme suit :

— Créer une matrice A(d X n), contenant des vecteurs indexes, 011 d est le nombre de documents ou de
contextes et n le nombre de dimensions choisies par l’expérimentateur. Les vecteurs indexes sont des
vecteurs creux générés aléatoirement.

6. Top—stories identiﬁcation task

FOUILLE DE GRANDES COLLECTIONS DE DOCUMENTS

— Créer une matrice B(t X n), contenant des vecteurs termes, ou t est le nombre de termes différents dans
le corpus. Initialiser tous ces vecteurs avec des valeurs nulles pour démarrer la construction de l’espace
sémantique.

— Pour tout document du corpus. Chaque fois qu’un terme 7' apparait dans un document 6, accumuler le
vecteur index de 6 au vecteur terme de 7' .

a la ﬁn du processus, les vecteurs termes qui apparaissent dans des contextes similaires ont accumulé des

vecteurs indexes similaire.

RI a été appliqué avec succes au test de synonymie du TOEFL (Kanerva et al., 2000) ainsi que dans la
categorisation de textes (Sahlgren & Coster, 2004; Hoareau et al., 2009b,a; El Ghali et al., 2009)

Dans notre application, pour chaque date D un espace sémantique S S D est construit en utilisant la librairie
Semantic Vectors 7 (Widdows & Ferraro, 2008). Celui-ci contient toutes les dépéches de la journée et tous
les posts dans une fenétre [D — 1, D + 1].

3.2 Un random walk dans les espaces sémantiques

Une fois l’espace sémantique SSD d’une journée D construit, nous utilisons un algorithme de marche
aléatoire pour naviguer dans l’espace aﬁn de récupérer pour chaque titre 12 posts pertinents.

Nous appellons prototype d’un ensemble de documents d’une catégorie (posts de blogs ou dépéches), c’est
un pseudo-document représenté dans l’espace sémantique par la somme de tous les vecteurs de l’ensemble.
Par exemple, le prototype de toutes les dépéches est un document pseudo PH représentée par le vecteur :

P; = Z I? <2)
heH
avec H l’ensemble contenant toutes les dépéches de SS ,3.

I-/3tant donné une dépéche hi 6 SSD et 7} E N, nous appelons 1}-voisinage de hi pour un prototype P,
l’ensemble des posts déﬁni comme suit :

_ _ d P, hi
r}—vo1s1nage(hi, P) = {bi-|d(bj, hi) <  (3)

avec d(di, dj) la distance euclidienne entre les vecteurs  and 

Aﬁn de récupérer les n posts pertinents pour la dépéche hi, nous choisissons un seuil m > 72, et nous
parcourons aléatoirement l’ensemble IE3 contenant tous les posts de S S D, jusqu’a trouver m posts candidats
dans l’r}-voisinage de hi pour le prototype PH de toutes les dépéches. Si nous avons trouvé m posts
candidats, nous déﬁnissons le score pi de hi comme le nombre de pas effectués dans IE3. Si le nombre de
posts récupérés est m’ < m, alors le score pi de ti est déﬁnie par :

pi = card(B) — m’ (4)

Le premiere application de BRAT dans le cadre du TREC’09 vise essentiellement a tester l’effet du para-
metre 7}-voisinage. Une description en sera donnée dans la section suivante.

7. http: //code . google . com/p/semanticvectOrs/

ADIL EL GHALI, YANN VIGILE HOAREAU

4 Application in la fouille de Blogs

Le modele BRAT a ete applique a la tache d’identiﬁcation des depeches dans le cadre du TREC’09. Les
objectifs sont de detecter, pour une joumee de publication, les depeches importantes du NewYork Times
(NYT) a partir de l’analyse de la blogosphere et pour chacune des depeches consideree comme importante,
de proposer une dizaine de blogs pertinents.

L’experience rapportee ci-apres est le resultat de la participation a un concours, elle n’a donc pas pour
objectif d’evaluer systematiquement l’effet de chacun des parametres du modele. Mais plut6t a veriﬁer
quelques hypotheses et a eclairer des pistes de travail pour les recherches futures.

4.1 Les hypothéses

Pour chaque journee de publication un espace semantique est construit a partir des posts produits dans une
fenetre de trois jours et des titres du NYT pour la journee. Une representation de l’identite semantique de
la blogosphere pour cette fenetre est approximee en creant un prototype PH contenant tous les posts de la
fenetre. Une representation de l’identite semantique semantique correspondant a «la vision» de l’actualite
par le NYT est approximee un prototype PH (cf 3.2).

Les executions souIr1ises correspondent a differentes hypotheses concernant l’organisation de la connais-
sance dans l’espace semantique construit a partir de la blogosphere. Les hypotheses qui ont guide ce travail
sont les suivantes : (i) Le voisinage de PH est dense et pollue. Il est donc preferable de recruter des blogs
qui ne sont pas dans ce voisinage. De plus, differents facteurs devraient ameliorer la precision de BRAT :
(ii) l’augmentation de la contrainte sur la proximite du voisinage de PH pour le recrutement des blogs (plus
17 est petit); (iii) la fusion des resultats produits a partir de l’augmentation successives de la contrainte sur
le voisinage au prototype (methode d’adaptative) ; (iv) La combinaison de la contrainte sur le voisinage de
PH et sur le voisinage de PH ; (v) L’ augmentation de la dimension de l’espace semantique.

Ces hypotheses ont ete implantes dans les differentes executions decrites dans la sous-section 4.4.

4.2 La collection

La collection Blog08 (cf. Table 1) a ete consrtuite par l’aspiration de la blogosphere pendant plus d’un an.
Elle est composee de trois elements : feeds correspondant a l’ensemble des resume des posts d’un blog,
permalinks correspondant aux posts de blogs et homepages contenant les pages d’accueil des auteurs.

La collection # d’elements Taille
Feeds 1.303.520 808GB
Permalinks 28.488.766 1445GB
Homepages 1.011.733 56GB

TABLE 1 — Caracteristiques de la collection Blogs08

Dans le cadre de nos experiences, seuls les documents Permalink (i.e. les posts de blogs) ont ete utilises.
Les espaces semantiques produits pour chaque joumees sont composes en moyenne de plus de 150 000
posts pour une centaine de titres.

FOUILLE DE GRANDES COLLECTIONS DE DOCUMENTS
4.3 L’évaluation
4.3.1 Description de la méthode

Les exécutions sont regroupées par les organisateurs puis redistribuées de telle facon a ce que les partici-
pants évaluent la validité des exécutions les uns des autres. L’ évaluation manuelle se déroule en plusieurs
phases.

Dans la premiere phase, l’ensemble des titres proposés par l’ensemble des équipes sont souInis aux évalua-
teurs aﬁn qu’ils déterminent les titres qui leur paraissent les plus importants pour la joumée. Il est demandé
aux évaluateurs de se mettre a la place d’un responsable de l’édition d’un journal et de décider, en fonction
de leurs connaissances générales ou d’autres ressources (intemet notamment), quels titres devraient étre
retenus comme important pour la joumée. A partir des jugements sur l’importance des titres, une premiere
évaluation des systemes est réalisée.

Dans la deuxieme phase, les jugements de l’importance des titres servent a établir la pertinence des blogs
proposés par les systemes. Les organisateurs regroupent les blogs associés aux titres ayant été jugés "im-
portants" lors de la premiere phase et les distribuent a l’ensemble des participants pour une évaluation
croisée. Pour chaque dépéche, les évaluateurs doivent juger de la pertinence des blogs qui lui Ont été as-
sociés. La consigne par défaut est de considérer comme pertinent, tout ce qui est en lien avec la dépéche.
Autrement dit, un blog qui partage un lien, méme ténu, avec la dépéche est considérer comme "pertinent".

4.3.2 Décalage entre la déﬁnition de la tﬁche et la consigne d’évaluation

L’évaluation telle qu’elle a été conduite s’appuye sur l’avis des participants-évaluateurs, a qui il a été
demandé de se positionner en tant que rédacteur-en-chef, pour décider de l’importance des titres 8 :

In essence, you should think like the editor of a newspaper or
news website. For each headline, make a decision about whether
the headline actually occurred on the query day, and whether you
would have placed it on the front page of your news website or
newspaper on that day

alors que l’objectif de la tache était explicitement d’indiquer les titres qui pourrait étre jugés importants
en tenant compte de ce que les blogeurs produisaient :
For a given unit of time (e.g. date), systems will be asked to
identify the top news stories (similar to what is displayed on

the main page of Google Blog Search or Google News), and provide
a list of relevant blog posts discussing each news story.

Il y a donc un décalage entre la consigne de la tache qui était d’identiﬁer les titres pertinents au regard
de ce qui est produit par la blogosphere et la consigne de l’évaluation qui est de se mettre a la place d’un
responsable de l’édition.

Il est important de noter que l’évaluation des blogs est dépendante de l’évaluation de l’importance des
titres ; augmentant ainsi l’effet du décalage sur l’importance des dépéches pour une joumée a l’évaluation
des blogs étant associés a ces titres. Ainsi, les blogs associés a des titres ayant été jugés non-importants

8.http://ir.dcs.gla.ac.uk/wiki/TREC—BLOG

ADIL EL GHALI, YANN VIGILE HOAREAU

dans la premiere phase de l’évaluation (du "point de vue de l’éditeur") ne sont jamais concemés par la
deuxieme phase d’évaluation portant sur les blogs.

Ce décalage entre la consigne de la tache et la consigne d’évaluation n’est pas sans poser probleme.
Comme l’ont montré (Balog et al., 2009), pour des jours comme ceux de la féte des meres ou les lende-
mains de compétitions, les échanges sur la blogosphere sont tres fortement impactés par ces thematiques.
Or, il est tout a fait probable qu’un événement majeur tel qu’un séisme ou qu’un scandale politique se pro-
duise pour ces mémes jours. L’ éditeur (et donc l’évaluateur) les considérera comme important tandis qu’un
grand nombre de blogeurs souhaiteront de joyeuses fétes a leur mere ou discuteront des performances de
leur équipe favorite.

Ainsi, ce décalage, tout a fait dépendant des choix des organisateurs, est de nature a contrarier l’apprécia-
tion sereine des performances des équipes et des systemes.

4.4 Description des exécutions

Les exécutions décrites ici correspondent aux différentes hypotheses de travail décrites dans la sous-section
4.1. Les hypotheses sur la constraintes de la restriction du voisinage au prototype des dépéches PH et au
prototype des blogs PB sont implantées en fonction des valeurs de 1} qui leur est associé.

Ainsi, ri1025rw2b correspond a une exécution qui choisit les blogs avec la seule contrainte qu’il soit
a une certaine distance par rapport au voisinage du prototype des blogs PB, avec 1} = 2. L’exécution
riI025rw5432 correspond a un algorithme adaptatif utilisant le méme principe, et o1‘1 les résultats de la
marche aléatoire avec 1} = 5, 4, 3, 2 sont combinés. L’exécution riI025rw5h2b utilise un algorithme si-
milaire, mais utilisant une fonction de voisinage correspondant a l’intersection du 5-voisinage par rapport
a PT et du 2-voisinage par rapport a P3. Tandis que les précédentes exécutions utilisaient un espace sé-
mantique a 1025 dimensions, l’exécution ri2049rw3 correspond a une application de l’algorithme dans un
espace de 2049 dimensions en prenant pour unique contrainte la distance au voisinage du prototype des
dépéches PH avec 1} = 3.

4.5 Résultats

Les résultats qui sont présentés ci-apres correspondent aux performances pour l’identiﬁcation des titres
importants pour une journée donnée. La mesure utilisées et R-précision@ 10 qui correspond a la valeur de
précision calculée pour 10 dépéches correctement identiﬁées. Les différentes caractéristiques des exécu-
tions décrites ci-apres ainsi que leur performances sont rappelées dans le Tableau 2.

ParIr1i les différentes méthodes testés, le nombre de dimension de l’espace sur lequel est appliqué la marche
aléatoire semble jouer un role déterminant. Ainsi, l’eXécution ri2049rw3 donne les meilleurs résultats. Par
ailleurs, la méthode adaptative qui combine les résultats de plusieurs marches aléatoires donne de meilleurs
résultats que la méthode qui réalise la marche aléatoire en prenant comme double contraintes les voisinage
a PT eta PB (respectivementri1025rw5432 et riI025rw5h2b) . Enﬁn, la seule contrainte sur le voisinage
de PB donne les moins bonnes performances (riI025rw2b).

FOUILLE DE GRANDES COLLECTIONS DE DOCUMENTS

Parametres de Brat Performance
EXécution Dimension de RI Valeur de 1} pour R-Precision@10 Position
PT | PB
ri1025rw2b 1025 X 2 0,0964 < Md
ri1025rw5h2b 1025 5 2 0,1145 < Md
ri1025rw5432 1025 ada{5-2} X 0,1200 > Md
ri2049rw3 2049 3 X 0,1182 > Md

TABLE 2 — Parametres des eXécutions, valeurs des R-Precision@10 et positionnement par rapport a la
Valeur médiane (Md) sur l’ensemble de participants a la Blog-Track.

5 Conclusion

Nous avons décrit une approche qui permet la recherche d’information dans des grandes collections de
documents représentées dans un espace sémantique et interrogées en utilisant une marche aléatoire. L’ ap-
proche consiste a construire avec RI un espace sémantique pour une journée de publication a partir des
posts de la blogosphere et des titres édités par un journal pour le meme jour aﬁn d’identiﬁer les titres les
plus importants.

BRAT construit une représentation de l’actualité du point de vue de la blogosphere et du point de vue
du journal et évalue la pertinence des titres et des blogs associés en prenant en compte leurs similarité
sémantique et leur proXiIr1ité avec la représentation de l’identité sémantique de l’actualité du point de vue
de la blogosphere ainsi qu’avec la représentation de l’identité sémantique de l’actualité du point de Vue du
journal. BRAT réalise une marche aléatoire dans l’espace sémantique et détermine l’importance d’un titre
en évaluant le nombre de blogs qui lui sont similaires étant donnée certaines contraintes dépendantes de
la marche. Les eXpériences réalisées ont montrées que les contraintes sur le voisinage lié a representation
de l’actualité du point de vue du journal est plus efﬁcace que les contraintes sur le voisinage liée a la
représentation de l’actualité du point de vue de la blogosphere et que la conjugaison de contraintes sur
le voisinage liés au deuX types de représentations améliore les résultats, de méme que l’utilisation de
méthodes adaptatives ou l’augmentation de la dimension de l’espace construit avec RI.

Ces différents éléments constituent autant de pistes de recherche qui nous permettrons d’améliorer notre
modele.

Remerciements

Cette recherche a bénéﬁcié de l’aide généreuse et solidaire des sociétés Thales et Pertimn ainsi que du Pole
de Compétitivité Cap-Digital de la Region Ile de France. Nous leur adressons nos sinceres remerciements.
Nous remercions par ailleurs tous les collegues du Lutin UserLab.

Références

BALOG K., BRON M., HE J., HOFMANN K.,ME1J E. J., DE RIJKE M., TSAGKIAS E. & WEERKAMP

ADIL EL GHALI, YANN VIGILE HOAREAU

W. (2009). The University of Amsterdam at TREC 2009 : Blog, web, entity, and relevance feedback. In
TREC 2009 Working Notes : NIST.

BEYER K. S., GOLDSTEIN J ., RAMAKRISHNAN R. & SHAFT U. (1999). When is ”nearest neighbor”
meaningful? In C. BEERI & P. BUNEMAN, Eds., ICDT, volume 1540 of Lecture Notes in Computer
Science, p. 217-235 : Springer.

BINGHAM E. & MANNILA H. (2001). Random projection in dimensionality reduction : Applications to
image and text data. In in Knowledge Discovery and Data Mining, p. 245-250 : ACM Press.

EL GHALI A., HOAREAU Y. & EL GHALI K. (2009). The Episodic Memory Metaphor for Opinion
Judgment Categorization. In IADIS International Conference WWW/Intemet (2), Rome.

GIANNELLA C. (2009). New instability results for high-dimensional nearest neighbor search. Inf Pro-
cess. Lett., 109(19), 1109-1113.

HARRIS Z. (1968). Mathematical Structures of Language. New York : John Wiley and Son.

HOAREAU Y., EL GHALI A., LEGROS D. & EL GHALI K. (2009a). Random Indexing and the episodic
memory metaphor. Application to text categorization. In A. ABDOLLAHZADEH & H. PEDRAM, Eds.,
IEEE CSICC 2009. I 4th International CSI, Teheran, Iran : IEEE.

HOAREAU Y. V., EL GHALI A. & TIJUS C. (2009b). Detection of opinions and facts. A cognitive
approach. In Recent Advance in Natural Language Processing (RANLP’09), Borovets, Bulgaria.

KANERVA P., KRISTOFERSON J. & HOLST A. (2000). Random Indexing of Text Samples for Latent
Semantic Analysis. In L. GLEITMAN & A. JOSH, Eds., Proceedings of the 22nd Annual Conference of
the Cognitive Science Society, Mahwah : Lawrence Erlbaum Associates.

LANDAUER T. K. & DUMAIS S. T. (1997). A Solution to Plato’s Problem : The Latent Semantic
Analysis Theory of Acquisition, Induction and Representation of Knowledge. Psychological Review,
104(2), 211-240.

LUND K. & BURGESS C. (1996). Producing high-dimensional semantic space from lexical co-
occurence. Behavior research methods, instruments & computers, 28(2), 203-208.

REHDER B., SCHREINER M., WOLFE M., LAHAM D., LANDAUER T. & KINTSCH W. (1998). Using

Latent Semantic Analysis to assess knowledge : Some technical considerations. Discourse Processes,
25(2), 337-354.

SAHLGREN M. & C(")STER R. (2004). Using bag-of-concepts to improve the performance of support
vector machines in text categorization. In COLIN G ’04 .' Proceedings of the 20th international conference
on Computational Linguistics, p. 487, Morristown, NJ, USA : Association for Computational Linguistics.

WIDDOWS D. & FERRARO K. (2008). Semantic Vectors : A Scalable Open Source Package and Online

Technology Management Application. In Proceeding of the Sixth International Conference on Language
Resources and Evaluation (LREC’08).

