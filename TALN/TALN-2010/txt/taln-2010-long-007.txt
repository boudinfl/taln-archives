TALN 2010, Montréal, 19–23 juillet 2010
Motifs de graphe pour le calcul de dépendances syntaxiques
complètes
Jonathan Marchand, Bruno Guillaume, Guy Perrier
INRIA Nancy-Grand Est - LORIA - Nancy-Université
Résumé. Cet article propose une méthode pour calculer les dépendances syntaxiques d’un énoncé
à partir du processus d’analyse en constituants. L’objectif est d’obtenir des dépendances complètes c’est-
à-dire contenant toutes les informations nécessaires à la construction de la sémantique. Pour l’analyse en
constituants, on utilise le formalisme des grammaires d’interaction : celui-ci place au cœur de la composi-
tion syntaxique un mécanisme de saturation de polarités qui peut s’interpréter comme la réalisation d’une
relation de dépendance. Formellement, on utilise la notion de motifs de graphes au sens de la réécriture de
graphes pour décrire les conditions nécessaires à la création d’une dépendance.
Abstract. This article describes a method to build syntactical dependencies starting from the phrase
structure parsing process. The goal is to obtain all the information needed for a detailled semantical
analysis. Interaction Grammars are used for parsing; the saturation of polarities which is the core of this
formalism can be mapped to dependency relation. Formally, graph patterns are used to express the set of
constraints which control dependency creations.
Mots-clés : Analyse syntaxique, dépendance, grammaires d’interaction, polarité.
Keywords: Syntactic analysis, dependency, interaction grammars, polarity.
Introduction
Quand on envisage l’analyse syntaxique en vue de produire une analyse sémantique complète de la phrase,
il est intéressant de représenter le résultat sous forme de dépendances entre mots. On s’abstrait ainsi de
tous les détails qui ne jouent pas de rôle dans le calcul de la sémantique afin de ne conserver que l’essentiel.
Mais alors, il est important de définir des structures en dépendances suffisamment riches pour permettre
un calcul fin et complet des relations sémantiques. La campagne PASSAGE 1 d’évaluation des analyseurs
syntaxiques du français utilise de façon essentielle de telles structures en dépendances. Les analyseurs
participants à la campagne devaient produire à la fois un découpage des phrases en groupes syntaxiques
et une annotation de ces phrases à l’aide de relations entre groupes ou mots 2. Une des difficultés était de
produire toutes les relations déterminées par la syntaxe, en particulier les moins immédiates comme celles
concernant les sujets des infinitifs par exemple. Le guide d’annotation de PASSAGE n’impose aucune
contrainte sur la structure de dépendances obtenue. De fait, la structure en dépendances obtenue est un
graphe qui n’est pas toujours un arbre ; il contient même parfois des cycles.
1. http://atoll.inria.fr/passage/index.fr.html
2. De fait, toutes les relations pouvaient être ramenées à des relations entre mots.
J. MARCHAND, B. GUILLAUME ET G. PERRIER
Il existe deux approches pour obtenir des analyses en dépendances. La première consiste à les calculer
directement. Or, pour des raisons d’efficacité, les analyseurs qui font cela imposent des contraintes sur
les structures en dépendances produites (Kübler et al., 2009; Debusmann, 2006). Généralement, ils ne
produisent que des arbres et ne permettent donc pas de retrouver toutes les relations nécessaires à la
construction d’une représentation sémantique. La seconde approche consiste à extraire une analyse en
dépendances à partir d’une analyse en constituants (Rambow & Joshi, 1997; Kučerová & Žabokrtský,
2002; Candito et al., 2009). Les relations de dépendances sont alors extraites de l’arbre syntagmatique de
la phrase, ce qui n’est pas toujours évident, mais surtout l’information pour produire certaines relations
peut être manquante.
La méthode que nous proposons s’apparente à la seconde approche dans la mesure où nous utilisons une
analyse en constituants. Cependant, comme Rambow & Joshi (1997) et Candito & Kahane (1998) l’ont
observé dans le cas des TAG il est souvent utile de ne pas s’appuyer seulement sur le résultat de l’analyse
mais sur le processus d’analyse lui-même, pour produire des dépendances. Notre méthode utilise le cadre
des Grammaires d’interaction (GI) et en exploite la spécificité : l’utilisation de polarités pour guider la
composition syntaxique. Nous avions, dans un précédent article (Marchand et al., 2009), montré comment
obtenir une analyse en dépendances en réalisant une dépendance entre deux mots à chaque fois que des
polarités qui étiquetaient les objets lexicaux correspondants se saturaient. Cette approche nous imposait
d’ajouter une nouvelle polarité au système de polarités des GI afin de repérer les saturations qui ne faisaient
que contrôler le contexte des mots lors de l’analyse et qui provoquaient une sur-génération de relations de
dépendances.
La méthode avait été testée sur une grammaire du français à relativement large échelle (Perrier, 2007) mais
les principes qui avaient présidé à la construction de cette grammaire n’avaient pas pris en compte l’ob-
jectif d’extraire des dépendances syntaxiques des analyses, dans la mesure où cet objectif est apparu après
que la grammaire ait été construite. Récemment, la grammaire a été revue afin d’intégrer des principes ex-
primant les dépendances syntaxiques. Cela a permis de se passer de la nouvelle polarité et a fait apparaı̂tre
des régularités structurelles dans la saturation des polarités donnant lieu à la production de dépendances.
Ces régularités ont été formalisées à l’aide du concept de motif de graphe (pattern en anglais dans l’idée
de pattern matching). Un motif est un ensemble de contraintes qui décrit le contexte structurel dans le-
quel deux polarités qui se saturent réalisent une dépendance syntaxique. Le processus d’analyse avec les
GI étant formalisé sous forme d’un graphe, les dépendances sont alors créées par détection de motifs dans
ce graphe.
La section 1 précise ce qu’on entend par analyse en dépendances syntaxiques complète. La section 2
présente brièvement le formalisme des GI et la section 3 décrit les principes de construction de la gram-
maire du français qui permettent d’exprimer les dépendances syntaxiques. Enfin, la section 4 montre com-
ment les motifs de graphe sont utilisés pour produire des dépendances.
1 Analyse en dépendances syntaxiques complète
La notion d’analyse complète fait appel à la différence entre dépendances dites directes (en noir dans les
figures) et dépendances indirectes (en rouge dans les figures), selon qu’elles se réalisent sans ou à l’aide
d’un mot intermédiaire. Dans la proposition “Jean permet à Marie de venir” (figure 1), “Jean” sujet de
“permet” et “à” complément d’attribution de “permet” correspondent à des dépendances directes (1a).
La relation “Marie” sujet de “venir” est quant à elle une dépendance indirecte (1b).
MOTIFS DE GRAPHE POUR LE CALCUL DE DÉPENDANCES SYNTAXIQUES COMPLÈTES
Nous appellerons analyses partielles les analyses uniquement composées de dépendances directes. Dans
nos exemples, les analyses partielles sont inspirées par le guide d’annotation de la French Dependency
Treebank 3. Nous appellerons analyses complètes les analyses qui contiennent les dépendances indirectes
utiles pour l’analyse sémantique 4.
obj obj
subj dat obj obj subj dat obj subj
Jean permet à Marie de venir Jean permet à Marie de venir
np v prep np cpl v np v prep np cpl v
(a) Partielle (b) Complète
FIGURE 1 – Structure en dépendances pour la phrase “Jean permet à Marie de venir”
Souvent, les dépendances indirectes peuvent être retrouvées à partir des dépendances directes. Toutefois,
ce n’est pas toujours le cas. Dans la phrase “Jean promet à Marie de venir”, la structure en dépendances
partielle est identique à celle de la phrase “Jean permet à Marie de venir” (1a). Cependant, dans la
première il y a une dépendance indirecte “Jean” sujet de “venir”, et dans la deuxième cette dépendance
est entre “Marie” et “venir”.
La figure (1b) montre déjà que les dépendances complètes ne forment pas un arbre. Dans le syntagme
nominal contenant une relative “la fille que Jean connaı̂t”, l’analyse complète (figure 2b) n’utilise plus le
pronom relatif “que” comme relais pour introduire la relative et rappeler l’objet de “connaı̂t”. La relation
“fille” objet de “connaı̂t” est une dépendance indirecte qui introduit un cycle dans la structure. De plus,
la structure n’est plus connexe : le pronom relatif “que” qui a servi d’intermédiaire entre la relative et son
antécédent n’a plus d’utilité.
modif modif
obj obj
det subj det subj
la fille que Jean connaît la fille que Jean connaît
det n pro np v det n pro np v
(a) Partielle (b) Complète
FIGURE 2 – Structure en dépendances pour le syntagme nominal “la fille que Jean connaı̂t”
2 Le formalisme des grammaires d’interaction
Les grammaires d’interaction (Perrier, 2003) sont un formalisme grammatical qui place la notion de pola-
rité au cœur du mécanisme de composition syntaxique. Les objets de base d’une grammaire d’interaction
sont des fragments d’arbres syntaxiques sous-spécifiés qui sont décorés par des polarités. Ces polarités
expriment l’état de saturation du fragment concerné et sa capacité d’interaction avec d’autres fragments.
La composition syntaxique consiste alors à superposer partiellement ces fragments d’arbres pour saturer
leurs polarités et obtenir un arbre unique complètement spécifié où toutes les polarités auront été saturées.
3. http://www.linguist.univ-paris-diderot.fr/̃mcandito/Rech/FTBDeps/
4. Certaines dépendances directes deviennent alors inutiles et sont supprimées.
J. MARCHAND, B. GUILLAUME ET G. PERRIER
On peut voir la composition syntaxique de façon totalement statique. L’ensemble des fragments d’arbres
servant à construire un arbre syntaxique peut être vu comme une spécification d’une famille d’arbres qui
constituent les modèles de cette spécification. C’est pourquoi nous l’appellerons une Description d’Arbre
Polarisée (DAP). L’arbre syntaxique final représente alors un modèle particulier de cette description. La
composition syntaxique apparaı̂t ensuite comme la réalisation d’une fonction d’interprétation associant
chaque nœud d’une DAP à un nœud d’un arbre syntaxique. On peut oublier le processus de composition
pour ne conserver finalement que le triplet (DAP, arbre syntaxique, interprétation) que nous appellerons
graphe d’interprétation, dans la mesure où il peut se représenter sous forme d’un graphe.
Seules les principales caractéristiques du formalisme des GI nécessaires à la compréhension de la suite de
l’article sont données ici (voir Guillaume & Perrier (2010) pour une présentation complète).
Une DAP est un ensemble de nœuds représentant des syntagmes, structuré par des relations de domination
et de précédence immédiates et sous-spécifiées. Les propriétés morpho-syntaxiques de chaque syntagme
sont décrites par une structure de traits attachée à au nœud correspondant. Il existe deux types de traits :
– les traits polarisables qui portent en plus de leur valeur une polarité qui peut être positif (→), négatif
(←), virtuel (∼) ou saturé (↔) ; dans la suite deux traits de ce type seront utilisés : cat et funct ;
– les traits neutres qui ne portent pas de polarités (le symbole = est utilisé pour ces traits).
Dans la suite, les nœuds des modèles sont notés {N} ; ceux des DAP, [N].
[Np1]
cat → np cat ~ s [S]
[Np2]
funct ← ? cat → s
cat ~ np cat → np
funct ← ?
Jean cat ~ np [Subj] [Obj]
cat ↔ np cat ~ <5>aux | v funct ~ obj cat ← np
[Vmax] cat ← np cat → det cat ← det
funct → subj cat ↔ v funct → obj funct ← det funct → det
cat ↔ n
cat = np | pp
funct = deobj | obj
[Clit]
en cat ~ np [V]
cat ↔ clit cat ~ <5>aux | v funct ~ obj apprécie
le goût
ref = <4>? cat ↔ v
cat ↔ det cat ↔ n
[DeObj]
cat ↔ pp
funct ↔ deobj
ref = <4>?
{S}
cat : s
{Np1-Subj}
cat : np {Vmax}
{Np2-Obj}
t : np
funct : subj cat : v
ca
funct : obj
{Clit}
Jean {V}
{DeObj}
en cat : det p
cat : np apprécie
cat : p
cat : clit funct : det cat : n funct : deobj
ref : <9>? cat : v ref : <9>?
le goût
cat : det cat : n
FIGURE 3 – Graphe d’interprétation de la phrase “Jean en apprécie le goût”
MOTIFS DE GRAPHE POUR LE CALCUL DE DÉPENDANCES SYNTAXIQUES COMPLÈTES
Une interprétation d’une DAP dans un arbre syntaxique est valide si elle préserve les relations de do-
mination et de précédence. Par ailleurs, elle doit préserver les valeurs de traits ainsi que les relations de
co-indexations entre celles-ci 5. Concernant la structure d’arbre ainsi que des traits étiquetant les nœuds,
une interprétation garantit une minimalité du modèle en un sens défini dans Guillaume & Perrier (2010).
Pour ce qui est des polarités, une interprétation valide doit respecter une des deux propriétés suivantes
pour chaque ensemble de traits polarisés de la DAP de départ interprétés dans le même trait de l’arbre
syntaxique d’arrivée :
– cas non-linéaire : un seul trait est saturé et tous les autres sont virtuels ;
– cas linéaire : un trait est positif, un second négatif et tous les autres virtuels.
Une conséquence des conditions de saturation est que l’on peut définir, pour un nœud {N} contenant un
trait polarisable f , l’antécédent principal de {N} relativement à f (noté f−1({N})) comme l’unique nœud
de l’ensemble I−1({N}) de la DAP porteur du trait f saturé (dans le cas non-linéaire) ou du trait f positif
(dans le cas linéaire).
Dans la suite, on appellera nœud principal un nœud d’une DAP qui porte un trait cat positif ou saturé (on
notera donc cat→|↔? dans les motifs).
Une grammaire particulière d’interaction est définie par l’ensemble de ses DAP élémentaires (DAPE)
utilisées pour composer des arbres syntaxiques.
Illustrons ces notions par l’exemple de l’analyse syntaxique de la phrase “Jean en apprécie le goût”
avec la grammaire d’interaction du français Gf (Perrier, 2007). Dans une première phase, il s’agit de
sélectionner les DAPE de Gf qui vont servir à analyser la phrase. Elles sont réunies en une unique DAP D
représentant le point de départ de l’analyse. Cette DAP est présentée par la figure 3 dans sa partie haute.
L’arbre syntaxique T résultant de l’analyse est présenté dans la partie basse de la même figure. La fonction
d’interprétation de D dans T est représentée sur la figure par des arcs orange allant des nœuds de D vers
ceux de T 6. L’ensemble des deux structures et de la fonction d’interprétation de la figure 3 constitue le
graphe d’interprétation.
3 Principes de construction de la grammaire du français Gf
La grammaire Gf a été construite en suivant un certain nombre de règles qui sont l’expression dans le
formalisme des GI de principes linguistiques qui ne sont pas spécifiques au français mais qui valent aussi
pour d’autres langues plus ou moins proches. Voici l’essentiel de ces règles :
1. La grammaire est strictement lexicalisée, ce qui signifie que chaque DAPE est associée à un mot-
forme unique du français par le biais d’une feuille spéciale de la description, appelée son ancre.
Sur les figures, les ancres sont représentées en jaune foncé. L’ensemble des ascendants de l’ancre
s’appelle l’épine dorsale de la DAPE.
2. Certains nœuds ont une forme phonologique vide. Ce sont toujours des feuilles qui représentent la
trace d’un argument qui n’est pas dans sa position canonique. Cela peut correspondre à un argument
extrait, un sujet inversé ou encore un clitique comme “en” dans notre exemple. Sur les figures, les
nœuds vides sont représentés en blanc et les nœuds non vides en jaune ; dans les DAP, un nœud gris
5. A la différence de Guillaume & Perrier (2010), nous considérons que les traits peuvent être co-indexés non seulement
dans les DAP mais aussi dans les arbres syntaxiques.
6. Elle est en fait partiellement représentée pour alléger la figure, la fonction d’interprétation étant en fait totale mais il n’est
pas difficile de construire les arcs manquants.
J. MARCHAND, B. GUILLAUME ET G. PERRIER
ne porte pas de contrainte sur la forme phonologique, il peut être vide ou non vide. Par exemple, sur
la figure 3, la trace du complément de l’objet du verbe modifié par le clitique “en” est représentée
par le nœud vide [DeObj].
3. Tous les nœuds de la grammaire portent un trait cat. Pour chaque DAPE, tous les nœuds principaux
non vides sont sur l’épine dorsale. Ces nœuds forment un chemin non vide commençant à un nœud
que l’on appelle la projection maximum de l’ancre et terminant à l’ancre elle-même. L’ancre est
la tête de tous ces nœuds et de façon duale, ceux-ci représentent ses diverses projections. Pour
une projection différente de l’ancre, on définit son fils principal comme son fils qui est aussi une
projection de la tête.
Sur la figure 3, dans la DAPE de “apprécie”, l’ancre [V] a comme projections, outre elle-même, les
nœuds [Vmax] et [S]. Dans la DAPE de “en”, l’ancre [Clit] n’a qu’elle-même comme projection.
Telles qu’elles viennent d’être définies, les notions de tête et de projection sont relatives à une DAPE
mais on peut les transposer à un arbre syntaxique modèle d’un ensemble de DAPE à l’aide d’une
interprétation I. Pour tout nœud non vide {N}, cat−1({N}) est un nœud non vide d’une DAPE Di
dont la tête est l’ancre [Ai] de Di. On dit alors que la tête de {N} est I([Ai]) et que {N} est une
projection de I([Ai]).
Par exemple, dans l’arbre syntaxique T de la figure 3, le nœud {V} est la tête de {Vmax} et {S}.
4. Si un nœud d’un arbre syntaxique modèle d’une DAP est porteur d’un trait funct avec une valeur
X , cela signifie d’un point de vue linguistique que le syntagme correspondant remplit la fonction
syntaxique X par rapport à un syntagme représenté par un de ses nœuds frères dans l’arbre.
Par exemple dans l’arbre T de la figure 3, les nœuds {Subj} et {Obj} remplissent les fonctions
respectives sujet et objet par rapport au noyau verbal représenté par leur frère {Vmax}.
Lorsqu’un nœud d’un arbre syntaxique pourvu d’un trait funct de valeur X a plusieurs frères,
la lecture du modèle ne permet pas de déterminer lequel est celui par rapport auquel il remplit la
fonction X . Pour cela, il faut revenir à la DAP correspondante via l’interprétation. Nous devons
distinguer trois cas. Considérons une DAP D composée de n DAPE D1, . . . ,Dn qui est interprétée
dans un modèle T via une interprétation I. Considérons dans T un nœud {N} porteur d’un trait
funct de valeur X , le père de {N} étant noté {P}.
(a) Interaction linéaire prédicat-argument. Le trait funct est l’image d’un trait positif issu
d’une DAPEDi et d’un trait négatif issue d’une autre DAPEDj . DansDi, la grammaire assure
que le nœud [Ni] porteur du trait funct positif a toujours un unique frère [Mi] qui est un nœud
principal. Dans l’arbre T , on peut alors dire que {N} remplit la fonctionX par rapport à l’image
{M} de ce frère. On parle alors d’interaction linéaire entre les DAPEDi etDj . Cette interaction
est la réalisation d’une relation prédicat-argument.
Par exemple, il y a une interaction linéaire entre les DAPE associées à “goût” et à “apprécie”
qui a pour résultat de réaliser la fonction objet du nœud [Obj] par rapport au nœud [Vmax].
(b) Interaction non-linéaire modifié-modificateur. Le trait funct est l’image d’un trait saturé
issu d’une DAPE Di et l’antécédent du nœud {N} dans Di est un nœud [Ni] qui a comme père
un nœud [Pi] pourvu d’un trait virtuel cat. Il existe alors une DAPE unique Dj qui contient
le nœud principal [Pj] = cat−1({P}). Le fils principal [Mj] de [Pj] a pour image le frère {M}
de {N}. Dans l’arbre T , on peut alors dire que {N} remplit la fonction X par rapport à {M}.
On parle alors d’interaction non-linéaire entre les DAPE Di et Dj . Cette interaction est la
réalisation d’une relation de modification ou d’adjonction.
MOTIFS DE GRAPHE POUR LE CALCUL DE DÉPENDANCES SYNTAXIQUES COMPLÈTES
Par exemple, il y a une interaction non-linéaire entre les DAPE associées à “goût” et “en” qui
a pour résultat de réaliser la fonction complément de nom du nœud {DeObj} par rapport au
nœud {Np2− Obj}.
(c) Relation prédicat-argument non réalisée. Le trait funct est l’image d’un trait saturé issu
d’une DAPE Di et l’antécédent du nœud {N} dans Di est un nœud vide [Ni] qui a comme père
un nœud principal [Pi]. [Ni] a comme frère le fils principal [Mi] de [Pi]. Dans l’arbre T , {N}
remplit alors la fonction X par rapport à l’image {M} = I([Mi]) de ce frère.
Dans la figure 3, nous n’avons pas d’illustration de ce troisième cas que l’on rencontre en
particulier pour représenter des relations prédicat-argument non réalisées phonologiquement,
comme les relations verbe-sujet pour les infinitifs.
5. Si un nœud d’une DAPE porte un trait ref, cela signifie que le syntagme correspondant est associé
à une référence sémantique (la valeur du trait peut préciser la qualité de cette référence : animée,
inanimée mais concrète ou encore abstraite). Si dans une même DAPE, deux nœuds ont des traits
ref co-indexés, cela signifie qu’ils renvoient à la même entité sémantique de référence. Par exemple,
dans la DAPE associée à “en”, les nœuds [Clit] et [DeObj] ont des traits ref co-indexés. Cela
veut dire qu’ils représentent la même entité sémantique. De même, c’est avec la co-indexation de
traits ref que l’on modélise la différence de contrôle entre “permet” et “promet” (ce mécanisme
s’apparente aux équations de contrôle de LFG).
Cette co-indexation entre traits ref de plusieurs nœuds se propage dans un modèle via la fonction
d’interprétation et elle permet de réaliser des interactions indirectes entre syntagmes.
4 Des motifs de graphe pour calculer les dépendances
Comme nous l’avons vu plus haut, pour calculer une structure en dépendances, il est parfois nécessaire
de considérer des informations qui ne sont pas dans l’arbre syntaxique mais plutôt dans l’historique de
sa dérivation. En grammaire d’interaction, l’historique d’une dérivation est décrit par ce que nous avons
appelé le graphe d’interprétation et qui représente le triplet (DAP, arbre syntaxique, interprétation). Le
calcul des dépendances à partir du graphe d’interprétation peut alors s’exprimer à l’aide de motifs de
graphe.
Les motifs de graphe Un motif de graphe décrit un ensemble de contraintes à satisfaire par le graphe
d’interprétation pour qu’une dépendance soit produite. Formellement, un motif de graphe est constitué
d’un ensemble de motifs de nœud et de relations entre ces motifs. Identifier un motif dans une structure
revient à construire une fonction d’appariement (on note l’image de N par la fonction d’appariement N)
qui associe à chaque nœud du motif un nœud du graphe d’interprétation compatible avec les contraintes
exprimées par le motif. Il est important de noter que les motifs font apparaı̂tre des nœuds de la DAP
(rectangles) et des nœuds du modèle (coins arrondis).
La figure 5 décrit les motifs que l’on utilise pour la grammaire Gf ; les contraintes portent sur les structures
de trait, notamment sur les traits cat et funct et les polarités associées. Ces contraintes portent également
sur le fait qu’un nœud est vide (fond blanc) ou non vide (fond jaune) dans le modèle.
Pour les relations, deux types de contraintes sont utilisées. D’une part, on peut contraindre N à être l’in-
terprétation de M (les motifs de nœuds M et N sont alors reliés par une arête orange dans le motif). D’autre
part, on peut contraindre N à être un sous-constituant immédiat de M (M est au-dessus de N et ils sont reliés
par un trait noir).
J. MARCHAND, B. GUILLAUME ET G. PERRIER
Chaque motif décrit un ensemble de contraintes à vérifier pour qu’une dépendance soit ajoutée. La flèche
rouge ne fait pas partie du motif, elle indique simplement qu’une dépendance doit être ajoutée quand le
motif est repéré dans le graphe d’interprétation ; la dépendance créée relie alors les mots-formes portés
par les ancres des descriptions correspondant aux nœuds G et D.
Par exemple, on peut appliquer le motif représentant le cas linéaire et canonique, en haut et à gauche dans
la figure 5, au graphe d’interprétation de la figure 3 par l’appariement : N = {Np1− Subj}, G = [Subj] et
D = [Np1]. On vérifie facilement que toutes les contraintes imposées par le motif sont vérifiées ; on peut
donc ajouter une relation de dépendance portant l’étiquette subj (valeur du trait funct dans le nœud N)
entre “apprécie” (mot-forme de l’ancre de la DAPE qui contient le nœud G) et “Jean” (mot-forme de
l’ancre de la DAPE qui contient le nœud D). Cela correspond à la dépendance verte dans la figure 4.
deobj
obj
subj det
Jean en apprécie le goût
np clit v det n
FIGURE 4 – Structure en dépendance pour la phrase “Jean en apprécie le goût”
Motifs de graphe pour les dépendances complètes Présentons maintenant les quatre motifs qui s’ap-
puient sur les principes de la grammaire pour calculer les dépendances complètes d’une phrase. La gram-
maire modélise chaque dépendance par l’utilisation d’un trait funct ; il s’agit donc d’interpréter les
principes décrits dans le point 4 de la section 3 de telle façon que :
si {N} remplit la fonction syntaxique X par rapport à un frère {M}
alors une dépendance existe entre la tête de {M} et la tête de {N}.
Les quatre règles de la figure 5 contiennent toutes un motif de nœud N avec le trait funct de valeur X .
Elles correspondent à la combinaison de deux alternatives : la linéarité et le fait que le dépendant soit en
position canonique ou pas. Pour chaque nœud {N} du modèle portant un trait funct de valeur X , on fixe
N = {N} et on distingue :
Le cas linéaire : ce cas correspond aux deux règles à gauche dans la figure 5 et il est caractérisé par le
fait que funct−1({N}) a un trait funct positif. Cela correspond au point 4(a) de la section 3 et
donc, le nœud par rapport auquel {N} remplit la fonction syntaxique X est dans la même DAPE que
funct−1({N}) et donc G = funct−1({N}).
Le cas non-linéaire : ce cas (les deux règles de droite) s’applique quand funct−1({N}) a un trait funct
saturé (4(b) et 4(c) de la section 3). Le nœud {M} par rapport auquel {N} remplit la fonction syn-
taxique X est le fils principal du nœud [Pj] dans le cas 4(b) et du nœud [Pi] dans le cas 4(c). Dans
les deux cas, ce nœud {M} est donc dans la même DAPE que la tête du père {P} du nœud {N}.
Le cas canonique : le dépendant de la relation de dépendance est la tête du nœud {N} quand elle existe
(c’est-à-dire quand {N} est non-vide) et donc par définition cette tête est dans la même DAPE que
cat−1({N}) c’est le cas pour les deux motifs de graphe en haut de la figure 5 qui correspondent au
cas où le dépendant est en position canonique.
MOTIFS DE GRAPHE POUR LE CALCUL DE DÉPENDANCES SYNTAXIQUES COMPLÈTES
linéaire non-linéaire
funct−1({N}) a un trait funct positif funct−1({N}) a un trait funct saturé
G : gouvereur
cat →   | ↔ ? P : père
G : gouverneur X
funct  →  ?
canonique X N I
{ funct : X funct ↔ ?N} est vide D : dépendant N
cat →   | ↔ ? funct : X
D : dépendant
cat →   | ↔ ?
G : gouverneur
cat →   | ↔ ? P : père
X
G : gouveneur N
funct  →  ? funct : X
non-canonique ref = <1> I NX funct ↔ ? funct : X{ ref : <1>N} est non-vide
D : dépendant C : co-indéxé
cat →   | ↔ ? ref : <1>
D : dépendant
cat →   | ↔ ? C : co-indéxéref : <1>
FIGURE 5 – Motifs pour le calcul de dépendances
Le cas non-canonique : si le nœud {N} est vide, on utilise le principe du point 5 de la partie 3 ; ce principe
assure qu’un nœud {C} non-vide dont le trait ref est co-indexé avec celui du nœud {N} renvoie à
la même entité sémantique, c’est donc ce nœud qui a pour tête le dépendant réel ; les deux motifs
de graphe du bas de la figure 5 s’appliquent alors avec C = {C} et D = cat−1({C}). L’existence et
l’unicité d’un tel nœud {C} est assuré par la grammaire.
Par exemple, considérons le trait funct : deobj du nœud {DeObj} de la figure 3.
On considère le trait funct : deobj du nœud {DeObj} N = {DeObj}
funct−1({Deobj}) = [DeObj] qui a un trait funct saturé donc
cas non-linéaire I = [DeObj]
le père de {DeObj} est {Np2− Obj} P = {Np2− Obj}
cat−1({Np2− Obj}) = [Np2] G = [Np2]
{DeObj} est vide (cas non-canonique), on considère l’unique
nœud non-vide avec le même index 〈9〉, il s’agit de {Clit} C = {Clit}
cat−1({Clit}) = [Clit] D = [Clit]
Le motif de graphe pour le cas non-linéaire non-canonique s’applique donc, ce qui donne la dépendance
(dessinée en bleu sur la figure 4) deobj entre “goût” (le mot-forme de l’ancre de G = [Np2]) et “en” (le
mot-forme de l’ancre de D = [Clit]). Sur la figure 4, les trois autres dépendances sont des applications du
cas linéaire canonique. 7.
7. D’autres exemples de structures de dépendances obtenues par la méthode décrite ci-dessus peuvent être consultés à
l’adresse http://leopar.loria.fr/exemples_dep/.
J. MARCHAND, B. GUILLAUME ET G. PERRIER
5 Conclusion
Nous avons présenté une méthode pour calculer les dépendances syntaxiques d’un énoncé à partir du pro-
cessus d’analyse en constituants à l’aide des grammaire d’interaction. Cette méthode à base de motifs de
graphes permet de retranscrire tout l’information de l’analyse en constituants nécessaire à la construction
de la sémantique. Il nous reste maintenant à valider notre méthode sur des corpus à grande échelle, par
exemple dans le cadre d’une campagne d’évaluation comme PASSAGE.
D’autre part, notre méthode de sélection de motifs de graphe peut être généralisée pour l’analyse sémantique.
Il ne s’agit plus de détecter des motifs de graphes mais d’appliquer des transformations directement sur
les graphes dans le cadre de la réécriture de graphes (Bonfante et al., 2010).
Références
BONFANTE G., GUILLAUME B., MOREY M. & PERRIER G. (2010). Réécriture de graphes de
dépendances pour l’interface syntaxe-sémantique. In Actes de TALN 2010, Montréal.
CANDITO M.-H., CRABBÉ B., DENIS P. & GUÉRIN F. (2009). Analyse syntaxique statistique du
français : des constituants aux dépendances. In TALN 2009, Senlis, France.
CANDITO M.-H. & KAHANE S. (1998). Can the TAG derivation tree represent a semantic graph ? An
answer in the light of Meaning-Text Theory. In TAG. Proc+4, p. 21–24, Philadelphie.
DEBUSMANN R. (2006). Extensible Dependency Grammar : A Modular Grammar Formalism Based On
Multigraph Description. PhD thesis, Saarland University.
GUILLAUME B. & PERRIER G. (2010). Interaction Grammars. Research on Language and Computation
(à paraı̂tre).
KÜBLER S., MCDONALD R. T. & NIVRE J. (2009). Dependency Parsing. Synthesis Lectures on
Human Language Technologies. Morgan & Claypool Publishers.
KUČEROVÁ I. & ŽABOKRTSKÝ Z. (2002). Transforming Penn Treebank Phrase Trees into (Praguian)
Tectogrammatical Dependency Trees. The Prague Bulletin of Mathematical Linguistics, (78), 77–94.
MARCHAND J., GUILLAUME B. & PERRIER G. (2009). Analyse en dépendances à l’aide des gram-
maires d’interaction. In TALN 2009, Senlis, France.
PERRIER G. (2003). Les grammaires d’interaction. Habilitation à diriger les recherches, Université
Nancy 2.
PERRIER G. (2007). A French Interaction Grammar. In RANLP 2007, p. 463–467, Borovets Bulgarie.
RAMBOW O. & JOSHI A. (1997). A Formal Look at Dependency Grammars and Phrase-Structure
Grammars, with Special Consideration of Word-Order Phenomena. In Current Issues in Meaning-Text
Theory, London : Pinter.
