<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Un mod&#232;le de caract&#233;risation de la complexit&#233; syntaxique</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>Un mod&#232;le de caract&#233;risation de la complexit&#233; syntaxique
</p>
<p>Philippe Blache
Laboratoire Parole et Langage, CNRS &amp; Universit&#233; de Provence
</p>
<p>5, Avenue Pasteur
13604 Aix en Provence - France
</p>
<p>blache@lpl-aix.fr
</p>
<p>R&#233;sum&#233;.
Cet article pr&#233;sente un mod&#232;le de la complexit&#233; syntaxique. Il r&#233;unit un ensemble d&#8217;indices de complexit&#233;
et les repr&#233;sente &#224; l&#8217;aide d&#8217;un cadre formel homog&#232;ne, offrant ainsi la possibilit&#233; d&#8217;une quantification
automatique : le mod&#232;le propos&#233; permet d&#8217;associer &#224; chaque phrase un indice refl&#233;tant sa complexit&#233;.
</p>
<p>Abstract.
This paper proposes a model of syntactic complexity. It brings together a set of complexity parameters
and represnt them thanks to a unique formal framework. This approach makes it possible an automatic
evaluation : a complexity index can be associated to each sentence.
</p>
<p>Mots-cl&#233;s : Complexit&#233; syntaxique, analyse syntaxique automatique, parser humain.
</p>
<p>Keywords: Syntactic complexity, parsing, human parser.
</p>
<p>1 Introduction
</p>
<p>L&#8217;objectif de cet article est de proposer un mod&#232;le unifi&#233; de la complexit&#233; syntaxique. Il s&#8217;agit plus pr&#233;-
cis&#233;ment d&#8217;identifier un ensemble d&#8217;indices de complexit&#233; et de les repr&#233;senter &#224; l&#8217;int&#233;rieur d&#8217;un cadre
formel homog&#232;ne, offrant ainsi la possibilit&#233; d&#8217;une quantification : le mod&#232;le propos&#233; permet d&#8217;associer &#224;
chaque phrase un indice refl&#233;tant sa complexit&#233;.
</p>
<p>L&#8217;&#233;valuation de la complexit&#233; linguistique est une question aussi ancienne que la syntaxe formelle. L&#8217;id&#233;e
de pouvoir quantifier cet &#233;l&#233;ment est par exemple abord&#233;e dans (Chomsky65), en proposant l&#8217;estimation
d&#8217;un indice d&#233;rivationnel. On retrouve ce param&#232;tre dans la plupart des &#233;tudes en psycholinguistique (p.
ex. (Gibson91)). La complexit&#233; y est consid&#233;r&#233;e comme refl&#233;tant une difficult&#233; d&#8217;interpr&#233;tation par des
sujets humains. Des exp&#233;rimentations permettent de la mettre en &#233;vidence de diff&#233;rentes fa&#231;ons : temps
de lecture des mots (cf. (Gibson98), (Vasishth03)), observation des mouvement oculaires lors de la lecture
(voir (Lee07)). Un temps de lecture plus long sur un mot ou des retours en arri&#232;re du regard sont le signe
d&#8217;une difficult&#233;. Le probl&#232;me consiste alors &#224; pr&#233;dire la complexit&#233;, sur la base des propri&#233;t&#233;s syntaxiques
d&#8217;une phrase. Bien entendu, il ne peut s&#8217;agir l&#224; que d&#8217;une approximation : les m&#233;canismes d&#8217;interpr&#233;tation
sont &#233;videmment &#233;galement d&#233;pendants de facteurs s&#233;mantiques ou extra-linguistiques comme la charge
m&#233;morielle li&#233;e &#224; la fr&#233;quence, la saillance, etc. (cf. (Caplan99)). Pour autant, une premi&#232;re mod&#233;lisa-
tion s&#8217;appuyant uniquement sur la syntaxe pourra malgr&#233; tout constituer une bonne approximation de la</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PHILIPPE BLACHE
</p>
<p>complexit&#233; en offrant de plus la possibilit&#233; d&#8217;une &#233;valuation automatique.
</p>
<p>Cet article propose de r&#233;unir plusieurs des indices de complexit&#233; propos&#233;s en psycholinguistique &#224; l&#8217;int&#233;-
rieur d&#8217;un mod&#232;le unique permettant de calculer automatiquement une estimation globale de la complexit&#233;
d&#8217;un &#233;nonc&#233;. Apr&#232;s la pr&#233;sentation de quelques facteurs de complexit&#233;, nous en proposons une repr&#233;senta-
tion &#224; l&#8217;int&#233;rieur d&#8217;un cadre formel bas&#233; sur les contraintes et permettant leur &#233;valuation. Une illustration
de l&#8217;utilisation de ce mod&#232;le appliqu&#233; &#224; un cas standard de la complexit&#233; syntaxique (complexit&#233; compar&#233;e
des relatives sujet et objet) est ensuite donn&#233;e.
</p>
<p>2 Les th&#233;ories de la complexit&#233; syntaxique
</p>
<p>Nous proposons dans cette section un panorama de quelques approches fournissant des &#233;l&#233;ments d&#8217;&#233;valua-
tion de la complexit&#233;, s&#8217;appuyant essentiellement sur les d&#233;pendances et leurs cons&#233;quences. Ces mod&#232;les
reposent en particulier sur la saturation de la structure (l&#8217;hypoth&#232;se de d&#233;pendance incompl&#232;te), la com-
plexit&#233; informationnelle (th&#233;orie de la localit&#233; de d&#233;pendance) ainsi que d&#8217;autres param&#232;tres comme le
degr&#233; d&#8217;activation d&#8217;une cat&#233;gorie ou la profondeur de la structure syntaxique.
</p>
<p>2.1 Hypoth&#232;se de d&#233;pendance incompl&#232;te
</p>
<p>Pour la plupart des th&#233;ories, deux op&#233;rations sont facteurs de complexit&#233; dans l&#8217;analyse des phrases :
l&#8217;int&#233;gration (insertion d&#8217;un &#233;l&#233;ment nouveau &#224; une structure syntaxique existante) et la m&#233;morisation
(nombre de d&#233;pendances syntaxiques incompl&#232;tes).
</p>
<p>L&#8217;hypoth&#232;se de d&#233;pendance incompl&#232;te (cf. (Gibson91)) repose sur l&#8217;id&#233;e que la complexit&#233; est fonction
du nombre de structures incompl&#232;tes &#224; m&#233;moriser. L&#8217;exemple (1b) pr&#233;sente une structure de ce type,
comportant un constituant emboit&#233; (la relative) s&#233;parant le nom du verbe dont il est sujet. L&#8217;exemple (1c),
comportant deux constructions de ce type, est consid&#233;r&#233; comme &#233;tant quant &#224; lui trop complexe pour &#234;tre
interpr&#233;t&#233; naturellement. En revanche, l&#8217;exemple (1d), comportant le m&#234;me mat&#233;riel lexical et le m&#234;me
nombre de relatives, est lui consid&#233;r&#233; comme plus simple car ne comportant pas de rupture entre les noms
et les verbes dont ils sont sujets.
</p>
<p>(1) a. The reporter disliked the editor.
</p>
<p>b. The reporter [who the senator attacked] disliked the editor.
</p>
<p>c. #The reporter [who the senator [who John met] attacked] disliked the editor.
</p>
<p>d. John met the senator [who attacked the reporter [who disliked the editor]].
</p>
<p>Il est donc possible de donner une estimation quantitative de ce facteur en sommant &#224; chaque t&#234;te le
nombre de d&#233;pendances incompl&#232;tes. Dans l&#8217;exemple (1a), les valeurs suivantes indiquent les co&#251;ts pour
deux des positions de la phrase :
</p>
<p>&#8211; Co&#251;t au niveau du SN the reporter = 1 : le SN sujet d&#233;pend du V qui suit
&#8211; Co&#251;t au SN the senator = 3 : les SN the reporter et the senator d&#233;pendent en tant que sujet d&#8217;un V &#224;
</p>
<p>suivre ; who d&#233;pend en tant qu&#8217;objet d&#8217;un V &#224; suivre</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UN MOD&#200;LE DE CARACT&#201;RISATION DE LA COMPLEXIT&#201; SYNTAXIQUE
</p>
<p>2.2 Th&#233;orie de la localit&#233; de d&#233;pendance (DLT)
</p>
<p>Cette th&#233;orie, d&#233;velopp&#233;e dans (Gibson00) propose de prendre en compte la charge li&#233;e au traitement des
objets r&#233;f&#233;rentiels pr&#233;sents entre entre deux structures syntaxiques, la seconde devant &#234;tre int&#233;gr&#233;e &#224; la
premi&#232;re. Cette th&#233;orie s&#8217;appuie sur l&#8217;identification de r&#233;f&#233;rents du discours, sur le co&#251;t de leur int&#233;gration
et propose de compl&#233;ter cette &#233;valuation par une quantification du co&#251;t de m&#233;morisation des objets trait&#233;s.
</p>
<p>Les r&#233;f&#233;rents du discours Plusieurs travaux ont montr&#233; l&#8217;importance du degr&#233; d&#8217;accessibilit&#233; des r&#233;f&#233;-
rents du discours (not&#233;s DR). Il s&#8217;agit ici de distinguer les r&#233;f&#233;rents en fonction de leur statut au moment o&#249;
ils sont mobilis&#233;s pour l&#8217;interpr&#233;tation. Un r&#233;f&#233;rent peut &#234;tre &#8220;nouveau&#8221; (ils sont dans ce cas par exemple
introduits par un SN ind&#233;fini). Il peut &#234;tre &#8220;donn&#233;&#8221;, faisant ainsi r&#233;f&#233;rence &#224; un r&#233;f&#233;rent d&#233;j&#224; utilis&#233; (par
exemple introduit par un pronom ou un nom propre). Il peut &#234;tre &#233;galement &#8220;accessible&#8221;, c&#8217;est &#224; dire qu&#8217;il
a d&#233;j&#224; &#233;t&#233; introduit mais de mani&#232;re indirecte. Il est ainsi possible d&#8217;organiser cette information de fa&#231;on
hi&#233;rarchis&#233;e. A partir de cette organisation de l&#8217;accessibilit&#233;, des travaux (cf. (Aissen03)) ont propos&#233; une
hi&#233;rarchie reposant sur l&#8217;aspect plus ou moins d&#233;fini du SN : Pronom &gt; Nom propre &gt; SN d&#233;fini &gt; SN
ind&#233;fini. Une simplification de cette observation propos&#233;e dans (Gibson98) consiste &#224; dire que les SN in-
d&#233;finis sont les moins accessibles et n&#233;cessitent le plus de ressources pour &#234;tre int&#233;gr&#233;s que les pronoms.
On consid&#232;re donc que les objets les plus co&#251;teux sont les r&#233;f&#233;rents &#8220;nouveaux&#8221;. Dans le mod&#232;le DLT,
chaque r&#233;f&#233;rent ayant le statut &#8220;nouveau&#8221; repr&#233;sentera une unit&#233; de complexit&#233;, on les notera dor&#233;navant
DRn.
</p>
<p>Co&#251;t d&#8217;int&#233;gration Le co&#251;t d&#8217;int&#233;gration d&#233;fini par la DLT consiste &#224; identifier la charge n&#233;cessit&#233;e par
le traitement de nouveaux r&#233;f&#233;rents, qu&#8217;il s&#8217;agisse d&#8217;un objet (un SN d&#233;fini) ou d&#8217;un &#233;v&#233;nement (un verbe).
Le processus d&#8217;int&#233;gration consiste, en rencontrant une t&#234;te, &#224; rechercher dans la structure syntaxique en
cours de construction la t&#234;te &#224; laquelle cette nouvelle structure partielle va pouvoir se rattacher (&#224; la
mani&#232;re d&#8217;un processus d&#8217;adjonction). Le co&#251;t de ce processus correspond au nombre de DRn s&#233;parant
ces deux t&#234;tes, y compris la derni&#232;re.
</p>
<p>Dans l&#8217;exemple (1b), voici deux exemples de co&#251;ts d&#8217;int&#233;gration :
</p>
<p>&#8211; Co&#251;t &#224; attacked = 3 unit&#233;s. 1 unit&#233; pour le DRn &#233;v&#233;nement de attacked + 2 unit&#233;s pour les DRn entre le
d&#233;but de la relative et l&#8217;objet vide (les 2 DRn sont the senator et attacked)
</p>
<p>&#8211; Co&#251;t &#224; admitted = 3 unit&#233;s. 1 unit&#233; pour le nouveau R admitted + 2 pour les DRn (the senator et
attacked) s&#233;parant le sujet (the reporter) et le V disliked.
</p>
<p>Co&#251;t de m&#233;morisation Le second param&#232;tre utilis&#233; dans l&#8217;&#233;valuation de la complexit&#233; par DLT est
le co&#251;t de m&#233;morisation. Il repose sur le nombre minimal de t&#234;tes syntaxique n&#233;cessaires entre le mot
courant et la saturation d&#8217;une structure grammaticale compl&#232;te (une phrase). Par exemple, &#224; la r&#233;alisation
d&#8217;un clitique sujet, on attend la r&#233;alisation d&#8217;un verbe pour obtenir une structure compl&#232;te. Dans l&#8217;exemple
(1b), nous aurons les co&#251;ts suivants :
</p>
<p>&#8211; Co&#251;t &#224; The = 2 unit&#233;s. On attend un N pour terminer le SN sujet et un V, t&#234;te du SV, pour former un P.
&#8211; Co&#251;t &#224; who = 3 unit&#233;s. On attend une proposition relative, une position vide objet pour lier who, plus un
</p>
<p>SV principal.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PHILIPPE BLACHE
</p>
<p>2.3 Autres param&#232;tres
</p>
<p>Activation Dans une &#233;tude r&#233;cente, (Vasishth03) d&#233;crit une limite des mod&#232;les de d&#233;pendance incom-
pl&#232;te et de localit&#233; de d&#233;pendance. Les exp&#233;riences montrent en effet que le degr&#233; d&#8217;activation d&#8217;un mot
peut compenser de fa&#231;on significative la complexit&#233; induite par une construction (par exemple l&#8217;extraction
d&#8217;objet). Ainsi, les productions de type (2b) sont trait&#233;es plus rapidement que (2a), contrairement &#224; ce que
pr&#233;disent DI et DLT :
</p>
<p>(2) a. The rat the cat saw died.
</p>
<p>b. The rat the cat briefly saw died.
</p>
<p>La diff&#233;rence vient de la pr&#233;sence de l&#8217;adverbe qui semble activer le verbe. Cette observation est confor-
t&#233;e par des comportement identiques pour d&#8217;autres modificateurs ou compl&#233;ments pr&#233;c&#233;dant la t&#234;te. Un
constituant fortement activ&#233; sera plus facilement int&#233;gr&#233; au reste de la structure.
</p>
<p>Une analyse comparable est propos&#233;e dans (Hawkins10) qui propose un principe de maximisation du
traitement on-line, reposant sur le nombre de propri&#233;t&#233;s non satisfaites &#224; un moment donn&#233; de la phrase :
on pr&#233;f&#232;re les structures dans lesquelles plus de propri&#233;t&#233;s sont satisfaites plus t&#244;t.
</p>
<p>Profondeur de la structure Plusieurs approches font reposer l&#8217;&#233;valuation de la complexit&#233; sur la pro-
fondeur de l&#8217;arbre correspondant. Le mod&#232;le le plus simple consiste &#224; compter le nombre de noeuds dans
l&#8217;arbre (voir par exemple (Ferreira91)). Il est possible de compl&#233;ter ce param&#232;tre par la prise en compte
du type de certains noeuds (e.g. les conjonctions de subordination, induisant un niveau d&#8217;emboitement
suppl&#233;mentaire, correspondant donc &#224; un facteur de complexit&#233;). Ce type de mod&#232;le reste cependant trop
superficiel et ne permet pas de rendre compte des effets cit&#233;s pr&#233;c&#233;demment. On sait en particulier que la
complexit&#233; doit &#233;galement prendre en compte le nombre de noeuds &#233;num&#233;r&#233;s pour construire la structure,
pas seulement ceux qui sont construits in fine : il s&#8217;agit en d&#8217;autres termes de prendre en compte l&#8217;impact
de la strat&#233;gie d&#8217;analyse sur la complexit&#233; (cf. (Abney91)). D&#8217;autres approches s&#8217;appuient sur la hauteur
des piles utilis&#233;es par le parser en cours d&#8217;analyse, ind&#233;pendamment de la structure construite (voir par
exemple (Schuler09) dont la technique repose sur des mod&#232;les de Markov hi&#233;rarchis&#233;s).
</p>
<p>Si la profondeur de la structure ne peut donc &#224; elle seule expliquer les variations de complexit&#233;, elle reste
tout de m&#234;me un &#233;l&#233;ment important dans de nombreux mod&#232;les psycholinguistiques, &#224; condition d&#8217;&#234;tre
compl&#233;t&#233;e par d&#8217;autres informations.
</p>
<p>Adjacence Dans une &#233;tude s&#8217;appuyant &#224; la fois sur des temps de r&#233;action et l&#8217;analyse de corpus, (Hawkins01)
a montr&#233; que les syntagmes courts compl&#233;ments ou adjoints sont plus souvent adjacents de leurs t&#234;tes.
</p>
<p>(3) a. The gamekeeper [looked [SP1 through is binoculars][SP2 into the blue but slightly overcast sky]].
</p>
<p>b. The gamekeeper [looked [SP1 into the blue but slightly overcast sky] [SP2 through is binoculars]].
</p>
<p>En (3a), SP2 est distant de 3 mots de la t&#234;te, tandis qu&#8217;il est s&#233;par&#233; par 5 mots de sa t&#234;te en (3b). Le premier
type de production est trait&#233; dans un temps significativement plus court que le second. Cette observation
s&#8217;appuie sur le fait que dans le premier cas, la connaissance du fait que le SV est compos&#233; de 2 SP est
atteinte plus t&#244;t. En d&#8217;autres termes, le locuteur atteint en 5 mots (de looked &#224; into) le fait que 3 syntagmes
seront utilis&#233;s : SV, SP1 et SP2. En (3b) en revanche, la m&#234;me information est atteinte en 9 mots.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UN MOD&#200;LE DE CARACT&#201;RISATION DE LA COMPLEXIT&#201; SYNTAXIQUE
</p>
<p>Hawkins propose un crit&#232;re form&#233; par le ratio nombre de constituant
nombre de mots
</p>
<p>sur lequel il base un principe (Early
Immediate Constituents principle) stipulant une pr&#233;f&#233;rence pour les ordres lin&#233;aires qui maximisent le
ratio constituant/mot.
</p>
<p>3 Calcul de la complexit&#233; : une approche par contraintes
</p>
<p>Nous proposons dans cette section une repr&#233;sentation des param&#232;tres de complexit&#233; en termes de contraintes.
Chacune de ces contraintes peut &#234;tre interpr&#233;t&#233;e ind&#233;pendament de toute th&#233;orie. Elles sont ici sp&#233;cifi&#233;es
dans le cadre des Grammaires de Propri&#233;t&#233;s (cf. (Blache01)) dans lesquelles l&#8217;analyse consiste &#224; &#233;valuer
la satisfaction d&#8217;un ensemble de contraintes (&#233;galement appel&#233;es propri&#233;t&#233;s) formant la grammaire. Les
contraintes du mod&#232;le de complexit&#233; reposent sur la satisfaction de certaines propri&#233;t&#233;s jouant le r&#244;le de
pr&#233;-conditions permettant l&#8217;&#233;valuation du crit&#232;re.
</p>
<p>3.1 Les indices de complexit&#233;
</p>
<p>D&#233;pendances incompl&#232;tes Le principe de cette contrainte repose sur l&#8217;&#233;valuation du nombre d&#8217;&#233;l&#233;ments
s&#233;parant un compl&#233;ment de sa t&#234;te. Deux contraintes permettent d&#8217;identifier cette situation : la d&#233;pendance
(not&#233;e;) et la lin&#233;arit&#233; (not&#233;e &#8826;). Soit Ci et Cj deux cat&#233;gories, avec i et j les indices de leur position
dans la cha&#238;ne. Si Cj est une t&#234;te dont d&#233;pend Ci et si Ci pr&#233;c&#232;de Cj , alors l&#8217;indice DI de d&#233;pendance
incompl&#232;te au moment de l&#8217;analyse de Ci est le nombre de d&#233;pendances partant de Ci, auquel s&#8217;ajoute le
nombre de d&#233;pendances incompl&#232;tes en cours. Cette information se repr&#233;sente par la contrainte suivante :
</p>
<p>[(Ci ; Cj) &#8743; (Ci &#8826; Cj)]&#8658; [DI[i]&#8592; (DI[i] + 1)] &#8743; [DI[j]&#8592; (DI[j]&#8722; 1)](4)
</p>
<p>En d&#8217;autres termes, on incr&#233;mente l&#8217;indice &#224; chaque mot initialisant une nouvelle d&#233;pendance, on le d&#233;-
cr&#233;mente en rencontrant la cible de la d&#233;pendance.
</p>
<p>Localit&#233; de d&#233;pendance On repr&#233;sente ici la partie relevant des co&#251;ts d&#8217;int&#233;gration de cette th&#233;orie.
Elle consiste &#224; identifier les objets r&#233;f&#233;rentiels pr&#233;sents entre une t&#234;te et son d&#233;pendant situ&#233; au d&#233;but du
syntagme. La valeur de l&#8217;indice est la cardinalit&#233; de l&#8217;ensemble de ces r&#233;f&#233;rents.
</p>
<p>[(Ci ; Cj) &#8743; (Ci &#8826; Cj)] &#8743; [@k | (Ck ; Cj) &#8743; (Ck &#8826; Ci)]&#8658; DLT [j]&#8592; |DRn[i, j]|
avec DRn[i,j] = {Cl[+ref ] | i &#8804; l &#8804; j}(5)
</p>
<p>Cette contrainte identifie le d&#233;pendant Ci le plus &#224; gauche du syntagme projet&#233; par Cj (il n&#8217;existe aucun
d&#233;pendant Ck de Cj qui pr&#233;c&#232;de Ci). Elle instancie la valeur DLT au point j de la cha&#238;ne. Celle-ci cor-
respond &#224; la cardinalit&#233; de l&#8217;ensemble des cat&#233;gories r&#233;f&#233;rentielles comprises entre le d&#233;pendant le plus &#224;
gauche et sa t&#234;te.
</p>
<p>Activation Le degr&#233; d&#8217;activation d&#8217;une cat&#233;gorie Cj se mesure en fonction du poids de la relation de
d&#233;pendance existant entre cette cat&#233;gorie et une autre cat&#233;gorie Ci qui la pr&#233;c&#232;de et qui d&#233;pend d&#8217;elle.
Nous proposons d&#8217;&#233;tendre cette mesure en prenant en compte toutes les relations syntactico-s&#233;mantiques
entretenues par la t&#234;te avec des cat&#233;gories qui la pr&#233;c&#232;de. Dans le cadre des Grammaires de Propri&#233;t&#233;s,</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PHILIPPE BLACHE
</p>
<p>il s&#8217;agit simplement de l&#8217;ensemble des propri&#233;t&#233;s mettant en relation au moins la t&#234;te et une cat&#233;gorie
qui la pr&#233;c&#232;dent. Nous appelons cette mesure la densit&#233;. Une cat&#233;gorie est tr&#232;s activ&#233;e si elle est la cible
d&#8217;un grand nombre de relations (en termes de graphes, si le degr&#233; entrant du sommet est important).
Intuitivement, une cat&#233;gorie sera fortement activ&#233;e si un grand nombre de contraintes sont elles-m&#234;mes
actives et attendent la r&#233;alisation de la cat&#233;gorie pour &#234;tre satisfaites.
</p>
<p>Activ(Cj) =
&#8721;
</p>
<p>Weight(PCj)
avec PCj = {P (x,Cj) | (P (x,Cj) &#8712; G) &#8743; (x unionsq Ci) &#8743; (Ci &#8826; Cj)}
</p>
<p>(6)
</p>
<p>La valeur de l&#8217;indice d&#8217;activation d&#8217;une cat&#233;gorie Cj est donc la somme des poids des propri&#233;t&#233;s de la
grammaire impliquant Cj et une autre cat&#233;gorie Ci qui la pr&#233;c&#232;de. On note que dans l&#8217;&#233;tat de cette d&#233;fini-
tion, c&#8217;est la densit&#233; qui est prise en compte, en mettant au m&#234;me niveau toutes les propri&#233;t&#233;s quel que soit
leur type. Il est possible de modifier cet indice pond&#233;rant les valeurs en fonction du type de contraintes
(permettant par exemple d&#8217;augmenter le poids de la relation de d&#233;pendance). C&#8217;est &#233;galement &#224; ce niveau
que devraient &#234;tre prise en consid&#233;ration les contraintes de s&#233;lection s&#233;mantique, augmentant de fa&#231;on
ind&#233;pendante le niveau d&#8217;activation.
</p>
<p>Degr&#233; d&#8217;embo&#238;tement Nous avons vu qu&#8217;un des facteurs repris r&#233;cemment par des approches com-
putationnelles repose sur la profondeur maximale atteinte par la structure syntaxique lors de l&#8217;analyse.
Dans une approche bas&#233;e sur les contraintes, il existe plusieurs fa&#231;ons de calculer cet indice. Une solution
simple, ind&#233;pendante des strat&#233;gies de parsing, consiste &#224; &#233;valuer les niveaux de d&#233;pendance :
</p>
<p>[Ci ; Cj]&#8658; Prof(Ci) = Prof(Cj) + 1(7)
</p>
<p>Dans ce calcul, chaque cat&#233;gorie C dispose d&#8217;un indice de profondeur, donn&#233; par la fonction Prof(C),
initialis&#233; &#224; 0. En cas de d&#233;pendance, cet indice est &#233;gal &#224; celui de la cat&#233;gorie t&#234;te incr&#233;ment&#233; d&#8217;une unit&#233;.
</p>
<p>Taille des compl&#233;ments / Adjacence Cette contrainte indique que si deux cat&#233;gories Ci et Cj d&#233;pendent
d&#8217;une m&#234;me t&#234;te Ck et que Ci est plus grande en nombre de constituants que Cj , alors Ci sera adjacent
&#224; Ck. Il s&#8217;agit d&#8217;une contrainte dynamique dans le sens ou celle-ci sera ajout&#233;e en cours d&#8217;analyse &#224;
l&#8217;ensemble des contraintes de la grammaire lorsque la pr&#233;-condition est r&#233;alis&#233;e.
</p>
<p>[(Ci ; Ck) &#8743; (Cj ; Ck) &#8743; (|Ci| &gt; |Cj|)]&#8658; Ci &#8853; Ck(8)
</p>
<p>Il est &#224; noter que le principe d&#8217;adjacence tel que d&#233;crit dans cette contrainte n&#8217;implante pas directement
le principe EIC (Early Immediate Constituents). Ce dernier est en effet destin&#233; &#224; comparer deux construc-
tions, tandis que la contrainte ci-dessus est destin&#233;e &#224; &#233;valuer cette propri&#233;t&#233; de fa&#231;on ind&#233;pendante. La
prise en compte de cette propri&#233;t&#233; dans la quantification de la complexit&#233; se fera via la satisfaction ou non
de ces contraintes.
</p>
<p>3.2 Evaluation globale de la complexit&#233;
</p>
<p>La formalisation des indices de complexit&#233; &#224; l&#8217;aide de contraintes permet d&#8217;en distinguer deux types :
indices quantifi&#233;s et contraintes dynamiques. Cette distinction recoupe un second niveau d&#8217;information : il</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UN MOD&#200;LE DE CARACT&#201;RISATION DE LA COMPLEXIT&#201; SYNTAXIQUE
</p>
<p>est en effet possible de distinguer l&#8217;&#233;valuation de la complexit&#233; &#224; un instant t de l&#8217;analyse de la complexit&#233;
d&#8217;une phrase compl&#232;te. Nous parlerons dans ce qui suit de complexit&#233; locale vs. complexit&#233; globale.
</p>
<p>Complexit&#233; locale Les premi&#232;res contraintes correspondent &#224; des indices quantifi&#233;s et sont associ&#233;s &#224;
des cat&#233;gories. Ils permettent de donner une estimation de la complexit&#233; au moment d&#8217;analyser la cat&#233;gorie
courante. Certains indices ont une valeur proportionnelle &#224; la difficult&#233; d&#8217;interpr&#233;tation : c&#8217;est par exemple
le cas de la profondeur (Prof ), de l&#8217;indice de d&#233;pendances incompl&#232;tes (ID) ou de l&#8217;indice de d&#233;pendance
locale (DLT ). D&#8217;autres indices sont en revanche r&#233;v&#233;lateurs d&#8217;une facilitation de l&#8217;interpr&#233;tation, comme
le degr&#233; d&#8217;activation (Activ).
</p>
<p>On introduit ici la notion de complexit&#233; locale permettant de donner une indication de la complexit&#233; au
moment de l&#8217;analyse d&#8217;une cat&#233;gorie C.
</p>
<p>Loc_comp(Ci) = Prof(Ci) +DLT (i) + ID(I)&#8722; Activ(Ci)(9)
</p>
<p>Cette valeur est donc form&#233;e de la somme des valeurs des indices d&#233;notant une difficult&#233; &#224; laquelle on
retranche le degr&#233; d&#8217;activation. Dans un mod&#232;le prenant en compte la fr&#233;quence (ou le niveau de marque
de la construction), on prendrait en compte cette valeur au titre de la facilitation, comme l&#8217;activation.
Signalons que dans l&#8217;&#233;tat de cette proposition, il n&#8217;est pas possible de proposer une pond&#233;ration de ces
crit&#232;res, qui sera obtenue par une exp&#233;rimentation ad hoc. Il est en effet difficile de pr&#233;dire dans quelle
proportion les indices de facilitations peuvent compenser les indices de difficult&#233;.
</p>
<p>Complexit&#233; globale Le second type de contraintes correspond &#224; des propri&#233;t&#233;s ajout&#233;es dynamique-
ment &#224; la grammaire en cours d&#8217;analyse. C&#8217;est le cas de l&#8217;indice sur la taille des compl&#233;ments entra&#238;nant
l&#8217;adjacence &#224; la t&#234;te des compl&#233;ments. Il s&#8217;agit donc au final de contraintes au m&#234;me niveau que celles
de la grammaire. Leur violation entra&#238;nera donc, selon les &#233;tudes psycholinguistiques conduites dans ce
domaine, un surcro&#238;t de complexit&#233;. Nous proposons d&#8217;&#233;largir cette observation &#224; la prise en compte de
la violation de toutes les contraintes. L&#8217;id&#233;e consiste &#224; dire que la complexit&#233; est inversement proportion-
nelle &#224; la grammaticalit&#233; : le nombre de contraintes viol&#233;es pour une phrase est un facteur indicatif de sa
difficult&#233; d&#8217;interpr&#233;tation. Il s&#8217;agit donc d&#8217;un &#233;l&#233;ment indicatif de sa complexit&#233;. La possibilit&#233; de quanti-
fier ce que nous avons appel&#233; &#8220;l&#8217;indice de grammaticalit&#233; (IG)&#8221; permet donc de proposer une valeur qui
participera &#224; l&#8217;&#233;valuation de la complexit&#233; d&#8217;une phrase. Sans entrer dans les d&#233;tails du calcul de IG (cf.
(Blache06)), on rappellera simplement qu&#8217;il s&#8217;agit d&#8217;une fonction reposant sur le poids des contraintes
satisfaites, viol&#233;es, leur situation et leur importance relative dans la phrase et dans la grammaire.
</p>
<p>Nous proposons une &#233;valuation de la complexit&#233; globale d&#8217;une phrase se basant sur l&#8217;indice de gramma-
ticalit&#233; et les complexit&#233;s locales. L&#8217;indice de grammaticalit&#233; permet de rendre compte de la structure de
l&#8217;&#233;nonc&#233; et en particulier des contraintes viol&#233;es. L&#8217;exp&#233;rimentation d&#233;crite dans (Blache06) montre que
les sujets trouvent plus complexes &#224; interpr&#233;ter les phrases ayant un indice de grammaticalit&#233; plus faible.
Nous compl&#233;tons ce type d&#8217;information avec la somme des indices de complexit&#233; locale rapport&#233;e &#224; la
taille de la phrase.
</p>
<p>Glob_comp(Sn) =
n&#8721;
i=1
</p>
<p>Loc_comp(Ci)
n
</p>
<p>+
1
</p>
<p>IG(S)
(10)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PHILIPPE BLACHE
</p>
<p>4 Application de la complexit&#233; locale
</p>
<p>Nous illustrons dans cette section &#224; l&#8217;aide de quelques exemples, le mode de calcul de la complexit&#233; locale
et ses effets sur l&#8217;identification du niveau de complexit&#233;. Dans ces exemples, la grammaire utilis&#233;e se
limite aux relations de d&#233;pendances. Un seul type de propri&#233;t&#233; &#233;tant utilis&#233;, nous n&#8217;introduisons pas de
poids. Par ailleurs, et pour la m&#234;me raison, nous ne prenons pas en compte la notion de complexit&#233; globale
qui repose sur la pond&#233;ration de la complexit&#233; locale par l&#8217;indice de grammaticalit&#233; de la phrase. En se
limitant aux relations de d&#233;pendances, cet indice de grammaticalit&#233; est en effet directement pris en compte
par l&#8217;indice d&#8217;activation et la profondeur. Une &#233;valuation compl&#232;te n&#233;cessiterait bien entendu la prise en
compte d&#8217;une grammaire compl&#232;te. Enfin, le poids respectif de chacun des indices doit &#234;tre pond&#233;r&#233;. En
particulier, nous avons vu que l&#8217;importance de la profondeur de la structure de l&#8217;arbre (ou celle du parser)
doit &#234;tre relativis&#233;e.
</p>
<p>Les exemples qui suivent ont vocation &#224; illustrer le fonctionnement du mod&#232;le propos&#233; plus haut. Les
indices des secondes colonnes des tableaux suivants sont ramen&#233;s soit au nombre de t&#234;tes (c&#8217;est le cas des
indices DRn, Int&#233;gration, et DI), soit au nombre de mots (M&#233;morisation). Les exemples pris sont ceux
traditionnellement utilis&#233;s en psycholinguistique et pour lesquels des effets de complexit&#233; ont &#233;t&#233; montr&#233;
par plusieurs exp&#233;rimentations (temps de r&#233;action, et mouvement oculaire en particulier). Quelques indices
m&#233;ritent d&#8217;&#234;tre d&#233;taill&#233;s :
</p>
<p>&#8211; L&#8217;indice DI r&#233;pertorie le nombre de d&#233;pendance restant &#224; satisfaire. Chaque t&#234;te de syntagme compl&#233;-
ment d&#8217;une autre t&#234;te situ&#233;e apr&#232;s incr&#233;mente la valeur d&#8217;une unit&#233;. Par exemple, le SN sujet, au niveau
de la t&#234;te reporter, introduit une d&#233;pendance incompl&#232;te par rapport au verbe principal qui suit. Le pro-
nom relatif sujet introduit quant &#224; lui une d&#233;pendance incompl&#232;te pour la m&#234;me raison et incr&#233;mente
l&#8217;indice d&#8217;une unit&#233;.
</p>
<p>&#8211; L&#8217;indice Int&#233;gration comptabilise le nombre de DRn s&#233;parant deux &#233;l&#233;ments d&#8217;une relation de d&#233;pen-
dance. Dans cet exemple, le sujet et le verbe de la principale sont s&#233;par&#233;s par 3 r&#233;f&#233;rents (incluant le
r&#233;f&#233;rent &#233;v&#233;nement port&#233; par le verbe lui-m&#234;me).
</p>
<p>&#8211; L&#8217;indice M&#233;morisation s&#8217;incr&#233;mente pour chaque nouvelle relation de compl&#233;mentation, sp&#233;cification
ou adjonction attendue en vue de cr&#233;er une structure syntaxique satur&#233;e. Par exemple, le d&#233;terminant du
SN sujet introduit deux nouvelles relations : une sp&#233;cification (du d&#233;terminant vers le nom) et une de
compl&#233;mentation (du SN qu&#8217;il introduit vers le verbe dont il est sujet).
</p>
<p>&#8211; L&#8217;indice Activation identifie pour chaque t&#234;te le nombre de relations de d&#233;pendances introduites par une
source ant&#233;pos&#233;e dont elle est cible.
</p>
<p>&#8211; Le total des co&#251;ts somme l&#8217;ensemble de ces indices. Rappelons que la valeur de complexit&#233; totale de
l&#8217;&#233;nonc&#233; est faite de cette somme diminu&#233;e de la valeur d&#8217;activation.
</p>
<p>Le premier exemple illustre l&#8217;application du mod&#232;le &#224; une phrase comportant une relative sujet et des
objets multiples permettant d&#8217;introduire des r&#233;f&#233;rents du discours entre le verbe principal et le sujet.
</p>
<p>Le reporter qui adressa le photographe &#224; l&#8217; &#233;diteur travaillait sur un bon sujet
DI 0,86 0 1 2 1 0 1 0 0 1 0 0 0 0 0
</p>
<p>DRn 0,86 0 1 0 1 0 1 0 0 1 1 0 0 0 1
Int&#233;gration 0,43 0 0 0 0 0 0 0 0 0 3 0 0 0 0
</p>
<p>M&#233;morisation 0,93 2 1 2 2 1 1 1 1 1 1 0 0 0 0
Profondeur 3,93 2 2 3 4 5 5 5 6 6 2 3 4 4 4
Total co&#251;ts 7 4 5 7 8 6 8 6 7 9 7 3 4 4 5
Activation 0,64 0 1 0 1 0 1 1 0 1 1 1 0 0 2
</p>
<p>COMPLEXITE 6,36</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UN MOD&#200;LE DE CARACT&#201;RISATION DE LA COMPLEXIT&#201; SYNTAXIQUE
</p>
<p>Le tableau suivant d&#233;crit le cas d&#8217;une relative objet. Les exp&#233;riences montrent que ce type de construc-
tion est plus complexe que la pr&#233;c&#233;dente. Cet effet se manifeste dans plusieurs indices : les d&#233;pendances
incompl&#232;tes sont en plus grand nombre, en particulier suite au fait que les sujets de la principale celui
de la relative ainsi que son objet restent &#224; lier au moment du verbe de la relative (cet effet se retrouvant
&#233;galement au niveau du co&#251;t de m&#233;morisation). De la m&#234;me fa&#231;on, le co&#251;t d&#8217;int&#233;gration est sup&#233;rieur &#224; la
relative sujet, chaque verbe &#233;tant s&#233;par&#233; de la t&#234;te de sa structure locale par deux DRn. Au total, malgr&#233;
une meilleure activation, et conform&#233;ment aux donn&#233;es des exp&#233;rimentations, la relative objet est pr&#233;dite
par le mod&#232;le comme &#233;tant plus complexe &#224; traiter que la relative sujet.
</p>
<p>Le reporter que le photographe adressa &#224; l&#8217; &#233;diteur travaillait sur un bon sujet
DI 1,14 0 1 2 0 3 1 0 0 1 0 0 0 0 0
</p>
<p>DRn 0,86 0 1 0 0 1 1 0 0 1 1 0 0 0 1
Integration 0,86 0 0 0 0 0 3 0 0 0 3 0 0 0 0
</p>
<p>M&#233;morisation 1,36 2 1 3 4 3 2 1 1 1 1 0 0 0 0
Profondeur 4,21 2 2 3 5 5 5 6 7 7 2 3 4 4 4
Total co&#251;ts 8,43 4 5 8 9 12 12 7 8 10 7 3 4 4 5
Activation 0,71 0 1 0 0 1 2 1 0 1 1 1 0 0 2
</p>
<p>COMPLEXITE 7,71
</p>
<p>Le mod&#232;le permet par ailleurs de confirmer l&#8217;observation de complexit&#233; de la relative objet, y compris en
comparant des phrases plus diff&#233;rentes. Le tableau suivant r&#233;v&#232;le cet effet : la phrase, malgr&#233; un nombre de
mots inf&#233;rieurs, est pr&#233;dite comme plus complexe que la premi&#232;re phrase, conform&#233;ment aux exp&#233;riences.
Signalons au passage que, ind&#233;pendamment de la structure, la relative objet en anglais peut &#234;tre encore
plus complexe &#224; traiter par un humain en cas d&#8217;&#233;lision du pronom relatif (The reporter the senator attacked
disliked the editor).
</p>
<p>Le reporter que le s&#233;nateur attaquait d&#233;testait l&#8217; &#233;diteur
DI 1,17 0 1 2 0 3 1 0 0 0
</p>
<p>DRn 0,83 0 1 0 0 1 1 1 0 1
Integration 0,83 0 0 0 0 0 3 2 0 0
</p>
<p>M&#233;morisation 1,78 2 1 3 4 3 1 1 1 0
Profondeur 3,33 2 2 3 5 5 5 2 3 3
Total co&#251;ts 7,94 4 5 8 9 12 11 6 4 4
Activation 0,67 0 1 0 0 1 2 1 0 1
</p>
<p>COMPLEXITE 7,28
</p>
<p>5 Conclusion
</p>
<p>Le mod&#232;le de complexit&#233; d&#233;crit dans cet article pr&#233;sente plusieurs int&#233;r&#234;ts. Il est tout d&#8217;abord un outil
contribuant &#224; l&#8217;explication du fonctionnement du parser humain. Il permet ainsi, en identifiant et locali-
sant les &#233;l&#233;ments de complexit&#233;, de donner un &#233;l&#233;ment de pr&#233;diction de la charge cognitive li&#233;e &#224; la t&#226;che
d&#8217;interpr&#233;tation d&#8217;un &#233;nonc&#233;. Il devient alors possible de quantifier la complexit&#233; de chaque construction
syntaxique. Un des ph&#233;nom&#232;nes que ce type de mod&#232;le permettra d&#8217;examiner est celui de la contribution
relative de chaque domaine linguistique (prosodie, morphologie, syntaxe, etc.) au processus d&#8217;interpr&#233;ta-
tion : une zone de complexit&#233; syntaxique induit vraisemblablement un processus de compensation dans les
autres domaines (la prosodie, par exemple, apportant des &#233;l&#233;ments d&#8217;informations compl&#233;mentaires). Par
ailleurs, un mod&#232;le de complexit&#233; constitue un &#233;l&#233;ment d&#233;cisif pour certaines th&#233;ories linguistiques (typi-
quement la Th&#233;orie de l&#8217;Optimalit&#233;) en offrant la possibilit&#233; de hi&#233;rarchiser des ph&#233;nom&#232;nes syntaxiques.
Enfin, ce type d&#8217;information peut constituer un outil efficace pour la contr&#244;le des processus d&#8217;analyse</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PHILIPPE BLACHE
</p>
<p>syntaxique automatique, en particulier dans le cadre de strat&#233;gies conduisant &#224; une surg&#233;n&#233;ration de struc-
tures. Les perspectives de recherches sont nombreuses. L&#8217;int&#233;gration de ce mod&#232;le de complexit&#233; &#224; un
parser robuste permettra tout d&#8217;abord le traitement de donn&#233;es r&#233;elles. Il sera ainsi possible de tester sur
des sujets humains la difficult&#233; de traitement d&#8217;exemples attest&#233;s, franchissant un pas suppl&#233;mentaire vers
la description de la langue parl&#233;e. Ce type d&#8217;outil permettra par ailleurs une &#233;tude pr&#233;cise des facteurs
de complexit&#233; syntaxique pour un sujet humain : il s&#8217;agit d&#8217;un &#233;l&#233;ment indispensable avant d&#8217;envisager
des &#233;tudes exp&#233;rimentales lourdes sur les processus cognitifs, reposant par exemple sur l&#8217;utilisation de
dispositifs comme l&#8217;IRMf.
</p>
<p>R&#233;f&#233;rences
</p>
<p>[Abney91] Abney S. &amp; M. Johnson (1991) &#8220;Memory requirements and local ambiguities of parsing stra-
tegies&#8221;, in Journal of Psycholinguistic Research, 20(3).
</p>
<p>[Aissen03] Aissen, J. (2003) &#8220;Differential object marking : Iconicity vs. economy&#8221;, in Natural Language
and Linguistic Theory, 21.
</p>
<p>[Blache01] Blache P. (2001) Les Grammaires de Propri&#233;t&#233;s : des contraintes pour le traitement automa-
tique des langues naturelles, Herm&#232;s Sciences.
</p>
<p>[Blache06] Blache P. , B. Hemforth, &amp; S. Rauzy (2006) &#8220;Acceptability prediction by means of gramma-
ticality quantification&#8221;, in proceedings of COLING/ACL 2006.
</p>
<p>[Caplan99] Caplan, D. &amp; Waters, G (1999) &#8220;Verbal working memory and sentence comprehension&#8221;. Be-
havioral and brain Sciences, 22.
</p>
<p>[Chomsky65] Chomsky, N. (1965) Aspects of the theory of syntax. Cambridge, MIT Press.
[Ferreira91] Ferreira F. (1991) &#8220;Effects of Length and Syntactic Complexity on Initiation Times for Pre-
</p>
<p>pared Utterances&#8221;, in Journal of Memory and Language, vol. (30/2).
[Gibson91] Gibson E. (1991) A computational theory of human linguistic processing : memory limita-
</p>
<p>tions and processing breakdown, PhD Dissertation, Carnegie Mellon University.
[Gibson98] Gibson E. (1998) &#8220;Linguistic complexity : Locality of syntactic dependencies&#8221;, 1998 vol. 68
</p>
<p>(1).
[Gibson00] Gibson, E. (2000) &#8220;The dependency locality theory : A distance-based theory of linguistic
</p>
<p>complexity&#8221;. In A. Marantz, Y. Miyashita, &amp; W. O ?Neil (Eds.), Image, language, brain : Papers from
the first mind articulation project symposium, MIT Press.
</p>
<p>[Hale06] Hale J. (2006) &#8220;Uncertainty About the Rest of the Sentence&#8221;, in Cognitive Science 30
[Hawkins01] Hawkins J. (2001) &#8220;Why are categories adjacent&#8221;, in Journal of Linguistics, 37.
[Hawkins10] Hawkins J. (2010) &#8220;Processing efficiency and complexity in typological patterns&#8221;, &#224; para&#238;tre
</p>
<p>in Oxford Handbook of Language Typology (J.J. Song, ed.), Oxford University Press.
[Lee07] Lee Y., H. Lee, P. Gordon (2007) &#8220;Linguistic complexity and information structure in Korean :
</p>
<p>Evidence from eye-tracking during reading&#8221;, in Cognition, vol. 104 (3)
[Vasishth03] Vasishth S. (2003) &#8220;Quantifying processing difficulty in human sentence parsing : The role
</p>
<p>of decay, activation, and similarity-based interference&#8221;, in Proceedings of Eurocogsci 03 : The European
Cognitive Science Conference 2003
</p>
<p>[Schuler09] Schuler W. (2009&#224; &#8220;Positive results for parsing with a bounded stack using a model-based
right-corner transform&#8221;, in proceedings of NAACL 2009</p>

</div></div>
</body></html>