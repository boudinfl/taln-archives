<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Une approche hybride traduction/correction pour la normalisation des SMS</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>Une approche hybride traduction/correction
pour la normalisation des SMS
</p>
<p>Richard Beaufort1 Sophie Roekhaut2 Louise-Am&#233;lie Cougnon1 C&#233;drick Fairon1
</p>
<p>(1) CENTAL, Universit&#233; catholique de Louvain, 1348 Louvain-la-Neuve, Belgique
(2) TCTS Lab, Universit&#233; de Mons, 7000 Mons, Belgique
</p>
<p>R&#233;sum&#233;. Cet article pr&#233;sente une m&#233;thode hybride de normalisation des SMS, &#224; mi-chemin entre
correction orthographique et traduction automatique. La partie du syst&#232;me qui assure la normalisation uti-
lise exclusivement des mod&#232;les entra&#238;n&#233;s sur corpus. Evalu&#233; en fran&#231;ais par validation crois&#233;e, le syst&#232;me
obtient un taux d&#8217;erreur au mot de 9.3% et un score BLEU de 0.83.
</p>
<p>Abstract. This paper presents a method of normalizing SMS messages that shares similarities
with both spell checking and machine translation approaches. The normalization part of the system is
entirely based on models trained from a corpus. Evaluated in French by ten-fold cross-validation, the
system achieves a 9.3% Word Error Rate and a 0.83 BLEU score.
</p>
<p>Mots-cl&#233;s : SMS, normalisation, machines &#224; &#233;tats finis, approche hybride, orient&#233; traduction,
orient&#233; correction, apprentissage sur corpus.
</p>
<p>Keywords: SMS messages, normalization, finite-state machines, hybrid approach, machine translation-
like, spell checking-like, corpus-based learning.
</p>
<p>1 Introduction
</p>
<p>Depuis quelques ann&#233;es, le &#171; Short Message Service &#187; (SMS), moyen de communication qui a &#233;t&#233; ra-
pidement adopt&#233; par les utilisateurs, offre la possibilit&#233; d&#8217;&#233;changer des messages &#233;crits entre t&#233;l&#233;phones
mobiles. Souvent, ces messages s&#8217;&#233;cartent des conventions orthographiques. Comme l&#8217;ont montr&#233; les sp&#233;-
cialistes (Thurlow &amp; Brown, 2003; Fairon et al., 2006), cette variabilit&#233; tient &#224; l&#8217;usage simultan&#233; de plu-
sieurs strat&#233;gies de codage, comme les jeux et les transcriptions phon&#233;tiques (demain&#8594; 2m1, comme&#8594;
kom), les squelettes consonantiques (toujours&#8594; tjrs), les s&#233;parateurs abusifs, manquants ou incorrects (j
esper pour j&#8217;esp&#232;re ; j&#8217;croibi1k pour je crois bien que), etc. Ces &#233;carts sont dus &#224; trois facteurs principaux :
le faible nombre de caract&#232;res autoris&#233; par le service sans surco&#251;t (140 octets), les contraintes dues au
clavier du mobile et, enfin et surtout, le fait que les usagers du SMS communiquent principalement entre
parents ou amis, dans un registre informel. Quelles qu&#8217;en soient les causes, ces &#233;carts entravent consid&#233;ra-
blement le fonctionnement de tout syst&#232;me TAL traditionnel, qui n&#8217;est pas pr&#233;vu pour g&#233;rer tant de mots
hors-vocabulaire. De ce fait, comme le remarquent Sproat et al. (2001), une normalisation SMS, c&#8217;est-&#224;-
dire la r&#233;&#233;criture d&#8217;un SMS en orthographe conventionnelle, doit &#234;tre r&#233;alis&#233;e avant qu&#8217;un module TAL
plus standard (un syst&#232;me de synth&#232;se de la parole, par exemple) ne puisse entrer en action.
</p>
<p>La normalisation SMS a jusqu&#8217;&#224; pr&#233;sent &#233;t&#233; abord&#233;e selon trois angles diff&#233;rents : correction orthogra-
phique, traduction automatique et reconnaissance de la parole. Chaque approche, bas&#233;e sur des postu-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R. BEAUFORT, S. ROEKHAUT, L.-A. COUGNON, C. FAIRON
</p>
<p>lats diff&#233;rents, g&#232;re efficacement certains des ph&#233;nom&#232;nes pr&#233;sents dans les SMS. Cependant, dans l&#8217;en-
semble, normaliser un SMS reste un probl&#232;me complexe et non r&#233;solu : les meilleurs syst&#232;mes, en effet,
descendent difficilement en dessous des 11% d&#8217;erreurs au mot. La m&#233;thode de normalisation que nous
pr&#233;sentons ici, d&#233;velopp&#233;e dans le cadre g&#233;n&#233;ral d&#8217;un syst&#232;me de synth&#232;se de la parole &#224; partir de SMS1,
se situe &#224; mi-chemin entre les approches orient&#233;es correction et traduction. Comme en correction, le sys-
t&#232;me distingue diff&#233;rents types d&#8217;unit&#233;s au sein du texte, et ne normalise que les unit&#233;s consid&#233;r&#233;es comme
bruit&#233;es. Comme en traduction, les mod&#232;les de normalisation sont exclusivement appris &#224; partir de corpus
parall&#232;les.
</p>
<p>Cet article s&#8217;organise comme suit. La section 2 dresse un &#233;tat de l&#8217;art du domaine. La section 3 donne
ensuite une vue d&#8217;ensemble du syst&#232;me, tandis que la section 4 se concentre sur la mani&#232;re dont nous
apprenons et dont nous combinons les mod&#232;les de normalisation. Sur cette base, la section 5 &#233;value le
syst&#232;me et le compare aux travaux ant&#233;rieurs. La section 6, enfin, fait un point sur le travail accompli et
propose quelques am&#233;liorations envisageables.
</p>
<p>2 Travaux ant&#233;rieurs
</p>
<p>Kobus et al. (2008) l&#8217;ont soulign&#233;, la normalisation SMS a jusqu&#8217;&#224; pr&#233;sent &#233;t&#233; formalis&#233;e au travers de
trois m&#233;taphores : correction orthographique, traduction automatique et reconnaissance de la parole.
</p>
<p>La m&#233;taphore orient&#233;e correction (Guimier de Neef &amp; Fessard, 2007; Choudhury et al., 2007; Cook &amp;
Stevenson, 2009) r&#233;alise la t&#226;che de normalisation mot &#224; mot. Partant de l&#8217;hypoth&#232;se que la plupart des
mots sont corrects pour les besoins de la communication, le principe est ici de garder les mots connus en
dehors du processus de normalisation. Guimier de Neef &amp; Fessard (2007) ont propos&#233; un syst&#232;me expert
dont les seules ressources linguistiques d&#233;di&#233;es aux SMS sont des lexiques d&#8217;abr&#233;viations sp&#233;cifiques.
Choudhury et al. (2007) et Cook &amp; Stevenson (2009) ont pr&#233;f&#233;r&#233; impl&#233;menter la m&#233;taphore du canal
bruit&#233; (Shannon, 1948), qui pose un processus de communication dans lequel l&#8217;&#233;metteur envoie le message
voulu W au travers d&#8217;un canal de communication imparfait (bruit&#233;) tel que la s&#233;quence O observ&#233;e par le
destinataire est une version bruit&#233;e de W . Sur cette base, l&#8217;id&#233;e est de retrouver W cach&#233; derri&#232;re O, en
maximisant :
</p>
<p>Wmax = arg maxP (W |O) (1)
= arg max
</p>
<p>P (O|W )P (W )
P (O)
</p>
<p>o&#249; P (O) est ignor&#233; parce que constant, P (O|W ) mod&#233;lise le bruit du canal, et P (W ) mod&#233;lise le lan-
gage de la source. Quelle que soit l&#8217;impl&#233;mentation propos&#233;e, cependant, la limitation principale de cette
m&#233;taphore &#171; correction &#187; est probablement la trop grande confiance qu&#8217;elle accorde aux fronti&#232;res de mots.
</p>
<p>La m&#233;taphore orient&#233;e traduction (Aw et al., 2006) envisage le processus de normalisation comme une
t&#226;che de traduction depuis un langage source (le SMS) vers un langage cible (l&#8217;&#233;crit normalis&#233;). Ce point de
vue se base sur l&#8217;observation que d&#8217;une part, les SMS diff&#232;rent fortement de leur transcription normalis&#233;e
et que d&#8217;autre part, la plupart des erreurs d&#233;passent la fronti&#232;re du mot et ne peuvent &#234;tre g&#233;r&#233;es qu&#8217;au
sein d&#8217;un contexte plus large. Partant de cette analyse, Aw et al. (2006) ont propos&#233; un mod&#232;le statistique
travaillant au niveau du groupe. Bien que cette approche obtienne de tr&#232;s bons r&#233;sultats (voir section 5),
</p>
<p>1Le projet Vocalise. Voir : http://cental.fltr.ucl.ac.be/team/projects/vocalise/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UNE APPROCHE HYBRIDE POUR LA NORMALISATION DES SMS
</p>
<p>Kobus et al. (2008) consid&#232;rent qu&#8217;une traduction au niveau du groupe n&#8217;est pas &#224; m&#234;me de capturer la
grande cr&#233;ativit&#233; lexicale des messages SMS. En outre, les principes de base de la traduction automatique,
pr&#233;vue pour g&#233;rer des correspondances multiples entre source et cible, d&#233;passent largement les besoins de
la normalisation SMS, quasi d&#233;terministe.
</p>
<p>Sur cette base, Kobus et al. (2008) ont propos&#233; de g&#233;rer cette t&#226;che selon la m&#233;taphore de la reconnais-
sance de la parole (automatic speech recognition, ASR). Il est vrai que les SMS pr&#233;sentent de nombreux
jeux phon&#233;tiques qui rendent parfois la forme SMS (sr&#233;, mwa) plus proche de sa repr&#233;sentation phon&#233;-
tique ([sKe], [mwa]) que de sa forme normalis&#233;e (serai, moi). Or, typiquement, un syst&#232;me ASR tente
de d&#233;couvrir la meilleure s&#233;quence de mots cach&#233;e derri&#232;re un treillis de s&#233;quences phon&#233;tiques. Appli-
qu&#233;e aux SMS, cette m&#233;taphore implique de commencer par convertir le message en un treillis de phones,
avant de le transformer en un treillis de s&#233;quences de mots, &#224; l&#8217;aide d&#8217;un dictionnaire invers&#233; phon&#232;mes&#8211;
graph&#232;mes. Un mod&#232;le de langue est ensuite appliqu&#233; au treillis de mots, avant d&#8217;en retenir uniquement
la s&#233;quence de mots la plus probable. Un avantage ind&#233;niable de cette approche est sa capacit&#233; intrin-
s&#232;que &#224; g&#233;rer les fronti&#232;res de mots. Mais l&#8217;inconv&#233;nient de l&#8217;&#233;tape de conversion graph&#232;mes&#8211;phon&#232;mes
est qu&#8217;elle emp&#234;che d&#8217;identifier les graph&#232;mes pr&#233;sents dans la s&#233;quence initiale.
</p>
<p>Notre approche, d&#233;taill&#233;e en sections 3 et 4, partage des similitudes avec les deux premi&#232;res m&#233;taphores,
en essayant de combiner leurs avantages, tout en &#233;vitant leurs inconv&#233;nients : comme les syst&#232;mes de
correction, nous d&#233;tectons au plus t&#244;t les unit&#233;s de texte non ambigu&#235;s et nous utilisons les fronti&#232;res de
mots lorsqu&#8217;elles semblent suffisamment fiables ; mais comme les approches orient&#233;es traduction, notre
processus de normalisation utilise des mod&#232;les exclusivement appris &#224; partir de corpus parall&#232;les. Dans
notre cas, il s&#8217;agit d&#8217;un corpus SMS et de sa transcription, align&#233;s au niveau du caract&#232;re.
</p>
<p>3 Vue d&#8217;ensemble du syst&#232;me
</p>
<p>Notre syst&#232;me repose enti&#232;rement sur des lexiques, des mod&#232;les de langue et des r&#232;gles de r&#233;&#233;criture
compil&#233;s en machines &#224; &#233;tats finis (finite-state machines, FSMs) et combin&#233;s avec le texte &#224; traiter par
composition (&#9702;). Le lecteur qui ne ma&#238;triserait pas les FSMs et leurs propri&#233;t&#233;s fondamentales consultera
utilement la litt&#233;rature de r&#233;f&#233;rence (Hopcroft et al., 1979; Roche &amp; Schabes, 1997). Nous utilisons nos
propres outils &#224; &#233;tats finis : une biblioth&#232;que de FSMs et son compilateur associ&#233; (Beaufort, 2008).
</p>
<p>Modules SMS&#13;
Pr&#233;-traitement 
</p>
<p>SMS&#13;
Normalisation 
</p>
<p>SMS&#13;
Post-traitement&#13;
</p>
<p>SMS&#13;
</p>
<p>Modules TAL standard&#13;
Analyse 
</p>
<p>morphologique&#13;
D&#233;sambigu&#239;sation 
</p>
<p>contextuelle&#13;
SMS&#13;
</p>
<p>Synth&#232;se&#13;
</p>
<p>Impression&#13; Message normalis&#233;&#13;
</p>
<p>Parole&#13;
</p>
<p>FIG. 1 &#8211; Architecture du syst&#232;me
</p>
<p>Comme l&#8217;illustre la figure 1, un SMS passe d&#8217;abord au travers de trois modules SMS qui en normalisent les
parties bruit&#233;es. Deux modules TAL r&#233;alisent ensuite une analyse morphosyntaxique du texte normalis&#233;.
Le dernier module, enfin, d&#233;pend du type de sortie d&#233;sir&#233; : soit un synth&#233;tiseur, qui construit le signal de
parole correspondant au texte normalis&#233; sur la base de son analyse linguistique, soit un module d&#8217;impres-
sion, qui produit le texte normalis&#233; et lui applique les r&#232;gles typographiques fondamentales (majuscule en
d&#233;but de phrase, pr&#233;sence ou absence d&#8217;espaces entre les unit&#233;s du texte, etc.) en se basant sur les uni-
t&#233;s d&#233;tect&#233;es par les modules de pr&#233;- et de post-traitement SMS. Cet article &#233;tant consacr&#233; &#224; l&#8217;&#233;tape de
normalisation, le reste de cette section d&#233;crit exclusivement les trois modules SMS.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R. BEAUFORT, S. ROEKHAUT, L.-A. COUGNON, C. FAIRON
</p>
<p>Le module de pr&#233;traitement. Au sein d&#8217;un texte, ce module rep&#232;re exclusivement les s&#233;quences sui-
vantes : fins de paragraphes et de phrases, URL, num&#233;ros de t&#233;l&#233;phone, dates, unit&#233;s de mesure et de
temps, monnaies et, tr&#232;s fr&#233;quents dans le contexte des SMS, les smileys2. Ces s&#233;quences, identifi&#233;es &#224;
l&#8217;aide de grammaires locales, sont consid&#233;r&#233;es comme des unit&#233;s non ambigu&#235;s et &#233;vitent l&#8217;&#233;tape de nor-
malisation. Toute autre s&#233;quence de caract&#232;res est consid&#233;r&#233;e comme une unit&#233; bruit&#233;e et subit l&#8217;&#233;tape de
normalisation. Ceci rapproche la m&#233;thode de la m&#233;taphore orient&#233;e correction.
</p>
<p>Le module de normalisation. Les mod&#232;les et les lexiques utilis&#233;s ici sont tous appris au cours d&#8217;un
entra&#238;nement d&#233;taill&#233; en section 4. Inspir&#233;e de la m&#233;taphore du canal bruit&#233; (cf. section 2), notre approche
s&#8217;en distingue n&#233;anmoins dans la mesure o&#249; le mod&#232;le d&#233;di&#233; au bruit du canal varie selon que la s&#233;quence
bruit&#233;e est connue (known sequence, KN) ou non (unknown sequence, UNK) :
</p>
<p>P (O|W ) =
&#63729;&#63730;&#63731;
</p>
<p>PKN(O|W ) si O est une s&#233;quence connue
</p>
<p>PUNK(O|W ) sinon
(2)
</p>
<p>Ce mod&#232;le est le r&#233;sultat de nombreux tests, qui ont mis en &#233;vidence le fait que distinguer les s&#233;quences
connues et inconnues am&#233;liore consid&#233;rablement l&#8217;efficacit&#233; du syst&#232;me, sans nuire aux performances. Sur
cette base, notre algorithme se divise en trois &#233;tapes. La premi&#232;re est une composition de l&#8217;unit&#233; bruit&#233;e
U avec un transducteur (finite-state transducer, FST) Seg dont la t&#226;che est de diff&#233;rencier les s&#233;quences
connues des s&#233;quences inconnues, en les &#233;tiquetant avec des symboles de l&#8217;alphabet consid&#233;r&#233;s comme des
marqueurs : KN et UNK. L&#8217;unit&#233; est ensuite divis&#233;e (split) en n segmentsOi en fonction de ces marqueurs :
</p>
<p>{O1, O2, . . . , On&#8722;1, On} = Split(U &#9702; Seg) (3)
</p>
<p>Dans une seconde &#233;tape, chaque segment est compos&#233; avec le mod&#232;le de r&#233;&#233;criture correspondant &#224; son
type : le mod&#232;le RKN pour les s&#233;quences connues, et le mod&#232;le RUNK pour les s&#233;quences inconnues :
</p>
<p>O&#8242;i =
</p>
<p>&#63729;&#63730;&#63731;
Oi &#9702;RKN si Oi est une s&#233;quence connue
</p>
<p>Oi &#9702;RUNK sinon
(4)
</p>
<p>Tous les segments r&#233;&#233;crits sont ensuite reconcat&#233;n&#233;s ensemble, de mani&#232;re &#224; r&#233;cup&#233;rer l&#8217;unit&#233; compl&#232;te :
</p>
<p>U = &#12;ni=1(O&#8242;i) (5)
o&#249; &#12; est l&#8217;op&#233;rateur de concat&#233;nation. La troisi&#232;me &#233;tape, enfin, concerne une phrase compl&#232;te S. Toutes
les unit&#233;s Uj de S sont concat&#233;n&#233;es ensemble et compos&#233;es avec le mod&#232;le de langue lexical LM . Le
r&#233;sultat est un treillis pond&#233;r&#233; de mots, dont on ne retient que la s&#233;quence de mots la plus probable S &#8242;,
c&#8217;est-&#224;-dire le meilleur chemin (best path) du treillis :
</p>
<p>S &#8242; = BestPath( (&#12;mj=1Uj) &#9702; LM ) (6)
o&#249; m est le nombre d&#8217;unit&#233;s de S. Dans S &#8242;, chaque unit&#233; bruit&#233;e Uj de S est associ&#233;e &#224; sa normalisation la
plus probable.
</p>
<p>Le module de post-traitement. Ce dernier module SMS n&#8217;est appliqu&#233; qu&#8217;&#224; la version normalis&#233;e des
unit&#233;s bruit&#233;es, afin d&#8217;y identifier toute s&#233;quence non alphab&#233;tique et de l&#8217;isoler dans une unit&#233; distincte.
A ce stade, par exemple, un point devient une &#171; ponctuation forte &#187;. Les grammaires locales utilis&#233;es ici
sont plus compl&#232;tes que celles du pr&#233;traitement, car elles peuvent &#8211; et doivent &#8211; d&#233;tecter les s&#233;quences
num&#233;riques et alphanum&#233;riques, les champs de donn&#233;es (comme les num&#233;ros de cartes bancaires), les
ponctuations et les symboles.
</p>
<p>2Notre liste compte environ 680 smileys distincts.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UNE APPROCHE HYBRIDE POUR LA NORMALISATION DES SMS
</p>
<p>4 Les mod&#232;les de normalisation
</p>
<p>Nos mod&#232;les de normalisation ont &#233;t&#233; entra&#238;n&#233;s sur un corpus fran&#231;ais de 30 000 messages, collect&#233;s en
Belgique, anonymis&#233;s semi-automatiquement et normalis&#233;s manuellement par l&#8217;Universit&#233; catholique de
Louvain (Fairon &amp; Paumier, 2006). Ensemble, le corpus SMS et sa transcription constituent des corpus
parall&#232;les align&#233;s au niveau du message. Afin de pouvoir apprendre &#224; partir de ces corpus, nous avions
besoin d&#8217;un alignement au niveau du caract&#232;re. Cet alignement a &#233;t&#233; obtenu de mani&#232;re compl&#232;tement
automatique en appliquant l&#8217;algorithme it&#233;ratif d&#233;crit dans (Cougnon &amp; Beaufort, 2009). De mani&#232;re suc-
cincte, cet algorithme apprend graduellement la meilleure fa&#231;on d&#8217;aligner deux s&#233;quences de caract&#232;res,
en affinant pas &#224; pas la probabilit&#233; de chaque op&#233;ration d&#8217;&#233;dition classique (substitution, insertion et sup-
pression) en fonction des caract&#232;res &#224; aligner. L&#8217;apprentissage r&#233;alis&#233; sur l&#8217;alignement obtenu rapproche
la m&#233;thode de la m&#233;taphore orient&#233;e traduction.
</p>
<p>4.1 Le mod&#232;le de segmentation Seg
</p>
<p>Ce mod&#232;le segmente une unit&#233; bruit&#233;e en une suite altern&#233;e de s&#233;quences connues et inconnues. La seg-
mentation est donc r&#233;alis&#233;e en fonction des s&#233;quences connues, collect&#233;es au cours de l&#8217;apprentissage.
Lors du parcours de nos corpus parall&#232;les align&#233;s au niveau du caract&#232;re, nous avons consid&#233;r&#233; comme
s&#233;quence &#171; la plus longue suite de caract&#232;res parcourue sans rencontrer le m&#234;me s&#233;parateur de part et
d&#8217;autre de l&#8217;alignement &#187;. Par exemple, l&#8217;alignement (a) ci-dessous :
</p>
<p>(a) J esper_ k___tu va_ &#8594; (b) J esper_ k___tu va_
J&#8217;esp&#232;re que tu vas J&#8217;esp&#232;re que tu vas
</p>
<p>o&#249; les soulign&#233;s (_) notent les insertions, donne selon notre d&#233;finition la segmentation (b), puisque le
s&#233;parateur dans &#171; J esper &#187; est diff&#233;rent de sa transcription, et que &#171; ktu &#187; ne contient pas de s&#233;parateur.
Cette notion de s&#233;quence se base sur le fait que, dans les SMS, les s&#233;parateurs sont peut-&#234;tre indicatifs,
mais certainement pas fiables.
</p>
<p>Donc, un premier parcours de nos corpus parall&#232;les nous a fourni une liste de s&#233;quences connues corres-
pondant &#224; notre lexique, KN. Le FST de segmentation Seg est construit sur cette base :
</p>
<p>Seg = ( ( Sep&#8727; (Kn|Unk) ( Sep+(Kn|Unk) )&#8727; Sep&#8727; ) &#9702;Mrg ) (7)
o&#249; :
</p>
<p>&#8211; Kn est un FST correspondant au lexique KN, dans lequel chaque s&#233;quence connue est projet&#233;e sur le
marqueur KN.
</p>
<p>&#8211; Unk est le compl&#233;ment de Kn3, o&#249; les s&#233;quences inconnues sont projet&#233;es sur le marqueur UNK.
&#8211; Sep est un FST correspondant &#224; la liste des s&#233;parateurs (tout caract&#232;re non alphab&#233;tique et non num&#233;-
</p>
<p>rique), projet&#233;s sur un marqueur SEP.
&#8211; Mrg est un FST capable de d&#233;tecter les suites de s&#233;quences connues (resp. inconnues), et de les regrou-
</p>
<p>per (merge) sous un unique marqueur KN (resp. UNK). Au cours de ce processus, tous les marqueurs
SEP disparaissent de Seg, et les s&#233;parateurs entourant une s&#233;quence inconnue lui sont associ&#233;s.
</p>
<p>La figure 2 illustre le r&#233;sultat de l&#8217;application de Seg &#224; une unit&#233; bruit&#233;e.
3En r&#233;alit&#233;, le vrai compl&#233;ment de Kn accepte toutes les s&#233;quences avec s&#233;parateurs, alors que Unk ne les accepte pas.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R. BEAUFORT, S. ROEKHAUT, L.-A. COUGNON, C. FAIRON
</p>
<p>e&#13;J&#13; s&#13; p&#13; e&#13; r&#13; k&#13; c&#13; v&#13; b&#13; 1&#13;'  '&#13; '  '&#13; '  '&#13;
KN&#13; KN&#13;UNK&#13;
</p>
<p>FIG. 2 &#8211; R&#233;sultat de l&#8217;application du mod&#232;le de segmentation Seg &#224; l&#8217;unit&#233; &#171; J esper kcv b1 &#187; (J&#8217;esp&#232;re
que &#231;a va bien). Dans cet exemple, la s&#233;quence &#171; kcv &#187; n&#8217;a pas &#233;t&#233; rencontr&#233;e lors de l&#8217;entra&#238;nement ; elle
est donc consid&#233;r&#233;e comme inconnue par Seg, et &#233;tiquet&#233;e UNK.
</p>
<p>4.2 Le mod&#232;le de r&#233;&#233;criture des s&#233;quences connues RKN
</p>
<p>Ce mod&#232;le est construit au cours d&#8217;un second parcours de nos corpus parall&#232;les, dont l&#8217;objectif est de
recenser les normalisations associ&#233;es aux s&#233;quences du lexique KN. Au cours de ce second parcours et
contrairement au pr&#233;c&#233;dent, les s&#233;quences du lexique sont recherch&#233;es dans le corpus quel que soit le
contexte (s&#233;parateurs ou non), afin d&#8217;assurer le recensement de toutes les normalisations possibles.
</p>
<p>Chaque normalisation kn d&#8217;une s&#233;quence connue kn est pond&#233;r&#233;e comme suit :
</p>
<p>p(kn|kn) = Occ(kn, kn)
Occ(kn)
</p>
<p>(8)
</p>
<p>o&#249; Occ(x) note le nombre d&#8217;occurrences de x dans le corpus. Le FST RKN est ensuite construit comme
suit :
</p>
<p>RKN = SKN
&#8727; KNR ( SKN+ KNR )&#8727; SKN &#8727; (9)
</p>
<p>o&#249; :
&#8211; KNR est un lexique pond&#233;r&#233;, dans lequel chaque s&#233;quence KN est associ&#233;e &#224; la liste pond&#233;r&#233;e de ses
</p>
<p>normalisations.
&#8211; SKN est un lexique pond&#233;r&#233;, dans lequel chaque s&#233;parateur est associ&#233; &#224; la liste de ses normalisations
</p>
<p>possibles. Souvent, la suppression du s&#233;parateur est l&#8217;une des normalisations possibles. Lorsque ce n&#8217;est
pas le cas, cette possibilit&#233; de suppression (DEL) est ajout&#233;e, et pond&#233;r&#233;e comme suit :
</p>
<p>p(DEL|kn) = 0.1
Occ(kn) + 0.1
</p>
<p>(10)
</p>
<p>4.3 Le mod&#232;le de r&#233;&#233;criture des s&#233;quences inconnues RUNK
</p>
<p>Les deux mod&#232;les pr&#233;c&#233;dents &#233;taient des expressions r&#233;guli&#232;res construites &#224; partir de lexiques pond&#233;r&#233;s.
Celui-ci, par contre, correspond &#224; une liste de r&#232;gles de r&#233;&#233;criture pond&#233;r&#233;es &#966; &#8594; &#968; / w, apprises &#224;
partir de l&#8217;alignement, o&#249; le remplacement &#966; &#8594; &#968; se voit attribuer le poids w. Pourquoi cette diff&#233;rence
de mod&#233;lisation ? Les expressions r&#233;guli&#232;res des mod&#232;les pr&#233;c&#233;dents avaient pour objectif de contraindre
le langage accept&#233;, et plus particuli&#232;rement la place des s&#233;parateurs, de mani&#232;re &#224; forcer le syst&#232;me &#224;
favoriser certains solutions. Dans le cas des s&#233;quences inconnues, nous savons que dans l&#8217;absolu, tout doit
&#234;tre possible. Il n&#8217;&#233;tait donc pas n&#233;cessaire de d&#233;finir un langage diff&#233;rent de &#931;&#8727;.
</p>
<p>Les cibles de nos r&#232;gles (&#966;) sont des s&#233;quences de 1 &#224; 5 caract&#232;res prises du c&#244;t&#233; SMS de l&#8217;alignement,
tandis que les r&#233;&#233;critures (&#968;) sont leurs normalisations correspondantes. Une contrainte importante ex-
prim&#233;e sur les listes de r&#232;gles est que les r&#232;gles sont class&#233;es de la plus sp&#233;cifique &#224; la plus g&#233;n&#233;rale, de</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UNE APPROCHE HYBRIDE POUR LA NORMALISATION DES SMS
</p>
<p>sorte qu&#8217;une r&#232;gle donn&#233;e n&#8217;est appliqu&#233;e que si aucune r&#232;gle plus sp&#233;cifique et plus pertinente n&#8217;a &#233;t&#233;
rencontr&#233;e plus haut dans la liste. Pour cette raison, nos r&#232;gles sont class&#233;es dans l&#8217;ordre d&#233;croissant de la
longueur de leurs cibles, afin que les r&#232;gles aux cibles les plus longues soient choisies le plus souvent pos-
sible. Ceci r&#233;duit le nombre de normalisations propos&#233;es pour une s&#233;quence donn&#233;e, puisque les s&#233;quences
les plus longues ont tendance &#224; pr&#233;senter moins de normalisations diff&#233;rentes.
</p>
<p>Du large ensemble de s&#233;quences possibles de 2 &#224; 5 caract&#232;res collect&#233;es dans le corpus, nous n&#8217;avons gard&#233;
dans notre liste de r&#232;gles que les s&#233;quences qui autorisent au moins une normalisation faite exclusivement
de mots appartenant &#224; la langue : lors du recensement des s&#233;quences candidates dans le corpus, nous
avons syst&#233;matiquement v&#233;rifi&#233; chaque forme normalis&#233;e dans un lexique de formes fran&#231;aises standard.
Le lexique utilis&#233; contient 430 000 formes fl&#233;chies et est d&#233;riv&#233; de la base de donn&#233;es lexicales Morlex4.
</p>
<p>4.4 Le mod&#232;le de langue
</p>
<p>Notre mod&#232;le de langue statistique est un 3-gramme de formes lexicales, liss&#233; par interpolation lin&#233;aire
(Chen &amp; Goodman, 1998), estim&#233; sur la partie normalis&#233;e de notre corpus d&#8217;entra&#238;nement et compil&#233; en
un FST pond&#233;r&#233; LMw.
</p>
<p>A ce stade, ce FST ne peut pas &#234;tre combin&#233; avec nos autres mod&#232;les, parce que l&#8217;alphabet sur lequel il
est d&#233;fini est fait de formes lexicales et non de caract&#232;res. Ce probl&#232;me est r&#233;solu en composant LMw
avec un autre FST L, qui repr&#233;sente un lexique associant chaque mot, consid&#233;r&#233; comme une s&#233;quence
de caract&#232;res, avec le m&#234;me mot, consid&#233;r&#233; cette fois comme une forme lexicale. Les formes lexicales
sont ensuite supprim&#233;es d&#233;finitivement du mod&#232;le de langue en ne conservant que la premi&#232;re projection
(l&#8217;entr&#233;e) de la composition :
</p>
<p>LM = FirstProjection( L &#9702; LMw ) (11)
</p>
<p>5 Evaluation
</p>
<p>L&#8217;efficacit&#233; et les performances de notre syst&#232;me ont &#233;t&#233; &#233;valu&#233;es sur un MacBook Pro, Intel Core Duo
2,4 GHz, 4 Go SDRAM 667 MHz DDR2, tournant sous Mac OS X version 10.5.8. L&#8217;&#233;valuation a &#233;t&#233;
r&#233;alis&#233;e sur le corpus de 30 000 SMS pr&#233;sent&#233; en section 4, par validation crois&#233;e en 10 blocs (Kohavi,
1995). Le principe de cette m&#233;thode d&#8217;&#233;valuation est de diviser le corpus initial en 10 blocs de taille &#233;gale
(ici, 3 000 SMS). Le syst&#232;me est ensuite entra&#238;n&#233; et test&#233; 10 fois, chaque bloc &#233;tant &#224; son tour exclu du
corpus d&#8217;entra&#238;nement, mais le seul &#224; servir de corpus de test.
</p>
<p>Le tableau 1 pr&#233;sente le nombre moyen d&#8217;entr&#233;es/sorties des 10 mod&#232;les appris au cours de la valida-
tion crois&#233;e. Si les s&#233;quences inconnues (de 1 &#224; 5 caract&#232;res) sont beaucoup moins nombreuses que les
s&#233;quences connues, leur nombre de r&#233;&#233;critures est par contre significativement plus &#233;lev&#233;, ce qui est d&#251;
au fait que ces s&#233;quences sont s&#233;lectionn&#233;es ind&#233;pendamment des s&#233;parateurs &#233;ventuels. Malgr&#233; le grand
nombre de s&#233;quences connues apprises, le syst&#232;me a cependant trait&#233; en moyenne 85% des s&#233;quences
SMS &#224; l&#8217;aide du mod&#232;le UNK.
</p>
<p>Avec une vitesse moyenne de 1836,57 caract&#232;res/sec (&#233;cart type de 159,65), le syst&#232;me traite un SMS
de 140 caract&#232;res en 76,23 ms (&#233;cart type de 22,34 ms). Le syst&#232;me semble donc efficace, &#233;tant donn&#233; le
</p>
<p>4Voir : http://bach.arts.kuleuven.be/pmertens/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R. BEAUFORT, S. ROEKHAUT, L.-A. COUGNON, C. FAIRON
</p>
<p>KN(&#8727;) R&#233;&#233;critures KN UNK(&#8727;) R&#233;&#233;critures UNK Lex&#232;mes(&#8727;&#8727;) n-grammes
Total 41 281 49 152 12 225 69 841 19 801 515 128
</p>
<p>Rapport 1,19 5,71 26,01
</p>
<p>TAB. 1 &#8211; Entr&#233;es/sorties des mod&#232;les. (&#8727;) S&#233;quences SMS. (&#8727;&#8727;) Formes normalis&#233;es.
</p>
<p>1. Notre approche
Validation crois&#233;e, fran&#231;ais
</p>
<p>Copie Hybride
x&#772; &#963; x&#772; &#963;
</p>
<p>Sub. 25,90 1,65 6,69 0,45
Del. 8,24 0,74 1,89 0,31
Ins. 0,46 0,08 0,72 0,10
</p>
<p>WER 34,59 2,37 9,31 0,78
SER 85,74 0,87 65,07 1,85
</p>
<p>BLEU 0,47 0,03 0,83 0,01
x&#772;=moyenne, &#963;=&#233;cart type
</p>
<p>2. Autres approches
En fran&#231;ais En anglais
</p>
<p>Guimier Kobus 2008 Aw Choudury Cook
2007 1 2(&#8727;) 2006 2007(&#8727;&#8727;) 2009(&#8727;&#8727;)
</p>
<p>11,94
2,36
2,21
</p>
<p>16,51 10,82 41,00 44,60
76,05
</p>
<p>0,736 0,8 0,81
</p>
<p>TAB. 2 &#8211; Performances. (&#8727;) Kobus 2008-2 correspond &#224; une combinaison du mod&#232;le ASR de Kobus 2008-1
et d&#8217;un mod&#232;le &#171; orient&#233; traduction &#187; r&#233;alis&#233; &#224; partir d&#8217;un ensemble de logiciels libres. (&#8727;&#8727;) Scores obtenus
sur des donn&#233;es bruit&#233;es uniquement, en dehors du contexte de la phrase.
</p>
<p>temps consid&#233;rable pass&#233; dans le mod&#232;le UNK. Sur ce point, il n&#8217;est malheureusement pas possible de
proposer une comparaison avec les autres syst&#232;mes, qui ne fournissent pas cette information.
</p>
<p>Le tableau 2, partie 1, pr&#233;sente les performances de notre approche (Hybride) et les compare &#224; un simple
copier-coller du SMS (Copie). Nous avons &#233;valu&#233; le syst&#232;me en termes de score BLEU (Papineni et al.,
2001), de taux d&#8217;erreur &#224; la phrase (Sentence Error Rate, SER), et de taux d&#8217;erreur au mot (Word Error
Rate, WER), le WER se subdivisant lui-m&#234;me en substitutions (Sub.), suppressions (Del.) et insertions
(Ins.). Les r&#233;sultats du copier-coller donnent une id&#233;e du bruit r&#233;ellement pr&#233;sent dans le corpus SMS,
et mettent en &#233;vidence le fait que notre syst&#232;me a encore des difficult&#233;s &#224; r&#233;duire le SER, alors que les
r&#233;sultats en termes de WER et de score BLEU sont plut&#244;t encourageants.
</p>
<p>Le tableau 2, partie 2, reproduit les r&#233;sultats des autres approches de la litt&#233;rature. La plupart des r&#233;sultats
sont cependant difficiles &#224; comparer aux n&#244;tres, parce qu&#8217;ils ont &#233;t&#233; obtenus soit dans une langue diff&#233;rente
(l&#8217;anglais), soit sur un corpus diff&#233;rent : c&#8217;est le cas de Kobus et al. (2008), qui d&#8217;une part ont combin&#233;
le corpus que nous avons utilis&#233; &#224; un autre corpus SMS, et d&#8217;autre part ont r&#233;alis&#233; un seul test, bas&#233; sur
un corpus d&#8217;entra&#238;nement plus important (36 704 SMS) pour un corpus de test comparable &#224; l&#8217;un de nos
blocs (2 998 SMS). Les seuls r&#233;sultats v&#233;ritablement comparables sont ceux de Guimier de Neef &amp; Fessard
(2007), qui ont &#233;valu&#233; leur approche sur le m&#234;me corpus que nous, mais sans validation crois&#233;e, parce que
leur syst&#232;me expert ne n&#233;cessite pas d&#8217;apprentissage. Quoi qu&#8217;il en soit, le tableau 2 montre que notre
m&#233;thode supporte tr&#232;s bien la comparaison avec les meilleures m&#233;thodes ant&#233;rieures.
</p>
<p>L&#8217;analyse des normalisations produites par notre syst&#232;me a mis en &#233;vidence trois caract&#233;ristiques impor-
tantes :
</p>
<p>1. Les s&#233;parateurs manquants (Pensa ms&#8594; Pense &#224; mes) ou superflus (G t&#8594; J&#8217;&#233;tais) sont globalement</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UNE APPROCHE HYBRIDE POUR LA NORMALISATION DES SMS
</p>
<p>bien g&#233;r&#233;s, ce qui est refl&#233;t&#233; par nos taux de suppression et d&#8217;insertion r&#233;duits.
</p>
<p>2. Le pr&#233;traitement est utile, puisque les unit&#233;s non ambigu&#235;s ne sont pas modifi&#233;es.
</p>
<p>3. Les erreurs sont souvent contextuelles : elles concernent le genre (quel(le)), le nombre (bisou(s)), la
personne ([tu t&#8217;]inqui&#232;te(s)) ou le temps (arriv&#233;/arriver). Cependant, comme le soulignent Kobus
et al. (2008), la fr&#233;quence de ces erreurs n&#8217;est pas surprenante en fran&#231;ais, langue dans laquelle les
mod&#232;les n-grammes sont souvent incapables de mod&#233;liser cette information, hors de leur port&#233;e.
</p>
<p>6 Conclusion et perspectives
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; une normalisation SMS bas&#233;e sur des machines &#224; &#233;tats finis et d&#233;ve-
lopp&#233;e dans le contexte d&#8217;un syst&#232;me de synth&#232;se de la parole &#224; partir de SMS. Afin d&#8217;&#233;viter la modification
erron&#233;e des unit&#233;s non ambigu&#235;s, nous avons con&#231;u une m&#233;thode hybride, entre correction et traduction.
Notre algorithme de normalisation est original &#224; deux niveaux. Premi&#232;rement, il repose enti&#232;rement sur
des mod&#232;les appris. Deuxi&#232;mement, le mod&#232;le de r&#233;&#233;criture appliqu&#233; &#224; un segment d&#8217;unit&#233; bruit&#233;e change
selon que le segment est connu ou non.
</p>
<p>Evalu&#233; par validation crois&#233;e, le syst&#232;me semble efficace, et les performances en termes de score BLEU
et de WER sont plut&#244;t encourageantes. Cependant, le SER reste trop &#233;lev&#233;, ce qui met en &#233;vidence le fait
que le syst&#232;me a besoin d&#8217;&#234;tre am&#233;lior&#233;.
</p>
<p>Avant tout, la normalisation devrait mieux mod&#233;liser les similarit&#233;s phon&#233;tiques, au vu du grand nombre de
jeux phon&#233;tiques dans les SMS. Le mod&#232;le phon&#233;tique, par exemple, devrait savoir que o, au, eau, . . ., aux
se prononcent [o], tandis que &#232;, ais, ait, . . ., aient sont souvent prononc&#233;s [E]. Cependant, contrairement &#224;
Kobus et al. (2008), nous pensons que ce mod&#232;le doit &#233;viter l&#8217;&#233;tape de conversion graph&#232;mes&#8211;phon&#232;mes,
qui emp&#234;che aux &#233;tapes suivantes d&#8217;identifier les graph&#232;mes pr&#233;sents dans la s&#233;quence initiale. A la place,
nous proposons d&#8217;apprendre les similarit&#233;s phon&#233;tiques &#224; partir d&#8217;un dictionnaire de mots accompagn&#233;s
de leurs transcriptions phon&#233;tiques, et de construire des r&#232;gles graph&#232;mes&#8211;graph&#232;mes. Ces r&#232;gles pour-
raient ensuite &#234;tre pond&#233;r&#233;es, en apprenant leurs fr&#233;quences &#224; partir de nos corpus align&#233;s. Ce mod&#232;le
devrait &#233;galement autoriser les variations de timbre, comme [e]&#8211;[E], afin d&#8217;accepter des similarit&#233;s entre
graph&#232;mes fr&#233;quemment confondus en fran&#231;ais, comme ai ([e]) et ais/ait/aient ([E]).
</p>
<p>Il serait &#233;galement int&#233;ressant de tester l&#8217;impact d&#8217;un autre mod&#232;le de langue lexical, entra&#238;n&#233; sur des
phrases non-SMS. En effet, le mod&#232;le lexical pr&#233;sente un inconv&#233;nient majeur dans le contexte de mes-
sages SMS : il doit &#234;tre appris sur des formes standard, ce qui, dans le contexte des SMS, implique
la retranscription du corpus, un processus co&#251;teux qui r&#233;duit le nombre de donn&#233;es d&#8217;entra&#238;nement du
mod&#232;le. . . Le corpus qui remplacerait le corpus SMS retranscrit devrait cependant partager deux points
communs avec le langage SMS : il devrait mimer la syntaxe de l&#8217;oral et &#234;tre le plus spontan&#233; possible. Sur
la base de ces contraintes, notre intention est de r&#233;colter des phrases de forums Internet, en s&#233;lectionnant
ces forums avec soin, parce que leurs textes partagent un autre point commun avec les SMS : ils sont
bruit&#233;s. De ce fait, l&#8217;id&#233;e est de choisir un forum dont la philosophie est explicitement d&#8217;&#233;viter l&#8217;utilisation
du langage SMS et d&#8217;accorder de l&#8217;importance &#224; l&#8217;orthographe et &#224; la grammaire.
</p>
<p>La derni&#232;re am&#233;lioration que nous proposons ici est plus orient&#233;e correction : l&#8217;id&#233;e est d&#8217;autoriser la
correction orthographique &#224; l&#8217;int&#233;rieur des modules TAL du syst&#232;me. Plac&#233;es &#224; ce stade du processus,
guid&#233;es par l&#8217;analyse morphosyntaxique et en combinaison avec elle, des m&#233;thodes de correction plus
sophistiqu&#233;es pourraient ainsi se focaliser sur le probl&#232;me non trivial des erreurs contextuelles.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R. BEAUFORT, S. ROEKHAUT, L.-A. COUGNON, C. FAIRON
</p>
<p>Remerciements
</p>
<p>Cette recherche a &#233;t&#233; co-financ&#233;e par les projets FIRST Post-Doc &#171; Vocalise &#187; (convention 716619) et
WIST2 &#171; Expressive &#187; (convention 616422) de la R&#233;gion wallonne.
</p>
<p>R&#233;f&#233;rences
</p>
<p>AW A., ZHANG M., XIAO J. &amp; SU J. (2006). A phrase-based statistical model for sms text normaliza-
tion. In Proc. COLING/ACL 2006.
BEAUFORT R. (2008). Application des Machines &#224; Etats Finis en Synth&#232;se de la Parole. S&#233;lection
d&#8217;unit&#233;s non uniformes et Correction orthographique. PhD thesis, FUNDP, Namur, Belgium. 605 pages.
CHEN S. F. &amp; GOODMAN J. (1998). An Empirical Study of Smoothing Techniques for Language Mode-
ling. Rapport interne 10-98, Computer Science Group, Harvard University.
CHOUDHURY M., SARAF R., JAIN V., MUKHERJEE A., SARKAR1 S. &amp; BASU A. (2007). Investigation
and modeling of the structure of texting language. International Journal on Document Analysis and
Recognition, 10(3), 157&#8211;174.
COOK P. &amp; STEVENSON S. (2009). An Unsupervised Model for Text Message Normalization. In Proc.
Workshop on Computational Approaches to Linguistic Creativity, p. 71&#8211;78.
COUGNON L.-A. &amp; BEAUFORT R. (2009). SSLD : a French SMS to Standard Language Dictionary.
In S. GRANGER &amp; M. PAQUOT, Eds., Proc. eLexicography in the 21st century : New applications, new
challenges (eLEX 2009) : Presses Universitaires de Louvain. To appear.
FAIRON C., KLEIN J. R. &amp; PAUMIER S. (2006). Le langage SMS : &#233;tude d&#8217;un corpus informatis&#233; &#224;
partir de l&#8217;enqu&#234;te Faites don de vos SMS &#224; la science. Presses Universitaires de Louvain.
FAIRON C. &amp; PAUMIER S. (2006). A translated corpus of 30,000 French SMS. In Proc. LREC 2006.
GUIMIER DE NEEF E. &amp; FESSARD S. (2007). Evaluation d&#8217;un syst&#232;me de transcription de SMS. In
Actes de Lexique et Grammaire 2007, p. 217&#8211;224.
J. HOPCROFT, R. MOTWANI &amp; J. ULLMAN, Eds. (1979). Introduction to Automata Theory, Languages,
and Computation. Massachusetts : Addison-Wesley.
KOBUS C., YVON F. &amp; DAMNATI G. (2008). Normalizing SMS : are two metaphors better than one ?
In Proc. COLING 2008, p. 441&#8211;448, Manchester, UK.
KOHAVI R. (1995). A study of Cross-Validation and Bootstrap for Accuracy Estimation and Model
Selection. In Proc. IJCAI&#8217;95, p. 1137&#8211;1143.
PAPINENI K., ROUKOS S., WARD T. &amp; ZHU W.-J. (2001). BLEU : a method for automatic evaluation
of machine translation. In Proc. ACL 2001, p. 311&#8211;318.
E. ROCHE &amp; Y. SCHABES, Eds. (1997). Finite-State Language Processing. Cambridge : MIT Press.
SHANNON C. E. (1948). A mathematical theory of communication. The Bell System Technical Journal,
27, 379&#8211;423.
SPROAT R., BLACK A., CHEN S., KUMAR S., OSTENDORF M. &amp; RICHARDS C. (2001). Normaliza-
tion of non-standard words. Computer Speech &amp; Language, 15(3), 287&#8211;333.
THURLOW C. &amp; BROWN A. (2003). Generation txt ? The sociolinguistics of young people&#8217;s text-
messaging. Discourse Analysis Online, 1(1).</p>

</div></div>
</body></html>