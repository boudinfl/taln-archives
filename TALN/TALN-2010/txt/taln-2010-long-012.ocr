TALN 2010, Montréal, 19-23 juillet 2010

Une approche hybride traduction/correction
pour la normalisation des SMS

Richard Beaufortl Sophie Roekhautz Louise-Amelie Cougnonl Cédrick Faironl
(1) CENTAL, Université catholique de Louvain, 1348 Louvain-la-Neuve, Belgique
(2) TCTS Lab, Université de Mons, 7000 Mons, Belgique

Résumé. Cet article présente une méthode hybride de normalisation des SMS, a mi-chemin entre
correction orthographique et traduction automatique. La partie du systeme qui assure la normalisation uti-
lise exclusivement des modeles entrainés sur corpus. Evalué en francais par validation croisée, le systeme
obtient un taux d’erreur au mot de 9.3% et un score BLEU de 0.83.

Abstract. This paper presents a method of normalizing SMS messages that shares similarities
with both spell checking and machine translation approaches. The normalization part of the system is
entirely based on models trained from a corpus. Evaluated in French by ten-fold cross-validation, the
system achieves a 9.3% Word Error Rate and a 0.83 BLEU score.

M0tS-CléS 2 SMS, normalisation, machines a états ﬁnis, approche hybride, orienté traduction,
orienté correction, apprentissage sur corpus.

Keywords: SMS messages, normalization, ﬁnite-state machines, hybrid approach, machine translation-
like, spell checking-like, corpus-based learning.

1 Introduction

Depuis quelques années, le « Short Message Service » (SMS), moyen de communication qui a été ra-
pidement adopté par les utilisateurs, offre la possibilité d’échanger des messages écrits entre téléphones
mobiles. Souvent, ces messages s’écartent des conventions orthographiques. Comme l’ont montré les spé-
cialistes (Thurlow & Brown, 2003; Fairon et al., 2006), cette variabilité tient a l’usage simultané de plu-
sieurs stratégies de codage, comme les jeux et les transcriptions phonétiques (demain —> 2m], comme —>
kom), les squelettes consonantiques (toujours —> zjrs), les séparateurs abusifs, manquants ou incorrects (j
esper pour j’espere ; j’cr0ibiI k pour je crois bien que), etc. Ces écarts sont dus a trois facteurs principaux :
le faible nombre de caracteres autorisé par le service sans surcoﬁt (140 octets), les contraintes dues au
clavier du mobile et, enﬁn et surtout, le fait que les usagers du SMS communiquent principalement entre
parents ou amis, dans un registre informel. Quelles qu’en soient les causes, ces écarts entravent considera-
blement le fonctionnement de tout systeme TAL traditionnel, qui n’est pas prévu pour gérer tant de mots
hors-vocabulaire. De ce fait, comme le remarquent Sproat et al. (2001), une normalisation SMS, c’est-a-
dire la réécriture d’un SMS en orthographe conventionnelle, doit étre réalisée avant qu’un module TAL
plus standard (un systeme de synthese de la parole, par exemple) ne puisse entrer en action.

La normalisation SMS a jusqu’a présent été abordée selon trois angles différents : correction orthogra-
phique, traduction automatique et reconnaissance de la parole. Chaque approche, basée sur des postu-

R. BEAUFORT, S. ROEKHAUT, L.-A. COUGNON, C. FAIRON

lats différents, gere efﬁcacement certains des phénomenes présents dans les SMS. Cependant, dans l’en-
semble, normaliser un SMS reste un probleme complexe et non résolu : les meilleurs systemes, en effet,
descendent difﬁcilement en dessous des 11% d’erreurs au mot. La méthode de normalisation que nous
présentons ici, développée dans le cadre général d’un systeme de synthese de la parole a partir de SMS1,
se situe a mi-chemin entre les approches orientées correction et traduction. Comme en correction, le sys-
teme distingue différents types d’unités au sein du texte, et ne normalise que les unités considérées comme
bmitées. Comme en traduction, les modeles de normalisation sont exclusivement appris £1 partir de corpus
paralléles.

Cet article s’organise comme suit. La section 2 dresse un état de l’art du domaine. La section 3 donne
ensuite une vue d’ensemble du systeme, tandis que la section 4 se concentre sur la maniere dont nous
apprenons et dont nous combinons les modeles de normalisation. Sur cette base, la section 5 évalue le
systeme et le compare aux travaux antérieurs. La section 6, enﬁn, fait un point sur le travail accompli et
propose quelques améliorations envisageables.

2 Travaux antérieurs

Kobus et al. (2008) l’ont souligné, la normalisation SMS a jusqu’a présent été formalisée au travers de
trois métaphores : correction orthographique, traduction automatique et reconnaissance de la parole.

La métaphore orientée correction (Guimier de Neef & Fessard, 2007; Choudhury et al., 2007; Cook &
Stevenson, 2009) réalise la tache de normalisation mot £1 mot. Partant de l’hypothese que la plupart des
mots sont corrects pour les besoins de la communication, le principe est ici de garder les mots connus en
dehors du processus de normalisation. Guimier de Neef & Fessard (2007) ont proposé un systeme expert
dont les seules ressources linguistiques dédiées aux SMS sont des lexiques d’abréviations spéciﬁques.
Choudhury et al. (2007) et Cook & Stevenson (2009) ont préféré implémenter la métaphore du canal
bruité (Shannon, 1948), qui pose un processus de communication dans lequel l’émetteur envoie le message
voulu W au travers d’un canal de communication imparfait (bruité) tel que la sequence 0 observée par le
destinataire est une version bruitée de W. Sur cette base, l’idée est de retrouver W caché derriere 0, en
maximisant :

Wm“ = arg maxP(W|O) (1)

P(O|W) P(W)
P(O)

arg max

ou P(O) est ignoré parce que constant, P(O|W) modélise le bruit du canal, et P(W) modélise le lan-
gage de la source. Quelle que soit l’implémentation proposée, cependant, la limitation principale de cette
métaphore « correction » est probablement la trop grande conﬁance qu’elle accorde aux frontieres de mots.

La métaphore orientée traduction (Aw et al., 2006) envisage le processus de normalisation comme une
tache de traduction depuis un langage source (le SMS) vers un langage cible (l’écrit normalisé). Ce point de
vue se base sur l’observation que d’une part, les SMS different fortement de leur transcription normalisée
et que d’autre part, la plupart des erreurs dépassent la frontiere du mot et ne peuvent étre gérées qu’au
sein d’un contexte plus large. Partant de cette analyse, Aw et al. (2006) ont proposé un modele statistique
travaillant au niveau du groupe. Bien que cette approche obtienne de tres bons résultats (voir section 5),

1Le projetVoca1ise. Voir : http: //cental . fltr . ucl . ac . be/team/projects/vocalise/

UNE APPROCHE HYBRIDE POUR LA NORMALISATION DES SMS

Kobus et al. (2008) considerent qu’une traduction au niveau du groupe n’est pas a meme de capturer la
grande créativité lexicale des messages SMS. En outre, les principes de base de la traduction automatique,
prevue pour gérer des correspondances multiples entre source et cible, dépassent largement les besoins de
la normalisation SMS, quasi déterministe.

Sur cette base, Kobus et al. (2008) ont propose de gerer cette tache selon la métaphore de la reconnais-
sance de la parole (automatic speech recognition, ASR). Il est Vrai que les SMS présentent de nombreux
jeux phonetiques qui rendent parfois la forme SMS (sré, mwa) plus proche de sa representation phone-
tique ([SB6], [mwa]) que de sa forme normalisee (serai, moi). Or, typiquement, un systeme ASR tente
de découvrir la meilleure sequence de mots cachée derriere un treillis de sequences phonetiques. Appli-
quee aux SMS, cette métaphore implique de commencer par convertir le message en un treillis de phones,
avant de le transformer en un treillis de sequences de mots, a l’aide d’un dictionnaire inverse phonemes-
graphemes. Un modele de langue est ensuite applique au treillis de mots, avant d’en retenir uniquement
la sequence de mots la plus probable. Un avantage indeniable de cette approche est sa capacité intrin-
seque a gérer les frontieres de mots. Mais l’inconVénient de l’étape de conversion graphemes—phonemes
est qu’elle empeche d’identiﬁer les graphemes presents dans la sequence initiale.

Notre approche, détaillée en sections 3 et 4, partage des similitudes avec les deux premieres métaphores,
en essayant de combiner leurs avantages, tout en évitant leurs inconvénients : comme les systemes de
correction, nous détectons au plus tot les unites de texte non ambigues et nous utilisons les frontieres de
mots lorsqu’elles semblent suﬁisamment ﬁables; mais comme les approches orientees traduction, notre
processus de normalisation utilise des modeles exclusivement appris a partir de corpus paralleles. Dans
notre cas, il s’agit d’un corpus SMS et de sa transcription, alignés au niveau du caractere.

3 Vue d’ensemble du systéme

Notre systeme repose entierement sur des lexiques, des modeles de langue et des regles de réécriture
compiles en machines a états ﬁnis (ﬁnite-state machines, FSMs) et combines avec le texte a traiter par
composition (0). Le lecteur qui ne maitriserait pas les FSMs et leurs propriétés fondamentales consultera
utilement la littérature de reference (Hopcroft et al., 1979; Roche & Schabes, 1997). Nous utilisons nos
propres outils a états ﬁnis : une bibliotheque de FSMs et son compilateur associé (Beaufort, 2008).

Modules SMS Modules TAL standard Synthése
SMS Pré—traitement Normalisation Post—traitement — Analyse Désambiguisation <
SMS SMS SMS morphologique contextuelle Impression — 

FIG. 1 — Architecture du systeme

Comme l’illustre la ﬁgure 1, un SMS passe d’abord au travers de trois modules SMS qui en normalisent les
parties bruitees. Deux modules TAL réalisent ensuite une analyse morphosyntaxique du texte normalise.
Le dernier module, enﬁn, depend du type de sortie desire : soit un synthétiseur, qui construit le signal de
parole correspondant au texte normalise sur la base de son analyse linguistique, soit un module d’impres—
sion, qui produit le texte normalise et lui applique les regles typographiques fondamentales (majuscule en
debut de phrase, presence ou absence d’espaces entre les unites du texte, etc.) en se basant sur les uni-
tes detectées par les modules de pre— et de post—traitement SMS. Cet article étant consacré a l’étape de
normalisation, le reste de cette section décrit exclusivement les trois modules SMS.

R. BEAUFORT, S. ROEKHAUT, L.-A. COUGNON, C. FAIRON

Le module de prétraitement. Au sein d’un texte, ce module repere exclusivement les séquences sui-
vantes : ﬁns de paragraphes et de phrases, URL, numéros de téléphone, dates, unités de mesure et de
temps, monnaies et, tres fréquents dans le contexte des SMS, les smileysz. Ces séquences, identiﬁées a
l’aide de grammaires locales, sont considérées comme des unite’s non ambigues et évitent l’étape de nor-
malisation. Toute autre séquence de caracteres est considérée comme une unite’ bruitée et subit l’étape de
normalisation. Ceci rapproche la méthode de la métaphore orientée correction.

Le module de normalisation. Les modeles et les lexiques utilisés ici sont tous appris au cours d’un
entrainement détaillé en section 4. Inspirée de la métaphore du canal bruité (cf. section 2), notre approche
s’en distingue néanmoins dans la mesure ou le modele dédié au bruit du canal varie selon que la séquence
bruitée est connue (known sequence, KN) ou non (unknown sequence, UNK) :

PKN(O|W) si 0 est une séquence connue
P(0 | W) = (2)
PUNK(O | W) sinon

Ce modele est le résultat de nombreux tests, qui ont mis en évidence le fait que distinguer les séquences
connues et inconnues améliore considérablement l’efﬁcacité du systeme, sans nuire aux performances. Sur
cette base, notre algorithme se divise en trois étapes. La premiere est une composition de l’unité bruitée
U avec un transducteur (ﬁnite-state transducer, FST) Seg dont la tache est de différencier les séquences
connues des séquences inconnues, en les étiquetant avec des symboles de l’alphabet considérés comme des
marqueurs : KN et UNK. L’unité est ensuite divisée (split) en n segments 0, en fonction de ces marqueurs :

{O1,O2, . . . ,On_1, On} 2  O  

Dans une seconde étape, chaque segment est composé avec le modele de réécriture correspondant a son
type : le modele RKN pour les séquences connues, et le modele RUNK pour les séquences inconnues :

O, o RKN si 0, est une séquence connue
I
Oi = (4)

Oi O RUNK SlI1OI1
Tous les segments réécrits sont ensuite reconcaténés ensemble, de maniere a récupérer l’unité complete :
_ 1'1. I
U — ®i=1(Oi) (5)

oil 6) est l’opérateur de concaténation. La troisieme étape, enﬁn, conceme une phrase complete S . Toutes
les unités Uj de S sont concaténées ensemble et composées avec le modele de langue lexical LM. Le
résultat est un treillis pondéré de mots, dont on ne retient que la séquence de mots la plus probable S’,
c’est-a-dire le meilleur chemin (best path) du treillis :

S’ = BestPath( (G);-":1Uj) 0 LM ) (6)

o1‘1 m est le nombre d’unités de S . Dans S’, chaque unité bruitée U 9- de S est associée a sa normalisation la
plus probable.

Le module de post-traitement. Ce demier module SMS n’est appliqué qu’a la version normalisée des
unités bruitées, aﬁn d’y identiﬁer toute séquence non alphabétique et de l’isoler dans une unité distincte.
A ce stade, par exemple, un point devient une « ponctuation forte ». Les grammaires locales utilisées ici
sont plus completes que celles du prétraitement, car elles peuvent — et doivent — détecter les séquences
numériques et alphanumériques, les champs de données (comme les numéros de cartes bancaires), les
ponctuations et les symboles.

2Notre liste compte environ 680 smileys distincts.

UNE APPROCHE HYBRIDE POUR LA NORMALISATION DES SMS

4 Les modéles de normalisation

Nos modeles de normalisation ont ete entraines sur un corpus francais de 30 000 messages, collectes en
Belgique, anonymises seIni-automatiquement et normalises manuellement par l’Universite catholique de
Louvain (Fairon & Paumier, 2006). Ensemble, le corpus SMS et sa transcription constituent des corpus
paralléles alignes au niveau du message. Aﬁn de pouvoir apprendre a partir de ces corpus, nous avions
besoin d’un alignement au niveau du caractére. Cet alignement a ete obtenu de maniere completement
automatique en appliquant l’algorithme iteratif decrit dans (Cougnon & Beaufort, 2009). De maniere suc-
cincte, cet algorithme apprend graduellement la meilleure facon d’aligner deux sequences de caracteres,
en afﬁnant pas a pas la probabilite de chaque operation d’edition classique (substitution, insertion et sup-
pression) en fonction des caracteres a aligner. L’ apprentissage realise sur l’alignement obtenu rapproche
la methode de la metaphore orientee traduction.

4.1 Le modele de segmentation Seg

Ce modele segmente une unite bruitee en une suite alternee de sequences connues et inconnues. La seg-
mentation est donc realisee en fonction des sequences connues, collectees au cours de l’apprentissage.
Lors du parcours de nos corpus paralleles alignes au niveau du caractere, nous avons considere comme
séquence « la plus longue suite de caracteres parcourue sans rencontrer le meme separateur de part et
d’autre de l’a1ignement ». Par exemple, l’alignement (a) ci-dessous :

(a) J esper_ k tu va_ —> (b) J esper_

J’espére que tu vas J’espére

k tu

que tu

va

vas

ou les soulignes (J notent les insertions, donne selon notre deﬁnition la segmentation (b), puisque le
separateur dans « J e spe r » est different de sa transcription, et que « ktu » ne contient pas de separateur.
Cette notion de séquence se base sur le fait que, dans les SMS, les separateurs sont peut-étre indicatifs,
mais certainement pas ﬁables.

Donc, un premier parcours de nos corpus paralleles nous a foumi une liste de sequences connues corres-
pondant a notre lexique, KN. Le FST de segmentation S eg est construit sur cette base :

.369 = ( ( Sep* (Kn|Unk) (Sep+(Kn|Unk) )* Sep* ) o Mrg) (7)

\

0113

— Kn est un FST correspondant au lexique KN, dans lequel chaque sequence connue est projetee sur le
marqueur KN.

— U nk est le complement de K123, ou les sequences inconnues sont projetees sur le marqueur UNK.

— S ep est un FST correspondant a la liste des separateurs (tout caractere non alphabetique et non nume-
rique), projetes sur un marqueur SEP.

— M rg est un FST capable de detecter les suites de sequences connues (resp. inconnues), et de les regrou-
per (merge) sous un unique marqueur KN (resp. UNK). Au cours de ce processus, tous les marqueurs
SEP disparaissent de S eg, et les separateurs entourant une sequence inconnue lui sont associes.

La ﬁgure 2 illustre le resultat de l’application de Seg a une unite bruitee.

3En realite, le Vrai complement de K n accepte toutes les sequences avec separateurs, alors que U nk ne les accepte pas.

R. BEAUFORT, S. ROEKHAUT, L.-A. COUGNON, C. FAIRON

JL
\ ¥ \/—’%

J"esper"kcV"bl

 
KN UNK KN

FIG. 2 — Resultat de l’application du modele de segmentation Seg a l’unite << J esper kcv bl » (J ’espére
que ya va bien). Dans cet exemple, la sequence « kcv >> n’a pas été rencontree lors de l’entrainement; elle
est donc considéree comme inconnue par Seg, et etiquetée UNK.

4.2 Le modéle de réécriture des séquences connues RKN

Ce modele est construit au cours d’un second parcours de nos corpus paralleles, dont l’objectif est de
recenser les normalisations associées aux sequences du lexique KN. Au cours de ce second parcours et
contrairement au precedent, les sequences du lexique sont recherchees dans le corpus quel que soit le
contexte (separateurs ou non), aﬁn d’assurer le recensement de toutes les normalisations possibles.

Chaque normalisation % d’une sequence connue kn est ponderee comme suit :

Occ(%, kn)

 : Occ(lm)

(8)

ou Occ(a:) note le nombre d’occurrences de :5 dans le corpus. Le FST RKN est ensuite construit comme
suit :
RKN = SKN* KNR (SKN+ KNR )* 3KN* (9)

\

ou :

— K N R est un lexique pondere, dans lequel chaque sequence KN est associée a la liste ponderée de ses
normalisations.

— SKN est un lexique pondéré, dans lequel chaque separateur est associe a la liste de ses normalisations
possibles. Souvent, la suppression du separateur est l’une des normalisations possibles. Lorsque ce n’est
pas le cas, cette possibilite de suppression (DEL) est ajoutée, et ponderee comme suit :

0.1
p(DEL|/€71)‘  (10)

4.3 Le modéle de réécriture des séquences inconnues RUNK

Les deux modeles precedents etaient des expressions régulieres construites a partir de lexiques pondérés.
Celui—ci, par contre, correspond a une liste de régles de réécriture pondérées gb —> 1D / w, apprises a
partir de l’alignement, ou le remplacement gb —> zb se Voit attribuer le poids w. Pourquoi cette difference
de modelisation ? Les expressions régulieres des modeles precedents avaient pour objectif de contraindre
le langage accepte, et plus particulierement la place des séparateurs, de maniere a forcer le systeme a
favoriser certains solutions. Dans le cas des sequences inconnues, nous savons que dans l’absolu, tout doit
étre possible. Il n’était donc pas necessaire de deﬁnir un langage different de 2*.

Les cibles de nos regles (gb) sont des séquences de l a 5 caracteres prises du cote SMS de l’alignement,
tandis que les réécritures (zb) sont leurs normalisations correspondantes. Une contrainte importante ex-
primee sur les listes de regles est que les regles sont classees de la plus speciﬁque a la plus générale, de

UNE APPROCHE HYBRIDE POUR LA NORMALISATION DES SMS

sorte qu’une regle donnée n’est appliquée que si aucune regle plus spéciﬁque et plus pertinente n’a été
rencontrée plus haut dans la liste. Pour cette raison, nos regles sont classées dans l’ordre décroissant de la
longueur de leurs cibles, aﬁn que les regles aux cibles les plus longues soient choisies le plus souvent pos-
sible. Ceci réduit le nombre de normalisations proposées pour une séquence donnée, puisque les séquences
les plus longues ont tendance a presenter moins de normalisations différentes.

Du large ensemble de séquences possibles de 2 a 5 caracteres collectées dans le corpus, nous n’avons gardé
dans notre liste de regles que les séquences qui autorisent au moins une normalisation faite exclusivement
de mots appartenant a la langue : lors du recensement des séquences candidates dans le corpus, nous
avons systématiquement vériﬁé chaque forme normalisée dans un lexique de formes francaises standard.
Le lexique utilisé contient 430 000 formes ﬂéchies et est dérivé de la base de données lexicales Morlex4.

4.4 Le modéle de langue

Notre modele de langue statistique est un 3-gramme de formes lexicales, lissé par interpolation linéaire
(Chen & Goodman, 1998), estimé sur la partie normalisée de notre corpus d’entrainement et compilé en
un FST pondéré LMw.

A ce stade, ce FST ne peut pas étre combine’ avec nos autres modeles, parce que l’alphabet sur lequel il
est déﬁni est fait de formes lexicales et non de caractéres. Ce probleme est résolu en composant LMH,
avec un autre FST L, qui représente un lexique associant chaque mot, considéré comme une séquence
de caracteres, avec le meme mot, considéré cette fois comme une forme lexicale. Les formes lexicales
sont ensuite supprimées déﬁnitivement du modele de langue en ne conservant que la premiere projection
(l’entrée) de la composition :

LM = FirstProjection( L o LMU, ) (11)

5 Evaluation

L’efﬁcacité et les performances de notre systeme ont été évaluées sur un MacBook Pro, Intel Core Duo
2,4 GHz, 4Go SDRAM 667MHz DDR2, tournant sous Mac OS X version 10.5.8. L’évaluation a été
réalisée sur le corpus de 30000 SMS présenté en section 4, par validation croisée en 10 blocs (Kohavi,
1995). Le principe de cette méthode d’évaluation est de diviser le corpus initial en 10 blocs de taille égale
(ici, 3 000 SMS). Le systeme est ensuite entrainé et testé 10 fois, chaque bloc étant a son tour exclu du
corpus d’entrainement, mais le seul a servir de corpus detest.

Le tableau 1 présente le nombre moyen d’entrées/sorties des 10 modeles appris au cours de la valida-
tion croisée. Si les séquences inconnues (de 1 a 5 caracteres) sont beaucoup moins nombreuses que les
séquences connues, leur nombre de réécritures est par contre signiﬁcativement plus élevé, ce qui est dﬁ
au fait que ces séquences sont sélectionnées indépendamment des séparateurs éventuels. Malgré le grand
nombre de séquences connues apprises, le systeme a cependant traité en moyenne 85% des séquences
SMS a l’aide du modele UNK.

Avec une vitesse moyenne de 1836,57 caracteres/sec (écart type de 159,65), le systeme traite un SMS
de 140 caracteres en 76,23 ms (écart type de 22,34 ms). Le systeme semble donc efﬁcace, étant donné le

4Voir : http : //bach . arts . kuleuven . be/pmertens/

R. BEAUFORT, S. ROEKHAUT, L.-A. COUGNON, C. FAIRON

KN(*) Réécritures KN UNK(*) Réécritures UNK Lexemes(**) n-grammes
Total 41281 49152 12 225 69 841 19 801 515128
Rapport 1,19 5,71 26,01

TAB. 1 — Entrées/sorties des modeles. (*) Séquences SMS. (**) Formes normalisées.

1. Notre approche 2. Autres approches
Validation croisée, francais En francais En anglais
Copie Hybride Guimier Kobus 2008 Aw Choudury Cook
0?‘ a 0?‘ a 2007 1 2<*> 2006 2007<**> 2009<**>

Sub. 25,90 1,65 6,69 0,45 1 1,94
Del. 8,24 0,74 1,89 0,31 2,36
Ins. 0,46 0,08 0,72 0,10 2,21

WER 34,59 2,37 9,31 0,78 16,51 10,82 41,00 44,60
SER 85,74 0,87 65,07 1,85 76,05

BLEU 0,47 0,03 0,83 0,01 0,736 0,8 0,81

0T'=m0yenne, a=e’cart type

TAB. 2 — Performances. (*) Kobus 2008-2 correspond a une combinaison du modele ASR de Kobus 2008-1
et d’un modele « orienté traduction » réalisé a partir d’un ensemble de logiciels libres. (**) Scores obtenus
sur des données bruitées uniquement, en dehors du contexte de la phrase.

temps considérable passé dans le modele UNK. Sur ce point, il n’est malheureusement pas possible de
proposer une comparaison avec les autres systemes, qui ne fournissent pas cette information.

Le tableau 2, partie 1, présente les performances de notre approche (Hybride) et les compare a un simple
copier-coller du SMS (Copie). Nous avons évalué le systeme en termes de score BLEU (Papineni et al.,
2001), de taux d’erreur a la phrase (Sentence Error Rate, SER), et de taux d’erreur au mot (Word Error
Rate, WER), le WER se subdivisant lui-méme en substitutions (Sub.), suppressions (Del.) et insertions
(Ins.). Les résultats du copier-coller donnent une idée du bruit réellement présent dans le corpus SMS,
et mettent en évidence le fait que notre systeme a encore des difﬁcultés a réduire le SER, alors que les
résultats en termes de WER et de score BLEU sont plutot encourageants.

Le tableau 2, partie 2, reproduit les résultats des autres approches de la littérature. La plupart des résultats
sont cependant difﬁciles a comparer aux notres, parce qu’ils ont été obtenus soit dans une langue différente
(l’anglais), soit sur un corpus différent : c’est le cas de Kobus et al. (2008), qui d’une part ont combiné
le corpus que nous avons utilisé a un autre corpus SMS, et d’autre part ont réalisé un seul test, basé sur
un corpus d’entrainement plus important (36 704 SMS) pour un corpus de test comparable a l’un de nos
blocs (2 998 SMS). Les seuls résultats véritablement comparables sont ceux de Guimier de Neef & Fessard
(2007), qui ont évalué leur approche sur le méme corpus que nous, mais sans validation croisée, parce que
leur systeme expert ne nécessite pas d’apprentissage. Quoi qu’il en soit, le tableau 2 montre que notre
méthode supporte tres bien la comparaison avec les meilleures méthodes antérieures.

L’ analyse des normalisations produites par notre systeme a Inis en évidence trois caractéristiques impor-
tantes :

1. Les séparateurs manquants (Pensa ms —> Pense £1 mes) ou superﬂus (G t —> J ’e’tais) sont globalement

UNE APPROCHE HYBRIDE POUR LA NORMALISATION DES SMS

bien gérés, ce qui est reﬂété par nos taux de suppression et d’insertion réduits.
2. Le prétraitement est utile, puisque les unités non ambigues ne sont pas modiﬁées.

3. Les erreurs sont souvent contextuelles : elles concernent le genre (quel(le)), le nombre (bis0u( s )), la
personne ([tu t’]inquiéte(s)) ou le temps (arrivé/arriver). Cependant, comme le soulignent Kobus
et al. (2008), la fréquence de ces erreurs n’est pas surprenante en frangais, langue dans laquelle les
modeles n-grammes sont souvent incapables de modéliser cette information, hors de leur portée.

6 Conclusion et perspectives

Dans cet article, nous avons présenté une normalisation SMS basée sur des machines a états ﬁnis et deve-
loppée dans le contexte d’un systeme de synthese de la parole a partir de SMS. Aﬁn d’éviter la modiﬁcation
erronée des unités non ambigues, nous avons congu une méthode hybride, entre correction et traduction.
Notre algorithme de normalisation est original a deux niveaux. Premierement, il repose entierement sur
des modeles appris. Deuxiemement, le modele de réécriture appliqué a un segment d’unité bruitée change
selon que le segment est connu ou non.

Evalué par validation croisée, le systeme semble efﬁcace, et les performances en termes de score BLEU
et de WER sont plutot encourageantes. Cependant, le SER reste trop élevé, ce qui met en évidence le fait
que le systeme a besoin d’étre amélioré.

Avant tout, la normalisation devrait Inieux modéliser les similarités phonétiques, au vu du grand nombre de
jeux phonétiques dans les SMS. Le modele phonétique, par exemple, devrait savoir que 0, au, eau, . . ., aux
se prononcent [o], tandis que é, ais, ait, ..., aient sont souvent prononcés [8]. Cependant, contrairement a
Kobus et al. (2008), nous pensons que ce modele doit éviter l’étape de conversion graphemes—phonemes,
qui empéche aux étapes suivantes d’identiﬁer les graphemes présents dans la séquence initiale. A la place,
nous proposons d’apprendre les similarités phonétiques a partir d’un dictionnaire de mots accompagnés
de leurs transcriptions phonétiques, et de construire des regles graphémes—graphémes. Ces regles pour-
raient ensuite étre pondérées, en apprenant leurs fréquences a partir de nos corpus alignés. Ce modele
devrait également autoriser les variations de timbre, comme [e]—[e], aﬁn d’accepter des similarités entre
graphemes fréquemment confondus en frangais, come at" ([e]) et ais/ait/aiem,‘ ([8]).

I1 serait également intéressant de tester l’impact d’un autre modele de langue lexical, entrainé sur des
phrases non-SMS. En effet, le modele lexical présente un inconvenient majeur dans le contexte de mes-
sages SMS : il doit étre appris sur des formes standard, ce qui, dans le contexte des SMS, implique
la retranscription du corpus, un processus coﬁteux qui réduit le nombre de données d’entrainement du
modele. .. Le corpus qui remplacerait le corpus SMS retranscrit devrait cependant partager deux points
communs avec le langage SMS : il devrait Inimer la syntaxe de l’oral et étre le plus spontané possible. Sur
la base de ces contraintes, notre intention est de récolter des phrases de forums Internet, en sélectionnant
ces forums avec soin, parce que leurs textes partagent un autre point commun avec les SMS : ils sont
bruités. De ce fait, l’idée est de choisir un forum dont la philosophie est explicitement d’éviter l’utilisation
du langage SMS et d’accorder de l’importance a l’orthographe eta la grammaire.

La derniere amélioration que nous proposons ici est plus orientée correction : l’idée est d’autoriser la
correction orthographique £1 l’inte’rieur des modules TAL du systeme. Placées a ce stade du processus,
guidées par l’analyse morphosyntaxique et en combinaison avec elle, des méthodes de correction plus
sophistiquées pourraient ainsi se focaliser sur le probleme non trivial des erreurs contextuelles.

R. BEAUFORT, S. ROEKHAUT, L.-A. COUGNON, C. FAIRON

Remerciements

Cette recherche a été co-ﬁnancée par les projets FIRST Post-Doc « Vocalise » (convention 716619) et
WIST 2 « Expressive » (convention 616422) de la Région wallonne.

Références

AW A., ZHANG M., XIAO J. & SU J. (2006). A phrase-based statistical model for sms text normaliza-
tion. In Proc. COLING/ACL 2006.

BEAUFORT R. (2008). Application des Machines a Etats Finis en Synthese de la Parole. Se’lection
d’unite’s non uniformes et Correction orthographique. PhD thesis, FUNDP, Namur, Belgium. 605 pages.
CHEN S. F. & GOODMAN J. (1998). An Empirical Study of Smoothing Techniques for Language Mode-
ling. Rapport interne 10-98, Computer Science Group, Harvard University.

CHOUDHURY M., SARAF R., JAIN V., MUKHERJEE A., SARKAR1 S. & BASU A. (2007). Investigation
and modeling of the structure of texting language. International Journal on Document Analysis and
Recognition, 10(3), 157-174.

COOK P. & STEVENSON S. (2009). An Unsupervised Model for Text Message Normalization. In Proc.
Workshop on Computational Approaches to Linguistic Creativity, p. 71-78.

COUGNON L.-A. & BEAUFORT R. (2009). SSLD : a French SMS to Standard Language Dictionary.
In S. GRANGER & M. PAQUOT, Eds., Proc. eLexicography in the 21 st century .' New applications, new
challenges (eLEX 2009) : Presses Universitaires de Louvain. To appear.

FAIRON C., KLEIN J. R. & PAUMIER S. (2006). Le langage SMS .' e’tude d’un corpus informatisé a
partir de l’enquéte Faites don de vos SMS a la science. Presses Universitaires de Louvain.

FAIRON C. & PAUMIER S. (2006). A translated corpus of 30,000 French SMS. In Proc. LREC 2006.
GUIMIER DE NEEF E. & FESSARD S. (2007). Evaluation d’un systeme de transcription de SMS. In
Actes de Lexique et Grammaire 2007, p. 217-224.

J. HOPCROFT, R. MOTWANI & J. ULLMAN, Eds. (1979). Introduction to Automata Theory, Languages,
and Computation. Massachusetts : Addison-Wesley.

KOBUS C., YVON F. & DAMNATI G. (2008). Normalizing SMS : are two metaphors better than one ?
In Proc. COLING 2008, p. 441-448, Manchester, UK.

KOHAVI R. (1995). A study of Cross-Validation and Bootstrap for Accuracy Estimation and Model
Selection. In Proc. IJCAI’95, p. 1137-1143.

PAPINENI K., ROUKOS S., WARD T. & ZHU W.-J. (2001). BLEU : a method for automatic evaluation
of machine translation. In Proc. ACL 2001, p. 311-318.

E. ROCHE & Y. SCHABES, Eds. (1997). Finite-State Language Processing. Cambridge : MIT Press.
SHANNON C. E. (1948). A mathematical theory of communication. The Bell System Technical Journal,
27, 379-423.

SPROAT R., BLACK A., CHEN S., KUMAR S., OSTENDORF M. & RICHARDS C. (2001). Normaliza-
tion of non-standard words. Computer Speech & Language, 15(3), 287-333.

THURLOW C. & BROWN A. (2003). Generation txt? The sociolinguistics of young people’s text-
messaging. Discourse Analysis Online, 1(1).

