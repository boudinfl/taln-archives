<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Recueil et analyse d&#8217;un corpus &#233;cologique de corrections orthographiques extrait des r&#233;visions de Wikip&#233;dia</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>Recueil et analyse d&#8217;un corpus &#233;cologique de corrections
orthographiques extrait des r&#233;visions de Wikip&#233;dia
</p>
<p>Guillaume Wisniewski Aur&#233;lien Max Fran&#231;ois Yvon
LIMSI&#8212;CNRS, B.P. 133 91 403 ORSAY CEDEX
</p>
<p>Universit&#233; Paris Sud 11
{guillaume.wisniewski,aurelien.max,francois.yvon}@limsi.fr
</p>
<p>R&#233;sum&#233;. Dans cet article, nous introduisons une m&#233;thode &#224; base de r&#232;gles permettant d&#8217;extraire
automatiquement de l&#8217;historique des &#233;ditions de l&#8217;encyclop&#233;die collaborative Wikip&#233;dia des corrections
orthographiques. Cette m&#233;thode nous a permis de construire un corpus d&#8217;erreurs compos&#233; de 72 483 er-
reurs lexicales (non-word errors) et 74 100 erreurs grammaticales (real-word errors). Il n&#8217;existe pas, &#224;
notre connaissance, de plus gros corpus d&#8217;erreurs &#233;cologiques librement disponible. En outre, les tech-
niques mises en &#339;uvre peuvent &#234;tre facilement transpos&#233;es &#224; de nombreuses autres langues. La collecte
de ce corpus ouvre de nouvelles perspectives pour l&#8217;&#233;tude des erreurs fr&#233;quentes ainsi que l&#8217;apprentissage
et l&#8217;&#233;valuation des correcteurs orthographiques automatiques. Plusieurs exp&#233;riences illustrant son int&#233;r&#234;t
sont propos&#233;es.
</p>
<p>Abstract. This paper describes a French spelling error corpus we built by mining Wikipedia revision
history. This corpus contains 72,493 non-word errors and 74,100 real-word errors. To the best of our
knowledge, this is the first time that such a large corpus of naturally occurring errors is collected and
made publicly available, which opens new possibilities for the evaluation of spell checkers and the study
of error patterns. In the second part of this work, a first study of french spelling error patterns and of the
performance of a spell checker is presented.
</p>
<p>Mots-cl&#233;s : ressources pour le TAL, correction orthographique, Wikip&#233;dia.
</p>
<p>Keywords: resources for NLP, spelling correction, Wikipedia.
</p>
<p>1 Introduction
</p>
<p>Cet article d&#233;crit la cr&#233;ation d&#8217;un corpus d&#8217;erreurs orthographiques &#224; partir des r&#233;visions des pages de
Wikip&#233;dia en fran&#231;ais. Ce corpus contient 72 493 erreurs lexicales (non-word errors) et 74 100 erreurs
grammaticales (real-word errors) &#233;cologiques. C&#8217;est, &#224; notre connaissance, la premi&#232;re fois qu&#8217;un aussi
gros corpus d&#8217;erreurs (et de corrections) est collect&#233; et rendu disponible, ce qui ouvre de nouvelles perspec-
tives pour l&#8217;&#233;tude des erreurs ainsi que pour l&#8217;&#233;valuation et l&#8217;apprentissage de correcteurs automatiques.
</p>
<p>Les corpus jouent un r&#244;le moteur dans le d&#233;veloppement et l&#8217;analyse de syst&#232;mes de traitement des
langues ; il n&#8217;est que plus regrettable que, pour de nombreuses t&#226;ches, de tels corpus ne soient pas publique-
ment disponibles. C&#8217;est en particulier le cas en correction orthographique, la plupart des &#233;valuations, telles
que celle de (Islam &amp; Inkpen, 2009), utilisent des petits corpus artificiels, car les sources de donn&#233;es</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>GUILLAUME WISNIEWSKI, AUR&#201;LIEN MAX ET FRAN&#199;OIS YVON
</p>
<p>usuelles (articles de journaux, rapports, ...) ne comportent que peu de fautes et leur annotation a un cout
&#233;lev&#233;.
</p>
<p>L&#8217;utilisation de corpus artificiels limite toutefois l&#8217;utilisation de m&#233;thodes d&#8217;apprentissage statistique, qui
n&#233;cessitent des corpus repr&#233;sentatifs de la t&#226;che. Il en va de m&#234;me pour leur utilisation pour l&#8217;&#233;valuation :
il n&#8217;y a aucune garantie qu&#8217;un correcteur capable de d&#233;tecter des erreurs introduites artificiellement ne soit
biais&#233; et ne sache reconnaitre que celles-ci. A contrario, les erreurs introduites artificiellement risquent
d&#8217;&#234;tre plus compliqu&#233;es &#224; d&#233;tecter et &#224; corriger que les erreurs r&#233;elles.
</p>
<p>Nous souhaitons montrer, dans cet article, que le d&#233;veloppement des wikis tel Wikip&#233;dia et, plus g&#233;n&#233;rale-
ment, des syst&#232;mes de gestion de r&#233;visions peut aider &#224; la construction de corpus &#171; naturels &#187;. Une des
particularit&#233;s de ces syst&#232;mes est, en effet, de conserver un historique complet de toutes les modifications.
Il est donc possible d&#8217;acc&#233;der aux r&#233;visions successives d&#8217;un document pour en extraire, non seulement
les modifications, ajouts ou suppressions d&#8217;informations, mais &#233;galement toutes les corrections et modifi-
cations de style. La collecte de ce dernier type de modifications permet de constituer ais&#233;ment des corpus
pour plusieurs t&#226;ches de TAL (Nelken &amp; Yamangil, 2008) et notamment pour la correction orthographique.
</p>
<p>Notre contribution est triple. Dans la premi&#232;re section, nous d&#233;crivons la construction d&#8217;un corpus d&#8217;er-
reurs &#233;cologique &#224; partir des r&#233;visions de Wikip&#233;dia. Puis nous pr&#233;sentons les premi&#232;res analyses de ce
corpus qui nous permettent d&#8217;identifier les types d&#8217;erreurs fr&#233;quentes. Finalement, dans la troisi&#232;me sec-
tion, nous conduisons une premi&#232;re &#233;valuation d&#8217;un correcteur libre de l&#8217;&#233;tat de l&#8217;art, Hunspell, et montrons
comment notre corpus d&#8217;erreurs pourrait faciliter la construction d&#8217;un correcteur performant.
</p>
<p>2 Construction du corpus
</p>
<p>Notre corpus est une sous-partie de WICOPACO, un corpus qui regroupe des corrections orthographiques,
des corrections typographiques, ainsi que des reformulations. Nous d&#233;crivons dans cette section la con-
struction de WICOPACO, puis de notre corpus d&#8217;erreurs.
</p>
<p>2.1 Le corpus WICOPACO
</p>
<p>Le corpus WICOPACO (Wikipedia Correction and Paraphrase Corpus) (Max &amp; Wisniewski, 2010) est
un corpus de modifications locales extrait des r&#233;visions des articles de Wikip&#233;dia. Sa construction repose
sur l&#8217;observation que la plupart des r&#233;visions &#171; mineures &#187; d&#8217;un article (celles qui ne portent que sur
quelques mots) sont des corrections d&#8217;erreurs (orthographiques, grammaticales, typographiques, ...) ou des
am&#233;liorations du style. L&#8217;extraction de ces modifications permet de constituer des corpus pour plusieurs
t&#226;ches de traitement automatique des langues (Nelken &amp; Yamangil, 2008). La construction de ce corpus se
compose de deux &#233;tapes. Dans une premi&#232;re &#233;tape, un ensemble de modifications locales est extrait1. Pour
cela, nous calculons l&#8217;ensemble des diff&#233;rences textuelles entre deux versions d&#8217;une m&#234;me page &#224; l&#8217;aide
d&#8217;un algorithme de recherche de plus grandes sous-s&#233;quences communes2. L&#8217;objectif &#233;tant d&#8217;extraire des
modifications locales, seules les modifications portant sur sept mots au plus sont prises en compte.
</p>
<p>1Les modifications effectu&#233;es par les &#171; robots de correction &#187; de Wikip&#233;dia sont ignor&#233;es (voir http://fr.wikipedia.
org/wiki/Wikipedia:Bot).
</p>
<p>2Nous avons utilis&#233; une impl&#233;mentation identique &#224; celle du programme diff standard.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CORPUS DE CORRECTIONS ORTHOGRAPHIQUES
</p>
<p>Cette premi&#232;re &#233;tape permet d&#8217;extraire un tr&#232;s grand nombre de modifications locales. Nous appliquons,
dans une seconde &#233;tape, un ensemble de filtres afin de ne s&#233;lectionner que les plus int&#233;ressantes. En
particulier, les modifications qui ne conservent pas un minimum de mots et qui ne concernent que des
signes de ponctuation ou des changements de casse sont exclues. Le premier filtre permet de rejeter (de
mani&#232;re grossi&#232;re) des corrections &#171; s&#233;mantiques &#187; ne conservant pas le sens ; le second permet de limiter
la taille du corpus.3
</p>
<p>Les modifications extraites sont ensuite normalis&#233;es (notamment en supprimant toutes les informations de
mise en page), segment&#233;es et sauvegard&#233;es dans un format XML. Lors de l&#8217;extraction, les informations
permettant de faire le lien entre la modification et la page Wikip&#233;dia sont conserv&#233;es, et le contexte (le
paragraphe dans lequel la modification est effectu&#233;e) est &#233;galement extrait. La figure 1 pr&#233;sente un exemple
extrait du corpus WICOPACO et illustre les informations disponibles.4
</p>
<p>&lt;modif id=&quot;23&quot; wp_page_id=&quot;7&quot; wp_before_rev_id=&quot;4649540&quot;
wp_after_rev_id=&quot;4671967&quot; wp_user_id=&quot;0&quot;
wp_user_num_modif=&quot;1096911&quot; wp_comment=&quot;D&#233;finition&quot;&gt;
</p>
<p>&lt;before&gt;On nomme &lt;m num_words=&quot;1&quot;&gt;Algebre&lt;/m&gt; lin&#233;aire la branche
des math&#233;matiques qui se penche...&lt;/before&gt;
&lt;after&gt;On nomme &lt;m num_words=&quot;1&quot;&gt;Alg&#232;bre&lt;/m&gt; lin&#233;aire la branche
des math&#233;matiques qui se penche...&lt;/after&gt;
</p>
<p>&lt;/modif&gt;
</p>
<p>FIG. 1 &#8211; Exemple d&#8217;entr&#233;e de WICOPACO. Les attributs commen&#231;ant par wp_ correspondent aux index
de Wikip&#233;dia et permettent de retrouver la r&#233;vision correspondant &#224; la modification ; les segments modifi&#233;s
sont signal&#233;s par la balise m.
</p>
<p>La version actuelle de WICOPACO5 comporte 408 817 modifications. Une analyse des r&#233;visions extraites
permet de distinguer trois grands types de modifications pr&#233;sent&#233;s dans le Tableau 1. Nous exploitons
actuellement ce corpus pour l&#8217;analyse des erreurs orthographiques et l&#8217;&#233;valuation des correcteurs. Ce cor-
pus pr&#233;sente &#233;galement un int&#233;r&#234;t particulier pour l&#8217;&#233;tude des ph&#233;nom&#232;nes de reformulation, et nos travaux
futurs incluent l&#8217;identification automatique de paraphrases &#224; l&#8217;int&#233;rieur du corpus.
</p>
<p>2.2 Constitution d&#8217;un corpus de corrections orthographiques
</p>
<p>Le corpus WICOPACO permet de construire facilement un corpus de corrections orthographiques : comme
le montrent les extraits pr&#233;sent&#233;s Table 1, il suffit pour cela de distinguer, parmi toutes les entr&#233;es du cor-
pus, les corrections des reformulations et du vandalisme. Il est &#233;galement possible d&#8217;extraire la correction
de cette erreur, en faisant une hypoth&#232;se forte : il faut supposer qu&#8217;aucune &#171; petite &#187; modification avec la
</p>
<p>3Une autre version du corpus ne comportant que des corrections typographiques est en cours de r&#233;alisation.
4Pour plus de clart&#233;, le contexte de la modification a &#233;t&#233; r&#233;duit.
5T&#233;l&#233;chargeable &#224; l&#8217;adresse http://wicopaco.limsi.fr. Elle a &#233;t&#233; extraite &#224; partir 85 000 articles de la version
</p>
<p>d&#8217;octobre 2007 de la Wikip&#233;dia francophone. Ce corpus est naturellement appel&#233; &#224; s&#8217;enrichir pour prendre en compte des
versions plus r&#233;centes.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>GUILLAUME WISNIEWSKI, AUR&#201;LIEN MAX ET FRAN&#199;OIS YVON
</p>
<p>Correction
normalisations &#5; [Son 2&#232;me disque&#8594; Son deuxi&#232;me disque]
erreurs lexicales &#5; c&#8217;est-&#224;-dire la [dernri&#232;re&#8594; derni&#232;re] ann&#233;e avant l&#8217;&#232;re chr&#233;tienne
corrections des diacritiques &#5; la jeune Natascha Kampusch,[ag&#233;e&#8594; &#226;g&#233;e] de 18 ans
corrections grammaticales &#5; dans le but de [sensibilis&#233;&#8594; sensibiliser] sur les changements
Reformulation
sans changement de sens &#5; Le tritium [existe dans la nature . Il est produit&#8594; se forme naturellement]
</p>
<p>dans l&#8217; atmosph&#232;re
&#5; &#8220;Gimme Gimme Gimme&#8221; et &#8220;I Have A Dream&#8221; [contribueront au gigan-
tesque succ&#232;s de&#8594; viendront alimenter la gloire d&#8217;] Abba
</p>
<p>avec changement de sens &#5; alors [que l&#8217; ordinateur&#8594; qu&#8217;un processeur de la famille x86] reconna&#238;tra
ce que l&#8217; instruction machine
&#5; [Le principal du coll&#232;ge M. Desdouets&#8594; Un de ses professeurs] dit de lui
&#5; Des op&#233;rations de base sont disponibles dans [tous les &#8594; la plupart des]
jeux d&#8217; instructions
</p>
<p>Vandalisme
vandalisme agrammatical &#5; S&#252;leyman Ier s&#8217; [empare de l&#8217; Arabie et fait entrer dans l&#8217;&#8594; emp kikoo c
</p>
<p>moi ca va loll &#8217;] empire ottoman M&#233;dine et La Mecque
vandalisme subtil &#5; pour promouvoir la justice , la solidarit&#233; et [la paix &#8594; l&#8217;ap&#233;ro] dans le
</p>
<p>monde
</p>
<p>TAB. 1 &#8211; Typologie des modifications pr&#233;sentes dans le corpus WICOPACO
</p>
<p>derni&#232;re version d&#8217;un article (au moment du t&#233;l&#233;chargement) n&#8217;introduit d&#8217;erreur et que le contenu apr&#232;s
la modification peut donc &#234;tre consid&#233;r&#233; comme une &#171; r&#233;f&#233;rence &#187;. Une &#233;tude rapide du corpus montre que
cette hypoth&#232;se est valable dans la grande majorit&#233; des cas.
</p>
<p>Nous souhaitons &#233;galement classer les erreurs selon les deux cat&#233;gories traditionnellement identifi&#233;es (Ku-
kich, 1992) : les erreurs &#171; lexicales &#187; (non-word errors), pour lesquelles le mot mal orthographi&#233; n&#8217;est plus
un mot valide de la langue (p. ex., lorsque &#171; maman &#187; est &#233;crit &#171; maaman &#187;) et les erreurs &#171; grammaticales &#187;
(real-word errors) qui correspondent aux cas o&#249; le mot mal orthographi&#233; reste un mot valide de la langue.
En plus des erreurs grammaticales &#224; proprement parler (p. ex., lorsque &#171; mang&#233;s &#187; est &#233;crit &#171; manger &#187;),
cette derni&#232;re cat&#233;gorie regroupe certaines erreurs lexicales (p. ex., lorsque &#171; pour &#187; est &#233;crit &#171; pur &#187;). Les
erreurs grammaticales ne peuvent &#234;tre d&#233;tect&#233;es qu&#8217;en prenant en compte le contexte dans lequel le mot
apparait.
</p>
<p>Le corpus d&#8217;erreurs est construit en s&#233;lectionnant les modifications ne comportant ni signe de ponctuation,
ni chiffre, ni nombre &#233;crit en toutes lettres (sauf &#171; un &#187; et &#171; une &#187;), ni plus d&#8217;une lettre en majuscule.
Ces crit&#232;res permettent d&#8217;&#233;carter des modifications ne portant pas sur l&#8217;orthographe du mot et notamment
certaines corrections de nature s&#233;mantique (p. ex. lorsque &#171; sept &#187; est corrig&#233; en &#171; six &#187;). Les modifications
portant sur plus d&#8217;un mot sont &#233;galement rejet&#233;es.
</p>
<p>Comme l&#8217;on dispose, pour chaque modification, du mot corrig&#233; (avant et apr&#232;s correction), la distinction
des erreurs peut &#234;tre faite quasi automatiquement en deux &#233;tapes simples. Dans une premi&#232;re &#233;tape, nous
utilisons un correcteur orthographique6 pour identifier si les mots avant et apr&#232;s correction sont des mots
valides. Trois cas de figure peuvent se pr&#233;senter :
</p>
<p>6Dans toutes nos exp&#233;riences, nous utilisons la version 1.2.8 du correcteur libre Hunspell http://hunspell.sf.net
avec la version 3.4.1 du dictionnaire fran&#231;ais &#171; Classique et r&#233;forme 90 &#187;.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CORPUS DE CORRECTIONS ORTHOGRAPHIQUES
</p>
<p>1. le mot avant modification n&#8217;est pas un mot valide, mais le mot apr&#232;s modification l&#8217;est ; ce cas
correspond &#224; la correction d&#8217;une erreur lexicale ;
</p>
<p>2. le mot avant modification et le mot apr&#232;s modification sont des mots valides ; ce cas correspond &#224; la
correction d&#8217;une erreur grammaticale ou &#224; une reformulation ;
</p>
<p>3. le mot apr&#232;s modification n&#8217;est pas un mot valide ; ce cas correspond soit &#224; l&#8217;introduction d&#8217;une
erreur (mauvaise correction ou introduction de vandalisme), &#224; la modification d&#8217;un nom propre,
d&#8217;un mot &#233;tranger ou d&#8217;un mot inconnu.
</p>
<p>Ce premier traitement simple nous permet donc d&#8217;extraire de WICOPACO les modifications qui sont des
corrections d&#8217;erreurs lexicales (cas 1) et de rejeter certaines modifications, dont la validit&#233; est plus difficile
&#224; &#233;tablir, telles les corrections de noms propres et de mots &#233;trangers (cas 3).
</p>
<p>Pour distinguer, dans le cas 2, les reformulations des corrections d&#8217;erreurs, nous utilisons un crit&#232;re fond&#233;
sur la distance d&#8217;&#233;dition.7 En effet, plusieurs travaux ont montr&#233; que les mots mal orthographi&#233;s sont,
en g&#233;n&#233;ral, proches (au sens de la distance d&#8217;&#233;dition) de leur forme correcte (Kukich, 1992). L&#8217;&#233;tude d&#8217;un
&#233;chantillon du corpus corrobore ce r&#233;sultat : nous observons que dans une modification correspondant &#224; au
moins 4 &#233;ditions, le mot est g&#233;n&#233;ralement compl&#232;tement r&#233;&#233;crit et la correction est donc une reformulation.
Il apparait &#233;galement qu&#8217;une modification correspondant &#224; plus que 5 &#233;ditions correspond en g&#233;n&#233;ral &#224;
diverses formes de vandalisme. Le corpus d&#8217;erreurs est donc construit &#224; l&#8217;aide des r&#232;gles suivantes :
&#8211; les erreurs lexicales sont les entr&#233;es correspondant &#224; l&#8217;&#233;dition d&#8217;un mot inconnu en un mot connu, la
</p>
<p>correction donnant lieux &#224; strictement moins que 6 &#233;ditions ;
&#8211; les erreurs grammaticales sont les entr&#233;es dans lesquelles un mot connu est remplac&#233; par un autre mot
</p>
<p>connu suffisamment proche (la distance d&#8217;&#233;dition doit &#234;tre strictement plus petite que 4) ;
&#8211; tous les autres cas sont rejet&#233;s.
L&#8217;application de ces r&#232;gles permet d&#8217;extraire un corpus de 74 100 erreurs grammaticales et 72 493 erreurs
lexicales en contexte. Ce corpus est &#233;galement t&#233;l&#233;chargeable &#224; partir de la page de WICOPACO.
</p>
<p>3 Erreurs fr&#233;quentes en fran&#231;ais
</p>
<p>WICOPACO fournit des informations pr&#233;cieuses sur les distributions de patrons d&#8217;erreurs en fran&#231;ais.
Dans cette section, nous pr&#233;sentons les r&#233;sultats de nos premi&#232;res analyses statistiques de ces patrons.
</p>
<p>La principale analyse que nous avons effectu&#233;e consiste &#224; identifier les corrections (et donc les erreurs) les
plus fr&#233;quentes dans le corpus. &#201;tant donn&#233; le mot initial et le mot corrig&#233;, la correction peut facilement
&#234;tre d&#233;termin&#233;e en calculant la distance d&#8217;&#233;dition entre ces deux mots et la suite d&#8217;op&#233;rations (ou trace
d&#8217;&#233;dition) qui lui est associ&#233;e.
</p>
<p>Il existe de nombreuses mani&#232;res de d&#233;finir la distance d&#8217;&#233;dition et la liste des modifications lui corre-
spondant (Navarro, 1999). Nous avons utilis&#233; l&#8217;algorithme de Ratcliff &amp; Metzener (1988) qui produit des
s&#233;quences d&#8217;&#233;dition plus facilement interpr&#233;tables dans le cadre de la correction orthographique. Notons
que la plupart des corrections fr&#233;quentes ne portant que sur un caract&#232;re, les r&#233;sultats pr&#233;sent&#233;s dans cette
section ne seraient pas fondamentalement modifi&#233;s si l&#8217;on consid&#233;rait un autre algorithme.
</p>
<p>7Nous avons utilis&#233; la distance de Levenshtein (Wagner &amp; Fischer, 1974), avec un cout identique pour les trois op&#233;rations.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>GUILLAUME WISNIEWSKI, AUR&#201;LIEN MAX ET FRAN&#199;OIS YVON
</p>
<p>3.1 &#201;tude des erreurs lexicales
</p>
<p>Les corrections des erreurs lexicales les plus fr&#233;quentes sont pr&#233;sent&#233;es dans la partie gauche de la Table 2.
Les corrections les plus fr&#233;quentes portent sur des accents : au total, 32,4% de ces corrections consistent &#224;
ajouter, supprimer ou modifier un accent. La plupart de ces corrections peuvent difficilement &#234;tre qualifi&#233;es
d&#8217;erreurs : elles sont plus probablement dues &#224; une m&#233;connaissance des r&#232;gles typographiques du fran&#231;ais
(accentuation des majuscules) ou &#224; une mauvaise maitrise des dispositifs de saisie (les caract&#232;res accentu&#233;s
ou encore la ligature &#339;).
</p>
<p>Lorsque l&#8217;on consid&#232;re le &#171; contexte8 &#187; des corrections, on observe qu&#8217;hormis les fautes d&#8217;accents, les
corrections les plus fr&#233;quentes portent sur les doublements de consonnes (ajout d&#8217;un n apr&#232;s ou avant un
autre n, par exemple). Plusieurs travaux ont d&#233;j&#224; signal&#233; la complexit&#233; des r&#232;gles aff&#233;rentes en fran&#231;ais
ainsi que la fr&#233;quence de ce type d&#8217;erreurs.
</p>
<p>Il est finalement int&#233;ressant de noter que, lorsqu&#8217;une correction est fr&#233;quente, sa correction &#171; inverse &#187;
l&#8217;est &#233;galement : par exemple, l&#8217;ajout et la suppression d&#8217;un s sont, toutes deux, des op&#233;rations fr&#233;quentes.
</p>
<p>3.2 &#201;tude des erreurs grammaticales
</p>
<p>La partie droite de la Table 2 pr&#233;sente les corrections les plus fr&#233;quentes pour les erreurs grammaticales.
On peut observer que le corpus est essentiellement constitu&#233; de quelques corrections, tr&#232;s fr&#233;quentes,
alors que de nombreuses corrections n&#8217;apparaissent qu&#8217;une ou deux fois. Il apparait donc que la plupart
des erreurs se r&#233;p&#232;tent, ce qui ouvre la possibilit&#233; de construire des ensembles de confusions regroupant
les mots souvent mal orthographi&#233;s et leur correction (Kukich, 1992). Comme nous le d&#233;taillerons dans la
section 4.1, ces ensembles permettent de faciliter la correction automatique.
</p>
<p>Les corrections les plus fr&#233;quentes sont caus&#233;es par des erreurs d&#8217;accentuation ou par des erreurs dans les
accords des f&#233;minins (ajout/suppression du e final) et des pluriels (ajout/suppression du s final ou de la
terminaison nt). Il est &#233;galement int&#233;ressant de noter que, comme pour les erreurs lexicales quand une
modification est fr&#233;quente, la modification inverse l&#8217;est &#233;galement.
</p>
<p>La Table 3 indique dans quelle partie du mot se situent les erreurs. Cette information se d&#233;duit directement
de la s&#233;quence d&#8217;op&#233;rations permettant de corriger un mot. Les erreurs grammaticales se situent quasiment
toutes dans la deuxi&#232;me moiti&#233; des mots. En fait, une observation plus pr&#233;cise montre que 47% des cor-
rections portent sur la partie finale du mot, ce qui confirme le fait que la plupart des erreurs correspondent
&#224; des confusions entre formes d&#8217;un m&#234;me paradigme (typiquement, des probl&#232;mes d&#8217;accord).
</p>
<p>Comme le sugg&#232;re la Table 2, de nombreuses corrections (au moins 3%) consistent &#224; r&#233;crire un mot,
correctement orthographi&#233; selon la r&#233;forme de l&#8217;orthographe de 1990, selon la norme orthographique qui
s&#8217;imposait ant&#233;rieurement. Par exemple, &#233;v&#232;nement est presque toujours r&#233;crit en &#233;v&#233;nement. De
m&#234;me, de nombreuses corrections r&#233;introduisent un &#238; &#224; la place de i, alors que la r&#233;forme de 1990 fait
pratiquement disparaitre les accents circonflexes sur le i. La fr&#233;quence de ces corrections peut s&#8217;expliquer
soit par la pr&#233;sence de contributeurs &#171; puristes &#187; qui pensent qu&#8217;une encyclop&#233;die doit respecter une
orthographe plus &#171; stricte &#187; que celle de la r&#233;forme de 1990, soit &#224; une ignorance des simplifications
introduites par la derni&#232;re r&#233;forme.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CORPUS DE CORRECTIONS ORTHOGRAPHIQUES
</p>
<p>Erreurs lexicales
e &#8594; &#233; 6,7% -l 1,9%
E &#8594; &#201; 6,7% +i 1,9%
oe &#8594; &#339; 4,6% a &#8594; &#226; 1,8%
+n 4,3% -e 1,7%
+s 2,8% -n 1,7%
+r 2,7% +t 1,6%
&#233; &#8594; &#232; 2,7% +m 1,6%
-s 2,5% e &#8594; &#232; 1,4%
+e 2,2% +l 1,3%
&#233; &#8594; e 2,1% -r 1,3%
</p>
<p>Erreurs grammaticales
+s 16.2% -t 1.5%
+e 9.9% e &#8594; a 1.4%
-s 8.8% &#233; &#8594; er 1.0%
A &#8594; &#192; 5.6% er &#8594; &#233; 0.9%
-e 4.9% u &#8594; &#249; 0.9%
i &#8594; &#238; 2.7% &#224; &#8594; a 0.9%
a &#8594; &#224; 2.2% e &#8594; &#233; 0.8%
+nt 1.9% &#233; &#8594; &#232; 0.7%
+t 1.7% s &#8594; t 0.7%
a &#8594; e 1.5% &#251; &#8594; u 0.7%
</p>
<p>TAB. 2 &#8211; Les vingt corrections les plus fr&#233;quentes. Ces corrections repr&#233;sentent 65,0% des corrections
d&#8217;erreurs grammaticales du corpus et 53,5% des corrections d&#8217;erreurs lexicales
</p>
<p>erreurs lexicales erreurs grammaticales
premi&#232;re moiti&#233; du mot 34,06% 4,08%
seconde moiti&#233; du mot 62,81% 93,26%
</p>
<p>erreurs dans les deux moiti&#233;s 3,13% 2,63%
</p>
<p>TAB. 3 &#8211; Localisation des erreurs &#224; l&#8217;int&#233;rieur d&#8217;un mot
</p>
<p>3.3 Bilan
</p>
<p>Les r&#233;sultats pr&#233;sent&#233;s dans les sections pr&#233;c&#233;dentes illustrent quelques-unes des limites que notre m&#233;thode
de d&#233;tection automatique des erreurs rencontre dans un contexte o&#249; la norme autorise des variations et o&#249;
l&#8217;usage est de plus en plus tol&#233;rant (par l&#8217;exemple sur l&#8217;accentuation des majuscules) : faute d&#8217;utiliser des
ressources lexicales ad&#233;quates pour mieux filtrer les corrections, notre corpus agr&#232;ge un certain nombre
de modifications qui ne sont pas des corrections d&#8217;erreurs. Il est &#233;galement important de noter que les
statistiques pr&#233;sent&#233;es, si elles s&#8217;accordent globalement avec d&#8217;autres observations sur les difficult&#233;s du
fran&#231;ais (Catach, 1980), ne doivent pas &#234;tre prises trop litt&#233;ralement : notre corpus ne permet de mesurer
que les fautes les plus courantes effectu&#233;es au clavier par des scripteurs dont on peut penser qu&#8217;ils sont
globalement plus &#233;duqu&#233;s, plus famili&#233;s des nouvelles technologies, etc. que l&#8217;ensemble des scripteurs
du fran&#231;ais. Par ailleurs, l&#8217;utilisation de nombreux filtres nous a conduit &#224; ignorer dans cette premi&#232;re
version du corpus les modifications de ponctuation, les corrections qui conduisent &#224; fusionner deux mots,
ou au contraire &#224; remplacemer un mot par deux. Il reste ici un gros effort d&#8217;analyse &#224; accomplir pour
mieux caract&#233;riser notre corpus. Nous montrons dans la suite qu&#8217;en d&#233;pit de ces limites, une exploitation
raisonn&#233;e de ce corpus permet d&#8217;aider au d&#233;veloppement d&#8217;outils de correction automatique.
</p>
<p>4 &#201;valuation et apprentissage de correcteurs orthographiques
</p>
<p>Nous proposons, dans cette section, de montrer comment le corpus d&#8217;erreurs que nous avons construit
peut &#234;tre utilis&#233; &#224; la fois pour &#233;valuer les performances d&#8217;un correcteur orthographique automatique et
pour apprendre certains des param&#232;tres de celui-ci. Jusqu&#8217;&#224; pr&#233;sent, l&#8217;&#233;valuation des correcteurs ne s&#8217;est
</p>
<p>8D&#233;fini ici comme la lettre pr&#233;c&#233;dant et la lettre suivant le lieu de la modification</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>GUILLAUME WISNIEWSKI, AUR&#201;LIEN MAX ET FRAN&#199;OIS YVON
</p>
<p>faite que sur des corpus artificiels (Islam &amp; Inkpen, 2009). En utilisant un corpus d&#8217;erreurs &#233;cologiques,
nous esp&#233;rons d&#233;velopper un correcteur mieux adapt&#233; aux erreurs r&#233;elles des utilisateurs.
</p>
<p>Aujourd&#8217;hui, la plupart des correcteurs orthographiques sont des syst&#232;mes d&#8217;&#171; aide &#224; la correction &#187; :
ils sont capables d&#8217;identifier les mots non valides d&#8217;une langue, de sugg&#233;rer un ensemble de corrections
possibles pour un mot donn&#233; (que ce mot ait &#233;t&#233; identifi&#233; comme une erreur ou non), mais ils laissent le
choix de la bonne correction &#224; l&#8217;utilisateur. Dans ce travail, nous nous concentrons sur l&#8217;&#233;valuation de la
qualit&#233; des corrections sugg&#233;r&#233;es, puis introduisons, dans la deuxi&#232;me partie de cette section, une premi&#232;re
exp&#233;rience portant sur la possibilit&#233; d&#8217;automatiser la correction.
</p>
<p>4.1 Qualit&#233; de l&#8217;ensemble des suggestions
</p>
<p>Deux crit&#232;res doivent &#234;tre pris en compte dans l&#8217;&#233;valuation de l&#8217;ensemble des suggestions : le nombre de
fois o&#249; la correction d&#8217;une faute est sugg&#233;r&#233;e et le nombre de suggestions du syst&#232;me. Nous proposons
donc d&#8217;utiliser la mesure suivante :
</p>
<p>qualit&#233; =
1
</p>
<p>N
</p>
<p>&#8721;
i
</p>
<p>&#948;i
#si
</p>
<p>La somme se fait sur les N exemples de l&#8217;ensemble d&#8217;&#233;valuation, &#948;i vaut 1 si la ie correction est dans
l&#8217;ensemble des suggestions, 0 sinon et #si est la taille de l&#8217;ensemble de suggestions correspondant.
</p>
<p>Dans ce travail pr&#233;liminaire, nous consid&#233;rons trois moyens de construire l&#8217;ensemble des suggestions :
1. en consid&#233;rant l&#8217;ensemble des suggestions propos&#233; par Hunspell (m&#233;thode hunspell). Ces sugges-
</p>
<p>tions sont engendr&#233;es par une liste de r&#232;gles qui d&#233;crivent des corrections possibles du lemme et des
variantes morphologiques des formes corrig&#233;es9. Toutes ces r&#232;gles sont &#233;crites &#224; la main.
</p>
<p>2. en appliquant un ensemble de patrons des corrections au mot &#224; corriger et en ne conservant que les
applications g&#233;n&#233;rant un mot valide selon Hunspell (m&#233;thode motif ). Nous utilisons les 20 patrons
les plus fr&#233;quents du corpus, qui sont d&#233;crits dans la Table 2. Ces patrons (i &#8594; &#238; par exemple)
sont appliqu&#233;s ind&#233;pendamment les uns des autres et sans tenir compte du contexte.
</p>
<p>3. en consid&#233;rant la liste des corrections apparaissant dans le corpus (m&#233;thode liste). Cette liste est
construite simplement en associant, pour chaque exemple du corpus, le mot mal orthographi&#233; &#224;
l&#8217;ensemble de ses corrections. Cette liste est semblable aux ensembles de confusions utilis&#233;s dans
plusieurs correcteurs orthographiques (Islam &amp; Inkpen, 2009; Carlson &amp; Fette, 2007). Mais, comme
nous disposons d&#8217;un corpus d&#8217;erreurs, la construction de cette liste est triviale et rapide, alors que
dans la plupart des travaux, les ensembles de confusions sont construits manuellement.
</p>
<p>La premi&#232;re approche permet d&#8217;&#233;valuer un correcteur libre de l&#8217;&#233;tat de l&#8217;art utilis&#233; dans de nombreux
produits &#171; grand public &#187; tels que le navigateur Firefox ou la suite bureautique OpenOffice. Les deux
autres approches ont pour objectif de montrer l&#8217;impact que peut avoir l&#8217;utilisation d&#8217;un corpus d&#8217;erreurs
avec les caract&#233;ristiques de celui que nous avons construit sur le d&#233;veloppement de correcteurs.
</p>
<p>Pour &#233;valuer ces trois approches, nous s&#233;parons al&#233;atoirement le corpus en un ensemble d&#8217;apprentissage
contenant 80% des exemples et un ensemble de test contenant les 20% restants. L&#8217;ensemble de test sert &#224;
mesurer la qualit&#233; des suggestions ; l&#8217;ensemble d&#8217;apprentissage &#224; construire la liste des corrections.
</p>
<p>Les r&#233;sultats de cette exp&#233;rience sont pr&#233;sent&#233;s Table 4. Ils montrent clairement qu&#8217;il est possible, en
combinant ces trois approches, d&#8217;assurer que l&#8217;orthographe correcte d&#8217;un mot est toujours pr&#233;sente dans
</p>
<p>9Ces r&#232;gles sont &#233;crites par des volontaires, en suivant un mode de d&#233;veloppement similaire &#224; celui des logiciels libres.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CORPUS DE CORRECTIONS ORTHOGRAPHIQUES
</p>
<p>l&#8217;ensemble des suggestions. Notons &#233;galement qu&#8217;Hunspell obtient de tr&#232;s bonnes performances pour la
correction des erreurs lexicales, mais est moins utile pour la correction des erreurs grammaticales. Les
deux types d&#8217;erreurs partagent pourtant plusieurs caract&#233;ristiques (notamment leur distance d&#8217;&#233;dition) et
l&#8217;on aurait pu esp&#233;rer que les r&#232;gles de corrections d&#8217;Hunspell seraient suffisamment g&#233;n&#233;rales pour traiter
certaines des erreurs grammaticales. Il est, par exemple, surprenant qu&#8217;Hunspell ne propose quasiment
aucune variation morphologique des mots corrig&#233;s.
</p>
<p>Erreurs lexicales Erreurs grammaticales
m&#233;thode qualit&#233; moyenne max. corr. qualit&#233; moyenne max. corr.
hunspell 40,0% 4,5 15 95,0% 13,0% 8,6 15 65,1%
</p>
<p>liste 51,1% 1,3 7 58,7% 32,1% 8,3 41 75,7%
motif 35,5% 1,7 11 48,7% 31,3% 2,3 7 53,2%
</p>
<p>combi. 38,9% 4,7 22 96,8% 13,7% 14,9 47 92,6%
</p>
<p>TAB. 4 &#8211; Qualit&#233; des ensembles de suggestions &#233;valu&#233;e par la mesure introduite (qualit&#233;), la taille de
l&#8217;ensemble de suggestion (moyenne et max), et le pourcentage d&#8217;erreurs dont la correction est sugg&#233;r&#233;e
(corr.)
</p>
<p>4.2 Correction automatique des erreurs orthographiques
</p>
<p>Nous pr&#233;sentons, Table 5, nos premiers r&#233;sultats sur la correction automatique des erreurs orthographiques10.
Ces r&#233;sultats sont obtenus en ordonnant par un mod&#232;le de langage statistique de type n-gram, estim&#233; sur le
corpus d&#8217;apprentissage, les suggestions propos&#233;es par la combinaison des trois m&#233;thodes introduites dans
la section pr&#233;c&#233;dente.
</p>
<p>Malgr&#233; la simplicit&#233; du mod&#232;le (il n&#8217;y a aucune mod&#233;lisation des erreurs et seul le contexte est utilis&#233; pour
classer les suggestions), les r&#233;sultats sont plut&#244;t encourageants : dans la majorit&#233; des cas, notre correcteur
est capable de trouver automatiquement la bonne correction.
</p>
<p>erreurs lexicales erreur grammaticales
corpus corrections possibles corpus corrections possibles
</p>
<p>mod&#232;le 3-gram 58,9% 60,8% 46,7% 51,9%
mod&#232;le 5-gram 75,2% 77,7% 66,9% 71,3%
</p>
<p>TAB. 5 &#8211; Pourcentage de mots correctement corrig&#233;s sur tout le corpus de test et lorsque l&#8217;on ne consid&#232;re
que les mots dont la correction est possible
</p>
<p>5 Conclusion
</p>
<p>Nous avons pr&#233;sent&#233; et analys&#233; un nouveau corpus d&#8217;erreurs d&#8217;orthographe &#233;cologique, qui ouvre de nou-
velles possibilit&#233;s pour une &#233;tude in vivo de l&#8217;orthographe du fran&#231;ais tel qu&#8217;il s&#8217;&#233;crit &#233;lectroniquement,
</p>
<p>10Par manque de place ni ces r&#233;sultats ni notre m&#233;thode ne sont d&#233;taill&#233;s.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>GUILLAUME WISNIEWSKI, AUR&#201;LIEN MAX ET FRAN&#199;OIS YVON
</p>
<p>ainsi que pour l&#8217;&#233;valuation et l&#8217;apprentissage de dispositifs de correction automatis&#233;e. Un des int&#233;r&#234;ts de
ce corpus pour la correction orthographique est qu&#8217;il permet de d&#233;velopper des syst&#232;mes de correction
plus adaptatifs, c&#8217;est-&#224;-dire s&#8217;appuyant sur l&#8217;usage r&#233;el du fran&#231;ais dans diverses situations de communi-
cation plut&#244;t que sur une norme d&#233;finie de mani&#232;re abstraite et rigide. La m&#233;thodologie utilis&#233;e pour le
construire est g&#233;n&#233;rique et ne requiert que la disponibilit&#233; de r&#233;visions successives d&#8217;un document : elle
pourrait facilement &#234;tre utilis&#233;e, par exemple, pour acqu&#233;rir des corpus permettant d&#8217;adapter un correcteur
aux erreurs typiques d&#8217;un scripteur &#224; partir des r&#233;visions effectu&#233;es.
</p>
<p>Des exp&#233;riences pr&#233;liminaires illustrant l&#8217;utilisation de ce corpus dans un contexte de correction automa-
tique ont &#233;t&#233; pr&#233;sent&#233;es. WICOPACO peut &#234;tre &#233;galement utilis&#233; dans de nombreuses autres t&#226;ches de TAL
et nous sommes actuellement en train de l&#8217;exploiter pour l&#8217;&#233;tude des reformulations et l&#8217;identification des
paraphrases, pour l&#8217;apprentissage et l&#8217;&#233;valuation d&#8217;un syst&#232;me de correction automatique complet ainsi
que pour le d&#233;veloppement de syst&#232;me de normalisation de documents pour la traduction automatique.
</p>
<p>Remerciements
</p>
<p>Ce travail a &#233;t&#233; partiellement financ&#233; dans le cadre d&#8217;une Action Incitative du LIMSI et du projet TRACE
(ANR CONTINT 2009). Les auteurs remercient Julien Boulet et Martine Hurault-Plantet pour leur aide.
</p>
<p>R&#233;f&#233;rences
</p>
<p>CARLSON A. &amp; FETTE I. (2007). Memory-based context-sensitive spelling correction at web scale. In
ICMLA &#8217;07, p. 166&#8211;171, Washington, DC, USA : IEEE Computer Society.
</p>
<p>CATACH N. (1980). L&#8217;orthographe francaise : traite theorique et pratique avec des travaux d&#8217;application
et leurs corriges (avec la collaboration de Claude Gruaz et Daniel Duprez). Nathan, Paris.
</p>
<p>ISLAM A. &amp; INKPEN D. (2009). Real-word spelling correction using Google Web 1T 3-grams. In
Proceedings of EMNLP&#8217;09, p. 1241&#8211;1249, Singapore.
</p>
<p>KUKICH K. (1992). Techniques for automatically correcting words in text. ACM Comput. Surv., 24(4),
377&#8211;439.
</p>
<p>MAX A. &amp; WISNIEWSKI G. (2010). Mining naturally-occurring corrections and paraphrases from
wikipedia&#8217;s revision history. In LREC&#8217;10, Valletta, Malta.
</p>
<p>NAVARRO G. (1999). A guided tour to approximate string matching. ACM Computing Surveys, 33, 2001.
NELKEN R. &amp; YAMANGIL E. (2008). Mining wikipedia&#8217;s article revision history for training computa-
tional linguistics algorithms. In AAAI Workshop on Wikipedia and Artificial Intelligence.
</p>
<p>RATCLIFF J. W. &amp; METZENER D. E. (1988). Pattern matching : The gestalt approach. Dr. Dobb&#8217;s
Journal.
</p>
<p>WAGNER R. A. &amp; FISCHER M. J. (1974). The string-to-string correction problem. Journal of the ACM
(JACM), 21(1), 168&#8211;173.</p>

</div></div>
</body></html>