TALN 2010, Montreal, 19-23 juillet 2010

Recueil et analyse d’un corpus écologique de corrections
orthographiques extrait des révisions de Wikipédia

Guillaume Wisniewski Aurelien Max Francois Yvon
LIMSI—CNRS, B.P. 133 91403 ORSAY CEDEX
Université Paris Sud 11
{guillaume.wisniewski,aurelien.max,francois.yvon} @limsi.fr

Resume. Dans cet article, nous introduisons une methode a base de regles permettant d’extraire
automatiquement de l’historique des editions de l’encyclopedie collaborative Wikipedia des corrections
orthographiques. Cette methode nous a permis de construire un corpus d’erreurs compose de 72 483 er-
reurs lexicales (non-word errors) et 74100 erreurs grammaticales (real-word errors). Il n’existe pas, a
notre connaissance, de plus gros corpus d’erreurs ecologiques librement disponible. En outre, les tech-
niques Inises en oeuvre peuvent étre facilement transposees a de nombreuses autres langues. La collecte
de ce corpus ouvre de nouvelles perspectives pour l’etude des erreurs frequentes ainsi que l’apprentissage
et l’evaluation des correcteurs orthographiques automatiques. Plusieurs experiences illustrant son interet
sont proposees.

Abstract. This paper describes a French spelling error corpus we built by mining Wikipedia revision
history. This corpus contains 72,493 non-word errors and 74,100 real-word errors. To the best of our
knowledge, this is the ﬁrst time that such a large corpus of naturally occurring errors is collected and
made publicly available, which opens new possibilities for the evaluation of spell checkers and the study
of error patterns. In the second part of this work, a ﬁrst study of french spelling error patterns and of the
performance of a spell checker is presented.

M0tS-CléS I ressources pour le TAL, correction orthographique, Wikipedia.

Keywords: resources for NLP, spelling correction, Wikipedia.

1 Introduction

Cet article decrit la creation d’un corpus d’erreurs orthographiques a partir des revisions des pages de
Wikipedia en frangais. Ce corpus contient 72 493 erreurs lexicales (non-word errors) et 74100 erreurs
grammaticales (real-word errors) ecologiques. C’est, a notre connaissance, la premiere fois qu’un aussi
gros corpus d’erreurs (et de corrections) est collecte et rendu disponible, ce qui ouvre de nouvelles perspec-
tives pour l’etude des erreurs ainsi que pour l’evaluation et l’apprentissage de correcteurs automatiques.

Les corpus jouent un role moteur dans le developpement et l’analyse de systemes de traitement des
langues ; il n’est que plus regrettable que, pour de nombreuses taches, de tels corpus ne soient pas publique-
ment disponibles. C’est en particulier le cas en correction orthographique, la plupart des evaluations, telles
que celle de (Islam & Inkpen, 2009), utilisent des petits corpus artiﬁciels, car les sources de donnees

GUILLAUME WISNIEWSKI, AURELIEN MAX ET FRANCOIS YVoN

usuelles (articles de joumaux, rapports, ...) ne comportent que peu de fautes et leur annotation a un cout
élevé.

L’utilisation de corpus artiﬁciels liIr1ite toutefois l’utilisation de méthodes d’apprentissage statistique, qui
nécessitent des corpus représentatifs de la tache. Il en Va de meme pour leur utilisation pour l’évaluation :
il n’y a aucune garantie qu’un correcteur capable de détecter des erreurs introduites artiﬁciellement ne soit
biaisé et ne sache reconnaitre que celles-ci. A contrario, les erreurs introduites artiﬁciellement risquent
d’étre plus compliquées a détecter eta corriger que les erreurs réelles.

Nous souhaitons montrer, dans cet article, que le développement des wikis tel Wikipédia et, plus générale-
ment, des systemes de gestion de révisions peut aider a la construction de corpus « naturels ». Une des
particularités de ces systemes est, en effet, de conserver un historique complet de toutes les modiﬁcations.
Il est donc possible d’accéder aux révisions successives d’un document pour en extraire, non seulement
les modiﬁcations, ajouts ou suppressions d’informations, mais également toutes les corrections et modiﬁ-
cations de style. La collecte de ce dernier type de modiﬁcations permet de constituer aisément des corpus
pour plusieurs taches de TAL (Nelken & Yamangil, 2008) et notamment pour la correction orthographique.

Notre contribution est triple. Dans la premiere section, nous décrivons la construction d’un corpus d’er-
reurs écologique a partir des révisions de Wikipédia. Puis nous présentons les premieres analyses de ce
corpus qui nous permettent d’identiﬁer les types d’erreurs fréquentes. Finalement, dans la troisieme sec-
tion, nous conduisons une premiere évaluation d’un correcteur libre de l’état de l’art, Hunspell, et montrons
comment notre corpus d’erreurs pourrait faciliter la construction d’un correcteur performant.

2 Construction du corpus

Notre corpus est une sous-partie de WICOPACO, un corpus qui regroupe des corrections orthographiques,
des corrections typographiques, ainsi que des reformulations. Nous décrivons dans cette section la con-
struction de WICOPACO, puis de notre corpus d’erreurs.

2.1 Le corpus WICOPACO

Le corpus WICOPACO (Wikipedia Correction and Paraphrase Corpus) (Max & Wisniewski, 2010) est
un corpus de modiﬁcations locales extrait des révisions des articles de Wikipédia. Sa construction repose
sur l’observation que la plupart des révisions « mineures » d’un article (celles qui ne portent que sur
quelques mots) sont des corrections d’erreurs (orthographiques, grammaticales, typographiques, ...) ou des
améliorations du style. L’ extraction de ces modiﬁcations permet de constituer des corpus pour plusieurs
taches de traitement automatique des langues (Nelken & Yamangil, 2008). La construction de ce corpus se
compose de deux étapes. Dans une premiere étape, un ensemble de modiﬁcations locales est extraitl. Pour
cela, nous calculons l’ensemble des differences textuelles entre deux versions d’une méme page a l’aide
d’un algorithme de recherche de plus grandes sous-séquences communesz. L’objectif étant d’extraire des
modiﬁcations locales, seules les modiﬁcations portant sur sept mots au plus sont prises en compte.

1Les modiﬁcations effectuées par les << robots de correction » de Wikipédia sont ignorées (Voir http : / / f r . wikipedi a .
org/wiki /Wikipedia : Bot).
2Nous avons utilisé une implementation identique a celle du programme di f f standard.

CORPUS DE CORRECTIONS ORTHOGRAPHIQUES

Cette premiere étape permet d’extraire un tres grand nombre de modiﬁcations locales. Nous appliquons,
dans une seconde étape, un ensemble de ﬁltres aﬁn de ne sélectionner que les plus intéressantes. En
particulier, les modiﬁcations qui ne conservent pas un minimum de mots et qui ne concement que des
signes de ponctuation ou des changements de casse sont exclues. Le premier ﬁltre permet de rejeter (de
maniere grossiere) des corrections « sémantiques » ne conservant pas le sens; le second permet de limiter
la taille du corpus.3

Les modiﬁcations extraites sont ensuite normalisées (notamment en supprimant toutes les informations de
Inise en page), segmentées et sauvegardées dans un format XML. Lors de l’extraction, les informations
permettant de faire le lien entre la modiﬁcation et la page Wikipédia sont conservées, et le contexte (le
paragraphe dans lequel la modiﬁcation est effectuée) est également extrait. La ﬁgure 1 présente un exemple
extrait du corpus WICOPACO et illustre les informations disponibles.4

<modif id="23" wp_page_id="7" wp_before_rev_id="4649540"
wp_after_rev_id="467l967" wp_user_id="O"
wp_user_num_modif="lO96911" wp_comment="Définition">
<before>On nomme <m num_words="1">Algebre</m> linéaire la branche
des mathématiques qui se penche...</before>
<after>On nomme <m num_words="1">Algébre</m> linéaire la branche
des mathématiques qui se penche...</after>
</modif>

FIG. 1 — Exemple d’entrée de WICOPACO. Les attributs commencant par wp_ correspondent aux index
de Wikipédia et permettent de retrouver la révision correspondant a la modiﬁcation ; les segments modiﬁés
sont signalés par la balise In.

La version actuelle de WICOPAC05 comporte 408 817 modiﬁcations. Une analyse des révisions extraites
permet de distinguer trois grands types de modiﬁcations présentés dans le Tableau 1. Nous exploitons
actuellement ce corpus pour l’analyse des erreurs orthographiques et l’évaluation des correcteurs. Ce cor-
pus présente également un intérét particulier pour l’étude des phénomenes de reformulation, et nos travaux
futurs incluent l’identiﬁcation automatique de paraphrases a l’intérieur du corpus.

2.2 Constitution d’un corpus de corrections orthographiques

Le corpus WICOPACO permet de construire facilement un corpus de corrections orthographiques : comme
le montrent les extraits présentés Table 1, il sufﬁt pour cela de distinguer, parmi toutes les entrées du cor-
pus, les corrections des reformulations et du vandalisme. Il est également possible d’extraire la correction
de cette erreur, en faisant une hypothese forte : il faut supposer qu’aucune « petite » modiﬁcation avec la

3Une autre Version du corpus ne comportant que des corrections typographiques est en cours de realisation.

4Pour plus de clarté, le contexte de la modiﬁcation a été réduit.

5Téléchargeable a l’adresse http : / /wicopaco . limsi . fr. Elle a été extraite a partir 85 000 articles de la Version
d’octobre 2007 de la Wikipédia francophone. Ce corpus est naturellement appelé a s’enrichir pour prendre en compte des
Versions plus récentes.

GUILLAUME WISNIEWSKI, AURELIEN MAX ET FRANCOIS YVoN

TAB. 1 — Typologie des modiﬁcations présentes dans le corpus WICOPACO

derniere version d’un article (au moment du téléchargement) n’introduit d’erreur et que le contenu apres
la modiﬁcation peut donc étre considéré comme une « référence ». Une étude rapide du corpus montre que
cette hypothese est valable dans la grande majorité des cas.

Nous souhaitons également classer les erreurs selon les deux catégories traditionnellement identiﬁées (Ku-
kich, 1992) : les erreurs « lexicales » (non-word errors), pour lesquelles le mot mal orthographié n’est plus
un mot valide de la langue (p. ex., lorsque « maman » est écrit « maaInan ») et les erreurs « grammaticales »
(real-word errors) qui correspondent aux cas ou le mot mal orthographié reste un mot valide de la langue.
En plus des erreurs grammaticales a proprement parler (p. ex., lorsque « mangés » est écrit « manger »),
cette derniere catégorie regroupe certaines erreurs lexicales (p. ex., lorsque « pour » est écrit « pur »). Les
erreurs grammaticales ne peuvent étre détectées qu’en prenant en compte le contexte dans lequel le mot
apparait.

Le corpus d’erreurs est construit en sélectionnant les modiﬁcations ne comportant ni signe de ponctuation,
ni chiffre, ni nombre écrit en toutes lettres (sauf « un » et « une »), ni plus d’une lettre en majuscule.
Ces criteres permettent d’écarter des modiﬁcations ne portant pas sur l’orthographe du mot et notamment
certaines corrections de nature sémantique (p. ex. lorsque « sept » est corrigé en « six »). Les modiﬁcations
portant sur plus d’un mot sont également rejetées.

Comme l’on dispose, pour chaque modiﬁcation, du mot corrigé (avant et apres correction), la distinction
des erreurs peut étre faite quasi automatiquement en deux étapes simples. Dans une premiere étape, nous
utilisons un correcteur orthographique6 pour identiﬁer si les mots avant et apres correction sont des mots
valides. Trois cas de ﬁgure peuvent se présenter :

5Dans toutes nos experiences, nous utilisons la Version 1.2.8 du correcteur libre Hunspell http : / /hunspell . sf . net
avec la Version 3.4.1 du dictionnaire frangais << Classique et réforme 90 ».

Correction
normalisations <> [Son Zéme disque —> Son deuxiéme disque]
erreurs lexicales <> c ’est-a-dire la [dernriére —> derniére] année avant l ’ére chrétienne
corrections des diacritiques <> la jeune Natascha Kampusch,[age’e —> dgée] de 18 ans
corrections grammaticales <> dans le but de [sensibilisé —> sensibiliser] sur les changements
Reformulation
sans changement de sens <> Le tritium [existe dans la nature . Il est produit —> seforme naturellement]
dans l ’ atmosphere
<> “Gimme Gimme Gimme” et “I Have A Dream” [contribueront au gigan-
tesque succés de —> viendront alimenter la gloire d ’ ] Abba
avec changement de sens <> alors [que l’ ordinateur —> qu’un processeur de la famille x86] reconnaitra
ce que l ’ instruction machine
<> [Le principal du collége M. Desdouets —> Un de ses professeurs] dit de lui
<> Des opérations de base sont disponibles dans [tous les —> la plupart des]
jeux d ’ instructions
Vandalisme
Vandalisme agrammatical <> Siileyman Ier s’ [empare de l’ Arabie etfait entrer dans l’ —> emp kikoo c
moi ca va loll ’] empire ottoman Médine et La Mecque
Vandalisme subtil <> pour promouvoir la justice , la solidarite’ et [la paix —> l’ape’ro] dans le
monde

CORPUS DE CORRECTIONS ORTHOGRAPHIQUES

1. le mot avant modiﬁcation n’est pas un mot valide, mais le mot apres modiﬁcation l’est; ce cas
correspond a la correction d’une erreur lexicale ;

2. le mot avant modiﬁcation et le mot apres modiﬁcation sont des mots valides ; ce cas correspond a la
correction d’une erreur grammaticale ou a une reformulation ;

3. le mot apres modiﬁcation n’est pas un mot valide; ce cas correspond soit a l’introduction d’une
erreur (mauvaise correction ou introduction de vandalisme), a la modiﬁcation d’un nom propre,
d’un mot étranger ou d’un mot inconnu.

Ce premier traitement simple nous permet donc d’extraire de WICOPACO les modiﬁcations qui sont des
corrections d’erreurs lexicales (cas 1) et de rejeter certaines modiﬁcations, dont la validité est plus difﬁcile
a établir, telles les corrections de noms propres et de mots étrangers (cas 3).

Pour distinguer, dans le cas 2, les reformulations des corrections d’erreurs, nous utilisons un critere fondé
sur la distance d’édition.7 En effet, plusieurs travaux ont montré que les mots mal orthographiés sont,
en général, proches (au sens de la distance d’édition) de leur forme correcte (Kukich, 1992). L’ étude d’un
échantillon du corpus corrobore ce résultat : nous observons que dans une modiﬁcation correspondant a au
moins 4 éditions, le mot est généralement completement réécrit et la correction est donc une reformulation.
I1 apparait également qu’une modiﬁcation correspondant a plus que 5 éditions correspond en general a
diverses formes de vandalisme. Le corpus d’erreurs est donc construit a l’aide des regles suivantes :

— les erreurs lexicales sont les entrées correspondant a l’édition d’un mot inconnu en un mot connu, la

correction donnant lieux a strictement moins que 6 éditions;
— les erreurs grammaticales sont les entrées dans lesquelles un mot connu est remplacé par un autre mot
connu sufﬁsamment proche (la distance d’édition doit étre strictement plus petite que 4) ;

— tous les autres cas sont rejetés.

L’ application de ces regles permet d’extraire un corpus de 74 100 erreurs grammaticales et 72 493 erreurs
lexicales en contexte. Ce corpus est également téléchargeable a partir de la page de WICOPACO.

3 Erreurs fréquentes en frangais

WICOPACO fournit des informations précieuses sur les distributions de patrons d’erreurs en francais.
Dans cette section, nous présentons les résultats de nos premieres analyses statistiques de ces patrons.

La principale analyse que nous avons effectuée consiste a identiﬁer les corrections (et donc les erreurs) les
plus fréquentes dans le corpus. I-/3tant donné le mot initial et le mot corrigé, la correction peut facilement
étre déterminée en calculant la distance d’édition entre ces deux mots et la suite d’opérations (ou trace
d ’e’diti0n) qui lui est associée.

I1 existe de nombreuses manieres de déﬁnir la distance d’édition et la liste des modiﬁcations lui corre-
spondant (Navarro, 1999). Nous avons utilisé l’algorithme de Ratcliff & Metzener (1988) qui produit des
séquences d’édition plus facilement interprétables dans le cadre de la correction orthographique. Notons
que la plupart des corrections fréquentes ne portant que sur un caractere, les résultats présentés dans cette
section ne seraient pas fondamentalement modiﬁés si l’on considérait un autre algorithme.

7Nous avons utilisé la distance de Levenshtein (Wagner & Fischer, 1974), avec un cout identique pour les trois opérations.

GUILLAUME WISNIEWSKI, AURELIEN MAX ET FRANCOIS YvoN

3.1 Etude des erreurs lexicales

Les corrections des erreurs lexicales les plus fréquentes sont présentées dans la partie gauche de la Table 2.
Les corrections les plus fréquentes portent sur des accents : au total, 32,4% de ces corrections consistent a
aj outer, supprimer ou modiﬁer un accent. La plupart de ces corrections peuvent difﬁcilement étre qualiﬁées
d’erreurs : elles sont plus probablement dues a une méconnaissance des regles typographiques du francais
(accentuation des majuscules) ou a une mauvaise maitrise des dispositifs de saisie (les caracteres accentués
ou encore la ligature oe).

Lorsque l’on considere le « contextes » des corrections, on observe qu’hormis les fautes d’accents, les
corrections les plus fréquentes portent sur les doublements de consonnes (ajout d’un n apres ou avant un
autre 11, par exemple). Plusieurs travaux ont déja signalé la complexité des regles afférentes en francais
ainsi que la fréquence de ce type d’erreurs.

Il est ﬁnalement intéressant de noter que, lorsqu’une correction est fréquente, sa correction « inverse »
l’est également : par exemple, l’ajout et la suppression d’un s sont, toutes deux, des opérations fréquentes.

3.2 Etude des erreurs grammaticales

La partie droite de la Table 2 présente les corrections les plus fréquentes pour les erreurs grammaticales.
On peut observer que le corpus est essentiellement constitué de quelques corrections, tres fréquentes,
alors que de nombreuses corrections n’apparaissent qu’une ou deux fois. I1 apparait donc que la plupart
des erreurs se répetent, ce qui ouvre la possibilité de construire des ensembles de confusions regroupant
les mots souvent mal orthographiés et leur correction (Kukich, 1992). Come nous le détaillerons dans la
section 4.1, ces ensembles permettent de faciliter la correction automatique.

Les corrections les plus fréquentes sont causées par des erreurs d’accentuation ou par des erreurs dans les
accords des féminins (ajout/suppression du e ﬁnal) et des pluriels (ajout/suppression du s ﬁnal ou de la
terminaison nt). 11 est également intéressant de noter que, comme pour les erreurs lexicales quand une
modiﬁcation est fréquente, la modiﬁcation inverse l’est également.

La Table 3 indique dans quelle partie du mot se situent les erreurs. Cette information se déduit directement
de la séquence d’opérations permettant de corriger un mot. Les erreurs grammaticales se situent quasiment
toutes dans la deuxieme moitié des mots. En fait, une observation plus précise montre que 47% des cor-
rections portent sur la partie ﬁnale du mot, ce qui conﬁrme le fait que la plupart des erreurs correspondent
a des confusions entre formes d’un méme paradigme (typiquement, des problemes d’accord).

Comme le suggere la Table 2, de nombreuses corrections (au moins 3%) consistent a récrire un mot,
correctement orthographié selon la réforme de l’orthographe de 1990, selon la norme orthographique qui
s’imposait antérieurement. Par exemple, événement est presque toujours récrit en événement. De
méme, de nombreuses corrections réintroduisent un 31 a la place de i, alors que la réforme de 1990 fait
pratiquement disparaitre les accents circonﬂexes sur le i. La fréquence de ces corrections peut s’expliquer
soit par la présence de contributeurs « puristes » qui pensent qu’une encyclopédie doit respecter une
orthographe plus « stricte » que celle de la réforme de 1990, soit a une ignorance des simpliﬁcations
introduites par la derniere réforme.

CORPUS DE CORRECTIONS ORTHOGRAPHIQUES

Erreurs lexicales Erreurs grammaticales
e —> é 6,7% —l 1,9% +s 16.2% —t 1.5%
E —> E 6,7% +i 1,9% +e 9.9% e —> a 1.4%
0e —> 08 4,6% a —> F31 1,8% —s 8.8% é —> er 1.0%
H1 4,3% -e 1,7% A —> A 5.6% er —> é 0.9%
+S 2,8% ‘I1 1,7% —e 4.9% u —> £1 0.9%
+1: 2,7% +t 1,6% i —> i 2.7% a —> a 0.9%
é —> é 2,7% +m 1,6% a —> 23 2.2% e —> é 0.8%
—s 2,5% e —> é 1,4% +nt 1.9% é —> é 0.7%
+e 2,2% +1 1,3% +t 1.7% s —> t 0.7%
é —> e 2,1% -I 1,3% a —> e 1.5% f1 —> u 0.7%

TAB. 2 — Les vingt corrections les plus fréquentes. Ces corrections représentent 65,0% des corrections
d’erreurs grammaticales du corpus et 53,5% des corrections d’erreurs lexicales

| erreurs lexicales erreurs grammaticales

premiere moitié du mot 34,06% 4,08%
seconde moitié du mot 62,81% 93,26%
erreurs dans les deux moitiés 3,13% 2,63%

TAB. 3 — Localisation des erreurs a l’intérieur d’un mot

3.3 Bilan

Les résultats présentés dans les sections précédentes illustrent quelques-unes des limites que notre méthode
de détection automatique des erreurs rencontre dans un contexte ou la norme autorise des variations et ou
l’usage est de plus en plus tolérant (par l’eXemple sur l’accentuation des majuscules) : faute d’utiliser des
ressources lexicales adéquates pour mieux ﬁltrer les corrections, notre corpus agrege un certain nombre
de modiﬁcations qui ne sont pas des corrections d’erreurs. Il est également important de noter que les
statistiques présentées, si elles s’accordent globalement avec d’autres observations sur les difﬁcultés du
francais (Catach, 1980), ne doivent pas étre prises trop littéralement : notre corpus ne permet de mesurer
que les fautes les plus courantes effectuées au clavier par des scripteurs dont on peut penser qu’ils sont
globalement plus éduqués, plus familiés des nouvelles technologies, etc. que l’ensemble des scripteurs
du francais. Par ailleurs, l’utilisation de nombreux ﬁltres nous a conduit a ignorer dans cette premiere
version du corpus les modiﬁcations de ponctuation, les corrections qui conduisent a fusionner deux mots,
ou au contraire a remplacemer un mot par deux. Il reste ici un gros effort d’analyse a accomplir pour
mieux caractériser notre corpus. Nous montrons dans la suite qu’en dépit de ces limites, une exploitation
raisonnée de ce corpus permet d’aider au développement d’outils de correction automatique.

4 Evaluation et apprentissage de correcteurs orthographiques

Nous proposons, dans cette section, de montrer comment le corpus d’erreurs que nous avons construit
peut étre utilisé a la fois pour évaluer les performances d’un correcteur orthographique automatique et
pour apprendre certains des parametres de celui-ci. Jusqu’a présent, l’évaluation des correcteurs ne s’est

8Déﬁni ici comme la lettre précédant et la lettre suivant le lieu de la modiﬁcation

GUILLAUME WISNIEWSKI, AURELIEN MAX ET FRANCOIS YVoN

faite que sur des corpus artiﬁciels (Islam & Inkpen, 2009). En utilisant un corpus d’erreurs écologiques,
nous espérons développer un correcteur mieux adapté aux erreurs réelles des utilisateurs.

Aujourd’hui, la plupart des correcteurs orthographiques sont des systemes d’« aide a la correction » :
ils sont capables d’identiﬁer les mots non valides d’une langue, de suggérer un ensemble de corrections
possibles pour un mot donné (que ce mot ait été identiﬁé comme une erreur ou non), mais ils laissent le
choix de la bonne correction a l’utilisateur. Dans ce travail, nous nous concentrons sur l’évaluation de la
qualité des corrections suggérées, puis introduisons, dans la deuxieme partie de cette section, une premiere
expérience portant sur la possibilité d’automatiser la correction.

4.1 Qualité de l’ensemble des suggestions

Deux criteres doivent étre pris en compte dans l’évaluation de l’ensemble des suggestions : le nombre de
fois ou la correction d’une faute est suggérée et le nombre de suggestions du systeme. Nous proposons
donc d’utiliser la mesure suivante :

. , 1 5;‘
qual1te = —
N ¥ #si
La somme se fait sur les N exemples de l’ensemble d’évaluation, 6, vaut I si la i° correction est dans
l’ensemble des suggestions, 0 sinon et #3, est la taille de l’ensemble de suggestions correspondant.

Dans ce travail préliminaire, nous considérons trois moyens de construire l’ensemble des suggestions :

1. en considérant l’ensemble des suggestions proposé par Hunspell (méthode hunspell). Ces sugges-
tions sont engendrées par une liste de regles qui décrivent des corrections possibles du lemme et des
variantes morphologiques des formes corrigées9. Toutes ces regles sont écrites a la main.

2. en appliquant un ensemble de patrons des corrections au mot a corriger et en ne conservant que les
applications générant un mot valide selon Hunspell (méthode motif). Nous utilisons les 20 patrons
les plus frequents du corpus, qui sont décrits dans la Table 2. Ces patrons (i —> .1 par exemple)
sont appliqués indépendamment les uns des autres et sans tenir compte du contexte.

3. en considérant la liste des corrections apparaissant dans le corpus (méthode liste). Cette liste est
construite simplement en associant, pour chaque exemple du corpus, le mot mal orthographié a
l’ensemble de ses corrections. Cette liste est semblable aux ensembles de confusions utilisés dans
plusieurs correcteurs orthographiques (Islam & Inkpen, 2009; Carlson & Fette, 2007). Mais, comme
nous disposons d’un corpus d’erreurs, la construction de cette liste est triviale et rapide, alors que
dans la plupart des travaux, les ensembles de confusions sont construits manuellement.

La premiere approche permet d’évaluer un correcteur libre de l’état de l’art utilisé dans de nombreux
produits « grand public » tels que le navigateur Firefox ou la suite bureautique OpenOfﬁce. Les deux
autres approches ont pour objectif de montrer l’impact que peut avoir l’utilisation d’un corpus d’erreurs
avec les caractéristiques de celui que nous avons construit sur le développement de correcteurs.

Pour évaluer ces trois approches, nous séparons aléatoirement le corpus en un ensemble d’apprentissage
contenant 80% des exemples et un ensemble de test contenant les 20% restants. L’ ensemble detest sert a
mesurer la qualité des suggestions ; l’ensemble d’apprentissage a constr11ire la liste des corrections.

Les résultats de cette experience sont présentés Table 4. Ils montrent clairement qu’il est possible, en
combinant ces trois approches, d’assurer que l’orthographe correcte d’un mot est toujours présente dans

9Ces régles sont écrites par des Volontaires, en suivant un mode de développement similaire a celui des logiciels libres.

CORPUS DE CORRECTIONS ORTHOGRAPHIQUES

l’ensemble des suggestions. Notons également qu’Hunspell obtient de tres bonnes performances pour la
correction des erreurs lexicales, mais est moins utile pour la correction des erreurs grammaticales. Les
deux types d’erreurs partagent pourtant plusieurs caractéristiques (notaInment leur distance d’édition) et
l’on aurait pu espérer que les regles de corrections d’Hunspell seraient sufﬁsamment générales pour traiter
certaines des erreurs grammaticales. Il est, par exemple, surprenant qu’Hunspell ne propose quasiment
aucune variation morphologique des mots corrigés.

Erreurs lexicales Erreurs graInmaticales
méthode qualité moyenne max. corr. qualité moyenne max. corr.
hunspell 40,0% 4,5 15 95,0% 13,0% 8,6 15 65,1 %

liste 51,1% 1,3 7 58,7% 32,1% 8,3 41 75,7%
motif 35,5% 1,7 11 48,7% 31,3% 2,3 7 53,2%
combi. 38,9% 4,7 22 96,8% 13,7% 14,9 47 92,6%

TAB. 4 — Qualité des ensembles de suggestions évaluée par la mesure introduite (qualité), la taille de
l’ensemble de suggestion (moyenne et max), et le pourcentage d’erreurs dont la correction est suggérée
(corr.)

4.2 Correction automatique des erreurs orthographiques

Nous présentons, Table 5, nos premiers résultats sur la correction automatique des erreurs orthographiques“).
Ces résultats sont obtenus en ordonnant par un modele de langage statistique de type n-gram, estimé sur le
corpus d’apprentissage, les suggestions proposées par la combinaison des trois méthodes introduites dans
la section précédente.

Malgré la simplicité du modele (il n’y a aucune modélisation des erreurs et seul le contexte est utilisé pour
classer les suggestions), les résultats sont plutot encourageants : dans la majorité des cas, notre correcteur
est capable de trouver automatiquement la bonne correction.

erreurs lexicales erreur graInmaticales
corpus corrections possibles corpus corrections possibles
modele 3-gram 58,9% 60,8% 46,7% 51,9%
modele 5-gram ‘ 75,2% 77,7% ‘ 66,9% 71,3%

TAB. 5 — Pourcentage de mots correctement corrigés sur tout le corpus de test et lorsque l’on ne considere
que les mots dont la correction est possible

5 Conclusion

Nous avons présenté et analysé un nouveau corpus d’erreurs d’orthographe écologique, qui ouvre de nou-
velles possibilités pour une étude in Vivo de l’orthographe du francais tel qu’il s’écrit électroniquement,

1°Par manque de place ni ces résultats ni notre méthode ne sont détajllés.

GUILLAUME WISNIEWSKI, AURELIEN MAX ET FRANCOIS YvoN

ainsi que pour l’évaluation et l’apprentissage de dispositifs de correction automatisée. Un des intéréts de
ce corpus pour la correction orthographique est qu’il permet de développer des systemes de correction
plus adaptatifs, c’est-a-dire s’appuyant sur l’usage réel du francais dans diverses situations de communi-
cation plutot que sur une norme déﬁnie de maniere abstraite et rigide. La méthodologie utilisée pour le
construire est générique et ne requiert que la disponibilité de révisions successives d’un document : elle
pourrait facilement étre utilisée, par exemple, pour acquérir des corpus permettant d’adapter un correcteur
aux erreurs typiques d’un scripteur a partir des révisions effectuées.

Des expériences préliminaires illustrant l’utilisation de ce corpus dans un contexte de correction automa-
tique ont été présentées. WICOPACO peut étre également utilisé dans de nombreuses autres taches de TAL
et nous sommes actuellement en train de l’exploiter pour l’étude des reformulations et l’identiﬁcation des
paraphrases, pour l’apprentissage et l’évaluation d’un systeme de correction automatique complet ainsi
que pour le développement de systeme de normalisation de documents pour la traduction automatique.

Remerciements

Ce travail a été partiellement ﬁnancé dans le cadre d’une Action Incitative du LIMSI et du projet TRACE
(ANR CONTINT 2009). Les auteurs remercient J ulien Boulet et Martine Hurault-Plantet pour leur aide.

Références

CARLSON A. & FETTE I. (2007). Memory-based context-sensitive spelling correction at web scale. In
ICMLA ’07, p. 166-171, Washington, DC, USA : IEEE Computer Society.

CATACH N. (1980). L’orthographefrancaise .' traite theorique etpratique avec des travaux d’application
et leurs corriges (avec la collaboration de Claude Gruaz et Daniel Duprez). Nathan, Paris.

ISLAM A. & INKPEN D. (2009). Real-word spelling correction using Google Web 1T 3-grams. In
Proceedings of EMNLP’09, p. 1241-1249, Singapore.

KUKICH K. (1992). Techniques for automatically correcting words in text. ACM Comput. Surv., 24(4),
377-439.

MAX A. & WISNIEWSKI G. (2010). Mining naturally-occurring corrections and paraphrases from
wikipedia’s revision history. In LREC’I0, Valletta, Malta.

NAVARRO G. (1999). A guided tour to approximate string matching. ACM Computing Surveys, 33, 2001.

NELKEN R. & YAMANGIL E. (2008). Mining wikipedia’s article revision history for training computa-
tional linguistics algorithms. In AAAI Workshop on Wikipedia and Artiﬁcial Intelligence.

RATCLIFF J . W. & METZENER D. E. (1988). Pattern matching : The gestalt approach. Dr. Dobb’s
Journal.

WAGNER R. A. & FISCHER M. J . (1974). The string-to-string correction problem. Journal of the ACM
(JACM), 21(1), 168-173.

