<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Reconnaissance robuste d&#8217;entit&#233;s nomm&#233;es sur de la parole transcrite automatiquement</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>Reconnaissance robuste d&#8217;entit&#233;s nomm&#233;es sur de la parole
transcrite automatiquement
</p>
<p>Christian Raymond1, 2 Julien Fayolle1
</p>
<p>(1) Universit&#233; Europ&#233;enne de Bretagne, INRIA,IRISA, UMR 6074, France
(2) INSA de Rennes, 20 Avenue des buttes de coesme, Rennes, France
</p>
<p>pr&#233;nom.nom@irisa.fr
</p>
<p>R&#233;sum&#233;. Les transcriptions automatiques de parole constituent une ressource importante, mais sou-
vent bruit&#233;e, pour d&#233;crire des documents multim&#233;dia contenant de la parole (e.g. journaux t&#233;l&#233;vis&#233;s). En
vue d&#8217;am&#233;liorer la recherche documentaire, une &#233;tape d&#8217;extraction d&#8217;information &#224; caract&#232;re s&#233;mantique,
pr&#233;c&#233;dant l&#8217;indexation, permet de faire face au probl&#232;me des transcriptions imparfaites. Parmis ces conte-
nus informatifs, on compte les entit&#233;s nomm&#233;es (e.g. noms de personnes) dont l&#8217;extraction est l&#8217;objet de ce
travail. Les m&#233;thodes traditionnelles de reconnaissance bas&#233;es sur une d&#233;finition manuelle de grammaires
formelles donnent de bons r&#233;sultats sur du texte ou des transcriptions propres manuellement produites,
mais leurs performances se trouvent fortement affect&#233;es lorsqu&#8217;elles sont appliqu&#233;es sur des transcriptions
automatiques. Nous pr&#233;sentons, ici, trois m&#233;thodes pour la reconnaissance d&#8217;entit&#233;s nomm&#233;es bas&#233;es sur
des algorithmes d&#8217;apprentissage automatique : les champs conditionnels al&#233;atoires, les machines &#224; de sup-
port, et les transducteurs &#224; &#233;tats finis. Nous pr&#233;sentons &#233;galement une m&#233;thode pour rendre consistantes
les donn&#233;es d&#8217;entrainement lorsqu&#8217;elles sont annot&#233;es suivant des conventions l&#233;g&#232;rement diff&#233;rentes. Les
r&#233;sultats montrent que les syst&#232;mes d&#8217;&#233;tiquetage obtenus sont parmi les plus robustes sur les donn&#233;es
d&#8217;&#233;valuation de la campagne ESTER 2 dans les conditions o&#249; la transcription automatique est particuli&#232;re-
ment bruit&#233;e.
</p>
<p>Abstract. Automatic speech transcripts are an important, but noisy, ressource to index spoken mul-
timedia documents (e.g. broadcast news). In order to improve both indexation and information retrieval,
extracting semantic information from these erroneous transcripts is an interesting challenge. Among these
meaningful contents, there are named entities (e.g. names of persons) which are the subject of this work.
Traditional named entity taggers are based on manual and formal grammars. They obtain correct perfor-
mance on text or clean manual speech transcripts, but they have a lack of robustness when applied on
automatic transcripts. We are introducing, in this work, three methods for named entity recognition based
on machine learning algorithms, namely conditional random fields, support vector machines, and finite-
state transducers. We are also introducing a method to make consistant the training data when they are
annotated with slightly different conventions. We show that our tagger systems are among the most robust
when applied to the evaluation data of the French ESTER 2 campaign in the most difficult conditions where
transcripts are particularly noisy.
</p>
<p>Mots-cl&#233;s : &#233;tiqueteur d&#8217;entit&#233;s nomm&#233;es, transcription automatique de parole, apprentissage au-
tomatique, champs conditionnels al&#233;atoires, machines &#224; vecteurs de support, transducteurs &#224; &#233;tats finis.
</p>
<p>Keywords: named entity tagger, automatic speech recognition transcripts, machine learning, condi-
tionnal random fields, support vector machines, finite-state transducers.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Christian Raymond, Julien Fayolle
</p>
<p>1 Introduction
</p>
<p>La transcription de flux audio (enregistrements radiophoniques, de r&#233;unions, de journaux t&#233;l&#233;vis&#233;s, etc.)
est un enjeu important pour le domaine de l&#8217;archivage et de la recherche d&#8217;information. L&#8217;extraction auto-
matique de contenus &#224; valeur ajout&#233;e &#224; partir de ces transcriptions devient un axe de recherche primordial
afin d&#8217;utiliser et d&#8217;exploiter le maximum d&#8217;information contenu dans le flux audio. Parmi ces contenus
&#224; valeur ajout&#233;e, sont souvent consid&#233;r&#233;es les entit&#233;s nomm&#233;es. La plupart des syst&#232;mes d&#8217;&#233;tiquetage en
entit&#233;s nomm&#233;es utilisent des m&#233;thodes symboliques &#224; base de grammaires formelles, &#233;ventuellement
compl&#233;t&#233;es par des connaissances a priori (e.g. listes de pr&#233;noms, de villes ou de pays). Dans les grandes
campagnes d&#8217;&#233;valuation, ces syst&#232;mes impl&#233;ment&#233;s manuellement obtiennent les meilleurs r&#233;sultats sur le
texte propre (texte ou transcription manuelle de parole) (voir [1] pour la campagne ESTER 2). Lorsque la
reconnaissance d&#8217;entit&#233;s nomm&#233;es se fait sur des transcriptions automatiques de parole, le probl&#232;me gagne
en difficult&#233; car contrairement aux documents textuels, les documents transcrits automatiquement ne sont
pas structur&#233;s (ni casse, ni ponctuation) et certains mots transcrits sont erron&#233;s : le taux d&#8217;erreur de mots
peut varier de 5% &#224; plus de 50% selon le document et les conditions de transcriptions. Dans ces conditions,
les syst&#232;mes symboliques sont g&#233;n&#233;ralement moins robustes que des &#233;tiqueteurs bas&#233;s sur des m&#233;thodes
d&#8217;apprentissage automatique, notamment car elles sont capables d&#8217;extraire de ces donn&#233;es des r&#232;gles de
d&#233;cision qu&#8217;un expert humain n&#8217;aurait pu appr&#233;hender. Guid&#233;s par cette notion de robustesse face aux
transcriptions automatiques, nous pr&#233;sentons trois syst&#232;mes d&#8217;&#233;tiquetage bas&#233;s sur diff&#233;rents algorithmes
de classification automatique qui ont d&#233;j&#224; fait leurs preuves dans la t&#226;che de reconnaissance en entit&#233;s
nomm&#233;es (voir respectivement [8, 5, 3]), un syst&#232;me &#224; base de champs conditionnels al&#233;atoires (CRF),
un &#224; base de machines &#224; vecteurs de support (SVM), et un &#224; base de transducteurs &#224; &#233;tats finis (FST).
Dans la partie 2, nous pr&#233;sentons l&#8217;approche g&#233;n&#233;rale utilis&#233;e en reconnaissance d&#8217;entit&#233;s nomm&#233;es par
des m&#233;thodes &#224; base d&#8217;apprentissage automatique. Seront ensuite pr&#233;sent&#233;es dans la partie 3, les m&#233;thodes
d&#8217;apprentissage utilis&#233;es dans ce travail. Enfin, la partie 4 pr&#233;sentera les donn&#233;es d&#8217;&#233;valuations et la partie
5 les exp&#233;riences effectu&#233;es ainsi que les r&#233;sultats obtenus.
</p>
<p>2 Reconnaissance d&#8217;entit&#233;s nomm&#233;es
</p>
<p>La reconnaissance d&#8217;entit&#233;s nomm&#233;es consiste &#224; rechercher des objets textuels (i.e. un mot, ou un groupe
de mot) cat&#233;gorisables dans des classes telles que noms de personnes, noms d&#8217;organisations ou d&#8217;entre-
prises, noms de lieux, quantit&#233;s, distances, valeurs, dates, etc. C&#8217;est un probl&#232;me typique d&#8217;&#233;tiquetage de
s&#233;quences dont le but est, pour une s&#233;quence donn&#233;e, de trouver la s&#233;quence d&#8217;&#233;tiquettes correspondante
la plus probable. Dans notre cas, la s&#233;quence donn&#233;e est une s&#233;quence de mots issus de la transcrip-
tion de parole, et la s&#233;quence d&#8217;&#233;tiquettes recherch&#233;e est la s&#233;quence d&#8217;entit&#233;s nomm&#233;es correspondante.
Pour r&#233;soudre le double probl&#232;me de la segmentation et de l&#8217;&#233;tiquetage (i.e. trouver l&#8217;entit&#233; ainsi que ses
fronti&#232;res dans la s&#233;quence de mots), l&#8217;encodage BIO (pour begin, inside, outside) est traditionnellement
utilis&#233;. Un indicateur B, I ou O est ajout&#233; &#224; l&#8217;&#233;tiquette afin d&#8217;identifier si le mot correspondant est au d&#233;but,
&#224; l&#8217;int&#233;rieur ou &#224; l&#8217;ext&#233;rieur de l&#8217;entit&#233; nomm&#233;e. Un exemple est donn&#233; table 1.
</p>
<p>Les m&#233;thodes &#224; base d&#8217;apprentissage automatique utilisent des donn&#233;es annot&#233;es (en g&#233;n&#233;ral par des ex-
perts humains) pour construire automatiquement des r&#232;gles de d&#233;cision &#224; partir d&#8217;un ensemble de des-
cripteurs. Les mots de la transcription sont d&#233;j&#224; un premier niveau de description. Afin de construire des
syst&#232;mes plus performants, d&#8217;autres niveaux sont g&#233;n&#233;ralement envisag&#233;s.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Reconnaissance robuste d&#8217;entit&#233;s nomm&#233;es sur de la parole transcrite automatiquement
</p>
<p>mots ici jacques doutisoro lom&#233; africa num&#233;ro un
&#233;tiquettes O pers-B pers-I loc-B org-B org-I org-I
</p>
<p>entit&#233;s null pers loc org
</p>
<p>TABLE 1 &#8211; Exemple d&#8217;&#233;tiquetage de s&#233;quences appliqu&#233; &#224; la reconnaissance d&#8217;entit&#233;s nomm&#233;es. On y
retrouve les mots de la transcription automatique &#224; &#233;tiqueter, les &#233;tiquettes trouv&#233;es suivant l&#8217;encodage
BIO et les entit&#233;s nomm&#233;es correspondantes.
</p>
<p>Par exemple, le r&#233;sultat d&#8217;un &#233;tiqueteur morpho-syntaxique peut &#234;tre utilis&#233; pour construire des r&#232;gles &#224;
port&#233;e plus g&#233;n&#233;rale et ainsi am&#233;liorer le rappel du syst&#232;me, ou bien des connaissances a priori fortes
peuvent &#234;tre int&#233;gr&#233;es pour am&#233;liorer la pr&#233;cision ainsi que le rappel.
</p>
<p>niveau type exemple
premier MOT : mot &quot;Jacques&quot;
</p>
<p>second
MS : &#233;tiquette morpho-syntaxique &quot;NPMS&quot;, nom propre masculin singulier
</p>
<p>AP : classe connu a priori &quot;VILLE&quot;
MI : mot &quot;important&quot; &quot;num&#233;ro&quot;
</p>
<p>TABLE 2 &#8211; Niveaux de description
</p>
<p>Ici, deux niveaux de description (table 2) sont utilis&#233;s. Le premier est directement compos&#233; des mots
(MOT) de la transcription et le second peut &#234;tre des trois types suivants :
&#8211; MS : r&#233;sultat d&#8217;un &#233;tiquetage morpho-syntaxique [4],
&#8211; AP : classe de g&#233;n&#233;ralisation correspondant &#224; des connaissances connues a priori, i.e. listes de pays, de
</p>
<p>villes, de gentil&#233;s, d&#8217;unit&#233;s de mesure,
&#8211; MI : mot &quot;important&quot; dont l&#8217;information mutuelle partag&#233;e avec son &#233;tiquette d&#8217;entit&#233; nomm&#233;e est su-
</p>
<p>p&#233;rieure &#224; z&#233;ro (i.e. mot suppos&#233; plus discriminant qu&#8217;une &#233;tiquette morpho-syntaxique) et qui appara&#238;t
au moins trente fois dans le corpus d&#8217;apprentissage (i.e. mot &#224; capacit&#233; de g&#233;n&#233;ralisation suffisante).
</p>
<p>Comme illustr&#233; sur la figure 1, l&#8217;&#233;tiquette courante est estim&#233;e &#224; partir des descripteurs (mots et classes)
situ&#233;s dans la fen&#234;tre locale [&#8722;2,+2] entourant la position 0 de d&#233;cision. On y retrouve les trois types de
classe du second niveau de description, &#224; savoir les &#233;tiquettes morpho-syntaxiques en rouge, les classes
connues a priori en bleu, et les mots &quot;importants&quot; en vert.
</p>
<p>FIGURE 1 &#8211; Exemple d&#8217;&#233;tiquetage en entit&#233;s nomm&#233;es &#224; partir des descripteurs de premier et second
niveaux</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Christian Raymond, Julien Fayolle
</p>
<p>3 Algorithmes d&#8217;apprentissage automatique
</p>
<p>3.1 Machines &#224; vecteurs de support
</p>
<p>Les machines &#224; vecteurs de support introduites par Vapnik [11], couramment abr&#233;g&#233;es en SVM sont des
classifieurs discriminants &#224; large marge. Les SVM sont au d&#233;part des classifieurs binaires qui repr&#233;sentent
les &#233;chantillons &#224; classer sous la forme d&#8217;un vecteur dont chaque composante repr&#233;sente la contribution
d&#8217;un param&#232;tre &#224; un exemple. Par exemple, pour une t&#226;che de classification de documents les vecteurs
repr&#233;sentant chaque document pourraient avoir la taille du vocabulaire associ&#233; aux documents et chaque
composante du vecteur serait nulle ou non nulle selon que le mot correspondant est absent ou non du
document en question. Le principe est alors de d&#233;terminer l&#8217;hyperplan s&#233;parateur optimal entre les deux
classes (si le probl&#232;me est lin&#233;airement s&#233;parable), celui qui maximise la marge entre les &#233;chantillons et
l&#8217;hyperplan s&#233;parateur. La marge est la distance entre l&#8217;hyperplan et les &#233;chantillons le plus proches : appe-
l&#233;s &quot;vecteurs de support&quot;. Si la m&#233;thode ne fonctionne que si le probl&#232;me est lin&#233;airement s&#233;parable, gr&#226;ce
aux fonctions noyaux, les SVM sont capables de consid&#233;rer le probl&#232;me dans un espace de dimension plus
&#233;lev&#233; dans lequel il existe probablement un s&#233;parateur lin&#233;aire.
</p>
<p>Deux m&#233;thodes principales ont &#233;t&#233; propos&#233;es pour &#233;tendre la classification binaire au cas o&#249; l&#8217;on a M
classes :
&#8211; La m&#233;thode one-versus-all consiste &#224; construire M classifieurs binaires en attribuant le label 1 aux
</p>
<p>&#233;chantillons de l&#8217;une des classes et le label -1 &#224; toutes les autres. En phase de test, le classifieur donnant
la valeur de confiance (e.g. la marge) la plus &#233;lev&#233;e remporte le vote.
</p>
<p>&#8211; La m&#233;thode one-versus-one consiste &#224; construire M(M &#8722; 1)/2 classifieurs binaires en confrontant
chacune des M classes. En phase de test, l&#8217;&#233;chantillon &#224; classer est analys&#233; par chaque classifieur et un
vote majoritaire permet de d&#233;terminer sa classe.
</p>
<p>Bien que les SVM permettent l&#8217;utilisation de param&#232;tres tr&#232;s vari&#233;s, contrairement aux algorithmes sp&#233;ci-
fiquement connus pour l&#8217;&#233;tiquetage s&#233;quentiel, ils ne peuvent prendre de d&#233;cision globale sur la s&#233;quence
car chaque &#233;tiquette de la s&#233;quence est vue ind&#233;pendamment des autres. Toutefois, certaines heuristiques
peuvent &#234;tre impl&#233;ment&#233;es, par l&#8217;exemple l&#8217;ajout d&#8217;un param&#232;tre de classification qui serait la d&#233;cision pr&#233;-
c&#233;dente dans la s&#233;quence. YAMCHA, un syst&#232;me bas&#233; sur cette approche, a obtenu les meilleurs r&#233;sultats
dans la t&#226;che de chunking et BaseNP chunking de CoNLL2000 [6] et a &#233;t&#233; choisi pour l&#8217;impl&#233;mentation
de l&#8217;&#233;tiqueteur SVM.
</p>
<p>Dans ce travail, le vecteur de chaque exemple est compos&#233; des couples mots ou/et classes associ&#233;s &#224; leur
position par rapport &#224; la position de d&#233;cision dans un intervalle local [&#8722;2,+2] (figure 1).
</p>
<p>3.2 Transducteurs &#224; &#233;tats finis
</p>
<p>L&#8217;approche &#224; base de transducteurs &#224; &#233;tats finis est une approche g&#233;n&#233;rative stochastique bas&#233;e sur le cal-
cul de la probabilit&#233; jointe entre la s&#233;quence d&#8217;observations (mots) et la s&#233;quence d&#8217;&#233;tiquettes (entit&#233;s
nomm&#233;es). Cette approche est particuli&#232;rement appropri&#233;e pour traiter des transcriptions de parole [3]
puisqu&#8217;elle est bas&#233;e sur le m&#234;me paradigme traditionnellement utilis&#233;e dans les syst&#232;mes de reconnais-
sance automatique de la parole. Plus formellement, notons e = e1, e2, . . . , eN la s&#233;quence d&#8217;&#233;tiquettes
associ&#233;es &#224; la s&#233;quence de mots m = m1,m2, . . . ,mN produite par un syst&#232;me de reconnaissance auto-
matique de la parole. Le processus d&#8217;&#233;tiquetage consiste &#224; trouver la s&#233;quence d&#8217;&#233;tiquettes maximisant la</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Reconnaissance robuste d&#8217;entit&#233;s nomm&#233;es sur de la parole transcrite automatiquement
</p>
<p>probabilit&#233; a posteriori p(e|A), o&#249; A repr&#233;sente les observations acoustiques extraites du signal de parole.
Pour r&#233;soudre ce probl&#232;me, il est commode de faire intervenir des connaissances suppl&#233;mentaires tels que
des classes d&#8217;&#233;quivalence (pr&#233;sent&#233;es dans la partie 2). Notons c = c1, c2, . . . , cN la s&#233;quence de classes.
Ainsi, trouver la meilleure s&#233;quence d&#8217;&#233;tiquettes e&#770; &#233;tant donn&#233;es les observations acoustiquesA se formule
par :
</p>
<p>p(e&#770;|A) = argmax
e
</p>
<p>&#8721;
c
</p>
<p>&#8721;
m
</p>
<p>p(m, c, e|A)
</p>
<p>= argmax
e
</p>
<p>&#8721;
c
</p>
<p>&#8721;
m
</p>
<p>p(A|m, c, e)p(m, c, e)
</p>
<p>&#8776; argmax
m,c,e
</p>
<p>p(A|m, c, e)p(m, c, e)
o&#249;
</p>
<p>p(A|m, c, e) &#8776; p(A|m)
p(m, c, e) = p(m|c, e)p(c, e)
</p>
<p>alors
p(e&#770;|A) &#8776; argmax
</p>
<p>m,c,e
p(A|m)p(m|c, e)p(c, e) (1)
</p>
<p>La probabilit&#233; p(A|m) est estim&#233;e par le mod&#232;le acoustique du syst&#232;me de reconnaissance automatique de
la parole. p(m|c, e) est la probabilit&#233; d&#8217;une s&#233;quence de mots sachant le couple classe/&#233;tiquette et p(c, e)
la probabilit&#233; jointe estim&#233;e sur les couples classe/&#233;tiquette.
</p>
<p>p(m|c, e) est estim&#233;e de la mani&#232;re suivante :
</p>
<p>p(m|c, e) =
N&#8719;
i=1
</p>
<p>cooccurence(mi, ci, ei)
</p>
<p>cooccurence(ci, ei)
(2)
</p>
<p>Les probl&#232;mes de segmentation et de classification sont r&#233;solus simultan&#233;ment &#224; travers l&#8217;utilisation de
l&#8217;encodage BIO (table 1). &#192; chaque mot mi est alors associ&#233;e l&#8217;&#233;tiquette ti, ti = {ei-[B|I],O}. La proba-
bilit&#233; jointe est alors calcul&#233;e par :
</p>
<p>p(c, e) = p{(t1, c1)(t2, c2) . . . (tn, cn)} = p(t, c)
Cette probabilit&#233; est estim&#233;e par un mod&#232;le N-gramme du troisi&#232;me ordre :
</p>
<p>p(c, e) =
N&#8719;
n=1
</p>
<p>p(cn, tn|hn) (3)
</p>
<p>avec hn = (cn&#8722;1, tn&#8722;1), (cn&#8722;2, tn&#8722;2)
</p>
<p>Le processus d&#8217;&#233;tiquetage est g&#233;n&#233;ralement effectu&#233; pour une s&#233;quence de mots m fix&#233;e (i.e. la meilleure
hypoth&#232;se de transcription automatique). L&#8217;originalit&#233; de cette approche est de pouvoir s&#8217;int&#233;grer direc-
tement dans le processus de reconnaissance automatique de la parole. En effet, elle permet de r&#233;aliser
l&#8217;&#233;tiquetage directement sur des graphes de mots, &#224; condition que ceux-ci soient encod&#233;s comme des
automates &#224; &#233;tats finis. L&#8217;impl&#233;mentation de cette approche a &#233;t&#233; r&#233;alis&#233; avec la librairie AT&amp;T [9].
</p>
<p>La meilleure s&#233;quence de couples mot/&#233;tiquette est le meilleur chemin dans le transducteur &#955;m2e obtenu
par composition de trois transducteurs : &#955;m2e = &#955;m &#9702; &#955;m2ce &#9702; &#955;ce
Les trois transducteurs sont d&#233;finis de la mani&#232;re suivante :</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Christian Raymond, Julien Fayolle
</p>
<p>1. &#955;m est la repr&#233;sentation de l&#8217;entr&#233;e &#224; &#233;tiqueter sous forme d&#8217;automate &#224; &#233;tats finis (hypoth&#232;se ou graphe
de mots g&#233;n&#233;r&#233; par le moteur de reconnaissance de la parole avec les scores acoustiques, p(A|m) dans la
formule 1). Dans les exp&#233;riences suivantes, dans le but de rester comparable avec les autres m&#233;thodes,
&#955;m encode la meilleure hypoth&#232;se de reconnaissance ;
</p>
<p>2. &#955;m2ce fait l&#8217;association entre les mots et leurs couples classe/entit&#233;, les classes peuvent &#234;tre le r&#233;sultat
d&#8217;un &#233;tiquetage morpho-syntaxique ou/et des classes repr&#233;sentant des connaissances a priori sur les
mots (e.g. liste de pays, de ville) ou/et les mots eux-m&#234;mes. Le transducteur poss&#232;de alors en entr&#233;e les
mots et en sortie les couples classe/entit&#233;. Les scores associ&#233;s aux transitions encodent p(m|c, e) dans
la formule 1 et sont calcul&#233;s selon 2 ;
</p>
<p>3. &#955;ce encode le mod&#232;le estimant la probabilit&#233; jointe &#233;tiquette/entit&#233; d&#233;crite dans la formule 4.
</p>
<p>3.3 Champs Conditionnels Al&#233;atoires
</p>
<p>Les champs conditionnels al&#233;atoires, introduits par [7], poss&#232;dent les avantages des mod&#232;les g&#233;n&#233;ratifs
et discriminants. Comme les classifieurs discriminants, ils peuvent manipuler un grand nombre de des-
cripteurs et comme les mod&#232;les g&#233;n&#233;ratifs, ils int&#232;grent des d&#233;pendances entre les &#233;tiquettes de sortie et
prennent une d&#233;cision globale sur la s&#233;quence. Cependant, ils ne sont pas facilement int&#233;grables avec le
syst&#232;me de reconnaissance automatique de la parole (e.g. analyse d&#8217;un graphe de mots).
</p>
<p>Un champ conditionnel al&#233;atoire est d&#233;fini par un graphe de d&#233;pendances et un ensemble de fonctions fk
auxquelles sont associ&#233;es des poids &#955;k. La probabilit&#233; conditionnelle d&#8217;une annotation, s&#233;quence d&#8217;&#233;ti-
quettes e &#233;tant donn&#233; l&#8217;observation O (i.e. mots, &#233;tiquettes morpho-syntaxiques) est donn&#233;e par :
</p>
<p>p(e|O) = 1
Z(O)
</p>
<p>exp(
&#8721;
c&#8712;C
</p>
<p>&#8721;
k
</p>
<p>&#955;kfk(ec, O, c))
</p>
<p>avec
</p>
<p>Z(O) =
&#8721;
e
</p>
<p>exp(
&#8721;
c&#8712;C
</p>
<p>&#8721;
k
</p>
<p>&#955;kfk(ec, O, c))
</p>
<p>Les connaissances, les descripteurs (lexicaux, s&#233;mantique, etc.), et les relations entre concepts sont enco-
d&#233;s dans le mod&#232;le &#224; travers ces fonctions. Ces fonctions binaires retournent 1 s&#8217;il y a correspondance ou
0 sinon. Elles prennent en param&#232;tre les valeurs prises par les variables al&#233;atoires (ec) de la clique (c) sur
laquelle elles s&#8217;appliquent, ainsi que la totalit&#233; de l&#8217;observation O. Les poids &#955;k associ&#233;s &#224; chacune de
ces fonctions sont les param&#232;tres du mod&#232;le estim&#233;s lors de la phase d&#8217;apprentissage. Dans ce travail, le
graphe des d&#233;pendances mod&#233;lise des d&#233;pendances du premier ordre, et les cliques seront alors compos&#233;es
de deux variables al&#233;atoires, celle &#224; la position courante et &#224; la position pr&#233;c&#233;dente. Les exp&#233;riences ont
&#233;t&#233; r&#233;alis&#233;es &#224; l&#8217;aide de l&#8217;outil libre CRF++ 1.
</p>
<p>Dans nos exp&#233;riences, les fonctions encodent tous les unigrammes, bigrammes et trigrammes construits
sur les couples symbole/position dans une fen&#234;tre [&#8722;2,+2] autour de la position de d&#233;cision.
</p>
<p>1. Disponible sur Internet &#224; l&#8217;adresse http://crfpp.sourceforge.net/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Reconnaissance robuste d&#8217;entit&#233;s nomm&#233;es sur de la parole transcrite automatiquement
</p>
<p>4 Conditions exp&#233;rimentales
</p>
<p>4.1 Corpus et t&#226;ches ESTER 2
</p>
<p>Le corpus ESTER 2 relatif aux entit&#233;s nomm&#233;es se composent de 72 heures d&#8217;&#233;missions radiophoniques
francophones (France-Inter, France Info, RFI, RTM, France Culture, Radio Classique) manuellement
transcrites et annot&#233;es en entit&#233;s nomm&#233;es suivant les conventions des deux campagnes ESTER [Ester]
qui sont l&#233;g&#232;rement diff&#233;rentes. La premi&#232;re campagne comporte un jeu de 30 types d&#8217;entit&#233;s nomm&#233;es
r&#233;parties en 9 cat&#233;gories principales (personne, organisation, groupe g&#233;o-socio-politique, lieu, b&#226;timent
et construction humaine, production humaine, date et heure, montant, inconnue), alors que la seconde
poss&#232;de un jeu de 37 types d&#8217;entit&#233;s nomm&#233;es r&#233;parties en 7 cat&#233;gories principales (personne, fonction,
organisation, lieu, production humaine, date et heure, montant). Le tableau 3 d&#233;taille la composition des
donn&#233;es utilis&#233;es dans ce travail.
</p>
<p>corpus nombre d&#8217;heures source
</p>
<p>entrainement 60h apprentissage ESTER 16h d&#233;veloppement ESTER 2
test 6h test ESTER 2
</p>
<p>TABLE 3 &#8211; D&#233;composition du corpus ESTER 2 pour la t&#226;che d&#8217;annotation en entit&#233;s nomm&#233;es
</p>
<p>La campagne ESTER 2 comporte deux t&#226;ches de reconnaissance d&#8217;entit&#233;s nomm&#233;es qui consistent &#224; recon-
na&#238;tre les entit&#233;s nomm&#233;es, d&#8217;une part, dans la transcription manuelle (man) du corpus de test et, d&#8217;autre
part, dans les trois transcriptions automatiques (aut) du corpus de test dont les taux d&#8217;erreur de mots sont
12.11%, 17.83% et 26.09%. On se place, ici, dans le cas o&#249; la transcription automatique est la plus bruit&#233;e
(i.e. taux d&#8217;erreur de mots de 26.09%).
</p>
<p>4.2 Mesure des performances
</p>
<p>Les performances pour la reconnaissance d&#8217;entit&#233;s nomm&#233;es sont ici &#233;valu&#233;es en terme de slot error rate
(SER) utilis&#233; dans la campagne ESTER 2 [Ester]. Le SER fournit un taux d&#8217;erreur sur l&#8217;ensemble des
entit&#233;s nomm&#233;es de r&#233;f&#233;rence (R) pour lequel on distingue les erreurs d&#8217;insertion (I), de suppression (D)
et de substitution (S). Dans le cas de la substitution, on distingue les erreurs de type (T), d&#8217;extension
(E), de type et d&#8217;extension (TE), ou multiples (M) o&#249; plusieurs hypoth&#232;ses correspondent &#224; une entit&#233; de
r&#233;f&#233;rence. Pour &#233;valuer la mise au point de nos syst&#232;mes, nous utilisons un premier SER d&#233;fini par :
</p>
<p>SER1 =
#I +#D +#S
</p>
<p>#R
</p>
<p>Dans le cadre de la campagne ESTER 2, chaque type d&#8217;erreur est pond&#233;r&#233; par un coefficient suivant son
importance. Il est d&#233;fini par :
</p>
<p>SER2 =
&#945;I .#I + &#945;D.#D + &#945;T .#T + &#945;E .#E + &#945;TE .#TE + &#945;M .#M
</p>
<p>#R
</p>
<p>avec (&#945;I , &#945;D, &#945;T , &#945;E , &#945;TE , &#945;M ) = (1, 1, 0.5, 0.5, 0.7, 0.7).
</p>
<p>La F-mesure en entit&#233;s nomm&#233;es est aussi utilis&#233; pour mesurer les performances lors la mise au point de
nos syst&#232;mes. Elle correspond &#224; la moyenne harmonique entre la pr&#233;cision et le rappel en entit&#233;s nomm&#233;es.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Christian Raymond, Julien Fayolle
</p>
<p>Le SER1 et la F-mesure permettront de comparer les diff&#233;rents syst&#232;mes combin&#233;s aux diff&#233;rents descrip-
teurs utilis&#233;s, tandis que le SER2 permettra de s&#8217;&#233;valuer par rapport aux meilleurs syst&#232;mes de la campagne
ESTER 2.
</p>
<p>5 R&#233;sultats
</p>
<p>5.1 Apport des diff&#233;rents descripteurs
</p>
<p>Afin de mesurer l&#8217;apport des diff&#233;rents descripteurs, on teste quatre cas de syst&#232;me (MOT, MOT+MS,
MOT+MS+AP, et MOT+MS+AP+MI), utilisant progressivement les informations d&#233;crites dans la table 2.
</p>
<p>descripteurs MOT MOT+MS MOT+MS+AP MOT+MS+AP+MI
transcription man man man man
</p>
<p>FST 32.3 (0.77) 31.9 (0.77) 32.2 (0.77) 30.9 (0.78)
SVM 35.1 (0.77) 29.4 (0.80) 29.1 (0.81) 28.9 (0.81)
CRF 41.7 (0.72) 29.8 (0.79) 28.4 (0.80) 28.1 (0.80)
</p>
<p>TABLE 4 &#8211; Performances des &#233;tiqueteurs en SER1 (F-mesure) suivant diff&#233;rents descripteurs
</p>
<p>Les r&#233;sultats (tableau 4) nous montrent l&#8217;influence positive de l&#8217;ajout du deuxi&#232;me niveau de description.
On le voit notamment pour les m&#233;thodes discriminantes (SVM et CRF) o&#249; le gain est significatif lorsqu&#8217;on
ajoute des informations morpho-syntaxiques qui permettent de d&#233;duire des r&#232;gles plus g&#233;n&#233;ralisatrices que
dans le cas des mots seuls. Il est int&#233;ressant de noter que, pour le mod&#232;le FST, l&#8217;ajout de connaissances a
priori d&#233;grade les performances. On peut aussi supposer que l&#8217;inconsistance des annotations (diff&#233;rentes
suivant les deux campagnes ESTER) du corpus d&#8217;apprentissage perturbe les classifieurs, ce qui sera l&#8217;objet
de la partie suivante.
</p>
<p>5.2 Correction des donn&#233;es d&#8217;entra&#238;nement
</p>
<p>En apprentissage automatique (AA), la quantit&#233; de donn&#233;es d&#8217;apprentissage est une notion cruciale. C&#8217;est
pourquoi certains concepteurs privil&#233;gient l&#8217;enrichissement des connaissances au d&#233;triment de leur aspect
qualitatif. Or les m&#233;thodes d&#8217;AA y sont tr&#232;s sensibles. De plus, dans un contexte de transcription de parole,
o&#249; la robustesse est une priorit&#233; et o&#249; les mots &#224; analyser sont limit&#233;s au lexique d&#233;fini par le syst&#232;me de
reconnaissance de la parole, la qualit&#233; de ces donn&#233;es est primordiale. Comme pr&#233;cis&#233; dans la partie 4.1,
l&#8217;ensemble utilis&#233; pour l&#8217;entra&#238;nement des classifieurs est le corpus d&#8217;apprentissage annot&#233; dans le cadre
de la campagne ESTER 1 ainsi que le corpus de d&#233;veloppement annot&#233;, suivant des conventions l&#233;g&#232;rement
diff&#233;rentes, dans le cadre de ESTER 2. Les syst&#232;mes obtenus sont bien s&#251;r plus performants en utilisant
conjointement les deux corpora plut&#244;t que s&#233;par&#233;ment. N&#233;anmoins, l&#8217;incoh&#233;rence des annotations affecte
les performances de ces syst&#232;mes [10]. Il n&#8217;est pas rare de se retrouver dans ce genre de situation et nous
proposons une m&#233;thode pour harmoniser, et rendre les annotations coh&#233;rentes. L&#8217;id&#233;e est de conserver
le syst&#232;me de description le plus performant (MOT+MS+AP+MI) pour le corpus le plus fiable (corpus de
d&#233;veloppement (DEV), annot&#233; suivant les m&#234;mes conventions que le test ESTER 2). Le corpus d&#8217;apprentis-
sage (APP), quant &#224; lui, est d&#233;crit avec les mots ainsi que les &#233;tiquettes morpho-syntaxiques (MOT+MS). Le
premier niveau de description, compos&#233; des mots, va permettre de g&#233;n&#233;rer des r&#232;gles faibles, peu g&#233;n&#233;rali-
santes. Le deuxi&#232;me niveau de description, compos&#233; de (MOT+MS) ou de MOT+MS+AP+MI selon la partie</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Reconnaissance robuste d&#8217;entit&#233;s nomm&#233;es sur de la parole transcrite automatiquement
</p>
<p>consid&#233;r&#233;e des donn&#233;es d&#8217;entra&#238;nement, va permettre de produire des r&#232;gles plus fortes. En utilisant le
syst&#232;me le plus performant (CRF), un mod&#232;le est appris sur la concat&#233;nation des deux corpora. &#192;u corpus
d&#8217;entra&#238;nement sont de nouveau associ&#233;s les niveaux de description les plus efficaces MOT+MS+AP+MI
sur toutes les donn&#233;es. Il est ensuite r&#233;-annot&#233; automatiquement avec le mod&#232;le pr&#233;c&#233;dent. Lors de la r&#233;-
annotation, les annotations de la partie DEV seront reproduites. Sur la partie APP, les r&#232;gles fortes apprises
sur la partie APP ne pourront plus s&#8217;appliquer du fait de la modification du second niveau de description,
seules les r&#232;gles fortes apprises sur la partie DEV vont s&#8217;appliquer. Les r&#232;gles faibles apprises sur la partie
APP vont permettre de r&#233;g&#233;n&#233;rer les annotations sur la partie APP (et donc de conserver la connaissance
incluse dans APP) sauf en cas de contradiction avec les r&#232;gles fortes apprises sur le DEV qui dans ce cas
vont l&#8217;emporter pour proposer une nouvelle annotation plus conforme &#224; la partie DEV. C&#8217;est cette nouvelle
annotation qui servira de r&#233;f&#233;rence &#224; l&#8217;entra&#238;nement de tous les syst&#232;mes.
</p>
<p>Le tableau 5 montre les performances des syst&#232;mes entra&#238;n&#233;s avec ce nouveau jeu d&#8217;annotations. On
constate une am&#233;lioration significative (jusqu&#8217;&#224; 5 points absolu ou environ 20% relatif de gain) des r&#233;sul-
tats par rapport &#224; ceux de la partie pr&#233;c&#233;dente.
</p>
<p>descripteurs MOT MOT+MS MOT+MS+AP MOT+MS+AP+MI
transcription man man man man
</p>
<p>FST 27.3 (0.81) 29.6 (0.80) 29.1 (0.80) 26.6 (0.82)
SVM 32.4 (0.79) 27.4 (0.82) 26.9 (0.83) 26.6 (0.83)
CRF 36.2 (0.76) 24.8 (0.83) 23.4 (0.84) 22.8 (0.84)
</p>
<p>TABLE 5 &#8211; Performances des &#233;tiqueteurs en SER1 (F-mesure) suivant diff&#233;rents descripteurs avec correc-
tion automatique du corpus d&#8217;entra&#238;nement
</p>
<p>5.3 &#201;valuation ESTER 2
</p>
<p>Nous &#233;valuons ici les performances de nos syst&#232;mes sur le jeu de donn&#233;es ESTER 2 en les comparant aux
meilleurs syst&#232;mes de la campagne ESTER 2. Le meilleur syst&#232;me ESTER 2 sur la transcription manuelle
est bas&#233; sur des r&#232;gles de grammaires formelles, not&#233; ref-man, tandis que le meilleur syst&#232;me ESTER 2 sur
la transcription automatique la plus bruit&#233;e (taux d&#8217;erreur de mots de 26.09%) est &#224; base d&#8217;apprentissage
automatique proche de notre approche &#224; base de CRF, not&#233; ref-aut. Un post-traitement simple est appliqu&#233;
sur la sortie des trois syst&#232;mes. Il consiste &#224; appliquer quelques r&#232;gles d&#8217;imbrications d&#8217;entit&#233;s nomm&#233;es
et de correction de segmentation afin de mieux correspondre aux conventions d&#8217;annotation d&#8217;ESTER 2.
</p>
<p>syst&#232;me FST SVM CRF oracle(SVM+CRF) oracle(FST+SVM+CRF) ref-man ref-aut
man 27.89 28.06 22.79 / / 9.80 23.91
aut 59.44 59.83 53.49 50.40 45.80 66.22 56.79
</p>
<p>TABLE 6 &#8211; Performances des &#233;tiqueteurs en SER2 (&#233;valuation ESTER 2)
</p>
<p>Les trois syst&#232;mes que nous pr&#233;sentons obtiennent tous des r&#233;sultats inf&#233;rieurs &#224; 60% en SER2, ce qui
les classerait premier, troisi&#232;me et quatri&#232;me de la campagne ESTER 2 sur les transcriptions les plus
bruit&#233;es. Notre syst&#232;me &#224; base de CRF, proche du meilleur syst&#232;me ref-aut, obtient des performances
sensiblement meilleures gr&#226;ce &#224; notre m&#233;thode d&#8217;am&#233;lioration de la qualit&#233; des annotations (partie 5.2) et
ce bien qu&#8217;aucune ressource autre que celles annot&#233;es durant ESTER n&#8217;ai &#233;t&#233; utilis&#233;es contrairement au
syst&#232;me participant. Outre les avantages respectifs de chaque m&#233;thode, l&#8217;analyse directe des graphes de</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Christian Raymond, Julien Fayolle
</p>
<p>mots pour les FST et la pr&#233;cision des m&#233;thodes discriminantes (CRF et SVM), l&#8217;int&#233;r&#234;t de proposer trois
syst&#232;mes ayant une vue diff&#233;rente du probl&#232;me permettra d&#8217;am&#233;liorer dans de futurs travaux la robustesse
de l&#8217;&#233;tiquetage par des strat&#233;gies de fusion. Le tableau 6 illustre &#224; travers les taux oracles (taux d&#8217;erreur
minimal que ferait une strat&#233;gie qui prend toujours la bonne d&#233;cision) le gain potentiel d&#8217;une telle strat&#233;gie.
</p>
<p>6 Conclusion
</p>
<p>Nous avons pr&#233;sent&#233; dans ce travail trois m&#233;thodes pour la reconnaissance d&#8217;entit&#233;s nomm&#233;es &#224; partir de
transcriptions automatiques de parole ainsi qu&#8217;une m&#233;thode permettant d&#8217;am&#233;liorer automatiquement la
qualit&#233; des annotations d&#8217;un corpus dont les annotations ont &#233;t&#233; effectu&#233;es suivant des conventions l&#233;g&#232;re-
ment diff&#233;rentes. Nous avons montr&#233; que les syst&#232;mes d&#8217;&#233;tiquetage obtenus sont parmi les plus robustes
sur les donn&#233;es d&#8217;&#233;valuation de la campagne ESTER 2 dans les conditions o&#249; la transcription automatique
est particuli&#232;rement bruit&#233;e (taux d&#8217;erreur de mots de 26.09%). Le syst&#232;me &#224; base de CRF obtient les
meilleures performances. Bien que moins performante, la m&#233;thode &#224; base de SVM offre tout de m&#234;me une
distribution des erreurs diff&#233;rentes. La m&#233;thode &#224; base de FST poss&#232;de l&#8217;avantage de pouvoir &#234;tre coupl&#233;e
efficacement avec les syst&#232;mes de reconnaissance de la parole et sera &#233;valu&#233;e prochainement dans ces
conditions. Enfin, l&#8217;&#233;valuation oracle montre que les trois syst&#232;mes offrent des r&#233;sultats compl&#233;mentaires
que nous comptons combiner gr&#226;ce &#224; des m&#233;thodes de fusion pour am&#233;liorer les performances.
</p>
<p>R&#233;f&#233;rences
</p>
<p>[1] BRUN C. &amp; EHRMANN M. (2009). Adaptation of a named entity recognition system for the ester 2
evaluation campaign. In IEEE NLP-KE, Dalian, Chine.
</p>
<p>[Ester] ESTER. Conventions et plans d&#8217;&#233;valuation des campagnes ester. Disponible sur Internet &#224; l&#8217;adresse
http://www.afcp-parole.org/ester/docs.html.
</p>
<p>[3] FAVRE B., B&#201;CHET F. &amp; NOC&#201;RA P. (2005). Robust named entity extraction from spoken archives.
In HLT-EMNLP&#8217;05.
</p>
<p>[4] HUET S., GRAVIER G. &amp; S&#201;BILLOT P. (2008). Morphosyntactic resources for automatic speech
recognition. In LREC&#8217;08, Marrakech, Maroc.
</p>
<p>[5] ISOZAKI H. &amp; KAZAWA H. (2002). Efficient support vector classifiers for named entity recognition.
In COLING.
</p>
<p>[6] KUDO T. &amp; MATSUMOTO Y. (2001). Chunking with support vector machines. In NAACL&#8217;01, p. 1&#8211;8.
[7] LAFFERTY J., MCCALLUM A. &amp; PEREIRA F. (2001). Conditional random fields : Probabilistic
</p>
<p>models for segmenting and labeling sequence data. In ICML&#8217;01, p. 282&#8211;289.
[8] MCCALLUM A. &amp; LI W. (2003). Early results for named entity recognition with conditional random
</p>
<p>fields, feature induction and web-enhanced lexicons. In CoNLL-2003, p. 188&#8211;191.
[9] MOHRI M., PEREIRA F. &amp; RILEY M. (1997). AT&amp;T FSM Library - Finite State Machine Library.
</p>
<p>Rapport interne, AT&amp;T.
[10] RAYMOND C. &amp; RICCARDI G. (2007). Generative and discriminative algorithms for spoken lan-
</p>
<p>guage understanding. In Interspeech, Anvers, Belgique.
[11] VAPNIK V. N. (1995). The nature of statistical learning theory. Springer-Verlag New York, Inc.</p>

</div></div>
</body></html>