<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C BRUN</author>
<author>M EHRMANN</author>
</authors>
<title>Adaptation of a named entity recognition system for the ester 2 evaluation campaign.</title>
<date>2009</date>
<booktitle>In IEEE NLP-KE,</booktitle>
<location>Dalian, Chine.</location>
<contexts>
<context position="4281" citStr="[1]" startWordPosition="589" endWordPosition="589">recherche primordial afin d’utiliser et d’exploiter le maximum d’information contenu dans le flux audio. Parmi ces contenus à valeur ajoutée, sont souvent considérées les entités nommées. La plupart des systèmes d’étiquetage en entités nommées utilisent des méthodes symboliques à base de grammaires formelles, éventuellement complétées par des connaissances a priori (e.g. listes de prénoms, de villes ou de pays). Dans les grandes campagnes d’évaluation, ces systèmes implémentés manuellement obtiennent les meilleurs résultats sur le texte propre (texte ou transcription manuelle de parole) (voir [1] pour la campagne ESTER 2). Lorsque la reconnaissance d’entités nommées se fait sur des transcriptions automatiques de parole, le problème gagne en difficulté car contrairement aux documents textuels, les documents transcrits automatiquement ne sont pas structurés (ni casse, ni ponctuation) et certains mots transcrits sont erronés : le taux d’erreur de mots peut varier de 5% à plus de 50% selon le document et les conditions de transcriptions. Dans ces conditions, les systèmes symboliques sont généralement moins robustes que des étiqueteurs basés sur des méthodes d’apprentissage automatique, no</context>
</contexts>
<marker>[1]</marker>
<rawString>BRUN C. &amp; EHRMANN M. (2009). Adaptation of a named entity recognition system for the ester 2 evaluation campaign. In IEEE NLP-KE, Dalian, Chine.</rawString>
</citation>
<citation valid="false">
<authors>
<author>ESTER</author>
</authors>
<title>Conventions et plans d’évaluation des campagnes ester. Disponible sur Internet à l’adresse http://www.afcp-parole.org/ester/docs.html.</title>
<contexts>
<context position="18749" citStr="[Ester]" startWordPosition="2815" endWordPosition="2815">struits sur les couples symbole/position dans une fenêtre [−2,+2] autour de la position de décision. 1. Disponible sur Internet à l’adresse http://crfpp.sourceforge.net/ Reconnaissance robuste d’entités nommées sur de la parole transcrite automatiquement 4 Conditions expérimentales 4.1 Corpus et tâches ESTER 2 Le corpus ESTER 2 relatif aux entités nommées se composent de 72 heures d’émissions radiophoniques francophones (France-Inter, France Info, RFI, RTM, France Culture, Radio Classique) manuellement transcrites et annotées en entités nommées suivant les conventions des deux campagnes ESTER [Ester] qui sont légèrement différentes. La première campagne comporte un jeu de 30 types d’entités nommées réparties en 9 catégories principales (personne, organisation, groupe géo-socio-politique, lieu, bâtiment et construction humaine, production humaine, date et heure, montant, inconnue), alors que la seconde possède un jeu de 37 types d’entités nommées réparties en 7 catégories principales (personne, fonction, organisation, lieu, production humaine, date et heure, montant). Le tableau 3 détaille la composition des données utilisées dans ce travail. corpus nombre d’heures source entrainement 60h </context>
<context position="20145" citStr="[Ester]" startWordPosition="3026" endWordPosition="3026">tâches de reconnaissance d’entités nommées qui consistent à reconnaître les entités nommées, d’une part, dans la transcription manuelle (man) du corpus de test et, d’autre part, dans les trois transcriptions automatiques (aut) du corpus de test dont les taux d’erreur de mots sont 12.11%, 17.83% et 26.09%. On se place, ici, dans le cas où la transcription automatique est la plus bruitée (i.e. taux d’erreur de mots de 26.09%). 4.2 Mesure des performances Les performances pour la reconnaissance d’entités nommées sont ici évaluées en terme de slot error rate (SER) utilisé dans la campagne ESTER 2 [Ester]. Le SER fournit un taux d’erreur sur l’ensemble des entités nommées de référence (R) pour lequel on distingue les erreurs d’insertion (I), de suppression (D) et de substitution (S). Dans le cas de la substitution, on distingue les erreurs de type (T), d’extension (E), de type et d’extension (TE), ou multiples (M) où plusieurs hypothèses correspondent à une entité de référence. Pour évaluer la mise au point de nos systèmes, nous utilisons un premier SER défini par : #I +#D +#S SER1 = #R Dans le cadre de la campagne ESTER 2, chaque type d’erreur est pondéré par un coefficient suivant son import</context>
</contexts>
<marker>[Ester]</marker>
<rawString>ESTER. Conventions et plans d’évaluation des campagnes ester. Disponible sur Internet à l’adresse http://www.afcp-parole.org/ester/docs.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B FAVRE</author>
<author>F BÉCHET</author>
<author>P NOCÉRA</author>
</authors>
<title>Robust named entity extraction from spoken archives.</title>
<date>2005</date>
<booktitle>In HLT-EMNLP’05.</booktitle>
<contexts>
<context position="5303" citStr="[8, 5, 3]" startWordPosition="734" endWordPosition="736">les conditions de transcriptions. Dans ces conditions, les systèmes symboliques sont généralement moins robustes que des étiqueteurs basés sur des méthodes d’apprentissage automatique, notamment car elles sont capables d’extraire de ces données des règles de décision qu’un expert humain n’aurait pu appréhender. Guidés par cette notion de robustesse face aux transcriptions automatiques, nous présentons trois systèmes d’étiquetage basés sur différents algorithmes de classification automatique qui ont déjà fait leurs preuves dans la tâche de reconnaissance en entités nommées (voir respectivement [8, 5, 3]), un système à base de champs conditionnels aléatoires (CRF), un à base de machines à vecteurs de support (SVM), et un à base de transducteurs à états finis (FST). Dans la partie 2, nous présentons l’approche générale utilisée en reconnaissance d’entités nommées par des méthodes à base d’apprentissage automatique. Seront ensuite présentées dans la partie 3, les méthodes d’apprentissage utilisées dans ce travail. Enfin, la partie 4 présentera les données d’évaluations et la partie 5 les expériences effectuées ainsi que les résultats obtenus. 2 Reconnaissance d’entités nommées La reconnaissance</context>
<context position="12606" citStr="[3]" startWordPosition="1850" endWordPosition="1850"> et a été choisi pour l’implémentation de l’étiqueteur SVM. Dans ce travail, le vecteur de chaque exemple est composé des couples mots ou/et classes associés à leur position par rapport à la position de décision dans un intervalle local [−2,+2] (figure 1). 3.2 Transducteurs à états finis L’approche à base de transducteurs à états finis est une approche générative stochastique basée sur le calcul de la probabilité jointe entre la séquence d’observations (mots) et la séquence d’étiquettes (entités nommées). Cette approche est particulièrement appropriée pour traiter des transcriptions de parole [3] puisqu’elle est basée sur le même paradigme traditionnellement utilisée dans les systèmes de reconnaissance automatique de la parole. Plus formellement, notons e = e1, e2, . . . , eN la séquence d’étiquettes associées à la séquence de mots m = m1,m2, . . . ,mN produite par un système de reconnaissance automatique de la parole. Le processus d’étiquetage consiste à trouver la séquence d’étiquettes maximisant la Reconnaissance robuste d’entités nommées sur de la parole transcrite automatiquement probabilité a posteriori p(e|A), où A représente les observations acoustiques extraites du signal de </context>
</contexts>
<marker>[3]</marker>
<rawString>FAVRE B., BÉCHET F. &amp; NOCÉRA P. (2005). Robust named entity extraction from spoken archives. In HLT-EMNLP’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S HUET</author>
<author>G GRAVIER</author>
<author>P SÉBILLOT</author>
</authors>
<title>Morphosyntactic resources for automatic speech recognition.</title>
<date>2008</date>
<booktitle>In LREC’08,</booktitle>
<location>Marrakech, Maroc.</location>
<contexts>
<context position="8492" citStr="[4]" startWordPosition="1219" endWordPosition="1219">i améliorer le rappel du système, ou bien des connaissances a priori fortes peuvent être intégrées pour améliorer la précision ainsi que le rappel. niveau type exemple premier MOT : mot &amp;quot;Jacques&amp;quot; MS : étiquette morpho-syntaxique &amp;quot;NPMS&amp;quot;, nom propre masculin singulier second AP : classe connu a priori &amp;quot;VILLE&amp;quot; MI : mot &amp;quot;important&amp;quot; &amp;quot;numéro&amp;quot; TABLE 2 – Niveaux de description Ici, deux niveaux de description (table 2) sont utilisés. Le premier est directement composé des mots (MOT) de la transcription et le second peut être des trois types suivants : – MS : résultat d’un étiquetage morpho-syntaxique [4], – AP : classe de généralisation correspondant à des connaissances connues a priori, i.e. listes de pays, de villes, de gentilés, d’unités de mesure, – MI : mot &amp;quot;important&amp;quot; dont l’information mutuelle partagée avec son étiquette d’entité nommée est supérieure à zéro (i.e. mot supposé plus discriminant qu’une étiquette morpho-syntaxique) et qui apparaît au moins trente fois dans le corpus d’apprentissage (i.e. mot à capacité de généralisation suffisante). Comme illustré sur la figure 1, l’étiquette courante est estimée à partir des descripteurs (mots et classes) situés dans la fenêtre locale [</context>
</contexts>
<marker>[4]</marker>
<rawString>HUET S., GRAVIER G. &amp; SÉBILLOT P. (2008). Morphosyntactic resources for automatic speech recognition. In LREC’08, Marrakech, Maroc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H ISOZAKI</author>
<author>H KAZAWA</author>
</authors>
<title>Efficient support vector classifiers for named entity recognition.</title>
<date>2002</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="5303" citStr="[8, 5, 3]" startWordPosition="734" endWordPosition="736">les conditions de transcriptions. Dans ces conditions, les systèmes symboliques sont généralement moins robustes que des étiqueteurs basés sur des méthodes d’apprentissage automatique, notamment car elles sont capables d’extraire de ces données des règles de décision qu’un expert humain n’aurait pu appréhender. Guidés par cette notion de robustesse face aux transcriptions automatiques, nous présentons trois systèmes d’étiquetage basés sur différents algorithmes de classification automatique qui ont déjà fait leurs preuves dans la tâche de reconnaissance en entités nommées (voir respectivement [8, 5, 3]), un système à base de champs conditionnels aléatoires (CRF), un à base de machines à vecteurs de support (SVM), et un à base de transducteurs à états finis (FST). Dans la partie 2, nous présentons l’approche générale utilisée en reconnaissance d’entités nommées par des méthodes à base d’apprentissage automatique. Seront ensuite présentées dans la partie 3, les méthodes d’apprentissage utilisées dans ce travail. Enfin, la partie 4 présentera les données d’évaluations et la partie 5 les expériences effectuées ainsi que les résultats obtenus. 2 Reconnaissance d’entités nommées La reconnaissance</context>
</contexts>
<marker>[5]</marker>
<rawString>ISOZAKI H. &amp; KAZAWA H. (2002). Efficient support vector classifiers for named entity recognition. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T KUDO</author>
<author>Y MATSUMOTO</author>
</authors>
<title>Chunking with support vector machines.</title>
<date>2001</date>
<booktitle>In NAACL’01,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="12003" citStr="[6]" startWordPosition="1758" endWordPosition="1758">er sa classe. Bien que les SVM permettent l’utilisation de paramètres très variés, contrairement aux algorithmes spécifiquement connus pour l’étiquetage séquentiel, ils ne peuvent prendre de décision globale sur la séquence car chaque étiquette de la séquence est vue indépendamment des autres. Toutefois, certaines heuristiques peuvent être implémentées, par l’exemple l’ajout d’un paramètre de classification qui serait la décision pré- cédente dans la séquence. YAMCHA, un système basé sur cette approche, a obtenu les meilleurs résultats dans la tâche de chunking et BaseNP chunking de CoNLL2000 [6] et a été choisi pour l’implémentation de l’étiqueteur SVM. Dans ce travail, le vecteur de chaque exemple est composé des couples mots ou/et classes associés à leur position par rapport à la position de décision dans un intervalle local [−2,+2] (figure 1). 3.2 Transducteurs à états finis L’approche à base de transducteurs à états finis est une approche générative stochastique basée sur le calcul de la probabilité jointe entre la séquence d’observations (mots) et la séquence d’étiquettes (entités nommées). Cette approche est particulièrement appropriée pour traiter des transcriptions de parole </context>
</contexts>
<marker>[6]</marker>
<rawString>KUDO T. &amp; MATSUMOTO Y. (2001). Chunking with support vector machines. In NAACL’01, p. 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J LAFFERTY</author>
<author>A MCCALLUM</author>
<author>F PEREIRA</author>
</authors>
<title>Conditional random fields : Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In ICML’01,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="16408" citStr="[7]" startWordPosition="2464" endWordPosition="2464">s couples classe/entité, les classes peuvent être le résultat d’un étiquetage morpho-syntaxique ou/et des classes représentant des connaissances a priori sur les mots (e.g. liste de pays, de ville) ou/et les mots eux-mêmes. Le transducteur possède alors en entrée les mots et en sortie les couples classe/entité. Les scores associés aux transitions encodent p(m|c, e) dans la formule 1 et sont calculés selon 2 ; 3. λce encode le modèle estimant la probabilité jointe étiquette/entité décrite dans la formule 4. 3.3 Champs Conditionnels Aléatoires Les champs conditionnels aléatoires, introduits par [7], possèdent les avantages des modèles génératifs et discriminants. Comme les classifieurs discriminants, ils peuvent manipuler un grand nombre de descripteurs et comme les modèles génératifs, ils intègrent des dépendances entre les étiquettes de sortie et prennent une décision globale sur la séquence. Cependant, ils ne sont pas facilement intégrables avec le système de reconnaissance automatique de la parole (e.g. analyse d’un graphe de mots). Un champ conditionnel aléatoire est défini par un graphe de dépendances et un ensemble de fonctions fk auxquelles sont associées des poids λk. La probab</context>
</contexts>
<marker>[7]</marker>
<rawString>LAFFERTY J., MCCALLUM A. &amp; PEREIRA F. (2001). Conditional random fields : Probabilistic models for segmenting and labeling sequence data. In ICML’01, p. 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A MCCALLUM</author>
<author>W LI</author>
</authors>
<title>Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons.</title>
<date>2003</date>
<booktitle>In CoNLL-2003,</booktitle>
<pages>188--191</pages>
<contexts>
<context position="5303" citStr="[8, 5, 3]" startWordPosition="734" endWordPosition="736">les conditions de transcriptions. Dans ces conditions, les systèmes symboliques sont généralement moins robustes que des étiqueteurs basés sur des méthodes d’apprentissage automatique, notamment car elles sont capables d’extraire de ces données des règles de décision qu’un expert humain n’aurait pu appréhender. Guidés par cette notion de robustesse face aux transcriptions automatiques, nous présentons trois systèmes d’étiquetage basés sur différents algorithmes de classification automatique qui ont déjà fait leurs preuves dans la tâche de reconnaissance en entités nommées (voir respectivement [8, 5, 3]), un système à base de champs conditionnels aléatoires (CRF), un à base de machines à vecteurs de support (SVM), et un à base de transducteurs à états finis (FST). Dans la partie 2, nous présentons l’approche générale utilisée en reconnaissance d’entités nommées par des méthodes à base d’apprentissage automatique. Seront ensuite présentées dans la partie 3, les méthodes d’apprentissage utilisées dans ce travail. Enfin, la partie 4 présentera les données d’évaluations et la partie 5 les expériences effectuées ainsi que les résultats obtenus. 2 Reconnaissance d’entités nommées La reconnaissance</context>
</contexts>
<marker>[8]</marker>
<rawString>MCCALLUM A. &amp; LI W. (2003). Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons. In CoNLL-2003, p. 188–191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M MOHRI</author>
<author>F PEREIRA</author>
<author>M RILEY</author>
</authors>
<date>1997</date>
<booktitle>AT&amp;T FSM Library - Finite State Machine Library. Rapport interne, AT&amp;T.</booktitle>
<contexts>
<context position="15120" citStr="[9]" startWordPosition="2263" endWordPosition="2263">e du troisième ordre :N p(c, e) = p(cn, tn|hn) (3) n=1 avec hn = (cn−1, tn−1), (cn−2, tn−2) Le processus d’étiquetage est généralement effectué pour une séquence de mots m fixée (i.e. la meilleure hypothèse de transcription automatique). L’originalité de cette approche est de pouvoir s’intégrer directement dans le processus de reconnaissance automatique de la parole. En effet, elle permet de réaliser l’étiquetage directement sur des graphes de mots, à condition que ceux-ci soient encodés comme des automates à états finis. L’implémentation de cette approche a été réalisé avec la librairie AT&amp;T [9]. La meilleure séquence de couples mot/étiquette est le meilleur chemin dans le transducteur λm2e obtenu par composition de trois transducteurs : λm2e = λm ◦ λm2ce ◦ λce Les trois transducteurs sont définis de la manière suivante : Christian Raymond, Julien Fayolle 1. λm est la représentation de l’entrée à étiqueter sous forme d’automate à états finis (hypothèse ou graphe de mots généré par le moteur de reconnaissance de la parole avec les scores acoustiques, p(A|m) dans la formule 1). Dans les expériences suivantes, dans le but de rester comparable avec les autres méthodes, λm encode la meill</context>
</contexts>
<marker>[9]</marker>
<rawString>MOHRI M., PEREIRA F. &amp; RILEY M. (1997). AT&amp;T FSM Library - Finite State Machine Library. Rapport interne, AT&amp;T.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C RAYMOND</author>
<author>G RICCARDI</author>
</authors>
<title>Generative and discriminative algorithms for spoken language understanding.</title>
<date>2007</date>
<journal>In Interspeech, Anvers, Belgique.</journal>
<contexts>
<context position="23627" citStr="[10]" startWordPosition="3577" endWordPosition="3577">limités au lexique défini par le système de reconnaissance de la parole, la qualité de ces données est primordiale. Comme précisé dans la partie 4.1, l’ensemble utilisé pour l’entraînement des classifieurs est le corpus d’apprentissage annoté dans le cadre de la campagne ESTER 1 ainsi que le corpus de développement annoté, suivant des conventions légèrement différentes, dans le cadre de ESTER 2. Les systèmes obtenus sont bien sûr plus performants en utilisant conjointement les deux corpora plutôt que séparément. Néanmoins, l’incohérence des annotations affecte les performances de ces systèmes [10]. Il n’est pas rare de se retrouver dans ce genre de situation et nous proposons une méthode pour harmoniser, et rendre les annotations cohérentes. L’idée est de conserver le système de description le plus performant (MOT+MS+AP+MI) pour le corpus le plus fiable (corpus de développement (DEV), annoté suivant les mêmes conventions que le test ESTER 2). Le corpus d’apprentissage (APP), quant à lui, est décrit avec les mots ainsi que les étiquettes morpho-syntaxiques (MOT+MS). Le premier niveau de description, composé des mots, va permettre de générer des règles faibles, peu généralisantes. Le deu</context>
</contexts>
<marker>[10]</marker>
<rawString>RAYMOND C. &amp; RICCARDI G. (2007). Generative and discriminative algorithms for spoken language understanding. In Interspeech, Anvers, Belgique.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V N VAPNIK</author>
</authors>
<title>The nature of statistical learning theory.</title>
<date>1995</date>
<publisher>Springer-Verlag</publisher>
<location>New York, Inc.</location>
<contexts>
<context position="9613" citStr="[11]" startWordPosition="1391" endWordPosition="1391">estimée à partir des descripteurs (mots et classes) situés dans la fenêtre locale [−2,+2] entourant la position 0 de décision. On y retrouve les trois types de classe du second niveau de description, à savoir les étiquettes morpho-syntaxiques en rouge, les classes connues a priori en bleu, et les mots &amp;quot;importants&amp;quot; en vert. FIGURE 1 – Exemple d’étiquetage en entités nommées à partir des descripteurs de premier et second niveaux Christian Raymond, Julien Fayolle 3 Algorithmes d’apprentissage automatique 3.1 Machines à vecteurs de support Les machines à vecteurs de support introduites par Vapnik [11], couramment abrégées en SVM sont des classifieurs discriminants à large marge. Les SVM sont au départ des classifieurs binaires qui représentent les échantillons à classer sous la forme d’un vecteur dont chaque composante représente la contribution d’un paramètre à un exemple. Par exemple, pour une tâche de classification de documents les vecteurs représentant chaque document pourraient avoir la taille du vocabulaire associé aux documents et chaque composante du vecteur serait nulle ou non nulle selon que le mot correspondant est absent ou non du document en question. Le principe est alors de</context>
</contexts>
<marker>[11]</marker>
<rawString>VAPNIK V. N. (1995). The nature of statistical learning theory. Springer-Verlag New York, Inc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>