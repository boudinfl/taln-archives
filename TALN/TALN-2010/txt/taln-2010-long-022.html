<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Utilisation de relations s&#233;mantiques pour am&#233;liorer la segmentation th&#233;matique de documents t&#233;l&#233;visuels</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>Utilisation de relations s&#233;mantiques pour am&#233;liorer la segmentation
th&#233;matique de documents t&#233;l&#233;visuels&#8727;
</p>
<p>Camille Guinaudeau1 Guillaume Gravier2 Pascale S&#233;billot3
</p>
<p>INRIA Rennes1 &amp; IRISA (CNRS2, INSA3), France
camille.guinaudeau@irisa.fr, guillaume.gravier@irisa.fr, pascale.sebillot@irisa.fr
</p>
<p>R&#233;sum&#233;. Les m&#233;thodes de segmentation th&#233;matique exploitant une mesure de la coh&#233;sion lexicale
peuvent &#234;tre appliqu&#233;es telles quelles &#224; des transcriptions automatiques de programmes t&#233;l&#233;visuels. Ce-
pendant, elles sont moins efficaces dans ce contexte, ne prenant en compte ni les particularit&#233;s des &#233;mis-
sions TV, ni celles des transcriptions. Nous &#233;tudions ici l&#8217;apport de relations s&#233;mantiques pour rendre les
techniques de segmentation th&#233;matique plus robustes. Nous proposons une m&#233;thode pour exploiter ces
relations dans une mesure de la coh&#233;sion lexicale et montrons qu&#8217;elles permettent d&#8217;augmenter la F1-
mesure de +1.97 et +11.83 sur deux corpus compos&#233;s respectivement de 40h de journaux t&#233;l&#233;vis&#233;s et de
40h d&#8217;&#233;missions de reportage. Ces am&#233;liorations d&#233;montrent que les relations s&#233;mantiques peuvent rendre
les m&#233;thodes de segmentation moins sensibles aux erreurs de transcription et au manque de r&#233;p&#233;titions
constat&#233; dans certaines &#233;missions t&#233;l&#233;vis&#233;es.
</p>
<p>Abstract. Topic segmentation methods based on a measure of the lexical cohesion can be applied
as is to automatic transcripts of TV programs. However, these methods are less effective in this context as
neither the specificities of TV contents, nor those of automatic transcripts are considered. The aim of this
paper is to study the use of semantic relations to make segmentation techniques more robust. We propose a
method to account for semantic relations in a measure of the lexical cohesion. We show that such relations
increase the F1-measure by +1.97 and +11.83 for two data sets consisting of respectively 40h of news
and 40h of longer reports on current affairs. These results demonstrate that semantic relations can make
segmentation methods less sensitive to transcription errors or to the lack of repetitions in some television
programs.
</p>
<p>Mots-cl&#233;s : Segmentation th&#233;matique, documents oraux, coh&#233;sion lexicale, relations s&#233;mantiques.
</p>
<p>Keywords: Topic segmentation, spoken document, lexical cohesion, semantic relations.
</p>
<p>&#8727; Travaux partiellement financ&#233;s par le projet Quaero.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CAMILLE GUINAUDEAU, GUILLAUME GRAVIER, PASCALE S&#201;BILLOT
</p>
<p>1 Introduction
Les travaux pr&#233;sent&#233;s dans cet article se placent dans le contexte de la structuration automatique de flux
t&#233;l&#233;visuels et, plus particuli&#232;rement, dans ce que l&#8217;on peut consid&#233;rer comme la premi&#232;re &#233;tape n&#233;cessaire
&#224; cette structuration : la segmentation. Afin de permettre aux utilisateurs de naviguer de fa&#231;on non lin&#233;aire
&#224; l&#8217;int&#233;rieur d&#8217;un document t&#233;l&#233;vis&#233;, il est en effet essentiel de d&#233;couper ce flux en &#233;missions d&#8217;une part,
et d&#8217;extraire de ces &#233;missions des segments th&#233;matiquement coh&#233;rents d&#8217;autre part.
</p>
<p>La segmentation de documents t&#233;l&#233;visuels quelconques ne pouvant s&#8217;appuyer sur l&#8217;utilisation des seuls
indices audio disponibles &#8211; aucune m&#233;thode fond&#233;e sur ces derniers ne fournissant de r&#233;sultats satisfai-
sants &#8211; la prise en compte d&#8217;indices alternatifs (textuels ou vid&#233;o) appara&#238;t n&#233;cessaire. Les performances
des syst&#232;mes de reconnaissance de la parole (RAP) s&#8217;&#233;tant consid&#233;rablement am&#233;lior&#233;es ces derni&#232;res
ann&#233;es (Ostendorf et al., 2008), la segmentation th&#233;matique de documents oraux peut d&#233;sormais s&#8217;effec-
tuer par le biais des transcriptions automatiques. La plupart des travaux d&#233;velopp&#233;s en ce sens appliquent
g&#233;n&#233;ralement sur ces transcriptions des m&#233;thodes issues de la segmentation de documents textuels, tr&#232;s
fr&#233;quemment fond&#233;es sur la notion de coh&#233;sion lexicale. Ainsi (Mulbregt et al., 1999) et (Utiyama &amp;
Isahara, 2001) proposent respectivement une technique utilisant un mod&#232;le de Markov cach&#233; et une m&#233;-
thode consistant &#224; rechercher la meilleure segmentation parmi toutes les segmentations possibles. Des
marqueurs discursifs, obtenus lors d&#8217;une phase pr&#233;alable d&#8217;apprentissage, peuvent aussi servir &#224; rep&#233;rer
des fronti&#232;res th&#233;matiques ((Beeferman et al., 1999) et (Christensen et al., 2005)). Cependant, lors de
pr&#233;c&#233;dents travaux sur la segmentation d&#8217;&#233;missions radiophoniques par une approche non supervis&#233;e fon-
d&#233;e sur la coh&#233;sion lexicale, nous avons constat&#233; un gros &#233;cart de performances entre les segmentations
de transcriptions manuelles et automatiques. En effet, les transcriptions automatiques poss&#232;dent certaines
particularit&#233;s. Premi&#232;rement, ces donn&#233;es ne contiennent ni ponctuation ni majuscule ; elles ne sont donc
pas structur&#233;es en phrases comme un texte classique mais en unit&#233;s appel&#233;es groupes de souffle, qui cor-
respondent &#224; la parole prononc&#233;e par un locuteur entre deux respirations. De plus, le taux d&#8217;erreur de notre
syst&#232;me de RAP, m&#234;me s&#8217;il reste raisonnable sur des &#233;missions comme les journaux t&#233;l&#233;vis&#233;s (JT), peut
atteindre 70% pour des &#233;missions telles que des films ou des talk shows, rendant impossible l&#8217;utilisation
de certains indices tels que les marqueurs discursifs. Ces &#233;carts de performances sont d&#251;s &#224; la qualit&#233;
de l&#8217;enregistrement &#8211; enregistrement studio ou ext&#233;rieur &#8211;, &#224; la pr&#233;sence ou non de bruits de fond, d&#8217;ap-
plaudissements, &#224; la diff&#233;rence de style de parole. Enfin, les &#233;missions t&#233;l&#233;visuelles sont compos&#233;es de
segments th&#233;matiques pouvant &#234;tre tr&#232;s courts, contenant peu de r&#233;p&#233;titions de vocabulaire (notamment
au sein des journaux t&#233;l&#233;vis&#233;s) et dans lesquels le niveau de langage peut &#234;tre tr&#232;s variable (alternance
pr&#233;sentateur/interview). Nous souhaitons donc adapter les m&#233;thodes de segmentation th&#233;matique fond&#233;es
sur la coh&#233;sion lexicale &#224; ces donn&#233;es particuli&#232;res.
</p>
<p>Pour pallier les difficult&#233;s li&#233;es aux erreurs de transcription, certains travaux ont propos&#233; d&#8217;ajouter &#224; la
seule notion de coh&#233;sion lexicale des indices propres aux documents oraux. Par exemple, (Amaral &amp;
Trancoso, 2003) exploite la d&#233;tection de locuteur afin de rep&#233;rer le pr&#233;sentateur du journal t&#233;l&#233;vis&#233;, celui-
ci introduisant de nouveaux reportages et donc les changements th&#233;matiques. Conjointement &#224; la trans-
cription, les auteurs de (Stolcke et al., 1999) utilisent quant &#224; eux la prosodie. Cependant de tels indices
sont globalement peu employ&#233;s car leur extraction automatique est difficile. De plus, ils permettent uni-
quement de rem&#233;dier aux erreurs de transcription et ne traitent en rien le manque de r&#233;p&#233;titions inh&#233;rent
&#224; un corpus t&#233;l&#233;visuel. Pour rendre la segmentation th&#233;matique plus robuste aux sp&#233;cificit&#233;s des transcrip-
tions automatiques d&#8217;&#233;missions t&#233;l&#233;vis&#233;es, l&#8217;utilisation de relations s&#233;mantiques nous semble pertinente,
un mot mal transcrit ayant peu de chance d&#8217;&#234;tre li&#233; s&#233;mantiquement aux autres mots du segment. Certains
travaux, comme (Ferret, 2002), ont int&#233;gr&#233; dans le pass&#233; des relations s&#233;mantiques dans des m&#233;thodes
de segmentation de l&#8217;&#233;crit inspir&#233;es de TextTiling (Hearst, 1997), c&#8217;est-&#224;-dire bas&#233;es sur la d&#233;tection de</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UTILISATION DE RELATIONS S&#201;MANTIQUES POUR LA SEGMENTATION TH&#201;MATIQUE
</p>
<p>ruptures de la coh&#233;sion au sein d&#8217;une fen&#234;tre glissante. Cependant, la m&#233;thode propos&#233;e dans (Utiyama
&amp; Isahara, 2001), fond&#233;e sur une mesure de la coh&#233;sion lexicale d&#8217;un segment plut&#244;t que sur la d&#233;tec-
tion de ruptures, donne de meilleurs r&#233;sultats pour la segmentation de documents oraux. Nous proposons
donc ici une technique originale pour introduire des relations s&#233;mantiques dans la m&#233;thode de calcul de
la coh&#233;sion lexicale d&#233;crite dans (Utiyama &amp; Isahara, 2001). Nous exploitons cette int&#233;gration dans deux
m&#233;thodes de segmentation th&#233;matique, l&#8217;une globale, l&#8217;autre locale. Ces techniques, test&#233;es sur deux cor-
pus oraux compos&#233;s de documents t&#233;l&#233;visuels transcrits d&#8217;une dur&#233;e globale de 80 heures (40 heures de
JT et 40 heures d&#8217;&#233;missions de reportages), permettent de d&#233;couper nos donn&#233;es en segments th&#233;matiques
compos&#233;s des reportages &#233;ventuellement pr&#233;c&#233;d&#233;s d&#8217;un plateau de lancement. Les deux corpus utilis&#233;s
constituent &#224; notre connaissance le plus gros volume de donn&#233;es t&#233;l&#233;visuelles test&#233; jusqu&#8217;&#224; pr&#233;sent.
</p>
<p>Dans cet article, nous pr&#233;sentons le calcul de la coh&#233;sion lexicale, d&#8217;abord sans, puis avec prise en compte
des relations s&#233;mantiques, avant de d&#233;crire, en section 3, les algorithmes de segmentation que nous uti-
lisons pour traiter nos corpus. Le choix des relations &#224; int&#233;grer constituant un probl&#232;me majeur &#8211; elles
peuvent, en effet, &#234;tre s&#233;lectionn&#233;es de diff&#233;rentes fa&#231;ons, en ne conservant que les relations correspon-
dant aux forces d&#8217;association entre mots les plus &#233;lev&#233;es par exemple ou en ne retenant qu&#8217;un nombre
fixe de relations par mot &#8211; nous exposons, dans la quatri&#232;me partie, les techniques retenues d&#8217;acquisition
et de s&#233;lection des relations s&#233;mantiques. Nous testons l&#8217;int&#233;gration des relations sur nos deux corpus et
d&#233;crivons les r&#233;sultats de ces exp&#233;riences en section 5, avant la pr&#233;sentation de quelques perspectives.
</p>
<p>2 Mesure de coh&#233;sion lexicale...
Le crit&#232;re de coh&#233;sion lexicale fait r&#233;f&#233;rence aux relations lexicales qui existent au sein d&#8217;un texte et lui
donnent une certaine unit&#233;. Les m&#233;thodes de segmentation, utilisant cette notion pour d&#233;couper un texte
en segments pr&#233;sentant une homog&#233;n&#233;it&#233; du point de vue de leurs th&#232;mes, se fondent sur l&#8217;analyse de
la distribution des mots au sein du texte pour d&#233;tecter des ruptures ou, de mani&#232;re duale, des segments
homog&#232;nes. Nous pr&#233;sentons, dans cette partie, une technique de mesure de la coh&#233;sion lexicale pour la
segmentation de documents textuels, ainsi que la m&#233;thode que nous utilisons pour int&#233;grer des relations
s&#233;mantiques afin de rendre ce crit&#232;re plus robuste aux particularit&#233;s de donn&#233;es t&#233;l&#233;visuelles transcrites,
en particulier le manque de r&#233;p&#233;titions et les erreurs de transcription.
</p>
<p>2.1 sans prise en compte des relations s&#233;mantiques
</p>
<p>Dans (Utiyama &amp; Isahara, 2001), les auteurs pr&#233;sentent une m&#233;thode de mesure de la coh&#233;sion lexicale
fond&#233;e sur le calcul d&#8217;une probabilit&#233; g&#233;n&#233;ralis&#233;e. La valeur de la coh&#233;sion lexicale d&#8217;un segment Si est vue
comme la mesure de la capacit&#233; d&#8217;un mod&#232;le de langue &#8710;i &#8211; c&#8217;est-&#224;-dire une distribution de probabilit&#233;s &#8211;
appris sur le segment Si &#224; pr&#233;dire les mots contenus dans le segment. Cette d&#233;finition de la coh&#233;sion
lexicale n&#233;cessite de calculer, dans un premier temps, un mod&#232;le de langue &#8710;i pour chaque segment Si du
texte &#224; segmenter, puis de d&#233;terminer la probabilit&#233; des mots du segment Si, &#233;tant donn&#233; &#8710;i.
</p>
<p>Mod&#232;le de langue Un mod&#232;le de langue n-gramme est un mod&#232;le probabiliste qui assigne une proba-
bilit&#233; &#224; toute s&#233;quence de n mots d&#8217;un texte. Le mod&#232;le de langue utilis&#233; pour le calcul de la coh&#233;sion
lexicale est un mod&#232;le unigramme, qui d&#233;termine la probabilit&#233; d&#8217;apparition de chaque mot plein &#8211; c&#8217;est-
&#224;-dire ici les noms, les adjectifs et les verbes &#8211; au sein du texte. Lors de l&#8217;estimation du mod&#232;le de langue
&#8710;i d&#8217;un segment Si, on &#233;value la probabilit&#233; d&#8217;apparition de chacun des mots du vocabulaire du texte dans
le segment Si. Afin d&#8217;&#233;viter que toute la masse de probabilit&#233; soit attribu&#233;e aux seuls mots apparaissant
dans le segment, on applique un lissage &#224; ce mod&#232;le de langue dans le but de redistribuer une partie des
probabilit&#233;s aux mots non observ&#233;s &#8211; le nombre de mots observ&#233;s dans le segment &#233;tant relativement petit</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CAMILLE GUINAUDEAU, GUILLAUME GRAVIER, PASCALE S&#201;BILLOT
</p>
<p>au regard du nombre de mots dans le texte. Le calcul du mod&#232;le de langue du segment Si se formalise par
</p>
<p>&#8710;i = {Pi(u) = Ci(u) + 1
zi
</p>
<p>, &#8704; u &#8712; VK} , (1)
avec VK le vocabulaire, de taille K, du texte et Ci(u) le compte du mot u. Dans le cas habituel, le compte
d&#8217;un mot correspond &#224; son nombre d&#8217;occurrences dans le segment Si. La distribution de probabilit&#233;s est
liss&#233;e en incr&#233;mentant le compte de chacun des mots de 1. On a donc zi = K +
</p>
<p>&#8721;
u&#8712;VK Ci(u).
</p>
<p>Vraisemblance La seconde &#233;tape du calcul de la coh&#233;sion lexicale d&#8217;un segment consiste &#224; &#233;valuer une
probabilit&#233; traduisant &#224; quel point le mod&#232;le de langue &#8710;i permet d&#8217;expliquer les mots contenus dans le
segment Si, soit
</p>
<p>ln(P (Si|&#8710;i)) =
ni&#8721;
j=1
</p>
<p>ln(
Ci(w
</p>
<p>i
j) + 1
</p>
<p>zi
) , (2)
</p>
<p>avec ni le nombre de mots dans le segment et wij le j
e mot du segment. Intuitivement cette probabilit&#233;
</p>
<p>favorise les segments les plus coh&#233;rents lexicalement puisque sa valeur est plus importante lorsque les
mots apparaissent plusieurs fois au sein du segment et qu&#8217;elle atteint sa valeur minimale lorsque tous les
mots du segment sont diff&#233;rents.
</p>
<p>Le calcul de la coh&#233;sion lexicale tel que nous venons de le pr&#233;senter se base uniquement sur la r&#233;p&#233;tition
des mots au sein d&#8217;un texte et n&#8217;accorde aucune importance au fait que deux mots diff&#233;rents peuvent &#234;tre
s&#233;mantiquement proches. C&#8217;est pourquoi nous proposons une m&#233;thode d&#8217;int&#233;gration de relations s&#233;man-
tiques dans le calcul du crit&#232;re de coh&#233;sion lexicale afin de le rendre moins sensible aux probl&#232;mes li&#233;s
aux transcriptions automatiques.
</p>
<p>2.2 avec prise en compte des relations s&#233;mantiques
</p>
<p>L&#8217;int&#233;gration de relations s&#233;mantiques que nous proposons se fonde sur l&#8217;id&#233;e que si le mot &#171; voiture &#187;, par
exemple, appara&#238;t dans un texte th&#233;matiquement homog&#232;ne, alors les probabilit&#233;s d&#8217;apparition des mots
&#171; conduire &#187; ou &#171; automobile &#187; sont plus importantes que celles de mots n&#8217;appartenant pas au m&#234;me champ
lexical. Nous int&#233;grons donc les relations s&#233;mantiques au niveau du calcul du mod&#232;le de langue de fa&#231;on
&#224; ce que, pour chaque mot wij rencontr&#233; dans le texte, son compte Ci(w
</p>
<p>i
j) soit incr&#233;ment&#233; ainsi que celui
</p>
<p>des mots qui lui sont s&#233;mantiquement li&#233;s, proportionnellement &#224; la valeur de leur proximit&#233; s&#233;mantique
avec le mot wij . Plus formellement, on a pour chaque mot w
</p>
<p>i
j du segment Si :
</p>
<p>Ci(w
i
j) = Ci(w
</p>
<p>i
j) + 1
</p>
<p>Ci(v) = Ci(v) + r(v, w
i
j) &#8704;v &#8712; VK v 6= wij , (3)
</p>
<p>avec r(v, wij) &#8712; [0, 1] la proximit&#233; s&#233;mantique des mots v et wij , dont le calcul est d&#233;crit en section 4.
</p>
<p>3 Segmentation th&#233;matique
Notre objectif n&#8217;est pas de mettre au point une nouvelle technique de segmentation th&#233;matique, mais de
voir si des m&#233;thodes &#233;tat de l&#8217;art sur du texte &#233;crit peuvent tirer profit de l&#8217;int&#233;gration de relations s&#233;-
mantiques pour traiter des transcriptions automatiques. Nous utilisons donc d&#8217;une part la technique de
segmentation propos&#233;e dans (Utiyama &amp; Isahara, 2001) et, d&#8217;autre part, une technique locale d&#233;riv&#233;e de
TextTiling, les deux s&#8217;appuyant sur une mesure de la coh&#233;sion lexicale. L&#8217;utilisation de m&#233;thodes aux com-
portements diff&#233;rents nous permet de v&#233;rifier que l&#8217;int&#233;gration de relations rend le calcul de la coh&#233;sion
lexicale plus robuste aux probl&#232;mes li&#233;s aux transcriptions automatiques, ind&#233;pendamment de la m&#233;thode
de segmentation employ&#233;e.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UTILISATION DE RELATIONS S&#201;MANTIQUES POUR LA SEGMENTATION TH&#201;MATIQUE
</p>
<p>&#8710;3&#65079; &#65080;&#65080; &#65079;
mot&#8722;1 mot&#8722;2 mot1 ... mot50 mot51 ... mot100 mot101 mot102
</p>
<p>&#65080; &#65079;&#65079; &#65080; &#65080; &#65079;&#65079; &#65080;
&#8710;2&#8710;1
</p>
<p>Fen&#234;tre
</p>
<p>FIG. 1 &#8211; Rapport de vraisemblance g&#233;n&#233;ralis&#233;
</p>
<p>M&#233;thode globale La m&#233;thode de segmentation d&#233;velopp&#233;e par Utiyama et Isahara consiste &#224; rechercher
la segmentation qui produit les segments les plus coh&#233;rents d&#8217;un point de vue lexical, tout en respectant
une distribution a priori de la longueur des segments. Son principe est de trouver la segmentation la plus
probable d&#8217;une s&#233;quence de l unit&#233;s &#233;l&#233;mentaires (mots, phrases, ou groupes de souffle) W = W l1 parmi
toutes les segmentations possibles, soit
</p>
<p>S&#770; = argmax
S
</p>
<p>P [W |S]P [S] . (4)
En supposant que P [Sm1 ] = n
</p>
<p>&#8722;m, avec n le nombre de mots du texte et m le nombre de segments, la
probabilit&#233; d&#8217;un texte W pour une segmentation S = Sm1 est donn&#233;e par
</p>
<p>S&#770; = argmax
Sm1
</p>
<p>m&#8721;
i=1
</p>
<p>(ln(P [Si|&#8710;i])&#8722; &#945; ln(n)) . (5)
</p>
<p>La coh&#233;sion lexicale ln(P [Si|&#8710;i]) pour le segment Si est calcul&#233;e comme d&#233;crit en section 2. Le facteur
&#945; permet de contr&#244;ler la taille moyenne des segments retourn&#233;s.
</p>
<p>M&#233;thode locale La seconde technique de segmentation consid&#233;r&#233;e est adapt&#233;e de la m&#233;thode TextTi-
ling (Hearst, 1997), qui consiste &#224; &#233;valuer, pour chaque fen&#234;tre centr&#233;e sur une fronti&#232;re potentielle, la
similarit&#233; entre la partie droite et la partie gauche de la fen&#234;tre. Afin de comparer les deux m&#233;thodes de
segmentation, globale et locale, le calcul de la similarit&#233;, fond&#233; sur une mesure cosinus dans la technique
originale, a &#233;t&#233; modifi&#233; pour utiliser la m&#234;me mesure de coh&#233;sion lexicale que pour la m&#233;thode globale.
Contrairement &#224; la m&#233;thode TextTiling, notre m&#233;thode de segmentation locale ne consiste donc pas &#224; com-
parer les parties gauche et droite de la fen&#234;tre pour d&#233;terminer s&#8217;il y a ou non rupture de la coh&#233;sion
lexicale mais plut&#244;t &#224; calculer le rapport de probabilit&#233; entre l&#8217;hypoth&#232;se consid&#233;rant une fronti&#232;re et celle
n&#8217;en consid&#233;rant pas (cf. figure 1).
</p>
<p>Ce rapport R, s&#8217;il est important, traduit le fait que la coh&#233;sion lexicale au sein de la fen&#234;tre est meilleure si
le segmentmot1 ... mot100 est divis&#233; en deux, c&#8217;est-&#224;-dire que les vocabulaires des segmentsmot1 ... mot50
et mot51 ... mot100 sont diff&#233;rents. La valeur du rapport R est donn&#233;e par :
</p>
<p>R = ln(P [mot1 ... mot50|&#8710;1]) + ln(P [mot51 ... mot100|&#8710;2])&#8722; ln(P [mot1 ... mot100|&#8710;3]) , (6)
avec ln(P [moti ... moti+n|&#8710;i]) la coh&#233;sion lexicale du segment moti ... moti+n calcul&#233;e comme d&#233;crit en
section 2.
</p>
<p>La segmentation th&#233;matique du texte est finalement obtenue &#224; partir des valeurs du rapport de vraisem-
blance pour chaque s&#233;paration entre deux groupes de souffle. De ces valeurs sont extraits des maxima
locaux par une technique d&#8217;extraction des pics dominants qui, s&#8217;ils sont sup&#233;rieurs &#224; un seuil &#963;, d&#233;finissent
une fronti&#232;re th&#233;matique. Cette m&#233;thode permet d&#8217;obtenir une valeur de Pk-mesure d&#8217;environ 9% sur le
corpus de Choi (pour des segments compos&#233;s de 9 &#224; 11 phrases). Les r&#233;sultats sont donc bien meilleurs
que ceux obtenus par TextTiling (Pk-mesure de 48%) sur le m&#234;me corpus.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CAMILLE GUINAUDEAU, GUILLAUME GRAVIER, PASCALE S&#201;BILLOT
</p>
<p>4 Acquisition et s&#233;lection de relations s&#233;mantiques
</p>
<p>Le choix des relations s&#233;mantiques int&#233;gr&#233;es dans le calcul de la coh&#233;sion lexicale peut avoir une influence
importante sur les r&#233;sultats de la segmentation th&#233;matique. Nous pr&#233;sentons ici, les m&#233;thodes d&#8217;extraction
et de s&#233;lection utilis&#233;es pour obtenir les relations les plus pertinentes pour notre t&#226;che de segmentation.
</p>
<p>Acquisition de relations s&#233;mantiques Bien que de nombreuses ressources lexicales d&#233;j&#224; contruites
soient disponibles, elles sont malheureusement souvent li&#233;es &#224; certain domaine. Les documents t&#233;l&#233;vi-
suels &#233;tudi&#233;s &#233;tant multi-domaines, nous avons donc extrait les relations s&#233;mantiques &#224; partir de corpus.
L&#8217;objectif de cet article &#233;tant d&#8217;&#233;tudier l&#8217;influence de l&#8217;int&#233;gration de relations s&#233;mantiques et non d&#8217;opti-
miser leur extraction, nous avons choisi d&#8217;appliquer des m&#233;thodes standards afin d&#8217;acqu&#233;rir deux types de
relations : des relations syntagmatiques et des relations paradigmatiques. Les relations syntagmatiques cor-
respondent &#224; des relations de successivit&#233; et de contigu&#239;t&#233; que les mots entretiennent au sein d&#8217;une phrase
(exemple : &#171; conduire &#187; et &#171; voiture &#187;). Pour les calculer, nous avons retenu deux indices de force d&#8217;as-
sociation couramment utilis&#233;s : l&#8217;information mutuelle IM et l&#8217;information mutuelle au cube IM3 (Daille,
1994), ce second indice ayant &#233;t&#233; d&#233;fini afin de r&#233;duire l&#8217;importance associ&#233;e aux &#233;v&#233;nements rares par
IM. Le second type de relation r&#233;unit deux mots pr&#233;sentant une composante commune importante du point
de vue du sens, comme &#171; voiture &#187; et &#171; automobile &#187;. Ces relations paradigmatiques sont calcul&#233;es en as-
sociant &#224; chaque couple de mots le cosinus de l&#8217;angle entre les vecteurs de voisinage des occurrences des
deux mots. Nous obtenons ainsi une liste de synonymes, d&#8217;hyp&#233;ronymes, etc., non diff&#233;renci&#233;s.
</p>
<p>Pour l&#8217;ensemble des m&#233;thodes d&#8217;acquisition, les relations ont &#233;t&#233; extraites sur un corpus compos&#233; d&#8217;articles
du Monde, de l&#8217;Humanit&#233; et des transcriptions de r&#233;f&#233;rence des campagnes Ester 1 et Ester 2 correspondant
respectivement &#224; 100 et 150 heures de journaux radiophoniques. Dans ce corpus, lemmatis&#233; et normalis&#233;,
seuls les noms, adjectifs, et verbes autres que &#171; &#234;tre &#187;, &#171; avoir &#187; et &#171; falloir &#187; ont &#233;t&#233; conserv&#233;s. Les scores
d&#8217;association ont finalement &#233;t&#233; normalis&#233;s afin d&#8217;obtenir des valeurs comprises entre 0 et 1.
</p>
<p>S&#233;lection de relations s&#233;mantiques La question qui se pose alors est de retenir, pour notre t&#226;che de
segmentation, les relations s&#233;mantiques les plus pertinentes parmi tous les liens extraits. Nous explorons
deux m&#233;thodes de s&#233;lection :
&#8211; conserver les &#948; relations ayant les scores les plus &#233;lev&#233;s tous mots confondus (Total&#948;) ; ces relations sont
</p>
<p>appel&#233;es &#171; premi&#232;res relations &#187; dans la suite de cet article. Dans nos tests, la valeur de &#948; peut &#234;tre &#233;gale
&#224; 5 000, 10 000, 20 000, 50 000 et 90 000 ;
</p>
<p>&#8211; conserver un nombre fixe &#946; de relations pour chaque mot (ParMot&#946;), &#946; prenant les valeurs 2, 3 et 10.
De plus, nous avons remarqu&#233; que certains mots du corpus, comme &#171; aller &#187;, &#171; an &#187;, etc., &#233;taient s&#233;manti-
quement li&#233;s avec un nombre important d&#8217;autres mots. Afin d&#8217;&#233;viter de cr&#233;er des liens s&#233;mantiques entre de
trop nombreux couples de mots, ce qui conduirait &#224; cr&#233;er un nombre excessif de liens entre les segments
dans nos techniques de segmentation, nous avons d&#233;fini une technique de filtrage, Seuil&#947; , pouvant &#234;tre
associ&#233;e aux deux m&#233;thodes de s&#233;lection. Elle consiste &#224; ignorer les relations s&#233;mantiques des mots qui
entretiennent un nombre de relations sup&#233;rieur &#224; un certain seuil. La valeur du seuil est &#233;gale au nombre
moyen de relations associ&#233;es aux mots du texte &#224; segmenter multipli&#233; par un param&#232;tre &#947; prenant les
valeurs 1, 2, 3, 5 ou 10.
</p>
<p>Le tableau 1 illustre les 5 relations aux scores d&#8217;association les plus &#233;lev&#233;s rattach&#233;es au mot &#171; ciga-
rette &#187; en s&#233;lectionnant les 90 000 premi&#232;res relations, Total90000, et 10 relations par mot, ParMot10. Nous
constatons que la qualit&#233; de ces relations change selon la m&#233;thode utilis&#233;e pour leur extraction. Ainsi,
les relations obtenues gr&#226;ce au score IM correspondent g&#233;n&#233;ralement &#224; des &#233;v&#233;nements rares, &#224; tel point
d&#8217;ailleurs qu&#8217;aucune des relations existant avec le mot &#171; cigarette &#187; n&#8217;appara&#238;t pas dans les 90 000 pre-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UTILISATION DE RELATIONS S&#201;MANTIQUES POUR LA SEGMENTATION TH&#201;MATIQUE
</p>
<p>TAB. 1 &#8211; Relations aux scores d&#8217;association les plus &#233;lev&#233;s pour le mot &#171; cigarette &#187;
</p>
<p>IM IM3 paradigmatique
Total90000 cigarette fumer cigarette cigare
</p>
<p>cigarette paquet cigarette gitane
cigarette gauloise
</p>
<p>ParMot10 cigarette chevignon cigarette fumer cigarette cigare
cigarette liggett cigarette paquet cigarette gitane
cigarette altadi cigarette allumer cigarette gauloise
cigarette d&#233;taxer cigarette contrebande cigarette clope
</p>
<p>mi&#232;res relations, alors que les relations IM3 et paradigmatiques semblent plus pertinentes.
</p>
<p>5 R&#233;sultats
L&#8217;int&#233;gration des relations s&#233;mantiques pour la segmentation de documents t&#233;l&#233;visuels a &#233;t&#233; test&#233;e sur deux
corpus. Le premier est constitu&#233; de 60 journaux t&#233;l&#233;vis&#233;s, d&#8217;une dur&#233;e de 40 minutes chacun, diffus&#233;s en
f&#233;vrier et mars 2007 sur la cha&#238;ne de t&#233;l&#233;vision France 2. Le second est compos&#233; de 12 &#233;missions de
reportage de 2 heures, &#171; Envoy&#233; Sp&#233;cial &#187;, diffus&#233;es sur France 2 entre mars 2008 et janvier 2009, et de
16 &#233;missions de reportage &#171; Sept &#224; Huit &#187;, de 1 heure chacune, programm&#233;es sur la cha&#238;ne TF1 entre
septembre 2008 et f&#233;vrier 2009. Ces deux corpus ont &#233;t&#233; d&#233;finis pour prendre en compte les diff&#233;rences
importantes existant entre les deux types d&#8217;&#233;missions : nombre de r&#233;p&#233;titions dans les JT beaucoup moins
important que dans les &#233;missions de reportages, avec une proportion de parole spontan&#233;e plus &#233;lev&#233;e dans
ces derniers, et longueur moyenne des reportages d&#8217;&#171; Envoy&#233; Sp&#233;cial &#187; beaucoup plus grande.
</p>
<p>Ces &#233;missions ont &#233;t&#233; transcrites par un syst&#232;me de reconnaissance automatique de la parole, impl&#233;ment&#233;
pour la transcription de journaux radiophoniques, atteignant un taux d&#8217;erreur d&#8217;environ 20% sur les don-
n&#233;es du corpus Ester 2. Les deux corpus transcrits sont compos&#233;s respectivement de 12 000 et 11 000
mots pleins. Pour chacune des transcriptions, nous avons supprim&#233; la partie pr&#233;c&#233;dant le lancement du
premier reportage, c&#8217;est-&#224;-dire la partie constitu&#233;e des titres du journal ou du sommaire de l&#8217;&#233;mission,
ainsi que celle suivant la fin du dernier reportage, ces deux parties tr&#232;s sp&#233;cifiques perturbant l&#8217;algorithme
de segmentation. Cette extraction manuelle aurait pu &#234;tre effectu&#233;e en utilisant des indices audiovisuels.
Une segmentation de r&#233;f&#233;rence a &#233;t&#233; effectu&#233;e en consid&#233;rant un changement de th&#232;me &#224; chaque change-
ment de reportage, bien que ce ne soit pas toujours le cas, notamment pour le premier corpus. En effet,
les premiers reportages des JT traitent g&#233;n&#233;ralement du titre principal du journal et abordent donc tous
le m&#234;me th&#232;me. Nous obtenons un total de 1180 fronti&#232;res th&#233;matiques pour le premier corpus et de 141
pour le second. L&#8217;&#233;valuation de nos m&#233;thodes de segmentation se fait en consid&#233;rant comme correcte une
fronti&#232;re &#233;loign&#233;e de moins de 10 secondes d&#8217;une fronti&#232;re de r&#233;f&#233;rence. Nous utilisons les m&#233;triques
pr&#233;cision, rappel et F1-mesure pour chiffrer les r&#233;sultats de nos algorithmes. Afin de confronter nos dif-
f&#233;rentes m&#233;thodes, nous comparons la valeur de la F1-mesure pour des valeurs de param&#232;tre (&#945; pour la
m&#233;thode globale et &#963; pour la m&#233;thode locale) conduisant &#224; une segmentation dont la longueur moyenne
des segments est la plus proche de celle de la segmentation de r&#233;f&#233;rence.
</p>
<p>Nous pr&#233;sentons dans un premier temps les r&#233;sultats obtenus sur le premier corpus gr&#226;ce &#224; la m&#233;thode de
segmentation globale, en analysant les techniques de s&#233;lection utilis&#233;es pour chaque type de relations. Puis,
nous comparons le comportement des deux m&#233;thodes de segmentation face &#224; l&#8217;int&#233;gration des relations
s&#233;mantiques. Enfin, nous analysons la portabilit&#233; de l&#8217;int&#233;gration des relations sur le second corpus.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CAMILLE GUINAUDEAU, GUILLAUME GRAVIER, PASCALE S&#201;BILLOT
</p>
<p>40
</p>
<p>45
</p>
<p>50
</p>
<p>55
</p>
<p>60
</p>
<p>65
</p>
<p>70
</p>
<p>75
</p>
<p>80
</p>
<p>50 55 60 65 70
</p>
<p>rappel
</p>
<p>pr&#233;cision
</p>
<p>sans relations
</p>
<p>?
</p>
<p>?
?
</p>
<p>??
</p>
<p>?
Total10
</p>
<p>b
bb
</p>
<p>bbb
bbb
</p>
<p>b
Total90000
</p>
<p>r
rr
</p>
<p>rrr
r
</p>
<p>Total10 + Seuil1
</p>
<p>&#215;
</p>
<p>&#215;
&#215;
</p>
<p>&#215;
&#215;&#215;&#215; &#215;
</p>
<p>Total90000 + Seuil1
</p>
<p>r
rr
</p>
<p>rr r
</p>
<p>FIG. 2 &#8211; Courbes rappel/pr&#233;cision pour l&#8217;int&#233;gration de relations IM3 dans la m&#233;thode de segmentation
globale sur des journaux t&#233;l&#233;vis&#233;s, obtenues en faisant varier le facteur &#945; contr&#244;lant la taille des segments
</p>
<p>5.1 Comparaison des techniques de s&#233;lection des relations s&#233;mantiques
</p>
<p>Les deux techniques de s&#233;lection, &#233;ventuellement combin&#233;es &#224; une m&#233;thode de filtrage, ayant &#233;t&#233; test&#233;es
sur trois types de relations, nous avons obtenu un nombre important de r&#233;sultats qu&#8217;il n&#8217;est pas possible
de pr&#233;senter ici en d&#233;tails. Nous d&#233;crivons donc dans cette partie l&#8217;influence g&#233;n&#233;rale des techniques de
s&#233;lection sur les r&#233;sultats de la segmentation globale.
</p>
<p>Information mutuelle (IM) L&#8217;int&#233;gration de relations s&#233;mantiques extraites par IM au sein de la m&#233;thode
de segmentation globale permet d&#8217;am&#233;liorer les r&#233;sultats lorsque la technique de s&#233;lection ParMot est
utilis&#233;e, am&#233;lioration proportionnelle au nombre de relations introduites. La m&#233;thode de s&#233;lection Total ne
permet pas de faire &#233;voluer la qualit&#233; de la segmentation, de fa&#231;on positive ou n&#233;gative. Ceci s&#8217;explique
par le fait que les toutes premi&#232;res relations calcul&#233;es sur nos corpus d&#8217;apprentissage par le score IM
correspondent &#224; des &#233;v&#233;nements rares (cf. tableau 1) qui n&#8217;apparaissent pas dans nos transcriptions et
n&#8217;ont donc pas d&#8217;influence sur la valeur de la coh&#233;sion lexicale. Finalement, l&#8217;association de la technique
filtrant les mots li&#233;s &#224; trop d&#8217;autres mots &#224; la m&#233;thode ParMot permet une am&#233;lioration suppl&#233;mentaire de
la F1-mesure.
</p>
<p>Information mutuelle au cube (IM3) Lorsqu&#8217;elles sont appliqu&#233;es sur des relations IM3, les deux tech-
niques de s&#233;lection Total et ParMot obtiennent des r&#233;sultats &#233;quivalents : toutes deux d&#233;t&#233;riorent &#224; la fois
les valeurs de rappel et de pr&#233;cision (cf. figure 2), d&#233;t&#233;rioration d&#8217;autant plus marqu&#233;e que le nombre de
relations introduites est important. Cependant, l&#8217;utilisation de la m&#233;thode de filtrage Seuil permet d&#8217;am&#233;-
liorer la qualit&#233; de la segmentation, et la meilleure valeur de la F1-mesure est obtenue gr&#226;ce &#224; la com-
binaison Total90000 + Seuil1. L&#8217;introduction de trop nombreuses relations s&#233;mantiques semble donc relier
un nombre excessif de mots et de segments, faisant diminuer la qualit&#233; des r&#233;sultats de la segmentation et
rendant n&#233;cessaire une limitation du nombre de relations introduites par filtrage.
</p>
<p>Relations paradigmatiques L&#8217;introduction de relations paradigmatiques dans la m&#233;thode de segmentation
globale a un comportement assez similaire &#224; celui observ&#233; pour les relations IM3. En effet, les r&#233;sultats
de la segmentation se d&#233;gradent avec le nombre croissant de relations introduites et ceci, pour les deux
techniques Total et ParMot. &#192; nouveau, le filtrage des mots auxquels on associe des relations s&#233;mantiques
permet d&#8217;am&#233;liorer les r&#233;sultats. Enfin, les r&#233;sultats pour les deux techniques de s&#233;lection sont, pour ces
relations &#233;galement, tout &#224; fait &#233;quivalents, m&#234;me si la meilleure valeur de la F1-mesure est ici obtenue</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UTILISATION DE RELATIONS S&#201;MANTIQUES POUR LA SEGMENTATION TH&#201;MATIQUE
</p>
<p>TAB. 2 &#8211; Valeurs1 de la F1-mesure pour l&#8217;int&#233;gration des relations s&#233;mantiques
</p>
<p>M&#233;thode globale M&#233;thode locale
Corpus JT reportages JT reportages
</p>
<p>Sans relations 59.44 51.09 26.19 26.62
IM ParMot10 + Seuil5 ParMot10 + Seuil5 ParMot10 ParMot10 + Seuil1
</p>
<p>61.41 61.42 26.29 39.20
IM3 Total90000 + Seuil1 Total5000 + Seuil1 Total90000 ParMot2 + Seuil2
</p>
<p>60.44 62.92 27.11 39.27
Paradigmatiques ParMot10 + Seuil3 ParMot3 + Seuil3 ParMot10 + Seuil3 Total90000 + Seuil2
</p>
<p>61.27 62.28 28.02 41.54
</p>
<p>avec une m&#233;thode de s&#233;lection diff&#233;rente, ParMot10 + Seuil3.
</p>
<p>5.2 Comparaison des m&#233;thodes de segmentation globale et locale
Bien qu&#8217;une augmentation ponctuelle de la valeur de la F1-mesure est obtenue pour l&#8217;int&#233;gration des trois
types de relations dans la m&#233;thode de segmentation locale, l&#8217;ajout de relations s&#233;mantiques n&#8217;a ici que peu
d&#8217;influence sur la qualit&#233; des segmentations obtenues, comme nous avons pu l&#8217;observer sur les courbes
rappel/pr&#233;cision. Deux facteurs peuvent expliquer ces r&#233;sultats. Tout d&#8217;abord, lors de l&#8217;ajout de relations
s&#233;mantiques au sein de la fen&#234;tre glissante, si les valeurs de la coh&#233;sion lexicale des trois segments &#8211; ceux
situ&#233;s &#224; droite et &#224; gauche de la fen&#234;tre et celui constitu&#233; de tous les mots de la fen&#234;tre &#8211; sont augment&#233;es,
l&#8217;int&#233;gration des relations n&#8217;aura que tr&#232;s peu d&#8217;effet sur la valeur du rapport R calcul&#233;. Par ailleurs, la
technique d&#8217;extraction des maxima locaux utilis&#233;e pour d&#233;finir les fronti&#232;res th&#233;matiques peut &#233;galement
permettre d&#8217;interpr&#233;ter ces r&#233;sultats. En effet, cette technique, tr&#232;s sensible aux variations, peut proposer
des segmentations diff&#233;rentes alors m&#234;me que l&#8217;&#233;volution de la valeur de la coh&#233;sion lexicale au fil du texte
pr&#233;sente des profils fortement similaires. Enfin, nous pouvons constater dans le tableau 2 que les r&#233;sultats
de la m&#233;thode locale sont bien moins &#233;lev&#233;s que ceux de la m&#233;thode globale. Ceci peut s&#8217;expliquer par le
fait que notre corpus de JT est constitu&#233; de segments de tailles tr&#232;s variables et pouvant &#234;tre tr&#232;s petits.
La fen&#234;tre glissante peut alors contenir plusieurs segments, ce qui rend la valeur de la coh&#233;sion lexicale
au sein de cette fen&#234;tre inexploitable, la variabilit&#233; de la taille des segments au sein d&#8217;un m&#234;me corpus
emp&#234;chant de d&#233;finir une taille de fen&#234;tre optimale.
</p>
<p>5.3 Portabilit&#233; de l&#8217;int&#233;gration de relations s&#233;mantiques sur d&#8217;autres corpus
En analysant les courbes rappel/pr&#233;cision pour l&#8217;ajout de relations s&#233;mantiques dans la m&#233;thode locale,
nous constatons que les r&#233;sultats fournis sur le corpus de reportages sont peu encourageants bien que,
ponctuellement, la valeur de la F1-mesure soit augment&#233;e pour les trois types de relations (tableau 2).
Concernant la m&#233;thode globale, l&#8217;int&#233;gration d&#8217;un grand nombre de relations paradigmatiques et IM3 d&#233;-
grade, ici aussi, la qualit&#233; de la segmentation sauf si on associe un filtrage aux m&#233;thodes de s&#233;lection. De
plus, le comportement des relations IM est, lui aussi, similaire puisque la s&#233;lection Total ne permet pas
d&#8217;influencer la qualit&#233; de la segmentation et qu&#8217;une s&#233;lection des relations par mot est n&#233;cessaire pour
obtenir un impact sur les r&#233;sultats. Cependant, l&#8217;am&#233;lioration obtenue lors de l&#8217;int&#233;gration des relations
s&#233;mantiques sur ce corpus est plus sensible que celle observ&#233;e sur les JT et ceci pour les deux m&#233;thodes.
Cette diff&#233;rence s&#8217;explique par le fait que le nombre de r&#233;p&#233;titions est ici plus important. &#192; chaque r&#233;p&#233;-
</p>
<p>1Mesures obtenues pour des valeurs de param&#232;tres conduisant &#224; une segmentation pour laquelle la longueur des segments
est la plus proche de celle de la segmentation de r&#233;f&#233;rence.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CAMILLE GUINAUDEAU, GUILLAUME GRAVIER, PASCALE S&#201;BILLOT
</p>
<p>tition d&#8217;un mot, des relations s&#233;mantiques vont &#234;tre int&#233;gr&#233;es, renfor&#231;ant la valeur de la coh&#233;sion lexicale
pour les segments coh&#233;rents. L&#8217;augmentation de la valeur de la F1-mesure doit toutefois &#234;tre analys&#233;e avec
prudence car le nombre de fronti&#232;res dans ce corpus est beaucoup plus faible.
</p>
<p>6 Conclusion
Nous avons propos&#233; une m&#233;thode pour int&#233;grer des relations s&#233;mantiques dans une mesure de la coh&#233;-
sion lexicale et montr&#233; que l&#8217;utilisation de ces relations dans une m&#233;thode de segmentation th&#233;matique
globale am&#233;liore les r&#233;sultats pour des documents t&#233;l&#233;visuels transcrits, compensant en partie l&#8217;absence
de r&#233;p&#233;titions dans les documents consid&#233;r&#233;s et les erreurs de transcription. Nous avons mis en &#233;vidence
l&#8217;importance de limiter le nombre de relations introduites afin d&#8217;emp&#234;cher qu&#8217;elles ne relient entre eux
un nombre excessif de segments. Afin d&#8217;am&#233;liorer nos m&#233;thodes de segmentation de documents oraux,
nous privil&#233;gions deux pistes utilisant des caract&#233;ristiques des transcriptions automatiques. La premi&#232;re
exploite les mesures de confiance associ&#233;es &#224; chacun des mots de la transcription &#8211; correspondant &#224; la
probabilit&#233; que le mot soit correctement transcrit &#8211; afin de mieux g&#233;rer les erreurs de transcription. L&#8217;in-
troduction de ces seules mesures dans de pr&#233;c&#233;dents travaux, nous a permis d&#8217;am&#233;liorer la F1-mesure de
+1.5 sur le corpus de journaux t&#233;l&#233;vis&#233;s. En associant relations s&#233;mantiques et mesures de confiance, nous
esp&#233;rons combiner leurs gains et rendre ainsi notre m&#233;thode plus adapt&#233;e aux transcriptions automatiques.
La seconde piste consiste &#224; fonder notre segmentation non pas sur une seule transcription, c&#8217;est-&#224;-dire la
meilleure hypoth&#232;se fournie par le syst&#232;me de reconnaissance automatique de la parole, mais sur la liste
des n meilleures hypoth&#232;ses qu&#8217;il propose.
</p>
<p>R&#233;f&#233;rences
</p>
<p>AMARAL R. &amp; TRANCOSO I. (2003). Topic indexing of TV broadcast news programs. In 6th Interna-
tional Workshop on Computational Processing of the Portuguese Language.
BEEFERMAN D., BERGER A. &amp; LAFFERTY J. (1999). Statistical models for text segmentation. Machine
Learning, 34(1-3), 177&#8211;210.
CHRISTENSEN H., KOLLURU B. &amp; ET al. Y. G. (2005). Maximum entropy segmentation of broadcast
news. In 30th IEEE ICASSP.
DAILLE B. (1994). Approche mixte pour l&#8217;extraction automatique de terminologie : statistiques lexicales
et filtres linguistiques. PhD thesis, Universit&#233; de Paris 7.
FERRET O. (2002). Segmenter et structurer th&#233;matiquement des textes par l&#8217;utilisation conjointe de
collocations et de la r&#233;currence lexicale. In 9e Actes de Traitement Automatique des Langues Naturelles.
HEARST M. A. (1997). Texttiling : segmenting text into multi-paragraph subtopic passages. Computa-
tional Linguistics, 23, 33&#8211;64.
MULBREGT P. V., CARP I., GILLICK L., LOWE S. &amp; YAMRON J. (1999). Segmentation of automati-
cally transcribed broadcast news text. In DARPA Broadcast News Workshop.
OSTENDORF M., FAVRE B. &amp; ET al. R. G. (2008). Speech segmentation and spoken document proces-
sing. IEEE Signal Processing Magazine, 25(3), 59&#8211;69.
STOLCKE A., SHRIBERG E. &amp; ET al. D. H.-T. (1999). Combining words and speech prosody for
automatic topic segmentation. In DARPA Broadcast News Workshop.
UTIYAMA M. &amp; ISAHARA H. (2001). A statistical model for domain-independent text segmentation. In
9th ACL.</p>

</div></div>
</body></html>