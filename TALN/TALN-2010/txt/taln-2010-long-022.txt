TALN 2010, Montréal, 19-23 jui11et2010

Utilisation de relations sémantiques pour améliorer la segmentation
thématique de documents télévisuels*

Camille Guinaudeaul Guillaume Gravierz Pascale Sébillot3
INRIA Rennesl & IRISA (CNRS2, INSA3), France
camille.guinaudeau@irisa.fr, guillaume.gravier@irisa.fr, pascale.sebillot@irisa.fr

Résumé. Les méthodes de segmentation thématique exploitant une mesure de la cohésion lexicale
peuvent étre appliquées telles quelles a des transcriptions automatiques de programmes télévisuels. Ce-
pendant, elles sont moins efﬁcaces dans ce contexte, ne prenant en compte ni les particularités des éInis-
sions TV, ni celles des transcriptions. Nous étudions ici l’apport de relations sémantiques pour rendre les
techniques de segmentation thématique plus robustes. Nous proposons une méthode pour exploiter ces
relations dans une mesure de la cohésion lexicale et montrons qu’elles permettent d’augmenter la Fl-
mesure de +1.97 et +1 1.83 sur deux corpus composés respectivement de 40h de journaux télévisés et de
40h d’émissions de reportage. Ces améliorations démontrent que les relations sémantiques peuvent rendre
les méthodes de segmentation moins sensibles aux erreurs de transcription et au manque de répétitions
constaté dans certaines emissions télévisées.

Abstract. Topic segmentation methods based on a measure of the lexical cohesion can be applied
as is to automatic transcripts of TV programs. However, these methods are less effective in this context as
neither the speciﬁcities of TV contents, nor those of automatic transcripts are considered. The aim of this
paper is to study the use of semantic relations to make segmentation techniques more robust. We propose a
method to account for semantic relations in a measure of the lexical cohesion. We show that such relations
increase the F1-measure by +1.97 and +ll.83 for two data sets consisting of respectively 40h of news
and 40h of longer reports on current affairs. These results demonstrate that semantic relations can make
segmentation methods less sensitive to transcription errors or to the lack of repetitions in some television
programs.

M0tS-CléS I Segmentation thématique, documents oraux, cohésion lexicale, relations sémantiques.

Keywords: Topic segmentation, spoken document, lexical cohesion, semantic relations.

* Travaux partiellement ﬁnancés par le proj et Quaero.

CAMILLE GUINAUDEAU, GUILLAUME GRAVIER, PASCALE SEBILLOT

1 Introduction

Les travaux presentes dans cet article se placent dans le contexte de la structuration automatique de ﬂux
televisuels et, plus particulierement, dans ce que l’on peut considerer comme la premiere etape necessaire
a cette structuration : la segmentation. Aﬁn de permettre aux utilisateurs de naviguer de fagon non lineaire
a l’interieur d’un document televise, il est en effet essentiel de decouper ce ﬂux en emissions d’une part,
et d’extraire de ces emissions des segments thematiquement coherents d’autre part.

La segmentation de documents televisuels quelconques ne pouvant s’appuyer sur l’utilisation des seuls
indices audio disponibles — aucune methode fondee sur ces demiers ne foumissant de resultats satisfai-
sants — la prise en compte d’indices altematifs (textuels ou video) apparait necessaire. Les performances
des systemes de reconnaissance de la parole (RAP) s’etant considerablement ameliorees ces dernieres
annees (Ostendorf et al., 2008), la segmentation thematique de documents oraux peut desormais s’effec-
tuer par le biais des transcriptions automatiques. La plupart des travaux developpes en ce sens appliquent
generalement sur ces transcriptions des methodes issues de la segmentation de documents textuels, tres
frequemment fondees sur la notion de cohesion lexicale. Ainsi (Mulbregt et al., 1999) et (Utiyama &
Isahara, 2001) proposent respectivement une technique utilisant un modele de Markov cache et une me-
thode consistant a rechercher la meilleure segmentation parmi toutes les segmentations possibles. Des
marqueurs discursifs, obtenus lors d’une phase prealable d’apprentissage, peuvent aussi servir a reperer
des frontieres thematiques ((Beeferman et al., 1999) et (Christensen et al., 2005)). Cependant, lors de
precedents travaux sur la segmentation d’eInissions radiophoniques par une approche non supervisee fon-
dee sur la cohesion lexicale, nous avons constate un gros ecart de performances entre les segmentations
de transcriptions manuelles et automatiques. En effet, les transcriptions automatiques possedent certaines
particularites. Premierement, ces donnees ne contiennent ni ponctuation ni majuscule; elles ne sont donc
pas structurees en phrases comme un texte classique mais en unites appelees groupes de soufﬂe, qui cor-
respondent a la parole prononcee par un locuteur entre deux respirations. De plus, le taux d’erreur de notre
systeme de RAP, meme s’il reste raisonnable sur des emissions comme les joumaux televises (JT), peut
atteindre 70% pour des emissions telles que des ﬁhns ou des talk shows, rendant impossible l’utilisation
de certains indices tels que les marqueurs discursifs. Ces ecarts de performances sont dﬁs a la qualite
de l’enregistrement — enregistrement studio ou exterieur —, a la presence ou non de bruits de fond, d’ap-
plaudissements, a la difference de style de parole. Enﬁn, les emissions televisuelles sont composees de
segments thematiques pouvant étre tres courts, contenant peu de repetitions de vocabulaire (notamment
au sein des journaux televises) et dans lesquels le niveau de langage peut etre tres variable (alternance
presentateur/interview). Nous souhaitons donc adapter les methodes de segmentation thematique fondees
sur la cohesion lexicale a ces donnees particulieres.

Pour pallier les difﬁcultes liees aux erreurs de transcription, certains travaux ont propose d’ajouter a la
seule notion de cohesion lexicale des indices propres aux documents oraux. Par exemple, (Amaral &
Trancoso, 2003) exploite la detection de locuteur aﬁn de reperer le presentateur du journal televise, celui-
ci introduisant de nouveaux reportages et donc les changements thematiques. Conjointement a la trans-
cription, les auteurs de (Stolcke et al., 1999) utilisent quant a eux la prosodie. Cependant de tels indices
sont globalement peu employes car leur extraction automatique est difﬁcile. De plus, ils permettent uni-
quement de remedier aux erreurs de transcription et ne traitent en rien le manque de repetitions inherent
a un corpus televisuel. Pour rendre la segmentation thematique plus robuste aux speciﬁcites des transcrip-
tions automatiques d’emissions televisees, l’utilisation de relations semantiques nous semble pertinente,
un mot mal transcrit ayant peu de chance d’etre lie semantiquement aux autres mots du segment. Certains
travaux, comme (Ferret, 2002), ont integre dans le passe des relations semantiques dans des methodes
de segmentation de l’ecrit inspirees de TextTiling (Hearst, 1997), c’est-a-dire basees sur la detection de

UTILISATION DE RELATIONS SEMANTIQUES POUR LA SEGMENTATION THEMATIQUE

ruptures de la cohésion au sein d’une fenétre glissante. Cependant, la méthode proposée dans (Utiyama
& Isahara, 2001), fondée sur une mesure de la cohésion lexicale d’un segment plutot que sur la detec-
tion de ruptures, donne de meilleurs résultats pour la segmentation de documents oraux. Nous proposons
donc ici une technique originale pour introduire des relations sémantiques dans la méthode de calcul de
la cohésion lexicale décrite dans (Utiyama & Isahara, 2001). Nous exploitons cette intégration dans deux
méthodes de segmentation thématique, l’une globale, l’autre locale. Ces techniques, testées sur deux cor-
pus oraux composés de documents télévisuels transcrits d’une durée globale de 80 heures (40 heures de
JT et 40 heures d’éIr1issions de reportages), permettent de découper nos données en segments thématiques
composés des reportages éventuellement précédés d’un plateau de lancement. Les deux corpus utilisés
constituent a notre connaissance le plus gros volume de données télévisuelles testé jusqu’a présent.

Dans cet article, nous présentons le calcul de la cohésion lexicale, d’abord sans, puis avec prise en compte
des relations sémantiques, avant de décrire, en section 3, les algorithmes de segmentation que nous uti-
lisons pour traiter nos corpus. Le choix des relations a intégrer constituant un probleme majeur — elles
peuvent, en effet, étre sélectionnées de différentes facons, en ne conservant que les relations correspon-
dant aux forces d’association entre mots les plus élevées par exemple ou en ne retenant qu’un nombre
ﬁxe de relations par mot — nous exposons, dans la quatrieme partie, les techniques retenues d’acquisition
et de sélection des relations sémantiques. Nous testons l’intégration des relations sur nos deux corpus et
décrivons les résultats de ces expériences en section 5, avant la présentation de quelques perspectives.

2 Mesure de cohésion lexicale...

Le critere de cohésion lexicale fait référence aux relations lexicales qui existent au sein d’un texte et lui
donnent une certaine unité. Les méthodes de segmentation, utilisant cette notion pour découper un texte
en segments présentant une homogénéité du point de vue de leurs themes, se fondent sur l’analyse de
la distribution des mots au sein du texte pour détecter des ruptures ou, de maniere duale, des segments
homogenes. Nous présentons, dans cette partie, une technique de mesure de la cohésion lexicale pour la
segmentation de documents textuels, ainsi que la méthode que nous utilisons pour intégrer des relations
sémantiques aﬁn de rendre ce critere plus robuste aux particularités de données télévisuelles transcrites,
en particulier le manque de répétitions et les erreurs de transcription.

2.1 sans prise en compte des relations sémantiques

Dans (Utiyama & Isahara, 2001), les auteurs présentent une méthode de mesure de la cohésion lexicale
fondée sur le calcul d’une probabilité généralisée. La valeur de la cohésion lexicale d’un segment S, est vue
comme la mesure de la capacité d’un modele de langue A, — c’est-a-dire une distribution de probabilités —
appris sur le segment S, a prédire les mots contenus dans le segment. Cette déﬁnition de la cohésion
lexicale nécessite de calculer, dans un premier temps, un modele de langue A, pour chaque segment S, du
texte a segmenter, puis de déterminer la probabilité des mots du segment S,, étant donné A,.

Modéle de langue Un modele de langue n-gramme est un modele probabiliste qui assigne une proba-
bilité a toute séquence de 12 mots d’un texte. Le modele de langue utilisé pour le calcul de la cohésion
lexicale est un modele unigramme, qui détermine la probabilité d’apparition de chaque mot plein — c’est-
a-dire ici les noms, les adjectifs et les verbes — au sein du texte. Lors de l’estimation du modele de langue
A, d’un segment 3,, on évalue la probabilité d’apparition de chacun des mots du vocabulaire du texte dans
le segment S,. Aﬁn d’éviter que toute la masse de probabilité soit attribuée aux seuls mots apparaissant
dans le segment, on applique un lissage a ce modele de langue dans le but de redistribuer une partie des
probabilités aux mots non observés — le nombre de mots observés dans le segment étant relativement petit

CAMILLE GUINAUDEAU, GUILLAUME GRAVIER, PASCALE SEBILLOT

au regard du nombre de mots dans le texte. Le calcul du modele de langue du segment Si se formalise par

Ai={Pi(“)= aVu€VK}a (1)

Z
avec VK le vocabulaire, de taille K, du texte et  le compte du mot u. Dans le cas habituel, le compte
d’un mot correspond a son nombre d’occurrences dans le segment S,-. La distribution de probabilités est
lissée en incrémentant le compte de chacun des mots de 1. On a donc 21- = K + ZUEVK Ci 

Vraisemblance La seconde étape du calcul de la cohésion lexicale d’un segment consiste a évaluer une
probabilité traduisant a quel point le modele de langue Ai permet d’expliquer les mots contenus dans le

segment S,-, soit M C. (M) + 1
1n(P(Si|Ai)) =  7 (2)
j=1 ‘

avec ni le nombre de mots dans le segment et 1123- le jg mot du segment. Intuitivement cette probabilité
favorise les segments les plus cohérents lexicalement puisque sa valeur est plus importante lorsque les
mots apparaissent plusieurs fois au sein du segment et qu’elle atteint sa valeur minimale lorsque tous les
mots du segment sont différents.

Le calcul de la cohésion lexicale tel que nous venons de le présenter se base uniquement sur la répétition
des mots au sein d’un texte et n’accorde aucune importance au fait que deux mots différents peuvent étre
sémantiquement proches. C’est pourquoi nous proposons une méthode d’intégration de relations séman-
tiques dans le calcul du critere de cohésion lexicale aﬁn de le rendre moins sensible aux problemes liés
aux transcriptions automatiques.

2.2 avec prise en compte des relations sémantiques

L’ intégration de relations sémantiques que nous proposons se fonde sur l’idée que si le mot « voiture », par
exemple, apparait dans un texte thématiquement homogene, alors les probabilités d’apparition des mots
« conduire » ou « automobile » sont plus importantes que celles de mots n’appartenant pas au méme champ
lexical. Nous intégrons donc les relations sémantiques au niveau du calcul du modele de langue de facon
a ce que, pour chaque mot 111; rencontré dans le texte, son compte  soit incrémenté ainsi que celui
des mots qui lui sont sémantiquement liés, proportionnellement a la valeur de leur proximité sémantique
avec le mot Plus formellement, on a pour chaque mot 111;. du segment Si :
C,-(11) = C1-('0) + 7‘(11,w;-) V11 6 VK 11 75 111; ,

avec r(v,  E [0, 1] la proximité sémantique des mots 11 et wj-, dont le calcul est décrit en section 4.

3 Segmentation thématique

Notre objectif n’est pas de mettre au point une nouvelle technique de segmentation thématique, mais de
voir si des méthodes état de l’art sur du texte écrit peuvent tirer proﬁt de l’intégration de relations sé-
mantiques pour traiter des transcriptions automatiques. Nous utilisons donc d’une part la technique de
segmentation proposée dans (Utiyama & Isahara, 2001) et, d’autre part, une technique locale dérivée de
TextTiling, les deux s’appuyant sur une mesure de la cohésion lexicale. L’ utilisation de méthodes aux com-
portements différents nous permet de vériﬁer que l’intégration de relations rend le calcul de la cohésion
lexicale plus robuste aux problemes liés aux transcriptions automatiques, indépendamment de la méthode
de segmentation employée.

UTILISATION DE RELATIONS SEMANTIQUES POUR LA SEGMENTATION THEMATIQUE

Fenétre

m0t_1m0t_2§ ’fn0t1  m0t50 m0t51  ’fn0t100 E Tn0t101 Tn0t102

FIG. 1 — Rapport de vraisemblance généralisé

Méthode globale La méthode de segmentation développée par Utiyama et Isahara consiste a rechercher
la segmentation qui produit les segments les plus cohérents d’un point de vue lexical, tout en respectant
une distribution a priori de la longueur des segments. Son principe est de trouver la segmentation la plus
probable d’une séquence de l unités élémentaires (mots, phrases, ou groupes de soufﬂe) W = W1’ parmi
toutes les segmentations possibles, soit

A

S = argrgI1aXP[W|S]P[S] . (4)

En supposant que P[S{”] = n‘"‘, avec 12 1e nombre de mots du texte et m le nombre de segments, la
probabilité d’un texte W pour une segmentation S = S{” est donnée par

5* : arggnlax Z(1n(P[S,|A,]) — 0z1I1(n)) . (5)
1 i=1
La cohésion lexicale 1n(P[S,-|A,-]) pour le segment S, est calculée comme décrit en section 2. Le facteur
oz permet de controler la taille moyenne des segments retoumés.

Méthode locale La seconde technique de segmentation considérée est adaptée de la méthode TextTi-
ling (Hearst, 1997), qui consiste a évaluer, pour chaque fenétre centrée sur une frontiere potentielle, la
similarité entre la partie droite et la partie gauche de la fenétre. Aﬁn de comparer les deux méthodes de
segmentation, globale et locale, le calcul de la similarité, fondé sur une mesure cosinus dans la technique
originale, a été modiﬁé pour utiliser la meme mesure de cohésion lexicale que pour la méthode globale.
Contrairement a la méthode TextTiling, notre méthode de segmentation locale ne consiste donc pas a com-
parer les parties gauche et droite de la fenétre pour déterminer s’il y a ou non rupture de la cohésion
lexicale mais plutot a calculer le rapport de probabilité entre l’hypothese considérant une frontiere et celle
n’en considérant pas (cf ﬁgure 1).

Ce rapport R, s’il est important, traduit le fait que la cohésion lexicale au sein de la fenétre est meilleure si
le segment motl  motloo est divisé en deux, c’est-a-dire que les vocabulaires des segments motl  m0t50
et m0t51  motloo sont différents. La valeur du rapport R est donnée par :

R = II1(P[’fn0t1  ’ITL0t50|A1D + lI1(P[’fn0t51  m0t100|A2]) — II1(P[’fn0t1  m0t100|A3]) , 

avec 111(P[m0t,-  mot,-+n|A,-]) la cohésion lexicale du segment mot,  mot,-+n calculée comme décrit en
section 2.

La segmentation thématique du texte est ﬁnalement obtenue a partir des valeurs du rapport de vraisem-
blance pour chaque séparation entre deux groupes de soufﬂe. De ces valeurs sont extraits des maxima
locaux par une technique d’extraction des pics dominants qui, s’ils sont supérieurs a un seuil 0, déﬁnissent
une frontiere thématique. Cette méthode permet d’obtenir une valeur de Pk-mesure d’environ 9% sur le
corpus de Choi (pour des segments composés de 9 a 11 phrases). Les résultats sont donc bien meilleurs
que ceux obtenus par TextTiling (Pk-mesure de 48%) sur le meme corpus.

CAMILLE GUINAUDEAU, GUILLAUME GRAVIER, PASCALE SEBILLOT

4 Acquisition et sélection de relations sémantiques

Le choix des relations semantiques integrees dans le calcul de la cohesion lexicale peut avoir une inﬂuence
importante sur les resultats de la segmentation thematique. Nous presentons ici, les methodes d’extraction
et de selection utilisees pour obtenir les relations les plus pertinentes pour notre tache de segmentation.

Acquisition de relations sémantiques Bien que de nombreuses ressources lexicales deja contruites
soient disponibles, elles sont malheureusement souvent liees a certain domaine. Les documents televi-
suels etudies etant multi-domaines, nous avons donc extrait les relations semantiques a partir de corpus.
L’ objectif de cet article etant d’etudier l’inﬂuence de l’integration de relations semantiques et non d’opti-
miser leur extraction, nous avons choisi d’app1iquer des methodes standards aﬁn d’acquerir deux types de
relations : des relations syntagmatiques et des relations paradigmatiques. Les relations syntagmatiques cor-
respondent a des relations de successivite et de contigu'1'te que les mots entretiennent au sein d’une phrase
(exemple : « conduire » et « voiture »). Pour les calculer, nous avons retenu deux indices de force d’as-
sociation couramment utilises : l’information mutuelle IM et l’information mutuelle au cube IM3 (Daille,
1994), ce second indice ayant ete deﬁni aﬁn de reduire l’importance associee aux evenements rares par
IM. Le second type de relation reunit deux mots presentant une composante commune importante du point
de vue du sens, comme « voiture » et « automobile ». Ces relations paradigmatiques sont calculees en as-
sociant a chaque couple de mots le cosinus de l’angle entre les vecteurs de voisinage des occurrences des
deux mots. Nous obtenons ainsi une liste de synonymes, d’hyperonymes, etc., non differencies.

Pour l’ensemble des methodes d’acquisition, les relations ont ete extraites sur un corpus compose d’articles
du Monde, de l’Humam'te’ et des transcriptions de reference des campagnes Ester I et Ester 2 correspondant
respectivement a 100 et 150 heures de joumaux radiophoniques. Dans ce corpus, lemmatise et normalise,
seuls les noms, adjectifs, et verbes autres que « étre », « avoir » et « falloir » ont ete conserves. Les scores
d’association ont ﬁnalement ete normalises aﬁn d’obtenir des valeurs comprises entre 0 et 1.

Selection de relations sémantiques La question qui se pose alors est de retenir, pour notre tache de
segmentation, les relations semantiques les plus pertinentes parmi tous les liens extraits. Nous explorons
deux methodes de selection :
— conserver les 6 relations ayant les scores les plus eleves tous mots confondus (T011115) ; ces relations sont

appelees « premieres relations » dans la suite de cet article. Dans nos tests, la valeur de 6 peut etre egale

a 5 000, 10 000, 20 000, 50 000 et 90 000;
— conserver un nombre ﬁxe B de relations pour chaque mot (ParM0t5), B prenant les valeurs 2, 3 et 10.
De plus, nous avons remarque que certains mots du corpus, comme « aller », « an », etc., etaient semanti-
quement lies avec un nombre important d’ autres mots. Aﬁn d’eviter de creer des liens semantiques entre de
trop nombreux couples de mots, ce qui conduirait a creer un nombre excessif de liens entre les segments
dans nos techniques de segmentation, nous avons deﬁni une technique de ﬁltrage, Seuil , pouvant étre
associee aux deux methodes de selection. Elle consiste a ignorer les relations semantiques des mots qui
entretiennent un nombre de relations superieur a un certain seuil. La valeur du seuil est egale au nombre
moyen de relations associees aux mots du texte a segmenter multiplie par un parametre 7 prenant les
valeurs 1, 2, 3, 5 ou 10.

Le tableau 1 illustre les 5 relations aux scores d’association les plus eleves rattachees au mot « ciga-
rette » en selectionnant les 90 000 premieres relations, Totalgoooo, et 10 relations par mot, ParM0t10. Nous
constatons que la qualite de ces relations change selon la methode utilisee pour leur extraction. Ainsi,
les relations obtenues grace au score IM correspondent generalement a des evenements rares, 51 tel point
d’ailleurs qu’aucune des relations existant avec le mot « cigarette » n’apparait pas dans les 90 000 pre-

UTILISATION DE RELATIONS SF.MANTIQUES POUR LA SEGMENTATION THEMATIQUE

TAB. 1 — Relations aux scores d’association les plus élevés pour le mot « cigarette »

IM IM3 paradigmatique

Totalgoooo cigarette fumer cigarette cigare
cigarette paquet cigarette gitane

cigarette gauloise
ParM0t10 cigarette chevignon cigarette fumer cigarette cigare
cigarette liggett cigarette paquet cigarette gitane

cigarette altadi cigarette allumer cigarette gauloise
cigarette détaxer cigarette contrebande cigarette clope

mieres relations, alors que les relations IM3 et paradigmatiques semblent plus pertinentes.

5 Résultats

L’ intégration des relations sémantiques pour la segmentation de documents télévisuels a été testée sur deux
corpus. Le premier est constitué de 60 journaux télévisés, d’une durée de 40 minutes chacun, diffusés en
février et mars 2007 sur la chaine de télévision France 2. Le second est composé de 12 émissions de
reportage de 2 heures, « Envoyé Spécial », diffusées sur France 2 entre mars 2008 et janvier 2009, et de
16 émissions de reportage « Sept a Huit », de 1 heure chacune, programmées sur la chaine TF1 entre
septembre 2008 et février 2009. Ces deux corpus ont été déﬁnis pour prendre en compte les différences
importantes existant entre les deux types d’émissions : nombre de répétitions dans les JT beaucoup moins
important que dans les émissions de reportages, avec une proportion de parole spontanée plus élevée dans
ces derniers, et longueur moyenne des reportages d’« Envoyé Spécial » beaucoup plus grande.

Ces émissions ont été transcrites par un systeme de reconnaissance automatique de la parole, implémenté
pour la transcription de journaux radiophoniques, atteignant un taux d’erreur d’environ 20% sur les don-
nées du corpus Ester 2. Les deux corpus transcrits sont composés respectivement de 12 000 et 11 000
mots pleins. Pour chacune des transcriptions, nous avons supprimé la partie précédant le lancement du
premier reportage, c’est-a-dire la partie constituée des titres du journal ou du sommaire de l’éInission,
ainsi que celle suivant la ﬁn du dernier reportage, ces deux parties tres spéciﬁques perturbant l’algorithme
de segmentation. Cette extraction manuelle aurait pu étre effectuée en utilisant des indices audiovisuels.
Une segmentation de reference a été effectuée en considérant un changement de theme a chaque change-
ment de reportage, bien que ce ne soit pas toujours le cas, notamInent pour le premier corpus. En effet,
les premiers reportages des JT traitent généralement du titre principal du journal et abordent donc tous
le meme theme. Nous obtenons un total de 1180 frontieres thématiques pour le premier corpus et de 141
pour le second. L’ évaluation de nos méthodes de segmentation se fait en considérant comme correcte une
frontiere éloignée de moins de 10 secondes d’une frontiere de référence. Nous utilisons les métriques
précision, rappel et F1-mesure pour chiffrer les résultats de nos algorithmes. Aﬁn de confronter nos dif-
férentes méthodes, nous comparons la valeur de la F1-mesure pour des valeurs de parametre (oz pour la
méthode globale et a pour la méthode locale) conduisant a une segmentation dont la longueur moyenne
des segments est la plus proche de celle de la segmentation de référence.

Nous présentons dans un premier temps les résultats obtenus sur le premier corpus grace a la méthode de
segmentation globale, en analysant les techniques de sélection utilisées pour chaque type de relations. Puis,
nous comparons le comportement des deux méthodes de segmentation face a l’intégration des relations
sémantiques. Enﬁn, nous analysons la portabilité de l’intégration des relations sur le second corpus.

CAMILLE GUINAUDEAU, GUILLAUME GRAVIER, PASCALE SEBILLOT

80
75
70_ 

I
sans relations +

Totalm —9— —
T0tal9000o ' ' " ' '

Totalio + Seuill --><- -- -
Totalgoooo + S euz'l1 —-—

 
 
 
    

rappel 60

50 55 60 65 70

precision

FIG. 2 — Courbes rappel/precision pour l’integration de relations IM3 dans la methode de segmentation
globale sur des journaux televises, obtenues en faisant varier le facteur oz controlant la taille des segments

5.1 Comparaison des techniques de sélection des relations sémantiques

Les deux techniques de selection, eventuellement combinees a une methode de ﬁltrage, ayant ete testees
sur trois types de relations, nous avons obtenu un nombre important de resultats qu’il n’est pas possible
de presenter ici en details. Nous decrivons donc dans cette partie l’inﬂuence generale des techniques de
selection sur les resultats de la segmentation globale.

Information mutuelle (IM) L’ integration de relations semantiques extraites par IM au sein de la methode
de segmentation globale permet d’ameliorer les resultats lorsque la technique de selection ParMot est
utilisee, amelioration proportionnelle au nombre de relations introduites. La methode de selection Total ne
permet pas de faire evoluer la qualite de la segmentation, de fagon positive ou negative. Ceci s’explique
par le fait que les toutes premieres relations calculees sur nos corpus d’apprentissage par le score IM
correspondent a des evenements rares (cf tableau 1) qui n’apparaissent pas dans nos transcriptions et
n’ont donc pas d’inﬂuence sur la valeur de la cohesion lexicale. Finalement, l’association de la technique
ﬁltrant les mots lies a trop d’autres mots a la methode ParMot permet une amelioration supplementaire de
la F1-mesure.

Information mutuelle au cube (IM3) Lorsqu’elles sont appliquees sur des relations IM3, les deux tech-
niques de selection Total et ParMot obtiennent des resultats equivalents : toutes deux deteriorent a la fois
les valeurs de rappel et de precision (cf ﬁgure 2), deterioration d’autant plus marquee que le nombre de
relations introduites est important. Cependant, l’utilisation de la methode de ﬁltrage S euil permet d’ame-
liorer la qualite de la segmentation, et la meilleure valeur de la F1-mesure est obtenue grace a la com-
binaison Totalgoooo + Seuill. L’introduction de trop nombreuses relations semantiques semble donc relier
un nombre excessif de mots et de segments, faisant diminuer la qualite des resultats de la segmentation et
rendant necessaire une limitation du nombre de relations introduites par ﬁltrage.

Relations paradigmatiques L’ introduction de relations paradigmatiques dans la methode de segmentation
globale a un comportement assez similaire a celui observe pour les relations IM3. En effet, les resultats
de la segmentation se degradent avec le nombre croissant de relations introduites et ceci, pour les deux
techniques Total et ParMot. A nouveau, le ﬁltrage des mots auxquels on associe des relations semantiques
permet d’ame1iorer les resultats. Enﬁn, les resultats pour les deux techniques de selection sont, pour ces
relations egalement, tout a fait equivalents, meme si la meilleure valeur de la F1-mesure est ici obtenue

UTILISATION DE RELATIONS SEMANTIQUES POUR LA SEGMENTATION THEMATIQUE

TAB. 2 — Valeursl de la F1-mesure pour l’integration des relations semantiques

Methode globale Methode locale
Corpus JT | reportages JT 1 reportages
Sans relations 59.44 51.09 26.19 26.62
IM ParM0t10 + Seuil5 ParM0t10 + Seuilg, ParM0t10 ParM0t1o + Seuill
61.41 61.42 26.29 39.20
IM3 Totalgoooo + Seuill T0tal5000 + Seuill Totalgoooo ParM0t2 + Seuilg
60.44 62.92 27.11 39.27
Paradigmatiques ParM0t10 + Seuilg ParM0t3 + Seuilg ParM0t10 + Seuilg Totalgoooo + Seuilg
61.27 62.28 28.02 41.54

avec une methode de selection differente, ParM0t1o + Seuilg.

5.2 Comparaison des méthodes de segmentation globale et locale

Bien qu’une augmentation ponctuelle de la valeur de la F1-mesure est obtenue pour l’integration des trois
types de relations dans la methode de segmentation locale, l’ajout de relations semantiques n’a ici que peu
d’inﬂuence sur la qualite des segmentations obtenues, comme nous avons pu l’observer sur les courbes
rappel/precision. Deux facteurs peuvent expliquer ces resultats. Tout d’abord, lors de l’ajout de relations
semantiques au sein de la fenetre glissante, si les valeurs de la cohesion lexicale des trois segments — ceux
situes a droite eta gauche de la fenetre et celui constitue de tous les mots de la fenetre — sont augmentees,
l’integration des relations n’aura que tres peu d’effet sur la valeur du rapport R calcule. Par ailleurs, la
technique d’extraction des maxima locaux utilisee pour deﬁnir les frontieres thematiques peut egalement
permettre d’interpreter ces resultats. En effet, cette technique, tres sensible aux variations, peut proposer
des segmentations differentes alors meme que l’evolution de la valeur de la cohesion lexicale au ﬁl du texte
presente des proﬁls fortement similaires. Enﬁn, nous pouvons constater dans le tableau 2 que les resultats
de la methode locale sont bien moins eleves que ceux de la methode globale. Ceci peut s’expliquer par le
fait que notre corpus de JT est constitue de segments de tailles tres variables et pouvant etre tres petits.
La fenétre glissante peut alors contenir plusieurs segments, ce qui rend la valeur de la cohesion lexicale
au sein de cette fenétre inexploitable, la variabilite de la taille des segments au sein d’un meme corpus
empechant de deﬁnir une taille de fenetre optimale.

5.3 Portabilité de l’intégration de relations sémantiques sur d’autres corpus

En analysant les courbes rappel/precision pour l’ajout de relations semantiques dans la methode locale,
nous constatons que les resultats fournis sur le corpus de reportages sont peu encourageants bien que,
ponctuellement, la valeur de la F1-mesure soit augmentee pour les trois types de relations (tableau 2).
Concernant la methode globale, l’integration d’un grand nombre de relations paradigmatiques et IM3 de-
grade, ici aussi, la qualite de la segmentation sauf si on associe un ﬁltrage aux methodes de selection. De
plus, le comportement des relations IM est, lui aussi, similaire puisque la selection Total ne permet pas
d’inﬂuencer la qualite de la segmentation et qu’une selection des relations par mot est necessaire pour
obtenir un impact sur les resultats. Cependant, l’amelioration obtenue lors de l’integration des relations
semantiques sur ce corpus est plus sensible que celle observee sur les JT et ceci pour les deux methodes.
Cette difference s’explique par le fait que le nombre de repetitions est ici plus important. A chaque repe-

1Mesures obtenues pour des valeurs de parametres conduisant a une segmentation pour laquelle la longueur des segments
est la plus proche de celle de la segmentation de reference.

CAMILLE GUINAUDEAU, GUILLAUME GRAVIER, PASCALE SEBILLOT

tition d’un mot, des relations sémantiques vont étre intégrées, renforcant la valeur de la cohésion lexicale
pour les segments cohérents. L’ augmentation de la valeur de la F1-mesure doit toutefois étre analysée avec
prudence car le nombre de frontieres dans ce corpus est beaucoup plus faible.

6 Conclusion

Nous avons proposé une méthode pour intégrer des relations sémantiques dans une mesure de la cohé-
sion lexicale et montré que l’utilisation de ces relations dans une méthode de segmentation thématique
globale améliore les résultats pour des documents télévisuels transcrits, compensant en partie l’absence
de répétitions dans les documents considérés et les erreurs de transcription. Nous avons mis en évidence
l’importance de limiter le nombre de relations introduites aﬁn d’empécher qu’elles ne relient entre eux
un nombre excessif de segments. Aﬁn d’améliorer nos méthodes de segmentation de documents oraux,
nous privilégions deux pistes utilisant des caractéristiques des transcriptions automatiques. La premiere
exploite les mesures de conﬁance associées a chacun des mots de la transcription - correspondant a la
probabilité que le mot soit correctement transcrit - aﬁn de mieux gérer les erreurs de transcription. L’in-
troduction de ces seules mesures dans de précédents travaux, nous a permis d’améliorer la F1-mesure de
+1.5 sur le corpus de journaux télévisés. En associant relations sémantiques et mesures de conﬁance, nous
espérons combiner leurs gains et rendre ainsi notre méthode plus adaptée aux transcriptions automatiques.
La seconde piste consiste a fonder notre segmentation non pas sur une seule transcription, c’est-a-dire la
meilleure hypothese fournie par le systeme de reconnaissance automatique de la parole, mais sur la liste
des n meilleures hypotheses qu’il propose.

Références

AMARAL R. & T RANCOSO I. (2003). Topic indexing of TV broadcast news programs. In 6th Interna-
tional Workshop on Computational Processing of the Portuguese Language.

BEEFERMAN D., BERGER A. & LAFFERTY J. (1999). Statistical models for text segmentation. Machine
Learning, 34(1-3), 177-210.
CHRISTENSEN H., KOLLURU B. & ET al. Y. G. (2005). Maximum entropy segmentation of broadcast
news. In 30th IEEE I CASSP.

DAILLE B. (1994). Approche mixte pour l ’extraction automatique de terminologie .' statistiques lexicales
etﬁltres linguistiques. PhD thesis, Université de Paris 7.

FERRET O. (2002). Segmenter et structurer thématiquement des textes par l’utilisation conjointe de
collocations et de la récurrence lexicale. In 9e Actes de Traitement Automatique des Langues Naturelles.

HEARST M. A. (1997). Texttiling : segmenting text into multi-paragraph subtopic passages. Computa-
tional Linguistics, 23, 33-64.

MULBREGT P. V., CARP 1., GILLICK L., LowE S. & YAMRoN J. (1999). Segmentation of automati-
cally transcribed broadcast news text. In DARPA Broadcast News Workshop.

OSTENDORF M., FAVRE B. & ET al. R. G. (2008). Speech segmentation and spoken document proces-
sing. IEEE Signal Processing Magazine, 25(3), 59-69.

STOLCKE A., SHRIBERG E. & ET al. D. H.-T. (1999). Combining words and speech prosody for
automatic topic segmentation. In DARPA Broadcast News Workshop.

UTIYAMA M. & ISAHARA H. (2001). A statistical model for domain-independent text segmentation. In
9th ACL.

