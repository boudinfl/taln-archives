TALN 2010, Montreal, 19-23 juillet 2010

Une évaluation de l’impact des types de textes sur la tache de
segmentation thématique

Clementine Adam 1 Philippe Muller 2 Cecile Fabre 1
(1) CLLE / Universite de Toulouse
(2) IRIT / Universite de Toulouse & Alpage / INRIA
adam@univ-tlse2.fr, muller@irit.fr, cfabre@univ-tlse2.fr

Résllmé. Cette etude a pour but de contribuer a la deﬁnition des objectifs de la segmentation thema-
tique (ST), en incitant a prendre en consideration le parametre du type de textes dans cette tﬁche. Notre
hypothese est que, si la ST est certes pertinente pour traiter certains textes dont l’organisation est bien
thematique, elle n’est pas adaptee a la prise en compte d’autres modes d’organisation (temporelle, rheto-
rique), et ne peut pas étre appliquee sans precaution a des textes tout-venants. En comparant les perfor-
mances d’un systeme de ST sur deux corpus, an organisation thematique "forte" et "faible", nous montrons
que cette tache est effectivement sensible a la nature des textes.

Abstract. This paper aims to contribute to a better deﬁnition of the requirements of the text seg-
mentation task, by stressing the need for taking into account the types of texts that can be appropriately
considered. Our hypothesis is that while TS is indeed relevant to analyse texts with a thematic organi-
sation, this task is ill-ﬁtted to deal with other modes of text organisation (temporal, rhetorical, etc.). By
comparing the performance of a TS system on two corpora, with either a "strong" or a "weak" thematic
organisation, we show that TS is sensitive to text types.

M0tS-CléS I Segmentation thematique, organisation textuelle, cohesion lexicale, voisins distribu-
tionnels.

Keywords: Text segmentation, textual organisation, lexical cohesion, distributional neighbours.

1 Introduction

La tache de segmentation thematique (ST), qui consiste a delimiter des segments textuels de contenu ho-
mogene sur la base d’indices de rupture lexicale, a fait la preuve de sa faisabilite et de son apport dans
differentes taches de TAL (Hearst, 1997; Chen et al. , 2009). Meme si certains travaux ont cherche a prendre
en compte des indices de rupture (cue-phrases) de differentes natures — par exemple (Litman & Passon-
neau, 1995) —, cette tache repose generalement sur l’hypothese que les textes s’organisent principalement
selon un plan thematique, chaque theme se singularisant par le recours a un vocabulaire sufﬁsamment spe-
ciﬁque pour le distinguer des autres. Cette hypothese est pourtant loin de faire consensus dans les travaux
menes sur le discours, qui montrent au contraire que l’organisation thematique n’est qu’un mode d’orga-
nisation des textes parmi d’autres (Pery-Woodley & Scott, 2006). Elle n’est pas pertinente pour tous les
types de textes, et elle n’est pas exclusive, pour un meme texte, d’autres types d’organisation alternatifs.
En particulier, de nombreux travaux ont etudie les textes sous l’angle de leur organisation rhetorique, qui

CLEMENTINE ADAM, PHILIPPE MULLER, CECILE FABRE

s’articule autour de segments identiﬁés comme des unités fonctionnelles déterminées par des buts argu-
mentatifs spéciﬁques, ‘argumentative moves’ (Swales, 1990), ‘argumentative zoning’ (Teufel, 1999). Ces
études ont montré que différents segments sont caractérisables par des faisceaux de traits linguistiques de
nature essentiellement grammaticale, et ne considerent pas forcément la répartition du vocabulaire comme
un critere discriminant (Biber et al., 2007). De fait, il ne va pas du tout de soi que l’on puisse aborder par
les mémes méthodes de segmentation des textes organisés thématiquement, rhétoriquement, temporelle-
ment, voire par une combinaison de ces modes, et que les indices lexicaux soient toujours discriminants
pour placer des ruptures entre segments textuels. Les tableaux 1 et 2 donnent des exemples de textes tirés
de Wikipédia de maniere a illustrer cette diversité des modes d’organisation. La liste des titres de section
de premier niveau donne un bon apercu de la facon dont le texte s’organise. Le tableau 1 montre des textes
dont l’organisation thématique est manifeste.

Le Malawi Le panda géant
- Histoire - Historique

- Politique - Légende

- Géographie - Alimentation
- Economic - Reproduction
- Démographie - Protection

- Culture

TABLE 1 — Exemples d’organisation textuelle thématique

Le tableau 2 montre d’abord un exemple d’organisation temporelle, typique des biographies, qui se clot par
une partie bilan. Les deux autres textes (leadership et mythe) illustrent un mode de progression rhétorique
(sur le principe des ’moves’ de Swales) qui permet dans ces deux cas d’organiser la présentation d’une
notion selon un schéma argumentatif similaire : d’abord déﬁnir la notion, puis présenter une typologie,
enﬁn détailler certaines de ses instances.

Laurent Truguet Leadership Mythe

- J eunesse jusqu’a la Rév. - Terminologie - Déﬁnition

- sous la Révolution - Types de leadership - Aspects du mythe

- L’ Empire - Caractéristiques du leadership - Typologie et éléments du mythe
- sous la Monarchie - Le leadership de droit et de fait - Postérité du mythe

- Le bilan - Le paradigme des leaderships multiples

TABLE 2 — Exemples d’organisation textuelle non thématique

L’ impact des types de textes sur la procédure de ST a rarement été pris en considération par les travaux qui
mettent en oeuvre cette tache — exception faite de (Ferret et al., 1998) —, au point que, comme le déplorent
(Bestgen & Piérard, 2006), les memes algorithmes sont parfois appliqués a une tache de segmentation de
texte et de délimitation de textes concaténés. Les expériences de ST sont généralement menées sur des
types de textes qui se prétent intuitivement a cette approche — par exemple les articles encyclopédiques sur
les villes chez (Chen et al., 2009) ou (Adam & Morlane-Hondere, 2009) —, sans qu’on cherche a établir
explicitement la nature des textes qui sont adaptés a la tache.

Notre objectif est d’intégrer le parametre du type de textes dans la tache de segmentation en comparant
les performances d’un systeme de ST sur deux groupes de textes, déterminés selon leur propension a
s’organiser plutot thématiquement ou a obéir a d’autres principes de présentation - rhétorique, temporelle.
Nous montrons dans cet article que la tache de ST est effectivement sensible a la nature des textes, en

IMPACT DES TYPES DE TEXTES SUR LA TACHE DE SEGMENTATION THEMATIQUE

montrant que meme une approche relativement na'1've de la notion de type de texte permet de faire émerger
des différences signiﬁcatives de performances. Apres avoir brossé un panorama des méthodes actuelles en
ST (section 2), nous décrivons le systeme de ST que nous avons Inis en oeuvre pour cette étude (section
3); nous présentons ensuite l’expérimentation qui vise a comparer ses performances selon les deux types
de textes (section 4), et discutons les résultats obtenus (section 5).

2 La segmentation thématique : un panorama des méthodes

La segmentation thématique a pour but le découpage linéaire d’un texte en unités présentant une cohérence
autour d’un sujet. La grande majorité des approches de ST se fondent sur la méthode initiée par (Hearst,
1997) : le texte est divisé en blocs contigus correspondant a une unité ﬁxée a l’avance (un nombre n de
mots, de phrases ou de paragraphes), puis on déﬁnit une fenétre glissante qui parcourt le texte linéairement
et permet de calculer un score de similarité a chaque intersection entre blocs dans le texte. Une méthode de
segmentation s’attache alors a trouver les points ou la similarité présente des évolutions fortes, interprétées
comme des indications de rupture de la continuité thématique. Une alternative a cette approche par pavage
(tiling) est de supposer des themes sous-jacents qu’il s’agit de détecter : chaque unité du texte considéré
est rapportée a un ou plusieurs themes, et la segmentation consiste a trouver ces themes (Chen et al., 2009;
Ferret, 2007). Les themes peuvent étre prédits par des « topic models » (Chen et al., 2009), une forme
d’Allocation de Dirichlet Latente (ADL), qui sont associés a des distributions lexicales différentes, ou
bien par des associations lexicales calculées a partir des textes, par exemple par un clustering en amont
(Ferret, 2007). Une fois les themes identiﬁes pour chaque unité de texte, les segments correspondent aux
blocs d’unités contigues partageant le meme theme.

Dans les approches par pavage, la mesure de similarité entre blocs la plus simple est basée sur le nombre de
répétitions lexicales (souvent uniquement les noms), rapporté au nombre des unités présentes.Les variantes
consistent alors a jouer sur le lissage de l’évolution de la similarité en prenant en compte des contextes
différents (plus de blocs voisins, et plus d’interactions entre eux) ou sur la normalisation des liens de
cohésion lexicale, avec des mesures de lfidf locales par exemple (Malioutov & Barzilay, 2006). Mais la
similarité peut également dériver d’autres sources : collocations (Ferret, 2002), similarité dans un espace
lexical de dimension réduite par exemple par analyse sémantique latente (Choi et al., 2001; Bestgen &
Piérard, 2006) — proche de l’ADL mentionnée ci-dessus —, ou bien similarité de distribution des unités
lexicales (Adam & Morlane-Hondere, 2009), toutes méthodes qui sont censées apporter une forme de
lissage pour prévenir d’éventuels fossés dans les répétitions de forme, dans la mesure o1‘1 elles font émerger
une large gaInme de liens de proximité sémantique.

Dans le systeme que nous avons développé et que nous décrivons dans la section suivante, nous comparons
deux types de similarité, en utilisant d’une part les répétitions simples et d’autre part une mesure de
similarité distributionnelle. Nous aurions pu faire appel a d’autres approches utilisant des similarités plus
riches, mais pour notre propos (la comparaison des performances d’un systeme de ST en fonction des
types de textes), il est sufﬁsant que notre systeme ait des performances comparables a celles de l’état de
l’art. Par ailleurs les approches génératives (topics models) ont l’inconvénient de devoir étre entrainées sur
des textes représentatifs des themes a retrouver, ce qui rend la technique un peu circulaire dans le cadre de
ce que nous cherchons a étudier 1.

1. Nous pourrons de toute fagon étendre la portée de la comparaison dans une étude plus large, notamment en transposant
l’approche de Ferret au réseau lexical induit par la similarité distributionnelle.

CLEMENTINE ADAM, PHILIPPE MULLER, CECILE FABRE

3 Description du systeme de segmentation thématique mis en oeuvre

Notre systeme de ST, developpe dans le cadre du projet VOILADIS 2, utilise une approche lineaire, a la
maniere de (Hearst, 1997), et fait appel pour le calcul des scores de similarite lexicale a une base de
voisins distributionnels. La base de voisins distributionnels utilisee a ete generee a partir d’un corpus
constitue de l’ensemble des articles de la version francophone de Wikipedia, soit plus de 470000 articles
pour 194 millions de mots. Le programme d’analyse distributionnelle est lance en aval des sorties de
l’analyse SYNTEX (Bourigault, 2007). Les triplets syntaxiques <gouverneur, relation, dependant> (ex :
<depart,POUR,destination>) foumissent les donnees permettant de rapprocher les paires de voisins en
utilisant la mesure de Lin.

Nous donnons ci-dessous le detail de notre chaine de traitement :

— Les liens de voisinage, eventuellement ponderes par leur score de Lin, sont projetes sur les textes; les
repetitions sont egalement prises en compte, et dotees d’un score de 1. Quelques parametres de ﬁltrage
des voisins sont testes : seuils sur le nombre de voisins que peut avoir un mot, et sur l’ecart quadratique
moyen de ces voisins a la position du mot (ainsi, les mots ayant peu de voisins ou des voisins proches
de leur position dans le texte seront favorises)

— Le texte est parcouru par une fenétre glissante, aﬁn de calculer localement des scores de cohesion.
L’unite de segmentation, ainsi que la taille de la fenétre en nombre d’unites, sont parametrables. Les
unites de segmentation possibles sont : (i) la phrase; (ii) le bloc de mots de taille ﬁxe. Par exemple, si
l’unite choisie est la phrase, et que la taille de la fenétre est ﬁxee a 6, on calculera a la ﬁn de chaque
phrase un score base sur le nombre de liens entretenus par le groupe de trois phrases qui precede, et le
groupe de trois phrases qui suit (ﬁg. 1); ce nombre est normalise par le nombre de liens possibles (le
produit des noms, verbes et adjectifs situes a gauche et a droite de la fenétre).

. . . | phrase k-2 I I phrase k-1 | | phrasek | | phrase k+1 | |phrase k+2 | |phrase k+3 | . . .
l

Score(k-1)

Score(k)
Score(k+1)

FIGURE 1 — Representation de la fenétre glissante avec -fen=3 et -unit=phrase

— La courbe des scores obtenue est lissee; nous avons opte pour un lissage gaussien3, avec deux para-
metres ajustables : le nombre d’iterations et le degre du lissage. La ﬁgure 2 presente les courbes brute
et lissee pour l’article Wikipedia Bulgarie. Les barres verticales indiquent la segmentation de reference
(c’est-a-dire les positions des titres de section).

— Les vallees (creux de la courbe) dont la profondeur depasse un ecart-type a la moyenne des profondeurs
sont considerees comme correspondant aux ruptures du texte. Ces ruptures, qui, selon l’unite choisie,
se trouvent dans le meilleur des cas a la frontiere d’une phrase, mais peuvent egalement intervenir en
plein milieu d’une phrase, sont ramenees a la frontiere de paragraphe la plus proche, ce qui produit le
texte segmente ﬁnal.

On constate que de nombreux parametres sont ajustables dans notre systeme; nous les recapitulons dans

le tableau 3. C’est pourquoi dans la phase experimentale de notre etude, qui fait l’objet de la prochaine

section, nous recourons a un corpus de developpement pour optimiser ces parametres.

2. Projet ﬁnance par le PRES de Toulouse
3. En fait une estimation par noyau, le noyau etant gaussien; il correspond ici a une moyenne sur le Voisinage de chaque

IMPACT DES TYPES DE TEXTES SUR LA TACHE DE SEGMENTATION THEMATIQUE

— bu|garie_score.txtD
— Iissage gaussien degre 5

0.5 —

0.0 —

_0_5 ,

 

—1.c —

—1.5 —

 

4'00 2b 4'0 so so 160 120

FIGURE 2 — Exemple de courbe avec lissage

Parametre Description Valeurs
—unit unité de segmentation phrase / bloc
—bloc taille du bloc <nb mots>
—fen taille de la demi—fenetre glissante <nb blocs>
—it nb d’itérations du lissage <nb>
—deg degré du lissage <nb>
—lin pondération des liens par score de Lin oui / non
—ﬁltNb seuil sur le nb max de voisins différents par item non ou <nb voisins>

—ﬁltPos seuil sur l’écart moyen des voisins a la position de l’item non ou <nb tokens>

TABLE 3 — Parametres de notre systeme de ST

4 Procédure et évaluation

L’hypothese que nous souhaitons Valider par cette experience est que le recours a la ST se justiﬁe pour
des textes dont la structuration est effectivement ressentie comme thématique, mais n’est pas motivé pour
aborder d’autres modes d’organisation textuelle. Ainsi, nous Voulons inciter a mieux déﬁnir quel peut étre
l’objet de la tache de ST, eta ne pas appliquer cette tache sans précaution Ea des textes tout—Venant.

Caractérisation du corpus utilisé Nous avons pour cette experience constitué deux sous—corpus a par-
tir de la Version d’aVril 2007 de l’encyclopédie en ligne Wikipédia (nous avons choisi de sélectionner des
textes qui appartiennent tous au corpus sur lequel la ressource lexicale a été construite). Les articles ont
été extraits de maniere automatique, sur la base de criteres de sélection ﬁxés par nous. Les criteres de
sélection sont les suivants : pour étre retenu, un article doit avoir au minimum 1000 mots, au moins 4 titres
de sections (qui fournissent la segmentation de référence), et un maximum de 2 niveaux de profondeur de
titres (une profondeur trop importante aurait amené Ea faire des choix délicats quant aux titres retenus pour
la segmentation de référence) ; il doit également appartenir Ea une liste de catégories établie. Nous avons
en effet pris le niveau des catégories déﬁnies dans l’encyclopédie comme critere de répartition des textes
dans les deux sous—corpus. Le sous—corpus Ea organisation thématique forte (corpus THEM) rassemble des
textes consacrés a la description de pays, de Villes et d’animaux, dont on sait qu’ils se prétent généralement

point, pondérée selon la distance au point selon une gaussienne.

CLEMENTINE ADAM, PHILIPPE MULLER, CECILE FABRE

bien a une organisation thématique. Le sous-corpus a organisation thématique faible (corpus NON-THEM)
réunit des biographies, dont l’organisation est typiquement temporelle, et des textes présentant des notions
abstraites, des concepts, pour lesquels nous avons montré (tab. 2) que l’approche thématique est gene-
ralement mal adaptée. L’intervention humaine se concentre donc en amont de la constitution du corpus,
par la déﬁnition des criteres de sélection et de repartition dans les sous-corpus. Aucun traitement n’est
effectué en aval (post-sélection, nettoyage, etc.). La caractérisation des corpus obtenus est donnée dans le
tableau 4. Nous précisons pour chaque sous-corpus le nombre de paragraphes, qui correspond au nombre
de segments potentiels pour notre systeme de ST et le nombre de titres de premier niveau, c’est-a-dire le
nombre de ruptures dans notre segmentation de référence.

nb textes nb mots nb para. nb seg. (titre niV=1) nb seg/txt nb seg/para
corpus THEM 344 578346 10953 3051 8, 869 0,279
corpus NON-THEM 210 387941 6454 1182 5, 629 0,183

TABLE 4 — Caractérisation des corpus THEM et NON-T HEM

Corpus de développement et optimisation des paramétres La procedure de segmentation décrite sec-
tion 3 dépend de nombreux parametres dont les conséquences ne sont pas toujours prédictibles a priori.
Beaucoup d’auteurs ﬁxent des parametres similaires selon des criteres empiriques pas toujours explicites.
Nous avons choisi d’isoler une partie du corpus de départ pour l’utiliser comme un corpus de développe-
ment explicite, sur lequel nous avons fait varier un certain nombre de parametres aﬁn d’ajuster la segmen-
tation. Pour cela, nous avons extrait au hasard un peu moins de 10% du corpus rassemblé initialement,
en prenant autant (i. e. 21) de textes des sous-corpus THEM et NON-THEM (rappelons que le corpus initial
n’est pas tout a fait équilibré ; nous avons équilibré celui de développement pour ne pas favoriser la classe
majoritaire). Les variations faites sur les 8 parametres sujet de l’optiIr1isation ont généré plus de 2000
conﬁgurations.Nous avons conservé la conﬁguration ayant obtenu les meilleurs résultats selon l’indice
classique WindowDiff (noté WD) de comparaison de segmentation; elle est donnée dans le tableau 5.

-unit -bloc -fen -it -deg -lin -ﬁ1tNb -ﬁ1tPos
bloc 10 mots 10 blocs 2 3 non 10 Voisins max. 500 tokens

TABLE 5 — Conﬁguration de parametres retenue

Evaluation Pour évaluer les résultats de la segmentation, nous prenons comme référence les positions
des titres de premier niveau au sein des articles; pour comparer les résultats du systeme de ST a cette
référence, nous appliquons les mesures classiques pour cette tache : les indices Pk et WindowDiff. Ces
mesures sont moins strictes sur les positions des bornes de segments que la précision et le rappel, qui ne
permettent pas de juger de la proximité d’une prédiction avec la borne réelle. Les deux mesures Pk et
WD « adoucissent » l’évaluation en estimant le nombre moyen de bornes correctes dans une fenétre de
taille donnée projetée sur le texte. Nous avons ajouté une mesure proposée par (Bestgen, 2009), appelée
par lui « distance de Hamming généralisé » et qui est en fait une distance d’édition avec des coefﬁcients
particuliers pour les coﬁts d’insertion/d’effacement/de déplacement, rapportée au nombre de points de
coupure possibles. Elle est notée “edit” dans nos tables de résultats. La distance d’édition est censée
corriger certains biais de WD, elle-meme censée corriger certains biais de Pk; nous ne rentrons pas dans
les détails ici, les mesures étant relativement cohérentes entre elles sur nos résultats 4. Ces mesures étant

4. On peut se référer a (Georgescul et al., 2006) pour une discussion de la pertinence des procedures d’éVa1uation de la ST.

IMPACT DES TYPES DE TEXTES SUR LA TACHE DE SEGMENTATION THEMATIQUE

souvent difﬁciles a interpréter et a comparer, la table 6 donne les résultats pour la pire conﬁguration, la
conﬁguration moyenne et la meilleure conﬁguration, que nous allons appliquer au reste de notre corpus. Il
faut noter que ces mesures sont des mesures de distance, la distance de la reference a elle-meme est donc
0., et un score plus bas indique une plus grande proximité avec la référence.

conﬁguration pk wd edit nb seg/txt

référence 0,000 0,000 0,000 7,67
meilleure 0,294 0,299 1,61 1 5,27
moyenne 0,321 0,329 1,787 5,18
pire 0,352 0,369 1,983 6,47

TAB LE 6 — Résultats sur le corpus de développement avec différentes conﬁgurations de parametres
5 Résultats et analyse

Nous avons appliqué notre systeme de ST, avec la conﬁguration de parametres optimisée sur le corpus de
développement, sur les deux sous-corpus THEM et NON-THEM. Les tables 7 et 8 synthétisent les résultats.
Nous donnons deux résultats pour notre systeme, selon les types de liens de cohésion lexicale pris en
compte : répétitions simples de lemmes, ou voisinage distributionnel. Nous avons en outre généré deux
baselines simpliﬁées qui permettent de donner une idée des écarts que l’on peut avoir sur les mesures
Pk et WD, qui ne sont pas nécessairement simples a interpréter. La premiere baseline (nommée plus bas
« hasard exact ») place des ruptures au hasard, mais en nombre correspondant a la référence. Elle permet de
controler la facilité de se rapprocher des vraies bornes par rapport au nombre moyen de segments rapporté
a la taille du texte. Une deuxieme baseline (« hasard bruité ») proche consiste a perturber le nombre exact
de ruptures, en le faisant varier au hasard dans un intervalle de 30% du vrai nombre de ruptures.

Méthode Pk WD edit nb seg/txt
référence 0 0 0 7,89
baseline "hasard bruité" 0,3659 0,3738 1,6492 9,46
baseline "hasard exact" 0,3417 0,3452 1,5789 7,89
répétitions 0,3114 0,3144 1,5907 4,93
Voisins 0,3091 0,3129 1,5837 5,09

TABLE 7 — Résultats pour le sous-corpus THEM

Méthode Pk WD edit nb seg/txt
référence 0 0 0 8,07
baseline "hasard bruité" 0,3569 0,3616 1,8032 6,68
baseline "hasard exact" 0,3149 0,3181 1,5645 8,07
répétitions 0,3612 0,3662 1,8846 5,08
Voisins 0,3613 0,3676 1,9291 5,16

TABLE 8 — Résultats pour le sous-corpus NON-THEM

Une autre indication de la représentativité des scores pourrait étre prise dans la littérature, meme si la
variété des approches, des entrées et des évaluations (vrai textes ou concaténations artiﬁcielles) doit inciter
a la prudence. Si l’on se réfere au tres récent (Chen et al., 2009), qui opere sur un corpus similaire a une
partie du notre (les articles de villes dans le Wikipédia anglais), l’état de l’art précédent représenté par

CLEMENTINE ADAM, PHILIPPE MULLER, CECILE FABRE

(Eisenstein & Barzilay, 2008) atteint un Pk de 0,317 et un WD de 0,376 sur ce corpus, avec la connaissance
du nombre de segments; l’approche de (Chen et al., 2009) a base de topic models enrichis de contraintes
globales atteint quant a elle sur leur meilleure conﬁguration les tres bons scores de 0,28 pour le Pk et
de 0,25 pour le WD, sans connaissance du nombre de segments, mais en posant une borne supérieure
sur le nombre de themes présents dans tout le corpus (ﬁxée a 10 ou 20 themes), ce qui limite un peu la
généralisation.

Au vu de nos résultats, on constate que l’hypothese globale d’une différence entre les deux types de
textes THEM et NON-THEM se vériﬁe assez nettement, quelle que soit la métrique considérée, et que
les algorithmes de segmentation choisis sont meilleurs sur les textes du sous-corpus THEM, meme si les
variances (non rapportées dans le tableau) sont importantes.

Pour évaluer les différences entre méthodes, (Chen et al., 2009) afﬁrment que les tests de signiﬁcativité
statistique sur cette tache ne sont pas standardisés, et ils n’en reportent pas. Ceux qui font de tels tests
utilisent un t-test sans préciser s’il est apparié ou pas, (Choi et al., 2001; Galley et al., 2003; Ferret, 2007).
Nous avons pour notre part fait le test des rangs signés de Wilcoxon entre les séries de scores des baselines
et des méthodes par cohésion, appariées par texte, test qui ne suppose rien sur la distribution a priori
des scores, au contraire du t-test. Alors qu’on observe des valeurs de p<0,01 pour la différence entre les
baselines et les algorithmes de segmentation sur l’expérience THEM, la différence n’est pas signiﬁcative
pour les textes du sous-corpus NON-THEM (et on constate que les variances sont plus fortes). La baseline
exacte dans le cas NON-THEM présente des résultats étonnants, dont il faudrait vériﬁer s’ils ne sont pas
directement liés au nombre de prédictions plus élevé que fait cette méthode (il s’agirait alors d’un effet
secondaire indésirable des mesures de comparaison de segmentation).

Une hypothese secondaire de ce travail était que les liens induits par similarité distributionnelle étaient
plus informatifs et devaient avoir un impact sur l’évaluation globale. Concemant cet aspect, on ne peut
que constater la proximité des scores sur les deux sous-corpus (et le test de Wilcoxon n’indique pas de
différence signiﬁcative).

I-/3tant donnée la forte variance que nous avons observée sur les résultats, y compris sur le sous-corpus
THEM, nous avons évalué les résultats par catégories Wikipédia a l’intérieur des corpus THEM et NON-
THEM (ces résultats sont récapitulés dans le tableau 9). On constate que les résultats des deux sous-corpus

theme Pk WD edit nb par./seg. nb par. nb textes
animaux 0,2794 0,2803 1,4076 0,1651 25,5724 145

pays 0,3443 0,3472 1,7695 0,1223 40,7353 136
concepts 0,3488 0,3510 1,8377 0,1632 30,4706 68

Villes 0,3508 0,3541 1.7610 0,1348 31,1250 32
personnes 0,3738 0,3777 1.9062 0,1778 26,6132 106
autres NON-THEM 0,4041 0,4112 1,7337 0,1655 31,7333 15

TABLE 9 — Résultats par sous-catégories par Pk/WD croissant

se reportent sur les catégories qui les composent, a l’eXception de la catégorie concepts qui obtient des
résultats légerement meilleurs que ceux de la catégorie villes. Encore une fois les variances sont fortes.
Il s’avere que notre découpage volontairement grossier a priori (dans un souci de ne pas trop biaiser
l’étude) pourrait s’afﬁner — a condition de poser clairement les parametres de ce que nous avons appelé
pour l’instant le caractere thématique fort ou faible des textes —, mais qu’il semble valide.

IMPACT DES TYPES DE TEXTES SUR LA TACHE DE SEGMENTATION THEMATIQUE

6 Conclusion et perspectives

Nous avons montre dans cette etude que les types de textes ont un impact important sur la ST, et qu’il s’agit
donc d’un parametre a ne pas negliger dans le cadre de cette tache. Neanmoins, le bilan de l’experience
menee, s’il comporte la conﬁrmation de l’hypothese de depart, doit étre Initige par des resultats effectifs
sur la tache. Meme si les resultats sont proches de ceux de l’etat de l’art sur le corpus THEM (surtout
si on tient compte du fait que le nombre de segments n’est jamais donne), ils montrent des variances
tres fortes sur les textes, et n’ont pu conﬁrmer le role d’une similarite lexicale plus ﬁche que la simple
repetition de formes. I1 ressort de l’observation du corpus que les donnees que nous avons recueillies
etaient ﬁnalement assez heterogenes, avec des sections de longueurs tres differentes qui ont pose de gros
problemes aux approches qui se basent sur un niveau de variation moyen. La diversite des niveaux de
ﬁnalisation des articles de Wikipedia explique en particulier la succession de paragraphes tres developpes
et de paragraphes reduits a une seule phrase.

Concernant la segmentation de reference, la subdivision par sections n’est pas toujours le bon mode de
segmentation. On trouve beaucoup de sections heterogenes sur le plan thematique parce que la repartition
thematique est faite au niveau des sous-sections (ex : une section « Domaines inﬂuences par le positi-
visme » se decline en sous-sections : « medecine », « philosophie », « enseignement », « droit », etc.).
L’ interét de prendre la structuration en titres comme segmentation de reference etait de foumir facilement
des donnees annotees, et nous avions bien sﬁr conscience du bruit que cela devait entrainer par rapport a
la tache evaluee. Cela nous a fourni une premiere analyse qui nous incite a reprendre ces donnees pour
aller vers une evaluation moins artiﬁcielle. Mais au-dela d’un simple nettoyage qui court le risque d’étre
biaise par l’objectif, on peut aussi poser le probleme autrement et partir de l’observation des endroits o1‘1
les programmes coupent, pour chercher a determiner si ces lieux sont « interpretables », plut6t que de
chercher un alignement avec une segmentation de reference problematique.

Enﬁn, la question du mode de differenciation des textes a traiter se pose egalement. Le fait de choisir de
comparer des textes appartenant a un meme genre textuel (l’article d’encyclopedie), limite leur diversite.
La distinction que nous avons consideree se situe au niveau du sujet traite. C’est un premier point d’entree,
qui n’est pas entierement satisfaisant. Le rapport que nous avons pose au prealable entre categorie de sujet
et type d’organisation n’est pas systematiquement veriﬁe : si les articles traitant de personnalites sont
quasi systematiquement organises temporellement, certaines notions sont malgre tout traitees de maniere
au moins partiellement thematique. Une etude privilegiant cette fois une distinction par genre de textes
permettrait d’etablir un classement sur des criteres plus ﬁables, et d’opposer des textes au fonctionnement
plus marque, renforgant sans doute le contraste deja observe.

References

ADAM C. & MORLANE-HONDERE F. (2009). Detection de la cohesion lexicale par voisinage distribu-
tionnel : application a la segmentation thematique. In Actes du colloque RECITAL, Senlis, France.

BESTGEN Y. (2009). Quel indice pour mesurer l’efﬁcacite en segmentation de textes ? In Actes de
TALN’09, Senlis, France.

BESTGEN Y. & PIERARD S. (2006). Comment evaluer les algorithmes de segmentation automatiques ?

Essai de construction d’un materiel de reference. Actes de TALN .' Verbum ex machina, Louvain-la-neuve,
6, 407-414.

CLEMENTINE ADAM, PHILIPPE MULLER, CECILE FABRE

BIBER D., CONNOR U. & UPTON T. (2007). Discourse on the move .' Using corpus analysis to describe
discourse structure. John Benjamins Publishing Co.

BOURIGAULT D. (2007). Un analyseur syntaxique operationnel .' Syntex. CNRS & Université de
Toulouse-Le Mirail.

CHEN H., BRANAVAN S., BARZILAY R. & KARGER D. (2009). Content Modeling Using Latent Per-
mutations. Journal of Artiﬁcial Intelligence Research, 36, 129-163.

CHOI F. Y. Y., WIEMER-HASTINGS P. & MOORE J. (2001). Latent semantic analysis for text segmen-
tation. In Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing,
p. 109-117, Pittsburgh.

EISENSTEIN J. & BARZILAY R. (2008). Bayesian unsupervised topic segmentation. In EMNLP ’08 .-
Proceedings of the Conference on Empirical Methods in Natural Language Processing, p. 334-343,
Morristown, NJ, USA : Association for Computational Linguistics.

FERRET O. (2002). Segmenter et structurer thématiquement des textes par l’utilisation conjointe de
collocations et de la recurrence lexicale. In TALN’02 .' 9e confe’rence sur le TraitementAutomatique des
Langues Naturelles, p. 155-164, Nancy, France.

FERRET O. (2007). Finding document topics for improving topic segmentation. In Proceedings of
the 45th Annual Meeting of the Association of Computational Linguistics, p. 480-487, Prague, Czech
Republic : Association for Computational Linguistics.

FERRET 0., GRAU B. & MASSON N. (1998). Thematic segmentation of texts : two methods for two
kinds of texts. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguis-
tics and I 7th International Conference on Computational Linguistics-Volume I, p. 392-396 : Association
for Computational Linguistics.

GALLEY M., MCKEOWN K. R., FOSLER-LUSSIER E. & J ING H. (2003). Discourse segmentation of
multi-party conversation. In E. HINRICHS & D. ROTH, Eds., Proceedings of the 41st Annual Meeting of
the Association for Computational Linguistics (ACL-03), p. 562-569, Sapporo, Japan.

GEORGESCUL M., CLARK A. & ARMSTRONG S. (2006). An Analysis of Quantitative Aspects in
the Evaluation of Thematic Segmentation Algorithms. In Proceedings of the 7th SIGdial Workshop on
Discourse and Dialogue, p. 144-151, Sydney, Australia : Association for Computational Linguistics.
HEARST M. A. (1997). TextTiling : segmenting text into multi-paragraph subtopic passages. Computa-
tional Linguistics, 23(1), 33-64.

LITMAN D. & PASSONNEAU R. (1995). Combining multiple knowledge sources for discourse seg-
mentation. In Proceedings of the 33rd annual meeting on Association for Computational Linguistics, p.
108-115 : Association for Computational Linguistics.

MALIOUTOV I. & BARZILAY R. (2006). Minimum cut model for spoken lecture segmentation. In ACL-
44 .' Proceedings of the 21 st International Conference on Computational Linguistics and the 44th annual
meeting of the Association for Computational Linguistics, p. 25-32, Morristown, NJ, USA : Association
for Computational Linguistics.

PERY-WOODLEY M.-P. & SCOTT (2006). Discours et Document : traitements automatiques. Numéro
thématique. revue T.A.L., 47(2), 7-19.

SWALES J . (1990). Genre analysis .' English in academic and research settings. New York :Cambridge
University Press.

TEUFEL S. (1999). Argumentative Zoning .' Information Extraction from Scientiﬁc Text. PhD thesis,
University of Edinburgh.

