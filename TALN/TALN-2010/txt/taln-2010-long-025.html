<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>&#201;valuation automatique de r&#233;sum&#233;s avec et sans r&#233;f&#233;rence</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>&#201;valuation automatique de r&#233;sum&#233;s avec et sans r&#233;f&#233;rence
</p>
<p>Juan-Manuel Torres-Moreno1, 2 Horacio Saggion3 Iria da Cunha1, 4
</p>
<p>Patricia Vel&#225;zquez-Morales5 Eric SanJuan1
(1) LIA, Universit&#233; d&#8217;Avignon et des Pays de Vaucluse, Avignon, France
</p>
<p>(2) Ecole Polytechnique de Montr&#233;al, (Qu&#233;bec) Canada
(3) DTIC, Universtitat Pompeu Fabra, Barcelona, Espagne
(4) IULA, Universitat Pompeu Fabra, Barcelona, Espagne
</p>
<p>(5) VM Labs, Avignon, France
</p>
<p>juan-manuel.torres@univ-avignon.fr, {horacio.saggion, iria.dacunha}@upf.edu
</p>
<p>R&#233;sum&#233;. Nous &#233;tudions diff&#233;rentes m&#233;thodes d&#8217;&#233;valuation de r&#233;sum&#233; de documents bas&#233;es sur le
contenu. Nous nous int&#233;ressons en particulier &#224; la corr&#233;lation entre les mesures d&#8217;&#233;valuation avec et sans
r&#233;f&#233;rence humaine. Nous avons d&#233;velopp&#233; FRESA, un nouveau syst&#232;me d&#8217;&#233;valuation fond&#233; sur le contenu
qui calcule les divergences entre les distributions de probabilit&#233;. Nous appliquons notre syst&#232;me de com-
paraison aux diverses mesures d&#8217;&#233;valuation bien connues en r&#233;sum&#233; de texte telles que la Couverture, Res-
ponsiveness, Pyramids et Rouge en &#233;tudiant leurs associations dans les t&#226;ches du r&#233;sum&#233; multi-document
g&#233;n&#233;rique (francais/anglais), focalis&#233; (anglais) et r&#233;sum&#233; mono-document g&#233;n&#233;rique (fran&#231;ais/espagnol).
</p>
<p>Abstract. We study document-summary content-based evaluation methods in text summarization
and we investigate the correlation among evaluation measures with and without human models. We apply
our comparison framework to various well-established content-based evaluation measures in text summa-
rization such as Coverage, Responsiveness, Pyramids and Rouge studying their associations in various
text summarization tasks including generic (English/French) and focus-based (English) multi-document
summarization and generic multi and single-document summarization (French/Spanish). The research is
carried out using the new content-based evaluation framework FRESA to compute the divergences among
probability distributions.
</p>
<p>Mots-cl&#233;s : Mesures d&#8217;&#233;valuation, R&#233;sum&#233; automatique de textes.
</p>
<p>Keywords: Evaluation measures, Text Automatic Summarization.
</p>
<p>1 Introduction
</p>
<p>L&#8217;&#233;valuation des r&#233;sum&#233;s produits de mani&#232;re automatique a toujours &#233;t&#233; une question complexe et contro-
vers&#233;e du Traitement Automatique de la Langue (TAL). Au cours des derni&#232;res ann&#233;es, des &#233;valuations
&#224; grande &#233;chelle, ind&#233;pendantes des concepteurs des syst&#232;mes, ont vu le jour et plusieurs mesures d&#8217;&#233;va-
luation ont &#233;t&#233; propos&#233;es. En ce qui concerne l&#8217;&#233;valuation des syst&#232;mes de r&#233;sum&#233; automatique, deux
campagnes d&#8217;&#233;valuation ont d&#233;j&#224; &#233;t&#233; men&#233;es par l&#8217;agence am&#233;ricaine DARPA (Defense Advanced Re-
search Projects Agency). La premi&#232;re, intitul&#233;e SUMMAC, s&#8217;est d&#233;roul&#233;e de 1996 &#224; 1998 sous l&#8217;&#233;gide
du programme TIPSTER (Mani et al., 2002), et la deuxi&#232;me, intitul&#233;e DUC (Document Understanding
Conferences) (Over et al., 2007) a suivi de 2000 &#225; 2007. Depuis 2008 c&#8217;est la Text Analysis Conference</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>TORRES-MORENO ET AL.
</p>
<p>(TAC) (TAC, 2008) qui a pris la suite et est le forum pour l&#8217;&#233;valuation des diff&#233;rentes technologies d&#8217;acc&#232;s
&#224; l&#8217;information textuelle, y compris le r&#233;sum&#233; de texte. Les &#233;valuations du r&#233;sum&#233; de texte sont de deux
types : extrins&#232;que et intrins&#232;que (Sp&#228;rck Jones &amp; Galliers, 1996). Dans une &#233;valuation extrins&#232;que, les
r&#233;sum&#233;s sont &#233;valu&#233;s dans le contexte d&#8217;une t&#226;che sp&#233;cifique r&#233;alis&#233;e par un humain ou une machine. Dans
l&#8217;&#233;valuation intrins&#232;que, les r&#233;sum&#233;s sont &#233;valu&#233;s par rapport &#224; une r&#233;f&#233;rence ou mod&#232;le id&#233;al. SUMMAC
a suivi un paradigme d&#8217;&#233;valuation extrins&#232;que et DUC/TAC ont suivi celui de l&#8217;&#233;valuation intrins&#232;que.
Afin d&#8217;&#233;valuer intrins&#232;quement les r&#233;sum&#233;s, un r&#233;sum&#233; candidat (peer) est compar&#233; &#224; un ou plusieurs r&#233;-
sum&#233;s de r&#233;f&#233;rence (models). DUC a utilis&#233; l&#8217;interface SEE qui permet aux juges humains de comparer
un peer aux models. Les juges attribuent ainsi une note de couverture au r&#233;sum&#233; candidat et la note finale
(score) est la moyenne des notes obtenues. Le score final peut alors &#234;tre utilis&#233; pour &#233;tablir un classement
(ranking) des syst&#232;mes de r&#233;sum&#233; automatique (r&#233;sumeurs). Dans le cas du r&#233;sum&#233; orient&#233; par une requ&#234;te
(par exemple, lorsque le r&#233;sum&#233; doit r&#233;pondre &#224; une ou &#224; un ensemble de questions) un score d&#8217;ad&#233;quation
de la r&#233;ponse Responsiveness est assign&#233; au r&#233;sum&#233;. Ce score &#233;value la mani&#232;re dont le r&#233;sum&#233; r&#233;pond
aux questions. Puisque la comparaison manuelle des r&#233;sum&#233;s candidats avec ceux de r&#233;f&#233;rence est un pro-
cessus ardu et co&#251;teux, des recherches ont &#233;t&#233; men&#233;es ces derni&#232;res ann&#233;es sur les proc&#233;dures d&#8217;&#233;valuation
automatique fond&#233;es sur le contenu. Les premi&#232;res &#233;tudes utilisaient des mesures de similarit&#233; telles que
le cosinus (avec ou sans pond&#233;ration) pour comparer les r&#233;sum&#233;s candidats et ceux de r&#233;f&#233;rence (Donaway
et al., 2000). Diverses mesures de Couverture du vocabulaire telles que les n-grammes ou la plus longue
sous-s&#233;quence commune entre le candidat et le mod&#232;le ont &#233;t&#233; propos&#233;es (Radev et al., 2003). La mesure
d&#8217;&#233;valuation des syst&#232;mes de traduction automatique BLEU (Papineni et al., 2002) a &#233;t&#233; &#233;galement test&#233;e
en r&#233;sum&#233; de texte par Pastra &amp; Saggion (2003). Les conf&#233;rences DUC ont adopt&#233; ROUGE (Lin, 2004) pour
l&#8217;&#233;valuation du r&#233;sum&#233; fond&#233;e sur le contenu. Il a &#233;t&#233; montr&#233; que les classements des syst&#232;mes g&#233;n&#233;r&#233;s par
certaines mesures ROUGE (par exemple, ROUGE-2 qui utilise 2-grammes) ont une bonne corr&#233;lation avec
les classements produits par couverture. Ces derni&#232;res ann&#233;es, la m&#233;thode d&#8217;&#233;valuation PYRAMIDS a &#233;t&#233;
introduite par Nenkova &amp; Passonneau (2004). PYRAMIDS est bas&#233;e sur la distribution de l&#8217;informativit&#233;
(content) d&#8217;un ensemble de r&#233;sum&#233;s de r&#233;f&#233;rence. Les unit&#233;s informatives (Summary Content Units, SCU)
sont d&#8217;abord identifi&#233;es dans les r&#233;sum&#233;s de r&#233;f&#233;rence, puis chacune re&#231;oit un poids &#233;gal au nombre de
r&#233;f&#233;rences contenant la m&#234;me unit&#233;. Les SCU des r&#233;sum&#233;s candidats identifi&#233;es sont align&#233;es contre celles
des r&#233;f&#233;rences, puis pond&#233;r&#233;es. Le score PYRAMIDS attribu&#233; aux candidats est le rapport entre la somme
des poids de ces unit&#233;s et la somme des poids du meilleur r&#233;sum&#233; id&#233;ale possible avec le m&#234;me nombre
d&#8217;unit&#233;s SCUs des candidats. Les scores PYRAMIDS sont aussi utilis&#233;s pour le classement des syst&#232;mes.
Nenkova &amp; Passonneau (2004) ont montr&#233; que les scores PYRAMIDS produisent de classements fiables
lorsque plusieurs (4 ou plus) r&#233;f&#233;rences sont utilis&#233;es et que les classements PYRAMIDS sont en corr&#233;-
lation avec ceux produits par ROUGE-2 et ROUGE-SU4 (ROUGE avec skip 2-grammes). Cependant cette
m&#233;thode n&#233;cessite la cr&#233;ation de r&#233;f&#233;rences et l&#8217;identification, l&#8217;alignement et la pond&#233;ration des SCU dans
les r&#233;f&#233;rences et dans les candidats. Nenkova &amp; Passonneau (2004) ont propos&#233; d&#8217;utiliser directement le
document complet &#224; des fins de comparaison et ont argument&#233; que les mesures bas&#233;es sur le contenu,
qui comparent le document entier au r&#233;sum&#233;, pourraient &#234;tre des substituts acceptables &#224; celles utilisant
les r&#233;sum&#233;s de r&#233;f&#233;rence. Une nouvelle m&#233;thode d&#8217;&#233;valuation de syst&#232;mes de r&#233;sum&#233; sans r&#233;f&#233;rence a &#233;t&#233;
r&#233;cemment propos&#233;e (Louis &amp; Nenkova, 2009). Elle est bas&#233;e sur la comparaison directe de l&#8217;informa-
tion contenue entre les r&#233;sum&#233;s et leurs documents. Louis &amp; Nenkova (2009) ont &#233;valu&#233; l&#8217;efficacit&#233; de la
mesure th&#233;orique de Jensen-Shannon (JS) (Lin, 1991) pour le classement des syst&#232;mes dans les t&#226;ches
de r&#233;sum&#233; multi-document focalis&#233; sur une requ&#234;te. Elles ont montr&#233; que les classements produits par
PYRAMIDS et ceux produits par la mesure JS sont corr&#233;l&#233;s, m&#234;me si on ne tenait pas compte de la re-
qu&#234;te dans l&#8217;&#233;valuation, c&#8217;est &#224; dire que l&#8217;on ram&#232;ne en premi&#232;re approximation la t&#226;che de r&#233;sum&#233; guid&#233;
&#224; celle de r&#233;sum&#233; g&#233;n&#233;rique. On peut cependant &#233;tudier l&#8217;effet de la mesure JS dans une r&#233;elle t&#226;che de</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;VALUATION AUTOMATIQUE DE R&#201;SUM&#201;S AVEC ET SANS R&#201;F&#201;RENCE
</p>
<p>r&#233;sum&#233; g&#233;n&#233;rique multi-document en se r&#233;f&#233;rent &#224; la t&#226;che 2 de DUC&#8217;04, ce que nous faisons ici. Nous
nous int&#233;ressons aussi &#224; d&#8217;autres types de r&#233;sum&#233;s tels que le r&#233;sum&#233; biographique (DUC&#8217;04 t&#226;che 5), le
r&#233;sum&#233; d&#8217;opinions (TAC&#8217;08 OS) et le r&#233;sum&#233; dans de langues autres que l&#8217;anglais. Dans cet article, nous
pr&#233;sentons une s&#233;rie d&#8217;exp&#233;riences visant une meilleure compr&#233;hension de la pertinence de la divergence
JS pour le classement des syst&#232;mes de r&#233;sum&#233;. Nous avons effectu&#233; des exp&#233;riences avec la mesure JS
et nous avons v&#233;rifi&#233; que, pour certaines t&#226;ches (telles que celles &#233;tudi&#233;es par Louis &amp; Nenkova (2009)
il existe une forte corr&#233;lation entre PYRAMIDS, Responsiveness et la divergence JS, mais comme nous
allons le montrer plus loin, il existe aussi des jeux de donn&#233;es de r&#233;f&#233;rence pour lesquelles la corr&#233;lation
n&#8217;est pas si forte. Nous pr&#233;sentons aussi des exp&#233;riences sur des jeux de donn&#233;es en espagnol et en fran&#231;ais
qui montrent aussi une corr&#233;lation positive entre les mesures JS et ROUGE. Cet article est organis&#233; de
la fa&#231;on suivante : dans la section 2 nous pr&#233;sentons les travaux existants dans le domaine de l&#8217;&#233;valua-
tion du r&#233;sum&#233; bas&#233;e sur le contenu, ce qui nous permet de pr&#233;ciser le point de d&#233;part de nos recherches.
Dans la section 3, nous d&#233;crivons la m&#233;thodologie suivie, les outils ainsi que les ressources utilis&#233;s lors
des exp&#233;riences. Dans la section 4, nous pr&#233;sentons les exp&#233;riences men&#233;es et les r&#233;sultats obtenus sur les
diff&#233;rents corpora et t&#226;ches. En section 5 comprend une discussion sur ces r&#233;sultats, avant de conclure et
de pr&#233;senter quelques perspectives et travaux futurs.
</p>
<p>2 Etat de l&#8217;art
</p>
<p>Donaway et al. (2000) est un des premiers travaux qui mentionne l&#8217;utilisation de mesures fond&#233;es sur le
contenu. Il a pr&#233;sent&#233; une m&#233;thode d&#8217;&#233;valuation des syst&#232;mes de r&#233;sum&#233; automatique au moyen de calculs
de rappel et de variantes de la distance du cosinus entre le texte et le r&#233;sum&#233; produit. Ce dernier calcul est
clairement une mesure fond&#233;e sur le contenu. Ils ont montr&#233; qu&#8217;il y avait une corr&#233;lation faible entre les
classements produits par le calcul du rappel, mais que les mesures bas&#233;es sur le contenu produisaient des
classements fortement corr&#233;l&#233;s. Ceci a ouvert la voie aux mesures fond&#233;es sur le contenu, en comparant
le contenu du r&#233;sum&#233; automatique &#224; ceux des r&#233;sum&#233;s de r&#233;f&#233;rence. Saggion et al. (2002) ont pr&#233;sent&#233; un
ensemble de mesures d&#8217;&#233;valuation bas&#233;es sur la notion de chevauchement du vocabulaire qui inclut les n-
grammes, la similarit&#233; cosinus et la plus longue sous-s&#233;quence commune. Ils les ont appliqu&#233;es au r&#233;sum&#233;
automatique multi-document en anglais et en chinois. Toutefois, ils n&#8217;ont pas &#233;valu&#233; les performances
de ces mesures sur diff&#233;rentes t&#226;ches de r&#233;sum&#233;. Radev et al. (2003) ont &#233;galement compar&#233; diff&#233;rentes
mesures d&#8217;&#233;valuation bas&#233;es sur le chevauchement du vocabulaire. Bien que ces mesures permettaient
de s&#233;parer les syst&#232;mes al&#233;atoires de ceux non-al&#233;atoires, aucune conclusion claire ne s&#8217;est d&#233;gag&#233;e sur
la pertinence des mesures &#233;tudi&#233;es. Un syst&#232;me d&#8217;&#233;valuation de r&#233;sum&#233; bien r&#233;pandu est ROUGE, qui
offre un ensemble de statistiques pour comparer les r&#233;sum&#233;s candidats avec un ensemble de r&#233;f&#233;rences
produites par des experts. Diverses statistiques existent selon le n-gramme utilis&#233; et le type de traitement
appliqu&#233; aux textes d&#8217;entr&#233;e (par exemple lemmatisation, suppression de mots fonctionnels). Lin et al.
(2006) ont propos&#233; une m&#233;thode d&#8217;&#233;valuation bas&#233;e sur l&#8217;utilisation de mesures de divergence entre deux
distributions de probabilit&#233; (la distribution d&#8217;unit&#233;s dans le r&#233;sum&#233; automatique et celle d&#8217;unit&#233;s dans le
r&#233;sum&#233; de r&#233;f&#233;rence). Ils ont &#233;tudi&#233; deux mesures th&#233;oriques d&#8217;information : la divergence de Kullback-
Leibler (KL) (Kullback &amp; Leibler, 1951) et celle de Jensen-Shannon (JS) (Lin, 1991). La divergence
JS est d&#233;finie par :
</p>
<p>DJS(P ||Q) = 1
2
</p>
<p>&#8721;
w
</p>
<p>Pw log2
2Pw
</p>
<p>Pw +Qw
+Qw log2
</p>
<p>2Qw
Pw +Qw
</p>
<p>(1)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>TORRES-MORENO ET AL.
</p>
<p>Ces mesures peuvent &#234;tre appliqu&#233;es &#224; la distribution d&#8217;unit&#233;s dans les r&#233;sum&#233;s des syst&#232;mes P et dans
ceux de r&#233;f&#233;renceQ. La valeur obtenue est utilis&#233;e pour attribuer un score au r&#233;sum&#233; produit. La m&#233;thode a
&#233;t&#233; &#233;valu&#233;e par Lin et al. (2006) sur le corpus DUC&#8217;02, pour les t&#226;ches de r&#233;sum&#233; mono et multi-document.
Une bonne corr&#233;lation a &#233;t&#233; trouv&#233;e entre les mesures de divergence et les deux classements obtenus avec
ROUGE et la couverture. Louis &amp; Nenkova (2009) sont all&#233;es encore plus loin et, comme Donaway et al.
(2000), ont propos&#233; de comparer directement la distribution de mots dans les documents complets avec
celle des mots dans les r&#233;sum&#233;s automatiques afin d&#8217;inf&#233;rer une mesure d&#8217;&#233;valuation bas&#233;e sur le contenu.
Elles ont constat&#233; une forte corr&#233;lation entre les classements produits avec r&#233;f&#233;rences et ceux obtenus sans
r&#233;f&#233;rence. Ce travail est le point de d&#233;part de nos recherches sur la pertinence des mesures qui ne reposent
pas sur des r&#233;f&#233;rences humaines.
</p>
<p>3 Protocole d&#8217;&#233;tude
</p>
<p>La m&#233;thodologie suivie dans cet article refl&#232;te celle adopt&#233;e dans les travaux pass&#233;s (Donaway et al.,
2000; Radev et al., 2003; Louis &amp; Nenkova, 2009). &#201;tant donn&#233; une t&#226;che de r&#233;sum&#233; sp&#233;cifique T , une jeu
de p sp&#233;cifications textuelles :{Ii}p&#8722;1i=0 (par exemple, document(s), question(s), topics) devant guider les
r&#233;sum&#233;s produits, s r&#233;sum&#233;s candidats {SUMi,k}sk=0 par entr&#233;e i, et m r&#233;sum&#233;s de r&#233;f&#233;rence {REFi,j}mj=0
par entr&#233;e i, nous allons comparer les classements produits par diff&#233;rentes mesures d&#8217;&#233;valuation bas&#233;es
sur le contenu, de s syst&#232;mes de r&#233;sum&#233; automatique. Certaines mesures sont utilis&#233;es pour comparer les
r&#233;sum&#233;s automatiques avec n des m r&#233;f&#233;rences humaines :
</p>
<p>MESUREM(SUMi,k, {REFi,j}nj=0) (2)
tandis que d&#8217;autres mesures comparent les r&#233;sum&#233;s candidats avec l&#8217;entr&#233;e ou une partie de l&#8217;entr&#233;e :
</p>
<p>MESUREM(SUMi,k, I &#8242;i) (3)
</p>
<p>o&#249; I &#8242;i est un sous-ensemble des entr&#233;es Ii. On obtient la moyenne des valeurs produites par les mesures
pour chaque r&#233;sum&#233; SUMi,k et pour chaque syst&#232;me k = 0, . . . , s. Ces moyennes induisent un classe-
ment. Ensuite, les classements sont compar&#233;s avec le taux &#961; de corr&#233;lation de Spearman (Siegel &amp; Cas-
tellan, 1998), utilis&#233; pour mesurer le degr&#233; d&#8217;association entre deux variables dont les valeurs servent &#224;
classer des objets. Nous avons choisi d&#8217;utiliser cette corr&#233;lation pour comparer directement les r&#233;sultats
&#224; ceux pr&#233;sent&#233;s par Louis &amp; Nenkova (2009). Les calculs des corr&#233;lations ont &#233;t&#233; effectu&#233;s avec le logi-
ciel Statistics-RankCorrelation-0.121, qui calcule la corr&#233;lation du classement entre deux vecteurs. Nous
avons par ailleurs v&#233;rifi&#233; la bonne conformit&#233; de ces r&#233;sultats avec le test de corr&#233;lation du &#964; de Kendall
calcul&#233; avec le logiciel de statistique R. Les deux tests non param&#233;triques de Spearman et de Kendall ne
se distinguent r&#233;ellement que sur le traitement des ex-&#230;quo. La bonne correspondance entre les deux tests
montre que ces derniers n&#8217;introduisent pas de biais dans nos analyses. Par la suite nous ne mentionneront
que le &#961; de Sperman, plus largement utilis&#233; dans ce domaine.
</p>
<p>3.1 Outils
</p>
<p>Les exp&#233;riences ont &#233;t&#233; r&#233;alis&#233;es en utilisant un nouveau syst&#232;me d&#8217;&#233;valuation de r&#233;sum&#233;s : FRESA &#8211;
FRamework for Evaluating Summaries Automatically&#8211; qui inclut des mesures d&#8217;&#233;valuation fond&#233;es sur
</p>
<p>1CPAN, http://search.cpan.org/~gene/Statistics-RankCorrelation-0.12/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;VALUATION AUTOMATIQUE DE R&#201;SUM&#201;S AVEC ET SANS R&#201;F&#201;RENCE
</p>
<p>la distribution de probabilit&#233;s. De fa&#231;on similaire &#224; ROUGE, FRESA utilise des n-grammes et des skip
n-grammes dans le calcul des distributions de probabilit&#233;. L&#8217;environnement FRESA peut &#234;tre utilis&#233; pour
l&#8217;&#233;valuation de r&#233;sum&#233;s en anglais, fran&#231;ais, espagnol et catalan. Il int&#232;gre filtrage et lemmatisation dans
le pre-traitement des documents. Il a &#233;t&#233; d&#233;velopp&#233; en Perl et mis &#224; disposition de la communaut&#233;2. Nous
utilisons aussi ROUGE pour calculer diverses statistiques des corpora de test.
</p>
<p>3.2 T&#226;ches de r&#233;sum&#233; et corpora
</p>
<p>Nous avons men&#233; nos exp&#233;riences sur les corpus et les t&#226;ches de r&#233;sum&#233; suivants :
1. R&#233;sum&#233; g&#233;n&#233;rique multi-document en anglais (g&#233;n&#233;ration d&#8217;un petit r&#233;sum&#233; &#224; partir d&#8217;un groupe de
</p>
<p>documents pertinents d&#8217;une th&#233;matique donn&#233;e) de DUC&#8217;043, t&#226;che 2 : 50 groupes, 10 documents
par groupe, 294.636 mots ;
</p>
<p>2. R&#233;sum&#233; guid&#233; (Focused-based) en anglais (par exemple, g&#233;n&#233;ration d&#8217;un r&#233;sum&#233; multi-document
guid&#233; par la question &quot;qui est X ?&quot;, o&#249; X est le nom d&#8217;une personne) &#224; partir des donn&#233;es DUC&#8217;04,
t&#226;che 5 : 50 groupes, 10 documents dans chaque plus le nom d&#8217;une personne-cible, 284.440 mots ;
</p>
<p>3. T&#226;che mise &#224; jour, qui consiste &#224; cr&#233;er un r&#233;sum&#233; d&#8217;un groupe de documents et une th&#233;matique.
Deux sous-t&#226;ches sont consid&#233;r&#233;es : a) un premier r&#233;sum&#233; doit &#234;tre produit &#224; partir d&#8217;un ensemble
de documents et d&#8217;une th&#233;matique ; b) une mise &#224; jour du r&#233;sum&#233; doit &#234;tre r&#233;alis&#233;e &#224; partir d&#8217;un
groupe diff&#233;rent (mais li&#233;) en supposant que les documents utilis&#233;s en a) ont &#233;t&#233; lus. Le corpus de
r&#233;sum&#233;s mis &#224; jour TAC&#8217;08 en anglais est utilis&#233; : 48 th&#232;mes, 20 documents chacun, 36.911 mots.
</p>
<p>4. R&#233;sum&#233; d&#8217;opinions o&#249; les syst&#232;mes r&#233;sument les opinions sur une entit&#233; cible dans un ensemble
d&#8217;articles de blogs. Le corpus TAC&#8217;08 OS en anglais4 (tir&#233; de la collection de textes du Blogs06) a
&#233;t&#233; utilis&#233; : 25 groupes et cibles (par exemple, la cible entit&#233; et questions), 1,167.735 mots.
</p>
<p>5. R&#233;sum&#233; g&#233;n&#233;rique mono-document en espagnol, corpus Medicina Cl&#237;nica5 compos&#233; de 50 articles
m&#233;dicaux, chacun avec le r&#233;sum&#233; de l&#8217;auteur correspondant, 124.929 mots ;
</p>
<p>6. R&#233;sum&#233; g&#233;n&#233;rique mono-document en fran&#231;ais, revue Perspectives interdisciplinaires sur le travail
et la sant&#233; (PISTES)6 ; 50 articles et leurs r&#233;sum&#233;s des auteurs, 381.039 mots ;
</p>
<p>7. R&#233;sum&#233; g&#233;n&#233;rique multi-document en fran&#231;ais, corpus RPM27 (journalistique) ; 20 th&#233;matiques dif-
f&#233;rentes compos&#233;es de 10 articles et 4 r&#233;sum&#233;s de r&#233;f&#233;rence par th&#233;matique, 185.223 mots.
</p>
<p>Pour les exp&#233;riences avec les corpora TAC et DUC nous avons utilis&#233; directement les r&#233;sum&#233;s candi-
dats produits par les syst&#232;mes participant aux &#233;valuations (donn&#233;es officielles). Pour les exp&#233;riences en
espagnol et en fran&#231;ais (r&#233;sum&#233; mono et multi-document), nous avons cr&#233;&#233; des r&#233;sum&#233;s &#224; un taux de
compression similaire &#224; ceux de r&#233;f&#233;rence en utilisant les syst&#232;mes suivants :
&#8211; ENERTEX (Fernandez et al., 2007), un syst&#232;me de r&#233;sum&#233; automatique fond&#233;e sur l&#8217;&#233;nergie textuelle ;
&#8211; CORTEX (Torres-Moreno et al., 2002), un syst&#232;me d&#8217;extraction de phrases mono-document multi-
</p>
<p>langue qui combine diff&#233;rentes mesures statistiques de pertinence (angle entre les phrases et la th&#233;-
matique, le poids de Hamming des phrases, etc.) et applique un algorithme de d&#233;cision optimale pour la
s&#233;lection des phrases pertinentes ;
2R&#233;cup&#233;rable &#224; l&#8217;adresse : http://lia.univ-avignon.fr/fileadmin/axes/TALNE/Ressources.html
3http://www-nlpir.nist.gov/projects/duc/guidelines/2004.html
4http://www.nist.gov/tac/data/index.html
5http://www.elsevier.es/revistas/ctl_servlet?_f=7032&amp;revistaid=2
6http://www.pistes.uqam.ca/
7http://labs.sinequa.com/rpm2/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>TORRES-MORENO ET AL.
</p>
<p>&#8211; SUMMTERM (Vivaldi et al., 2010), syst&#232;me de r&#233;sum&#233; des articles m&#233;dicaux bas&#233; sur la terminologie
sp&#233;cialis&#233;e afin de donner un score et un classement aux phrases ;
</p>
<p>&#8211; REG (Torres-Moreno &amp; Ramirez, 2010), syst&#232;me de r&#233;sum&#233; bas&#233; sur un algorithme glouton ;
&#8211; R&#233;sumeur JS, syst&#232;me qui donne un score et un classement aux phrases en consid&#233;rant leur divergence
</p>
<p>Jensen-Shannon par rapport au document source ;
&#8211; Baseline-premi&#232;res phrases, qui s&#233;lectionne les premi&#232;res phrases du document pour construire les
</p>
<p>r&#233;sum&#233;s ;
&#8211; Baseline-al&#233;atoire, s&#233;lectionne les phrases au hasard pour construire les r&#233;sum&#233;s ;
&#8211; Open Text Summarizer (Yatsko &amp; Vishnyakov, 2007), r&#233;sumeur multi-langue bas&#233; sur la fr&#233;quence, et
&#8211; les syst&#232;mes de r&#233;sum&#233; commerciaux multi-langues Word, SSSummarizer8, Pertinence9 et Copernic10.
</p>
<p>3.3 Mesures d&#8217;&#233;valuation
</p>
<p>Les mesures suivantes, qui proviennent de l&#8217;&#233;valuation humaine du contenu des r&#233;sum&#233;s, ont &#233;t&#233; utilis&#233;es
dans nos exp&#233;riences :
&#8211; Couverture : la quantit&#233; d&#8217;information partag&#233;e entre un r&#233;sum&#233; candidat et un r&#233;sum&#233; de r&#233;f&#233;rence
</p>
<p>(Over et al., 2007). Elle a &#233;t&#233; utilis&#233;e dans les campagnes d&#8217;&#233;valuation DUC.
&#8211; Responsiveness : elle classe les r&#233;sum&#233;s sur une &#233;chelle de 5, en indiquant dans quelle mesure le r&#233;sum&#233;
</p>
<p>r&#233;pond &#224; un besoin d&#8217;information pr&#233;cis (Over et al., 2007). Elle est utilis&#233;e dans les t&#226;ches de r&#233;sum&#233;
guid&#233;, comme cela a &#233;t&#233; le cas de certaines t&#226;ches des campagnes DUC et TAC.
</p>
<p>&#8211; PYRAMIDS : elle v&#233;rifie que les unit&#233;s d&#8217;information essentielles (telles qu&#8217;on les trouve dans des
r&#233;sum&#233;s de r&#233;f&#233;rence g&#233;n&#233;r&#233;s par les humains) soient pr&#233;sents dans les r&#233;sum&#233;s candidats. PYRAMIDS
est la mesure d&#8217;&#233;valuation bas&#233;e sur le contenu des campagnes TAC.
</p>
<p>Pour les corpus DUC et TAC, les valeurs de ces mesures sont disponibles et nous les avons utilis&#233;es
directement. Dans nos exp&#233;riences nous avons utilis&#233; les mesures d&#8217;&#233;valuation automatiques suivantes :
&#8211; ROUGE : m&#233;trique de rappel qui emploie des n-grammes comme unit&#233;s de contenu pour comparer les
</p>
<p>r&#233;sum&#233;s candidats vs. ceux de r&#233;f&#233;rence. L&#8217;&#233;quation ROUGE sp&#233;cifi&#233;e dans (Lin, 2004) est la suivante :
</p>
<p>ROUGE-n(R,M) =
&#8721;
m &#8712;M
</p>
<p>&#8721;
n&#8722;gramme&#8712;P countmatch(n&#8722; gramme)&#8721;
m &#8712;M
</p>
<p>&#8721;
count(n-gramme)
</p>
<p>(4)
</p>
<p>o&#249; R est le r&#233;sum&#233; &#224; &#233;valuer, M est l&#8217;ensemble des r&#233;sum&#233;s mod&#232;les (humains), countmatch le nombre
de n-grammes communs en m et P , et count est le nombre de n-grammes dans les r&#233;sum&#233;s mod&#232;les.
Pour nos exp&#233;riences, nous avons utilis&#233; uni-grammes, 2-grammes et skip 2-grammes avec une distance
maximale de 4 (ROUGE-1, ROUGE-2 et ROUGE-SU4). ROUGE est utilis&#233;e pour comparer un r&#233;sum&#233;
candidat &#224; l&#8217;ensemble des r&#233;sum&#233;s de r&#233;f&#233;rence disponibles.
</p>
<p>&#8211; L&#8217;&#233;quation 1 de la divergence de JS a &#233;t&#233; impl&#233;ment&#233;e dans notre syst&#232;me FRESA avec la sp&#233;cification
suivante pour la distribution de probabilit&#233;s de mots w :
</p>
<p>Pw =
CTw
N
</p>
<p>; Qw =
</p>
<p>&#63729;&#63730;&#63731;
CSw
NS
</p>
<p>si w &#8712; S
CTw+&#948;
N+&#948;&#8727;B autrement
</p>
<p>(5)
</p>
<p>o&#249; P est la distribution de probabilit&#233;s des mots w dans le texte T et Q la distribution de probabilit&#233;s
des mots w dans le r&#233;sum&#233; S ; N est le nombre de mots dans le texte et le r&#233;sum&#233; N = NT + NS ,
8http://www.kryltech.com/summarizer.htm
9http://www.pertinence.net
</p>
<p>10http://www.copernic.com/en/products/summarizer</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;VALUATION AUTOMATIQUE DE R&#201;SUM&#201;S AVEC ET SANS R&#201;F&#201;RENCE
</p>
<p>B = 1.5|V |, CTw est le nombre de mots dans le texte et CSw est le nombre de mots dans le r&#233;sum&#233;. Pour
le lissage des probabilit&#233;s du r&#233;sum&#233;, nous avons utilis&#233; &#948; = 0.005. Nous avons &#233;galement impl&#233;ment&#233;
d&#8217;autres m&#233;thodes de lissage (par exemple, Good-Turing Manning &amp; Sch&#252;tze (1999) qui utilise le pa-
ckage statistique de Perl Statistics-Smoothing-SGT-2.1.211) dans FRESA, mais nous ne les utilisons pas
dans les exp&#233;riences rapport&#233;es ici. &#192; l&#8217;instar de l&#8217;approche ROUGE, en plus des uni-grammes de mots
nous avons utilis&#233; des 2-grammes et skip 2-grammes pour le calcul des divergences telles que JS (&#224;
l&#8217;aide des uni-grammes), JS2 (&#224; l&#8217;aide des 2-grammes), JS4 (&#224; l&#8217;aide des skip 2-grammes de ROUGE-
SU4) et JSM qui est la moyenne des JS i. Les mesures JS sont utilis&#233;es pour comparer les r&#233;sum&#233;s
candidats &#224; son document(s) source, dans notre cadre.
</p>
<p>4 Exp&#233;riences et r&#233;sultats
</p>
<p>Dan premier temps, nous avons reproduit les exp&#233;riences pr&#233;sent&#233;es dans Louis &amp; Nenkova (2009) pour
v&#233;rifier que notre impl&#233;mentation JS obtient des r&#233;sultats de corr&#233;lation coh&#233;rents avec ce travail. Nous
avons utilis&#233; les corpus de r&#233;sum&#233;s mis &#224; jour de TAC&#8217;08 pour calculer les mesures JS et ROUGE pour
chaque r&#233;sum&#233; candidat. Nous avons r&#233;alis&#233; deux classements des syst&#232;mes (un pour chaque mesure),
qui ont &#233;t&#233; compar&#233;s aux classements produits selon les scores de PYRAMIDS et de Responsiveness. Les
corr&#233;lations de Spearman ont &#233;t&#233; calcul&#233;es entre les diff&#233;rents classements. Les r&#233;sultats sont pr&#233;sent&#233;s
au tableau 1 avec leur p-value12. Ils confirment une forte corr&#233;lation entre PYRAMIDS, Responsiveness et
JS. Nous avons &#233;galement v&#233;rifi&#233; la corr&#233;lation &#233;lev&#233;e entre JS et ROUGE-2 (0, 83 Spearman, non affi-
ch&#233;e dans le tableau) pour cette t&#226;che et ce corpus. Puis, nous avons men&#233; des exp&#233;riences sur les corpus
</p>
<p>Mesure PYRAMIDS p-value Responsiveness p-value
ROUGE-2 0,96 p &lt; 0, 005 0,92 p &lt; 0, 005
JS 0,85 p &lt; 0, 005 0,74 p &lt; 0, 005
</p>
<p>TAB. 1 &#8211; Corr&#233;lation de Spearman, mesures d&#8217;informativit&#233;, TAC&#8217;08 Update Summarization
</p>
<p>DUC&#8217;04 et TAC&#8217;08 pour la t&#226;che pilote de r&#233;sum&#233;s d&#8217;opinion. Nous avons aussi men&#233; des exp&#233;riences
de r&#233;sum&#233; mono et multi-document en fran&#231;ais et espagnol. En d&#233;pit du fait que les exp&#233;riences pour les
corpus fran&#231;ais et espagnol utilisent moins de syst&#232;mes ou de documents (par exemple, un nombre inf&#233;-
rieur de r&#233;sum&#233;s par t&#226;che) que pour l&#8217;anglais, les r&#233;sultats restent significatifs. Pour DUC&#8217;04, nous avons
calcul&#233; la mesure JS pour chaque r&#233;sum&#233; candidat des t&#226;ches 2 et 5 et nous avons calculer les diff&#233;rents
classements des syst&#232;mes induits par JS, ROUGE, les score de Couverture et Responsiveness. Les dif-
f&#233;rentes valeurs de la corr&#233;lation de classement Spearman pour DUC&#8217;04 sont pr&#233;sent&#233;es aux tableaux 2
(pour la t&#226;che 2) et 3 (pour la t&#226;che 5). Pour la t&#226;che 2, nous avons v&#233;rifi&#233; une forte corr&#233;lation entre JS
et la Couverture. Pour la t&#226;che 5, la corr&#233;lation entre JS et la Couverture est faible, et la corr&#233;lation entre
JS et Responsiveness est faible voire n&#233;gative. Bien que la t&#226;che de r&#233;sum&#233; d&#8217;opinion soit r&#233;cente et
son &#233;valuation un probl&#232;me compliqu&#233;, nous avons d&#233;cid&#233; de comparer les classements JS avec ceux de
PYRAMIDS et Responsiveness sur le corpus de TAC&#8217;08. Les valeurs de la corr&#233;lation de Spearman sont
affich&#233;es au tableau 4. Comme on peut le constater, il existe une corr&#233;lation faible voire n&#233;gative entre
JS et PYRAMIDS ou Responsiveness. La corr&#233;lation entre les classement PYRAMIDS et Responsiveness
</p>
<p>11CPAN, http://search.cpan.org/~bjoernw/Statistics-Smoothing-SGT-2.1.2/
12En statistique, la p-value est le plus petit niveau auquel on rejette l&#8217;hypoth&#232;se nulle.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>TORRES-MORENO ET AL.
</p>
<p>Mesure Couverture p-value
ROUGE-2 0,79 p &lt; 0, 0050
JS 0,68 p &lt; 0, 0025
</p>
<p>TAB. 2 &#8211; Corr&#233;lation de Spearman, mesures JS et ROUGE vs. Couverture, DUC&#8217;04 t&#226;che 2
</p>
<p>Mesure Couverture p-value Responsiveness p-value
ROUGE-2 0,78 p &lt; 0, 001 0,44 p &lt; 0, 05
JS 0,40 p &lt; 0, 050 -0,18 p &lt; 0, 25
</p>
<p>TAB. 3 &#8211; Corr&#233;lation de Spearman, JS et ROUGE vs. Responsiveness et Couverture, DUC&#8217;04 t&#226;che 5
</p>
<p>est &#233;lev&#233;e pour cette t&#226;che (0,71 valeur de corr&#233;lation de Spearman). Pour les exp&#233;riences en espagnol et
</p>
<p>Mesure PYRAMIDS p-value Responsiveness p-value
JS -0,13 p &lt; 0, 25 -0,14 p &lt; 0, 25
</p>
<p>TAB. 4 &#8211; Corr&#233;lation de Spearman, mesure JS vs. Responsiveness et PYRAMIDS, TAC&#8217;08 OS
</p>
<p>en fran&#231;ais mono-document, nous avons lanc&#233; 11 syst&#232;mes de r&#233;sum&#233; multi-langue sur les corpus. Pour
l&#8217;exp&#233;rience en fran&#231;ais multi-document nous avons utilis&#233; 12 syst&#232;mes. Dans tous les cas, nous avons
produit des r&#233;sum&#233;s aux taux de compression proches de ceux des r&#233;sum&#233;s des auteurs (abstracts). Puis
nous avons calcul&#233; les mesures JS et ROUGE pour chaque r&#233;sum&#233; et nous avons obtenu la moyenne des
valeurs pour chaque syst&#232;me. Ces moyennes ont &#233;t&#233; utilis&#233;es pour produire les classements pour chaque
mesure. Nous avons calcul&#233; les corr&#233;lations de Spearman pour toutes les paires de classement. Les r&#233;-
sultats sont pr&#233;sent&#233;s dans les tablaux 5, 6 et 7. Ils montrent une corr&#233;lation moyenne &#224; forte entre les
mesures JS et celles ROUGE. Toutefois, la mesure JS bas&#233;e sur les uni-grammes obtient une corr&#233;lation
inf&#233;rieure &#224; celle qui utilise des n-grammes d&#8217;ordre sup&#233;rieur.
</p>
<p>5 Discussion
</p>
<p>Nos recherches s&#8217;inspirent des r&#233;cents travaux sur l&#8217;utilisation des m&#233;triques d&#8217;&#233;valuation bas&#233;es sur le
contenu qui ne reposent pas sur des r&#233;f&#233;rences humaines, mais qui comparent le contenu des r&#233;sum&#233;s
directement aux entr&#233;es (Louis &amp; Nenkova, 2009). Nous avons obtenu des r&#233;sultats positifs et n&#233;gatifs en
ce qui concerne l&#8217;utilisation directe des documents &#224; r&#233;sumer pour &#233;tablir des mesures d&#8217;&#233;valuation par
contenu. Nous avons v&#233;rifi&#233; que dans les deux vari&#233;t&#233;s de r&#233;sum&#233; multi-document en anglais, g&#233;n&#233;rique et
bas&#233; sur une th&#233;matique, la corr&#233;lation entre les mesures qui utilisent de r&#233;f&#233;rences humaines (PYRAMIDS,
Responsiveness et ROUGE) et une mesure qui n&#8217;utilise pas de r&#233;f&#233;rence (la divergence de JS) est forte.
Nous avons trouv&#233; que la corr&#233;lation entre les m&#234;mes mesures est faible pour le r&#233;sum&#233; d&#8217;informations
biographiques et le r&#233;sum&#233; d&#8217;opinions des blogs. Nous pensons que dans ces cas, les mesures fond&#233;es sur
le contenu devraient prendre en compte en plus du document d&#8217;entr&#233;e, la t&#226;che du r&#233;sum&#233; (par exemple
la repr&#233;sentation texte de la t&#226;che-question, description, etc.) pour mieux &#233;valuer le contenu des candi-
dats (Sp&#228;rck Jones, 2007), puisque la t&#226;che est un facteur d&#233;terminant dans la s&#233;lection du contenu pour</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;VALUATION AUTOMATIQUE DE R&#201;SUM&#201;S AVEC ET SANS R&#201;F&#201;RENCE
</p>
<p>Mesure ROUGE-1 p-value ROUGE-2 p-value ROUGE-SU4 p-value
JS 0,56 p &lt; 0, 100 0,46 p &lt; 0, 100 0,45 p &lt; 0, 200
JS2 0,88 p &lt; 0, 001 0,80 p &lt; 0, 002 0,81 p &lt; 0, 005
JS4 0,88 p &lt; 0, 001 0,80 p &lt; 0, 002 0,81 p &lt; 0, 005
JSM 0,82 p &lt; 0, 005 0,71 p &lt; 0, 020 0,71 p &lt; 0, 010
</p>
<p>TAB. 5 &#8211; Corr&#233;lation de Spearman, JS vs. ROUGE, corpus mono-document Medicina Cl&#237;nica (espagnol)
</p>
<p>Mesure ROUGE-1 p-value ROUGE-2 p-value ROUGE-SU4 p-value
JS 0,70 p &lt; 0, 050 0,73 p &lt; 0, 05 0,73 p &lt; 0, 500
JS2 0,93 p &lt; 0, 002 0,86 p &lt; 0, 01 0,86 p &lt; 0, 005
JS4 0,83 p &lt; 0, 020 0,76 p &lt; 0, 05 0,76 p &lt; 0, 050
JSM 0,88 p &lt; 0, 010 0,83 p &lt; 0, 02 0,83 p &lt; 0, 010
</p>
<p>TAB. 6 &#8211; Corr&#233;lation de Spearman, mesures JS vs. ROUGE, corpus mono-document PISTES (fran&#231;ais)
</p>
<p>le r&#233;sum&#233;. Les exp&#233;riences multi-langue r&#233;alis&#233;es en r&#233;sum&#233; g&#233;n&#233;rique mono-document confirment une
</p>
<p>Mesure ROUGE-1 p-value ROUGE-2 p-value ROUGE-SU4 p-value
JS 0,830 p &lt; 0, 002 0,660 p &lt; 0, 05 0,741 p &lt; 0, 01
JS2 0,800 p &lt; 0, 005 0,590 p &lt; 0, 05 0,680 p &lt; 0, 02
JS4 0,750 p &lt; 0, 010 0,520 p &lt; 0, 10 0,620 p &lt; 0, 05
JSM 0,850 p &lt; 0, 002 0,640 p &lt; 0, 05 0,740 p &lt; 0, 01
</p>
<p>TAB. 7 &#8211; Corr&#233;lation de Spearman, mesures JS vs. ROUGE, corpus multi-document RPM2 (fran&#231;ais)
</p>
<p>forte corr&#233;lation entre les mesures de divergence JS et ROUGE. Il faut noter que ROUGE est en g&#233;n&#233;ral
le logiciel choisi pour pr&#233;senter les r&#233;sultats des &#233;valuations bas&#233;es sur le contenu des r&#233;sum&#233;s en d&#8217;autres
langues que l&#8217;anglais. Pour les exp&#233;riences en espagnol, nous sommes conscients que nous n&#8217;avons qu&#8217;un
seul r&#233;sum&#233; de r&#233;f&#233;rence &#224; comparer avec les r&#233;sum&#233;s candidats. N&#233;anmoins, ces r&#233;f&#233;rences sont les r&#233;su-
m&#233;s d&#8217;auteurs. Comme le montrent les exp&#233;riences conduites par da Cunha et al. (2007), les professionnels
d&#8217;un domaine sp&#233;cialis&#233; (par exemple le domaine m&#233;dical) adoptent des strat&#233;gies similaires pour r&#233;sumer
leurs textes : ils ont tendance &#224; choisir des passages &#224; peu pr&#232;s du m&#234;me contenu pour leurs r&#233;sum&#233;s.
Des &#233;tudes ant&#233;rieures ont montr&#233; qu&#8217;&#224; partir des r&#233;sum&#233;s d&#8217;auteur, il est possible de reformuler fid&#232;le-
ment le contenu du texte (Chuah, 2001). De ce fait, le r&#233;sum&#233; de l&#8217;auteur d&#8217;un article m&#233;dical peut &#234;tre
pris comme r&#233;f&#233;rence pour l&#8217;&#233;valuation des r&#233;sum&#233;s. Dans le corpus en fran&#231;ais PISTES, on suppose une
situation semblable au cas en espagnol.
</p>
<p>6 Conclusions et travail futur
</p>
<p>Dans cet article, nous avons &#233;tudi&#233; la validit&#233; des mesures d&#8217;&#233;valuation du contenu des r&#233;sum&#233;s sans
utilisation de r&#233;sum&#233;s de r&#233;f&#233;rence. Il est &#224; noter qu&#8217;il y a un d&#233;bat sur le nombre de r&#233;f&#233;rences &#224; utiliser
pour &#233;valuer les r&#233;sum&#233;s (Owkzarzak &amp; Dang, 2009). Nous avons men&#233; de multiples exp&#233;rimentations sur</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>TORRES-MORENO ET AL.
</p>
<p>un large spectre de t&#226;ches du r&#233;sum&#233; mono-document g&#233;n&#233;rique au r&#233;sum&#233; des opinions. Les principales
contributions de cet article sont les suivantes :
&#8211; Nous avons montr&#233; que, si l&#8217;on s&#8217;int&#233;resse uniquement au classement des r&#233;sumeurs par informativit&#233;,
</p>
<p>il y a des t&#226;ches o&#249; les r&#233;f&#233;rences pourraient &#234;tre substitu&#233;es par le document complet, tout en obtenant
des classements fiables. Cependant, nous avons aussi constat&#233; que la substitution des r&#233;f&#233;rences par le
document complet n&#8217;est pas toujours souhaitable. Nous n&#8217;avons ainsi trouv&#233; qu&#8217;une faible corr&#233;lation
entre les diff&#233;rents classements dans des t&#226;ches de r&#233;sum&#233; complexes telles que le r&#233;sum&#233; biographique
et le r&#233;sum&#233; d&#8217;opinion.
</p>
<p>&#8211; Nous avons &#233;galement effectu&#233; des exp&#233;riences &#224; grande &#233;chelle en espagnol et en fran&#231;ais qui montrent
une corr&#233;lation positive de moyenne &#224; forte entre les classements des syst&#232;mes obtenus par ROUGE et
les mesures de divergence qui n&#8217;utilisent pas des r&#233;sum&#233;s de r&#233;f&#233;rence.
</p>
<p>&#8211; Nous avons pr&#233;sent&#233; les r&#233;sultats du syst&#232;me FRESA, pour le calcul des mesures bas&#233;es sur la divergence
JS. De m&#234;me que dans ROUGE, FRESA utilise des uni-grammes, 2-grammes et des skip 2-grammes
de mots pour le calcul des divergences.
</p>
<p>Bien d&#8217;autres d&#233;veloppements et exp&#233;rimentations sont envisageables. Ainsi, afin de v&#233;rifier la corr&#233;lation
entre ROUGE et JS, &#224; court terme, nous avons l&#8217;intention d&#8217;&#233;tendre nos recherches &#224; d&#8217;autres langues et
corpora telles que le portugais et le chinois pour lesquels nous avons acc&#232;s aux donn&#233;es et &#224; la techno-
logie pour produire des r&#233;sum&#233;s dans plusieurs langues. Nous envisageons &#233;galement d&#8217;appliquer FRESA
aux autres t&#226;ches de r&#233;sum&#233; de DUC et TAC. &#192; plus long terme, nous pr&#233;voyons d&#8217;int&#233;grer une repr&#233;-
sentation de la t&#226;che/th&#233;matique dans le calcul des mesures. Pour mener &#224; bien toutes ces comparaisons
nous sommes cependant d&#233;pendants de l&#8217;existence de r&#233;f&#233;rences, sans lesquelles on ne peut mesurer la
proximit&#233; entre r&#233;sum&#233;s automatiques et performances humaines. Enfin, FRESA sera utilis&#233; dans la nou-
velle t&#226;che de question-r&#233;ponse (QA) de la campagne INEX (http://www.inex.otago.ac.nz/
tracks/qa/qa.asp) pour l&#8217;&#233;valuation des r&#233;ponses longues. Cette t&#226;che consiste &#224; r&#233;pondre &#224; une
question de type encyclop&#233;dique par extraction et agglom&#233;ration de phrases de Wikip&#233;dia. Ce type de
texte et de question correspond bien &#224; ceux des t&#226;ches pour lesquelles nous avons constat&#233; des taux de cor-
r&#233;lation &#233;lev&#233;s entre les mesures JS et les m&#233;thodes d&#8217;&#233;valuation avec intervention humaine. Par ailleurs,
le calcul de la divergence se fera entre les r&#233;sum&#233;s produits et un ensemble repr&#233;sentatif des passages perti-
nents du Wikip&#233;dia. FRESA sera ainsi utilis&#233; pour comparer trois types de syst&#232;mes appliqu&#233;s &#224; une m&#234;me
t&#226;che : les r&#233;sumeurs multi-documents guid&#233;s par une requ&#234;te, les syst&#232;mes de recherche d&#8217;information
cibl&#233;es (focused IR) et les syst&#232;mes de QA.
</p>
<p>Remerciements. Ce travail a &#233;t&#233; financ&#233; partiellement par la bourse post-doctorale d&#8217;Iria da Cunha (Mi-
nisterio Espa&#241;ol de Ciencia e Innovaci&#243;n, MICINN). H. Saggion remercie les supports des programmes
Ramon y Cajal (MICINN) et Come&#231;a 2010 de l&#8217;Universitat Pompeu Fabra, Barcelone.
</p>
<p>R&#233;f&#233;rences
</p>
<p>CHUAH C.-K. (2001). Types of lexical substitution in abstracting. In ACL Student Research Workshop,
p. 49&#8211;54, Toulouse, France : Association for Computational Linguistics.
</p>
<p>DA CUNHA I., WANNER L. &amp; CABR&#201; M. T. (2007). Summarization of specialized discourse : The case
of medical articles in spanish. Terminology, 13(2), 249&#8211;286.
</p>
<p>DONAWAY R. L., DRUMMEY K. W. &amp; MATHER L. A. (2000). A comparison of rankings produced by
summarization evaluation measures. In NAACL Workshop on Automatic Summarization, p. 69&#8211;78.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;VALUATION AUTOMATIQUE DE R&#201;SUM&#201;S AVEC ET SANS R&#201;F&#201;RENCE
</p>
<p>FERNANDEZ S., SANJUAN E. &amp; TORRES-MORENO J.-M. (2007). Textual Energy of Associative Me-
mories : performants applications of Enertex algorithm in text summarization and topic segmentation. In
MICAI&#8217;07, p. 861&#8211;871.
KULLBACK S. &amp; LEIBLER R. (1951). On information and sufficiency. Ann. of Math. Stat., 22(1), 79&#8211;86.
LIN C.-Y. (2004). ROUGE : A Package for Automatic Evaluation of Summaries. In M.-F. MOENS &amp;
S. SZPAKOWICZ, Eds., Text Summarization Branches Out : ACL-04 Workshop, p. 74&#8211;81, Barcelona.
LIN C.-Y., CAO G., GAO J. &amp; NIE J.-Y. (2006). An information-theoretic approach to automatic
evaluation of summaries. In HLT-NAACL, p. 463&#8211;470, Morristown, USA.
LIN J. (1991). Divergence Measures based on the Shannon Entropy. IEEE Tr. on Inf. Th., 37(145-151).
LOUIS A. &amp; NENKOVA A. (2009). Automatically Evaluating Content Selection in Summarization wi-
thout Human Models. In Empirical Methods in Natural Language Processing, p. 306&#8211;314, Singapore.
MANI I., KLEIN G., HOUSE D., HIRSCHMAN L., FIRMIN T. &amp; SUNDHEIM B. (2002). Summac : a
text summarization evaluation. Natural Language Engineering, 8(1), 43&#8211;68.
MANNING C. D. &amp; SCH&#220;TZE H. (1999). Foundations of Statistical Natural Language Processing.
Cambridge, Massachusetts : The MIT Press.
NENKOVA A. &amp; PASSONNEAU R. J. (2004). Evaluating Content Selection in Summarization : The
Pyramid Method. In HLT-NAACL, p. 145&#8211;152.
OVER P., DANG H. &amp; HARMAN D. (2007). DUC in context. IPM, 43(6), 1506&#8211;1520.
OWKZARZAK K. &amp; DANG H. T. (2009). Evaluation of automatic summaries : Metrics under varying
data conditions. In UCNLG+Sum&#8217;09, p. 23&#8211;30, Suntec, Singapore.
PAPINENI K., ROUKOS S., WARD T., &amp; ZHU W. J. (2002). BLEU : a method for automatic evaluation
of machine translation. In ACL&#8217;02, p. 311&#8211;318.
PASTRA K. &amp; SAGGION H. (2003). Colouring summaries BLEU. In Evaluation Initiatives in Natural
Language Processing, Budapest, Hungary : EACL.
RADEV D. R., TEUFEL S., SAGGION H., LAM W., BLITZER J., QI H., &#199;ELEBI A., LIU D. &amp; DR&#193;BEK
E. (2003). Evaluation challenges in large-scale document summarization. In ACL&#8217;03, p. 375&#8211;382.
SAGGION H., RADEV D., TEUFEL S. &amp; LAM W. (2002). Meta-evaluation of Summaries in a Cross-
lingual Environment using Content-based Metrics. In COLING 2002, p. 849&#8211;855, Taipei, Taiwan.
SIEGEL S. &amp; CASTELLAN N. (1998). Nonparametric Statistics for the Behavioral Sciences. McGraw-
Hill.
SP&#196;RCK JONES K. (2007). Automatic summarising : The state of the art. IPM, 43(6), 1449&#8211;1481.
SP&#196;RCK JONES K. &amp; GALLIERS J. (1996). Evaluating Natural Language Processing Systems, An
Analysis and Review, volume 1083 of Lecture Notes in Computer Science. Springer.
TAC (2008). Proceedings of the Text Analysis Conference, Gaithesburg, Maryland, USA. NIST.
TORRES-MORENO J.-M. &amp; RAMIREZ J. (2010). REG : un algorithme glouton appliqu&#233; au r&#233;sum&#233;
automatique de texte. In JADT&#8217;10 : Rome.
TORRES-MORENO J.-M., VEL&#193;ZQUEZ-MORALES P. &amp; MEUNIER J.-G. (2002). Condens&#233;s de textes
par des m&#233;thodes num&#233;riques. In JADT&#8217;02, volume 2, p. 723&#8211;734, St Malo, France.
VIVALDI J., DA CUNHA I., TORRES-MORENO J.-M. &amp; VEL&#193;ZQUEZ-MORALES P. (2010). Automatic
summarization using terminological and semantic resources. In LREC&#8217;10, Malta.
YATSKO V. &amp; VISHNYAKOV T. (2007). A method for evaluating modern systems of automatic text
summarization. Automatic Documentation and Mathematical Linguistics, 41(3), 93&#8211;103.</p>

</div></div>
</body></html>