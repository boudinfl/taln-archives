<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Jusqu&#8217;o&#249; peut-on aller avec les m&#233;thodes par extraction pour la r&#233;daction de r&#233;sum&#233;s?</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19&#8211;23 juillet 2010
</p>
<p>Jusqu&#8217;o&#249; peut-on aller avec les m&#233;thodes par extraction pour la
r&#233;daction de r&#233;sum&#233;s?
</p>
<p>Pierre-Etienne Genest, Guy Lapalme, Mehdi Yousfi-Monod
RALI-DIRO
</p>
<p>Universit&#233; de Montr&#233;al
B.P. 6128, Centre-Ville
</p>
<p>Montr&#233;al, Qu&#233;bec, Canada, H3C 3J7
{genestpe,lapalme,yousfim}@iro.umontreal.ca
</p>
<p>R&#233;sum&#233;. La majorit&#233; des syst&#232;mes de r&#233;sum&#233;s automatiques sont bas&#233;s sur l&#8217;extraction de phrases,
or on les compare le plus souvent avec des r&#233;sum&#233;s r&#233;dig&#233;s manuellement par abstraction. Nous avons
men&#233; une exp&#233;rience dans le but d&#8217;&#233;tablir une limite sup&#233;rieure aux performances auxquelles nous pouvons
nous attendre avec une approche par extraction. Cinq r&#233;sumeurs humains ont compos&#233; 88 r&#233;sum&#233;s de
moins de 100 mots, en extrayant uniquement des phrases pr&#233;sentes int&#233;gralement dans les documents
d&#8217;entr&#233;e. Les r&#233;sum&#233;s ont &#233;t&#233; not&#233;s sur la base de leur contenu, de leur niveau linguistique et de leur
qualit&#233; globale par les &#233;valuateurs de NIST dans le cadre de la comp&#233;tition TAC 2009. Ces r&#233;sum&#233;s ont
obtenus de meilleurs scores que l&#8217;ensemble des 52 syst&#232;mes automatiques participant &#224; la comp&#233;tition,
mais de nettement moins bons que ceux obtenus par les r&#233;sumeurs humains pouvant formuler les phrases
de leur choix dans le r&#233;sum&#233;. Ce grand &#233;cart montre l&#8217;insuffisance des m&#233;thodes par extraction pure.
</p>
<p>Abstract. The majority of automatic summarization systems are based on sentence extraction, whe-
reas they are usually compared with human-written, abstractive summaries. We have thus conducted an
experiment to establish an upper bound on the expected performance of extractive summarization. 5 hu-
man summarizers completed 88 summaries of no more than 100 words from unedited sentences of the
source documents. The summaries were scored based on their content, linguistic quality and overall res-
ponsiveness by NIST annotators in the context of the TAC 2009 competition. The human extracts received
better scores than all of the 52 participating automatic systems, but much lower scores than those obtai-
ned by human summarizers free to use abstraction. This large gap shows that pure extraction methods are
insufficient for summarization.
</p>
<p>Mots-cl&#233;s : R&#233;sum&#233;s automatiques, r&#233;sum&#233;s par extraction, r&#233;sum&#233;s manuels.
</p>
<p>Keywords: Automatic summarization, extractive summarization, manual summarization.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PIERRE-ETIENNE GENEST, GUY LAPALME, MEHDI YOUSFI-MONOD
</p>
<p>1 Introduction
</p>
<p>Depuis que Luhn (Luhn, 1958) a publi&#233; un premier article sur une technique de r&#233;daction automatique de
r&#233;sum&#233;s &#224; la fin des ann&#233;es 1950, les approches les plus performantes, ann&#233;e apr&#232;s ann&#233;e, ont toujours uti-
lis&#233; l&#8217;extraction de phrases pour la r&#233;daction de r&#233;sum&#233;s. Les phrases extraites ont l&#8217;avantage d&#8217;avoir une
bonne grammaticalit&#233;, mais peuvent souffrir d&#8217;un manque de coh&#233;rence et parfois inclure des r&#233;f&#233;rences
non r&#233;solues. Lors des comp&#233;titions &#224; la Document Understanding Conference 1 (DUC, 2001-2007) et en-
suite &#224; la Text Analysis Conference 2 (TAC, 2008-2009), la tr&#232;s grande majorit&#233; des syst&#232;mes automatiques
de r&#233;daction de r&#233;sum&#233;s recourent syst&#233;matiquement &#224; l&#8217;extraction de phrases 3 plut&#244;t qu&#8217;&#224; l&#8217;abstraction.
On peut se poser la question de savoir s&#8217;il est vraiment souhaitable de concentrer autant d&#8217;efforts &#224; maxi-
miser la qualit&#233; des r&#233;sum&#233;s r&#233;dig&#233;s par extraction. Ceux-ci ont-ils une chance d&#8217;un jour pouvoir atteindre
un niveau de performance comparable &#224; celui des r&#233;sum&#233;s r&#233;dig&#233;s manuellement ? Les syst&#232;mes actuels
d&#8217;extraction atteignent-ils d&#233;j&#224; le maximum qu&#8217;on peut esp&#233;rer avec cette approche ? C&#8217;est ce que nous
avons voulu v&#233;rifier exp&#233;rimentalement dans les travaux que nous pr&#233;sentons dans cet article.
</p>
<p>Lors de ces conf&#233;rences et dans la litt&#233;rature en g&#233;n&#233;ral, ce sont des r&#233;sum&#233;s r&#233;dig&#233;s par des humains qui
servent de base &#224; la comparaison et aux &#233;valuations automatiques. Ces mod&#232;les sont toujours compos&#233;s par
abstraction et, bien qu&#8217;ils d&#233;montrent ad&#233;quatement l&#8217;&#233;cart qui existe entre les performances humaines et
celles des machines, ils ne permettent pas de d&#233;terminer le degr&#233; de performance des syst&#232;mes sur la t&#226;che
sp&#233;cifique d&#8217;extraire les phrases pour r&#233;diger un r&#233;sum&#233;. Notons que dans certains domaines, comme dans
les r&#233;sum&#233;s de documents juridiques dans un contexte l&#233;gal o&#249; on utilise la jurisprudence, les m&#233;thodes
par extraction pure sont souhaitables justement parce qu&#8217;il y a assurance qu&#8217;aucune interpr&#233;tation n&#8217;a &#233;t&#233;
faite lors de la r&#233;daction du r&#233;sum&#233;.
</p>
<p>En somme, un ensemble de r&#233;sum&#233;s par extraction &#233;crits par des humains permet &#224; la fois : a) de v&#233;rifier
l&#8217;&#233;cart de performance th&#233;orique entre les r&#233;sum&#233;s par extraction pure et les r&#233;sum&#233;s par abstraction ; et
b) de comparer la performance des syst&#232;mes automatiques aux performances humaines lorsqu&#8217;ils sont
soumis &#224; des contraintes semblables.
</p>
<p>En collaboration avec les organisateurs de TAC 2009, mais &#224; l&#8217;insu de la majorit&#233; des participants, nous
avons cr&#233;&#233; un tel ensemble de r&#233;sum&#233;s compos&#233;s par extraction, que nous avons intitul&#233; Human EXtrac-
tion for the Text Analysis Conference (HEXTAC) (Genest et al., 2010). Cinq r&#233;sumeurs de notre &#233;quipe,
francophones avec une connaissance d&#8217;usage de l&#8217;anglais, ont particip&#233; &#224; la r&#233;daction des 88 r&#233;sum&#233;s n&#233;-
cessaires pour compl&#233;ter une participation &#224; la comp&#233;tition 2009 de TAC. Les r&#233;sum&#233;s de 100 mots ou
moins ont &#233;t&#233; compos&#233;s uniquement &#224; partir de phrases contenues int&#233;gralement dans les documents &#224;
r&#233;sumer et aucune modification des phrases n&#8217;a &#233;t&#233; faite. En pratique, il s&#8217;agissait de s&#233;lectionner environ
de 3 &#224; 5 phrases sur les 232 (en moyenne) contenues dans les documents d&#8217;entr&#233;e de chaque r&#233;sum&#233;, une
t&#226;che plus difficile et m&#234;me plus p&#233;nible que nous ne l&#8217;imaginions initialement.
</p>
<p>Nous d&#233;crivons la t&#226;che de r&#233;sum&#233; &#224; mener &#224; bien dans le cadre de la comp&#233;tition 2009 de TAC &#224; la section
2. La m&#233;thodologie employ&#233;e pour mener notre exp&#233;rience est expliqu&#233;e &#224; la section 3. Nous pr&#233;sentons
les r&#233;sultats et leur analyse &#224; la section 4 et concluons &#224; la section 5.
</p>
<p>1. duc.nist.gov
2. www.nist.gov/tac
3. Voir par exemple les deux meilleurs syst&#232;mes de TAC 2009, (Long et al., 2010) et (Gillick et al., 2010).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>JUSQU&#8217;O&#217; PEUT-ON ALLER AVEC LES M&#201;THODES PAR EXTRACTION?
</p>
<p>2 T&#226;che &#224; r&#233;aliser
</p>
<p>Nous avons compl&#233;t&#233; l&#8217;exp&#233;rience en suivant les consignes de la t&#226;che de r&#233;daction de r&#233;sum&#233;s de la
conf&#233;rence TAC 2009, organis&#233;e par le National Institute of Standards and Technology (NIST) bas&#233; au
Maryland aux &#201;tats-Unis. Il s&#8217;agissait de r&#233;diger des r&#233;sum&#233;s de 100 mots, multi-documents, orient&#233;s sur
une requ&#234;te et faisant de la mise &#224; jour.
</p>
<p>L&#8217;entr&#233;e est constitu&#233;e d&#8217;un groupe de 10 articles (cluster dans la terminologie de TAC) reli&#233;s de pr&#232;s ou
de loin &#224; un sujet d&#8217;actualit&#233; restreint. Ces articles proviennent de la collection AQUAINT-2, qui inclut
des articles de six agences de presse, r&#233;dig&#233;s en langue anglaise entre le 1er octobre 2004 et le 31 mars
2006. Un cluster compte en moyenne un peu moins de 5000 mots, ce qui aboutit pour un r&#233;sum&#233; de 100
mots &#224; un taux de compression moyen de 98%. Les r&#233;sum&#233;s doivent r&#233;pondre &#224; une requ&#234;te, qui contient
un titre et une ou deux phrase(s) compl&#232;te(s) en forme imp&#233;rative, pour un total de 20 mots en moyenne. &#192;
chaque cluster est associ&#233;e une telle requ&#234;te pour orienter le r&#233;sum&#233; sur un besoin d&#8217;information sp&#233;cifique
du lecteur.
</p>
<p>Un deuxi&#232;me cluster de 10 articles est fourni pour la m&#234;me requ&#234;te et fait l&#8217;objet d&#8217;un second r&#233;sum&#233;.
Les articles du deuxi&#232;me cluster ont tous &#233;t&#233; publi&#233;s apr&#232;s ceux du premier, ce qui simule un utilisateur
cherchant &#224; rester bien inform&#233; sur un sujet d&#8217;actualit&#233; en &#233;volution. Le r&#233;sum&#233; du deuxi&#232;me cluster doit
r&#233;pondre &#224; la m&#234;me requ&#234;te et est un r&#233;sum&#233; de mise &#224; jour, c&#8217;est-&#224;-dire un r&#233;sum&#233; de l&#8217;information
nouvelle n&#8217;apparaissant que dans le deuxi&#232;me cluster. On suppose que le lecteur a d&#233;j&#224; pris connaissance
de tout le contenu des articles du premier cluster (non seulement du r&#233;sum&#233;).
</p>
<p>La t&#226;che compl&#232;te requiert donc deux r&#233;sum&#233;s par sujet, chacun sur un cluster de 10 articles d&#8217;agences
de presse et r&#233;pondant &#224; la m&#234;me requ&#234;te. Le premier est un r&#233;sum&#233; standard, portant sur le cluster A et
le deuxi&#232;me est un r&#233;sum&#233; de mise &#224; jour, portant sur le cluster B tout en ne r&#233;p&#233;tant aucune information
contenue dans le cluster A. Lors de la comp&#233;tition de TAC 2009, 44 requ&#234;tes et 880 articles ont fait l&#8217;objet
de 44 r&#233;sum&#233;s standards et 44 r&#233;sum&#233;s de mise &#224; jour.
</p>
<p>3 M&#233;thodologie
</p>
<p>3.1 Interface pour l&#8217;extraction de phrases
</p>
<p>Pour simplifier la r&#233;daction des r&#233;sum&#233;s par extraction, nous avons d&#233;velopp&#233; une interface sur fureteur 4
</p>
<p>qui permet de construire un r&#233;sum&#233; dans un environnement convivial. Les r&#233;sumeurs peuvent ais&#233;ment
choisir sur quelle requ&#234;te travailler, acc&#233;der aux donn&#233;es, sauvegarder les r&#233;sum&#233;s, et les consulter ou les
modifier plus tard. En arri&#232;re-plan, le syst&#232;me conserve des traces des temps de travail et d&#8217;autres donn&#233;es
p&#233;riph&#233;riques.
</p>
<p>Les r&#233;sum&#233;s sont cr&#233;&#233;s sur une seule page facile d&#8217;utilisation, illustr&#233;e au haut de la figure 1.
</p>
<p>Tous les articles du m&#234;me cluster apparaissent les uns &#224; la suite des autres, suivant l&#8217;ordre chronologique.
Le texte de chaque article a &#233;t&#233; pr&#233;alablement segment&#233; en phrases et la structure en paragraphes est
conserv&#233;e. Les phrases sont des blocs impossibles &#224; modifier durant la r&#233;daction. Quand un utilisateur
survole une partie du texte, la phrase sur laquelle repose le pointeur est surlign&#233;e et son nombre de mots
</p>
<p>4. L&#8217;interface est disponible &#224; cette adresse : http ://rali.iro.umontreal.ca/Resume/HexTAC/index.fr.html</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PIERRE-ETIENNE GENEST, GUY LAPALME, MEHDI YOUSFI-MONOD
</p>
<p>1. Choisir un des sujets qui vous ont &#233;t&#233; assign&#233;s. Commencer par la partie A, soit le r&#233;sum&#233; standard.
</p>
<p>2. Lire la requ&#234;te et l&#8217;enti&#232;ret&#233; des 10 documents &#224; r&#233;sumer pour &#233;viter de manquer une phrase qui
aurait &#233;t&#233; pertinente. Pour le cluster A, il faut faire bien attention de se souvenir de l&#8217;information
contenue dans les articles, car il faudra &#233;viter de la r&#233;p&#233;ter dans le r&#233;sum&#233; de mise &#224; jour.
</p>
<p>3. Extraire des phrases qui permettent de r&#233;pondre &#224; la requ&#234;te de l&#8217;utilisateur. S&#233;lectionner des phrases
compr&#233;hensibles m&#234;me hors de leur contexte particulier dans l&#8217;article d&#8217;origine, pour &#233;viter que le
r&#233;sum&#233; ne contienne d&#8217;ambigu&#239;t&#233; r&#233;f&#233;rentielle.
</p>
<p>4. Maximiser la quantit&#233; d&#8217;information contenue dans le r&#233;sum&#233; en respectant la limite de 100 mots.
</p>
<p>5. Ajuster l&#8217;ordre des phrases dans le r&#233;sum&#233; pour en am&#233;liorer la lisibilit&#233;.
</p>
<p>6. Compl&#233;ter le r&#233;sum&#233; de mise &#224; jour (partie B) imm&#233;diatement apr&#232;s avoir compl&#233;t&#233; le r&#233;sum&#233; stan-
dard sur la m&#234;me requ&#234;te. Suivre les m&#234;mes &#233;tapes que dans la partie A, tout en &#233;vitant d&#8217;inclure de
l&#8217;information d&#233;j&#224; contenue dans les articles du cluster A.
</p>
<p>FIGURE 1 &#8211; En haut, capture d&#8217;&#233;cran de l&#8217;interface HEXTAC ; en bas, consignes donn&#233;es aux r&#233;sumeurs.
De haut en bas et de gauche &#224; droite, la page de travail contient une bo&#238;te pour entrer le nom d&#8217;utilisa-
teur, une section contenant la requ&#234;te, les articles et leurs m&#233;ta-donn&#233;es (ID, date de publication et titre),
les outils d&#8217;&#233;dition (incluant les op&#233;rations d&#233;faire et refaire), le bouton de sauvegarde et la r&#233;gion de
construction du r&#233;sum&#233;. Les ajouts, retraits et changements d&#8217;ordre des phrases se font enti&#232;rement par
glisser-d&#233;poser.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>JUSQU&#8217;O&#217; PEUT-ON ALLER AVEC LES M&#201;THODES PAR EXTRACTION?
</p>
<p>appara&#238;t. Elle peut &#234;tre ajout&#233;e au r&#233;sum&#233; par un double-clic ou en glissant et d&#233;posant la phrase dans la
r&#233;gion de r&#233;sum&#233;. Le nombre total de mots dans le r&#233;sum&#233; est toujours mis &#224; jour et il passe au rouge s&#8217;il
d&#233;passe la limite de 100 mots. Aucun r&#233;sum&#233; d&#233;passant la limite ne sera accept&#233; par le syst&#232;me HEXTAC.
Des sauvegardes temporaires sont possibles et celles-ci peuvent d&#233;passer la limite. Toute l&#8217;interface fonc-
tionne aussi bien avec glisser-d&#233;poser qu&#8217;avec le double-clic et les boutons. Enfin, il est possible de d&#233;faire
et refaire les derni&#232;res actions gr&#226;ce &#224; des boutons.
</p>
<p>Cette interface a &#233;t&#233; adapt&#233;e &#224; partir d&#8217;une interface de r&#233;vision de r&#233;sum&#233;s qui avait &#233;t&#233; d&#233;velopp&#233;e pour
un projet de r&#233;vision de r&#233;sum&#233; automatique de textes juridiques avec NLP Technologies 5 (Chieze et al.,
2008).
</p>
<p>3.2 Contexte exp&#233;rimental
</p>
<p>La t&#226;che de r&#233;diger les deux r&#233;sum&#233;s pour chacune des 44 requ&#234;tes a &#233;t&#233; divis&#233;e in&#233;galement entre 5 b&#233;n&#233;-
voles, tous sp&#233;cialistes du TAL avec de l&#8217;exp&#233;rience en r&#233;sum&#233;s automatiques, incluant les trois auteurs.
Ils ont utilis&#233; exclusivement l&#8217;interface d&#233;crite &#224; la figure 1 et respect&#233; les consignes reproduites au bas de
celle-ci. Les r&#233;sum&#233;s ont &#233;t&#233; r&#233;dig&#233;s dans l&#8217;intervalle d&#8217;une semaine.
</p>
<p>Le tableau 1 pr&#233;sente le nombre de r&#233;sum&#233;s &#233;crits par chaque r&#233;sumeur (ID R1 &#224; R5) et le temps moyen
pour compl&#233;ter un r&#233;sum&#233; par extraction en utilisant l&#8217;interface. Au total, 30 heures-personnes ont &#233;t&#233;
requises pour compl&#233;ter les 88 r&#233;sum&#233;s.
</p>
<p>R&#233;sumeur # de r&#233;sum&#233;s Temps moyen (minutes)
R1 18 17
R2 18 16
R3 12 27
R4 24 24
R5 16 17
</p>
<p>Moyenne 18 20
</p>
<p>TABLE 1 &#8211; Nombre de r&#233;sum&#233;s compos&#233;s par chaque r&#233;sumeur humain et leur temps moyen pour r&#233;diger
un r&#233;sum&#233;
</p>
<p>3.3 R&#233;actions des r&#233;sumeurs
</p>
<p>&#192; la suite de l&#8217;exp&#233;rience, nous avons rencontr&#233; les r&#233;sumeurs ayant particip&#233; &#224; HEXTAC pour prendre
note de leurs r&#233;actions et &#233;valuer la d&#233;marche.
</p>
<p>L&#8217;opinion dominante a &#233;t&#233; que l&#8217;interface rendait le processus beaucoup plus agr&#233;able. Cet outil leur a
&#233;pargn&#233; beaucoup de temps et a m&#234;me aid&#233; &#224; l&#8217;organisation des id&#233;es. Utiliser un &#233;diteur de texte et les
fonctions copier et coller aurait rendu la t&#226;che encore plus p&#233;nible, selon eux.
</p>
<p>Les r&#233;sumeurs ont ressenti de la frustration parce qu&#8217;ils ne pouvaient pas effectuer la moindre modification
sur les phrases ou encore inclure plus de 100 mots dans le r&#233;sum&#233;. Dans plusieurs cas, la possibilit&#233; de
</p>
<p>5. www.nlptechnologies.ca</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PIERRE-ETIENNE GENEST, GUY LAPALME, MEHDI YOUSFI-MONOD
</p>
<p>couper ne serait-ce qu&#8217;un ou deux mots aurait pu faire une grande diff&#233;rence. Certaines phrases poss&#233;daient
un excellent contenu d&#8217;information mais incluaient une r&#233;f&#233;rence non-r&#233;solue qui les rendait inadmissibles
pour le r&#233;sum&#233;.
</p>
<p>Les requ&#234;tes ont soulev&#233; quelques interrogations, car elles demandaient parfois d&#8217;&#233;num&#233;rer plusieurs &#233;v&#233;-
nements/opinions/etc. reli&#233;s, alors que les articles ne contenaient que des phrases incluant une seule par-
celle d&#8217;information &#224; la fois. Choisir quelles phrases inclure dans le r&#233;sum&#233; s&#8217;av&#233;rait donc tr&#232;s ardu dans
ce contexte.
</p>
<p>En g&#233;n&#233;ral, beaucoup de choix tr&#232;s subjectifs &#224; propos de quel contenu inclure dans un r&#233;sum&#233; d&#8217;une
taille restreinte doivent &#234;tre faits et peuvent &#234;tre probl&#233;matiques. Il &#233;tait difficile de faire un compromis
entre la qualit&#233; linguistique et la quantit&#233; de contenu, un &#233;quilibre difficile &#224; g&#233;rer &#233;galement pour les sys-
t&#232;mes automatiques par extraction. Certaines phrases plus informatives ont du &#234;tre rejet&#233;es parce qu&#8217;elles
comportaient des r&#233;f&#233;rences non r&#233;solues.
</p>
<p>Enfin, la plupart des r&#233;sumeurs se sont plaints de la dur&#233;e totale pour compl&#233;ter leurs r&#233;sum&#233;s et de l&#8217;aspect
r&#233;p&#233;titif de la t&#226;che. Les sujets abord&#233;s dans les articles &#233;taient souvent d&#8217;un int&#233;r&#234;t tr&#232;s limit&#233; pour des
non-am&#233;ricains et compl&#233;ter plusieurs r&#233;sum&#233;s cons&#233;cutivement pouvait diminuer le niveau d&#8217;attention
aux d&#233;tails. Il reste que plusieurs ont trouv&#233; que plus ils assemblaient de r&#233;sum&#233;s, plus la difficult&#233; de la
t&#226;che s&#8217;amenuisait.
</p>
<p>4 R&#233;sultats et analyse
</p>
<p>4.1 &#201;valuations &#224; TAC 2009
</p>
<p>Les organisateurs de TAC 2009 ont inscrit HEXTAC comme l&#8217;un des trois ensembles de contr&#244;le 6 &#224; la
comp&#233;tition de TAC 2009 et l&#8217;ont &#233;valu&#233; au m&#234;me titre que les syst&#232;mes automatiques participants et les
r&#233;sumeurs humains qui produisent les r&#233;sum&#233;s de r&#233;f&#233;rence. Les r&#233;sultats ont &#233;t&#233; publi&#233;s dans le compte-
rendu de la conf&#233;rence (Dang &amp; Owczarzak, 2010).
</p>
<p>Le tableau 2 pr&#233;sente les r&#233;sultats des &#233;valuations manuelles des r&#233;sumeurs humains, des r&#233;sumeurs de
HEXTAC et du meilleur r&#233;sultat obtenu par un syst&#232;me automatique pour chaque cat&#233;gorie (ce n&#8217;est pas
toujours le m&#234;me syst&#232;me dans chaque cas).
</p>
<p>Le contenu est le r&#233;sultat d&#8217;une &#233;valuation par la m&#233;thode Pyramid (Passonneau, 2006). Cette m&#233;thode
d&#8217;&#233;valuation requiert que des humains identifient toutes les unit&#233;s s&#233;mantiques de contenu (SCU en an-
glais) pr&#233;sentes dans les r&#233;sum&#233;s de r&#233;f&#233;rences (ceux &#233;crits librement par des humains). Le score de Py-
ramid correspond au nombre de SCU pr&#233;sents dans le r&#233;sum&#233;, divis&#233; par le nombre total de SCU pr&#233;sents
dans tous les r&#233;sum&#233;s de r&#233;f&#233;rence. Ce calcul est en fait pond&#233;r&#233; de sorte que chaque SCU a une valeur
&#233;gale au nombre de r&#233;sum&#233;s de r&#233;f&#233;rence dans lesquels il appara&#238;t.
</p>
<p>Le score du niveau linguistique s&#8217;appuie sur cinq aspects, soient la grammaticalit&#233;, la non redondance, la
clart&#233; r&#233;f&#233;rentielle, la convergeance (focus en anglais) et la coh&#233;sion des r&#233;sum&#233;s. L&#8217;&#233;valuation se fait sur
une &#233;chelle de 1 &#224; 10 par des &#233;valuateurs humains, sans donner de score &#224; chaque aspect. Les erreurs de
</p>
<p>6. Les deux autres ensembles de contr&#244;le &#233;taient : 1) les 100 premiers mots du document le plus r&#233;cent ; et 2) les phrases
d&#8217;un des r&#233;sum&#233;s &#233;crits manuellement, r&#233;ordonn&#233;es al&#233;atoirement</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>JUSQU&#8217;O&#217; PEUT-ON ALLER AVEC LES M&#201;THODES PAR EXTRACTION?
</p>
<p>R&#233;sum&#233;s standards Contenu Niveau linguistique Qualit&#233; globale
R&#233;sumeurs humains libres 0,683 8,915 8,830
R&#233;sumeurs humains par extraction (HEXTAC) 0,352 7,477 6,341
Meilleur r&#233;sultat d&#8217;un syst&#232;me automatique 0,383 5,932 5,159
</p>
<p>R&#233;sum&#233;s de mise &#224; jour
R&#233;sumeurs humains libres 0,606 8,807 8,506
R&#233;sumeurs humains par extraction (HEXTAC) 0,324 7,250 6,114
Meilleur r&#233;sultat d&#8217;un syst&#232;me automatique 0,307 5,886 5,023
</p>
<p>TABLE 2 &#8211; R&#233;sultats d&#8217;&#233;valuation des r&#233;sumeurs &#224; TAC 2009. Il s&#8217;agit de scores moyens, avec un &#233;chan-
tillon de 44 r&#233;sum&#233;s de chaque type.
</p>
<p>langues sont punies s&#233;v&#232;rement ; une phrase incompl&#232;te ou d&#233;nu&#233;e de sens implique g&#233;n&#233;ralement que le
r&#233;sum&#233; qui la contient recevra une note inf&#233;rieure &#224; 4 sur 10 pour le niveau linguistique.
</p>
<p>Enfin, le score de la qualit&#233; globale &#233;value, sur une &#233;chelle de 1 &#224; 10, &#224; la fois le niveau linguistique et
la quantit&#233; d&#8217;information permettant de r&#233;pondre au besoin d&#8217;information du lecteur, tel qu&#8217;exprim&#233; dans
la requ&#234;te. Ce score se veut un reflet du niveau d&#8217;appr&#233;ciation d&#8217;un client d&#233;sirant recevoir un r&#233;sum&#233;.
Nous avons observ&#233; qu&#8217;un niveau linguistique bas encourt presque syst&#233;matiquement un score de qualit&#233;
globale bas &#233;galement. La quantit&#233; de contenu semble plut&#244;t servir &#224; d&#233;partager les r&#233;sum&#233;s consid&#233;r&#233;s
comme bien &#233;crits.
</p>
<p>Les scores ROUGE (Lin, 2004), obtenus automatiquement par similarit&#233; lexicale avec les r&#233;sum&#233;s de
r&#233;f&#233;rence, ont &#233;t&#233; calcul&#233;s pour HEXTAC et tous les syst&#232;mes lors de la comp&#233;tition, mais nous n&#8217;en
discutons pas ici car ceux-ci sont moins pertinents que les &#233;valuations manuelles de la qualit&#233; des r&#233;sum&#233;s.
</p>
<p>Le score de qualit&#233; globale de HEXTAC est plus &#233;lev&#233; de plus d&#8217;un point sur 10, en moyenne, que celui
de tous les syst&#232;mes automatiques, pour les deux types de r&#233;sum&#233;s. Cette sup&#233;riorit&#233; s&#8217;explique avant
tout par le nettement meilleur niveau linguistique des r&#233;sum&#233;s de HEXTAC. Pour ce qui est du contenu, les
meilleurs syst&#232;mes automatiques s&#8217;approchent ou d&#233;passent tout juste la performance des extraits manuels.
Une des raisons de cette faible diff&#233;rence dans le contenu peut &#234;tre justement que des phrases informatives
mais contenant des r&#233;f&#233;rences non-r&#233;solues devaient &#234;tre rejet&#233;es par nos r&#233;sumeurs, selon les consignes.
Les syst&#232;mes automatiques avaient la chance de modifier les phrases &#224; leur guise, quoique les meilleurs
syst&#232;mes ne font gu&#232;re plus qu&#8217;&#233;diter les dates relatives et remplacer certaines anaphores simples par leur
r&#233;f&#233;rant.
</p>
<p>Les r&#233;sum&#233;s manuels par extraction ont re&#231;u un score global tr&#232;s nettement inf&#233;rieur (de 2.4 &#224; 2.5 points
sur 10) &#224; celui des r&#233;sum&#233;s de r&#233;f&#233;rence, dans les deux cat&#233;gories. Cette diff&#233;rence entre deux m&#233;thodes
manuelles ne peut s&#8217;expliquer que par la s&#233;v&#233;rit&#233; des contraintes impos&#233;es par l&#8217;extraction pure. En effet,
il va de soi que la reformulation permet d&#8217;inclure beaucoup plus d&#8217;information en moins de mots. Le
niveau linguistique demeure plus bas que celui atteint par les r&#233;sumeurs libres, parce qu&#8217;il est difficile
de conserver un bon degr&#233; de convergeance et de coh&#233;sion dans le r&#233;sum&#233;, n&#8217;ayant pas de flexibilit&#233; sur
les phrases &#224; notre disposition. Il demeure int&#233;ressant d&#8217;observer qu&#8217;un bon niveau linguistique peut &#234;tre
conserv&#233; en ne faisant que de l&#8217;extraction, m&#234;me si le contenu et la qualit&#233; globale sont tr&#232;s nettement
inf&#233;rieurs aux r&#233;sum&#233;s compos&#233;s librement.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PIERRE-ETIENNE GENEST, GUY LAPALME, MEHDI YOUSFI-MONOD
</p>
<p>Nous croyons que les r&#233;sultats de HEXTAC peuvent &#234;tre interpr&#233;t&#233;s comme une approximation de la per-
formance maximale qui peut &#234;tre atteinte en r&#233;sum&#233; par extraction pure. De meilleurs r&#233;sum&#233;s auraient
sans doute pu &#234;tre produits, en partie parce que les r&#233;sumeurs auraient pu &#234;tre plus comp&#233;tents, n&#8217;ayant
pas d&#8217;expertise en r&#233;daction de r&#233;sum&#233;s et un possible biais li&#233; &#224; leur connaissance des m&#233;thodes automa-
tiques. La diff&#233;rence de performance entre les r&#233;sumeurs et le faible taux d&#8217;accord entre eux, comme nous
le verrons dans la prochaine section, permet &#233;galement de conclure qu&#8217;il ne s&#8217;agit que d&#8217;une approxima-
tion d&#8217;une borne sup&#233;rieure &#224; l&#8217;extraction. Il n&#8217;en demeure pas moins que l&#8217;&#233;cart observ&#233; entre les r&#233;sum&#233;s
par extraction et les r&#233;sum&#233;s libres est tellement grand que nous pouvons affirmer avec confiance que les
r&#233;sum&#233;s par extraction pure ne pourront jamais s&#8217;approcher, en termes de performances, des r&#233;sum&#233;s par
abstraction.
</p>
<p>4.2 Taux d&#8217;accord inter-r&#233;sumeurs
</p>
<p>Nous avons calcul&#233; le taux d&#8217;accord entre les r&#233;sumeurs sur un petit &#233;chantillon de 16 r&#233;sum&#233;s qui ont &#233;t&#233;
r&#233;dig&#233;s deux fois. En moyenne, chaque r&#233;sum&#233; inclut 0.58 phrase s&#233;lectionn&#233;e par les deux r&#233;sumeurs, sur
une moyenne de 3.88 phrases par r&#233;sum&#233;. Ceci peut s&#8217;interpr&#233;ter comme une probabilit&#233; de 15% qu&#8217;un
second r&#233;sumeur s&#233;lectionne une phrase d&#233;j&#224; s&#233;lectionn&#233;e pour le r&#233;sum&#233; par extraction. Nous consid&#233;rons
ce taux d&#8217;accord bas, m&#234;me si cela est en quelque sorte pr&#233;visible, &#233;tant donn&#233;es la redondance et les
r&#233;p&#233;titions entre les documents d&#8217;un m&#234;me cluster, et donc la pr&#233;sence de phrases diff&#233;rentes contenant
relativement la m&#234;me information. Cependant, la majorit&#233; des diff&#233;rences dans la s&#233;lection de phrases
entre r&#233;sumeurs ne produisent pas des r&#233;sum&#233;s contenant exactement la m&#234;me information. Des r&#233;sumeurs
diff&#233;rents font des choix diff&#233;rents de contenu et proc&#232;dent de mani&#232;re diff&#233;rente. Le m&#234;me ph&#233;nom&#232;ne
s&#8217;observe d&#233;j&#224; dans les r&#233;sum&#233;s libres.
</p>
<p>Contenu Niveau linguistique Qualit&#233; globale
R1 0,278 8,222 7,556
R2 0,297 7,611 5,333
R3 0,340 7,000 5,917
R4 0,378 7,583 7,125
R5 0,392 6,063 4,125
</p>
<p>TABLE 3 &#8211; Scores moyens des r&#233;sum&#233;s &#233;crits par chaque r&#233;sumeur
</p>
<p>Les r&#233;sultats individuels pour chaque r&#233;sumeur sont pr&#233;sent&#233;s dans le tableau 3, pour illustrer les effets
de ces choix diff&#233;rents d&#8217;un r&#233;sumeur &#224; un autre. Nous observons des diff&#233;rences importantes dans les
r&#233;sultats individuels, qui laissent supposer un processus d&#233;cisionnel diff&#233;rent, malgr&#233; des consignes com-
munes. Certains ont travaill&#233; de sorte &#224; privil&#233;gier le contenu, alors que d&#8217;autres semblent produire des
r&#233;sum&#233;s syst&#233;matiquement de meilleur niveau linguistique, ce qui a un plus grand impact sur le score de
qualit&#233; globale.
</p>
<p>Le faible nombre de r&#233;sum&#233;s r&#233;dig&#233;s par chaque r&#233;sumeur explique aussi en partie la variance tr&#232;s &#233;lev&#233;e
des scores individuels. Certains r&#233;sum&#233;s sont plus difficiles &#224; r&#233;diger que d&#8217;autres, &#224; cause d&#8217;une requ&#234;te
plus difficile ou du nombre limit&#233; de phrases pertinentes et linguistiquement ad&#233;quates disponibles. Men-
tionnons aussi que les r&#233;sumeurs avaient un niveau in&#233;gal de connaissance sur les sujets abord&#233;s et une
comp&#233;tence variable de l&#8217;anglais.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>JUSQU&#8217;O&#217; PEUT-ON ALLER AVEC LES M&#201;THODES PAR EXTRACTION?
</p>
<p>5 Conclusion
</p>
<p>L&#8217;exp&#233;rience HEXTAC a permis de d&#233;velopper une approche r&#233;utilisable permettant de composer un en-
semble de r&#233;sum&#233;s par extraction pure pouvant servir de mod&#232;les et de bases de comparaison aux r&#233;sum&#233;s
automatiques. Les r&#233;sum&#233;s produits peuvent servir de corpus d&#8217;entra&#238;nement &#224; un module de s&#233;lection
de phrases, corpus qui n&#8217;a, &#224; notre connaissance, jamais &#233;t&#233; d&#233;velopp&#233; auparavant. Enfin, cette m&#233;thode
permet d&#8217;&#233;tablir une borne sup&#233;rieure &#224; la performance th&#233;orique d&#8217;un syst&#232;me automatique de r&#233;daction
automatique de r&#233;sum&#233;s fonctionnant par extraction de phrases.
</p>
<p>Nous avons d&#233;velopp&#233; une m&#233;thodologie compl&#232;te incluant des contraintes bien d&#233;finies et des consignes
pr&#233;cises pour les r&#233;sumeurs. Nous avons une id&#233;e nettement plus pr&#233;cise du temps requis pour compl&#233;ter
manuellement des r&#233;sum&#233;s par extraction, soit environ une vingtaine de minutes, alors que les r&#233;sumeurs
de NIST d&#233;pensent 75 minutes pour compl&#233;ter chaque r&#233;sum&#233;. Nous avons aussi observ&#233; qu&#8217;une interface
telle que celle que nous avons d&#233;velopp&#233;e est un outil pratique pour diminuer le temps de r&#233;daction et cette
interface est mise &#224; la disposition de tous en tant que logiciel libre.
</p>
<p>Les r&#233;sultats obtenus lors des &#233;valuations manuelles, interpr&#233;t&#233;s comme une borne sup&#233;rieure aux perfor-
mances escompt&#233;es pour les r&#233;sum&#233;s par extraction pure, nous m&#232;nent &#224; deux conclusions importantes.
D&#8217;un c&#244;t&#233;, les approches automatiques utilisant l&#8217;extraction de phrases semblent encore loin d&#8217;avoir atteint
leur plein potentiel, et des efforts devraient &#234;tre d&#233;ploy&#233;s en particulier pour am&#233;liorer le niveau linguis-
tique des r&#233;sum&#233;s cr&#233;&#233;s. En pratique, l&#8217;extraction des phrases n&#8217;est pas toujours &#8220;pure&#8221;, c&#8217;est-&#224;-dire que
des modifications relativement mineures aux phrases sont apport&#233;es, telles que la r&#233;solution de r&#233;f&#233;rences
et la reformulation de dates relatives. Nous croyons que nos r&#233;sultats montrent que les modifications per-
mettant d&#8217;am&#233;liorer la lisibilit&#233; sont un moyen tr&#232;s efficace d&#8217;am&#233;liorer la qualit&#233; globale des r&#233;sum&#233;s.
</p>
<p>De l&#8217;autre c&#244;t&#233;, cette borne sup&#233;rieure sur l&#8217;extraction de phrases indique que la diff&#233;rence entre les per-
formances &#8220;maximales&#8221; qui peuvent &#234;tre atteintes par l&#8217;extraction pure sont grandement insufisantes pour
esp&#233;rer que les approches bas&#233;es sur l&#8217;extraction, avec seulement des modifications mineures, puissent un
jour rejoindre celles des r&#233;sum&#233;s par abstraction. La diff&#233;rence de performance, aussi bien aux niveaux
du contenu, du niveau linguistique que de la qualit&#233; globale, est si grande qu&#8217;il nous semble essentiel de
diriger les efforts de recherche dans de nouvelles directions qui s&#8217;&#233;loignent de l&#8217;extraction pure.
</p>
<p>Nous croyons que nos r&#233;sultats encouragent le d&#233;veloppement de syst&#232;mes de r&#233;daction automatique de
r&#233;sum&#233;s qui effectuent des modifications majeures aux phrases. Une technique avanc&#233;e comme pouvant
&#234;tre combin&#233;e &#224; l&#8217;extraction est la compression de phrases (Gagnon &amp; Sylva, 2006) (Yousfi-Monod &amp;
Prince, 2006) (Cohn &amp; Lapata, 2009). La compression consiste &#224; retirer des mots de la phrase tout en
maintenant l&#8217;essentiel de son contenu. Un syst&#232;me automatique de r&#233;sum&#233; aurait le choix d&#8217;inclure une
phrase du document &#224; r&#233;sumer &#224; diff&#233;rents niveaux de compression, ce qui s&#8217;&#233;loigne de l&#8217;extraction pure.
La fusion de phrases (Barzilay &amp; McKeown, 2005) est aussi une technique alternative dans laquelle les
phrases du r&#233;sum&#233; sont diff&#233;rentes des phrases originales. Cette approche n&#233;cessite de rep&#233;rer des groupes
de phrases se ressemblant syntaxiquement et lexicalement (th&#232;mes) dans le document &#224; r&#233;sumer, puis de
fusionner chacun de ces groupes pour optenir une seule phrase fusionn&#233;e qui sera incluse dans le r&#233;sum&#233;.
</p>
<p>&#201;ventuellement, une borne maximale de performance sur les techniques plus avanc&#233;es que l&#8217;extraction
pure pourrait &#234;tre obtenue en menant des exp&#233;riences similaires &#224; HEXTAC. On pourrait inclure des choix
suppl&#233;mentaires aux phrases non &#233;dit&#233;es des documents &#224; r&#233;sumer, pour les r&#233;sumeurs humains de l&#8217;exp&#233;-
rience. Par exemple, ils pourraient s&#233;lectionner parmi des phrases non &#233;dit&#233;es, des phrases o&#249; les r&#233;f&#233;rences
et les dates relatives ont &#233;t&#233; r&#233;solues automatiquement, o&#249; de la compression a eu lieu, ou encore parmi</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PIERRE-ETIENNE GENEST, GUY LAPALME, MEHDI YOUSFI-MONOD
</p>
<p>des phrases fusionn&#233;es automatiquement. Ceci pourrait aider &#224; faire un choix entre diff&#233;rentes approches
possibles pour le r&#233;sum&#233; et &#224; orienter l&#8217;effort de recherche dans une direction o&#249; l&#8217;on peut esp&#233;rer obtenir
des performances comparables aux performances humaines, ce qui n&#8217;est pas le cas avec les r&#233;sum&#233;s par
extraction.
</p>
<p>Remerciements
</p>
<p>Merci &#224; Atefeh Farzidar, pr&#233;sidente de NLP Technologies, qui a accept&#233; que nous adaptions l&#8217;interface de
r&#233;vision &#224; notre projet. Merci &#224; Fabrizio Gotti et Florian Boudin pour leur contribution de r&#233;sumeurs.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BARZILAY R. &amp; MCKEOWN K. R. (2005). Sentence fusion for multidocument news summarization.
Computational Linguistics, 31(3), 297&#8211;328.
CHIEZE E., FARZINDAR A. &amp; LAPALME G. (2008). Automatic summarization and information ex-
traction from canadian immigration decisions. In Proceedings of the Semantic Processing of Legal Texts
Workshop, p. 51&#8211;57 : LREC 2008.
COHN T. &amp; LAPATA M. (2009). Sentence compression as tree transduction. J. Artif. Int. Res., 34(1),
637&#8211;674.
DANG H. T. &amp; OWCZARZAK K. (2010). Overview of the TAC 2009 summarization track. In Pro-
ceedings of the Second Text Analysis Conference, Gaithersburg, Maryland, USA : National Institute of
Standards and Technology.
GAGNON M. &amp; SYLVA L. D. (2006). Text compression by syntactic pruning. In Proceedings of the 19th
Canadian Conference on Artificial Intelligence.
GENEST P.-E., LAPALME G. &amp; YOUSFI-MONOD M. (2010). Hextac : the creation of a manual ex-
tractive run. In Proceedings of the Second Text Analysis Conference, Gaithersburg, Maryland, USA :
National Institute of Standards and Technology.
GILLICK D., FAVRE B., T&#220;R D.-H., BOHNET B., LIU Y. &amp; XIE S. (2010). The icsi/utd summarization
system at tac 2009. In Proceedings of the Second Text Analysis Conference, Gaithersburg, Maryland,
USA : National Institute of Standards and Technology.
LIN C.-Y. (2004). Rouge : A package for automatic evaluation of summaries. In Proceedings of the
ACL-04 Workshop : Text Summarization Branches Out, p. 74&#8211;81.
LONG C., HUANG M. &amp; ZHU X. (2010). Tsinghua university at tac 2009 : Summarizing multi-
documents by information distance. In Proceedings of the Second Text Analysis Conference, Gaithers-
burg, Maryland, USA : National Institute of Standards and Technology.
LUHN H. P. (1958). The automatic creation of literature abstracts. IBM Journal of Research and Deve-
lopment, 2(2), 159&#8211;165.
PASSONNEAU R. J. (2006). Pyramid annotation guide : Duc 2006.
http ://www1.cs.columbia.edu/ becky/DUC2006/2006-pyramid-guidelines.html.
YOUSFI-MONOD M. &amp; PRINCE V. (2006). Compression de phrases par &#233;lagage de leur arbre morpho-
syntaxique. Technique et Science Informatiques, 25(4), 437&#8211;468.</p>

</div></div>
</body></html>