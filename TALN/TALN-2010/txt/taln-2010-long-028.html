<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Apprentissage non supervis&#233; pour la traduction automatique : application &#224; un couple de langues peu dot&#233;</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2010, Montr&#233;al, 19-23 juillet 2010 
</p>
<p>Apprentissage non supervis&#233; pour la traduction automatique : 
application &#224; un couple de langues peu dot&#233; 
</p>
<p>Do Thi Ngoc Diep1,2, Laurent Besacier1, Eric Castelli2 
</p>
<p>(1) Laboratoire LIG, GETALP, Grenoble, France 
(2) Centre MICA, CNRS/UMI-2954, Hanoi, Vietnam 
</p>
<p>thi-ngoc-diep.do@imag.fr 
</p>
<p> 
</p>
<p>R&#233;sum&#233; Cet article pr&#233;sente une m&#233;thode non-supervis&#233;e pour extraire des paires de phrases parall&#232;les &#224; 
partir d&#8217;un corpus comparable. Un syst&#232;me de traduction automatique est utilis&#233; pour exploiter le corpus 
comparable et d&#233;tecter les paires de phrases parall&#232;les. Un processus it&#233;ratif est ex&#233;cut&#233; non seulement pour 
augmenter le nombre de paires de phrases parall&#232;les extraites, mais aussi pour am&#233;liorer la qualit&#233; globale du 
syst&#232;me de traduction. Une comparaison avec une m&#233;thode semi-supervis&#233;e est pr&#233;sent&#233;e &#233;galement. Les 
exp&#233;riences montrent que la m&#233;thode non-supervis&#233;e peut &#234;tre r&#233;ellement appliqu&#233;e dans le cas o&#249; on manque 
de donn&#233;es parall&#232;les. Bien que les exp&#233;riences pr&#233;liminaires soient men&#233;es sur la traduction fran&#231;ais-anglais, 
cette m&#233;thode non-supervis&#233;e est &#233;galement appliqu&#233;e avec succ&#232;s &#224; un couple de langues peu dot&#233; : 
vietnamien-fran&#231;ais. 
</p>
<p>Abstract This paper presents an unsupervised method for extracting parallel sentence pairs from a 
comparable corpus. A translation system is used to mine and detect the parallel sentence pairs from the 
comparable corpus. An iterative process is implemented not only to increase the number of extracted parallel 
sentence pairs but also to improve the overall quality of the translation system. A comparison between this 
unsupervised method and a semi-supervised method is also presented. The experiments conducted show that 
the unsupervised method can be really applied in cases where parallel data are not available. While preliminary 
experiments are conducted on French-English translation, this unsupervised method is also applied 
successfully to a low e-resourced language pair (Vietnamese-French). 
</p>
<p>Mots-cl&#233;s :   apprentissage non-supervis&#233;, syst&#232;me de traduction automatique, corpus comparable, paires 
de phrases parall&#232;les 
Keywords:   unsupervised training, machine translation, comparable corpus, parallel sentence pairs 
 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>DO THI NGOC DIEP, LAURENT BESACIER, ERIC CASTELLI 
</p>
<p>1 Introduction 
Les syst&#232;mes de traduction automatique (TA) obtiennent aujourd&#8217;hui de bons r&#233;sultats sur certains couples 
de langues comme anglais-fran&#231;ais, anglais-italien, anglais-espagnol, etc. Il existe de nombreuses approches 
de TA : des approches expertes fond&#233;es sur des r&#232;gles linguistiques, des approches empiriques fond&#233;es sur 
l&#8217;apprentissage automatique &#224; partir de corpus bilingues, ainsi que des approches hybrides. Toutefois, la 
recherche sur la TA pour des couples de langues dits &#171; peu dot&#233;s &#187; doit faire face au d&#233;fi du manque de 
donn&#233;es. La TA probabiliste est fond&#233;e sur l&#8217;apprentissage de mod&#232;les &#224; partir de grands corpus parall&#232;les 
bilingues pour les langues source et cible. Ensuite, ces mod&#232;les et un module de recherche sont utilis&#233;s pour 
d&#233;coder la meilleure hypoth&#232;se de traduction &#224; partir d&#8217;un texte inconnu (Brown et al., 1993 ; Koehn et al., 
2003). Ainsi un grand corpus parall&#232;le bilingue est pr&#233;alablement n&#233;cessaire. Un tel corpus n&#8217;est pas 
toujours disponible en grande quantit&#233;, surtout pour les langues peu dot&#233;es. Les m&#233;thodes les plus 
communes pour construire des corpus parall&#232;les consistent en des m&#233;thodes automatiques qui collectent des 
paires de phrases parall&#232;les &#224; partir du Web (Resnik, Smith, 2003 ; Kilgarriff, Grefenstette, 2003), ou des 
m&#233;thodes d&#8217;alignement qui extraient des documents/phrases parall&#232;les &#224; partir des deux corpus monolingues 
(Gale, Church, 1993 ; Patry, Langlais, 2005). Il y a aussi les m&#233;thodes d&#8217;extraction de paires de phrases 
parall&#232;les &#224; partir d&#8217;un corpus comparable (Zhao and Vogel, 2002; Fung and Cheung, 2004; Munteanu and 
Marcu, 2006). Ces m&#233;thodes n&#233;cessitent un corpus parall&#232;le initial pour construire le premier syst&#232;me de 
TA qui sera utilis&#233; dans le processus d&#8217;extraction (voir plus de d&#233;tails dans la section 2.1). Nous supposons 
que dans le cas d&#8217;un couple de langues peu dot&#233;, m&#234;me un petit corpus parall&#232;le n&#8217;est pas forc&#233;ment 
disponible pour d&#233;velopper le syst&#232;me de TA initial. La question que nous nous posons alors est : est-ce 
qu&#8217;un processus totalement non-supervis&#233;, initialis&#233; &#224; partir d&#8217;un corpus comparable particuli&#232;rement bruit&#233;, 
permet d&#8217;apporter des solutions au probl&#232;me du manque de donn&#233;es parall&#232;les ?  
Cet article pr&#233;sente une m&#233;thode d&#8217;extraction enti&#232;rement non-supervis&#233;e, qui est compar&#233;e avec une 
m&#233;thode semi-supervis&#233;e. Les premiers r&#233;sultats montrent que la m&#233;thode non-supervis&#233;e peut &#234;tre 
r&#233;ellement appliqu&#233;e dans le cas du manque de donn&#233;es parall&#232;les. La section 2 d&#233;finit les deux m&#233;thodes 
d&#8217;extraction de paires de phrases parall&#232;les &#224; partir d&#8217;un corpus comparable : la m&#233;thode semi-supervis&#233;e et 
la m&#233;thode totalement non-supervis&#233;e. La section 3 pr&#233;sente nos exp&#233;riences et nos r&#233;sultats obtenus 
pr&#233;alablement pour la m&#233;thode non-supervis&#233;e sur des donn&#233;es parall&#232;les bruit&#233;es anglais - fran&#231;ais. La 
section suivante pr&#233;sente une application de cette m&#233;thode sur un corpus comparable d&#8217;un couple de 
langues peu dot&#233; : vietnamien - fran&#231;ais. La derni&#232;re section donne quelques conclusions et perspectives.  
</p>
<p>2 Apprentissage semi-supervis&#233; et non-supervis&#233; 
</p>
<p>2.1 M&#233;thode d&#8217;apprentissage semi-supervis&#233;e 
</p>
<p>Un corpus comparable contient des donn&#233;es qui ne sont pas parall&#232;les (des phrases non-align&#233;es), mais &#171; 
&#233;troitement li&#233;s par les m&#234;mes contenus &#187; (Zhao, Vogel, 2002 ; Fung, Cheung, 2004). Il contient &#171; des 
niveaux de parall&#233;lisme diff&#233;rents, tels que des mots, des cha&#238;nes de mots, des phrases... &#187; (Kumano et al., 
2007). Pour extraire des donn&#233;es parall&#232;les &#224; partir d&#8217;un corpus comparable, (Zhao, Vogel, 2002) 
proposent un crit&#232;re de maximum de vraisemblance qui combine des mod&#232;les de longueur des phrases et un 
mod&#232;le de lexique extrait d&#8217;un corpus parall&#232;le align&#233; existant. Un processus it&#233;ratif est appliqu&#233; pour r&#233;-
apprendre le mod&#232;le de lexique en utilisant les donn&#233;es extraites. (Munteanu, Marcu, 2006) pr&#233;sentent une 
m&#233;thode d&#8217;extraction des fragments parall&#232;les de phrases. Chaque document en langue source est traduit 
vers la langue cible, en utilisant un dictionnaire bilingue. Le document dans la langue cible qui correspond &#224; 
cette traduction est extrait. Des paires de phrases et de fragments parall&#232;les sont extraits &#224; partir de cette 
paire de document en utilisant un lexique de traduction. (Abdul-Rauf, Schwenk, 2009) pr&#233;sentent une 
technique similaire &#224; celle de (Munteanu, Marcu, 2006), mais un syst&#232;me de TA statistique est utilis&#233; au lieu </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>APPRENTISSAGE NON SUPERVISE POUR LA TRADUCTION AUTOMATIQUE  
APPLICATION A UN COUPLE DE LANGUES PEU DOTE 
</p>
<p>d&#8217;un dictionnaire bilingue, et une m&#233;trique d&#8217;&#233;valuation (TER) est utilis&#233;e pour d&#233;cider du degr&#233; de 
parall&#233;lisme entre les phrases. (Sarikaya et al, 2009) pr&#233;sente une m&#233;thode semi-supervis&#233;e avec des 
it&#233;rations lors desquelles les donn&#233;es extraites sont ajout&#233;es au corpus initial parall&#232;le pour re-construire le 
syst&#232;me de traduction. Toutes ces m&#233;thodes sont pr&#233;sent&#233;es comme des m&#233;thodes efficaces pour extraire 
des phrases/fragments parall&#232;les &#224; partir d&#8217;un corpus comparable. 
Dans le contexte de notre travail, on consid&#232;re que les termes corpus &#171; comparable &#187; et corpus &#171; parall&#232;le 
bruit&#233; &#187; ont un sens &#233;quivalent, car un corpus &#171; parall&#232;le bruit&#233; &#187; peut &#234;tre extrait &#224; partir d&#8217;un corpus &#171; 
comparable &#187; en utilisant un module de recherche d&#8217;information (RI) fond&#233; sur des caract&#233;ristiques de base 
comme la date de publication, la longueur de phrases, etc. La proposition d&#8217;approches de RI avanc&#233;es pour 
l&#8217;exploitation le corpus comparable est en dehors du champ de cet article dont le but est pr&#233;cis&#233;ment de 
proposer un processus it&#233;ratif permettant de s&#8217;affranchir de m&#233;thodes de RI avanc&#233;es pour l&#8217;extraction de 
corpus parall&#232;les. 
</p>
<p>2.2 M&#233;thode d&#8217;apprentissage non-supervis&#233;e 
</p>
<p>Les m&#233;thodes present&#233;es ci-dessus peuvent &#234;tre consid&#233;r&#233;es comme des m&#233;thodes semi-supervis&#233;es, qui ont 
besoin d&#8217;un corpus parall&#232;le initial (ou au moins un dictionnaire bilingue) pour construire le syst&#232;me 
d&#8217;extraction. Nous supposons que dans le cas des langues peu dot&#233;es, ce corpus parall&#232;le, m&#234;me de petite 
taille, n&#8217;est pas disponible. Donc, nous proposons ici une m&#233;thode totalement non-supervis&#233;e o&#249; le point de 
d&#233;part est un corpus comparable bruit&#233;. Un des objectifs de ce travail est donc de voir si on peut construire 
un syst&#232;me de TA acceptable &#224; partir d&#8217;un tel point de d&#233;part (corpus comparable bruit&#233;, versus corpus 
vraiment parall&#232;le). La figure 1 illustre la diff&#233;rence entre notre d&#233;finition des deux m&#233;thodes. Dans le cas 
de l&#8217;apprentissage non-supervis&#233;, un syst&#232;me de TA statistique S0 (le syst&#232;me de r&#233;f&#233;rence) est construit &#224; 
partir d&#8217;un corpus comparable (C2) (&#224; l'inverse, dans la m&#233;thode semi-supervis&#233;e, le syst&#232;me S0 est construit 
&#224; partir d&#8217;un corpus parall&#232;le (C1)). Bien s&#251;r, la qualit&#233; de S0 n&#8217;est pas bonne dans le cas non-supervis&#233;. 
Nous proposons d&#8217;utiliser ce syst&#232;me S0 pour exploiter un autre corpus comparable bruit&#233; (D), et aussi 
pour am&#233;liorer la qualit&#233; globale du syst&#232;me de traduction. Le c&#244;t&#233; source du corpus D est traduit par le 
syst&#232;me S0. La sortie est en suite compar&#233;e avec le c&#244;t&#233; cible du corpus D. Une m&#233;trique d&#8217;&#233;valuation est 
calcul&#233;e pour chaque paire de phrases. Plusieurs m&#233;triques d&#8217;&#233;valuation sont envisag&#233;es et compar&#233;es pour 
d&#233;terminer laquelle est le plus appropri&#233;e : BLEU (Papineni et al., 2002), NIST (Doddington, 2002), TER 
(Snover et al., 2006) et une modification de PER : PER* (voir d&#233;tails dans la section 3.3). Une paire est 
consid&#233;r&#233;e comme une paire parall&#232;le si la m&#233;trique d&#8217;&#233;valuation est plus grande (avec les m&#233;triques BLEU, 
NIST, PER*) ou moins grande (avec la m&#233;trique TER) qu&#8217;un certain seuil. 
</p>
<p>  
Figure 1 : M&#233;thode de l&#8217;apprentissage semi supervis&#233;e (a) et non-supervis&#233;e (b) 
</p>
<p>Les paires de phrases extraites sont ensuite combin&#233;es avec le syst&#232;me de r&#233;f&#233;rence S0 selon plusieurs 
mani&#232;res pour cr&#233;er un nouveau syst&#232;me de traduction. Un processus it&#233;ratif est effectu&#233; qui va re-traduire 
le c&#244;t&#233; source par le nouveau syst&#232;me, re-calculer les m&#233;triques d&#8217;&#233;valuation et re-filtrer les paires de 
phrases parall&#232;les. Nous esp&#233;rons que chaque it&#233;ration augmente non seulement le nombre de paires de 
phrases parall&#232;les extraites, mais am&#233;liore &#233;galement la qualit&#233; du syst&#232;me de traduction. Pour utiliser les 
donn&#233;es extraites, quatre combinaisons diff&#233;rentes sont propos&#233;es : 
</p>
<p>Corpus parall&#232;le : C1 
Donn&#233;e 
comparable : D 
</p>
<p>Traduire et 
filtrer par 
m&#233;trique 
</p>
<p>Donn&#233;e 
parall&#232;le SMT0 
</p>
<p>Semi-supervis&#233; 
(a) 
</p>
<p>Corpus comparable : C2 
Donn&#233;e 
comparable : D 
</p>
<p>Traduire et 
filtrer par 
m&#233;trique  
</p>
<p>Non-supervis&#233; 
(b) 
</p>
<p>~ Donn&#233;e 
parall&#232;le SMT0 </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>DO THI NGOC DIEP, LAURENT BESACIER, ERIC CASTELLI 
&#183; W1 : le syst&#232;me de TA &#224; la ieme &#233;tape est entra&#238;n&#233; par un corpus consistant en C2 et Ei-1 (les donn&#233;es 
extraites &#224; la derni&#232;re it&#233;ration) ; E0 &#233;tant les donn&#233;es extraites lorsque le syst&#232;me de TA est entra&#238;n&#233; par 
C2 seulement (S0).  
&#183; W2 : le syst&#232;me de TA &#224; la ieme &#233;tape est entra&#238;n&#233; par un corpus comprenant C2 et E0 + E1 +...+ Ei-1 
(les donn&#233;es sont extraites aux it&#233;rations pr&#233;c&#233;dentes).  
&#183; W3 : &#224; la ieme it&#233;ration, une nouvelle table de traduction est construite bas&#233;e sur des donn&#233;es 
extraites Ei-1. Le syst&#232;me de TA d&#233;code en utilisant deux tables de traduction combin&#233;e dans un mod&#232;le 
log-lin&#233;aire : S0 et cette nouvelle table. Les poids associ&#233;s &#224; chacune des tables sont les m&#234;mes.  
&#183; W4 : la m&#234;me combinaison que W3, mais la table de traduction de S0 et la nouvelle table sont 
combin&#233;es en donnant plus d&#8217;importance aux donn&#233;es extraites Ei-1 (par exemple 1:2). 
</p>
<p>3 Exp&#233;riences pr&#233;liminaires sur des donn&#233;es fran&#231;ais-anglais 
Dans cette section, nous pr&#233;sentons des exp&#233;riences pr&#233;liminaires concernant la m&#233;thode non-supervis&#233;e, 
qui est compar&#233;e &#224; une approche semi-supervis&#233;e. Deux syst&#232;mes ont &#233;t&#233; construits, un fond&#233; sur la 
m&#233;thode semi-supervis&#233;e (Sys1), un autre bas&#233; sur la m&#233;thode non-supervis&#233;e (Sys2). 
</p>
<p>3.1 Pr&#233;paration des donn&#233;es 
</p>
<p>Afin de contr&#244;ler la pr&#233;cision et le rappel de la m&#233;thode d&#8217;extraction, un corpus comparable &#171; artificiel &#187; a 
&#233;t&#233; simul&#233; en assemblant des paires de phrases parall&#232;les et non parall&#232;les, ainsi ces paires sont marqu&#233;es en 
vue de l&#8217;estimation de la pr&#233;cision et du rappel du processus d&#8217;extraction. Nous avons choisi le couple de 
langues fran&#231;ais-anglais pour ces exp&#233;riences pr&#233;liminaires. Les paires de phrases parall&#232;les ont &#233;t&#233; choisies 
dans le corpus Europarl, version 3 (Koehn, 2005). Le corpus comparable &#171; artificiel &#187; a &#233;t&#233; construit par 
l&#8217;introduction d&#8217;un grand nombre de paires de phrases non-parall&#232;les dans les donn&#233;es (environ 50%) (donc 
il peut &#234;tre consid&#233;r&#233; comme un corpus parall&#232;le bruit&#233;). Pour &#234;tre comparable avec le cas r&#233;el trait&#233; dans la 
section 4 (pour les langues peu dot&#233;es), la taille des donn&#233;es exp&#233;rimentales a &#233;t&#233; choisie relativement 
petite. Ainsi, le corpus C1 (cas semi-supervis&#233;, voir fig.1a) ne contient que 50K paires de phrases parall&#232;les 
correctes. Le corpus C2 (cas non supervis&#233;, voir fig.1b) contient 25K paires de phrases parall&#232;les correctes 
(retir&#233;es &#224; partir de C1) et 25K paires de phrases non-parall&#232;les. Le corpus D, donn&#233;es d&#8217;entr&#233;e pour le 
processus d&#8217;extraction, a &#233;t&#233; construit, quant &#224; lui, avec 10K paires de phrases parall&#232;les correctes et 10K 
paires de phrases non-parall&#232;les, diff&#233;rentes des paires de phrases de C1 et C2. 
</p>
<p>3.2 Construction du syst&#232;me 
</p>
<p>Les deux syst&#232;mes Sys1 et Sys2 ont &#233;t&#233; construits en utilisant l&#8217;outil Moses (Koehn et al., 2007). Nous 
avons utilis&#233; les param&#232;tres par d&#233;faut de Moses et le param&#233;trage peut &#234;tre r&#233;sum&#233; comme suit : 
</p>
<p>&#183; L&#8217;outil GIZA++ (Och, Ney, 2003) a &#233;t&#233; utilis&#233; pour l&#8217;alignement au niveau des mots, l&#8217;option pour 
l&#8217;extraction des s&#233;quences est de type &#171; grow-diag-final-and &#187;  
&#183; 14 caract&#233;ristiques ont &#233;t&#233; utilis&#233;es dans le mod&#232;le log-lin&#233;aire : le mod&#232;le de distorsion (6 
caract&#233;ristiques), un mod&#232;le de langage, les probabilit&#233;s de traduction bidirectionnelle au niveau 
s&#233;quence (2 caract&#233;ristiques), les probabilit&#233;s associ&#233;es au lexique bilingue mots (2 caract&#233;ristiques), 
une p&#233;nalit&#233; de phrase, une p&#233;nalit&#233; de mot et une p&#233;nalit&#233; de distance de distorsion.  
&#183; Le mod&#232;le de langage cible (3-gramme) a &#233;t&#233; construit &#224; partir seulement de la partie anglaise du 
corpus Europarl entier en utilisant l&#8217;outil SRILM (Stolcke, 2002).  
&#183; Les mod&#232;les de traduction initiaux ont &#233;t&#233; construits &#224; partir des corpus C1 et C2, pour les 
m&#233;thodes semi-supervis&#233;e et non supervis&#233;e respectivement. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>APPRENTISSAGE NON SUPERVISE POUR LA TRADUCTION AUTOMATIQUE  
APPLICATION A UN COUPLE DE LANGUES PEU DOTE 
</p>
<p>3.3 Commencer &#224; partir d&#8217;un corpus parall&#232;le ou comparable? 
</p>
<p>La premi&#232;re question &#224; laquelle nous voulons r&#233;pondre tout d&#8217;abord est de savoir si le syst&#232;me de TA bas&#233; 
sur un corpus parall&#232;le bruit&#233; ou comparable peut &#234;tre utilis&#233; pour filtrer les donn&#233;es d&#8217;entr&#233;e aussi 
efficacement que le syst&#232;me de TA bas&#233; sur un corpus parall&#232;le. Pour r&#233;pondre &#224; cette question, le c&#244;t&#233; 
fran&#231;ais du corpus D a &#233;t&#233; traduit par les Sys1 et Sys2. Ensuite, les traductions ont &#233;t&#233; compar&#233;es avec le 
c&#244;t&#233; anglais du corpus D. Quatre m&#233;triques d&#8217;&#233;valuation ont &#233;t&#233; utilis&#233;es pour cette comparaison : BLEU, 
NIST, TER et PER*. Notre m&#233;trique PER* (la modification de PER - position-independent word error 
rate (Tillmann et al., 1997)) est calcul&#233;e en se fondant sur la similitude, alors que le PER mesure une erreur 
(les mots diff&#233;rents) entre les hypoth&#232;ses et la r&#233;f&#233;rence. Ainsi la formule de notre PER* est la suivante : 
</p>
<p> 
Ensuite, les distributions des scores d&#8217;&#233;valuation pour les paires de phrases parall&#232;les correctes et les paires 
de phrases non-parall&#232;les sont calcul&#233;es et pr&#233;sent&#233;es dans la figure 2. 
</p>
<p> 
Figure 2 : Les distributions des scores pour la m&#233;thode semi-supervis&#233;e (Sys1) et non-supervis&#233;e (Sys2) 
</p>
<p>Nous pouvons faire les observations suivantes : les distributions des scores ont la m&#234;me forme entre Sys1 et 
Sys2. En particulier, les distributions des scores pour les paires non-parall&#232;les sont presque identiques selon 
les deux syst&#232;mes. Ainsi, un corpus parall&#232;le bruit&#233; ou un corpus comparable peut remplacer un corpus 
parall&#232;le dans la construction du syst&#232;me de TA initial. Par cons&#233;quent, cette m&#233;thode non-supervis&#233;e peut 
&#234;tre r&#233;ellement appliqu&#233;e dans le cas du manque de donn&#233;es parall&#232;les. Un autre r&#233;sultat important est que 
le PER*, un score simple et facile &#224; calculer, peut &#234;tre consid&#233;r&#233; comme le meilleur score pour filtrer les 
paires de phrases parall&#232;les correctes. Le tableau 1 pr&#233;sente la pr&#233;cision et le rappel du filtrage des paires de 
phrases parall&#232;les des deux syst&#232;mes : Sys1 et Sys2. 
</p>
<p>Sys1 &#8211; m&#233;thode semi-supervis&#233;e Sys2 &#8211; m&#233;thode non-supervis&#233;e 
Filtr&#233; par Trouv&#233; Correct Pr&#233;cision Rappel F1-mesure Filtr&#233; par Trouv&#233; Correct Pr&#233;cision Rappel F1-mesure 
Bleu=0.1 6908 6892 99.76 68.92 81.52 Bleu=0.1 6233 6218 99.75 62.18 76.61
Nist=0.4 8350 8347 99.96 83.47 90.97 Nist=0.4 7110 7108 99.97 71.08 83.08
Per*=0.3 10342 9785 94.61 97.85 96.20 Per*=0.3 10110 9468 93.65 94.68 94.16
Per*=0.4 9390 9333 99.39 93.33 96.27 Per*=0.4 8682 8629 99.38 86.29 92.37
Tableau 1 : Pr&#233;cision et rappel du filtrage des paires de phrases parall&#232;les (avec 10K paires des phrases 
</p>
<p>parall&#232;les correctes) </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>DO THI NGOC DIEP, LAURENT BESACIER, ERIC CASTELLI 
3.4 It&#233;rations de la m&#233;thode non-supervis&#233;e 
</p>
<p>La section 3.3 a montr&#233; qu&#8217;une m&#233;thode non-supervis&#233;e peut &#234;tre utilis&#233;e aussi pour filtrer/extraire les 
paires de phrases parall&#232;les &#224; partir d&#8217;un corpus comparable. Toutefois, le r&#233;sultat du filtrage dans le Sys2 
est plus faible que celui dans Sys1 (par exemple, le nombre de paires de phrases correctes extraites est 
r&#233;duit (Tableau 1)). Ainsi nous proposons, dans cette section, un processus it&#233;ratif, afin d&#8217;am&#233;liorer la 
qualit&#233; du syst&#232;me de traduction, puis d&#8217;augmenter le nombre de paires de phrases extraites correctement.  
</p>
<p>Augmenter le nombre de paires de phrases correctes extraites : Les paires de phrases extraites sont 
combin&#233;es avec le syst&#232;me de r&#233;f&#233;rence S0 de quatre mani&#232;re diff&#233;rentes (comme mentionn&#233; dans la section 
2.2). L&#8217;exp&#233;rience avec les it&#233;rations a &#233;t&#233; effectu&#233;e pour le Sys2 (non-supervis&#233;). Afin de recevoir le 
nombre maximal de paires de phrases correctes extraites, pour toutes les it&#233;rations, on a choisi le score 
d&#8217;&#233;valuation PER* avec le seuil = 0,3, qui a donn&#233; le rappel maximum = 94,68% pour le syst&#232;me de 
r&#233;f&#233;rence. La figure 3 pr&#233;sente le nombre de paires de phrases extraites correctement apr&#232;s 6 it&#233;rations pour 
les quatre combinaisons diff&#233;rentes : W1, W2, W3 et W4 d&#233;crites dans la section 2.2. Le nombre de paires 
correctes extraites est augment&#233; dans tous les cas, mais la combinaison W2 introduit le plus grand nombre 
de paires de phrases correctes extraites.  
</p>
<p>Augmenter la pr&#233;cision et le rappel du processus de filtrage : La pr&#233;cision et le rappel de ces quatre 
combinaisons sont pr&#233;sent&#233;s dans la figure 4. Parce que le processus de filtrage se concentre sur l&#8217;extraction 
du plus grand nombre de paires de phrases correctes extraites, la pr&#233;cision diminue. Toutefois, en utilisant 
la combinaison W2, le rappel apr&#232;s 6 it&#233;rations (97,77) atteint presque le rappel du syst&#232;me semi-supervis&#233; 
Sys1 (97,85). 
</p>
<p>&#201;valuation du syst&#232;me de TA : La qualit&#233; du syst&#232;me de TA est &#233;valu&#233;e &#233;galement. Un ensemble de test 
contenant 400 paires de phrases parall&#232;les Fran&#231;ais-Anglais qui ont &#233;t&#233; extraites du corpus Europarl, est 
utilis&#233;. Chaque phrase fran&#231;aise n&#8217;a qu&#8217;une seule r&#233;f&#233;rence en anglais. La qualit&#233; est calcul&#233;e selon BLEU et 
TER. La figure 5 donne les scores d&#8217;&#233;valuation pour les syst&#232;mes apr&#232;s chaque it&#233;ration. 
</p>
<p> 
Figure 3 : Nombre de paires de phrases extraites 
</p>
<p>correctement apr&#232;s 6 it&#233;rations pour quatre 
combinaisons diff&#233;rentes 
</p>
<p> 
Figure 4 : Pr&#233;cision et rappel du filtrage en utilisant 
</p>
<p>des combinaisons diff&#233;rentes 
</p>
<p> 
Figure 5 : &#201;valuation des syst&#232;mes de traduction 
</p>
<p>L&#8217;&#233;valuation du syst&#232;me de TA r&#233;v&#232;le un r&#233;sultat important. La qualit&#233; du syst&#232;me de TA augmente 
rapidement au cours des premi&#232;res it&#233;rations, mais diminue apr&#232;s. On peut expliquer que, dans les premi&#232;res 
it&#233;rations, un grand nombre de paires de phrases parall&#232;les nouvelles sont extraites et sont incluses dans le 
mod&#232;le de traduction. Toutefois, dans les it&#233;rations suivantes, lorsque la pr&#233;cision du processus d&#8217;extraction </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>APPRENTISSAGE NON SUPERVISE POUR LA TRADUCTION AUTOMATIQUE  
APPLICATION A UN COUPLE DE LANGUES PEU DOTE 
</p>
<p>diminue, des paires de phrases non parall&#232;les sont ajout&#233;es au syst&#232;me ; le mod&#232;le de traduction est alors 
d&#233;grad&#233; et la qualit&#233; du syst&#232;me de TA est r&#233;duite. Apr&#232;s environ 3 it&#233;rations, le score BLEU peut 
augmenter d&#8217;environ 2 points. On notera qu&#8217;il n&#8217;y a ici aucun r&#233;glage des param&#232;tres du mod&#232;le log-lin&#233;aire 
&#224; chaque it&#233;ration (pas de donn&#233;es de d&#233;veloppement utilis&#233;es, etc.). 
</p>
<p>(Sarikaya et al, 2009) pr&#233;sente une m&#233;thode semi-supervis&#233;e avec des it&#233;rations mais le syst&#232;me de TA 
initial est fond&#233; sur un corpus parall&#232;le. Il utilise la m&#233;trique d&#8217;&#233;valuation Bleu pour le filtrage, et une 
combinaison semblable &#224; notre combinaison W2. Cependant, leur recherche ne fournit pas une explication 
compl&#232;te sur la fa&#231;on dont ils choisissent la m&#233;trique d&#8217;&#233;valuation, ou la m&#233;thode de combinaison (une 
seule est propos&#233;e &#224; chaque fois), et en plus, la diminution de la qualit&#233; du syst&#232;me de TA apr&#232;s plusieurs 
it&#233;rations n&#8217;est pas mentionn&#233;e. 
</p>
<p>4 Application pour le couple de langues vietnamien-fran&#231;ais 
Le vietnamien est la 14eme langue la plus parl&#233;e dans le monde. Cependant, les recherches sur la TA pour le 
Vietnamien sont rares. Le plus ancien syst&#232;me de TA pour le Vietnamien est le syst&#232;me de &#171; Logos 
Corporation &#187; des ann&#233;es 1970. Ce syst&#232;me a &#233;t&#233; d&#233;velopp&#233; pour traduire des manuels d&#8217;utilisation en 
a&#233;ronautique de l&#8217;anglais vers le vietnamien (Hutchins, 2001). Au Vietnam, jusqu&#8217;&#224; pr&#233;sent, on compte peu 
de groupes de recherche travaillant sur la TA vietnamien - anglais (Ho, 2005) et les r&#233;sultats obtenus par les 
syst&#232;mes sont modestes. Nous nous concentrons sur la construction d&#8217;un syst&#232;me de TA statistique 
vietnamien-fran&#231;ais. Le corpus d&#8217;apprentissage a &#233;t&#233; cr&#233;&#233; par l&#8217;exploitation d&#8217;un corpus des nouvelles 
journalistiques (news) collect&#233; &#224; partir du Web.  
</p>
<p>Une des m&#233;thodes d&#8217;exploitation a d&#233;j&#224; &#233;t&#233; pr&#233;sent&#233;e par les auteurs de cet article dans (Do et al., 2009). 
Cette m&#233;thode est bas&#233;e sur l&#8217;utilisation de la date de publication, des mots sp&#233;ciaux et des scores 
d&#8217;alignement des phrases. D&#8217;abord, les paires de documents parall&#232;les possibles sont filtr&#233;s utilisant la date 
de publication et les mots sp&#233;ciaux (les num&#233;ros, les symboles joints, les entit&#233;s nomm&#233;es). Deuxi&#232;mement, 
des phrases dans une paire de documents parall&#232;les possibles sont align&#233;es en utilisant l&#8217;outil Champollion 
(Ma, 2006), qui utilise des informations lexicales (lex&#232;mes, mots vides, dictionnaire bilingue, etc.). Enfin, 
des paires de phrases parall&#232;les sont extraites en utilisant des informations d&#8217;alignement, des informations de 
longueur et un lexique du document. Cette m&#233;thode a &#233;t&#233; appliqu&#233;e pour exploiter un corpus de texte &#224; 
partir d&#8217;un site Web multilingue d&#8217;actualit&#233;s, le Vietnam News Agency1 (VNA) (contenant 20.884 
documents fran&#231;ais et 54.406 documents vietnamiens) qui est un corpus v&#233;ritablement comparable : m&#234;mes 
sujets trait&#233;s, mais pas d&#8217;alignement &#233;vident en phrases. 50.322 paires de phrases &#171; parall&#232;les &#187; ont &#233;t&#233; 
extraites. Un syst&#232;me de TA statistique pour le vietnamien-fran&#231;ais a ensuite &#233;t&#233; construit en utilisant l&#8217;outil 
Moses avec les m&#234;mes param&#232;tres par d&#233;faut que ceux d&#233;crits dans la section 3.2 (voir plus dans (Do et al., 
2009)). Ici, nous souhaitons comparer notre m&#233;thode non-supervis&#233;e, avec la m&#233;thode d&#8217;extraction 
pr&#233;sent&#233;e dans (Do et al., 2009). La m&#233;thode propos&#233;e a &#233;t&#233; appliqu&#233;e sur le m&#234;me corpus de VNA. Au 
lieu d&#8217;aligner les phrases et de les filtrer par des informations d&#8217;alignement de phrases, nous cr&#233;ons un 
corpus comparable et appliquons la m&#233;thode non-supervis&#233;e propos&#233;e directement sur ce corpus bruit&#233;. 
</p>
<p>4.1 Pr&#233;paration des donn&#233;es 
</p>
<p>Chaque phrase dans un document vietnamien a &#233;t&#233; fusionn&#233;e avec toutes les phrases dans le document 
fran&#231;ais correspondant. Ainsi une paire de documents vietnamien (contenant m phrases) et fran&#231;ais 
(contenant n phrases) produit mxn paires de phrases. A partir du corpus VNA, nous avons obtenu un 
                                               
1 http://www.vnagency.com.vn/ </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>DO THI NGOC DIEP, LAURENT BESACIER, ERIC CASTELLI 
corpus comparable de 1.442.448 de paires de phrases. Nous avons gard&#233; seulement les paires avec le 
rapport de longueur (compt&#233; en mots) de la phrase fran&#231;aise et de la phrase vietnamienne entre 0,8 et 1,3. 
Nous avons obtenu ainsi un corpus comparable de 345.575 paires de phrases (nomm&#233; Call). 
</p>
<p>4.2 Cr&#233;ation du syst&#232;me de traduction initial 
</p>
<p>Afin d&#8217;appliquer la m&#233;thode non-supervis&#233;e propos&#233;e, nous avons divis&#233; le corpus Call en deux ensembles : 
un corpus d&#8217;apprentissage initial C2 et un corpus &#224; &#171; fouiller &#187; D (C2 et D sont indiqu&#233;es dans la figure 1). 
Pour garantir une qualit&#233; minimale de C2 (et par cons&#233;quent pour la syst&#232;me de TA initial S0), nous 
proposons ci-dessous un processus de filtrage crois&#233; pour extraire le corpus C2 : 
</p>
<p>&#183; Diviser le corpus Call en 4 sous-corpus contenant des paires de phrases diff&#233;rentes : SC1 (85.011 
paires de phrases), SC2 (85.008 paires de phrases), SC3 (86.529 paires de phrases), SC4 (89.027 paires 
de phrases).  
&#183; Construire 4 syst&#232;mes de TA diff&#233;rents : SC1&#8594;SMTSC1, SC2&#8594;SMTSC2, SC3&#8594;SMTSC3, 
SC4&#8594;SMTSC4.  
&#183; Appliquer la m&#233;thode non-supervis&#233;e pour chaque paire (SC1, SMTSC2), (SC2, SMTSC1), (SC3, 
SMTSC4), (SC4, SMTSC3), (une it&#233;ration seulement ; seuil de PER* = 0,45 pour assurer la fiabilit&#233; des 
paires de phrases extraites (selon la figure 2) et un nombre acceptable de paires pour construire le 
syst&#232;me de traduction). Nous obtenons les paires de phrases extraites C21, C22, C23, C24, et leur union 
est consid&#233;r&#233;e comme suffisamment fiable pour servir comme corpus comparable initial C2. Le reste est 
trait&#233; comme le corpus D. 
</p>
<p> 
Figure 6 : Procesus d&#8217;extraction du corpus C2, pour 
</p>
<p>la paire (SC1, SMTSC2), (SC2, SMTSC1), etc. 
</p>
<p>Sous-
corpus 
</p>
<p>Traduit 
par 
</p>
<p>Nombre de 
paires C2 
</p>
<p>Nombre de 
paires D 
</p>
<p>SC1 SMTSC2 C21 : 2916 82095 
SC2 SMTSC1 C22 : 3495 81513 
SC3 SMTSC4 C23 : 3820 82709 
SC4 SMTSC3 C24 : 3892 85135 
Tableau 2 : Donn&#233;es extraites pour C2 et D 
</p>
<p> 
Apr&#232;s cette &#233;tape, nous avons obtenu un corpus C2 contenant 14.123 paires de phrases, et un corpus D 
contenant 331.452 paires de phrases. La m&#233;thode non-supervis&#233;e d&#233;crite dans la section 2.2 est ensuite 
appliqu&#233;e sur C2 et D pour extraire plus de paires de phrases parall&#232;les. 
</p>
<p>4.3 Application de la m&#233;thode non-supervis&#233;e 
</p>
<p>Le premier syst&#232;me de TA vietnamien-fran&#231;ais S0 a &#233;t&#233; construit &#224; partir du corpus d&#8217;apprentissage C2 de 
14.123 paires de phrases. Le corpus D contient 331.452 paires de phrases. La m&#233;thode non-supervis&#233;e a &#233;t&#233; 
appliqu&#233;e avec le type de combinaison W2 et la m&#233;trique d&#8217;&#233;valuation PER*. Il n&#8217;y a pas de processus de 
r&#233;glage des poids des mod&#232;les log-lin&#233;aires de traduction. Le nombre de paires de phrases extraites apr&#232;s 
chaque it&#233;ration est indiqu&#233; dans la figure 7. Apr&#232;s 5 it&#233;rations, nous avons obtenu 39.758 paires. La qualit&#233; 
du syst&#232;me de TA est &#233;valu&#233;e &#233;galement sur un ensemble de test de 400 paires de phrases parall&#232;les 
extraites manuellement (le m&#234;me ensemble de test que dans (Do et al., 2009)). Les phrases en vietnamien 
sont segment&#233;es en syllabes (pas de segmentation en mots). Chaque phrase vietnamienne n&#8217;a qu&#8217;une seule 
r&#233;f&#233;rence en fran&#231;ais. Les scores d&#8217;&#233;valuation apr&#232;s chaque it&#233;ration sont report&#233;s dans le tableau 3. Les 
r&#233;sultats dans ce cas sont similaires &#224; ceux obtenus lors des exp&#233;riences pr&#233;liminaires : le nombre de paires 
de phrases extraites augmente apr&#232;s quelques it&#233;rations, la qualit&#233; du syst&#232;me de TA augmente &#233;galement 
lors des premi&#232;res it&#233;rations et diminue par la suite. 
</p>
<p>SC1 
</p>
<p>SC2 
</p>
<p>SMTsc2 Traduire +  filtrer par PER* C21 
</p>
<p>SC2 
</p>
<p>SC1 
</p>
<p>SMTsc1 
Traduire + 
filtrer par PER* 
</p>
<p>C22 
&#8230; </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>APPRENTISSAGE NON SUPERVISE POUR LA TRADUCTION AUTOMATIQUE  
APPLICATION A UN COUPLE DE LANGUES PEU DOTE 
</p>
<p> 
Figure 7 : Nombre de paires de phrases extraites apr&#232;s 
</p>
<p>chaque it&#233;ration dans le syst&#232;me de TA VN-FR 
</p>
<p>iter. Donn&#233;es 
d&#8217;apprentissage 
</p>
<p>Bleu Nist Ter 
</p>
<p>0 14.123 30,67 6,45 0,59 
1 26.517 32,18 6,70 0,57 
2 37.210 32,42 6,75 0,56 
3 38.530 32,45 6,77 0,55 
4 39.254 32,14 6,73 0,56 
5 39.758 31,85 6,68 0,56 
</p>
<p>Tableau 3 : Scores d&#8217;&#233;valuation apr&#232;s chaque 
it&#233;ration pour le syst&#232;me de TA VN-FR 
</p>
<p>Bien que le nombre de paires de phrases d&#8217;apprentissage ait augment&#233; d&#8217;environ deux fois de l&#8217;it&#233;ration 0 &#224; 
l&#8217;it&#233;ration 1, le score d&#8217;&#233;valuation n&#8217;augmente que de 2 points pour BLEU. Une raison est peut &#234;tre que le 
syst&#232;me initial (S0) a d&#233;j&#224; une bonne performance gr&#226;ce &#224; notre filtrage crois&#233; d&#233;crit dans la section 4.2. En 
outre, l&#8217;&#233;valuation est conduite exclusivement avec des m&#233;triques automatiques en utilisant une seule 
r&#233;f&#233;rence, donc une analyse plus approfondie devrait &#234;tre men&#233;e avec des &#233;valuations subjectives. Pour 
comparer avec la m&#233;thode d&#8217;exploitation pr&#233;sent&#233;e dans (Do et al., 2009), la qualit&#233; des syst&#232;mes de TA 
des deux m&#233;thodes (&#233;valu&#233;e sur le m&#234;me corpus) est donn&#233;e dans le tableau 4. Bien que le nombre de paires 
de phrases extraites dans notre m&#233;thode soit plus faible que celui dans (Do et al., 2009), la qualit&#233; du 
syst&#232;me de TA est comparable. La m&#233;thode propos&#233;e dans (Do et al., 2009) d&#233;pend cependant de donn&#233;es / 
informations suppl&#233;mentaires telles que la qualit&#233; du dictionnaire bilingue ou des r&#232;gles heuristiques. 
</p>
<p>M&#233;thodes Donn&#233;e d&#8217;apprentissage Bleu Nist Ter 
 Informations lexicales  
+ heuristiques (Do et al., 2009) 50.322 32,74 6,78 0,55 
</p>
<p> Non-supervis&#233;e (it. 3) 38.530 32,45 6,77 0,55 
Tableau 4 : Comparaison entre la m&#233;thode d&#8217;exploitation de (Do et al., 2009) et la m&#233;thode non-supervis&#233;e 
A partir de ces r&#233;sultats, nous pouvons dire que la m&#233;thode non-supervis&#233;e a &#233;t&#233; appliqu&#233;e avec succ&#232;s 
pour une couple de langues peu dot&#233; : vietnamien-fran&#231;ais. Le r&#233;sultat montre que cette m&#233;thode peut &#234;tre 
r&#233;ellement appliqu&#233;e dans le cas d&#8217;un manque de donn&#233;es parall&#232;les. En outre, la qualit&#233; du syst&#232;me de TA 
construit &#224; partir des donn&#233;es extraites est comparable avec celle du syst&#232;me de TA d&#8217;une autre m&#233;thode 
utilisant des informations lexicales et des filtrages heuristiques. Cette m&#233;thode propos&#233;e ne n&#233;cessite pas de 
donn&#233;es suppl&#233;mentaires. Nous avons l&#8217;intention d&#8217;appliquer cette m&#233;thode &#224; une plus grande &#233;chelle pour 
exploiter un plus grand flux de donn&#233;es comparables extraites du Web. 
</p>
<p>5 Conclusions et perspectives 
Cet article pr&#233;sente une m&#233;thode non-supervis&#233;e pour l&#8217;extraction de paires de phrases parall&#232;les &#224; partir 
d&#8217;un corpus comparable. Un syst&#232;me de TA initial a &#233;t&#233; construit, fond&#233; sur un corpus parall&#232;le bruit&#233; ou 
comparable, au lieu d&#8217;un corpus parall&#232;le. Le syst&#232;me de TA initial a &#233;t&#233; ensuite utilis&#233; pour traduire un 
autre corpus comparable. Un processus it&#233;ratif a &#233;t&#233; &#233;valu&#233; pour augmenter le nombre de paires de phrases 
parall&#232;les extraites et pour am&#233;liorer la qualit&#233; du syst&#232;me de traduction. Les exp&#233;riences montrent que 
cette m&#233;thode peut &#234;tre r&#233;ellement appliqu&#233;e, notamment dans le cas du manque de donn&#233;es parall&#232;les. 
Plusieurs m&#233;thodes de filtrage et utilisant les donn&#233;es extraites ont &#233;galement &#233;t&#233; pr&#233;sent&#233;es. Un r&#233;sultat 
int&#233;ressant est que la qualit&#233; du syst&#232;me de TA peut &#234;tre am&#233;lior&#233;e au cours des premi&#232;res it&#233;rations, mais 
elle est d&#233;grad&#233;e plus tard en raison de l&#8217;ajout de donn&#233;es bruit&#233;es dans les mod&#232;les statistiques. En outre, 
la qualit&#233; du syst&#232;me de TA construit avec cette m&#233;thode est comparable &#224; celle d&#8217;une autre m&#233;thode qui 
n&#233;cessite des donn&#233;es de meilleure qualit&#233; comme un dictionnaire bilingue, des heuristiques etc. Dans </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>DO THI NGOC DIEP, LAURENT BESACIER, ERIC CASTELLI 
l&#8217;avenir, nous nous concentrerons sur l&#8217;approfondissement de l&#8217;analyse des meilleures techniques de filtrage, 
sur l&#8217;exp&#233;rimentation &#224; plus grande &#233;chelle, et sur des &#233;valuations subjectives pour confirmer notre m&#233;thode 
non-supervis&#233;e. 
</p>
<p>6 R&#233;f&#233;rences 
ABDUL-RAUF S., SCHWENK H. (2009). On the use of comparable corpora to improve SMT performance, Proceedings of the 
12th Conference of the European Chapter of the Association for Computational Linguistics.  
BROWN P.F., PIETRA S.A.D., PIETRA V.J.D., MERCER R.L. (1993). The mathematics of statistical machine translation: 
parameter estimation. Computational Linguistics. Vol. 19, no. 2. 
DO T.N.D., LE V.B., BIGI B., BESACIER L., CASTELLI E. (2009). Exploitation d&#8217;un corpus bilingue pour la cr&#233;ation d&#8217;un syst&#232;me 
de traduction probabiliste Vietnamien - Fran&#231;ais. TALN 2009. 
DODDINGTON  G. (2002). Automatic evaluation of machine translation quality using n-gram co-occurrence statistics. In Human 
Language Technology Proceedings.  
FUNG P., CHEUNG P. (2004). Mining very-non-parallel corpora: parallel sentence and lexicon extraction via bootstrapping and 
EM. Conference on Empirical Methods on Natural Language Processing. 
GALE W.A., CHURCH K.W. (1993). A program for aligning sentences in bilingual corpora. Proceedings of the 29th annual 
meeting on Association for Computational Linguistics. 
HO T.B. (2005). Current status of machine translation research in vietnam, towards asian wide multi language machine 
translation project. Vietnamese Language and Speech Processing Workshop. 
HUTCHINS W.J. (2001). Machine translation over fifty years. Histoire, epistemologie, langage. ISSN 0750-8069. 
KILGARRIFF A, GREFENSTETTE G. (2003). Introduction to the special issue on the Web as corpus. Computational Linguistics, 
volume 29. 
KOEHN P. (2005). Europarl: a parallel corpus for statistical machine translation. Machine Translation Summit. 
KOEHN P., OCH F.J., MARCU D. (2003). Statistical phrase-based translation. Conference of the North American Chapter of the 
Association for Computational Linguistics on Human Language Technology Vol. 1. 
KOEHN P., HOANG H., BIRCH A., CALLISON-BURCH C., ZENS R., FEDERICO M., BERTOLDI N., COWAN B., SHEN W., MORAN C. 
(2007). Moses: open source tool-kit for statistical machine translation. Proceedings of the Association for Computational 
Linguistics. 
KUMANO, T., TANAKA H., TOKUNAGA T. (2007). Extracting phrasal alignments from comparable corpora by using joint 
probability SMT model. Conference on Theoretical and Methodological Issues in Machine Translation. 
MA X. (2006). Champollion: A robust parallel text sentence aligner. LREC: Fifth International Conference on Language 
Resources and Evaluation. 
MUNTEANU D.S., MARCU D. (2006). Extracting parallel sub-sentential fragments from non-parallel corpora. 44th annual 
meeting of the Association for Computational Linguistics. 
OCH F.J., NEY H. (2003). A systematic comparison of various statistical alignment models. Computational Linguistics 29.1  
PAPINENI K., ROUKOS S., WARD T., ZHU W. (2002). BLEU:a method for automatic evaluation of machine translation. In 
Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics. 
PATRY A., LANGLAIS P. (2005). Paradocs: un syst&#232;me d&#8217;identification automatique de documents parall&#232;les. 12e Conference 
sur le Traitement Automatique des Langues Naturelles. 
RESNIK P., SMITH N.A. (2003). The Web as a parallel corpus. Computational Linguistics.  
SARIKAYA R., MASKEY S., ZHANG R., JAN E., WANG D., RAMABHADRAN B., ROUKOS S. (2009). Iterative sentence&#8211;pair extraction 
from quasi&#8211;parallel corpora for machine translation. Interspeech. 
SNOVER M., DORR B., SCHWARTZ R., MICCIULLA L., MAKHOUL J. (2006). A study of translation edit rate with targeted human 
annotation. Proceedings of Association for Machine Translation in the Americas. 
STOLCKE A. (2002). SRILM an extensible language modeling toolkit. Intl. Conf. on Spoken Language Processing. 
TILLMANN C., VOGEL S., NEY H., ZUBIAGA A., SAWAF H. (1997). Accelerated DP based search for statistical translation. In 5th 
European Conf. on Speech Communication and Technology. 
ZHAO B., VOGEL S. (2002). Adaptive parallel sentences mining from Web bilingual news collection. International Conference 
on Data Mining. </p>

</div></div>
</body></html>